FLawN-T5: An Empirical Examination of Effective Instruction-
Tuning Data Mixtures for Legal Reasoning
JoelNiklausSX LuciaZhengS AryaD.McCarthy J ChristopherHahnX BrianM.RosenX
PeterHendersonSP∗ DanielE.HoS∗ GarrettHonkeX∗ PercyLiangS∗ ChristopherManningS∗
SStanfordUniversity JJohnsHopkinsUniversity XX,theMoonshotFactory PPrincetonUniversity
Abstract
Instruction tuning is an important step in making language models useful for
directuserinteraction. However,manylegaltasksremainoutofreachformost
openLLMsandtheredonotyetexistanylargescaleinstructiondatasetsforthe
domain. Thiscriticallylimitsresearchinthisapplicationarea. Inthiswork,we
curateLawInstruct,alargelegalinstructiondataset,covering17jurisdictions,24
languagesandatotalof12Mexamples. Wepresentevidencethatdomain-specific
pretrainingandinstructiontuningimproveperformanceonLegalBench,including
improvingFlan-T5XLby8pointsor16%overthebaseline. However,theeffect
doesnotgeneralizeacrossalltasks,trainingregimes,modelsizes,andotherfactors.
LawInstructisaresourceforacceleratingthedevelopmentofmodelswithstronger
informationprocessinganddecisionmakingcapabilitiesinthelegaldomain.
1 Introduction
Inrecentyears,LargeLanguageModels(LLMs)advancedsignificantly,evidentintheirperformance
gainsacrossnumerousbenchmarks,includingSuperGLUE(Wangetal.,2019),MMLU(Hendrycks
etal.,2021b),andvarioushumanexaminations(OpenAI,2023),suchastheU.S.barexamsforlaw
practiceadmission(Katzetal.,2023). However,theinterplaybetweendomain-specifictrainingand
within-domainevaluationispoorlyunderstood. Thisworkexamineshowtrainingondomain-specific
legalcorporaaffectsperformanceonthewidestsetoflegal-domainevaluationbenchmarksknownto
theauthors. Wethusconductastudyoftheabilityofmodelstoanswerquestions,classify,make
judgments,extractinformation,andotherwiseperformdecisionmakingorhigher-ordercognitive
tasks(i.e.,to“reason”)withinalimiteddomain,asopposedtobroad-domainbenchmarking. We
presentevidencethatdomain-specificpretrainingandinstructiontuningimproveperformance—but
theeffectdoesnotgeneralizeacrossalltasks,trainingregimes,modelsizes,andotherfactors.
Althoughlargeclosedmodelsalsostillhallucinateheavilyonlegaltexts(Dahletal.,2024),they
achievemuchbetterperformanceonLegalBenchthansmalleropenmodels(e.g.,77.3forGPT-4
vs.60.1forFlan-T5XXL,thestate-of-the-artopenmodel). Inthelegaldomainitisoftencrucial
forreasonsoftrustanddataprotectionnottousepublicmodels,somanyfirmsneedon-premise
deployments. ThereforemodelslikeClaudeorGPT-4cannotbeused,stressingtheneedforopen
models. Inthisstudy,weexplorethepotentialofenhancingmodelperformancethroughin-domain
instructiontuningandcontinuedpretrainingonFlan-T5,thecurrentstate-of-the-artopenmodelon
LegalBenchinboththe3Band11Brange.
Tostudythis,weusetheMultiLegalPile(Niklausetal.,2023b),a689GBmultilinguallegalcorpus,
forcontinuedpretraining.Becausenoinstructiondatasetforlegalreasoningisavailable,weintroduce
LawInstruct,spanning24languagesin17jurisdictionsonfourcontinents. Itcontains12Mtraining
examplesforQA,entailment,summarization,andinformationextractiontasksinthelegaldomain,
each presented as a bespoke instruction with corresponding output. With this large instruction
datasetinhand,wefine-tunemodelsandthenperformquantitativeanalysesoftheiroutputsonthe
LegalBench(Guhaetal.,2023)andMMLU(Hendrycksetal.,2021a)benchmarksuites. Instruction
∗equalco-supervisioninalphabeticalorder
1
4202
rpA
2
]LC.sc[
1v72120.4042:viXraFigure1: WecontinuepretrainingonMultiLegalPile,instructiontuneonLawInstructandevaluate
onLegalBenchandMMLU.
tuningFlan-T5modelsonLawInstruct,weachieveabalancedaccuracyof58.1onLegalBenchfor
theXLsize,improvingby8pointsor16%overthebaseline. TheSmallmodelevenimprovesby9.6
pointsor38.1%andby14pointsor55.4%whenwealsocontinuepretrainingit.
Thecontributionsofthispaperarefour-fold: First,wecuratethefirstlegalinstructiondatasetby
unifyingandwritinginstructionsfor58high-qualityannotateddatasetscoveringdiverselegaltasks.
Second, wecontinuepretrainingandinstructiontuneT5, mT5, andFlan-T5modelsandachieve
newstate-of-the-artonLegalBenchinalltestedparameterranges. Third,weperformawiderange
ofablationsacrossdifferentdatasetconfigurationsprovidingnewinsightsfordomainadaptation.
Finally,wepubliclyreleasethepermissively-licensedportionofthecurateddatasetontheHugging
FaceHub1andreleasethecodeusedtocreatethedataset2includingpointersonhowtoaccessthe
portionsofthedatathatrequirespecialagreements.
2 ExperimentalSetup
In this section, we describe the experimental setup we used to test the effect of pretraining and
instructiontuningonin-domainlegaldata. WeconsiderT5v1.1+LMadaptation(Raffeletal.,2020;
Lesteretal.,2021),Flan-T5(Chungetal.,2022)andmT5(Xueetal.,2021)modelsinthesizes
Small,Base,XLandXXL,allowingustostudyeffectsoverdifferentmodelscales. Weselectedthe
T5familyofmodelsoverothermodelsforthreereasons: 1)Flan-T5XLandXXLperformbestin
theirparameterrangeonLegalBench,2)T5andmT5allowustomeasuretheeffectofmultilinguality
inacontrolledsetting,and3)theT5modelfamilycontainsmodelsfrom60Mparameters(Small)to
11B(XXL)allowingustostudyscalingbehaviouralsoatsmallerscales.
Weusedrandomseed42throughout. OurexperimentswereperformedwithT5X3onTPUv4pods
usingbetween2and512cores. WepresentthemeanacrosstasksperLegalBenchcategoryandfor
LegalBenchoverallbyaggregatingoverthecategories.
2.1 ContinuedPretraining
We continue pretraining on the MultiLegalPile (Niklaus et al., 2023b), a 689GB corpus in 24
languages from 17 jurisdictions. The MultiLegalPile corpus, which includes diverse legal data
sourceswithvaryinglicenses,allowsforpretrainingNLPmodelsunderfairuse,withmorepermissive
licensesfortheEurlexResourcesandLegalmC4subsets. Itconsistsoffourlargesubsets: a)Native
Multi Legal Pile (112 GB), b) Eurlex Resources (179 GB), c) Legal mC4 (106 GB), and d) Pile
ofLaw(292GB).ForourexperimentsonthemT5models,weusetheentirecorpus,andforthe
experimentsontheT5andFlan-T5modelsweuseonlythetextsintheEnglishlanguage.
Wecontinuedpretraining(a.k.a.domainadaptationof)themodelswith512tokensinbothinputsand
targetsontheMultiLegalPile(Niklausetal.,2023b)whereastheoriginalmodelswerepretrained
onC4(Raffeletal.,2020). WeusedtheUL2mixture(Tayetal.,2022)duetoitspromisetoenable
1https://huggingface.co/lawinstruct/lawinstruct
2https://github.com/JoelNiklaus/LawInstruct/
3https://github.com/google-research/t5x
2Instruction:Answerthefollowinglegalquestion.Citerelevantevidencewhenpossible.
Prompt: Question: So say a bank robber walks into a bank and hands the teller a note saying
simply"pleasegiveme$1,000"(ormaybeevenjustverballysaying"Ineed$1,000please")andiftheteller
accepts, whichtheyprobablywouldbecausethey’resupposedtocomplywiththerobber, hetakesthe
money,otherwiseiftheyrefuse,heleaves.Howisthisdifferentthansaypeopleaskingforcharitydonations
inthestreet?Hejustpolitelyrequestedmoneywithoutmakinganythreats.
Answer: Answer: As a concrete example, consider Missouri v. Coleman, where Coleman handed
atelleraplasticbagandsaid"Ineedyoutodomeafavor. Putthemoneyinthisbag",andlaterasthe
managerapproached,said"Ma’am,stopwhereyouareanddon’tmoveanyfarther".Colemanwasconvicted
ofseconddegreerobbery:buttheappealscourtfoundthathehadnotactedforcibly,sohisconvictionwas
overturned. Instead,thecourtenteredaconvictionforthelesseroffenseofstealingwhichiswhenone
appropriatespropertyorservicesofanotherwiththepurposetodeprivehimorherthereof,eitherwithout
hisorherconsentorbymeansofdeceitorcoercion.Theactmayalsobetermed"theft",asinWashington
state.Thethiefisactingdeceptivelyandtherebygainingcontroloverproperty.
Figure 2: Instruction template in LawInstruct for StackExchangeQuestionsLegal populated with
instruction, prompt and answer. Models are trained to generate the answer conditioned on the
instructionandprompt.
improvedtrainingefficiencywithitsmixtureofdenoiserstasks. Ininitialexperimentsweusedbatch
size1024andwarmedupthelearningratelinearlyforthefirst10Kstepsfrom2.5e-3to5e-3and
finallydecayeddownto1.5e-3. However,wenoticedtraininginstabilitiesfortheXXLmodels. We
switchedtoaconstantlearningrateof1e-3andranasweepoverbatchsizes64,128,256,512,1024.
TheXXLmodelonlytrainedstablywithbatchsize128.
2.2 InstructionTuning
Inthispaper,weareinterestedintheabilityoflargelanguagemodelstoanswerquestions,make
judgments,andperformdecisionmaking(i.e.,to“reason”)withinthelegaldomain. Legalreasoning
isoftenhighlysensitive,andthestrugglesoffactualityinLLMsleadtolegalesewith“bogusjudicial
decisions, bogus quotes, and bogus internal citations” (Weiser, 2023; Dahl et al., 2024). In the
absenceoflegalinstructiondatasetsandtoevaluatetheeffectoflegalinstructiontuningonmodels’
capability to reason in legal domains, we develop LawInstruct: a large instruction dataset that
normalizesandadapts58existingornovellegal-domaindatasetswithcustomtemplates. LawInstruct
isthefirstinstructiondatasetinthelegaldomainknowntotheauthors. Weattemptedtocollecta
broadsampleofdatasetstoexposethemodeltoavarietyoflegalsystemsandconcepts. Westarted
bytakingthedatasetsoperatingonlegaldatafromNaturalInstructions(Mishraetal.,2022;Wang
et al., 2022) and then surveyed the literature to select high-quality legal datasets. The resulting
datasetcontainsatotalofalmost12Mexamplesin24languages. Datasourcesanddetailedstatistics
includinglicense,languageandjurisdictionaregiveninAppendixATable2. LawInstructincludes
datafrom58novelorexistingdatasets;wecitethosethatcomefrompriorwork. Eachexampleis
builtfromahuman-writtentask-specifictemplate: Wewriteaninstructionpertask,wetaketheinput
ofthesuperviseddatasetasthepromptandtheoutputastheanswer(seeFigure2foranexample).
WeshowpiechartsvisualizingthecompositionofLawInstructacrossthejurisdictionandtasktypes
calculatedbythenumberofexamplesinFigure3andbydatasetsinAppendixAFigure12. Figure4
showsthelengthdistributionoftheinstructions,promptsandanswersfollowingWangetal.(2023b).
Wefinetunedthemodelswith2048inputand512targettokens. Weranahyperparametersweepfor
theXLmodeloverthelearningrate(5e-5,1e-5,5e-4,1e-4,5e-4)anddropout(0,0.05,0.1,0.15,0.2,
0.25),withlearningrate5e-4anddropout0.15achievingthebestvalidationloss. Unlessspecified
otherwise,wetrainedthemodelsfor2Kstepswithbatchsize64. InadditiontoLawInstruct,weused
anupdatedFlanmixture(Chungetal.,2022). Webuilttheinputbyconcatenatingthepromptwith
twonewlines,theinstructionandtwoadditionalnewlines. PerLawInstructconfig,weusedthe
first16examplesforvalidationandtheremainingonesfortraining. Weselectedthemodelwiththe
bestLawInstructvalidationloss. Whilein-contextlearninghasachievedstrongresultsinmanytasks
(Brownetal.,2020),furtherfinetuninglanguagemodelsforspecifictasksmaystillbenecessaryfor
betterresults(Mosbachetal.,2023).
3Task Type by Number of Examples Jurisdiction by Number of Examples
Brazil
5.63 %.2% 39.7% M Nau tl ut rip all e L C anh go uic ae ge 5.6% 15.1% 25.4% C EUhina
Inference
3.2% 5.6% Germany
Question Answering
Switzerland
Summarization
9.5% Unknown
23.0% Text Classification
25.4% US
25.4% Other 9.5%
4.0% Other
Figure3: Jurisdictionandtasktypebyexamples.
Instruction Lengths Prompt Lengths Answer Lengths
40
20 60
15 30
40
10 20
20
5 10
0 0 0
0 20 40 60 80 0 5000 10000 15000 0 200 400 600 800 1000
(a)Instructions(cappedat100) (b)Prompts(cappedat15K) (c)Answers(cappedat1K)
Figure4: Meanlengthdistributionsforinstructions,promptsandanswers.
2.3 Evaluation
WeevaluateourmodelsonLegalBenchandMMLUtotestin-domainandgeneralizationperformance,
respectively.LegalBench(Guhaetal.,2023)consistsof162tasksevaluatingdifferentaspectsoflegal
classificationandreasoning. Eachtaskisassignedtooneofsixcategories,dependingonthebroader
typeoflegalreasoningimplicated. LegalBenchtasksaresourcedfrombothpreviouslyconstructed
datasetsandnoveltaskscollectedfromdifferentmembersofthelegalcommunity(e.g.,lawyers,legal
impactorganizations,legalacademics). Assuch,LegalBenchisthoughttocapturetasksofinterest
andpracticalapplicability. LegalBenchtasksspanawiderangeoflegalsubjectareas(e.g.,contracts,
civilprocedure,tax,etc.) andtext-types(naturallanguage,contractualterms,judicialopinions,etc.).
Themajorityoftasksareeitherclassificationorextractiontasks,thusenablingautomatedevaluation.
MassivelyMultilingualLanguageUnderstanding(MMLU)benchmarksmodelsfactualknowledge
(Hendrycksetal.,2021a). MMLUcontainsmultiple-choicequestionson57subjects,includingthree
relatedtolaw: jurisprudence,internationallaw,andprofessionallaw. Whilethereexistmultilingual
benchmarkslikeLEXTREME(Niklausetal.,2023a),theyarestillverychallengingforgenerative
modelsnotspecificallyfinetunedpertask. Therefore,wefocusonLegalBenchandMMLUbothin
theEnglishlanguage.
Forevaluation, wesettemperatureto0inlinewithacceptedpracticeforLegalBenchevaluation
(Guhaetal.,2023)thatfocusesonthehighest-likelihoodtokensequencewithminimalvariance. We
removedthefollowingprefixesbeforescoring: “label”,“target”,“option”,“answer”,“a:”. Wedid
notevaluateRuleQAbecauseitnecessitatedmanualevaluation. Weshowpaperbaselineresults
comparedwithourrunsinAppendixDTable3. OurXLmodelisquiteclosetotheXLmodelin
theLegalBenchpaper,buttherearesignificantdifferencesfortheXXLmodel. Weprovideamore
detailedanalysisofpossiblecausesinAppendixB.1. Unlessspecificallymentioned,wecompare
toourbaselinesresults. WeholdoutLegalBenchtasksoverlappingwithLawInstructtasksunless
specifiedotherwise(seeAppendixB.2fordetails).
3 Results
Inthissection,wediscussthemainresultsachievedbyinstructiontuningandcontinuedpretraining.
Figure5andTable1showtheperformanceprogressionfromthebaselineoverinstructiontuningto
domainadaptation+instructiontuningonLegalBenchandMMLU.Instructiontuningleadstoalarge
4Mean for all four sizes on LegalBench Mean for all four sizes on MMLU
70 70
Baseline Baseline
60 IFT 58.1 59.659.1 60 IFT
PRE-IFT+IFT 55.9 PRE-IFT+IFT 53.652.4
50 50.1 50 48.749.2
44.944.6 42.9
40 39.3 40
30 34.9 29.9 31.3 30 28.229.0 33.1
25.3
21.122.7
20 20 16.4
10 10 9.2
0 0
Small Base XL XXL Small Base XL XXL
Models Models
(a)LegalBench (b)MMLU
Figure5:PerformanceprogressiononLegalBenchandMMLUfrombaselinetoinstructionfinetuning
anddomainadaptation+instructionfinetuning.
Table1: Progressionofperformancefrombaselinetoinstructiontuning(IFT)andinstructiontuning
togetherwithcontinuedpretraining(PRE-IFT+IFT).
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench Improvement
SmallBaseline 0.3±0.7 30.4±20.3 39.8±20.8 28.2±21.6 27.7±21.9 25.3±14.8 -
SmallIFT 25.0±22.0 38.1±25.4 43.0±17.1 36.1±26.5 32.6±24.2 34.9±6.7 9.6(38.1%)
SmallPRE-IFT+IFT 51.6±2.7 37.7±25.2 39.8±18.4 33.7±23.3 33.8±22.4 39.3±7.4 14.0(55.4%)
BaseBaseline 44.7±12.4 18.0±23.6 20.9±24.8 28.9±21.2 37.0±21.3 29.9±11.1 -
BaseIFT 50.3±2.4 38.8±25.9 40.5±15.7 49.5±19.1 45.2±22.0 44.9±5.2 15.0(50.2%)
BasePRE-IFT+IFT 51.6±4.8 38.2±25.5 44.0±13.4 45.4±16.5 44.1±19.0 44.6±4.8 14.8(49.5%)
XLBaseline 53.5±6.0 32.1±24.6 46.8±15.6 58.7±21.3 59.6±25.6 50.1±11.3 -
XLIFT 65.7±15.2 45.1±30.3 49.5±14.2 61.7±17.1 68.6±24.1 58.1±10.3 8.0(16.0%)
XLPRE-IFT+IFT 60.3±10.6 44.3±29.7 50.5±15.4 57.3±15.9 67.3±23.1 55.9±8.9 5.8(11.6%)
XXLBaseline 36.1±21.5 18.8±24.6 25.2±26.0 35.1±22.2 41.1±18.4 31.3±9.1 -
XXLIFT 55.2±23.7 46.3±31.6 56.2±18.3 66.3±19.7 73.8±24.4 59.6±10.6 28.3(90.5%)
XXLPRE-IFT+IFT 52.2±14.7 47.4±30.8 59.2±18.3 66.6±18.5 70.0±24.1 59.1±9.5 27.8(89.0%)
performanceincreaseforallmodelsizes(38.1%forSmall,50.2%forBase,16%forXL,and90.5%
forXXL).Domainadaptation+instructiontuningonlyimprovesfurtherfortheSmallmodelsize
(55.4%vs.38.1%). Itseemslikelargermodelsbenefitlessfromin-domainpretrainingthansmaller
models,possiblybecausetheycan“remember”morefromthepretrainingphaseduetoincreased
capacity. Alternatively,areasonfornon-consistentimprovementsofdomainadaptationcouldbethe
switchfromtheUL2tasksincontinuedpretrainingtostandardnext-tokenpredictionininstruction
tuning. Finally,weconjecturethattheswitchfrominputlength512tokensincontinuedpretraining
to2048tokensininstructiontuningcouldhaveledlowerperformancefordomain-adaptedmodels.
To analyze the change in performance in more detail, we show the difference to the baseline for
theXLmodelonLegalBenchandMMLUacrosstasks(seeFigure6)andacrosscategories(see
Figure7). WefindthatFLawN-T5outperformsbaselineFlan-T5inmostLegalBenchtasksinmost
categories. Theexceptionaretasksintheinterpretationcategory,specificallyCUAD(Hendrycks
etal.,2021c),wherethefine-tunedmodelisactuallyworsethanthebaselinebyaround10points
onaverage. Apossibleexplanationcouldbenegativetransferfromtheinstructiontuningdatasince
thetaskformulationsareverydifferenttotheinstructionsinLegalBench. InMAUD(Wangetal.,
2023a)andContract-NLI(Koreeda&Manning,2021),theinstructionsaremuchmoresimilarfrom
LawInstructtoLegalBench,leadingtoimprovementscomparedtothebaseline. OnMMLU,most
categoriesandtasksseeincreasesinperformance,especiallythecategoriessocialsciencesandother.
WefindthatperformancesuffersmostlyintheSTEMcategoryandtosomeextentinthehumanities.
Interestingly,thelargestdropisinmachinelearningbutthelargestriseisinhighschoolcomputer
science. Inthehumanities,more“hard”disciplinesareaffectedbyperformancedecrease,suchas
formallogicandlogicalfallacies.
Acrosscategoriesoverallweseelowerimprovementsinconclusionandinterpretation. Conclusion
isoneofLegalBenchcategoriesrequiringmoresophisticatedreasoningcapabilities;maybelarger
models would see larger gains there. Concurrent work (Colombo et al., 2024) instruction tuned
onsyntheticlegaldata. Theyevensawadropinperformanceinconclusiontaskscomparedtothe
baselinearguing,thatconclusiontasks“requiremuchmorepuredeductivereasoningthanactuallegal
5
naeM
hcneBlageL
naeM
ULMMDifference to Baseline Across Tasks on LegalBench Difference to Baseline Across Tasks on MMLU
learned_hands_benefits Categories formal_logic Categories
lea lr e l lnl e eae le a ar ea d rn rar n_ nen rh e ende a d de_d n _h _d_ hd hah _as ahna _ n nadn e d dnsd d s_ sds u _e _s_ hc tsc _ ra et tr aa ot ai fim t rl fo e t t in he cs s I R C I Rs nu hos tnl eu ee tc re oplu rr is e ci to an tion high h_ is gc hhh _io g so chl h__ os ie nc ou th lr e_oo jw r uop n role a_ ir sa u tl pin ds o r_ __ n uh hh a di ii ls ss e_t tt nlo oo a cr rr w ey yy H S S Oo T tu hc Em i eMa ra ln Sit ci ie es nces
citation_prediction_classifica... logical_fallacies
nys_judicial_ethics moral_disputes
abercrombie moral_scenarios
hearsay philosophy
ucc_v_common_law prehistory
contract_nli_confidentiality_o... professional_law
c co on nc c to o tr rn n a at t c cr r t ta a _ _c c n nt t l l_ _ i in _n _p pl li i e e_ _ re rp m mx ep r i ism sli s sc i i ii s b bt s l_ lei ei bd _ _l d pe e en o_ v scti e tof _li p . .. . .. y . .. high_schw oo oer c l_l od gn_ er o oe m gli reg ati r po i hn c ys s
contract_nli_sharing_with_empl... high_school_government_and_pol...
contract_nli_sharing_with_thir... high_school_macroeconomics
contract_nli_survival_of_oblig... high_school_microeconomics
contract_qa high_school_psychology
cuad_affiliate_license_license... human_sexuality
cuad_affiliate_license_licenso... professional_psychology
cuad_change_of_control public_relations
cuad_irc reu va od c_ ac c bo u lv a ee d _n oc_a g u rn _o a pt v d_ ee _n rr io n pnt s ei_ n u tt ug ro a a__ n lls _au c .w .ee
.
us se _fc ou rr ei it gsy o n_s c _t i pou old o lii g ce yys
cuad_liquidated_damages abstract_algebra
cuad_most_favored_nation anatomy cuad_no_solicit_of_customers astronomy
cuad_no_solicit_of_employees college_chemistry
cuad_non_compete college_computer_science
cuad_non_disparagement college_mathematics
cuad c_n uo at di _c c te hu_ iap rd de _r _pi po r ad i rc_ t jet cyo _ r__ r ebet wee s nr _tm r e bi f lci i on ct ci ia o kat n er.. ys r. cc oo nm cc epo pl ul te t ueg are l_ __ s pp e hh c yy u ss r ii i cc ty ss
maud_ability_to_consummate_con... electrical_engineering
maud_additional_matching_right... elementary_mathematics
maud_changes_in_gaap_or_other_... high_school_biology
maud_cor_standard_superior_off... high_school_chemistry
maud_fiduciary_exception__boar... high_school_computer_science
maud_fls_mae_standard high_school_mathematics
maud_initial_matching_rights_p... high_school_physics
mm m aa a uu u dd d __ o_i ln ri dait ibi na i all i_ rtm yy __a cst t oc a uh n ri d sn eag _r_ edr f_i fg f ooh rrt t_s sn_ _p o s. .. . .. . .. high m_s ac ch ho inol e_ _s lt ea at ris nt ii nc gs
maud_specific_performance business_ethics
maud_tail_period_length clinical_knowledge
maud_type_of_consideration college_medicine
opp115_first_party_collection_... global_facts
opp115_user_choice_control human_aging
privacy_policy_qa management
sara_entailment marketing
supp cly a_ nc ah dda eai fn _ dit_ n ead i fx ti iis n_ oc c in tl oo i_ ou cs nru lt a _r _ s ee o s x_ u i td ft rii c c as o a cc m t tl i io o oe.. n ns. med mic isa cl e_ ng ll ue a tn n re e itt o ii ouc ns s
legal_reasoning_causality professional_accounting
scalr professional_medicine
textualism_tool_plain virology
20 0 20 40 60 30 20 10 0 10 20 30
LegalBench Difference to Baseline MMLU Difference to Baseline
(a)LegalBench (b)MMLU
Figure6: DifferencetothebaselinefortheXLmodelacrosstasksonLegalBenchandMMLU.For
LegalBench,weexcludedtaskswithadifferencebetween-10and10forclarity.
Mean Difference to Baseline Across Categories on LegalBench Mean Difference to Baseline Across Categories on MMLU
20.0 20.0
Issue Humanities
17.5 Rule 17.5 Social Sciences
Conclusion STEM
15.0 Interpretation 15.0 Other 12.5 12.2 13.0 Rhetoric 12.5
10.0 9.0 10.0
8.0 8.1
7.5 7.5
5.0 5.0 4.0 2.7 3.0 3.0
2.5 2.5
0.0 0.0
Issue Rule Conclusion Interpretation Rhetoric Humanities Social Sciences STEM Other
LegalBench Categories MMLU Categories
(a)LegalBench (b)MMLU
Figure7: DifferencetothebaselinefortheXLmodelacrosscategoriesonLegalBenchandMMLU.
knowledge”comparedtotasksfromtheothercategories. Lowerimprovementininterpretationcould
beexplainedbynegativetransfercausedthroughdifferentinstructionsinCUAD.Ourhypothesisof
apotentialnegativetransferiscorroboratedbyourresultsonLegalBenchbycategorieswhenwe
removethedatasetsortasksthatoverlapbetweenLawInstructandLegalBench(seeFigure14): We
seelargergainscomparedtothebaselineforboththeconclusionandtheinterpretationcategories.
4 Ablations
Inthissection,wepresentdiverseablationsacrossthestartingcheckpoints,datamixtures,sampling
styles,licences,instructionstylesandamountofinstructiontuningdataduringpretraining. Weshow
additionalablationsregardingcrosslingualtransferfrommultilingualdatainAppendixC.
6
sksaT
enilesaB
ot ecnereffiD
naeM
hcneBlageL
sksaT
enilesaB
ot ecnereffiD
naeM
ULMM4.1 StartingCheckpoint
Mean for all four sizes on LegalBench
70
T5
Shouldyoustartin-domaininstructiontun- 60 Flan-T5 59.1 60.0
ingfromabasemodelorfromaninstruc-
51.4
tion tuned model? ⇒ Starting from an 50
44.1
instructiontunedmodelisbetteracross 40.3
40 sizesexceptSmall. InFigure8,wecom- 36.2
31.5
pareinstructiontuningfromabaseT5and 30 29.5
a Flan-T5 model in four different sizes
20
(Small, Base, XL and XXL) (detailed re-
sults in Appendix D Table 4). We find 10
that for the larger sizes, the instruction
0
tuned Flan-T5 is a better starting point Small Base XL XXL
Models
(p < 0.001), leading to higher perfor-
manceonLegalBench. FortheSmallsize Figure8: StartinginstructiontuningfromtheFlan-T5
thedifferenceisnotstatisticallysignificant checkpointimprovesresultsacrossallsizes.
(p = 0.058). Bydefault,weusetheFlan-
T5modelasastartingpointinallfollowingexperimentsunlessspecifiedotherwise.
4.2 DataMixture
Mean for different data mixtures on LegalBench
70
Whatdatamixturesshouldyouchoosefor 60 57.0 59.1
in-domaininstructiontuning? ⇒Mixing
ingeneralinstructiontuningdatasetsis 50 48.3 46.2
necessary. In Figure 9, we compare in-
40
struction tuning with three different data
mixtures: lawinstruct,flan2(Chungetal., 30
2022), and flan2-lawinstruct (where we
20
sampleequallyfromflan2andlawinstruct)
(detailed results in Appendix D Table 5). 10
Interestingly,whenonlytrainingonlawin-
0
struct,downstreamaccuracydrops,possi- baseline lawinstruct flan2 flan2-lawinstruct
Data Mixtures
blyduetotheinstructionsinourdatasets
beingformulateddifferentlythantheorig- Figure9: AccuracyoftheFlan-T5XLmodelonLegal-
inal Flan instructions. Training on flan2 Benchusingthreedatamixtures.
andflan2-lawinstructleadstoanaggregate
increaseof7.7points(48.3to56)and10.8points(48.3to59.1)respectively. Bydefaultweusethe
flan2-lawinstructmixtureinallfollowingexperimentsunlessspecifiedotherwise.
4.3 SamplingStyle
Mean for all four sizes on LegalBench
70
res-number
Shouldwesampleeachdatasetequallyor 60 res-equal 59.4 59.1 61.3 60.058.5
rather by the number of examples? ⇒ comm-number 56.3 56.1 55.9
Sampling by the number of examples 50 comm-equal
generally leads to better performance.
43.343.444.143.4
40 38.0
InFigure10,wecomparetheperformance 34.1 31.533.1
oftwosamplingstyles(equalsamplingof 30
eachdatasetandsamplingbythenumber
20
ofexamples)acrossboththeresearchand
commercial licensed dataset (detailed re- 10
sultsinAppendixDTable6). FortheXL
0
and XXL sizes, sampling by the number Small Base XL XXL
Models
ofexamplesisbetterthanequalweightfor
datasetsforboththeresearchandcommer- Figure 10: Ablation on sampling style and license
cialdatasets,althoughnotalwaysstatisti- onEnglishflan2-lawinstructfromtheFlan-T5check-
cally significant (XL res p = 0.049, XL pointacrosssizes. Abbreviations: res: licensedforre-
comm p = 0.052, XXL res p < 0.001, searchuse(alldatasets),comm: commerciallyfriendly
XXLcomm p =0.31). FortheSmallsize, licensed,number: samplingbythenumberofexamples
samplingbythenumberofexamplesisbet- perdataset,equal: equallysamplingfromeachdataset
7
naeM
hcneBlageL
naeM
hcneBlageL
naeM
hcneBlageLterfortheresearchdataset(p <0.001)butnotforthecommercialdataset(p =0.099),whilethere
isnodifferencefortheBasesize. Bydefault,wesamplebythenumberofexamplesinallfollowing
experimentsunlessspecifiedotherwise.
4.4 LicenseofInstructionTuningDatasets
Doweneeddatalicensednon-commerciallyforgoodperformance? ⇒Thecommerciallylicensed
dataseemstobeenoughforthelargermodels. InFigure10,wecomparetheperformanceoftwo
differentlylicenseddatasets(researchandcommerciallicenses)acrossbothsamplingeachdataset
equallyandbythenumberofexamples(detailedresultsinAppendixDTable6). ExceptforSmall
size(p < 0.001),usingmorediversedataavailableonlyforresearchshowsnosignificantbenefit.
Bydefault,weusethecommerciallylicenseddatasetinallsubsequentexperimentsunlessspecified.
4.5 InstructionStyle
AremodelstrainedwithmorediverseinstructionsbetteronLegalBench? ⇒Resultsaremixed,
overalljustusingoneinstructionisprobablysufficient. InFigure11,wecomparetheperformance
oftrainingwithjustonemanuallywritteninstructionvs.tenparaphrasedinstructionswithGPT-4
fromoneseedinstruction(detailedresultsinAppendixDTable8). ForFlan-T5(seeTable8),for
Small,oneinstructionisbetterthanten(p =0.035);fortheothersizeswefindnodifference. For
mT5(seeFigure11b),forSmall,oneinstructionisworsethantenbothmonolingual(p = 0.005)
andmultilingual(p = 0.01)whereasforXL,tenEnglishinstructionsunderperformoneEnglish
(p < 0.001)andtenmultilingualones(p < 0.001). Inaggregate,differencesaresmallwithouta
consistenttrend.
Mean for all four sizes on LegalBench Mean for all four sizes on LegalBench
70 70
1-english 1-english
60 10-english 58.3 59.1 60.9 60.0 60 10-english
10-multi
50 50 45.5 44.1 42.7 42.4
40 40 39.2 38.2 39.0 39.0 33.6 31.5 32.2 35.4 34.9
30 30
20 20
10 10
0 0
Small Base XL XXL Small Base XL
Models Models
(a)English (b)Multilingual
Figure 11: Ablation on the instruction style on English/multilingual flan2-lawinstruct from the
Flan-T5/mT5checkpointacrossallsizes.
4.6 AmountofInstructionDataDuringContinuedPretraining
Howmuchinstructiontuningdatashouldbemixedinduringcontinuedpretraining? ⇒Continued
pretrainingseemstoberatherrobustwithregardtotheamountofinstructiontuningsamples
mixedin. InTables10to13,weinvestigatethebenefitofmixingvaryingamountsofinstruction
tuningdatainduringcontinuedpretraining(detailedresultsinAppendixDTables10to13). We
compare results on LegalBench of instruction tuning runs after 10K to 90K steps of continued
pretraining. FortheSmallmodel,thebenefitofcontinuedpretrainingoverjustinstructiontuningis
significant(34.9forjustinstructiontuningvs. 40aftercontinuedpretraining). Conversely,fortheXL
model,continuedpretrainingoftenunderperformscomparedtojustinstructiontuning. FortheXXL
model,moreinstructiontuningsamplesduringcontinuedpretrainingimproveperformance,unlike
fortheSmallandXLmodels. Acrosssizes,continuedpretraining’seffectivenessappearsrobustto
thenumberofinstructiontuningsamplesused.4
4Justmixinginstructiontuningdataduringcontinuedpretrainingwithoutmoreinstructiontuningdoesnot
improveresults.
8
naeM
hcneBlageL
naeM
hcneBlageL5 RelatedWork
Domain-specificpretraining,coveringareassuchasmedicine,law,andscience,significantlyenhances
LanguageModelperformanceonrelatedtasks(Beltagyetal.,2019;Guetal.,2021;Chalkidisetal.,
2020). SciBERT (Beltagy et al., 2019), for instance, underwent pretraining on a combination of
computerscienceandbiomedicalpapers,exemplifyingthisapproachinthescientificdomain. Other
modelslikePubMedBERT(Guetal.,2021)andBioBERT(Leeetal.,2020),specificallypretrained
onbiomedicaldatasets,haveshownimprovementsinmedicalNLPtasks(Huangetal.,2019).
5.1 Domain-specificLegalPretraining
Inthelegaldomain,modelssuchasLegalBERT,pretrainedon12GBofEnglishlegaltexts,demon-
strated notable success in domain-specific challenges (Chalkidis et al., 2020). CaseLaw-BERT
capitalizedontheEnglishHarvardLawcasecorpusspanningfrom1965to2021(Zhengetal.,2022),
whileNiklaus&Giofré(2022)pretrainedLongFormermodelsonthePile-of-Law(Hendersonetal.,
2022)usingthereplacedtokendetectiontask(Clarketal.,2020)forenhancedperformance. Further
advancementsweremadebyChalkidisetal.(2023),whodevelopednewEnglishlegalLMsyielding
superiorresultsonLexFiles,acompilationof11sub-corporafromsixEnglish-speakinglegalsystems
encompassing19Btokens. Additionally,Niklausetal.(2023b)introducedavastmultilinguallegal
corpus,trainingbothmonolingualandmultilinguallegalmodelstoachievestate-of-the-artresults
onLexGLUE(Chalkidisetal.,2022)andLEXTREME(Niklausetal.,2023a). Modelshavealso
beendevelopedforspecificjurisdictions,includingtheSwiss(Rasiahetal.,2023),Italian(Licari
&Comandè,2022),Romanian(Masalaetal.,2021),andSpanish(Gutiérrez-Fandiñoetal.,2021)
legalsystems. Despitetheprevalenceofsmallerencoder-basedlegal-specificLMs,largergenerative
modelsinthisspaceremainscarce. Thisworkseekstobridgethatgap.
5.2 InstructionTuning
Instructiontuning–theprocessoffinetuningauto-regressivepretrainedlanguagemodelsoncorpora
of reciprocal instruction–response pairs – has emerged as a critical step for building responsive
modelsthatareusefulformanytasks(Ouyangetal.,2022;Chowdheryetal.,2022;Weietal.,2022b;
Sanh et al., 2022). Some go as far as to claim that this training paradigm is the key to imbuing
languagemodelswiththegeneralizedcapabilityofzero-shotinstructionfollowingbehavior(Chung
etal.,2022). Instructiontuningreferstofew-shotorzero-shotadaptationoflargelanguagemodels
tonewtasks,wherethetaskisdescribedinnaturallanguageinthetrainingexamples. Following
Weietal.(2022a),itiscommontotransformexistingdatasetsintoinstructiondatasetsbymanually
composingtemplatesandfillingthesewithspecificexamples. Itisthroughthesedomain-specific
trainingproceduresthatwebuildandevaluatelegaldataadaptationinLLMs.
6 ConclusionandFutureWork
We curated LawInstruct, the first instruction tuning dataset for the legal domain by aggregating
various high-quality annotated datasets and writing instructions for the different tasks. We used
LawInstructtoinstructiontuneT5basedmodels,creatingFLawN-T5andanewstate-of-the-arton
LegalBenchinallinvestigatedparametersizes. WeopenlyreleaseLawInstructonHuggingFace.
Inthefuture,wewouldliketoextendLawInstructwithmorehigh-qualitydatasetsreleasedafterour
experimentssuchasLong-formLegalQuestionAnswering(Louisetal.,2023),KeyphraseGeneration
(Salaünetal.,2024),NegationScopeResolution(Christenetal.,2023),orLegalViolationDetection
(Bernsohnetal.,2024). Additionally,futureworkcouldworkwithlegalprofessionalstoidentifyand
annotatenewtasksforthelegaldomain. Futureworkcouldexplorethebenefitsofsyntheticdata
generationinthelegaldomain,eitherbygeneratingresponsesfrominstructions(Wangetal.,2023c)
orreversely,bygeneratinginstructionstoresponses(Köksaletal.,2024),butshouldtakecaretodo
detailedqualitycheckssincehallucinatedcontentmayhurtmorethanimprove,especiallyinthelegal
domain. Finally,itwouldbeinterestingtoinvestigateoverlapbetweentheT5pretrainingdatasetC4
andtheMultiLegalPiletogetabetterunderstandingofthepotentialbenefitsofcontinuedpretraining.
9Acknowledgements
WewouldliketothankBaqHaidriforhelpwithdebuggingandJohnKirchenbauer,SangMichael
Xie and David Hall for feedback on the project. Thanks to Neel Guha for help with debugging
LegalBenchandforfeedbackonanalyzingresults.
References
Dennis Aumiller, Ashish Chouhan, and Michael Gertz. EUR-Lex-Sum: A Multi- and Cross-
lingualDatasetforLong-formSummarizationintheLegalDomain,October2022. URLhttp:
//arxiv.org/abs/2210.13448. arXiv:2210.13448[cs].
NikosBartziokas,ThanassisMavropoulos,andConstantineKotropoulos. DatasetsandPerformance
MetricsforGreekNamedEntityRecognition.In11thHellenicConferenceonArtificialIntelligence
(SETN2020),SETN2020,pp.160–167,NewYork,NY,USA,2020.AssociationforComputing
Machinery. ISBN9781450388788. doi: 10.1145/3411408.3411437. URLhttps://doi.org/10.
1145/3411408.3411437.
ShrutarshiBasu,NateFoster,JamesGrimmelmann,ShanParikh,andRyanRichardson. Aprogram-
minglanguageforfutureinterest. YaleJL&Tech.,24:75,2022.
IzBeltagy,KyleLo,andArmanCohan. SciBERT:Apretrainedlanguagemodelforscientifictext.
InConferenceonEmpiricalMethodsinNaturalLanguageProcessing,2019.
DorBernsohn,GilSemo,YaronVazana,GilaHayat,BenHagag,JoelNiklaus,RohitSaha,andKyryl
Truskovskyi. LegalLens: LeveragingLLMsforLegalViolationIdentificationinUnstructuredText,
February2024. URLhttp://arxiv.org/abs/2402.04335. arXiv:2402.04335[cs].
PaheliBhattacharya,KaustubhHiware,SubhamRajgaria,NilayPochhi,KripabandhuGhosh,and
SaptarshiGhosh.Acomparativestudyofsummarizationalgorithmsappliedtolegalcasejudgments.
InEuropeanConferenceonInformationRetrieval,pp.413–428.Springer,2019.
TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel
Herbert-Voss,GretchenKrueger,TomHenighan,RewonChild,AdityaRamesh,DanielZiegler,
JeffreyWu,ClemensWinter,ChrisHesse,MarkChen,EricSigler,MateuszLitwin,ScottGray,
BenjaminChess,JackClark,ChristopherBerner,SamMcCandlish,AlecRadford,IlyaSutskever,
and Dario Amodei. Language Models are Few-Shot Learners. In H. Larochelle, M. Ranzato,
R.Hadsell,M.F.Balcan,andH.Lin(eds.),AdvancesinNeuralInformationProcessingSystems,
volume33,pp.1877–1901.CurranAssociates,Inc.,2020.URLhttps://proceedings.neurips.
cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.
WilliamBrunoandDanRoth.LawngNLI:ALong-PremiseBenchmarkforIn-DomainGeneralization
fromShorttoLongContextsandforImplication-BasedRetrieval.arXivpreprintarXiv:2212.03222,
2022.
CAIL2022. CAIL2022. https://github.com/china-ai-law-challenge/CAIL2022,2022.
Pablo Calleja, Patricia Martín Chozas, Elena Montiel-Ponsoda, Víctor Rodríguez-Doncel, Elsa
Gómez,andPascualBoil. Bilingualdatasetforinformationretrievalandquestionansweringover
thespanishworkersstatute. InXIXConferenciadelaAsociaciónEspañolaparalaInteligencia
Artificial(CAEPIA),2021.
Casebriefs. Casebriefs. https://www.oyez.org/,2024.
IliasChalkidis,EmmanouilFergadiotis,ProdromosMalakasiotis,andIonAndroutsopoulos. Large-
Scale Multi-Label Text Classification on EU Legislation. In Proceedings of the 57th Annual
MeetingoftheAssociationforComputationalLinguistics,pp.6314–6322,Florence,Italy,July
2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1636. URL https:
//aclanthology.org/P19-1636.
10IliasChalkidis, ManosFergadiotis, ProdromosMalakasiotis, NikolaosAletras, andIonAndrout-
sopoulos. LEGAL-BERT: The muppets straight out of law school. In Findings of the Associ-
ation for Computational Linguistics: EMNLP 2020, pp. 2898–2904, Online, November 2020.
Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.261. URL
https://aclanthology.org/2020.findings-emnlp.261.
Ilias Chalkidis, Manos Fergadiotis, and Ion Androutsopoulos. MultiEURLEX – A multi-
lingualandmulti-labellegaldocumentclassificationdatasetforzero-shotcross-lingualtransfer.
arXiv:2109.00904[cs],September2021a. URLhttp://arxiv.org/abs/2109.00904. arXiv:
2109.00904.
IliasChalkidis,ManosFergadiotis,DimitriosTsarapatsanis,NikolaosAletras,IonAndroutsopoulos,
andProdromosMalakasiotis. Paragraph-levelRationaleExtractionthroughRegularization: A
casestudyonEuropeanCourtofHumanRightsCases. InProceedingsofthe2021Conferenceof
theNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguage
Technologies,pp.226–241,Online,June2021b.AssociationforComputationalLinguistics. doi:
10.18653/v1/2021.naacl-main.22. URLhttps://aclanthology.org/2021.naacl-main.22.
Ilias Chalkidis, Abhik Jana, Dirk Hartung, Michael J. Bommarito II, Ion Androutsopoulos,
DanielMartinKatz,andNikolaosAletras. LexGLUE:Abenchmarkdatasetforlegallanguage
understandinginEnglish. InACL(1),pp.4310–4330.AssociationforComputationalLinguistics,
2022. doi: 10.18653/v1/2022.acl-long.297.
IliasChalkidis,NicolasGarneau,CatalinaGoanta,DanielMartinKatz,andAndersSøgaard.LeXFiles
andLegalLAMA:FacilitatingEnglishmultinationallegallanguagemodeldevelopment,2023.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts,PaulBarham,HyungWonChung,CharlesSutton,SebastianGehrmann,ParkerSchuh,
KensenShi,SashaTsvyashchenko,JoshuaMaynez,AbhishekRao,ParkerBarnes,YiTay,Noam
Shazeer,VinodkumarPrabhakaran,EmilyReif,NanDu,BenHutchinson,ReinerPope,James
Bradbury,JacobAustin,MichaelIsard,GuyGur-Ari,PengchengYin,TojuDuke,AnselmLev-
skaya,SanjayGhemawat,SunipaDev,HenrykMichalewski,XavierGarcia,VedantMisra,Kevin
Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret
Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick,
AndrewM.Dai,ThanumalayanSankaranarayanaPillai,MariePellat,AitorLewkowycz,Erica
Moreira,RewonChild,OleksandrPolozov,KatherineLee,ZongweiZhou,XuezhiWang,Brennan
Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas
Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM: Scaling Language Modeling with Path-
ways. arXiv:2204.02311[cs],April2022. URLhttp://arxiv.org/abs/2204.02311. arXiv:
2204.02311.
RamonaChristen,AnastassiaShaitarova,MatthiasStürmer,andJoelNiklaus. ResolvingLegalese:
AMultilingualExplorationofNegationScopeResolutioninLegalDocuments,September2023.
URLhttp://arxiv.org/abs/2309.08695. arXiv:2309.08695[cs].
HyungWonChung,LeHou,ShayneLongpre,BarretZoph,YiTay,WilliamFedus,EricLi,Xuezhi
Wang,MostafaDehghani,SiddharthaBrahma,AlbertWebson,ShixiangShaneGu,ZhuyunDai,
MiracSuzgun,XinyunChen,AakankshaChowdhery,SharanNarang,GauravMishra,AdamsYu,
VincentZhao,YanpingHuang,AndrewDai,HongkunYu,SlavPetrov,EdH.Chi,JeffDean,Jacob
Devlin,AdamRoberts,DennyZhou,QuocV.Le,andJasonWei. ScalingInstruction-Finetuned
LanguageModels,October2022.URLhttp://arxiv.org/abs/2210.11416.arXiv:2210.11416
[cs].
KevinClark,Minh-ThangLuong,QuocV.Le,andChristopherD.Manning. ELECTRA:Pre-training
TextEncodersasDiscriminatorsRatherThanGenerators. arXiv:2003.10555[cs],March2020.
URLhttp://arxiv.org/abs/2003.10555. arXiv: 2003.10555.
PierreColombo,TelmoPessoaPires,MalikBoudiaf,DominicCulver,RuiMelo,CaioCorro,Andre
F.T.Martins,FabrizioEsposito,VeraLúciaRaposo,SofiaMorgado,andMichaelDesa. SaulLM-
7B:ApioneeringLargeLanguageModelforLaw,March2024. URLhttp://arxiv.org/abs/
2403.03883. arXiv:2403.03883[cs].
11MatthewDahl,VarunMagesh,MiracSuzgun,andDanielE.Ho. LargeLegalFictions: Profiling
LegalHallucinationsinLargeLanguageModels,January2024. URLhttp://arxiv.org/abs/
2401.01301. arXiv:2401.01301[cs].
OnadeGibertBonet,AitorGarcíaPablos,MontseCuadros,andMaiteMelero. Spanishdatasets
for sensitive entity detection in the legal domain. In Proceedings of the Thirteenth Language
ResourcesandEvaluationConference,pp.3751–3760,Marseille,France,June2022.European
LanguageResourcesAssociation. URLhttps://aclanthology.org/2022.lrec-1.400.
Pedro Delfino, Bruno Cuconato, Edward Hermann Haeusler, and Alexandre Rademaker. Pass-
ing the Brazilian OAB exam: data preparation and some experiments, 2017. arXiv preprint
arXiv:1712.05128.
Kasper Drawzeski, Andrea Galassi, Agnieszka Jablonowska, Francesca Lagioia, Marco Lippi,
Hans Wolfgang Micklitz, Giovanni Sartor, Giacomo Tagiuri, and Paolo Torroni. A Corpus
for Multilingual Analysis of Online Terms of Service. In Proceedings of the Natural Legal
LanguageProcessingWorkshop2021,pp.1–8,PuntaCana,DominicanRepublic,November2021.
AssociationforComputationalLinguistics. URLhttps://aclanthology.org/2021.nllp-1.1.
AnnaFilighera,SiddharthParihar,TimSteuer,TobiasMeuser,andSebastianOchs. Youransweris
incorrect...wouldyouliketoknowwhy? introducingabilingualshortanswerfeedbackdataset. In
Proceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume
1: Long Papers), pp. 8577–8591, Dublin, Ireland, May 2022. Association for Computational
Linguistics. doi: 10.18653/v1/2022.acl-long.587. URL https://aclanthology.org/2022.
acl-long.587.
YuGu,RobertTinn,HaoCheng,MichaelLucas,NaotoUsuyama,XiaodongLiu,TristanNaumann,
JianfengGao,andHoifungPoon. Domain-SpecificLanguageModelPretrainingforBiomedical
NaturalLanguageProcessing. ACMTrans.Comput.Healthcare,3(1),oct2021. ISSN2691-1957.
doi: 10.1145/3458754. URLhttps://doi.org/10.1145/3458754.
NeelGuha,JulianNyarko,DanielE.Ho,ChristopherRé,AdamChilton,AdityaNarayana,Alex
Chohlas-Wood,AustinPeters,BrandonWaldon,DanielN.Rockmore,DiegoZambrano,Dmitry
Talisman,EnamHoque,FaizSurani,FrankFagan,GalitSarfaty,GregoryM.Dickinson,Haggai
Porat,JasonHegland,JessicaWu,JoeNudell,JoelNiklaus,JohnNay,JonathanH.Choi,Kevin
Tobia,MargaretHagan,MeganMa,MichaelLivermore,NikonRasumov-Rahe,NilsHolzenberger,
NoamKolt,PeterHenderson,SeanRehaag,SharadGoel,ShangGao,SpencerWilliams,Sunny
Gandhi,TomZur,VarunIyer,andZehuaLi. LegalBench: ACollaborativelyBuiltBenchmarkfor
MeasuringLegalReasoninginLargeLanguageModels,August2023. URLhttp://arxiv.org/
abs/2308.11462. arXiv:2308.11462[cs].
AsierGutiérrez-Fandiño,JordiArmengol-Estapé,AitorGonzalez-Agirre,andMartaVillegas.Spanish
Legalese Language Model and Corpora, October 2021. URL http://arxiv.org/abs/2110.
12201. arXiv:2110.12201[cs].
Ivan Habernal, Daniel Faber, Nicola Recchia, Sebastian Bretthauer, Iryna Gurevych, Indra
SpieckergenanntDöhmann,andChristophBurchard. MiningLegalArgumentsinCourtDecisions.
arXivpreprint,2022. doi: 10.48550/arXiv.2208.06178.
PeterHenderson,MarkS.Krass,LuciaZheng,NeelGuha,ChristopherD.Manning,DanJurafsky,and
DanielE.Ho. PileofLaw: LearningResponsibleDataFilteringfromtheLawanda256GBOpen-
SourceLegalDataset,July2022. URLhttp://arxiv.org/abs/2207.00220. arXiv:2207.00220
[cs].
DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,DawnSong,andJacob
Steinhardt. Measuringmassivemultitasklanguageunderstanding. InInternationalConferenceon
LearningRepresentations,2021a. URLhttps://openreview.net/forum?id=d7KBjmI3GmQ.
DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,DawnSong,andJacob
Steinhardt. MeasuringMassiveMultitaskLanguageUnderstanding,January2021b. URLhttp:
//arxiv.org/abs/2009.03300. arXiv:2009.03300[cs].
12DanHendrycks,CollinBurns,AnyaChen,andSpencerBall. CUAD:AnExpert-AnnotatedNLP
DatasetforLegalContractReview,November2021c.URLhttp://arxiv.org/abs/2103.06268.
arXiv:2103.06268[cs].
NilsHolzenberger,AndrewBlair-Stanek,andBenjaminVanDurme.Adatasetforstatutoryreasoning
intaxlawentailmentandquestionanswering. InNLLP@KDD,pp.31–38,2020. URLhttps:
//ceur-ws.org/Vol-2645/paper5.pdf.
KexinHuang,JaanAltosaar,andRajeshRanganath. ClinicalBERT:ModelingClinicalNotesand
PredictingHospitalReadmission. 2019. URLhttp://arxiv.org/abs/1904.05342.
WonseokHwang,DongjunLee,KyoungyeonCho,HanuhlLee,andMinjoonSeo. AMulti-Task
BenchmarkforKoreanLegalLanguageUnderstandingandJudgementPrediction,October2022.
URLhttp://arxiv.org/abs/2206.05224. arXiv:2206.05224[cs].
EliasJacobdeMenezes-NetoandMarcoBrunoMirandaClementino. Usingdeeplearningtopredict
outcomesoflegalappealsbetterthanhumanexperts: AstudywithdatafromBrazilianfederal
courts. PLOSONE,17(7):e0272287,July2022. ISSN1932-6203. doi: 10.1371/journal.pone.
0272287. URLhttps://dx.plos.org/10.1371/journal.pone.0272287.
HeewonJeon. Legalqausingsentencekobart. https://github.com/haven-jeon/LegalQA,2021.
PrathameshKalamkar,AsthaAgarwal,AmanTiwari,SmitaGupta,SaurabhKarn,andVivekRagha-
van. NamedentityrecognitioninIndiancourtjudgments. InProceedingsoftheNaturalLegal
LanguageProcessingWorkshop2022,pp.184–193,AbuDhabi,UnitedArabEmirates(Hybrid),
December2022.AssociationforComputationalLinguistics. doi: 10.18653/v1/2022.nllp-1.15.
URLhttps://aclanthology.org/2022.nllp-1.15.
DanielMartinKatz,MichaelJamesBommarito,ShangGao,andPabloArredondo. GPT-4Passes
theBarExam,March2023. URLhttps://papers.ssrn.com/abstract=4389233.
MonibaKeymanesh,MichaElsner,andSrinivasanSarthasarathy.Towarddomain-guidedcontrollable
summarizationofprivacypolicies. InNLLP@KDD,pp.18–24,2020.
Mi-Young Kim, Juliano Rabelo, Randy Goebel, Masaharu Yoshioka, Yoshinobu Kano, and Ken
Satoh. Coliee 2022 summary: Methods for legal document retrieval and entailment. In JSAI
InternationalSymposiumonArtificialIntelligence,pp.51–67.Springer,2022.
Yuta Koreeda and Christopher Manning. ContractNLI: A Dataset for Document-level Natural
LanguageInferenceforContracts. InFindingsoftheAssociationforComputationalLinguistics:
EMNLP2021,pp.1907–1919,PuntaCana,DominicanRepublic,November2021.Association
for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.164. URL https://
aclanthology.org/2021.findings-emnlp.164.
AnastassiaKornilovaandVladimirEidelman. BillSum: ACorpusforAutomaticSummarization
of US Legislation. In Proceedings of the 2nd Workshop on New Frontiers in Summarization,
pp.48–56,HongKong,China,November2019.AssociationforComputationalLinguistics. doi:
10.18653/v1/D19-5406. URLhttps://aclanthology.org/D19-5406.
AliceKwak,JacobIsraelsen,ClaytonMorrison,DerekBambauer,andMihaiSurdeanu. Validity
assessmentoflegalwillstatementsasnaturallanguageinference.InFindingsoftheAssociationfor
ComputationalLinguistics: EMNLP2022,pp.6047–6056,AbuDhabi,UnitedArabEmirates,De-
cember2022.AssociationforComputationalLinguistics. doi: 10.18653/v1/2022.findings-emnlp.
447. URLhttps://aclanthology.org/2022.findings-emnlp.447.
Abdullatif Köksal, Timo Schick, Anna Korhonen, and Hinrich Schütze. LongForm: Effective
Instruction Tuning with Reverse Instructions, February 2024. URL http://arxiv.org/abs/
2304.08460. arXiv:2304.08460[cs].
AndréLage-Freitas, HéctorAllende-Cid, OrivaldoSantana, andLíviaOliveira-Lage. Predicting
BrazilianCourtDecisions. PeerJComputerScience,8:e904,March2022. ISSN2376-5992. doi:
10.7717/peerj-cs.904. URLhttps://peerj.com/articles/cs-904. Publisher: PeerJInc.
13LawStackExchange. Lawstackexchange. https://law.stackexchange.com/,2024.
JinhyukLee,WonjinYoon,SungdongKim,DonghyeonKim,SunkyuKim,ChanHoSo,andJaewoo
Kang. BioBERT:Apre-trainedbiomedicallanguagerepresentationmodelforbiomedicaltext
mining. Bioinformatics,36(4):1234–1240,2020. ISSN14602059. doi: 10.1093/bioinformatics/
btz682.
LegalQA. LegalQA. https://github.com/siatnlp/LegalQA,2019.
Brian Lester, Rami Al-Rfou, and Noah Constant. The Power of Scale for Parameter-Efficient
Prompt Tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural
Language Processing, pp. 3045–3059, Online and Punta Cana, Dominican Republic, 2021.
Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.243. URL
https://aclanthology.org/2021.emnlp-main.243.
Daniele Licari and Giovanni Comandè. ITALIAN-LEGAL-BERT: A Pre-trained Transformer
LanguageModelforItalianLaw. 2022.
Marco Lippi, Przemysław Pałka, Giuseppe Contissa, Francesca Lagioia, Hans-Wolfgang Mick-
litz, Giovanni Sartor, and Paolo Torroni. CLAUDETTE: an automated detector of poten-
tiallyunfairclausesinonlinetermsofservice. ArtificialIntelligenceandLaw,27(2):117–139,
2019. ISSN1572-8382. doi: 10.1007/s10506-019-09243-2. URLhttps://doi.org/10.1007/
s10506-019-09243-2.
AntoineLouis,GijsvanDijck,andGerasimosSpanakis. InterpretableLong-FormLegalQuestion
Answering with Retrieval-Augmented Large Language Models, September 2023. URL http:
//arxiv.org/abs/2309.17050. arXiv:2309.17050[cs].
PedroHenriqueLuzdeAraujo,TeófiloE.deCampos,RenatoR.R.deOliveira,MatheusStauffer,
Samuel Couto, and Paulo Bermejo. LeNER-Br: A Dataset for Named Entity Recognition in
Brazilian Legal Text. In Aline Villavicencio, Viviane Moreira, Alberto Abad, Helena Caseli,
PabloGamallo,CarlosRamisch,HugoGonçaloOliveira,andGustavoHenriquePaetzold(eds.),
ComputationalProcessingofthePortugueseLanguage,LectureNotesinComputerScience,pp.
313–323,Cham,2018.SpringerInternationalPublishing. ISBN978-3-319-99722-3.
VijitMalik,RishabhSanjay,ShubhamKumarNigam,KripabandhuGhosh,ShouvikKumarGuha,
Arnab Bhattacharya, and Ashutosh Modi. ILDC for CJPE: Indian Legal Documents Corpus
for Court Judgment Prediction and Explanation. In Proceedings of the 59th Annual Meeting
of the Association for Computational Linguistics and the 11th International Joint Conference
on Natural Language Processing (Volume 1: Long Papers), pp. 4046–4062, Online, August
2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.313. URL
https://aclanthology.org/2021.acl-long.313.
Laura Manor and Junyi Jessy Li. Plain English summarization of contracts. In Proceedings of
the Natural Legal Language Processing Workshop 2019, pp. 1–11, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-2201. URL
https://aclanthology.org/W19-2201.
Mihai Masala, Radu Cristian Alexandru Iacob, Ana Sabina Uban, Marina Cidota, Horia Velicu,
TraianRebedea,andMariusPopescu. jurBERT:ARomanianBERTmodelforlegaljudgement
prediction. InProceedingsoftheNaturalLegalLanguageProcessingWorkshop2021,pp.86–94,
PuntaCana,DominicanRepublic,November2021.AssociationforComputationalLinguistics.
doi: 10.18653/v1/2021.nllp-1.8. URLhttps://aclanthology.org/2021.nllp-1.8.
SwaroopMishra,DanielKhashabi,ChittaBaral,andHannanehHajishirzi.Cross-TaskGeneralization
viaNaturalLanguageCrowdsourcingInstructions. InProceedingsofthe60thAnnualMeetingof
theAssociationforComputationalLinguistics(Volume1: LongPapers),pp.3470–3487,Dublin,
Ireland,May2022.AssociationforComputationalLinguistics. doi: 10.18653/v1/2022.acl-long.
244. URLhttps://aclanthology.org/2022.acl-long.244.
Marius Mosbach, Tiago Pimentel, Shauli Ravfogel, Dietrich Klakow, and Yanai Elazar. Few-
shotFine-tuningvs.In-contextLearning: AFairComparisonandEvaluation,May2023. URL
http://arxiv.org/abs/2305.16938. arXiv:2305.16938[cs].
14EmreMumcuog˘lu,CeyhunE.Öztürk,HaldunM.Ozaktas,andAykutKoç. Naturallanguageprocess-
inginlaw: Predictionofoutcomesinthehighercourtsofturkey. InformationProcessing&Man-
agement,58(5):102684,2021. ISSN0306-4573. doi: https://doi.org/10.1016/j.ipm.2021.102684.
URLhttps://www.sciencedirect.com/science/article/pii/S0306457321001692.
Joel Niklaus and Daniele Giofré. BudgetLongformer: Can we Cheaply Pretrain a SotA Legal
LanguageModelFromScratch?,November2022. URLhttp://arxiv.org/abs/2211.17135.
arXiv:2211.17135[cs].
JoelNiklaus,IliasChalkidis,andMatthiasStürmer. Swiss-Judgment-Prediction: AMultilingual
LegalJudgmentPredictionBenchmark. InProceedingsoftheNaturalLegalLanguageProcessing
Workshop2021,pp.19–35,PuntaCana,DominicanRepublic,November2021.Associationfor
ComputationalLinguistics. URLhttps://aclanthology.org/2021.nllp-1.3.
JoelNiklaus, VetonMatoshi, PoojaRani, AndreaGalassi, MatthiasStürmer, andIliasChalkidis.
LEXTREME:AMulti-LingualandMulti-TaskBenchmarkfortheLegalDomain,January2023a.
URLhttp://arxiv.org/abs/2301.13126. arXiv:2301.13126[cs].
JoelNiklaus,VetonMatoshi,MatthiasStürmer,IliasChalkidis,andDanielE.Ho. MultiLegalPile:
A689GBMultilingualLegalCorpus,June2023b. URLhttp://arxiv.org/abs/2306.02069.
arXiv:2306.02069[cs].
OpenAI. GPT-4 Technical Report, March 2023. URL http://arxiv.org/abs/2303.08774.
arXiv:2303.08774[cs].
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL.Wainwright,PamelaMishkin,Chong
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,JohnSchulman,JacobHilton,FraserKelton,
LukeMiller,MaddieSimens,AmandaAskell,PeterWelinder,PaulChristiano,JanLeike,and
RyanLowe. Traininglanguagemodelstofollowinstructionswithhumanfeedback,2022. URL
https://arxiv.org/abs/2203.02155.
Vasile Pais, Maria Mitrofan, Carol Luca Gasan, Vlad Coneschi, and Alexandru Ianov. Named
entity recognition in the Romanian legal domain. In Proceedings of the Natural Legal Lan-
guage Processing Workshop 2021, pp. 9–18, Punta Cana, Dominican Republic, November
2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.nllp-1.2. URL
https://aclanthology.org/2021.nllp-1.2.
Christos Papaloukas, Ilias Chalkidis, Konstantinos Athinaios, Despina Pantazi, and Manolis
Koubarakis. Multi-granularlegaltopicclassificationonGreeklegislation. InProceedingsofthe
NaturalLegalLanguageProcessingWorkshop2021,pp.63–75,PuntaCana,DominicanRepublic,
November2021.AssociationforComputationalLinguistics. doi:10.18653/v1/2021.nllp-1.6. URL
https://aclanthology.org/2021.nllp-1.6.
ColinRaffel,NoamShazeer,AdamRoberts,KatherineLee,SharanNarang,MichaelMatena,Yanqi
Zhou,WeiLi,andPeterJ.Liu. ExploringtheLimitsofTransferLearningwithaUnifiedText-to-
TextTransformer. JournalofMachineLearningResearch,21(140):1–67,2020. ISSN1533-7928.
URLhttp://jmlr.org/papers/v21/20-074.html.
VishvaksenanRasiah,RonjaStern,VetonMatoshi,MatthiasStürmer,IliasChalkidis,DanielE.Ho,
andJoelNiklaus. SCALE:ScalinguptheComplexityforAdvancedLanguageModelEvaluation,
June2023. URLhttp://arxiv.org/abs/2306.09237. arXiv:2306.09237[cs].
AbhilashaRavichander,AlanWBlack,ShomirWilson,ThomasNorton,andNormanSadeh. Ques-
tion answering for privacy policies: Combining computational and legal perspectives. In Pro-
ceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and
the9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-IJCNLP),pp.
4947–4958,HongKong,China,November2019.AssociationforComputationalLinguistics. doi:
10.18653/v1/D19-1500. URLhttps://aclanthology.org/D19-1500.
Olivier Salaün, Frédéric Piedboeuf, Guillaume Le Berre, David Alfonso Hermelo, and Philippe
Langlais. EUROPA:ALegalMultilingualKeyphraseGenerationDataset,February2024. URL
http://arxiv.org/abs/2403.00252. arXiv:2403.00252[cs].
15Victor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai,
AntoineChaffin,ArnaudStiegler,TevenLeScao,ArunRaja,MananDey,M.SaifulBari,Canwen
Xu,UrmishThakker,ShanyaSharmaSharma,ElizaSzczechla,TaewoonKim,GunjanChhablani,
NihalNayak,DebajyotiDatta,JonathanChang,MikeTian-JianJiang,HanWang,MatteoManica,
ShengShen,ZhengXinYong,HarshitPandey,RachelBawden,ThomasWang,TrishalaNeeraj,
JosRozen,AbheeshtSharma,AndreaSantilli,ThibaultFevry,JasonAlanFries,RyanTeehan,
TaliBers,StellaBiderman,LeoGao,ThomasWolf,andAlexanderM.Rush. MultitaskPrompted
Training Enables Zero-Shot Task Generalization. arXiv:2110.08207 [cs], March 2022. URL
http://arxiv.org/abs/2110.08207. arXiv: 2110.08207.
Gil Semo, Dor Bernsohn, Ben Hagag, Gila Hayat, and Joel Niklaus. ClassActionPrediction: A
Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US. In
ProceedingsoftheNaturalLegalLanguageProcessingWorkshop2022,pp.31–46,AbuDhabi,
UnitedArabEmirates(Hybrid),December2022.AssociationforComputationalLinguistics. URL
https://aclanthology.org/2022.nllp-1.3.
ZejiangShen,KyleLo,LaurenYu,NathanDahlberg,MargoSchlanger,andDougDowney. Multi-
LexSum: Real-WorldSummariesofCivilRightsLawsuitsatMultipleGranularities,July2022.
URLhttp://arxiv.org/abs/2206.10883. arXiv:2206.10883[cs].
AbhayShukla,PaheliBhattacharya,SohamPoddar,RajdeepMukherjee,KripabandhuGhosh,Pawan
Goyal,andSaptarshiGhosh. LegalCaseDocumentSummarization: ExtractiveandAbstractive
MethodsandtheirEvaluation. InProceedingsofthe2ndConferenceoftheAsia-PacificChapter
oftheAssociationforComputationalLinguisticsandthe12thInternationalJointConferenceon
NaturalLanguageProcessing,pp.1048–1064,2022.
HaroldJ.Spaeth,LeeEpstein,AndrewD.Martin,JeffreyA.Segal,TheodoreJ.Ruger,andSaraC.
Benesh. SupremeCourtDatabase,Version2020Release01,2020.
RalfSteinberger,BrunoPouliquen,AnnaWidiger,CameliaIgnat,TomažErjavec,DanTufis¸,and
Dániel Varga. The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages.
In Proceedings of the Fifth International Conference on Language Resources and Evaluation
(LREC’06),Genoa,Italy,May2006.EuropeanLanguageResourcesAssociation(ELRA). URL
http://www.lrec-conf.org/proceedings/lrec2006/pdf/340_pdf.pdf.
ChenhaoTan,VladNiculae,CristianDanescu-Niculescu-Mizil,andLillianLee. Winningarguments:
Interactiondynamicsandpersuasionstrategiesingood-faithonlinediscussions. InProceedingsof
WWW,2016.
YiTay,MostafaDehghani,VinhQ.Tran,XavierGarcia,DaraBahri,TalSchuster,HuaixiuSteven
Zheng,NeilHoulsby,andDonaldMetzler. UnifyingLanguageLearningParadigms,May2022.
URLhttp://arxiv.org/abs/2205.05131. arXiv:2205.05131[cs].
Nguyen Ha Thanh, Bui Minh Quan, Chau Nguyen, Tung Le, Nguyen Minh Phuong, Dang Tran
Binh,VuongThiHaiYen,TeeradajRacharak,NguyenLeMinh,TranDucVu,PhanVietAnh,
NguyenTruongSon,HuyTienNguyen,BhumindrButr-indr,PeeraponVateekul,andPrachya
Boonkwan. Asummaryofthealqac2021competition. In202113thInternationalConference
onKnowledgeandSystemsEngineering(KSE),pp.1–5,2021. doi: 10.1109/KSE53942.2021.
9648724.
DonTuggener,PiusvonDäniken,ThomasPeetz,andMarkCieliebak. LEDGAR:ALarge-Scale
Multi-labelCorpusforTextClassificationofLegalProvisionsinContracts. InProceedingsof
the 12th Language Resources and Evaluation Conference, pp. 1235–1241, Marseille, France,
May2020.EuropeanLanguageResourcesAssociation. ISBN979-10-95546-34-4. URLhttps:
//aclanthology.org/2020.lrec-1.155.
Georgios Tziafas, Eugenie de Saint-Phalle, Wietse de Vries, Clara Egger, and Tommaso Caselli.
A multilingual approach to identify and classify exceptional measures against covid-19. In
ProceedingsoftheNaturalLegalLanguageProcessingWorkshop2021,pp.46–62,2021. Dataset
URL:https://tinyurl.com/ycysvtbm.
16Stefanie Urchs, Jelena Mitrovic´, and Michael Granitzer. Design and Implementation of Ger-
man Legal Decision Corpora:. In Proceedings of the 13th International Conference on
Agents and Artificial Intelligence, pp. 515–521, Online Streaming, — Select a Country —,
2021. SCITEPRESS - Science and Technology Publications. ISBN 978-989-758-484-8. doi:
10.5220/0010187305150521. URL https://www.scitepress.org/DigitalLibrary/Link.
aspx?doi=10.5220/0010187305150521.
MaartenPeterVink,LuukVanDerBaaren,RainerBauböck,JelenaDZANKIC,IseultHONOHAN,
andBronwenMANBY. Globalcitcitizenshiplawdataset. 2021.
VernRWalker,KrishnanPillaipakkamnatt,AlexandraMDavidson,MarysaLinares,andDomenickJ
Pesce. Automaticclassificationofrhetoricalrolesforsentences: Comparingrule-basedscripts
withmachinelearning. ASAIL@ICAIL,2385,2019.
AlexWang,YadaPruksachatkun,NikitaNangia,AmanpreetSingh,JulianMichael,FelixHill,Omer
Levy,andSamuelRBowman. SuperGLUE:AStickierBenchmarkforGeneral-PurposeLanguage
UnderstandingSystems. pp. 30,2019.
StevenH.Wang,AntoineScardigli,LeonardTang,WeiChen,DimitryLevkin,AnyaChen,Spencer
Ball,ThomasWoodside,OliverZhang,andDanHendrycks. MAUD:AnExpert-AnnotatedLegal
NLPDatasetforMergerAgreementUnderstanding,November2023a. URLhttp://arxiv.org/
abs/2301.00876. arXiv:2301.00876[cs].
YizhongWang,SwaroopMishra,PegahAlipoormolabashi,YeganehKordi,AmirrezaMirzaei,Anjana
Arunkumar,ArjunAshok,ArutSelvanDhanasekaran,AtharvaNaik,DavidStap,EshaanPathak,
GiannisKaramanolakis,HaizhiGaryLai,IshanPurohit,IshaniMondal,JacobAnderson,Kirby
Kuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar Pal, Mehrad Moradshahi, Mihir Parmar,
MiraliPurohit,NeerajVarshney,PhaniRohithaKaza,PulkitVerma,RavsehajSinghPuri,Rushang
Karia, Shailaja Keyur Sampat, Savan Doshi, Siddhartha Mishra, Sujan Reddy, Sumanta Patro,
TanayDixit,XudongShen,ChittaBaral,YejinChoi,NoahA.Smith,HannanehHajishirzi,and
DanielKhashabi. Super-NaturalInstructions: GeneralizationviaDeclarativeInstructionson1600+
NLPTasks,October2022. URLhttp://arxiv.org/abs/2204.07705. arXiv:2204.07705[cs].
YizhongWang,HamishIvison,PradeepDasigi,JackHessel,TusharKhot,KhyathiRaghaviChandu,
DavidWadden,KelseyMacMillan,NoahA.Smith,IzBeltagy,andHannanehHajishirzi. Howfar
cancamelsgo? exploringthestateofinstructiontuningonopenresources,2023b.
YizhongWang,YeganehKordi,SwaroopMishra,AlisaLiu,NoahA.Smith,DanielKhashabi,and
HannanehHajishirzi. Self-instruct: Aligninglanguagemodelswithself-generatedinstructions. In
Proceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume
1: LongPapers),pp.13484–13508,Toronto,Canada,July2023c.AssociationforComputational
Linguistics. doi: 10.18653/v1/2023.acl-long.754. URL https://aclanthology.org/2023.
acl-long.754.
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du,
AndrewM.Dai,andQuocVLe.Finetunedlanguagemodelsarezero-shotlearners.InInternational
ConferenceonLearningRepresentations,2022a. URLhttps://openreview.net/forum?id=
gEZrGCozdqR.
JasonWei,MaartenBosma,VincentY.Zhao,KelvinGuu,AdamsWeiYu,BrianLester,NanDu,
AndrewM.Dai,andQuocV.Le. FinetunedLanguageModelsAreZero-ShotLearners,February
2022b. URLhttp://arxiv.org/abs/2109.01652. arXiv:2109.01652[cs].
Benjamin Weiser. Here’s what happens when your lawyer uses chatgpt. New
York Times, may 2023. URL https://www.nytimes.com/2023/05/27/nyregion/
avianca-airline-lawsuit-chatgpt.html.
ShomirWilson,FlorianSchaub,AswarthAbhilashDara,FrederickLiu,SushainCherivirala,Pe-
droGiovanniLeon,MadsSchaarupAndersen,SebastianZimmeck,KanthashreeMysoreSathyen-
dra,NCameronRussell,etal. Thecreationandanalysisofawebsiteprivacypolicycorpus. In
Proceedingsofthe54thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume
1: LongPapers),pp.1330–1340,2016.
17ChaojunXiao,HaoxiZhong,ZhipengGuo,CunchaoTu,ZhiyuanLiu,MaosongSun,YansongFeng,
XianpeiHan,ZhenHu,HengWang,andJianfengXu. CAIL2018: ALarge-ScaleLegalDataset
forJudgmentPrediction. arXiv:1807.02478[cs],July2018. URLhttp://arxiv.org/abs/1807.
02478. arXiv: 1807.02478.
Chaojun Xiao, Haoxi Zhong, Zhipeng Guo, Cunchao Tu, Zhiyuan Liu, Maosong Sun, Tianyang
Zhang,XianpeiHan,HengWang,JianfengXu,etal. Cail2019-scm: Adatasetofsimilarcase
matchinginlegaldomain. arXivpreprintarXiv:1911.08962,2019.
LintingXue,NoahConstant,AdamRoberts,MihirKale,RamiAl-Rfou,AdityaSiddhant,Aditya
Barua, and Colin Raffel. mT5: A massively multilingual pre-trained text-to-text transformer.
arXiv:2010.11934 [cs], March 2021. URL http://arxiv.org/abs/2010.11934. arXiv:
2010.11934.
Lucia Zheng, Neel Guha, Brandon R. Anderson, Peter Henderson, and Daniel E. Ho. When
does pretraining help? assessing self-supervised learning for law and the casehold dataset of
53,000+legalholdings. InProceedingsoftheEighteenthInternationalConferenceonArtificial
Intelligence and Law, ICAIL ’21, pp. 159–168, New York, NY, USA, 2021. Association for
ComputingMachinery. ISBN9781450385268. doi: 10.1145/3462757.3466088. URLhttps:
//doi.org/10.1145/3462757.3466088.
ZheZheng, Xin-ZhengLu, Ke-YinChen, Yu-ChengZhou, andJia-RuiLin. PretrainedDomain-
SpecificLanguageModelforNaturalLanguageProcessingTasksintheAECDomain. Comput.
Ind., 142(C),November2022. ISSN0166-3615. doi: 10.1016/j.compind.2022.103733. URL
https://doi.org/10.1016/j.compind.2022.103733. Place:NLDPublisher:ElsevierScience
PublishersB.V.
HaoxiZhong,ChaojunXiao,CunchaoTu,TianyangZhang,ZhiyuanLiu,andMaosongSun. Jec-qa:
Alegal-domainquestionansweringdataset. InProceedingsofAAAI,2020.
A DetailedDatasetDescription
Figure12showstheLawInstructtasktypeandjurisdictioncompositionbydataset. Table2liststhe
dataset(andsources),license,language,jurisdiction,tasktype,subtask,andnumberofexamplesfor
eachdatasetincludedinLawInstruct.
Task Type by Number of Datasets Jurisdiction by Number of Datasets
Brazil
Multiple Choice China
3.3% 35.0% Natural Language 11.5% 27.9% EU
Inference 4.9% Germany
10.0%
Question Answering 8.2% India
6.7% 8.3% Question Generation South Korea
3.3% S Teu xm t m Ca lari sz sa ift ii co an tion 6.6 4% .9% 14.8% S Uw nkit nz oer wla nnd
4.9%
33.3% Other 3.3% 13.1% US
Other
Figure12: Jurisdictionandtasktypebydatasets.
B DetailedExperimentalSetup
B.1 InexplicableBehaviourattheXXLsize
Wespentconsiderableeffort,includingjointdebuggingwiththeauthorsofLegalBench,toreproduce
theirresults. Wedoublecheckedthattheprompts,decodinghyperparametersandgeneralsetupare
18Dataset License Languages Jurisdiction Tasks Subtask Examples
BenchmarkforUnderstandingIndianLegalDocuments Unknown en India Textclassification Rhetoricalrole 28,986
(BUILD)(Kalamkaretal.,2022)
BrazilianBarExam(Delfinoetal.,2017) Unknown pt Brazil Questionanswering Barexamquestions 2,130
BrazilianCourtDecisions(Lage-Freitasetal.,2022) Unknown pt Brazil Textclassification Judgment 3,234
BrazilianCourtDecisions(Lage-Freitasetal.,2022) Unknown pt Brazil Textclassification DecisionUnanimity 1,715
BrCAD5(JacobdeMenezes-Neto&Clementino,2022) CCBY-NC-SA4.0 pt Brazil Multiplechoice Judgment 1,225,922
BrCAD5(JacobdeMenezes-Neto&Clementino,2022) CCBY-NC-SA4.0 pt Brazil Textclassification Judgment 612,961
BrCAD5(JacobdeMenezes-Neto&Clementino,2022) CCBY-NC-SA4.0 pt Brazil Textclassification Areaoflaw 612,961
BrCAD5(JacobdeMenezes-Neto&Clementino,2022) CCBY-NC-SA4.0 pt Brazil Textclassification Topic 1,838,883
BVADecisions(Walkeretal.,2019) MIT en USA Textclassification Rhetoricalrole 8,818
BVADecisions(Walkeretal.,2019) MIT en USA Questionanswering Relevantrules 2
CAIL2019(Xiaoetal.,2019) Unknown zh China Questionanswering Chineselegalcasequestions 39,333
CAIL2022(CAIL2022) Unknown zh China Textclassification Charge/crime 10,448
CAIL2022(CAIL2022) Unknown zh China Argument&counter-argument 5,224
CAIL2022(CAIL2022) Unknown zh China Questionanswering Responsetoargument 5,224
CaseBriefs(Casebriefs) CCBY-NC en USA Questionanswering Legalanalysisoffacts 2,619
CaseHOLD(Zhengetal.,2021) CC-BY en USA Multiplechoice Legalholdingstatements 45,000
ChangeMyView(Tanetal.,2016) Unknown en N/A Argument&counter-argument 3,456
COLIEE(Kimetal.,2022) Academicuseonly en,jp Canada/Japan Questiongeneration Entailedquestion 1,774
COLIEE(Kimetal.,2022) Academicuseonly en,jp Canada/Japan Naturallanguageinference Passageentailment 125,954
COLIEE(Kimetal.,2022) Academicuseonly en,jp Canada/Japan Questionanswering Relevantlegalrule 1,774
ContractNLI(Koreeda&Manning,2021) CCBY-NC en USA Naturallanguageinference Premisehypothesisentailment 14,010
COVID-19EmergencyMeasures(EXCEPTIUS)(Tziafas Unknown en,fr,hu,it, EU Textclassification Measuretype 3,312
etal.,2021) nb,nl,pl
EuropeanCourtofHumanRights(ECtHR)(Chalkidis CCBY-NC-SA4.0 en EU Textclassification(multi-label) Violatedarticle 9,000
etal.,2021b)
EuropeanCourtofHumanRights(ECtHR)(Chalkidis CCBY-NC-SA4.0 en EU Textclassification(multi-label) Allegedlyviolatedarticle 9,000
etal.,2021b)
EOIR(Hendersonetal.,2022) CCBY-NC-SA4.0 en USA Textclassification Pseudonymity 8,089
EURLEX(Chalkidisetal.,2019) CCBY-SA4.0 en EU Textclassification EuroVoccoreconcepts 55,000
EUR-Lex-Sum(Aumilleretal.,2022) CCBY4.0 24EUlangs EU Summarization EULegalActs 22,989
GermanArgumentMining(Urchsetal.,2021) CCBY4.0 de Germany Textclassification Argumentativefunction 19,271
GermanRentalAgreements(Steinbergeretal.,2006) Unknown de Germany Textclassification Semantictype 3,292
GreekLegalCode(Papaloukasetal.,2021) CCBY4.0 el Greece Textclassification Volume(coarsethematictopic) 28,536
GreekLegalCode(Papaloukasetal.,2021) CCBY4.0 el Greece Textclassification Chapter(intermediatethematictopic) 28,536
GreekLegalCode(Papaloukasetal.,2021) CCBY4.0 el Greece Textclassification Subject(fine-grainthematictopic) 28,536
GreekLegalNER(elNER)(Bartziokasetal.,2020) CCBY-NC-SA4.0 el Greece Namedentityrecognition Greeklegalentities 17,699
ILDC(Maliketal.,2021) CCBY-NC en India Textclassification Judgment 37,387
InternationalCitizenshipLaw(Vinketal.,2021) CCBY4.0 en International Questionanswering Citizenshipacquisition 6,460
InternationalCitizenshipLaw(Vinketal.,2021) CCBY4.0 en International Questionanswering Citizenshiploss 2,850
JEC-QA(Zhongetal.,2020) CCBY-NC-ND zh China Multiplechoice NationalJudicialExaminationofChina 21,072
KoreanLegalQA(Jeon,2021) Academicuseonly ko SouthKorea Questionanswering Relevantlaw 1,830
LawngNLI(Bruno&Roth,2022) MIT en USA Naturallanguageinference Premisehypothesisentailment 1,142,304
LBOXOPEN(Hwangetal.,2022) CCBY-NC ko SouthKorea Textclassification Judgment 12,142
LBOXOPEN(Hwangetal.,2022) CCBY-NC ko SouthKorea Textclassification Relevantstatutes 13,317
LEDGAR(Tuggeneretal.,2020) CCBY-NC en USA Textclassification Contractprovisioncategory 60,000
LegalCaseDocumentSummarization(Shuklaetal.,2022; CCBY-SA en India Summarization IndianSupremeCourt 7,080
Bhattacharyaetal.,2019)
LegalCaseSummarization(Shuklaetal.,2022;Bhat- CCBY-SA en UK Summarization UKSupremeCourt 693
tacharyaetal.,2019)
LegalNERo(Paisetal.,2021) CC01.0 ro Romania Namedentityrecognition Romanianlegalentities 7,552
LegalQA(LegalQA) Unknown zh China Questionanswering Legaladvice 21,946
LeNER-Br(LuzdeAraujoetal.,2018) Unknown pt Brazil Namedentityrecognition Brazilianlegalentities 7,828
Littleton(Basuetal.,2022) MIT en USA Questionanswering Relevantfutureinterests 131
Littleton(Basuetal.,2022) MIT en USA Questionanswering Eventgraph 143
MAPA(deGibertBonetetal.,2022) CCBY-NC4.0 24EUlangs EU Namedentityrecognition Coarse-grained 27,823
MAPA(deGibertBonetetal.,2022) CCBY-NC4.0 24EUlangs EU Namedentityrecognition Fine-grained 27,823
MAUD(Wangetal.,2023a) CCBY en USA Multiplechoice Mergeragreementquestions 10,751
MAUD(Wangetal.,2023a) CCBY en USA Textclassification Dealpointcategory 25,827
MAUD(Wangetal.,2023a) CCBY en USA Textclassification Questiontype 25,827
MAUD(Wangetal.,2023a) CCBY en USA Textclassification Texttype 25,827
MiningLegalArguments(Habernaletal.,2022) Apache-2.0 en EU Namedentityrecognition Actors 31,852
MiningLegalArguments(Habernaletal.,2022) Apache-2.0 en EU Namedentityrecognition Argumenttype 31,852
MultiEURLEX(Chalkidisetal.,2021a) CCBY-SA 24EUlangs EU Textclassification(multi-label) EuroVoctaxonomy(coarselevel) 1,265,000
MultiEURLEX(Chalkidisetal.,2021a) CCBY-SA 24EUlangs EU Textclassification(multi-label) EuroVoctaxonomy(intermediatelevel) 911,798
MultiEURLEX(Chalkidisetal.,2021a) CCBY-SA 24EUlangs EU Textclassification(multi-label) EuroVoctaxonomy(fine-grainlevel) 1,265,000
Multi-LexSum(Shenetal.,2022) ODC-By en USA Summarization Longtoshort 2,210
Multi-LexSum(Shenetal.,2022) ODC-By en USA Summarization Longtotiny 1,130
Multi-LexSum(Shenetal.,2022) ODC-By en USA Summarization Shorttotiny 1,129
NaturalInstructions(BillSum)(Kornilova&Eidelman, CC01.0 en USA Summarization U.SCongressionalandCaliforniastatebills 25,200
2019)
NaturalInstructions(CAIL2018)(Xiaoetal.,2018) Unknown zh China Questionanswering Judgment 5,988
NaturalInstructions(CaseHOLD)(Zhengetal.,2021) CC-BY en USA Multiplechoice Correctanswer 5,988
NaturalInstructions(CaseHOLD)(Zhengetal.,2021) CC-BY en USA Multiplechoice Incorrectanswer 5,988
NaturalInstructions(CUAD)(Hendrycksetal.,2021c) CCBY4.0 en Questionanswering Informationrelevantforcontractreview 2,442
NaturalInstructions(CUAD)(Hendrycksetal.,2021c) CCBY4.0 en USA Questiongeneration Questionsrelevantforcontractreview 2,442
NaturalInstructions(EURLEX)(Chalkidisetal.,2019) CCBY-SA4.0 en EU Textclassification Regulation,decisions,ordirective 5,850
NaturalInstructions(EURLEX)(Aumilleretal.,2022) CCBY-SA4.0 en EU Summarization EULegalActs 3,900
NaturalInstructions(OPP-115)(Wilsonetal.,2016) CCBY-NC en USA Questionanswering Typeofinformationusedbywebsite 18,480
NaturalInstructions(OPP-115)(Wilsonetal.,2016) CCBY-NC en USA Questionanswering Purposeofprivacypolicy 18,474
NaturalInstructions(Overruling)(Zhengetal.,2021) Unknown en USA Textclassification Sentenceisoverruling 14,370
OLCMemos(Hendersonetal.,2022) CCBY-NC en USA Questionanswering Writealegalresearchmemo 1,038
OnlineToS(Drawzeskietal.,2021) CCBY-NC2.5 de,en,it,pt Unknown Textclassification Clausetopic 19,942
OnlineToS(Drawzeskietal.,2021) CCBY-NC2.5 de,en,it,pt Unknown Textclassification Unfaircontractualtermtype 2,074
PlainEnglishContractsSummarization(Manor&Li, Unknown en USA Summarization Softwarelicenses,ToS 446
2019)
PrivacyQA(Ravichanderetal.,2019) MIT en Unknown Questionanswering Contentsofprivacypolicies 185,200
PrivacySummarization(Keymaneshetal.,2020) MIT en USA Summarization Privacypolicies,ToS,andcookiepolicies 5,751
RedditLegalQA(Hendersonetal.,2022) CCBY4.0 en Unknown Questionanswering Legaladvicefromr/legaladvice 192,953
Sara(Holzenbergeretal.,2020) Unknown en USA Naturallanguageentailment Factentailment 176
Sara(Holzenbergeretal.,2020) Unknown en USA Questionanswering Taxliability 160
SaraProlog(Holzenbergeretal.,2020) Unknown en USA Questionanswering Factpatterntoprologcode 376
SaraProlog(Holzenbergeretal.,2020) Unknown en USA Questionanswering Taxstatutetoprologcode 9
ShortAnswerFeedback(Filigheraetal.,2022) CCBY4.0 de Germany Questionanswering AnswerquestionaboutGermanlaw 1,596
ShortAnswerFeedback(Filigheraetal.,2022) CCBY4.0 de Germany Questionanswering Feedbackratingforanswer 1,596
SpanishLaborLaw(Callejaetal.,2021) CCBY4.0 es Spain Extractivequestionanswering AnswerquestionaboutSpanishlaborlaw 111
StackExchangeQuestions(Law)(LawStackExchange) CCBY-SA en Unknown Questionanswering Onlinelegalforum 10,158
TheSupremeCourtDatabase(Spaethetal.,2020) CCBY-NC3.0 en USA Textclassification Issueareas 5,000
SwissFederalSupremeCourt(Rasiahetal.,2023) CCBY4.0 de,fr Textgeneration Caseconsiderationssections(lowercourt) 26
SwissCourts(Rasiahetal.,2023) CCBY4.0 de,fr,it Switzerland Textgeneration Caseconsiderationssections(samecourt) 234,313
SwissFederalSupremeCourt(Rasiahetal.,2023) CCBY4.0 de,fr,it Switzerland Textclassification Casecriticality(basedoncitations) 91,075
SwissCourts(Rasiahetal.,2023;Niklausetal.,2021) CCBY4.0 de,fr,it,en Switzerland Multiplechoice Judgment 477,636
SwissCourts(Rasiahetal.,2023;Niklausetal.,2021) CCBY4.0 de,fr,it Switzerland Textclassification Judgment 385,719
SwissCourts(Rasiahetal.,2023;Niklausetal.,2021) CCBY4.0 de,fr,it,en Switzerland Textclassification Areaoflaw 18,162
SwissCourts(Rasiahetal.,2023;Niklausetal.,2021) CCBY4.0 de,fr,it,en Switzerland Textclassification Subareaoflaw 18,162
Swiss Federal Supreme Court (Leading Decisions) CCBY4.0 de,en,fr,it Switzerland Textclassification Location(canton,region) 42,342
(Rasiahetal.,2023)
SwissLegislation(Rasiahetal.,2023) CCBY4.0 de,fr,it,rm Switzerland Textclassification Abbreviation 11,045
SwissLegislation(Rasiahetal.,2023) CCBY4.0 de,en,fr,it,rm Switzerland Textclassification Canton 35,698
SwissLegislation(Rasiahetal.,2023) CCBY4.0 de,en,fr,it,rm Switzerland Textclassification Shortdescription 3,747
SwissLegislation(Rasiahetal.,2023) CCBY4.0 de,en,fr,it,rm Switzerland Textclassification Title 35,359
ThaiSupremeCourtCases(TSCC)(Thanhetal.,2021) Academicuseonly th Thailand Questionanswering Relevantlegalarticles(ThaiCriminalCode) 2,883
TurkishConstitutionalCourt(Mumcuog˘luetal.,2021) CCBY4.0 tr Turkey Multiplechoice Judgment 1,804
TurkishConstitutionalCourt(Mumcuog˘luetal.,2021) CCBY4.0 tr Turkey Textclassification Judgment 902
UnfairToS(Lippietal.,2019) Unknown en USA Textclassification(multi-label) Unfaircontractualtermtype 5,532
U.SClassActions(Semoetal.,2022) GPL-3.0 en USA Textclassification Judgment 3,000
ValidWills(Kwaketal.,2022) Unknown en USA Textclassification Statementsupportedbylaw/condition 1,512
Table2: OverviewoftheLawInstructdatasets. The24EUlangsarebg,cs,da,de,el,en,es,et,
fi,fr,ga,hu,it,lt,lv,mt,nl,pt,ro,sv,sk. Abbreviations: TermsofService(ToS)
19consistent. Weconjecture,thattheconversionoftheFlan-T5weightsasdonebyHuggingFaceon
theirhubleadstodifferentbehaviorwhenrunningthemodelswithT5XonTPUs(oursetup)vs
runningthemwithHuggingFacetransformersandPyTorchonNVIDIAGPUs(originalLegalBench
setup)5.
TheXXLmT5modeldidnottrainstablyinthecontinuedpretrainingphasedespiteheavyhyperpa-
rametertuning.
B.2 Evaluation
WeexcludedanylegaltasksoccurringinMMLUfromLawInstruct. However,thereissomeoverlap
regardingthetasksincludedinLawInstructandinLegalBenchbecausehigh-qualitylegaltasksare
rare. Tocontrolfortheseoverlappingtasks,weevaluateontwoversionsofLegalBenchholdingout
tasksbythedatasetsortasksoccurringinLawInstructrespectively.
B.2.1 LegalBenchDatasetHeldOut
IfthesourcedatasetoftheLegalBenchtaskoccursinLawInstruct,weremoveitfromtheevaluation.
Below,welistwhichtasksareoverlapping. Overall100tasksareheldout,so61tasksareremaining
forLegalBenchevaluation.
5Similarissuesarementionedinthisissue:https://github.com/PiotrNawrot/nanoT5/issues/25
20• ContractNLI
– LawInstruct: ContractNLI-contract_nli
– LegalBench: contract_nli_*
• CUAD
– LawInstruct: NaturalInstructionsLegal-cuad_answer_generation,
NaturalInstructionsLegal-cuad_question_generation
– LegalBench: cuad_*
• GLOBALCITCitizenshipLawDataset
– LawInstruct: InternationalCitizenshipLawQuestions-
international_citizenship_law_questions_mode_acq,
InternationalCitizenshipLawQuestions-international_citizenship_law_questions_mode_loss
– LegalBench: international_citizenship_questions
• MAUD
– LawInstruct: MAUD-answer,MAUD-category,MAUD-question,MAUD-text_type
– LegalBench: maud_*
• OPP-115(OnlinePrivacyPolicies,setof115)Corpus
– LawInstruct:NaturalInstructionsLegal-online_privacy_policy_text_information_type_generation,
NaturalInstructionsLegal-online_privacy_policy_text_purpose_answer_generation
– LegalBench: opp_115_*
• Overruling
– LawInstruct: NaturalInstructionsLegal-overruling_legal_classification
– LegalBench: overruling
• PrivacyQA
– LawInstruct: PrivacyQA-privacy_qa
– LegalBench: privacy_policy_qa
Note: TheLegalBenchprivacy_policy_entailmentSourcefieldiscurrentlyincorrectly
linkedtothisdataset(PrivacyQA),butisderivedfromadifferentdataset(APP-350
Corpus).
• StAtutoryReasoningAssessment(SARA)
– LawInstruct: Sara-sara_entailment, Sara-sara_tax_liability, SaraProlog-
sara_prolog_facts,SaraProlog-sara_prolog_statute
– LegalBench: sara_*(builtoffofSARAv2)
• UnfairTermsofService
– LawInstruct: ThisdatasetisduplicatedbetweenLexGLUE-unfair_tos,LEXTREME-
online_terms_of_service_clause_topics (multilingual version), LEXTREME-
online_terms_of_service_unfairness_levels(multilingualversion)
– LegalBench: unfair_tos
B.2.2 LegalBenchTaskHeldOut
WeadditionallycataloginstructionswhichtraintheLLMforataskcapturedinLegalBench. Itis
notnecessarythattheinstruction-responsepairinLawInstructcontaindatafromLegalBench,just
thattheyareaboutsimilarlegaltasks(e.g.,classifyingchoice-of-forumprovisions). Below,welist
whichtasksareoverlapping. Overall64tasksareheldout,so97tasksareremainingforLegalBench
evaluation.
21• RhetoricalRoleLabeling(EvaluatesLLM’sabilitytoannotatethefunctionofapieceof
legaltext.)
– LawInstruct: bva_decisions_label, indian_text_segmentation, ger-
man_argument_mining
– LegalBench: function_of_decision_section,oral_argument_question_purpose
• CivilProcedureQuestions(EvaluatesLLM’sapplicationofbasiclawsofUSjurisdiction.)
– LawInstruct: civipro_questions_generate_*
– LegalBench: diversity_*,personal_jurisdiction
• LegalEntailment(EvaluatesLLM’sunderstandingoflogicalrelationshipsinlegaltexts.)
– LawInstruct: coliee_task3_passage_entailment,contract_nli,lawng_nli_entailment
– LegalBench: contract_nli_*
• ContractualClauseClassification(EvaluatesLLM’sabilitytoclassifycontractualclauses.)
– LawInstruct: unfair_tos,german_rental_agreements
– LegalBench: cuad_*,jcrew_blocker,unfair_tos,contract_qa
C AdditionalAblations
C.1 CrosslingualTransferfromMultilingualData
Istherecrosslingualtransferfrommultilingual Mean for all four sizes on LegalBench
70
data? ⇒OntheEnglishLegalBench,wedo all-res
notseeanycrosslingualtransfer. InFigure13, 60 en-res
all-comm
we compare the performance of the complete 50 en-comm 46.547.446.847.2
m suu bl st eil tin ag cu roa sl sin ts wtr ouc dt ii fo fn erd ea nt ta lyse lt ica en nd st eh de dE an tag sli es th s 40 35.135.534.135.8 37.639.038.738.2 41.039.940.740.6
(researchandcommerciallicenses). Weseeno 30
statistically significant difference between the
20
multilingual training and the English training.
10
Wealsoseenodifferencebetweenthedifferently
licenseddatasets. Thismeansthatjusttraining 0
Small Base XL XXL
onthecommercialsubsetisenough. Weshow Models
detailedresultsonindividualLegalBenchcate-
Figure13:Ablationonthelanguageandlicenseon
goriesinAppendixDTable7. Perdefaultwe
flan2-lawinstructfromthemT5checkpointacross
usetheEnglishdatasetinallfollowingexperi-
allsizes,samplingbythenumberofexamples.
mentsunlessspecifiedotherwise.
22
naeM
hcneBlageLD DetailedResults
Table3: BaselineresultsonLegalBench.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Flan-T5XXL(ours) 36.1 18.8 25.2 35.1 41.1 31.3
Flan-T5-XXL(Guhaetal.,2023) 66.0 36.0 63.3 64.4 70.7 60.1
LLaMA-2-13B(Guhaetal.,2023) 50.2 37.7 59.3 50.9 54.9 50.6
OPT-13B(Guhaetal.,2023) 52.9 28.4 45.0 45.1 43.2 42.9
Vicuna-13B-16k(Guhaetal.,2023) 34.3 29.4 34.9 40.0 30.1 33.7
WizardLM-13B(Guhaetal.,2023) 24.1 38.0 62.6 50.9 59.8 47.1
Flan-T5XL(ours) 53.5 32.1 46.8 58.7 59.6 50.1
Flan-T5-XL(Guhaetal.,2023) 56.8 31.7 52.1 51.4 67.4 51.9
BLOOM-3B(Guhaetal.,2023) 47.4 20.6 45.0 45.0 36.4 38.9
Incite-3B-Instruct(Guhaetal.,2023) 51.1 26.9 47.4 49.6 40.2 43.0
OPT-2.7B(Guhaetal.,2023) 53.7 22.2 46.0 44.4 39.8 41.2
Flan-T5Base(ours) 44.7 18.0 20.9 28.9 37.0 29.9
Flan-T5Small(ours) 0.3 30.4 39.8 28.2 27.7 25.3
Table4: TheT5andFlan-T5modelsfinetunedonflan2-lawinstructinfoursizes.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
SmallT5 45.5±13.2 25.0±28.9 25.6±27.4 18.6±23.6 32.9±26.8 29.5±10.3
SmallFlan-T5 25.0±22.0 38.1±25.4 33.1±24.4 20.6±26.4 40.7±19.5 31.5±8.5
BaseT5 49.8±0.7 38.1±25.4 34.0±23.3 21.3±22.8 38.0±19.4 36.2±10.2
BaseFlan-T5 50.3±2.4 38.8±25.9 34.0±22.4 43.0±21.1 54.1±13.0 44.1±8.2
XLT5 47.8±12.5 37.5±25.0 38.2±15.5 28.6±25.1 49.4±8.1 40.3±8.5
XLFlan-T5 65.7±15.2 45.1±30.3 49.0±23.5 56.8±18.8 79.0±11.4 59.1±13.6
XXLT5 52.7±6.8 38.5±25.7 50.0±22.8 44.9±25.2 70.7±20.5 51.4±12.1
XXLFlan-T5 55.2±23.7 46.3±31.6 56.1±29.1 57.7±19.8 84.6±9.6 60.0±14.4
Table5: TheFlan-T5modelsfinetunedonthreedifferentdatamixtures.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Smallbaseline 0.3±0.7 30.4±20.3 23.8±25.0 16.9±21.1 32.8±21.4 20.8±13.0
Smalllawinstruct 0.0±0.1 15.9±23.9 10.7±22.7 10.5±19.8 18.6±25.7 11.1±7.1
Smallflan2 28.2±22.4 37.8±25.3 35.1±24.2 22.6±23.3 40.5±19.4 32.8±7.3
Smallflan2-lawinstruct 25.0±22.0 38.1±25.4 33.1±24.4 20.6±26.4 40.7±19.5 31.5±8.5
Basebaseline 44.7±12.4 18.0±23.6 36.0±23.8 15.6±19.9 42.7±19.8 31.4±13.8
Baselawinstruct 14.6±14.7 22.3±26.3 30.2±22.6 19.7±26.0 17.8±27.4 20.9±5.9
Baseflan2 47.2±4.3 37.6±25.0 28.6±23.4 32.5±21.9 54.4±16.3 40.0±10.6
Baseflan2-lawinstruct 50.3±2.4 38.8±25.9 34.0±22.4 43.0±21.1 54.1±13.0 44.1±8.2
XLbaseline 53.5±6.0 32.1±24.6 38.2±22.4 49.8±22.6 68.1±20.1 48.3±14.0
XLlawinstruct 54.5±7.7 30.2±35.1 42.9±20.8 39.8±30.8 63.7±14.1 46.2±13.1
XLflan2 65.5±14.6 40.6±27.7 52.0±25.6 53.0±21.9 74.0±20.8 57.0±13.0
XLflan2-lawinstruct 65.7±15.2 45.1±30.3 49.0±23.5 56.8±18.8 79.0±11.4 59.1±13.6
XXLbaseline 36.1±21.5 18.8±24.6 39.4±32.1 25.7±24.2 47.6±14.0 33.5±11.4
XXLlawinstruct 54.1±7.2 37.7±27.2 53.2±32.6 46.7±25.0 73.7±15.1 53.1±13.3
XXLflan2 64.0±12.6 44.7±31.4 56.4±27.7 55.5±20.2 81.3±9.7 60.4±13.6
XXLflan2-lawinstruct 55.2±23.7 46.3±31.6 56.1±29.1 57.7±19.8 84.6±9.6 60.0±14.4
23Table6: Flan-T5modelsfinetunedonfourdifferentlicence-samplingstyleconfigurations.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Smallres-number 50.3±1.3 38.2±25.5 34.9±25.6 21.3±26.6 45.3±22.0 38.0±11.1
Smallres-equal 34.9±21.2 37.5±25.0 33.0±25.3 21.1±25.1 43.8±19.2 34.1±8.3
Smallcomm-number 25.0±22.0 38.1±25.4 33.1±24.4 20.6±26.4 40.7±19.5 31.5±8.5
Smallcomm-equal 31.6±25.1 37.2±24.8 33.6±22.8 20.2±24.0 42.6±21.3 33.1±8.3
Baseres-number 49.8±3.2 38.1±25.4 36.0±23.8 42.8±21.3 49.5±12.1 43.3±6.3
Baseres-equal 48.9±3.8 39.4±26.3 38.4±25.6 36.6±19.8 53.4±18.3 43.4±7.4
Basecomm-number 50.3±2.4 38.8±25.9 34.0±22.4 43.0±21.1 54.1±13.0 44.1±8.2
Basecomm-equal 49.2±2.9 38.5±25.7 36.4±20.3 40.5±19.8 52.6±13.3 43.4±7.1
XLres-number 59.9±10.4 44.2±29.8 53.5±28.0 57.1±20.2 82.4±11.1 59.4±14.2
XLres-equal 58.2±8.4 42.3±28.7 46.6±16.8 55.4±19.3 79.0±11.9 56.3±14.3
XLcomm-number 65.7±15.2 45.1±30.3 49.0±23.5 56.8±18.8 79.0±11.4 59.1±13.6
XLcomm-equal 59.3±10.4 40.6±27.2 47.7±20.7 54.1±20.0 78.7±11.9 56.1±14.4
XXLres-number 62.9±12.3 46.9±31.7 57.6±30.2 56.7±21.5 82.3±9.3 61.3±13.1
XXLres-equal 54.9±6.3 43.3±30.1 55.5±27.3 55.4±19.2 70.5±11.6 55.9±9.6
XXLcomm-number 55.2±23.7 46.3±31.6 56.1±29.1 57.7±19.8 84.6±9.6 60.0±14.4
XXLcomm-equal 59.5±13.1 45.7±30.0 54.8±27.6 55.4±19.6 77.2±12.3 58.5±11.6
Table7: Flan-T5modelsfinetunedonfourdifferentlanguage-licenseconfigurations.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Smallall-res 46.8±12.2 38.2±24.2 33.8±22.8 20.1±22.0 36.5±21.1 35.1±9.7
Smallen-res 50.7±5.9 37.4±24.9 34.0±23.0 18.5±22.9 37.1±23.0 35.5±11.5
Smallall-comm 49.7±2.1 38.0±24.1 34.0±23.0 13.2±19.9 35.8±21.8 34.1±13.2
Smallen-comm 49.1±13.3 37.5±25.0 34.4±23.3 19.7±23.2 38.2±24.2 35.8±10.6
Baseall-res 51.7±4.4 38.7±26.1 33.6±22.7 22.0±23.6 41.8±18.5 37.6±10.9
Baseen-res 51.8±5.5 37.5±25.0 37.1±16.5 20.7±22.7 48.0±18.1 39.0±12.1
Baseall-comm 51.8±5.2 38.0±25.4 34.3±22.9 23.7±24.7 45.5±12.6 38.7±10.7
Baseen-comm 52.0±3.7 37.5±25.0 33.2±22.7 21.9±21.8 46.5±21.2 38.2±11.7
XLall-res 49.9±0.9 37.5±25.0 36.9±18.1 28.3±22.9 52.2±10.7 41.0±9.9
XLen-res 49.9±0.3 37.5±25.0 36.6±18.4 24.8±25.9 50.5±8.6 39.9±10.7
XLall-comm 51.5±2.3 37.5±25.0 36.9±18.1 26.8±24.2 50.7±9.4 40.7±10.4
XLen-comm 49.9±1.0 37.5±25.0 38.3±16.0 27.2±24.3 50.3±9.8 40.6±9.7
XXLall-res 51.5±2.8 38.2±24.2 40.9±18.5 45.3±19.0 56.4±10.4 46.5±7.5
XXLen-res 53.4±5.4 39.0±24.8 40.1±20.5 45.4±20.6 59.0±9.9 47.4±8.7
XXLall-comm 50.6±1.4 38.3±24.3 45.2±22.4 41.0±20.2 58.9±8.7 46.8±8.2
XXLen-comm 52.5±4.1 33.3±27.0 43.9±24.8 47.2±17.8 59.2±16.2 47.2±9.7
Table8: Flan-T5modelsfinetunedontwodifferentinstructionstyleconfigurations.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Small1-english 28.3±22.1 37.5±25.0 35.3±20.2 21.8±26.5 44.8±17.9 33.6±8.8
Small10-english 25.0±22.0 38.1±25.4 33.1±24.4 20.6±26.4 40.7±19.5 31.5±8.5
Base1-english 51.1±6.2 39.0±26.0 36.2±21.6 43.6±21.2 57.6±14.7 45.5±8.8
Base10-english 50.3±2.4 38.8±25.9 34.0±22.4 43.0±21.1 54.1±13.0 44.1±8.2
XL1-english 60.6±11.1 42.5±28.8 52.1±24.4 55.0±18.7 81.3±11.1 58.3±14.5
XL10-english 65.7±15.2 45.1±30.3 49.0±23.5 56.8±18.8 79.0±11.4 59.1±13.6
XXL1-english 63.0±13.1 43.9±29.7 59.0±30.5 58.1±20.2 80.7±9.9 60.9±13.2
XXL10-english 55.2±23.7 46.3±31.6 56.1±29.1 57.7±19.8 84.6±9.6 60.0±14.4
24Table9: mT5modelsfinetunedonthreedifferentinstructionstyleconfigurations.
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Small1-english 30.2±20.4 39.4±25.1 35.0±24.3 18.3±24.2 37.8±24.4 32.2±8.5
Small10-english 50.8±3.1 38.4±25.7 33.8±23.6 17.9±23.9 36.0±23.0 35.4±11.8
Small10-multi 46.5±13.4 39.4±25.1 33.4±23.5 18.2±24.2 36.9±23.5 34.9±10.5
Base1-english 53.4±5.7 37.5±23.8 34.7±23.7 26.3±23.7 44.3±20.0 39.2±10.2
Base10-english 52.4±5.1 37.3±23.6 38.0±17.9 21.8±23.0 41.5±20.5 38.2±11.0
Base10-multi 51.3±3.2 38.0±24.1 34.4±22.7 29.6±21.2 41.7±18.1 39.0±8.2
XL1-english 51.7±3.4 38.0±24.1 36.9±18.1 36.3±21.7 50.9±8.9 42.7±7.8
XL10-english 43.6±16.5 38.0±24.1 36.9±18.1 30.9±20.0 45.6±13.8 39.0±5.8
XL10-multi 51.2±3.3 38.0±24.1 36.9±18.1 31.1±25.4 54.8±12.9 42.4±10.1
Table10: Flan-T5Smallmodelswithdifferentdomainadaptationstrategies(amountofIFTdata
duringcontinuedpretraining).
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Baseline 0.3±0.7 30.4±20.3 39.8±20.8 28.2±21.6 27.7±21.9 25.3±13.2
IFT 25.0±22.0 38.1±25.4 43.0±17.1 36.1±26.5 32.6±24.2 34.9±6.0
1-IFT-to-200-PRE+IFT10K 50.6±4.2 38.2±25.6 44.3±15.6 33.8±23.3 33.7±23.8 40.1±6.5
1-IFT-to-200-PRE+IFT20K 50.8±2.2 37.9±25.3 44.4±15.7 35.5±25.1 31.9±24.0 40.1±6.7
1-IFT-to-200-PRE+IFT30K 42.2±16.2 37.3±24.9 39.8±19.4 34.3±23.7 32.4±23.5 37.2±3.6
1-IFT-to-200-PRE+IFT40K 45.8±10.8 37.7±25.2 39.7±20.8 35.1±24.4 33.4±24.0 38.3±4.3
1-IFT-to-200-PRE+IFT50K 47.0±8.8 37.4±24.9 38.9±20.7 35.6±24.6 34.1±21.0 38.6±4.5
1-IFT-to-200-PRE+IFT60K 50.0±0.4 37.1±24.7 39.3±18.7 34.7±23.3 33.8±21.7 39.0±5.8
1-IFT-to-200-PRE+IFT70K 41.4±16.9 38.4±25.6 38.8±21.1 34.0±22.7 33.8±22.9 37.3±2.9
1-IFT-to-200-PRE+IFT80K 51.8±3.8 38.2±25.5 38.5±20.9 36.2±22.6 33.4±21.5 39.6±6.4
1-IFT-to-200-PRE+IFT90K 42.4±16.7 37.9±25.3 39.7±20.3 35.8±23.5 34.1±22.2 38.0±2.9
1-IFT-to-1000-PRE+IFT10K 42.3±16.1 38.1±25.4 43.9±15.0 33.6±23.8 32.7±24.5 38.1±4.5
1-IFT-to-1000-PRE+IFT20K 41.7±20.5 37.0±24.7 42.9±16.6 33.1±23.4 33.0±24.6 37.5±4.2
1-IFT-to-1000-PRE+IFT30K 49.9±0.4 37.8±25.3 40.3±17.7 34.3±24.2 32.4±23.5 38.9±6.1
1-IFT-to-1000-PRE+IFT40K 51.4±2.7 37.8±25.2 38.9±20.6 34.7±24.4 33.0±22.5 39.2±6.5
1-IFT-to-1000-PRE+IFT50K 51.6±2.7 37.7±25.2 39.8±18.4 33.7±23.3 33.8±22.4 39.3±6.6
1-IFT-to-1000-PRE+IFT60K 50.0±0.6 37.5±25.0 40.5±20.2 34.4±23.5 33.2±22.4 39.1±6.0
1-IFT-to-1000-PRE+IFT70K 50.3±1.4 37.3±24.9 43.1±17.1 34.6±24.6 33.1±22.4 39.7±6.3
1-IFT-to-1000-PRE+IFT80K 50.6±1.5 37.7±25.2 43.0±17.4 34.0±23.1 32.9±23.0 39.6±6.5
1-IFT-to-1000-PRE+IFT90K 51.6±2.6 37.0±24.7 40.2±19.2 34.4±24.8 32.9±21.4 39.2±6.7
1-IFT-to-10000-PRE+IFT10K 46.0±12.1 38.0±25.4 44.4±15.5 33.5±23.3 33.8±24.3 39.1±5.2
1-IFT-to-10000-PRE+IFT20K 50.5±1.4 37.9±25.3 44.3±15.4 34.9±25.2 32.1±24.0 39.9±6.7
1-IFT-to-10000-PRE+IFT30K 51.3±4.0 38.2±25.5 40.5±18.1 33.6±23.3 34.7±26.5 39.7±6.3
1-IFT-to-10000-PRE+IFT40K 52.3±4.4 38.9±26.1 38.8±19.8 33.2±23.0 33.6±25.3 39.4±6.9
1-IFT-to-10000-PRE+IFT50K 47.3±12.3 37.6±25.1 41.5±17.2 35.1±24.4 32.8±22.2 38.8±5.1
1-IFT-to-10000-PRE+IFT60K 49.4±2.7 38.1±25.5 39.0±20.6 35.3±24.3 32.2±23.2 38.8±5.8
1-IFT-to-10000-PRE+IFT70K 49.2±13.9 37.7±25.2 42.1±16.2 33.2±23.1 33.8±24.3 39.2±5.9
1-IFT-to-10000-PRE+IFT80K 51.4±7.0 37.5±25.0 42.5±16.0 33.5±22.4 32.7±22.4 39.5±6.9
1-IFT-to-10000-PRE+IFT90K 44.1±20.2 37.5±25.0 43.0±16.4 33.6±22.3 33.0±21.9 38.2±4.6
ONLY-PRE+IFT10K 51.1±3.1 37.9±25.3 44.9±16.9 33.8±23.6 34.6±24.7 40.5±6.6
ONLY-PRE+IFT20K 51.4±4.4 38.1±25.5 43.9±14.0 34.1±25.1 33.2±25.3 40.2±6.8
ONLY-PRE+IFT30K 43.0±17.8 37.9±25.4 42.2±16.2 35.1±25.6 32.4±23.6 38.1±4.1
ONLY-PRE+IFT40K 47.1±12.5 38.4±25.6 42.5±16.6 34.9±25.0 32.9±24.5 39.2±5.1
ONLY-PRE+IFT50K 42.0±19.2 37.8±25.2 42.3±17.4 34.8±25.1 32.4±23.3 37.8±3.9
ONLY-PRE+IFT60K 50.6±2.1 37.9±25.3 43.0±16.0 35.6±25.0 32.6±22.9 39.9±6.3
ONLY-PRE+IFT70K 48.6±7.0 38.1±25.4 42.6±17.0 34.8±24.3 32.6±24.0 39.4±5.7
ONLY-PRE+IFT80K 51.2±3.4 37.5±25.0 43.7±17.2 33.2±23.1 34.0±25.7 39.9±6.7
ONLY-PRE+IFT90K 51.5±3.7 37.5±25.0 40.7±17.5 34.7±21.8 33.7±24.4 39.6±6.4
25Table 11: Flan-T5 Base models with different domain adaptation strategies (amount of IFT data
duringcontinuedpretraining).
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Baseline 44.7±12.4 18.0±23.6 20.9±24.8 28.9±21.2 37.0±21.3 29.9±9.9
IFT 50.3±2.4 38.8±25.9 40.5±15.7 49.5±19.1 45.2±22.0 44.9±4.6
1-IFT-to-200-PRE+IFT10K 50.5±3.2 37.3±24.9 40.7±16.6 47.7±17.7 49.7±20.8 45.2±5.2
1-IFT-to-200-PRE+IFT20K 50.4±2.2 37.8±25.2 40.9±14.2 48.4±15.9 46.2±24.7 44.7±4.7
1-IFT-to-200-PRE+IFT30K 49.9±2.6 37.7±25.2 41.2±14.1 45.3±16.1 48.4±20.0 44.5±4.5
1-IFT-to-200-PRE+IFT40K 49.4±4.3 37.8±25.2 40.4±15.5 47.8±17.2 49.0±20.9 44.9±4.8
1-IFT-to-200-PRE+IFT50K 51.2±3.9 37.7±25.2 41.2±12.7 45.0±16.0 49.1±20.1 44.8±4.9
1-IFT-to-200-PRE+IFT60K 50.1±0.9 37.6±25.1 45.1±13.0 44.2±16.0 45.2±18.9 44.4±4.0
1-IFT-to-200-PRE+IFT70K 51.1±2.7 37.6±25.0 43.4±13.6 45.1±15.4 46.5±21.0 44.7±4.4
1-IFT-to-200-PRE+IFT80K 50.4±2.3 37.7±25.2 42.2±15.9 45.2±15.7 44.8±22.7 44.1±4.1
1-IFT-to-200-PRE+IFT90K 51.4±3.6 37.7±25.2 41.6±14.5 42.9±19.0 43.2±21.6 43.4±4.5
1-IFT-to-1000-PRE+IFT10K 46.8±4.8 38.5±25.7 43.9±13.7 47.6±16.6 45.9±18.0 44.5±3.2
1-IFT-to-1000-PRE+IFT20K 50.1±2.0 37.8±25.2 43.2±15.0 46.7±15.9 48.2±24.9 45.2±4.3
1-IFT-to-1000-PRE+IFT30K 50.8±3.3 38.9±26.0 42.3±15.9 49.9±17.6 50.4±21.4 46.5±4.9
1-IFT-to-1000-PRE+IFT40K 50.1±0.7 38.4±25.7 45.1±12.0 46.6±16.2 48.0±21.4 45.7±4.0
1-IFT-to-1000-PRE+IFT50K 51.1±3.0 37.7±25.1 41.9±13.8 48.0±19.3 50.1±20.5 45.8±5.1
1-IFT-to-1000-PRE+IFT60K 49.9±2.3 37.7±25.1 44.2±15.7 46.1±18.3 49.7±22.1 45.5±4.5
1-IFT-to-1000-PRE+IFT70K 50.5±1.5 38.5±25.7 44.9±16.8 47.9±15.9 49.8±19.2 46.3±4.4
1-IFT-to-1000-PRE+IFT80K 50.6±2.5 37.9±25.2 42.4±16.6 48.8±19.2 48.7±22.8 45.7±4.8
1-IFT-to-1000-PRE+IFT90K 50.8±4.2 37.8±25.2 43.4±15.7 45.9±16.9 47.8±22.0 45.1±4.4
1-IFT-to-10000-PRE+IFT10K 48.8±4.1 38.1±25.4 43.6±13.4 47.4±16.4 47.7±19.6 45.1±3.9
1-IFT-to-10000-PRE+IFT20K 50.0±2.9 37.7±25.1 41.5±13.6 47.2±18.4 52.0±20.8 45.7±5.3
1-IFT-to-10000-PRE+IFT30K 50.5±4.6 38.4±25.6 44.3±14.6 48.4±17.3 51.5±20.7 46.6±4.8
1-IFT-to-10000-PRE+IFT40K 50.2±2.9 37.7±25.1 42.4±16.4 45.6±16.8 49.2±20.7 45.0±4.6
1-IFT-to-10000-PRE+IFT50K 50.3±2.0 37.4±24.9 41.8±16.2 45.8±17.7 49.3±21.7 44.9±4.8
1-IFT-to-10000-PRE+IFT60K 49.6±4.5 37.6±25.1 43.7±17.3 43.1±19.3 48.4±22.0 44.5±4.3
1-IFT-to-10000-PRE+IFT70K 49.6±2.9 37.7±25.1 46.4±16.0 46.9±18.7 50.5±22.2 46.2±4.5
1-IFT-to-10000-PRE+IFT80K 49.7±3.0 37.7±25.2 45.1±12.2 41.1±18.4 47.7±23.7 44.2±4.3
1-IFT-to-10000-PRE+IFT90K 50.0±1.8 37.2±24.8 40.6±14.5 41.8±20.0 45.3±22.3 43.0±4.4
ONLY-PRE+IFT10K 50.7±2.7 37.2±24.8 42.0±16.3 48.0±18.6 47.6±20.8 45.1±4.9
ONLY-PRE+IFT20K 50.1±2.6 38.2±25.5 41.1±13.7 45.0±19.7 46.7±25.7 44.2±4.2
ONLY-PRE+IFT30K 50.7±3.6 38.0±25.3 43.3±15.3 44.6±19.0 48.3±21.6 45.0±4.4
ONLY-PRE+IFT40K 50.4±3.8 38.4±25.6 41.9±14.5 47.4±17.4 46.8±21.4 45.0±4.3
ONLY-PRE+IFT50K 50.6±2.5 37.5±25.0 41.1±12.8 44.5±18.6 48.2±21.6 44.4±4.7
ONLY-PRE+IFT60K 49.6±3.4 37.6±25.1 40.4±15.5 47.2±16.7 46.3±21.0 44.2±4.5
ONLY-PRE+IFT70K 50.6±1.9 38.4±25.6 41.7±13.2 46.1±18.7 45.5±21.9 44.4±4.2
ONLY-PRE+IFT80K 51.0±3.1 39.2±26.3 42.2±15.7 46.8±18.0 45.3±21.9 44.9±4.0
ONLY-PRE+IFT90K 50.5±3.8 37.4±25.0 44.3±14.7 43.2±18.1 44.4±22.5 44.0±4.1
Mean Difference to Baseline Across Categories on LegalBench Mean Difference to Baseline Across Categories on LegalBench
20.0 20.0
Issue Issue
17.5 Rule 17.5 Rule
Conclusion Conclusion
15.0 14.1 Interpretation 15.0 Interpretation 12.5 12.2 Rhetoric 12.5 12.2 13.0 Rhetoric
10.8 10.8
10.0 9.6 10.0
7.5 7.5 7.0
5.0 4.9 5.0
2.7
2.5 2.5
0.0 0.0
Issue Rule Conclusion Interpretation Rhetoric Issue Rule Conclusion Interpretation Rhetoric
LegalBench Categories LegalBench Categories
(a)DatasetOverlap (b)TaskOverlap
Figure14: DifferencetothebaselinefortheXLmodelacrosscategoriesonLegalBenchwithdataset
andtaskoverlapheldoutrespectively.
26
enilesaB
ot ecnereffiD
naeM
hcneBlageL
enilesaB
ot ecnereffiD
naeM
hcneBlageLTable12: Flan-T5XLmodelswithdifferentdomainadaptationstrategies(amountofIFTdataduring
continuedpretraining).
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Baseline 53.5±6.0 32.1±24.6 46.8±15.6 58.7±21.3 59.6±25.6 50.1±10.1
IFT 65.7±15.2 45.1±30.3 49.5±14.2 61.7±17.1 68.6±24.1 58.1±9.2
1-IFT-to-200-PRE+IFT10K 56.7±6.9 41.8±28.1 55.2±16.9 62.1±18.6 66.8±23.7 56.5±8.4
1-IFT-to-200-PRE+IFT20K 63.4±13.8 44.2±29.8 52.5±17.4 58.7±16.8 67.0±23.2 57.2±8.1
1-IFT-to-200-PRE+IFT30K 58.7±10.3 43.6±29.3 56.3±18.2 60.2±18.4 67.9±24.5 57.3±7.9
1-IFT-to-200-PRE+IFT40K 58.4±9.7 42.3±28.2 54.3±15.2 61.2±18.8 67.5±23.6 56.7±8.4
1-IFT-to-200-PRE+IFT50K 61.4±13.3 42.2±28.3 51.8±16.3 59.4±17.9 67.3±23.6 56.4±8.7
1-IFT-to-200-PRE+IFT60K 57.5±8.7 43.6±29.2 53.5±15.8 60.3±17.5 68.2±23.5 56.6±8.1
1-IFT-to-200-PRE+IFT70K 58.3±10.2 43.1±28.8 54.3±17.9 58.8±18.2 67.6±22.6 56.4±8.0
1-IFT-to-200-PRE+IFT80K 58.9±11.0 44.9±30.0 51.1±13.2 59.8±17.3 68.5±23.3 56.6±8.1
1-IFT-to-200-PRE+IFT90K 55.2±6.9 44.4±30.1 51.7±15.6 57.9±17.0 67.7±24.3 55.4±7.6
1-IFT-to-1000-PRE+IFT10K 61.3±11.8 41.8±28.0 53.4±16.1 60.9±18.8 67.0±23.1 56.9±8.7
1-IFT-to-1000-PRE+IFT20K 63.3±13.7 44.3±29.6 52.2±17.4 60.7±17.5 67.3±24.6 57.6±8.3
1-IFT-to-1000-PRE+IFT30K 58.3±9.8 43.4±29.2 54.4±17.1 61.3±20.4 70.2±25.4 57.5±8.8
1-IFT-to-1000-PRE+IFT40K 62.5±13.2 45.6±30.6 51.3±17.5 60.1±18.9 68.0±25.6 57.5±8.0
1-IFT-to-1000-PRE+IFT50K 56.8±7.5 44.7±30.2 51.5±14.5 58.9±16.9 69.7±24.9 56.3±8.3
1-IFT-to-1000-PRE+IFT60K 54.4±5.3 42.2±28.2 52.7±16.3 59.9±17.8 67.1±23.5 55.2±8.2
1-IFT-to-1000-PRE+IFT70K 59.7±10.8 44.1±29.5 54.5±17.3 59.4±17.6 67.4±23.4 57.0±7.7
1-IFT-to-1000-PRE+IFT80K 59.8±11.2 41.6±27.9 52.8±17.2 63.5±19.8 67.3±24.5 57.0±9.0
1-IFT-to-1000-PRE+IFT90K 60.3±10.6 44.3±29.7 50.5±15.4 57.3±15.9 67.3±23.1 55.9±8.0
1-IFT-to-10000-PRE+IFT10K 60.0±10.2 42.3±28.4 52.7±16.0 61.6±18.3 68.0±22.8 56.9±8.8
1-IFT-to-10000-PRE+IFT20K 59.5±11.0 42.6±28.5 52.5±15.7 61.6±18.0 68.1±25.0 56.9±8.7
1-IFT-to-10000-PRE+IFT30K 62.2±12.2 42.3±28.5 53.6±16.7 62.5±20.1 69.2±25.2 57.9±9.3
1-IFT-to-10000-PRE+IFT40K 59.7±10.1 43.6±29.2 53.1±15.9 62.6±18.9 67.6±23.1 57.3±8.3
1-IFT-to-10000-PRE+IFT50K 58.8±8.9 42.9±29.1 52.5±16.9 61.1±17.9 64.6±25.0 56.0±7.6
1-IFT-to-10000-PRE+IFT60K 55.3±5.6 42.1±28.3 52.1±16.6 59.1±19.0 66.4±23.1 55.0±8.0
1-IFT-to-10000-PRE+IFT70K 60.3±10.0 43.6±29.5 51.8±16.8 61.2±18.5 69.0±24.7 57.2±8.7
1-IFT-to-10000-PRE+IFT80K 64.7±13.9 44.4±29.9 50.8±16.9 58.4±17.1 70.4±25.8 57.8±9.3
1-IFT-to-10000-PRE+IFT90K 63.3±13.3 44.8±30.2 51.9±16.3 58.7±16.6 68.2±25.1 57.4±8.3
ONLY-PRE+IFT10K 62.8±13.6 44.3±29.8 52.0±16.7 58.9±16.2 68.2±23.9 57.2±8.3
ONLY-PRE+IFT20K 64.0±13.9 42.6±28.7 52.8±15.6 62.0±18.0 68.7±25.0 58.0±9.3
ONLY-PRE+IFT30K 52.9±15.5 42.0±28.3 51.5±16.0 62.0±18.7 67.3±24.9 55.1±8.8
ONLY-PRE+IFT40K 60.4±12.2 43.1±29.1 52.4±16.9 60.6±17.5 68.9±23.4 57.1±8.7
ONLY-PRE+IFT50K 57.4±8.5 42.6±28.8 51.6±15.3 61.2±18.1 70.0±23.8 56.5±9.2
ONLY-PRE+IFT60K 56.7±7.6 42.5±28.4 52.0±16.3 61.2±17.9 68.8±23.8 56.2±8.8
ONLY-PRE+IFT70K 57.2±8.5 42.1±28.4 51.5±17.0 60.8±18.1 70.2±24.8 56.3±9.4
ONLY-PRE+IFT80K 60.3±11.1 42.4±28.4 54.6±16.4 65.1±20.9 69.2±24.8 58.3±9.3
ONLY-PRE+IFT90K 60.3±12.0 44.4±29.8 52.3±17.1 59.8±17.8 67.8±24.4 56.9±7.9
27Table13: Flan-T5XXLmodelswithdifferentdomainadaptationstrategies(amountofIFTdata
duringcontinuedpretraining).
LLM Issue Rule Conclusion Interpretation Rhetorical LegalBench
Baseline 36.1±21.5 18.8±24.6 25.2±26.0 35.1±22.2 41.1±18.4 31.3±8.1
IFT 55.2±23.7 46.3±31.6 56.2±18.3 66.3±19.7 73.8±24.4 59.6±9.5
1-IFT-to-200-PRE+IFT10K 53.4±16.2 47.9±32.1 58.1±19.5 63.8±17.6 74.2±27.1 59.5±9.0
1-IFT-to-200-PRE+IFT20K 53.6±3.7 48.9±32.9 58.8±18.7 65.3±17.5 72.0±25.5 59.7±8.2
1-IFT-to-200-PRE+IFT30K 56.5±18.3 48.9±31.5 60.5±19.9 65.2±18.3 69.5±24.2 60.1±7.1
1-IFT-to-200-PRE+IFT40K 58.3±20.2 47.3±30.8 57.9±19.1 65.6±18.2 71.3±24.1 60.1±8.1
1-IFT-to-200-PRE+IFT50K 60.3±12.6 48.4±31.4 63.2±20.2 67.9±18.9 71.4±26.1 62.2±7.9
1-IFT-to-200-PRE+IFT60K 58.6±20.5 48.5±31.5 60.9±20.7 67.5±19.9 71.0±24.7 61.3±7.8
1-IFT-to-200-PRE+IFT70K 58.6±10.5 48.5±31.4 60.6±20.4 65.3±18.4 69.3±23.4 60.5±7.0
1-IFT-to-200-PRE+IFT80K 53.7±16.4 47.8±30.8 58.8±18.2 63.7±17.7 71.3±25.7 59.1±8.1
1-IFT-to-200-PRE+IFT90K 52.0±14.5 48.8±31.7 59.4±19.6 64.4±17.9 72.3±25.1 59.4±8.5
1-IFT-to-1000-PRE+IFT10K 41.1±24.2 45.9±30.3 58.2±18.4 65.5±20.2 68.8±25.2 55.9±10.8
1-IFT-to-1000-PRE+IFT20K 47.7±24.8 48.0±31.1 60.3±20.3 67.2±19.7 70.3±23.8 58.7±9.4
1-IFT-to-1000-PRE+IFT30K 40.3±28.4 45.5±29.6 62.3±21.1 67.8±21.1 69.3±22.6 57.0±11.9
1-IFT-to-1000-PRE+IFT40K 44.2±27.4 46.7±29.9 61.9±21.9 68.6±20.7 71.2±24.9 58.5±11.1
1-IFT-to-1000-PRE+IFT50K 49.7±25.2 49.1±33.1 55.5±19.2 68.2±19.8 71.4±24.3 58.8±9.3
1-IFT-to-1000-PRE+IFT60K 44.9±22.0 47.6±30.7 57.9±19.4 69.7±21.1 72.1±26.0 58.5±11.1
1-IFT-to-1000-PRE+IFT70K 40.6±25.0 48.1±31.2 60.5±20.0 68.2±20.5 72.5±24.4 58.0±12.0
1-IFT-to-1000-PRE+IFT80K 53.8±23.7 47.9±32.4 53.5±17.5 67.1±19.3 71.8±25.9 58.8±9.1
1-IFT-to-1000-PRE+IFT90K 47.6±23.5 47.1±30.5 60.1±18.9 65.1±24.3 70.3±23.5 58.0±9.3
1-IFT-to-10000-PRE+IFT10K 49.8±13.6 46.6±30.0 59.0±16.6 64.6±19.3 72.6±24.7 58.5±9.5
1-IFT-to-10000-PRE+IFT20K 45.2±27.4 46.3±31.2 58.8±20.1 68.1±19.0 71.7±24.1 58.0±10.9
1-IFT-to-10000-PRE+IFT30K 46.8±24.6 46.0±29.6 62.6±18.4 66.1±18.1 72.1±25.3 58.7±10.5
1-IFT-to-10000-PRE+IFT40K 56.8±24.5 46.9±30.4 59.1±19.3 68.3±21.1 72.2±26.2 60.7±8.9
1-IFT-to-10000-PRE+IFT50K 54.5±28.7 43.1±28.1 62.2±19.8 64.2±19.1 70.2±24.3 58.8±9.3
1-IFT-to-10000-PRE+IFT60K 52.0±16.0 42.0±28.7 60.3±17.4 65.7±19.6 71.3±24.7 58.2±10.3
1-IFT-to-10000-PRE+IFT70K 52.2±14.7 47.4±30.8 59.2±18.3 66.6±18.5 70.0±24.1 59.1±8.5
1-IFT-to-10000-PRE+IFT80K 56.5±18.5 44.9±28.9 59.7±17.2 65.3±17.7 72.3±25.6 59.7±9.1
1-IFT-to-10000-PRE+IFT90K 45.0±17.4 41.5±27.3 56.3±16.3 66.3±18.5 72.1±25.7 56.2±11.8
ONLY-PRE+IFT10K 49.2±24.4 47.1±30.4 62.0±20.3 66.9±20.4 71.7±25.1 59.4±9.7
ONLY-PRE+IFT20K 35.6±24.0 46.2±30.0 56.3±17.9 62.3±18.4 68.6±24.2 53.8±11.7
ONLY-PRE+IFT30K 46.3±28.4 45.7±29.3 56.1±18.5 67.7±19.9 72.1±25.6 57.6±10.8
ONLY-PRE+IFT40K 48.8±30.3 45.7±29.5 56.6±18.0 68.1±20.0 71.6±26.3 58.1±10.2
ONLY-PRE+IFT50K 47.5±24.9 47.1±30.2 53.5±16.2 67.1±19.5 71.8±25.4 57.4±10.2
ONLY-PRE+IFT60K 33.2±23.3 47.8±30.7 55.0±17.9 63.1±19.7 69.3±25.0 53.7±12.6
ONLY-PRE+IFT70K 42.7±25.9 47.2±30.5 55.9±19.4 60.7±17.5 68.0±23.8 54.9±9.1
ONLY-PRE+IFT80K 43.7±25.8 46.3±29.9 55.8±17.1 64.8±18.7 71.8±25.9 56.5±10.7
ONLY-PRE+IFT90K 55.3±16.9 45.2±28.9 60.0±17.0 64.9±20.0 69.0±24.3 58.9±8.2
28