Gaussian Copula Models for Nonignorable
Missing Data Using Auxiliary Marginal
Quantiles
Joseph Feldman1, Jerome P. Reiter1, and Daniel R. Kowal∗ 2,3
1Department of Statistical Science, Duke University
2Department of Statistics and Data Science, Cornell University
3Department of Statistics, Rice University
June 6, 2024
Abstract
We present an approach for modeling and imputation of nonignorable missing
data under Gaussian copulas. The analyst posits a set of quantiles of the marginal
distributions of the study variables, for example, reflecting information from external
datasourcesorelicitedexpertopinion. Whenthesequantilesareaccuratelyspecified,
we prove it is possible to consistently estimate the copula correlation and perform
multiple imputation in the presence of nonignorable missing data. We develop al-
gorithms for estimation and imputation that are computationally efficient, which we
evaluate in simulation studies of multiple imputation inferences. We apply the model
to analyze associations between lead exposure levels and end-of-grade test scores for
170,000 students in North Carolina. These measurements are not missing at random,
as children deemed at-risk for high lead exposure are more likely to be measured.
We construct plausible marginal quantiles for lead exposure using national statis-
tics provided by the Centers for Disease Control and Prevention. Complete cases
and missing at random analyses appear to underestimate the relationships between
certain variables and end-of-grade test scores, while multiple imputation inferences
under our model support stronger, adverse associations between lead exposure and
educational outcomes.
Keywords: Bayesian; imputation; MNAR; data integration; nonresponse
∗The findings and conclusions in this paper are those of the authors and do not necessarily represent
the views of the North Carolina Department of Health and Human Services, Division of Public Health
1
4202
nuJ
5
]EM.tats[
1v36430.6042:viXra1 Introduction
The Gaussian copula is a flexible joint distribution for multivariate data. The model
can characterize complex dependencies while also capturing non-Gaussian marginal dis-
tributions. Methodological advances have made the Gaussian copula compatible with
mixed data types (Hoff, 2007; Feldman and Kowal, 2022), increased its scalability to high-
dimensional variable sets (Murray et al., 2013), and improved its ability to capture non-
linearity and interactions (Feldman and Kowal, 2024). Because of these appealing features,
it has been deployed in numerous applications including, for example, in economics and
finance (Fan and Patton, 2014), marketing and management (Eckert and Hohberger, 2023),
and political science (Chiba et al., 2015).
The Gaussian copula can be readily implemented when data have missing values. In-
deed, researchers (e.g., Ka¨a¨rik and K¨aa¨rik, 2010; Di Lascio et al., 2015; Zhao and Udell,
2020; Hollenbach et al., 2021; Hoff, 2022; Christoffersen et al., 2023) have suggested Gaus-
sian copulas as multivariate, joint modeling engines for (multiple) imputation. Existing
methods, however, tend to assume that missingness among the study variables is missing
completely at random (MCAR) or missing at random (MAR) (Rubin, 1976). We are not
aware of methodology for itemwise nonignorable missingness with Gaussian copula models.
In this article, we develop a framework to handle nonignorable missing data in Gaussian
copula models. Our general strategy is to specify a Bayesian Gaussian copula model that
includes both the study variables and the missingness indicators, coupled with auxiliary
information on the marginal distributions of the study variables. Using this strategy, we
prove that analysts need to know only a small, arbitrary set of auxiliary marginal quan-
tiles to enable consistent estimation of the copula correlation; entire distributions are not
necessary. These results hold for a version of an additive nonignorable (AN) missingness
2mechanism (Hirano et al., 2001; Sadinle and Reiter, 2019). This mechanism allows the
reason for missingness in a variable potentially to depend on the value of the variable itself.
We develop algorithms for estimating the copula correlation that result in significant com-
putational gains relative to alternative copula models, which allows fitting to scale to data
with(moderately)largesamplesizesinreasonabletimeusingtypicalcomputationalsetups.
We also present strategies for estimating other quantiles of the marginal distributions be-
yond those in the auxiliary information. Our approach provides uncertainty quantification
for the unknown marginals, which we utilize for multiple imputation (Rubin, 1987).
We develop the methodology for settings where marginal quantiles for variables subject
to missingness are available in external data sources. For example, previewing the appli-
cation in Section 5, suppose an analysis involving health measurements suffers from nonig-
norable missingness, e.g., people likely to have unconcerning values are not measured. For
many health measurements, there exists information on marginal quantiles from national
benchmark surveys or administrative databases. We seek to use the auxiliary quantiles to
adjust for nonignorable missingness in the analysis at hand. When auxiliary quantiles are
not available or known precisely, analysts can posit different plausible marginal quantiles
and assess the sensitivity of ultimate analyses under those specifications, e.g., via multiple
imputation analyses. We note that the use of known marginal distributions for imputation
of nonignorable missing data also has been proposed for categorical data models (Pham
et al., 2018; Akande et al., 2021; Deng et al., 2013; Si et al., 2015, 2016; Tang et al., 2024),
but not for continuous and mixed variables like we do here.
We apply the methodology in data comprising health, socioeconomic, demographic
and educational measurements collected on over 170,000 North Carolina children. Among
the study variables are end-of-grade math and reading test scores and a measure of lead
3exposure, the latter of which is subject to abundant missingness that is likely nonignorable.
The state requires children at high risk of lead exposure to be measured, but not children
at low risk of lead exposure. To inform the imputation of the missing values, we leverage
marginal quantiles on lead exposure published by the Centers for Disease Control and
Prevention. Using this information, we find lead exposure apparently is more adversely
associated with test scores than suggested from complete cases or MAR analyses.
The remainder of this article is organized as follows. In Section 2, we present the
Gaussian copula model with nonignorable missing data and information on marginal dis-
tributions. Here we present two theoretical results, namely (i) that fully specified marginal
distributions provide posterior consistency of the copula correlation in the presence of non-
ignorable missingness, and (ii) a derivation that the Gaussian copula implies a version of
the AN missingness mechanism. In Section 3, we modify the copula model and develop
imputation strategies for settings where the auxiliary marginal information constitutes a
specified set of marginal quantiles. Here we present our main theorem: under the AN miss-
ingness mechanism, this limited auxiliary information still allows consistent estimation of
the copula correlation. In Section 4, we present simulations studying the effect of differing
amounts of auxiliary quantiles and repeated sampling properties of multiple imputation
inferences with the model. In Section 5, we present the analysis of the North Carolina lead
exposure data. In Section 6, we summarize and suggest research directions. Codes for all
analyses are available at https://github.com/jfeldman396/EHQL-Impute.
2 Gaussian Copula with Nonignorable Missing Data
For i = 1,...,n individuals, let y = (y ,...,y ) comprise measurements on p study
i i1 ip
variables. Let y = y : i = 1,...,n . When y contains missing values, let r = 1
{ i } ij
when y is missing, and r = 0 otherwise. Let r = r ,...,r for i = 1,...,n, and
ij ij i i1 ip
{ }
4r = r : i = 1,...,n . We refer to the study variables using Y = (Y ,...,Y ) and
i 1 p
{ }
nonresponse indicators using R = (R ,...,R ). When the missingness is nonignorable, we
1 p
require a model for the joint distribution of (y,r). To aid specification of this distribution,
we partition the data into observed and missing components, y = (yobs,ymis), where yobs =
y : r = 0;i = 1,...,n;j = 1,...,p andymis = y : r = 1;i = 1,...,n;j = 1,...,p .
ij ij ij ij
{ } { }
Then, the two principal modeling tasks are to specify the distribution of the observed data,
p(yobs,r γ) = p(yobs,ymis,r γ)dymis, (1)
| |
Z
and to impose some identifying restriction on p(ymis yobs,r,γ), also known as the extrap-
|
olation model (Linero and Daniels, 2018). Here, γ are parameters of the model for (y,r).
We accomplish these tasks via a Gaussian copula specification, which we now describe.
For each (y ,r ), let z = (z ,z ) be a 2p 1 vector of latent variables. Here,
i i i y i ri ×
z = (z ,...,z ) and z = (z ,...,z ). Let α = (0 ,α ,...,α ) be a 2p 1
y
i
i1 ip ri i(p+1) i(2p) p r1 rp
×
vector, where 0 is a vector of p zeros corresponding to z and the next p elements
p y
i
correspond to z . Let C be a 2p 2p copula correlation matrix. With generality, we let
ri θ
×
θ include parameters that generate a copula correlation; see Section 4 for the specification
in our analyses. For j = 1,...,p, let F be the marginal distribution for Y . To begin, we
j j
assume that each Y is continuous; modifications for discrete Y are introduced in Section
j j
3. To incorporate unordered categorical variables, we employ the construction in Feldman
and Kowal (2022); see the supplement for details. The data generating model is then
z N (α,C ) (2)
i 2p θ
∼
y = F 1 Φ(z ) ; r = 1 , (3)
ij j−
{
yij
}
ij z i(p+j)>0
where 1 = 1 when the expression e in its index is true and 1 = 0 otherwise. The C
e e θ
captures multivariate dependence among the study variables themselves as well as between
5studyvariablesandnonresponseindicators. Thevaluesof(α ,...,α )modelthemarginal
r1 rp
probabilitiesofmissingness. Forthestudyvariables, eachz istransformedtotheobserved
ij
data scale by applying the standard normal cumulative distribution function Φ and the
inverse of the marginal distribution function for Y . For the nonresponse indicators, each
j
z satisfies a probit data augmentation (Chib and Greenberg, 1998).
i(p+j)
For prediction or imputation under copula models with no missing or MCAR data, an-
alysts typically estimate each F from yobs using the empirical CDF (Hoff, 2007; Feldman
j
and Kowal, 2022; Zhao and Udell, 2020) or with some model (Pitt et al., 2006; Feldman
and Kowal, 2024). With nonignorable missing data, however, estimates of F p com-
{ j }j=1
puted from yobs can be biased, which in turn affects the quality of imputations of ymis.
Additionally, inference for C from (yobs,r) alone may be biased, as we show in Section 4.
θ
We address these potential problems by utilizing some source of auxiliary information
about each F . We write this auxiliary information set as and, across study variables,
j j
A
as = p . As a first step, we presume = F for all j, i.e., the full marginal
A {Aj }j=1 Aj j
distributions are known. In this case, we show that C can be consistently estimated
θ
despite the presence of nonignorable missing data (Section 2.1) and that the Gaussian
copula implies a version of an AN missingness mechanism (Section 2.2). We leverage these
results in Section 3 when comprises quantiles rather than full distributions.
A
In what follows, we include an R for each Y in the modeling. When Y is considered
j j j
MCAR or has no missing values, analysts can remove R from (2) and (3), which reduces
j
the dimension of z .
i
2.1 Results with Complete Marginals
Let z = z : i = 1,...,n and z = z : i = 1,...,n be the collections of latent
y
{
y
i }
r
{
ri
}
variables for the study variables and nonresponse indicators, respectively. For convenience,
6we partition z = (zobs,zmis) into observed and missing components corresponding to
y
(yobs,ymis). Define the set restriction (r) as the condition that z satisfies the probit
r
E
constraints in (3) for the realized r across i = 1,...,n and j = p + 1,...,2p. Because
each F is known from , the latent variable corresponding to each yobs is fixed to zobs =
j A ij ij
Φ 1 F (yobs) . Thus, by conditioning on F p , (1) becomes
− { j ij } { j }j=1
p(yobs,r C ,α, F p ) = p zobs,z (r) C ,α (4)
| θ { j }j=1 { r ∈ E | θ }
= ϕ (zobs,zmis,z ;C ,α)dz dzmis, (5)
2p r θ r
Z Zzr (r)
∈E
where ϕ is the density of a 2p-dimensional multivariate normal distribution with covari-
2p
ance C and mean α.
θ
With nonignorable missing data, typically one cannot estimate model parameters con-
sistently unless one knows the full distribution of ymis. However, as we show in Theorem
1, we need far less information when data follow a copula model: knowledge of the true
F p is sufficient information to ensure consistent estimation of the copula correlation.
{ j }j=1
For a fixed sample (yobs,r), the posterior distribution of (C ,α) with known marginals is
θ
p(C ,α yobs,r, F p ) p(zobs,z (r) C ,α)p(C ,α). (6)
θ | { j }j=1 ∝ r ∈ E | θ θ
Subsequently, we refer to the marginal posterior of C as Π (C ).
θ n θ
Theorem 1. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation
{ i i }i=1 ∼ 0 0
C and marginals F p as in (2)–(3), and p = F p . Let p(θ) be a prior with
0 { j }j=1 {Aj }j=1 { j }j=1
respect a measure that induces a prior Π over the space of all 2p 2p correlation matrices
×
C with Π(C ) > 0 for all C C. Then, for all ϵ > 0, lim Π (C ) 1 almost
θ θ n n ϵ 0
∈ →∞ {U } →
surely [Π ], where (C ) = C C : C C < ϵ and . is the Frobenius norm.
0 ϵ 0 θ 0 θ F F
U { ∈ ∥ − ∥ } ∥ ∥
The proof is in the supplement. Theorem 1 implies that the copula correlation can
be estimated consistently using the observed data (yobs,r). As a result, we can use the
7true F p and estimates of C to impute ymis from (2)–(3). Furthermore, if F p is
{ j }j=1 θ { j }j=1
not known, Theorem 1 suggests that analysts can specify different F p to enable inter-
{ j }j=1
pretable sensitivity analyses. In other words, when the specified F p is true, analysts
{ j }j=1
areassuredthatthemodelestimatestheC thataccordswiththosemarginalsconsistently.
0
2.2 Implied Additive Nonignorable Missingness Mechanism
The Gaussian copula with known margins implies a specific nonignorable missingness
mechanism, p(R = 1 yobs,ymis,C ,α, F p ). To show this, we first note that
ij | θ { j }j=1
when (Y,R) are distributed according (2)–(3), any subset of these variables also follows
a Gaussian copula (Joe, 2014). For the joint distribution of (Y,R ), let the corresponding
j
(p + 1) (p + 1) copula correlation matrix be C . This comprises the p p sub-matrix
×
∗j
×
C of C corresponding to the study variables concatenated with the (p+1) 1 column
y θ
×
vector (C ,1)t and 1 (p+1) row vector (C ,1). Here, C comprises the entries of
yrj
×
rjy yrj
C in the column for R , and C is its transpose. We have
θ j rjy
p(R = 1 yobs,ymis,C ,α, F p ) = p(R = 1 yobs,ymis,C ,α , F p ) (7)
ij | θ { j }j=1 ij | i i ∗j rj { j }j=1
= p(Z > 0 zobs,zmis,C ,α ) = 1 Φ (0), (8)
rij | i i ∗j rj − α∗ij,σ j2 ∗
where Φ is the CDF of a Gaussian distribution with mean and variance
α∗ij,σ2
∗
α = α +C C 1(zobs,zmis), σ2 = 1 C C 1C . (9)
i∗j rj rjy −y i i j∗ − rjy −y yrj
Therefore, the marginal missingness mechanism is a probit regression on (zobs,zmis).
i i
The expression for α reveals a connection to the additive nonignorable (AN) missing-
i∗j
ness mechanism. For any generic observation x = (x ,...,x ) comprising observed and
i i1 ip
missing components (xobs,xmis), the AN missingness mechanism holds for some X when
i i j
p
p(R = 1 xobs,xmis) = g β + β x , (10)
ij | i i 0 k ik
(cid:18) k=1 (cid:19)
X
8with g satisfying lim g(β ) = 0 and lim g(β ) = 1. Special cases of AN miss-
β0 0 β0 0
→−∞ →∞
ingness mechanisms include an itemwise conditionally independent nonresponse (Sadinle
and Reiter, 2017) mechanism when β = 0, and a MCAR mechanism when β = 0 for all
j k
k = 1,...,p. Common link functions g include the logistic and probit (Hirano et al., 2001).
Lemma 1 formally connects the model for R in (8) to the AN missingness mechanism
ij
in (10). Unlike the formulation in Hirano et al. (2001), the AN missingness mechanism for
the Gaussian copula model has additivity on the latent scale.
Lemma 1. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation C
{ i i }i=1 ∼ 0 0 0
and marginals F p as in (2)–(3), and p = F p . For any value of (yobs,ymis),
{ j }j=1 {Aj }j=1 { j }j=1 i i
p(R = 1 yobs,ymis,C ,α , F p ) satisfies (10) with x = z , g the probit link
ij | i i ∗j rj { j }j=1 ik ik
function in (8)–(9), β = α , and β the kth component of the vector C C 1.
0 rj k rjy −y
Ofcourse, itisgenerallyimpossibletodeterminewhetheranyspecificmissingnessmech-
anism holds in practice (Molenberghs et al., 2008). However, if additive nonignorability
on the latent scale does not hold, e.g., the true model for z includes interactions between
rj
z and other latent variables, the Gaussian copula with fixed margins may not offer re-
j
liable inferences or sensitivity analyses. Developing methods and sensitivity analyses for
nonignorable missingness that is not AN are topics for future research
3 Using Auxiliary Quantiles
In many contexts, the available information on the marginals does not comprise full
distributions. For example, analysts may have access to sets of quantiles from other data
sources but not entire distributions. Or, they may be able to elicit reasonable marginal
quantiles of F from domain experts but not necessarily an entire distribution. To incorpo-
j
rate this information within the Gaussian copula framework, we address two salient issues.
First, with incomplete knowledge of any F , the transformation between y and z is un-
j ij ij
9known, which could complicate estimation of C . Second, a small set of auxiliary quantiles
θ
for each study variable could be insufficient for imputation of ymis.
For each Y , suppose we have a finite set of m 3 non-decreasing quantiles of F .
j j j
≥
Thus, = F 1(τ1),...,F 1(τq),...,F 1(τmj) , where τq [0,1] for q = 1,...,m . We
Aj { j− j j− j j− j } j ∈ j
fix each τ1 = 0 and τmj = 1, while the remaining quantiles can differ across Y . We require
j j j
include F 1(0) and F 1(1). These bounds can be specified based on domain knowledge,
Aj j− j−
e.g., human ages cannot be negative and are generally 110. When an intermediate quan-
≤
tile is not available via external sources, it can be specified using subject-matter expertise
as part of a sensitivity analysis, as described below and in Section 5.
Even though the exact map between each y and z is unknown, does provide
ij ij j
A
partial information about z under (2)–(3). We construct a set of m 1 non-overlapping
ij j
−
intervals that partition the support of Y ,
j
q = (F 1(τq),F 1(τq+1)], q = 1,...,m 1. (11)
Ij j− j j− j j −
Each y belongs to exactly one q. Further, y q implies z (Φ 1(τq),Φ 1(τq+1)]
ij Ij ij ∈ Ij ij ∈ − j − j
under(2)–(3); thatis, ify liesinsomequantileinterval, thenz mustliebetweenthesame
ij ij
quantiles of a standard Gaussian random variable. We visualize this mapping in Figure 1.
3.1 Estimation of the Copula Correlation
The partial mapping between yobs and zobs in Figure 1 provides the basis for estimating
ij ij
the copula correlation. Using the intervals in Figure 1, define the binning function
bobs(yobs) = q yobs q. (12)
ij ij ⇐⇒ ij ∈ Ij
In what follows, we suppress the dependence of bobs(yobs) on yobs. Let bobs = bobs : r =
ij ij ij i { ij ij
0,j = 1,...,p and bobs = bobs : i = 1,...,n . The binning in (12) has the effect of
} { i }
coarsening the observed data (Heitjan and Rubin, 1991; Miller and Dunson, 2018) based
10Y j F j−1(0) F j−1(.25) F j−1(.5) F j−1(.75) F j−1(1)
-5 -2 0 3 5
1 2 3 4
Ij Ij Ij Ij
Z
j
( ,Φ 1(.25)] (Φ 1(.25),Φ 1(.5)](Φ 1(.5),Φ 1(.75)](Φ 1(.75), )
− − − − − −
−∞ ∞
Figure 1: Using the set of auxiliary information to create non-overlapping intervals
j
A
q 4 partitioning the support of Y . For y q, the auxiliary quantiles defining
{Ij}q=1 j ij ∈ Ij
this interval pre-determine the interval containing z on the latent Gaussian scale. Here,
ij
= F 1(0) = 5,F 1(0.25) = 2,F 1(0.50) = 0,F 1(0.75) = 3,F 1(1) = 5 .
Aj
{
j−
−
j−
−
j− j− j−
}
on the intervals defined by . Thus, we require a likelihood for (C ,α) using (bobs,r).
θ
A
AsevidentinFigure1, wheneverbobs = q, wemusthavezobs (Φ 1(τq),Φ 1(τq+1)]. We
ij ij ∈ − j − j
represent this restriction by defining (bobs) to be the set of zobs satisfying the condition
D
that each zobs is in the latent interval defined by corresponding bobs. By conditioning on
ij ij
rather than F p , we have
A { j }j=1
p(bobs,r C ,α, ) = p(zobs (bobs),z (r) C ,α) (13)
θ r θ
| A ∈ D ∈ E |
= p(zobs,zmis,z C ,α)dz dzobsdzmis. (14)
r θ r
|
Z Z (bobs)Zzr (r)
D ∈E
The equivalence in (13) is by construction; observing bobs implies that zobs must belong to
(bobs) conditional on . We refer to (13) as the extended quantile likelihood, abbreviated
D A
as EQL. The EQL also enables inclusion of discrete Y in the copula model, as bobs and
j
A
can be constructed from discrete support. Extensions of the EQL to incorporate unordered
categorical study variables are discussed in the supplement.
From (13), posterior inference for (C ,α) under the EQL targets
θ
p(C ,α zobs (bobs),z (r), ) p(zobs (bobs),z (r) C ,α)p(C ,α).
θ r r θ θ
| ∈ D ∈ E A ∝ ∈ D ∈ E |
(15)
11We refer to the marginal posterior distribution of C under (15) as Π (C ).
θ ∗n θ
Remarkably, even when comprises only a few marginal quantiles for each study
A
variable, it is still possible to estimate C accurately under the EQL in the presence of
θ
AN missingness as defined in Lemma 1, assuming of course that the full data distribution
is a Gaussian copula. This fact is summarized in Theorem 2. We empirically examine the
concentration of Π (C ) as a function of the number of auxiliary quantiles in Section 4.1.
∗n θ
Theorem 2. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation
{ i i }i=1 ∼ 0 0
C and marginals F p as in (2)–(3). For j = 1,...,p, suppose comprises m 3
0 { j }j=1 Aj j ≥
auxiliary quantiles of F , including F 1(0) and F 1(1). Let p(θ) be a prior with respect a
j j− j−
measure that induces a prior Π over the space of all 2p 2p correlation matrices C such
×
that Π(C ) > 0 for all C C. Then, for any neighborhood of C , lim Π (C
θ θ
∈ B
0 n
→∞
∗n θ
∈
) 1 almost surely [Π ].
0
B →
Theorem 2 provides a practically useful result when study variables have nonignorable
missing values: analysts need only specify lower/upper bounds and a single intermediate
quantile for each study variable to estimate C accurately, provided the joint distribution
θ
for (y,r) is a Gaussian copula and thus the missingness follows the AN mechanism of
Section 2.2. Though the result is asymptotic, we demonstrate empirically in Section 4.1
that under the conditions of Theorem 2, Π (C ) can concentrate rapidly with sample
∗n θ
sizes of a few hundred. Furthermore, estimation of C is possible without specifying full
θ
marginal distribution models that require parameter updates for each study variable.
A similar estimation strategy for C is employed under the extended rank (RL) and
θ
rank-probit (RPL) likelihoods (Hoff, 2007; Feldman and Kowal, 2022), which target pos-
terior inference for the Gaussian copula correlation by conditioning on the set of latent
variables consistent with the multivariate ranks on the observed variables. However, the
12Algorithm 1 Gibbs sampler for the EQL Gaussian copula
Require: prior p(C ,α), auxiliary quantiles . Let C = C .
θ θ
A
• Step 1: Sample (zobs,zmis,z ) C,α
r
|
for z zobs do
ij
∈
Sample z Normal(µ ,σ2)1(ℓ ,u ]
ij ∼ ij j ij ij
ℓ = Φ 1(τℓ), τℓ = max F 1(τq) : yobs > F 1(τq) ,
ij − ij ij { j− j ∈ Aj ij j− j }
u = Φ 1(τu), τu = min F 1(τq) : yobs F 1(τq)
ij − ij ij { j− j ∈ Aj ij ≤ j− j }
for z z do
ij r
∈
Sample z Normal(µ ,σ2)1(ℓ ,u )
ij ∼ ij j ij ij
ℓ = 0 1 , u = 0+ 1
ij
−∞
rij=1 ij
∞
rij=0
for z zmis do
ij
∈
Sample z Normal(µ ,σ2)
ij ∼ ij j
where µ = α +C C 1 (z α ) and σ2 = C C C 1 C
ij j j( −j) − −(jj) i( −j) − −j j jj − j( −j) − −(jj) ( −j)j
• Step 2: Sample C,α p(C,α zobs,zmis,z )
r
∼ |
where p(C,α zobs,zmis,z ) N ((zobs,zmis,z );C,α)p(C,α)
r 2p r
| ∝
EQL and the RL/RPL make different uses of their conditioning events. Under the EQL
event, partially locates zobs. By comparison, the RL/RPL event does not restrict where
A
zobs lies in latent space, as long as the orderings of the individual zobs are consistent with
ij
the ranks of yobs. As a result, inferences for C under AN missingness may be biased for
ij θ
the RL/RPL. We demonstrate this empirically in Section 4.1.
To estimate the model, we utilize a Gibbs sampler with data augmentation (Chib and
Greenberg, 1998), alternating sampling (zobs,zmis,z ) C ,α and C ,α (zobs,zmis,z ).
r θ θ r
| |
Algorithm 1 summarizes the two steps for an arbitrary specification of p(C ,α). We
θ
present details for the p(C ,α) used in the analyses in Section 4 and the supplement. In
θ
the algorithm, the subscript ( j) in a vector indicates that vector without the jth element
−
andinthecolumn(row)indexofamatrixindicatesexclusionoftheelementscorresponding
to the jth column (row) of that matrix. The subscript (jj) in a matrix indicates exclusion
−
of all row and column elements for the jth variable in that matrix.
Algorithm 1 offers significant computational advantages over similar samplers for RL
13Gaussian copula models. Typically, m << n, so the upper and lower truncation regions
j
in Step 1 of Algorithm 1 are shared by many observations. Consequently, the data aug-
mentation is computationally efficient: for all bobs = q, corresponding zobs may be sampled
ij ij
simultaneously using truncated normal distributions. This enables reasonable computation
times for (moderately) large n; for example, we fit the copula model to the North Carolina
data comprising nearly 170,000 children. By contrast, the computational complexity of RL
Gibbs samplers depends on the number of unique marginal ranks for each Y , which may
j
approach n. Because of these computational benefits, it can be advantageous to specify
auxiliary quantiles for Y with no or MCAR missingness, for example, by letting for
j j
A
those variables comprise a set of empirical quantiles. We note that empirical quantiles may
be biased if the missingness mechanism is not MCAR. For such Y , analysts should specify
j
a small set of auxiliary quantiles believed to closely approximate their corresponding true
quantiles and conduct sensitivity analysis to alternative specifications of .
j
A
3.2 Imputation with Limited Auxiliary Information
Given posterior samples of C and posterior predictive samples of zmis from Algorithm
θ ij
1, missing study variables may be imputed through ymis = F˜ 1(Φ 1(zmis)), where F˜ is
ij j− − ij j
an estimator of F . When contains sufficient information to outline salient features of
j j
A
˜
F , one option is to construct F via a monotone interpolating spline through the quan-
j j
tiles. This expands the support of each F beyond the quantiles in . However, when
j j
A A
comprises few quantiles, the interpolation may not accurately approximate the marginals
needed for imputation. Furthermore, this strategy does not account for the uncertainty in
the resulting estimate of F at values between the specified auxiliary quantiles. With this
j
in mind, we describe a model-based approach for estimating intermediate quantiles of Y
j
not included in . The method applies to any study variable, requires no modifications
j
A
14of the model for z, and maintains the computational benefits of the EQL.
The basic idea is to augment each with a finite, increasing set of s values, yq sj ,
Aj j { j}q=1
which we use as intermediate quantiles. Each yq is distinct from the quantiles in . We
j Aj
specify these points to be consistent with the support of Y ; for example, if Y is discrete,
j j
each yq is discrete. For Y taking on few values, yq can cover its full support. For Y
j j { j} j
taking on many unique values, using s 15 intermediate quantiles across the range of yobs
j ≈ j
suffices to provide a discrete approximation of F , which we then smooth for imputation.
j
The key step is to coarsen yobs into bins using both the quantiles in and intermediate
A
quantiles in yq sj , through which we can relate the latent variables to the binned data.
{ j}q=1
In doing so, we maintain the ordering between auxiliary and intermediate quantiles on the
latent scale. Let = yq sj , a = , and = p . Using , we construct
A∗j Aj ∪{ j}q=1 j |A∗j| A∗ {A∗j}j=1 A∗j
a 1 disjoint intervals 1,..., aj like those in (11), partitioning the support of Y at the
j − {Ij Ij } j
a points in . We then define bobs similarly to (12) but based on the a 1 intervals. The
j A∗j ij j −
interval for zobs is determined relative to the closest auxiliary quantiles in and adjacent
ij Aj
intermediate points in yq . This is illustrated in Figure 2. Using the mapping from the
{ j}
intervals to the latent variables allows us to estimate C and F (yq).
θ j j
We first formally describe the method, followed by motivation for why it works. When-
ever bobs = q (and analogously, yobs q) we have ℓ < zobs < u , where
ij ij ∈ Ij ij ij ij
ℓ = max Φ 1(τℓ),max(zobs : b = q 1);v = 1,...,n (16)
ij { − ij vj vj − }
u = min Φ 1(τu),min(zobs : b = q +1);v = 1,...,n
ij { − ij vj vj }
and τℓ,τu are defined as in Step 1 of Algorithm 1. The interval (ℓ ,u ) ensures that
ij ij ij ij
whenever bobs < bobs we have zobs < zobs,i = v. With intermediate points determined
ij vj ij vj ̸
analogously for (Y ,...,Y ), we define the quantile ordering set restriction (bobs), which
1 p ∗
D
incorporates the intermediate quantiles to encode the condition that zobs is in the interval
ij
15Y j F j−1(0) F j−1(.25) F j−1(.5) F j−1(.75) F j−1(1)
-5 -4 -3 -2 -1 0 1 2 3 4 5
1 2 3 4 5 6 7 8 9 10
Ij Ij Ij Ij Ij Ij Ij Ij Ij Ij
Z
j
?] ?] )] ?] )] ?] ?] )] ?] ]
( −
, ∞ (( ?? ,,
Φ 1 −
(.2 (5
Φ 1 −
(.25),
(?,Φ
1
−
(0
(Φ 1 −
(0), ?( ,?,
Φ 1 −
(0.7 Φ5
1 −
(0.75), (?, ∞
( (
Figure 2: Augmenting with intermediate points yq = 4, 3, 1,1,2,4 . Thus,
Aj { j} {− − − }
= 11. For y q with at least one intermediate endpoint, the unknown bounds on
|A∗j| ij ∈ Ij
the latent interval containing z are represented by the question marks.
ij
(16) corresponding to its bobs. We replace with and (bobs) with (bobs) in (13) and
ij A A∗ D D∗
(14) to estimate C . We refer to this variation as the extended hybrid quantile likelihood
θ
(EHQL). Estimating the copula correlation under the EHQL requires minor modifications
to Algorithm 1, namely replacing the truncation bounds for zobs in Step 1 with (16).
ij
The modified Algorithm 1 produces draws of each zobs. For any interval q constructed
ij Ij
using an intermediate point as an upper bound, define Zq = max zobs : bobs = q . With
j { ij ij }
enough observations having bobs = q, Algorithm 1 should generate values of zobs that cover
ij ij
much of the interval on the latent scale corresponding to q. When this is the case, we
Ij
should sample a Zq that is close to the corresponding Φ 1(F (yq)) under the copula model.
j − j j
Using each sampled Zq from Algorithm 1, for all j and q, we compute posterior draws of
j
F˜ (yq) = Φ(Zq). (17)
j j j
Thedrawsof (17)provideestimatesofuncertaintyabouttheintermediatequantiles. When
few individuals have bobs = q, which may occur for intervals constructed at quantiles in
ij
the tails, we expect higher uncertainty in the draws of F˜ (yq). This is borne out in the
j j
16Algorithm 2 Estimating F under the EHQL Gaussian copula
j
Require: and one draw of zobs from Algorithm 1
∗
Return: OA ne draw F˜ (yq) sj , j 1,...,p
{ j j }q=1 ∈ { }
for j 1,...,p do
Com∈ p{ ute Zq =} max zobs : bobs = q for each element in yq sj
j { ij ij } { j}q=1
Compute F˜ (yq) = Φ(Zq)
j j j
simulations of Section 4. Algorithm 2 summarizes the process of estimating F˜ (yq) .
{ j j }
For imputation, we interpolate between posterior samples of yq,F˜ (yq) sj and the
{ j j j }q=1
pointsin viaamonotonespline, fitusingthepackagesplinefuninR. Becausetheupper
j
A
and lower bounds of are fixed, the smoothing step is guaranteed to produce samples of
A∗j
a valid distribution function that pass through the points in . We use these versions of
A∗j
F˜ to impute each ymis at any iteration of Algorithm 1 by setting ymis = F˜ 1(Φ(zmis)).
j ij ij j− ij
Using (17) in addition to to approximate F has advantages over approximating F
j j j
A
based on the quantiles in alone, as done in the EQL. First, yq lends more informa-
Aj { j}
tion to the discrete approximation, helping the estimator better capture features of each
marginal. Second, thedrawsofΦ(Zq)in(17)propagateuncertaintyaboutF (yq)totheim-
j j j
putations, whereas the EQL interpolation of F (yq) is deterministic. For these reasons, we
j j
recommend employing the EHQL for copula estimation and Algorithm 2 for marginal CDF
estimation whenever imputation is needed. We note that Feldman and Kowal (2024) used
a strategy similar to (17) for the RL Gaussian mixture copula under MAR mechanisms.
4 Simulation Studies
In this section, we present results of simulation studies evaluating (i) the impact of
the level of detail in the marginal distributions on the quality of inferences and (ii) the
repeated sampling performance of the model as a multiple imputation engine compared to
alternative methods that do not use the auxiliary information for imputations.
In the simulations as well as the analysis of the North Carolina data in Section 5, the
17prior distribution on the parameters θ that index C is the factor model,
θ
z = α+Λη +ϵ , ϵ N (0,Σ). (18)
i i i i ∼ 2p
Here, Λ is a (2p) k matrix of factor loadings possibly with k << 2p; η is a k 1 vector
× i ×
of factors; and, Σ = diag(σ2,...,σ2 ). By specifying η N (0,I ), where I is the k k
1 2p i ∼ k k k ×
identity matrix, marginally we have z N (α,Ω), where Ω = ΛΛ⊺ +Σ is the reduced
i 2p
∼
rank covariance. Thus, θ = (Λ,Σ). Given posterior samples of Ω, samples of C are
θ
obtainedbyscalingΩintocorrelations. Theprioronthefactorloadingsprovidesshrinkage,
automating rank selection (Bhattacharya and Dunson, 2011). In addition, the components
of z are independent conditional on η , which benefits computation, especially in Step 1
i i
of Algorithm 1. The full hierarchical specification of (18) is available in the supplement.
4.1 Accuracy with Sparse Auxiliary Information
Theorem 2 provides posterior consistency for the copula correlation when each com-
j
A
prises at least m 3 ground truth quantiles. In this section, we investigate how sensitive
j
≥
the contraction of the posterior is to the cardinality of .
j
A
We simulate 2p-dimensional observations (y ,r ) n for n 200,1000,5000 and
{ i i }i=1 ∈ { }
p 5,10,20 from Gaussian copulas. For each (n,p), we randomly generate C from
0
∈ { }
a scaled inverse-Wishart distribution. Since each entry of C is non-zero, this generates
0
nonignorable missingness per Lemma 1. We vary the amount of missing data by setting
Φ(α ) 0.25,0.50 . Thus, marginally, missingness in each study variable is approxi-
rj
∈ { }
mately25%or50%. Forj p,wevaryF sothatY Gamma(1,1)whenj 1,4,7,... ;
j j
≤ ∼ ∈ { }
Y t(ν = 5,ncp = 2) when j 2,5,8,... ; and, Y Beta(1,2) when j 3,6,9,... .
j j
∼ ∈ { } ∼ ∈ { }
Here, ν andncpareadegreesoffreedomandnon-centralityparameter. Eachz forj pis
ij
≤
transformed to y via F 1(Φ(z˜ )). When z > 0, we set r = 1 and make y missing.
ij j− ij i(p+j) ij ij
We estimate the copula using Algorithm 1, incorporating three granularities of .
A
18The first includes the fully specified, true F p , referred to as “Full.” The second
{ j }j=1
is significantly more sparse, using just the lower/upper bounds and median, i.e., each
= F 1(0),F 1(0.5),F 1(1) . This is referred to as “EQL-M.” The supplement in-
Aj
{
j− j− j−
}
cludes results for variants of EQL where comprises deciles and every fourth quantile.
A
We also employ the EHQL, with each = F 1(0),F 1(0.5),F 1(1) p and s 15
Aj { j− j− j− }j=1 j ≈
intermediate quantiles. We refer to this as “EHQL-M.” The intermediate quantiles are
constructed in each simulation run by first specifying 20 evenly spaced bins over the range
of yobs and creating q based on the bins occupied by the observed data. This results in
j {Ij}
approximately 15 intermediate points in each simulation run.
We generate several datasets for each (n,p,α) setting. For each dataset and , we
A
simulate 1000 posterior samples of C . We emphasize that fitting EQL-M and EHQL-M in
θ
these datasets does not simply parrot the data generating model, as they use only a sparse
set of marginal quantiles in . We also include comparisons to the copula fit under the RL
A
of Hoff (2007), which we estimate using the sbgcop package in R. Although the RL copula
is a joint model for (y,r), it does not leverage any information beyond the observed data.
Let ρ represent the element (correlation) in row u and column v of C . Similarly, let
θ,uv θ
ρ bethecorrespondingelementintheC usedindatageneration. Figure3displays95%
0,uv 0
credible intervals based on 1000 draws of ρ ρ for the 2p(2p 1)/2 unique correlation
0,uv θ,uv
− −
coefficients for one randomly selected dataset in the p = 5 and 50% missingness scenario.
Results for other datasets and settings are qualitatively similar; see the supplement.
Theorem 2 implies that, under the EQL, ρ ρ should converge to 0 as sample
0,uv θ,uv
−
size increases. This is confirmed in Figure 3 for all versions of . The credible intervals
A
under EQL-M are slightly wider than those under Full, which suggests a loss in efficiency
with lower levels of auxiliary information. The intervals for EHQL-M are virtually indis-
19Figure 3: Plots of 95% credible intervals for ρ ρ for all unique correlations in
0,uv θ,uv
−
C using various for three sample sizes. “Full” uses full marginals; “EQL-M” uses the
0
A
lower/upper bounds and median; “EHQL-M” augments each for EQL-M with s 15
j j
A ≈
estimated intermediate quantiles. Results are presented for scenario with 50% missing
values for each of p = 5 study variables. The right-most column provides results for the
copula correlation estimated under the RL. For the larger sample sizes, posterior inference
for C under the EQL/EHQL is accurate with minor efficiency losses when incorporating
θ
fewer auxiliary quantiles. In contrast, the inferences under RL can be biased.
tinguishable from those for Full. Even though EHQL-M and EQL-M leverage the same ,
A
EHQL-M makes greater use of the information in yobs by better locating the corresponding
zobs, which improves precision. By contrast, for the two larger values of n, estimates of
C under the RL copula are significantly biased. Finally, for n = 200, the sampling vari-
θ
ability is sufficiently large that inferences for all four methods are not obviously different
qualitatively.
We run each EQL/EHQL and RL sampler for 10,000 iterations on a 2023 Macbook
Pro. When n = 5000, the EQL/EHQL samplers average around five minutes to complete,
whereas the RL sampler takes nearly four hours. Mixing is also facilitated by introducing
20Figure 4: EHQL posterior samples of F˜ (lines) compared to true F (yq) (triangles) and
j j j
empirical CDFs (crosses) computed from yobs. Columns index j = 1,2,3 from left to right.
Rows index the sample size. Each uses the lower/upper bounds and the median (dots)
∗
A
and 15 intermediate quantiles. The proposed estimator accurately outlines each true CDF
and corrects the biases in the ECDF caused by nonignorable missingness.
, with apparent convergence of the posterior of C after a few hundred samples.
θ
A
Finally, we evaluate how closely (17) under the EHQL-M approximates each true F .
j
Figure 4 displays posterior samples of F˜ (yq) for j = 1,2,3 evaluated at the specified
j j
intermediate quantile points; it also displays the empirical CDFs (ECDF) computed from
yobs. TheseECDFsexhibitvaryingdegreesofbiascausedbythenonignorablemissingdata.
In contrast, each F˜ (yq) accurately approximates the general shape of F , even though
j j j A
only includes bounds and medians. As expected, posterior uncertainty with (17) is highest
for regions with relatively small sample sizes.
4.2 Simulation of Repeated Sampling Performance
In this simulation study, we evaluate repeated sampling properties of the EHQL copula
with multiple imputation inferences. We use p = 5 variables from the North Carolina lead
exposure data displayed in Table 5, namely Economically Disadvantaged (EconDisadv),
21Mother’sAge(mAge), Mother’sRace(mRace), anindexofNeighborhoodDeprivation(NDI),
and end-of-fourth grade (EoG) standardized math test scores (Math_Score). These vari-
ables are mixed binary, unordered categorical, count, and continuous variables that have
complex univariate and multivariate features. We collect all individuals with complete
data on these five variables, excluding observations with NDI > 5 to provide stability,
| |
which we treat as a finite population comprising approximately 165,000 individuals. Using
this population, we estimate 10th, 50th, and 90th quantile regressions (Koenker, 2010) of
Math_Score on main effects of the other four variables, which we treat as population quan-
tities. The target models aim to uncover potentially heterogeneous effects of the covariates
depending on the level of academic achievement, previewing the analysis in Section 5.
We take 500 simple random samples of n = 5000 individuals from this constructed
population. In each sample, we generate nonignorable missingness in NDI. Letting j = 1
index the variable corresponding to NDI, we do so by the missingness mechanism,
p(R = 1 y) Bernoulli(Φ( 0.5 1.3yscale)), (19)
i1 | ∼ − − i1
where superscript scale indicates that the variable is centered and scaled to unit variance.
After deleting any y where r = 1, we have approximately 40% missing values of NDI,
i1 i1
with lower values more likely to be missing in the sampled data. We also randomly remove
5% of the other variables, including Math_Score. Because of the nonignorable missingness,
completecaseanalysiscouldresultinbiasedestimatesofthequantileregressioncoefficients.
As auxiliary information, we assume access to selected quantiles of NDI, which we take
from its marginal distribution in the constructed population. Here, we let include the
A
lower/upper bounds and median. The supplement includes results using the lower/upper
bounds and 75th quantile, which are qualitatively identical to those presented here. We
implement the EHQL using 15 evenly spaced quantiles across the range of observed values
22Figure 5: Empirical coverage rates (left) and mean squared error (MSE) of multiple impu-
tation point estimates (right) for the EHQL copula and MICE imputations in the repeated
simulation study. For the coefficients of NDI, the EHQL provides significantly lower bias
and higher coverage rates. While not shown, the average interval widths are similar.
of NDI. For the other study variables, we use the empirical deciles in the sampled data
as the quantiles in . We add a missingness indicator for NDI to the Gaussian copula
A
model. We exclude the remaining indicators, which effectively models that data for the
corresponding variables are MCAR.
We run the Gibbs sampler in Algorithm 1 for 5,000 iterations. After a conservative
burn-in of 2,500 draws, we extract interpolated CDFs for imputation using Algorithm 2,
andtakethecompleteddatainevery125thiterationtocreatem = 20multipleimputations.
We estimate the targeted quantile regressions and use the combining rules of Rubin (1987)
for point estimates and 95% confidence intervals for the quantile regression coefficients. We
also implement a default application of multiple imputation by chained equations (MICE)
based on the mice package in R (van Buuren, 2018). This does not use , although we add
A
R as a predictor for MICE. We repeat the entire procedure of sampling 5000 individuals,
1
making missing values, and obtaining multiple imputation inferences 500 times.
Figure 5 summarizes the multiple imputation inferences over the 500 runs. The infer-
encesforthecoefficientssubjecttoMCARmissingnessarereasonablysimilarforEHQLand
MICE, and generally of high quality. However, we see substantial differences among EHQL
23Figure 6: Marginal distribution of NDI in 20 completed datasets produced by EHQL and
MICE. The EHQL imputations capture the bi-modality and skewness of the population
marginal, whereas the MICE imputations mimic the distribution of the observed values.
and MICE coefficient estimates for NDI. These coefficients are accurately estimated with
close to nominal coverage rates under EHQL, but not MICE. Evidently, the incorporation
of and the flexible dependence structure under the copula model allow the imputations
A
to reflect the multivariate relationships more accurately than MICE does. The advantage
of EHQL relative to MICE is also evident in the imputations of NDI, which match the
population marginal for EHQL but do not for MICE. This is visualized in Figure 6.
5 Analysis of North Carolina Lead Exposure Data
Public health research in recent years has concluded overwhelmingly that lead exposure
has adverse impacts on childhood cognitive development (e.g., Bellinger et al., 1992; Mi-
randa et al., 2009; Kowal et al., 2021; Bravo et al., 2022). Many studies investigating this
topic rely on administrative health and education datasets, linked at the individual child
level, to estimate associations between lead exposure and outcomes of interest. Typically,
blood-lead measurements are available only for children who are tested for lead exposure,
andchildrenaremorelikelytobetestedwhenthereisconcernabouttheirexposure(Kamai
et al., 2022). Consequently, abundant missingness among lead measurements is common-
24Variable Name
Y¯obs/Y¯mis
Description
Blood lead 2.79/NA Blood lead level (micrograms per deciliter)
Math Score 448.9/452.5 Standardized score on first 4th grade EoG math test
Reading Score 445.2/448.5 Standardized score on first 4th grade EoG reading test
mEduc (.25,.56,.21)/ Mother’s education at the time of birth
(.10,.48,.42) (No degree, High school degree, College degree)
mRace (.57,.31,.12)/ Mother’s race/ethnicity
(.76,.19,.05) (Non-Hispanic (NH) White, NH Black, Hispanic)
BWTpct 46.9/51.7 Birthweight percentile
mAge 25.9/28.7 Mother’s age at the time of birth
Gestation 38.6/38.7 Gestational period (in weeks)
Male .50/.50 Male infant (1 = Yes, 0 = No)
Smoker .15/.09 Mother smoked (1 = Yes, 0 = No)
NotMarried .46/.22 Not married at time of birth (1 = Yes, 0 = No)
EconDisadv .61/.32 Economically disadvantaged, per participation in
the Child Nutrition Lunch Program (1 = Yes, 0 = No)
RI .23/.18 Residential isolation index, at time of EoG test
NDI .10/-1.04 Neighborhood Deprivation Index, at time of EoG test
Table 1: Variables used in the analysis of the relationship between lead exposure and
EoG test scores among fourth grade children in North Carolina. Data are restricted to
children with 30–42 weeks of gestation, 0–104 weeks of age-within-cohort, mother’s age
15–44, Blood Lead 10, birth order 4, no status as an English Language Learner, and
≤ ≤
residence in North Carolina at the time of birth and the time of the EoG test. For the
quantile regressions, numeric covariates are scaled to mean 0 with 0.5 standard deviation.
place, and individuals who are measured tend to have higher levels of exposure than much
of the population. Accurate imputation of lead measurements is important in this setting,
as selection biases could influence population-level inferences on the associations between
cognitive outcomes and lead exposure (e.g., as simulated in Section 4.2).
We analyze a dataset containing information on 170,000 North Carolina children born
∼
between 2003 and 2005. The dataset is constructed by linking children’s data across three
databases comprising (i) detailed birth records, which include maternal demographics, ma-
ternal and infant health measures, and maternal obstetrics history for all documented live
births in N.C.; (ii) lead exposure surveillance records from a registry maintained by the
state of N.C., which include integer-valued blood-lead levels; and (iii) test score data from
the N.C. Education Research Data Center at Duke University, which include EoG reading
25Figure 7: Empiricaldistribution ofBlood_leadin theNorth Carolinadata andpopulation-
level quantiles published by the CDC. Also displayed are average estimated quantiles of
Blood_lead in completed datasets after EHQL imputations. We include CDC values con-
sistentwiththeyearsmostchildrenweremeasuredforleadexposure. Afterimputation, the
marginal distribution of Blood_lead more closely matches the population-level estimates.
and mathematics test scores as well as some demographic and socioeconomic information
(CEHI, 2020). Table 1 summarizes the variables we use, including their sample averages
among children with lead exposure (Blood_lead) observed or missing. Notably, 35% of the
lead measurements are missing. Other variables have missing data rates less than 0.02%.
Figure 7 displays the ECDF of Blood_lead compared to three years of annual point
estimates for the 50th, 75th, 90th, and 95th quantiles of lead exposure levels published
by the CDC (Centers for Disease Control and Prevention, 2022). Clearly, the observed
distribution does not match the population-level quantile estimates. We therefore consider
the missingness in Blood_lead as possibly missing not at random (MNAR). As we discuss
later, the EHQL copula correlation estimates suggest this missingness in fact is MNAR.
To adjust for this missingness, we seek to leverage the CDC estimates as auxiliary in-
formation for Blood_lead. However, the Blood_lead measurements in the North Carolina
dataarerecordedasintegerscorrespondingtotheintervalinwhichthechild’smeasurement
26is contained. For instance, Blood_lead=1 means that the child’s measurement was in the
interval (0,1] µg/ml. By contrast, the CDC measurements are continuous. In addition, the
CDC estimates are national, which ignores regional or state-specific effects.
We therefore use the CDC estimates to approximately locate the marginal distribution
ofBlood_leadandemployAlgorithm2toinferintermediatequantiles. AsevidentinFigure
7, the 75th quantile estimates from the three years of CDC publications are reliably around
2.0. Because of this stability, we set = F 1 (0) = 0,F 1 (0.75) =
ABlood_lead
{
B−lood_lead B−lood_lead
2,F 1 (1) = 10 . We also examine sensitivity of results when using F 1 (0.70) =
B−lood_lead
}
B−lood_lead
2 and F 1 (0.80) = 2. For the remaining numerical study variables, we use empirical
B−lood_lead
deciles for the auxiliary quantiles. This is reasonable given the scarce missingness and large
sample size. These auxiliary quantiles are not varied in the sensitivity analysis.
We use the EHQL copula with the factor model in (18) to implement multiple imputa-
tion of all missing values. We include a missingness indicator for Blood_lead but not the
other variables, which are almost completely observed. Their indicators comprise almost
all zeros and thus are not likely to to inform the imputation but would slow computation.
Consequently, theremaining studyvariables aretreated asMCAR. For each setof auxiliary
information, we estimate the EHQL copula by running Algorithm 1 for 10,000 iterations
and discarding 5,000 draws as burn-in. We use every 250th posterior sample of model pa-
rameters to create m = 20 multiple imputations. Posterior predictive checks suggest that
the model reasonably describes the observed data; these are available in the supplement.
Using the completed datasets, we estimate the 10th, 50th, and 90th quantile regressions
of math and reading scores on main effects of all the study variables, and derive point
estimates and uncertainty quantification using multiple imputation combining rules. These
quantities describe potentially heterogeneous impacts of the covariates on low, middle, and
27Figure 8: Multiple imputation inferences for coefficients of 10th quantile regression when
Blood_lead = 2 is the 75th quantile of the marginal distribution. Compared to complete
case analysis, we see sizeable differences especially for the coefficient of Blood_lead. It is
estimated to be more adversely associated with EoG math scores. MICE imputations do
not capture this difference for Blood_lead, as MICE mimics patterns in the observed data.
high-achievingstudents, whichisofinteresttopublichealthresearch(Mirandaetal.,2009).
Figure 8 summarizes the multiple imputation inferences for the 10th quantile regression
coefficients for Blood_lead, EconDisadv, NDI, and RI using Math_Score as the response.
The results are presented for F 1 (0.75) = 2; the findings are insensitive to the other
B−lood_lead
values of this auxiliary quantile. We compare these inferences to those obtained by fitting
the quantile regression models to complete case (CC) observations, which exclude any
observations with missing study variables, and to results from m = 20 multiple imputations
using a bespoke application of MICE. Results for the other auxiliary quantile specifications,
quantile regressions, and using reading scores as the response are in the supplement.
After multiple imputation, we see sizeable shifts in the inferences. The estimated asso-
ciations of Blood_lead, EconDisadv, and NDI with Math_Score are more adverse than in
the CC analysis. The association of Blood_lead with Math_Score is estimated to be sig-
nificantly stronger when using the EHQL imputations rather than the MICE imputations.
28Specifically, the point estimate for this coefficient under the EHQL is nearly two standard
errors more negative than point estimates under CC and MICE, which is a substantively
large change. The inferences under EHQL and MICE are similar for the other predictors’
coefficients, which is not unexpected as these variables have few missing values. Similar
shifts are evident in the 50th and 90th quantile regressions as well.
To illuminate the effect of the EHQL imputations further, we examine the empirical
CDF of Blood_lead obtained by averaging across the 20 completed datasets; this is dis-
played in Figure 7. Because it utilizes , the EHQL imputes values of missing Blood_lead
A
measurements that are small relative to the observed values. Simultaneously, the per-
centiles of EoG math scores are higher for students missing Blood_lead than for students
with recorded values. Consequently, imputing Blood_lead so that its completed-data dis-
tribution accords with strengthens its negative association with Math_Score. We see
A
similar strengthening of inverse associations with the other predictors except for RI, which
has estimates mostly shrunk towards zero. RI is strongly correlated to NDI, which may
help explain why its estimates attenuate. We note that a 95% credible interval for the cop-
ula correlation between Blood_lead and its missingness indicator is (-0.92,-0.91), offering
additional evidence that the missingness in lead exposure measurements is MNAR.
6 Concluding Remarks
Using auxiliary marginal quantiles offers a convenient and flexible way to handle nonig-
norable missing data in Gaussian copula models. The simulation studies suggest that using
reliable —for example, informed by external sources like national surveys or administra-
A
tive databases—can result in more accurate inferences than treating nonignorable missing
data as MCAR or MAR. In fact, under AN missingness, it is possible to estimate accurately
the copula correlation and perform well-calibrated multiple imputation even with just a few
29auxiliary quantiles on each study variable. The simulations also suggest that augmenting
with intermediate quantiles can improve the quality of inferences and imputations.
A
There are many topics worthy of future research. For example, the marginal quantiles
may be known with uncertainty, for example, estimates from a probability sample. In cases
where analysts desire a single inference, it may be possible to posit sampling distributions
for the true quantiles that can be integrated into the model specification. Additionally,
often data have survey weights. While there are methods for using auxiliary margins with
survey-weighted data for categorical data models (Akande and Reiter, 2022; Tang et al.,
2024), work is needed to develop methods for the EQL/EHQL copulas.
The North Carolina lead exposure analysis suggests that utilizing auxiliary marginal
quantiles to handle nonignorable missing data can impact empirical findings. In particu-
lar, inferences drawn from the multiple imputations based on the EHQL copula suggest
that lead exposure affects childhood cognitive development more adversely than might be
concluded from a complete case analysis. More broadly, linked data like these are com-
monly used in public health studies and full of missing values. When the missingness
may be MNAR, analysts can consider imputation strategies that leverage known marginal
quantiles of the study variables to better inform health policy and intervention strategies.
References
Akande, O., Madson, G., Hillygus, D. S., and Reiter, J. P. (2021). Leveraging auxiliary
information on marginal distributions in nonignorable models for item and unit nonre-
sponse. Journal of the Royal Statistical Society Series A, 184:643–662.
Akande, O. and Reiter, J. P. (2022). Multiple imputations for nonignorable item nonre-
sponse in complex surveys using auxiliary margins. In Statistics in the Public Interest:
In Memory of Stephen E. Fienberg, pages 289–306. Cham: Springer.
30Bellinger, D. C., Stiles, K. M., and Needleman, H. L. (1992). Low-level lead exposure,
intelligence and academic achievement: a long-term follow-up study. Pediatrics, 90:855–
861.
Bhattacharya, A. and Dunson, D. B. (2011). Sparse Bayesian infinite factor models.
Biometrika, 98:291–306.
Bravo, M. A., Zephyr, D., Kowal, D., Ensor, K., and Miranda, M. L. (2022). Racial
residentialsegregationshapestherelationshipbetweenearlychildhoodleadexposureand
fourth-grade standardized test scores. Proceedings of the National Academy of Sciences,
119:e2117868119.
CEHI (2020). Linked births, lead surveillance, grade 4 end-of-grade scores [data set].
Centers for Disease Control and Prevention (2022). CDC Exposure Report Data Tables.
https://www.cdc.gov/exposurereport/data_tables.html.
Chib, S. and Greenberg, E. (1998). Analysis of multivariate probit models. Biometrika,
85:347–361.
Chiba, D., Martin, L. W., and Stevenson, R. T. (2015). A copula approach to the problem
of selection bias in models of government survival. Political Analysis, 23:42––58.
Christoffersen, B., Genz, A., Bretz, F., and Hothorn, T. (2023). mdgc: Missing data
imputation using Gaussian copulas. R package version 0.1.7.
Deng, Y., Hillygus, D. S., Reiter, J. P., Si, Y., and Zheng, S. (2013). Handling attrition in
longitudinal studies: The case for refreshment samples. Statistical Science, 28:238–256.
Di Lascio, F., Giannerini, S., and Reale, A. (2015). Exploring copulas for the imputation
of complex dependent data. Statistical Methods and Application, 24:159––175.
31Eckert, C. and Hohberger, J. (2023). Addressing endogeneity without instrumental vari-
ables: An evaluation of the Gaussian copula approach for management research. Journal
of Management, 49:1460–1495.
Fan, Y. and Patton, A. J. (2014). Copulas in econometrics. Annual Review of Economics,
6:179–200.
Feldman, J. and Kowal, D. R. (2022). Bayesian data synthesis and the utility-risk trade-off
for mixed epidemiological data. The Annals of Applied Statistics, 16:2577–2602.
Feldman, J. and Kowal, D. R. (2024). Nonparametric copula models for multivariate,
mixed, and missing data. Journal of Machine Learning Research, 25(164):1–50.
Heitjan, D. F. and Rubin, D. B. (1991). Ignorability and coarse data. The Annals of
Statistics, 49:2244–2253.
Hirano, K., Imbens, G. W., Ridder, G., and Rubin, D. B. (2001). Combining panel data
sets with attrition and refreshment samples. Econometrica, 69:1645–1659.
Hoff, P. D. (2007). Extending the rank likelihood for semiparametric copula estimation.
The Annals of Applied Statistics, 1:265–283.
Hoff, P. D. (2022). sbgcop: Semiparametric Bayesian Gaussian copula estimation and
imputation. R package version 0.980.
Hollenbach, F. M., Bojinov, I., Minhas, S., Metternich, N. W., Ward, M. D., and Volfovsky,
A.(2021). MultipleimputationusingGaussiancopulas. Sociological Methods & Research,
50:1259–1283.
Joe, H. (2014). Dependence Modeling with Copulas. Chapman & Hall/CRC Press.
32Ka¨¨arik, M. and K¨aa¨rik, E. (2010). Imputation by Gaussian copula model with an appli-
cation to incomplete customer satisfaction data. In Lechevallier, Y. and Saporta, G.,
editors, Proceedings of COMPSTAT’2010, pages 485–492. Physica-Verlag HD.
Kamai, E. M., Daniels, J. L., Delamater, P. L., Lanphear, B. P., MacDonald Gibson, J.,
and Richardson, D. B. (2022). Patterns of children’s blood lead screening and blood lead
levels in North Carolina, 2011–2018 — who is tested, who is missed? Environmental
Health Perspectives, 130:067002.
Koenker, R. (2010). Quantile Regression. Cambridge University Press.
Kowal, D. R., Bravo, M., Leong, H., Bui, A., Griffin, R. J., Ensor, K. B., and Miranda,
M. L. (2021). Bayesian variable selection for understanding mixtures in environmental
exposures. Statistics in Medicine, 40:4850–4871.
Linero, A. R. and Daniels, M. J. (2018). Bayesian approaches for missing not at random
outcome data: the role of identifying restrictions. Statistical Science, 33:198–213.
Miller, J. W. and Dunson, D. B. (2018). Robust Bayesian inference via coarsening. Journal
of the American Statistical Association, 114:1113–1125.
Miranda, M. L., Kim, D., Reiter, J. P., Overstreet Galeano, M. A., and Maxson, P. (2009).
Environmental contributors to the achievement gap. Neurotoxicology, 30:1019–1024.
Molenberghs, G., Beunckens, C., Sotto, C., and Kenward, M. G. (2008). Every missingness
not at random model has a missingness at random counterpart with equal fit. Journal
of the Royal Statistical Society, Series B, 70:371–378.
Murray, J. S., Dunson, D. B., Carin, L., and Lucas, J. E. (2013). Bayesian Gaussian
33copula factor models for mixed data. Journal of the American Statistical Association,
108:656–665.
Pham, T. M., Carpenter, J. R., Morris, T. P., Wood, A. M., and Petersen, I. (2018).
Population-calibrated multiple imputation for a binary/categorical covariate in categor-
ical regression models. Statistics in Medicine, 38:792–808.
Pitt, M., Chan, D., and Kohn, R. (2006). Efficient Bayesian inference for Gaussian copula
regression models. Biometrika, 93(3):537–554.
Rubin, D. B. (1976). Inference and missing data. Biometrika, 63:581––592.
Rubin, D. B. (1987). Multiple Imputation for Nonresponse in Surveys. New York: John
Wiley.
Sadinle, M. and Reiter, J. P. (2017). Itemwise conditionally independent nonresponse
modelling for incomplete multivariate data. Biometrika, 104:207–220.
Sadinle, M. and Reiter, J. P. (2019). Sequentially additive nonignorable missing data
modelling using auxiliary marginal information. Biometrika, 106:889–911.
Si, Y., Reiter, J. P., and Hillygus, D. S. (2015). Semi-parametric selection models for
potentially non-ignorable attrition in panel studies with refreshment samples. Political
Analysis, 23:92–112.
Si, Y., Reiter, J. P., and Hillygus, D. S. (2016). Bayesian latent pattern mixture models
for handling attrition in panel studies with refreshment samples. Annals of Applied
Statistics, 10:118–143.
Tang, J., Hillygus, D. S., and Reiter, J. P. (2024). Using auxiliary marginal distributions
34in imputations for nonresponse while accounting for survey weights, with application to
estimating voter turnout. Journal of Survey Statistics and Methodology, 12:155–182.
van Buuren, S. (2018). Flexible Imputation of Missing Data. Chapman & Hall/CRC Press.
Zhao, Y. and Udell, M. (2020). Missing value imputation for mixed data via Gaussian
copula. InProceedingsof the26th ACMSIGKDDInternational ConferenceonKnowledge
Discovery & Data Mining, pages 636–646.
35Supplement to
“Gaussian Copula Models for Nonignorable Missing Data Using
Auxiliary Marginal Quantiles”
A Introduction
This document includes supplementary material to the main text. Section B outlines
the Gibbs sampler for use with full marginal specifications in . Section C includes the
A
proofs of the theorems from the main text. Section D presents the extension of the Gaussian
copula model to handle unordered categorical variables. Section E presents the full model
specification for the EQL and EHQL including the prior distributions from the factor model
described in the main text, as well as the full conditional distributions used in the Gibbs
samplers for those models. Section F presents results of additional simulations. Section G
presents additional results from the analysis of the North Carolina lead data.
B Gibbs Sampler for Full Marginal Specifications
Given a set F p of fully specified marginal distributions for the study variables, we
{ j }j=1
use Algorithm 3 to sample from the posterior distribution of (C ,α) and impute ymis. We
θ
presume the analyst uses the prior distribution described in Section 4 of the main text. In
the algorithm, the subscript ( j) in a vector denotes that vector without the jth element;
−
the subscript ( j) in the column (row) index of a matrix indicates exclusion of the elements
−
1
4202
nuJ
5
]EM.tats[
1v36430.6042:viXraAlgorithm 3 Bayesian estimation and imputation for the Gaussian copula with fixed marginals.
Require: prior p(C ,α), marginals F p . Let C =C .
θ { j }j=1 θ
• Step 1: Sample (zmis,z ) C,α
r
|
for j 1,...,2p do
iC fo zm∈ p{ ut ze µ
tij
h= en} α
j
+C
j(
−j)C− −1 (jj)(z
i( −j)
−α −j) and σ j2 =C
jj
−C
j(
−j)C− −1 (jj)C
( −j)j
ij r
∈ ℓ =0 1 , u =0+ 1
Si aj
mple− z∞
r Nj= o1 rmal(i µj
,σ2)1∞
(ℓ
,ri uj=0
)
ij ∼ ij j ij ij
if z zmis then
ij
∈
Sample z Normal(µ ,σ2)
ij ∼ ij j
• Step 2: Sample C,α p(C,α zobs,zmis,z )
r
∼ |
where p(C,α zobs,zmis,z ) N ((zobs,zmis,z );α,C)p(C,α)
r 2p r
| ∝
• Step 3: Impute y im jis =F j−1(Φ(z im jis))
corresponding to the jth column (row) of that matrix; and, the subscript (jj) in a matrix
−
indicates exclusion of all row and column elements for the jth variable in that matrix.
Algorithm 3 can be used generally when full marginal distributions are available.
C Proofs of Theorems in Main Text
In this section we present proofs of Theorem 1, Lemma 1, and Theorem 2 from the
main text. In the proofs, equations referenced by number only, e.g., (2)–(3), refer to the
corresponding equations in the main text.
Theorem 1. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation
{ i i }i=1 ∼ 0 0
C and marginals F p as in (2)–(3), and p = F p . Let p(θ) be a prior with
0 { j }j=1 {Aj }j=1 { j }j=1
respect a measure that induces a prior Π over the space of all 2p 2p correlation matrices
×
C with Π(C ) > 0 for all C C. Then, for all ϵ > 0, lim Π (C ) 1 almost
θ θ n n ϵ 0
∈ →∞ {U } →
surely [Π ], where (C ) = C C : C C < ϵ and . is Frobenius norm.
0 ϵ 0 θ 0 θ F F
U { ∈ ∥ − ∥ } ∥ ∥
Proof. Without loss of generality, suppose α = 0. Let f (C ) = n 1 n logp(zobs,z
n θ − − i=1 i ri ∈
(r );C ) computed with the n sampled draws of (yobs,r ). Here, P(r ) is the probit set
E i θ i i E i
restriction defined in the main text specific to the values of the nonresponse indicators r .
i
2Let (Zobs,Z ) represent the latent random variables for a random draw of (yobs,r) from Π .
R 0
Define f(C ) = E logp(Zobs,Z (R);C ), where the expectation is with respect
θ
−
Π0 R
∈ E
θ
to Π with known = F p and (R) is the probit set restriction corresponding to the
0 A { j }j=1 E
random draw of r. Let ϕ and ϕ represent the 2p-dimensional multivariate Gaussian
Cθ C0
densities with correlation C and C , respectively.
θ 0
The proof establishes that the following conditions from Theorem 3 in Miller (2021) hold
almost surely [Π ]:
0
1. Π (C ) > 0;
ϵ 0
{U }
2. f f pointwise on C;
n
→
3. f is convex for each n;
n
4. C R2p(2p 1);
−
⊆
5. C int(C); and
0
∈
6. f(C ) > f(C ) for all C C C .
θ 0 θ 0
∈ \
Conditions 1, 4, and 5 are satisfied directly by the theorem assumptions on the prior Π.
Condition 3 is satisfied since p(zobs,z (r );C ) is a function of the Gaussian density
i ri ∈ E i θ
which is log concave. Condition 2 is satisfied by the strong law of large numbers and since
each (y ,r ), where i = 1,...,n, is an i.i.d. sample from Π .
i i 0
To validate condition 6, we first establish the Kullback-Leibler (KL) divergence between
Πobs = p(yobs,r C , F p ) for C C and the distribution of the observed data
Cθ | θ { j }j=1 θ ∈
given the ground truth copula correlation, Πobs = p(yobs,r C , F p ). Here, the KL-
0 | 0 { j }j=1
divergence between distributions P and Q with density functions p and q, respectively, is
given by d (P,Q) = p(x)log p(x)/q(x) dx.
KL
{ }
To begin, let rg beRone of the 2p possible combinations of (R ,...,R ), with (rg) the
1 p
E
associated probit set restriction for z when r = rg. For example, for two study variables
r
consider rg = (R = 1,R = 1). For arbitrary C , we write the marginal probability p(R =
1 2 θ
3rg) = zr (rg)ϕ Cθ(z r)dz r = 0∞ 0∞ϕ Cθ(z 1,z 2)dz 1dz 2. The set restriction E(rg) implied by
∈E
the colRlection of unique missinRgnesRs patterns in rg covers a non-overlapping orthant in the p-
dimensional latent space for z . Thus, we have 2p (rg) = 2p (rg) = Rp. Illustrating
r ∪g=1E g=1E
this with the two-dimensional example above, we observe thatP
22
ϕ (z )dz =
g=1 zr (rg) Cθ r r
∈E
∞ ∞ ϕ Cθ(z r)dz r. Thus, for p-dimensional z r, we may exprPess thRe expectation of g(z r)
−∞ −∞
Rfor soRme function g as
2p
g(z )ϕ (z )dz = g(z )ϕ dz (C.1)
r Cθ r r r Cθ r
Xg=1 Zzr ∈E(rg) ZRp
Consequently,withknownmarginals,weleveragethesimplificationoftheGaussiancopula
likelihood in (4)–(5) to express d (Πobs,Πobs) as
KL 0 Cθ
2p p(yobs,rg C , F p )
d (Πobs,Πobs) = p(yobs,rg C , F p )log | 0 { j }j=1 dyobs
KL 0 Cθ | 0 { j }j=1 p(yobs,rg C , F p )
g=1 Z (cid:26) | θ { j }j=1 (cid:27)
X
(C.2)
2p
ϕ (zobs,zmis,z )
= ϕ (zobs,zmis,z )log C0 r dzobsdzmisdz (C.3)
C0 r ϕ (zobs,zmis,z ) r
Xg=1 Z Z Zzr ∈E(rg) (cid:26) Cθ r (cid:27)
ϕ (zobs,zmis,z )
= ϕ (zobs,zmis,z )log C0 r dzobsdzmisdz . (C.4)
C0 r ′ ϕ (zobs,zmis,z ) r
Z Z Z (cid:26) Cθ r (cid:27)
The equivalence between (C.2) and (C.3) arises from (4)–(5) in the main text: with the
margins known, the transformation between yobs and zobs is fixed. In addition, since
2p (rg) = Rp, we may collapse the sum into an integral which leads to the equivalence
∪g=1E
between (C.3) and (C.4).
Consequently, the KL-divergence between Πobs and Πobs when the margins are known
0 Cθ
reduces to evaluating the KL divergence between 2p-dimensional multivariate Gaussian dis-
tributions. It is well known that
1 C
d (Πobs,Πobs) = tr(C 1C ) 2p+log | θ | . (C.5)
KL 0 Cθ 2 −θ 0 − C
(cid:26) (cid:18)| 0 |(cid:19)(cid:27)
4This quantity is minimized when C = C , in which case d (Πobs,Πobs) = 0. By construc-
θ 0 KL 0 Cθ
tion, C = C also minimizes f(C ). Therefore, f(C ) > f(C ) for all C C C .
θ 0 θ θ 0 θ 0
∈ \
Lemma 1. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation C
{ i i }i=1 ∼ 0 0 0
and marginals F p as in (2)–(3), and p = F p . For any value of (yobs,ymis),
{ j }j=1 {Aj }j=1 { j }j=1 i i
p(R = 1 yobs,ymis,C ,α , F p ) satisfies (10) with x = z , g the probit link function
ij | i i ∗j rj { j }j=1 ik ik
in (8)–(9), β = α , and β the kth component of the vector C C 1.
0 rj k rjy −y
Proof. The probit restriction implies that Z > 0 when R = 1. Therefore,
Rij ij
p(R = 1 yobs,ymis,C ,α , F p ) = p(Z > 0 zmis,zobs,C ,α ) (C.6)
ij | i i ∗j rj { j }j=1 Rij | i i ∗j rj
= 1 Φ (0) (C.7)
− α∗ij,σ j2 ∗
= 1 Φ (α ). (C.8)
− 0,σ j2 ∗ i∗j
Here, we have
α = α +C C 1z (C.9)
i∗j rj rjy −y i
p p
= α + C C 1 z (C.10)
rj rjyj −ykyj ij
k=1 j=1
XX
p
= α + β z . (C.11)
rj j ij
j=1
X
Consequently, the mean of (C.8) is additive in the components of z , which implies that
i
p(R = 1 yobs,ymis,C ,α , F p ) satisfies (10) with the probit link function.
ij | i i ∗j rj { j }j=1
Theorem 2. Suppose (y ,r ) n iid Π where Π is the Gaussian copula with correlation
{ i i }i=1 ∼ 0 0
C and marginals F p as in (2)–(3). For j = 1,...,p, suppose comprises m 3
0 { j }j=1 Aj j ≥
auxiliary quantiles of F , including F 1(0) and F 1(1). Let p(θ) be a prior with respect a
j j− j−
measure that induces a prior Π over the space of all 2p 2p correlation matrices C such that
×
5Π(C ) > 0 for all C C. Then, for any neighborhood of C , lim Π (C )
θ θ
∈ B
0 n
→∞
∗n θ
∈ B →
1 almost surely [Π ].
0
Proof. We prove this result using a variant of Doob’s theorem presented in Gu and Ghosal
(2009).
Doob’s Theorem Let X be observations whose distributions depend on a parameter θ,
i
both taking values in Polish spaces. Assume θ Π and X θ P . Let be the σ-field
i θ N
∼ | ∼ X
generated by X 1,...,X N, and
X∞
= σ( ∞
i
Xi). If there exists a
X∞
measurable function
f such that for (ω,θ) Ω Θ, θ =Sf(ω) a.e. [P Π] then the posterior is strongly
∈
∞
×
θ∞
×
consistent at θ for almost every θ [Π].
For j = 1,...,p, let B be the ordinal random variable with m 1 levels resulting from
j j
−
the coarsening of Y from the intervals in (12). Let R be the random variable corresponding
j j
to the process of nonresponse for Y . Because of Doob’s theorem, it suffices to show that, for
j
any pair of (B ,B ), (B ,R ), or (R ,R ), we can recover the true copula correlation ρ
j j j j j j 0,jj
′ ′ ′ ′
between the pair of variables by a function that is measurable with respect to the σ-field
generated by the sequence of zobs (bobs),z (r) as n .
r
{ ∈ D ∈ E } → ∞
We first note that the marginal distribution of any B is fully specified by . To see this,
j j
A
for any level q = 1,...,m 1 with B = q defined as in (12), the marginal probability is
j j
−
exactly p(B
j
= q) = p(Z
j
∈
(Φ −1(τ jq),Φ −1(τ jq+1)]) = τ jq+1 −τ jq. Furthermore, qm =j 1−1 p(B
j
=
q) = mj−1 τq+1 τq = 1, since τmj = 1 and mj−1 τq+1 τq is a telescopingPseries. Thus,
q=1 j − j j q=1 j − j
prPovides the entire marginal distribution fuPnction of B .
j j
A
We next consider the joint distributions arising from the three combinations of binned
study variables and missingness indicators for any j,j = 1,...,p . The joint distribution
′
∈ { }
for (B ,B ), where j = j , can be represented by a contingency table concatenated to
j j ′
′ ̸
a m m 1 vector π = π : q = 1,...,m ;k = 1,...,m , where any π =
j j
′ ×
Bj,B
j′ {
qk j j
′}
qk
p(B = q,B = k). Similarly, we can define π = π : q = 1...,m ;k = 0,1 where
j j
′
Bj,R
j′ {
qk j
}
π = p(B = q,R = k). And, for j = j , we can define π = π : q = 0,1;k = 0,1
qk j j
′ ̸
′ Rj,R
j′ {
qk
}
6where π = p(R = q,R = k). By construction, we have that p(B = q) = p(Y q), and
qk j j ′ j j ∈ Ij
so any of the joint probabilities above involving B may be expressed in terms of Y . Since
j j
(y ,r ) n come from a Gaussian copula with correlation C , and any pair of variables also
{ i i }i=1 0
follows a Gaussian copula with sub-correlation ρ , we may express the joint distributions
0,jj
′
in terms of the data generating Gaussian copula parameters. For example,
p(B = q,B = k) = p(Y q,Y k) (C.12)
j j ′ j ∈ Ij j ′ ∈ Ij ′
=
,Φ−1(τ jq+1) Φ−1(τ jk ′+1)
ϕ(z ,z ;ρ )dz dz . (C.13)
j j 0,jj j j
′ ′ ′
ZΦ −1(τ jq) ZΦ −1(τ jk ′)
For notational convenience, we drop the subscripts from π , π , and π and let
Bj,B
j′
Bj,R
j′
Rj,R
j′
π be defined in context.
We consider three types of sequences of empirical contingency tables. For pairs (B ,B ),
j j
′
the sequence is πn with entries πn = n 1 n 1(B = q,B = k). Re-using πn for
qk − i=1 ij ij ′ qk
economy of notation, for pairs (R ,R ), thePsequence has entries πn = n 1 n 1(R =
j j ′ qk − i=1 ij
q,R = k). Finally, for pairs (B ,R ), the sequence has entries πn = n 1Pn 1(B =
ij ′ j j ′ qk − i=1 ij
q,R = k). Note that we may construct πn from the information containPed in any re-
ij
′
alization of zobs (bobs),z (r) by simply observing the counts falling into cor-
r
{ ∈ D ∈ E }
responding intervals specified by or the probit restrictions on the R . Therefore, the
j
A
σ-field generated by the sequence of πn is a sub σ-field of that generated by the sequence
of zobs (bobs),z (r) . Thus, any function that is measurable with respect to the
r
{ ∈ D ∈ E }
σ-field generated by the sequence of πn is also measurable with respect to that generated by
the sequence of zobs (bobs),z (r) . We will work exclusively with the former.
r
{ ∈ D ∈ E }
We proceed to show that for any pair of variables among B ,...,B ,R ,...,R , each
1 p 1 p
{ }
entry in πn is identified by the observed (coarsened) data. As a consequence of the model for
(y ,r ) n , we show that πn a.s. π. We then show that there exists an estimator ρˆ which
{ i i }i=1 → jj ′
maybeobtainedbyafunctionthatismeasurablewithrespecttotheσ-fieldgeneratedbythe
sequence of π . This estimator must converge to a limit, ρ , which is therefore measurable
n ∗jj
′
7with respect to the σ-field generated by the infinite sequence of π . Finally, we show that
n
ρ = ρ which concludes the proof.
∗jj
′
0,jj
′
We first consider πn constructed from (R ,R ). Since each R is always observed, it is
j j ij
′
immediately apparent through the strong law of large numbers (S.L.L.N.) that πn a.s. π.
→
For πn constructed using (B ,R ), we first utilize theory on the additive nonignorable
j j
′
missingness mechanism along with the identifying information for B to demonstrate that
j
πn is identified by the observed data. We have the following equivalences under the data
generating Gaussian copula.
p(B = q,R = 1) = p(B = q)p(R = 1 B = q) (C.14)
j j j j j
′ ′ |
= p(Y q)p(R = 1 Y q) (C.15)
j ∈ Ij j ′ | j ∈ Ij
= p(Z (Φ 1(τq),Φ 1(τq+1)])p(Z > 0 Z (Φ 1(τq),Φ 1(τq+1)]). (C.16)
j ∈ − j − j R j′ | j ∈ − j − j
The first term in (C.16) is known since the marginal distribution of B is fully specified
j
from . To characterize the missingness mechanism implied by the second term, we require
j
A
theory on the selection normal distribution (Arellano-Valle and Azzalini, 2006), given in
Lemma (2).
Lemma 2. Suppose (x ,x ) are jointly Gaussian such that X N (µ ,Σ ) and X
0 1 0 ∼ p 0 0 1 ∼
Σ Σ
0 01 ( ) d
N p ∗(µ 1,Σ 1) with joint covariance matrix Σ =

. Define X 0C = [X 0
|
X 0
∈
C]
Σ Σ
10 1
for
C
some p-dimensional hypercube. Then, [X
1
|
X
0
∈
C ] =d µ
0
+X
1
+ΣT 10Σ −01X( 0C) , and
we say that [X X ] SLCT-N (µ ,µ ,Σ ,Σ ,Σ , ).
1 | 0 ∈ C ∼ p,p ∗ 0 1 0 1 01 C
Setting = (Φ 1(τq),Φ 1(τq+1)] we observe from (C.16) that [Z Z ]
C − j − j R j′ | j ∈ C ∼
SLCT-N (α ,0,1,1,ρ ). This distribution satisfies the requisite properties of a link
1,1 Rj 0,jj
d
function outlined in Lemma 1. Furthermore, the construction [X X ] = µ +X +
1 0 0 1
| ∈ C
Σ ′10Σ −01X 0( C) of SLCT-N random variables demonstrates that this missingness mechanism is
additive in Z , with β = ρ . Using the equivalence between (C.14) and (C.16), to-
j 0,jj
∈ C ′
8gether with the fact that the marginal distribution of B is completely specified, by Theorem
j
1 of Sadinle and Reiter (2019) this establishes that each component of πn is identified by
the observed data. Furthermore, due to the correspondence between (B ,R ) and (Y ,R ),
j j j j
′ ′
and since (Y ,R ) are distributed according to a Gaussian copula with correlation ρ , the
j j 0,jj
′ ′
identified probability πn must converge to π generated by the true copula by the S.L.L.N.
qk qk
Applying this to each entry of the vector we have πn a.s. π for any pair (B ,R ).
j j
→ ′
For πn constructed using (B ,B ), we use similar logic as used for (B ,R ). We first
j j j j
′ ′
consider the joint probability, p(B = q,B = k,R = 1,R = 1). This may be written as
j j j j
′ ′
p(B = q,B = k,R = 1,R = 1)
j j j j
′ ′
= p(B = q,B = k)p(R = 1,R = 1 B = q,B = k). (C.17)
j j j j j j
′ ′ | ′
Ofcourse,thisdecompositionholdsforanycombinationinthesamplespaceof(B ,B ,R ,R ).
j j j j
′ ′
We can expand the joint missingness mechanism in (C.17) as
p(R = 1,R = 1 B = q,B = k)
j j j j
′ | ′
= p(R = 1 B = q,B = k)p(R = 1 B = q,B = k,R = 1) (C.18)
j j j j j j j
| ′ ′ | ′
= p(Z > 0 Z ,Z )p(Z > 0 Z ,Z ,Z > 0), (C.19)
Rj
|
j
∈ C
j
∈
C′ R
j′ |
j
∈ C
j
∈
C′ Rj
where = (Φ 1(τq),Φ 1(τq+1)] and = (Φ 1(τk),Φ 1(τk+1)]. Thus, each term in (C.19)
C − j − j C′ − j ′ − j ′
reveals an additive nonignorable missingness mechanism via SLCT-N random variables per
Lemma 2. This form defines a sequential additive nonignorable missingness mechanism for
multivariate nonignorable missing data (Sadinle and Reiter (2019), Definition 6). Since
the marginal distributions of both B and B are fully specified by and , and the
j j j j
′ A A ′
joint missingness mechanism is sequentially additive nonignorable under a SLCT-N link, the
conditions in Theorem 3 of Sadinle and Reiter (2019) are satisfied. Therefore, the joint
probabilities p(B ,B ,R ,R ), and thus the πn, are identified from the observed data. As
j j j j
′ ′
9in the (B ,R ) case, the correspondence between (B ,B ) and (Y ,Y ) coupled with the
j j j j j j
′ ′ ′
true data generating model enables application of the S.L.L.N. to conclude that πn a.s. π for
→
any pair (B ,B ).
j j
′
Finally, any πn arises from discretizing latent Gaussian variables at fixed cut-points given
by and the probit restrictions on R. Thus, the problem of estimating ρ from πn reduces
jj
A ′
to estimating the polychoric correlation coefficient (Olsson, 1979). The resulting likelihood
is a regular parametric family admitting a consistent estimator through maximum likelihood
estimation(MLE).Therefore, theMLEρˆ ofthepolychoriccorrelationcoefficientestimated
jj
′
from πn is measurable with respect the σ-field generated by the sequence of πn, and its limit
as n , denoted ρ , is measurable with respect to the σ-field generated by the infinite
→ ∞
∗jj
′
sequence of πn.
It remains to show that ρ = ρ . Suppose towards a contradiction that ρ = ρ .
∗jj
′
0,jj
′
∗jj
′ ̸
0,jj
′
For (B ,B ), by construction, the limiting polychoric correlation satisfies
j j
′
π = p(B = q,B = k ρ ) (C.20)
qk j j
′ |
∗jj
′
= p(Y q,Y k ρ ) (C.21)
j ∈ Ij j ′ ∈ Ij ′ | ∗jj ′
= p(z (Φ 1(τq),Φ 1(τq+1)],z (Φ 1(τk),Φ 1(τk+1)];ρ ) (C.22)
j ∈ − j − j j ′ ∈ − j ′ − j ′ ∗jj ′
=
Φ−1(τ jq+1) Φ−1(τ jk ′+1)
ϕ(z ,z ;ρ )dz dz (C.23)
ZΦ −1(τ jq) ZΦ −1(τ jk ′)
j j
′
∗jj
′
j j
′
=
Φ−1(τ jq+1) Φ−1(τ jk ′+1)
ϕ(z ,z ;ρ )dz dz . (C.24)
j j 0,jj j j
̸ ZΦ −1(τ jq) ZΦ −1(τ jk ′) ′ ′ ′
This is a contradiction, since under Π , π =
Φ−1(τ jq+1) Φ−1(τ jq ′′+1)
ϕ(z ,z ;ρ )dz dz . We
0 qk Φ −1(τ jq) Φ −1(τ jq ′′) j j ′ 0,jj ′ j j ′
have shown the contradiction for joint probabiRlities invoRlving (B ,B ), but this construction
j j
′
holds for combinations of (B ,R ) as well. Therefore, we conclude that ρ = ρ . Conse-
j j
′
∗jj 0,jj
′
quently, we have shown the existence of a consistent estimator of ρ which is measurable
0,jj
′
with respect to the σ-field generated by the sequence of πn .
{
}∞n=1
10D Extensions for Unordered Categorical Variables
In the main text, we present the EQL and EHQL likelihoods for mixed count and con-
tinuous variables. We now describe how to incorporate unordered categorical variables with
no missing or MCAR values. In this case, we need not include nonresponse indicators for
the unordered categorical variables in the copula model, and we do not need auxiliary in-
formation about these variables in . We took this modeling approach for the analysis of
A
the North Carolina lead exposure data. We leave to future research handling nonignorable
missing data and incorporating known marginal information about unordered categorical
variables.
We use a diagonal orthant (Johndrow et al., 2013) representation for the unordered cat-
egorical study variables. The basic idea is to model each unordered categorical Y with a
j
set of binary indicators for the levels of Y , adding a restriction that for any individual only
j
one of these indicators can equal one. Following the Gaussian copula, we include a latent
variable for each binary indicator, carrying the restriction on the set of indicators to the set
of latent variables.
Suppose we have t < p unordered categorical variables among the p study variables.
Without loss of generality, let Y ,...,Y represent these t unordered categorical study vari-
1 t
ables, and let Y ,...,Y represent the remaining study variables, which may be continuous
t+1 p
or ordinal. For j = 1,...,t, each Y takes one of c levels, which we write as 1,...,c . For
j j j
{ }
any y = c 1,...,c , we define a diagonal orthant representation that encodes a vector
ij j
∈ { }
of c binary variables, γ = (γ ,...,γ ). For any individual’s observed data, only one
j j j1 jcj
element in (γ ,...,γ ) equals one. For example, if y = 2 and c = 4, then γ = (0,1,0,0)
1 cj ij j j
for individual i. We refer to each individual’s γ as γ = (γ ,...,γ ).
j ij ij1 ijcj
InlieuofasinglelatentvariableZ forunorderedcategoricalY , weaddc latentvariables,
j j j
11(Z ,...,Z ), to the copula model corresponding to each γ ,...,γ . Thus, the copula
j1 jcj
{
j1 jcj}
model with t unordered categorical study variables includes t c +(p t) latent variables
j=1 j −
for the study variables. We refer to each individual’s vectorPof latent values for Y as z =
j ij
(z ,...,z ). Sincetheselatentvariablesmodelindicators,weusetheprobitrepresentation
ij1 ijcj
so that z > 0 when γ = 1 and z < 0 when γ = 0, for any j and c. We also add a
ijc ijc ijc ijc
restriction that only one of (z ,...,z ) for any individual can be positive. That is, for all
ij1 ijcj
individuals i and unordered categorical variables Y , we require for any c that
j
γ = 1,γ = 0 c = c = z > 0,z < 0 c = c . (D.1)
ijc ijc ′ ijc ijc ′
{ ′ ∀ ̸ } ⇒ { ′ ∀ ̸ }
ThisrepresentationavoidstheneedtoselectonelevelofY asareferencegroup. Aggregating
j
this representation across (Y ,...,Y ), the observed categorical variables must satisfy the
1 t
event
(yobs) = zobs : γ = 1 = z > 0,z < 0 c = c, j = 1,...,t . (D.2)
′ ijc ijc ijc ′
D { ⇒ ′ ∀ ̸ }
This representation is also recommended for ordinal variables with few levels (Feldman and
Kowal, 2022).
To estimate the copula model when the data are comprised of mixed continuous, ordinal,
and unordered categorical variables, we combine the EQL/EHQL event from the main text
defined over (Y ,...,Y ) with the diagonal orthant probit event in (D.2). This combined
t+1 p
event, which we write as (bobs) (yobs), is used in (13)–(14) in the main text. Poste-
∗ ′
D ∪D
rior inference for C under the factor model of Section 4 in the main text requires simple
θ
modifications to Algorithm 1 of the main text, which are outlined in Section E. As with the
specification of the model for z corresponding to the indicators for R, we add a non-zero
r
α term to the model for any indicator variable introduced into the model by the diagonal
j
orthant probit representation.
12E Model Specification and Gibbs Samplers for EQL and EHQL
E.1 Hierarchical Specification of the Factor Model
We provide a hierarchical specification of the latent factor model in Section 4 in the main
text, which is used to estimate the copula correlation matrix C . For ease of notation and
θ
to match the setting of the simulations in Section 4 of the main text, we presume each Y is
j
continuous or ordinal. Let λ be the element in the jth row and hth column of the factor
jh
loadings matrix Λ. When we include latent variables for missingness indicators for all p
study variables, so that we have 2p variables in total, the model is given by
δ Gamma(a ,1),δ (a ,1),l 2
1 1 l 2
∼ ∼ ≥
h
ξ = δ , ϕ Gamma(ν/2,ν/2)
h l jh
∼
l=1
Y
[λ ϕ ,ξ ] N(0,ϕ 1,ξ 1),η N (0,I ),α N(0,1),σ 2 Inverse Gamma(a ,b )
jh | jh h ∼ −jh h− i ∼ k k j ∼ j− ∼ σ σ
z = α+Λη +ϵ , ϵ N (0,Σ).
i i i i ∼ 2p
We place a prior on each non-zero component α of α. These correspond to latent variables
j
for each R . The prior for Λ adopts the global-local shrinkage structure from Bhattacharya
j
and Dunson (2011), which encourages column-wise shrinkage for rank selection. By design,
this ordered shrinkage prior reduces sensitivity to the choice of the rank of Λ, which we
label k, provided the rank is sufficiently large. In the simulation studies, we set k = 2p to
be full-rank, although our results were not sensitive to k < 2p. We set a = 2,a = 3,ν =
1 2
3,a = 1,b = 0.3 for the simulation studies, as well as for the North Carolina data analysis.
σ σ
When the observed data include binary variables, for example, a binary Y or a set of
j
γ created by expressing multinomial variables using the diagonal orthant representation
j
from Section D, the model also should include a prior distribution on the non-zero α for
j
the latent Z corresponding to each binary variable. The α for any continuous or ordered
j j
13categorical Y remains set to zero.
j
IntheNorthCarolinadataanalysis,theGaussiancopulamodeldoesnothave2pvariables.
Rather, we use 18 latent variables corresponding to the study variables used in the modeling,
whichincludelatentvariablesforthebinaryindicatorsfortheunorderedcategoricalvariables
per Section D. We also use one nonresponse indicator for blood-lead measurements. Thus,
we have 19 latent variables in the copula model, with dimensions adjusted accordingly. We
set k = 19 for the rank of Λ.
E.2 Gibbs Sampling for the EHQL Gaussian Copula
Bayesian estimation of the EHQL Gaussian copula involves sampling from the condi-
tional distributions for the model parameters, latent variables, and marginal distributions
per Algorithm 2 of the main text. Here, we assume that the auxiliary information set in-
∗
A
cludesintermediatequantiles. Wepresentthesamplerforstudyvariablesthatincludebinary
variables, including the diagonal orthant representation of unordered categorical variables.
We do not include an R for those variables; we do include R for continuous and ordinal
j j
variables. As discussed previously, this requires adding a non-zero α for each indicator vari-
j
able with prior distribution as described in Section (E.1). Modeling unordered categorical
variables as nonignorable under the copula model is an area for future research.
As such, let p be the dimension of the combined set of study variables and missing-
∗
ness indicators, with unordered categorical variables augmented with their diagonal orthant
representation per Section D. We index the p variables with j = 1,...,p . Let k be the
∗ ∗
rank of Λ and dimension of latent factors η, which we index with h. Finally, we index the
observations with i = 1,...,n.
We present the steps in the Gibbs sampler for the EHQL. Under the EQL, only two steps
change. We describe these changes after presenting the EHQL sampler.
1. Sample the factor model parameters:
14• λ
j
− | − ∼
N k((D j−1 + σ j−2ηTη) −1ηTσ j−2(z
j
−
α j),(D j−1 + σ j−2ηTη) −1), where
D 1 = diag(ϕ ξ ,...,ϕ ξ ), z = (z ,...z )T, and η = (η ,...η )T, for j =
j− j1 1 jk k j 1j nj 1 n
1,...,p .
∗
• σ j−2
| − ∼
Gamma(a σ+n 2,b σ+1
2
n
i=1
k h=1(z
ij
−(α j+λ jhη ih))2), for j = 1,...,p ∗.
• η N (I + (ΛTΣ 1Λ) 1P ΛTΣP1(z α),(I + ΛΣ 1Λ) 1), where z =
i | − ∼ k k − − − i − k − − i
(z ,...,z ), for i = 1,...,n.
i1 ip
∗
• ϕ Gamma(ν+1,
ν+ξhλ2
jh), for j = 1,...,p , h = 1,...,k.
jh | − ∼ 2 2 ∗
• δ Gamma(a + p∗k,1+ 1 k ξ(1) p ϕ λ2 ), and for h 2.
1 | − ∼ 1 2 2 h=1 h j=1 jh jh ≥
δ h
| − ∼
Gamma(a 1+p∗(k − 2h+1),1P+ 21 k h=2ξP h(h) p j=1ϕ jlλ2 jh),whereξ h(h) = h w=h,w=hδ w,
̸
for h = 1,...,k. P P Q
2. Sample all α
j
For all j corresponding to binary study variables, missingness indicators, or diagonal
orthant expanded unordered categorical variables, we sample α from
j
• α
j | − ∼
N((nσ j−2 +1) −1σ j−2 n
i=1
k h=1(z
ij
−λ jhη ih),(nσ j−2 +1) −1).
P P
3. Sample zobs,zmis,z
r
Given the conditional independence among the components of z given η , we sample
i i
components of z corresponding to observed data points column-by-column, consistent
with the ordering induced by the EHQL. For components of z associated with missing
i
values, no ordering is imposed, and only the diagonal orthant restriction for categorical
variables is enforced.
• Missing unordered categorical/binary data: For zmis corresponding to the cth level
ijc
of categorical variable Y with c levels, we first calculate the predictive probability
j j
that ymis = c. To so, we compute the categorical probabilities for each level in Y ,
ij j
using the diagonal orthant set restriction of Section D. That is, we calculate the
probability that zmis > 0 while the components of zmis < 0 for c = c corresponding
ijc ijc ′ ̸ ′
15to the remaining levels. Explicitly, this is written
P(zmis > 0, zmis < 0 : c = c,c = 1,...,c ) (E.1)
ijc { ijc ′ ′ ̸ ′ j } | − ∝
k k
1 Φ(0; λ η ,σ2) Φ(0; λ η ,σ2).
− ct ih j c ′h ih c ′
Xh=1 c ′∈{c1, Y...,cj},c ′̸=c Xh=1
We sample ymis using these probabilities, with the resulting imputation used in
ij
the sampling of zmis under the diagonal orthant set restriction in Section D. Let
ijc
TN(µ,σ2,a,b) denote a truncated univariate normal with mean µ, variance σ2,
lower truncation a, and upper truncation b. The re-sampling step for any zmis is
ijc
given by
TN( k λ η ,σ2,0, ), ymis = c
zmis  h=1 ct ih j ∞ ij (E.2)
ijc ∼   TN(Pk h=1λ ctη ih,σ j2, −∞,0), y im jis ̸= c.
 P
If Y is binary, the pro bability is instead given by P(zmis > 0 ) = 1
j ij | − −
Φ(0; k λ η ,σ2), but the re-sampling step E.2 remains the same
h=1 jh ih j
• MissiP ng numeric data: Inthiscase, zmis issampledfromtheunrestrictedunivariate
ij
Gaussian,
k
zmis N( λ η ,σ2). (E.3)
ij | − ∼ jt ih j
h=1
X
• Observed data: For each j, sample zobs from a truncated normal, with lower and
ij
upper bounds for each observation specified by the EHQL/diagonal orthant probit
restriction:
k
zobs TN( λ η ,ℓ ,u ). (E.4)
ij | − ∼ jt ih ij ij
h=1
X
For ordinal, count, and continuous variables, the truncation limits are
ℓ
ij
= max {Φ −1(τ iℓ j),max(z vo jbs : z vo jbs
∈
Ijq −1,v = 1,...,n)
}
(E.5)
u = min Φ 1(τu),min(zobs : zobs q+1,v = 1,...,n) . (E.6)
ij { − ij vj vj ∈ Ij }
16with τℓ,τu defined as in Step 1 of Algorithm 1. For binary study variables, the
ij ij
upper and lower truncation limits are
0, yobs = 1 , yobs = 1
ℓ =  ij , u = ∞ ij (E.7)
ij ij
 
  , yobs = 0  0, yobs = 0.
−∞ ij ij
 
 
 
Similarly, for missingness indicators, the upper and lower truncation limits are
0, r = 1 , r = 1
ij ij
ℓ =  , u = ∞ (E.8)
ij ij
 
  , r ij = 0  0, r ij = 0.
−∞
 
 
 
Finally, for unordered categorical variables augmented with the diagonal orthant
representation of Section D, the upper and lower truncation limits for each compo-
nent of z are
ij
0, γ = 1 , γ = 1
ijc ijc
ℓ =  , u = ∞ (E.9)
ijc ijc
 
  , γ ijc = 0  0, γ ijc = 0.
−∞
 
4. Sample F˜    
j
For each unique yq sj , we first find Z (yq) as defined in the main text and compute
{ j}j=1 j j
F˜ (yq) = Φ Z (yq) . (E.10)
j j j { j j }
Here, Φ is the Gaussian CDF for Z under the current draw of copula parameters.
j j
˜
To estimate F across unobserved values, we fit a monotone interpolating spline to
j
[ yq sj , F˜ (yq) sj τq ℓj ] as described in Section 3.2 of the main text, and
{ j}q=1 ∪Aj { j j }q=1 ∪{ j}q=1
use this estimate to approximate F˜ (x) for x / yq .
j ′ ′ ∈ { j ∪Aj }
˜
The smoothing step in the sampling of F is needed for multiple imputation, as the trans-
j
formation ymis = F˜ 1(zmis) provides realizations across the entire support of Y .
ij j− ij j
17We now describe how to modify these steps for the EQL. The sampling of latent variables
corresponding to observed numeric (ordered discrete and continuous) variables, and specifi-
cally the lower and upper bounds in (E.5) and (E.6), are now given by τℓ = max F 1(τq)
{ j− j ∈
: y > F 1(τq) and τu = min F 1(τq) : y < F 1(τq) , since we no longer have
Aj ij j− j } { j− j ∈ Aj ij j− j }
intermediate quantile points. In addition, the interpolation step for F smooths between
j
pairs [ , τq ℓj ] since we no longer compute (E.10).
Aj { j}q=1
F Additional Simulation Results
This section includes supporting results for the some of the statements made in Section
4.1 of the main text.
F.1 Accuracy with Sparse Auxiliary Information
Fixing p = 10 study variables and the proportion of marginal missingness at 50%, we
now provide comparisons of the efficiency of posterior inference for the copula correlation by
graduallyincreasingthesetofauxiliaryquantilesincorporatedintothemodel. InFigureF.1,
weincludethesameplotsasthemaintext, augmentedwithinferenceundertheauxiliarysets
comprising every fourth quantile (i.e., = 0,0.04,0.08,...,1 ) and every decile (i.e., =
j j
A { } A
0,0.1,0.2,...,1 ). We observe small gains when increasing the number of true auxiliary
{ }
quantiles introduced for each margin. However, as the sample size increases, the gains
become practically negligible relative to using Median or MA + Median.
We also check whether the results are sensitive to the dimension of the study variables.
Figure F.2 increases the dimension of the study variables to p = 20, holding the missingness
at 50%. The results show similar patterns as Figure 3 in the main text, owing to the
scalability of the factor model used to model the latent variables. We do not include the
RL of (Hoff, 2007) in these comparisons because the computation is infeasible with our
setup when p = 20 and n > 1000. For p = 5, the RL copula sampler took nearly 4
18Figure F.1: Expanding Figure 3 in the main text to all levels of auxiliary information considered in the
simulationstudy. Minorgainsforsmallersamplesizesareobservedbyincorporatingmoreauxiliaryquantiles
intothemodelrelativetousingjustthemedian. Evenwitheveryfourthquantile,theinferencesarevirtually
indistinguishable from the MA + median method.
hours to complete for n = 5000. By contrast, with n = 5000 and p = 20 study variables,
the EQL/EHQL completed 10000 iterations in around 15 minutes on average using a 2023
Macbook Pro. The computation could be sped up with parallel computing for the sampling
of z, since the columns are conditionally independent under the factor model. We leave this
to future research.
Finally, we complete the information in Figure 4 in the main text by lowering the miss-
ingness to 25% and plotting posterior samples of the interpolated marginals obtained using
Algorithm 2 in the main text. As shown in Figure F.3, the interpolation accurately captures
notable features of each distribution function, with minor gains under less severe missing-
ness, particularly for smaller sample sizes. These findings are not sensitive to the type of F
j
or p.
19Figure F.2: Results of the simulation using p = 20 study variables. As in the main paper, the contraction
of the posterior is moderately impacted by the level of auxiliary information introduced in the model,
particularly for smaller sample sizes. This is evidenced by the interval widths for EQL-M, which are wider
than those for the other auxiliary specifications.
F.2 Simulation of Repeated Sampling Performance
In the main text, we summarise the improvement of the EHQL copula over MICE in
empirical coverage rates under the repeated sampling experiment. We mention that the
average interval widths are similar, and so the gains are not merely due to wider uncertainty
under the proposed approach. We support this claim in Figure F.4, which plots the average
confidence interval widths for the quantile regression coefficients across the experiment. The
results for the other settings considered are consistent.
InSection4.2ofthemaintext,wespecifiedthemedianastheadditionalauxiliaryquantile
for NDI to the lower and upper bounds. Here, we repeat the simulation in Section 4.2 of the
main text using the auxiliary 75th quantile for NDI in addition to lower and upper bounds.
As shown in Figure F.5, the results are consistent with what is presented in the main text.
20Figure F.3: The same comparisons as Figure 4 in the main text, but now with 25% marginal missingness.
Since there is only 25% missingness, the ECDF is less biased. Again, the interpolation strategy at interme-
diate quantile points enables accurate estimation of each marginal, which holds for each study variable.
The EHQL copula outperforms MICE on multiple imputation inferences for all quantile
regression coefficients corresponding to NDI.
We also include results from misspecifying the auxiliary quantile introduced into the
model. To do so, we set = F 1(0),F 1(0.5) + ϵ,F 1(1) , ϵ 0.5,1 . That is,
ANDI
{
− j− j−
} ∈ { }
we increasingly perturb the true median for NDI. Figure F.6 displays the results. As ex-
pected, the performance of the EHQL copula model deteriorates as the auxiliary quantiles
are increasingly biased. However, the performance still improves upon MICE for ϵ = 0.5.
G Analysis of North Carolina Data: Additional Results
In this section, we provide details on the auxiliary information from the CDC used in
, posterior predictive checks of the Gaussian copula model on the observed data, and
A
additional quantile regression inferences not presented in the main text.
21Figure F.4: Average interval widths of multiple imputation confidence intervals for the EHQL copula and
MICE. Results are presented for the auxiliary specification presented in the main text (i.e., the median
for NDI is incorporated into the copula model). The gains in empirical coverage rates under the proposed
approach are not simply due to wide confidence intervals
Figure F.5: Empirical coverage rates ( left) and average mean squared error (MSE) of multiple imputation
point estimates for the EHQL copula and MICE imputations in the repeated simulation study. Instead of
specifying the median for NDI, we use the 75th population quantile (in addition to the upper and lower
bounds) as the auxiliary information set. Both approaches perform similarly for coefficients other than NDI,
which is subject to nonignorable missingness. For this coefficient, the EHQL provides lower bias and higher
coverage rates.
G.1 Determining Auxiliary Information from CDC Estimates
As mentioned in Section 5 of the main text, we leverage published quantile estimates of
lead exposure from the CDC (Centers for Disease Control and Prevention, 2022) to specify
auxiliary quantiles on blood-lead levels. Table G.1 displays the population-level estimates
provided by the CDC. Among the children in the North Carolina data who were measured
for lead, 90% were measured between 2005 and 2009. Since they were born between 2003
and 2005, we base the auxiliary information on the published estimates between 2005 and
A
22Figure F.6: Empirical coverage rates (left column) and average mean squared error of multiple imputation
point estimates (right column) for the EHQL copula and MICE imputations in the repeated simulation
study. Here, we misspecify the auxiliary median for NDI by ϵ = 0.5 (top row) and ϵ = 1 (bottom row).
For ϵ = 0.5, the EHQL still performs better than MICE in inference for the quantile regression coefficients
of NDI. However, with extreme misspecification, the EHQL copula does not offer reliable inferences under
nonignorable missing data.
2010 for the 1-5 years old group.
We incorporate a single auxiliary quantile (besides the lower and upper bounds) for two
reasons. First, the CDC estimates are continuous, whereas the North Carolina data are
binned into intervals of exposure. For instance, observing Blood_lead = 1 implies that an
individual has a measure between (0,1] µg/ml. Second, the reported quantiles are national
estimates, whereas we use data from North Carolina.
G.2 Posterior Predictive Checks
We verify that the EHQL copula model generates predictive samples that resemble plausi-
ble realizations of the observed values in the North Carolina lead exposure data. Specifically,
we examine the joint predictive distribution of Blood_lead and the other study variables
23Figure G.1: CDC published estimates for select quantiles of lead exposure.
given that Blood_lead is observed.
Given a posterior draw of C ,α, F˜ , we can generate replicate values of yobs in
θ j
{ { }}
three steps. Let j = 1 when Y is Blood_lead. We generate the predictive latent variables
j
correspondingtoleadexposurebeingobserved,i.e.,z˜ N(α ,1)1 . Wethengenerate
r1
∼
r1 ( −∞,0)
predictive latent variables for the study variables conditional on the sampled z˜ using the
r1
distribution for z˜ z˜ . This is conditionally multivariate Gaussian with the mean varying
y
|
r1
as a function of the realized z˜ and covariance Σ derived from C . For each numeric Y ,
r1 ∗ θ j
for a hypothetical individual i we obtain y˜ = F˜ 1(Φ(z˜ )). For binary variables, sampling
ij j− ij
z˜ > 0 indicates for our hypothetical individual that y˜ = 1. For Y that is unordered
ij ij j
categorical, we generate the vector z˜ , and set Y˜ = c z˜ = max z˜ . We repeat
ij ij ijc ij
⇐⇒ { }
this process ten times per parameter draw, resulting in 50,000 posterior predictive samples.
We note here that our posterior predictive sampling of the categorical variables does not
enforce the diagonal orthant restriction of Section D as part of the latent variable generation;
rather, for any ymis, we generate its value by selecting the c corresponding to the maximum
ij
value in z : c = 1,...,c . This is done for computational convenience. To enforce it, we
ijc j
{ }
would have to decompose the joint distribution of the latent study variables into a sequence
of conditionals for each z corresponding to an unordered categorical variable. Then, we
ij
would compute the mean and variance, derive the categorical probabilities, and sample a
multinomial. The resulting categorical membership would specify the diagonal orthant set
24restriction for those variables, after which predictive latent variables could be sampled.
To compute Σ , we first partition each posterior sample of
∗
C C
y yr
C = . (G.1)
θ
 
C C
ry r
 
Then, Σ = C C C 1C .
∗ y
−
yr −r ry
Figure G.2 displays the joint predictive distribution of reading/math scores and blood-
pred
lead levels. Table 1 compares the posterior predictive means of Blood_lead (Y )
blood_lead
for each level of the binary/categorical variables in the model with their counterparts in
˜
the observed data. Table 2 compares the correlations between Y of the remaining
Blood_lead
numeric variables in the predictive samples and observed data. We see some evidence of
lack of fit for average lead levels for Hispanic children, who represent less than 10% of the
observations. Nonetheless, overall, the copula model adequately captures the associations in
the observed data. All results are for the EHQL copula with auxiliary Blood_lead quantile
F(2) = 0.75.
mRace mEduc EconDisadv Male NotMarried Smoker
(Wh./Bl./Hisp.) (No H.S., H.S., Coll.) (No/Yes) (No/Yes) (No/Yes) (No/Yes)
pred
Y 2.68/3.28/2.92 3.20/2.98/2.38 2.49/3.13 2.82/2.92 2.58/3.25 2.80/3.23
Blood_lead
obs
Y 2.65/3.16/2.59 3.07/2.84/2.31 2.46/3.02 2.74/2.85 2.58/3.05 2.75/3.07
Blood_lead
Table1: PosteriorpredictivemeansofBlood_leadcomparedtoobservedmeansbyeachlevelofthecategor-
icalandbinarystudyvariables. TheEHQLcopulamodelaccuratelycapturesthesemultivariateassociations
in the observed data.
Yj mAge NDI RI BWTpct Gestation
cor(Y ,Blood_lead)pred -0.12 0.22 0.11 -0.03 0.03
j
cor(Y ,Blood_lead)obs -0.14 0.15 0.12 -0.07 -0.001
j
Table 2: Predictive correlations compared to observed correlations between Blood_lead and the other
numeric study variables, excluding reading and math scores. The EHQL copula approximately captures
these pairwise associations in the observed data.
25FigureG.2: Observed(leftcolumn)vsposteriorpredictive(rightcolumn)distributionsofmath/readingEoG
test scores and blood-lead levels. The EHQL copula model adequately captures the bivariate associations
between the EoG test scores and lead exposure.
G.3 Complete Results for the 10th Quantile Regression
In the main paper, we present results for the 10th quantile regression coefficients for
selectedexposurevariablesusingEoGmathscoresastheresponse. Inthissectionweprovide
the multiple imputation coefficient estimates and 95% confidence intervals for the remaining
coefficients, and also include parallel results using EoG reading scores as the response. Here,
F (2) = 0.75.
Blood_lead
Figure G.3 provides the multiple imputation inferences for the remaining coefficients with
EoG math scores as the response variable. Both the EHQL and MICE provide inferences
that are notably different than complete cases (CC) analysis. Unsurprisingly, the inferences
from both approaches are very similar, as these variables are almost completely observed
and both the EHQL and MICE treat their missingness as MCAR.
Figure G.4 presents multiple imputation inferences for the 10th quantile regression for the
26FigureG.3: Multipleimputationinferencesfortheremainingcoefficientsunderthe10thquantileregression.
Here, F (2) = 0.75 and the response variable is EoG math scores. For both the EHQL and MICE,
Blood_lead
multipleimputationoffersmoreprecisionandshiftscertaincoefficientsrelativetoCCanalysis. Theinferences
between the two methods are virtually identical, owing the fact that the variables are almost completely
observed and we treat their missingness as MCAR.
four selected exposure variables presented in the main text with EoG reading test scores as
the response. Accounting for the nonignorable missingness in lead exposure measurements
still results in stronger, more adverse associations for reading test scores and lead exposure,
although the shift is not as pronounced as for math test scores. As with the quantile re-
gressions using math test scores as the dependent variable, we see little practical difference
between the EHQL and MICE results for the three coefficients that do not correspond to
Blood_lead.
Finally, Figure G.5 displays multiple imputation inferences for the remaining coefficients
with EoG reading test scores as the response. The multiple imputation inferences result in
greater precision. The EHQL and MICE offer very similar inferences—which are sometimes
quite different than the CC inferences—due to the dearth of missing values for these other
variables.
27Figure G.4: Multiple imputation inference for the remaining coefficients under the 10th quantile regression.
Here, F (2)=0.75 and the response variable is EoG reading scores. Similar to the model with EoG
Blood_lead
math scores as the response, the EHQL estimates a more strong, adverse association between lead exposure
and reading scores than both CC and MICE.
G.4 Results from Additional Quantile Regressions and Alternative Auxiliary
Quantile Specifications
In this section, we demonstrate that the quantile regression inferences are not sensitive
to the alternative auxiliary specifications considered (F (2) = 0.80,F (2) =
Blood_lead Blood_lead
0.70). We combine these with results for the quantile regressions at the 50th and 90th
quantiles,wheneitherEoGmathorreadingtestscoresistheresponsevariable. Toeconomize
on the number of figures, we present the results for all quantile regressions and auxiliary
specifications in the same plots. We again distinguish between the four selected exposure
variables and the remaining covariates.
Figures G.6 and G.7 provide results for the models with EoG math scores as the re-
sponse, and Figures G.8 and G.9 provide results for the models with EoG reading scores
as the response. Across all analyses, we see little differences in the inferences for these
different specifications of the auxiliary quantiles, suggesting the results are not sensitive to
modest perturbations of the auxiliary quantile specification. Accounting for the nonignor-
28Figure G.5: Multiple imputation inference for the remaining coefficients under the 10th quantile regression.
Here, F (2)=0.75 and the response variable is EoG reading scores. For both the EHQL and MICE,
Blood_lead
imputationoffersmoreprecisionandshiftscertaincoefficientsrelativetoCCanalysis. Theinferencesbetween
the two methods are virtually identical, owing the fact that the variables are almost completely observed
and we treat their missingness as MCAR.
able missingness in Blood_lead seems to have greater effects on the inferences for the math
regressions than for the reading regressions. The effects of lead exposure appear relatively
constant across quantiles for the math regressions, whereas they are more adverse at lower
quantiles for the reading regressions.
29Figure G.6: Multiple imputation inferences for quantile regression coefficients for the four predictors high-
lighted in the main text for all quantile regressions and auxiliary quantile settings. EoG math test score is
the response variable. We observe that inference is not sensitive to auxiliary quantile specifications for lead
exposure under the proposed approach, with sizeable shifts between complete case (CC) inference for all
coefficients across quantiles. Furthermore, for each auxiliary quantile specification and quantile regression,
Blood_lead is more adversely associated with EoG math scores than it is in both the CC and MICE infer-
ences.
30Figure G.7: Multiple imputation inferences for quantile regression coefficients for the remaining covariates
in the analysis of the North Carolina lead exposure data presented in the main text. EoG math test score
is the response variable.
31Figure G.8: Multiple imputation inferences with EoG reading test score as the response variable. Results
areforthequantileregressioncoefficientsforthefourpredictorshighlightedinthemaintextforallquantile
regressionsandauxiliaryquantilesettings. ForEoGreadingscores,theimputationsundertheEHQLcopula
suggest more heterogeneous impacts of Blood_lead across the distribution of reading scores. This includes
estimating a more adverse impact of lead for lower scoring children. By contrast, the MICE imputations
estimate the quantile regression coefficients as closer to one another.
32Figure G.9: Multiple imputation inferences with EoG reading test score as the response variable for the
remaining coefficients.
33References
Arellano-Valle, R. B. and Azzalini, A. (2006). On the unification of families of skew-normal
distributions. Scandinavian Journal of Statistics, 33:561–574.
Bhattacharya, A. and Dunson, D. B. (2011). Sparse Bayesian infinite factor models.
Biometrika, 98:291–306.
Centers for Disease Control and Prevention (2022). CDC Exposure Report Data Tables.
https://www.cdc.gov/exposurereport/data_tables.html.
Feldman, J. and Kowal, D. R. (2022). Bayesian data synthesis and the utility-risk trade-off
for mixed epidemiological data. The Annals of Applied Statistics, 16:2577–2602.
Gu, J. and Ghosal, S. (2009). Bayesian ROC curve estimation under binormality using a
rank likelihood. Journal of Statistical Planning and Inference, 139(6):2076–2083.
Hoff, P. D. (2007). Extending the rank likelihood for semiparametric copula estimation. The
Annals of Applied Statistics, 1:265–283.
Johndrow, J., Dunson, D., andLum, K.(2013). Diagonalorthantmultinomialprobitmodels.
In Artificial Intelligence and Statistics, pages 29–38. PMLR.
Miller, J. W. (2021). Asymptotic normality, concentration, and coverage of generalized
posteriors. Journal of Machine Learning Research, 22:1–53.
Olsson, U. (1979). Maximum likelihood estimation of the polychoric correlation coefficient.
Psychometrika, 44:443–460.
Sadinle, M. and Reiter, J. P. (2019). Sequentially additive nonignorable missing data mod-
elling using auxiliary marginal information. Biometrika, 106:889–911.
34