1
Task-Oriented Wireless Communications for
Collaborative Perception in
Intelligent Unmanned Systems
Sheng Zhou, Senior Member, IEEE, Yukuan Jia, Ruiqing Mao, Zhaojun Nan, Member, IEEE,
Yuxuan Sun, Member, IEEE, Zhisheng Niu, Fellow, IEEE
Abstract—Collaborative Perception (CP) has shown great po- According to the data sharing and fusion stage, CP can
tential to achieve more holistic and reliable environmental per- be categorized into three levels: raw-level, feature-level, and
ceptioninintelligentunmannedsystems(IUSs).However,imple-
object-level. In raw-level CP, agents directly exchange raw
mentingCPstillfaceskeychallengesduetothecharacteristicsof
sensor data, such as images and point clouds. While these
theCPtaskandthedynamicsofwirelesschannels.Inthisarticle,
a task-oriented wireless communication framework is proposed raw data preserve the full information for perception, they
to jointly optimize the communication scheme and the CP require extremely high communication costs. In object-level
procedure. We first propose channel-adaptive compression and CP, each agent conducts perception tasks locally based on its
robustfusionapproachestoextractandexploitthemostvaluable
own sensor data, and then exchanges the perception results,
semanticinformationunderwirelesscommunicationconstraints.
suchasdetectedobjects,withothers.Thecommunicationcost
Wethenproposeatask-orienteddistributedschedulingalgorithm
toidentifythebestcollaboratorsforCPunderdynamicenviron- is generally low, but many details in sensor data are lost. As
ments. The main idea is learning while scheduling, where the a result, the perception quality is usually the lowest among
collaboration utility is effectively learned with low computation the three categories. In feature-level CP, agents extract fea-
and communication overhead. Case studies are carried out in
tures from their raw sensor data, exchange these features on-
connected autonomous driving scenarios to verify the proposed
demand, and finally conduct fusion algorithms. Since feature-
framework.Finally,weidentifyseveralfutureresearchdirections.
level CP can strike a balance between perception quality and
communication cost, it is a promising solution for IUSs [4].
Typically,agentsinIUSsaremoving,andthustheyarecon-
I. INTRODUCTION nected wirelessly. The wireless communication process plays
a significant role in CP, aiming to deliver useful information
Intelligent unmanned systems (IUSs) have received
among agents and to enhance the perception quality as much
widespread attention in recent years, and play increasingly
as possible. Different from conventional wireless communi-
significant roles in various aspects of human life and society,
cations, data sharing in CP needs to be perception-aware,
such as transportation, surveillance, and industry. In IUSs,
taking into account the sensing and computing capabilities
agentssuchasautonomousvehicles,unmannedaerialvehicles
of agents as well as wireless channel qualities. Therefore, a
(UAVs) and robots are typically equipped with a variety
novel task-oriented wireless communication framework needs
of sensors, including cameras, LiDARs, and millimeter-wave
to be designed. In fact, CP is a representative example of the
radars. They need to carry out perception tasks such as object
emerging paradigm in communication systems, namely task-
detection, tracking, and semantic segmentation using multi-
orientedcommunications[5]orsemanticcommunications[6],
modal sensor data and advanced artificial intelligence (AI)
which has drawn great attention recently.
algorithms.Conventionalstand-aloneperceptionissusceptible
Despitethepotentialbenefits,optimizingtask-orientedwire-
to occlusions and ambiguity in complex scenarios, due to
less communications for CP is extremely challenging. First,
single viewpoint and limited sensing range. In collaborative
thewirelesschannelconditionsamongthecollaborativeagents
perception (CP), on the other hand, sensor data from multiple
aredynamic,duetothetime-varyingpathloss,shadowing,and
agents are fused to improve the perception quality of distant
fast fading. This necessitates a channel-adaptive CP scheme.
or occluded views [1]. For example, in object detection
Second, the perception topology, defined by whether an agent
tasks, more true positive objects and fewer false positives
(or a group of agents) can monitor an area or detect an object
are expected to be detected through CP [2]. For semantic
of interest, is constantly changing. The mobility of agents
segmentationtasks,CPisexpectedtoimprovetheintersection-
causes dynamic perspectives of mounted sensors. Therefore,
over-union between the ground truth and the predicted region
it is challenging to determine which collaborative agents are
of each object [3].
more beneficial for enhancing the perception quality, taking
the time-varying wireless channels into account. Last but not
Sheng Zhou, Yukuan Jia, Ruiqing Mao, Zhaojun Nan and Zhisheng Niu
are with Beijing National Research Center for Information Science and least, features to be fused may not align in both temporal and
Technology, Department of Electronic Engineering, Tsinghua University, spatial domains, due to the asynchrony in sensing, computing
Beijing100084,China.
and communication delays, and localization errors. A robust
Yuxuan Sun (Corresponding Author) is with School of Electronic and
InformationEngineering,BeijingJiaotongUniversity,Beijing100044,China. feature fusion scheme needs to be incorporated.
4202
nuJ
5
]AM.sc[
1v68030.6042:viXra2
Typical IUSs
Autonomous Vehicles
Req Ru ee sst ponse Co-Agent
UAVs
Beacon broadca
R
Rs et eq su pe os nt
se Co-Agent Shared RFMs
Ego Agent
Shared RFMs
Camera
LiDAR
Intelligent Robots
Raw
Feature Feature
Sensor Detection
Extraction Fusion
Data
CP results in BEV
RFMs in BEV Fused RFMs Dashed boxes show the CP gain
Fig.1. Illustrationoftheproposedtask-orientedwirelesscommunicationframeworkforCPinIUSs.
In this article, we propose a task-oriented wireless com- receiver, thereby significantly improving the communication
munication framework, aiming at improving the CP qual- efficiency.
ity of IUSs. The proposed framework adopts feature-level At a co-agent, the raw sensor data needs to be processed
CP. First, given the collaborative agents and their wireless andcompressedtolightweightfeaturestofitinthebandwidth
communication constraints, we design a channel-adaptive fea- constraint.Weadoptatwo-stagedetectionparadigminbird’s-
ture extraction module to extract lightweight regional feature eye-view (BEV) representation, where perception data are
maps (RFMs) from raw sensor data. Meanwhile, a deep projectedintoaglobalfeaturespacewiththesamecoordinates
metriclearning-basedrobustfusionmoduleisproposed,which and semantic representations. In this paradigm, BEV feature
matchestheRFMsofdifferentagentsunderinaccuratespatio- backbones,suchasPointPillars[7]forLiDARsandLift-Splat-
temporal alignment to improve the perception quality. Then, Shoot (LSS) [8] for cameras, extract RFMs from the raw
inthetheoreticframeworkoftherestlesscombinatorialmulti- sensordata.TheRFMgenerationprocessservesasaneffective
armed bandit, we propose a task-oriented distributed schedul- sourcecompressionapproach,extractingcriticalfeaturesofthe
ing algorithm to identify the best collaborators under the interested foreground objects, while eliminating the irrelevant
dynamic environment. The CP utility, which jointly reflects background information. A co-agent can flexibly adjust the
the perception and communication conditions, is effectively data rate according to the wireless channel state, by sharing
learned in an online fashion. Through two case studies in the most critical RFMs.
connected autonomous driving scenarios, we show the poten- At the ego agent, the messages containing RFMs from
tial perception gain of the proposed framework and stimulate multiple co-agents are decoded. The RFMs are first spatially
further research directions. transformed to the local BEV coordinate of the ego agent
based on the attached geo-location information. Then, RFMs
II. TASK-ORIENTEDWIRELESSCOMMUNICATIONFOR oftheegoandco-agentsarefusedtoobtainthefinalperception
CP:ANOVERVIEW results. Moreover, with a fuse-and-forward mechanism, the
fused BEV feature can be further shared with other agents as
Inthissection,weproposeatask-orientedwirelesscommu-
RFMs, implicitly facilitating a multi-hop fusion system.
nication framework that jointly optimizes the communication
Overall,thecompleteprocedureofCPviawirelessnetwork
scheme and the perception procedure for higher CP quality.
is described in three steps:
AsshowninFig.1,weadoptapull-baseddistributed com-
munication framework. Each agent simultaneously acts as an 1) (Request)Basedonlocallyavailableinformation,anego
ego agent and a collaborative agent (co-agent). The co-agents agent sends CP requests to scheduled neighboring co-
periodically beacon short messages to indicate the availability agents and specifies the maximum data rate according
of CP and the available data formats. The wireless bandwidth totheavailablebandwidthsandmeasuredchannelstates.
for CP is originally allocated to ego agents, and to be further 2) (Response) Upon receiving a CP request, a co-agent
assigned to co-agents when requesting collaborations. By compresses its sensor data through the channel-adaptive
jointly considering the perception topology and the wireless feature extraction algorithm according to the rate con-
channel conditions, the ego agent selects an optimal subset of straint, and responses with the most critical RFMs.
its nearby co-agents to share the perception data. Compared 3) (Fusion)TheegoagentcollectsandaggregatestheRFMs
with the simplest broadcast scheme, the proposed pull-based with feature fusion. Finally, the perception result is
framework takes into account the perception need of the obtained through object detection.3
Toguaranteethetimelinessoftheperceptionresult,theend- in the channel conditions and the perception topology, and
to-endlatencyisrestrictedtotenstohundredsofmilliseconds, proceed to schedule other collaborators. Moreover, the multi-
depending on the downstream application. Since the compu- hop mechanism may also help to aggregate information from
tation takes tens of milliseconds, communication should be more distant agents.
finished within the remaining delay budget. 4) CausalityIssue: Oneofthemostdistinctivecharacteris-
There are several performance metrics to evaluate the tics in agent scheduling is the causality issue. The perception
quality of CP. In object detection, recall is defined as the topology is difficult to predict because the environment is
ratio of true positive detections to all ground-truth objects, usually partially known, along with imperfect modeling of
while precision is the ratio of true positive detections to all practical issues such as occlusions, sensor characteristics, and
detections. The recall and precision metrics form a trade- lighting conditions. Moreover, the transmitted intermediate
off, and Average Precision (AP) is the average of precision features from detection neural networks have the black-box
values at certain levels of recall. Considering the contextual nature,whicharehardtointerpretwithouttheactualexecution
importance, one can also calculate a perception loss which of the networks. In particular, an interested object might not
sums up the importance-weighted penalties of false positives be correctly detected even when it is within the coverage area
and false negatives. of a sensor, due to unusual object shapes, partial occlusions
and other influencing factors.
III. KEYCHALLENGES
Thereareseveralkeychallengesindesigningatask-oriented
IV. RFMPROPOSALANDFEATUREFUSION
wirelesscommunicationframeworkforCPinIUSs,described In this section, we design feature extraction and fusion
as follows: modules to overcome non-ideal channel and alignment con-
1) LimitedBandwidthandFadingChannels: Typically,the ditions, aiming to maximize the CP gain given collaborative
constrained bandwidth cannot afford feature sharing among agents. The limited bandwidth necessitates a channel-adaptive
all agents in IUSs. For example, at the sub-6 GHz frequency compression scheme to extract features from raw sensor data.
band, the officially allocated bandwidth for sidelink vehicular Meanwhile, the mobility of agents results in varying chan-
communication is only 20 MHz in China and 30 MHz in the nel conditions and intermittent connectivity, which necessi-
US. This bandwidth is shared by all vehicles for various real- tates multi-hop fusion. Moreover, inaccurate spatio-temporal
time collaboration services. Therefore, agents should extract alignment may introduce noise into the fusion process, thus
the most valuable semantic features from the raw sensor data demanding robust fusion techniques to enhance calibration
to share. Besides, since the wireless channel conditions are accuracy. The overall architecture is shown in Fig. 2.
dynamic, the achievable data rate is also time-varying. The
CPalgorithmshouldactivelyadjustthedatavolumegiventhe
A. Channel-Adaptive RFMs Proposal
channel conditions.
2) Inaccurate Spatio-Temporal Alignment: Due to the Through typical BEV feature backbones, such as Point-
multi-path effect and signal interference, localization error in Pillars [7] for LiDARs and LSS [8] for cameras, raw data
IUSs is inevitable. Moreover, the perceptual data aggregated are encoded and projected into a global BEV feature repre-
from various perspectives may not correspond to the same sentation space. It provides universal coordinates among all
timestamp, owing to stochastic sensing and communication agents, which are fundamental for multi-hop fusion. Then,
delays. When the ego agent extracts RFMs from its sensors the global BEV features are sent into the region proposal
and receives RFMs from others, feature-level fusion is carried process to generate RFMs, along with the confidence score
out to merge those features from different perspectives. The of each region. Noted that each RFM indicates a possible
common solution is to use the geo-positions and the poses of foreground area in the BEV map, the RFMs are all we need
sensors, which suffers performance degradation when agents to be transmitted and fused, which greatly reduces the data
are moving and localization is inaccurate. Deep learning- volume.
based strategies have been proposed to compensate for the To meet various communication conditions, the RFM
misalignment, but the lack of interpretability affects their extraction and transmission procedure should be channel-
reliability. adaptive. If the channel state information (CSI) is perfect,
3) Dynamic Perception Topology & Channel Conditions: there are some effective approaches to further compress the
In most IUSs, the perspectives of sensors mounted on agents sourcedatabyadjustingthenumberofRFMstobetransmitted
and the wireless communication channels are ever-changing according to the available data rate (e.g., [2], [9]). First,
duetothemobilityofagents.Knowledgeabouttheperception if a co-agent knows which areas have already been well-
topology and the channel conditions can stale quickly and perceivedbytheegoagentaccordingtothesharedconfidence
becomeinaccurate.Forexample,aco-agentmaynolongerbe score, it can selectively transmit the RFMs of the areas
able to detect an interested object due to occlusion, or it may that require enhancement. Second, if agents can utilize their
be suffering from a poor channel state and the transmission relative positions and historical data to infer the overlapping
is interrupted. If out-of-date information is used to schedule relationship of viewpoints, they can collaborate to perform
collaborators,thereliabilityofCPcanbeimpaired.Undersuch optimized scheduling transmissions, achieving good coverage
circumstances, the agent should quickly identify the changes of the entire area with minimal communication cost. On the4
Ego Agent
Camera
RFM Feature Fusion
Detection
Extraction RFMs in BEV Fused
LiDAR
RFMs
Spario-Temporal Deep Metric Learning
Misalignment based Matching
Selected RFMs Selected RFMs
to be shared in to be shared in
Co-Agent 1 single-hop CP multi-hop CP
Camera
RFM Feature Detection
Extraction Fusion
LiDAR
Co-Agent 2
Shared RFMs
Fig.2. Illustrationoftheproposedchannel-adaptiveRFMproposalandrobustfeaturefusionmodules.
other hand, if the CSI is unknown or imperfect, the trans- on the BEV feature maps, generating 300 regions that po-
mission procedure should take redundancy into account. The tentially contain foreground objects. Based on the foreground
retransmissionprocedureaswellasanerror-correctingcoding confidencescores,theTop-K regionsareselectedaccordingto
scheme can be utilized under such circumstances, as a future current bandwidth limitations. Additionally, positioning errors
extension to the proposed source compression technique. following Gaussian distribution N(0,0.12) are considered in
the feature fusion stage.
The experiment result is shown in Fig. 3. Compared with
B. Feature Fusion under Spatio-Temporal Misalignment
thestand-aloneperception,CPbringssignificantimprovement
To tackle the inaccurate localization (spatial) and com-
under any communication payload. The gain of CP rises
munication latency (temporal) in the dynamic environment,
with an increasing number of transmitted regions, but the
we propose a robust feature map alignment strategy exploit-
diminishing marginal utility reveals the possibility of saving
ing both semantic feature similarities and intrinsic spatial
the data volume with little precision loss. The feature-level
structures. The deep metric learning method is introduced to
fusionschemealsobeatstheraw-levelfusion,sincethefeature
learn the similarity between different RFMs. Meanwhile, the
extractionandregionproposalstageseliminatethebackground
relative positions of the RFMs from a single perspective are
noises in the raw data. On the other hand, our proposed
well-recorded under the BEV representation. Such kind of
architecture also shows robustness against positioning error,
information is similar to the relative poses used in [10] to
especially under large data volumes when there are more
calibrate the localization and pose errors. Therefore, the ego
regions to be matched and aligned.
agent learns to estimate the relative translation and rotation
Given that the DOLPHINS dataset is recorded at 2 frames
relationship between two sets of BEV RFMs by matching
per second, a deliberate one-frame shift in the initial hop fu-
featuremapsandspatialstructures.Afteralignment,theagent
sionintroducesadelayof0.5seconds.Fig.3demonstratesthat
couldgainawiderperspectivefieldfromtheenhancedfeature
the collaborative fusion from a third viewpoint significantly
maps and get more precise perception results.
enhancesCPperformancebyexpandingtherangeavailableto
the ego agent. However, as the number of RFMs transmitted
C. Case Study: Two-hop Feature Fusion in Connected Au- increases in the second hop, the incremental gains provided
tonomous Driving by the third viewpoint diminish. This finding underscores the
We evaluate our proposed feature-level CP architecture by critical balance between data volume and viewpoint diversity
object detection tasks on point clouds in vehicular CP. We subject to limited communication bandwidth, which arouses
use the DOLPHINS dataset [11], which contains six typical the necessity of designing scheduling algorithms.
autonomousdrivingscenarios,suchasintersections,high-way
on-ramp merging, and mountain roads. For each scenario, V. TASK-ORIENTEDDISTRIBUTEDSCHEDULING
camerasandLiDARsareequippedonthreecriticalviewpoints, Based on the RFM extraction and robust fusion modules
including both vehicles and road-side units. proposedabove,wefurtherintroducetask-orienteddistributed
We adopt the PointPillars [7] backbone as the global BEV scheduling algorithms in this section. The goal is to optimize
feature generator. Each pillar is set to 0.16m×0.16m×4m, the collaboration topology, i.e., from which agents to request
while the region of interest of each agent is set to be RFMs.
100m×100m. Therefore, the dimension of the BEV feature To make scheduling decisions, it is fundamental to define
mapsis625×625×64.Weperformaregionproposaldirectly the collaboration utility associated with an agent or a group5
0.68 / / CP[13].Theperceptualdataofeachagentisfirstcompressed
0.67 into compact query and key features, then the queries are
0.66 broadcast to all neighboring agents to compute the query-
0.65 key matching scores. Finally, the priority of collaboration can
n o0.64 be decided by descending order of the scores. Note that the
is
ic0.63 feature extraction and matching processes are functions with
e
rP0.62 learnable parameters, which generally capture the relevance
e g between the sensor data.
a0.61
re
v A 0.6
O On ne e- -h ho op
p
w w/ io
th
p po os sit ii to ion nin ing
g
e er rr ro or
r In [2], a BEV spatial confidence map is first encoded
Two-hop w/o positioning error from the sensor data, which reflects the probability that there
0.59
Two-hop with positioning error is an object within the area. In the first receiver-agnostic
0.58 Raw-level fusion
Stand-alone perception collaboration round, a small portion of features is broadcast
0.57
based on the confidence scores, along with a request map that
0.56 / /
0 5 10 15 20 25 30 35 1755 1760 negativelycorrelateswiththeconfidencemap.Forthefollow-
Data volume to be transmitted (kB) ing rounds, the utility of transmitting an area is calculated by
themultiplicationofthesender’sconfidenceandthereceiver’s
Fig.3. PerformanceoftheproposedCParchitecture.
request map, which represents the potential of discovering
missedinformation.Thisapproachlaysthefoundationforfine-
ofagents.DependingonthemetricofCP,thisutilitycouldbe grainedsensordatadistributedschedulingattheinstancelevel.
the extra coverage area or additionally detected objects. The However, the above solutions based on metadata exchange
perceptiontopologyisthecrucialfactortotheutility,parame- introduce extra communication and computation overheads
terized by the transmission bandwidth, since more data gener- that result in higher end-to-end latency, which in turn impairs
ally assist the detection of objects, as reported in the previous the perception.
section. Therefore, in bandwidth-constrained networked IUSs,
scheduling more agents can sometimes negatively influence
C. Learning While Scheduling
theperformanceofCP,becausethetransmitteddatafromeach
agent becomes less comprehensive. This intuition necessitates Instead of requesting extra information, we propose to
a task-oriented wireless communication system with a sparse leverage the historical data from nearby agents to learn the
and essential collaboration topology to optimize perception CP utilities at present. In a task-oriented way, the utility of
performance. received features from an agent can be extracted from the
To address the design challenges, we review existing so- innovative corrections of CP, by comparing the perception
lutions in the literature and propose an efficient yet effective results of CP with stand-alone perception. The tricky part
approach, learning while scheduling. is that the ego agent can only evaluate the utilities after
it completes the CP in this time frame, while the potential
utilities of unscheduled agents are evolving and unobservable.
A. Spatial Reasoning
Withtheutilityknowledgeofpreviousfeaturemaps,theagent
To obtain an approximated perception topology, the fun-
can proactively schedule co-agents to continuously exploit the
damental approach is spatial reasoning based on geometry
sensor data, and update the knowledge at the same time.
relationships [12]. Specifically, based on the locally available
Note that with the multi-hop mechanism, the feature map of
sensor data, the agent can construct a dynamic environment
a co-agent could also include the sensing information from
map and calculate the visibility of an object from another
its neighbor agents. In a highly dynamic scenario, one has to
nearby agent. The visibility is determined by the line-of-sight
explorebyschedulingeachcandidateco-agentonceinawhile
condition, indicating whether there are blockages between the
to learn the perception topology, otherwise one could miss a
object and the agent. This spatial reasoning process can be
co-agent that provides potentially superior sensor data. This
enhanced with the assistance of a high-definition map, which
forms an exploration-exploitation trade-off.
provides the background information of the environment.
In a simpler setting that considers scheduling only one
Althoughefficienttoimplement,spatialreasoninginevitably
collaborator at a time, our preliminary work adopts the the-
introduces error since there can be blockages that are unob-
oretical framework of restless multi-armed bandits (RMAB)
served by the agent. As stated previously, visibility alone is
[14].Oneofthemoststraightforwardsolutionsistheperiodic
insufficient for accurate prediction of real-world object detec-
explore-then-commit (ETC) algorithm. In ETC, each nearby
tors,whichresultsinunexpectedfalsenegatives.Furthermore,
agent is scheduled once at the beginning of an epoch, and the
when multi-hop feature fusion is introduced, the collaboration
empirical leader is scheduled constantly until the end of the
utility of an agent is beyond its visibility. Therefore, spatial
epoch.However,itisunabletoadapttotherapidandirregular
reasoninghasitslimitationsinevaluatingmodernCPsystems.
shiftsoftheutilities.InspiredbytheUpperConfidenceBound
(UCB) algorithm in the static MAB problem, the mobility-
B. Metadata Exchange
aware sensor scheduling (MASS) algorithm is proposed to
Inspired by the attention mechanism, a three-stage hand- balance the exploration-exploitation trade-off in restless ban-
shake communication is designed to determine the utility of dits problems. To tackle the dynamics of utilities, Brownian6
a more holistic environmental perception. The CoVs period-
Determine the set of
candidate agents Empirical Perception Topology ically beacon short status messages which also declare their
Object 1 Object 2 Object 3 functionality of CP. Under a limited wireless bandwidth, the
Schedule the unexplored agents
if there is any Redundancy level: 2 1 0 egovehicleselectsasubsetofnearbyavailableCoVs,requests
and aggregates their sensor data, and finally executes the
Yes No. scheduled No detection network, at an operating frequency of 10Hz. Each
agents < N Ego Agent 1 Agent 2 Agent 3 Agent 4 undetected traffic participant incurs a perception loss that
(already scheduled)
equals its importance weight, which relates to the distance
Calculate empirical utility to the ego vehicle. Therefore, the utility of CP is defined as
for each candidate agent
Empirical Collaboration Utility thesumofweightsoftheadditionallydetectedobjects.Inthis
w/ Confidence Bound
Schedule the agent with case study, we consider maximizing the average utility of CP
the highest UCB of utility by scheduling N CoVs in a time frame and allocating equal
bandwidths to the CoVs.
Agent 2 Agent 3 Agent 4
Request, Aggregate, For simulation, we set up an urban traffic setting similar
Detect & Evaluate
to [14], where vehicles and pedestrians are moving along bi-
directionaltwo-lanestreetswithsidewalks.Assumethemarket
Fig.4. IllustrationoftheC-MASSscheme.Left:ThediagramofC-MASS
algorithm. Upper right: The orange nodes and edges are already scheduled penetrationratio(MPR)is0.7,whichdenotestheratioofCP-
agentsandanticipateddetectionsinthecurrentround.Empiricalcollaboration enabledCoVsamongallthevehicles.Weadoptthe3GPPV2V
utilitiesarecalculatedusingthelearnedperceptiontopologyandthecurrent
sidelinkchannelmodelspecifiedin3GPPTR37.885[15].The
redundancy level. Bottom right: The confidence bounds of collaboration
utilities.Agent4ispreferredoverAgent3becauseithasnotbeenexplored link is classified by LOS, NLOSv, and NLOS, with different
forarelativelylongtime. sets of parameters. The channel gain of a V2V link consists
of a distance-related path loss, a spatial-correlated shadowing
loss, and attenuation losses caused by vehicle blockages. The
motion is used to approximate the underlying process of the
fast fading is simulated with i.i.d. Rician distribution for
utilities.TheUCBsofcollaborationutilities,swellingthrough
LOS and NLOSv links, and Rayleigh distribution for NLOS
time when unexplored, are ranked to encourage moderate
links. Under the bandwidth constraint 0.6MHz, the proposed
exploration. If a new co-agent is discovered, it is scheduled
C-MASS scheme is compared with two baselines: Closest
immediately, and its UCB of utility will be computed in
Candidates scheme selects the closest N CoVs, which are
subsequent scheduling decisions until it leaves.
generally close to the most important objects and enjoy the
Extending to scheduling multiple collaborators, a combina-
best communication channels. Greedy Coverage greedily
torial mobility-aware sensor scheduling scheme, C-MASS, is
maximizes the weighted coverage area in each of the N
proposed. To reduce the complexity due to the combinatorial
rounds. However, accurate calculation of coverage requires
explosion,weexploittheproblemstructureandadoptamulti-
high-definitionmapsandspatialreasoningwhichinduceextra
round greedy approach, as illustrated in Fig. 4. In each round,
delay in scheduling decisions. When the number N is large,
the ego agent calculates the empirical collaboration utilities
all three schemes converge to All Candidates, which selects
of the candidates based on the learned perception topology
all candidate CoVs within the communication range of 150m.
from past observations. In specific, the utility consists of new
TheexperimentresultwithavaryingnumberN ofselected
detections from the candidate alone and also from the col-
CoVsisshowninFig.5duringatripof10,000frames(1,000
laborative detections with the other agents. We also note that
seconds).Asexpected,withlargerN,thebandwidthallocated
new anticipated detections contribute to the empirical utility
to each CoV is less, which in turn negatively influences the
according to other factors such as the importance and the
utility of CP. It can be seen from Fig. 5 that the optimal
currentredundancyleveloftheobject.Takingthedynamicsof
number of selected vehicles are N =4 for C-MASS, N =5
the environment into account, we then compare the UCBs of
for Greedy Coverage, and N = 8 for Closest Candidates,
CP utilities to greedily schedule the most beneficial agent to
respectively.Moreover,C-MASSoutperformsallthebaselines
collaborateinthisround.AfterN roundsofselection,theego
in terms of both the perception loss and the recall metrics.
agentrequestssensordataandexecutesthedetectionnetwork.
Intuitively, C-MASS is oriented directly towards detecting
Finally, the perception topology of the scheduled agents is
more important objects rather than keeping wider coverage.
evaluated and updated for future scheduling. In addition to
Althoughtheempiricalperceptiontopologyisfrompastobser-
thetask-orientedcharacteristic,theproposedC-MASSscheme
vations, UCB is introduced to effectively balance exploration
also has the merit that no extra communication overhead is
and exploitation in a dynamic environment, as discussed in
required prior to scheduling decisions.
[14].Theproposedschemeisalsohighlyefficientwithoutthe
need to acquire metadata such as coverage information.
D. Case Study: Task-oriented Collaborative Vehicle Selection
in Connected Autonomous Driving VI. CONCLUSIONANDOUTLOOK
To evaluate and compare the solutions, we conduct a case In this article, we have proposed a task-oriented wireless
study in a connected autonomous driving scenario where communication framework for CP, addressing the challenges
collaborativevehicles(CoVs)exchangesensordatatoachieve of limited bandwidth, inaccurate spatio-temporal alignment,7
0.46 the energy consumption from communications and computing
All Candidate under given timeliness constraints, to achieve better energy
0.44 Closest Candidates
efficiency.
Greedy Coverage
C-MASS [Proposed] Security Issues. CP over wireless inevitably needs to share
s0.42
s
o sensor information among agents, which leads to potential
L
n o 0.4 privacy leakage. In-depth analysis on the privacy information
itp
carried by RFMs is required, based on which coding schemes
e
c0.38
re andprotocolsshouldbedesignedforbetterprivacypreserving.
P
e g0.36 Since malicious agents may send fake sensor data or RFMs,
a
re consensus algorithms among agents are needed to detect such
v
A0.34
harmful behaviors.
0.32
REFERENCES
0.3
1 2 3 4 5 6 7 8 [1] Q.Yang,S.Fu,H.WangandH.Fang,“Machine-Learning-EnabledCo-
Number of CoVs to Schedule operative Perception for Connected Autonomous Vehicles: Challenges
and Opportunities,” in IEEE Network, vol. 35, no. 3, pp. 96-101,
(a)
May/June2021.
[2] Y. Hu, S. Fang, Z. Lei, Y. Zhong, and S. Chen, “Where2comm:
0.8 Communication-efficientcollaborativeperceptionviaspatialconfidence
maps,”inProc.NeuralInf.Process.Syst.(NeurIPS),NewOrleans,USA,
0.79
Nov.2022.
[3] Z.Liuetal.,“BEVFusion:Multi-TaskMulti-SensorFusionwithUnified
0.78
Bird’s-Eye View Representation,” in Proc. IEEE Int. Conf. Robot.
0.77 Automat.(ICRA),London,UnitedKingdom,2023,pp.2774-2781.
lla
c0.76
[4] PY e. rH cea pn t, ioH n. inZ Aha un tog n, oH m. ouL si, DY ri. vJ inin g, :MC. etL ha on dg s,a Dn ad taY se. tsL ,i a, n“ dC Co hll aa lb leo nr gat ei sv ,”e
e
R inIEEEIntell.Transp.Syst.Mag.,vol.15,no.6,pp.131-151,Nov.-Dec.
e0.75
g 2023.
a
re v0.74 [5] D.Gu¨ndu¨zetal.,“BeyondTransmittingBits:Context,Semantics,and
A Task-OrientedCommunications,”inIEEEJ.Sel.AreasinCommun.,vol.
0.73 All Candidate 41,no.1,pp.5-41,Jan.2023.
Closest Candidates [6] M.KountourisandN.Pappas,“Semantics-EmpoweredCommunication
0.72 Greedy Coverage for Networked Intelligent Systems,” in IEEE Commun. Mag., vol. 59,
C-MASS [Proposed]
no.6,pp.96-102,June2021.
0.71
[7] A. H. Lang, S. Vora, H. Caesar, L. Zhou, J. Yang and O. Beijbom,
0.7 “PointPillars:FastEncodersforObjectDetectionFromPointClouds,”
1 2 3 4 5 6 7 8 inProc.IEEE/CVFConf.Comput.Vis.PatternRecognit.(CVPR),Long
Number of CoVs to Schedule Beach,CA,USA,2019.
[8] J.Philion,S.Fidler,“Lift,Splat,Shoot:EncodingImagesfromArbitrary
(b)
Camera Rigs by Implicitly Unprojecting to 3D,” in Proc. Eur. Conf.
Fig. 5. Performance of CP with different CoV selection schemes. (a) The Comput.Vis.(ECCV),Glasgow,UK,August2020.
averageperceptionloss.(b)Theaveragerecall. [9] T. Wang et al., “UMC: A Unified Bandwidth-efficient and Multi-
resolution based Collaborative Perception Framework,” in Proc. Int.
Conf.Comput.Vis.(ICCV),Paris,France,October2023.
[10] Y. Lu et al., “Robust Collaborative 3D Object Detection in Presence
dynamic topologies, and the causality issue. The framework
ofPoseErrors,”inProc.IEEEInt.Conf.Robot.andAutomat.(ICRA),
consists of BEV-based RFM extraction, metric learning-based London,UnitedKingdom,2023.
fusion, and task-oriented distributed agent scheduling. Case [11] R. Mao, J. Guo, Y. Jia, Y. Sun, S. Zhou, and Z. Niu, “DOLPHINS:
DatasetforCollaborativePerceptionenabledHarmoniousandIntercon-
studies showcase the perception performance gain brought
nectedSelf-driving,”inProc.AsianConf.Comput.Vis.(ACCV),Macau
by the proposed framework, and also inspire some future SAR,China,Dec.2022.
directions as follows. [12] H. Qiu, P. Huang, N. Asavisanu, X. Liu, K. Psounis, R. Govindan,
“Autocast: Scalable infrastructure-less cooperative perception for dis-
CP Timeliness. The study of robust feature fusion high-
tributed collaborative driving,” in Proc. ACM Int. Conf. Mobile Syst.,
lightstheintroductionofcommunicationlatencyduringmulti- Appl.,Services(MobiSys),Portland,USA,Jun.2022.
hop feature fusion. As the first case study shows, the more [13] Y. Liu, J. Tian, N. Glaser, and Z. Kira, “When2com: Multi-agent
Perception via Communication Graph Grouping,” in Proc. IEEE Conf.
hops a set of RFMs needs to be transmitted, the less informa-
Comput.Vis.PatternRecognit.(CVPR),Virtual,Jun.2020.
tive it is, and thus the confidence score is decayed according [14] Y. Jia, R. Mao, Y. Sun, S. Zhou and Z. Niu, “MASS: Mobility-Aware
to the freshness. One possible solution is to use metrics like SensorSchedulingofCooperativePerceptionforConnectedAutomated
Driving,”inIEEETrans.Veh.Technol.,vol.72,no.11,pp.14962-14977,
age of information to represent the time decay of each fusion
Nov.2023.
process. In addition, the computation delay should also be [15] 3GPP,“StudyonevaluationmethodologyofnewVehicle-to-Everything
appropriately modeled and considered. usecasesforLTEandNR,”3GPPTR37.885,v15.1.0,Sept.2018.
Energy Efficiency Optimization. The end-to-end process
of CP not only consumes the wireless communication energy
but also the computing energy. While one can save commu-
nication energy by sharing less data, the energy consumption
for feature extraction and compression, as well as for fusion
may increase. Careful design should be adopted to balance