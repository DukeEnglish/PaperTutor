LM4OPT: Unveiling the Potential of Large Language Models in Formulating
Mathematical Optimization Problems
Tasnim Ahmed, SalimurChoudhury
SchoolofComputing,Queen’sUniversity
Kingston,OntarioK7L2N8,Canada
{tasnim.ahmed,s.choudhury}@queensu.ca
Abstract quently,optimizationmodelingwouldbecomeaccessibleto
individualswhocannotaffordexpertstoaugmentefficiency
Intherapidlyevolvingfieldofnaturallanguageprocessing,
usingoptimizationtechniques.Providedtheproblemiscor-
the translation of linguistic descriptions into mathematical
rectlyformulated,itcanbereadilysolvedbytranscribingit
formulationofoptimizationproblemspresentsaformidable
intoanalgebraicmodelinglanguageinterpretablebysolvers
challenge, demanding intricate understanding and process-
(Ramamonjisonetal.2023).
ingcapabilitiesfromLargeLanguageModels(LLMs).This
study compares prominent LLMs, includingGPT-3.5,GPT- ThefieldofNaturalLanguageProcessing(NLP)presents
4,andLlama-2-7b,inzero-shotandone-shotsettingsforthis a potent avenue for enhancing the accessibility and effi-
task.OurfindingsshowGPT-4’ssuperiorperformance, par- ciency of optimization problem formulation. From the in-
ticularly in the one-shot scenario. A central part of this re- ception of word embeddings to the evolution of language
search isthe introduction of ‘LM4OPT,’a progressive fine- models, NLP has undergone transformative progress over
tuning framework for Llama-2-7b that utilizes noisy em-
theyears.Especiallywiththeemergenceofpre-trainedlan-
beddings and specialized datasets. However, this research
guage models (Devlin et al. 2019), these models have at-
highlightsanotablegapinthecontextualunderstanding ca-
tained state-of-the-art results on a multitude of NLP tasks
pabilities of smaller models such as Llama-2-7b compared
suchasnaturallanguageinference(NLI),questionanswer-
to larger counterparts, especially in processing lengthy and
complexinputcontexts.Ourempiricalinvestigation,utilizing ing, summarization, collaborative writing, etc., with min-
the NL4Opt dataset, unveils that GPT-4surpasses the base- imal task-specific fine-tuning (Laskar, Hoque, and Huang
line performance established by previous research, achiev- 2021). The recent advancements in LLMs, including GPT
ing an F1-score of 0.63, solely based on the problem de- (OpenAI2023),andLlama(Touvronetal.2023),havesig-
scriptioninnaturallanguage,andwithoutrelyingonanyad- nificantlyreshapedtheNLPlandscapeandpractices.These
ditional named entity information. GPT-3.5follows closely, LLMs,withparametersizesexceedingseveralbillions,and
both outperforming the fine-tuned Llama-2-7b. These find-
evenreachinghundredsof billions, have exhibitedremark-
ingsnotonlybenchmarkthecurrentcapabilitiesofLLMsina
able generalization abilities in zero-shot and few-shot set-
novelapplicationareabutalsolaythegroundworkforfuture
tings through prompting. Furthermore, these LLMs have
improvements in mathematical formulation of optimization
shownexceptionalfine-tuningcapabilities,evenwhenfine-
problemsfromnaturallanguageinput.
tuned on datasets significantly smaller than those used by
theirpredecessors.
Introduction
To this end, formal assessment of this specific
Numerouspracticalchallengesoriginatingfromdiversedo- task−mathematical formulation of optimization prob-
mainssuchasoperations,economics,engineering,andcom- lems from natural language descriptions using the latest
puter science can be articulated as optimization problems developmentsfromtheGPTseriesmodels,namelyGPT-3.5
(AhmadiTeshnizi,Gao,andUdell2023).Standardoptimiza- and GPT-4, which have garnered widespread recognition,
tion algorithms, including the simplex (Nash 2000) and remains an uncharted territory. Additionally, this research
interior-pointmethods(Karmarkar1984),canefficientlyad- aims to investigate the capabilities and limitations of a
dresstheseproblems.Nevertheless,thetranslationofareal- smaller Large Language Model (LLM), Llama-2-7b,when
world situation into a mathematical formulation necessi- fine-tuned on this task. Consequently, this study offers the
tates specialized knowledge. This expertise barrier hinders followingcontributions:
many individuals from utilizing optimization algorithms,
• ComprehensiveanalysisofGPT-3.5,GPT-4,andLlama-
even when these could substantially enhance their opera-
2-7bin mathematicalformulationof optimizationprob-
tions.Theadvancementofautomatingproblemformulation,
lemsfromnaturallanguagedescription.
whichinvolvestranslatingnaturallanguagedescriptionsinto
decisionvariables,constraints,andobjectivefunctions,has • Evaluation in zero-shot and one-shot settings to under-
thepotentialtomaketheseprocessesmoreaccessibletoin- stand the impact of few-shot prompt engineering and
dividuals beyond just operations research experts. Conse- learningadaptationsofthemodels.
4202
raM
2
]LC.sc[
1v24310.3042:viXra• EmpiricalstudyusingtheNL4Opt(Ramamonjisonetal. solutions at each iteration, balancing the need to explore
2023)dataset,demonstratingthesuperiorperformanceof different options with refining existing ones. The authors
GPT-4,followedbyGPT-3.5. demonstratedencouraging preliminary outcomeswhen ap-
plyingtheirmethodstotheGSM8K(Cobbeetal.2021)and
• ExplorationofutilizingtheLM4OPTframeworktofine-
BBH(Suzgunetal.2022)datasets,inadditiontotaskssuch
tune Llama-2-7b, revealing significant performance en-
aslinearregressionandthetravelingsalesmanproblem.The
hancements.
effectiveness of OPRO for complex optimization tasks is
yet to be fully determined. In a recent study focused on
Related Work
practicalapplications,researchersintroducedtheOptiGuide
Effortsto simplifycombinatorialoptimizationusingLLMs framework (Li et al. 2023), a novel integration of combi-
have seen diverse approaches, aiming to make the process natorialoptimizationtechnologywithadvancedLargeLan-
user-friendly for laypersons. The NL4Opt (Ramamonjison guage Models (LLMs), such as GPT-4, aimed at augment-
et al. 2023) competition stands out, exploring the trans- ing decision-making processes within supply chain man-
formation of natural language into structured optimization agement. This framework transforms user queries into in-
models.InTask1whichisdescribedin(Dakleetal.2023), contextlearning (ICL) queriesfor LLM processing, gener-
the aim is to accurately identify and label the components ating code that is vetted for accuracy and reliability. Upon
of optimization models—such as objectives, variables, and validation, this code interfaces with specific components
constraints—withinnaturallanguagetexts.Researchersap- like optimizationsolversand databasesto derivesolutions.
proachedthisbyusingclassicalNERtechniquesthatrelyon The results, convertedinto understandableexplanationsby
the morphological and grammatical properties of the text. theLLM, simplifycomplexsupplychain optimizationsfor
Additionally, modern methods were employed, involving non-technicalusers, fostering trust in automated decisions.
the use of pre-trained LLMs like BERT and GPT, which Inpracticaldeployments,suchasMicrosoftAzure’ssupply
were furtherfine-tunedonoptimization-specificdatasetsto chain,OptiGuidehasexhibitedpromisingoutcomes,achiev-
betterunderstandtheuniquelanguageofoptimizationprob- inganaverageaccuracyof93%withGPT-4,highlightingits
lems.Task2requiredbuildingmathematicalrepresentations effectivenessinreal-worldsettings.Asummaryoftherecent
fromtheseelements,amorecomplexstepinvolvingdeeper worksinthefieldofOptimizationandLanguageModelsis
modelcomprehension.Themethodologieshereincludedthe showninTable1.
useofsequence-to-sequencemodels,whichareadeptathan- Despite these strides, a gap persists−an end-to-end sys-
dlingsuchtranslationtasks. tem that allows users the flexibility to verify and mod-
The former two-step approach to generate mathemati- ify mathematical problem formulation, independent of the
cal formulation from optimization problem description re- solverorprogramminglanguageused.Addressingthis,our
quirestraininganddependencyontwoseparatemodels.To research identifies a niche for benchmarking popular pre-
bridgetheresearchgap,Tsourosetal.(Tsourosetal.2023) trained LLMs on the specific task of optimizationproblem
proposedanall-in-oneLLM-basedmodelthatcreatesopti- formulationanddevelopinga tailoredfine-tuningapproach
mization models directly from prompts, showing early po- to enhance LLM specificity for this nuanced application.
tential on the dataset described in NL4Opt but without es- This work endeavors to bridge the research gap, offering
tablished benchmarks for comparison. Advancing this ap- a robust benchmark and a novel fine-tuning strategy that
proach, Teshinizi et al. (AhmadiTeshnizi, Gao, and Udell couldsignificantlybenefitthescientificcommunity’spursuit
2023)presentedanovelframeworknamedOptiMUS,which ofdemocratizingoptimizationmodeling.
utilizes LLMs (pre-trained GPT) to formulate and solve
TaskFormulation
MixedIntegerLinearProgramming(MILP)problemsfrom
natural language descriptions. They introduced a dataset, This research investigates a generative task in the field of
NLP4LP, containing linear programming and MILP prob- natural language processing, concentrating on the genera-
lemsto benchmarkOptiMUS, which showssignificantim- tion of mathematical formulations for optimization prob-
provementoverbasicLLMpromptingstrategies.OptiMUS lems derived from textual descriptions. Our objective is to
integratesmathematicalmodeling,Gurobisolvercodegen- derivestructured representations- encompassingvariables,
eration,automatedtesting,anddebugginginacohesivesys- constraints,andtheobjectivefunctionbasedongivennatu-
tem thatstreamlinesthe optimizationproblem-solvingpro- rallanguagedescriptions.Weutilizeadataset,denotedasS,
cess.Thegoalofthisstudyistodemocratizeaccesstoopti- comprisinga series of problem descriptions,and C, repre-
mizationtechniquesacrossvariousdomains,therebybroad- sentingtheircorrespondingformulationsincanonicalmath-
ening the use of optimization tools beyond expert circles. ematical form. At the core of our methodology is the in-
Furthermore,Yang et al. (Yang et al. 2023) introducedan- troductionofanintermediaterepresentationalset,R,which
other prompt-based framework, OPRO, which uses LLMs encapsulatestheessentialcomponentsofoptimizationprob-
to optimize problems without needing traditional solvers. lems (variables, constraints, and objective functions) in an
OPRO works by iteratively improving solutions using a equation-centricformat,asopposedtothefinalmatrixform
‘meta-prompt’ that incorporates both the problem descrip- depicted in C. For a given problem descriptions ∈ S, the
tion and feedbackfromprevioussolutions. It aims to learn primary goal of an LLM is to predict an intermediate rep-
continuouslyasitupdatesthemeta-promptwithnewinfor- resentation r ∈ R. Finally, the predicted intermediate rep-
mation. To ensure stable results, OPRO generates several resentation, r, undergoes a systematic conversion into theResearchWork Dataset Input Framework Objective
ProblemTypeinNaturalLanguage Human-in-the-loop MultipleLLMs Fine-tuning PromptEngineering
NER4Opt NL4Opt Optimization × × X × Identifyingnamedentitties
NL4OptCompetition NL4Opt Optimization × X X × MathematicalFormulation
HolyGrail2.0 − Optimization − − − − MathematicalFormulation
OPRO GSM8K,BBH Mathword,Common-sense,Optimization × × × X ProblemSolution
Optimus NLP4LP Optimization X X × X ProblemSolution
Optiguide Private Supplychainmanagement × × × X ProblemSolution(QASession)
LM4OPT(ours) NL4Opt Optimization × × X X MathematicalFormulation
Table1:RecentworksinthefieldofOptimizationandLanguageModels
canonicalformulation,denotedasc∈C,tofacilitateacom- AdvancedTuningofLlama-2-7bviaLM4OPT
prehensiveevaluationoftheperformanceofLLM.Thispro-
cessisexemplifiedinFigure1,whereanexampleofaprob- A progressive fine-tuning strategy was employed for the
lem description along with the correspondingintermediate Llama-2-7bmodel,enablingittoinitiallyadapttoabroader
representationandcanonicalformisprovided.Itshouldbe domain context related to the final task. This preliminary
notedthattheconstraintsaretransformedintoaformatem- adaptation phase is crucial in enhancing the model’s com-
bodying‘lessthanorequalto’conditions,andtheobjective prehensionandperformancecapabilities.Followingthis,the
functionisreformulatedintoaminimizationparadigm. modelundergoesfurtherfine-tuningon a specialized, task-
specificdataset,whereitappliestheknowledgeacquiredin
theinitialphasetoachieveimprovedperformanceandgen-
Methodology eralizationonthe targettask. Priorto its fine-tuningon the
NL4Opt dataset, the model was fine-tuned on GSM8K−a
Incontemporaryresearch,languagemodelsareconceptual- datasetcomprisinghigh-quality,linguisticallydiversegrade
izedasfunctionsthatacceptatextualinputcontextandyield schoolmathwordproblemscraftedbyhumanproblemwrit-
a correspondingtextual output. This paradigm is predomi- ers(Cobbeetal.2021).Thissequentialfine-tuningapproach
nantlyinstantiatedthroughtheuseoftransformer-basedar- effectively leverages the broader contextual understanding
chitectures,aconceptintroducedbyVaswanietal.(Vaswani gained from GSM8K, thereby refining the model’s perfor-
et al. 2017) in 2017, which has since revolutionized the manceontheNL4Opttasks.
field of NLP. The quintessential aspect of transformer lan- In the fine-tuning phase, a methodological approach in-
guagemodelsistheirrelianceonself-attentionmechanisms. tegrating Low-Rank Adaptations (LoRA) (Hu et al. 2021)
These mechanisms are designed to encode input contexts with Parameter-Efficient Fine-Tuning (PEFT) (Liu et al.
by weighing the importance of different parts of the input 2022)wasemployed.Thefine-tuningprocessinvolvedcare-
textrelativetoeachother.However,thesemodelsfaceano- fullyadjustingthe low-rankmatricesintroducedby LoRA,
tablelimitationinprocessinglongtextsequencesduetothe ensuring minimal yet strategic changes to the pre-existing
quadraticincreaseincomputationalcomplexitywithlonger weights.Thismethodpreservesthegenerallinguisticunder-
inputs(Devlinetal.2019).Thisleadstoarestrictedcontext standinggainedfrompre-trainingwhile efficientlysteering
window during pre-training,limiting the model’s ability to ittowardthespecializedtaskofmathematicalproblemfor-
maintain and utilize long-term dependencies and integrate mulation.Theeffectivenessofthisapproachisevidentinthe
information from distant text segments. Consequently, this improvedabilitytoparseandtranslatecomplexnaturallan-
impacts the model’s effectivenessin tasks requiring exten- guagedescriptionsintostructuredmathematicalrepresenta-
sive contextual understanding (Brown et al. 2020). To this tions, a crucialrequirementfor the NL4Optdataset. PEFT,
end,our experimentsinvestigatethe performanceof LLMs ontheotherhand,extendsthisconceptbyfocusingonselec-
in zero-shot and one-shot pre-trained settings, alongside a tivelyfine-tuningasmallsubsetoftheparameters.Byadopt-
smallerLLM, specificallyfine-tunedforthe task ofmathe- ingPEFT,thefine-tuningprocessbecomescomputationally
maticalformulationofoptimizationproblems. less demanding and more feasible on standard hardware,
For this purpose, we evaluate GPT-3.5, GPT-4, and whilestillachievingperformancecomparabletofull-model
Llama-2-7bmodels.Asfine-tuningisnotaprerequisitefor fine-tuning.ThesynergybetweenLoRA andPEFT infine-
inference in these LLMs, our approach centers on the de- tuningLlama-2-7bisparticularlyeffectiveinaddressingthe
velopmentofoptimalpromptinstructionsforbothzero-shot challengesoflargemodeladaptationtospecifictasks.
and one-shot settings. This development is guided by the Furthermore,the inclusionof Noisy EmbeddingInstruc-
prompt optimization techniques delineated in (Yang et al. tionFine Tuning(NEFTune)(Jain etal. 2023)furtheraug-
2023).Additionally,toexploretheimpactoffine-tuningon mented the fine-tuning process. NEFTune, by integrating
a task-specific dataset, we selected the Llama-2-7b model, controlledrandomnoiseintotheembeddingvectorsduring
primarilyduetoitscomparativelylowerresourcedemands. trainingpreventsthemodelfromoverfittingtothespecifics
Thismodelwasfine-tunedusingtheNL4Optdataset,allow- ofthetrainingdataset, suchasformattingdetailsandexact
ingforanin-depthanalysisoffine-tuningeffectsonmodel wording. Instead, it encourages the model to generate re-
performancewithinthisspecificcontext.Optimizedinstruc- sponsesthataremorecoherent,longer,andmorediverse.A
tions for fine-tuning, zero-shot, and one-shot prompts are detailedconfigurationofourexperimentalsetupisdescribed
providedinFigure2. inthefollowingsubsection.ProblemDescription
Ahotelemployscleanersandreceptionists.
IntermediateRepresentation
Cleanersearn$500perweekandreception-
istsearn$350perweek.Thehotelrequires Variables:cleaners,receptionists
CanonicalForm
aminimumof100workersofwhomatleast Constraints:
20must bereceptionists. Tokeep thehotel (−1.0)∗cleaners+(−1.0)∗receptionists≤−100.0 [[-1.0,-1.0,-100.0],
cleanandrunning smoothly, thenumber of (−0.0)∗cleaners+(−1.0)∗receptionists≤−20.0 [0.0,-1.0,-20.0],
receptionistsshouldbeatleastathirdofthe (0.33)∗cleaners+(−1.0)∗receptionists≤−0.0 [0.33,-1.0,0.0],
numberofcleaners.Thehotelwantstokeep (500.0)∗cleaners+(350.0)∗receptionists≤30000.0 [500.0,350.0,30000]],
theweeklywagebillbelow$30000.Formu- ObjectiveFunction:
lateanLPtominimizethewagebill. minimize(500.0)∗cleaners+(350.0)∗receptionist [500.0,350.0]
Figure1:TaskRepresentation
Fine-tuningInstruction
Imagine you are acombinatorial optimization problem solver. I will give you a problem description. Your task isto findthe variables,
constraints,andobjectivefunctionsfromthatdescription.Inyourresponse,alltheconstraintsmustbeinthelessthanorequaltoformat.
Yourresponsemustcontainonlythese3parts:-Variables,Constraints,andObjectiveFunction.Theremustbenoextrastringsbeforeor
afterit.
Zero-shotInstruction
Imagine you are acombinatorial optimization problem solver. I will give you a problem description. Your task isto findthe variables,
constraints,andobjectivefunctionsfromthedescription.Iamgivingyouanexampleresponseformat;youroutputshouldbeformatted
likethis.ExampleResponse:
“Variables:cleaners,receptionists
Constraints:
(−1.0)∗cleaners+(−1.0)∗receptionists≤−100.0
(−0.0)∗cleaners+(−1.0)∗receptionists≤−20.0
(0.33)∗cleaners+(−1.0)∗receptionists≤−0.0
(500.0)∗cleaners+(350.0)∗receptionists≤30000.0
ObjectiveFunction:
minimize(500.0)∗cleaners+(350.0)∗receptionist”.
Now,belowistheactualproblemdescriptionthatyouhavetosolve.Inyourresponse,alltheconstraintsmustbeinthelessthanorequal
toformat.Yourresponsemustcontainonlythese3parts:Variables,Constraints,andObjectiveFunction.Theremustbenoextrastrings
beforeorafterit.Problemdescriptiontosolve:
One-shotInstruction
Imagine you are acombinatorial optimization problem solver. I will give you a problem description. Your task isto findthe variables,
constraints,andobjectivefunctionsfromthatdescription.Beforethat,Iamgivingyouanexampleproblemdescriptionandresponsefor
yourunderstanding;Yourresponseshouldbeformattedlikethis.ExampleProblemDescription:
“A hotel employs cleaners and receptionists. Cleaners earn $500 per week and receptionists earn $350 per week. The hotel requires
a minimum of 100 workers of whom at least 20 must be receptionists. To keep the hotel clean and running smoothly, the number of
receptionistsshouldbeatleastathirdofthenumberofcleaners.Thehotelwantstokeeptheweeklywagebillbelow$30000.Formulate
anLPtominimizethewagebill.”
ExampleResponseforthegivenexampleproblem:
“Variables:cleaners,receptionists
Constraints:
(−1.0)∗cleaners+(−1.0)∗receptionists≤−100.0
(−0.0)∗cleaners+(−1.0)∗receptionists≤−20.0
(0.33)∗cleaners+(−1.0)∗receptionists≤−0.0
(500.0)∗cleaners+(350.0)∗receptionists≤30000.0
ObjectiveFunction:minimize(500.0)∗cleaners+(350.0)∗receptionist”.
Now,belowistheactualproblemdescriptionthatyouhavetosolve.Inyourresponse,alltheconstraintsmustbeinthelessthanorequal
toformat.Yourresponsemustcontainonlythese3parts:Variables,Constraints,andObjectiveFunction.Theremustbenoextrastrings
beforeorafterit.Problemdescriptiontosolve:
Figure2:InstructionsetforthePromptstoLLMs
The incorporation of methodologiessuch as progressive tional fine-tuning framework of Large Language Models
fine-tuning, LoRA, PEFT, and NEFTune into the conven- (LLMs) has notably augmented the inferential efficacy oftheLlama-2-7bmodel.Thisstrategicenhancementispartic- LanguageModel k-Shot F1-score
ularlysalientforagenerativelanguagemodelofthisscale,
Baseline(Ramamonjisonetal.2023) - 0.610
withaparametercountofonly7billion,especiallyinintri-
Llama-2-7b 0 0.1259
cate tasks that challenge even more extensive models like
Llama-2-7b 1 0.1022
GPT-3.5 and GPT-4 in their capacity to comprehend and
GPT-3.5 0 0.4381
maintainprolongedandcomplexcontexts.
GPT-3.5 1 0.4928
ExperimentalSetup GPT-4 0 0.6072
GPT-4 1 0.6330
Thefine-tuningoftheLlama-2-7bmodelwasconductedon
an NVIDIA A40 GPU, equipped with 48 GB of VRAM,
Table 2: Performance evaluation of LLMs for opti-
overa spanof7epochs.Thisprocessleveragedthedataset
mization problem formulation. The best performance
divisionsuggestedbythe authorsof NL4Opt(Ramamonji-
in terms of F1-score is highlighted in bold. GPT-3.5
sonetal.2023),segregatingitintotraining,validation,and
evaluation subsets. A batch size of 4 was employed, cou- (gpt-3.5-turbo-0613) and GPT-4 (gpt-4-0613)
pledwithagradientaccumulationstepof1,andtheAdamW models are accessed through OpenAI api1on November 1,
2023. Llama-2-7b model is fine-tuned using the proposed
(Loshchilov and Hutter 2017) optimizer was utilized. The
initial learning rate was set at 3e − 4, with a weight de- LM4OPTframework.
cay factor of 0.001. A random noisy embedding strength
of 5 provided the most satisfactory results during the fine- Model k-Shot Fine-tune NEFTune F1-Score
tuning process. A maximum response sequence length of
200 was designated, under the premise that model outputs 0 × × 0.0036
would not exceed this threshold for this specific task. Fur- 0 N × 0.0617
thermore, the implementation of Gradient Checkpointing 1 N × 0.0581
Llama-2-7b 0 N X 0.0770
(Chenetal.2016)facilitatedamoreresource-efficientfine-
1 N X 0.0693
tuningframework.
0 P X 0.1259
Anadditionalaspectofthisresearchinvolvedestimating
1 P X 0.1022
the carbon footprint associated with the fine-tuning phase,
guided by the methodology proposed by Lannelongue et
al. (Lannelongue, Grealey, and Inouye 2021). This analy- Table 3: Performance comparison of fine-tuned Llama-
sisrevealedthateachfine-tuningsessionoftheLlama-2-7b 2-7b. ‘N’ in the ‘Fine-tune’ column represents non-
modelproducedapproximately23.52gramsofCO2 emis- progressive fine-tuning, whereas, ‘P’ refers to progressive
sions.Notably,thisfindingunderscorestherelativelymod- finetuning.Thebestperformanceishighlightedinbold.
est environmentalimpact of fine-tuning the modelfor spe-
cializedtasks.
0.6330.ThissuperiorperformancecanbeattributedtoGPT-
ResultandDiscussion 4’sadvancedarchitectureandlargerdatasettraining,assug-
A comprehensive assessment of various LLMs was con- gestedbyrecentstudiesemphasizingthe enhancedcontex-
ducted,focusingontheircapabilityinformulatingoptimiza- tualunderstandingandresponseaccuracyinmoreextensive
tion problems.This evaluationwas based on prompt-based models(OpenAI2023).Conversely,Llama-2-7b,despitebe-
zero-shot and one-shot learning experiments. The perfor- ing a smaller model, shows notable performance improve-
mancesoftheseLLMsweremeticulouslycomparedagainst mentsinthezero-shotsettingcomparedtoone-shot,which
the established baseline provided by Ramamonjison et al. alignswith the findingsthatsmallermodelsmightstruggle
(Ramamonjison et al. 2023), as detailed in Table 2. For a withlongercontextprompts.
consistentandobjectiveassessment,thesamescoringmech- Table 3 showcases the performance comparison of the
anism employedin the baseline evaluationby Ramamonji- Llama-2-7b model under various fine-tuning conditions. It
sonetal.wasadopted.Thisapproachensuresafairanddi- assesses the F1-Score across different configurations, in-
rectcomparisonoftheperformanceofLLMsrelativetothe cluding zero-shot and one-shot settings (k-Shot), with and
existingbenchmarkinthistask. without fine-tuning, and the application of Noisy Embed-
The baseline performance in Table 2 is derived from a dings Fine-tuning (NEFTune). Notably, progressive fine-
fine-tuned BART (Lewis et al. 2019) model, which oper- tuningusingtheLM4OPTframework(P),especiallyinthe
atesunderdifferentinputconditionscomparedtotheLLMs. zero-shot setting, significantly enhances the performance,
While LLMs like Llama-2 and GPT receive instruction achievingthehighestF1-Scoreof0.1259.Thisindicatesthe
prompts and problem descriptions in natural language, the efficacyofprogressivefine-tuningcombinedwithNEFTune
baseline BART model is also provided with named en- in improving the ability to understand and solve optimiza-
tity information extracted from the natural language prob- tion problems, as opposed to non-progressive fine-tuning
lemdescriptions.Thisadditionaldatapotentiallycontributes (N)andthebaselinewithoutanyfine-tuning.
to the baseline’s competitive F1-score of 0.61. The GPT-4 A notable observation from Table 3 is the superior out-
model, especially in the one-shotsetting, outperformsoth-
ers,includingthebaselineandGPT-3.5,withanF1-scoreof 1https://platform.openai.com/docs/modelscomesinzero-shotsettingscomparedtotheirone-shotcoun- Limitations
terpartsacrossallconfigurations.Thisphenomenoncouldbe
In this study, certain limitations have been identified that
attributedtothehypothesisthatasmallermodellikeLlama-
bear on the research outcomes. A noticeable constraint
2-7bstruggleswith longercontexts.The data suggeststhat
within the dataset utilized for this research is its composi-
inscenariosinvolvingextendedcontexts,themodeltendsto
tionofstraightforward,formallystructuredsamplesreplete
exhibit behavior indicative of hallucinations and produces
with specific optimization domain terminologies like ‘for-
repetitive responses that lack coherence with the broader
mulateanLP.’Thisframeworkdivergesfromouroverarch-
context.Suchpatternsreinforcethenotionthatsmallermod-
ing aim to assess the efficacy of LLMs in interpreting and
elsmayfacechallengesinmaintainingconsistencyandrel-
formulating optimization problems as presented in natural
evanceinresponsesasthepromptlengthincreases,acritical
languagebyindividualsunversedindomain-specificjargon.
considerationinoptimizingmodelperformanceforcomplex
It is posited that this dataset limitation might yield a dis-
tasks.
crepancy between the documented performance of LLMs
and their practical application by domain-agnostic users.
EffectofProgressive Fine-tuning Moreover,resource constraints impeded the exploration of
progressive fine-tuning effects on larger LLMs, such as
As shown in Table 3, fine-tuning specifically for instruc- Llama-2-70b and GPT-3.5, which may have offered addi-
tion processing significantly enhanced the performance of tionalinsights.Furthermore,theadoptionofarule-basedap-
the Llama-2-7b model. Initially, the pre-trained Llama-2- proachforconvertingintermediaterepresentationstocanon-
7b, in both zero-shot and one-shot settings, exhibited sub- ical forms has its drawbacks. Upon meticulous review, it
stantial hallucination. A notable example of this was the wasobservedthatsomeLLM-generatedintermediaterepre-
modelgeneratingtwodistinctsetsofvariableswithinasin- sentationswereinaccuratelyformatted,leadingtocanonical
gleresponse,anditsoutputformatoftendidnotalignwith formsthatdivergedfromthegroundtruth.Whilethesedis-
thegivenpromptinstructions,asdemonstratedinFigure3. crepanciesinfluencedtheLLMs’performancemetrics,itis
However,theperformancesignificantlyimprovedafterpro- conjecturedthatsuchnuanceswouldbewithinhumaninter-
gressively fine-tuning the model. As it is evident from the pretive capabilities, suggesting that a collaborativehuman-
responsesamples,theperformanceofthefine-tunedLlama- modelapproachmightcounterbalancethe observedperfor-
2-7bmodelsignificantlydeclinedduetoitsinabilitytocon- mancedegradationlinkedtoformatconversions.Theinter-
sistently maintain a specific response format. It is hypoth- action between what the model producesand how humans
esized that involving human evaluators or a human-in-the- understandithighlightsanimportantareaforfuturestudies.
loopapproachforminormodificationstotheoutputscould Itemphasizestheneedtoharmonizemachineprecisionwith
significantlyimproveitsefficiency.Suchinterventionscould humanjudgment.
potentially bring the performance of a smaller model like
Llama-2-7bclosertothatofsomeofthelargermodels. Conclusion
In this study, we undertooka comprehensiveevaluation of
LLMs such as GPT-3.5, GPT-4, and Llama-2-7b, focusing
DoesIncreasedInstructionLengthAlways
ontheirabilitytotranslatenaturallanguagedescriptionsinto
EnhancePerformance?
mathematicalformulationofoptimizationproblems.There-
searchhighlightsthatwhileGPT-4exhibitssuperiorperfor-
Upon a thorough examination of the results and the out-
mance in both zero-shot and one-shot scenarios, there is a
puts from both GPT and Llama models, it became evi-
notablecapabilitygapwithsmallermodelslikeLlama-2-7b,
dentthatlongerinstructionsdonotuniversallyenhancere-
particularlyinhandlingcomplexcontexts.Progressivefine-
sponses across all models. The study noted that extended,
tuningofLlama-2-7b,especiallywithnoisyembeddingsand
detailed instructions were beneficial for larger models like
specialized datasets using our proposed LM4OPT frame-
GPT-3.5 and GPT-4. Longer instructions aided GPT-3.5
work,significantlyenhancesitsperformance.Thesefindings
and GPT-4 in resolving parsing issues common in scenar-
contribute to understandingthe capabilities and limitations
ios where multiple formulations are correct but are scored
of LLMs in a novel application area, paving the way for
differently due to manual parsing in the scoring mecha-
future improvements in the field of optimization and OR.
nism. By specifying the solution format, these larger mod-
Drawing upon the foundationalresearch by Teshnizi et al.
els were guided to respond in a particular way. For in-
(AhmadiTeshnizi,Gao,andUdell2023),thisstudylaysthe
stance, GPT-3.5 in a zero-shot setting produced the equa-
groundworkforfutureextensions,whereintheintermediate
tion large ≤ small , whereas in a one-shot set-
ting, it gens eh ri ap ts edlarge ship −s small ≤ 0. The latter mathematicalrepresentationsderivedfromnaturallanguage
ships ships descriptions in this research could serve as precursors for
formulation,afterparsing,yieldedahigherscore.However,
LLMstogenerateILPsolvercodeinPython.
with Llama-2-7b, a smaller model, longer instructions led
to issues such as repetition and hallucination, particularly
References
noticeable in one-shot settings. As illustrated in Figure 4,
Llama-2-7b not only repeated parts of the instructions but AhmadiTeshnizi, A.; Gao, W.; and Udell, M. 2023. Opti-
alsogeneratednonexistentvariablessuchasx1,x2,x3,de- MUS:OptimizationModelingUsingmipSolversandlarge
viatingfromtheoriginalproblemdescription. languagemodels. ArXiv,abs/2310.06116.Pre-trained
###Solution
“‘
Variables:thin,stubby
Constraints:
(50.0)∗thin+(90.0)∗baking<=3000.0
(30.0)∗thin+(150.0)∗baking<=4000.0
(5.0)∗thin+(9.0)∗baking<=0.0
(5.0)∗thin+(9.0)∗baking<=0.0
ObjectiveFunction:
maximize(5.0)∗thin+(9.0)∗baking
Fine-tuned
“‘
###Solution ExampleResponse:“Variables:thinjar,stubbyjar
“‘ Constraints:
Variables:cleaners,receptionists (50.0)∗thinjar+(30.0)∗stubbyjar<=3000.0
Constraints: (90.0)∗thinjar+(150.0)∗stubbyjar<=4000.0
(−1.0)∗cleaners+(−1.0)∗receptionists<=−100.0 ObjectiveFunction:
(−0.0)∗cleaners+(−1.0 maximize(5.0)∗thinjar+(9.0)∗stubbyjar”
Figure3:Sampleresponsefrompre-trainedandfine-tunedLlama-2-7b.Hallucinatingbehaviorishighlightedinred.
Looping
Response:“Variables:apple,pear
Constraints:
(−1.0)∗apple+(−0.0)∗pear≤−5.0
(−0.0)∗apple+(−1.0)∗pear≤−10.0
(1.0)∗apple+(−0.0)∗pear≤−0.0
Hallucination
(1.0)∗apple+(2.0)∗pear≤0.0
ObjectiveFunction:maximize(2.0)∗apple+(4.0)∗pear”. Variables:x1,x2,x3
##Part2:AneasyLPInthispart,youaregivenaproblemdescriptionandyouhaveto Constraints:
findthevariablesandconstraints.Yourresponsemustbeinthefollowingformat: (−1.0)∗x1+(−0.0)∗
Figure 4: Looping Behavior and Hallucinationfor few-shot instructions in Llama-2-7b.The repetitiveand hallucinating
behaviorsarehighlightedinred.
Brown,T.B.;Mann,B.;Ryder,N.;Subbiah,M.;Kaplan,J.; LanguageUnderstanding.InNorthAmericanChapterofthe
Dhariwal,P.;Neelakantan,A.;Shyam,P.;Sastry,G.;Askell, AssociationforComputationalLinguistics.
A.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan,
Hu,J.E.;Shen,Y.;Wallis, P.;Allen-Zhu,Z.;Li,Y.;Wang,
T.J.;Child,R.;Ramesh,A.;Ziegler,D.M.;Wu,J.;Winter,
S.; and Chen, W. 2021. LoRA: Low-Rank Adaptation of
C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.;
LargeLanguageModels. ArXiv,abs/2106.09685.
Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford,
Jain, N.; yeh Chiang, P.; Wen, Y.; Kirchenbauer, J.;
A.;Sutskever,I.;andAmodei,D.2020. LanguageModels
Chu, H.-M.; Somepalli, G.; Bartoldson, B.; Kailkhura, B.;
areFew-ShotLearners. ArXiv,abs/2005.14165.
Schwarzschild,A.;Saha,A.;Goldblum,M.;Geiping,J.;and
Chen,T.;Xu,B.;Zhang,C.;andGuestrin,C.2016. Train- Goldstein,T.2023. NEFTune:NoisyEmbeddingsImprove
ing Deep Nets with Sublinear Memory Cost. ArXiv, InstructionFinetuning. ArXiv,abs/2310.05914.
abs/1604.06174.
Karmarkar,N.1984. Anewpolynomial-timealgorithmfor
Cobbe, K.; Kosaraju, V.; Bavarian, M.; Chen, M.; Jun, H.; linearprogramming. Combinatorica,4:373–395.
Kaiser,L.;Plappert,M.;Tworek,J.;Hilton,J.;Nakano,R.;
Lannelongue,L.; Grealey,J.; and Inouye,M. 2021. Green
Hesse, C.; and Schulman, J. 2021. Training Verifiers to
algorithms:quantifyingthecarbonfootprintofcomputation.
SolveMathWordProblems. ArXiv,abs/2110.14168.
Advancedscience,8(12):2100707.
Dakle, P.; Kadiog˘lu, S.; Uppuluri, K.; Politi, R.; Ragha- Laskar, M. T. R.; Hoque, E.; and Huang, J. 2021. Do-
van,P.;Rallabandi,S.K.;andSrinivasamurthy,R.S.2023. main Adaptation with Pre-trainedTransformersfor Query-
Ner4Opt:NamedEntityRecognitionforOptimizationMod- Focused Abstractive Text Summarization. Computational
ellingfromNaturalLanguage. InIntegrationofAIandOR Linguistics,48:279–320.
TechniquesinConstraintProgramming.
Lewis, M.; Liu, Y.; Goyal, N.; Ghazvininejad, M.; rahman
Devlin,J.;Chang,M.-W.;Lee,K.;andToutanova,K.2019. Mohamed,A.;Levy,O.; Stoyanov,V.; andZettlemoyer,L.
BERT:Pre-trainingofDeepBidirectionalTransformersfor 2019.BART:DenoisingSequence-to-SequencePre-trainingforNaturalLanguageGeneration,Translation,andCompre-
hension. InAnnualMeetingoftheAssociationforCompu-
tationalLinguistics.
Li, B.; Mellou, K.; qing Zhang, B.; Pathuri, J.; and Men-
ache, I. 2023. Large Language Models for Supply Chain
Optimization. ArXiv,abs/2307.03875.
Liu, H.; Tam, D.; Muqeeth, M.; Mohta, J.; Huang, T.;
Bansal, M.; and Raffel, C. 2022. Few-Shot Parameter-
EfficientFine-TuningisBetterandCheaperthanIn-Context
Learning. ArXiv,abs/2205.05638.
Loshchilov,I.;andHutter,F. 2017. DecoupledWeightDe-
cayRegularization. InInternationalConferenceonLearn-
ingRepresentations.
Nash,J.C. 2000. The(Dantzig)simplexmethodforlinear
programming. Comput.Sci.Eng.,2:29–31.
OpenAI. 2023. GPT-4 Technical Report. ArXiv,
abs/2303.08774.
Ramamonjison, R.; Yu, T. T.; Li, R.; Li, H.; Carenini,
G.; Ghaddar, B.; He, S.; Mostajabdaveh, M.; Banitalebi-
Dehkordi, A.; Zhou, Z.; and Zhang, Y. 2023. NL4Opt
Competition: Formulating Optimization Problems Based
on Their Natural Language Descriptions. ArXiv,
abs/2303.08233.
Suzgun,M.;Scales,N.;Scharli,N.;Gehrmann,S.;Tay,Y.;
Chung, H. W.; Chowdhery, A.; Le, Q. V.; hsin Chi, E. H.;
Zhou,D.;andWei,J.2022. ChallengingBIG-BenchTasks
andWhetherChain-of-ThoughtCanSolveThem.InAnnual
MeetingoftheAssociationforComputationalLinguistics.
Touvron, H.; Martin, L.; Stone, K. R.; Albert, P.; Alma-
hairi, A.; Babaei, Y.; Bashlykov, N.; Batra, S.; Bhargava,
P.; Bhosale, S.; Bikel, D. M.; Blecher, L.; Ferrer, C. C.;
Chen,M.;Cucurull,G.;Esiobu,D.;Fernandes,J.;Fu,J.;Fu,
W.;Fuller,B.;Gao,C.;Goswami,V.;Goyal,N.;Hartshorn,
A. S.;Hosseini,S.;Hou,R.; Inan,H.;Kardas,M.;Kerkez,
V.; Khabsa, M.; Kloumann, I. M.; Korenev, A. V.; Koura,
P.S.;Lachaux,M.-A.;Lavril,T.;Lee,J.;Liskovich,D.;Lu,
Y.; Mao, Y.; Martinet, X.; Mihaylov, T.; Mishra, P.; Moly-
bog, I.; Nie, Y.; Poulton, A.; Reizenstein, J.; Rungta, R.;
Saladi,K.;Schelten,A.;Silva,R.;Smith, E.M.;Subrama-
nian,R.;Tan,X.;Tang,B.;Taylor,R.;Williams,A.;Kuan,
J. X.; Xu, P.; Yan, Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kam-
badur,M.; Narang,S.; Rodriguez,A.; Stojnic, R.; Edunov,
S.; and Scialom, T. 2023. Llama 2: Open Foundation and
Fine-TunedChatModels. ArXiv,abs/2307.09288.
Tsouros,D.C.;Verhaeghe,H.;Kadiouglu,S.;andGuns,T.
2023. HolyGrail2.0:FromNaturalLanguagetoConstraint
Models. ArXiv,abs/2308.01589.
Vaswani, A.; Shazeer, N. M.; Parmar, N.; Uszkoreit, J.;
Jones,L.;Gomez,A.N.;Kaiser,L.;andPolosukhin,I.2017.
AttentionisAllyouNeed. InNeuralInformationProcess-
ingSystems.
Yang, C.; Wang, X.; Lu, Y.; Liu, H.; Le, Q. V.; Zhou, D.;
andChen,X.2023. LargeLanguageModelsasOptimizers.
ArXiv,abs/2309.03409.