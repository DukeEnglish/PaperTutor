Composite Distributed Learning and Synchronization of Nonlinear
Multi-Agent Systems with Complete Uncertain Dynamics
Emadodin Jandaghi, Dalton L. Stein, Adam Hoburg, Mingxi Zhou and Chengzhi Yuan
Abstract—This paper addresses the challenging problem of of multiple robots. [9] explored a virtual leader-follower
composite synchronization and learning control in a network strategy for robot manipulators under uncertainties and dis-
of multi-agent robotic manipulator systems operating under
turbances. While a high-gain observer was used for velocity
heterogeneous nonlinear uncertainties within a leader-follower
estimation, this approach risks exciting unmodeled high-
framework. A novel two-layer distributed adaptive learning
control strategy is introduced, comprising a first-layer dis- frequency dynamics and magnifying measurement noise.
tributedcooperativeestimatorandasecond-layerdecentralized Suchissuesmakecontrollerimplementationchallengingand
deterministic learning controller. The primary objective of necessitate meticulous parameter tuning. Another drawback
the first layer is to facilitate each robotic agent’s estimation
in the existing literature is the assumption of homogeneous
of the leader’s information. The second layer is responsible
systemdynamicsacrossallrobots,whichisoftennotthecase
for both enabling individual robot agents to track desired
reference trajectories and accurately identifying and learning in real-world applications. Meanwhile, [10] ignored system
their nonlinear uncertain dynamics. The proposed distributed uncertainties and assumed full model knowledge. Further-
learning control scheme represents an advancement in the more, while some research has considered non-identical
existing literature due to its ability to manage robotic agents
robotic systems [9], others [11] mostly focused solely on
with completely uncertain dynamics including uncertain mass
achieving adaptive tracking control, without consideration
matrices. This framework allows the robotic control to be
environment-independentwhichcanbeusedinvarioussettings, for the convergence of controller parameters to their optimal
from underwater to space where identifying system dynamics states.Neuralnetworkshavebeenemployedtotackleuncer-
parametersischallenging.Thestabilityandparameterconver- tainties, but they also suffer from the unrealistic assumption
gence of the closed-loop system are rigorously analyzed using
of uniform robot dynamics.
the Lyapunov method. Numerical simulations conducted on
Previous literature has not fully tackled the identification
multi-agentrobotmanipulatorsvalidatetheeffectivenessofthe
proposed scheme. The identified nonlinear dynamics can be of all system nonlinearities without certain assumptions.
saved and reused whenever the system restarts. These include having a known Mass or Inertia matrix [12],
using large gains to suppress errors caused by the Coriolis
I. INTRODUCTION andCentripetalforcematrix[8],andassumingastructurally
Robotics has many applications from manufacturing to balanced, signed switching network for multiple systems
surgicalprocedures[1],[2],[3].However,controllingrobots in their adaptive control law [13]. In contrast, our work
in space and underwater is challenging due to unpredictable uniquelyidentifiesthenonlinear,uncertaindynamicsofeach
robot dynamics in such environments. Also, the increasing robotwithoutmakinganyassumptionsaboutthecertaintyor
demand for high precision and operational complexity has structure of each system.
shifted the focus towards cooperatively utilizing multiple In this study, we make a significant step forward com-
standard robots. This approach benefited from improved pared to previous research. This framework is completely
efficiency, cost reduction, and redundancy [4], [5]. Given independent of any multi-agent system attributes, rendering
theseadvantages,numerousstudieshavebeendonetoformu- this method universally applicable to any nonlinear Euler-
late diverse decentralized control strategies for coordinating Lagrange (EL) system dynamics. We tackle the challenges
multiple robotic arms effectively [6]. ofachievingsynchronizationcontrolandintegratinglearning
Despite extensive research, there are several outstanding capabilities into multi-robot systems with heterogeneous
challenges. One persistent challenge is the management of nonlinear uncertain dynamics without any knowledge of
model uncertainties which can impair the performance of each robotic system’s nonlinearities, which operate under a
distributed control systems [7]. Some studies have examined virtual leader-following framework. These robots have the
the role of uncertainties in robotic arm control [8], however, same kinematics and the same degree of freedom but have
these did not extend their findings to the synchronization distinct dynamic system parameters like masses, inertia, and
stiffness.
Emadodin Jandaghi, Dalton L. Stein and Chengzhi Yuan are Our control architecture employs a fixed directed graph
with the Department of Mechanical, Industrial and Systems Engi- communication, with a virtual leader modeled as a Linear
neering, Kingston, RI 02881, USA emadjandaghi@uri.edu;
Time-Invariant (LTI) system. Only select agents access the
daltonstein98@uri.edu; cyuan@uri.edu
Adam Huborg is with the Department of Electrical, Computer leader’s data directly. The control strategy is dual-layered:
and Biomedical Engineering, Kingston, RI 02881, USA The first layer focuses on cooperative estimation, allowing
ajhoburg@uri.edu
agents to have inter-agent communication and share leader-
MingxiZhouiswiththeGraduateSchoolofOceanography,,Kingston,
RI02881,USAmzhou@uri.edu estimatedstatesandsystemmatriceswhilekeepingtheirown
4202
raM
1
]AM.sc[
1v78900.3042:viXraplantdataprivate(i.e.,robot’sposition/velocity).Thesecond A=[a ]∈RN×N, where a =0 and a >0 =⇒ (j,i)∈E.
ij ii ij
layer involves a decentralized adaptive learning controller, The Laplacian of G is denoted as L=[l ]∈RN×N, where
ij
designed to regulate each robot’s state and pinpoint its l =(cid:80)N a and l =−a if i̸=j. It is established that L
ii j=1 ij ij ij
uniquedynamicsusingfirst-layerestimates.Thesecondlayer has at least one eigenvalue at the origin, and all nonzero
operates without any data sharing, allowing each local robot eigenvalues of L have positive real parts. Furthermore, as
toimplementitsadaptivelearningcontrollerinacompletely statedin[14],Lemma3.3,Lhasoneeigenvalueattheorigin
decentralized way. and (N−1) eigenvalues with positive real parts if and only
Our adaptive learning control law uses precise function if G includes a directed spanning tree.
approximation with Radial Basis Function (RBF) Neural
Networks (NN) for the identification of systems with com- B. Radial Basis Function NNs
pletely uncertain dynamics. This enhances control over
The RBF Neural Networks (NN) can be described
robotics in space and underwater environments, where the as f (Z)=(cid:80)N ws(Z)=WTS(Z), where Z ∈Ω ⊆Rq
system dynamics are often unpredictable. We confirm the nn i=1 i i Z
and W =w ,...,wT ∈RN as input and weight vectors
efficacy of the approach through mathematically rigorous 1 N
respectively. N indicates the number of NN nodes,
validation and comprehensive simulation studies. Presenting
S(Z)=[s (||Z−µ||),...,s (||Z−µ||)]T with s(·) is a RBF,
1 i N i i
a thorough convergence analysis for the neural network
and µ(i=1,...,N) is distinct points in the state space.
weights guarantees that the learned nonlinearities are only
The
Gi
aussian function
s(||Z−µ||)=exp(cid:104) −(Z−µi)T(Z−µi)(cid:105)
storedonceandcanbeusedinthecontrollerafterthesystem i i η i2
is generally used for RBF, where µ =[µ ,µ ,...,µ ]T
isturnedoff,eliminatingtheneedforthecontrollertoadjust i i1 i2 iN
is the center and η is the width of the receptive field.
every time the system is restarted. i
The Gaussian function categorized by localized radial basis
The rest of the paper contains the following sections:
function s in the sense that s(||Z−µ||)→0 as ||Z||→∞.
Section II provides an initial overview of graph theory and i i
It has been shown in [15], [16] for any continuous function
RadialbasisfunctionNNs.Distributedcooperativeestimator
f(Z):Ω →R where Ω ⊂Rp is a compact set. For the NN
and decentralized deterministic learning control law are Z Z
approximator,wherethenodenumberNissufficientlylarge,
discussed in Section III. The simulation studies is provided
thereexistsanidealconstantweightvectorW∗,suchthatfor
in Section IV. Finally, Section V concludes the paper.
eachϵ∗>0,f(Z)=W∗TS(Z)+ϵ(Z),∀Z ∈Ω ,whereϵ(Z)
Z
II. PRELIMINARIESANDPROBLEMSTATEMENT is the approximation error. The following lemma describes
A. Notation and Graph Theory the PE (Persistent Excitation) condition for RBF NN from
[17].
We denote the sets of real numbers as R and R+. Rm×n
represents the set of real m×n matrices, and Rn is the set Lemma 1. Consider any continuous recurrent trajectory
of real n×1 vectors. The identity matrix is symbolized as Z(t):[0,∞)→Rq. Z(t) remains in a bounded compact set
I. The vector with all elements being 1 in an n-dimensional Ω ⊂Rq. For RBF NN WTS(Z) with centers placed on a
Z
spaceisrepresentedas1 n.ThesetsSn +andSn −+standforreal regular lattice (large enough to cover compact set Ω Z), the
symmetric n×n and positive definite matrices, respectively. regressor subvector S (Z) consisting of RBFs with centers
ζ
A block diagonal matrix with matrices X ,X ,...,X on its located in a small neighborhood of Z(t) is persistently
1 2 p
main diagonal is denoted by diag{X ,X ,...,X }. The nota- exciting.
1 2 p
tionA⊗BsignifiestheKroneckerproductofmatricesAand
B. For a matrix A, A⃗ is the vectorization of A by stacking C. Problem Statement
its columns on top of each other. Given two integers k and
1 In this paper, we consider a multi-robot manipulator
k with k <k , I[k ,k ]={k ,k +1,...,k }. For a vector
2 1 2 1 2 1 1 2 system of N robots with heterogeneous uncertain nonlinear
x∈Rn, its norm is defined as |x|:=(xTx)1/2. For a square
dynamics described with Euler-Lagrange (EL) mechanical
matrixA, λ(A) denotes its i-theigenvalue,whileλ (A)and
i min systems as:
λ (A) represent its maximum and minimum eigenval-
max
ues, respectively. A directed graph denoted as G=(V,E) M (θ )θ¨ +C (θ ,θ˙ )θ˙ +g (θ )=τ , i∈I[1,N], (1)
i i i i i i i i i i
comprises nodes in the set V ={1,2,...,N} and edges in
E ⊆V ×V.Anedgefromnodeitonodej isrepresentedas where τ ∈Rn is the vector of input signals. The sub-
i
(i,j),withiastheparentnodeandj asthechildnode.Node script i denotes the ith robotic agent. For each i∈I[1,N],
i is also termed a neighbor of node j. N considered as the θ =[θ ,θ ,...,θ ]T ∈Rn are the joint positions, θ˙,θ¨ are
i i i1 i2 in i i
subsetofV consistingoftheneighborsofnodei.Asequence the joint velocities and accelerations, respectively. M ∈Sn
+
of edges in G, (i ,i ),(i ,i ),...,(i ,i ), is called a path is a positive definite mass matrix, C ∈Rn×n is the matrix
1 2 2 3 k k+1
fromnodei tonodei .Nodei isreachablefromnode containing Coriolis and Centripetal forces, g∈Rn is the
1 k+1 k+1
i . A directed tree is a graph where each node, except for a gravity term. It is crucial to note that as opposed to our
1
rootnode,hasexactlyoneparent.Therootnodeisreachable previous work [12], we make no assumptions about the
fromallothernodes.AdirectedgraphGcontainsadirected certainty of any system matrices (M,C, and g) throughout
spanning tree if at least one node can reach all other nodes. designing our distributed controller and consider all system
TheweightedadjacencymatrixofGisanon-negativematrix matricestobeuncertain.Wecanrewritethesystemdynamicsas: III. DISTRIBUTEDADAPTIVECONTROL
x˙ =x
i1 i2 FRAMEWORK
(2)
x˙ =M−1(x )[τ −C (x )x −g (x )]
i2 i i1 i i i i2 i i1 A. First Layer: Distributed Cooperative Estimator
where x = θ , x = θ˙ , and let x be a column vector
i1 i i2 i i In a distributed control setting, each robotic agent can
of x and x . In a leader-follower setting, the leader’s
i1 i2 accessonlyitsowndataandthedataofitsimmediateneigh-
dynamics is:
bors. Consequently, the leader’s parameters, such as χ and
χ˙ 0 =A 0χ 0 (3) 0
A , may not be available to all agents. This constraint leads
0
Here,”0”markstheleadernode.χ 0isacolumnvectorofx 01 ustocreateadistributedcooperativeestimator,enablingeach
andx 02,whicharetheleader’sstates.A 0isaconstantsystem agent to estimate the leader’s state and dynamics through
matrix. Only robots directly linked to the leader have access inter-agent collaboration:
to χ and A . For a multi-robot system with N follower
0 0
N
robots and one leader, we describe an adjacency matrix A χˆ˙ (t)=A (t)χˆ (t)+β (cid:88) a (χˆ (t)−χˆ (t)), ∀i∈I[1,N]
i i i i1 ij j i
and set V = {0,1,...,N}, with ”0” being the leader. We
j=0
make two assumptions, which do not sacrifice generality: (4)
The observer states for each robot, represented by χˆ =
Assumption 1. All eigenvalues of A are imaginary. i
0 [xˆ ,xˆ ]T, are used to estimate the leader’s state χ =
i1 i2 0
Assumption 2. The digraph G has a directed spanning tree [x ,x ]T. β are positive design constant numbers. The
01 02 i1
rooted at node 0. time-varying system parameters Aˆ (t) are updated by the
i
following equation for all i:
Assumption1ensuresallthestatesoftheleaderdynamics
remainperiodicanduniformlybounded.TheLaplacianLof N
thegraphcanbedividedasfollowsusingtheAssumption2: Aˆ˙ i(t)=β i2(cid:88) a ij(Aˆ j(t)−Aˆ i(t)), ∀i∈I[1,N] (5)
j=0
L=(cid:20)(cid:80) −N
j= Φ1
1Na0j −[a01, H...,a0N](cid:21)
The matrices Aˆ
i
are used to estimate the leader’s system
Here, Φ is a diagonal matrix and H has only positive real matrixA andhavedimensionsn×n.Theconstantsβ are
0 i2
parts for its non-zero eigenvalues. The main problem to be allpositivenumbers.Weobservethatonlylocalinformation,
addressed in this paper: such as the observer states χˆ and Aˆ , need to be shared
i i
among neighboring robotic agents. For each agent i in the
Problem 1. Given the robotic system with N agents as
range [1,N], we define the local errors as χ˜ =χˆ −χ and
describedin(2)andaleaderas(3),alongwithAssumption1 i i 0
A˜ = Aˆ −A . This allows us to describe the local error
and Assumption 2, we aim to create a control plan that uses i i 0
dynamics for agent i:
only local data for each robot. The goals are:
χ˜˙ (t)=A χ˜ (t)+A˜ (t)χ˜ (t)+A˜ (t)χ (t)
1) Cooperative Synchronization: All robots should syn- i 0 i i i i 0
N
chronize with the common path set by the leader, (cid:88)
+β a (χ˜ (t)−χ˜ (t)), ∀i∈I[1,N]
meaning lim t→∞(x i1(t)−x 01(t))=0 ∀i∈I[1,N]. i1
j=0
ij j i (6)
2) Decentralized Learning: Each robot should learn its
N
ownnonlinearuncertaindynamicsviaitslocaladaptive A˜˙ (t)=β (cid:88) a −(A˜ (t)−A˜ (t)), ∀i∈I[1,N].
i i2 ij j i
controller using RBF NNs. j=0
Remark 1. Unlike existing works that only focus on syn- Now consider χ˜ = col{χ˜ ,...,χ˜ }, A˜ =
1 N
chronization, our problem also aims for both control and col{A˜ ,...,A˜ }, A˜ = diag{A˜ ,...,A˜ }, B =
1 N b 1 N β1
learning of robotic dynamics. This involves challenges like diag{β ,...,β }, and B =diag{β ,...,β }. Using
11 N1 β2 12 N2
diverse robot behaviors, limited information from the leader, these definitions, the error dynamics for the entire network
and complete uncertain nonlinear dynamics. system are:
A two-layer framework is proposed as follows: χ˜˙(t)=((I ⊗A )−B (H⊗I ))χ˜(t)
N 0 β1 2n
• The first layer uses a distributed estimator to figure out +A˜ b(t)⊗χ˜(t)+A˜ b(t)(1 N ⊗χ 0(t)), (7)
the leader’s state and system information.
A˜˙ (t)=−B (H⊗I )A˜(t).
• The second layer uses a decentralized controller for β2 n
synchronization and learning the local robot dynamics. Here, H is specified in II-C. We rely on Assumptions 1 and
Only the first layer requires data sharing between nearby 2 to support the following Theorem:
robotsandthesecondlayerjustworksonlocaldata.Thenext
Theorem 1. Given the error system (7) and under As-
section will explore each layer. In addition to a Theorem 1
sumptions 1 and 2, for all i ∈ I[1,N] and any initial
on the stability and convergence of the first layer, we
conditions χ (0),χˆ (0),Aˆ (0), we have lim A˜ (t) = 0
will present two crucial theorems. Theorem 2 will address 0 i i t→∞ i
and lim χ˜ (t)=0 exponentially.
the second layer’s learning and control performance, and t→∞ i
Theorem3willcombineinsightsfrombothlayerstoprovide The proof of Theorem 1 is similar to that of [12], which
conclusions. will be omitted here to save some space.B. Second Layer: Decentralized Deterministic Learning whereΓ andσ arepositiveconstantnumberswithσ being
i i i
Control very small, r represents the jth element of r . Substituting
ij i
(11), (12) and (13) into (8) for all i∈I[1,N] yields:
This section introduces our new decentralized determinis-
ticlearningcontrollawdesignedtoimprovesynchronization r˙ =M−1(x )(W˜TS (χ )−ϵ (χ)−K r −C (x ,x˙ )r ) (15)
i i i i i i i i i i i i i
performance. Given that the leader’s state information χ
0 where W˜ := Wˆ −W∗. Based on (14) and (15), we have
is unavailable to all robotic agents, χˆ will serve as the i i i
i
the following theorem.
tracking reference signal for tracking control design and
implementation for each agent. Additionally, all system Theorem 2. Given systems (14) and (15).If there ex-
matrices for each agent are considered to be unstructurally ists a sufficiently large compact set Ω such that
χi
uncertain. Meaning, unlike in previous studies, we make no χ ∈Ω ∀i∈I[1,N],thenforanybounded initialconditions
i χi
assumptions about agents’ system structures, and the track- withWˆ (0)=0(∀i∈I[1,N])wehave:(i)allthesignalsinthe
i
ing controller is implemented independently on each agent. system remain uniformly bounded; (ii) the position tracking
Therefore, the learning control objective is met when each error x −xˆ converges exponentially to a small neighbor-
i1 i1
agent’s system states x converge to the tracking reference hood around the origin, by choosing the design parameters
i
signalχˆ iinadecentralizedmanner.Forthestabilityanalysis, with K i∈Sn
+
∀i∈I[1,N]. (iii) along the system trajectory
we implement the EL system property below: denoted by φ(χ(t))| starting from T which represents
i t≥Ti i
the settling time of tracking control, the local estimated
Property 1. The Matrix M˙ (θ)−2C(θ,θ˙) is Skew-
i i i i i neural weights Wˆ converge to small neighborhoods close
symmetric which means 1M˙ (θ)=2C(θ,θ˙). iψ
2 i i i i i to the corresponding ideal values W∗, and locally-accurate
iϕ
To introduce the decentralized deterministic learning con- identificationofnonlinearuncertaindynamicsdefinedin(11)
trollaw,considertheithroboticagentwithareferencesignal canbeobtainedbyWˆTS(χ)aswellasW¯TS(χ)alongthe
i i i i i i
in its controller as x˙ and x¨ , while assuming a filtered system trajectory ψ(χ(t))| , where
ri ri i t≥Ti
output signal r be:
i W¯T =mean Wˆ (t), ∀i∈I[1,N], (16)
i t∈[tia,tib] i
r =x˙ −x˙
i i1 ri (8) with [t ia,t ib](t ib>t ia>T i) being a time segment after the
=e˙ +λ e ∀i∈I[1,N]
i i i transient period of tracking control.
where λ>0 and e ∈Rn is the position tracking error:
i Proof. (i) Given the systems (14) and (15) consider the
e i =x i1−xˆ i1, ∀i∈I[1,N] (9) following Lyaponuv function candidate,
n
Therefore: V =
1
rTM (x )r +
1(cid:88)
W˜TΓ−1W˜ . (17)
i 2 i i i i 2 ij ij
x˙ =xˆ˙ −λ(e ) ∀i∈I[1,N] (10) j=1
ri i1 i
Temporal differentiation of (17) yields,
where x˙ ri2 is the second derivative of reference signal with: V˙ =rTM (x)r˙ + 1 rTM˙ (x)r +(cid:88)n W˜˙ TΓ−1W˜ . (18)
M (x )x¨ +C (x ,x˙ )x˙ +g (x )=H (χ ) (11) i i i i 2 i i i ij i ij
i i1 ri i i i ri i i i i j=1
whereχ =col{x,x˙,x˙ ,x¨ }.Theunknownnonlinearfunction Exploiting (15) and the assumption in Property 1 in (18)
i r r
H (χ ) is aimed to be approximated using the universal yields
i i
approximationcapabilityofRBFNN.Specifically,according V˙ =−rTK r −rTϵ(χ )+rTW˜TS (χ)
to II-B, there exist RBF NNs W∗TS (χ ) such that i i i i i i i i i
i i i +(cid:88)n W˜˙ TΓ−1W˜ . (19)
H (χ )=W∗TS (χ )+ϵ (χ ) ∀i∈I[1,N] (12) ij i ij
i i i i i i i j=1
with W i∗ as the ideal constant weights, and |ϵ i(χ i)| ≤ ϵ∗ i Utilizing the fact that W˜˙ =Wˆ˙ in (14), and substituting (14)
is the ideal approximation errors which can be made arbi- into (19),
trarily small given the sufficiently large number of neurons.
Assuming Wˆ as the estimate of W∗, we construct the V˙ i =−r iTK ir i−r iTϵ(χ i)+r iTW˜ iTS i(χ i)
implementablei decentralized determinii stic learning control +(cid:88)n (cid:16) −Γ [S (χ )r +σ Wˆ ](cid:17)T Γ−1W˜
i ij i ij i ij i ij
law as: (20)
j=1
n
τ i =Wˆ iTS i(χ i)−K ir i, ∀i∈I[1,N]. (13) =−r iTK ir i−r iTϵ(χ i)−(cid:88) σ iWˆ iT jW˜ ij
where WˆTS (χ ) = [WˆTS (χ ),...,WˆTS (χ )]T and j=1
K ∈Rn×i n ai re ui sed to api p1 roi x1 imai te the uni kn noi wn n ni onlinear now, we select K i=K i1+K i2 with K i1 and K i2 being
i
positive definite to yield:
function vector H (χ ). A robust self-adaptation law for
i i
online updating Wˆ i is constructed as: V˙ =−rTK r −rTK r −rTϵ(χ )−
i i i1 i i i2 i i i
Wˆ˙ ij =−Γ i[S ij(χ i)r ij+σ iWˆ ij] (14) (cid:88)n σ iWˆ iTjW˜ ij. (21)
∀i∈I[1,N] and ∀j ∈I[1,n].
j=1As a result, we have for all i∈I[1,N] and j ∈I[1,n]: Where
2λ (K )
−σ iWˆ iTjW˜ ij =−σ i(W˜ ij+W i∗ j)TW˜ ij ρ i =min{2λ min(K i1), λmin (Mi1 ) }
max i
≤−σ iW˜ i2 j−σ iW˜ ijW i∗ j (22) δ∗2 W˜∗2s∗2
≤−σ 2i∥W˜ ij∥2+ σ 2i∥W i∗ j∥2. δ i = 4λ mini (K i2) + 4λ mi in(Ki i2).
Using the same approach we have: Solving 30 gives us:
−rTK r −rTϵ ≤
ϵT
i
ϵ
i ≤
||ϵ∗ i||2
. (23)
0≤V ri(t)≤V ri(0)exp(−ρ it)
i i2 i i i 4λ (K ) 4λ (K ) δ (31)
min i2 min i2 + i, ∀t≥0,∀i∈I[1,N]
ρ
Based on (22) and (23), we conclude: i
||ϵ∗||2 fromtheabovesolutions,itbecomesclearthatthereexistsa
V˙ i ≤−r iTK i1r i+ 4λ mini (K i2) finite time T i>0 such that r i will exponentially converge to
n n (24) asmallareanearzero.Thisfurtherconfirmsthatthetracking
−
1(cid:88)
σ ∥W˜ ∥2+
1(cid:88)
σ ∥W∗∥2. ∀i∈I[1,N] errors e will also reach a small zone around zero. The size
2 i ij 2 i ij i
j=1 j=1 of this zone can be minimized by carefully choosing the
Based on (24), and given that K i1 is positive definite, we design parameters K i1 with λ min(K i1)>0. This completes
can conclude that V˙ is negative definite under the condition the proof for the second part of the Theorem.
i
that: (iii): From the above proof of the second part, it has been
∥ϵ∗∥
∥r ∥> i + established that for all i∈I[1,N], there exists a finite time
i (cid:112)
2λ min(K i1)λ min(K i2) T
i
> 0 such that for all t≥T i, the tracking errors e
i
as
(cid:115) (25)
2σ i (cid:88)n ∥W∗∥ well as r i will converge to a vicinity near zero. Because
λ min(K i1) ij e i=x i1−xˆ i1, xˆ i1 will eventually converge to x 01 as per
j=1 Theorem 1, and x is a periodic signal under Assumption
01
or (cid:88)n ∥W˜ ∥> ∥ϵ i∥ +(cid:88)n ∥W∗∥. ∀i∈I[1,N] 1, x i1 will also become a periodic signal after a finite time
j=1
ij (cid:112) 2σ iλ min(K i2)
j=1
ij T i. Furthermore, while e i converges to zero, e˙ i converges to
zero,leadingx convergestox .Sincetheleaderdynamics
i2 02
The signals r i and W˜ ij are bounded, leading to boundedness isasmoothcontinuousLTIsystem,periodicityofx 01implies
of W˜ ij. As a result, Wˆ ij is also bounded. Given that the that x˙ 01 is also periodic and thus x i2 is periodic after a finite
regressor vector S ij(χ i) is bounded according to [18], the timeT i.Consequently,theinputsofRBFNNs(χ i)aremade
feedback control law τ i from (13) is bounded as well. as periodic signals for all t≥T i. According to Lemma 1,
This ensures boundedness for all signals in the closed-loop the partial PE condition of the localized RBF NN regression
system, thereby proving the first part. subvector S (χ) along the system trajectory ϕ(χ(t)| is
iϕ i i i t≥Ti
(ii) For the second part of the proof, we examine the guaranteed.
Lyapunov function for the dynamics of r given by (15) as,
i
WˆTS (χ )=WˆTS (χ )
1 i i i iϕ iϕ i
V ri = 2r iTM i(x i1)r i. (26) +Wˆ iT ϕ¯S iϕ¯(χ i), ∀i∈I[1,N]
Temporal differentiation of (26) and substituting in (15) for Accordingly, system dynamics of (19) can be expressed as:
M(θ)r˙ yields,
i i
V˙ =−rTK r +rTW˜TS (χ )−ϵTr . ∀i∈I[1,N] (27)
r˙
i
=M i−1(x i1)(W(cid:102)iT ϕS iϕ(χ i)−K ir i−C i(χ i)r i−ϵ′ iϕ),
ri i i i i i i i i i ∀i∈I[1,N]
Usinganapproachsimilartotheoneusedforinequality(23),
and by setting K i=K i1+2K i2, we can demonstrate: where ϵ′ iϕ=ϵ i−Wˆ iT ϕ¯S iϕ¯(χ i) is the localized ideal NN ap-
proximation error along the tracking trajectory. Thus, the
ϵ2
−rTK r −rTϵ ≤ i overall closed-loop adaptive learning system can be de-
i i2 i i i 4λ (K )
min i2 (28) scribed by:
ϵ∗2
−r iTK i2r i+ ≤≤ r 4i λW W˜4 ˜ mλ iT i i∗m n2S (i sn Kii ∗ i(( 2χ iK 2i )i )2 ,), ∀i∀ ∈i∈ I[1I ,[1 N,N ].] (29)          W(cid:102)W W(cid:102) (cid:102) ˙˙ ˙r˙ ii i ... ϕi ϕ ϕ ,, , n1 2        =           

− − −M Γ Γi ii− S S1 i i( ϕ ϕ ...x , ,1 2i ( (1 χ χ)K i i) )i M i−1(xi1)    S iT ϕ,1 0 0...(χi) S 0iT ϕ,2 00 ...(χi) .0 00 .. S iT ϕ,n0 0 ... (χi)               


In this case, s∗
i
is a fixed positive number so that −ΓiSiϕ,n(χi)
||S(χ)||≤s∗ for all i∈I[1,N]. The existence of such a s∗
is
ci oni firmedi
by [18]. Therefore, we arrive at:
i  ri  −M i−1(xi1)ϵiϕ
 W(cid:102)iϕ,1



−ΓiσiW(cid:99)iϕ,1 

V˙ ri ≤−r iTλ min(K i1)r i+δ i (30) ×    W(cid:102)i ...ϕ,2    +   

−Γiσi ...W(cid:99)iϕ,2     ,∀i∈I[1,N] (32)
≤−ρ iV ri+δ i, ∀i∈I[1,N] W(cid:102)iϕ,n −ΓiσiW(cid:99)iϕ,ninmulti-agent/multi-robotliterature:achievingbothsynchro-
   



W(cid:102)W W(cid:102) (cid:102) ˙˙ ˙ ii i
...
ϕϕ ϕ ¯¯ ¯ ,, , n1 2   


=  


−− − ΓΓ Γ ii i (( ( SS S ii i ϕϕ ϕ ¯¯ ¯ ,, , n1 2( ( (χ χ χi i i) ) )...r rri i i+ + +σ σ σi i iW W Wˆ ˆ ˆi i iϕ ϕ ϕ¯ ¯ ¯, , ,n1 2) ) )  

,∀i∈I[1,N] (33) n n roi oz bna olt i ti no men a ara nn iu pd n uc la e ac r totc a ru i sr n .at de ynid ae mn it cifi sc fa ot rio an/l te ea ar mnin og f ho ef tec ro om gep nle et oe uly s
IV. SIMULATION
Based on [18], the local approximation error ϵ′ and
iϕ The multiple 2-DOF robot manipulator system, as de-
WˆTS (χ) are both small. Moreover, ϵ′ is proportional to
iϕ¯ iϕ¯ i iϕ scribed in (2), is considered with parameters:
ϵ . Studies [18] [19] have thoroughly examined the stability
i
(cid:20) (cid:21) (cid:20) (cid:21)
and convergence of the closed-loop system given by (27). M (q )= M i11 M i12 , C (q ,q˙ )= C i11 C i12 ,
i i M M i i i C C
Specifically,it’sestablishedthatthePEconditionofS (χ ) i21 i22 i21 i22
iϕ i
leads to exponential convergence of (r i,W˜ iϕ) to zero for all
F (q˙
)=(cid:20) F i11(cid:21)
, g (q
)=(cid:20) g i11(cid:21)
.
i∈I[1,N]. i i F i21 i i g i21
Further,sinceϵ iϕ isproportionaltoϵ i,andσ i canbemade with
as small as desired, W˜
iϕ
will also converge to an arbitrarily
M =m l2 +m (l2 +l2 +2l l cos(qi2))
small vicinity of zero. This size is dictated by ϵ and σ. i11 i1 ic1 i2 i1 ic2 i1 ic2
i i +I +I ,
i1 i2
H (χ )=WˆTS (χ )+ϵ M =m (l2 +l l cos(q ))+I ,
i i iϕ iϕ i iϕ,1 (34) i12 i2 ic2 i1 ic2 i2 i2
=W¯ iT ϕS iϕ(χ i)+ϵ iϕ,2, ∀i∈I[1,N] M i21 =m i2(l ic2+l i1l ic2cos(qi2))+I i2,
M =m l2 +I ,
Here, ϵ and ϵ are approximation errors. They are i22 i2 ic2 i2
iϕ,1 iϕ,2
proportional to ϵ iϕ due to the proven convergence of W˜ iϕ to C i11 =−m i2l i1l ic2q˙ i2sin(q i2), (36)
zero. As for neurons far from the trajectory, S iϕ¯(χ i) is min- C i12 =−m i2l i1l ic2(q˙ i1+q˙ i2)sin(q i2),
imal, impacting the neural weight adaptation only slightly. C i21 =m i2l i1l ic2q˙ i1sin(q i2),
Therefore, the full RBF NN can still accurately approximate C i22 =0,
theunknownfunctionH (χ )alongthetrajectoryfort≥T . g =(m l +m l )gcos(q )
i i i i11 i1 ic2 i2 i1 i1
+m l gcos(q +q ),
Hi(χ )=WˆTS (χ )+ϵ i2 ic2 i1 i2
i =W¯i TSi (χi )+ϵi1
, ∀i∈I[1,N]
(35) G i22 =m i2l ic2gcos(q i1+q i2).
i i i i2
In Fig. 1, we identify the core components and their
Theapproximationerrorsϵ andϵ areproportionaltoϵ
i1 i2 iϕ,1
and ϵ respectively. This concludes the proof.
iϕ,2
Remark2. From(13)and (14),weobservethatthesecond-
layer deterministic learning control is fully decentralized.
Each local control law functions independently, without the
need for sharing information with neighboring agents. This
is in contrast to the first-layer’s cooperative estimation.
Theorem 3. Given a multi-robot manipulator system as
described by systems (2) and virtual leader dynamics (3),
along with the network communication topology G. Under
Assumption 1 and 2, Problem 1 can be addressed using a
distributed control protocol comprised of (13) (14) and (4)
(5). All design parameters should satisfy the requirements in Fig. 1: Schematic for the inverted double pendulum system..
Theorem 1 and 2.
specifications for the i-th robotic agent. l ,l represent
Remark 3. The proposed two-layer distributed learning ic1 ic2
half of these lengths, and F ,F are defined as constants.
i11 i21
control scheme consists of a cooperative estimation law, The inertia of the links is given by I and I , and the
i1 i2
given by (4) and (5), and a decentralized deterministic detailed values are provided in Table I. By employing
learningcontrollaw,detailedin(13)and(14)forthesecond N =5 manipulators, the robotic agents are set to follow the
reference trajectory provided by the virtual leader. A leader
layer. More specifically, the first layer requires inter-agent
dynamic is formulated to generate a periodic signal for the
communication for sharing estimated information (χˆ ,Aˆ).
i i synchronization control:
The second layer only demands local robot plant states χ
i  0 0 1 0  0 
and local estimated information χˆ i for feedback. (cid:20) x˙ (cid:21) 0 0 0 1 (cid:20) x (cid:21) (cid:20) x (0)(cid:21) 0.8
01 ,=  01 , 01 = 
Remark 4. Despiteextensiveresearchindistributedcontrol x˙ 02 −1 0 0 0 x 02 x 02(0) 0.8
0 −1 0 0 0
for multi-robot systems (e.g., [19]), most existing techniques
focus solely on control, largely overlooking the learning ThenetworktopologyGamongstthefiverobotsisdepicted
aspects. The distributed learning control scheme proposed in Fig 2. This topology includes a spanning tree with the
here fills this gap. It provides a capability currently missing virtualleader,referredtoasagent0,positionedatthecenter.Fig. 2: Network Topology with Agent 0 Serving as the
Fig. 3: Tracking error for each agent.
Virtual Leader
TABLE I: Parameters of the robot.
Parameter Robotnumber
1 2 3 4 5
m1(kg) 2 2.2 2.3 1.9 2.4
m2(kg) 0.85 0.9 1 0.9 1.5
l1(m) 0.35 0.5 0.6 0.52 0.57
l2(m) 0.31 0.4 0.5 0.48 0.53
I1×10−3 (kgm2) 61.25 70 72.14 67.21 73.42
I2×10−3 (kgm2) 20.42 25.21 27.1 25.4 22.63
The system states encompass both measured signals and
reference signals, totaling eight signals. Originally, if we
use a neural network with 4 nodes for each signal, we end
Fig. 4: Joint angle tracking response for each agent
up with a massive number of nodes 48 = 65,536 which is
computationally expensive to train. However, the reference
signals are expressed in terms of the measured signals, as
shown in (8), which accentuates the significance of the
measured signals. Consequently, we construct the Gaussian
RBF NN using the dominant four dimensions of the system
state. This strategy reduces the size of the NN to 44 =256
whichnotonlysavescomputationalresourcesbutalsoallows
us to build a more precise model by dedicating more nodes
to each of these four key dimensions. The range of each
dimension lies within [−1.2,1.2], with a width parameter
γ =0.8. The observer and controller parameters are set to
i
β =β =1, γ =10, K =10, and σ =0.001 for all i∈[1,5].
1 2 i i
The initial conditions are defined as x (0)=[0.2 0.1]T,
11
x (0)=[0.3 0.5]T, x (0)=[0.4 0.1]T, x (0)=[0.2 0.5]T,
21 31 41
x (0)=[0.4 0.1]T, and x =[0 0]T, ∀i∈[1,5]. Initial
51 i2
conditions for all distributed observer states χˆ and NN
i
weights Wˆ are uniformly initialized to zero. We conducted
i
an assessment of two key components within our system Fig. 5: NN weights Convergence for all agents.
setup: the distributed cooperative estimator, described by
(4) and (5), and the decentralized deterministic learning
control law, encapsulated by (13) and (14). Despite varying layer in comparison to the desired signals originating from
complexities and nonlinear uncertainties among multiple the first layer and the leader’s signal is represented in Fig.
robotic agents, the results indicate satisfactory tracking 4. It is observed that all signals rapidly converge to align
performance. This is further confirmed by Fig. 3, which with the leader’s signal within the initial seconds. Fig. 5
shows a rapid convergence of tracking errors to zero, as showshowquicklytheNeuralNetworkweightssettleforall
discussed in Theorem 2. robotic agents. This fast convergence is in accordance with
The tracking response of joint angles from the second Theorem2.Moreover,wegraphedtheNNapproximationas-[2] N. Seenu, K. C. RM, M. Ramya, and M. N. Janardhanan, “Review
on state-of-the-art dynamic task allocation strategies for multiple-
robotsystems,”IndustrialRobot:theinternationaljournalofrobotics
researchandapplication,vol.47,no.6,pp.929–942,2020.
[3] E. Jandaghi, X. Chen, and C. Yuan, “Motion dynamics modeling
and fault detection of a soft trunk robot,” in 2023 IEEE/ASME
InternationalConferenceonAdvancedIntelligentMechatronics(AIM).
IEEE,2023,pp.1324–1329.
[4] C.Yuan,S.Licht,andH.He,“Formationlearningcontrolofmultiple
autonomousunderwatervehicleswithheterogeneousnonlinearuncer-
taindynamics,”IEEEtransactionsoncybernetics,vol.48,no.10,pp.
2920–2934,2017.
[5] N. Hazon and G. A. Kaminka, “On redundancy, efficiency, and
robustnessincoverageformultiplerobots,”RoboticsandAutonomous
Systems,vol.56,no.12,pp.1102–1114,2008.
[6] J. Huang, C. Wen, W. Wang, and Y.-D. Song, “Adaptive finite-
timeconsensuscontrolofagroupofuncertainnonlinearmechanical
systems,”Automatica,vol.51,pp.292–301,2015.
[7] M.Abdelatti,C.Yuan,W.Zeng,andC.Wang,“Cooperativedetermin-
isticlearningcontrolforagroupofhomogeneousnonlinearuncertain
robotmanipulators,”ScienceChinaInformationSciences,vol.61,pp.
1–19,2018.
Fig. 6: NN approximation
[8] Q.Liu,D.Li,S.S.Ge,R.Ji,Z.Ouyang,andK.P.Tee,“Adaptivebias
rbfneuralnetworkcontrolforaroboticmanipulator,”Neurocomputing,
vol.447,pp.213–223,2021.
sociatedwiththeunknowndynamicvariablesH(χ)foreach [9] A. Rodriguez-Angeles and H. Nijmeijer, “Mutual synchronization of
i i robots via estimated state feedback: a cooperative approach,” IEEE
agent in Fig. 6, employing RBF NN approximation repre-
Transactionsoncontrolsystemstechnology,vol.12,no.4,pp.542–
sented as Wˆ iTS i(χ i). In our controller, all system parameters 554,2004.
aretreatedashavingunstructureduncertainty,indicatingthat [10] S.-J. Chung and J.-J. E. Slotine, “Cooperative robot control and
concurrentsynchronizationoflagrangiansystems,”IEEEtransactions
the control algorithm is environment-independent. Whether
onRobotics,vol.25,no.3,pp.686–700,2009.
thesystemoperatesunderwater,wherebuoyancyforcesvary [11] H. Wang, “Flocking of networked uncertain euler–lagrange systems
with the depth of a robot’s arm, or in space, where the ondirectedgraphs,”Automatica,vol.49,no.9,pp.2774–2779,2013.
[12] X.Dong,C.Yuan,P.Stegagno,W.Zeng,andC.Wang,“Composite
inertia matrix is unknown, the algorithm adapts accordingly.
cooperativesynchronizationanddecentralizedlearningofmulti-robot
Regardless of these conditions, after completing the training manipulatorswithheterogeneousnonlinearuncertaindynamics,”Jour-
process, the stored weights for dynamic parameter identifi- naloftheFranklinInstitute,vol.356,no.10,pp.5049–5072,2019.
[13] D.LiangandJ.Huang,“Leader-followingbipartiteconsensusofmul-
cation can beutilized in the controller, evenafter the system
tipleuncertaineuler-lagrangesystemsoversignedswitchingdigraphs,”
has been turned off. Neurocomputing,vol.405,pp.96–102,2020.
[14] W.RenandR.W.Beard,“Consensusseekinginmultiagentsystems
V. CONCLUSION under dynamically changing interaction topologies,” IEEE Transac-
tionsonautomaticcontrol,vol.50,no.5,pp.655–661,2005.
In this study, The challenge of implementing composite
[15] J. Park and I. W. Sandberg, “Universal approximation using radial-
synchronization and adaptive learning control for a network basis-functionnetworks,”Neuralcomputation,vol.3,no.2,pp.246–
of multi-robot manipulators, with complete nonlinear uncer- 257,1991.
[16] ——, “Approximation and radial-basis-function networks,” Neural
tain dynamics was successfully met. The novel approach
computation,vol.5,no.2,pp.305–316,1993.
contains a distributed cooperative estimator in the first layer [17] C.WangandD.J.Hill,Deterministiclearningtheoryforidentifica-
for estimating the virtual leader’s states, and a decentralized tion,recognition,andcontrol. CRCPress,2018.
[18] ——,Deterministiclearningtheoryforidentification,recognition,and
deterministic learning controller in the second layer to track
control. CRCPress,2009.
the leader’s states while identifying each robot’s distinct [19] C.YuanandC.Wang,“Persistencyofexcitationandperformanceof
nonlinear uncertain dynamics. The key strengths of This deterministiclearning,”Systems&controlletters,vol.60,no.12,pp.
952–959,2011.
method include simultaneously achieving synchronization
control and learning robots’ complete nonlinear uncertain
dynamics in a decentralized manner that eliminates the need
for global connectivity. This improves robotics control in
space and underwater settings, where system dynamics are
typically uncertain. The method’s effectiveness is verified
through detailed mathematical validation and simulations.
Stored identified nonlinearities can be used in the controller
once, eliminating frequent adjustments when the system
restarts. We aim to extend this framework to other robots
with Euler-Lagrangian dynamic systems.
REFERENCES
[1] R. Cui and W. Yan, “Mutual synchronization of multiple robot ma-
nipulatorswithunknowndynamics,”JournalofIntelligent&Robotic
Systems,vol.68,pp.105–119,2012.