Augmenting Automation: Intent-Based User
Instruction Classification with Machine Learning
Lochan Basyal and Bijay Gaudel
Stevens Institute of Technology, Hoboken, NJ, USA
{lbasyal, bgaudel}@stevens.edu
Abstract—Electric automation systems offer convenience and Central to our approach is the development of a machine
efficiencyincontrollingelectricalcircuitsanddevices.Tradition- learning model trained on a labeled dataset of user instruc-
ally, these systems rely on predefined commands for control,
tions. Leveraging natural language processing techniques and
limiting flexibility and adaptability. In this paper, we propose a
supervised learning algorithms, our model learns to recog-
novel approach to augment automation by introducing intent-
based user instruction classification using machine learning nize patterns and infer the underlying intent behind each
techniques. Our system represents user instructions as intents, instruction. This enables our proposed system to understand
allowingfordynamiccontrolofelectricalcircuitswithoutrelying a wide range of user instructions and respond accordingly,
on predefined commands. Through a machine learning model
regardless of variations in syntax or phrasing. By providing
trained on a labeled dataset of user instructions, our system
a more seamless and natural interaction between users and
classifies intents from user input, enabling a more intuitive and
adaptablecontrolscheme.Wepresentthedesignandimplemen- their environments, our work contributes to the advancement
tation of our intent-based electric automation system, detailing ofsmarttechnologiesandopensnewpossibilitiesforthefuture
the development of the machine learning model for intent of electric automation.
classification. Experimental results demonstrate the effectiveness
Furthermore, our paper is organized in such a way that it
ofourapproachinenhancinguserexperienceandexpandingthe
demonstrates the proposed system in Section II; the datasets
capabilitiesofelectricautomationsystems.Ourworkcontributes
to the advancement of smart technologies by providing a more used for the intent classification task are discussed in Section
seamless interaction between users and their environments. III; and the machine learning algorithms used are presented
Index Terms—Intent Classification, Electric Automation, Ma- in Section IV. The model development and training are dis-
chine Learning
cussed in Section V, the evaluation metrics used for the intent
classification are discussed in Section VI, and the results
I. INTRODUCTION
and observations in Section VII demonstrate the graphical
Electric automation systems have transformed the way we representation of accuracy over epochs, loss over epochs,
interact with our environments, offering unprecedented con- classification report, confusion matrix, and model inference
venience and efficiency in controlling electrical circuits and witharegularizedmodel.Thepaperconcludeswiththefuture
devices. Traditional approaches to automation often rely on work in Section VIII.
predefinedcommands[1]ormanualprogramming,limitingthe
adaptabilityandresponsivenessofthesystemtouserneedsand
II. PROPOSEDSYSTEM
preferences. In recent years, there has been a growing interest Our proposed system aims to enhance electric automation
in developing more intuitive and user-friendly automation through the integration of machine learning techniques for
systems that can understand and interpret natural language intent classification, facilitating more natural and intuitive
instructions. interaction between users and the automation system. The
In this paper, we present a novel approach to augment- system workflow can be divided into several key steps, as
ing electric automation systems through intent-based user shown in Figure 1:
instruction classification using machine learning techniques.
A. User Instruction Input
Unlike traditional systems that require users to memorize
specific commands or sequences, our approach enables users The system begins with the user providing instructions
to communicate their intentions naturally, allowing for more in the form of text. These instructions can encompass a
dynamic control of electrical circuits. The key innovation of wide range of commands, expressing the user’s intentions
our approach lies in representing user instructions as intents, regarding the control of electrical circuits, robotic movement,
which encapsulate the underlying purpose or goal of the or automation tasks.
user’s command. By classifying user intents based on their
B. Intent Classification
instructions, our proposed system can interpret and execute
the appropriate actions without relying on predefined com- The user-provided instructions are then processed through
mands. This not only enhances the user experience but also a machine learning model for intent classification. In our
improvesthesystem’sadaptabilitytonewcommandsanduser implementation,weutilizeLongShort-TermMemory(LSTM)
preferences over time. [2] networks, a type of recurrent neural network (RNN),
4202
raM
2
]GL.sc[
1v24210.3042:viXrafor this purpose. Prior to classification, the text instructions User Instruction Input
undergo preprocessing, including tokenization and TF-IDF
(Term Frequency-Inverse Document Frequency) vectorization
to convert them into a numerical representation suitable for
input into the LSTM model. Intent Classification
C. Predefined Intent Matching
The classified intents are compared with predefined intents
Predefined Intent Matching
stored within the system. These predefined intents represent
a set of commands or actions that the system is capable of
executing. The comparison process involves evaluating the
equalitybetweentheclassifiedintentandthepredefinedintent Embedded System Programming
to determine the most suitable match.
D. Embedded System Programming
Execution of Operations
Uponmatchingtheclassifiedintentwithapredefinedintent,
thecorrespondingoperationisprogrammedintotheembedded
controller. The embedded controller serves as the interface
betweenthesoftware-basedintentclassificationsystemandthe Feedback Loop
physical world of electrical appliances and robotics peripher-
Fig. 1: Proposed System Workflow
als.Ittranslatesthehigh-levelintentintolow-levelcommands
that can be executed by the electronic control system.
E. Execution of Operations
exploration(refertoFigure2)revealsthefirstfewrowsofthe
The electronic control system receives the commands from dataset, along with information and statistical summaries.
theembeddedcontrollerandexecutesthecorrespondingoper-
It is important to note that while our dataset provides a
ations in the real world. This may involve turning on/off elec-
foundational representation of intent-based user instructions
trical appliances, adjusting robotic movements, or performing
forelectricautomation,itisrelativelysmallinscale.Assuch,
automation tasks as the user’s intent dictates.
the performance of the intent classification model may be
limited by the size and diversity of the dataset. To address
F. Feedback Loop
thislimitationandimprovetherobustnessofthemodel,future
Throughout the process, the system may provide feedback
research efforts will focus on augmenting the dataset with
to the user regarding the successful execution of the intended
additional user instructions and intents. By expanding the
operation or any errors encountered. This feedback loop en-
scope and variety of the training data, we aim to enhance
surestransparencyanduserawarenessofthesystem’sactions.
the model’s ability to accurately classify a wider range of
The proposed system focuses primarily on the machine
user commands and accommodate varying user preferences
learningaspect,specificallyintentclassificationwhileleverag-
and expressions.
ing existing embedded systems and electronic control mecha-
nismsforphysicaloperation.Byemployingadvancedmachine
learning techniques, our system enhances the adaptability and
user-friendliness of electric automation, paving the way for
more intelligent and responsive automation systems.
III. DATASETS
For the purpose of training and evaluating our intent clas-
sification model for electric automation, we curated a dataset
consisting of intent-based user instructions. The dataset com-
prisesatotalof14intents,eachassociatedwithapproximately
10 user instructions, resulting in a total of 140 instructions
for electric automation. The intents were carefully selected
to cover a diverse range of control commands and actions
commonlyencounteredinelectricautomationscenarios.These
intents include commands for turning on/off electrical appli-
ances. Each user instruction in the dataset is labeled with its
Fig. 2: Data Exploration
correspondingintent,allowingthemodeltolearnthemapping
between input instructions and their intended actions. DataIV. MACHINELEARNINGALGORITHMS V. MODELDEVELOPMENTANDTRAINING
In our research, we employed a combination of machine For the development of our baseline intent classification
learningalgorithmstodevelopaneffectiveintentclassification model, we chose to utilize a Long Short-Term Memory
model for electric automation. The key algorithms utilized in (LSTM)networkduetoitseffectivenessinhandlinglong-term
our approach include TF-IDF (Term Frequency-Inverse Doc- sequential data and capturing semantic dependencies within
ument Frequency) for text vectorization, one-hot encoding for user instructions. The LSTM architecture is well-suited for
intent representation, and Long Short-Term Memory (LSTM) tasks requiring the retention of context over extended periods,
networks for sequence modeling. making it an ideal choice for processing natural language
inputs.Themodel5consistsofanLSTMlayerwith128units
A. TF-IDF for Text Vectorization followed by a dense output layer with softmax activation, fa-
cilitating multi-class classification. During training, the model
Prior to training the intent classification model, the user
is optimized using the categorical cross-entropy loss function
instructionsundergopreprocessing,includingtokenizationand
and the Adam optimizer. We trained the model for 75 epochs
removalofstopwordsandpunctuation.Subsequently,theTF-
using a batch size of 16 and evaluated its performance on the
IDF [3] algorithm is applied to convert the preprocessed text
test dataset.
intonumericalvectors.TF-IDFassignsweightstotermsbased
on their frequency in a document relative to their frequency
across all documents in the dataset. This enables the model to
capturetheimportanceofeachtermindistinguishingbetween
different intents.
B. One-Hot Encoding for Intent Representation
In parallel with text vectorization, intents are represented
usingone-hotencoding[4].Eachintentismappedtoabinary
Fig. 3: Baseline Model
vector, where a value of 1 indicates the presence of the intent
and 0 indicates its absence. This binary representation allows
the model to categorically classify each user instruction into In order to enhance the performance and generalization
one of the predefined intents. capability of our intent classification model, we incorporated
L2regularizationanddropouttechniquesintothearchitecture.
C. Long Short-Term Memory (LSTM) Networks These regularization techniques help mitigate overfitting and
improvethemodel’sabilitytogeneralizetounseendata.Inthe
To capture the temporal dependencies and semantic context
model development process, L2 regularization with a penalty
of user instructions, we employed LSTM networks [2], a
strength of 0.01 and a dropout rate of 0.2 was applied to
type of recurrent neural network (RNN). LSTM networks are
prevent overfitting, and the model was trained using the same
well-suited for handling sequences of data and are capable
batch size for 80 epochs. The regularized model is shown in
of learning long-term dependencies, making them particularly
Figure 4.
effective for sequence modeling tasks such as intent clas-
sification. By processing user instructions as sequences of
tokens, LSTM networks can effectively capture the semantic
nuances and contextual information necessary for accurate
intent classification.
D. Regularization Techniques
To enhance the generalization and robustness of the intent
classificationmodel,weincorporatedregularizationtechniques
such as L2 regularization [5] and dropout. L2 regularization
penalizes large weights in the model, helping to prevent over- Fig. 4: Regularized Model
fittingandimprovethemodel’sabilitytogeneralizetounseen
data. Dropout randomly drops a fraction of the connections
betweenneuronsduringtraining,reducingthemodel’sreliance
VI. EVALUATIONMETRICSFORINTENTCLASSIFICATION
on specific features and enhancing its resilience to noise and In assessing the performance of our intent classification
variability in the input data. model for electric automation, we employed a range of eval-
By leveraging these machine learning algorithms in combi- uation metrics to measure its accuracy and effectiveness in
nation,wedevelopedaneffectiveandefficientintentclassifica- correctly identifying user intents. These evaluation metrics
tion model capable of accurately interpreting user instructions provideinsightsintothemodel’soverallperformanceandhelp
for electric automation tasks. assess its suitability for real-world deployment.TABLE I: Interpretation of Confusion Matrix
A. Accuracy
Accuracy[6]measurestheproportionofcorrectlyclassified Predicted/Actual Positive Negative
user instructions out of the total number of instructions. It Positive (TP) (FP)
providesageneralindicationofthemodel’soverallcorrectness Negative (FN) (TN)
in predicting intent and is calculated as:
Number of correctly classified instructions VII. RESULTSANDOBSERVATIONS
Accuracy = ×100%
Total number of instructions In this section, we present the results and observations ob-
(1)
tainedfromourexperimentsonintentclassificationforelectric
B. Precision automation. We compare the performance of two scenarios: a
Precision [6] measures the proportion of correctly classi- baseline model and a model with regularization and dropout
fied positive predictions (true positives) out of all instances techniques applied. Furthermore, we test the inference of the
predicted as positive (true positives + false positives). In the regularized models on preprocessed test datasets and raw user
context of intent classification, precision reflects the model’s instructions.
ability to accurately identify a specific intent without misclas-
A. Training and Validation Loss Over Epochs
sifyingotherintentsasthetargetintent.Precisioniscalculated
as: Figure 5 illustrates the training and validation loss curves
forthebaselinemodel,andFigure5representstheregularized
True Positives
Precision= (2) model.Thevalidationlossremainsconsistentlyhigherthanthe
True Positives + False Positives
training loss throughout the training process. This widening
C. Recall (Sensitivity) gap between the training and validation loss suggests that the
Recall [6] measures the proportion of correctly classified modelmaybeoverfittingtothetrainingdataandstrugglingto
positiveinstances(truepositives)outofallinstancesthattruly generalizewelltounseenvalidationdata.However,themodel
belong to the positive class (true positives + false negatives). with regularization and dropout exhibits smoother loss curves
It indicates the model’s ability to capture all instances of a with reduced fluctuations, suggesting improved stability and
specific intent, without missing any. Recall is calculated as: generalization.
True Positives
Recall= (3)
True Positives + False Negatives
D. F1 Score
F1 score [6] is the harmonic mean of precision and recall,
providingabalancedmeasureofamodel’saccuracy.Itconsid-
ers both false positives and false negatives and is particularly
useful when the class distribution is imbalanced. F1 score is
calculated as:
2×Precision×Recall
F1= (4)
Precision+Recall
E. Confusion Matrix
The confusion matrix [6] provides a detailed breakdown of
the model’s predictions compared to the ground truth labels.
It consists of four quadrants: true positives (TP) (correctly
classified positive instances), true negatives (TN) (correctly Fig. 5: Training and Validation Loss Over Epochs - Baseline
classified negative instances), false positives (FP) (instances Model
that are actually negative but are classified as positive by the
model), and false negatives (FN) (instances that are actually
B. Training and Validation Accuracy Over Epochs
positive but are classified as negative by the model). The con-
fusionmatrixhelpsidentifyspecificareasofimprovementand Figure 7 depicts the training and validation accuracy trends
provides insights into the model’s strengths and weaknesses. forthebaselinemodelandFigure8fortheregularizedmodel.
By evaluating our intent classification model using these Thebaselinemodelachieveshightrainingaccuracybutshows
metrics, we gain a comprehensive understanding of its perfor- signs of overfitting, as evidenced by a noticeable gap between
manceandcanidentifyareasforrefinementandoptimization. training and validation accuracy. In contrast, the model with
Additionally, these metrics enable us to compare the effec- regularizationanddropoutachievescomparabletrainingaccu-
tiveness of different models and approaches, guiding future racy while maintaining higher validation accuracy, indicating
research and development efforts in electric automation. better generalization to unseen data.C. Classification Report
Figure9presentstheclassificationreport[7]forthebaseline
model, and Figure 10 for the regularized model, including
metrics such as precision, recall, and F1-score for each intent
class.Themodelwithregularizationanddropoutdemonstrates
improvements in precision, recall, and F1-score across most
intent classes compared to the baseline model, indicating
enhanced performance and robustness. The accuracy obtained
with the regularized model is 96%, compared to the baseline
model’s 75%.
Fig. 6: Training and Validation Loss Over Epochs -
Regularized Model
Fig. 9: Classification Report - Baseline Model
Fig. 7: Training and Validation Accuracy Over Epochs -
Baseline Model
Fig. 10: Classification Report - Regularized Model
D. Confusion Matrix
The confusion matrices for both scenarios are presented
in Figures 11 and 12. These matrices provide a detailed
breakdownofthemodel’spredictionscomparedtotheground
truth labels, highlighting areas of correct and incorrect classi-
fications for each intent class.
Overall, the experimentation and observation reveal the
Fig. 8: Training and Validation Accuracy Over Epochs - effectiveness of regularization and dropout techniques in im-
Regularized Model proving the performance and robustness of the intent classifi-
cation model for electric automation.Fig. 13: Inference Results for the First 5 Samples of the
Preprocessed Test Datasets
Fig. 11: Confusion Matrix - Baseline Model
Fig. 14: Inference Results from Raw User Instructions
Moving forward, our research serves as a foundation for
thedevelopmentofanintuitiveelectricalcontrolsystembased
on intent-based user instructions. Future work will focus on
augmentingdatasetstofurtherrefinethemodel’sperformance
and adaptability. Additionally, we aim to explore the utiliza-
tion of language models for intent classification with prompt
engineering,enablingmoresophisticatedinterpretationofuser
instructions.
Furthermore, our efforts will extend towards the develop-
ment of an end-to-end user-compatible product. This entails
integrating communication protocols, embedded systems, and
electronic control circuits to create a seamless interface be-
Fig. 12: Confusion Matrix - Regularized Model tween users and automated systems in the real world. By
pursuingtheseavenuesofresearch,weaimtoadvancethefield
of intent-based automation and contribute to the realization
E. Model Inference with Regularized Model
of intelligent systems that seamlessly interact with users in
We first examine the model’s performance on the prepro- various contexts.
cessedtestdataset.Theinferenceresultsforthefirst5samples
are presented in Figure 13, showcasing the model’s ability to ACKNOWLEDGMENT
classify intents based on the processed user instructions.
The author would like to acknowledge the foundation laid
Next, we explore the model’s inference capabilities on raw
by his previous work[1]. This paper represents an iteration
user instructions directly obtained from the users, which is
aimed at enhancing technology and the user experience with
shown in figure 14.
intent-based instructions for electrical automation.
VIII. CONCLUSIONWITHFUTUREWORK
REFERENCES
In conclusion, the integration of L2 regularization and
dropout techniques significantly enhanced the performance of [1] Basyal, Lochan. ”Voice recognition robot with real-time surveillance
and automation.” arXiv preprint arXiv:2312.04072 (2023). Available:
our intent classification model. With the addition of regu-
https://arxiv.org/abs/2312.04072.[Accessed:2024-02-25].
larization and dropout, the accuracy of the model increased [2] Hochreiter,Sepp,andJu¨rgenSchmidhuber.”Longshort-termmemory.”
substantiallyfrom75%to96%.Thisimprovementunderscores NeuralComputation9.8(1997):1735–1780.
[3] ”TfidfVectorizer.” [Online]. Available: https://scikit-learn.org/stable/
the effectiveness of these techniques in mitigating overfitting
modules/generated/sklearn.feature extraction.text.TfidfVectorizer.html.
and improving the generalization capability of the model. [Accessed:2024-02-29].[4] ”OneHotEncoder.” [Online]. Available: https://scikit-learn.org/
stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html.
[Accessed:2024-02-29].
[5] Cortes,Corinna,MehryarMohri,andAfshinRostamizadeh.”L2regu-
larizationforlearningkernels.”arXivpreprintarXiv:1205.2653(2012).
[6] ”A Look at Precision, Recall, and F1-Score.”
[Online]. Available: https://towardsdatascience.com/
a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec. [Accessed:
2024-02-29].
[7] ”Classification report.” [Online]. Available: https://scikit-learn.org/
stable/modules/generated/sklearn.metrics.classification report.html.
[Accessed:2024-02-29].