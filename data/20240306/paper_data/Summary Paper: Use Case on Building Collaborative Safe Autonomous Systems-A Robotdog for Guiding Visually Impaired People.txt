Summary Paper: Use Case on Building
Collaborative Safe Autonomous Systems
A Robotdog for Guiding Visually Impaired People
Aman Malhotra Selma Saidi
Chair of Embedded Systems Chair of Embedded Systems
TU Dortmund University TU Dortmund University
Dortmund, Germany Dortmund, Germany
aman.malhotra@tu-dortmund.de selma.saidi@tu-dortmund.de
Abstract—This is a summary paper of a use case of a
Robotdogdedicatedtoguidevisuallyimpairedpeopleincomplex
environment like a smart intersection. In such scenarios, the
Robotdog has to autonomously decide whether it is safe to
cross the intersection or not in order to further guide the
human.Weleveragedatasharingandcollaborationbetweenthe
Robotdog and other autonomous systems operating in the same
environment. We propose a system architecture for autonomous
systemsthroughaseparationofacollaborativedecisionlayer,to
enable collective decision making processes, where data about
the environment, relevant to the Robotdog decision, together
with evidences for trustworthiness about other systems and the
environment are shared.
I. WHATISTHEPROBLEMWEARESOLVING?
Autonomous systems are becoming an integral part of Fig.1. SketchoftheRobotdogoperatinginasmartintersection.Layersof
systemarchitectureforenablingcollaborativedecisionmakingaredepicted.A
many application domains, including mobility and human-
fulldemocanbefoundonthefollowinglink:https://tinyurl.com/tudrobotdog
assistive robotics. Human-assistive robotics, particularly for
social care, offer immense potential in aiding individuals with
disabilities in their daily life. However, ensuring safe and designperspectivearei)separationbetweenthedecisionlayer
correct behavior of such systems in dynamic and complex and the rest of sensing and actuating functionalities, this is
environmentsremainsasignificantchallenge.Weconsiderthe criticalasthesystemneedstodecideaboutwhichinformation
example of Robotdogs guiding blind and visually impaired can be shared and will contribute to the collective decision
people. Similarly to standard guide dogs [1], requirements making, ii) how to aggregate such information to improve
on safety are crucial when considering the design of those decisionmakingcollaboratively?severalaggregationrulesand
systems. These requirements include good traffic awareness semanticsmayleadtodifferentdegreesofincreasedreliability.
and safety, identifying obstacles or safety hazards in their
path,andguidingthehandlersafelyaroundthem,includingin
II. WHATISTHEMAINIDEAOFTHESOLUTION?
publicenvironments.Wefocusondevelopingdecision-making Autonomous systems are often designed with multiple
processes for safety critical autonomous systems, particularly embedded components for perception, trajectory planning,
in scenarios such as smart intersection depicted in 1), where and decision-making. By leveraging collaboration, we build
the Robotdog needs to autonomously determine whether it a dynamic and networked distributed system where nodes
is safe to cross the intersection without colliding with other are autonomous. We consider representative scenarios like the
(autonomous) systems or pedestrians. We propose a collab- one depicted in Fig, 1. The scenario involves a road inter-
orative framework enabling autonomous systems to leverage section with several autonomous systems (e.g., TurtleBots)
collective decision-making processes and increase reliability. and a human-assistive Robotdog. Every autonomous system
By allowing autonomous systems to share information and is equipped with different types of sensors (Lidar, optical and
aggregate data, we aim to reduce (perception) errors and RGBcamera)andispresentatadifferentlocationoftheinter-
improve decision outcomes. For that, we propose a system section,therebyatdifferentdistancesfromapotentialobstacle.
architecture supporting collaborative approaches for assuring Systems are therefore purposely designed with different per-
autonomy and good decision making. Two key aspects from a ceptionandactuationcapabilities.Enablingcollaborationwith
4202
raM
2
]OR.sc[
1v68210.3042:viXrathe Robotdog assisting a human in crossing the intersection theintersection2.Thedecisionlayerrequiresi)comparing
poses real-time and safety challenges. We propose a system symbolically different types of sensors and their quality
architectureseparatingthreelayers,i)SensingandNetworking to perform a ranking, ii) collect data in a timely manner
Layer, ii) Decision Layer, and iii) Actuation Layer, which forcomparison, Forthatwe usethenotion ofsessionsor
is fundamental for software development and safe decision- framesduringwhichsensordataobservationisfacilitated.
making. Each layer can be performed individually or in • Actuation Layer: this layer considers the actuation con-
collaboration. textandoutputofthedecisionlayertoactivatetheRobot-
dog.Makingsureautonomoussystemsactepreciselyand
• Sensing and Networking Layer: The role of this layer
reliably. This requires a sequential process of steps to
is to sense the environment and share knowledge (data
solve the data to trigger the actuation. This actuation
points in space) for decision making. Sensing happens in
trigger is required to be initiated with a session start and
adistributedmanneroneachnode(inourcaseseparately
end. Actuation sequencing is prioritized based on device
on the Robotdog and TurtleBots). We use WiFi 802.111,
IDs, with safety criticality managed through sequential
to enable mesh networking to communicate data and
sessions, enabling timely updates to actuation processes.
helps in building and establishing multi-node setup. In
ourapproachweconsideronemaster(theRobotdog)that III. WHATISTHEEXPECTEDIMPACT?
actsasthedecisionmakingnode,therestareslavenodes.
a) Scientific impact: Traditional designs of autonomous
We use ROS [2] designed to communicate at a master
systemsfocusonthedevelopmentofSense-Decide-Actblocks
slave setup and allows a common subscriber - publisher
in classical cyber-physical systems for functionality like per-
approach to perform data sharing.
ceptionandmaneuvering,usingincreasingsupportfromlearn-
• Decision Layer: The output of the decision layer is a ing enabled components. This might be sufficient for the
safe trajectory computed for every autonomous system,
Robotdog to operate autonomously but with no (or little)
and more critically for the Robotdog guiding the human.
safety guarantees in complex environments. We believe, as
For that, proper detection of objects and obstacles in
previouslyadvocatedin[4]throughthesupervisionlayer,that
the environment is crucial. Every autonomous systems
there is a need for more systems that control safe decision
is restricted in terms of sensing and perception to the
making at operation time. Defining appropriate aggregation
field of view of its sensors and this is what we would
and collaboration rules and deciding which data is relevant
liketoimproveusingacollaborativedecisionlayer.Note
to aggregate becomes key in increasing trustworthiness and
that we do not aim here at performing a complete col-
safety.
laborative perception system (e.g., using sensors fusion)
b) Social Impact: There is a promise that collaboration,
or a complete collaborative planning software stack, we
enabled by infrastructure like in smart intersections, help
rather aim at providing a systemic approach in enabling
buildstrustworthymodelsoftheenvironmentofoperation[5].
collaboration by sharing and aggregating information,
The proposed work in this paper goes in line with this vision
critical for good decision making. Let us consider for
that can be further used not just for the development of
everyautonomoussystemtheresultsofperceptionsystem
automated driving but also for human-assistive robotics in
after classification (e.g., in a simple binary form for
outdoorscenarios.Thiswillallowmoreautonomyforvisually
statements like ”pedestrian has been detected”). Such
impaired people and more safety since standard guide dogs
claims are shared through the sensing and networking
are very costly and trained for a specific sequence of places.
layer and passed on to the decision layer, together with
Changes in the environment will therefore require guide dogs
information such as sensors quality of the autonomous
tobetrainedfurther.Webelievethatautonomoussystemslike
system emitting the claim. These quality attributes act as
theproposedRobotdogcanoffermoreefficientandlesscostly
evidence for trustworthiness for the claim. Ranking for
alternative solutions for visually impaired people.
autonomous systems based on their quality of attributes,
as suggested in [3], to decide whether an autonomous REFERENCES
system is trustworthy or not and therefore their claims
[1] LeadAcademy. Howmuchdoesitcosttotrainaguidedog. https://lead-
canbetrustedbytheRobotdogisproposed.Inthesimple academy.org/blog/how-much-does-it-cost-to-train-a-guide-dog/.
example of Fig. 1, the Robotdog together with another [2] ROSWiki. Rosmasterslaveapi. https://wiki.ros.org/.
[3] SelmaSaidi. Collectivereasoningforsafeautonomoussystems,2023.
TurtlBotbasedontheirsensorsinformationconcludethat
[4] SelmaSaidi,DirkZiegenbein,JyotirmoyV.Deshmukh,andRolfErnst.
no pedestrian is detected (indicated with a green dot), Autonomous systems design: Charting a new discipline. IEEE Design
while another TurtlBot conclude the opposite (indicated
andTest,39(1):8–23,2022.
[5] Shaoshan Liu and Jean-Luc Gaudiot. Ieee international roadmap for
with a red dot). Since the second TurtleBot has better
devicesandsystems(irds)autonomousmachinecomputingwhitepaper
quality of sensors and is closer to the pedestrian, it can 2022. 2022.
beconsideredasthemosttrustworthy(i.e.,expert)inthe
group, the Robotdog decides to stop and not to traverse
1Otherwirelesscommunicationnetworkslike5G/6Gcanalsobeused. 2AmoreelaboratedexampleanddemoisintheindicatedlinkoftheFigure.