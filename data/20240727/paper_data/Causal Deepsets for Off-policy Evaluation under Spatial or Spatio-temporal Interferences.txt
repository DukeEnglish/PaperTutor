Causal Deepsets for Off-policy Evaluation under Spatial or
Spatio-temporal Interferences
Runpeng Daia,b∗†, Jianing Wanga∗∗, Fan Zhoua∗∗, Shikai Luoc,
Zhiwei Qind, Chengchun Shie‡, and Hongtu Zhub§
aShanghaiUniversityofFinanceandEconomics,Shanghai,China
bUniversityofNorthCarolinaatChapelHill,NorthCarolina,USA
cBytedance,Beijing,China
dIndependentResearcher,California,USA
eLondonSchoolofEconomicsandPoliticalScience,London,UK
Summary. Off-policyevaluation(OPE)iswidelyappliedinsectorssuchaspharmaceuticalsande-commerce
to evaluate the efficacy of novel products or policies from offline datasets. This paper introduces a causal
deepset framework that relaxes several key structural assumptions, primarily the mean-field assumption,
prevalent in existing OPE methodologies that handle spatio-temporal interference. These traditional as-
sumptions frequently prove inadequate in real-world settings, thereby restricting the capability of current
OPE methods to effectively address complex interference effects. In response, we advocate for the imple-
mentationofthepermutationinvariance(PI)assumption. Thisinnovativeapproachenablesthedata-driven,
adaptivelearningofthemean-fieldfunction,offeringamoreflexibleestimationmethodbeyondconventional
averaging. Furthermore,wepresentnovelalgorithmsthatincorporatethePIassumptionintoOPEandthor-
oughlyexaminetheirtheoreticalfoundations. Ournumericalanalysesdemonstratethatthisnovelapproach
yieldssignificantlymorepreciseestimationsthanexistingbaselinealgorithms,therebysubstantiallyimprov-
ing the practical applicability and effectiveness of OPE methodologies. A Python implementation of our
proposedmethodisavailableathttps://github.com/BIG-S2/Causal-Deepsets.
Keywords: Causalinference,deepset,off-policyevaluation,permutationinvariance,spatialinter-
ference.
1. Introduction
1.1. Background
Many causal inference problems involve spatial or spatio-temporal data, which consist of observations
recorded at specific locations and/or times. This data type is increasingly prevalent in environmental
studies, epidemiology, social science, two-sided marketplaces, and various other fields due to advanced
modern data collection methods. Unlike traditional scenarios where observations are typically indepen-
dent across different subjects, spatial data often exhibit spillover effects. This means the treatment
applied to one subject can affect not only their own response but also the responses of their neighboring
subjects, challenging the stable unit treatment value assumption (SUTVA, Angrist et al., 1996). For
example, in infectious disease control, an individual’s risk of infection is influenced by the vaccination
status of others nearby (Hudgens and Halloran, 2008). Social scientists have also observed that living in
disadvantaged neighborhoods can intensify the difficulties faced by the urban poor, further illustrating
the impact of spatial interference (Sobel, 2006).
This paper is motivated by the challenge of managing complex spatio-temporal interferences in major
ride-sourcingplatformssuchasUber,Lyft,andDidiChuxing(HahnandMetcalfe,2017;Qinetal.,2022).
Key interferences in these platforms include fluctuating demand and supply across various locations and
times, the impact of surge pricing, changes in driver income due to shifts in driver locations, and the
influence of external factors such as weather and events on demand (Wang and Yang, 2019; Zhou et al.,
2021a; Qin et al., 2022). An example of these challenges can be seen in our evaluation of new passenger-
side subsidizing policies. When implemented in specific regions, these policies not only boost demand
anddrawdriversfromnearbyareas,affectingincomeinboththetargetandsurroundingregions,butalso
†The first three authors have contributed equally to this paper.
‡The final two authors listed are joint senior contributors to this work.
§Corresponding author. Email: htzhu@email.unc.edu
4202
luJ
52
]LM.tats[
1v01971.7042:viXra2 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
haveadelayedeffectonthedriverincomedistribution,leadingtobothspatialandtemporalinterferences.
The presence of such complex interferences significantly complicates the application of traditional causal
inference methods. To navigate these complexities effectively, the development of advanced statistical
models and methods is essential for accurately evaluating the impact of these policies in the context of
causal inference with spatio-temporal interference.
1.2. Related Works
Our proposal intersects with three distinct bodies of literature: spatial interference in causal inference,
off-policy evaluation (OPE), and the concept of permutation invariance within the realm of geometric
deep learning.
1.2.1. Spatial Interference in Causal Inference
Theliteratureonaddressingspatialinterferenceincausalinferencebroadlyfallsintotwomaincategories:
design-basedandmodel-basedmethods(seeReichetal.,2021, andthereferencestherein). Design-based
methods concentrate on leveraging the design of experiments and sampling processes. For instance,
Aronow and Samii (2017) introduced a spatial causal inference framework that estimates average po-
tential outcomes using known treatment distributions and exposure mapping. Li et al. (2019) proposed
randomization-based point estimators and confidence intervals to study peer effects with arbitrary num-
bers of peers and peer types. Wang et al. (2020) proposed estimating the average marginalized response
to quantify outcome interference by treatments at specific distances, assuming a Bernoulli treatment
distribution. On the other hand, model-based methods are divided into four subcategories. The first
subcategory, structural models, imposes interference structures to approximate interference effects. No-
tableexamplesincludeconditionalautoregressive(CAR,Banerjeeetal.,2003)andspatialautoregressive
(SAR, Lee, 2007) models, which introduce spatial random effects to represent neighborhood influences.
The second subcategory, partial interference methods, divides populations into non-overlapping blocks,
assuming interference within these blocks (Sobel, 2006; Tchetgen and VanderWeele, 2012; Zigler et al.,
2012; Perez-Heydrich et al., 2014). The third subcategory focuses on experimental units in geographical
spaces or networks, employing local or network-based assumptions for causal inference (Verbitsky-Savitz
and Raudenbush, 2012; Wang et al., 2020; Tchetgen Tchetgen et al., 2021; Puelz et al., 2022). The final
subcategory considers scenarios where interference manifests as congestion or pricing effects in two-sided
markets (Munro et al., 2021; Johari et al., 2022).
1.2.2. Off-policy Evaluation
Off-policy evaluation (OPE) represents an actively evolving research domain within the field of rein-
forcement learning (RL, Sutton and Barto, 2018; Agarwal et al., 2019; Levine et al., 2020). The primary
goal of OPE is to accurately estimate the mean reward that a prospective target policy might yield, uti-
lizing observational data generated under a different, behavior policy. This area encompasses a variety
of methods (see Dud´ık et al., 2014; Uehara et al., 2022, for reviews), including model-based approaches
(Gottesman et al., 2019; Yin and Wang, 2020), value-based techniques (Le et al., 2019; Luckett et al.,
2020; Hao et al., 2021; Liao et al., 2021; Chen and Qi, 2022; Shi et al., 2022b), importance sampling
methods (Thomas et al., 2015; Luedtke and Van Der Laan, 2016; Liu et al., 2018; Hu and Wager, 2023;
Thams et al., 2023; Wang et al., 2023), and doubly robust strategies (Zhang et al., 2012; Jiang and
Li, 2016; Thomas and Brunskill, 2016; Tang et al., 2019b; Kallus and Uehara, 2022; Liao et al., 2022).
Despite the progress in OPE methodologies, a notable shortcoming is their general lack of accounting for
spatial interference, an essential factor in many real-world scenarios, including ride-sharing platforms.
Recognizing this gap, recent research endeavors have started integrating concepts from mean-field multi-
agent RL (Yang et al., 2018) to handle spatio-temporal interference effects (Shi et al., 2023; Luo et al.,
2024). This approach marks a significant step towards modeling the complex interactions in environ-
mentswhereactionsinonelocationortimecaninfluenceoutcomesinanother. However,akeylimitation
of these emerging methods is their dependency on specifying the mean-field function. This requirement
often poses challenges in terms of flexibility and adaptability, particularly when applied to diverse and
unpredictable real-world settings where the dynamics of interference are not easily quantifiable or pre-
defined. Therefore, while these methods mark a critical advancement towards OPE with spatial data,
there remains a need for further development to enhance their applicability and efficacy in a wider range
of practical applications.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 3
1.2.3. Permutation Invariance
Permutation invariant functions, which maintain their output regardless of the order of their inputs,
are prevalent in domains such as cosmology (Ntampaka et al., 2016) and computer vision (Aittala and
Durand, 2018). This characteristic has led to the design of numerous geometric deep learning models
specifically aimed at approximating these types of functions (Bronstein et al., 2017). A notable example
is the structure called DeepSets, proposed by Zaheer et al. (2017), which is capable of approximating
any permutation invariant function. DeepSets has shown impressive performance in a number of tasks
such as sum of digits, classification of point-clouds, and regression with clustering side-information,
highlighting its versatility. Expanding on this concept, the PINE model (Gui et al., 2021) offers a gen-
eralization of DeepSets by studying partially permutation invariant functions. In these functions, inputs
arecategorizedintodistinctgroups, andthefunctionremainsinvarianttopermutationsoccurringwithin
these individual groups. This design allows for greater flexibility in various contexts. Applying these
permutation invariant models to studying the interference effects in spatio-temporal systems appears to
be a natural progression. However, there is a lack of existing literature specifically addressing the appli-
cation of these models in spatio-temporal interference modeling. This gap suggests an opportunity for
novel research contributions in this area, potentially leading to advancements in understanding complex
spatio-temporal systems, such as ride-sharing platforms.
Fig. 1: The illustration of permutation invariant (PI) mean-outcome function. The red hexagon repre-
sents confounder-treatment pair of the central region while the other six hexagons represent its neigh-
boring regions. The upper-right subplot shows the mean-outcome function with only general network
interference assumption 1. Here, the output of f changes across different permutations of neighboring
regions. On the other hand, the subplot on the right bottom shows that with the permutation invariant
assumption 2, all outputs have the same value.
1.3. Contributions
In our paper, we introduce a novel causal deepsets model designed to address spatial interference, in-
corporating several innovative elements. Firstly, we propose a permutation invariant neural network
architecture that effectively manages spatial interference. This architecture aggregates information from
neighboring areas and constructs a general permutation invariant function through neural networks,
thereby moving beyond traditional parametric models and facilitating adaptive learning of interference
patterns. Additionally, we seamlessly combine this architecture with OPE algorithms to produce robust
causal estimators. For spatio-temporal data, we further employ the multi-agent RL (MARL) framework
which models each spatial region as an individual agent to capture spatial interference through agent
interactions and utilizes Markov decision processes (MDPs, Puterman, 2014) to model temporal rela-
tionships. Our methodology’s efficacy is evidenced through comprehensive simulations and real data
analyses, where it demonstrates outstanding performance. Beyond these methodological advancements,
we conduct an in-depth theoretical analysis of our proposed estimator. We establish its consistency and
convergence rate under practical assumptions. We also prove the minimax optimality of our estimator
in approximating permutation invariant functions, underscoring our approach’s capability in accurately4 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
representingandmanagingcomplexinterferencestructures. Consideringthatourestimatorisbuiltupon
the assumption of permutation invariance, we have named it the Permutation Invariant Estimator, or
PIE, for short.
1.4. Paper Outline
The paper is structured as follows. In Sections 2 and 3, we focus on the derivation of our estimators,
along with the underlying assumptions. The statistical properties of our method are discussed in Section
4. InSection5,wepresenttheresultsofnumericalstudiesandrealdataanalysis,showcasingthesuperior
performance of our approach.
2. Spatial Interference in Nondynamic Settings
This section aims to thoroughly explore the issue of spatial interference in nondynamic settings, often
referred to as contextual bandits in OPE. Spatial interference implies that the potential outcome in one
region is influenced by other regions. We denote each region by an index i within the set {1,...,R}.
For the ith region, Y , A , and X = (X ,...,X )⊤ ∈ RM represent the response, treatment, and
i i i i,1 i,M
M-dimensional confounding variables, respectively.
In scenarios without spatial interference, a region’s outcome is a function of its own confounding
variables and treatment:
Y = f (X ,A )+ϵ , (1)
i i i i i
where the error term ϵ satisfies E(ϵ |{A }R ,{X }R ) = 0. In practical applications, however, the
i i j j=1 j j=1
assumption of no interference is often unrealistic, making model (1) inapplicable. Without specific
knowledge of the interference pattern, the outcome in a region can generally be expressed as a function
of its own confounding variables and the treatments across all regions:
Y = f (X ,A ,m (X ,A ))+ϵ , (2)
i i i i i −i −i i
where X = (X ,...,X ,X ,...,X ) and A = (A ,...,A ,A ,...,A ). Here, f includes
−i 1 i−1 i+1 R −i 1 i−1 i+1 R i
two components: the first reflecting the ith region’s contribution and the second capturing interference
effects from other regions, denoted by the function m (·). This model, depicted in Figure 2b, extends
i
beyond traditional models that only consider neighboring region effects (see e.g., Reich et al., 2021).
Specifically,theinterferenceeffectfunctionm (·)in(2)accountsforinfluencesfromallregions. Moreover,
i
this framework accommodates nonlinear interference effects, which are common in real-world scenarios.
Model(2)offersabroadframeworkforunderstandingspatialinterference,butitscomplexitybecomes
daunting with the increase in the number of regions, often rendering it impractical to solve. To combat
this, various strategies have been developed to reduce its complexity. One notable approach is spatial
network inference (see e.g., Forastiere et al., 2021), which narrows the focus to interactions between
regions and their immediate neighbors. While “neighborhood” could be defined in various ways, we
simplify it here to mean geographical proximity.
The study of spatial interference has a rich history (Blume, 1993). Many researchers have posited
that interference typically occurs within a defined neighborhood and can be transmitted via environ-
mental conduits like adjacent regions. Although this method simplifies the complexity of inter-regional
interactions, it still implies dependencies between any two regions due to their potential indirect con-
nections. There’s often at least one indirect path connecting any two regions, creating a dependency
link. For example, consider two non-adjacent units A and B. In this case, A would be conditionally
independent of B if we have complete information about A’s neighbors. However, indirect connections
between A and B are still permissible. Our proposed approach is based on such an understanding of
spatial interdependencies.
Assumption 1 (General Network Interference). The outcome within a particular region is
conditionally independent of all other pairs of confounders and treatments, provided the pairs of con-
founders and treatments of its neighboring regions are given.
We remark that Assumption 1 slightly generalizes existing network inference by permitting the out-
come of a region to be influenced by both the treatments and confounders of its neighboring regions;
see Figures 2c and 2d for illustrations. From a mathematical perspective, let N(i) denote the index setCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 5
(a)Nospatialinterference (b) Full spatial interfer- (c) Network interference (d)Generalnetworkinter-
(1) ence (2) Forastiere et al. (2021) ference (3)
Fig. 2: Variable dependencies under different spatial interference structures. The dashed line represents
the spatial interference effect. Each line represents a different region and horizontal adjacency depicts
the proximity of regions.
of neighboring regions for region i. Let X and A represent the confounders and treatments of
N(i) N(i)
neighboring regions for region i, respectively. Then, according to Assumption 1,
Y = f (X ,A ,m (X ,A ))+ϵ , (3)
i i i i i N(i) N(i) i
for some interference function m that measures the interference effect.
i
Various methods have been proposed to model the function m (·,·). A prominent method is the
i
mean-field approach, in which m (·,·) is defined by the average values of X and A (Yang et al.,
i N(i) N(i)
2018; Li and Wager, 2022; Shi et al., 2023). This can be expressed as:
1 (cid:88)
m (X ,A ) = [X ,A ]. (4)
MF,i N(i) N(i) |N(i)| j j
j∈N(i)
The mean-field method greatly simplifies the interference structure by averaging the inputs from neigh-
boring units. However, it also implies a strong parametric assumption, which could limit its flexibility.
Given these considerations, it is reasonable to explore whether a more robust interference structure can
be identified using minimal assumptions. This pursuit leads to the consideration of the permutation in-
variant assumption, offering a potentially more flexible and comprehensive approach to modeling spatial
interference.
2.1. PIE: A Permutation-Invariant Estimator with Interference Effect
We first introduce some definitions pertaining to permutation-invariant functions.
Definition 1 (Permutation operator). Given an index set I = {1,2,...,N} with N integers,
the permutation operator Π is a one-to-one mapping Π : I → I such that Π = {Π(1),Π(2),...,Π(N)}
I
is the resulting permutation of I. Let the symmetric group S denote the set containing all permutations.
N
Apparently, we have |S | = N!.
N
For instance, consider the set I = {1,2,3}, which has six different permutations. Let Π denote the
permutation operator such that Π(1) = 3,Π(2) = 1,Π(3) = 2. We have Π = {3,1,2}. With the
I
definition of permutation operator, we impose the permutation invariant assumption on mean outcome
function.
Assumption 2 (Permutation Invariance). For any given region i, the mean-outcome function
f (X ,A ,m (X ,A )) exhibits Permutation Invariance with respect to its neighboring regions. This
i i i i N(i) N(i)
implies that for any permutation Π : N(i) → N(i), the following holds true:
f (X ,A ,m (X ,A )) = f (X ,A ,m (X ,A )).
i i i i N(i) N(i) i i i i Π N(i) Π N(i)
In essence, the outcome function remains unchanged regardless of the order in which the neighboring
regions are considered, emphasizing a key characteristic of spatial invariance in the model.
This assumption is based on the observation that, from the perspective of the target region, all
neighboring regions are indistinguishable. Therefore, the interference effect of neighbors on the center6 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
regiondependssolelyontheirfeaturesandisindependentoftheorder. Assumption2providesaproblem-
specific description of the permutation invariant property within the context of spatial causal inference.
A more general definition will be formalized in Section 4. As an example, it is immediate to see f
i
is permutation invariant to neighboring regions with m (·) = m (·) in (4). However, Assumption 2
i MF,i
alleviates the parametric constraint imposed by the mean-field interference function, thereby enhancing
its expressiveness. In the subsequent section, we will illustrate through theoretical and experimental
analysis how this relaxation enhances expressivity.
OurobjectiveistodevelopanestimatorthatnotonlyadherestoAssumptions1and2butalsoadeptly
captures the complex nature of spatial interference. Research on permutation invariant interference
structures is scant. The following theorem provides a closed-form expression for any such permutation
invariant estimator (PIE) .
Theorem 1 (Permutation Invariant Estimator (PIE)). Assuming that Assumptions 1 and 2
hold, the mean outcome function f can be accurately approximated by the following estimator, achieving
i
any desired level of precision with the appropriate selection of the functions ϕ and ψ ,
i i
ψ (X ,A ,m (X ,A ))
i i i PIE,i N(i) N(i)
1 (cid:88)
with m (X ,A ) = ϕ (X ,A ). (5)
PIE,i N(i) N(i) |N(i)| i j j
j∈N(i)
Theorem 1 suggests a versatile method for approximating PI mean outcome functions. The proposed
PIEframework,withitsfocusonaveragingoverneighboringregions, inherentlysatisfiesthepermutation
invariance criterion. The mean-field function in (4) can be seen as a specific instance of m when
PIE,i
{ϕ } are identity functions.
i i
Itremainstospecify{ϕ } and{ψ } . Forpracticalapplication, werecommendtoemploydeepneural
i i i i
networkstoparameterizethesefunctions. Figure3graphicallyillustratestheresultingarchitecture. The
treatment and confounding variables from neighboring regions are concatenated into a single vector and
inputintoafeedforwardneuralnetworkϕ ,capturingtheirintricateinterrelations. Subsequently,toalign
i
withAssumption2, theseneighboringeffectsareaveraged. Theoutputisthencombinedwiththecentral
region’s treatment-confounder vector and processed through another feedforward network ψ , resulting
i
in the final mean outcome value. Section 4 will demonstrate that this architecture also functions as a
universalapproximator, capableofpreciselyapproximatinganypermutation-invariantinterferenceeffect
function. Contrarily, traditional mean-field structures lack the versatility to effectively represent general
permutation-invariant functions.
To demonstrate the effectiveness of the proposed neural network structure, let us revisit our ride-
sharing example. In this system, potential customers use the ride-sharing app to compare prices and
decide whether to place an order. Each region’s confounding vector X includes variables like the total
i
number of orders O and the total number of available drivers D , reflecting the supply and demand
i i
dynamics of this marketplace. The system, following a specific dispatch policy, pairs orders with drivers,
generating revenue Y when an order is completed.
t
As previously mentioned, this ride-sharing system experiences significant spatial interference, as
drivers often gravitate towards areas with more orders and fewer competing drivers. Additionally, the
system may strategically assign move drivers to nearby regions with driver shortages, enhancing pickup
rates and service coverage. This process, which involves assessing the supply-demand imbalance between
neighboring regions, is discussed in detail in Zhou et al. (2021a). The imbalance in each region, is typ-
ically a function of the total orders O and drivers D and often quantified as M = |D −O | (Shi
i i i,t i,t i,t
et al., 2023). This results in an average mismatch
|N(i)|−1(cid:80)
|D −O | for the ith region.
j∈N(i) j,t j,t
For an effective assessment of interference, the mean outcome function f must accurately reflect this
i
mismatch. The neural network-based PIE is able to approximate this mismatch with high precision.
Particularly, when using the ReLU activation function, the proposed m can perfectly replicate the
PIE,i
averageabsolutedifferencewithoutanyapproximationerror. Incontrast,ameanoutcomefunctionusing
(cid:80) (cid:80)
the traditional mean-field interference effect can only model functions of D and O .
j∈N(i) j,t j∈N(i) j,t
It is, however, not capable of effectively capturing the mismatch represented by
|N(i)|−1(cid:80)
|D −
j∈N(i) j,t
O |.
j,t
To conclude this section, here are some key highlights of the proposed estimator:
• Objective and Flexibility: The primary goal of PIE is to accurately identify suitable mean
outcome functions under the permutation invariance condition. The functions {ϕ } and {ψ }
i i i iCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 7
Fig. 3: The proposed structure is depicted in a graphical visualization. In this representation, the
hexagonal prism at the bottom-right corner symbolizes the confounder-treatment vector for a central
region (colored green) and its six neighboring regions (colored blue). The vectors from these neighboring
regions are simultaneously input into the same neural network, denoted by ψ. The aggregated output
from this process forms the PIE interference effect function, m . Subsequently, the central region’s
PIE,i
vector is concatenated with m . The final estimator is then obtained after this combined vector is
PIE,i
processed through a feedforward neural network, labeled as ϕ.
are instrumental in capturing the complex interference structure, which may vary across different
settings. Utilizing deep neural networks to parameterize these functions enables the application of
advanced machine learning techniques in spatial causal inference, providing a robust framework for
diverse environmental contexts.
• Permutation Invariance and Extensibility: The effectiveness of our approach is anchored
in the permutation invariance assumption. If this assumption does not hold, the PIE can be
modified to align with necessary extensions. For example, instead of using a simple average in
ϕ(X ,A ),aweightedaveragecouldbeemployed,withweightstailoredtothespecificcharacteristics
j j
of neighboring regions. This adaptability further enhances the applicability of PIE to a even wider
range of scenarios.
2.2. Application to Policy Evaluation in Nondynamic Settings
To demonstrate the versatility of the proposed architecture, we apply PIE to OPE in nondynamic
settings. The observed data consists of the confounders-treatment-outcome triplets {(X ,A ,Y ) :
i,j i,j i,j
1 ≤ i ≤ R,1 ≤ j ≤ S} measured over time. In our ridesharing application, {(X ,A ,Y ) : 1 ≤
i,j i,j i,j
i ≤ R} corresponds to the data collected on the jth day. We assume these triplets are i.i.d. copies of
{(X ,A ,Y ) : 1 ≤ i ≤ R} defined at the beginning of Section 2. It is important to note that while there
i i i
are strong temporal correlations within each day’s data, it is reasonable to assume independence across
different days, provided that the same treatment is implemented throughout each day. This assumption
is partly based on the observation that order volumes typically decrease significantly between 1 am and
5 am. Consequently, we treat the observations of each day as new, independent realizations. In Section
3, we will study settings where different treatments are implemented across various time periods within
each day.
We next introduce our estimand. In real-world applications, it is often necessary to understand
the effects of implementing a specific policy denoted by π = (π ,...,π ). Each π corresponds to a
1 R i
deterministic function of the confounding vector, indicating the treatment assignment for the ith agent.8 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Specifically, on the tth day, the ith agent receives the treatment π (X ). To simplify the presentation,
i i,j
we assume that all agents receive the same treatment assignment function, i.e., π = π = ... = π ,
1 2 R
which we denote as π. This assumption allows us to use a single symbol to represent the common
mapping. However, it is worth noting that our approach can be easily extended to scenarios where the
treatment assignment functions {π } differ among agents, accommodating more complex settings.
i i
We are interested in evaluating the average reward under π, given by
R
(cid:88)
J(π) = E[E(Y |{A = π(X )}R ,{X }R )], (6)
i p p p=1 p p=1
i=1
Here, the initial expectation in (6) is with respect to the distributions of {X }R , while the second
p p=1
expectation pertains to the conditional distribution of the outcome given all confounder-treatment pairs.
Following the formulation of our estimand, we construct three OPE estimators utilizing the proposed
PIE, corresponding to the value-based estimator, the importance sampling estimator and the doubly
robust estimator, respectively.
2.2.1. Value-based Method
Thevalue-basedmethodinvolvesatwo-stepprocedure. UnderAssumption1,theconditionalexpectation
of Y is given by f (X ,A ,m (X ,A )), so the initial step involves the estimation of the regression
i i i i i N(i) N(i)
function f i. In the second step, the obtained estimator f(cid:98)i is plugged in to value-based estimate of the
policy value, i.e.,
S R
1 (cid:88)(cid:88)
J(cid:98)VB(π) =
S
f(cid:98)i(X i,j,π(X i,j),m (cid:98)i(X N(i),j,π(X N(i),j))), (7)
j=1 i=1
where we use the proposed PIE in Theorem 1 to parameterize f(cid:98)i and m (cid:98)i, respectively. Recall that
X denotes the vector obtained by concatenating {X } and the vector π(X ) is obtained
N(i),j p,j p∈N(i) N(i),j
by applying the policy π componentwise to each element of X N(i),j. The parameters in f(cid:98)i and m
(cid:98)i
are
estimated by minimizing the least square loss function,
S
1 (cid:88)
(f(cid:98)i,m (cid:98)i) = argmin
S
[Y
i,j
−f i(X i,j,π(X i,j),m i(X N(i),j,π(X N(i),j)))]2. (8)
(f ,m )
i i j=1
The above formulation can be viewed as a regression problem, where the reward Y is regressed on the
i,j
tuple (X ,π(X ),X ,π(X ) using the network structures proposed. It is worth mentioning
i,j i,j N(i),j N(i),j)
that the value-based estimator may suffer from a significant bias when f(cid:98)i and m
(cid:98)i
are misspecified,
renderingitlessrobust. Thismotivatesustoconsidertheimportancesamplingmethodasanalternative
approach.
2.2.2. Importance Sampling Method
The importance sampling method is motivated by the change-of-measure theorem which yields that
EπY =
E(cid:104) I(A i = π(X i))(cid:81) p∈N(i)I(A p = π(X p))
Y
(cid:105)
,
i P(∩ {A = π(X )}∩{A = π(X )}|X ,X ) i
p∈N(i) p p i i i N(i)
(cid:124) (cid:123)(cid:122) (cid:125)
ωπ(X ,X ,A ,A )
i i N(i) i N(i)
where ωπ denotes the importance sampling ratio. This suggests the following important sampling esti-
i
mator for the policy value J(π),
S R
1 (cid:88)(cid:88)
ωπ(X ,X ,A ,A )Y ,
S (cid:98)i i,j N(i),j i,j N(i),j i,j
j=1 i=1
for some estimated ratio ωπ.
(cid:98)iCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 9
Nevertheless, the above estimator exhibits substantial variance introduced by the importance sam-
pling ratio. To elucidate this limitation, we consider the case where the overall ratio is the product of
ratios associated with each individual region in the neighborhood set. As the number of neighborhoods
for one unit increases, the variances in the individual ratios accumulate multiplicatively. Consequently,
the variance of the overall ratio grows exponentially fast with respect to the number of neighborhoods,
leading to an estimator with exceedingly high variance.
To address this limitation, we notice that under Assumption 1, Y is conditionally independent of
i
(X ,A ) given A , X and the interference effect function m (X ,A ). Utilizing this condi-
N(i) N(i) i i i N(i) N(i)
tional independence property, we obtain that
E[ωπ(X ,X ,A ,A )Y ] = E[ωπ(X ,A ,m (X ,A ))Y ],
i i N(i) i N(i) i i i i i N(i) N(i) i
where
ωπ(X ,A ,m (X ,A )) = E[ωπ(X ,X ,A ,A )|X ,A ,m (X ,A )],
i i i i N(i) N(i) i i N(i) i N(i) i i i N(i) N(i)
whose closed-form is given by
I(A = π(X ),m (X ,A ) = m (X ,π(X )))
i i i N(i) N(i) i N(i) N(i)
.
P(A = π(X ),m (X ,A ) = m (X ,π(X ))|X ,X )
i i i N(i) N(i) i N(i) N(i) i N(i)
In practice, the likelihood of the two equalities in the numerator perfectly coincide is quite low. Instead
of insisting on exact equality, we adopt a different approach to reduce the variance. Specifically, we
only require that the Euclidean difference between the left-hand side and right-hand side of each equa-
tion is smaller than a predefined τ. This yields the following importance sampling ratio, denoted by
ωπ (X ,A ,m (X ,A )),
i,τ i i i N(i) N(i)
I(|A −π(X )| < τ,|m (X ,A )−m (π(X ,X ))| < τ)
i i i N(i) N(i) i N(i) N(i)
.
P(|A −π(X )| < τ,|m (X ,A )−m (X ,π(X ))| < τ|X ,X )
i i i N(i) N(i) i N(i) N(i) i N(i)
The resulting importance sampling estimator is given by
S R
1 (cid:88)(cid:88)
J(cid:98)IS(π) =
S
ω (cid:98)i,τ(X i,j,A i,j,m i(X N(i),j,A N(i),j))Y i,j,
j=1 i=1
where ω
(cid:98)i,τ
denotes some consistent estimator for ωπ i,τ. The consistency of J(cid:98)IS(π) relies on the estimation
accuracies of ω and m .
(cid:98)i,τ (cid:98)i
2.2.3. Doubly Robust Method
The doubly robust estimator is given by
S R
1 (cid:88)(cid:88)
J(cid:98)DR(π) = J(cid:98)VB(π)+
S
ω (cid:98)i,τ(X i,j,X N(i),j,A i,j,A N(i),j)[Y
i,j
−f(cid:98)i(X i,j,A i,j,m (cid:98)i(X N(i),j,A N(i),j))].
j=1 i=1
By definition, J(cid:98)DR(π) can be decomposed into two terms. The first term is essentially the value-based
estimator. The second term, is a “centered” importance sampling estimator where we replace the
response Y
i
by the residual Y
i,j
−f(cid:98)i(X i,j,A i,j,m (cid:98)i(X N(i),j,A N(i),j)). The purpose of adding the second
term is to debias the bias of J(cid:98)VB(π) resulting from the estimation of {f(cid:98)i} i. In particular, when {m (cid:98)i}
i
is consistent, it can be shown that the consistency of J(cid:98)DR(π) relies only on the consistency of {f(cid:98)i}
i
or
{ω (cid:98)i,τ} i. Meanwhile, it can be shown that J(cid:98)DR(π) converges at a much faster rate than these nuisance
functions themselves (Chernozhukov et al., 2018).
So far, we have presented our approach to estimating the mean outcome in non-dynamic settings.
However, interference effects are not confined solely to the spatial realm; they also manifest temporally.
Thetreatmentsappliedatpresentcanimpactnotonlyimmediateoutcomesbutalsofutureones,through
their influence on the distribution of forthcoming confounding variables. This necessitates an extension
of spatial interference models to account for temporal interference.10 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
3. Spatio-temporal Interference in Dynamic Settings
In this section, we will integrate concepts from multi-agent reinforcement learning (MARL) to address
additional temporal interference, treating the process as an MDP. This allows us model how actions
takenatonepointintimecanaffectoutcomesatsubsequentpoints. Wewillintroduceseveralestimators
designedtoaccuratelyevaluatetheaveragetreatmenteffectinscenarioswherebothspatialandtemporal
interference are present.
3.1. Interference Modelling via MDP
Inadynamicsetting,theindependenceassumptionamongconfounder-treatment-outcometripletsatdif-
ferent time points is no longer valid. Thus, we encounter both spatial and temporal interference, necessi-
tating the introduction of new assumptions to appropriately model both interference structures. Spatial
interference continues to be described by the spatial interference function m, as in the non-dynamic
setting. Temporal interference, however, is twofold. Firstly, an individual’s response is influenced by the
confounders and treatments in neighboring regions. Secondly, the present confounders are affected by
the history of past confounder-treatment interactions.
Mirroring Assumption 1 from the non-dynamic context, we approach temporal interference by im-
posing specific conditional independence assumptions which relate to the future confounder, current
confounder-treatment-response triplet, and their historical context. For ease of explanation, let X
·,t
represent the set {X } at each time t, and similarly for A (treatment) and Y (response). The following
i,t i
assumptions detail the conditional independence properties in this dynamic setting.
Assumption 3 (Conditional mean independence assumption (CIMA)). Thereexistfunctions
{r } such that for each region i (where 1 ≤ i ≤ R), the following equation is almost surely satisfied:
i i
E(Y |A ,X ,{A ,X ,Y } ) = r (A ,X ,m (A ,X )),
i,t ·,t ·,t ·,k ·,k ·,k 0≤k<t i i,t i,t i N(i),t N(i),t
where m (·) represents the interference effect function.
i
Assumption 4 (Markov assumption (MA)). ThereexistMarkovtransitionkernelP (·)suchthat
i
for any t ≥ 0 and x ∈ S, we have almost surely that
Pr{X = x|A ,X ,{A ,Y ,X } } = P (x;A ,X ,m (A ,X )).
i,t+1 ·,t ·,t ·,k ·,k ·,k 0≤k<t i i,t i,t i N(i),t N(i),t
To verify these assumptions, one can employ the approach proposed by Shi et al. (2020) and test the
conditional independence using appropriate statistical tests (see e.g., Chen and Hong, 2012; Shah and
Peters, 2020; Kim et al., 2022; Polo et al., 2023). Additionally, these assumptions can be satisfied by
concatenating measurements over several decision points and selecting the optimal order. By combining
the assumption on spatial interference (Assumption 1) with these temporal interference assumptions, we
establish the assumption on spatio-temporal interference effects.
In a similar vein to Assumption 2 in a static setting, we propose that both the response function r (·)
i
and the transition kernel P (·) are unaffected by the order of neighboring regions. This means for any
i
given region i and any permutation Π : N(i) → N(i), the following holds true:
r (X ,A ,m (X ,A )) = r (X ,A ,m (X ,A )),
i i,t i,t i N(i),t N(i),t i i,t i,t i Π N(i),t Π N(i),t
P (X ,A ,m (X ,A )) = P (X ,A ,m (X ,A )).
i i,t i,t i N(i),t N(i),t i i,t i,t i Π N(i),t Π N(i),t
With the interference assumptions in place, conventional reinforcement learning models can be adapted
to form PIE estimators. The details and discussions will be presented in the following section.
3.2. Application to Offline Policy Evaluation
In the dynamic setting, the observed data consists of S i.i.d samples of {(X ,A ,Y ) : 1 ≤ i ≤ R,1 ≤
i,t i,t i,t
t ≤ T} generated under a specific behavior policy, each of which is a confounders-treatment-outcome
triplet measured over time. Consequently, the observed data can be represented as {(X ,A ,Y ) :
i,t,j i,t,j i,t,j
1 ≤ i ≤ R,1 ≤ t ≤ T,1 ≤ j ≤ S}, where j indicates the index of the sample. In our illustrative
ridesharing example, the index i denotes the ith spatial unit, j corresponds to the jth day, and t
represents the tth time interval within each day. This dynamic model, as compared to the nondynamic
one discussed in Section 2, facilitates the analysis of scenarios where the company may implement
different treatments on each day.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 11
In this section, we consider a known deterministic stationary policy π = (π ,...,π ), where each π
1 N i
is a deterministic decision rule mapping X ∈ RM to {0,1} and remains constant across all time periods
i,t
t. We assume the conditions of CMIA and MA are met, and extend the concept of average reward to
a dynamic context by introducing the discounted cumulative outcome. This is calculated for a given
discount factor 0 ≤ γ ≤ 1 over a time horizon of T steps, as shown in the equation:
R T
(cid:88)(cid:88)
J (π) = γtE[E(Y |A = π(X ),X )]. (9)
γ i,t ·,t ·,t ·,t
i=1 t=1
Here, the first expectation accounts for the distribution of the Markov transition kernels {P } and the
i i
distributionoftheinitialconfoundersX . Thesecondexpectationpertainstotheconditionaldistribution
0
of the outcome given the confounder-treatment pairs.
We adapt the three estimators discussed in Section 2.2 to the dynamic setting. These are the value-
based estimator, the importance sampling estimator, and the doubly robust estimator. Each is tailored
to estimate the discounted cumulative outcome function J (π).
γ
3.2.1. Value-based Method
To introduce the value-based estimator, we first simplify the notations. For 0 ≤ t ≤ T, let
(X ,A ) = (X ,A ,X ,A ),
N∗(i),t N∗(i),t i,t i,t N(i),t N(i),t
M (X ,A ) = (X ,A ,m (X ,A )), (10)
i N∗(i),t N∗(i),t i,t i,t i N(i),t N(i),t
where N∗(i) = N(i)∪{i} denotes the index of the central and neighboring regions. Similarly, we use M(cid:99)i
to denote the corresponding estimated M by substituting m with its estimator m . Next, we introduce
i i (cid:98)i
the Q-function as the expected discounted accumulative outcome given current confounder-treatment
pair:
T
(cid:88)
Q(i,k)(X ,A ) = E[Y + γt−kE(Y |X ,π(X ))|X ,A ]
π ·,k ·,k i,k i,t ·,t ·,t ·,k ·,k
t=k+1
T
= E[Y + (cid:88) γt−kE(cid:0) Y |X ,π(X )(cid:1)(cid:12) (cid:12)X ,A ], (11)
i,k i,t N∗(i),t N∗(i),t (cid:12) N∗(i),k N∗(i),k
t=k+1
(i,k)
where the second equation comes from assumptions CMIA and MA and we rewrite Q (X ,A )
π ·,k ·,k
(i,k)
to Q (X ,A ) due to the conditional independence. The discounted cumulative outcome
π N∗(i),k N∗(i),k
J (π) can be represented using the Q-function:
γ
(cid:34) R (cid:12) (cid:35)
J γ(π) = E (cid:88) Q( πi,1)(X N∗(i),1,A N∗(i),1)(cid:12) (cid:12)A
N∗(i),1
∼ π i(X N∗(i),1) , (12)
(cid:12)
i=1
wheretheexpectationistakenwithrespecttothedistributionofX . Thismotivatesustofirstestimate
·,1
the Q-function and then construct the value based estimator J(cid:98)γ(π).
The Q-function can be estimated with the fitted Q-evaluation algorithm (Le et al., 2019). For each
(i,T+1)
region 1 ≤ i ≤ R, we first set Q(cid:98)π = 0 and for t = T,...,1, we iteratively solve:
S
(cid:88)(cid:104) (cid:16) (cid:17)
(Q(cid:98)( πi,t),M(cid:99)i) ← arg min Y
i,t,j
+γQ(cid:98)( πi,t+1) M(cid:99)i(X N∗(i),t+1,j,π(X N∗(i),t+1,j)) (13)
(Q,M)
j=1
(cid:3)2
−Q(M(X ,A )) , (14)
N∗(i),t,j N∗(i),t,j
Utilizing the relationship between Q-function and J
γ
in (12), we can construct J(cid:98) γVB(π) as follows:
S R
1 (cid:88)(cid:88)
J(cid:98) γVB(π) =
S
Q(cid:98)( πi,1)(M(cid:99)i(π i(X N∗(i),1,j),X N∗(i),1,j))). (15)
j=1 i=112 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
3.2.2. Importance Sampling Method
The importance sampling estimator is constructed based on the marginal density ratio proposed in Liu
et al. (2018):
(cid:80)T γtp (M (X ,A ))/(cid:80)T γt
µ(i)(M (X ,A )) = t=1 π,t i N∗(i),k N∗(i),k t=0
π i N∗(i),k N∗(i),k p (M (X ,A ))
i i N∗(i),k N∗(i),k
(cid:80)T γtp (M (X ,A ))
≈ (1−γ) t=1 π,t i N∗(i),k N∗(i),k ,
p (M (A ,X ))
i i N∗(i),k N∗(i),k
where p denotes the probability mass function of confounder-treatment pair (X ,A ) under
π,t N∗(i),t N∗(i),t
π at time step t, and p denotes the stationary distribution under the behavior policy. The above
i
approximation requires T → ∞, a condition that is reasonable in ridesharing applications where T
typically equals 24 or 48. This is considered moderately large relative to the sample size S (number of
days).
(i)
Notethatµ istheratiobetweentheaveragediscountedprobabilitydistributionofM (X ,A )
π i N∗(i) N∗(i)
under the target policy and its data distribution under the behavior policy. Using the change of measure
theorem, J (π) can be represented as:
γ
(cid:34) (cid:35)
R
1 (cid:88)
J (π) = E µ(i)(M (X ,A ))Y
γ X,A∼p (1−γ) π i N∗(i),k N∗(i),k i,k
i=1
(i)
Its estimator µ can be computed by solving the following minimax optimization,
(cid:98)π
argminsup{EL(µ,f)}2,
µ∈Ωf∈F
for some function classes Ω and F, where L(µ,f) equals
E µ(M (X ,A )){γf(M (X ,A ))
A N∗(i),t+1∼π(X N∗(i),t+1) i N∗(i),t N∗(i),t i N∗(i),t+1 N∗(i),t+1
−f(M (X ,A ))}+(1−γ)E f(M (X ,A )).
i N∗(i),t N∗(i),t A N∗(i),0∼π(X N∗(i),0) i N∗(i),1 N∗(i),1
The expectation in the above expression can be approximated by the sample mean. To simplify the
calculation, we may choose F to be a reproducing kernel Hilbert space (RKHS). This yields a closed
formexpression forsup {EL(µ,f)}2 (seee.g., Liuet al.,2018;Uehara etal., 2020;Kallusand Uehara,
f∈F
2022). Notice that in the above optimization, although M
i
is unknown, we can replace it by {M(cid:99)i}R
i=1
derived in 14. Then resulting estimator is given by
R S T
1 (cid:88)(cid:88)(cid:88)
V(cid:98) 1IS(π) =
ST(1−γ)
µ (cid:98)( πi)(M(cid:99)i(X N∗(i),t,j,A N∗(i),t,j))Y i,t,j.
i=1 j=1 t=1
3.2.3. Doubly Robust Method
Combining the direct estimator and the importance sampling estimator yields the following doubly-
robust estimator
R S T
1 (cid:88)(cid:88)(cid:88)
V(cid:98) 1DR(π) = J(cid:98) γVB(π)+
ST(1−γ)
µ (cid:98)( πi)(M(cid:99)i(X N∗(i),t,j,A N∗(i),t,j))
i=1 j=1 t=1
(i,t+1) (i,t)
× {Y
i,t,j
+γQ(cid:98)
i
(M(cid:99)i(X N∗(i),t+1,j,π(X N∗(i),t+1,j)))−Q(cid:98)
i
(M(cid:99)i(X N∗(i),t,j,A N∗(i),t,j))}.
Similar to the doubly robust estimator in non-dynamic settings (see Section 2.2.3), the first term is
the value based estimator where the second term differs from the importance sampling estimator by
substituting the outcome Y with the temporal difference residual Y +γQ(t+1) −Q(t). Either when the
value based or important sampling estimator is consistent, the doubly robust estimator is consistent.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 13
4. Theoretical Results
This section provides a detailed analysis of the statistical properties of PIE. Initially, we explore the
theoretical properties of PIE in a generic supervised learning setting. This includes an examination of
their consistency, convergence rate, and minimax optimality. Subsequently, we apply these theoretical
results to evaluate the sample efficiency of value-based PIE in both non-dynamic (see Section 2.2.1) and
dynamic settings (see Section 3.2.1).
4.1. Theoretical properties of PIE
We establish the theoretical properties of PIE in a generic supervised learning setting. Let X =
[X ,X ,...,X ] ∈ RM×N denote the predictor and Y ∈ R denote the outcome variable. Our goal
1 2 N
is to estimate the conditional mean function f∗(x) = E(Y|X = x). Toward that end, we restrict our
attentions to the class of permutation invariant estimators F defined as
   
(cid:12) N
F =  f : RM×N (cid:55)→ R(cid:12) (cid:12)f(X) = ψ(cid:88) φ(X q),φ,ψ ∈ F ReLU ,
(cid:12)
 
q=1
where the detailed definition of ReLU neural networks is given in Appendix. Consider the following
empirical risk minimization (ERM) predictor
n
1 (cid:88)
f(cid:98)= argmin [Y −f(X )]2, (16)
f∈F n (j) (j)
j=1
where {(X ,Y ) : 1 ≤ j ≤ n} denote n i.i.d. copies of (X,Y).
(j) (j)
We introduce the following assumptions
Definition 2 (Permutation Invariant Functions). A function f is defined to be permutation
invariant function if for any permutation Π ∈ S .
N
f(X) = f(X ,X ,...,X ),
Π(1) Π(2) Π(N)
where the permutation operator Π is defined in Definition 1.
Assumption 5 (Permutation Invariance). Assume the target function f∗ is a permutation in-
variant function as defined in Definition 2.
BeforeestablishingtheconsistencyofthePIE,weneedthefollowingassumptionsontheboundedness
and continuity of target function:
Assumption 6 (Boundedness). Let ∥f∥ = sup |f(x)| and F denote the envelope function of F,
∞ x
i.e., F(x) = sup |f(x)|. Assume there exist some constant J > 0 such that
f∈F
max{∥f∗∥ ,∥F∥ ,|Y|} ≤ J.
∞ ∞
Assumption 7 (Continuity). Assume the target function f∗ is continuous function defined on
[0,1]M×N.
The assumption of a continuous and bounded target function is commonplace in nonparametric settings.
The response variable Y is often assumed to be bounded in the RL literature (see e.g., Fan et al., 2020).
The following theorem specifies the consistency of PIE.
Theorem 2 (Consistency of PIE). Under Assumption 6, the ERM estimator f(cid:98)is consistent for
the target function f∗ in the sense that as n → ∞,
∥f(cid:98)−f∗∥2 → 0,
L (P )
2 X
in which the convergence occurs with probability at least 1−2/n. Here, ∥·∥ denotes the L norm
L (P ) 2
associatedwiththeprobabilitydistributionfunctionofX (denotedbyP ), i.e.,2 ∥fX ∥2 = (cid:82) f(x)2dP .
X L (P ) x X
2 X
To further establish the convergence rate of f(cid:98), an additional smoothness assumption is required.14 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Assumption 8 (Smoothness of target function). Consider a Sobolev ball Wβ,∞([0,1]M×N),
J
characterized by smoothness parameter β ∈ N , is defined as follows,
+
(cid:40) (cid:41)
Wβ,∞([0,1]M×N)) = f : max ess sup |Dpf(x)| ≤ J ,
J
p:|p|≤β x∈[0,1]M×N
where p = (p ,...,p ), |p| = p +...+p , and Dpf denotes the weak derivative. We assume
1,1 M,N 1,1 M,N
that f∗ lies in the Soblev ball, i.e., f∗ ∈ Wβ,∞([0,1]M×N)).
J
The smoothness assumption implies that all derivatives of f∗ up to order β −1 must be Lipschitz
continuous. This assumption is frequently employed to establish the convergence rate of neural network-
type estimators (see e.g., Yarotsky, 2017; Farrell et al., 2021) and supports the effective approximation
of smooth functions by ReLU networks. The following theorem establishes the convergence rate of the
PIE.
Theorem 3 (Convergence rate of PIE). Under Assumptions 6 and 8, the finite sample con-
vergence rate of f(cid:98)in approximating f∗ is described by
∥f(cid:98)−f∗∥2
L2(P )
= O p(n− MN2β +2β).
X
Theorems 2 and 3 introduce pioneering theoretical findings regarding the statistical estimation prop-
erties of PIEs. Previous research has primarily focused on the representational capabilities of PIEs and
suffered from some limitations:
• Theorem 2 in (Zaheer et al., 2017): This theorem establishes that any continuous function
(cid:80)
g(X)ispermutationinvariantifandonlyifitcanbeexpressedasg(X) = ψ( ϕ(x)). However,
x∈X
this result was proven for X ∈ RN, and its applicability to X ∈ RM×N — crucial for processing
confounder-treatment vectors in neighboring regions — is less straightforward.
• Theorem 3.2 in (Gui et al., 2021): Extending the input domain from vectors to matrices, it
proves that any permutation invariant function g(X) for X ∈ RM×N can be approximated with
arbitrary precision by a function in the form g(X) = ψ((cid:80) ϕ(x)), with x ∈ RM. However, this
x∈X
theorem does not detail the precise rate of convergence.
To the best of our knowledge, our work is the first to derive the convergence rate of PIEs and extend its
application to value-based methods in OPE; see Sections 4.2 and 4.3.
It is noteworthy that standard neural network-type estimators, even without leveraging the permu-
tation invariant property, can achieve a convergence rate of O(n−2β/(MN+2β)) (see e.g., Farrell et al.,
2021). To explore further, we have rigorously derived the minimax rates for PI estimators in Theorem
4. Our findings reveal that no estimator, even with the incorporation of the permutation invariance
assumption, can exceed a convergence rate of O(n−2β/(MN+2β)) in a minimax sense. This suggests that
the cannot enhance the convergence rate beyond this established bound.
Assumption 9. Let p denote the probability density function of X. There exist two positive con-
X
stants P and P such that
X X
0 < P ≤ p (x) ≤ P < ∞,
X X X
for any x ∈ [0,1]M×N.
Building on this assumption, we establish the minimax optimality of the PIE for estimating permu-
tation invariant functions.
Theorem 4 (Minimax Optimality of PIE). Given the distribution of the confounding variable
X ∈ RM×N adhering to Assumption 9, the minimax risk for approximating any permutation invariant
target function that meets Assumptions 6 and 8 is subject to the following lower bound:
inf sup |f(cid:98)−f|2
L2(P )
≥ C(β,M,N)n− 2β+2β MN, (17)
f(cid:98)∈A nf∈Pβ,M×N X
where C(β,M,N) is a constant depending only on M,N and β, A represents the space of all measur-
n
able functions of the confounding variable in L (P ), and Pβ,M×N includes all functions that satisfy
2 X
Assumptions 6 and 8.
Finally, we remark that despite that employing the permutation invariance assumption cannot improve
theminimaxrateofconvergence, itdoessignificantlyreducethevarianceoftheestimator. Thisvariance
reduction has been substantiated in our numerical studies, as seen in Sections 5.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 15
4.2. Nondynamic Results
We establish convergence rate for the OPE estimator in a nondynamic setting in this subsection. Ac-
cordingly, the notation used here aligns with that in Section (2.2).
Recall that under Assumption 2, the conditional mean of the response of the ith region is denoted
by f (X ,A ,m (X ,A )). Let G represent the PIE function class defined in Theorem 1 which
i i i i N(i) N(i)
approximates the mean-outcome function f .
i
Forthenondynamicsetting, weimposesimilarboundednessandsmoothnessassumptionstoAssump-
tions 6 and 8.
Assumption 10. For any i = 1,··· ,R and any f˜∈ G, there exist a constant J that:
max{∥f ∥ ,|Y |,∥f˜∥ } ≤ J.
i ∞ i ∞
Furthermore, it is assumed that each f resides within the Sobolev space Wβ,∞([0,1](M+1)×(N+1)).
i J
We extend the results of Theorem 3 to derive the convergence rate for estimator in Theorem 1.
Corollary 1 (Convergence Rate of PIE). Under Assumption 2, Smoothness Assumption that
f
i
∈ W Jβ,∞([0,1](M+1)(N+1))) for any i = 1,··· ,R. We derive f(cid:98)i ∈ G in estimation scheme shown in
(16), the PIE exhibits consistency and the following finite sample convergence rate:
∥f(cid:98)i−f i∥2
L2(P )
= O p(S− (M+1)(2 Nβ +1)+2β). (18)
X
To facilitate the derivation of the convergence rate of the OPE estimator J(cid:98)VB(π), we employ a cross-
fitting scheme as outlined in (Chernozhukov et al., 2018) and (Athey and Wager, 2021), the detail
of cross-fitting scheme can be found in Appendix. With above preparation, the following corollary is
establishes the convergence rate of OPE estimator J(cid:98)VB(π).
Corollary 2. Under Assumption 10, the finite sample convergence rate of J(cid:98)VB(π) in approximating
the true value J(π) is described by
− β
|J(cid:98)VB(π)−J(π)| ≤ O(RS (M+1)(N+1)+2β)+e, (19)
where this holds for any e > 0 with a probability of at least 1−exp(−Se2).
8J2
4.3. Dynamic Results
To establish the statistical properties of J(cid:98)VB(π) in dynamic settings, we begin by defining the transition
γ
operator Pπ:
(Pπf(t) )(cid:0)
X ,A
(cid:1)
i N∗(i),t,j N∗(i),t,j
(cid:26) (cid:12) (cid:27)
=E f i(t+1)(cid:0) X N∗(i),t+1,j,π(X N∗(i),t+1,j)(cid:1)(cid:12) (cid:12) (cid:12)X N∗(i),t,j,A N∗(i),t,j , (20)
where M has been defined in (10). The Bellman operator Tπ can therefore be defined as
i
(Tπf(t) )(cid:0)
X ,A
(cid:1)
= r
(cid:0)
X ,A
(cid:1) +γ(Pπf(t) )(cid:0)
X ,A
(cid:1)
i N∗(i),t,j N∗(i),t,j i N∗(i),t,j N∗(i),t,j i N∗(i),t,j N∗(i),t,j
Based on the Bellman operator, we redefine the Smoothness Assumption.
Assumption 11. For any i = 1,··· ,R, it is assumed that:
• r ∈ Wβ,∞([0,1](M+1)×(N+1)).
i J
• For any f ∈ G, we have Tf ∈ Wβ,∞([0,1](M+1)×(N+1)).
i i J
Assumption 11 addresses the smoothness of the mean-outcome function and target function in train-
ing. Recall p denote the stationary probability measure under behavior policy, and p denote prob-
i π,t
ability measure under policy π at time step t. Distribution shift caused by policy distinction can be
controlled by the following assumption16 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Assumption 12 (Concentration). The concentration coefficient at time t is defined as
κ2 t = E p i(cid:12) (cid:12) (cid:12) (cid:12)d dp pπ,t(cid:12) (cid:12) (cid:12) (cid:12)2 , (21)
i
and it is assumed that for any 1 ≤ t ≤ T, there exists a constant κ such that κ ≤ κ.
t
The concentration assumption is standard in batch reinforcement learning (see e.g., Fan et al., 2020;
Chen and Jiang, 2019; Xie and Jiang, 2020, 2021). It essentially stipulates that the policy used in the
dataset should be sufficiently diverse to ensure adequate coverage of the (X ×A) probability space, a
condition easily met in our application as the data follows a random policy. Moreover, the the cross-
fitting scheme is employed in this subsection as well. With these assumptions in place, we can now
extend to the OPE estimator in dynamic setting.
Corollary 3. Under Assumptions 11 and 12, for any e > 0, the finite sample convergence rate of
J(cid:98) γVB(π) in approximating the true value J γ(π) is:
|J(cid:98) γVB(π)−J γ(π)| ≤ O(κTRS− (N+1)(Mβ +1)+2β)+e, (22)
with a probability of at least 1−exp(−Se2).
8J2
The bound in Corollary 3 differs from that in Corollary 2 due to the added complexity of temporal
interference in the dynamic setting, resulting in a linear dependence on T. However, the convergence
rate relative to the sample size S remains consistent with the non-dynamic setting. Importantly, J(cid:98)VB(π)
converges with high probability.
5. Numerical Study
In this section, we conduct comprehensive numerical experiments to demonstrate the superior empirical
performance of our proposed method compared to established alternatives. Section 5.1 focuses on a
comparison between our proposed method and the mean-field approach in a nondynamic setting. In
Section 5.2, we expand our analysis to dynamic settings. Finally, Section 5.3 shifts the focus to a
synthetic environment derived from a real-world ride-sharing platform dataset.
5.1. Nondynamic Simulation
In this subsection, we focus on the nondynamic setting introduced in Section 2. We begin by dividing
the entire space into R = l×l non-overlapping spatial units, where l is chosen from {5,10}. The data
are generated as follows:
(a) Confounder: Each confounder vector X is two-dimensional, represented by (U ,V ), generated
i i i
under the CAR model detailed in Section 2.1 of Reich et al. (2021);
(b) Treatment: {A } are independently sampled from a Bernoulli distribution with a success proba-
i i
bility of 0.5.
(c) Response: {Y } are generated according to the following additive model:
i 1≤i≤R
Y = 0.1×(A β +A⊤ β )+g(X ,A )γ +γ⊤ g(X ,A )+ϵ , (23)
i i 1 N(i) 2,1:|N(i)| i i 1 2,1:|N(i)| N(i) N(i) i
with the following components:
• Linear component coefficients:
– β ∈ R: Regression coefficient for the treatment variable A .
1 i
– β : Subvector of β ∈ RR, comprising the first |N(i)| elements, corresponding to
2,1:|N(i)| 2
the regression coefficients for the treatments of the ith unit’s neighboring regions.
• Nonlinear function and coefficients:
– g: A potentially nonlinear scalar function applied to confounder-treatment pairs
– g(X ,A ) applies the scalar function g element-wise to each pair in {(X ,A ) : j ∈
N(i) N(i) j j
N(i)}, producing an |N(i)|-dimensional vector.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 17
– γ ∈ R: Regression coefficients associated with the function g applied to (X ,A ).
1 i i
– γ : Subvector of γ ∈ RR, consisting of the first |N(i)| elements, corresponding to
2,1:|N(i)| 2
the regression coefficients for the treatments of the ith unit’s neighboring regions.
• Residuals: {ϵ } : Independent standard normal random variables.
i 1≤i≤R
Notice that under Model (23), the interference effect is captured by the terms 0.1A β +
N(i) 2,1:|N(i)|
γ⊤ g (X ,A ). We evaluate the performance of our method under three distinct scenarios by
2,1:|N(i)| i N(i) N(i)
varying the link function g and the regression coefficients:
(a) Linear Setting: This setting is relatively straightforward, as both the treatment and interference
effectsarelinear. Themean-fieldmethodisexpectedtobeeffectiveinthislinearmodel. Specifically,
we set g(X ,A ) = U +V , which is independent of the treatment. The parameters are chosen as
i i i i
γ = β = 1.5 and γ = β = (−0.5,−0.5,−0.5,−0.5,...).
1 1 2 2
(b) Nonlinear Setting I: This scenario incorporates an interaction term between the confounder and
the treatment, violating the linear structure and challenging the mean-field method. However, our
proposed method can accurately model this interaction, adhering to the permutation invariance
assumption. Specifically, we set g(X ,A ) to A ×U . The parameters are given as γ = β = 1.5
i i i i 1 1
and γ = β = (−0.5,−0.5,−0.5,−0.5,...).
2 2
(c) Nonlinear Setting II: This is a more complex scenario where β and γ are not constant vectors,
2 2
deviating from both permutation invariance and linearity assumptions. This setting tests the
robustness of the mean-field method and our proposed method under model mis-specification.
Specifically, we set g(X ,A ) = A ×U . The parameters are given as γ = β = 1.5, and γ = β =
i i i i 1 1 2 2
(−0.2,−0.8,−0.2,−0.8,...).
Additionally, we consider a deterministic linear target policy π such that for any X , π(X ) = 1 if and
i i
onlyifU κ+V (1−κ) > 0.5forsomeκ ∈ [0,1]. Wevaryκ ∈ {0.2,0.5,0.8}toinvestigatetheperformance
i i
with different target policies. We also fix the number of days S to 100.
Figure 4 presents the results ofour proposed value-based estimator (denoted as PIE) andthe baseline
value-basedestimatorusingmean-fieldapproximation(denotedasMean-field). Inthelinearsetting,both
methodsshowcomparableperformance,withourmethodachievingamarginalimprovementinaccuracy.
However, the mean-field method struggles in the nonlinear settings, failing to produce consistent causal
estimators due to the violation of the linearity assumption. In contrast, our estimator exhibits signifi-
cantly lower mean squared errors (MSEs), maintaining robust performance even when the permutation
invariance assumption is not fully met.
5.2. Dynamic Simulation
In this subsection, we design a synthetic environment to simulate the dynamics of order dispatching
within a ridesharing platform. We analyze a map grid of size l×l, with l taking values from the set {5,
10, 15} to represent different scales of the operational environment. This results in R = l2 spatial units.
The data generation process is outlined as follows:
(a) Confounder: For each spatial unit i, at time t, on day j, we construct a five-dimensional obser-
vation X , comprising:
i,t,j
(i) Order counts (O ): Generated by first drawing a mean µ from a uniform distribution
i,t,j i
ranging between 40 and 180. Then sampling from a normal distribution with mean µ and
i
standard deviation 1. The order counts, indicative of the intrinsic demand within each region,
are not altered by treatments. The actual order counts post-treatment are calculated using
the formula O∗ = O +0.3A O .
i,t,j i,t,j i,t,j i,t,j
(ii) Connectivity factor (C ): The connectivity factor, reflecting a grid’s road condition, is
i
generated following a uniform distribution ranging from 0.1 to 1. A higher connectivity factor
facilitates more rapid redistribution of drivers.
(iii) Number of neighboring grids (N(i)).
(iv) Driver counts (D ): Initially set 130 drivers per grid. Redistribution of these drivers
i,t,j
to neighboring grids is determined by the actual orders counts, past drivers counts, and the
connectivity factor of both the central grid and its neighboring grids. Specifically, this redis-
tribution process adheres to the methodology outlined in Algorithm 1.18 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Fig. 4: Nondynamic simulation results: Mean Squared Errors (MSEs) of various policy value estimators
areaggregatedover50simulationreplications. Thetoppanelsdisplayresultsforl = 5, whilethebottom
panels are for l = 10. The left panels correspond to the linear setting, the middle panels to nonlinear
setting I, and the right panels to nonlinear setting II.
(v) Mismatch rate (M ): Calculated as 0.9[1 − |D − O∗ |/(1 + D + O∗ )] +
i,t,j i,t,j i,t−1,j i,t,j i,t−1,j
0.1M , reflecting higher values when driver and order counts are closely aligned.
i,t−1,j
(b) Treatment (A ): Represents whether a discount is offered for orders in the i-th grid at time t
i,t,j
on day j, independently sampled from a Bernoulli distribution with a success probability of 0.5.
(c) Response (Y ): Computed as M2 min(D ,O∗ )−2|D −O∗ |.
i,t,j i,t+1,j i,t+1,j i,t,j i,t+1,j i,t,j
Algorithm 1: Driver transition process
∀ i,t,j V ← 0;
i,t,j
for i ≤ N do
∆ = |D −O∗ |; /* Calculate the surpass of drivers */
i,t,j i,t−1,j i,t−1,j
for k ∈ N(i) do
C = min{C ,C }; /* Calculate bi-connectivity */
i−k i k
V = V −C (∆ −∆ ) ; /* Update transition vectors */
i,t,j i,t,j i−k i,t,j k,t,j
V = V +C (∆ −∆ ) ;
k,t,j i,t,j i−k i,t,j k,t,j
end
end
D = D +V /N(i) ; /* Update the driver numbers */
i,t,j i,t−1,j i,t,j
Data span S = 200 days, each with T = 40 time points. We evaluate top-Q policies that subsidize
the Q spatial units with highest average number of orders. These units receive treatment 1, while others
receive treatment 0. The discount factor γ is set to 0.9. We employ Monte Carlo simulations to estimate
theoraclepolicyvalues,andimplementtheproposedvalue-based(VB)anddoublyrobust(DR)methods
detailedinSections3.2.1and3.2.3,comparingthemagainstmean-fieldversions. TheirMSEs,forvarious
l and Q combinations, are shown in Figure 5. It can be seen that our VB and DR estimators yield much
smaller MSEs than their mean-field counterparts, highlighting the effectiveness of the proposed neural
network architecture in capturing complex interference structures.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 19
Fig. 5: Dynamic simulation results: MSEs of VB and DR estimators corresponding to different combi-
nations of l and Q.
5.3. Real Data-based Simulation
In this subsection, we leverage a historical dataset from a globally renowned ridesharing company to
develop a simulator, aimed at evaluating our proposed method. This dataset encompasses a five-day
period in a particular city, capturing drivers’ trajectories, order requests, idle drivers’ movements, and
theirstatusofbeingonlineoroffline. WefollowTangetal.(2019a)tosimulatekeydynamicsofreal-world
ridesharing markets. The process involves:
(a) Spatial Division: The city is divided into R = 85 hexagonal regions, providing a detailed spatial
framework for the simulation.
(b) Time Partitioning: Each day, spanning from 4 am to 12 pm, is segmented into numerous slices,
with each slice lasting 2 seconds.
At each simulation’s start, drivers are distributed across the city based on their empirical distribution
from the offline dataset. The simulator, during each time slice, updates the states of drivers and orders
through the following steps:
(a) Drivers assigned to orders decide whether to accept these based on probabilities calculated by a
pre-trained LightGBM model, taking into account driver and order characteristics.
(b) Idle drivers, not assigned to orders, are directed to specific locations according to the historical idle
movement data.
(c) Drivers subjected to repositioning follow the platform’s instructions, determined by a pre-trained
repositioning algorithm.
(d) Drivers engaged with accepted orders move to pick-up locations, collect passengers, and head to
the destinations.
(e) Thedriverpoolisdynamicallyupdated, reflectingnewdriversenteringthecityandexistingdrivers
going offline.
The order update process in the simulator comprises two main components:
(I) Generation of new orders based on historical data, influenced by the passenger-side subsidy policy
under evaluation. This policy offers discounts to passengers placing orders within certain spatial
units at specific times, thereby increasing order volume in those areas.
(II) Processing and dispatching of both existing unassigned and new orders, following a dispatch algo-
rithm detailed in (Tang et al., 2019a).
For evaluation, we set the immediate outcome as the gross merchandise value (GMV), sample treat-
ments from a Bernoulli distribution (with success probability p = 0.5), and run the simulator S times to
generate an offline dataset where S varies among {4, 7, 14}. T is fixed to 120. We use the total numbers
of orders and drivers in each region at each time as the time-varying confounding vector.
Analyzing this dataset poses multiple challenges:
(I) Theunderlyingdynamicsdemonstratesignificantvariabilitythroughoutthedayandacrossdistinct
spatial units, thus exhibiting both temporal nonstationarity and spatial heterogeneity;20 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
(II) The Markov test developed by (Shi et al., 2020) reveals that the data does not conform to the
Markov property.
To address the first challenge, we include the location of each region and the timestamp in the set of
confounding variables. Previous studies, such as (Xu et al., 2018), have shown that a region’s proximity
to the city center and whether the timestamp corresponds to rush hour are crucial factors in estimating
the value function. To account for spatial heterogeneity, we employ one-hot encoding based on the
region’s index to encapsulate spatial information. Regarding temporal nonstationarity, we consider two
encoding schemes: one utilizing one-hot encoding based on the current hour (denoted by “hour”), and
the other dividing a day into five periods separated by the morning peak (7-9am) and afternoon peak
(5-7pm) times (denoted by “rush”). To overcome the second challenge related to the non-Markov nature
of the data, we reconstruct the time-varying confounder by concatenating the past L measurements to
satisfy the Markov assumption. We consider two choices for L, corresponding to lengths of 4 and 8.
Similar to Section 5.2, we set the target policy to the top-Q policy that assigns treatments based on
the order demand and driver availability. In our experiment, the degree of mismatch is quantified by
the difference in the number of orders and drivers in each region. We then apply the subsidying policies
to the top Q regions exhibiting the highest degree of mismatch. The parameter Q determines the size
of the treated regions, and we consider various values: Q = 10,15,20,25, and 30. The discounted factor
is fixed to 0.98. The MSEs of the proposed value-based, doubly robust estimators and their mean-field
counterparts are reported in Figure 6, with different combinations of encoding schemes, Markov orders
L, days of experiment S, and the number of treated regions Q .
We draw several conclusions:
(i) The performance of the mean-field method is highly dependent on different encoding schemes and
the number of trajectories, exhibiting substantial variation. In certain circumstances, it performs
extremely poorly. For instance, when (S,L,Q) = (7,8,15) under one-hot encoding, MSEs larger
than 1000 are observed;
(ii) The proposed methods consistently perform well across the majority of scenarios. They especially
excel in conditions where the mean-field method struggles to achieve effective results;
(iii) When the mean-field function is mis-specified, both the density ratio and the value function are
impacted. Thiscouldpartiallyexplainwhythemean-fieldDRmethodunderperformsincomparison
to the mean-field VB method in certain situations; see e.g., the subplots in row 1 column 3 and
row 2 column 4;
(iv) Our proposed method shows strong performance when used in conjunction with either DR or VM,
showcasing the precision of the proposed interference effect function estimator.
6. Discussion
We have introduced a novel causal deepsets model that effectively addresses the challenge of spatial
interference. The versatility of our framework opens up a plethora of applications in diverse fields. In
urban planning, it could be pivotal in modeling the impact of policy interventions on traffic flow and
public transportation. Environmental studies could leverage this model to assess the effects of policy
changes on pollution patterns across different regions. In public health, our methodology could be
instrumental in analyzing the spread of diseases and the efficacy of intervention strategies over varying
spatial scales.
Meanwhile,ourtheoreticalanalysis,whichestablishestheconsistency,convergencerate,andminimax
optimality of the PIE estimator, is a cornerstone of our research, not only validate the robustness of
our methodology but also provide a solid foundation for future advancements in the field. They also
encourage the exploration of PIE in other contexts where permutation invariance is a key characteristic,
potentiallybroadeningthescopeofitsapplicability. Severalimportantavenuesforextensionandfurther
research emerge from our study:
(i) Spatial-Temporal Interference and Invariance Property: Our paper represents an early yet sig-
nificant effort in addressing spatial-temporal interference. The methodologies we have developed for
handling either spatial or temporal interference offer avenues for extension and refinement.
In terms of temporal dynamics, while our model employs MDPs, it is possible that they do not
completely capture the intricacies of interference structures. Therefore, more complex models, such asCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 21
Fig. 6: MSE Comparison in Real Data-Based Simulations. This figure presents the performance of
proposed estimators and their mean-field counterparts in the simulated ridesharing environment. Each
row’s subplot corresponds to a different number of trajectories, denoted as S . Columns distinguish be-
0
tween various encoding schemes and Markov orders. The terms ’days’, ’lag’, ’hour’, and ’rush’ indicate
the number of trajectories S , the Markov order L, and the temporal encoding schemes, respectively.
0
All spatial encoding is performed using the ’one-hot’ scheme. In the legend, ’Mean-field VB’ refers to
the Value-based method combined with the mean-field method, and ’PIE VB’ denotes the Value-based
method implemented with the PIE method. ’DR’ stands for the Doubly Robust method. Each experi-
ment was replicated 21 times, and the confidence bands represent the variance among these replications.
higher-order MDPs or Partially Observable Markov Decision Processes (POMDPs), might be necessary
for a more comprehensive understanding. Additionally, the latest advancements in transformer-based
models, celebrated for their proficiency in managing temporal correlations (Vaswani et al., 2017; Zhou
et al., 2021b; Li et al., 2023b), point towards exciting possibilities for future investigations in this area.
In the spatial dimension, our current model primarily considers interference effects among geograph-
ically proximate neighbors. This can be expanded by utilizing more complex metrics than Euclidean
distance, such as transport costs and actual road conditions, to better reflect real-world scenarios (Zhou
et al., 2021a). Moreover, incorporating semantic aspects like functional similarity into the concept of
proximity could enhance our understanding of spatial dynamics (Geng et al., 2019; Wang et al., 2019).
Finally, transformer-based invariant neural networks, known for their effectiveness in various domains
(Lee et al., 2019; Zhao et al., 2021), have yet to be explored in spatial modeling contexts.
Finally, our method is predicated on the assumption of permutation invariance among neighboring
regions within a network interference context, which leads to an essential empirical question regarding
the validity of this assumption. One solution could involve developing a non-parametric test based on
collected data. Alternatively, strategies like adaptively learning invariance properties from the data
(Benton et al., 2020), as well as balancing representational capacity and model invariance through
regularization (Cohen-Karlik et al., 2020), could be explored. An empirical and theoretical examination
of the aforementioned extensions would provide invaluable insights, enhancing our understanding and
application of spatial-temporal interference models.
(ii) Unmeasured Confounding: Ourframeworkoperatesundertheassumptionof‘unconfoundedness’,
which presumes the absence of unmeasured confounders that could simultaneously influence both the
treatment and the response (or future confounders in a dynamic setting). This is a standard assumption
in scenarios where data is generated through automated, data-adaptive policies. However, its applicabil-22 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
ity is less certain in contexts involving human decision-making. For instance, in ridesharing platforms,
human interventions during unexpected events like severe weather or large public gatherings can sig-
nificantly alter passenger behavior, leading to an inherently confounded dataset due to the omission of
these contextual factors (Shi et al., 2022c).
Addressing unmeasured confounding in spatial causal inference and OPE algorithms has garnered
significant interest recently (Jarner et al., 2002; Thaden and Kneib, 2018; Papadogeorgou et al., 2019;
Kallus and Zhou, 2020; Keller and Szpiro, 2020; Tennenholtz et al., 2020; Giffin et al., 2021; Fu et al.,
2022; Shi et al., 2022a; Bennett and Kallus, 2023; Bruns-Smith and Zhou, 2023; Xu et al., 2023). How-
ever, a critical gap remains in these approaches: they often focus solely on either spatial or temporal
dependencies, without considering scenarios where both types of confounders coexist. Bridging this
gap would significantly enhance the robustness and applicability of spatial-temporal causal inference
methods, particularly in complex real-world settings that involve decision making over time and space.
(iii) Design of Spatial and/or Temporal Experiments: Our research contributes to the burgeoning
field of policy evaluation given a pre-collected dataset. A compelling area for future exploration is the
design of spatial and/or temporal experiments to generate such data, in order to optimize the estimation
accuracy of the resulting treatment effect estimator. While there is a growing body of literature on
optimal experimental designs (see e.g., Ugander et al., 2013; Li et al., 2019; Kong et al., 2021; Wager and
Xu,2021;HuandWager,2022;Leung,2022;Bojinovetal.,2023;Lietal.,2023a;Xiongetal.,2023),these
studies typically focus on experiments that either primarily feature spatial or temporal dependencies.
Rarely do they explore designs that simultaneously account for both dependencies. Future research in
this domain could potentially revolutionize our approach to understanding and predicting the impact of
complex, dynamic interventions in a wide range of real-world scenarios.
Acknowledgments
This research received partial support from the National Science Foundation of China (Grant Numbers:
#1636933 and #1920920) and a grant from the Engineering and Physical Sciences Research Council in
the United Kingdom (Grant Number: EP/W014971/1).CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 23
Appendix
A. Definition and Notations
ConsiderarandomvariablegovernedbyaprobabilitymeasureQthatiscompactlysupportedonRd. The
space L (Q) represents the set of real-valued functions on Rd, equipped with an inner product defined
2
as ⟨f,g⟩ =
(cid:82)
f(x)g(x)dQ(x) and a corresponding norm ∥f∥ =
(cid:0)(cid:82) f(x)2dQ(x)(cid:1)1/2
. When
L (Q) L (Q)
2 2
consideringtheLebesguemeasureλ,thespaceL denotesthesetofreal-valuedfunctionsonRd,withthe
2
norm∥f∥ =
(cid:0)(cid:82) f(x)2dx(cid:1)1/2
. Thenotation∥·∥ representstheempiricalnorm, definedforafunctionf
L n
2
as ∥f∥2 = 1 (cid:80)n f(x )2. The empirical norm of a random variable X is defined analogously as ∥X∥ =
n n i=1 i n
(cid:0)1 (cid:80)n x2(cid:1)1/2 . Finally, the infinity norm for a real-valued vector Y = [Y ,...,Y ]T ∈ Rd is defined as
n i=1 i 1 d
∥Y∥ = max |Y |. The infinity norm for a real-valued function f is given by ∥f∥ = max |f(X)|
∞ k k ∞ X∈Rd
and the infinity norm for a vector function f(X) = [f (X),...,f (X)] is max ∥f (X)∥ .
1 K k k ∞
To lay the groundwork, we expand upon the definition of the permutation operator (Definition 1).
Specifically, consider a matrix X = [X ,X ,...,X ] ∈ RM×N. Under the permutation operator Π, we
1 2 N
define its permutation as another M ×N matrix Π = [X ,X ,...,X ].
X Π(1) Π(2) Π(N)
B. Proof of Theorem 2
To establish the consistency of fˆ, it suffices to show that ∥fˆ−f∗∥2 = o (1). First, let’s formalize the
L p
2
definition of the PIE function class. The PIE, as defined in (4.1), comprises two components: ψ and
φ. Denote L as the number of hidden layers between the input and output of φ. The total number of
ψ
non-zero parameters in ψ is capped by S . Similarly, define L and S as the number of hidden layers
ψ φ φ
and the upper bound for the number of non-zero parameters in φ, respectively. Additionally, we assume
that the magnitude of all parameters in both ψ and φ is bounded by B, and all the PIE functions under
consideration are bounded such that |f| ≤ J. Therefore, we can represent the PIE function class using
F = F(S ,S ,L ,L ,B).
ψ φ ψ φ
To proceed with our proof, let us first introduce the concept of the ’uniform best predictor’, denoted
by f . This predictor is determined by the following criterion
n
f = argmin∥f −f∗∥ , ϵ = ∥f −f∗∥ .
n ∞ n ∞
f∈F
Subsequently, we apply a standard error decomposition, akin to that described in (Farrell et al., 2021)
c ∥fˆ−f∗∥2 ≤ E[l(fˆ)]−E[l(f∗)]
1 L
2
≤ E[l(fˆ)]−E[l(f∗)]+E [l(f ,Z)−l(fˆ,Z)]
n n
= E[l(fˆ)]−E[l(f∗)]+E [l(f ,Z)−l(fˆ,Z)]+E [l(f∗,Z)−l(f∗,Z)]
n n n
= (E−E )[l(fˆ)−l(f∗)]+E [l(f )−l(f∗)].
n n n
In this formulation, the second inequality stems from the definition of f . These inequalities effectively
n
disaggregate the error into two principal components: the empirical process term (the first term) and
the approximation error (the second term). We intend to establish bounds for both components.
Toboundtheapproximationerror,weutilizetheprincipleofLipschitzcontinuityonthelossfunction.
Considering that the mean squared error (MSE) loss l(f) exhibits Lipschitz continuity for a bounded
f, and in light of Assumption 6 which confines both f∗ and functions within F to a maximum of J, it
follows that
∀f ∈ F, ∥l(f)−l(f∗)∥ ≤ C ∥f −f∗∥ ,
∞ l ∞
where C denotes the Lipschitz constant. Given that f belongs to F, we can infer
l n
E [l(f )−l(f∗)] ≤ E [C |f −f∗|] ≤ C ϵ. (24)
n n n l n l
To bound the estimation error, we need the following lemmas24 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Lemma 1 (Symmetrization, Lemma 5 in (Farrell et al., 2021)). Given function class G, for
any g ∈ G that |g| ≤ G and V[g] ≤ V, then with probability at least 1−2e−γ
(cid:114)
2Vγ 23Gγ
sup{Eg−E g} ≤ 6E R G + + ,
n η n
n 3n
g∈G
where R nG = E ξ(cid:2) sup g∈G(cid:12) (cid:12) n1 (cid:80)n i=1ξ ig(x i)(cid:12) (cid:12)(cid:3) denote the empirical Rademacher complexity of function class
G.
Lemma 2 (Chaining Theorem 2.3.7 in (Gine´ and Nickl, 2021)). Let (S,d) be a metric space,
(cid:82)∞(cid:112)
wheredisapseudo-distance. LetX(t)beasub-Gaussianprocessrelativetod. Assumethat logN(ϵ,S,d)dϵ <
0
∞, then
√ (cid:90) δ/2
(cid:112)
Esup∥X(t)∥ ≤ E∥X(t )∥+4 2 log2N(ϵ,S,d)dϵ,
0
t∈T 0
where t ∈ T, δ is the diameter of (S,d).
0
By setting X(t) = √1
n
(cid:80)n i=1ξ if(x i) and X(t 0) = 0, the empirical Rademacher complexity R nF can
√
be upper bounded by 4 √2 (cid:82)δ/2(cid:112) logN(ϵ,F,∥·∥ ), where δ/2 is the diameter of function class F with
n 0 k
k-norm.
From the Lipschitz continuity of the MSE loss l, it follows that
∀f ∈ F, ∥l(f)−l(f∗)∥ ≤ C ∥f −f∗∥ ≤ 2JC .
∞ l ∞ l
Then we have
V[l(f)−l(f∗)] ≤ E(cid:2) (l(f)−l(f∗))2(cid:3) ≤ 4J2C2.
l
We apply Symmetrization in Lemma 1 with G = {g = l(f) − l(f∗) : f ∈ F}, G = 2JC and
l
V = 4J2C2, so with probability at least 1−2e−γ
l
(cid:114)
(cid:104) (cid:105) 8J2C2γ 46JC γ
(E−E ) l(fˆ)−l(f∗) ≤ 6E R G + l + l . (25)
n η n
n 3n
Due to Lemma 2, we have
(cid:34) (cid:12) (cid:12)(cid:35)
n
(cid:12)1 (cid:88) (cid:12)
E R G = E sup(cid:12) η f(X(i))(cid:12)
η n η (cid:12)n i (cid:12)
f∈G(cid:12) (cid:12)
i=1
√
4 2 (cid:90) JC l(cid:112)
≤ √ log(2N(ϵ,G,∥·∥ ))dϵ,
∞
n
0
where the diameter of G comes from
∀g,g′ ∈ G, ∥g−g′∥ = ∥l(f)−l(f′);f,f′ ∈ F∥ ≤ 2JC .
∞ ∞ l
Putting (24) and (25) together, by setting γ = logn, we get
c ∥fˆ−f∗∥2
1 L
2
(cid:114)
≤ c ϵ+
√1 (cid:90) JC l(cid:112)
log(N(η,F,∥·∥ ))dη+
8J2C l2logn
+
67JC llogn
.
2 ∞
n n 3n
0
Following Theorem 3.2 of (Gui et al., 2021), there exists such PIE function class F . By setting
0
F = F , ϵ = min ∥f −f∗∥ can be arbitrarily small. So that ∥fˆ−f∗∥2 → 0, with probability
0 f∈F 0 ∞ L 2 n
1− 2 converging to one.
nCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 25
C. Proof of Theorem 3
C.1. Error decomposition
In this section, we explore the convergence rate of PIE networks, employing an error decomposition
approach akin to the one described in (Imaizumi and Fukumizu, 2019). Given that fˆis the Empirical
Risk Minimization (ERM) predictor, it holds for all f ∈ F that
∥Y −fˆ∥2 ≤ ∥Y −f∥2.
n n
This is followed by the representation Y = f∗(X)+ξ, leading to
∥f∗+ξ−fˆ∥2 ≤ ∥f∗+ξ−f∥2.
n n
A straightforward calculation results in
n
2 (cid:88)
∥f∗−fˆ∥2 ≤ ∥f∗−f∥2 + ξ (fˆ(x )−f(x )) (26)
n n n i i i
i=1
n
2 (cid:88)
≤ ∥f∗−f∥2 + ξ (fˆ(x )−f(x )).
∞ n i i i
i=1
In the above expression, the first term represents the approximation error, which quantifies the capacity
of F to uniformly approximate f∗. The second term is the estimation error, gauging the variance of fˆ.
C.2. Approximation Error
We first define uniform best predictor
f = argmin∥f −f∗∥ .
n ∞
f∈F
In this section, we follow a two-step approach to upper bound ∥f∗ − f ∥2 . We first construct a
n ∞
speciallymodifiedTaylorexpansionofthetargetfunctionf∗, hereinafterreferredtoasf . Subsequently,
1
this modified expansion is uniformly approximated using functions from F.
We first perform a Taylor expansion in line with Theorem 1 from (Yarotsky, 2017), we revisit the
construction details. Let N′ be a positive integer and d = M × N. We partition unity by a grid of
(N′+1)d functions ϕ on the domain [0,1]d, satisfying
m
Σ ϕ (x) ≡ 1, x ∈ [0,1]M×N.
m m
In this context, m represents a matrix given by m = (m ) ∈ {0,1,...,N′}M×N, and the function ϕ is
ij m
defined as
M N
ϕ (x) = (cid:89)(cid:89) ω(3N′(x − m i,j )),
m i,j N′
i=1j=1
where

1, |x| < 1,


ω(x) = 0, 2 < |x|,

2−|x|, 1 ≤ |x| ≤ 2.
For any m ∈ {0,...,N′}d, we consider the Taylor polynomial of degree −(β −1) for the function f∗,
centered at the point x = m. This polynomial is expressed as
N′
P m(x) = (cid:88) D pp !f∗(cid:12) (cid:12) (cid:12)
(cid:12)
(x− Nm ′)p,
p:|p|≤β x= Nm ′
where |p| = (cid:80)M (cid:80)N p , p! = (cid:81)M (cid:81)N p ! and Dp is the respective weak derivative. (x− m)p =
i=1 j=1 i,j i=1 j=1 i,j N′
(cid:81)M i=1(cid:81)N j=1(x
i,j
− m Ni, ′j)p i,j.
We now establish an approximation of f∗, defined as
(cid:88)
f∗(X) = ϕ P (X).
1 m m
m∈[0,...,N′]d26 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Referring to insights from (Yarotsky, 2017), the approximation error can be upper bounded as
2ddβJ (cid:18) 1 (cid:19)β
∥f∗−f∗∥ ≤ .
1 ∞ β! N′
Then we construct a permutation invariant variant approximation of f∗, denoted as f , based on f∗
1 1
1 (cid:88)
f (X) = f∗(Π ).
1 |S | 1 X
N
Π∈S
N
Considering that f∗ is inherently permutation invariant, we proceed to assess the approximation error
associated with f
1
|f∗(X)−f 1(X)| = |S1 |(cid:12) (cid:12) (cid:88) (cid:0) f 1∗(Π X)−f∗(Π X)(cid:1)(cid:12) (cid:12)
N
Π∈S
N
≤ |S1
|
(cid:88) (cid:12) (cid:12)f 1∗(Π X)−f∗(Π X)(cid:12) (cid:12)
N
Π∈S
N
2ddβJ (cid:18) 1 (cid:19)β
≤ , (27)
β! N′
which leads to
2ddβJ (cid:18) 1 (cid:19)β
∥f∗−f ∥ ≤ .
1 ∞ β! N′
Then,weconstructthePIEtoapproximatef . Letωk = ω(3N′(X − k ))andconstructY(X,N′) ∈
1 i,j i,j N′
RK×N given X and N′ as follows
Y(X,N′) = (ω0 ,...ωN′,x ,...,ω0 ,...ωN′ ,X ), (28)
·,i 1,i 1,i 1,i M,i M,i M,i
where K = (N′+1)×M. Note Y(X,N′) contains all the terms in f (X) that involve X . For ease of
·,i 1 i
notation, Y and Y will be used to denote Y(X,N′) and Y(X,N′) , respectively.
i ·,i
It is noteworthy that Y represents a piece-wise linear transformation of X, which can be precisely
modeled using a ReLU network, as delineated in Proposition 1 of (Yarotsky, 2017). Consequently, the
conversionfromX toY doesnotincuranyapproximationerror. Furthermore,Y isafunctioncontingent
on both X and N′. By selecting an appropriate N′ to minimize the approximation error, the function
class and, consequently, Y become fixed entities. Hence, Y(X,N′) also does not add to the estimation
error. Therefore, in our subsequent analysis, we will focus solely on Y, having transformed X into this
new representation.
f 1∗(X) = (cid:88)(cid:89)M (cid:89)N ω(3N′(X i,j − m Ni, ′j )) (cid:88) D pp !f(cid:12) (cid:12) (cid:12)
(cid:12)
(X − Nm ′)p
m i=1j=1 p:|p|≤β X= Nm ′
=
(cid:88)(cid:89)M (cid:89)N
ωm i,j (cid:88)
Dpf(cid:12)
(cid:12) (cid:12) (X − m )p
i,j p! (cid:12) N′
m i=1j=1 p:|p|≤β X= Nm ′
= (cid:88)(cid:89)M (cid:89)N ω im ,ji,j (cid:88) D pp !f(cid:12) (cid:12) (cid:12)
(cid:12)
(cid:89)M (cid:89)N (X s,t− m Ns ′,t )p s,t
m i=1j=1 p:|p|≤β X= Nm ′ s=1t=1
= g∗(Y(X,N′)), (29)
so that we have
1 (cid:88) 1 (cid:88)
f (X) = f∗(Π ) = g∗(Y(Π ,N′)).
1 |S | 1 X |S | X
N N
Π∈S Π∈S
N N
Consider the function g(Y), defined as
1 (cid:88)
g(Y) = g∗(Y(Π ,N′)),
X
|S |
N
Π∈S
NCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 27
which ensures that g(Y) possesses permutation invariance. As indicated by (29), g(Y) can be expressed
as a polynomial in terms of Y, characterized by a degree of MN +β. To further dissect the structure of
g(Y), additional lemmas will be introduced and utilized in the analysis.
Lemma 3 (Weyl’s Polarization (Gui et al., 2021)). For any polynomial permutation invari-
ant function f : RK×N (cid:55)→ R, there exist a series of 1×K vectors {a }T and a series of permutation
t t=1
invariant functions f : R1×N (cid:55)→ R, such that f can be represented by
t
T
(cid:88)
f(X) = f (a⊤X).
t t
t=1
Lemma 4 (Hilbert finiteness Theorem (Gui et al., 2021)). There exists finitely many per-
mutation invariant polynomial basis f ,...,f : RN → R such that any permutation invariant poly-
1 N
nomial f : RN → R can be expressed as
f(X) = f˜(f (X),...,f (X)),
1 N
with some polynomial f˜of N variables. Especially, the following power sum basis is one possible permu-
tation invariant polynomial basis
N
(cid:88)
f (X) = Xj, j = 1,...,N,
j n
n=1
where X is the n−th entry of X.
n
Given that g(Y) is a permutation invariant polynomial function, we can apply Lemma 3
T T
(cid:88) (cid:88)
g(Y) = s (a⊤Y) = s (a⊤Y ,...,a⊤Y ),
t t t t 1 t N
t=1 t=1
where s : RN (cid:55)→ R is a permutation invariant polynomial and a = [a ,...,a ] ∈ RK. We postulate
t t t,1 t,K
that T = O(N′MN), assuming the components of a are uniformly bounded by a constant a, with
t
|a | < a. While Lemma 3 is broad and doesn’t impose an upper limit on T, our specific application
i,j
of g as a polynomial with unique structure allows us to estimate the order of T using linear equations,
making our claim about T’s order plausible. Subsequently, Lemma 4 is employed to express s (a⊤Y) in
t t
terms of h (g (Y)). Here, g (Y) = [(cid:80)N (a⊤Y )1,...,(cid:80)N (a⊤Y )N] forms the power sum basis, and
t t t n=1 t n n=1 t n
h : RN → R is a polynomial
t
MN+β
(cid:88) (cid:88) (cid:89)
h (X) = c X , X ∈ RN.
t t,s j
i=0 s∈{1,..,N}i j∈s
Recall that g(Y) is a polynomial of degree MN + β, where each term in g (Y) is of at least first
t
order. Consequently, we assert that h is a polynomial whose degree does not exceed MN + β, and
t
the coefficients, denoted by c , are constrained by a bound C. Integrating these elements yields the
t,s
following expression for g(Y)
T T N N
(cid:88) (cid:88) (cid:88) (cid:88)
g(Y) = h (g (Y)) = h ( (a⊤Y ),..., (a⊤Y )N).
t t t t n t n
t=1 t=1 n=1 n=1
To approximate f above, we construct a PIE f˜∈ F(S ,S ,L ,L ,B) and is characterized by the
1 ψ φ ψ φ
following structure
f˜(X) = ψ(φ(Y)) = g˜(Y),
T T N N
(cid:88) (cid:88) (cid:88) (cid:88)
g˜(Y) = ψ (φ (Y)) = ψ ( φ (Y ),..., φ (Y )),
t t t t,1,n n t,N,n n
t=1 t=1 n=1 n=1
where ψ : RN (cid:55)→ R and φ : RK (cid:55)→ R are fully connected ReLU neural networks. The detailed
t t,1,n
structure and attributes of these networks will be provided later.28 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
In light of the definition of f , the following inequality holds
n
∥f −f ∥ ≤ ∥f −f˜∥ ≤ |g(Y)−g˜(Y)|, ∀Y.
1 n ∞ 1 ∞
To establish a bound for ∥f −f ∥ , it suffices to bound the term |g(Y)−g˜(Y)|. We approach this
1 n ∞
through the following decomposition
T T T T
(cid:88) (cid:88) (cid:88) (cid:88)
|g(Y)−g˜(Y)| ≤ | h (φ (Y))− h (g (Y))|+| ψ (φ (Y))− h (φ (Y))|
t t t t t t t t
t=1 t=1 t=1 t=1
T
(cid:88)(cid:104) (cid:105)
≤ |h (φ (Y))−h (g (Y))|+|ψ (φ (Y))−h (φ (Y))| . (30)
t t t t t t t t
t=1
Lemma 5 (ReLU Approximation (Yarotsky, 2017)). Given M′ > 0 and ϵ ∈ (0,1), there’s a
ReLU network η with two input units that implements a function x˜ : R2 → R so that
• for any inputs x,y, if |x| ≤ M′ and |y| ≤ M′, then |x˜(x,y)−xy| ≤ ϵ;
• the depth and the number of computation units in η are O(ln(1/ϵ)+ln(M′));
• the width of η is a constant C independent of x,y.
w
Bound of the first term in (30)
We commence by outlining the detailed structure of φ
t
(cid:34) (cid:35)
N N
(cid:88) (cid:88)
φ (Y) = [φ ,...,φ ] = φ ,..., φ , (31)
t t,1 t,N t,1,n t,N,n
n=1 n=1
where
φ (Y ) = w⊤Y , φ (Y ) = x˜ (φ (Y ),φ (Y )), (32)
t,1,n n t i t,k+1,n n 1 t,1,n n t,k,n n
with w ∈ [−B,B]K representing learnable weights approximating a⊤, and x˜ being a ReLU network as
t t 1
per Lemma 5. Given that ∥Y∥ ≤ 1, it follows that |(a⊤Y )j| ≤ |a⊤Y |j ≤ (aK)j. Consequently, the
∞ t n t n
deviation|φ (Y)−g (Y)|canbeboundedbyiterativelyapplyingLemma5withparametersM′ = (aK)N
t t
and ϵ = δ , leading to
1
|φ (Y )−(a⊤Y )1| = 0,
t,1,n n t n
|φ (Y )−(a⊤Y )2| = |x˜ (φ (Y ),φ (Y ))−(a⊤Y )2| ≤ δ ,
t,2,n n t n 1 t,1,n n t,1,n n t n 1
|φ (Y )−(a⊤Y )k+1|
t,k+1,n n t n
= |x˜ (φ (Y ),φ (Y ))−φ (Y )φ (Y )+a⊤Y φ (Y )−(a⊤Y )k+1|
1 t,1,n n t,k,n n t,1,n n t,k,n n t n t,k,n n t n
≤ δ +aK|φ (Y )−(a⊤Y )k|.
1 t,k,n n t n
Through recursion, we obtain
k−1
(cid:88)
∀ t,n, |φ (Y )−(a⊤Y )k| ≤ δ ( (aK)n) ≤ δ (aK)k. (33)
t,k,n n t n 1 1
n=0
So we can bound the error between φ (Y) and g (Y) as follows
t t
∥φ (Y)−g (Y)∥
t t ∞
(cid:13)(cid:34) (cid:35) (cid:34) (cid:35)(cid:13)
N N N N
(cid:13) (cid:88) (cid:88) (cid:88) (cid:88) (cid:13)
= (cid:13) φ (Y ),..., φ (Y ) − (a⊤Y ),..., (a⊤Y )N (cid:13)
(cid:13) t,1,n n t,N,n n t n t n (cid:13)
(cid:13) (cid:13)
n=1 n=1 n=1 n=1 ∞
N N
(cid:88) (cid:88)
= ∥ φ (Y )− (a⊤Y )N∥
t,N,n n t n ∞
n=1 n=1
N
(cid:88)
≤ ∥φ (Y )−(a⊤Y )N∥
t,N,n n t n ∞
n=1
≤ δ N(aK)N.
1CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 29
Lemma 6 (Lipschitz continulty of polynomial functions). Suppose f(x) : [−k,k]n → R is a
polynomial with degree β and coefficients bounded by C. f is Lipschitz continues with Lipschitz constant
Cβkβ−1
|f(x)−f(y)| = |f(x)−(f(x)−∇f(ξ)⊤(y−x))| = |∇f(ξ)⊤(x−y)| ≤ Cβkβ−1∥x−y∥ .
∞
Recall that h is a polynomial over N variables, having a maximum order of MN +β. Its coefficients
t
are bounded by C and the infinity norm of the input ∥g ∥ = (cid:80)N (a⊤Y )N can be upper bounded by
t ∞ n=1 t n
N(aK)N. By applying Lemma 6 with a parameter k = N(aK)N to h , we obtain
t
|h (φ (Y))−h (g (Y))|
t t t t
≤ C(MN +β)(N(aK)N)MN+β∥φ (Y)−g (Y)∥
t t ∞
≤ C(MN +β)(N(aK)N)MN+βN2(aK)Nδ . (34)
1
Bound of the second term in (30)
Then we provide the detailed structure of ψ
t
MN+β
(cid:88) (cid:88)
ψ (x) = γ ψ˜ (x), x ∈ RN, (35)
t t,s s
i=0 s∈{1,...,N}i
where γ ∈ [−B,B] are learnable weights and ψ˜ (x) is the following ReLU network approximating
t,s s
(cid:81)
x by
j∈s j

ψ˜ (x) = x ,
  s,1 s 1
ψ˜ (x) = x˜ (ψ˜ (x),x ), k ≤ |s|,
s,k 2 s,k−1 s
k
  ψ˜ s = ψ˜ |s s|,
wherex˜ istheReLUnetworkfromLemma5,withparametersettingsofϵ = δ andM′ = (∥φ (X)∥ )MN+β ≤
2 2 t ∞
NMN+β(aK)MN2+βN. Adhering to the procedure in (33), we derive
(cid:89)
|ψ˜ (φ (Y))− φ (Y)| ≤ δ (MN +β)∥φ (Y)∥MN+β ≤ δ (MN +β)(N(aK)N)MN+β.
s t t,j 2 t ∞ 2
j∈s
By setting γ = c , we establish a bound for the error as follows
t,s t,s
|ψ (φ (Y))−h (φ (Y))|
t t t t
MN+β
(cid:88) (cid:88) (cid:89)
= c |ψ˜ (φ (Y))− φ (Y)|
t,s s t t,j
i=0 s∈{1,...,N}i j∈s
≤ NMN+βC(MN +β)(N(aK)N)MN+βδ . (36)
2
In summary, we have demonstrated the following
∥f −f ∥ ≤ |g(Y)−g˜(Y)|
1 n ∞
T
(cid:88)(cid:104) (cid:105)
≤ |h (φ (Y))−h (g (Y))|+|ψ (φ (Y))−h (φ (Y))|
t t t t t t t t
t=1
(cid:104) (cid:105)
≤ TC(MN +β) (N(aK)N)MN+β+2δ +(N2(aK)N)MN+βδ , (37)
1 2
where the final inequality is deduced from (34) and (36), along with certain calculations.
To put things together, recall that
∥f −f∗∥ ≤ ∥f −f∗∥ +∥f −f ∥ . (38)
n ∞ 1 ∞ n 1 ∞
To ensure ∥f −f∗∥ ≤ ϵ, we set ∥f −f∗∥ and ∥f −f ∥ to be less than or equal to ϵ. Based on
n ∞ 1 ∞ 1 n ∞ 2
the upper bound for ∥f −f∗∥ as given in (27), we establish
1 ∞
2ddβJ (cid:18) 1 (cid:19)β ϵ
= .
β! N′ 230 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
(cid:16) (cid:17)−1/β
This setting confirms that ∥f −f∗∥ ≤ ϵ, leading to N′ = β!ϵ = O(ϵ−1/β). Consequently,
1 ∞ 2 2d+1dβJ
we have T = O((N′)MN) = O(ϵ−M βN ) and K = (N′+1)M = O(Mϵ−1/β).
Finally, we set both terms in (37) equal to ϵ, leading to
4
ϵ
TC(MN +β)(N(aK)N)MN+β+2δ = ,
1
4
ϵ
TC(MN +β)(N2(aK)N)MN+βδ = ,
2
4
disregarding lower-order terms and constants, we have
ϵ MN2+Nβ
δ 1 = O( TNMN+β(aK)MN2+βN) = O(ϵ β ), (39)
ϵ MN2+Nβ
δ 2 = O( TN2MN+2β(aK)MN2+βN) = O(ϵ β ). (40)
Utilizing δ and δ , we determine the bounds for the structural parameters of the PIE ψ(φ(Y)),
1 2
referencing Lemma 5. Notably, ψ(φ(Y)) =
(cid:80)T
ψ (φ (Y)) signifies that the outlier network ψ is a
t=1 t t
composition of T sub-networks ψ , each being a weighted average of NMN+β distinct ψ˜ functions. Each
t s
ψ˜ is recursively constructed using at most MN +β instances of x˜ , as indicated in (38), where x˜ (·)
s 2 2
possesses a depth and weight count of O(ln(1/δ )). Thus, each ψ˜ exhibits a depth and parameter count
2 s
of at most (MN +β)O(ln(1/δ )). Consequently, ψ represents a weighted aggregation of up to NMN+β
2 t
distinct ψ˜ functions. Therefore, we establish that
s
L
ψ
= (MN +β)O(ln(1/δ 2)) =
O(ln(ϵ−MN2 β+Nβ
)),
S
ψ
= TNMN+β(MN +β)O(ln(1/δ 2)) = O(ϵ−M βN ).
Likewise, the inner network φ comprises T sub-networks φ ,...,φ , each defined iteratively using N
1 T
instances of x˜ and T distinct learnable weights w , as outlined in (32). Hence, we ascertain
1 t
L
φ
= NO(ln(1/δ 1)) =
O(ln(ϵ−MN2 β+Nβ
)),
S
φ
= KT +TNO(ln(1/δ 1)) =
O(ϵ−M βN
).
C.3. Estimation error
Here, we evaluate the term
n
2 (cid:88)
ξ (fˆ(Y )−f(Y )).
n i (i) (i)
i=1
As defined in (28), here Y ∈ RK×N is the transformation of the i-th sample X ∈ RM×N in the
(i) (i)
dataset. To employ concentration inequalities, we examine the expectation of the upper bound of this
term
(cid:34) (cid:12) (cid:12)(cid:35)
n
(cid:12)2 (cid:88) (cid:12)
E sup(cid:12) ξ (fˆ(Y )−f(Y ))(cid:12) .
ξ (cid:12)n i (i) (i) (cid:12)
f∈F(cid:12) (cid:12)
i=1
Initially, we define a subset F ⊂ F as
δ
F = {f −fˆ: ∥f −fˆ∥ ≤ δ,f ∈ F}.
δ n
where δ is finite, given that functions in F are bounded as
δ
∥f −fˆ∥ ≤ ∥f −fˆ∥ ≤ ∥f∥ +∥fˆ∥ ≤ 2J, f ∈ F.
n ∞ ∞ ∞
Thus, by applying the chaining technique from Lemma 2, we deduce
(cid:34) (cid:12) (cid:12)(cid:35) √
(cid:12)1 (cid:88)n (cid:12) 4 2σ (cid:90) δ/2 (cid:112)
E sup (cid:12) ξ f′(Y )(cid:12) ≤ 2logN(ϵ′,F ,∥·∥ )dϵ′, (41)
ξ (cid:12)n i (i) (cid:12) n1/2 δ ∞
f′∈F δ(cid:12)
i=1
(cid:12) 0
and subsequently, we establish a bound for logN(ϵ′,F ,∥·∥ ), analogous to Theorem 2 in (Schmidt-
δ ∞
Hieber, 2020).CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 31
Lemma 7. Let f : [−M,M]d (cid:55)→ R be fully connected ReLU neural network. Suppose f has L layers
W ,...,W with weights bounded by B and let σ denotes the ReLU activation function, we can represent
1 L
f as
f(X) = W σ(W ···σ(W X)···).
L L−1 1
Let p denotes the width of layer W , then f(X) is upper bounded by
(cid:81)L
(p B)M =
MBL(cid:81)L
p and
l l l=1 l l=1 l
is Lipschitz continues with Lipschitz constant (cid:81)L (p B) = BL(cid:81)L p . Suppose f∗ is another neural
l=1 l l=1 l
network with same structure as f but with all the parameters ϵ away from f, then
L L
(cid:89) (cid:89)
∥f −f∗∥ ≤ ϵ (p B)LM = ϵLMBL p .
∞ l l
l=1 l=1
Lemma 7 is an application of Lemma 8 in (Schmidt-Hieber, 2020), we skip the detailed proof.
Consider ψ(φ),ψ∗(φ∗) ∈ F, which are two PIEs with identical structures. However, each correspond-
ingparameterinthesePIEsdiffersbynomorethanζ. Weaimtoestablishaboundfor∥ψ(φ)−ψ∗(φ∗)∥
∞
T
(cid:88)
|ψ(φ(Y))−ψ∗(φ∗(Y))| ≤ |ψ (φ (Y))−ψ∗(φ∗(Y))|.
t t t t
t=1
To further analyze this, we decompose the last term as follows
|ψ (φ (Y))−ψ∗(φ∗(Y))| ≤ |ψ (φ (Y))−ψ (φ∗(Y))|+|ψ (φ∗(Y))−ψ∗(φ∗(Y))|. (42)
t t t t t t t t t t t t
Bound of the first term in (42)
We first bound ∥φ (Y)−φ∗(Y)∥ . Recall that φ is iteratively defined with ReLU network x˜ ,which
t t ∞ t 1
is a special case of f of Lemma 7. Here we use L to denote the number of layers in x˜ . From the
x˜ 1
1
construction of φ, we know L = NL . From Lemma5, the width of x˜ is bounded by C . We apply
φ x˜ 1 w
1
Lemma 7 with L being L and p = C , so for any t,n
x˜ l w
1
φ (Y ) = w⊤Y ≤ BK,
t,1,n n t n
φ t,2,n(Y n) = x˜ 1(φ t,1,n(Y n),φ t,1,n(Y n)) ≤ (C wB)L x˜1BK,
φ t,k+1,n(Y n) = x˜ 1(φ t,1,n(Y n),φ t,k,n(Y n)) ≤ (C wB)L x˜1|φ t,k,n(Y n)| ≤ (C wB)i×L x˜1BK.
Thus, φ t,N,n(Y n) ≤ (C wB)L φBK and φ t(Y) ≤ N(C wB)L φBK. By defining ∆
t,k,n
= |φ t,k,n(Y n) −
φ∗ (Y )|, we iteratively bound the differences
t,k,n n
∆ = |w⊤Y −w∗⊤Y | ≤ Kζ,
t,1,n t n t n
∆ ≤ |x˜ (φ (Y ),φ (Y ))−x˜ (φ (Y )φ∗ (Y ))|
t,k,n 1 t,1,n n t,k−1,n n 1 t,1,n n t,k−1,n n
+|x˜ (φ (Y ),φ∗ (Y ))−x˜∗(φ (Y ),φ∗ (Y ))|
1 t,1,n n t,k−1,n n 1 t,1,n n t,k−1,n n
≤ (C wB)L x˜1∆ t,k−1,n+ζ(C wB)L x˜1L
x˜
1max(φ t,1,n(Y n),φ∗ t,k−1,n(Y n))
≤ (C wB)L x˜1∆ t,k,n+ζ(C wB)L x˜1L
x˜
(C wB)i−1×L x˜1BK.
1
Through recursive application, ∆
t,N,n
is bounded by ζ(C wB)N×L x˜1L φBK = ζ(C wB)L φL φBK, allow-
ing us to establish a bound for ∥φ (Y)−φ∗(Y)∥
t t ∞
∥φ (Y)−φ∗(Y)∥
t t ∞
(cid:13)(cid:34) (cid:35)(cid:13)
N N
(cid:13) (cid:88) (cid:88) (cid:13)
= (cid:13) ∆ (Y ),..., ∆ (Y ) (cid:13)
(cid:13) t,1,n n t,N,n n (cid:13)
(cid:13) (cid:13)
n=1 n=1 ∞
N
(cid:88)
≤ ∆ (Y )
t,N,n n
n=1
≤ ζ(C wB)L φL φBKN. (43)32 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
To finalize the bound on the first term in (42), it is necessary to establish the Lipschitz continuity of
ψ . Assume x,y ∈ RN, then
t
MN+β
(cid:88) (cid:88)
|ψ (x)−ψ (y)| = | γ (ψ˜ (x)−ψ˜ (y))|.
t t t,s s s
i=0 s∈{1,..,N}i
According to Lemma 5, x˜
2
is Lipschitz continuous with a Lipschitz constant of (C wB)L x˜2. Let Γ
i
=
|ψ˜ (x)−ψ˜ (y)|, we have
s,i s,i
Γ = |x −y | ≤ ∥x−y∥ ,
1 s s ∞
1 1
Γ = x˜ (ψ˜ (x),x )−x˜ (ψ˜ (y),y )
i+1 2 s,i m 2 s,i m
i+1 i+1
≤ (C wB)L x˜2 max{Γ i,|x s −y s |}
i+1 i+1
≤ (C wB)L x˜2Γ i.
After some computations, we find |ψ˜ s(x) − ψ˜ s(y)| ≤ (C wB)L ψ∥x − y∥ ∞. Consequently, ψ
t
exhibits
Lipschitz continuity with
|ψ t(x)−ψ t(y)| ≤ NMN+β(C wB)L ψ∥x−y∥ ∞.
Therefore, the first term in (42) can be bounded as follows
∥ψ t(φ t(Y))−ψ t(φ∗ t(Y))∥
∞
≤ NMN+β(C wB)L ψ∥φ t(Y)−φ∗ t(Y)∥
∞
≤ ζNMN+β(C wB)L ψ+L φL φK, (44)
where the last inequality is derived by incorporating (43) and disregarding the term BN.
Bound of the second term in (42)
With the similar argument as in (43), we derive the following bound
MN+β
(cid:88) (cid:88)
∥ψ (φ∗(Y))−ψ∗(φ∗(Y))∥ ≤ | (γ ψ˜ −γ ψ˜∗)(φ∗(Y))|.
t t t t ∞ t,s s t,s s t
i=0 s∈{1,..,N}i
Additionally, we establish that
|(γ ψ˜ −γ ψ˜∗)(φ∗(Y))| ≤ |(γ ψ˜ −γ ψ˜∗+γ ψ˜∗−γ ψ˜∗)(φ∗(Y))|
t,s s t,s s t t,s s t,s s t,s s t,s s t
≤ |γ t,sζ(C wB)L ψL ψ∥φ∗ t(Y)∥ ∞|+|(γ t,s−γ t∗ ,s)(C wB)L ψ∥φ∗ t(Y)∥ ∞|
≤ [ζB(C wB)L ψL
ψ
+ζ(C wB)L ψ]∥φ∗ t(Y)∥
∞
≤ ζ(C wB)L ψL ψ(C wB)L φK
= ζ(C wB)L ψ+L φL ψK.
In a similar fashion to our earlier derivation for φ, we apply bounds to ψ˜ and evaluate the discrepancy
s
betweenψ˜ andψ˜∗. Forsimplicity,weomitthelowerordertermB inthefourthinequality. Consequently,
s s
we obtain
∥ψ t(φ∗ t(Y))−ψ t∗(φ∗ t(Y))∥
∞
≤ ζ(C wB)L ψ+L φL ψNMN+βK. (45)
To summarize, we bring (44) and (45) together
∥ψ(φ(Y))−ψ∗(φ∗(Y))∥
∞
≤ ζT(C wB)L ψ+L φ(L
ψ
+L φ)NMN+βK. (46)
Given that the total number of parameters is constrained by S +S , with each parameter bounded
ψ φ
by B, we discretize the range of each parameter using a grid of size
∆ = ϵ′/T(C wB)L ψ+L φ(L
ψ
+L φ)NMN+βK,
which leads to an upper bound on the covering number as follows
logN(ϵ′,F δ,∥·∥ ∞) ≤
log((2 ∆B
)S ψ+S φ) = (S
ψ
+S
φ)log(BT(C wB)L ψ+L φ(L
ϵ′ψ
+L φ)NMN+βK
).CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 33
Returning to (41) and integrating, we derive
 (cid:12) (cid:12)
E ξ sup (cid:12) (cid:12) (cid:12) (cid:12)n1 (cid:88) ξ if′(Y (i))(cid:12) (cid:12) (cid:12) (cid:12) ≤ 2√ 2σ(cid:112) S nψ 1/+
2
S φδ (cid:18) log (T(C wB)L ψ+L φ(L δψ +L φ)NMN+βK +1(cid:19) .
f′∈F δ(cid:12) i∈[n] (cid:12)
Utilizing this bound for the expectation , we apply the Gaussian concentration inequality, as presented
in (Gin´e and Nickl, 2021), by considering 1 (cid:80)n ξ f′(Y ) as the Gaussian process X(t). The variance
n i=1 i (i)
of 1 (cid:80)n ξ f′(Y ) is upper bounded by σ2δ2, thus
n i=1 i (i) n
1−exp(−nu2/2σ2δ2)
 
n
1 (cid:88) 1 (cid:88)
≤ P ξ2 sup |
n
ξ if′(Y (i))| ≤ 2E ξ[ sup |
n
ξ if′(Y (i))|]+u
f′∈F f′∈F
δ i=1 δ i∈[n]
(cid:32) (cid:33)
≤ P 2 sup
|1 (cid:88)n
ξ f′(Y )| ≤ V δ(log
(T(C wB)LLNMN+βK
+1)+u , (47)
ξ n i (i) n δ
f′∈F
δ i=1
√ √
where L = L +L , S = S +S and V = 4 2σ S.
ψ φ ψ φ n n1/2
Let δ = max{∥fˆ−f∥ ,V }, then by the definition of F , we have
n n δ
n n
1 (cid:88) 1 (cid:88)
sup| ξ (fˆ(Y −f(Y ))| ≤ sup | ξ f′(Y )|.
n i (i) (i) n i (i)
f∈F f′∈F
i=1 δ i=1
Thus, for any f ∈ F, it follows that
n
2 (cid:88)
| ξ (fˆ(Y )−f(Y ))|
n i (i) (i)
i=1
(cid:26) (T(C B)LLNMN+βK (cid:27)
≤ max{∥fˆ−f∥ ,V } V (log w +1) +u
n n n
V
n
1 (cid:26) (T(C B)LLNMN+βK (cid:27)2
≤ (max{∥fˆ−f∥ ,V })2+2 V (log w +1) +u, (48)
n n n
4 V
n
with probability at least 1−exp(−nu2/2σ2δ2). The last inequality holds since xy ≤ 1x2+2y2. Utilizing
4
the inequality given in (26), we have
n
2 (cid:88)
− ξ (fˆ(Y )−f(Y ))+∥f∗−fˆ∥2 ≤ ∥f∗−f∥2.
n i (i) (i) n n
i=1
Applying the inequality 1∥fˆ−f∥2 ≤ ∥f −f∗∥2 +∥f∗−fˆ∥2, we obtain
2 n n n
n
2 (cid:88) 1
− ξ (fˆ(Y )−f(Y ))+ ∥fˆ−f∥2 ≤ 2∥f∗−f∥2. (49)
n i (i) (i) 2 n n
i=1
Combining (49) and (48), we derive
1 (cid:26) (T(C B)LLNMN+βK (cid:27)2 1
− (max{∥fˆ−f∥ ,V })2−2 V (log w +1) −u+ ∥fˆ−f∥2 ≤ 2∥f∗−f∥2.
4 n n n V 2 n n
n
It can be verified that whether ∥fˆ−f∥ ≥ V or ∥fˆ−f∥ ≤ V , the following holds
n n n n
(cid:26) (T(C B)LLNMN+βK (cid:27)2
∥fˆ−f∥ ≤ 4 V (log w +1) +2u+4∥f∗−f∥2. (50)
n n V n
n
Apply (50) to the inequality 1∥fˆ−f∗∥2 ≤ ∥f∗−f∥2 +∥fˆ−f∥2, we obtain
2 n n n
(cid:26) (T(C B)LLNMN+βK (cid:27)2
∥fˆ−f∗∥2 ≤ 10∥f∗−f∥2 +8 V (log w +1) +4u, (51)
n n n V
n
with probability at least 1−exp(−nu2/2σ2δ2) for all u > 0.34 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
C.4. Overall order
Recall that (51) is valid for any f ∈ F, allowing us to select f as f from Section C.2. So that
n
δ2 = max{∥fˆ−f∥2,V2}. Then we set u = 1 δ2
n n 16
(cid:26) (T(C B)LLNMN+βK (cid:27)2 1
∥fˆ−f∗∥2 ≤ 10∥f∗−f ∥2 +8 V (log w +1) + (∥fˆ−f ∥2 +V2)
n n n n V 4 n n n
n
(cid:26) (T(C B)LLNMN+βK (cid:27)2
≤ 21∥f∗−f ∥2 +17 V (log w +1) , (52)
n n n V
n
withprobabilityatleast1−exp(−nδ2/2σ2). Thelatterinequalityfollowssince 1∥fˆ−f ∥2 ≤ ∥f∗−f ∥2+
2 n n n n
∥fˆ−f∗∥2 n. Let ϵ = n− MNβ +2β and substitute the order of of S ψ,S φ,L ψ,L φ from Section C.2. We obtain
that V
n
= O(n− MN2β +2β), therefore (52) holds with probability 1−exp(−nδ2/2σ2) ≥ 1−exp(−nV n2/2σ2)
converging to one. Then we take the expectation of both sides of the inequality with respect to P
X
∥fˆ−f∗∥2
L (P )
2 X
(cid:26) (T(C B)LLNMN+βK (cid:27)2
≤ 21∥f −f∗∥2 +17 V (log w +1)
n L 2(P X) n V
n
(cid:26) (T(C B)LLNMN+βK (cid:27)2
≤ 21ϵ2+17 V (log w +1) , (53)
n
V
n
where the latter inequality follows since ∥f −f∗∥ ≤ ∥f −f∗∥ ≤ ϵ2. Disregarding constants and
n L (P ) n ∞
2 X
lower-order terms, we obtain
∥fˆ−f∗∥2 ≤
21ϵ2+17 
V (log
ϵ−M βN (C wB)ln(ϵ−MN2 β+Nβ +1) ) 2
L 2(P X)

n V
n 
= O(n− MN2β +2β),
with probability converging to one. So we conclude
∥fˆ−f∗∥2
L2(P )
= O p(n− MN2β +2β). (54)
X
D. Proof of Theorem 4
This section is devoted to deriving a lower bound for the L minimax risk associated with the class of
2
permutation invariant functions. Additionally, we aim to demonstrate that the PIE proposed in this
study constitutes an optimal estimator in the minimax framework.
Definition 3 (L minimax risk). Given a random variable X following a probability measure P
2 X
on Rd, the L minimax risk of estimation associated with any function space I ∈ L (P ) is defined as
2 2 X
r2(I,P ,σ) = inf sup∥fˆ−f∥2 ,
n X L (P )
fˆ∈A f∈I 2 X
n
where A is the space of all measurable functions of data in L (P ) and σ is the variance of Gaussian
n 2 X
noise in the data generating process.
Given the definition of permutation invariance as specified in Assumption 2, it follows that Pβ,1×MN is
a subset of Pβ,M×N. Consequently, r2(Pβ,M×N,P ,σ) ≥ r2(Pβ,1×MN,P ,σ). This implies that any
n X n X
lower bound on the L minimax risk of Pβ,1×MN also serves as a valid lower bound for Pβ,M×N. For
2
ease of notation, let us denote d = MN and use Pβ,d to refer to Pβ,1×MN.
We try to get the L minimax lower bound using the relationship between minimax risk and packing
2
number. So we first bound the packing number T(ϵ,Pβ,d,∥·∥ ) using the lemma that follows
L
2CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 35
Lemma 8. The packing number of Pβ,d is lower bounded with
T(ϵ,Pβ,d,∥·∥ ) ≥ exp{M (1/ϵ)d/β}.
L 0
2
In addition, we have
T(ϵ,Pβ,d,∥·∥ ) ≥ exp{M (P /ϵ)d/β},
L (P ) 0 X
2 X
where M depends on only β and d.
0
Proof. In alignment with the approach outlined in Lemma 6.1 of (Yang and Tokdar, 2015), we
define
d
(cid:89)
K(X ,...,X ) = K (X ), K (t) = te−1/(1−t2)I(|t| ≤ 1),t ∈ R.
1 d 0 j 0
j=1
For arbitrary radius h ∈ (0,1/2), we evenly split [0,1] into m = (cid:6) 1 (cid:7) intervals and obtain D = md
2h
(cid:16) (cid:17)
rectangular grid points j 1 −h,..., j d −h with (j ,...,j ) ∈ {1,...,m}d. We use {x : k = 1...,D}
m m 1 d k
to represent these grids and assume h is small enough to ensure D ≥ 8.
For simplicity, let W = Wβ,∞([0,1]MN) and let ∥·∥ denote the norm of the Soblev space. Corre-
J W
spondingly, we construct functions ϕ for each 1 ≤ k ≤ D
k
(cid:18) (cid:19)
1 x−x
ϕ (x) = hβK k , x ∈ [0,1]d,
k
∥K∥ h
W
with each ϕ having its support confined to [x − h,x + h]d. It’s noteworthy that K (t) is an odd
k k k 0
(cid:82)
function, ensuring that ψ (x)dx = 0. Moreover, the supports of ϕ and ϕ for k ̸= j do not overlap,
k k j
thus allowing for
(cid:90) k
ϕ ϕ dx = 0, ∥ϕ +···+ϕ ∥2 = (cid:88) ∥ϕ ∥2 = kh2β+d∥K∥ L 2. (55)
k j 1 k L 2 i L 2 ∥K∥
W
i=1
Furthermore, we define permutation invariant functions ϕ∗ based on ϕ as
k k
(cid:18) (cid:19)
ϕ∗(x) = 1 (cid:88) 1 hβK x−Π x k , x ∈ [0,1]d, (56)
k |S |1/2 ∥K∥ h
d W
Π∈S
d
so ϕ∗(x) is a permutation invariant function for any k and
k
∥ϕ∗∥2 = 1 (cid:13) (cid:13) (cid:13) (cid:88) 1 hβK(cid:18) x−Π x k(cid:19)(cid:13) (cid:13) (cid:13)2
k L 2 |S | (cid:13) ∥K∥ h (cid:13)
d (cid:13) W (cid:13)
Π∈S d L 2
≥
1 (cid:88) (cid:13) (cid:13)
(cid:13)
1 hβK(cid:18) x−Π x k(cid:19)(cid:13) (cid:13) (cid:13)2
|S | (cid:13)∥K∥ h (cid:13)
d Π∈S d W L 2
∥K∥
= h2β+d L 2,
∥K∥
W
where the second inequality becomes equal when for all permutations Π in S , Π ̸= x . Consider
d x k
k
the total number of distinct functions ϕ∗, denoted as D∗. In (56), we construct a set of D functions ϕ∗
k k
derived from ϕ . Specifically, each ϕ∗ is identical to ϕ∗ for distinct indices k and j if and only if there
k k j
exists a permutation Π such that Π equals x . Considering that there are at most |S | ≤ dd distinct
x j d
k
permutations for the d-dimensional vector x , we can infer that D∗ is bounded from below by D/dd.
k
Let Ω = {0,1}D∗ and for each ω ∈ Ω define f = (cid:80)D∗ ω ϕ∗. It is evident that each f belongs to
ω k=1 k k ω
Pβ,d
(cid:40) D∗ (cid:90) (cid:41)1/2
(cid:88) ∥K∥
∥f −f ∥ = (ω −ω′)2 ϕ∗2dx ≥ hβ+d/2 ψ1/2(ω,ω′),
ω ω′ L 2 k k k ∥K∥
W
k=1
where ψ(ω,ω′) = (cid:80)D∗ I(ω ̸= ω′) represents the hamming distance. Applying the Varshamov-Gilbert
k=1 k k
bound from coding theory, it can be shown that there exist U ≥ 2D∗/8 binary strings ω(1),...,ω(U) ∈ Ω
such that ψ(ω(k),ω(k′)) ≥ D∗/8 for 0 ≤ k ≤ k′ ≤ A. Then36 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
(cid:114)
∥K∥ D∗
∥f −f ∥ ≥ hβ+d/2 L 2 ≥ M hβ,
ω(k) ω(k′) L 2 ∥K∥ 8 1
W
where M = ∥K∥ /{2(d+3)/2dd/2∥K∥ } is a constant that depends solely on β and d. By setting
1 L W
2
ϵ = M hβ, we are able to identify U distinct functions within the function class P . These functions
1 β,d
are separated from each other by at least ϵ with respect to the L norm distance, with
2
U ≥ exp{D∗log(2)/8}
≥ exp{mdlog(2)/dd8}
≥ exp{(1/2h)dlog(2)/dd8}
≥ exp{(M /ϵ)d/βlog(2)/dd2d+3}
1
= exp{M (1/ϵ)d/β},
0
where M = (Md/β log(2))/dd2d+3 depends on only d and β. Consequently, in accordance with the
0 1
definition of the packing number, we have
T(ϵ,P ,∥·∥ ) ≥ exp{M (1/ϵ)d/β}.
β,d L 0
2
For any two functions f,f′ ∈ Pβ,d that satisfy ∥f −f′∥ ≥ ϵ, it follows that ∥f −f′∥ ≥ ϵP .
L 2 L 2(P X) X
Therefore
T(ϵP ,P ,∥·∥ ) ≥ exp{M (1/ϵ)d/β},
X β,d L (P ) 0
2 X
and upon setting ϵ′ = P ϵ, we deduce
X
T(ϵ′,P ,∥·∥ ) ≥ exp{M (P /ϵ)d/β}.
β,d L (P ) 0 X
2 X
By Theorem 6 of (Yang and Barron, 1999), the minimax risk r is the solution to log(T(r ,Pβ,d,∥·
n n
∥
L 2(P
X))) = n σr n2 . From the definition of packing number, T(r n,Pβ,d,∥·∥
L 2(P
X)) decreases as r
n
increases,
whiler2 increaseswithr . SoanyrsatisfyingT(r,Pβ,d,∥·∥ ) ≥ nr2 isalowerboundofr . Choosing
n n L 2(P X) σ n
r = (M 0σ)2ββ +d(P X)2βd +dn− 2ββ +d,itcanbeverifiedthatT(r,Pβ,d,∥·∥
L 2(P
X)) ≥ n σr2. Consequently,r2 forms
a lower bound for the minimax risk r2.
n
Returning to the notation where d = MN, we deduce that
r n2(Pβ,M×N,P X,σ) ≥ r n2(Pβ,1×MN,P X,σ) ≥ C(β,M,N)n− 2β+2β MN,
which aligns with the convergence rate of PIE, as established in (54), up to a constant factor. Thus,
the minimax optimality of PIE in approximating fully permutation invariant functions is established.
E. Proof of Corollary 1
Inthissection,ourobjectiveistosubstantiateCorollary1throughabroaderperspective. Toachievethis,
we expand the scope beyond the conventional permutation invariance assumptions and the associated
Permutation Invariant Estimator PIE. We introduce and focus on the concept of partially permutation
invariant functions and the corresponding Partially Permutation Invariant Estimator PPIE. Once we
ascertain the convergence rate of PPIE, it will provide the necessary foundation to validate Corollary 1.
Definition 4 (Partially Permutation Invariant Function). Afunctionf ispartiallypermu-
tation invariant if its input can be separate into P input matrix {X 1,··· ,X P} , where each X
p
∈ RM×N p.
The function remains unchanged under column permutations within each individual input matrix. For-
mally, this property is expressed as
(1) (2) (P)
f(X ,X ,··· ,X ) = f(Π ,Π ,··· ,Π ), (57)
1 2 P X X X
1 2 P
for any permutation Π(k) ∈ S .
N
p
The corresponding estimator, known as the Partially Permutation Invariant Estimator (PPIE), is
defined as follows:CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 37
Definition 5 (Partially Permutation Invariant Estimator(PPIE) Structure). Givenapar-
tially permutation invariant function f with P input matrix X = {X 1,··· ,X P},where X p ∈ RM×N p as
described in Definition 4, the PPIE neural network is structured as
(cid:32) N N N (cid:33)
1 (cid:88)1 1 (cid:88)2 1 (cid:88)P
ψ φ(1)(X ), φ(2)(X ),··· , φ(K)(X ) ,
1,i 2,i P,i
N N N
1 2 P
n=1 n=1 n=1
where X denotes the i-th column of X , and φ and ψ are neural networks.
p,i p p
Our goal is to establish the bound for
2
∥f∗−fˆ∥2 ≤ ∥f∗−f∥2 + ξ (fˆ(x )−f(x )).
n ∞ n i i i
It can be shown that the fully permutation invariant target function, as stipulated in Assumption 2, is
a specific case of the partially permutation invariant function. This is achieved by setting P = 2, with
X ∈ R(M+1)×|N(i)| and X ∈ R(M+1)×1. Therefore, our focus shifts to examining the convergence rate
1 2
of the PPIE function class.
E.1. Approximation Error
For ease of discussion, let us denote N =
(cid:80)P
N . Following a similar approach as in Section C.2, we
p=1 p
define an approximation of the function f∗ by
f 1∗(X) = (cid:88) ϕ m(X) (cid:88) D pp !f(cid:12) (cid:12) (cid:12)
(cid:12)
(X − Nm ′)p,
m∈{0,1,···,N′}K×M×N p:|p|≤β X= Nm ′
where ϕ is defined identically to its counterpart in Section C.2.
m
Considering X = {X 1,··· ,X P} and defining |S(cid:98)| =
(cid:81)P
p=1|S
N
p|, we construct the partially permuta-
tion invariant (PI) approximation using f∗
1
1 (cid:88)
f (X) = f (X ,··· ,X ) = f∗((Π ) ,··· ,(Π ) ).
1 1 1 P |S(cid:98)| 1 1 X 1 K X P
Π ∈S ···
1 N1
Π ∈S
K NP
Using similar arguments, it can be shown that
2ddβJ (cid:18) 1 (cid:19)β
∥f∗(X)−f (X)∥ ≤ .
1 ∞ β! N′
LetK′ = (N′+1)×N anddefineK′ = (cid:80)P K′. WethenconstructY(X,N′) = (Y (X ,N′),...,Y (X ,N′))
p p p=1 p 1 1 P P
where Y p(X p,N′) ∈ RK p′×M is defined analogously to (28). Consequently, f 1(X) can be transformed into
g(Y) by
f∗(X) = g∗(Y(X,N′)),
1
f (X) = 1 (cid:88) g∗(cid:0) Y ((Π ) ,N′),··· ,Y ((Π ) ,N′)(cid:1) = g(Y).
1 1 1 X p K X
|S(cid:98)| 1 P
Π ∈S ···
1 N1
Π ∈S
K NP
From the arguments in Section C.2, we know g(Y) is a partially permutation invariant polynomial.
To further decompose g(Y), we introduce the following lemma which is similar to Lemma 3.
Lemma 9 (Partially PI polynomial decomposition). Given Y = {Y ,··· ,Y } where Y ∈
1 P p
RM×N p, any partially permutation invariant polynomial g(Y) can be expressed in the following form
Q
(cid:88)
g(Y) = h (Y )h (Y )···h (Y ),
1,q 1 2,q 2 P,q P
q=1
where Q is an integer, and h (Y ) are permutation invariant polynomials.
p,q p38 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
With Lemma 9, we can show g(Y) =
(cid:80)Q
h (Y )h (Y )···h (Y ), where each function h is
q=1 1,q 1 2,q 2 P,q P p,q
a fully permutation invariant polynomial. Therefore, we can further decompose each h into a power
p,q
sum basis as described in Lemma 4
T N N
(cid:88)p,q (cid:88)p (cid:88)p
h p,q(Y p) = s p,q,t( (a⊤ p,q,tY p,n)1,··· , (a⊤ p,q,tY p,n)N p).
t=0 n=1 n=1
With this decomposition of g(Y), we can construct a PPIE, g(Y), as follows
(cid:101)
g (cid:101)(Y) = τ((cid:101)h 1,q(Y 1),...,(cid:101)h p,q(Y p),...,(cid:101)h P,Q(Y P)),
where (cid:101)h p,q(Y p) approximates h p,q(Y p), and τ approximates the product of the h
p,q
functions. Then we
propose the structure of τ and (cid:101)h
p,q
in detail. τ is iterativly defined with x˜ such that
Q
(cid:88)
τ((cid:101)h 1,1,...,(cid:101)h 1,Q,(cid:101)h 2,1,...,(cid:101)h 2,Q,...,(cid:101)h P,Q) = x˜((cid:101)h 1,q,x˜((cid:101)h 2,q...,(cid:101)h P,q)), (58)
q=1
where x˜ is a ReLU network from Lemma 5 with an error of ϵ = δ . Following the methodology in Section
3
C.2, each h
p,q
can approximated by a PIE, denoted as (cid:101)h p,q.
T
(cid:88)p,q
(cid:101)h p,q(Y p) = ψ p,q,t(φ p,q,t,1(Y p),··· ,φ
p,q,t,N
(Y p)),
p
t=0
where φ are iteratively defined using x˜ , akin to φ in (31). Similarly, ψ is defined iteratively
p,q,t,n 1 t,n p,q,t
with x˜ , as is ψ in (35). The approximation errors for x˜ and x˜ are denoted as δ and δ , respectively.
2 t 1 2 1 2
We establish that T
p,q
= O((N′)MN p) and accordingly define T = O((N′)MN).
With some calculation, we can show function g˜ is a PPIE as in Definition 5. The function class of
PPIE, denoted as F = F(S ,L ,S ,L ,S ,L ,B), encapsulates the structure of g˜. Here, S ,S ,S
τ τ ψ ψ φ φ τ ψ φ
and L ,L ,L represent the total number of parameters and the depth of the networks for τ,ψ,φ,
τ ψ φ
respectively. All the paramters in these networks are bounded by B.
Considering the definition of f , we have
n
∥f −f ∥ ≤ ∥f −f˜∥ ≤ |g(Y)−g˜(Y)|, ∀Y.
1 n ∞ 1 ∞
To establish the bound for ∥f −f ∥ , it suffices to bound |g(Y)−g˜(Y)|. This decomposition and
1 n ∞
bounding process will be carried out following the approach described in Section C.2.
Q
(cid:88)
|g˜(Y)−g(Y)| ≤ |x˜((cid:101)h 1,q(Y 1),x˜((cid:101)h 2,q(Y 2),x˜((cid:101)h 3,q(Y 3),···)))−h 1,q(Y 1)h 2,q(Y 2)···h P,q(Y P)|
q=1

Q
(cid:88)
≤  |x˜((cid:101)h 1,q(Y 1),x˜((cid:101)h 2,q(Y 2),x˜((cid:101)h 3,q(Y 3),···)))−(cid:101)h 1,q(Y 1)(cid:101)h 2,q(Y 2)···(cid:101)h P,q(Y P)|
(cid:124) (cid:123)(cid:122) (cid:125)
q=1
η
1

+|(cid:101)h 1,q(Y 1)(cid:101)h 2,q(Y 2)···(cid:101)h P,q(Y P)−h 1,q(Y 1)h 2,q(Y 2)···h P,q(Y P)| .
(cid:124) (cid:123)(cid:122) (cid:125)
η
2
FromresultsinSectionC.2,itisestablishedthatforeachpairofindicespandq,thebound∥h ∥ ≤
p,q ∞
T p,q(MN
p
+ β)(aK k′)MN p+β holds true. If we define G as T(MN + β)(aK′)MN+β, then it follows
that ∥h p,q∥
∞
≤ G for all p,q. According to (37), we note that each ∥(cid:101)h
p,q
− h p,q∥
∞
can be upper
bounded by T p,q(N(aK k′)N)MN p+β(δ
1
+δ 2), provided we disregard lower order terms. Setting δ to be
T(N(aK′)N)MN+β(δ 1+δ 2), we find that ∥(cid:101)h
p,q
−h p,q∥
∞
≤ δ for every p,q, upon neglecting lower-order
components. Consequently, ∥(cid:101)h p,q∥
∞
is bounded by G+δ.
Accordingly, the bound for η can be similarly derived, utilizing the results in (33)
1
η ≤ (G+δ)P+1δ .
1 3CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 39
To establish an upper bound for η , we consider the following inequalities
2
η
2
≤ |(cid:101)h 1(cid:101)h 2···(cid:101)h
P
−h 1h 2···h P|
≤ |(cid:101)h 1(cid:101)h 2···(cid:101)h
P
−(cid:101)h 1(cid:101)h 2···(cid:101)h P−1h P|
+|(cid:101)h 1(cid:101)h 2···(cid:101)h P−1h
P
−(cid:101)h 1(cid:101)h 2···h P−1h P|
+···
+|(cid:101)h 1h 2···h
P
−h 1h 2···h P|
≤ P(G+δ)P−1δ.
Given that δ is a relatively small error term compared to G, and considering that P is independent
of δ, we can neglect the lower order terms. Consequently, we arrive at the bounds η ≤ GPδ and
1 3
η ≤ PGPδ. To summarize
2
∥f −f ∥ ≤ |g˜(Y)−g(Y)| ≤ Q(η +η ) ≤ QPGPδ+QGPδ .
n 1 ∞ 1 2 3
Remembering that ∥f − f∗∥ can be bounded by ∥f − f∗∥ + ∥f − f ∥ , we aim to ensure
n ∞ 1 ∞ n 1 ∞
∥f −f∗∥ ≤ ϵ. To achieve this, we set ∥f −f∗∥ = ϵ and constrain ∥f −f ∥ to be at most ϵ.
n ∞ 1 ∞ 2 n 1 ∞ 2
Let ∥f −f∗∥ = ϵ, we can get N′ = O(ϵ−1/β).
1 2
To ensure ∥f −f ∥ ≤ ϵ , we set QPGPδ = QGPδ = ϵ. By setting QGPδ = ϵ
n 1 2 3 4 3 4
ϵ
(MN+β)P
δ 3 = O( ) = O(ϵ β ).
QTP(MN +β)P(aK′)P(MN+β)
Given that δ = (N(aK′)N)MN+β(δ +δ ), and aiming for QPGPδ = ϵ, we set
1 2 8
ϵ (MN2+βN)P
δ 1 = δ 2 = O( ) = O(ϵ β ).
QNMN+βTP(MN +β)K(aK′)(N+K)(MN+β)
With δ established, we can determine the network parameters for τ. Recalling that τ sums up Q
3
distinct sub-networks, each constructed iteratively with P instances of x˜, the depth and total number of
parameters of τ can be approximated as
L
τ
= PO(ln(1/δ 3)) =
O(ln(ϵ−(MN β+β)P
)),
S
τ
= QKO(ln(1/δ 3)) =
O(ln(ϵ−(MN β+β)P
)).
The network parameters for ψ and φ are derived in a similar fashion to those in Section C.2, using
δ and δ . The details are omitted for brevity.
1 2
L
ψ
= (MN +β)×O(ln(1/δ 2)) =
O(ln(ϵ−(MN2 β+Nβ)P
)),
S
ψ
= TNMN+βO(ln(1/δ 2)) = O(ϵ−M βN ),
L
φ
= NO(ln(1/δ 1)) =
O(ln(ϵ−(MN2 β+Nβ)P
)),
S
φ
= PT +TNO(ln(1/δ 1)) =
O(ϵ−M βN
).
E.2. Estimation Error
In this section, our focus is on bounding the term
n
2 (cid:88)
ξ (fˆ(x )−f(x )).
i i i
n
i=1
The primary objective here is to establish an upper limit for the covering number associated with the
PPIE function class.40 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
Adopting the approach used in Section C.3, we consider two functions from the class F, denoted as
f and f∗, with the all corresponding parameters of these functions differ by at most ζ. With this setup,
we proceed to the following decomposition
Q Q
(cid:88) (cid:88)
∥f −f∗∥
∞
= ∥ x˜((cid:101)h 1,q,x˜((cid:101)h 2,q...,(cid:101)h P,q))− x˜∗((cid:101)h∗ 1,q,x˜∗((cid:101)h∗ 2,q...,(cid:101)h∗ P,q))∥
∞
q=1 q=1
Q
(cid:88)
≤ ∥x˜((cid:101)h 1,q,x˜((cid:101)h 2,q...,(cid:101)h P,q))−x˜((cid:101)h∗ 1,q,x˜((cid:101)h∗ 2,q...,(cid:101)h∗ P,q))∥
∞
q=1
(cid:124) (cid:123)(cid:122) (cid:125)
γ
1
Q
(cid:88)
+ ∥x˜((cid:101)h∗ 1,q,x˜((cid:101)h∗ 2,q...,(cid:101)h∗ P,q))−x˜∗((cid:101)h∗ 1,q,x˜∗((cid:101)h∗ 2,q...,(cid:101)h∗ P,q))∥ ∞.
q=1
(cid:124) (cid:123)(cid:122) (cid:125)
γ
2
Building upon the insights from Section C.3, we have established that
∥(cid:101)h
p,q
−(cid:101)h∗ p,q∥
∞
≤ ζT p,q(C wB)L ψ+L φ(L
ψ
+L φ)N pMN p+βK p′
≤ ζT(C wB)L ψ+L φ(L
ψ
+L φ)NMN+βK′.
Applying a similar recursive technique as used for bounding the first term in (42), it can be shown
that
Q
(cid:88)
γ
1
≤ (C wB)L τL
τ
max ∥(cid:101)h
p,q
−(cid:101)h∗ p,q∥
∞
≤ ζQT(C wB)L τ+L ψ+L φ(L
ψ
+L φ)NMN+βK′.
1≤p≤P
q=1
Similarly, for γ , following the approach for bounding the second term in (42), we have
2
Q
(cid:88)
γ
2
≤ (C wB)L τL
τ
max ∥(cid:101)h∗ p,q∥
∞
≤ ζQT(C wB)L τ+L ψ+L φL τ(L
ψ
+L φ)NMN+βK′,
1≤p≤P
q=1
where the final inequality is derived using results from Section C.3.
In summary, a perturbation of the parameters by ζ results in a bounded change in the output
Q
(cid:88)
∥f −f∗∥
∞
≤ (C wB)L τL
τ
max ∥(cid:101)h∗ p,q∥
∞
≤ ζQT(C wB)L τ+L ψ+L φ(L
τ
+1)(L
ψ
+L φ)NMN+βK′.
1≤p≤P
q=1
Following this, we can replicate the arguments from Section C.3 to determine the upper bound for
both the covering number and the empirical Rademacher Complexity. Let L = L + L + L and
ψ φ τ
S = S +S +S .
ψ φ τ
QBT(C B)L(L +L )(L +1)NMN+βK′
w ψ φ τ
logN(ϵ,F ,∥·∥ ) ≤ Slog( ),
δ ∞
ϵ
(cid:34) (cid:35) √
E sup
|1 (cid:88)n
ξ f′(Y )| ≤
2√ 2σ Sδ log(QT(C wB)L(L
ψ
+L φ)(L
τ
+1)NMN+βK′
+1). (59)
ξ n i (i) n1/2 δ
f′∈F
δ i=1
√ √
Building upon the arguments from (47) to (51), let’s denote V = 4 2σ S. Using this notation, we
n n1/2
can express the inequality as follows
(cid:26) QT(C B)L(L +L )(L +1)NMN+βK′ (cid:27)2
∥fˆ−f∗∥2 ≤ 10∥f∗−f∥2 +8 V log( w ψ φ τ +1) +4u,
n n n V
n
with probability at least 1−exp(−nu2/2σ2δ2).CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 41
Upon taking the expectation on both sides, we derive a bound for ∥fˆ−f∗∥ similar to (53)
L (P )
2 X
∥fˆ−f∗∥2
L (P )
2 X
(cid:26) QT(C B)L(L +L )(L +1)NMN+βK′ (cid:27)2
≤ 21ϵ2+17 V log( w ψ φ τ +1) , (60)
n
V
n
with probability converging to one. Let ϵ = n− MNβ +2β. By substituting the expressions of V n, S ψ, S φ,
S , L , L , and L in terms of ϵ into equation (60) and disregarding smaller terms, we arrive at
τ ψ φ τ
∥fˆ−f∗∥2
L2(P )
= O p(n− MN2β +2β).
X
In conclusion, it’s noteworthy that the Permutation Invariant Estimator (PIE) is a specific instance
of the partially permutation invariant function, achievable by setting P = 2, N = 1, and N = N, while
1 2
adjusting the column dimension to M +1. This modification seamlessly aligns with the desired result.
F. Proof of Value-based Estimator
F.1. The cross-fitting scheme
Considerourdataset{(X ,A ,Y ) : 1 ≤ i ≤ R,1 ≤ j ≤ S}. Specifically,theS samplesarepartitioned
i,j i,j i,j
(cid:83)
intomequallysizedbatches,denotedas[S] ∈ B . Here,mischosensuchthatm ≥ 2andtypically
z∈[m] z
m ≍ 1. Eachbatch,B ,containsapproximately|B | = S ≍ S/m ≍ S samples. Foreachsampleindexed
z z z
by j ∈ [S], let z ∈ [m] be the index of the batch containing that sample, such that j ∈ B . For the j-th
j z
j
sample, the optimization process described in (8) of the main text is applied to the out-of-batch samples
B
−z
= [S]\B
z
. This procedure yields estimators f(cid:98)j and m
(cid:98)j
which for offline policy evaluation.
j j
F.2. Proof of Corollary 2
According to the definitions of J(cid:98)VB and J(π), the following holds true
S R R
1 (cid:88)(cid:88) (cid:88)
|J(cid:98)VB(π)−J(π)| = |
S
f(cid:98)i,j(X i,j,π(X i,j),m (cid:98)i(X N(i),t,π(X N(i),t)))− E[E(Y i|{A
j
= π(X j)} j,{X j} j)]|.
j=1 i=1 i=1
(cid:0) (cid:1)
To simplify, we introduce the notation x to denote X ,π(X ),m (X ,π(X )) and x for
i,j i,j i,j (cid:98)i N(i),t N(i),t i
(X ,A ,m (X ,A )). With this notation, the conditional expectation E(Y |{A = π(X )} ,{X } )
i i i N(i) N(i) i j j j j j42 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
can be rewritten as f (X ,A ,m (X ,A ) = f (x ). Thus, we have
i i i i N(i) N(i) i i
S R R
1 (cid:88)(cid:88) (cid:88)
|J(cid:98)VB(π)−J(π)| = | f(cid:98)i,j(x i,j)− E[f i(x i)]|
S
j=1 i=1 i=1
 
R S S S
(cid:88) 1 (cid:88) 1 (cid:88) 1 (cid:88) 
≤ | f(cid:98)i,j(x i,j)− E[f(cid:98)i,j(x i,j)]|+| E[f(cid:98)i,j(x i,j)]−E[f i(x i)]|
S S S
 
i=1 j=1 j=1 j=1

R m m
(cid:88) 1 (cid:88) 1 (cid:88) 1 (cid:88) 1 (cid:88)
≤ | S
z
f(cid:98)i,j(x i,j)− S
z
E[f(cid:98)i,j(x i,j)]|
S S S S
 z z
i=1 z=1 j∈B z=1 j∈B
z z

m
1 (cid:88) 1 (cid:88) 
+| S
z
E[f(cid:98)i,j(x i,j)]−E[f i(x i)]|
S S
z 
z=1 j∈B
z

R m
(cid:88)1 (cid:88) 1 (cid:88) 1 (cid:88)
≤ S z| f(cid:98)i,j(x i,j)− E[f(cid:98)i,j(x i,j)]|
S S S
 z z
i=1 z=1 j∈B j∈B
z z

m
1 (cid:88) 1 (cid:88) 
+ S z| E[f(cid:98)i,j(x i,j)]−E[f i(x i)]|
S S
z 
z=1 j∈B
z

R m
(cid:88)1 (cid:88) 1 (cid:88)
≤
S
S z|
S
z
f(cid:98)i,j(x i,j)−E[f(cid:98)
i,B
z(1)(x
i,B
z(1))]|
i=1 z=1 j∈B
z
(cid:41)
m
1 (cid:88)
+
S
S z|E[f(cid:98)
i,B
z(1)(x
i,B
z(1))]−E[f i(x i)]| . (61)
z=1
Thederivationof(61)isbasedontheobservationthatf(cid:98)i,j areequalforallj ∈ B z,∀z ∈ [m]. Additionally,
the expected value E[f(cid:98)i,j(x i,j)] remains constant for t ∈ B j. Therefore, we designate B z(1) as the initial
element in B j, leading to the conclusion that E[f(cid:98) i,B(1)(x i,B(1))] = E[f(cid:98)i,j(x i,j)] for all t ∈ B j. Concerning
z z
the term | S1
z
(cid:80)
j∈B
zf(cid:98)i,j(x i,j)−E[f(cid:98)
i,B
z(1)(x
i,B
z(1))]|, Theorem 4.10 in (Wainwright, 2019) is applied, yielding
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)S1
z
(cid:88) f(cid:98)i,j(x i,j)−Ef(cid:98) i,B z(1)(x i,B z(1))(cid:12) (cid:12) (cid:12) ≤ s fu ∈p G(cid:12) (cid:12) (cid:12)S1
z
(cid:88) f(x i,j)−Ef(x i,B z(1))(cid:12) (cid:12) (cid:12) ≤ E XR S zG +e,
j∈B j∈B
z z
with probability at least 1−exp(−S ze2). Subsequently, Lemma 2 is utilized to establish an upper bound
8J2
for R (G)
S
z √
4 2 (cid:90) J (cid:112)
R G ≤ log2N(ϵ,G,∥·∥ )dϵ.
S ∞
z S
z 0
Building upon the arguments presented in E.2, we establish a bound for the covering number of G.
For simplicity, we omit these details. Considering x ∈ R(M+1)×(N+1) and recognizing that S − S
i,j z
samples are utilized to construct fˆ , the Rademacher complexity R (G) can be upper bounded as
i,j S
z
(M+1)(N+1) −1/2
O((S −S z)2((M+1)(N+1)+2β)S
z
).
Next, combining this with the bound for ∥f(cid:98)i−f i∗∥
L2(P
X), we derive
(cid:40) (cid:41)
R m m
|J(cid:98)VB(π)−J(π)| ≤ (cid:88) S1 (cid:88) S zC j(S −S z)2((M(M ++ 1)1 () N(N ++ 1)1 +) 2β)S z−1/2+ S1 (cid:88) S zC j′(S −S z)− (M+1)(Nβ +1)+2β +e
i=1 z=1 z=1
≤
C˜RS− (M+1)(Nβ
+1)+2β +e =
O(RS− (M+1)(Nβ
+1)+2β)+e,
with probability at least 1−exp(−Se2). The second inequality is predicated on the assumption that
8J2
S ≍ S/m ≍ S.
zCausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 43
F.3. Proof of Corollary 3
Inthissection,ourobjectiveistoestablishtheconvergencerateforthevalue-basedestimatorindynamic
setting. We commence by broadening the scope of the transition kernel Pπ, as defined in Section 4.3.
Pπr(X,A) = E(cid:2) r(X′,A′)|X′ ∼ P(·|X,A),A′ ∼ π(X′)(cid:3) .
As deduced from (15), the value-based estimator J(cid:98)VB(π) is intrinsically linked to Q(cid:98)(i,1). Our initial
γ
(i,1) (i,1)
endeavor is to establish an upper bound for ∥Q
i
(X N∗(i),1,A N∗(i),1)−Q(cid:98)π (X N∗(i),1,A N∗(i),1)∥
L2(p
i),
with p denoting the stationary distribution of the confounder-action pair (X ,A ) under the
i N∗(i),t N∗(i),t
(i,1) (i,1)
given behavioural policy. For the sake of brevity, we will hereafter refer to these as Q
i
and Q(cid:98)π ,
omitting the explicit mention of X and A.
(1)
Based on the established definition of Q in (11), it follows that
π
i
(cid:104) (cid:105)
Q(cid:98)( πi,1)−Q( ii,1) = Q(cid:98)( πi,1)− r i+γPπQ( π1 i) +γPπQ(cid:98)( πi,1)−γPπQ(cid:98)( πi,1)
= Q(cid:98)( πi,1)−r i−γPπQ(cid:98)( πi,1)+γPπ[Q(cid:98)( πi,1)−Q( ii,1) ].
(cid:16) (cid:17)2
Defining the square error of one-step approximation as ζ
i(t)
=
Q(cid:98)( πi,T)
−r
i−γPπQ(cid:98)( πi,T)
, we obtain
(cid:16) (cid:17)2 (cid:104) (cid:105)2
Q(cid:98)(i,1)−Q(i,1) = ζ(1) +γ2 Pπ(Q(cid:98)(i,1)−Q(i,1) )
π i i π i
≤ ζ(1) +γ2Pπ(Q(cid:98)(i,1)−Q(i,1) )2.
i π i
where the second inequality holds since the expectation of a squared random variable exceeds the square
of its expectation . In a similar vein, we deduce that
(cid:16) (cid:17)2
Pπ Q(cid:98)(i,1)−Q(i,1) ≤ Pπζ(2) +γ2PπPπ(Q(cid:98)(i,1)−Q(i,1) )2,
π i i π i
leading to the conclusion that
(cid:16) (cid:17)2
Q(cid:98)(i,1)−Q(i,1) ≤ ζ(1) +γ2Pπζ(2) +γ4PπPπ(Q(cid:98)(i,1)−Q(i,1) )2.
π i i i π i
Utilizing the established recurrence relation, we derive that
T
(cid:16) Q(cid:98)(i,1)−Q(i,1)(cid:17)2 ≤ (cid:88) γ2t−2(Pπ)t−1ζ(t) +γ2T(Pπ)⊤(Q(cid:98)(i,1)−Q(i,1) )2.
π i i π i
t=1
Taking expectation s on both sides with respect to p , we obtain
i
T
∥Q( ii,1) −Q(cid:98)( πi,1)∥
L2(p i)
≤ (cid:88) E
p
i(cid:104) γ2t−2(Pπ)t−1ζ i(t)(cid:105) +γ2TE
p
i(cid:104) (Pπ)⊤(Q(cid:98)( πi,1)−Q( ii,1) )2(cid:105) . (62)
t=1
Considering any measurable function f over time step t, we have
(cid:90) (cid:90)
E (cid:2) (Pπ)tf(cid:3) = (Pπ)tfdp = fdp = E [f].
p i,1 π,t p
i π,t
Applying the Cauchy-Schwarz inequality leads to
(cid:115) (cid:115)
(cid:90) (cid:12)dp (cid:12) (cid:90)
E (f) ≤ (cid:12) π,t(cid:12)dp · fdp .
p π,t (cid:12) dp (cid:12) i i
i
From Assumption 12, it follows that
E (f) ≤ κ(t)·E (f) ≤ κE (f).
p p p
π,t i i
Incorporating this into (62), we deduce
T
∥Q( π1)−Q(cid:98)( πi,1)∥
L2(p i)
≤
κ(cid:88)
γ2t−2E
p
i(cid:104)
ζ
i(t)(cid:105)
+κγ2TE
p
i(Q(cid:98)( πi,T)−Y i)2. (63)
t=144 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
From Assumption 11, for all t both r
i
+γPπQ(cid:98)( πi,t)
and r
i
are permutation invariant and belongs to
(cid:104) (cid:105)
Wβ,∞([0,J](N+1)(M+1)). Using the results in Corollary (1), it is evident that for each t, E ζ(t) and
p i i
E
p
(Q(cid:98)π(i,T) −Y i)2 are bounded above by O(S− (N+1)(M2β +1)+2β) with probability converging to one. Bring
i
back to (63), we have
∥Q( p1 i,)
1
−Q(cid:98)( πi,1)∥
L2(p i)
≤ κTγ2TO(S− (N+1)(Mβ +1)+2β) ≤ O(κTS− (N+1)(Mβ +1)+2β).
Employing empirical process techniques akin to those in Section F, we can establish that
|J γ(π)−J(cid:98) γVB(π)| ≤ O(RS− (N+1)(Mβ +1)+2β)+O(κTRS− (N+1)(Mβ +1)+2β)+e = O(κTRS− ((N+1)(Mβ +1)+2β))+e,
with probability at least 1−exp(−Se2).
8J2CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 45
References
Agarwal, A., Jiang, N., Kakade, S. M. and Sun, W. (2019) Reinforcement learning: Theory and algo-
rithms. CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep, 32.
Aittala, M. and Durand, F. (2018) Burst image deblurring using permutation invariant convolutional
neural networks. In Proceedings of the European Conference on Computer Vision (ECCV), 731–747.
Angrist, J. D., Imbens, G. W. and Rubin, D. B. (1996) Identification of causal effects using instrumental
variables. Journal of the American statistical Association, 91, 444–455.
Aronow, P. and Samii, C. (2017) Estimating average causal effects under general interference, with
application to a social network experiment.
Athey, S. and Wager, S. (2021) Policy learning with observational data. Econometrica, 89, 133–161.
Banerjee, S., Carlin, B. P. and Gelfand, A. E. (2003) Hierarchical Modeling and Analysis for Spatial
Data. Chapman and Hall/CRC.
Bennett, A. and Kallus, N. (2023) Proximal reinforcement learning: Efficient off-policy evaluation in
partially observed markov decision processes. Operations Research.
Benton, G., Finzi, M., Izmailov, P. and Wilson, A. G. (2020) Learning invariances in neural networks
from training data. Advances in neural information processing systems, 33, 17605–17616.
Blume, L. E. (1993) The statistical mechanics of strategic interaction. Games and Economic Behavior,
5, 387–424.
Bojinov, I., Simchi-Levi, D. and Zhao, J. (2023) Design and analysis of switchback experiments. Man-
agement Science, 69, 3759–3777.
Bronstein, M. M., Bruna, J., LeCun, Y., Szlam, A. and Vandergheynst, P. (2017) Geometric deep
learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34, 18–42.
Bruns-Smith, D. and Zhou, A. (2023) Robust fitted-q-evaluation and iteration under sequentially exoge-
nous unobserved confounders. arXiv preprint arXiv:2302.00662.
Chen, B. and Hong, Y. (2012) Testing for the markov property in time series. Econometric Theory, 28,
130–178.
Chen, J. and Jiang, N. (2019) Information-theoretic considerations in batch reinforcement learning. In
International Conference on Machine Learning, 1042–1051. PMLR.
Chen, X. and Qi, Z. (2022) On well-posedness and minimax optimal rates of nonparametric q-function
estimation in off-policy evaluation. In International Conference on Machine Learning, 3558–3582.
PMLR.
Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W. and Robins, J.
(2018) Double/debiased machine learning for treatment and structural parameters.
Cohen-Karlik, E., Ben David, A. and Globerson, A. (2020) Regularizing towards permutation invariance
in recurrent models. Advances in Neural Information Processing Systems, 33, 18364–18374.
Dud´ık, M., Erhan, D., Langford, J. and Li, L. (2014) Doubly robust policy evaluation and optimization.
Fan, J., Wang, Z., Xie, Y. and Yang, Z. (2020) A theoretical analysis of deep q-learning. In Learning
for Dynamics and Control, 486–489. PMLR.
Farrell, M. H., Liang, T. and Misra, S. (2021) Deep neural networks for estimation and inference.
Econometrica, 89, 181–213.
Forastiere, L., Airoldi, E. M. and Mealli, F. (2021) Identification and estimation of treatment and inter-
ference effects in observational studies on networks. Journal of the American Statistical Association,
116, 901–918.
Fu, Z., Qi, Z., Wang, Z., Yang, Z., Xu, Y. and Kosorok, M. R. (2022) Offline reinforcement learning with
instrumental variables in confounded markov decision processes. arXiv preprint arXiv:2209.08666.
Geng, X., Li, Y., Wang, L., Zhang, L., Yang, Q., Ye, J. and Liu, Y. (2019) Spatiotemporal multi-graph
convolution network for ride-hailing demand forecasting. In Proceedings of the AAAI conference on
artificial intelligence, vol. 33, 3656–3663.
Giffin, A., Reich, B. J., Yang, S. and Rappold, A. G. (2021) Instrumental variables, spatial confounding
and interference. arXiv preprint arXiv:2103.00304.
Gin´e, E. and Nickl, R. (2021) Mathematical foundations of infinite-dimensional statistical models. Cam-
bridge university press.
Gottesman, O., Liu, Y., Sussex, S., Brunskill, E. and Doshi-Velez, F. (2019) Combining parametric and
nonparametric models for off-policy evaluation. In International Conference on Machine Learning,
2366–2375. PMLR.
Gui, S., Zhang, X., Zhong, P., Qiu, S., Wu, M., Ye, J., Wang, Z. and Liu, J. (2021) Pine: Universal46 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
deep embedding for graph nodes via partial permutation invariant set functions. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 44, 770–782.
Hahn, R. and Metcalfe, R. (2017) The ridesharing revolution: Economic survey and synthesis. More
equal by design: economic design responses to inequality, 4.
Hao, B., Ji, X., Duan, Y., Lu, H., Szepesvari, C. and Wang, M. (2021) Bootstrapping fitted q-evaluation
for off-policy inference. In International Conference on Machine Learning, 4074–4084. PMLR.
Hu, Y. and Wager, S. (2022) Switchback experiments under geometric mixing. arXiv preprint
arXiv:2209.00197.
— (2023) Off-policy evaluation in partially observed markov decision processes under sequential ignora-
bility. The Annals of Statistics, 51, 1561–1585.
Hudgens, M. G. and Halloran, M. E. (2008) Toward causal inference with interference. Journal of the
American Statistical Association, 103, 832–842.
Imaizumi, M. and Fukumizu, K. (2019) Deep neural networks learn non-smooth functions effectively. In
The 22nd International Conference on Artificial Intelligence and Statistics, 869–878. PMLR.
Jarner, M. F., Diggle, P. and Chetwynd, A. G. (2002) Estimation of spatial variation in risk using
matched case-control data. Biometrical Journal: Journal of Mathematical Methods in Biosciences,
44, 936–945.
Jiang, N. and Li, L. (2016) Doubly robust off-policy value evaluation for reinforcement learning. In
International Conference on Machine Learning, 652–661. PMLR.
Johari, R., Li, H., Liskovich, I.andWeintraub, G.Y.(2022)Experimentaldesignintwo-sidedplatforms:
An analysis of bias. Management Science, 68, 7069–7089.
Kallus, N. and Uehara, M. (2022) Efficiently breaking the curse of horizon in off-policy evaluation with
double reinforcement learning. Operations Research, 70, 3282–3302.
Kallus, N. and Zhou, A. (2020) Confounding-robust policy evaluation in infinite-horizon reinforcement
learning. Advances in neural information processing systems, 33, 22293–22304.
Keller, J. P. and Szpiro, A. A. (2020) Selecting a scale for spatial confounding adjustment. Journal of
the Royal Statistical Society Series A: Statistics in Society, 183, 1121–1143.
Kim, I., Neykov, M., Balakrishnan, S. and Wasserman, L. (2022) Local permutation tests for conditional
independence. The Annals of Statistics, 50, 3388–3414.
Kong, X., Yuan, M. and Zheng, W. (2021) Approximate and exact designs for total effects. The Annals
of Statistics, 49, 1594–1625.
Le, H., Voloshin, C. and Yue, Y. (2019) Batch policy learning under constraints. In International
Conference on Machine Learning, 3703–3712. PMLR.
Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S. and Teh, Y. W. (2019) Set transformer: A framework
for attention-based permutation-invariant neural networks. In International conference on machine
learning, 3744–3753. PMLR.
Lee,L.-F.(2007)Identificationandestimationofeconometricmodelswithgroupinteractions,contextual
factors and fixed effects. Journal of Econometrics, 140, 333–374.
Leung, M. P. (2022) Rate-optimal cluster-randomized designs for spatial interference. The Annals of
Statistics, 50, 3064–3087.
Levine, S., Kumar, A., Tucker, G. and Fu, J. (2020) Offline reinforcement learning: Tutorial, review,
and perspectives on open problems. arXiv preprint arXiv:2005.01643.
Li, S. and Wager, S. (2022) Random graph asymptotics for treatment effect estimation under network
interference. Annals of Statistics, 50, 2334–2358.
Li, T., Shi, C., Wang, J., Zhou, F. and Zhu, H. (2023a) Optimal treatment allocation for efficient
policy evaluation in sequential decision making. In Thirty-seventh Conference on Neural Information
Processing Systems.
Li, W., Luo, H., Lin, Z., Zhang, C., Lu, Z. and Ye, D. (2023b) A survey on transformers in reinforcement
learning. arXiv preprint arXiv:2301.03044.
Li, X., Ding, P., Lin, Q., Yang, D.andLiu, J.S.(2019)Randomizationinferenceforpeereffects. Journal
of the American Statistical Association, 114, 1651–1664.
Liao, P., Klasnja, P. and Murphy, S. (2021) Off-policy estimation of long-term average outcomes with
applications to mobile health. Journal of the American Statistical Association, 116, 382–391.
Liao, P., Qi, Z., Wan, R., Klasnja, P. and Murphy, S. A. (2022) Batch policy learning in average reward
markov decision processes. Annals of statistics, 50, 3364.
Liu, Q., Li, L., Tang, Z. and Zhou, D. (2018) Breaking the curse of horizon: Infinite-horizon off-policy
estimation. Advances in Neural Information Processing Systems, 31.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 47
Luckett,D.J.,Laber,E.B.,Kahkoska,A.R.,Maahs,D.M.,Mayer-Davis,E.andKosorok,M.R.(2020)
Estimating dynamic treatment regimes in mobile health using v-learning. Journal of the American
Statistical Association, 115, 692.
Luedtke, A. R. and Van Der Laan, M. J. (2016) Statistical inference for the mean outcome under a
possibly non-unique optimal treatment strategy. Annals of statistics, 44, 713.
Luo, S., Yang, Y., Shi, C., Yao, F., Ye, J. and Zhu, H. (2024) Policy evaluation for temporal and/or
spatial dependent experiments. Journal of the Royal Statistical Society Series B, in press.
Munro, E., Wager, S. and Xu, K. (2021) Treatment effects in market equilibrium. arXiv preprint
arXiv:2109.11647.
Ntampaka, M., Trac, H., Sutherland, D. J., Fromenteau, S., P´oczos, B. and Schneider, J. (2016) Dynam-
ical mass measurements of contaminated galaxy clusters using machine learning. The Astrophysical
Journal, 831, 135.
Papadogeorgou, G., Choirat, C. and Zigler, C. M. (2019) Adjusting for unmeasured spatial confounding
with distance adjusted propensity score matching. Biostatistics, 20, 256–272.
Perez-Heydrich, C., Hudgens, M. G., Halloran, M. E., Clemens, J. D., Ali, M. and Emch, M. E. (2014)
Assessing effects of cholera vaccination in the presence of interference. Biometrics, 70, 731–741.
Polo, F. M., Sun, Y. and Banerjee, M. (2023) Conditional independence testing under misspecified
inductive biases. In Thirty-seventh Conference on Neural Information Processing Systems.
Puelz, D., Basse, G., Feller, A. and Toulis, P. (2022) A graph-theoretic approach to randomization tests
of causal effects under general interference. Journal of the Royal Statistical Society Series B, 84,
174–204.
Puterman, M. L. (2014) Markov decision processes: discrete stochastic dynamic programming. John
Wiley & Sons.
Qin, Z. T., Zhu, H. and Ye, J. (2022) Reinforcement learning for ridesharing: An extended survey.
Transportation Research Part C: Emerging Technologies, 144, 103852.
Reich, B. J., Yang, S., Guan, Y., Giffin, A. B., Miller, M. J. and Rappold, A. (2021) A review of spatial
causal inference methods for environmental and epidemiological applications. International Statistical
Review, 89, 605–634.
Schmidt-Hieber, J. (2020) Nonparametric regression using deep neural networks with relu activation
function.
Shah, R. D. and Peters, J. (2020) The hardness of conditional independence testing and the generalised
covariance measure. The Annals of Statistics, 48, 1514–1538.
Shi, C., Uehara, M., Huang, J. and Jiang, N. (2022a) A minimax learning approach to off-policy eval-
uation in confounded partially observable markov decision processes. In International Conference on
Machine Learning, 20057–20094. PMLR.
Shi, C., Wan, R., Song, G., Luo, S., Zhu, H. and Song, R. (2023) A multiagent reinforcement learning
framework for off-policy evaluation in two-sided markets. The Annals of Applied Statistics, 17, 2701–
2722.
Shi, C., Wan, R., Song, R., Lu, W. and Leng, L. (2020) Does the markov decision process fit the
data: Testing for the markov property in sequential decision making. In International Conference on
Machine Learning, 8807–8817. PMLR.
Shi, C., Zhang, S., Lu, W. and Song, R. (2022b) Statistical inference of the value function for reinforce-
ment learning in infinite-horizon settings. Journal of the Royal Statistical Society Series B: Statistical
Methodology, 84, 765–793.
Shi, C., Zhu, J., Ye, S., Luo, S., Zhu, H. and Song, R. (2022c) Off-policy confidence interval estimation
with confounded markov decision process. Journal of the American Statistical Association, accepted.
Sobel, M. E. (2006) What do randomized studies of housing mobility demonstrate? causal inference in
the face of interference. Journal of the American Statistical Association, 101, 1398–1407.
Sutton, R. S. and Barto, A. G. (2018) Reinforcement Learning: An Introduction. MIT press.
Tang, X., Qin, Z., Zhang, F., Wang, Z., Xu, Z., Ma, Y., Zhu, H. and Ye, J. (2019a) A deep value-
network based approach for multi-driver order dispatching. In Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining, 1780–1790.
Tang, Z., Feng, Y., Li, L., Zhou, D. and Liu, Q. (2019b) Doubly robust bias reduction in infinite horizon
off-policy estimation. In International Conference on Learning Representations.
Tchetgen, E. J. T. and VanderWeele, T. J. (2012) On causal inference in the presence of interference.
Statistical Methods in Medical Research, 21, 55–75.
Tchetgen Tchetgen, E. J., Fulcher, I. R. and Shpitser, I. (2021) Auto-g-computation of causal effects on48 RunpengDaia,b∗,JianingWanga∗∗,FanZhoua∗∗
a network. Journal of the American Statistical Association, 116, 833–844.
Tennenholtz, G., Shalit, U. and Mannor, S. (2020) Off-policy evaluation in partially observable environ-
ments. In Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, 10276–10283.
Thaden, H. and Kneib, T. (2018) Structural equation models for dealing with spatial confounding. The
American Statistician, 72, 239–252.
Thams, N., Saengkyongam, S., Pfister, N. and Peters, J. (2023) Statistical testing under distributional
shifts. Journal of the Royal Statistical Society Series B: Statistical Methodology, accepted.
Thomas,P.andBrunskill,E.(2016)Data-efficientoff-policypolicyevaluationforreinforcementlearning.
In International Conference on Machine Learning, 2139–2148. PMLR.
Thomas, P., Theocharous, G. and Ghavamzadeh, M. (2015) High-confidence off-policy evaluation. In
Proceedings of the AAAI Conference on Artificial Intelligence, vol. 29.
Uehara, M., Huang, J. and Jiang, N. (2020) Minimax weight and q-function learning for off-policy
evaluation. In International Conference on Machine Learning, 9659–9668. PMLR.
Uehara, M., Shi, C. and Kallus, N. (2022) A review of off-policy evaluation in reinforcement learning.
arXiv preprint arXiv:2212.06355.
Ugander, J., Karrer, B., Backstrom, L. and Kleinberg, J. (2013) Graph cluster randomization: Network
exposure to multiple universes. In Proceedings of the 19th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, 329–337.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L(cid:32) . and Polosukhin,
I. (2017) Attention is all you need. Advances in neural information processing systems, 30.
Verbitsky-Savitz, N. and Raudenbush, S. W. (2012) Causal inference under interference in spatial set-
tings: a case study evaluating community policing program in chicago. Epidemiologic Methods, 1,
107–130.
Wager, S. and Xu, K. (2021) Experimenting in equilibrium. Management Science, 67, 6694–6715.
Wainwright, M. J. (2019) High-dimensional Statistics: A Non-asymptotic Viewpoint, vol. 48. Cambridge
university press.
Wang, H. and Yang, H. (2019) Ridesourcing systems: A framework and review. Transportation Research
Part B: Methodological, 129, 122–155.
Wang,J.,Qi,Z.andWong,R.K.(2023)Projectedstate-actionbalancingweightsforofflinereinforcement
learning. The Annals of Statistics, 51, 1639–1665.
Wang, Y., Samii, C., Chang, H. and Aronow, P. (2020) Design-based inference for spatial experiments
with interference. arXiv preprint arXiv:2010.13599.
Wang, Y., Yin, H., Chen, H., Wo, T., Xu, J. and Zheng, K. (2019) Origin-destination matrix prediction
via graph convolution: a new perspective of passenger demand modeling. In Proceedings of the 25th
ACM SIGKDD international conference on knowledge discovery & data mining, 1227–1235.
Xie, T. and Jiang, N. (2020) Q* approximation schemes for batch reinforcement learning: A theoretical
comparison. In Conference on Uncertainty in Artificial Intelligence, 550–559. PMLR.
— (2021) Batch value-function approximation with only realizability. In International Conference on
Machine Learning, 11404–11413. PMLR.
Xiong, R., Chin, A. and Taylor, S. (2023) Data-driven switchback designs: Theoretical tradeoffs and
empirical calibration. SSRN Electronic Journal.
Xu, Y., Zhu, J., Shi, C., Luo, S. and Song, R. (2023) An instrumental variable approach to confounded
off-policy evaluation. In International Conference on Machine Learning, 38848–38880. PMLR.
Xu, Z., Li, Z., Guan, Q., Zhang, D., Li, Q., Nan, J., Liu, C., Bian, W.andYe, J.(2018)Large-scaleorder
dispatch in on-demand ride-hailing platforms: A learning and planning approach. In Proceedings of
the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, 905–913.
Yang, Y. and Barron, A. (1999) Information-theoretic determination of minimax rates of convergence.
Annals of Statistics, 1564–1599.
Yang,Y.,Luo,R.,Li,M.,Zhou,M.,Zhang,W.andWang,J.(2018)Meanfieldmulti-agentreinforcement
learning. In International Conference on Machine Learning, 5571–5580. PMLR.
Yang, Y. and Tokdar, S. T. (2015) Minimax-optimal nonparametric regression in high dimensions.
Yarotsky, D. (2017) Error bounds for approximations with deep relu networks. Neural Networks, 94,
103–114.
Yin, M. and Wang, Y.-X. (2020) Asymptotically efficient off-policy evaluation for tabular reinforcement
learning. In International Conference on Artificial Intelligence and Statistics, 3948–3958. PMLR.
Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R. and Smola, A. J. (2017) Deep
sets. Advances in Neural Information Processing Systems, 30.CausalDeepsetsforOff-policyEvaluationunderSpatialorSpatio-temporalInterferences 49
Zhang, B., Tsiatis, A. A., Laber, E. B. and Davidian, M. (2012) A robust method for estimating optimal
treatment regimes. Biometrics, 68, 1010–1018.
Zhao, H., Jiang, L., Jia, J., Torr, P. H. and Koltun, V. (2021) Point transformer. In Proceedings of the
IEEE/CVF international conference on computer vision, 16259–16268.
Zhou, F., Luo, S., Qie, X., Ye, J. and Zhu, H. (2021a) Graph-based equilibrium metrics for dynamic
supply–demand systems with applications to ride-sourcing platforms. Journal of the American Statis-
tical Association, 116, 1688–1699.
Zhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H. and Zhang, W. (2021b) Informer: Beyond
efficient transformer for long sequence time-series forecasting. In Proceedings of the AAAI conference
on artificial intelligence, vol. 35, 11106–11115.
Zigler, C.M., Dominici, F.andWang, Y.(2012)Estimatingcausaleffectsofairqualityregulationsusing
principal stratification for spatially correlated multivariate intermediate outcomes. Biostatistics, 13,
289–302.