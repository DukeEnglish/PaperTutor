Fast convergence of the Expectation Maximization algorithm
under a logarithmic Sobolev inequality
Rocco Caprio and Adam M. Johansen
Department of Statistics, University of Warwick.
Email: rocco.caprio, a.m.johansen @warwick.ac.uk.
{ }
July 26, 2024
Abstract
By utilizing recently developedtools for constructing gradientflowson Wasserstein
spaces,weextendananalysistechniquecommonlyemployedtounderstandalternating
minimization algorithms on Euclidean space to the Expectation Maximization (EM)
algorithm via its representation as coordinate-wise minimization on the product of a
EuclideanspaceandaspaceofprobabilitydistributionsduetoNealandHinton(1998).
In so doing we obtain finite sample error bounds and exponential convergence of the
EM algorithm under a natural generalisation of a log-Sobolev inequality. We further
demonstratethattheanalysistechniqueissufficientlyflexibletoallowalsotheanalysis
of several variants of the EM algorithm.
Keywords: EM algorithm, first-order EM algorithm, maximum likelihood estimator,
empiricalBayes,latentvariablemodels,non-asymptoticbounds,functionalinequalities,
log-Sobolev inequality, Wasserstein gradient.
1 Introduction
TheExpectation Maximization (EM) algorithm has been a central partof the statistician’s
toolbox since being formalised by [22] as an effective general computational solution to the
marginal maximum likelihood problem. At that time the algorithm had been proposed
previously in numerous special contexts, including that of empirical Bayes [27]. Empirical
Bayes methods have received considerable attention in the modern machine learning liter-
ature, where they are widely used to specify hyper-parameters in high-dimensional models.
In recent years there has been a great deal of interest within the Bayesian statistics and
machine learning communities in the construction of gradient flows, especially Wasserstein
gradient flows, which underlie Langevin Monte Carlo algorithms. Some recent work has
focussed on the intersection of empirical Bayes type methods and gradient flow-based algo-
rithms. Our aim is to demonstrate here that some of the tools, particularly those emerging
from optimal transport and Wasserstein geometry, which have been developed in the con-
text of these modern computational methods provide a natural approach to the analysis
of the EM algorithm itself—and many of its approximations. Such analysis is quite direct,
requires limited further technical work and yields state-of-the-art conclusions under con-
ditions which are, if anything, weaker than those ordinarily employed in the quantitative
analysis of EM algorithms.
1
4202
luJ
52
]LM.tats[
1v94971.7042:viXraIn this paperwe utilize the connection between EM and acoordinate-wise minimization
algorithm applied to the free energy functional identified by [43] to provide non-asymptotic
error bounds for EM algorithms under an extended form of the log-Sobolev inequality. To
dothis,weextendanargumentcommonlyusedtounderstandEuclideancoordinatedescent
algorithms by comparison with gradient descent via the descent lemma [9, 8, 10], together
with recently developed results for using and understanding gradients on the product of
Euclidean and Wasserstein spaces [13].
1.1 The Expectation Maximization Algorithm
Considertheproblemoffittingaprobabilisticmodel,withLebesguedensityp (x,y),featur-
θ
ing latent variables, x Rdx, to data, y, which have been observed. Within the maximum
∈
likelihood framework one seeks model parameters, θ Rdθ, that maximize the (marginal)
∈
likelihood —theprobability density, p (y), ofobservingtheobtained datauponintegrating
θ
out the latent variables: that is, θ belonging to
⋆
:= argmaxp (y) = argmax p (x,y)dx. (1)
⋆ θ θ
O θ∈Rdθ θ∈Rdθ
Z
One can also characterize the conditional distribution of the latent variables given the
observed data under the model specified by parameter vector θ as:
⋆
p (x,y)
p (x y) := θ⋆ ,
θ⋆
| p (y)
θ⋆
and due to the Bayesian flavour of this computation and the connection with empirical
Bayes [49] we will term this the posterior distribution of x throughout. For most models
of practical interest, the integral in (1) is intractable, we have no closed-form expressions
for p (y) or its derivatives, and we are unable to directly optimize p (y). The most popular
θ θ
algorithm to solve this problem is the Expectation Maximization (EM) algorithm.
Notation. As the data y can be treated as fixed, in the description of the algorithm
below and in the remainder we shorten our notation and write ρ (x) for p (x,y), Z for its
θ θ θ
normalizing constant p (y), π (x) = ρ (x)/Z for p (x y), and additionally ℓ(θ;x) for the
θ θ θ θ θ
|
(complete) log-likelihood log(ρ (x)). When dealing with measures absolutely continuous
θ
with respect to the Lebesgue measure we use the same symbol to refer to both the measure
and its Lebesgue density. A summary of this and other relevant notation can be found in
Appendix A.
Algorithm 1 EM Algorithm
1: Inputs: Initial values (θ ,q ).
0 0
2: for k 0 do
≥
3: (M-step) Update the parameter estimate:
θ = argmax ℓ(θ;x)q (dx). (2)
k+1 k
θ
Z
4: (E-step) Update the posterior estimate:
q = π . (3)
k+1 θk+1
5: end for
2In Algorithm 1, we perform the M-step first, hence the initial value θ is not used. In
0
some cases, it might be more convenient to perform the E-step first by specifying an initial
guess θ and then setting q := π . Our results apply to both cases.
0 0 θ0
Related literature. The importance of EM in statistics, machine learning and science
morebroadly, means thatitsconvergence propertieshave beenextensively studied. Beyond
the characterization provided by [22], early analysis was provided by [12, 58]. These and
other works [30, 40, 39] focus on asymptotic convergence rates. However, relatively little
is known about the non-asymptotic performance. [33, 34] leverage interesting connections
betweentheEMalgorithm,generalizedsurrogateoptimization methodsandmirrordescent,
respectively,tostudythisproblem. Inparticular,[33]showsglobalsub-exponentialratesfor
the parameter estimates under the hypothesis of strong concavity of the surrogate function
θ Q(θ θ′) = ℓ(θ;x)π θ′(dx). (4)
7→ |
Z
for all θ′ Rdθ. [34] obtains global sub-exponential rates for the posterior estimates when
∈
(ρ θ(dx)) θ∈Rdθ forms a minimal exponential family, which implies that the surrogate is con-
cave. [7] studies the related but different problem of deriving convergence rates to the true
population parameter, and not the MLE, in the case of an infinite sample (‘population
EM’) and of a finite sample (‘sample EM’), by also considering an assumption of strong
concavity of the surrogate and provided one starts the algorithm in some neighbourhood
of the optimum. Other lines of work have focused on more specific models or situations,
such as Gaussian mixtures [59, 29, 56], the case of misspecified models [24], or stochastic
EM methods [32].
1.2 A differential analysis of the EM Algorithm
In this work, we take a somewhat different approach to earlier literature and we connect
EM’sexponentialconvergence withtheconcepts ofgradients inthespaceofprobabilitydis-
tributions,appropriatelog-Sobolev inequalities, andotherresultsandtechniquesinoptimal
transport and sampling. Let (Rdx) denote the space of the Borel probability measures on
P
theEuclideanspaceRdx. We startfromthefollowing keyobservation, dueto[43], thatcon-
nects the EM algorithm to an alternating minimization procedure on := Rdθ (Rdx).
M ×P
Proposition 1. The steps of the EM iteration, (2) and (3), are, respectively, equivalent to
θ argminF(θ,q ), (2’)
k+1 k
∈ θ∈Rdθ
q argminF(θ ,q), (3’)
k+1 k+1
∈ q∈P(Rdx)
where F : Rdθ (Rdx) R is the free energy functional:
×P →
q(x)
log q(dx) if q ρ (dx)
F(θ,q) := 
Z
(cid:18)ρ θ(x)
(cid:19)
≪ θ ∀(θ,q) ∈M. (5)
 + otherwise

∞
For reasons that will b ecome clear later, we focus our attention on := Rdθ (Rdx),
2 2
M ×P
where (Rdx)istherestriction of (Rdx)toelements whichareabsolutely continuouswith
2
P P
3respecttoLebesguemeasureandadmitfinitesecond moments. SinceEMis aminimization
procedureonF, itiskey totheanalysis tounderstandF’svariations alongtheEMiterates.
Proposition 1 shows that the free energy can only decrease along the EM iterations:
F(θ ,q ) F(θ ,q ) F(θ ,q ) F(θ ,q ) F(θ ,q ) F(θ ,q ),
0 0 1 0 1 1 k k k+1 k k+1 k+1
≥ ≥ ≥ ··· ≥ ≥ ≥
and to characterize EM’s exponential convergence, we would like to quantify this decrease.
The alternating minimization representation of EM suggests we might be able to adapt
the analysis of alternating minimization algorithms on Euclidean space [9, 8, 10]. When
minimizing a smooth function f : Rdx R satisfying a gradient growth condition
→
2λ[f(x) f ] f(x) 2 x Rdx, where λ > 0 and f := inff
⋆ x ⋆
− ≤ ∇ ∀ ∈
knownasPolyak–L ojas(cid:13)iewiczine(cid:13)quality(PL I),thisanalysiscanbeconductedbycomparing
(cid:13) (cid:13)
thealternatingminimizationupdateswithappropriategradientsteps. Sincethefreeenergy
isafunctionon ,itisnotimmediatelyclearhowtotranslatethisapproachtooursetting.
2
M
However, recent advances in optimal transport provide natural solutions to this problem.
In particular, we show that under a smoothness assumption, we can lower bound EM’s
free energy decrease abstractly in terms of the norm of grad F, F’s gradient in the
M2
geometryinducedbytheproductoftheEuclideanandWassersteinmetricson . Because
2
M
the posterior updates is on the space of probability measures, the notion of a gradient step
with which to compare the EM step relates to the concepts of Wasserstein gradient flows.
Having lower-bounded the decrease in free energy in in terms of grad F via smoothness,
M2
we assume that grad F’s norm grows at least quadratically away from F’s minimizers
M2
along EM iterations, a natural analogue of the PL I on . More precisely:
2
M
2
2λ[F(θ,q) F ] grad F(θ,q) (6)
− ⋆ ≤ M2 M2
for all relevant EM iterates (θ,q), where λ >(cid:13)0 is a positive c(cid:13)onstant and where
(cid:13) (cid:13)
F := inf F(θ,q)= inf F(θ,π )= log sup Z =: logZ .
⋆ θ θ ⋆
(θ,q)∈M2 θ∈Rdθ − (cid:18)θ∈Rdθ
(cid:19)
−
Inequality (6) is a generalization of the log-Sobolev and Polyak–L ojasiewicz inequalities
(LSI and PL I, respectively) of optimal transport and optimization, and was studied in [13]
in the context of a gradient flow on , where it appears naturally. Whether the log-
2
M
Sobolev type inequality (6) holds depends solely on the model. In particular, it is always
verified if the model is strongly log-concave.
Once the convergence of the free energy of EM iterates to F via (6) has been estab-
⋆
lished, we investigate fast convergence of the EM iterates themselves (θ ,q ) to :=
k k ⋆
M
argminF(θ,q)= (θ ,π ) :θ , i.e. to a (local) maximum of the marginal likelihood
{
⋆ θ⋆ ⋆ ∈O⋆
}
and its corresponding posterior. The decomposition
F(θ ,q ) F = KL(q π )+[log(Z ) log(Z )] (7)
k k
−
⋆ k
||
θk ⋆
−
θk
whereKLdenotestheKullback–Leiblerdivergence,suggeststhattheconvergenceinfreeen-
ergy shouldalsogive information onconvergence ofboththeEMiterates, sinceKL(q π )
k
||
θk
gives information on the convergence of the posterior updates q in terms of KL, while
k
log(Z ) log(Z ) tracks the convergence of the parameter updates θ . An natural exten-
⋆
−
θk k
sion of the Otto–Villani Theorem [46] enables this intuition: inequality (6) actually implies
an extension of the Talagrand inequality [52]:
2[F(θ,q) F ] λd((θ,q), )2, (8)
⋆ ⋆
− ≥ M
4where d is the product metric
d((θ,q),(θ′,q′)) := d (θ,θ′)2+d (q,q′)2, (9)
E W2
q
with d and d denoting the Euclidean and Wasserstein-2 distances, respectively. As a
E W2
result,weareabletoderivenon-asymptoticconvergence errorboundsind-distanceforboth
the posterior and parameter estimates of EM by assuming solely a smoothness condition
and that the model satisfies the log-Sobolev type inequality (6).
1.3 Paper structure
This paperis organized as follows. In Section 2 we study theinequality (6), primarily using
resultsfrom[13]. Inparticular,wederiveanexpressionforgrad F,studytherelationship
M2
between (6) and (8), and derive some sufficient conditions on the model to verify these.
In Section 3 we derive non-asymptotic rates of convergence for the EM algorithm under
condition (6) and a smoothness assumption using the approach we outlined. We further
analyze threealternatives to theEMthatcan beusedwheneither theE-or M-step(2)–(3)
isintractable(orbothareintractable)andcomparetheirconvergencepropertiesillustrating
the potential of the method to study the many variants of the EM algorithm.
2 Differential inequalities for EM
As outlined above, the EM algorithm can be viewed as a minimization procedure applied
to the free energy F. We aim to understand how to think about free energy dissipation
along the EM iterations, and in particular how to think about its gradient, and hence to
understand (6). In Section 2.1, we derive an expression for grad F(θ,q) and its norm.
M2
Our aim there is solely motivating the use of a certain functional (given in (12) below) for
that later, and in this sense it can be skipped on a first reading. In Section 2.2 we study
inequality (6),characterizing itasageneralization ofthewell-knownlog-Sobolev inequality.
Usingresultsrecently derivedin[13],weconnectitwiththegeneralization oftheTalagrand
inequality (8). In Section 2.3 we study sufficient conditions on the model to verify (6), and
show howwe can leverage advances from thefunctionalinequalities literature to investigate
the performance of models with different completions.
2.1 Differentiating the free energy in
2
M
Inthis section we show how wecan derive thegradient of thefreeenergy in ’s geometry,
2
M
which is key for our analysis, and which we need to make sense of the inequality (6). To
do so, we leverage the formal interpretation of (Rdx) endowed with the Wasserstein-2
2
P
distanced asaRiemannian-manifold,anapproachpioneeredin[45]. Thesecomputations
W2
were carried out in [35] to make sense of gradient descent for F, which we discuss later.
In this section we skim over technical details; this approach is not completely rigorous but
more technical arguments following the approach in [2] yield the same result. None of our
results depend upon this informal reasoning.
If we think of as a Riemannian manifold, in order to define gradients on , we
2 2
M M
needasensiblenotionoftangentspaceandinnerproduct. Becauseoftheproductstructure
of = Rdθ (Rdx), our tangent space will be the product of the tangent spaces of
2 2
M × P
each component. For the Rdθ component, we identify the tangent space at any point θ as
5Rdθ itself, so that Rdθ = Rdθ. For (Rdx) we consider the geometry induced by the
θ 2
T P
Wasserstein-2 distance d . With this choice, we think at the tangent space at any point
W2
q (Rdx) as the space of Lebesgue-integrable functions with zero integral
2
∈ P
(Rdx) := h : h(x)dx = 0 ,
q 2
T P
(cid:26) Z (cid:27)
which we equip with the following inner product.
Definition 1 (Wasserstein-2 inner product). Given two elements h ,h (Rdx), we
1 2 q 2
∈ T P
define their Wasserstein-2 inner product at q (Rdx) as
2
∈ P
h ,h := ψ (x), ψ (x) q(dx), where ψ solves (q ψ )= h i = 1,2.
h 1 2 iW2 ∇x 1 ∇x 2 i ∇x · ∇x i − i
Z
(cid:10) (cid:11)
and we denote with the induced norm.
k·kW2
Onemotivationforthischoiceoftangentspaceandinnerproductcomesfromcomparing
the Benamou–Brenier formula [55, p.159],
1
d (q,p) = inf inf v 2q (dx)dt : (q v ) = ∂ q :q = q,q = p , (10)
W2
qt ( Z0 vt (cid:26)Z k
t
k
t ∇x
·
t t
−
t t
(cid:27)
0 1
)
with the formula for the distance between two points in a Riemannian manifold (M,d )
M
1
d (p,q) = inf ∂ q dt : q = q,q = p ,
M qt ( Z0 k t t kM 0 1 )
upon noting that the optimal ‘velocity’ field v realizing the infimum in (10) is achieved by
t
a gradient of a function ψ, and that for (q ψ) = h to be solvable it is required
x x x
∇ ∇ · ∇ −
that h has zero Lebesgue integral. See [26, 55] for more details.
For a point (θ,q) , we set := Rdθ (Rdx) and we endow with
2 (θ,q) 2 θ q 2 2
∈ M T M T ×T P M
the following inner product which arises naturally from the product-space structure.
Definition 2 ( inner product). Given two elements (a ,h ),(a ,h ) , we
2 1 1 2 2 (θ,q) 2
M ∈ T M
define their inner product as
2
M
(a ,h ),(a ,h ) := a ,a + h ,h
1 1 2 2 M2 h 1 2 i h 1 2 iW2
(cid:10) (cid:11)
and we denote with the induced norm.
k·kM2
We can now definethegradient on in analogy with Riemannian geometry (see, e.g.,
2
M
Section 3 in [11]).
Definition 3 (Gradients in ). For a functional F on , its -gradient at (θ,q)
2 2 2
M M M ∈
M2
is the unique function grad M2F(θ,q)= (grad RdθF(θ,q),grad P2(Rdx)F(θ,q)) such that
d d d
F(θ ,q ) = grad F(θ,q), θ , q
dt t t M2 dt t dt t
(cid:12) (cid:12)t=0 * (cid:12) (cid:12)t=0 (cid:12) (cid:12)t=0 !+ M2
(cid:12) (cid:12) (cid:12)
for any smooth cu(cid:12)rve t (θ ,q ) such that (θ ,q ) = ((cid:12)θ,q), prov(cid:12)ided that it exists.
t t 0 0
7→
6The first variation will prove useful in calculating gradients, as the following lemma
shows.
Definition 4 (Firstvariation). For a functional F on , its first variation at (θ,q)
2 2
M ∈M
istheunique(uptoanadditiveconstant)functionδ M2F(θ,q)= (δ RdθF(θ,q),δ P2(Rdx)F(θ,q))
such that
d d d
F(θ ,q ) = δ F(θ,q), θ , q
dt
t t M2
dt
t
dt
t
(cid:12)t=0 * (cid:12)t=0 (cid:12)t=0 !+ L2(dx)
(cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)
for any smooth cu(cid:12)rve t (θ t,q t) such that (θ 0,q 0) =(cid:12) (θ,q), p(cid:12)rovided that it exists.
7→
Lemma 2. If it exists, grad F(θ,q) satisfies
M2
grad M2F(θ,q) = δ RdθF(θ,q),
−∇x
·(q ∇xδ P2(Rdx)F(θ,q)) .
(cid:16) (cid:17)
Proof. See Appendix B.1.
Using Definition 4 we readily compute δ F(θ,q) = ( ℓ(θ;x)q(dx),log(q/ρ )),
M2
−
∇θ θ
and using the above lemma we identify the following gradient of the free energy:
R
grad F(θ,q)= ℓ(θ;x)q(dx), q( log(q) log(ρ ) . (11)
M2 − ∇θ −∇x · ∇x −∇x θ
(cid:18) Z (cid:19)
(cid:0) (cid:1)
2.2 Log-Sobolev and Talagrand Inequalities on
2
M
Having a notion of gradient on , we are ready to define a very important quantity—the
2
M
squared norm of the gradient of the free energy in :
2
M
2
2
q(x)
2
I(θ,q) := grad F(θ,q) = ℓ(θ;x)q(dx) + log q(dx). (12)
M2 M2
(cid:13)Z
∇θ
(cid:13) Z
(cid:13) (cid:13)∇x (cid:18)ρ θ(x) (cid:19)(cid:13)
(cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
We refer to this quantity as the(cid:13)extended Fisher i(cid:13)nforma(cid:13)tion functional, b(cid:13)ecause if the
(cid:13) (cid:13)
parameter space is the trivial space θ , this quantity reduces to the relative Fisher infor-
{ }
mation functional (e.g. see equation (8) in [46]):
2
q(x)
I(q π ) := log q(dx). (13)
θ x
||
Z
(cid:13) (cid:13)∇ (cid:18)π θ(x) (cid:19)(cid:13)
(cid:13)
(cid:13) (cid:13)
Inlightofthis, uponconsideringtheres(cid:13) (cid:13)triction P21(Rdx)o(cid:13) (cid:13)f P2(Rdx)toprobabilitymeasures
having at least a.e. differentiable densities to ensure (12) is well defined, we can interpret
the following as a gradient growth condition on the free energy in ’s geometry.
2
M
Definition 5 (Extendedlog-Sobolev inequality; xLSI). The measures (ρ θ(dx)) θ∈Rdθ satisfy
the extended log-Sobolev inequality with constant λ > 0 if (6) holds for all (θ,q) 1 :=
∈ M2
Rdθ 1(Rdx).
×P2
This inequality generalizes both the well-known log-Sobolev inequality (LSI) in optimal
transport [55, Definition 21.1] and the Polyak–L ojasiewicz inequality (PL I) in optimization
[48, 38], which arise when π is independentof θ and when we consider q = π , respectively.
θ θ
While the LSI is a statement about a single probability distribution, and PL I about a
single function, the xLSI is a statement about a parameterized family of finite measures,
7our (complete data) model. The xLSI does not imply that the marginal likelihood has an
unique maximizer, and it allows for multiple stationary points. However, it implies that
any stationary point is a global maximizer.
We will use the xLSI in conjunction with a smoothness assumption to conclude conver-
gence of the free energy along EM iterates, but we would like to infer convergence of the
iterates themselves in some appropriate distance. We consider the product metric on
2
M
given by (9).
Definition 6 (Extension of the Talagrand inequality; xT 2I). The measures (ρ θ(dx)) θ∈Rdθ
satisfy an extension of the Talagrand inequality with constant λ > 0 if (8) holds for all
(θ,q) .
2
∈ M
We can show that xT I generalizes both the Talagrand inequality (‘T I’) [46, 52] and
2 2
thequadraticgrowth (QG) condition [4]byconsideringagain thecases whentheparameter
or the distribution spaces are trivial as above. To investigate the link between xT I and
2
the xLSI we impose some regularity conditions on the model.
Assumption 1. (i) For all x in Rdx, θ π (x) is differentiable; and θ Z is differ-
θ θ
7→ 7→
entiable; (ii) for all θ in Rdθ, π is twice continuously differentiable; (iii) for all θ in Rdθ
θ
and x in Rdx, ρ (x) > 0; (iv) π has finite second moments for all θ Rdθ, and these are
θ θ
∈
continuous in θ; (v) is compact.
⋆
O
Assumption 2. The log-likelihood ℓ is differentiable and its gradient ℓ = ( ℓ, ℓ)
θ x
∇ ∇ ∇
satisfies
ℓ(θ;x) ℓ(θ′;x′) L θ θ′ +L x x′
θ x
∇ −∇ ≤ − −
for some constants L(cid:13) and L . In particu(cid:13)lar, ℓ(cid:13)is L :=(cid:13) max((cid:13)L ,L )(cid:13)-Lipschitz.
(cid:13)θ x (cid:13) ∇(cid:13) (cid:13) (cid:13) θ x(cid:13)
Assumption 1 imposes only very mild regularity conditions on the model and it is
typically satisfied by models used in practice. Conditions (iv,v) are only required for the
results in Lemma 11 and Theorem 12 to ensure that π ’s second moments are uniformly
θ⋆
bounded across θ . If consists of finitely many points (e.g. if Assumption 3 below
⋆ ⋆ ⋆
∈O O
holds), in (iv) the continuity of second moments is not even needed. Assumption 2 is a
classical, but more stringent, smoothness condition. We have the following generalization
of the Otto–Villani Theorem [46]:
Theorem 3 (Theorem 2in[13]; xLSI xT I). If Assumptions 1–2 hold, and the measures
2
⇒
(ρ θ(dx)) θ∈Rdθ satisfy the xLSI with constant λ, then they also satisfy the xT 2I with the same
constant.
For our analysis, this Theorem tells us that it is enough to establish convergence of free
energy of EM iterates under the xLSI, as then we can just use the xT I to translate that
2
into the convergence of the iterates themselves in d-distance.
2.3 Bakry–E´mery and the perturbation and contraction principles
In this section we study some sufficient conditions on the model to verify the xLSI. A
generalization of the Bakry and E´mery criterion [5] shows that a convenient sufficient (but
not necessary) condition for the xLSI is strong log-concavity.
8Assumption 3 (Strong log-concavity). There exists a λ > 0 such that
λt(1 t)
ℓ((1 t)θ+tθ′;(1 t)x+tx′) (1 t)ℓ(θ;x)+tℓ(θ′;x′)+ − (θ,x) (θ′,x′) 2 ,
− − ≥ − 2 −
for all (θ,x),(θ′,x′) in Rdθ Rdx and 0 t 1. (cid:13) (cid:13) (cid:13) (cid:13)
× ≤ ≤
Theorem 4 (Theorem 3 in [13]; Strong log-concavity xLSI). Any model satisfying
⇒
Assumptions 1(iii) and 3 satisfies the xLSI.
We now show a simple example of a model class in which this Bakry–E´mery argument
allows us to verify that the xLSI holds.
Example 1. For m N, C Rdx/m×dx/m,D Rdθ×dx/m, consider the hierarchical model
i
∈ ∈ ∈
Y = C X +U X = Dθ+V for i = 1,...,m,
i i i i i i
where U and V are i.i.d. symmetric around 0 random vectors with distribution densities p
i i u
and p , respectively. We think of this model as describing an underlying process of interest
v
X, that depends on some parameter θ, and which is only observed with noise via Y. The
model is given by
m
ρ (x) := p (y C x )p (x Dθ)
θ u i i i v i
− −
i=1
Y
and within the Empirical Bayes setting, we would like to perform inference on the states
using π , with θ being the MLE, via the EM algorithm. In this setting, whether the xLSI
θ⋆ ⋆
holds depends solely on the tail behaviour of both the noise distributions p and p . It is
u v
common to assume that p is a Normal density. In this case, any strongly log-concave
v
density p returns a model satisfying the xLSI by Theorem 4, and any gradient-Lipschitz
v
density p returns a model satisfying Assumption 2. The Normal hierarchical model, which
v
assumes that p and p are both Normal, also satisfies both requirements.
u v
2.3.1 Operations preserving the xLSI and models with different completions
The literature on functional inequalities contains many results which show preservation
of functional inequalities under various operations. For instance, the LSI is known to
be preserved under contractive mappings [6], bounded perturbations [31], mixtures [17],
convolutions with Gaussians and some class of smooth perturbations [15] and many more.
Theseresults extend considerablythesettings whereonecan verify theLSI,showingthatit
goes far beyond strong log-concavity. These sorts of considerations also motivated the use
of functional inequalities for the analysis of Langevin Monte Carlo [54, 18]. Here our goal
is to illustrate that similar results hold for the xLSI, by generalizing the aforementioned
contractive mapping and the bounded perturbation results.
For the LSI, these results allow us to conclude that if a probability distribution satisfies
theLSI,thenanotherdistributionnottoodifferentfromtheoriginal, asobtainedasaresult
of these operations, still does. To understand what the xLSI analogues say, recall that for
any given marginal likelihood, Z , there are many possible choices of complete likelihood,
θ
ρ = π Z , depending on the completion, π , the choice which is known to dramatically
θ θ θ θ
impact the performance and convergence properties of the associated EM algorithm [22,
41]. The following results then say that if a given model satisfies the xLSI, a model using
anothercompletion, thatisnottoodifferentfromtheoriginal, stilldoes. Aswewillconnect
the fast convergence of EM with the xLSI, this in principle also gives an estimate on the
performance we can expect from models obtained with different completions.
9Proposition 5 (Perturbation principle). Let Assumption 1(i) hold, and suppose that the
measures (ρ θ(dx)) θ∈Rdθ satisfy the xLSI with constant λ > 0. Consider the measures
(ρ˜ θ(dx)) θ∈Rdθ defined by ρ˜ θ := π˜ θZ θ, where π˜ θ is a bounded perturbation of π θ in the sense
that c−1 dπ /dπ˜ c for some c> 1 independent of θ, and that
θ θ
≤ ≤
2
[ ρ ρ˜ ]/ρ˜
θ θ θ θ θ
b:= sup ∇ −∇ < . (14)
[log(Z ) log(Z )] ∞
(cid:13) ⋆ θ(cid:13)
−
(cid:13) (cid:13)
Then the measures (ρ˜ θ(dx)) θ∈Rdθ also satisfy the xLSI with constant (λ −c2 ·b)/2c2.
Proof. See Appendix B.2.
Notice that in the result above, the marginal likelihood Z of the perturbed model
θ
is the same as that of the unperturbed one, so we are comparing models with different
completions defined on a common space. In the degenerate case in which π is independent
θ
of θ, we can take b = 0 and this result reduces, up to a factor of 2, to the Holley–Stroock
perturbation lemma [31] (also see [6, Lemma 5.1.6]) which asserts that if a probability
measure π satisfies the LSI with constant λ, then its bounded perturbation π˜ also does,
θ θ
but with constant λ/c2. In this case, Theorem 4 and Proposition 5 immediately imply
that, under Assumption 1(i,iii), if the log-likelihood ℓ is strongly concave only in the ‘tails’
i.e. over A∁ Rdθ, where A is some compact set in Rdx, then the xLSI will still hold. When
×
π depends on θ, (14) says that the gradients of the completions need to be identical in
θ
the stationary points of the marginal likelihood (at the MLE, where log(Z ) = log(Z )),
θ ⋆
and that outside there it should not be too large relative to the tail behaviour of the
marginal likelihood. On the other hand, the marginal log-likelihood is typically intractable
so verifying (14) is complicated in real settings. Using this result, we speculate it should be
possible to show that the xLSI can hold in situations where the surrogate (4) is not even
concave.
As is the case for the LSI, the xLSI is preserved under the action of Lipschitz maps.
For a probability measure µ (Rdx) and a measurable map T with domain Rdx, let
∈ P
T µ = µ T−1 denote the pushforward of µ by T.
#
◦
Proposition 6 (Contraction principle). Let Assumption 1(i) hold, and suppose that the
measures (ρ θ(dx)) θ∈Rdθ satisfy the xLSI with constant λ > 0. If π˜ θ can be written as
π˜ θ = T #π θ, for some L T-Lipschitz diffeomorphism T, then the measures (ρ˜ θ(dx)) θ∈Rdθ
defined by ρ˜ := π˜ Z also satisfy the xLSI with constant λ/max(1,L2).
θ θ θ T
Proof. See Appendix B.3.
Rather than deriving results in the most general form our aim here was to illustrate the
flavour of this sort of results. We believe that such arguments have the potential to further
characterize EM’s fast convergence; developing a theory similar to that other standard
functional inequalities and Langevin Monte Carlo.
3 Non-asymptotic analysis of EM and related algorithms
3.1 EM Algorithm
The goal is to establish exponential convergence of the EM iterates under the xLSI. To do
so, we first establish the exponential convergence of the free energy to its minimizer and
10then transfer the result, via the extension of the Talagrand inequality and Theorem 3, to
the EM iterates themselves. Proposition 1 shows that the free energy can only decrease
along the EM iterations, and in order to prove EM’s exponential convergence we need to
quantify the decrease. Since we think of the extended Fisher information functional I (12)
as the squared norm of the free energy gradient, we might expect that under a smoothness
assumption we can lower bound the magnitude of this decrease in terms of I:
Lemma 7. If Assumption 2 holds, for all k N,
∈
1
F(θ ,q ) F(θ ,q ) I(θ ,q ) (15)
k k k+1 k k k
− ≥ 2L
θ
Proof. Consider ϑ := θ +(1/L ) ℓ(θ ;x)q (dx). By the minimality of θ ,
k k θ θ k k k+1
∇
F(θ ,q ) FR(θ ,q ) F(θ ,q ) F(ϑ ,q ), (16)
k k k+1 k k k k k
− ≥ −
and because θ ℓ(θ;x) is L -Lipschitz for all x Rdx,
θ θ
7→ ∇ ∈
L
ℓ(x;θ ) ℓ(x;ϑ )+ ℓ(θ ;x),ϑ θ θ ϑ θ 2,
k k θ k k k k k
− ∇ − ≤ 2 k − k
(cid:10) (cid:11)
so that
F(θ ,q ) F(ϑ ,q )= (ℓ(ϑ ;x) ℓ(θ ;x))q (dx)
k k k k k k k
− −
Z
2
1 1
ℓ(θ ;x), ℓ(θ ;x˜)q (dx˜) ℓ(θ ;x˜)q (dx˜) q (dx)
θ k θ k k θ k k k
≥ L ∇ ∇ − 2L ∇
Z θ (cid:28) Z (cid:29) θ(cid:13)Z (cid:13) !
(cid:13) (cid:13)
1 2 (cid:13) (cid:13)
= ℓ(θ ;x)q (dx) , (cid:13) (cid:13) (17)
θ k k
2L ∇
θ(cid:13)Z (cid:13)
(cid:13) (cid:13)
(an inequal(cid:13)ity known as the des(cid:13)cent lemma in optimization). Now, (15) follows by combin-
(cid:13) (cid:13)
ing this estimate with (16) while also noting that we have
2
q argminF(θ ,q) = π I(θ ,q ) = ℓ(θ ;x)q (dx) . (18)
k
∈ q∈P(Rdx)
k θk
⇒
k k
(cid:13)Z
∇θ k k
(cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
Nowwejustneedtoknowthat,alongEMiterations,F’sgradientgrowsatleastquadrat-
ically away from the set of minimizers, but that is precisely what the xLSI says.
Proposition 8. LetAssumption 2hold, andassume that the measures (ρ θ(dx)) θ∈Rdθ satisfy
the xLSI with constant λ > 0. Then, for all k N,
∈
F(θ ,q ) F (1 λ/L )k[F(θ ,q ) F ] e−kλ/Lθ[F(θ ,q ) F ].
k k ⋆ θ 0 0 ⋆ 0 0 ⋆
− ≤ − − ≤ −
Proof. By Lemma 7 and then the xLSI,
1 λ
F(θ ,q ) F(θ ,q ) F(θ ,q ) F(θ ,q ) I(θ ,q ) [F(θ ,q ) F ]
k k k+1 k+1 k k k+1 k k k k k ⋆
− ≥ − ≥ 2L ≥ L −
θ θ
for all k N, and the claim follows upon rearranging this inequality as
∈
F(θ ,q ) F (1 λ/L )[F(θ ,q ) F ]
k+1 k+1 ⋆ θ k k ⋆
− ≤ − −
and iterating.
11We can use the extension of Talagrand’s inequality provided by Theorem 3 to conclude
convergence in d-distance of the EM iterates.
Corollary 9. Under Assumption 1 and the conditions of Proposition 8,
λd((θ ,q ), )2 2(1 λ/L )k[F(θ ,q ) F ] 2e−kλ/Lθ[F(θ ,q ) F ].
k k ⋆ θ 0 0 ⋆ 0 0 ⋆
M ≤ − − ≤ −
Having demonstrated that differential arguments provide an efficient way to obtain a
convergence bound for both the parameter and the posterior estimates in EM to the MLE,
before commenting on the significance and the interpretation of this result, we first explore
how this bound can be sharpened.
To prove the above results, we considered only the decrease in free energy due the
parameter updates. We can improve the bound by also considering the decreases due
posterior updates. To do so, we would like to follow the same principles as the proofs
above, by comparing EM’s updates to appropriate gradient steps. We need a notion of a
gradient step for q F(θ ,q) KL(q π ). As is well-known in some areas of optimal
7→
k+1
∝ ||
θk+1
transportand sampling, in the Wasserstein-2 geometry this coincides with a Langevin step,
in the sense that following this gradient direction coincides with evolving the probability
density according to the Langevin Fokker–Planck equation. Actually, from (11) we are
already in a good position to prove (at least formally) this fact: when the parameter space
is the trivial space θ from (11) we have
k+1
{ }
grad P2(Rdx)KL(q ||π θk+1) =
∇x
·
q( ∇xlog(q) −∇xlog(π θk+1))
(cid:16) (cid:17)
which implies that the curve t q defined by
t
7→
∂ tq
t
= grad P2(Rdx)KL(q
t
||π θk+1)=
∇x
·
q t( ∇xlog(q t) −∇xlog(π θk+1))
(cid:16) (cid:17)
is the ‘Wasserstein’ gradient flow of q KL(q π ) in (Rdx)—the steepest descent
7→ ||
θk+1 P2
curve on the space of probability distributions that connects an initial distribution to the
invariantπ . ThisdifferentialequationistheFokker–Planck equation oftheoverdamped
θk+1
Langevin diffusion
dX = log(π (X ))dt+√2dW = ℓ(θ ;X )dt+√2dW
t ∇x θk+1 t t ∇x k+1 t t
where W denotes a Brownian Motion. Hence, as an analogue of (16), we wish to bound
t
F(θ ,q ) F(θ ,q ) F(θ ,q ) F(θ ,Law(X +h ℓ(θ ;X )+√2hξ ))
k+1 k k+1 k+1 k+1 k k+1 k x k+1 k k
− ≥ − ∇
(19)
from below, where Law(X ) = q , h > 0 is to be chosen based upon L and ξ is a
k k x k
standard normal random variable. We would like to obtain a lower bound on the right
hand side quantity that depends on L and the extended Fisher information functional,
x
giving something that looks like (15). The only difficulty is that there is not an immediate
candidate for an analogue of the descent lemma (inequality (17)) on (Rdx). However, we
2
P
have the following:
Lemma 10 (Descent lemma on (Rdx)). Let Assumption 2 hold. Let (p ) be an inter-
2 t
P
polation in (Rdx) between q at t = kh and Law(X +h ℓ(θ ;X )+√2hξ ), where
2 k k x k+1 k k
P ∇
Law(X )= q , at t = (k+1)h, defined by the law of
k k
Z =X dZ = ℓ(θ ;Z )dt+√2dW ,
t− k t ∇x k+1 t− t
12where t [kh,(k+1)h] and t = kh. If h 1/4L ,
− x
∈ ≤
1
∂ KL(p π ) I(p π )+6L2d (t t ) (20)
t t || θk+1 ≤ −2 t || θk+1 x x − −
ThisresulthasbeenusedtostudyLangevinMonteCarloandwasestablishedin[54]and
refined in [18, Section 4.2]. In Section 3.4 we present a generalization of this result, whose
proof also illustrates how the above lemma can be established. The term 6L2d (t t ) is
x x − −
a bias term which has no analogue in the Euclidean case, and it is essentially due to the
fact that the na¨ıve discretization of the Langevin diffusion does not preserve the stationary
distribution of the continuous time process.
We need one last ingredient: in the proof of Proposition 8 we used the fact that q
k
minimizes F(θ , ) to obtain (18). Now, we can use the fact that θ minimizes F(,q ),
k+1 k+1 k
· ·
to obtain
θ argminF(θ,q ) ℓ(θ ,x)q (dx) = 0 I(θ ,q ) = I(q π ). (21)
k+1
∈ θ∈Rdθ
k
⇒
Z
∇θ k+1 k
⇒
k+1 k k
||
θk+1
However, since we will work with the interpolation as in Lemma 16 we also need to know
that ℓ(θ ,x)p (dx) is small and establishing that is the focus of the next lemma.
θ k+1 t
∇
LemRma 11. Let Assumption 2 hold and let (p ) be as in Lemma 10. For h 1/4L ,
t x
≤
2
ℓ(θ ,x)p (dx) L (t t )[C +4d L ], t [kh,(k+1)h]
θ k+1 t x − x x
∇ ≤ − ∈
(cid:13)Z (cid:13)
(cid:13) (cid:13)
with C :=(cid:13) (cid:13)L2sup x x 2 q(cid:13) (cid:13)(dx)+ θ θ 2 , and where (θ ,x ) is a stationary point
k − † k k+1 − † † †
of ℓ. In particular R, (cid:13)when q
k(cid:13)
is given b (cid:13)y the EM (cid:13)update, q
k
= argmin q∈P2(Rdx)F(θ k+1,q),
we have the bound (cid:13) (cid:13) (cid:13) (cid:13)
2L2
C L2 sup x x 2 π (dx)+ θ θ 2 + [F(θ ,q ) F ]. (22)
≤ −
† θ⋆ ⋆
−
†
λ
0 0
−
⋆
θ⋆∈O⋆(cid:26)Z (cid:27)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
Proof. See Appendix C.1.
(22) shows that C is finite under Assumption 1. It is common to shift coordinates so
that (θ ,x ) = (0,0). We now improve on Proposition 8.
† †
Theorem 12. Let Assumptions 1–2 hold, and assume that the measures (ρ θ(dx)) θ∈Rdθ
satisfy the xLSI with constant λ > 0. Then, for all k N,
∈
h2B
F(θ ,q ) F inf e−kλ(h+1/Lθ)[F(θ ,q ) F ]+ (23)
k k − ⋆ ≤ h≤1/4Lx( 0 0 − ⋆ 1 e−λ(h+1/Lθ) )
−
where B := [8L2d +CL /2] and C is as per Lemma 11.
x x x
Proof. Because ∂ F(θ ,p ) = ∂ KL(p π ), we can write, by equation (20), the xLSI
t k+1 t t t
||
θk+1
and Lemma 11, that for all h 1/4L , t [kh,(k+1)h], with t = kh:
x −
≤ ∈
2
1 1
∂ F(θ ,p ) I(θ ,p )+ ℓ(θ ,x)p (dx) +6L2d (t t )
t k+1 t ≤ −2 k+1 t 2 ∇θ k+1 t x x − −
(cid:13)Z (cid:13)
(cid:13) (cid:13)
λ[F(θ k+1,p t) F(cid:13)⋆]+(t t −)B. (cid:13) (24)
≤ − − (cid:13) − (cid:13)
13Hence,
∂ etλ[F(θ ,p ) F ] = etλ λ[F(θ ,p ) F ]+∂ F(θ ,p ) etλhB.
t k+1 t ⋆ k+1 t ⋆ t k+1 t
− − ≤
h i
(cid:2) (cid:3)
Integrating between t = kh and t = (k+1)h we obtain
e(k+1)hλ[F(θ ,p ) F ] ekhλ[F(θ ,p ) F ] e(k+1)hλh2B,
k+1 (k+1)h ⋆ k+1 kh ⋆
− − − ≤
and thus:
F(θ ,p ) F e−hλ[F(θ ,q ) F ]+h2B. (25)
k+1 (k+1)h ⋆ k+1 k ⋆
− ≤ −
Combining the left hand side with the observation in (19) and the right hand side with the
bound in the proof of Proposition 8,
F(θ ,q ) F e−λ(h+1/Lθ)[F(θ ,q ) F ]+h2B.
k+1 k+1 ⋆ k k ⋆
− ≤ −
Iterating this inequality we finally prove
k−1
F(θ ,q ) F e−kλ(h+1/Lθ)[F(θ ,q ) F ]+h2B e−jλ(h+1/Lθ)
k k ⋆ 0 0 ⋆
− ≤ −
j=0
X
and we conclude by bounding the geometric sum above with its limit, and taking the
infimum across h 1/4L .
x
≤
As before, convergence in d-distance of the both the sequence of parameters and the
posterior now follows by the extension of the Talagrand inequality via Theorem 3.
Corollary 13. Under the same conditions as Theorem 12,
h2B
λd((θ ,q ), )2 2 inf e−kλ(h+1/Lθ)[F(θ ,q ) F ]+ .
k k M⋆ ≤ h≤1/4Lx( 0 0 − ⋆ 1 e−λ(h+1/Lθ) )
−
Since = (θ ,π ) : θ , we are bounding the distance of the EM iterates
M⋆
{
⋆ θ⋆ ⋆
∈
O⋆
}
to a (local) maxima of the marginal likelihood and the corresponding posterior, which can
be identified as the projection of (θ ,q ) onto the optimal set . By definition, the log-
k k ⋆
M
Sobolev constant λ, which dictates the convergence rate of EM, has the interpretation of
being bounded by the maximum ratio between information and the free energy produced
along the EM iterates, as given by the functionals I and F.
By the results in Section 2.3, we know, for instance, that the same bound holds if we
replace the xLSI assumption with ℓ’s strong concavity (Assumption 3), or any bounded
perturbation, in the sense of Proposition 5, of such model. When Assumption 3 holds, ℓ
has a unique maximizer, as does the marginal likelihood Z , and is a singleton. At
θ ⋆
M
least without additional assumptions, we are required to start the algorithm with an initial
distribution q having a density, otherwise the term F(θ ,q ) would be infinite. In practice,
0 0 0
thisis never anissue, andwecan avoid this problemaltogether byperforminganadditional
E-step as part of the initialization procedure, so given θ we set q = π which is, in any
0 0 θ0
case, the optimal choice of q for a given θ in terms of the resulting error bound, since
0 0
F(θ 0,π θ0) = inf q0∈P2(Rdx)F(θ 0,q 0).
The bound above is reminiscent of the convergence bounds in Langevin Monte Carlo
(LMC) when h is its discretization step size, which we need to be small enough, and that
14appears both in a bias term and in the convergence rate, showing that the LMC algorithm
is biased [23]. However, the rightmost term in (23) is not a bias term in the sense that the
EM algorithm converges to the correct limit—we can always just take h= 0 and eliminate
this term, while retaining a non-zero convergence rate. Of course, small choices of h reduce
the rightmost term, but they also make the rate of convergence smaller. When k is small,
larger choices of h provide a much sharper boundthan h = 0. In principle one could obtain
still sharper bounds by considering different values of h for each step of the algorithm but
we do not pursue that.
We now show that we can use similar techniques to analyze alternatives to the EM
algorithm that we consider when either, or both, the E-M steps (2)–(3) are intractable.
3.2 First-order EM
Often, the M-step (2) is intractable. In these cases, rather than solving (2) exactly, one
often performs instead a gradient step to find a θ with a smaller, but not optimal, value of
F(θ,q ) ℓ(θ;x)q (dx). This results in the first-order EM (or gradient EM) algorithm
k k
∝ −
(see, e.g. [7]).
R
Algorithm 2 First-order EM Algorithm
1: Inputs: Step size h, initial parameters (θ ,q ).
0 0
2: for k 0 do
≥
3: Update the parameter estimate
θ = θ +h ℓ(θ ;x)q (dx).
k+1 k θ k k
∇
Z
4: Update the posterior estimate
q = π .
k+1 θk+1
5: end for
We can easily use the tools developed above to study first-order EM. Indeed, provided
h 1/L , we can verbatim adapt the proofs of Lemma 7, Proposition 8 and Corollary 9
θ
≤
with h in place of 1/L , yielding:
θ
Theorem 14. Let Assumption 1–2 hold, and assume that the measures (ρ θ(dx)) θ∈Rdθ sat-
isfy the xLSI with constant λ > 0. Then, if h 1/L , for all k N,
θ
≤ ∈
λd((θ ,q ), )2 2e−kλh[F(θ ,q ) F ]
k k ⋆ 0 0 ⋆
M ≤ −
Because the parameter update here is not a minimization step anymore, we cannot
leverage the posterior updates to improve the convergence bound in the same way as for
the basic EM algorithm. Therefore, we can ensure first-order EM convergence with a small
enough choice of the step size, but the error bounds for first-order EM algorithm will in
general decrease more slowly than those for EM, which of course is consistent with the way
in which we would expect the actual error to behave. Using similar techniques, it should
be straightforward to analyze the case in which h is specified adaptively.
3.3 Langevin EM
In a complementary setting, the E-step (3) might be intractable. Hypothetically, in these
cases, we could consider following the same strategy as the first-order EM algorithm, al-
15though it is perhaps less obvious how to implement such a scheme: rather than perform-
ing (3), which is minimizing the free energy for a fixed θ (Proposition 1), one can
k+1
take a gradient step in the space of probability measures to find a new q which reduces
F(θ ,q) KL(q π ). For a step size h > 0, as we argued in Section 3.1, in the
k+1
∝ ||
θk+1
Wasserstein-2 geometry this step consists in q Law(X ), where
k k+1
→
X = X +h ℓ(θ ;X )+√2hξ , Law(X )= q , (26)
k+1 k x k+1 k k k k
∇
andwhereξ isastandardnormalrandomvariable. Wetermtheresultingalgorithm,which
k
appears in Appendix D of [35] as the gradient flow approximated by “marginal particle
gradientdescent”, LangevinEM.Althoughthisalgorithm mayappearsomewhatcontrived,
we view it as an idealisation of a form of Monte CarloEM in which q is approximated with
k
a particle system and the particles within theapproximation are updated by an application
of an unadjusted Langevin kernel of step-size h and invariant distribution π at each step.
θk
The use of (unadjusted) Langevin steps with EM type algorithms has been explored in a
number of contexts, e.g. [28], and we anticipate that the analysis of Langevin EM can also
be adapted to study these implementations.
Algorithm 3 Langevin EM Algorithm
1: Inputs: Step size h, initial parameters (θ ,q =: Law(X )).
0 0 0
2: for k 0 do
≥
3: Update the parameter estimate
θ = argmax ℓ(θ ;x)q (dx)
k+1 k k
θ Z
4: Update the posterior estimate, with ξ denoting a (0,I ) r.v.,
k
N
dx
q = Law(X ), where
k+1 k+1
X = X +h ℓ(θ ;X )+√2hξ
k+1 k x k+1 k k
∇
5: end for
We can study Langevin EM almost immediately with our results: we follow verbatim
the proof of Theorem 12 until (25). Then, rather than combining the bound with the one
in Proposition 8, which we cannot use as the posterior update is not a minimization step
here, we use the looser bound F(θ ,q ) F(θ ,q ), iterate the resulting inequality and
k+1 k k k
≤
then combine it with Theorem 3 as usual.
Theorem 15. Let Assumptions 1–2 hold, and assume that the measures (ρ θ(dx)) θ∈Rdθ
satisfy the xLSI with constant λ > 0. Then, if h 1/4L , for all k N,
x
≤ ∈
2h2B
λd((θ ,q ), )2 2e−kλh[F(θ ,q ) F ]+ .
k k M⋆ ≤ 0 0 − ⋆ 1 e−λ(h+1/Lθ)
−
B is as defined as in Theorem 12. In contrast to the EM case, we have not shown that
B is always finite here. However, doing so is not typically onerous and is, for example,
immediately true if the log-likelihood is strongly concave in the tails uniformly on θ, as can
be shown by adapting e.g. the arguments of Corollary 2.3 in [16].
We notice that, as opposed to EM or first-order EM, Langevin EM is actually biased:
there is no way to cancel the rightmost term without getting a null rate of convergence.
However, we can control the bias by choosing a small step size h. This is because the
discretization of the Langevin diffusion (26) introduces a bias, and it is consistent with
known results for Langevin Monte Carlo [23].
163.4 (Alternating) Gradient Descent
When both E- and M- steps are intractable, we can take a gradient step in both directions
at each iteration; essentially replacing the usual alternating minimization optimization of
the free energy with an alternating gradient descent method, as one might in Euclidean
optimization problems for which both the coordinate-wise minimization problems are not
tractable. ThisresultsintheAlternatingGradientDescentAlgorithm4below,amean-field
limit version of the SOUL algorithm [21] when the batch sizes are set to one, and when the
parameter updates can be carried out explicitly.
Algorithm 4 Alternating Gradient Descent Algorithm
1: Inputs: Step size h, initial parameters (θ ,q =: Law(X )).
0 0 0
2: for k 0 do
≥
3: Update the parameter estimate
θ = θ +h ℓ(θ ;x)q (dx), (27)
k+1 k θ k k
∇
Z
4: Update the posterior estimate: with ξ denoting a (0,I ) r.v.,
k
N
dx
q = Law(X ), where
k+1 k+1
(28)
X = X +h ℓ(θ ;X )+√2hξ
k+1 k x k+1 k k
∇
5: end for
To study Algorithm 4, we need a generalization of the descent lemma on the whole
2
M
Lemma 16 (Descent lemma on ). Let Assumptions 1–2 hold. Let (ϑ ,p ) be an in-
2 t t
M
terpolation in between (θ ,q ) at t = kh and (θ + h ℓ(θ ;x)q (dx),Law(X +
2 k k k θ k k k
M ∇
h ℓ(θ ;X ) + √2hξ )), where Law(X ) = q , at t = (k + 1)h. If h 1/4L, for
x k+1 k k k k
∇ R ≤
t [kh,(k+1)h],
∈
1
∂ F(θ ,p ) I(θ ,p )+6L2d (t t ), t := kh.
t t t t t x − −
≤ −2 −
Proof. See Appendix C.2.
The interpolating (ϑ ,p ) is specified in the proof. When the parameter space is trivial
t t
and equal to θ , this result reduces in to Lemma 10.
k+1
{ }
Theorem 17. Let Assumptions 1–2 hold, and assume that the measures (ρ θ(dx)) θ∈Rdθ
satisfy the xLSI with constant λ > 0. Then, if h 1/4L, for all k N,
≤ ∈
12L2d h2
λd((θ ,q ), )2 2e−kλh[F(θ ,q ) F ]+ x
k k M⋆ ≤ 0 0 − ⋆ 1 e−λh
−
Proof. See Appendix C.3.
It is also possible to update both parameters and distributions simultaneously (rather
thaninthealternatingfashiondescribedhere), inwhichcasewewouldobtain (amean-field
limit version of) the algorithm recently proposed in [35], studied and extended in [36, 13].
Such algorithm in fact corresponds to the (non alternating) gradient descent method on
the free energy F in ’s geometry.
2
M
A comparison with EM, first-order EM and Langevin EM results shows that the vanilla
EM algorithm is the fastest of the four. While comparing error bounds cannot provide
17definitivestatements, thisisconsistentwiththewayonewouldexpecttheerrorsthemselves
to behave in general—because EM is solving two entire minimization problems at each
iterations, whereas first-order EM and Langevin EM are solving one and taking a gradient
step for the other and the alternative gradient descent approach is actually only taking
a gradient step in both directions. Like Langevin EM, the alternating gradient descent
approachisexpectedlybiased,andthisisinlinewithpreviousanalysesofsimilaralgorithms
[13, 1, 25, 44]. This hierarchy between alternating minimization and gradient descent type
algorithms is consistent with the corresponding results and behaviour in Euclidean space;
on this see [9] for a comparative convergence analysis and [51] for a qualitative comparison.
These results do not necessarily imply that implementable variants of EM algorithm
outperformstheimplementableformofanyofthesealternatives inpractice, althoughitwill
certainly be the case when the minimization steps can be implemented exactly. Algorithms
1–4 are idealized algorithms, and for many models of interest, particularly in large-scale
modern applications, the iterations therein are still intractable. In practice, one often
resorts to Monte Carlo approximations. As noted above, for EM and first-order EM, it
is common to substitute the E-steps with N Monte Carlo samples from π (the Monte
θk+1
Carlo EM algorithm [57]) whereas one would make Algorithms 3 and 4 implementable by
approximatingLaw(X )withtheempiricaldistributionofN particlesfollowingtheabove
k+1
Langevin dynamics. An analysis of these Monte Carlo versions of the algorithms under the
xLSI and using the techniques we introduced here would potentially be interesting but
introduces a number of further technical complications, and is left for future work.
4 Discussion
This paper established non-asymptotic error bounds and convergence rates for the EM
algorithm—and some of its variants—under a log-Sobolev type inequality. Starting from
the observation of [43] that EM corresponds to an alternating procedure on the product
of Euclidean and the space of probability distributions, this approach can be considered a
generalization of standard arguments used to study alternating minimization on Euclidean
space via some concepts in optimal transport and sampling.
Thelog-Sobolevconstant, whichdictatestheconvergencerateinEM(Corollary13),has
the natural interpretation of being bounded by the maximum ratio between information
and free energy produced along the EM iterates (as measured by the functionals I and
F). The convergence bounds seem to be state-of-the-art in terms of characterizing the
exponential regime of EM, at least when the latent space is continuous (but see comments
below). A complete comparison with the results of [33, 34] is hard to carry out due the
very different approaches and settings: while they do not assume any smoothness, they
characterize the sub-exponential convergence of EM parameter estimates [33] or posterior
estimates [34] assuming (or implying) at least concavity of the surrogate.
The connections established herein mean there is potential to leverage the literatures of
optimal transport, functional inequalities and Langevin Monte Carlo to better understand
the EM algorithm and its many variants theoretically. Below we mention some potential
connections and extensions, some of which form part of current or future research.
In Section 2.3 we presented a couple of generalizations of standard results (the Bakry–
E´mery criterion, the Holley–Stroock and the contraction principles) to verify the xLSI and
compare the performance of models with different completions, and we expect that many
other results of this flavour can be adapted from the LSI literature, further characteriz-
18ing the exponential convergence regime of EM. Moreover, we expect that it is possible to
consider ‘weak’ or ‘modified’ versions of the xLSI, as done in [53, 14, 50, 3, 42] for other
standard functional inequalities, and similarly to consider gradient H¨older continuity as-
sumptions in place of the assumed Lipschitz condition, to characterize the sub-exponential
regime of convergence for a wide class of models.
The fact that the EM iterations are actually agnostic to any type of underlying metric
on means that we could have considered different ones, and thus different induced
M
log-Sobolev type inequalities; for instance, by considering the gradient of the free energy
grad F induced by the product of Euclidean and Stein’s geometry on (Rdx). These
M2 P2
might translate into different practical conditions on the underlying model (as analogues of
the results in Section 2.3) and could better characterize EM’s convergence in some settings,
and it would be interesting to consider these.
Lastly, we mention that a limitation of our approach is that we focus on continuous Eu-
clidean state spaces. While these constitute an important part of the models EM is applied
to, in particular within the Empirical Bayes framework, many other typical applications,
such as Gaussian Mixture Models, involve discrete latent spaces. We believe that it is pos-
sible to obtain analogues of our results in the discrete setting by leveraging advances on the
study of Wasserstein gradients on discrete spaces [20]. Similarly, within a continuous state
spaces setting, it should be possible to consider appropriate Riemannian manifolds rather
than Rdx by adapting the relevant results in the literature [46].
Acknowledgements
The authors thank Juan Kuntz for very helpful comments on an earlier version of this
manuscript. RCwasfundedbytheUKEngineeringandPhysicalSciencesResearchCouncil
(EPSRC)via studentship2585619 as partof grant numberEP/W523793/1. AMJ acknowl-
edges further EPSRC support under grant numbers EP/R034710/1 and EP/Y014650/1.
References
[1] O¨.DenizAkylid`ız,FrancescaR.Crucinio,MarkGirolami,TimJohnston,andSotirios
Sabanis. “Interacting particle Langevin algorithm for maximum marginal likelihood
estimation”. In: arXiv:2303.13429 (2023).
[2] LuigiAmbrosio,Nicola Gigli, andGiuseppeSavar´e. Gradient Flows: In Metric Spaces
and in the Space of Probability Measures. Springer Science & Business Media, 2005.
[3] Christophe Andrieu, Anthony Lee, Samuel Power, and Andi Q Wang. “Comparison
of Markov chains via weak Poincar´e inequalities with application to pseudo-marginal
MCMC”. In: The Annals of Statistics 50.6 (2022), pp. 3592–3618.
[4] Mihai Anitescu. “Degenerate nonlinear programming with a quadratic growth condi-
tion”. In: SIAM Journal on Optimization 10 (2000), pp. 1116–1135.
[5] Dominique Bakry and Michel E´mery. “Diffusions hypercontractives”. In: S´eminaire
de Probabilit´es XIX 1983/84. Lecture Notes in Mathematics Springer, 1985.
[6] DominiqueBakry,IvanGentil,andMichelLedoux.Analysis and Geometry of Markov
Diffusion Operators. Springer, 2014.
19[7] Sivaraman Balakrishnan, Martin J. Wainwright, and Bin Yu. “Statistical guarantees
for the EM algorithm: From population to sample-based analysis”. In: The Annals of
Statistics 40 (2017), pp. 77–120.
[8] AmirBeck. “Ontheconvergence ofalternatingminimization forconvex programming
withapplications toiteratively reweighted leastsquares anddecomposition schemes”.
In: SIAM Journal on Optimization 25.1 (2015), pp. 185–209.
[9] Amir Beck and Luba Tetruashvili. “On the convergence of block coordinate descent
type methods”. In: SIAM Journal on Optimization 23.4 (2013), pp. 2037–2060.
[10] Jakub Wiktor Both. “On therate of convergence of alternating minimization for non-
smoothnon-stronglyconvex optimization inBanach spaces”.In:Optimization Letters
16.2 (2022), pp. 729–743.
[11] Nicolas Boumal. An Introduction to Optimization on Smooth Manifolds. Cambridge
University Press, 2023.
[12] RussellABoyles. “Ontheconvergence oftheEMalgorithm”.In:Journal of the Royal
Statistical Society Series B: Statistical Methodology 45.1 (1983), pp. 47–50.
[13] Rocco Caprio,JuanKuntz,SamuelPower, andAdam MJohansen.“Errorboundsfor
particle gradient descent, and extensions of the log-Sobolev and Talagrand inequali-
ties”. In: arXiv:2403.02004 (2024).
[14] Patrick Cattiaux, Ivan Gentil, and Arnaud Guillin. “Weak logarithmic Sobolev in-
equalities and entropic convergence”. In: Probability Theory and Related Fields 139
(2007), pp. 563–603.
[15] Patrick Cattiaux and Arnaud Guillin. “Functional inequalities for perturbed mea-
sures with applications to log-concave measures and to some Bayesian problems”. In:
Bernoulli 28.4 (2022), pp. 2294–2321.
[16] Patrick Cattiaux, Arnaud Guillin, and Florent Malrieu. “Probabilistic approach for
granular media equations in the non-uniformly convex case”. In: Probability Theory
and Related Fields 140 (2008), pp. 19–40.
[17] Hong-BinChen,SinhoChewi,andJonathanNiles-Weed.“Dimension-freelog-Sobolev
inequalities for mixture distributions”. In: Journal of Functional Analysis 281.11
(2021), p. 109236.
[18] SinhoChewi.“Log-concaveSampling”.Bookdraft.2024.url:https://chewisinho.github.io.
[19] Sinho Chewi, Murat A Erdogdu, Mufan Bill Li, Ruoqi Shen, and Matthew Zhang.
“Analysis of Langevin Monte Carlo from Poincar´e to Log-Sobolev”. In: Proceedings
of Thirty Fifth Conference on Learning Theory. PMLR. 2022.
[20] Shui-NeeChow,WuchenLi,andHaominZhou.“EntropydissipationofFokker-Planck
equations on graphs”. In: Discrete & Continuous Dynamical Systems 38 (2018).
[21] Valentin De Bortoli, Alain Durmus, Marcelo Pereyra, and Ana F Vidal. “Efficient
stochastic optimisation by unadjusted Langevin Monte Carlo: Application to maxi-
mummarginallikelihood andempiricalBayesian estimation”. In:Statistics and Com-
puting 31 (2021), pp. 1–18.
[22] ArthurP.Dempster,NanM.Laird,andDonaldB.Rubin.“Maximumlikelihoodfrom
incomplete data via the EM Algorithm”. In: Journal of the Royal Statistical Society,
Series B 39 (1977), pp. 2–38.
20[23] Alain Durmus and E´ric Moulines. “High-dimensional Bayesian inference via the un-
adjusted Langevin algorithm”. In: Bernoulli 25.4A (2019), pp. 2854 –2882.
[24] Raaz Dwivedi, Nhat Ho, Koulik Khamaru, Martin J Wainwright, Michael I Jordan,
and Bin Yu. “Singularity, misspecification and the convergence rate of EM”. In: The
Annals of Statistics 48.6 (2020), pp. 3161–3182.
[25] Paula C. Encinar, O¨. Deniz Akylid`ız, and Francesca R. Crucinio. “Proximal Interact-
ing Particle Langevin Algorithms”. In: arXiv:2406.14292 (2024).
[26] AlessioFigalliandFederico Glaudo.AnInvitation to Optimal Transport, Wasserstein
Distances, and Gradient Flows. EMS Press, 2021.
[27] Irving J Good. “On the estimation of small frequencies in contingency tables”. In:
JournaloftheRoyalStatisticalSociety:SeriesB(Methodological) 18.1(1956),pp.113–
124.
[28] Samuel Gruffaz, Kyurae Kim, Alain Durmus, and Jacob Gardner. “Stochastic Ap-
proximation with Biased MCMC for Expectation Maximization”. In: Proceedings of
The 27th International Conference on Artificial Intelligence and Statistics. Vol. 238.
PMLR. 2024, pp. 2332–2340.
[29] Botao Hao, Will Wei Sun, Yufeng Liu, and Guang Cheng. “Simultaneous clustering
and estimation of heterogeneous graphical models”. In: Journal of Machine Learning
Research 18.217 (2018), pp. 1–58.
[30] AlfredOHeroandJeffreyAFessler.“Convergenceinnormforalternatingexpectation-
maximization (EM) type algorithms”. In: Statistica Sinica 5 (1995), pp. 41–54.
[31] RichardHolleyandDanielWStroock.“LogarithmicSobolevinequalitiesandstochas-
tic Ising models”. In: Journal of Statistical Physics 46 (1987), pp. 1159–1194.
[32] Belhal Karimi, Hoi-To Wai, Eric Moulines, and Marc Lavielle. “On the Global Con-
vergence of (Fast) Incremental Expectation Maximization Methods”. In: Advances in
Neural Information Processing Systems 32 (2019).
[33] RaunakKumarandMarkSchmidt.“ConvergenceRateofExpectation-Maximization”.
In: 10th NeurIPS Workshop on Optimization for Machine Learning. 2017.
[34] Frederik Kunstner, Raunak Kumar, and Mark Schmidt. “Homeomorphic-invariance
of EM: Non-Asymptotic Convergence in KL divergence for Exponential Families via
Mirror Descent”. In: Proceedings of The 24th International Conference on Artificial
Intelligence and Statistics. PMLR. 2021, pp. 3295–3303.
[35] Juan Kuntz, Jen Ning Lim, and Adam M. Johansen. “Particle algorithms for maxi-
mum likelihood trainingof latent variable models”.In:Proceedings of The 26th Inter-
national Conference on Artificial Intelligence and Statistics. Vol. 206. 2023, pp.5134–
5180.
[36] Jen Ning Lim, Juan Kuntz, Samuel Power, and Adam M. Johansen. “Momentum
particle maximum likelihood”. In: Proceedings of 41st International Conference on
Machine Learning (ICML). In press. PMLR. 2024.
[37] Michel Lo`eve. “Probability Concepts”. In: Probability Theory I. Springer New York,
1977, pp. 151–176.
[38] Stanislaw L ojasiewicz. “Une propri´et´e topologique des sous-ensembles analytiques
r´eels”. In: Les ´equations aux d´eriv´ees partielles 117 (1963), pp. 87–89.
21[39] Geoffrey J. McLachlan and Thriyambakam Krishnan. The EM Algorithm and Exten-
sions. John Wiley & Sons, 2007.
[40] Xiao-Li Meng and Donald B. Rubin. “On the global and componentwise rates of
convergenceoftheEMalgorithm”.In:Linear Algebraand itsApplications 199(1994),
pp. 413–425.
[41] Xiao-Li Meng and David Van Dyk. “The EM algorithm—an old folk-song sung to
a fast new tune”. In: Journal of the Royal Statistical Society Series B: Statistical
Methodology 59.3 (1997), pp. 511–567.
[42] Alireza Mousavi-Hosseini, Tyler Farghly, Ye He, Krishnakumar Balasubramanian,
and Murat A Erdogdu. “Towards a complete analysis of Langevin Monte Carlo: Be-
yond Poincar´e inequality”. In: Proceedings of Thirty Sixth Conference on Learning
Theory. 2023, pp. 1–35.
[43] RadfordM.NealandGeoffreyE.Hinton.“AViewoftheEMAlgorithm thatJustifies
Incremental, Sparse, and other Variants”. In: Learning in Graphical Models. Springer
Netherlands, 1998, pp. 355–368.
[44] PaulFelixValsecchiOlivaandO¨ DenizAkyildiz.“KineticInteractingParticleLangevin
Monte Carlo”. In: arXiv:2407.05790 (2024).
[45] Felix Otto. “The Geometry of Dissipative Evolution Equations: the Porous Medium
Equation”. In:Communications in Partial Differential Equations 26 (2001), pp.101–
174.
[46] Felix Otto and C´edric Villani. “Generalization of an Inequality by Talagrand and
Links with the Logarithmic Sobolev Inequality”. In: Journal of Functional Analysis
173 (2000), pp. 361–400.
[47] Grigorios A. Pavliotis. Diffusion Processes, the Fokker-Planck and Langevin Equa-
tions. 1st. Texts in Applied Mathematics. New York: Springer, 2014.
[48] BorisT.Polyak.“Gradientmethodsfortheminimisationoffunctionals(inRussian)”.
In: Zhurnal Vychislitel’noi Matematiki i Matematicheskoi Fiziki 3 (1963), pp. 643–
653.
[49] Herbert Robbins. “An empirical Bayes approach to statistics”. In: Proceedings of the
Third Berkeley Symposium on Mathematical Statistics and Probability. Vol. 3.1. 1956,
pp. 157–164.
[50] MichaelRo¨cknerandFeng-YuWang.“WeakPoincar´einequalitiesandL2-convergence
ratesofMarkovsemigroups”.In:JournalofFunctionalAnalysis 185.2(2001),pp.564–
603.
[51] James C. Spall. “Cyclic Seesaw Process for Optimization and Identification”. In:
Journal of Optimization Theory and Applications 154 (2012), pp. 187–208.
[52] Michel Talagrand. “Transportation cost for Gaussian and other product measures”.
In: Geometric & Functional Analysis 6 (1996), pp. 587–600.
[53] Guiseppe Toscani and C´edric Villani. “On the trend to equilibrium for some dissipa-
tive systemswithslowly increasingaprioribounds”.In:Journal of Statistical Physics
98 (2000), pp. 1279–1309.
[54] SantoshVempalaandAndreWibisono.“RapidConvergenceoftheUnadjustedLangevin
Algorithm: Isoperimetry Suffices”. In: Advances in Neural Information Processing
Systems. Vol. 32. 2019, pp. 8094 –8106.
22[55] C´edric Villani. Optimal Transport: Old and New. Springer Science & Business Media,
2009.
[56] ZhaoranWang,QuanquanGu,YangNing,andHanLiu.“Highdimensionalexpectation-
maximization algorithm: Statistical optimization and asymptotic normality”. In: Ad-
vances in Neural Information Processing Systems 28 (2015).
[57] Greg C.G. Wei and Martin A. Tanner. “A Monte Carlo implementation of the EM
algorithm and the poor man’s data augmentation algorithms”. In: Journal of the
American Statistical Association 85.411 (1990), pp. 699–704.
[58] Jeff CF Wu. “On the convergence properties of the EM algorithm”. In: The Annals
of Statistics 11 (1983), pp. 95–103.
[59] Ji Xu, Daniel J Hsu, and Arian Maleki. “Global analysis of expectation maximiza-
tion for mixtures of two Gaussians”. In: Advances in Neural Information Processing
Systems 29 (2016).
A Notation
We collect together the most widely used notation here for convenience:
ρ (x) Joint distribution p (x,y) of latent variables x and data y
θ θ
ℓ(θ;x) Logarithm of ρ (x)
θ
Z The marginal likelihood, Z := ρ (x)dx
θ θ θ
Z Value of Z at a stationary point
⋆ θ
R
π (x) Posterior of x given y, π (x) = p (x y) = ρ (x)/Z
θ θ θ θ θ
|
F(θ,q) Free energy functional (5)
I(θ,q) Extended Fisher information functional (12)
I(q π ) Relative Fisher information functional (13)
θ
||
Local maxima of the marginal likelihood
⋆
O
(Rdx) Space of probability measures with densities and finite second moments
2
P
Product spaces, := Rdθ (Rdx)
2 2 2
M M ×P
F’s optimal set in , = argminF = (θ ,π ): θ
M⋆
M
M⋆
{
⋆ θ⋆ ⋆
∈
O⋆
}
, and Euclidean inner product and norm
h· ·i k·k
, (Rdx,dx)’s inner product
h· ·iL2(dx) L2
, , , Wasserstein-2 and inner products (Definitions 1 and 2)
h· ·iW2 h· ·iM2 M2
d ,d and d Euclidean distance, Wasserstein-2 distance, and their product (9)
E W2
and Gradient and divergence operators
∇ ∇·
∆ Laplacian operator, ∆ :=
∇·∇
B Proofs for Section 2
B.1 Proof of Lemma 2
By comparing Definitions 3 and 4 we observe
d d d
dt
F(θ t,q t) = δ RdθF(θ,q),
dt
θ
t
+ δ P2(Rdx)F(θ,q),
dt
q
t
(cid:12)t=0 * (cid:12)t=0 + * (cid:12)t=0 + L2(dx)
(cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) (cid:12)
(cid:12) (cid:12) d (cid:12) d
= grad RdθF(θ,q),
dt
θ
t
+ grad P2(Rdx)F(θ,q),
dt
q
t
.
* (cid:12) (cid:12)t=0 + * (cid:12) (cid:12)t=0 + W2
(cid:12) (cid:12)
(cid:12) (cid:12)
23Let ψ denote the solution of (q ψ) = (dq /dt) . The first terms on the RHS
x x t t=0
∇ · ∇ − |
clearly coincide. We then have, upon equating the second terms on the RHS of the above
display and inserting ψ so defined:
d
grad P2(Rdx)F(θ,q),
dt
q
t
=
−
δ P2(Rdx)F(θ,q)(x)
∇x
·(q(x) ∇xψ(x))dx
* (cid:12) (cid:12)t=0 + W2 Z
(cid:12)
(cid:12) = ∇xδ P2(Rdx)F(θ,q)(x), ∇xψ(x) q(dx)
Z D E
where we integrated by parts. We conclude by noting that by Definition 1 we know that
grad P2(Rdx)F(θ,q) has to satisfy
−∇x
·(q ∇xδ P2(Rdx)F(θ,q)) = grad P2(Rdx)F(θ,q).
B.2 Proof of Proposition 5
Let φ(r):= rlog(r) and for a non-negative function f on Rdx Rdθ define the functionals
×
E (f):= φ(f)dπ φ f dπ ,
θ θ θ
−
Z (cid:18)Z (cid:19)
f 2
x
J (f):= |∇ | dπ ,
θ θ
f
Z
with E˜ (f) and J˜(f) denoting the corresponding functionals when the model is ρ˜ (dx):=
θ θ θ
π˜ (dx)Z . Importantly, notice that if f := dq/dπ , E (f) log(Z ) = F(θ,q) and J (f)+
θ θ θ θ θ θ
−
2
ℓ(θ;x)q(dx) = I(θ,q). We begin as in the proof of [6, Proposition 5.1.6] and use
θ
∇
the following variational formula.
(cid:13)R (cid:13)
(cid:13) (cid:13)
Lemma 18. Letting φ′(r) denote the derivative of φ at r, we have,
E (f)= inf [φ(f) φ(r) φ′(r)(f r)]dπ
θ θ
r>0 − − −
Z
Proof. Let X π . Since φ is convex, for any r > 0,
θ
∼
φ(E f(X) ) φ(r) φ′(r)(E f(X) r) 0
− − − ≥
so that, adding E φ(f(X))(cid:2) φ((cid:3)E f(X) ) both sid(cid:2) es, (cid:3)
−
E φ(f(X))(cid:2) φ(r) (cid:3) φ′(r)(f((cid:2) X) (cid:3) r) E φ(f(X)) φ(E f(X) ) = E (f)
θ
− − − ≥ −
with equ(cid:2) ality if and only if r = E f(X) . (cid:3) (cid:2) (cid:3) (cid:2) (cid:3)
By φ’s convexity φ(f) φ(r) (cid:2)φ′(r)((cid:3)f r) 0 for all r > 0, so using the formula above
− − − ≥
we can readily write
E˜ (f) cinf [φ(f) φ(r) φ′(r)(f r)]dπ = cE (f).
θ θ θ
≤ r>0 − − −
Z
Next, we take f := dq/dπ , which gives
θ
E˜ (f)+c(log(Z ) log(Z )) c[E (f)+log(Z ) log(Z )]= c[F(θ,q) F ]
θ ⋆ θ θ ⋆ θ ⋆
− ≤ − −
24and because (ρ θ(dx)) θ∈Rdθ satisfy the xLSI
f 2 2
2λ[E˜ (f)+c(log(Z ) log(Z ))] cI(θ,q) c2 |∇x | dπ˜ +c ℓ(θ;x)q(dx) .
θ ⋆ θ θ θ
− ≤ ≤ f ∇
Z (cid:13)Z (cid:13)
(cid:13) (cid:13)
Define now (cid:13) (cid:13)
(cid:13) (cid:13)
1dπ˜ dπ˜ f dq˜
q˜(dx):= θ (x)q(dx), c˜:= θ (x)q(dx), f˜(x) := (x) = (x),
c˜dπ dπ c˜ dπ˜
θ θ θ
Z
noting that q˜is a probability measure in 1(Rdx) under our assumptions. Since the func-
P2
tional E is homogeneous, i.e. E˜ (af)= aE˜ (f) for all a > 0, we may write
θ θ
2λ[F˜(θ,p) F˜ ] = 2λ[E˜ (f˜) log(Z )+log(Z )]
⋆ θ θ ⋆
− −
c
2λ[E˜ (f˜)+ (log(Z ) log(Z ))]
θ ⋆ θ
≤ c˜ −
c2 f 2 c 2
x
|∇ | dπ˜ + ℓ(θ;x)q(dx)
θ θ
≤ c˜ f c˜ ∇
Z (cid:13)Z (cid:13)
(cid:13) 2(cid:13)
(cid:13) dρ (cid:13)
c2 J˜(f˜)+ ℓ(θ(cid:13);x) θ (x)q˜(dx) (cid:13)
θ θ
≤ ∇ dρ˜
" (cid:13)Z θ (cid:13) #
(cid:13) (cid:13)
(cid:13) ρ (x) 2 (cid:13)
= c2 J˜(f˜)+(cid:13) ∇θ θ q˜(dx) (cid:13) (29)
θ
ρ˜ (x)
" (cid:13)Z θ (cid:13) #
(cid:13) (cid:13)
where in the first and penultimate inequalitie(cid:13)s we used c˜ c a(cid:13)nd log(Z ) log(Z ) 0.
(cid:13) (cid:13) ⋆ θ
≤ − ≥
By the inequality (a+b)2 2a2+2b2 ([37, p. 157]), Jensen’s inequality and the assumed
≤
growth condition on ρ˜ (x) ρ (x) ,
θ θ θ θ
∇ −∇
ρ (x) (cid:13) 2 (cid:13) 2 ρ˜ (x) ρ (x) 2
∇θ θ q˜(dx(cid:13)) 2 ℓ˜(θ;x(cid:13))q˜(dx) +2 ∇θ θ −∇θ θ q˜(dx)
θ
ρ˜ (x) ≤ ∇ ρ˜ (x)
(cid:13)Z θ (cid:13) (cid:13)Z (cid:13) Z (cid:13) θ (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)2 (cid:13) (cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2(cid:13)
(cid:13)
θℓ˜(θ;x)q˜(dx)(cid:13)
(cid:13)
+2b[lo(cid:13)
(cid:13)g(Z ⋆) log(Z θ)]
(cid:13)
(cid:13)
≤ ∇ −
(cid:13)Z (cid:13)
(cid:13) (cid:13)2
2(cid:13) (cid:13) θℓ˜(θ;x)q˜(dx)(cid:13) (cid:13) +2b[F˜(θ,q˜) F˜ ⋆]
≤ ∇ −
(cid:13)Z (cid:13)
(cid:13) (cid:13)
where in the last inequality w(cid:13)e used KL(q˜ π˜ ) (cid:13) 0. Combining this estimate with (29),
(cid:13) || θ ≥(cid:13)
2
2 λ c2 b [F˜(θ,q˜) F˜ ] 2c2 J˜(f˜)+ ℓ˜(θ;x)q˜(dx) = 2c2I˜(θ,q˜)
⋆ θ θ
− · − ≤ ∇
(cid:16) (cid:17) " (cid:13) (cid:13)Z (cid:13) (cid:13) #
(cid:13) (cid:13)
(cid:13) (cid:13)
B.3 Proof of Proposition 6
DenotewithF˜ andI˜thefreeenergyandextendedFisherinformationforthemodelρ˜ . Con-
θ
sider an arbitrary (θ,q˜) 1 and set q := T q˜. By assumption, π˜ (T(x))det( T(x)) =
∈ M2 # θ ∇x
π (x) and similarly for q’s density, hence, by a change of variables x T(x),
θ
7→
q˜(x) q˜(T(x))
F˜(θ,q˜) log(Z ) = log q˜(x)dx = log q˜(T(x))det( T(x))dx
θ x
− π˜ (x) π˜ (T(x)) ∇
Z (cid:18) θ (cid:19) Z (cid:18) θ (cid:19)
q(x)
= log q(x)dx = F(θ,q) log(Z )
θ
π (x) −
Z (cid:18) θ (cid:19)
25Thus, since q belongs to 1(Rdx) by the Lipschitz property of T, 2λ[F˜(θ,q˜) F ] =
2λ[F(θ,q) F ] I(θ,q)P b2 y the xLSI. On the other hand, if we let 2 de− note⋆ the
− ⋆ ≤ k·k∞
uniform norm,
2
2
q(x) π (x) π (x) Z
x x θ θ θ θ θ
I(θ,q)= ∇ ∇ q(dx)+ ∇ + ∇ q(dx)
Z (cid:13) q(x) − π θ(x) (cid:13) (cid:13) (cid:13)Z (cid:18) π θ(x) Z θ (cid:19) (cid:13) (cid:13)
(cid:13) (cid:13)
=
∇x(q˜(cid:13) (cid:13)(T(x))) ∇x(π˜ θ(T(x(cid:13) (cid:13)))) 2 q(dx(cid:13) (cid:13)
(cid:13))+
∇θ(π˜ θ(T(x)))
+
∇θZ(cid:13) (cid:13)
(cid:13)θ q(dx)
2
Z (cid:13) q˜(T(x)) − π˜ θ(T(x)) (cid:13) (cid:13) (cid:13)Z (cid:18) π˜ θ(T(x)) Z θ (cid:19) (cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13) (cid:13)2 (cid:13) 2
(cid:13) T 2 ∇T(x)q˜(T(x)) ∇T(x(cid:13))π˜ θ(T(x))(cid:13) (cid:13) q(dx)+ ∇θπ˜ θ(T(x)) + ∇θZ(cid:13) (cid:13)θ q(dx)
≤k∇x k∞ Z (cid:13) (cid:13) q˜(T(x)) − π˜ θ(T(x)) (cid:13) (cid:13) (cid:13) (cid:13)Z (cid:18) π˜ θ(T(x)) Z θ (cid:19) (cid:13) (cid:13)
(cid:13) (cid:13)2 (cid:13) (cid:13)
≤k∇xT k2 ∞I˜(q˜(cid:13) (cid:13) ||π˜ θ)+ ∇θlog(ρ˜(θ,x))q˜(x)dx(cid:13) (cid:13)
≤
max((cid:13) (cid:13)1, k∇xT k2 ∞)I˜(θ,q˜) (cid:13) (cid:13)
(cid:13)Z (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
where in the second (cid:13)line we substituted the e(cid:13)xpression for the density of q˜(T(x)) and
π˜ (T(x)) (noting that the terms with the determinant cancel), in the third we used the
θ
chain rule and the fact that T does not depend on θ, and in the fourth we used the formula
for q(x) and a change of variables T(x) x. We conclude by noting that L provides a
T
7→
bound on T .
k∇x k∞
C Proofs for Section 3
C.1 Proof of Lemma 11
Because of θ ’s minimality (21), by Jensen’s inequality and Assumption 2,
k+1
2
2
ℓ(θ ,x)p (dx) = E ℓ(θ ,Z ) ℓ(θ ,X ) L2E Z X 2
∇θ k+1 t ∇θ k+1 t −∇θ k+1 k ≤ x k t − k k
(cid:13) (cid:13)Z (cid:13) (cid:13) (cid:13) (cid:13) (cid:2) (cid:3)(cid:13) (cid:13) h i
(cid:13) (cid:13)
for(cid:13)any couplingof (Z t,X(cid:13)k). L(cid:13)et(θ †,x †)denotea stationary point(cid:13)of ℓ, sothat ℓ(θ †,x †)=
∇
0. Inserting the expression for Z , since Z = X a.s., using (a+b)2 a2 +b2, the fact
t kh k
≤
h 1/4L 2L (t t ) 1/2 and again Assumption 2,
x x −
≤ ⇒ − ≤
2
2
ℓ(θ ,x)p (dx) L2E E (t t ) ℓ(θ ,X )+√2(W W ) X
∇θ k+1 t ≤ x − − ∇x k+1 k t − t− | k
(cid:13)Z (cid:13) " (cid:20)(cid:13) (cid:13) (cid:21)#
(cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13) L (t t (cid:13) ) 2L (t t )E ℓ(θ ,X ) 2 +4d(cid:13) L
x − x − x k+1 k x x
≤ − − ∇
(cid:18) (cid:19)
1 h(cid:13) (cid:13) i
L (t t ) E ℓ(θ (cid:13) ,X ) 2 +4d L(cid:13)
x − x k+1 k x x
≤ − 2 ∇
(cid:18) (cid:19)
h(cid:13) (cid:13) i
L (t t )
L2 E(cid:13)
X x
2 +(cid:13)
θ θ
2
+4d L .
x − k † k+1 † x x
≤ − 2 − −
!
h(cid:13) (cid:13) (cid:13) (cid:13) i
(cid:13) (cid:13) (cid:13) (cid:13)
When q is given by an EM update, we now derive an uniform bound for E[ X x 2+
k k †
k − k
θ θ 2]. Consider the point (θ ,π ) corresponding to the projection of
k
k+1
−
†
k
⋆ θ⋆
∈
M⋆
(θ ,q )onto ,letX π andconsideranoptimalcouplingbetweenX andX q .
k+1 k M⋆ ⋆
∼
θ⋆ ⋆ k
∼
k
26By the definition of d , Theorem 3, together with the fact that the free energy can only
W2
decrease along EM iterations,
λE X X 2+ θ θ 2 2[F(θ ,q ) F ] 2[F(θ ,q ) F ].
k ⋆ k+1 ⋆ k+1 k ⋆ 0 0 ⋆
k − k k − k ≤ − ≤ −
h i
We conclude upon combining the two previously obtained inequalities via the bounds
X x 2 2 X x 2 +2 X X 2, and the analogous bound for θ θ 2 .
k † ⋆ † k ⋆ k+1 †
− ≤ − k − k −
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)
(cid:13)C.2 P(cid:13)roof o(cid:13)f Lemm(cid:13)a 16 (cid:13) (cid:13)
The following proof is a suitable generalization of the one of [54] and in particular of the
refinement in [18, Section 4.2] under the hypothesis of non-trivial parameter space, and
the proof is therefore somewhat similar. Consider the continuous time process given for all
t [kh,(k+1)h) and any k N by
0
∈ ∈
ϑ =θ dϑ = ℓ(ϑ ;x)p (dx)dt,
kh k t ∇θ t− t−
(30)
Z
Z =X dZ = ℓ(ϑ ;Z )dt+√2dW ,
kh k t ∇x t− t− t
wherewe set t := kh,p := Law(Z ) and where W is a Brownian Motion. Notice that this
− t t t
is an interpolation of the Algorithm 4 iterates. To prove Lemma 16 we need three auxiliary
results.
Lemma 19. If Assumptions 1–2 hold, (ϑ ,p ) :t t < t +h is a solution of the PDE
t t − −
{ ≤ }
∂ ϑ = ℓ(ϑ ;x)p (dx)+E[ ℓ(ϑ ;Z ) ℓ(ϑ ;Z )]
t t ∇θ t t ∇θ t− t− −∇θ t t
Z (31)
p
∂ p = p log t +p E[ ℓ(ϑ ; ) ℓ(ϑ ;Z )Z = ] .
t t ∇x
·
t ∇x
ρ
t ∇x t
·
−∇x t− t−
|
t
·
(cid:20) (cid:18) ϑt(cid:19) (cid:21)
Proof. Conditionally on (ϑ ,Z ) = (ϑ,z), (ϑ ,Z ) : t t < t + h has a time
t− t−
{
t t −
≤
−
}
independent drift, hence p ( z), the conditional density of Z given Z = z, is the
t|t−
·|
t t−
density of a Normal with mean z+(t t ) ℓ(ϑ;z) and variance 2(t t ). Hence, we can
− x −
− ∇ −
directly check that p solves the following PDE
t|t−
∂ ϑ = ℓ(ϑ ;x)p (dx),
t t ∇θ t− t−
Z
p
∂ p = p log
t|t−
= ∆ p (p ℓ(ϑ ;Z )).
t t|t− ∇x
·
t|t−∇x
ρ
x t|t− −∇x
·
t|t−∇x t− t−
(cid:20) (cid:18) ϑt−(cid:19)(cid:21)
OnecanalsoderivetheaboveimmediatelybyusingformulæfortheFokker–Planckequation
of Itˆo diffusions, see [47, Chapters 2 and 4]. We notice that all the derivatives of x
7→
p (x z) exist and are continuous in all arguments by Assumption 2, that z p (x z)
t|t−
| 7→
t|t−
|
is at least continuous for all x Rdx, and that t p (x z) is continuously differentiable
∈ 7→
t|t−
|
for all x,z Rdx. By Bayes’ rule, if we take expectation w.r.t. p ,
∈
t−
E p (x Z ) ℓ(ϑ ;Z ) = p (x z) ℓ(ϑ ;z)p (dz)
t|t−
|
t− ∇x t− t− t|t−
|
∇x t− t−
h i Z
= p (x) p (dz x) ℓ(ϑ ;z) = p (x)E ℓ(ϑ ;Z )Z = x
t t−|t
|
∇x t− t ∇x t− t−
|
t
Z
(cid:2) (cid:3)
27Hence, taking expectation in the Fokker–Planck equation, the regularity properties of p
t|t−
allow us to use the tower rule and compute
∂ ϑ = ℓ(ϑ ;x)p (dx), ∂ p = ∆ p (p E[ ℓ(ϑ ;Z )Z = ]).
t t ∇θ t− t− t t x t −∇x
·
t ∇x t− t−
|
t
·
Z
Adding and subtracting E[ ℓ(ϑ ;Z )] in the first expression and (p E[ ℓ(ϑ ; )Z =
θ t t x t x t t
∇ ∇ · ∇ · |
]) = (p log(ρ )) in the second yields the claim.
·
∇x
·
t ∇x ϑt
Lemma 20. If Assumptions 1–2 hold, for all t [t ,t +h),
− −
∈
3
∂ F(ϑ ,p ) I(ϑ ,p )+E ℓ(ϑ ;Z ) ℓ(ϑ ;Z ) 2 (32)
t t t
≤ −4
t t
∇
t t
−∇
t− t−
h(cid:13) (cid:13) i
Proof. By the regularity properties of p illu(cid:13)strated in the proof of the(cid:13)previous Lemma,
t|t−
p (x) = E[p (x,Z )] is smooth in x and at least continuously differentiable in t. This
t t|t− t−
allows us to compute
2
p (x) p (x)
t t
∂ F(ϑ ,p ) = log +1 p (x) log dx ℓ(ϑ ;x)p (dx)
t t t x t x θ t t
ρ (x) ∇ · ∇ ρ (x) − ∇
Z (cid:20) (cid:18) ϑt (cid:19) (cid:21) (cid:20) (cid:18) ϑt (cid:19)(cid:21) (cid:13)Z (cid:13)
p (x) (cid:13) (cid:13)
+ log t +1 [p (x)E[ ℓ(ϑ ,x) ℓ(ϑ ;(cid:13) Z )Z = x]]dx (cid:13)
ρ (x)
∇x
·
t ∇x t −∇x t− (cid:13)t−
|
t (cid:13)
Z (cid:20) (cid:18) ϑt (cid:19) (cid:21)
+E[ ℓ(ϑ ;Z ) ℓ(ϑ ,Z )]E[ ℓ(ϑ ;Z )]
∇θ t t −∇θ t− t− ∇θ t t
p (x)
= I(ϑ ,p )+ log t E[ ℓ(ϑ ;Z ) ℓ(ϑ ;x)Z = x]p (dx)
−
t t ∇x
ρ (x)
∇x t− t− −∇x t
|
t t
Z (cid:18) ϑt (cid:19)
+E[ ℓ(ϑ ;Z ) ℓ(ϑ ;Z )]E[ ℓ(ϑ ;Z )] (33)
∇θ t t −∇θ t− t− ∇θ t t
where we used the regularity of (ϑ ,p ) : t t < t + h to differentiate inside the
t t − −
{ ≤ }
integral and the chain rule in the first equality, and we integrated by parts for the second.
Now, by the Young’s inequality ab (a2/4)+b2 and then Jensen’s inequality, we have
≤
p (x)
log t E[ ℓ(ϑ ;Z ) ℓ(ϑ ;x)Z = x]p (dx)
∇x
ρ (x)
∇x t− t− −∇x t
|
t t
Z (cid:18) ϑt (cid:19)
1
I(p π )+ E[ ℓ(ϑ ;Z ) ℓ(ϑ ;x)Z = x] 2 p (dx)
≤ 4
t
||
ϑt ∇x t− t− −∇x t
|
t t
Z
1 (cid:13) (cid:13)
I(p π )+E (cid:13) ℓ(ϑ ;Z ) ℓ(ϑ ;Z ) 2 (cid:13)
≤ 4
t
||
ϑt ∇x t t −∇x t− t−
h(cid:13) (cid:13) i
and similarly (cid:13) (cid:13)
E[ ℓ(ϑ ;Z ) ℓ(ϑ ;Z )]E[ ℓ(ϑ ;Z )]
∇θ t t −∇θ t− t− ∇θ t t
2
1
ℓ(ϑ ;x)p (dx) +E ℓ(ϑ ;Z ) ℓ(ϑ ;Z ) 2
≤ 4
∇θ t t ∇θ t t −∇θ t− t−
(cid:13) (cid:13)Z (cid:13) (cid:13) h(cid:13) (cid:13) i
now by combining these l(cid:13)ast two estimates wi(cid:13)th (33)(cid:13)we prove the desired result.(cid:13)
(cid:13) (cid:13)
Our goal now is to obtain a bound on the rightmost term in (32) in terms of I.
Lemma 21. If Assumption 2 holds, for any θ Rdθ and q (Rdx) we have
2
∈ ∈ P
2
E ℓ(θ;X) +E ℓ(θ;X) 2 I(θ,q)+2Ld , where Law(X) = q.
θ x x
∇ ∇ ≤
(cid:13) (cid:13) (cid:2) (cid:3)(cid:13) (cid:13) h(cid:13) (cid:13) i
(cid:13) (cid:13)
(cid:13) (cid:13) 28Proof. Thisinequalityfollowsalmostimmediatelyfrom[18,Lemma4.2.5]or[19,Lemma16]
andthedefinitionofI(θ,q). Wereproducethoseproofshereinournotationforconvenience.
Consider the (overdamped) Langevin diffusion with stationary distribution π eℓ(θ;·). Its
θ
∝
2
generator satisfies ℓ(θ, ) = ∆ ℓ(θ; )+ ℓ(θ; ) . We can estimate directly
x x
L · · ∇ ·
E xℓ(θ;X) 2 = E ∆ xℓ(θ;X)+ ℓ(cid:13) (cid:13)(θ;X) (cid:13) (cid:13)
∇ − L
h(cid:13) (cid:13) i (cid:2) dq (cid:3)
(cid:13) (cid:13) Ld + ℓ(θ;x) (x)π (dx)
x θ
≤ L dπ
θ
Z
dq dq
2
= Ld + ℓ(θ;x) (x)π (x)+∆ ℓ(θ;x) (x)π (x)dx
x x θ x θ
∇ dπ dπ
θ θ
Z
(cid:13) (cid:13)
(cid:13) (cid:13)2 dq dq
= Ld + ℓ(θ;x) (x)π (x) ℓ(θ;x), (x)π (x) dx
x x θ x x θ
∇ dπ − ∇ ∇ dπ
Z θ * (cid:18) θ (cid:19)+
(cid:13) (cid:13)
(cid:13) (cid:13)
where in the second line we used ∆ ℓ(θ, ) Ld by Assumption 2, in the fourth integra-
x x
− · ≤
tion by parts. Now, with the product rule and the fact ℓ(θ;x)π (x) = π (x),
x θ x θ
∇ ∇
dq
E ℓ(θ;X) 2 =Ld ℓ(θ;x), (x) π (dx)
x x x x θ
∇ − ∇ ∇ dπ
h(cid:13) (cid:13) i Z (cid:28) θ (cid:29)
(cid:13) (cid:13) dq dq
=Ld 2 (x) ℓ(θ;x), (x) π (dx)
x x x θ
− *sdπ
θ
∇ ∇ sdπ
θ +
Z
2
1 dq
Ld + E ℓ(θ;X) 2 +2 (x) π (dx)
x x x θ
≤ 2 h(cid:13)∇
(cid:13) i Z (cid:13)
(cid:13)∇ sdπ
θ (cid:13) (cid:13)
1 1
=Ld x + E (cid:13) xℓ(θ;X)(cid:13)2 + I(q(cid:13) (cid:13)π θ), (cid:13) (cid:13)
2 ∇ 2 ||
h(cid:13) (cid:13) i
where we used the chain rule, and the(cid:13)Young’s ine(cid:13)quality ab (a2/4)+b2 again. Now re-
≤
arranging, adding E ℓ(θ;x) 2 to both sides and using the definition of I(θ,q) proves
θ
∇
the bound.
(cid:13) (cid:2) (cid:3)(cid:13)
(cid:13) (cid:13)
Having established these intermediate results we can return to the now straightforward
proof of the lemma of interest.
Proof of Lemma 16. By Assumption 2, the inequality (a+b)2 2a2+2b2, and Jensen’s,
≤
E ℓ(ϑ ,Z ) ℓ(ϑ ,Z ) 2 L2E (ϑ ,Z ) (ϑ ,Z ) 2
∇
t t
−∇
t− t−
≤
t t
−
t− t−
=h(cid:13) (cid:13)L2(t t )2 E ℓ(ϑ ,Z(cid:13) (cid:13) i ) 2 +Eh(cid:13) (cid:13) ℓ(ϑ ,Z ) 2 (cid:13) (cid:13)+i 2L2E W W 2
−
− ∇θ t− t− ∇x t− t− t
−
t−
2L2(t t )2(cid:26)(cid:13) (cid:13) (cid:13) E(cid:2) ℓ(ϑ ,Z ) (cid:3)2(cid:13) (cid:13) (cid:13)+E h(cid:13) (cid:13) ℓ(ϑ ,Z ) 2 +(cid:13) (cid:13) Ei(cid:27) ℓ(ϑ ,Zh(cid:13) (cid:13) ) ℓ(ϑ (cid:13) (cid:13) ,Zi ) 2
≤ −
− ∇θ t t ∇x t t
∇
t t
−∇
t− t−
+2L2E W (cid:26) W(cid:13) (cid:13) (cid:2)2 (cid:3)(cid:13) (cid:13) h(cid:13) (cid:13) (cid:13) (cid:13) i h(cid:13) (cid:13) (cid:13) (cid:13) i(cid:27)
t
−
(cid:13)t− (cid:13)
h(cid:13) (cid:13) i
Hence, if(cid:13)h 1/2L (cid:13) 1/2 (1 2L2(t t −)2) we can then rearrange into
≤ ⇒ ≤ − −
1
E ℓ(ϑ ,Z ) ℓ(ϑ ,Z ) 2 (1 2L2(t t )2)E ℓ(ϑ ,Z ) ℓ(ϑ ,Z ) 2
2 ∇
t t
−∇
t− t−
≤ − −
−
∇
t t
−∇
t− t−
h(cid:13) (cid:13) i2 h(cid:13) (cid:13) i
2L(cid:13)2(t t )2 E ℓ(ϑ ,Z(cid:13)) +E ℓ(ϑ ,Z ) 2 (cid:13)+2L2d (t t ) (cid:13)
− θ t t x t t x −
≤ − ∇ ∇ −
(cid:26)(cid:13) (cid:13) (cid:2) (cid:3)(cid:13) (cid:13) h(cid:13) (cid:13) i(cid:27)
(cid:13) (cid:13)
(cid:13) (cid:13)
29if further h 1/4L 4L2(t t )2 1/4, we can use Lemma 21 to estimate
−
≤ ⇒ − ≤
1
E ℓ(ϑ ,Z ) ℓ(ϑ ,Z ) 2 I(ϑ ,p )+8L3d (t t )2+4L2d (t t )
∇
t t
−∇
t− t−
≤ 4
t t x
−
− x
−
−
h(cid:13) (cid:13) i 1
(cid:13) (cid:13) I(ϑ t,p t)+6L2d x(t t −)
≤ 4 −
where we used 8L(t t ) 2. We conclude by combining this inequality with Lemma 20.
−
− ≤
C.3 Proof of Theorem 17
By the descent Lemma 16 and the xLSI we have
1
∂ [F(ϑ ,p ) F ] I(ϑ ,p )+6L2d (t t ) λ[F(ϑ ,p ) F ]+6L2d (t t ).
t t t ⋆ t t x − t t ⋆ x −
− ≤ −2 − ≤ − − −
Now we proceeding similarly to the proof of Theorem 12, and write
∂ etλ[F(ϑ ,p ) F ] 6L2d hetλ.
t t t ⋆ x
− ≤
h i
so that integrating from t = kh to t = (k+1)k gives
[F(ϑ ,p ) F ] e−hλ[F(ϑ ,p ) F ]+6L2d h2.
(k+1)h (k+1)h ⋆ kh kh ⋆ x
− ≤ −
We conclude by iterating the above inequality, and by combining the result with the exten-
sion of Talagrand inequality via Theorem 3.
30