DART2: a robust multiple testing method to smartly leverage
helpful or misleading ancillary information
Jichun Xie and Xuechan Li
September 6, 2024
Abstract
In many applications of multiple testing, ancillary information is available, reflecting the hypoth-
esis null or alternative status. Several methods have been developed to leverage this ancillary
informationtoenhancetestingpower,typicallyrequiringtheancillaryinformationishelpfulenough
toensurefavorableperformance. Inthispaper,wedeveloparobustandeffectivedistance-assisted
multiple testing procedure named DART2, designed to be powerful and robust regardless of the
qualityofancillaryinformation. Whentheancillaryinformationishelpful,DART2canasymptotically
control FDR while improving power; otherwise, DART2 can still control FDR and maintain power
at least as high as ignoring the ancillary information. We demonstrated DART2’s superior perfor-
mancecomparedtoexistingmethodsthroughnumericalstudiesundervarioussettings. Inaddition,
DART2 has been applied to a gene association study where we have shown its superior accuracy
androbustnessundertwodifferenttypesofancillaryinformation.
Keywords: Multipletesting,Ancillaryinformation,Robustinference,Falsediscoverycontrol.
1
4202
peS
5
]LM.tats[
1v81630.9042:viXra1 Introduction
Multiple testing is a useful statistical framework that has been widely applied to genomics, clinical
trials,neuroimaging,andenvironmentalstudies. Inmanystudiesinthesefields,ancillaryvariablesare
available to provide contextual information about the hypothesis. One commonly seen assumption is
that these ancillary information, such as genetic annotations, patient demographic variables in clinical
trials, and neuron spatial locations in neuroimaging studies imply the null or alternative statuses of the
hypothesesregardinggeneticvariants,patients,orbrainneurons.
Under the assumption, many methods have been developed to leverage the ancillary information to
improve testing accuracy. A popular approach is covariate-adaptive testing, which convert ancillary
information into covariates linked to each hypothesis. Those methods gain power by incorporating co-
variates through parametrically modeling the distribution of testing statistics or the proportion of null
hypotheses (Leung and Sun, 2022; Lei and Fithian, 2018; Yun et al., 2022; Cai et al., 2022; Qiu et al.,
2021). Another category includes methods that employ non-parametric models to categorize hypothe-
sesintogroupsbasedontheirancillaryinformation,subsequentlyenhancingpowerthroughtheaggre-
gationofp-values(Zhangetal.,2011;Lietal.,2023)ortheapplicationofweightedp-valueswithinthese
groups (Hu et al., 2010; Barber and Ramdas, 2017; Yang et al., 2024). Although these methods can
improve testing accuracy when the ancillary information correctly implies the hypothesis status follow-
ing their proposed models, they may suffer from inflated false discovery rates (FDR) or reduced power
when this assumption does not hold. Especially, many methods require specifying correct parametric
models or priors, which can be challenging in practice, and thus greatly compromise the performance
ofthemethodsinrealdataanalysis.
Toaddressthischallenge,weintroduceDART2,whichdoesnotrelyonaccuratelyspecifyingtheancil-
laryinformation;itimprovestheFDRcontrolandpowerofmultipletestingatdifferentlevelsofancillary
information quality. DART2 has two stages: screening and refining. The screening stage is similar to
DART (Li et al., 2023); it hierarchically aggregates the hypotheses based on their ancillary information
and test them at different resolution levels; the screened out hypotheses will be recorded. If we stop
atthisstage,whentheancillaryinformationdoesnotcorrectlyreflectthehypothesisstatus,thetesting
results may have inflated FDR. Thus, DART2 adds the refining stage to examine all the screened-out
2hypotheses again and selectively reject them based on their testing statistics. This selection strategy
ensuresthattheFDRcontrolisguaranteedevenwhentheancillaryinformationisnotaccurate.
Comparedtotheexistingmethods,DART2hastwomajorbenefits:
• Robust and powerful regardless of the quality of ancillary information: DART2’s unique refining
stage guarantees the FDR control even when the ancillary information does not correctly reflect
the hypothesis status. DART2 ensures asymptotic type I error control even if the ancillary infor-
mation is wrong, and its power at least matches Benjamini-Hochberg (BH) procedure(Benjamini
andHochberg,1995),therebyprovidingarobustandeffectivetoolforhypothesistesting. Onthe
otherhand,whenancillaryinformationpartiallyreflectthehypothesisstatus,DART2canimprove
power,matchingtheperformanceofotherancillaryinformation-basedmethods.
• Fewerconstraintsontheformatofancillaryinformation: Mostexistingmethodsdemandthatan-
cillary information be explicitly linked to each hypothesis individually. In contrast, our approach
relies on ancillary information structured as an aggregation tree, requiring only the mutual infor-
mationbetweenhypotheses. Insuchanaggregationtree,hypotheseswithgreatersimilaritiesare
clusteredtogether,sharingmorecommonancestornodes,eliminatingtheneedforinformationto
be attached to each hypothesis directly. More details about the aggregation tree can be found in
section2.
Therestofthepaperisorganizedasfollows. Section2introducestheDART2methodanditstheoretical
properties. Section3presentssimulationstudiesthatcompareDART2withothercompetingmethods.
Section 4 demonstrates DART2’s superior performance in a gene association study compared to the
competingmethods. Section5discussestheresultsandconcludesthepaper.
2 Methods
2.1 Hypotheses and aggregation tree
SupposemnullhypothesesformthenullsetΩ andm alternativehypothesisformthealternativeset
0 1
Ω , with Ω ∩Ω = ∅, and |Ω ∪Ω | = m +m = m. For any set A, the notation |A| represents its
1 0 1 0 1 0 1
cardinality.
3DenotetheteststatisticforhypothesisibyT . WeassumeT followsN(θ ,1)withθ ≤ 0ifi ∈ Ω . For
i i i i 0
example, Wald tests usually generate statistics asymptotically following these distributions under the
null. More generally, if P-values P are summarized for tests, we can transform them to test statistics
i
T by T = Φ−1(1 − P ), where Φ−1(·) is the inverse standard Gaussian distribution function. The
i i i
alternativedistributionofT couldbeflexible,althoughundertraditionalhypothesistestingsettings,we
i
oftenassume
P(T < x | i ∈ Ω ) ≥ P(T < x | i ∈ Ω ).
i 0 i 1
Infact,thedistributionrequirementofT canbefurtherrelaxed. Forexample,thenulldistributionofthe
i
null P-value statistics P might be asymptotically super-uniform. See Li et al. (2023) for more details.
i
Wefocusonlessgeneralcasesinthispaperforkeepingtheasymptoticresultssimple.
To implement DART2, we need an aggregation tree T to summarize the ancillary information. Li et al.
(2023) introduces an algorithm to construct T based on the distances between hypotheses: a shorter
distancebetweentwohypothesessuggestthattheyaremorelikelytobeco-nullorco-alternative. After
applying the tree construction algorithm, let the resulting aggregation tree be T = {A(1),...,A(L)}.
A(ℓ) is the node set of level ℓ of the tree; each node is a set of hypotheses that will be tested on this
layer. A(1) is the leaf node set, containing individual hypotheses A(1) = {{1},...,{m}}. On a higher
layer A(ℓ) (ℓ ≥ 2), close nodes from A(ℓ−1) are merged to form nodes in A(ℓ). For any S ∈ A(ℓ), its
childrensetisdenotedbyC(S),asubsetofA(ℓ−1).
Although any finite layer and finite children aggregation tree can be used to implement DART2, proper
tuningparametersettingmighthelpachievebetterresultsforDART2. Theseparameterscanbeimple-
mentedwiththetreeconstructionalgorithminLietal.(2023).
• Maximum children size M: We recommend setting M = 2. Larger values of M might lead to
some nodes containing many hypotheses, which need to be re-examined in the refining stage.
Too many large nodes will decrease the statistical and computational efficiency of the refining
stage.
• Maximum layer number L: Our approach mirrors that of DART in establishing the maximum
number of layers, defined by L = ⌊log m−log c ⌋, with c indicating the preferred number
M M m m
of nodes at layer L. Previously, DART (Li et al., 2023) suggested using c ≥ 35 to ensure
m
asymptoticFDRcontrol. BecauseDART2isamorerobustalgorithm,wecanlowerc to5. Inall
m
4numericalandempiricalexperimentsinthispaper,wesetc = 5togetthemaximumnumberof
m
layers and thus maximum power. Besides, The robustness of DART2 across various L values is
examinedinsection3.
Otherthanbeingconstructedbasedonthedistancematrix, theaggregationtreecanalsobeobtained
from prior knowledge, such as Phylogenetic trees and genealogy trees. A phylogenetic tree illustrates
the evolutionary connections between biological entities (e.g. species or taxa); and a genealogy tree
shows the inheritance relationships between family members. In both examples, closer nodes on the
tree indicate the entities share a more recent common ancestor, suggesting their possible similarities
intheirphysicalorgeneticcharacteristics. Ifeachbiologicalentityorfamilymemberonthetreeleaves
forms a hypothesis regarding its function or phenotype, then these trees can be used to implement
DART2.
2.2 Algorithm
DART2 has two stages: screening and refining. In the screening stage, DART2 go through the ag-
gregation tree to screen out hypothesis sets (nodes) that might contain alternative hypotheses. In the
refiningstage,DART2examinesallscreened-outhypothesestoselectasubsetthatismorelikelytobe
alternative.
DART2’s algorithm is outlined in Algorithm 1, with details explained afterwards. A toy example with 7
hypothesesarrangedunderapredefined3-layeraggregationtreeisillustratedinFigure1.
Screeningstage
Inthescreeningstage,DART2willtestallnodes(hypothesissets)intheaggregationtreefromtheleaf
layertothetoplayer. Thepurposeistoscreensomehypothesissetsthatprobablycontainoneormore
alternativehypotheses. Hereweintroducethetechnicaldetails.
ForanynodeS ontheaggregationtree,wedefinethenode-levelhypothesisasfollows:
H : forallj ∈ S,j ∈ Ω versusH : thereexistssomej ∈ S suchthatj ∈ Ω . (1)
0,S 0 A,S 1
Therefore, a screened-out node indicates strong evidence that it contains at least one alternative hy-
5(a) Aggregation Tree (b) Stage I: Screening (c) Stage II: Refining
Layer 3 5 6
2 7
Layer 2 3
4 5 6
2 7
1 1
Layer 1 1 2 3 4 5 6 7 3 3
4 5 6 4 5 6
2 7 2 7
Edge: Non-Candidate Candidate
Bins Bins
Color: Selected Bins Selected Bins Not selected
in Stage I in Stage II Bins
Figure1: AnillustrationexampleofDART2procedurewith7features. (a)Anaggregationtreeobtained
from prior knowledge, comprising L = 3 layers with a maximum of two children allowed for each node
(M = 2);(b)Screeningprocessembedintheaggregationtree,whereeachparentnodeisassociated
with a node-level hypothesis. Nodes on the aggregation tree are depicted as bins, with higher bins
corresponding to nodes with a larger test statistics T ; (c) Refining process for further selecting the
S
featureslocatedwithinthenodes(bins)thatwerescreened-outinStageI.Therejectedhypotheseson
eachlayerispresentedasR(ℓ) inthefigure,andthefinalrejectionsetisR = {1,3,5,6}.
6Algorithm1:DART2procedure
Data: TeststatisticsT ,...,T ;treeT = {A(ℓ) : ℓ ∈ [L]}.
1 m
Result: RejectedhypothesesR,ℓ ∈ [L].
//Screeningstage
Onlayer1(leaflayer),setthenodescreeningthresholdcˆ(1) as(2);
InitializetherejectionsetR = {i : T > cˆ(1)};
i
R = {{i} : T > cˆ(1)}; //Initializethescreened-outnodeset
node i
forℓ ∈ {2,...,L}do
A˜(ℓ) = {A\R : A ∈ A(ℓ),R = {i : i ∈ S,S ∈ R }}; //Removetherejectedhypothesis
node
fromallnodes
DefinethequalifiednodesetB(ℓ) = {S : S ∈ A˜(ℓ),|C(S)| ≥ 2};
DerivethenodetestingstatisticsT asin(3)foreachS ∈ B(ℓ);
S
Setthenodescreeningthresholdcˆ(ℓ) asin(4);
Updatethescreened-outnodesetR = R ∪{S : T > cˆ(ℓ)}.
node node S
//Refiningstage
ForallS ∈ R ,settherefiningthresholdtˆ asins(5);
node S
UpdatetherejectionsetasR = R∪{i : i ∈ ∪ S, T ≥ tˆ }
S∈R i S
node
pothesis. On layer 1, each node is a singleton set, and the node-level hypothesis is equivalent to the
individualhypothesis. Thus,ascreened-outnodeonlayer1correspondstoarejectedhypothesis.
DART2’slayer1nodethresholdissameasDART:
(cid:26) (cid:80) |S|Φ¯(c) (cid:27)
cˆ(1) = inf α ≤ c ≤ α : S∈B(ℓ) ≤ α , (2)
m (cid:80)
max{ |S|I{T > c},1}
S∈B(ℓ) S
where α = (mlogm)−1, and Φ¯(·) is the complementary cumulative density function of standard
m
Gaussian,definedasΦ¯(·) = 1−Φ(·). Thisthresholdhasbeenusedinothermultipletestingliterature
(Liuetal.,2013;XieandLi,2018).
On layer ℓ (ℓ ≥ 2), we recursively define A˜(ℓ) as the node set on layer ℓ after removing the rejected
hypotheses from the previous layer. The qualified node set B(ℓ) is defined as the set of nodes with at
least two children; all nodes in B(ℓ) will be tested on layer ℓ. We exclude those nodes with only one
childbecausetheyhavebeentestedbeforelayerℓ.
For any node S ∈ B(ℓ), we define the node-level statistic T using the Stouffer aggregation (Stouffer
S
7etal.,1949)fortestingthenode-levelhypothesis(1):
(cid:88) (cid:112)
T = T / |S|. (3)
S i
i∈S
Thenodescreeningthresholdtˆ(ℓ) is
(cid:26) (cid:80) |S|Φ¯(c) (cid:27)
cˆ(ℓ) = inf α ≤ c ≤ α(ℓ) : S∈B(ℓ) ≤ α(ℓ) , (4)
m (cid:80)
max{ |S|I{T > c},1}
S∈B(ℓ) S
where α(ℓ) is the layer-specific node FDR control level. Although in theory setting α(ℓ) = α still guar-
anteesDART2’sFDRcontrol(seeproofoftheorem1inAppendixB.1),numericalstudiessuggestthat
optimal performance in finite samples is achieved through a more conservative approach. Specifically,
werecommendsettingα(ℓ) = α/max{|S| : S ∈ B(ℓ)}forbestfinitesampleperformancesuggestedby
numericalstudies.
Refiningstage
Iftheancillaryinformationdoesnotreflecthypothesisstatustheaggregationtreemightfailtoaggregate
co-nullorco-alternativehypothesesinthesamenode. Therejectionsofthesenodesmightonlyindicate
that the node contains at least one alternative hypothesis, not that all hypotheses in the node are
alternative. Therefore,wefurtherdefinearefiningthreshold;amongallhypothesesinthescreened-out
nodes,onlythosewithtestingstatisticsexceedingthisthresholdwillberejected.
Foranyscreened-outnodeS ∈ R(ℓ),
(cid:88) (cid:112)
T ≥ cˆ(ℓ) ⇐⇒ T /|S| ≥ cˆ(ℓ)/ |S|.
S i
i∈S
(cid:112)
Thus,individualhypotheseswithT ≥ cˆ(ℓ)/ |S|contributemoretothenoderejection. Intuitively,these
i
hypothesesaremorelikelytobealternative. Basedonthisidea,weproposeanaiverefiningthreshold
tˆ∗ = cˆ(ℓ)/(cid:112) |S|foranyscreened-outnodeS ∈ B(ℓ),andonlyrejecthypotheseswithT ≥ tˆ∗.
S i S
Theorem1. Assumethenumberofalternativehypothesism
1
= O(mr1)forsomer
1
< (ML−1+1)−1,
DART2 with naive refining threshold tˆ∗ controls the FDR at any pre-specified level α ∈ (0,1), i.e.,
S
lim FDR ≤ α.
m,n→∞
Although Theorem 1 shows the Naive refining threshold tˆ∗ provides asymptotic validity in theory, we
S
8found that it is too liberal in practice. Numerical studies suggest that the naive method might lead to
moderateFDRinflationunderfinitesampleandhypothesiscase. Onepossiblereasonoftheinflationis
that,higher-layernodescontainmanyhypothesesandtˆ∗ maybetoosmalltoexcludenullhypotheses.
S
Toaddressthis,amorerobustandconservativerefiningthresholdisproposed.
Definition1(Robustrefiningthreshold). Forascreened-outnodeS ∈ B(ℓ),itsrobustrefiningthreshold
isdefinedas
tˆ = min{tˆ ,tˆ },withtˆ = max{tˆ∗,Φ¯−1(α)}andtˆ = max{T ,i ∈ S}. (5)
S S,1 S,2 S,1 S S,2 i
The robust refining threshold introduces the lower bounds Φ¯−1(α) in tˆ to avoid excessively small
S,1
thresholds,whereΦ¯(·)isthecomplementcumulativedensityfunctionofthestandardGaussian.
Addi-
tionally, because the screened-out nodes is considered to contain at least one alternative hypothesis,
we set tˆ to ensure at least one hypothesis will be rejected. The following theorem ensures the
S,2
asymptoticFDRcontrolbyapplyingtherobustrefiningthreshold.
Theorem 2. Assume the number of alternative hypothesis m
1
= O(mr1) for some r
1
< (ML−1 +
1)−1, DART2 with robust refining threshold controls the FDR at any pre-specified level α ∈ (0,1), i.e.,
lim FDR ≤ α.
m,n→∞
3 Numerical Experiments
We set up m = 1000 hypotheses. The hypothesis status is determined by {η : i ∈ [m]}, which are
i
independentlygeneratedbythefollowingrules:
(cid:110) (cid:111)
η = {[3.4ϕ (d )−0.6]∨0}+3ϕ (d )−0.1 ∨0,
i 1 156,i 2 800,i
where ϕ and ϕ are the probability density functions of N(0,1) and N(0,0.1), respectively. If η = 0,
1 2 i
then hypothesis i is null; otherwise, it is alternative. After fixing the random seed to generate η , we
i
obtained 216 alternative hypotheses and the rest are null. Our aim is to test these hypotheses with a
desiredFDRα ∈ {1%,5%}.
Suppose all hypotheses are in a two-dimensional Euclidean space. Under the ideal case, shorter
distances between hypotheses imply a higher likelihood of two hypotheses’ co-null or co-alternative
9status. Especially, for our numerical experiments, the alternative hypotheses are concentrated within
twoclusters,asshowninAppendixFigureA1. Thus,undertheidealcase,thedistancescanbetreated
ashelpfulancillaryinformationtoimprovetestingaccuracy.
Toevaluatemethodrobustness,wealsoconsiderednon-idealscenariowheretheancillaryinformation
is less helpful. We introduced a misleading level τ ∈ [0,1] to represent the proportion of alternative
hypothesesrandomlyswitchedwithnullhypotheses. Thus,τ = 0representingfullyinformativeancillary
information and τ = 1 indicating completely non-informative (misleading) ancillary information. We
varied τ ∈ {0,0.2,0.4,0.6,0.8,1.0} to systematically evaluate and compare DART2’s performance
againstothermethods.
Regardlessofthehelpfulnessoftheancillaryinformation,weappliedtheaggregationtreeconstruction
algorithm in DART(Li et al., 2023) to build the aggregation tree. The maximum number of children for
eachnodeissetasM = 2,andbysettingc = 5,themaximumnumberoflayersisL = 7.
m
We used four settings to generate test statistics, denoted as SE1–SE3. SE1 simulated test statistics
following Gaussian distribution. SE2 simulated test statistics with intentionally misspecified null distri-
butionstoassessrobustness. SE3andSE4correspondtoWaldteststatisticsfromalinearregression
model and the Cox proportional hazard model, respectively. The details of the simulation settings are
providedinAppendixA.Eachsimulationforaspecificteststatistictypecomprises200repetitions.
EvaluatingDART2’svalidityandrobustness
WeappliedDART2toallsettingsandevaluateditsperformancewhentheaggregationtreelayernum-
ber L and the ancillary information misleading level τ. The performance is measured by average false
discovery proportion and sensitivity over the 200 repetitions. If DART2 stopped at layer 1, then this is
asymptotically equivalent to the Benjamini-Hochberg (BH) procedure(Benjamini and Hochberg, 1995).
TheresultsareshowninFigure2.
Based on the number of hypotheses m = 1000, we reach the root of the aggregation tree when L =
13; thus, 13 is the maximum possible number of layers in the aggregation tree. Across all L values,
DART2 consistently controls the FDR under the desired level α. This indicates that increasing testing
layers will not inflate the FDR. The testing sensitivity increases with L when L reaches 7 and keeps
10stable afterwards. This indicates that DART2 has already reached the maximum power at L = 7. To
save computation time, there is no need to further increase the layer number. This fits our suggested
aggregationtreeconstructioncriteriainSection2.1.
Across all misleading level τ, under all cases, DART2 controls the average FDP within the desired
level α. Besides, as τ increases, DART2’s sensitivity decreases a little, but still maintains a high level.
Specifically, when τ = 1, DART2’s power still increases as L increases; suggesting DART2’s superior
performance than the BH procedure even when the ancillary information is completely misleading.
This is because DART2 uses an aggregation structure to test aggregated node hypotheses; even if
the ancillary information does not help to construct the informative aggregation tree, DART2 may still
identifysomeadditionaltruealternativesbychance.
ComparingwithCompetingmethods
WecomparetheperformanceofDART2withfourdifferentmethods: BH,DART,AdaPT(LeiandFithian,
2018), and FDR (Zhang et al., 2011). AdaPT is an iterative FDR control procedure that incorporates
L
side information into testing. It proposed an EM algorithm to parametrically estimate the proportion of
nullsandthedensitiesofP-valuestoimplementthemethod. Meanwhile,FDR incorporatessideinfor-
L
mation by aggregating p-values from each hypothesis’s k nearest neighbors, using these aggregated
p-valuestoconductmultipletesting. Tosimplifycomparison, forDART2, weusedtheaggregationtree
withM = 2andL = 7followingtheoptimaltreeconstructioncriteriainSection2.1. Figure3showsthe
averageFDPandsensitivityofeachmethod. TheFDPandsensitivityerrorbarsareshowninAppendix
FigureA2.
Asexpected,BHprocedure’sperformanceisalmostthesameasDART2withL = 1. Itcansuccessfully
control the desired FDR no matter whether the ancillary information is helpful or not; however, BH’s
sensitivity is too low when the ancillary information is helpful or partially helpful. This is because BH
completelyignorestheancillaryinformation.
Twocompetingmethods,DARTandFDRLmaintainedhighersensitivitywhilecontrollingaverageFDP
at the desired level when τ = 0. However, their average FDP inflated as τ increases: DART has a
moderateinflation,andFDRLhasthelargestinflation. Also,weobservedawide90%FDPconfidence
intervalforDARTandFDRL(FigureA2). Sincethesimulationunderτ > 0involvesrandomlyswitching
11Test DART2 (1) DART2 (4) DART2 (7) DART2 (10) DART2 (13)
a =0.01 a =0.05 a =0.01 a =0.05
0.08 0.4
0.04 0.2
0.00 0.0
0.08 0.4
0.04 0.2
0.00 0.0
0.08 0.4
0.04 0.2
0.00 0.0
0.08 0.4
0.04 0.2
0.00 0.0
0.08 0.4
0.04 0.2
0.00 0.0
0.08 0.4
0.04 0.2
0.00 0.0
1 2 3 1 2 3 1 2 3 1 2 3
SE SE
Figure2: PerformanceofDART2wasevaluatedacrossvaryingnumbersoflayers,withdesiredfeature-
level FDR α ∈ {1%,5%}, and misleading level τ ∈ {0,0.2,0.4,0.6,0.8,1}. The bars indicate DART2’s
average performance (FDP and sensitivity) in testing m = 1000 hypotheses, while the error bars the
90%confidenceintervals(the5%and95%quantiles)overthe200repetitions. Theleftpanelshowsthe
average FDP, with dashed horizontal lines indicating the desired FDR level α. The right panel shows
theaveragesensitivity.
12
PDF
t
=0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t
=1
ytivitisneS
t
=0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t
=1the null and alternative hypotheses under each repetition, the wider confidence intervals suggest that
theirtestingresultsarenotrobust,highlydependingontheancillaryinformationevenifthemisleading
levelisthesame.
AdaPTeffectivelycontrolstheaverageFDPunderthedesiredlevel,evenwhentheancillaryinformation
ismisleading. Whenα = 5%,AdaPT’ssensitivityishigherthanDART2whenτ ≤ 0.2. However,when
α = 1%,AdaPT’ssensitivityiscloseto0,significantlyworsethanDART2. ThisindicatesthatAdaPT’s
performance relies on the quality of ancillary information, and it fails to identify true alternatives when
FDRcontrolcriterionisstringent.
DART2 outperforms all competing methods in terms of both average FDP and sensitivity. DART2
maintainstheaverageFDPwithinthedesiredlevelαandhasthehighestsensitivityacrossallsettings.
This indicates that DART2 is robust and powerful regardless of the quality of ancillary information and
thedesiredFDRlevel.
DART2 also demonstrates significantly higher computational efficiency. Across various simulation set-
tings and violation levels, the median computation time for a single repetition using DART2 is 17.7
seconds. Incontrast,AdaPThas11.7%runsthatfailtoconvergewithin1hour;amongthosethatsuc-
cessfullyconvergewithin1hour,themediancomputationtimeis540.9seconds. Thisisapproximately
30 times longer than that required for DART2. More details for the median computation time and the
average converging percentage by simulation settings and misleading levels are presented in Table 1
andTableA1.
Table1: MeanandstandarddeviationofthecomputationtimeforDART2andAdaPT*
AdaPT DART2
τ
SE=1 SE=2 SE=3 SE=1 SE=2 SE=3
0.00 941.1(891.4) 807.6(725) 1113.3(993.9) 18.1(2.8) 12(2.1) 23.1(3.2)
0.20 539.3(542.4) 550.7(552.7) 480.7(392.7) 18(2.8) 12(2.1) 23.2(3.1)
0.40 465.6(282.2) 467.3(294.2) 455.4(232.3) 17.9(2.8) 12(2) 23.2(3.1)
0.60 466.4(215.1) 442.5(78.7) 456.8(68.6) 17.7(2.8) 11.9(2.1) 23(3.2)
0.80 448.9(44.6) 437.5(45.7) 440.9(36.3) 17.9(2.8) 12.1(2.1) 23.1(2.9)
1.00 439.1(42.7) 471.3(256.4) 439.6(184.6) 17.9(2.9) 11.5(2.1) 21.8(3.5)
*Themeanandstandarddeviationarepresentedintheformatofmean(standarddeviation).ThecomputationtimeforAdaPT
iscalculatedbasedonlyonthoserepetitionsthatsuccessfullyconvergedwithin1hour.
13Test BH DART2 DART FDRL Adapt
a =0.01 a =0.05 a =0.01 a =0.05
0.6
0.15 0.3
0.10
0.05
0.00 0.0
0.6
0.15 0.3
0.10
0.05
0.00 0.0
0.6
0.15 0.3 0.10
0.05
0.00 0.0
0.6
0.15 0.3
0.10
0.05
0.00 0.0
0.6
0.15 0.3
0.10
0.05
0.00 0.0
0.6
0.15 0.3
0.10
0.05
0.00 0.0
1 2 3 1 2 3 1 2 3 1 2 3
SE SE
Figure 3: Performance comparison of the 7-layer DART2 with the competing method under different
types of testing statistics, different desired FDR level α and different misleading level τ. The primary
bars indicate the average performance over 200 repetitions. The left panel shows the average feature-
levelFDP,withdashedhorizontallinesindicatingthedesiredFDRα. Therightpanelshowstheaverage
feature-levelsensitivity.
14
PDF
t =0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t =1
ytivitisneS
t =0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t =14 Real Data Application
We applied DART2 to a breast cancer study, with pre-analyzed P-values to indicate the significance of differential gene
expressionsinresponsetoestrogeninbreastcancercells. ThedataisoriginallyfromtheNCBIGeneExpressionOmnibus
(GEO)databasewiththeaccessnumberGSE4668. Itcanalsobeaccessedthroughthe’GEOquery’package(Davisand
Meltzer, 2007). The dataset contains m = 22,283 genes in response to estrogen treatments in breast cancer cells with
different dosage levels. The objective is to identify the genes that respond to a low dosage of treatment. The analysis
involvescomparinggeneexpressionlevelsbetweenacontrolgroup(receivingaplacebo)andalow-dosetreatmentgroup,
using p-values to assess the evidence for changes in gene expression. The processed data includes two distinct sets of
geneorderings: 1)ahighlyinformativeorderingobtainedbasedonthedatafrompatientsreceivinghigherdosagelevelof
treatment, withgenesorderedbasedontheresponseleveltothesehigherdosages, and2)amedianinformativeordering
obtained based on the data from patients receiving intermediate dosage level treatment, organizing genes based on their
responseleveltothisintermediatedoselevel. Previously,LeiandFithian(2018)analyzedthisdatasetandderivedP-values
andorderingsforeachgenetoindicateiftheirgeneexpressionshavebeensignificantlyalteredbyestrogen.
Utilizingthehighlyinformativeorderingandthemedianinformativeordering,wedesignedastudytochecktheperformance
ofallmethodswhentheancillaryinformationispartiallyinformative. First,Wesetupthehypothesesforeachgenetotest
iftheirdifferentiallyexpressed. Next, weappliedDART2andfourcompetingmethodsBH,DART,AdaPT,andFDRLtothe
P-valuestatisticstogetherwiththehighlyinformativeorderingastheancillaryinformationwiththedesiredFDRα=5%.The
genesselectedbyatleasttwomethodsaresetasthebenchmark.Subsequently,weimplementallmethodswiththemedian
informativeordering,andthencompareeachmethod’stestingresultswiththebenchmark.Weusedsensitivityandprecision
tomeasuretheperformance.
Numberofgenesidentifiedalsoincludedinbenchmark
Sensitivity=
Numberofgenesincludedinbenchmark
Numberofgenesidentifiedalsoincludedinbenchmark
Precision=
Numberofgenesidentified
Figure 4 illustrates the performance for all methods except for the BH procedure. The BH procedure is not shown since it
failedtoidentifyanygenes. Tofacilitateaclearercomparison,theF1scorecontoursareincluded. TheF1scorerepresents
theharmonicmeanofprecisionandsensitivity, thusservingasanoverallaccuracymetric: ahighF1scoreindicateshigh
accuracy. FDRLischaracterizedbylowsensitivityandprecision,whileDARTisnotedforitshighsensitivitybutsignificantly
lowprecision. AdaPTstandsoutforitshighprecision,albeitwithlowersensitivity. DART2,ontheotherhand,achievesthe
highestF1scoreamongallmethods,indicatingitssuperioroverallperformance. Theseresultsalignwellwithoursimulation
studies,furtherdemonstratingDART2’srobustnessandpowerinrealdataapplications.
151.00
F1=0.9
0.75
Method
Adapt
DART
0.50 F1=0.7
DART2
FDRL
F1=0.5
0.25
F1=0.3
F1=0.1
0.25 0.50 0.75 1.00
precision
Figure4: F1scorecontourplotstocomparetheperformanceofDART2,AdaPT,DARTandFDRL.The
dashedlinerepresentstheF1scorecontour.
16
ytivitisnes5 Discussion
Inthispaper,weintroducedDART2,anoveltwo-stagerobusthypothesistestingmethodtoautomaticallyadapttothequality
of ancillary information. DART2’s stage 1 is very similar to DART. It hierarchically aggregates hypotheses based on their
ancillary information and tests them at different resolution levels. The major difference between DART and DART2 is that
DART2hasanadditionalstage2, therefiningstage, whichensuresFDRcontrolbyselectivelyrejectinghypothesesinthe
screened-out hypothesis set. In stage 2, each individual hypothesis is tested again separately, to ensure the hypothesis
level asymptotic FDR level control. Thus, when ancillary information is informative, it will improve power while maintaining
asymptoticFDRcontrol.Whenancillaryinformationismisleading,DART2stillasymptoticallycontrolFDRandmaintainpower
atleastashighastheBHprocedure.WedemonstratedthesuperiorperformanceofDART2throughnumericalstudiesunder
varioussettingsandappliedittoageneassociationstudy,whereweshoweditssuperioraccuracyandrobustnessundertwo
differenttypesofancillaryinformation.
Inournumericalstudies,wealsofoundthateveniftheancillaryinformationismisleading,itisstillpossiblethatDART2can
identifysomeadditionaltruealternativescomparedwiththeBHprocedure. Thus,itispossiblethatwecanfurtherimprove
thepowerofDART2bytryingmultiplerandomorderings.Wewillexplorethisdirectioninourfuturestudies.
17Appendix A Simulation details
Appendix A.1 Simulated data
Wegeneratedthreesimulationsettings,eachwithn=300observationsonm=1000hypotheses.Beforepresentingthethree
settings,let’sfirstdefinethenotationsthatwillbeconsistentlyusedacrossallofthem:
(cid:110) (cid:111)
η = {[5.1ϕ (d )−0.9]∨0}+4.5ϕ (d )−0.1 ∨0;
i 1 156,i 2 800,i
whereϕ 1andϕ 2arethePDFofN(0,1)andN(0,0.1),respectively.
√
SE1: Fornodei∈{1,...,m},thefeaturetestingstatisticsT iareindependentlygeneratedfromN( nθ i,1),withθ i = 1 5η i.
SE2: Considerthelinearmode
Y
i
=θ 0,i+θ 1,iW 1+θ 2,iW 2+ϵ i, withϵ∼N(0,1)
ThecovariatesW
1
andW
2
aresampledfromBinom(0.5)andUnif(0.1,0.5),respectively. Alsoletθ
0,i
= θ
2,i
= 0.1
andθ i =θ 1,i = 31η i.ThefeatureteststatisticT iistheWaldteststatistics.
SE3: Considerthecoxregressionmodel
λ (t)=λ (t)exp{θ W +θ W }
i 0i 1,i 1 2,i 2
Whereλ i(t)andλ 0i(t)isthehazardandbaselinehazardattimet,respectively. Setθ
0,i
=θ
2,i
=0.1andθ
i
=θ
i
=
1 2η i. The covariates W 1 and W 2 are sampled from Binom(0.5) and Unif(0.1,0.5), respectively. The event time is
generatedfromtheexponentialdistributionwithrateexp{θ 1,iW 1+θ 2,iW 2},andthecensoringtimeissampledfrom
Unif(0,5).ThefeatureteststatisticT iisobtainedfromtheWaldtest.
Appendix A.2 Tunning parameter settings
Inourstudy,weappliedvariousstatisticalmethodstothethreenumericalsettingsincludingDART,DART2,BHprocedure,
the FDRL procedure, and AdaPT. The BH method does not require tuning parameters. For DART, following the tuning
parameterselectioncriteriafromSection3.3inLietal.(2023),weconstructeda4-layeraggregationtreewithM = 2and
distancethresholds: g(2) = 1.33, g(3) = 1.56, g(4) = 1.90. ForRDART,followingthesimilarparameterselectioncriteria,
we constructed the aggregation tree up to 13 layers, with M = 2 and distance thresholds: g(2) = 1.33, g(3) = 1.56,
g(4) = 1.90,g(5) = 2.10, g(6) = 2.60, g(7) = 3.93, g(8) = 4.13, g(9) = 4.96, g(10) = 5.40, g(11) = 6.96, g(12) =
9.58, g(13) = 12.12. For the FDRL methods, following recommendations from Zhang et al. (2011), we set k = 5 for
our simulations, as it is suggested to use an odd number greater than three. Zhang et al. (2011) introduced two types of
FDRL methods: FDRL I and FDRL II, but we only applied the FDRL II method in this paper given its consistent better
performancecomparedtotheFDRLI(Zhangetal.,2011;Lietal.,2023). WithAdaPT,wefollowedtheinstructionsfoundat
https://cran.r-project.org/web/packages/adaptMT/vignettes/adapt_demo.html to set up its tuning parameters.
During the simulation, we observed that AdaPT occasionally failed to produce results after extended processing times. To
ensuretheintegrityofourfindings,Figure3onlyincludesdatafromrepetitionswhereAdaPTsuccessfullydeliveredresults
A1L−eta
4
0.5
1.0
3
1.5
2.0
2
2.5
1
Feature
Alternative
0
−6 −3 0 3 6 Null
d1
Figure A1: Illustration of the simulated hypotheses’ affiliated location and their corresponding η . Each
i
hypothesis is represented by a dot. The dot color stands for the hypothesis status; and its size is
L-eta = log(η +1)+0.01,whichisproportionaltothesignalstrength.
i
A2
2dwithin 1 hour of processing. Table A1 summarizes the number of failed repetitions across different scenarios among 200
repetitions.
TableA1: Percentageofrepetitionfailstodelivertestingresultwithin1hour.
τ
SE
0 0.2 0.4 0.6 0.8 1
1 17.0% 16.5% 8.0% 2.5% 3.0% 2.5%
2 10.5% 14.5% 14.0% 24.5% 33.0% 22.0%
3 24.5% 13.5% 1.5% 1.5% 0 1.5%
Appendix A.3 Additional simulation outputs
Figure A2 displays the simulation results along with 90% error bars to illustrate the variability of the outcomes across 200
repetitions.
Test BH DART2 DART FDRL Adapt
a =0.01 a =0.05 a =0.01 a =0.05
0.6
0.4
0.2 0.3
0.0 0.0
0.6
0.4
0.2 0.3
0.0 0.0
0.6
0.4
0.2 0.3
0.0 0.0
0.6
0.4
0.2 0.3
0.0 0.0
0.6
0.4
0.2 0.3
0.0 0.0
0.6
0.4
0.2 0.3
0.0 0.0
1 2 3 1 2 3 1 2 3 1 2 3
SE SE
Figure A2: Performance comparison of the 7-layer DART2 with the competing method under different
types of testing statistics, different desired FDR level α and different misleading level τ. The primary
bars indicate the average performance over 200 repetitions. while the error bars represent the 90%
confidence intervals, denoting the 5% and 95% quantiles from 200 simulations. The left panel shows
the average feature-level FDP, with dashed horizontal lines indicating the desired FDR α. The right
panelshowstheaveragefeature-levelsensitivity.
A3
PDF
t
=0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t
=1
ytivitisneS
t
=0
t
=0.2
t
=0.4
t
=0.6
t
=0.8
t
=1Appendix B Proofs
Appendix B.1 Proofs of main theorems
Notethatintheproof,weareprovingastrongerversionofthetheorem1and2,withα(ℓ) =α,ℓ=1,...,L.
We introduce some notations before we provide the proofs. On layer ℓ, for a working node S ∈ B(ℓ), let U(S) = {S′ ⊂
S : S′ ∈ ∪ℓ−1 B(ℓ′)} be the collection of sets in the testing path of S. In addition, let Uc(S) = {S′′ ∈ ∪ℓ−1 B(ℓ′) :
ℓ′=1 ℓ′=1
S′′ ∩S = ∅,S′′ ∪S ⊂ A, forsomeA ∈ A(ℓ)} be the collection of sets that was planning to combined with S on layer
ℓ of the static aggregation tree but rejected on previous layers. When S ∈ B(1), we set U(S) = Uc(S) = ∅. We define
G S(c)asthecomplementaryCDFconditionalonprevioustestingresults. Whenℓ=1,wehaveS ={i}⊂{1,...,m},and
G S(c) = P(Z i ≥ c) with Z 1,...,Z m i∼id N(0,1). When ℓ > 1, the oracle rejection path for set S ∈ B(ℓ) is recursively
definedas
Q( z1:ℓ−1) ={z:∀S′ ∈U(S),G S′(Z S′)≥tˆ(ℓS′)(α),∀S′′ ∈Uc(S),G S′′(Z S′′)≤tˆ(ℓS′′)(α)},
where
G S(c)=P(cid:0) Z
S
≥c(cid:12) (cid:12)Q( z1:ℓ−1)(cid:1)
andZ S =(cid:80) i∈SZ i/(cid:112) |S|,andℓ S′,ℓ S′′ ∈{1,...,ℓ−1}isthevalues.t.S′ ∈B(ℓS′)andS′′ ∈B(ℓS′′),respectively.
GivenZ 1,...,Z maremutuallyindependent,wehave
G S(c)=P(cid:0) Z
S
≥c(cid:12) (cid:12)∀S′ ∈U(S),G S′(Z S′)≥tˆ(ℓS′)(α)(cid:1)
GiventhedefinitionofG S(c),wedefinetherejectionpathas
Q(1:ℓ−1) ={t:∀S′ ∈U(S),G S′(T S′)≥tˆ(ℓS′)(α),∀S′′ ∈Uc(S),G S′′(T S′′)≤tˆ(ℓS′′)(α)} (A1)
Inaddition,fortwosequenceofrealnumbersa mandb m,wewritea
m
=o(b m)whena m/b
m
→0,anda
m
=O(b m)when
lim m→∞|a m/b m|≤C forsomeconstantC. ToprovetheasymptoticpropertiesofRDART,weneedthefollowinglemmas.
Here,Lemma1isintroducedandprovedinDART,Lemma3(Lietal.,2023).
Lemma1. LetΩ˜ 0 ={i:T˜ ifollowsUnif(0,1)},B 0(ℓ a) :={S ∈B 0(ℓ) :∃A∈A(L)\A′,s.t.S ⊂A},andB 0(ℓ b) :={S ∈B 0(ℓ a) :
S ∈Ω˜ 0},wehave:
(cid:12) (cid:12)
(1) Sm ∈Ba 0(x
ℓ
a)c∈s [0u ,p γm](cid:12) (cid:12) (cid:12)G Φ¯S (( cc )) −1(cid:12) (cid:12) (cid:12)→0
(2) max sup (cid:12) (cid:12) (cid:12)P(T S >c|Q(1:ℓ−1)) −1(cid:12) (cid:12) (cid:12)→0
S∈B(ℓ)c∈[0,Φ¯−1(1/m)](cid:12) P(T S >c) (cid:12)
0b
√
Lemma2. Let γ m = 2logm+logloglogm,then
P(cˆ(ℓ) <γ )→1,∀ℓ∈{1,...,L}
m
Lemma3. ForanynodeS ∈B(ℓ)withS ⊂Ω 0,
P(∃i,j, s.t. T i ≥tˆ∗ S,T j ≥tˆ∗ S|T S ≥cˆ(ℓ))→0 (A2)
A4ProofofTheorem1. SinceFDP isarandomvariableboundedby1,toprovetheFDRcontrol,itissufficetoshow:
lim P(FDP ≤α+ϵ)=1.
m→∞
LetR(ℓ) = {j ∈ Ω : ∃Ss.t.S ∈ B(ℓ)∩R nodeandj ∈ S,T
j
≥ tˆ S}bethesetofrejectedhypothesesonlayerℓ, V(ℓ) =
{i ∈ R(ℓ) : ∃Ss.t.S ∈ B(ℓ)andi ∈ S}andW(ℓ) = {i ∈ R(ℓ) : ∃Ss.t.S ∈ B(ℓ)andi ∈ S}betherejectedhypothesis
0 1
who were originally selected from the node-level null node and alternative node on layer ℓ, respectively. On layer ℓ, since
m
1
=O(mr1),wehave
√
P(∀j ∈W(ℓ),j ∈Ω )≥1−mr1P(T ≥β/ ML−1,j ∈Ω )
1 j 0
≥1−o(mr1+(r1−1)/ML−1
)
→1 (A3)
Thus,if
lim P(FDP(ℓ) ≤α+ϵ)=1, (A4)
m→∞
thentogetherwithLemma3,wehave
(cid:18) |R(ℓ)∩Ω | (cid:19) (cid:18) |W(ℓ)∩Ω |+|V(ℓ)| (cid:19)
P 0 ≤α+ϵ ≥P 0 ≤α+ϵ
|R(ℓ)| |R(ℓ)|
≥P(FDP(ℓ) ≤α+ϵ)→1
and,
(cid:18) |R(ℓ)∩Ω | (cid:19)
lim P(FDP ≤α+ϵ)≤ lim P max 0 ≤α+ϵ
m→∞ m→∞ ℓ |R(ℓ)|
(cid:18) |R(ℓ)∩Ω | (cid:19)
≤ lim P 0 ≤α+ϵ,∀ℓ∈{1,...,L}
m→∞ |R(ℓ)|
→1
Thus,itissufficetoprove(A4)foranylayerℓ=1,...,L.
TherandomvariableFDP(ℓ)canbedecomposedtotheproductintotwoparts.
(cid:80) |S|I{T >cˆ(ℓ)} (cid:80) |S|G(cˆ(ℓ))
FDP(ℓ) = S (cid:80)∈B 0(ℓ) |S|GS (cˆ(ℓ)) × max((cid:80) S∈B 0(ℓ |S) |I{T >cˆ(ℓ)},1) (A5)
S∈B(ℓ) S∈B(ℓ) S
0
Basedon(A5),inordertoprovelim m→∞P(FDP(ℓ) ≤α+ϵ)=1forallϵ>0,weonlyneedprove
(cid:40)(cid:80) |S|I{T >cˆ(ℓ)} (cid:41)
S∈B(ℓ) S
ml →im ∞P (cid:80) S0 ∈B(ℓ)|S|G(cˆ(ℓ)) −1<ϵ →1 (A6)
0
(cid:40)(cid:12) (cid:80) |S|G(cˆ(ℓ)) (cid:12) (cid:41)
(cid:12) S∈B(ℓ) (cid:12)
ml →im ∞P (cid:12) (cid:12)max((cid:80) S∈B(ℓ)0 |S|I{T
S
>cˆ(ℓ)},1) −α(cid:12) (cid:12)>ϵ →0 (A7)
(A7)isimmediatelyfollowedbythecontinuityofG(·)andthemonotonicityoftheindicatorfunction. Wewillprove(A6)by
induction.
A5Layer1:
Letν m =1/logmandJ =⌈(γ m−Φ¯−1(α))/ν m⌉.Defineasequence0=c 0 <...<c J =γ msatisfiesc k−c k−1 =ν mfor
1≤k<J andc J −c J−1 ≤ν m.ByMarkovinequality,wehave
(cid:80)
(cid:90) c′ (cid:26)(cid:12) (cid:12) S∈B(1)I(T S >c)−P(T S >c)(1−δ 0m)(cid:12) (cid:12) (cid:27)
P (cid:12) (cid:12) 0 (cid:80) Φ¯(c) (cid:12) (cid:12)≥ϵ dc=o(ν m) (A8)
0 S∈B(1)
0
Accordingly,∀ϵ>0,
(cid:80) (cid:80)
(cid:18) (cid:12) (cid:12) i∈B(1)I(T i >c k)− i∈B(1)P(T i >c k)(1−δ 0m)(cid:12) (cid:12) (cid:19)
P max (cid:12) 0 (cid:80) 0 (cid:12)>ϵ →0 (A9)
0≤k≤J(cid:12) i∈B(1)G(c k) (cid:12)
0
(cid:12) (cid:12)
(cid:12) (cid:12)
Togetherwiththefactthatsup (cid:12)G(k)/G(k−1)−1(cid:12)=o(1),wehave
j=1,...,J(cid:12) (cid:12)
(cid:80)
(cid:18) (cid:12) (cid:12) i∈B(1)I(X i >c)−m 0G(c)(cid:12) (cid:12) (cid:19)
P sup (cid:12) 0 (cid:12)>ϵ =o(1) (A10)
c∈[0,γm](cid:12) m 0G(c) (cid:12)
Thus,
P(FDP(1) <α+ϵ)→1 (A11)
Let
X(1) =(cid:26) x:(cid:12) (cid:12) (cid:12)(cid:80) i∈B 0(1)I(T i >cˆ(1))−m 0G(cˆ(1))(cid:12) (cid:12) (cid:12)≤ϵ(cid:27)
(cid:12) m 0G(cˆ(1)) (cid:12)
OnX(1),
(cid:88) I(T >cˆ(1))≤m G(cˆ(1))+m G(cˆ(1))ϵ
S 0 0
S∈B(ℓ)
0
Combinedwith
m G(cˆ(1))≤α (cid:88) I{T >cˆ(1)}≤m αI{T >cˆ(1)}+αCmr1
0 S 0 S
S∈B(ℓ)
wehave,
(1−α−αϵ)m G(cˆ(1))≤αCmr1
0
andaccordinglycˆ(1) ≥β mwhenmlargeenough.Thus,togetherwith(A10),wehave
P(cˆ(1) ≥β )→1
m
Layerℓ≥2:
Suppose on layer h = 1,...,ℓ−1, P(cˆ(h) ≥ β m) → 1 and FDP(h) ≤ α/Mh−1 with probability converging to 1, then
togetherwithlemma1,similartotheproofinLayer1,wehave
P(cid:18) sup (cid:80) S∈B 0(ℓ)|S|I (cid:80)(T S >c) |S− |G(cid:80) (cS )∈B 0(ℓ)|S|G(c) >ϵ(cid:12) (cid:12) (cid:12) (cid:12)Q(1:ℓ−1)(cid:19) =o(1)
c∈[0,γm] S∈B(ℓ) (cid:12)
0
DefineX(ℓ) =(cid:26) x:(cid:12) (cid:12) (cid:12) (cid:12)(cid:80) S∈B0(ℓ)|S|I (cid:80)(T SS ∈> B0c (ˆ ℓ( )ℓ) |) S− |G(cid:80) (S cˆ(∈ ℓB ))0(ℓ)|S|G(cˆ(ℓ))(cid:12) (cid:12) (cid:12) (cid:12)≤ϵ(cid:27) ,then
P(X(ℓ))→1.
A6Thus,
P(FDP(ℓ) <α+ϵ)→1
Inaddition,on∩ℓ X(t),givenP(FDP(h) <α+ϵ)→1forallh=1,...,ℓ,wehave
t=1
P(cˆ(ℓ) ≥β )→1
m
ProofofTheorem2. Lettˆ S representtherobustrefiningthresholdandtˆ∗ S representthenaiverefiningthreshold. Basedon
definition1forrobustrefiningthreshold,wehave
tˆ ≥tˆ∗
S S
Then, byredefiningtheV(ℓ), W(ℓ) andR(ℓ) basedontherobustrefinethreshold, andconsideringthattherobustrefining
thresholdguaranteesthatatleastonehypothesiswillberejectedineveryscreened-outnode,wecanstillget.
P(∀j ∈W(ℓ),j ∈Ω )→1
1
ThenfollowingthesameprovingprocessinTheorem1,wecanprovetheasymptoticFDRcontrolundertherobustrefining
threshold.
Appendix B.2 Proofs of Lemmas
ProofofLemma2.
P(cˆ(ℓ) <γ m)≥P(cid:18) max{(cid:80) Sm ∈( Bℓ) lo I( (m
T
S−1 >)
γ m),1}
≤α(cid:12) (cid:12) (cid:12) (cid:12)Q(1:(ℓ)−1)(cid:19)
≥P(o(m−1)m≤α)
→1
ProofofLemma3. Itisequivalenttoprove
(cid:0) (cid:112) (cid:112) (cid:112) (cid:112) (cid:1)
P Z ≥a/ |S|,Z ≥a/ |S|,Z +Z + |S|−2Z ≥ |S|a
1 2 1 2 3
sup →0
Φ¯(a)
a∈[β,γ]
(cid:2)(cid:112) (cid:3)
SinceforA S = (|S|−2)/|S|a−loglogm,+∞ ,
(cid:0) (cid:112) (cid:112) (cid:112) (cid:112) (cid:1)
P Z ≥a/ |S|,Z ≥a/ |S|,Z +Z + |S|−2Z ≥ |S|a,Z ∈A
1 2 1 2 3 3 S
sup →0
Φ¯(a)
a∈[β,γ]
Itissufficienttoshow
sup H(a)→0
a∈[β,γ]
A7where
P(cid:0)
Z
≥a/(cid:112)
|S|,Z
≥a/(cid:112)
|S|,Z +Z
+(cid:112)
|S|−2Z
≥(cid:112)
|S|a,Z
∈Ac(cid:1)
H(a)= 1 2 1 2 3 3 S
Φ¯(a)
TogetherwithL’Hospitalruleandsometediouscalculation,wehave
d P(cid:0) Z ≥a/(cid:112) |S|,Z ≥a/(cid:112) |S|,Z +Z +(cid:112) |S|−2Z ≥(cid:112) |S|a,Z ∈Ac(cid:1)
lim da 1 2 1 2 3 3 S =0 (A12)
m→∞ d Φ¯(a)
da
Hence,whenevera=βorγ,
d P(cid:0) Z ≥a/(cid:112) |S|,Z ≥a/(cid:112) |S|,Z +Z +(cid:112) |S|−2Z ≥(cid:112) |S|a,Z ∈Ac(cid:1)
lim H(a)= lim da 1 2 1 2 3 3 S
m→∞ m→∞ d Φ¯(a)
da
=0 (A13)
DefineH
m
:={a∈[β,γ]: dd aH(a)=0},wehave
d P(cid:0) Z ≥a/(cid:112) |S|,Z ≥a/(cid:112) |S|,Z +Z +(cid:112) |S|−2Z ≥(cid:112) |S|a,Z ∈Ac(cid:1)
H(a)= da 1 2 1 2 3 3 S
d Φ¯(a)
da
andhence
lim sup H(a)→0 (A14)
a∈Hm
Sotogetherwith(A13)and(A14),wehave
(cid:26) (cid:27)
sup H(a)=max H(β),H(γ), sup H(a) →0
a∈[β,γ] a∈Hm
References
Barber,R.F.,Ramdas,A.,2017. Thep-filter: multilayerfalsediscoveryratecontrolforgroupedhypotheses. Journalofthe
RoyalStatisticalSocietySeriesB:StatisticalMethodology79,1247–1268.
Benjamini,Y.,Hochberg,Y.,1995. Controllingthefalsediscoveryrate: apracticalandpowerfulapproachtomultipletesting.
JournaloftheRoyalstatisticalsociety:seriesB(Methodological)57,289–300.
Cai,T.T.,Sun,W.,Xia,Y.,2022.Laws:Alocallyadaptiveweightingandscreeningapproachtospatialmultipletesting.Journal
oftheAmericanStatisticalAssociation117,1370–1383.
Davis,S.,Meltzer,P.S.,2007. Geoquery: abridgebetweenthegeneexpressionomnibus(geo)andbioconductor. Bioinfor-
matics23,1846–1847.
Hu,J.X.,Zhao,H.,Zhou,H.H.,2010.Falsediscoveryratecontrolwithgroups.JournaloftheAmericanStatisticalAssociation
105,1215–1227.
Lei, L., Fithian, W., 2018. Adapt: an interactive procedure for multiple testing with side information. Journal of the Royal
StatisticalSociety:SeriesB80,649–679.
A8Leung,D.,Sun,W.,2022. Zap: z-valueadaptiveproceduresforfalsediscoveryratecontrolwithsideinformation. Journalof
theRoyalStatisticalSocietySeriesB:StatisticalMethodology84,1886–1946.
Li,X.,Sung,A.D.,Xie,J.,2023. Dart:Distanceassistedrecursivetesting. JournalofMachineLearningResearch24,1–41.
Liu, W., et al., 2013. Gaussian graphical model estimation with false discovery rate control. The Annals of Statistics 41,
2948–2978.
Qiu, L., Murrugarra-Llerena, N., Silva, V., Lin, L., Chinchilli, V.M., 2021. Neurt-fdr: Controlling fdr by incorporating feature
hierarchy. arXivpreprintarXiv:2101.09809.
Stouffer,S.A.,Suchman,E.A.,DeVinney,L.C.,Star,S.A.,WilliamsJr,R.M.,1949. Theamericansoldier: Adjustmentduring
armylife.(studiesinsocialpsychologyinworldwarii),vol.1.
Xie, J., Li, R., 2018. False discovery rate control for high dimensional networks of quantile associations conditioning on
covariates. JRStatSocSeriesBStatMethodol80,1015–1034. doi:10.1111/rssb.12288.
Yang, L., Wang, P., Chen, J., 2024. 2dgbh: Two-dimensionalgroupbenjamini–hochbergprocedureforfalsediscoveryrate
controlintwo-waymultipletestingofgenomicdata. Bioinformatics40,btae035.
Yun,S.,Zhang,X.,Li,B.,2022. Detectionoflocaldifferencesinspatialcharacteristicsbetweentwospatiotemporalrandom
fields. JournaloftheAmericanStatisticalAssociation117,291–306.
Zhang,C.,Fan,J.,Yu,T.,2011. MultipletestingviaFDRLforlargescaleimagingdata. AnnalsofStatistics39,613.
A9