ATTENTION HEADS OF LARGE LANGUAGE MODELS: A SURVEY
ZifanZheng1,∗ YezhaohuiWang1,∗ YuxinHuang2,∗ ShichaoSong1 BoTang1
FeiyuXiong1 ZhiyuLi1,†
1InstituteforAdvancedAlgorithmsResearch(IAAR),Shanghai
2InstituteforAIIndustryResearch(AIR),TsinghuaUniversity
ABSTRACT
Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in various tasks
butremainlargelyasblack-boxsystems. Consequently,theirdevelopmentreliesheavilyondata-
drivenapproaches,limitingperformanceenhancementthroughchangesininternalarchitectureand
reasoning pathways. As a result, many researchers have begun exploring the potential internal
mechanisms of LLMs, aiming to identify the essence of their reasoning bottlenecks, with most
studiesfocusingonattentionheads. Oursurveyaimstoshedlightontheinternalreasoningprocesses
of LLMs by concentrating on the interpretability and underlying mechanisms of attention heads.
Wefirstdistillthehumanthoughtprocessintoafour-stageframework: KnowledgeRecalling,In-
ContextIdentification,LatentReasoning,andExpressionPreparation. Usingthisframework,we
systematicallyreviewexistingresearchtoidentifyandcategorizethefunctionsofspecificattention
heads. Furthermore,wesummarizetheexperimentalmethodologiesusedtodiscoverthesespecial
heads,dividingthemintotwocategories: Modeling-FreemethodsandModeling-Requiredmethods.
Also,weoutlinerelevantevaluationmethodsandbenchmarks. Finally,wediscussthelimitationsof
currentresearchandproposeseveralpotentialfuturedirections. Ourreferencelistisopen-sourcedat
https://github.com/IAAR-Shanghai/Awesome-Attention-Heads.
Keywords AttentionHead·MechanisticInterpretability·LargeLanguageModel(LLMs)·Survey
1 Introduction
TheTransformerarchitecture[Vaswanietal.,2017]hasdemonstratedoutstandingperformanceacrossvarioustasks,
suchasNaturalLanguageInferenceandNaturalLanguageGeneration. However,itstillretainstheblack-boxnature
inherenttoDeepNeuralNetworks(DNNs)[Gilpinetal.,2018,Lipton,2018]. Asaresult,manyresearchershave
dedicatedeffortstounderstandingtheinternalreasoningprocesseswithinthesemodels,aimingtouncovertheunderlying
mechanisms[Montavonetal.,2018]. ThislineofresearchprovidesatheoreticalfoundationformodelslikeBERT
[Devlin,2018]andGPT[Radfordetal.,2019]toperformwellindownstreamapplications. Additionally,inthecurrent
erawhereLargeLanguageModels(LLMs)arewidelyapplied,interpretabilitymechanismscanguideresearchersin
interveninginspecificstagesofLLMinference,therebyenhancingtheirproblem-solvingcapabilities[Chuangetal.,
2024,Lietal.,2024a,b].
AmongthecomponentsofLLMs,attentionheadsplayacrucialroleinthereasoningprocess. Particularlyintherecent
years,attentionheadswithinLLMshavegarneredsignificantattention,asillustratedinFigure1. Numerousstudies
haveexploredattentionheadswithspecificfunctions. Thispaperconsolidatestheseresearchefforts,organizingand
analyzingthepotentialmechanismsofdifferenttypesofattentionheads.Additionally,wesummarizethemethodologies
employedintheseinvestigations.
∗Equalcontribution.
†Correspondingauthor:lizy@iaar.ac.cn
4202
peS
5
]LC.sc[
1v25730.9042:viXraAttentionHeadsofLargeLanguageModels: ASurvey
Figure1: TheglobalGoogleTrendsPopularityofthekeywords“AttentionHead”and“ModelInterpretability”. The
dataretrievaldateisAugust1st,2024.
1.1 StructureofOurWork
ThelogicalstructureandclassificationmethodofthispaperareillustratedinFigure2. Webeginwiththebackgroundof
theprobleminSection2,wherewepresentasimplifiedrepresentationoftheLLMs’structures(Section2.1)andexplain
therelatedkeyterms(Section2.2). InSection3,wefirstsummarizethefourstagesofhumanthoughtprocessesfroma
cognitiveneuroscienceperspectiveandapplythisframeworktoanalyzethereasoningmechanismsofLLMs. Usingthis
asourclassificationcriterion,wecategorizeexistingworkonattentionheads,identifyingcommonalitiesamongheads
thatcontributetosimilarreasoningprocesses(Sections3.2–3.5)andexploringthecollaborativemechanismsofheads
functioningatdifferentstages(Section3.6).
Investigatingtheinternalmechanismsofmodelsoftenrequiresextensiveexperimentstovalidatehypotheses.Toprovide
a comprehensive understanding of these methods, we summarize the current experimental methodologies used to
explorespecialattentionheadsinSection4. Wedividethesemethodologiesintotwomaincategoriesbasedonwhether
theyrequireadditionalmodeling: Modeling-Free(Section4.1)andModeling-Required(Section4.2).
InadditiontothecoresectionsshowninFigure2,wesummarizetheevaluationtasksandbenchmarksusedinrelevant
studiesinSection5. Furthermore,inSection6,wecompileresearchonthemechanismsofFeed-ForwardNetworks
(FFNs)andMechanicalInterpretabilitytohelpdeepenourunderstandingofLLMstructuresfrommultipleperspectives.
Finally,inSection7,weofferourinsightsonthecurrentstateofresearchinthisfieldandoutlineseveralpotential
directionsforfutureresearch.
1.2 ComparisonwithRelatedSurveys
Tothebestofourknowledge,thereisnosurveyfocusedonthemechanismsofLLMs’attentionheads. Specifically,
Räukeretal.[2023]mainlydiscussesnon-Transformerarchitectures,withlittlefocusonattentionheads. Thesurveys
byGonçalvesetal.[2022],SantanaandColombini[2021],Chaudharietal.[2021],BrauwersandFrasincar[2021]
coveroldercontent,primarilyfocusingonthevariousattentioncomputationmethodsthatemergedduringtheearly
developmentoftheTransformer. However,currentLLMsstillusetheoriginalscaled-dotproductattention,indicating
that many of the derived attention forms have become outdated. Although [Luo and Specia, 2024] focuses on the
internalstructureofLLMs,itonlysummarizesexperimentalmethodologiesandoverlooksresearchfindingsrelatedto
operationalmechanisms.
Comparedtotheaforementionedsurveys,thestrengthsofourworkare:
• Focusonthelatestresearch. Althoughearlierresearchersexploredthemechanismsofattentionheadsin
models like BERT, many of these conclusions are now outdated. This paper primarily focuses on highly
popularLLMs,suchasLLaMAandGPT,consolidatingthelatestresearchfindings.
• Aninnovativefour-stageframeworkforLLMreasoning. Wehavedistilledkeystagesofhumanthought
processesbyintegratingknowledgefromcognitiveneuroscience,psychology,andrelatedfields. Andwehave
appliedthesestagesasananalogyforLLMreasoning.
2AttentionHeadsofLargeLanguageModels: ASurvey
+ +
Figure2: Thesurvey’sframework.
• Detailed categorization of attention heads. Based on the proposed four-stage framework, we classify
differentattentionheadsaccordingtotheirfunctionswithinthesestages,andweexplainhowheadsoperating
atdifferentstagescollaboratetoachievealignmentbetweenhumansandLLMs.
• Clearsummarizationofexperimentalmethods. Weprovideadetailedcategorizationofthecurrentmethods
usedtoexploreattentionheadfunctionsfromtheperspectiveofmodeldependency,layingafoundationforthe
improvementandinnovationofexperimentalmethodsinfutureresearch.
3AttentionHeadsofLargeLanguageModels: ASurvey
1.3 Out-of-scopeTopics
• ThispaperprimarilytargetstheattentionheadswithincurrentmainstreamLLMarchitectures,specifically
thosewithadecoder-onlystructure. Assuch,wedonotdiscussearlystudiesrelatedtotheTransformer,such
asthosefocusingonattentionheadsinBERT-basedmodels.
• Somestudiesonmechanisticinterpretabilityproposeholisticoperationalprinciplesthatencompassembed-
dings,attentionheads,andMLPs. However,thispaperfocusesexclusivelyonattentionheads. Consequently,
Sections3through4donotcovertherolesofothercomponentswithintheTransformerarchitecture;theseare
onlybrieflysummarizedinSection6.
2 Background
2.1 MathematicalRepresentationofLLMs
Tofacilitatethediscussioninsubsequentsections,wefirstdefinetherelevantnotations3.
AsshowninFigure3,amodelMconsistsofanembeddinglayer,Lidenticaldecoderblocks,andanunembedding
layer. TheinputtoMareone-hotsentencetokens,withashapeof{0,1}N×|V|,whereN isthelengthofthetoken
sequenceand|V|representsthevocabularysize.
Afterpassingthroughtheembeddinglayer,whichappliessemanticembeddingW ∈R|V|×dandpositionalencoding
E
P (e.g.,RoPE[Suetal.,2024]),theone-hotmatrixistransformedintotheinputX ∈RN×dforthefirstdecoder,
E 0,0
wheredrepresentsthedimensionofthetokenembedding(latentvector).
𝑳
Χ
ℓ+1,0
𝑉 Χ ℓ,0 Χ ℓ,1 𝑉
Χ 0,0 𝐴𝑡𝑡𝑛 𝑡0(Χ ℓ,0) + Χ ℓ,1 𝐹𝐹𝑁 ℓ(Χ ℓ,1) + Χ 𝐿+1,0
𝐴𝑡𝑡𝑛1(Χ )
𝑡 ℓ,0
Qℎ
ℓ
𝐴𝑡𝑡𝑛 𝑡𝐻(Χ ℓ,0) Κ ℓℎ × O ℓℎ
Vℎ
ℓ
Figure3: Theoverallstructureofdecoder-onlyLLMs.
Intheℓ-thℓ(1≤ℓ≤L)decoderblock,therearetworesidualblocks. EachdecoderblockscontainH attentionheads.
ThefirstresidualblockcombinestheinputmatrixX ∈RN×dwiththeoutputXattnobtainedfromthemulti-head
ℓ,0 ℓ
attentionoperation,producingX (asshowninEquation1). Subsequently,X servesastheinputforthesecond
ℓ,1 ℓ,1
residualblock. Here,Attnh(·) (1≤ℓ≤L,1≤h≤H)representsthecomputationfunctionoftheh-thattention
ℓ
headintheℓ-thlayer,where1≤h≤H.
H
(cid:88)
Xattn = Attnh(X )
ℓ ℓ ℓ,0 (1)
h=1
X =X +Xattn
ℓ,1 ℓ,0 ℓ
Similarly,asshowninEquation2,thesecondresidualblockcombinesX withtheoutputXffnobtainedafterpassing
ℓ,1 ℓ
throughtheFFN,yieldingthefinaloutputX oftheℓ-thdecoderblock. Thisoutputalsoservesastheinputforthe
ℓ+1,0
3Currently,therearetwomainlayernormalizationmethodsinLLMs:Pre-NormandPost-Norm[Liuetal.,2020,Xiongetal.,
2020].However,sincethesearenotthefocusofthispaper,wewillomitLayerNormalizationinourdiscussion.
4AttentionHeadsofLargeLanguageModels: ASurvey
ℓ+1-thdecoderblock. Here,FFN (·)consistsoflinearlayers(andactivationfunctions)suchasGLU(GatedLinear
ℓ
Units),SwiGLU[Shazeer,2020],orMoE[Fedusetal.,2022].
Xffn =FFN (X )
ℓ ℓ ℓ,1
(2)
X =X +Xffn
ℓ+1,0 ℓ,1 ℓ
Here,wewillconcentrateonthedetailsofAttnh(·). Thisfunctioncanbeexpressedusingmatrixoperations. Specif-
ℓ
ically,eachlayer’sAttnh
ℓ
(·)functioncorrespondstofourlow-rankmatrices: W Qh ℓ,W Kh ℓ,W Vh
ℓ
∈ Rd× Hd,Oh
ℓ
∈
R Hd×d. BymultiplyingX ℓ,0withW Qh ℓ,thequerymatrixQh
ℓ
∈RN× Hd isobtained. Similarly,thekeymatrixKh
ℓ
and
thevaluematrixVhcanbederived. ThefunctionAttnh(·)canthenbeexpressedasEquation3[Vaswanietal.,2017].
ℓ ℓ
Attnh(X )=softmax(cid:0) Qh⊤·Kh(cid:1) ·Vh·Oh (3)
ℓ ℓ,0 ℓ ℓ ℓ ℓ
+
+ + + + + + + + + + + +
+ + + + + + + + + + + +
+ + + + + + + + + + + +
+ + + + + + + + + + + +
Figure4: Fromtheperspectiveofresidualstreams,theinferenceprocessofLLMscanbeunderstoodatamicro-level
whereattentionheadsaccesslatentstatematricesfromotherresidualstreams,asindicatedbythegrayarrowsacross
layersinthediagram. Atamacro-level,differentresidualstreamscontroltheflowofinformationthroughattention
heads,asshownbythegraywavylinesinthediagram.
2.2 GlossaryofKeyTerms
Thispaperintroducesseveralspecializedtermsrelatedtoreasoningmechanismmodelingandexperimentalexploration
methods. Below,weprovideexplanationsforthekeyterms4.
• Circuits. Circuits are abstractions of the reasoning logic in deep models. The model M is viewed as a
computationalgraph. Therearetwomainapproachestomodelingcircuits. Oneapproachtreatsthefeaturesin
thelatentspaceofMasnodesandthetransitionsbetweenfeaturesasedges[Olahetal.,2020]. Theother
approachviewsdifferentcomponentsofM,suchasattentionheadsandneurons,asnodes;andtheinteractions
betweenthesecomponents,suchasresidualconnections,asedges[Wangetal.,2022]. Acircuitisasubgraph
ofM. Currentresearchonattentionheadsprimarilyusestheseconddefinition.
• Residualstream. Theresidualstreamafterlayerℓisthesumoftheembeddingandtheoutputsofalllayers
uptolayerℓ,andistheinputtolayerℓ+1. Elhageetal.[2021]offersaperspectiveoftheresidualstreamasa
sharedbandwidth. Differentlayerscantransmitinformationthroughthissharedbandwidth(withlowerlayers
writinginformationandhigherlayersreadingit),asillustratedinFigure4.
• Knowledge circuit. As defined in [Yao et al., 2024], a knowledge circuit is a critical subgraph in M to
viewtheknowledgemechanismofTransformers. Knowledgecircuitsfocusonhowdifferentcomponents
collaboratetoexpressinternalknowledge.
4Formoredefinitionsofspecializedterms,pleaserefertotheworkofNanda[2022].
5AttentionHeadsofLargeLanguageModels: ASurvey
• Activationpatching&Ablationstudy. Activationpatchinginvolvesreplacingtheactivationvaluesincertain
layersofamodeltoanalyzethecontributionoftheselayerstothemodel’sdecision-making. Ablationstudy,
ontheotherhand,involvesremovingacomponentfromtheLLMandobservingthechangesintheoutput
[HeimersheimandNanda,2024].
Bothmethodsrequirecalculatingtheeffecttowardsoutputaftertheoperation. Specifically,therearethree
typesofeffects: directeffect,indirecteffect,andtotaleffect,asshowninFigure5.
ThekeydifferencebetweenthemisthatActivationPatchingdoesnotremovecomponents,whereasAblation
Studylogicallyremovesacomponent.
• Logit lens. When calculating effects like those shown in Figure 5, logit lens can quantify this effect.
Specifically,itusesuembeddinglayertomapanintermediaterepresentationvectortothelogitsvaluesofthe
vocabulary,allowingforthecomparisonoflogitsdifferencesorothermetrics[nostalgebraist,2021].
Figure5: Threedifferenttypesofcalculatingeffects.
3 OverviewofSpecialAttentionHeads
Previousresearchhasshownthatthedecoder-onlyarchitecturedescribedinSection2followstheScalingLaw,andit
exhibitsemergentabilitiesoncethenumberofparametersreachesacertainthreshold[Kaplanetal.,2020,Bommasani
etal.,2021]. ManyLLMsthathaveemergedsubsequentlydemonstrateoutstandingperformanceinnumeroustasks,
evenclosetohuman. However,researchersstilldonotfullyunderstandwhythesemodelsareabletoachievesuch
remarkableresults. Toaddressthisquestion,recentstudieshavebeguntodelveintotheinternalmechanismsofLLMs,
focusingontheirfundamentalstructure—aneuralnetworkcomposedofmulti-attentionheadsandFFNs.
Wehaveobservedthatmanystudiesconcentrateonthefunctionsofattentionheads,attemptingtoexplaintheirreasoning
processes. Additionally,severalresearchershavedrawnparallelsofreasoningmethodsbetweenLLMsandhuman
[Liangetal.,2024a,GignacandSzodorai,2024]. Therefore, inthissection, wewillusetheframeworkofhuman
cognitiveparadigmsasaguidingmethodtoclassifythefunctionsofdifferentattentionheads.
Figure6: Thefour-stageframeworkonhumanthinking/LLMsreasoning.
6AttentionHeadsofLargeLanguageModels: ASurvey
3.1 HowdoesBrain/AttentionHeadthink?
Bysummarizingandanalyzingexistingresearch,wefindthattheroleofanattentionhead,asitsnamesuggests,is
quiteanalogoustothefunctionsofthehumanbrain. Fromabehavioralneuroscienceperspective,theprocessbywhich
thehumanbrainthinksaboutspecificproblemscanbeabstractedintoafour-stepprocess: KnowledgeRecalling(KR),
In-ContextIdentification(ICI),LatentReasoning(LR),andExpressionPreparation(EP).Thesefourstepscaninteract
andtransitionbetweeneachother,asillustratedinFigure6.
Whensolvingaproblem,humansfirstneedtorecalltheknowledgetheyhavelearnedthatisrelevanttotheissueathand.
ThisprocessisknownasKnowledgeRecalling(KR).Duringthisstage,thehippocampusintegratesmemoriesintothe
brain’snetwork[Squire,1992]andactivatesdifferenttypesofmemoriesasneeded[Tulving,1972]. Confrontedwith
thespecifictextoftheproblem,humansneedtoperformIn-ContextIdentification(ICI).Thismeansthatthebrain
notonlyfocusesontheoverallstructuralcontentofthetext[Kintsch,1988]butalsoparsesthesyntactic[Chomsky,
2014]andsemantic[Jackendoff,1992]informationembeddedwithinit.
Oncethebrainhasacquiredtheaforementionedtextualandmemoryinformation,itattemptstointegratethisinformation
toderiveconclusions,aprocessknownasLatentReasoning(LR).Thisstageprimarilyincludesarithmeticoperations
[Dehaene,2011]andlogicalinference[Johnson-Laird,1983]. Finally,thebrainneedstotranslatethereasoningresults
intonaturallanguage,formingananswerthatcanbeexpressedverbally. ThisistheExpressionPreparation(EP)
stage. Atthispoint,thebrainbridgethegapbetween“knowing”and“saying”[Levelt,1999].
As indicated by the arrows in Figure 6, these four stages are not executed in a strictly one-direction fashion when
humanssolveproblems;rather,theycanjumpandswitchbetweeneachother. Forexample,thebrainmay“cycle”
throughtheidentificationofcontextualcontent(theICIstage)andthenretrieverelevantknowledgebasedonthecurrent
context(theKRstage). Similarly,iflatentreasoningcannotproceedfurtherduetomissinginformation,thebrainmay
returntotheKnowledgeRecallingandIn-ContextIdentificationstagestogathermoreinformation.
Wewillnowdrawananalogybetweenthesefourstepsandthemechanismsofattentionheads,asdepictedinFigure7.
PreviousresearchhasshownthatLLMspossessstrongcontextuallearningabilitiesandhavemanypracticalapplications
[Winataetal.,2021]. Asaresult,muchoftheworkoninterpretabilityhasfocusedontheabilityofLLMstocapture
andreasonaboutcontextualinformation. Consequently,thefunctionsofcurrentlyknownspecialattentionheadsare
primarilyconcentratedintheICIandLRstages,whiletherearefewerattentionheadsthatoperateintheKRandEP
stages.
GeneralTasks AssociativeMemoriesHead[Biettietal.,2024],MemoeyHead[Jinetal.,2024]
§3.2KnowledgeRecalling
ConstantHead(MCQA)[Lieberumetal.,2023],SingleLetterHead(MCQA)[Lieberumetal.,2023],
SpecificTasks
NegativeHead(BDT)[Yuetal.,2024a]
PreviousHead[Olssonetal.,2022],PositionalHead[FerrandoandVoita,2024,Voitaetal.,2019],
OverallStructure RareWordsHead[Voitaetal.,2019], DuplicateTokenHead[Wangetal.,2022], Retrievalhead
[Wuetal.,2024],GlobalRetrievalhead[Tangetal.,2024]
SubwordMergeHead[FerrandoandVoita,2024],SyntacticHead[Voitaetal.,2019],MoverHead
§3.3In-ContextIdentification SyntacticInformation [Yaoetal.,2024],NameMoverHead&BackupNameMoverHead[McDougalletal.,2023],
LetterMoverHead[García-Carrascoetal.,2024a],NegativeNameMoverHead[Wangetal.,2022]
ContextHead[Jinetal.,2024],ContentGathererHead[Lieberumetal.,2023,Merulloetal.,2024],
SemanticInformation SentimentSummarizer[Tiggesetal.,2023],SemanticInductionHead[Renetal.,2024],
SubjectHead&RelationHead[Chughtaietal.,2024]
SummaryReader[Tiggesetal.,2023],FunctionVector[Toddetal.,2023],InductionHead
In-contextLearning
[Olssonetal.,2022,Edelmanetal.,2024,Singhetal.,2024,Ji-Anetal.,2024,Crosbie,2024]
TruthfulnessHead[Lietal.,2024b,Hoscilowiczetal.,2024],AccuracyHead[Guoetal.,2024],
§3.4LatentReasoning EffectiveReasoning
VulnerableHead[García-Carrascoetal.,2024b]
CorrectLetterHead[Lieberumetal.,2023],IterationHead[Cabannesetal.,2024],SuccessorHead
Task-Specific
[Gouldetal.,2023],S-InhibitionHead[Wangetal.,2022]
InformationAggregation MixedHead[Chughtaietal.,2024]
§3.4ExpressionPreparation SignalAmplification AmplificationHead[Lieberumetal.,2023],CorrectHead[Wiegreffeetal.,2024]
InstructionAlignment CoherenceHead[Guoetal.,2024],FaithfulnessHead[Tanneruetal.,2024]
Figure7: Taxonomyofspecialattentionheadsinlanguagemodels.
7
sdaeHnoitnettAlaicepSAttentionHeadsofLargeLanguageModels: ASurvey
3.2 KnowledgeRecalling(KR)
ForLLMs,mostknowledgeislearnedduringthetrainingorfine-tuningphases,whichisembeddedinthemodel’s
parameters. This form of knowledge is often referred to as LLMs’ “parametric knowledge”. Similar to humans,
certainattentionheadsinLLMsrecallthisinternallystoredknowledge—suchascommonsenseordomain-specific
expertise—tobeusedinsubsequentreasoning. Theseheadstypicallyretrieveknowledgebymakinginitialguessesor
byfocusingonspecificcontentwithinthecontext,injectingthememoryinformationintotheresidualstreamasinitial
data.
Ingeneraltasks,Biettietal.[2024]identifiedthatsomeattentionheadsfunctionasassociativememories,gradually
storingandretrievingknowledgeduringthemodel’strainingphase. Theso-calledMemoryHead [Jinetal.,2024]
canretrievecontentrelatedtothecurrentproblemfromtheparametricknowledge. Thiscontentcouldbeknowledge
learnedduringpre-trainingorexperienceaccumulatedduringpreviousreasoningprocesses.
Inspecifictaskscenarios,suchaswhenLLMstackleMultipleChoiceQuestionAnswering(MCQA)problems,they
mayinitiallyuseConstantHeadtoevenlydistributeattentionscoresacrossalloptions,ortheymightuseSingleLetter
Headtoassignahigherattentionscoretooneoptionwhilegivinglowerscorestoothers,therebycapturingallpotential
answers[Lieberumetal.,2023].
Additionally, in the context of Binary Decision Tasks (BDT)5, Yu et al. [2024a] found that LLMs often exhibit a
negativebiaswhenhandlingsuchtasks. Thiscouldbebecausethemodelhaslearnedasignificantamountofnegative
expressionsrelatedtosimilartasksfrompriorknowledgeduringtraining. Consequently,whenthemodelidentifiesa
giventextasabinarytask,aNegativeHeadmay“preemptively”choosethenegativeanswerduetothispriorbias.
3.3 In-ContextIdentification(ICI)
Understandingthein-contextnatureofaproblemisoneofthemostcriticalprocesstoeffectivelyaddressingit. Justas
humansreadaproblemstatementandquicklypickuponvariouskeypiecesofinformation,someattentionheadsin
LLMsalsofocusontheseelements. Specifically,attentionheadsthatoperateduringtheICIstageusetheirQKmatrices
tofocusonandidentifyoverallstructural,syntactic,andsemanticinformationwithinthein-context. Thisinformation
isthenwrittenintotheresidualstreamviaOVmatrices.
3.3.1 OverallStructuralInformationIdentification
IdentifyingtheoverallstructuralinformationwithinacontextmainlyinvolvesLLMsattendingtocontentinspecial
positionsorwithuniqueoccurrencesinthetext. PreviousHead[Olssonetal.,2022](alsoreferredtoasPositional
Headin[FerrandoandVoita,2024])attendtothepositionalrelationshipswithinthetokensequence. Theycapture
theembeddinginformationofthecurrenttokenandtheprevioustoken. RareWordsHead[Voitaetal.,2019]focus
ontokensthatappearwiththelowestfrequency,emphasizingrareoruniquetokens. DuplicateTokenHeadexcelat
capturingrepeatedcontentwithinthecontext,givingmoreattentiontotokensthatappearmultipletimes[Wangetal.,
2022].
Besides, asLLMscangraduallyhandlelongtexts, thisisalsorelatedtothe“Needle-in-a-Haystack”capabilityof
attentionheads. (Global)RetrievalHeadcanaccuratelylocatespecifictokensinlongtexts[Wuetal.,2024,Fuetal.,
2024,Tangetal.,2024]. TheseheadsenableLLMstoachieveexcellentreadingandin-contextretrievalcapabilities.
3.3.2 SyntacticInformationIdentification
For syntactic information identification, sentences primarily consist of subjects, predicates, objects, and clauses.
SyntacticHeadcandistinctlyidentifyandlabelnominalsubjects,directobjects,adjectivalmodifiers,andadverbial
modifiers. Somewordsintheoriginalsentencemaygetsplitintomultiplesubwordsbecauseofthetokenizer(e.g.,
“happiness”mightbesplitinto“happi”and“ness”). TheSubwordMergeHeadfocusonthesesubwordsandmerge
themintoonecompleteword[FerrandoandVoita,2024].
Additionally, Yao et al. [2024] proposed the Mover Head cluster, which can be considered as “argument parsers”.
These heads often copy or transfer sentence’s important information (such as the subject’s position) to the [END]
position6. NameMoverHeadandBackupNameMoverHeadcanmovethenamesinthetexttothe[END]position.
LetterMoverHeadcanextractthefirstlettersofcertainwordsinthecontextandaggregatethematthe[END]position
5ABinaryDecisionTaskisaproblemwherethesolutionspaceisdiscreteandcontainsonlytwooptions,suchasyes-noquestions
oranswerverification.
6The[END]positionreferstothelasttoken’spositioninthesentencebeingdecodedbytheLLM.Manystudiesindicatethat
summarizingcontextualinformationatthispositionfacilitatessubsequentreasoningandnext-tokenprediction.
8AttentionHeadsofLargeLanguageModels: ASurvey
[García-Carrasco et al., 2024a]. Conversely, Negative Name Mover Head prevent name information from being
transferredtothe[END]position[Wangetal.,2022,McDougalletal.,2023].
3.3.3 SemanticInformationIdentification
Asforsemanticinformationidentification,ContextHead[Jinetal.,2024]extractinformationfromthecontextthatis
relatedtothecurrenttask. Further,ContentGathererHead[Lieberumetal.,2023,Merulloetal.,2024]“move”tokens
relatedtothecorrectanswertothe[END]position,preparingtoconvertthemintothecorrespondingoptionletterfor
output. TheSentimentSummarizerproposedbyTiggesetal.[2023]cansummarizeadjectivesandverbsthatexpress
sentimentinthecontextnearthe[SUM]position7,makingiteasierforsubsequentheadstoreadandreason.
Capturingthemessageaboutrelationshipisalsoimportantforfuturereasoing. SemanticInductionHead[Renetal.,
2024]capturesemanticrelationshipswithinsentences,suchaspart-whole,usage,andcategory-instancerelationships.
SubjectHeadandRelationHead[Chughtaietal.,2024]focusonsubjectattributesandrelationattributes,respectively,
andtheninjecttheseattributesintotheresidualstream.
3.4 LatentReasoning(LR)
The KR and ICI stages focus on gathering information, while Latent Reasoning (LR) is where all the collected
informationissynthesizedandlogicalreasoningoccurs. WhetherinhumansorLLMs,theLRstageisthecoreof
problem-solving. Specifically,QKmatricesofaheadperformsimplicitreasoningbasedoninformationreadfromthe
residualstream,andthenthereasoningresultsorsignalsarewrittenbackintotheresidualstreamthroughOVmatrices.
3.4.1 In-contextLearning
In-contextLearningisoneofthemostwidelydiscussedareas. Itprimarilyincludestwotypes: TaskRecognition(TR)
andTaskLearning(TL)[Pan,2023]. Bothinvolvelearningfromcontexttoinfertheproblem’ssolution,buttheydiffer
intheirrelianceonsemanticinformation. TRhaslabelswithclearsemantics,suchas“positive”and“negative”in
sentimentclassification. Incontrast,TLdependsonlearningthespecificmappingfunctionbetweenexample-label
pairs,wheretheexampleandlabeldonothaveasemanticconnection.
ForTaskRecognition: SummaryReader [Tiggesetal.,2023]canreadtheinformationsummarizedatthe[SUM]
positionduringtheICIstageandusethisinformationtoinferthecorrespondingsentimentlabel. Toddetal.[2023]
proposedthattheoutputofcertainmid-layerattentionheadscancombineintoaFunctionVector. Theseheadsabstract
thecorefeaturesandlogicalrelationshipsofatask,basedonthesemanticinformationidentifiedduringICI,andthereby
triggertaskexecution.
ForTaskLearning,theessenceofsolvingtheseproblemsisenablingLLMstoinductivelyfindpatterns. Induction
Headisamongthemostwidelystudiedattentionheads[Olssonetal.,2022,Edelmanetal.,2024,Singhetal.,2024,
Crosbie,2024]. Theycapturepatternssuchas“... [A][B]... [A]”wheretoken[B]followstoken[A],andpredict
thatthenexttokenshouldbe[B].Specifically,InductionHeadcangetinformationaboutalltokensinthecontextand
theprevioustokenfromPreviousHead. Itthenmatchthiswithinformationatthe[END]positiontoperformfurther
reasoning.
InductionHeadtendstostrictlyfollowapatternonceidentifiedandcompletefill-in-the-blankreasoning. However,in
mostcases,therealproblemwillnotbeidenticaltotheexamples—justasastudent’sexampaperwillnotbeexactly
thesameastheirhomework. Toaddressthis,YuandAnaniadou[2024]introducedtheIn-contextHead,whoseQK
matrixcalculatesthesimilaritybetweeninformationatthe[END]positionandeachlabel. TheOVmatrixthenextracts
labelfeaturesandweightsthemaccordingtothesimilarityscorestodeterminethefinalanswer(takealllabelsinto
considerationratherthanonlyonelabel).
3.4.2 EffectiveReasoning
Somestudieshaveidentifiedheadsrelatedtoreasoningeffectiveness. TruthfulnessHead[Lietal.,2024b,Hoscilowicz
et al., 2024] and Accuracy Head [Guo et al., 2024] are heads highly correlated with the truthfulness andaccuracy
ofanswers. TheyhelpthemodelinfertruthfulandcorrectresultsinQAtasks,andmodifyingthemodelalongtheir
activationdirectionscanenhanceLLMs’reasoningabilities.
However,notallheadspositivelyimpactreasoning. Forexample,VulnerableHead[García-Carrascoetal.,2024b]
areoverlysensitivetocertainspecificinputforms,makingthemsusceptibletoirrelevantinformationandleadingto
incorrectresults. Duringreasoning,itisadvisabletominimizetheinfluenceofsuchheads.
7[SUM]positionisnextto[END]position.
9AttentionHeadsofLargeLanguageModels: ASurvey
3.4.3 TaskSpecificReasoning
Finally,someheadsarespecializedforspecifictasks. InMCQAtasks,CorrectLetterHead[Lieberumetal.,2023]can
completethematchingbetweentheanswertextandoptionlettersbycomparingtheindexofeachoption,determining
thefinalanswerchoice. Whendealingwithtasksrelatedtosequentialdata,IterationHead[Cabannesetal.,2024]can
iterativelyinferthenextintermediatestatebasedonthecurrentstateandinput. Forarithmeticproblems,Successor
Head[Gouldetal.,2023]canperformincrementoperationsonordinalnumbers.
Theseexamplesillustratehowvariousattentionheadsspecializeindifferentaspectsofreasoning,contributingtothe
overallproblem-solvingcapabilitiesofLLMs.
3.5 ExpressionPreparation(EP)
DuringtheExpressionPreparation(EP)stage,LLMsneedtoaligntheirreasoningresultswiththecontentthatneedsto
beexpressedverbally. Specifically,EPheadsmayfirstaggregateinformationfromvariousstages. Chughtaietal.
[2024]proposed the MixedHead, whichcan linearlycombine andaggregateinformationwritten intothe residual
streambyheadsfromtheICIandLRstages(suchasSubjectHeads,RelationHeads,InductionHeads,etc.). The
aggregatedresultsarethenmappedontothevocabularylogitsvalueviatheOVmatrix.
SomeEPheadshaveasignalamplificationfunction. Specifically,theyreadinformationaboutthecontextorreasoning
resultsfromtheresidualstream,thenenhancetheinformationthatneedstobeexpressedasoutput,andwriteitback
intothestream. AmplificationHead[Lieberumetal.,2023]andCorrectHead[Wiegreffeetal.,2024]amplifythe
signalofthecorrectchoiceletterinMCQAproblemsnearthe[END]position. Thisamplificationensuresthatafter
passingthroughtheUnembeddinglayerandsoftmaxcalculation,thecorrectchoiceletterhasthehighestprobability.
Inadditiontoinformationaggregationandsignalamplification,someEPheadsareusedtoalignthemodel’sreasoning
resultswithuser’sinstructions. Inmultilingualtasks,themodelmaysometimesfailtorespondinthetargetlanguage
thatuserwanted. CoherenceHead [Guoetal.,2024]ensurelinguisticconsistencyinthegeneratedcontent. They
helpLLMsmaintainconsistencybetweentheoutputlanguageandthelanguageofuser’squerywhendealingwith
multilingualinputs. FaithfulnessHead [Tanneruetal.,2024]arestronglyassociatedwiththefaithfulnessofCoT8.
EnhancingtheactivationoftheseheadsallowsLLMstobetteraligntheirinternalreasoningwiththeoutput,makingthe
CoTresultsmorerobustandconsistent.
However, for some simple tasks, LLMs might not require special EP heads to refine language expression. At this
situation,theinformationwrittenbackintotheresidualstreamduringtheICIandLRstagesmaybedirectlysuitablefor
output,i.e.,skiptheEPstageandselecttokenwithhighestprobability.
Figure8: Diagramoftherelationshipbetweenthestageswhereheadsactandthelayerstheyarein,asdescribedin
Section3.2-3.5.
8CoTstandsforChain-of-Thought[Weietal.,2022].Faithfulnessreferstowhetherthemodel’sgeneratedresponseaccurately
reflectsitsinternalreasoningprocessandbehavior,i.e.,theconsistencybetweenoutputandinternalreasoning.
10AttentionHeadsofLargeLanguageModels: ASurvey
3.6 HowAttentionHeadsWorkingTogether?
IfwedividethelayersofaLLM(e.g.,GPT-2Small)intothreesegmentsbasedontheirorder—shallow(e.g.,layers
1-4),middle(e.g.,layers5-8),anddeep(e.g.,layers9-12)—wecanmaptherelationshipbetweenthestageswhere
headsactandthelayerstheyarein,accordingtoSection3.2-3.5. ThefigureisillustratedinFigure8.
Someresearchershaveexploredthepotentialsemanticmeaningsembeddedinthequeryvectorqh =Qh[:,j]and
ℓ,j ℓ
keyvectorkh =Kh[:,j]whenattentionheadscollaborate. Forexample,inMCQAproblem,duringtheICIstage,a
ℓ,j ℓ
ContentGathererHeadmovesthetokensofthecorrectanswertexttothe[END]position. Then,intheLRstage,the
CorrectLetterHeadusestheinformationpassedbytheContentGathererHeadtoidentifythecorrectoption. Thequery
vectorinthiscontexteffectivelyasks,“Areyouthecorrectlabel?” whilerecallingthegatheredcorrectanswertext. The
keyvectorrepresents,“I’mchoice[A/B/C/D],withcorrespondingtext[...]”. Aftermatchingtherightkeyvectortothe
queryvector,wecangetthecorrectanswerchoice.
ConsidertheParityProblem9. DuringtheICIstage,aMoverHeadtransmitsthepositionofthe[EOI]token,which
separatestheinputsequenceandtheintermediatestatesequence,tothe[END]position. IntheLRstage,anIteration
Headfirstreadsthe[EOI]’spositionindexfrom[END]andusesitsqueryvectortoask,“Areyoupositiont?” Thekey
vectorforeachtokenresponds,“I’mpositiont′.” Thisqueryingprocessidentifiesthelastdigitintheinputsequence,
which,combinedwiths ,allowsthemodeltocalculates .
t−1 t
Furtherresearchhasexploredintegratingmultiplespecialattentionheadsintoacohesiveworkingmechanism. Take
theIOI(IndirectObjectIdentification)task,whichteststhemodel’sabilitytodeducetheindirectobjectinasentence,
asanexample. Figure9outlinestheprocess.
1. IntheKRstage,theSubjectHeadandRelationHeadfocuson“Mary”and“boughtflowersfor”,respectively,
triggeringthemodeltorecallthattheanswershouldbeaperson’sname[Chughtaietal.,2024].
2. ThenintheICIstage,theDuplicateHeadidentifies“John”,whiletheNameMoverHeadfocusesonboth
“John”and“Mary”.
3. DuringtheiterativestagesofICIandLR,thePreviousHeadandInductionHeadworktogethertoattendto
“John”. Allthisinformationiswrittentotheresidualstream. ThentheInhibitionHeaddetectsthat“John”
appearsmultipletimesandisthesubject,therebysuppressingthelogitsvalueof“John”.
4. FinallyinthestageofEP,theAmplificationHeadbooststhelogitsvaluefor“Mary”.
Figure9: SchematicdiagramofthecollaborativemechanismofdifferentattentionheadsinIOItask.
9TheParityProbleminvolvesdeterminingtheparity(oddoreven)ofthesumofagivensequence.Thesequenceonlyconsistsof
0/1values.Forinstance,thesumofthesequence“001011”is3,soitisanoddsequence.Lets indicatestheparityofthesumof
i
firstidigits.Sothecorrespondings to“001011”iseeeooeo,whereerepresentsevenandorepresentsodd.Whenqueryingan
[0:t]
LLM,thepromptformatis“[0/1seq.][EOI][s ][END]”,with[EOI]astheEnd-Of-Inputtoken.Theexpectedansweristhefinal
[0:t]
states .
t
11AttentionHeadsofLargeLanguageModels: ASurvey
4 UnveilingtheDiscoveryofAttentionHeads
HowcanweuncoverthespecificfunctionsofthosespecialheadsmentionedinSection3? Inthissection,wewill
unveilingthediscoverymethods. Currentresearchprimarilyemploysexperimentalmethodstovalidatetheworking
mechanismsofthoseheads. Wecategorizethemainstreamexperimentalapproachesintotwotypesbasedonwhether
theyrequiretheconstructionofnewmodels: Modeling-FreeandModeling-Required. Theclassificationschemeand
methodexamplesareshowninFigure10.
+/-
+ +
+
⟹
RetrievalScoreℓℎ =|𝒟𝑟𝑖𝑔 |𝒟ℎ𝑡 𝑎⋂ 𝑙𝑙𝒟 |𝑎𝑙𝑙|
NASℓℎ =෍𝐴𝑡𝑡𝑛ℓℎ𝑖,𝑡𝑌𝑒𝑠 +𝐴𝑡𝑡𝑛ℓℎ𝑖,𝑡𝑁𝑜
+ 𝑖 ⋅𝑙𝑜𝑔 𝐴𝐴 𝑡𝑡 𝑡𝑡 𝑛𝑛 ℓℎℓℎ 𝑖𝑖 ,, 𝑡𝑡 𝑌𝑁 𝑒𝑜
𝑠
……
Figure10: Piechartofmethodsforexploringspecialattentionheadsanddiagramofvariousmethods.
4.1 Modeling-Free
Table1: BriefsummarizationofModeling-Freemethods.
Type SpecificMethod CoreOperation RepresentativeWorks
DirectionalAddition Addingextrainformationtoaspecificcomponent’slatentstate Tiggesetal.[2023],Yuetal.[2024a],Turneretal.[2023]
Modification-Based
DirectionalSubtraction Subtractingpartofinformationfromaspecificcomponent’slatentstate Tiggesetal.[2023]
Wangetal.[2022],YuandAnaniadou[2024],Jinetal.[2024],
ZeroAblation Thecomponent’slatentstateisreplacewithzerovectors
Yaoetal.[2024]
Thecomponent’slatentstateisreplacewiththemeanstateacrossall
Replacement-Based MeanAblation samplespassingthroughit McDougalletal.[2023],Wangetal.[2022]
Thecomponent’sactivationisreplacedwithcorrespondingactivation Merulloetal.[2024],Toddetal.[2023],Wangetal.[2022],
NaïveActivationPatching
runbyacorruptedprompt Lieberumetal.[2023],Wiegreffeetal.[2024]
Modeling-Free methods do not require setting up new models, making them widely applicable in interpretability
research. ThesemethodstypicallyinvolvealteringalatentstatecomputedduringtheLLMs’reasoningprocessand
then using Logit Lens to map the intermediate results to token logits or probabilities. By calculating the logit (or
probability) difference, researchers can infer the impact of the change. Modeling-Free methods primarily include
ActivationPatchingandAblationStudy. However,duetothefrequentinterchangeofthesetermsintheliterature,a
newperspectiveisrequiredtodistinguishthem. ThispaperfurtherdividesthesemethodsintoModification-Basedand
Replacement-BasedMethodsbasedonhowthelatentstaterepresentationisaltered,assummarizedinTable1.
Modification-Basedmethodsinvolvealteringthevaluesofaspecificlatentstatewhileretainingsomeoftheoriginal
information. Directional Addition retains part of the information in the original state and then directionally adds
someadditionalinformation. Forinstance,Tiggesetal.[2023]inputtextscontainingpositiveandnegativesentiments
intoLLMs,obtainingpositiveandnegativerepresentationsfromthelatentstate. Thedifferencebetweenthesetwo
representationscanbeseenasasentimentdirectioninthelatentspace. Byaddingthissentimentdirectionvectortothe
activationoftheattentionheadunderinvestigation,theeffectontheoutputcanbeanalyzedtodeterminewhetherthe
headhastheabilitytosummarizesentiment.
Conversely,DirectionalSubtractionretainspartoftheoriginalstateinformationwhiledirectionallyremovingsomeof
it[Liangetal.,2024b]. Thismethodcanbeusedtoinvestigatewhetherremovingspecificinformationfromalatent
12AttentionHeadsofLargeLanguageModels: ASurvey
stateaffectsthemodel’soutputinasignificantway,therebyrevealingwhethercertainattentionheadscanbackuporfix
thedeletedinformation.
IncontrasttoModification-Basedmethods,Replacement-Basedmethodsdiscardallinformationinaspecificlatent
stateandreplaceitwithothervalues. ZeroAblationandMeanAblationreplacetheoriginallatentstatewithzerovalues
orthemeanvalueoflatentstatesacrossallsamplesfromadataset,respectively. Thiscanlogically“eliminate”thehead
orcauseittoloseitsspecialfunction,allowingresearcherstoassessitsimportance.
NaiveActivationPatchingisthetraditionalpatchingmethod. Itinvolvesusingalatentstateobtainedfromacorrupted
prompttoreplacetheoriginallatentstateatthecorrespondingposition. Forexample,considertheoriginalprompt
“JohnandMarywenttothestore.” Replacing“Mary”with“Alice”resultsinacorruptedprompt. Bysystematically
replacingthelatentstateobtainedundertheoriginalpromptwiththeoneobtainedunderthecorruptedpromptacross
eachhead,researcherscanpreliminarilydeterminewhichheadhastheabilitytofocusonnamesbasedonthemagnitude
oftheimpact[HeimersheimandNanda,2024,ZhangandNanda,2024].
4.2 Modeling-Required
Table2: BriefsummarizationofModeling-Requiredmethods.
Type SpecificMethod CoreOperation RepresentativeWorks
Calculatethescorethatreflectstherelationshipbetween Jinetal.[2024],Wuetal.[2024],Crosbie[2024],Yuetal.[2024a],
Scoring
Training-Free thecomponent’sattributesandLLMfeatures Ji-Anetal.[2024]
Others Newmethodsthathavenotyetbeenwidelyadopted FerrandoandVoita[2024]
Trainaclassifiertodistinguishheadswithdifferentfunc- Lietal.[2024b],Hoscilowiczetal.[2024],Gouldetal.[2023],
Probing
Training-Required tionsusingactivationvalues Guoetal.[2024],Yangetal.[2024]
SimplifiedModelTraining Trainanapproximatesimplifiedmodel Edelmanetal.[2024],Cabannesetal.[2024],Elhageetal.[2021]
Modeling-Requiredmethodsinvolveexplicitlyconstructingmodelstodelvedeeperintothefunctionsofspecificheads.
Basedonwhetherthenewlyconstructedmodelsrequiretraining,wefurthercategorizeModeling-Requiredmethods
intoTraining-RequiredandTraining-Freemethods,assummarizedinTable2.
Training-Required methods necessitate training the newly established models to explore mechanisms. Probing
isacommontraining-basedmethod. Thisapproachextractsactivationvaluesfromdifferentheadsasfeaturesand
categorizesheadsintodifferentclassesaslabels.Aclassifieristhentrainedonthisdatatolearntherelationshipbetween
theactivationpatternsandthehead’sfunction. Subsequently,thetrainedclassifiercanserveasaprobetodetectwhich
headswithintheLLMspossesswhichfunctions[Yangetal.,2024,Lietal.,2024b].
Anotherapproachinvolvestrainingasimplifiedtransformermodelonacleandatasetforaspecifictask. Researchers
investigatewhethertheheadsinthissimplifiedmodelexhibitcertainfunctionalities,whichcanthenbeextrapolated
whethersimilarheadsintheoriginalmodelpossessthesamecapabilities. Thismethodreducescomputationalcosts
duringtrainingandanalysis,whiletheconstructedmodelremainssimpleandhighlycontrollable[Cabannesetal.,
2024].
Training-Freemethodsprimarilyinvolvedesigningscoresthatreflectspecificphenomena. Thesescorescanbeviewed
asmathematicalmodelsthatconstructanintrinsicrelationshipbetweentheattributesofcomponentsandcertainmodel
characteristicsorbehaviors. Forinstance,wheninvestigatingRetrievalHeads,Wuetal.[2024]definedaRetrieval
Score. Thisscorerepresentsthefrequencywithwhichaheadassignsthehighestattentionscoretothetokenitaimsto
retrieveacrossasampleset,asshowninEquation4. AhighRetrievalScoreindicatesthattheheadpossessesastrong
“NeedleinaHaystack”ability.
Similarly,whenexploringNegativeHeads,Yuetal.[2024a]introducedtheNegativeAttentionScore(NAS),asshown
inEquation5. Here,idenotesthei-thtokenintheinputprompt,andt andt representthepositionsof“Yes”
Yes No
and“No”intheprompt, respectively. AhighNASsuggeststhattheheadfocusesmoreonnegativetokensduring
decision-making,makingitpronetogeneratingnegativesignals.
|D ∩D |
RetrievalScoreh = right all (4)
ℓ |D |
all
NASh =(cid:88)(cid:0) Attnh[i,t ]+Attnh[i,t ](cid:1) ·log(cid:18) Attnh ℓ [i,t No](cid:19) (5)
ℓ ℓ Yes ℓ No Attnh[i,t ]
i ℓ Yes
Inadditiontoscoring,researchershaveproposedothernoveltraining-freemodelingmethods. FerrandoandVoita
[2024] introduced the concept of an Information Flow Graph, where nodes represent tokens and edges represent
13AttentionHeadsofLargeLanguageModels: ASurvey
informationtransferbetweentokensviaattentionheadsorFFNs. Bycalculatingandfilteringtheimportanceofeach
edgetothenodeitpointsto,keyedgescanbeselectedtoformasubgraph. Thissubgraphcanthenbeviewedasthe
primaryinternalmechanismthroughwhichLLMsperformreasoning.
5 Evaluation
Thissectionsummarizesthebenchmarksanddatasetsusedintheinterpretabilityresearchofattentionheads. Basedon
thedifferentevaluationgoalsduringthemechanismexplorationprocess,wecategorizethemintotwotypes:Mechanism
Exploration Evaluation and Common Evaluation. The former is designed to evaluate the working mechanisms of
specificattentionheads,whilethelatterassesseswhetherenhancingorsuppressingthefunctionsofcertainspecial
headscanimprovetheoverallperformanceofLLMs.
Table3: Mechanismexplorationevaluationbenchmarks. Table4: Commonevaluationbenchmarks.
Type Benchmark Source Type Benchmark Source
Knowledgerecalling LRE[Hernandezetal.,2023] MIT Knowledgereasoning MMLU[Hendrycksetal.,2020] UCB
Sentimentanalysis ToyMovieReview[Tiggesetal.,2023] EleutherAI Knowledgereasoning TruthfulQA[Linetal.,2021] Oxford
Sentimentanalysis ToyMoodStory[Tiggesetal.,2023] EleutherAI Sentimentanalysis SST/SST2[Socheretal.,2013] Standford
Token-levelreasoning ICL-MC[Edelmanetal.,2024] Harvard Longcontextretrieval Needle-in-a-Haystack[Kedaretal.,2023] Github
Arithmeticreasoning Succession[Gouldetal.,2023] Cambridge Textcomprehension TriviaQA[Joshietal.,2017] UoW
Word-levelreasoning ColoredObject[Merulloetal.,2024] BrownU Textcomprehension AGENDA[Koncel-Kedziorskietal.,2019] UoW
Word-levelreasoning IOI[Wangetal.,2022] UCB Textcomprehension AGNews[Zhangetal.,2015] NYU
5.1 MechanismExplorationEvaluation
TodelvedeeperintotheinternalreasoningpathsofLLMs,manyresearchershavesynthesizednewdatasetsbasedon
existingbenchmarks. Theprimaryfeatureofthesedatasetsisthesimplificationofproblemdifficulty,withelements
unrelatedtointerpretability,suchasproblemlengthandqueryformat,beingstandardized. AsshowninTable3,these
datasetsessentiallyevaluatethemodel’sknowledgereasoningandknowledgerecallingcapabilities,buttheysimplify
theanswersfromaparagraph-leveltoatoken-level.
Takeexploringsentiment-relatedheadsasanexample,Tiggesetal.[2023]createdtheToyMovieReviewandToyMood-
Storydatasets,withspecificprompttemplatesillustratedinFigure11. Usingthesedatasets,researchersemployed
samplingmethodstocalculatetheactivationdifferencesofeachheadforpositiveandnegativesentiments. Thisallowed
themtoidentifyheadswithsignificantdifferencesaspotentialcandidatesfortheroleofSentimentSummarizers.
ToyMovieReview:
IthoughtthismoviewasADJECTIVE,IVERBedit.Conclusion:Thismovieis_____.
ToyMoodStory:
NAME VERB parties,andVERB themwheneverpossible.
1 1 2
NAME VERB parties,andVERB themwheneverpossible.
2 3 4
Oneday,theywereinvitedtoagrandgala.[NAME orNAME ]feelsvery_____.
1 2
Figure11: PrompttemplateforToyMovieReviewandToyMoodStorydataset. Forexample,ADJECTIVEcouldbe
“fantastic”/“horrible”,VERBcouldbe“like”/“dislike”.
5.2 CommonEvaluation
The exploration of attention head mechanisms is ultimately aimed at improving the comprehensive capabilities of
LLMs. Manyresearchers, uponidentifyingaheadwithaspecificfunction, haveattemptedtomodifythattypeof
head—suchasbyenhancingordiminishingitsactivation—toobservewhethertheLLMs’responsesbecomemore
accurateanduseful. WeclassifytheseCommonEvaluationBenchmarksbasedontheirevaluationfocus,asshownin
Table4. ThespecialattentionheadsdiscussedinthispaperarecloselyrelatedtoimprovingLLMs’abilitiesinfourkey
areas: knowledgereasoning,sentimentanalysis,longcontextretrieval,andtextcomprehension.
14AttentionHeadsofLargeLanguageModels: ASurvey
6 AdditionalTopics
In this section, we summarize various works related to the LLMs interpretability. Although these works may not
introducenewspecialheadsasdiscussedinSection3,theydelveintotheunderlyingmechanismsofLLMsfromother
perspectives. Wewillelaborateonthesestudiesundertwocategories: FFNInterpretabilityandMachinePsychology.
6.1 FFNInterpretability
AsdiscussedinSection2,apartfromattentionheads,FFNsalsoplaysasignificantroleintheLLMsreasoningprocess.
ThissectionprimarilysummarizesresearchfocusedonthemechanismsofFFNsandthecollaborativeinteractions
betweenattentionheadsandFFNs.
OneoftheprimaryfunctionsofFFNsistostoreknowledgeacquiredduringthepre-trainingphase. Daietal.[2021]
proposedthatfactualknowledgestoredwithinthemodelisoftenconcentratedinafewneuronsoftheMLP.Gevaetal.
[2020]observedthattheneuronsintheFFNofGPTmodelscanbelikenedtokey-valuepairs,wherespecifickeyscan
retrievecorrespondingvalues,i.e.,knowledge. Lvetal.[2024]discoveredahierarchicalstorageofknowledgewithin
themodel’sFFN,withlowerlayersstoringsyntacticandsemanticinformation,andhigherlayersstoringmoreconcrete
factualcontent.
FFNseffectivelycomplementthecapabilitiesofattentionheadsacrossthefourstagesdescribedinSection3. The
collaborationbetweenFFNsandattentionheadsenhancestheoverallcapabilitiesofLLMs. Gevaetal.[2023]proposed
thatattentionheadsandFFNscanworktogethertoenrichtherepresentationofasubjectandthenextractitsrelated
attributes,thusfacilitatingfactualinformationretrievalduringtheKnowledgeRecall(KR)stage. Stolfoetal.[2023]
foundthat,unlikeattentionheads,whichfocusonglobalinformationandperformaggregation,FFNsfocusonlyon
asinglerepresentationandperformlocalupdates. Thiscomplementaryfunctionalityallowsthemtoexploretextual
informationbothinbreadth(attentionheads)anddepth(FFNs).
Insummary, eachcomponentofLLMsplaysacrucialroleinthereasoningprocess. Theindividualcontributions
ofthesecomponents,combinedwiththeirinteractions,accomplishtheentireprocessfromKnowledgeRecallingto
Expression.
6.2 MachinePsychology
CurrentresearchontheLLMsinterpretabilityoftendrawsparallelsbetweenthereasoningprocessesofthesemodels
andhumanthinking. ThissuggeststheneedforamoreunifiedframeworkthatconnectsLLMswithhumancognition.
TheconceptofMachinePsychologyhasemergedtofillthisgap[KrichmarandEdelman,2002],exploringthecognitive
activitiesofAIthroughpsychologicalparadigms.
Recently, Hagendorff[2023]andJohanssonetal.[2024]haveproposeddifferentapproachestostudyingmachine
psychology. Hagendorff’sworkfocusesonusingpsychologicalmethodstoidentifynewabilitiesinLLMs,suchas
heuristics and biases, social interactions, language understanding, and learning. His research suggests that LLMs
displayhuman-likecognitivepatterns,whichcanbeanalyzedtoimproveAIinterpretabilityandperformance.
Johansson’sframeworkintegratesprinciplesofoperantconditioning[StaddonandCerutti,2003]withAIsystems,
emphasizingadaptabilityandlearningfromenvironmentalinteractions. ThisapproachaimstobridgegapsinAGI
researchbycombininginsightsfrompsychology,cognitivescience,andneuroscience.
Overall, Machine Psychology provides a new perspective for analyzing LLMs. Psychological experiments and
behavioralanalysesmayleadtonewdiscoveriesaboutthesemodels. AsLLMsareincreasinglyappliedacrossvarious
domainsofsociety,understandingtheirbehaviorthroughapsychologicallensbecomesincreasinglyimportant,which
offersvaluableinsightsfordevelopingmoreintelligentAIsystems.
7 Conclusion
7.1 LimitationsinCurrentResearch
Firstly, we observe that the application scenarios explored in current research are relatively simple and limited to
specifictypesoftasks,lackinggeneralizability. Forinstance,studieslike[Wangetal.,2022]and[Merulloetal.,2024]
havediscoveredreasoningcircuitsinLLMsthroughtaskssuchastheIOItaskandtheColorObjectTask. However,
thesecircuitshavenotbeenvalidatedacrossothertasks,makingitdifficulttoprovewhetherthesemechanismsare
universallyapplicable.
15AttentionHeadsofLargeLanguageModels: ASurvey
Secondly,mostresearchfocusesonthemechanismsofindividualheads,withonlyafewresearchersdelvingintothe
collaborativerelationshipsamongmultipleheads. Asaresult,theexistingworklacksacomprehensiveframeworkfor
understandingthecoordinatedfunctioningofalltheattentionheadsinLLMs.
Finally,theconclusionsofmoststudieslackmathematicalproofs. Manystudiesstartbyproposingahypothesisabouta
circuitormechanismbasedonanobservedphenomenon,followedbyexperimentsdesignedtovalidatethehypothesis.
Thedownsideofthisresearchapproachisthatexperimentscannotestablishthetheoreticalsoundnessofthemechanism,
norcantheydeterminewhetherthemechanismismerelycoincidental.
7.2 FutureDirectionsandChallenges
Building on the limitations discussed above and the content presented earlier, this paper outlines several potential
researchdirectionsforthefuture:
• Exploringmechanismsinmorecomplextasks. Investigatewhethercertainattentionheadspossessspecial
functionsinmorecomplextasks,suchasopen-endedquestionanswering,mathproblems.
• Mechanism’srobustnessagainstprompts. ResearchhasshownthatcurrentLLMsarehighlysensitiveto
prompts,withslightchangespotentiallyleadingtooppositeresponses[Yuetal.,2024b]. Futureworkcould
analyzethisphenomenonthroughthelensofattentionheadmechanismsandproposesolutionstomitigatethis
issue.
• Developingnewexperimentalmethods. Explorenewexperimentalapproaches,suchasdesigningexperi-
mentstoverifywhetheraparticularmechanismisindivisibleorwhetherithasuniversalapplicability.
• Building a Comprehensive Interpretability Framework. This framework should encompass both the
independentandcollaborativefunctioningmechanismsofmostattentionheadsandothercomponents.
• IntegratingMachinePsychology. IncorporateinsightsfromMachinePsychologytoconstructaninternal
mechanism framework for LLMs from an anthropomorphic perspective, understanding the gaps between
currentLLMsandhumancognitionandguidingtargetedimprovements.
8 Limitation
Current research on the interpretability of LLMs’ attention heads is relatively scattered, primarily focusing on the
functionsofindividualheads,withalackofoverarchingframeworks. Asaresult,thecategorizationofattentionhead
functionsfromtheperspectiveofhumancognitivebehaviorinthispapermaynotbeperfectlyorthogonal,potentially
leadingtosomeoverlapbetweendifferentstages.
References
AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,ŁukaszKaiser,andIllia
Polosukhin. Attentionisallyouneed. Advancesinneuralinformationprocessingsystems,30,2017.
LeilaniHGilpin,DavidBau,BenZYuan,AyeshaBajwa,MichaelSpecter,andLalanaKagal. Explainingexplanations:
Anoverviewofinterpretabilityofmachinelearning. In2018IEEE5thInternationalConferenceondatascienceand
advancedanalytics(DSAA),pages80–89.IEEE,2018.
ZacharyCLipton. Themythosofmodelinterpretability: Inmachinelearning,theconceptofinterpretabilityisboth
importantandslippery. Queue,16(3):31–57,2018.
GrégoireMontavon,WojciechSamek,andKlaus-RobertMüller. Methodsforinterpretingandunderstandingdeep
neuralnetworks. Digitalsignalprocessing,73:1–15,2018.
Jacob Devlin. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint
arXiv:1810.04805,2018.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are
unsupervisedmultitasklearners. OpenAIblog,1(8):9,2019.
Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, and James Glass. Lookback lens:
Detecting and mitigating contextual hallucinations in large language models using only attention maps. arXiv
preprintarXiv:2407.07071,2024.
HeLi,HaoangChi,MingyuLiu,andWenjingYang. Lookwithin,whyllmshallucinate: Acausalperspective. arXiv
preprintarXiv:2407.10153,2024a.
16AttentionHeadsofLargeLanguageModels: ASurvey
Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg. Inference-time intervention:
Elicitingtruthfulanswersfromalanguagemodel. AdvancesinNeuralInformationProcessingSystems,36,2024b.
TilmanRäuker,AnsonHo,StephenCasper,andDylanHadfield-Menell.Towardtransparentai:Asurveyoninterpreting
theinnerstructuresofdeepneuralnetworks. In2023ieeeconferenceonsecureandtrustworthymachinelearning
(satml),pages464–483.IEEE,2023.
Tiago Gonçalves, Isabel Rio-Torto, Luís F Teixeira, and Jaime S Cardoso. A survey on attention mechanisms for
medicalapplications: arewemovingtowardbetteralgorithms? IEEEAccess,10:98909–98935,2022.
AlanaSantanaandEstherColombini. Neuralattentionmodelsindeeplearning: Surveyandtaxonomy. arXivpreprint
arXiv:2112.05909,2021.
SnehaChaudhari,VarunMithal,GungorPolatkan,andRohanRamanath. Anattentivesurveyofattentionmodels. ACM
TransactionsonIntelligentSystemsandTechnology(TIST),12(5):1–32,2021.
GianniBrauwersandFlaviusFrasincar. Ageneralsurveyonattentionmechanismsindeeplearning. IEEETransactions
onKnowledgeandDataEngineering,35(4):3279–3298,2021.
HaoyanLuoandLuciaSpecia. Fromunderstandingtoutilization: Asurveyonexplainabilityforlargelanguagemodels.
arXivpreprintarXiv:2401.12874,2024.
Liyuan Liu, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, and JiaweiHan. Understanding the difficulty of training
transformers. InBonnieWebber,TrevorCohn,YulanHe,andYangLiu,editors,Proceedingsofthe2020Conference
on Empirical Methods in Natural Language Processing (EMNLP), pages 5747–5763, Online, November 2020.
AssociationforComputationalLinguistics.
RuibinXiong,YunchangYang,DiHe,KaiZheng,ShuxinZheng,ChenXing,HuishuaiZhang,YanyanLan,Liwei
Wang, and Tieyan Liu. On layer normalization in the transformer architecture. In International Conference on
MachineLearning,pages10524–10533.PMLR,2020.
JianlinSu,MurtadhaAhmed,YuLu,ShengfengPan,WenBo,andYunfengLiu. Roformer: Enhancedtransformerwith
rotarypositionembedding. Neurocomputing,568:127063,2024.
NoamShazeer. Gluvariantsimprovetransformer. arXivpreprintarXiv:2002.05202,2020.
WilliamFedus,BarretZoph,andNoamShazeer. Switchtransformers: Scalingtotrillionparametermodelswithsimple
andefficientsparsity. JournalofMachineLearningResearch,23(120):1–39,2022.
NeelNanda. Acomprehensivemechanisticinterpretabilityexplainer&glossary. NeelNanda’sBlog,1,2022.
Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. Zoom in: An
introductiontocircuits. Distill,5(3):e00024–001,2020.
KevinWang,AlexandreVariengien,ArthurConmy,BuckShlegeris,andJacobSteinhardt. Interpretabilityinthewild:
acircuitforindirectobjectidentificationingpt-2small. arXivpreprintarXiv:2211.00593,2022.
NelsonElhage,NeelNanda,CatherineOlsson,TomHenighan,NicholasJoseph,BenMann,AmandaAskell,Yuntao
Bai,AnnaChen,TomConerly,NovaDasSarma,DawnDrain,DeepGanguli,ZacHatfield-Dodds,DannyHernandez,
AndyJones,JacksonKernion,LianeLovitt,KamalNdousse,DarioAmodei,TomBrown,JackClark,JaredKaplan,
SamMcCandlish,andChrisOlah. Amathematicalframeworkfortransformercircuits. TransformerCircuitsThread,
2021. https://transformer-circuits.pub/2021/framework/index.html.
YunzhiYao,NingyuZhang,ZekunXi,MengruWang,ZiwenXu,ShuminDeng,andHuajunChen. Knowledgecircuits
inpretrainedtransformers. arXivpreprintarXiv:2405.17969,2024.
StefanHeimersheimandNeelNanda. Howtouseandinterpretactivationpatching. arXivpreprintarXiv:2404.15255,
2024.
nostalgebraist. LogitLensonnon-GPT2models+extensions,2021. URLhttps://colab.research.google.com/
drive/1MjdfK2srcerLrAJDRaJQKO0sUiZ-hQtA.
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec
Radford,JeffreyWu,andDarioAmodei. Scalinglawsforneurallanguagemodels. arXivpreprintarXiv:2001.08361,
2020.
RishiBommasani,DrewAHudson,EhsanAdeli,RussAltman,SimranArora,SydneyvonArx,MichaelSBernstein,
JeannetteBohg,AntoineBosselut,EmmaBrunskill,etal. Ontheopportunitiesandrisksoffoundationmodels. arXiv
preprintarXiv:2108.07258,2021.
XunLiang,ShichaoSong,ZifanZheng,HanyuWang,QingchenYu,XunkaiLi,Rong-HuaLi,FeiyuXiong,andZhiyu
Li. Internalconsistencyandself-feedbackinlargelanguagemodels: Asurvey. arXivpreprintarXiv:2407.14507,
2024a.
17AttentionHeadsofLargeLanguageModels: ASurvey
GillesEGignacandEvaTSzodorai. Definingintelligence: Bridgingthegapbetweenhumanandartificialperspectives.
Intelligence,104:101832,2024.
LarryRSquire.Memoryandthehippocampus:asynthesisfromfindingswithrats,monkeys,andhumans.Psychological
review,99(2):195,1992.
EndelTulving. “episodicandsemanticmemory,”inorganizationofmemory. (NoTitle),page381,1972.
WalterKintsch. Theroleofknowledgeindiscoursecomprehension: aconstruction-integrationmodel. Psychological
review,95(2):163,1988.
NoamChomsky. AspectsoftheTheoryofSyntax. Number11.MITpress,2014.
RaySJackendoff. Semanticstructures,volume18. MITpress,1992.
StanislasDehaene. Thenumbersense: Howthemindcreatesmathematics. OUPUSA,2011.
PNJohnson-Laird. Mentalmodels.Towardsacognitivescienceoflanguage,inference,andconsciousness. Harvard
UniversityPress,1983.
WillemJMLevelt. Modelsofwordproduction. Trendsincognitivesciences,3(6):223–232,1999.
GentaIndraWinata,AndreaMadotto,ZhaojiangLin,RosanneLiu,JasonYosinski,andPascaleFung.Languagemodels
arefew-shotmultilinguallearners. InDuyguAtaman,AlexandraBirch,AlexisConneau,OrhanFirat,Sebastian
Ruder,andGozdeGulSahin,editors,Proceedingsofthe1stWorkshoponMultilingualRepresentationLearning,
pages1–15,PuntaCana,DominicanRepublic,November2021.AssociationforComputationalLinguistics.
AlbertoBietti,VivienCabannes,DianeBouchacourt,HerveJegou,andLeonBottou. Birthofatransformer: Amemory
viewpoint. AdvancesinNeuralInformationProcessingSystems,36,2024.
ZhuoranJin,PengfeiCao,HongbangYuan,YuboChen,JiexinXu,HuaijunLi,XiaojianJiang,KangLiu,andJunZhao.
Cuttingofftheheadendstheconflict: Amechanismforinterpretingandmitigatingknowledgeconflictsinlanguage
models. arXivpreprintarXiv:2402.18154,2024.
TomLieberum,MatthewRahtz,JánosKramár,GeoffreyIrving,RohinShah,andVladimirMikulik.Doescircuitanalysis
interpretabilityscale? evidencefrommultiplechoicecapabilitiesinchinchilla. arXivpreprintarXiv:2307.09458,
2023.
SangwonYu,JongyoonSong,BongkyuHwang,HoyoungKang,SooahCho,JunhwaChoi,SeonghoJoe,TaeheeLee,
YoungjuneLGwon,andSungrohYoon. Correctingnegativebiasinlargelanguagemodelsthroughnegativeattention
scorealignment. arXivpreprintarXiv:2408.00137,2024a.
CatherineOlsson,NelsonElhage,NeelNanda,NicholasJoseph,NovaDasSarma,TomHenighan,BenMann,Amanda
Askell,YuntaoBai,AnnaChen,TomConerly,DawnDrain,DeepGanguli,ZacHatfield-Dodds,DannyHernandez,
ScottJohnston,AndyJones,JacksonKernion,LianeLovitt,KamalNdousse,DarioAmodei,TomBrown,JackClark,
JaredKaplan,SamMcCandlish,andChrisOlah. In-contextlearningandinductionheads. TransformerCircuits
Thread,2022. https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html.
JavierFerrandoandElenaVoita. Informationflowroutes: Automaticallyinterpretinglanguagemodelsatscale. arXiv
preprintarXiv:2403.00824,2024.
Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov. Analyzing multi-head self-attention:
Specializedheadsdotheheavylifting,therestcanbepruned. arXivpreprintarXiv:1905.09418,2019.
Wenhao Wu, Yizhong Wang, Guangxuan Xiao, Hao Peng, and Yao Fu. Retrieval head mechanistically explains
long-contextfactuality. arXivpreprintarXiv:2404.15574,2024.
HanlinTang,YangLin,JingLin,QingsenHan,ShikuanHong,YiwuYao,andGongyiWang. Razorattention: Efficient
kvcachecompressionthroughretrievalheads. arXivpreprintarXiv:2407.15891,2024.
CallumMcDougall,ArthurConmy,CodyRushing,ThomasMcGrath,andNeelNanda. Copysuppression: Comprehen-
sivelyunderstandinganattentionhead. arXivpreprintarXiv:2310.04625,2023.
JorgeGarcía-Carrasco,AlejandroMaté,andJuanCarlosTrujillo. Howdoesgpt-2predictacronyms? extractingand
understandingacircuitviamechanisticinterpretability. InInternationalConferenceonArtificialIntelligenceand
Statistics,pages3322–3330.PMLR,2024a.
JackMerullo,CarstenEickhoff,andElliePavlick. Circuitcomponentreuseacrosstasksintransformerlanguagemodels.
InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
CurtTigges,OskarJohnHollinsworth,AtticusGeiger,andNeelNanda. Linearrepresentationsofsentimentinlarge
languagemodels. arXivpreprintarXiv:2310.15154,2023.
18AttentionHeadsofLargeLanguageModels: ASurvey
JieRen,QipengGuo,HangYan,DongruiLiu,XipengQiu,andDahuaLin. Identifyingsemanticinductionheadsto
understandin-contextlearning. arXivpreprintarXiv:2402.13055,2024.
BilalChughtai,AlanCooney,andNeelNanda. Summingupthefacts: Additivemechanismsbehindfactualrecallin
llms. arXivpreprintarXiv:2402.07321,2024.
EricTodd,MillicentLLi,ArnabSenSharma,AaronMueller,ByronCWallace,andDavidBau. Functionvectorsin
largelanguagemodels. arXivpreprintarXiv:2310.15213,2023.
BenjaminLEdelman,EzraEdelman,SurbhiGoel,EranMalach,andNikolaosTsilivis. Theevolutionofstatistical
inductionheads: In-contextlearningmarkovchains. arXivpreprintarXiv:2402.11004,2024.
Aaditya K Singh, Ted Moskovitz, Felix Hill, Stephanie CY Chan, and Andrew M Saxe. What needs to go right
for an induction head? a mechanistic study of in-context learning circuits and their formation. arXiv preprint
arXiv:2404.07129,2024.
LiJi-An,CoreyYZhou,MarcusKBenna,andMarceloGMattar. Linkingin-contextlearningintransformerstohuman
episodicmemory. arXivpreprintarXiv:2405.14992,2024.
JoyCrosbie. Inductionheadsasanessentialmechanismforpatternmatchinginin-contextlearning. arXivpreprint
arXiv:2407.07011,2024.
Jakub Hoscilowicz, Adam Wiacek, Jan Chojnacki, Adam Cieslak, Leszek Michon, Vitalii Urbanevych, and Artur
Janicki. Nl-iti:Optimizingprobingandinterventionforimprovementofitimethod. arXivpreprintarXiv:2403.18680,
2024.
Ping Guo, Yubing Ren, Yue Hu, Yanan Cao, Yunpeng Li, and Heyan Huang. Steering large language models for
cross-lingualinformationretrieval. InProceedingsofthe47thInternationalACMSIGIRConferenceonResearch
andDevelopmentinInformationRetrieval,pages585–596,2024.
JorgeGarcía-Carrasco,AlejandroMaté,andJuanTrujillo. Detectingandunderstandingvulnerabilitiesinlanguage
modelsviamechanisticinterpretability. arXivpreprintarXiv:2407.19842,2024b.
VivienCabannes,CharlesArnal,WassimBouaziz,AliceYang,FrancoisCharton,andJuliaKempe. Iterationhead: A
mechanisticstudyofchain-of-thought. arXivpreprintarXiv:2406.02128,2024.
RhysGould,EuanOng,GeorgeOgden,andArthurConmy. Successorheads: Recurring,interpretableattentionheads
inthewild. arXivpreprintarXiv:2312.09230,2023.
SarahWiegreffe,OyvindTafjord,YonatanBelinkov,HannanehHajishirzi,andAshishSabharwal. Answer,assemble,
ace: Understandinghowtransformersanswermultiplechoicequestions. arXivpreprintarXiv:2407.15018,2024.
SreeHarshaTanneru, DanLey, ChiragAgarwal, andHimabinduLakkaraju. Onthedifficultyoffaithfulchain-of-
thoughtreasoninginlargelanguagemodels. InTrustworthyMulti-modalFoundationModelsandAIAgents(TiFA),
2024.
TianyuFu,HaofengHuang,XuefeiNing,GenghanZhang,BojuChen,TianqiWu,HongyiWang,ZixiaoHuang,Shiyao
Li,ShengenYan,etal. Moa: Mixtureofsparseattentionforautomaticlargelanguagemodelcompression. arXiv
preprintarXiv:2406.14909,2024.
JanePan. Whatin-contextlearning“learns”in-context: Disentanglingtaskrecognitionandtasklearning. Master’s
thesis,PrincetonUniversity,2023.
ZepingYuandSophiaAnaniadou.Howdolargelanguagemodelslearnin-context?queryandkeymatricesofin-context
headsaretwotowersformetriclearning. arXivpreprintarXiv:2402.02872,2024.
JasonWei,XuezhiWang,DaleSchuurmans,MaartenBosma,FeiXia,EdChi,QuocVLe,DennyZhou,etal. Chain-
of-thoughtpromptingelicitsreasoninginlargelanguagemodels. Advancesinneuralinformationprocessingsystems,
35:24824–24837,2022.
AlexanderMattTurner,LisaThiergart,GavinLeech,DavidUdell,JuanJVazquez,UlisseMini,andMonteMacDiarmid.
Activationaddition: Steeringlanguagemodelswithoutoptimization. arXivpreprintarXiv:2308.10248,2023.
XunLiang,HanyuWang,YezhaohuiWang,ShichaoSong,JiaweiYang,SiminNiu,JieHu,DanLiu,ShunyuYao,Feiyu
Xiong,etal. Controllabletextgenerationforlargelanguagemodels: Asurvey. arXivpreprintarXiv:2408.12599,
2024b.
FredZhangandNeelNanda. Towardsbestpracticesofactivationpatchinginlanguagemodels: Metricsandmethods.
InTheTwelfthInternationalConferenceonLearningRepresentations,2024.
JingyuanYang,DapengChen,YajingSun,RongjunLi,ZhiyongFeng,andWeiPeng. Enhancingsemanticconsistency
oflargelanguagemodelsthroughmodelediting: Aninterpretability-orientedapproach. InLun-WeiKu, Andre
Martins,andVivekSrikumar,editors,FindingsoftheAssociationforComputationalLinguisticsACL2024,pages
3343–3353,Bangkok,Thailandandvirtualmeeting,August2024.AssociationforComputationalLinguistics.
19AttentionHeadsofLargeLanguageModels: ASurvey
EvanHernandez,ArnabSenSharma,TalHaklay,KevinMeng,MartinWattenberg,JacobAndreas,YonatanBelinkov,
andDavidBau. Linearityofrelationdecodingintransformerlanguagemodels. arXivpreprintarXiv:2308.09124,
2023.
DanHendrycks,CollinBurns,StevenBasart,AndyZou,MantasMazeika,DawnSong,andJacobSteinhardt.Measuring
massivemultitasklanguageunderstanding. arXivpreprintarXiv:2009.03300,2020.
StephanieLin,JacobHilton,andOwainEvans. Truthfulqa: Measuringhowmodelsmimichumanfalsehoods. arXiv
preprintarXiv:2109.07958,2021.
RichardSocher,AlexPerelygin,JeanWu,JasonChuang,ChristopherDManning,AndrewYNg,andChristopher
Potts. Recursivedeepmodelsforsemanticcompositionalityoverasentimenttreebank. InProceedingsofthe2013
conferenceonempiricalmethodsinnaturallanguageprocessing,pages1631–1642,2013.
ChandrayanKedar,MartinLance,HurtadoLazaro,ArivalaganPrabha,KralPavel,andEltociearAshimine. Llmtest:
Needle-in-a-haystack. https://github.com/gkamradt/LLMTest_NeedleInAHaystack,2023.
Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised
challengedatasetforreadingcomprehension. arXivpreprintarXiv:1705.03551,2017.
RikKoncel-Kedziorski,DhanushBekal,YiLuan,MirellaLapata,andHannanehHajishirzi. Textgenerationfrom
knowledgegraphswithgraphtransformers. arXivpreprintarXiv:1904.02342,2019.
XiangZhang,JunboZhao,andYannLeCun. Character-levelconvolutionalnetworksfortextclassification. Advances
inneuralinformationprocessingsystems,28,2015.
Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Baobao Chang, and Furu Wei. Knowledge neurons in pretrained
transformers. arXivpreprintarXiv:2104.08696,2021.
MorGeva,RoeiSchuster,JonathanBerant,andOmerLevy. Transformerfeed-forwardlayersarekey-valuememories.
arXivpreprintarXiv:2012.14913,2020.
AngLv,KaiyiZhang,YuhanChen,YulongWang,LifengLiu,Ji-RongWen,JianXie,andRuiYan. Interpretingkey
mechanismsoffactualrecallintransformer-basedlanguagemodels. arXivpreprintarXiv:2403.19521,2024.
Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson. Dissecting recall of factual associations in
auto-regressivelanguagemodels. arXivpreprintarXiv:2304.14767,2023.
AlessandroStolfo,YonatanBelinkov,andMrinmayaSachan. Amechanisticinterpretationofarithmeticreasoning
in language models using causal mediation analysis. In Houda Bouamor, Juan Pino, and Kalika Bali, editors,
Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing, pages7035–7052,
Singapore,December2023.AssociationforComputationalLinguistics.
JeffreyLKrichmarandGeraldMEdelman. Machinepsychology: autonomousbehavior,perceptualcategorizationand
conditioninginabrain-baseddevice. CerebralCortex,12(8):818–830,2002.
ThiloHagendorff. Machinepsychology: Investigatingemergentcapabilitiesandbehaviorinlargelanguagemodels
usingpsychologicalmethods. arXivpreprintarXiv:2303.13988,2023.
Robert Johansson, Patrick Hammer, and Tony Lofthouse. Functional equivalence with nars. arXiv preprint
arXiv:2405.03340,2024.
JohnERStaddonandDanielTCerutti. Operantconditioning. Annualreviewofpsychology,54(1):115–144,2003.
QingchenYu,ZifanZheng,ShichaoSong,ZhiyuLi,FeiyuXiong,BoTang,andDingChen. xfinder: Robustand
pinpointanswerextractionforlargelanguagemodels. arXivpreprintarXiv:2405.11874,2024b.
20