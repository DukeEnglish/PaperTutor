Characterizing the Interpretability of Attention
Maps in Digital Pathology
Tomé Albuquerque[0000−0003−3246−7206], Anil Yüce[0000−0003−2688−1873], Markus
D. Herrmann[0000−0002−7257−9205], and Alvaro Gomariz[0000−0002−6172−5190]
F Hoffmann-La Roche AG, Basel, Switzerland
Abstract. Interpreting machine learning model decisions is crucial for
high-risk applications like healthcare. In digital pathology, large whole
slide images (WSIs) are decomposed into smaller tiles and tile-derived
featuresareprocessedbyattention-basedmultipleinstancelearning(AB-
MIL) models to predict WSI-level labels. These networks generate tile-
specificattentionweights,whichcanbevisualizedasattentionmapsfor
interpretability.However,astandardizedevaluationframeworkforthese
maps is lacking, questioning their reliability and ability to detect spuri-
ouscorrelationsthatcanmisleadmodels.Wehereinproposeaframework
to assess the ability of attention networks to attend to relevant features
in digital pathology by creating artificial model confounders and using
dedicated interpretability metrics. Models are trained and evaluated on
data with tile modifications correlated with WSI labels, enabling the
analysis of model sensitivity to artificial confounders and the accuracy
of attention maps in highlighting them. Confounders are introduced ei-
therthroughsynthetictilemodificationsorthroughtileablationsbased
ontheirspecificimage-basedfeatures,withthelatterbeingusedtoassess
moreclinicallyrelevantscenarios.Wealsoanalyzetheimpactofvarying
confounder quantities at both the tile and WSI levels. Our results show
that ABMIL models perform as desired within our framework. While
attention maps generally highlight relevant regions, their robustness is
affectedbythetypeandnumberofconfounders.Ourversatileframework
has the potential to be used in the evaluation of various methods and
theexplorationofimage-basedfeaturesdrivingmodelpredictions,which
could aid in biomarker discovery.
1 Introduction
The integration of digital pathology (DP), particularly with images of Hema-
toxylin and Eosin (H&E) stained tissue sections, in clinical practice opens the
possibility to advance diagnostics through artificial intelligence (AI). Machine
learning (ML) models could assist diagnostic tasks by discovering input-output
correlations in training data. However, these models usually rely on correlations
rather than causal connections [3]. Consequently, ML predictions may be based
on spurious correlations, including confounding artifacts such as pen marks on
animage[14].Suchconfounderscaninaccuratelyinflatepredictionperformance,
posing risks when human practitioners depend on these predictions. Indeed, the
4202
luJ
2
]VI.ssee[
1v48420.7042:viXra2 T. Albuquerque et al.
lackofexplainabilityofblack-boxmodelsisasignificantbarriertoimplementing
AIinhigh-stakesfields,namelyinhealthcare[6].Therefore,toolstounderstand
and trace ML decision processes are essential to ensure reliable AI support in
medicaldecisions.TherapidadvancementofexplainableAIhasledtonumerous
techniques enhancing the transparency of black-box ML systems [9]. However,
the intricacies of DP datasets call for the use of dedicated methodologies.
Whole slide images (WSI) in DP are very large and usually cannot be pro-
cessed by typical deep learning classification models due to computational con-
straints. The multiple instance learning (MIL) framework has been adopted in
the community, where WSIs are decomposed into smaller tiles that inherit the
WSI’slabelduringtraining[12].Thepopularattention-basedMIL(ABMIL)[10]
network employs a global attention mechanism to learn weights accounting for
the contribution of each tile representation to the final WSI prediction. Tiles
in the WSI are often visualized by their weights values as attention maps, en-
abling the interpretation of which regions are prioritized by the ABMIL model
prediction process [4].
The described interpretability methods make ML predictions more trans-
parent and may reveal new pathological insights. However, the proficiency of
attention maps in identifying misleading correlations, also known as spurious
correlations, has been criticized [2,7]. In the context of X-ray chest images, a
framework has been proposed [15] to assess the identification of spurious corre-
lations in classification models by systematically introducing confounders in the
training and evaluation data.
In the DP ABMIL setting, only some of the tiles may contain the informa-
tion necessary for model predictions, hence requiring a different experimental
design and evaluation metrics for the assessment of attention maps employed
for interpretability. We herein build on the work of Sun et al. [15] by providing
a framework suitable for ABMIL with DP WSIs, including new experimental
designs and metrics that emphasize the role of tiles in model predictions. Our
framework, illustrated in Fig. 1, includes the study of tile- and WSI-based con-
founders, which are first validated with synthetic confounders involving image
modifications.Wethenexplorethemoreclinicallyrelevantscenarioofenriching
for confounders via sampling tiles based on image-based features.
2 Methods
2.1 Attention Maps in Digital Pathology
WeadopttheABMIL[10]frameworkdescribedaboveforbinaryclassification.A
WSIs , i∈{1,...,S}isdecomposedintonon-overlappingtiles tj ∈Rn×n,with
i i
nthetilesizeandS thenumberofWSIs.Tilesareprocessedbyafeatureextrac-
tion model G:Rn×n →Rk, yielding embedding vectors of length k. We define
the ABMIL model as F :RT×k →{0,1}, which employs an attention mecha-
nism on the T embeddings to predict the binary WSI label, with ground truth
y . Attention maps are generated by visualizing the resulting attention weights
si
aj ∈R corresponding to each of the tiles tj. These maps help identify which
i ier
d
n
u
o
nf
o
C
Characterizing the Interpretability of Attention Maps in Digital Pathology 3
Classification
0riginal MIL Prediction evaluation
NO
WSI
0
Different
Tiling prediction with YES
confounders?
AAtttteennttiioonn
% mmaappss
Classification Interpretability
Modified MIL Prediction evaluation evaluation
Fig.1: Overview of our framework for the evaluation of attention maps in DP.
regions contribute most to the WSI-level prediction, enhancing interpretability
and aiding in the detection of spurious correlations or areas of interest.
2.2 Framework for the Interpretability of Attention Maps
As illustrated in Fig. 1, our framework applies controlled modifications to the
tiles in WSIs of a specific class. These modifications act as spurious correlations
thataidtheclassificationmodel.Aconfoundedmodelmaychangeitsprediction
when such modification is also used in a test image. When this occurs, we can
assess whether the attention map highlights the modified tiles, hence enabling
our evaluation.
Let M ∼ Bernoulli(p) be a Bernoulli random function. We define M sep-
p p
arately for tiles (Mt) and WSIs (Ms). This means that a modified WSI sˆi is
p p
produced when Ms(s ) = 1, which occurs with probability p. As the goal of
p i
M is to introduce confounders, it is only applied to WSIs with positive label.
p
Consequently, Ms(s ) is always 0 for WSIs with negative label (y = 0). Only
p i si
modifiedWSIssˆi canhavemodifiedtilestˆj,asdefinedbyM (tj).Thus,withina
i p i
modified WSI, only some tiles are actually modified. Two different modification
designs are employed in our experimental setting:
• Tile-based: Different percentages of tiles are modified for all WSIs. Specifi-
cally, Ms is set to 1, and a range of Mt values is assessed. This strategy enables
p p
the examination of how the amount of systematic confounders (i.e., present in
all WSIs) influences the model.
• WSI-based: We study the effect of sporadic confounders that only affect a
varying number of WSIs, whose tiles are affected with the same probability, i.e.
arangeofMs isassessedwhileMt issetto0.5.ThisvalueofMt isheuristically
p p p
defined based on the tile-based observations.
2.3 Evaluation of Artificially Confounded Datasets
ABMIL models F are trained for different training sets created with different
modifications M . Two types of evaluations are performed for assessing the pre-
p
dictions and interpretability separately:
...4 T. Albuquerque et al.
Model predictions: The performance of F is measured with the Area Under
the receiver operator characteristics Curve (AUC) in the binary classification
task.AtestsetisemployedwiththesameM processasthetrainingsetofthat
p
model. The goal is to assess whether the performance increases with p, which
wouldconfirmthatthemodificationisindeedactingasaconfounderandaiding
the model in an artificial way, hence enabling the interpretability evaluation.
Interpretability: EachmodelF isevaluatedoneachWSIofthetestset,once
with and once without modification (F(sˆ) and F(s ) respectively). The goal
i i
is to assess attention differences in the subset of WSIs where the modification
alters the prediction, defined as S¯={s |F(sˆ)̸=F(s )}. These differences are
i i i
measuredasaconfusionmatrix,wheremodifiedtilestˆj
areconsideredpositives,
i
and unmodified tiles tj are considered negatives. The predicted attention aj is
i i
considered a positive prediction when it is in the top 20% of attention tiles, and
negativeotherwise.WeusethefunctionFtop todenotewhenatileisamongthe
att
top 20% tiles (Ftop(tj)=1) or not (Ftop(tj)=0). Two metrics are used in our
att i att i
evaluation:
• Confounder Robustness (CR): We propose this metric to quantify the
abilityofanABMILmodeltoattributeitsdecisiontoaconfounder,specifically
as the ratio of WSIs for which the attention to modified tiles is better than
random guess. With the confounder matrix as defined above, it follows that
Prevalence=(1/T)(cid:80) M(tj) and
tj i∈si i
(cid:80) Ftop(tj)M(tj)
Precision= ti∈S¯ att i i
(cid:80) Ftop(tj)
ti∈S¯ att i
Considering that by definition a random assignment would, in average, match
the precision to the prevalence, we define the CR metric as:
1 (cid:88)
CR= 1(Precision>Prevalence)
S¯
s∈S¯
•Normalized Cross Correlation (NCC): Thismetricmeasuresthesensitivity
to changes in attention when applying a modification.
(cid:16) (cid:17)(cid:16) (cid:17)
(cid:80) aj −a aˆj −aˆ
NCC=
1 (cid:88) tj i∈si i i i i
S¯ (cid:114)
(cid:16) (cid:17)2(cid:16) (cid:17)2
si∈S¯(cid:80)
tj i∈si
aj
i
−a
i
aˆj
i
−aˆ
i
where the mean of the attention across tiles in s is denoted as a and aˆ for its
i i i
original and modified version respectively.
In this framework, NCC=1 and CR=0 when p=0, as there are no modifica-
tionsandthemodelproducesthesamepredictions.Forlowp,themodelmaynot
be confounded yet, hence not paying attention to the modifications and yield-
ing high NCC and low CR values. When p=1, the model should be completely
confounded and base its predictions only on the existence of confounders in the
test data, which, in an ideal scenario, would lead to NCC=0 and CR=1.Characterizing the Interpretability of Attention Maps in Digital Pathology 5
3 Experiments and Results
Dataset: We employ CAMELYON16 [11], a publicly available dataset formed
by399WSIsofsentinellymphnodetissuesectionsusedforbinaryclassification
ofWSIsintolymphnodetissuewith(60%)orwithout(40%)cancermetastasis.
We use all tissue tiles and follow the train-test split proposed for the original
challenge, with 20% of the training data employed as validation set, which is
employed to select the best training epoch based on the loss value.
Implementation: WSIs are decomposed into patches of size n=256 pixels,
which are processed by a ResNet50 pre-trained on DP samples as described
in [1,8,5]. The resulting embeddings are aggregated using ABMIL with bags of
of 1024 tiles, 32 bags per batch, a maximum of 300 epochs, feature layers with
[1024,1024,512,128,64,32] nodes, dropout rate of 0.1, binary crossentropy loss
with label smoothing, and learning rate 0.0001.
3.1 Synthetic Modifications
We employ transformations that change the appearance of individual tiles as
indicated in Fig. 2, which allow for controlled experiments to assess the impact
ofthesemodificationsbothontheclassificationandinterpretabilityperformance.
Note that the modifications are only added to the metastatic tissue class to act
asmodelconfounders.TheClever Hans modificationiscreatedbyinsertingtext
("Clever Hans") into the tile at a random position, applying random rotation,
and overlaying it onto the original image using alpha compositing. The blur
artifact is achieved using a Gaussian filter with a standard deviation of 4 pixels.
Thepen mark modificationisgeneratedwithtworandompoints,betweenwhich
a red line is drawn and overlaid with alpha compositing.
Original Clever Hans Blur Pen mark
Fig.2: Examples of synthetic tile modifications employed.
Classification Performance:TheAUCinFig.3showsthat,withafewminor
exceptions, the ABMIL model gradually obtains better classification results as
the amount of confounders increases, both for the tile- and WSI-based experi-
ments, and for all three types of modifications. This performance improvement
confirms that the synthetic modifications act as a confounder for the model.
These results highlight the model’s susceptibility to spurious correlation, hence6 T. Albuquerque et al.
enabling an accurate evaluation of the interpretability of the attention maps.
Interestingly, the increase in performance is generally lower for the WSI-based
approach. This suggests that a lower amount of systematic (tile-based) con-
founders can mislead the model more easily than a higher amount of sporadic
(WSI-based) confounders. The varying influence of each type of modification
underscores the different effects that various confounders can have.
CleverHans Blur PenMark
1 1 1
Tile-Based
0.98 WSI-Based 0.98
0.96 0.95 0.96
0.94 0.94
0.9
0.92 0.92
0.9 0.9
1 1 1
0.5 0.5 0.5
0 0 0
1 1 1
0.5 0.5 0.5
0 0 0
0 20 50 80 100 0 20 50 80 100 0 20 50 80 100
%ofmodification %ofmodification %ofmodification
Fig.3: Classification (top) and explainability performance results (middle and
bottom) for synthetic experiments.
Interpretability Performance: The explainability metrics in Fig. 3 confirm
that, as the amount of confounders increases, the attention maps tend to focus
more on the modified tiles. This effect is reflected by the fact that, as the % of
modification p increases, the NCC decreases and the CS increases, which would
otherwisebecloseto1and0respectivelyforanydegreeofmodifications.When
theWSI-based%ofmodificationsislow,theCRincreasessubstantiallymorefor
Clever Hans than for the other transformations. This observation highlights the
dependence of model’s sensitivity to different confounders, which in our setup
is lower for Clever Hans. The low value of NCC for the blur experiments is
also relevant. We hypothesize this is due to the difficulty in extracting perti-
nent information from blurred tiles, which creates higher variations in attention
weights.
CUA
RC
CCN
CUA
SC
CCN
CUA
SC
CCNCharacterizing the Interpretability of Attention Maps in Digital Pathology 7
3.2 Feature-based Sampling Strategy
While the synthetic confounders presented above allow for controlled experi-
ments in our framework, the results may not be representative of real-world
cases with more subtle confounders. We herein present a proof of concept using
tile ablations to dilute an existing signal, namely by leveraging the known influ-
ence of real WSI-derived features on the model prediction. The size of nuclei of
breastcancercellsisknowntobemorevariablethanthesizeofnucleiofnormal
lymphocytes in the lymph nodes [13]. Hence a higher variance in nuclear size
can be leveraged as a proxy for the presence of breast cancer metastases. We
employtheStandard Deviation of the Average Nuclear Area (SDANA),whichis
calculatedbyfirsttakingtheaverageareaofthecellnucleiforeachtileandthen
taking the standard deviation of these values across the entire WSI. SDANA is
hereinstudiedasafeaturethattheABMILmodelF leveragesforitspredictions.
In this setting, the prevalence of specific tiles is systematically reduced with
the goal of obtaining a similar SDANA in WSIs from either class, so that the
modelcannotleveragethisfeature.Theoriginaltrainingsethasthedistribution
ofSDANAperWSIshowninFig.4a,withaclearseparationbetweenmetastatic
andhealthytissueWSIs.Weanalyzehowtoreducethisseparationbyselectively
removing tiles, only for metastatic tissue WSIs, with an average cell area above
aspecificthreshold.Fig.4bshowstheresultingp-value,asmeasuredbyat-test,
of the separation between both distributions (SDANA for healthy and ablated
WSIs)fordifferentthresholds.Thep-valueismaximizedatthreshold470,which
isusedhereon.ByeliminatingthetilesinthemetastatictissueWSIswithamean
area of cells above 470, we bring the class distributions for SDANA as close as
possible, as shown in Fig. 4c, and hence prevent the ABMIL model from using
SDANA as a discriminative feature.
In this setting, the modification function M is not random. Instead, p de-
p
notes the ratio of tiles with cell area above the selected threshold of 470 to be
removed. The removed tiles are chosen based on their cell area from highest
to lowest. This setting only accounts for classification performance, since our
interpretability metrics require a consistent number of modified tiles; however,
in this setting tiles are removed. Baseline results with a random ablation are
includedforcomparison.Thisbaselineisbasedonanequivalentablation,where
the same number of tiles are removed as in the feature-based experiment, with
the difference that they are selected randomly across the WSI. The ablation for
this random baseline is repeated with 5 replicates using different random tiles,
for which the average AUC is employed.
The results in Fig. 4d show that, as hypothesized, the AUC decreases as the
amountofremovedtilesincreases,whichbringstheSDANAdistributionscloser
across both classes. This is a realistic scenario with less control on the data,
which explains why the trend is not as clear as with the synthetic experiment
results.Still,thedecreaseinperformanceisclearwhencomparedtotherandom
baseline experiment. Hence, this feature-based framework enables the study of
the relevance of specific concept features for DP classification tasks, further
improving our understanding of the model’s decision-making process.8 T. Albuquerque et al.
b)
a) 1
0.8
0.6
0.4
0.2
0
350 400 450 500 550 600
Thresholdaveragenucleararea
d) 1
c)
Tile-Based Tile-BasedBaseline
0.98 WSI-Based WSI-BasedBaseline
0.96
0.94
0.92
0.9
0.88
0 20 50 80 100
%ofmodification
Fig.4: Feature-based sampling strategy. (a) Original distribution. (b) SDANA
class separation. (c) Distribution after ablation. (d) Classification results.
4 Conclusions
We herein establish a framework for evaluating the ability of attention maps
to highlight regions in a WSI containing patterns that correlate with the WSI-
level label. Our results based on synthetic tile ablations underscore the value
of this framework, as both the classification and interpretability metrics follow
the expected trends. The results further confirm that the robustness and in-
terpretability of ABMIL models depend on the type and systematic nature of
confounders. Additionally, we propose a feature-based sampling strategy, where
realDPfeaturesareemployedfordilutingthesignal, i.e.byreducingthepreva-
lence of tiles containing patterns known to be relevant for the task. This setting
demonstrates the value of our framework in real-world scenarios, where the im-
pactofspecificDPfeaturescanbequantitativelymeasured.Ourframeworkcan
also be extended to evaluate real-world confounders that may negatively affect
ML models, which could be assessed on a dataset where natural confounders
have been labeled. Moreover, different feature extraction models and attention
mechanisms could be evaluated in our framework to characterize their behavior
in the presence of confounders. This versatility enhances the potential applica-
tion of our framework, paving the way for more robust and interpretable AI
solutions in digital pathology.
eulav-p
CUACharacterizing the Interpretability of Attention Maps in Digital Pathology 9
References
1. Abbasi-Sureshjani, S., Yüce, A., Schönenberger, S., Skujevskis, M., Schalles, U.,
Gaire, F., Korski, K.: Molecular subtype prediction for breast cancer using H&E
specializedbackbone.In:MICCAIWorkshoponComputationalPathology.pp.1–9
(2021)
2. Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., Kim, B.: Sanity
checks for saliency maps. Advances in neural information processing systems 31
(2018)
3. Baaj,I.,Bouraoui,Z.,Cornuéjols,A.,Denœux,T.,Destercke,S.,Dubois,D.,Lesot,
M.J., Marques-Silva, J., Mengin, J., Prade, H., et al.: Synergies between machine
learning and reasoning-an introduction by the Kay R. Amel group. International
Journal of Approximate Reasoning p. 109206 (2024)
4. Bodria, F., Giannotti, F., Guidotti, R., Naretto, F., Pedreschi, D., Rinzivillo, S.:
Benchmarking and survey of explanation methods for black box models. Data
Mining and Knowledge Discovery 37(5), 1719–1778 (2023)
5. Bredell, G., Fischer, M., Szostak, P., Abbasi-Sureshjani, S., Gomariz, A.: Ag-
gregation model hyperparameters matter in digital pathology. arXiv preprint
arXiv:2311.17804 (2023)
6. Cui, M., Zhang, D.Y.: Artificial intelligence and computational pathology. Labo-
ratory Investigation 101(4), 412–422 (2021)
7. Ghassemi, M., Oakden-Rayner, L., Beam, A.L.: The false hope of current ap-
proaches to explainable artificial intelligence in health care. The Lancet Digital
Health 3(11), e745–e750 (2021)
8. Gildenblat, J., Yüce, A., Abbasi-Sureshjani, S., Korski, K.: Deep cellular embed-
dings: An explainable plug and play improvement for feature representation in
histopathology. In: International Conference on Medical Image Computing and
Computer-Assisted Intervention. pp. 776–785 (2023)
9. Hassija,V.,Chamola,V.,Mahapatra,A.,Singal,A.,Goel,D.,Huang,K.,Scarda-
pane, S., Spinelli, I., Mahmud, M., Hussain, A.: Interpreting black-box models: a
review on explainable artificial intelligence. Cognitive Computation 16(1), 45–74
(2024)
10. Ilse,M.,Tomczak,J.,Welling,M.:Attention-baseddeepmultipleinstancelearning.
In: International conference on machine learning. pp. 2127–2136 (2018)
11. Litjens,G.,Bandi,P.,EhteshamiBejnordi,B.,Geessink,O.,Balkenhol,M.,Bult,
P.,Halilovic,A.,Hermsen,M.,VandeLoo,R.,Vogels,R.,etal.:1399H&E-stained
sentinel lymph node sections of breast cancer patients: the CAMELYON dataset.
GigaScience 7(6), giy065 (2018)
12. Maron, O., Lozano-Pérez, T.: A framework for multiple-instance learning. Ad-
vances in neural information processing systems 10 (1997)
13. Pienta,K.J.,Coffey,D.S.:Correlationofnuclearmorphometrywithprogressionof
breast cancer. Cancer 68(9), 2012–2016 (1991)
14. Plass, M., Kargl, M., Kiehl, T.R., Regitnig, P., Geißler, C., Evans, T., Zerbe, N.,
Carvalho, R., Holzinger, A., Müller, H.: Explainability and causability in digital
pathology. The Journal of Pathology: Clinical Research 9(4), 251–260 (2023)
15. Sun, S., Koch, L.M., Baumgartner, C.F.: Right for the wrong reason: Can inter-
pretable ml techniques detect spurious correlations? In: International Conference
on Medical Image Computing and Computer-Assisted Intervention. pp. 425–434.
Springer (2023)