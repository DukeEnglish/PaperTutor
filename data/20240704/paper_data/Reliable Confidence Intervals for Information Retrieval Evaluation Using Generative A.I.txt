Reliable Confidence Intervals for
Information Retrieval Evaluation Using Generative A.I.
HarrieOosterhuis∗†‡ RolfJagerman∗† ZhenQin†
GoogleResearch GoogleResearch GoogleResearch
RadboudUniversity Amsterdam,TheNetherlands NewYork,US
Amsterdam,TheNetherlands jagerman@google.com zhenqin@google.com
harrie.oosterhuis@ru.nl
XuanhuiWang† MichaelBendersky†
GoogleResearch GoogleResearch
MountainView,US MountainView,US
xuanhui@google.com bemike@google.com
Abstract Keywords
Thetraditionalevaluationofinformationretrieval(IR)systemsis InformationRetrievalEvaluation,LargeLanguageModels,Confi-
generallyverycostlyasitrequiresmanualrelevanceannotation denceIntervals,GenerativeA.I.,ConformalPrediction
fromhumanexperts.Recentadvancementsingenerativeartificial
ACMReferenceFormat:
intelligence–specificallylargelanguagemodels(LLMs)–cangen-
HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichael
eraterelevanceannotationsatanenormousscalewithrelatively
Bendersky.2024.ReliableConfidenceIntervalsforInformationRetrievalEval-
smallcomputationalcosts.Potentially,thiscouldalleviatethecosts uation Using Generative A.I.. In Proceedings of the 30th ACM SIGKDD
traditionallyassociatedwithIRevaluationandmakeitapplicableto ConferenceonKnowledgeDiscoveryandDataMining(KDD’24),August
numerouslow-resourceapplications.However,generatedrelevance 25–29,2024,Barcelona,Spain.ACM,NewYork,NY,USA,11pages.https:
annotationsarenotimmuneto(systematic)errors,andasaresult, //doi.org/10.1145/3637528.3671883
directlyusingthemforevaluationproducesunreliableresults.
In this work, we propose two methods based on prediction-
1 Introduction
poweredinferenceandconformalriskcontrolthatutilizecomputer-
generatedrelevanceannotationstoplacereliableconfidencein- Theevaluationofinformationretrieval(IR)systemsisanimpor-
tervals(CIs)aroundIRevaluationmetrics.Ourproposedmethods tantandlong-establishedpartoftheIRfield[30,71,73].Thegoal
requireasmallnumberofreliableannotationsfromwhichthemeth- ofstandardIRsystemsistoretrieveandrankdocumentsaccord-
odscanstatisticallyanalyzetheerrorsinthegeneratedannotations. ingtotheirrelevancetoaqueryanduser.Accordingly,standard
Usingthisinformation,wecanplaceCIsaroundevaluationmetrics IRevaluationmetrics(e.g.,precision,recall,discountedcumula-
withstrongtheoreticalguarantees.Unlikeexistingapproaches,our tivegain(DCG),etc.)measurehowrelevantthetoprankeditems
conformalriskcontrolmethodisspecificallydesignedforrank- are for a set of known queries [12, 35, 36]. Accordingly, tradi-
ing metrics and can vary its CIs per query and document. Our tionalevaluationrequiresadatasetwithexamplesofdocuments,
experimentalresultsshowthatourCIsaccuratelycaptureboththe queriesandannotationsthatindicatetherelevanceofdocuments
varianceandbiasinevaluationbasedonLLMannotations,better toqueries[39,40,57,69].Whilstdocumentsandqueriesareoften
thanthetypicalempiricalbootstrappingestimates.Wehopeour gatheredbylogginguserinteractions,relevanceannotationsare
contributionsbringreliableevaluationtothemanyIRapplications traditionallycreatedthroughthelabourofhumanexperts,whoare
wherethiswastraditionallyinfeasible. trainedforthespecificlabellingtask[6,17,30,47].Consequently,
creatinganewdatasetforIRevaluationpurposesisgenerallyvery
CCSConcepts costly,andasaresult,nolargedatasetshavebeencreatedformany
IRsettings[19,34,63,74].Thus,fortheselow-resourcesettings
•Informationsystems Evaluationofretrievalresults;•
Computingmethodolog→ ies Semi-supervisedlearningsettings. traditionalevaluationisnotavailableinpractice.
→ Despitethelargecostsinvolved,therehasbeenacontinuous
∗Authorscontributedequallytothiswork. effort,oftendrivenbyinitiativeslikeTRECandCLEF,tocreate
†NowatGoogleDeepMind. newdatasetsfordifferentIRtasks[9,14,31,38,43,52–54,62,65,
‡WorkdonewhileHarrieOosterhuiswasworkingatGoogleResearch.
67,68,70].SincethefoundationalCranfieldcollection[67],many
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor datasets have been created for ad-hoc retrieval [31, 38, 52, 70].
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed However,tomatchthelargevarietyofIR-relatedtasks,manyother
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
datasetsweresubsequentlyintroduced,accordingly;Forexample,
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.
Forallotheruses,contacttheowner/author(s). datasetswithnumericalIRfeaturesforlearning-to-rank[14,53,54],
KDD’24,August25–29,2024,Barcelona,Spain
orlargecollectionsofnaturallanguagequestion-answeringexam-
©2024Copyrightheldbytheowner/author(s).
plessuchasMSMARCO[47]andBioASQ[65].Similarly,recent
ACMISBN979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671883 yearshaveseentheintroductionoftheTREC-DL[17],BEIR[62]
1
4202
luJ
2
]RI.sc[
1v46420.7042:viXraKDD’24,August25–29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
andIstella22[20],amongothers[9,68],specificallyfortheevalua- theconfidenceofthegenerativemodel.Thesepredictionscanbe
tionofneuralIRsystems.Consequently,mostofthesubsequent propagatedtoformanintervalaroundmetricsonthequeryor
advancementsinneuralIRwereonlypossiblebecauseoftheavail- datasetlevel.ThroughCRC,ourapproachcalibratestheintervals
abilityofthesedatasetsandthereliablebenchmarkingthatthey toguaranteethatthetruevalueliesbetweenthemwithamini-
enable[29,45,46,48].Thishighlightstheimportanceandimpact mumprobability.Inotherwords,ourmethodputslowerandup-
ofreliableevaluationontheIRfield[30,57,69]. perboundsaroundtherelevanceofeachdocumentthatnaturally
Itisthusnosurprisethatpotentialnoveldatasourcesarere- translatetoreliableCIonqueryanddataset-levelmetrics.Thereby,
ceivedwithgreatexcitement.Inthepasttwoyears,newadvance- unlikePPI,ourCRCapproachdoesutilizetheconfidenceofthe
mentsingenerativeartificialintelligence[18,28,37,41,51],espe- generativemodelandcanprovideCIonquery-levelperformance.
ciallythearrivaloflargelanguagemodels(LLMs)[11,49,61],are OurresultsonseveralIRbenchmarksshowthatbothourmeth-
speculatedtobringpotentiallygroundbreakingsourcesforIReval- odsprovideCIsaroundLLM-basedmetricpredictionsthataccu-
uation[15,25].LLMsaretrainedonextremelylargecorporaofdi- ratelycapturethetruevalues,whilealsobeingsignificantlyless
versetextsforthetaskofgeneratingfluentnaturallanguage[42,60]. widethanthoseofpreviousCImethods[16,73].Moreover,unlike
Importantly,LLMsarealsocapableatperformingnumerousmis- otherapproaches[3],ourCRCmethodcanvaryCIsperdocument,
cellaneoustaskssuchasquestion-answering,text-summarization queryorcollectionofqueriesandcanthusbetterindicatewherea
andtext-annotation[1,15,27,61,64].Comparedtoannotationby generativemodelismoreorlessreliable.
humanexperts,annotationviaLLMscanbeperformedrelatively Tothebestofourknowledge,ournovelapproachesarethefirst
cheaplyandatmuchlargerscale[44,63].Severalexistingstud- thatleveragescomputer-generatedrelevanceannotationstopro-
ies have already investigated the application of LLM-generated ducereliableCIsforIRevaluation.Wehopethiscontributionopens
relevanceannotationstoIRevaluation[15,25,44].Inparticular, upnovelpossibilitiesforreliablebenchmarkingoflow-resourceIR
Thomasetal.[63]foundthat,whenappliedcorrectlytospecific tasksthathavebeentraditionallyinfeasible.
settings,LLMscanproducebetterlabelsthanthird-partyassessors
at a fraction of the costs. Thus, there is a clear potential for IR
evaluationbasedoncomputer-generatedrelevanceannotations.
However,afundamentalissuewithevaluationbasedonLLMs,
or other generative models, is that they are bound to make er- 2 RelatedWork
rors[8,15,63].Partoftheseerrorsarecoincidental,sinceperfect
2.1 ConfidenceintervalsforIRevaluation
relevancepredictionisinfeasibleinpractice,butothererrorsare
systematic[25].Forinstance,anLLMcouldsystematicallymisesti- Evaluationisawell-establishedcorepartoftheIRfield[30,52,
materelevanceincertaindomainsorondocumentswithparticular 67,71,73].Generally,itaimstomeasurehowwellaretrievalsys-
attributes[8,63].Inturn,theseerrorscouldaffectthefinalevalu- temcanproducealistofrankeddocumentsinresponsetoauser
ationmetricsandresultinincorrectassessmentsofperformance. query[30,58,69].ThemostprevalentformofIRevaluationrelies
Unfortunately,generativemodelscannotgivetrustworthyinsight ondatasetscontainingexamplequeries,documentsandhuman-
into their own reliability [37, 51]. Thus when solely relying on annotatedrelevancelabels[30,57,67,69].Accordingly,thereis
LLM-basedevaluation,onecannotbecertainhowreliabletheir alonghistoryofeffortstocreatesuchdatasetsintheIRcommu-
conclusionsare. nity,suchasTREC[17,31,68,70,71],CLEF[52],NTCIR[38]and
Inthiswork,weinvestigatehowcomputer-generatedrelevance many others [9, 14, 20, 43, 53, 54, 62, 65, 67]. Despite the enor-
annotationscanbeusedforreliableevaluation,byconstructing mousimportanceofthesedatasets,theyareknowntohavelimi-
confidenceintervals(CIs)aroundrankingmetricswiththem[56, tations.Forinstance,expertannotatorscangiveconflictingrele-
73].Ourapproachrequiresasmallnumberofreliablegroundtruth vanceassessments,andtheactualusersofanIRapplicationcan
annotations,inordertostatisticallyanalyzethedistributionofer- disagreewiththeexpertsaswell[57].Furthermore,theconstruc-
rorsthatexistinthegeneratedannotations.Subsequently,weapply tionsofthesedatasetsisoftencostlywhichputsconstraintson
twostate-of-the-artmethodologies[3,4]withastrongtheoretical theirsize[13,14,67,70].Asaresult,IRdatasetscanonlyrepresent
groundingtofindreliableCIs.Inthiswork,weprovidetwomain alimitedsliceofthequeriesthatarealIRsystemreceives[13,73].
methodologicalcontributions: Accordingly,statisticalapproachestoIRevaluationhavebeen
Our first contribution is the novel application of prediction- developedtodealwiththeselimitations.Forexample,ithasbe-
poweredinference(PPI)toIRevaluation[3].PPIappliesclassical come common practice to use significance tests to ensure that
methods for building CIs but builds them around the error be- observeddifferencesinIRmetricsare,withhighprobability,not
tweenthepredictedandtruevaluesofametric.Thereby,somewhat- theresultofrandomchance[26,59,66].Confidenceintervals(CIs)
reasonablepredictionscanleadtosubstantiallysmallerCIsthan have been used to express the uncertainty that comes from us-
classicalCIaroundjustthemetricvalue.ThelimitationsofPPIis ingthedatasetsampleofqueriestoestimateperformanceoverall
thatitdoesnotutilizetheuncertaintyofthegenerativemodel,and queries[16,56].Furthermore,previousworkhasalsoappliedCIfor
thatitonlyprovidesaCIaroundthefinalmetricvalue. relevanceannotatordisagreement[21,33]andmissingrelevance
Oursecondcontributionaddressestheselimitationsbypropos- annotations[5,72,75].ThestatisticalmethodsusedtoconstructCI
inganovelconformalriskcontrol(CRC)approach[2,4].Wein- bypreviousworkinIRhavebeenbasedonempiricalbootstrapping
troduceanovelmethodtoplaceanoptimisticandapessimistic techniques[22,23,32].Tothebestofourknowledge,ourworkis
predictionaroundeachgeneratedrelevancelabel,whichfollows thefirsttoconsiderPPIandCRCmethodsforIRevaluation[3,4].
2ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDD’24,August25–29,2024,Barcelona,Spain
2.2 LLMsforrelevanceannotationgeneration 3.2 Problemsetting
RecentadvancesinLLMshavedemonstratedimpressivecapabil- Inoursetting,wemakethestandardassumptionthatalargeset
itiesonabroadrangeoftasks[1,27,61,64].Previousworkhas ofsampleduserqueriesandadocumentcollectionareavailable.
specificallyconsideredusingLLMsforrelevanceannotationinan However,wedonotassumethattherearehumanrelevanceanno-
IRcontext[15,25,44,63].Thomasetal.[63]proposeusingground tationsforeverydocument-querypair,andinstead,weassumethat
truthrelevancelabelsfromhumanannotators,tofindapromptthat groundtruthannotationsareonlyavailableforasmallsubset:the
resultsinthemostaccurateLLMgeneratedlabels.Theyclaimthat first𝑛queriesoutofatotalof𝑁 queries.Uniquetoourproblem
thismethodproducesrelevanceannotationsatthesamequality settingisthatagenerativemodelisavailabletopredictrelevance
asthird-partyhumanassessorsbutatafractionofthecosts[63]. annotations.Furthermore,ouraimisnottogiveapointestimateof
Clarkeetal.[15]proposethatLLMrelevance-annotationshould thetrueperformanceofasystem,insteadourgoalistoconstructa
beapproachedasaspectrum,sincetheinvolvementofhumanscan reliableCIaroundthetruevalueofanIRmetric.Thereby,weutilize
bevaried.Forinstance,onecoulddelegatemostworktoanLLM thegeneratedrelevanceannotations,butstillexplicitlyindicatethe
butaddsomehumanverification,asacompromiseofreducedcosts resultinguncertaintyinourevaluationwithCIs.
andreliability.Faggiolietal.[25]supportthisapproach,astheysee Informalterms,let𝛼 0,1 beaconfidenceparameter,we
∈ [ ]
severeriskinblindlyfollowingLLMgeneratedrelevancelabels(at desiretofindalowerbound𝑈ˆ andanupperbound𝑈ˆ s.t:
low high
leastforthecurrentstate-of-the-artLLMs).Thedangerforeseenby 𝑃(cid:0) 𝑈ˆ 𝑈 𝑈ˆ (cid:1) 1 𝛼. (3)
bothisthatgeneratedlabelscanmakesystematicerrorsthatlead low ≤ (Q) ≤ high ≥ −
toincorrectandunreliableevaluationofIRsystems[8,15,25].Our Accordingly,𝛼canbechosentomatchthedesiredconfidence,i.e.,
workaddressesthisproblem,andisthusveryrelated;specifically, 𝛼 =0.05leadstoa95%CI.Additionally,inSection6,wepropose
ourcontributioncanbeseenasanapproachofhumanverification a CRC method that can also bound the performance per query,
designedtoquantifyuncertaintystemmingfromLLMusage. thereby,itcanmeetthefollowingquery-levelCIgoal:
(cid:16) (cid:17)
𝑃 𝑈ˆ 𝑞 𝑈 𝑞 𝑈ˆ 𝑞 𝑞 1 𝛼. (4)
3 Preliminaries low ( ) ≤ ( ) ≤ high ( ) | ∼Q ≥ −
Weassumethattheavailablegenerativemodelpredictsadistribu-
3.1 Evaluationmetricsforretrievalsystems
tionoverpossiblerelevancelabelsperquery-documentpair[44,63].
Thegeneralapproachtotheevaluationofaretrievalsystemisto Let𝑃ˆ 𝑅=𝑟 𝑑,𝑞 indicatethepredictedprobabilityforrelevance
considertheexpectedvalueofarankingmetricacrossthequeries ( | )
value𝑟 forthecombinationofdocument𝑑andquery𝑞,themean
it will receive [30]. Standard ranking metrics assume that each
predictedrelevanceisthen:
documenthascertainrelevancetoaquery[39].Forasetoflabels
∑︁
,weuse𝑃 𝑅 =𝑟 𝑑,𝑞 todenotetheprobabilitythatahuman 𝜇ˆ 𝑑 = 𝑃ˆ 𝑅=𝑟 𝑑,𝑞 𝑟. (5)
R ( | ) ( ) ( | )
raterwouldgiverating𝑟 ,tothecombinationofdocument𝑑and 𝑟
query𝑞.Wedefinereleva∈ncReastheexpectedratingvalueoverthis Usingthesepredictedreleva∈ nR
ces,wecanconstructapredictionof
distribution:𝜇 𝑑 𝑞 =(cid:205) 𝑟 𝑃 𝑅=𝑟 𝑑,𝑞 𝑟.Instandardranking performanceonthedataset-levelfromasampledsetofqueries𝑄.
settings,theg( oal| is) topla∈cRem( orerel| evan)
tdocumentsathigher Thisresultsinthefollowingpredictedmetricvalue:
ranks[36].Rankingmetricscapturethisgoalbygivingaweightto
1 ∑︁ ∑︁
eachrank,whichindicateshowmuchtherelevanceofadocument 𝑈ˆ 𝑄 = 𝜔 rank 𝑑 𝑞, 𝑞 𝜇ˆ 𝑑 𝑞 . (6)
( ) 𝑄 ( ( | D )) ( | )
placedatthatrankshouldcontributetothemetric[35].Wewill | |𝑞 𝑄𝑑 𝑞
∈ ∈D
use𝜔todenoteourweightingfunctionwhichtakestherankofa
Asdiscussedinpreviouswork[15,25],basing𝑈ˆ 𝑄 onstate-of-the-
documentasitsinput.Forexample,Precision@Khasthefollowing ( )
artLLMscouldgreatlyreducecosts[63],buttherearemanyrisks
wc tho eer ir gpe hos tp p so u an la nd r din Dg C 𝑞w G ,e t[i h3g e5h ] st : e𝜔f tu D on C fc Gt ai @ vo an K i: ( l𝑥 a𝜔 b)P lr = eec dl@ o1 ogK c[ 2𝑥 u( (≤𝑥 𝑥 m𝐾 +) e1]= n). tsG𝐾1 fi1 ov re[𝑥 n qua≤ ec rh𝐾 yo] 𝑞i; c ,a e tn hod ef i c mn ov omo dpl ev l lee .td Teli hyn udr se e ,p p wl ea in tc hdin s og uo th nu ft um h rea thn p era ren d kn i nco t ot ia v wt eo lecr ds a gp[ ea8 b] a. il bT i oth i uee s ta o tc hfc eu thr ra e ec lg iy ae bo nf ie lr𝑈 iˆ ta yt( i𝑄 v oe)
f
D
metricvalueforasinglequeryis: thepredictions,onehasnoindicationofitstrustworthiness.Our
proposedmethodologiesusetheavailable𝑛groundtruthquery-
∑︁
𝑈 𝑞 = 𝜔 rank 𝑑 𝑞, 𝑞 𝜇 𝑑 𝑞 . (1) levelperformancestogetherwiththemanygeneratedrelevance
( ) ( ( | D )) ( | )
𝑑 𝑞 predictionstoconstructreliableCIsthatquantifytheserisks.
∈D
Let𝑃 𝑞 denotethenaturalquerydistribution;theperformanceof 4 Method1:Prediction-PoweredInferencefor
( )
asystemintermsofthemetricis:
InformationRetrievalEvaluation
𝑈 =E 𝑈 𝑞 = ∑︁ 𝑃 𝑞 𝑈 𝑞 . (2) Our first proposed method applies the prediction-powered infer-
(Q) 𝑞 ∼Q[ ( )] ( | Q) ( ) ence(PPI)frameworktoIRevaluation.PPIisaveryrecentadvance-
𝑞
∈Q mentinCIconstructionintroducedbyAngelopoulosetal.[3].It
Inpractice,𝑈 canneverbecomputedexactly,since𝑃 𝑞 and𝑃 𝑅= utilizescomputer-generatedpredictionstocreatesmallerCIwhen
( ) (
𝑟 𝑑,𝑞 areneverdirectlyavailable.Thus,generally,anestimateof thesepredictionsaresomewhataccurate.Thecoreideaistoavoid
| )
𝑈 ismadeonalargesetofsampleduserqueriesandafewrelevance estimatingavariableonlabelleddatadirectly,andinstead,buildan
judgementsperdocument-querypair[57,73]. estimatearoundthepredictionswhichisthencorrectedbasedon
3KDD’24,August25–29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
thelabelleddata[10].Ifthepredictionsarefoundtobeaccurateon moreaccurate,whilst𝜎ˆ2 shrinksasmoreunlabelleddatabe-
pred
thelabelleddata,thenthisincreasesourconfidencethatitspredic- comesavailable(as𝑁 increases).Comparing𝜎ˆ2 with𝜎ˆ2 reveals
tionsonunlabelleddataarealsoaccurate.Aspredictionsbecome PPI emp
thatPPIcangivealowervarianceestimate,butonlyifpredictions
availableinmuchlargerquantities,thiscanincreaseourconfidence
aresomewhataccurate.Conversely,whentheyareinaccuratethe
furtherintheoverallestimate.Tothebestofourknowledge,we
variancecouldactuallybegreater.
arethefirsttoapplyPPItoIRevaluation.
Finally,inordertoturntheestimatedmeanandvarianceintoa
CI,wefollowAngelopoulosetal.[3]andassume𝑈ˆ PPI 𝑄 follows
4.1 Classicalempiricalmeanestimation ( )
anormaldistribution.The95%confidenceintervalisthen:
BeforewedetailourapplicationofPPI,itiseasiesttostartwith √︄
classicalempiricalestimates.AsstatedinSection3.2,ouraimisto 𝑈ˆ 𝑄 =𝑈ˆPPI 𝑄 1.96 𝜎ˆ e2 rror 𝜎ˆ p2 red . (11)
placeareliableCIaroundthetrueperformance𝑈 𝑄 ,andrelevance high/low ( ) ( )± 𝑛 + 𝑁
( )
annotationsareavailableforthefirst𝑛queriesin𝑄.Therefore,we Accordingly,onecanuseadifferentz-scorethan1.96tochoosea
canmakeanempiricalestimateofthemeanmetricperformance differentlevelofconfidence.Wenotethatthisimplicitlyassumes
basedonthesequeries: thepredictionerrorfollowsasymmetricdistribution.
𝑈ˆemp 𝑄 =
(cid:205)𝑛 𝑖=1𝑈 (𝑞𝑖
), 𝜎ˆ2 =
(cid:205)𝑛 𝑖=1(cid:0) 𝑈ˆemp (𝑄 )−𝑈 (𝑞𝑖 )(cid:1)2
, (7)
advT ah ni ts agc eon iscl iu tsd se is mo pu lir cid tyes ac nri dp sti to ran igo hf tfo ou rr wP aP rdIm ape pt lh ico ad t. ioI nts ,mbi ag kg ie ns gt
( ) 𝑛 emp 𝑛 1
itattractiveforpracticalusage.Alimitationisthatitonlygivesa
−
where𝜎ˆ2 istheestimatedvarianceoftheempiricalestimate,and CIoftheoverallperformance(dataset-level).Therefore,PPIcannot
emp
𝑈 𝑞𝑖 themetricvalueforthesinglequery𝑞𝑖 (Eq.1).Wenotethat beusedtoplaceCIaroundindividualqueryperformances,and
( )
itsvarianceissolelyreflectiveofthegroundtruthdata.Obviously, similarly,itcannotvaryitsconfidencefordifferentqueries.
thisestimatedoesnotfullyutilizeourproblemssetting,asitignores
thequerieswithoutgroundtruthrelevanceannotationsandtheir 5 Background:ConformalPredictionand
correspondingcomputer-generatedrelevanceannotations. ConformalRiskControl
Thissectionprovidesthenecessarybackgroundonconformalpre-
4.2 Prediction-poweredinference
dictionandconformalriskcontrol(CRC)[2,4,7,50],beforeSec-
Incontrast,PPImeanestimationcombinesgroundtruthandpre- tion6introducesourCRCapproachforIRevaluation.
dictedvaluestocreateanestimatorthathaspotentiallymuchlower
variance.Inoursetting,thePPIestimatorisacombinationofthe 5.1 Conformalprediction
estimatedmeanpredictedqueryperformanceandtheestimated Conformalpredictionprovidesauniqueapproachtouncertainty
meanpredictionerror: quantificationinpredictions[7,50].Thekeycharacteristicofcon-
𝑈ˆPPI 𝑄 =
(cid:205) 𝑖𝑁 =1𝑈ˆ (𝑞𝑖
)
(cid:205)𝑛 𝑖=1𝑈 (𝑞𝑖 )−𝑈ˆ (𝑞𝑖
) . (8)
f so etr sm oa fl lp ar be ed lsic .t Fio on rii ns st th aa nt ci ets ,tp hr eed mic ot sio tn bs asa ir ce vn eo rt sii on ndi ov fid tu ha isll aa pb pe rls oab cu ht
( ) 𝑁 + 𝑛
(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) constructsapredictionset byincludingalllabelsthathaveapre-
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) C
meanprediction meanpredictionerror dictedprobabilityaboveathreshold𝜆 0,1 [2].Let𝑃ˆindicatea
∈ [ ]
predictedprobability,𝑋 contextualfeaturesand𝑌 acorresponding
Inotherwords,PPIconstructsanestimateofthequeryperformance
label,thisbasicpredictionsetisthen:
basedonthepredictedrelevanceannotations,andcorrectsitby
theestimatederrorbasedonthedifferencebetweenthepredicted basic 𝑋 𝜆 = 𝑦:𝑃ˆ 𝑌 =𝑦 𝑋 >𝜆 . (12)
C ( | ) { ( | ) }
andgroundtruthannotations.Asaresult,itisunbiased:
Givenasetofi.i.d.calibrationdata,conformalpredictioncanset𝜆
E
𝑄
(cid:2) 𝑈ˆPPI 𝑄 (cid:3) =E
𝑄
(cid:2) 𝑈ˆemp 𝑄 (cid:3) =𝑈 , (9) sothat Cbasiccontainsthetruelabelwithhighprobability:
∼Q ( ) ∼Q ( ) (Q) 𝑃(cid:0) 𝑌 𝑋 𝜆 (cid:1) >1 𝛼. (13)
WhilsttheempiricalandPPIestimateshavethesameexpected ∈Cbasic ( | ) −
value,thekey-differenceistheirvariances.Assumingthequeries Thereby, cancapturetheuncertaintyinthepredictionof
basic
C
arei.i.d.,theestimatedvarianceofPPIcanbedecomposedinto 𝑋,withstrongtheoreticalguarantees,whenappliedtothesame
apartstemmingfromthemeanpredictionandanotherfromthe distributionfromwhichthecalibrationdatawassampled[2].
predictionerror:
5.2 Conformalriskcontrol
𝜎ˆ2 𝑄 =𝜎ˆ2 𝑄 𝜎ˆ2 𝑄 ,
PPI( ) pred( )+ error( ) Forpurposesotherthanlabelprediction,thereisamoregeneral
𝜎ˆ2 𝑄
=∑︁𝑁 (𝑈ˆ (𝑞𝑖
)−
𝑁1 (cid:205)𝑁 𝑗=1𝑈ˆ (𝑞𝑗 ))2
, (10)
versionofthisapproach:conformalriskcontrol(CRC)[4].Let C(𝑋
|
pred( ) 𝑁 1 𝜆 beanarbitraryfunctionthatconstructssetsthatincreasewith
𝑖=1 − 𝜆) , aboundedlossfunctionthatshrinksas grows,andinthis
𝜎ˆ2 𝑄
=∑︁𝑛 (𝑈 (𝑞𝑖 )−𝑈ˆ (𝑞𝑖 )−𝑛1 (cid:205)𝑛 𝑗=1(𝑈 (𝑞𝑗 )−𝑈ˆ (𝑞𝑗 )))2
.
conL text𝛼 ∈R,CRCaimstoguaranteetheexpeC ctedlossisbounded:
error( ) 𝑖=1 𝑛 −1 E (𝑥,𝑦 )∼𝑃 (𝑋,𝑌 )[L(C(𝑋 =𝑥 |𝜆 ),𝑌 =𝑦
)]
<1 −𝛼. (14)
ThisrevealshowPPIcanbenefitfrompredictionsandunlabelled Wecanseethatthisisageneralizedversionofconformalprediction,
data.Weseethat𝜎ˆ2 shrinksaspredictedperformancesbecome sinceitisequivalenttoEq.13when: ,𝑌 =1 𝑌 ∉ [2].
error L(C ) [ C]
4ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDD’24,August25–29,2024,Barcelona,Spain
0.4 15
0.3 10
0.2
5
0.1
0
0
0 1 3 7 15 0 1 3 7 15 0 1 3 7 15 1 0.5 0 0.5 1
− −
Gain(2𝑟 1) Pessimism/optimismparameter:𝜆
−
Figure1:Threedifferentpredictedrelevancedistributions(left)andtheircorresponding𝜇ˆ CRC(𝑑,𝜆 )curves(right).
CRCcanguaranteeEq.14,byfindingavalueof𝜆basedonaset producethevalidprobabilitydistributions;𝑃ˆ and𝑃ˆ :
high low
of𝑛i.i.d.calibrationdata-pointssuchthat:
𝑄ˆ 𝑅=𝑟 𝑑,𝜆
𝑛1∑︁𝑛 L(C(𝑋𝑖 |𝜆 ),𝑌𝑖
)
<𝛼
−
𝐵 − 𝑛𝛼 , (15) 𝑃ˆ high/low (𝑅=𝑟 |𝑑,𝜆 )= (cid:205) 𝑟 ′∈Rhi 𝑄g ˆh h/ il go hw /l( ow (𝑅=| 𝑟 ′ |) 𝑑,𝜆 ). (17)
𝑖=1 Duetopossiblebiasinthepredictedrelevanceannotations,e.g.,
where𝐵isthemaximumpossiblevalueof .Undertheassumption allpredictionscouldbesevereoverorunderestimates,wewantto
L
thatthecalibrationdatawassampledfromthesamedistribution enablebothboundariesofCIstobeoptimisticorpessimistic.For
(𝑃 𝑋,𝑌 ),CRCisproventoprovidetheboundguaranteestatedin elegance,welet𝜆 1,1 andourperturbeddistributioniseither
( ) ∈ (− )
Eq.14[2,4].Wenotethatitispossiblethatno𝜆valueexiststhat optimisticorpessimisticbasedonthesignof𝜆:
cansatisfyEq.15becausethenumberofdata-points𝑛istoosmall. (cid:40) 𝑃ˆ 𝑅=𝑟 𝑑,𝜆 if𝜆 0,
Inthiscase,themethodexplicitlyfailstoprovideaCI,thereby,CRC 𝑃ˆ CRC (𝑅=𝑟 |𝑑,𝜆 )= 𝑃ˆhigh (
𝑅=𝑟
|
𝑑,
𝜆) othe≥
rwise.
(18)
indicateswhenitisunabletoguaranteereliableCIs.Thegenerality low ( | − )
andflexibilityoftheCRCframeworkenablesustobuildourown Thefinaloptimisticorpessimisticestimatesaretheexpectedvalues
CImethodforIRevaluationontopofit. overtheseperturbeddistributions:
∑︁
6 Method2:ConformalRiskControlfor 𝜇ˆCRC (𝑑,𝜆 )= 𝑃ˆ CRC (𝑅=𝑟 |𝑑,𝜆 )𝑟. (19)
𝑟
InformationRetrievalEvaluation ∈R
Oursecondproposedmethodusesconformalriskcontrol(CRC)for
Figure1visualizeshow𝜇ˆCRCvariesoverdifferent𝜆valuesfor
threedifferentpredictedrelevancedistributions.Weseethatlow
CIconstruction[4].IncontrastwithPPI,itcanprovidebothCI
predictedprobabilitiesforthelargestlabelsmeanthat𝜆hastobe
aroundmeanperformanceandperqueryperformance.Italsorelies
greaterfor𝜇ˆCRCtoreachhighvalues,andviceversa,𝜆hastobe
ondifferentassumptionsthanPPIandempiricalbootstrapping.
lowerforlowprobabilitiesforthelowestlabelvaluestoreachlow
Ourdescriptionofthemethodisdividedintothreeparts:firstly,
values.Inotherwords,ittakesmoreextreme𝜆valuesfor𝜇ˆCRCto
weintroduceour function,secondly,wedescribehowcalibra-
C beheavilyoptimisticwhenthegenerativemodelisveryconfidently
tiondataisgathered,andthirdly,weproposeouralternativedual-
pessimistic,andviceversa.
calibrationapproachspecificforCIs.
Thedocument-level 𝜇ˆCRC aretranslatedtoperformanceesti-
matesfollowingEq.1&6butwith𝜇ˆ 𝑑 replacedby𝜇ˆCRC 𝑑,𝜆 .
6.1 Optimisticandpessimisticestimation ( ) ( )
Finally,toconstructCIs,weusetwoparameters:𝜆 1,1
high
∈ (− )
F ino dr ivo iu dr uap lu dr op co us mes e, nC t,tw hi al tl ac ro en ts ht eru nc tt raC nI ss laf to er dt ih ne tore Cle Isv oa nnc qe uo erf ye aa nch d 𝑈a ˆn Cd RC𝜆 lo 𝑄w ,𝜆∈ hig(− h1 .,1 T) h, es.t p. r𝜆 el do iw cte< d𝜆 Chi Igh is,t to heob rt aa nin ge𝑈ˆ bC eR tC w(𝑄 ee, n𝜆 lo thw e) pan erd
-
dataset-levelperformance.Thus,ourCRCmethodtreatseachCIas ( )
turbedestimates:
asetthatincludesallvaluesbetweenitsminimumandmaximum.
Accordingly,wemustpredicttheboundariesofCIsonadocument- 𝑄,𝜆 high,𝜆 low = 𝑈ˆ CRC 𝑄,𝜆 low ,𝑈ˆ CRC 𝑄,𝜆 high . (20)
C( ) [ ( ) ( )]
level, therefore, we propose two functions: 𝜇ˆ high and 𝜇ˆ low, that Ourproposed functionhasseveralsignificantpropertiesthat
providemoreoptimisticandpessimisticpredictionsthan𝜇ˆ,respec- enableittofunC ctionwellasCI:When𝜆 = 𝜆 = 0,itonly
low high
t oi fv te hly e. gW ene ew rai ts ih veth me oo dp et li ,m this um s,/ wpe ess taim keis tm heto prf eo dll io ctw edth de isc tro in bufi td ie on nc 𝑃e ˆ containsthepredicted𝑈ˆ (𝑄 )value,since:𝑈ˆ CRC (𝑄,0 )=𝑈ˆ (𝑄 ).As
the𝜆approachoneandminusone,theperturbedestimatesbecome
andremove𝜆probabilityfromthetoporbottomlabels:1
theminimumandmaximalpossiblemetricvalues:
(cid:16) ∑︁ (cid:17)
𝑄 𝑄ˆ ˆh li og wh ( 𝑅𝑅 == 𝑟𝑟 | 𝑑𝑑 ,, 𝜆𝜆 ) == 𝑃𝑃 ˆˆ ( 𝑅𝑅 == 𝑟𝑟 | 𝑑𝑑 )− mm aa xx
(cid:16)
00 ,, 𝜆𝜆 − 𝑟 ∑︁′∈R 𝑃𝑃 ˆˆ :𝑟( ′ 𝑅𝑅 <𝑟 == 𝑟𝑟 ′′ | 𝑑𝑑 ) (cid:17), .(16) Con𝜆h si egh q→ uel 1i n,m 𝜆 tlo lyw ,→ th− e1 reC a( l𝑄 w, a𝜆 yh sig eh x, i𝜆 stlo sw v) al= ue[ sm foa rx 𝜆𝑈 hi( g· h), am ndin 𝜆𝑈 low(·) t] o. bou(2 n1 d)
( | ) ( | )− − ( | ) thetrueperformance𝑈 ,sinceitmustliebetweentheminimal
𝑟 ′∈R:𝑟 ′>𝑟 andmaximalpossiblem( eQ tr)
icvalues:
Wenotethatwhen𝜆isgreaterthanthepredictedprobabilityfor
𝜆 1,1 ,𝜆 1,𝜆 ; 𝑈 𝑄,𝜆 ,𝜆 .
thelowest/highestlabel,theremainderissubtractedfromthenext ∃ high ∈ (− ) low ∈ (− high ] (Q) ∈C( high low )
lowest/highestlabel,andsoforth.Theresultsarenormalizedto Tosummarize,wehaveproposedanovel 𝑄,𝜆 functionthat
C( )
createsaCIbasedontherelevanceannotationsofagenerative
1Forbrevity,weomit𝑞fromournotation:𝑃ˆ 𝑅=𝑟𝑑,𝑞 =𝑃ˆ 𝑅=𝑟𝑑 . model.Itfollowstheconfidenceoftheunderlyinggenerativemodel
( | ) ( | )
5
𝑑
𝑟=𝑅
ˆ𝑃
)
|
(
𝜆,𝑑
CRCˆ𝜇
)
(KDD’24,August25–29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
byperturbingthepredictedrelevancedistributionsinanoptimistic Table1:DCG@10performanceofdifferentrankersasmea-
orpessimisticmanner.Theremainderofthissectionexplainshow suredbyhuman-annotatedlabelsandLLM-generatedlabels.
wedeterminethevaluesof𝜆 and𝜆 suchthatareliableCIis Eachapproachranksthetop-100resultsretrievedbyBM25.
high low
foundthatcapturesthetruemetricvaluewithhighconfidence.
TREC-DL Robust04
Human LLM Human LLM
6.2 Datasamplingandbootstrapping
Random 3.16 6.86 0.99 2.96
InordertoperformCRCcalibration,asetofgroundtruthexamples
BM25 8.25 12.93 2.71 4.32
isrequiredtoserveascalibrationdata.Inoursetting,weaimto
LLM 12.81 23.73 3.23 7.17
estimatethemeanoverthetruequery-distribution basedonthe
Q Perfect 19.00 17.44 5.70 4.65
sampledsetofqueries𝑄.Accordingly,asetofexamplesofmean
estimatesbasedonsampledsetfrom isrequired;wecreate𝑀
Q
examplesbysamplingfromthe𝑛queriesin𝑄withgroundtruth
annotations:𝑄¯ 𝑖 𝑞1,𝑞2,...𝑞𝑛 .Thecollectionofthese𝑀 sets Accordingly,weassumethatthis(Eq.26)impliesthefollowing:
sho Tu hld erm eaim reic mt ah ne⊂ yd oi{ s ptr tii ob nut sio ton co of n} Q st: rQ u¯ ct= ¯{𝑄 ,¯ f1 o, r𝑄¯ in2, s. ta.. n, c𝑄 e¯ ,𝑀 o} n.
ecould
𝑃(cid:16) 𝑈ˆ CRC (𝑄,𝜆 low )≤𝑈 (Q)≤𝑈ˆ CRC (𝑄,𝜆 high )|𝑄 ∼Q(cid:17) >1 −𝛼. (27)
Q
samplequerieswithorwithoutreplacement,thesizeofthesampled ThisisaverystandardassumptionmadeinCIliterature,andat
setscouldbevaried,etc.Moreover,ifonewantstocreateCIsaround thecoreofmanybootstrappingmethods[22,24].If ¯ iscreatedby
Q
theperformanceofeachquery,theycanchoosethesetstocontain standardsamplingfrom𝑄,thenthisisarelativelysafeassumption.
asinglequery:𝑄¯ 𝑖 = 𝑞𝑖 .Anotheroptionistosamplequeriesand
{ }
subsetsofthedocumenttoberanked,toartificiallyincreasethe 6.4 Overview
varietyincandidatedocumentsavailableperquery.Choicesthat
Finally,wegiveanoverviewofthedifferentcomponentsinour
increasethenumberofexamples𝑀havethepotentialtodecrease
CIwidth.However,iftheresulting ¯ isnolongerrepresentative CRCapproach:OurCIarecreatedwiththe CCRC (𝑄,𝜆 high,𝜆 low )
Q function(Eq.20),where𝑄areallavailablequeries(nogroundtruth
ofthetruedistribution ,thereliabilityoftheCIswilldecrease.
Q annotations required). We note that when the set𝑄 contains a
singlequery,itproducesaCIforquery-levelperformance.
6.3 Dual-calibrationforconfidenceintervals
TheresultingCIareonlyreliableif𝜆 and𝜆 areproperly
high low
Withourdefinitionof 𝑄,𝜆 high,𝜆 low andthecalibrationdata ¯, calibrated.Wedosobyfirstsamplingacollectionofquery-sets ¯
allthatremainsistocC al( ibrate𝜆 highan) d𝜆 low.However,standarQ d (Section6.2)andcalibratingeachparameterindependently(Eq.24Q ).
CRCisdesignedforthecalibrationofasingleparameter.Luckily, DuetothenatureofCI(Eq.22),thisguaranteestheCRCrequire-
forthepurposeofconstructionaCI,wecanapplyCRCcalibration mentismet(Eq.25),andassuming ¯ isrepresentativeof ,this
sequentially.Becauseforany𝑈ˆ low <𝑈ˆ high,thefollowingholds: guaranteesthatourCIarereliablewiQ thagivenprobability(Q Eq.27).
(cid:16) 𝛼 𝛼(cid:17)
𝑃 𝑈 𝑈ˆ 𝑃 𝑈 𝑈ˆ
low high
( ≤ ) ≤ 2 ∧ ( ≥ ) ≤ 2 (22)
𝑃 𝑈ˆ 𝑈 𝑈ˆ 1 𝛼. 7 ExperimentalSetup
low high
−→ ( ≤ ≤ ) ≤ −
Ourexperimentscomparetheconfidenceintervalsproducedby
Therefore,wecanfirstcalibrateoneoftheboundswithCRC,and PPI,CRCandclassicalempiricalbootstrappingonbenchmarkIR
theotherafterwards.Accordingly,weproposetwolossfunctions: datasets,byansweringthefollowingresearchquestions:2
high(cid:0)
CRC
𝑄,𝜆
high
,𝑈 𝑄 (cid:1) =1(cid:2) 𝑈ˆ
CRC
𝑄,𝜆
high
<𝑈 𝑄 (cid:3) , RQ1: Howmanyhuman-annotatedlabelsarerequiredtoproduce
L Llow(cid:0)C CCRC( (𝑄,𝜆 low) ),𝑈( (𝑄) )(cid:1) =1(cid:2) 𝑈ˆ CRC( (𝑄,𝜆
low
)) >𝑈 (( 𝑄 )) (cid:3) . (23)
RQ2:
i Hn ofo wrm rea st ii lv iee nc to an refid the enc ce onin fit de er nv ca els i?
ntervalstosystematicmis-
Throughapplyingtwobinarysearchprocedures,wefindthevalues takesmadebyLLMlabelers?
for𝜆 1,1 and𝜆 1,1 suchthat𝜆 <𝜆 and: RQ3: WhatbenefitscouldPPIandCRCgetfrompotentialimprove-
high low low high
∈ (− ) ∈ (− )
mentsintheaccuracyoflabelgeneration?
𝑀1 ∑︁𝑀 Lhigh/low(cid:0) CCRC (𝑄¯ 𝑖,𝜆 high/low ),𝑈 (𝑄¯ 𝑖 )(cid:1)<1 2(cid:18) 𝛼
−
1 𝑀−𝛼(cid:19) . (24) RQ L4 L: MC -a gn enC eR rC atc ea dpt ru er le ed vi aff ne cr een lc ae bs ei ln s.u Fn oc rer et aa ci hnt qy up ee rr y-q du oe cr uy m?
ent
𝑖=1
pair,apromptisconstructedthataskstheLLMtoassesstherele-
Consequently,accordingtoEq.22,itmustbethecasethattheCRC
vanceaccordingtotherelevancescalesofthedataset,inourcase:
requirementforthecompleteintervalholds:
0–2 (Robust04) and 0–3 (TREC-DL). The LLM is provided with
𝑀 cleardefinitionsofthedifferentrelevancelabels,similarto[63].
𝑀1 ∑︁ 1(cid:2) 𝑈 (𝑄¯ 𝑖
)
∈CCRC (𝑄¯ 𝑖,𝜆 high,𝜆 low )(cid:3) <𝛼
−
1 𝑀−𝛼 . (25) Specifically,instructionsthatgivedefinitionsforrelevancelabels
𝑖=1 in each prompt. We chose prompts that mimic the instructions
forhumanannotatorsascloselyaspossible,hereby,wehopeto
Therefore,theresultingCIhasthedesiredreliability,whenapplied
tothedistributionunderlying ¯:
Q 2OurexperimentalimplementationandourdatasetofgeneratedLLMlabelsare
𝑃(cid:16) 𝑈ˆ CRC (𝑄¯,𝜆 low )≤𝑈 (𝑄¯ )≤𝑈ˆ CRC (𝑄¯,𝜆 high )|𝑄¯ ∼Q¯(cid:17) >1 −𝛼. (26) a cov nai fila db el ne ca et _: irh _t etp vs a: l/ _/ ugi st ih nu gb _. gc eo nm a/ igoogle-research/google-research/tree/master/high_
6ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDD’24,August25–29,2024,Barcelona,Spain
TREC-DL Robust04 TREC-DL Robust04
3.25
12 5 Bootstrap 3.00 1.00 Bootstrap
10 4 PPI 2.75 0.95 PPI
8 3 CRC 2.50 0.90 CRC
46 2 2.25 0.85
2 1 2.00 0.80
0 0 1.75 0.75
0 20 40 60 80 100 0 20 40 60 80 100 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Adversarialbias𝛽 Adversarialbias𝛽
1.00 1.00
0.95 0.95 3.00 1.00
0.90 0.90 0.75
0.85 0.85 2.00
0.50
0.80 0.80 1.00
0.25
0.75 0.75
0 20 40 60 80 100 0 20 40 60 80 100 0.00 0.00
Nr.human-labeledqueries Nr.human-labeledqueries 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1
Oracleweight𝜏 Oracleweight𝜏
Figure2:Width(top)andcoverage(bottom)oftheconfidence
intervalsproducedbythemethods.Thedashedlineinthe Figure3:Widthoftheconfidenceintervalsforincreasing
bottomplotsisthe95%coveragetarget.Shadedareasindicate levelsofLLMbias(𝛽,top-row)andoracle-enhancedLLMac-
95%predictionintervalsover500independentruns. curacy(𝜏 1,bottomrow)with𝑛 = 112onTREC-DLand
→
𝑛 = 125onRobust04.Shadedareasindicate95%prediction
preciselysimulatethemanuallabelingprocessforeachdataset. intervalsover500independentruns.Coverageplotsareomit-
TheexactpromptsareprovidedinAppendixA. tedsinceallmethodsmaintain>95%coverage.
Toobtainrelevancelabels,weruntheLLMsin‘scoringmode’[76].
Thatis,foreachrelevancelabel𝑟 ,wecomputethelog-probability thatonlyconsiderstheavailablehuman-labeleddata,thisisastan-
∈R
oftheLLMoutputtingtherelevancerating𝑟.Thelog-probabilities dardapproachinpreviousIRliterature[5,56,72,73,75].Allour
arethennormalizedviaasoftmaxfunctionsothatweobtaina empiricalbootstrapCIarebasedon10,000bootstrapsamples.PPI
probabilitydistributionthatrepresentstheLLM’sconfidencein iscomputedbyapplyingEq.11toboththevalidationset(thefirst
assigningeachrelevancelabeltothequery-documentpair. 𝑛queries)andthetestset(theremaining𝑁 𝑛queries),itutilizes
AsourLLMmodel,wechoosetouseFlan-UL2[42,60],because bothhumanandLLM-generatedlabels.Fina− lly,ourCRCapproach
itisopensourceandhasdemonstratedstrongperformanceonrank- alsoutilizesboth,weusethevalidationsettocalibratethe𝜆param-
ingtasks[55].Itisworthnotingthatlarger,morepowerful,LLMs etersandthencomputetheCIusingonlytheLLM-generatedlabels
exist[61],andthatwedonotutilizeanyprompt-engineering[63]. onthetest-set.Forcalibration,CRCisprovided𝑀 =10,000batches
Thesechoicesweremadebecausethegoalofourexperimentsisnot eachconsistingof𝑛queriesthatweresampledwithreplacement
tofindthebestLLM-generatedlabels,buttoconfirmwhetherthe fromthevalidationset(seeSection6.2).Wenotethatthebatch
confidenceintervalsproposedbyourmethodsaccuratelycapture sizedependsonthenumberofavailablequerieswithhumanan-
theuncertaintyinLLM-generatedrelevancelabels.Sinceadvance- notations,whichisvariedinourexperiments.FortheCIstobe
mentsinLLMtechniquesresultinrapidchangesinthestate-of- evaluated,theCIisappliedtotheentiretest-settoobtainadataset-
the-art,wechoosetofocusontheestablishedhumanannotator levelCI,i.e.,wecompute 𝑄test,𝜆 high,𝜆
low
(Eq.20).Someofour
settinginstead[17,71]. experimentsconsiderCRCC C( Isaroundquery) -levelperformance,in
Datasets.Ourevaluationisbasedontwoestablishedbenchmark thesecases,𝜆isnotcalibratedonbootstrappedbatchesbuton𝑛
datasets:TREC-DL[17]andTREC-Robust04[71].Bothdatasets batchesthateachcontainasinglequery.
are comprised of documents and queries together with human- WeevaluatetheCIsproducedbyeachmethodbyconsidering
annotatedrelevancejudgments.Foreachdataset,weperforma theirwidthandcoverage.Thewidthmeasureshowwideandthus
random50:50splittoobtainavalidationandtestsetwherethe howinformativeorspecifictheCIis,whereasmallerwidthisbetter.
validationsetisusedforcalibrationofthemethods.(Atraining ThecoveragemeasureshowfrequenttheCIcoversthetrueperfor-
setisnotrequiredinoursetting.)Toavoiddistributionshifts,for manceonthetest-setover500independentlyrepeatedexperiment
TREC-DL, we create a stratified sample over four years (2019 - runs,thusthehigherthebetter.Thetargetforallthemethodsisa
2022)thatensureseachyearisequallyrepresentedineachsplit.As coverageof95%orhigherandweset𝛼 =0.05accordingly.
therankertoevaluate,wechooseBM25,asthemetricwechoose
DCG@10 [35]. In other words, our methods will construct CIs 8 Results
aroundtheDCG@10ofBM25onbothdatasets.Table1displays
8.1 Numberofrequiredhuman-annotations
therankingperformanceofBM25andtheLLM-generatedlabels.
TomatchthegainfunctionofDCGalllabelsweretransformed OurmainresultsaredisplayedinFigure2.Hereweseehowthe
accordingly:𝑟 ′ =2𝑟 1,forallperformanceestimations. widthandcoverageofthedifferentmethodsvary,astheyarepro-
−
Methodsincomparison.Themethodsincludedinourcom- videdwith𝑛querieswithhumanannotationssampledfromthe
parisonare:(i)empiricalbootstrapping[22],(ii)prediction-powered validationset.Asexpected,allmethodsprovidesbetterCIswhen
inference (PPI) (Section 4), and (iii) conformal risk control (CRC) providedwithlargerportionhuman-annotatedqueries,i.e.,as𝑛
(Section6).Theempiricalbootstrapapproachactsasabaseline increasescoverageincreasesandwidthdecreases.
7
egarevoC
htdiW htdiW
htdiWKDD’24,August25–29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
𝜏 =0 𝜏 =0.25 𝜏 =0.50 𝜏 =0.75
30
20
10
0
15
10
5
0
Figure4:95%CIproducedper-querybyCRCusingLLMpredictedrelevanceannotations(𝜏 =0)andoracle-enhancedLLM
annotations(𝜏 >0).ThequeriesaresortedbytheirtrueDCGperformance(accordingtohuman-annotations),indicatedbyred
andgreendots.GreendotsarecoveredbytheirCIwhereasreddotsarenot.BluedotsindicatethepredictedDCGperformance
(accordingtoLLM-generatedannotations).Clearly,theCIsshrinkconsiderablyasannotationsbecomemoreaccurate(𝜏 1).
→
Westartbyconsideringtheperformanceoftheempiricalboot- Figure3showsthewidthsas 𝛽 isvaried(𝑛 = 112onTREC-
strapbaseline.OntheTREC-DLdataset,weseethatitrequires DLand𝑛 = 125onRobust04).Wedonotreportcoverageasall
atleast40labeledqueriestoachieve95%coverage.Furthermore, methodsobtainameancoverageofatleast95%.When𝛽 <0.5,CRC
onRobust04,with100labeledqueriesitalmostreaches95%cover- consistentlyprovidesbetterwidthsthanempiricalbootstrap,whilst
age.However,theplottedpredictionintervalsaroundthereported PPIhasinconsistentimprovements.Asexpected,when𝛽 > 0.5
coveragerevealthatmanyofitsrunsdidnotreach95%coverage. bothmethodsdoworsethanempiricalbootstrapintermsofwidth.
Incontrast,bothourPPIandCRCapproacheshavestronger Thus,wecananswerRQ2:thecoverageofbothPPIandCRC-
coveragewithlessqueries:PPIneedslessthan20queriesonTREC- bootstrap are robust to systematic mistakes made by the LLM,
DLandlessthan40onRobust04.Similarly,CRCneedslessthan30 however,improvementsinwidthsaredependentonLLMaccuracy.
onTREC-DLandlessthan50onRobust04.Intermsofwidth,CRC
clearlyprovidesthesmallestwidthofallthemethods,whilstPPIis 8.3 Potentialfrommoreaccuratelabels
worsethanempiricalbootstraponTREC-DLandcomparableon WerunadditionalexperimentstounderstandhowtheCIsbehave
Robust04.Thiscomparisonisnotentirelyfair,i.e.,thereisgenerally underanoracleLLM:onethatcanperfectlygeneraterelevance
atradeoffbetweencoverageandwidth,itappearsPPIdoesbetter labels.InFigure3,weincreasinglyinterpolatebetweentheLLM-
intermsofcoveragebutthatresultsinwiderCIs.Thus,PPIhas generated relevance labels and the true (human-annotated) rel-
aclearadvantageoverempiricalbootstraponRobust04whereit evance labels using a parameter𝜏 0,1 . As𝜏 increases, the
hasthesamewidthbutmuchbettercoverage.Nevertheless,when performanceoftheLLMlabelsbecom∈ es[ bett] er.First,wenotethat
CRCandPPIhavethesamecoverage,CRChassmallerwidths,with allmethodsretainaperfect100%coverageinthesescenarios,so
anespeciallylargedifferenceonTREC-DL.Therefore,itappears weomittheplotsforcoverage.Theempiricalbootstrapapproach
that CRC has the most informative CI, whilst PPI needs fewer doesnotusetheLLM-generatedlabelsanditsCIisthusnotim-
queriestoreach95%coverage.Bothmethodsprovidesubstantial pactedbytheincreasinglystrongerLLMlabels.ThePPImethodis
improvementsoverempiricalbootstrapping. abletoleveragethestrongerLLMlabelsandisabletosignificantly
ThusweanswerRQ1asfollows:bothPPIandCRCrequireas outperformtheempiricalbootstrapmethod.ThefactthatitsCIis
fewas30human-labeledqueriestoproduceinformativeandreli- placedaroundtheoverallperformance(dataset-level),preventsit
ableconfidenceintervals.Whilstempiricalbootstrappingrequires fromfurtherimprovingthewidth,asitisinherentlylimitedbythe
significantlymorehuman-labeledqueriestoachievesimilarresults. numberofqueries.TheCRCapproachesareabletoworkaround
thislimitationbyefficientlyidentifyingthattheLLM-generated
labelsaremoreaccurateas𝜏 1ontheper-documentlevel.Their
→
per-queryCIscorrespondinglyshrinkandapproach0astheLLM-
8.2 SensitivitytoLLMaccuracy
generatedlabelsbecomebetter.ThisanswersRQ3:BothPPIand
OurPPIandCRCmethodscanbenefitfromaccurateLLMlabels, CRCbenefitfromimprovementsinlabelgenerationaccuracy.
butinordertobereliable,itisalsoimportantthattheyarero-
busttoinaccuratelabels.WeinvestigatetheeffectofLLMaccu- 8.4 Query-performanceconfidenceintervals
racy by adding adversarial bias to the predicted relevance dis-
WeplottheconfidenceintervalsproducedbyCRConindividual
tributions, with 𝛽 0,1 , change the predictions as follows:
(cid:16)∈ [ ] (cid:17) queriesinFigure4.EachplotinthefigureshowsthetrueDCG
𝑃ˆ 𝛽 (𝑅 =𝑟 |𝑑,𝑞
)
= 𝑍1 (1 −𝛽 )𝑃ˆ (𝑅=𝑟 |𝑑,𝑞 )+𝛽 (1 −𝑃ˆ (𝑅=𝑟 |𝑑,𝑞
))
, (basedonhuman-annotatedrelevancelabels)andthepredicted
where𝑍 isanormalizingfactortoensuretheresultisavalidproba- DCG(basedonLLM-generatedlabels)ofallqueriesinthetestsplit.
bilitydistribution.For𝛽 =0thisleavespredictionsunaltered,with ThequeriesaresortedbytheirtrueDCG,thatis,querieswhere
𝛽 =0.5thisisauniformdistributionandat𝛽 =1itproducesthe therankerperformsbestappearontheleftandprogressivelythe
inverseoftheoriginalpredictions. queryperformancegoesdown.Furthermore,weplottheper-query
8
LD-CERT
40tsuboR
01@GCD
01@GCDReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDD’24,August25–29,2024,Barcelona,Spain
CIforvaryingvaluesof𝜏,toindicatehowtheconfidenceintervals inthisworkarethoseoftheauthorsandarenotnecessarilyshared
behaveastheLLM-generatedlabelsbecomemoreaccurate,similar orendorsedbytheirrespectiveemployersorsponsors.
toSection8.3.First,forallplots,weobservethattheCIsvaryper
query:CRCcapturestheuncertaintythroughoutLLM-generated
References
labels.Second,fortheLLM-generatedlabels(𝜏 = 0),weobserve
[1] MeysamAlizadeh,MaëlKubli,ZeynabSamei,ShirinDehghani,JuanDiego
thatwhentheLLMpredictsthattherankerperformspoorlyona Bermeo,MariaKorobeynikova,andFabrizioGilardi.2023.Open-sourcelarge
query,theboundstendtobesmallerforthatquery.Similarly,when languagemodelsoutperformcrowdworkersandapproachChatGPTintext-
annotationtasks.arXivpreprintarXiv:2307.02179(2023).
thepredictedperformanceoftherankerislarge,theboundstendto
[2] AnastasiosNAngelopoulosandStephenBates.2021.Agentleintroductionto
bewider.ThisindicatesthattheLLM-generatedlabelsaregenerally conformalpredictionanddistribution-freeuncertaintyquantification. arXiv
betteratidentifyingquerieswithpoorrankingperformance.Third,
preprintarXiv:2107.07511(2021).
[3] AnastasiosNAngelopoulos,StephenBates,ClaraFannjiang,MichaelIJordan,and
as𝜏
→
1,weseethatCRCisabletoidentifythatthelabelsare TijanaZrnic.2023.Prediction-poweredinference.arXivpreprintarXiv:2301.09633
moreaccurateanditsper-queryCIsbecomesignificantlytighter. (2023).
ThisshowsthatCRCisnotonlyabletovaryitsCIperquery,but [4] AnastasiosNAngelopoulos,StephenBates,AdamFisch,LihuaLei,andTal
Schuster.2022.Conformalriskcontrol.arXivpreprintarXiv:2208.02814(2022).
isalsoabletoestablishbetterper-queryCIsasLLMlabelsbecome [5] JavedAAslam,VirgilPavlu,andEmineYilmaz.2006.Astatisticalmethodfor
moreaccurate.Thisisespeciallynoticeableinthe𝜏 =0.75plotfor systemevaluationusingincompletejudgments.InProceedingsofthe29thannual
internationalACMSIGIRconferenceonResearchanddevelopmentininformation
TREC-DL(top-rightplotinFigure4).Inthisplotthereisasingle retrieval.541–548.
outlierqueryontheleftwheretheLLMiswronganditspredicted [6] PeterBailey,NickCraswell,IanSoboroff,PaulThomas,ArjenPdeVries,and
labelsareuncertain.AsaresulttheCRCmethodcorrectlyplacesa EmineYilmaz.2008.Relevanceassessment:arejudgesexchangeableanddoesit
matter.InProceedingsofthe31stannualinternationalACMSIGIRconferenceon
verywideCIaroundthisparticularquery,whilekeepingtheCIson Researchanddevelopmentininformationretrieval.667–674.
otherqueriestight.Finally,onbothdatasetstheempiricalcoverage [7] VineethBalasubramanian,Shen-ShyangHo,andVladimirVovk.2014.Confor-
of95%isreached,indicatingtheCIsarereliable.Thus,weanswer
malpredictionforreliablemachinelearning:theory,adaptationsandapplications.
Newnes.
RQ4positively:CRCisabletoconstructCIsonaper-querybasis.
[8] EmilyMBender,TimnitGebru,AngelinaMcMillan-Major,andShmargaret
Shmitchell.2021. Onthedangersofstochasticparrots:Canlanguagemodels
betoobig?.InProceedingsofthe2021ACMconferenceonfairness,accountability,
9 Conclusion andtransparency.610–623.
[9] LuizBonifacio,HugoAbonizio,MarziehFadaee,andRodrigoNogueira.2022.
InthispaperwestudyreliableevaluationofIRsystemsusingLLM- Inpars:Unsuperviseddatasetgenerationforinformationretrieval.InProceedings
generatedrelevancelabels.Obtaininghuman-annotatedrelevance ofthe45thInternationalACMSIGIRConferenceonResearchandDevelopmentin
labelsiscostly,especiallyinlow-resourcesettings.WhileLLMscan
InformationRetrieval.2387–2392.
[10] FJayBreidtandJeanDOpsomer.2017.Model-assistedsurveyestimationwith
helpgeneraterelevancelabelsatscale,theyarepronetomakesys- modernpredictiontechniques.(2017).
tematicerrorsandmaybeunreliable.Weresolvethisbyintroducing [11] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,
PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,Amanda
twomethodsthatconstructconfidenceintervals(CIs)aroundrank-
Askell,etal.2020.Languagemodelsarefew-shotlearners.Advancesinneural
ingmetricsproducedbyLLM-generatedrelevancelabels:PPIand informationprocessingsystems33(2020),1877–1901.
CRC.Theseapproachesrequireasmallamountofreliableground [12] MichaelBucklandandFredricGey.1994.Therelationshipbetweenrecalland
precision. JournaloftheAmericansocietyforinformationscience45,1(1994),
truthannotationstostatisticallyanalyzethedistributionoferrors
12–19.
andcorrectthoseerrors. [13] BenCarterette,JamesAllan,andRameshSitaraman.2006.Minimaltestcollec-
Ourresultsdemonstratethattheproposedmethodscancorrect
tionsforretrievalevaluation.InProceedingsofthe29thannualinternationalACM
SIGIRconferenceonResearchanddevelopmentininformationretrieval.268–275.
errorsinLLM-generatedlabelsandproducereliableCIs.Compared [14] OlivierChapelleandYiChang.2011.Yahoo!learningtorankchallengeoverview.
tootherCIapproaches,wecanproduceCIsofsuperiorcoverage InProceedingsofthelearningtorankchallenge.PMLR,1–24.
[15] CharlesLAClarke,GianlucaDemartini,LauraDietz,GuglielmoFaggioli,Matthias
withtighterbounds,leadingtomoreinformativeevaluation.Fur-
Hagen,ClaudiaHauff,NorikoKando,EvangelosKanoulas,MartinPotthast,Ian
thermore,theCIsproducedbyCRCcanbecomputedper-query, Soboroff,etal.2023.4.2HMC:ASpectrumofHuman–Machine-Collaborative
providingfurtherinsightsintoloworhighperformingqueries. RelevanceJudgmentFrameworks.FrontiersofInformationAccessExperimentation
forResearchandEducation(2023),41.
Ourworkisnotwithoutlimitations.First,wenotethatourmeth-
[16] GordonVCormackandThomasRLynam.2006.Statisticalprecisionofinfor-
odsrequireanLLMwithscoring-modetoproduceadistribution mationretrievalevaluation.InProceedingsofthe29thannualinternationalACM
overLLMlabels.ForLLMswithoutscoring-modeonecouldgener-
SIGIRconferenceonResearchanddevelopmentininformationretrieval.533–540.
[17] NickCraswell,BhaskarMitra,EmineYilmaz,DanielCampos,EllenMVoorhees,
atemultiplelabelsstochasticallytoapproximateapredicteddistri- andIanSoboroff.2021.TRECdeeplearningtrack:Reusabletestcollectionsinthe
bution.Second,ourresultssuggestthatapplyingsomesmoothing largedataregime.InProceedingsofthe44thinternationalACMSIGIRconference
onresearchanddevelopmentininformationretrieval.2369–2375.
totheLLM-generatedlabeldistributionisbeneficialtotheresulting
[18] AntoniaCreswell,TomWhite,VincentDumoulin,KaiArulkumaran,BiswaSen-
CIs.Howtosystematicallyoptimizetheamountofsmoothingisan gupta,andAnilABharath.2018.Generativeadversarialnetworks:Anoverview.
openquestion.Similarly,fine-tuningorprompt-engineeringcould IEEEsignalprocessingmagazine35,1(2018),53–65.
[19] JiaCui,BrianKingsbury,BhuvanaRamabhadran,AbhinavSethy,KartikAu-
alsoleadtodistributionsbettersuitedforCIconstruction.Third,we
dhkhasi,XiaodongCui,EllenKislal,LidiaMangu,MarkusNussbaum-Thom,
onlyusetheFlan-UL2asanLLMlabeler.Ourworkcanbeextended MichaelPicheny,etal.2015. Multilingualrepresentationsforlowresource
tousedifferentandpotentiallymorepowerfulLLMs.Futurework
speechrecognitionandkeywordsearch.In2015IEEEworkshoponautomatic
speechrecognitionandunderstanding(ASRU).IEEE,259–266.
couldexploreallofthesedirectionsfurther. [20] DomenicoDato,SeanMacAvaney,FrancoMariaNardini,RaffaelePerego,and
NicolaTonellotto.2022.TheIstella22Dataset:BridgingTraditionalandNeural
LearningtoRankEvaluation.InProceedingsofthe45thInternationalACMSIGIR
Acknowledgements ConferenceonResearchandDevelopmentinInformationRetrieval.3099–3107.
[21] ThomasDemeester,RobinAly,DjoerdHiemstra,DongNguyen,andChrisDe-
ThisresearchwassupportedbytheGoogleVisitingResearcher
velder.2016.Predictingrelevancebasedonassessordisagreement:analysisand
program.Anyopinions,findingsandrecommendationsexpressed practicalapplicationsforsearchevaluation. InformationRetrievalJournal19
9KDD’24,August25–29,2024,Barcelona,Spain HarrieOosterhuis,RolfJagerman,ZhenQin,XuanhuiWang,andMichaelBendersky
(2016),284–312. [49] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,Pamela
[22] ThomasJDiCiccioandBradleyEfron.1996. Bootstrapconfidenceintervals. Mishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal.2022.
Statisticalscience11,3(1996),189–228. Traininglanguagemodelstofollowinstructionswithhumanfeedback.Advances
[23] ThomasJDiciccioandJosephPRomano.1988.Areviewofbootstrapconfidence inNeuralInformationProcessingSystems35(2022),27730–27744.
intervals.JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology [50] HarrisPapadopoulos.2008.Inductiveconformalprediction:Theoryandapplica-
50,3(1988),338–354. tiontoneuralnetworks.InToolsinartificialintelligence.Citeseer.
[24] BradleyEfron.1987.Betterbootstrapconfidenceintervals.JournaloftheAmeri- [51] JohnVPavlik.2023.CollaboratingwithChatGPT:Consideringtheimplicationsof
canstatisticalAssociation82,397(1987),171–185. generativeartificialintelligenceforjournalismandmediaeducation.Journalism
[25] GuglielmoFaggioli,LauraDietz,CharlesLAClarke,GianlucaDemartini,Matthias &MassCommunicationEducator78,1(2023),84–93.
Hagen,ClaudiaHauff,NorikoKando,EvangelosKanoulas,MartinPotthast, [52] CarolPeters.2001.Cross-LanguageInformationRetrievalandEvaluation:Work-
BennoStein,etal.2023. Perspectivesonlargelanguagemodelsforrelevance shopofCross-LanguageEvaluationForum,CLEF2000,Lisbon,Portugal,September
judgment.InProceedingsofthe2023ACMSIGIRInternationalConferenceon 21-22,2000,RevisedPapers.Vol.2069.SpringerScience&BusinessMedia.
TheoryofInformationRetrieval.39–50. [53] TaoQinandTie-YanLiu.2013.IntroducingLETOR4.0datasets.arXivpreprint
[26] NorbertFuhr.2018.SomecommonmistakesinIRevaluation,andhowtheycan arXiv:1306.2597(2013).
beavoided.InAcmsigirforum,Vol.51.ACMNewYork,NY,USA,32–41. [54] TaoQin,Tie-YanLiu,JunXu,andHangLi.2010.LETOR:Abenchmarkcollection
[27] FabrizioGilardi,MeysamAlizadeh,andMaëlKubli.2023.Chatgptoutperforms forresearchonlearningtorankforinformationretrieval.InformationRetrieval
crowd-workersfortext-annotationtasks.arXivpreprintarXiv:2303.15056(2023). 13(2010),346–374.
[28] IanGoodfellow,JeanPouget-Abadie,MehdiMirza,BingXu,DavidWarde-Farley, [55] ZhenQin,RolfJagerman,KaiHui,HongleiZhuang,JunruWu,JiamingShen,
SherjilOzair,AaronCourville,andYoshuaBengio.2020.Generativeadversarial TianqiLiu,JialuLiu,DonaldMetzler,XuanhuiWang,etal.2023.Largelanguage
networks.Commun.ACM63,11(2020),139–144. modelsareeffectivetextrankerswithpairwiserankingprompting.arXivpreprint
[29] JiafengGuo,YixingFan,LiangPang,LiuYang,QingyaoAi,HamedZamani,Chen arXiv:2306.17563(2023).
Wu,WBruceCroft,andXueqiCheng.2020.Adeeplookintoneuralranking [56] TetsuyaSakai.2014.Statisticalreformininformationretrieval?.InACMSIGIR
modelsforinformationretrieval. InformationProcessing&Management57,6 Forum,Vol.48.ACMNewYork,NY,USA,3–12.
(2020),102067. [57] MarkSandersonetal.2010. Testcollectionbasedevaluationofinformation
[30] DonnaHarman.2011. Informationretrievalevaluation. Morgan&Claypool retrievalsystems.FoundationsandTrends®inInformationRetrieval4,4(2010),
Publishers. 247–375.
[31] DonnaKHarman.2005.TheTRECtestcollections.(2005). [58] MarkSandersonandJustinZobel.2005.Informationretrievalsystemevaluation:
[32] TimHesterberg.2011.Bootstrap.WileyInterdisciplinaryReviews:Computational effort,sensitivity,andreliability.InProceedingsofthe28thannualinternational
Statistics3,6(2011),497–526. ACMSIGIRconferenceonResearchanddevelopmentininformationretrieval.162–
[33] GeorgeHripcsakandAdamSRothschild.2005.Agreement,thef-measure,and 169.
reliabilityininformationretrieval.JournaloftheAmericanmedicalinformatics [59] MarkDSmucker,JamesAllan,andBenCarterette.2007. Acomparisonof
association12,3(2005),296–298. statisticalsignificancetestsforinformationretrievalevaluation.InProceedings
[34] ZhiqiHuang,PuxuanYu,andJamesAllan.2023.ImprovingCross-lingualInfor- ofthesixteenthACMconferenceonConferenceoninformationandknowledge
mationRetrievalonLow-ResourceLanguagesviaOptimalTransportDistillation. management.623–632.
InProceedingsoftheSixteenthACMInternationalConferenceonWebSearchand [60] YiTay,MostafaDehghani,VinhQTran,XavierGarcia,DaraBahri,TalSchus-
DataMining.1048–1056. ter,HuaixiuStevenZheng,NeilHoulsby,andDonaldMetzler.2022.Unifying
[35] KalervoJärvelinandJaanaKekäläinen.2002.Cumulatedgain-basedevaluation languagelearningparadigms.arXivpreprintarXiv:2205.05131(2022).
ofIRtechniques.ACMTransactionsonInformationSystems(TOIS)20,4(2002), [61] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-Baptiste
422–446. Alayrac,JiahuiYu,RaduSoricut,JohanSchalkwyk,AndrewMDai,AnjaHauth,
[36] KalervoJärvelinandJaanaKekäläinen.2017.IRevaluationmethodsforretrieving etal.2023.Gemini:afamilyofhighlycapablemultimodalmodels.arXivpreprint
highlyrelevantdocuments.InACMSIGIRForum,Vol.51.ACMNewYork,NY, arXiv:2312.11805(2023).
USA,243–250. [62] NandanThakur,NilsReimers,AndreasRücklé,AbhishekSrivastava,andIryna
[37] MladanJovanovicandMarkCampbell.2022.Generativeartificialintelligence: Gurevych.2021.Beir:Aheterogenousbenchmarkforzero-shotevaluationof
Trendsandprospects.Computer55,10(2022),107–112. informationretrievalmodels.arXivpreprintarXiv:2104.08663(2021).
[38] NorikoKando,KazukoKuriyama,ToshihikoNozue,KojiEguchi,HiroyukiKato, [63] PaulThomas,SethSpielman,NickCraswell,andBhaskarMitra.2023. Large
andSouichiroHidaka.1999.OverviewofIRtasksatthefirstNTCIRworkshop. languagemodelscanaccuratelypredictsearcherpreferences. arXivpreprint
InProceedingsofthefirstNTCIRworkshoponresearchinJapanesetextretrieval arXiv:2309.10621(2023).
andtermrecognition.11–44. [64] PetterTörnberg.2023. Chatgpt-4outperformsexpertsandcrowdworkersin
[39] JaanaKekäläinenandKalervoJärvelin.2002.Usinggradedrelevanceassessments annotatingpoliticaltwittermessageswithzero-shotlearning. arXivpreprint
inIRevaluation. JournaloftheAmericanSocietyforInformationScienceand arXiv:2304.06588(2023).
Technology53,13(2002),1120–1129. [65] GeorgeTsatsaronis,GeorgiosBalikas,ProdromosMalakasiotis,IoannisPartalas,
[40] MichaelELeskandGerardSalton.1968.Relevanceassessmentsandretrieval MatthiasZschunke,MichaelRAlvers,DirkWeissenborn,AnastasiaKrithara,Ser-
systemevaluation.Informationstorageandretrieval4,4(1968),343–359. giosPetridis,DimitrisPolychronopoulos,etal.2015.AnoverviewoftheBIOASQ
[41] YueLiu,ZhengweiYang,ZhenyaoYu,ZituLiu,DahuiLiu,HailongLin,Mingqing large-scalebiomedicalsemanticindexingandquestionansweringcompetition.
Li,ShuchangMa,MaximAvdeev,andSiqiShi.2023.Generativeartificialintel- BMCbioinformatics16,1(2015),1–28.
ligenceanditsapplicationsinmaterialsscience:Currentsituationandfuture [66] JuliánUrbano,HarlleyLima,andAlanHanjalic.2019. Statisticalsignificance
perspectives.JournalofMateriomics(2023). testingininformationretrieval:anempiricalanalysisoftypeI,typeIIandtypeIII
[42] ShayneLongpre,LeHou,TuVu,AlbertWebson,HyungWonChung,YiTay, errors.InProceedingsofthe42ndInternationalACMSIGIRconferenceonResearch
DennyZhou,QuocVLe,BarretZoph,JasonWei,etal.2023.Theflancollection: anddevelopmentininformationretrieval.505–514.
Designingdataandmethodsforeffectiveinstructiontuning. arXivpreprint [67] CornelisJoostVanRijsbergenandWBruceCroft.1975.Documentclustering:An
arXiv:2301.13688(2023). evaluationofsomeexperimentswiththeCranfield1400collection.Information
[43] ClaudioLucchese,FrancoMariaNardini,RaffaelePerego,SalvatoreOrlando,and Processing&Management11,5-7(1975),171–182.
SalvatoreTrani.2018.Selectivegradientboostingforeffectivelearningtorank. [68] Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman,
InThe41stInternationalACMSIGIRConferenceonResearch&Developmentin WilliamRHersh,KyleLo,KirkRoberts,IanSoboroff,andLucyLuWang.2021.
InformationRetrieval.155–164. TREC-COVID:constructingapandemicinformationretrievaltestcollection.In
[44] SeanMacAvaneyandLucaSoldaini.2023. One-ShotLabelingforAutomatic ACMSIGIRForum,Vol.54.ACMNewYork,NY,USA,1–12.
RelevanceEstimation.arXivpreprintarXiv:2302.11266(2023). [69] EllenMVoorhees.2019.Theevolutionofcranfield.InformationRetrievalEvalua-
[45] BhaskarMitraandNickCraswell.2017.Neuralmodelsforinformationretrieval. tioninaChangingWorld:LessonsLearnedfrom20YearsofCLEF(2019),45–69.
arXivpreprintarXiv:1705.01509(2017). [70] EllenMVoorheesetal.2003.OverviewoftheTREC2003robustretrievaltrack..
[46] BhaskarMitra,NickCraswell,etal.2018.Anintroductiontoneuralinformation InTrec.69–77.
retrieval.FoundationsandTrends®inInformationRetrieval13,1(2018),1–126. [71] EllenMVoorhees,DonnaKHarman,etal.2005.TREC:Experimentandevaluation
[47] TriNguyen,MirRosenberg,XiaSong,JianfengGao,SaurabhTiwary,Rangan ininformationretrieval.Vol.63.MITpressCambridge.
Majumder,andLiDeng.2016.MSMARCO:Ahumangeneratedmachinereading [72] WilliamWebber.2013.Approximaterecallconfidenceintervals.ACMTransac-
comprehensiondataset.choice2640(2016),660. tionsonInformationSystems(TOIS)31,1(2013),1–33.
[48] KezbanDilekOnal,YeZhang,IsmailSengorAltingovde,MdMustafizurRahman, [73] WilliamEdwardWebber.2010.Measurementininformationretrievalevaluation.
PinarKaragoz,AlexBraylan,BrandonDang,Heng-LuChang,HennaKim,Quin- Ph.D.Dissertation.UniversityofMelbourne,DepartmentofComputerScience
tenMcNamara,etal.2018.Neuralinformationretrieval:attheendoftheearly andSoftwareEngineering.
years.InformationRetrievalJournal21(2018),111–182.
10ReliableConfidenceIntervalsforInformationRetrievalEvaluationUsingGenerativeA.I. KDD’24,August25–29,2024,Barcelona,Spain
[74] MahsaYarmohammadi,XutaiMa,SoramiHisamoto,MuhammadRahman,Yim- Listing1:PromptforTREC-DL.
ingWang,HainanXu,DanielPovey,PhilippKoehn,andKevinDuh.2019.Robust
documentrepresentationsforcross-lingualinformationretrievalinlow-resource Assess the relevance of the passage to the query on a four-point
settings.InProceedingsofMachineTranslationSummitXVII:ResearchTrack. scale:
12–20. [0] Irrelevant: The passage has nothing to do with the query.
[75] EmineYilmaz,EvangelosKanoulas,andJavedAAslam.2008. Asimpleand [1] Related: The passage seems related to the query but does not
efficientsamplingmethodforestimatingAPandNDCG.InProceedingsofthe answer it.
31stannualinternationalACMSIGIRconferenceonResearchanddevelopmentin [2] Highly relevant: The passage has some answer for the query, but
informationretrieval.603–610. the answer may be a bit unclear, or hidden amongst extraneous
[76] HongleiZhuang,ZhenQin,KaiHui,JunruWu,LeYan,XuanhuiWang,and information.
MichaelBerdersky.2023.Beyondyesandno:Improvingzero-shotllmrankers [3] Perfectly relevant: The passage is dedicated to the query and
viascoringfine-grainedrelevancelabels.arXivpreprintarXiv:2310.14122(2023). contains the exact answer.
Query: {query}
A Prompts Passage: {passage}
Relevance:
Theexactpromptsusedinourexperimentsarelistedhere.We
notethatthesepromptsaretailoredtowardseachdatasetanduse
Listing2:PromptforRobust04.
therelevancelabeldefinitionsthathumanlabelersusedforeach
dataset.The{query}and{passage}/{document}areplaceholders Assess the relevance of the document to the query on a three-point
scale:
thatareformattedwiththeactualqueryandpassage/document
[0] Not relevant: The document is not relevant to the query.
duringinference. [1] Relevant: Parts of the document may be relevant to the query.
Weobservedthatthemodelissensitivetotheparticularprompt [2] Highly Relevant: The document is highly relevant to the query.
anddatasetduringscoringmode.ForTREC-DLwescorethesuffixes Query: {query}
"0","1","2"and"3".ForRobust04wefoundthatscoringthesuffixes Document: {document}
Relevance:
withbracketsismoreeffective:"[0]","[1]"and"[2]".
11