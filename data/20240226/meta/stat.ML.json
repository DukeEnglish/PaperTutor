[
    {
        "title": "Rao-Blackwellising Bayesian Causal Inference",
        "authors": "Christian TothChristian KnollFranz PernkopfRobert Peharz",
        "links": "http://arxiv.org/abs/2402.14781v1",
        "entry_id": "http://arxiv.org/abs/2402.14781v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14781v1",
        "summary": "Bayesian causal inference, i.e., inferring a posterior over causal models for\nthe use in downstream causal reasoning tasks, poses a hard computational\ninference problem that is little explored in literature. In this work, we\ncombine techniques from order-based MCMC structure learning with recent\nadvances in gradient-based graph learning into an effective Bayesian causal\ninference framework. Specifically, we decompose the problem of inferring the\ncausal structure into (i) inferring a topological order over variables and (ii)\ninferring the parent sets for each variable. When limiting the number of\nparents per variable, we can exactly marginalise over the parent sets in\npolynomial time. We further use Gaussian processes to model the unknown causal\nmechanisms, which also allows their exact marginalisation. This introduces a\nRao-Blackwellization scheme, where all components are eliminated from the\nmodel, except for the causal order, for which we learn a distribution via\ngradient-based optimisation. The combination of Rao-Blackwellization with our\nsequential inference procedure for causal orders yields state-of-the-art on\nlinear and non-linear additive noise benchmarks with scale-free and Erdos-Renyi\ngraph structures.",
        "updated": "2024-02-22 18:39:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14781v1"
    },
    {
        "title": "Causal Imputation for Counterfactual SCMs: Bridging Graphs and Latent Factor Models",
        "authors": "Alvaro RibotChandler SquiresCaroline Uhler",
        "links": "http://arxiv.org/abs/2402.14777v1",
        "entry_id": "http://arxiv.org/abs/2402.14777v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14777v1",
        "summary": "We consider the task of causal imputation, where we aim to predict the\noutcomes of some set of actions across a wide range of possible contexts. As a\nrunning example, we consider predicting how different drugs affect cells from\ndifferent cell types. We study the index-only setting, where the actions and\ncontexts are categorical variables with a finite number of possible values.\nEven in this simple setting, a practical challenge arises, since often only a\nsmall subset of possible action-context pairs have been studied. Thus, models\nmust extrapolate to novel action-context pairs, which can be framed as a form\nof matrix completion with rows indexed by actions, columns indexed by contexts,\nand matrix entries corresponding to outcomes. We introduce a novel SCM-based\nmodel class, where the outcome is expressed as a counterfactual, actions are\nexpressed as interventions on an instrumental variable, and contexts are\ndefined based on the initial state of the system. We show that, under a\nlinearity assumption, this setup induces a latent factor model over the matrix\nof outcomes, with an additional fixed effect term. To perform causal prediction\nbased on this model class, we introduce simple extension to the Synthetic\nInterventions estimator (Agarwal et al., 2020). We evaluate several matrix\ncompletion approaches on the PRISM drug repurposing dataset, showing that our\nmethod outperforms all other considered matrix completion approaches.",
        "updated": "2024-02-22 18:37:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14777v1"
    },
    {
        "title": "Batch and match: black-box variational inference with a score-based divergence",
        "authors": "Diana CaiChirag ModiLoucas Pillaud-VivienCharles C. MargossianRobert M. GowerDavid M. BleiLawrence K. Saul",
        "links": "http://arxiv.org/abs/2402.14758v1",
        "entry_id": "http://arxiv.org/abs/2402.14758v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14758v1",
        "summary": "Most leading implementations of black-box variational inference (BBVI) are\nbased on optimizing a stochastic evidence lower bound (ELBO). But such\napproaches to BBVI often converge slowly due to the high variance of their\ngradient estimates. In this work, we propose batch and match (BaM), an\nalternative approach to BBVI based on a score-based divergence. Notably, this\nscore-based divergence can be optimized by a closed-form proximal update for\nGaussian variational families with full covariance matrices. We analyze the\nconvergence of BaM when the target distribution is Gaussian, and we prove that\nin the limit of infinite batch size the variational parameter updates converge\nexponentially quickly to the target mean and covariance. We also evaluate the\nperformance of BaM on Gaussian and non-Gaussian target distributions that arise\nfrom posterior inference in hierarchical and deep generative models. In these\nexperiments, we find that BaM typically converges in fewer (and sometimes\nsignificantly fewer) gradient evaluations than leading implementations of BBVI\nbased on ELBO maximization.",
        "updated": "2024-02-22 18:20:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14758v1"
    },
    {
        "title": "How Transformers Learn Causal Structure with Gradient Descent",
        "authors": "Eshaan NichaniAlex DamianJason D. Lee",
        "links": "http://arxiv.org/abs/2402.14735v1",
        "entry_id": "http://arxiv.org/abs/2402.14735v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14735v1",
        "summary": "The incredible success of transformers on sequence modeling tasks can be\nlargely attributed to the self-attention mechanism, which allows information to\nbe transferred between different parts of a sequence. Self-attention allows\ntransformers to encode causal structure which makes them particularly suitable\nfor sequence modeling. However, the process by which transformers learn such\ncausal structure via gradient-based training algorithms remains poorly\nunderstood. To better understand this process, we introduce an in-context\nlearning task that requires learning latent causal structure. We prove that\ngradient descent on a simplified two-layer transformer learns to solve this\ntask by encoding the latent causal graph in the first attention layer. The key\ninsight of our proof is that the gradient of the attention matrix encodes the\nmutual information between tokens. As a consequence of the data processing\ninequality, the largest entries of this gradient correspond to edges in the\nlatent causal graph. As a special case, when the sequences are generated from\nin-context Markov chains, we prove that transformers learn an induction head\n(Olsson et al., 2022). We confirm our theoretical findings by showing that\ntransformers trained on our in-context learning task are able to recover a wide\nvariety of causal structures.",
        "updated": "2024-02-22 17:47:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14735v1"
    },
    {
        "title": "Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning",
        "authors": "Andrei V. KonstantinovLev V. Utkin",
        "links": "http://arxiv.org/abs/2402.14726v1",
        "entry_id": "http://arxiv.org/abs/2402.14726v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14726v1",
        "summary": "A problem of incorporating the expert rules into machine learning models for\nextending the concept-based learning is formulated in the paper. It is proposed\nhow to combine logical rules and neural networks predicting the concept\nprobabilities. The first idea behind the combination is to form constraints for\na joint probability distribution over all combinations of concept values to\nsatisfy the expert rules. The second idea is to represent a feasible set of\nprobability distributions in the form of a convex polytope and to use its\nvertices or faces. We provide several approaches for solving the stated problem\nand for training neural networks which guarantee that the output probabilities\nof concepts would not violate the expert rules. The solution of the problem can\nbe viewed as a way for combining the inductive and deductive learning. Expert\nrules are used in a broader sense when any logical function that connects\nconcepts and class labels or just concepts with each other can be regarded as a\nrule. This feature significantly expands the class of the proposed results.\nNumerical examples illustrate the approaches. The code of proposed algorithms\nis publicly available.",
        "updated": "2024-02-22 17:33:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14726v1"
    }
]