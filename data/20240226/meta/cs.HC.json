[
    {
        "title": "The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success",
        "authors": "André Calero ValdezMoreen HeineThomas FrankeNicole JochemsHans-Christian JetterTim Schrills",
        "links": "http://arxiv.org/abs/2402.14728v1",
        "entry_id": "http://arxiv.org/abs/2402.14728v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14728v1",
        "summary": "The evolution of AI is set to profoundly reshape the future. The European\nUnion, recognizing this impending prominence, has enacted the AI Act,\nregulating market access for AI-based systems. A salient feature of the Act is\nto guard democratic and humanistic values by focusing regulation on\ntransparency, explainability, and the human ability to understand and control\nAI systems. Hereby, the EU AI Act does not merely specify technological\nrequirements for AI systems. The EU issues a democratic call for human-centered\nAI systems and, in turn, an interdisciplinary research agenda for\nhuman-centered innovation in AI development. Without robust methods to assess\nAI systems and their effect on individuals and society, the EU AI Act may lead\nto repeating the mistakes of the General Data Protection Regulation of the EU\nand to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more\nconfusion than lending guidance. Moreover, determined research activities in\nHuman-AI interaction will be pivotal for both regulatory compliance and the\nadvancement of AI in a manner that is both ethical and effective. Such an\napproach will ensure that AI development aligns with human values and needs,\nfostering a technology landscape that is innovative, responsible, and an\nintegral part of our society.",
        "updated": "2024-02-22 17:35:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14728v1"
    },
    {
        "title": "COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling",
        "authors": "Baihan LinDjallel BouneffoufYulia LandaRachel JespersenCheryl CorcoranGuillermo Cecchi",
        "links": "http://arxiv.org/abs/2402.14701v1",
        "entry_id": "http://arxiv.org/abs/2402.14701v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14701v1",
        "summary": "The therapeutic working alliance is a critical factor in predicting the\nsuccess of psychotherapy treatment. Traditionally, working alliance assessment\nrelies on questionnaires completed by both therapists and patients. In this\npaper, we present COMPASS, a novel framework to directly infer the therapeutic\nworking alliance from the natural language used in psychotherapy sessions. Our\napproach utilizes advanced large language models to analyze transcripts of\npsychotherapy sessions and compare them with distributed representations of\nstatements in the working alliance inventory. Analyzing a dataset of over 950\nsessions covering diverse psychiatric conditions, we demonstrate the\neffectiveness of our method in microscopically mapping patient-therapist\nalignment trajectories and providing interpretability for clinical psychiatry\nand in identifying emerging patterns related to the condition being treated. By\nemploying various neural topic modeling techniques in combination with\ngenerative language prompting, we analyze the topical characteristics of\ndifferent psychiatric conditions and incorporate temporal modeling to capture\nthe evolution of topics at a turn-level resolution. This combined framework\nenhances the understanding of therapeutic interactions, enabling timely\nfeedback for therapists regarding conversation quality and providing\ninterpretable insights to improve the effectiveness of psychotherapy.",
        "updated": "2024-02-22 16:56:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14701v1"
    },
    {
        "title": "Doing AI: Algorithmic decision support as a human activity",
        "authors": "Joachim Meyer",
        "links": "http://arxiv.org/abs/2402.14674v1",
        "entry_id": "http://arxiv.org/abs/2402.14674v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14674v1",
        "summary": "Algorithmic decision support (ADS), using Machine-Learning-based AI, is\nbecoming a major part of many processes. Organizations introduce ADS to improve\ndecision-making and make optimal use of data, thereby possibly avoiding\ndeviations from the normative \"homo economicus\" and the biases that\ncharacterize human decision-making. A closer look at the development process of\nADS systems reveals that ADS itself results from a series of largely\nunspecified human decisions. They begin with deliberations for which decisions\nto use ADS, continue with choices while developing the ADS, and end with using\nthe ADS output for decisions. Finally, conclusions are implemented in\norganizational settings, often without analyzing the implications of the\ndecision support. The paper explores some issues in developing and using ADS,\npointing to behavioral aspects that should be considered when implementing ADS\nin organizational settings. It points out directions for further research,\nwhich is essential for gaining an informed understanding of the processes and\ntheir vulnerabilities.",
        "updated": "2024-02-22 16:29:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14674v1"
    },
    {
        "title": "GazeTrak: Exploring Acoustic-based Eye Tracking on a Glass Frame",
        "authors": "Ke LiRuidong ZhangBoao ChenSiyuan ChenSicheng YinSaif MahmudQikang LiangFrançois GuimbretièreCheng Zhang",
        "links": "http://dx.doi.org/10.1145/3636534.3649376",
        "entry_id": "http://arxiv.org/abs/2402.14634v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14634v1",
        "summary": "In this paper, we present GazeTrak, the first acoustic-based eye tracking\nsystem on glasses. Our system only needs one speaker and four microphones\nattached to each side of the glasses. These acoustic sensors capture the\nformations of the eyeballs and the surrounding areas by emitting encoded\ninaudible sound towards eyeballs and receiving the reflected signals. These\nreflected signals are further processed to calculate the echo profiles, which\nare fed to a customized deep learning pipeline to continuously infer the gaze\nposition. In a user study with 20 participants, GazeTrak achieves an accuracy\nof 3.6{\\deg} within the same remounting session and 4.9{\\deg} across different\nsessions with a refreshing rate of 83.3 Hz and a power signature of 287.9 mW.\nFurthermore, we report the performance of our gaze tracking system fully\nimplemented on an MCU with a low-power CNN accelerator (MAX78002). In this\nconfiguration, the system runs at up to 83.3 Hz and has a total power signature\nof 95.4 mW with a 30 Hz FPS.",
        "updated": "2024-02-22 15:28:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14634v1"
    },
    {
        "title": "Non-Contact Acquisition of PPG Signal using Chest Movement-Modulated Radio Signals",
        "authors": "Israel Jesus Santos FilhoMuhammad Mahboob Ur RahmanTaous-Meriem Laleg-KiratiTareq Al-Naffouri",
        "links": "http://arxiv.org/abs/2402.14565v1",
        "entry_id": "http://arxiv.org/abs/2402.14565v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14565v1",
        "summary": "We present for the first time a novel method that utilizes the chest\nmovement-modulated radio signals for non-contact acquisition of the\nphotoplethysmography (PPG) signal. Under the proposed method, a\nsoftware-defined radio (SDR) exposes the chest of a subject sitting nearby to\nan orthogonal frequency division multiplexing signal with 64 sub-carriers at a\ncenter frequency 5.24 GHz, while another SDR in the close vicinity collects the\nmodulated radio signal reflected off the chest. This way, we construct a custom\ndataset by collecting 160 minutes of labeled data (both raw radio data as well\nas the reference PPG signal) from 16 healthy young subjects. With this, we\nfirst utilize principal component analysis for dimensionality reduction of the\nradio data. Next, we denoise the radio signal and reference PPG signal using\nwavelet technique, followed by segmentation and Z-score normalization. We then\nsynchronize the radio and PPG segments using cross-correlation method. Finally,\nwe proceed to the waveform translation (regression) task, whereby we first\nconvert the radio and PPG segments into frequency domain using discrete cosine\ntransform (DCT), and then learn the non-linear regression between them.\nEventually, we reconstruct the synthetic PPG signal by taking inverse DCT of\nthe output of regression block, with a mean absolute error of 8.1294. The\nsynthetic PPG waveform has a great clinical significance as it could be used\nfor non-contact performance assessment of cardiovascular and respiratory\nsystems of patients suffering from infectious diseases, e.g., covid19.",
        "updated": "2024-02-22 14:04:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14565v1"
    }
]