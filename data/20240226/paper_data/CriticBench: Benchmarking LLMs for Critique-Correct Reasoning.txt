CRITICBENCH: Benchmarking LLMs for Critique-Correct Reasoning
ZichengLin1*, ZhibinGou1*, TianLiang1, RuilinLuo1, HaoweiLiu2, YujiuYang1†
1TsinghuaUniversity2UniversityofHongKong
linzc23@mails.tsinghua.edu.cn, zebgou@gmail.com
https://criticbench.github.io
Abstract
generation & critique & correction critique & correction correction
generation & critique generation fail
generation & correction critique
TheabilityofLargeLanguageModels(LLMs)
100
tocritiqueandrefinetheirreasoningiscrucial 15.1%
22.9%
for their application in evaluation, feedback 28.0%
provision, and self-improvement. This paper 80 46.2% 50.2% 46.4% 42.0% 36.4% 8.3% 237 ... 363 %%%
introduces CRITICBENCH, a comprehensive 13.9% 6.0%
benchmarkdesignedtoassessLLMs’abilities 60 24 .. 38 %% 21.9% 9.1% 3.1%
tocritiqueandrectifytheirreasoningacrossa 12.1% 14.6% 2.9%
v fia vr eie rt ey ao sof nta insk gs. doC mR aIT inI sC :B mEN atC hH emen ac tio cm alp ,a cs os mes
-
40 2 340
..
16.6 %%% 1 527
..
49.8 %%% 3.1% 32 .. 51 %% 2423 .... 1876 %%%% 26 .. 71 %%
52.4%
69.5%
monsense,symbolic,coding,andalgorithmic. 20 7.9% 34.5% 33.4% 37.1%
It compiles 15 datasets and incorporates re- 28.0%
21.5%
16.8%
sponses from three LLM families. Utilizing
0
CRITICBENCH,weevaluateanddissecttheper- LLaMa-2-7 Vb icuna-7 Lb LaMa-2-1 V3 ib cuna-13 Vb icuna-3 L3 Lb aMa-2-70b GPT-3.5 GPT-4
formanceof17LLMsingeneration,critique,
Model
andcorrectionreasoning,i.e.,GQCreasoning,
andanalyzethekeyfactorsaffectingLLMcrit- Figure 1: The distribution of the correct sets and in-
icalreasoning. Ourfindingsreveal: (1)alinear tersectionformodelgeneration(G),critique(Q),and
relationshipinGQCcapabilities,withcritique- correction(C)onCRITICBENCH,with"&"represent-
focused training markedly enhancing perfor- ingintersection.
mance; (2) a task-dependent variation in cri-
tiqueandcorrectioneffectiveness,withlogic-
orientedtasksbeingmoreamenabletocorrec-
2023;Teametal.,2023). Theirpotentialforself-
tion;(3)GQCknowledgeinconsistenciesthat
evaluation and improvement is particularly fasci-
decrease as model size increases; and (4) an
intriguinginter-modelcritiquingpattern,where nating,withstudiessuggestingthatLLMscanef-
strongermodelsarebetteratcritiquingweaker fectively assess model outputs (Liu et al., 2023;
ones, while weaker models can surprisingly Fu et al., 2023a; Chiang et al., 2023), and even
surpassstrongeronesintheirself-critique. We engageinself-reflectionandcorrection(Baietal.,
hopetheseinsightsintothenuancedcritique-
2022;Saundersetal.,2022;Madaanetal.,2023;
correctreasoningofLLMswillfosterfurtherre-
Gou et al., 2024a). This capability rests on the
searchinLLMcritiqueandself-improvement1.
LLMs’criticalreasoningskills,whichinvolves(1)
critique-identifyingissuesinprovidedresponses,
1 Introduction and(2)correct-proposingsuitablemodifications.
However, a comprehensive understanding of
Theadventoflargelanguagemodels(LLMs)has
LLMs’criticalreasoningabilitiesremainselusive.
revolutionizedartificialintelligence,showcasingre-
Prior research (Lightman et al., 2023; Li et al.,
markableproficiencyacrossdiversetasks(Brown
2024; Luo et al., 2024) has focused on a narrow
et al., 2020; Ouyang et al., 2022; Achiam et al.,
rangeofmodelsanddatasetsandhasyieldedincon-
2023; Chowdhery et al., 2023; Touvron et al.,
sistentfindings(Madaanetal.,2023;Huangetal.,
*Equalcontribution.
2024),underscoringtheneedforathoroughinves-
†Correspondingauthor.
tigation. It is imperative to systematically gauge
1 Codeanddataareavailableathttps://github.com/
CriticBench/CriticBench. LLMs’proficiencyincritiquingandcorrectingpro-
4202
beF
22
]LC.sc[
1v90841.2042:viXra
egatnecrePLLaMa-2-7b Vicuna-7b Mistral-7b Phi-2
LLaMa-2-13b Vicuna-13b Mixtral-8x7b GPT-3.5
LLaMa-2-70b Vicuna-33b Mixtral-8x7b inst GPT-4
Math Math Math
100 100 95
80 80 80
nse 60
A
nse 60
A
nse 60
A
monse
24 00
lg
o rith
monse
24 00
lg
o rith
monse
40
lg
o rith
m m m m m 20 m
Co ic Co ic Co ic
cilob
myS
edoC cilob
myS
edoC cilob
myS
edoC
Generation Critique Correction
Figure2: Models’performanceonCRITICBENCH.
videdanswers. shipintheirgeneration,critique,andcorrec-
To address these challenges, we present CRIT- tion(GQC)capabilities,despitelimitedtrain-
ICBENCH,acomprehensivebenchmarkdesigned ingoncritiquetasks.
to evaluate the critique and correction skills of
• The type of task has a significant impact
LLMs. CRITICBENCH encompasses 15 datasets
on correction performance. LLMs struggle
spanningfivetaskcategories: mathematical,com-
morewithincorrectanswersindetail-oriented
monsense,symbolic,coding,andalgorithmic. We
taskslikealgorithmictaskscomparedtologic-
leverage eight models from the LLaMA, Vicuna,
centrictaskslikecodegeneration.
and GPT series to create the responses that are
to be critiqued and corrected. Moreover, we in-
• By comparing the sets of questions where
clude GPT-4 and undertake manual data reviews
models correctly generate, critique, and cor-
to ensure data quality, culminating in 3.8K data
rect, we find that a model’s knowledge is
instances(seeTable2fordetaileddatacollection
inconsistent across these three tasks, with
information). We conduct extensive experiments
stronger models showing more consistency
onCRITICBENCHwith17LLMs,includingclosed-
inGQCcapabilities.
source models GPT-3.5 and GPT-4, open-source
models like Phi-2 (Javaheripi et al., 2023), the • Weobservethatalthoughstrongermodelsare
LLaMAfamily(Touvronetal.,2023),theVicuna betteratcritiquing,modelswithweakergen-
family(Chiangetal.,2023),andtheMistralfamily erative abilities can still accurately evaluate
(Jiang et al., 2023, 2024), as well as two models responses from stronger models, sometimes
specificallytrainedforcritiquing,namelyAuto-J evenoutperformingthelatterinself-critique.
(Li et al., 2024) and UltraCM (Cui et al., 2023).
2 RelatedWork
PartialresultsareshowninFigure2.
Ourcontributionsaresummarizedasfollows:
LLMReasoning Theadventoffew-shotlearn-
ingandChainofThought(CoT)prompting(Brown
• WepresentCRITICBENCH,abenchmarkcom-
et al., 2020; Wei et al., 2022) has significantly
prising five different domains to systemati-
improvedtheperformanceofLLMsinreasoning
callyassesscritiqueandcorrectionreasoning
tasks. Since then, various advanced prompting
in various LLMs. Utilizing CRITICBENCH,
methods(Wangetal.,2022;Zhouetal.,2022;Fu
we investigate the impact of base models,
et al., 2022; Zheng et al., 2023a) have achieved
trainingstrategies,promptstrategies,andora-
remarkableresults,andresearchershaveproposed
clefeedbackonthecritique-correctreasoning
touseexternaltoolslikesearchengines(Nakano
performanceofLLMs.
et al., 2021; Gou et al., 2024a) and Python inter-
• WerevealthatLLMsexhibitalinearrelation- preters (Chen et al., 2022; Gao et al., 2023; GouOriginal Dataset:
AmbigQA, StrategyQA, HotpotQA, CSQA, Prompt Valid Responses
TabMWP, AQuA. MATH, GSM8K, HumanEval,
Question
MBPP, Object Counting, Repeat Copy, Penguins,
Colored Obiects, Date. Answer
1. Rule-based answer matching
Question
2. GPT-4 Evaluation
Model: 3. Manual Review
ChatGPT GPT-4
Vicuna LLaMa2 Question:Ryanplants2flowersadayin
Quheisstiogna:rdReyna.nApfltaenrts125fldoawyesr,sahodwayminany
hisflogwaredresnd.oeAsfhteerha1v5eifd5aydsi,dnhootwgromwa?ny
flowTyeprsed:oMesathheemhaavtiecaifl5Rdeaidsonnoitnggrow?
TypAen:sMwearth:e2m5aticalReasoning
Filtering by Rules AnSswouerrc:e2D5ataset:GSM8K
SouSrocleutDioant:asReyt:anGpSlMan8tsK2flowersadayfor15
Solduatyios,ns:oRhyeanplpalnatnetds22f*lo1w5e=rs3a0dfaloywfoerrs1.5If5
daydsi,dsonohtepglraonwte,dth2e*n1h5e=h3a0sfl3o0we-rs5.If=525
didflonwotergs.roTwh,eathnesnwehreish2a5s.30 - 5 = 25
flowSoelrus.tiTohneLaanbswele:rTirsu2e5.
Valid Responses SolMutoiodnelL:aGbPeTl:-4True
Model:GPT-4
Source dataset distribution
(a) Question Collection (b) Response Collection (c) Response Annotation
Figure3: AnoverviewfortheCRITICBENCHconstruction.
etal.,2024b)tofurtheraugmentLLMreasoningin 2024), and mathematics (Lightman et al., 2023;
varioustasks(Schicketal.,2024;Maetal.,2024). Luo et al., 2024). However, these datasets are
typically limited to specific tasks and models. In
LLMCritiquing&Correction AsLLMscon-
contrast, our work introduces CRITICBENCH to
tinuetoevolveintheircapabilitiesacrossvarious
provide the first comprehensive and comparative
domains, many studies seek to enhance perfor-
analysisofLLMsabilitiesingeneration,critique,
mancebyrequiringLLMstoprovidecritiquesof
andcorrection(GQC).
the generated responses in various forms, includ-
ing utilizing internal feedback (Bai et al., 2022;
Saundersetal.,2022;Wellecketal.,2022;Madaan
etal.,2023;Zhengetal.,2023b),leveragingexter-
3 The CRITICBENCH
nalfeedback(Kimetal.,2023;Shinnetal.,2023;
Gouetal.,2024a;Chenetal.,2024),andemploy-
3.1 Overviewof CRITICBENCH
ing multiple models for critiquing and debating
answers (Liang et al., 2023; Du et al., 2023; Yin
CRITICBENCH is designed to assess the two key
et al., 2023). These studies all demonstrate the
aspectsofLLMs’criticalreasoning: critiqueand
potentialofLLMsinCritique-CorrectingReason-
correction. Bycombiningthesetwoaspects,LLMs
ing. Additionally, some researchers have trained
cancritiqueagivenresponseandapplycorrective
critiquemodelstoprovidesupervisorysignalsfor
reasoning to produce an updated answer. In this
generativemodels(Keetal.,2023;Lietal.,2024;
section,wedetailtheprinciplesandprocessesin-
Yeetal.,2023;Wangetal.,2023b;Cuietal.,2023).
volvedintheconstructionof CRITICBENCH;the
However, these works focus on specific methods
constructionprocessislistedinFigure3.
withoutprovidingacomprehensiveevaluationand
CRITICBENCHisdesignedtofollowthesecollec-
analysisofCritique-CorrectingReasoning,which
tion principles: (1) it encompasses multiple task
alsolimitsthedevelopmentofthisfield.
types, aimed at comprehensively showcasing the
Critiquing Tasks Many researchers have ad- model’sabilities;(2)itincorporatesdiversemodels
vanced the field by creating critiquing datasets, forresponsegeneration,promotingresponsevari-
covering areas such as text generation (Stiennon ety;(3)itemploysacknowledgeddatasets,enabling
et al., 2020; Matiana et al., 2021), semantic un- straightforwardcomparisonswiththemodels’gen-
derstanding (Pougué-Biyong et al., 2021), factu- erationcapabilities;and(4)itensuresdataquality
ality (Thorne et al., 2018), alignment (Li et al., throughbothGPT-4andmanualreview.Forthesethreedatasets,weusedcompletesets.
Code Generation For code generation, we se-
lectedMBPP(Austinetal.,2021)andHumanEval
(Chen et al., 2021) to construct our dataset. For
MBPP,werandomlysampled300questions,while
forHumanEval,weuseditscompleteset.
AlgorithmicTasks WeutilizedObjectCounting
and Repeat Copy, sourced from BIG-Bench (Sri-
vastavaetal.,2023)toevaluatethemodel’sability
tomanagedetails. ObjectCountinginvolvesenu-
meratingitemspresentedwithinquestions,while
Repeat Copy requires the generation of word se-
quencesbasedoninstructions. Thecompletesets
of these tasks are employed to form the detail-
Figure4: EvaluationprocessonCRITICBENCH. oriented algorithmic task of CRITICBENCH. By
utilizing the aforementioned datasets, we ensure
thatthequestionsinCRITICBENCHcoveradiverse
3.2 QuestionCollection
rangeofexaminationangles. Thefivetypesoftasks
Thissectiondescribesthedatacollectionmethod-
correspondtoavarietyofknowledgedomains,with
ology, following defined principles. A specific
thedetail-focusedalgorithmictasks,thedetailand
quantity of data is extracted from an existing
logic-encompassingmathematicalreasoning,and
dataset,utilizinganyrelevantsubsetifavailable,or
the logic-focused code generation corresponding
alternatively,selectingrandomlyfromthedataset.
todifferentstylesofreasoningprocesses. Specific
datastatisticscanbeseeninAppendixA
MathematicalReasoning WeselectedGSM8K
3.3 ResponseCollection
(Cobbe et al., 2021), MATH (Hendrycks et al.,
2021), AQuA (Ling et al., 2017), and TabMWP Followingthecollectionofbenchmarkquestions,
(Lu et al., 2023) for mathematical reasoning. weemployvariousLLMs,includingGPT-3.5,GPT-
We utilized the existing subsets from Shi et al. 4,LLaMa2(7B,13B,and70Bvariants),andvicuna
(2022) and Lightman et al. (2023) respectively, (7B,13B,and33Bvariants)togenerateresponse
randomlysampled300questionsfromTabMWP, for each question, using greedy decoding. The
andincorporatedallquestionsfromAQuA. detailsofthepromptsusedareavailableinTableE.
Next, we filter out the responses that did not
providevalidreasoning. Wethenapplyarandom
Commonsense Reasoning To thoroughly eval-
samplingstrategytomaintainaconsistentnumber
uate the GQC ability of LLMs in commonsense
ofmodel-generatedresponsesacrosseachdataset.
reasoningtasks,weemployfourdatasets: CSQA
(Talmoretal.,2019),AmbigNQ(Minetal.,2020), 3.4 ResponseAnnotation
StrategyQA (Geva et al., 2021), and HotpotQA
Response correctness is initially determined by
(Yangetal.,2018). Werandomlysample300ques-
rule-basedmatching,followedbyamoredetailed
tionsfromCSQA,HotpotQA,andAmbigNQ,and
evaluation using GPT-4 to assess response preci-
includeallquestionsinStrategyQA.
sion. Thisincludesflaggingmathematicallycorrect
Symbolic Reasoning To enrich the variety of answerswithincorrectreasoningandrecognizing
symbolic reasoning question types, we utilized near-correctcommonsenseresponses. Discrepan-
three datasets from BIG Bench (Srivastava et al., ciesbetweenGPT-4evaluationsandinitialannota-
2023), namely Penguins, which requires under- tionsareresolvedthroughmanualreview. During
standing of tabular data; Colored Object, which this review, we identified questions in the Date
involvesanalyzingtherelativepositions,absolute datasetthatlackcorrectoptions,withdetailedex-
positions,andcolorsofvariousobjects;andDate, amplesprovidedinFigure6. Examplesofannota-
whichinvolvesunderstandingandcalculatingdates. tionsareprovidedinAppendixB.Critiquing Correction
Model Type Generation
ZS-AO ZS-CoT FS ZS-CoT FS FS(oracle)
Baseline - - 50.80 48.37
Phi-2 SIFT 43.74 40.45(-10.35) 29.31(-21.49) 27.92(-22.88) 17.41(-30.96) 37.67(-10.70) 50.04(+1.67)
LLaMa-2-7b BASE 34.48 - - 41.72(-9.08) - 41.91(-6.46) 50.98(+2.61)
LLaMa-2-7bchat RLHF 34.22 60.47(+9.67) 47.36(-3.44) 42.50(-8.30) 10.33(-38.04) 38.22(-10.15) 51.79(+3.42)
Vicuna-7b SIFT 32.31 6.82(-43.98) 13.85(-36.95) 40.87(-9.93) 15.32(-33.05) 41.23(-7.14) 51.48(+3.11)
Mistral-7b BASE 47.37 - - 56.09(+5.29) - 42.46(-5.91) 53.18(+4.81)
LLaMa-2-13b BASE 42.68 - - 33.11(-17.69) - 45.25(-3.12) 50.85(+2.48)
LLaMa-2-13bchat RLHF 41.67 58.84(+8.04) 43.54(-7.26) 51.10(+0.30) 12.13(-36.24) 41.33(-7.04) 52.18(+3.81)
Vicuna-13b SIFT 40.12 41.94(-8.86) 12.97(-37.83) 47.17(-3.63) 10.77(-37.60) 42.22(-6.15) 51.71(+3.34)
Vicuna-33b SIFT 45.18 24.04(-26.67) 45.94(-4.86) 53.41(+2.61) 37.62(-10.75) 42.43(-5.94) 52.24(+3.87)
LLaMa-2-70b BASE 57.61 - - 53.39(+2.59) - 45.75(-2.62) 55.14(+6.77)
LLaMa-2-70bchat RLHF 51.53 68.00(+17.20) 54.82(+4.02) 64.27(+13.47) 31.92(-16.45) 43.95(-4.42) 55.53(+7.16)
Mixtral-8×7b BASE 58.43 - - 64.21(+13.41) - 49.31(+0.94) 56.13(+7.76)
Mixtral-8×7binst SIFT 60.03 33.56(-17.24) 46.54(-4.26) 54.06(+3.26) 41.12(-7.25) 50.82(+2.45) 56.39(+8.02)
GPT-3.5 RLHF 64.21 69.96(+19.16) 51.51(+0.71) 60.17(+9.37) 46.89(-1.48) 51.24(+2.87) 61.03(+12.66)
GPT-4 RLHF 76.15 81.65(+30.85) 78.89(+28.09) 86.19(+35.39) 56.42(+8.05) 69.83(+21.46) 74.98(+26.61)
Average - 48.65 48.57(-2.23) 42.47(-8.33) 51.75(+0.95) 27.99(-20.38) 45.57(-2.8) 54.91(+6.54)
Auto-J-13b CT - - 65.29(+14.49) - - - -
UltraCM-13b CT - - 61.11(+10.31) - - - -
Table1: AverageperformanceonCRITICBENCH. Inthetable,thevaluesinparenthesesunderthe"Critiquing"
columnshowcomparisonstotheBaselinecritiquescoreofrandomguessing(50.80). Similarly,inthe"Correction"
column,theparenthesesdisplaychangesrelativetotheBaselinegenerationscorefromtheoriginalresponse(48.37).
Bluehighlightsindicateimprovement,whileorangemarksdecline.Type:BASEreferstothepretrainedmodel,SIFT
meansitsenhancementviaSupervisedInstructionFinetuning,RLHFdenotesfurthertrainingwithReinforcement
LearningfromHumanFeedback,andCTrepresentsCritiqueTraining.
(cid:40)
3.5 Evalution 1, ifcorrectlyclassifiedaswrong,
q = (4)
i
Evaluation Process The evaluation process on 0, otherwise.
CRITICBENCH is illustrated in Figure 4. First, a
S ×S
p r
critiquepromptisconstructedusingtheresponse S f = 2× , (5)
S +S
p r
withinCRITICBENCH,promptingthemodeltoper-
where S is the precision score, S is the recall
form a critique. Subsequently, a correct prompt p r
score,misthenumberofclassifiedaswrong,nis
is built incorporating the critique to obtain the
the number of actual wrong, and q indicates the
model’scorrectionresults. i
correctdiscriminationofaresponseaswrong.
GenerationandCorrectionMetricsWeusethe
accuracy metric S to assess models’ generation
a 4 Experiments
andcorrectioncapabilityasfollows:
4.1 ExperimentalSetup
c
S = (1)
a N Toconductacomprehensiveassessment,wehave
selectedthefollowingmodels: Phi-2,theLLaMa
wherecisthenumberofcorrectpredictions,N is
family,theVicunafamily,theMistralfamily,and
thetotalnumberofquestions.
the GPT family. We evaluate those models on
CritiqueMetricsWeassessthecritiqueabilityof
CRITICBENCH under three phases: (1) Genera-
LLMsbypromptingthemtoevaluatethecorrect-
tion: Modelsaretaskedwithansweringquestions
nessofgivenresponses. Toaddresspotentialissues
through the utilization of CoT (Wei et al., 2022).
likeclassimbalance, biases(Wangetal.,2023a),
(2) Critique: This phase evaluates provided re-
and the unreliability (Gou et al., 2024a) of LLM-
sponse correctness. After testing three prompts
basedevaluations,weutilizetheF1scoreasamore
fromHuangetal.(2024),weselectedthemostef-
robustandreproduciblemetricforcritiquingerrors:
fectiveforzero-shotuse. Bymodifyingtheoriginal
(cid:80)m q prompt,weexperimentedwithtwoprompts: azero-
S = i=1 i , (2)
p m shot answer only (ZS-AO) and a zero-shot chain
(cid:80)n
q
ofthought(ZS-COT)requestinganalysis. Forpre-
S r = i=1 i , (3) trainedmodelswithweakerinstructionadherence
nAverage Model Scores by Task Type heavilytowardsgeneration,lackingproficiencyin
70 Generation critiqueandcorrectiontasks. Thisunderscoresthe
Critique
60 Correction necessity of evaluating generation, critique, and
correctioncollectivelytoachieveacomprehensive 50
assessment of a model’s mastery of knowledge.
40
Additionally,Mistral-7bstandsoutasthetopper-
30
formeramongmodelsofsimilarsize,evenoutper-
20
formingVicuna-33b. However,inFigure2,GPT-4
10
consistently maintains a significant lead in GQC
0
Mathematica Cl ommonsense Symbolic Coding Algorithmic of all types of tasks. Despite this, other models
Task Type like LLaMA-70b and Mixtral-8×7b demonstrate
competitivenessagainstGPT-3.5.
Figure5: AverageScoreondifferenttypesoftasks.
Furthermore, it is observed that models with
more than 13 billion parameters exhibit certain
(labeledBASE),wefocusedonfew-shot(FS)set- critiquecapabilities(surpassingthebaselineofran-
ting. Additionally, to assess critique training ef- dom guessing). Meanwhile, only models of the
fects,weevaluatedthe13BmodelAuto-J(Lietal., Mixtral-8×7bandabovearecapableofachieving
2024)andUltraCM(Cuietal.,2023)byextracting effectivecorrection(exceedingthebaselinegenera-
their discrimination on the response using a rule- tionscore).
basedmethod. (3)Correction: Afterthecritique,
Training Strategy By comparing the results
thisphaserefinesresponsesbyaddressingidenti-
of different models under LLaMa family, it is
fied inaccuracies. Besides ZS-COT and FS, we
observed that the alignment tax has limited the
evaluatedFS(oracle),applyingcorrectionssolely
RLHF’s generation performance. However, for
toinaccuratelygeneratedresponses.
critiqueandcorrection,RLHFconsistentlyoutper-
ThepromptsforabovephasesaredetailedinE.
formsBASE,suggestingthatRLHFmightsuppress
Forallexperimentalsetups,wesetthetemperature
theexpressionofknowledgeingeneration. Simul-
to0duringthethreephases.
taneously,incritique,CTdemonstratesresultssur-
4.2 ResultsandAnalysis passingthoseofGPT-3.5withasmallerparameter
size(13B),provingtheeffectivenessofCT.
Table 1 showcases the performance of LLMs on
CRITICBENCH. Specifically,weareinterestedin PromptStrategy Thecritiqueresultsfromzero-
exploringthefollowingresearchquestions: RQ1: shot settings show sensitivity to prompts. For in-
Whatfactorsinfluencethemodel’sgeneration,cri- stance, Vicuna-13b’s ZS-AO flagged 22.04% of
tique, and correction? RQ2: What’s the interre- responsesasincorrect,comparedtoonly4.8%in
lationship between a model’s capabilities in gen- ZS-CoT, against an actual error rate of 51.63%.
eration, critique, and correction? RQ3: How do Thisinconsistencylikelystemsfromthemodel’s
critique-correctreasoningcapabilitiesdifferacross insufficient training on critique tasks, making it
various task types? RQ4: Is the model’s knowl- struggle without clear examples. Meanwhile, in
edgeconsistentingeneration,critique,andcorrec- correction,few-shotalsosignificantlyoutperforms
tion? RQ5: Howdoestheinter-modelcritiquing zero-shot. Therefore,FSisalwaysthebetterchoice
patternsmanifestamongmodelsofvaryingcapa- in both critique and correction. For subsequent
bility? In the following sections, we will discuss analysis,wewillprimarilyfocusonFSresults.
theseresearchquestionsinturn.
OrcaleFeedback Wealsoexploredanoracleset-
4.2.1 RQ1: KeyFactorsinLLMCritical
ting for corrections by modifying only incorrect
Reasoning
responsesinCRITICBENCH. ResultsfromFS(ora-
Base Model & Scale Observations reveal that cle)outperformedthosewithoutanoracle,showing
Phi-2(2.7B),despiteexcellingingenerationtasks, thatreliableexternalfeedbackcansignificantlyen-
exhibits weaker performance in critique and cor- hance correction efficiency. However, for more
rectiontaskscomparedtomodelswithsimilargen- advancedmodels(fromLLaMa-2-70btoGPT-4),
erationperformance(e.g.,LLaMa-2-13b,Vicuna- correctionsintheoraclesettingstillfellshortofdi-
33b). This suggests Phi-2’s training focus leans rectgeneration,indicatingtheyarestillinfluenced
erocS
egarevA(a) Critique vs. Generation (b) Correction vs. Generation (c) Correction vs. Critique
Q/G 70 C/G 70 C/Q
Ideal growth line(y=x) Original accuracy Original accuracy
80 65 Ideal growth line(y=x) Ideal growth line(y=x)
60
70 60
55
60 50
50
50
45 40
40
40
30 35 30
30 40 50 60 70 80 40 50 60 70 30 40 50 60 70 80
Generation Score Generation Score Critique Score
Figure6: Interrelationshipbetweenamodel’scapabilitiesingeneration,critique,andcorrection. Eachpointon
thegraphrepresentsamodel,withcoordinatesindicatingitsperformanceinGeneration(G),Critique(Q),and
Correction(C).Thegraphfeaturesfittedlinesforthescatterplots,denotedbybluelinesforQ/G,C/G,andC/Q,
whileareddashedlinerepresentstheidealgrowthline(y=x). Thegreendashedlinemarkstheoriginalaccuracyof
responsesfromCRITICBENCH.
byincorrectresponsesfromothermodels. surpassgenerationcapabilities. Theabilitytocor-
recterrorsinalgorithmictasksisalsolimited,even
4.2.2 RQ2: CorrelationsofGQCAbilities
whenthemodelanswerscorrectly. Formathemat-
The capabilities of generation, critique, and cor-
ical tasks requiring detailed and logical reason-
rection exhibit a positive correlation. Figures 6
ing,significantlyhigheraccuracyingenerationis
illustratestheinterconnectednessamongthreeca-
neededforeffectivecorrections,explainingthelack
pabilities. It is observed that there is a positive
ofimprovementofmathintheself-refine(Madaan
linearrelationshipbetweengeneratingandjudging.
et al., 2023). Interestingly, For the logic-focused
Theimprovementratesofgenerationandcritique
CodeGenerationtasks,improvementsarerealized
arenearlyidentical,eventhoughthemodelprimar-
aslongasthemodel’sgenerationperformancesur-
ilyfocusesonlearningtasksrelatedtogeneration
passesthatoftheoriginalresponses’performance.
during training. However, the linear correlation
Thisresultindicatesthatmodels,whenperforming
betweenthegenerationandcorrectioncapacitiesis
critiqueandcorrection,areeasilydisruptedbyin-
notprominent. Weakermodelstendtoexhibitdi-
correctanswersintasksthatfocusondetails,but
minishedcorrectnessuponcorrection,ascompared
notinthosethatemphasizelogic.
totheinitialbenchmarkresponses. Thisobserva-
Additionally,Figure5displaysthemodel’saver-
tionindicatesthatamodel’slimitedcapabilityto
ageGQCscoreondifferenttypesoftasks. Itcan
generatepreciseanswersimpactsitsabilitytocor-
beobservedthat,similartoalgorithmictasks,the
rect those responses. Similarly, the relationship
model struggles to effectively critique in detail-
betweencritiqueandcorrectionrevealsthat,even
oriented symbolic reasoning, where its perfor-
ifthemodelcandiscriminatebetweencorrectand
mance is significantly lower than that in genera-
incorrectresponses,itisnotabletorectifythem.
tionandcorrection. Thisfurtherdemonstratesthe
4.2.3 RQ3: ImpactofTaskType model’slackofcritiqueabilityonsuchtasks. For
moredetailedresults,pleaserefertoAppendixD.
Themodel’scritiqueandcorrectioncapabilityde-
pends on whether the task focuses on details or
4.2.4 RQ4: ConsistencyofGQCKnowledge
logic. In Figure 7, we illustrate the variability in
critiqueandcorrectioncapabilitiesacrossvarious GQCknowledgeinconsistenciespersistacrossall
task types. Figure 7 (a), (b), and (c) demonstrate models. The relationship between human abili-
thevaryingrelationshipsbetweenQandGacross tiesofgeneration,critique,andcorrectionsuggests
differenttypesoftasks. Specifically,themodelsex- that generation falls under critique, with correc-
hibitweakercritiqueperformanceindetail-oriented tioncloselylinkedtogeneration(Westetal.,2024).
algorithmictaskscomparedtotheirgenerationabil- This implies humans can identify errors without
ities,indicatedbydotsbelowtheidealgrowthline necessarily knowing the correct answer, whereas
y=x. Incontrast, formathematicalreasoningand generatingtherightansweralsoimpliestheability
code generation tasks, their critique capabilities tocritiqueandcorrectit. However,theknowledge
erocS
euqitirC
erocS
noitcerroC
erocS
noitcerroC(a) Algorithmic Task (b) Mathematical Reasoning (c) Code Generation
60 90
80 80
50
70
40 60
60
30 50
40
20 40
30
10 20
Q/G 20 Q/G Q/G
Ideal growth line(y=x) Ideal growth line(y=x) Ideal growth line(y=x)
0
50 60 70 80 90 20 30 40 50 60 70 80 90 20 30 40 50 60 70 80 90
Generation Score Generation Score Generation Score
(d) Algorithmic Task (e) Mathematical Reasoning (f) Code Generation
80
60
70
70
50 60
60
40 50
50
40
30
40 30
C/G 20 C/G C/G
Original accuracy Original accuracy Original accuracy
30 Ideal growth line(y=x) Ideal growth line(y=x) 20 Ideal growth line(y=x)
50 60 70 80 90 20 30 40 50 60 70 20 30 40 50 60 70
Generation Score Generation Score Generation Score
Figure7: Critique/Generation(Q/G)andCorrection/Generation(C/G)lineinAlgorithmicTask, Mathematical
Reasoning,andCodeGeneration.
Critique between models asignificantportion,indicatingthatthemodelpos-
Vicuna-7b 0.00 -1.15 +1.85 +11.58 -7.51 -7.67 +6.21 -15.82 sessesaconsiderableamountofknowledgethatis
LLaMa-2-7b +5.33 0.00 +4.06 +8.27 -11.34 -3.55 +9.87 -17.44 notexpressedthroughgenerationorcorrection.
Vicuna-13b +9.85 +9.76 0.00 +18.11 -0.78 +3.59 +3.91 -13.43
4.2.5 RQ5: PatternsofInter-ModelCritique
LLaMa-2-13b -12.11 -10.01 -3.51 0.00 -19.42 -8.08 +1.81 -16.51
Figure 8 presents a visualization illustrating the
Vicuna-33b +20.02 +15.67 +17.20 +22.91 0.00 +5.95 +5.85 -10.80
inter-model critiquing result. Overall, it can be
LLaMa-2-70b +17.72 +21.91 +14.88 +25.33 -0.81 0.00 +11.38 -19.85
observedthatstrongmodelsconsistentlyhaveasu-
GPT-3.5 +26.74 +28.42 +18.11 +31.79 +11.76 +8.29 0.00 -11.80
perior ability to critique than weak models, and
GPT-4 +53.29 +46.16 +50.82 +56.12 +37.06 +36.03 +34.60 0.00 the responses of weak models are more easily
Auto-J +38.27 +33.02 +31.36 +38.73 +19.45 +15.48 +6.87 -10.86 critiqued accurately, possibly because the errors
UltraCM +29.18 +20.61 +26.73 +29.15 +14.02 +9.09 +11.01 -0.78 made by weak models are more evident. Inter-
Vicuna-7b LLaMa-2-7 Vb icuna-13 Lb LaMa-2-13 Vb icuna-33 Lb LaMa-2-70b GPT-3.5 GPT-4 estingly,certainweakermodelsapproachoreven
Criticized model(weak strong)
exceed the self-critique scores of stronger mod-
Figure 8: The results of model critiques are depicted els,suggestingthattheircritiquecapacityagainst
in the graph, where the self-critique scores of LLMs stronger models might surpass the latter’s self-
aresetto0forcomparison. Modelsarearrangedfrom
critique. Post-critique training, models such as
weakesttostrongestinorderofgenerationaccuracy.
Auto-JandUltraCMshowenhancedabilitytoas-
sess response correctness across different mod-
acquiredbyLLMsisnotentirelyconsistentacross els,withUltraCM’sperformancenearingitsself-
generation,critique,andcorrectiontasks. critique level against GPT-4, underscoring the
valueofcritiquetraining.
Figure1delineatestheoverlapanddistinctive-
ness of GQC, highlighting their inconsistencies
5 Conclusion
of knowledge. As a model’s parameter size in-
creases,itsknowledgecoherenceacrossGQC,and In conclusion, our investigation through CRIT-
instancesofcompletetaskfailure(whereG,Q,and ICBENCHhasilluminatedthecapacitiesandlimita-
C all fail) decrease. Notably, it can be noted that tionsofLLMsinGQCreasoning. Ourfocusedex-
questionscorrectlycritiquedalonealwaysoccupy plorationusing CRITICBENCHontherelationship
)kaew
gnorts(ledom
gniuqitirC
erocS
euqitirC
erocS
noitcerroC
erocS
euqitirC
erocS
noitcerroC
erocS
euqitirC
erocS
noitcerroCamongmodelsinGQCrevealedalinearcorrelation responsesgeneratedbydifferentmodels.
andsubtleinconsistenciesbetweenGQC,whileour Additionally,whenusingthecritiqueabilityof
analysisacrossdifferenttasktypesfoundthatmod- LargeLanguageModels(LLMs),it’salsoimpor-
els perform better in Q and C for tasks focused tanttobeawareoftherisksinvolved,suchaspoten-
onlogiccomparedtothoserequiringattentionto tialbiases. WhentheGQCcapabilityofanLLM
detail. Additionally,byexaminingtheoutcomesof isinconsistent,anditscritiqueabilitysurpassesthe
models critiquing each other, we discovered that othertwoaspects, itisnecessarytocarefullydis-
weakermodelscouldsometimescorrecttheoutputs cernwhetheritsdiscriminateresultscontainharm-
ofstrongermodelsmoreeffectivelythanthosemod- fulbiases.
els could self-correct. These findings underscore
the effectiveness of CRITICBENCH in evaluating
References
andanalyzingtheGQCcapabilitiesofLLMs.
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama
Limitations
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
DiogoAlmeida,JankoAltenschmidt,SamAltman,
Measuringtheabilityofmodelcritiqueeffectively ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
hasalwaysbeenachallenge. Inthispaper,weuse arXivpreprintarXiv:2303.08774.
discriminationresultsasavalidindicatortomea-
JacobAustin,AugustusOdena,MaxwellNye,Maarten
sure its critique ability, mainly for the following
Bosma, Henryk Michalewski, David Dohan, Ellen
reasons: (1) Fine-grained indicators that provide
Jiang,CarrieCai,MichaelTerry,QuocLe,etal.2021.
scoresbasedonevaluationprinciplesareonlysuit- Programsynthesiswithlargelanguagemodels. arXiv
able for specific tasks and lack generality. More- preprintarXiv:2108.07732.
over, different tasks have different focuses, and
Yuntao Bai, Saurav Kadavath, Sandipan Kundu,
evaluation principles valued by humans may dy-
Amanda Askell, Jackson Kernion, Andy Jones,
namicallychange. Itissomewhatidealistictoex- Anna Chen, Anna Goldie, Azalia Mirhoseini,
haustivelylistallevaluationprinciplesonceandfor Cameron McKinnon, et al. 2022. Constitutional
ai: Harmlessnessfromaifeedback. arXivpreprint
all. (2)Scoresbasedonevaluationprinciplesrely
arXiv:2212.08073.
on human annotations or results from GPT-4 for
validation. However, reliable human annotations Tom Brown, Benjamin Mann, Nick Ryder, Melanie
incurhighcosts,andGPT-4maycontainerrorsand Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Neelakantan,PranavShyam,GirishSastry,Amanda
biases. UsingGPT-4resultsalsomakesitimpos-
Askell,etal.2020. Languagemodelsarefew-shot
sible to evaluate its critique ability. Additionally,
learners. Advancesinneuralinformationprocessing
in reasoning tasks, the most important aspect of systems,33:1877–1901.
critique and correction is to judge whether there
areerrorsinthereasoningprocessanditsresults. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming
Yuan,HenriquePondedeOliveiraPinto,JaredKa-
Therefore, considering the above considerations,
plan, HarriEdwards, YuriBurda, NicholasJoseph,
weuseabinarymetrictomeasuretheresults. Greg Brockman, Alex Ray, Raul Puri, Gretchen
Futureworkshouldaddressthesechallengesby Krueger,MichaelPetrov,HeidyKhlaaf,GirishSas-
exploringalternativeevaluationmethodologiesthat try, Pamela Mishkin, Brooke Chan, Scott Gray,
NickRyder,MikhailPavlov,AletheaPower,Lukasz
mitigaterelianceoncostlyhumanannotations. Ad-
Kaiser, Mohammad Bavarian, Clemens Winter,
ditionally,thereisaneedtodevelopmorenuanced
Philippe Tillet, Felipe Petroski Such, Dave Cum-
critiquemetricsthatcaneffectivelycapturethedi- mings, Matthias Plappert, Fotios Chantzis, Eliza-
verseaspectsofmodelperformanceacrossvarious beth Barnes, Ariel Herbert-Voss, William Hebgen
Guss,AlexNichol,AlexPaino,NikolasTezak,Jie
tasksandevaluationscenarios.
Tang,IgorBabuschkin,SuchirBalaji,ShantanuJain,
William Saunders, Christopher Hesse, Andrew N.
EthicsStatement
Carr,JanLeike,JoshAchiam,VedantMisra,Evan
Morikawa, Alec Radford, Matthew Knight, Miles
We constructed the model based on existing pub- Brundage,MiraMurati,KatieMayer,PeterWelinder,
lic datasets and models, as detailed in Section 3, BobMcGrew,DarioAmodei,SamMcCandlish,Ilya
andannotatedtheresultsusingGPT-4andhuman Sutskever,andWojciechZaremba.2021. Evaluating
largelanguagemodelstrainedoncode.
evaluation. Weacknowledgethat,despiteemploy-
ingrule-basedfiltering,GPT-4review,andhuman
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
review, unpredictableerrorsmaystillexistinthe William W Cohen. 2022. Program of thoughtsprompting: Disentanglingcomputationfromreason- ZhibinGou,ZhihongShao,YeyunGong,yelongshen,
ing for numerical reasoning tasks. arXiv preprint Yujiu Yang, Nan Duan, and Weizhu Chen. 2024a.
arXiv:2211.12588. CRITIC: Large language models can self-correct
withtool-interactivecritiquing. InTheTwelfthInter-
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and nationalConferenceonLearningRepresentations.
DennyZhou.2024. Teachinglargelanguagemodels
toself-debug. InTheTwelfthInternationalConfer- ZhibinGou,ZhihongShao,YeyunGong,yelongshen,
enceonLearningRepresentations.
YujiuYang,MinlieHuang,NanDuan,andWeizhu
Chen. 2024b. ToRA: A tool-integrated reasoning
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
agent for mathematical problem solving. In The
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
TwelfthInternationalConferenceonLearningRepre-
Zhuang,YonghaoZhuang,JosephEGonzalez,etal.
sentations.
2023. Vicuna: Anopen-sourcechatbotimpressing
gpt-4with90%*chatgptquality. Seehttps://vicuna.
DayaGuo,QihaoZhu,DejianYang,ZhendaXie,Kai
lmsys.org(accessed14April2023).
Dong, Wentao Zhang, Guanting Chen, Xiao Bi,
AakankshaChowdhery,SharanNarang,JacobDevlin, YWu,YKLi,etal.2024. Deepseek-coder:Whenthe
MaartenBosma,GauravMishra,AdamRoberts,Paul largelanguagemodelmeetsprogramming–theriseof
Barham,HyungWonChung,CharlesSutton,Sebas- codeintelligence. arXivpreprintarXiv:2401.14196.
tianGehrmann,etal.2023. Palm: Scalinglanguage
modelingwithpathways. JournalofMachineLearn- DanHendrycks,CollinBurns,SauravKadavath,Akul
ingResearch,24(240):1–113. Arora, Steven Basart, Eric Tang, Dawn Song, and
Jacob Steinhardt. 2021. Measuring mathematical
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, problemsolvingwiththemathdataset. NeurIPS.
MarkChen,HeewooJun,LukaszKaiser,Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Jie Huang, Xinyun Chen, Swaroop Mishra,
Nakano,etal.2021. Trainingverifierstosolvemath Huaixiu Steven Zheng, Adams Wei Yu, Xiny-
wordproblems. arXivpreprintarXiv:2110.14168. ingSong,andDennyZhou.2024. Largelanguage
models cannot self-correct reasoning yet. In The
Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao,
Twelfth International Conference on Learning
WeiZhu,YuanNi,GuotongXie,ZhiyuanLiu,and
Representations.
MaosongSun.2023. Ultrafeedback: Boostinglan-
guage models with high-quality feedback. arXiv
MojanJavaheripi,SébastienBubeck,MarahAbdin,Jy-
preprintarXiv:2310.01377.
oti Aneja, Sebastien Bubeck, Caio César Teodoro
Mendes, Weizhu Chen, Allie Del Giorno, Ronen
YilunDu,ShuangLi,AntonioTorralba,JoshuaBTenen-
Eldan,SivakanthGopi,etal.2023. Phi-2: Thesur-
baum,andIgorMordatch.2023. Improvingfactual-
prisingpowerofsmalllanguagemodels.
ityandreasoninginlanguagemodelsthroughmultia-
gentdebate. arXivpreprintarXiv:2305.14325.
Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
JinlanFu,See-KiongNg,ZhengbaoJiang,andPengfei sch,ChrisBamford,DevendraSinghChaplot,Diego
Liu.2023a. Gptscore: Evaluateasyoudesire. arXiv delasCasas,FlorianBressand,GiannaLengyel,Guil-
preprintarXiv:2302.04166. laumeLample,LucileSaulnier,etal.2023. Mistral
7b. arXivpreprintarXiv:2310.06825.
Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao
Peng, and Tushar Khot. 2023b. Chain-of-thought Albert Q Jiang, Alexandre Sablayrolles, Antoine
hub: Acontinuousefforttomeasurelargelanguage Roux,ArthurMensch,BlancheSavary,ChrisBam-
models’ reasoning performance. arXiv preprint ford,DevendraSinghChaplot,DiegodelasCasas,
arXiv:2305.17306. Emma Bou Hanna, Florian Bressand, et al. 2024.
Mixtralofexperts. arXivpreprintarXiv:2401.04088.
YaoFu,HaoPeng,AshishSabharwal,PeterClark,and
TusharKhot.2022. Complexity-basedpromptingfor
PeiKe,BosiWen,ZhuoerFeng,XiaoLiu,XuanyuLei,
multi-stepreasoning. InTheEleventhInternational
JialeCheng,ShengyuanWang,AohanZeng,Yuxiao
ConferenceonLearningRepresentations.
Dong, Hongning Wang, et al. 2023. Critiquellm:
Scaling llm-as-critic for effective and explainable
Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,
evaluationoflargelanguagemodelgeneration. arXiv
PengfeiLiu, YimingYang, JamieCallan, andGra-
preprintarXiv:2311.18702.
ham Neubig. 2023. Pal: Program-aided language
models. In International Conference on Machine
Learning,pages10764–10799.PMLR. Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
2023. Languagemodelscansolvecomputertasks.
MorGeva,DanielKhashabi,EladSegal,TusharKhot, arXivpreprintarXiv:2303.17491.
DanRoth, andJonathanBerant.2021. DidAristo-
tle Use a Laptop? A Question Answering Bench- JunlongLi,ShichaoSun,WeizheYuan,Run-ZeFan,hai
markwithImplicitReasoningStrategies. Transac- zhao,andPengfeiLiu.2024. Generativejudgefor
tionsoftheAssociationforComputationalLinguis- evaluatingalignment. InTheTwelfthInternational
tics(TACL). ConferenceonLearningRepresentations.Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
YanWang,RuiWang,YujiuYang,ZhaopengTu,and CarrollWainwright,PamelaMishkin,ChongZhang,
ShumingShi.2023. Encouragingdivergentthinking SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
inlargelanguagemodelsthroughmulti-agentdebate. 2022. Training languagemodelsto followinstruc-
arXivpreprintarXiv:2305.19118. tions with human feedback. Advances in Neural
InformationProcessingSystems,35:27730–27744.
HunterLightman,VineetKosaraju,YuraBurda,Harri
Bhargavi Paranjape, Scott Lundberg, Sameer Singh,
Edwards, Bowen Baker, Teddy Lee, Jan Leike,
Hannaneh Hajishirzi, Luke Zettlemoyer, and
John Schulman, Ilya Sutskever, and Karl Cobbe.
MarcoTulioRibeiro.2023. Art: Automaticmulti-
2023. Let’s verify step by step. arXiv preprint
stepreasoningandtool-useforlargelanguagemod-
arXiv:2305.20050.
els. arXivpreprintarXiv:2303.09014.
WangLing,DaniYogatama,ChrisDyer,andPhilBlun-
John Pougué-Biyong, Valentina Semenova, Alexan-
som.2017. Programinductionbyrationalegenera-
dreMatton,RachelHan,AerinKim,RenaudLam-
tion: Learningtosolveandexplainalgebraicword
biotte,andDoyneFarmer.2021. Debagreement: A
problems. ACL.
comment-replydatasetfor(dis)agreementdetection
inonlinedebates. InThirty-fifthConferenceonNeu-
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, ral Information Processing Systems Datasets and
Ruochen Xu, and Chenguang Zhu. 2023. Gpteval: BenchmarksTrack(Round2).
Nlgevaluationusinggpt-4withbetterhumanalign-
ment. arXivpreprintarXiv:2303.16634. WilliamSaunders,CatherineYeh,JeffWu,StevenBills,
LongOuyang,JonathanWard,andJanLeike.2022.
Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Self-critiquingmodelsforassistinghumanevaluators.
Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, arXivpreprintarXiv:2206.05802.
andAshwinKalyan.2023. Dynamicpromptlearning
TimoSchick,JaneDwivedi-Yu,RobertoDessì,Roberta
viapolicygradientforsemi-structuredmathematical
reasoning. InInternationalConferenceonLearning Raileanu,MariaLomeli,EricHambro,LukeZettle-
Representations(ICLR). moyer,NicolaCancedda,andThomasScialom.2024.
Toolformer: Languagemodelscanteachthemselves
to use tools. Advances in Neural Information Pro-
LiangchenLuo,ZiLin,YinxiaoLiu,LeiShu,YunZhu,
cessingSystems,36.
JingboShang,andLeiMeng.2024. Critiqueability
oflargelanguagemodels.
FredaShi,MiracSuzgun,MarkusFreitag,XuezhiWang,
SurajSrivats,SoroushVosoughi,HyungWonChung,
Yubo Ma, Zhibin Gou, Junheng Hao, Ruochen Xu,
Yi Tay, Sebastian Ruder, Denny Zhou, et al. 2022.
ShuohangWang,LiangmingPan,YujiuYang,Yixin
Languagemodelsaremultilingualchain-of-thought
Cao, and Aixin Sun. 2024. Sciagent: Tool- reasoners. arXivpreprintarXiv:2210.03057.
augmentedlanguagemodelsforscientificreasoning.
arXivpreprintarXiv:2402.11451. Noah Shinn, Federico Cassano, Ashwin Gopinath,
KarthikRNarasimhan,andShunyuYao.2023. Re-
AmanMadaan, NiketTandon,PrakharGupta,Skyler flexion: Languageagentswithverbalreinforcement
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, learning. In Thirty-seventh Conference on Neural
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, InformationProcessingSystems.
et al. 2023. Self-refine: Iterative refinement with
self-feedback. arXivpreprintarXiv:2303.17651. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao,
AbuAwalMdShoeb,AbubakarAbid,AdamFisch,
AdamRBrown,AdamSantoro,AdityaGupta,Adrià
Shahbuland Matiana, JR Smith, Ryan Teehan, Louis
Garriga-Alonso, et al. 2023. Beyond the imitation
Castricato,StellaBiderman,LeoGao,andSpencer
game: Quantifying and extrapolating the capabili-
Frazier. 2021. Cut the carp: Fishing for zero-shot
tiesoflanguagemodels. TransactionsonMachine
storyevaluation. arXivpreprintarXiv:2110.03111.
LearningResearch.
SewonMin,JulianMichael,HannanehHajishirzi,and
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
LukeZettlemoyer.2020. Ambigqa: Answeringam-
Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
biguousopen-domainquestions. InProceedingsof
DarioAmodei,andPaulFChristiano.2020. Learn-
the2020ConferenceonEmpiricalMethodsinNat-
ingtosummarizewithhumanfeedback. Advances
ural Language Processing (EMNLP), pages 5783–
inNeuralInformationProcessingSystems,33:3008–
5797.
3021.
ReiichiroNakano,JacobHilton,SuchirBalaji,JeffWu, Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-
Long Ouyang, Christina Kim, Christopher Hesse, bastian Gehrmann, Yi Tay, Hyung Won Chung,
ShantanuJain,VineetKosaraju,WilliamSaunders, AakankshaChowdhery,QuocVLe,EdHChi,Denny
et al. 2021. Webgpt: Browser-assisted question- Zhou,etal.2022. Challengingbig-benchtasksand
answering with human feedback. arXiv preprint whether chain-of-thought can solve them. arXiv
arXiv:2112.09332. preprintarXiv:2210.09261.Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-
JonathanBerant.2019. CommonsenseQA:Aques- gio,WilliamW.Cohen,RuslanSalakhutdinov,and
tion answering challenge targeting commonsense ChristopherD.Manning.2018. HotpotQA:Adataset
knowledge. InProceedingsofthe2019Conference fordiverse,explainablemulti-hopquestionanswer-
oftheNorthAmericanChapteroftheAssociationfor ing. InConferenceonEmpiricalMethodsinNatural
ComputationalLinguistics: HumanLanguageTech- LanguageProcessing(EMNLP).
nologies,Volume1(LongandShortPapers),pages
4149–4158,Minneapolis,Minnesota.Associationfor SeonghyeonYe,YongraeJo,DoyoungKim,Sungdong
ComputationalLinguistics. Kim, Hyeonbin Hwang, and Minjoon Seo. 2023.
Selfee: Iterativeself-revisingllmempoweredbyself-
Gemini Team, Rohan Anil, Sebastian Borgeaud, feedbackgeneration. Blogpost,May,3.
Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,
Radu Soricut, Johan Schalkwyk, Andrew M Dai, Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng
Anja Hauth, et al. 2023. Gemini: a family of Guo,JunqiDai,Xuan-JingHuang,andXipengQiu.
highlycapablemultimodalmodels. arXivpreprint 2023. Exchange-of-thought: Enhancing large lan-
arXiv:2312.11805. guagemodelcapabilitiesthroughcross-modelcom-
munication. InProceedingsofthe2023Conference
James Thorne, Andreas Vlachos, Christos onEmpiricalMethodsinNaturalLanguageProcess-
Christodoulopoulos, and Arpit Mittal. 2018. ing,pages15135–15153.
Fever: a large-scale dataset for fact extraction and
verification. arXivpreprintarXiv:1803.05355. ChuanyangZheng,ZhengyingLiu,EnzeXie,Zhenguo
Li, and Yu Li. 2023a. Progressive-hint prompting
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
improvesreasoninginlargelanguagemodels. arXiv
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
preprintarXiv:2304.09797.
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale, et al. 2023. Llama 2: Open founda- LianminZheng,Wei-LinChiang,YingSheng,Siyuan
tion and fine-tuned chat models. arXiv preprint Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
arXiv:2307.09288.
Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023b.
Judging llm-as-a-judge with mt-bench and chatbot
PeiyiWang,LeiLi,LiangChen,DaweiZhu,Binghuai
arena. arXivpreprintarXiv:2306.05685.
Lin,YunboCao,QiLiu,TianyuLiu,andZhifangSui.
2023a. Largelanguagemodelsarenotfairevaluators.
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
arXivpreprintarXiv:2305.17926.
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean ClaireCui,OlivierBousquet,QuocVLe,etal.2022.
O’Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Least-to-mostpromptingenablescomplexreasoning
OlgaGolovneva,LukeZettlemoyer,MaryamFazel- inlargelanguagemodels. InTheEleventhInterna-
Zarandi,andAsliCelikyilmaz.2023b. Shepherd: A
tionalConferenceonLearningRepresentations.
criticforlanguagemodelgeneration. arXivpreprint
arXiv:2308.04592.
XuezhiWang,JasonWei,DaleSchuurmans,QuocVLe,
EdHChi, SharanNarang, AakankshaChowdhery,
andDennyZhou.2022. Self-consistencyimproves
chainofthoughtreasoninginlanguagemodels. In
TheEleventhInternationalConferenceonLearning
Representations.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems,35:24824–24837.
Sean Welleck, Ximing Lu, Peter West, Faeze Brah-
man, Tianxiao Shen, Daniel Khashabi, and Yejin
Choi. 2022. Generating sequences by learning to
self-correct. InTheEleventhInternationalConfer-
enceonLearningRepresentations.
PeterWest,XimingLu,NouhaDziri,FaezeBrahman,
LinjieLi,JenaD.Hwang,LiweiJiang,JillianFisher,
AbhilashaRavichander,KhyathiChandu,Benjamin
Newman,PangWeiKoh,AllysonEttinger,andYejin
Choi.2024. ThegenerativeAIparadox: “whatitcan
create,itmaynotunderstand”. InTheTwelfthInter-
nationalConferenceonLearningRepresentations.ContentsoftheAppendix
A Statisticsof CRITICBENCH 14
B AnnotationExample 14
C ManualQualityCheck 16
D DetailedResultsonDifferentTasks 17
E Prompt 21
E.1 Generationprompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
E.2 Critiqueprompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
E.3 Correctionprompt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28A Statisticsof CRITICBENCH
Type Dataset Samples License
GSM8K 250 MITLicense
MATH 500 MITLicense
Math
AQuA 254 ApacheLicense2.0
TabMWP 300 CCBY-NC-SA4.0
CSQA 300 MITLicense
AmbigNQ 300 CCBY-SA3.0
Commonsense
StrategyQA 229 MITLicense
HotpotQA 300 CCBY-SA4.0
Penguins 146 ApacheLicense2.0
Symbolic ColoredObject 250 ApacheLicense2.0
Date 250 ApacheLicense2.0
MBPP 300 CCBY4.0
Coding
HumanEval 164 MITLicense
ObjectCounting 250 ApacheLicense2.0
Algorithmic
RepeatCopy 32 ApacheLicense2.0
All - 3825 -
Table2: StatisticsofthedatasetsusedinCRITICBENCH.
B AnnotationExample
Question: MachineAputsoutayo-yoevery6minutes. MachineBputsoutayo-yoevery9minutes.
Afterhowmanyminuteswilltheyhaveproduced10yo-yos?
AnswerChoices: A)24minutesB)32minutesC)36minutesD)64minutesE)72minutes
Solution: MachineAputsoutayo-yoevery6minutes. MachineBputsoutayo-yoevery9minutes. So
MachineAwillproduce10yo-yosin60minutes. MachineBwillproduce10yo-yosin90minutes. So
MachineAwillproduce10yo-yosin60minutesandMachineBwillproduce10yo-yosin90minutes.
Soafter120minutes,theywillhaveproduced10yo-yos. TheanswerisC)120.
Answer: C
Rule-basedanswermatching: Correct
GPT-4evaluation: Wrong
Manualreview: Wrong
Finallabel: Wrong
Table3: Inconsistenciesbetweenrule-basedmatchingandGPT-4evaluations(AQuA).Question:
def words_in_sentence(sentence):
"""
You are given a string representing a sentence,
the sentence contains some words separated by a space,
and you have to return a string that contains the words from the original sentence,
whose lengths are prime numbers,
the order of the words in the new string should be the same as the original one.
Example 1:
Input: sentence = "This is a test"
Output: "is"
Example 2:
Input: sentence = "lets go for swimming"
Output: "go for"
Constraints:
* 1 <= len(sentence) <= 100
* sentence contains only letters
"""
Solution:
def words_in_sentence(sentence):
words = sentence.split()
prime_words = [word for word in words if len(word) in [2, 3, 5, 7]]
return ' '.join(prime_words)
Checkfunction:
def check(candidate):
# Check some simple cases
assert candidate("This is a test") == "is"
assert candidate("lets go for swimming") == "go for"
assert candidate("there is no place available here") == "there is no place"
assert candidate("Hi I am Hussein") == "Hi am Hussein"
assert candidate("go for it") == "go for it"
# Check some edge cases that are easy to work out by hand.
assert candidate("here") == ""
assert candidate("here is") == "is"
check(words_in_sentence)
Checkresult: Correct
GPT-4evaluation: Wrong
Manualreview: Wrong
Finallabel: Wrong
Table4: Inconsistenciesbetweenrule-basedmatchingandGPT-4evaluations(HumanEval).Question: LakeWalesRidgeNationalWildlifeRefugeisontheUSroutethatrunsbetweenacityin
whatFloridacounty?
Solution: LakeWalesRidgeNationalWildlifeRefugeisontheUSroutethatrunsbetweenacityinPolk
County. TheanswerisPolkCounty.
Answer: polk
Rule-basedanswermatching: Wrong
GPT-4evaluation: Correct
Manualreview: Correct
Finallabel: Correct
Table5: Inconsistenciesbetweenrule-basedmatchingandGPT-4evaluations(HotpotQA).
C ManualQualityCheck
Wehaveconducteddetailedmanualcheckstoensurethelabelcorrectnessofthe CRITICBENCH. e.g.,
duringourexamination,wediscoveredthatallquestionsinthedatasetpertainingtotheevent"Janeand
JohnmarriedonJan2,1958,"haveissueswiththeiroptions. ThespecificerrorsaredetailedinTable6.
Question: JaneandJohnmarriedonJan2,1958. Itistheir5-yearanniversarytoday. Whatisthedate
todayinMM/DD/YYYY?
Options:
(A)01/02/1894
(B)01/02/1961
(C)12/23/1960
(D)01/02/1960
(E)01/03/1961
(F)01/02/1990
ProvidedAnswer: B
Explanation: IfJaneandJohnmarriedonJan2,1958,thedateofJaneandJohn’s5-yearanniversary
shouldbeJan2,1963.
Table6: IncorrectQuestioninDate(nocorrectoptionsprovided).D DetailedResultsonDifferentTasks
Model Generation Critiquing Correction
Baseline - 57.08 33.51
Phi-2 29.14 25.99 14.19
LLaMa-2-7b 19.88 31.73 31.83
LLaMa-2-7bchat 21.24 16.42 33.44
Vicuna-7b 19.73 31.24 33.36
Mistral-7b 33.90 55.28 33.36
LLaMa-2-13b 28.23 29.09 32.06
LLaMa-2-13bchat 28.30 45.91 31.52
Vicuna-13b 27.76 44.39 31.90
Vicuna-33b 30.82 54.15 33.51
LLaMa-2-70b 46.27 51.02 33.28
LLaMa-2-70bchat 36.89 69.47 30.90
Mixtral-8×7b 47.70 72.59 38.50
Mixtral-8×7binst 50.08 54.97 38.19
GPT-3.5 59.04 62.22 41.75
GPT-4 72.24 92.55 63.19
Averagescore 36.75 49.13 34.73
Table7: MathematicalReasoningTaskPerformance
Model Generation Critiquing Correction
Baseline - 46.82 55.98
Phi-2 37.56 39.28 42.96
LLaMa-2-7b 42.35 57.21 37.47
LLaMa-2-7bchat 43.05 61.05 33.22
Vicuna-7b 35.49 54.93 33.84
Mistral-7b 49.25 63.36 36.76
LLaMa-2-13b 49.78 48.42 45.26
LLaMa-2-13bchat 48.36 59.66 38.80
Vicuna-13b 40.20 53.49 43.49
Vicuna-33b 51.81 47.39 43.58
LLaMa-2-70b 58.72 57.86 46.94
LLaMa-2-70bchat 56.24 62.24 46.15
Mixtral-8×7b 55.36 59.07 47.92
Mixtral-8×7binst 56.07 46.77 50.75
GPT-3.5 47.85 50.89 44.02
GPT-4 65.32 72.13 59.96
Averagescore 49.16 55.58 43.41
Table8: CommonsenseReasoningTaskPerformanceModel Generation Critiquing Correction
Baseline - 40.84 65.48
Phi-2 69.20 26.80 68.58
LLaMa-2-7b 49.92 45.12 66.56
LLaMa-2-7bchat 48.92 32.62 65.94
Vicuna-7b 54.27 48.75 65.79
Mistral-7b 70.90 51.77 64.09
LLaMa-2-13b 62.93 24.83 67.65
LLaMa-2-13bchat 63.00 31.48 67.34
Vicuna-13b 65.30 55.66 67.34
Vicuna-33b 65.53 53.88 62.54
LLaMa-2-70b 80.47 56.77 63.93
LLaMa-2-70bchat 78.64 53.49 64.71
Mixtral-8×7b 82.51 57.21 69.97
Mixtral-8×7binst 82.97 52.66 70.74
GPT-3.5 87.79 64.49 71.83
GPT-4 96.00 90.75 92.41
Averagescore 70.56 49.75 68.63
Table9: SymbolicReasoningTaskPerformance
Model Generation Critiquing Correction
Baseline - 55.73 37.07
Phi-2 50.22 13.92 30.39
LLaMa-2-7b 18.75 10.79 37.93
LLaMa-2-7bchat 20.69 54.73 30.82
Vicuna-7b 20.69 30.30 32.76
Mistral-7b 38.58 50.72 38.15
LLaMa-2-13b 25.00 22.49 38.36
LLaMa-2-13bchat 25.86 56.26 29.74
Vicuna-13b 22.84 42.39 19.61
Vicuna-33b 27.16 67.14 21.98
LLaMa-2-70b 39.66 54.76 39.66
LLaMa-2-70bchat 37.07 65.60 37.28
Mixtral-8×7b 48.71 63.30 42.89
Mixtral-8×7binst 51.08 67.95 49.57
GPT-3.5 68.32 73.13 61.99
GPT-4 74.57 91.55 76.29
Averagescore 37.95 51.00 39.16
Table10: CodeGenerationTaskPerformanceModel Generation Critiquing Correction
Baseline - 40.51 65.96
Phi-2 67.02 7.84 66.31
LLaMa-2-7b 47.16 30.97 56.38
LLaMa-2-7bchat 47.52 42.86 29.08
Vicuna-7b 43.38 4.04 64.89
Mistral-7b 62.77 16.81 64.89
LLaMa-2-13b 48.58 5.83 66.31
LLaMa-2-13bchat 53.90 45.24 56.38
Vicuna-13b 61.70 7.55 64.54
Vicuna-33b 59.22 16.67 66.67
LLaMa-2-70b 77.30 16.98 67.02
LLaMa-2-70bchat 62.06 53.63 58.87
Mixtral-8×7b 81.21 21.43 68.09
Mixtral-8×7binst 84.04 41.48 65.96
GPT-3.5 90.43 46.15 58.36
GPT-4 94.68 63.51 77.66
Averagescore 65.40 28.07 62.09
Table11: AlgorithmicTaskPerformance
Mathematical Reasoning Task Performance
100
Generation
Critiquing
Correction
Correction baseline
80
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
Commonsense Reasoning Task Performance
100
Generation
Critiquing
Correction
Correction baseline
80
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
Figure9: Models’performanceondifferenttypesoftasks(Part1).
erocS
erocSSymbolic Reasoning Task Performance
100
Generation
Critiquing
Correction
80 Correction baseline
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
Code Generation Task Performance
100
Generation
Critiquing
Correction
80 Correction baseline
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
Algorithmic Task Performance
100
Generation
Critiquing
Correction
80 Correction baseline
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
All Task Performance
100
Generation
Critiquing
Correction
80 Correction baseline
Critiquing baseline
60
40
20
0
Phi-2 LLaMa-2-7 Lb LaMa-2-7b cha Vt icuna-7b Mistral-7b LLaMa-2-1 L3 Lb aMa-2-13b ch Va it cuna-13b Vicuna-33b LLaMa-2-7 L0 Lb aMa-2-70b c Mh ia xt tral-8× M7 ib xtral-8×7b inst GPT-3.5 GPT-4
Model
Figure10: Models’performanceondifferenttypesoftasks(Part2).
erocS
erocS
erocS
erocSE Prompt
E.1 Generationprompt
InTable12,wedetailedallthepromptsforgeneration.
Dataset PromptSource
GSM8K CoT(Weietal.,2022)
MATH CoTHub(Fuetal.,2023b)
AQuA Self-Consistency(Wangetal.,2022)
CSQA CoT(Weietal.,2022)
AmbigNQ CRITIC(Gouetal.,2024a)
StrategyQA CoT(Weietal.,2022)
HotpotQA Self-Consistency(Wangetal.,2022)
Penguins BIG-BenchHard(Suzgunetal.,2022)
ColoredObject BIG-BenchHard(Suzgunetal.,2022)
Date BIG-BenchHard(Suzgunetal.,2022)
MBPP DeepSeek-Coder(Guoetal.,2024)
ObjectCounting BIG-BenchHard(Suzgunetal.,2022)
RepeatCopy ART(Paranjapeetal.,2023)
TabMWP WrittenbyAuthors
HumanEval WrittenbyAuthors
Table12: GenerationPromptsandSources
E.2 Critiqueprompt
Question: {question}
Answer: {response}
Reviewyourpreviousanswerandfindproblemswithyouranswer.
Finally,concludewitheither’[[correct]]’iftheaboveansweriscorrector’[[wrong]]’ifitisincorrect.
Verdict:
Table13: Zero-shotAnswerOnlyPromptforCritique
Question: {question}
Answer: {response}
Reviewyourpreviousanswerandfindproblemswithyouranswer.
Provide your analysis and verdict in JSON format as follows: {"analysis": "your analysis", "verdict":
"correctorwrong"}.
Analysisandverdict:
Table14: Zero-shotChainofThoughtPromptforCritiqueReviewtheaboveansweranddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheaboveansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
Question: To locate a choker not located in a jewelry box or boutique where would you go? Answer
Choices: (a)jewelrystore(b)neck(c)jewlerybox(d)jewelrybox(e)boutique
Answer: Ifyouwanttolocateachokerthatisnotinajewelryboxorboutique,youwouldmostlikelygo
toyourneck(b)sinceachokerisatypeofnecklacethatiswornaroundtheneck. Sotheansweris(b).
Verdict: Thequestionaskswhereyouwouldfindachokerifit’snotlocatedinajewelryboxorboutique.
Thegivenanswersuggeststhatthechokerwouldbefoundonyourneck,whichisalogicalplacefora
chokerwhenitisbeingworn. However,thequestionseemstobeseekingalocationwhereonemight
findachokerforpurchaseorretrievalotherthanajewelryboxorboutique. Theoptionsprovidedare(a)
jewelrystore,(b)neck,(c)jewelrybox,(d)jewelrybox,and(e)boutique.
Considering the context, option (a) jewelry store is the most appropriate answer. A jewelry store is a
commonplacetofindchokersforpurchaseordisplay,apartfromajewelryboxorboutique. Thegiven
answerassumesthechokerisbeingworn,whichisnotnecessarilyimpliedbythequestion. Sotheverdict
is: [[wrong]]
—
......
—
Question: Stanleyhadadreamthatwasveryvividandscary. Hehadtroubletellingitfromwhat? Answer
Choices: (a)reality(b)imagination(c)dreamworker(d)nightmare(e)awake
Answer: TheanswershouldbesomethingthatStanleyhadtroubledistinguishinghisdreamfrom. Inthis
case,theansweris(a)reality. Stanleyhadtroubletellinghisvividandscarydreamfromreality. Sothe
answeris(a).
Verdict: ThequestionaskswhatStanleyhadtroubledistinguishinghisvividandscarydreamfrom. The
givenanswerstatesthatthecorrectchoiceis(a)reality,indicatingthatStanleyhaddifficultytellinghis
dreamapartfromreallife. Thisinterpretationisconsistentwiththetypicaluseofthephrase"hadtrouble
tellingitfrom"inthecontextofdreams. ItsuggeststhatthedreamfeltsorealtoStanleythathestruggled
todifferentiateitfromactualeventsorexperiences. Sotheverdictis: [[correct]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Question: {question}
Answer: {response}
Verdict:
Table15: Few-shotPrompt(4-shot)ofCSQAforCritiqueReviewtheaboveansweranddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheaboveansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
Question: Basedonwhentheprojectwasbeingworkedon,whendidtheManhattanprojectbeginand
end?
Answer: TheManhattanProjectbeganin1939andendedin1946. Itwasaresearchanddevelopment
projectduringWorldWarIIthatproducedthefirstnuclearweapons. Sotheansweris: Began1939,end
1946
Verdict: TheManhattanProjectactuallybeganin1942,not1939,andwascompletedin1946. Itwas
indeedaresearchanddevelopmentprojectduringWorldWarIIthatledtothecreationofthefirstnuclear
weapons. Theincorrectstartdateintheanswermakesitinaccurate. Sotheverdictis: [[wrong]]
—
Question: Whohelpedlewisandclarkontheirjourney?
Answer: Lewis and Clark were helped on their journey by the Corps of Discovery, which included
memberslikeSacagawea,whoservedasaninterpreterandguide. Sotheansweris: Sacagawea
Verdict: Theanswertothequestion""WhohelpedLewisandClarkontheirjourney?""iscorrect. Lewis
andClarkwereassistedbytheCorpsofDiscovery,whichincludedSacagawea,animportantmember
whoservedasaninterpreterandguide. Therefore,theansweridentifyingSacagaweaasakeyhelperis
accurate. Sotheverdictis: [[correct]]
—
Question: Whodoesthevoiceofcortanainhalovideogames?
Answer: ThevoiceofCortanaintheHalovideogamesisprovidedbyactressJenTaylor. Sotheanswer
is: JenTaylor
Verdict: TheanswerprovidedforthevoiceofCortanaintheHalovideogamesiscorrect. JenTayloris
indeedtheactresswhovoicesCortanaintheseries. Sotheverdictis: [[correct]]
—
Question: Whoislin’sfatherinlegendofkorra?
Answer: Intheanimatedseries""TheLegendofKorra,""LinBeifong’sfatherisTophBeifong,whois
aprominentcharacterintheAvataruniverseandoneoftheoriginalmembersofTeamAvatarfromthe
precedingseries,""Avatar: TheLastAirbender.""Sotheansweris: TophBeifong
Verdict: In""TheLegendofKorra,""LinBeifong’sfatherisnotTophBeifong. TophBeifongisLin’s
mother. Lin’sfatherisrevealedtobeamannamedKanto. Thisinformationisdisclosedinseason4ofthe
series,makingtheoriginalanswerincorrect. Sotheverdictis: [[wrong]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Question: {question}
Answer: {response}
Verdict:
Table16: Few-shotPrompt(4-shot)ofAmbigNQforCritiqueReviewtheaboveansweranddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheaboveansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
Question: HermanlikestofeedthebirdsinDecember,JanuaryandFebruary. Hefeedsthem1/2cupin
themorningand1/2cupintheafternoon. Howmanycupsoffoodwillheneedforallthreemonths?
Answer: Hermanfeedsthebirds1/2cupinthemorningand1/2cupintheafternoon,soeachdayheuses
1/2+1/2=1cupoffood. Thereare3monthsintotal,sohewillneed3*1=3cupsoffoodforallthree
months. Theansweris3.
Verdict: TheanswercalculatesHermanfeedingthebirds1cupoffoodperday(1/2cupinthemorning
and1/2cupintheafternoon). However,itincorrectlymultipliesthisdailyamountby3,assumingthere
areonly3daysinthreemonths,resultingin3cupsoffoodforallthreemonths. Thisisasignificanterror
inunderstandingthedurationofthreemonths.
Sotheverdictis: [[wrong]]
—
......
—
Question: Wengearns$12anhourforbabysitting. Yesterday,shejustdid50minutesofbabysitting. How
muchdidsheearn?
Answer: Weng earns $12 per hour for babysitting. Yesterday, she babysat for 50 minutes, which is
equivalentto50/60=5/6ofanhour. Tocalculateherearnings,multiplyherhourlyratebythefractionof
anhoursheworked: 12∗5/6=10. Wengearned$10forher50minutesofbabysitting. Theansweris10.
Verdict: The given answer accurately calculates Weng’s earnings for babysitting for 50 minutes. It
correctlyidentifiesthat50minutesis5/6ofanhourandthenmultipliesthisfractionbyherhourlyrate
of$12. Thecalculationof$12*5/6equals$10, whichisthecorrectamountWengearnedforher50
minutesofbabysitting.
Sotheverdictis: [[correct]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Question: {question}
Answer: {response}
Verdict:
Table17: Few-shotPrompt(4-shot)ofGSM8KforCritiqueReviewtheaboveansweranddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheaboveansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
......
—
Table:
[TITLE]: Ferryfares
Ferry|Car|Bicycle
Seattle-Bremerton|$12|$8
Mukilteu-Clinton|$7|$5
Southport-FortFisher|$5|$2
Fauntleroy-Vashon|$15|$5
Ocracoke|$15|$3
Question: Foraneconomicsproject,Layladeterminedthecostofferryridesforbicyclesandcars. How
muchdoesitcosttotakeabicycleontheSouthport-FortFisherferry? Answer: Tofindthecostoftaking
abicycleontheSouthport-FortFisherferry,youcanrefertothetable:
Southport-FortFisher|$5|$2
ThecostforabicycleontheSouthport-FortFisherferryis$2.
So,itcosts$2totakeabicycleonthisferry. Theansweris2.
Verdict:
Uponreviewingtheprovidedanswer:
ThequestionasksforthecostoftakingabicycleontheSouthport-FortFisherferry. Thetableprovides
thecostofferryridesforbothcarsandbicycles.
TheentryfortheSouthport-FortFisherferryshowsthecostforabicycleas$2.
Theanswercorrectlyidentifiesthisvaluefromthetableandstatesthatitcosts$2totakeabicycleon
theSouthport-FortFisherferry. Nocalculationsareneededastheinformationisdirectlyavailableinthe
table.
Theansweraccuratelyextractstherelevantdatafromthetableandcorrectlyidentifiesthecostoftakinga
bicycleontheSouthport-FortFisherferryas$2.
Sotheverdictis: [[correct]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Question: {question}
Answer: {response}
Verdict:
Table18: Few-shotPrompt(4-shot)ofTabMWPforCritiqueReviewtheprovidedcodeanddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheprovidedansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
Code:
def last_digit_sum(a: int, b: int) -> int:
"""
Complete the function that takes two integers and returns the sum of their last digits.
Assume the input is always valid.
Examples:
last_digit_sum(123, 453) should return 6 (3 + 3).
last_digit_sum(789, 10) should return 9 (9 + 0).
last_digit_sum(100, 27) should return 7 (0 + 7).
last_digit_sum(25, -31) should return 6 (5 + 1).
"""
return abs(a \% 100) + abs(b \% 100)
Verdict: The provided function last_digit_sum is supposed to return the sum of the last digits of two
integers,butthecurrentimplementationreturnsthesumoftheabsolutevaluesofthelasttwodigitsof
each integer. The examples in the problem statement also indicate that the function should return the
actualsumofthelastdigits,nottheirabsolutevalues.
Sotheverdictis: [[wrong]]
—
...
—
Code:
from typing import List
def has_similar_word_lengths(words: List[str], threshold: int) -> bool:
"""
Check if in the given list of words, are any two words whose length difference is less than or equal to
the given threshold.
>>> has_similar_word_lengths(["hello", "world", "hi", "python"], 2)
True
>>> has_similar_word_lengths(["chat", "learning", "ai"], 1)
False
"""
for i in range(len(words)):
for j in range(i + 1, len(words)):
if abs(len(words[i]) - len(words[j])) <= threshold:
return True
return False
Verdict: Theprovidedcodeiteratesoveralluniquepairsofwordsbyusingtwonestedloops,compares
thelengthsofthewords,andreturnsTrueifitfindsapairthatsatisfiesthecondition(lengthdifferenceis
lessthanorequaltothethreshold). Ifnosuchpairisfound,itreturnsFalse.
Sotheverdictis: [[correct]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Code:
{code}
Verdict:
Table19: Few-shotPrompt(4-shot)ofHumanEvalforCritiqueReviewtheprovidedansweranddeterminewhetherit’scorrect. Ifwrong,findtheproblemswithit.
Finally,concludewitheither’[[correct]]’iftheprovidedansweriscorrector’[[wrong]]’ifitisincorrect.
Herearesomeexamples:
—
Question: Saypickupapoundofgreenbeanstwice,replacingapoundwithabunchforeventimesanda
handfulforodd
Answer: pickupahandfulofgreenbeanspickupabunchofgreenbeans
Verdict: Let’sbreakdowntheinstruction:
Theinstructionisto"pickupapoundofgreenbeanstwice".
Foreventimes,replace"apound"with"abunch".
Foroddtimes,replace"apound"with"ahandful".
Followingtheseinstructions:
The first time (odd), "pick up a pound of green beans" becomes "pick up a handful of green beans".
Thesecondtime(even),"pickupapoundofgreenbeans"becomes"pickupabunchofgreenbeans".
Therefore,theprovidedanswerof"pickupahandfulofgreenbeanspickupabunchofgreenbeans"
matchestheinstructionsgiven.
Sotheverdictis: [[correct]]
—
...
—
Question: Saystacktenbricksthreetimes,replacingtenwithtwentyforeventimesandfiveforoddtimes.
Answer: stackfivebricksstacktwentybricksstacktenbricks.
Verdict: Accordingtotheinstruction:
Say"stacktenbricks"threetimes.
Replace"ten"with"twenty"foreventimes.
Replace"ten"with"five"foroddtimes.
Applyingtheserules:
Firsttime(odd): Replace"ten"with"five",resultingin"stackfivebricks".
Secondtime(even): Replace"ten"with"twenty",resultingin"stacktwentybricks".
Thirdtime(oddagain): Replace"ten"with"five",resultingin"stackfivebricks".
Theprovidedanswerincorrectlysays"stacktenbricks"forthethirdtimeinsteadofreplacing"ten"with
"five". Sotheverdictis: [[wrong]]
—
Pleaseconsidertheexampleprovidedandthinkitstepbystep.
Question: {question}
Answer: {solution}
Verdict:
Table20: Few-shotPrompt(4-shot)ofRepeatCopyforCritiqueE.3 Correctionprompt
Question: {question}
Answer: {answer}
Analysisandverdict: {critique}
Basedontheproblemsyoufound,improveyouranswer. Pleasereiterateyoursolution,withyourfinal
answer as either a single numerical number, a single word, or a short phrase, in the JSON format as
follows: {"solution":"improvedsolution","answer":"youranswer"}.
Improvedsolutionandanswer:
Table21: Zero-shotChainofThoughtPromptforCorrectionBasedontheproblemsyoufound,improveyouranswer. YoumustchooseonlyoneoptionfromAtoE.
Pleasereiterateyouranswer,withyourfinalanswerasingleletterfromAtoE,intheform[[answer]].
Herearesomeexamples:
—
Question: To locate a choker not located in a jewelry box or boutique where would you go? Answer
Choices: (a)jewelrystore(b)neck(c)jewlerybox(d)jewelrybox(e)boutique
Answer: Ifyouwanttolocateachokerthatisnotinajewelryboxorboutique,youwouldmostlikelygo
toyourneck(b)sinceachokerisatypeofnecklacethatiswornaroundtheneck. Sotheansweris(b).
Verdict: Thequestionaskswhereyouwouldfindachokerifit’snotlocatedinajewelryboxorboutique.
Thegivenanswersuggeststhatthechokerwouldbefoundonyourneck,whichisalogicalplacefora
chokerwhenitisbeingworn.
However, the question seems to be seeking a location where one might find a choker for purchase or
retrievalotherthanajewelryboxorboutique. Theoptionsprovidedare(a)jewelrystore,(b)neck,(c)
jewelrybox,(d)jewelrybox,and(e)boutique.
Considering the context, option (a) jewelry store is the most appropriate answer. A jewelry store is a
commonplacetofindchokersforpurchaseordisplay,apartfromajewelryboxorboutique. Thegiven
answerassumesthechokerisbeingworn,whichisnotnecessarilyimpliedbythequestion.
Sotheverdictis: [[wrong]]
ImprovedAnswer: Theimprovedansweris: [[a]]jewelrystore.
—
......
—
Question: Stanleyhadadreamthatwasveryvividandscary. Hehadtroubletellingitfromwhat? Answer
Choices: (a)reality(b)imagination(c)dreamworker(d)nightmare(e)awake
Answer: TheanswershouldbesomethingthatStanleyhadtroubledistinguishinghisdreamfrom. Inthis
case,theansweris(a)reality. Stanleyhadtroubletellinghisvividandscarydreamfromreality. Sothe
answeris(a).
Verdict: ThequestionaskswhatStanleyhadtroubledistinguishinghisvividandscarydreamfrom. The
givenanswerstatesthatthecorrectchoiceis(a)reality,indicatingthatStanleyhaddifficultytellinghis
dreamapartfromreallife. Thisinterpretationisconsistentwiththetypicaluseofthephrase"hadtrouble
tellingitfrom"inthecontextofdreams. ItsuggeststhatthedreamfeltsorealtoStanleythathestruggled
todifferentiateitfromactualeventsorexperiences. Sotheverdictis: [[correct]]
ImprovedAnswer: Theansweris[[a]]
—
Question: {question}
Answer: {answer}
Verdict: {critique}
ImprovedAnswer:
Table22: Few-shotPrompt(4-shot)ofCSQAforCorrectionBasedontheproblemsyoufound,improveyouranswer. Pleasereiterateyouranswer,withyourfinal
answeraseitherasinglenumericalnumber,asingleword,orashortphrase,intheform[[answer]].
Herearesomeexamples:
—
Question: Basedonwhentheprojectwasbeingworkedon,whendidtheManhattanprojectbeginand
end?
Answer: TheManhattanProjectbeganin1939andendedin1946. Itwasaresearchanddevelopment
projectduringWorldWarIIthatproducedthefirstnuclearweapons. Sotheansweris: Began1939,end
1946
Verdict: TheManhattanProjectactuallybeganin1942,not1939,andwascompletedin1946. Itwas
indeedaresearchanddevelopmentprojectduringWorldWarIIthatledtothecreationofthefirstnuclear
weapons. Theincorrectstartdateintheanswermakesitinaccurate. Sotheverdictis: [[wrong]]
ImprovedAnswer: TheManhattanProject[[beganin1942andendedin1946]].
—
Question: Whohelpedlewisandclarkontheirjourney?
Answer: Lewis and Clark were helped on their journey by the Corps of Discovery, which included
memberslikeSacagawea,whoservedasaninterpreterandguide. Sotheansweris: Sacagawea
Verdict: Theanswertothequestion"WhohelpedLewisandClarkontheirjourney?"iscorrect. Lewis
andClarkwereassistedbytheCorpsofDiscovery,whichincludedSacagawea,animportantmember
whoservedasaninterpreterandguide. Therefore,theansweridentifyingSacagaweaasakeyhelperis
accurate. Sotheverdictis: [[correct]]
ImprovedAnswer: [[Sacagawea]]helpedLewisandClarkontheirjourney.
—
Question: Whodoesthevoiceofcortanainhalovideogames?
Answer: ThevoiceofCortanaintheHalovideogamesisprovidedbyactressJenTaylor. Sotheanswer
is: JenTaylor
Verdict: TheanswerprovidedforthevoiceofCortanaintheHalovideogamesiscorrect. JenTayloris
indeedtheactresswhovoicesCortanaintheseries. Sotheverdictis: [[correct]]
ImprovedAnswer: [[JenTaylor]]
—
Question: Whoislin’sfatherinlegendofkorra?
Answer: Intheanimatedseries"TheLegendofKorra,"LinBeifong’sfatherisTophBeifong,whoisa
prominent character in the Avatar universeand one of the originalmembers of Team Avatar from the
precedingseries,"Avatar: TheLastAirbender."Sotheansweris: TophBeifong
Verdict: In "The Legend of Korra," Lin Beifong’s father is not Toph Beifong. Toph Beifong is Lin’s
mother. Lin’sfatherisrevealedtobeamannamedKanto. Thisinformationisdisclosedinseason4ofthe
series,makingtheoriginalanswerincorrect. Sotheverdictis: [[wrong]]ImprovedAnswer: LinBeifong’s
fatherin"TheLegendofKorra"is[[Kanto]].
—
Question: {question}
Answer: {answer}
Verdict: {critique}
ImprovedAnswer:
Table23: Few-shotPrompt(4-shot)ofAmbigNQforCorrectionBasedontheproblemsyoufound,improveyouranswer. Pleasereiterateyouranswer,withyourfinal
answerasinglenumericalnumber,intheform[[answer]].
Herearesomeexamples:
—
Question: HermanlikestofeedthebirdsinDecember,JanuaryandFebruary. Hefeedsthem1/2cupin
themorningand1/2cupintheafternoon. Howmanycupsoffoodwillheneedforallthreemonths?
Answer: Hermanfeedsthebirds1/2cupinthemorningand1/2cupintheafternoon,soeachdayheuses
1/2+1/2=1cupoffood. Thereare3monthsintotal,sohewillneed3*1=3cupsoffoodforallthree
months. Theansweris3.
Verdict: TheanswercalculatesHermanfeedingthebirds1cupoffoodperday(1/2cupinthemorning
and1/2cupintheafternoon). However,itincorrectlymultipliesthisdailyamountby3,assumingthere
areonly3daysinthreemonths,resultingin3cupsoffoodforallthreemonths. Thisisasignificanterror
inunderstandingthedurationofthreemonths. Sotheverdictis: [[wrong]]
ImprovedAnswer: TocalculatetheamountoffoodHermanwillneedforallthreemonths,weneedto
considerthenumberofdaysinDecember,January,andFebruary. DecemberandJanuarytypicallyhave
31dayseach,whileFebruarycanhave28or29days,dependingonwhetherit’saleapyear. Assuminga
non-leapyear,Februaryhas28days. Therefore,thetotalnumberofdaysis31(December)+31(January)
+28(February)=90days. SinceHermanfeedsthebirds1cupoffoodeachday(1/2cupinthemorning
and1/2cupintheafternoon),thetotalamountoffoodhewillneedforallthreemonthsis90cups. The
answeris[[90]].
—
......
—
Question: Wengearns$12anhourforbabysitting. Yesterday,shejustdid50minutesofbabysitting. How
muchdidsheearn?
Answer: Weng earns $12 per hour for babysitting. Yesterday, she babysat for 50 minutes, which is
equivalentto50/60=5/6ofanhour. Tocalculateherearnings,multiplyherhourlyratebythefractionof
anhoursheworked: $12*5/6=$10. Wengearned$10forher50minutesofbabysitting. Theansweris
10.
Verdict: The given answer accurately calculates Weng’s earnings for babysitting for 50 minutes. It
correctlyidentifiesthat50minutesis5/6ofanhourandthenmultipliesthisfractionbyherhourlyrate
of$12. Thecalculationof$12*5/6equals$10, whichisthecorrectamountWengearnedforher50
minutesofbabysitting.
Sotheverdictis: [[correct]]
ImprovedAnswer: Theansweris[[10]].
—
Question: {question}
Answer: {answer}
Verdict: {critique}
ImprovedAnswer:
Table24: Few-shotPrompt(4-shot)ofGSM8KforCorrectionBasedontheproblemsyoufound,improveyouranswer. Pleasereiterateyouranswer,withyourfinal
answeraseitherasinglenumericalnumberoroneoptionfromAtoD,intheform[[answer]].
Herearesomeexamples:
—
......
—
Table:
[TITLE]: Ferryfares
Ferry|Car|Bicycle
Seattle-Bremerton|$12|$8
Mukilteu-Clinton|$7|$5
Southport-FortFisher|$5|$2
Fauntleroy-Vashon|$15|$5
Ocracoke|$15|$3
Question: Foraneconomicsproject,Layladeterminedthecostofferryridesforbicyclesandcars. How
muchdoesitcosttotakeabicycleontheSouthport-FortFisherferry? Answer: Tofindthecostoftaking
abicycleontheSouthport-FortFisherferry,youcanrefertothetable:
Southport-FortFisher|$5|$2
ThecostforabicycleontheSouthport-FortFisherferryis$2.
So,itcosts$2totakeabicycleonthisferry. Theansweris2.
Verdict:
Uponreviewingtheprovidedanswer:
ThequestionasksforthecostoftakingabicycleontheSouthport-FortFisherferry. Thetableprovides
thecostofferryridesforbothcarsandbicycles.
TheentryfortheSouthport-FortFisherferryshowsthecostforabicycleas$2.
Theanswercorrectlyidentifiesthisvaluefromthetableandstatesthatitcosts$2totakeabicycleon
theSouthport-FortFisherferry. Nocalculationsareneededastheinformationisdirectlyavailableinthe
table.
Theansweraccuratelyextractstherelevantdatafromthetableandcorrectlyidentifiesthecostoftakinga
bicycleontheSouthport-FortFisherferryas$2.
Sotheverdictis: [[correct]]
ImprovedAnswer: Theansweris[[2]].
—
Question: {question}
Answer: {answer}
Verdict: {critique}
ImprovedAnswer:
Table25: Few-shotPrompt(4-shot)ofTabMWPforCorrectionBasedontheproblemsyoufound,improveyourcodeintheform[BEGIN]\nimprovedcode\n[DONE]
Herearesomeexamples:
—
......
—
Code:
from typing import List
def has_similar_word_lengths(words: List[str], threshold: int) -> bool:
"""
Check if in the given list of words, are any two words whose length difference is less than or equal to
the given threshold.
>>> has_similar_word_lengths(["hello", "world", "hi", "python"], 2)
True
>>> has_similar_word_lengths(["chat", "learning", "ai"], 1)
False
"""
for i in range(len(words)):
for j in range(i + 1, len(words)):
if abs(len(words[i]) - len(words[j])) <= threshold:
return True
return False
Verdict: Theprovidedcodeiteratesoveralluniquepairsofwordsbyusingtwonestedloops,compares
thelengthsofthewords,andreturnsTrueifitfindsapairthatsatisfiesthecondition(lengthdifferenceis
lessthanorequaltothethreshold). Ifnosuchpairisfound,itreturnsFalse.
Sotheverdictis: [[correct]]
ImprovedCode:
[BEGIN]
from typing import List
def has_similar_word_lengths(words: List[str], threshold: int) -> bool:
"""
Check if in the given list of words, are any two words whose length difference is less than or equal to
the given threshold.
>>> has_similar_word_lengths(["hello", "world", "hi", "python"], 2)
True
>>> has_similar_word_lengths(["chat", "learning", "ai"], 1)
False
"""
for i in range(len(words)):
for j in range(i + 1, len(words)):
if abs(len(words[i]) - len(words[j])) <= threshold:
return True
return False
[DONE]
—
Code:
{code}
Verdict: {critique}
ImprovedCode:
Table26: Few-shotPrompt(4-shot)ofHumanEvalforCorrectionBasedontheproblemsyoufound,improveyouranswer. Pleasereiterateyouranswer,withyourfinal
answerintheform[[answer]].
Herearesomeexamples:
—
Question: Saypickupapoundofgreenbeanstwice,replacingapoundwithabunchforeventimesanda
handfulforodd
Answer: pickupahandfulofgreenbeanspickupabunchofgreenbeansVerdict: Let’sbreakdownthe
instruction:
Theinstructionisto"pickupapoundofgreenbeanstwice".
Foreventimes,replace"apound"with"abunch".
Foroddtimes,replace"apound"with"ahandful".
Followingtheseinstructions:
Thefirsttime(odd),"pickupapoundofgreenbeans"becomes"pickupahandfulofgreenbeans".
Thesecondtime(even),"pickupapoundofgreenbeans"becomes"pickupabunchofgreenbeans".
Therefore,theprovidedanswerof"pickupahandfulofgreenbeanspickupabunchofgreenbeans"
matchestheinstructionsgiven. Sotheverdictis: [[correct]]
ImprovedAnswer: [[pickupahandfulofgreenbeanspickupabunchofgreenbeans]]
—
......
—
Question: Saystacktenbricksthreetimes,replacingtenwithtwentyforeventimesandfiveforoddtimes.
Answer: stackfivebricksstacktwentybricksstacktenbricks.
Verdict: Accordingtotheinstruction:
Say"stacktenbricks"threetimes.
Replace"ten"with"twenty"foreventimes.
Replace"ten"with"five"foroddtimes.
Applyingtheserules:
Firsttime(odd): Replace"ten"with"five",resultingin"stackfivebricks".
Secondtime(even): Replace"ten"with"twenty",resultingin"stacktwentybricks".
Thirdtime(oddagain): Replace"ten"with"five",resultingin"stackfivebricks".
Theprovidedanswerincorrectlysays"stacktenbricks"forthethirdtimeinsteadofreplacing"ten"with
"five".
Sotheverdictis: [[wrong]]
ImprovedAnswer: [[stackfivebricksstacktwentybricksstackfivebricks]]
—
Question: {question}
Answer: {answer}
Verdict: {critique}
ImprovedAnswer:
Table27: Few-shotPrompt(4-shot)ofRepeatCopyforCorrection