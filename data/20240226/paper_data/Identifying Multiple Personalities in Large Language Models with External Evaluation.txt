Identifying Multiple Personalities in Large Language Models
with External Evaluation
XiaoyangSong1,YutaAdachi2∗,JessieFeng2∗,MouweiLin2∗,LinhaoYu2∗,FrankLi2∗,
AkshatGupta3,GopalaAnumanchipalli3,SimerjotKaur4
1UniversityofMichigan,2ColumbiaUniversity,3UCBerkeley,4 AIResearch,JPMorgan
xysong@umich.edu, akshat.gupta@berkeley.edu, simerjot.kaur@jpmchase.com
Abstract their unprecedented capacities to understand and
generate human-like languages (Radford et al.,
AsLargeLanguageModels(LLMs)areinte-
2018, 2019; Brown et al., 2020; Ouyang et al.,
gratedwithhumandailyapplicationsrapidly,
2022;OpenAI,2023,2022;Zhangetal.,2022;Tou-
manysocietalandethicalconcernsareraisedre-
vron et al., 2023a). For instance, LLMs are now
gardingthebehaviorofLLMs.Oneoftheways
tocomprehendLLMs’behavioristoanalyze beingdeployedasvirtualassistantstoprovidemen-
theirpersonalities. Manyrecentstudiesquan- talhealthsupport(Laietal.,2023),asonlineedu-
tifyLLMs’personalitiesusingself-assessment catorsforcommonknowledgeretrieval(OpenAI,
tests that are created for humans. Yet many 2022;JeonandLee,2023),andevenashelpersin
critiques question the applicability and relia- symbolic music compositions (Agostinelli et al.,
bility of these self-assessment tests when ap-
2023;Imasatoetal.,2023). However,thisgrowing
plied to LLMs. In this paper, we investigate
integrationofLLMsacrossdifferentsocialsectors
LLMpersonalitiesusinganalternatepersonal-
ofhumanliferaisesimportantconcernsaboutrelia-
itymeasurementmethod,whichwerefertoas
theexternalevaluationmethod,whereinstead bility,safety,andethics. ThisdualnatureofLLMs
ofpromptingLLMswithmultiple-choiceques- openstheneedtostudytheirbehaviors,especially
tions in the Likert scale, we evaluate LLMs’ theirbehaviorswheninteractingwithhumans. Al-
personalities by analyzing their responses to- thoughmostchat-basedmodelsincludingChatGPT
ward open-ended situational questions using
(OpenAI,2022)andLlama(Touvronetal.,2023b)
anexternalmachinelearningmodel. Wefirst
haveundergonesafetytrainingtopreventdeliver-
fine-tuned a Llama2-7B model as the MBTI
ingpoisonousandbiasedinformation,thereisstill
personalitypredictorthatoutperformsthestate-
of-the-artmodelsasthetooltoanalyzeLLMs’ anurgentneedtofindapropervenueandmetrics
responses. Then, we prompt the LLMs with tounderstandtheirsocietalbehaviors.
situationalquestionsandaskthemtogenerate One common way to understand the behavior
Twitterpostsandcomments,respectively,inor- ofLLMsistomeasuretheirpersonalitiesthrough
dertoassesstheirpersonalitieswhenplaying
rigorouspsychometricstudies(Jiangetal.,2022;
twodifferentroles. Usingtheexternalperson-
Miottoetal.,2022;Huangetal.,2023;Caronand
ality evaluation method, we identify that the
Srivastava, 2022; Karra et al., 2022). According
obtainedpersonalitytypesforLLMsaresignif-
totheAmericanPsychologicalAssociation(APA),
icantlydifferentwhengeneratingpostsversus
comments,whereashumansshowaconsistent personality for humans is defined as “the endur-
personalityprofileinthesetwodifferentsitua- ing characteristic and behavior that comprise a
tions. ThisshowsthatLLMscanexhibitdiffer- person’s unique adjustment to life" (Association,
entpersonalitiesbasedondifferentscenarios, 2023). On the other hand, the exact definition of
thushighlightingafundamentaldifferencebe-
LLM personalities remains an open yet mysteri-
tweenpersonalityinLLMsandhumans. With
ous question in the field. Nevertheless, many re-
ourwork,wecallforare-evaluationofperson-
searchersmadeanalogiestohumanpersonalityand
alitydefinitionandmeasurementinLLMs.
attemptedtostudyLLMpersonalitiesbyleverag-
1 Introduction ing the psychometric tests used for humans. For
instance, most recent literature prompted LLMs
1 TheevolutionofLargeLanguageModels(LLM)
withstandardizedself-assessmentpersonalitytest
hasbenefitedhumansinthepastfewyearsthrough
questions and then recorded and analyzed the re-
1∗equalcontribution sults(Jiangetal.,2023;Karraetal.,2022;Miotto
4202
beF
22
]LC.sc[
1v50841.2042:viXraet al., 2022; Bodroza et al., 2023; Safdari et al., using our personality prediction model. We per-
2023). However, while these tests are shown to form this analysis for ChatGPT (OpenAI, 2022),
be effective for human personality measurement Llama2-7B-chat, Llama2-13B-chat and Llama2-
(Digman,1990),thereisevidencethattheycannot 70B-chat models (Touvron et al., 2023b). At the
bedirectlyappliedtoreliablymeasurepersonality sametime,wealsorepeatthesameprocedurefor
ofbothbaseLLMsincludingGPTs(Radfordetal., human-writtenpostsandcommentstovalidatethe
2018, 2019; Brown et al., 2020) and chat-based proposedpersonalitydetectionmodel. Tooursur-
LLMs like ChatGPT (OpenAI, 2022) and Llama prise, we find that the personality distribution of
(Touvron et al., 2023b). For instance, Song et al. LLMswhenwritingtweetsiscompletelydifferent
(2023) and Gupta et al. (2023) managed to show from the distribution when responding to tweets.
thattheself-assessmentpersonalitytestresultsof As defined by APA, personality is supposed to
thesameLLMdiffersignificantlyastheprompting beanenduringcharacteristicforhumans. While
templatesarechanged,whichisnotsurprisingas this consistency is shown to be true for humans,
LLMsareknowntobeproneandsensitivetodiffer- weshowthatLLMsexhibitdifferentpersonalities
entprompts(Sclaretal.,2023;Chenetal.,2023). whileplayingdifferentroles. (Sec. 3.2&Sec. 3.3).
However, it has also been shown that even under To summarize, our paper makes the following
the same prompt template, the psychometric test contributions:
resultsarestatisticallydifferentwhentheoptions
• Wefine-tuneaLlama2-7BforMBTIperson-
of those multiple-choice questions are presented
alitydetectionthatsignificantlyoutperforms
indifferentorders(Songetal.,2023;Guptaetal.,
thestate-of-the-artmodels.
2023). Theseobservationsindicatethatprompting
LLMs with standardized self-assessment is not a • We use the fine-tuned personality detection
reliable method to quantify LLMs’ personalities. modelontweetsmadebyhumansandshow
Therefore, an alternative to self-assessment psy- that human personality remains consistent
chometrictestsisdesiredtobetterunderstandand acrossdifferentroles.
analyzepersonalitiesinLLMs.
Inthispaper,weinvestigateanalternatemethod • WeshowthatLLMsexhibitdifferentperson-
tomeasureLLMpersonalities. Todoso,wefirst alities across different roles when using the
develop a state-of-the-art personality prediction externalevaluationmethod.
model. Specifically,weutilizedthefamousMyers-
• With our work, we call for a re-evaluation
BriggsTypeIndicator(MBTI)personalityframe-
ofpersonalitydefinitionandmeasurementin
workandfine-tunedaLlama2-7B(Touvronetal.,
LLMs.
2023b)modelonahumanpersonalitydataset. The
dataset contains multiple posts written by a hu- 2 RelatedWork
mansubjectandtheirMBTIpersonalitytype. This
2.1 PersonalityTheory
model is then used to analyze the personality of
LLMs under the MBTI framework and compare Human personality is defined as “the enduring
theresultswithhumancounterparts. (Sec. 3.1) characteristic and behavior that comprise a per-
TomeasureLLMpersonality,wehavedifferent son’suniqueadjustmenttolife"byAPA(Associa-
LLMswritetweetswhichareusedasinputforour tion,2023),whichistypicallymeasuredacrossdif-
personalitypredictionmodel. Whiledoingthis,we ferenteffectivetraitdimensions(Cattell,1943b,a).
have LLMs take two different roles. In the first Central to human psychological profiling are the
role,theLLMisaskedtowritetweetsaboutreal- Big Five personality traits, also referred to as
worldeventsbasedontheeventtopicswhichwere the OCEAN traits, which stands for Openness,
obtainedbyanalyzingnewsarticles. Thisisdone Conscientiousness, Extraversion, Agreeableness,
topreventdataleakageandstopLLMsfromrepeat- and Neuroticism, respectively (Digman, 1990;
ingtweetsseenpreviouslyinpre-trainingdata. In Goldberg, 1990, 1993). The Big Five personal-
thesecondrole,weasktheLLMtowriterepliesto itytraitsaretypicallymeasuredthroughmultiple
existingtweets. Thetweetsareagaincollectedin choice self-assessment questions where a situa-
realtimeandarenotpartofthemodelpre-training tional statement is presented and the test-takers
corpus. Wethenevaluatethepersonalityofdiffer- are requested to choose from an option in Likert
entLLMsbasedonthetweetsgeneratedbythem scales, typically 1 to 5, to reflect the degree ofdifferentpersonalitiesondifferentself-assessment
tests,whichfailstoachievethecrucialconsistency
criterioninpersonalitydefinitionandhighlightsthe
invalidityofself-assessmenttests. Theoriginsof
theseconcernsarerelatedtoboththedifficultyof
MCQAtasksandthefactthatLLMsaresensitive
to the change in prompts as well as the structure
oftheprompts. Awell-knownexampleofthisis
that the LLMs can be manipulated logically via
Chain-of-Thoughts(CoT)(Weietal.,2022).
Tothebestofourknowledge,thereisnotmuch
literaturethatattemptstoevaluateLLMpersonality
without leveraging standardized tests. Driven by
Figure1: MBTItraitdescription(Faust,2019).
this gap, in this work, we attempt to completely
discard self-assessment tests and use an external
fitness of the statement to themselves (Johnson, personality assessment method, where a person-
2014). ManystudiesonLLMpersonalitydirectly alitydetectionmodelisusedtopredictLLMper-
basetheirworksonthisstraightforwardtest(Jiang sonality. In addition, unlike previous works that
etal.,2023;Songetal.,2023;CaronandSrivastava, conducttestswithoutvalidation,wealsojustifythe
2022). personality prediction model used for evaluation
However,theresultofthistestisadistribution byconductingavalidationexperimentonhumans.
ofscoresamongallfivetraits, makingitdifficult
to analyze and compare. Instead, we build our 2.3 MBTIPersonalityDetectionModels
paper on another famous categorical personality MostMBTIpersonalitydetectionmodelsarebuilt
framework called the Myers-Briggs Type Indica- based on the public Kaggle dataset2 (Tang et al.,
tor(MBTI),whichdetails16distincttypesbased 2023;Yangetal.,2023;Mehta,2023). Thedataset
ontraitcombinationsacrossfourdifferentdimen- consistsofover8600entries,whereeachentrycor-
sions: Extraverts vs. Introverts (E/I), Sensors vs. respondstoanindividual’sMBTItypeandincludes
Intuitives (S/I), Thinkers vs. Feelers (T/F), and excerptsfromthelast50postsandcommentsmade
Judegersvs. Perceivers(J/P).Figure 1abovepro- by the individual on the PersonalityCafe forum3.
videsdetailedinformationaboutthetraiteachdi- Detailed introduction to example entry, label dis-
mensionmeasures. tribution,andthetweettopicdistributionscanbe
foundinAppendixA.1.
2.2 LLMPersonalityMeasurement
To predict MBTI personality types from texts,
Many recent works regarding LLM personal- Mehta (2023) processed the texts using a BERT
ity asked the LLM to perform Multiple-Choice model (Devlin et al., 2018) and then trained an
Question-Answering (MCQA) on those well- MLPtopredicttheMBTIpersonalitytype,while
known standardized self-assessment personality Yang et al. (2023) utilized a graph convolutional
tests(Jiangetal.,2023;Miottoetal.,2022;Caron neural network to learn the connections between
andSrivastava,2022;Huangetal.,2023;Bodroza different posts made by an individual in order
et al., 2023; Safdari et al., 2023; Pan and Zeng, to make decent predictions. Furthermore, Tang
2023;NoeverandHyams,2023). Forinstance,as et al. (2023) proposed an attention-based denois-
one of the foundation works, Jiang et al. (2023) ingframework(ADF)forMBTIpersonalitydetec-
promptedtheLLMswiththewidely-usedIPIP-120 tion, where they trained the model to effectively
datasetinpsychology(Johnson,2014)andevalu- extractpersonalitysignalsfromnoisyandverbose
ated their Big Five scores (i.e. OCEAN scores). textdata. However,acommonweaknessinthese
However,althoughtheseworksmanagedtoelab- worksisthattheirmethodspredictthepersonality
orateonhowpersonalitycanplayaroleinLLMs, typeforeachMBTIdimensionseparately. There-
thevalidityoftheseself-assessmenttestsremains fore, although their methods achieve an average
unchecked, making their conclusions unreliable.
2https://www.kaggle.com/datasets/datasnaek/mbti-type
As shown by Song et al. (2023) and Gupta et al.
3https://www.personalitycafe.com/forums/myers-briggs-
(2023),thesameLLMtendstoexhibitsignificantly forum.49/of around 70% prediction accuracy for each trait the16-classesmodel,apre-trainedLlama2-7Bis
dimension,theoverallperformanceremainsmyste- directly fine-tuned to predict one of the sixteen
riouswhenthepredictionsforeachdimensionare classes. AligningwiththeKaggledatasetformat,
aggregatedtogetherbecausetheerrorsanduncer- both models take 50 posts from an individual as
taintiesaccumulatemultiplicatively. Inourmethod, inputs at a time to predict personality. The fine-
we fine-tuned the popular Llama2-7B (Touvron tuningprocesswasconductedundertheLoRA(Hu
etal.,2023b)modelasthepredictor,whichoutper- etal.,2021)framework,wherethetargetmodules
formedtheirmodelssignificantly. to fine-tune are the query (q) and the value (v)
layers. We chose the rank to be r = 16 and fine-
3 Experiments tuned it for only 5 epochs with a learning rate of
10−4andbatchsizeof8. Thetrainingstartedwitha
In this paper, we refer to using personality pre-
warm-upphaseforthefirst100iterations,followed
dictionmodeltomeasurepersonalityasanexter-
byalinearlearningratedecay.
nalpersonalityevaluationmethod,juxtaposingit
withthepersonalityself-assessmentmethods. The Models Accuracy F1score Precision Recall
BERT-Base+MLP
experiments on the proposed external evaluation 73.1 63.2 78.0 65.5
(Mehta,2023)
method are divided into three stages. Firstly, a D-DGCN
78.2 53.5 60.5 49.1
Llama2-7B(Touvronetal.,2023b)modelisfine- (Yangetal.,2023)
ADF
tunedonthepublicMBTIdatasetsasthepersonal- 61.0 38.8 47.5 56.8
(Tangetal.,2023)
itydetectionmodel. Then,toperformexternaleval- Llama2-7B+FT(B)
93.3 91.1 92.3 90.1
uations,wepromptedtheLLMswithpre-processed (ours)
Llama2-7B+FT(16)
situationalquestions/scenariosandpromptedthem 93.5 91.4 92.0 90.8
(ours)
foropen-endedgenerationsbasedontheinput. Fi-
Table1: Averageperformanceofpersonalitydetection
nally,thecollectedresponsesfromtheLLMswere
models on each of the four MBTI dimensions. Each
fedintothepersonalitydetectionmodeltoobtain
cellisanumericalaverageoftheperformanceofeach
theevaluationresults. Inthispaper,webaseourex-
binarymodelinpercentage.
perimentsonfourpopularchat-basedLLMs: Chat-
GPT(OpenAI,2022)andthreeversionsofLlama2
(7B,13B&70B)(Touvronetal.,2023b). Theover- Models Accuracy F1score Precision Recall
BERT-Base+MLP
all experiment pipeline can be found in Figure 2. 29.4 8.70 14.1 12.0
(Mehta,2023)
Inaddition,thecomputationalresourcesusedare D-DGCN
37.6 35.9 35.9 37.6
introducedinAppendixA.2. (Yangetal.,2023)
ADF
14.0 4.10 3.28 5.74
(Tangetal.,2023)
3.1 StageI:Fine-tuningLlama2-7B-based Llama2-7B+FT(B)
81.0 74.3 76.9 73.1
PersonalityDetectionModel (ours)
Llama2-7B+FT(16)
81.7 76.9 79.8 75.2
In this work, we utilized the widely used afore- (ours)
mentioned Kaggle MBTI dataset to fine-tune the
Table2: Performanceofpersonalitydetectionmodels
personalitydetectionmodel. Althoughmanyprevi-
on16-classMBTIpredictiontasks. Thenumbersinthe
ousstudiesbuildtheirmodelsonthesamedataset cellareallpercentages.
(Yangetal.,2023;Tangetal.,2023;Mehta,2023),
there is room for improvement in the overall per- Thetestingperformanceoftheproposedperson-
formance of their models, which may affect the alitydetectionmodelandthebaselinesarereported.
reliabilityofpersonalityprediction. With the capacities of LLMs to understand texts
In particular, we proposed two models: (1) a andextractkeyknowledge,boththefine-tunedbi-
binary model and (2) a 16-class model. In terms narymodeland16-classesmodeloutperformthe
ofthebinarymodel,wefine-tunedfourpre-trained state-of-the-artmodelssignificantlyinallmetrics.
Llama2-7Bmodels,andeachofthemisdesigned InTable1,wereporttheaverageperformanceof
tobeabinaryclassifierforeachofthefourMBTI themodelforeachtraitdimension. Todothis,the
dimensions. Thepredictionsarethenaggregatedto accuracy of the model in predicting each of the
formthefinalprediction,whichissimilartomost fourdimensionsofMBTIpersonalityiscalculated
of the previous works (Tang et al., 2023; Yang separately. Thentheaccuracyforthesefourdimen-
etal.,2023;Mehta,2023). Ontheotherhand, in sionsisaveragedtopresentthenumbersinTable1,Figure2: Methodologyflowchart.
whichisthemostcommonformofevaluationused personalitypredictionmodel.
inpriorwork(Tangetal.,2023;Yangetal.,2023). PromptingPipeline. Toeffectivelyanalyzedaily
One drawback of such an evaluation is that it news,promptLLMs,andprocesstheirresponses,
doesn’t take into account the overall accuracy of we designed a prompting pipeline. The pipeline
the model in predicting one of the 16 classes of startsbyanalyzingnewsfromdifferenttopicsand
personality. In Table 2, we take into account the summarizingthemintothelatestnewseventsbe-
overallpredictionerrorsandpresenttheaggregated forepromptingtheLLMs. Weanalyzedthelatest
16-classclassificationperformance. Thedifference news articles from November 2023 to make sure
in performance between Table 1 and Table 2 for thattheeventswerenotpresentinthetrainingdata
thesamemodelshighlightstheeffectivenessofour ofthepersonalitypredictionmodels. Theselatest
model. For instance, while the baseline methods news events serve as the basis for prompting the
achievearound70%accuracywhenaveragedover LLMstogeneratetweets,withtheLLMstakingon
eachtrait,whenthosepredictionsareaggregatedto- theroleofindividualspostingtweetsaboutthese
gethertopredicttheactual16-classesMBTItype, news events. Additionally, we also gather online
the accuracy drops significantly to around 30%. tweetswrittenbyotherindividualsandpromptthe
However,forourfine-tunedbinarymodel,thepre- LLMstogeneratecommentsinresponsetothese
dictionaccuracyforeachtraitis93.3%whilethe tweets. This allows the LLMs to assume differ-
overall accuracy remains as high as 81.0%. This ent roles, specifically that of replying to tweets
evaluationmethodhelpshighlighterroraccumula- madebyothers. Topreventanypotentialdataleak-
tion during the personality evaluation procedure, age,thesetweetsarecollectedexclusivelyfromthe
renderingtheexperimentalresultsmoreaccurate. monthofNovember2023.
Weobservedthatthebinarymodeland16-classes Depending on whether we want the LLMs to
modelyieldcomparableperformancefornearlyall write posts (i.e. tweets) about the summarized
themetrics. Inlaterexperiments,wechosetostick events or comments (i.e. replies) to the existing
tothebinarymodelasitisoftenusedinprevious tweets, thepromptingtemplatesarechosentobe
works(Tangetal.,2023;Yangetal.,2023;Mehta, different accordingly. For instance, the template
2023),makingtheresultscomparable. Complete forpromptingLLMstowriteapostisthefollow-
resultsforfine-tunedmodelscanbefoundinAp- ing: “As a user on Twitter. Write a tweet on the
pendixA.3. followingcontents: [summarized contents]”. It
is noteworthy that we chose not to engineer the
3.2 StageII:CollectingLLMsResponses
promptingtemplatesinordertokeepthemassim-
TowardOpen-endedSituationalQuestions
ple as possible, so as to not induce behavior of
Inthesecondstage,wepromptLLMswithopen- LLMs. The exact prompts used in this work are
ended situational questions and collect their re- shown in Table 3. We use the simplest prompts
sponses as inputs for external evaluation. This is toelicitgenerationinordertonotbiasthemodel
done to collect social media post data generated throughpromptsforgenerations.
by an LLM which can be used as input for our Intotal,weanalyzedseveralthousandnewsarti-Type SystemPromptUsed UserPromptUsed
Posts Generate a Twitter post As a user on Twitter, write a tweet on the following
contents: [summarized contents]
Comments Generate a Twitter comment As a user on Twitter, write a tweet to comment on this
Tweet: [tweet contents]
Table3: Promptingtemplates.
Figure3: MBTIdistributionofChatGPTandLlama2modelsusingexternalevaluationmethodfor100times. Inthe
figure,thefirstrowistheassessmentresultsonthegeneratedpostsdataset(P),whereasthesecondrowprovidesthe
resultsonthecommentsdataset(C).Inaddition,personalitytypesthatappearlessthan3timesaremergedtogether
toformtheclass“Others”.
clestoextractrelevantnewseventsandcollected duetosamplingandmodelinaccuracy,wecreated
5000tweetsfrom10populartopics. Subsequently, 100 sets of 50 generations for each type of tweet
we tasked the LLMs with generating 4500 posts (posts vs. comments) generated by the LLM. To
based on the news events and 5000 comments in doso,wesampled50responseswithreplacements
responsetothecollectedtweets. Thesegenerated from our generation dataset 100 times. We then
textswerethenutilizedtostudythepersonalitiesof reportthepredictedMBTIpersonalitydistribution
theLLMsusingourpersonalitydetectionmodel. It forthe100samplesforeachroleinFigure3and
isworthnotingthattherolesassignedtotheLLMs themostfrequentpersonalitytypeforeachLLMis
varied depending on whether they were asked to reportedasthepredictedpersonalityinTable4.
generatepostsorcomments,allowingforadiverse
rangeofresponses. Adetaileddescriptionofthis ExternalEvaluation
Model
pipelineanddownloadedcontentscanbefoundin Posts Comments
ChatGPT INFJ INFJ
AppendixA.4.
Llama2-7B ESTJ INFP
Llama2-13B ESTJ INFP
3.3 StageIII:ExternalLLMsPersonality Llama2-70B ESTJ INFJ
Detection&Validation
Table 4: MBTI personality type obtained by external
After obtaining the posts and comments datasets evaluationmethod. ThemostfrequentMBTIpersonal-
foreachLLMofinterest,weevaluatetheirperson- itytypeisreportedhere.
alities using our fine-tuned personality detection
model. Thepersonalitydetectionmodelistrained WecanobservefromTable4thatforthesame
to take 50 social media posts of a user as input LLM,theexternalevaluationresultsonthegener-
andoutputtheirpersonalitybasedonthe16-class atedpostsandcommentsdatasetsareverydiffer-
MBTIpersonalityframework. Tominimizeerrors ent. Forinstance,forLlama2-7B,themostfrequentFigure4: MBTIdistributionof4celebritiesusingtheexternalevaluationmethodfor100times. Inthefigure,the
firstrowistheassessmentresultsonthegeneratedpostsdataset(P),whereasthesecondrowprovidestheresultson
thecommentsdataset(C).Inaddition,personalitytypesthatappearlessthan3timesaremergedtogethertoform
theclass“Others”. Completeresultsforall8selectedcelebritiescanbefoundinAppendixA.5.
MBTItypeisESTJwhenitpoststweets,whereas evaluateLLMpersonality,itbecomesimportantto
it is INFP on the generated comments. In addi- checkifthedetectionmodelisabletoproducesim-
tion,thepredictedpersonalitydistributionsforthe ilarpersonalitydistributionswhenhumanstakeon
100 trials in Figure 3 are also significantly differ- thetworolesofwritingpostsversuscomments. If
ent between posts and comments. For example, thisisnotthecase,thentheinconsistenciesinLLM
in ChatGPT personality evaluation, although the personalities in the two roles can be attributed to
most frequent MBTI type is the same in Table 4 thepersonalitydetectionmodel. Furthermore,this
between posts and comments, the predicted per- iscrucialtojustifythecorrectnessofourlateranal-
sonality distributions are extremely different, as ysis,whichiscompletelybasedonthispersonality
canbeseeninthefirstcolumnofpiechartsinFig- detectionmodel.
ure 3. We can see that INFJ and INFP are nearly Tocheckthis,weconductthesamestudywith
equally distributed when writing posts, whereas human counterparts. We randomly downloaded
INFJ dominates over all other MBTI types when theTwitterpostsandcommentsfrom8celebrities4
writing comments. In plain words, this indicates fromdifferentdomainsandappliedthepersonality
ChatGPT behaves very differently when generat- detectionmodeltothesetwodifferentdatasets. We
ing posts and comments. We can see this very again created 100 samples of 50 tweets each and
clearly for the other Llama2 models, where the foundthepersonalitydistributionforthesecelebri-
personality distribution while writing posts (first tiesinthetwodifferentroles-whilewritingposts
rowofpiechartsinFigure3)isverydifferentfrom versuscomments. Thepersonalitydistributionre-
the personality distribution we get when writing sults for four celebrities can be seen in Figure 4,
comments(secondrowinFigure3). Theseexperi- whiletheremainingfourcanbeseeninFigure5.
mentsclearlyshowthatLLMsexhibitdifferent Table5presentstheresultsfortheeightcelebri-
personalitieswhenplayingdifferentroles. ties. WecanseethatthemostfrequentMBTItype,
thesecondmostfrequentMBTItype,andeventhe
Validation with Human Counterpart. Person-
predicteddistributions(Figure4)areveryakinto
ality is defined as an enduring characteristic in
eachotherfornearlyallthecelebritiesthatwein-
humans by the American Psychological Associa-
vestigated. Thisempiricallyconfirmsthathumans
tion. This means that for humans, the personal-
tend to exhibit enduring MBTI personality types
itydistributionobtainedforhumanswhenwriting
postsversuscommentsisexpectedtobeconsistent.
4Duetoproprietaryreasons,wehavemaskedtheidentities
Asweemployedapersonalitydetectionmodelto oftheselectedcelebrities.ExternalEvaluation works have shown that self-assessment tests are
Celebrity
P C
nottheappropriatetooltomeasurepersonalityin
CelebrityI INTJ(INFJ) INTJ(INFJ)
LLMs. Whenwe combine ourobservations with
CelebrityII INFJ(ENFJ) INFJ(ENFJ)
CelebrityIII INFJ(ENFJ) INFJ(ENFJ) theseresults,wecanconcludethatnotonlydowe
CelebrityIV INFJ(ENFJ) INFJ(ENFJ) nothaveaccuratetoolstomeasureLLMpersonal-
CelebrityV INFJ(INFP) INFJ(INFP) ity, but we also lack the appropriate definition of
CelebrityVI INFJ(INTJ) ENTJ(ENFJ)
personalityforLLMs. Withourwork,wecaution
CelebrityVII INFJ(INFP) INFJ(INFP)
againstanaivetransferofdefinitionandmethods
CelebrityVIII INFJ(ISFJ) INFJ(ENFJ)
usedtoanalyzehumanpersonalityonLLMsand
Table5: ThemostfrequentMBTIpersonalitytypefor callformorefundamentalworkonevaluatingLLM
8 celebrities under external evaluation method using
personality and behavior, taking into account the
postsandcomments. ThesecondmostfrequentMBTI
specificcharacteristicsofLLMs.
personalitytypeisreportedintheparenthesis.
5 Limitation
even when playing different roles, which echoes
Thispaperinvestigatesthevalidityofapplyingex-
theobservationsinmostofthepsychologylitera-
ternalevaluationtomeasuringLLMpersonalities
ture(Greenetal.,2019;Association,2023)aswell
and calls for a re-evaluation of the definition and
asthepersonalitydefinition(AmericanPsycholog-
measurement of LLM personalities. As we em-
ical Association, 1983). A detailed introduction
ployedafine-tunedmodelasanexternalagentto
tothisvalidationexperimentcanbefoundinAp-
evaluatepersonalitiesandbasedouranalysisonit,
pendixA.5. Simultaneously,thisconfirmsthatour
oneofthelimitationsofourworkistheaccuracy
fine-tunedmodelisabletoattainsimilarpersonal-
ofthepersonalitydetectionmodel. Althoughour
itydistributionsforhumansandrulesoutitseffects
modelattainsstate-of-the-artperformanceandwe
intheobservedinconsistencyinLLMs.
reducethechancesoferrorsbyusing100samples
TheaboveexperimentsshowthatLLMsclearly
ofgenerationsinsteadof1,theuncertaintiesintro-
exhibit different personalities in different roles,
ducedduetoerrorratesarestillinevitable. Further-
which is not true for humans. Our experiments
more,althoughourworkidentifiesthatthecurrent
alsoshowthatthedefinitionofpersonalityasde-
definition of LLM personality should be reevalu-
finedforhumansmaynotbeapplicabletoLLMs,
ated,thispaperdoesnotprovideanalternativefor
aspersonalityinLLMsnolongerseemstobean
defining LLM personality and the measurement
enduringcharacteristic.
method,whichareleftforfuturework.
4 Conclusions 6 Acknowledgement
In this paper, we investigate the personality ex- Thispaperwaspreparedforinformationpurposes
hibited by LLMs using an external personality by the Artificial Intelligence Research group of
evaluationmethod,whichisanalternativetoself- JPMorganChase&Coanditsaffiliates(“JPMor-
assessmenttestsforpersonalitymeasurement. To gan”), and is not a product of the Research De-
perform external personality evaluation, we fine- partment of JP Morgan. J.P. Morgan makes no
tunedaLlama2-7Bmodelasthethird-partyagent representation and warranty whatsoever and dis-
forpersonalitydetectionandcollectedLLMs’re- claimsallliabilityforthecompleteness,accuracy
sponses and attitudes toward open-ended situa- or reliability of the information contained herein.
tional questions. We also developed a prompt- This document is not intended as investment re-
ing pipeline to automate the prompts for LLMs searchorinvestmentadvice,orarecommendation,
with proper content. Our experiments show that offerorsolicitationforthepurchaseorsaleofany
LLMs exhibit different personalities in different security,financialinstrument,financialproductor
roles,whichisnottrueforhumans. service,ortobeusedinanywayforevaluatingthe
Theseobservationsalsoshedlightonthevalidity meritsofparticipatinginanytransaction,andshall
ofquantifyinganddefiningLLMpersonalityusing notconstituteasolicitationunderanyjurisdiction
thesamestandardforhumans. Inourwork,wesee ortoanyperson,ifsuchsolicitationundersuchju-
thatLLMpersonalityisnotanenduringcharacter- risdictionortosuchpersonwouldbeunlawful. ©
isticasitisseeninhumans. Additionally,previous 2023JPMorganChase&Co. Allrightsreserved.References JenniferPGreen,ReeshadSDalal,KristenLSwigart,
MelissaABleiberg,DavidMWallace,andAmberK
Andrea Agostinelli, Timo I Denk, Zalán Borsos,
Hargrove.2019. Personalityconsistencyandsitua-
Jesse Engel, Mauro Verzetti, Antoine Caillon,
tional influences on behavior. Journal of Manage-
QingqingHuang,ArenJansen,AdamRoberts,Marco
ment,45(8):3204–3234.
Tagliasacchi,etal.2023. Musiclm: Generatingmu-
sicfromtext. arXivpreprintarXiv:2301.11325.
Akshat Gupta, Xiaoyang Song, and Gopala Anu-
manchipalli. 2023. Investigating the applicability
American Psychological Association. 1983. Publica-
of self-assessment tests for personality measure-
tionsManual. AmericanPsychologicalAssociation,
ment of large language models. arXiv preprint
Washington,DC.
arXiv:2309.08163.
AmericanPsychologicalAssociation.2023. Definition
AriHoltzman,JanBuys,LiDu,MaxwellForbes,and
of Personality - https://www.apa.org/topics/
Yejin Choi. 2019. The curious case of neural text
personality.
degeneration. arXivpreprintarXiv:1904.09751.
Bojana Bodroza, Bojana M Dinic, and Ljubisa Bojic.
2023. Personalitytestingofgpt-3: Limitedtemporal Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan
reliability,buthighlightedsocialdesirabilityofgpt- Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,
3’s personality instruments results. arXiv preprint and Weizhu Chen. 2021. Lora: Low-rank adap-
arXiv:2306.04308. tation of large language models. arXiv preprint
arXiv:2106.09685.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind Jen-tseHuang,WenxuanWang,ManHoLam,EricJohn
Neelakantan,PranavShyam,GirishSastry,Amanda Li,WenxiangJiao,andMichaelRLyu.2023. Chat-
Askell,etal.2020. Languagemodelsarefew-shot gpt an enfj, bard an istj: Empirical study on per-
learners. Advancesinneuralinformationprocessing sonalitiesoflargelanguagemodels. arXivpreprint
systems,33:1877–1901. arXiv:2305.19926.
GrahamCaronandShashankSrivastava.2022. Identi- NaomiImasato,KazukiMiyazawa,CaitlinDuncan,and
fyingandmanipulatingthepersonalitytraitsoflan- TakayukiNagai.2023. Usingalanguagemodelto
guagemodels. arXivpreprintarXiv:2212.10276. generatemusicinitssymbolicdomainwhilecontrol-
lingitsperceivedemotion. IEEEAccess.
RaymondBCattell.1943a. Thedescriptionofperson-
ality: Basictraitsresolvedintoclusters. Thejournal JaehoJeonandSeongyongLee.2023. Largelanguage
ofabnormalandsocialpsychology,38(4):476. modelsineducation: Afocusonthecomplementary
relationship between human teachers and chatgpt.
RaymondBCattell.1943b. Thedescriptionofperson- EducationandInformationTechnologies, pages1–
ality.i.foundationsoftraitmeasurement. Psycholog- 20.
icalreview,50(6):559.
GuangyuanJiang, ManjieXu, Song-ChunZhu, Wen-
Banghao Chen, Zhaofeng Zhang, Nicolas Langrené,
juan Han, Chi Zhang, and Yixin Zhu. 2022. Mpi:
andShengxinZhu.2023. Unleashingthepotentialof
Evaluating and inducing personality in pre-trained
promptengineeringinlargelanguagemodels: acom-
languagemodels. arXivpreprintarXiv:2206.07550.
prehensivereview. arXivpreprintarXiv:2310.14735.
GuangyuanJiang, ManjieXu, Song-ChunZhu, Wen-
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
juanHan,ChiZhang,andYixinZhu.2023. Evaluat-
KristinaToutanova.2018. Bert: Pre-trainingofdeep
ingandinducingpersonalityinpre-trainedlanguage
bidirectionaltransformersforlanguageunderstand-
models.
ing. arXivpreprintarXiv:1810.04805.
JohnAJohnson.2014. Measuringthirtyfacetsofthe
John M Digman. 1990. Personality structure: Emer-
fivefactormodelwitha120-itempublicdomainin-
gence of the five-factor model. Annual review of
ventory: Developmentoftheipip-neo-120. Journal
psychology,41(1):417–440.
ofresearchinpersonality,51:78–89.
Katrina Faust. 2019. Myers-briggs type indicator
(mbti)overview-https://leadx.org/articles/ SakethReddyKarra,ThejaTulabandhula,etal.2022.
mbti-myers-briggs-type-indicator-overview/. Estimating the personality of white-box language
models. arXive-prints,pagesarXiv–2204.
LewisRGoldberg.1990. Analternative"descriptionof
personality": thebig-fivefactorstructure. Journalof Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu,
personalityandsocialpsychology,59(6):1216. Yichao Dou, and Ziqi Wang. 2023. Psy-llm: Scal-
ingupglobalmentalhealthpsychologicalservices
LewisRGoldberg.1993. Thestructureofphenotypic withai-basedlargelanguagemodels. arXivpreprint
personalitytraits. Americanpsychologist,48(1):26. arXiv:2307.11991.Yash Mehta. 2023. Personality predic- Qirui Tang, Wenkang Jiang, Yihua Du, and Lei Lin.
tion. https://github.com/yashsmehta/ 2023. Anattention-baseddenoisingframeworkfor
personality-prediction.git. GitHub reposi- personality detection in social media texts. arXiv
tory. preprintarXiv:2311.09945.
YashMehta,SaminFatehi,AmirmohammadKazameini, Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
ClemensStachl,ErikCambria,andSaulehEetemadi. bert, Amjad Almahairi, Yasmine Babaei, Nikolay
2020. Bottom-upandtop-down: Predictingperson- Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
alitywithpsycholinguisticandlanguagemodelfea- Bhosale, et al. 2023a. Llama 2: Open founda-
tures. In 2020 IEEE International Conference on tion and fine-tuned chat models. arXiv preprint
DataMining(ICDM),pages1184–1189.IEEE. arXiv:2307.09288.
Marilù Miotto, Nicola Rossberg, and Bennett Klein- Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
berg. 2022. Who is gpt-3? an exploration of per- bert, Amjad Almahairi, Yasmine Babaei, Nikolay
sonality, values and demographics. arXiv preprint Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
arXiv:2209.14338. Bhosale, et al. 2023b. Llama 2: Open founda-
tion and fine-tuned chat models. arXiv preprint
David Noever and Sam Hyams. 2023. Ai text-to- arXiv:2307.09288.
behavior: A study in steerability. arXiv preprint
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
arXiv:2308.07326.
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
OpenAI.2022. Chatgpt-https://openai.com/blog/ etal.2022. Chain-of-thoughtpromptingelicitsrea-
chatgpt#OpenAI. soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems,35:24824–24837.
OpenAI.2023. Gpt-4technicalreport-https://cdn.
T.Yang,J.Deng,X.Quan,andQ.Wang.2023. Orders
openai.com/papers/gpt-4.pdf.
are unwanted: Dynamic deep graph convolutional
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida, network for personality detection. In Proceedings
CarrollWainwright,PamelaMishkin,ChongZhang,
of the AAAI Conference on Artificial Intelligence,
SandhiniAgarwal,KatarinaSlama,AlexRay,etal. volume37,pages13896–13904.
2022. Training languagemodelsto followinstruc-
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
tions with human feedback. Advances in Neural
Artetxe,MoyaChen,ShuohuiChen,ChristopherDe-
InformationProcessingSystems,35:27730–27744.
wan,MonaDiab,XianLi,XiVictoriaLin,etal.2022.
Opt: Openpre-trainedtransformerlanguagemodels.
KeyuPanandYawenZeng.2023. Dollmspossessa
arXivpreprintarXiv:2205.01068.
personality? makingthembtitestanamazingeval-
uation for large language models. arXiv preprint
arXiv:2307.16180.
AlecRadford,KarthikNarasimhan,TimSalimans,Ilya
Sutskever, et al. 2018. Improving language under-
standingbygenerativepre-training.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,
DarioAmodei,IlyaSutskever,etal.2019. Language
modelsareunsupervisedmultitasklearners. OpenAI
blog,1(8):9.
MustafaSafdari,GregSerapio-García,ClémentCrepy,
Stephen Fitz, Peter Romero, Luning Sun, Marwa
Abdulhai,AleksandraFaust,andMajaMataric´.2023.
Personality traits in large language models. arXiv
preprintarXiv:2307.00184.
MelanieSclar,YejinChoi,YuliaTsvetkov,andAlane
Suhr.2023. Quantifyinglanguagemodels’sensitiv-
itytospuriousfeaturesinpromptdesignor: Howi
learned to start worrying about prompt formatting.
arXivpreprintarXiv:2310.11324.
XiaoyangSong,AkshatGupta,KiyanMohebbizadeh,
ShujieHu,andAnantSingh.2023. Havelargelan-
guagemodelsdevelopedapersonality?: Applicabil-
ityofself-assessmenttestsinmeasuringpersonality
inllms. arXivpreprintarXiv:2305.14693.A Appendix Metrics E/I N/S T/F P/J Average
Accuracy(%) 93.09 96.31 93.55 90.90 93.46
A.1 KaggleMBTIDataset F1(%) 89.49 92.10 93.50 90.29 91.35
Precision(%) 90.33 93.37 93.65 90.64 92.00
ThepublicKaggleMBTIdatasetiscomprisedof
Recall(%) 88.71 90.93 93.40 89.99 90.76
8675entries,eachcorrespondingtoanindividual’s
MBTItype. Inparticular,everydataentryincludes Table7: Performanceofpersonalitydetectionmodels
excerptsfromthelast50postsorcommentsmade oneachofthefourMBTIdimensionsforthe16-class
model. Notethatthenumbersarecalculatedbyextract-
by the individual on the PersonalityCafe forum,
ingeachdimensionfromthepredictions.
separatedbythespecialcharacter“|||”. Twoexam-
pledataentriesareprovidedinTable8. Notethat
thisdatasetisanonymousuponcreation. Fitness,Gaming,andTechnology,wheretheyare
nearlyevenlydistributed.
A.2 ComputationalResources
ThetemplatesthatweusedtogenerateTwitter
In this work, all the experiments are done with postsandcommentsareprovidedinTable3. Asfor
NvidiaRTXA6000GPU.Inparticular,wehosted theparametersforgeneration,weutilizedanucleus
Llama2-7B,Llama2-13B,andLlama2-70Bon1,2, sampling(Holtzmanetal.,2019)withthetemper-
and4GPUcards,respectively,whereLlama2-70B ature and top_p set to 0.2 and 0.95, respectively.
washostedinmixedprecisions. FortheChatGPT Inaddition,themaximumlengthofgeneratedcon-
experiment,wedirectlyuseOpenAIAPIs5.
tentsissetto200. Thesameconfigurationisused
forallLLMsthatweinvestigated.
A.3 FinetuningExperimentsDetails
Inthissection,wereporttheexperimentaldetails A.5 ValidationExperimentonHuman
andcompleteresultsforbothbinaryand16-class Counterpart
modelstoreproduceTable1. Forbaselinemodels, Inthevalidationexperiment, wedownloadedthe
asthemodelsaretrainedonthesamedataset,we public Twitter posts and comments made by 8
kindlyrefertheaudiencetotheoriginalpapersfor celebritiesfromdifferentdomainsandusethesame
theperformanceoftheirmodels(Yangetal.,2023; personalityevaluationprocedureaswhatwehave
Mehta et al., 2020; Tang et al., 2023). In partic- doneforLLMs. Specifically,wecreated100sam-
ular, in the fine-tuning experiments, the original pleswith50tweetsineachforeverycelebrityand
MBTIdatasetisdividedintotraining,evaluation, repeated the external evaluation method for 100
andheldouttestingsubsetsinan81:9:10ratio. Fur- times. The obtained MBTI distributions and the
thermore,forthebinarymodel,themodelforeach mostfrequentMBTItypesarereportedinFigure5
traitsharedthesamesetofhyperparameters. andTable5,respectively,wheretheresultsechothe
factinpsychologyliteraturewherepersonalityisa
Metrics E/I N/S T/F P/J Average
consistentcharacteristicforhumans(Association,
Accuracy(%) 94.01 96.08 92.97 89.98 93.26
F1(%) 90.57 91.48 92.91 89.38 91.09 2023;Greenetal.,2019).
Precision(%) 93.16 93.44 93.13 89.41 92.29
Recall(%) 88.57 89.76 92.78 89.36 90.10
Table6: Performanceofpersonalitydetectionmodels
on each of the four MBTI dimensions for the binary
model.
A.4 PromptingPipeline&DownloadedTopics
Inprinciple,wewanttofeedLLMswithreal-world
topics,andtweetsandcollecttheirresponsesand
attitudes toward them. We analyzed daily news
to obtain a list of real-world topics. In terms of
thetopicsfortweets,wedownloaded5000tweets
containing the following 10 different topics: Bit-
coin,NFL,Music,Oscars,Travel,Fashion,Food,
5https://platform.openai.com/Type Contents(50postsorcommentsonPersonalityCafe)
ENTP Iamfindingthelackofmeinthesepostsveryalarming|||This+LackofBalanceand
Hand-EyeCoordination.|||...
INTJ 2%stillmeansabout1/50people.I’veprobablyseen1-2otherstoday.Ineverunderstood
fascinationbyvirtueofrarity.|||Icollectshoes. IdosobecauseIlikestatusandnothing
communicatessuchathingasmuchasapairofJordans...
... ...
Table8: TwoexampledataentriesofthepublicKaggleMBTIdataset.
Figure5: MBTIdistributionof8selectedcelebritiesusingexternalevaluationmethodfor100times. Inthefigure,
thefirstrowistheassessmentresultsonthegeneratedpostsdataset(P),whereasthesecondrowprovidestheresults
onthecommentsdataset(C).Inaddition,personalitytypesthatappearlessthan3timesaremergedtogetherto
formtheclass“Others”.