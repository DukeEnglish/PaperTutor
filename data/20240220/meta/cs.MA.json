[
    {
        "title": "Nash Equilibrium and Learning Dynamics in Three-Player Matching $m$-Action Games",
        "authors": "Yuma FujimotoKaito AriuKenshi Abe",
        "links": "http://arxiv.org/abs/2402.10825v1",
        "entry_id": "http://arxiv.org/abs/2402.10825v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10825v1",
        "summary": "Learning in games discusses the processes where multiple players learn their\noptimal strategies through the repetition of game plays. The dynamics of\nlearning between two players in zero-sum games, such as matching pennies, where\ntheir benefits are competitive, have already been well analyzed. However, it is\nstill unexplored and challenging to analyze the dynamics of learning among\nthree players. In this study, we formulate a minimalistic game where three\nplayers compete to match their actions with one another. Although interaction\namong three players diversifies and complicates the Nash equilibria, we fully\nanalyze the equilibria. We also discuss the dynamics of learning based on some\nfamous algorithms categorized into Follow the Regularized Leader. From both\ntheoretical and experimental aspects, we characterize the dynamics by\ncategorizing three-player interactions into three forces to synchronize their\nactions, switch their actions rotationally, and seek competition.",
        "updated": "2024-02-16 16:54:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10825v1"
    },
    {
        "title": "Modelling crypto markets by multi-agent reinforcement learning",
        "authors": "Johann LussangeStefano VrizziStefano PalminteriBoris Gutkin",
        "links": "http://arxiv.org/abs/2402.10803v1",
        "entry_id": "http://arxiv.org/abs/2402.10803v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10803v1",
        "summary": "Building on a previous foundation work (Lussange et al. 2020), this study\nintroduces a multi-agent reinforcement learning (MARL) model simulating crypto\nmarkets, which is calibrated to the Binance's daily closing prices of $153$\ncryptocurrencies that were continuously traded between 2018 and 2022. Unlike\nprevious agent-based models (ABM) or multi-agent systems (MAS) which relied on\nzero-intelligence agents or single autonomous agent methodologies, our approach\nrelies on endowing agents with reinforcement learning (RL) techniques in order\nto model crypto markets. This integration is designed to emulate, with a\nbottom-up approach to complexity inference, both individual and collective\nagents, ensuring robustness in the recent volatile conditions of such markets\nand during the COVID-19 era. A key feature of our model also lies in the fact\nthat its autonomous agents perform asset price valuation based on two sources\nof information: the market prices themselves, and the approximation of the\ncrypto assets fundamental values beyond what those market prices are. Our MAS\ncalibration against real market data allows for an accurate emulation of crypto\nmarkets microstructure and probing key market behaviors, in both the bearish\nand bullish regimes of that particular time period.",
        "updated": "2024-02-16 16:28:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10803v1"
    },
    {
        "title": "Network Formation and Dynamics Among Multi-LLMs",
        "authors": "Marios PapachristouYuan Yuan",
        "links": "http://arxiv.org/abs/2402.10659v1",
        "entry_id": "http://arxiv.org/abs/2402.10659v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10659v1",
        "summary": "Social networks influence behaviors, preferences, and relationships and play\na crucial role in the dissemination of information and norms within human\nsocieties. As large language models (LLMs) increasingly integrate into social\nand professional environments, understanding their behavior within the context\nof social networks and interactions becomes essential. Our study analyzes the\nbehaviors of standard network structures and real-world networks to determine\nwhether the dynamics of multiple LLMs align with human social dynamics. We\nexplore various social network principles, including micro-level concepts such\nas preferential attachment, triadic closure, and homophily, as well as\nmacro-level concepts like community structure and the small-world phenomenon.\nOur findings suggest that LLMs demonstrate all these principles when they are\nprovided with network structures and asked about their preferences regarding\nnetwork formation. Furthermore, we investigate LLMs' decision-making based on\nreal-world networks to compare the strengths of these principles. Our results\nreveal that triadic closure and homophily have a stronger influence than\npreferential attachment and that LLMs substantially exceed random guessing in\nthe task of network formation predictions. Overall, our study contributes to\nthe development of socially aware LLMs by shedding light on LLMs' network\nformation behaviors and exploring their impacts on social dynamics and norms.",
        "updated": "2024-02-16 13:10:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10659v1"
    },
    {
        "title": "OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models",
        "authors": "Ali AhmadiTeshniziWenzhi GaoMadeleine Udell",
        "links": "http://arxiv.org/abs/2402.10172v1",
        "entry_id": "http://arxiv.org/abs/2402.10172v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10172v1",
        "summary": "Optimization problems are pervasive in sectors from manufacturing and\ndistribution to healthcare. However, most such problems are still solved\nheuristically by hand rather than optimally by state-of-the-art solvers because\nthe expertise required to formulate and solve these problems limits the\nwidespread adoption of optimization tools and techniques. This paper introduces\nOptiMUS, a Large Language Model (LLM)-based agent designed to formulate and\nsolve (mixed integer) linear programming problems from their natural language\ndescriptions. OptiMUS can develop mathematical models, write and debug solver\ncode, evaluate the generated solutions, and improve its model and code based on\nthese evaluations. OptiMUS utilizes a modular structure to process problems,\nallowing it to handle problems with long descriptions and complex data without\nlong prompts. Experiments demonstrate that OptiMUS outperforms existing\nstate-of-the-art methods on easy datasets by more than $20\\%$ and on hard\ndatasets (including a new dataset, NLP4LP, released with this paper that\nfeatures long and complex problems) by more than $30\\%$.",
        "updated": "2024-02-15 18:19:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10172v1"
    },
    {
        "title": "Identifying and modelling cognitive biases in mobility choices",
        "authors": "Chloe ConradCarole Adam",
        "links": "http://arxiv.org/abs/2402.09921v1",
        "entry_id": "http://arxiv.org/abs/2402.09921v1",
        "pdf_url": "http://arxiv.org/pdf/2402.09921v1",
        "summary": "This report presents results from an M1 internship dedicated to agent-based\nmodelling and simulation of daily mobility choices. This simulation is intended\nto be realistic enough to serve as a basis for a serious game about the\nmobility transition. In order to ensure this level of realism, we conducted a\nsurvey to measure if real mobility choices are made rationally, or how biased\nthey are. Results analysed here show that various biases could play a role in\ndecisions. We then propose an implementation in a GAMA agent-based simulation.",
        "updated": "2024-02-15 12:58:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.09921v1"
    }
]