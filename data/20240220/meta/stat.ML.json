[
    {
        "title": "The Price of Adaptivity in Stochastic Convex Optimization",
        "authors": "Yair CarmonOliver Hinder",
        "links": "http://arxiv.org/abs/2402.10898v1",
        "entry_id": "http://arxiv.org/abs/2402.10898v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10898v1",
        "summary": "We prove impossibility results for adaptivity in non-smooth stochastic convex\noptimization. Given a set of problem parameters we wish to adapt to, we define\na \"price of adaptivity\" (PoA) that, roughly speaking, measures the\nmultiplicative increase in suboptimality due to uncertainty in these\nparameters. When the initial distance to the optimum is unknown but a gradient\nnorm bound is known, we show that the PoA is at least logarithmic for expected\nsuboptimality, and double-logarithmic for median suboptimality. When there is\nuncertainty in both distance and gradient norm, we show that the PoA must be\npolynomial in the level of uncertainty. Our lower bounds nearly match existing\nupper bounds, and establish that there is no parameter-free lunch.",
        "updated": "2024-02-16 18:56:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10898v1"
    },
    {
        "title": "Trading off Consistency and Dimensionality of Convex Surrogates for the Mode",
        "authors": "Enrique NueveBo WaggonerDhamma KimparaJessie Finocchiaro",
        "links": "http://arxiv.org/abs/2402.10818v1",
        "entry_id": "http://arxiv.org/abs/2402.10818v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10818v1",
        "summary": "In multiclass classification over $n$ outcomes, the outcomes must be embedded\ninto the reals with dimension at least $n-1$ in order to design a consistent\nsurrogate loss that leads to the \"correct\" classification, regardless of the\ndata distribution. For large $n$, such as in information retrieval and\nstructured prediction tasks, optimizing a surrogate in $n-1$ dimensions is\noften intractable. We investigate ways to trade off surrogate loss dimension,\nthe number of problem instances, and restricting the region of consistency in\nthe simplex for multiclass classification. Following past work, we examine an\nintuitive embedding procedure that maps outcomes into the vertices of convex\npolytopes in a low-dimensional surrogate space. We show that full-dimensional\nsubsets of the simplex exist around each point mass distribution for which\nconsistency holds, but also, with less than $n-1$ dimensions, there exist\ndistributions for which a phenomenon called hallucination occurs, which is when\nthe optimal report under the surrogate loss is an outcome with zero\nprobability. Looking towards application, we derive a result to check if\nconsistency holds under a given polytope embedding and low-noise assumption,\nproviding insight into when to use a particular embedding. We provide examples\nof embedding $n = 2^{d}$ outcomes into the $d$-dimensional unit cube and $n =\nd!$ outcomes into the $d$-dimensional permutahedron under low-noise\nassumptions. Finally, we demonstrate that with multiple problem instances, we\ncan learn the mode with $\\frac{n}{2}$ dimensions over the whole simplex.",
        "updated": "2024-02-16 16:42:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10818v1"
    },
    {
        "title": "Double Duality: Variational Primal-Dual Policy Optimization for Constrained Reinforcement Learning",
        "authors": "Zihao LiBoyi LiuZhuoran YangZhaoran WangMengdi Wang",
        "links": "http://arxiv.org/abs/2402.10810v1",
        "entry_id": "http://arxiv.org/abs/2402.10810v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10810v1",
        "summary": "We study the Constrained Convex Markov Decision Process (MDP), where the goal\nis to minimize a convex functional of the visitation measure, subject to a\nconvex constraint. Designing algorithms for a constrained convex MDP faces\nseveral challenges, including (1) handling the large state space, (2) managing\nthe exploration/exploitation tradeoff, and (3) solving the constrained\noptimization where the objective and the constraint are both nonlinear\nfunctions of the visitation measure. In this work, we present a model-based\nalgorithm, Variational Primal-Dual Policy Optimization (VPDPO), in which\nLagrangian and Fenchel duality are implemented to reformulate the original\nconstrained problem into an unconstrained primal-dual optimization. Moreover,\nthe primal variables are updated by model-based value iteration following the\nprinciple of Optimism in the Face of Uncertainty (OFU), while the dual\nvariables are updated by gradient ascent. Moreover, by embedding the visitation\nmeasure into a finite-dimensional space, we can handle large state spaces by\nincorporating function approximation. Two notable examples are (1) Kernelized\nNonlinear Regulators and (2) Low-rank MDPs. We prove that with an optimistic\nplanning oracle, our algorithm achieves sublinear regret and constraint\nviolation in both cases and can attain the globally optimal policy of the\noriginal constrained problem.",
        "updated": "2024-02-16 16:35:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10810v1"
    },
    {
        "title": "BlackJAX: Composable Bayesian inference in JAX",
        "authors": "Alberto CabezasAdrien CorenflosJunpeng LaoRémi Louf",
        "links": "http://arxiv.org/abs/2402.10797v1",
        "entry_id": "http://arxiv.org/abs/2402.10797v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10797v1",
        "summary": "BlackJAX is a library implementing sampling and variational inference\nalgorithms commonly used in Bayesian computation. It is designed for ease of\nuse, speed, and modularity by taking a functional approach to the algorithms'\nimplementation. BlackJAX is written in Python, using JAX to compile and run\nNumpPy-like samplers and variational methods on CPUs, GPUs, and TPUs. The\nlibrary integrates well with probabilistic programming languages by working\ndirectly with the (un-normalized) target log density function. BlackJAX is\nintended as a collection of low-level, composable implementations of basic\nstatistical 'atoms' that can be combined to perform well-defined Bayesian\ninference, but also provides high-level routines for ease of use. It is\ndesigned for users who need cutting-edge methods, researchers who want to\ncreate complex sampling methods, and people who want to learn how these work.",
        "updated": "2024-02-16 16:21:02 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10797v1"
    },
    {
        "title": "Error Feedback Reloaded: From Quadratic to Arithmetic Mean of Smoothness Constants",
        "authors": "Peter RichtárikElnur GasanovKonstantin Burlachenko",
        "links": "http://arxiv.org/abs/2402.10774v1",
        "entry_id": "http://arxiv.org/abs/2402.10774v1",
        "pdf_url": "http://arxiv.org/pdf/2402.10774v1",
        "summary": "Error Feedback (EF) is a highly popular and immensely effective mechanism for\nfixing convergence issues which arise in distributed training methods (such as\ndistributed GD or SGD) when these are enhanced with greedy communication\ncompression techniques such as TopK. While EF was proposed almost a decade ago\n(Seide et al., 2014), and despite concentrated effort by the community to\nadvance the theoretical understanding of this mechanism, there is still a lot\nto explore. In this work we study a modern form of error feedback called EF21\n(Richtarik et al., 2021) which offers the currently best-known theoretical\nguarantees, under the weakest assumptions, and also works well in practice. In\nparticular, while the theoretical communication complexity of EF21 depends on\nthe quadratic mean of certain smoothness parameters, we improve this dependence\nto their arithmetic mean, which is always smaller, and can be substantially\nsmaller, especially in heterogeneous data regimes. We take the reader on a\njourney of our discovery process. Starting with the idea of applying EF21 to an\nequivalent reformulation of the underlying problem which (unfortunately)\nrequires (often impractical) machine cloning, we continue to the discovery of a\nnew weighted version of EF21 which can (fortunately) be executed without any\ncloning, and finally circle back to an improved analysis of the original EF21\nmethod. While this development applies to the simplest form of EF21, our\napproach naturally extends to more elaborate variants involving stochastic\ngradients and partial participation. Further, our technique improves the\nbest-known theory of EF21 in the rare features regime (Richtarik et al., 2023).\nFinally, we validate our theoretical findings with suitable experiments.",
        "updated": "2024-02-16 15:55:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.10774v1"
    }
]