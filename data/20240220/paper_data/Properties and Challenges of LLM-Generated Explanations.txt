Properties and Challenges of LLM-Generated Explanations
JennyKunz and MarcoKuhlmann
Dept.ofComputerandInformationScience
LinköpingUniversity
jenny.kunz@liu.se and marco.kuhlmann@liu.se
Abstract cangiveexplanationsforamuchbroaderrangeof
questionsorinstructions.
Theself-rationalisingcapabilitiesoflargelan-
Generated explanations can be a means to im-
guagemodels(LLMs)havebeenexploredin
restrictedsettings,usingtask-specificdatasets. prove model performance (Wei et al., 2022b;
However,currentLLMsdonot(only)relyon Kojima et al., 2022) and decrease hallucinations
specificallyannotateddata; nonetheless,they viaafeedbackloop(Stammeretal.,2023);butthey
frequentlyexplaintheiroutputs. Theproperties arealsoexpectedtoprovidecontextforhumande-
of the generated explanations are influenced
cision-making(Gonzálezetal.,2021;Narayanan
by the pre-training corpus and by the target
etal.,2018). AsLLMstypicallyarenotexplicitly
data used for instruction fine-tuning. As the
trainedwithannotatedexplanations,incontrastto
pre-trainingcorpusincludesalargeamountof
earliermodels, thepropertiesoftheexplanations
human-writtenexplanations“inthewild”,we
hypothesisethatLLMsadoptcommonproper- they provide are not obvious, making it hard to
tiesofhumanexplanations. Byanalysingthe predicttheusefulnessofthesemodels’self-ration-
outputsforamulti-domaininstructionfine-tun- alisingcapabilities.
ingdataset,wefindthatgeneratedexplanations
Twomainfactorscaninfluencetheexplanations
show selectivity and contain illustrative ele-
given by LLMs: the properties of the explana-
ments,butlessfrequentlyaresubjectiveormis-
tions contained in the pre-training data, and the
leading. Wediscussreasonsandconsequences
oftheproperties’presenceorabsence. Inpar- propertiesfosteredbyalignmenttechniquessuch
ticular,weoutlinepositiveandnegativeimplic- asinstructionfine-tuning(IFT;Weietal.,2022a)
ationsdependingonthegoalsandusergroups andreinforcementlearningwithhumanfeedback
oftheself-rationalisingsystem.
(Ouyangetal.,2022). Basedonthis,wehypothes-
isethatLLMscapturevariouspropertiesofhuman
1 Introduction
explanationsfromthelargeamountofhumantext
Self-rationalisingmodelsproduceexplanationsto- in the training data, including characteristics un-
gether with their primary output, often in natural commonintheearlierannotatedexplanations,and
language(Marasovicetal.,2022;Wiegreffeetal., inparticularpropertiesthatcontributeprimarilyto
2022). Thesemodelshavereceivedincreasedatten- thecommunicativefunctionofhumanexplanations
tioninrecentyearsaslanguagegenerationabilities (Lombrozo, 2006; Miller, 2019). Many of these
have improved with autoregressive Transformer propertieshavebeenarguedtobeirrelevantoreven
(Vaswanietal.,2017)architectures,pioneeredby detrimentaltothegoalsofexplainableNLP,where
theGPTmodels(Radfordetal.,2018,2019). Nat- the aim is to understand how a system arrived at
urallanguageexplanationsareeasilyaccessibleto acertainprediction;theseincludeincompleteness
usersandflexibleinthetaskstheycanbeusedfor (particularlyselectivity),subjectivity,theinclusion
and the types of reasoning they can express. So ofillustrativeelements,andtheabilityofsystems
far, the focus of this line of research has been on to provide explanations even for wrong answers
modelstrainedonannotatedexplanationsfor(more (Tan,2022;Bommasanietal.,2021;Turpinetal.,
or less) well-definedtasks such as commonsense 2023). Incontrast,inthefieldofhuman–computer
questionanswering(Parketal.,2018;Rajanietal., interaction,human-likeexplanationsareseenmore
2019; Aggarwal et al., 2021) or natural language favourably(deGraafandMalle,2017;Ehsanetal.,
inference(Camburuetal.,2018). However,thecur- 2019),indicatingtensionbetweenthevariousgoals
rentgenerationoflargelanguagemodels(LLMs) andusergroupsofself-rationalisingsystems.
4202
beF
61
]LC.sc[
1v23501.2042:viXraTheaimofthispaperistosystematiseproperties openinstructionstomakethemresemblehumanex-
ofhumanexplanationsandtogaugetowhatextent planations,thenarrownatureofthetargetedtasks
these properties are reflected in the explanations canresultinatemplate-likecharacterofexplana-
generatedbyLLMs. Thisknowledgecanhelpde- tions(Camburuetal.,2018;WiegreffeandMara-
velopersandusersofthesemodelsunderstandin sovic,2021). Incontrast,recentworkincreasingly
whichcasesthegeneratedexplanationsarealigned uses LLMs to create explanation-annotated data-
withspecificgoals,andwhenamodelneedstobe sets. As an example, Wiegreffe et al. (2022) sug-
adaptedorisunfitfortheintendedusecase. Toget gestusingfew-shotlearninginGPT-3togenerate
insightsintothepropertiesofLLM-generatedex- explanationsforlargerdatasetswithanacceptabil-
planations,welookintotheAlpacadataset(Taori ityfilteringsystemthatselectsthemostacceptable
etal.,2023;Pengetal.,2023). Choosingthisdata- explanation from a set of candidate explanations
setletsusstudythepropertiesoftheexplanations generatedforthesamesample.
generated by GPT-4 (OpenAI, 2023), the LLM Letting a model generate explanations along
usedintheconstructionofAlpaca. However,our withitsprimaryoutputhasbeenshowntoimprove
findingsalsohaveawiderscope,asAlpacaisused the model’s prediction accuracy in some cases
forIFTandthepropertiesitexhibits,includingthe (Liu et al., 2019; Zhao and Vydiswaran, 2020).
propertiesoftheexplanationscontainedinit,are Recentexamplesarechain-of-thoughtprompting
likelytobefurtherpropagatedtoderivedmodels (Weietal.,2022b;Kojimaetal.,2022)andtree-of-
fine-tunedonit. thoughts(Yaoetal.,2023),whereanLLMgener-
atesintermediatereasoningstepspriortomaking
Contributions:
a prediction in a zero-shot setting, “guiding” the
• Weidentifytypicalpropertiesofhumanexplan- modeltowardstherightanswer.
ations,specificallysuchthathavebeenpointed
outasunfitforexplainingmodelpredictions. 2.2 FaithfulnessVersusUnderstandability
• Weinvestigateinahumananalysisofasubsetof Self-rationalising models are viewed with some
Alpacaifandhowfrequentlysuchpropertiesare scepticisminNLPandmachinelearning,wherethe
attestedinreal-worlddata. maingoalofexplanationsisoftenseenasproviding
insights into the model’s decision process. Bom-
• We discuss the implications of these proper- masanietal.(2021)expressdoubtsaboutfree-text
ties for different goals of explainable NLP, explanationsasatoolforunderstandingLLMs,as
namelysafety,trustworthiness,troubleshooting plausible-soundingexplanationsmaynotprovide
andknowledgediscovery,andthecorresponding true insights into model behaviour. Tan (2022)
targetusergroupsthatmayuseLLMs. discusses if human explanations are suitable as
additional supervision or as ground truth, given
2 RelatedWork
thathumanscanalsoprovideexplanationsforin-
We give a brief overview of the work on self-ra- correctlabels. Theypointoutthathumanexplan-
tionalisingmodelsin§2.1. In§2.2wesummarise ations for most tasks are necessarily incomplete
argumentsforandagainsttheuseofgeneratednat- and do not present valid and complete reasoning
urallanguageexplanations. paths. Thedoubtsaresupportedbyevidencethat
models mimic human misconceptions (Lin et al.,
2.1 Self-RationalisingModels 2022), which will likely affect generated explan-
Mostpastworkonfree-textexplanationsinNLP ations. Turpin et al. (2023) show with prompts
usesdatasetsthatincludehuman-annotatedexplan- containingsurfacebiasesthataffectthepredictions
ations (Marasovic et al., 2022; Zhao and Vydis- thatthisbiasisneverreflectedintheexplanations.
waran,2020;Narangetal.,2020). Eachsuchdata- Herman (2017) emphasizes the importance of
setfocusesonaspecific,well-definedtask,suchas differentiatingbetweendescriptiveandpersuasive
naturallanguageinference(Camburuetal.,2018), explanations. Descriptiveexplanationsdescribethe
multiple-choicecommonsensequestionanswering underlyingmodelwithmaximumfidelityandserve
(Rajanietal.,2019;Aggarwaletal.,2021)orvisual theethicalgoaloftransparency,whilepersuasive
questionanswering(Parketal.,2018). Whilethe explanations are tailored to the human cognitive
explanationsinthesedatasetswerecollectedwith functionandpreferencestobuildtrustandunder-standingintheenduser. Similarly,JacoviandGold- 2023). Toidentifyandsystematiserelevantprop-
berg(2020)callforaseparationbetweenplausibil- erties, we take inspiration from work on how hu-
ityandfaithfulness. Whilemostworksusingother mansconstructandunderstandexplanations(Keil,
explanatorytechniques,suchasinputfeatureattri- 2006;Lombrozo,2006). Inrecentyears,suchwork
bution, implicitly or explicitly focus on descript- haseventargetedtheexplainablemachinelearning
iveexplanations(Narayananetal.,2018),free-text audience(Miller,2019;Byrne,2023).
explanations are often interpreted as persuasive, Itisimportanttonotethathumanexplanations
strivingforplausibility. However,Wiegreffeetal. donotallshareuniversalproperties. Theirnature
(2021)provideastartingpointforananalysisthat and structure interact heavily with the explanan-
quantifiesfaithfulnessinfree-textexplanationsby dum, thatis, thetopicoftheexplanation. Forex-
measuringifpredictionsandexplanationsshowa ample, while both an everyday explanation (e.g.,
correlated behaviour, e.g., under input perturba- why you are late for dinner) and a mathematical
tions. Despitethiswork,thereremainsatrade-off proof are human-made explanations, they have
between understandability and faithfulness. As littleincommon(WilsonandKeil,1998). Inthis
Doshi-Velez and Kim (2017) argue, the latter is section,wewillfocusspecificallyonpropertiesof
ultimatelyimpossibleformodelsthatarenotinter- humanexplanationsthathavebeenpointedoutas
pretableperse,whichincludesLLMs. Laterinthis disadvantageousinthecontextofexplainableNLP,
article,in§6.3,wewilldiscussforwhichgoalsand andthatwewilltestforinourexperiment.
usersexplanationscan(ordonot)havevalueifwe
3.1 Incompleteness
cannotguaranteetheirrelationtotheprediction.
ContrarytothescepticisminexplainableNLP, Human explanations are often incomplete, as the
workinhuman–computerinteractionoftenprefers full set of relations behind a phenomenon can be
free-text over more formalised types of explana- farbeyondthegraspofboththeexplainerandthe
tions,astheyarenaturallyunderstandabletousers. explainee (Keil, 2006). Incompleteness has been
deGraafandMalle(2017)arguethatautonomous pointed out as an issue for explainable NLP, as
systemsmustcommunicatetheirgoalsandbeliefs incompleteexplanationsdonotpresentvalidreas-
topeopleinteractingwiththemanddosoinnatural oningpaths(Tan,2022).
language. They posit that systems, like humans, Theincompletenessofexplanationscomesindif-
needtobeabletodistinguishintentionalfromunin- ferentshapes. Inparticular,explanationsoften(or,
tentionalbehaviourandexplaineachoftheminthe dependingontheinterpretationofthephenomenon,
expectedway: intentionalbehaviourwithreasons, always)relyoncommonsenseconceptswithoutfur-
and unintentional behaviour with individual sets therspecification,assumingthattheconversation
of causes. Ehsan et al. (2019) argue that natural counterpartssharethem(§3.1.1). Secondly,explan-
languageexplanationshelphumanscommunicate ationsoftennameonlyasubsetofallcausesand
effectively with models by verbalizing plausible mechanismsthatleadtoanoutcome(§3.1.2).
motivations. Ehsanetal.(2021)agreethatexplain-
3.1.1 CommonsenseConcepts
ability is crucial for trustworthy and accountable
human–AIcollaboration, butarguethatresearch- Human explainers make assumptions about the
ers working on explainable AI are mostly driven knowledgeandunderstandingoftheircommunica-
bytheirintuitionsratherthanknowledgeaboutthe tionpartneranddonotexplaintheconceptstheybe-
intended audience. They call for more research lievetherespectiveothershares(Lombrozo,2006).
on human-centred explainable AI for a better un- Explanationsaresocialandfollowtherulesofef-
derstanding of user goals and how technological, ficientcommunication;therefore,onlyknowledge
individual,andsocialfactorsshapethesegoals. thattheexplainerassumesisnewtotheexplainee
iscommunicated(Miller,2019;Hilton,1990). For
3 PropertiesofExplanations example,assumethequestion“WhyisBertwear-
ingshorts?” andtheexplanation“Hewearsshorts
Inthissection, weintroducethepropertiesofex- becauseheisinMalta.” Thisexplanationassumes
planationsthatwewillreviewanddiscussinthis thattheexplaineesharesthecommonunderstand-
paper. AsLLMsarelargelytrainedonhuman-au- ingthatMaltaisawarmplaceandthatinawarm
thoredtext,weexpecttheirgeneratedexplanations climate,itispleasanttowearlightclothes,ofwhich
tobesimilartohumanexplanations(McCoyetal., shortsareaninstance.Reliance on commonsense concepts is related 1998;Tan,2022). Ontheotherhand,incertainsitu-
totheillusionofexplanatorydepth(Rozenblitand ations,humansneedtoreflectontheirsubjective
Keil,2002),thephenomenonthatpeople’sexplan- mentalprocessesintheexplanations(Tan,2022),
atoryknowledge,especiallyrelatedtodevicesand andcertaindecisionsareinherentlysubjective. For
naturalphenomena(e.g.ofaflushtoilet),ismuch example,ifaskedforrecommendationsforaholi-
more fragmental then they perceive it to be. To daydestination,theexplanationwilllikelycontain
avoidanoverwhelmingcognitiveload,peopleare subjective criteria based on personal perceptions
satisfied with a skeletal level of comprehension. andopinions. (“IrecommendgoingtoLisbonbe-
Howreliableexplanationsbasedoncommonsense causeofthebeautifularchitectureandgreatfood.”)
conceptsaredependsonhowdeeptheunderstand-
ingoftheunderlyingconceptsis. Similarly,when
3.3 MisleadingExplanationsforIncorrect
languagemodelsimitatethisbehaviour,theymay
Labels
imitatethestylewithoutnecessarilyhavingafull
representationoftheunderlyingconcepts. Aproblemofhuman-annotatedexplanationsthat
Ascommonsenseconceptsarepresentinalllan- has been pointed out for explainable NLP is that
guageusagetovaryingdegrees,wedecidedtoex- humans can provide explanations even for incor-
cludethispropertyfromourannotationstudy.1 A rectlabelsandfortasksthattheyperformbadlyon
quantitative dive into this phenomenon is left for (Tan, 2022). For example, if the task is to calcu-
futurework.
latetheresultof0.5+0.5∗10andtheexplainer
answers that “It is 11 because 0.5+0.5 = 1 and
3.1.2 Selectivity 1 + 10 = 11”, this explains their reasoning and
maybeconvincingtoexplaineeswhoareunaware
Humansincludecausesintheirexplanationsifthey
ofthemathematicalconventionthatmultiplication
judgethemtoberelevantandprobable(Lombrozo,
comesbeforeaddition.
2006; White, 1995). They hardly ever expect an
explanation to contain the complete causes of an It has been noted that hallucinations in LLMs,
event,noristhisfeasible(WilsonandKeil,1998). i.e. generations that are unfaithful to the input or
Selecting one or two causes suffices, as long as factuallyincorrect(Leeetal.,2018;Maynezetal.,
the selection mirrors their impact and potentially 2020;Jietal.,2023),canbeaccompaniedbyhal-
other human preferences, such as giving priority locinatoryexplanations(Augensteinetal.,2023).
to events that are more recent, surprising, inten- However,therehasbeenlessworkonhowpersuas-
tionalorimmoral(Miller,2019). Mittelstadtetal. ivetheyareinpractice. YeandDurrett(2022)show
(2019)nameselectivityasafundamentalproperty thatmodel-generatedexplanationsratedasfactual
ofexplanations,giventhatsomereasonsaremore byhumanscorrelatewithaccuratepredictions,but
relevantthanothers. Asanexample,considerthe thattheeffectdependsonthedataset.
statement “Eating less beef is beneficial for com-
batting climate change.” In many circumstances, 3.4 IllustrativeElements
explaineeswouldconsiderareferencetomethane
ThatexplanationsgeneratedbyLLMsarenotfaith-
emissionsfromcattleavalidexplanation. However,
fultotheirprimaryoutputisaclassicalobjection
therearevariousotherfactorsthatcouldbenamed,
intheNLPcommunity(Bommasanietal.,2021).
e.g.landuseanddeforestation;whileotherfactors
Humanexplanationscanincludeelementsthatare
areunlikelytoappearastheirimpactusnegligible,
off-path in terms of effective reasoning but illus-
e.g.emissionsconnectedtotheelectricityneeded
trate the thought process to the explainee, such
tooperatecattlefences. Selectingthemostrelevant
asexamples. Theseareafundamentalpartofex-
factorsiscrucialforefficientcommunication.
planation and learning (Chi et al., 1989). For the
3.2 Subjectivity question“Whatis12/4?”,theanswercouldbean
illustration: “It is 3: If you cut a pizza into 12
Humandecision-makingcanincludesubjectiveand
pieces,anddividethemfairlyamongfourpeople,
biasedcriteriathatarenotreflectedintheexplan-
everyonewillhavethreepieces.” Whiletheillustra-
ationsgivenforthesedecisions(Greenwaldetal.,
tionmaynotreflecthowtheexplainerarrivedatthe
answer,theyexpectthatitwillhelptheexplainee
1Apreliminarystudyshowedalowinter-rateragreement
onwhetheranexplanationinvokescommonsenseconcepts. understandtheanswer.4 ExperimentalSetup
In this section, we introduce our data and an-
notation setup. All data, code and ratings can Other Facts & Lists
befoundathttps://github.com/jekunz/
7 92
llm-expl-properties. Coding Assistance
27
4.1 Data
26
WeuseAlpaca(Taorietal.,2023),adatasetauto-
Math Problems 19 29
maticallygeneratedusingtheself-instructpipeline
(Wangetal.,2022),intheversionwithGPT-4an- Text Classification
Grammar & Language
notations(Pengetal.,2023). Alpacahasabroad
coverageofinstructions,asreportedinananalysis
inTaorietal.(2023). Itisgeneratedinatwo-step Figure1: DistributionofthecategoriesdefinedinSec-
tion4.1intheevaluationset.
process: firsttheinstructionsandthentheoutputs.
AlpacaislicensedunderApache2.0.
To create a dataset for our manual evaluation,
• Iftheanswertotheformerquestionwasyes:
weidentified200instructionsthatwebelievedcan
benefit from an explanation for the primary out- – Q3: Does the explanation list contributing
put. Tothatend,weiteratedovertheshuffleddata factors?
anddiscardedunfittinginstructions,e.g.suchthat – Q4: Does the explanation include subjective
are meant to evoke creative generations (“Write orbiasedcriteria?
twolinesofiambicpentameter.”),thataskforvery
– Q5: Doestheexplanationincludeillustrative
straightforwardfacts(“WhowroteHarryPotter?”)
elements(e.g.examples)?
orthatareunclearandthereforelikelytoberefuted
– Q6: Istheexplanationmisleading(e.g.arguing
bythemodel. Wediscarded500instructionsuntil
foralabelthatiswrong)?
wereachedourtargetof200.
Next,wecategorisedthe200instructions,giving
Thefullquestionnairewithfurtherinstructionsfor
usthedistributioninFigure1. CodingAssistance
the annotation can be found in Appendix A. The
are prompts that ask the model for concrete im-
annotation was performed by three raters using
plementations of programming problems. Math
LabelStudio(Tkachenkoetal.,2020-2022).
Problems are mathematical questions. Grammar
Tomeasurethecorrelationbetweenthefirsttwo
&Languagereferstopromptsforcorrectingorim-
questions,wereportMatthew’scorrelationcoeffi-
provingapieceoftextorpointingouterrorsinit.
cient(MCC;Matthews,1975).
TextClassificationincludesallinstructionsthatask
themodeltoclassifyasentenceinto(pre-defined
5 Results
orimplicit)categories. Facts&Listsreferstoall
instructionswherethemodelisaskedforafactor We separate the results of our human evaluation
alistoffactsorsuggestions. Otherareallprompts intotwoparts: theanswerstothefirsttwoquestions
thatdonotfallintoanyoftheothercategories. abouttheexistenceofexplanationsin§5.1andthe
answerstothelatterfourquestionsin§5.2.
4.2 Questionnaire
Foreachofthe200examples(instructionplusout- 5.1 PresenceofExplanations(Q1andQ2)
put),weaskedthefollowingsixquestionsbasedon
InFigure2,wepresenttheresultsforthequestion
thepropertiesintroducedinSection3,withanswer
ofhowmanyinstructionsGPT-4explainsandhow
optionsyesandno:
manyinstructionsthethreeindividualannotators
self-report they would explain. In Table 1, we
• Q1: Doestheoutputcontainanexplanationfor
presentabreakdownpercategoryofthenumberof
theprediction?
sampleswhereatleasttworatersansweredyesto
• Q2: Wouldyougiveanexplanation/justifyyour QuestionsQ1andQ2.
reasoning if you were asked this question by a Theoutputscontainexplanationsin(onraterav-
friend? erage)64.3%ofthecases,whiletheraterswould200 Category Q3 Q4 Q5 Q6 Total
Q1
Q2 Math 4 0 3 0 19
150
Code 3 0 10 0 16
List/Facts 64 1 63 0 81
100 Grammar 1 0 4 0 6
Class. 5 0 3 0 10
50
All: 79 1 86 0 137
0
A1 A2 A3 Table2: Samplesthatreceivedatleasttwoyes-Answers
Annotator
fromtheratersforQuestionsQ3–Q6. Totalisnumber
ofexplanationsforthecategory(asreportedviaQ1).
Figure2: Comparisonoftheyes-answersthethreean-
notators (A1, A2, A3) for Questions Q1 (“Does the
outputcontainanexplanationfortheprediction?”) and
Q2(“Wouldyougiveanexplanation/justifyyourreas- explainedbyGPT-4,with6outof19(32%)and11
oningifyouwereaskedthisquestionbyafriend?”). outof24(46%)ofinstructionsexplained. Theaver-
agelengthofthiscategoryisalsotheshortest,with
Category Q1 Q2 Total Length 30and24tokens,respectively. Mathandcodeques-
tions are in between both for the number (19 out
Math 19 11 26 77
of26–73%–and17outof27–63%–)andlength
Code 17 12 27 110
(77and110tokens)ofexplanations. Incontrastto
List/Facts 80 78 92 168
theothercategories,thelattertwoareexplainedby
Grammar 6 7 19 30
themodelnotablymoreoftenthantheratersreport
Class. 11 12 29 24
they would explain them. The raters would only
All: 137 125 200 113 explain11and12samples,respectively.
Table1: Samplesthatreceivedatleasttwoyes-Answers
fromtheratersforQuestionsQ1andQ2aswellasthe 5.2 PropertiesofExplanations(Q3–Q6)
averageoutputlengthintokens.
Table 2 shows the results for the questions about
which properties the raters have observed in the
onaverageexplain62.5%oftheanswers. Thelat-
explanation. For attested examples of each of
terhasalargevariationfrom50.0%to74.5%,in-
the properties from the dataset, we refer to Ap-
dicatingtheindividualnatureoftheproblem. There
pendixB.
isamoderatelypositivecorrelationbetweenwhich
Weseethat thepropertythat ismostprevalent
explanations are explained by GPT-4 and which
in our study is selectivity (Q3); it is, as two of
the raters report they would explain. Matthew’s
three raters agree, included in 61 samples. Illus-
correlation coefficient for the individual raters is
trativeelements(Q5)arealmostequallycommon;
0.58,0.48and0.70.2
with58sampleswhereatleasttworatersnotedthe
Thereare137sampleswhereatleasttworaters
presence of this property. In contrast, the raters
agree that there is an explanations, while at least
report only 8 subjective explanations (Q4) and 1
tworatersagreethattheywouldexplaintheques-
misleadingexplanation(Q6).
tionfor125samples.
Breakdownbycategory AsweseeinTable1,
Breakdown by category Looking at the indi-
lists and facts are by far the most likely to be ex-
vidualcategories,weseethatmathproblemshave
plained: For 80 out of 92 samples (87%), there
theleastofthedefinedcriteria,apparentlyhaving
are yes-answers by at least two raters. This cat-
theleastsocialandthemostformalexplanations.
egory also gets the most verbose output, with an
Subjectivity(Q4)isonlyreportedforthecategory
averagelengthof168tokens. Grammarandclassi-
Lists and facts in one example, while there is no
ficationinstructionsareparticularlyunlikelytobe
example for misleading explanations (Q6) in the
definedcategories. Selectivity(Q3)andillustrating
2TheintervalofMCCis[−1,1],where0israndomand1
isperfectcorrelation.MCCisbalancedbetweenclasses. factors(Q5)areobservedforallcategories.
srewsnA-seY
fo
rebmuN6 Discussion askthesamequestionstohumansandannotatethe
answersforexplanations.
ThenaturallanguageexplanationsgivenbyLLMs
The observation that there are no explanations
areapparentlynotfaithfultothepredictionprocess
forwronglabelsislikelyaconsequenceofthespe-
buttheresultoftheautoregressivepre-training,i.e.
cificdatasetweuse. AsAlpacaisLLM-generated,
theyimitatehumanexplanationsfromthetraining
itlikelyonlyproposesquestionsandexamplesthat
data,possiblyconstrainedbyinstructionfine-tun-
isclosetothesourcemodel’spre-trainingdata,i.e.
ingandotheralignmenttechniques. Assuch,they
theinstructionsarehigh-probabilityandarethere-
exhibit typical properties of human explanations,
forelikelytobeansweredcorrectly(McCoyetal.,
whichwediscussin§6.1. In§6.2wereflectonour
2023). Totestthishypothesis,ifonlyanecdotally,
evaluationmethodanddata. Finally,in§6.3wedis-
we follow McCoy et al. (2023) and construct a
cusstheimplicationsofourfindingsfordifferent
mathproblemwithlesscommonnumbers:
goalsofexplainableNLP.
Question: Whatistheresultof1/7+1/17+0.54?
6.1 Properties Answer: 0.8117
Inourexperiments,weobservedthatthemostpre- Question: Canyouexplain?
valentpropertiesoftheexplanationsareselectivity Answer: Theresultof1/7+1/17+0.54is0.8117.
and illustrative elements, while subjectivity and This is calculated by adding the fractions 1/7 +
misleadingexplanationsoccurlessoften. 1/17andthenaddingthatsumto0.54. Thesumof
The different properties are spread unevenly thefractionsis0.7117,andwhenthisisaddedto
across categories of the dataset. This shows that 0.54theresultis0.8117.
thereisnotonetypeofexplanationthatfitsallin-
Theresultiswrong,butwhenweaskforanex-
structiontypesandtopics. Inparticular,formath
planation,wereceiveamisleadingexplanationfor
andcodequestions,itisoftenpossibletoprovide
thewrongprediction. Thisexampleindicatesthata
acompletereasoningpathwithlogicalinferences,
morechallenging,notLLM-generateddatasetmay
which allows these explanations to be complete
infacttriggermoreexplanationsforwronglabels.
(Tan, 2022). Not unexpectedly, these questions
arealsorarelyratedassubjective,andillustrative 6.3 ImplicationsforDifferentGoals
elements are more frequent – probably because,
Todiscusstheeffectsofthedifferentpropertiesof
for many humans, examples facilitate the under-
explanations, it is crucial to distinguish between
standing of abstract logical reasoning. Illustrat-
different types of user groups that may employ a
ive elements are even common in grammar ques-
system, and what their goals are. Adadi and Ber-
tions, which is another more formal domain. On
rada(2018)identifyfourreasonstoseekexplana-
the other hand, factual questions and list gener-
tions: tojustifydecisions,to(enhance)control,to
ation tasks more often represent questions about
improvemodels,andtodiscovernewknowledge.
complex phenomena that are rarely explained by
Mittelstadtetal.(2019)nameactualinterpretabil-
simple facts and logical inferences; this includes
ity (faithfulness), trustworthiness, accountability,
questionsaboutnutritionorclimate. selectivityis
accessibility,comprehensibility,andusefulnessas
thereforeparticularlyprevalenthere.
common goals. We discuss the goals under four
Subjectivityisaspecialcaseasbiasisexplicitly
umbrellas: safety,trustworthiness,troubleshooting,
discouragedincurrentcommercialLLMs(Askell
andknowledgediscovery.
et al., 2021; Ouyang et al., 2022) and therefore
likelytohavebeenpunishedduringthealignment 6.3.1 Safety
phase of GPT-4 training. We believe that this Weusethetermsafetyforthepossibilityofdeploy-
explains why subjective explanations are rare in ing the model with a human in the loop without
Alpaca,eveniftheymayhavebeenmorecommon riskofharminacontrollableandaccountableway.
intheautoregressivetrainingphase. Thegeneratedexplanationscanprovideevidence
foraprediction,butthisevidencemustbecritically
6.2 LimitationsofourMethod
reflectedbytheuser. Iftheuseriscompetent,their
Askingraterstheywouldgiveanexplanationisnot decisionscouldbeimprovedbythisadditionalin-
an actual measurement of their likeliness to give formation,asexplanationscangiveusersachance
anexplanation. Amorenaturalsetupwouldbeto to discover general inconsistencies between theuser’s and the model’s beliefs (Keil et al., 2004). ciesofthemodel. Asaresult,thedevelopermay
Tothatend,communicationthatmakesuseofhu- make targeted modifications to the training data,
manexplanationfeaturessuchasincompleteness suchasmitigatingunwantedstatisticalcues.
andselectivity,illustrativeexamplesandsubjectiv-
6.3.4 KnowledgeDiscovery
itymayprovideanaccessibletrade-offtoevaluate
alignment. Incompleteexplanationscanbeunsafe Explanationscanbeusedforattemptstodiscover
ifharmful(e.g.biased)factorsareleftout,wrongly newknowledge. Thiscanagainhappeninseveral
givingtheimpressionofanunbiasedmodel. contexts: ausermaywanttolearnexistingknow-
Iftheuser,however,isalaypersonintheapplic- ledge (“the user as a student”) or discover novel
ationdomainorinattentive,thereisthedangerthat scientific knowledge (“the user as a researcher”).
a rhetorically convincing explanation for a failed Fortheformer,factualcorrectnessiscrucial,asthe
predictiondeceivesthemandleadsthemtowrong learnercannotbeexpectedtobeabletojudgethe
and potentially harmful decisions. While we did reliabilityofthepredictionandexplanationthem-
notobservealargenumberofsuchexplanationsin selves,andmaybemisledbywronglabelsorsub-
ourstudy,thereis,asdiscussedin§6.2,theriskthat jectiveexplanations. selectivitymaybemisleading
thiswastheresultofthespecificcreationprocess insomecases,butsimplificationmoreoftenmakes
ofourdataset,andmaydifferforinstructionsthat newinformationmoreaccessibletolearners. The
arelessfamiliartothemodel. situationisdifferentforscientificdiscovery,asthe
explanation seeker is likely an expert in the field
6.3.2 Trustworthiness
andabletojudgewhethertoacceptanewtheory.
The largest consensus on where free-text explan- Thatthemodelpotentiallyexplainsfalselabelscan
ations can have a positive impact is that they bemisleadingbutindirectlyalsobepositive,asit
canimprovehuman-modelinteractionbyincreas- may correlate with the likelihood of making new
ing the users’ trust in the model. Trust, often a connections.
vagueconcept(JacoviandGoldberg,2021),ishere
defined as the user’s confidence that the model 7 Conclusion
workscorrectly,beitjustifiedornot. Confidently
explainingwrongorambiguouslabelsorobviously Largelanguagemodelsimitatehumanexplanations
subjective arguments can harm the trust of users intheirtrainingdataandadoptsomeoftheirtyp-
who are not familiar with how the system works ical properties. In our analysis of GPT-4 outputs
and generates explanations. Other than that, hu- from the Alpaca dataset, selectivity and illustrat-
man-likepropertiesintheexplanationsarealigned ingfactorswereparticularlycommon. Subjectivity
withtheuser’sexpectations(deGraafandMalle, was less common, as it was probably mitigated
2017),andthereforelikelytoincreasetrust. in the alignment and filtering process of GPT-4.
Misleadingexplanationswereobservedrarely,but
6.3.3 Troubleshooting given that the Alpaca dataset is LLM-generated,
Bytroubleshooting,wemeanthedeveloper’spos- it is likely that the observation will not hold for
sibilitytodebugandimproveanLLMwiththehelp lower-probabilityinputs.
ofexplanations. AsLertvittayakumjornandToni Wediscussedtheconsequencesofthepresence
(2021)note,explanationscanhelpdebugasystem, ofthesepropertiesandemphasizedthatitiscrucial
especiallywhereidentifiablepropertiesofthetrain- to consider both the goals and the target groups
ingdataleadtothebug. Forthisgoal,theunclear oftheapplication. Forlesscompetentandcareful
relationbetweenpredictionandexplanationispar- users, there is a risk of shaping false confidence
ticularlyproblematic,thereforepropertiessuchas with incomplete, rhetorically convincing but in-
illustrativeelementsmaybelessdesired. selectiv- correct or biased explanations. However, not all
ity and subjectivity can also be limiting factors, propertiesthatappearundesirableareunequivoc-
albeitinevitableinmanysituations. Evenincom- ally negative: Explanations for false predictions
pleteandsubjectiveexplanationscanhoweverbe mayhelpdevelopersspotthefallaciesofthemodel.
useful if the developer observes a consistency in Unfaithfulreasoningcanmakeexplanationsmore
the explanations including or lacking the desired accessiblewithsimplificationsandillustrativeex-
reasoning process. Explaining wrong labels may amples. selectivityisoftenevennecessaryforgen-
beausefulfeature,too,asitcandisplaythefalla- eratingcomprehensibleexplanations.Limitations DarioAmodei,TomB.Brown,JackClark,SamMc-
Candlish, Chris Olah, and Jared Kaplan. 2021. A
In §6.2, we discussed the key limitations of our generallanguageassistantasalaboratoryforalign-
setupandquestionnaire. Wementionedthatexpli- ment. CoRR,abs/2112.00861.
citlyaskingthequestioniftheraterwouldexplain
IsabelleAugenstein,TimothyBaldwin,MeeyoungCha,
theiranswermaynotreflectiftheyactuallywould
Tanmoy Chakraborty, Giovanni Luca Ciampaglia,
explain it in a natural setting. We also discussed DavidCorney,ReneeDiResta,EmilioFerrara,Scott
that the LLM-generated Alpaca dataset is likely Hale,AlonHalevy,EduardHovy,HengJi,Filippo
Menczer, Ruben Miguez, Preslav Nakov, Dietram
to only contain instructions that lead to a correct
Scheufele, Shivam Sharma, and Giovanni Zagni.
answer,andtherebyhavealowriskofamisleading
2023. Factualitychallengesintheeraoflargelan-
explanation. Thegenerationmethodofthedataset guagemodels.
willalsoaffectthedistributionoftheotherproper-
RishiBommasani,DrewA.Hudson,EhsanAdeli,Russ
ties. Whileweselectedthedatasetforitscomparat-
Altman,SimranArora,SydneyvonArx,MichaelS.
ivelybroadcoverage,thequantitativefindingsare
Bernstein,JeannetteBohg,AntoineBosselut,Emma
unlikelytogeneralisetootherdomains(inpartic- Brunskill,ErikBrynjolfsson,S.Buch,DallasCard,
ulartosuchthatarelow-resource)andinstruction Rodrigo Castellon, Niladri S. Chatterji, Annie S.
types. Chen, Kathleen A. Creel, Jared Davis, Dora Dem-
szky, Chris Donahue, Moussa Doumbouya, Esin
OtherLLMsmayalsoexhibitadifferentdistri-
Durmus,StefanoErmon,JohnEtchemendy,Kawin
bution due to their pre-training data and instruc- Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale,
tion-tuningdataandsetup. Amajorlimitationof LaurenE.Gillespie,KaranGoel,NoahD.Goodman,
thisstudyistheuseofoutputsfromGPT-4,apro- ShelbyGrossman,NeelGuha,TatsunoriHashimoto,
PeterHenderson,JohnHewitt,DanielE.Ho,Jenny
prietarymodelforwhichthereislittleconfirmed
Hong,KyleHsu,JingHuang,ThomasF.Icard,Saahil
informationavailabletothepublic. Usinganopen-
Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth
sourcemodelwithopenlyaccessibletrainingdata Karamcheti,GeoffKeeling,FereshteKhani,O.Khat-
wouldallowforadditionalinsightsfortheresearch tab,PangWeiKoh,MarkS.Krass,RanjayKrishna,
Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak,
community.
MinaLee,TonyLee,JureLeskovec,IsabelleLevent,
WeonlyconsiderEnglish-languageinstructions.
Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Ma-
Thegeneratedoutputsandexplanationsprobably lik,ChristopherD.Manning,SuvirP.Mirchandani,
reflect cultural norms of the English-speaking EricMitchell,ZaneleMunyikwa,SurajNair,Avanika
Narayan,DeepakNarayanan,BenjaminNewman,Al-
world. In addition, our three raters were a rel-
len Nie, Juan Carlos Niebles, Hamed Nilforoshan,
atively homogenous group with respect to their
J.F.Nyarko,GirayOgut,LaurelJ.Orr,IsabelPapadi-
demographicandeducationalbackground. Amore mitriou, Joon Sung Park, Chris Piech, Eva Portel-
diversesetofraterswouldbedesirable. ance,ChristopherPotts,AditiRaghunathan,Robert
Reich,HongyuRen,FriedaRong,YusufH.Roohani,
Camilo Ruiz, Jack Ryan, Christopher R’e, Dorsa
Sadigh, Shiori Sagawa, Keshav Santhanam, Andy
References
Shih,KrishnaParasuramSrinivasan,AlexTamkin,
Amina Adadi and Mohammed Berrada. 2018. Peek- Rohan Taori, Armin W. Thomas, Florian Tramèr,
ingInsidetheBlack-Box: ASurveyonExplainable RoseE.Wang,WilliamWang,BohanWu,JiajunWu,
ArtificialIntelligence(XAI). IEEEAccess,6:52138– YuhuaiWu,SangMichaelXie,MichihiroYasunaga,
52160. JiaxuanYou,MateiA.Zaharia,MichaelZhang,Tia-
nyiZhang,XikunZhang,YuhuiZhang,LuciaZheng,
Shourya Aggarwal, Divyanshu Mandowara, Vishwa- Kaitlyn Zhou, and Percy Liang. 2021. On the op-
jeetAgrawal,DineshKhandelwal,ParagSingla,and portunitiesandrisksoffoundationmodels. CoRR,
Dinesh Garg. 2021. Explanations for Common- abs/2108.07258.
senseQA:NewDatasetandModels. InProceedings
of the 59th Annual Meeting of the Association for RuthM.J.Byrne.2023. GoodExplanationsinExplain-
ComputationalLinguisticsandthe11thInternational ableArtificialIntelligence(XAI):EvidencefromHu-
JointConferenceonNaturalLanguageProcessing manExplanatoryReasoning. InProceedingsofthe
(Volume1: LongPapers),pages3050–3065,Online. Thirty-SecondInternationalJointConferenceonArti-
AssociationforComputationalLinguistics. ficialIntelligence,IJCAI-23,pages6536–6544.Inter-
nationalJointConferencesonArtificialIntelligence
AmandaAskell,YuntaoBai,AnnaChen,DawnDrain, Organization. SurveyTrack.
Deep Ganguli, Tom Henighan, Andy Jones, Nich-
olasJoseph,BenjaminMann,NovaDasSarma,Nel- Oana-Maria Camburu, Tim Rocktäschel, Thomas
sonElhage,ZacHatfield-Dodds,DannyHernandez, Lukasiewicz,andPhilBlunsom.2018. e-SNLI:Nat-
JacksonKernion,KamalNdousse,CatherineOlsson, uralLanguageInferencewithNaturalLanguageEx-planations. InAdvancesinNeuralInformationPro- AlonJacoviandYoavGoldberg.2021. Aligningfaithful
cessingSystems,volume31.CurranAssociates,Inc. interpretationswiththeirsocialattribution. Transac-
tionsoftheAssociationforComputationalLinguist-
MicheleneTHChi,MiriamBassok,MatthewWLewis, ics,9:294–310.
Peter Reimann, and Robert Glaser. 1989. Self-
explanations: Howstudentsstudyanduseexamples ZiweiJi,NayeonLee,RitaFrieske,TiezhengYu,Dan
in learning to solve problems. Cognitive science, Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea
13(2):145–182. Madotto,andPascaleFung.2023. Surveyofhallucin-
ationinnaturallanguagegeneration. ACMComput.
Maartje M. A. de Graaf and Bertram F. Malle. 2017.
Surv.,55(12).
How People Explain Action (and Autonomous In-
telligentSystemsShouldToo). In2017AAAIFall
F Keil, L Rozenblit, and C Mills. 2004. What lies
Symposia,Arlington,Virginia,USA,November9-11,
beneath? Understandingthelimitsofunderstanding.
2017,pages19–26.AAAIPress.
ThinkingandSeeing:VisualMetacognitioninAdults
andChildren.
FinaleDoshi-VelezandBeenKim.2017. ARoadmap
for a Rigorous Science of Interpretability. CoRR,
Frank C Keil. 2006. Explanation and understanding.
abs/1702.08608.
Annualreviewofpsychology,57:227.
UpolEhsan,PradyumnaTambwekar,LarryChan,Brent
Harrison,andMarkO.Riedl.2019. AutomatedRa- TakeshiKojima,ShixiangShaneGu,MachelReid,Yu-
tionale Generation: A Technique for Explainable takaMatsuo,andYusukeIwasawa.2022. LargeLan-
AI and Its Effects on Human Perceptions. In Pro- guageModelsareZero-ShotReasoners.
ceedings of the 24th International Conference on
IntelligentUserInterfaces,IUI’19,page263–274, KatherineLee,OrhanFirat,AshishAgarwal,ClaraFan-
New York, NY, USA. Association for Computing njiang,andDavidSussillo.2018. Hallucinationsin
Machinery. neuralmachinetranslation. InInterpretabilityand
RobustnessinAudio, Speech, andLanguageWork-
UpolEhsan,PhilippWintersberger,Q.VeraLiao,Mar- shop.ConferenceonNeuralInformationProcessing
tina Mara, Marc Streit, Sandra Wachter, Andreas Systems(NeurIPS2018),Montreal,Canada.
Riener,andMarkO.Riedl.2021. Operationalizing
Human-CenteredPerspectivesinExplainableAI. In PiyawatLertvittayakumjornandFrancescaToni.2021.
ExtendedAbstractsofthe2021CHIConferenceon Explanation-BasedHumanDebuggingofNLPMod-
HumanFactorsinComputingSystems,CHIEA’21, els: ASurvey. TransactionsoftheAssociationfor
New York, NY, USA. Association for Computing ComputationalLinguistics,9:1508–1528.
Machinery.
StephanieLin,JacobHilton,andOwainEvans.2022.
Ana Valeria González, Gagan Bansal, Angela Fan, TruthfulQA:Measuringhowmodelsmimichuman
YasharMehdad,RobinJia,andSrinivasanIyer.2021. falsehoods. InProceedingsofthe60thAnnualMeet-
Do explanations help users detect errors in open- ingoftheAssociationforComputationalLinguistics
domainQA?anevaluationofspokenvs.visualex- (Volume1: LongPapers),pages3214–3252,Dublin,
planations. InFindingsoftheAssociationforCom- Ireland.AssociationforComputationalLinguistics.
putational Linguistics: ACL-IJCNLP 2021, pages
1103–1116,Online.AssociationforComputational HuiLiu,QingyuYin,andWilliamYangWang.2019.
Linguistics. TowardsexplainableNLP:Agenerativeexplanation
frameworkfortextclassification. InProceedingsof
Anthony G Greenwald, Debbie E McGhee, and
the57thAnnualMeetingoftheAssociationforCom-
Jordan LK Schwartz. 1998. Measuring individual
putationalLinguistics,pages5570–5581,Florence,
differencesinimplicitcognition: theimplicitassoci-
Italy.AssociationforComputationalLinguistics.
ationtest. Journalofpersonalityandsocialpsycho-
logy,74(6):1464.
TaniaLombrozo.2006. Thestructureandfunctionofex-
planations. Trendsincognitivesciences,10(10):464–
BerneaseHerman.2017. Thepromiseandperilofhu-
470.
man evaluation for model interpretability. CoRR,
abs/1711.07414. Withdrawn.
Ana Marasovic, Iz Beltagy, Doug Downey, and Mat-
Denis J Hilton. 1990. Conversational processes thewPeters.2022. Few-shotself-rationalizationwith
and causal explanation. Psychological Bulletin, naturallanguageprompts. InFindingsoftheAssoci-
107(1):65. ationforComputationalLinguistics: NAACL2022,
pages410–424,Seattle,UnitedStates.Association
AlonJacoviandYoavGoldberg.2020. Towardsfaith- forComputationalLinguistics.
fully interpretable NLP systems: How should we
define and evaluate faithfulness? In Proceedings BrianWMatthews.1975. Comparisonofthepredicted
of the 58th Annual Meeting of the Association for andobservedsecondarystructureoft4phagelyso-
Computational Linguistics, pages 4198–4205, On- zyme. BiochimicaetBiophysicaActa(BBA)-Protein
line.AssociationforComputationalLinguistics. Structure,405(2):442–451.Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Nazneen Fatema Rajani, Bryan McCann, Caiming
Ryan McDonald. 2020. On faithfulness and factu- Xiong, and Richard Socher. 2019. Explain your-
alityinabstractivesummarization. InProceedings self! leveraginglanguagemodelsforcommonsense
of the 58th Annual Meeting of the Association for reasoning. InProceedingsofthe57thAnnualMeet-
Computational Linguistics, pages 1906–1919, On- ingoftheAssociationforComputationalLinguistics,
line.AssociationforComputationalLinguistics. pages 4932–4942, Florence, Italy. Association for
ComputationalLinguistics.
RThomasMcCoy,ShunyuYao,DanFriedman,Mat-
thewHardy,andThomasLGriffiths.2023. Embers LeonidRozenblitandFrankKeil.2002. Themisunder-
ofAutoregression: UnderstandingLargeLanguage stoodlimitsoffolkscience: Anillusionofexplanat-
Models Through the Problem They are Trained to orydepth. Cognitivescience,26(5):521–562.
Solve. arXivpreprintarXiv:2309.13638.
Wolfgang Stammer, Felix Friedrich, David Stein-
TimMiller.2019. Explanationinartificialintelligence:
mann,HikaruShindo,andKristianKersting.2023.
Insights from the social sciences. Artificial Intelli-
Learning by Self-Explaining. arXiv preprint
gence,267:1–38.
arXiv:2309.08395.
BrentMittelstadt, ChrisRussell, andSandraWachter.
Chenhao Tan. 2022. On the diversity and limits of
2019. ExplainingExplanationsinAI. InProceed-
human explanations. In Proceedings of the 2022
ingsoftheConferenceonFairness,Accountability,
Conference of the North American Chapter of the
and Transparency, FAT* ’19, page 279–288, New
AssociationforComputationalLinguistics: Human
York, NY, USA. Association for Computing Ma-
LanguageTechnologies,pages2173–2188,Seattle,
chinery.
United States. Association for Computational Lin-
Sharan Narang, Colin Raffel, Katherine Lee, Adam guistics.
Roberts,NoahFiedel,andKarishmaMalkan.2020.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
WT5?!TrainingText-to-TextModelstoExplaintheir
Dubois, Xuechen Li, Carlos Guestrin, Percy Li-
Predictions.
ang, and Tatsunori B. Hashimoto. 2023. Stan-
Menaka Narayanan, Emily Chen, Jeffrey He, Been ford Alpaca: An Instruction-following LLaMA
Kim,SamGershman,andFinaleDoshi-Velez.2018. model. https://github.com/tatsu-lab/
How do Humans Understand Explanations from stanford_alpaca.
Machine Learning Systems? An Evaluation of
the Human-Interpretability of Explanation. CoRR, Maxim Tkachenko, Mikhail Malyuk, Andrey
abs/1802.00682. Holmanyuk, and Nikolai Liubimov. 2020-
2022. Label Studio: Data labeling soft-
OpenAI. 2023. Gpt-4 technical report. ArXiv, ware. Open source software available from
abs/2303.08774. https://github.com/heartexlabs/label-studio.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car- Miles Turpin, Julian Michael, Ethan Perez, and
rollL.Wainwright,PamelaMishkin,ChongZhang, SamuelR.Bowman.2023. Languagemodelsdon’t
SandhiniAgarwal,KatarinaSlama,AlexRay,John alwayssaywhattheythink: Unfaithfulexplanations
Schulman,JacobHilton,FraserKelton,LukeMiller, in chain-of-thought prompting. In Thirty-seventh
Maddie Simens, Amanda Askell, Peter Welinder, ConferenceonNeuralInformationProcessingSys-
PaulF.Christiano,JanLeike,andRyanLowe.2022. tems,NewOrleans,Louisiana,USA.Conferenceon
Traininglanguagemodelstofollowinstructionswith NeuralInformationProcessingSystems(NeurIPS).
humanfeedback. CoRR,abs/2203.02155.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
DongHukPark,LisaAnneHendricks,ZeynepAkata,
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
AnnaRohrbach,BerntSchiele,TrevorDarrell,and
Kaiser,andIlliaPolosukhin.2017. Attentionisall
MarcusRohrbach.2018. MultimodalExplanations:
youneed. InAdvancesinNeuralInformationPro-
Justifying Decisions and Pointing to the Evidence.
cessingSystems,volume30.CurranAssociates,Inc.
In2018IEEE/CVFConferenceonComputerVision
andPatternRecognition,pages8779–8788.
YizhongWang,YeganehKordi,SwaroopMishra,Alisa
Liu,NoahA.Smith,DanielKhashabi,andHannaneh
BaolinPeng,ChunyuanLi,PengchengHe,MichelGal-
Hajishirzi.2022. Self-Instruct: AligningLanguage
ley,andJianfengGao.2023. InstructionTuningwith
ModelwithSelfGeneratedInstructions.
GPT-4. arXivpreprintarXiv:2304.03277.
AlecRadford,KarthikNarasimhan,TimSalimans,and JasonWei, MaartenBosma, VincentY.Zhao, Kelvin
Ilya Sutskever. 2018. Improving language under- Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
standingwithunsupervisedlearning. drew M. Dai, and Quoc V. Le. 2022a. Finetuned
Language Models are Zero-Shot Learners. In The
Alec Radford, Jeff Wu, Rewon Child, David Luan, TenthInternationalConferenceonLearningRepres-
DarioAmodei,andIlyaSutskever.2019. Language entations, ICLR 2022, Virtual Event, April 25-29,
ModelsareUnsupervisedMultitaskLearners. 2022.Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, • *****OUTPUT:*****: The output that the
Barret Zoph, Sebastian Borgeaud, Dani Yogatama, modelproduces.
MaartenBosma,DennyZhou,DonaldMetzler,etal.
2022b. Emergentabilitiesoflargelanguagemodels.
• *****QUESTION:*****: Thequestionthat
arXivpreprintarXiv:2206.07682.
youaresupposedtoanswerabouttheinstruc-
PeterAWhite.1995. Useofpriorbeliefsintheassign- tionandoutput.
mentofcausalroles:Causalpowersversusregularity-
basedaccounts. Memory&Cognition,23:243–254.
Thefollowingsevenquestionsareaskedforeach
Sarah Wiegreffe, Jack Hessel, Swabha Swayamdipta, datasampleandmustbeansweredwithyesorno.
Mark Riedl, and Yejin Choi. 2022. Reframing Questions5-7onlyneedtobeansweredifquestion
human-AIcollaborationforgeneratingfree-textex- 1 was answered with yes. If the answer was no,
planations. InProceedingsofthe2022Conference
skipthemorclickN/A.
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies,pages632–658,Seattle,UnitedStates. 1. Doestheoutputcontainanexplanationforthe
AssociationforComputationalLinguistics. prediction? -Themodelprovidesareason(ing
path)whyitgaveacertainanswer.
SarahWiegreffeandAnaMarasovic.2021. TeachMe
to Explain: A Review of Datasets for Explainable
Natural Language Processing. In Proceedings of 2. Would you give an explanation/justify your
theNeuralInformationProcessingSystemsTrackon reasoningifyouwereaskedthisquestionbya
DatasetsandBenchmarks,volume1.
friend? -Ifyouwereaskedthisquestionina
dialoguewithsomeone,wouldyoubelikely
SarahWiegreffe,AnaMarasovic´,andNoahA.Smith.
2021. Measuring association between labels and toaddajustificationtoyouranswer?
free-textrationales. InProceedingsofthe2021Con-
ferenceonEmpiricalMethodsinNaturalLanguage 3. Ifthereisanexplanation: Doestheexplana-
Processing,pages10266–10284,OnlineandPunta
tionrefertocommonsenseconceptsthatare
Cana,DominicanRepublic.AssociationforCompu-
taken as given? - There are parts in the ex-
tationalLinguistics.
planationthatrequireworldknowledge(facts
RobertA.WilsonandFrankKeil.1998. TheShadows abouttheworldthataretrivialforhumansand
andShallowsofExplanation. Mindsandmachines,
rarelyexplicitlystated)tocomprehend.
8(1):137–159.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, 4. Ifthereisanexplanation: Doestheexplana-
ThomasL.Griffiths,YuanCao,andKarthikNarasim- tionlistcontributingfactors? -Theexplana-
han. 2023. Tree of thoughts: Deliberate prob-
tion lists reasons that contribute to the truth
lem solving with large language models. CoRR,
valueoftheanswer(thatmaynotbecomplete
abs/2305.10601.
though).
XiYeandGregDurrett.2022. Theunreliabilityofex-
planationsinfew-shotpromptingfortextualreason- 5. If there is an explanation: Does the explan-
ing. InAdvancesinNeuralInformationProcessing
ation include subjective or biased criteria?
Systems.
- There are reasons stated in the explanation
Xinyan Zhao and V. G. Vinod Vydiswaran. 2020. thataretheresultsofsubjectiveexperiences.
LIREx: AugmentingLanguageInferencewithRel-
evantExplanation. CoRR,abs/2012.09157.
6. If there is an explanation: Does the explan-
ation include illustrative elements (e.g. ex-
A FullQuestionnaire
amples)? -Thereareelementsintheexplana-
The following information and instructions were tionsthatdonotrefertoconcretereasonsbut
providedtotheannotatorsinwrittenform. illustratethereasoningsothattheexplanation
becomeseasiertounderstand.
A.1 InstructionsforAnnotators
Eachannotationsampleconsistsofthefollowing 7. Ifthereisanexplanation: Istheexplanation
misleading (e.g. arguing for a label that is
parts:
wrong)? -Theexplanationcontainselements
• *****INSTRUCTION:*****: The prompt thatarewrongorirrelevantandcantherefore
thatwasgiventothemodel. misleadtheuserofthesystem.B Examples attemptingtounderstandhowrobustlythemodel
willbeabletosolvesimilartasks.
Inthissection,weprovideexamplesfortheproper-
tiesasobservedintheAlpacadataset. Wechoose B.2 Selectivity(Q3)
shortexampleswherepossible,andexampleswith
For the following example, all three annotators
thehighestavailableagreementbetweenannotators
agreedthatitcontainscontributingfactors.
except for section B.1 where we in addition dis-
INSTRUCTION: Identify 3 people who have
cussoneexamplewhereannotatorsdisagree. For
made significant contributions to the field of ro-
the full dataset, we refer to https://github.
botics.
com/jekunz/llm-expl-properties.
OUTPUT:1. MasahiroMori: MasahiroMoriisa
B.1 CommonsenseConcepts Japaneseroboticistandresearcher,widelyknown
for his pioneering work in robotics and human-
Thefollowingexamplefromtheannotationillus-
robot interaction. He is most famous for creat-
tratesthedifferentapproachesoftheannotatorsto
ingtheconceptofthe"uncannyvalley,"whichde-
theideaofcommonsenseconceptsthataretakenas
scribesthediscomfortpeoplefeelwhenarobotor
given. Thelargedisagreementbetweenannotators
animationlooksandmovesalmost,butnotexactly,
inapreliminarystudymadeusremovethisconcept
likeanaturalhumanbeing.
fromtheannotationasdiscussedinSection3.
2. RodneyBrooks: RodneyBrooksisanAustralian
INSTRUCTION: Is the following sentence true
roboticistandcomputerprogrammer, recognized
orfalse? –Allatomsofthesameelementhavethe
forhispioneeringworkinautonomousrobotsand
samemass.
artificialintelligence. Heistheco-founderofiRo-
OUTPUT:ThestatementisFalse. Thisisbecause
bot Corp., which is the maker of the Roomba va-
whileallatomsofthesameelementhavethesame
cuum cleaning robot. Brooks also served as the
numberofprotons,theycanhavedifferentnumbers
director of the MIT Computer Science and Artifi-
ofneutrons. Atomsofthesameelementwithdiffer-
cialIntelligenceLaboratory,andisknownforhis
ent numbers of neutrons are called isotopes, and
influentialworkinbehavior-basedrobotics.
theyhavedifferentmassesduetothedifferencein
3. CynthiaBreazeal: CynthiaBreazealisanAmer-
thenumberofneutrons.
ican roboticist and professor, widely known for
Annotators1and3haveannotatedthisexampleas her work in social robotics and human-robot in-
containing commonsense factors, as the explana- teraction. She is the director of the Personal Ro-
tionreliesontheimplicitcommonknowledgethat botsGroupattheMITMediaLab,whereshecre-
neutronshavemass. Annotator2howeverdidnot atedtheworld’sfirstsocialrobot,Kismet,in1997.
thinkthatitrequiresfurtherexplanationasauser Breazeal’sworkfocusesondevelopingrobotsthat
reading the output either knows it, or can infer it can communicate and interact with people in a
fromthetext. morehuman-likeway,andshehasreceivednumer-
Ontheotherhand,thefollowingexampleisun- ousawardsforherresearchinthisfield.
equivocally agreed on by all three annotators to
Foreachperson,severalcontributionsandachieve-
containnoteworthycommonsenseconcepts.
mentsarelistedthatjustifytheirappearanceinthis
INSTRUCTION: Does the following sentence list. It is safe to assume that the mentioned re-
contain a run-on? – I walked to the park and I searchershavemanymoreachievementsthanthe
orderedahotdog. onesmentioned,butthataprioritisationhasbeen
OUTPUT: No, the sentence is not a run-on. It made.
containstwoindependentclausesseparatedbya
B.3 Subjectivity(Q4)
coordinatingconjunction’and’,whichisanaccept-
ablewayofjoiningtwoclauses. The following example contains subjective ele-
ments in the explanation, as reported by two of
The linguistic terminology in this example (inde-
thethreeannotators.
pendentclauseandcoordinatingconjunction,and
their relation to the concept of a run-on) require INSTRUCTION:Whatarethemainadvantages
furtherexplanationforabroadersetofgoals: For oflearningtocode?
users who are not experts of linguistics and who OUTPUT:Thereareseveraladvantagestolearn-
wanttounderstandtheoutputaswellasforusers inghowtocode,including:1. Betterjobopportunities: There’sahighdemand thatpriceswillincrease”or“Itprovedinevitable
forprogrammersandsoftwaredevelopers,andthe thatthecompanywouldgobankrupt.”
fieldofferslucrativeandstablejobopportunities.
Theexamplesillustratecommonusage,butwithout
Additionally,evenifyoudon’tpursueacareerin acausalexplanationwhytheverbsareappropriate
tech,manyindustriesvalueemployeeswithcoding (exceptthattheyarecommon). Itcanhoweverbe
skills,astechnologybecomesmoreintegratedinto
a suitable, practicalexplanation if the userwants
allaspectsofbusiness.
tounderstandhowtoembed“inevitable”inasen-
2. Improved problem-solving skills: Learning to tence.
code involves breaking big problems down into
small, manageable parts, developing an eye for B.5 MisleadingExplanationsforIncorrect
detailandsharpeningyourlogicalthinking. These Labels
problem-solvingskillscanbeappliedtomanyother The following example contains a wrong answer
areasofyourprofessionalandpersonallife. andexplainsitconfidently. Duringtheannotation,
3. Increasedcreativity: Codingallowsyoutobring themistakewasdiscoveredonlybyonerater,but
yourideastolife,whetheryou’rebuildingaweb- was agreed upon by the other two when it was
site,anapp,oragame. Asyoulearntocodeand indicated.
experimentwithdifferentprogramminglanguages
INSTRUCTION:Createaregularexpressionto
and tools, you’ll find new ways to express your
findallwordswiththreeconsonantsandonevowel.
creativity.
OUTPUT:Thefollowingregularexpressionpat-
4. Morecontrolovertechnology: Withcodingskills,
terncanbeusedtofindallwordswiththreecon-
youcanbetterunderstandhowtechnologyworks
sonantsandonevowel:
and make changes to suit your needs. Whether
\b[^aeiou\s]{3}[aeiou]\b
you’re automating repetitive tasks, customizing
yourwebsite,orfixingbugsinaprogram,coding Explanation:
putsyouincontrol. - \b - Matches the word boundary, which indic-
5. Personalsatisfaction: Finally,learningtocode atesthepositionbetweenawordandanon-word
canprovideimmensepersonalsatisfaction,asyou character. Itensurestomatchthewholeword.
gaintheabilitytocreatesomethingfromnothing -[^aeiou\s]Withinthesquarebrackets,the^
andtacklecomplexchallenges. It’sanempowering symbol indicates negation. So, this character set
andrewardingskilltohave. matches any character that is not a vowel or a
Overall,learningtocodecanprovidevaluablejob whitespacecharacter.
opportunities,improvedproblem-solvingandcre-
-{3}-Specifiesthattheprecedingcharacterset
ativity, greater control over technology, and per- shouldbematchedexactlythreetimes. Therefore,
sonal satisfaction. It’s a valuable skill that can itmatchesthreeconsecutiveconsonants.
benefityouinmanydifferentways.
-[aeiou]-Thischaractersetmatchesanysingle
vowel(a,e,i,ooru).
The clearest subjective element is under point 5,
-\b-Matchesthewordboundaryattheendofthe
where the explanation states that coding is a per-
word,toensurethewholewordismatched.
sonallyempoweringandrewardingskill,without
This regular expression will match words such
a constraint that this feeling may not apply to all
as“milk”,“help”,and“desk”butnotwordslike
individuals.
“hello”,“world”or“me”.
B.4 IllustrativeElements(Q5) Thegivenregularexpressionmatchesonlywords
that consist of three consonants followed by a
For the following example, all three annotators
vowel. Itwouldmatchnoneoftheexamplesgiven
agreedthatitcontainsillustrativeelements.
intheexplanation(“milk”, “help”, and“desk”),
INSTRUCTION:Whatverbdoyouusewiththe
thereforeitismisleading.
word“inevitable”?
OUTPUT:Theverbmostcommonlyusedwiththe
word “inevitable” is “to be,” as in “something
is inevitable.” Other verbs that can be used with
inevitableinclude“seem”,“appear”,“become”,
and “prove”. For example, “It seems inevitable