When is Tree Search Useful for LLM Planning?
It Depends on the Discriminator
ZiruChen1,MichaelWhite1,RaymondMooney2,AliPayani3,YuSu1,HuanSun1
1TheOhioStateUniversity 2TheUniversityofTexasatAustin 3CiscoResearch
{chen.8336, white.1240, su.809, sun.397}@osu.edu
mooney@cs.utexas.edu apayani@cisco.com
Abstract
Inthispaper,weexaminehowlargelanguage
models(LLMs)solvemulti-stepproblemsun-
deralanguageagentframeworkwiththreecom-
ponents: a generator, a discriminator, and a
planningmethod. Weinvestigatethepractical
utility of two advanced planning methods, it-
erativecorrectionandtreesearch. Wepresent
a comprehensive analysis of how discrimina- Figure1: Agenerator-discriminatorframeworkoflan-
tionaccuracyaffectstheoverallperformance guageagents,whereplanningmethodscontroltheinter-
ofagentswhenusingthesetwomethodsora actionbetweenageneratorandadiscriminator,bothof
simpler method, re-ranking. Experiments on whichareusuallyinstantiatedbysomeLLM.
twotasks,text-to-SQLparsingandmathemat-
sharescommontraitswithhowlargelanguagemod-
icalreasoning, showthat: (1)advancedplan-
els(LLMs)solvemulti-steptasks,includingmath-
ning methods demand discriminators with at
ematical reasoning (Wei et al., 2022), multi-hop
least90%accuracytoachievesignificantim-
provementsoverre-ranking;(2)currentLLMs’ questionanswering(Yaoetal.,2023b),andcode
discriminationabilitieshavenotmettheneeds generation (Yang et al., 2023). At each step, an
ofadvancedplanningmethodstoachievesuch LLM searches for possible next actions and gen-
improvements;(3)withLLM-baseddiscrimi- eratestheirlanguagerepresentations(generation).
nators,advancedplanningmethodsmaynotad-
Toevaluatetheactions,theLLMutilizesitselfor
equatelybalanceaccuracyandefficiency. For
anotherLLMtopredicttheoutcomesofactions,in
example,comparedtotheothertwomethods,
theformofrewardsorcorrectness(discrimination).
treesearchisatleast10–20timesslowerbut
leadstonegligibleperformancegains, which Afterwards, it incorporates the outcomes into its
hindersitsreal-worldapplications.1 problem-solvingprocesswithsomestrategytofind
thebestactionsequence(planning).
1 Introduction Motivated by the similarity, we critically ex-
amine how LLMs solve multi-step tasks from a
Planningplaysacrucialroleinintelligentbehav-
language-agentview. Weunifydifferentproblem-
iorsofhumanandAIagents. Sincetheearlystage
solvingproceduresofLLMsintoanagentframe-
of AI research, various methods have been pro-
work(Figure1)consistingofagenerator,adiscrim-
posedtobuildagentsthatcanplanefficientlyand
inator, andaplanningmethod. Underthisframe-
accurately(NewellandSimon,1956;Russelland
work, we investigate the practical utility of more
Norvig, 2010). The problem-solving procedure
advancedplanningmethods,suchastreesearch,in
in these AI agents usually involves three steps:
comparisonwithsimplermethods(e.g. re-ranking).
searching for possible action sequences, predict-
We hypothesize that the discriminator may be a
ingtheirexpectedoutcomeswithaninternalworld
decidingfactorandsystematicallyinvestigatetwo
model,andfindinganactionsequencetoachieve
researchquestions: (RQ1)Howdoesdiscrimina-
the best expected outcome (Russell and Norvig,
tionaccuracyaffecttheperformanceoflanguage
2010;MattarandLengyel,2022). Thisprocedure
agents using different planning methods? (RQ2)
Can LLM-based discriminators correctly assess
1Codeanddatawillbereleasedathttps://github.com/
OSU-NLP-Group/llm-planning-eval. languageagents’actionsinpracticalsettings?
4202
beF
61
]LC.sc[
1v09801.2042:viXraTo this end, we analyze LLMs’ discrimination itsplanningmethod(MattarandLengyel,2022).
abilities and their impact on three categories of Whileitiscommonlybelievedthatdiscrimina-
planningmethods: re-ranking,iterativecorrection, tion is easier than generation for human and AI
and tree search. We comprehensively evaluate agents(Guetal.,2023),Westetal.(2024)posethe
thesemethodsontworeal-worldtasks,text-to-SQL hypothesisthatstate-of-the-artgenerativeAImod-
parsing and mathematical reasoning, with open- els,includingLLMs,maynothavediscrimination
source,closed-source,andfine-tunedLLMdiscrim- abilities matching their generation abilities. This
inators. First,weuseoracleenvironmentalinforma- hypothesis coincides with the findings of Huang
tiontosimulatediscriminatorswithdifferentlevels etal.(2024)andWangetal.(2023a)that,without
ofaccuracy. Thesimulationexperimentsexhibita any external feedback or with obviously absurd
strongcorrelationbetweendiscriminationaccuracy feedback,LLMsmayrecognizesomeoftheirself-
andoveralltaskperformanceamongallthreetypes generated correct plans as wrong. Huang et al.
ofplanningmethods. Then,inanon-oraclesetting, (2024)alsonotethattheperformancegainsofself-
wecloselyinvestigatetheLLM-baseddiscrimina- correction, a kind of iterative correction method,
torsandshowhowenvironmentalobservationscan mayrelyonsomehigh-qualityexternalfeedback,
effectivelyimprovethem. Finally,weconductend- such as checking ground-truth labels or test sets
to-endevaluationsofthediscriminatorsandplan- forplanninglooptermination. However,suchex-
ningmethodstoverifyandstrengthenourfindings. ternalfeedbackusuallydoesnotexistinpractical
Insummary,ourexperimentsshowthat: applicationsbecausesolutionstonewproblemsare
(1)Advancedplanningmethods,i.e.,iterativecor- unknown,andannotatingcomprehensivetestcases
rection and tree search, demand highly accurate canbenontrivialandcostly.
discriminators(≥ 90%accuracy)toachievedecent Distinctfromtheseexistingstudies,ourworkfo-
improvementsoverthesimplermethod,re-ranking. cusesonstudyingtherelationshipbetweendiscrim-
(2)Usingenvironmentalfeedback,weimprovethe inators and planning methods, including but not
discrimination accuracy of LLMs by up to 30.2 limitedtoself-correction,andattemptstoimprove
and8.4absolutepointsontext-to-SQLparsingand LLMs’discriminationcapability. Ourfindingscan
mathematicalreasoning,respectively. Yet,ourend- provide useful guidelines for choosing planning
to-end evaluations suggest they have barely met methodsandimplementinglanguageagentsinprac-
theneedforadvancedplanningmethodstoshow tice. Inlightofourfindings,weencouragefuture
significantimprovementsoverre-ranking. research to thoroughly evaluate language agents
(3) Meanwhile, advanced planning methods may with various practical, non-oracle discriminators.
not adequately balance accuracy and efficiency WealsoadvocatethatimprovingLLM-baseddis-
when using LLM-based discriminators. In our criminatorsisanimportantfuturedirectiontoen-
experiments,comparedtotheothertwomethods, hanceagents’accuracyandefficiencywhenusing
treesearchisatleast10–20timesslowerbutleads advancedplanningmethods.
to negligible performance gains. This accuracy-
3 OurFramework
efficiencytrade-offcanimpedethedeploymentof
treesearchinreal-worldapplications. AsshowninFigure1, wesystematicallyanalyze
differentplanningmethodsinaunifiedgenerator-
2 RelatedWork
discriminatorframework. Ourframeworkconsists
Alotofrecentresearcheffortshavefocusedonad- of a generator that proposes (partial) action se-
vancedplanningmethodsforimprovingthemulti- quences, a discriminator that evaluates the out-
step problem-solving abilities of LLMs (Li et al. comesoftheseactions,andaplanningmethodthat
2023b;Madaanetal.2023;Wangetal.2023b;Yao rankstheactionsaccordingtotheiroutcomesand
etal.2023a,b;Zhouetal.2023,interalia). Despite managestheinteractionbetweenthetwomodels.
differentdesigns,allthesemethodsuseadiscrim- Inthissection,wedescribeeachofthethreecompo-
inatortoevaluatetheagents’actions,orplanning nentsandhowtheyareinstantiatedontext-to-SQL
steps. In fact, instead of planning methods, an parsingandmathematicalreasoning(Section4.1).
agent’s discriminator could be the more critical
3.1 Generator
component. Since incorrect outcome predictions
couldleadtosuboptimalplans,discriminatorsmay Foreachplanningstep,wepromptthegeneratorto
decidetheperformanceofanagent,regardlessof sampleactionsequences(SQLqueriesorPython(a)Re-ranking. (b)IterativeCorrection. (c)TreeSearch.
Figure2:Illustrationofthreecategoriesofplanningmethodsexaminedinourunifiedgenerator-evaluatorframework.
programs for math reasoning). For text-to-SQL implementationsamplesthesamenumberofaction
parsing,weuse1-shotprompting,wheretheexam- sequencesasotherplanningmethodsforfaircom-
pleisretrievedfromthetrainingsetsusingBM25 parison. Then, it uses the discriminator to select
(RobertsonandZaragoza,2009). Formathreason- thebest-scoringoneforthenextround’srevision.
ing,weuseafixed2-shotpromptadaptedfromNi Weallowupto10roundsofcorrections,withearly
etal.(2023b). SeepromptsinAppendixC. exiting when the best plan meets a threshold of
discriminationscore(> 0.99), orthescoreisnot
3.2 Discriminator
improvedfor3consecutiveiterations. Forfaircom-
Givensome(partial)actionsequences,weformu- parison, we prompt the generator to revise plans
latethediscriminationtaskasbinaryquestionan- with0-shotinstructionfollowing(AppendixC)in-
swering (Kadavath et al., 2022; Ke et al., 2023). steadoffew-shot,sincein-contextexamplesmay
The discrimination score of each tested example introduceadditionalinformation.
istheprobabilityof“Yes”beinggeneratedasthe TreeSearch. Treesearchisanotherpopularplan-
nexttoken. Specifically,weprompttheLLMswith ningmethodforlanguageagents,suchasMonte-
thequestion“IstheSQL/pythonprogramcorrect Carlo Tree Search (Chaffin et al., 2022), Pangu
giventheutterance/problem?” togenerateonesin- (Gu et al., 2023), Tree of Thoughts (Yao et al.,
gletokenwithitsprobabilityasthescore. Withthis 2023a), and Language Agent Tree Search (Zhou
formulation, we evaluate three types of LLMs in et al., 2023). It uses a memory structure (e.g., a
ourexperiments(Section4.2). Similartothegener- heap) to store observed partial action sequences
ator,weuse1-shotpromptingwithBM25retrieval andtheirscores. Foreachiteration,itpromptsthe
fortext-to-SQLparsingandafixed2-shotprompt generatorforpossiblenextstepsforthecurrentbest
formathreasoning. DetailsareinAppendixA. partialplan,callsthediscriminatortoevaluatethe
steps,andupdatesthememorywithnewplansand
3.3 PlanningMethods
scores(Figure2c). Ourtreesearchimplementation
Re-ranking. Re-rankingisastraightforwardplan- isakindofMCTS(Zhangetal.,2023):
ningmethod. Aftersamplingafewcompleteaction
(1)Selection: Findthehighestscoringpartialplan
sequencesfromthegenerator,itusesthediscrimi-
inthememory,implementedasaheapstructure.
natortoscorethemandreturnthehighest-scoring
(2)Expansion: Promptthegeneratorforthenext
plan(Figure2a). Althoughsimple,itiscommonly
stepofthispartialplan. Wefollowrecentworkto
used for code generation (Ni et al., 2023a) and
defineasteptobeaSQLclause(Chenetal.,2023c)
mathematicalreasoningtasks(Wangetal.,2023b;
oronelineofPythoncode(Buietal.,2022),which
Lietal.,2023b). Weconsiderre-rankingasabase-
issemanticallymoremeaningful.
lineplanningmethodformoreadvancedones.
(3) Simulation: Reuse the generator to complete
Iterativecorrection. Likere-ranking,iterativecor-
thepartialplansasMonte-Carlosimulations.
rectionstartswiththegeneratorproposingacom-
pleteactionsequence. Thenitleveragesmultiple (4)Evaluation: Evaluatethesimulationswiththe
roundsofrevisiontoimprovetheinitialplanbased discriminator. The score for each new step is the
onthediscriminator’sfeedback(Figure2b). When maximumscoreofallsimulationsstartingfromit.
the generator and the discriminator are the same (5)Backpropagation: Updatethepartialplanwith
LLM,itbecomesaprevalentplanningmethod,self- thenewstepandscore(ifhigher)andinsertthem
correction(Madaanetal.,2023;Shinnetal.,2023; intotheheapmemory. Aftertheupdate,ifthereis
Yaoetal.,2023b;Chenetal.,2024). acompleteplanintheheapmemory,weterminate
While some work uses greedy generation, our thetreesearchandreturnthisplan.4 ExperimentalSetup higher discrimination score than the wrong one
(Bai et al., 2022; Touvron et al., 2023). (2) Clas-
4.1 TasksandDatasets
sification macro F1 (F1): We treat “correct” and
Text-to-SQL Parsing. Text-to-SQL parsing is a “wrong”astwoclassesandcomputethemacroav-
codegenerationtaskofmappingnaturallanguage erageofF1scoresonthesetwolabels. (3)Hit@1
utterances to SQL queries. It requires agents to (H@1): Givenabatchofcandidateprograms,we
groundutterancestodatabaseenvironmentandgen- calculate the percentage where the highest scor-
eratemulti-stepplansasSQLqueries,makingitan ingcandidateiscorrect. (4)Meanreciprocalrank
appropriate testbed in our study. To evaluate lan- (MRR):WecomputethestandardMRRscoreby
guageagents’potentialfortext-to-SQLparsing,we thehighest-rankingcorrectprograminthebatches.
adapttwowidelyuseddatasets,Spider(Yuetal., End-to-End Evaluation. To show the impact of
2018)andBird(Lietal.,2023a). discriminators,weevaluatelanguageagents’end-
We use the entire training split in each dataset to-endperformanceusingourthreeplanningmeth-
topromptorfine-tuneLLMs.2 Forevaluation,due ods,withexecutionaccuracyfortext-to-SQLpars-
to resource and budget constraints, we randomly ingandansweraccuracyformathreasoning.
select 400 and 300 development set examples in
Spider and Bird, respectively. We also note that 5 SimulationExperimentswithOracle
model performance may be lower on our evalua-
5.1 Oracle-BasedDiscriminator
tionsetsbecauseweuniformlysampledexamples
from each difficulty level, while the original de- Toinvestigatehowdiscriminationaccuracyaffects
velopmentsetshaveskeweddistributionstowards theoverallperformanceoflanguageagentsusing
easierexamples(AppendixA.1). differentplanningmethods(RQ1),weutilizeoracle
MathematicalReasoning. Mathematicalreason- environmentalfeedbacktosimulateadiscriminator
ing is a common task for evaluating language withcontrollableaccuracy. Fortext-to-SQLpars-
agents’multi-stepreasoningandplanningcapabili- ing,wecomparethefirstfiverowsintheexecution
ties. With500randomexamplesfromGSM8K’s resultsofpredictedandgoldSQLqueriesandcal-
development set (Cobbe et al., 2021), we follow culatetheirtablecelloverlaps(AppendixA.4). For
program of thoughts (Chen et al., 2023b) to test mathematicalreasoning,wecomparethepredicted
theagents’abilitytoplaninPythonprogramsand Pythonprograms’answerswiththegroundtruth.
solvethesegradeschoolmathwordproblems. We use a probability-based threshold τ to con-
troltheaccuracyofeachsimulateddiscriminator
4.2 Models
(Gaoetal.,2022). Whenevaluatingeachplan,the
In all experiments, we use CodeLlama-13B- discriminatorfirstcomputesascoreswithoracle
Instructasthegeneratorinourframework. Wealso information. Then, it uses a random function to
evaluatethreekindsofLLMsasthediscriminator: generate a number p ∈ [0,1). If p < τ, the dis-
(1) open-source LLMs: CodeLlama-7B-Instruct criminatorreturnsthescores. Otherwise,itreturns
andCodeLlama-13B-Instruct(Rozièreetal.,2024), aninvertedscore1−s. Inthisway,weensurethat
(2)closed-sourceLLMs: GPT-3.5-Turbo(OpenAI, thediscriminator’saccuracyisatmostτ.
2022)andGPT-4-Turbo(OpenAI,2023),and(3)
fine-tunedLLMs: CodeLlama-7B-Instruct-FTand 5.2 ResultsandAnalysis
CodeLlama-13B-Instruct-FT. Their implementa- As shown in Figure 3, discrimination accuracy
tiondetailsareinAppendixA.3. Forbrevity, we closelycorrelateswiththeperformanceofagents
willomit“Instruct”inmodelnames. on all three datasets, no matter which planning
methodisused. Forinstance,theperformanceof
4.3 Evaluation
re-rankingagentsimproveslinearlyasweincrease
IntrinsicEvaluation. Wemeasurethediscrimina- the discrimination accuracy threshold, setting up
tionabilitiesofLLMswithfourintrinsicmetrics. a strong baseline for agents using other planning
(1) Discrimination accuracy (Acc): Given a pair methods. Wealsonotethatittakesaround80%dis-
of correct and wrong programs, we calculate the criminationaccuracyforallagentstooutperform
percentage where the correct program obtains a greedygenerationontext-to-SQLparsing,demon-
strating the task’s difficulty. To answer RQ1, we
2InBird,weexcludetrainingexamplesforonedatabase,
retail_world,duetoannotationerrors. further analyze the performance of agents using(a)Spider. (b)Bird. (c)GSM8K.
Figure3: End-to-endevaluationresults(thefirstrow)andaverageinferencetimeinlogscale(thesecondrow)of
oursimulationexperimentswithoracle.
iterativecorrectionandtreesearchasfollows: remainsakeyproblemforAIagents.
Advancedplanningmethodsdemandhighly Monte-Carlotreesearchcanbeunstable,es-
accuratediscriminators. Foriterativecorrection pecially in the early stages. We observe that it-
agents, their performance usually cannot distin- erativecorrectionoutperformstreesearchonBird
guishfromthere-rankingbaselinesuntilwemaxi- (Figure 3b) when the accuracy threshold is 1.0.
mizethethresholdτ = 1.0(Figure3). Thisfinding Thisobservationmaybecausedbytheinstability
resonateswithHuangetal.(2024)thathigh-quality ofMonte-Carlotreesearch. WefirstnotethatMc-
feedbackmaybethekeytothesuccessofiterative Nemar’stestfindsnodifferencebetweeniterative
correction. Moreinterestingly,treesearchagents correctionandtreesearch(p > 0.05),despitetheir
consistentlyunderperformtheothertwowhenthe performancegap(29.3vs32.7). Therationalesare
discriminationaccuracythresholdτ ≤ 0.8. More- discussedinAppendixB.Furthermore,weanalyze
over,whenraisingthethresholdto0.9,weobserve all 25 examples of which iterative correction de-
asharpincreaseoftheirperformance,withwhich rives the correct answer but tree search fails. In
theystarttobeatotherkindsofagents. 12outofthe25examples(48%),treesearchfails
toselectthecorrectpartialplanwhenthediscrim-
Advanced planning methods may not ade-
ination scores are the same. Especially, this can
quatelybalanceaccuracyandefficiency. Bycal-
happenintheearlystagesoftreesearch,wherea
culating the average inference time per example
correct program has not yet been discovered and
(Figure3),wefindthatourimplementationoftree
all the steps receive a score of 0 from the oracle
searchisatleast10–20timesslowerthantheother
discriminator. Thus,weconsiderthisunderperfor-
twoplanningmethods,mainlyduetofrequentgen-
manceaconsequenceofsearchinstability.
erationofMonte-Carlosimulations(Zhangetal.,
2023). While we can remove the simulations to
6 LLM-BasedDiscriminators
bemoreefficientandevaluatepartialplans,inour
preliminary study, we find LLMs would struggle Whilewehaveshownthatiterativecorrectionand
inthissetting. Thisaccuracy-efficiencytrade-off tree search work well with oracle discriminators,
mayhinderreal-worldapplicationsoftreesearch itremainsunclearwhetherLLM-baseddiscrimina-
methods. Meanwhile,theinferencetimeforitera- torscancorrectlyassesslanguageagents’actions
tivecorrectionincreasesastheaccuracythreshold (RQ2). Toanswerthisquestion,weleveragegen-
is raised, suggesting more iterations are required erator outputs in the simulation experiments and
toderiveacorrectanswer. Thisindicatesthatde- re-label them with ground-truths to evaluate the
velopingefficientandaccurateplanningmethods LLMs’discriminationaccuracy(AppendixA.2).Spider Bird GSM8K‡
Models
Acc F1 H@1 MRR Acc F1 H@1 MRR Acc F1 H@1 MRR
CodeLlama-7B 54.0 37.1 56.0 62.3 44.6 46.7 13.0 18.0 48.6 38.7 36.2 46.9
CodeLlama-13B 58.2 37.1 57.0 63.1 49.4 46.7 12.7 18.3 62.2 38.7 41.8 51.0
CodeLlama-7B-FT 62.4 60.3 59.5 64.6 52.4 46.7 14.3 19.1 - - - -
CodeLlama-13B-FT 69.7 67.2 61.3 65.7 62.1 46.7 16.0 20.5 - - - -
GPT-3.5-Turbo 67.0 47.3 59.0 64.3 64.3 35.7 16.0 20.5 72.1 49.1 46.6 54.0
GPT-4-Turbo 76.5 54.9 63.0 66.7 76.2 50.1 20.3 23.0 93.8 91.1 59.8 61.6
Table1: IntrinsicevaluationresultsofnaiveLLMs’discriminationabilities. Thebestperformanceisinboldfor
open-sourceandclosed-sourceLLMs. ‡SinceGSM8K’strainingsetdoesnothaveprogramofthoughtsannotated
forfine-tuning,wehaveonlyevaluatedthemodelswithin-contextlearning.
CodeLlama-13B GPT-3.5-Turbo CodeLlama-13B-FT
Spider Bird GSM8K Spider Bird GSM8K Spider Bird
NaiveDiscriminator 58.2 49.4 62.2 67.0 64.3 72.1 69.7 62.1
+ExecutabilityCheck 78.7 78.8 64.5 84.8 86.3 73.2 83.6 82.2
++ExecutionResult 83.6 79.6 70.6 90.0 89.2 76.5 88.5 85.1
Improvement 25.4 30.2 8.4 23.0 24.9 4.4 18.8 23.0
Table2: Discriminationaccuracyofobservation-enhancedLLMs. Thebestperformance(inbold)isachieved
usingbothkindsofenvironmentalobservations. Wealsounderlinethelargestimprovementforeachdataset.
6.1 NaiveDiscriminators (Nietal.,2023a). Ifaprogramisnon-executable,
weuseERRORtorepresentitsexecutionresult.
As Table 1 shows, most open-source LLMs have
Evaluation results (Table 2) show that these
mediocrediscriminationabilities. Afterfine-tuning,
two non-oracle environmental observations can
CodeLlama-13B-FTcouldreachthesamelevelof
effectively improve LLMs’ discrimination accu-
performance as GPT-3.5. In comparison, closed-
racy. Enhancedwithenvironmentalobservations,
sourceLLMsexhibitstrongerdiscriminationabil-
CodeLlama-13Bcanobtainupto25.4,30.2,and
ities,withGPT-4achievingthebestperformance
8.4pointsabsoluteaccuracygainonSpider,Bird,
acrossallthreedatasets. AlthoughGPT-4has93.8
andGSM8K,respectively. Fortheothertwomod-
discriminationaccuracyonGSM8Kandisalsobet-
els,wealsoobservesignificantgainscomparedto
terthanGPT-3.5ontext-to-SQLparsing,duetoits
thenaivediscriminatorbaseline. Suchnotableim-
highcost,wewilluseGPT-3.5inourexperiments.
provementsalsohighlighttheimportanceoffilter-
6.2 Observation-EnhancedDiscriminators ingoutnon-executableprograms,orinvalidplans,
duringplanning.
ToimproveLLMs’discriminationabilities,wecon-
duct an error analysis for CodeLlama-13B on its
7 End-to-EndEvaluation
worst-performingintrinsicevaluationset,Bird. We
sample50pairsofSQLqueriesfromtheBirdin- Whilewehaveevaluatedtheirdiscriminationabili-
trinsicevaluationsetwithincorrectpredictions. In tieswithafixedtestset,toanswerRQ2,wewonder
25ofthe50pairs(50%),CodeLlama-13Bassigns ifLLMscancorrectlyassessconstantlychanging
ahigherscoretonon-executableSQLqueries. Con- setsofprogramsinactualplanningprocesses. To
sequently,nomatterusingwhichplanningmethod, thisend,weevaluatetheend-to-endperformance
language agents could hardly perform well with oflanguageagentswithLLM-baseddiscriminators
suchdiscriminators. andthethreeplanningmethods.
Motivatedbyourerroranalysis,wefirstpropose
7.1 Text-to-SQLParsing
toaddaprogramexecutabilitycheckasasafeguard
forLLMs. Ifaprogramisnon-executable,ourdis- As shown in Table 3, agents using naive LLM-
criminatorwoulddiscardLLMs’scoreandreturn baseddiscriminatorsdonotperformwellontext-
0. Otherwise, it returns the original LLM score. to-SQL parsing. On Spider, the re-ranking agent
Besidesexecutabilitycheck,weincorporatetheex- using CodeLlama-13B-FT has the best accuracy
ecutionresultsofpredictedprograms(first5table (61.5),whichisstilllowerthangreedygeneration
rowsofSQLqueriesoranswerofPythonprogram) (62.3) that requires no planning and is more ef-
intothein-contextexamplesandfine-tuningdata ficient. On Bird, GPT-3.5-Turbo and re-rankingSpider(GreedyGen=62.3) Bird(GreedyGen=16.0)
Discriminators
Re-ranking Iter.Correct. TreeSearch Re-ranking Iter.Correct. TreeSearch
CodeLlama-13B 57.5 51.7 55.5 13.3 13.3 13.3
GPT-3.5-Turbo 58.3 52.7 56.2 18.0 17.3 14.0
CodeLlama-13B-FT 61.5 51.7 56.0 14.3 13.0 13.0
CodeLlama-13BE 65.5 62.0 62.5 21.0 24.3 22.7
GPT-3.5-TurboE 67.0 67.5 66.0 22.3 25.0 22.7
CodeLlama-13B-FTE 70.3 68.0 67.5 23.7 26.3 21.7
OracleSimulation(τ =1.0) 71.0 76.0∗ 76.2∗ 27.0 32.7∗ 29.3
Table3: End-to-endexecutionaccuracyontext-to-SQLparsing. Thebestperformanceforeachdiscriminator
is in bold. The overallbestperformance for naive and enhanced discriminators on each dataset is underlined.
EObservation-enhanceddiscriminators. ∗Statisticallysignificant(p<0.05;McNemar’s)comparedtore-ranking
withthesamediscriminatoroneachdataset. Weonlyobservesuchimprovementwiththeoraclediscriminator.
showanaccuracyof18.0,whichisslightlyhigher Discriminators Re-rankingIter.Correct.TreeSearch‡
than greedy generation (16.0). In addition to the
CodeLlama-13B 39.7 10.2 41.0
mediocre performance, we find that when using GPT-3.5-Turbo 47.0 37.0 50.0
naivediscriminators,iterativecorrectionandtree CodeLlama-13BE 42.8 42.2 46.0
searchconsistentlyshowworseorthesameperfor- GPT-3.5-TurboE 47.6 48.4 51.0
mance as re-ranking. These results mostly agree
OracleSimulation
64.1 66.0 73.0
withourfindingsinpreviousexperimentsthat(1) (τ =1.0)
advanced planning methods need strong discrim-
Table 4: End-to-end answer accuracy on GSM8K
inators, and (2) naive LLM-based discriminators
(GreedyGen=39.4). Notationshavethesamemeaning
arenotaccurateenough. asinTable3. McNemar’sdoesnotfinddifferencebe-
Afterenhancingthediscriminatorswithtwoen- tweenmethodsonGSM8K.‡Treesearchisevaluated
vironmentalobservations(Section6.2),weeffec- on100randomlyselectedexamplesfromthe500evalu-
ationexamplesduetoslowinferencespeed(Figure3c).
tivelyimprovetheagents’performancewithoutany
For McNemar’s, we comparetree search results with
modificationstothegeneratorortheplanningmeth-
thoseofre-rankingonthesame100examples.
ods. In 5 of the 6 experiments, CodeLlama-13B-
FTE resultsinthebestexecutionaccuracyamong ing GPT-3.5-Turbo as the discriminator, it is less
alldiscriminators. Italsoleadstotheoverallbest severe because GPT would sometimes assign a
performanceonSpiderwithre-ranking(70.3)and highscore(> 0.99)totheinitialPythonprogram.
on Bird with iterative correction (26.3), showing These scores trigger an early exit condition in it-
theeffectivenessoffine-tuningLLMsfordiscrimi- erativecorrection(Section3.3)andstoptheagent
nationandusingenvironmentalobservations. fromcallingthegeneratortoaddanynaturallan-
guage,thusavoidingtheissue. Thesefindingsecho
7.2 MathematicalReasoning related analysis on self-correction (Stechly et al.,
2023;Valmeekametal.,2023;Huangetal.,2024).
The most interesting result in mathematical rea-
Withanexecutabilitycheck,enhanceddiscrim-
soning evaluation (Table 4) is the failure of itera-
inatorshelpmitigatethisissueiniterativecorrec-
tive correction with naive discriminators. When
tion,whichnowachievesbetterperformance(42.2
prompting the generator CodeLlama-13B for 0-
and 48.4) than greedy generation (39.4). Over-
shotcorrection,itwoulddisregardtheinstruction
all, the tree search agent using GPT-3.5-TurboE
to “generate a fixed python program” (Appendix
achieves the best answer accuracy. Nevertheless,
C),copytheprogramtobemodified,andgenerate
McNemar’stestfindsnodifference(p > 0.05)be-
explanations and correction steps in natural lan-
tweentheperformanceofre-ranking(47.6)andthat
guage. Suchnaturallanguagesteps,usuallyhaving
ofiterativecorrection(48.4)ortreesearch(51.0).
somelexicaloverlapwiththemathproblem,would
increase the discrimination score of LLMs while
7.3 Analysis
being non-executable. As a result, our iterative
correction agent only has 10.2 answer accuracy Tobetterunderstandtheend-to-endevaluationre-
when using CodeLlama-13B to evaluate its own sults,weconductanin-depthanalysisofexamples
generation. While this issue also exists when us- wherere-rankingreturnsthecorrectprogram,butSpider Bird GSM8K
ErrorType
Iter.Correct. TreeSearch Iter.Correct. TreeSearch Iter.Correct. TreeSearch
Discrimination 29(78.4%) 17(60.7%) 9(52.9%) 12(50.0%) 30(62.5%) 6(66.7%)
Exploration 8(21.6%) 11(39.3%) 8(47.1%) 12(50.0%) 18(37.5%) 3(33.3%)
Total 37 28 17 24 48 9
Table5: Erroranalysisofexampleswherere-rankingoutperformsadvancedplanningmethods. Welisttheactual
numberoferrorcasesandtheirpercentagesinparenthesisforeachdatasetandplanningmethod.
iterativecorrectionortreesearchdoesnot(Table explorationofplanningmethodsinvariousways,
5). Specifically,weanalyzecasesofthestrongest suchaslooseningterminationconditions,increas-
discriminators, CodeLlama-13B-FTE for text-to- ingthenumberofgenerationsamplesforeachstep,
SQLparsingandGPT-3.5-TurboE formathemat- andadjustingsomehyperparametersformoredi-
icalreasoning,anddividethemintotwokindsof verseprogramsamples. Yet,alltheseadjustments
errors. (1)Discriminationerror: Thediscriminator can slow down the planning methods and reduce
assigns a higher score for wrong programs than thelanguageagents’efficiency. Additionally,we
correctones,whichisnotrecoverablebyanyplan- notethatthesestrategiesmaynotalwaysresultin
ningmethod. (2)Explorationerror: Theplanning betterperformance,asthediscriminatorsmaygive
methodhasnotfoundthecorrectprogrambefore unseenwrongprogramsahigherscore.
termination. Ouranalysissuggeststhat: Forthesereasons,iterativecorrectionandtree
LLM-baseddiscriminatorshavenotyetmet searchcannotgaindecentimprovementoverre-
theneedsofadvancedplanningmethods. Across ranking with the same LLM-based discriminator.
alldatasets,50%ormorediscriminationerrorsare On text-to-SQL parsing, tree search even shows
observedineachplanningmethod. OnSpider,the worse performance than re-ranking when using
numberofsucherrorsiniterativecorrectionisas CodeLlama-13B-FTE (Table 3: 67.5 vs 70.3 on
largeas29outof37(78.4%). Infact,amongthe Spider; 21.7vs23.7onBird). Moresurprisingly,
29 errors, iterative correction has already found onGSM8K,advancedplanningmethodsmaynot
thecorrectSQLqueriesfor15(40.5%ofthetotal performmuchbetterthanre-rankingevenwiththe
37 errors) of them. However, not only does the oraclediscriminator(p > 0.05;McNemar’s). Ad-
discriminatorfailtotriggerearlyexits,butitalso mittedly, some of the performance gains appear
assigns a higher score for wrong SQL queries in considerable,butMcNemar’stellsustherearestill
newiterations. Consequently,theseerroneousSQL decentchancesofthesimpleragentoutperforming
queriesoverridetheoriginallycorrectones,leading amorecomplexone(AppendixB).
toanoverallperformancedrop. Thesameissueis
8 Conclusions
alsoseriousintreesearch. Whenanincorrectpar-
tialprogramreceivesahighdiscriminationscore, This paper presents a thorough investigation into
tree search will commit to it and hardly explore therelationshipbetweendiscriminationaccuracy
otherpossibilities,includingthecorrectpartialpro- andperformanceofplanningmethodsinlanguage
grams. Suchdiscriminationerrorsusuallycannot agents. Through comprehensive experiments on
berecoveredbytheplanningmethodsthemselves, text-to-SQLparsingandmathematicalreasoning,
unlesstheyfindanothercorrectprogramwitheven wefindthat: Discriminationaccuracystronglycor-
higherscores. Thisfindingalsodemonstratesthat relates with the overall performance of language
determiningearlyexitsusingoracleinformationin agentsusingdifferentplanningmethodsandalsoaf-
iterativecorrectionmayintroducealargerbenefit fectstheirefficiency(answertoRQ1). LLM-based
thanpreviouslythought(Huangetal.,2024). discriminatorscancorrectlyassessadecentnum-
Advancedplanningmethodsneedmorethor- beroflanguageagents’actionswiththeirenviron-
ough exploration. For the remaining cases, we mentalobservations,buttheyarestillnotaccurate
observethatadvancedplanningmethodshavenot enoughforadvancedplanningmethods(answerto
foundacorrectprogrambeforeterminating,which RQ2). Futureresearchshouldinvestigatethedevel-
we call exploration errors. This kind of error cir- opmentofmoreaccuratediscriminationmodelsfor
clesourdiscussionbacktotheaccuracy-efficiency languageagents,e.g.byimprovingtheirgrounded
trade-offmentionedinoursimulationexperiments understanding of execution results beyond error
withoracle(Section5.2). Indeed,wecanextendthe signals.Limitations methodsinfuturework.
Experiments with Other Models. In this study, Acknowledgements
wefocusonstudyingthegenerationanddiscrim-
WewouldliketothankcolleaguesfromtheOSU
inationofinstruction-tunedLLMsthathaveseen
NLPgroupfortheirthoughtfulcomments. Thisre-
codedataduringpre-training. Thisconsideration
searchwassupportedinpartbyasponsoredaward
is because: (a) They may have better in-context
fromCiscoResearch,NSFIIS-1815674,NSFCA-
learningperformanceonourtwotasks,text-to-SQL
REER #1942980, NSF OAC-2112606, and Ohio
parsingandmathematicalreasoningwithprogram-
SupercomputerCenter(Center,1987). Theviews
of-thought(Nietal.,2023b);(b)Wewanttolever-
andconclusionscontainedhereinarethoseofthe
agetheir0-shotinstructionfollowingcapabilities
authorsandshouldnotbeinterpretedasrepresent-
in iterative correction for fair comparisons with
ingtheofficialpolicies,eitherexpressedorimplied,
otherplanningmethods;(c)ForGSM8Kproblems,
oftheU.S.government. TheU.S.Governmentis
LLMstendtogeneratenaturallanguageplansin-
authorizedtoreproduceanddistributereprintsfor
steadofprogramswith2-shotprompting,andsome
Government purposes notwithstanding any copy-
instructionsotherthanin-contextexampleshelpto
rightnoticeherein.
mitigatethisissue. Futureresearchmayextendour
studytootherLLMsofcodeandconductanabla-
tionstudyofinstruction-tuning’simpactonmodels’
References
discriminationaccuracy.
ExperimentswithNaturalLanguagePlans. Our Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda
Askell, AnnaChen, NovaDasSarma, DawnDrain,
study focuses on the generation and discrimina-
Stanislav Fort, Deep Ganguli, Tom Henighan,
tion of formal language plans, i.e., programs, as NicholasJoseph,SauravKadavath,JacksonKernion,
theycandirectlyinteractwiththeenvironment. Al- TomConerly,SheerEl-Showk,NelsonElhage,Zac
though feasible for mathematical reasoning (Wei Hatfield-Dodds, Danny Hernandez, Tristan Hume,
ScottJohnston,ShaunaKravec,LianeLovitt,Neel
et al., 2022), natural language plans require an-
Nanda, Catherine Olsson, Dario Amodei, Tom
other semantic parsing step to convert them into
Brown, Jack Clark, Sam McCandlish, Chris Olah,
actionsdefinedinthecorrespondingenvironment, BenMann,andJaredKaplan.2022. Trainingahelp-
whichmayintroduceintermediateerrorsandadd fulandharmlessassistantwithreinforcementlearn-
ingfromhumanfeedback.
noisetoouranalysis. Therefore,weconducttheex-
perimentswithformallanguageplansusingLLMs
Nghi Bui, Yue Wang, and Steven C.H. Hoi. 2022.
trainedoncodedata. Asafuturedirection,itwould Detect-localize-repair:Aunifiedframeworkforlearn-
be interesting to extend our study to natural lan- ingtodebugwithCodeT5. InFindingsoftheAssoci-
ationforComputationalLinguistics: EMNLP2022,
guageplansandseehowtheintermediatesemantic
pages812–823,AbuDhabi,UnitedArabEmirates.
parsingstepwouldaffecttheoverallperformance
AssociationforComputationalLinguistics.
ofagentsformathematicalreasoning.
Impact of Generators on Planning Methods. OhioSupercomputerCenter.1987. Ohiosupercomputer
center.
While our work focuses on studying the relation-
shipbetweendifferentdiscriminatorsandplanning AntoineChaffin,VincentClaveau,andEwaKijak.2022.
methods, we acknowledge that the generator can PPL-MCTS:Constrainedtextualgenerationthrough
alsoactivelyaffectdifferentplanningmethods. For discriminator-guidedMCTSdecoding. InProceed-
ings of the 2022 Conference of the North Ameri-
example,wecantransformthegenerator’sperplex-
can Chapter of the Association for Computational
ity into a probability and multiply it by the dis- Linguistics: HumanLanguageTechnologies,pages
criminator’s score. We exclude such uses of the 2953–2967, Seattle, UnitedStates.Associationfor
generatorbecauseinourpreliminaryexperiments, ComputationalLinguistics.
we find that incorporating its perplexity leads to
ShijieChen,ZiruChen,HuanSun,andYuSu.2023a.
mixedresults. Theseresultsmakeitevenharderto
Errordetectionfortext-to-SQLsemanticparsing. In
analyzehowlanguageagentsbehavewhenusing FindingsoftheAssociationforComputationalLin-
differentplanningmethods. Thus,weexcludethe guistics: EMNLP2023,pages11730–11743,Singa-
pore.AssociationforComputationalLinguistics.
generatortohaveaclearpictureofhowdiscrimina-
torscanaffectplanningmethods. Nevertheless,itis
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
worthstudyingthegenerator’simpactonplanning William W. Cohen. 2023b. Program of thoughtsprompting: Disentanglingcomputationfromreason- PeiKe,FeiHuang,FeiMi,YashengWang,QunLiu,Xi-
ingfornumericalreasoningtasks. Transactionson aoyanZhu,andMinlieHuang.2023. DecompEval:
MachineLearningResearch. Evaluatinggeneratedtextsasunsuperviseddecom-
posed question answering. In Proceedings of the
Xinyun Chen, Maxwell Lin, Nathanael Schärli, and 61stAnnualMeetingoftheAssociationforCompu-
DennyZhou.2024. Teachinglargelanguagemodels tationalLinguistics(Volume1: LongPapers),pages
toself-debug. InTheTwelfthInternationalConfer- 9676–9691,Toronto,Canada.AssociationforCom-
enceonLearningRepresentations. putationalLinguistics.
Ziru Chen, Shijie Chen, Michael White, Raymond JinyangLi, BinyuanHui, GeQu, JiaxiYang, Binhua
Mooney,AliPayani,JayanthSrinivasa,YuSu,and Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying
HuanSun.2023c. Text-to-SQLerrorcorrectionwith Geng,NanHuo,XuanheZhou,ChenhaoMa,Guo-
language models of code. In Proceedings of the liangLi,KevinChang,FeiHuang,ReynoldCheng,
61stAnnualMeetingoftheAssociationforCompu-
andYongbinLi.2023a. CanLLMalreadyserveas
tationalLinguistics(Volume2: ShortPapers),pages
a database interface? a BIg bench for large-scale
1359–1372,Toronto,Canada.AssociationforCom- databasegroundedtext-to-SQLs. InThirty-seventh
putationalLinguistics. ConferenceonNeuralInformationProcessingSys-
temsDatasetsandBenchmarksTrack.
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
MarkChen,HeewooJun,LukaszKaiser,Matthias
YifeiLi,ZeqiLin,ShizhuoZhang,QiangFu,BeiChen,
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Jian-GuangLou,andWeizhuChen.2023b. Making
Nakano, Christopher Hesse, and John Schulman.
language models better reasoners with step-aware
2021. Training verifiers to solve math word prob-
verifier. In Proceedings of the 61st Annual Meet-
lems.
ingoftheAssociationforComputationalLinguistics
(Volume1: LongPapers),pages5315–5333,Toronto,
Allen L. Edwards. 1948. Note on the “correction for
Canada.AssociationforComputationalLinguistics.
continuity”intestingthesignificanceofthediffer-
encebetweencorrelatedproportions. InPsychome-
AmanMadaan, NiketTandon,PrakharGupta,Skyler
trika,volume13,page185–187.
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
GeGao,EunsolChoi,andYoavArtzi.2022. Simulat-
Shashank Gupta, Bodhisattwa Prasad Majumder,
ingbanditlearningfromuserfeedbackforextractive
Katherine Hermann, Sean Welleck, Amir Yazdan-
questionanswering. InProceedingsofthe60thAn-
bakhsh, and Peter Clark. 2023. Self-refine: Itera-
nualMeetingoftheAssociationforComputational
tiverefinementwithself-feedback. InThirty-seventh
Linguistics (Volume 1: Long Papers), pages 5167–
ConferenceonNeuralInformationProcessingSys-
5179,Dublin,Ireland.AssociationforComputational
tems.
Linguistics.
MarceloG.MattarandMátéLengyel.2022. Planning
YuGu,XiangDeng,andYuSu.2023. Don’tgenerate,
inthebrain. Neuron,110(6):914–934.
discriminate: A proposal for grounding language
modelstoreal-worldenvironments. InProceedings
Quinn McNemar. 1947. Note on the sampling error
of the 61st Annual Meeting of the Association for
ofthedifferencebetweencorrelatedproportionsor
ComputationalLinguistics(Volume1: LongPapers),
percentages. In Psychometrika, volume 12, page
pages4928–4949,Toronto,Canada.Associationfor
153–157.
ComputationalLinguistics.
A. Newell and H. Simon. 1956. The logic theory
Jie Huang, Xinyun Chen, Swaroop Mishra,
machine–acomplexinformationprocessingsystem.
Huaixiu Steven Zheng, Adams Wei Yu, Xiny-
IRE Transactions on Information Theory, 2(3):61–
ingSong,andDennyZhou.2024. Largelanguage
79.
models cannot self-correct reasoning yet. In The
Twelfth International Conference on Learning AnsongNi,SriniIyer,DragomirRadev,VeselinStoy-
Representations. anov,Wen-TauYih,SidaWang,andXiVictoriaLin.
2023a. LEVER:Learningtoverifylanguage-to-code
SauravKadavath,TomConerly,AmandaAskell,Tom
generation with execution. In Proceedings of the
Henighan, Dawn Drain, Ethan Perez, Nicholas
40thInternationalConferenceonMachineLearning,
Schiefer,ZacHatfield-Dodds,NovaDasSarma,Eli
volume 202 of Proceedings of Machine Learning
Tran-Johnson, Scott Johnston, Sheer El-Showk,
Research,pages26106–26128.PMLR.
Andy Jones, Nelson Elhage, Tristan Hume, Anna
Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, AnsongNi,PengchengYin,YilunZhao,MartinRiddell,
Deep Ganguli, Danny Hernandez, Josh Jacobson, TroyFeng, RuiShen, StephenYin, YeLiu, Semih
JacksonKernion,ShaunaKravec,LianeLovitt,Ka- Yavuz, Caiming Xiong, Shafiq Joty, Yingbo Zhou,
malNdousse,CatherineOlsson,SamRinger,Dario DragomirRadev,andArmanCohan.2023b. L2ceval:
Amodei,TomBrown,JackClark,NicholasJoseph, Evaluatinglanguage-to-codegenerationcapabilities
BenMann,SamMcCandlish,ChrisOlah,andJared oflargelanguagemodels.
Kaplan.2022. Languagemodels(mostly)knowwhat
theyknow. OpenAI.2022. Chatgpt.OpenAI.2023. Gpt-4technicalreport. reasoningviadebate. InFindingsoftheAssociation
forComputationalLinguistics: EMNLP2023,pages
Stephen Robertson and Hugo Zaragoza. 2009. The 11865–11881,Singapore.AssociationforComputa-
probabilistic relevance framework: Bm25 and be- tionalLinguistics.
yond. Found.TrendsInf.Retr.,3(4):333–389.
XuezhiWang,JasonWei,DaleSchuurmans,QuocVLe,
BaptisteRozière,JonasGehring,FabianGloeckle,Sten EdH.Chi,SharanNarang,AakankshaChowdhery,
Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, andDennyZhou.2023b. Self-consistencyimproves
JingyuLiu,RomainSauvestre,TalRemez,Jérémy chainofthoughtreasoninginlanguagemodels. In
Rapin,ArtyomKozhevnikov,IvanEvtimov,Joanna TheEleventhInternationalConferenceonLearning
Bitton,ManishBhatt,CristianCantonFerrer,Aaron Representations.
Grattafiori, Wenhan Xiong, Alexandre Défossez,
JadeCopet,FaisalAzhar,HugoTouvron,LouisMar- JasonWei,XuezhiWang,DaleSchuurmans,Maarten
tin,NicolasUsunier,ThomasScialom,andGabriel Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,
Synnaeve.2024. Codellama: Openfoundationmod- andDennyZhou. 2022. Chain-of-thoughtprompt-
elsforcode. ing elicits reasoning in large language models. In
AdvancesinNeuralInformationProcessingSystems,
StuartRussellandPeterNorvig.2010. ArtificialIntel- volume35,pages24824–24837.CurranAssociates,
ligence: A Modern Approach, 3 edition. Prentice Inc.
Hall.
PeterWest,XimingLu,NouhaDziri,FaezeBrahman,
Noah Shinn, Federico Cassano, Ashwin Gopinath, LinjieLi,JenaD.Hwang,LiweiJiang,JillianFisher,
KarthikRNarasimhan,andShunyuYao.2023. Re- AbhilashaRavichander,KhyathiChandu,Benjamin
flexion: languageagentswithverbalreinforcement Newman,PangWeiKoh,AllysonEttinger,andYejin
learning. In Thirty-seventh Conference on Neural Choi.2024. ThegenerativeAIparadox: “whatitcan
InformationProcessingSystems. create,itmaynotunderstand”. InTheTwelfthInter-
nationalConferenceonLearningRepresentations.
KayaStechly,MatthewMarquez,andSubbaraoKamb-
hampati.2023. GPT-4doesn’tknowit’swrong: An Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
analysis of iterative prompting for reasoning prob- Chaumond,ClementDelangue,AnthonyMoi,Pier-
lems. InNeurIPS2023FoundationModelsforDeci- ricCistac,TimRault,RemiLouf,MorganFuntow-
sionMakingWorkshop. icz,JoeDavison,SamShleifer,PatrickvonPlaten,
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- Teven Le Scao, Sylvain Gugger, Mariama Drame,
bert, Amjad Almahairi, Yasmine Babaei, Nikolay QuentinLhoest,andAlexanderRush.2020. Trans-
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti formers:State-of-the-artnaturallanguageprocessing.
Bhosale,DanBikel,LukasBlecher,CristianCanton InProceedingsofthe2020ConferenceonEmpirical
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu, Methods in Natural Language Processing: System
JudeFernandes,JeremyFu,WenyinFu,BrianFuller, Demonstrations,pages38–45,Online.Association
CynthiaGao,VedanujGoswami,NamanGoyal,An- forComputationalLinguistics.
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa, JohnYang,AksharaPrabhakar,KarthikRNarasimhan,
IsabelKloumann,ArtemKorenev,PunitSinghKoura, and Shunyu Yao. 2023. Intercode: Standardizing
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di- andbenchmarkinginteractivecodingwithexecution
anaLiskovich,YinghaiLu,YuningMao,XavierMar- feedback. InThirty-seventhConferenceonNeural
tinet,TodorMihaylov,PushkarMishra,IgorMoly- InformationProcessingSystemsDatasetsandBench-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen- marksTrack.
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama- Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay- Thomas L. Griffiths, Yuan Cao, and Karthik R
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Narasimhan. 2023a. Tree of thoughts: Deliberate
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan, problem solving with large language models. In
Melanie Kambadur, Sharan Narang, Aurelien Ro- Thirty-seventh Conference on Neural Information
driguez,RobertStojnic,SergeyEdunov,andThomas ProcessingSystems.
Scialom.2023. Llama2: Openfoundationandfine-
tunedchatmodels. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik R Narasimhan, and Yuan Cao.
KarthikValmeekam,MatthewMarquez,andSubbarao 2023b. React: Synergizing reasoning and acting
Kambhampati.2023. Investigatingtheeffectiveness inlanguagemodels. InTheEleventhInternational
of self-critiquing in LLMs solving planning tasks. ConferenceonLearningRepresentations.
In NeurIPS 2023 Foundation Models for Decision
MakingWorkshop. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,
DongxuWang,ZifanLi,JamesMa,IreneLi,Qingn-
Boshi Wang, Xiang Yue, and Huan Sun. 2023a. Can ingYao,ShanelleRoman,ZilinZhang,andDragomir
ChatGPTdefenditsbeliefintruth? evaluatingLLM Radev.2018. Spider: Alarge-scalehuman-labeleddatasetforcomplexandcross-domainsemanticpars- Spider Bird GSM8K
ingandtext-to-SQLtask. InProceedingsofthe2018
NumberofPrograms 1,221 1,291 2,453
Conference on Empirical Methods in Natural Lan-
NumberofProgramPairs 409 269 1,238
guageProcessing,pages3911–3921,Brussels,Bel-
NumberofProgramBatches 400 300 500
gium.AssociationforComputationalLinguistics.
TableA.1: Statisticsofourintrinsicevaluationsets.
Shun Zhang, Zhenfang Chen, Yikang Shen, Mingyu
Ding,JoshuaB.Tenenbaum,andChuangGan.2023.
Planningwithlargelanguagemodelsforcodegener- (accuracythresholdτ = 1.0). Then,weconstruct
ation. InTheEleventhInternationalConferenceon ourintrinsicevaluationsetsbasedontherelabeled
LearningRepresentations.
programs (Table A.1). Intuitively, the number of
program batches for each dataset is the same as
Andy Zhou, Kai Yan, Michal Shlapentokh-Rothman,
Haohan Wang, and Yu-Xiong Wang. 2023. Lan- theend-to-endevaluationexampleswehave,and
guageagenttreesearchunifiesreasoningactingand thethenumberofprogramsisalluniqueprograms
planninginlanguagemodels.
wecangetfromthebatches. Topairtheprograms
and calculate discrimination accuracy, we iterate
A ImplementationDetails
througheachbatchandenumeratecombinationsof
A.1 Text-to-SQLParsingEvaluationSets correctandwrongprogramswithinthebatch. We
do not include cross-batch pairs, as those do not
For text-to-SQL parsing, we sub-sample the de-
alignwithourend-to-endevaluationsettings.
velopmentsplitsofeachdataset,SpiderandBird,
Fordiscriminationaccuracy,weenumeratepairs
followingthreesteps: (1)categorizedevelopment
of correct and wrong programs and ask LLMs to
set examples by difficulty levels defined in each
selectthebetterone. ForclassificationF1,welet
dataset,(2)randomlyselectadatabaseandchoose
LLMs predict the correctness of each individual
oneassociatedexample,and(3)repeatstep2until
program. ForHit@1andMRR,weuseLLMsto
we have 100 samples for each difficulty level. In
scorethebatchesofprogramsinsimulationexperi-
thisway,weensureauniformdistributionacross
ments.
differentdifficultylevelsanddatabase. Sincethere
are four and three difficulty levels in Spider and
A.3 PromptingandTrainingLLMs
Bird,respectively,ourevaluationsetshave400and
300examplesforeachdataset. Prompting the Generator LM. We prompt our
Text-to-SQLparsingmodels, includingLLMs, generator LM, CodeLlama-13B-Instruct, with
may show lower performance on our evaluation temperature-basedsamplingfordifferentprogram
sets because of their uniformly distributed diffi- suggestions(Section3.1). Weusethemodelcheck-
culty(100examplesperlevel). Incomparison,the pointandgenerationfunctionimplementedbyHug-
originaldatasetshaveskeweddistributionstowards gingFace(Wolfetal.,2020). Wesetthemaximum
easierexamples. Spider’sdevelopmentsethas248 generation length max_length = 300, tempera-
(24.0%) examples at easy level and 446 (43.1%) turetemperature = 0.6andnumberofsamples
examplesatmediumlevel,whilethehardandextra num_return_sequences = 5.
hardexamplesonlysumupto32.9%ofthe1,034 Data for Discriminator LMs. For text-to-SQL
examples. In Bird, 925 out of the 1,534 (60.3%) parsing,weperform2-foldcross-validationonthe
developmentsetexamplesareatsimplelevel,465 training sets to synthesize incorrect SQL queries
examples(30.3%)areatmoderatelevel,andonly foreachexample(Chenetal.,2023a). Weprompt
144examples(9.4%)areatchallenginglevel. Our theLMusingonepairofcorrectandwrongSQL
evaluation sets normalize these skewed distribu- queries (labeled with “Yes” and “No”), also re-
tionsandmakethemacroaveragesofmodelper- trievedbyBM25(Section3.2). Alternatively,we
formancelessbiased(Section4.1). fine-tune the LM on the entire training set with
ground-truthandsynthesizedSQLqueriestogen-
A.2 IntrinsicEvaluationData
erate“Yes”or“No.” Formathematicalreasoning,
To evaluate LLMs’ discrimination performance, weannotatetwoincorrectpythonprogramsforthe
we reuse the generation results from our oracle- two examples used in generator. Similar to text-
simulation experiments (Section 6). Specifically, to-SQLparsing,weusethetwoprogrampairsto
weusetheevaluationscriptstore-labelthegener- promptLMsforbinaryquestionanswering. Since
atedprogramsinsimulatedre-rankingexperiments the training set of GSM8K is not annotated withprogramofthoughts,wearenotabletofine-tune resultshead-to-headunderastrongassumptionthat
LMsonthisdataset. therowsareordered. Althoughstrict,thisassump-
PromptingDiscriminatorLMs. ForCodeLlama- tionishelpfulforevaluatingthecorrectnessofSQL
7B-InstructandCodeLlama-13B-Instruct(Section querieswithanORDER BYclause. Then,thefunc-
3.2),wesimplyfeedtheinputprompttothemodels tioncounthowmanytablecellsoverlapwitheach
to get the last logit’s values, which give us the otherinanunorderedmanner. Wedividethenum-
token-levelprobabilityafterapplyingthesoftmax berofoverlappingcellsbythetotalnumberofcells
function. inexecutionresultsofthegoldSQLquery(preci-
For GPT-3.5-Turbo and GPT-4-Turbo, we sion) and the predicted one (recall). Finally, we
access them through the API of (OpenAI, computetheharmonicmeanofthesetwonumbers
2022, 2023). The specific model versions are togettheoraclescore(F1).
gpt-3.5-turbo-1106andgpt-4-1106-preview, For instance, given “-- countryid: 1, 2, 4, 5 --
respectively. WeprompttheLLMstogenerateone countryname: usa, germany, japan, italy” as the
token and leverage the top_logprobs request to gold execution result and “-- countryid: 1, 4, 6 --
checkthetop-5tokensandtheirprobabilities3. If countryname: usa, japan, japan” as the result of
“Yes”appearsasoneofthetop-5tokens,wetake predicted SQL query. We compare (1, usa), (4,
itsprobabilitypwithoutanymodifications. If“Yes” japan), and (6, japan) the first, second, and third
is missing and “No” appears as one of the top-5 rowinthegoldresult,respectively. Theyhave2,0,
tokens,weinverseitsprobability1−pasthescore. and 1 overlapping table cells, respectively. Thus,
Otherwise, our implementation returns 0 if both wehaveourprecisiontobe3/8 = 0.375andrecall
tokensaremissing,thoughthiscaseshouldberare tobe3/6 = 0.5. Theoracle’sscorewouldbe:
orevendoesnothappeninourexperiments.
2·0.375·0.5
TrainingDiscriminatorLMs. TogetCodeLlama- = 0.43
0.375+0.5
7B-Instruct-FT and CodeLlama-13B-Instruct-FT
(Section 3.2), we again use the checkpoints and For mathematical reasoning, our oracle directly
trainer implemented by Hugging Face. We fine- checksifthepredictedanswerequalstotheground-
tunethemodelstogeneratethenexttoken(“Yes”or truth. If the answer is None (non-executable pro-
“No”)baseontheinputpromptsusingthefollowing gram)ordoesnotequaltotheground-truth,itre-
hyperparameters: turns0. Otherwise,itreturns1.
• Numberofepochs: 1
B McNemar’sTestforStatistical
• Batchsize: 128
Significance
• Learningrate: 1e-5
• Warmupratio: 3% We measure the statistical significance of perfor-
• Scheduler: cosine mancegainsusingtheexactMcNemar’sTest4(Mc-
The inference procedure of fine-tuned models is Nemar, 1947). We choose the test’s exact bino-
thesameashowweprompttheoriginalLLMs,but mialversionbecauseoursamplesizesarerelatively
withoutusinganyin-contextexample. small(Edwards,1948),andthefirsttwosignificant
ComputingResources. Allofourexperimentson digits of p-values are the same for this binomial
SpiderandGSM8KuseuptofourNVIDIARTX versionandtheoriginalchi-squareversioninour
A6000GPU(48GB).ExperimentsonBirduseup tests. Intuitively,thistestmeasureshowlikelythe
tofourNVIDIAA100TensorCoreGPU(80GB). weaker method can still outperform the stronger
one.
A.4 ImplemendationofOracleDiscriminator
For example, we consider the comparison be-
For text-to-SQL parsing, our oracle uses the first tweentreesearchanditerativecorrectiononBird
fiverowsinexecutionresultsofthepredictedand whenusingCodeLlama-13B-FTE asthediscrimi-
goldSQLqueryandcalculatethetablecelloverlap. nator(Section5.2). Bycomputinga2×2contin-
Morespecifically,thecalculationissimilartospan gencytable(TableB.1),McNemar’sTestfocuses
F1inmachinereadingcomprehension. Ouroracle on the 40 examples where only one of the two
functionfirstcompareseachrowintheexecution methodhavepredictedcorrectly. Specifically,there
3https://platform.openai.com/docs/ 4https://www.statsmodels.org/dev/generated/
api-reference/chat/create#chat-create-top_ statsmodels.stats.contingency_tables.mcnemar.
logprobs htmlICCorrect ICWrong
TSCorrect 73 15
TSWrong 25 187
TableB.1: Contingencytablefortreesearch(TS)and
iterativecorrection(IC)onBird,usingCodeLlama-13B-
FTE asthediscriminator(Section5.2).
are25examplesthatiterativecorrectionfindsthe
correctanswer,buttreesearchdoesnot,whichis
the source of performance gain. Also, there are
15examplesthatiterativecorrectionfails,buttree
search succeeds. According to McNemar’s Test,
these15(37.5%ofthetotal40)examplesresultina
p-valueof0.15,meaningthereisstillsomechance
fortreesearchtooutperformiterativecorrection.
Incontrast,supposethereareonly10examples
that iterative correction finds the correct answer,
but tree search does not. Meanwhile, there are
noexamplesthatiterativecorrectionfails,buttree
search succeeds. Then, we can still observe the
same number of accuracy gain, but it is now sta-
tisticallydifferentbecauseitisalmostimpossible
fortreesearchtooutperformiterativecorrection(0
outof10). Thesamerationalealsoappliestothe
resultsofothertestsinSection7.C PromptExamples
Given database schema and a question in natural language, generate the corresponding SQL query.
-- Database climbing:
-- Table mountain: mountain_id, name, height, prominence, range, country
-- Table climber: climber_id, name, country, time, points, mountain_id
-- Question: How many distinct countries are the climbers from?
-- SQL:
SELECT COUNT(DISTINCT country) FROM climber;
-- Database concert_singer:
-- Table stadium: stadium_id, location, name, capacity, highest, lowest, average
-- Table singer: singer_id, name, country, song_name, song_release_year, age, is_male
-- Table concert: concert_id, concert_name, theme, stadium_id, year
-- Table singer_in_concert: concert_id, singer_id
-- Question: What are all distinct countries where singers above age 20 are from?
-- SQL:
SELECT
TableC.1: Anexamplepromptfor1-shotgeneration(text-to-SQLparsing).
Given database schema and a question in natural language, correct the buggy SQL query and
generate a fixed SQL query.
-- Database concert_singer:
-- Table stadium: stadium_id, location, name, capacity, highest, lowest, average
-- Table singer: singer_id, name, country, song_name, song_release_year, age, is_male
-- Table concert: concert_id, concert_name, theme, stadium_id, year
-- Table singer_in_concert: concert_id, singer_id
-- Question: What are all distinct countries where singers above age 20 are from?
-- Buggy SQL:
SELECT DISTINCT country FROM singer WHERE age > 20;
-- Fixed SQL:
SELECT
TableC.2: Anexamplepromptfor0-shotiterativecorrection(text-to-SQLparsing).Answer the following Yes/No question: Is the SQL correct given the utterance?
-- Utterance: How many different countries are all the swimmers from?
-- SQL:
SELECT COUNT(DISTINCT nationality) FROM swimmer;
-- Answer: Yes
-- Utterance: How many different countries are all the swimmers from?
-- SQL:
SELECT DISTINCT country FROM swimmer;
-- Answer: No
-- Utterance: What are all distinct countries where singers above age 20 are from?
-- SQL:
SELECT DISTINCT country FROM singer WHERE age > 20;
-- Answer:
TableC.3: Anexamplepromptfor1-shotdiscrimination(text-to-SQLparsing). Fordiscrimination,eachin-context
examplehasapairofcorrectandwrongprograms.
Answer the following Yes/No question: Is the SQL correct given the utterance and its result?
-- Utterance: How many different countries are all the swimmers from?
-- SQL:
SELECT COUNT(DISTINCT nationality) FROM swimmer;
-- Result:
-- count(distinct nationality): 7
-- Answer: Yes
-- Utterance: How many different countries are all the swimmers from?
-- SQL:
SELECT DISTINCT country FROM swimmer;
-- Result:
ERROR
-- Answer: No
-- Utterance: What are all distinct countries where singers above age 20 are from?
-- SQL:
SELECT DISTINCT country FROM singer WHERE age > 20;
-- Result:
-- country: Netherlands, United States, France
-- Answer:
Table C.4: An example prompt for 1-shot discrimination with execution results (text-to-SQL parsing). For
discrimination,eachin-contextexamplehasapairofcorrectandwrongprograms.## Given questions in the comment, use python programs to produce the correct answers with
the ’answer’ variable.
## James takes 2 Tylenol tablets that are 375 mg each, every 6 hours. How many mg
does he take a day?
## Python Program:
mg_tylenol_per_tablet = 375
mg_tylenol_taken_each_time = 2 * mg_tylenol_per_tablet
hours_per_day = 24
times_per_day = hours_per_day / 6
mg_each_day = mg_tylenol_taken_each_time * times_per_day
answer = mg_each_day
## There were 63 Easter eggs in the yard. Hannah found twice as many as Helen. How
many Easter eggs did Hannah find?
## Python Program:
n_easter_eggs = 63
unit_times = 2
total_units = unit_times + 1
n_easter_eggs_per_unit = n_easter_eggs / total_units
n_easter_eggs_helen = n_easter_eggs_per_unit * 1
n_easter_eggs_hannah = n_easter_eggs_per_unit * 2
answer = n_easter_eggs_hannah
## Gloria is shoe shopping when she comes across a pair of boots that fit her shoe
budget. However, she has to choose between the boots and two pairs of high heels that
together cost five dollars less than the boots. If one pair of heels costs $33 and the other
costs twice as much, how many dollars are the boots?
## Python Program:
TableC.5: Anexamplepromptfor2-shotgeneration(mathematicalreasoning).
## Given the question in the comment, correct the buggy python program and generate a fixed
python program to produce the correct answer with the ’answer’ variable.
## Gloria is shoe shopping when she comes across a pair of boots that fit her shoe
budget. However, she has to choose between the boots and two pairs of high heels that
together cost five dollars less than the boots. If one pair of heels costs $33 and the other
costs twice as much, how many dollars are the boots?
## Buggy Python Program:
price_boots = 50
price_heels = 33
price_heels_twice = 2 * price_heels
price_heels_total = price_heels + price_heels_twice
price_boots_difference = price_boots - price_heels_total
answer = price_boots_difference
## Fixed Python Program:
TableC.6: Anexamplepromptfor0-shotiterativecorrection(mathematicalreasoning).## Answer the following Yes/No question: Is the python program correct given the problem in
the comment?
## James takes 2 Tylenol tablets that are 375 mg each, every 6 hours. How many mg
does he take a day?
## Python Program:
mg_tylenol_per_tablet = 375
mg_tylenol_taken_each_time = 2 * mg_tylenol_per_tablet
hours_per_day = 24
times_per_day = hours_per_day / 6
mg_each_day = mg_tylenol_taken_each_time * times_per_day
answer = mg_each_day
## Answer: Yes
## James takes 2 Tylenol tablets that are 375 mg each, every 6 hours. How many mg
does he take a day?
## Python Program:
mg_per_tablet = 375
n_tablets_per_day = 2
n_tablets_per_6hrs = n_tablets_per_day / 6
mg_per_6hrs = mg_per_tablet * n_tablets_per_6hrs
answer = mg_per_6hrs
## Answer: No
## There were 63 Easter eggs in the yard. Hannah found twice as many as Helen. How
many Easter eggs did Hannah find?
## Python Program:
n_easter_eggs = 63
unit_times = 2
total_units = unit_times + 1
n_easter_eggs_per_unit = n_easter_eggs / total_units
n_easter_eggs_helen = n_easter_eggs_per_unit * 1
n_easter_eggs_hannah = n_easter_eggs_per_unit * 2
answer = n_easter_eggs_hannah
## Answer: Yes
## There were 63 Easter eggs in the yard. Hannah found twice as many as Helen. How
many Easter eggs did Hannah find?
## Python Program:
eggs_in_yard = 63
eggs_found_by_hannah = 2 * eggs_in_yard
eggs_found_by_helen = eggs_found_by_hannah / 2
answer = eggs_found_by_hannah
## Answer: No
## Gloria is shoe shopping when she comes across a pair of boots that fit her shoe
budget. However, she has to choose between the boots and two pairs of high heels that
together cost five dollars less than the boots. If one pair of heels costs $33 and the other
costs twice as much, how many dollars are the boots?
## Python Program:
price_boots = 50
price_heels = 33
price_heels_twice = 2 * price_heels
price_heels_total = price_heels + price_heels_twice
price_boots_difference = price_boots - price_heels_total
answer = price_boots_difference
## Answer:
Table C.7: An example prompt for 2-shot discrimination (mathematical reasoning). For discrimination, each
in-contextexamplehasapairofcorrectandwrongprograms.## Answer the following Yes/No question: Is the python program correct given its result and
the problem in the comment?
## James takes 2 Tylenol tablets that are 375 mg each, every 6 hours. How many mg
does he take a day?
## Python Program:
mg_tylenol_per_tablet = 375
mg_tylenol_taken_each_time = 2 * mg_tylenol_per_tablet
hours_per_day = 24
times_per_day = hours_per_day / 6
mg_each_day = mg_tylenol_taken_each_time * times_per_day
answer = mg_each_day
## Result: 3000.0
## Answer: Yes
## James takes 2 Tylenol tablets that are 375 mg each, every 6 hours. How many mg
does he take a day?
## Python Program:
mg_per_tablet = 375
n_tablets_per_day = 2
n_tablets_per_6hrs = n_tablets_per_day / 6
mg_per_6hrs = mg_per_tablet * n_tablets_per_6hrs
answer = mg_per_6hrs
## Result: 125.0
## Answer: No
## There were 63 Easter eggs in the yard. Hannah found twice as many as Helen. How
many Easter eggs did Hannah find?
## Python Program:
n_easter_eggs = 63
unit_times = 2
total_units = unit_times + 1
n_easter_eggs_per_unit = n_easter_eggs / total_units
n_easter_eggs_helen = n_easter_eggs_per_unit * 1
n_easter_eggs_hannah = n_easter_eggs_per_unit * 2
answer = n_easter_eggs_hannah
## Result: 42
## Answer: Yes
## There were 63 Easter eggs in the yard. Hannah found twice as many as Helen. How
many Easter eggs did Hannah find?
## Python Program:
eggs_in_yard = 63
eggs_found_by_hannah = 2 * eggs_in_yard
eggs_found_by_helen = eggs_found_by_hannah / 2
answer = eggs_found_by_hannah
## Result: 126
## Answer: No
## Gloria is shoe shopping when she comes across a pair of boots that fit her shoe
budget. However, she has to choose between the boots and two pairs of high heels that
together cost five dollars less than the boots. If one pair of heels costs $33 and the other
costs twice as much, how many dollars are the boots?
## Python Program:
price_boots = 50
price_heels = 33
price_heels_twice = 2 * price_heels
price_heels_total = price_heels + price_heels_twice
price_boots_difference = price_boots - price_heels_total
answer = price_boots_difference
## Result: -49
## Answer:
TableC.8: Anexamplepromptfor2-shotdiscriminationwithexecutionresults(mathematicalreasoning). For
discrimination,eachin-contextexamplehasapairofcorrectandwrongprograms.