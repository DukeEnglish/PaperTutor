Instruction Diversity Drives Generalization To Unseen Tasks
DylanZhang JustinWang FrancoisCharton
UniversityofIllinois UniversityofIllinois MetaAIResearch
Urbana-Champaign Urbana-Champaign fcharton@meta.com
shizhuo2@illinois.edu jw93@illinois.edu
Abstract model’sabilitytolearntogeneralizetounseentasks
–instructionsthatwerenotseenduringtraining.
Instructiontuning–fine-tuningalargelanguage
Whereaslargeinstruction-tuningdatasetsofincreas-
model(LLM)onpairsofinstructionsanddesired
ingqualityhavebeenproposedinrecentyears,there
outcomes–isanapproachthatenablespre-trained
arecomparativelyfewsystematicstudiesofthekey
languagemodelstoperformreal-worldtasksand
followhumaninstructions. Itspracticalsuccess factorsthatenableinstruction-tunedmodelstogener-
dependsonthemodellearningabroadersetof alizetounseentasks. Intuitively,severalpotentialfac-
instructionsthanthoseitwastrainedon.Yetthe torscanimprovefinetuning:largertrainingsamples,a
factors that determine model generalization to greaterdiversityofinstructions,andbetterannotation
such unseen tasks are not well understood. In
quality. However,thereal-worldinstruction-following
thispaper,weexperimentwithstringrewrites,a
datasetslackcontrolovereachfactor,failingtoanswer
symbolictaskthatservesasabuildingblockfor
thequestioninasystematicandprincipledway.
TuringcompleteMarkovalgorithmswhileallow-
In this paper, we study task generalization in
ingexperimentalcontrolof“inputs”and“instruc-
tions”. Weinvestigatethetrade-offbetweenthe instruction-following on a simple symbolic task:
numberofinstructionsthemodelistrainedonand stringrewrites. Symbolictasksallowustogainfiner
thenumberoftrainingsamplesprovidedforeach control over the data. Also, this string-rewriting
instructionandobservethatthediversityofthe setupallowsustoseparatebetweenthe“inputs”and
instructionsetdeterminesgeneralization.General- “instructions”andvaryeachindependently.
izationemergesonceadiverseenoughsetoftasks
Ourstring-rewritingtasksareinspiredbyMarkov
isprovided,eventhoughveryfewexamplesare
algorithm (Markov, 1954), which is a Turing-
providedforeachtask.Instructiondiversityalso
ensuresrobustnesswithrespecttonon-uniform complete computation model. A model that can
distributionsofinstructionsinthetrainingset. generalizestringrewritescanthereforebeturnedinto
ageneralmodelofcomputation. Thus,thesymbolic
1 Introduction
task we adopt has considerable generality over the
tasksLLMperforms.Weconcludethat1)instruction
Therapidadvanceoflargelanguagemodels(LLM)
diversityistheenablingfactorforgeneralization.
is one of the most exciting recent developments in
Modelsgeneralizeoncetheyaretrainedonenough
artificial intelligence. LLM, pre-trained on large
differentinstructions,evenifthenumberofexamples
text corpora, can be fine-tuned to achieve high
perinstructionissmall2)Semanticdiversityofrules
performance over a broad set of tasks, ranging
is also important in addition to the number of
fromnaturallanguageunderstandingtologicaland
instructionsand3)non-uniformityindistribution
mathematicalreasoningandprogramming.
canaffectgeneralization,butadiverseenoughset
Instruction tuning – training models on pairs of
ofinstructionsprovidesrobustness.
instructions and desired outcomes – emerged as an
approachtoadaptlanguagemodelspre-trainedover
2 RelatedWork
text corpus with a next-token-prediction objective
tosolvingcertainproblemswithitsknowledgeand Both the size and quality of fine-tuning are impor-
reasoning capabilities. Through instruction-tuning, tant(Chungetal.,2022;Iyeretal.,2022;Wangetal.,
LLMsareexpectedtolearntoperformabroadsetof 2023a). High-qualitydatasetsforinstructiontuning
taskstosolvealargenumberofreal-worldproblems canbecollatedusinghumansannotators(Khashabi
and seamlessly interact with humans. The success etal.,2020;Yeetal.,2021;Sanhetal.,2022;Wang
ofinstructiontuningisthereforeconditionedbythe etal.,2022;Longpreetal.,2023;Conoveretal.,2023;
4202
beF
61
]LC.sc[
1v19801.2042:viXraKöpf et al., 2023), but their size is constrained by 4 ExperimentResults
thecostofannotation. Alternativemethods,usingex-
4.1 InstructionDiversityDrivesGeneralization
amplesdistilledfromlarger,morepowerfullanguage
modelshavebeenproposed(Wangetal.,2023b;Hon- Inthefirstsetofexperiments,wetrainGPT-2models
ovichetal.,2022;Taorietal.,2023;Pengetal.,2023; with 6 layers, 4 heads, and hidden dimension 256
Chiang et al., 2023; Xu et al., 2023; Köksal et al., (see Appendix 4.5 for more information on our
2023; Kim et al., 2023). They allow for the larger experimental setting) on a generated sample of
trainingset,inexchangeforpotentiallylowerquality. S×I inputsequences,correspondingtoI different
Ongeneralizationtounseeninstruction,previous replacementrules(instructions)appliedtoS different
research has shown that data quality matters more sequences. The trained model is then tested on a
than quantity (Zhou et al., 2023), and other works dataset of 105 examples with unseen instructions.
pointed out the importance of consistency in Figure 2a presents the generalization accuracy for
format (Liang et al., 2024) and mixing tasks from models trained on 106 examples as a function of
differentcategories(Longpreetal.,2023;Iyeretal., the number of different instructions in the training
2022;BukharinandZhao,2024). set. We note that models trained on less than 300
instructionsnevergeneralize, evenwhenthemodel
3 MarkovAlgorithmsandrewriterules only has a few rules to learn and is provided with
a very large number of examples per rule. On the
Markovalgorithms(Markov,1954)processsequences otherhand, modelstrainedon1,000instructionsor
of letters on a fixed alphabet Σ={σ 1,...,σ K}. An more always generalize, even when the number of
algorithm is an ordered sequence of rewrite rules instructionsbecomesverylarge,andeachruleisonly
I={(x i→y i)i=1,2...,|I|}, withs i andy i words featuredinahandfulofexamples.Averysharpphase
overanextensionofΣ: Σ′=Σ+{α 1,...,α n}+{·}. transitionhappensaround400instructions.
Toapplythealgorithmtoagivensequencez,rules
Weconcludethatthenumberofinstructionsinthe
areconsideredinorder,andthefirstapplicablerule trainingset(I)isthekeyfactorthatallowsthemodel
x →y isusedtoreplacetheleftmostoccurrenceof
i i to generalize to different instructions and variation
x ibyy i,thereforetransformingzintoz′.Theprocess
ininputsemantics(seeAppendix4.5)insteadofS.
continues until a special rule x→· is encountered,
indicatingthatthealgorithmterminatesandreturns 4.2 Searchingandreplacing,therolesofNo-Ops
thetransformedvalueofz,ortheprocessisblocked.
So far, the sub-string to be replaced was always
AppendixAprovidesexamplesofMarkovalgorithms. featuredintheinputsequence. Wenowconsiderthe
Markov algorithms can be shown to be Turing- more general case where some rules do not apply.
complete:anyfinitecomputationcanbeimplemented In such cases, which we call “no-ops”, the model
by Markov algorithms, which therefore constitute returnsitsoriginalinput. Themodelmustnowlearna
a complete model of computation. Any language two-steptask: checkwhetheraruleisano-ops,then
modelthatcanbetrainedtoimplementrewriterules applyit. Thisisclosertoareal-worldsetting,where
can serve as a universal computation tool. In this replacementsoftendonotapply. Italsocorresponds
paper,weconsidertwotasks: to the “skip inapplicable rule and try the next one”
• learn to apply the rule on a sequence where it case in Markov algorithms. We evaluate model
isapplicable generalizationtounseeninstructionsasafunctionof
• learntoapplytheruleifitisapplicableorreturn thenumberofinstructionsinthetrainingsetandthe
theinputsequence frequency of no-ops, which we vary between 50%
The first task is the basic rewrite operation. The and10%(Figure2b). Thesizeofthetrainingandtest
secondallowsthealgorithmtomovetothenextrule setsarethesameasinpreviousexperiments.
ifthecurrentonedoesnotapply. Onaverage,theadditionofno-opshaslittleimpact
Allthestringsconsideredinourexperimentsare on model performance for “has-ops” cases (where
sequencesofthelowercaseLatinlettersa...z. Model replacementhappens): generalizationonlyhappensin
inputsaretripletsofstrings,(x,y,z),representingthe modelstrainedonmorethan400differentinstructions
rulex→yandtheinputsequencez. Modeloutputs (vs500previously). No-opscases,ontheotherhand,
areobtainedbyreplacingtheleftmostinstanceofx arealwayscorrectlypredicted,andmodelstrainedon
byy,inthesequencez. Ifxdoesnotappearinz,the afewdifferentinstructionsdefaulttoalwayspredict-
modeloutputisz(inputsentenceiscopied,Figure1a). ingno-ops. Thefrequencyofno-opsinthetrainingr e g r e t
Instructions:
Instruction: hello-> lunch 1. enjoy-> regret Findtheword (if exists) and change. a->b:key=1
qwerthellohellozxcvb qwertlunchhellozxcvb
2. a -> b Encryptusing CaesarCipher
s f h s f u
Find the firstoccurrence Replace with Input: with the specified key. Target Output:
of the substring target substring I enjoydoing research. LLM I sfhsfudoing research.
qwertbyebyezxcvb qwertbyebyezxcvb
If no such substring found Return the original string
(b)EncryptedRe-writing. Similartothere-writingexperiment,butthemodel
(a)Ourstring-rewritingtaskset-up. needstoinfertheruleofencryptionbasedontheruleofshiftingspecifiedin
theinstructionsandcomputetheencryptedword.
Figure1:Illustrationofoursymbolictasksinthispaper.
1.0 105 1.0
0.8 0.8
11::99
0.6 103 22::88
AverageAccuracy 0.6 33::77
0.4 N Peu rm In.E sx tra um ctp il oe ns 44::66
0.4 55::55
0.2 101 AAvveerraaggee
0.2
0.0 No-Op
10 20 50 100 200 300 400 500 6001k 2k 2.5k5k 10k 100 1k 000k
0.0
Has-Op
100 200 300 400 500 1000 10000100000
Num.Instructions Number of Instructions
(a)Re-writingaccuracyagainstthenumberofinstructions (b)Rewritingwithno-opsituationincluded.
withafixed-sizetrainingset.
Figure2:Generalizationversusnumberofinstructionsduringtraining.
samplehasamarginalimpactonperformance: our instructionsdoesnothelp. Althoughthemodelcan
generalconclusionsremainthesame,butthenumber generalize to unseen tasks in-domain (same k), the
of instructions needed for generalization is slightly accuracyisalwayszeroonlowerk(orunrestricted).
lowerwhentherearefewerno-ops. Thesituationchangeswhenthethreetrainingsets
Weusepower-lawdistributioninthedistribution are mixed together (Figure 4). Models trained on
experimentinSection 4.4.Figure3bisavisualization large k (for all three constraints) do generalize to
ofhowthepercentagesofruledecay. small k (and other unconstrained instructions). As
before,alargernumberofinstructionsinthetraining
4.3 DiversityofInstructionSemantics set improves model generalization. Also, the more
constrained the training instructions are (i.e. larger
Previous experiments demonstrate the merit of
valuesofk),thehardergeneralizationbecomes.
training models on a large set of instructions. We
now investigate the impact of semantic diversity in Overall,wenoticethatjustastrainingonalarge
theinstructionset. Tothiseffect,wetrainmodelson setofinstructionsiskeytoachievinggeneralization
alargebutrestrictedsetofrulesbyconstrainingthe tounseeninstruction,trainingonseveralsemantically
sub-stringstoreplaceortobereplacedandtestthem constrainedsetsofrulesallowsforgeneralizationto
onlessconstrainedinstructions. Weexperimentwith semanticallyunconstrainedrules.
threesetsofconstrainedsubstrings:
4.4 ImpactofinstructionDistributions
• charactersrepeatedktimes:aaabbbcccfork=3
• patternsrepeatedktimes: abcabcfork=2 Inallpreviousexperiments,trainingexampleswere
• mirroringpatternsrepeatedktimes: abccbaabc evenlydistributedbetweeninstructions. Thissituation
fork=3. can be achieved in controlled experiments, but it is
Inallthreesettings,largevaluesofk correspond unlikelytohappeninreal-worldscenarios.Wenowin-
tomoreconstrainedinstructions. Wetrainmodelson vestigatetheimpactofunbalancedinstructiontraining
instructionswithlargekandtestthemonlowk. We sets. Tothiseffect,wefixthesizeofthetrainingset
observethatmodelstrainedononesetofconstrained andthenumberofdifferentinstructionsconstantbut
(repeated, periodic, or mirror) do not generalize distributethenumberofexamplesforeachinstruction
to lower k, and mixing repeated and periodic according to a power law and experiment with
ycaruccAegarevA
noitcurtsnIrePselpmaxE.muN
ycaruccA1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3 Num. Instructions
1000
0.2
10000
0.1 100000 RankIndex
0.0
Uniform 2 1 0.5 0.2 0.1 0.07 0.03 ( pb o) wT eh r-e las wort de id stp rie br uc te ion ntag we ito hf de ia ffc eh rein ns tt sru hc at pi eon pafo rall mow eti en rg
s.
Shape Parameter They-axisisthepercentageoftherulesinthetraining
(a)Effectoflong-tailtaskdistributionsonmodel’sgeneralizationmixture. Thex-axisistherankedindex(byproportion
ability. ofexamples)ofinstructions.
Figure3:Generalizationversusnumberofinstructionsduringtraining.
1.0 semanticinputspace,ourresearchexploredhowwell
Rangeofk
0.9
3-4 the model could identify and manipulate specific
0.8
3-6 sub-string occurrences within sequences previously
0.7
3-12
0.6 duringitstrainingphase. Wespecificallytrainedthe
3-20
0.5
3-30 modelondatasetscharacterizedbylimitedoccurrence
0.4
3-60
0.3 frequenciesandthenevaluateditsperformanceacross
0.2 aspectrumrangingfrom1to20occurrences.
0.1
Thefindings,asshowninTable1,revealamarked
0.0
500 1000 5000 10000
declineinperformancewhenthemodelisconfronted
Num.Instructions
with variable occurrence counts compared with
Figure4:Model’sperformancewhentrainedonthethree
situationswithaconsistentsingleoccurrence. This
classesofrestrictedsemantics. Modelstrainedon500or
variabilitytendstoconfoundthemodel,impedingits
lessinstructionsnevergeneralize.
abilitytorecognizetheinputstringsaccuratelyand,
consequently,toapplytheinstructionsasintended.
different shape parameters, ranging from uniform Crucially,however,enrichingthetrainingsetwith
laws to situations where a few training instructions awiderarrayofoccurrencefrequenciesdemonstrably
areverycommon,butmostareextremelyrare. enhances the model’s performance. It becomes
Figure 3a presents model generalization as a evident that incorporating examples containing
function of the variance of the distribution of occurrence numbers from each sub-interval within
examples for training sets with 1,000, 10,000, and the overall range significantly boosts the model’s
100,000 instructions. For models trained on 1000 operationaleffectiveness.
instructions(theminimaldiversityleveltoguarantee Thekeytakeawayfromourstudyistheundeniable
generalization, according to our previous experi- importance of instruction diversity. A training regi-
ments),performancedropssteeplyoncetheexample men infused with various instructions substantially
distributionbecomestoouneven. Modelstrainedon improves the model’s capability to generalize to
largerinstructionsets,ontheotherhand,sufferlittle unseen occurrences. This enhanced generalization
penalty. Thisconfirmsourearlierobservationsabout ability underscores the critical role that diverse
thephasetransitionhappeningaround500examples. instructionplaysinmakingthemodelgeneralizeto
A long-tailed example distribution amounts to a unseensemanticinputspacesmoreeffectively.
reduction in the number of training instructions. It
5 ExperimentswithPre-TrainedModels
impactsmodelstrainedonlimitedsetsofinstructions
–closetothecut-offlimitof500.
All models so far were trained from scratch. In
this section, we show how our experiments can
4.5 GeneralizationAcrossInputSemantics
be extended to pre-trained models. LLM already
To assess the impact of instruction diversity on learns basic string replacement during pre-training,
a model’s ability to generalize across a broader so we need a more difficult task. We introduce an
ycaruccA
ycaruccA egatnecrePTrainOcc.\Num. Inst 2000 1000 500 200 cannotcorrectlyperformthe“replace-then-encrypt”
operation(Figure5).
1 0.71 0.41 0.00 0.00
10 0.88 0.71 0.00 0.00 6 Conclusion
15 0.84 0.59 0.00 0.00
Throughoursymbolicexperiments,wehaveshown
20 0.73 0.28 0.07 0.00
thatlanguagemodelsonlygeneralizetoinstructions
1,5,10,15,20 0.94 0.94 0.62 0.00
unseenduringtrainingwhentrainedonalargeand
diverse set of instructions. For a fixed data budget,
Table 1: Results on the generalizability across input
semantics. Train Occ. Denotes the occurrences of the instruction diversity outweighs better illustration
substring in the training dataset, Num. Inst denotes the (i.e. more examples) for each instruction. These
numberofdiverseinstructions. observationsapplynotonlytothenumberofdifferent
instructionsinthedatasetbutalsototheirsemantic
1.0 diversity. The negative effect of an unbalanced dis-
0.9 tributionofexamplescanbecounteractedbyalarger
0.8 SubsampleStrategy
numberofinstructionsinthetrainingset. Wealsoem-
0.7 Non-Unif.
0.6 Unif. piricallydemonstratedthattheseresultsindeedapply
0.5
tothefine-tuningofpre-trainedlanguagemodels.
0.4 OperationType
0.3
No-Op Limitations
0.2
Has-Op
0.1
Overall Lack of real-world instruction datasets. To gain
2000 3000 4000 9000 40000 fullcontroloverdifferentfactorsandablatetheeffect
Num. Instructions of each, we adopted a synthetic setup instead of
experimentingwithreal-worldinstruction-following
Figure5:PerformanceofLlama-2modelontheencrypted-
rewritingtask.Wealsoconducteduniform/non-uniform datasets. The abstraction might ignore certain at-
sub-samplingstohalfthetotalsamplesizeat9000instruc- tributeslikeknowledgeduringpre-training,language,
tions.Uniformsub-samplingdoesnotharmperformance etc. That beingsaid, thesefactors are notthe main
whereasnon-uniformsubsamplingimpactsgeneralization.
focusofthiswork.
Lack of theoretical justifications. The results
areempirical. Ourfutureworkshallseektheoretical
encrypted-rewriting task that requires multi-hop
justificationsfortheconclusionswehad.
reasoning(Figure1b). Thetaskinvolvesasentence
andanencryptedre-writinginstruction. Themodel
EthicsStatement
firstreplacesthespecifiedwordwithanotherword,
then encrypts that word using Caesar cipher with a Instruction tuning may have ethical consequences.
keyspecifiedintheinstruction. If the fine-tuning data is not controlled or has low
quality, biases can be introduced as the model is
Wekeeptwodisjointdictionariesfortrainandtest
fine-tuned. Webelieveourresultssuggestapossible
setsandpromptGPT-3.5-turbotogeneratesentences
mitigationtosuchbiases. Byincreasingthediversity
containing words from the dictionary. If the word
of instructions in fine-tuning sets, models learn to
isinthegeneratedsentence,werandomlysamplea
generalizetounseendistributionsandmaytherefore
replacementandencryptitwitharandomkey. Inno-
be less susceptible to biases in their training data.
opscases,theinputshouldbereturned. Wegenerate
Additionalresearchandextensiveexperimentswould
trainingsetsof40,000sequencesandtestthemonsets
beneededtoturnthisintoapracticaltechnique.
of5,000instances-eachgeneratedusingadistinct
word in the test dictionary and again a randomly
chosenkey. Bothsetscontain40%no-opscases.
References
We fine-tuned the pre-trained language model
AlexanderBukharinandTuoZhao.2024. Datadiversity
(Llama2-7b)(Touvronetal.,2023)withLoRA(Hu
mattersforrobustinstructiontuning.
et al., 2021) with rank 512 and α of 1024 till
convergence. Consistentwithourearlierobservations, Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan
the diversity of instructions benefits the model’s
Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion
generalization. Withasmallernumberofinstructions,
Stoica,andEricP.Xing.2023. Vicuna:Anopen-source
thepre-trainedLLMalsoonlysolvesno-opcasesbut chatbotimpressinggpt-4with90%*chatgptquality.
ycaruccAHyung Won Chung, Le Hou, Shayne Longpre, Barret Shayne Longpre, Le Hou, Tu Vu, Albert Webson,
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V.
Wang,MostafaDehghani,SiddharthaBrahma,Albert Le,BarretZoph,JasonWei,andAdamRoberts.2023.
Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac The flan collection: Designing data and methods for
Suzgun, XinyunChen, AakankshaChowdhery, Alex effectiveinstructiontuning.
Castro-Ros,MariePellat,KevinRobinson,DashaValter,
A.A.Markov.1954. Thetheoryofalgorithms,volume42.
Sharan Narang, Gaurav Mishra, Adams Yu, Vincent
Acad.Sci.USSR.
Zhao,YanpingHuang,AndrewDai,HongkunYu,Slav
Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam
BaolinPeng,ChunyuanLi,PengchengHe,MichelGalley,
Roberts, Denny Zhou, Quoc V. Le, and Jason Wei.
andJianfengGao.2023. Instructiontuningwithgpt-4.
2022. Scalinginstruction-finetunedlanguagemodels.
AlecRadford,JeffWu,RewonChild,DavidLuan,Dario
MikeConover,MattHayes,AnkitMathur,JianweiXie,Jun Amodei,andIlyaSutskever.2019. Languagemodels
Wan,SamShah,AliGhodsi,PatrickWendell,MateiZa- areunsupervisedmultitasklearners.
haria,andReynoldXin.2023. Freedolly:Introducing
theworld’sfirsttrulyopeninstruction-tunedllm. Victor Sanh, Albert Webson, Colin Raffel, Stephen H.
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Or Honovich, Thomas Scialom, Omer Levy, and Timo Chaffin, ArnaudStiegler, TevenLeScao, ArunRaja,
Schick.2022. Unnaturalinstructions:Tuninglanguage Manan Dey, M Saiful Bari, Canwen Xu, Urmish
modelswith(almost)nohumanlabor. Thakker, Shanya Sharma Sharma, Eliza Szczechla,
Taewoon Kim, Gunjan Chhablani, Nihal Nayak,
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan DebajyotiDatta,JonathanChang,MikeTian-JianJiang,
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and HanWang, MatteoManica, ShengShen, ZhengXin
Weizhu Chen. 2021. Lora: Low-rank adaptation of Yong,HarshitPandey,RachelBawden,ThomasWang,
largelanguagemodels. TrishalaNeeraj,JosRozen,AbheeshtSharma,Andrea
Santilli,ThibaultFevry,JasonAlanFries,RyanTeehan,
Srinivasan Iyer, Xi Victoria Lin, Ramakanth Pasunuru, TaliBers,StellaBiderman,LeoGao,ThomasWolf,and
TodorMihaylov,DanielSimig,PingYu,KurtShuster, AlexanderM.Rush.2022. Multitaskpromptedtraining
TianluWang,QingLiu,PunitSinghKoura,etal.2022. enableszero-shottaskgeneralization.
Opt-iml: Scaling language model instruction meta
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
learning through the lens of generalization. arXiv
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
preprintarXiv:2212.12017.
and Tatsunori B. Hashimoto. 2023. Stanford alpaca:
An instruction-following llama model. https:
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish
//github.com/tatsu-lab/stanford_alpaca.
Sabharwal,OyvindTafjord,PeterClark,andHannaneh
Hajishirzi. 2020. UNIFIEDQA: Crossing format HugoTouvron,LouisMartin,KevinStone,PeterAlbert,
boundaries with a single QA system. In Findings AmjadAlmahairi,YasmineBabaei,NikolayBashlykov,
of the Association for Computational Linguistics: SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,Dan
EMNLP2020,pages1896–1907,Online.Association Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya
forComputationalLinguistics. Chen,GuillemCucurull,DavidEsiobu,JudeFernandes,
Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao,
Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, VedanujGoswami,NamanGoyal,AnthonyHartshorn,
SeonghyeonYe,JaminShin,andMinjoonSeo.2023. SagharHosseini,RuiHou,HakanInan,MarcinKardas,
Thecotcollection: Improvingzero-shotandfew-shot Viktor Kerkez, Madian Khabsa, Isabel Kloumann,
learning of language models via chain-of-thought Artem Korenev, Punit Singh Koura, Marie-Anne
fine-tuning. Lachaux,ThibautLavril,JenyaLee,DianaLiskovich,
Yinghai Lu, Yuning Mao, Xavier Martinet, Todor
AbdullatifKöksal,TimoSchick,AnnaKorhonen,andHin-
Mihaylov,PushkarMishra,IgorMolybog,YixinNie,
richSchütze.2023. Longform:Optimizinginstruction
Andrew Poulton, Jeremy Reizenstein, Rashi Rungta,
tuningforlongtextgenerationwithcorpusextraction.
KalyanSaladi,AlanSchelten,RuanSilva,EricMichael
Smith, Ranjan Subramanian, Xiaoqing Ellen Tan,
AndreasKöpf,YannicKilcher,DimitrivonRütte,Sotiris
BinhTang,RossTaylor,AdinaWilliams,JianXiang
Anagnostidis, Zhi-RuiTam, KeithStevens, Abdullah
Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen
Barhoum,NguyenMinhDuc,OliverStanley,Richárd
Zhang,AngelaFan,MelanieKambadur,SharanNarang,
Nagyfi, Shahul ES, Sameer Suri, David Glushkov,
Aurelien Rodriguez, Robert Stojnic, Sergey Edunov,
ArnavDantuluri,AndrewMaguire,ChristophSchuh-
andThomasScialom.2023. Llama2:Openfoundation
mann, Huu Nguyen, and Alexander Mattick. 2023.
andfine-tunedchatmodels.
Openassistant conversations – democratizing large
languagemodelalignment. Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack
Hessel,TusharKhot,KhyathiRaghaviChandu,David
Shihao Liang, Runchu Tian, Kunlun Zhu, Yujia Qin, Wadden,KelseyMacMillan,NoahA.Smith,IzBeltagy,
HuadongWang,XinCong,ZhiyuanLiu,XiaojiangLiu, andHannanehHajishirzi.2023a. Howfarcancamels
andMaosongSun.2024. Exploringformatconsistency go? exploringthestateofinstructiontuningonopen
forinstructiontuning. resources.YizhongWang, YeganehKordi, SwaroopMishra, Alisa A ComplementonMarkovalgorithms
Liu,NoahA.Smith,DanielKhashabi,andHannaneh
Hajishirzi. 2023b. Self-instruct: Aligning language Markovalgorithms(Markov,1954)areorderedsets
modelswithself-generatedinstructions. ofrewriterules,operatingonsequencesofsymbols
in a fixed alphabet U. A sequence S is processed
YizhongWang,SwaroopMishra,PegahAlipoormolabashi,
YeganehKordi,AmirrezaMirzaei,AnjanaArunkumar, by applying the first rewrite applicable to S, at the
ArjunAshok,ArutSelvanDhanasekaran,AtharvaNaik, leftmostpositionifseveralexist: i.e. therewriterule
David Stap, Eshaan Pathak, Giannis Karamanolakis, ss→trtransformsthesequenceS=mississipiinto
HaizhiGaryLai,IshanPurohit,IshaniMondal,Jacob S′=mitrissipi. ThealgorithmisthenappliedtoS′,
Anderson, Kirby Kuznia, Krima Doshi, Maitreya
andtheprocessisrepeateduntileithernorulesapply,
Patel,KuntalKumarPal,MehradMoradshahi,Mihir
Parmar,MiraliPurohit,NeerajVarshney,PhaniRohitha andthealgorithmissaidtobeblocked,oraspecial
Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang rule,calledastopruleisinvoked,andthealgorithm
Karia,ShailajaKeyurSampat,SavanDoshi,Siddhartha
terminatesandreturnsthefinalrewrittensequence.
Mishra, Sujan Reddy, Sumanta Patro, Tanay Dixit,
Specifically, the algorithm uses and alphabet A,
XudongShen,ChittaBaral,YejinChoi,NoahA.Smith,
Hannaneh Hajishirzi, and Daniel Khashabi. 2022. whichincludesthealphabetU usedbuythesequences
Super-naturalinstructions:Generalizationviadeclarative tobeprocessed(henceforth,smallcaselatinletters),
instructionson1600+nlptasks.
a set of additional symbols (henceforth, the small
CanXu,QingfengSun,KaiZheng,XiuboGeng,PuZhao, case greek letters {α,β...}, and a special symbol ·
JiazhanFeng,ChongyangTao,andDaxinJiang.2023. indicatingastoprule.
Wizardlm: Empowering large language models to For instance, we could define the following
followcomplexinstructions.
algorithm,withU={a,b},andA={a,b,α,β,·},and
Qinyuan Ye, Bill Yuchen Lin, and Xiang Ren. 2021. therules
Crossfit: Afew-shotlearningchallengeforcross-task
generalizationinnlp.
αx → xαβx (1)
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao
Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, βxy → yβx (2)
LiliYu,SusanZhang,GargiGhosh,MikeLewis,Luke
αβx → xα (3)
Zettlemoyer,andOmerLevy.2023. Lima:Lessismore
foralignment. α → · (4)
→ α (5)
wherexandy standforanyletteraorb. Thiswill
transformanysequenceofaandbintoaconcatenation
ofthesequenceanditsreverse. Appliedonabb,the
algorithmwillperformthefollowingrewrites:
abb→αabb (by5)
αabb→aαβabb (by1)
aαβabb→aαbβab (by2)
aαbβab→abαβbβab (by1)
abαbβbβab→abαβbbβa (by2)
abαβbbβa→abαbβbβa (by2)
abαbβbβa→abbαβbβbβa (by1)
abbαβbβbβa→abbbαβbβa (by3)
abbbαβbβa→abbbbαβa (by3)
abbbbαβa→abbbbaα (by3)
abbbbaα→abbbba (by4)
Sincerule4isastoprule,thealgorithmterminates
andreturnsabbbba.Judiciousintroductionofadditional(greek)letters
allowsonetocomposeMarkovalgorithms,effectively
writingcomplexprograms. Anyeffectiveprocess(i.e.
finitecomputation)canberepresentedasaMarkov
algorithm(thisisMarkov’sthesis).
B Experimentalset-up
B.1 ModelandTraining
Inrewriteexperiments,wetrainGPT-2models(Rad-
fordetal.,2019),adecoder-onlytransformer-based
architecture, with 6 layers, 256 dimensions and
4 attention heads from scratch, on a generated
instruction-tuningdatasetusingstandardsupervised
fine-tuningapproach. WeusetheAdamWoptimizer,
a learning rate of 10−3, and linear scheduling. All
modelsaretrainedfor50epochs. Fortheencrypted-
rewritingtask,weLoRAfine-tunedLlama-2models
withalearningrateof1e-4,batchsize64,8-bitquanti-
zation. Themodeltakesabout2000stepstoconverge.
Weusedgreedydecodingforallexperiments.
B.2 DataGeneration
Exceptforthediversityofsemanticsexperiment,the
results we reported in the main paper are obtained
from an input length of 50 and a pattern length of
20. To validate the generality of our findings, we
conducted experiments on various input sizes {50,
100, 200} and, correspondingly, pattern lengths
{20,40,50}.
Inthediversityofsemanticsexperiment,weused
aninputlengthof500andapatternlengthof60. We
strictly restricted the sub-strings to look for and to
replacethemwithbothtobeunseenduringtesting.