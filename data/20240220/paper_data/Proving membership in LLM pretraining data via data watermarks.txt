Proving membership in LLM pretraining data via data watermarks
JohnnyTian-ZhengWei∗ RyanYixiangWang∗ RobinJia
DepartmentofComputerScience,UniversityofSouthernCalifornia
{jtwei, ryanywan, robinjia}@usc.edu
Abstract
Z-score
-6 -4 -2 0 2
Detecting whether copyright holders’ works
wereusedinLLMpretrainingispoisedtobean
importantproblem. Thisworkproposesusing
datawatermarkstoenableprincipleddetection
with only black-box model access, provided
thattherightholdercontributedmultipletrain-
MPadd*t6Ex ingdocumentsandwatermarkedthembefore
publicrelease. Byapplyingarandomlysam-
pleddatawatermark,detectioncanbeframed
ashypothesistesting,whichprovidesguaran- 2 4 6 8 10
tees on the false detection rate. We study Avg. token loss
two watermarks: one that inserts random se-
quences,andanotherthatrandomlysubstitutes Figure 1: An illustration of hypothesis testing
characters with Unicode lookalikes. We first for membership inference. The rightholder inserts
showhowthreeaspectsofwatermarkdesign—
"MPadd*t6Ex"acrosstheirdocumentcollectionbefore
watermarklength,numberofduplications,and publicrelease,whichwassampledfromadistributionof
interference—affectthepowerofthehypoth- randomsequences. Themodel’saveragetokenlosson
esis test. Next, we study how a watermark’s alltherandomsequencesformsanulldistribution,and
detection strength changes under model and thelossontheincludedwatermarkistheteststatistic.
dataset scaling: while increasing the dataset The effectiveness of hypothesis test is determined by
size decreases the strength of the watermark, theeffectsize,andvarianceofthenulldistribution.
watermarksremainstrongifthemodelsizealso
increases. Finally,weviewSHAhashesasnat-
whether rightholders’ works were used for large
uralwatermarksandshowthatwecanrobustly
detect hashes from BLOOM-176B’s training languagemodel(LLM)trainingispoisedtobean
data,aslongastheyoccurredatleast90times. importanttechnicalproblem.
Together,ourresultspointtowardsapromising Asanexample,TheNewYorkTimesCo. v. Mi-
futurefordatawatermarksinrealworlduse. crosoftCorp.,S.D.N.Y.20232 isarecentcopyright
infringementlawsuitfiledintheU.S.,whereakey
1 Introduction
pieceofevidenceisthefactthatChatGPTcanre-
Many jurisdictions will likely give authors and producelongsnippetsofhistoricalnewsarticles.3
other copyright holders a right to opt-out their Ingeneral,usingexactreproductiontoprovetexts
worksfrommachinelearningtrainingdata. Inthe weretrainedonisquestionable: certaintextmaybe
EU,suchrightsaregrantedbythetextanddatamin- easytopredictforthemodel,especiallyaftertrain-
ingexceptions,1 whichrequireanynon-academics ingonothersourcesofinformationontheinternet.
whominedatatorespectopt-outrequestsfromthe
rightholdersofthatdata(Keller,2023). IntheU.S., 2The New York Times Co. v. Microsoft Corp., No.
1:2023cv11195, 17 U.S.C. § 501 Copyright Infringement
therighttoopt-outwillbedeterminedbyongoing
(S.D.N.Y.filedDec.27,2023).
copyrightlawsuits. Asthelawdevelops,detecting 3Trainingonrightholders’datadoesnotimmediatelycon-
stitutecopyrightinfringement, seeHendersonetal.(2023)
1Directive(EU)2019/790oftheEuropeanParliamentand foranoverviewoffairuseandmachinelearning. However,
oftheCouncilof17April2019oncopyrightandrelatedrights whethercopyrighteddatawasincludedintrainingwillbean
intheDigitalSingleMarketandamendingDirectives96/9/EC importantpieceofevidencetomakeastrongcaseforcopy-
and2001/29/EC.Article4. rightinfringement.
4202
beF
61
]RC.sc[
1v29801.2042:viXraInpursuinglegalaction,itwouldbebesttoprovide given test set is present in the training data of a
statistically sound evidence which indicates that languagemodel(termedasdatacontamination;see
the rightholder’s data was used for training with MagarandSchwartz,2022). Theirmethodassumes
highprobability. thetestdatawasrandomlyshuffledpriortorelease,
In this work, we propose data watermarks, which allows the model’s preference for the re-
whichallowrightholderstostatisticallyprovethat leased ordering to be tested against random per-
anLLMhastrainedontheirdata.4 Centraltoour mutations. Ourworkinsteadintentionallyinsertsa
methodisahypothesistest,whichprovidesstatis- randomlychosenwatermark,whichisapplicableto
ticalguaranteesonthefalsedetectionrate(§3.1). arbitrarydocumentcollections. Inimageclassifica-
Our method first randomly inserts one of many tion,Sablayrollesetal.(2020)provideahypothesis
possible data watermarks across a document col- testingmethodtodetectdatasetmembershipbywa-
lection. Amodel’slossontheinsertedwatermark termarkingimageswithrandomperturbations. Our
can then be compared against those of randomly workprovidesinsightsintowatermarkdesignfor
sampled watermarks. If the loss on the inserted languagedataanddemonstratesthefeasibilityof
watermarkislowerinastatisticallysignificantway, hypothesistesting-baseddetectionforLLMs.
wecanbeconfidentthatthemodeltrainedonthe Tangetal.(2023)useadversarialattackstocre-
watermarkeddocuments(illustratedinFigure1). ate backdoors for verifying dataset membership
We introduce two types of data watermarks: (comingfromalineageofworkonbackdoors,see
one that inserts random character sequences and Wallaceetal.,2021). However,theirmethodsdo
whose controllable properties inform watermark notuserandomnessandremainheuristic. Without
design (§3.2), and another that randomly substi- randomness,thebehaviorofamodelthathasnot
tutes ASCII characters with Unicode lookalikes been backdoored is not easily known. Random-
and is imperceptible to humans (§3.3). In §4, nessallowstheinsertedwatermarktobecompared
we train medium-sized language models on wa- againstanulldistributionofrandomwatermarks;
termarkeddatasetsandstudyhowaspectsofwater- Carlini et al. (2019) study such null distributions
markdesign—numberofwatermarkeddocuments, forrandomsequencesbutinthecontextofprivacy.
watermarklength,andinterference—influencethe Tothebestofourknowledge,ourworkisthefirst
varianceandeffectsizeofthenulldistribution,and tocombinehypothesistestingandrandompertur-
thereforethepowerofthehypothesistest. bationstoprovideprincipleddetectionofdataset
Finally,wedemonstratethepromiseofdatawa- membershipinlanguagemodels.
termarksevenforverylargeLLMs. In§5,wecon-
ductscalingexperimentsondatawatermarksand Membership inference. Work in membership
findthatwatermarksbecomeweaker(i.e.,harder inference seeks to use the model to infer which
todetect)asthetrainingdatasetgrowslarger,but data are members of the training data (Hu et al.,
remainstrongifthemodelsizegrowsalongwith 2022). Ourworksharessimilargoals,butmethods
it. In§6,weconfirmthefeasibilityofdatawater- inmembershipinferenceareprimarilymotivated
marksona176-billionparameterLLM.Bytesting byprivacyconcerns,aimingtoextractpartsofthe
BLOOM-176BonSHAhashesinStackExchange trainingdataorsensitivesecrets. Ourfocusison
asnaturalwatermarks,wefindthathashescanbe anarrowercaseofmembershipinference,seeking
robustly detected, as long as they occurred more only to detect whether rightholders’ documents
than 90 times in the training data. This suggests were trained on. We assume that the documents
thatdatawatermarkscanenabledetectionevenfor could be perturbed beforehand, and our problem
smalldocumentcollections,pointingtoapromis- admitsastatisticalsolution.
ingfutureforitsrealworlduse. Many membership inference works cannot be
directlyappliedtoLLMs,astheytrainadistribu-
2 Relatedwork tionofmodelswithslightlydifferenttrainingsets
(Shokri et al., 2017; Carlini et al., 2022). This
Datasetmembership. Orenetal.(2023)provide
would be impractical for LLMs, as training even
a hypothesis testing method to detect whether a
onesuchmodeliscomputationallyexpensiveand
4Werefertoperturbingatextcollectionasdatawatermark- the datasets are often proprietary (Brown et al.,
ing,butwedistinguishitfromworkswhichusewatermarksto
2020). Carlinietal.(2021)performsmembership
identifymachine-generatedtext(Kirchenbaueretal.,2023a;
Venugopaletal.,2011). inferenceonLLMsbycomparingtoanothercanon-icallanguagemodel,whichsidestepstrainingcosts measuringmemorizationinthemembership
but offers no statistical guarantees. Since we as- inferenceliterature(Carlinietal.,2021).
sume that the data is randomly perturbed before- Arightholderwouldfirstsampleasecretrandom
hand, we know that a clean model should only seed s ∼ U, then publicly release the perturbed
recognizetheseperturbationsatlevelsofrandom collectionD′ = π(D,s). Testingwhetheramodel
s
chanceanddonotneedacanonicalmodel. has seen D′ can now be formulated as hypothe-
s
sistesting,whichguaranteesafalsedetectionrate
Memorization. The ability of LLMs to mem- (basedonanαthreshold). Ahypothesistestmea-
orize its training data is key to any membership sureshow“unusual”itistoobserveourteststatistic
inference. LLMsareknowntomemorizesomeof T = f(D′)assuminganullhypothesis:
s
their training data (Zhang et al., 2021), and two
factorsarewell-studiedrelatingtoanLLMsabil- H 0: The language model has not seen
ity to memorize: the number of times a piece of theperturbedcollectionD s′.
dataisduplicatedinthetrainingdata(moredupli-
Under the null hypothesis, the model should not
cations implies better completion rates; Kandpal
beabletodistinguishsfromotherrandomseeds.
etal.,2022),andsizeofthemodel(largermodels
Thus, the observed test statistic T = f(D′)
impliesbettercompletion;Tirumalaetal.,2022b). s
should look like samples from the null distribu-
Ourworkexploreshowthesekeypropertiessubse-
tion of f(π(D,r)) with r ∼ U. We empirically
quentlyaffectthestrengthofdatawatermarks.
construct the null distribution by sampling many
r ∼ U and computing f(π(D,r)), then estimate
3 Datawatermarks
Pr [f(π(D,r)) < T]asourp-value. Bydeclar-
r∼U
ing a significant result and rejecting the null hy-
Ourworkproposestheuseofdatawatermarksto
pothesis H only when p < α, we can guarantee
detectwhetherarightholder’sdocumentcollection 0
thatourfalsedetectionrateisnomorethanα.
isinthetrainingdataofanLLM.Inthecontextof
Figure1illustratesahypothesistest. Intuitively,
opting-out,wemaketwoobservations: (1)Collec-
thestrengthof thetestdependsontheeffect size
tions(e.g. newsarticles)areoftencentrallyacces-
(i.e. distancebetweenT andthenulldistribution)
sible(i.e. throughanewswebsite),andthetraining
andthevariance(i.e. spreadofthenull),whichwe
datacontainseithernoneormanyofthedocuments.
measure with Z-scores (i.e. number of standard
(2)Asrightholdershavecontroloverhowtheirdata
deviationsawayT isfromthenull). Thestatistical
isdistributed,thepublicversionsofthedocuments
power of the test (i.e. likelihood of a significant
can be randomly perturbed. In this setting, this
results)willthendependontheabilityofthelan-
problemadmitsastatisticalsolution.
guagemodeltomemorizeperturbationsofπ,and
3.1 Testingfordatawatermarks howwellthismemorizationisreflectedinf.
Toenablethedetectionoflanguagemodeltraining Z-scores. The tests in this work do not make a
onadocumentcollectionD,weintroduceatesting distributionalassumptiononthenull—p-valuesare
frameworkwiththreecomponents: directlycalculatedusingtheempiricalnulldistribu-
• A random seed r. Let r ∼ U be a random tion. However,theteststatisticisoftensmallerthan
seedsampledfromadistributionU. Theran- allofoursamplesfromtheempiricalnulldistribu-
domnessinU inducesthenulldistribution. tion, so we characterize watermark strength with
• A perturbation function π. Let π(D,r) = Z-scores (i.e., the number of standard deviations
D′ be a perturbation function that returns a betweenT andthemeanofthenulldistribution).
watermarked collection D′ by perturbing D Ifweassumethatf isroughlynormal,5 aZ-score
accordingtoseedr,whichseedstherandom of±2correspondstoap-valueofabout0.05,and
numbergeneratorusedtoperturbdocuments. a Z-score of ±4 is extreme enough for most use
• Ascoringfunctionf. Letf(D′)beascalar casesinvolvingmultipletesting.
functionwhichmeasuresthemodel’smemo-
5Whilef isasumoflossesovertokens,thesetoken-level
rizationondocumentsinD perturbedaccord- lossesmaynotbeindependentsothenulldistributionmay
ing to r. Any function can be used for f; notbenormal.Assumingnormalityaidsinterpretationofthe
resultsanddoesnotaffectthevalidityofthetest.Weprovide
we use the model loss on all or some of the
furtheranalysisonthenulldistributionsinAppendixAand
textinD′,aslossisknowntobeeffectivefor
findthattheyareroughlynormal.3.2 Randomsequencewatermark acrossalldocumentsinD. π thenreturnsthedoc-
umentcollectionwherethesubstitutionsspecified
Asafirstapproach,wewillconsiderawatermark
byv areappliedtoD.
that appends a sequence of random characters to
theendofandocument. Thiswatermarkdoesnot
Word-levelperturbation. Theword-levelUni-
alter the original text and offers control over its
code watermark replaces each unique word in D
duplication and length, which allows for careful
withaconsistentUnicodelookalike. Theperturba-
studyonhowthesedesignelementsimpactwater-
tionfunctionπ firstcreatesarandommappingm
mark strength. In practice, the rightholder could
(seededbyr)thatmapseachuniquewordw inD
programmaticalyhidetheserandomsequencesin
(tokenizedbywhitespace)toareplacement. Each
a webpage. Since the pretraining data for LLMs
word’sreplacementischoseninthesamewayas
is very large, it is reasonable to assume that ad-
the global Unicode watermark, but we sample a
ditionalpreprocessingwillnotaffecttheinserted
differentv foreachwordandapplyitonlytothat
watermark,andsuchassumptionsarecommonin
word. Finally, we apply the mapping m to each
promptinjection(Greshakeetal.,2023)andback-
word in each document x ∈ D to yield π(D,r).
dooringworks(Chenetal.,2021). Weinstantiate
Table1oftheAppendixprovidesanillustration.
componentsofthetestingframeworkbelow:
Scoringfunction. f(D)isdefinedasthemodel’s
Perturbation. π firstcreatesarandomcharacter
average token loss on the last 512 tokens in D
sequencew oflengthnaccordingtorandomseed
(wheresomemayberegularwords,andsomemay
r by sampling from the ASCII table (the first 0-
beUnicodesegmentedsequences). Wechooseto
100indexesoftheGPT2Tokenizer6). π returnsa
upperboundthenumberoftokensf averagesover
documentcollectionwithw concatenatedtoeach
toreducecomputationalcosts.
x ∈ D. In§4,westudytheeffectofvaryingn.
Scoringfunction. f(D)isdefinedasthemodel’s 4 Relatingwatermarkdesigntostrength
averagetokenlossononlythewatermarkstringw
In this section, we train many medium-sized lan-
whichwasappendedtoallthedocumentsofD.
guage models on watermarked datasets and mea-
3.3 Unicodewatermark sure the strengths of the watermarks. We further
explorehowdifferentpropertiesofthewatermark
Weproposeaseconddatawatermarkthatisembed-
affectsthepowerofthehypothesistest,eitherbyin-
dedintothetextandimperceptibletohumansby
creasingtheeffectsize(i.e.,thedifferencebetween
usingUnicodelookalikes(alsocalledhomoglyphs).
theteststatisticandmeanofthenulldistribution)
Unicodeattacksarewell-studiedforarangeoftext
ordecreasingthevarianceofthenulldistribution
applicationsandrelyonthetokenizer’ssensitivity
(asillustratedinFigure1).
toUnicodecharacterstoperturbaninputsequence
(Boucher et al., 2021). Further considerations re-
4.1 Experimentalsetup
latedtowatermarkstealtharediscussedin§7. We
curateaconservativelistof28Unicodelookalike Training. We use GPT-NeoX (Andonian et al.,
substitutionsfortheupperandlowercaseASCII 2023)totrainourlanguagemodels. Thetraining
alphabet.7 TherearetwovariantsoftheUnicode parameters we use are adapted from Pythia (Bi-
watermark: globalandword-level,andweinstanti- dermanetal.,2023),whichinheritsstandardprac-
atethecomponentsofthetestingframeworkbelow: ticeoftrainingthelanguagemodelontheshuffled
trainingdataforoneepoch. Thismeansthateach
Global perturbation. For the global Unicode
instance of the data watermark is seen only once
watermark,πfirstgeneratesarandombinaryvector
but its duplications are encountered periodically
voflength28accordingtor. Eachindexofvspec-
throughout training. The batch sizes used in this
ifieswhetherthecorrespondingASCIIcharacteris
section are small (128 batch size, 512 sequence
substitutedwithitsUnicodelookalikeeverywhere,
length)toaccommodatethesmallertrainingdata.
6https://huggingface.co/gpt2/raw/main/vocab.
json Datasets. Forallourexperiments,weusesubsets
7We use character lookalikes only if they are rendered ofthePileastrainingdata(Gaoetal.,2020). We
identicallyinbothArialandConsolas.Thesearetwodefault
assumethatweareprotectingadocumentcollec-
fontsinapopularonlinebrowser.Thefulllistofsubstitutions
isgiveninAppendixC.1. tion D of up to n documents, sampled randomly(a) Number of documents & length (b) Length = 80 (c) Number of documents = 128
0 10 10
8 8
5
6 6
10
4 4
Watermark len
15 10 40 2 2
20 80
20 0 0
1 4 16 64 256 1024 1 4 16 64 256 1024 10 20 40 80
# of documents # of documents Watermark length
Figure2:Experimentsonrandomsequencewatermarksrelatingitslengthandthenumberofwatermarkeddocuments
tothedetectionstrength. Resultsin(a)areaveragedover5runs,and(b)and(c)visualizesthenulldistributionand
teststatisticforonerun. LowernegativeZ-scoresindicatestrongerwatermarks. (a)Watermarkstrengthincreases
asthedocumentsincrease,buttapersoutquickly. Watermarklengthdeterminestheeventualstrength. (b)Fixinga
watermarklength,asthenumberofwatermarkeddocumentsincreases,thewatermarklossdecreases. (c)Fixingthe
numberofwatermarkeddocuments,asthewatermarklengthincreases,thenulldistribution’svariancedecreases.
fromthetrainingsubset. Foralltheexperimentsin thenulldistribution,sothewatermarklengthdeter-
thissection,weusethePile’sfirst100Mtokens. mineswheredetectionstrengthtapersout. Unlike
theeffectsize,thevariancecanalwaysdecreaseas
Compute. Weuseupto8RTXA6000sforour
itisinverselyrelatedtothenumberoftokens.
experiments. Forreference,traininga70Mparam-
etermodelon100Mtokenstakes0.5GPUhours. ForUnicodewatermarks,theword-levelvariant
Resultsinthissectionareaveragedover5runs. hasmorerandomnessandisstronger. InFig-
ure3(a),weseethattheword-levelvariantofthe
4.2 Results
Unicodewatermarkisstrongerthantheglobalvari-
Watermarking more documents increases the ant. Whiletheglobalvariantsamplesonerandom
effect size. In Figure 2(a), we see that for wa- binary vector of length 28 (the possible Unicode
termarks of the same length, watermarking more substitutions),theword-levelvariantsamplessepa-
documents increases the effect size and strength- ratecharactersubstitutionsforeachword. Onaver-
ensthewatermark. LLMsareknowntomemorize age,eachwordhas2.5charactersthatcanbesubsti-
duplicatedsequenceswell(Kandpaletal.,2022), tutedforaUnicodelookalike,sothetotalnumber
andFigure2(b)showsthatasmoredocumentsare of bits is 2.5|V|, where |V| is the size of the vo-
appended with the random sequence watermark, cabulary (for a collection of 256 documents, |V|
themodel’slossontherandomsequencequickly is roughly 118,000). Based on the Z-scores, this
decreasesthentapersout. Sincetheteststatisticis Unicodewatermarkisnearlyequivalentinstrength
the loss of the watermark, which cannot be nega- tothe20lengthrandomsequencewatermark.
tive,duplicatingthewatermarkacrossdocuments
IndependentUnicodewatermarksreduceeach
cannotunboundedlyincreasethestrengthofthewa-
other’seffectsizes. InFigure3(b),westudythe
termark. Thereareonlymarginalgainsindetection
strengthofawatermarkwhenmultipleindependent
strengthwhenwatermarkingover200documents.
rightsholdersusethesamewatermarkingmethod
The null distributions of longer watermarks (withdifferentrandomsecrets)toeachwatermark
havelowervariance. InFigure2(a),weseethat theirowndocumentcollections. Whiletherandom
whenfixingthenumberofdocumentswatermarked, character watermark is not affected much by in-
longerwatermarksarestronger. Asf(π(D,r))is terference, the independent Unicode watermarks
anaveragelossoverwatermarktokens,Figure2(c) interferewitheachotheranddecreaseeachother’s
showsthemoretokensf averagesover,thelower strength. Figure3(c)showsthatinterferenceshifts
its variance. Once enough documents are water- thenulldistribution,decreasingtheeffectsize. For
markedtomaximizetheeffectsize,thestrengthof theUnicodewatermark,manywordsonlyhavea
thehypothesistestthendependsonthevarianceof few unique segmentations when Unicode looka-
erocs-Z
ssoL(a) Unicode variants (b) Interference (256 docs/exp) (c) Unicode interference
0 0 3.8
Random sequence
2 2 Unicode (word-level) 3.6
4 4 3.4
6 6 3.2
8 8 3.0
Global
10 Word-level 10 2.8
1 4 16 64 256 1024 1 2 4 8 16 1 2 4 8 16
# of documents # of indep. watermarks # of indep. watermarks
Figure3: ExperimentsonUnicodevariantsandinterference. (a)and(b)areaveragedover5runsand(c)visualizes
the null distribution and test statistic on one run. (a) Word-level Unicode watermarks outperforms the global
variant. (b)InsertingmultipleindependentUnicodewatermarks(256docsperexperiment)causestheirstrengthsto
degrade,butrandomsequencesarenotaffectedbyinterference. (c)Fortheword-levelUnicodewatermark,asmore
independentwatermarksareinserted,thenulldistributionshiftsdown,causingthestrengthtodrop.
likesaresubstituted. Asthetrainingdatacontains size. Carlini et al. (2019) show that a model’s
more independent Unicode watermarks, most of loss on a random sequence decreases when train-
these forms will appear in training. For random ingonbatchesthatcontaintherandomsequence,
characterwatermarks,thenulldistributionconsists andslowlyincreaseswhentrainingonbatchesthat
ofalargespaceofrandomsequencesandthemem- donotcontainit. Thisintuitionexplainswhythe
orizationofanumberofrandomsequenceshasno lossonthewatermarkwoulddirectlyrelatetoits
largeeffectontheentirenulldistribution. relativefrequencyinthetrainingdata.
5 Watermarksunderscaling
Scalingupthemodelsizeincreasesthestrength
Boththetrainingdatasetsandmodelsizesarevery ofthewatermark. Figure4(a)showsthatwater-
large for popular LLMs. To show that data wa- marks are stronger on larger models, when train-
termarks can be effective for large-scale models, ing on a fixed amount of data. The results here
we fix a watermarked document collection while concur with Tirumala et al. (2022a), where they
scaling both the dataset and model size. We fo- observe that larger models memorize with less
cusontherandomsequencewatermarkhere,and epochs. Comparing across 4(b) and (c), the 70M
presentsimilarfindingsfortheword-levelUnicode and410Mmodelshavesimilarnulldistributions,
watermarkinAppendixC.3. butthelargermodelexhibitslowerlossonthewa-
termark for the same training setting. The 410M
5.1 Experimentalsetup modelisqualitativelydifferentthanthe70Mmodel
Thesetupheremirrorsthesetupin§4.1,withthe undertrainingdatascaling,wheretheteststatistic
exceptionofthetrainingdataandbatchsize. For almostdoesnotchangeatall.
trainingdata,weuseupto12Btokens(exhausting
the first shard of the Pile). For batch sizes, we Scalingupboththemodelandtrainingdatare-
increasethenumberofsequenceperbatchto1024. sultsinstrongwatermarking. Theexperiments
Resultsareaveragedover3runs. herescaleboththetrainingdataandmodelsizeup
to 6 times. In our setting, when both factors are
5.2 Results
scaled, data watermarks remain strong with 256
Scaling up the training data decreases the watermarkeddocuments. Thesettingsweconsider
strengthofthewatermark. Figure4(b)shows herearestillsmallcomparedtopopularLLMs,but
thatasthetrainingdatasetgrowslarger,thelosson wenotethatthescaleofLLMsoftenoutpacesthe
therandomsequencewatermarksincreases,trans- scaleofthetrainingdata(Hoffmannetal.,2022).
latingtoaweakerdetectionstrength. Whenscaling Inthenextsection,weconductapost-hocstudyon
thetrainingdata,thefrequencyofencounteringa amuchlargerLLMtoprovideadditionalempirical
watermarkisinverselyrelatedtothetrainingdata supportforthefeasibilityofdatawatermarks.
erocs-Z
ssoL(a) Dataset scaling (z-score) (b) Model size = 70M (c) Model size = 410M
8 8
Model
70M
10 160M 6 6
410M
4 4
15
2 2
20
0 0
2 4 6 8 10 12 2 4 6 8 10 12 2 4 6 8 10 12
Dataset size (B tokens) Dataset size (B tokens) Dataset size (B tokens)
Figure4:Experimentsonrandomsequencewatermarksundermodelanddatasetscaling.Allexperimentswatermark
256documentswithalength80randomsequence. Resultsin(a)areaveragedover3runs,and(b)and(c)visualize
thenulldistributionandteststatisticforonerun. (a)Whenscalingthetrainingdata,watermarksbecomeweaker.
However,watermarksremainstrongforlargermodels. (b)Asdatasetsizescales,thewatermarklossofthe70M
modelincreases. (c)Asdatasetsizescales,thewatermarklossofthe410Mmodelroughlyremainsconstant.
6 Post-hocstudyonnaturalwatermarks the ROOTS search tool (Piktus et al., 2023) and
query for exact matches, where matches may ap-
To confirm the feasibility of data watermarks in
pearwithinthesamedocument.
real LLMs, we conduct a post-hoc study on the
detectabilityofSHAandMD5hashesinBLOOM- Models. Weprovideresultsforthe176Bvariant
176B(Scaoetal.,2022). Sinceagoodhashfunc- of BLOOM (Scao et al., 2022) here, and the 7B
tion produces hex sequences that are nearly ran- variantinAppendixD.2. Bothmodelsusedlarge
dom(Rivest,1992),theinclusionofthesehashes batchsizes(512and2048,respectively)andwere
intrainingformsanaturalexperiment. Wecande- trainedontheROOTScorpuscontaining341Bto-
tectthehashesasiftheyweresampledandinserted kensforoneepoch. The176Bmodelwastrained
as random sequence watermarks, where we test onanadditionalrepeated25Btokens.
themodel’slossonseenhashesagainstrandomly
sampledhexsequences. Somehashes,suchasthe 6.2 Results
MD5hashofanemptystring,appearinerrormes-
MorefrequenthasheshavebetterZ-scores. As
sagesorcodeandarewellduplicated. Sincemost
shown in Figure 5, high-occurrence hashes have
of BLOOM’s training data is publicly available,
lowerp-valuesandZ-scores,indicatinghigherwa-
we can pair observations of the occurrences of a
termarkstrength. However,thecorrelationbetween
hashwiththedetectionstrengthofthishash. With
occurrenceandstrengthisimperfect,sinceoccur-
theseobservations,weprovideadditionalempirical
rencesareaweakproxyfortheactualnumberof
guidanceonhowmuchduplicationisnecessaryto
watermarkeddocumentsahashmayhaveappeared
watermarkadocumentcollection.
in(manyoccurrencesmaybeconcentratedinone
document).8 For instance, we manually confirm
6.1 Experimentalsetup
that the two SHA-512 hashes with many occur-
Dataset. To find naturally occurring hex se-
rencesbutweakZ-scoresarerepeatedmanytimes
quences,wefilteredtheStackExchangesubsetof
inthesamedocument, sotheyappearedinfewer
theROOTScorpus(BLOOM’strainingdata;Lau-
distinct training batches than suggested by their
rençon et al., 2022), which is publicly available.
numberofoccurrences. Meanwhile,otherhashes
Weconsiderthreehashingalgorithms: MD5,SHA-
inFigure5arememorizedstronglydespiteoccur-
256,andSHA-512,anduseregularexpressionsthat
ringinrelativelyfewdocuments.
capturehexsequencesoftheappropriatelength(32,
64, and 128, respectively). Starting from the top Hashes occurring as few as 12 times can be
50 most frequently occurring hashes for each al- extremelystrong. Figure5showsanumberof
gorithm,wemanuallyexcludedsequenceswhich
8Ideally,wewouldprovidethenumberofuniquedocu-
are unlikely to be hashes (e.g. all 0s). To collect
mentseachhashappearedin,butweencounteredlimitations
thenumberofoccurrencesforeachhash, weuse oftheROOTSsearchtool.
erocS-Z
ssoLwatermarks—one that we suggested hiding pro-
1.0
grammatically, and another that is imperceptible
0.8
tohumans. Ifthewatermarkisobvious,malicious
0.6
modelcreatorscouldtamperwiththewatermark.
0.4 Hidingthewatermarkthroughwordsubstitutions
0.2 or semantic paraphrases (in the spirit of Venu-
0.0 gopaletal.,2011)isanaturalnextstep,whichre-
quiresfurtherstudyonwatermarkdetectabilityand
0 erasability(similartoKirchenbaueretal.,2023b)
5 Themaincontributionofthisworkistorelateba-
10 sic aspects of watermark design to the detection
Length
15 32 strength. We hope that future work uses our in-
64 sightsasaguideindesigningstealthydatawater-
20
128
marks. Finally, pretrained language models are
1 10 100 1000 oftenfine-tunedonhumanfeedback(Ouyangetal.,
Occurrences
2022), andwhetherdatawatermarkspersistafter
fine-tuningrequiresadditionalstudy.
Figure5: TestresultsforBLOOM-176BonSHAand
MD5hashesnaturallyoccurringinStackExchange. Oc- Beyondsupportingarighttoopt-out,datawater-
currencesarecollectedfromtheROOTSsearchtooland marksmayalsohavethepotentialtomeaningfully
multipleoccurrencesmayappearinthesamedocument. contributetothediscourseondatastewardshipfor
A SHA-512 hash occurring 12 times can achieve 10- responsible machine learning (Peng et al., 2021).
sigmadetection. Thedottedlinesdenotesathresholdof
Oneimportantquestioninthisareaishowtomit-
Z =−2andafalsedetectionrateofα<5%. Empiri-
igate the risks of unintended usages of open data
cally,robustdetectionispossiblepast90occurrences.
(TarkowskiandWarso,2022). Chanetal.(2023)
propose to establish a public trust for the digital
hashes that have extreme detection strength (less commons, where data watermarks could be used
than −10). In line with our findings in §4, the to verify whether models were trained on open
strongesthashesarethelongestones(i.e. SHA-512 data. Thetrustcouldthenensuretheircompliance
hashes)becausethevarianceofthenulldistribution with standards that align with the public interest.
ismuchlower. WhileaSHA-512watermarkcan Methodsthatstrengthentherelationshipbetween
achievestrongdetectionwithonly12occurrences, a model and its training data, such as data water-
theshorterMD5hashesarestrongonlywhenthey marks,mayopenupnewlegalfrontiersandpresent
occurmorethan100times. opportunities for training data to play a role in a
model’sresponsibledeployment.
Robustdetectionispossiblepast90occurrences.
BysettingaZ-scorethresholdof−2(correspond-
ingtoafalsedetectionrateα < 5%),wecanempir- 8 Conclusion
icallyestimatethenumberofoccurrencesneeded
for robust detection. Based on the observational
Tosupportarighttoopt-outofmodeltraining,our
datainFigure5,weestimatethatrobustdetection
workproposesthestudyofdatawatermarks. These
for BLOOM requires hashes to be duplicated 90
watermarksprovidestatisticalevidenceonwhether
timesormore. IfStackExchangewishedtodoso,
rightholders’datahasbeentrainedon. Byrelating
theycouldapplyarobustdatawatermarkbyinsert-
aspectsofwatermarkdesigntothestrengthofits
ingarelativelysmallnumberofdocumentscontain-
detection,ourinsightslaythegroundworkforfu-
ingasecrethash. Thisisnotaprohibitivelylarge
tureworkondatawatermarks. Scalingexperiments
duplicationrequirement,suggestingthatapplying
showthatdatawatermarksarestrongerforlarger
datawatermarksmaybefeasibleforrightholders
models, and a post-hoc study on naturally occur-
withsmallerdocumentcollections.
ringSHAhashesconfirmsthatrandomsequences
watermarkscouldbedetectedinBLOOM-176Bif
7 Futuredirections
itoccurredmorethan90timesinthetrainingdata.
Furtherresearchinseveralareasofdatawatermarks Together, our results point towards a promising
willenableitsmainstreamuse. Weproposedtwo futurefordatawatermarksinrealworlduse.
erocs-Z
eulav-p9 Limitations manyusecases,enforcingcopyrightisamajorone.
Building tools to support copyright law is not an
Limitationsofthemethodology. Themethods
ethicallyneutralposition,andweacknowledgethe
here cannot detect membership of arbitrary data,
potentialforunethicalabuseofcopyrightlaw,such
andadatacollectionhastobecarefullyprepared
asenablingcensorship(Tehranian,2015). Despite
beforepublicrelease. Inthecontextofsupporting
theseconcerns,webelievethatitisvaluabletocon-
arighttoopt-out,wefindtherelaxationsin§1to
ducttechnicalresearchthatcomplementsexisting
be practical, and show that data watermarks can
legalsystems. Asatechniquethatstrengthensthe
provide strong statistical guarantees (Oren et al.,
relationshipbetweenmodelsandtheirtrainingdata,
2023, studies a similar setting with restrictive as-
datawatermarkshavethepotentialtobroadenthe
sumptions). As testing for data watermarks is an
legaldiscourseonlargelanguagemodels.
auditingprocedure,itreliesonsomeformofblack-
box access, as opposed to observing output text
alone. Weassumedaccesstothelog-probabilities References
ofthemodel’spredictions,butextrastepsmaybe
MartínAbadi,AndyChu,IanJ.Goodfellow,H.Bren-
involvedtoobtainthelogprobabilitiesfromrestric-
dan McMahan, Ilya Mironov, Kunal Talwar, and
tiveAPIs(Morrisetal.,2023). Onthedesignofthe LiZhang.2016. Deeplearningwithdifferentialpri-
watermarks, both the random and unicode water- vacy. In Proceedings of the 2016 ACM SIGSAC
ConferenceonComputerandCommunicationsSe-
markscanberemovedormanipulated,andcreating
curity,Vienna,Austria,October24-28,2016,pages
undetectableandun-eraseablewatermarksrequires
308–318.ACM.
further study. Different training procedures such
AlexAndonian,QuentinAnthony,StellaBiderman,Sid
asdifferentiallyprivateoptimizationmayprevent
Black,PreethamGali,LeoGao,EricHallahan,Josh
watermarkmemorization(Abadietal.,2016),but
Levy-Kramer, Connor Leahy, Lucas Nestler, Kip
suchoptimizationmayalsoserveadualpurposein Parker,MichaelPieler,JasonPhang,ShivanshuPuro-
enablingthefairuseofthedata(Hendersonetal., hit,HaileySchoelkopf,DashiellStander,TriSongz,
Curt Tigges, Benjamin Thérien, Phil Wang, and
2023).
SamuelWeinbach.2023. GPT-NeoX:LargeScale
Limitations of the application setting. This AutoregressiveLanguageModelinginPyTorch.
workfocusesondetectingunauthorizedusageof StellaBiderman,HaileySchoelkopf,QuentinGregory
data,whichfundamentallyassumesthatmodelcre- Anthony, Herbie Bradley, Kyle O’Brien, Eric Hal-
atorsareunwillingtodisclosethecontentsoftheir lahan,MohammadAflahKhan,ShivanshuPurohit,
USVSNSaiPrashanth,EdwardRaff,AviyaSkowron,
trainingdata. Withoutthisassumption,usingdata
Lintang Sutawika, and Oskar van der Wal. 2023.
watermarkstodetectdatasetmembershipwouldbe Pythia: Asuiteforanalyzinglargelanguagemodels
unnecessary. Havingmotivatedourworkwithreal across training and scaling. In International Con-
examplesoflegalnegotiation(see§1),webelieve ference on Machine Learning, ICML 2023, 23-29
July2023,Honolulu,Hawaii,USA,volume202of
thatdatawatermarksarerelevantwhilenewlegal
ProceedingsofMachineLearningResearch,pages
developmentsareunderway. Asofnow,adopting
2397–2430.PMLR.
transparencymeasuresarevoluntarybutcouldbe
Nicholas P. Boucher, Ilia Shumailov, Ross Anderson,
backed by legislation similar to the reporting re-
and Nicolas Papernot. 2021. Bad Characters: Im-
quirementsintheEUAIAct9. However,thescope perceptibleNLPAttacks. 2022IEEESymposiumon
ofsuchtransparencyrequirementswillbedepen- SecurityandPrivacy(SP),pages1987–2004.
dentonthejurisdiction,anddatawatermarkswill
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
continuetoberelevantwheretransparencyrequire- Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
mentsareweak. Withadditionalregulatorysupport, Neelakantan,PranavShyam,GirishSastry,Amanda
wehighlightafewsociotechnicalsolutions,such Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
asbetterdatadocumentationtoolsandresponsible
AdityaRamesh,DanielZiegler,JeffreyWu,Clemens
reporting, which can efficiently address member-
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
shipqueriesandothersocietalconcerns(Marone teusz Litwin, Scott Gray, Benjamin Chess, Jack
andVanDurme,2023;Mitchelletal.,2019). Clark, ChristopherBerner, SamMcCandlish, Alec
Radford, Ilya Sutskever, and Dario Amodei. 2020.
Authors’ positionality In building technical Language models are few-shot learners. In Ad-
tools to support a right to opt-out, amongst the
vances in Neural Information Processing Systems,
volume 33, pages 1877–1901. Curran Associates,
9COM(2021)206final. Inc.Nicholas Carlini, Steve Chien, Milad Nasr, Shuang HongshengHu,ZoranSalcic,LichaoSun,GillianDob-
Song, Andreas Terzis, and Florian Tramèr. 2022. bie,PhilipSYu,andXuyunZhang.2022. Member-
Membershipinferenceattacksfromfirstprinciples. shipinferenceattacksonmachinelearning: Asurvey.
In 43rd IEEE Symposium on Security and Privacy, ACMComputingSurveys(CSUR),54(11s):1–37.
SP2022,SanFrancisco,CA,USA,May22-26,2022,
pages1897–1914.IEEE. NikhilKandpal,EricWallace,andColinRaffel.2022.
Deduplicatingtrainingdata mitigatesprivacy risks
NicholasCarlini,ChangLiu,ÚlfarErlingsson,Jernej inlanguagemodels. InInternationalConferenceon
Kos,andDawnSong.2019. Thesecretsharer: Eval- MachineLearning,ICML2022,17-23July2022,Bal-
uatingandtestingunintendedmemorizationinneu- timore,Maryland,USA,volume162ofProceedings
ralnetworks. In28thUSENIXSecuritySymposium, ofMachineLearningResearch,pages10697–10707.
USENIXSecurity2019,SantaClara,CA,USA,Au- PMLR.
gust14-16,2019,pages267–284.USENIXAssocia-
Paul Keller. 2023. Protecting creatives or impeding
tion.
progress?
Nicholas Carlini, Florian Tramèr, Eric Wallace,
John Kirchenbauer, Jonas Geiping, Yuxin Wen,
Matthew Jagielski, Ariel Herbert-Voss, Katherine
JonathanKatz,IanMiers,andTomGoldstein.2023a.
Lee,AdamRoberts,TomBrown,DawnSong,Úlfar
Awatermarkforlargelanguagemodels.
Erlingsson,AlinaOprea,andColinRaffel.2021. Ex-
tractingtrainingdatafromlargelanguagemodels. In
JohnKirchenbauer,JonasGeiping,YuxinWen,Manli
30thUSENIXSecuritySymposium(USENIXSecurity
Shu,KhalidSaifullah,KezhiKong,KasunFernando,
21),pages2633–2650.USENIXAssociation.
AniruddhaSaha,MicahGoldblum,andTomGold-
stein. 2023b. On the reliability of watermarks for
Alan Chan, Herbie Bradley, and Nitarshan Rajkumar.
largelanguagemodels. CoRR,abs/2306.04634.
2023. Reclaiming the digital commons: A public
data trust for training data. In Proceedings of the Hugo Laurençon, Lucile Saulnier, Thomas Wang,
2023AAAI/ACMConferenceonAI,Ethics,andSoci- Christopher Akiki, Albert Villanova del Moral,
ety,AIES’23,page855–868,NewYork,NY,USA. TevenLeScao,LeandrovonWerra,ChenghaoMou,
AssociationforComputingMachinery. Eduardo González Ponferrada, Huu Nguyen, Jörg
Frohberg, Mario Sasko, Quentin Lhoest, Angelina
XiaoyiChen, AhmedSalem, DingfanChen, Michael McMillan-Major,GérardDupont,StellaBiderman,
Backes,ShiqingMa,QingniShen,ZhonghaiWu,and AnnaRogers,LoubnaBenAllal,FrancescoDeToni,
YangZhang.2021. Badnl: Backdoorattacksagainst Giada Pistilli, Olivier Nguyen, Somaieh Nikpoor,
nlpmodelswithsemantic-preservingimprovements. MaraimMasoud,PierreColombo,JavierdelaRosa,
InAnnualComputerSecurityApplicationsConfer-
PauloVillegas,TristanThrush,ShayneLongpre,Se-
ence, ACSAC ’21, page 554–569, New York, NY, bastian Nagel, Leon Weber, Manuel Muñoz, Jian
USA.AssociationforComputingMachinery. Zhu, Daniel van Strien, Zaid Alyafeai, Khalid Al-
mubarak, Minh Chien Vu, Itziar Gonzalez-Dios,
LeoGao,StellaBiderman,SidBlack,LaurenceGold-
Aitor Soroa, Kyle Lo, Manan Dey, Pedro Ortiz
ing, Travis Hoppe, Charles Foster, Jason Phang,
Suarez, Aaron Gokaslan, Shamik Bose, David Ife-
Horace He, Anish Thite, Noa Nabeshima, Shawn
oluwaAdelani,LongPhan,HieuTran,IanYu,Suhas
Presser, and Connor Leahy. 2020. The Pile: An
Pai, Jenny Chim, Violette Lepercq, Suzana Ilic,
800gbdatasetofdiversetextforlanguagemodeling.
MargaretMitchell,AlexandraSashaLuccioni,and
arXivpreprintarXiv:2101.00027.
YacineJernite.2022. ThebigscienceROOTScorpus:
A1.6tbcompositemultilingualdataset. InAdvances
Kai Greshake, Sahar Abdelnabi, Shailesh Mishra,
in Neural Information Processing Systems 35: An-
Christoph Endres, Thorsten Holz, and Mario Fritz.
nualConferenceonNeuralInformationProcessing
2023. Notwhatyou’vesignedupfor:Compromising
Systems2022,NeurIPS2022,NewOrleans,LA,USA,
real-worldllm-integratedapplicationswithindirect
November28-December9,2022.
promptinjection.
InbalMagarandRoySchwartz.2022. Datacontamina-
PeterHenderson,XuechenLi,DanJurafsky,Tatsunori tion:Frommemorizationtoexploitation. InProceed-
Hashimoto,MarkA.Lemley,andPercyLiang.2023. ingsofthe60thAnnualMeetingoftheAssociation
Foundationmodelsandfairuse. forComputationalLinguistics(Volume2: ShortPa-
pers),pages157–165,Dublin,Ireland.Association
JordanHoffmann,SebastianBorgeaud,ArthurMensch,
forComputationalLinguistics.
Elena Buchatskaya, Trevor Cai, Eliza Rutherford,
DiegodeLasCasas,LisaAnneHendricks,Johannes MarcMaroneandBenjaminVanDurme.2023. Data
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, portraits: Recordingfoundationmodeltrainingdata.
KatieMillican,GeorgevandenDriessche,Bogdan
Damoc, Aurelia Guy, Simon Osindero, Karen Si- Margaret Mitchell, Simone Wu, Andrew Zaldivar,
monyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, Parker Barnes, Lucy Vasserman, Ben Hutchinson,
andLaurentSifre.2022. Trainingcompute-optimal Elena Spitzer, Inioluwa Deborah Raji, and Timnit
largelanguagemodels. Gebru.2019. Modelcardsformodelreporting. InProceedingsoftheConferenceonFairness,Account- A176b-parameteropen-accessmultilinguallanguage
ability,andTransparency,FAT*2019,Atlanta,GA, model. CoRR,abs/2211.05100.
USA,January29-31,2019,pages220–229.ACM.
RezaShokri,MarcoStronati,CongzhengSong,andVi-
JohnX.Morris,WentingZhao,JustinT.Chiu,Vitaly talyShmatikov.2017. Membershipinferenceattacks
Shmatikov,andAlexanderM.Rush.2023. Language againstmachinelearningmodels. In2017IEEESym-
modelinversion. posiumonSecurityandPrivacy,SP2017,SanJose,
CA,USA,May22-26,2017,pages3–18.IEEECom-
YonatanOren,NicoleMeister,NiladriChatterji,Faisal puterSociety.
Ladhak,andTatsunoriB.Hashimoto.2023. Proving
testsetcontaminationinblackboxlanguagemodels. RuixiangTang,QizhangFeng,NinghaoLiu,FanYang,
and Xia Hu. 2023. Did you train on my dataset?
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida, towards public dataset protection with cleanlabel
Carroll L. Wainwright, Pamela Mishkin, Chong backdoor watermarking. SIGKDD Explor. Newsl.,
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay, 25(1):43–53.
JohnSchulman,JacobHilton,FraserKelton,Luke
Miller,MaddieSimens,AmandaAskell,PeterWelin- Alek Tarkowski and Zuzanna Warso.
der,PaulF.Christiano,JanLeike,andRyanLowe. 2022. Ai_Commons. Open Future.
2022. Training languagemodelsto followinstruc- Https://openfuture.pubpub.org/pub/ai-commons.
tionswithhumanfeedback. InNeurIPS.
John Tehranian. 2015. The new censorship. Iowa L.
KennethPeng,AruneshMathur,andArvindNarayanan. Rev.,101:245.
2021. Mitigating dataset harms requires steward-
KushalTirumala,AramMarkosyan,LukeZettlemoyer,
ship: Lessonsfrom1000papers. InProceedingsof
andArmenAghajanyan.2022a. Memorizationwith-
theNeuralInformationProcessingSystemsTrackon
outoverfitting: Analyzingthetrainingdynamicsof
DatasetsandBenchmarks1,NeurIPSDatasetsand
largelanguagemodels. InAdvancesinNeuralInfor-
Benchmarks2021,December2021,virtual.
mationProcessingSystems,volume35,pages38274–
AleksandraPiktus,ChristopherAkiki,PauloVillegas, 38290.CurranAssociates,Inc.
Hugo Laurençon, Gérard Dupont, Sasha Luccioni,
Kushal Tirumala, Aram H. Markosyan, Luke Zettle-
YacineJernite,andAnnaRogers.2023. TheROOTS
moyer,andArmenAghajanyan.2022b. Memoriza-
searchtool: Datatransparencyforllms. InProceed-
tionwithoutoverfitting: Analyzingthetrainingdy-
ingsofthe61stAnnualMeetingoftheAssociationfor
namicsoflargelanguagemodels. InNeurIPS.
ComputationalLinguistics: SystemDemonstrations,
ACL2023,Toronto,Canada,July10-12,2023,pages
Ashish Venugopal, Jakob Uszkoreit, David Talbot,
304–314.AssociationforComputationalLinguistics.
FranzOch,andJuriGanitkevitch.2011. Watermark-
ingtheoutputsofstructuredpredictionwithanappli-
RonaldL.Rivest.1992. TheMD5message-digestalgo-
cationinstatisticalmachinetranslation. InProceed-
rithm. RFC,1321:1–21.
ingsofthe2011ConferenceonEmpiricalMethods
inNaturalLanguageProcessing,pages1363–1372,
Alexandre Sablayrolles, Matthijs Douze, Cordelia
Edinburgh,Scotland,UK.AssociationforComputa-
Schmid,andHervéJégou.2020. Radioactivedata:
tionalLinguistics.
tracing through training. In Proceedings of the
37thInternationalConferenceonMachineLearning,
EricWallace,TonyZhao,ShiFeng,andSameerSingh.
ICML2020,13-18July2020,VirtualEvent,volume
2021. Concealed data poisoning attacks on NLP
119ofProceedingsofMachineLearningResearch,
models. InProceedingsofthe2021Conferenceof
pages8326–8335.PMLR.
theNorthAmericanChapteroftheAssociationfor
ComputationalLinguistics: HumanLanguageTech-
Teven Le Scao, Angela Fan, Christopher Akiki, El-
nologies, pages 139–150, Online. Association for
lie Pavlick, Suzana Ilic, Daniel Hesslow, Roman
ComputationalLinguistics.
Castagné,AlexandraSashaLuccioni,FrançoisYvon,
MatthiasGallé,JonathanTow,AlexanderM.Rush,
Chiyuan Zhang, Daphne Ippolito, Katherine Lee,
StellaBiderman,AlbertWebson,PawanSasankaAm-
MatthewJagielski,FlorianTramèr,andNicholasCar-
manamanchi, ThomasWang,BenoîtSagot, Niklas
lini. 2021. Counterfactual memorization in neural
Muennighoff,AlbertVillanovadelMoral,Olatunji
languagemodels. CoRR,abs/2112.12938.
Ruwase, Rachel Bawden, Stas Bekman, Angelina
McMillan-Major, Iz Beltagy, Huu Nguyen, Lucile
Saulnier, Samson Tan, Pedro Ortiz Suarez, Vic-
tor Sanh, Hugo Laurençon, Yacine Jernite, Julien
Launay, Margaret Mitchell, Colin Raffel, Aaron
Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri
Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg
Nitzav,CanwenXu,ChenghaoMou,ChrisEmezue,
ChristopherKlamm,ColinLeong,DanielvanStrien,
DavidIfeoluwaAdelani,andetal.2022. BLOOM:A Normalityofnulldistributions "y": "\\u0443", "A": "\\u0391",
"B": "\\u0392", "C": "\\u03f9",
Thenulldistributioniscomposedofrandomwater-
"E": "\\u0395", "H": "\\u0397",
marklosses,whichareaveragelossesovertokens.
"I": "\\u0399", "J": "\\u0408",
Thetokenslossesmaynotbeindependenttoeach
"K": "\\u039a", "M": "\\u039c",
othersothenulldistributionsmaynotbenormal.
"N": "\\u039d", "O": "\\u039f",
Normality of the null distribution does not affect
"P": "\\u03a1", "S": "\\u0405",
thevalidityofthehypothesistest(see3.1).
"T": "\\u03a4", "X": "\\u03a7",
Normalityofthenulldistributioncanaidinin-
"Y": "\\u03a5", "Z": "\\u0396"
terpreting the Z-scores (if the null is normal, a
}
Z-scoreof−2correspondstop ≈ 0.05). Weper-
formnormalitytestswithQQplotsinFigure6and C.2 Unicodewatermarkillustration
qualitatively show that null distributions for for
Anillustrationoftokenizationsontheword-level
differentwatermarksareroughlynormal.
UnicodewatermarkisprovidedinTable1.
B Tokenrarity
Seed I have a dream
0 40 423 12466,108 4320
A watermark is stronger if it is constructed from
1 40 257
289,16142,85,16843 288,260,16142,76
raretokens. Tobetterunderstandhowvocabulary
2 40 257
289,16142,303 288,260,16142,76
usage affects watermarks, we conduct an oracle
study that uses the model’s tokenizer. In Figure Table1: Tokenizationsoftheword-levelvariantofthe
8, we construct our watermarks by sampling ran- UnicodewatermarkbytheGPT2Tokenizer.Afterchoos-
ingaseed,eachwordinthevocabularyisperturbedand
dom sequences of tokens from different regions
weshowitscorrespondingtokenization. Unicodelooka-
of the GPT2Tokenizer which are ordered by fre-
likescanbreak-upacommonwordintoraresubwords.
quency(higherrankimpliesrarertokens). Inpar-
ticular, instead of always sampling random char-
acters from the first [0 : 100]10 indexes of the C.3 Scalingresults
GPT2Tokenizer (outlined in Section 3), we ran-
ThescalingresultsfortheUnicodewatermarkare
domlysamplefromtherangeof[i : i+100],for
presentedinFigure7. Ingeneral,thesametrends
i ∈ {0,10000,20000,30000,40000,50000}. In
hold as here in the scaling of random sequence
8(a), we see that random sequence watermarks
watermarks,butUnicodewatermarksaregenerally
composing of rarer tokens have lower Z-scores.
weaker.
Figure 8(b) shows that the test statistic of rarer-
tokenwatermarksarelower. Wehypothesizethat D AdditionalresultsonSHAhashes
theusageofrarertokensmayinducelargergradient
D.1 Regexstringsusedtofilterthehashes
updates during training and exhibit better memo-
rization. Theregularexpressionsusedtoextractthenaturally
occuring hashes from the StackExchange corpus
C AdditionaldetailsontheUnicode areprovidedbelow:
watermark • MD5: \b[a-f0-9]{32}\b
• SHA-256: \b[a-f0-9]{64}\b
C.1 Unicodelookalikes
• SHA-512: \b[a-f0-9]{128}\b
The mapping we use between ASCII characters
D.2 ResultsonBLOOM-7B
and their Unicode lookalikes are provided below.
Thereare28substitutions: ThetestingresultsforBLOOM-7Barepresented
in Figure 9. The 7B model only memorizes the
{
mostduplicatedhashes. Forsmallermodeltrained
"a": "\\u0430", "c": "\\u03f2",
on large datasets, data watermarks may need to
"e": "\\u0435", "g": "\\u0261",
watermarkmanydocumentstobedetected.
"i": "\\u0456", "j": "\\u03f3",
"o": "\\u03bf", "p": "\\u0440",
"s": "\\u0455", "x": "\\u0445",
10followingstandardpythonicslicingnotationUnicode global Unicode word-based Random (len=10) Random (len=80)
12
8
6
4 10
5 8 7
3
4 6
6
2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5
12
4.2
8 10
5 4.1
8
7
4.0
4 6
6
2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5
Theoretical Quantiles Theoretical Quantiles Theoretical Quantiles Theoretical Quantiles
Figure 6: QQ-plots of null distributions across different experimental configurations. The null distributions
visualizedareindividualrunsfrom70Mmodeltrainedonadatasetof100Mtokens. Watermarktypevariesacross
columns,whilenumberofwatermarkeddocumentsvariesacrossrows. Ingeneral,nulldistributionsarequalitatively
normalforword-basedUnicodesubstitutionsandrandomsequences,withminordeviationsintheglobalvariantof
theUnicodeexperiments.
(a) Dataset scaling (z-score) (b) Model size = 70M (c) Model size = 410M
3.4 3.4
8
3.2 3.2
10 3.0 3.0
12 70M 2.8 2.8
160M
2.6 2.6
14 410M
1 2 4 8 1 2 4 8 1 2 4 8
Dataset size (B tokens) Dataset size (B tokens) Dataset size (B tokens)
Figure7: Experimentsontheword-levelUnicodewatermarksundermodelanddatasetscaling. Allexperiments
watermark 256 documents. Results in (a) are averaged over 3 runs, and we visualize the null distribution and
teststatisticforonerunin(b)and(c). (a)Whenscalingthetrainingdatawatermarksbecomeweaker. However,
watermarks remain strong for larger models. (b) As dataset size scales, the watermark loss of the 70M model
increases. (c)Forthe410Mmodel,asdatasetsizescales,boththenulldistributionandteststatisticdecrease.
cod
1
scod
652
erocS-Z
selitnauQ
elpmaS
selitnauQ
elpmaS
ssoL(a) Token rarity
8.0
8.5
1.0
9.0
0.8
9.5
0.6
10.0 0.4
0.2
0 10k 20k 30k 40k 50k
GPT2Tokenizer rank 0.0
2.5
(b) Length = 20
0.0
10
2.5
8
5.0 Length
32
6 7.5
64
10.0 128
4
1 10 100 1000
2
Occurrences
0
Figure9: TestresultsonnaturallyoccurringSHAand
0 10000 20000 30000 40000 50000
MD5hashesinBLOOM-7B.Duplicationratesarepro-
# of documents
videdbytheROOTSsearchtoolandoccurrencesmay
appearinthesamedocument. Thedottedlinedenotes
Figure8: Experimentsonwatermarkingstrengthand
aZ-scoreof−2correspondingtoafalsedetectionrate
token rarity. Results are on 70M models trained on
ofα=0.05.
100Mtokens,averagedover5runs. 20-lengthrandom
sequencewatermarkswereusedandinsertedinto256
documents.Randomsequencewatermarkscomposedof
rarertokensarestronger. Watermarkswithrarertokens
haveslightlylowerlossaftertraining.
ssoL
erocs-Z
eulav-p