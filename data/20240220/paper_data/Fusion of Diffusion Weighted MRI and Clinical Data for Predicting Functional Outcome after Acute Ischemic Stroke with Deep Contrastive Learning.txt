FUSION OF DIFFUSION WEIGHTED MRI AND CLINICAL DATA
FOR PREDICTING FUNCTIONAL OUTCOME AFTER ACUTE
ISCHEMIC STROKE WITH DEEP CONTRASTIVE LEARNING
APREPRINT
Chia-LingTsai∗1 Hui-YunSu*2 Shen-FengSung3 Wei-YangLin2 Ying-YingSu3
Tzu-HsienYang3 Man-LinMai2
February19,2024
ABSTRACT
Stroke is a common disabling neurological condition that affects about one-quarter of the adult
population over age 25; more than half of patients still have poor outcomes, such as permanent
functional dependence or even death, after the onset of acute stroke. The aim of this study is to
investigate the efficacy of diffusion-weighted MRI modalities combining with structured health
profileonpredictingthefunctionaloutcometofacilitateearlyintervention. Adeepfusionlearning
networkisproposedwithtwo-stagetraining: thefirststagefocusesoncross-modalityrepresentation
learning and the second stage on classification. Supervised contrastive learning is exploited to
learndiscriminativefeaturesthatseparatethetwoclassesofpatientsfromembeddingsofindividual
modalities and from the fused multimodal embedding. The network takes as the input DWI and
ADCimages,andstructuredhealthprofiledata. Theoutcomeisthepredictionofthepatientneeding
long-termcareat3monthsaftertheonsetofstroke. Trainedandevaluatedwithadatasetof3297
patients,ourproposedfusionmodelachieves0.87,0.80and80.45%forAUC,F1-scoreandaccuracy,
respectively,outperformingexistingmodelsthatconsolidatebothimagingandstructureddatainthe
medicaldomain.Iftrainedwithcomprehensiveclinicalvariables,includingNIHSSandcomorbidities,
thegainfromimagesonmakingaccuratepredictionisnotconsideredsubstantial,butsignificant.
However, diffusion-weighted MRI can replace NIHSS to achieve comparable level of accuracy
combiningwithotherreadilyavailableclinicalvariablesforbettergeneralization.
Keywords Acute ischemic stroke · Diffusion-weighted MRI · Hierarchical multimodal fusion · Multimodal
representationlearning·Strokeprognosticmodel
1 Introduction
Strokeisamajorcauseofacquiredlong-termdisability[1,2]andisoneofthemajorcausesofdeathanddisability
worldwide[3]. Thisdisablingneurologicalconditionaffectsaboutone-quarteroftheadultpopulationoverage25,with
arisingincidenceinyoungpeople. Evenwithadvancedacutetreatmentofstrokes,morethanhalfofpatientswhohave
hadstrokesstillhavepooroutcomes,suchaspermanentfunctionaldependenceorevendeath.
Thelong-termfunctionaloutcomeofastrokepatientismeasuredbythemodifiedRankinScale(mRS),whichgrades
thedegreeofdisabilityindailyactivities,rangingfrom0fornosymptomsto6fordeath. Studieshaveshownthat
physicians specialized in stroke treatment can only achieve an overall accuracy of 16.9% in predicting long-term
∗Equalcontribution.
1QueensCollegeoftheCityUniversityofNY,USA.
2NationalChungChengUniversity,Taiwan
3DitmansonMedicalFoundationChia-YiChristianHospital,Taiwan
Correspondenceto:ctsai@qc.cuny.edu.
4202
beF
61
]VC.sc[
1v49801.2042:viXraFusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
disabilityordeath[4,5]. However,anaccurateprognosticriskmodelformRSplaysacrucialroleinpost-acutecareto
facilitateshareddecision-makingandtomitigatethementalandfinancialstressofthepatientsandtheirfamiliesforthe
long-termcare.
Diffusion-weightedMRIimagingisawidelyusedmodalityforacuteischemicstroke(AIS)diagnosis: hyperacute
lesionsandverysmallischemiclesionscanbemoreeasilydetected,comparingtousingbrainCTandconventional
MRIsequences[6]. WhenApparentDiffusionCoefficient(ADC)andDiffusionWeightedImage(DWI)areusedjointly,
theevolutionofthelesionofAIScanbemoreaccuratelyidentified[7]. Yet,itcanstillbechallengingforphysiciansto
makeaccurateprognosesgiventhediffusionimagesatthetimeofstrokeonset. Figure1showstwocasesofstrokethat
caneasilymisleadthephysicianstomakeincorrectprognosesduetotheextentofthelesion.
EarlierresearchforpredictingmRSafterstrokemainlyrelyonstructureddata,i.e. patient-specificclinicalvariables,
usingtraditionalmachinelearningapproaches,suchaslogisticregression[8,9,10],randomforest[8,9,10,11,12],
supportvectormachine[8,10,11,12],andXGBoost[8,10]. Suchmethodscanhavehighdependenceonhuman-
interpretedinformation,suchasstrokeseverityassessment,whichcanvarybasedontheexpertiseofthephysicians,
leadingtolowergeneralizabilityofthemodelsinrealclinicalsettings.
Overthelastdecade,deeplearning(DL)hasshownpromisingsuccessinnumerousapplicationsinmedicalimage
analysis,suchascancerscreeningandtumorsegmentation[13]. However,researchapplyingDLintheareaofischemic
strokeprognosisforpredictingmRSafterstrokeremainslimitedintheliterature. Mostattemptscanbeclassifiedinto
twocategoriesbasedonthetypeofdataused: brainimagedata(unstructureddata),andheterogeneousdata(combining
bothstructuredandunstructureddata). Theformeroftenusesclassicdeeplearningmodels,includingconvolutional
neuralnetwork(CNN) [14],siamesenetwork[16]forcross-modalityparametersharing,andautoencoderforfeature
learning[17]. Allstudiessuggestlittlebenefitofusingimagingalonefor3-monthfunctionaloutcomeprediction.
Riskmodelsusingheterogeneousdatahavetheadvantageovermodelsusingonlystructuredorunstructureddata,as
bothimage-embeddedinformationandpatientmedicalhistoryareconsideredformakingtheprediction[15]. Samaket
al.[18]exploitattentionmechanismtocapturechannelandspatialinformationinthe3Dimage,allowingthemodel
to focus more on information in specific regions of the image. Structured features are generated using multilayer
perceptron(MLP)andconcatenatedwithCNNimagefeatures. Thecombinedfeaturesgothroughafullyconnected
(FC)layertoproducethefinaloutput. SimplermodelsareproposedbyZihnietal.[19]andBacchietal.[20]asa
combinationof3DCNNandMLPtoprocessimagedataandstructureddata,respectively. Theyonlydifferinthe
numberoflayersinsideCNNandMLP.FeatureconcatenationalsotakesplacebeforetheFClayerforclassification.
Insteadofusing3DCNN,Hatamietal.[21]processa3Dimageasasequenceof2Dimagesusingacombination2D
CNNandarecurrentneuralnetworkLSTM,andthefinaloutputisweightedbyonesinglestructuredattribute,suchas
age,toenhancetheoutcome. Overall,multi-modalnetworkshaveslightlybetterpredictiveperformancecomparedto
themodeltrainedononlyclinicalvariables,butimprovementovertheimage-trainedCNNmodelsisprominent. There
isaneedtoexplorealternativefusionapproachestoachievebetterperformance.
Modelsdesignedforheterogeneousdatahavealsobeenappliedtoothermedicalproblems. Hsuetal. [23]applythe
sameapproachas[19]and[20]tofundusimagesandstructureddatatodetectdiabeticretinopathy,butInceptionv4is
usedasthebackboneinsteadofavanilla2DCNN.Followingasimilarapproach,Huangetal.[24]computetheaverage
of the predicted probabilities from the 3D CNN and MLP, respectively, as the final prediction for the detection of
pulmonaryembolism. Theyalsoexperimentedwithvariousfusionmethodswithhighermodelcomplexitybutproduced
lessdesirableoutcome. Woodetal.[25]designamodelthatconcatenatestheagewithCNNimagefeaturesasinputtoa
FClayertoproducethefinaloutputtodetectabnormalMRIbrainscans. Qiuetal.[26]applyhierarchicalvotingwhich
firstvotesonCNNoutputsforindividualMRIslicesandthenvotesonthefinalCNNvoteandmultipleMLPoutputs
forthestructureddatatodetectcognitiveimpairmentinpatients. Insummary,allaforementionedmodelsperformlate
fusionofmultiplemodalitiesbyeitherconcatenation/averagingoffeaturesormultiplicationoftheoutcomesfrom
individualmodalities. Inallcases,cross-modalitylearningfordiscriminativefeaturesisnotfacilitatedtotakeinto
considerationthecommonalitybetweenmodalitiesandtheinformationgranularityofeachmodality.
Inthisstudy, weinvestigatetheefficacyofcombiningdiffusion-weightedMRIimagingwithclinicalvariablesfor
predicting the 3-month functional outcome (mRS> 2) with a cross-modality fusion model. Our proposed model
performs representation learning to learn discriminative features cross modalities that separate the two classes of
patientsfromembeddingsofindividualmodalitiesandfromthefusedmultimodalembedding. Forthelatter, data
fusionisperformedinahierarchicalfashiontoensureequalcontributionsfrombothfine-grainedandcoarse-grained
representations. Figure2providesavisualsummaryofourproposedmultimodalprognosticationframework.
2FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
𝑚𝑅𝑆 ≤2 𝑚𝑅𝑆 >2
DWI ADC DWI ADC
Figure1: MRIscansofbrainsafterstroke. Theimagepairontheleftcomesfromapatientwithgoodrecoveryat3
monthsafterstroke(mRS≤2),whereasthepairontherightcomesfromapatienthavingpermanentdisability(mRS>2).
Theredboxhighlightstheaffectedregionofthebrain.
Figure2: Overviewoftheproposedmultimodalprognosticationframeworkforacuteischemicstroke.
2 MaterialsandMethods
2.1 Dataset
The study protocol is independently approved by the Ditmanson Medical Foundation Chia-Yi Christian Hospital
InstitutionalReviewBoard(IRB2022011). Studydataaremaintainedwithconfidentialitytoensuretheprivacyofall
participants.
OurdatasetconsistsofADCandDWI,bothtakenbetween1to7dayspost-stroke,and62clinicalvariables,including
age,onset-to-admissiondelay,comorbiditiesandtheNationalInstitutesofHealthStrokeScale(NIHSS).Thedataset
contains3297patientsfromDitmansonMedicalFoundationChia-YiChristianHospital,beinghospitalizedforAIS
betweenOctober2007andSeptember2021andhavingcompletedthe3-monthpost-strokefollow-up. Onlytheearliest
hospitalizationforeachpatientisconsidered. Table1givesthesummaryofthecohortcharacteristics. Imageswith
substantialartifacts,suchasblurringordentures,arealsoexcludedfromthisstudy. Thedatasetisdividedintotraining,
validation, and testing with the ratio of 6:2:2. The number of slices of an MRI volume varies between 18 and 28,
dependingontheshootingangleandthesizeofthepatient’shead. Weselectthemiddle18slicesofeachpatientas
theycontainthemostlesioninformation.
Intermofdataaugmentation,randomflipping,Gaussianblurringwiththestdin[0.1,2.0],andrandomnoiseaddition
withaprobabilityof0.2areappliedinthefirststageoftraining. Inaddition,partialmaskingisappliedwithapatch
sizeof32×32andmaskingprobabilityof0.5foreachpatch,asproposedbyHeetal.[27],toensureuniformmask
distributionacrosstheimage. Forstructureddata,weadddropout0.5tothemodeltomaskthestructuredfeatures. No
dataaugmentationisappliedinthesecondstageoftraining.
3FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
Table1: Summaryofcohortcharacteristics. IQR:interquartilerange. NIHSS:NationalInstitutesofHealthStroke
Scale.
Clinicalattributes mRs=[0,2](N=1802) mRs=[3,6](N=1495)
Medianage(IQR) 67.0(17.0) 75.0(15.0)
MedianinitialNIHSS(IQR) 4.0(4.0) 8.0(12.0)
Sex(females/males) 610/1192 692/803
Thrombolysistreatment(yes/no) 184/1618 130/1365
Diabetes(yes/no) 691/1111 695/800
Smoking(yes/no) 805/997 519/976
Onset-to-admissiondelay(yes/no) 1316/486 1102/393
Hyperlipidemia(yes/no) 1082/720 804/691
Hypertension(yes/no) 1373/429 1222/273
Cardiachistory(yes/no) 335/1467 484/1011
(a) (b) (c)
Figure3: PreprocessingforDWI.(a)Beforebiascorrection. (b)Afterbiascorrection. (c)Biasfieldbeingremoved.
2.2 DataPreprocessing
Due to imperfection of the image acquisition process, bias field is often perceived in medical images as a smooth
variation of intensity across one image. It is especially prominent in MRI because of the variation in magnetic
susceptibilityamongtissuetypes. Thiseffectcausesvariationintheintensityofthesametissueindifferentlocations
withintheimage.Biasfieldcangreatlydegradetheaccuracyofmanyautomatedmedicalimageanalysistechniques[28].
Tomitigatetheeffectofbiasfieldintrainingofthemodel,wepreprocesstheADCandDWIsequenceimageswith
N4BiasFieldCorrection[29]implementedinSimpleITK[30]. Thismethodistoremovethelow-frequencyintensity
deviationtohomogenizetheimage. AsshowninFigure3,theDWI,inboththewhiteandgraymatters,hasmore
homogeneousbrightnessacrosstheimageafterbiascorrection.
Missingclinicalattributesisacommonprobleminarealclinicalsetting. Thehighestmissingrateis15.4%foradata
attributeinourdataset. Toresolvethisissue, weexperimentedwithseveraldataimputationtechniques, including
MissForest[31],andsettledwithmodeimputationforbetterempiricaloutcomes. Dataimputationisappliedtothe
inputdatabeforefeedingthebackbonenetwork.
2.3 Cross-modalityFusionNetwork
Theproposedarchitectureconsistsoftwotrainingstages,asshowninFigure4. Inthefirststageoftraining,representa-
tionlearningisaccomplishedthroughcontrastivelearning,inspiredby[32]forself-supervisedlearning. Theideaof
contrastivelearningistoclustertogethersimilarsamplesandpushapartdifferentsamplesinfeatureembedding[33,34].
FeaturesareextractedusingeitheraCNNnetwork,whichisResNet50,forunstructureddataorMLPforstructureddata.
Thesamefeaturesetsgointobothcross-modalitycontrastivelearning(CMCL)moduleandfused-modalitycontrastive
learning(FMCL).Thelossesfromthetwomodulesarerandomlyselectedtoproducethefinalcontrastiveloss.
4FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
Stage 1: Representation Learning
Cross-Modality Contrastive Learning(CMCL)
Encoders A
CMCL loss
ADC
S D
DWI
Hierarchical Fusion (HF)
Struct
Projection A D
Class 0 Class 1
heads
(AD)’ Class 0 Class 1
FMCL loss
S S’(AD)’ Class 0 Class 1
Fused-Modality Contrastive Learning(FMCL)
A D
HF A D
F
(AD)’ 0、1
C
S S S’(AD)’
Stage 2: Classification
Figure4: Illustrationoftheproposedmultimodalfusionlearningnetwork. Theoutcomeisthepredictionofthepatient
needinglong-termcareat3monthsaftertheonsetofacuteischemicstroke.
Inthesecondstageoftraining,whichisforclassification,thebackbonenetworksstaythesameasinstage1andare
initializedwithparameterslearnedinstage1formorediscriminativefeaturesfromcontrastivelearningtoachieve
higherclassificationaccuracy.
2.3.1 Encoder
Inthedeeplearningmethod,anencoderistotransformanimagetoalatentrepresentationtocapturetheimportant
informationinacondensedform. ResNet50[35]isthebackboneforencodingbothDWIandADC.Thetwomodalities
areprocessedseparatelybytwonetworks,bothinitializedbyImageNetpre-trainedweights. Forthestructureddata,a
MLPisusedasanencoder,with3hiddenlayers—150,100,and60nodes,respectively.
2.3.2 ProjectionHead
Earlierliterature[33]demonstratesthenecessitytoincludeaprojectionheadbetweenfeatureencodingandcontrastive
losstolearnfeaturesinvarianttodataaugmentation. Nonlinearprojectionheadisshowntobemoreeffectivethan
linearprojection. Inourmodel,wedesignanon-linearprojectionheadwith3layerswithdecreasingdimensionsfor
representationlearning. Forthedownstreamtask,onlythelayerwiththelowestdimensionismaintainedtoreduce
computationwithoutlossinperformance.
2.3.3 Cross-ModalityContrastiveLearning(CMCL)Module
CloselyfollowingSimCLR[33],asimplifiedframeworkforself-supervisedcontrastivelearningwiththeemphasison
dataaugmentation,weintroduceasupervisedcontrastivelossthatincorporateslabelstofacilitatelearning. Imagesof
allmodalities(includingaugmentedimages)fromthesamepatientareallconsideredasviewsofaninstance.
LetA∈Rd,D ∈RdandS ∈RdrepresentthemodalityfeaturesatagivenlayeroffeatureextractorfromADC,DWI,
andstructureddata,respectively. Eachfeaturevectorisinitsoriginalembedding. Wecalculatethelossfunctionusinga
combinationofmodalitypairs: pairsofviewsofthesamemodality,suchas{D,D’},whereDandD’arefromthesame
modality,andpairsofviewsfromdifferentmodalities,suchas{A,S},whereAandSareviewsofdifferentmodalities.
5FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
Alloriginalandaugmentedviewsareconsidered. Thecontrastivelossforonly{D,D’}pairsisthesameasin[34]:
L
=(cid:88) −1 (cid:88)
log
exp(D i·D p′/τ)
(1)
DD |P(i)| (cid:80) (D ·D′/τ)
i∈I p∈P(i) k∈K(i) i k
P(i)≡{p∈K(i):y˜ =y˜},whereiistheanchor,K(i)representsallsamplesexceptiitself,P(i)representsallthe
p i
viewsofallsamplesofthesamecategoryasofi. τ ∈R+isthescalartemperatureparameter. SimilarlyforL ,L ,
AA SS
L ,L andL .
DA DS SA
L isthecombinedlossofallintra-modalitylossesfromdifferentviewsofthesamemodalityforall3modalities:
intra
L =L +L +L (2)
intra AA DD SS
Toconsiderviewsfromdifferentmodalities,L isthecombinedlossofinter-modalitylossesamongthe3modalities:
inter
L =L +L +L (3)
inter AD DS SA
L canfacilitatelearningofdiscriminativefeaturesinindividualmodalities,whileL promoteslearningof
intra inter
strongfeaturessharedbyallmodalitiesforcross-modalitylearning.
2.3.4 Fused-ModalityContrastiveLearning(FMCL)Module
Features of different modalities are often concatenated or averaged out when combined. If multiple modalities of
similargranularityinfeatureembeddingareinvolvedinthelearningprocessing,suchdatarepresentationmaydictate
thelearningoutcome. Forthisreason,weintroducemulti-stageHierarchicalFusion(HF):imagefeaturevectorsfrom
thebackbonenetworksareconcatenatedandprocessedbythefirstFClayer,thefusedimagefeaturesareconcatenated
withthefeaturesofthestructureddataandprocessedagainbythesecondFClayer. Multi-stagefusionensuresequal
weightsforfeaturesofdifferentgranularitiesinthecommonfeatureembedding.
HFgeneratesthecommonfeatureembeddingM fromallthreemodalities. SameasforCMCL,thecontrastivelossfor
FMCLiscomputedas:
L
=(cid:88) −1 (cid:88)
log
exp(M i·M p′/τ)
(4)
FMCL |P(i)| (cid:80) (M ·M′/τ)
i∈I p∈P(i) k∈K(i) i k
2.3.5 Combinedloss
Inthestageofrepresentationlearning, wecombinethelossescomputedbyCMCLandFMCL,aimingtoachieve
cross-modalitylearningandmulti-modalitylearning.Bydoingso,weobtainthepre-trainedweightsforourdownstream
predictivetask. OurstrategyistoupdatethefinallossbyrandomlyselectingonlyonelossfromL ,L ,and
intra inter
L foreachmini-batchwithoutintroducingadditionalhyper-parameters.
FMCL
2.3.6 Classification
As our ultimate goal is to predict the range of mRS at 3 months after stroke, we transfer the model parameters of
the backbone networks obtained in the first stage of training for representation learning to fine-tune the model for
classification. Instage2,HFisalsoappliedtofusethefeaturesinthecommonembedding. AFClayerisaddedatthe
endtoserveastheclassifier,whichoutputs0formRS≤2,and1formRS>2. Toachievethis,weusecross-entropyloss
asthelossfunctionforclassification.
3 Results
3.1 ImplementationDetails
Theoriginalimageisresizedfrom256×256to224×224whilepreservingtheaspectratio. Thebackbonenetworksfor
imagemodalitiesareResNet50[35]pre-trainedonImageNet. BothADCandDWIare3Dimagemodalities. Wetreat
slicesaschannelsandperform2Dconvolutiononthe3Dimageforcomputationefficiency,comparingto3DCNN.
Forstage1,theimagebackbonenetworksarefollowedbyaprojectionhead,whichtakesaninputof2048dimensions
andprojectstoafeaturespaceof60dimensionsforimagemodalities. Theidentityfunctionisusedforthestructured
6FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
Table2: Comparisonswithothermultimodalpredictionmodelsinvolvingbothimagesandstructureddata. (*indicates
modelsdevelopedfornon-strokeapplications.)
Validationset Testingset
Model AUC F1 Acc(%) AUC F1 Acc(%)
Samaketal.[18] 0.8568 0.7890 79.70 0.8527 0.7778 78.94
Bacchietal.[20] 0.8730 0.7638 77.88 0.8468 0.7470 76.52
Hatamietal.[21] 0.7950 0.7190 73.18 0.7801 0.6835 70.30
Hsuetal.*[23] 0.8609 0.8071 81.21 0.8548 0.7693 77.73
Huangetal.*[24] 0.8711 0.8021 80.45 0.8637 0.7657 76.97
Ours 0.8863 0.8304 83.48 0.8703 0.7968 80.45
dataforprojection. Forthehierarchicalfusion,theFClayersofbothstagesconsistsofalinearlayerwiththeReLU
activationfunction.
ThenetworksaretrainedusinganAdamoptimizerwithamini-batchof20epochs. Thelearningrateisinitiallysetto
1×10−3 anddecreasesgraduallyafterevery10epochs. Thesecondstageusesasmallerlearningrateof1×10−4.
AlltheexperimentsareimplementedwiththePyTorchplatformandtrained/testedonRTX3090GPUwith24GBof
memory.
3.2 ComparisonwithState-of-the-artFusionMethods
Weadoptthreemetricsforevaluationofperformance: areaundercurve(AUC),F1-scoreandaccuracy(Acc). Asthe
numbersofsamplesfromthetwoclassesinourdatasetareimbalanced,weusethemacro-F1-scoretocomputethe
averageF1scoreforeachclass. Accuracyiscomputedastheproportionofcorrectpredictions.
WecompareourproposedmethodwithmethodsthatalsopredictmRS3-monthoutcomesafterstrokeandalsowith
methodsdevelopedforotherapplicationsusingbothimagesandstructureddata. Toensurefaircomparison,except
for[21]whichislimitedtouseonlyonestructuredattributeastheweight,weusethesamesetofstructuredattributes
asinourstudyforallothermodels2. Samepreprocessingofinputdataisalsoapplied,buteachmodelisindividually
adjustedfollowingtheoriginalpublication. Table2showstheresultsofcomparison.
3.3 AblationStudy
Sinceourarchitectureincorporatesmultiplelossfunctionsforrepresentationlearning,weinvestigatedifferentcom-
binationsoflossfunctionsL ,L andL andfusionmethodstodeterminetheindividualcontributions
intra inter FMCL
of CMCL, FMCL, and HF modules. Additionally, models excluding HF are performed by averaging across three
modalitiestocalculateL . TheresultsareshowninTable3.
FMCL
Ourfinalmodel(ModelJ)withalllossfunctionsinvolvedperformsthebestforallthreemeasuresforthevalidationset.
ItisslightlyoutperformedbythemodelwithFMCLbranchonly(ModelE)inAUCforthetestingset. ModelEcomes
secondforthevalidationdataset,butnotasgeneralizableforthetestingset. ModelsAtoCshowtheeffectivenessif
onlyonelossfunctionisconsidered. ModelDshowstheresultofnorepresentationlearning,andtheperformanceis
substantiallyworsecomparingtoModelJ.ThecontributionofHFcanbeobservedbycomparingModelsCwithE,and
ModelsIwithJ.ModelsFtoHshowtheeffectofmissingaparticularlossfunction.
Wealsoinvestigatethreedifferentstrategiesofcomputingthefinallossfunctionforrepresentationlearning. Thefirst
oneistoaverageL ,L andL sotheyallmakeequalcontributiontothefinalloss. Thesecondisto
intra inter FMCL
randomlyselectalossforeachepoch. Thethirdapproachinvolvesrandomlyselectingalossforeachmini-batch.
Table4showstheresults. Thefirstandthesecondstrategiesperformverysimilarly. Thespeculationforthemore
superiorperformancecomingfromthethirdstrategyisthecloser-to-equalprobabilityofanindividuallossfunction
beingoptimized.
2[26]isnotre-implementedbecausevotingofthethreemodalitiesshouldbedominatedbyoutcomesoftwoimagemodalities,
whichisempiricallyshowntocapturelessinformationthanstructureddata(seeTable5),resultinginworseperformance.
7FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
Table3: Ablationstudyoncontrastivelearning(stage1training)
Validationset Testingset
Model L L L HF
intra inter FMCL
AUC F1 Acc(%) AUC F1 Acc(%)
A V 0.8770 0.8237 82.73 0.8701 0.7869 79.39
B V 0.8701 0.8212 82.58 0.8613 0.7773 78.64
C V 0.8756 0.8153 82.12 0.8682 0.7891 79.85
D V 0.8677 0.8163 81.82 0.8491 0.7662 77.12
E V V 0.8843 0.8271 83.03 0.8737 0.7895 79.70
F V V 0.8612 0.8134 81.82 0.8680 0.7953 80.30
G V V V 0.8772 0.8234 82.73 0.8689 0.7941 80.15
H V V V 0.8685 0.8152 81.97 0.8656 0.7927 80.00
I V V V 0.8635 0.8076 81.36 0.8547 0.7811 79.09
J V V V V 0.8863 0.8304 83.48 0.8703 0.7968 80.45
Table4: Combinedlosscomputation(stage1training)
Validationset Testingset
Trainingstrategies
AUC F1 Acc(%) AUC F1 Acc(%)
Averaging 0.8760 0.8197 82.27 0.8623 0.7842 79.09
Randomlypickedperepoch 0.8760 0.8239 82.73 0.8642 0.7874 79.39
Randomlypickedpermini-batch 0.8863 0.8304 83.48 0.8703 0.7968 80.45
3.4 ComparisonwithSingleModalityLearning
Tostudyhowmucheachmodalitycanpotentiallycontributestotheoveralllearning,wetrainbaselinemodels,onefor
eachmodality: ResNet50forADCandDWI,andMLPforstructureddata. Table5showstheresults. Wealsotrain
modelswithoutNIHSSvariables(16intotal)toevaluatetheperformanceofthesystemwithouttheinputofclinical
variableswithhighinter-observervariability. NIHSSvariablesarealsoknowntobethemosteffectivevariablesdriving
thepredictionoffunctionalstrokeoutcomebyMLP[22]
Table5: Singlemodalitybaselineresults
Validationset Testingset
Model AUC F1 Acc(%) AUC F1 Acc(%)
ResNet50(ADC) 0.7484 0.6960 70.15 0.7610 0.6932 70.30
ResNet50(DWI) 0.7832 0.7397 74.09 0.7552 0.6845 68.78
MLP(allclinicalattributes) 0.8726 0.8090 81.36 0.8569 0.7481 75.76
MLP(withoutNIHSS) 0.8439 0.7828 78.94 0.8179 0.7447 75.30
Ours(allclinicalattributes) 0.8863 0.8304 83.48 0.8703 0.7968 80.45
Ours(withoutNIHSS) 0.8401 0.7949 80.00 0.8408 0.7690 77.73
4 Discussion
Comparedwithothermultimodalfusionlearningnetworks,ourproposedmodelperformsthebestinallthreemetrics.
[18,20,23,24]ratethesecond: toproducethefinaloutcome,[18,20,23]performsimpleconcatenationforfeatures
fromCNNandMLPbeforetheFClayer,whereas[24]computestheaverageofthepredictedprobabilityfromboth
CNNandMLP.[21]performstheworstsincetheonlystructuredattributeinvolvedisonlyeffectiveiftheoutcome
fromtheCNNissufficientlyaccurate.
8FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
(a) DWI (b) DWI CAM (c) ADC (d)ADC CAM
Figure5: IllustrationofclassactivationmapsforcorrectlypredictedpatientsfromthetestsetbyCNNpre-trainedwith
ourrepresentationlearning. Ourfusionmodelalsosucceededonall3cases,butMLPfailed. Theredboxhighlightsthe
affectedregionofthebrain.
ThefusionmodelmakessignificantimprovementoverCNNmodelsforbothADCandDWI,whichisinalignment
with earlier studies [17, 19, 20]. However, the improvement over MLP is considered incremental. [19] came to a
similarconclusionwithwhole-brainTOF-MRAmodality: theCNNmodelachieveslowperformance(AUC:0.64),
while MLP on clinical variables and multi-modal learning achieve comparable outcomes (AUCs:0.75 and 0.76,
respectively). [20]claimedsignificantimprovementfrommulti-modallearningtrainedonNCCT(AUC:0.75),due
tomuchlowerperformancebyCNNandMLP(AUCs:0.54and0.61,respectively). Interestingly,[20]achieveseven
higherperformanceincross-modallearningwithourdataset(AUCs:0.847). Ourstudyconfirmsthesuperiorityof
diffusion-weightedMRimaging,comparedwithbrainCTorotherMRmodalities,forfunctionaloutcomeprediction.
Thedesignofthefusiontechniquealsoplaysanimportantrole. [21]combinesbothperfusionanddiffusionMRI
modalities(5intotal),andclinicalmetadata,butachievesverysimilarperformanceas[19]intheirownstudyof119
patients(AUC:0.77)andwithourdatasetaswell(AUC:0.78). Table5alsoshowsresultsofomittingNIHSSvariables,
whichcanleadtohighergeneralizabilitybecauseNIHSSscoresaresubjecttointer-observervariability. Ourfusion
modelwithoutNIHSSachievescomparableresultsasMLPusingall62attributes. Inotherwords,diffusion-weighted
MRIcanserveasareplacementforNIHSSassessmentinpredictingthe3-monthfunctionaloutcome.
WeareinterestedtofindouthowADCandDWIcontributetothepredictiontaskinthejointframework,andifthe
decision is derived from clinically relevant evidence. The fusion model accurately predicted 6.3% of the test set
whileMLPfailed,butfailed1.6%whileMLPsucceeded,foranetincreaseof4.7%inaccuracy. Foranimage-based
learningnetwork,theexplainabilityofadecisioncanbevisualizedbytechniques,suchasGradient-weightedClass
ActivationMapping(Grad-CAM[36]),toidentifiesregionsofinterestintheinputimagethatareimportantformaking
the prediction. Grad-CAM calculates the rate of change in the prediction of a target class regarding a change in
the pixel/voxel location and display the analysis as a heatmap. Unfortunately, Grad-CAM cannot be applied to a
fusionmodelbecauseofthefusionlayer. InsteadwegeneratetheGrad-CAMfromCNNmodelspre-trainedwithour
contrastiverepresentationlearning(stage1). Fig.5shows3typicalcases,onemildandtwoseverethatonlyMLPon
structureddatafailed. ForallcasestheCNNmodelsfocusonmorethanjusttheischemicregions. Possibleexplanations
includeatrophyrelatedtothepatient’sageandabnormalitiesduringimageacquisitionthatarehighlycorrelatedwith
strokeseverity. Otherexplainabletechniquesshouldbeexploredtoproperlyvisualizetheinteractionamongthemodals
afterthesecondstageoftraining.
9FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
5 Conclusion
Inthispaper,weproposedanovelprognosticriskmodelforpredictingthefunctionaloutcome3monthsafterAIS
testedwithdiffusion-weightedMRIimagingcombinedwithclinicalstructureddata. Ourmodelappliesrepresentation
learninginembeddingsofindividualmodalitiesandinthefusedmultimodalembeddingwithhierarchicalfusionto
ensureequalweightsforfeaturesofdifferentgranularitiesinthecommonfeatureembedding. Discriminativefeatures
arelearnedandappliedtoclassification.
The proposed model outperforms existing risk-prediction fusion models for prognostication of AIS. Given a com-
prehensivehealthassessmentofapatient,thepredictioncanbedrivenbytheclinicalvariables,buttheadditionof
diffusion-weightedMRIalonecanfurtherimprovetheaccuracyofprediction,andcanalsoreplaceNIHSSforbetter
generalization.
The study was initiated with a set of 4505 stroke patient records, but 1208 without 3-month mRS assessment and
discardedforthecurrentstudyforlackinggroundtruth. Asthenextstep,wewillexpandourmodeltoalsoleverage
datawithoutlabelforsemi-supervisedlearningtofurtherimprovegeneralizationofthemodel. Differentpost-hoc
explainabilitymethodsforafusionmodelshouldalsobeexploredtoestablishtheconnectionbetweenDLfeaturesand
imagingpropertiesalreadyidentifiedwithclinicalrelevancetoconfirmthereliabilityofthefusionmodelasaclinical
decisionsupportsystem.
Acknowledgment
ThisworkwaspartiallysupportedbygrantsPSC-CUNYResearchAward65406-0053,CYCH-CCU-2022-14,and
NSTC112-2221-E-194-034.
References
[1] P.Gorelick,Theglobalburdenofstroke: persistentanddisabling.TheLancetNeurology.18,417-418(2019)
[2] P.Langhorne,F.Coupar&A.Pollock,Motorrecoveryafterstroke: asystematicreview.TheLancetNeurology.8,
741-754(2009)
[3] V. Feigin, B. Stark, C. Johnson, G. Roth, C. Bisignano, G. Abady, M. Abbasifard, M. Abbasi-Kangevari, F.
Abd-Allah,V.Abedi&OthersGlobal,regional,andnationalburdenofstrokeanditsriskfactors,1990–2019: a
systematicanalysisfortheGlobalBurdenofDiseaseStudy2019.TheLancetNeurology.20,795-820(2021)
[4] G.Saposnik,R.Cote,M.Mamdani,S.Raptis,K.Thorpe,J.Fang,D.Redelmeier&L.Goldstein,JURaSSiC:
accuracyofclinicianvsriskscorepredictionofischemicstrokeoutcomes.Neurology.81,448-455(2013)
[5] J.Reid,D.Dai,S.Delmonte,C.Counsell,S.Phillips&M.MacLeod,Simplepredictionscorespredictgoodand
devastatingoutcomesafterstrokemoreaccuratelythanphysicians.AgeAndAgeing.46,421-426(2017)
[6] S.Warach,J.Gaa,B.Siewert,P.Wielopolski&R.Edelman,Acutehumanstrokestudiedbywholebrainecho
planardiffusion-weightedmagneticresonanceimaging.AnnalsOfNeurology: OfficialJournalOfTheAmerican
NeurologicalAssociationAndTheChildNeurologySociety.37,231-241(1995)
[7] M.Lansberg,V.Thijs,M.O’Brien,J.Ali,A.Crespigny,D.Tong,M.Moseley&G.Albers,Evolutionofapparent
diffusioncoefficient,diffusion-weighted,andT2-weightedsignalintensityofacutestroke.AmericanJournalOf
Neuroradiology.22,637-644(2001)
[8] M.Monteiro,A.Fonseca,A.Freitas,T.Melo,A.Francisco,J.Ferro&A.Oliveira,Usingmachinelearningtoim-
provethepredictionoffunctionaloutcomeinischemicstrokepatients.IEEE/ACMTransactionsOnComputational
BiologyAndBioinformatics.15,1953-1959(2018)
[9] J.Heo,J.Yoon,H.Park,Y.Kim,H.Nam&J.Heo,Machinelearning–basedmodelforpredictionofoutcomesin
acutestroke.Stroke.50,1263-1265(2019)
[10] X.Li,X.Pan,C.Jiang,M.Wu,Y.Liu,F.Wang,X.Zheng,J.Yang,C.Sun,Y.Zhu&OthersPredicting6-month
unfavorableoutcomeofacuteischemicstrokeusingmachinelearning.FrontiersInNeurology.11pp.539509
(2020)
[11] C.Lin,K.Hsu,K.Johnson,Y.Fann,C.Tsai,Y.Sun,L.Lien,W.Chang,P.Chen,C.Lin&OthersEvaluationof
machinelearningmethodstostrokeoutcomepredictionusinganationwidediseaseregistry.ComputerMethods
AndProgramsInBiomedicine.190pp.105381(2020)
10FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
[12] S.Alaka,B.Menon,A.Brobbey,T.Williamson,M.Goyal,A.Demchuk,M.Hill&T.Sajobi,Functionaloutcome
predictioninischemicstroke: acomparisonofmachinelearningalgorithmsandregressionmodels.FrontiersIn
Neurology.11pp.889(2020)
[13] S. Suganyadevi, V. Seethalakshmi & K. Balasamy, A review on deep learning in medical image analysis.
InternationalJournalOfMultimediaInformationRetrieval.11,19-38(2022)
[14] Y.Lai,Y.Wu,H.Yeh,Y.Wu,H.Tsai&J.Chen,UsingconvolutionalneuralnetworktoanalyzebrainMRIimages
forpredictingfunctionaloutcomesofstroke.Medical&BiologicalEngineering&Computing.60,2841-2849
(2022)
[15] E.Zihni,B.McGarry&J.Kelleher,MovingTowardExplainableDecisionsofArtificialIntelligenceModelsfor
thePredictionofFunctionalOutcomesofIschemicStrokePatients.ExonPublications.pp.73-90(2022)
[16] S. Osama, K. Zafar & M. Sadiq, Predicting clinical outcome in acute ischemic stroke using parallel multi-
parametricfeatureembeddedSiamesenetwork.Diagnostics.10,858(2020)
[17] A.Hilbert,L.Ramos,H.Os,S.Olabarriaga,M.Tolhuisen,M.Wermer,R.Barros,I.Schaaf,D.Dippel,Y.Roos&
OthersData-efficientdeeplearningofradiologicalimagedataforoutcomepredictionafterendovasculartreatment
ofpatientswithacuteischemicstroke.ComputersInBiologyAndMedicine.115pp.103516(2019)
[18] Z.Samak,P.Clatworthy&M.Mirmehdi,Predictionofthrombectomyfunctionaloutcomesusingmultimodal
data.MedicalImageUnderstandingAndAnalysis: 24thAnnualConference,MIUA2020,Oxford,UK,July15-17,
2020,Proceedings24.pp.267-279(2020)
[19] E. Zihni, V. Madai, A. Khalil, I. Galinovic, J. Fiebach, J. Kelleher, D. Frey & M. Livne, Multimodal Fusion
StrategiesforOutcomePredictioninStroke..HEALTHINF.pp.421-428(2020)
[20] S. Bacchi, T. Zerner, L. Oakden-Rayner, T. Kleinig, S. Patel & J. Jannes, Deep learning in the prediction of
ischaemicstrokethrombolysisfunctionaloutcomes: apilotstudy.AcademicRadiology.27,e19-e23(2020)
[21] N. Hatami, T. Cho, L. Mechtouff, O. Eker, D. Rousseau & C. Frindel, CNN-LSTM Based Multimodal MRI
andClinicalDataFusionforPredictingFunctionalOutcomeinStrokePatients.202244thAnnualInternational
ConferenceOfTheIEEEEngineeringInMedicine&BiologySociety(EMBC).pp.3430-3434(2022)
[22] E.Zihni,V.Madai,M.Livne,I.Galinovic,A.Khalil,J.Fiebach&D.Frey,Openingtheblackboxofartificial
intelligenceforclinicaldecisionsupport: Astudypredictingstrokeoutcome.PlosOne.15,e0231166(2020)
[23] M.Hsu,J.Chiou,J.Liu,C.Lee,Y.Lee,C.Chou,S.Lo,E.Kornelius,Y.Yang,S.Chang&OthersDeeplearning
forautomateddiabeticretinopathyscreeningfusedwithheterogeneousdatafromEHRscanleadtoearlierreferral
decisions.TranslationalVisionScience&Technology.10,18-18(2021)
[24] S.Huang,A.Pareek,R.Zamanian,I.Banerjee&M.Lungren,Multimodalfusionwithdeepneuralnetworksfor
leveragingCTimagingandelectronichealthrecord: acase-studyinpulmonaryembolismdetection.Scientific
Reports.10,1-9(2020)
[25] D.Wood,S.Kafiabadi,A.AlBusaidi,E.Guilhem,A.Montvila,J.Lynch,M.Townend,S.Agarwal,A.Mazumder,
G.Barker&OthersDeeplearningmodelsfortriaginghospitalheadMRIexaminations.MedicalImageAnalysis.
78pp.102391(2022)
[26] S. Qiu, G. Chang, M. Panagia, D. Gopal, R. Au & V. Kolachalama, Fusion of deep learning models of MRI
scans,Mini–MentalStateExamination,andlogicalmemorytestenhancesdiagnosisofmildcognitiveimpairment.
Alzheimer’s&Dementia: Diagnosis,Assessment&DiseaseMonitoring.10pp.737-749(2018)
[27] K. He, X. Chen, S. Xie, Y. Li, P. Dollár & R. Girshick, Masked autoencoders are scalable vision learners.
ProceedingsOfTheIEEE/CVFConferenceOnComputerVisionAndPatternRecognition.pp.16000-16009(2022)
[28] S.Song,Y.Zheng&Y.He,Areviewofmethodsforbiascorrectioninmedicalimages.BiomedicalEngineering
Review.1(2017)
[29] N.Tustison,B.Avants,P.Cook,Y.Zheng,A.Egan,P.Yushkevich&J.Gee,N4ITK:improvedN3biascorrection.
IEEETransactionsOnMedicalImaging.29,1310-1320(2010)
[30] B.Lowekamp,D.Chen,L.Ibáñez&D.Blezek,ThedesignofSimpleITK.FrontiersInNeuroinformatics.7pp.
45(2013)
[31] D. Stekhoven & P. Bühlmann, MissForest—non-parametric missing value imputation for mixed-type data.
Bioinformatics.28,112-118(2012)
[32] B.Chen,A.Rouditchenko,K.Duarte,H.Kuehne,S.Thomas,A.Boggust,R.Panda,B.Kingsbury,R.Feris,D.
Harwath&OthersMultimodalclusteringnetworksforself-supervisedlearningfromunlabeledvideos.Proceedings
OfTheIEEE/CVFInternationalConferenceOnComputerVision.pp.8012-8021(2021)
11FusionofDiffusionWeightedMRIandClinicalDataforPredictingFunctionalOutcomeafterAcuteIschemicStroke
withDeepContrastiveLearning TECHNICALREPORT
[33] T.Chen,S.Kornblith,M.Norouzi&G.Hinton,Asimpleframeworkforcontrastivelearningofvisualrepresenta-
tions.InternationalConferenceOnMachineLearning.pp.1597-1607(2020)
[34] P.Khosla,P.Teterwak,C.Wang,A.Sarna,Y.Tian,P.Isola,A.Maschinot,C.Liu&D.Krishnan,Supervised
contrastivelearning.AdvancesInNeuralInformationProcessingSystems.33pp.18661-18673(2020)
[35] K. He, X. Zhang, S. Ren & J. Sun, Deep residual learning for image recognition. Proceedings Of The IEEE
ConferenceOnComputerVisionAndPatternRecognition.pp.770-778(2016)
[36] R.Selvaraju,M.Cogswell,A.Das,R.Vedantam,D.Parikh&D.Batra,Grad-cam: Visualexplanationsfromdeep
networksviagradient-basedlocalization.ProceedingsOfTheIEEEInternationalConferenceOnComputerVision.
pp.618-626(2017)
12