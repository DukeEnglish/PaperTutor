Learning vs Retrieval: The Role of In-Context Examples in Regression with LLMs
AliakbarNafar1,KristenBrentVenable2,ParisaKordjamshidi1,
1MichiganStateUniversity
2FloridaInstituteforHumanandMachineCognition
nafarali@msu.edu,bvenable@ihmc.org,kordjams@msu.edu
Abstract learningorretrievingknowledge,butrather,itsbehaviorlies
on a spectrum between the two, which can be adjusted de-
Generative Large Language Models (LLMs) are capable of
pending on various factors. Before exploring our proposed
being in-context learners. However, the underlying mecha-
approach,weelaborateonthemethodsmentionedabove1.
nism of in-context learning (ICL) is still a major research
question,andexperimentalresearchresultsabouthowmodels Thefirsthypothesissuggeststhattransformersareeffec-
exploitICLarenotalwaysconsistent.Inthiswork,wepro- tivemeta-learners,andLLMscangenerateaccuratepredic-
pose a framework for evaluating in-context learning mech- tionsbasedsolelyonthegiveninput-outputpairs.(Baietal.
anisms, which we claim are a combination of retrieving in- 2023)theoreticallyprovesandpracticallyteststhecapability
ternalknowledgeandlearningfromin-contextexamplesby of an encoder-based transformer to implement generalized
focusingonregressiontasks.First,weshowthatLLMscan linearmodelsin-context.(Gargetal.2022)usesadecoder-
performregressiononreal-worlddatasetsandthendesignex-
basedmodel,aGPT-2architecturemodifiedforregression,
perimentstomeasuretheextenttowhichtheLLMretrieves
thatputstheinputfeaturesinsidetheembeddings(insteadof
itsinternalknowledgeversuslearningfromin-contextexam-
using tokens) and outputs a number. Their model’s perfor-
ples.Wearguethatthisprocessliesonaspectrumbetween
mance surpasses a 2-layer Multi-Layer Perceptron (MLP)
these two extremes. We provide an in-depth analysis of the
degreestowhichthesemechanismsaretriggereddepending and a decision tree by meta-learning. Further, (Vacareanu
on various factors, such as prior knowledge about the tasks et al. 2024) directly uses LLMs to test regression capabil-
andthetypeandrichnessoftheinformationprovidedbythe ities using a limited number of features (less than 3) and
in-contextexamples.WeemploythreeLLMsandutilizemul- concludes that LLMs are capable regressors. However, ac-
tiple datasets to corroborate the robustness of our findings. cording to our findings, their claim of avoiding data con-
Ourresultsshedlightonhowtoengineerpromptstoleverage taminationisnotwell-supported.Wenotethatnoneofthese
meta-learning from in-context examples and foster knowl-
researchworksuserealisticdatasetsorconsiderthecombi-
edgeretrievaldependingontheproblembeingaddressed.
nationofmeta-learningwithknowledgeretrieval.
The second approach emphasizes knowledge retrieval
Introduction while downplaying the learning aspect. For example, (Min
The emergence of transformers (Vaswani et al. 2017) has et al. 2022) examines 12 LLMs across various classifica-
revolutionized natural language processing, leading to the tiontasks,concludingthatalteringoutputlabels,whichare
development of LLMs such as GPTs (Brown et al. 2020) needed for learning, has no impact on performance. They
andLLaMA(Touvronetal.2023a).Inadditiontotheirim- argue that the crucial elements of ICL are limited to defin-
pressivezero-shotperformance,thesemodelsdemonstrated ing the label space, input distribution, and overall task for-
the capability of in-context learning (ICL), by which they mat. Meanwhile (Kossen, Gal, and Rainforth 2024) argues
learn a task from examples provided in the context of the thatLLMsutilizethelabelsbutinanarbitrarymannerwhen
prompt (Brown et al. 2020). In tasks where both zero-shot experimenting with the same classification tasks. (Li et al.
and ICL settings are applicable, ICL consistently outper- 2024)furtherdismissesthesignificanceofoutputlabelsand
forms the zero-shot setting (Brown et al. 2020; Liu et al. insteadproposestwoknowledgeretrievalapproaches.These
2022). However, the inner mechanism of ICL in LLMs re- include the retrieval of pre-existing solutions from training
mains a topic of discussion. Broadly speaking, current re- data(Minetal.2022;Wangetal.2024;Wies,Levine,and
search identifies two main approaches to the explain ICL Shashua2023),andanovelsolutioncompositionapproach,
mechanism: 1) Meta-learning (Schmidhuber 1987), which inspired by (Hahn and Goyal 2023), which proposes that
suggests that transformers are capable of using the in- learned solutions can be combined. While this work offers
context input-output examples to learn their distribution valuableinsightsintoICLmechanisms,itsfindingsarepo-
function;2)Knowledgeretrieval,accordingtowhichLLMs tentiallyskewedbyexperimentaldesignchoicesandanar-
utilizein-contextinputstoretrieveknowledgefromthedata row selection of datasets and models. A significant limita-
theyweretrainedonandthenapplyittothegiveninput.We
proposeadifferentapproach,arguingthatICLisnotmerely 1SeeAppendixAforadetaileddiscussiononrelatedwork.
4202
peS
6
]LC.sc[
1v81340.9042:viXraFigure 1: The three main prompt configurations that we use in our regression task. In configuration a) the actual names of
the features and the output are known, and the LLM is asked to guess the “price of a used Toyota or Maserati car in 2019”.
Configurationb)issimilartoa)exceptthatthefeaturenamesareanonymized.Here,theLLMisaskedtoestimatethe“Output”.
Finally,inConfigurationc),wereplacetherealpricesofin-contextexampleswithrandomly(Gaussian)generatednumbers.
tionistheexclusiveuseofLLaMA2(Touvronetal.2023b), formregressiononrealisticdatasetsandmeasuretheextent
whichisknowntostrugglewithlongtokencontexts(Mach- to which the LLM retrieves its internal knowledge versus
labandBattle2024;Zuhashaiketal.2023)whichnegatively learningfromin-contextexamples.Weprovideanin-depth
impactstheICL.Ourresearchchallengesseveralaspectsof analysisofthedegreestowhichthesemechanismsaretrig-
their conclusions. For instance, they report that remapping gereddependingonthefactorsweuseinourframework:the
theinputsofin-contextinput-outputpairstoalternativetext number of (feature, value) pairs, the number of in-context
reduces the accuracy to that of a random model (even with examples,andthepromptingstrategies.
upto40in-contextexamples).Ontheotherhand,undersim- Insummaryourcontributionsareasfollows:
ilarconditions,ourexperimentsindicatethatlearningoccurs 1)WedemonstratethatLLMscaneffectivelylearnfrom
withoptimalperformance.Werefrainfrommakingspecific regressionexamplesofrealisticdatasetsin-context,extend-
claimsabouttaskselectionorcompositioninourwork.In- ing previous work on synthetic data to more practical sce-
stead,wecategorizetheseprocessesunderthebroaderum- narios. 2) We propose an ICL mechanism hypothesis that
brella of knowledge retrieval 2. Similarly, to investigate in- combines both learning and knowledge retrieval during the
contextlearning,(Panetal.2023)usessimpleclassification LLMinference,reconcilingtheresearchcommunity’sfind-
tasksandoldermodels(suchasGPT-3Ada)andasaresult ings. 3) We introduce an evaluation framework that allows
itsfindingsarepartiallydifferentfromours. for systematic comparison of ICL mechanisms across dif-
We propose a different hypothesis that resolves the con- ferentLLMs,datasets,andpromptconfigurations3.
tradictions in the research community and support our 4) We provide a comprehensive analysis of how LLMs
claimswithextensiveempiricaltesting.WearguethatICLis balance internal knowledge retrieval and learning from in-
notmerelylearningorretrievingknowledgebutusesacom- context examples and provide prompt engineering tools to
bination of the two, which lies on a spectrum determined controlthem.
by factors we can manipulate. In this regard, we propose
an evaluation framework and conduct a comparative study ProblemSetting
ofdifferentLLMsanddatasets,focusingspecificallyonre-
Our study focuses on a regression task where we
gression problems as our testing ground. In our evaluation
use LLMs to predict numerical outputs based on the
framework, we query the LLM to estimate an output num-
given inputs. We assume a regression dataset, D =
ber based on a set of (feature, value) pairs given a set of
{(x ,y ),(x ,y ),...,(x ,y )}, comprising input-output
1 1 2 2 n n
ICLexamples,asshowninFigure1(a).Weoptedforregres-
pairs, is given. Each x comprises a set of pairs (f ,v )
i ij ij
siontasksprimarilyfortworeasons.First,thischoicealigns
wheref representsthefeature’snameandv isanumer-
ij ij
our work with the majority of related ICL meta-learning
ical value for f . Furthermore, the target variable y is the
ij i
research, thus facilitating direct comparisons and building
numerical value of the output. For example, if we consider
uponexistingfindings.Thistaskalsohasacomplexoutput
a dataset providing the price of used cars given their fuel
space(e.g.,continuousorunbounded)whichischallenging
economyandmileage,wecouldhaveaninputwith2(fea-
forLLMs(Fangetal.2024).WeshowthatLLMscanper-
ture, value) pairs, (Fuel Economy,16), (Mileage, 0), and an
2SeeAppendixBforamoredetailedanalysisofthediscrepan- 3Theframeworkcodeandanalyticaltoolsusedinthisworkare
ciesbetweenourfindingsandthoseof (Lietal.2024). availableathttps://github.com/HLR/LvsR-LLM.outputanswerof95595fortheprice. maintainthenamedfeaturesbutreplacethegroundtruthval-
In our experimental setting, we first present the ues with randomly generated numbers (independent of the
LLM with a subset of m input-output examples featurevalues).Theserandomnumbersaregeneratedusing
{(x ,y ),(x ,y ),...,(x ,y )} from the in-context a Gaussian distribution based on the dataset statistics. This
1 1 2 2 m m
split of D for learning. Then, we query the LLM with the setup mainly serves as a control to test to what degree the
feature pairs of x from the test split of D and expect the LLMsaretrulylearningfromtheprovidedgroundtruth.
answer y as the output.4 Figure 1(a) depicts our problem
DirectQuestionAnswering (DirectQA):Toestablishan
setting in the context of a regression task that involves
LLMbaseline,weaskourLLMstoestimatethetargetvari-
predicting the “price of a used Toyota or Maserati car
able based on the given named features without any in-
in 2019”, which is the target variable name, given three
contextexamples(m=0).Inthispromptconfiguration,we
(feature, value) pairs with a set of in-context examples
also define the scope of the output by providing the mean
provided beforehand. When m equals 0, we obtain the
and the standard definition of the questioned dataset in the
zero-shotsettingwherenopriorexamplesareprovided.
instructiontotheLLM.Anexampleofthisaddedinforma-
tionis:“Estimatetheinsurancecostofthispersongiventhe
PromptConfigurations
information.Anissuancecostistypicallyaround13270.42
We employ three main prompt configurations for prompt- withastandarddeviationof12110.01”.
ingthemodels,asshowninFigure1.Theseconfigurations
varyindifferentways,suchashidingtherealnameoffea-
ModelsandMetrics
tures (Figure 1(b)) or the actual ground truth (Figure 1(c)).
We also prompt the LLM with simple numerical genera- In our experiments, we evaluate several LLMs, including
tion as a baseline in our experiments. This results in a to- LLaMA 3 70B (AI@Meta 2024), GPT3.5 (Brown et al.
taloffourpromptconfigurations.Wealsoconsideredother 2020), and GPT4 (OpenAI 2023). We initially considered
prompt configuration which, either served as ablations, or smaller LLMs such as Mistral 7B (Jiang et al. 2023), but
didn’t provide any significant insights. We do not formally found them insufficient for our regression tasks and subse-
definethembutbrieflydiscussthemlaterinourexperiments. quently excluded them. To provide a comprehensive com-
In each prompt configuration, the context of the prompt parison,wealsoemployedclassicalmachinelearningtech-
comprises a task instruction, in-context examples (sample niques alongside these LLMs. Specifically, we utilized a
regressiontaskinput-outputs),andaquery.Thetaskinstruc- straightforwardRidgeregression(HoerlandKennard1970)
tion asks the LLM to estimate the objective of the dataset and the more advanced RandomForest model (Breiman
(suchas,thepriceofausedcar)basedonthegivenfeatures 2001). Further details about these models, such as their
by just providing a number and no explanation as the hyper-parameters,areincludedinAppendixC.
output.Eachofthesethreepartscanchangeorberemoved In our analysis, for each dataset, we test the LLMs
accordingtothepromptconfigurationasexplainedbelow: with a mix of factors (we call these factors to distinguish
them from the features f defined in our problem set-
ij
Named Features (Configuration a): This is our most
ting). The first factor is the prompt configurations, which
straightforward prompt configuration. It reveals the actual
canbeNamedFeature,AnonymizedFeatures,Randomized
names of the features and the required target variable (de-
Ground Truth, or Direct QA. The second and third factors
pending on the dataset) in the context of the prompt. For
are the number of in-context examples and the number of
instance, in the case of a dataset about the price of used
(feature,value)pairs,whichwewillcallthenumberoffea-
cars, the LLM is instructed to estimate a “Used Car Price”
turesgoingon.Thenumberofin-contextexamplesis0,10,
based on “City fuel Economy”, “Mileage” and “Passen-
30,and100,andthenumberoffeaturesis1,2,and3inour
ger Car Classification”. Following this instruction, sample
experiments.Thesefeaturenumbersrepresentusingthefirst
input-output examples are demonstrated to the model, and
feature (F1), the first two features (F2), and all three fea-
thenthequeryisaskedasshowninFigure1(a).
tures(F3)(featuresareorderedandsortedindecreasingor-
derofimportance).Notallthesefactorscanbeusedtogether
Anonymized Features (Configuration b): In this setup,
as the 0 in-context examples factor can only be used with
which is shown in Figure 1(b), we present the LLM with
theDirectQApromptconfiguration,andotherpromptcon-
input-outputpairswheretheactualnameofthefeaturesand
figurations can not be used with the 0 in-context examples
thetargetvariablearechangedtothegenericnamesof“Fea-
factor.ToassesstheperformanceoftheLLMsandthema-
ture#”and“Output”,respectively.Theinstructionasksthe
chinelearningmodelsonourregressiontasks,weuseMean
LLM to estimate the “Output” based on the given “Fea-
Squared Error (MSE) as our main comparison metric. We
tures”. Here, the LLM can not use its domain knowledge,
alsocalculateandreportthecoefficientofdeterminationR2
andcanonlyusetheprovidednumberofthefeatures.
andMeanAbsoluteError(MAE)inAppendixD.
RandomizedGroundTruth (Configurationc):Inourfi-
nal main prompt configuration shown in Figure 1(c), we Experiments
4We note that since we do not change the architecture of the This section presents our experimental findings, highlight-
LLMs,allnumbersmustberepresentedtoandreadbytheLLMin ing the interplay between various factors that influence the
textualform. performanceofLLMsacrossregressiontasksanddatasets.Datasets
To assess the LLMs’ performance across diverse domains
and complexity levels, we select three regression datasets.5
These datasets are pre-processed to select their most im-
portant features. All numerical values in the datasets are
roundedtotwodecimalpoints.Wedivideeachdatasetinto
two splits: an in-context subset comprising 100 instances
andatestsubsetwith300instances.
Figure 3: Baseline results of LLMs’ (Direct QA configura-
tion)acrossdatasetsandnumberoffeatures.Thedashedred
lineshowstheperformanceoftheMeanmodel.
KnowledgeRetrievalAssessment(DirectQA)
Figure 2: The relative importance of features across our Toestablishabaselineforoursubsequentanalyses,wefirst
datasets calculated with RandomForest (also reflecting im- evaluate the LLMs’ performance using only their knowl-
provementsinourRidgeaslatershowninFigure7. edgeretrieval,withoutanyin-contextexamples.Thisbase-
line assessment is required for understanding how the in-
context examples in other prompt configurations modulate
Admission Chance This dataset estimates the likeli- the LLMs’ performance and ICL mechanisms. The perfor-
hood of admission to graduate programs for Indian stu- mance of LLMs with Direct QA prompt configuration is
dents (Acharya, Armaan, and Antony 2019). Since this showninFigure3onallthreedatasets.Thereddashedline
dataset is about Indian students, it may be less seen in shows the performance of Mean model, which outputs the
our model’s training data, reflecting the general imbal- meanofthedatasetindependentoftheinputfeatures.Ascan
ance that skews towards USA-centric data (Zhu et al. beobservedtheadditionalfeaturesgenerallyimprovethe
2023). The dataset’s selected features are CGPA (Cumula- performanceacrosstasks(withinconsistencieswhenusing
tive Grade Point Average), GRE Score, and TOEFL Score. LLaMA3).However,theLLMs’utilizationoffeaturesdoes
Amongourthreedatasets,thisistheonlydatasetwithhigh notdirectlycorrelatewithpreviouslyestablishedfeatureim-
inter-correlation among each feature pair (Pearson correla- portancesshowninFigure2.Asfortheimpactofdatasets,
tion(Pearson1895)greaterthan0.80).Asaresult,thefea- theAdmissionChancedatasetconsistentlyshowsthepoor-
ture importances, which are calculated with RandomFor- estresultswithmostoutcomesatorabovetheMeanmodel’s
est(Louppeetal.2013)andshowninFigure2,assignmin- MSE.Asmentionedearlier,thisdatasetistheleastexposed
imalimportancetothesecondandthirdfeatures.Thetarget toLLMs,whichlikelyexplainsthesefindings.
variablehasameanof0.72andastandarddeviationof0.14. We further explored the Direct QA approach by asking
theLLMtoexplainitsreasoningprocessbasedonthegiven
InsuranceCost Thisdatasetfocusesonpredictingasimi- features before providing the final estimate. This variation
lardistributionoftheannualindividualmedicalcostsbilled yielded predictions comparable to the Direct QA results
by health insurance companies in the USA, drawing from without offering significant additional insights and conse-
demographic statistics compiled by the U.S. Census Bu- quentlywasexcludedfromourmainpromptconfigurations.
reau(Lantz2013).TheselectedfeaturesareSmokerStatus, SeeAppendixEforexampleanswersandrelateddiagrams.
BMI, and Age with their importances shown in Figure 2.
Smoking Status emerges as the most critical feature, fol- InterplayofKnowledgeRetrievalandLearning
lowedbyBMI,andthenAge.Theaverageandstandardde-
We have defined four main prompt configurations to vary
viationsofcostsare13,270.42and12,110.01,respectively.
the degree to which the model uses its knowledge retrieval
Used Car Prices We use selected subset of the used car or learning from the outputs of the in-context examples.
pricesdataset(Mital2023)thatinvolvespredictingtheprice By comparing the performance of these prompt configu-
of a used Toyota or Maserati car in 2019. The features in- rations, we can understand how LLMs utilize knowledge
cludeCityFuelEconomy,Mileagewithsimilarhighimpor- retrieval and learning from the outputs. Figure 4 presents
tance,andPassengerCarClassificationwithminimalimpor- a comprehensive comparison of these prompt configura-
tance,asshowninFigure2.Thetargetvariablehasamean tions’effectsonourmodels.TheRandomizedGroundTruth
of42,279.49andastandarddeviationof50,014.51. prompt configuration, shown with the lime color, consis-
tentlyyieldstheworstresults.Notethatthenamesofthefea-
5Alldatasetsusedinthisstudyarepubliclyavailable.Thepre- turesarerevealedtothemodelinthissetting.Asaresult,this
processingcodeforthesedatasetscanbeaccessedathttps://github. promptconfigurationcreatesascenariowherepatternsinthe
com/HLR/LvsR-LLM/tree/main/Datasets. datamaycontradictthemodel’sinternalknowledge.Forin-Figure4:Comprehensivecomparisonofpromptconfigurations’effectsonourmodelsacrossvariousfactors,showninahier-
archy.ThetoplevelforeachdatasetdistinguishesbetweenGPT-3,LLaMA3,andGPT-4resultsusingblack,grey,andwhite
arcs,respectively.ThenotationIC indicatesthenumberofin-contextexamples,whileF1,F2,andF3representtheuseofthe
i
firstfeature,thefirsttwofeatures,andallthreefeatures,respectively.TheMSEscaleofeachdatasetisshownattopleftcorner.
stance, in the Insurance dataset, some in-context examples KnowledgeRetrievalCompensatesICLExamples
show that people who smoke less require lower insurance
As previously noted, the Named Feature prompt config-
costs,whileothersindicatehighercostsforthesamegroup.
uration, which combines knowledge and learning, gener-
Thenegativeimpactofthispromptconfigurationonperfor-
allyoutperformstheAnonymizedFeaturepromptconfigura-
mancebecomesmoresignificantasthenumberofin-context
tion,whichreliesonlyonlearning.Regardingtheseprompt
exampleswithrandomoutputsincreases.Thisisparticularly
configurations, analyzing our defined factors, such as the
evident when using 100 in-context examples. These results
numberofin-contextexamples,revealsmoreinsightsabout
suggestthattheLLMsareusingtheoutputvariablestolearn
ICL.Conventionally,intherealmofLLMs,morein-context
fromtheexamples,andincreasingthenumberofin-context
examples tend to improve the task outcome. However, as
examples shifts the spectrum from knowledge retrieval
demonstrated in Figure 4, performance deteriorates with
tolearningfromoutputs.Ourfindings,whichindicatethat
more in-context examples when outputs are random, even
LLMs can be pushed to prioritize outputs from in-context
if the model possesses knowledge about the subject. Fig-
examplesoverknowledgeretrieval,challengeuselessnessof
ure 5, which compares the performance of different num-
theoutputsclaimedby(Minetal.2022;Lietal.2024).
bersofin-contextexamples,revealsthattheNamedFeature
ComparingtheNamedFeaturesandAnonymizedFeatures promptconfigurationperformsbetterwhenfewerin-context
prompt configurations shows the power of combining the examplesareused(solidvsdashedlines).Asignificantper-
two paradigms of learning from in-context examples and formancegapbetweenthetwopromptconfigurationsisob-
knowledge retrieval. Anonymized Features prompt config- servedat10in-contextexamples,shownwiththesolidand
uration,shownwiththegreencolorinFigure4,allowsonly dashed purple lines. However, at 100 in-context examples,
usageofthenumericpartofthefeaturesforlearning.Itstill shownwiththesolidanddashedlimelines,theperformance
achieves better results than the Direct QA and the Mean levelsconverge.Thisunderscoresthepotentialforreducing
model. Named Features prompt configuration, which adds the number of required in-context examples by provid-
the actual name of the features to the examples, is shown ingtask-specificinformation,therebyshiftingthespectrum
in purple. By encouraging the use of knowledge resulting fromlearningtoknowledgeretrievalutilization.
from the added names of the features, it consistently out- Moreover, Figure 6 shows the advantage of the Named
performsAnonymizedFeaturespromptconfigurationacross Features prompt configuration over both the Anonymized
variationsofthefactors(numberofin-contextexamplesand Features prompt configuration and also the traditional ma-
number of features). These results show that these models chine learning models by comparing them across various
can exploit both in-context examples’ outputs for learn- numbers of in-context examples (In the diagram, the num-
ingandclueslikefeaturenamesforknowledgeretrieval ber of features is fixed at 3). With fewer in-context exam-
(In any form, such as task selection for a particular regres- ples (30 and especially 10), Named Features prompt con-
sionsetting.).Notethatwhenwereplacedthefeaturenames figurationmodels,shownwithsolidlines,generallyoutper-
with random, unrelated names with the same ranges as the formallothermodels.Theirresultsindicatethatthetypeof
original features (e.g., replacing Smoker Status with Mar- informationintheLLMs’promptcanencourageexploiting
riedsincebotharebinary),theresultsremainedthesameas theirinternalknowledge.Moreover,theLLMs’capabilityto
thoseoftheAnonymizedFeaturespromptconfiguration. retrieveknowledgemakesthemmoredata-efficient(i.e.,Figure5:Comparisonofthenumberofin-contextexamplesusingNamedFeatures(straightlines)andAnonymizedFeatures
(dashedlines)promptconfigurations.IC indicatesiin-contextexamples.F1,F2andF3representsusing1st(F1),then1stand
i
2nd(F2),andallthreefeature(F3).TheMSEscaleofeachdatasetisshownattopleftcorner.
few-shot learners) than even classical machine learning improvestheresultsormaintainsnear-optimalperformance
models,shownwithgrey(RandomForest)andblack(Ridge) (asimilar,butlessrobust,trendisseeninthe30in-context
dashedlines.Allthemodelseventuallyconvergeat100ex- examples’diagraminAppendixE.).Whileaddingmorefea-
amples when sufficient data is provided. Providing beyond turesimprovesresults,thisimprovementismoresignificant
100in-contextexamplesyieldedasimilarperformance,sug- in language models compared to machine learning models
gestingthatthebenefitsofadditionaldatabecomemarginal. such as Ridge and RandomForest, black and grey dashed
linesinFigure7.Giventhatinthispromptconfiguration1)
feature names are anonymous, 2) only raw numerical data
is available for output estimation, and 3) the improvement
intheperformanceofLLMsdoesnotcorrelatewiththe
importance of the features, we conjecture that the results
could be influenced by data contamination from the ob-
servednumbers.Thisassertionissupportedbythefactthat
thisphenomenonisabsentintheAdmissionChancedataset,
theleastlikelyseendatasetbythelanguagemodels.
In the Named Feature prompt configuration for 100 in-
context examples depicted in Figure 7 (the solid lines), the
results show an overall improvement, yet the trend is not
as consistently downward or smooth as observed in the
Anonymized Features prompt configuration when features
are added. This fluctuation suggests that the knowledge re-
trievalaspectbecomesmoreprominentandoccasionallysu-
persedes the learning component as the number of features
Figure6:PerformanceofNamedFeaturesandAnonymized
increases. Based on these observations (that happen at a
Features prompt configurations, Ridge, and RandomForest
high number of 100 in-context examples), we hypothesize
for3featuresbasedonthenumberofin-contextexamples.
thataddingfeaturesprimarilyenhancestheknowledgere-
trievalaspectratherthancontributingtothelearning.
MoreFeaturesEncouragesKnowledgeRetrieval
Discussion
Unlike the number of in-context examples, the number of
Our evaluation framework and extensive experiments pro-
featuresstandsoutasauniquefactorthatcanimproveboth
vide insights into the ICL mechanisms of LLMs. In this
learningandknowledgeretrievalinLLMs.Asadditional
section,wediscusstheimplicationsofourfindings,address
features are incorporated into the context, LLMs can bet-
limitations,andsuggestdirectionsforfutureresearch.
terlearntherelationshipsbetweenfeaturesandoutputsand
alsoretrievemorerelevantknowledge.Thisclearlyhelpsthe
KeyFindingsandImplications
NamedFeaturespromptconfiguration.
However,thelessobviousinsightsinthissectionemerge ComprehendingandControllingICLMechanisms Un-
fromtheAnonymizedFeaturespromptconfiguration,which derstanding and manipulating ICL mechanisms in LLMs
relies only on learning and consistently improves with the proves invaluable for practical applications and effective
additionoffeatures.AsshowninFigure7for100in-context prompt engineering. Our experiments show that the LLMs
examples (the dotted lines), each additional feature either use both learning from the in-context input-output exam-tratedinFigure7,theimprovementdoesnotcorrelatewith
the actual importance of input features in the dataset. This
discrepancy strongly suggests that data contamination oc-
curs even at the level of numerical values. These findings
challengetheclaimsmadeby(Vacareanuetal.2024),which
usesapromptconfigurationsimilartoAnonymizedFeatures
toavoiddatacontamination.Theirstudyutilizeseitherwell-
known Friedman formulas or formulas that can be closely
approximated(usingtwodecimalplaces)bycommonmath-
ematicalexpressions6.
LimitationsofourFrameworkandFutureWork
Scope of Study Our framework focuses on regression
tasksinlinewithmostpreviousmeta-learningresearch.We
also utilize three diverse regression datasets. More regres-
Figure7:PerformanceofAnonymizedFeaturespromptcon-
sion(orclassification)datasetswithdifferentcharacteristics,
figuration,Ridge,andRandomForestfor100in-contextex-
suchasdifferentrelationshipsbetweentheirfeatures,canbe
amplesbasedonthenumberoffeatures.
usedforfutureinvestigation,whichcouldelaboratemoreon
the findings of our work with the previous work that dis-
missedtheimportanceofoutputsforlearning.
ples and prior information with varying extents. We found
that increasing the number of in-context examples encour-
Interpretability We interact with LLMs as a black box
ages learning while adding more features mainly boosts
andtheunderlyingneuralmechanismsremainopaqueinour
knowledgeretrieval.However,thesebenefitsonlymaterial-
experiments. Integrating this approach with interpretability
ize when there is room for improvement in the respective
techniquescouldyieldadeeperunderstandingofICL.
mechanism. For example, using more than 100 in-context
examples did not help our models, and in the Admission
Experimental Constraints The token limit of some
Chance dataset, where the features were highly correlated,
LLMspreventedusfromtestingbeyond100in-contextex-
the addition of features did not help the performance ei-
amplesandthreefeaturesincertaincombinations.Although
ther.Thisinsightexplainswhy(Minetal.2022)’stasksap-
we found that results with 200 in-context examples closely
pearednottoutilizeoutputlabelsforlearning;Intheirtasks,
mirroredthosewith100,includinga4thfeaturecouldhave
thedominantknowledgeretrievalaspectlikelyeclipsedany
further reinforced our findings. When tested, the results of
learning benefits. Our findings also challenge the view of
the 4th feature aligned with our conclusions. However, we
LLMs as merely meta-learners. While previous research
ultimately restricted our analysis to three features to main-
demonstrates decoder models’ capacity for meta-learning,
tainacomprehensivecombinationacrossallmodels.
the complex interplay of different training objectives (un-
knowninsomeproprietarymodels)andotherfactorsintro- Data Contamination Challenge Addressing the chal-
duce a significant knowledge retrieval component. Conse- lengeofdatacontaminationremainsacomplexissue(Sainz
quently,earlierfindingscanonlybedirectlyextrapolatedto et al. 2023; Balloccu et al. 2024). As mentioned earlier,
LLMswhenconsideringallthesedynamics. it is hard to distinguish the degree of Data Contamination
fromapproximateKnowledgeRetrieval.Basedonourfind-
Practical Applications Our findings emphasize the im-
ings,datacontaminationcanhappenevenwiththesequence
portance of striking an optimal balance between the num-
of numerical values without any linguistic clues. To miti-
berofmeaningfulfeaturesandthenumberofin-contextex-
gate this issue, we suggest using distributions that are nei-
amples to optimize LLM performance. By strategically re-
ther widely recognized nor easily approximated by com-
ducing the quantity of in-context examples while increas-
mon mathematical expressions. Furthermore, for datasets,
ing the number of named features, it is possible to achieve
it is advisable to utilize information sourced from regions
resource efficiency and other potential benefits, such as
beyondtheUnitedStatesoroutsidetheprimarytrainingdo-
mitigatingdatabiases,withoutcompromisingperformance.
main of the language model. This approach helps to mini-
Conversely, when tackling tasks unfamiliar to the model,
mizethepotentialinfluenceofknowledgeretrievalingener-
pruning less important features can free up space in the
atingtheresults.
LLM’stokencontext,allowingittoaccommodatemorein-
context examples. This shifts the ICL mechanism towards
learning from the examples’ side of the spectrum and im- Conclusion
provesthemodel’sperformancebythat.
Inthisstudy,wehaveexploredtheICLcapabilitiesofLLMs
Data Contamination is Hard to Disentangle In our ex- through an empirical study on regression tasks. Our results
periments,weshowedthatLLMscanperformregressionon demonstrate that LLMs utilize a blend of retrieved internal
realisticdatasets,evenwhenfeaturenamesareanonymized.
However, as detailed in the experiments section and illus- 6E.g.y=10x+sin(5πx)+cos(6πx)simplifiedasy=10x.knowledge and learned information from in-context exam- Hoerl, A. E.; and Kennard, R. W. 1970. Ridge regression:
ples. Our findings extend the evaluations of prior hypothe- Biasedestimationfornonorthogonalproblems. Technomet-
ses on ICL. For example, we evaluate the usage of outputs rics,12(1):55–67.
in in-context learning examples and show how to manipu-
Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
latetheireffectiveness.Thisworknotonlyadvancesourun-
Chaplot,D.S.;delasCasas,D.;Bressand,F.;Lengyel,G.;
derstanding of LLMs’ in-context learning phenomenon but
Lample, G.; Saulnier, L.; Lavaud, L. R.; Lachaux, M.-A.;
alsoofferspracticalinsightsforoptimizingtheirapplication
Stock,P.;Scao,T.L.;Lavril,T.;Wang,T.;Lacroix,T.;and
throughcarefulpromptengineering.
Sayed,W.E.2023. Mistral7B. arXiv:2310.06825.
Kossen, J.; Gal, Y.; and Rainforth, T. 2024. In-Context
References
Learning Learns Label Relationships but Is Not Conven-
Acharya, M. S.; Armaan, A.; and Antony, A. S. 2019. A
tionalLearning. arXiv:2307.12375.
ComparisonofRegressionModelsforPredictionofGradu-
Lantz,B.2013. MachineLearningwithR. PacktPublishing
ateAdmissions. In2019InternationalConferenceonCom-
Ltd. ISBN9781782162148.
putationalIntelligenceinDataScience(ICCIDS),1–5.
AI@Meta.2024. LLaMA3ModelCard. Li,J.;Hou,Y.;Sachan,M.;andCotterell,R.2024.WhatDo
Language Models Learn in Context? The Structured Task
Anthropic. 2024. Claude 3. https://www.anthropic.com.
Hypothesis. arXiv:2406.04216.
Largelanguagemodel.
Bai, Y.; Chen, F.; Wang, H.; Xiong, C.; and Mei, S. 2023. Li, Y.; Sreenivasan, K.; Giannou, A.; Papailiopoulos, D.;
TransformersasStatisticians:ProvableIn-ContextLearning and Oymak, S. 2023. Dissecting Chain-of-Thought: Com-
withIn-ContextAlgorithmSelection. arXiv:2306.04637. positionality through In-Context Filtering and Learning.
arXiv:2305.18869.
Balloccu, S.; Schmidtova´, P.; Lango, M.; and Dusˇek,
O. 2024. Leak, Cheat, Repeat: Data Contamination Liu,J.;Shen,D.;Zhang,Y.;Dolan,B.;Carin,L.;andChen,
and Evaluation Malpractices in Closed-Source LLMs. W.2022. WhatMakesGoodIn-ContextExamplesforGPT-
arXiv:2402.03927. 3? In Agirre, E.; Apidianaki, M.; and Vulic´, I., eds., Pro-
Breiman, L. 2001. Random Forests. Machine Learning, ceedingsofDeepLearningInsideOut(DeeLIO2022):The
3rdWorkshoponKnowledgeExtractionandIntegrationfor
45(1):5–32.
DeepLearningArchitectures,100–114.Dublin,Irelandand
Brown,T.B.;Mann,B.;Ryder,N.;Subbiah,M.;Kaplan,J.;
Online:AssociationforComputationalLinguistics.
Dhariwal,P.;Neelakantan,A.;Shyam,P.;Sastry,G.;Askell,
A.; Agarwal, S.; Herbert-Voss, A.; Krueger, G.; Henighan, Louppe,G.;Wehenkel,L.;Sutera,A.;andGeurts,P.2013.
T.; Child, R.; Ramesh, A.; Ziegler, D. M.; Wu, J.; Winter, Understanding variable importances in forests of random-
C.; Hesse, C.; Chen, M.; Sigler, E.; Litwin, M.; Gray, S.; ized trees. Advances in neural information processing sys-
Chess, B.; Clark, J.; Berner, C.; McCandlish, S.; Radford, tems,26.
A.; Sutskever, I.; and Amodei, D. 2020. Language Models Machlab, D.; and Battle, R. 2024. LLM In-Context Recall
areFew-ShotLearners. arXiv:2005.14165. isPromptDependent. arXiv:2404.08865.
Cheng, X.; Chen, Y.; and Sra, S. 2024. Transformers Im-
Min, S.; Lyu, X.; Holtzman, A.; Artetxe, M.; Lewis, M.;
plement Functional Gradient Descent to Learn Non-Linear
Hajishirzi, H.; and Zettlemoyer, L. 2022. Rethinking the
FunctionsInContext. arXiv:2312.06528.
Role of Demonstrations: What Makes In-Context Learning
Coda-Forno, J.; Binz, M.; Akata, Z.; Botvinick, M.; Wang, Work? ArXiv,abs/2202.12837.
J.; and Schulz, E. 2023. Meta-in-context learning in large
Mital,A.2023. USUsedCarsDataset.
language models. In Oh, A.; Naumann, T.; Globerson, A.;
Saenko, K.; Hardt, M.; and Levine, S., eds., Advances in OpenAI.2023.GPT-4TechnicalReport.arXiv:2303.08774.
NeuralInformationProcessingSystems,volume36,65189– Pan, J.; Gao, T.; Chen, H.; and Chen, D. 2023. What In-
65201.CurranAssociates,Inc. ContextLearning“Learns”In-Context:DisentanglingTask
Deutch, G.; Magar, N.; Natan, T. B.; and Dar, G. Recognition and Task Learning. In Rogers, A.; Boyd-
2024. In-contextLearningandGradientDescentRevisited. Graber, J.; and Okazaki, N., eds., Findings of the Associa-
arXiv:2311.07772. tionforComputationalLinguistics:ACL2023,8298–8319.
Fang, X.; Xu, W.; Tan, F. A.; Zhang, J.; Hu, Z.; Qi, Y. J.; Toronto, Canada: Association for Computational Linguis-
Nickleach, S.; Socolinsky, D.; Srinivasan Sengamedu, S.; tics.
andFaloutsos,C.2024. Largelanguagemodels(LLMs)on Pearson, K. 1895. VII. Note on regression and inheritance
tabular data: Prediction, generation, and understanding - a inthecaseoftwoparents. proceedingsoftheroyalsociety
survey. TransactionsonMachineLearningResearch. ofLondon,58(347-352):240–242.
Garg,S.;Tsipras,D.;Liang,P.;andValiant,G.2022. What Pedregosa, F.; Varoquaux, G.; Gramfort, A.; Michel, V.;
CanTransformersLearnIn-Context?ACaseStudyofSim- Thirion,B.;Grisel,O.;Blondel,M.;Prettenhofer,P.;Weiss,
pleFunctionClasses. ArXiv,abs/2208.01066. R.;Dubourg,V.;Vanderplas,J.;Passos,A.;Cournapeau,D.;
Hahn, M.; and Goyal, N. 2023. A Theory of Emer- Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-
gent In-Context Learning as Implicit Structure Induction. learn: Machine Learning in Python. Journal of Machine
arXiv:2303.07971. LearningResearch,12:2825–2830.Razeghi, Y.; Logan IV, R. L.; Gardner, M.; and Singh, S. Wang, X.; Zhu, W.; Saxon, M.; Steyvers, M.; and Wang,
2022. Impact of Pretraining Term Frequencies on Few- W. Y. 2024. Large Language Models Are Latent Variable
ShotNumericalReasoning. InGoldberg,Y.;Kozareva,Z.; Models: Explaining and Finding Good Demonstrations for
and Zhang, Y., eds., Findings of the Association for Com- In-ContextLearning. arXiv:2301.11916.
putationalLinguistics:EMNLP2022,840–854.AbuDhabi, Wies,N.;Levine,Y.;andShashua,A.2023. TheLearnabil-
United Arab Emirates: Association for Computational Lin- ityofIn-ContextLearning. arXiv:2303.07895.
guistics.
Zhu, W.; Lv, Y.; Dong, Q.; Yuan, F.; Xu, J.; Huang, S.;
Sainz, O.; Campos, J. A.; Garc´ıa-Ferrero, I.; Etxaniz, J.; Kong, L.; Chen, J.; and Li, L. 2023. Extrapolating Large
de Lacalle, O. L.; and Agirre, E. 2023. NLP Evaluation in Language Models to Non-English by Aligning Languages.
trouble:OntheNeedtoMeasureLLMDataContamination arXiv:2308.04948.
foreachBenchmark. arXiv:2310.18018.
Zuhashaik; et al. 2023. LLaMA-2-70B Model: Challenges
Schmidhuber, J. 1987. Evolutionary principles in self- with Long Token Sequences. https://github.com/meta-
referential learning. On learning how to learn: The meta- LLaMA/LLaMA/issues/887. GitHubIssue.
meta-... hook.) Diploma thesis, Institut f. Informatik, Tech.
Univ.Munich,1(2):48.
AppendixA:RelatedWork
Shen, L.; Mishra, A.; and Khashabi, D. 2024. Do pre-
As mentioned in the introduction, the research in this field
trained Transformers Learn In-Context by Gradient De-
can be categorized into meta-learning (Schmidhuber 1987)
scent? arXiv:2310.08540.
andknowledgeretrieval.Sofar,mostworksaretheoretical,
Team, G. 2024. Gemini 1.5: Unlocking multimodal and most can be categorized into one of these two groups.
understanding across millions of tokens of context. However, both of these aspects are changing as this field
arXiv:2403.05530. rapidly expands; New empirical research is coming along,
Touvron,H.;Lavril,T.;Izacard,G.;Martinet,X.;Lachaux, andnewideasareemerging,suchasours,thatcannoteas-
M.-A.; Lacroix, T.; Rozie`re, B.; Goyal, N.; Hambro, E.; ilyfitintooneofthesegroups.Forexample,(Lietal.2023)
Azhar, F.; Rodriguez, A.; Joulin, A.; Grave, E.; and Lam- proposesastructurethatimprovesabasictransformer’sin-
ple,G.2023a.LLaMA:OpenandEfficientFoundationLan- contextlearningcapabilitiesbybreakingtheinputintomul-
guageModels. arXiv:2302.13971. tiplesteps.Thetransformerstillusestheoutputsbutalsothe
Touvron,H.;Martin,L.;Stone,K.;Albert,P.;Almahairi,A.; knowledgethatisgiventoitinitsinput.Anotherexample
Babaei,Y.;Bashlykov,N.;Batra,S.;Bhargava,P.;Bhosale, wouldbe (Kossen,Gal,andRainforth2024),whichempiri-
S.; Bikel, D.; Blecher, L.; Ferrer, C. C.; Chen, M.; Cucu- callytestsLLMsandclaimsthattheycanlearnfromtheout-
rull,G.;Esiobu,D.;Fernandes,J.;Fu,J.;Fu,W.;Fuller,B.; putlabelsbutinanarbitrarymanner,achallengeourpaper
Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini, aimstoaddress.Anotherinterestingexamplethatwecannot
S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.; simplyputintoagroupis (Coda-Fornoetal.2023),which
Kloumann, I.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.; performsmeta-in-contextlearningbyshowingsimilarentire
Lavril,T.;Lee,J.;Liskovich,D.;Lu,Y.;Mao,Y.;Martinet, tasksandtheirsolutionsinthecontextofthemodel.Despite
X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poul- theseemergingworks,it’sworthnotingthatmostpaperscan
ton, A.; Reizenstein, J.; Rungta, R.; Saladi, K.; Schelten, stillbeclassifiedintoourestablishedgroups.Whenevaluat-
A.; Silva, R.; Smith, E. M.; Subramanian, R.; Tan, X. E.; ingtheliterature,it’scrucialtodistinguishbetweentheoret-
Tang,B.;Taylor,R.;Williams,A.;Kuan,J.X.;Xu,P.;Yan, ical claims and those based on empirical or synthetic data.
Z.; Zarov, I.; Zhang, Y.; Fan, A.; Kambadur, M.; Narang, Sometheoreticalpaperssuggestorimplythattheirfindings
S.; Rodriguez, A.; Stojnic, R.; Edunov, S.; and Scialom, T. might extend to LLMs, but such extrapolations should be
2023b. LLaMA 2: Open Foundation and Fine-Tuned Chat approached with caution, as highlighted by (Deutch et al.
Models. arXiv:2307.09288. 2024;Shen,Mishra,andKhashabi2024).
Inthemeta-learninggroup,(Baietal.2023)theoretically
Vacareanu, R.; Negru, V.-A.; Suciu, V.; and Surdeanu, M.
prove that transformers can be trained to implement linear
2024. From Words to Numbers: Your Large Language
models within a specific error threshold. Then, they practi-
Model Is Secretly A Capable Regressor When Given In-
cally test the capability of an encoder-based transformer to
ContextExamples. arXiv:2404.07544.
implement generalized linear models in context and show
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, that they are also robust against noisy data. In order to test
L.; Gomez, A. N.; Kaiser, L. u.; and Polosukhin, I. 2017. theICLcapabilityoftransformers,(Gargetal.2022)usea
Attention is All you Need. In Guyon, I.; Luxburg, U. V.; GPT-2 architecture which is closer to an LLM than a sim-
Bengio,S.;Wallach,H.;Fergus,R.;Vishwanathan,S.;and pletransformer.However,theymodifythisGPT-2architec-
Garnett,R.,eds.,AdvancesinNeuralInformationProcess- tureforregressionbyinputtingtheinputfeaturesinsidethe
ingSystems,volume30.CurranAssociates,Inc. embeddings instead of using tokens and outputting a num-
vonOswald,J.;Niklasson,E.;Schlegel,M.;Kobayashi,S.; ber at the end instead of generating tokens. Their model’s
Zucchet,N.;Scherrer,N.;Miller,N.;Sandler,M.;yArcas, performancesurpasseslinearmodelsaswellasKNNmod-
B. A.; Vladymyrov, M.; Pascanu, R.; and Sacramento, J. els,XGBoost,anda2-layerneuralnetwork.Differentfrom
2023. Uncovering mesa-optimization algorithms in Trans- these, (vonOswaldetal.2023)hypothesizethatthestrong
formers. arXiv:2309.05858. performance of Transformers comes from an architecturalbias towards mesa-optimization which they test on simple able at the time of publication. Some of their experiments
sequencingtasks,and(Cheng,Chen,andSra2024)suggest requiredirectaccesstotheLLMarchitecture,whichneces-
Transformers can implement gradient descent in function sitatesanopen-sourceLLM.However,manyoftheirexpe-
space,enablingthemtolearnlinearandnon-linearmodels. riences can be done with the GPT family or other power-
In the realm of empirical research, our focus is exclu- ful models. Based on the LLM choice alone, this work is
sivelyonstudiesexaminingICL,distinctfromrelatedworks severely limited. Further limiting the study, the authors se-
involving numerical concepts such as numerical reason- lectedthreesimplereviewsentiment/news-typedatasetsthat
ing(Razeghietal.2022).(Vacareanuetal.2024)usesalot evenbasicmachinelearningmodelscanexcelat.
ofdifferentLLMssuchasGemini-pro(Team2024),Claude
Regarding specific experiments, experiment 4.1 demon-
3(Anthropic2024),GPT-4(OpenAI2023)totesttheirICL
stratesthatmappingeachlabeltoanotherfixedlabelyields
regressioncapabilities.Theyusevarioussettingswithupto
results worse than a random baseline, even with 40 in-
three features, but not all features are relevant to the out-
context examples. This finding contradicts our work and
putaslimitedasaresult.Thisworkconductsrigoroustest-
other related studies, which have shown that models can
ingwithmanymodels,andtheonlyissueithasisregarding
learnfromoutputs.Wesuspectthisdiscrepancymaybeat-
itsclaimofavoidingdatacontaminationwhichisnotwell-
tributedtoLLaMA2’swell-documentedissueofforgetting
supported. They either use well-known Friedman formulas
tasks as the number of tokens increases. Confusion ensues
or formulas that can be closely approximated (using two
becausetheoutputslikelyappearnonsensicaltoLLaMA2,
decimalplaces)bycommonmathematicalexpressionssuch
andithasforgottenitsinstructions.Itwouldhavebeenben-
asy = 10x+sin(5πx)+cos(6πx)simplifiedasy = 10x.
eficialfortheauthorstospecifywhetherLLaMA2wasout-
Also, the data is based on formulas, which are not realistic
puttingincorrectlabelsorentirelyirrelevantanswers.
regressiondatasets.
Thefirstpaperthatarguesthatoutputlabelsdonotmatter Experiments4.2and5.1alsoraisequestions,astheyrely
was (Minetal.2022).IttestedvariousLLMsacrossmulti- on token embeddings, which, without further evidence, ap-
pletasksandconcludedthatreplacingtheoutputswithran- pearunrelatedtoICL.Forexample,(Lietal.2023)suggests
domlabelsdoesnotaffecttheresults,andtheonlyimportant thatthelevel-by-levelinferenceintransformersisnecessary
elementsofICLarelimitedtodefiningthelabelspace,input forICL.Thecombinationofembeddingsandotherfactors,
distribution, and overall task format. Following this work, such as training the linear model for 80 epochs to match
(Panetal.2023)usesthesamesentimentanalysis,toxicity LLaMA2’s80layers,seemsarbitraryandlacksclearjusti-
detection, natural language inference/paraphrase detection, ficationintheseexperiments.
andtopic/stanceclassificationtasksbutarguesthatlearning Inconclusion,whilethepaper(Lietal.2024)offersinter-
and retrieval occur under different circumstances. In con- estinginsightsspecificallyregardingitscategorizationofthe
trast to our research, their approach employs less complex threehypotheses,itsmethodologicalchoicesandrelianceon
tasks(sametasksusedin (Minetal.2022)),whichtheyac- LLaMA2significantlylimititsrelevancetothebroaderdis-
knowledgecouldinfluencetheobservedpatterns.Addition- cussionsofin-contextlearninginlanguagemodels.
ally, they utilize more basic models, including earlier and
smaller iterations of GPT-3 such as ada. As a result, their
findingsyielddistincttrendsandvisualrepresentationscom-
AppendixC:Hyper-Parameters
paredtoourwork.Inspiredby (HahnandGoyal2023),(Li
et al. 2024) dismisses the significance of output labels and
proposes that learned solutions can be combined for infer- Asmentionedearlier,weevaluateseveralLLMs,whichare
ence. The main limitation of this work is the exclusive use LLaMA 3 70B (AI@Meta 2024), GPT3.5 (Brown et al.
of LLaMA 2 (Touvron et al. 2023b). Our experimental re- 2020), and GPT4 (OpenAI 2023). We also used Ridge
sults differ from (Min et al. 2022; Pan et al. 2023; Li et al. regression (Hoerl and Kennard 1970) and RandomFor-
2024),whichrequiresaunifiedplatformfordirectcompari- est(Breiman2001).TheGPT-3andGPT-4versionsweuse
son,whichispracticallyinfeasible.Wearguethisconflictis are ”gpt-4-0125-preview“, ”gpt-3.5-turbo-0125“. In these
mainlyduetothetaskandmodelselection.Wewillexplain models,thetemperatureissetto0.1,andmaketokensisset
furtheron(Lietal.2024)inAppendixB. to10.Eachtimethemodelsdonotgenerateanumber(i.e.,
generateadisclaimerthatsays“thedataisinsufficient”),the
AppendixB:LearningfromOutputs
seedvalue,whichisinitializedto100,isincreasedbyone.
In this section, we examine the paper (Li et al. 2024) and This precaution was not necessary for GPT-4, but GPT-3.5
whyitsfindingsdifferfromours.Asmentionedearlier,the sometimes refused to answer the questions. For LLaMA 3,
main problem with this work lies in its exclusive use of toppvalueissetto0.99,maxtokensto6,andthetemper-
LLaMA2(Touvronetal.2023b),amodelknowntostrug- ature to 0.1. Similar to GPT models, we propmt LLaMA 3
gle with long token contexts (Machlab and Battle 2024; againifitfailstogenerateanumber.ForRidge,thedefault
Zuhashaik et al. 2023) which negatively impacts the ICL. Python class of scikit(Pedregosa et al. 2011) has the alpha
While the choice of LLaMA 2 as a powerful open-source value ( the normalizing variable) of 1. For RandomForest,
LLM at the time is understandable, LLaMA 3 (AI@Meta however, we wanted to make it more generalized. Conse-
2024),whichaddressedmanyofLLaMA2’sissuesandof- quently, we used 10,000 estimators and a max depth of 2
feredsignificantlyimprovedcapabilities,wasalreadyavail- forit.AppendixD:MAEandR2
In this section, we depict the main diagrams in the paper
withMAEandR2metricsinsteadofMSE.MAEislesssen-
sitive to outliers compared to MSE and is expressed in the
sameunitsastheoriginaldata.R2,alsoknownasthecoef-
ficient of determination, ranges from 0 to 1 and represents
the proportion of variance in the dependent variable that is
predictable from the independent variable(s). An R2 value
of 1 indicates that the model explains all the variability of
theresponsedataarounditsmean,while0meansthemodel
explains none of the variability. It can also be negative, in-
dicating that the model fits the data worse than the Mean
model.R2 differsfromMSEandMAEbecausethehigher,
thebetter.Asaresult,tomakeR2diagramscomparable,in-
Figure 9: This figure shows Figure 3 with R2 instead of
stead of R2, we show the results for 1−R2 (1 is included
MSE. The figure shows the baseline results of LLMs’ (Di-
toshowthenegativeresults,whichareworsethantheMean
rect QA configuration) across datasets and number of fea-
model).ThisalsomovesthebaselineresultsofR2 to1for
tures. The dashed red line shows the performance of the
theMeanmodel.
Meanmodel.
ForFigures3,4,5,6and7,theMAEresultsareshownin
Figures8,10,12,14and16,respectively.ForFigures3,4,5,
6and7,the1−R2 resultsareshowninFigures9,11,13,15 ReasoningExamples
and17,respectively.
In this section, we show an examples of reasoning to esti-
mateatheoutputforeachdatasetandLLMwith3features.
Wewillshowtheresultsofthissettinginthenextsection.
GPT-3 Reasoning over the Admission Chance Dataset:
Basedonthegiveninformation,theapplicanthasahighCu-
mulative GPA of 8.48, a decent GRE score of 311.0, and a
goodTOEFLscoreof104.0.Thesescoresareaboveaverage
andindicateastrongacademicbackground.
ConsideringthattheaverageChanceofAdmissionis0.74
withastandarddeviationof0.14,andtheapplicant’sstrong
academic profile, I would estimate that the Chance of Ad-
missionforthisapplicantishigherthantheaverage.
Myfinalestimationis0.80.
LLaMAReasoningovertheAdmissionChanceDataset:
Based on the provided information, I will estimate the
Figure 8: This figure shows Figure 3 with MAE instead of
ChanceofAdmission.
MSE.ThefigureshowstheaselineresultsofLLMs’(Direct
Thegivenscoresareallaboveaverage,indicatingastrong
QA configuration) across datasets and number of features.
applicant.ThecumulativeGPAof8.48isexcellent,suggest-
The dashed red line shows the performance of the Mean
ing a high level of academic achievement. The GRE score
model.
of311.0isalsoaboveaverage,indicatingstrongverbaland
quantitativeskills.TheTOEFLscoreof104.0iswellabove
the average required for most graduate programs, demon-
AppendixE:ReasoningConfigurationand stratingahighlevelofEnglishproficiency.
AdditionalDiagrams Considering these strong scores, I would expect the
ChanceofAdmissiontobehigherthantheaverageof0.74.
In this section, we include some diagrams that could have Given the standard deviation of 0.14, I would estimate the
providedmoreinsightandwereremovedfromthemaintext Chance of Admission to be around one standard deviation
forspace.Wealsoshowexamplesofthereasoningconfigu- abovethemean.
rationsanddiagramsrelatedtothat. Myfinalestimationis0.88.
GPT-4 Reasoning over the Admission Chance Dataset:
AdditionalDiagramsoftheMainPaper
ToestimatetheChanceofAdmissionbasedontheprovided
Here, we included the variants of Figures 6 and 7 that we information,weneedtoconsiderhowthegivendatapoints
omitted for space. Figure 6 with 1 and 2 features is shown (CumulativeGPA,GREScore,TOEFLScore)mightrelate
in Figures 18 and 19. Figure 7, with 10 and 30 in-context to the average Chance of Admission and its standard devi-
examples,isshowninFigures20and21. ation. However, without specific information on how theseFigure10:ThisfigureshowsFigure4withMAEinsteadofMSE.Thefigureshowsthecomprehensivecomparisonofprompt
configurations’effectsonourmodelsacrossvariousfactors,showninahierarchy.Thetoplevelforeachdatasetdistinguishes
between GPT-3, LLaMA 3, and GPT-4 results using black, grey, and white arcs, respectively. The notation IC indicates the
i
numberofin-contextexamples,whileF1,F2,andF3representtheuseofthefirstfeature,thefirsttwofeatures,andallthree
features,respectively.
Figure 11: This figure shows Figure 4 with R2 instead of MSE. The figure shows the comprehensive comparison of prompt
configurations’effectsonourmodelsacrossvariousfactors,showninahierarchy.Thetoplevelforeachdatasetdistinguishes
between GPT-3, LLaMA 3, and GPT-4 results using black, grey, and white arcs, respectively. The notation IC indicates the
i
numberofin-contextexamples,whileF1,F2,andF3representtheuseofthefirstfeature,thefirsttwofeatures,andallthree
features,respectively.
factorscorrelatewithadmissionchances,we’llhavetomake 3. **TOEFL Score**: A TOEFL score of 104 is good,
somegeneralassumptions basedontypicaladmissions cri- indicating a strong proficiency in English. For most uni-
teria. versities,thisscoreisabovetheminimumrequirementand
1.**CumulativeGPA**:An8.48GPA,assumingit’son should be sufficient to not negatively impact the chance of
a10-pointscale,isquitehigh.Thiswouldgenerallybeseen admission.
asastrongpositiveintheadmissionsprocess,suggestinga Given the average Chance of Admission is 0.74 with a
higherthanaveragechanceofadmission. standarddeviationof0.14,andconsideringthestrongGPA,
2. **GRE Score**: A score of 311 is somewhat above adequate GRE, and TOEFL scores, it’s reasonable to esti-
average(theaverageGREscoresformanyprogramstendto matetheChanceofAdmissiontobeaboveaveragebutnot
hover around the low to mid-300s). While not outstanding, exceptionally so due to the GRE score not being far above
it’s competitive enough not to detract significantly from an average.
application,especiallywithastrongGPA. Taking into account the positive impact of a high GPAFigure12:ThisfigureshowsFigure5withMAEinsteadofMSE.Thefigureshowsthecomparisonofthenumberofin-context
examplesusingNamedFeatures(straightlines)andAnonymizedFeatures(dashedlines)promptconfigurations.IC indicates
i
iin-contextexamples.F1,F2andF3representsusing1st(F1),then1stand2nd(F2),andallthreefeature(F3).
Figure13:ThisfigureshowsFigure5withR2 insteadofMSE.Thefigureshowsthecomparisonofthenumberofin-context
examplesusingNamedFeatures(straightlines)andAnonymizedFeatures(dashedlines)promptconfigurations.IC indicates
i
iin-contextexamples.F1,F2andF3representsusing1st(F1),then1stand2nd(F2),andallthreefeature(F3).
Figure14:ThisfigureshowsFigure6withMSEinsteadof Figure 15: This figure shows Figure 6 with R2 instead of
MSE.ThefigureshowstheperformanceofNamedFeatures MSE.ThefigureshowstheperformanceofNamedFeatures
and Anonymized Features prompt configurations, Ridge, and Anonymized Features prompt configurations, Ridge,
and RandomForest for 3 features based on the number of and RandomForest for 3 features based on the number of
in-contextexamples. in-contextexamples.Figure 16: This figure shows Figure 7 with MAE instead Figure18:ThisfigureshowsFigure6ofthemainpaperwith
ofMSE.ThefigureshowstheperformanceofAnonymized 1featuresinsteadof3.Thefigureshowstheperformanceof
Features prompt configuration, Ridge, and RandomForest Named Features and Anonymized Features prompt config-
for 100 in-context examples based on the number of fea- urations,Ridge,andRandomForestbasedonthenumberof
tures. in-contextexamples.
Figure 17: This figure shows Figure 7 with R2 instead of Figure19:ThisfigureshowsFigure6ofthemainpaperwith
MSE. The figure shows the performance of Anonymized 2featuresinsteadof3.Thefigureshowstheperformanceof
Features prompt configuration, Ridge, and RandomForest Named Features and Anonymized Features prompt config-
for 100 in-context examples based on the number of fea- urations,Ridge,andRandomForestbasedonthenumberof
tures. in-contextexamples.
andgoodTOEFLscore,balancedagainsttheGREscore,a
medicalcosts.ABMIof24.7isconsideredwithinthenor-
reasonable estimate might place the Chance of Admission
malrange,whichmayhaveaslightlylowerimpactonmed-
slightlyabovetheaveragebutnotbyalargemargin.There-
icalcostscomparedtoindividualswithhigherBMIs.
fore, considering the given data and the average Chance of
Taking into account these factors, along with the aver-
Admission,myfinalestimationis0.78.”
age annual individual medical costs billed by health insur-
GPT-3 Reasoning over the Insurance Cost Dataset: ance in the USA of $13,270.42 and a standard deviation
Based on the given information of being a smoker, having of $12,110.01, I estimate that the annual individual medi-
aBMIof24.7,andbeing43yearsold,wecanexpecthigher calcostsfora43-year-oldsmokerwithaBMIof24.7inthe
annualmedicalcostscomparedtonon-smokers,individuals USAwouldbehigherthantheaverageduetotheincreased
withlowerBMIs,andyoungerindividuals.Smokerstendto health risks associated with smoking and age. Therefore,
havehighermedicalcostsduetotheincreasedriskofvari- myfinalestimationis$20,000.””Basedontheprovidedin-
oushealthconditionssuchaslungcancer,heartdisease,and formation of being a non-smoker with a BMI of 25.8 and
respiratoryissues.Additionally,asindividualsage,theyare an age of 46, we can estimate that the individual is rela-
morelikelytodevelopchronichealthconditionsthatrequire tivelyhealthy.Typically,youngerindividualswithahealthy
ongoing medical care, which can also contribute to higher BMI and who do not smoke tend to have lower medicalucated estimation of the annual individual medical costs
billedbyhealthinsuranceintheUSA.
Wearegiventheaverageannualindividualmedicalcosts
billedbyhealthinsuranceintheUSA,whichis$13,270.42,
along with the standard deviation of $12,110.01. This sug-
gests that the distribution of medical costs is likely to be
skewedtotheright,withalongtailofhigh-costindividuals.
Theadditionalinformationprovidedabouttheindividual,
suchasbeingasmoker(smoker:1.0),havingaBMIof24.7,
and being 43 years old, can also influence the estimation.
Smokers tend to have higher medical costs due to the in-
creasedriskofsmoking-relatedillnesses.ABMIof24.7is
consideredoverweight,whichcanalsoleadtohighermedi-
calcosts.Theageof43isrelativelymiddle-aged,whichmay
nothaveasignificantimpactonmedicalcostscomparedto
Figure20:ThisfigureshowsFigure7ofthemainpaperwith olderoryoungerindividuals.
10in-contextexamplesinsteadof100.Thefigureshowsthe Consideringthesefactors,Iwouldadjusttheaveragean-
performanceofAnonymizedFeaturespromptconfiguration, nualindividualmedicalcostsupwardstoaccountforthein-
Ridge, and RandomForest for based on the number of fea- creasedriskassociatedwithsmokingandbeingoverweight.
tures. However,Iwouldnotadjustittoodrastically,astheindivid-
ual’sageisnotextremelyhigh.
Myfinalestimationis$16,500.”
GPT-4ReasoningovertheInsuranceCostDataset: To
estimatetheannualindividualmedicalcostsbilledbyhealth
insuranceintheUSAfora43-year-oldsmokerwithaBMI
of 24.7, we need to consider how the given factors (smok-
ingstatus,BMI,andage)typicallyinfluencemedicalcosts,
basedontheprovidedaverageandstandarddeviation.
1. **Smoking Status**: Being a smoker generally in-
creasesmedicalcostssignificantlyduetothehigherriskof
diseases associated with smoking (e.g., lung cancer, heart
disease). 2. **BMI**: A BMI of 24.7 is within the normal
weight range (18.5-24.9), which might not significantly in-
crease medical costs compared to those with higher BMI
values. 3. **Age**: At 43 years old, an individual might
start to experience more health issues than a younger per-
Figure21:ThisfigureshowsFigure7ofthemainpaperwith son, but not as many as someone in a more advanced age
30in-contextexamplesinsteadof100.Thefigureshowsthe group. This could mean slightly higher than average costs
performanceofAnonymizedFeaturespromptconfiguration, duetoagebutnotthehighestpossible.
Ridge, and RandomForest for based on the number of fea- Giventheaverageannualmedicalcostsof$13,270.42and
tures. consideringthesignificantimpactofsmoking,theeffectof
age, and the relatively neutral effect of a normal BMI, the
costsforthisindividualwouldlikelybehigherthantheav-
costscomparedtoolderindividualsorthosewithunhealthy eragebutnotexcessivelysoduetothemitigatingfactorofa
habits. healthyBMI.
Considering the average annual individual medical costs Consideringthestandarddeviationof$12,110.01,which
billedbyhealthinsuranceintheUSAof$13,270.42witha indicatesawiderangeofcosts,andthefactthatsmokingis
standard deviation of $12,110.01, we can assume that this amajorcostdriver,it’sreasonabletoestimatethatthecosts
individual’s medical costs might be lower than the average for this individual would be above average but not at the
due to their healthy profile. However, since medical costs extremeendofthespectrum.
canvarysignificantlybasedonindividualhealthconditions Giventheseconsiderations,areasonableestimateforthe
and unforeseen circumstances, it is challenging to provide annualindividualmedicalcostsforthisperson,factoringin
anaccurateestimatewithoutmorespecificinformation. thesignificantincreaseduetosmokingbutmoderatedbyage
Taking into account the individual’s healthy profile and and a healthy BMI, would be somewhat above the average
the average costs in the USA, my final estimation is butnotbythefullextentofonestandarddeviation.
$10,000.” Myfinalestimationis$20,000.”
LLaMA Reasoning over the Insurance Cost Dataset: GPT-3ReasoningovertheUsedCarPricesDataset: To
Based on the provided information, we can make an ed- estimatethepriceofausedcarthatcanbeeitheraToyotaorMaseratiin2019,wecanconsiderthefollowingfactors: Considering the standard deviation and the average, and
1. City Fuel Economy: The given city fuel economy of thefactthatthisisaluxuryvehiclelikelyonthehigherend
14.0 suggests that the car may not be very fuel-efficient, of the price spectrum, a reasonable estimation, taking into
whichcouldpotentiallyloweritsprice. account the luxury brand premium and the new condition,
2. Mileage: The mileage of 0.0 indicates that the car is wouldbeonestandarddeviationabovethemean.Thus,my
essentially brand new or has very low mileage, which gen- finalestimationis$92,294.”
erallytendstoincreasethepriceofausedcar.
ReasoningConfigurationDiagrams
3.IsToyota:ThefactthatthecarisnotaToyotaimplies
that it could be a Maserati, which is a luxury brand known ThediagramsthatcomparetheDirectQApromptconfigu-
forhigherpricetagscomparedtoToyotavehicles. rationtothereasoningconfigurationareshowninFigure22.
Considering these factors, we can infer that the car is Asmentionedinthetextofthemainpaper,thereisnorhyme
likelyaMaseratiduetoitsnon-Toyotastatus,whichwould orreasontothebehaviouroftheLLMsinthisregard.
generally have a higher price tag. Given that the average
priceofausedcarthatcanbeeitheraToyotaorMaseratiin
2019is$50,014.51withastandarddeviationof$42,279.49,
and considering the low mileage and potential luxury sta-
tusofthecar,myfinalestimationforthepriceofthisused
car would be higher than the average, so I estimate it to be
$60,000.”
LLaMA Reasoning over the Used Car Prices Dataset:
Basedonthegiveninformation,wecanseethattheaverage
price of a used car that can be either a Toyota or Maserati
in2019is50014.51withastandarddeviationof42279.49.
Since the mileage is 0.0, it’s likely that the car is relatively
new or has been well-maintained, which could increase its
value. The city fuel economy is 14.0, which is a moderate
value,butit’snotakeyfactorindeterminingthepriceofa
usedcar.
Themostimportantfactoristhebrand,andsinceIsToy-
ota is 0.0, it means the car is a Maserati, which is a luxury
brand known for its high-performance and premium vehi-
cles. Maserati cars tend to hold their value well, and their
pricesaregenerallyhigherthanthoseofToyotacars.
Considering these factors, I would estimate the price of
this used car to be higher than the average price. My final
estimationis65000.”
GPT-4 Reasoning over the Used Car Prices Dataset:
Giventheinformation,wehaveacarwithacityfuelecon-
omyof14.0,mileageof0.0,anditisnotaToyota(implying
itcouldbeaMaseratisincetheoptionsareeitherToyotaor
Maserati).Maseratisareluxuryvehiclesandtypicallyhave
ahigherpricepointcomparedtoToyotas.Theaverageprice
ofausedcarfromthegivendatais$50,014.51withastan-
darddeviationof$42,279.49.
ConsideringthecarinquestionisaMaserati(asindicated
by ””Is Toyota: 0.0””), and it has 0.0 mileage, which sug-
gestsit’seithernewornearlynew,wecanexpecttheprice
tobehigherthantheaverageofthemixedpoolofToyotaand
Maseratiusedcars.Thelowcityfueleconomyischaracter-
istic of high-performance or luxury vehicles, which aligns
withitbeingaMaserati.
Giventhesefactors,andknowingthatMaseratisarepre-
miumvehicles,thepricewouldlikelybeabovetheaverage.
However,withoutknowingtheexactmodeloryear(beyond
itbeing aused carasof 2019),wecan’t pinpointthe exact
price but can infer it would be higher due to the brand and
thenewnessindicatedbyzeromileage.Figure 22: Comparison between Direct QA and Reasoning prompt configurations between dataset, LLMs and the number of
features.