Exploring Foundation Models for Synthetic Medical
Imaging: A Study on Chest X-Rays and
Fine-Tuning Techniques
Davide Clode da Silva, Marina Musse Bernardes, Natha´lia Giacomini Ceretta, Gabriel Vaz de Souza,
Gabriel Fonseca Silva, Rafael Heitor Bordini and Soraia Raupp Musse
Pontifical Catholic University of Rio Grande do Sul (PUCRS), RS, Brazil
Email: gabriel.fonseca94@edu.pucrs.br, soraia.musse@pucrs.br
Abstract—Machinelearninghassignificantlyadvancedhealth- wide range of generalized and unlabeled data, typically using
carebyaidingindiseasepreventionandtreatmentidentification. self-supervision techniques. Examples of Foundation Models
However,accessingpatientdatacanbechallengingduetoprivacy
include ELMo [10], GPT-3 [11], CLIP [12], ResNet [13],
concerns and strict regulations. Generating synthetic, realistic
DALL-E [14], and Stable Diffusion [15]. These models
data offers a potential solution for overcoming these limitations,
and recent studies suggest that fine-tuning foundation models have achieved significant advancements in various complex
can produce such data effectively. In this study, we explore the tasks[16],suchasQuestionAnswering[11],KnowledgeBase
potential of foundation models for generating realistic medical Construction[17],andInformationRetrieval[18].Fine-tuning
images, particularly chest x-rays, and assess how their perfor-
such models targets the foundation model generalization ca-
mance improves with fine-tuning. We propose using a Latent
pabilities into specific applications.
Diffusion Model, starting with a pre-trained foundation model
and refining it through various configurations. Additionally, we One example is the MedCLIP project [19], where a
performed experiments with input from a medical professional
Contrastive Language-Image Pre-Training (CLIP) model was
to assess the realism of the images produced by each trained
adapted using the ROCO dataset [12], which includes fine-
model.
tuned images and corresponding captions. Researchers claim
I. INTRODUCTION that the adjusted model, MedCLIP, can identify higher-level
characteristics such as the image modality, distinguishing
Inrecentyears,MachineLearning(ML)hasplayedacrucial
between PET (Positron Emission Tomography) scans and
roleinhealthcare.Forinstance,indiseasepreventionandtreat-
ultrasound scans. Other studies have used generative model
ment,MLcanhelpanalyzelargedatasetstoidentifytrendsand
approaches for various purposes, including synthesizing real-
predict disease outcomes, such as modeling the progression
istic medical data [20], [21] and augmenting datasets for deep
and treatment of cancerous conditions [1]. Nevertheless, the
learning model training [8].
adoption of ML techniques in healthcare has been slow due
In this work, we present an initial exploration of the capa-
to factors like scarcity of patient data, data privacy concerns,
bilities of foundational models on generating realistic medical
regulatory requirements, and the critical nature of healthcare
imagesandhowtheirperformanceisimpactedbyfine-tuning.
decisions [2], [3].
We use a small dataset during the fine-tuning process to
Oneofthemainbarrierstoaccessingpatientmedicaldatais
assess the ability of FMs to learn effectively with limited
theneedtoprotectsensitiveandconfidentialinformationfrom
data. We focus on generating chest x-ray images, considering
unauthorized access. Additionally, the lack of standardized
healthyandunhealthydiagnoses.WeproposeutilizingaLatent
records and the effort required to collect medical data pose
Diffusion Model (LDM) approach, employing a pre-trained
significant challenges [4], [5]. Generating synthetic, realistic,
foundation model as a basis and later fine-tuning it with dif-
and high-quality medical data could be a viable alternative to
ferentconfigurations.Furthermore,weconductedexperiments
mitigate some of these issues. The industry predicts a signifi-
with the assistance of a medical professional to evaluate the
cantincreaseintheavailabilityofsyntheticdatainthecoming
realism of images generated by each model trained.
years, potentially doubling the amount of real data currently
available[6].Examplesincludegenerativemodelsforcreating The remainder of this work is organized as follows: Sec-
photorealistic images from natural language descriptions [7] tionsIIpresentsrelatedworkthathasplayedanimportantrole
and improving GAN-based (Generative Adversarial Network) in understanding different approaches to generating synthetic
models’ performance on super-resolution images [8]. medical data. Section III details our proposed method for
In the context of medical images, generative models may generating synthetic medical images. Section IV presents the
offer a practical solution, with some work focusing on fine- experiments conducted and preliminary results achieved. Fi-
tuningfoundationmodelsusingsmalldatasets[9].Foundation nally, Section V presents our final considerations, limitations,
Models (FMs) are machine learning models trained on a and possible future contributions.
4202
peS
6
]VI.ssee[
1v42440.9042:viXraII. RELATEDWORK [20] introduced the Inception Augmentation GAN (IAGAN)
for chest x-ray data augmentation, targeting semi-supervised
The literature presents various image-generated techniques,
detection of pneumonia and COVID-19. Inspired by the Data
often based on a textual description. Chen et al [22] proposed
Augmentation Generative Adversarial Networks (DAGAN)
Re-Imagen(Retrieval-AugmentedText-to-ImageGenerator),a
[27], their model aimed to generate synthetic data to enhance
generativemodelthatutilizesretrievedinformationtoproduce
training datasets for other models.
accurateimages.Itisdistinguishedbyitscapabilitytogenerate
faithful images, even for rare or never-before-seen entities. III. PROPOSEDMODEL
Zhou et al. [23] introduced LAFITE (LAnguage-Free traIning In this work, our main task is to perform the fine-tuning of
for Text-to-image gEneration) to address one of the major a Latent Diffusion Model in order to generate high-resolution
challenges in training text-to-image generation models: the syntheticchestx-rayimages.SectionIII-Adescribethedataset
requirement for a large number of image-text pairs. The utilized for fine-tuning, composed of real chest x-ray images.
authorsclaimthattheirproposedmodelcanbetrainedwithout Section III-B describes the fine-tuning process, resources and
any text data, and it has shown promising results. parameterization utilized.
Focusing on medical images, Pinaya et al. [21] proposed
A. Dataset
a model to generate synthetic images from high-resolution
brain MRIs. Their model uses data to learn the probabilistic In this study, we use the Montgomery County CXR Set
distribution of brain images based on covariates like age, sex, dataset for tuberculosis, developed by the National Library
and brain structure volumes. The authors employed Latent of Medicine in collaboration with the Department of Health
Diffusion Models (LDM), which combine autoencoders to and Human Services in Montgomery1. The dataset is publicly
compress input data into a lower-dimensional latent represen- available2 andiscomposedof138postero-anteriorchestx-ray
tation with the generative modeling properties of diffusion images. Of these, 80 are from normal (or healthy) cases, and
models. The compression model, crucial for enabling the 58arefromabnormal(orunhealthy)caseswithmanifestations
scalability of high-resolution medical images, was trained consistent with tuberculosis.
using a combination of perceptual loss and an adversarial Additionally, the dataset includes consensus annotations
objective based on patches—specific small areas of an image from two radiologists for resized 1024 × 1024 images and
used to modify or manipulate parts of the image to create a report describing the imaging results [28]. Figure 1 presents
adversaries or deceive machine learning algorithms. sample images of both cases and their respective annotations.
Ali et al. [24] investigated medical image synthesis using All images are anonymized and available in PNG format.
diffusion models. Initially, the authors used a pre-trained Basedonthe138x-raysavailable,weusedasubsetconsisting
DALLE2 [14] model to generate lung x-ray and CT images of30images(50%healthyimagesand50%unhealthyimages)
from text prompts, then, they trained a stable diffusion model to fine-tune the models. We chose to work with a data set of
on 3,165 x-ray images. For evaluation, two independent ra- thissizeasaninitialexplorationsothatwecouldobtainmore
diologists conducted a qualitative analysis by labeling ran- precise guidance on the next steps to be taken in future work.
domly chosen samples as real, fake, or uncertain. The results
B. Fine-tuning
indicated that the diffusion model could effectively translate
In our approach, we utilized the Kohya-ss GUI3, a friendly
features specific to certain medical conditions into chest X-
userinterfacethatallowsthesetup,trainingandfine-tuningof
rays or CT images.
diffusion models. The interface provides different techniques
Packhauser et al. [25], [26] utilized (LDM) to generate
for fine-tuning, such as DreamBooth [29] and LoRA (Low-
high-quality chest x-ray images while preserving the privacy
Rank Adaptation) [30]. We believe LoRA to be a more
of sensitive biometric information. Conditional information
appropriateoptionforourmethod,givenitstrainingefficiency
was embedded using a trainable lookup table combined with
by having a smaller number of parameters, reduced hardware
cross-attentionattheU-Netbottleneck.Themodelwastrained
requirementsforadaptiveoptimizers,versatilityinfine-tuning,
on a dataset of chest X-rays from 30,805 patients, including
and a smaller final model [30]. Additionally, we utilized
metadata with 14 abnormality labels and an additional class
TensorBoard4 alongside the Kohya-ss GUI as a visualization
for healthy individuals. The generated dataset was evaluated
toolkit for the loss and learning rates during the fine-tuning.
in a thoracic abnormality classification task, and the approach
Weselected“stable-diffusion-v1-5”,proposedbyRombach
outperformed GAN-based methods.
et al. [15], as our foundation model, which is capable of
Other recent work focuses on image generation for dataset
generating realistic images based on textual descriptions. We
augmentation. Sundaram et al. [6] proposed using Genera-
tive Adversarial Networks (GANs) to augment a chest x-ray
1Information on the research is available at: https://lhncbc.nlm.nih.gov/
dataset to address class imbalance. Their strategy involved LHC-downloads/dataset.html
creating synthetic chest X-ray images featuring at least one 2The dataset is available for download at: https://data.lhncbc.nlm.nih.
gov/public/Tuberculosis-Chest-X-ray-Datasets/Shenzhen-Hospital-CXR-Set/
of three underrepresented pathologies: lung injury, pleural
index.html
injury, or fracture. These synthetic images were added to the 3Availableat:https://github.com/bmaltais/kohya ss
original dataset to reduce class imbalance. Motamed et al. 4Availableat:https://github.com/tensorflow/tensorboardWe fine-tuned five distinct models, two utilizing the
AdamW8bit, and one with each remaining optimizer. Table I
presents the parameterization of each training. All models
were trained for 100 epochs. Finally, we utilized the Stable
Diffusion Web UI5 for generating the images. The interface
allowstheusertoselectdifferentmodels,imagequantitiesand
dimensions, seeds, and the prompt used for the generation.
TABLEI
PARAMETRIZATIONOFTHEFINE-TUNINGPROCESS.ALLMODELSWERE
TRAINEDUSING“stable-diffusion-v1-5”ASFOUNDATIONMODEL.THE
ADAM8BITOPTIMIZERWASUSEDINTWODISTINCTMODELS,M1USING
(a)“Normalchestx-ray”
ITSDEFAULTPARAMETERS,ANDM2USINGACONFIGURATIONSIMILAR
TOTHEREMAININGOPTIMIZERS.
Model M1 M2 M3 M4 M5
Optimizer AdamW8bit AdamW8bit Adafactor DAdaptSGD Prodigy
ClipSkip 2 2 2 2 2
Epochs 100 100 100 100 100
LR 1.10−4 1.10−4 1.10−4 1.10−4 1.10−4
MaxResolution 512x512 512x512 512x512 512x512 512x512
LRScheduler constant constant constant constant constant
TrainBatchSize 2 2 2 2 2
TextEncoderLR 5.10−5 5.10−5 5.10−5 1.10−5 1.10−5
Unetlr 1.10−4 1.10−4 1.10−4 1.10−5 1.10−5
VAEBatchSize 0 32 32 32 32
NoiseOffsetType Original Multires Multires Multires Multires
NoiseDiscount 0 0.1 0.1 0.1 0.1
NoiseIteration 0 6 6 6 6
IV. EXPERIMENTALRESULTS
For our experiments, we generated images of chest x-rays
(b) “Large infiltrate Right Upper Lobe with
cavitation plus infiltrate in RML. Consistent usingsixdifferentmodels:thepre-trainedfoundationalmodel,
withactivecavitaryTB.” named M0, and the five models fine-tuned using the different
Fig.1. Sampleimagesfromthedatasetandtheirrespectiveannotations[28]. optimizers presented in Table I, named M1 through M5. Each
(a)presentsanormalcase,and(b)anabnormalcase.
modelwasusedtogeneratetwosetsof12imageseach:oneset
representing normal cases, created with the prompt “healthy
or normal human chest x-ray”; and the other representing
performedafine-tuningonthisfoundationmodelutilizingthe
abnormal cases, created with the prompt “Human chest x-ray
chest x-ray dataset described in Section III-A. For the fine-
with tuberculosis.Bilateral miliarynodules withRight Middle
tuning process, we consider different optimizers, described
Lobe infiltrate. Right pleural effusion”.
next:
Figure 2 and Figure 3 present the sets of images generated
• AdamW8bit:isavariantofAdam,astochasticoptimiza- forthenormalandabnormalcases,respectively.Allfine-tuned
tion method designed for large-scale machine learning models (i.e., M1 through M5) were trained for 100 epochs.
problems. It adjusts the learning rate for each model We presented the generated images to a medical doctor, who
weight individually and computes adaptive learning rates evaluated their level of realism using a five-level Likert scale
for different parameters [31]–[33]. from Very Unrealistic (1) to Very Realistic (5). Normal and
• Adafactor: aims to overcome the memory requirements abnormal images were evaluated separately for each model.
of stochastic optimization methods like RMSProp and Table II presents the evaluation of the images made by the
Adam by storing only the row and column sums of medical doctor regarding each model, with respect to their
these averages, reducing memory usage while retaining realism. Models M0, M3, M4, and M5 were evaluated as
adaptability [34]. Very Unrealistic (1) for both image sets. Indeed, it can be
• DAdaptSGD: is a variant of DAdaption, specifically empirically observed in Figures 2 and 3 that these models
designed to automatically determine the learning rate generateimagesthatarequitedifferentfromarealx-rayimage
in the Stochastic Gradient Descent (SGD) optimization (Figure 1). Additionally, models M4 and M5, in particular,
algorithm [35]. presented a similar result to the foundational model M0 by
• Prodigy:isanoptimizerthatestimatesthedistancetothe generating more colorful and cartoon images.
solution, allowing for optimal learning rate adjustment
Models M1 and M2 achieved better results, with M1
in adaptive methods like Adagrad and Adam. It’s an
obtaining a Very Realistic (5) evaluation for normal cases
adaptation of the D-Adaptation method for learning-rate-
and Average Realism (3) for abnormal cases. Both models
free learning, where the learning rate is set automatically
[36]. 5Availableat:https://github.com/AUTOMATIC1111/stable-diffusion-webui(a)M0-Normal(Foundation) (b)M1-Normal(Adam8bit1) (a)M0-Abnormal(Foundation) (b)M1-Abnormal(Adam8bit1)
(c)M2-Normal(Adam8bit2) (d)M3-Normal(Adafactor) (c)M2-Abnormal(Adam8bit2) (d)M3-Abnormal(Adafactor)
(e)M4-Normal(DAdaptSGD) (f)M5-Normal(Prodigy) (e)M4-Abnormal(DAdaptSGD) (f)M5-Abnormal(Prodigy)
Fig.2. Setofnormalchestx-rayimagesgeneratedbythemodelspresentedin Fig.3. Setofabnormalchestx-rayimagesgeneratedbythemodelspresented
TableI.AllmodelsexceptM1werefine-tunedfor100epochsonadatasetof in Table I. All models except M0 were fine-tuned for 100 epochs on a
30chestx-rayimages.Allimagesweregeneratedusingtheprompt”healthy datasetof30chestx-rayimages.Allimagesweregeneratedusingtheprompt
ornormalhumanchestx-ray”. ”Human chest x-ray with tuberculosis. Bilateral miliary nodules with Right
MiddleLobeinfiltrate.Rightpleuraleffusion”.
utilize the Adam8bit optimizer, with M1 using the default V. CONCLUSION
configuration. These results indicate that further experimen-
In this work, we presented an initial exploration of the im-
tation could be conducted using the Adam8bit optimizer,
pact of fine-tuning foundation models for generating medical
as it demonstrated satisfactory performance. However, it is
images, focusing on chest X-rays. Our approach considers a
important to acknowledge the limitation of having only one
Latent Diffusion Model as a base model and different opti-
evaluator.
mizerconfigurationsforthefine-tuningprocess.Wegenerated
a set of images using these models, considering both normal
and abnormal cases. Our experiments indicate that even the
TABLEII
RESULTSOFTHEMEDICALDOCTOR’SEVALUATION.IMAGESGENERATED use of a small dataset for fine-tuning could generate images
BYEACHMODELWEREEVALUATEDUSINGAFIVE-LEVELLIKERTSCALE, with satisfactory levels of realism. However, our work has
FROMVERYUNREALISTIC(1)TOVERYREALISTIC(5).
some limitations. The experiments were conducted with input
from only one medical doctor and relied on visual inspection.
Normal Abnormal
Model Total Additional validation techniques could be applied, such as
(Figure2) (Figure3)
using qualitative metrics to assess the generated images and
M0(Foundation) 1 1 2
M1(Adam8bit1) 5 3 8 evaluating potential overfitting in the fine-tuned models.
M2(Adam8bit2) 3 2 5 For future work, we consider further experimentation with
M3(Adafactor) 1 1 2
different dataset sizes, evaluating the impact of different
M4(DAdaptSGD) 1 1 2
M5(Prodigy) 1 1 2 training times, and evaluating our model with more medical
professionals.TheAdam8bitoptimizer,inparticular,presented
better results and could be used in such experiments. We alsoconsider experimenting with additional prompts for abnormal [13] K.He,X.Zhang,S.Ren,andJ.Sun,“Deepresiduallearningforimage
cases,giventhevarietyofconditionsthatcouldbepresentedin recognition,”inProceedingsoftheIEEEconferenceoncomputervision
andpatternrecognition,2016,pp.770–778.
anx-ray.Finally,wealsoconsiderthedevelopmentofapplica-
[14] A.Ramesh,M.Pavlov,G.Goh,S.Gray,C.Voss,A.Radford,M.Chen,
tionsthatwillbebeneficialinbothhealthcareandeducational andI.Sutskever,“Zero-shottext-to-imagegeneration,”inInternational
settings. One concept involves creating an application that ConferenceonMachineLearning. PMLR,2021,pp.8821–8831.
[15] R.Rombach,A.Blattmann,D.Lorenz,P.Esser,andB.Ommer,“High-
allows teachers to use our method to generate personalized
resolutionimagesynthesiswithlatentdiffusionmodels,”inProceedings
examples tailored to their students’ needs. This approach can oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition,
improve the teaching and learning experience by providing a 2022,pp.10684–10695.
[16] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von
more interactive and engaging environment.
Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill et al.,
“On the opportunities and risks of foundation models,” arXiv preprint
ACKNOWLEDGMENTS arXiv:2108.07258,vol.Nothing,2021.
[17] F. Petroni, T. Rockta¨schel, P. Lewis, A. Bakhtin, Y. Wu, A. H. Miller,
This study was partly funded by the Coordenac¸a˜o de andS.Riedel,“Languagemodelsasknowledgebases?”arXivpreprint
Aperfeic¸oamento de Pessoal de N´ıvel Superior - Brazil arXiv:1909.01066,vol.Nothing,2019.
[18] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “Retrieval
(CAPES) - Finance Code 001, FAPERGS (RITE CIARS
augmented language model pre-training,” in International conference
22/2551-0000390-7), and by the Conselho Nacional de De- onmachinelearning,vol.Nothing. PMLR,2020,pp.3929–3938.
senvolvimento Cient´ıfico e Tecnolo´gico - Brasil (CNPq). This [19] Z.Wang,Z.Wu,D.Agarwal,andJ.Sun,“Medclip:Contrastivelearning
fromunpairedmedicalimagesandtext,”2022.
paper was supported by the Ministry of Science, Technology,
[20] S.Motamed,P.Rogalla,andF.Khalvati,“Dataaugmentationusinggen-
and Innovations, with resources from Law No. 8.248, dated erativeadversarialnetworks(gans)forgan-baseddetectionofpneumonia
October 23, 1991, within the scope of PPI-SOFTEX, coordi- andcovid-19inchestx-rayimages,”InformaticsinMedicineUnlocked,
vol.27,p.100779,2021.
natedbySoftex,andpublishedintheResideˆnciaemTIC02-
[21] W.H.Pinaya,P.-D.Tudosiu,J.Dafflon,P.F.DaCosta,V.Fernandez,
Aditivo, Official Gazette 01245.012095/2020-56. The authors P. Nachev, S. Ourselin, and M. J. Cardoso, “Brain imaging generation
wouldliketothankthemedicaldoctorwhoparticipatedinour withlatentdiffusionmodels,”inMICCAIWorkshoponDeepGenerative
Models. Springer,2022,pp.117–126.
experiments.
[22] W.Chen,H.Hu,C.Saharia,andW.W.Cohen,“Re-imagen:Retrieval-
augmented text-to-image generator,” arXiv preprint arXiv:2209.14491,
REFERENCES 2022.
[23] Y. Zhou, R. Zhang, C. Chen, C. Li, C. Tensmeyer, T. Yu, J. Gu,
[1] K. Kourou, T. P. Exarchos, K. P. Exarchos, M. V. Karamouzis, and J. Xu, and T. Sun, “Towards language-free training for text-to-image
D. I. Fotiadis, “Machine learning applications in cancer prognosis generation,”inProceedingsoftheIEEE/CVFConferenceonComputer
and prediction,” Computational and structural biotechnology journal, VisionandPatternRecognition,2022,pp.17907–17917.
vol.13,pp.8–17,2015. [24] H. Ali, S. Murad, and Z. Shah, “Spot the fake lungs: Generating
[2] A. Goncalves, P. Ray, B. Soper, J. Stevens, L. Coyle, and A. P. Sales, syntheticmedicalimagesusingneuraldiffusionmodels,”inIrishCon-
“Generation and evaluation of synthetic patient data,” BMC medical ferenceonArtificialIntelligenceandCognitiveScience. Springer,2022,
researchmethodology,vol.20,no.1,pp.1–40,2020. pp.32–39.
[3] C.ThapaandS.Camtepe,“Precisionhealthdata:Requirements,chal- [25] K. Packha¨user, L. Folle, F. Thamm, and A. Maier, “Generation of
lengesandexistingtechniquesfordatasecurityandprivacy,”Computers anonymouschestradiographsusinglatentdiffusionmodelsfortraining
inbiologyandmedicine,vol.129,p.104130,2021. thoracic abnormality classification systems,” in 2023 IEEE 20th Inter-
[4] I. Keshta and A. Odeh, “Security and privacy of electronic national Symposium on Biomedical Imaging (ISBI). IEEE, 2023, pp.
health records: Concerns and challenges,” Egyptian Informatics 1–5.
Journal, vol. 22, no. 2, pp. 177–183, 2021. [Online]. Available: [26] R. M. Favaretto, L. Dihl, S. Raupp Musse, F. Vilanova, and A. Bran-
https://www.sciencedirect.com/science/article/pii/S1110866520301365 delliCosta,“Usingbigfivepersonalitymodeltodetectculturalaspects
[5] N.S.AlmaghrabiandB.A.Bugis,“Patientconfidentialityofelectronic incrowds,”in201730thSIBGRAPIConferenceonGraphics,Patterns
healthrecords:Arecentreviewofthesaudiliterature,”Dr.SulaimanAl andImages(SIBGRAPI),2017,pp.223–229.
HabibMedicalJournal,vol.4,no.3,pp.126–135,2022. [27] A.Antoniou,A.Storkey,andH.Edwards,“Dataaugmentationgenera-
[6] S.SundaramandN.Hulkund,“Gan-baseddataaugmentationforchest tiveadversarialnetworks,”arXivpreprintarXiv:1711.04340,2017.
x-rayclassification,”2021. [28] S. Jaeger, S. Candemir, S. Antani, Y.-X. J. Wa´ng, P.-X. Lu, and
[7] S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee, G.Thoma,“Twopublicchestx-raydatasetsforcomputer-aidedscreen-
“Generative adversarial text to image synthesis,” in International con- ing of pulmonary diseases,” Quantitative imaging in medicine and
ferenceonmachinelearning. PMLR,2016,pp.1060–1069. surgery,vol.4,no.6,p.475,2014.
[8] H. Dou, C. Chen, X. Hu, Z. Xuan, Z. Hu, and S. Peng, “Pca- [29] N.Ruiz,Y.Li,V.Jampani,Y.Pritch,M.Rubinstein,andK.Aberman,
srgan:Incrementalorthogonalprojectiondiscriminationforfacesuper- “Dreambooth: Fine tuning text-to-image diffusion models for subject-
resolution,” in Proceedings of the 28th ACM International Conference driven generation,” in Proceedings of the IEEE/CVF Conference on
onMultimedia,2020,pp.1891–1899. ComputerVisionandPatternRecognition,2023,pp.22500–22510.
[9] B.Azad,R.Azad,S.Eskandari,A.Bozorgpour,A.Kazerouni,I.Rekik, [30] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
and D. Merhof, “Foundational models in medical imaging: A compre- and W. Chen, “Lora: Low-rank adaptation of large language models,”
hensivesurveyandfuturevision,”2023. arXivpreprintarXiv:2106.09685,2021.
[10] M.E.Peters,M.Neumann,M.Iyyer,M.Gardner,C.Clark,K.Lee,and [31] T.Dettmers,M.Lewis,S.Shleifer,andL.Zettlemoyer,“8-bitoptimizers
L. Zettlemoyer, “Deep contextualized word representations. naacl-hlt,” viablock-wisequantization,”arXivpreprintarXiv:2110.02861,2021.
arXiv,vol.Nothing,no.Nothing,2018. [32] H. Face, “8-bit optimizers,” 2023. [Online]. Available: https://
[11] T.Brown,B.Mann,N.Ryder,M.Subbiah,J.D.Kaplan,P.Dhariwal, huggingface.co/docs/bitsandbytes/main/en/optimizers
A.Neelakantan,P.Shyam,G.Sastry,A.Askelletal.,“Languagemod- [33] D.P.KingmaandJ.Ba,“Adam:Amethodforstochasticoptimization,”
els are few-shot learners,” Advances in neural information processing 2017.
systems,vol.33,pp.1877–1901,2020. [34] N. Shazeer and M. Stern, “Adafactor: Adaptive learning rates with
[12] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, sublinearmemorycost,”2018.
G.Sastry,A.Askell,P.Mishkin,J.Clarketal.,“Learningtransferable [35] A. Defazio and K. Mishchenko, “Learning-rate-free learning by d-
visual models from natural language supervision,” in International adaptation,”inInternationalConferenceonMachineLearning. PMLR,
conferenceonmachinelearning. PMLR,2021,pp.8748–8763. 2023,pp.7449–7479.[36] K. Mishchenko and A. Defazio, “Prodigy: An expeditiously adaptive
parameter-freelearner,”arXivpreprintarXiv:2306.06101,2023.