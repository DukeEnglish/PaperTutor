SPACE: A Python-based Simulator for Evaluating Decentralized
Multi-Robot Task Allocation Algorithms
Inmo Jang∗
Abstract—Swarm robotics explores the coordination of
multiplerobotstoachievecollectivegoals,withcollectivedecision-
makingbeingacentralfocus.Thisprocessinvolvesdecentralized
robotsautonomouslymakinglocaldecisionsandcommunicating
them, which influences the overall emergent behavior. Testing
such decentralized algorithms in real-world scenarios with
hundreds or more robots is often impractical, underscoring the
need for effective simulation tools. We propose SPACE (Swarm
Planning and Control Evaluation), a Python-based simulator
designedtosupporttheresearch,evaluation,andcomparisonof
decentralized Multi-Robot Task Allocation (MRTA) algorithms.
SPACE streamlines core algorithmic development by allowing
users to implement decision-making algorithms as Python plug- Fig.1. SPACEsimulatorvisualizationexample(na=5;nt=40)with
ins, easily construct agent behavior trees via an intuitive GUI, theCBBAplugininSectionIV
and leverage built-in support for inter-agent communication
and local task awareness. To demonstrate its practical utility,
we implement and evaluate CBBA and GRAPE within the
agent performing local decision-making based on local
simulator,comparingtheirperformanceacrossdifferentmetrics,
particularlyinscenarioswithdynamicallyintroducedtasks.This information, keeping computational demands relatively low.
evaluationshowstheusefulnessofSPACEinconductingrigorous Moreover, MRTA algorithms often do not necessitate high-
and standardized comparisons of MRTA algorithms, helping to fidelity individual-level robot physics, as decision-making
support future research in the field.
occurs in an abstract layer. Consequently, researchers often
implement their own simulations using MATLAB or Python
I. INTRODUCTION
on standard computers to evaluate their proposed algorithms.
Swarm robotics is a field that studies the coordination However, this approach lacks standardization, leading to
of multiple robots to perform tasks collectively, offering varied and inconsistent evaluation methods.
promising potential for future technological advancements. A Evaluating MRTA algorithms in dynamic situations is also
unique characteristic of control strategies in swarm robotics valuable but requires additional effort in simulation setup.
is their high-level layer called the collective decision-making Many MRTA studies primarily focus on static scenarios,
process [1], where each robot evaluates available options, where tasks are defined before a mission begins, and agents
selectsoneofthem,andthencommunicatesthislocaldecision calculate the assignments [4], [5]. Although there is some ex-
to its neighboring agents. This process, coupled with the plorationofdynamictaskgenerationscenarios,mostresearch
large number of robots typically involved in swarm robotics, doesnotsimulateenvironmentalchangesresultingfromagent
leads to significant inter-robot interactions that influence the movementortaskprogression.Instead,theseevaluationsoften
overall emergent behavior. Analyzing these interactions and considercaseswherenewtasksareintroducedafteranagreed
understandinghowtoachievedesiredemergentbehaviorsisa assignment and measure the computational time required
central research focus [2]. While real-world experimentation for re-convergence [6], [7]. Recently, analysis of sequential
with dozens of robots is feasible, testing decentralized decision-making in dynamic task generation scenarios have
algorithms with hundreds or more robots is impractical in an emerged [8], [9]. Nevertheless, researchers still need to
academic setting, emphasizing the crucial role of simulation implementthesefeaturesintheirownsimulatorsforthorough
in this field [3]. evaluation.
Several simulators exist for robotics, although few are ThisstudyintroducesSPACE(SwarmPlanningandControl
specifically tailored for studying collective decision-making
Evaluation), a simulator designed to facilitate the research,
algorithmsinswarmrobotics(seeSectionII-Aforareviewof
evaluation,andcomparisonofdecentralizedMRTAalgorithms
existing simulators). Evaluating high-level decision-making
with minimal coding effort. Users only need to develop
algorithms, such as Multi-Robot Task Allocation (MRTA)
their own decision-making algorithm as a Python plugin
problems, does not necessarily require highly powerful
and configure agents to use it through YAML settings.
computing resources. Decentralized algorithms involve each
SPACE comes equipped with built-in features for local
communication and local situational awareness, and supports
The authors is with Department of Autonomous Vehicle Engineering,
dynamic task generation. By implementing the core of the
KoreaAerospaceUniversity,Goyang,Gyeonggi,10540,SouthKorea.
∗correspondingauthor:inmo.jang@kau.ac.kr agent controller based on behavior trees (BTs) [10], [11], the
4202
peS
6
]OR.sc[
1v03240.9042:viXrasimulator facilitates easy development of necessary agent- B. Multi-Robot Task Allocation
level behaviors surrounding the decision-making algorithm.
As robotic systems mature, interest in deploying multiple
Thanks to this feature, SPACE facilitates effective compar- robots has grown. This has brought attention to Multi-Robot
isons of algorithms across different MRTA categories [12], Task Allocation (MRTA) problems, which focus on deter-
for example, evaluating ST-MR algorithms like GRAPE [7]
mining which robot should perform which tasks to optimize
againstMT-SRalgorithmslikeCBBA[5]inaspecificmission
system-level objective functions. MRTA are classified into
scenario.
various taxonomies based on the characteristics of the robots
and tasks involved (see [12], [18] for more details). Among
these, the two most studied types are Multi-Task robots
II. RELATEDWORK
with Single-Robot tasks (MT-SR) and Single-Task robots
with Multi-Robot tasks (ST-MR) [18]. To demonstrate the
A. Simulators for Swarm Robotics
usefulnessoftheSPACEsimulator,wecomparerepresentative
Each simulator has distinct design goals, and this fact decentralized algorithms for these two types (see Section V).
makes direct comparisons not straightforward [13]. Despite Therefore,theremainderofthissectionprovidesbriefreviews
the challenge, this section aims to review the features of of these algorithms.
simulators that have been ever updated in the past five years CBBA [5] is a decentralized method for MT-SR scenarios,
[3], specifically focusing on Gazebo, Webots, CoppeliaSim, where each agent performs multiple tasks sequentially, and
ARGoS, and Stage, from the perspective of high-level each task requires only one agent. Agents in CBBA greedily
collective decision-making algorithm research. build task bundles by bidding on their desired tasks and
sharing these bids with neighbors. Through a consensus
Gazebo, Webots, CoppeliaSim are well-known for their
process, they resolve inter-agent conflicts and determine task
high-fidelitysimulationsintheroboticsdomain.Theyprovide
assignments without a central auctioneer. CBBA has inspired
precise physical modeling, creating realistic environments for
various extensions. ACBBA [6] introduces asynchronous
testingandvalidatingroboticalgorithms.However,theirfocus
operations, eliminating the need for agents to synchronize
on high-fidelity makes real-time simulation of even dozens
between the decision-making and conflict resolution phases.
of robots challenging [14], limiting their effectiveness for
CBBA with Partial Replanning (CBBA-PR) handles newly
large-scale swarm robotics studies.
emerging tasks by resetting parts of previous allocations
ARGoS [14] is a simulator that balances realism and per-
during bidding rounds [19]. Grouped CBBA [20] improves
formance, efficiently managing larger robot swarms through
communication efficiency by organizing agents into groups.
its modular architecture that accommodate various simulation
GRAPE [7] is a decentralized algorithm that leverages
requirements. It supports agent-level programming, as well
an anonymous hedonic game framework. It was originally
as local communication and sensing. However, despite its
developedforST-MRscenarios[21],[22],whereeachagentis
use in evaluating multi-robot task allocation algorithms [15],
responsible for a single task that requires the collaboration of
the need for C++ implementation to set up simulations with
multiple robots. The algorithm aims to achieve a Nash stable
specific MRTA features can be challenging for researchers
partition, where no agent has an incentive to unilaterally
whopreferhigher-levellanguagesforrapidprototyping,quick
deviate, indicating that the swarm system has reached an
testing, and comparative analysis.
agreed assignment. A few GRAPE variants have recently
Stage [16] is known for its lightweight nature, making
emerged, extending to accommodate heterogeneous robots
it one of the simplest simulators available for multi-robot
that can perform distinct services [23]. Some studies have
systems. Although it natively supports agent local sensing, it
enhancedconvergencespeedbyutilizingabipartitealgorithm
lacks support for local communication. Additionally, its last
for initial partitioning [24] or by refining partition selection
update was nearly five years ago, and its documentation and
during its conflict-resolution process [25].
tutorials are not comprehensive enough.
C. Contributions
Our work was inspired by SwarmLab [17], a MATLAB-
based simulator developed to create standardized processes Inthisstudy,weproposeSPACE,aPython-basedsimulator
and metrics for assessing the performance of swarm algo- for MRTA research. We detail the development philosophy
rithms. SwarmLab functions as both a development tool and and software architecture behind its implementation (Section
a comparative platform for the aerial swarm research commu- III). As a use case, we demonstrate how to implement CBBA
nity and for educational purposes. The simulator proposed in and GRAPE as decision-making plugins within SPACE,
thisstudyalignswithSwarmLab’saim.Nevertheless,SPACE specifically for scenarios where tasks are newly added over
isdistinctinthatitisspecificallytailoredforMRTAresearch, time. Additionally, we describe the adaptation of GRAPE,
whereas SwarmLab concentrates on the navigation of aerial initiallydevelopedforST-MRscenarios,toaccommodateMT-
swarms in cluttered environments. To minimize coding effort SR scenarios (Section IV). We then provide a performance
and support complex agent behaviors, the architecture of our comparison of the two algorithms in terms of mission
simulatoremploysbehaviortreesandincludesagraphicaluser completion time, distance traveled by the agents, and tasks
interface tool for easy adjustment of these trees, enhancing completed, discussing the distinct characteristics of each
both usability and flexibility in simulation setup. algorithm based on these metrics (Section V).Below are the key features of the SPACE simulator: and then moves to the TaskExecutionNode to carry out
• Swarm Robotics Focus: Optimized for swarm robotics the assigned task. If the decision-making process fails (e.g.,
research, supporting large-scale simulations with a if no tasks are perceived nearby), the agent executes the
lightweight design. ExplorationNode, moving to a random position for a
• Behavior Trees: Uses behavior trees to define and certain period to search for tasks.
manage agent behaviors, allowing for flexible and We initially considered using an existing behavior tree
structured decision-making. library such as py trees; however, we opted to develop
• Groot2 Integration: Compatible with Groot21 for our own implementation to maintain a lightweight design
visualizing and editing behavior trees, enhancing ease for the simulator while ensuring greater flexibility for future
of use and analysis. enhancements. Notably, py trees lacks support for GUI
• FlexibleConfiguration:EasilyconfigurableviaaYAML tools[10].ByimplementingourbehaviortreeinXMLformat,
file, enabling customization without modifying the we made it compatible with Groot2, a GUI tool designed for
source codes of the simulator. BehaviorTree.CPP, thereby allowing easy visualization
• Custom Plugins: Integrates custom decision-making and modification for behaviors of individual agents.
algorithms as plugins, allowing for tailored testing and Ourbehaviortreeimplementationcurrentlysupportscontrol
experimentation. nodes (e.g., Sequence, Fallback) and action nodes
• Local Communication and Awareness: Agents com- (e.g., DecisionMaking Node, TaskExecutionNode,
municate locally within specified radii and maintain ExplorationNode,LocalSensingNode).Information
situationalawarenessbasedontheirsituationalawareness exchange between action nodes is facilitated through a
ranges. mechanismknownasblackboard [10],[11].Userscanextend
• Dynamic Task Generation: Supports the creation of functionality by adding custom action nodes, and a detailed
tasks dynamically during the simulation, adapting to tutorial for this is available on the official documentation
evolving scenarios. website. Custom behavior trees can be easily defined by
• Algorithm Comparison: Facilitates the comparison of dragging, dropping, and connecting nodes using Groot2.
different decision-making algorithms within a consistent
simulation environment and supports Monte Carlo tests B. Agent
for statistical analysis.
The Agent class encapsulates the core attributes and
The simulator is open-sourced2 and its tutorials are also
methods relevant for each agent in the simulator. Each agent
available at the official documentation website3.
instance possesses several fundamental attributes such as its
III. SOFTWAREARCHITECTURE statusinformation(e.g.,identificationnumber,position,veloc-
The core components of SPACE, as shown in Figure 2, ity, acceleration, rotation), and its mobility capabilities (e.g.,
are as follows: behavior tree, agent, decision-making plug-in, maximum linear speed, maximum angular speed, maximum
task, and simulation tools. acceleration). Each agent instance also has an attribute called
work rate, which specifies the amount of task workload the
A. Behavior Tree
agent can perform per second.
The simulator is developed using pygame4, with each Each agent also has attributes related to its local percep-
agent operating according to its own behavior tree. Behavior tion capabilities. These include its communication range,
treesareincreasinglypopularinopen-sourceroboticsprojects which defines the distance within which the agent can
due to their modularity and flexibility [11], which also interact with neighboring agents, and its situational aware-
motivated their use in our simulator. In each game loop ness range, which determines the area within which the
iteration, the behavior tree of each agent is executed from agent can perceive nearby tasks. A crucial function for
the root. The simulator assumes that the behavior tree local communication, local message receive(), col-
computation would be completed within a predefined control lects local decision data from neighboring agents. When
loopperiod,necessitatingadjustmentstothesimulationframe each agent executes its decision-making process at the
rate parameter based on actual robot computation times for DecisionMakingNode, it stores the resulting local
more realistic simulation. decision data in message to share, a Python dic-
The default behavior tree is shown in Figure 2. During tionary. The use of a dictionary allows users to de-
eachloop,theagentstartswiththeLocalSensingNodeto fine the message structure flexibly within their decision-
perceive any tasks nearby and receive any messages from its making plugins (see Section III-C), adapting the format
neighboring agents. Using such local information, the agent as needed. The local message receive() function
executes the DecisionMakingNode for task assignments, retrieves these local data and appends them to a Python
where a decision-making plugin operates (see Section III-C), list messages received of the agent. This function is
invoked by the LocalSensingNode of the behavior tree
1https://www.behaviortree.dev/groot/
in each game loop.
2https://github.com/inmo-jang/space-simulator
3https://space-simulator.rtfd.io/ Agents are modeled as point masses and move in straight
4https://www.pygame.org/ lines toward their assigned tasks, which is executed atFig.2. SPACESimulatorSoftwareArchitecture
the TaskExecutingNode. Although practical implemen- Thisstatusisthenmadeavailabletoneighboringagentswhose
tations involve obstacle avoidance and inter-agent collision situational awareness range includes the task.
avoidance,thesimulatoromitsthesecomplexitiesforaclearer Task instances are initially generated at the start of the
focus on evaluating high-level decision-making algorithms, simulationinaspecifiednumberwithinadefinedarea,usinga
which are the primary subject of the analysis. uniformrandomdistribution.Afterthisinitialsetup,additional
tasks can be created periodically at defined time intervals.
C. Decision-making Plug-in The frequency and number of the additional tasks can be
configured through config.yaml file. This dynamic task
Inspired by the approach used in Navigation2 [26], which
generation feature allows for the evaluation of decision-
allows for easy replacement of planners or controllers, our
making algorithms in terms of how effectively they can adapt
simulator is designed to enable users to effortlessly swap
decision-making algorithms by modifying config.yaml to changes in the environment.
file, treating it as a plugin. Three decision-making plugins E. Other Features
are currently implemented and will be detailed in Section IV.
Upon completion of a simulation, metrics such as the
Users can also implement their own decision-making
distance traveled and workload completed by the agents are
algorithms as custom plugins in separate Python files. Our
recorded, not only offering a time-wise summary of the
simulator aims to simplify the process of implementing
simulation progress but also capturing the individual agent-
algorithms from pseudocodes found in the literature. For
level data at the end of the mission. Both results are saved
instance,decentralizedalgorithmstypicallyinvolveatwo-step
in CSV files.
process [4], [5], [7]: first, each agent performs local decision-
The simulator supports two testing modes: with screen
makingandsharestheresultswithneighboringagents;second,
rendering and without. In screen rendering mode, the simula-
the agent uses the shared information to resolve conflicts.
tion can be visualized using pygame, and the output can be
Handling local communication requires extra coding efforts,
saved as a GIF through an optional feature.
buttheSPACEsimulatorstreamlinesthisprocessbyproviding
A notable feature of this simulator is its support for Monte
built-in support for local communication. Users can imple-
Carloexperiments.Toconducttheseexperiments,usersbegin
ment the first step by simply storing data to be shared (e.g.,
by configuring a scenario in a config.yaml, specifying
local decision data) in the message to share attribute
parameterssuchasthedecision-makingplugin,agent,andtask
of an agent before exiting the DecisionMakingNode.
settings. Multiple configurations can be developed to explore
The simulator automatically manages the distribution of
various parametric studies. A set of these configurations can
this data, ensuring that, in the next game loop, each agent
be defined in a separate YAML file, where the number of
receives the data from its neighboring agents during the
Monte Carlo runs for each scenario is also specified. The
LocalSensingNode. Consequently, agents can then use
simulator then automatically performs the tests repeatedly
this data to perform conflict resolution.
according to the defined parameters.
D. Task IV. PLUG-INIMPLEMENTATIONEXAMPLES
The Task class contains attributes for each task, includ- This section presents examples of how to implement
ing its identification number, position, and workload. To decision-making plugins within the SPACE simulator. We
manage these tasks, two key functions are utilized. The implemented CBBA [5], GRAPE [7], and a simple algorithm
reduce amount() function decreases the workload ac- namedFirst-ClaimedGreedy.Drawingfromourdevelopment
cording to the work rate of an agent performing the task. The experience, we outline a recommended structure for decision-
set done() function is called when the workload reaches making plugins. We then discuss additional modifications
zero,updatingthecompletedattributeofthetasktoTrue. made to GRAPE and CBBA, which extend beyond theiroriginaldescriptionstosupporttheMT-SRtypedynamictask satisfied is set to True (indicating the agent is content with
generation scenario in Section V. its decision), after which the function ends (Lines 9-11).
In the next game loop, the message received will
A. Structure Overview
contain messages from its neighboring agents. Since
Basically, a decision-making plugin is supposed to be de- satisfied was set to True in the previous loop, the
finedasaPythonclass(seeClass1),withamemberfunction DecisionMakingNodeskipsthedecision-makingprocess
DECIDE() that is invoked by the DecisionMakingNode
and instead runs the conflict-mitigating process (Line 13).
inthebehaviortree.Thenodeactsasawrapperthatconnects
For GRAPE, this is Algorithm 2 in [7], and for CBBA, it
the behavior tree with the plugin. Any elements that require
is the implementation of Table 1 in [5]. If the conflict is
initialization at the start of the mission should be placed in resolved, satisfied remains True; otherwise, it is set back to
a separate initialization function. For example, the boolean False (Line 14), prompting the decision-making process in
variable satisfied (Line 7) should be initially set to False the subsequent game loop. When the conflict is resolved for
(not shown here for simplicity).
everyagent,itmeansthatGRAPEhasidentifiedaNashstable
partitionorthatCBBAhasfinalizedthetaskbundlelist.Based
Class 1 DM Plug-in Structure
on this converged information, each agent can determine
1: function DECIDE() its assigned task and returns the task identification number
2: Get local tasks and local tasks from blackboard as output (Line 15). Then, the DecisionMakingNode
3: Post-process if the previously assigned task is done records the identification number in the blackboard, allowing
4: if no task in local tasks then the TaskExecutionNode to direct the agent toward the
5: return None task.
6: end if To summarize, if users follow the proposed structure, they
7: if satisfied = False then only need to implement Lines 8 and 13 as specified in
8: Local decision-making the pseudocodes of the literature, minimizing the need for
9: message to share ← data to share additional modifications. A template for this is available in
10: satisfied ← True the SPACE official documentation website.
11: return None
12: else B. GRAPE Modifications
13: Conflict-mitigating using messages received
In the scenario involving dynamic task generation, addi-
14: satisfied ← False if not conflict-free yet
tional modifications are made to the original GRAPE. First,
15: return assigned task id if satisfied = True
weincorporateamechanismwhereeachagentdecentralizedly
None otherwise
constructs an initial partition such that each neighbor agent is
16: end if
assignedataskclosesttoitasthestartingpoint.Asshownby
17: end function
[24], setting an initial partition can accelerate convergence to
a Nash stable partition, thereby facilitating better adaptation
The decision-making plugin starts by retrieving local
to dynamic environments. This process is implemented at the
information from the blackboard (Line 2), which was gath-
initialization function of the decision-making plugin and also
ered by the LocalSensingNode at the beginning of the
during the post-processing after a task is completed (Line 3).
behavior tree, as shown in Figure 2. If there is already
AlthoughGRAPEhasbeentheoreticallyproventoconverge
an assigned task, the plugin checks its completion status
to a Nash stable partition when agents are connected in a
and takes necessary post-completion actions (Line 3). For
strongly connected topology, determining whether all agents
instance, in CBBA, this involves removing the completed
haveconvergedrequiresglobalinformation.Hence,weimple-
task from the task bundle and designating the next task in
ment such that each agent assesses convergence based solely
the list as the new assignment. If no local tasks are found on
on its local information. Specifically, the agent compares
the blackboard, the decision-making process concludes with
its locally-known partition with the partition resulted from
None (Lines 4-6), causing the DecisionMakingNode to
the distributed-mutex algorithm [7] (Line 13). If there is no
signal a failure and triggering the Fallback to activate
differencebetweenthetwopartitions,theagentconcludesthat
the ExplorationNode to search for other tasks in the
itslocally-knownpartitionbecomesNash-stable,andsatisfied
environment.
remains True (Line 14). However, if the agent receives a
Decentralized MRTA algorithms typically involve a local
new partition information from another agent further than
decision-making process followed by a conflict-mitigating
one hop away, satisfied might be set to False. This triggers
process using information from neighboring agents. To
to proceed the decision-making process based on the new
distinguish between these two steps within the plugin, we
information.
use a boolean flag, satisfied. When satisfied is False, the
For the individual utility function of agent a ∈ A with
i
decision-making process is executed as required (Line 8).
respect to t , we use the following equation:
j
For GRAPE, this corresponds to Algorithm 1 in [7], and for
CBBA, Algorithm 3 in [5]. Next, any messages to share with R
u (t ,|S |)= j −c ·|S |fs, (1)
neighboring agents are stored in message to share, and i j j |S | i,j j
jwhere S ⊆A is the task-specific coalition; R is the reward In the scenario, each agent can sequentially execute
j j
for completing task t ; c is the distance-based cost from multiple tasks, with each task requiring at least one robot
j i,j
agent a to t ; and f ∈ R+ is a scalar factor representing for completion. While multiple robots may collaborate on a
i j s
socialinhibitionbetweenagents.ToadaptGRAPE,originally single task if necessary, this can increase the associated costs
designed for ST-MR scenarios, to MT-SR scenarios, we for those robots. When such collaboration occurs, the work
introduce the term |S j|fs. When the coalition size is 1, this rates of the participating agents are combined, resulting in
term has no effect, making Equation (1) identical to the form faster task completion. Although in practice the summation
in [7]. However, as the coalition size increases, this term of work rates might exhibit submodular characteristics, for
amplifies the cost, encouraging agents to disperse, which simplicity in this evaluation, we assume a linear summation.
facilitates handling MT-SR scenarios.
C. CBBA Modifications A. Experiment Setting
In dynamic environments, as noted by [6], [19], CBBA
may need to be rerun to address outdated information or
TABLEI
significant changes in situational awareness. Our empirical
OVERVIEWOFEXPERIMENTALPARAMETERS
experiments also reveal that discrepancies between bid costs
and actual execution results further affect the phenomenon. Feature ParameterValue
For instance, we observed scenarios where an agent, after SimulationUpdateRate 1Hz
winning a task with a high bid value, later removed the task AreaSize(w,h) 1400,1000
from its task bundle when a more attractive one emerged.
NumberofTasks(nt) 250(initial);50×3(additional)
TaskWorkload [6,60]
Consequently, the task remained unassigned, as the other
AgentWorkRate 1
agents were unable to bid on it due to its high cost. MaxLinearSpeed(vmax) 0.25
Toaddresstheproblemofinvalidbidvaluesandunassigned MaxAcceleration(amax) 0.01
tasks,weintroduceasimplemechanism:ifthetaskbundleof
MaxAngularSpeed(ωmax) 0.25
SituationAwarenessRange(rp) 300
an agent remains empty for a certain period, the agent resets
CommunicationRange(rc) {100,200,300}
all of its known winning bid values and winning agent IDs. NumberofAgents(na) {10,30,50}
Although resetting bid values was also proposed in CBBA- MRTAAlgorithm {CBBA,GRAPE,FCG}
PR [19], our study aims to compare the baseline versions
of CBBA and GRAPE. Thus, we implement this simple The common settings for the scenario are as follows. Basi-
modificationtoCBBAinsteadofusingCBBA-PRtoevaluate cally,thesimulationloopoccurswith1Hzwithconsideration
its effectiveness in dynamic environments. of potentially low communication bandwidth between agents.
For the scoring function of agent a i with regard to its The map has dimensions of 1400 units in width and 1000
task-execution path p i, we use the time-discounted reward units in height. The scenario starts with 250 tasks, with
[5]: an additional 50 tasks being generated every 1000 seconds
S ipi =(cid:88) λτ ij(pi)·R j, (2) for 3 times, resulting in 400 tasks in total. These tasks are
distributed randomly across the map according to a uniform
where λ∈[0,1] is the discount factor; τj ∈R+ represents
i distribution. Each task takes between 6 and 60 seconds to
the estimated time for the agent to finish task t , taking into
j complete, as all agents work at the same work rate of 1.
account the distance to the task along the path, and its work
Each agent has the same mobility capabilities as shown in
rate. R is the reward received upon task completion.
j Table I, and has a situation awareness range with 300 units.
D. First-Claimed Greedy Algorithm Regarding the utility functions for GRAPE and CBBA, i.e.,
Equations(1)and(2),weusethefollowingparameters:R is
Weimplementasimplealgorithmwhereeachagentselects j
set to be the workload of task t ; the social inhibition factor
the task nearest to itself based on local task information. In j
f is 100; the discount factor λ is 0.999.
making this selection, the agent also considers messages s
Our experiments evaluate the performance of GRAPE,
received from its neighboring agents. If the agent realizes
CBBA, and FCG algorithms under varying conditions.
that the chosen task has already been assigned to another
We vary the number of agents n ∈ {10,30,50} and
agent,itabandonsthattaskandtriesthetaskselectionprocess a
communication radii r ∈ {100,200,300} to assess their
again in the next game loop. We refer to this approach as the c
First-Claimed Greedy algorithm, as it ensures that the initial impact on each algorithm. Specifically, we test a total of
27 scenarios, corresponding to all combinations of agent
claim of an agent on a task is confirmed.
numbers, communication radii, and algorithms, with 100
V. USECASE:COMPARISONOFALGORITHMS
Monte Carlo simulations conducted for each scenario. The
This section demonstrates the usefulness of the SPACE performanceofeachalgorithmisassessedbasedonthreekey
simulator by comparing three algorithms, GRAPE, CBBA, metrics:(1)missioncompletiontime,(2)distancetraveledby
and First-Claimed Greedy (FCG), in a MT-SR scenario. Our the agents, and (3) workload done by the agents. Note that
goal aims to showcase how SPACE can be used to evaluate all experiments are conducted using SPACE’s Monte Carlo
and contrast these algorithms effectively. simulation support, as detailed in Section III-E.(a) na=10 (b) na=30 (c) na=50
(d) na=10 (e) na=30 (f) na=50
(g) na=10 (h) na=30 (i) na=50
Fig.3. ComparativeperformanceresultsofGRAPE[7],CBBA[5],FCGinscenarioswithna∈{10,30,50}andrc∈{100,200,300}.
B. Comparative Results When the agents eventually become aware of these conflicts,
they often resolve the conflicts by rerouting, which increases
Figure 3 presents the results of mission completion time,
their travel distance. This is particularly evident in FCG,
average travel distance per agent, and average workload per
where the agents do not abandon their assigned tasks even
agent for scenarios with 10, 30, and 50 agents over 100
upon detecting other agents heading to the same task. Hence,
episodes. These results are visualized using boxplots, with
shorter communication ranges result in increased average
varying communication ranges of 100, 200, and 300, and
distances due to more frequent rerouting.
for the algorithms GRAPE (blue), CBBA (orange), and FCG
(green). 3) Mission Completion Time: Figure 3(a)-(c) shows mis-
sion completion time. Interestingly, the impact of communi-
1) AverageWorkloadPerAgent: Figure3(a)-(c)visualizes
cation range on mission completion time varies by algorithm.
the average workload per agent for each scenario. Notably,
For CBBA and FCG, mission completion time decreases as
regardless of the number of agents, algorithm used, or
communication range increases. In CBBA, each agent only
communicationrange,theaverageworkloadperagentremains
needs to verify the convergence of its task bundle. Even if
consistent. This can be explained by the fixed number of
some other agents within the communication radius have not
tasks. Given that the task workload ranges between [6, 60]
yet converged on their bundles, conflicts are avoided as long
with a total of 400 tasks, the expected workload sum is
astheagentdoesnotpreferanyofthetasksselectedbythem.
approximately 13,200. Thus, with the fixed number of tasks,
For each agent, once its task bundle converges, it proceeds
increasing the number of agents leads to a decrease in
to execute the assigned tasks.
individual agent workload. Since all tasks must be completed
to conclude the mission, the average workload per agent However, in the case of GRAPE, since the partition
remains unaffected by variations in communication range or information itself must converge, even if other agents select
the choice of algorithm. taskswithoutconflict,thepartitioninformationisstillaffected,
resultinginFalseafterthedistributedmutexalgorithm.This
2) Average Travel Distance Per Agent: Figure 3(d)-(f)
effect extends the convergence time as the communication
illustrates the average travel distance per agent. As commu-
range widens.
nication range increases, the travel distance decreases for all
algorithms and scenarios. This effect is more noticeable with 4) ComparisonofCBBAandGRAPE: Theresultswith50
a higher number of agents. A shorter communication range agentshighlightthemostnotabletrends.CBBAwithr =300
c
leads to conflicts between agents that are not immediately achievesthebestmissioncompletiontime(Figure3(i)),while
aware of each other during local decision-making processes. GRAPE results in the shortest average distance (Figure 3(f)).These findings suggest that CBBA may be more suitable [11] R.Ghzouli,T.Berger,E.B.Johnsen,A.Wasowski,andS.Dragule,
for scenarios requiring faster completion, whereas GRAPE “BehaviorTreesandStateMachinesinRoboticsApplications,”IEEE
TransactionsonSoftwareEngineering,vol.49,no.9,pp.4243–4267,
could be advantageous for missions where minimizing travel
2023.
distance is critical. However, it is important to note that these [12] B.P.GerkeyandM.J.Mataric´,“AFormalAnalysisandTaxonomyof
outcomes are based on the specific settings of this study, and TaskAllocationinMulti-RobotSystems,”TheInternationalJournal
ofRoboticsResearch,vol.23,no.9,pp.939–954,2004.
therefore, should be interpreted with caution before making
[13] T.Erez,Y.Tassa,andE.Todorov,“Simulationtoolsformodel-based
broader generalizations. robotics:ComparisonofBullet,Havok,MuJoCo,ODEandPhysX,”
inIEEEInternationalConferenceonRoboticsandAutomation,2015,
VI. CONCLUSION pp.4397–4404.
[14] C.Pinciroli,V.Trianni,R.O’Grady,G.Pini,A.Brutschy,M.Brambilla,
In this study, we proposed SPACE, a Python-based simu- N.Mathews,E.Ferrante,G.DiCaro,F.Ducatelle,M.Birattari,L.M.
lator designed for MRTA research, and outlined the design Gambardella, and M. Dorigo, “ARGoS: a modular, parallel, multi-
enginesimulatorformulti-robotsystems,”SwarmIntelligence,vol.6,
philosophy and software architecture underlying its develop-
no.4,pp.271–295,2012.
ment. To demonstrate its practical utility, we implemented [15] W.Kang,E.Jeong,S.Shim,andS.Ha,“OptimizationofTaskAllo-
CBBAandGRAPEasdecision-makingpluginswithinSPACE cationforResource-ConstrainedSwarmRobots,”IEEETransactions
onAutomationScienceandEngineering,pp.1–18,2024.
and compared their performance across various metrics, par-
[16] R. Vaughan, “Massively multi-robot simulation in stage,” Swarm
ticularly in scenarios where tasks are dynamically introduced Intelligence,vol.2,no.2-4,pp.189–208,2008.
over time. This evaluation revealed distinct characteristics [17] E.Soria,F.Schiano,andD.Floreano,“SwarmLab:aMatlabDrone
SwarmSimulator,”inIEEE/RSJInternationalConferenceonIntelligent
of each algorithm, providing valuable insights into their
RobotsandSystems,2020,pp.8005–8011.
respective strengths and weaknesses. These findings highlight [18] H.Chakraa,F.Gue´rin,E.Leclercq,andD.Lefebvre,“Optimization
the usefulness of SPACE as a tool for conducting in-depth techniques for Multi-Robot Task Allocation problems: Review on
thestate-of-the-art,”RoboticsandAutonomousSystems,vol.168,p.
comparisons and analyses of different algorithms, thereby
104492,2023.
facilitating future research in MRTA. [19] N. Buckman, J. P. How, and H. L. Choi, “Partial replanning for
Forfuturework,weplantoenhanceSPACEbydeveloping decentralized dynamic task allocation,” AIAA Scitech 2019 Forum,
pp.1–11,2019.
a reinforcement learning interface that functions similarly
[20] K. S. Kim, H. Y. Kim, and H. L. Choi, “A Bid-Based Grouping
to the OpenAI Gym environment. This enhancement will MethodforCommunication-EfficientDecentralizedMulti-UAVTask
enable SPACE to support multi-agent reinforcement learning Allocation,”InternationalJournalofAeronauticalandSpaceSciences,
vol.21,no.1,pp.290–302,2020.
[27]specificallyfocusedonMRTAresearch.Additionally,we
[21] I. Jang, J. Jeong, H.-S. Shin, S. Kim, A. Tsourdos, and J. Suk,
aim to broaden the range of scenarios beyond the currently “CooperativeControlforaFlightArrayofUAVsandanApplicationin
implemented MT-SR scenario, including more complex RadarJamming,”IFAC-PapersOnLine,vol.50,no.1,pp.8011–8018,
2017.
scenarios such as delivery task allocation [28], where tasks
[22] J.Hu,P.Bhowmick,I.Jang,F.Arvin,andA.Lanzon,“ADecentralized
have constraints on starting and ending positions. Extending ClusterFormationContainmentFrameworkforMultirobotSystems,”
the behavior tree by adding behavior nodes for path planning IEEETransactionsonRobotics,vol.37,no.6,pp.1936–1955,dec
2021.
and control could be a valuable direction as well.
[23] G. Diehl and J. A. Adams, “GRAPE-S: Near Real-Time Coalition
FormationforMultipleServiceCollectives,”arXive-prints,pp.1–34,
REFERENCES oct2023.[Online].Available:http://arxiv.org/abs/2310.12480
[24] A. Dutta, V. Ufimtsev, T. Said, I. Jang, and R. Eggen, “Distributed
[1] G.Valentini,H.Hamann,andM.Dorigo,“Self-OrganizedCollective
Hedonic Coalition Formation for Multi-Robot Task Allocation,” in
Decision-Makingina100-RobotSwarm,”ProceedingsoftheAAAI
IEEEInternationalConferenceonAutomationScienceandEngineering,
ConferenceonArtificialIntelligence,vol.29,no.1,2015.
2021,pp.639–644.
[2] M.Dorigo,M.Birattari,andM.Brambilla,“Swarmrobotics,”Schol-
[25] L.Wang,T.Qiu,Z.Pu,J.Yi,J.Zhu,andW.Yuan,“HedonicCoalition
arpedia,p.1463,2014.
Formation for Distributed Task Allocation in Heterogeneous Multi-
[3] C.Caldero´n-Arce,J.C.Brenes-Torres,andR.Solis-Ortega,“Swarm
agent System,” International Journal of Control, Automation and
Robotics:Simulators,PlatformsandApplicationsReview,”Computa-
Systems,vol.22,no.4,pp.1212–1224,2024.
tion,vol.10,no.6,p.80,2022.
[26] S.Macenski,F.Martin,R.White,andJ.G.Clavero,“TheMarathon
[4] S.Chopra,G.Notarstefano,M.Rice,andM.Egerstedt,“ADistributed
2:ANavigationSystem,”inIEEE/RSJInternationalConferenceon
VersionoftheHungarianMethodforMultirobotAssignment,”IEEE
IntelligentRobotsandSystems,2020,pp.2718–2725.
TransactionsonRobotics,vol.33,no.4,pp.932–947,2017.
[27] S. Na, T. Roucˇek, J. Ulrich, J. Pikman, T. Krajn´ık, B. Lennox,
[5] H.-L.Choi,L.Brunet,andJ.How,“Consensus-BasedDecentralized
and F. Arvin, “Federated Reinforcement Learning for Collective
AuctionsforRobustTaskAllocation,”IEEETransactionsonRobotics,
NavigationofRoboticSwarms,”IEEETransactionsonCognitiveand
vol.25,no.4,pp.912–926,2009.
DevelopmentalSystems,vol.15,no.4,pp.2122–2131,2023.
[6] L. Johnson, S. Ponda, H.-L. Choi, and J. How, “Asynchronous
[28] Z.Chen,J.Alonso-Mora,X.Bai,D.D.Harabor,andP.J.Stuckey,
Decentralized Task Allocation for Dynamic Environments,” in In-
“IntegratedTaskAssignmentandPathPlanningforCapacitatedMulti-
fotech@Aerospace2011,2011,pp.1–12.
AgentPickupandDelivery,”IEEERoboticsandAutomationLetters,
[7] I. Jang, H. S. Shin, and A. Tsourdos, “Anonymous Hedonic Game
vol.6,no.3,pp.5816–5823,2021.
forTaskAllocationinaLarge-ScaleMultipleAgentSystem,”IEEE
TransactionsonRobotics,vol.34,no.6,pp.1534–1548,2018.
[8] S.Park,Y.D.Zhong,andN.E.Leonard,“Multi-RobotTaskAllocation
GamesinDynamicallyChangingEnvironments,”inIEEEInternational
ConferenceonRoboticsandAutomation,2021,pp.8678–8684.
[9] S.Choudhury,J.K.Gupta,M.J.Kochenderfer,D.Sadigh,andJ.Bohg,
“Dynamicmulti-robottaskallocationunderuncertaintyandtemporal
constraints,”AutonomousRobots,vol.46,no.1,pp.231–247,2022.
[10] M.ColledanchiseandL.Natale,“OntheImplementationofBehavior
Trees in Robotics,” IEEE Robotics and Automation Letters, vol. 6,
no.3,pp.5929–5936,2021.