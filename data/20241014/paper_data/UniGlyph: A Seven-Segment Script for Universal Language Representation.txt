UniGlyph: A Seven-Segment Script for
Universal Language Representation
Bency Sherin, G. V.
Department of Electronics and Communication Engineering, St. Xavier's Catholic College of Engineering,
Chunkankadai, Tamil Nadu 629003, India.
Abijesh Euphrine, A.
Deen Dayal Upadhyay Centre, Loyola College, Affiliated to University of Madras, Chennai, Tamil Nadu 600034, India.
Lenora Moreen, A.
Bell Matriculation Higher Secondary School, Palayamkottai, Tamil Nadu 627002, India.
Arun Jose, L.*
Department of Physics, St. Xavier’s College, affiliated to Manonmaniyam Sundaranar University, Palayamkottai, Tamil
Nadu 627002, India., arunjose@stxavierstn.edu.in
UniGlyph represents a groundbreaking venture into the realm of constructed languages (conlangs), aiming to establish a universal
transliteration system using a script derived from seven-segment characters. Its core objective is to foster cross-language communication
through the provision of a flexible and standardized script capable of accurately representing a broad spectrum of phonetic sounds. This
innovative system addresses the imperfections of the International Phonetic Alphabet (IPA) and the limitations of traditional character
sets by offering a compact and versatile method to represent phonetic diversity across languages. This paper delves into the intricate design
of UniGlyph, delineating its script structure, phonetic mapping, and transliteration rules. The essence of UniGlyph lies in its unique design,
characterized by a succinct character set augmented with markers for pitch and length variations. This streamlined script facilitates
efficient representation of phonetic elements, enabling seamless transliteration from diverse languages into a cohesive script. The
discussion also encompasses the challenges inherent in crafting a universal script and elucidates the guiding principles governing the
transliteration process. By exploring various applications and use cases, from multilingual messaging to enhance artificial intelligence
systems by providing a consistent and precise method for phonetic transcription, including future expansion possibilities such as the
assignment of new scripts to previously unrepresented phonetic sounds and the potential for encoding animal phonetic communication.
Each species could be assigned a distinct script followed by a specific number, allowing for the study and documentation of non-human
vocal patterns. Through its innovative design and adaptability, UniGlyph presents a promising tool for bridging linguistic gaps and
enhancing both human and non-human communication thereby improving language processing capabilities, the paper underscores the
versatility and adaptability of UniGlyph. This system has the potential to revolutionize cross-language communication, offering an
innovative solution to bridge linguistic divides. UniGlyph’s robust transliteration system, coupled with its compact and versatile script
design, presents a promising avenue for fostering a more interconnected world.
CCS CONCEPTS • Computing methodologies → Natural language processing • Information systems → Cross-language
information retrieval • Artificial intelligence → Speech recognition • Applied computing → Education technologies •
* Corresponding Author and all authors contributed equally to this research.Human-centered computing → Multilingual interaction • Linguistic analysis • Symbolic and algebraic manipulation →
Representations
Additional Keywords and Phrases: Constructed Language, Conlang, Transliteration System, Seven-Segment Script,
Universal Script, Cross Language Communication, Phonetic Mapping, Script Design, Language Bridging, Phonetics,
Universal Transliteration, Symbolic Representation.
1 INTRODUCTION
Language has evolved significantly over millennia, reflecting the complex interplay between human communication
needs and technological advancements [49]. From the intricate pictographs of ancient civilizations to the sophisticated
scripts of today, writing systems have continually adapted to better capture and convey the nuances of spoken language [8,
41, 122]. The development of UniGlyph, a constructed language (conlang) featuring a seven-segment script for universal
language representation, represents a modern effort to address the limitations of traditional writing systems and enhance
cross-language communication [88].
1.1 Evolution of Writing Systems
The earliest forms of writing, such as cuneiform in Mesopotamia and hieroglyphs in Egypt, were characterized by their
complexity and exclusivity. These scripts, comprised of intricate symbols and pictographs, were used primarily for
administrative and ceremonial purposes and required specialized knowledge to interpret [39, 62, 113, 123]. This
complexity limited literacy to a small group of scribes and scholars, creating a significant barrier to widespread
communication and knowledge dissemination. As societies expanded and communication needs grew more diverse, the
limitations of early writing systems became apparent [20]. The transition to more abstract and standardized scripts, such
as the Phoenician alphabet around 1200 BCE, marked a significant advancement [41]. This alphabetic system simplified
writing by using a limited set of symbols to represent sounds, making literacy more accessible and facilitating trade and
cultural exchange [34, 40, 100, 102]. The Greek and Latin alphabets, derived from the Phoenician script, further
standardized writing and played crucial roles in the development of Western languages [92]. The invention of the printing
press by Johannes Gutenberg in the 15th century revolutionized writing by enabling the mass production of texts. This
technological breakthrough significantly increased the availability of written materials, leading to higher literacy rates and
the rapid spread of knowledge and ideas during the Renaissance [35, 92]. Despite these advancements, the complexity of
accurately representing phonetic nuances in written form persisted [43].
1.2 Modern Challenges in Phonetic Representation
In contemporary times, the diversity of spoken languages and their phonetic complexities present significant challenges
for transcription and digital communication [7, 10, 90, 95]. Traditional writing systems often struggle to capture the full
range of phonetic sounds in languages, leading to inconsistencies and misunderstandings in transliteration [37, 93]. The
International Phonetic Alphabet (IPA), developed to provide a standardized system for representing the sounds of spoken
language, has been a critical tool in addressing these challenges [69, 71]. However, the IPA is not without its imperfections
[14, 71, 105]. While it offers a comprehensive framework for phonetic transcription, its extensive set of symbols can be
daunting for non-specialists to learn and use. Moreover, the IPA's typographic complexity poses challenges in digital
representation, particularly on platforms with limited font support [13, 94]. These issues underscore the need for a simpler,
more intuitive script that can effectively represent phonetic diversity across languages [17, 36, 78, 114].
21.3 The Need for a Simplified Script
The rise of digital technology and globalization has intensified the demand for efficient and versatile systems for cross-
language communication [105]. In a world where individuals increasingly interact across linguistic boundaries, the ability
to accurately represent and transmit diverse phonetic sounds is crucial [18, 21, 81, 103, 106, 119]. Traditional writing
systems and the IPA, while valuable, often fall short in meeting these needs due to their complexity and limitations [60].
UniGlyph addresses these challenges by introducing a novel seven-segment script designed for universal phonetic
representation [68]. Drawing inspiration from the geometric clarity and simplicity of seven-segment displays commonly
used in digital devices, UniGlyph offers a compact and versatile method for capturing phonetic elements [12, 14, 15, 54,
88, 91]. This script, constructed from a combination of seven segments, provides a minimal yet sufficiently diverse
character set that can be easily rendered on digital platforms.
1.4 Design Principles of UniGlyph
The design of UniGlyph focuses on creating a universal script that can accommodate the phonetic diversity of multiple
languages. The script's structure includes representations for consonants, vowels, length variations, and pitch variations.
By distinguishing between continuous and non-continuous consonants, UniGlyph captures the phonetic properties of
sounds more accurately [99]. Continuous consonants, such as O {s} (s) and m {m} (m) (The script written inside the curly
brackets ‘{ }’ follows the ISO 15919 standard – Transliteration of Devanagari and related Indic scripts into Latin characters
[1, 5, 6], while the text inside the normal brackets ‘( )’ represents the International Phonetic Alphabet [124]), can be
sustained without altering their phonetic quality, while non-continuous consonants, such as q {t) (t) and k {k} (k), are
characterized by brief, explosive sounds [25, 63, 68, 77, 124, 125]. Vowels in UniGlyph are represented using distinct
segment combinations that reflect their phonetic characteristics. The script includes mechanisms for indicating short and
long variations of sounds, enabling precise representation of phonetic length. Additionally, pitch variations are
incorporated to allow the transcription of tonal languages, where pitch plays a crucial role in distinguishing meaning [23,
27].
1.5 Addressing IPA Imperfections
UniGlyph's design addresses several key imperfections of the IPA. The IPA's extensive symbol set, while
comprehensive, can be difficult to master and use, particularly for individuals without linguistic training [16, 42, 58, 71].
while useful for representing the sounds of spoken languages, has some limitations. It provides limited coverage for
important linguistic elements like tone, stress, and prosody. Additionally, mastering the IPA requires significant effort due
to the complexity and number of specialized symbols, making it challenging for casual users [52, 79]. There is also
inconsistency in its application, with different linguists and publications sometimes using varying conventions.
Technological challenges further complicate its use, as inputting and displaying IPA symbols can be cumbersome on
platforms without native support [53, 64, 82]. Moreover, the IPA transcription often differs from a language's standard
orthography, creating difficulties for language learners in connecting written and spoken forms. UniGlyph simplifies
phonetic representation by using a smaller, more intuitive set of characters, making it accessible to a broader audience [98].
The geometric clarity of UniGlyph's seven-segment characters ensures they are well-suited for digital representation,
overcoming the typographic limitations associated with the IPA [26, 72, 126]. Moreover, UniGlyph's adaptability allows
it to accommodate new pronunciation characters as linguistic needs evolve. This flexibility ensures that UniGlyph remains
relevant and useful in the face of ongoing linguistic developments, providing a robust framework for future enhancements
3[14]. This adaptability positions UniGlyph as a versatile tool for phonetic transcription in a rapidly changing linguistic
landscape.
1.6 Conclusion
UniGlyph represents a significant step forward in the quest for a universal language representation system. By
simplifying the transcription of phonetic sounds while allowing for expansion and flexibility, it provides a practical solution
to the challenges posed by cross-language communication and linguistic diversity. The potential for integrating animal
phonetic systems into this framework further expands its relevance, making it a tool that could benefit not just human
communication but the broader understanding of communication as a biological phenomenon. As AI continues to shape
the future of communication, a system like UniGlyph, which bridges linguistic gaps and accommodates a wide range of
phonetic systems, will be crucial in creating a more interconnected and understanding world.
2 BACKGROUND AND MOTIVATION
The evolution of language and its representation has always been central to the development of human civilization.
From the earliest forms of writing, such as cuneiform and hieroglyphics, to modern alphabets and phonetic scripts, the
representation of speech sounds has been a challenge that societies have continuously sought to address. In ancient times,
written communication was complex and accessible to only a few, as it required mastering intricate symbols, often
numbering in the thousands. As languages and societies evolved, so did the need for simplified, yet comprehensive writing
systems that could accurately represent the wide array of sounds produced in human speech. Modern scripts like the
Roman, Cyrillic, and Devanagari alphabets have addressed this need to varying degrees, each tailored to specific linguistic
families.
However, the increasing interconnectedness of the world in the 21st century has exposed the limitations of traditional
scripts and phonetic systems. As global communication becomes more integral to commerce, science, education, and
diplomacy, the demand for a universal script capable of representing diverse languages has become apparent. The
International Phonetic Alphabet (IPA) was a groundbreaking attempt to create such a system, offering a standardized way
to represent phonetic sounds across languages. Yet, despite its comprehensive design, the IPA remains a complex and
difficult-to-master system, particularly for non-linguists. Furthermore, the IPA’s rigid structure does not easily
accommodate the dynamic nature of language evolution, nor does it adequately address the phonetic needs of tonal
languages or dialects with continuous and non-continuous consonant distinctions [65].
These limitations have given rise to the development of UniGlyph, a seven-segment-based script designed to provide a
more flexible and versatile solution for representing the phonetic diversity of human languages. UniGlyph builds upon the
concept of using a compact character set, much like the digital displays used in calculators and electronic devices, to
represent phonetic elements in a visually efficient way. The need for such a system has been driven by several factors,
including the shortcomings of the IPA and traditional character sets in representing a wide range of phonetic sounds,
particularly for tonal languages and languages with unique consonant structures [48].
2.1 The Challenge of Limited Character Sets
The evolution of human language has brought about an incredible diversity of spoken sounds, each carrying unique
phonetic characteristics that can be challenging to capture in written form [2, 19, 21, 66, 70, 76, 79, 79, 81, 86, 89].
Traditional character sets, while functional, often fall short in representing the full range of phonetic nuances present in
different languages [16, 18, 21, 97, 105, 107, 127]. The Roman alphabet, for instance, is widely used but lacks the flexibility
4to accommodate the vast phonetic diversity of global languages without additional diacritical marks or modifications [16,
31, 52, 74, 84, 112, 112, 119]. One of the significant challenges in linguistic representation is the need for a universal
system that can accurately and consistently capture these phonetic elements. Existing systems like the International
Phonetic Alphabet (IPA) aim to address this issue by providing a comprehensive set of symbols designed to represent all
the sounds of spoken languages. However, the complexity and extensive nature of the IPA can make it inaccessible to non-
specialists and challenging to implement in digital formats. This complexity often leads to inconsistencies and errors in
transcription, hindering effective cross-language communication.
2.2 Why Seven-Segment Characters?
The idea of using seven-segment characters for language representation stems from their simplicity and widespread
recognition in digital displays. Seven-segment displays, commonly found in digital clocks, calculators, and other electronic
devices, use a combination of seven segments to form numeric and some alphabetic characters [11, 96, 104, 109]. This
geometric simplicity ensures that the characters are easily recognizable and can be rendered across various digital platforms
without losing clarity. By adopting a seven-segment script, UniGlyph leverages this simplicity to create a compact and
versatile method for representing phonetic diversity. Each character in UniGlyph is constructed from a combination of
seven segments, allowing for a limited but sufficient character set that can capture essential phonetic elements. This design
not only simplifies the learning process but also ensures that the script is easily translatable to digital formats, addressing
the typographic challenges faced by more complex systems like the IPA.
2.3 Complexity in Writing: Ancient and Modern Contexts
Throughout history, the complexity of writing systems has been a significant barrier to literacy and effective
communication [59, 87]. In ancient times, scripts like cuneiform and hieroglyphs were intricate and required specialized
knowledge to interpret [20, 28, 32, 50, 61, 85, 113, 128]. These scripts served administrative and ceremonial purposes but
were inaccessible to the general populace, limiting their utility for widespread communication. As languages evolved, there
was a clear need for simpler and more standardized scripts. The development of alphabets like the Phoenician, Greek, and
Latin scripts marked a pivotal shift towards more accessible writing systems. These alphabets reduced the complexity of
writing by using a limited set of symbols to represent sounds, paving the way for broader literacy and more efficient
communication [8, 24, 30, 44, 51, 80, 129]. However, even these advancements could not fully capture the phonetic
richness of spoken languages, leading to the continued evolution of writing systems. In the modern era, the advent of digital
technology has further highlighted the need for simple and versatile scripts. Digital communication requires scripts that
can be easily rendered on various devices and platforms. Traditional character sets, while functional in print, often struggle
to maintain clarity and consistency in digital formats. This has driven the search for innovative solutions like UniGlyph,
which can bridge the gap between phonetic accuracy and digital efficiency.
2.4 Imperfections in the International Phonetic Alphabet (IPA)
IPA is a standardized system for phonetic transcription that has been widely adopted by linguists and language
educators. The IPA provides a comprehensive set of symbols designed to represent the sounds of all spoken languages,
offering a valuable tool for phonetic analysis and language learning. However, the IPA's extensive symbol set and
typographic complexity present significant challenges. Firstly, the IPA's complexity can be daunting for non-specialists to
learn and use. The sheer number of symbols and their intricate designs require a high level of familiarity and expertise,
making the IPA less accessible to the general public. This complexity can lead to inconsistencies in transcription and
5difficulties in accurately representing phonetic elements, especially in multilingual contexts. Secondly, the IPA's
typographic nature poses challenges in digital representation. Many digital platforms and devices have limited support for
IPA symbols, leading to rendering issues and loss of phonetic detail. These limitations hinder the effective use of the IPA
in digital communication, where clarity and consistency are paramount. UniGlyph addresses these imperfections by
offering a simplified and intuitive script that retains phonetic accuracy. The seven-segment design ensures that characters
are easily recognizable and digitally translatable, overcoming the typographic challenges associated with the IPA. By
providing a more accessible and versatile system, UniGlyph enhances the representation of phonetic diversity across
languages.
2.5 Versatility for Future Adaptations
One of the key strengths of UniGlyph is its adaptability. While the initial character set is designed to capture a broad
range of phonetic elements, the system is versatile enough to accommodate new pronunciation characters as linguistic
needs evolve. This adaptability ensures that UniGlyph remains relevant and useful in the face of ongoing changes in
language and phonetics. Linguistic evolution is a constant process, driven by cultural exchange, technological
advancements, and changes in communication practices. New sounds and phonetic variations emerge, requiring updates
to existing transcription systems. UniGlyph's modular design allows for the seamless integration of new characters and
symbols, ensuring that the script can evolve alongside language. This adaptability is crucial for the long-term success of a
universal transliteration system. By providing a flexible framework, UniGlyph can continue to meet the needs of diverse
linguistic communities and contribute to more effective cross-language communication. This versatility positions
UniGlyph as a forward-looking solution that can accommodate future developments in phonetics and linguistics.
2.6 Potential application in artificial intelligence
Another key motivation for UniGlyph's development is its potential application in artificial intelligence (AI) [67, 88,
101, 116, 118, 119]. In recent years, AI has made significant strides in areas such as speech recognition, natural language
processing (NLP), and machine translation. However, these technologies often struggle with the variability and complexity
of human language, particularly when dealing with multiple languages or dialects. The ability to accurately transcribe and
analyze phonetic data is crucial for improving the performance of AI systems in these areas. UniGlyph offers a solution by
providing a standardized, consistent method for representing phonetic sounds across different languages. This consistency
can help reduce errors in AI-driven language processing, leading to more reliable and effective applications. For example,
in speech recognition systems, UniGlyph can be used to improve the accuracy of phonetic transcription, ensuring that the
AI correctly interprets and processes spoken input. Similarly, in machine translation, UniGlyph can facilitate more accurate
transliteration of source texts, reducing the risk of mistranslation and improving the overall quality of the output.
Furthermore, UniGlyph's design allows for future adaptability. As languages continue to evolve and new sounds emerge,
the system can be expanded to include additional characters, ensuring that it remains relevant and useful in the face of
linguistic change. This adaptability is particularly important in the context of AI, where the ability to quickly incorporate
new linguistic data is essential for keeping pace with the rapid development of language technologies.
2.7 Expanding UniGlyph to Non-Human Communication
Another exciting frontier for UniGlyph lies in its potential application to the study and representation of animal phonetic
systems. While the current focus of UniGlyph is on human languages, future research may extend its scope to include the
structured sound systems used by certain animal species. Animal communication, particularly in species such as dolphins,
6birds, and primates, has been shown to exhibit complex patterns of vocalization that share similarities with human
phonetics [121]. These sound systems, though not as linguistically structured as human languages, nonetheless follow
recognizable patterns of pitch, duration, and tonal variation. UniGlyph’s adaptability makes it well-suited to the task of
representing these animal phonetic systems in a systematic and standardized way. As researchers in bioacoustics and
animal communication continue to explore the intricacies of non-human vocalization, UniGlyph could offer a framework
for transcribing and analyzing these sounds, much as the IPA does for human languages. By expanding its utility beyond
human communication, UniGlyph could become a valuable tool in the fields of animal behavior research and interspecies
communication, further broadening its impact.
2.8 Conclusion
The development of UniGlyph is motivated by the need for a simplified and versatile script that can accurately represent
phonetic diversity across languages. Traditional writing systems and the IPA, while valuable, face significant challenges
in terms of complexity, accessibility, and digital representation. UniGlyph addresses these issues by leveraging the
geometric simplicity of seven-segment characters to create a compact and efficient phonetic script. By distinguishing
between continuous and non-continuous consonants and incorporating mechanisms for pitch and length variations,
UniGlyph ensures accurate phonetic representation. Its adaptability allows for the inclusion of new pronunciation
characters as linguistic needs evolve, making it a versatile tool for phonetic transcription. In a world where cross-language
communication is increasingly important, UniGlyph offers a promising solution for bridging linguistic gaps. Its innovative
design and robust transliteration system enhance the representation of phonetic elements, contributing to a more
interconnected and linguistically diverse global community. Its application in AI, in particular, highlights the system's
potential to improve the accuracy and effectiveness of language processing technologies, making it a valuable tool for the
future of communication.
3 SCRIPT DESIGN
UniGlyph is designed with simplicity and versatility in mind, making it an ideal foundation for a universal script
applicable to a wide range of uses, including artificial intelligence (AI) systems. The goal is to create a universal
transliteration system that accurately represents the phonetic diversity of languages. The script utilizes seven-segment
characters, offering a unique and efficient approach through their geometric simplicity. This section explores the different
components of the UniGlyph script, including the character set, consonants, vowels, variations in sound length and pitch,
and other key considerations.
3.1 Character Set
The core of UniGlyph's design lies in its limited yet comprehensive character set. Each character is constructed from a
combination of seven segments, similar to those used in digital displays. This geometric simplicity of the seven-segment
model ensures that UniGlyph can be rendered on any device that supports basic digital display technology, from low-
resolution screens to advanced AI-driven interfaces. This adaptability makes UniGlyph a versatile tool for both human and
machine use, enabling seamless communication across different languages and platforms. The character set includes
symbols for consonants, vowels, and markers for variations in sound length and pitch.
3.2 The use of seven-segment characters offers several advantages
• Simplicity: The limited number of segments ensures that characters remain simple and easy to learn.
7• Consistency: The geometric design allows for consistent rendering on various devices and platforms.
• Versatility: Despite the limited number of segments, the character set is versatile enough to represent a wide
range of phonetic sounds.
3.3 Consonants
UniGlyph includes a set of consonant characters designed to capture the essential phonetic features of consonants across
different languages. The consonant characters are divided into two categories: continuous and non-continuous consonants.
• Continuous Consonants: These consonants, such as nasals and fricatives, involve a continuous airflow through
the vocal tract [22, 130]. Examples include {m} (m), {n} (n), and {s} (s) (The script written inside the curly
brackets ‘{ }’ follows the ISO 15919 standard – Transliteration of Devanagari and related Indic scripts into Latin
characters [1], while the text inside the normal brackets ‘( )’ represents the International Phonetic Alphabet
[124]). Continuous consonants in UniGlyph are represented by characters that include specific segments
indicating continuous phonation.
• Non-Continuous Consonants: These consonants, such as plosives and stops, involve a complete closure and
release of airflow. Examples include {p} (p), {t} (t), and {k} (k). non-continuous consonants are represented
by characters with different segment combinations to distinguish them from continuous consonants.
Each consonant character in UniGlyph is mapped to its corresponding sound in various languages, ensuring accurate
phonetic representation. This mapping takes into account the International Phonetic Alphabet (IPA) and other standard
transliteration systems to maintain consistency and accuracy. In the UniGlyph script, consonants are represented by specific
configurations of the seven segments. Each configuration corresponds to a distinct consonant sound, with continuous
consonants (those that can be sustained) being distinguished from non-continuous consonants (those that cannot be
sustained) by their unique segment patterns. This distinction is crucial for accurate phonetic representation and is
particularly relevant in AI applications, where precise differentiation between sounds can improve the accuracy of speech
recognition and natural language processing (NLP) systems. By providing a clear and consistent method for representing
consonants, UniGlyph enhances the ability of AI systems to process and interpret spoken language as shown in Error!
Reference source not found.. This is especially important in multilingual contexts, where the accurate identification of
consonant sounds can significantly impact the performance of AI-driven language models.
Table 1: Detailed mapping of Consonants in UniGlyph
Language Indic ISO 15919 International phonetic Continuous Proposed seven Assigned keyboard
origin script transliteration alphabet consonants segment displays character
Tamil க் k k, ɡ, x, ɣ, h, ŋ No k
Tamil ங் ṅ ŋ Yes A
Tamil ச ் c ͡tʃ, d͡ʒ, ʃ, s, ʒ No c
Tamil ஞ் ñ ɲ Yes E
Tamil ட் ṭ ʈ, ɖ, ɽ No x
Tamil ண் ṇ ɳ Yes C
Tamil த் t t̪, d̪, ð No q
Tamil ந் n n Yes y
Tamil ப் p p, b, β No p
Tamil ம் m m Yes m
Tamil ர ் r ɾ Yes s
Tamil ல் l l Yes l
Tamil வ் v ʋ No r
8Language Indic ISO 15919 International phonetic Continuous Proposed seven Assigned keyboard
origin script transliteration alphabet consonants segment displays character
Tamil ழ் ḻ ɻ Yes w
Tamil ள் ḷ ɭ Yes I
Tamil ற் t t, d No N
Tamil ன் ṉ n Yes S
Tamil ஜ் j d͡ʒ No j
Grantha
Tamil ஶ் ś ɕ, ʃ Yes H
Grantha
Tamil ஷ் ṣ ʂ Yes v
Grantha
Tamil ஸ் s s Yes O
Grantha
Tamil ஹ் h h No T
Grantha
Devanagari ग् g ɡ No g
Devanagari ड् ḍ ɖ No R
Devanagari द् d ð No d
Devanagari ब् b b No b
Devanagari ज् z z Yes z
Devanagari झ ् zh ʒ Yes D
Devanagari फ् f f Yes f
3.4 Vowels
Vowels in UniGlyph are similarly represented by unique seven-segment configurations, each corresponding to a
specific vowel sound. The script includes provisions for both short and long vowel variations, ensuring that the nuances of
vowel length are accurately captured. This is essential for maintaining the integrity of phonetic transcription, particularly
in languages where vowel length can alter the meaning of words [3, 4, 9, 38]. The accurate representation of vowels is
critical for AI applications such as text-to-speech (TTS) systems, where vowel length and pitch variations must be correctly
interpreted to produce natural-sounding speech. UniGlyph's design allows for these variations to be encoded in a simple
and consistent manner, reducing the potential for errors in AI-driven language processing as shown in Error! Reference
source not found..
Table 2: Detailed mapping of Vowels in UniGlyph
Language Indic ISO 15919 International phonetic Proposed seven segment Assigned keyboard
origin script transliteration alphabet displays character
Russian ɨ i
English ɛ n
Tamil அ a ʌ a
Tamil இ i i e
Tamil எ e e t
Tamil உ u u, ɯ u
Tamil ஒ o o o
93.5 Short and Long Variations
UniGlyph incorporates markers for variations in sound length, distinguishing between short, long, very short, and very
long sounds. These markers are essential for accurate phonetic representation, as the length of a sound can significantly
affect its meaning in many languages. In AI-driven language models, the ability to recognize and process these variations
can lead to more accurate speech recognition and synthesis, improving the overall quality of AI-based communication
systems as shown in Error! Reference source not found.. For example, in languages like Japanese, where vowel length
can change the meaning of a word, UniGlyph's markers for short and long variations can help AI systems correctly interpret
and translate spoken input [57, 73, 110].
• Short Sounds: Represented by a base character followed by a specific marker indicating short duration.
• Long Sounds: Represented by the base character followed by a different marker indicating longer duration.
• Very Short and Very Long Sounds: Additional markers are used to indicate very short or very long durations,
ensuring precise phonetic transcription.
Table 3: Detailed mapping of Short and Prolong Variations of Sound in UniGlyph
Short and long variations Proposed seven segment displays Assigned keyboard character
Shot
Long
Example for Shot
Example for Very Shot
Example for Long
Example for Very Long
Example for Prolong width defined number
3.6 Examples of sound length variations in UniGlyph
Short: a represented by a specific segment combination.
• Long: represented by the base segment combination followed by a length marker.
• Very Short: represented by the base segment combination followed by a very short marker.
• Very Long: represented by the base segment combination followed by a very long marker.
3.7 Pitch Variation
Pitch variation is another critical aspect of phonetic representation in UniGlyph. Pitch can convey different meanings
and nuances in many languages, especially tonal languages [45, 55]. UniGlyph includes markers for different pitch levels,
ensuring accurate transcription of pitch variations which are essential for conveying meaning in tonal languages such as
Mandarin or Thai. The ability to encode pitch variations directly into the script is a significant advantage for AI
applications, where the correct interpretation of pitch is critical for accurate speech recognition and synthesis as shown in
Error! Reference source not found.. In AI-based translation and communication systems, pitch variations play a crucial
role in ensuring that the intended meaning of a speaker is accurately conveyed. UniGlyph's design allows these pitch
variations to be seamlessly integrated into the transliteration process, providing a robust framework for AI systems to
process tonal languages effectively.
• Normal Pitch: Represented by the base character without any additional markers.
• High Pitch: Represented by the base character followed by a marker indicating high pitch.
• Low Pitch: Represented by the base character followed by a marker indicating low pitch.
10• Very High and Very Low Pitch: Additional markers are used to indicate very high or very low pitch levels.
Table 4: Detailed mapping of Pitch Variations of Sound in UniGlyph
Pitch variations Proposed seven segment displays Assigned keyboard character
Very Very High Pitch Z
Very High Pitch Y
High Pitch X
Normal Pitch Q
Low Pitch U
Very Low Pitch V
Very Very Low Pitch W
3.8 Examples of pitch variation in UniGlyph
• Normal Pitch: Q represented by a specific segment combination.
• High Pitch: X represented by the base segment combination followed by a high pitch marker.
• Low Pitch: U represented by the base segment combination followed by a low pitch marker.
• Very High Pitch: Y represented by the base segment combination followed by a very high pitch marker.
• Very Low Pitch: V represented by the base segment combination followed by a very low pitch marker.
4 ADDITIONAL CONSIDERATIONS
While UniGlyph presents significant advancements in the realm of phonetic transcription and language representation,
there are several additional considerations that merit attention as we look toward its broader implementation and future
development. These considerations involve challenges in standardization, the complexities of integrating UniGlyph into
current linguistic and technological frameworks, potential ethical concerns, and the role of interdisciplinary research in
ensuring the system’s long-term success.
4.1 Standardization and Global Adoption
A major challenge for any new linguistic system is the process of achieving widespread standardization and acceptance.
For UniGlyph to succeed as a universal script, it must be adopted by linguists, technologists, educators, and policymakers
worldwide. This would require extensive collaboration across different sectors and regions to ensure that the system meets
the needs of diverse linguistic communities. Unlike the International Phonetic Alphabet (IPA), which has had more than a
century to establish itself, UniGlyph would need a coordinated effort to gain traction, especially among communities
unfamiliar with its underlying principles. Standardization efforts must also consider the potential need for regulatory
frameworks that oversee the integration of UniGlyph into educational materials, translation tools, and AI platforms.
International linguistic bodies such as the International Phonetic Association, the United Nations Educational, Scientific
and Cultural Organization (UNESCO), and global technology leaders may play pivotal roles in this process. The
collaborative effort needed to integrate UniGlyph into these domains will be a critical step toward achieving its goal of
becoming a truly universal script.
4.2 Integration with Existing Linguistic Systems
The practical integration of UniGlyph into existing linguistic systems raises important considerations regarding
compatibility and co-existence with current writing systems and phonetic transcriptions. While UniGlyph offers a
11streamlined and compact system, its design must accommodate languages with complex phonetic structures, including
those with unique tonal variations, intricate consonant clusters, and grammatical structures that differ significantly from
English or other Indo-European languages. Additionally, successful implementation will depend on the system's ability to
coexist with widely used scripts, such as Latin, Cyrillic, Arabic, and Chinese characters. These scripts are deeply ingrained
in the cultural and historical identities of various communities, and any attempt to introduce a universal script must be
sensitive to the linguistic heritage of these groups. Ensuring that UniGlyph can be used in conjunction with traditional
writing systems, rather than replacing them, will be key to its acceptance.
4.3 Ethical Considerations in Language Standardization
The introduction of any universal system, particularly one related to language, raises important ethical considerations.
Language is a key component of cultural identity, and the imposition of a standardized system could be viewed by some
communities as a form of linguistic imperialism. While UniGlyph is designed to enhance communication and foster
understanding across linguistic barriers, its implementation must be carried out in a way that respects the autonomy and
linguistic diversity of all communities. The risk of marginalizing lesser-known languages or dialects by prioritizing certain
phonetic structures over others must be carefully addressed in the development and promotion of UniGlyph. Moreover,
the application of UniGlyph in AI-driven systems introduces concerns related to data privacy, bias, and the potential for
misuse in areas such as surveillance or manipulation of information. As AI continues to evolve, ensuring that linguistic
data is used ethically and responsibly will be paramount to maintaining public trust in technologies that rely on systems
like UniGlyph.
4.4 Future Expansion: Non-Human Communication
As mentioned earlier, UniGlyph has the potential to extend beyond human phonetic systems into the realm of animal
communication. Research in bioacoustics and animal behavior has revealed that many species, including cetaceans
(dolphins and whales), birds, and primates, possess complex vocalization systems that may one day be transcribed using a
version of UniGlyph. This expansion of the system could revolutionize how we study animal communication, potentially
leading to new insights into the cognitive abilities and social structures of non-human species. However, this expansion
will require further development of the UniGlyph script to accommodate the unique sound patterns and frequencies
observed in animal vocalizations. Unlike human languages, animal sounds often involve frequencies and patterns beyond
the typical range of human hearing or speech, which presents new challenges in terms of phonetic transcription.
Nevertheless, this remains an exciting frontier for future research, and the successful adaptation of UniGlyph for animal
communication could open up entirely new fields of study.
For human communication, the expansion will involve assigning new scripts to phonetic sounds that have not yet been
represented. As language evolves and new phonetic variations emerge across different dialects and linguistic contexts,
UniGlyph's adaptable framework allows for the seamless inclusion of these sounds. By assigning specific glyphs to newly
identified phonetic elements, the system can evolve in tandem with linguistic changes, ensuring that it remains relevant
and comprehensive in representing human speech.
For non-human communication, UniGlyph envisions an exciting opportunity to document and encode animal phonetics.
Each species exhibits distinct vocal patterns and sounds that could be assigned unique scripts. This will involve assigning
a new script for each species, followed by a distinct number to represent that particular species. For example, birds,
dolphins, or other vocal animals could have their unique glyph systems, with numbers indicating species differentiation.
12This expansion would not only create a comprehensive phonetic database but could also be an invaluable tool for studying
animal communication and cross-species interaction.
4.5 Challenges in AI Integration
While UniGlyph offers promising applications for artificial intelligence, particularly in speech recognition and natural
language processing, its integration into existing AI frameworks presents some technical challenges. Current AI models,
particularly those based on machine learning and neural networks, are often trained using large datasets that rely on existing
phonetic systems such as the IPA. Transitioning these models to UniGlyph would require retraining on new datasets that
accurately represent phonetic sounds using the UniGlyph system. Furthermore, the success of AI applications in translation
and speech recognition depends heavily on the quality and consistency of the data used to train these systems. Ensuring
that UniGlyph can provide the necessary accuracy and comprehensiveness across different languages, dialects, and accents
will be crucial to its effectiveness in AI applications. Collaborations between linguists, computer scientists, and AI
developers will be essential to overcoming these challenges.
4.6 Interdisciplinary Collaboration and Research
The development of UniGlyph is an inherently interdisciplinary endeavor, requiring expertise from fields as diverse as
linguistics, computer science, education, artificial intelligence, and cognitive psychology. This collaboration is essential to
ensure that the system meets both linguistic and technological requirements, while also being user-friendly and accessible
to a broad audience. Future research into the applications of UniGlyph should explore how it can be optimized for different
linguistic contexts, as well as its potential for integration into educational systems and digital communication platforms.
Additionally, cognitive studies on the learning and usage of UniGlyph could provide valuable insights into how the human
brain processes new scripts and phonetic systems. Understanding the cognitive load associated with learning UniGlyph,
particularly for users with no prior experience in phonetics, will be an important consideration in determining the system’s
long-term viability.
4.7 Conclusion
In summary, while UniGlyph presents a groundbreaking solution for phonetic representation across languages, several
additional considerations must be taken into account to ensure its successful implementation and future development.
These include challenges related to standardization, ethical concerns, and technical integration, as well as exciting
opportunities for expansion into non-human communication and AI-driven applications. By addressing these
considerations through interdisciplinary collaboration and ongoing research, UniGlyph has the potential to revolutionize
global communication and foster greater understanding across linguistic and cultural boundaries.
5 PHONETIC MAPPING AND TRANSLITERATION RULES
The core of UniGlyph lies in its ability to accurately map phonetic sounds to a simplified and universally recognizable
script. This process, known as phonetic mapping, is crucial for ensuring that UniGlyph can be used to represent the diverse
range of sounds found in the world's languages. Transliteration, the process of converting text from one script to another
while preserving pronunciation, is guided by a set of rules designed to maintain phonetic accuracy across different
languages.
135.1 Phonetic Mapping
Phonetic mapping in UniGlyph is based on the precise identification of sounds, or phonemes, in a language and their
corresponding representation using the seven-segment script. Each segment configuration in UniGlyph corresponds to a
specific sound, ensuring that the script can faithfully represent the phonetic structure of any language. The simplicity of
the seven-segment design allows for a direct and efficient mapping process, reducing the potential for ambiguity in
pronunciation. In the context of artificial intelligence, accurate phonetic mapping is critical for applications such as speech
recognition and natural language processing (NLP). AI systems rely on precise phonetic representations to correctly
interpret spoken language and convert it into text. By providing a clear and consistent method for representing phonemes,
UniGlyph enhances the ability of AI systems to process a wide range of languages, improving the accuracy of speech-to-
text conversion and other language processing tasks.
5.2 Transliteration Rules
The transliteration rules of UniGlyph are designed to ensure that text converted from one language to another retains
its original pronunciation as closely as possible. These rules take into account the phonetic differences between languages
and provide guidelines for how sounds should be represented in the UniGlyph script. This process involves identifying
equivalent sounds in the target language and mapping them to the corresponding UniGlyph characters. For AI-driven
applications, these transliteration rules are essential for enabling accurate cross-language communication. In machine
translation systems, for example, the ability to correctly transliterate names, technical terms, and other phonetic elements
is crucial for producing translations that are both accurate and understandable. UniGlyph's transliteration rules provide a
standardized approach to this process, ensuring that AI systems can handle the complexities of transliteration with minimal
errors.
Table 5: Examples of Translation from different languages to UniGlyph
Language Script in native language English equivalent IPA UniGlyph
English The sun is shining brightly The sun is shining brightly ðə sʌn ɪz ˈʃaɪnɪŋ ˈbraɪtli
today today təˈdeɪ
Mandarin 今天的阳光明媚 Jīntiān de yángguāng míngmèi ͡tɕɪn˥ tʰjɛn˥ jaŋ˥ kwaŋ˥ miŋ˧
Chinese meɪ˧˥
Spanish Hoy el sol brilla intensamente El sol brilla intensamente hoy el ˈsol ˈbrilla inˈtensaˈmente
hoy oi
Arabic ةيهازلا قرشت سمشلا مويلاا Al-yom ash-shams tashraqo az- alˈjoːm ʔaʃˈʃams taʃraqʊ
zāhiyah ʔazˈzaːhijah
Portuguese Hoje o sol está brilhando Hoje o sol está brilhando ˈoʒi o ˈsɔw ˈesta brilˈjandu
intensamente hoje intensamente hoje inˈtẽˈsamente ˈoʒi
French Aujourd'hui, le soleil brille Aujourd'hui, le soleil brille oʒuʁˈdui lə soˈlɛj bril
intensément aujourd'hui intensément aujourd'hui intensəmɑ̃ oʒuʁˈdui
Japanese 今日、太陽は今日はとても Kyōjitsu, taiyō wa kyō wa kʲoːdzi͡tsu taijoː wa kʲoː wa
明るく輝いています totemo akiraka ni hikatte imasu totemo akaraka ni hikatte
imasu
Tamil இன்று சூரியன் மிகவும் Indru sūriyan mikavum indu suːrijan mikavum
பிரகாசமாக pirakāśamakāga piɾakaːsamaːgaka
பிரகாசிக்கிறது pirakāśikkiradu piɾakaːsikkiɾadu
14Language Script in native language English equivalent IPA UniGlyph
German Heute scheint die Sonne heute Heute scheint die Sonne heute ˈhɔʏtə ˈʃaɪnt diː ˈzɔnə ˈhɔʏtə
sehr hell sehr hell zeːr ˈhɛl
Hindi आज सूरज बहुत चमक रहा है Aaj sooraj bahut chamak rahā aːdz suːrya bahut ͡tʃəmək raɦa
hai hɛː
Bengali সূর্ আয জ খুব উজ্জ্বল Sūrya āja khuba ujjbala ˈsuːɾjɔ ˈaːdʒ ˈkhub ˈuddʒɔl
Russian Сегодня ярко светит солнце Segodnya yarko svetit solntse sʲevɐˈdɲa ˈjarka ˈsviertʲit
ˈsoln͡tsɨ
Hebrew םויה תוריהבב תחרוז שמשה HaShamesh zoret be'behirut haʃaˈmeʃ zoˈret bevihiˈrut
hayom haˈjom
Greek ἥλιος λάμπει φωτεινῶς σήμερον Hhēlios lampei phōteinōs ˈheːlios ˈlampi fotiˈnos
sēmeron ˈseːmeron
Latin Sol splendet clare hodie Sol splendēt clārē hodiē sɔl ˈsplɛndɛt ˈklare ˈhodie
Old 𐎭𐎡𐎹 𐎢𐏃𐎴𐎢𐏁 Huvašra citiya hya haruva huvaʃra citija hja haruva
Persian 𐏃𐎶𐎢𐎴𐎡 duvarš tiy duvarʃ tiy
Dutch De zon schijnt vandaag fel De zon schijnt vandaag fel də zɔn ʃxɛint fɑndaːx fɛl
Korean 오늘 태양이 밝게 빛난다 Oneul taeyang-i balkge onɯl tʰɛjaŋi palkːe pi͡tɕnanda
bichnanda
Swedish Skiner solen klart idag Skiner solen klart idag ˈʃiːnər ˈsuːlɛn ˈklɑːʈ ɪˈdɑː
Ancient 𓇳𓅓𓏤𓅪𓆱𓏛𓏏𓏤𓊃𓂝𓂋𓏏𓀀𓏞𓉐𓂋𓏏 Ra hrw šsp m dšr.w ḥr ibd ra ħrw ʃsp m dʃrw ħr ibd
Egyptian 𓋇𓁻
Aramaic ܐܡܘܝ ܐܫܕܩܠ ܐܫܡܫܕ ܐܫܡܫ Shəmshā dshəmshā l'qādshā ʃəmʃa dəʃəmʃa lqaːdʃa
yawmā jɑwmaː
Italian il sole splende luminosamente il sole splende luminosamente il ˈsole ˈsplɛnde
oggi oggi luˈminozamente ˈɔddʒi
Sumerian Utu-da ud-lu-un-na-da-lil₂-ḫa utu da ud luna da lil ħa
𒌓𒀭𒌓𒂊𒀭𒂊𒌓𒍣𒍪𒍪𒋻
𒍣𒋻𒂗𒀭𒍣𒁍𒂠
Akkadian Šamaš ērib issak marduk zi' gub ʃamaʃ eːrib issak marːduːk ziː
𒌷𒂗𒆠𒌓𒆠𒌑𒁺𒂗𒀭𒍣
ma guːb ma
𒁍𒁀𒁀𒁀
5.3 Handling Diverse Phonetic Elements
UniGlyph is designed to accommodate the wide variety of phonetic elements found in different languages, including
sounds that may not have direct equivalents in other scripts. This versatility is achieved through the use of additional
markers and modifiers that can be applied to the basic seven-segment characters to represent pitch, length, and other
phonetic variations. These features allow UniGlyph to capture the full range of sounds in any language, ensuring that the
script can be used for accurate phonetic transcription and transliteration as shown in Error! Reference source not found..
The inclusion of these markers is particularly important for AI applications that involve speech synthesis and recognition.
In tonal languages, for example, pitch variation can change the meaning of a word, making it essential for AI systems to
correctly identify and reproduce these variations. UniGlyph's ability to encode pitch and length variations directly into the
script allows AI systems to process these elements more accurately, improving the overall performance of speech-based
applications.
155.4 Integration with AI Systems
UniGlyph's design is inherently suited for integration with AI technologies, particularly in the areas of speech
recognition, natural language processing, and machine translation. The script's simplicity and consistency make it an ideal
candidate for use in AI systems that require efficient and accurate phonetic representation. By providing a standardized
method for phonetic mapping and transliteration, UniGlyph can help reduce the complexity of language processing tasks
in AI, leading to more reliable and effective language-based applications. For example, in automatic speech recognition
(ASR) systems, UniGlyph can be used as an intermediate representation of spoken input, allowing the system to more
accurately identify and process phonetic elements. This can lead to improved recognition accuracy, particularly in
multilingual environments where traditional character sets may struggle to capture the nuances of different languages.
Similarly, in machine translation systems, UniGlyph can provide a consistent framework for transliterating names,
technical terms, and other non-translatable elements, enhancing the quality and coherence of the translated output.
5.5 Future Directions
As AI technologies continue to evolve, the need for flexible and adaptable language representation systems will only
grow. UniGlyph's design allows for the easy addition of new characters and markers as linguistic needs change, ensuring
that the script remains relevant and useful over time. This adaptability is particularly important for AI applications, where
the ability to quickly incorporate new phonetic data can significantly impact system performance. In conclusion,
UniGlyph's approach to phonetic mapping and transliteration offers a robust framework for representing the phonetic
diversity of the world's languages. Its integration with AI technologies holds significant potential for improving the
accuracy and efficiency of language processing tasks, making it a valuable tool for both human and machine
communication in an increasingly interconnected world.
6 APPLICATION AND USE CASES
The versatility and adaptability of UniGlyph make it a powerful tool for a wide range of applications across various
domains. Its potential extends beyond traditional linguistic contexts, offering innovative solutions for cross-language
communication, education, symbolic representation, multicultural interactions, and creative endeavors. Moreover, its
integration with artificial intelligence (AI) technologies opens up new possibilities for enhancing language processing,
translation, and communication systems.
6.1 Cross-Language Communication
One of the primary applications of UniGlyph is in facilitating cross-language communication. By providing a universal
script that can represent the phonetic structure of any language, UniGlyph enables speakers of different languages to
communicate more effectively. This is particularly useful in multilingual regions where a common script can bridge
language barriers, allowing for clearer and more accurate communication between diverse language groups. In AI-driven
communication tools, such as chatbots and virtual assistants, UniGlyph can be employed to improve the accuracy and
consistency of cross-language interactions. These AI systems can use UniGlyph as an intermediate script to transliterate
and process inputs from multiple languages, ensuring that the intended meaning is preserved and understood across
different linguistic contexts. This capability is especially valuable in globalized environments where effective
communication across languages is essential.
166.2 Educational Contexts
UniGlyph also has significant potential in educational settings, particularly in the teaching of phonetics, linguistics, and
language learning. Its simplified and consistent script can be used as a teaching aid to help students understand the phonetic
elements of different languages. By providing a clear and unified representation of sounds, UniGlyph can make it easier
for learners to grasp the nuances of pronunciation and phonetic variation. In AI-powered educational tools, such as
language learning apps and pronunciation training software, UniGlyph can serve as a foundational script for teaching
phonetics. AI systems can leverage UniGlyph to provide personalized feedback on pronunciation, helping learners to
achieve more accurate and natural speech. The use of UniGlyph in these contexts can enhance the effectiveness of language
education by providing a consistent and accessible framework for understanding phonetic principles.
6.3 Symbolic Representation
Beyond its use in language, UniGlyph can also be employed as a symbolic representation system for encoding phonetic
information in a compact and visually distinct manner. This makes it suitable for use in various symbolic applications,
such as shorthand writing, phonetic transcription, and even artistic expression. The ability to represent complex phonetic
data with a limited set of symbols allows UniGlyph to function as a versatile tool for symbolic communication. AI systems
that require efficient and accurate encoding of phonetic data can benefit from integrating UniGlyph into their symbolic
processing algorithms. For example, in speech recognition systems, UniGlyph can be used to encode and analyze phonetic
features, enabling more efficient and accurate processing of spoken language. This symbolic representation capability also
extends to areas such as text-to-speech synthesis and linguistic data analysis, where precise phonetic encoding is critical
for achieving high-quality results.
6.4 Multicultural Contexts
In multicultural and multilingual environments, UniGlyph offers a standardized script that can be used to represent the
phonetic elements of multiple languages. This is particularly useful in contexts where individuals from different linguistic
backgrounds need to communicate or collaborate. By providing a common script that is both neutral and universally
applicable, UniGlyph can help to reduce language-related misunderstandings and foster more inclusive interactions. AI
applications in multicultural contexts can leverage UniGlyph to enhance communication and collaboration between
individuals from diverse linguistic backgrounds. For instance, AI-powered translation tools can use UniGlyph to
transliterate and process multilingual inputs, ensuring that the original phonetic intent is preserved in the translated output.
This can lead to more accurate and culturally sensitive translations, improving the quality of cross-cultural communication
in various settings.
6.5 Creative Applications
The unique design of UniGlyph also lends itself to creative applications, where its distinct visual style can be used to
explore new forms of artistic expression. Whether in graphic design, typography, or digital art, UniGlyph’s seven-segment
characters offer a visually striking and adaptable medium for creative experimentation. Artists and designers can use
UniGlyph to create works that play with the boundaries between language, symbol, and visual art. In AI-driven creative
tools, UniGlyph can be integrated as a font or script option, allowing users to explore new aesthetic possibilities in their
digital creations. For example, AI-powered UniGlyph can be used to generate dynamic, real-time visualizations of speech
or text, turning linguistic data into an artistic experience. The script’s versatility and adaptability make it an ideal candidate
for creative projects that seek to blend linguistic and visual elements in innovative ways.
176.6 AI-Powered Language Processing
UniGlyph’s integration with artificial intelligence opens up new possibilities for enhancing language processing tasks.
AI systems that involve speech recognition, natural language processing, and machine translation can benefit from
UniGlyph’s compact and consistent phonetic representation. By providing a standardized script for encoding phonetic
elements, UniGlyph can improve the accuracy and efficiency of these AI-driven processes. In particular, AI-powered
speech recognition systems can use UniGlyph as an intermediate representation of spoken input, enabling more precise
identification and processing of phonetic features. This can lead to improved recognition accuracy, especially in
multilingual environments where traditional character sets may struggle to capture the nuances of different languages.
Additionally, in machine translation, UniGlyph can serve as a framework for transliterating names, technical terms, and
other phonetic elements, enhancing the quality and coherence of the translated output.
Encode animal phonetic languages
Looking ahead, one of the most exciting future applications of UniGlyph lies in its potential to encode animal phonetic
languages. As scientific research continues to explore the communication patterns of non-human species, UniGlyph could
be adapted to represent the phonetic elements of animal calls, sounds, and vocalizations. This expansion of the system
could contribute to fields like bioacoustics, zoology, and even AI, where understanding and interpreting animal
communication is becoming a growing area of study. By providing a script for animal sounds, UniGlyph could support
researchers in categorizing and analyzing vocalizations, ultimately enhancing our understanding of cross-species
communication [29, 33, 46, 47, 56, 75, 83, 108, 111, 115, 117, 120].
6.7 Future Directions
The applications and use cases of UniGlyph demonstrate its potential to transform various aspects of language
representation and communication. As AI technologies continue to advance, the integration of UniGlyph into AI systems
holds significant promise for improving the accuracy and effectiveness of language processing tasks. The script’s
adaptability and versatility ensure that it can meet the evolving needs of linguistic research, education, and cross-language
communication in an increasingly interconnected world. In conclusion, UniGlyph’s innovative script design and robust
transliteration system offer a flexible and powerful solution for representing phonetic diversity across languages. Its
potential applications span a wide range of fields, from education and communication to creative expression and AI-driven
language processing. As the world becomes more globalized and interconnected, UniGlyph’s contributions to cross-
language communication and linguistic research will continue to grow, making it a valuable tool for the future.
7 CONCLUSION
UniGlyph represents a significant advancement in the development of a universal transliteration system that bridges
the gaps between different languages. Its design, rooted in a seven-segment display script, offers a compact, versatile, and
efficient method for representing the phonetic diversity of languages worldwide. The system's ability to address the
imperfections of the International Phonetic Alphabet (IPA) and the limitations of traditional character sets is a testament
to its innovative approach to phonetic representation. The adaptability of UniGlyph is one of its most remarkable features.
By distinguishing between continuous and non-continuous consonants, and incorporating mechanisms for pitch and
duration variations, UniGlyph ensures accurate and nuanced phonetic representation. Furthermore, the script is designed
to be future-proof, with the ability to accommodate new pronunciation characters as linguistic needs evolve. UniGlyph's
potential applications are vast and varied. In cross-language communication, it serves as a universal script that facilitates
clearer and more accurate interactions between speakers of different languages. In educational contexts, UniGlyph offers
18a consistent and accessible framework for teaching phonetics, helping learners understand the nuances of pronunciation
across languages. Its use in symbolic representation and multicultural contexts further demonstrates its versatility and
adaptability. One of the most exciting prospects for UniGlyph lies in its integration with artificial intelligence. As AI
continues to play a central role in language processing, communication, and translation, UniGlyph offers a standardized
script that can enhance the accuracy and efficiency of these AI-driven processes. Whether in speech recognition, natural
language processing, or machine translation, UniGlyph provides a robust framework for encoding and analyzing phonetic
data, leading to improved outcomes in multilingual environments. Additionally, future expansions of UniGlyph may
involve integrating non-human communication systems, particularly animal phonetics, into the script. As research into
animal communication continues to grow, UniGlyph could evolve to represent these phonetic patterns, allowing for a
broader understanding of cross-species communication. The ability to encode animal sounds and calls would not only aid
in scientific research but could also open new avenues for AI to interpret and interact with the natural world. The creative
possibilities of UniGlyph also extend to the realms of art and design, where its distinct visual style can be used to explore
new forms of artistic expression. AI-powered design tools can leverage UniGlyph to generate visually unique
representations of phonetic data, further pushing the boundaries of creativity and innovation. In conclusion, UniGlyph
stands out as a pioneering system that addresses the complex challenges of cross-language communication, phonetic
representation, and language education. Its innovative script design, combined with its adaptability and potential for AI
integration, positions UniGlyph as a valuable tool for the future. As the world becomes increasingly interconnected,
UniGlyph’s contributions to bridging linguistic divides and enhancing communication will continue to grow. With future
expansions that may include the representation of animal phonetic languages, UniGlyph could even contribute to the
broader understanding of communication beyond the human sphere, making it an indispensable asset in both language and
technology.
ACKNOWLEDGMENTS
We would like to express our sincere gratitude to Jeseentha V. for her invaluable assistance in helping with the
pronunciation aspects of this project. Her expertise greatly contributed to the development and refinement of the phonetic
elements of UniGlyph. No funding was received for this research.
DECLARATION OF INTERESTS
The authors declare that they have no known competing financial interests or personal relationships that could have
appeared to influence the work reported in this paper.
DECLARATION OF GENERATIVE AI AND AI-ASSISTED TECHNOLOGIES IN THE WRITING PROCESS
During the preparation of this work, the author(s) used ChatGPT in order to generate initial drafts, refine language and
brainstorm ideas. After using this tool, the author(s) reviewed and edited the content as needed and take(s) full
responsibility for the content of the publication.
REFERENCES
[1] 14:00-17:00. ISO 15919:2001. ISO. Retrieved August 16, 2024 from https://www.iso.org/standard/28333.html
[2] Ife Adebara and Muhammad Abdul-Mageed. 2022. Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go.
https://doi.org/10.48550/arXiv.2203.08351
[3] Yossi Adi, Joseph Keshet, Emily Cibelli, Erin Gustafson, Cynthia Clopper, and Matthew Goldrick. 2016. Automatic measurement of vowel
duration via structured prediction. The Journal of the Acoustical Society of America 140, 6 (December 2016), 4517–4527.
https://doi.org/10.1121/1.4972527
19[4] Yossi Adi, Joseph Keshet, and Matthew Goldrick. 2015. Vowel duration measurement using deep neural networks. In 2015 IEEE 25th
International Workshop on Machine Learning for Signal Processing (MLSP), September 2015. 1–6.
https://doi.org/10.1109/MLSP.2015.7324331
[5] alib-ms. 2022. Developing OpenType Fonts for Tamil Script - Typography. Retrieved September 9, 2024 from https://learn.microsoft.com/en-
us/typography/script-development/tamil
[6] alib-ms. 2022. Developing OpenType Fonts for Devanagari Script - Typography. Retrieved September 9, 2024 from
https://learn.microsoft.com/en-us/typography/script-development/devanagari
[7] Ashraf Alkhairy and Afshan Jafri. 2016. Heterophonic speech recognition using composite phones. SpringerPlus 5, 1 (November 2016), 2008.
https://doi.org/10.1186/s40064-016-3332-9
[8] Alfredo Ardila. 2018. Origins of Writing. In Historical Development of Human Cognition: A Cultural-Historical Neuropsychological
Perspective, Alfredo Ardila (ed.). Springer, Singapore, 61–81. https://doi.org/10.1007/978-981-10-6887-4_4
[9] Sercan O. Arik, Mike Chrzanowski, Adam Coates, Gregory Diamos, Andrew Gibiansky, Yongguo Kang, Xian Li, John Miller, Andrew Ng,
Jonathan Raiman, Shubho Sengupta, and Mohammad Shoeybi. 2017. Deep Voice: Real-time Neural Text-to-Speech.
https://doi.org/10.48550/arXiv.1702.07825
[10] Ebbie Awino, Lilian Wanzare, Lawrence Muchemi, Barack Wanjawa, Edward Ombui, Florence Indede, Owen McOnyango, and Benard Okal.
2022. Phonemic Representation and Transcription for Speech to Text Applications for Under-resourced Indigenous African Languages: The
Case of Kiswahili. arXiv.org. Retrieved September 8, 2024 from https://arxiv.org/abs/2210.16537v1
[11] Md Abul kalam Azad, Rezwana Sharmeen, and S. M. Kamruzzaman. 2010. Universal Numeric Segmented Display.
https://doi.org/10.48550/arXiv.1009.4977
[12] Subith Babu and Mahesh Jangid. 2016. Touching character segmentation of Devanagari script. In Proceedings of the 7th International
Conference on Computing Communication and Networking Technologies (ICCCNT ’16), July 06, 2016. Association for Computing Machinery,
New York, NY, USA, 1–5. https://doi.org/10.1145/2967878.2967908
[13] Martin J. Ball, Sara J. Howard, and Kirk Miller. 2018. Revisions to the extIPA chart. Journal of the International Phonetic Association 48, 2
(August 2018), 155–164. https://doi.org/10.1017/S0025100317000147
[14] Mohammed Belatar and Franck Poirier. 2007. UniGlyph: une méthode universelle pour la saisie de texte sur dispositifs mobiles. In Proceedings
of the 19th Conference on l’Interaction Homme-Machine (IHM ’07), November 12, 2007. Association for Computing Machinery, New York,
NY, USA, 111–118. https://doi.org/10.1145/1541436.1541458
[15] Mohammed Belatar and Franck Poirier. 2008. Text entry for mobile devices and users with severe motor impairments: handiglyph, a primitive
shapes based onscreen keyboard. In Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility (Assets
’08), October 13, 2008. Association for Computing Machinery, New York, NY, USA, 209–216. https://doi.org/10.1145/1414471.1414510
[16] Barbara Bernhardt and Martin J. Ball. 1993. Characteristics of Atypical Speech currently not included in the Extensions to the IPA. Journal of
the International Phonetic Association 23, 1 (June 1993), 35–38. https://doi.org/10.1017/S0025100300004771
[17] Robert Bishop and Ruggero Micheletto. 2012. The Hangulphabet: A Descriptive Alphabet. https://doi.org/10.48550/arXiv.1210.7282
[18] A.W. Black and K.A. Lenzo. 2004. Multilingual text-to-speech synthesis. In 2004 IEEE International Conference on Acoustics, Speech, and
Signal Processing, May 2004. iii–761. https://doi.org/10.1109/ICASSP.2004.1326656
[19] Charlotte Burck. 2004. Living in several languages: implications for therapy. Journal of Family Therapy 26, 4 (2004), 314–339.
https://doi.org/10.1111/j.1467-6427.2004.00287.x
[20] M. E. Bywater. 2013. The impact of writing: ancient and modern views on the role of early writing systems within society and as a part of
“civilisation.” Masters. UCL (University College London). Retrieved September 8, 2024 from https://discovery.ucl.ac.uk/id/eprint/1387202/
[21] Zexin Cai, Yaogen Yang, and Ming Li. 2020. Cross-lingual Multispeaker Text-to-Speech under Limited-Data Scenario.
https://doi.org/10.48550/arXiv.2005.10441
[22] J. C. Catford. 1990. Glottal consonants … another view. Journal of the International Phonetic Association 20, 2 (December 1990), 25–26.
https://doi.org/10.1017/S0025100300004229
[23] J. C. Catford. 2001. Practical Introduction to Phonetics: The British Army and the War against Germany 1919-1945 (2nd edition ed.). OUP
Oxford, Oxford ; New York.
[24] Françoise Briquel Chatonnet and Robert Hawley. 2020. Phoenician and Punic. In A Companion to Ancient Near Eastern Languages. John Wiley
& Sons, Ltd, 297–318. https://doi.org/10.1002/9781119193814.ch16
[25] Hee-Sung Chung. 1990. A phonological knowledge base system using unification-based formalism: a case study of Korean phonology. In
Proceedings of the 13th conference on Computational linguistics - Volume 3 (COLING ’90), August 20, 1990. Association for Computational
Linguistics, USA, 76–78. https://doi.org/10.3115/991146.991160
[26] Chuzaimah Chuzaimah, Falih Fadli, and Desy Satriyani Tamrin. 2021. Investigating the Role of International Phonetic Alphabet to Enhance
Highschool Students’ Pronunciation Skill. Tamaddun 20, 1 (2021), 124–131. https://doi.org/10.33096/tamaddun.v20i1.95
[27] J. Clark. 2006. An Introduction to Phonetics and Phonology 3e: 9. Wiley-Blackwell, Malden, Mass.
[28] Frank Moore Cross. 1980. Newly Found Inscriptions in Old Canaanite and Early Phoenician Scripts. Bulletin of the American Schools
of Oriental Research 238, (April 1980), 1–20. https://doi.org/10.2307/1356511
[29] Maksymilian Dąbkowski and Gašper Beguš. 2023. Large language models and (non-)linguistic recursion.
https://doi.org/10.48550/arXiv.2306.07195
[30] Peter T. Daniels. 2012. Alphabets and scripts, ancient Near East. In The Encyclopedia of Ancient History. John Wiley & Sons, Ltd.
https://doi.org/10.1002/9781444338386.wbeah01007
[31] Aliya Deri and Kevin Knight. 2016. Grapheme-to-Phoneme Models for (Almost) Any Language. In Proceedings of the 54th Annual Meeting of
the Association for Computational Linguistics (Volume 1: Long Papers), August 2016. Association for Computational Linguistics, Berlin,
Germany, 399–408. https://doi.org/10.18653/v1/P16-1038
[32] F. W. Dobbs-Allsopp. 2006. Asia, Ancient Southwest: Scripts, Earliest. In Encyclopedia of Language & Linguistics (Second Edition), Keith
Brown (ed.). Elsevier, Oxford, 495–500. https://doi.org/10.1016/B0-08-044854-2/04552-1
[33] Gordana Dodig-Crnkovic. 2023. Morphological Computing as Logic Underlying Cognition in Human, Animal, and Intelligent Machine.
https://doi.org/10.48550/arXiv.2309.13979
[34] Johanna Drucker. 2022. Inventing the Alphabet: The Origins of Letters from Antiquity to the Present. University of Chicago Press, Chicago, IL.
Retrieved September 8, 2024 from https://press.uchicago.edu/ucp/books/book/chicago/I/bo141943649.html
20[35] Elizabeth L. Eisenstein. 1980. The Printing Press as an Agent of Change: Communications and Cultural Transformations in Early-Modern
Europe. Cambridge University Press, Cambridge.
[36] John H. Esling. 1988. 7.1 Computer coding of IPA symbols and 7.3 Detailed phonetic representation of computer data bases. Journal of the
International Phonetic Association 18, 2 (December 1988), 99–106. https://doi.org/10.1017/S0025100300003704
[37] Dan Farrell. 2019. PHONETICS OF ENDANGERED LANGUAGES - D. H. Whalen. Acoustics Today. Retrieved September 8, 2024 from
https://acousticstoday.org/phonetics-of-endangered-languages-d-h-whalen/
[38] David Ferris. 2017. Techniques and Challenges in Speech Synthesis. https://doi.org/10.48550/arXiv.1709.07552
[39] Jil Fine. 2003. Writing in Ancient Egypt. Powerkids Pr.
[40] Stephen Roger Fischer and Steven Roger Fischer. 2003. A History of Writing (Reprint edition ed.). Reaktion Books, London.
[41] Rochelle Forrester. 2016. History of Writing and Record Keeping. https://doi.org/10.2139/ssrn.2862739
[42] Anthony Fox. 1974. The IPA alphabet: remarks on some proposals for reform. Journal of the International Phonetic Association 4, 2 (December
1974), 76–79. https://doi.org/10.1017/S0025100300001043
[43] Armand L. De Gaetano. 1967. G. B. Gelli and the Rebellion Against Latin. Studies in the Renaissance 14, (January 1967), 131–158.
https://doi.org/10.2307/2857164
[44] Alan H. Gardiner. 1916. The Egyptian Origin of the Semitic Alphabet. The Journal of Egyptian Archaeology 3, 1 (January 1916), 1–16.
https://doi.org/10.1177/030751331600300101
[45] Pegah Ghahremani, Bagher BabaAli, Daniel Povey, Korbinian Riedhammer, Jan Trmal, and Sanjeev Khudanpur. 2014. A pitch extraction
algorithm tuned for automatic speech recognition. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing
(ICASSP), May 2014. 2494–2498. https://doi.org/10.1109/ICASSP.2014.6854049
[46] Sankalpa Ghose, Yip Fai Tse, Kasra Rasaee, Jeff Sebo, and Peter Singer. 2024. The Case for Animal-Friendly AI.
https://doi.org/10.48550/arXiv.2403.01199
[47] Shafi Goldwasser, David F. Gruber, Adam Tauman Kalai, and Orr Paradise. 2023. A Theory of Unsupervised Translation Motivated by
Understanding Animal Communication. https://doi.org/10.48550/arXiv.2211.11081
[48] Matthew Kelly Gordon. 2016. Phonological Typology. Oxford University Press.
[49] David Graddol. 2004. The Future of Language. Science 303, 5662 (February 2004), 1329–1331. https://doi.org/10.1126/science.1096546
[50] G. B. Gragg. 2006. Mesopotamian Cuneiform Script. In Encyclopedia of Language & Linguistics (Second Edition), Keith Brown (ed.). Elsevier,
Oxford, 27–31. https://doi.org/10.1016/B0-08-044854-2/04550-8
[51] Paul Grosswiler. 2004. Dispelling the Alphabet Effect. Canadian Journal of Communication 29, 2 (February 2004), 145–158.
https://doi.org/10.22230/cjc.2004v29n2a1432
[52] Hans Gua. 2017. The Standard of Speech Sounds-On a Reform for International Phonetic Alphabet. International Journal of Linguistics 9, 3
(June 2017), 214–228. https://doi.org/10.5296/ijl.v9i3.11446
[53] Yohan Guerrier, Christophe Kolski, and Franck Poirier. 2013. Proposition of a communication system used in mobility by users with physical
disabilities, focus on cerebral palsy with athetoid problems. In 2013 International Conference on Advanced Logistics and Transport, May 2013.
269–274. https://doi.org/10.1109/ICAdLT.2013.6568471
[54] Jon Gunderson, George Gruetzmacher, and Naomi Swanson. 1991. Legibility of Seven Segment Numeric LED Displays: Comparisons of Two
Fonts at Various Distances. Proceedings of the Human Factors Society Annual Meeting 35, 6 (September 1991), 491–495.
https://doi.org/10.1518/107118191786754941
[55] Sunil K. Gupta and Juergen Schroeter. 1993. Pitch‐synchronous frame‐by‐frame and segment‐based articulatory analysis by synthesis. The
Journal of the Acoustical Society of America 94, 5 (November 1993), 2517–2530. https://doi.org/10.1121/1.407364
[56] Masato Hagiwara, Marius Miron, and Jen-Yu Liu. 2024. ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds.
https://doi.org/10.48550/arXiv.2402.03269
[57] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam
Coates, and Andrew Y. Ng. 2014. Deep Speech: Scaling up end-to-end speech recognition. https://doi.org/10.48550/arXiv.1412.5567
[58] William M. Hartmann. 1996. Pitch, periodicity, and auditory organization. The Journal of the Acoustical Society of America 100, 6 (December
1996), 3491–3502. https://doi.org/10.1121/1.417248
[59] Archibald A. Hill. 2016. The Typology of Writing Systems. In Papers in linguistics in honor of Léon Dostert, William Mandeville Austin (ed.).
De Gruyter Mouton, 92–99. https://doi.org/10.1515/9783111675886-008
[60] Hinton and Nichols. 2006. Sound Symbolism (1st edition ed.). Cambridge University Press, Cambridge ; New York.
[61] Hartwig Hirschfeld. 1911. XXVI Recent Theories on the Origin of the Alphabet. Journal of the Royal Asiatic Society 43, 4 (October 1911), 963–
977. https://doi.org/10.1017/S0035869X00042313
[62] Stephen Houston, John Baines, and Jerrold Cooper. 2003. Last Writing: Script Obsolescence in Egypt, Mesopotamia, and Mesoamerica.
Comparative Studies in Society and History 45, 3 (July 2003), 430–479. https://doi.org/10.1017/S0010417503000227
[63] Richard Ishida. 2002. An Introduction to Indic Scripts. 2002. . Retrieved September 9, 2024 from https://www.semanticscholar.org/paper/An-
Introduction-to-Indic-Scripts-Ishida/a96ceaa3edaf52f87fe65acd0bd9bba1e308de94
[64] Wiktor Jassem and Piotra Łobacz. 1989. IPA Phonemic Transcription Using an IBM PC and Compatibles. Journal of the International Phonetic
Association 19, 1 (July 1989), 16–23. https://doi.org/10.1017/S0025100300005879
[65] Keith Johnson. 2002. Peter Ladefoged (2001). Vowels and consonants: an introduction to the sounds of languages. Maldon, Mass. & Oxford:
Blackwell Publishers. Pp. xxii+191. Phonology 19, 2 (August 2002), 306–310. https://doi.org/10.1017/S0952675702234387
[66] Daniel Jurafsky and James H. Martin. 2008. Speech and Language Processing: International Edition (2nd edition ed.). Pearson, Upper Saddle
River, NJ.
[67] Seng Kheang, Kouichi Katsurada, Yurie Iribe, and Tsuneo Nitta. 2016. Using Reversed Sequences and Grapheme Generation Rules to Extend
the Feasibility of a Phoneme Transition Network-Based Grapheme-to-Phoneme Conversion. IEICE Transactions on Information and Systems
E99.D, 4 (2016), 1182–1192. https://doi.org/10.1587/transinf.2015EDP7349
[68] Adorjan Kiss and Joël Quinqueton. 2004. Uniscript: a model for persistent and incremental knowledge storage. In Proceedings of the the 1st
ACM workshop on Continuous archival and retrieval of personal experiences (CARPE’04), October 15, 2004. Association for Computing
Machinery, New York, NY, USA, 66–73. https://doi.org/10.1145/1026653.1026663
[69] Peter Ladefoged. 1996. The Sounds of the World’s Languages (1st edition ed.). Wiley-Blackwell, Oxford, UK.
[70] Peter Ladefoged and John Choi. 2005. A database demonstrating the sounds of the world’s languages. The Journal of the Acoustical Society of
America 86, S1 (August 2005), S75–S76. https://doi.org/10.1121/1.2027639
21[71] Peter Ladefoged and Morris Halle. 1988. Some Major Features of the International Phonetic Alphabet. Language 64, 3 (1988), 577–582.
https://doi.org/10.2307/414533
[72] John Laver. 1994. Principles of Phonetics. Cambridge University Press, Cambridge ; New York, NY.
[73] Ho-Joon Lee and Jong C. Park. 2005. Vowel Sound Disambiguation for Intelligible Korean Speech Synthesis. In Proceedings of the 19th Pacific
Asia Conference on Language, Information and Computation, December 2005. Institute of Linguistics, Academia Sinica, Taipei, Taiwan,
R.O.C., 131–142. http://hdl.handle.net/2065/28995
[74] Xinjian Li, Siddharth Dalmia, Juncheng Li, Matthew Lee, Patrick Littell, Jiali Yao, Antonios Anastasopoulos, David R. Mortensen, Graham
Neubig, Alan W. Black, and Florian Metze. 2020. Universal Phone Recognition with a Multilingual Allophone System.
https://doi.org/10.48550/arXiv.2002.11800
[75] Yulong Liu, Yunlong Yuan, Chunwei Wang, Jianhua Han, Yongqiang Ma, Li Zhang, Nanning Zheng, and Hang Xu. 2024. From Summary to
Action: Enhancing Large Language Models for Complex Tasks with Open World APIs. https://doi.org/10.48550/arXiv.2402.18157
[76] Andrew Maas, Ziang Xie, Dan Jurafsky, and Andrew Ng. 2015. Lexicon-Free Conversational Speech Recognition with Neural Networks. In
Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, May 2015. Association for Computational Linguistics, Denver, Colorado, 345–354. https://doi.org/10.3115/v1/N15-1038
[77] Deepshikha Mahanta, Bidisha Sharma, Priyankoo Sarmah, and S.R. Mahadeva Prasanna. 2016. Text to speech synthesis system in Indian
English. In 2016 IEEE Region 10 Conference (TENCON), November 2016. 2614–2618. https://doi.org/10.1109/TENCON.2016.7848511
[78] Louis Mahon. 2024. Towards a Universal Method for Meaningful Signal Detection. https://doi.org/10.48550/arXiv.2408.00016
[79] John Maidment and Michael Ashby (Eds.). 2005. Introduction to speech. In Introducing Phonetic Science. Cambridge University Press,
Cambridge, 1–20. https://doi.org/10.1017/CBO9780511808852.001
[80] Joyce Marcus. 1980. Zapotec Writing. Scientific American. Retrieved September 9, 2024 from
https://www.scientificamerican.com/article/zapotec-writing/
[81] J. B. Millar and H. Oasa. 1981. Proposal for ASCII coded phonetic script. Journal of the International Phonetic Association 11, 2 (December
1981), 62–74. https://doi.org/10.1017/S0025100300002279
[82] Rafael C. Monroy. 2004. NEW TRANSCRIPTIONAL POLICIES IN THE LATEST ENGLISH PRONUNCIATION DICTIONARIES. A
HELP OR HINDRANCE TO THE FOREIGN LEARNER? International Journal of Lexicography 17, 3 (September 2004), 275–290.
https://doi.org/10.1093/ijl/17.3.275
[83] Roger K. Moore. 2019. Vocal Interactivity in Crowds, Flocks and Swarms: Implications for Voice User Interfaces.
https://doi.org/10.48550/arXiv.1907.11656
[84] David R. Mortensen, Xinjian Li, Patrick Littell, Alexis Michaud, Shruti Rijhwani, Antonios Anastasopoulos, Alan W. Black, Florian Metze, and
Graham Neubig. 2020. AlloVera: A Multilingual Allophone Database. https://doi.org/10.48550/arXiv.2004.08031
[85] Hans J. Nissen. 1985. The Emergence of Writing in the Ancient Near East. Interdisciplinary Science Reviews 10, 4 (January 1985), 349–361.
https://doi.org/10.1179/isr.1985.10.4.349
[86] Verbitskaya Olga and Lesnikovskaya Ekaterina. 2022. Reshaping of communicative and cultural codes in the new global digital communicative
sphere. SHS Web Conf. 134, (2022), 00160. https://doi.org/10.1051/shsconf/202213400160
[87] B. Parhami. 2018. Computers and Challenges of Writing in Persian : A Personal History Spanning Five Decades. 2018. . Retrieved September 9,
2024 from https://www.semanticscholar.org/paper/Computers-and-Challenges-of-Writing-in-Persian-%3A-A-
Parhami/551f321ac47d94a89e1afb1f7bafb803b27d18c3
[88] Seung-won Park. 2020. Generating Novel Glyph without Human Data by Learning to Communicate. arXiv.org. Retrieved September 6, 2024
from https://arxiv.org/abs/2010.04402v2
[89] Sunyoung Park. 2023. Multilingualism, Social Inequality, and the Need for a Universal Language. Journal of Universal Language 24, 1 (2023),
77–93. https://doi.org/10.22425/jul.2023.24.1.77
[90] Gordon E. Peterson and June E. Shoup. 1966. A Physiological Theory of Phonetics. Journal of Speech and Hearing Research 9, 1 (March
1966), 5–67. https://doi.org/10.1044/jshr.0901.05
[91] Franck Poirier and Mohammed Belatar. 2015. UniWatch - Some Approaches Derived from UniGlyph to Allow Text Input on Tiny Devices
Such as Connected Watches. In Human-Computer Interaction: Interaction Technologies, 2015. Springer International Publishing, Cham, 554–
562. https://doi.org/10.1007/978-3-319-20916-6_51
[92] Barry B. Powell. 1996. Homer and the Origin of the Greek Alphabet (Reprint edition ed.). Cambridge University Press, Cambridge.
[93] Rohit Prasad, Stavros Tsakalidis, Ivan Bulyko, Chia-lin Kao, and Prem Natarajan. 2010. Pashto speech recognition with limited pronunciation
lexicon. In 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, March 2010. 5086–5089.
https://doi.org/10.1109/ICASSP.2010.5495052
[94] Pullum. 1987. Pullum: Phonetic Symbol Guide. University of Chicago Press, Chicago.
[95] Behrang QasemiZadeh, Saeed Rahimi, and Mehdi Safaee Ghalati. 2014. Challenges in Persian Electronic Text Analysis.
https://doi.org/10.48550/arXiv.1404.4740
[96] Partha Pratim Ray. 2012. Universal Numeric Segment Display for Indian Scheduled Languages: an Architectural View.
https://doi.org/10.48550/arXiv.1208.0755
[97] Agha Ali Raza, Sarmad Hussain, Huda Sarfraz, Inam Ullah, and Zahid Sarfraz. 2009. Design and development of phonetically rich Urdu speech
corpus. In 2009 Oriental COCOSDA International Conference on Speech Database and Assessments, August 2009. 38–43.
https://doi.org/10.1109/ICSDA.2009.5278380
[98] Aning Riza and Akhmad Nurul Kawakib. 2021. Utilizing the Phonetic Transcription of IPA (International Phonetic Alphabet) to Avoid EFL
Students Miss-Pronunciation. April 22, 2021. Atlantis Press, 464–468. https://doi.org/10.2991/assehr.k.210421.067
[99] Roach. 2010. English Phonetics and Phonology: A Practical Course, 4 Ed. Cambridge University Press.
[100] Andrew Robinson. 2007. The Story of Writing (2nd edition ed.). Thames & Hudson, London.
[101] James Route, Steven Hillis, Isak Czeresnia Etinger, Han Zhang, and Alan W Black. 2019. Multimodal, Multilingual Grapheme-to-Phoneme
Conversion for Low-Resource Languages. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo
2019), November 2019. Association for Computational Linguistics, Hong Kong, China, 192–201. https://doi.org/10.18653/v1/D19-6121
[102] Benjamin Sass. 2009. The Alphabet at the Turn of the Millennium: West Semitic Alphabet CA 1150-850 BCE. Institute of Archaeology, Tel-
Aviv.
22[103] Tanja Schultz and Tim Schlippe. 2014. GlobalPhone: Pronunciation Dictionaries in 20 Languages. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation (LREC’14), May 2014. European Language Resources Association (ELRA), Reykjavik,
Iceland, 337–341. Retrieved September 8, 2024 from http://www.lrec-conf.org/proceedings/lrec2014/pdf/1212_Paper.pdf
[104] George R. Seaton and David A. Wayne. 1975. Techniques For Driving Digital Displays. February 01, 1975. SAE International.
https://doi.org/10.4271/750367
[105] Bu-Yong Shin and Jinhan Kim. 2012. Introducing a new script system for computer communication. In 2012 International Conference on ICT
Convergence (ICTC), October 2012. 181–186. https://doi.org/10.1109/ICTC.2012.6386812
[106] Sebastian Stuker, Teresa Herrmann, Munstin Kolss, Jan Niehues, and Matthias Wolfel. 2012. Research Opportunities In Automatic Speech-To-
Speech Translation. IEEE Potentials 31, 3 (May 2012), 26–33. https://doi.org/10.1109/MPOT.2011.2178192
[107] Ching Y. Suen. 1982. Computational analysis of Mandarin sounds with reference to the English language. In Proceedings of the 9th conference
on Computational linguistics - Volume 1 (COLING ’82), July 05, 1982. Academia Praha, CZE, 371–376. https://doi.org/10.3115/991813.991873
[108] Alberto Testolin, Kuinan Hou, and Marco Zorzi. 2024. Visual Enumeration is Challenging for Large-scale Generative AI.
https://doi.org/10.48550/arXiv.2402.03328
[109] Harold Thimbleby. 2013. Reasons to question seven segment displays. In Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems (CHI ’13), April 27, 2013. Association for Computing Machinery, New York, NY, USA, 1431–1440.
https://doi.org/10.1145/2470654.2466190
[110] Noriko Umeda. 1975. Vowel duration in American English. The Journal of the Acoustical Society of America 58, 2 (August 1975), 434–445.
https://doi.org/10.1121/1.380688
[111] Yufei Wang, Chunhao Zhang, Jieyi Huang, Mengyue Wu, and Kenny Zhu. 2023. Towards Lexical Analysis of Dog Vocalizations via Online
Videos. https://doi.org/10.48550/arXiv.2309.13086
[112] In-sung Woo, Chwa-cheul Shin, Heung-soon Kang, Seong-soo Hong, and Suk-dong Kim. 2007. International Phoneticizing Engine Technology
through Language Independent Lexical Acquisition. In 2007 International Conference on Multimedia and Ubiquitous Engineering (MUE’07),
April 2007. 226–231. https://doi.org/10.1109/MUE.2007.141
[113] Christopher Woods (Ed.). 2010. Visible Language: Inventions of Writing in the Ancient Middle East and Beyond: 32. Oriental Institute of the
University of Chicago, Chicago, Ill.
[114] Yiqi Wu, Xiaodan Hu, Ziming Fu, Siling Zhou, and Jiangong Li. 2024. GPT-4o: Visual perception performance of multimodal large language
models in piglet activity understanding. https://doi.org/10.48550/arXiv.2406.09781
[115] Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, Yaru Niu, Tingnan Zhang, Fei Xia, Jie Tan, and Ding Zhao. 2023. Creative
Robot Tool Use with Large Language Models. https://doi.org/10.48550/arXiv.2310.13065
[116] Kaisheng Yao and Geoffrey Zweig. 2015. Sequence-to-Sequence Neural Net Models for Grapheme-to-Phoneme Conversion.
https://doi.org/10.48550/arXiv.1506.00196
[117] Shaokai Ye, Jessy Lauer, Mu Zhou, Alexander Mathis, and Mackenzie W. Mathis. 2023. AmadeusGPT: a natural language interface for
interactive animal behavioral analysis. https://doi.org/10.48550/arXiv.2307.04858
[118] Sevinj Yolchuyeva, Géza Németh, and Bálint Gyires-Tóth. 2019. Grapheme-to-Phoneme Conversion with Convolutional Neural Networks.
Applied Sciences 9, 6 (January 2019), 1143. https://doi.org/10.3390/app9061143
[119] Piotr Żelasko, Siyuan Feng, Laureano Moro Velazquez, Ali Abavisani, Saurabhchand Bhati, Odette Scharenborg, Mark Hasegawa-Johnson, and
Najim Dehak. 2022. Discovering Phonetic Inventories with Crosslingual Automatic Speech Recognition.
https://doi.org/10.48550/arXiv.2201.11207
[120] Willem Zuidema, Dieuwke Hupkes, Geraint Wiggins, Constance Scharff, and Martin Rohrmeier. 2019. Formal models of Structure Building in
Music, Language and Animal Songs. https://doi.org/10.48550/arXiv.1901.05180
[121] 2018. The social origins of language. Princeton University Press, Princeton, NJ, US. https://doi.org/10.1515/9781400888146
[122] International Encyclopedia of the Social & Behavioral Sciences. ScienceDirect. Retrieved September 6, 2024 from
http://www.sciencedirect.com:5070/referencework/9780080970875/international-encyclopedia-of-the-social-and-behavioral-sciences
[123] OIMP 32. Visible Language: Inventions of Writing in the Ancient Middle East and Beyond | Institute for the Study of Ancient Cultures.
Retrieved September 8, 2024 from https://isac.uchicago.edu/research/publications/oimp/oimp-32-visible-language-inventions-writing-ancient-
middle-east-and
[124] Full IPA Chart | International Phonetic Association. Retrieved August 20, 2024 from
https://www.internationalphoneticassociation.org/content/full-ipa-chart
[125] Describing Speech Sounds. Retrieved September 9, 2024 from
https://ccrma.stanford.edu/~rjc/pubs/audio_speech/Describing_Speech_Sounds.html
[126] UTN #19: Recommendations for Creating New Orthographies. Retrieved September 9, 2024 from https://www.unicode.org/notes/tn19/
[127] Recent Trends in Text to Speech Synthesis of Indian Languages – Helix. Retrieved September 9, 2024 from
http://helix.dnares.in/2019/07/01/recent-trends-in-text-to-speech-synthesis-of-indian-languages/
[128] The History of Writing - Title. Retrieved September 9, 2024 from https://www.ling.upenn.edu/courses/Fall_1998/ling001/Writinglect.html
[129] The World’s Oldest Alphabet: Hebrew as the - ProQuest. Retrieved September 9, 2024 from
https://www.proquest.com/docview/2048068294?sourcetype=Scholarly%20Journals
[130] Phonetics. Retrieved September 9, 2024 from https://www.csun.edu/~sk36711/WWW2/engl302/phon.htm
23