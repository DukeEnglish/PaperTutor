PILLAR: AN AI-POWERED PRIVACY THREAT MODELING TOOL
MajidMollaeefara,AndreaBissolia,andSilvioRanisea, b
a FBK-CenterforCybersecurity,Trento,Italy.
bDepartmentofMathematics,UniversityofTrento,Trento,Italy.
{mmollaeefar, abissoli, ranise}@fbk.eu
ABSTRACT
TherapidevolutionofLargeLanguageModels(LLMs)hasunlockednewpossibilitiesforapplying
artificialintelligenceacrossawiderangeoffields,includingprivacyengineering.Asmodernappli-
cationsincreasinglyhandlesensitiveuserdata,safeguardingprivacyhasbecomemorecriticalthan
ever. Toprotectprivacyeffectively,potentialthreatsneedtobeidentifiedandaddressedearlyinthe
systemdevelopmentprocess. FrameworkslikeLINDDUNofferstructuredapproachesforuncover-
ingtheserisks,butdespitetheirvalue,theyoftendemandsubstantialmanualeffort,expertinput,and
detailedsystem knowledge. This makesthe processtime-consumingandproneto errors. Current
privacythreatmodelingmethods,suchasLINDDUN,typicallyrelyoncreatingandanalyzingcom-
plexdataflowdiagrams(DFDs)andsystemdescriptionstopinpointpotentialprivacyissues. While
theseapproachesarethorough,theycanbecumbersome,relyingheavilyontheprecisionofthedata
providedby users. Moreover,they often generate a long list of threats without clear guidance on
howtoprioritizethem,leavingdevelopersunsureofwheretofocustheirefforts.Inresponsetothese
challenges,we introducePILLAR(PrivacyriskIdentificationwithLINDDUN andLLM Analysis
Report),anewtoolthatintegratesLLMswiththeLINDDUNframeworktostreamlineandenhance
privacythreatmodeling.PILLARautomateskeypartsoftheLINDDUNprocess,suchasgenerating
DFDs, classifyingthreats,andprioritizingrisks. ByleveragingthecapabilitiesofLLMs,PILLAR
can take natural language descriptions of systems and transform them into comprehensive threat
models with minimal input from users, reducing the workload on developers and privacy experts
whileimprovingtheefficiencyandaccuracyoftheprocess.
Keywords PrivacyThreatModeling·LargeLanguageModel·RiskAssessment
1 Introduction
In today’s digital landscape, privacyhas become a paramountconcernas applicationsincreasinglyhandle sensitive
userdata. Ensuringrobustprivacyprotectionrequiresidentifyingandmitigatingpotentialprivacythreatsduringthe
early stages of system development. Privacy threat modeling frameworks, such as LINDDUN [1], provide struc-
turedapproachestouncoverandaddressthesethreats. However,despitetheirstructuredmethodologies,theseframe-
worksoftenrequiresignificantmanualeffort,expertknowledge,anddetailedsystemdescriptions,whichcanbetime-
consumingandpronetooversight.
Existingprivacythreatmodelingapproaches,includingLINDDUN,involvecreatingandanalyzingdetaileddataflow
diagrams(DFDs)andothersystemdescriptionstoidentifypotentialprivacyrisks.Whileeffective,thisprocessisoften
cumbersomeanddependsheavilyontheaccuracyandcompletenessoftheinputprovidedbyusers.Additionally,these
methodscanstrugglewiththe prioritizationofidentifiedthreats, leadingto anoverwhelminglist ofpotentialissues
withoutclearguidanceonwhichtoaddressfirst.
Toaddressthesechallenges,weproposePILLAR(PrivacyriskIdentificationwiththeLINDDUNandLLMAnalysis
Report),anoveltoolthatintegratesLargeLanguageModels(LLMs)withtheLINDDUNframeworktoautomateand
enhancetheprivacythreatmodelingprocess.PILLARisdesignedtosimplifytheidentificationandanalysisofprivacy
threatsbyautomatingkeyaspectsoftheLINDDUNmethodology,suchasthegenerationofDFDs,thecategorization
4202
tcO
11
]RC.sc[
1v55780.0142:viXraPILLAR:anAI-PoweredPrivacyThreatModelingTool
ofthreats,andtheprioritizationofrisks. ByleveragingLLMs,PILLARcanprocessnaturallanguagedescriptionsof
systems to producedetailed threatmodelswith minimaluser input, reducingthe burdenon developersand security
researchers.
Ourtoolintroducesaninnovativeapproachtothreatmodelingbysimulatingmulti-agentcollaborationamongvirtual
experts,eachfocusedondifferentaspectsofprivacythreats. InPILLAR,virtualagents,suchasaprivacyexpertora
developer,communicateanddebateprivacyrisksusingdistinctbutcomplementaryperspectives.Thisstructurereflects
thecooperativecommunicationparadigmoutlinedbyGuoetal.(2024)[2],wheremultipleagentscooperatetoachieve
asharedgoalthroughinteractionsandknowledgesharing.Bysimulatingmultipleroundsofcommunicationbetween
agents, PILLAR reduces the likelihood of overlookingcritical privacy risks, mirroring the real-world collaborative
effortsbetweenstakeholdersinprivacythreatmodeling. Thisapproachenablesthetooltocaptureabroaderrangeof
potential threats by allowing agents to deliberate and adjust their insights iteratively, leading to more thoroughrisk
assessments.
In this work, we present the design and implementation of PILLAR, which introduces several key innovations to
enhanceandstreamlinetheprivacythreatmodelingprocess:
• AutomatedApplicationDescription:PILLARenablesuserstoinputanaturallanguagedescriptionoftheir
application,includingdetailsonthetype(e.g.,mobileapp,webapp),thedataitcollects,anditsdatapolicies.
Thisautomationhelpsreducemanualeffortandensuresaccuratesystemdescriptions.
• DataFlow Diagram(DFD)Management: Userscan upload,edit, generatefromanimageordescription,
and download DFDs, which are essential for identifying privacy threats. This flexibility streamlines the
modelingandvisualizationofsystemdataflows.
• LINDDUNAnalysisAutomation: PILLARfacilitatesquickandstructuredLINDDUNanalyseswithinthe
platform,simplifyingtheprocessofidentifyingpotentialprivacyrisks.
• LINDDUN Go Simulation: By incorporatingLLM agents, PILLAR offersLINDDUN Go simulationsto
evaluateprivacythreatsdynamically,allowingforscenario-basedanalysiswithmultiplevirtualagentswork-
ingcollaboratively.
• LINDDUNProMethodology: Formoreadvancedthreatidentification,PILLARintegratestheLINDDUN
Promethodology,allowinguserstoperformpreciseandthoroughthreatanalysesusingDFDs.
• ImpactAssessment andControlMeasures: PILLARprovidestoolsforassessingtheimpactofidentified
threatsandsuggestscontrolmeasuresbasedonestablishedprivacypatterns,guidingusersinmitigatingrisks
effectively.
• ComprehensiveReportGeneration:Finally,PILLARallowsuserstogenerateanddownloadadetailedre-
portsummarizingtheentireprivacythreatmodelingprocess,includingidentifiedthreats,impactassessments,
andrecommendedcontrolmeasures,aidingindocumentationandcomplianceefforts.
ThesecontributionsdemonstratePILLAR’spotentialtoautomate,simplify,andenhancetheprivacythreatmodeling
process, makingit moreaccessible andefficientfordevelopers,privacyexperts, andsecurityresearchersalike. Fur-
thermore, we implemented PILLAR as a web-based tool which offers a friendly user interface (UI) to its users by
utilizinganinteractivewebapplicationframework.
Theremainderofthispaperisorganizedasfollows:Section2providesanecessarybackgroundonthreatmodelingand
LargeLanguageModels. Section3detailsthearchitectureandfunctionalityofthePILLARtool. Section4presents
ourcase studiesand evaluationresults. Related workis discussedin Section 4. Finally, Section 4 concludeswith a
discussionoffutureworkandpotentialenhancements.
2 Background
Inthissection,wefocusontwoprimaryareas:theimportanceofthreatmodelingincybersecurityandprivacy,andthe
applicationofLargeLanguageModelstoenhancethethreatmodelingprocess. Bycombiningthese methodologies,
weaimtoaddressthechallengesinidentifyingandmitigatingprivacyrisksefficientlyandeffectively.
2.1 ThreatModeling
Threatmodelingisafoundationalpracticeincybersecurityandprivacymanagement,providingastructuredmethod-
ologytoidentify,assess, andmitigatepotentialriskswithinasystem,andsupportinensuringcompliancewithregu-
lationssuchastheGeneralDataProtectionRegulation[3](GDPR).Itiscrucialforseveralreasons: First,itenables
2PILLAR:anAI-PoweredPrivacyThreatModelingTool
organizationstoidentifyvulnerabilitiesbyanalyzingsystemarchitectureandpotentialattackvectors,helpingtopin-
pointweakspotsthatcouldbeexploitedbyadversaries. Second,threatmodelingallowsfortheprioritizationofrisks
based on both their potential impact and likelihood, ensuring that resources are allocated effectively to address the
most critical vulnerabilities. Third, it fosters clear communication among various stakeholders, including develop-
ers, securityteams,andmanagement,ensuringthatallpartiesunderstandtherisksandthecorrespondingmitigation
strategies. Moreover,threatmodelingsupportscompliancewithregulatoryrequirements,asmanylegalframeworks
mandate comprehensive risk assessments. Finally, threat modeling is not a one-time effort, it is a continuous pro-
cessthatshouldbeintegratedintothesoftwaredevelopmentlifecycle(SDLC),allowingforongoingassessmentand
adaptationtoemergingthreats.
There are several established methodologies for conducting threat modeling, each offering a distinct approach to
securityandprivacyriskidentification.Thesemethodologiesarewidelyadoptedinbothindustryandacademia:
• STRIDE[4]: Thisframeworkcategorizessecuritythreatsintosixdistincttypes: Spoofing,Tampering,Re-
pudiation,InformationDisclosure,DenialofService(DoS),andElevationofPrivilege.STRIDEispredomi-
nantlyusedtoidentifysecurityvulnerabilitiesinsoftwareapplications.
• PASTA[5]: TheProcessforAttackSimulationandThreatAnalysis(PASTA)emphasizessimulatingpoten-
tial attacks to understand their impact on business objectives. This methodology is more business-driven,
focusingonhowsecuritythreatsaffectanorganization’sgoalsandoperations.
• LINDDUN [6]: Specifically designed for privacy threat modeling, LINDDUN identifies privacy-specific
risks, including Linkability, Identifiability, Non-repudiation, Detectability, Disclosure of Information, Un-
awareness,andNon-compliance.Itoffersastructuredprocessforassessingprivacyrisksinsystems,aligning
withregulationsliketheGeneralDataProtectionRegulation(GDPR).
2.2 TheLINDDUNFramework
TheLINDDUNframeworkisacomprehensivetoolforconductingprivacythreatmodeling,allowingorganizationsto
systematicallyidentifyandmitigateprivacyrisksthroughoutthesoftwaredevelopmentlifecycle.LINDDUNoperates
intwomainphases:
• Problem Space: This phase involves creating Data Flow Diagrams (DFDs), mapping privacy threats to
elementswithin the DFD, andidentifyingpotentialthreatscenarios. DFDs offera visual representationof
howdataflowsthroughthesystem,highlightingpointswhereprivacyrisksmayarise.
• SolutionSpace: Inthisphase,identifiedthreatsareprioritized,mitigationstrategiesareelicited, andcorre-
spondingprivacy-enhancingtechnologies(PETs)areselected. LINDDUN’sstructuredmethodologyensures
thatprivacyconsiderationsareintegratedintoboththedesignandimplementationphasesofsoftwaresystems.
To serve different needs, LINDDUN comes in various flavors. These approaches vary in complexity and compre-
hensiveness, ranging from lean to in-depth analysis. LINDDUN framework can be applied through three different
methods1,GO,PRO,andMAESTRO.LINDDUNGOtakesonalean,cross-teamapproachinfindingprivacyissues.
GOcomesintheformofa“carddeck"representingthemostcommonprivacythreats,withthekeyhotspotstolookfor
inyoursystem. Theseself-containedcardswillguideyouthroughtheprivacyassessment. LINDDUNPROtakeson
asystematicandexhaustiveapproachinfindingprivacyissues. ThestartingpointisaDFDsystemabstraction,where
youfocuson all interactionsbetween DFD elementsand investigatepotentialprivacythreats. Available knowledge
support: privacy threat types, privacy threat trees, mapping table. PRO allows you to leverage tooling to automate
your analysis activities. Best performed in a structured brainstormingsetting with a diverse team of privacy enthu-
siasts. LINDDUNMAESTROtakesona systematicandexhaustiveapproachinfindingprivacyissuesbyleveraging
an enriched system description to enable more precise threat elicitation. Starting point is a threat-specific system
abstraction,tosupporttheadvancedanalysisforthreatsofthatparticulartype.
By now, only the first two methods of this framework is available. Despite its thoroughness, LINDDUN can be
resource-intensive,requiringdetailedknowledgeofsystemarchitecture,significantmanualeffortindiagramcreation,
and expertise to interpret results effectively. These challenges, while manageable for privacy experts, may present
obstaclesfororganizationslackingspecializedresources.
1https://linddun.org
3PILLAR:anAI-PoweredPrivacyThreatModelingTool
2.3 PrivacyPatterns
InadditiontostructuredframeworkslikeLINDDUN,privacypatterns2 haveemergedasausefultoolforenhancing
privacypracticesduringsystemdesign.Privacypatternsarereusablesolutionstocommonprivacy-relatedchallenges,
suchasdataminimization,userconsent,andtransparency.Byadoptingthesepatterns,developerscanaddressspecific
privacyconcernsandimprovecompliancewithprivacyregulations. Moreover,theuseofprivacypatternsencourages
aproactiveapproachtoprivacy,embeddingbestpracticesintosystemdesignsfromtheoutset.
2.4 LargeLanguageModels
LargeLanguageModels(LLMs)representasignificantadvancementinnaturallanguageprocessingandhaveshown
potentialfor a variety of applicationsin the field of security. LLMs, such as GPT-4, are built on transformerarchi-
tecturesthatallowthemtoprocessvastamountsoftextdataandlearncomplexlinguisticpatterns. Thesemodelsare
typicallytrainedonmassivedatasets,comprisingbillionsofwords,enablingthemtogeneratecoherentandcontextu-
allyrelevanttext.
LLMsareparticularlywell-suitedfortasksinvolvingtheanalysisofsystemdocumentation,thegenerationofcodeor
systemmodels,andtheidentificationofsecurityandprivacyvulnerabilities. Theirabilitytounderstandandgenerate
human-liketextmakesthemavaluabletoolforautomatingprocessesthattraditionallyrequiredexpertinput,suchas
privacythreatmodeling.
However,theuseofLLMsisnotwithoutchallenges. Thesemodelscaninheritbiasesfromtheirtrainingdata,which
raisesconcernsaboutfairnessandaccuracyintheiroutputs. Additionally,whileLLMsexcelatgeneratingcoherent
responses,theymaynotalwaysproducetechnicallyaccurateorunbiasedresultswithoutcarefulpromptengineering
andrefinement.
2.5 PromptEngineering
PromptengineeringreferstothedesignandrefinementofinputqueriestoguidetheoutputofLLMs. Well-structured
promptscansignificantlyimprovethequalityoftheresponsesproducedbyLLMs,whileiterativerefinementcanbe
usedtofurtherenhanceperformance.Keyaspectsofpromptengineeringinclude:
• StructureandClarity: Clear andstructuredpromptshelpguidethe model’soutputtowardsspecificareas
ofinterest,improvingtherelevanceofthegeneratedresponses.
• IterativeRefinement:Promptengineeringofteninvolvesmultipleiterationstorefinethepromptandachieve
thedesiredoutcome. Thismayincludeadjustingthewording,providingexamples,orspecifyingtheformat
oftheoutput.
• Impact onPerformance: Researchhasshownthatpromptdesigncansignificantlyaffecttheperformance
of LLMs, making promptengineeringan essential skill for developersand researchersworkingwith these
models.
By leveraging effective prompt engineering, LLMs can be utilized in privacy threat modeling to produce accurate,
relevant results with minimal manual effort, reducing the burden on developersand privacy experts while ensuring
alignmentwithethicalandoperationalstandards.
3 Tool Architecture
Figure 1 illustrates the tool architecture which has 4 main phases, namely, System Description, Threat Elicitation,
ImpactAssessment,andReportCreation. Weusedacolorcodetobetterspecifytheprocessesofeachphase. Below
wedescribeeachphaseindetail.
3.1 Implementation
PILLAR3 has been developed with ease of experimentation and functionality in mind. The Python programming
languagehasbeendevisedastheoptimalchoiceforthispurpose,duetoitshighprototypingspeedanditswidespread
adoption as a standard tool for machine learning development and interfacing. To offer PILLAR users a familiar
2https://privacypatterns.org
3https://github.com/stfbk/PILLAR
4PILLAR:anAI-PoweredPrivacyThreatModelingTool
Application
Guided Text Input Co Dll ee sc cte ripd t iD oa nta Description
System
Description DFD From
Manual Graph Description
Building
Application Info Tab
DFD Graph
From CSV File Input
DFD Tab
From PNG/JPG
Image Input
Insert LLM API Keys
Ze W Cro i lt a- hs s h L so I iN ft i cDP ar D to ioUm nNpt Sim Elp icle it aT tih or neat Threat Model Output
LINDDUN Go Simulation
Spawn A M gu el nti tp sle LLM O FCb roata mrdin EQ A aun ces hsw t Aie o gr ns es nt o t
Repeat For # Of Rounds Ju Fd ing ae l P Vr eo rd du icc tes
Yes Incl Iu nd Te h T eh Pe r A omna ply tsis " FP rr oeA mvs i o Ts ue hsm e A b Anl ne a s la y w s eis rs" LINDDUN Go Output
Threat Card Is "Drawn" Multi-Agent
Elicitation
At Least
One
No Repeat For # Of Cards
Threat Model Tab O Cb ata ri dn QA un esw ste ior ns sto Threat Elicitation
LINDDUN Go Tab
LINDDUN Pro Tab
LINDDUN Pro Process
DFD Edge Selection C Th ho reo as tin Cg a R tee gle ov ria en st DD ea st ca r iF pl to iow n Tree G-B ea ns ee rad t iT oh nreat LINDDUN Pro Output
Repeat Until Satisfied
Impact Assessment
Impact
Assessment
Threat Selection Impa Gc et nA es rs ae tis os nm ent M Ro ed qifi uc ia reti don No A Pp ap tli tc ea rnb sle C P hr oiv ica ecy MeS asp ue rc eif sic G C eo nn et rr ao tl ion
Impact Assessment Tab At O L ne east Threat List Import
Yes
Manual Repeat For All Threats
Modification
Report
Creation
Adding General Final Report
Information
Report Tab
Legend
Process Output "AC t o L Cn e hd a ei sti cto kOna nl e" Co Sn wdi it ti co hnal Process Output LLM-Powered Process
User
Figure1:Tool’sarchitecture.
5PILLAR:anAI-PoweredPrivacyThreatModelingTool
interface,wedevelopeditasawebapplicationusingtheStreamlit4framework.Manyotherlibrariesforthelanguage
have been used for specific PILLAR features, such as Graphviz5 for DFD graph display and modification, csv to
handlefilesin the format, markdownandpdfkit forthe finalreportcreation. Additionally,theLLM functionalityis
accomplished by using the Python libraries developed by the LLM providers. PILLAR currently supports models
offeredbyOpenAI,GoogleGeminiandMistral.
3.1.1 Streamlit
TheuseofStreamlitprovedhighlyadvantageousincreatinganinteractiveinterfacewithminimalcodingrequirements
andallowedtohaveacleareroutlineofthenecessarypartsoftheapplication. Furthermore,theinterfaceisclearand
modern, with intuitivefields and interactivity, as well as fully responsive. Nonetheless, the frameworkforcessome
constraintsontheapplication’sappearanceandfunctionality.Someworkaroundshavebeennecessaryto,forexample,
defer the report’sgenerationuntilthe downloadbutton is pressed, or layingout items correctlyin the interface. Of
course,theselimitationsaredirectlycorrelatedwithStreamlit’seaseofuseanddonotsignificantlycompromisethe
finalresult.
3.1.2 LLMproviders
The primary LLM providerused throughoutthe application is OpenAI6. The company has established itself as the
current de facto standard for LLM-based applications and offers robust developer experience for interactions with
its models. During PILLAR’s development, the gpt-4o-mini model has been released, which greatly improves the
responsequalityandcost-effectivenessofourtoolcomparedtoitspredecessor,GPT-3.5-turbo.PILLARalsosupports
the other OpenAI models, such as gpt-4o, for increased accuracy at a higher cost. Another state-of-the-art feature
integrated into PILLAR is OpenAI’s Structured Output: a JSON schema is specified for the LLM output and the
correctformatisguaranteedtobeobtained,allthankstotherecentlyupgradedAPIprovidedbyOpenAI.
For some functionalities, such as the simple threat modeling or multi-agent LINDDUN GO, Google Gemini7 and
Mistral8 can be used as LLM providers in PILLAR. These providers offer simple Python integration and similar
servicestoOpenAI,butatthepresenttimedonothavecomparablestructuredmodeloutputguarantees.
3.2 Usage
PILLARismeanttobeoperatedinamostlylinearfashion,traversingthephasesoutlinedinFigure1,byauserwhohas
knowledgeaboutthesystemtobeanalyzed. AnOpenAIAPIkey(withavailablecredit)isrequiredforfunctionality,
whileGoogleGeminiandMistralkeysareonlyrecommendedforcertainfeatures.AllAPIkeysshouldbeinsertedin
PILLAR’ssidebarview. Next,wegothrougheachphase.
3.2.1 SystemDescription
Theuserneedstodescribethesystemtobeanalyzed,suchthatthesubsequentthreatelicitationcanbeperformed.Nat-
urally,themoredetailedinformationprovidedaboutthesystem,includingspecifictechnicaldetailsandassumptions
aboutthedata,themorelikelytheresultingoutputwillbeofhigherquality.
Thefirstwaytodescribethesystem’sfeaturesisbyfillingoutthefieldsintheApplicationInfotab. Thesefieldsguide
theuserininsertingvaluableprivacy-relatedinformationaboutthesystem,usefulfortheLLMtobemoreprecisein
theresponses. Itisalsopossibletodescribe,throughatableinterface,thetypesofdatacollectedbythesystemand
otherdetailsassociatedwiththem,agreatlyimportantaspectofprivacythreatmodeling.
ThesystemdescriptioncanalsobeprovidedintheformofaDataFlowDiagram(DFD),throughtheDFDtab. The
taballowsformanualeditingoftheDFDthroughanedge-basedtable,aswellasvisualizationoftheDFDgraph.The
DFDcanalsobeLLM-generatedbasedoneitherthetextualsystemdescription,ifalreadyprovided,oronanimageof
theDFD,leveraginggpt-4o’svisioncapabilities. OncetheDFDhasbeengeneratedfromtheseways,itcanbefurther
perfectedandtailoredtofitthesystem.
BothtableinterfacesallowuserstodownloadtheircontentsasCSVfilesanduploadonesuchfileastheirnewcontent.
Thisway,theycanbeeditedorgeneratedinanotherprogram,orconservedforfutureanalysisonthesamesystem.
4https://streamlit.io
5https://graphviz.org
6https://openai.com
7https://gemini.google.com
8https://mistral.ai
6PILLAR:anAI-PoweredPrivacyThreatModelingTool
Theseinputmethodsaredesignedtominimizetheeffortrequiredforuserstodescribethesystem,whilestillallowing
forprecisionandrefinementifdesired.Oneofthebiggestchallengesinthreatmodelingisgettingdeveloperstoengage
withandfollowthenecessarystepsintheprocess,whichoftenrequiressignificantworkandsecurityknowledge[7].
PILLARaimsto alleviatethisissue withLLMs’ supportandease ofuse, streamliningtheprocessandreducingthe
burdenonusers.
3.2.2 ThreatElicitation
Afterthesystemdescriptionhasbeenprovided,threatshavetobeelicitedfollowingtheLINDDUNframework.With
eitherthetextualsystemdescriptionortheDFD(orboth),asimplethreatmodelingandLINDDUNGOareavailable.
LINDDUNPROrequirestheDFDasaninput.
IntheThreatModeltab,abasiczero-shotprivacythreatmodelcanbeobtained.TheLLMusesthesystemdescription
providedandidentifiesthreatswithafocusoneachofLINDDUN’sthreatcategories. Theoutputisgenerallyunspe-
cificbutcanbeaquickinitialinsightonthetypesofthreatstobeawareof,whilestillminimizingtherequiredeffort
fromtheuser.
In the LINDDUN Go tab, the wholeprocessdescribedbythe LINDDUNGO methodcan be simulated throughthe
useofLLMs. TheusercanspecifytheamountofcardstoextractfromtheLINDDUNGOdeckandwhetherornot
tocarryoutamulti-agentsimulation. Then,cardsuptothenumberspecifiedareselectedfromthedeck,carryingout
theprocessforeachcard.
In the single-agent simulation, each card’s description and information is provided to the LLM, together with the
systemdescription.TheLLM’staskistodeterminewhetherornotthethreatcontainedinthecardispresentornotin
thesystemandthereasonforeitherdecision. Therefore,theoutputspecifieswhichthreatsarerelevantandwhythey
shouldbetakenintoconsideration.
Themulti-agentsimulationenactsnotonlyGO’scard-basedelicitationbutalsotheteambrainstormingaspectofthe
methodology. Foreach card, differentLLMagentsare spawned, eachwith a differentpromptthatsuggestsits area
of expertise and focus, just like real-life membersof a privacy threat modeling team. Each of them carries out the
single-agentanalysisfocusingontheaspectsimportanttotheirownarea. Onceallanswershavebeencollected,they
aregatheredin a previousanalysis. Multipleroundsofthe analysisarethenperformedandeverytime theprevious
analysis obtained from the previous round is supplied as additional input to each agent. This process recreates a
discussionbetweenthe LLMs, providinga chanceto sharethedifferingopinionsresultingfromdifferentaspectsof
thethreat,andincreasingtheaccuracyoftheelicitationprocess. Afterthespecifiednumberofroundsisreached,the
lastpreviousanalysisissuppliedtoajudgeLLMagent,whosetaskisonlytodeterminethefinalverdictaftertaking
intoaccountthefinalopinionsfromallagents.
Duringthemulti-agentanalysis,ifspecified,LLMagentsarerandomlyselectedfromthedifferentproviders,toadd
variabilityintheoutputandraisemoreinterestingviews.
TheLINDDUNPROtabmakesitpossibletoperformthefullLINDDUNPROprocessbasedonthesystemDFD.In
thismethod, the userselects an edgeto analyzeand specifiesoneor moreLINDDUNcategoriesto assess potential
threats. AdescriptionofthespecificdataflowalsoneedstobeaddedfortheLLMtounderstandhowdataishandled
throughoutthesystem. Oncealloftheinformationisprovided,theusercanobtainaprobablethreatofthespecified
categoryatthedifferentlocations,namelysource,dataflow,anddestination.Theprocesscanberepeatedmanytimes,
withdifferentcategoriesandotherDFDedges.
Underthehood,PILLARusestheLINDDUNmappingtable9todecidewhetherathreatassessmentisapplicablefor
acertainDFDedge. Furthermore,theLLMreceivesaversionofLINDDUN’sthreattrees10andbasesitsanalysison
theirnodes.Whenpresentingthethreat,theoutputalsoincludesthespecificthreattreenodewheretheLLMidentified
thethreat.
3.2.3 ImpactAssessment
Oncethreatshavebeenelicited,withanyoneofthemethodologiesofferedbyPILLAR,intheImpactAssessmenttab
theusercanimportthethreatsfoundtoproceedwiththeprivacyimpactassessment. Ifmultiplemethodologieswere
used,theusercanselectoneofthemasthesourceforthethreats.
9https://downloads.linddun.org/tutorials/pro/v0/mappingtable.pdf
10https://linddun.org/threat-trees
7PILLAR:anAI-PoweredPrivacyThreatModelingTool
Thethreatscanbebrowsedthroughtheinterfaceanditispossibletochoosewhetherornottoincludetheminthefinal
report. WiththeLLM,itispossibletogeneratetheimpactassessmentforthethreat,whichcanalsobemodifiedby
theuserastheyseefit.
Controlmeasuresfor the threatare generatedusing privacypatterns. Initially, the LLM receivesas inputthe threat,
the system descriptionand a brief description of each privacypattern. This approachminimizestoken usage while
allowing the LLM to generate a list of potentiallyrelevantpatternsfor addressingthe threat. Subsequently,a more
detailedrequestissenttotheLLMwiththefullinformationfortheselectedprivacypatterns,andtheLLMperforms
a further selection among them, as well as offering reasons for each pattern’s relevance and guidelines on how to
implementitwithinthesystem.
3.2.4 ReportCreation
PILLARoffers, asa finalresultforthe user, a PDFreportcontainingallthe elicited threatsthatwere chosenin the
previousimpactassessment,aswellastheadditionalinformationassociatedtoeachofthem. Additionally,thereport
containssomegeneralinformation,whichneedstobeprovidedintheReporttab.Ifitisdeemeduseful,thereportcan
alsoincludetheDFDgraph.
Onceitisdownloaded,thereportcanbereferencedaseitherastartingpointforfurtherprivacythreatmodelingoras
aguidetocontaintheelicitedprivacythreats.
4 Related Work
TheintegrationofLLMsintothefieldofcybersecurityhasgarneredconsiderableattentionduetotheirabilitytopro-
cess and analyze vast datasets. As cyber threats become more sophisticated, the cybersecuritydomain increasingly
turnstotheseadvancedmodelstostrengthendefenses. Cybersecurityprofessionalscontinuallyseekinnovativesolu-
tionstoimplementrobustpoliciesandenhancetechnologicalsafeguards[8]. Theseeffortsareessentialforpreventing
theunauthorizeddisclosureofsensitiveinformation,unauthorizedaccess,andvariousformsofdatamanipulation[9].
TheabilityofLLMstoadaptandscaleisparticularlyvaluableforaddressingthegrowingcomplexityofcyberthreats.
ThefollowingsectionshighlightkeyapplicationsofLLMsincybersecurity,summarizefindingsfromrecentresearch,
anddiscussnotabletoolsleveragingLLMstoimprovesecurity.ApplicationsofLLMsincybersecurityinclude:
• VulnerabilityDetection:LLMscananalyzecodeandsecurityadvisoriestoidentifypotentialvulnerabilities
insoftwaresystems.
• MalwareAnalysis: Thesemodelsassistinclassifyingandanalyzingmalwarebyrecognizingcomplexdata
patterns.
• NetworkIntrusionDetection: LLMscanprocessnetworktrafficdatato detectanomaliesthatmaysignal
potentialintrusions.
• PhishingDetection:Byanalyzingtextualpatterns,LLMscandetectphishingattemptswithgreaterprecision
thantraditionalmethods[10,11].
AlthoughtheapplicationofLLMsshowspromisingadvancements,researchsuggestschallengesremain,suchasthe
needforlargertrainingdatasetsandmoreinterpretablemodels.Futureworkisexpectedtofocusonimprovingmodel
explainability,addressingprivacyconcerns,anddevelopingproactivedefensemechanismsagainstcyberthreats.
One significant application of LLMs in network security is web fuzzing. For example, Liang et al. [12] proposed
GPTFuzzer,whichusesanencoder-decoderarchitecturetogenerateeffectivepayloadsforwebapplicationfirewalls
(WAFs). It specifically targets vulnerabilities such as SQL injection, cross-site scripting (XSS), and remote code
execution(RCE)bygeneratingfuzztestcases. AnothernotableuseofLLMsisindetectingnetworktrafficanomalies.
Liu et al. [13] developed a method to detect malicious URLs by leveraging LLMs to extract hierarchical features.
Thisworkextendsthe useof LLMsin intrusiondetectiontasksto the userlevel, demonstratingtheirgeneralityand
effectivenessinintrusionandanomalydetection.
Ascyberthreatsgrowincomplexity,traditionalCyberThreatIntelligence(CTI)methodsstruggletokeeppace. AI-
based solutions, including LLMs, offer an opportunity to automate and enhance several tasks, ranging from data
ingestion to resilience verification. LLMs have shown promise in generating CTI from various sources, including
networksecuritytexts(e.g.,books,blogs,news)[14],generatingstructuredreportsfromunstructureddata[15],and
extracting intelligence from network security entity graphs [16]. Aghaei et al. [17] introduced CVEDrill, which
generatespriorityrecommendationreportsforcybersecuritythreatsandpredictstheirpotentialimpact. Furthermore,
8PILLAR:anAI-PoweredPrivacyThreatModelingTool
Moskal et al. [18] examined the use of ChatGPT in assisting or automating decision-making in response to threat
behaviors,illustratingthepotentialofLLMsinhandlingsimplenetworkattackscenarios.
In the context of vulnerability detection, Liu et al. [19] proposed LATTE, which combines LLMs with automated
binarytaintanalysis. LATTEovercomesthelimitationsoftraditionaltaintanalysis,whichoftenrequiresmanualcus-
tomizationoftaintpropagationandvulnerabilityinspectionrules. Phishingandscamdetectionisanotherareawhere
LLMsdemonstratesignificantutility. Labonneetal.[20]highlightedtheeffectivenessofLLMsinspamemaildetec-
tion, showcasing their superiority over traditional machine learning approaches. Additionally, Cambiaso et al. [21]
presentedan innovativestudysuggestingthatLLMscan mimic humaninteractionswith scammersin an automated
yetmeaninglessmanner,wastingscammers’timeandresources,andtherebyreducingtheimpactofscamemails.
DetectionandIntelligenceAnalysisforNewAlerts11 (DIANA)isanotherrecentlydevelopedtoolthatautomatesthe
creation of detections from threat intelligence using LLMs. In the context of modeling security threats, STRIDE-
GPT12 is another advanced tool that generates threat models and attack trees for a given application based on the
STRIDEmethodology.AttackGen13isacybersecurityincidentresponsetestingtoolthatleveragesthepoweroflarge
languagemodelsandthecomprehensiveMITREATT&CKframework14.Thetoolgeneratestailoredincidentresponse
scenariosbasedonuser-selectedthreatactorgroupsandyourorganisation’sdetails.
AframeworkthatleveragesmultipleintelligentLLMagentsworkingcollaborativelycanenhancetheefficiencyand
effectivenessofhandlingcomplextasks. Thisapproachaddressesvariouschallengessuchassecurityrisks,scalability,
andsystemevaluation,showcasingthepotentialforadvancedapplicationsincybersecurity[22].Forinstance,authors
in [23] introduced Audit-LLM, a multi-agent log-based insider threat detection (ITD) framework comprising three
collaborativeagents,whereitdetectsmalicioususeractivitiesbyauditinglogentries.
5 Conclusion
Inthispaper,wepresentedPILLAR,anAI-poweredprivacythreatmodelingtooldesignedtoautomateandenhance
theprivacyriskidentificationprocessbyintegratingtheLINDDUNframeworkwithlargelanguagemodels.PILLAR
addresses the limitations of traditional privacy threat modeling approaches, which often require substantial manual
effort,expertknowledge,anddetailedsystemdescriptions.
Byautomatingkeyprocessessuchasdataflowdiagramgeneration,threatidentification,andriskprioritization,PIL-
LARreducestheworkloadfordevelopersandprivacyexperts,whileimprovingtheoverallefficiencyandaccuracyof
thethreatmodelingprocess. Thetool’sabilitytogenerateandanalyzeprivacythreatsfromnaturallanguagedescrip-
tionsofsystemsdemonstratesitspotentialtostreamlineprivacyassessments,particularlyfororganizationsthatmay
lackspecializedprivacyresources.
PILLARintroducesinnovativefeatures,suchasmulti-agentcollaborationusingLLMs,whichsimulatesexpertbrain-
stormingsessionstoproducemorecomprehensiveandpreciseprivacythreatanalyses.Additionally,theincorporation
ofadvancedprioritizationtechniquesensuresthatuserscanfocusonaddressingthemostcriticalprivacythreats,help-
ingtooptimizeresourceallocation.
Movingforward,futureenhancementstoPILLARwillincluderefiningtheaccuracyofthreatgenerationandexpand-
ing its interoperabilitywith otherprivacyand securitytools. Additionally,we aim to exploredeeperintegrationsof
LLMstofurtherreducemanualinputandimprovethreatmodelingaccuracy.Byaddressingthesegoals,PILLARwill
continueto evolveas a robusttoolfor privacythreatmodeling,enablingmoreorganizationsto securetheir systems
andcomplywithprivacyregulationssuchasGDPR.
References
[1] MinaDeng,KimWuyts,RiccardoScandariato,BartPreneel,andWouterJoosen.Aprivacythreatanalysisframe-
work:supportingtheelicitationandfulfillmentofprivacyrequirements. RequirementsEngineering,16(1):3–32,
2011.
[2] TaichengGuo,XiuyingChen,YaqiWang, RuidiChang,ShichaoPei, NiteshV Chawla,Olaf Wiest, andXian-
gliangZhang. Largelanguagemodelbasedmulti-agents: Asurveyofprogressandchallenges. arXivpreprint
arXiv:2402.01680,2024.
11https://github.com/dwillowtree/diana
12https://github.com/mrwadams/stride-gpt
13https://github.com/mrwadams/attackgen
14https://attack.mitre.org/
9PILLAR:anAI-PoweredPrivacyThreatModelingTool
[3] Regulation (eu) 2016/679 of the EUROPEAN parliament and of the council on the protection of nat-
ural persons with regard to the processing of personal data and on the free movement of such data.
https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679&from=EN,2016.
[4] AdamShostack. Threatmodeling:Designingforsecurity. JohnWiley&Sons,2014.
[5] TonyUcedaVelezandMarcoMMorana. Riskcentricthreatmodeling: Processforattacksimulationandthreat
analysis,2015.
[6] Kim Wuyts and Wouter Joosen. Linddun privacy threat modeling: a tutorial.
https://www.linddun.org/linddun,2015.
[7] DannyDhillon. Developer-driventhreatmodeling: Lessonslearnedinthetrenches. IEEESecurity&Privacy,
9(4):41–47,2011.
[8] RamanpreetKaur,DušanGabrijelcˇicˇ,andTomažKlobucˇar. Artificialintelligenceforcybersecurity: Literature
reviewandfutureresearchdirections. InformationFusion,97:101804,2023.
[9] Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Shaochen Zhong,
Bing Yin, and Xia Hu. Harnessing the power of llms in practice: A survey on chatgpt and beyond. ACM
TransactionsonKnowledgeDiscoveryfromData,18(6):1–32,2024.
[10] HanXiang Xu, ShenAo Wang, Ningke Li, Yanjie Zhao, Kai Chen, Kailong Wang, Yang Liu, Ting Yu, and
HaoYu Wang. Large language models for cyber security: A systematic literature review. arXiv preprint
arXiv:2405.04760,2024.
[11] Farzad NourmohammadzadehMotlagh, MehrdadHajizadeh, MehryarMajd, Pejman Najafi, Feng Cheng, and
ChristophMeinel. Largelanguagemodelsincybersecurity: State-of-the-art. arXivpreprintarXiv:2402.00891,
2024.
[12] HongliangLiang, XiangyuLi, Da Xiao, Jie Liu, Yanjie Zhou, Aibo Wang, and Jin Li. Generativepre-trained
transformer-basedreinforcementlearningfortestingwebapplicationfirewalls. IEEETransactionsonDepend-
ableandSecureComputing,21(1):309–324,2023.
[13] Ruitong Liu, Yanbin Wang, Haitao Xu, Zhan Qin, Yiwei Liu, and Zheng Cao. Malicious url detection via
pretrainedlanguagemodelguidedmulti-levelfeatureattentionnetwork. arXivpreprintarXiv:2311.12372,2023.
[14] EhsanAghaei,XiNiu,WaseemShadid,andEhabAl-Shaer. Securebert: Adomain-specificlanguagemodelfor
cybersecurity. In InternationalConference on Security and Privacy in CommunicationSystems, pages 39–56.
Springer,2022.
[15] GiuseppeSiracusano,DavideSanvito,RobertoGonzalez,ManikantanSrinivasan,SivakamanKamatchi,Wataru
Takahashi,MasaruKawakita, TakahiroKakumaru,andRobertoBifulco. Timeforaction: Automatedanalysis
ofcyberthreatintelligenceinthewild. arXivpreprintarXiv:2307.10214,2023.
[16] FilippoPerrina,FrancescoMarchiori,MauroConti, andNinoVincenzoVerde. Agir: Automatingcyberthreat
intelligence reporting with natural language generation. In 2023 IEEE InternationalConference on Big Data
(BigData),pages3053–3062.IEEE,2023.
[17] EhsanAghaei,EhabAl-Shaer,WaseemShadid,andXiNiu. Automatedcveanalysisforthreatprioritizationand
impactprediction. arXivpreprintarXiv:2309.03040,2023.
[18] Stephen Moskal, Sam Laney, Erik Hemberg, and Una-May O’Reilly. Llms killed the script kiddie: How
agents supported by large language models change the landscape of network threat testing. arXiv preprint
arXiv:2310.06936,2023.
[19] PuzhuoLiu,ChengnianSun,YaowenZheng,XuanFeng,ChuanQin,YunchengWang,ZhiLi,andLiminSun.
Harnessingthepowerofllmtosupportbinarytaintanalysis. arXivpreprintarXiv:2310.08275,2023.
[20] Maxime Labonneand Sean Moran. Spam-t5: Benchmarkinglarge language models for few-shotemail spam
detection. arXivpreprintarXiv:2304.01238,2023.
[21] EnricoCambiasoandLucaCaviglione. Scammingthescammers:Usingchatgpttoreplymailsforwastingtime
andresources. arXivpreprintarXiv:2303.13521,2023.
[22] Yashar Talebirad and Amirhossein Nadiri. Multi-agentcollaboration: Harnessing the power of intelligentllm
agents. arXivpreprintarXiv:2306.03314,2023.
[23] ChengyuSong,LinruMa,JianmingZheng,JinzhiLiao,HongyuKuang,andLinYang. Audit-llm: Multi-agent
collaborationforlog-basedinsiderthreatdetection. arXivpreprintarXiv:2408.08902,2024.
10