GOVERNMENTLICENSE
The submitted manuscript has been created by UChicago Argonne, LLC, Operator of Argonne
NationalLaboratory(“Argonne”).Argonne,aU.S.DepartmentofEnergyOfficeofSciencelaboratory,
isoperatedunderContractNo. DE-AC02-06CH11357. TheU.S.Governmentretainsforitself,and
othersactingonitsbehalf,apaid-upnonexclusive,irrevocableworldwidelicenseinsaidarticleto
reproduce,preparederivativeworks,distributecopiestothepublic,andperformpubliclyanddisplay
publicly,byoronbehalfoftheGovernment. TheDepartmentofEnergywillprovidepublicaccess
to these results of federally sponsored research in accordance with the DOE Public Access Plan.
http://energy.gov/downloads/doe-public-access-plan
1
4202
tcO
11
]EC.sc[
1v43090.0142:viXraPEAR: A Robust and Flexible Automation Framework
for Ptychography Enabled by Multiple Large
Language Model Agents
XiangyuYin ChuqiaoShi YimoHan
ArgonneNationalLaboratory RiceUniversity RiceUniversity
Lemont,IL Houston,Tx Houston,Tx
xyin@anl.gov cs109@rice.edu yh76@rice.edu
YiJiang
ArgonneNationalLaboratory
Lemont,IL
yjiang@anl.gov
Abstract
PtychographyisanadvancedcomputationalimagingtechniqueinX-rayandelec-
tron microscopy. It has been widely adopted across scientific research fields,
includingphysics,chemistry,biology,andmaterialsscience,aswellasinindustrial
applicationssuchassemiconductorcharacterization. Inpractice,obtaininghigh-
quality ptychographic images requires simultaneous optimization of numerous
experimentalandalgorithmicparameters. Traditionally,parameterselectionoften
reliesontrialanderror,leadingtolow-throughputworkflowsandpotentialhuman
bias. Inthiswork,wedevelopthe“PtychographicExperimentandAnalysisRobot”
(PEAR),aframeworkthatleverageslargelanguagemodels(LLMs)toautomate
data analysis in ptychography. To ensure high robustness and accuracy, PEAR
employsmultipleLLMagentsfortasksincludingknowledgeretrieval,codegener-
ation,parameterrecommendation,andimagereasoning. Ourstudydemonstrates
thatPEAR’smulti-agentdesignsignificantlyimprovestheworkflowsuccessrate,
evenwithsmalleropen-weightmodelssuchasLLaMA3.18B.PEARalsosupports
variousautomationlevelsandisdesignedtoworkwithcustomizedlocalknowledge
bases,ensuringflexibilityandadaptabilityacrossdifferentresearchenvironments.
1 Introduction
Ptychography[Hoppe,1969]isapowerfulcomputationalimagingtechniquewidelyusedinoptical,
X-ray,andelectronmicroscopy.Unlikeconventionalimagingmethods,whosespatialresolutionisfun-
damentallylimitedbyfocusingoptics,modernptychographyemploysoptimization-basedalgorithms
todirectlyreconstructsamplestructuresfromaseriesofscanningdiffractionpatterns[Rodenburg
andFaulkner,2004]. Thisapproachovercomesphysicallimitationsimposedbythelenses,enabling
muchhigherresolutionundersimilarconditions. Currently,electronptychographyholdstheworld
recordforthehighestspatialresolutionamongallmicroscopytechniques. Todate,ptychographyhas
enablednumerousscientificapplications,rangingfromin-situstudiesofbatteryparticles[Liuetal.,
2022]and3Dimagingofintegratedcircuits[Aidukasetal.,2024]tosingleoxygenvacancydetection
insuperconductingmaterials[Dongetal.,2024].
Despiteitspopularity,achievinghigh-resolutionptychographyremainschallengingduetovarious
parametersthatsignificantlyimpactreconstructionqualityandrequirecarefuladjustmentfordifferent
Technicalpreview.datasets or applications. For example, physical parameters describing processes such as noise
generation,partialcoherence,andmultiplescatteringcanbemodeledintheoptimizationproblem.
Choosingappropriatevaluesfortheseparameterstoaccountforvariouspracticalerrorsisparamount
toreachingsolutionsthatcloselyrepresenttherealobject. Otherparameters,includingthenumber
ofiterations,updatestepsize,andinitialsolutions,alsoimpactreconstructionsbycontrollingthe
convergence process. Given the virtually infinite possibilities and complex trade-offs between
parameters, optimizing all variables by exhaustive search is practically impossible. In practical
applications[Jiangetal.,2018,Songetal.,2019,Chenetal.,2020],researchersoftenrelyontheir
ownexperiencesandknowledgetochoosealimitedsetofparametersthroughtrialanderror. This
processreducestheoverallthroughputandpotentiallyintroducesbiasestoscientificconclusions
drawnfromtheresults. Therefore,thereisacriticalneedtodevelopworkflowsthatautomatically
optimizeparametersforunknowndatasetswithminimalhumaninput.
Previously,black-boxoptimizationtechniquessuchasBayesianoptimizationwithGaussianprocesses
(BO-GP)havebeendevelopedforparametertuningtasksinptychography[Caoetal.,2022]. BO-GP
workflowsmakeminimalassumptionsabouttheinputdataorreconstructionalgorithms,iteratively
searching for the global optima by automatically balancing exploration and exploitation. This
approachhasfoundgreatsuccessincalibratingexperimentalparametersthataredifficulttomeasure
byinstruments[YoonandMuller,2024],andindesigningcomplexexperimentsinvolvingmultiple
trade-offs between parameters[Cao et al., 2022]. However, BO-GP requires a large number of
reconstructionstoconstructgoodsurrogatemodelsthatapproximatetheobjectivefunction,which
cansignificantlyprolongprocessingtimeandincreasethecomputationalresourcedemandscompared
with experienced researchers whose existing knowledge can guide them obtaining useful results
withinafewreconstructions.
Therecentadvancementoffoundationmodelshaspropelledintelligence(AI)toaneweracharacter-
izedbybillion-parametermodelsandmultifunctionalcapabilities. Recently,LargeLanguageModels
(LLMs), such as those popularized by OpenAI’s ChatGPT, have gained significant attention due
totheir“intelligent”capabilities,includingcomprehensiveknowledge,commonsense,andbasic
logic. Withextensivetrainingdatasets,thesefoundationmodelscanbeeasilyadaptedtoautomate
varioustasksincludingliteraturesearch,reasoning,codegeneration,whicharekeycomponentsin
manyscientificfield. Boikoetal.[2023]developedanLLM-poweredsystemnamedCoscientistto
autonomouslydesign,planandperformseveralorganicchemistryexperiments. M.Branetal.[2024]
introducedChemCrow,anLLMchemistryagentthatcanperformtasksacrossorganicsynthesis,
drugdiscovery,andmaterialsdesignbyintegrating18expert-designedtools. Cherukaraetal.[2024]
proposedContext-AwareLanguageModelforScience(CALMS)toassistscientistswithinstrument
operationsandcomplexexperimentationinthescientificuserfacilities.
Inthiswork,wedevelopedthe"PtychographicExperimentandAnalysisRobot"(PEAR),aworkflow
designedtoassistresearcherswithparametertuninginptychographicreconstructions. PEARmimics
humanexperts’thoughtprocessbasedondomainknowledgeembeddedwithinmultipleLLMagents
toautomateandrobustlyperformtaskssuchasinformationcollection,codegeneration,knowledge
retrieval,andimagereasoning. Wedesignedvariouslevelsofautomation,rangingfromhuman-in-
the-looptofullyautomatedclosed-loop,tosupportabroadrangeofusers,fromnoviceresearchers
toexperiencedexperts,tailoredtotheircustomizedknowledgebases. ThesefeaturesmakePEAR
highlyadaptable,allowingittobeeasilyextendedtoothercomputationalimagingtechniquesand
beyond.
2 Method
Inthissection,weintroducethemaindesignfeaturesofPEAR,whicharecriticalfortheworkflowto
consistentlyproduceaccurateparametersandhigh-qualityptychographicreconstructions.
2.1 CustomKnowledgeBase
EffectivelyutilizingdomainknowledgeiscrucialinapplyingLLMsforscientificapplicationsto
ensurethattheiroutcomesarebothscientificallyaccurateandtailoredtospecificscientifictasksat
hand.InPEAR,wedecoupletheworkflowfromtheknowledgebases.Theworkflowitselfcontainsno
specificinformationaboutptychography,whiletheknowledgebasesserveasdedicatedrepositories
forproblem-anduser-specificinformation, suchasexperimentsettings, examplescripts, related
3documents,andimages. Byleveragingacustomknowledgebase,thePEARworkflowcanmake
informeddecisionsandprovideguidancetailoredtospecifictasksinptychographyreconstruction.
Thisseparationoftheworkflowfromtheknowledgebasesallowsfordynamicupdatingormodifica-
tionofeithercomponentwithoutaffectingtheother. Forexample,asnewptychographictechniques
orparametersaredeveloped,theknowledgebasecanbeexpandedwithoutalteringthecoreworkflow
logic. Similarly,improvementscanbemadetotheLLMsandtheoverallagenticworkflowswith-
outmodifyingtheknowledgebases. Thisseparationisparticularlyvaluableinpracticalscientific
research,asitallowsforcustomizationandensuresinformationprivacyfordifferentresearchgroups.
In PEAR’s knowledge base, we limit the types of knowledge sources to Markdown files, PDF
documents, and PNG/JPG images, which encompass most of the information types relevant to
ptychography. Regulating the types of knowledge sources ensures effective and reliable storage,
retrieval,andutilizationofinformationusingcommonLLMtechniques. Additionally,thesesource
typesarehuman-readableandmanageable,makingitpossibletotracebackLLMoutputs,thereby
enhancinguserinterpretabilityandtrust. Figure1illustratesthreedifferentfileformatsinPEAR’s
knowledgebaseandhowtheyfacilitatevarioussub-tasksinthedataanalysisworkflow.
2.2 Human-in-the-Loop(HITL)
Despitetheirimpressivecapabilities,LargeLanguageModels(LLMs)cansometimesproduceerrors
orinconsistencies,particularlywhendealingwithcomplexscientificconcepts. Human-in-the-Loop
(HITL) serves as a critical quality control mechanism, allowing human experts to intervene and
correctsubtleerrorsthatmightotherwisegounnoticedbyLLMs. Scientificresearchofteninvolves
navigatingconflictinginformation,scenarioswherestandardprotocolsdonotapply,andoutcomes
thatareinherentlyuncertain. HITLplaysavitalroleinmanagingtheseedgecasesandpreventing
catastrophicfailures.
InPEAR,theHITLapproachisintegratedatvariousstagesoftheworkflow, performingseveral
essentialfunctions:
• ProvidingContextualInformation: Humanuserscanoffercontext-specificdetails,suchas
experimentalsetupsorpriorknowledgeaboutthesamplethatarenotcapturedinthegeneral
knowledgebase. Thisinputisfacilitatedthroughresponsestotargetedquestionsgenerated
by LLM agents, ensuring that the workflow remains grounded in realistic experimental
conditions.
• ValidationandErrorCorrection: HumanuserscanverifyLLM-generatedvaluesandrec-
ommendations,ensuringalignmentwithscientificprinciplesandexperimentalconstraints.
Experiencedresearcherscanidentifyandcorrecterrorsearlyintheworkflow,preventing
thepropagationofinaccuraciesandmaintainingtheintegrityofthescientificanalysis.
• AssessmentandFeedback: Expertscanevaluateptychographicreconstructions,enabling
aniterativeprocesswheretheirassessmentsguideLLMagentsinrefiningtheworkflow.
Feedbackfromhumanexpertsisloggedandcanbeusedtoenhancetheknowledgebase
overtime,contributingtocontinuousimprovementandadaptationofthesystem.
2.3 Multi-agentWorkflow
TofurtherenhancethereliabilityandeffectivenessofLLM-poweredscientificworkflows,particularly
incomplextaskslikeptychographydataanalysis,PEARemploysmultipleLLMagentsforeach
sub-taskinsteadofrelyingonasingleagent. ThisdesignchoiceenablesPEARtoachievenearly
100%accuracyinitsoutputs. OneofthecoretasksinPEARistheHITLcodegenerationtask,where
experimentalinformationisgatheredfromuserstogenerateacorrespondingreconstructionscript.
Weusethistaskasanexampletocomparesingle-agentandmulti-agentapproaches,illustratingthe
benefitsofthemulti-agentdesign.
In a single-agent system, one LLM agent manages the entire process, including user interaction,
parametercollection,andscriptgeneration. Althoughsimpler,thisapproachismoresusceptibleto
errorsandinconsistencies,especiallywhenhandlingcomplexparameterrelationshipsanddomain-
specificconstraints. Incontrast,themulti-agentapproachinPEARdistributesthesetasksamong
specializedagents,eachresponsibleforaspecificaspectoftheworkflow.
4Markdown files PDF documents PNG/JPG images
Prompt engineering Retrieval augmented generation Few-shot learning
parameter_description
| variable name | variable type | description | default value | minimum “The image is blurry, and
value | maximum value | unit | losing most features”
| :---| :---| :---| :---| :---| :---| :---|
| scan_number | int | scans id number |0|0|3| -|
| energy | float | beam energy | 80.0 | 20.0 | 400.0 | keV |
| rbf| float | radius of the bright field disk | 20.0 | 1.0 | 1024.0 | pixels |
| alpha_max| float | semi-convergence angle | 20.0 | 0.5 | 50.0 | mrad|
| use_external_probe| boolean| true if initial probe is loaded from an
e | dxi es ft oin cg u r se |c fo lon as tt r | u inc it ti io an l p| rf oa bls ee 's | d-| e - fo| c- u| s value | 0.0 | 0.0 | 100.0 | nm | “The image shows major
| use_external_positions| boolean| true if initial scan positions are features but lacks contrast”
loaded from an existing reconstruction | false | -| -| -|
…
recommender_knowledge
### Situation:
* The initial probe is NOT accurate enough. “The image is blurry with a
* * T Rh ee g ao rb dj le ec st s h oa fs a g nr yid o a thrt eif ra cc ot ns. ditions. dark halo shaped artifacts
### Recommendation: around the object”
* Do not use an external reconstruction for initial probe.
* Increase the initial probe's defocus by 50 angstroms.
### Situation:
* The initial probe is accurate enough. “The image seems clear
* The reconstruction didn't converge.
* Regardless of any other conditions. with good contrast, showing
### Recommendation: high frequency features”
• Increase the number of iterations by 100.
.…
Embed textual information directly Parse, chunk and encode documents Encode images into base64 format
into Markdown formatted prompts into vector store via embeddings
Simulate prior chat messages
# PARAMETER DESCRIPTION: Retrieve relevant_context via
{parameter_description} hybrid keyword-similarity search
User: Describe image 1
# RECOMMENDER KNOWLEDGE: Description 1:Assistant
{recommender_knowledge} User: Describe image 2
# RECOMMENDER KNOWLEDGE: Description 2:Assistant
# RECONSTRUCTION RESULTS: {relavant_context} User: Describe image 3
{State['current']['quality']} Description 3:Assistant
# KNOWN PARAMETER: User: Describe image 4
# Instruction: {State['current']['parameters']} Description 4:Assistant
Recommend parameters for RECONSTRUCTION User: Describe this new image
RESULTS, according to PARAMETER # Instruction:
DESCRIPTION and RECOMMENDER KNOWLEDGE. Recommend unknown parameters according
to RECOMMENDER KNOWLEDGE.
LLM (JSON mode) LLM VLM
{"use_external_probe": false, “Since fly scan is used, increasing “This image shows object features
"defocus": 50} number of probe modes may help” but has dark halo shaped artifacts”
Figure1: SupportedknowledgefilesinPEAR.(Left)Markdownfilesareusedforstructured,text-
basedinformationsuchasparameterdescriptionsorstep-by-stepprotocols. InPEAR,thesefilescan
bedirectlyembeddedintopromptsandformattedusingpromptengineeringtechniques. Forexample,
parameterdescriptionsenableLLMstounderstandthenuancesofvariousptychographicparameters,
theiracceptableranges,andtheirimpactsonthereconstructionprocess. Theknowledgebasealso
includesexpertguidanceonparameterselectionandoptimizationstrategies,allowingLLMstomake
informedrecommendationsbasedonspecificreconstructionresultsandconditions. JSONformatting
ensuresthatmodeloutputsareconsistentandmachine-readable,facilitatingseamlessintegration
withothercomponentsofthePEARsystem. (Middle)PDFdocuments,includingscientificpapers,
user manuals, and technical reports, provide richer, more detailed information. PEAR processes
these documents using Retrieval Augmented Generation techniques, which involve parsing the
content,chunkingitintomanageablesections,andencodingthesechunksintoavectorstoreusing
embeddings.Whenrequired,PEARefficientlyretrievesrelevantinformationthroughhybridkeyword-
similaritysearches, ensuringthatthemostpertinentcontentinformsitsoutputs. (Right)Images
(PNG/JPG) are critical for representing ptychographic data and results. In PEAR, images are
encodedinbase64format,makingthemcompatiblewithmostvision-languagemodels. Few-shot
learning techniques enable PEAR to understand and describe new images based on previously
seen examples. This approach simulates prior interactions where the system describes various
ptychographicimages, providingafoundationforinterpretingnew, unseendata. Toprocessand
understandimagecontent,PEARincorporatesVisualLanguageModelsthatanalyzeptychographic
images and generate descriptive outputs, which inform parameter recommendations and quality
assessments.
5Task: Human-in-the-loop Code Generation
Single Agent: # EXAMPLE SCRIPT: {Example Script}
Example Script
# PARAMS DESCRIPTIONS: {Parameter Description}
# Instructions:
First, interact with user, ask questions to collect parameter
values listed in PARAMS DESCRIPTIONS.
Parameter One-shot Script Reconstruction Your questions should cover all parameters in PARAMS DESCRIPTIONS,
Description Generation Agent Script b Qe u ec sa tr ie of nu sl sa hb oo uu lt d t bh ee cc oo nn vd ei rt si ao tn ia ol n ar le l aa nt di o sn os uh ni dp ss lb ie kt ew e he un m ap na .rameters.
Afterasking all questions and collecting all parameter values,
interact with user to ask for confirmation.
Finally, replace and fill in exact values collected from the user
in EXAMPLE RECON SCRIPT to generate a new script.
Do not make up or change values. Do not add new lines. Do not add
User new code. The script should be surrounded by ```script and ```
only. Do not add explanation before or after the code block.
Multiple Agents:
Parameter
Description Example Script
Questions Parameters Parameters Parameters Script Generation
Generation Agent Collection Agent Validation Agent Confirm Agent Agent
Reconstruction
User User Script
CodeGeneration Success Rate Comparison (Success/Mistake/Error)
Single agent Multiple agents
Figure2: Comparisonofsingle-Agentvs. multi-AgentDesignforCodeGenerationinPEAR.The
single-agentworkflowusesasingleprompttocollectparametervaluesfromusersandgeneratea
reconstructionscriptbasedontheirinputs. Themulti-agentworkflowbreaksthetaskintosimpler
sub-tasks,eachhandledbyspecializedagents. TheQuestionGenerationAgentformulatesquestions
to gather necessary information from the user. The Parameter Collection Agent processes user
responses and extracts relevant parameter values. The Parameter Validation Agent checks these
valuesforconsistencyandcompliancewithdomain-specificconstraints. TheParameterConfirmation
Agentinteractswiththeusertoconfirmthecollectedparametersbeforescriptgeneration. Finally,the
ScriptGenerationAgentusesthevalidatedparameterstogeneratethecompletereconstructionscript,
enhancingaccuracyandreducingerrorscomparedtothesingle-agentapproach.
AsshowninFigure2,weconductedacomputationalexperimentcomparingthesingle-agentand
multi-agentapproaches. Wegenerated100setsofhypotheticalptychographyproblemsandproduced
reconstruction scripts for each condition using both approaches. To efficiently handle the large
number of tests, we prompted an advanced LLM model to simulate human responses in a HITL
setup. Boththesingle-agentandmulti-agentapproachesweretestedusingvariousLLMs,including
open-weightmodelslikeLLaMA3.1andclosed-sourcemodelslikeChatGPT.Performancewas
evaluatedbycomparingthegeneratedscriptsagainstexpert-curatedgroundtruthscripts,classifying
the outcomes into three categories: success, mistake, and error. The success category includes
scriptsthatarecorrectandfullyfunctional. Themistakecategoryconsistsofrunnablescriptswith
incorrectparametervalues,whiletheerrorcategoryincludesscriptswithsyntaxerrorsthatprevent
reconstruction. DetailedexperimentsetupsandpromptsareprovidedintheAppendix.
Theresultsdemonstratethatthemulti-agentapproachsignificantlyenhancesthesuccessrateand
robustnessofthecodegenerationprocess. ThisincreasedaccuracyallowsPEARtoutilizeopen-
weightmodelswithfewerparameterscomparedtopopularmodelslikeGPT-4,offeringsignificant
advantagesforscientificworkflows.Open-weightmodelscanbefine-tunedortrainedontask-specific
datasets, enhancingcustomization. Furthermore, thesemodelscanbedeployedlocally, ensuring
reproducibilityanddatasecurityusingexistinginfrastructure.
62.4 AutomationLevels
Inspired by the self-driving car industry, PEAR offers different levels of automation to enhance
the framework’s versatility and user-friendliness. These levels accommodate users with varying
degrees of expertise and familiarity with ptychography and autonomous systems, allowing both
noviceandexperienceduserstoeffectivelyutilizetheplatform. Newcomerstoptychographycan
beginwithlowerlevelsofautomationandgraduallyadvancetomoresophisticatedfeaturesasthey
gainconfidenceandunderstandingindataanalysis. Additionally,asusersinteractwithPEARat
differentautomationlevels,thesystemautomaticallytracksandsavesvaluabledataonuserbehavior,
decision-makingprocesses,andproblem-solvingstrategies. Thismulti-modaldata,comprisingboth
textandimages,israreinthescientificcommunityandiscrucialfordevelopingimprovedknowledge
basesandmoreintelligentLLMagents.
Currently,PEARimplementsthreeprimarylevelsofautomation,asshowninFigure3,eachoffering
anincreasingdegreeofAIassistanceandautonomousoperation:
• Level0: ManualWorkflowSteering: Thislevelrepresentsthemostbasicformofautoma-
tion in PEAR, designed for users who prefer maximum control over the ptychographic
reconstructionprocessorforscenariosrequiringcarefulhumanoversight.
• Level1: AI-AssistedRecommendations: Atthislevel,PEARprovidesAI-generatedrecom-
mendationsbasedontheuser’sknowledgebasewhilemaintainingsignificantuserinvolve-
ment. ItisidealforuserswhowishtoleverageAIinsightsbutstillretaindecision-making
control.
• Level2: AutomatedQualityAssessment: ThehighestlevelcurrentlyimplementedinPEAR,
Level 2 incorporates automated quality assessment of reconstruction results. This level
is particularly suited for experienced users or for handling large datasets where manual
inspectionofeachresultwouldbeinefficientandtime-consuming.
The multi-level design of PEAR is flexible and adaptable, allowing the framework to be easily
modifiedforuseinothercomputationalimagingtechniquesandbeyond.
3 ACaseStudyinElectronPtychography
TofurtherdemonstratePEAR’sworkflow,weappliedittoanexperimentalelectronptychography
datasetof2DVanderWaalsSnSe,amaterialwithstructuresthatarecrucialforunderstandingthe
electronicpropertiesofferroelectrics[Zhangetal.,2023]. Figure4showsselectedptychographic
reconstructionsalongwiththecorrespondingevaluationsandrecommendationsrecordedbyPEAR.
Thecompletelogoftheparametertuningprocessisprovidedintheappendix,withsomesensitive
dataredactedtoprotectuserprivacy.
At automation Level 1, PEAR leverages user feedback on the reconstruction quality to suggest
adjustmentstoreconstructionparameters.Inafewreconstructions,thereconstructedatomicstructures
becomenotablysharperandexhibitfewernoisyartifactswhenusingparametersrecommendedby
PEAR’sknowledgebase. Theseoptimizedchoicescloselyalignwiththosemadebyexperienced
scientists. Withouttheknowledgeaboutptychography,conventionalBOapproachescouldrequire
tensofreconstructionstoachievesimilarquality[Caoetal.,2022].
4 Conclusions
Inthiswork,wepresentPEAR,anautomaticparameter-tuningworkflowforptychographypowered
byLargeLanguageModels. Toensuremorerobustandaccurateresults,PEARincorporatesseveral
keystrategies,includingcustomknowledgebases,human-in-the-loopintegration,andamulti-agent
workflow. ThesefeaturesenablePEARtoachievehighsuccessratesevenwhenusingsmallerLLM
models,suchasLLaMA3.18B.Despitethegreatimprovement,weacknowledgethaterrorsand
hallucinations can still happen given the nature of current foundation model technologies. The
differentlevelsofautomationprovideflexibilityandadaptability,allowingPEARtocatertoawide
range of users and extend automation capabilities to computational imaging techniques beyond
ptychography. Lookingahead,thelogfilesgeneratedbyPEARusershavethepotentialtoserveas
valuabletrainingdataforthedevelopmentoffuturefoundationmodels.
7Automation Levels
Level 0: fully manual steering
Human-in-the-loop RunGenerated Human-in-the-loop
Code Generation Recon. Script Result Feedback
Level 1: intelligent recommendation
Parameter Human-in-the-loop RunGenerated Human-in-the-loop
Recommendation Code Generation Recon. Script Result Feedback
Level 2: intelligent diagnosis
Parameter Human-in-the-loop RunGenerated Autonomous Human-in-the-loop
Recommendation Code Generation Recon. Script Quality Diagnosis Result Feedback
Figure 3: Levels of automation in PEAR. At level 0, human users maintain full control over the
reconstructionprocess. Theymanuallyspecifyinputparametersandcustomizethecodeaccording
totheirspecificneeds. PEARthengeneratesareconstructionscriptbasedontheseinputs. After
reconstruction,usersmanuallyexaminetheresultsanddecideonfurtherstepsorparameteradjust-
ments. Evenatthismanuallevel,thesystemcollectsdataonuserinputsanddecisions,whichis
valuable for refining future recommendations and enhancing automation capabilities. At level 1,
usersstillcontrolcodegeneration,butthesystemprovidesintelligentsuggestionsbasedontheinput
dataandexperimentalparameters. PEARgeneratesareconstructionscriptthatintegratesbothuser
inputsandAI-recommendedparameters. Afterthereconstruction,PEARoffersrecommendations
forfurtherparameteradjustmentstoimprovequalitybasedonuserfeedback. Usershavetheoption
toaccept, modify, orrejecttheserecommendationsinsubsequentiterations. Atlevel2, PEAR’s
diagnosticagentsautomaticallyassessthequalityofthereconstruction,identifyingpotentialissues
such as artifacts or convergence problems. The AI provides a quality assessment that users can
review,offeringinsightsandfeedbackonthereconstructionqualityandsuggestingfurtheractionsor
adjustments.
5 Acknowledgements
ThisresearchusedresourcesoftheAdvancedPhotonSource,anU.S.DepartmentofEnergy(DOE)
OfficeofScienceUserFacilityoperatedfortheDOEOfficeofSciencebyArgonneNationalLabora-
toryunderContractNo. DE-AC02-06CH11357. X.Y.andY.J.acknowledgefundingsupportfrom
ArgonneLDRD2023-0049. C.S.andY.H.acknowledgeNSF(FUSE-2329111andCMMI–2239545),
WelchFoundation (C-2065), and American Chemical SocietyPetroleum Research Fund (67236-
DNI10).
8User Case Study:
PEAR-assisted Ptychography Reconstruction of SnSe(Automation Level 1)
Human-in-the-loop Code Generation Human-in-the-loop Code Generation Human-in-the-loop Code Generation
Run Generated Reconstruction Script Run Generated Reconstruction Script Run Generated Reconstruction Script
5 Å 5 Å 5 Å
Human-in-the-loop Result Feedback Human-in-the-loop Result Feedback Human-in-the-loop Result Feedback
PEAR: Your command execution is successful :) Please PEAR: Your command execution is successful :) Please PEAR: Your command execution is successful :) Please
check your reconstructions and answer some questions: check your reconstructions and answer some questions: check your reconstructions and answer some questions:
PEAR: Did the reconstruction converge? PEAR: Did the reconstruction converge? PEAR: Did the reconstruction converge?
User: yes User: yes User: yes
PEAR: Do you see any grid artifacts in the object? PEAR: Do you see any grid artifacts in the object? PEAR: Do you see any grid artifacts in the object?
User: no User: no User: no
PEAR: Is the initial probe accurate enough? PEAR: Is the initial probe accurate enough? PEAR: Is the initial probe accurate enough?
User: yes User: yes User: yes
PEAR: Do you see any structures in the last probe mode? PEAR: Do you see any structures in the last probe mode? PEAR: Do you see any structures in the last probe mode?
User: no User: no User: no
PEAR: Is there anything else you want to tell me? PEAR: Is there anything else you want to tell me? PEAR: Is there anything else you want to tell me?
User: each layer seems to have random features User: the atoms still look a bit blurred User: no
PEAR: Thank you for your feedback! PEAR: Thank you for your feedback! PEAR: Thank you for your feedback!
Parameter Recommendation Parameter Recommendation Parameter Recommendation
PEAR: Summarizing previous conversation... PEAR: Summarizing previous conversation... PEAR: Summarizing previous conversation...
The reconstruction converged successfully. The reconstruction converged successfully. The reconstruction converged successfully.
-There are no grid artifacts present in the object. -There are no grid artifacts present in the object. -There are no grid artifacts present in the object.
-The initial probe is accurate enough. -The initial probe is accurate enough. -The initial probe is accurate enough.
-There are no visible structures in the last probe mode. -There are no visible structures in the last probe mode. -There are no visible structures in the last probe mode.
-Each reconstructed layer has random features -The atoms still appear a bit blurred. -The user has no additional information
### Recommendation: ### Recommendation:
### Recommendation: * * Increase the standard deviation of the gaussian kernel * * Increase the standard deviation of the gaussian kernel
* Increase the layer regularization by 0.3. for detector blurring by 0.5. for detector blurring by 0.5.
Figure4: PEAR-assistedreconstructionsofanelectronptychographydatasetofSnSe. Atautomation
Level1,PEARincorporatesuserfeedbacktorecommendoptimizedparametersthatenhanceimage
quality. Asaresult,thereconstructedatomicstructuresbecomenoticeablysharperandcontainless
noisyartifactsthroughoutthePEAR-guidedworkflow.
References
TomasAidukas,NicholasWPhillips,AnaDiaz,EmiliyaPoghosyan,ElisabethMüller,AFJLevi,GabrielAeppli,
ManuelGuizar-Sicairos,andMirkoHoller. High-performance4-nm-resolutionx-raytomographyusingburst
ptychography. Nature,632(8023):81–88,2024.
DaniilABoiko,RobertMacKnight,BenKline,andGabeGomes. Autonomouschemicalresearchwithlarge
languagemodels. Nature,624(7992):570–578,2023.
MichaelCCao,ZhenChen,YiJiang,andYimoHan. Automaticparameterselectionforelectronptychography
viabayesianoptimization. ScientificReports,12(1):12284,2022.
ZhenChen,MichalOdstrcil,YiJiang,YimoHan,Ming-HuiChiu,Lain-JongLi,andDavidAMuller. Dataset:
Mixed-stateelectronptychographyenablessub-angstromresolutionimagingwithpicometerprecisionatlow
dose. NatureCommunications,2020.
Matthew Cherukara, Alkaterini Vriza, Henry Chan, Tao Zhou, Varuni Katti Sastry, and Michael Prince.
Calms:Context-awarelanguagemodelforscience. [ComputerSoftware]https://doi.org/10.11578/
dc.20240410.1,apr2024. URLhttps://doi.org/10.11578/dc.20240410.1.
ZehaoDong,MengwuHuo,JieLi,JingyuanLi,PengchengLi,HualeiSun,LinGu,YiLu,MengWang,Yayu
Wang,etal. Visualizationofoxygenvacanciesandself-dopedligandholesinla3ni2o7-δ. Nature,pages1–6,
2024.
WalterHoppe. Beugungiminhomogenenprimärstrahlwellenfeld.i.prinzipeinerphasenmessungvonelektro-
nenbeungungsinterferenzen. ActaCrystallographicaSectionA:CrystalPhysics,Diffraction,Theoreticaland
GeneralCrystallography,25(4):495–501,1969.
9YiJiang,ZhenChen,YimoHan,PratitiDeb,HuiGao,SaienXie,PrafullPurohit,MarkWTate,JiwoongPark,
SolMGruner,etal. Electronptychographyof2dmaterialstodeepsub-ångströmresolution. Nature,559
(7714):343–349,2018.
QiangLiu,Yu-TongLiu,ChenZhao,Qing-SongWeng,JunjingDeng,InhuiHwang,YiJiang,ChengjunSun,
TianyiLi,WenqianXu,etal. Conformalpedotcoatingenablesultra-high-voltageandhigh-temperature
operationforsingle-crystalni-richcathodes. ACSnano,16(9):14527–14538,2022.
Andres M. Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller.
Augmentinglargelanguagemodelswithchemistrytools. NatureMachineIntelligence,pages1–11,2024.
JohnMRodenburgandHelenMLFaulkner. Aphaseretrievalalgorithmforshiftingillumination. Applied
physicsletters,85(20):4795–4797,2004.
JiameiSong,ChristopherSAllen,SiGao,ChenHuang,HidetakaSawada,XiaoqingPan,JamieWarner,Peng
Wang,andAngusIKirkland. Atomicresolutiondefocusedelectronptychographyatlowdosewithafast,
directelectrondetector. Scientificreports,9(1):3919,2019.
DasolYoonandDavidAMuller. Improvingrobustnessofelectronptychographybybayesianoptimizationof
tiltandthickness. MicroscopyandMicroanalysis,30(Supplement_1),2024.
DaweiZhang,PeggySchoenherr,PankajSharma,andJanSeidel. Ferroelectricorderinvanderwaalslayered
materials. NatureReviewsMaterials,8(1):25–40,2023.
A ComputationalExperimentSetup
InthecomputationalexperimentdescribedinSection2.3,weusedanadvancedLLMtosimulate
humanresponsestotheLLMagents’questions,enablingustoefficientlyconductalargenumber
oftests. Specifically,weemployedtheGPT-4modelviaAzureOpenAIServicetosimulatehuman
responses. FortheLLMagents,weutilizedarangeofmodels,includingLLaMA3.1(8b,70b,405b)
throughTogetherAI,andChatGPTmodels(gpt-4o,chatgpt-4o-latest,gpt-4o-mini)viaOpenAI.The
exactpromptsusedintheseexperimentsaredetailedinFigure5.
The hypothetical experiment conditions and computational experiment logs are available in the
supplementarymaterials.
10Questions Generation Agent Parameters Confirm Agent
# PARAMS DESCRIPTION:
# PARAMS DESCRIPTIONS: {}
{} # CURRENT PARAMETERS:
# EXAMPLE QUESTIONS: {}
- - -W W Wh h ha a at t t i i is s s t t th h he e e s b cc e oa a nn m v en e ru n gm e eb r ne g cr y e? ? angle? # { }MY FEEDBACK:
- o g t - -r e hD H D n eo o ol e w o r ny ya a uo m od t mu a u e b n t ew y wh s ra ae c n i nm a ot t t n f e f t r tr p so a oo o c t m s ag i e i ne o na t n n an i pe s b o or le n ia d ex s nt o i , te ps s y ot p s o si l ic u in e na tg a n w i s b a or e op n ne to t c p hs co r i t on o Xt o rs v i rt i ao r er d nn u cu e ds n tc ? it t Ya oi h s no e ds ?n iu ? s rm c ei I a cn f n tg i y s oa o t n u e sp p .e w r a sf n ie t zc et t o ag nr di d # M u O t o p u hI d d t en i a p s f t u Jt y e t Sr d Ou C M Nc U J U .t R S Si R O To E N n N bs T f e: o P l JA l SR o OA w NM i E n OT g NE LR t YS h , e a dc P oc A o R nr A od M ti S n ag D d E dt S o C e R xM I pY P l T aF I nE O aE N tD . iB oA nC K b ea fn od r eo u ot rp u at f ta en r
-Do you want to use a multislicemodel? Please provide total
thickness of the object, number of layers and layer Parameters Confirm Agent Responder
regularization coefficient. # TRUE PARAM VALUES:
{}
# Instructions:
Generate a list of questions based on the PARAMS DESCRIPTIONS to # CURRENT PARAM VALUES:
collect information about parameter values from the user. {}
The questions should be asked in a conversational manner one by
one. # EXAMPLE ACTIONS:
The question should cover all the parameters, be careful about * set energy to 100
the units and conditional dependencies between parameters. * set use_grid_scanto true
Follow the examples in the EXAMPLE QUESTIONS. Output MUST be a * set multislice_ptychoto false
list of questions ONLY, do not add explanation before or after * set regularize_layersto 0.7
the list. * set scan_step_size_xto 0.2
* all parameters look good, CONFIRM
Parameters Collection Agent # Instructions:
Examine the CURRENT PARAM VALUES to identify any value
discrepancies between TRUE PARAM VALUES and CURRENT PARAM VALUES.
# PARAMS DESCRIPTION: If there are discrepancies, provide an action to correct the
{} discrepancies. Do not try to change parameter names or convert
values to other units.
# PARAMS QUESTIONS: The action should be in one simple sentence following the EXAMPLE
{} ACTIONS. Answer ONLY the action, do not add any explanation or
comment.
# Instructions: If all values are correct, confirm the values by outputting
Ask ALL questions from pre-defined PARAMS QUESTIONS one by one. "CONFIRM".
Ask ONLY ONE question at a time following the pre-defined order.
YOU NEED TO ASK ALL QUESTIONS! DO NOT SKIP QUESTIONS! DO NOT
CHANGE ORDER OF QUESTIONS! DO NOT REWRITE QUESTIONS! Parameters Validation Agent
If all questions have been asked, output exactly # PARAMS DESCRIPTION:
"COLLECT_COMPLETE". {}
# Instructions:
Summarize ptychography parameters from our previous conversation
and output JSON following the PARAMS DESCRIPTION according to the
Parameters Collection Agent Responder recommendations. Include ALL parameters described in PARAMS
DESCRIPTION in the JSON. Use "parameter name" in PARAMS
# PARAM VALUES: DESCRIPTION as variable names in JSON. If a parameter is not
{} mentioned in the conversation, use the default values in the
PARAMS DESCRIPTION. Do not make up values. Output MUST be JSON
# EXAMPLE ANSWERS: ONLY, do not add explanation before or after the JSON.
* beam energy is 20
* use multisliceptychography
* use grid scan positions Script Generation Agent
* do not use position correction # EXAMPLE RECON SCRIPT:
* set layer regularization coefficient to 0.7 {}
# Instructions: # USER PARAMS VALUES:
Answer the question asked based on the PARAM VALUES. {}
Answer the question in one simple sentence following the EXAMPLE
ANSWERS. Answer should not contain any instructions. # Instructions:
Stick to the exact values in the PARAM VALUES, don't make up or Generate a script following the EXAMPLE RECON SCRIPT, only
change values, don't try to convert values to other units. replace and fill in exact values from USER PARAMS VALUES.
Answer ONLY the question asked directly, don't add any Keep other code and values. Do not make up or change values. Do
explanation or comment. Don't repeat the question, just answer not add new lines. Do not add new code.
it. Don't ask follow up questions. The script should be surrounded by ```script and ``` only. Do not
add explainationbefore or after the script block.
# QUESTION: The accuracy of the script is very important, please make sure to
{} follow the instructions carefully.
Figure5: Promptsusedinthecomputationalexperiment.
11B UserCaseStudyLog
20240913-00:02:56 - Initializaing PEAR...
20240913-00:02:56 - ########## Settings ##########
20240913-00:02:56 - Automation level: 1
20240913-00:02:56 - LLM: gpt-4o-mini
20240913-00:02:56 - Knowledge base: neurips_demo
20240913-00:02:56 - Data’s base directory: /Modified/to/Hide/User/Info/
20240913-00:02:56 - Script directory: /Modified/to/Hide/User/Info/ptycho
20240913-00:02:56 - User name: User
20240913-00:02:56 - Computer name: lamda
20240913-00:02:56 - Matlab directory: /usr/local/bin/matlab
20240913-00:02:56 - External reconstruction script:
20240913-00:02:56 - ##############################
20240913-00:02:56 - PEAR: A driver file exists in the current working directory, it will be overwritten
.
20240913-00:02:56 - PEAR: Driver file created at driver.m
20240913-00:02:56 - PEAR: Hello User. Thank you for letting me assist with your ptychographic
reconstruction today.
20240913-00:02:56 - Agent: ParamsCollector
20240913-00:02:56 - PEAR: First I’d like to ask some questions about your data:
20240913-00:02:56 - PEAR: What is the scan number?
20240913-00:02:59 - User: 31
20240913-00:03:00 - PEAR: What is the beam energy (in keV)?
20240913-00:03:03 - User: 300
20240913-00:03:03 - PEAR: What is the radius of the bright field disk (in pixels)?
20240913-00:03:14 - User: 23.25
20240913-00:03:14 - PEAR: What is the convergence angle (in mrad)?
20240913-00:03:17 - User: 25
20240913-00:03:18 - PEAR: What is the detector size (in # of pixels)?
20240913-00:03:19 - User: 128
20240913-00:03:20 - PEAR: Do you want to load the initial object from an existing reconstruction? If so
, please provide the path to the reconstruction file.
20240913-00:03:22 - User: no
20240913-00:03:22 - PEAR: Do you want to generate the initial probe based on the ideal model or load it
from an existing reconstruction? If use ideal model, please provide the value of defocus (in
angstroms). If use existing probe, please provide the path to the reconstruction file.
20240913-00:03:44 - User: load an existing probe from /Modified/to/Hide/User/Info/Niter1000.mat
20240913-00:03:44 - PEAR: Is the initial probe accurate (similar size to the real probe)?
20240913-00:03:46 - User: yes
20240913-00:03:47 - PEAR: Do you want to generate scan positions assuming a perfect grid or load them
from an existing reconstruction? If you want to generate scan positions, please provide the scan
step size (in angstroms) and the number of scan points in both X and Y directions. If use existing
reconstructions, please provide the path to the reconstruction file.
20240913-00:04:05 - User: 128 x 128, step size is 0.2546 A
20240913-00:04:06 - PEAR: How many mixed-state probe modes do you want to use?
20240913-00:04:07 - User: 3
20240913-00:04:07 - PEAR: Which GPU do you want to use for reconstruction?
20240913-00:04:09 - User: 1
20240913-00:04:10 - PEAR: How many diffraction patterns does the scan have in total?
20240913-00:04:14 - User: 128 x 128
20240913-00:04:15 - PEAR: Did the sample drift during scan?
20240913-00:04:17 - User: no
20240913-00:04:17 - PEAR: What’s the estimated sample thickness (in angstroms)?
20240913-00:04:20 - User: 100
20240913-00:04:20 - PEAR: Thank you for answering my questions.
20240913-00:04:20 - Agent: ParamsRecommender
20240913-00:04:20 - PEAR: Next I will initialize some reconstruction parameters based on your inputs.
20240913-00:04:20 - Agent: _summarize_conversation
20240913-00:04:20 - PEAR: Summarizing previous conversation...
20240913-00:04:23 - - The scan number is 31.
- The beam energy is 300 keV.
- The radius of the bright field disk is 23.25 pixels.
- The convergence angle is 25 mrad.
- The detector size is 128 pixels.
- The initial object will not be loaded from an existing reconstruction.
- An existing probe will be loaded from the path provided.
- The initial probe is accurate and similar in size to the real probe.
- The scan positions will be generated assuming a perfect grid with a step size of 0.2546 angstrom and
128 x 128 scan points.
- Three mixed-state probe modes will be used.
- GPU 1 will be used for reconstruction.
- The total number of diffraction patterns for the scan is 128 x 128.
- The sample did not drift during the scan.
- The estimated sample thickness is 100 angstrom.
20240913-00:04:25 - PEAR: Based on the provided information and the recommendations, here are the
suggested reconstruction parameters:
1. **Update Batch Size**: Set the update batch size to \( \lfloor \sqrt{128 \times 128} \rfloor = 128
\).
2. **Gaussian Kernel Standard Deviation for Detector Blurring**: Since the beam energy is 300 keV, set
the standard deviation of the Gaussian kernel for detector blurring to **1**.
3. **Scan Position Correction**: Since the sample did not drift during the scan, set scan position
correction to **false**.
4. **Multislice Ptychography**: Given that the estimated sample thickness is 100 angstrom, set
multislice ptychography to **true** and the number of layers to **10** (1/10 of the sample
thickness).
125. **Number of Iterations**: Since the initial probe is accurate, set the number of iterations to
**50**.
These parameters should help optimize your ptychography reconstruction process.
20240913-00:04:25 - Agent: ParamsFormatter
20240913-00:04:28 - PEAR: Here are the current parameters:
20240913-00:04:28 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info/Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 50,
"update_batch_size": 128,
"number_of_probe_modes": 3,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0,
"diff_pattern_blur": 1,
"gpu_id": 1
}
20240913-00:04:28 - ########## Reconstruction No.1: ##########
20240913-00:04:28 - Agent: ParamsConfirmer
20240913-00:04:28 - PEAR: Let me know any changes you would like to make. If it looks good to you,
please say "LGTM".
20240913-00:04:51 - User: lgtm
20240913-00:04:51 - PEAR: Thank you for the feedback. I will create a reconstruction script using these
parameters.
20240913-00:04:51 - Agent: ScriptGenerator
20240913-00:04:51 - PEAR: Generating a reconstruction script...
20240913-00:04:57 - PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/
ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_1.m
20240913-00:04:57 - Agent: ScriptRunner
20240913-00:04:57 - PEAR: Running ptychographic reconstruction...
20240913-00:04:57 - PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...
20240913-00:04:57 - PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch "
driver(’/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_1.m’)"
20240913-00:04:57 - PEAR: Executing command /usr/local/bin/matlab -batch "driver(’/Modified/to/Hide/
User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_1.m’)"
20240913-00:12:23 - [init] : Preparing paths.
[Warning: Applying custom scan flip: 1 1 1 ]
[> In scans.positions.matlab_pos (line 14)
In scans.read_positions (line 20)
In core.initialize_ptycho (line 107)
In core.ptycho_recons/ptycho_call (line 172)
In core.ptycho_recons (line 289)
In ptycho_recon (line 576)
In ptycho_recon_pear (line 114)
In neurips_demo_gpt4o_mini_l1_ptycho_script_1 (line 44)
In run (line 99)
In driver (line 11)]
[init] : Preparing initial guess.
[init] : Preparing data using matlab APS data preparation.
[init] : Finished data preparation and initialization.
[ptycho] : Reconstructing S00031
[ptycho] : Calling engine GPU_MS
[GPU/CPU_MS-engine] : Intermediate results will be saved in the directory below every 50 iterations.
[GPU/CPU_MS-engine] : /Modified/to/Hide/User/Info/
[Warning: Applying custom data flip: 0 1 0 ]
[ptycho] : Elapsed time for engine GPU_MS: 425.7 s
Elapsed time is 438.322446 seconds.
20240913-00:12:23 - PEAR: Your command execution is successful :) Please take a look and give me some
feedback.
20240913-00:12:23 - Agent: QualityCollector
20240913-00:12:23 - PEAR: Please check your reconstructions and answer some questions:
20240913-00:12:24 - PEAR: Did the reconstruction converge?
20240913-00:12:44 - User: yes
20240913-00:12:44 - PEAR: Do you see any grid artifacts in the object?
20240913-00:12:47 - User: no
20240913-00:12:48 - PEAR: Is the initial probe accurate enough?
20240913-00:12:50 - User: yes
20240913-00:12:50 - PEAR: Do you see any structures in the last probe mode?
20240913-00:12:53 - User: yes
20240913-00:12:53 - PEAR: Is there anything else you want to tell me about the results?
20240913-00:13:01 - User: nothing at this moment
20240913-00:13:01 - PEAR: Thank you for your feedback!
1320240913-00:13:01 - Agent: UpdatesRecommender
20240913-00:13:01 - PEAR: Next I will suggest some changes to the parameters:
20240913-00:13:01 - Agent: _summarize_conversation
20240913-00:13:01 - PEAR: Summarizing previous conversation...
20240913-00:13:02 - - The reconstruction converged successfully.
- There are no grid artifacts present in the object.
- The initial probe is accurate enough.
- Structures are visible in the last probe mode.
- There is nothing else to report about the results at this moment.
20240913-00:13:03 - Based on the CONVERSATION SUMMARY, the situation is as follows:
- The initial probe is accurate enough.
- The reconstruction has converged.
- The last probe mode has structures.
### Recommendation:
* Increase the number of probe modes by 3.
20240913-00:13:03 - Agent: ParamsUpdater
20240913-00:13:07 - PEAR: Here are the updated parameters that will be used to create the next
reconstruction script
20240913-00:13:07 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info/Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 50,
"update_batch_size": 128,
"number_of_probe_modes": 6,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0,
"diff_pattern_blur": 1,
"gpu_id": 1
}
20240913-00:13:07 - PEAR: Do you want to run another reconstruction? If so, please say "yes".
20240913-00:13:18 - User: yes
20240913-00:13:18 - ########## Reconstruction No.2: ##########
20240913-00:13:18 - Agent: ParamsConfirmer
20240913-00:13:18 - PEAR: Let me know any changes you would like to make. If it looks good to you,
please say "LGTM".
20240913-00:13:21 - User: lgtm
20240913-00:13:21 - PEAR: Thank you for the feedback. I will create a reconstruction script using these
parameters.
20240913-00:13:21 - Agent: ScriptGenerator
20240913-00:13:21 - PEAR: Generating a reconstruction script...
20240913-00:13:26 - PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/
ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_2.m
20240913-00:13:26 - Agent: ScriptRunner
20240913-00:13:26 - PEAR: Running ptychographic reconstruction...
20240913-00:13:26 - PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...
20240913-00:13:26 - PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch "
driver(’/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_2.m’)"
20240913-00:13:26 - PEAR: Executing command /usr/local/bin/matlab -batch "driver(’/Modified/to/Hide/
User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_2.m’)"
20240913-00:25:12 - [init] : Preparing paths.
[Warning: Applying custom scan flip: 1 1 1 ]
[> In scans.positions.matlab_pos (line 14)
In scans.read_positions (line 20)
In core.initialize_ptycho (line 107)
In core.ptycho_recons/ptycho_call (line 172)
In core.ptycho_recons (line 289)
In ptycho_recon (line 576)
In ptycho_recon_pear (line 114)
In neurips_demo_gpt4o_mini_l1_ptycho_script_2 (line 44)
In run (line 99)
In driver (line 11)]
[init] : Preparing initial guess.
[init] : Preparing data using matlab APS data preparation.
[init] : Finished data preparation and initialization.
[ptycho] : Reconstructing S00031
[ptycho] : Calling engine GPU_MS
[GPU/CPU_MS-engine] : Intermediate results will be saved in the directory below every 50 iterations.
[GPU/CPU_MS-engine] : /Modified/to/Hide/User/Info/
[Warning: Applying custom data flip: 0 1 0 ]
[ptycho] : Elapsed time for engine GPU_MS: 684.4 s
Elapsed time is 697.096650 seconds.
1420240913-00:25:12 - PEAR: Your command execution is successful :) Please take a look and give me some
feedback.
20240913-00:25:12 - Agent: QualityCollector
20240913-00:25:12 - PEAR: Please check your reconstructions and answer some questions:
20240913-00:25:13 - PEAR: Did the reconstruction converge?
20240913-00:25:27 - User: yes
20240913-00:25:27 - PEAR: Do you see any grid artifacts in the object?
20240913-00:25:30 - User: no
20240913-00:25:30 - PEAR: Is the initial probe accurate enough?
20240913-00:25:34 - User: yes
20240913-00:25:34 - PEAR: Do you see any structures in the last probe mode?
20240913-00:25:42 - User: not anymore
20240913-00:25:43 - PEAR: Is there anything else you want to tell me about the results?
20240913-00:26:19 - User: each layer in the reconstructed object seems to have random features that are
not real
20240913-00:26:20 - PEAR: Thank you for your feedback!
20240913-00:26:20 - Agent: UpdatesRecommender
20240913-00:26:20 - PEAR: Next I will suggest some changes to the parameters:
20240913-00:26:20 - Agent: _summarize_conversation
20240913-00:26:20 - PEAR: Summarizing previous conversation...
20240913-00:26:21 - - The reconstruction converged successfully.
- There are no grid artifacts present in the object.
- The initial probe is accurate enough.
- There are no visible structures in the last probe mode.
- Each layer in the reconstructed object seems to have random features that are not real.
20240913-00:26:21 - * Increase the layer regularization by 0.3.
20240913-00:26:21 - Agent: ParamsUpdater
20240913-00:26:25 - PEAR: Here are the updated parameters that will be used to create the next
reconstruction script
20240913-00:26:25 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info/Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 100,
"update_batch_size": 100,
"number_of_probe_modes": 5,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0.3,
"diff_pattern_blur": 1,
"gpu_id": 1
}
20240913-00:26:25 - PEAR: Do you want to run another reconstruction? If so, please say "yes".
20240913-00:27:10 - User: yes
20240913-00:27:10 - ########## Reconstruction No.3: ##########
20240913-00:27:10 - Agent: ParamsConfirmer
20240913-00:27:10 - PEAR: Let me know any changes you would like to make. If it looks good to you,
please say "LGTM".
20240913-00:27:23 - User: lgtm
20240913-00:27:23 - PEAR: Thank you for the feedback. I will create a reconstruction script using these
parameters.
20240913-00:27:23 - Agent: ScriptGenerator
20240913-00:27:23 - PEAR: Generating a reconstruction script...
20240913-00:27:29 - PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/
ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_3.m
20240913-00:27:29 - Agent: ScriptRunner
20240913-00:27:29 - PEAR: Running ptychographic reconstruction...
20240913-00:27:29 - PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...
20240913-00:27:29 - PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch "
driver(’/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_3.m’)"
20240913-00:27:29 - PEAR: Executing command /usr/local/bin/matlab -batch "driver(’/Modified/to/Hide/
User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_3.m’)"
20240913-00:49:23 - [init] : Preparing paths.
[Warning: Applying custom scan flip: 1 1 1 ]
[> In scans.positions.matlab_pos (line 14)
In scans.read_positions (line 20)
In core.initialize_ptycho (line 107)
In core.ptycho_recons/ptycho_call (line 172)
In core.ptycho_recons (line 289)
In ptycho_recon (line 576)
In ptycho_recon_pear (line 114)
In neurips_demo_gpt4o_mini_l1_ptycho_script_3 (line 44)
In run (line 99)
In driver (line 11)]
15[init] : Preparing initial guess.
[init] : Preparing data using matlab APS data preparation.
[init] : Finished data preparation and initialization.
[ptycho] : Reconstructing S00031
[ptycho] : Calling engine GPU_MS
[GPU/CPU_MS-engine] : Intermediate results will be saved in the directory below every 50 iterations.
[GPU/CPU_MS-engine] : /Modified/to/Hide/User/Info/
[Warning: Applying custom data flip: 0 1 0 ]
[ptycho] : Elapsed time for engine GPU_MS: 1293.5 s
Elapsed time is 1306.163743 seconds.
20240913-00:49:23 - PEAR: Your command execution is successful :) Please take a look and give me some
feedback.
20240913-00:49:23 - Agent: QualityCollector
20240913-00:49:23 - PEAR: Please check your reconstructions and answer some questions:
20240913-00:49:23 - PEAR: Did the reconstruction converge?
20240913-00:56:04 - User: yes
20240913-00:56:05 - PEAR: Do you see any grid artifacts in the object?
20240913-00:56:15 - User: no
20240913-00:56:15 - PEAR: Is the initial probe accurate enough?
20240913-00:56:18 - User: yes
20240913-00:56:18 - PEAR: Do you see any structures in the last probe mode?
20240913-00:56:28 - User: no
20240913-00:56:28 - PEAR: Is there anything else you want to tell me about the results?
20240913-00:56:42 - User: the atoms still look a bit blurred
20240913-00:56:43 - PEAR: Thank you for your feedback!
20240913-00:56:43 - Agent: UpdatesRecommender
20240913-00:56:43 - PEAR: Next I will suggest some changes to the parameters:
20240913-00:56:43 - Agent: _summarize_conversation
20240913-00:56:43 - PEAR: Summarizing previous conversation...
20240913-00:56:44 - - The reconstruction converged successfully.
- There are no grid artifacts present in the object.
- The initial probe is accurate enough.
- There are no visible structures in the last probe mode.
- The atoms still appear a bit blurred.
20240913-00:56:44 - * Increase the standard deviation of the gaussian kernel for detector blurring by
0.5.
20240913-00:56:44 - Agent: ParamsUpdater
20240913-00:56:47 - PEAR: Here are the updated parameters that will be used to create the next
reconstruction script
20240913-00:56:47 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info/Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 100,
"update_batch_size": 100,
"number_of_probe_modes": 5,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0.3,
"diff_pattern_blur": 1.5,
"gpu_id": 1
}
20240913-00:56:47 - PEAR: Do you want to run another reconstruction? If so, please say "yes".
20240913-00:57:20 - User: yes
20240913-00:57:20 - ########## Reconstruction No.4: ##########
20240913-00:57:20 - Agent: ParamsConfirmer
20240913-00:57:20 - PEAR: Let me know any changes you would like to make. If it looks good to you,
please say "LGTM".
20240913-00:57:34 - User: set the update batch size to 256
20240913-00:57:38 - PEAR: Here are the updated parameters:
20240913-00:57:38 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info/Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
16"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 100,
"update_batch_size": 256,
"number_of_probe_modes": 5,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0.3,
"diff_pattern_blur": 1.5,
"gpu_id": 1
}
20240913-00:57:38 - PEAR: Let me know any changes you would like to make. If it looks good to you,
please say "LGTM".
20240913-00:57:50 - User: lgtm
20240913-00:57:50 - PEAR: Thank you for the feedback. I will create a reconstruction script using these
parameters.
20240913-00:57:50 - Agent: ScriptGenerator
20240913-00:57:50 - PEAR: Generating a reconstruction script...
20240913-00:57:56 - PEAR: The reconstruction script has been generated at /Modified/to/Hide/User/Info/
ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_4.m
20240913-00:57:56 - Agent: ScriptRunner
20240913-00:57:56 - PEAR: Running ptychographic reconstruction...
20240913-00:57:56 - PEAR: Executing script using /usr/local/bin/matlab on Modified-to-Hide-User-Info...
20240913-00:57:56 - PEAR: The MATLAB command used for reconstruction: /usr/local/bin/matlab -batch "
driver(’/Modified/to/Hide/User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_4.m’)"
20240913-00:57:56 - PEAR: Executing command /usr/local/bin/matlab -batch "driver(’/Modified/to/Hide/
User/Info/ptycho/neurips_demo_gpt4o_mini_l1_ptycho_script_4.m’)"
20240913-01:17:09 - [init] : Preparing paths.
[Warning: Applying custom scan flip: 1 1 1 ]
[> In scans.positions.matlab_pos (line 14)
In scans.read_positions (line 20)
In core.initialize_ptycho (line 107)
In core.ptycho_recons/ptycho_call (line 172)
In core.ptycho_recons (line 289)
In ptycho_recon (line 576)
In ptycho_recon_pear (line 114)
In neurips_demo_gpt4o_mini_l1_ptycho_script_4 (line 44)
In run (line 99)
In driver (line 11)]
[init] : Preparing initial guess.
[init] : Preparing data using matlab APS data preparation.
[init] : Finished data preparation and initialization.
[ptycho] : Reconstructing S00031
[ptycho] : Calling engine GPU_MS
[GPU/CPU_MS-engine] : Intermediate results will be saved in the directory below every 50 iterations.
[GPU/CPU_MS-engine] : /Modified/to/Hide/User/Info/
[Warning: Applying custom data flip: 0 1 0 ]
[ptycho] : Elapsed time for engine GPU_MS: 1132.4 s
Elapsed time is 1145.022578 seconds.
20240913-01:17:09 - PEAR: Your command execution is successful :) Please take a look and give me some
feedback.
20240913-01:17:09 - Agent: QualityCollector
20240913-01:17:09 - PEAR: Please check your reconstructions and answer some questions:
20240913-01:17:09 - PEAR: Did the reconstruction converge?
20240913-01:19:28 - User: yes
20240913-01:19:28 - PEAR: Do you see any grid artifacts in the object?
20240913-01:19:30 - User: no
20240913-01:19:31 - PEAR: Is the initial probe accurate enough?
20240913-01:19:36 - User: yes
20240913-01:19:36 - PEAR: Do you see any structures in the last probe mode?
20240913-01:19:39 - User: no
20240913-01:19:40 - PEAR: Is there anything else you want to tell me about the results?
20240913-01:19:42 - User: no
20240913-01:19:43 - PEAR: Thank you for your feedback!
20240913-01:19:43 - Agent: UpdatesRecommender
20240913-01:19:43 - PEAR: Next I will suggest some changes to the parameters:
20240913-01:19:43 - Agent: _summarize_conversation
20240913-01:19:43 - PEAR: Summarizing previous conversation...
20240913-01:19:44 - - The reconstruction converged successfully.
- There are no grid artifacts present in the object.
- The initial probe is accurate enough.
- There are no structures visible in the last probe mode.
- The user has no additional information to provide about the results.
- All diagnosis questions have been asked.
20240913-01:19:45 - * Increase the standard deviation of the gaussian kernel for detector blurring by
0.5.
20240913-01:19:45 - Agent: ParamsUpdater
20240913-01:19:48 - PEAR: Here are the updated parameters that will be used to create the next
reconstruction script
20240913-01:19:48 - {
"data_directory": "/Modified/to/Hide/User/Info/",
"scan_number": 31,
"beam_energy": 300,
"radius_bright_field": 23.25,
"convergence_angle": 25,
"size_of_diffraction_patterns": 128,
17"use_external_object": false,
"initial_object_path": "",
"use_external_probe": true,
"initial_probe_file": "/Modified/to/Hide/User/Info//Niter1000.mat",
"defocus": 0,
"use_external_positions": false,
"initial_position_file": "",
"grid_scan_positions": true,
"scan_step_size_x": 0.2546,
"scan_step_size_y": 0.2546,
"number_scan_points_x": 128,
"number_scan_points_y": 128,
"number_of_iterations": 100,
"update_batch_size": 256,
"number_of_probe_modes": 5,
"position_correction": false,
"multislice_ptycho": true,
"object_thickness": 100,
"number_of_layers": 10,
"layer_regularization_coefficient": 0.3,
"diff_pattern_blur": 2.0,
"gpu_id": 1
}
20240913-01:19:48 - PEAR: Do you want to run another reconstruction? If so, please say "yes".
20240913-01:20:20 - User: no
20240913-01:20:20 - PEAR: Reconstructions completed. Have a nice day!
18