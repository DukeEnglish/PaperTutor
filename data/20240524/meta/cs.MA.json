[
    {
        "title": "CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System",
        "authors": "Qinghua GuanJinhui OuyangDi WuWeiren Yu",
        "links": "http://arxiv.org/abs/2405.14691v1",
        "entry_id": "http://arxiv.org/abs/2405.14691v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14691v1",
        "summary": "The spatiotemporal data generated by massive sensors in the Internet of\nThings (IoT) is extremely dynamic, heterogeneous, large scale and\ntime-dependent. It poses great challenges (e.g. accuracy, reliability, and\nstability) in real-time analysis and decision making for different IoT\napplications. The complexity of IoT data prevents the common people from\ngaining a deeper understanding of it. Agentized systems help address the lack\nof data insight for the common people. We propose a generic framework, namely\nCityGPT, to facilitate the learning and analysis of IoT time series with an\nend-to-end paradigm. CityGPT employs three agents to accomplish the\nspatiotemporal analysis of IoT data. The requirement agent facilitates user\ninputs based on natural language. Then, the analysis tasks are decomposed into\ntemporal and spatial analysis processes, completed by corresponding data\nanalysis agents (temporal and spatial agents). Finally, the spatiotemporal\nfusion agent visualizes the system's analysis results by receiving analysis\nresults from data analysis agents and invoking sub-visualization agents, and\ncan provide corresponding textual descriptions based on user demands. To\nincrease the insight for common people using our framework, we have agnentized\nthe framework, facilitated by a large language model (LLM), to increase the\ndata comprehensibility. Our evaluation results on real-world data with\ndifferent time dependencies show that the CityGPT framework can guarantee\nrobust performance in IoT computing.",
        "updated": "2024-05-23 15:27:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14691v1"
    },
    {
        "title": "Global Behavior of Learning Dynamics in Zero-Sum Games with Memory Asymmetry",
        "authors": "Yuma FujimotoKaito AriuKenshi Abe",
        "links": "http://arxiv.org/abs/2405.14546v1",
        "entry_id": "http://arxiv.org/abs/2405.14546v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14546v1",
        "summary": "This study examines the global behavior of dynamics in learning in games\nbetween two players, X and Y. We consider the simplest situation for memory\nasymmetry between two players: X memorizes the other Y's previous action and\nuses reactive strategies, while Y has no memory. Although this memory\ncomplicates the learning dynamics, we discover two novel quantities that\ncharacterize the global behavior of such complex dynamics. One is an extended\nKullback-Leibler divergence from the Nash equilibrium, a well-known conserved\nquantity from previous studies. The other is a family of Lyapunov functions of\nX's reactive strategy. These two quantities capture the global behavior in\nwhich X's strategy becomes more exploitative, and the exploited Y's strategy\nconverges to the Nash equilibrium. Indeed, we theoretically prove that Y's\nstrategy globally converges to the Nash equilibrium in the simplest game\nequipped with an equilibrium in the interior of strategy spaces. Furthermore,\nour experiments also suggest that this global convergence is universal for more\nadvanced zero-sum games than the simplest game. This study provides a novel\ncharacterization of the global behavior of learning in games through a couple\nof indicators.",
        "updated": "2024-05-23 13:25:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14546v1"
    },
    {
        "title": "AI-Olympics: Exploring the Generalization of Agents through Open Competitions",
        "authors": "Chen WangYan SongShuai WuSa WuRuizhi ZhangShu LinHaifeng Zhang",
        "links": "http://arxiv.org/abs/2405.14358v1",
        "entry_id": "http://arxiv.org/abs/2405.14358v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14358v1",
        "summary": "Between 2021 and 2023, AI-Olympics, a series of online AI competitions was\nhosted by the online evaluation platform Jidi in collaboration with the IJCAI\ncommittee. In these competitions, an agent is required to accomplish diverse\nsports tasks in a two-dimensional continuous world, while competing against an\nopponent. This paper provides a brief overview of the competition series and\nhighlights notable findings. We aim to contribute insights to the field of\nmulti-agent decision-making and explore the generalization of agents through\nengineering efforts.",
        "updated": "2024-05-23 09:33:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14358v1"
    },
    {
        "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration",
        "authors": "Yang ZhangShixin YangChenjia BaiFei WuXiu LiXuelong LiZhen Wang",
        "links": "http://arxiv.org/abs/2405.14314v1",
        "entry_id": "http://arxiv.org/abs/2405.14314v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14314v1",
        "summary": "Grounding the reasoning ability of large language models (LLMs) for embodied\ntasks is challenging due to the complexity of the physical world. Especially,\nLLM planning for multi-agent collaboration requires communication of agents or\ncredit assignment as the feedback to re-adjust the proposed plans and achieve\neffective coordination. However, existing methods that overly rely on physical\nverification or self-reflection suffer from excessive and inefficient querying\nof LLMs. In this paper, we propose a novel framework for multi-agent\ncollaboration that introduces Reinforced Advantage feedback (ReAd) for\nefficient self-refinement of plans. Specifically, we perform critic regression\nto learn a sequential advantage function from LLM-planned data, and then treat\nthe LLM planner as an optimizer to generate actions that maximize the advantage\nfunction. It endows the LLM with the foresight to discern whether the action\ncontributes to accomplishing the final task. We provide theoretical analysis by\nextending advantage-weighted regression in reinforcement learning to\nmulti-agent systems. Experiments on Overcooked-AI and a difficult variant of\nRoCoBench show that ReAd surpasses baselines in success rate, and also\nsignificantly decreases the interaction steps of agents and query rounds of\nLLMs, demonstrating its high efficiency for grounding LLMs. More results are\ngiven at \\url{https://read-llm.github.io/}.",
        "updated": "2024-05-23 08:33:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14314v1"
    },
    {
        "title": "Agent Planning with World Knowledge Model",
        "authors": "Shuofei QiaoRunnan FangNingyu ZhangYuqi ZhuXiang ChenShumin DengYong JiangPengjun XieFei HuangHuajun Chen",
        "links": "http://arxiv.org/abs/2405.14205v1",
        "entry_id": "http://arxiv.org/abs/2405.14205v1",
        "pdf_url": "http://arxiv.org/pdf/2405.14205v1",
        "summary": "Recent endeavors towards directly using large language models (LLMs) as agent\nmodels to execute interactive planning tasks have shown commendable results.\nDespite their achievements, however, they still struggle with brainless\ntrial-and-error in global planning and generating hallucinatory actions in\nlocal planning due to their poor understanding of the ''real'' physical world.\nImitating humans' mental world knowledge model which provides global prior\nknowledge before the task and maintains local dynamic knowledge during the\ntask, in this paper, we introduce parametric World Knowledge Model (WKM) to\nfacilitate agent planning. Concretely, we steer the agent model to\nself-synthesize knowledge from both expert and sampled trajectories. Then we\ndevelop WKM, providing prior task knowledge to guide the global planning and\ndynamic state knowledge to assist the local planning. Experimental results on\nthree complex real-world simulated datasets with three state-of-the-art\nopen-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our\nmethod can achieve superior performance compared to various strong baselines.\nBesides, we analyze to illustrate that our WKM can effectively alleviate the\nblind trial-and-error and hallucinatory action issues, providing strong support\nfor the agent's understanding of the world. Other interesting findings include:\n1) our instance-level task knowledge can generalize better to unseen tasks, 2)\nweak WKM can guide strong agent model planning, and 3) unified WKM training has\npromising potential for further development. Code will be available at\nhttps://github.com/zjunlp/WKM.",
        "updated": "2024-05-23 06:03:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.14205v1"
    }
]