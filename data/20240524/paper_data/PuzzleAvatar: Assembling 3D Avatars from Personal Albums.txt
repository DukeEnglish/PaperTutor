PuzzleAvatar: Assembling 3D Avatars from Personal Albums
YULIANGXIU,MaxPlanckInstituteforIntelligentSystems,Germany
YUFEIYE,MaxPlanckInstituteforIntelligentSystems,GermanyandCarnegieMellonUniversity,USA
ZHENLIU,MaxPlanckInstituteforIntelligentSystems,GermanyandMila,UniversitédeMontréal,Canada
DIMITRIOSTZIONAS,UniversityofAmsterdam,Netherlands
MICHAELJ.BLACK,MaxPlanckInstituteforIntelligentSystems,Germany
…
“<B> shirt” Personal “OOTD” Photo Collection (Subject B)
PuzzleBooth “<A> shirt”
+SDS
Personal “OOTD” Photo Collection (Subject A) Textured 3D Human A Virtual Try-On (A+B) Text-guided Editing “<A> shirt” → “<A> coat”
Fig.1. PuzzleAvatarreconstructsafaithful,personalized,textured3Dhumanavatarfromapersonalphotocollection.Thatis,ittakesasinputasetof“OOTD”
(OutfitOfTheDay)personalphotoswithunconstrainedbodyposes,cameraposes,framing,lightingandbackgrounds,albeitwithaconsistentoutfitand
hairstyle.Alltheseconsistentfactorsarelearnedasseparateuniquetokens<asset X>inacompositionalmanner,likepiecesofapuzzle.PuzzleAvatar
allowsuseasilyinter-changetokensfordownstTreexatumred t3aDs Hkusm,asn uBchasforcustomizingavatarsandperformingvirtualtry-onwhilepreservingidentity,seevideo.
1 INTRODUCTION
Generatingpersonalized3DavatarsiscrucialforAR/VR.However,recent
text-to-3Dmethodsthatgenerateavatarsforcelebritiesorfictionalchar-
Inallchaosthereisacosmos,inalldisorderasecretorder.
acters,strugglewitheverydaypeople.Methodsforfaithfulreconstruction
typicallyrequirefull-bodyimagesincontrolledsettings.Whatifuserscould CarlJung
justuploadtheirpersonal“OOTD”(OutfitOfTheDay)photocollection
Advancesintext-guideddigitalhumansynthesisopenthedoor
andgetafaithfulavatarinreturn?Thechallengeisthatsuchcasualphoto
to 3D avatar creation with arbitrary skin tones, clothing styles,
collectionscontaindiverseposes,challengingviewpoints,croppedviews,
andocclusion(albeitwithaconsistentoutfit,accessories…alonngd shhirta…irstyle…)b.luWe jeaens… …h yea lloi wr hs att …ylesandaccessories.Whiletheseadvanceshavedemonstrated
addressthisnovel“Album2Human”taskbydevelopingPuzzleAvatar,a greatpotentialbygeneratingiconicfigures(suchasSupermanor
Text-guided Attributes Editing
novelmodelthatgeneratesafaithful3Davatar(inacanonicalpose)from BruceLee)andeditingspecifichumanfeatures(suchaswavyhair
apersonalOOTDalbum,bypassingthechallengingestimationofbody orfullbeards),theproblemofcraftingone’spersonalizedfull-body
andcamerapose.Tothisend,wefine-tuneafoundationalvision-language avatarisrelativelyunexplored.Imaginethatyouaregivenaper-
model(VLM)onsuchphotos,encodingtheappearance,identity,garments, sonal“outfitoftheday”(OOTD)photoalbumincasualsnapshots:
hairstyles,andaccessoriesofapersonintoseparatelearnedtokens,instill-
strollingthroughapark,crouchingtotieashoelace,seatedatacafe,
ingthesecuesintotheVLM.Ineffect,weexploitthelearnedtokensas
etc.Thesesnapshots,capturingfull-bodyactions,upper-bodyposes
“puzzlepieces"fromwhichweassembleafaithful,personalized3Davatar.
andclose-upselfieswithdiversebackgrounds,lightingandcam-
Importantly,wecancustomizeavatarsbysimplyinter-changingtokens.As
erasettings,formarichphotocollection.Notably,thiscollectionis
abenchmarkforthisnewtask,wecreateanewdataset,calledPuzzleIOI,
with41subjectsinatotalofnearly1kOOTDconfigurations,inchalleng- relatively“unconstrained”,thatis,itsonlyconstraintishavingacon-
ingpartialphotoswithpairedground-truth3Dbodies.Evaluationshows sistentidentity,outfit,hairstyleandaccessories,whileeveryother
thatPuzzleAvatarnotonlyhashighreconstructionaccuracy,outperforming factorcanvaryarbitrarily;seeFig.1.Canweeffectivelyconstruct
TeCHandMVDreamBooth,butalsoauniquescalabilitytoalbumphotos, fromthisalbumapersonalized3Davatarthatvividlycharacterizes
andhasdemonstratingstrongrobustness.Ourmodelanddatawillbepublic. theuser’sclothes,physique,andfacialdetails?Inthiswork,we
CCSConcepts:•Computingmethodologies→Appearanceandtexture investigatethisnoveltask,whichwecall“Album2Human”,that
representations;Reconstruction;Shapeinference. transformseverydayalbumcollectionsintotextured3Dhumans.
Comparedtoworkthatreconstructsgeneral3Dscenesfrompho-
AdditionalKeyWordsandPhrases:Text-to-ImageDiffusionModel,Image-
toswithvaryinglightingconditions,croppingratio,background
basedModeling,Text-guided3DGeneration,DigitalHuman
andcamerasettings[Martin-Bruallaetal.2021;Sunetal.2022],
Authors’addresses:YuliangXiu,yuliang.xiu@tuebingen.mpg.de,MaxPlanckInstitute Album2Humanismorechallengingduetotheadditionalfactor
forIntelligentSystems,Germany;YufeiYe,yeyf13.judy@gmail.com,MaxPlanckInsti-
ofvaryingbodyarticulation.Ontheotherhand,Album2Human
tuteforIntelligentSystems,GermanyandCarnegieMellonUniversity,USA;ZhenLiu,
zhen.liu@tuebingen.mpg.de,MaxPlanckInstituteforIntelligentSystems,Germanyand drasticallydiffersfrompriorwork[Alldiecketal.2018b;Pengetal.
Mila,UniversitédeMontréal,Canada;DimitriosTzionas,d.tzionas@uva.nl,University 2023;Vlasicetal.2009]thatcreatespersonalizedavatarsfromim-
ofAmsterdam,Netherlands;MichaelJ.Black,black@tuebingen.mpg.de,MaxPlanck
agescapturedinlaboratorysettings[Chengetal.2023;Işıketal.
InstituteforIntelligentSystems,Germany.
4202
yaM
32
]VC.sc[
1v96841.5042:viXra2 • Xiu,etal.
Full-body image or video Multi-view video w/ calibrated cameras PuzzleIOI Benchmark Real in-the-wild photos
Monocular video w/ standard (T/A) body pose
Previous Settings Our Settings
Fig.2. Imagesettingsforavatarcreation.Pastwork(left)requiresimageswithfull-bodyvisibility,knowncameracalibration,orsimplehumanposes.Our
PuzzleAvatarmethodoperatesonin-the-wildphotos(right);itassumesaconsistentoutfit,hairstyleandaccessories,butdealswithunconstrainedhuman
poses,camerasettings,lightingandbackground).OurPuzzleIOIdatasetcontainsmulti-viewimageswithchallengingcropspairedwith3Dgroundtruth.
2023;Maetal.2020;Shenetal.2023;Xiongetal.2024;Yuetal. learnedtokensareusedaspuzzlepiecestoassembleavatars,guided
2021;Zhengetal.2019],inwhichfullhumanbodiesinlimitedbody bytextprompts.Thus,wecallourmethod“PuzzleAvatar”.
posesarecapturedusingwellcalibratedandsynchronizedcameras SincethereexistsnobenchmarkforournewAlbum2Human
withcontrolledlightingandsimplebackgrounds;seeFig.2. task,wecollectanewdataset,calledPuzzleIOI,of41subjectsina
Whileitispossibletocreateavatarsfrommonocular(imageor totalofroughly1kconfigurations(outfits,accessories,hairstyles).
video)inputasshownbysomemethods[Habermannetal.2020; Ourevaluationmetricsincludeboth3Dreconstructionerrors(e.g.,
Xiuetal.2022;Yangetal.2023],suchmethodsperformpoorlyfor Chamferdistances,P2Sdistances)betweenreconstructedshapes
unusualbodyposes,motionblur,andocclusions,becausetheyrely and ground-truth 3D scans, as well as 2D image similarity mea-
onaccuratehumanandcameraposeestimationfromfull-bodyshots. sures (e.g.,PSNR,SSIM)betweenrenderedmulti-viewimagesof
Instead,webypassposeestimation,andfollowthenewparadigmof the reconstructed surface and ground-truth textured scans. Our
“reconstructionasconditionalgeneration”,asrecentlydemonstrated PuzzleAvatariscompatiblewithdifferenttypesofdiffusionmodels.
forText-to-Image(T2I)generation[Gaoetal.2023;Huangetal. WeevaluatethisonPuzzleIOIusingtwodiffusionmodels,namely
2024b;Wuetal.2024;Yangetal.2024;Zhangetal.2023].Specifi- single-viewStableDiffusion[Rombachetal.2022]andmulti-view
cally,theseworkscastreconstructionfrompartialobservationsas MVDream[Shietal.2024].Moreover,weevaluatethecontribution
“inpainting”unobservedregionsthroughfoundational-modelpri- ofeachmodelcomponentbothqualitativelyandquantitativelywith
ors,whileimposingcross-viewconsistency.WeadaptexistingT2I anin-depthablationanalysis(Section4.4).
work[Avrahamietal.2023]tolearnsubject-specificpriorsfrom Insummary,herewemakethefollowingmaincontributions:
apersonalOOTDimagecollection,byfinetuningT2Imodelson Task:Weintroduceanoveltask,called“Album2Human”,forrecon-
suchimagestocaptureidentity,piecesofclothing,accessories,and structinga3Davatarfromapersonalphotoalbumwithaconsistent
hairstyleintouniqueandinter-exchangeabletokens,andextracting outfit,hairstyleandaccessories,butunconstrainedhumanpose,
3DgeometryandtexturewithScoreDistillationSampling(SDS) camerasettings,framing,lightingandbackground.
basedtechniques[Pooleetal.2023].Metaphorically,ourmodelswal- Benchmark:Forevaluationofournoveltask,wecollectanew
lowsrelatively“unstructured”dataanddigeststhisintoa“structured dataset, called PuzzleIOI, with challenging cropped images and
library”;thatis,“seekingorderinchaos,findingharmonyinturmoil.” paired3Dgroundtruth.Thisfacilitatesquantitativelyevaluating
OurinsighttotreatT2Imodelsaspersonalizedpriorsenablesus methodsonboth3Dreconstructionandview-synthesisquality.
tonotonlyavoidexplicitper-pixelcorrespondencestoacanonical Methodology:PuzzleAvatarfollowsthefreshparadigmof“recon-
humanspace,butalsotobuildavatarsinacompositionalmanner.To structionasconditionalgeneration”,thatis,itperformsimplicit
thisend,givenaphotocollectionofaperson,variousassetsareex- humancanonicalizationusingapersonalizedT2Imodeltobypass
tractedviaanopen-vocabularysegmentor[Renetal.2024],suchas explicitposeestimation,orre-projectionpixellosses.
theface,garments,accessories,andhairstyles.Eachoftheseassetsis Analysis:Weconductdetailedevaluationandablationstudiesto
labeledbyauniquetokenas“<asset X>”.Weexploitthesetoken- analyzetheeffectivenessandscalabilityofPuzzleAvatarandeach
assetpairs,tofinetuneapre-trainedT2Imodel,sothatitlearns ofitscomponents,sheddinglightonpotentialfuturedirections.
togenerate“personalized”assetsgivenarespectivetoken.Based Downstreamapplications:WeshowthatPuzzleAvatar’shighly-
onthispersonalizedT2Imodel,weproducea3Dhumanavatar modular tokens and text guidance facilitates downstream tasks
viaScoreDistillationSampling(SDS)givenadescriptiveandcom- throughtwoexamples: charactereditingandvirtualtry-on.
positional text prompt, e.g., “a DSLR photo of a man, with Pleasecheckoutmorequalitativeresultsanddemosofappli-
<asset1> face, wearing <asset0> shirt, ...”(seeFig.1). cationsinvideo.PuzzleAvatarisasteptowardspersonalizing3D
Here,eachuniqueassetislikeapuzzlepiece,characterizingthe avatars.Todemocratizethis,codeandPuzzleIOIdatasetwillbe
identity,hairstyleanddressingstyleoftheperson.Inasense,the madepublicforonlyresearchpurpose.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 3
2 RELATEDWORK
beexploitedfordownstreamtasks.Inparticular,Score-Distillation-
3DHumanCreation.Manyworkshaveexploredhowtorecon- Samplingtechniquesstandout[Pooleetal.2023;Wangetal.2023a]
structclothedhumansfromvisualcueslikemulti-viewimages[Lin fordistilling“commonknowledge"fromtext-to-imagemodelsto-
etal.2024;Pengetal.2023;Saitoetal.2019]orfull-shotmonocu- wardscreating3Dobjects.Workonmodelcustomizationinjects
larvideo[Alldiecketal.2018a,b;Lietal.2020;Wengetal.2022]. new concepts via fine-tuning (partial or whole) pre-trained net-
Recently,alotofworksstrivetocreatehumanavatarscharacter- works[Avrahamietal.2023;Jainetal.2022;Kumarietal.2023;Liu
ized by language. Initial work guided by language uses a CLIP etal.2024b;Ruizetal.2023].Otherworkre-purposesthediffusion
embedding[Hongetal.2022]tosculptcoarsebodyshape.Recent modelstonewtasks[Fuetal.2024b;Keetal.2024;Kocsisetal.2024].
work[Caoetal.2024;Huangetal.2023a;Kolotourosetal.2023; Weleveragealltheabovetechniquesforfaithful3Dhuman-avatar
Liaoetal.2024;Wangetal.2023b]capturesfinergeometryand generationfromnaturalimages,achallengingtaskinvolvingwidely
texture for a clothed human, or multiple humans, by exploiting varyingappearance,lighting,backgrounds,bodyandcameraposes.
large-scaletext-to-imagemodelsandScoreDistillationSampling
(SDS) [Poole et al. 2023; Wang et al. 2023a]. In addition to text, 3 METHOD
whensubjectimagesareavailable,theyareusedtofinetunethe
pretrainedmodel[Ruizetal.2023]andtoencouragefidelityvia
Givenanimagecollection{I 1,I 2,...I𝑁}ofaperson,weaimto
re-projectionlosses[Gaoetal.2023;Huangetal.2023b,2024b;Yang
builda3Davatarthatcapturestheperson’sshape𝜓 𝑔andappearance
etal.2024].WhileSDSframeworkstypicallytakeafewthousand
𝜓 𝑐.Notably,personaldaily-lifephotosareunconstrained(seeFig.2)
as humans (1) appear in diverse poses and scales, (2) are often
iterations,otherwork[Chenetal.2024]speedsuptheprocessby
occludedorlargelytruncated,and(3)arecapturedfromunknown
one-stepgenerationconditionedonagivenimageinput.However,
viewpointsindiversebackgrounds.Thus,cameracalibrationand
allimage-conditionedmethodsassumereliablehumanposeesti-
posecanonicalizationforthesephotosareextremelychallenging,
mation[Pavlakosetal.2019]asaproxyrepresentationtodraw
makingdirectreconstructionofhumanavatarsdifficult.
correspondencesbetweentheinputimageandthereconstructed3D
Ourkeyinsightistocircumventestimatinghumanbodyposes
avatar.Hence,theyrequireimageswithcleanbackgrounds,com-
andcameras,and,instead,toperformimplicithumancanonical-
monbodyposes,andfull-bodyviewswithoutcrops.Furthermore,
izationviaafoundationvision-languagemodel(e.g.,StableDiffu-
externalcontrollers(e.g.,ControlNet[ZhangandAgrawala2023],
sion[Rombachetal.2022]).Ourmethodissummarizedvisuallyin
Zero123[Liuetal.2023])andadditionalgeometricregularizers(e.g.,
Fig.3,andhastwomainstages.Specifically,wefirst“decompose”
LaplacianandEikonal[Chenetal.2023])appearessentialtoachieve
photosintomultipleassets(e.g.,garments,accessories,faces,hair),
high-qualityoutput.Incontrast,PuzzleAvatardoesnotrequireany
allofwhicharelinkedwithuniquelearnedtokensbyapersonalized
ofthese,thus,itisuniquelycapableofoperatingonunconstrained
T2Imodel,PuzzleBooth(Sec.3.1),thatis𝐺 inFig.3.Then,we
personal-albumphotos. puzzle
Pose-FreeReconstructioninthewild.Inourwork,theterm “compose”thesemultipleassetsintoa3Dfull-bodyrepresentation
“pose”refersnotonlytocameraposebutalsotobodyarticulation. 𝜓 𝑔,𝜓 𝑐 viaScoreDistillationSampling(SDS)(Sec.3.2).
Cameraposeplaysacrucialrolein3Dreconstruction,asit“anchors”
3Dgeometryonto2Dimages[Mildenhalletal.2021],however,es- 3.1 PuzzleBooth–PersonalizePuzzlePieces
timatingitforin-the-wildimagesishighlychallenging.Thus,to
Ourfirststepistosegmentsubjectimagesintomultipleassetsrepre-
accountforcameraestimationerrors,someworkleveragesjointop-
sentingdifferenthumanpartssuchastrousers,shoes,andhairstyle.
timizationbetweentheobjectandcamera[Linetal.2021;Wangetal.
Whileonecouldbuildeachassetindividually,weadaptthe“Break-
2021;Xiaetal.2022],off-the-shelfgeometriccueestimates[Bian
A-Scene”[Avrahamietal.2023],whichshowsthatjointlylearning
etal.2023;Fuetal.2024a;Meulemanetal.2023],orlearning-based
multipleconceptssignificantlyboostsperformance,possiblybe-
cameraestimation[Wangetal.2024c,b;Zhangetal.2024].Body
causethisfacilitatesglobalreasoningwhenmultipleregionsare
poseisalsohardtoestimatefromin-the-wildimagesandismuch
simultaneouslygenerated.Suchastrategyisevenmorebeneficialin
higherdimensionalthancamerapose.Someworkcanreconstruct
oursettingsincehuman-relatedconcepts,suchasfaceandhair,are
staticscenesfromin-the-wildimageswithchallengingillumination
hardertolearnastheirpropertiesarestronglycorrelatedcompared
conditionsandbackgrounds[Martin-Bruallaetal.2021;Sunetal.
toclearlydistinctobjectsinthesettingof“Break-A-Scene.”
2022],butthesecannotbeappliedtoarticulatedobjects,likehu-
AssetCreation.Allimagesaresegmentedintomultipleassets
mans.Inourwork,wetackleallabovechallengesfor“pose-free”
humanreconstruction.Thatis,wetacklein-the-wildphotoswith
𝑉 𝑘,eachofwhichisassociatedwithasegmentationmaskM𝑘,a
unknowncameraposes,unknownbodyposes,possiblytruncated
dedicatedlearnabletoken[𝑣 𝑘],anditstextualname[𝑐 𝑘],suchas
“pants”or“skirt.”Inaddition,wealsoobtainacoarseviewdirection
images(e.g.headshots),anddiversebackgroundsandillumination
𝑑foreachimage.Allsuchinformationisobtainedautomaticallyby
conditions,whicharehighlychallengingforexistingmethods.
Grounded-SAM[Renetal.2024]andGPT-4V[OpenAI2023].Specif-
LargeVision-LanguageModels.Largefoundationmodelshave
ically,wequeryGPT-4Vwithanimagetodirectlygettheproperty
achievedgreatprogressinvisualunderstanding[Kirillovetal.2023;
Lietal.2022;Radfordetal.2021]andgeneration[Athanasiouetal.
ofeachasset[𝑐 𝑘]andcoarseviewdirection𝑑.Then,giventhefull
2023;Brooksetal.2024;Rombachetal.2022].Astheyaretrained listofqueriedassetnames{[𝑐 𝑘]} 𝑘𝐾 =1,Grounded-SAMoutputsseg-
onatremendousamountofdata,theirstronggeneralizabilitycan mentationmasksiftheyarepresent.PleaserefertoAppendixAfor
ourfullprompttemplate.4 • Xiu,etal.
< asset 01 > < asset 02 >
Nvdiffrast
Grounded-SAM PuzzleBooth
Geometry
GPT-4V < asset 03 > < asset 04 >
……
Texture
Personal “OOTD” Photo Collections Asset Creation
Stage 1 (Sec 3.1) — Break Human into Puzzle Pieces to Train PuzzleBooth Stage 2 (Sec 3.2) — Put Puzzle Pieces Together via SDS
“DSLR photo of a man” + wearing <asset 03> pants, and <asset 04> sneakers <asset 04>
- wearing <asset 02> T-shirts
- with <asset 01> face,
Cross-
- ww ee aa rr ii nn gg < <a as ss se et t 0 04 2> > s Tn -sea hk ire tr ss , + T2I A Mtte an st kio sn <asset 03>
<asset 03> pants, and Diffuser
<asset 04> sneakers
Synthetic Paired Prior
Union-Sampling Diffusion Model Fine-tuning (Text-Encoder, UNet)
Fig.3. OverviewofPuzzleAvatar.Theupperfigureshowsthetwomainstages:(1)PuzzleBooth(Section3.1),wheretheunconstrainedphotocollections Textured 3D Human
arecaptionedandsegmentedtocreatepersonalizedpuzzlepieces,fortrainingPuzzleBooth,𝐺 puzzle,and(2)Create-3D-Avatar (Section3.2),wherethe
T-posedtexturedtetrahedralbodymeshisoptimizedusingamulti-viewSDSlossL .ThebottomfigureillustratesthetrainingdetailsofPuzzleBooth;the
SDS
Text-EncoderandtheUNetofT2IDiffuser(i.e.,StableDiffusion)arefine-tunedusingthemaskeddiffusionloss,L (Eq.(1)),cross-attentionloss,L
rec attn
(Eq.(2)),andpriorpreservationloss,L (Eq.(3)).Componentsmarkedinlightbluearetrainableoroptimizable.
prior
Two-StagePersonalization.Wefinetunethepretrainedtext-to- whereM∪istheunionmask,and𝜖 𝜃(𝑧 𝑡,𝑡,𝑝 ∪)isthedenoisedoutput
imagediffusionmodel[Rombachetal.2022;Shietal.2024]sothat atdiffusionstep𝑡 giventheunionprompt,𝑝 ∪.
itadaptstothenewassets.Following“Break-A-Scene”[Avrahami Todisentangledifferentlearnedassets,weuseaCross-Attention
etal.2023],weoptimizethe…l “ong t s ehirt x… t”p… ablue r je tan ,s… i.e.,…y tell how h eat… textembeddingof Loss[Avrahamietal.2023]toencourageeachofthenewly-added
Text-guided Attributes Editing
assettoken[𝑣 𝑗],andthe“visual”part,i.e.,theweightsofthediffu- tokenstobeexclusivelyassociatedwithonlythetargetasset:
s oi fo tn hem ao sd se el t, ti on kt ew nso [s 𝑣t 𝑘a ]ge as r: eI on pt th ime ifi zr es dt wst ia tg he a,o lan rl gy et le ex at re nm inb ge rd ad tein .g Ins L attn=E 𝑧,𝑗,𝑡(cid:2) ∥CA𝜃(𝑣 𝑗,𝑧 𝑡)−M𝑗∥2 2(cid:3), (2)
thesecondstage,boththe“text”and“visual”partareoptimized whereCA𝜃(𝑣 𝑗,𝑧 𝑡)isthecross-attentionmapinthediffusionU-Net
withasmalllearningrate.Thisstrategyeffectivelypreventsguid- betweenthenewly-addedtoken,[𝑣 𝑗],andthevisualfeature,𝑧 𝑡.
ancecollapse[Gaoetal.2024]betweennewlyintroducedtokens Lastly,weapplyaPriorPreservationLoss [Ruizetal.2023]to
[𝑣 𝑘]andexistingassetnames[𝑐 𝑘],or,equivalently,preservesthe retainthegeneralizationcapabilityofthevanillaT2Imodel—Sta-
compositionalityofvisualconcepts. bleDiffusion(SD-2.1).Themodelistrainedtoreconstructimages
Duringtraining,werandomlyselect,foreveryimageI,asubset withgeneralconceptswhenthespecialtokensareremovedfrom
ofassetsthatappearintheimageandtrainthemodelontheunion prompts.Generalhumanimagescomefromtwosources:(1)Gen-
setoftheseselectedassets.Thisunionsamplingstrategy,originally erated images, I gp er n, come from SD. (2) Synthetic color-normal
introduced in [Avrahami et al. 2023], is crucial for effective pairs(seeFig.4),Ipr ,renderedfrommultipleviews,comefrom
syn
assetdisentanglement.Specifically,themaskunionisdoneviaa THuman2.0[Yuetal.2021].Thelatteristoimprovethegeometry
pixel-wiseunionoperationM∪=∪ 𝑖𝑗 =1M𝑖,whiletheimageunion qualityandcolor-normalconsistency[Huangetal.2024a].Instead
appliestheunionmaskontheimage,I∪=I⊙M∪.Theuniontext ofapplyingpriorpreservationlossforindividualconceptssepa-
prompt𝑝 ∪isconstructedbyconcatenatingselectedassets,i.e.“a rately,wefinditbeneficialtocomputethelossontheentirehuman
high-resolution DSLR colored image of a man/woman images.
w .i .t .h
,
[ [𝑣 𝑣1 𝑗]
]
[ [𝑐 𝑐1 𝑗] ],
,
. [. 𝑑. ], v[ i𝑣 e2 w] ”.[𝑐 2], and wearing [𝑣 3] [𝑐 3], L prior=E 𝑧pr,𝜖∼N(0,1),𝑡(cid:2) ∥[𝜖−𝜖 𝜃(𝑧 𝑡pr,𝑡,𝑝 ∪∗)]∥2 2(cid:3) (3)
Losses.Inbothoptimizationstages,themodelistrainedtoen- where𝑝 ∪∗ isthetextpromptwithoutspecialtokens.
courageconceptseparationwhilestillretainingitsgeneralization
3.2 PuzzleAvatar–PutPuzzlePiecesTogether
capability.Todoso,themodelisoptimizedwiththreelossterms:
aMaskedDiffusionLoss, L rec,Cross-AttentionLoss, L attn,and Withthefine-tuneddiffusionmodelcustomizedforallprovided
PriorPreservationLoss, L prior.Theoveralltrainingobjectiveis assets,weareabletodistilladescriptive3DavatarviaSDS.
L total=L rec+𝜆 attnL attn+L priorwhere𝜆 attn=0.01.
Score Distillation Sampling (SDS). A pretrained diffusion
TheMaskedDiffusionLossencouragesfidelityinreplicatingeach
modeloverimages𝐷(z) capturesthedatadistributionlog𝑝(z𝜓).
conceptviaapixel-wisereconstructionwithinthesegmentedmask:
SDS[Pooleetal.2023]isatechniquethatguidessomeparameteri-
L rec=E 𝑧,𝜖∼N(0,1),𝑡(cid:2) ∥[𝜖−𝜖 𝜃(𝑧 𝑡,𝑡,𝑝 ∪)]⊙M∪∥2 2(cid:3), (1) zationofimagesz(𝜓)(rawpixels,neuralnetworks,etc.)togeneratePuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 5
Table1. DatasetsrelatedtoPuzzleIOI.“–”meansimagecapturesare
Prompt (GPT-4V): “a high-resolution DSLR colored image / detailed sculpture of (the headshot of) a woman, with
oval face, eyes with visible epicanthic folds, and medium length, straight, dark brown haircut, wearing loose-fitting, unavailable.“Scan”isA-posed,and“SMPL-X”isitsrespectiveSMPL-Xfits.
teal-colored with long sleeves shirt, wide-legged, dark gray or black pants and black, ankle-high boots”
Dataset Reference #Views#ID#Outfits#ActionsSMPL-XScanTextTexture
ActorsHQ [Işıketal.2023] 160 8 8 52 ✓ ✓ ✗ ✓
MVHumanNet [Xiongetal.2024] 48 4500 9000 500 ✓ ✗ ✓ ✓
HuMMan [Caietal.2022] 10 1000 1000 500 ✗ ✗ ✗ ✓
DNA-Rendering[Chengetal.2023] 60 500 1500 1187 ✗ ✗ ✗ ✓
THuman2.0 [Yuetal.2021] – 200 500 – ✗ ✗ ✗ ✓
CAPE [MaetParol.m2p0t 2(G0]PT-4V): “–a high-1re5solution8 DSLR col6o0r0ed image / ✓detailed ✓sculptu✗re of the✗ headshot of a woman, with
BUFF [Zhanogveatl faalc.e2, 0e1ye7s] with –visible e5picanthi2c folds, and 3medium leng✓th, straig✓ht, dar✗k brown✓ haircut, wearing loose-fitting,
teal-colored with long sleeves shirt, wide-legged, dark gray or black pants and black, ankle-high boots”
PuzzleIOI(Ours) 22 41 933 40 ✓ ✓ ✓ ✓
Fig.4. Color-NormalSyntheticPrior.Thecorrespondingdescriptionsare
generatedviaGPT-4V[OpenAI2023],wherethepromptofRGBimagestarts
with“a high-resolution DSLR colored image”,whilethatof
thenormalimagestartswith“a detailed sculpture of”Thezoom- theysample3Davatarsfromarelativelysmallcollectionofprompts
inheadimagesaregeneratedbyappending“the headshot of” andevaluatethequalityoftheseavatarsthroughperceptualstudies
withalimitednumberofparticipants.
WhilePuzzleAvataradopts“Text-to-3D”techniques,itsgoalisto
imagestowardshigherlikelihood.Thecoreideaistoapproximate reconstructavatarsfromphotosofaspecificpersoninaspecificout-
theparametergradient∇𝜓Lasaweightedreconstructionresidual. fit,ratherthantorandomlygenerateavatars.Asaresult,anatural
Asthevanillamethodsuffersfromcoloroversaturation,weusean andreliablewaytobenchmarkPuzzleAvataristoexploita4Dscan-
improvedSDS–Noise-FreeDistillationSampling(NFDS)[Katzir ners(syncedwithIOIcolorcameras1)forcapturingground-truth
etal.2024].Thismodifiestheguidancefromasinglereconstruction 3Dshapeandappearance,andtomeasurethereconstructionerror
residualintotwocomposedresidualterms𝛿 𝐶 and𝛿 𝐷.Specifically, betweenthereconstructedandground-truthshapeandappearance.
bydenotingthederivedgradientofanetwork𝜓 fromNFSDas Wethusbuildadataset,calledPuzzleIOI(Section4.1),onwhichwe
∇L NFDS[x,𝜓]: evaluatePuzzleAvatarandablateitscomponents.
𝜕z
∇𝜓L NFDS[z,𝜓] =𝑤(𝑡)(𝛿 𝐷 +𝑠𝛿 𝐶) 𝜕𝜓, where (4) 4.1 PuzzleIOIDataset
WecreatePuzzleIOI(seestatisticsinTable1)tosimulatereal-world
𝛿 C(𝑧 𝑡,𝑝,𝑡)=𝜖 𝜃(𝑧 𝑡;𝑝,𝑡)−𝜖 𝜃(𝑧 𝑡;∅,𝑡), albumphotosofhumans,which:(1)coverawiderangeofhuman
(cid:40) identities(#IDcolumninTable1)anddailyoutfits(#Outfits),(2)
𝛿 D(𝑧 𝑡,𝑡)= 𝜖 𝜖𝜃 𝜃( (𝑧 𝑧𝑡 𝑡; ;∅ ∅, ,𝑡 𝑡) ),
−𝜖 𝜃(𝑧 𝑡;𝑝neg,𝑡),
i of t𝑡 he≤ rw20 is0
e,
(5) s op ca cln usn iu om n,e or uo tu -s ofv -i fe rw ams e(# cV roie pw pis n) gt )o ,am ni dm (i 3c )r inea cl l- uw deor tl ed xc ta dp et su cr re ips t( ie o. ng s.,
Inourcase,zisthe(latentof)diffusionoutput(humanimagesor (Text),andground-truthtexturedA-posedscans(Scan,Texture)
normals)and𝜓 denotesthe3Davatarrepresentation(both𝜓 𝑔,𝜓 𝑐), andtheirSMPL-Xfits(SMPL-X)forshapeinitializationpurposes.
𝑠istheguidancescale,wefollowNFDSandset𝑠 =7.5. A-Pose SMPL-X & Scan. Almost all “Text-to-Avatar” meth-
RepresentationandInitialziation.The3Dhumanavataris ods [Cao et al. 2024; Huang et al. 2024a; Kolotouros et al. 2023;
parameterizedwithDMTet[Gaoetal.2020;Shenetal.2021],a Liaoetal.2024;Yuanetal.2023]useanA-posebodyforshape
flexibletetrahedron-based3Dneuralrepresentation.Thegeometry, initializationduetoitsminimalself-occlusions.Thus,weadhereto
𝜓 g,andappearance,𝜓 c,areoptimizable,andcanbedifferentially thisempiricalsettinginPuzzleIOI.Foreachsubject(ID+Outfit),we
renderedintonormal,n,andcoloredimages,c.Thegeometry𝜓 𝑔is captureaground-truthA-posed3DscanandfitaSMPL-Xmodel
firstinitializedtoanA-posedSMPL-Xbody[Pavlakosetal.2019]. toit,asinAGORA[Pateletal.2021].
Optimization.Weusethefull-textdescriptionofthehuman MultipleViews.Tosimulatethediversityandimperfectionsof
𝑝allasaguidingprompt.Itisaconcatenationoftextpromptsfrom real-worldphotos,foreachsubject(ID+outfit)werandomlysample
allassetsi.e.,(𝑣 𝑖,𝑐 𝑖),...,(𝑣 𝐾,𝑐 𝐾).Weoptimizegeometryandcolor 120photosfromthemulti-viewhumanactionsequence(approx.760
separatelyintwooptimizationstages,bothusingNoise-Free-Score frames/subject)capturedby22cameras;seeFig.2.Thecaptured
Distillation(NFSD).Inthefirststage,theavatar’sgeometryisguided imagesaresegmentedandshuffledtobuildthetrainingdatasetfor
inthesurfacenormalspace,∇Lnorm ≡ ∇L NFDS[n,𝜓 𝑔].Weaddi- PuzzleBooth(Section3.1).
tionallyprepend“a detailed sculpture of”tothefull-textto Text Description. Similar to how image captioning is done
indicatetheguidancespace.Inthesecondstage,itsappearance inSection3.1,herewerandomlyselecttwofrontalfull-bodyim-
is guided by ∇Lcolor ≡ ∇L NFDS[c,𝜓 𝑐]. The camera settings for agesanduseGPT-4Vtoquerytheassetnamesandcorresponding
multi-viewSDSareinAppendixB. descriptionsofvisibleassets.Weusethepositionoftheground
truthcameratocategorizethephotosinto4viewgroups{front,
4 EXPERIMENTS back, side, overhead}inPuzzleIOI,whileweuseGPT-4Vto
automaticallylabelviewpointsfromin-the-wildimages.
Ithasbeenalong-standingchallengeinthefieldof“Text-to-3D”
(including“Text-to-Avatar”)toquantitativelybenchmarknewal-
gorithms.Existingbenchmarksaretypicallylessreliablebecause 1https://www.ioindustries.com/cameras6 • Xiu,etal.
4.2 2Dand3DMetrics
non-humanartifactsarisewhensegmentationornormalmapesti-
We conduct quantitative evaluation on the PuzzleIOI dataset
mationfails.(3)Improvedgeometry-texturedisentanglement,where
(Sec. 4.1). To evaluate the quality of shape reconstruction we PuzzleAvatarexcelsinseparatingshirtstripescomparedtoTeCH
reportthreemetrics:(1)Chamferdistance(bidirectionalpoint-to- Thismainlyattributestothefailednormalmapestimatedfromthe
surface,cmasunit),(2)P2Sdistance(1-directionalpoint-to-surface, inputimage(seeFig.73throw,rightmostnormalestimate).,which
cmasunit)distance,and(3)L2errorforNormalmapsrendered reliesonoftenincorrectlyestimatednormalmapsfromtheinput
forfourviews({0◦,90◦,180◦,270◦})tocapturelocalsurfacedetails. image. Notably, MVDreamBooth highlights PuzzleAvatar’s profi-
Toevaluatethequalityofappearancereconstruction,weren- ciencyinproducingintricategeometricdetailsandtextures.We
dermulti-viewcolorimagesasabove,andreportthreeimage-quality alsocomparewithAvatarBooth[Zengetal.2023],whichaddresses
metrics:PSNR(PeakSignal-to-NoiseRatio),SSIM(StructuralSimi- thesimilarproblem.Sinceitscodeandtrainedmodelshavenotbeen
larity)andLPIPS(LearnedPerceptualImagePathSimilarity). releasedyet,wetestPuzzleAvataronthesamephotocollections
usedbyAvatarBooth,andshowtheresultsinFig.10andvideo.
4.3 Benchmark
4.4 Ablations
PuzzleAvatarisageneralframework,compatiblewithdifferentdif-
Ablation:CommonPractices.InTable3-B,weanalyzetheeffect
fusionmodels.InTable2webenchmarkvariantsofPuzzleAvatar
of common practices that have been shown to be beneficial for
with twodifferent backbones:(1) vanilla StableDiffusion [Rom-
bachetal.2022],i.e.,SD-2.12,and(2)MVDream[Shietal.2024]3 generalscenes,includingview-specificprompt[Ruizetal.2023],
NFSDovervanillaSDS[Katziretal.2024],andpriorpreservation
fine-tuned from vanilla SD using multi-view images rendered
loss[Huangetal.2024a;Ruizetal.2023].Theperformancegain
from Objaverse [Deitke et al. 2023]. The shared basic pipeline
confirmsthatourproblemalsobenefitsfromthesepractices.Some
for our PuzzleAvatar, the state-of-the-art image-to-3D methods
qualitativecomparisonsareshowninFigs.8and9.Ourablation
TeCH[Huangetal.2024b]andMVDreamBooth[Shietal.2024]is:
resultsshowtheeffectivenessofPuzzleIOImetricsinmeasuring
1)firsttofinetunethesebackboneswithsubjectimagesand2)later
theperformanceofdifferentmethodsinoursetting,andalsohelp
toextractavatarswithtext-guidedSDSoptimization.
usanswerthefollowingquestions.
QuantitativeEvaluation.Table2showsthatPuzzleAvatarison
parwithTeCHon3Dmetrics,whileoutperformingitonall2D
Doestheviewprompt[𝑑]helpsthereconstruction?Yes.This
metrics.Notethat,toenhanceshapequality,TeCHemploysmultiple isacommonpracticeofnumerousexistingworks[Chenetal.2023;
supervisionsignalsandregluarizationterms,includingnormalmaps Huang et al. 2024b; Liao et al. 2024; Poole et al. 2023], and has
predictedfromtheinputimageviaECON[Xiuetal.2023],silhouette notyetbeenquantitativelyjustified.AsdetailedinTable3(B.w/o
masksproducedbySegFormer[Xieetal.2021]andaLaplacian viewprompt),thenormalerrorincreasedby+9.3%.Apartfromview
regularizer.Intermsoftexturequality,TeCHusesanRGB-based promptscaptionedbyLLM,thereisstillroomtogrowwithimproved
chamferlosstominimizecolorshiftbetweentheinputimageand representativesforcameras,suchascameraposeembeddingused
the backside texture, while its front-side texture is achieved by inLGM[Tangetal.2024]andCameras-as-Rays[Zhangetal.2024].
back-projectingtheinputimage.Incontrast,PuzzleAvatarachieves DoesNSFDoutperformsvanillaSDS?Yes.Forfaircomparison,
on-par3Daccuracyandbettertexturequalitywithoutanyofthese wesettheguidancescale𝑠 = 7.5forbothNSFDandvanillaSDS.
auxiliarylosses,regularizers,orpixelback-projection. AsdetailedinTable3(B.w/oNFSD),comparedwithNFSD(Noise-
As for the MVDream-based comparison, PuzzleAvatar outper- FreeScoreDistillation[Katziretal.2024]),vanillaSDSdegrades
formsMVDreamBoothontexturequalitybyalargemargin(PSNR thegeometryqualityabitby+2.2%,whileconsiderablydegrading
+10.09%,LPIPS-8.79%),andongeometryquality(measuredbyCham- thetexturequality(PSNR+17.3%,LPIPS+16.4%),astheSDSoften
ferandP2S),whileshowingcomparativeperformancewiththebase- crashes,leadingtofull-gray/yellowtextures.
linesonnormalconsistency.ThekeydifferenceofPuzzleAvatar,
comparedtoMVDreamBoothandTeCH,isitspuzzle-wisetraining Doesthesynthetichumanpriorhelps?Yes,anditsignificantly
strategy.Withoutthis,2Ddiffusionmodelsfine-tunedonhuman improvesthereconstructionquality,inboththegeometry(chamfer
photoswithcomplexposesandcroppingmightproducecompletely error-38.1%,P2Serror-58.8%,Normalerror-73.3%),andtexture
flawed3Dhumans,withlow-quality(evenfullblack)texturesor (PSNR+11.2%,LPIPS-27.9%).Andsyntheticnormalsappeartocon-
overlysmoothshapes;seeFig.7. tributemorethansyntheticRGB(chamfererror-31.5%vs.-5.7%,
LPIPS-21.3%vs.-3.3%).Introducingphotorealisticsyntheticdata
QualitativeEvaluation.AsdepictedinFig.7,PuzzleAvatarhas
duringfine-tuningprovesbeneficial,andtheperformanceboost
variousadvantagesoverTeCH:(1)Enhancedfront-backconsistency,
fromcolor-normalpairssurpassesthatfromonlyusingsinglemode
becausePuzzleAvatartreatallviewswithID-consistentgeneration,
(color/normal)ofdata,suchaschamfer(+38.1%>+31.5%++5.7%)
whileTeCHintroducesinconsistencybetweenthefrontviewcre-
andLPIPS(+27.9%>+21.3%++3.3%),seeFig.5,weattributesuch
atedbyreconstructionandthebackviewcreatedbyimagination.
“1+1>2effect”totheenhancedgeometry-texturealignment,which
(2)Reducednon-humanartifacts,PuzzleAvatarbypassthedepen-
benefitsfromsuchpairwisetraining.PleasecheckoutFig.8for
denceonnumerousoff-the-shelfestimatorsusedinTeCH,forwhich
morequalitativeablationresults.
2huggingface.co/stabilityai/stable-diffusion-2-1-base Can token[𝑣 𝑖] encodethe identity andfeatures of assets?
3huggingface.co/ashawkey/mvdream-sd2.1-diffusers Yes.AsshowninTable3(A.w/detailedGPT-4Vdescription),bothPuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 7
Table2. EvaluationonfullPuzzleIOI(933OOTD).†meansusingSMPL-Xfitsofground-truthscanstoinitializeDMTetandfactoroutposeerror(unlike
thevanillaTeCH[Huangetal.2024b]thatestimatesSMPL-XusingPIXIE[Fengetal.2021]).Thebestresultsaremarkedwith“bold”.“Ratio%”istherelative
performancedrop,while“ratio%”istherelativeperformancegain,w.r.t.thecompetitors,i.e.TeCHandMVDreamBooth[Shietal.2024].
Method Backbone 3DMetrics(Shape) 2DMetrics(Color)
Chamfer↓ P2S↓ Normal↓ PSNR↑ SSIM↑ LPIPS↓
TeCH† SD-2.1-base 1.646 1.590 0.076 23.635 0.919 0.065
PuzzleAvatar SD-2.1-base 1.617-1.76% 1.613+1.45% 0.077+1.32% 24.687+4.45% 0.930+1.20% 0.062-4.62%
MVDreamBooth† MVDream 1.705 1.835 0.100 19.401 0.909 0.091
PuzzleAvatar MVDream 1.697-0.47% 1.811-1.31% 0.101+1.00% 21.361+10.09% 0.906-0.33% 0.083-8.79%
Table3. AblationstudyonsubsetofPuzzleIOI(120OOTD).Thebestresultsaremarkedwith“bold”,thesecondbestresultsaremarkedwithand
underline.The“ratio%”istherelativeperformancedrop,and“ratio%”istherelativeperformancegain,w.r.t. PuzzleAvatar,wherethedroplargerthan20%
aremarkedwith“bold”.Group-Asummarizesthefailedattempts,Group-Bjustifiesthekeycomponents,andGrounp-Canalysesthescalabilityofourmethod.
Group Method 3DMetrics(Shape) 2DMetrics(Color)
Chamfer↓ P2S↓ Normal↓ PSNR↑ SSIM↑ LPIPS↓
TeCH† 1.600 1.541 0.073 23.665 0.919 0.065
PuzzleAvatar 1.589 1.570 0.075 24.718 0.931 0.061
A. w/detailedGPT-4Vdescription 1.604+0.9% 1.607+2.4% 0.079+5.3% 24.208-2.1% 0.929-0.2% 0.062+1.6%
w/oviewprompt 1.641+3.3% 1.653+5.3% 0.082+9.3% 23.929-3.2% 0.928-0.3% 0.064+4.9%
w/oNFSD(vanillaSDS) 1.624+2.2% 1.604+2.2% 0.072-4.0% 20.441-17.3% 0.923-0.9% 0.071+16.4%
B. w/osyntheticnormal+color 2.194+38.1% 2.493+58.8% 0.130+73.3% 21.940-11.2% 0.912-2.0% 0.078+27.9%
w/osyntheticnormal 2.089+31.5% 2.335+48.7% 0.123+64.0% 23.684-4.2% 0.919-1.3% 0.074+21.3%
w/osyntheticcolor 1.680+5.7% 1.687+7.5% 0.084+12.0% 23.813-3.7% 0.927-0.4% 0.063+3.3%
C. multi-subjecttraining(5subjects/model) 1.809+13.8% 1.560-0.6% 0.080+6.7% 24.990+1.1% 0.929-0.2% 0.062+1.6%
w/ofull-bodyimages 1.603+0.9% 1.580+0.6% 0.073-2.7% 23.703-4.1% 0.9310.0% 0.062+1.6%
50%trainingdata 1.590+0.1% 1.569-0.1% 0.074-1.3% 24.095-2.5% 0.930-0.1% 0.0610.0%
10%trainingdata 1.583-0.4% 1.531-2.5% 0.069-8.0% 23.477-5.0% 0.928-0.3% 0.062+1.6%
(i.e.,completeimages),slightlydecreasesthequalityofbothge-
Fig.5. “1+1>2Effect”ofSyntheticPriors.Allthenumbersrefertothe
ometryandtexture(Chamfer+0.9%andPSNR-4.1%;Table3,C.
performancegain(%),whereFullmeanstrainingwithcolor-normalpairs,
w/ofull-bodyimages)..Nevertheless,itisunsurprisingtofindthat
andRGBandNormalmeanstrainingwithsinglemodality.
PuzzleAvatarwithouttrainingonfull-bodyimagesstilloutperforms
Chamfer P2S Normal thebestTeCHsetting(bettertexturepluson-pargeometryquality).
Full RGB Normal Full RGB Normal Full RGB Normal
40 60 80
30 60 HowmuchdatadoesPuzzleAvatarneed?Withjustafraction
40
20 40 ofthetrainingdata(10%),PuzzleAvatarcanalreadyachievesat-
20
10 20 isfactoryreconstructionperformance.Asthenumberoftraining
0 0 0 imagesincreasing,theviewsynthesisperformanceinitiallykeeps
chamfer chamfer (full) P2S P2S (full) Normal Normal (full)
PSNR SSIM LPIPS improvinginbothtextureandgeometryquality(showninTable3,
Full RGB Normal Full RGB Normal Full RGB Normal
12 2.5 30 C.50%/10%trainingdata)butinterestinglystartstodeterioratein
10 2 geometryquality.WehypothesizethattrainingPuzzleBoothusing
8 20
1.5 moreRGBimagescouldimpairthequaliyofSDSgradientsinthe
6
4 1 10 spaceofnormalmaps,thusdegradingthegeometryoptimizedvia
2 0.5 SDS.Wefindsomeempiricalevidencesupportingthishypothesis
0 PSNR PSNR (full) 0 SSIM SSIM (full) 0 LPIPS LPIPS (full) Table3(B.withoutsyntheticnormal),wheretheabsenceofnormal
priorsleadstoanotabledeclineingeometryqualitycomparedto
shape and color quality slightly decrease when too-detailed de- texture(P2S+48.7%vs.SSIM-1.3%).
scriptionsareusedintheprompt,suchas“wearing sleeveless
<asset1> t-shirts, and fitted <asset2> jeans”,instead
DoesPuzzleAvatarsupportmulti-subjecttraining?Yes.Infact,
of “wearing <asset1> t-shirts, and <asset2> jeans”.
andperhapssurprisingly,multi-subjecttrainingevenslightlyim-
Surprisingly,moredetailedpromptscanintroducebias,conflicting
provesreconstructionquality(Table3-C).Thisdemonstratesthe
withtheoriginalidentityandharmingperformance;seeFig.9.
powerofStableDiffusiontoprocessandintegratenumeroushuman
DoesPuzzleAvatarworkwithoutusinganyfull-bodyshots? identitiessimultaneously,andtherobustnessofourpuzzle-based
Yesbutwithsomeperformancedrop.Excludingthefull-bodyshots trainingstrategyinlearningdisentangledhumanidentities.8 • Xiu,etal.
PuzzleAvatar
Wrong Garment Type → Long or Short Coat? Garment Hallucination → Black or White Pants?
TeCH
Conflict → predicted normal vs. SDS Thin structures→ Hat or ahoge? Guidance Collapse → White or Red Pants?
(a) TeCH may create non-human noisy artifacts (b) PuzzleAvatar creates realistic 3D humans, but struggles from …
Fig.6. FailureCases.Non-humanartifactsmainlycauseerrorsinTeCH(seea),whereaserrorsinPuzzleAvatarstemfromhallucinationandflawedDMTet
modelingofthinstructures.Fortheright-topcase,theblackpantsshowingthroughthewhitecoat,whilerealistic,deviatesfromtheoriginalinput.Asaresult
ofthishallucination,thefailuresofPuzzleAvatararedistinctfromground-truth,butnotcompletelycatastrophic(seeb).
03626-02 03588-24
5 APPLICATIONS
PotentialNegativeEffect.AsdiscussedinSec.4.4,theperfor-
ThecompositionalityofPuzzleAvatarthroughitstokensandtext manceofPuzzleAvatarreliesheavilyonexistingpublic/commercial
promptssupportsdiverseapplicationslikeVirtualTry-Onandtext- syntheticdatasetsandthereforemayinherittheirgender,racialand
guidedavatarediting,asshownin Fig.1andvideo.Moreover,the agebiases.Onemayaddresssuchanissuebycuratingbalanced
A-Po03 s6 e17 d-0 o5 utputcansimplifytheriggingandskinni0 n3 g607 p-0 r2
ocess.With
“<assetd Aa>t sahsiret”tsfromreal-wo03 r6 l2 d“<1a-0 ism2set aBg> sehsirt(”withoff-the-shelfmethodstoes-
theunderlyingSMPL-Xparametricbody,the3Doutputcouldbe timatenormals[BaeandDavison2024;Saitoetal.2020;Xiuetal.
easilyanimatedwithSMPL-Xmotiondata,likeAMASS[Mahmood 2023,2022])orbysimplybuildingbettersyntheticdatasets.
etal.2019]andAIST++[Lietal.2021],asthecommonpractice ContributionstotheCommunity.PuzzleAvatarpavestheway Unconstrained Photo Collections B
in[Huangetal.2020;Xiuetal.2022;Zhengetal.2021]. inreconstructingarticulatedhumansfrompersonal,naturalphoto
collections – introducing the new “Album2Human” task. Mean-
6 CONCLUSION while,PuzzleIOIoffersanewbenchmarkthatfacilitatesobjective
evaluationofvariousdiffusion-model-basedtechniques,including
Limitations&FutureWork.SincePuzzleAvatarbuildsonPuz-
butnotlimitedtomodelcustomization,modelpersonalizationand
zleBoothandScoreDistillationSampling(SDS),whileusingnore-
distillationsampling.Webelievethatournewtask,Album2Human,
projecUtnioconnstterarimneds ,Pshootmo Ceolhleactlilounsc Ainationisinevitable.AsTFexitgur.e6d 3sDh Houwmsa,n A Virtual Try-On (A+B) Textured 3D Human B
togetherwithournewbenchmark,PuzzleIOI,couldpushthebound-
PuzzleAvatarmayincorrectlyhallucinategarmenttextureortypes,
ary of the field of AI-Generated Content (AIGC). Furthermore,
andsufferfromdescriptioncontamination,acommonissueinT2I
PuzzleAvatar offers a simple yet scalable reconstruction system,
models.Despitebeingtrainedwithsyntheticpaireddata,ourmodel
withwhichusersmayignorethetechnicaldetailsofreconstruction
sometimesstrugglestoperfectlydisentangleshapeandcolor,lead-
parameters.Moreimportantly,webelievethatPuzzleAvatardemon-
ingtobaked-intexture.Additionally,preservingfacialidentityis stratesanewandpracticalparadigmfor“puzzle-assembledclothed
challengingwithouthigh-resolutionheadshotselfiesinthetraining humanreconstruction” thatproducesa3Davatarfromeveryday
data.Potentialsolutionsforbetteridentitypreservationmayinclude
photosinascalableandconstraint-freemanner.
enhancingsegmentedfaceswithsuper-resolutiontechniques[Wang
…long shirt… …blue jeans… …yellow hat…
etal.2022],conductingpersonalizedrestoration[Charietal.2023],
orincorporatingfaceIDembeddings[Wangetal.2024a]. Text-guided Attributes Editing
Acknowledgments.WethankPeterKulitsandYandongWenfor
PuzzleAvatar’smainissuecurrentlyisitscomputationalcomplex-
proofreading,YifeiZengforprovidingtheresultsofAvatarBooth,
ity,asspendingroughly4hourstotrainPuzzleBoothandperform
YameiChenandKexinWangforteaserphotos,JiaxiangTang,Yangyi
SDS-basedoptimizationisimpracticalforcertainapplications.In
Huang,NikosAthanasiou,YaoFengandWeiyangLiuforfruitfuldis-
thefuturewewillexplorebettertraining-freestrategies[Lietal.
cussions, Jinlong Yang and Tsvetelina Alexiadis for data capture.
2024;Teweletal.2024]andbettersamplingmethodsfordiffusion
ThisprojecthasreceivedfundingfromtheEuropeanUnion’sHori-
models[Luoetal.2023;Songetal.2023].Besides,thecomposi-
zon 2020 research and innovation programme under the Marie
tional3Dcouldbeachievedthroughnon-watertightandmulti-layer
Skłodowska-CuriegrantagreementNo.860768(CLIPEproject).Yufei
representations[Fengetal.2022;Liuetal.2024a;Sonetal.2024].
Ye’sPhDresearchispartiallysupportedbyaGoogleGift.
Multi-subjecttrainingwithPuzzleAvatarseemspromising.Thus,
itmightbefeasibletoextendPuzzleAvatartodecentralizedtrain- Disclosure.MJBhasreceivedresearchgiftfundsfromAdobe,Intel,
ingsettings.Byfine-tuningasharedT2Imodelthroughfederated Nvidia,Meta/Facebook,andAmazon.MJBhasfinancialinterests
learning[LiangzeandLin2023],usersacrosstheglobecouldupload in Amazon and Meshcapade GmbH. While MJB is a co-founder
theirpersonalalbumstobuildaglobal“styleset”ofreallydiverse andChiefScientistatMeshcapade,hisresearchinthisprojectwas
clothing,accessories,andhairstyles,forcustomizingavatars. performedsolelyat,andfundedsolelyby,theMaxPlanckSociety.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 9
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
(03626-20) Reference
Training Data
TeCH (Geometry) TeCH (Texture)
(03618-17)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
TeCH (Geometry) TeCH (Texture)
(03633-15)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
TeCH (Geometry) TeCH (Texture)
Image2Normal
(ECON)
(03590-16)
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Reference
Training Data
MVDreamBooth (Geometry) MVDreamBooth (Texture)
Fig.7. QualitativeResults.WecomparePuzzleAvatar,TeCHandMVDreamBoothonrandomlysampledsubjects.PuzzleAvataroffersvariousadvantagesover
TeCH:(1)Enhancedfront-backconsistency.(2)Reducednon-humanartifacts.(3)Improvedgeometry-texturedisentanglement.Atthebottom,MVDreamBooth
highlightsPuzzleAvatar’sproficiencyinproducingintricategeometricdetailsandtextures.(cid:252)Zoomintoseemore3Dandcolordetails.03626-02 Wrong Garment Type → Long or Short Coat? 03588-24 Garment Hallucination → Black or White Pants?
10 • Xiu,etal.
03607-02 Thin Structure → Hat or Dyeing Hair? 03621-02 Description Contamination → White or Red Pants?
(b) Failure cases of TeCH (b) Failure cases of PuzzleAvatar
PuzzleAvatar (Body) PuzzleAvatar (Head)
03584-25
PuzzleAvatar w/o Synthetic Prior (Body) PuzzleAvatar w/o Synthetic Prior (Head)
PuzzleAvatar (Body) PuzzleAvatar (Head)
03626-02 Wrong Garment Type → Long or Short Coat? 03588-24 Garment Hallucination → Black or White Pants?
03626-16
PuzzleAvatar w/o Synthetic Prior (Body) PuzzleAvatar w/o Synthetic Prior (Head)
Fig.8. HowSyntheticPriorHelps?SeeFig.5formorein-de03p607t-h02analyThsini Sstr.ucture → Hat or Dyeing Hair? 03621-02 Description Contamination → White or Red Pants?
(b) Failure cases of TeCH (b) Failure cases of PuzzleAvatar
PuzzleAvatar (“<asset 01> haircut” ) PuzzleAvatar (“<asset 02> face” )
…long shirt… …blue jeans…
Unconstrained Photo Collections A Textured 3D Human A Virtual Try-On (A+B)
PuzzleAvatar w/ Detailed Description (“<asset 01> short haircut” ) PuzzleAvatar w/ Detailed Description (“<asset 02> oval face” )
Fig.9. Detailedvs.PlainPromptToken<assetX>sufficestomaintaintheappearanceofassets.Elaboratepromptscouldintroducebiasandhallucination.
PuzzleAvatar (Geometry) PuzzleAvatar (Texture)
Training Data AvatarBooth (Geometry) AvatarBooth (Texture)
(AvatarBooth)
Fig.10. AvatarBooth[Zengetal.2023]vs.Pu…zlozng lsehirAt…vata…rbluAe jevanas…tarBoothintroducesasimilartask,butoverlooksthecompositionalityofgarmentsand
utilizestwoseparateDreamBooths(Head,Body)alongwithControlNet,makingitmorecomplexandlessscalablethanPuzzleAvatar.
Unconstrained Photo Collections A Textured 3D Human A Virtual Try-On (A+B)PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 11
REFERENCES
realistic3dhumangeneration. ComputerVisionandPatternRecognition(CVPR)
ThiemoAlldieck,MarcusA.Magnor,WeipengXu,ChristianTheobalt,andGerard (2024).
Pons-Moll.2018a.DetailedHumanAvatarsfromMonocularVideo.InInternational YukunHuang,JiananWang,AilingZeng,HeCao,XianbiaoQi,YukaiShi,Zheng-Jun
Conferenceon3DVision(3DV). Zha,andLeiZhang.2023a.DreamWaltz:MakeaScenewithComplex3DAnimatable
ThiemoAlldieck,MarcusA.Magnor,WeipengXu,ChristianTheobalt,andGerard
Avatars.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
Pons-Moll.2018b.VideoBasedReconstructionof3DPeopleModels.InComputer YangyiHuang,HongweiYi,WeiyangLiu,HaofanWang,BoxiWu,WenxiaoWang,
VisionandPatternRecognition(CVPR). BinbinLin,DebingZhang,andDengCai.2023b. One-shotImplicitAnimatable
NikosAthanasiou,MathisPetrovich,MichaelJ.Black,andGülVarol.2023. SINC:
AvatarswithModel-basedPriors.InInternationalConferenceonComputerVision
SpatialCompositionof3DHumanMotionsforSimultaneousActionGeneration.
(ICCV).
InternationalConferenceonComputerVision(ICCV)(2023). YangyiHuang,HongweiYi,YuliangXiu,TingtingLiao,JiaxiangTang,DengCai,and
OmriAvrahami,KfirAberman,OhadFried,DanielCohen-Or,andDaniLischinski.2023. JustusThies.2024b.TeCH:Text-guidedReconstructionofLifelikeClothedHumans.
Break-A-Scene:ExtractingMultipleConceptsfromaSingleImage.InSIGGRAPH InInternationalConferenceon3DVision(3DV).
Asia2023ConferencePapers(SA’23). ZengHuang,YuanluXu,ChristophLassner,HaoLi,andTonyTung.2020. ARCH:
GwangbinBaeandAndrewJ.Davison.2024.RethinkingInductiveBiasesforSurface
AnimatableReconstructionofClothedHumans.InComputerVisionandPattern
NormalEstimation.InComputerVisionandPatternRecognition(CVPR). Recognition(CVPR).
WenjingBian,ZiruiWang,KejieLi,Jia-WangBian,andVictorAdrianPrisacariu.2023. MustafaIşık,MartinRünz,MarkosGeorgopoulos,TarasKhakhulin,JonathanStarck,
Nope-nerf:Optimisingneuralradiancefieldwithnoposeprior.InComputerVision LourdesAgapito,andMatthiasNießner.2023. HumanRF:High-FidelityNeural
andPatternRecognition(CVPR). RadianceFieldsforHumansinMotion.TransactionsonGraphics(TOG)(2023).
TimBrooks,BillPeebles,ConnorHolmes,WillDePue,YufeiGuo,LiJing,DavidSchnurr, AjayJain,BenMildenhall,JonathanT.Barron,PieterAbbeel,andBenPoole.2022.
JoeTaylor,TroyLuhman,EricLuhman,ClarenceNg,RickyWang,andAditya
Zero-ShotText-GuidedObjectGenerationwithDreamFields.InComputerVision
Ramesh.2024.Videogenerationmodelsasworldsimulators.(2024).
andPatternRecognition(CVPR).
ZhongangCai,DaxuanRen,AilingZeng,ZhengyuLin,TaoYu,WenjiaWang,Xiangyu OrenKatzir,OrPatashnik,DanielCohen-Or,andDaniLischinski.2024. Noise-free
Fan,YangGao,YifanYu,LiangPan,FangzhouHong,MingyuanZhang,ChenChange
ScoreDistillation.InInternationalConferenceonLearningRepresentations(ICLR).
Loy,LeiYang,andZiweiLiu.2022.HuMMan:Multi-modal4Dhumandatasetfor BingxinKe,AntonObukhov,ShengyuHuang,NandoMetzger,RodrigoCayeDaudt,
versatilesensingandmodeling.InEuropeanConferenceonComputerVision(ECCV). andKonradSchindler.2024. Repurposingdiffusion-basedimagegeneratorsfor
YukangCao,Yan-PeiCao,KaiHan,YingShan,andKwan-YeeKWong.2024.DreamA- monoculardepthestimation. ComputerVisionandPatternRecognition(CVPR)
vatar:Text-and-ShapeGuided3DHumanAvatarGenerationviaDiffusionModels. (2024).
ComputerVisionandPatternRecognition(CVPR)(2024). AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura
PradyumnaChari,SizhuoMa,DaniilOstashev,AchutaKadambi,GurunandanKrishnan, Gustafson,TeteXiao,SpencerWhitehead,AlexanderCBerg,Wan-YenLo,etal.
JianWang,andKfirAberman.2023.PersonalizedRestorationviaDual-PivotTuning.
2023.Segmentanything.InInternationalConferenceonComputerVision(ICCV).
arXivpreprintarXiv:2312.17234(2023). PeterKocsis,VincentSitzmann,andMatthiasNießner.2024.IntrinsicImageDiffusion
MingjinChen,JunhaoChen,XiaojunYe,Huan-angGao,XiaoxueChen,ZhaoxinFan,
forSingle-viewMaterialEstimation.InComputerVisionandPatternRecognition
andHaoZhao.2024.Ultraman:SingleImage3DHumanReconstructionwithUltra
(CVPR).
SpeedandDetail.arXivpreprintarXiv:2403.12028(2024). NikosKolotouros,ThiemoAlldieck,AndreiZanfir,EduardGabrielBazavan,Mihai
RuiChen,YongweiChen,NingxinJiao,andKuiJia.2023.Fantasia3D:Disentangling Fieraru,andCristianSminchisescu.2023.DreamHuman:Animatable3DAvatars
GeometryandAppearanceforHigh-qualityText-to-3DContentCreation.InInter- fromText.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
nationalConferenceonComputerVision(ICCV). NupurKumari,BingliangZhang,RichardZhang,EliShechtman,andJun-YanZhu.
WeiCheng,RuixiangChen,WanqiYin,SimingFan,KeyuChen,HonglinHe,Huiwen
2023.Multi-ConceptCustomizationofText-to-ImageDiffusion.ComputerVision
Luo,ZhongangCai,JingboWang,YangGao,ZhengmingYu,ZhengyuLin,Daxuan
andPatternRecognition(CVPR)(2023).
Ren,LeiYang,ZiweiLiu,ChenChangeLoy,ChenQian,WayneWu,DahuaLin,Bo JunnanLi,DongxuLi,CaimingXiong,andStevenHoi.2022. Blip:Bootstrapping
Dai,andKwan-YeeLin.2023.DNA-Rendering:ADiverseNeuralActorRepository language-imagepre-trainingforunifiedvision-languageunderstandingandgenera-
forHigh-FidelityHuman-centricRendering.InInternationalConferenceonComputer tion.InInternationalConferenceonMachineLearning(ICML).PMLR.
Vision(ICCV). RuilongLi,YuliangXiu,ShunsukeSaito,ZengHuang,KyleOlszewski,andHaoLi.
MattDeitke,DustinSchwenk,JordiSalvador,LucaWeihs,OscarMichel,EliVanderBilt,
2020.Monocularreal-timevolumetricperformancecapture.InEuropeanConference
LudwigSchmidt,KianaEhsani,AniruddhaKembhavi,andAliFarhadi.2023.Obja-
onComputerVision(ECCV).
verse:Auniverseofannotated3dobjects.InComputerVisionandPatternRecognition RuilongLi,ShanYang,DavidARoss,andAngjooKanazawa.2021.Aichoreographer:
(CVPR). Musicconditioned3ddancegenerationwithaist++.InInternationalConferenceon
YaoFeng,VasileiosChoutas,TimoBolkart,DimitriosTzionas,andMichaelJ.Black.2021.
ComputerVision(ICCV).
CollaborativeRegressionofExpressiveBodiesusingModeration.InInternational ZhenLi,MingdengCao,XintaoWang,ZhongangQi,Ming-MingCheng,andYingShan.
Conferenceon3DVision(3DV). 2024.PhotoMaker:CustomizingRealisticHumanPhotosviaStackedIDEmbedding.
YaoFeng,JinlongYang,MarcPollefeys,MichaelJ.Black,andTimoBolkart.2022.Cap-
InComputerVisionandPatternRecognition(CVPR).
turingandAnimationofBodyandClothingfromMonocularVideo.InSIGGRAPH JiangLiangzeandTaoLin.2023. Test-TimeRobustPersonalizationforFederated
Asia2022ConferencePapers(SA’22). Learning.InInternationalConferenceonLearningRepresentations(ICLR).
XiaoFu,WeiYin,MuHu,KaixuanWang,YuexinMa,PingTan,ShaojieShen,Dahua TingtingLiao,HongweiYi,YuliangXiu,JiaxiangTang,YangyiHuang,JustusThies,and
Lin,andXiaoxiaoLong.2024b.GeoWizard:UnleashingtheDiffusionPriorsfor3D
MichaelJ.Black.2024.TADA!TexttoAnimatableDigitalAvatars.InInternational
GeometryEstimationfromaSingleImage.arXivpreprintarXiv:2403.12013(2024). Conferenceon3DVision(3DV).
YangFu,SifeiLiu,AmeyKulkarni,JanKautz,AlexeiAEfros,andXiaolongWang.2024a. Chen-HsuanLin,Wei-ChiuMa,AntonioTorralba,andSimonLucey.2021.Barf:Bundle-
COLMAP-Free3DGaussianSplatting. ComputerVisionandPatternRecognition adjustingneuralradiancefields.InInternationalConferenceonComputerVision
(CVPR)(2024). (ICCV).
GegeGao,WeiyangLiu,AnpeiChen,AndreasGeiger,andBernhardSchölkopf.2024. LixiangLin,SongyouPeng,QijunGan,andJiankeZhu.2024.FastHuman:Reconstruct-
GraphDreamer:Compositional3DSceneSynthesisfromSceneGraphs.InComputer ingHigh-QualityClothedHumaninMinutes.InInternationalConferenceon3D
VisionandPatternRecognition(CVPR). Vision,3DV.
JunGao,WenzhengChen,TommyXiang,AlecJacobson,MorganMcGuire,andSanjaFi- RuoshiLiu,RundiWu,BasileVanHoorick,PavelTokmakov,SergeyZakharov,andCarl
dler.2020.Learningdeformabletetrahedralmeshesfor3dreconstruction.Conference Vondrick.2023. Zero-1-to-3:Zero-shotOneImageto3DObject.InInternational
onNeuralInformationProcessingSystems(NeurIPS)(2020). ConferenceonComputerVision(ICCV).
XiangjunGao,XiaoyuLi,ChaopengZhang,QiZhang,YanpeiCao,YingShan,and WeiyangLiu,ZejuQiu,YaoFeng,YuliangXiu,YuxuanXue,LonghuiYu,HaiwenFeng,
LongQuan.2023.ConTex-Human:Free-ViewRenderingofHumanfromaSingle ZhenLiu,JuyeonHeo,SongyouPeng,YandongWen,MichaelJ.Black,AdrianWeller,
ImagewithTexture-ConsistentSynthesis.arXivpreprintarXiv:2311.17123(2023). andBernhardSchölkopf.2024b. Parameter-EfficientOrthogonalFinetuningvia
MarcHabermann,WeipengXu,MichaelZollhoefer,GerardPons-Moll,andChristian
ButterflyFactorization.InternationalConferenceonLearningRepresentations(ICLR)
Theobalt.2020. DeepCap:MonocularHumanPerformanceCaptureUsingWeak (2024).
Supervision.InComputerVisionandPatternRecognition(CVPR).IEEE. ZhenLiu,YaoFeng,YuliangXiu,WeiyangLiu,LiamPaull,MichaelJ.Black,and
FangzhouHong,MingyuanZhang,LiangPan,ZhongangCai,LeiYang,andZiweiLiu. BernhardSchölkopf.2024a.GhostonTheShell:AnExpressiveRepresentationof
2022. Avatarclip:Zero-shottext-drivengenerationandanimationof3davatars. General3DShapes. InternationalConferenceonLearningRepresentations(ICLR)
TransactionsonGraphics(TOG)(2022). (2024).
XinHuang,RuizhiShao,QiZhang,HongwenZhang,YingFeng,YebinLiu,andQing SimianLuo,YiqinTan,LongboHuang,JianLi,andHangZhao.2023. LatentCon-
Wang.2024a.HumanNorm:Learningnormaldiffusionmodelforhigh-qualityand sistencyModels:SynthesizingHigh-ResolutionImageswithFew-StepInference.12 • Xiu,etal.
arXiv:2310.04378 InInternationalConferenceonComputerGraphicsandInteractiveTechniques(SIG-
QianliMa,JinlongYang,AnuragRanjan,SergiPujades,GerardPons-Moll,SiyuTang, GRAPH).
andMichaelJ.Black.2020.LearningtoDress3DPeopleinGenerativeClothing.In Daniel Vlasic, Pieter Peers, Ilya Baran, Paul Debevec, Jovan Popović, Szymon
ComputerVisionandPatternRecognition(CVPR). Rusinkiewicz,andWojciechMatusik.2009.Dynamicshapecaptureusingmulti-view
NaureenMahmood,NimaGhorbani,NikolausF.Troje,GerardPons-Moll,andMichaelJ. photometricstereo.InACMSIGGRAPHAsia2009Papers.
Black.2019.AMASS:ArchiveofMotionCaptureasSurfaceShapes.InInternational HaochenWang,XiaodanDu,JiahaoLi,RaymondAYeh,andGregShakhnarovich.
ConferenceonComputerVision(ICCV). 2023a. ScoreJacobianChaining:LiftingPretrained2DDiffusionModelsfor3D
RicardoMartin-Brualla,NohaRadwan,MehdiSMSajjadi,JonathanTBarron,Alexey Generation.InComputerVisionandPatternRecognition(CVPR).
Dosovitskiy,andDanielDuckworth.2021.Nerfinthewild:Neuralradiancefields JionghaoWang,YuanLiu,ZhiyangDou,ZhengmingYu,YongqingLiang,XinLi,Wen-
forunconstrainedphotocollections.InComputerVisionandPatternRecognition pingWang,RongXie,andLiSong.2023b.DisentangledClothedAvatarGeneration
(CVPR). fromTextDescriptions.arXivpreprintarXiv:2312.05295(2023).
AndreasMeuleman,Yu-LunLiu,ChenGao,Jia-BinHuang,ChangilKim,MinHKim, PengWang,HaoTan,SaiBi,YinghaoXu,FujunLuan,KalyanSunkavalli,Wenping
andJohannesKopf.2023.Progressivelyoptimizedlocalradiancefieldsforrobust Wang,ZexiangXu,andKaiZhang.2024c.PF-LRM:Pose-FreeLargeReconstruction
viewsynthesis.InComputerVisionandPatternRecognition(CVPR). ModelforJointPoseandShapePrediction.InInternationalConferenceonLearning
BenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRa- Representations(ICLR).
mamoorthi,andRenNg.2021.Nerf:Representingscenesasneuralradiancefields QixunWang,XuBai,HaofanWang,ZekuiQin,andAnthonyChen.2024a. In-
forviewsynthesis.Commun.ACM(2021). stantID:Zero-shotIdentity-PreservingGenerationinSeconds. arXivpreprint
OpenAI.2023.GPT-4V(ision)systemcard. arXiv:2401.07519(2024).
PriyankaPatel,Chun-HaoPaulHuang,JoachimTesch,DavidHoffmann,Shashank ShuzheWang,VincentLeroy,YohannCabon,BorisChidlovskii,andRevaudJerome.
Tripathi,andMichaelJ.Black.2021.AGORA:AvatarsinGeographyOptimizedfor 2024b. DUSt3R:Geometric3DVisionMadeEasy. ComputerVisionandPattern
RegressionAnalysis.InComputerVisionandPatternRecognition(CVPR). Recognition(CVPR)(2024).
GeorgiosPavlakos,VasileiosChoutas,NimaGhorbani,TimoBolkart,AhmedAA XintaoWang,LiangbinXie,KeYu,KelvinC.K.Chan,ChenChangeLoy,andChao
Osman,DimitriosTzionas,andMichaelJBlack.2019.Expressivebodycapture:3d Dong.2022.BasicSR:OpenSourceImageandVideoRestorationToolbox.
hands,face,andbodyfromasingleimage.InComputerVisionandPatternRecognition ZiruiWang,ShangzheWu,WeidiXie,MinChen,andVictorAdrianPrisacariu.2021.
(CVPR). NeRF–:Neuralradiancefieldswithoutknowncameraparameters.arXivpreprint
SidaPeng,ChenGeng,YuanqingZhang,YinghaoXu,QianqianWang,QingShuai, arXiv:2102.07064(2021).
XiaoweiZhou,andHujunBao.2023.ImplicitNeuralRepresentationswithStructured Chung-YiWeng,BrianCurless,PratulP.Srinivasan,JonathanT.Barron,andIra
LatentCodesforHumanBodyModeling. TransactionsonPatternAnalysisand Kemelmacher-Shlizerman.2022.HumanNeRF:Free-ViewpointRenderingofMoving
MachineIntelligence(TPAMI)(2023). PeopleFromMonocularVideo.InComputerVisionandPatternRecognition(CVPR).
BenPoole,AjayJain,JonathanTBarron,andBenMildenhall.2023. DreamFusion: RundiWu,BenMildenhall,PhilippHenzler,KeunhongPark,RuiqiGao,DanielWatson,
Text-to-3dusing2ddiffusion.InInternationalConferenceonLearningRepresentations PratulP.Srinivasan,DorVerbin,JonathanT.Barron,BenPoole,andAleksander
(ICLR). Holynski.2024.ReconFusion:3DReconstructionwithDiffusionPriors.Computer
AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,Sandhini VisionandPatternRecognition(CVPR).
Agarwal,GirishSastry,AmandaAskell,PamelaMishkin,JackClark,Gretchen YitongXia,HaoTang,RaduTimofte,andLucVanGool.2022.Sinerf:Sinusoidalneural
Krueger,andIlyaSutskever.2021. LearningTransferableVisualModelsFrom radiancefieldsforjointposeestimationandscenereconstruction.InBritishMachine
NaturalLanguageSupervision.InInternationalConferenceonMachineLearning VisionConference(BMVC).
(ICML).PMLR. EnzeXie,WenhaiWang,ZhidingYu,AnimaAnandkumar,JoseMAlvarez,andPing
TianheRen,ShilongLiu,AilingZeng,JingLin,KunchangLi,HeCao,JiayuChen, Luo.2021.SegFormer:Simpleandefficientdesignforsemanticsegmentationwith
XinyuHuang,YukangChen,FengYan,ZhaoyangZeng,HaoZhang,FengLi,Jie transformers.InConferenceonNeuralInformationProcessingSystems(NeurIPS).
Yang,HongyangLi,QingJiang,andLeiZhang.2024.GroundedSAM:Assembling ZhangyangXiong,ChenghongLi,KenkunLiu,HongjieLiao,JianqiaoHu,JunyiZhu,
Open-WorldModelsforDiverseVisualTasks. arXiv:2401.14159[cs.CV] ShuliangNing,LingtengQiu,ChongjieWang,ShijieWang,etal.2024. MVHu-
RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjörnOmmer. manNet:ALarge-scaleDatasetofMulti-viewDailyDressingHumanCaptures.In
2022.High-resolutionimagesynthesiswithlatentdiffusionmodels.InComputer ComputerVisionandPatternRecognition(CVPR).
VisionandPatternRecognition(CVPR). YuliangXiu,JinlongYang,XuCao,DimitriosTzionas,andMichaelJ.Black.2023.ECON:
NatanielRuiz,YuanzhenLi,VarunJampani,YaelPritch,MichaelRubinstein,andKfir ExplicitClothedhumansOptimizedviaNormalintegration.InComputerVisionand
Aberman.2023.DreamBooth:Finetuningtext-to-imagediffusionmodelsforsubject- PatternRecognition(CVPR).
drivengeneration.InComputerVisionandPatternRecognition(CVPR). YuliangXiu,JinlongYang,DimitriosTzionas,andMichaelJ.Black.2022.ICON:Implicit
ShunsukeSaito,ZengHuang,RyotaNatsume,ShigeoMorishima,HaoLi,andAngjoo ClothedhumansObtainedfromNormals.InComputerVisionandPatternRecognition
Kanazawa.2019.PIFu:Pixel-AlignedImplicitFunctionforHigh-ResolutionClothed (CVPR).
HumanDigitization.InInternationalConferenceonComputerVision(ICCV). XiheYang,XingyuChen,DaihengGao,ShaohuiWang,XiaoguangHan,andBaoyuan
ShunsukeSaito,TomasSimon,JasonSaragih,andHanbyulJoo.2020.PIFuHD:Multi- Wang.2024. HAVE-FUN:HumanAvatarReconstructionfromFew-ShotUncon-
LevelPixel-AlignedImplicitFunctionforHigh-Resolution3DHumanDigitization. strainedImages.InComputerVisionandPatternRecognition(CVPR).
InComputerVisionandPatternRecognition(CVPR). XuetingYang,YihaoLuo,YuliangXiu,WeiWang,HaoXu,andZhaoxinFan.2023.
KaiyueShen,ChenGuo,ManuelKaufmann,JuanZarate,JulienValentin,JieSong,and D-IF:Uncertainty-awareHumanDigitizationviaImplicitDistributionField.In
OtmarHilliges.2023.X-Avatar:ExpressiveHumanAvatars.InComputerVisionand InternationalConferenceonComputerVision(ICCV).
PatternRecognition(CVPR). TaoYu,ZerongZheng,KaiwenGuo,PengpengLiu,QionghaiDai,andYebinLiu.2021.
TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler.2021. Deep InComputerVisionandPatternRecognition(CVPR).
marchingtetrahedra:ahybridrepresentationforhigh-resolution3dshapesynthesis. YeYuan,XuetingLi,YangyiHuang,ShaliniDeMello,KokiNagano,JanKautz,and
ConferenceonNeuralInformationProcessingSystems(NeurIPS)(2021). UmarIqbal.2023.GAvatar:Animatable3DGaussianAvatarswithImplicitMesh
YichunShi,PengWang,JianglongYe,LongMai,KejieLi,andXiaoYang.2024.MV- Learning.arXivpreprintarXiv:2312.11461(2023).
Dream:Multi-viewDiffusionfor3DGeneration.InternationalConferenceonLearning YifeiZeng,YuanxunLu,XinyaJi,YaoYao,HaoZhu,andXunCao.2023.AvatarBooth:
Representations(ICLR)(2024). High-QualityandCustomizable3DHumanAvatarGeneration.arXiv:2306.09864
Sanghyun Son, Matheus Gadelha, Yang Zhou, Zexiang Xu, Ming C. Lin, and (2023).
YiZhou.2024. DMesh:ADifferentiableRepresentationforGeneralMeshes. ChaoZhang,SergiPujades,MichaelBlack,andGerardPons-Moll.2017. Detailed,
arXiv:2404.13445[cs.CV] accurate,humanshapeestimationfromclothed3Dscansequences.InComputer
YangSong,PrafullaDhariwal,MarkChen,andIlyaSutskever.2023.Consistencymodels. VisionandPatternRecognition(CVPR).
InInternationalConferenceonMachineLearning(ICML). JingboZhang,XiaoyuLi,QiZhang,YanpeiCao,YingShan,andJingLiao.2023.Hu-
JiamingSun,XiChen,QianqianWang,ZhengqiLi,HadarAverbuch-Elor,Xiaowei manRef:SingleImageto3DHumanGenerationviaReference-GuidedDiffusion.
Zhou,andNoahSnavely.2022.Neural3DReconstructionintheWild.InSIGGRAPH arXivpreprintarXiv:2311.16961(2023).
ConferenceProceedings. JasonYZhang,AmyLin,MoneishKumar,Tzu-HsuanYang,DevaRamanan,and
JiaxiangTang,ZhaoxiChen,XiaokangChen,TengfeiWang,GangZeng,andZiwei ShubhamTulsiani.2024.CamerasasRays:PoseEstimationviaRayDiffusion.In
Liu.2024.LGM:LargeMulti-ViewGaussianModelforHigh-Resolution3DContent InternationalConferenceonLearningRepresentations(ICLR).
Creation.arXivpreprintarXiv:2402.05054(2024). LvminZhangandManeeshAgrawala.2023.AddingConditionalControltoText-to-
YoadTewel,OmriKaduri,RinonGal,YoniKasten,LiorWolf,GalChechik,andYuval ImageDiffusionModels.InInternationalConferenceonComputerVision(ICCV).
Atzmon.2024. ConsiStory:Training-FreeConsistentText-to-ImageGeneration.PuzzleAvatar:Assembling3DAvatarsfromPersonalAlbums • 13
ZerongZheng,TaoYu,YebinLiu,andQionghaiDai.2021.PaMIR:ParametricModel-
conditionedImplicitRepresentationforimage-basedhumanreconstruction.Trans-
actionsonPatternAnalysisandMachineIntelligence(TPAMI)(2021).
ZerongZheng,TaoYu,YixuanWei,QionghaiDai,andYebinLiu.2019.DeepHuman:
3DHumanReconstructionFromaSingleImage.InInternationalConferenceon
ComputerVision(ICCV).14 • Xiu,etal.
A GPT-4VPROMPTFORPUZZLEBOOTH
To ensure complete coverage of the entire body and face, we
QueriedPrompt.“Analyzetheprovidedimages,eachfeaturingan samplevirtualcameraposesaroundthefullbodyandzoominon
individual.Identifyanddescribetheindividual’sgender,facialfeatures thefaceregion.Toreducetheoccurrenceofmirroredappearance
(excludinghair),haircut,andspecificclothingitemssuchasshirts, artifacts(e.g.,Janus-head),weincorporatedview-awareprompts
hats,pants,shoes,dresses,skirts,scarves,etc.Returntheresultsina (i.e.,“front/side/back/overhead view”),regardingtheview-
dictionaryformatwithkeysfor"gender","face","haircut",andeach ingangleduringthegenerationprocess.Theeffectivenessofthis
typeofclothing.Thecorrespondingvalueshouldprovide1-3adjective approachhasbeendemonstratedinDreamFusion[Pooleetal.2023].
ornounwords,whichdescribethetopologicalorgeometricfeatures, Toensurefullcoverageoftheentirebodyandthehumanface,
suchaslength(e.g.,short,long,midi,mini,knee-length,floorlength, wesamplevirtualcameraposesintotwogroups:1)K bodycameras
ankle-length,hip-length,calf-length),shape(e.g.,oval,round,square, withafieldofview(FOV)coveringthefullbodyorthemainbody
heart-shaped,diamond-shaped,rectangular,voluminous,razor-cut, parts,and2)zoom-incamerasK facefocusingthefaceregion.
tousled,layered,messy),tightness(e.g.,tight,snug,fitted,skin-tight, TheratioP bodydeterminestheprobabilityofsamplingk∈K body,
loose,tight-fitting,clingy),style(e.g.,modern,casual,sporty,classic, while the heightℎ body, radius𝑟 body, elevation angle 𝜙 body, and
formal,vintage,bohemian,avant-garde),orhaircuttypes(e.g.,long, azimuth ranges𝜃 body are adjusted relative to the SMPL-X body
short,wavy,straight,curly,bald,medium-length,ponytail,bun,plaits, scale.Empirically,wesetP body =0.5,ℎ body = [−0.4,0.4],𝑟 body =
beard, sideburns, dreadlocks, goatee), without referencing color or (0.7,1.3),𝜃 body = [60◦,120◦],𝜙 body = [0◦,360◦],withthe𝑀 body
texturepattern.Excludeaccessoriesanddon’tincludeanyclothing proportionallyscaledtoa[−0.5,0.5]unitspace.
iteminthedescriptionofanother.Omitanykeysforwhichtheclothing Toenhancefacialdetails,wesampleadditionalvirtualcameras
itemdoesnotappearorthedescriptionisempty.Theresponseshould positionedaroundthefacek∈K face,togetherwiththeadditional
beadictionaryonly,withoutanyadditionalsentences,explanations, prompt“face of”.WithaprobabilityofP face=1−P body=0.5,the
ormarkdownssyntax(likejson)” samplingparametersincludetheviewtarget𝑐 face,radiusrange𝑟 face,
rotationrange𝜃 ,andazimuthrange𝜙 .Empirically,weset
face face
B CAMERASETTING 𝑐 tothe3DpositionofSMPL-Xheadkeypoint,𝑟 = [0.3,0.4],
face face
𝜃 = [90◦,90◦]and𝜙 = [−90◦,90◦].
Tofamiliarizethediffusionmodelwiththecamerapositionssampled face face
Regardingthesyntheticdata,weuseallthesubjects(525textured
duringSDSoptimization,werenderedthesyntheticcolor-normal
scans)inTHuman2.0.Foreachsubject,werender8full-bodyviews
imagepairsintheexactsamemannerastheSDSsamplingstrategy.
and8headviews,asshowninFig.4,andquerytheirdescriptive
Thisrendereddatawillbeusedinpreservingsynthetichumanprior
promptsviaGPT-4V[OpenAI2023].Thisgivesus525×8×2=8400
(L prior),whiletrainingthe2Dgenerator𝐺 puzzle.
color-normalpairsintotal.