Thispaperhasbeenacceptedforpublicationatthe
IEEEConferenceonComputerVisionandPatternRecognition(CVPR),Seattle,2024. ©IEEE
Federated Online Adaptation for Deep Stereo
MatteoPoggi1,2 FabioTosi1
1DepartmentofComputerScienceandEngineering(DISI) 2AdvancedResearchCenteronElectronicSystem(ARCES)
UniversityofBologna,Italy
Projectpage:https://fedstereo.github.io/
13.86% D1-all 9.16% D1-all 8.36% D1-all
(a) ~80 FPS (b) ~10 FPS (c) ~80 FPS (d)
Figure1.Federatedadaptationinchallengingenvironments.Whenfacingadomainverydifferentfromthoseobservedduringtraining
–e.g., nighttime images(a)–stereomodels[55] sufferdropsinaccuracy(b). Byenablingonlineadaptation [41](c)thenetworkcan
improveitspredictions, attheexpenseofdecimatingtheframerate. Inourfederatedframework, themodelcandemandtheadaptation
processtothecloud,toenjoyitsbenefitswhilemaintainingtheoriginalprocessingspeed(d).
Abstract databecomingavailable,hasrapidlyestablishedend-to-end
deepnetworks[42]asthestandardframeworkstodealwith
Weintroduceanovelapproachforadaptingdeepstereo theproblem[38,44,45].
networksinacollaborativemanner. Bybuildingoverprin- Inordertoprovidesufficientdatafortrainingdeepstereo
ciplesoffederatedlearning,wedevelopadistributedframe- networksattheirbest,theuseofsyntheticdatasets[35]has
workallowingfordemandingtheoptimizationprocesstoa become a standard practice in the field. This, to some ex-
numberof clientsdeployedin different environments. This tent, also revealed one of the main limitations these mod-
makes it possible, for a deep stereo network running on els suffered from at first, which was the scarce capability
resourced-constrained devices, to capitalize on the adap- to generalize to image domains very different from those
tation process carried out by other instances of the same observed at training time – a matter of concern common
architecture, and thus improve its accuracy in challenging to other tasks involving deep networks, such as semantic
environments even when it cannot carry out adaptation on segmentation[20]. Firstattemptstosolvethisshortcoming
its own. Experimental results show how federated adap- involved unsupervised adaptation techniques, either to be
tation performs equivalently to on-device adaptation, and carriedoutoffline[53,56]ordirectlyduringdeploymentin
evenbetterwhendealingwithchallengingenvironments. real-time[41,54,55],withsomecomputationaloverhead.
More recently, the community focused on dealing with
theproblematitssource–i.e., duringthetrainingprocess
1.Introduction itself,bydesigningspecificstrategiestodrivethedeepnet-
worklearningdomain-invariantfeatures[5,11,31,69,70]
Depth sensing plays a key role in several applications in while,eventually,themostmodernstereonetworks[24,30,
the fields of computer vision, robotics, and more. The use 63,65]cangeneralizemuchbetterthantheirpredecessors.
of stereo images [34] for this purpose has been one of the Despite these advancements, in the presence of very chal-
moststudiedtopicsfordecades,consistingofmatchingpix- lenging conditions never observed during training, such as
elsacrosstworectified images. Thisallowsforestimating lowillumination,sensornoiseoccurringatnight,orthere-
horizontaldisparitybetweencorrespondingpixelsand,con- flectionsappearingonrainyroads,wearguegeneralization
sequently, their depth through triangulation. This process capability alone might be insufficient. In such cases, on-
has been carried out through image processing algorithms line adaptation could still play a role, although at the cost
[43]untilnearlyonedecadeago,whendeeplearningstarted ofdroppingtheframerateatwhichthedeepnetworkoper-
replacinghand-craftedsolutionswithneuralnetworks[59]. ates. Thispricetopaymightbereducedbymeansofspe-
Theincreasinggrowthofcomputationalpowerinthehand cific adaptation strategies [41, 55] and allow for maintain-
of developers, together with the more and more annotated ingreal-timeprocessingwhenhigh-endGPUsareavailable,
1
4202
yaM
32
]VC.sc[
1v37841.5042:viXrayetmightstillbeprohibitivewhenthisisnotthecase–e.g., gorithmbuiltuponournewbaselinetoreducetheamount
whenrunningonaUAVoralow-poweredvehiclenotable ofdataexchangedbetweennodeswithnegligibleimpact
tosupportpower-hungryhardware. onadaptationeffectiveness.
Inanutshell,marryinggoodpracticestoachievegener- • Weevaluateourframeworkpairedwithmultiplereal-time
alization with online adaptation is essential for facing the stereo networks on a variety of datasets, supporting that
real world, but still not sufficient when computational re- federatedadaptationperformscomparablytosingle-node
sources cannot support additional overhead at deployment adaptation,andevenbetterinchallengingdomains.
time. In this context, the adaptation process has always
been approached as a single-instance task, in which a sin- 2.RelatedWork
gle stereo network is deployed in an unseen environment
Webrieflyreviewtheliteraturerelevanttoourwork.
andisgraduallyoptimizedoverit. Thissettingignoresthe
Deep Stereo Matching. The stereo matching litera-
existence of other instances of the model operating in dif-
ture counts several hand-crafted algorithms [43] through
ferent environments, potentially adapting independently to
theyears,usuallydividedintolocalandglobalmethodsac-
the specific domain they face. In a world where cameras
cordingtotheirstructureandtheirspeed/accuracytrade-off.
and sensors are increasingly widespread, and fleets of au-
In the last decade, deep learning has brought a paradigm
tonomousvehiclesareonthehorizon,weargueadaptation
shift into stereo matching, achieving more and more accu-
itself can be formulated as a distributed task. In this sce-
rate results on standard benchmarks [42]. While the first
nario, an agent lacking sufficient computational capacity
steps in this field aimed at replacing individual modules
can demand the adaptation process to a network of peers
of the conventional pipeline [43] with compact networks
equippedwithmorepowerfulhardwareandthuscapableof
[32, 46, 47, 59], with DispNet [35] the end-to-end archi-
sustainingtheadaptationprocess.
tecturesrapidlyconqueredthemainstage[6,9,22,29,48,
In this paper, we introduce a novel framework imple-
55,57,66,68]. Mostofthemodelscanbebroadlyclassi-
menting federated online adaptation for deep stereo net-
fiedinto2D[29,35,55,64]and3D[6,9,22,48,57,66,68]
works,bybuildingonprinciplesoffederatedlearning[36].
architectures,withsomeexploitingtransformers[19,28].
Since communication between nodes is strictly necessary
In the last years, several works focused on improving
to carry out adaptation in a distributed manner, a connec-
the capability of stereo networks to generalize across dif-
tion overhead is introduced to transfer data, proportional
ferent domains, for instance by reducing the gap between
to the quantity of data itself. To minimize this overhead,
trainingonsyntheticandtestingonrealimages. Themain
we design an algorithm specifically tailored to reduce the
approachesinvolvedtheuseofhand-craftedmatchingfunc-
dataquantityexchangedbetweenagentsatthemost,while
tions or algorithms [2, 5], techniques to learn for more ro-
maintainingtheeffectivenessoftheoveralladaptationpro-
bustfeatures[11,28,31,69],orthegenerationofphotore-
cess nearly unaltered. This is done by revising the MAD
alisticdatafortraining[58,62].Eventually,themostrecent
algorithm[55]tothefederatedsettingandthusdeveloping
stereo architectures [24, 30, 63, 65] proved to be capable
FedMAD. Our federated framework is extensively evalu-
ofstronggeneralizationfromsynthetictorealimageseven
atedonseveralstereodatasets,suchasKITTI[16],Driving-
withoutmakinguseofanyoftheaforementionedstrategies.
Stereo[67],andDSEC[14],provingthatfederatedadapta-
Self-supervised Stereo. To overcome the need for an-
tion can provide an equivalent or, in the most challenging
notated data, self-supervised techniques have been devel-
scenarios,evengreateraccuracyimprovementcomparedto
oped to directly train stereo networks on unlabelled image
single-device adaptation, as spotlighted in Fig. 1. To the
pairs. The minimization of the photometric error [18] be-
bestofourknowledge,ourworkrepresentsthefirstattempt
tweentheleftandrightimages,withthelatterbeingwarped
to deal with real-time adaptation through a federated ap-
according to estimated disparity, is at the core of most ap-
proach,inparticularinthefieldofself-adaptingstereonet-
proaches trained on unconstrained stereo pairs [74, 75] or
works[41,54,55]. Ourmainclaimscanberesumedas:
videos[10,23,61]. Analternativestrategyconsistsofob-
• Werevisereal-timeadaptationframeworks[41,55]toin- taining pseudo-labels from either hand-crafted algorithms
troducerecentadvancesindeepstereoconcerninggener- [53,56]orotherdepthestimationnetworks[1,49].
alization and architectural design, realizing a new base- Real-time Adaptation for Stereo. Although synthetic
linethatlargelyimprovesoverpriorworks. datasets provide countless annotated data, the poor gen-
• We introduce a novel framework casting online adapta- eralization capabilities of the stereo models developed at
tion as a federated process, allowing to free the single first led to the development of adaptation techniques to
device from the computational overhead that is instead overcome the synthetic to real domain shift directly dur-
distributedamonganumberofpeerdevices. ingdeployment. Asthisdemandsthemodeltoadaptinthe
• Since distributed adaptation introduces data traffic be- absence of ground truth, photometric losses [54, 55] and
tween nodes over the web, we propose FedMAD, an al- pseudolabels[41,60]havebeenemployed.
2t =0 … T … 2T … 3T … 4T t =0 … T … 2T … 3T … 4T t =0
Model Adaptation Frozen Weights Weights Update
Figure2.Overviewofourfederatedadaptationframework.Ontheonehand,activenodesrunonlineadaptation(blueandyellow)and
periodicallysendtheirupdatedweightstoacentralserver. Ontheother,alisteningclient(green)canbenefitfromtheadaptationprocess
carriedoutbytheactivenodes,byreceivingaggregatedweightsupdatesfromtheserver.
Federated Learning. This learning paradigm aims at bone (MADNet), made of 5 encoder-decoder blocks pre-
training models from distributed data sources. A large dicting disparity maps at different scales. For any adapta-
body of literature has emerged in the last five years [26], tion step t, a block i is sampled according to a probability
mostly focusing on classification tasks. The pivotal feder- distribution, then only the corresponding output is used to
atedlearningalgorithmisFedAvg[36]: asetofclientsfirst computethelossandoptimizethesubsetofweightsw [i]:
t
train their local model using private data and then upload
the weights to a server, where they are averaged to form a i=sample(softmax(H))
(2)
globalmodel. Severalmethods[21,25,27,37,50,51,71] w [i] w [i] η▽ℓ (w ,b )[i]
t+1 t i t t
tried to regularize the local training phase in FedAvg [36], ← −
withFedProx[27]andSCAFFOLD[21]restrictingthelo- This significantly reduces the computational overhead re-
cal update to be consistent globally, and MOON [25] ap- quired for adaptation. Consequently, MADNet coupled
plying a contrastive objective to regularize the optimiza- withMADoperatesatdoublethespeedcomparedtoFULL,
tion of local models to not deviate significantly from the despiteresultinginamoderatedropinaccuracy.
global model. In contrast, personalized federated learning Bothstrategiescanbedeployedusingphotometriclosses
[7,12,13,33,50]aimsattrainingcustommodelsforeach [55](FULL/MAD)orbyleveragingproxylabels[41]when
client to better fit local data. Finally, [8] shows the im- available(FULL++/MAD++).
portanceofexploitingpre-trainingwhenpossible,aswedo
sinceweaimatdeployingadistributedadaptationprocess. 3.2.FederatedAdaptationFramework
The FULL and MAD algorithms are defined on a single-
3.FederatedAdaptationforDeepStereo
instance perspective – i.e., a single stereo backbone is
deployed and adapted during navigation. However, this
Inthissection,weintroducethebasicprinciplesoverwhich
paradigm alone might not be sufficient to overcome chal-
ourfederatedadaptationframeworkisdeveloped.
lenging domain changes or might be unusable if not sup-
3.1.Background: OnlineAdaptationforStereo portedbypowerfulenoughhardware(e.g.,whenthestereo
modelsrunonembeddeddevices,barelygrantingreal-time
Despite the recent advances in domain generalization [24,
processingevenintheabsenceofanyadaptationprocess).
30,63,65],apre-trainedstereobackbonemightfacedrops
Purposely, we design a federated framework in which
in accuracy when deployed in challenging environments.
we define a set of active nodes A, capable of adapting in-
Assuch,adaptingthemodelonline[41,55]canbeasolu-
dependently, and other listening clients C which demand
tion for dealing with these occurrences. For any incoming
theadaptationprocesstotheformer, assketchedinFigure
stereopairb ,thenetworkpredictsadisparitymap(ormul-
t 2. The two categories are managed by a central server, in
tiple,dependingonthedesign)accordingtocurrentweights
charge of receiving updated weights and distributing them
w . Subsequently, it updates them by minimizing a loss
t tothelisteningnodes.Algo.1definestheoperationscarried
function,typicallythesumofmultipletermsℓ :
i out by the server and the active clients. The server runs a
loop(lines4-14)duringwhichitwaitsforupdatedweights
w w η▽ ℓ (w ,b ) (1)
t+1 ← t − i t t transmittedbytheactiveclients(lines5-7). Onceithasre-
(cid:88)i ceivedtheupdatesfromeachactiveclient,theserveraggre-
This step updates the whole set of parameters, thus car- gatessuchupdatesbycomputingtheaverageoftheweights
rying out full adaptation of the model (FULL) with non- as in FedAvg [36] and dispatches the updated model to
negligibleoverhead–andconsequentdropinframerate. clientsC (lines8-11). ClientsAsendtheirupdatesperiodi-
Tomitigatethissideeffect,Tonionietal.[55]introduced callyaftertheyperformT stepsofadaptation(lines15-19).
Modular Adaptation (MAD) along with a dedicated back- WedubthisframeworkFedFULL.
3Algorithm1FederatedAdaptationframework. Algorithm2ModularAdaptationupdate.
Serverexecutes: ClientUpdateMAD(k,wk,T,H)://extendsClientUpdate
1: sett=0,loadpre-trainedw t =w 0 1: foreachstepτ from0toT do
2: registeradaptingclientsA,listeningclientsC 2: samplebatchb τ
3: initializebuffersW =[][],H =[][] 3: updateweightswk ←w−η▽(cid:80) iℓ i(wk,b τ)
4: whileTruedo 4: foreachblockiinHdo
5: foreachclientk Ainparalleldo 5: H[k][i]+=1ifiwasupdated
6: W[k] ←Clien∈ tUpdate(k,w tk,T) 6 7:
:
enden fd orfor
7: endfor
8: j ←sample(softmax(H[k]))
8: foreachblockiinw tdo
9: H[k][j]=0.9·H[k][j]
9: w t+1[i] ← A1 k AW[k][i] 10: returnj,wk[j]toserver
10: sendw t+1t|o| C||
(cid:80)
∈
11: endfor
12: flushbufferW =[] Purposely,werevisetheMADNetdesignanddevelopa
13: t t+1 newbaselineforreal-timeself-adaptivedeepstereo,which
←
14: endwhile wedubMADNet2. Wearguethatoneoftheweaknessesin
its original architecture lies within the module responsible
ClientUpdateFULL(k,wk,T): //extendsClientUpdate
forbuildingthecostvolumeatmultiplescales.Specifically,
15: foreachstepτ from0toT do
it computes correlation scores between features along the
16: samplebatchb τ
17: updateweightswk ←w−η▽(cid:80) iℓ i(wk,b τ) epipolar line according to a radius r, defined as a hyper-
parameter(thelargertheradius,thehigherthechancetohit
18: endfor
19: returnwktoserver thecorrespondingpixels)andcollectsthemintocoarse-to-
fine volumes, processed by decoders to estimate disparity
maps at different scales. For the sake of efficiency, small
Thisway,Creceiveupdatestotheirweightsandimprove valuesofrareused–suchas2asintheoriginalMADNet–
theiraccuracy,withoutactivelyrunninganyGPU-intensive thusconstrainingthesearchrangeand,potentially,reducing
extra computation. However, significant data traffic be- accuracy for disparities falling out of it, despite the use of
tweenA,theserver,andCisintroduced,proportionaltothe featureswarpingateachscale.
numberofparametersinthestereonetwork,thenumberof Wereplacethismodulewiththeall-pairscorrelationvol-
clients,andtheupdatesintervalT. Purposely,weproposea ume proposed by RAFT-Stereo [30], thus extending the
variantoftheaforementionedfederatedframeworkinspired searchrangetotheentireepipolarlineatanyscale. Then,a
byMAD[55],bychangingtheupdatingprocedurecarried pyramidofcorrelationscoresissampledandforwardedto
outbynodesAasoutlinedinAlgo. 2. Ateachadaptation thedecoders:thisensuresobtainingafixedamountofchan-
step, the client keeps track of the blocks it updates (lines nels as input to the decoder, independently of the image
4-6)whichcouldbesomeorallofthem. Then,itsamples resolution. Differently from RAFT-Stereo, which builds a
asingleblockaccordingtoaprobabilitydistributionofthe singlevolumeatquarterresolutionanditeratesanarbitrary
most updated blocks (line 8), sends it solely to the server, amountoftimestoestimatedisparity,webuildmultiplevol-
and decays its number of updates (line 9). On the server umes at lower scales (from 1 up to 1 as in the original
64 4
side, averaging is performed only for the subset of blocks MADNet) and estimate a fixed number of disparity maps.
received. WerefertothisvariantasFedMAD;wewillshow This, together with the very compact design of the entire
howitcanreducedatatrafficsignificantly,withamarginal architecture, trades the high accuracy achieved by RAFT-
dropintheaccuracyofclientsC. Stereo with a significantly lower running time (about 60
×
lower).Finally,inourreviseddesignweremovethecontext
3.3.ProposedBackbone: MADNet2
network[55]tofurtherprioritizeefficiency.
Withourfederatedframeworkbeingdefined,wenowselect 4.ExperimentalResults
thestereobackbonetobecoupledwithit.MADNet[41,55]
wouldbeanaturalchoice,sincealreadydesignedtoexploit Inthissection,weevaluatetheimpactofourframework.
modular adaptation and thus ready for both FedFULL and
4.1.ExperimentalSettings
FedMADvariants. However,itsaccuracy,accordingto[41,
55], falls far behind the one achieved by modern state-of- ImplementationDetails. Weimplementourframework
the-artarchitectures[24,30,63,65]and,despitethemuch in PyTorch. We use models provided by the authors when
higherefficiency,evenwhileadapting,itcannotmatchtheir available, or retrain them following the recommended set-
results. tings – e.g., we retrain those showing bad generalization
4City Residential Campus(×2) Road All Runtime
D1-all EPE D1-all EPE D1-all EPE D1-all EPE D1-all EPE 3090 AGX
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px) (%) (px) (ms) (ms)
RAFT-Stereo[30] 1.55 0.89 1.77 0.82 2.53 0.89 1.77 0.85 1.75 0.84 333
CREStereo[24] 1.87 0.99 1.71 0.89 3.21 1.07 2.00 0.89 1.82 0.91 470
Noadapt. >2000
IGEV-Stereo[63] 2.26 1.00 2.56 0.94 3.01 0.99 2.52 0.96 2.51 0.96 493
UniMatch[65] 2.66 1.13 3.20 1.10 3.10 1.13 2.26 1.08 2.97 1.10 110
MADNet[55] 37.42 9.96 37.04 11.34 51.98 11.94 47.45 15.71 38.84 11.68 7 64
Noadapt.
MADNet2(ours) 4.04 1.10 4.05 1.03 6.07 1.29 4.01 1.08 4.21 1.09 5 47
(a)Noadaptation–pre-trainedon[35]
FULL 3.35 1.11 2.38 0.94 10.62 1.78 2.72 1.04 2.43 0.95 38 630
MADNet[55]
MAD 7.51 1.63 4.37 1.32 22.27 3.66 9.38 2.04 4.09 1.19 15 121
FULL 1.32 0.87 1.20 0.80 3.45 1.21 1.09 0.81 1.25 0.83 33 526
MADNet2
MAD 1.40 0.88 1.20 0.81 3.84 1.15 1.11 0.80 1.26 0.84 11 80
(b)Adaptation–photometricloss[55]
FULL++ 3.51 1.12 2.27 0.94 9.69 1.63 3.18 1.05 2.28 0.95 21 553
MADNet[41]
MAD++ 4.12 1.18 3.31 1.04 11.24 1.76 5.32 1.22 2.46 0.98 12 97
FULL++ 1.23 0.90 1.05 0.80 2.39 0.92 1.02 0.83 1.06 0.82 18 464
MADNet2
MAD++ 1.39 0.93 1.16 0.83 2.88 1.00 1.14 0.85 1.16 0.84 8 70
(c)Adaptation–proxylabels[41]
Table1.Onlineadaptationwithinasingledomain.ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI[17].
performance,usingtheaugmentationstrategysuggestedin ourmodelandotherreal-timenetworks.
[58]. Federated runs are carried out on a server featuring KITTI [17]. A large dataset featuring 61 stereo se-
4 3090GPUsandAMDEPYC745232-CoreCPU.Each quences, for a total of about 43k pairs with 375 1242
× ×
client runs independently on a single GPU, on a dedicated average resolution. Following [41, 55], we test on Road,
thread started through the Python threading module to en- Residential, Campus and City domains obtained by con-
ableconcurrency. Unlessotherwisespecified,thelistening catenatingallthesequencesaccordingtotheirclassification
clientissupportedbythreeclientsrunningfulladaptation, ontheofficialwebsite,usingfilteredLiDARmeasurements
withupdaterateT = 10. Toreducetherandomnessdueto [15]convertedtodisparitiesasground-truths.
allocation and run of any thread, the listening client starts DrivingStereo [67]. This dataset collects about 170k
only after other clients have started and transmitted their stereoimagesgroupedin38sequenceswithanaverageres-
firstupdatetotheserver. Then,theyloopthroughtheirse- olution of 400 880 pixels. As defined in [41], we se-
×
quenceuntilthelisteningclienthasfullyprocesseditsown. lectthesameRainy,Dusky,andCloudysequencesforeval-
Regarding adaptation, we use FULL and MAD strategies uation. For federated experiments, we sample additional
from [55], whereas, for the former, we compute losses for sequences according to their classification in [67], respec-
any predicted disparity rather than for the latest only [55]. tivelytaggedasFoggy(2018-10-17-14-35,2018-10-22-10-
Evaluation Protocol. We follow [41, 55] to evaluate any 44and2018-10-25-07-37,sincenootherrainsequencesare
model: we process the stereo pairs in a sequential order, presentonthedataset),Dusky(2018-10-16-07-40,2018-10-
mimickinganonlineacquisitionscenario. Wemeasurethe 16-11-13and2018-10-16-11-43)andCloudy(2018-10-17-
D1-all error rate as the percentage of pixels having abso- 14-35,2018-10-17-15-38and2018-10-18-10-39).
lute disparity error larger than 3 and relative error larger DSEC [14]. A dataset collected by means of stereo
than5%,aswellastheEnd-Point-Error(EPE).Inthecase RGB and event cameras, providing 53 sequences for a to-
of an adaptation, the error is computed before weights are talofabout50kstereopairsat1080 1440resolution,for
×
updated. Whenperformingfederatedadaptation,theactive halfofwhichground-truthdisparityisprovided. Fromthis
clients run on sequences from different domains to avoid dataset, we select four sequences to test online adaptation
any data leak and favor the passive client. We also re- on nighttime images: zurich city 03 a, zurich city 09 a,
port model speed by measuring the CUDA total execution zurich city 10 a and zurich city 10 b, respectively tagged
timewithPyTorchprofilingtools–i.e.,notconsideringin- as Night#1, Night#2, Night#3 and Night#4. In fed-
put/output overheads – both when running on nVidia RTX erated experimets, we use sequences zurich city 09 b,
3090(350Wconsumption)oronaJetsonAGXXavierem- zurich city 09 c, zurich city 09 d and zurich city 09 e for
bedded board (set in MAXN mode and consuming 30W), adaptingactiveclients.
averagedover100runsafterabootstrapof100inferences.
In most tables, we highlight the best and secondbest 4.3.EvaluationonKITTI
resultsamongmacro-categories.
Single-agent Adaptation. Tab. 1 collects the results
achieved by several pre-trained stereo models on the sin-
4.2.Datasets
gledomainsofKITTI.Ontop(a),wereportstate-of-the-art
FlyingThings3D. A collection of synthetic images, com- models[24,30,63,65]characterizedbyoutstandinggener-
prising approximately 22k training stereo pairs with dense alizationperformanceonthisdataset, yetfarfromrunning
groundtruthlabels,partoftheSceneFlowsyntheticdataset inreal-time–orevenfarfromachieving1FPSonAGX–
[35]. Following[52],thisdatasethasbeenusedtopre-train followedbyMADNetandMADNet2. Thelatter,although
5City Residential Campus(×2) Road DataTraffic Runtime
D1-all EPE D1-all EPE D1-all EPE D1-all EPE ToServer ToClient 3090 AGX
Model Fed.mode
(%) (px) (%) (px) (%) (px) (%) (px) (MB/s) (MB/s) (ms) (ms)
FedFULL 1.42 0.89 1.22 0.80 3.93 1.14 1.12 0.80 20.2 6.6
FedMAD 1.48 0.90 1.29 0.81 4.05 1.17 1.16 0.82 4.3 3.6
MADNet2 FedDEC 1.43 0.90 1.24 0.82 3.92 1.12 1.14 0.81 14.3 4.7 5 47
FedLAST 2.72 1.07 2.90 1.02 4.53 1.21 2.23 0.97 2.4 0.8
FedENC 3.44 1.05 3.40 0.98 5.56 1.23 3.43 1.03 6.8 2.3
(a)FederatedAdaptation–photometricloss[55]
FedFULL++ 1.38 0.94 1.12 0.81 3.45 1.10 1.11 0.85 28.4 9.4
FedMAD++ 1.46 0.95 1.20 0.83 3.55 1.11 1.19 0.87 6.4 5.2
MADNet2 FedDEC++ 1.54 0.98 1.35 0.86 3.74 1.11 1.22 0.90 20.1 6.7 5 47
FedLAST++ 3.09 1.16 3.07 1.05 4.80 1.24 2.54 1.06 3.7 1.2
FedENC++ 3.34 1.04 3.16 0.95 5.54 1.22 3.29 1.02 10.0 3.3
(b)FederatedAdaptation–proxylabels[41]
Table2.FederatedadaptationwithMADNet2.ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI[17].
Figure3. Ablationstudy–impactoftheupdatefrequency(top)andnumberofagents(bottom)onaccuracy. WereportD1-all(%)
ontheKITTIdatasetforFedFULL(blue)andFedMAD(green).
generalizinglargelybetterthantheformer,cannotreachthe
previousmodelsyet,despitebeingunquestionablymoreef-
ficient. Then, we report in (b) and (c) the results achieved
byenablingadaptationusingphotometricloss[55]orproxy
labels [41], either with FULL or MAD strategies [55]. In
the latter case, we can observe slightly lower processing
time, probably caused by the different effort required to
compute the loss on sparse labels rather than reprojecting
images and measuring photometric dissimilarity densely.
Figure4.Ablationstudy–impactoftheupdatefrequency(top)
Notably, MADNet falls short of achieving the accuracy of and number of clients (bottom) on traffic. We report MB/s
state-of-the-artmodels[24,30,63,65]trainedonsynthetic (top) and MB/updates (bottom) exchanged on the KITTI dataset
data solely, even when adapting. Conversely, MADNet 2 forFedFULL(blue)andFedMAD(green).
largely benefits from its improved generalization. By en-
abling adaptation, it bridges the gap with state-of-the-art (FedDEC), the last decoder (FedLAST), or the encoders
networks, even outperforming them when proxy labels are [12](FedENC)–whiledampeningtheeffectofadaptation.
available [41], and still running in real-time on high-end Only the former two nearly preserve the accuracy yielded
hardware – while on lower-powered platforms it reaches byFedFULL,withFedMADreducingthedatatrafficmuch
nearly 15 FPS in its most efficient setup, i.e. MAD++, if more than FedDEC while also retaining the highest accu-
dedicatedhardwareisavailabletogetproxylabels[41]. racy when the adapting clients mounting dedicated hard-
Federated Adaptation. We now measure the boost waretocomputeproxylabels. Inthislattercase,thelisten-
in accuracy MADNet 2 gains when exploiting distributed ingclientbenefitsfromtheboostgivenbylabelsyetwithout
adaptation. Tab. 2reportstheoutcomeofthisexperiment: havinganyhardwarededicatedtotheircomputation.
foraclientrunningonadomain,threeremoteclientsadapt AblationStudies. Theeffectivenessoffederatedadap-
on5randomsequencessampledfromtheotherdomainsac- tationscalesmainlywithtwohyper-parameters: i)thefre-
cordingtoFULL(a)orFULL++(b)algorithms.Withrefer- quencyatwhicheachclientpushesitsupdatedmodeltothe
encetoTab. 1, wecannoticehowFedFULL/FedFULL++ server, and ii) the number of remote clients actively con-
consistently outperforms MAD/MAD++ (except on Cam- tributing to adaptation. Both dictate the speed at which a
pus),whilenotaddinganycomputationaloverhead,thanks passive agent will benefit from adaptation, as well as the
totheeffortsbythedistributedclients,yetatthecostofin- volumeofdatabeingtransferredtothecloud.
troducing some data traffic between nodes. This latter can Fig. 3examinestheimpactofbothfactorsonaccuracy
be reduced by FedMAD – or some alternative strategies, withFedFULLandFedMAD.Ontop,wecanobservehow
consisting of averaging only the weights of the decoders sending updates to the server once every 100 adaptation
6City Residential Campus(×2) Road DataTraffic Runtime
D1-all EPE D1-all EPE D1-all EPE D1-all EPE ToServer ToClient 3090 AGX
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px) (MB/s) (MB/s) (ms) (ms)
NoAdapt. 2.57 1.04 2.51 0.96 3.97 1.25 2.98 1.02 - - 19 177
CoEX[3] FULL 0.93 0.81 0.79 0.72 2.11 0.90 0.85 0.77 - - 80 1403
FedFULL 1.13 0.84 0.90 0.74 2.55 0.99 1.12 0.80 8.2 2.2 19 177
NoAdapt. 1.99 1.00 2.15 0.93 3.11 1.06 2.07 0.95 - - 36 404
HITNet[52] FULL 0.92 0.81 0.93 0.74 2.15 0.88 0.83 0.76 - - 110 1653
FedFULL 0.94 0.82 0.94 0.74 2.03 0.82 0.90 0.79 2.2 0.6 36 404
NoAdapt. 4.33 1.26 3.47 1.10 3.80 1.19 4.67 1.21 - - 42 ✗
TemporalStereo[72] FULL 1.06 0.82 0.99 0.76 2.90 1.03 0.87 0.75 - - 162 ✗
FedFULL 1.25 0.86 1.04 0.78 2.24 0.91 1.15 0.82 31.2 8.9 42 ✗
Table3. Onlineadaptationbyfastnetworks(TemporalStereo[72],HITNet[52],CoEX[3])withinasingledomain–singleagent
vsfederatedadaptation.ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI[17].
Rainy Dusky Cloudy DataTraffic Runtime
D1-all EPE D1-all EPE D1-all EPE ToServer ToClient 3090 AGX
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (MB/s) (MB/s) (ms) (ms)
RAFT-Stereo[30] 11.52 1.59 3.08 0.88 4.18 1.02 - - 264
CREStereo[24] 17.43 3.61 7.08 1.23 4.08 1.07 - - 415
NoAdapt. >1000
IGEV-Stereo[63] 11.70 1.85 3.57 0.95 5.27 1.26 - - 389
UniMatch[65] 14.84 2.69 7.51 1.27 5.78 1.25 - - 85
CoEX[3] 13.48 2.53 11.00 1.58 4.46 1.16 - - 16 130
HITNet[52] NoAdapt. 14.08 2.74 8.88 1.37 4.17 1.14 - - 29 311
TemporalStereo[72] 18.53 3.94 13.61 1.80 6.02 1.31 - - 33 ✗
MADNet[55] 27.14 3.90 24.73 2.45 11.00 1.77 - - 6 64
NoAdapt.
MADNet2(ours) 16.47 3.03 13.16 1.66 6.72 1.35 - - 4 43
(a)NoAdaptation–pre-trainedon[35]
FULL 10.19 1.70 11.36 1.54 5.76 1.27 - - 30 492
MADNet2
MAD 11.12 1.78 13.36 1.61 5.93 1.26 - - 12 65
FedFULL 11.57 2.00 10.65 1.44 5.45 1.20 20.6 6.8 4 43
MADNet2
FedMAD 11.71 2.10 10.12 1.41 5.60 1.21 4.6 3.6 4 43
(b)Single-agentvsFederatedAdaptation–photometricloss[55]
FULL++ 10.34 2.27 4.41 1.04 5.20 1.63 - - 20 470
MADNet2
MAD++ 10.06 2.01 5.25 1.09 4.34 1.09 - - 8 48
FedFULL++ 8.33 1.73 4.13 1.00 4.55 1.13 28.8 9.6 4 43
MADNet2
FedMAD++ 8.58 1.74 4.40 1.01 4.65 1.16 6.5 4.5 4 43
(c)Single-agentvsFederatedAdaptation–proxylabels[41]
Table4.OnlineadaptationonDrivingStereo[67].ResultsontheRainy,DuskyandCloudysequencesasselectedin[41].
stepsyieldsnoticeableimprovementsinmostcasesalready, more accurate than MADNet 2 with reference to Tabs. 1
saturating when increasing it to one every 10. At the bot- and 2, it is worth observing how both of these models re-
tom, we show how increasing the number of active clients quiremorethanonesecondtogenerateadisparitymapon
consistentlyimprovestheresultsforthelisteningnode. AGX, and barely reach 5 FPS when adaptation is not en-
Fig.4reportstheamountofdatatransmittedfromadapt- abled1. Assuch, wefeelMADNet2isamoreflexibleso-
ingclientstotheserver(left),aswellasfromtheserverto lutionfordeployingreal-timeadaptivestereosystems,run-
the listening client (right) as functions of the update fre- ningat20FPSonAGXwhilefederallyadapting.
quency(top)andthenumberofclients(bottom). Wehigh- AdditionalResults. Forthesakeofspace,wereferthe
light how FedMAD enables moderate growth in data traf- readertothesupplementarymaterialformoreresults.
ficwhenthefrequencyisincreasedcomparedtoFedFULL,
with significant savings on the updates sent to the server. 4.4.EvaluationonDrivingStereo
ThegapwithFedFULLbecomeslargerwhenmoreclients
Following [41], we evaluate our framework on the Driv-
contribute to the process. In contrast, the data transferred
ingStereo dataset, characterized by more challenging en-
tothelisteningclientremainsconstantwithFedFULL,and
vironmental conditions harming the generalization capa-
thesavingbyFedMADnullifiesbeyond6clients.
bility of deep stereo models. Tab. 4 collects the results
Federated Adaptation – Other Networks. Online
achieved by state-of-the-art models [24, 30, 63, 65], real-
adaptationcanbeperformedbyanystereonetworkand,as
time networks [3, 52, 72], MADNet [55] and our MAD-
such, federated adaptation can as well. Purposely, we im-
Net 2 trained on synthetic data (a). We can notice how, in
plement FULL and FedFULL with other real-time stereo
general,theerrormetricsarehighercomparedtothoseob-
networks – CoEX [3], HITNet [52], and TemporalStereo
servedonKITTI,confirmingthemorechallengingnatureof
[72]andevaluatetheirperformanceonKITTI.Tab. 3col-
thisdataset. Again, MADNet2provestogeneralizemuch
lects the outcome of this experiment. We can notice how
betterthanMADNet,yetfallsfarbehindthetop-performing
the three models can effectively adapt on the single do-
stereonetworks,closetootherfastmodels.
mains, at the cost of dropping their efficiency. By de-
Adapting with photometric losses (b) within single do-
mandingtheadaptationprocesstodistributedclients,allof
mains only marginally improves the results on this bench-
themcanbenefitfromanequivalentboostinperformances
mark – especially on Dusky: we ascribe this to the more
whileavoidingefficiencydrops–withTemporalStereoand
challenging conditions depicted in these sequences, which
HITNetimprovingevenmorewithFedFULLcomparedto
FULLonCampus.AlthoughCoEXandHITNetareslightly 1wecouldnotrun[72]becauseofbrokendependenciesonAGX
7Night#1 Night#2 Night#3 Night#4 DataTraffic Runtime
D1-all EPE D1-all EPE D1-all EPE D1-all EPE ToServer ToClient 3090 AGX
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px) (MB/s) (MB/s) (ms) (ms)
RAFT-Stereo[30] 13.04 3.41 21.64 4.26 10.91 1.91 10.07 1.68 - - 1030
CREStereo[24] 11.34 2.38 23.48 3.19 15.37 2.39 12.42 1.75 - - 1242
Noadapt. >8000
IGEV-Stereo[63] 9.14 1.85 11.97 1.96 12.65 2.01 10.01 1.66 - - 1250
UniMatch[65] 34.29 5.43 39.80 5.32 26.75 3.29 26.29 3.28 - - 480
CoEX[3] 6.26 1.72 10.81 1.87 8.60 1.64 8.31 1.53 - - 53 539
HITNet[52] Noadapt. 6.49 1.54 9.57 1.71 8.28 1.62 7.88 1.47 - - 112 1400
TemporalStereo[72] 7.17 1.68 10.22 1.92 8.66 1.62 8.40 1.49 - - 118 ✗
MADNet2(ours) NoAdapt. 8.94 1.97 13.86 2.32 10.63 1.83 10.55 1.69 - - 12 111
(a)Noadaptation–pre-trainedon[35]
FULL 5.65 1.41 9.16 1.60 8.12 1.50 8.97 1.46 - - 102 1238
MADNet2
MAD 5.79 1.52 8.87 1.60 7.89 1.49 8.50 1.46 - - 30 253
FedFULL 5.50 1.43 8.36 1.52 7.63 1.48 7.57 1.37 13.8 4.6 12 111
MADNet2
FedMAD 5.52 1.43 8.39 1.53 7.91 1.50 7.79 1.39 2.9 2.0 12 111
(b)Single-agentvsFederatedAdaptation–photometricloss[55]
FULL++ 4.69 1.28 7.13 1.43 6.20 1.35 6.06 1.27 - - 45 808
MADNet2
MAD++ 5.66 1.43 7.76 1.49 6.57 1.39 6.47 1.30 - - 16 172
FedFULL++ 4.99 1.33 7.03 1.41 6.43 1.37 6.18 1.28 21.7 7.1 12 111
MADNet2
FedMAD++ 4.99 1.34 7.13 1.42 6.48 1.38 6.23 1.28 7.3 5.8 12 111
(c)Single-agentvsFederatedAdaptation–proxylabels[41]
Table5.OnlineadaptationonDSEC[14].ResultsontheNight#1,Night#2,Night#3andNight#4sequences.
potentially compromise the effectiveness of the photomet- tometric loss (b) or proxy labels (c), and even being more
ricloss.Intheseconditions,thepossibilityofrelyingonthe effective than FULL in the former case. Given the lower
adaptationcarriedoutbyotherclientsresultscrucialalsoin inference speed caused by the dataset resolution, we can
terms of accuracy, allowing both FedFULL and FedMAD noticelowerdatatraffic. Thisoccursastheadaptingmod-
toachievebetterresultsonDuskyandCloudycomparedto els require more time to perform the T steps set to update
standardFULL/MADexecutedoverthetwodomains. the server. Yet, FedMAD still allows for further reducing
When proxy labels are available (c), both FULL++ and thecommunicationoverheadwithlittledropsinaccuracy.
MAD++ produce notably better results, yet leveraging the Forthesakeofcompleteness,inthesupplementaryma-
adaptationcarriedoutremotelywithFedFULL++andFed- terialwereporttheresultsbyotherreal-timemodels.
MAD++allowstoimprovetheresultsevenfurtheronRainy
andDusky–ontheformerinparticular,itgainsabout1.5%
5.Conclusion
inD1-all–whileresultingcomparableonCloudy.
Insummary,aclientdemandingadaptationtothecloud In this paper, we presented for the first time a framework
can benefit even more than carrying it out independently thatimplementsfederatedonlineadaptationfordeepstereo
inchallengingenvironments, whileavoidingruntimeover- models. By demanding the optimization process to dis-
heads. Accordingly,MADNet2canstillruninreal-timeon tributed nodes, a single model can benefit from adaptation
AGXandsurpassotherfastmodels[3,52,72],runningnot even when deployed on low-powered hardware, thus im-
evenat10FPSthere. Thesupplementarymaterialreports provingitsaccuracywhilemaintainingitsoriginalprocess-
federatedexperimentswithotherreal-timemodels. ingspeed. Thisachievementcomesatthecostofintroduc-
ingdatatrafficbetweennodes; however, thistrafficcanbe
4.5.EvaluationonDSEC
reduced by means of an appropriate strategy that updates
We conclude by running further experiments on nighttime onlysomeportionsoftheentiremodelateachcommunica-
stereo sequences taken from the DSEC dataset [14]. Tab. tionround,specificallytailoredforourMADNet2.Exhaus-
5 collects the results yielded by any stereo model consid- tive experiments showcase the effectiveness of our frame-
ered so far on four selected night sequences. In contrast workanditsabilitytobecombinedwithdifferentmodels.
to KITTI and DrivingStereo, in (a) we can notice how the Limitations. At now, passive clients benefit from the
state-of-the-art models achieve a much higher error rate, adaptation carried out by some active clients, without the
with real-time architectures proving to be more robust in latterreceivingreciprocalbenefitsinreturn,andtheadapt-
thiscontext. Moreover,thehigherresolutionofthisdataset ing nodes process images with similar properties (resolu-
makes the runtime of each method increase notably, with tion, depth range, application context) to those observed
MADNet 2 being the only model still capable of retaining by the listening client. Finally, as clients run on the same
almost 10 FPS on AGX when not adapting. By actively server,connectiondelaysareignoredinourexperiments.
adapting with FULL or MAD (b,c), MADNet 2 can fur- Future Work. We foresee federated adaptation will be
ther improve its accuracy and outperform the other stereo appliedtoothervisualtasksforwhichonlineadaptationis
models,whiledroppingbelow5FPS.Insuchasetting,we areality,suchassingleimagedepthestimation[73],optical
can further appreciate how FedFULL becomes crucial for flow[39]orsemanticsegmentation[4,40].
maintainingreasonableruntimewhileenjoyingthebenefits Acknowledgment. WethankLARLaboratory(Univer-
ofadaptation,outperformingMADeitherwhenusingpho- sityofBologna)forprovidingtheJetsonAGXXavier.
8References [13] AlirezaFallah,AryanMokhtari,andAsumanOzdaglar.Per-
sonalizedfederatedlearningwiththeoreticalguarantees: A
[1] FilippoAleotti,FabioTosi,LiZhang,MatteoPoggi,andSte-
model-agnosticmeta-learningapproach. InNeurIPS,2020.
fano Mattoccia. Reversing the cycle: self-supervised deep
[14] MathiasGehrig,WillemAarents,DanielGehrig,andDavide
stereothroughenhancedmonoculardistillation. In16thEu-
Scaramuzza. DSEC:Astereoeventcameradatasetfordriv-
ropean Conference on Computer Vision (ECCV). Springer,
ingscenarios. IEEERoboticsandAutomationLetters,2021.
2020.
[15] Andreas Geiger, Martin Roser, and Raquel Urtasun. Effi-
[2] FilippoAleotti,FabioTosi,PierluigiZamaRamirez,Matteo
cient large-scale stereo matching. In Asian conference on
Poggi,SamueleSalti,StefanoMattoccia,andLuigiDiSte-
computervision,pages25–38.Springer,2010.
fano. Neural disparity refinement for arbitrary resolution
[16] AndreasGeiger, PhilipLenz, andRaquelUrtasun. Arewe
stereo. In International Conference on 3D Vision, 2021.
readyforautonomousdriving?TheKITTIvisionbenchmark
3DV.
suite.InConferenceonComputerVisionandPatternRecog-
[3] AntyantaBangunharcana,JaeWonCho,SeokjuLee,InSo
nition(CVPR),2012.
Kweon,Kyung-SooKim,andSoohyunKim.Correlate-and-
[17] AndreasGeiger, PhilipLenz, ChristophStiller, andRaquel
excite: Real-time stereo matching via guided cost volume
Urtasun. Vision meets robotics: The KITTI dataset. The
excitation. InIEEE/RSJInternationalConferenceonIntelli-
International Journal of Robotics Research, 32(11):1231–
gentRobotsandSystems(IROS),2021.
1237,2013.
[4] Marc Botet Colomer, Pier Luigi Dovesi, Theodoros Pana-
[18] Cle´ment Godard, Oisin Mac Aodha, and Gabriel J. Bros-
giotakopoulos, Joao Frederico Carvalho, Linus Ha¨renstam-
tow. Unsupervised monocular depth estimation with left-
Nielsen,HosseinAzizpour,HedvigKjellstro¨m,DanielCre-
rightconsistency. InCVPR,2017.
mers,andMatteoPoggi. Toadaptornottoadapt?real-time
[19] WeiyuGuo,ZhaoshuoLi,YongkuiYang,ZhengWang,Rus-
adaptationforsemanticsegmentation.InIEEEInternational
sellHTaylor, MathiasUnberath, AlanYuille, andYingwei
ConferenceonComputerVision,2023. ICCV.
Li. Context-enhanced stereo transformer. In Proceedings
[5] Changjiang Cai, Matteo Poggi, Stefano Mattoccia, and
of the European Conference on Computer Vision (ECCV),
Philippos Mordohai. Matching-space stereo networks for
2022.
cross-domaingeneralization. In2020InternationalConfer-
[20] Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu,
enceon3DVision(3DV),pages364–373,2020.
PhillipIsola,KateSaenko,AlexeiEfros,andTrevorDarrell.
[6] Jia-Ren Chang and Yong-Sheng Chen. Pyramid stereo
Cycada: Cycle-consistentadversarialdomainadaptation. In
matchingnetwork. InIEEE/CVFConferenceonComputer
Internationalconferenceonmachinelearning,pages1989–
VisionandPatternRecognition(CVPR),pages5410–5418,
1998.Pmlr,2018.
2018.
[21] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri,
[7] Hong-You Chen and Wei-Lun Chao. On bridging generic Sashank Reddi, Sebastian Stich, and Ananda Theertha
andpersonalizedfederatedlearningforimageclassification. Suresh. Scaffold: Stochastic controlled averaging for fed-
InICLR,2022. eratedlearning. InICML,2020.
[8] Hong-YouChen, Cheng-HaoTu, ZiweiLi, HanWeiShen, [22] AlexKendall,HaykMartirosyan,SaumitroDasgupta,Peter
andWei-LunChao. Ontheimportanceandapplicabilityof Henry,RyanKennedy,AbrahamBachrach,andAdamBry.
pre-trainingforfederatedlearning. InTheEleventhInterna- End-to-endlearningofgeometryandcontextfordeepstereo
tionalConferenceonLearningRepresentations,2022. regression. InTheIEEEInternationalConferenceonCom-
[9] Xuelian Cheng, Yiran Zhong, Mehrtash Harandi, Yuchao puterVision(ICCV),2017.
Dai, Xiaojun Chang, Hongdong Li, Tom Drummond, and [23] Hsueh-YingLai,Yi-HsuanTsai,andWei-ChenChiu.Bridg-
Zongyuan Ge. Hierarchical neural architecture search for ingstereomatchingandopticalflowviaspatiotemporalcor-
deepstereomatching. AdvancesinNeuralInformationPro- respondence. InProceedingsoftheIEEE/CVFConference
cessingSystems,33,2020. on Computer Vision and Pattern Recognition, pages 1890–
[10] ChengChi,QingjieWang,TianyuHao,PengGuo,andXin 1899,2019.
Yang. Feature-levelcollaboration:Jointunsupervisedlearn- [24] Jiankun Li, Peisen Wang, Pengfei Xiong, Tao Cai, Ziwei
ingofopticalflow,stereodepthandcameramotion. InPro- Yan,LeiYang,JiangyuLiu,HaoqiangFan,andShuaicheng
ceedingsoftheIEEE/CVFConferenceonComputerVision Liu. Practical stereo matching via cascaded recurrent net-
andPatternRecognition,pages2463–2473,2021. work with adaptive correlation. In Proceedings of the
[11] WeiQin Chuah, Ruwan Tennakoon, Reza Hoseinnezhad, IEEE/CVF Conference on Computer Vision and Pattern
Alireza Bab-Hadiashar, and David Suter. ITSA: An Recognition,pages16263–16272,2022.
information-theoreticapproachtoautomaticshortcutavoid- [25] Qinbin Li, Bingsheng He, and Dawn Song. Model-
anceanddomaingeneralizationinstereomatchingnetworks. contrastivefederatedlearning. InCVPR,2021.
In Proceedings of the IEEE/CVF Conference on Computer [26] QinbinLi,ZeyiWen,ZhaominWu,SixuHu,NaiboWang,
VisionandPatternRecognition,pages13022–13032,2022. YuanLi,XuLiu,andBingshengHe. Asurveyonfederated
[12] LiamCollins,HamedHassani,AryanMokhtari,andSanjay learning systems: vision, hype and reality for data privacy
Shakkottai. Exploitingsharedrepresentationsforpersonal- andprotection. IEEETransactionsonKnowledgeandData
izedfederatedlearning. InICML,2021. Engineering,2021.
9[27] TianLi,AnitKumarSahu,ManzilZaheer,MaziarSanjabi, tions.InEuropeanConferenceonComputerVision(ECCV),
AmeetTalwalkar,andVirginiaSmith. Federatedoptimiza- 2022.
tioninheterogeneousnetworks. InMLSys,2020. [41] MatteoPoggi,AlessioTonioni,FabioTosi,StefanoMattoc-
[28] ZhaoshuoLi, XingtongLiu, NathanDrenkow, AndyDing, cia, and Luigi Di Stefano. Continual adaptation for deep
Francis X Creighton, Russell H Taylor, and Mathias Un- stereo. IEEETransactionsonPatternAnalysisandMachine
berath. Revisitingstereodepthestimationfromasequence- Intelligence(TPAMI),2021.
to-sequenceperspective withtransformers. In Proceedings [42] Matteo Poggi, Fabio Tosi, Konstantinos Batsos, Philippos
oftheIEEE/CVFInternationalConferenceonComputerVi- Mordohai,andStefanoMattoccia.Onthesynergiesbetween
sion,pages6197–6206,2021. machinelearningandbinocularstereofordepthestimation
[29] Zhengfa Liang, Yiliu Feng, Yulan Guo, Hengzhu Liu, Wei fromimages: asurvey. IEEETransactionsonPatternAnal-
Chen,LinboQiao,LiZhou,andJianfengZhang. Learning ysisandMachineIntelligence,2021.
fordisparityestimationthroughfeatureconstancy. InPro- [43] Daniel Scharstein and Richard Szeliski. A taxonomy and
ceedings of the IEEE Conference on Computer Vision and evaluation of dense two-frame stereo correspondence algo-
PatternRecognition(CVPR),2018. rithms. IJCV,47(1-3):7–42,2002.
[30] LahavLipson,ZacharyTeed,andJiaDeng. RAFT-Stereo: [44] Daniel Scharstein, Heiko Hirschmu¨ller, York Kitajima,
Multilevelrecurrentfieldtransformsforstereomatching. In Greg Krathwohl, Nera Nesˇic´, Xi Wang, and Porter West-
InternationalConferenceon3DVision(3DV),2021. ling. High-resolutionstereodatasetswithsubpixel-accurate
[31] BiyangLiu,HuiminYu,andGuodongQi.Graftnet:Towards groundtruth. InGermanconferenceonpatternrecognition,
domaingeneralizedstereomatchingwithabroad-spectrum pages31–42.Springer,2014.
andtask-orientedfeature. InProceedingsoftheIEEE/CVF [45] ThomasSchops,JohannesLSchonberger,SilvanoGalliani,
Conference on Computer Vision and Pattern Recognition, TorstenSattler,KonradSchindler,MarcPollefeys,andAn-
pages13012–13021,2022. dreas Geiger. A multi-view stereo benchmark with high-
[32] WenjieLuo,AlexanderGSchwing,andRaquelUrtasun.Ef- resolution images and multi-camera videos. In IEEE Con-
ficientdeeplearningforstereomatching. InProceedingsof ferenceonComputerVisionandPatternRecognition,pages
theIEEEconferenceoncomputervisionandpatternrecog- 3260–3269.IEEE,2017.
nition,pages5695–5703,2016. [46] Akihito Seki and Marc Pollefeys. Patch based confidence
[33] Xiaosong Ma, Jie Zhang, Song Guo, and Wenchao Xu. prediction for dense disparity map. In Proceedings of the
Layer-wised model aggregation for personalized federated BritishMachineVisionConference2016, page23.BMVC,
learning. InCVPR,2022. 2016.
[34] DavidMarrandTomasoPoggio. Cooperativecomputation [47] AkihitoSekiandMarcPollefeys. SGM-Nets: Semi-global
ofstereodisparity:Acooperativealgorithmisderivedforex- matchingwithneuralnetworks. InCVPR,pages231–240,
tractingdisparityinformationfromstereoimagepairs. Sci- 2017.
ence,194(4262):283–287,1976. [48] ZhelunShen,YuchaoDai,andZhiboRao. Cfnet: Cascade
[35] NikolausMayer, EddyIlg, PhilipHausser, PhilippFischer, andfusedcostvolumeforrobuststereomatching. InPro-
DanielCremers,AlexeyDosovitskiy,andThomasBrox. A ceedingsoftheIEEE/CVFConferenceonComputerVision
large dataset to train convolutional networks for disparity, andPatternRecognition,pages13906–13915,2021.
opticalflow,andsceneflowestimation.InTheIEEEConfer- [49] ZhelunShen,XibinSong,YuchaoDai,DingfuZhou,Zhibo
enceonComputerVisionandPatternRecognition(CVPR), Rao, and Liangjun Zhang. Digging into uncertainty-based
2016. pseudo-label for robust stereo matching. IEEE Transac-
[36] Brendan McMahan, Eider Moore, Daniel Ramage, Seth tionsonPatternAnalysis&MachineIntelligence,(01):1–18,
Hampson, and Blaise Aguera y Arcas. Communication- 2023.
efficientlearningofdeepnetworksfromdecentralizeddata. [50] Benyuan Sun, Hongxing Huo, Yi Yang, and Bo Bai. Par-
InAISTATS,2017. tialfed: Cross-domain personalized federated learning via
[37] MatiasMendieta,TaojiannanYang,PuWang,MinwooLee, partialinitialization. NeurIPS,2021.
Zhengming Ding, and Chen Chen. Local learning mat- [51] YueTan,GuodongLong,LuLiu,TianyiZhou,QinghuaLu,
ters:Rethinkingdataheterogeneityinfederatedlearning. In JingJiang,andChengqiZhang. Fedproto: Federatedproto-
CVPR,2022. typelearningacrossheterogeneousclients. InAAAI,2022.
[38] Moritz Menze and Andreas Geiger. Object scene flow for [52] VladimirTankovich, ChristianHane, YindaZhang, Adarsh
autonomous vehicles. In Conference on Computer Vision Kowdle,SeanFanello,andSofienBouaziz. Hitnet: Hierar-
andPatternRecognition(CVPR),2015. chical iterative tile refinement network for real-time stereo
[39] Chaerin Min, Taehyun Kim, and Jongwoo Lim. Meta- matching. InProceedingsoftheIEEE/CVFConferenceon
learning for adaptation of deep optical flow networks. In Computer Vision and Pattern Recognition, pages 14362–
ProceedingsoftheIEEE/CVFWinterConferenceonAppli- 14372,2021.
cationsofComputerVision,pages2145–2154,2023. [53] AlessioTonioni,MatteoPoggi,StefanoMattoccia,andLuigi
[40] Theodoros Panagiotakopoulos, Pier Luigi Dovesi, Linus DiStefano. Unsupervisedadaptationfordeepstereo. InThe
Ha¨renstam-Nielsen,andMatteoPoggi.Onlinedomainadap- IEEEInternationalConferenceonComputerVision(ICCV).
tation for semantic segmentation in ever-changing condi- IEEE,2017.
10[54] AlessioTonioni,OscarRahnama,TomJoy,LuigiDiStefano, [68] Feihu Zhang, Victor Prisacariu, Ruigang Yang, and
AjanthanThalaiyasingam,andPhilipTorr.Learningtoadapt PhilipHSTorr. GA-Net:Guidedaggregationnetforend-to-
forstereo. InTheIEEEConferenceonComputerVisionand endstereomatching.InIEEE/CVFConferenceonComputer
PatternRecognition(CVPR).IEEE,2019. VisionandPatternRecognition(CVPR),2019.
[55] Alessio Tonioni, Fabio Tosi, Matteo Poggi, Stefano Mat- [69] FeihuZhang,XiaojuanQi,RuigangYang,VictorPrisacariu,
toccia, andLuigiDiStefano. Real-timeself-adaptivedeep Benjamin Wah, and Philip Torr. Domain-invariant stereo
stereo. In The IEEE Conference on Computer Vision and matchingnetworks. InEuropeConferenceonComputerVi-
PatternRecognition(CVPR).IEEE,2019. sion(ECCV),2020.
[56] AlessioTonioni,MatteoPoggi,StefanoMattoccia,andLuigi [70] Jiawei Zhang, Xiang Wang, Xiao Bai, Chen Wang, Lei
DiStefano. Unsuperviseddomainadaptationfordepthpre- Huang,YiminChen,LinGu,JunZhou,TatsuyaHarada,and
dictionfromimages.IEEETransactionsonPatternAnalysis Edwin R Hancock. Revisiting domain generalized stereo
andMachineIntelligence,2020. matching networks from a feature consistency perspective.
In Proceedings of the IEEE/CVF Conference on Computer
[57] FabioTosi,YiyiLiao,CarolinSchmitt,andAndreasGeiger.
VisionandPatternRecognition,pages13001–13011,2022.
Smd-nets: Stereomixturedensitynetworks. InConference
onComputerVisionandPatternRecognition(CVPR),2021. [71] Lin Zhang, Li Shen, Liang Ding, Dacheng Tao, and Ling-
YuDuan. Fine-tuningglobalmodelviadata-freeknowledge
[58] FabioTosi,AlessioTonioni,DanieleDeGregorio,andMat-
distillationfornon-iidfederatedlearning. InCVPR,2022.
teo Poggi. Nerf-supervised deep stereo. In Conference on
[72] YouminZhang,MatteoPoggi,andStefanoMattoccia. Tem-
Computer Vision and Pattern Recognition (CVPR), pages
poralstereo: Efficient spatial-temporal stereo matching net-
855–866,2023.
work. InIROS,2023.
[59] JureZˇbontar,YannLeCun,etal.Stereomatchingbytraining
[73] ZhenyuZhang,StephaneLathuiliere,ElisaRicci,NicuSebe,
aconvolutionalneuralnetworktocompareimagepatches.J.
Yan Yan, and Jian Yang. Online depth learning against
Mach.Learn.Res.,17(1):2287–2318,2016.
forgetting in monocular videos. In Proceedings of the
[60] HaiyangWang,XinchaoWang,JieSong,JieLei,andMingli
IEEE/CVF Conference on Computer Vision and Pattern
Song.Fasterself-adaptivedeepstereo.InProceedingsofthe
Recognition(CVPR),2020.
AsianConferenceonComputerVision,2020.
[74] Yiran Zhong, Yuchao Dai, and Hongdong Li. Self-
[61] YangWang, PengWang, ZhenhengYang, ChenxuLuo, Yi supervisedlearningforstereomatchingwithself-improving
Yang,andWeiXu. Unos:Unifiedunsupervisedoptical-flow ability. arXiv:1709.00930,2017.
andstereo-depthestimationbywatchingvideos.InProceed-
[75] ChaoZhou,HongZhang,XiaoyongShen,andJiayaJia.Un-
ingsoftheIEEEConferenceonComputerVisionandPattern
supervisedlearningofstereomatching.InTheIEEEInterna-
Recognition,pages8071–8081,2019.
tionalConferenceonComputerVision(ICCV).IEEE,2017.
[62] JamieWatson,OisinMacAodha,DaniyarTurmukhambetov,
Gabriel J. Brostow, and Michael Firman. Learning stereo
fromsingleimages. InEuropeanConferenceonComputer
Vision(ECCV),2020.
[63] GangweiXu,XianqiWang,XiaohuanDing,andXinYang.
Iterativegeometryencodingvolumeforstereomatching. In
ProceedingsoftheIEEE/CVFConferenceonComputerVi-
sionandPatternRecognition,pages21919–21928,2023.
[64] Haofei Xu and Juyong Zhang. Aanet: Adaptive aggrega-
tionnetworkforefficientstereomatching.InProceedingsof
theIEEE/CVFConferenceonComputerVisionandPattern
Recognition,pages1959–1968,2020.
[65] Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi,
FisherYu,DachengTao,andAndreasGeiger.Unifyingflow,
stereoanddepthestimation. IEEETransactionsonPattern
AnalysisandMachineIntelligence,2023.
[66] Gengshan Yang, Joshua Manela, Michael Happold, and
DevaRamanan. Hierarchicaldeepstereomatchingonhigh-
resolution images. In Proceedings of the IEEE/CVF Con-
ferenceonComputerVisionandPatternRecognition,pages
5515–5524,2019.
[67] GuorunYang, XiaoSong, ChaoqinHuang, ZhidongDeng,
JianpingShi,andBoleiZhou. Drivingstereo: Alarge-scale
datasetforstereomatchinginautonomousdrivingscenarios.
InIEEEConferenceonComputerVisionandPatternRecog-
nition(CVPR),2019.
11Federated Online Adaptation for Deep Stereo
Supplementary Material
ThisdocumentsupplementstheCVPR2024paper“FederatedOnlineAdaptationforDeepStereo”.Itprovidesadditional
implementationdetailsanddeeperinsightsintotheresultsreportedinthemainpaper.
6.ImplementationDetails
6.1.MADNet2Architecture
MADNet2isimplementedontopofMADNet[55].Specifically,itismadeoftwo,sharedfeatureextractorsandasetoffive
shallowdisparitydecoders.Thesemodulesareassembledtoimplementcoarse-to-fineprocessing,asshowninFig.5.
Figure5. MADNet2architecture. Givenastereopair,asetofmulti-scalefeaturesisextractedbymeansoftwofeatureextractorswith
sharedweights. Startingfromthelowestresolution–i.e., 1 –correlationscoresarecomputedandsampledbymeansoftheall-pair
64
correlationmoduleandlookupoperatorfrom[30].Sampledscoresandimagefeaturesareprocessedbyadisparitydecoder,whichpredicts
aninitialdisparitymapat 1 resolution. Thislatterisupsampledandusedbythelookoperatorworkingonthecorrelationvolumeat 1
64 32
resolution,thenaseconddecoderpredictsarefineddisparitymapat 1 resolution.Thisprocessisrepeatedupto 1 resolution.There,the
32 4
finalpredictionisbilinearlyupsampledtotheoriginalresolution.
FeatureExtractors. Thesesub-networksareimplementedasasequenceoftwelve3 3convolutionallayers,eachfol-
×
lowedbyLeakyReLUactivationswithα=0.2.Theselayershaverespectively[16,16,32,32,64,64,96,96,128,128,192,
192]outputchannelsand[2,1,2,1,2,1,2,1,2,1,2,1]stridefactors.Featuresextractedfromlayershavingstrideequalto
1arerespectivelyat 1,1,1, 1, 1,and 1 oftheinputresolutionandareusedtocomputecoarse-to-finecostvolumes.
2 4 8 16 32 64
All-pairs Correlation Volume [30]. Features obtained from the two extractors are used to build a pyramid of cost
volumes,bycomputingall-pairscorrelationscores[30].Givenfeaturemapsf,g RH ×W ×F,a3Dcorrelationvolumecan
∈
becomputedbycomputingtheinnerproductbetweenfeaturesonthesamehorizontalline:
C ijk= f ijh·g ikh, C ∈RH ×W ×W (3)
Xh
Converselytothecorrelationlayerusedoriginallyin[55],thisoperationisnotboundtoaspecificsearchrange,thusallowing
the network to compute matching scores for all possible candidates along the epipolar line. As the correlation volume
producesC RH ×W ×W,thismakesthecostvolumechannelsdimensiondependentontheresolutionoftheinputimage.
∈
However,byexploitingthelookupoperatorfromRAFT-Stereo[30]wecansampleafixednumberofcorrelationscoresalong
thechanneldimensionandbuildafixed-sizecostvolumetobeprocessed,subsequently,byadisparitydecoder.Samplingis
performedina1Dneighborhoodwitharadius2,selectingH W 5correlationfeatures.
× ×
DisparityDecoders.Thesemodulesprocesscorrelationscoressampledbythelookupoperator,thefeaturesproducedby
thefeatureextractorfromtheleftimage,andthedisparitymapestimatedatthepreviousstage,inordertopredictarefined
disparitymapatthecurrentresolution. Eachdecoderismadeoffive3 3convolutionallayers,withstride1and[128,96,
×
48,32,1]outputchannels. AnylayerisfollowedbyLeakyReLUactivationswithα=0.2,exceptthelastone. Following
[35,55],predicteddisparitymapsarescaledbyafactor 1.
20
Training. Following [55], we train MADNet2 with a weighted sum of L1 losses computed on each disparity map.
Specifically,thepixel-wiseL1betweenpredictedanddownsampledgroundtruthdisparityissummedovertheentireimage.
Thefourtermsaresummedwithweights[0.08,0.02,0.01,0.005]fromlowertohigherresolution.WeuseAdamoptimizer,
batchsize8,andaninitiallearningrateof1e 4,halvedafter150epochs.Weusecolorandspatialaugmentationsfrom[2].
−
Adaptation.WeuseAdamoptimizerandlearningrate1e 5whenadaptingMADNet2andanyothermodel.
−
16.2.Pre-trainedModelsandProxyLabels
Wenowreportwhichspecificweightshavebeenusedforanystereonetworkinvolvedinourexperiments.
RAFT-Stereo[30], CREStereo[24]–Weusepre-trainedweightsprovidedby[58], asi)theyshowedslightlybetter
generalizationforRAFT-Stereo[30],andii)officialweightspre-trainedonSceneFlowarenotavailableforCREStereo[24].
IGEV-Stereo [63], UniMatch [65] – We use the pre-trained weights provided by the authors – respectively,
sceneflow.pthandgmstereo-scale2-regrefine3-resumeflowthings-sceneflow-f724fee6.pth.
Real-timemodels(TemporalStereo[72],HITNet[52],CoEX[3])–Astheweightsavailableonlineprovedpoorgen-
eralizationfromsynthetictorealimages,were-trainedthesethreemodelsfromscratchonFlyingThings3D[35],usingthe
originallossespresentedintherespectivepapers,followingthesametrainingprotocolandusingthesamehyper-parameters.
ProxyLabels. DisparitymapsusedforFULL++/MAD++areobtainedfollowing[41],i.e.,byrunningrSGM2andthen
post-processingtheresultswithleft-rightconsistencycheckandaspecklefilter.
7.AdditionalExperiments
Wenowreportsomeadditionalexperimentsnotfittingthe8-pagelimitofthemainpaper.
7.1.MADNetvsMADNet2
WestartbydiscussingtheresultsachievedbyourimprovedversionoftheoriginalMADNet[41,55]. Tab. 6showsthe
errorratesachievedbydifferentflavorsofMADNetwithoutadaptation. OurPyTorchre-implementationalreadyimproves
overtheoriginalsourcecode,withstrongerdataaugmentation[58]furtherimprovinggeneralizationfromsynthetictoreal
images.Eventually,theall-pairscorrelationvolumeallowstodecimatetheerrorswithrespecttotheoriginalmodel.
City Residential Campus(×2) Road All
D1-all EPE D1-all EPE D1-all EPE D1-all EPE D1-all EPE
Model Impl.details
(%) (px) (%) (px) (%) (px) (%) (px) (%) (px)
[41,55] 37.42 9.96 37.04 11.34 51.98 11.94 47.45 15.71 38.84 11.68
MADNet ours(PyTorch) 28.26 4.61 26.10 4.79 34.68 5.05 34.27 6.25 27.82 4.96
+augment. 11.51 1.75 9.25 1.63 10.63 1.88 15.47 1.90 10.53 1.69
MADNet2(ours) +costvolume 4.04 1.10 4.05 1.03 6.07 1.29 4.01 1.08 4.21 1.09
Table6.MADNet[55]vsMADNet2.ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI[17]asdefinedin[55].
7.2.FederatedAdaptation–ListeningClientonLow-PoweredHardware
Allofthefederatedexperimentscarriedoutinthemainpaperareperformedbyrunningbothactiveandlisteningclientson
3090GPUsforsimplicity.Accordingly,thelisteningclientrunsatamuchfasterinferencespeedwithrespecttotheadapting
clients,andthustherelativefrequencyoftheupdatesreceivedfromtheserverwillbemuchlower.
Thistranslatesintoalowerimprovementachievedbythelisteningclientwithrespecttowhatwouldhappeninarealuse-
case,i.e.,whenitrunsonalow-poweredplatformandisnotcapableofadaptingonitsown. Insuchacase,itsprocessing
speedwouldalsobemuchlower,withaconsequentincreaseoftherelativefrequencyofupdatesitreceives.
To confirm this hypothesis, we run an additional experiment on KITTI, by constraining the listening client to run at
lowerspeed(about10FPS).Tab.7recalls,ontop(a),theresultsobtainedinthemainpaperwithourfederatedadaptation
framework(Tab.2). Atthebottom(b),wereporttheresultsachievedinthislatterexperiment. Wecannoticehowtheerror
ratesachievedonmostsequencesarelowerwhenthelisteningclientrunsatalowerspeed,confirmingourhypothesis.
City Residential Campus(×2) Road
D1-all EPE D1-all EPE D1-all EPE D1-all EPE
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px)
FedFULL 1.42 0.89 1.22 0.80 3.93 1.14 1.12 0.80
FedMAD 1.48 0.90 1.29 0.81 4.05 1.17 1.16 0.82
MADNet2
FedFULL++ 1.38 0.94 1.12 0.81 3.45 1.10 1.11 0.85
FedMAD++ 1.46 0.95 1.20 0.83 3.55 1.11 1.19 0.87
(a)ListeningClientonhigh-endhardware
FedFULL 1.29 0.87 1.21 0.79 3.46 1.25 1.04 0.80
FedMAD 1.39 0.90 1.35 0.82 3.51 1.27 1.10 0.83
MADNet2
FedFULL++ 1.25 0.90 1.09 0.78 2.99 1.06 0.99 0.82
FedMAD++ 1.32 0.92 1.22 0.82 3.10 1.08 1.04 0.84
(b)ListeningClientonlow-poweredhardware
Table7.FederatedAdaptation–Impactofspeedbythelisteningclient.ResultsontheCity,Residential,Campus,andRoadsequences
fromKITTI[17].Performanceachievedbyalisteningclientrunningeitheron(a)high-endhardwareor(b)low-poweredplatforms.
2https://github.com/ivankreso/stereo-vision/tree/master/reconstruction/base/rSGM
27.3.ImpactofRandomnessonFederatedAdaptation
Theasynchronousnatureofourfederatedframeworkmakesitsusceptibletodifferent,randomfactors,someofthemeven
outofourcontrol. Indeed,whilewecanconstrainsomeofthesebyfixingtherandomseedinourexperiments–e.g.,the
sequencessampledbytheactiveclients,theblockssampledbyMADandFedMADheuristics,etc.–wecannotenforcethe
verysameconcurrentbehaviorforthethreadsrunningindependentlyinourexperiments.
WemeasuretheimpactofthesefactorsinTabs.8to10,respectivelyonKITTI,DrivingStereo,andDSECdatasets.Each
tablereportstwodistinctexperiments,consistingin(a)runningourfederatedframeworkfivetimeswithdifferentrandom
seeds,and(b)runningitfivetimesbyfixingtheverysameseed.Wereport,foreachsequence,themarginintermsofD1-all
andEPEbetweenthemaximumandtheminimummeasuredoverthefiveruns,with referringtomarginslowerthan0.01.
↓
Starting from Tab. 8, we can notice how the fluctuations on D1-all are lower than 0.1 in most sequences, even when
changingtheseed(a). TheonlyexceptionistheCampussequencewhichis,unsurprisingly,theshortestandhardest. When
fixingtherandomseedovermultipleruns(b),wecanstillobservesomelowerfluctuations,confirmingtheinfluenceofsome
factorsoverwhichwehavenocontrol–suchasthreadsscheduling,initialization,andconcurrencetoaccessresources.
ThesametrendcanbeobservedonTabs.9and10. Inparticular,asthesequencesfromDrivingStereoandDSECare
shorterandmorechallenging,theimpactofrandomnessisslightlyhigherwithrespecttowhatobservedonKITTI.
City Residential Campus(×2) Road
D1-all EPE D1-all EPE D1-all EPE D1-all EPE
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px)
FedFULL 0.02 0.01 0.01 0.01 0.38 0.04 0.04 0.03
FedMAD 0.02 0.01 0.02 0.01 0.51 0.09 0.05 0.03
MADNet2
FedFULL++ 0.05 0.02 0.02 0.01 0.17 0.03 0.05 0.02
FedMAD++ 0.07 0.02 0.04 0.02 0.26 0.06 0.04 0.02
(a)Differentrandomseeds
FedFULL 0.06 0.02
FedMAD 0.03↓ 0.01↓ ↓ ↓ 0.15 0.06 0.0↓1 0.0↓1
MADNet2 FedFULL++ ↓ ↓ 0.01 0.01
FedMAD++ 0.01↓ ↓ ↓ ↓ 0.21 0.04↓ 0.03 0.0↓1
↓ ↓ ↓
(b)Samerandomseeds
Table8. FederatedAdaptation–Impactofrandomness. ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI
[17].Wereportthemarginbetweenminandmaxerrorsoverfiveruns,eitherwhenfixing(a)differentrandomseedsor(b)thesameseed.
Rainy Cloudy Dusky
D1-all EPE D1-all EPE D1-all EPE
Model Adapt.mode
(%) (px) (%) (px) (%) (px)
FedFULL 0.08 0.01 0.27 0.03 0.70 0.03
FedMAD 0.32 0.05 0.20 0.03 1.00 0.09
MADNet2
FedFULL++ 0.02 0.11 0.08 0.65 0.08
FedMAD++ 0.32 0.07↓ 0.19 0.18 0.79 0.09
(a)Differentrandomseeds
FedFULL 0.15 0.04 0.03 0.16 0.02
FedMAD 0.35 0.07 0.15 0.0↓1 0.83 0.04
MADNet2
FedFULL++ 0.01 0.01 0.01
FedMAD++ 0.05↓ 0.02↓ 0.06 0.02 0.19 0.01↓
(b)Samerandomseeds
Table9.FederatedAdaptation–Impactofrandomness.ResultsontheRainy,Dusky,andCloudysequencesfromDrivingStereo[67].
Wereportthemarginbetweenminandmaxerrorsoverfiveruns,eitherwhenfixing(a)differentrandomseedsor(b)thesameseed.
Night#1 Night#2 Night#3 Night#4
D1-all EPE D1-all EPE D1-all EPE D1-all EPE
Model Adapt.mode
(%) (px) (%) (px) (%) (px) (%) (px)
FedFULL 0.10 0.02 0.07 0.02 0.01 0.01 0.10 0.01
FedMAD 0.26 0.03 0.21 0.03 0.15 0.01 0.05 0.01
MADNet2
FedFULL++ 0.01 0.01 0.01
FedMAD++ 0.04 0.01↓ 0.06 0.0↓1 0.03↓ ↓ 0.06 0.0↓1
↓
(a)Differentrandomseeds
FedFULL 0.05 0.01 0.07 0.01 0.06 0.01 0.04 0.01
FedMAD 0.16 0.01 0.13 0.02 0.14 0.01 0.17 0.01
MADNet2
FedFULL++ 0.01 0.01
FedMAD++ 0.05 0.01↓ 0.0↓6 0.0↓1 0.03↓ 0.0↓5 ↓
↓ ↓
(b)Samerandomseeds
Table10.FederatedAdaptation–Impactofrandomness.ResultsontheNight#1,Night#2,Night#3,andNight#4sequencesfromDSEC
[14].Wereportthemarginbetweenminandmaxerrorsoverfiveruns,eitherwhenfixing(a)differentrandomseedsor(b)thesameseed.
37.4.FederatedAdaptationwithOtherReal-TimeNetworks
Inthemainpaper,weshowcasedinTab.3howfederatedadaptation–andonlineadaptation,ingeneral–canbeimplemented
withother,real-timenetworkssuchasTemporalStereo[72],HITNet[52]andCoEX[3],reportingresultswithphotometric
loss[55]onlyduetothelackofspace. Forcompleteness,wecomplementthoseresultshere. Tab.11completesTab.3with
theresultsachievedbyusingproxylabels[41]ontheKITTIdataset,confirmingwhatalreadydiscussedinthemainpaper.
City Residential Campus(×2) Road DataTraffic Runtime
Model Adapt.mode D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) To (S Me Brv /e s)r To (MCl Bie /n s)t 3 (0 m9 s0 ) A (mGX s)
NoAdapt. 2.57 1.04 2.51 0.96 3.97 1.25 2.98 1.02 - - 19 177
CoEX[3] FULL++ 1.00 0.86 0.85 0.78 1.73 0.85 0.94 0.82 - - 75 1197
FedFULL++ 1.16 0.88 0.96 0.78 2.40 0.98 1.16 0.84 8.4 2.4 19 177
NoAdapt. 1.99 1.00 2.15 0.93 3.11 1.06 2.07 0.95 - - 36 404
HITNet[52] FULL++ 0.89 0.85 0.83 0.76 1.80 0.83 0.97 0.82 - - 105 1535
FedFULL++ 1.04 0.89 1.05 0.80 2.24 0.89 1.17 0.85 2.3 0.6 36 404
NoAdapt. 4.33 1.26 3.47 1.10 3.80 1.19 4.67 1.21 - - 42 7
TemporalStereo[72] FULL++ 1.04 0.86 0.90 0.77 1.86 0.85 0.88 0.81 - - 150 7
FedFULL++ 1.22 0.88 1.01 0.79 2.32 0.95 1.11 0.83 33.5 9.5 42 7
(b)Single-agentvsFederatedAdaptation–proxylabels[41]
Table11.Onlineadaptationbyfastnetworks(TemporalStereo[72],HITNet[52],CoEX[3])withinasingledomain–singleagent
vsfederatedadaptation.ResultsontheCity,Residential,Campus,andRoadsequencesfromKITTI[17].
Furthermore,Tabs.12and13completethisevaluationbyextendingittoDrivingStereo[67]andDSEC[14]datasets. In
general,adaptinganynetworkthroughFULL/FULL++oftenallowsforimprovingtheiraccuracyandachievingerrorrates
evenlowercomparedtoMADNet2.Nonetheless,noneofthethreemodelscanstandwiththislatterinefficiency.
Rainy Dusky Cloudy DataTraffic Runtime
Model Adapt.mode D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) To (S Me Brv /e sr ) To (MCl Bie /n s)t 3 (m09 s0 ) A (mG sX )
NoAdapt. 13.48 2.53 11.00 1.58 4.46 1.16 - - 16 130
CoEX[3] FULL 8.33 1.81 9.11 1.41 4.91 1.19 - - 65 1278
FedFULL 10.70 2.30 8.32 1.32 4.06 1.09 10.2 3.4 16 130
NoAdapt. 14.08 2.74 8.88 1.37 4.17 1.14 - - 29 311
HITNet[52] FULL 10.42 2.00 9.12 1.36 5.56 1.22 - - 88 1720
FedFULL 10.05 2.00 6.20 1.15 4.16 1.09 3.3 1.1 29 311
NoAdapt. 18.53 3.94 13.61 1.80 6.02 1.31 - - 33 7
TemporalStereo[72] FULL 11.51 1.95 9.15 1.39 5.98 1.24 - - 140 7
FedFULL 13.86 3.06 7.81 1.32 4.30 1.06 43.7 14.5 33 7
(a)Single-agentvsFederatedAdaptation–photometricloss[55]
NoAdapt. 13.48 2.53 11.00 1.58 4.46 1.16 - - 16 130
CoEX[3] FULL++ 9.96 2.48 4.80 1.05 3.34 1.14 - - 60 1192
FedFULL++ 8.52 1.77 6.18 1.15 2.78 0.93 11.4 3.8 16 130
NoAdapt. 14.08 2.74 8.88 1.37 4.17 1.14 - - 29 311
HITNet[52] FULL++ 10.27 2.33 3.62 0.96 4.99 1.59 - - 84 1623
FedFULL++ 8.00 1.79 3.57 0.94 3.57 1.06 3.7 1.2 29 311
NoAdapt. 18.53 3.94 13.61 1.80 6.02 1.31 - - 33 7
TemporalStereo[72] FULL++ 10.36 2.16 4.88 1.06 4.51 1.23 - - 130 7
FedFULL++ 12.94 2.88 6.49 1.20 3.82 1.00 47.8 10.9 33 7
(b)Single-agentvsFederatedAdaptation–proxylabels[41]
Table12. Onlineadaptationbyfastnetworks(TemporalStereo[72],HITNet[52],CoEX[3])onDrivingStereo[67]–singleagent
vsfederatedadaptation.ResultsontheRainy,DuskyandCloudysequencesasselectedin[41].
Night#1 Night#2 Night#3 Night#4 DataTraffic Runtime
Model Adapt.mode D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) D1 (- %al )l E (pP xE ) To (S Me Brv /e s)r To (MCl Bie /n s)t 3 (m09 s0 ) A (mG sX )
NoAdapt. 6.26 1.72 10.81 1.87 8.60 1.64 8.31 1.53 - - 53 539
CoEX[3] FULL 4.82 1.49 6.28 1.34 5.60 1.27 5.31 1.19 - - 225 2842
FedFULL 5.32 1.57 7.57 1.49 6.16 1.33 5.79 1.21 9.6 3.1 53 539
HITNet[52] AnyAdapt. OutofMemory
NoAdapt. 7.17 1.68 10.22 1.92 8.66 1.62 8.40 1.49 - - 118 7
TemporalStereo[72] FULL 5.77 1.39 9.74 1.57 8.68 1.45 9.38 1.44 - - 425 7
FedFULL 5.27 1.42 7.19 1.50 6.46 1.32 6.46 1.24 41.3 13.7 118 7
(a)Single-agentvsFederatedAdaptation–photometricloss[55]
NoAdapt. 6.26 1.72 10.81 1.87 8.60 1.64 8.31 1.53 - - 53 539
CoEX[3] FULL++ 4.06 1.20 5.79 1.28 4.96 1.19 4.93 1.14 - - 205 2776
FedFULL++ 4.92 1.39 7.01 1.41 5.65 1.28 5.45 1.19 10.9 3.5 53 539
HITNet[52] AnyAdapt. OutofMemory
NoAdapt. 7.17 1.68 10.22 1.92 8.66 1.62 8.40 1.49 - - 118 7
TemporalStereo[72] FULL++ 4.90 1.25 6.95 1.36 5.89 1.25 5.67 1.18 - - 380 7
FedFULL++ 5.38 1.38 7.05 1.42 6.05 1.30 5.96 1.22 46.1 15.1 118 7
(d)Single-agentvsFederatedAdaptation–proxylabels[41]
Table13. Onlineadaptationbyfastnetworks(TemporalStereo[72], HITNet[52], CoEX[3])onDSEC[14]–singleagentvs
federatedadaptation.ResultsontheNight#1,Night#2,Night#3andNight#4sequences.
ThisbecomesparticularlyevidentontheAGXboard: whenadaptingonDrivingStereowithFULL/FULL++(Tab.12),
CoEXandHITNetcannotreach1FPS,whileMADNet2canstillrunat2FPS,orevenfasterwithMAD/MAD++. Con-
sequently,leveragingfederatedadaptationistheonlywayforCoEXandHITNettokeepadecentframerate,respectively
about9and3FPS.Yet,MADNet2maintainsitssupremacybyrunningatmorethan20FPSinthesamesetting.
OnDSEC(Tab.13),thisgapbecomesevenlarger,withCoEXnotevenrunningat2FPSandHITNetrunningout-of-
memorywhentryingtocarryoutadaptation,whereasMADNetstillreachesnearly10FPS.
48.QualitativeResults
Weconcludewithsomequalitativeexamplesofdisparitymapspredictedbytheseveralmodelsinvolvedinourexperiments.
Figs.6and7reportstwoexamplesrespectivelyfromtheRoadandResidentialsequencesoftheKITTIdataset[17]. On
each,wereportdifferentdisparitymapsandthecorrespondingerrormaps(theselatteraredilatedtoeasevisualization).We
canappreciatehowstate-of-the-artmodels[24,30,63,65]alreadypredictveryaccurateresults,yetwiththehighruntime
highlightedinTab.1. Real-timemodelsstartfromslightlyhighererrorrateswhennotperformingadaptation. Nonetheless,
theycanreach(andevensurpass)theaccuracyofstate-of-the-artmodelseitherbyactivelyadaptingoverthesequenceitself
(FULL++)orbyleveragingfederatedoptimizationperformedbyotherclientsrunningondifferentsequences(FedFULL++).
Figs.8and9showsexamplesfromCloudyandRainysequencesinDrivingStereo[67]. There,state-of-the-artmodels
[24,30,63,65]achieveslightlyloweraccuracy,withreal-timenetworkseasilyoutperformingthemthroughadaptation.
Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
TemporalStereo[72] HITNet[52]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure6.Qualitativeresults–KITTIdataset[17],Roadsequence.
Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
TemporalStereo[72] HITNet[52]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure7.Qualitativeresults–KITTIdataset[17],Residentialsequence.
5Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
TemporalStereo[72] HITNet[52]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure8.Qualitativeresults–DrivingStereodataset[67],Cloudysequence.
Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
TemporalStereo[72] HITNet[52]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure9.Qualitativeresults–DrivingStereodataset[67],Rainysequence.
6Finally,Figs.10and11reportsqualitativeexamplesfromNight#2andNight#4sequencesinDSEC[14].Onthisdataset,
state-of-the-artmodels[24,30,63,65]struggleseverely–inparticularonNight#2sequence–becauseofthesensiblyhigher
noiseintheimagesduetothepoorillumination.Again,onlineadaptationallowsreal-timemodelstoimprovetheiraccuracy
on-the-flyandtorecoverdetailssuchastrafficsignalsthatwerelostbytheoriginalmodelnotperforminganyadaptation.
ItisalsoworthinghowthequalityofproxylabelsusedbyFULL++andFedFULL++isinevitablyloweronthesescenes,
yieldingsomeartifactstoappearinthepredictionsbytheadaptedmodels–e.g.atthebottomleft.
Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure10.Qualitativeresults–DSECdataset[14],Night#2sequence.
Images RAFT-Stereo CREStereo[24] IGEV-Stereo[63] UniMatch[65]
MADNet2 CoEX[3]
NoAdapt. FULL++ FedFULL++ NoAdapt. FULL++ FedFULL++
Figure11.Qualitativeresults–DSECdataset[14],Night#4sequence.
7