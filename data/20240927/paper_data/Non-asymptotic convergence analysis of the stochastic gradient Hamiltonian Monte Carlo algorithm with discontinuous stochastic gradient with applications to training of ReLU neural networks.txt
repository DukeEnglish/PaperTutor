NON-ASYMPTOTIC CONVERGENCE ANALYSIS OF
THE STOCHASTIC GRADIENT HAMILTONIAN MONTE CARLO ALGORITHM
WITH DISCONTINUOUS STOCHASTIC GRADIENT
WITH APPLICATIONS TO TRAINING OF RELU NEURAL NETWORKS
LUXULIANG,ARIELNEUFELD,ANDYINGZHANG
ABSTRACT. Inthispaper,weprovideanon-asymptoticanalysisoftheconvergenceofthestochasticgradi-
entHamiltonianMonteCarlo(SGHMC)algorithmtoatargetmeasureinWasserstein-1andWasserstein-2
distance.Crucially,comparedtotheexistingliteratureonSGHMC,weallowitsstochasticgradienttobe
discontinuous.Thisallowsustoprovideexplicitupperbounds,whichcanbecontrolledtobearbitrarily
small,fortheexpectedexcessriskofnon-convexstochasticoptimizationproblemswithdiscontinuous
stochasticgradients,including,amongothers,thetrainingofneuralnetworkswithReLUactivationfunction.
Toillustratetheapplicabilityofourmainresults,weconsidernumericalexperimentsonquantileestimation
andonseveraloptimizationproblemsinvolvingReLUneuralnetworksrelevantinfinanceandartificial
intelligence.
1. INTRODUCTION
Inthispaper,weconsiderthenonconvexstochasticoptimizationproblem
minimize Rd ∋ θ (cid:55)→ u(θ) := E [U(θ,X)], (1)
X∼D
whereU : Rd ×Rm → RisameasurablefunctionandX isanm-dimensionalrandomvariablewith
someknownprobabilitydistributionD. Givenasetofobservations,ourgoalistoconstructanestimator
θˆ
suchthattheexpectedexcessriskgivenby
E[u(θˆ)]− inf u(θ)
θ∈Rd
isminimized. Itiswellknownthatcomputinganapproximateglobalminimizerofuiscloselylinked
to sampling from the distribution π (dθ) ∝ exp(−βu(θ))dθ which concentrates around the global
β
minimizersofuforsufficientlylargeβ,see[25]. Thus,theoptimizationproblem(1)canbeconvertedto
theproblemofsamplingfromπ .
β
Asπ istheuniqueinvariantmeasureoftheLangevinstochasticdifferentialequation(SDE)givenby
β
(cid:112)
Z = θ , dZ = −h(Z )dt+ 2β−1dB , t ∈ R , (2)
0 0 t t t +
whereθ isanRd-valuedrandomvariable,h := ∇u,β > 0istheso-calledinversetemperatureparameter,
0
and {B } is a d-dimensional Brownian motion, sampling from π can be achieved by employing
t t≥0 β
numericalalgorithmsthattrack(2),see[25]. Oneofthewidelyusedmethodisthestochasticgradient
Langevindynamics(SGLD)algorithmgivenby
θSGLD := θ , θSGLD = θSGLD−ηH(cid:0) θSGLD,X (cid:1) +(cid:112) 2ηβ−1ξ ,
0 0 n+1 n n n+1 n+1
whereη > 0isthestepsize,(X ) isthedatasequencebeingi.i.d.copiesofX,H isanunbiased
n n∈N
0
estimatorofh,i.e.,h(θ) = E[H(θ,X )]foranyθ ∈ Rd,calledstochasticgradientofu,and{ξ }
0 n n∈N
0
is a sequence of i.i.d. standard Gaussian random variables in Rd. Recently, this method has been
popularinnonconvexoptimizationandBayesianinferencewithwell-establishedconvergenceresults,
see,e.g.,[4,8,11,19,24,29,35,36,40,48,52,54]andreferencestherein.
In this paper, we focus on an alternative method to tackle the problem of sampling from π . We
β
considerthesecond-order(underdamped)LangevinSDEgivenby
(cid:112)
dV = −γV dt−h(θ )dt+ 2γβ−1dB ,
t t t t
(3)
dθ = V dt,
t t
FinancialsupportsbytheMOEAcRFTier2GrantMOE-T2EP20222-0013andtheGuangzhou-HKUST(GZ)JointFunding
Program(No.2024A03J0630)aregratefullyacknowledged.
1
4202
peS
52
]CO.htam[
1v70171.9042:viXra2 L.LIANG,A.NEUFELD,ANDY.ZHANG
where(θ ,V ) arecalledthepositionandmomentumprocess,respectively,andγ > 0isthefriction
t t t∈R
+
coefficient. Undersuitableassumptions,SDE(3)admitsauniqueinvariantmeasure(see,e.g.[38])
(cid:18) (cid:18) (cid:19)(cid:19)
1
π¯ (θ,v) ∝ exp −β u(θ)+ |v|2 . (4)
β
2
Wenotethatthemarginaldistributionof(4)inθisexactlythetargetmeasureπ ,thus,samplingfrom(4)
β
in the extended space while only considering the samples from the first coordinate (i.e., from θ) is
equivalenttosamplingfromπ . WeconsiderthestochasticgradientHamiltonianMonteCarlo(SGHMC)
β
algorithmgivenby
Vη := V , Vη = Vη −η[γVη +H(θη,X )]+(cid:112) 2γηβ−1ξ ,
0 0 n+1 n n n n+1 n+1 (5)
θη := θ , θη = θη +ηVη,
0 0 n+1 n n
where η > 0 is the step size. Note that while SGLD can be viewed as the analogue of the stochastic
gradientinMarkovChainMonteCarlo(MCMC)literatures,SGHMCcanbeviewedastheanalogueof
stochasticgradientmethodsaugmentedwithmomentum. Severalnumericalstudieshavedemonstrated
that SGHMC algorithm is superior over SGLD algorithm in term of robust updates w.r.t. gradient
estimation noise, see, e.g., [10, 31, 47]. Theoretical results for the SGHMC algorithm (5) have been
establishedundertheconditionthatthestochasticgradientisassumedtobe(locally)Lipschitzcontinuous,
see,e.g.[1,6,21]. However,theseassumptionsfailtoaccommodatediscontinuousstochasticgradients
used in practice, such as the signed regressor, signed error, sign-sign algorithms, and optimization
problems involving neural networks with ReLU activation function, see, e.g., [17, 18, 30]. To tackle
theseproblems,weconsiderthecasewhereH isdiscontinuousandonlysatisfiesacertaincontinuityin
averagecondition(seeAssumption3below). Wethenprovidenon-asymptoticresultsinWasserstein-1
andWasserstein-2distancebetweenthelawofthen-thiterateoftheSGHMCalgorithmandthetarget
distributionπ¯ . Thisfurtherallowsustoprovideanon-asymptoticupperboundfortheexpectedexcess
β
riskoftheassociatedoptimizationproblem(1).
To illustrate the applicability of our results, we present three key examples in statistical machine
learning,namely,quantileestimation,optimizationinvolvingReLUneuralnetworks,andhedgingunder
asymmetric risk, where each of the corresponding functions H are discontinuous. Numerical results
supportourtheoreticalfindingsanddemonstratethesuperiorityoftheSGHMCalgorithmoveritsSGLD
counterpart,whichalignwiththefindingsof[9,10,47].
Weconcludethissectionbyintroducingsomenotations. For1 ≤ p < ∞,Lp isusedtodenotethe
usualspaceofp-integrablereal-valuedrandomvariables. Foranintegerd ≥ 1,theBorelsigma-algebra
ofRd isdenotedbyB(cid:0)Rd(cid:1) . Wealsodenoteallnon-negativerealnumbersbyR . Forapositivereal
+
number a, we denote by ⌊a⌋ its integer part, and define ⌈a⌉ := ⌊a⌋+1. For any matrix M ∈ Rp×p,
denotebydiag(M) := (M ,...,M )thevectorofthediagonalelementsofM,anddenotebyM⊤
11 pp
its transpose. Denote by I the p×p identity matrix. We denote the dot product by ⟨·,·⟩ while |·|
p
denotestheassociatednorm.
Thesetofprobabilitymeasuresdefinedonspace(cid:0)Rd,B(cid:0)Rd(cid:1)(cid:1)
isdenoted
by P(cid:0)Rd(cid:1) . For an Rd-valued random variable X, L(X) and E[X] are used to denote its law and its
expectationrespectively. WedenotebyN thenon-negativeintegersincludingzero. Forµ,ν ∈ P(cid:0)Rd(cid:1) ,
0
letC(µ,ν)denotethesetofprobabilitymeasuresΓonB(cid:0)R2d(cid:1)
suchthatitsmarginalsareµ,ν. Finally,
foranyp ≥ 1,wedenotebyP
(cid:0)Rd(cid:1) theprobabilitymeasureinP(cid:0)Rd(cid:1)
withp-thfinitemoments. For
p
anyp ≥ 1,µ,ν ∈ P
(cid:0)Rd(cid:1)
,wedenotetheWassersteindistanceoforderp ≥ 1
p
(cid:18)(cid:90) (cid:90) (cid:19)1/p
W p(µ,ν) := inf
(cid:12) (cid:12)θ−θ′(cid:12) (cid:12)p Γ(cid:0) dθ,dθ′(cid:1)
.
Γ∈C(µ,ν) Rd Rd
2. SETTING AND ASSUMPTIONS
2.1. Setting. Let U : Rd ×Rm → R be a Borel measurable function, and let X be an Rm-valued
+
random variable defined on the probability space (Ω,F,P) with probability law L(X) satisfying
E[|U(θ,X)|] < ∞forallθ ∈ Rd. Weassumethatu : Rd → Rdefinedbyu(θ) := E[U(θ,X)],θ ∈ Rd,
isacontinuouslydifferentiablefunction,anddenotebyh := ∇uitsgradient. Inaddition,foranyβ > 0,
wedefine
e−βu(θ)
π (dθ) := dθ, (6)
β (cid:82)
e−βu(θ)dθ
Rd3
where we assume (cid:82) Rde−βu(θ)dθ < ∞. Deno (cid:83)te by (G n) n∈N
0
a given filtration representing the flow
of past information, and denote by G ∞ := σ( n∈N 0G n). Moreover, let (X n) n∈N 0 be a (G n)-adapted
process such that (X n) n∈N
0
is a sequence of i.i.d. Rm-valued random variables with probability law
L(X)andlet(ξ ) beasequenceofindependentstandardd-dimensionalGaussianrandomvariables.
n n∈N
0
Inthispaper,weconsidertheSGHMCalgorithmgivenby
Vη := V , Vη = Vη −η[γVη +H(θη,X )]+(cid:112) 2γηβ−1ξ , (7)
0 0 n+1 n n n n+1 n+1
θη := θ , θη = θη +ηVη, (8)
0 0 n+1 n n
whereη > 0isthestep-size,γ > 0isthefrictioncoefficient,β > 0istheinversetemperatureparameter,
andE[H(θ,X )] = h(θ)foreveryθ ∈ Rd. WeassumethroughoutthepaperthattheRd-valuedrandom
0
variablesθ 0, (cid:104)V 0 (in (cid:105)itialco (cid:104)nditio (cid:105)n),G ∞,and(ξ n) n∈N 0 areindependent. Moreover,weassumethatθ 0 and
V satisfyE |θ |4 +E |V |4 < ∞.
0 0 0
2.2. Assumptions.
Assumption1. ThefunctionH : Rd×Rm → Rd takestheformof
H(θ,x) = F(θ,x)+G(θ,x),
where
(i) F : Rd × Rm → Rd satisfies that there exist L ,L > 0 and ρ > 0 such that for any
1 2
(θ,x),(θ′,x′) ∈ Rd×Rm,
|F(θ,x)−F(θ′,x′)| ≤ (1+|x|+|x′|)ρ(L |θ−θ′|+L |x−x′|).
1 2
(ii) G : Rd ×Rm → Rd is measurable and bounded in θ, i.e., there exist a measurable function
K¯ : Rm → (0,∞)suchthatforany(θ,x) ∈ Rd×Rm,
1
|G(θ,x)| ≤ K¯ (x).
1
Remark2.1. ByAssumption1,wehave
|H(θ,x)| ≤ (1+|x|)ρ+1(L |θ|+L )+F (x),
1 2 ∗
whereF (x) := 2|K¯ (0)|+|K¯ (x)|+|F(0,0)|.
∗ 1 1
Assumption 2. The process {X } is i.i.d. with E(cid:2) |X |4(ρ+1)(cid:3) < ∞ and E(cid:2) |K¯ (X )|2(cid:3) < ∞,
n n∈N
0
0 1 0
whereρ > 0andK¯ : Rm → (0,∞)isintroducedinAssumption1.
1
Assumption3. ThereexistsapositiveconstantL > 0suchthat,forallθ,θ′ ∈ Rd,
E(cid:2) |H(θ,X )−H(θ′,X )|(cid:3) ≤ L|θ−θ′|.
0 0
Remark2.2. ByAssumption3,wehave
|h(θ)−h(θ′)| ≤ L|θ−θ′|,
whichimplies,byletingθ′ = 0,that
|h(θ)| ≤ L|θ|+|h(0)|.
Assumption 4. There exist measurable functions A : Rm → Rd×d and B : Rm → R such that the
followinghold: forany(θ,x) ∈ Rd×Rm,
(i) ⟨θ,A(x)θ⟩ ≥ 0and⟨F(θ,x),θ⟩ ≥ ⟨θ,A(x)θ⟩−B(x),
(ii) ThesmallesteigenvalueofE[|A(X )|]isapositiverealnumbera > 0andE[|B(X )|] = b ≥ 0.
0 0
Remark2.3. ByAssumption1,2,and4,wehave
⟨h(θ),θ⟩ ≥ a′|θ|2−b′,
wherea′ := a,b′ := b+ 1 E(cid:2) |K¯ (X )|2(cid:3) .
2 2a 1 04 L.LIANG,A.NEUFELD,ANDY.ZHANG
Remark2.4. ByRemark2.2and2.3,foranyθ ∈ Rd,weobtain,
γ2
⟨h(θ),θ⟩ ≥ 2λ(u(θ)+ |θ|2)−2A /β,
c
4
(cid:26) (cid:27)
whereA := β(2λu(0)+2λL|h(0)|+b′)andλ := min 1, a′ .
c 2 4 L+2L|h(0)|+γ2
2
DetailedproofsoftheremarksinthissectioncanbefoundinAppendixA.
3. MAIN RESULTS AND OVERVIEW
Wefirstdefine
(cid:26) (cid:27)
2 γλ K λγ
3
η := min 1, , , , > 0, (9)
max γ 2K
1
K
2
2K˜
whereγ isintroducedintheSGHMCalgorithm(7)-(8),λisdefinedinRemark2.4,theconstantsK ,
1
K ,andK areexplicitlygivenin(55),(56),and(57)whereasK˜ isexplicitlygivenin(74).
2 3
Then,undertheassumptionspresentedinSection2.2,weobtainthefollowingnon-asymptoticupper
boundinWasserstein-2distance.
Theorem3.1. LetAssumption1-4hold. Then,foranyβ > 0,thereexistconstantsC⋆,C⋆,C⋆,C⋆ > 0
1 2 3 4
suchthat,foreveryn ∈ N ,0 < η ≤ η withη definedin(9),weobtain
0 max max
(cid:16) (cid:17)
W
2
L(θ nη,V nη),π¯
β
≤ C 1⋆η1/2+C 2⋆η1/4+C 3⋆e−C 4⋆ηn,
whereC⋆,C⋆,C⋆,andC⋆ aremadeexplicitandaresummarizedinTable1.
1 2 3 4
Inparticular,foranyϵ > 0,ifwechooseη ≤
min(cid:110) ϵ2
,
ϵ4
,η
(cid:111)
andn ≥
ln(3C 3⋆/ϵ)
,
thenweobtainW (L(θη,Vη),π¯ ) ≤ ϵ.
9C 1⋆2 81C 2⋆4 max C 4⋆min(cid:26) 9Cϵ2 1⋆2, 81ϵ C4 2⋆4,ηmax(cid:27)
2 n n β
Also,ananalogousresultinWasserstein-1distancecanbeobtained.
Corollary3.2. LetAssumption1-4hold. Then,foranyβ > 0,thereexistconstantsC∗,C∗,C∗ > 0such
1 2 3
that,foreveryn ∈ N ,0 < η ≤ η withη definedin(9),weobtain
0 max max
(cid:16) (cid:17)
W
1
L(θ nη,V nη),π¯
β
≤ C 1∗η1/2+C 2∗e−C 3∗ηn,
whereC∗,C∗,andC∗ aremadeexplicitandaresummarizedinTable1.
1 2 3
(cid:26) (cid:27)
Inparticular,foranyϵ > 0,ifwechooseη ≤
min(cid:110) ϵ2
,η
(cid:111)
andn ≥ max
4C 1∗2ln(2C 2∗/ϵ)
,
ln(2C 2∗/ϵ)
,
4C 1∗2 max ϵ2C 3∗ C 3∗ηmax
thenweobtainW
(cid:0) L(cid:0) θ¯η,V¯η(cid:1)
,π¯
(cid:1)
≤ ϵ.
1 n n β
ByusingtheconvergenceresultinWasserstein-2distanceaspresentedinTheorem3.1,wecanobtain
anupperboundfortheexpectedexcessriskE[u(θη)]−inf u(θ).
n θ∈Rd
Theorem3.3. LetAssumption1-4hold. Then,foranyβ > 0,thereexistconstantsC¯⋆,C¯⋆,C¯⋆,C¯⋆ > 0
1 2 3 4
suchthat,foreveryn ∈ N ,0 < η ≤ η withη definedin(9),weobtain
0 max max
(cid:18) (cid:18) (cid:19)(cid:19)
d 8eL A
E[u(θη)]− inf u(θ) ≤ C¯⋆η1/2+C¯⋆η1/4+C¯⋆e−C¯ 4⋆ηn+ log c +1 ,
n θ∈Rd 1 2 3 2β γ2λ(1−2λ) d
whereC¯⋆,C¯⋆,C¯⋆,andC¯⋆ aregiveninTable1.
1 2 3 4
(cid:110) (cid:16) (cid:16) (cid:17)(cid:17)(cid:111)
Inparticular,foranyϵ > 0,ifwefirstchooseβ ≥ max 16d2 , 4d log 8eL λu(0)+λL|h(0)|+b′/2 +1 ,
ϵ2 ϵ γ2λ(1−2λ) d
then choose η ≤
min(cid:110) ϵ2
,
ϵ4
,η
(cid:111)
and n ≥
ln(4C¯ 3⋆/ϵ)
, then we obtain
E[u(θη)]−inf
u(θ)1 ≤6C¯ ϵ1⋆ .2 256C¯ 2⋆4 max C¯ 4⋆min(cid:26) 16ϵ C¯2 1⋆2, 256ϵ C4
¯
2⋆4,ηmax(cid:27)
n θ∈Rd5
3.1. Related papers and discussion. In this section, we compare our work with the most related
ones[1,6,21].
In [21], the authors provide a non-asymptotic upper bound in Wasserstein-2 distance between the
law of the SGHMC algorithm (7)-(8) and of the underdamped Langevin SDE (26) being O(cid:0) (δ1/4 +
η1/4)(nη)3/2(cid:112) log(nη)+(nη)√ η(cid:1)
,whereδ > 0isthegradientnoiselevelindependentofthestepsize
andnisthenumberofiterations.[6]improvedtheupperboundforSGHMCin[21]significantlytoan
order of
O(cid:0) δ1/4+η1/4(cid:1)
in the sense that it does not depend on the number of iterations. The results
in[6]and[21]areobtainedunderthesamesetofassumptions[21,Assumptioni-v].[21,Assumption
ii] assumes that H is (global) Lipschitz continuous in θ uniformly with respect to x. In our case, in
Assumption1,wesplitH intotwoparts,i.e.,H = F+G,whereF isjointlylocallyLipschitzcontinuous
and G is only required to be measurable, without assuming any continuity assumption. In particular,
we do not impose H to be continuous. Instead, we only assume H to satisfy a continuity in average
conditionsoastoallowdiscontinuousH inAssumption3. ByallowingH tobediscontinuous,wecan
coverimportantoptimizationproblemsinvolvingneuralnetworkswithReLUactivationfunctionaswell
as quantile estimation. [21, Assumption iii] assume the dissipativity assumption (which comes from
thetheoryofdynamicalsystems,see[43])whereasweimposeaweakerlocaldissipativityconditionin
Assumption4toallowthedependenceonthedatastream. Inaddition,[21,Assumptionv]requiresthe
finitenessofanexponentialmomentoftheinitialvalue,whilewerequireonlypolynomialmomentsof
theinitialvalueinAssumption2.
Wehighlightthat,under[6,21,Assumptioni-v],theauthorsobtainnon-asymptoticupperboundsthat
cannotbemadetovanishbyselectinganarbitrarilysmallstepsizeη > 0,sinceδ > 0ispredefinedand
independentofη. However,underourAssumptions1-4,ournon-asymptoticconvergenceboundscanbe
madearbitrarilysmallbychoosingappropriateparameters.
Wenowcompareourworkwith[1].[1]providesconvergenceresultsinWasserstein-2distanceunder
the assumptions [1, Assumption 2.1-2.4]. In [1, Assumption 2.1, 2.2], the authors assume that the
stochastic gradients are unbiased with finite moments which are the same as our Assumption 2. [1,
Assumption2.3]statesalocalLipschitzconditionofH inxandaglobalLipschitzconditioninθ,while
wesplitH intotwopartsF andGinAssumption1. Moreprecisely,weassumeF beingjointlylocal
LipschitzcontinuousandGonlybeingboundedinθ withoutrequiringittobecontinuous. Furthermore,
weonlyassumeacontinuityinaverageconditionofH inAssumption3,whichallowsfordiscontinuous
H. In [1, Assumption 2.4], authors assume a local dissipativity condition whereas we have similar
assumption in Assumption 4. Under our Assumptions 1-4, we obtain similar convergence results as
thoseof[1]withthesameratesofconvergenceinWassersteindistance. However,wehighlightthatour
resultsareapplicabletooptimizationproblemswithdiscontinuousstochasticgradients,whichcannotbe
coveredbytheresultsin[1].
Finally,wecommentonourAssumption3. Assumption3issimilarto[7,Eq.(6)]and[20,42],which
allows for discontinuous H. However, we note that the analysis of the SGHMC algorithm involves
studyingtheunderdampedLangevindiffusionanditsassociateddiscretetimeschemeonR2d, which
necessitatestheuseofdifferenttechniquescomparedtothoseemployedin[20,42].6 L.LIANG,A.NEUFELD,ANDY.ZHANG
noisnemidnoecnednepeD
noisserpxelluF
tnatsnoC
(cid:17)
d1−βγ6+(cid:3)
)0X(2
∗F(cid:2)E21+(cid:1)2
2L2+2
1L
θC(cid:0)(cid:105)
)1+ρ(2)|0X|+1((cid:104)
E6+vC2γ3(cid:16)2γ4e4(cid:18)
(cid:1)2/1d(cid:0)
O
(cid:17)(cid:105)
2|]0X[E−0X|ρ2)|]0X[E|+|0X|+1((cid:104)
E(cid:16)
2 2L8(cid:18)(cid:17)2γ4e42+4(cid:16)
+
⋆ 1C
2γ+2/2L2γ4e4e2/1(cid:19)(cid:19)
(cid:1)(cid:3)
)]0X[E(2
1K¯
+)0X(2
1K¯(cid:2)E(cid:0)
61+
(cid:1))d(Oe4/5d(cid:0)
O
(cid:19)2/1(cid:17)(cid:111)
1−
2c1−γ1−β)cA+d((cid:1)2
cα2+cα2+1(cid:0)
}1R,11
{nim4,1(cid:110)
xam(cid:16)
}cαγ
,1+ {1
nim2/cΛ+1e2/12(cid:18)
⋆C
1.3meroehT
2
(cid:1) V′Ccε+VCcε+1(cid:0)⋆
1C(cid:113)1−(cid:17)
2/xamη⋆
4C−e−1(cid:16)
}1−γ,cα+1{xam3(cid:112)
×
(cid:1))d(Oe(cid:0)
O
(cid:1)
βπ¯,0µ(cid:0)
ρW(cid:113)2/1(cid:19)(cid:27)
)cA
c˙+ γβd(
}) 12 c Rα
,2 1+ {nα
i2 m+1(
4,1(cid:26)
xam(cid:18)
2/c
}Λ
c+ α1 ,e 1)
{γ n+
im1(2√
⋆ 3C
(cid:1))d(O−e2/1d(cid:0)
O
(cid:111)
cΛ−e2/1
cΛ,2−γLcΛ−e2/1
cΛ,2−γLλ(cid:110)
nim
86γ
7
⋆ 4C
(cid:1))d(Oe2/1d(cid:0)
O
(cid:41)
1−
1c1−γ1−β)cA+d((cid:1)2
cα2+cα2+1(cid:0)(cid:111)
}1 1− 1 RR
,, 11 {(cid:110)
nx imam
4,1(cid:40)
xam
}cαγ
,1+
{1 nimcΛ+2e⋆
1C6+⋆
1C
∗C 1
(cid:1)(cid:1)
V′C+VC(cid:0)
cε+1(cid:0)1−(cid:19)
2/xamη(cid:17)(cid:111)
cΛ−e2/1
cΛ,2−γLcΛ−e2/1
cΛ,2−γLcλ(cid:110)
nim
48γ 3(cid:16)
−
e−1(cid:18)
(cid:9)1−γ,cα+1(cid:8)
xam×
2.3yralloroC
(cid:1))d(Oe(cid:0)
O
(cid:1)
βπ¯,0µ(cid:0)
ρW(cid:19)(cid:41)
1−
1c1−γ1−β)cA+d((cid:1)2
cα2+cα2+1(cid:0)(cid:111)
}1 1− 1 RR
,, 11 {(cid:110)
nx imam
4,1(cid:40)
xam
}cαγ
,1+
{1
nimcΛ+2e2(cid:18)
∗ 2C
(cid:1))d(O−e2/1d(cid:0)
O
(cid:111) cΛ−e2/1
cΛ,2−γLcΛ−e2/1
cΛ,2−γLcλ(cid:110)
nim
48γ
3
∗ 3C
(cid:1)2/3d(cid:0)
O
⋆C(cid:1)
|)0(h|+(cid:9)
C,cC(cid:8)
xamL(cid:0)
⋆¯C
1
θ
θ
1
(cid:1))d(Oe4/9d(cid:0)
O
⋆C(cid:1)
|)0(h|+(cid:9)
C,cC(cid:8)
xamL(cid:0)
⋆¯C
2
θ
θ
2
3.3meroehT
(cid:1))d(Oe(cid:0)
O
⋆C(cid:1)
|)0(h|+(cid:9)
C,cC(cid:8)
xamL(cid:0)
⋆¯C
3
θ
θ
3
(cid:1))d(O−e2/1d(cid:0)
O
(cid:111)
cΛ−e2/1
cΛ,2−γLcΛ−e2/1
cΛ,2−γLλ(cid:110)
nim
86γ
7
⋆ 4¯C
3.3meroehTdna,2.3yralloroC,1.3meroehTnistnatsnocehtfosnoisserpxeticilpxE
.1
ELBAT7
4. APPLICATIONS
Inthissection,weapplytheSGHMCalgorithmtogetherwithourtheoreticalresultstoseveralproblems
relevantinpractice,includingquantileestimationandregularizedoptimizationproblemsinvolvingneural
networksinordertoillustratetheconvergencepropertiesandwideapplicabilityoftheSGHMCalgorithm
foroptimizationproblemswithdiscontinuousstochasticgradient. InSection4.1,weapplytheSGHMC
algorithmtoquantileestimation,coveringtheGaussiandistribution,logisticdistribution,andGumbel
distribution. Then, inSection4.2, weapplytheSGHMCalgorithmtotrainReLUneuralnetworksin
ordertosolvecertainregularizedoptimizationproblems. First,in4.2.1,weprovideanexampleinvolving
theuseofatwo-hidden-layerfeedforwardneuralnetworkinthetransferlearningsetting,where(partof)
itsweightandbiasparametersaresourcedfromapre-trainedmodel. Transferlearningistheimprovement
of learning in a new task through the transfer of knowledge from a related task that has already been
learned,whichiswidelyemployedespeciallyinthenetwork-basedtasks,see,e.g.,[23]andreferences
therein. Moreover,inSection4.2.2,weapplytheSGHMCalgorithmtosolvetheproblemofhedging
underasymmetricrisk,wheretheSGHMCisusedtotraintheneuralnetworks. Datasetsaregenerated
fromthediscrete-timeversionofthemultidimensionalBlack-Scholes-Merton(BSM)model. Wefurther
conduct numerical experiments on regression and classification problems on real-world datasets, see
Section4.2.3. Crucially,weshowthatthequantileestimationandoptimizationprobleminthetransfer
learning setting satisfy our Assumptions 1-4, hence Theorem 3.3 provides a theoretical guarantee for
SGHMCtosolvetheoptimizationproblemsunderconsideration. Furthermore,byprovidingcomparisons
of SGHMC with other optimizers including SGLD, TUSLA, ADAM, AMSGrad, and RMSProp, we
demonstratenumericallythesuperiorperformanceoftheSGHMCalgorithm. ThePythoncodeforallthe
experimentsinthispaperisavailableathttps://github.com/LuxLiang/SGHMC discontinuous.
4.1. QuantileEstimationwithL2-Regularization. Quantilesarefrequentlyusedtoassessriskinawide
rangeofapplicationareas,suchasfinance,nuclearengineering,andserviceindustries(see[2,13,26,49]
andreferencestherein). Inthisexample,ourgoalistoidentifythequantileq ∈ (0,1)ofagivenrandom
variable under certain distributions, which is also studied in [3, 16, 20]. To this end, we consider the
followingL2-regularizedoptimizationproblem:
minimize Rd ∋ θ (cid:55)→ u(θ) := E[l (X −θ)]+λ |θ|2, (10)
q r
where X is the input random variable, θ ∈ Rd is the parameter to be optimized, λ is a positive
r
regularizationconstant,and
l (s) := (q−1 )s, s ∈ R,
q {s<0}
with0 < q < 1. Then,forany(θ,x) ∈ R×R,wedefineH(θ,x) := G(θ,x)+F(θ,x)with
F(θ,x) := 2λ θ, G(θ,x) := −q+1 . (11)
r {x<θ}
Proposition4.1. AssumethatX hasboundeddensitywithrespecttotheLebesguemeasureonRand
has finite fourth moment. Then, the optimization problem (10) with its associated stochastic gradient
definedin(11)satisfiesAssumptions1-4.
Proof. SeeAppendixD. □
Therefore, by using Theorem 3.3, we can, for any given precision level ϵ > 0, construct an estimator
usingtheSGHMCalgorithm,whichminimizesthecorrespondingexpectedexcessrisk.
Forthenumericalexperiments,weestimatequantilesforseveraltargetdistributions,includingGuassian
distribution N (µ,σ), Logistic distribution L(α,β), and Gumbel distribution G(µ,β) with respect to
correspondingparameters(µ,σ),(α,β),and(µ,β). Wenotethatthetrueq-quantilevaluesforLogistic
andGumbeldistributionsareα+βlog q andµ−βln(−lnq),respectively,whichweusetoobtain
(1−q)
theoptimalvaluesforthecomparisonwithournumericalresults. ThesetruevaluesarerecordedasQ∗
in Table 2. For initialization, we set θ ∼ N (0,1),v ∼ N (0,1), β = 1010, γ = 0.5, λ = 10−5,
0 0 r
η = 10−3 (satisfying the step restriction given in (9)). The experiments are run using 5 different
seeds that control the randomness of initialization and sampling. In Figure 1, by taking Logistic
distribution (α = 0,β = 1) as an example, solid lines in the left graph show the mean of the path of
E[u(θ )]−inf u(θ)withq = 0.95, whilethe shadedregionsindicate therange over the random
n θ∈Rd
seeds. Moreover,thereferencelineintherightgraphhasaslopeof0.5andthedashedlineshowsthat
the rate of convergence of the SGHMC algorithm is 0.594, which aligns with our theoretical results.8 L.LIANG,A.NEUFELD,ANDY.ZHANG
FIGURE 1. Expectedexcessriskoftheoptimizationproblem(10)byusingSGHMC
andSGLDalgorithm(left)andtherateofconvergenceoftheSGHMCalgorithmbased
on100000samples(right).
q=0.95 q=0.99
Q∗ Q Q T T Q∗ Q Q T T
SGHMC SGLD SGHMC SGLD SGHMC SGLD SGHMC SGLD
0.654 0.639 1.311 1.265
N(µ=−1,σ=1) 0.645 0.079s 0.111s 1.326 0.078s 0.372s
(0.007) (0.010) (0.010) (0.018)
4.329 4.235 5.529 5.525
N(µ=1,σ=2) 4.290 0.695s 1.848s 5.653 1.830s 5.011s
(0.050) (0.060) (0.125) (0.240)
11.137 11.127 14.379 14.379
N(µ=3,σ=5) 11.224 2.209s 5.316s 14.632 6.828s 15.769s
(0.730) (1.300) (1.960) (3.000)
2.969 2.883 4.454 4.455
L(α=0,β=1) 2.944 0.584s 1.817s 4.595 2.497s 6.134s
(0.026) (0.040) (0.107) (0.236)
1.907 1.766 3.454 3.455
L(α=−1,β=1) 1.944 0.432s 1.766s 3.595 2.615s 6.160s
(0.016) (0.024) (0.085) (0.176)
5.742 5.717 10.463 10.466
L(α=−3,β=3) 5.833 26.656s 56.744s 10.785 86.582s 210.637s
(0.314) (0.590) (1.890) (5.240)
3.005 2.912 4.456 4.451
G(µ=0,β=1) 2.970 0.815s 2.048s 4.600 2.690s 6.234s
(0.023) (0.030) (0.100) (0.210)
5.859 5.850 8.969 8.971
G(µ=0,β=2) 5.940 18.831s 37.833s 9.200 53.861s 130.092s
(0.120) (2.100) (0.827) (1.800)
6.859 6.851 9.966 9.966
G(µ=1,β=2) 6.940 16.806s 36.883s 10.200 55.363s 131.361s
(0.005) (0.07) (0.542) (0.960)
TABLE 2. QuantileEstimationforseveraldistributions.
Onenotesthatthesamplesfromπ isgeneratedbyrunningtheSGHMCalgorithmwithη = 10−5. In
β
Table2,tocomparetheperformancebetweenSGHMCandSGLD,wedenotebyQ andT
SGHMC SGHMC
thenumericalapproximationsofthevaluesofthecorrespondingoptimizationproblem(10)usingthe
SGHMCalgorithm(7)and(8)andtheirrunningtime1,respectively,whereasQ andT arethe
SGLD SGLD
correspondingvaluesandrunningtimefortheSGLDalgorithm. Eachapproximationandrunningtimein
thetableareobtainedbasedon5differentseedsandatmost107 iterationsfollowedbyitsmeansquared
errorshowninbrackets. Wenoticethat,comparedtotheSGLDalgorithm,itrequireslesstimeforthe
SGHMCalgorithmtoconverge. Inaddition,theresultsobtainedbySGHMChavelowermeansquare
error.
4.2. Solvingregularizedoptimizationproblemsusingneuralnetwork. Inthissection,weconsider
optimization problems involving neural networks, which includes transfer learning, hedging under
asymmetricriskaswellasregressionandclassificationproblemsonrealworlddatasets.
4.2.1. TransferLearning. Intransferlearningandmulti-tasklearning,neuralnetworkswithpre-trained
parametersareemployedtoreducecomputationalcosts(see,e.g.,[34]andreferencestherein).
1Therunningtimeiscomputedasfollows.WefirstselecttherandomseedandcalculateE[u(θ )]−inf u(θ).Once
n θ∈Rd
E[u(θ )]−inf u(θ)islessthanϵ=0.0001,werecordthetotaltimethatthealgorithmruns.Finally,weaverageallthe
n θ∈Rd
resultsoverdifferentseeds.9
Inthissubsection,weanalyzethefollowingoptimizationproblemusingneuralnetworksinatransfer
learning setup. Let d 1,d 2,m 1,m
2
∈ N, and let N = (cid:0) N1,...,Nm2(cid:1) : Rd × Rm1 → Rm2 be the
two-hidden-layerfeedforwardneuralnetwork(TLFN)withitsj-thelementgivenby
Nj(θ,z) :=
(cid:88)d2
Wjnσ
(cid:0)(cid:88)d1
(cid:2) f(cid:0) Wnk(cid:1) σ (cid:0)(cid:10) Wk·,z(cid:11) +f(bk)(cid:1)(cid:3) +bn(cid:1) , j ∈ {1,··· ,m }, (12)
2 2 1 1 0 0 1 2
n=1 k=1
wherez = (cid:0) z1,...,zm1(cid:1) ∈ Rm1 istheinputvector,σ
1
: R → RistheReLUactivationfunction,i.e.,
σ (v) := max{0,v}, and σ : R → R is the sigmoid activation function, i.e., σ (v) := 1/(1+e−v),
1 2 2
W
0
∈ Rd1×m1 andW
2
∈ Rm2×d2 arefixed weightmatrices2,b
0
∈ Rd1 andb
1
∈ Rd2,andW
1
∈ Rd2×d1
areparametersoverwhichweoptimize,f : R → Risgivenbyf(v) := ctanh(v/c)withsome3c > 0.
Then,theparameteroftheneuralnetwork(12)whichneedstobetrainedisgivenby
θ = (cid:0)(cid:2) W (cid:3) ,b ,b (cid:1) ∈ Rd (13)
1 0 1
with d := d +d +d d , where we denote by [W ] the vector of all elements in W . Moreover, we
1 2 1 2 1 1
(cid:110) (cid:111) (cid:110) (cid:111)
denotebyc := max Wij andc := max Wij ,andassumethatatleastoneelementineach
W0
i,j
0 W2
i,j
2
row of W
0
∈ Rd1×m1 is nonzero, i.e., for each K = 1,...,d 1, there exists I = 1,...,m
1
such that
WKI ̸= 0.
0
Ourgoalistoaddressthefollowingoptimizationproblem:
(cid:104) (cid:105)
minimize Rd ∋ θ (cid:55)→ u(θ) := E |Y −N(θ,Z)|2 +λ |θ|2, (14)
r
where Z is an Rm1-valued input random variable, Y is the corresponding Rm2-valued target random
variable,θ ∈ Rd istheparameterdefinedin(13),andλ > 0istheregularizationconstant.
r
Proposition 4.2. Let X = (Y,Z) ∈ Rm2 ×Rm1 with m := m
1
+m
2
be a continuously distributed
randomvariable. Assumethat,foranyI = 1,...,m ,J = 1,...,m ,thedensityfunctionofZI given
1 2
Z1,...,ZI−1,ZI+1,...,Zm1,YJ denotedby
f : R → [0,∞)
ZI|Z1,...,ZI−1,ZI+1,...,Zm1,YJ
satisfies,foranyI = 1,...,m ,J = 1,...,m ,thatthereexistconstantsC ,C¯ > 0,suchthat,for
1 2 ZI ZI
anyz = (cid:0) z1,...,zm1(cid:1) ∈Rm1,yJ ∈ R,
(cid:12) (cid:12)zI(cid:12) (cid:12)2 f
ZI|Z1,...,ZI−1,ZI+1,...,Zm1,YJ
(cid:0) zI | z1,...,zI−1,zI+1,...,zm1,yJ(cid:1) ≤ C¯ ZI,
(15)
f (cid:0) zI | z1,...,zI−1,zI+1,...,zm1,yJ(cid:1) ≤ C .
ZI|Z1,...,ZI−1,ZI+1,...,Zm1,YJ ZI
LetF,G : Rd×Rm → Rd bedefined,forall(θ,x) ∈ Rd×Rm withx = (y,z),y ∈ Rm2,z ∈ Rm1,by
(cid:16) (cid:17)
F(θ,x) := 2λ θ, G(θ,x) := G ,··· ,G ,G (θ,x),··· ,G (θ,x),G (θ,x),...,G (θ,x) ,
r W 111 W 1d2d1 b1 0 bd 01 b1 1 bd 12
(16)
whereforeveryK = 1,...,d ,N = 1,...,d ,
1 2
G (θ,x) :=
−2(cid:88)m2
(cid:0) yj −Nj(θ,z)(cid:1) WjNσ
(cid:32) (cid:88)d1
(cid:104)
f(WNk)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(bk)(cid:17)(cid:105)
+bN(cid:33)
f′(WNK)
WNK 2 2 1 1 0 0 1 1
1
j=1 k=1
×(cid:32)
1−σ
(cid:32) (cid:88)d1
(cid:104)
f(WNk)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(bk)(cid:17)(cid:105)
+bN(cid:33)(cid:33)
σ (cid:0)(cid:10) WK·,z(cid:11) +f(bK)(cid:1) ,
2 1 1 0 0 1 1 0 0
k=1
(17)
2Laterintheapplicationresolvedinsection4.2.1,W andW willcorrespondtothefixedparameterswhichweretransferred
0 2
fromapreviouslysolvedoptimizationproblem.
3Wenotethatitmakessensetoapplyf tob andW fromapracticalperspective,see[33,41],andasaconsequence,the
0 1
optimizationproblem(14)canbeshowntosatisfyourAssumptions1-4,seeProposition4.2.10 L.LIANG,A.NEUFELD,ANDY.ZHANG
FIGURE 2. Trueandpredictionvaluesfororiginallearningtaskinvolving(18)(left)and
newlearningtaskinvolving(12)(right).
G (θ,x) :=
−2(cid:88)m2
(cid:0) yj
−Nj(θ,z)(cid:1)(cid:88)d2
Wjnσ
(cid:32) (cid:88)d1
(cid:104)
f(Wnk)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(bk)(cid:17)(cid:105)
+bn(cid:33)
bK 2 2 1 1 0 0 1
0
j=1 n=1 k=1
(cid:32) (cid:32) (cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105)
(cid:33)(cid:33)
× 1−σ f(Wnk)σ Wk·,z +f(bk) +bn f(WnK)f′(bK)1 ,
2 1 1 0 0 1 1 0 {⟨WK·,z⟩+f(bK)>0}
0 0
k=1
G (θ,x) :=
−2(cid:88)m2
(cid:0) yj −Nj(θ,z)(cid:1) WjNσ
(cid:32) (cid:88)d1
(cid:104)
f(WNk)σ
(cid:16)
(cid:10) WK·,z(cid:11)
+f(bk)(cid:17)(cid:105)
+bN(cid:33)
bN 2 2 1 1 0 0 1
1
j=1 k=1
(cid:32) (cid:32) (cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105)
(cid:33)(cid:33)
× 1−σ f(WNk)σ Wk·,z +f(bk) +bN .
2 1 1 0 0 1
k=1
Then,theoptimizationproblem(14)satisfiesAssumptions1-4withcorrespondingstochasticgradient
H := F +G.
Proof. SeeAppendixD. □
Corollary4.3. LetY beanm 2-dimensionalrandomvariabledefinedbyY = y(Z),wherey : Rm1 →
Rm2 is a Borel measurable function satisfying |y(z)| ≤ c y(1+|z|ρ) with c
y
≥ 0,ρ ≥ 1 for any
z ∈ Rm1. For any I = 1,...,m 1, let f
ZI|Z1,...,ZI−1,ZI+1,...,Zm1
be the density function of ZI given
Z1,...,ZI−1,ZI+1,...,Zm1 andassumethatthereexistconstantsC ,C¯ > 0, suchthatforany
ZI ZI
z = (cid:0) z1,...,zm1(cid:1) ∈ Rm1,
max(cid:110)(cid:12) (cid:12)zI(cid:12) (cid:12)2 ,(cid:12) (cid:12)zI(cid:12) (cid:12)ρ ,(cid:12) (cid:12)zI(cid:12) (cid:12)ρ+2(cid:111) f
ZI|Z1,...,ZI−1,ZI+1,...,Zm1
(cid:0) zI | z1,...,zI−1,zI+1,...,zm1(cid:1) ≤ C¯ ZI,
f (cid:0) zI | z1,...,zI−1,zI+1,...,zm1(cid:1) ≤ C .
ZK|Z1,...,ZI−1,ZI+1,...,Zm1 ZI
Then,the optimization problem (14) satisfies Assumption 1-4 with corresponding stochastic gradient
H := F +Gdefinedin(16)-(17).
Proof. SeeAppendixD. □
Simulated data.Set d = 30,d = 30,m = 2,m = 1. We denote by z = (cid:0) z1,z2(cid:1) ∈ R2 with
1 2 1 2
z1,z2 ∈ R. Weaimtoapproximatethefunctiony(z) = −(cid:12) (cid:12)1.2z1+0.9z2−0.8(cid:12) (cid:12)2 on[0,1]×[0,1]using
theTLFNdefinedin(12). Tothisend,weconsiderthefollowingmethodtoobtainthefixedparameters
([W ],[W ]):
0 211
(i) First,wedefinethethree-hidden-layerfeedforwardneuralnetwork(ThreeLFN)N˙ : Rd˙ ×Rm1 →
Rm2 withitsj-thelementgivenbygivenby
N˙ j(θ˙,z˙) =
(cid:88)d3
W˙ jmσ
(cid:18) (cid:88)d2
W˙ mnσ
(cid:32) (cid:88)d1
(cid:104)
W˙ nkσ
(cid:16)(cid:68)
W˙
k·,z˙(cid:69) +b˙k(cid:17)(cid:105)
+b˙n(cid:33) +b˙m(cid:19)
, (18)
3 3 2 2 1 1 0 0 1 2
m=1 n=1 k=1
wherez˙ = (cid:0) z˙1,z˙2(cid:1) ∈ Rm1,W˙
0
∈ Rd1×m1,W˙
1
∈ Rd2×d1,W˙
2
∈ Rd3×d2,W˙
3
∈ Rm2×d3,b˙
0
∈
Rd1,b˙
1
∈ Rd2,b˙
2
∈ Rd3 withd
1
= d
2
= d
3
= 30,σ
1
istheReLUactivationfunction,σ
2
andσ
3
aretanhactivationfunctions,andwheretheparameteris
(cid:16)(cid:104) (cid:105) (cid:104) (cid:105) (cid:104) (cid:105) (cid:104) (cid:105) (cid:17)
θ˙ = W˙ , W˙ , W˙ , W˙ ,b˙ ,b˙ ,b˙ ∈ Rd˙
0 1 2 3 0 1 2
withd˙= d (m +1)+d (d +1)+d (d +m +1).
1 1 2 1 3 2 2
(ii) Then,wetraintheThreeLFNtoapproximatethefunctiony˙(z˙) =
(cid:12) (cid:12)2z˙1+2z˙2−1.5(cid:12) (cid:12)3
on[0,1]×
[0,1],thatis,weaimtosolvethefollowingoptimizationproblem:
(cid:104) (cid:105)
minimize Rd ∋ θ˙ (cid:55)→ u(θ˙) := E |y˙(Z˙)−N(θ˙,Z˙)|2 +λ |θ˙|2, (19)
r
(cid:16) (cid:17)
where Z˙ = Z˙1,Z˙2 ∈ R2. Note that (19) corresponds to a similar task (but not the same)
as our goal is to approximate the Borel function y. For the simulation, we generate 10000
independent samples y˙ = y˙(z˙ ) with z˙ = (cid:0) z˙1,z˙2(cid:1) for z˙1,z˙2 ∼ U(0,1) being independent
n n n n n
andsplitthedatasetintosubsetsincludingtrainingset(80%)andvalidationset(20%). Moreover,
we set η = 10−2,λ = 10−6,β = 108,γ = 0.5, and obtain the initial values θ˙ using Xavier
r 0
initialization(i.e.,thedefaultsettingofPyTorch,see[22]);
(cid:16)
(iii) OncetheThreeLFN(18)isfullytrained,weobtainthetrainedparametersθ˙∗ = [W˙ ∗],[W˙ ∗],[W˙ ∗],
0 1 2
(cid:17)
[W˙ ∗],b˙∗,b˙∗,b˙∗ . Finally, we let W := W˙ ∗, W := W˙ ∗ be the fixed weight parameters in
3 0 1 2 0 0 2 3
TLFN(12).
Nowweproceedtoapproximatey usingTLFN(12). Theinitialvalueofθ isobtainedbyusingXavier
0
initialization (see [22]). Let X = (y(Z),Z) ∈ R3 with Y ∈ R and Z = (cid:0) Z1,Z2(cid:1) ∈ R2 where
Z1,Z2 ∼ U(0,1)areindependentinputrandomvariables. Wegeneraten = 10000independentsamples
(x i)n
i=1
= (y i,z i)n
i=1
with z
i
= (cid:0) z i1,z i2(cid:1) and y
i
= y(z i) = −(cid:12) (cid:12)1.2z i1+0.9z i2−0.8(cid:12) (cid:12)2 . One notes that
Assumptions1-4holdinthissettingduetoCorollary4.2. Figure2showsthetruefunctions(inblue)
andtheapproximatedfunctions(inorange). TheseresultsindicatethatSGHMCcanbeusedforsolving
minimizationproblemsinvolvingReLUneuralnetworksinthetransferlearningsetting.
4.2.2. Hedgingunderasymmetricrisk. Hedgingisamajorconcerninfinance,bothfromatheoretical
andapracticalpointofview. Theoreticalfoundationsforcontinuous-timehedgingarewell-established
(see [27], for instance). However, in practice, hedging can be performed only at discrete time points,
whichyieldsaresidualrisk,namely,thetrackingerror. Themajorproblemistoobtainhedgingpolicies
thatminimizethiserror. Tothisend,thissubsectionadaptsadeeplearningapproachproposedin[45]
to solve hedging under asymmetric risk. We view the given hedging problem as a Markov Decision
Process(MDP)andthenapproximatetheoptimalpolicyfunctionoftheMDPusingneuralnetworks. We
useSGHMCtotraintheneuralnetworksandcompareitsperformancewithotherpopularoptimization
algorithms.
(cid:16) (cid:17)
Weassumethatthefinancialmarketisdefinedonafilteredprobabilityspace Ω,{F }K ,P with
k k=0
F = {∅,Ω} where p ∈ N assets (cid:0) Si(cid:1)i=1,···,p can be traded at discrete time points, i.e., 0 = t <
0 k k=0,···,K 0
t < t < ... < t < t = T for some fixed finite time horizon 0 < T < ∞. We are interested
1 2 K−1 K
in hedging the claim h ∈ F at time T using the p different hedging instruments. We denote by
K K
R ∈ Rp,k = 0,··· ,K −1,theexcessreturnvectorofthepriskyassetsbetweentheperiod(t ,t ]
k k k+1
whichareF -measurable,whereastheconstantrisk-freereturnisdenotedbyR ∈ [0,∞). Forany
k+1 f
k = 0,...,K −1,weconsiderthefollowing(discrete-time)multidimensionalBlack-Scholes-Merton
modelfortheexcessreturnR :
k
(cid:18)(cid:18) 1 (cid:16) (cid:17)(cid:19) √ (cid:19)
R = exp r˜1+Σλ˜− diag ΣΣ⊤ ∆+ ∆Σϵ −R 1,
k k f
212 L.LIANG,A.NEUFELD,ANDY.ZHANG
p,m 5,5 50,50 5,10 50,60
K˜ 5 50 5 60
W 1 1 1 1
0
S 1 1 1 1
0
γ 0.5 0.5 0.5 0.5
r 0.03 0.03 0.03 0.03
(cid:101)
∆ 1/40 1/40 1/40 1/40
D [0,1]p [0,1]p [0,1]p [0,1]p
λ(cid:101)i = 0.1 λ(cid:101)i = 0.01 λ(cid:101)i = 0.01 λ(cid:101)i = 0.01
fori = 1,2 fori = 1,...,25 fori = 1,2 fori = 1,...,25
λ(cid:101)
λ(cid:101)i = 0.2 λ(cid:101)i = 0.05 λ(cid:101)i = 0.05 λ(cid:101)i = 0.05
fori = 3,4,5 fori = 26,...,50 fori = 3,4,5 fori = 26,...,50
Σ = 0.15 Σ = 0.15 Σ = 0.15 Σ = 0.15
Σ ii ii ii ii
Σ = 0.01fori ̸= j Σ = 0.001fori ̸= j Σ = 0.01fori ̸= j Σ = 0.001fori ̸= j
ij ij ij ij
TABLE 3. Parametersforoptimizationproblem(22).
wherer˜∈ [0,∞),1 = (1,...,1) ∈ Rp,Σ ∈ Rp×m,m ≥ p,λ˜ ∈ Rm,∆ > 0isaconstantrebalancing
timeperiod,ϵ ,k = 0,...,K−1,arei.i.d. m-dimensionalGaussianvectorswithmean0andcovariance
k
I ,i.e.,ϵ ∼ N (0,I ),andR := exp(r˜∆)denotestheriskfreereturn. Inthissetting,theexcess
m k m m f
returns {R }K−1 are i.i.d.. Note that the market is complete when m = p and ΣΣ⊤ is invertible
k k=0
and incomplete when m > p. Moreover, denote by W ∈ R the wealth of the portfolio and S =
k k
(cid:0) S1,··· ,Sp(cid:1) ∈ Rptheequitypricesattimepointt . TomodelthisasanMDP,wedefinethestateprocess
k k k
(s ) bys := (W ,S ) ∈ R1+p anddenotebyD ⊆ Rp thesetofpossibleactionsrepresenting
k k=0,···,K k k k
the proportion of current wealth invested in each risky asset. Then, for any k = 0,1,...,K −1, the
evolution of the equity prices between the time points k and k + 1 is S := S (1+R ) and the
k+1 k k
evolutionofthewealthisgivenby
W := W (⟨g (s ),R ⟩+R ),
k+1 k k k k f
whereg (·) : R1+p → D (beingmeasurable)istheinvestmentcontrolpolicyfunctiononpriskyassets
k
attimepointt .
k
Inthissetting,weareinterestedinfindingthehedginginstrumentselectionofpriskyassetswhich
minimizesthelossfunctionoftheresidualrisk. Thelossfunctionminimizationproblemcanbewritten
asanMDPproblemasfollows:
(cid:16) (cid:17)2 
1−γSign(W −h ) (W −h )2
K K K K
min E (s ) := min E ,
g0,...,gK−1 K 0 g0,...,gK−1  2 
(cid:0) (cid:1) (cid:0) (cid:1)
s.t. s = W ,S = W (⟨g (s ),R ⟩+R ),S (1+R ) , k = 0,1,...,K −1,
k+1 k+1 k+1 k k k k f k k
(20)
where Sign(y) := 1 −1 , h := h(S ) is the claim for some measurable function h : Rp →
y>0 y<0 K K
(1−γSign(y))2y2
[0,∞),andγ ∈ [0,1)isthepenalizationparameter. Notethatthelossfunctionℓ (y) := ,
γ 2
y ∈ R,isasymmetricwhenγ > 0,whichpenalizeslosses(i.e.,whenW −h < 0)morethanprofits.
K K
Following[45],wesolvetheMDPproblem(20)byemployingstandardfeedforwardneuralnetworks
toapproximateeachoftheinvestmentcontrolpolicyfunctionsg (·). WedenotebyG thesetofstandard
k ν
feedforwardneuralnetworkswithtwohiddenlayers,whichisgivenexplicitlyby
G =(cid:8) f : R1+p → Rp | f(x) = tanh(W z+b ),z = σ(W y+b ),
ν 3 3 2 2
(21)
y = σ(W x+b ),W ∈ Rν×(1+p),W ∈ Rν×ν,W ∈ Rp×ν,b ,b ∈ Rν,b ∈ Rp(cid:9) ,
1 1 1 2 3 1 2 3
whereν denotesthenumberofneuronsoneachlayeroftheneuralnetwork,tanh(x),foranyx ∈ Rp,
isthehyperbolictangentfunctionatxappliedcomponentwise,andσ(y) := max{0,y},y ∈ Rν,isthe
ReLUactivationfunctionappliedcomponentwise.
Foranyk = 0,1,...,K −1,denotebyg (·;θ ) : R1+p → Rp theapproximatedpolicyfunctionat
k k
timet usinganeuralnetworkwithitsstructuredefinedinwith(21),whereθ :=(b ,b ,b ,[W ],[W ],[W ]) ∈
k k 1 2 3 1 2 313
(A)p=m=5andν =1 (B)p=m=5andν =5 (C)p=m=5andν =10
(D)p=m=50andν =1 (E)p=m=50andν =5 (F)p=m=50andν =10
FIGURE 3. Plots of test scores E KNN (s 0) for different numbers of assets and hidden
sizesundertheBlack-Scholes-Mertonmodelinthecompletemarketcase. Theparameter
settingsaresummarizedinTable3.
(A)p=5,m=10,andν =1 (B)p=5,m=10,andν =5 (C)p=5,m=10,andν =10
(D)p=50,m=60,andν =1 (E)p=50,m=60,andν =5 (F)p=50,m=60,andν =10
FIGURE4. PlotsoftestscoresE KNN (s 0)fordifferentnumbersofassetsandhiddensizes
undertheBlack-Scholes-Mertonmodelintheincompletemarketcase. Theparameter
settingsaresummarizedinTable3.
Rν(1+p+ν+p+2)+p denotes the parameter of the neural network. Then, the MDP problem (20) can be14 L.LIANG,A.NEUFELD,ANDY.ZHANG
approximatedbyrestrictingg (·;θ ) ∈ G :
k k ν
(cid:16)
1−γSign(WNN (ζ;θ)−h
)(cid:17)2(cid:0)
WNN (ζ;θ)−h
(cid:1)2
K K K K
min E (s ) ≈ minE  =: minENN (s ),
g0,...,gK−1 K 0 θ  2  θ K 0
(22)
whereζ := (s ,R ,...,R )denotesthevectoroftheinitialstatevariableandallthereturnsthrough-
0 0 K−1
outthetradingtimehorizon[0,T],andwheresNN(ζ;θ)isrecursivelydefined,fork = 0,1,...,K −1,
K
by
(cid:18) (cid:19)
sNN (ζ;θ) = (cid:0) WNN (ζ;θ),S (cid:1) = WNN (ζ;θ)(cid:0)(cid:10) g (cid:0) sNN;θ (cid:1) ,R (cid:11) +R (cid:1) ,S (1+R ) ,
k+1 k+1 k+1 k k k k k f k k
(23)
whereg (·;θ ) ∈ G istheapproximatedpolicyfunctionwithG givenin(21)andθ = (θ ,...,θ ) ∈ Rd
k k ν ν 0 K−1
istheparameterfortheneuralnetworkswithd :=K(ν(1+p+ν +p+2)+p).
(cid:110) (cid:111)
Wesettheclaimh := max (cid:80)p Si −K˜,0 ,whereK˜ isthestrikeprice. Differentsettingsof
K i=1 K
theBlack-Scholes-MertonmodelforsimulationsaresummarizedinTable3. Similarto[45],themodels
aretrainedfor200stepswithabatchsizeof128. Eachstepinvolvesgenerating20000trainingsamples,
requiring⌈20000/128⌉ = 157iterationsperstepformodeltraining. Subsequently,100000testsamples
are used to compute the test residual error. Furthermore, three different hidden sizes ν are tested for
each experimental setting. For p = 5 : ν values are {1,5,10} with m values {5,10}; for p = 50 : ν
valuesare{1,5,10}withmvalues{50,60}. ForSGHMC,optimalhyperparametersareselectedfrom
η = {0.5,0.1,0.05,0.01}, γ = {0.5,1,5}, and β = 1012. For SGLD and TUSLA (see [30, 32]), we
choosehyperparametersamongη = {0.5,0.1,0.05,0.01}andβ = 1012. ForADAM,AMSGrad,and
RMSProp,thebestlearningrateischosenamongη = {0.1,0.05,0.01}withotherhyperparametersset
asdefault.
Figure3and4plotslearningcurvesforalloptimizationalgorithmsacrossvariousconfigurationsin
completeandincompletemarkets. Asdepicted,theSGHMCalgorithmgenerallyoutperformsSGLDand
TUSLAinthistask. Furthermore,theSGHMCalgorithmachievescomparableperformancestoADAM,
AMSGrad,andRMSProp.
4.2.3. Real-worlddatasets. Inthissubsection,weapplytheSGHMCalgorithmtosolveoptimization
problemsusingreal-worlddatasets. Moreprecisely,weconsideraregressionproblemusingconcrete
compressivestrengthdataset(see[53])aswellasanimageclassificationproblemusingFashionMNIST
(see[50]). WethencomparetheperformanceofSGHMCwithotherpopularoptimizersincludingADAM,
AMSGrad,andRMSProp.
Weconsidertosolvethefollowingoptimizationproblem:
minimize Rd ∋ θ (cid:55)→ u(θ) := E[ℓ(Y,N¯(θ,Z))]+λ |θ|2, (24)
r
where ℓ : Rm2 ×Rm2 → R is a loss function with m
2
∈ N, θ ∈ Rd is the parameter over which we
optimize,Z ∈ Rm1 istheinputrandomvariable,Y ∈ Rm2 isthetargetrandomvariable,andN¯ isthe
neuralnetworkgivenby:
N¯(θ,z) := W σ (W z+b )+b , (25)
2 1 1 1 2
where W
1
∈ Rd1×m1, W
2
∈ Rm2×d1, b
1
∈ Rd1, and b
2
∈ Rm2 are the parameters, i.e., θ =
([W ],[W ],b ,b ) ∈ Rd withd = d (m +m +1)+m .
1 2 1 2 1 1 2 2
Regression.Intheregressionexample,weexploretheperformanceofSGHMCinsolving(24)using
concretecompressivestrengthdataset4,whichincludes1030instancesandeachsamplehas9attributes
(consistingof8quantitativeinputvariablesand1quantitativeoutputvariable)withnomissingvalues.
Forthenumericalexperiments,wesetm = 8,m = 1,d = 50andthusd = 501. Ourgoalistofind
1 2 1
thebestestimatorthatpredictstheconcretecompressivestrengthY ∈ RgiventheinputvariableZ ∈ R8
bysolvingtheoptimizationproblem(24)withthesquaredlossfunctionℓ(u,v) = |u−v|2 foru,v ∈ R.
In our experiments, we divided 10% of the dataset as a test set and employed the SGHMC, ADAM,
AMSGrad,andRMSpropalgorithms(see,e.g.,[28,44,51])withthreedifferentseeds. Wetrainedthe
modelsfor5000epochsusingabatchsizeof256. ForADAM,AMSGrad,andRMSProp,wesearched
4Datasetisavailableinhttps://archive.ics.uci.edu/dataset/16515
FIGURE 5. Meansquarederrorforconcretecompressivestrengthdataset(left)andTest
accuracycurveforFashionMNIST(right).
fortheoptimallearningratewithintherangeof{0.01,0.001}whereastheotherparametersaresetas
default.
Classification.Intheclassificationexample,wesetm = 784,m = 10,d = 50andthusd = 39760.
1 2 1
Weconsidertosolve(24)withtheneuralnetworkdefinedin(25)andthecrossentropylossgivenby
ℓ(u,v) := −(cid:80)m j=2 1u jlogv
j
foru,v ∈ Rm2. WeusetheFashionMNISTdataset5comprisingof28×28
imagesof70000fashionproductsfrom10categorieswith7000imagespercategory. Thetrainingset
has60000samplesandthetestsethas10000samples. Eachsampleisassignedtooneoftendifferent
labels. Then, the label variables are defined as y = [y ,··· ,y ]⊤ ∈ R10, where y := 1 ,
i i,0 i,9 i,j j=labeli
i = 1,··· ,60000. We train the models for 200 epochs with a batch size of 128. Also, we decay the
initiallearningrateby10after150epochs.
AsshownintheleftplotinFigure5,theSGHMCalgorithmachievesthelowestmeansquarederror
comparedtootheroptimizers. TherightplotinFigure5showsthattheperformanceoftheSGHMCis
slightlybetterthanADAM,Amsgrad,andRMSPropintermsoftestaccuracy. Ourresultsshowthatthe
SGHMCalgorithmcanoutperformtheSGLDalgorithminmanyapplicationsandachievecomparable
performancetopopularoptimizersonlearningtasksinvolvingreal-worlddatasets.
4.3. Conclusionofnumericalexperiments. WeconsideredapplyingtheSGHMCalgorithmtovarious
applicationstojustifyourtheoreticalresults. Fortheempiricalexperimentsonquantileestimationin
Section4.1,SGHMCoutperformsSGLDbyhavingasmallerexpectedexcessriskandashortertraining
time under different settings. In Section 4.2.1, the numerical results show that SGHMC can be used
for the training of ReLU neural networks in the transfer learning setting. Moreover, for the hedging
problemunderasymmetricriskdescribedinSection4.2.2, SGHMCoutperformsSGLDandTUSLA
indifferentscenarioswhileitachievescomparabletestscorestoADAM,AMSGrad,andRMSProp. In
addition,asdiscussedin4.2.3,forregressionandclassificationproblemsonreal-worlddatasets,SGHMC
demonstratesbetterperformancecomparedtootheroptimizersintermofthetestmean-squarederrorand
testaccuracy.
In summary, SGHMC achieves (at least) comparable results to existing algorithms including, e.g.,
ADAM, AMSGrad, RMSProp, SGLD, and TUSLA, while its performance is backed by theoretical
guaranteesasdescribedinTheorem3.1,Corollary3.2,andTheorem3.3.
5Datasetisavailableinhttps://github.com/zalandoresearch/fashion-mnist16 L.LIANG,A.NEUFELD,ANDY.ZHANG
5. PROOF OF MAIN THEOREMS
5.1. Introductionofauxiliaryprocesses. WefirstdefinetheunderdampedLangevinSDE(θ t,V t) t∈R
+
givenby
(cid:112)
dV = −(γV +h(θ ))dt+ 2γβ−1dB ,
t t t t
(26)
dθ = V dt,
t t
where h := ∇u, γ > 0 is the friction coefficient, β > 0 is the inverse temperature parameter, and
(B ) isastandardd-dimensionalBrownianmotionadaptedtoitscompletednaturalfiltrationdenoted
t t∈R
+
by(F ) . Weassumethat(F ) isindependentofG ∨σ(θ ,V ).
t t∈R
+
t t∈R
+
∞ 0 0
Foreachη > 0,weconsiderthescaledprocess(ζ tη,Z tη):=(θ ηt,V ηt)with(θ t,V t) t∈R
+
definedin(26).
Itcanbewrittenasfollows:
dZη = −η(γZη +h(ζη))dt+(cid:112) 2γηβ−1 dBη,
t t t t
(27)
dζη = ηZηdt,
t t
with the initial condition Z 0η := V
0
and ζ 0η := θ 0, where B tη := √1 ηB ηt. We denote the filtration of
(Bη) by(Fη) := (F ) ,andwenotethat(Fη) isindependentofG ∨σ(θ ,V ).
t t∈R
+
t t∈R
+
ηt t∈R
+
t t∈R
+
∞ 0 0
Next,wedefinethecontinuous-timeinterpolationofSGHMCas
dV¯η = −η(cid:16) γV¯η +H(cid:16) θ¯η ,X (cid:17)(cid:17) dt+(cid:112) 2γηβ−1dBη,
t ⌊t⌋ ⌊t⌋ ⌈t⌉ t
(28)
dθ¯η = ηV¯η dt,
t ⌊t⌋
with initial value V¯η := V and θ¯η := θ . The process (28) mimics the recursion (7) and (8) at grid
0 0 0 0
pointsinthesensethatL(θη,Vη) = L(cid:0) θ¯η,V¯η(cid:1) ,foreachn ∈ N .
n n n n 0
(cid:16) (cid:17)
Furthermore,wedefinetheauxiliaryprocess
ζˆs,u,v,η,Zˆs,u,v,η
as
t t
t≥s
dZˆs,u,v,η = −η(cid:16) γZˆs,u,v,η +h(cid:16) ζˆs,u,v,η(cid:17)(cid:17) dt+(cid:112) 2γηβ−1 dBη,
t t t t
dζˆs,u,v,η = ηZˆs,u,v,ηdt,
t t
withinitialconditionsζˆs,u,v,η = u,Zˆs,u,v,η = v.
s s
Definition5.1. Forany0 < η ≤ η withη givenin(9)andn ∈ N ,setT := ⌊1/η⌋anddefine
max max 0
ζ¯η,n = ζˆnT,θ¯ nη T,V¯ nη T,η , Z¯η,n = ZˆnT,θ¯ nη T,V¯ nη T,η . (29)
t t t t
We note that, by above Definition 5.1, the process
(ζ¯η,n,Z¯η,n)
is the underdamped Langevin
t t t≥nT
process(27)startingattimenT with(θ¯η ,V¯η ).
nT nT
5.2. Preliminary moment estimates. In this subsection, we provide preliminary results which are
essentialforprovingthemainresults. Tothisend,considerthefollowingLyapunovfunctiondefinedfor
any(θ,v) ∈ Rd×Rd by
β
V(θ,v) = βu(θ)+ γ2(|θ+γ−1v|2+|γ−1v|2−λ|θ|2). (30)
4
Denote by µ the probability law of the initial state (θ ,V ). Note that E[V(θ ,V )] < ∞, since we
0 0 0 0 0
(cid:104) (cid:105) (cid:104) (cid:105)
assumeE |θ |4 +E |V |4 < ∞.
0 0
Lemma5.2. LetAssumptions1-4hold. Then,wehave
(cid:104) (cid:105) (cid:82) V(θ,v)µ (dθ,dv)+ d+Ac
supE |θ |2 ≤ Cc := R2d 0 λ , (31)
t θ 1(1−2λ)βγ2
t≥0 8
(cid:104) (cid:105) (cid:82) V(θ,v)µ (dθ,dv)+ d+Ac
supE |V |2 ≤ Cc := R2d 0 λ . (32)
t v 1(1−2λ)β
t≥0 4
Proof. SeeAppendixB. □17
Lemma5.3. LetAssumptions1-4hold. Then,wehave,forany0 < η ≤ η withη givenin(9),
max max
that
supE(cid:104)(cid:12)
(cid:12)θ
kη(cid:12) (cid:12)2(cid:105)
≤C
θ
:=
(cid:82)
R2dV(θ,v 1) (µ 10 −(d 2θ λ, )d βv γ) 2+
4(d+ λAc)
,
t≥0 8
supE(cid:104)(cid:12)
(cid:12)V
kη(cid:12) (cid:12)2(cid:105)
≤C
v
:=
(cid:82)
R2dV(θ,v) 1µ (10( −dθ 2, λd )v β)+
4(d+ λAc)
.
t≥0 4
Proof. SeeAppendixB. □
Lemma 5.4. Let Assumptions 1-4 hold. Moreover, for any 0 < η ≤ η with η given in (9), set
max max
T := ⌊1/η⌋. Then,wehave,forany0 < η ≤ η withη definedin(9),that
max max
ns ∈u Np 0t∈[nTs ,u (np +1)T]E(cid:104)(cid:12) (cid:12)ζ¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ C
ζ
:=
(cid:82)
R2dV(θ,v
1
8) (µ 10 −(d 2θ λ, )d βv γ) 2+
5(d+ λAc)
,
(33)
ns ∈u Np 0t∈[nTs ,u (np +1)T]E(cid:104)(cid:12) (cid:12)Z¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ C
Z
:=
(cid:82)
R2dV(θ,v)
1
4µ (10( −dθ 2, λd )v β)+
5(d+ λAc)
.
Proof. SeeAppendixB. □
Lemma5.5. LetAssumptions1-4hold. Then,weobtain,forany0 ≤ η ≤ η withη givenin(9),
max max
that
sup E(cid:2) V2(cid:0) θη,Vη(cid:1)(cid:3) ≤ E(cid:2) V2(θ ,v )(cid:3) + 2D := C ,
k∈N
0
k k 0 0 γλ V
(cid:104) (cid:16) (cid:17)(cid:105)
sup E V2 ζ¯η,k,Z¯η,k ≤ C′ ,
t t V
k∈N
0
whereC′ isgivenby(83).
V
Proof. SeeAppendixB. □
Next,following[15,40],weprovidethecontractionpropertyoftheunderdampedSDEinthesemi-
metricdefinedbelow. Forany(θ,v),(θ′,v′) ∈ Rd×Rd,wedenoteby:
r(cid:0) (θ,v),(cid:0) θ′,v′(cid:1)(cid:1)
= α
c(cid:12) (cid:12)θ−θ′(cid:12) (cid:12)+(cid:12) (cid:12)θ−θ′+γ−1(cid:0) v−v′(cid:1)(cid:12)
(cid:12),
ρ(cid:0) (θ,v),(cid:0) θ′,v′(cid:1)(cid:1)
=
g(cid:0) r(cid:0) (θ,v),(θ′,v′)(cid:1)(cid:1) ·(cid:0)
1+ε V(θ,v)+ε
V(cid:0) θ′,v′(cid:1)(cid:1)
,
c c
where α and ε are appropriately chosen positive constants (see, e.g., [15, Theorem 2.3]) and g :
c c
[0,∞) → [0,∞) is a continuous, non-decreasing concave function such that g(0) = 0,g is twice
continuouslydifferentiableon(0,R )forsomeconstantR > 0withright-sidedderivativeg′ (0) = 1
1 1 +
andleft-sidedderivativeg′ (R ) > 0,andg isconstanton[R ,∞). Foranytwoprobabilitymeasures
− 1 1
µ,ν onR2d,wedefine
W (µ,ν) := inf E[ρ((θ ,V ),(θ ,V ))].
ρ 1 1 2 2
(θ1,V1)∼µ,(θ2,V2)∼ν
WenotethatρandW aresemi-metricsbutnotnecessarilymetrics.
ρ
Proposition5.6. LetAssumptions1-4holdandlettheinitialvalueofthescaledunderdampedLangevin
SDEs(θ ,V )and(θ′,V′)be(θ ,V ) ∼ µand(θ′,V′) ∼ ν, respectively. Then, thereexistconstants
t t t t 0 0 0 0
c˙,C˙ > 0suchthat,foranyt > 0and1 ≤ p ≤ 2,
W (cid:0) L(θ ,V ),L(cid:0) θ′,V′(cid:1)(cid:1) ≤ C˙W (µ,ν)1/pe−c˙t,
p t t t t ρ
wheretheconstantsc˙andC˙ aregiveninTable4.
Proof. ByusingRemark2.2andRemark2.4,theAssumption2.1of[15]issatisfied. Hence,theresult
followsbyapplyingthesameargumentasthatintheproofof[6,Theorem4.1]. □18 L.LIANG,A.NEUFELD,ANDY.ZHANG
Constant Fullexpression
C θc (cid:82) R2dV(θ,v)µ0(dθ,dv)+ d+ λAc (cid:0)1 8(1−2λ)βγ2(cid:1)−1
Lemma5.2
C vc (cid:82) R2dV(θ,v)µ0(dθ,dv)+ d+ λAc (cid:0)1 4(1−2λ)β(cid:1)−1
C
θ
(cid:82) R2dV(θ,v)µ0(dθ,dv)+ 4(d+ λAc)(1 8(1−2λ)βγ2)−1
Lemma5.3
Cv (cid:82) R2dV(θ,v)µ0(dθ,dv)+ 4(d+ λAc)(1 4(1−2λ)β)−1
C
ζ
(cid:82) R2dV(θ,v)µ0(dθ,dv)+ 5(d+ λAc)(1 8(1−2λ)βγ2)−1
Lemma5.4
CZ (cid:82) R2dV(θ,v)µ0(dθ,dv)+ 5(d+ λAc)(1 4(1−2λ)β)−1
CV (cid:82) R2dV2(θ,v)µ0(dθ,dv)+ 2 γD
λ
C V′
(cid:18) CV+2βγ(d+Ac)(cid:16)
u0+ |h( 20
L)|2(cid:17) +γβ(cid:16)
8+ 3(d+
2Ac)(cid:17) CZ+2γβ(cid:16) γ2+(d+Ac)(cid:16)
L+ 3γ
42(cid:17)(cid:17)
C
ζ(cid:19)
e2λγ
Lemma5.5
(2γAc+2γd+6max(cid:40)
1
8(5 1γ −d 2λ),3γd(cid:16) γ2+5L
11
62 1E (1(cid:104) −(1 2+ λ| )X γ0 2|)2(ρ+1)(cid:105)(cid:17)(cid:41) )(E[V(θ0,V0)]+ 4(A λc+d))
D
+2(2+γ)(cid:16) E(cid:104) (1+|X0|)2(ρ+1)(cid:105) L2 2+E(cid:2) F ∗2(X0)(cid:3)(cid:17) (E[V(θ0,V0)]+ 4(A λc+d))β+16γ2A2 c+48γ2d2
+(cid:18) 96(cid:0) 1+ γ 2(cid:1)2(cid:16) |h(0)|4+4L4 2E(cid:104) (1+|X0|)4(ρ+1)(cid:105) +4E(cid:2) F ∗4(X0)(cid:3)(cid:17) +64(cid:0) 1+ γ 2(cid:1)2
×(cid:18) L4 2E(cid:104) (1+|X0|)4(ρ+1)(cid:105) +E(cid:2) F ∗4(X0)(cid:3)(cid:19)(cid:19) β2+(cid:16) 90γdL2 2E(cid:104) (1+|X0|)2(ρ+1)(cid:105) +90γdE(cid:2) F ∗2(X0)(cid:3)(cid:17) β
c˙ 38γ 4pmin(cid:110) λcLγ−2,Λc1/2e−ΛcLγ−2,Λ1 c/2e−Λc(cid:111)
C˙ 21/pe2/p+Λc/p min1 {+ 1γ ,αc}(cid:32) max(cid:40) 1,4ma mx i(cid:110) n1 {, 1R ,R1p− 1}2(cid:111) (cid:0) 1+2αc+2α2 c(cid:1) (d+Ac)β−1γ−1c˙−1(cid:41)(cid:33)1/p
Proposition5.6 Λc 1 52(cid:0) 1+2αc+2α2 c(cid:1) (d+Ac)Lγ−2λ−1(1−2λ)−1
εc γ−1c˙/(d+Ac)
R1 4·(6/5)1/2(cid:0) 1+2αc+2α2 c(cid:1)1/2(d+Ac)1/2β−1/2γ−1(cid:0) λ−2λ2(cid:1)−1/2
(cid:16) (cid:17)
αc 1+Λ− c1 Lγ−2>0
TABLE 4. ExplicitexpressionsoftheconstantsinSection5.2.
5.3. Proof of main results. To provide a non-asymptotic upper bound for W
(cid:0) L(cid:0) θ¯η,V¯η(cid:1)
,π¯
(cid:1)
for
p t t β
p = 1,2,wefirstconsiderthefollowingsplittingusingthescaledprocessgivenin(27): foranyn ∈ N
0
andt ∈ (nT,(n+1)T],
W
(cid:0) L(cid:0) θ¯η,V¯η(cid:1)
,π¯
(cid:1)
≤ W
(cid:0) L(cid:0) θ¯,V¯η(cid:1) ,L(cid:0) ζ¯η,n,Z¯η,n(cid:1)(cid:1)
+W
(cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1)
p t t β p t t t t p t t t t
(34)
+W (L(ζη,Zη),π¯ ).
p t t β
Notethat(cid:0) θ¯η,V¯η(cid:1)
definedin(28)canbeviewedasacontinuousversionofthefirstorderEulerscheme
t t
of (cid:0) ζ¯η,n,Z¯η,n(cid:1) with stochastic gradient. We consider the corresponding L2-distance and employ the
t t
synchronouscouplingtoobtainanestimateforthefirsttermontheRHSof(34). Toupperboundthe
secondtermontheRHSof(34),weviewL(cid:0) ζ¯η,n,Z¯η,n(cid:1) andL(ζη,Zη)asthelawsofthetime-changed
t t t t
process(27)startingfromdifferentinitialpoints. Then, applyingthecontractionresultin[6, Lemma
5.4] and letting p = 1,2 yield the result. We note that, as π¯ is the invariant measure of the second-
β
order (underdamped) Langevin SDE in (26), L(ζη,Zη) and π¯ can also be viewed as the laws of the
t t β
process(26)fromdifferentinitialpoints,i.e.,from(θ ,V )andarandomvariabledistributedaccording
0 0
to π¯ , respectively. Therefore, the last term on the RHS of (34) can be upper bounded by the same
β
approachasthatforboundingthesecondterm.
WeestablishupperboundsforeachofthetermsontheRHSof(34). Theresultsarepresentedbelow.19
Lemma5.7. LetAssumptions1-4hold. Then,forany0 < η ≤ η withη givenin(9),n ∈ N ,
max max 0
andt ∈ [nT,(n+1)T)withT := ⌊1/η⌋,weobtain
W (cid:0) L(cid:0) θ¯η,V¯η(cid:1) ,L(cid:0) ζ¯η,n,Z¯η,n(cid:1)(cid:1) ≤ C⋆η1/2.
2 t t t t 1
whereC⋆ isgivenexplicitlyinTable1,
1
Proof. SeeAppendixC. □
Lemma5.8. LetAssumptions1-4hold. Then,forany0 < η ≤ η withη givenin(9),n ∈ N ,
max max 0
andt ∈ [nT,(n+1)T)withT := ⌊1/η⌋,weobtain
W (cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1) ≤ C∗η1/2, W (cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1) ≤ C⋆η1/4,
1 t t t t 2 t t t t 2
whereC∗ isgivenin(95)andC⋆ isgivenexplicitlyinTable1.
2
Proof. SeeAppendixC. □
Lemma5.9. LetAssumptions1-4hold. Then,forany0 < η ≤ η withη givenin(9),n ∈ N ,
max max 0
andt ∈ [nT,(n+1)T)withT := ⌊1/η⌋,wehave
W 1(L(ζ tη,Z tη),π¯ β) ≤ C 2∗e−C 3∗ηt, W 2(L(ζ tη,Z tη),π¯ β) ≤ C 3⋆e−C 4⋆ηt,
whereC∗,C∗,C⋆,andC⋆ areexplicitlygiveninTable1.
2 3 3 4
Proof. SeeAppendixC. □
ProofofTheorem3.1andCorollary3.2. First, by using Lemma 5.7, 5.8, and 5.9, we obtain, for any
n ∈ N andt ∈ [nT,(n+1)T)withT := ⌊1/η⌋,that
0
W 2(cid:0) L(cid:0) θ¯ tη,V¯ tη(cid:1) ,π¯ β(cid:1) ≤ C 1⋆η1/2+C 2⋆η1/4+C 3⋆e−C 4⋆nηT,
whichimplies
W 2(cid:0) L(cid:0) θ¯ nη T,V¯ nη T(cid:1) ,π¯ β(cid:1) ≤ C 1⋆η1/2+C 2⋆η1/4+C 3⋆e−C 4⋆nηT.
To obtain a non-asymptotic upper bound for the SGHMC algorithm, we set nT to n on the left-hand
sideoftheaboveinequality,whilenontheRHSoftheaboveinequalityissetton/T. Hence,forany
n ∈ N ,0 < η ≤ η withη givenin(9),onewrites
0 max max
W 2(cid:0) L(cid:0) θ¯ nη,V¯ nη(cid:1) ,π¯ β(cid:1) ≤ C 1⋆η1/2+C 2⋆η1/4+C 3⋆e−C 4⋆nη. (35)
Similarly,forWasserstein-1distance,weobtain
W 1(cid:0) L(cid:0) θ¯ nη,V¯ nη(cid:1) ,π¯ β(cid:1) ≤ (C∗+C 1⋆)η1/2+C 2∗e−C 3∗ηn. (36)
Moreover, for any ϵ > 0, if we choose η and n such that η ≤ η , C⋆η1/2 ≤ ϵ/3, C⋆η1/4 ≤ ϵ/3,
max 1 2
and C 3⋆e−C 4⋆nη ≤ ϵ/3, where η
max
is given in (9), then W 2(cid:0) L(cid:0) θ¯ nη,V¯ nη(cid:1) ,π¯ β(cid:1) ≤ ϵ. This further
implies that η ≤
min(cid:110) ϵ2
,
ϵ4
,η
(cid:111)
and nη ≥
ln(3C 3⋆/ϵ)
. Therefore, one can write n ≥
9C⋆2 81C⋆4 max C⋆
1 2 4 (cid:26) (cid:27)
ln(3C 3⋆/ϵ)
. Similarly,foranyϵ > 0,ifwechooseηandnsuchthatη ≤ min
ϵ2
,η
C 4⋆min(cid:26) 9Cϵ2 1⋆2,
81
(cid:26)ϵ C4 2⋆4,ηmax(cid:27)
(cid:27)
4(C∗+C 1⋆)2 max
andn ≥ max 4(C∗+C 1⋆)2 ln(2C 2∗/ϵ) , ln(2C 2∗/ϵ) ,thenW (cid:0) L(cid:0) θ¯η,V¯η(cid:1) ,π¯ (cid:1) ≤ ϵ. □
C 3∗ϵ2 C 3∗ηmax 1 n n β
Toprovideanon-asymptoticerrorboundfortheexpectedexcessrisk,weproceedwiththefollowing
decomposition:
E[u(θη)]− inf u(θ) = E[u(θη)]−E[u(θ )]+E[u(θ )]− inf u(θ), (37)
n n ∞ ∞
θ∈Rd (cid:124) (cid:123)(cid:122) (cid:125) θ∈Rd
T1 (cid:124) (cid:123)(cid:122) (cid:125)
T2
where θ is distributed according to π . We note that T depends on the sampling behavior of the
∞ β 1
SGHMCalgorithm,whichrelatestotheerrorinWasserstein-2distancebetweenthelawoftheSGHMC
algorithmandπ¯ . T isabouttheconcentrationpropertyofπ¯ andbecomessmallwhenthetemperature
β 2 β
parameterβ > 0islarge. ThefollowingtheorempresentsaboundforT underourassumptions.
120 L.LIANG,A.NEUFELD,ANDY.ZHANG
Lemma5.10. LetAssumptions1-4hold. Then,foreveryβ > 0,thereexistconstantsC¯⋆,C¯⋆,C¯⋆,C¯⋆ > 0
1 2 3 4
suchthat,foranyn ∈ N and0 ≤ η ≤ η withη givenin(9),wehave
0 max max
E[u(θ nη)]−E[u(θ ∞)] ≤ C¯ 1⋆η1/2+C¯ 2⋆η1/4+C¯ 3⋆e−C¯ 4⋆ηn,
where θ ∼ π and C¯⋆ := C⋆(LC +|h(0)|) with C := max(Cc,C ), for i = 1,2,3 and
∞ β i i m m θ θ
C¯⋆ := C⋆, and where C⋆, C⋆, C⋆, C⋆ are given explicitly in Table 1 while Cc and C are given
4 4 1 2 3 4 θ θ
explicitlyinTable4.
Proof. SeeAppendixC. □
Next,weboundthesecondtermT asfollows.
2
Lemma5.11. LetAssumptions1-4hold. Then,foranyβ > 0,wehave
(cid:18) (cid:18) (cid:19)(cid:19)
d 8eL A
E[u(θ )]− inf u(θ) ≤ log c +1 ,
∞ θ∈Rd 2β γ2λ(1−2λ) d
whereA isexplicitlygiveninRemark2.4.
c
Proof. SeeAppendixC. □
ProofofTheorem3.3. Substituting the results in Lemma 5.10 and Lemma 5.11 into (37) yields the
desired non-asymptotic upper bound. Moreover, for any ϵ > 0, if we choose β, η, and n such that
(cid:16) (cid:17)
η ≤ η max, C¯ 1⋆η1/2 ≤ ϵ/4, C¯ 2⋆η1/4 ≤ ϵ/4, C¯ 3⋆e−C¯ 4⋆nη ≤ ϵ/4, and 2d
β
log γ2λ8 (1e −L
2λ)
(cid:0)A dc +1(cid:1) ≤
ϵ/4, where η is given in (9), then E[u(θ )] − inf u(θ) ≤ ϵ. Calculations yield that η ≤
max ∞ θ∈Rd
min(cid:110) ϵ2
,
ϵ4
,η
(cid:111)
and ηn ≥
ln(4C¯ 3⋆/ϵ)
, which implies that n ≥
ln(4C¯ 3⋆/ϵ)
.
16C¯ 1⋆2 256C¯ 2⋆4 max C¯ 4⋆
(cid:16)
C¯ 4⋆min(cid:26) 16ϵ C¯2 1⋆2, 256ϵ C4
¯ 2⋆
(cid:17)4,ηmax(cid:27)
Furthermore,werecallthatA := β(λu(0)+λL|h(0)|+b′/2),then, d log 8eL (cid:0)Ac +1(cid:1) ≤ ϵ/4
c 2β γ2λ(1−2λ) d
(cid:110) (cid:16) (cid:16) (cid:17)(cid:17)(cid:111)
isachievedifwechooseβ ≥ max 16d2 , 4d log 8eL λu(0)+λL|h(0)|+b′/2 +1 . Indeed, for
ϵ2 ϵ γ2λ(1−2λ) d
anyβ > 0,wehave
(cid:18) (cid:18) (cid:19)(cid:19)
d 8eL A
c
log +1
2β γ2λ(1−2λ) d
d (cid:18) 8eL (cid:18) λu(0)+λL|h(0)|+b′/2 (cid:19)(cid:19) d
≤ log +1 + log(β +1)
2β γ2λ(1−2λ) d 2β
1 (cid:18) d (cid:18) 8eL (cid:18) λu(0)+λL|h(0)|+b′/2 (cid:19)(cid:19)(cid:19) d
≤ log +1 + √
β 2 γ2λ(1−2λ) d 2 β
≤ ϵ/8+ϵ/8 = ϵ/4,
√ √
wherethesecondinequalityholdsduetolog(β +1)/β ≤ 1/ β +1 ≤ 1/ β foranyβ > 0. □21
APPENDIXA. PROOFS OF SECTION 2
ProofofRemark2.1. ByusingAssumption1,weobtain,forany(θ,x) ∈ Rd×Rm,
|H(θ,x)−H(0,0)| ≤|F(θ,x)−F(0,0)|+|G(θ,x)−G(0,0)|
≤(1+|x|)ρ(L |θ|+L |x|)+K¯ (0)+K¯ (x)
1 2 1 1
≤(1+|x|)ρ+1(L |θ|+L )+K¯ (0)+K¯ (x).
1 2 1 1
Hence,lettingF (x) := 2K¯ (0)+K¯ (x)+|F(0,0)|,wehave
∗ 1 1
|H(θ,x)| ≤(1+|x|)ρ+1(L |θ|+L )+2K¯ (0)+K¯ (x)+|F(0,0)|
1 2 1 1
=(1+|x|)ρ+1(L |θ|+L )+F (x).
1 2 ∗
□
ProofofRemark2.3. ByAssumption1and4,forany(θ,x) ∈ Rd×Rm,wehave
⟨θ,H(θ,x)⟩ =⟨θ,F(θ,x)⟩+⟨θ,G(θ,x)⟩
≥⟨θ,A(x)θ⟩−B(x)−K¯ (x)|θ|.
1
Then,byusingAssumption2andCauchy-Schwarzinequality,weobtain
⟨θ,h(θ)⟩ ≥a|θ|2−b−E(cid:2) K¯ (X )(cid:3) |θ|
1 0
≥a|θ|2−b− a |θ|2− 1 (E(cid:2) (K¯ (X ))(cid:3) )2
1 0
2 2a
:=a′|θ|2−b′,
wherea′ := a andb′ := b+ 1 (E(cid:2) (K¯ (X ))(cid:3) )2. □
2 2a 1 0
ProofofRemark2.4. Denotebyu¯(t) := u(tθ),t ∈ [0,1]. Notethatforanyθ ∈ Rd,u¯′(t) := ⟨θ,h(tθ)⟩,
and
u(θ)−u(0) =u¯(1)−u¯(0)
(cid:90) 1
= ⟨θ,h(tθ)⟩dt
0
(cid:90) 1
≤ |θ||h(tθ)|dt
(38)
0
(cid:90) 1
≤ |θ|L(t|θ|+|h(0)|)dt
0
L
= |θ|2+L|h(0)||θ|,
2
(cid:26) (cid:27)
where the second inequality holds due to Remark 2.2. Define λ := min 1, a′ . By
4 L+2L|h(0)|+γ2
2
using(38)andRemark2.3,wehave,foranyθ ∈ Rd,that
⟨h(θ),θ⟩ ≥ a′|θ|2−b′
(cid:18)
L
γ2(cid:19)
≥ 2λ +L|h(0)|+ |θ|2−b′
2 4
(cid:18) L γ2 (cid:19)
= 2λ |θ|2+L|h(0)||θ|−L|h(0)||θ|+L|h(0)||θ|2+ |θ|2 −b′
2 4
(cid:18) γ2 (cid:19)
≥ 2λ u(θ)−u(0)−L|h(0)||θ|+L|h(0)||θ|2+ |θ|2 −b′
4
(cid:18) γ2 (cid:19)
≥ 2λ u(θ)−u(0)−L|h(0)|+ |θ|2 −b′
4
(cid:18) γ2 (cid:19) A
= 2λ u(θ)+ |θ|2 −2 c
4 β
withA := β(2λu(0)+2λL|h(0)|+b′),wherethelastinequalityholdsdueto|θ| ≤ 1+|θ|2. □
c 222 L.LIANG,A.NEUFELD,ANDY.ZHANG
APPENDIXB. PROOFS OF SECTION 3
ProofofLemma5.2. RecalltheLyapunovfunctiondefinedin(30),i.e.,foranyθ,v ∈ Rd,
β
V(θ,v) = βu(θ)+ γ2(|θ+γ−1v|2+|γ−1v|2−λ|θ|2).
4
Nowwedefinetheoperator
A := −⟨γv+h(θ),∇ ⟩+γβ−1∆ +⟨v,∇ ⟩. (39)
v v θ
Followingsimilarargumentsasin[15,Lemma2.2],byusingAssumption4,Remark2.2,andRemark2.4,
wehave
AV ≤ γ(d+A −λV).
c
Indeed,byusing(39),wehavethatAu(θ) = ⟨v,h(θ)⟩,A|θ|2 = 2⟨θ,v⟩,and
(cid:18) 1 (cid:19) 1 γ d |v|2 ⟨h(θ),v⟩
A |γ−1v|2 = − ⟨γv+h(θ),∇ |γ−1v|2⟩+ ∆ |γ−1v|2 = − − ,
2 2 v 2β v γβ γ γ2
(cid:18) 1 (cid:19) d ⟨h(θ),vγ−1+θ⟩
A |θ+γ−1v|2 = − .
2 γβ γ
Thisimpliesthat
βγ2 (cid:18) d d |v|2 ⟨h(θ),v⟩ (cid:19)
AV(θ,v) = β⟨v,h(θ)⟩+ −⟨h(θ),(vγ−1+θ)γ−1⟩+ − − −λ⟨θ,v⟩
2 γβ γβ γ γ2
(cid:18) (cid:19)
≤ γ d+A −λβu(θ)−
1 λβγ2(cid:0) |θ|2+2λ−1|γ−1v|2+2⟨θ,γ−1v⟩(cid:1)
c
4
(cid:18) (cid:19)
≤ γ d+A −λβu(θ)−
1 λβγ2(cid:0) (1−λ)|θ|2+2|γ−1v|2+2⟨θ,γ−1v⟩(cid:1)
c
4
= γ(d+A −λV(θ,v)),
c
(40)
wherethefirstinequalityholdsduetoRemark2.4,andthesecondinequalityholdsdueto0 < λ ≤ 1.
4
Moreover,byapplyingItoˆ formula,weobtain
(cid:18) (cid:19)
(cid:16) (cid:17) βγ (cid:112)
d eλγtV(θ ,V ) = λγeλγtV(θ ,V )dt+eλγtAV(θ ,V )dt+eλγt βV + θ 2γβ−1dB .
t t t t t t t t t
2
Hence,
(cid:90) t (cid:90) t (cid:18) βγ (cid:19) (cid:112)
eλγtV(θ ,V ) ≤ V(θ ,V )+γ(d+A ) eλγsdt− eλγs βV + θ 2γβ−1dB . (41)
t t 0 0 c s s s
2
0 0
Note that by Remark 2.2, SDE (26) has a unique strong solution. By [37, Theorem 5.2.1], for every
T > 0,wehavethat
(cid:20)(cid:90) T (cid:21)
E (cid:0) |V |2+|θ |2(cid:1) ds < ∞.
s s
0
Hence,
E(cid:34) (cid:90) T e2λγs(cid:12) (cid:12)
(cid:12)βV s+
βγ
θ
s(cid:12) (cid:12) (cid:12)2 2γ ds(cid:35)
< ∞,
(cid:12) 2 (cid:12) β
0
implying
(cid:20)(cid:90) T (cid:18) βγ (cid:19)(cid:114) 2γ (cid:21)
E eλγs βγ(s)+ θ(s) dB = 0.
s
2 β
0
Foreacht > 0,denoteL(t) := E[V(θ ,V )]. Byusing(41),weobtain
t t
d+A (cid:16) (cid:17)
L(t) ≤ L(0)e−λγt+ 1−e−λγt . (42)
λ23
Inaddition,notethat
β
V(θ,v) = βu(θ)+ γ2(|θ+γ−1v|2+|γ−1v|2−λ|θ+γ−1v−γ−1v|2)
4
β
≥ βu(θ)+ γ2(|θ+γ−1v|2+|γ−1v|2−2λ(|θ+γ−1v|2+|γ−1v|2)
4
(43)
β
= βu(θ)+ γ2(1−2λ)(|θ+γ−1v|2+|γ−1v|2)
4
(cid:26) βγ2 βγ2 (cid:27)
≥ max (1−2λ)|θ|2, (1−2λ)|γ−1v|2 .
8 4
Thus,combiningtheaboveresult(43)with(42)yields
β d+A
(1−2λ)γ2E∥θ ∥2 ≤ E[V(θ ,V )]+ c ,
t 0 0
8 λ
β d+A
(1−2λ)E∥V ∥2 ≤ E[V(θ ,V )]+ c .
t 0 0
4 λ
□
ProofofLemma5.3. ByusingRemark2.1andthefactthatX isindependentofθη andVη ,wehave
k+1 k k
(cid:104) (cid:105) (cid:104) (cid:105)
E(cid:2) |H(θη,X )|2(cid:3) ≤ 2E (1+|X |)2(ρ+1)L2|θη|2 +4E (1+|X |)2(ρ+1)L2+F2(X )
k k+1 k+1 1 k k+1 2 ∗ k+1
(cid:20) (cid:20) (cid:12) (cid:21)(cid:21)
= 2E |θ kη|2E (1+|X k+1|)2(ρ+1)L2 1(cid:12) (cid:12) (cid:12)θ kη +4E(cid:104) (1+|X 0|)2(ρ+1)L2 2+F ∗2(X 0)(cid:105)
(cid:104) (cid:105) (cid:104) (cid:105)
= 2L2E (1+|X |)2(ρ+1) E(cid:2) |θη|2(cid:3) +4L2E (1+|X |)2(ρ+1) +4E(cid:2) F2(X )(cid:3)
1 0 k 2 0 ∗ 0
=
L(cid:101)1E(cid:2)
|θ
kη|2(cid:3)
+C(cid:101)1,
(44)
where L(cid:101)1 := 2L2 1E(cid:2) (1+|X 0|)2(ρ+1)](cid:3) , C(cid:101)1 := 4L2 2E(cid:2) (1+|X 0|)2(ρ+1)(cid:3) +4E(cid:2) F ∗(X 0)2(cid:3) . Recall the
SGHMCalgorithmgivenin(7)and(8),andusing(44)yields
E(cid:2) |Vη |2(cid:3) = E(cid:2) |(1−γη)Vη −ηH(θη,X )|2(cid:3) +2γηβ−1d
k+1 k k k+1
= (1−γη)2E(cid:2) |Vη|2(cid:3) −2η(1−γη)E(cid:2) ⟨Vη,h(θη)⟩(cid:3) +η2E(cid:2) |H(θη,X )|2(cid:3) +2γηβ−1d
k k k k k+1
(cid:104) (cid:105)
≤ (1−γη)2E(cid:2) |V kη|2(cid:3) −2η(1−γη)E(cid:2) ⟨V kη,h(θ kη)⟩(cid:3) +η2 L(cid:101)1E(cid:2) |θ kη|2(cid:3) +C(cid:101)1 +2γηβ−1d,
(45)
wherethesecondequalityholdsduetothefactthatX isindependentofθη andVη ,andthat
k+1 k k
E(cid:2) ⟨Vη,H(θη,X )⟩(cid:3) = E(cid:2)E(cid:2) ⟨Vη,H(θη,X )⟩|θη,Vη(cid:3)(cid:3) = E(cid:2) ⟨Vη,h(θη)⟩(cid:3) .
k k k+1 k k k+1 k k k k
Moreover,denoteUˆ := U(θη +tηVη),t ∈ [0,1]. WeobservethatUˆ′(t) = ⟨h(θη +tηVη),ηVη⟩,and
t k k k k k
that,byusing(8),u(θη )−u(θη) = uˆ(1)−uˆ(0) = (cid:82)1 uˆ′(t)dt. Thus,byRemark2.2,
k+1 k 0
(cid:12)(cid:90) 1 (cid:12)
u(θη )−u(θη) ≤ (cid:12) (cid:12) ⟨h(θη +τηVη)−h(θη),ηVη⟩dτ(cid:12) (cid:12)
k+1 k (cid:12) k k k k (cid:12)
0
(cid:90) 1
≤ (cid:12) (cid:12)h(θη +τηVη)−h(θη)(cid:12) (cid:12)(cid:12) (cid:12)ηVη(cid:12) (cid:12)dτ
k k k k
0 (46)
(cid:90) 1
≤ Lτ|ηVη|2dτ
k
0
L
= η2|Vη|2.
2 k
Theaboveresultimplies
E(cid:2) u(θη )(cid:3) −E(cid:2) u(θη)(cid:3) ≤ ηE(cid:2) ⟨h(θη),Vη⟩(cid:3) + L η2|Vη|2. (47)
k+1 k k k 2 k
Then,noticethat
E(cid:2) |θη |2(cid:3) = E(cid:2) |θη|2(cid:3) +2ηE(cid:2) (θη,Vη)(cid:3) +η2E(cid:2) |Vη|2(cid:3) . (48)
k+1 k k k k24 L.LIANG,A.NEUFELD,ANDY.ZHANG
Furthermore,by(7)and(8),wehavethat
E(cid:104)(cid:12) (cid:12)θ kη +1+γ−1V kη +1(cid:12) (cid:12)2(cid:105) = E(cid:104)(cid:12) (cid:12)θ kη +γ−1V kη −ηγ−1H(cid:0) θ kη,X k+1(cid:1)(cid:12) (cid:12)2(cid:105) +2γ−1β−1ηd
= E(cid:104)(cid:12) (cid:12)θη +γ−1Vη(cid:12) (cid:12)2(cid:105) −2ηγ−1E(cid:2)(cid:10) θη +γ−1Vη,h(cid:0) θη(cid:1)(cid:11)(cid:3)
k k k k k
+η2γ−2E(cid:104)(cid:12) (cid:12)H(cid:0) θ kη,X k+1(cid:1)(cid:12) (cid:12)2(cid:105) +2γ−1ηβ−1d (49)
≤ E(cid:104)(cid:12) (cid:12)θη +γ−1Vη(cid:12) (cid:12)2(cid:105) −2ηγ−1E(cid:2)(cid:10) θη +γ−1Vη,h(cid:0) θη(cid:1)(cid:11)(cid:3)
k k k k k
+η2γ−2(cid:16) L(cid:101)1E(cid:104)(cid:12) (cid:12)θ kη(cid:12) (cid:12)2(cid:105) +C(cid:101)1(cid:17) +2γ−1ηβ−1d,
wherethelastinequalityholdsdueto(44). Nextwedefine,foranyk ∈ N ,
0
E(cid:2) V(θη,Vη)(cid:3) (cid:20) γ2 (cid:21)
M (k) := k k = E U(θη)+ (|θη +γ−1Vη|2+|γ−1Vη|2−λ|θη|2) . (50)
2 β k 4 k k k k
Byusing(45),(47),(48)and(49),wehave
M (k+1)−M (k) = E(cid:2) U(θη )(cid:3) −E(cid:2) U(θη)(cid:3) +
γ2
(cid:0)E(cid:2) |θη +γ−1Vη |2(cid:3) −E(cid:2) |θη +γ−1Vη|2(cid:3)(cid:1)
2 2 k+1 k 4 k+1 k+1 k k
+ 1 (cid:0)E(cid:2) |Vη |2(cid:3) −E(cid:2) |Vη|2(cid:3)(cid:1) − γ2λ (cid:0)E(cid:2) |θη |2(cid:3) −E(cid:2) |θη|2(cid:3)(cid:1)
4 k+1 k 4 k+1 k
≤ ηE(cid:2) ⟨h(θη),Vη⟩(cid:3) + L η2E(cid:2) |Vη|2(cid:3) +
γ2(cid:18)
−2ηγ−1E(cid:2) ⟨θη +γ−1Vη,h(cid:0) θη(cid:1) ⟩(cid:3)
k k 2 k 4 k k k
(cid:19)
+η2γ−2(cid:16) L(cid:101)1E(cid:12) (cid:12)θ kη(cid:12) (cid:12)2 +C(cid:101)1(cid:17) +2γ−1ηβ−1d + 41 (−2γη+γ2η2)E(cid:2) |V kη|2(cid:3)
+ 41 (cid:16) −2η(1−γη)E(cid:2) ⟨V kη,h(θ kη)⟩(cid:3) +η2(cid:104) L(cid:101)1E(cid:2) |θ kη|2(cid:3) +C(cid:101)1(cid:105) +2γηβ−1d(cid:17)
−
γ2λ
(cid:0) 2ηE(cid:2) ⟨θη,Vη⟩(cid:3) +η2E(cid:2) |Vη|2(cid:3)(cid:1)
.
4 k k k
Then,weobtain
M (k+1)−M (k) ≤
γη2 E(cid:2) ⟨h(θη),Vη⟩(cid:3)
−
γη E(cid:2) ⟨h(θη),θη⟩(cid:3)
+
η2L(cid:101)1E(cid:2) |θη|2(cid:3)
−
γ2ηλ E(cid:2) ⟨θη,Vη⟩(cid:3)
2 2 2 k k 2 k k 2 k 2 k k
+(cid:18) Lη2 − ηγ + γ2η2 − λγ2η2(cid:19) E(cid:2) |Vη|2(cid:3) + C(cid:101)1η2 +γηβ−1d
2 2 4 4 k 2
≤ −ηγλE(cid:2) u(θη)(cid:3) −
λγ3η
E(cid:2) |θη|2(cid:3) +A γηβ−1
k 4 k c
+(cid:18) Lη2
−
ηγ
+
γ2η2
−
λγ2η2(cid:19) E(cid:2) |Vη|2(cid:3)
+
γη2 E(cid:2) ⟨h(θη),Vη⟩(cid:3)
2 2 4 4 k 2 k k
+
η2L(cid:101)1E(cid:2)
|θη|2(cid:3) −
γ2ηλ
E(cid:2) ⟨θη,Vη⟩(cid:3) +
C(cid:101)1η2
+γηβ−1d,
2 k 2 k k 2
(51)
wherethelastinequalityholdsduetoRemark2.4. Byusing0 < λ ≤ 1,weobtain
4
M (k) =
E(cid:20)
u(θη)+
γ2
(cid:0)
|θη|2+2γ−1⟨θη,Vη⟩+2γ−2|Vη|2−λ|θη|2(cid:1)(cid:21)
2 k 4 k k k k k
≤
E(cid:2) u(θη)(cid:3)
+
γ2 E(cid:2) |θη|2(cid:3)
+
γ E(cid:2) ⟨θη,Vη⟩(cid:3)
+
1 E(cid:2) |Vη|2(cid:3)
,
k 4 k 2 k k 2 k
whichimplies,byrearrangingtheterms,that
−γ E(cid:2) ⟨θη,Vη⟩(cid:3) ≤ −M (k)+E(cid:2) U(θη)(cid:3) + γ2 E(cid:2) |θη|2(cid:3) + 1 E(cid:2) |Vη|2(cid:3) . (52)
2 k k 2 k 4 k 2 k25
Combiningtheresultin(51)and(52),weobtain
M (k+1) ≤ (1−λγη)M (k)+A γηβ−1+
γη2
E(cid:2) ⟨h(θη),Vη⟩(cid:3) +
η2L(cid:101)1E(cid:2)
|θη|2(cid:3) +γηβ−1d
2 2 c 2 k k 2 k
+
C(cid:101)1η2 +(cid:18) Lη2
−
ηγ
+
γ2η2
−
λγ2η2
+
ληγ(cid:19) E(cid:2) |Vη|2(cid:3)
2 2 2 4 4 2 k
≤ (1−λγη)M 2(k)+A cγηβ−1+ η 22 (γL2+L(cid:101)1)E(cid:2) |θ kη|2(cid:3) + γ 2η2 |h(0)|2+γηβ−1d
+
C(cid:101)1η2 +(cid:18) Lη2
−
ηγ
+
γ2η2
−
λγ2η2
+
ληγ
+
γη2(cid:19) E(cid:2) |Vη|2(cid:3)
2 2 2 4 4 2 4 k
≤ (1−λγη)M 2(k)+A cγηβ−1+ η 22 (γL2+L(cid:101)1)E(cid:2) |θ kη|2(cid:3) + γ 2η2 |h(0)|2+γηβ−1d
+
C(cid:101)1η2 +η2(cid:18) L
+
γ2
−
λγ2
+
γ(cid:19) E(cid:2) |Vη|2(cid:3)
,
2 2 4 4 4 k
(53)
wherethesecondinequalityholdsduetoRemark2.2and⟨a,b⟩ ≤ (|a|2+|b|2) witha = h(θη)andb = Vη ,
2 k k
and where the last inequality holds due to 0 < λ ≤ 1. By (43) and the fact that max{a,b} ≥ a+b,
4 2
a,b ∈ R,wehavethat
M (k) ≥
max(cid:26) γ2 (1−2λ)E(cid:2) |θη|2(cid:3)
,
1 (1−2λ)|E(cid:2) Vη|2(cid:3)(cid:27)
2 8 k 4 k
(54)
≥
γ2 (1−2λ)E(cid:2) |θη|2(cid:3)
+
1 (1−2λ)|E(cid:2) Vη|2(cid:3)
.
16 k 8 k
Bydenoting
K :=
1 max(cid:40) L(cid:101)1+γL2
,
L+ γ 22 − γ2 2λ + γ 2(cid:41)
, (55)
1 2 γ2 (1−2λ) 1(1−2λ)
16 8
wehavethat
2K 1η2M 2(k) ≥ η2(L(cid:101)1+γL2)E(cid:2) |θ kη|2(cid:3) +η2(L+ γ 22 − γ 22λ + γ 2)E(cid:2) |V kη|2(cid:3) .
This,togetherwith(53),yields
M (k+1) ≤ (1−γλη+K η2)M (k)+K η2+K η,
2 1 2 2 3
where
γ|h(0)|2+C(cid:101)1
K := (56)
2
2
and
K := γ(d+A )β−1. (57)
3 c
(cid:110) (cid:111)
Therefore,for0 < η ≤ min K3, γλ andη ≤ 2/γλ(impliedbyη ≤ 2/γ andλ ≤ 1/4),wehave
K2 2K1
(cid:18) γλη(cid:19) 1−(1− γλη)k 4
M (k+1) ≤ 1− M (k)+2K η ≤ M (0)+2ηK 2 ≤ M (0)+ K .
2 2 2 3 2 3 1−(1− γλη) 2 γλ 3
2
(58)
Byusing(54)and(58),wehenceobtain
supE(cid:104)(cid:12)
(cid:12)θ
kη(cid:12) (cid:12)2(cid:105)
≤ C
θ
:=
(cid:82)
R2dV(θ,v 1) (µ 10 −(d 2θ λ, )d βv γ) 2+
4(d+ λAc)
,
t≥0 8
supE(cid:104)(cid:12)
(cid:12)V
kη(cid:12) (cid:12)2(cid:105)
≤ C
v
:=
(cid:82)
R2dV(θ,v) 1µ (0 1( −dθ 2, λd )v β)+
4(d+ λAc)
.
t≥0 4
□26 L.LIANG,A.NEUFELD,ANDY.ZHANG
ProofofLemma5.4.
Recalltheprocess(cid:0) ζ¯η,n(cid:1)
definedinDefinition5.1. AccordingtoLemma5.2,
t t≥nT
foranyn ∈ N ,wehave
0
sup
E(cid:104)(cid:12) (cid:12)ζ¯η,n(cid:12) (cid:12)2(cid:105)
≤
E(cid:2) V(θ¯ nη T,V¯ nη T)(cid:3) + (d+ λAc)
.
t 1(1−2λ)βγ2
t∈[nT,(n+1)T] 8
ByusingtheexpressionofM (k),k ∈ N ,definedin(50),wehave
2 0
E(cid:2) V(θ¯η ,V¯η )(cid:3) = βM (nT) ≤ βM (0)+ 4 βK ≤ βM (0)+ 4(A c+d) =: c˜ , (59)
nT nT 2 2 λγ 3 2 λ 10
whichimpliesthat,
sup
E(cid:104)(cid:12) (cid:12)ζ¯η,n(cid:12) (cid:12)2(cid:105)
≤
βM 2(0)+ 5(d+ λAc)
=
(cid:82) R2dV(θ,v)µ 0(dθ,dv)+ 5(d+ λAc)
.
t 1(1−2λ)βγ2 1(1−2λ)βγ2
t∈[nT,(n+1)T] 8 8
Hence,weconcludethat
ns ∈u Np 0t∈[nTs ,u (np +1)T]E(cid:104)(cid:12) (cid:12)ζ¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ C
ζ
:=
(cid:82)
R2dV(θ,v
1
8() 1µ 0 −(d 2θ λ, )d βv γ) 2+
5(d+ λAc)
.
Similarly,recallingtheprocess(cid:0) Z¯η,n(cid:1)
andLemma5.2,weobtain
t t≥nT
sup
E(cid:104)(cid:12) (cid:12)Z¯η,n(cid:12) (cid:12)2(cid:105)
≤
E(cid:2) V(cid:0) θ¯ nη T,V¯ nη T(cid:1)(cid:3) + (d+ λAc)
.
t 1(1−2λ)β
t∈[nT,(n+1)T] 4
Byusing(59)yields
sup
E(cid:104)(cid:12) (cid:12)Z¯η,n(cid:12) (cid:12)2(cid:105)
≤
βM 2(0)+ 5(d+ λAc)
=
(cid:82) R2dV(θ,v)µ 0(dθ,dv)+ 5(d+ λAc)
.
t 1(1−2λ)β 1(1−2λ)β
t∈[nT,(n+1)T] 4 4
Therefore,wehave
ns ∈u Np 0t∈[nTs ,u (np +1)T]E(cid:104)(cid:12) (cid:12)Z¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ C
Z
:=
(cid:82)
R2dV(θ,v
1
4)µ (10( −dθ 2, λd )v β)+
5(d+ λAc)
.
□
ProofofLemma5.5. Inthisproof,wefollowasimilarstrategytotheproofofLemma5.2. Denoteby
∆1 := (1−ηγ)Vη −ηH(θη,X ), ∆2 := θη +γ−1Vη −γ−1ηH(θη,X ). (60)
k k k k+1 k k k k k+1
RecallSGHMCalgorithm(7)and(8). Byusing(8),weobtain
|θη |2 = |θη|+2η⟨θη,Vη⟩+η2|Vη|2. (61)
k+1 k k k k
Moreover,byusing(7),wehave
|Vη |2 = |∆1|2+2(cid:112) 2ηγ/β⟨∆1,ξ ⟩+ 2ηγ ξ2
k+1 k k k+1 β k+1
= (1−ηγ)2|Vη|2−2η(1−ηγ)⟨Vη,H(θη,X )⟩+η2|H(θη,X )|2 (62)
k k k k+1 k k+1
(cid:112) 2ηγ
+2 2ηγ/β⟨∆1,ξ ⟩+ ξ2 .
k k+1 β k+1
Wefurthernotethat
|θη +γ−1Vη |2 = |θη +γ−1Vη −γ−1ηH(θη,X )+γ−1(cid:112) 2γη/βξ |2
k+1 k+1 k k k k+1 k+1
2η
= |θη +γ−1Vη|2+ |ξ |2−2ηγ−1⟨θη +γ−1Vη,H(θη,X )⟩ (63)
k k γβ k+1 k k k k+1
+2(cid:112) 2γ−1β−1η⟨∆2,ξ ⟩+η2γ−2|H(θη,X )|2.
k k+1 k k+1
Using(46),weobtainthat
Lη2
u(θη )−u(θη) ≤ η⟨h(θη),Vη⟩+ |Vη|2. (64)
k+1 k k k 2 k27
Denoteby
γ2 (cid:112) 1(cid:112)
Σ := 2γ−1β−1η⟨∆2,ξ ⟩+ 2ηγ/β⟨∆1,ξ ⟩, (65)
k 2 k k+1 2 k k+1
and for the ease of notation, we denote by V :=
V(cid:0) θη,Vη(cid:1)
. By using (61), (62), (63), and (64), we
k k k
obtain
(V −V )/β = U(θη )−U(θη)+
γ2
(cid:2) |θη +γ−1Vη |2−|θη +γ−1Vη|2(cid:3)
k+1 k k+1 k 4 k+1 k+1 k k
+
γ2
(cid:2) |γ−1Vη |2−|γ−1Vη|2−λ(|θη |2−|θη|2)(cid:3)
4 k+1 k k+1 k
Lη2 γ2(cid:20) 2η
≤ η⟨h(θη),Vη⟩+ |Vη|2+ |ξ |2−2ηγ−1⟨θη +γ−1Vη,H(θη,X )⟩
k k 2 k 4 γβ k+1 k k k k+1
(cid:21) (cid:20)
1
+η2γ−2|H(θη,X )|2 + (−2ηγ +η2γ2)|Vη|2−2η(1−ηγ)⟨Vη,H(θη,X )⟩
k k+1 4 k k k k+1
+η2|H(θη,X )|2+ 2ηγ |ξ |2(cid:21) − γ2λ (cid:2) 2η⟨θη,Vη⟩+η2|Vη|2(cid:3) +Σ
k k+1 β k+1 4 k k k k
ηγ (cid:18) Lη2 ηγ γ2η2 η2γ2λ(cid:19)
≤ − ⟨θη,H(θη,X )⟩+η⟨h(θη),Vη⟩+ − + − |Vη|2
2 k k k+1 k k 2 2 4 4 k
η2 (cid:18) γη2 (cid:19)
+ |H(θη,X )|2+γηβ−1|ξ |2+ −η ⟨Vη,H(θη,X )⟩
2 k k+1 k+1 2 k k k+1
γ2λη
− ⟨θη,Vη⟩+Σ .
2 k k k
(66)
Usingthefactthat0 < λ ≤ 1 andtheexpressionofLyapunovfunction(30),wehavethat
4
γ γ2 1
− ⟨θη,Vη⟩ ≤ −V /β +U(θη)+ |θη|2+ |Vη|2. (67)
2 k k k k 4 k 2 k
Hence,substituting(67)into(66)yields
ηγ
(V −V )/β ≤ − ⟨θη,H(θη,X )⟩+η⟨h(θη)−H(θη,X ),Vη⟩
k+1 k 2 k k k+1 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη(cid:19) η2
+ − + − + |Vη|2+ |H(θη,X )|2+γηβ−1|ξ |2
2 2 4 4 2 k 2 k k+1 k+1
+
γη2
(cid:10) Vη,H(θη,X )(cid:11) −γληV /β +ληγU(θη)+
γ3λη
|θη|2+Σ .
2 k k k+1 k k 4 k k
Then,byrearrangingtheterms,wearriveat
V /β ≤ (1−γλη)V /β − ηγ ⟨θη,H(θη,X )⟩+η(cid:10) h(θη)−H(θη,X ),Vη(cid:11)
k+1 k 2 k k k+1 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη(cid:19) η2
+ − + − + |Vη|2+ |H(θη,X )|2+γηβ−1|ξ |2
2 2 4 4 2 k 2 k k+1 k+1
γη2 γ3λη
+ ⟨Vη,H(θη,X )⟩+ληγU(θη)+ |θη|2+Σ
2 k k k+1 k 4 k k
ηγ ηγ
= (1−γλη)V /β − ⟨θη,h(θη)⟩+ ⟨θη,h(θη)−H(θη,X )⟩+η⟨h(θη)−H(θη,X ),Vη⟩
k 2 k k 2 k k k k+1 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη(cid:19) η2
+ − + − + |Vη|2+ |H(θη,X )|2+γηβ−1|ξ |2
2 2 4 4 2 k 2 k k+1 k+1
γη2 γ3λη
+ ⟨Vη,H(θη,X )⟩+ληγU(θη)+ |θη|2+Σ
2 k k k+1 k 4 k k
γ3λη ηγ
≤ (1−γλη)V /β −λγηU(θη)− |θη|2+ηγβ−1A − ⟨θη,H(θη,X )−h(θη)⟩
k k 4 k c 2 k k k+1 k
(cid:68) (cid:16)ηγ (cid:17) (cid:69) (cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη(cid:19)
+η h(θη)+ −1 H(θη,X ),Vη + − + − + |Vη|2
k 2 k k+1 k 2 2 4 4 2 k28 L.LIANG,A.NEUFELD,ANDY.ZHANG
η2 γ3λη
+ |H(θη,X )|2+γηβ−1|ξ |2+ληγU(θη)+ |θη|2+Σ ,
2 k k+1 k+1 k 4 k k
wherethelastinequalityholdsduetoRemark2.4. Then,
ηγ
V /β ≤ (1−γλη)V /β +ηγβ−1A − ⟨θη,H(θη,X )−h(θη)⟩
k+1 k c 2 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη(cid:19)
+η⟨h(θη)−H(θη,X ),Vη⟩+ − + − + |Vη|2
k k k+1 k 2 2 4 4 2 k
η2 η2γ
+ |H(θη,X )|2+γηβ−1|ξ |2+Σ + ⟨H(θη,X ),Vη⟩
2 k k+1 k+1 k 2 k k+1 k
ηγ
≤ (1−γλη)V /β +ηγβ−1A − ⟨θη,H(θη,X )−h(θη)⟩
k c 2 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη η2γ(cid:19)
+η⟨h(θη)−H(θη,X ),Vη⟩+ − + − + + |Vη|2
k k k+1 k 2 2 4 4 2 4 k
η2 η2γ
+( + )|H(θη,X )|2+γηβ−1|ξ |2+Σ ,
2 4 k k+1 k+1 k
(68)
wherethelastinequalityholdsdueto⟨a,b⟩ ≤ |a|2+|b|2 , fora,b ∈ Rd. Byusing(43)andthefactthat
2
max{x,y} ≥ (x+y)/2,foranyx,y ≥ 0,weobtain
(cid:26) γ2 1 (cid:27)
V(θη,Vη)/β ≥max (1−2λ)|θη|2, (1−2λ)|Vη|2 ,
k k 8 k 4 k
(69)
γ2 1
≥ (1−2λ)|θη|2+ (1−2λ)|Vη|2.
16 k 8 k
Denotebyϕ := (1−γλη)and
K˜ :=
max (cid:0) (1+ γ 2)L2 1E(cid:2) (1+|X 0|)2(ρ+1)(cid:3)(cid:1)
,
(cid:16) L 2η2 + γ2 4η2 − η2γ 42λ + η2 4γ(cid:17) 
.
1  γ 162 (1−2λ) 1 8(1−2λ) 
Theresultin(69)furtherimplies
(cid:16) γ(cid:17) (cid:104) (cid:105) (cid:18) Lη2 γ2η2 η2γ2λ η2γ(cid:19)
2ϕK˜ V /β ≥ 2ϕ 1+ E (1+|X |)2(ρ+1) L2|θη|2+2ϕ + − + |Vη|2.
1 k 2 0 1 k 2 4 4 4 k
(70)
Then,byusingRemark2.1,(65),(70),λ ≤ 1,andthefactthatξ isindependentof∆1 and∆2 ,we
4 k+1 k k
havethat
E(cid:2) V2 /β2(cid:12) (cid:12)θη,Vη(cid:3)
k+1 k k
(cid:18) (cid:18)
(cid:16) γ(cid:17) (cid:104) (cid:105)
≤ ϕ2V2/β2+2ϕV /β ηγβ−1A +γηβ−1d+η2 1+ E (1+|X |)2(ρ+1) L2|θη|2
k k c 2 0 1 k
+2E(cid:104)
(1+|X
|)2(ρ+1)(cid:105)
L2+2E(cid:2) F2(X
)(cid:3)(cid:19) +(cid:18) Lη2
+
γ2η2
−
η2γ2λ
+
η2γ(cid:19) |Vη|2(cid:19)
0 2 ∗ 0 2 4 4 4 k
(cid:34)(cid:32)
ηγ
+E ηγβ−1A + ⟨θη,h(θη)−H(θη,X )⟩+η⟨h(θη)−H(θη,X ),Vη⟩
c 2 k k k k+1 k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη η2γ(cid:19) (cid:18) η2 η2γ(cid:19)
+ − + − + + |Vη|2+ + |H(θη,X )|2
2 2 4 4 2 4 k 2 4 k k+1
(cid:33)2(cid:12) (cid:35)
(cid:12)
+γηβ−1|ξ |2+Σ (cid:12)θη,Vη
k+1 k (cid:12) k k
(cid:12)
(cid:18) (cid:19)
(cid:16) (cid:17) (cid:16) (cid:104) (cid:105) (cid:17)
≤ ϕ2+2ϕK˜ η2 V2/β2+2ϕV /β ηγβ−1A +γηβ−1d+η2(2+γ) E (1+|X |)2(ρ+1) L2+E(cid:2) F2(X )(cid:3)
1 k k c 0 2 ∗ 029
(cid:34)(cid:32)
ηγ
+E ηγβ−1A + ⟨θη,−H(θη,X )+h(θη)⟩+η⟨h(θη)−H(θη,X ),Vη⟩
c 2 k k k+1 k k k k+1 k
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη η2γ(cid:19)
+ − + − + + |Vη|2+γηβ−1|ξ |2+Σ
2 2 4 4 2 4 k k+1 k
(cid:18) η2γ(cid:19) (cid:16)
(cid:17)(cid:33)2(cid:12)
(cid:12)
(cid:35)
+ η2+ (1+|X |)2(ρ+1)L2|θη|2+2(1+|X |)2(ρ+1)L2+2F2(X ) (cid:12)θη,Vη .
2 k+1 1 k k+1 2 ∗ k+1 (cid:12) k k
(cid:12)
Thisfurtherimplies,byusing⟨a,b⟩ ≤ |a|2+|b|2 ,foranya,b ∈ Rd,that
2
E(cid:2) V2 /β2(cid:12) (cid:12)θη,Vη(cid:3)
k+1 k k
(cid:18)
(cid:16) (cid:17)
≤ ϕ2+2ϕK˜ η2 V2/β2+2ϕV /β ηγβ−1A +γηβ−1d
1 k k c
(cid:19)
(cid:16) (cid:104) (cid:105) (cid:17)
+η2(2+γ) E (1+|X |)2(ρ+1) L2+E(cid:2) F2(X )(cid:3)
0 2 ∗ 0
(cid:34)(cid:32)
+E ηγβ−1A + ηγ |θη|2+(cid:16)ηγ +η(cid:17) (cid:0) |h(θη)|2+|H(θη,X )|2(cid:1) +γηβ−1|ξ |2
c 4 k 2 k k k+1 k+1
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη η2γ η(cid:19)
+ − + − + + + |Vη|2+Σ
2 2 4 4 2 2 2 k k
(cid:18) η2γ(cid:19) (cid:16)
(cid:17)(cid:33)2(cid:12)
(cid:12)
(cid:35)
+ η2+ (1+|X |)2(ρ+1)L2|θη|2+2(1+|X |)2(ρ+1)L2+2F2(X ) (cid:12)θη,Vη .
2 k+1 1 k k+1 2 ∗ k+1 (cid:12) k k
(cid:12)
ByusingRemark2.1and2.2,wehave
E(cid:2) V2 /β2(cid:12) (cid:12)θη,Vη(cid:3)
k+1 k k
(cid:18) (cid:19)
(cid:16) (cid:17) (cid:16) (cid:104) (cid:105) (cid:17)
≤ ϕ2+2ϕK˜ η2 V2/β2+2ϕV /β ηγβ−1A +γηβ−1d+η2(2+γ) E (1+|X |)2(ρ+1) L2+E(cid:2) F2(X )(cid:3)
1 k k c 0 2 ∗ 0
(cid:34)(cid:32)
(cid:18)
ηγ (cid:16) γ(cid:17)
+E ηγβ−1A + |θη|2+η 1+ 2L2|θη|2+2|h(0)|2
c 4 k 2 k
(cid:19)
+2(1+|X |)2(ρ+1)L2|θη|2+4(1+|X |)2(ρ+1)L2+4F2(X ) +γηβ−1|ξ |2
k+1 1 k k+1 2 ∗ k+1 k+1
(cid:18) Lη2 ηγ γ2η2 η2γ2λ λγη η2γ η(cid:19)
+ − + − + + + |Vη|2+Σ
2 2 4 4 2 2 2 k k
γ (cid:18)
(cid:19)(cid:33)2(cid:12)
(cid:12)
(cid:35)
+η2(1+ ) (1+|X |)2(ρ+1)L2|θη|2+2(1+|X |)2(ρ+1)L2+2F2(X ) (cid:12)θη,Vη
2 k+1 1 k k+1 2 ∗ k+1 (cid:12) k k
(cid:12)
(cid:16) (cid:17) (cid:16) (cid:104) (cid:105) (cid:17)
= ϕ2+2ϕK˜ η2 V2/β2+2ϕη(γA +γd)V /β2+2ϕη2(2+γ) E (1+|X |)2(ρ+1) L2+E(cid:2) F2(X )(cid:3) V /β
1 k c k 0 2 ∗ 0 k
(cid:34)(cid:32)
+E η/β(cid:0) γA +γ|ξ |2(cid:1)
+η|θη|2(cid:16)γ +2(cid:16)
1+
γ(cid:17)
(L2+(1+|X
|)2(ρ+1)L2)(cid:17)
c k+1 k 4 2 k+1 1
(cid:18) (cid:19)
(cid:16) γ(cid:17) 1 λγ γ
+η2|θη|2 1+ (1+|X |)2(ρ+1)L2+η|Vη|2 + −
k 2 k+1 1 k 2 2 2
(cid:18) L γ2 λγ2 γ(cid:19) (cid:16) γ(cid:17)(cid:16) (cid:17)
+η2|Vη|2 + − + +Σ +η 1+ 2|h(0)|2+4(1+|X |)2(ρ+1)L2+4F2(X )
k 2 4 4 2 k 2 k+1 2 ∗ k+1
(cid:33)2(cid:12)
(cid:12) (cid:105)
+η2(2+γ)((1+|X |)2(ρ+1)L2+F2(X )) (cid:12)θη,Vη .
k+1 2 ∗ k+1 (cid:12) k k
(cid:12)30 L.LIANG,A.NEUFELD,ANDY.ZHANG
(cid:18) k (cid:19)2 k
Byusingthefactthat,foranyintegerk ≥ 2, (cid:80) X ≤ k (cid:80) X2,weobtain
i i
i=1 i=1
E(cid:2) V k2 +1/β2(cid:12) (cid:12)θ kη,V kη(cid:3) ≤ (cid:16) ϕ2+2ϕK˜ 1η2(cid:17) V k2/β2+2ϕηc˜ 1V k/β2+2ϕη2cˆ 1V k/β +η2β−2c˜ 2+η2|θ kη|4c˜
3
(cid:34) (cid:12) (cid:35)
(cid:12)
+η4|θη|4cˆ +η2|Vη|4c˜ +η4|Vη|4cˆ +η2c˜ +η4cˆ +8E Σ2(cid:12)θη,Vη ,
k 3 k 4 k 4 5 5 k(cid:12) k k
(cid:12)
(71)
where
(cid:16) (cid:104) (cid:105) (cid:17)
c˜ := γA +γd, cˆ = (2+γ) E (1+|X |)2(ρ+1) L2+E(cid:2) F2(X )(cid:3) ,
1 c 1 0 2 ∗ 0
c˜ := 16γ2A2+48γ2d2,
2 c
3 (cid:16) (cid:104) (cid:105)(cid:17)
c˜ := γ2+24(2+γ)2 L4+L4E (1+|X |)4(ρ+1) ,
3 2 1 0
(cid:16) γ(cid:17)2 (cid:104) (cid:105)
cˆ := 8 1+ L4E (1+|X |)4(ρ+1) ,
3 2 1 0
(cid:18) γ2 λγ2 (cid:19)2
c˜ := 2(1+λγ −γ)2, cˆ := 2 L+ − +γ ,
4 4
2 2
c˜ :=
96(cid:16)
1+
γ(cid:17)2(cid:16) |h(0)|4+4L4E(cid:104)
(1+|X
|)4(ρ+1)(cid:105)
+4E(cid:2) F4(X
)(cid:3)(cid:17)
,
5 2 2 0 ∗ 0
cˆ :=
64(cid:16)
1+
γ(cid:17)2(cid:16) L4E(cid:104)
(1+|X
|)4(ρ+1)(cid:105)
+E(cid:2) F4(X
)(cid:3)(cid:17)
.
5 2 2 0 ∗ 0
Next,recalltheexpressionof∆1,∆2 definedin(60)andofΣ in(65),k ∈ N . Wenotethat
k k k 0
Σ2 ≤ γβ−1η|∆1|2|ξ |2+γ3β−1η|∆2|2|ξ |2
k k k+1 k k+1
≤ ηγβ−1|ξ |2(cid:0) |Vn−η(cid:0) γVn+H(θη,X )(cid:1) |2+γ2|θη +γ−1Vη −ηγ−1H(θη,X )|2(cid:1)
k+1 k k k k+1 k k k k+1
≤ ηγβ−1|ξ |2(cid:0) 2(1−ηγ)2|Vη|2+(2+3η2)|H(θη,X )|2+3γ2|θη|2+3|Vη|2(cid:1)
k+1 k k k+1 k k
(cid:18) (cid:18)
≤ ηγβ−1|ξ |2 2(1−ηγ)2|Vη|2+(2+3η2) 3L2(1+|X |)2(ρ+1)|θη|2
k+1 k 1 k+1 k
(cid:19) (cid:19)
+3L2(1+|X |)2(ρ+1)+3F2(X ) +3γ2|θη|2+3|Vη|2 ,
2 k+1 ∗ k+1 k k
wherethelastinequalityholdsduetoRemark2.1. Thenbytakingexpectation,usingη ≤ 1andη ≤ 2,
γ
andthefactthatξ isindependentofX ,Vη andθη ,weobtain
k+1 k+1 k k
(cid:18)
E(cid:2) Σ2 k(cid:12) (cid:12)θ kη,V kη(cid:3) ≤ ηγβ−1d 5|V kη|2+(cid:16) 3γ2+15L2 1E(cid:104) (1+|X 0|)2(ρ+1)(cid:105)(cid:17) |θ kη|2
(cid:19)
(cid:104) (cid:105)
+15L2E (1+|X |)2(ρ+1) +15E(cid:2) F2(X )(cid:3) .
2 0 ∗ 0
Applying(69)totheinequalityaboveyields
E(cid:2) Σ2 k(cid:12) (cid:12)θ kη,V kη(cid:3) ≤η 8βV k 2c˜ 6+ 8η βc˜ 7, (72)
(cid:26) (cid:27)
wherec˜ := 8max 5γd , 3γd(γ2+5L2 1E[(1+|X0|)2(ρ+1)]) andc˜ := 120γdL2E(cid:2) (1+|X |)2(ρ+1)(cid:3) +
6 1(1−2λ) 1 (1−2λ)γ2 7 2 0
8 16
120γdE(cid:2) F2(X )(cid:3) . Substituting(72)into(71)andbyusingη ≤ 1,weobtain
∗ 0
E(cid:2) V k2 +1/β2(cid:12) (cid:12)θ kη,V kη(cid:3) ≤(cid:16) ϕ2+2ϕK˜ 1η2(cid:17) V βk 22 +(2ϕc˜ 1+c˜ 6)V βk 2η+2ϕη2cˆ 1V k/β + βη2 2c˜
2
η
+η2|θη|4(c˜ +cˆ )+η2|Vη|4(c˜ +cˆ )+η2(c˜ +cˆ )+ c˜ .
k 3 3 k 4 4 5 5 β 731
Next,byusing(69),wehave
(cid:26) (cid:27)
1 1
V2/β2 ≥max (1−2λ)2γ4|θη|4, (1−2λ)2|Vη|4 ,
k 64 k 16 k
1 1
≥ (1−2λ)2γ4|θη|4+ (1−2λ)2|Vη|4.
128 k 32 k
Thisimpliesthat
E(cid:2) V k2 +1/β2(cid:12) (cid:12)θ kη,V kη(cid:3) ≤(cid:16) ϕ2+(2ϕK˜ 1+c˜ 8)η2(cid:17) V k2/β2+(2ϕc˜ 1+c˜ 6)ηV k/β2+2ϕη2cˆ 1V k/β + βη2 2c˜
2
η
+η2(c˜ +cˆ )+ c˜ ,
5 5 7
β
(cid:110) (cid:111)
wherec˜ := max c˜3+cˆ3 , c˜4+cˆ4 . Bytakingexpectationsonbothsidesoftheaboveinequal-
8 1 (1−2λ)2γ4 1 (1−2λ)2
128 32
ityandbyusingthefactthatϕ = 1−λγη andϕ ≤ 1,weobtain
(cid:16) (cid:17)
E(cid:2) V2 (cid:3) ≤ 1−λγη+K˜η2 E(cid:2) V2(cid:3) +c˜ ηE[V ]+2cˆ βη2E[V ]+η2c˜
k+1 k 9 k 1 k 2
(73)
+η2(c˜ +cˆ )β2+ηc˜ β,
5 5 7
where
K˜ := 2K˜ +c˜ (74)
1 8
andc˜ := 2c˜ +c˜ . Byusing(59)andη ≤ 1,weobtain
9 1 6
(cid:16) (cid:17)
E(cid:2) V2 (cid:3) ≤ 1−λγη+K˜η2 E(cid:2) V2(cid:3) +ηD,
k+1 k
whereD := c˜ c˜ +2cˆ c˜ β+c˜ +(c˜ +cˆ )β2+c˜ β. Sinceη ≤ λγ,weobtain
9 10 1 10 2 5 5 7 2K˜
(cid:18) (cid:19)
E(cid:2) V2 (cid:3) ≤ 1− λγη E(cid:2) V2(cid:3) +ηD,
k+1 2 k
whichimplies
E(cid:2) V2(cid:3)
≤
E(cid:2) V2(cid:3)
+
2D
:= C . (75)
k 0 γλ V
Weclaimthat,forallθ ∈ Rd,wehavethat
a′ b′ L
|θ|2− log3 ≤ u(θ) ≤ u(0)+ |θ|2+|h(0)||θ|, (76)
3 2 2
Indeed,byusingRemark2.2,weobtain
(cid:90) 1
u(θ)−u(0) = ⟨θ,h(tθ)⟩dt
0
(cid:90) 1
≤ |θ||h(tθ)|dt
0
(cid:90) 1
≤ |θ|(tL|θ|+|h(0)|)dt.
0
Thisinturnleadsto
L
u(θ) ≤ u(0)+ |θ|2+|h(0)||θ|.
2
Next,weprovethelowerbound. Tothisend,bytakingc ∈ (0,1)andusingRemark2.3,wewrite
(cid:90) 1
u(θ) = u(cθ)+ ⟨θ,h(tθ)⟩dt
c
(cid:90) 1 1
≥ ⟨tθ,h(tθ)⟩dt
t
c
≥
(cid:90) 1 1 (cid:0) a′|tθ|2−b′(cid:1)
dt
t
c
a′(cid:0) 1−c2(cid:1)
= |θ|2+b′logc,
232 L.LIANG,A.NEUFELD,ANDY.ZHANG
√
whichbytakingc = 1/ 3leadstothebound. Byusing(76),wehave
(cid:18) (cid:19)
V(θ,v) ≤ β L |θ|2+|h(0)||θ|+u(0) + 1 βγ2(cid:16)(cid:12) (cid:12)θ+γ−1v(cid:12) (cid:12)2 +(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2 −λ|θ|2(cid:17)
2 4
(cid:18) (cid:19)
≤ β L ∥θ|2+|h(0)||θ|+u(0) + 1 βγ2(cid:16) 2|θ|2+2γ−2|v|2+(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2 −λ|θ|2(cid:17)
2 4
(77)
≤
β(cid:18)
L|θ|2+u(0)+
|h(0)|2(cid:19)
+ 1 βγ2(cid:16) 2|θ|2+2γ−2|v|2+(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2 −λ|θ|2(cid:17)
2L 4
(cid:18) 1 (cid:19) 3 β|h(0)|2
≤ βL+ βγ2 |θ|2+ β|v|2+βu(0)+ .
2 4 2L
Takingsquareonbothsidesfor(θ,v) = (θ ,V )andtakingexpectationyield
0 0
(cid:34) (cid:35)
E(cid:2) V2(cid:3) ≤ E
(cid:18)(cid:18)
βL+ 1
βγ2(cid:19)
|θ |2+ 3 β|V |2+βu(0)+
β|h(0)|2(cid:19)2
0 2 0 4 0 2L
≤ 4β2(L+ γ2 )E(cid:2) |θ |4(cid:3) + 9 β2E(cid:2) |V |4(cid:3) +4β2u(0)2+β2|h(0)|2 (78)
2 0 4 0 L2
≤ β2(cid:18) max{4(L+ γ2 ), 9 }(cid:0)E(cid:2) |θ |4(cid:3) +E(cid:2) |V |4(cid:3)(cid:1) +4u(0)2+ |h(0)|2(cid:19) .
2 4 0 0 L2
NotethataccordingtoAssumption2,theRHSof(78)isbounded.
Toobtainthesecondinequality,foreveryn ∈ N ,wedenotebyx∧y := min{x,y}foranyx,y ∈ R
0
anddefinethestoppingtime
(cid:110) (cid:12) (cid:16) (cid:17)(cid:12) (cid:111)
τ := inf t ∈ [kT,(k+1)T] : (cid:12)V ζ¯η,k,Z¯η,k (cid:12) > n ∧(k+1)T. (79)
n (cid:12) t t (cid:12)
Itisclearthatτ ↑ (k+1)T. Byusing
n
(cid:16) (cid:17)
V ζ¯η,k ,Z¯η,k
t∧τn t∧τn
= V(cid:0) θ¯η ,V¯η (cid:1) +(cid:90) t ηAV(cid:16) ζ¯η,k ,Z¯η,k (cid:17) 1 ds+(cid:112) 2γηβ−1(cid:90) t ∇ V(cid:16) ζ¯η,k ,Z¯η,k (cid:17) 1 dBη
kT kT s∧τn s∧τn {kT≤s≤τn} v s∧τn s∧τn {kT≤s≤τn} s
kT kT
(cid:16) (cid:17)
andapplyingItoˆ formulatothestoppedprocessV2 ζ¯η,k ,Z¯η,k ,oneobtains
t∧τn t∧τn
(cid:16) (cid:17)
V2 ζ¯η,k ,Z¯η,k
t∧τn t∧τn
= V2(cid:0) θ¯η ,V¯η (cid:1)
+2η(cid:90) t (cid:18) V(cid:16)
ζ¯η,k ,Z¯η,k
(cid:17) AV(cid:16)
ζ¯η,k ,Z¯η,k
(cid:17) +2γβ−1(cid:16)
∇
V(cid:16)
ζ¯η,k ,Z¯η,k
(cid:17)(cid:17)2(cid:19)
1 ds
kT kT s∧τn s∧τn s∧τn s∧τn v s∧τn s∧τn {kT≤s≤τn}
kT
+2(cid:112) 2γηβ−1(cid:90) t V(cid:16) ζ¯η,k ,Z¯η,k (cid:17) ∇ V(cid:16) ζ¯η,k ,Z¯η,k (cid:17) 1 dBη.
s∧τn s∧τn v s∧τn s∧τn {kT≤s≤τn} s
kT
(80)
Byusing(30),weobtain,foranyθ,v ∈ Rd,that
βγ
∇ V(θ,v) = βv+ θ,
v
2
whichimplies
β2γ2
|∇ V(θ,v)|2 ≤ 2β2v2+ θ2. (81)
v
2
Bytakingexpectationonbothsidesof(80),using(40),(81),andthefactthat
(cid:20)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:16) (cid:17)(cid:12)2 (cid:21)
E (cid:12)V ζ¯η,k ,Z¯η,k ∇ V ζ¯η,k ,Z¯η,k (cid:12) 1 ds
(cid:12) s∧τn s∧τn v s∧τn s∧τn (cid:12) {kT≤s≤τn}
kT
(cid:90) t (cid:20)(cid:12) (cid:12)2 (cid:21) n2γ2β2 (cid:90) t (cid:20)(cid:12) (cid:12)2 (cid:21)
≤ 2n2β2 E (cid:12)Z¯η,k (cid:12) 1 ds+ E (cid:12)ζ¯η,k (cid:12) 1 ds
(cid:12) s∧τn(cid:12) {kT≤s≤τn} 2 (cid:12) s∧τn(cid:12) {kT≤s≤τn}
kT kT
(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21) n2γ2β2 (cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
≤ 2n2β2 E (cid:12)Z¯η,k(cid:12) ds+ E (cid:12)ζ¯η,k(cid:12) ds < ∞,
(cid:12) s (cid:12) 2 (cid:12) s (cid:12)
kT kT33
wherethelastinequalityholdsdueto(33)inLemma5.4,weobtainthat
(cid:104) (cid:16) (cid:17)(cid:105)
E V2 ζ¯η,k ,Z¯η,k
t∧τn t∧τn
(cid:90) t (cid:104) (cid:16) (cid:17) (cid:16) (cid:17) (cid:105)
= E(cid:2) V2(cid:0) θ¯η ,V¯η (cid:1)(cid:3) +2η E V ζ¯η,k ,Z¯η,k AV ζ¯η,k ,Z¯η,k 1 ds
kT kT s∧τn s∧τn s∧τn s∧τn {kT≤s≤τn}
kT
(cid:90) t (cid:20) (cid:16) (cid:16) (cid:17)(cid:17)2 (cid:21)
+4γηβ−1 E ∇ V ζ¯η,k ,Z¯η,k 1 ds
v s∧τn s∧τn {kT≤s≤τn}
kT
(cid:90) t (cid:104)(cid:12) (cid:16) (cid:17)(cid:12)(cid:105) (cid:90) t (cid:104) (cid:16) (cid:17)(cid:105)
≤ E(cid:2) V2(cid:0) θ¯η ,V¯η (cid:1)(cid:3) +2ηγ(d+A ) E (cid:12)V ζ¯η,k ,Z¯η,k (cid:12) ds+2ηγλ E V2 ζ¯η,k ,Z¯η,k ds
kT kT c (cid:12) s∧τn s∧τn (cid:12) s∧τn s∧τn
kT kT
(cid:90) t (cid:20)(cid:12) (cid:12)2 (cid:21) (cid:90) t (cid:20)(cid:12) (cid:12)2 (cid:21)
+8ηγβ E (cid:12)Z¯η,k (cid:12) 1 ds+2ηβγ3 E (cid:12)ζ¯η,k (cid:12) 1 ds.
(cid:12) s∧τn(cid:12) {kT≤s≤τn} (cid:12) s∧τn(cid:12) {kT≤s≤τn}
kT kT
Notethat
(cid:18) (cid:19)
|V(θ,v)| ≤ β L |θ|2+|h(0)||θ|+u(0) + 1 βγ2(cid:16)(cid:12) (cid:12)θ+γ−1v(cid:12) (cid:12)2 +(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2 +λ|θ|2(cid:17)
2 4
(cid:18) (cid:19)
≤ β L ∥θ|2+|h(0)||θ|+u(0) + 1 βγ2(cid:16) 2|θ|2+2γ−2|v|2+(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2 +λ|θ|2(cid:17)
2 4
(82)
≤
β(cid:18)
L|θ|2+u(0)+
|h(0)|2(cid:19)
+ 1 βγ2(cid:16) 3|θ|2+2γ−2|v|2+(cid:12) (cid:12)γ−1v(cid:12) (cid:12)2(cid:17)
2L 4
(cid:18) 3 (cid:19) 3 β|h(0)|2
≤ β L+ γ2 |θ|2+ β|v|2+βu(0)+ ,
4 4 2L
wherethesecondinequalityholdsduetoλ ≤ 1/4. Byusing(82)andηT ≤ 1,weobtain
(cid:104) (cid:16) (cid:17)(cid:105)
E V2 ζ¯η,k ,Z¯η,k
t∧τn t∧τn
≤ E(cid:2) V2(cid:0) θ¯η ,V¯η (cid:1)(cid:3) +2γ(d+A
)(cid:18)
βu(0)+
β|h(0)|2(cid:19) +2ηγλ(cid:90) t E(cid:104) V2(cid:16)
ζ¯η,k ,Z¯η,k
(cid:17)(cid:105)
ds
kT kT c 2L s∧τn s∧τn
kT
(cid:18) (cid:18) 3 (cid:19)(cid:19)(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21) 3 (cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
+2ηγβ γ2+(d+A ) L+ γ2 E (cid:12)ζ¯η,k(cid:12) ds+2ηγβ(4+ (d+A )) E (cid:12)Z¯η,k(cid:12) ds
c 4 (cid:12) s (cid:12) 4 c (cid:12) s (cid:12)
kT kT
≤ C′ ,
V
wherethelastinequalityholdsdueto(33)inLemma5.4andGronwall’slemma,andwhere
(cid:18) (cid:18) |h(0)|2(cid:19) (cid:18)
3
(cid:19)
C′ := C +2βγ(d+A ) u(0)+ +2γβ 4+ (d+A ) C
V V c 2L 4 c Z
(83)
(cid:18) (cid:18) (cid:19)(cid:19) (cid:19)
3
+2γβ γ2+(d+A ) L+ γ2 C e2λγ.
c ζ
4
Bylettingn → ∞andusingFatou’slemma,oneobtains
(cid:20)(cid:12)
(cid:16)
(cid:17)(cid:12)2(cid:21) (cid:20)(cid:12)
(cid:16)
(cid:17)(cid:12)2(cid:21)
E (cid:12)V ζ¯η,k,Z¯η,k (cid:12) ≤ lim E (cid:12)V ζ¯η,k ,Z¯η,k (cid:12) ≤ C′ .
(cid:12) t t (cid:12)
n→+∞
(cid:12) t∧τn t∧τn (cid:12) V
Thenthedesiredinequalityfollowsbytakingthesupremum. □
APPENDIXC. PROOFS OF SECTION 5.2
Lemma C.1. Let Assumptions 1 and 2 hold. For any 0 < η ≤ η with η given in (9) and any
max max
k = 1,...,T withT := ⌊1/η⌋,weobtain
sup sup E(cid:104)(cid:12) (cid:12)h(cid:0) ζ¯ tη,n(cid:1) −H(cid:0) ζ¯ tη,n,X nT+k(cid:1)(cid:12) (cid:12)2(cid:105) ≤ σ H,
n∈Nt∈[nT,(n+1)T]
(cid:104) (cid:105)
whereσ := 8L2σ¯ +16σˆ ,σ¯ := E (1+|X |+|E[X ]|)2ρ|X −E[X ]|2 andσˆ := E(cid:2) K¯2(X )+K¯2(E[X ])(cid:3) .
H 2 z z z 0 0 0 0 z 1 0 1 034 L.LIANG,A.NEUFELD,ANDY.ZHANG
Proof. LetH := Fη ∨G . ByusingAssumptions1,2and[7,Lemma6.1],weobtain
t ∞ ⌊t⌋
E(cid:104)(cid:12) (cid:12)h(cid:0) θ¯ tη,n(cid:1) −H(cid:0) θ¯ tη,n,X nT+k(cid:1)(cid:12) (cid:12)2(cid:105)
=E(cid:104) E(cid:104)(cid:12) (cid:12)h(cid:0) θ¯ tη,n(cid:1) −H(cid:0) θ¯ tη,n,X nT+k(cid:1)(cid:12) (cid:12)2 | H nT(cid:105)(cid:105)
=E(cid:104) E(cid:104)(cid:12) (cid:12)E(cid:2) H(cid:0) θ¯ tη,n,X nT+k(cid:1) | H nT(cid:3) −H(cid:0) θ¯ tη,n,X nT+k(cid:1)(cid:12) (cid:12)2 | H nT(cid:105)(cid:105)
≤4E(cid:104) E(cid:104)(cid:12) (cid:12)H(cid:0) θ¯ tη,n,X nT+k(cid:1) −H(cid:0) θ¯ tη,n,E[X
nT+k
| H nT](cid:1)(cid:12) (cid:12)2 | H nT(cid:105)(cid:105)
≤4E[E[((1+|X |+|E[X | H ]|)ρL |X −E[X | H ]|
nT+k nT+k nT 2 nT+k nT+k nT
(cid:105)(cid:105)
+K¯ (X )+K¯ (E[X | H ])(cid:1)2 | H
1 nT+k 1 nT+k nT nT
(cid:104) (cid:105)
≤8L2E (1+|X |+|E[X ]|)2ρ|X −E[X ]|2 +16E(cid:2) K¯2(X )+K¯2(E[X ])(cid:3)
2 0 0 0 0 1 0 1 0
=8L2σ¯ +16σˆ ,
2 z z
(cid:104) (cid:105)
whereσ¯ := E (1+|X |+|E[X ]|)2ρ|X −E[X ]|2 andσˆ := E(cid:2) K¯2(X )+K¯2(E[X ])(cid:3) . □
z 0 0 0 0 z 1 0 1 0
ProofofLemma5.7. First,wenotethat
W 2(cid:0) L(cid:0) θ¯ tη,V¯ tη(cid:1) ,L(cid:0) ζ¯ tη,n,Z¯ tη,n(cid:1)(cid:1) ≤ E(cid:104)(cid:12) (cid:12)θ¯ tη −ζ¯ tη,n(cid:12) (cid:12)2(cid:105)1/2 +E(cid:104)(cid:12) (cid:12)V¯ tη −Z¯ tη,n(cid:12) (cid:12)2(cid:105)1/2 . (84)
To bound the first term on the RHS of (84), we start by using the definition of
(cid:0) θ¯η,V¯η(cid:1)
in (28) and
t t
(cid:0) ζ¯η,n,Z¯η,n(cid:1)
inDefinition5.1,andbyemployingthesynchronouscoupling,toobtain
t t
(cid:90) t
|θ¯η −ζ¯η,n| ≤ η |V¯η −Z¯η,n|ds.
t t ⌊s⌋ s
nT
Thisimplies,byusingCauchy-Schwarzinequality,that
sup E(cid:104)(cid:12) (cid:12)θ¯η −ζ¯η,n(cid:12) (cid:12)2(cid:105) ≤ η sup (cid:90) u E(cid:20)(cid:12) (cid:12)V¯η −Z¯η,n(cid:12) (cid:12)2(cid:21) ds,
u u (cid:12) ⌊s⌋ s (cid:12)
nT≤u≤t nT≤u≤t nT
(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
= η E (cid:12)V¯η −Z¯η,n(cid:12) ds.
(cid:12) ⌊s⌋ s (cid:12)
nT
Next,wesetforanyt ∈ [nT,(n+1)T],
(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)V¯η −Z¯η,n(cid:12) ≤ (cid:12)V¯η −V¯η(cid:12)+(cid:12) (cid:12)V¯η −Z¯η,n(cid:12) (cid:12)
(cid:12) ⌊t⌋ t (cid:12) (cid:12) ⌊t⌋ t (cid:12) t t
≤ (cid:12) (cid:12) (cid:12)V¯ ⌊η t⌋−V¯ tη(cid:12) (cid:12) (cid:12)+(cid:12) (cid:12) (cid:12) (cid:12)−γη(cid:90) t (cid:104) V¯ ⌊η s⌋−Z¯ sη,n(cid:105) ds−η(cid:90) t (cid:104) H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12)
(cid:12)
nT nT
≤ (cid:12) (cid:12) (cid:12)V¯ ⌊η t⌋−V¯ tη(cid:12) (cid:12) (cid:12)+γη(cid:90) t (cid:12) (cid:12) (cid:12)V¯ ⌊η s⌋−Z¯ sη,n(cid:12) (cid:12) (cid:12)ds+η(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) t (cid:104) H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12)
(cid:12)
nT nT
(cid:12) (cid:12) (cid:90) t (cid:12) (cid:12)
≤ (cid:12)V¯η −V¯η(cid:12)+γη (cid:12)V¯η −Z¯η,n(cid:12)ds
(cid:12) ⌊t⌋ t (cid:12) (cid:12) ⌊s⌋ s (cid:12)
nT
+η(cid:90) t (cid:12) (cid:12) (cid:12)H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(θ¯ ⌊η s⌋)(cid:12) (cid:12) (cid:12)ds+η(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) t (cid:104) h(θ¯ ⌊η s⌋)−h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12) (cid:12).
nT nT35
Wetakethesquaresonbothsidesanduse(a+b)2 ≤ 2(a2+b2)twicetoobtain
(cid:12) (cid:12)V¯η −Z¯η,n(cid:12) (cid:12)2 ≤ 4(cid:12) (cid:12)V¯η −V¯η(cid:12) (cid:12)2 +4γ2η2(cid:18)(cid:90) t |V¯η −Z¯η,n|ds(cid:19)2 +4η2(cid:12) (cid:12) (cid:12)(cid:90) t (cid:104) h(θ¯η )−h(cid:0) ζ¯η,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12)2
(cid:12) ⌊t⌋ t (cid:12) (cid:12) ⌊t⌋ t (cid:12) ⌊s⌋ s (cid:12) ⌊s⌋ s (cid:12)
nT nT
(cid:18)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:12) (cid:19)2
+4η2 (cid:12)H θ¯η ,X −h(θ¯η )(cid:12)ds
(cid:12) ⌊s⌋ ⌈s⌉ ⌊s⌋ (cid:12)
nT
≤ 4(cid:12) (cid:12)V¯η −V¯η(cid:12) (cid:12)2 +4γ2η(cid:18)(cid:90) t |V¯η −Z¯η,n|2ds(cid:19) +4η(cid:90) t (cid:12) (cid:12)h(θ¯η )−h(cid:0) ζ¯η,n(cid:1)(cid:12) (cid:12)2 ds
(cid:12) ⌊t⌋ t (cid:12) ⌊s⌋ s (cid:12) ⌊s⌋ s (cid:12)
nT nT
(cid:18)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:12) (cid:19)2
+4η2 (cid:12)H θ¯η ,X −h(θ¯η )(cid:12)ds ,
(cid:12) ⌊s⌋ ⌈s⌉ ⌊s⌋ (cid:12)
nT
wherethelastinequalityholdsduetoCauchy-SchwarzinequalityandηT ≤ 1. Thentakingexpectations
onbothsidesandbynoticingthatX isindependentofθ¯η andζ¯η,n ,weobtain
⌈s⌉ ⌊s⌋ s
(cid:20)(cid:12) (cid:12)2(cid:21) (cid:20)(cid:12) (cid:12)2(cid:21) (cid:18)(cid:90) t (cid:104) (cid:105) (cid:19)
E (cid:12)V¯η −Z¯η,n(cid:12) ≤ 4E (cid:12)V¯η −V¯η(cid:12) +4γ2η E |V¯η −Z¯η,n|2 ds
(cid:12) ⌊t⌋ t (cid:12) (cid:12) ⌊t⌋ t (cid:12) ⌊s⌋ s
nT
(cid:34) (cid:35)
(cid:18)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:12) (cid:19)2
+4η2E (cid:12)H θ¯η ,X −h(θ¯η )(cid:12)ds
(cid:12) ⌊s⌋ ⌈s⌉ ⌊s⌋ (cid:12)
nT
+4η(cid:90) t E(cid:20)(cid:12)
(cid:12)h(θ¯η )−h(cid:0)
ζ¯η,n(cid:1)(cid:12) (cid:12)2(cid:21)
ds
(cid:12) ⌊s⌋ s (cid:12)
nT
(85)
(cid:20)(cid:12) (cid:12)2(cid:21) (cid:18)(cid:90) t (cid:104) (cid:105) (cid:19)
≤ 4E (cid:12)V¯η −V¯η(cid:12) +4γ2η E |V¯η −Z¯η,n|2 ds
(cid:12) ⌊t⌋ t (cid:12) ⌊s⌋ s
nT
(cid:34) (cid:35)
(cid:18)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:12) (cid:19)2
+4η2E (cid:12)H θ¯η ,X −h(θ¯η )(cid:12)ds
(cid:12) ⌊s⌋ ⌈s⌉ ⌊s⌋ (cid:12)
nT
(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
+4ηL2 E (cid:12)θ¯η −ζ¯η,n(cid:12) ds.
(cid:12) ⌊s⌋ s (cid:12)
nT
Notethatforanyt ≥ 0,wehave
V¯η = V¯η −ηγ(cid:90) t V¯η ds−η(cid:90) t H(cid:0) θ ,X (cid:1) ds+(cid:112) 2γηβ−1(cid:16) Bη −Bη (cid:17) .
t ⌊t⌋ ⌊s⌋ ⌊s⌋ ⌈s⌉ t ⌊t⌋
⌊t⌋ ⌊t⌋
ByusingRemark2.1andη ≤ 1,wethereforeobtain
E(cid:20)(cid:12) (cid:12) (cid:12)V¯ ⌊η t⌋−V¯ tη(cid:12) (cid:12) (cid:12)2(cid:21) =
E (cid:12)
(cid:12) (cid:12) (cid:12)ηγ(cid:90) t V¯ ⌊η s⌋ds+η(cid:90) t H(cid:0) θ ⌊s⌋,X ⌈s⌉(cid:1) ds−(cid:112) 2γηβ−1(cid:16) B tη −B ⌊η
t⌋(cid:17)(cid:12)
(cid:12) (cid:12)
(cid:12)2

(cid:12) ⌊t⌋ ⌊t⌋ (cid:12)
(cid:104) (cid:105) (cid:104) (cid:105)
≤ 3η2γ2C +6η2L2E (1+|X |)2(ρ+1) C +12η2L2E (1+|X |)2(ρ+1)
v 1 0 θ 2 0
+12η2E(cid:2) F2(X )(cid:3) +6γηβ−1d
∗ 0
≤ σ η,
V
whereσ := 3γ2C +6E(cid:2) (1+|X |)2(ρ+1)(cid:3) (C L2+2L2)+12E(cid:2) F2(X )(cid:3) +6γβ−1d. Byapplying
V v 0 θ 1 2 ∗ 0
Gro¨nwallinequalityto(85)andusingηT ≤ 1,wearriveat
(cid:34) (cid:35)
(cid:20)(cid:12) (cid:12)2(cid:21) (cid:18) (cid:18)(cid:90) t (cid:12) (cid:16) (cid:17) (cid:12) (cid:19)2
E (cid:12)V¯η −Z¯η,n(cid:12) ≤c σ η+η2E (cid:12)H θ¯η ,X −h(θ¯η )(cid:12)ds
(cid:12) ⌊t⌋ t (cid:12) 1 V (cid:12) ⌊s⌋ ⌈s⌉ ⌊s⌋ (cid:12)
nT
(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21) (cid:19)
+ηL2 E (cid:12)θ¯η −ζ¯η,n(cid:12) ds ,
(cid:12) ⌊s⌋ s (cid:12)
nT36 L.LIANG,A.NEUFELD,ANDY.ZHANG
wherec = 4e4γ2 . Next,
1
sup E(cid:104)(cid:12) (cid:12)θ¯η −ζ¯η,n(cid:12) (cid:12)2(cid:105) ≤ η(cid:90) t E(cid:20)(cid:12) (cid:12)V¯η −Z¯η,n(cid:12) (cid:12)2(cid:21) ds
u u (cid:12) ⌊s⌋ s (cid:12)
nT≤u≤t nT
(cid:90) s (cid:20)(cid:12) (cid:12)2(cid:21)
≤ c ηL2 sup E (cid:12)θ¯η −ζ¯η,n(cid:12) ds′+c ησ
1 (cid:12) ⌊s′⌋ s′ (cid:12) 1 V (86)
nT≤s≤t nT
+c 1η3(cid:90) t E(cid:34)(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) s (cid:104) H(cid:16) θ¯ ⌊η s′⌋,X ⌈s′⌉(cid:17) −h(cid:16) θ¯ ⌊η s′⌋(cid:17)(cid:105) ds′(cid:12) (cid:12) (cid:12) (cid:12)2(cid:35) ds.
nT nT
ToobtainanupperboundforthefirsttermontheRHSof(86),weobservethat
(cid:90) s (cid:20)(cid:12) (cid:12)2(cid:21) (cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
sup E (cid:12)θ¯η −ζ¯η,n(cid:12) ds′ = E (cid:12)θ¯η −ζ¯η,n(cid:12) ds′
(cid:12) ⌊s′⌋ s′ (cid:12) (cid:12) ⌊s′⌋ s′ (cid:12)
nT≤s≤t nT nT
(cid:90) t (cid:20)(cid:12) (cid:12)2(cid:21)
≤ sup E (cid:12)θ¯η −ζ¯η,n(cid:12) ds′ (87)
(cid:12) ⌊u⌋ u (cid:12)
nT nT≤u≤s′
≤ (cid:90) t sup E(cid:104)(cid:12) (cid:12)θ¯η −ζ¯η,n(cid:12) (cid:12)2(cid:105) ds′.
u u
nT nT≤u≤s′
Then,weboundthelasttermontheRHSof(86)bypartitioningtheintegral. Foranys ∈ [nT,t]and
t ∈ [nT,(n+1)T],wedenotebyK := ⌊s−nT⌋andhave
(cid:12) (cid:12)
(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) s (cid:104) h(cid:16) θ¯ ⌊η s′⌋(cid:17) −H(cid:16) θ¯ ⌊η s′⌋,X ⌈s′⌉(cid:17)(cid:105) ds′(cid:12) (cid:12) (cid:12)
(cid:12)
= (cid:12) (cid:12) (cid:12)(cid:88)K I k +R K(cid:12) (cid:12) (cid:12),
nT (cid:12) (cid:12)
k=1
where
(cid:90) nT+k (cid:104) (cid:16) (cid:17) (cid:16) (cid:17)(cid:105) (cid:90) s
I = h θ¯η −H θ¯η ,X ds′, R = (cid:2) h(cid:0) θ¯η,n(cid:1) −H(cid:0) θ¯η,n,X (cid:1)(cid:3) ds′.
k ⌊s′⌋ ⌊s′⌋ nT+k K s′ s′ nT+K+1
nT+k−1 nT+K
Bytakingsquaresonbothsides,weobtain
(cid:12) (cid:12)2
K K K k−1 K
(cid:12)(cid:88) (cid:12) (cid:88) (cid:88)(cid:88) (cid:88)
(cid:12) I +R (cid:12) = |I |2+2 ⟨I ,I ⟩+2 ⟨I ,R ⟩+|R |2.
(cid:12) k K(cid:12) k k j k K K
(cid:12) (cid:12)
k=1 k=1 k=2j=1 k=1
Define the filtration H := Fη ∨G ,nT ≤ s ≤ (n+1)T. We have, for any k = 2,...,K,j =
s ∞ ⌊s⌋
1,...,k−1,that
E[⟨I ,I ⟩]
k j
= E[E[⟨I ,I ⟩ | H ]]
k j nT+j
(cid:34) (cid:34)(cid:42) (cid:43) (cid:35)(cid:35)
(cid:90) nT+k (cid:90) nT+j
= E E (cid:2) H(cid:0) θ¯η,n,X (cid:1) −h(cid:0) θ¯η,n(cid:1)(cid:3) ds′, (cid:2) H(cid:0) θ¯η,n,X (cid:1) −h(cid:0) θ¯η,n(cid:1)(cid:3) ds′ | H
s′ nT+k s′ s′ nT+j s′ nT+j
nT+(k−1) nT+(j−1)
(cid:34)(cid:42) (cid:43)(cid:35)
(cid:90) nT+k (cid:90) nT+j
= E E(cid:2) H(cid:0) θ¯η,n,X (cid:1) −h(cid:0) θ¯η,n(cid:1) | H (cid:3) ds′, (cid:2) H(cid:0) θ¯η,n,X (cid:1) −h(cid:0) θ¯η,n(cid:1)(cid:3) ds′
s′ nT+k s′ nT+j s′ nT+j s′
nT+(k−1) nT+(j−1)
= 0.37
Similarly,wehaveE[⟨I ,R ⟩] = 0forall1 ≤ k ≤ K. Then,
k K
(cid:90) t
(cid:34)(cid:12)(cid:90)
s
(cid:12)2(cid:35)
E (cid:12) (cid:12)
(cid:12)
(cid:2) H(cid:0) θ¯ sη ′,n,X ⌈s′⌉(cid:1) −h(cid:0) θ¯ sη ′,n(cid:1)(cid:3) ds′(cid:12) (cid:12)
(cid:12)
ds
nT nT
=
(cid:90) t

(cid:88)K
E (cid:12)
(cid:12)
(cid:12)
(cid:12)(cid:90) nT+k
(cid:2) h(cid:0) θ¯ sη ′,n(cid:1) −H(cid:0) θ¯ sη ′,n,X nT+k(cid:1)(cid:3)
ds′(cid:12)
(cid:12)
(cid:12)
(cid:12)2 
ds
nT (cid:12) nT+(k−1) (cid:12)
k=1
(cid:90) t
(cid:34)(cid:12)(cid:90)
s
(cid:12)2(cid:35)
+ E (cid:12) (cid:12)
(cid:12)
(cid:2) h(cid:0) θ¯ sη ′,n(cid:1) −H(cid:0) θ¯ sη ′,n,X nT+K+1(cid:1)(cid:3) ds′(cid:12) (cid:12)
(cid:12)
ds (88)
nT nT+K
≤ (cid:90) t (cid:34) (cid:88)K (cid:90) nT+k E(cid:104)(cid:12) (cid:12)h(cid:0) θ¯ sη ′,n(cid:1) −H(cid:0) θ¯ sη ′,n,X nT+k(cid:1)(cid:12) (cid:12)2(cid:105) ds′(cid:35) ds
nT nT+(k−1)
k=1
+(cid:90) t (cid:90) s E(cid:104)(cid:12) (cid:12)h(cid:0) θ¯ sη ′,n(cid:1) −H(cid:0) θ¯ sη ′,n,X nT+K+1(cid:1)(cid:12) (cid:12)2(cid:105) ds′ds
nT nT+K
≤ T2σ +Tσ ,
H H
wherethelastinequalityholdsduetoLemmaC.1. Substituting(87)and(88)into(86)yields
sup E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105) ≤ c 1ησ
V
+c 1ηL2(cid:90) t sup E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105) ds′
nT≤u≤t nT nT≤u≤s′
+c η3(cid:0) T2σ +Tσ (cid:1)
1 H H
(89)
≤ c 1ησ
V
+c 1ηL2(cid:90) t sup E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105) ds′
nT nT≤u≤s′
+c ησ +c η2σ ,
1 H 1 H
whereweusedηT ≤ 1inthelastinequality. Next,weconsiderthesecondtermof(84). Tothisend,we
write
(cid:12) (cid:12)V¯ tη −Z¯ tη,n(cid:12) (cid:12) ≤ (cid:12) (cid:12) (cid:12) (cid:12)γη(cid:90) t (cid:104) V¯ ⌊η s⌋−Z¯ sη,n(cid:105) ds(cid:12) (cid:12) (cid:12) (cid:12)+η(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) t (cid:104) H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12) (cid:12).
nT nT
Then,bytakingtheexpectationonbothsidesandbyusingηT ≤ 1,weobtain
E(cid:104)(cid:12) (cid:12)V¯ tη −Z¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ 2γ2η(cid:90) t E(cid:20)(cid:12) (cid:12) (cid:12)V¯ ⌊η s⌋−Z¯ sη,n(cid:12) (cid:12) (cid:12)2(cid:21) +2η2E(cid:34)(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) t (cid:104) H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12) (cid:12)2(cid:35) .
nT nT
(90)
ThesecondtermontheRHSoftheaboveinequalitycanbeboundedasfollows:
E(cid:34)(cid:12) (cid:12) (cid:12) (cid:12)(cid:90) l (cid:104) H(cid:16) θ¯ ⌊η s⌋,X ⌈s⌉(cid:17) −h(cid:0) ζ¯ sη,n(cid:1)(cid:105) ds(cid:12) (cid:12) (cid:12) (cid:12)2(cid:35) ≤ Tσ H +σ H.
nT
Substitutingtheresultintothesecondtermof(90)yields
E(cid:104)(cid:12) (cid:12)V¯ tη −Z¯ tη,n(cid:12) (cid:12)2(cid:105) ≤ 2γ2η(cid:90) t E(cid:20)(cid:12) (cid:12) (cid:12)V¯ ⌊η s⌋−Z¯ sη,n(cid:12) (cid:12) (cid:12)2(cid:21) +2σ Hη+2σ Hη2,
nT
whichimplies
sup E(cid:104)(cid:12) (cid:12)V¯ uη −Z¯ uη,n(cid:12) (cid:12)2(cid:105) ≤ 2γ2η(cid:90) t sup E(cid:104)(cid:12) (cid:12)V¯ uη −Z¯ uη,n(cid:12) (cid:12)2(cid:105) ds+2σ Hη+2σ Hη2. (91)
nT≤u≤t nT nT≤u≤s38 L.LIANG,A.NEUFELD,ANDY.ZHANG
Thenbycombining(89)and(91),wehave
sup (cid:110) E(cid:104)(cid:12) (cid:12)θ¯η −ζ¯η,n(cid:12) (cid:12)2(cid:105)(cid:111) + sup (cid:110) E(cid:104)(cid:12) (cid:12)V¯η −Z¯η,n(cid:12) (cid:12)2(cid:105)(cid:111)
u u u u
nT≤u≤t nT≤u≤t
≤ c 1ηL2(cid:90) t sup E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105) ds′+2γ2η(cid:90) t sup E(cid:104)(cid:12) (cid:12)V¯ uη −Z¯ uη,n(cid:12) (cid:12)2(cid:105) ds
nT nT≤u≤s′ nT nT≤u≤s
+c ησ +c ησ +c η2σ +2σ η+2σ η2
1 V 1 H 1 H H H
≤ (c 1L2+2γ2)η(cid:90) t sup (cid:110) E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105)(cid:111) + sup (cid:110) E(cid:104)(cid:12) (cid:12)V¯ uη −Z¯ uη,n(cid:12) (cid:12)2(cid:105)(cid:111) ds
nT nT≤u≤s nT≤u≤s
+(c σ +2c σ +4σ )η.
1 V 1 H H
Finally,applyingGronwall’slemmayields
sup (cid:110) E(cid:104)(cid:12) (cid:12)θ¯ uη −ζ¯ uη,n(cid:12) (cid:12)2(cid:105)(cid:111) + sup (cid:110) E(cid:104)(cid:12) (cid:12)V¯ uη −Z¯ uη,n(cid:12) (cid:12)2(cid:105)(cid:111) ≤ (c 1σ
V
+2c 1σ
H
+4σ H)ec1L2+2γ2 η := C 1⋆2η,
nT≤u≤t nT≤u≤t
(92)
where C 1⋆ := (cid:112) (c 1σ
V
+2c 1σ
H
+4σ H)ec1L2/2+γ2. Therefore, combining (84) and (92) yields the
desiredresult,i.e.,
W (cid:0) L(cid:0) θ¯η,V¯η(cid:1) ,L(cid:0) ζ¯η,n,Z¯η,n(cid:1)(cid:1) ≤ C⋆η1/2.
2 t t t t 1
□
ProofofLemma5.8. Letp = {1,2}. Byusingthetriangleinequality,Proposition5.6,and[6,Lemma
5.4],oneobtains
n
W
(cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1)
≤
(cid:88)
W
(cid:16) L(cid:16) ζ¯η,k,Z¯η,k(cid:17) ,L(cid:16) ζ¯η,k−1(cid:17) ,Z¯η,k−1(cid:17)
p t t t t p t t t t
k=1
=
(cid:88)n
W
(cid:18) L(cid:16) ζˆkT,θ¯ kη T,V¯ kη T,η ,ZˆkT,θ¯ kη T,V¯ kη T,η(cid:17) ,L(cid:18) ζˆ(k−1)T,θ¯ (η k−1)T,V¯ (η k−1)T,η(cid:19) ,Zˆ(k−1)T,θ¯ (η k−1)T,V¯ (η k−1)T,η(cid:19)(cid:33)
p t t t t
k=1
=
(cid:88)n
W
(cid:18) L(cid:16) ζˆkT,θ¯ kη T,V¯ kη T,η ,ZˆkT,θ¯ kη T,V¯ kη T,η(cid:17) ,L(cid:18) ζˆkT,ζ¯ kη T,k−1,Z¯ kη T,k−1,η ,ZˆkT,ζ¯ (η k−1)T,Z¯ (η k−1)T,η(cid:19)(cid:19)
p t t t t
k=1
n
≤ C˙ (cid:88) e−c˙η(t−kT)W1/p(cid:16) L(cid:0) θ¯η ,V¯η (cid:1) ,L(cid:16) ζ¯η,k−1,Z¯η,k−1(cid:17)(cid:17)
ρ kT kT kT kT
k=1
n
≤ (cid:0) 3max(cid:8) 1+α ,γ−1(cid:9)(cid:1)1/p C˙ (cid:88) e−c˙η(t−kT)(cid:16) 1+ε E1/2(cid:2) V2(cid:0) θη ,Vη (cid:1)(cid:3) +ε E1/2(cid:2) V2(cid:0) ζ¯η ,Z¯η (cid:1)(cid:3)(cid:17)1/p
c c kT kT c kT kT
k=1
(cid:16) (cid:16) (cid:17)(cid:17)
×W1/p L(cid:0) θη ,Vη (cid:1) ,L ζ¯η,(k−1)T ,Z¯η,(k−1)T
2 kT kT kT kT
n
≤ (cid:0) 3max(cid:8) 1+α ,γ−1(cid:9)(cid:1)1/p C˙ (cid:0) 1+ε C +ε C′
(cid:1)1/p(cid:16) C⋆η1/2(cid:17)1/p(cid:88)
e−c˙η(t−kT).
c c V c V 1
k=1
(93)
Byusingthefactsthat1−η ≤ ηT ≤ 1and⌊1/η⌋ ≥ 1,oneobtains
(cid:88)n
e−c˙η(t−kT) ≤
n (cid:88)−1
e−c˙ηkT ≤
1
≤
(cid:40) 1−e−1
c˙(1−η)
η ∈ (0,η max/2)
1−e−c˙ηT 1 η ∈ [η /2,η ]
k=1 k=0 1−e−c˙ηT max max
1 1
≤ max{ , }
1−e−c˙(1−ηmax/2) 1−e−c˙ηmax⌊1/η⌋/2 (94)
1 1
≤ max{ , }
1−e−c˙/2 1−e−c˙ηmax/2
1
≤ .
1−e−c˙ηmax/2
Substituting(94)into(93)andlettingp = 1andp = 2yields
W (cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1) ≤ C∗η1/2, W (cid:0) L(cid:0) ζ¯η,n,Z¯η,n(cid:1) ,L(ζη,Zη)(cid:1) ≤ C⋆η1/4,
1 t t t t 2 t t t t 239
where
3C
max(cid:8)
1+α
,γ−1(cid:9)
C∗ := 1 c C⋆(cid:0) 1+ε (cid:0) C +C′ (cid:1)(cid:1) (95)
1−e−c1ηmax/2 1 c V V
and
(cid:112)
C 3max{1+α ,γ−1}(cid:113)
C⋆ := 2 c C⋆(cid:0) 1+ε (cid:0) C +C′ (cid:1)(cid:1) .
2 1−e−c2ηmax/2 1 c V V
□
ProofofLemma5.9. We note, by [15], that h(r) ≤ min{r,h(R )} ≤ min{r,R }, for any r ≥ 0,
1 1
whichimpliesthat
ρ(cid:0) (x,v),(cid:0) x′,v′(cid:1)(cid:1)
≤
min(cid:8) r(cid:0) (x,v),(cid:0) x′,v′(cid:1)(cid:1)
,R
(cid:9)(cid:0)
1+ε V(x,v)+ε
V(cid:0) x′,v′(cid:1)(cid:1)
1 c c
≤ R
(cid:0)
1+ε V(x,v)+ε
V(cid:0) x′,v′(cid:1)(cid:1)
.
1 c c
Hence,byusing(77),weobtain
W (µ ,π¯ )
ρ 0 β
(cid:18)(cid:18)
1
(cid:19)(cid:90)
3
(cid:90) β|h(0)|2(cid:19)
≤ R +R ε βL+ βγ2 |θ|2µ (dθ,dv)+ β |v|2µ (dθ,v)+βu +
1 1 c 0 0 0
2 4 2L
R2d R2d
(cid:18)(cid:18)
1
(cid:19)(cid:90)
3
(cid:90) β|h(0)|2(cid:19)
+R ε βL+ βγ2 |θ|2π¯ (dθ,dv)+ β |v|2π¯ (dθ,dv)+βu + .
1 c β β 0
2 4 2L
R2d R2d
(96)
Moreover,byusing[40]andthefactthat
exp(cid:0) −β(cid:0)1|v|2+u(θ)(cid:1)(cid:1)
dθdv
exp(cid:0) −β(cid:0)1|v|2+u(θ)(cid:1)(cid:1)
dθdv
π¯ (dθ,dv) = 2 = (cid:0) 2πβ−1(cid:1)−d/2 2 ,
β (cid:82) exp(cid:0) −β(cid:0)1|v|2+u(θ)(cid:1)(cid:1)
dθdv
(cid:82)
exp(−βu(θ))dθ
R2d 2 Rd
(97)
weobtain
(cid:90) b′+d/β
|θ|2π¯ (θ,v) ≤
β a′
R2d
and
(cid:90) (cid:90)
|v|2π¯ (dθ,dv) = (cid:0) 2πβ−1(cid:1)−d/2 |v|2e−β|v|2/2dv = d/β. (98)
β
R2d Rd
Byusing(97),(98)andAssumption2,theRHSof(96)isbounded. ByusingProposition5.6andletting
p = 1,weobtain
W (L(ζη,Zη),π¯ ) ≤C e−c1ηtW (µ ,π¯ ),
1 t t β 1 ρ 0 β
≤C∗e−C 3∗ηt,
2
whereC∗ := C W (µ ,π¯ )andC∗ := c . Similarly,bylettingp = 2,wehave
2 1 ρ 0 β 3 1
(cid:113)
W (L(ζη,Zη),π¯ ) ≤C e−c2ηt W (µ ,π¯ ),
2 t t β 2 ρ 0 β
≤C⋆e−C 4⋆ηt,
3
(cid:112)
whereC⋆ := C W (µ ,π¯ )andC⋆ := c .
3 2 ρ 0 β 4 2
□
ProofofLemma5.10. Wedenotebyπη := L(θη,Vη)andwrite
n,β n n
(cid:90) (cid:90)
E[u(θη)]−E[u(θ )] = u(θ)πη (dθ,dv)− u(θ)π (dθ,dv).
n ∞ n,β β
R2d R2d
Notethatwehave
|h(θ)| ≤ L|θ|+|h(0)|,40 L.LIANG,A.NEUFELD,ANDY.ZHANG
hencebyusingsimilarargumentstothatin[39,Proposition1],weobtainthat
(cid:90) 1
|u(θη)−u(θ )| = | ⟨h(θ +t(θη −θ )),θη −θ ⟩|dt
n ∞ ∞ n ∞ n ∞
0
(cid:90) 1
≤ |h(θ +t(θη −θ ))||θη −θ |dt
∞ n ∞ n ∞
0
(cid:90) 1
≤ L|θη −θ | (t|θη|+(1−t)|θ |)dt+|h(0)||θη −θ |
n ∞ n ∞ n ∞
0
(cid:18) (cid:19)
1 1
= L |θη|+ |θ | |θη −θ |+|h(0)||θη −θ |.
2 n 2 ∞ n ∞ n ∞
ThentakingexpectationandusingHo¨lderinequalityyields
(cid:90) (cid:90) (cid:16) (cid:17)
| u(θ)πη (dθ,dv)− u(θ)π (dθ,dv)| ≤ (LC +|h(0)|)W πη ,π ,
n,β β m 2 n,β β
R2d R2d
(cid:16) (cid:17)
whereC := max (cid:82) |θ|2πη (dθ,dv),(cid:82) |θ|2π (dθ,dv) . ByusingTheorem3.1,weobtain
m R2d n,β R2d β
(cid:16) (cid:17)
E[u(θ nη)]−E[u(θ ∞)] ≤ (LC m+|h(0)|) C 1⋆η1/2+C 2⋆η1/4+C 3⋆e−C 4⋆n .
□
ProofofLemma5.11. Denote by p(θ) := e−βu(θ)/Λ for θ ∈ Rd the marginal density of π¯ , where
β
Λ := (cid:82) e−βu(θ)dθ is the normalization constant. Let θ∗ be a point that minimizes u(θ), i.e., u∗ :=
Rd
min u(θ) = u(θ∗),whichexistsbyAssumption4,see,e.g.,[5,Theorem2.32]. Wenotethat
θ∈Rd
(cid:32) (cid:33)
1 (cid:90) e−βu(θ) e−βu(θ)
E[u(θ )]−u∗ = − log dθ−logΛ −u∗, (99)
∞
β Λ Λ
Rd
wherethefirsttermontheRHSisthedifferentialentropyofp(θ). Toupper-boundthefirsttermonthe
RHSof(99),weestimatethesecondmomentofθ first. ByusingProposition5.6andlettingp = 2,one
∞
obtains
(cid:113)
W (L(θ ,V ),π¯ ) ≤ C e−c2t W (L(θ ,V ),π¯ ),
2 t t β 2 ρ 0 0 β
t→∞
whichimpliesW (L(θ ,V ),π¯ ) −→ 0. NotethatconvergenceofprobabilitymeasuresinWasserstein-
2 t t β
2distanceisequivalenttoweakconvergenceplusconvergenceofsecondmoments(see,e.g.,[46,Theorem
7.12]). Thus,byusing(42),(43),andFatou’slemma,weobtain
E(cid:2)
|θ
|2(cid:3)
= lim
E(cid:2)
|θ
|2(cid:3)
≤
8(d/β +A c/β)
.
∞ t→∞ t γ2λ(1−2λ)
ByusingthefactthatGaussiandistributionsmaximisethedifferentialentropyoveralldistributionswith
thesamefinitesecondmoment[12,Theorem9.6.5],weobtain
(cid:90) e−βu(θ) e−βu(θ) d (cid:18) 16πe(d/β +A /β)(cid:19)
c
− log dθ ≤ log . (100)
Λ Λ 2 dγ2λ(1−2λ)
Rd
Moreover,sinceθ∗ isaminimizerofu,i.e.,u(θ∗) = min u(θ),thisimplies∇u(θ∗) = 0. Byusing
θ∈Rd
Remark2.2,wehave
(cid:12)(cid:90) 1 (cid:12)
−β(u(θ∗)−u(θ)) ≤β(cid:12) (cid:12) ⟨h(tθ∗+(1−t)θ)−h(θ∗),θ∗−θ⟩dt(cid:12) (cid:12),
(cid:12) (cid:12)
0
(cid:18)(cid:90) 1 (cid:19)
≤β L(1−t)|θ−θ∗|2dt , (101)
0
L|θ−θ∗|2
≤β .
241
Then,wecanlower-boundlogΛbyusing(101),onewrites
(cid:90)
logΛ = log e−βu(θ)dθ,
Rd
(cid:90)
= −βu∗+log eβ(u∗−u(θ))dθ,
Rd
(102)
(cid:90) βL|θ−θ∗|2
≥ −βu∗+log e− 2 dθ,
Rd
(cid:18) (cid:19)
d 2π
= −βu∗+ log ,
2 Lβ
wherethelastinequalityholdsduetothefactthat(cid:82)+∞ e−ax2dx = (cid:112)π foranya > 0. Substituting(100)
−∞ a
and(102)into(99)yields
(cid:90) (cid:18) (cid:18) (cid:19)(cid:19)
d 8eL A
c
u(θ)π(dθ)− minu(θ) ≤ log +1 .
Rd θ∈Rd 2β γ2λ(1−2λ) d
□
APPENDIXD. PROOFS OF SECTION 4
ProofofProposition4.1. Assumption1holdswithρ = 0,L = 2λ ,L = 0andK¯ (x) = 2. Assump-
1 r 2 1
tion2issatisfiedbyconstruction. Denotebyf thedensityofX anddenotebyc¯ theupperboundof
X d
f . Then,Assumption3holdswithL = 2(λ +c¯ ). Indeed,wehave,foranyθ,θ′ ∈ Rd,that
X r d
E(cid:2)(cid:12) (cid:12)H(θ,X 0)−H(cid:0) θ′,X 0(cid:1)(cid:12) (cid:12)(cid:3) ≤2λ r|θ−θ′|+E(cid:2)(cid:12) (cid:12)1 {X0<θ}−1 {X0<θ′}(cid:12) (cid:12)(cid:3)
≤2λ
|θ−θ′|+E(cid:2)1 (cid:3) +E(cid:2)1 (cid:3)
r {θ′≤X0<θ} {θ≤X0<θ′}
(cid:12) (cid:12)
(cid:12)(cid:90) θ (cid:12) (cid:12)(cid:90) θ′ (cid:12)
≤2λ
r|θ−θ′|+(cid:12)
(cid:12)
(cid:12)
f
X0(x)dx(cid:12)
(cid:12) (cid:12)+(cid:12)
(cid:12)
f X0(x)dx(cid:12)
(cid:12)
θ′ (cid:12) θ (cid:12)
≤2(λ +c¯ )|θ−θ′|.
r d
Furthermore, Assumption 4 holds with A(x) = 2λ I and b(x) = 0, which implies a = 2λ and
r d r
b = 0. □
ProofofProposition4.2. ForN = 1,··· ,d ,wedenoteby
2
(cid:32) (cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105)
(cid:33)
σN := σ f(WNk)σ Wk·,Z +f(bk) +bN .
2 2 1 1 0 0 1
k=1
Weclaimthath(θ) := ∇u(θ) = E[H(θ,X )]. Indeed,forK = 1,··· ,d andN = 1,··· ,d ,wehave
0 1 2
∂ u(θ) =
−2E(cid:20) (cid:88)m2
(cid:0) Yj −Nj(θ,Z)(cid:1) WjNσN (cid:0) 1−σN(cid:1) f′(WNK)σ (cid:0)(cid:10) WK·,Z(cid:11)
+f(bK)(cid:1)(cid:21)
+2λ WNK,
WNK 2 2 2 1 1 0 0 r 1
1
j=1
∂ u(θ) =
−2E(cid:20) (cid:88)m2
(cid:0) Yj
−Nj(θ,Z)(cid:1)(cid:88)d2
Wjnσn(1−σn)f(WnK)f′(bK)1
(cid:21)
+2λ bK,
bK 2 2 2 1 0 {⟨WK·,Z⟩+f(bK)>0} r 0
0 0 0
j=1 n=1
∂ u(θ) =
−2E(cid:20) (cid:88)m2
(cid:0) Yj −Nj(θ,Z)(cid:1) WjNσN (cid:0)
1−σN(cid:1)(cid:21)
+2λ bN.
bN 2 2 2 r 1
1
j=1
WenotethatthepartialderivativeofuwithrespecttoW andb areobtainedbyusingthechainrule.
1 1
Next,weprovideaprooffor∂ u(θ)underthecasem = m = d = d = 1fortheeaseofnotation,
b0 1 2 1 2
whichcouldbenaturallyextendedtom ,m ,d ,d ∈ R. Inthiscase,
1 2 1 2
u(θ) := E(cid:2) |Y −N(θ,Z)|2(cid:3) +λ |θ|2
r
= E(cid:2) |Y −W σ (f(W )σ (W Z +f(b ))+b )|2(cid:3) +λ |θ|2
2 2 1 1 0 0 1 r
= E(cid:2) Y2−2YW σ (f(W )σ (W Z +f(b ))+b )+W2σ2(f(W )σ (W Z +f(b ))+b )(cid:3) +λ |θ|2.
2 2 1 1 0 0 1 2 2 1 1 0 0 1 r
Then,oneobtains
∂ u(θ) = T (θ)+T (θ)+2λ b , (103)
b0 b0,1 b0,2 r 042 L.LIANG,A.NEUFELD,ANDY.ZHANG
where
(cid:18) (cid:90) ∞ (cid:90) ∞ (cid:19)
T (θ) := ∂ −2W yσ (f(W )σ (W z+f(b ))+b )f (y,z)dz dy
b0,1 b0 2 2 1 1 0 0 1 Y,Z
−∞ −∞
withf denotingthejointdensityofY,Z,wheref denotingthedensityfunctionofZ,f denotes
Y,Z Z Z|Y
theconditionaldensityofZ givenY,andwhere
(cid:32) (cid:90) ∞ (cid:90) −f(b0) (cid:33)
T (θ) := W2∂ (cid:0) σ2(f(W )(W z+f(b ))+b )(cid:1) f (z)dz+ W0 (cid:0) σ2(b )(cid:1) f (z)dz .
b0,2 2 b0
−f(b0)
2 1 0 0 1 Z
−∞
2 1 Z
W0
Foranyθ ∈ Rd,wehave
T (θ)
b0,1
(cid:18)(cid:90) ∞ (cid:18)(cid:90) ∞ (cid:19) (cid:19)
= −2W ∂ y σ (f(W )σ (W z+f(b ))+b )f (z)dz f (y)dy
2 b0 2 1 1 0 0 1 Z|Y Y
−∞ −∞
(cid:18)(cid:90) ∞ (cid:18)(cid:90) ∞ (cid:90) −f(b0) (cid:19) (cid:19)
= −2W ∂ y σ (f(W )(W z+f(b ))+b )f (z)dz+
W0
σ (b )f (z)dz f (y)dy .
2 b0
−∞ −f(b0)
2 1 0 0 1 Z|Y
−∞
2 1 Z|Y Y
W0
(104)
Denote by σ := σ (f(W )(W z+f(b ))+b ). By using |σ (1−σ )| ≤ 1, |f(v)| ≤ c, and
2 2 1 0 0 1 2 2
|f′(v)| ≤ 1,weobtain,foranyb ∈ R,that
0
(cid:12) (cid:12)
(cid:90) ∞ (cid:12)(cid:90) ∞ (cid:12) (cid:90) ∞
inf sup (cid:12) yσ (1−σ )f(W )f′(b +ζ)f (z)dz(cid:12)f (y)dy ≤ c |y|f (y)dy < ∞.
(cid:12) 2 2 1 0 Z|Y (cid:12) Y Y
δ∈(0,∞) −∞ζ∈[−δ,δ](cid:12) −f(b0+ζ) (cid:12) −∞
W0
Thus,byusing[14,TheoremA.5.2],wehave
(cid:90) ∞ (cid:18)(cid:90) ∞ (cid:19)
T (θ) = −2W y σ (1−σ )f(W )f′(b )f (z)dz f (y)dy
b0,1 2
−∞ −f(b0)
2 2 1 0 Z|Y Y
(105)
W0
= −2E(cid:2) YW σ (1−σ )f(W )f′(b )1 (cid:3) .
2 2 2 1 0 {W0Z+f(b0)>0}
Similarly,oneobtains
(cid:90) ∞
T (θ) = 2W2 σ2(1−σ )f(W )f′(b )f (z)dz = 2E(cid:2) N(θ,Z)W σ (1−σ )f(W )f′(b )(cid:3) .
b0,2 2
−f(b0)
2 2 1 0 Z|Y 2 2 2 1 0
W0
(106)
Substituting(105)and(106)into(103)yields
∂ u(θ) = −2E(cid:2) (Y −N(θ,Z))W σ (1−σ )f(W )f′(b )1 (cid:3) +2λ b .
b0 2 2 2 1 0 {W0Z+f(b0)>0} r 0
Inaddition,since(X ) isasequenceofi.i.d.randomvariableswithprobabilitylawL(X),bythe
n n∈N
0
definitionsofF,Ggivenin(16)andasH := F +G,weobservethath(θ) := ∇u(θ) = E[H(θ,X )],
0
forallθ ∈ R. Thus,Assumption2holds. Assumption1holdswithρ = 0,L = 2λ ,L = 0. Indeed,
1 r 2
wehave,foranyθ,θ′ ∈ Rd,x,x′ ∈ Rm,that
(cid:12) (cid:12)F(θ,x)−F(θ′,x′)(cid:12)
(cid:12) ≤ 2λ
r(cid:12) (cid:12)θ−θ′(cid:12)
(cid:12).
WethenproceedtoshowthatAssumption3holds. Tothisend,wenotethat,foranyj = 1,··· ,m and
2
(θ,z) ∈ Rd×Rm1,that
|Nj(θ,z)| ≤
(cid:88)d2
(cid:12) (cid:12)Wjn(cid:12)
(cid:12)(cid:12)
(cid:12)
(cid:12)σ
(cid:32) (cid:88)d1
(cid:104)
f(Wnk)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(bk)(cid:17)(cid:105)
+bn(cid:33)(cid:12)
(cid:12)
(cid:12) ≤ d c , (107)
(cid:12) 2 (cid:12)(cid:12) 2 1 1 0 0 1 (cid:12) 2 W2
(cid:12) (cid:12)
n=1 k=143
(cid:110) (cid:111)
wherewerecallthatc := max Wij . Byusing(107)togetherwiththefactthat|σ (v)(1−σ (v))| ≤ 1,
W2
i,j
2 2 2
weobtain,forany(θ,x) ∈ Rd×Rm,K = 1,··· ,d andN = 1,··· ,d ,
1 2
(cid:12) (cid:12)
(cid:12)G (θ,x)(cid:12)
(cid:12) bK (cid:12)
0
≤
2(cid:88)m2 (cid:88)d2
|W 2jn|(cid:12) (cid:12)f(W 1nK)(cid:12) (cid:12)(cid:0) |yj||σ 2n(1−σ 2n)|+|Nj(θ,z)||σ 2n(1−σ 2n)|(cid:1)(cid:12) (cid:12)f′(b 0)(cid:12) (cid:12)1
{⟨WK·,z⟩+f(bK)>0}
0 0
j=1n=1
≤
2(cid:88)m2 (cid:88)d2
c(cid:0) c |yK|+c |Nj(θ,z)|(cid:1)1
W2 W2 {⟨WK·,z⟩+bK>0}
0 0
j=1n=1
≤
2(cid:88)m2 (cid:88)d2
(cid:0) cc |yj|+d cc2 (cid:1) ≤ C (1+|x|),
W2 2 W2 G b0
j=1n=1
whereC := 2m d cc (1+d c ). Similarly,wehavethat
G
b0
2 2 W2 2 W2
(cid:12) (cid:12) (cid:12)G bN(θ,x)(cid:12) (cid:12)
(cid:12)
≤
2(cid:88)m2
(cid:16)(cid:12) (cid:12)yj(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)W 2j,N(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1)(cid:12) (cid:12)+(cid:12) (cid:12)Nj(θ,z)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)W 2j,N(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1)(cid:12) (cid:12)(cid:17)
1
j=1
≤
2(cid:88)m2
(cid:0) c W2(cid:12) (cid:12)yj(cid:12) (cid:12)+d 2c2 W2(cid:1) ≤ C
G
b1
(1+|x|),
j=1
(cid:12) (cid:12) (cid:12) (cid:12)
whereC := 2m c (1+d c ). Byusing(107)togetherwith(cid:12)WK,i(cid:12) ≤ c ,(cid:12)Wj,N(cid:12) ≤ c for
G b1 2 W2 2 W2 (cid:12) 0 (cid:12) W0 (cid:12) 2 (cid:12) W2
K = 1,··· ,d ,i = 1,··· ,m ,N = 1,··· ,d ,andj = 1,··· ,m ,andthat|f′(v)| ≤ 1foranyv ∈ R,
1 1 2 2
weobtain,forany(θ,x) ∈ Rd×Rm,that
(cid:12) (cid:12)
(cid:12)G (θ,x)(cid:12)
(cid:12) WNK (cid:12)
1
≤
2(cid:88)m2
(cid:16)(cid:12) (cid:12)yj(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)W 2j,N(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1)(cid:12) (cid:12)+(cid:12) (cid:12)Nj(θ,z)(cid:12) (cid:12)(cid:12) (cid:12) (cid:12)W 2j,N(cid:12) (cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1)(cid:12) (cid:12)(cid:17)(cid:12) (cid:12)σ 1(cid:0)(cid:10) W 0K·,z(cid:11) +f(bK
0
)(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)f′(W 1NK)(cid:12) (cid:12)
j=1
≤
2(cid:88)m2
(cid:0) c W2(cid:12) (cid:12)yj(cid:12) (cid:12)+d 2c2
W2(cid:1)(cid:12)
(cid:12) (cid:12)(cid:0)(cid:10) W 0K·,z(cid:11) +f(bK
0
)(cid:1)1
{⟨W 0K·,z⟩+f(bK
0
)>0}(cid:12)
(cid:12)
(cid:12)
j=1
≤ 2m c (1+d c )(1+|y|)(m c +c)(1+|z|) ≤ C (1+|x|)2,
2 W2 2 W2 1 W0 GW1
where C := 2m c (1+d c )(m c +c). Thus, for any (θ,x) ∈ Rd ×Rm, we have that
GW1 2 W2 2 W2 1 W0
|G(θ,x)| ≤ d d C (1+|x|)2+d C (1+|x|)+d C (1+|x|) =: K¯ (x),thusAssumption1
issatisfied. Ne1 xt2 weG sW h1 owAssumption1 3hG ob l0 ds. Tothisend,2 noG teb1 thatforanyθ,θ¯:1 = (cid:0)(cid:2) W¯ (cid:3) ,¯b ,¯b (cid:1) ∈ Rd,
1 0 1
wehave
E(cid:2) |H(θ,X)−H(θ¯,X)|(cid:3)
≤ 2λ
|θ−θ¯|+E(cid:2)
|G (θ,X)−G
(θ¯,X)|(cid:3) +E(cid:2)
|G (θ,X)−G
(θ¯,X)|(cid:3) +E(cid:2)
|G (θ,X)−G
(θ¯,X)|(cid:3)
.
r b1 b1 b0 b0 W1 W1
(108)
Foreachj = 1,··· ,m ,wedenoteby
2
Nj(θ¯,z) :=
(cid:88)d2
Wjnσ
(cid:32) (cid:88)d1
(cid:104)
f(W¯ nk)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(¯bk)(cid:17)(cid:105)
+¯bn(cid:33)
,
2 2 1 1 0 0 1
n=1 k=1
andforanyN = 1,··· ,d ,wedenote
2
(cid:32) (cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105)
(cid:33)
σ¯N := σ f(W¯ Nk)σ Wk·,z +f(¯bk) +¯bN .
2 2 1 1 0 0 1
k=144 L.LIANG,A.NEUFELD,ANDY.ZHANG
ToupperboundthesecondtermontheRHSof(108),foranyj = 1,··· ,m ,onewrites
2
(cid:104)(cid:12) (cid:12)(cid:105)
E (cid:12)G (θ,X)−G (θ¯,X)(cid:12)
(cid:12) bN bN (cid:12)
1 1
(cid:12) (cid:12)
≤ 2E
(cid:12)
(cid:12) (cid:12)
(cid:12)(cid:88)m2
(cid:0) Yj −Nj(θ,Z)(cid:1) W 2jNσ 2N (cid:0) 1−σ 2N(cid:1)
−(cid:88)m2
(cid:0) Yj −Nj(θ¯,Z)(cid:1) W 2jNσ¯ 2N (cid:0) 1−σ¯
2N(cid:1)(cid:12)
(cid:12) (cid:12) (cid:12)
(cid:12)j=1 j=1 (cid:12)
 
≤ 2E
(cid:88)m2
(cid:12) (cid:12)Yj(cid:12)
(cid:12)(cid:12)
(cid:12) (cid:12)W
2jN(cid:12)
(cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)
j=1
 
+2E
(cid:88)m2
(cid:12)
(cid:12) (cid:12)W
2jN(cid:12)
(cid:12) (cid:12)(cid:12) (cid:12)Nj(θ,Z)σ 2N (cid:0) 1−σ 2N(cid:1) −Nj(θ¯,Z)σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)
j=1
≤ 2c
W2(cid:88)m2 (cid:18)
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Nj(θ,Z)σ 2N (cid:0) 1−σ 2N(cid:1) −Nj(θ¯,z)σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12)
(cid:12)(cid:3)(cid:19)
.
j=1 (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T1 T2
(109)
ToobtainanupperboundforT andT ,weproceedbycalculatingestimatesforseveralquantities
1 2
thatwillbeusefulthroughouttheproof. Tothisend,recallthatweassumeatleastoneelementineach
row of the fixed input matrix W
0
∈ Rd1×m1 is nonzero. For each k = 1,··· ,d 1, denote by v
k
:=
min(cid:8) i ∈ {1,...,m } | Wki ̸= 0(cid:9) ,thenWkv k denotesthefirstnonzeroelementinthek-throwofW .
1 0 0 0
AssumewithoutlossofgeneralitythatWkv k > 0,andbk ≤¯bk,whichimpliesthatf(bk) ≤ f(¯bk)sincef
0 0 0 0 0
isamonotoneincreasingfunction. Moreover,foranyi = 1,...,m 1,j = 1,...,m 2,z ∈ Rm1,y ∈ Rm2,
denoteby
z := (cid:0) z1,...,zi−1,zi+1,...,zm1(cid:1) ∈ Rm1−1, y := (cid:0) y1,...,yj−1,yj+1,...,ym2(cid:1) ∈ Rm2−1,
−i −j
whereasforeachk = 1,··· ,d ,wedenoteby
1
(cid:26) (cid:12) (cid:27) (cid:26) (cid:12) (cid:27)
A
k
:= z ∈ Rm1(cid:12) (cid:12)(cid:68) W 0k·,z(cid:69) +f(bk 0) > 0 , A¯
k
:= z ∈ Rm1(cid:12) (cid:12)(cid:68) W 0k·,z(cid:69) +f(¯bk 0) > 0 . (110)
(cid:12) (cid:12)
Thenwehave,foreachk = 1,...,d ,j = 1,··· ,m ,that
1 2
E(cid:2)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
(cid:20) (cid:21)
= E 1 (cid:110)(cid:16) −f(¯bk)−(cid:80) WkiZi(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WKiZi(cid:17) /Wkvk(cid:111)
0 i̸=vk 0 0 0 i̸=vK 0 0
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
=
R Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv Kk W0kizi f Zvk|Z−vk,Yj (cid:0) zv k | z −v k,yj(cid:1) dzv kf Z−vk,Yj (cid:0) z −v k,yj(cid:1) dz −v kdyj.
W0kvk
Thisimpliesthat
E(cid:2)(cid:12) (cid:12)1 A k(Z)−1 A¯ k(Z)(cid:12) (cid:12)(cid:3) ≤ WC Z kv vk
k
(cid:12) (cid:12) (cid:12)f(bk 0)−f(¯bk 0)(cid:12) (cid:12) (cid:12) ≤ C1,max|θ−θ¯|, (111)
045
wherethelastinequalityholdsdueto|f′(v)| ≤ 1,wherewerecallC Zvk isdefinedin(15)andC1,max :=
(cid:26) (cid:27)
max C Zvk . Furthermore,wehave,foreachk = 1,··· ,d andj = 1,··· ,m ,that
k
Wkvk 1 2
0
E(cid:104) |Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105)
(cid:20) (cid:21)
(cid:16) (cid:17)
= E |Zv k|2+|Z −v k|2 1 (cid:16) −f(¯bk)−(cid:80) WkiZi(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WkiZi(cid:17) /Wkvk
0 i̸=vk 0 0 0 i̸=vk 0 0
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
=
R Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |zv k|2f Zvk|Z−vk,Yj (cid:0) zv k | z −v k,yj(cid:1) dzv kf Z−vk,Yj (cid:0) z −v k,yj(cid:1) dz −v kdyj
W0kvk
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
+
R Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi f Zvk|Z−vk,Yj (cid:0) zv k | z −v k,yj(cid:1) dzv k|Z −v k|2f Z−vk,Yj (cid:0) z −v k,yj(cid:1) dz −v kdyj.
W0kvk
Thisimpliesthat
E(cid:2) |Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) ≤ WC¯ Z 0kv vk
k
(cid:12) (cid:12) (cid:12)f(b 0)−f(¯bk 0)(cid:12) (cid:12) (cid:12)+ C WZ 0vv kkE(cid:104) |Z
−v
k|2(cid:105)(cid:12) (cid:12) (cid:12)f(b 0)−f(¯bk 0)(cid:12) (cid:12)
(cid:12)
(112)
≤ C
Z,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(cid:26) (cid:27)
(cid:16) (cid:104) (cid:105)(cid:17)
wherewerecallC Zvk andC¯ Zvk aredefinedin(15)andC Z,max := m kax W1 kvk (cid:0) C¯ Zvk +C Zvk(cid:1) 1+E |Z|2 .
0
Similarcalculationsyield
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
(cid:20) (cid:21)
= E (cid:12) (cid:12)Yj(cid:12) (cid:12)1 (cid:110)(cid:16) −f(¯bk)−(cid:80) WkiZk(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WkiZk(cid:17) /Wkvk(cid:111)
0 i̸=vk 0 0 0 i̸=vk 0 0
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
= R Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk f Zvk|Z−vk,yj (cid:0) zv k | z −v k,yj(cid:1) dzv k(cid:12) (cid:12)yj(cid:12) (cid:12)f Z−vk,yj (cid:0) z −v k,yj(cid:1) dz −v k dyj.
W0kvk
Thisimpliesthat
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) ≤ WC Z 0kv vk
k
(cid:12) (cid:12) (cid:12)¯bk
0
−bk 0(cid:12) (cid:12) (cid:12)(cid:90) R(cid:90) Rm1−1(cid:12) (cid:12)yj(cid:12) (cid:12)f
Z−vk,Yj
(cid:0) z
−v
k,yj(cid:1) dz
−v k
dyj
(113)
≤ C
Y,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(cid:26) (cid:27)
whereC := max C Zvk E[|Y|]. Thenonewrites,foreachk = 1,··· ,d andj = 1,··· ,m ,
Y,max
k
Wkvk 1 2
0
that
E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105)
(cid:20) (cid:21)
= E (cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:16) |Zv k|2+|Z −v k|2(cid:17) 1 (cid:110)(cid:16) −f(¯bk)−(cid:80) WkiZi(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WkiZi(cid:17) /Wkvk(cid:111)
0 i̸=vk 0 0 0 i̸=vk 0 0
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
=
R Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |zv k|2f Zvk|Z−vk,Yj (cid:0) zv k | z −v k,yj(cid:1) dzv k(cid:12) (cid:12)yj(cid:12) (cid:12)f Z−vk,Yj (cid:0) z −v k,yj(cid:1) dz −v kdyj
W0kvk
(cid:90) (cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
+
R Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi f Zvk|Z−vk,Yj (cid:0) zv k | z −v k,yj(cid:1) dzv k(cid:12) (cid:12)yi(cid:12) (cid:12)|Z −v k|2f Z−vk,Yj (cid:0) z −v k,yj(cid:1) dz −v kdyj.
W0kvk46 L.LIANG,A.NEUFELD,ANDY.ZHANG
Thisimpliesthat
E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105) ≤ WC¯ Z kv vk kE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:3)(cid:12) (cid:12) (cid:12)f(bk 0)−f(¯bk 0)(cid:12) (cid:12) (cid:12)+ C WZ vv kkE(cid:104) |Z
−v
k|2(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:105)(cid:12) (cid:12) (cid:12)f(bk 0)−f(¯bk 0)(cid:12) (cid:12)
(cid:12)
0 0
≤ C
ZY,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(114)
(cid:26) (cid:27)
whereC := max C¯ Zvk + C Zvk (1+E[|Y|])(cid:16) 1+E(cid:104) |Y||Z|2(cid:105)(cid:17) .
ZY,max k W 0kvk W 0vk
Now we proceed with upper bounding T in (109). Since |σ′′(θ)| ≤ 2 for any θ ∈ R, we have
1 2
(cid:12) (cid:12)σ′(θ)−σ′(θ¯)(cid:12) (cid:12) ≤ 2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12). Thistogetherwiththefactthat|f(v)| ≤ cforanyv ∈ Rensuresthat
2 2
(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12)
(cid:12)
2 2 2 2
(cid:12) (cid:12)
(cid:12)(cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105)
(cid:88)d1
(cid:104) (cid:16)(cid:68) (cid:69) (cid:17)(cid:105) (cid:12)
≤ 2(cid:12) f(WNk)σ Wk·,z +f(bk) +bN − f(W¯ Nk)σ Wk·,z +f(¯bk) −¯bN(cid:12)
(cid:12) 1 1 0 0 1 1 1 0 0 1 (cid:12)
(cid:12) (cid:12)
k=1 k=1
≤ 2(cid:12) (cid:12)bN
1
−¯bN
1
(cid:12)
(cid:12)+2(cid:88)d1
(cid:12) (cid:12) (cid:12)f(cid:16) W 1Nk(cid:17)(cid:12) (cid:12) (cid:12)(cid:12) (cid:12) (cid:12)σ 1(cid:16)(cid:68) W 0k·,z(cid:69) +f(cid:16) bk 0(cid:17)(cid:17) −σ 1(cid:16)(cid:68) W 0k·,z(cid:69) +f(cid:16) ¯bk 0(cid:17)(cid:17)(cid:12) (cid:12)
(cid:12)
k=1
+2(cid:88)d1
(cid:12)
(cid:12)σ
(cid:16)(cid:68) Wk·,z(cid:69) +f(cid:16) ¯bk(cid:17)(cid:17)(cid:12) (cid:12)(cid:12) (cid:12)f(cid:16) Wjk(cid:17) −f(cid:16)
W¯
Nk(cid:17)(cid:12)
(cid:12).
(cid:12) 1 0 0 (cid:12)(cid:12) 1 1 (cid:12)
k=1
(115)
Thenbyusing(111)and(112)togetherwiththefactthat|x| ≤ 1+|x|2 foranyx ∈ R,weobtain,for
eachN = 1,··· ,d ,that
2
E(cid:2)(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ 2(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2c(cid:88)d1 (cid:18)(cid:12)
(cid:12) (cid:12)W
0k·(cid:12)
(cid:12) (cid:12)E(cid:2) |Z|(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) +cE(cid:2)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12)
(cid:12)(cid:3)(cid:19)
k=1
+2c(cid:88)d1
E(cid:2)(cid:12) (cid:12)1
A¯
(Z)(cid:12) (cid:12)(cid:3)(cid:12) (cid:12) (cid:12)f(cid:16) bk 0(cid:17) −f(cid:16) ¯bk 0(cid:17)(cid:12) (cid:12)
(cid:12)+2(cid:88)d1
(cid:16)(cid:12) (cid:12) (cid:12)W 0k·(cid:12) (cid:12) (cid:12)E[|Z|]+c(cid:17)(cid:12) (cid:12) (cid:12)W 1Nk −W¯ 1Nk(cid:12) (cid:12)
(cid:12)
k
k=1 k=1
≤ 2(1+cd 1)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2c(cid:88)d1 (cid:18)
m 1c W0E(cid:104) |Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105) +(c+m 1c W0)E(cid:2)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12)
(cid:12)(cid:3)(cid:19)
k=1
(cid:88)d1
(cid:12) (cid:12)
+2 (m c E[|Z|]+c)(cid:12)WNk −W¯ Nk(cid:12)
1 W0 (cid:12) 1 1 (cid:12)
k=1
(cid:18) (cid:19)
≤ 2(1+cd
1)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2cd 1 m 1c W0C Z,max+(c+m 1c W0)C1,max
(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2d 1(m 1c
W0E[|Z|]+c)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)
:= C
max,1(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(116)
(cid:18) (cid:19)
whereC
max,1
:= 2(1+cd 1)+2cd
1
m 1c W0C Z,max+(c+m 1c W0)C1,max +2d 1(m 1c W0E[|Z|]+c).
Moreover, by using the fact that |x| ≤ 1+|x|2 holds for any x ∈ R, (113) and (114), for x ∈ R, we47
obtain
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ 2E(cid:2) |Yj|(cid:3)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2c(cid:88)d1 (cid:18)(cid:12)
(cid:12) (cid:12)W
0k·(cid:12)
(cid:12) (cid:12)E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12)
(cid:12)(cid:3)(cid:19)
k=1
+2c(cid:88)d1
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A¯
(Z)(cid:12) (cid:12)(cid:3)(cid:12) (cid:12) (cid:12)f(cid:16) bk 0(cid:17) −f(cid:16) ¯bk 0(cid:17)(cid:12) (cid:12)
(cid:12)+2(cid:88)d1
(cid:16)(cid:12) (cid:12) (cid:12)W 0k·(cid:12) (cid:12) (cid:12)E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:3) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:3)(cid:17)(cid:12) (cid:12) (cid:12)W 1Nk −W¯ 1Nk(cid:12) (cid:12)
(cid:12)
k
k=1 k=1
≤ 2E[|Y|](cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2c(cid:88)d1 (cid:18)
m 1c W0E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12)
(cid:12)(cid:3)(cid:19)
k=1
+2cd
1E[|Y|](cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2d 1(m 1c
W0E[|Y||Z|]+cE[|Y|])(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)
≤ C
max,2(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(117)
where
C := 2E[|Y|]+2cd (m c C +(c+m c )C )+2cd E[|Y|]+2d (m c E[|Y||Z|]+cE[|Y|]).
max,2 1 1 W0 Y,max 1 W0 ZY,max 1 1 1 W0
Furthermore,byusing(112)and(111),wehave
E(cid:2) |Z|(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ 2E[|Z|](cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)+2c(cid:88)d1 (cid:18)(cid:12) (cid:12) (cid:12)W 0k·(cid:12) (cid:12) (cid:12)E(cid:104) |Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105) +cE(cid:2) |Z|(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)(cid:19)
k=1
+2c(cid:88)d1
E(cid:2) |Z|(cid:12) (cid:12)1
A¯
(Z)(cid:12) (cid:12)(cid:3)(cid:12) (cid:12) (cid:12)f(cid:16) bk 0(cid:17) −f(cid:16) ¯bk 0(cid:17)(cid:12) (cid:12)
(cid:12)+2(cid:88)d1
(cid:16)(cid:12) (cid:12) (cid:12)W 0k·(cid:12) (cid:12) (cid:12)E(cid:104) |Z|2(cid:105) +cE[|Z|](cid:17)(cid:12) (cid:12) (cid:12)W 1Nk −W¯ 1Nk(cid:12) (cid:12)
(cid:12)
k
k=1 k=1
≤ C
max,3(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(118)
where
(cid:18) (cid:19) (cid:88)d1
(cid:16) (cid:104) (cid:105) (cid:17)
C
max,3
:= 2E[|Z|]+2cd
1
(m 1c
W0
+c)C Z,max+cC1,max +2c E[|Z|]+2d
1
m 1c W0E |Z|2 +cE[|Z|] .
k=1
ToobtainupperboundforT ,weproceedtocalculatetheupperestimatesofthefollowingquantities. By
2
usingthefactthat|σ′(v)| ≤ 1and|f′(v)| ≤ 1foranyv ∈ R,wehave,foreachj = 1,··· ,m ,that,
2 2
(cid:12) (cid:12)Nj(θ,z)−Nj(θ¯,z)(cid:12)
(cid:12)
≤
(cid:88)d2 (cid:12) (cid:12)Wjn(cid:12) (cid:12)(cid:12) (cid:12)
(cid:12)σ
(cid:32) (cid:88)d1
(cid:2) f(Wnk)σ (cid:0)(cid:10) Wk·,z(cid:11) +f(bk)(cid:1)(cid:3)
+bn(cid:33)
−σ
(cid:32) (cid:88)d1
(cid:2) f(W¯nk)σ (cid:0)(cid:10) Wk·,z(cid:11) +f(¯bk)(cid:1)(cid:3)
+¯bn(cid:33)(cid:12) (cid:12)
(cid:12)
(cid:12) 2 (cid:12)(cid:12) 2 1 1 0 0 1 2 1 1 0 0 1 (cid:12)
(cid:12) (cid:12)
n=1 k=1 k=1
(cid:12) (cid:12)
≤
(cid:88)d2 (cid:12) (cid:12)Wjn(cid:12) (cid:12)(cid:12) (cid:12)(cid:88)d1
(cid:2) f(Wnk)σ (cid:0)(cid:10) Wk·,z(cid:11) +f(bk)(cid:1)(cid:3)
+bn−(cid:88)d1
(cid:2) f(W¯nk)σ (cid:0)(cid:10) Wk·,z(cid:11) +f(¯bk)(cid:1)(cid:3)
+¯bn(cid:12)
(cid:12)
(cid:12) 2 (cid:12)(cid:12) 1 1 0 0 1 1 1 0 0 1(cid:12)
(cid:12) (cid:12)
n=1 k=1 k=1
≤ (cid:88)d2 (cid:12) (cid:12) (cid:12)W 2jn(cid:12) (cid:12) (cid:12)(cid:18) (cid:12) (cid:12)bn
1
−¯bn 1(cid:12) (cid:12)+(cid:88)d1 (cid:12) (cid:12)f(W 1nk)(cid:12) (cid:12)(cid:12) (cid:12)σ 1(cid:0)(cid:10) W 0k·,z(cid:11) +f(cid:0) bk 0(cid:1)(cid:1) −σ 1(cid:0)(cid:10) W 0k·,z(cid:11) +f(cid:0)¯bk 0(cid:1)(cid:1)(cid:12) (cid:12)
n=1 k=1
+(cid:88)d1
(cid:12) (cid:12)σ 1(cid:0)(cid:10) W 0k·,z(cid:11) +f(cid:0)¯bk 0(cid:1)(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)f(W 1nk)−f(W¯ 1nk)(cid:12)
(cid:12)(cid:19)
k=1
≤c
W2(cid:88)d2 (cid:18)
(cid:12) (cid:12)bn 1 −¯bn 1(cid:12)
(cid:12)+c(cid:88)d1
(cid:10) W 0k·,z(cid:11)(cid:12) (cid:12)1 Ak(z)−1 A¯ k(z)(cid:12)
(cid:12)+c(cid:88)d1
(cid:12) (cid:12)f(cid:0) bk 0(cid:1)1 Ak(z)−f(cid:0)¯bk 0(cid:1)1 A¯ k(z)(cid:12) (cid:12)
n=1 k=1 k=1
+(cid:88)d1
(cid:12) (cid:12)(cid:0)(cid:12) (cid:12)Wk·(cid:12) (cid:12)|z|+c(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) Wnk(cid:1) −f(cid:0) W¯nk(cid:1)(cid:12)
(cid:12)(cid:19)
0 1 1
k=1
≤c W2d 2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)+cm 1c W0c W2d
2(cid:88)d1
|z|(cid:12) (cid:12)1 Ak(z)−1 A¯ k(z)(cid:12) (cid:12)+c2d 2c
W2(cid:88)d1
(cid:12) (cid:12)1 Ak(z)−1 A¯ k(z)(cid:12) (cid:12)
k=1 k=148 L.LIANG,A.NEUFELD,ANDY.ZHANG
+cd 2c
W2(cid:88)d1
(cid:12) (cid:12)bk
0
−¯bk 0(cid:12) (cid:12)+c
W2(cid:88)d2 (cid:88)d1
(m 1c W0|z|+c)(cid:12) (cid:12)W 1nk−W¯ 1nk(cid:12) (cid:12).
k=1 n=1k=1
Thisimpliesthat
(cid:12) (cid:12)Nj(θ,z)−Nj(θ¯,z)(cid:12)
(cid:12)
≤ c W2d 2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)+cm 1c W0c W2d
2(cid:88)d1
|z|(cid:12) (cid:12)1 A k(z)−1 A¯ k(z)(cid:12) (cid:12)+c2d 2c
W2(cid:88)d1
(cid:12) (cid:12)1 A k(z)−1 A¯ k(z)(cid:12) (cid:12)
k=1 k=1
(cid:88)d1
(cid:12) (cid:12)
(cid:88)d2 (cid:88)d1
(cid:12) (cid:12)
+cd c (cid:12)bk −¯bk(cid:12)+c (m c |z|+c)(cid:12)Wnk −W¯ nk(cid:12).
2 W2 (cid:12) 0 0(cid:12) W2 1 W0 (cid:12) 1 1 (cid:12)
k=1 n=1k=1
(119)
Byusing(111),(112)andtakingexpectationonbothsides,weobtain
E(cid:2)(cid:12) (cid:12)Nj(θ,Z)−Nj(θ¯,Z)(cid:12) (cid:12)(cid:3)
≤ c W2d 2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)+cm 1c W0c W2d
2(cid:88)d1
E(cid:2) |Z|(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3) +c2d 2c
W2(cid:88)d1
E(cid:2)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
k=1 k=1
(cid:88)d1
(cid:12) (cid:12)
(cid:88)d2 (cid:88)d1
(cid:12) (cid:12)
+cd c (cid:12)bk −¯bk(cid:12)+c (m c E[|Z|]+c)(cid:12)Wnk −W¯ nk(cid:12)
2 W2 (cid:12) 0 0(cid:12) W2 1 W0 (cid:12) 1 1 (cid:12)
k=1 n=1k=1
≤ C
max,N(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(120)
where C
max,N
:= c W2d
1
+cm 1c W0c W2d 1d 2C
Z,max
+cd 1d 2c W2(c+m 1c W0)C1,max +2cd 1d 2c
W2
+
d d m c c E[|Z|]. Furthermore,byusingthefactthat|x| ≤ 1+|x|2 holdsforanyx ∈ R,together
1 2 1 W0 W2
with(111),(112)and(119),weobtain
E(cid:2) |Z|(cid:12) (cid:12)Nj(θ,Z)−Nj(θ¯,Z)(cid:12) (cid:12)(cid:3)
≤c W2d 2E[|Z|](cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)+cm 1c W0c W2d
2(cid:88)d1
E(cid:104) |Z|2(cid:12) (cid:12)1 Ak(Z)−1 A¯ k(Z)(cid:12) (cid:12)(cid:105) +c2d 2c
W2(cid:88)d1
E(cid:2) |Z|(cid:12) (cid:12)1 Ak(Z)−1 A¯ k(Z)(cid:12) (cid:12)(cid:3)
k=1 k=1
+cd 2c
W2(cid:88)d1
E[|Z|](cid:12) (cid:12)bk
0
−¯bk 0(cid:12) (cid:12)+c
W2(cid:88)d2 (cid:88)d1
(cid:16) m 1c W0E(cid:104) |Z|2(cid:105) +cE[|Z|](cid:17)(cid:12) (cid:12)W 1nk−W¯ 1nk(cid:12) (cid:12)
k=1 n=1k=1
≤C
max,ZN(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(121)
whereC
max,ZN
:= c W2d 2E[|Z|]+cd 1d 2c W2(m 1c
W0
+c)C Z,max+c2d 1d 2c W2C1,max+2cd 1d 2c W2E[|Z|]+
d d m c c E[|Z|2]. Byusing(107),(111),(120),andthefactthat|σ (v)(1−σ (v))| ≤ 1,wehave,
1 2 1 W0 W2 2 2
foreachN = 1,··· ,d andj = 1,··· ,m ,that
2 2
E(cid:2)(cid:12) (cid:12)Nj(θ,z)σN (cid:0) 1−σN(cid:1) −Nj(θ¯,z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ E(cid:2)(cid:12) (cid:12)Nj(θ,z)σN (cid:0) 1−σN(cid:1) −Nj(θ,z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Nj(θ,z)σ¯N (cid:0) 1−σ¯N(cid:1) −Nj(θ¯,z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2 2 2 2 2
≤ d 2c W2E(cid:2)(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (1−σ¯ 2n)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Nj(θ,z)−Nj(θ¯,z)(cid:12) (cid:12)(cid:3)
≤ C
max,4(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(122)
whereC := d c C +C . Substituting(117)and(122)into(109)yields
max,4 2 W2 max,1 max,N
E(cid:104)(cid:12)
(cid:12) (cid:12)G
bN
1
(θ,X)−G
bN
1
(θ¯,X)(cid:12)
(cid:12)
(cid:12)(cid:105)
≤ C
max,b1(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12), (123)49
whereC := 2c m C +2c m C . Next,wecalculatetheupperboundforthesecond
max,b1 W2 2 max,2 W2 2 max,4
termof(108). Wehavethat
(cid:104)(cid:12) (cid:12)(cid:105)
E (cid:12)G (θ,X)−G (θ¯,X)(cid:12)
(cid:12) bK bK (cid:12)
0 0
≤ 2c
W2(cid:88)m2 (cid:88)d2 (cid:18)
E(cid:2)(cid:12) (cid:12)Yjσ 2n(1−σ 2n)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1)1 AK(Z)−Yjσ¯ 2n(1−σ¯ 2n)f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
j=1n=1
(cid:19)
+E(cid:2)(cid:12) (cid:12)Nj(θ,z)σ 2n(1−σ 2n)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1)1 AK(Z)−Nj(θ¯,Z)σ¯ 2n(1−σ¯ 2n)f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
≤ T +T +T +T +T ,
b0,3 b0,4 b0,5 b0,6 b0,7
where
T
b0,3
:= 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Yjf(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σ 2n(1−σ 2n)1 AK(Z)−σ¯ 2n(1−σ¯ 2n)1
A¯
K(cid:12) (cid:12)(cid:3) ,
j=1n=1
T
b0,4
:= 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σ¯ 2n(1−σ¯ 2n)1
A¯
K(Z)(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1) −f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:3) ,
j=1n=1
T
b0,5
:= 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1)1 AK(Z)(cid:12) (cid:12)(cid:12) (cid:12)Nj(θ,z)σ 2n(1−σ 2n)−Nj(θ¯,z)σ¯ 2n(1−σ¯ 2n)(cid:12) (cid:12)(cid:3) ,
j=1n=1
T
b0,6
:= 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯ 2n(1−σ¯ 2n)1 AK(Z)(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1) −f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:3) ,
j=1n=1
T
b0,7
:= 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯ 2n(1−σ¯ 2n)f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3) .
j=1n=1
ToupperboundT ,weuse|f(v)| ≤ cand|σ (v)(1−σ (v))| ≤ 1toobtain
b0,3 2 2
T b0,3 ≤ 2cc
W2(cid:88)m2 (cid:88)d2 (cid:18) E(cid:20)
(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σ 2n(1−σ 2n)1 AK(Z)−σ 2n(1−σ 2n)1 A¯ K(Z)(cid:12) (cid:12)
j=1n=1
(cid:21)(cid:19)
+(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A¯
K(Z)(cid:12) (cid:12)|σ 2n(1−σ 2n)−σ¯ 2n(1−σ¯ 2n)|
≤ 2cc
W2(cid:88)m2 (cid:88)d2 (cid:18)
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)+(cid:12) (cid:12)Yj(cid:12) (cid:12)|σ 2n(1−σ 2n)−σ¯ 2n(1−σ¯
2n)|(cid:3)(cid:19)
j=1n=1
≤ 2cc W2d 2m 2(C Y,max+C
max,2)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
wherethelastinequalityholdsdueto(113)and(117). ForT ,byusing|σ¯ (1−σ¯ )| ≤ 1,|f(x)| ≤ c,
b0,4 2 2
|f′(x)| ≤ 1and|f′′(x)| ≤ 2/cforanyx ∈ R,onewrites
T
b0,4
≤ 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1) −f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:3)
j=1n=1
≤ 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)f′(cid:0) bK
0
(cid:1) −f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)+(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) −f(cid:0) W¯ 1nK(cid:1)(cid:12) (cid:12)(cid:3)
j=1n=1
≤ 6c W2m 2d
2E[|Y|](cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12).
ForT ,byusing|f(v)| ≤ c,|f′(v)| ≤ 1,and(122),wehavethat
b0,5
T
b0,5
≤ 2cc
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Nj(θ,Z)σ 2n(1−σ 2n)−Nj(θ¯,Z)σ¯ 2n(1−σ¯ 2n)(cid:12) (cid:12)(cid:3) ≤ 4cc W2m 2d 2C max,4(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12).
j=1n=150 L.LIANG,A.NEUFELD,ANDY.ZHANG
ForT ,byusing|σ¯ (1−σ¯ )| ≤ 1and(107),weobtainthat
b0,6 2 2
T
b0,6
≤ 2d 2c2
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)f(cid:0) W 1nK(cid:1) f′(cid:0) bK
0
(cid:1) −f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:3) ≤ 6m 2d2 2c2 W2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12).
j=1n=1
ForT ,byusing|σ¯ (1−σ¯ )| ≤ 1,|f(v)| ≤ c,|f′(v)| ≤ 1,(107),and(111),wehavethat
b0,7 2 2
T
b0,7
≤ 2c
W2(cid:88)m2 (cid:88)d2
E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯ 2n(1−σ¯ 2n)f(cid:0) W¯ 1nK(cid:1) f′(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
j=1n=1
≤ 2cm 2d2 2c2 W2C1,max(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12).
Byusingtheresultsabove,weobtain
E(cid:104)(cid:12)
(cid:12) (cid:12)G
bK
0
(θ,x)−G
bK
0
(θ¯,x)(cid:12)
(cid:12)
(cid:12)(cid:105)
≤ C
max,b0(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12), (124)
w 2ch mer 2e dC 2 2cm 2 Wax 2, Cb0 1,: m= ax2 .c Tc W he2 nd ,2 dm en2 o( tC inY g,m ba yx σ+ 1K (cid:12)C :=m (cid:12)a σx, 12 (cid:0))+ (cid:10) W6c 0KW ·2 ,m Z2 (cid:11)d +2E f(cid:2) (cid:0)(cid:12) (cid:12) bY K 0j (cid:1)(cid:12) (cid:12)(cid:3) (cid:1)+ an4 dcc σ¯W 1K2m :=2d σ2 1C (cid:0)m (cid:10)a Wx, 04 K+ ·,6 Zm (cid:11)2 +d2 2c f2 W (cid:0)2 ¯b+ K
0
(cid:1)(cid:1) ,
byusing|f′(v)| ≤ 1,|f′′(v)| ≤ 2/cand(cid:12)σ 1K (cid:12) ≤ m 1c W0|z|+c,weobtain
(cid:104)(cid:12) (cid:12)(cid:105)
E (cid:12)G (θ,x)−G (θ¯,x)(cid:12)
(cid:12) WNK WNK (cid:12)
1 1
≤
2(cid:88)m2 (cid:12) (cid:12)WjN(cid:12) (cid:12)(cid:18)
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σK(cid:12) (cid:12)(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σK −σ¯K(cid:12) (cid:12)(cid:3)
(cid:12) 2 (cid:12) 1 2 2 2 2 2 2 1 1
j=1
+E(cid:2)(cid:12) (cid:12)σK(cid:12) (cid:12)(cid:12) (cid:12)Ni(θ,Z)σN (cid:0) 1−σN(cid:1) −Nj(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σK −σ¯K(cid:12) (cid:12)(cid:3)
1 2 2 2 2 2 2 1 1
+E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σ¯K(cid:12) (cid:12)(cid:12) (cid:12)f′(WNK)(cid:12) (cid:12)−(cid:12) (cid:12)f′(W¯ NK)(cid:12) (cid:12)(cid:3)
2 2 1 1 1
(cid:19)
+E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σ¯K(cid:12) (cid:12)(cid:12) (cid:12)f′(WNK)−f′(W¯ NK)(cid:12) (cid:12)(cid:3)
2 2 1 1 1
≤ 2c
W2(cid:88)m2 (cid:18)
m 1c W0E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12) (cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3)
j=1 (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T3 T4
+m 1c W0E(cid:2) |Z|(cid:12) (cid:12)Nj(θ,Z)σ 2N (cid:0) 1−σ 2N(cid:1) −Nj(θ¯,Z)σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3)
(cid:124) (cid:123)(cid:122) (cid:125)
T5
+cE(cid:2)(cid:12) (cid:12)Ni(θ,Z)σN (cid:0) 1−σN(cid:1) −Ni(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)σK −σ¯K(cid:12) (cid:12)(cid:3)
2 2 2 2 2 2 1 1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
T6 T7
+E(cid:2)(cid:12) (cid:12)Nj(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)σK −σ¯K(cid:12) (cid:12)(cid:3)
2 2 1 1
(cid:124) (cid:123)(cid:122) (cid:125)
T8
(cid:19)
+ 2
c
(m 1c W0E[|Y||Z|]+cE[|Y|]+m 1d 2c W0c W2E[|Z|]+cd 2c W2)(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12) .
ToupperboundT ,byusing(115),|f(x)| ≤ c,|f′(x)| ≤ 1,andthefactthat|x| ≤ 1+|x|2 holdsfor
3
anyx ∈ R,wehavethat
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ 2E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:3)(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12)+2c(cid:88)d1 (cid:18)
m 1c W0E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
k=1
+cE(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105)(cid:19) +2c(cid:88)d1 E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:12) (cid:12)1
A¯
k(Z)(cid:12) (cid:12)(cid:3)(cid:12) (cid:12) (cid:12)f(cid:16) bk 0(cid:17) −f(cid:16) ¯bk 0(cid:17)(cid:12) (cid:12)
(cid:12)
k=1
+2(cid:88)d1
(cid:16) m 1c W0E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:105) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|(cid:3)(cid:17)(cid:12) (cid:12) (cid:12)W 1Nk −W¯ 1Nk(cid:12) (cid:12)
(cid:12)
k=1
≤ C
T3,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),51
whereC := 2E[|Y||Z|]+2cd ((m c +c)C +cC )+2cd E[|Y||Z|]
(cid:16)
T3,max
(cid:104) (cid:105)
1 (cid:17)1 W0 ZY,max Y,max 1
+2d m c E |Y||Z|2 +cE[|Y||Z|] . ForT ,byusing(117),wederivethat
1 1 W0 4
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12) (cid:12) (cid:12)σ 2N (cid:0) 1−σ 2N(cid:1) −σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3) ≤ C max,2(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12).
ForT ,byusing(107),(118),and(121),wededucethat
5
E(cid:2) |Z|(cid:12) (cid:12)Nj(θ,Z)σN (cid:0) 1−σN(cid:1) −Nj(θ¯,Z)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3)
2 2 2 2
≤ E(cid:2) |Z|(cid:12) (cid:12)Nj(θ,Z)(cid:12) (cid:12)(cid:12) (cid:12)σN (cid:0) 1−σN(cid:1) −σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:3) +E(cid:2) |Z|(cid:12) (cid:12)σ¯N (cid:0) 1−σ¯N(cid:1)(cid:12) (cid:12)(cid:12) (cid:12)Nj(θ,Z)−Nj(θ¯,Z)(cid:12) (cid:12)(cid:3)
2 2 2 2 2 2
≤ C
T5,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
whereC := d c C +C . ForT ,weseethat
T5,max 2 W2 max,3 max,ZN 6
E(cid:2)(cid:12) (cid:12)Nj(θ,Z)σ 2N (cid:0) 1−σ 2N(cid:1) −Nj(θ¯,Z)σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)(cid:3) ≤ C T6,max(cid:12) (cid:12)θ−θ¯(cid:12) (cid:12),
whereC := C . ForT ,byusing(114)and(113),weget
T6,max max,4 7
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)(cid:0)(cid:10) W 0K·,Z(cid:11) +f(cid:0) bK
0
(cid:1)(cid:1)1 AK(Z)−(cid:0)(cid:10) W 0K·,Z(cid:11) +f(cid:0)¯bK
0
(cid:1)(cid:1)1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
≤ m 1c W0E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z| (cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3) +cE(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3) +E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0) bK
0
(cid:1) −f(cid:0)¯bK
0
(cid:1)(cid:12) (cid:12)(cid:3)
≤ m 1c W0E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:105) +(m 1c
W0
+c)E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
+E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)f(cid:0)¯bK(cid:1) −f(cid:0)¯bK(cid:1)(cid:12) (cid:12)(cid:3)
0 0
≤ C
T7,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
whereC := c C +(c +c)C +E[|Y|]. ForT ,byusing|f(v)| ≤ c,|f′(v)| ≤
T7,max W0 YZ,max W0 Y,max 8
1,(111),and(112),wenoticethat
E(cid:2)(cid:12) (cid:12)Nj(θ¯,z)σ¯ 2N (cid:0) 1−σ¯ 2N(cid:1)(cid:12) (cid:12)|σ 1−σ¯ 1|(cid:3)
≤ d 2c W2E(cid:2)(cid:12) (cid:12)(cid:0)(cid:10) W 0K·,Z(cid:11) +f(cid:0) bK
0
(cid:1)(cid:1)1 AK(Z)−(cid:0)(cid:10) W 0K·,Z(cid:11) +f(cid:0)¯bK
0
(cid:1)(cid:1)1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
(cid:18)
≤ d 2c
W2
m 1c W0(cid:16) E(cid:2)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3) +E(cid:104) |Z|2(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:105)(cid:17) +E(cid:2)(cid:12) (cid:12)f(bK
0
)(cid:12) (cid:12)(cid:12) (cid:12)1 AK(Z)−1
A¯
K(Z)(cid:12) (cid:12)(cid:3)
(cid:19)
+E(cid:2)(cid:12) (cid:12)1
A¯
K(Z)(cid:12) (cid:12)(cid:12) (cid:12)f(bK
0
)−f(¯bK
0
)(cid:12) (cid:12)(cid:3)
≤ C
T8,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
whereC
T8,max
:= d 2c W2(m 1c W0(C1,max+C Z,max)+cC1,max+1). Finally,weobtain
E(cid:104)(cid:12)
(cid:12) (cid:12)G
W
1NK(θ,x)−G
W
1NK(θ¯,x)(cid:12)
(cid:12)
(cid:12)(cid:105)
≤ C
max,W1(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12), (125)
(cid:18)
where C := 2c m m c C +cC +m c C +cC +C +
max,W1 W2 2 1 W0 T3,max T4,max 1 W0 T5,max T6,max T7,max
(cid:19)
C +C andC := 2 (m c E[|Y||Z|]+cE[|Y|]+m d c c E[|Z|]+cd c ).
T8,max T9,max T9,max c 1 W0 1 2 W0 W2 2 W2
Then,Assumption3holdsbysubstituting(123),(124),and(125)into(108). Furthermore,Assumption4
holdswithA(x) = 2λ I andB(x) = 0,whichimpliesa = 2λ andb = 0. Therefore,theoptimization
r d r
problem(14)satisfiesAssumptions1-4. □
ProofofCorollary4.3. Letθ = ([W ],b ,b ) ∈ Rd,θ¯= (cid:0)(cid:2) W¯ (cid:3) ,¯b ,¯b (cid:1) ∈ Rd,andletA andA¯ be
1 0 1 1 0 1 K K
definedin(110). OnenotesthatundertheassumptionsinProposition4.2,thefollowingresultcanbe
obtained. Foreachk = 1,··· ,d andj = 1,··· ,m ,wehave
1 2
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
(cid:20) (cid:21)
= E (cid:12) (cid:12)Yj(cid:12) (cid:12)1 (cid:110)(cid:16) −f(¯bk)−(cid:80) WkiZk(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WkiZk(cid:17) /Wkvk(cid:111)
0 i̸=vk 0 0 0 i̸=vk 0 0
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
= Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk (cid:12) (cid:12)yj(z)(cid:12) (cid:12)f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk52 L.LIANG,A.NEUFELD,ANDY.ZHANG
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
≤ Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk |c y(1+|z|ρ)|f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
≤ Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk |c y|f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
+ Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk |c y||z|ρf Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k.
W0kvk
Thisimpliesthat
E(cid:2)(cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:3)
≤ |c y|(cid:18) WC Z 0kv vk k (cid:12) (cid:12) (cid:12)¯bk 0 −bk 0(cid:12) (cid:12) (cid:12)+2ρ−1(cid:90) Rm1−1(cid:90) −− f(f ¯b( k 0b )k 0 −)− (cid:80)W(cid:80) i̸=0ki̸= vv kkvk WW 0k1 vk kizi |zv k|ρf Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW1kizi
(cid:19)
+2ρ−1 Rm1−1 −f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kvk f Zvk|Z−vk (zv k | z −v k)dzv k|z −v k|ρf Z−vk (z −v k)dz −v k
W0kvk
≤ |c |(cid:18) C Zvk (cid:12) (cid:12)bk −¯bk(cid:12) (cid:12)+2ρ−1C¯ Zvk (cid:12) (cid:12)bk −¯bk(cid:12) (cid:12)+2ρ−1C Zvk E[|Z |ρ](cid:12) (cid:12)bk −¯bk(cid:12) (cid:12)(cid:19)
y Wkv k (cid:12) 0 0(cid:12) Wkv k (cid:12) 0 0(cid:12) Wkv k −v k (cid:12) 0 0(cid:12)
0 0 0
≤ C
YZ,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
where the first inequality holds due to |x+y|p ≤ 2p−1(|x|p+|y|p) for any x,y ∈ R and p ≥ 1
(cid:26) (cid:27)
and where C := max (cid:0) 1+2ρ−1(cid:1) C Zvk +2ρ−1C¯ Zvk |c |(1+E[|Z|ρ]). Furthermore, by
YZ,max
k
Wkvk Wkvk y
0 0
using (112) and |x+y|p ≤ 2p−1(|x|p+|y|p) for any x,y ∈ R and p ≥ 1, we derive, for each
k = 1,··· ,d andj = 1,··· ,m ,that
1 2
E(cid:104)(cid:12) (cid:12)Yj(cid:12) (cid:12)|Z|2(cid:12) (cid:12)1
A
k(Z)−1
A¯
k(Z)(cid:12) (cid:12)(cid:105)
(cid:20) (cid:21)
= E (cid:12) (cid:12)Yj(cid:12) (cid:12)(cid:16) |Z|2(cid:17) 1 (cid:110)(cid:16) −f(¯bk)−(cid:80) WkiZi(cid:17) /Wkvk≤Zvk<(cid:16) −f(bk)−(cid:80) WkiZi(cid:17) /Wkvk(cid:111)
0 i̸=vk 0 0 0 i̸=vk 0 0
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
≤ |c y|
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |z|2|1+|z|ρ|f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
≤ |c y|
Rm1−1
−f(¯b0)k−W (cid:80)0
ik ̸=vk
vkW0kizi |z|2f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
+|c y|
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |z|ρ+2f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:18)(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
≤ |c y|
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |zv k|2f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk53
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
+
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi f Zvk|Z−vk (zv k | z −v k)dzv k|z −v k|2f Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
+2ρ+1
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi |zv k|ρ+2f Zvk|Z−vk (zv k | z −v k)dzv kf Z−vk (z −v k)dz −v k
W0kvk
(cid:90) (cid:90)
−f(bk 0)−(cid:80) i̸=vkW0kizi
(cid:19)
+2ρ+1
Rm1−1
−f(¯bk 0)−(cid:80)W i̸=0k vv kk W0kizi f Zvk|Z−vk (zv k | z −v k)dzv k|z −v k|ρ+2f Z−vk (z −v k)dz −v k
W0kvk
≤ |c y|(cid:18) (cid:0) 1+2ρ+1(cid:1) WC¯ Z kv vk
k
+(cid:16) E(cid:104) |Z −v k|2(cid:105) +2ρ+1E(cid:104) |Z −v k|ρ+2(cid:105)(cid:17) WC Z kv vk k(cid:19) (cid:12) (cid:12)θ−θ¯(cid:12) (cid:12)
0 0
≤ C
Y
Z2,max(cid:12) (cid:12)θ−θ¯(cid:12)
(cid:12),
(cid:26)(cid:18) (cid:19)(cid:27)
where C := |c |max (cid:0) 1+2ρ+1(cid:1) C¯ Zvk +(cid:16) E(cid:104) |Z|2(cid:105) +2ρ+1E(cid:104) |Z|ρ+2(cid:105)(cid:17) C Zvk . Then,
Y Z2,max y
k
Wkvk Wkvk
0 0
therestoftheprooffollowsthesimilarlinesasintheproofofProposition4.2. □
REFERENCES
[1] O¨mer Deniz Akyildiz and Sotirios Sabanis. Nonasymptotic analysis of Stochastic Gradient
Hamiltonian Monte Carlo under local conditions for nonconvex optimization. arXiv preprint
arXiv:2002.05465,2020.
[2] Peter C Austin and Michael J Schull. Quantile regression: a statistical tool for out-of-hospital
research. Academicemergencymedicine,10(7):789–797,2003.
[3] Olivier Bardou, Noufel Frikha, and Gilles Pages. Computing VaR and CVaR using stochastic
approximationandadaptiveunconstrainedimportancesampling. 2009.
[4] MathiasBarkhagen,NgocHuyChau,E´ricMoulines,Miklo´sRa´sonyi,SotiriosSabanis,andYing
Zhang. OnStochasticGradientLangevinDynamicswithDependentDataStreamsinthelogconcave
case. 2021.
[5] Amir Beck. Introduction to nonlinear optimization: Theory, algorithms, and applications with
MATLAB. SIAM,2014.
[6] HuyNChauandMiklosRasonyi. StochasticGradientHamiltonianMonteCarloforNon-convex
Learning. StochasticProcessesandtheirApplications,149:341–368,2022.
[7] Huy N Chau, Chaman Kumar, Miklo´s Ra´sonyi, and Sotirios Sabanis. On fixed gain recursive
estimatorswithdiscontinuityintheparameters. ESAIM:ProbabilityandStatistics,23:217–244,
2019.
[8] NgocHuyChau,E´ricMoulines,MiklosRa´sonyi,SotiriosSabanis,andYingZhang. OnStochastic
GradientLangevinDynamicswithDependentDataStreams: TheFullyNonconvexCase. SIAM
JournalonMathematicsofDataScience,3(3):959–986,2021.
[9] ChangyouChen,NanDing,andLawrenceCarin. OntheconvergenceofstochasticgradientMCMC
algorithms with high-order integrators. Advances in neural information processing systems, 28,
2015.
[10] TianqiChen,EmilyFox,andCarlosGuestrin. StochasticGradientHamiltonianMonteCarlo. In
Internationalconferenceonmachinelearning,pages1683–1691.PMLR,2014.
[11] Jiarui Chu and Ludovic Tangpi. Nonasymptotic Estimation of Risk Measures Using Stochastic
GradientLangevinDynamics. SIAMJournalonFinancialMathematics,15(2):503–536,2024.
[12] ThomasMCover. Elementsofinformationtheory. JohnWiley&Sons,1999.
[13] Hui Dong and Marvin K Nakayama. A tutorial on quantile estimation via Monte Carlo. Monte
CarloandQuasi-MonteCarloMethods: MCQMC2018, Rennes, France, July1–6, pages3–30,
2020.
[14] RickDurrett. Probability: TheoryandExamples. 2010.
[15] AndreasEberle,ArnaudGuillin,andRaphaelZimmer. Couplingsandquantitativecontractionrates
forLangevinDynamics. 2019.54 L.LIANG,A.NEUFELD,ANDY.ZHANG
[16] DanielEgloffandMarkusLeippold. Quantileestimationwithadaptiveimportancesampling. 2010.
[17] Eweda Eweda. Analysis and design of a signed regressor LMS algorithm for stationary and
nonstationaryadaptivefilteringwithcorrelatedGaussiandata. IEEETransactionsonCircuitsand
Systems,37(11):1367–1374,1990.
[18] EwedaEweda. Convergenceanalysisofanadaptivefilterequippedwiththesign-signalgorithm.
IEEEtransactionsonautomaticcontrol,40(10):1807–1811,1995.
[19] Tyler Farghly and Patrick Rebeschini. Time-independent generalization bounds for SGLD in
non-convexsettings. AdvancesinNeuralInformationProcessingSystems,34:19836–19846,2021.
[20] GersendeFort,EricMoulines,AmandineSchreck,andMattiVihola. ConvergenceofMarkovian
StochasticApproximationwithdiscontinuousdynamics.SIAMJournalonControlandOptimization,
54(2):866–893,2016.
[21] XuefengGao,MertGu¨rbu¨zbalaban,andLingjiongZhu. GlobalConvergenceofStochasticGradient
HamiltonianMonteCarloforNonconvexStochasticOptimization: NonasymptoticPerformance
BoundsandMomentum-BasedAcceleration. OperationsResearch,70(5):2931–2947,2022.
[22] XavierGlorotandYoshuaBengio. Understandingthedifficultyoftrainingdeepfeedforwardneural
networks. InProceedingsofthethirteenthinternationalconferenceonartificialintelligenceand
statistics,pages249–256.JMLRWorkshopandConferenceProceedings,2010.
[23] IanGoodfellow,YoshuaBengio,andAaronCourville. Deeplearning. MITpress,2016.
[24] Yuanhan Hu, Xiaoyu Wang, Xuefeng Gao, Mert Gurbuzbalaban, and Lingjiong Zhu. Non-
convexoptimizationvianon-reversibleStochasticGradientLangevinDynamics. arXivpreprint
arXiv:2004.02823,2020.
[25] Chii-RueyHwang. Laplace’smethodrevisited: weakconvergenceofprobabilitymeasures. The
AnnalsofProbability,pages1177–1182,1980.
[26] Philippe Jorion. Value at Risk: the new benchmark for managing financial risk. McGraw-Hill,
2007.
[27] Ioannis Karatzas, Steven E Shreve, I Karatzas, and Steven E Shreve. Methods of mathematical
finance,volume39. Springer,1998.
[28] DiederikPKingmaandJimmyBa. Adam: AMethodforStochasticOptimization. arXivpreprint
arXiv:1412.6980,2014.
[29] Chunyuan Li, Changyou Chen, Kai Fan, and Lawrence Carin. High-order stochastic gradient
thermostats for Bayesian learning of deep models. In Proceedings of the AAAI Conference on
ArtificialIntelligence,volume30,2016.
[30] Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, and Ying Zhang. Non-asymptotic estimates
for TUSLA algorithm for non-convex learning with applications to neural networks with ReLU
activationfunction. IMAJournalofnumericalanalysis,44(3):1464–1559,2024.
[31] YanliLiu, YuanGao, andWotaoYin. Animprovedanalysisofstochasticgradientdescentwith
momentum. AdvancesinNeuralInformationProcessingSystems,33:18261–18271,2020.
[32] AttilaLovas,IosifLytras,Miklo´sRa´sonyi,andSotiriosSabanis. TamingNeuralNetworkswith
TUSLA:NonconvexLearningviaadaptiveStochasticGradientLangevinAlgorithms. SIAMJournal
onMathematicsofDataScience,5(2):323–345,2023.
[33] Pierre-JeanMeyer. ReachabilityAnalysisofNeuralNetworkswithUncertainParameters. arXiv
preprintarXiv:2303.07917,2023.
[34] MatiurRahmanMinarandJibonNaher. Recentadvancesindeeplearning: Anoverview. arXiv
preprintarXiv:1807.08169,2018.
[35] Ariel Neufeld, Matthew Ng Cheng En, and Ying Zhang. Non-asymptotic convergence bounds
for modified tamed unadjusted Langevin algorithm in non-convex setting. arXiv preprint
arXiv:2207.02600,2022.
[36] Ariel Neufeld, Matthew Ng Cheng En, and Ying Zhang. Robust SGLD algorithm for solving
non-convexdistributionallyrobustoptimisationproblems. arXivpreprintarXiv:2403.09532,2024.
[37] BerntOksendal. StochasticDifferentialEquations: AnIntroductionwithApplications. Springer
Science&BusinessMedia,2013.
[38] Grigorios A Pavliotis. Stochasticprocesses and applications. Texts in Applied Mathematics, 60,
2014.
[39] YuryPolyanskiyandYihongWu. Wassersteincontinuityofentropyandouterboundsforinterfer-
encechannels. IEEETransactionsonInformationTheory,62(7):3992–4002,2016.55
[40] MaximRaginsky,AlexanderRakhlin,andMatusTelgarsky. Non-convexLearningviaStochastic
Gradient Langevin Dynamics: A Nonasymptotic Analysis. In Conference on Learning Theory,
pages1674–1703.PMLR,2017.
[41] Nageswara SV Rao andVladimir Protopopescu. Function estimation by feedforward sigmoidal
networkswithboundedweights. NeuralProcessingLetters,7:125–131,1998.
[42] SotiriosSabanisandYingZhang. Afullydata-drivenapproachtominimizingCVaRforportfolio
ofassetsviaSGLDwithdiscontinuousupdating. arXivpreprintarXiv:2007.01672,2020.
[43] AndrewStuartandAnthonyRHumphries. Dynamicalsystemsandnumericalanalysis,volume2.
CambridgeUniversityPress,1998.
[44] TaoTan,ShiqunYin,KunlingLiu,andManWan. OntheConvergenceSpeedofAMSGRADand
Beyond. In2019IEEE31stInternationalConferenceonToolswithArtificialIntelligence(ICTAI),
pages464–470.IEEE,2019.
[45] Ka Ho Tsang and Hoi Ying Wong. Deep-Learning Solution to Portfolio Selection with Serially
DependentReturns. SIAMJournalonFinancialMathematics,11(2):593–619,2020.
[46] CVillani. TopicsinOptimalTransportation(GraduateStudiesinmathematicsvol58)(Providence,
RI:AmericanMathematicalSociety). 2003.
[47] Ziyi Wang, Yujie Chen, Qifan Song, and Ruqi Zhang. Enhancing Low-Precision Sampling via
StochasticGradientHamiltonianMonteCarlo. TransactionsonMachineLearningResearch.
[48] MaxWellingandYeeWTeh. BayesianLearningviaStochasticGradientLangevinDynamics. In
Proceedingsofthe28thinternationalconferenceonmachinelearning(ICML-11),pages681–688,
2011.
[49] WeiBiaoWu. Onthebahadurrepresentationofsamplequantilesfordependentsequences. 2005.
[50] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a Novel Image Dataset for
BenchmarkingMachineLearningAlgorithms. arXivpreprintarXiv:1708.07747,2017.
[51] Dongpo Xu, Shengdong Zhang, Huisheng Zhang, and Danilo P Mandic. Convergence of the
RMSPropdeeplearningmethodwithpenaltyfornonconvexoptimization. NeuralNetworks,139:
17–23,2021.
[52] PanXu,JinghuiChen,DifanZou,andQuanquanGu. GlobalconvergenceofLangevinDynamics
basedalgorithmsfornonconvexoptimization. AdvancesinNeuralInformationProcessingSystems,
31,2018.
[53] I-C Yeh. Modeling of strength of high-performance concrete using artificial neural networks.
CementandConcreteresearch,28(12):1797–1808,1998.
[54] YingZhang,O¨merDenizAkyildiz,TheodorosDamoulas,andSotiriosSabanis. Nonasymptoticesti-
matesforStochasticGradientLangevinDynamicsunderlocalconditionsinnonconvexoptimization.
AppliedMathematics&Optimization,87(2):25,2023.
SCHOOLOFMATHEMATICS,RENMINUNIVERSITYOFCHINA,BEIJING,CHINA
Emailaddress:lianglux@ruc.edu.cn
DIVISIONOFMATHEMATICALSCIENCES,NANYANGTECHNOLOGICALUNIVERSITY,21NANYANGLINK,637371
SINGAPORE
Emailaddress:ariel.neufeld@ntu.edu.sg
FINANCIALTECHNOLOGYTHRUST,SOCIETYHUB,THEHONGKONGUNIVERSITYOFSCIENCEANDTECHNOLOGY
(GUANGZHOU),GUANGZHOU,CHINA
Emailaddress:yingzhang@hkust-gz.edu.cn