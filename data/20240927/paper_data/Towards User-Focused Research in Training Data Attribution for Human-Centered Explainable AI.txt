TowardsUser-FocusedResearchinTrainingDataAttributionfor
Human-CenteredExplainableAI
ELISANGUYEN,TübingenAICenter,UniversityofTübingen,Germany
JOHANNESBERTRAM,TübingenAICenter,UniversityofTübingen,Germany
EVGENIIKORTUKOV,FraunhoferHeinrichHertzInstitute,Germany
JEANY.SONG,InformationandInteractionDesign,YonseiUniversity,SouthKorea
SEONGJOONOH,TübingenAICenter,UniversityofTübingen,Germany
WhileExplainableAI(XAI)aimstomakeAIunderstandableandusefultohumans,ithasbeencriticisedforrelyingtoomuchon
formalismandsolutionism,focusingmoreonmathematicalsoundnessthanuserneeds.Weproposeanalternativetothisbottom-up
approachinspiredbydesignthinking:theXAIresearchcommunityshouldadoptatop-down,user-focusedperspectivetoensureuser
relevance.WeillustratethiswitharelativelyyoungsubfieldofXAI,TrainingDataAttribution(TDA).WiththesurgeinTDAresearch
andgrowingcompetition,thefieldrisksrepeatingthesamepatternsofsolutionism.Weconductedaneedfindingstudywithadiverse
groupofAIpractitionerstoidentifypotentialuserneedsrelatedtoTDA.Throughinterviews(N=10)andasystematicsurvey(N=31),
weuncoverednewTDAtasksthatarecurrentlylargelyoverlooked.WeinvitetheTDAandXAIcommunitiestoconsiderthesenovel
tasksandimprovetheuserrelevanceoftheirresearchoutcomes.
CCSConcepts:•Human-centeredcomputing→Userstudies;EmpiricalstudiesinHCI;•Computingmethodologies→Artificial
intelligence;Machinelearning.
AdditionalKeyWordsandPhrases:Needfinding,TrainingDataAttribution,ExplainableAI,Human-centredExplainableAI
1 INTRODUCTION
UnderstandingAImodelbehaviouriscriticalforusingAImodelsinpractice,especiallyinhigh-stakesdomainssuchas
medicine,law,orfinance[55].End-usersrequiretheunderstandingofmodelbehaviourstomakeinformeddecisions,
whiledevelopersneedthistobuildreliablemodelswithlimitedbiases[16].ExplainableAI(XAI)aimstoprovideinsights
intoAIsystems’functioningforhumans.Ithasproducedavarietyofexplanationmethodsthataddressdifferentmodel
architecturesanddatamodalities[16,26].
Despitetheprogress,theXAIcommunityhasfacedcriticismforitspredominanttechno-centricfocusonsolutionsas
opposedtotheproblemofhelpingusersunderstandmodelbehaviour[18].Historically,XAIresearchprogressedbottom-
up:startingwithmethodsprovidingqualitativeobservations,thenstructuringthefieldwithquantitativeevaluations,
andeventuallyconsideringapplicationinreal-worldenvironmentsincludingusers(seeFigure1).Consequently,XAI
wasmainlydrivenby“[solutionism(seekingtechnicalsolutions)and]formalism(seekingabstract,mathematical
solutions)”[18,p.2].Anexampleofthisbottom-upapproachisthedevelopmentofthesubfieldoffeatureattribution.
Featureattributionexplanationsquantifyeachinputfeature’scontributiontothemodelprediction,highlightingkey
inputs.Oneofthefirstfeatureattributionmethodsinthecontextofdeeplearningwaspresentedin2013introducing
thevisualisationofneuralnetworkinputgradientsassaliencymapexplanationsandproviding15qualitativeexamples
asevidencethatsaliencymapsexplain[68].Severalothermethodsfollowed,eitherbuildingonthisworkandproposing
Authors’addresses:ElisaNguyen,elisa.nguyen@uni-tuebingen.de,TübingenAICenter,UniversityofTübingen,Germany;JohannesBertram,Tübingen
AICenter,UniversityofTübingen,Germany;EvgeniiKortukov,FraunhoferHeinrichHertzInstitute,Germany;JeanY.Song,InformationandInteraction
Design,YonseiUniversity,SouthKorea;SeongJoonOh,TübingenAICenter,UniversityofTübingen,Germany.
1
4202
peS
52
]CH.sc[
1v87961.9042:viXra2 Nguyen,etal.
Fig.1. Comparisonofbottom-upandproposedtop-downdevelopmentofresearchwithselectedexamplesfromXAI.
changestosatisfyspecificformalaxioms(e.g.,[69,70]),orproposingmodel-agnosticmethodsinaquestforaone-
fits-allsolution(e.g.,[47,63]).Around2017,XAIreachedaninflectionpointwhereresearchersstartedtore-assess
thepracticalityofexplanationmethodsandproposedstandardevaluationprotocolstomeasurehowwellexplanation
methodsachievetheirgoalofexplaining[1,8,15].Subsequently,recommendationsfromthesocialscienceviewof
explanationsemphasisethatexplanationsarepartofasocialprocessandshiftedthefocusofthefieldin2019[49].
XAIwascriticisedforitsstrongsolutionismwithanincreasingamountofworksstudyingXAIasasociotechnical
systemfocusingontheuser[10,18,19,23,38–40,44,48,65,76]andnamingthissubfieldhuman-centredXAI(HCXAI)
in2020[20].
DespitetheeffortstorectifythesolutionismandformalisminXAIcommunities,weobserverepeatingpatternsin
sub-fieldsofXAI.Forexample,suchpatternsareemergingintherelativelyyoungfieldoftrainingdataattribution
explanations(TDA),wherethemodelbehaviourisexplainedbasedonthetrainingdata[29].TDAwasintroduced
tounderstanddeeplearningmodelsin2017[41]andhasproducedseveraltechnicalapproachestoprovideTDA
explanationssincethen[4,13,27,54,61,66].Thisdevelopmentdemonstratesastrongfocusonseekingtechnical
solutionsintheTDAfieldsimilartohowfeatureattributionresearchstarted.Currently,TDAresearchisgaining
momentumduetostudiesshowingthatTDAcanbeappliedtoaddressissueslikedatavaluation,debiasing,memorisation
andcopyrightinfoundationalmodels[14,22,24,34,43,46,78,80].Yet,thecurrentTDAlandscapesshowssolutionism
andformalism,withfewuser-focusedstudies,leadingtoapossibleriftbetweenTDAmethodsanduserneeds.
Inthiswork,weproposefutureresearchdirectionsfortheTDAcommunitythatareentirelysourcedandmotivated
bythepotentialusersofTDA.Westronglybelievethattheactualusecasesanduserneedsshouldinformandguide
XAIresearch,echoingthecallforHCXAI[20].Webreakdownourresearchquestionintothreeparts:
• RQ1:WhatdousersneedTDAexplanationsfor?
• RQ2:WhatdousersneedfromTDAexplanations?
• RQ3:TowhatextentdoexistingTDAapproachesalignwithuserneeds?
Weconductatwo-stageneedfindingstudywithpotentialusersofTDAtechnologytoanswerourresearchquestions.
ThroughaqualitativeinterviewstudywithAIpractitioners(N=10),weidentifymodeldevelopersasakeyusergroup
forTDAexplanationsasopposedtomodelusers.WederiveadesignspaceforTDAexplanationsrepresentingdifferent
TDAtasks(e.g.,identifyingthetrainingsampleswiththelargesteffectonmodelbehaviourwhenremovedincontrast
towhengivenalargerweightduringtraining).Westudywhichtasksareneededinmodeldevelopmentinasubsequent
mixed-methodssurveystudy(N=31)withmodeldevelopers.Byconsideringtheuserandtheirusagescenarios,we
identifytasksrelevanttousersbutlargelyoverlookedbycurrentTDAresearch.Weinvitetheresearchcommunityto
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 3
addressthesegapsandshiftthefocusofTDAresearchfromsolutionismtouser-servingquestions,i.e.,atop-down
approach.WeadvocateforadoptingthisapproachinotherareasofXAIandAIasawholetoavoidfocusingon
technicallyelegantsolutionsthatmayoverlookuserneeds.Ourcontributionsare:
• Weproposeatop-downapproachtoXAIresearchdrivenbyuserneedsanddemonstratethisapproachonthe
emergingTDAsubfield.
• Throughaneedfindingstudy,weidentifypotentialusecases,wheremodeldevelopersemergedaskeyusers
ofTDA.WefindthattheyrequireTDAexplanationstobe(1)flexibleandadapttotheuser’sintuitionsin
debuggingand(2)reliableandstable.Generally,weobserveapreferencefortrainingdatagroupattribution
overindividualattribution.
• Asaresultofstudyingtheuserneeds,weidentifytasksandresearchdirectionsforuser-focusedTDAthatare
currentlyunderstudied.
2 RELATEDWORK
Ourworkproposesatop-downapproachtoXAIresearch,groundedinuserneeds,whichpositionsitinhuman-centered
explainableAI(HCXAI).Weapplythisapproachtotherelativelyyoungsubfieldoftrainingdataattribution(TDA)to
provideearlyinsightsintousersandtheirneeds.Tothisend,weutilisemethodsfromneedfinding.Inthefollowing,we
relateourworktoHCXAI,TDAandneedfinding.
2.1 Human-centredexplainableAI
TheaimofexplainableAI(XAI)researchistostudymethodsthatexplainthebehaviourofAImodels[26].Thefieldhas
developedvariousexplanationmethodsovertheyearstoexplaindifferenttypesoftasksandmodels.Yet,explanationsare
onlymeaningfulinfrontofanaudience.ThishumanaspectwasoftenneglectedinXAIstudies[50,64].Toovercomethis
gap,Human-centredXAI(HCXAI)emphasisesthehumanintheexplanationprocessandfocusesonuserperspectivesin
XAI[20].InHCXAI,explanationsofblack-boxmodelsarestudiedholisticallyassociotechnicalsystemscentredaround
theuser[19].HCXAIexploreshowtodesignAItechnologyandexplanationsthatfocusonuserunderstandingand
practicality[20].Workinthisareacoversmultipleaspectsthataffecttheuser,e.g.human-AI-collaboration[40,44,67,71],
designguidelines[28,45,76],evaluationofhumanunderstandingofexplanations[28,39,64,65]andunderstandinguser
needsandrequirements[10,35,37,38].OurworkcontributestotheHCXAIfieldbyproposinganearlyconsideration
ofuserneedstoinformongoingresearchinXAImethods.WefocusparticularlyonTDAexplanationswhichhavenot
beenexploredwidelyinHCXAIbefore.
2.2 Trainingdataattribution
Trainingdataattribution(TDA)explainsmodelpredictionsbypointingtotrainingdatasamplesrelevanttothemodel
predictions[29].TDAdiffersfromthemainstreamXAIapproachknownasfeatureattribution(FA)wherethemodel
predictionsareattributedtothefeaturesofaninputgiventothemodel,disregardingtheimpactoftrainingdata.Interest
inTDAhasrecentlyacceleratedwiththeparadigmshifttowardsdata-centricAI(DCAI)[36],wheretheimportance
ofusingtherighttrainingdataisemphasisedoverotherfactorslikemodelarchitectureandoptimisationalgorithms.
UnderthecontextofDCAI,TDAhasbeenutilisedtoenhancedataqualitybycleaningfaultydatalabels[72]and
detectingmodelbiases[11,34,60,77].Therecentriseoffoundationalmodels,suchaslargelanguagemodels(LLMs)
anddiffusion-basedimage-generationmodels,furthercontributedtotheinterestinTDA,asithasproveneffective
Preprint.Underreview.4 Nguyen,etal.
forstudyingtheinnermechanismsaswellasunderstandingtheassociatedcopyrightandprivacyleakageissues
therein[14,22,24,46,80].Withtheacceleratedgrowth,weobserveagainageneralfocusontechnicalandmathematical
solutionsintheTDAcommunity[4,13,14,27,41,43,54,61,66],withoutadeepunderstandingofuserneeds,evenin
studiesapplyingTDAtoadownstreamtasks[2,22,34,80].Ourworkaddressesthisgapbystudyingpracticalneeds
andprovidingconcreterecommendationsforthefield.
2.3 Needfinding
Needfindingisanexploratoryandqualitativeapproachtouserresearchtounderstandusers’needsbeyondwhatsimply
askingusersmaytell[57].Itaimsatstudyingthetrueuserneeds,regardlessofsolutions,whichmaynotbeapparent
totheusersthemselves.Needfindingstemsfromthefieldofdesignthinking[74],whichisaniterativedesignapproach
drivenbyuserneeds.Needfindingisaniterativeprocessinvolvinguserswherethesubsequentstudiesextractgreater
informationabouttheirproblemsandneedsthroughfieldstudies,interviews,andlabstudies.InXAI,needfinding
hasbeenusedtostudygeneralneedssuchasuserexpectationsforXAI[10]orend-usertransparencyneedsinAI
decision-supportsystems[46,73]byusingsemi-structuredinterviews,scenario-basedstudydesignsandqualitative
analysesofcase-studyrelatedtextfiles.Needfindinghasalsobeenappliedtomorenarrowquestions,likeextractinguser
needsforweb-searchexplanationsthroughsurveysandsemi-structuredinterviews[37]orunderstandingexplainability
needsinhuman-AIcollaborations[40].Ourworkextendsthisoverallresearchdirectionbystudyingtheuserneedsof
TDAexplanationsthroughatwo-stagestudyinvolvingsemi-structuredinterviewsandasystematicsurveystudy.
3 TRAININGDATAATTRIBUTION
Ourworkstudiesuserneedsfortrainingdataattribution(TDA)explanations.ThissectionprovidesbackgroundonTDA.
TDAislinksspecificmodelbehaviourtothetrainingdata,treatingthedataastherootcauseforlearnedbehaviours[29].
Byprovidingtrainingdatarelevanttowhatthemodelhaslearnt,TDAgivesinsightsintothemodel.TDAhasbeen
appliedtoenhancingdataqualityandreducingmodelbiases,aswellasansweringquestionsarounddatavaluation,
memorisationandcopyrightissuesinfoundationalmodelsintherecentyears[14,24,46,80],attractingunprecedented
attention.
Formaldefinition. TheTDAcommunityhasfocusedonaparticularinstanceofattributingamodelpredictionona
singletestsampleonasingletrainingsample.Moreformally,letusconsideratrainingsample𝑧 train:=(𝑥 train,𝑦 train)
andatestsample𝑧 test:=(𝑥 test,𝑦 test),where𝑥indicatestheinputand𝑦indicatesthetrueanswerthemodelissupposed
topredict.Wedefinetheattributionscore𝜏 for𝑧 trainand𝑧 testasthechangeinthecorrectnessofthemodelprediction
on𝑧 test,measuredviathemodellossL(𝑓 𝜃(𝑥 test),𝑦 test),beforeandafterremovingthesample𝑧 trainfromthetraining
procedure[30]:
(cid:16) (cid:17)
𝜏(𝑧 train,𝑧 test;𝑓 𝜃):=L 𝑓 𝜃 \𝑧train(𝑥 test),𝑦 test −L(𝑓 𝜃(𝑥 test),𝑦 test). (1)
Here,weindicatethemodeltrainedwithalltrainingsamplesas𝑓 𝜃 andtheonetrainedwithout𝑧 trainas𝑓 𝜃 \𝑧train.
MainfocusofTDAresearch. Computing𝜏 directlybyre-trainingamodelwithouteachtrainingsample𝑧 train is
computationallyprohibitive.Toidentifythemostinfluentialtrainingsample,there-traininghastoberepeatedasmany
timesasthenumberoftrainingsamples.ThemainfocusoftheTDAcommunityhasbeenonefficientapproximationsof
Equation1.In2017,Koh&Liang[41]introducedagradient-basedapproximationcalledinfluencefunctions(IF).Since
IFwasstillcomputationallyprohibitiveduetotheneedtocomputeandinvertamassiveHessianmatrix,subsequent
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 5
worksin2020and2021havefocusedonspeedingupthealgorithmbytradingoffprecisionandcomputationalcosts
[13,27,61,66].AftertheadventofChatGPTinlate2022[53]andtheboominlargelanguagemodelsin2023[51],the
communityhasdevelopedfurtherenhancementstoapplytheTDAmethodsonbillion-scaleLLMs[4,14,24].
Critique. WeobservehintsofsolutionismandformalisminthedevelopmentofTDAresearch,asthemajorityof
thecommunityeffortisdedicatedtoaddressingcomputationalinefficienciesofthemethoditself,withoutquestioning
thepracticalrelevanceanduservaluesofTDAasdefinedinEquation1.ThisparticularformulationofTDAhasnot
gonewithoutcriticismwithinthecommunity:apriorwork[52]discussedthestatisticalinsignificanceofremovinga
singletrainingsampleinmodernneuralnetworktrainingand[33]recognisedthelimitationandarguedforexamining
theremovalofmultipletrainingsamples.SomeTDAworkshaveexploredpossibleapplicationsthatarepotentially
interestingtouserssuchasfixingmislabelleddata[41]oridentifyingbrittleclasses[33].However,theseapplications
arestillnotdrivenbyuserneeds.ThereisnoknownworkintheTDAdomaininvolvingactualuserstoidentifytheir
needstoassesstherelevanceofthecurrentTDAtasksandidentifyresearchdirectionsgroundedinuserneedsthatthe
communityshouldfocuson.
4 UNDERSTANDINGUSERNEEDSOFTDAEXPLANATIONSTHROUGHNEEDFINDINGSTUDY
Ourworkstudiesuserneedsoftrainingdataattribution(TDA)explanationstofacilitateuserneed-drivenTDAresearch.
Tothisend,weconductatwo-stageneedfindingstudy.First,weidentifyusecasesforTDAexplanationsusingsemi-
structuredinterviews.Theexperimentalsetupisdescribedin§4.1.§4.2presentstheinterviewfindings.Wederivea
designspacerepresentingdifferenttypesofinformationthatmaybeneededfromTDAin§4.3.Second,weconducta
systematicsurveystudytargetedatextractinguserneedsfromthisspace(§4.4).IRBapprovalwasobtainedfromone
oftheauthors’institutions.
4.1 Interviewstudy
Intheinterviewstudy,weconductsemi-structuredinterviewswithusersofmachinelearning(ML)applicationsoutside
ofMLresearch.Thisservesasanexploratorystudytogainanimpressionofpotentialusagescenariosanduserneeds
forTDARQ1–WhatdousersneedTDAexplanationsfor?
4.1.1 Participants. TogetarealisticimpressionofuserneedsforTDAexplanationsinpractice,wetargetparticipants
whoworkwithMLapplicationsoutsideofacademia.Ourinclusioncriteriaare:Participantsshould(1)haveatleastone
monthofexperienceinworkingwithMLsystemsand(2)workinahigh-riskapplicationareaaccordingtotheEU
AIAct[55](e.g.,healthcare,lawenforcement,completelistinAppendixA).Thiscriterionservestofinduserswho
arelikelytouseexplanations,astheseareasaresubjecttofurtherregulations[15,26].Recruitingparticipantsposesa
challenge,especiallyinhigh-riskapplicationareas.Hence,weusepurposivesampling[25]andapproachparticipants
fromtheauthors’network.Werecruit10participantsfromvariousdomainsanddegreesofexperience(seeTable1).
4.1.2 Interviewprocess. TheinterviewswereconductedduringJune–September2023,eitherinpersonorremotely
throughvideocallusingZoom1.Allinterviewsareone-on-oneconversationsinEnglish,exceptforP10inGerman.
Participantswerefirstbriefedaboutthepurposeofthestudyanddataprocessing.Uponreceivinginformedconsent,we
begantheinterviewrecording.Ingeneral,theinterviewslastedbetween30and60minutes.Eachinterviewaddresses
thefollowingtopicstoanswerRQ1-WhatdousersneedTDAexplanationsfor?:
Preprint.Underreview.6 Nguyen,etal.
Table1. Interviewparticipantinformation.HR=Humanresources,AV=autonomousvehicles,TC=telecommunications,CV=
Computervisionforautomation.P5didnotmeettheinclusioncriteria.
ID Location Domain Type Jobexperience/withML TypeofML
P1 DE HR User 3years/1months Chatbot
P2 US AV Developer 2years/7years Predictionmodel
P3 NL TC Developer 3years/5years Predictionmodel
P4 FI CV Developer 4years/6years Predictionmodel
P6 CH Health User 2years/2years Predictionmodel
P7 NL Health Developer 1year/3years Predictionmodel
P8 BE Health Developer 2years/6years Predictionmodel
P9 PK Health Developer 5years/2years Predictionmodel
P10 DE HR User 3years/1year Chatbot
P11 DE Health User 10years/6years Clustering,Chatbot
• Job-relatedinformation.Perspectivesmayvarybetweendifferentdomains,levelsofseniorityandexperience
withtheMLtool.Thisinformationprovidesusercontextandwillhelpindifferentiatingusergroups.
• Interviewee’sworkflowwithMLsystems.ByaskingabouttheworkflowwiththeMLtool,wewishto
understandthepatternsofusageandchallengesparticipantsencounter.Wecollectthisinformationtoidentify
challengesthatcouldpotentiallyaddressedbyTDA.
• Perspectivesontrainingdata.SinceweinvestigateTDAexplanations,weexplicitlyaskparticipantsabout
theroletrainingdataplaysintheirtasks.Thisindicateswhattypeofdata-centricinformationisrelevanttothe
participant’sworkandforwhichtasks.
• PerspectivesonXAIandTDA.Weaddresstheparticipant’sperspectivesonXAIandparticularlyonTDAto
understandcurrentexplanationusagescenariosandexploreparticipant’sopinionsaboutTDA,adata-centric
approachtoXAI.
4.1.3 Dataanalysis. WeanalysetheinterviewdataandextractrelevantinformationforansweringRQ1.Theinterviews
aretranscribedautomaticallyusingWhisper[62]andcleanedupmanuallybytheauthors.Thetranscriptisthen
pseudonymised.WetranslatedP10’sGermantranscripttoEnglishusingDeepL2.Wethenanalysethetranscripts
throughaninductivethematicanalysis[9]bytwocoders,wherethecodesaredirectlyannotatedinthetranscript.The
analysisisiterative:TheinterviewtranscriptofP1isfirstjointlyanalysedinaninitialcodingworkshopthatresulted
inaninitialsetofthemes.Afterwards,thecodersindependentlycodefivetranscripts,expandingonthethemesfound
intheinitialanalysis.Duringanintermediatecodingworkshop,agreementsanddisagreementsbetweenthecoder’s
themesarediscussed.Theworkshopresultedinamergeddefinitionofthethemesthatareusedfortheremaining
transcripts.Attheintermediatecodingworkshop,theinterrateragreementis77.3%measuredbythepercentage
ofagreementparticipantscodedtothemes.Thefinalcodingworkshoptakesplaceafterbothcodersreviewedthe
remainingtranscripts.Thefinalinterrateragreementis80.3%.
4.2 Interviewfindings
TheinterviewstudyaimstoprovideinsightsintothepotentialusefulnessofTDA,answeringRQ1-Whatdousers
needTDAexplanationsfor?Theanalysisyieldssixthemeareas,whicharecommonacrossallparticipants(seelight
1https://zoom.us/
2https://www.deepl.com/translator
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 7
Fig.2. Themeareaswithcorrespondingthemesfoundintheinductivethematiccodinganalysisoftheinterviewtranscripts.Training
dataandTDArelatedthemesareorangeandmarkedwithastar.FulldescriptionofthemesinAppendixB.
greyboxesinFigure2):theroleoftheMLsystemasanapplication,theworkflowofparticipantswithMLsystems,
theroleoftrainingdataforparticipant’swork,themainchallengesinworkingwithMLsystems,theuseandroleof
explanationtools,andperspectivesandopinionsaboutdata-centricexplanationslikeTDA.Weelaborateoneacharea
belowandprovideafulloverviewinAppendixB:
4.2.1 RoleofMLsystems. OurparticipantsworkwithdifferenttypesofMLmodelsacrossseveraldomainsandin
differentpositions(seeTable1).WefindthatMLsystemsareusedasworkassistants(P1,P10,P11),decisionsupport
systems(P3,5,6,7,8,9),andforautomationinsystemslikeautonomousvehiclesormachinery(P2,P4).Theseroles
providecontextforouranalysis,astheneedsandusagescenariosofXAImaydifferbasedonthelevelofuserinteraction.
Forexample,P4developsautomatedcomputervisionmodelsforanimalpopulationmonitoringwithminimalhuman
involvement,whileP10usesachatbottohandlesmallertaskslikeansweringemployeequestions.Ouranalysisisset
againstthebackdropoftheseusecases.
4.2.2 WorkflowwithMLsystems. AsMLsystemstakedifferentroles,theworkflowsdiffer.WenoticethatMLsystems
arenotanessentialpartoftheworkflowforsystemusers,asopposedtodevelopers.Systemusersonlyintegratethe
MLsystemintheirworkwhenitdelivershelpfulsuggestionsandreportbugsorignoreitotherwise(P6,P10).We
recogniseaseparationofdomainknowledge(collaborationwithdomainexperts):“Becausepersonally,Icannot
knowifthemodelisdoingthecorrectthing[...]businesshavetotellme"(P3).Fordeveloperswhosejobrevolves
aroundtheMLsystem,weidentifythemesthatarerelevantforunderstandingusagescenariosofXAIandTDA.We
findthatthedevelopmentworkflowisheavilycentredarounddata:“[What]drivesyourmodelisyourdata.[...]”(P8)
(data-focuseddebuggingprocess,dataqualitychecks).Often,standardmodelarchitecturesareemployedwith
standardhyperparameters(standardmodelchoices)andthemainworkliesindatacuration(P2,P4,P3,P7,P8,
P9).Thisthemeareashowsthattherearetwodistinctusergroups,systemuserswhoutiliseMLsystemsandmodel
developerswhobuildMLsystems.TheyhavedifferentworkflowsandpotentialXAIusecases.
Preprint.Underreview.8 Nguyen,etal.
4.2.3 Roleoftrainingdata. Thetrainingdataplaysdifferentrolestosystemusersandmodeldevelopers.Whileitis
themostimportantvariableinamodelfordevelopers(P3,P4,P8),trainingdataisgenerallynotinterestingto
systemusers(P1,P10).SystemusersoftendonothavecapacitytointeractmuchwiththeMLsystemtoverifymodel
behaviour,eveniftheyaninterestintheunderlyingmechanismsexists,becausetheyarepreoccupiedwiththeirown
tasks(interestingbutnocapacity)(P6).However,fordevelopers,trainingdataisaleverformodelperformance
(increasingtrainingdataasabugfix,trainingdataartifactsasmainbugcauses)(P2,P4,P3,P7,P8,P9,P11).
TheseinsightsunderlinethatXAIneedstobeintuitive,andTDAisparticularlysuitedformodeldevelopmentandless
forsystemusers.
4.2.4 ChallengesinworkingwithMLsystems. Intheinterviews,weaskparticipantsaboutchallengesintheirML
workflowtoexploreifXAIcanaddressthem.Weidentifiedsixthemesinthisthemearea.WeconfirmKimetal.’s[40]
observationthatsystemusers’mainchallengeforworkingwithMLsystemsistrustcalibration(P1,P6,P8,P11).
Inaddition,wefindthatsystemusersfeartheymaymisusetheMLsystemduetolackingknow-how(P1,P10,
P11),highlightingtheneedforusertrainingtomakeeffectiveuseofMLsystemsinpractice.Formodeldevelopers,we
identifyseveralchallenges:Dataqualityissuesareoftentherootcauseofmodelmalfunction(dataqualityissues)
(P2,P4,P3,P7,P8,P9,P11),inturnimpactingmodelvalidationandevaluation.Forinstance,participantsencounter
difficultiesduetomissingdataorabsentlabels(P2,P4,P3,P7,P8,P9).Additionally,resourceconstraints(P2,P4,P11)
andthestochasticnatureofMLmodels(P2)arepainpointsforthedevelopmentandevaluationofMLsystems.
Ouranalysisshowsthatthechallengesfacedbysystemusersrequiresociotechnicalconsideration,whereaschallenges
facedbymodeldevelopersaremoretechnicalwithdataqualityandevaluationbeingmostpressing.Webelievethatthe
latterisasuitableusagescenarioforTDA.
4.2.5 UseofXAIinpractice. ThisthemeareagroupssixthemesabouttheuseorlackofXAIinpractice.Ouranalysis
revealsthatXAIisusuallynotastandardpartofanMLsysteminpractice(XAIisnotused,XAIislittleused)
(P1,P4,P6,P7,P9,P10,P11).Infact,theusesofXAI,inparticularfeatureattribution,amongourparticipantsare
limitedtomodeldevelopment(P2,P3,P8).XAIoffersexplanationsforper-exampledebuggingoractasasanity
checkformodelreasoning(P8,P9).Unexpectedly,developerparticipantsalsouseXAItounderstandreal-world
phenomenamodelledbytheirMLsystem(P3)andasacommunicationmeanstogetcustomerbuy-infortheir
MLsystems(P8).Whileexplanationshavedifferentpurposes,wenotethatparticipantsuseXAItoolsmainlyasan
out-of-the-boxfunctionality(e.g.,theSHAPlibrary[47]).Wefindthatimplementationthresholdsmustbelowforthe
adoptionofXAIinpractice.
4.2.6 UserperspectivesonTDA. NoneoftheparticipantswerefamiliarwithTDA,highlightingagapbetweenresearch
andpractice.Ouranalysis,basedondiscussionsabouttheconceptofTDA,identifiesfourthemesreflectingparticipants’
viewsonXAIandTDA.Overall,participantsfindXAIusefulfordebuggingandcommunication,thoughtheynotedits
usefulnessisuse-casedependentandnotalwaysguaranteed.TheyexpectTDAnottobeanexception(P3,P6,P8,
P11),butareoptimisticaboutitspotential,especiallyformodeldevelopment.Forinstance,P2mentionedthatTDA
couldsavetimebyidentifyingfaultytrainingdata.OneparticipantsuggestedcombiningTDAwithfeatureattribution
fordebugging(P3).Weobservedthatparticipantshavedifferentnotionsofinterestingtrainingsamples,with
somefocusedonfindingfaultydata(P2,P11)andothersonidentifyingsamplessimilartoaspecificone(P6,P7,P8).
Inconclusion,weidentifythatTDAcouldbevaluableformodeldebugging,leadingustofocusonthisusergroup
andusecaseintheremainderofthiswork.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 9
Table2. Codesbelongingtothemesdataqualityissuesanddifferentnotionsofinterestingtrainingsamplesthatcorrespond
tocommondebuggingusecasesandinterestingquestionsforTDAmentionedbyparticipantsintheinterviewstudy.
ThemeA:Dataqualityissues
ThemeB:Differentnotionsofinterestingtrainingsamples
ID Theme Code Description Participants
#1 A Distributionshifts Ifthedifferenceindatadistributionbetweentrain- P3,P4
ingandtestingdataistoolarge,themodeldoesnot
learn.Thiscanalsohappenovertime.
#2 A Dataunavailability Missingdataentriesormissinglabelsarecommon P2,P3,P7,P8,P9
problems,particularlyfortabulardata.
#3 A&B Wronglabels Annotationisanexpensivetasksubjecttohuman P2,P4
error.mislabelleddataishenceapossiblereason
formodelerror.
#4 A Datascaling Wrongdatascalingintabulardata(e.g.usingmeters P3
insteadofcentimetres)canleadmodelstolearn
wrongcorrelations.
#5 A Historicaldata Outdateddatathatisnotcleanedoutofthetraining P9
datasetcancontaminatethetraining.
#6 B Outlierdatapoints Dataoutliers,i.e.mislabelleddataor“unusualdata P3,P8
points”(P3)canaidformodeldebugging.
#7 B Decisionboundarysamples Samplesatdecisionboundaryareinterestingto P7
understandthemodelbehaviour.
#8 B High-confidencesamples Samplesthatthemodelissureabouttendtorepre- P7
sentwhatthemodelhaslearntandhelpinunder-
standingthemodelbehaviour.
#9 B Similartrainingsamples Trainingsamplesthataresimilarinfeaturestothe (P6),P7,P8
testsampleandhowthemodelbehavesontheseis
helpfulforunderstandingmodelbehaviour.
#10 B Groupofsamples Inspectingmultipletrainingsamplesisgenerally P8
moreinterestingtoestimatemodelbehaviour.
4.3 DefiningadesignspaceofTDAexplanations
TheinterviewanalysisrevealsmodeldevelopersasakeyaudienceforTDAexplanations,withmodeldebuggingasa
promisingusecase.BeforeaddressingRQ2–WhatdousersneedfromTDAexplanations?,wetranslatethese
insightsintoadesignspaceofTDAexplanationsinmodeldebugging.Thespaceshallillustratehowexplanatory
informationabouttrainingsamplesandmodeloutputcouldlooklike,formingthebasisforthestudyaddressingRQ2.
Interviewparticipantsprovidedrichinformationaboutwhattheyusuallylookoutforinthetrainingdatawhen
debuggingamodel.Wecodedthisinformationintothefollowingthemes:Dataqualityissues,anddifferentnotions
ofinterestingtrainingsamples.WepresentthedescriptionsofthecorrespondingcodesinTable2andusethemto
identifydifferentaxesofinformationthatcouldberepresentedbyTDAexplanations.Specifically,wefindthatdifferent
dataartefactsaredebuggedusingdifferentactions,withusersinterestedinvariousmetricsandconsideringdifferent
numbersoftrainingsamples.Fromtheseobservations,wedefineathree-dimensionaldesignspace(seeFigure3).Inthe
following,wedetailthereasoningbehindeachaxisandconnectittothecodesinTable2viatheIDcolumn.
Preprint.Underreview.10 Nguyen,etal.
Fig.3. Three-dimensionaldesignspaceofTDAexplanationsrepresentingthetypeofdata-centricinformationusefultothemodel
developmentprocess.Derivedfromourinterviewstudyfindings.
4.3.1 Axis1:Actiondefiningrelevance. Thefirstaxiscorrespondstotheactionsparticipantsproposefordifferenttypes
ofdataartefacts:Removingdata,changingthelabel,reweightingdataandcollectingmoredata(x-axisofFigure3).
Participantslookatdatatoremovewhenitisclearlymaliciousdataandlikelyhurtsmodellearning,forinstance
mislabelled(#3)oroutdated,historicaldata(#5).Additionally,wefindthatparticipantslookfordatathattheywish
tochange,forexamplefillinginorimputingmissingdata(#2),orcorrectingwrongdatascales(#4)andlabels(#3).
Especiallywhendataishardtoobtain(e.g.inthemedicaldomain),removingdataisnotanoptionandcorrecting
dataispreferred(P6).Anotheractionisthereweightingoftrainingsamplesandcollectingmoredatarelatedtothe
error.Theseactionsemphasisespecificsamplesinthetrainingprocesstoencouragethemodeltolearnthem.Thisis
particularlyrelevanttolearningoutliers(#6)andhandlingdistributionshifts(#1).
Removal,changeandadditionofdatahavedifferenteffectsonamodelandthereforerepresentdifferentquantifications
ofattribution:Forinstance,removalasintraditionalTDA(Equation1in§3)orbyadditionofdata.Essentially,these
examplesmaptothequestions:Howwouldthemodelbehaviourchangeifonewereto(a)excludeatrainingsample?
or(b)addmoretrainingsampleslikethetestsampletothedataset?Byunderstandingpreferencesinthisaxis,weaim
toidentifywhatisneededfordataattributiontobeactionableandreflectthedebuggingprocess.
4.3.2 Axis2:Metric. Thesecondaxiscorrespondstothesample-wisemetricsparticipantsusedwhenreferringto
modelbehaviour:theloss,theprobabilityofthetrueclasslabel,andtheprobabilityofthepredictedclasslabel(y-axis
ofFigure3).Theinterviewsshownotallparticipantsthinkofmodelbehaviourintermsofsampleloss,butalsoin
classificationprobability.Whilehighlosscanbeanindicatorforwrongoroutliersamples(#3,#6),participantsvoiced
theirinterestinsampleswherethemodelhashighorlowclassificationprobability (#7,#8).Suchsamplesprovide
contextoftheglobalmodelbehaviourtothemodeldeveloper,andcanthereforebehelpfulfortheirwork.
Themetriccanbeseenasameasurebywhichparticipantsprimarilyperceivemodelbehaviourinthedebugging
process.Byunderstandingmetricpreferences,weaimtoidentifythemetricthathelpsmodeldevelopersmostin
debugging,testingwhetherthelossasintraditionalTDAisthemostactionablemeasure.
4.3.3 Axis3:Numberoftrainingsamples. Thethirdaxiscorrespondstothenumberoftrainingsamplesparticipants
needtomakesenseofamodelerrorthroughthetrainingdata.Weidentifytwomainoptions:Asinglesampleanda
groupofsamples(z-axisofFigure3).Wefoundthatmodeldevelopersusuallydonotinspectjustonetrainingdata
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 11
Fig.4. Histogramsshowingtheanswerdistributionsforthepreliminarydemographicquestionsofthesurveystudy(N=31).DL=
Deeplearning.
samplebutthinkmoregloballyastheyusuallyrefertotrainingdataandsamplesinpluralform(#10).Thisaspectis
addressedinTDAresearchbyworksstudyinggroupattribution[7,42,54].Byunderstandingpreferencesinthisaxis,
weaimtoidentifywhetherindividualattributionlikeintraditionalTDAorrathertrainingdatagroupsneedtobein
focusofTDAresearch.
4.4 Surveystudy
Buildingonthefindingsoftheinterviewstudy,weaimtostudytheneedsofmodeldevelopersandunderstandwhat
kindofinformationisuseful,addressingRQ2–WhatdousersneedfromTDAexplanations?Wedesignanonline
surveythatexploresthedesignspaceofTDAexplanations(seeFigure3)usingscenario-baseddesign[12].Wepiloted
thesurveytoensureclearphrasingandcompatibilityacrossdevices.DatawascollectedfromJune–August2024.
4.4.1 Participants. Werecruitparticipantswithpriorexperienceindevelopingmachinelearningmodelstoclosely
alignwithpotentialrealusers.Torecruitexpertparticipants,weusedsnowballsamplingalongsidesocialmediaadson
XandLinkedIn,reachingouttocontactsandaskingthemtosharethestudylink.Weexpectthematicsaturationin
thequalitativeanalysisandmeaningfulstatisticsinthequantitativeanalysisataround30replies.Of34responses,we
excludedthreeforlow-qualityanswers(shortandnon-sensical),leaving31participants(ninefemale).18participants
workinindustrywhile14workinacademia,withmosthaving1-5yearsofmachinelearningexperience.Fourdonot
workwithdeepmodels.Participantscomefromdiversefields,includingbiology,health,logistics,andmore.Whilethe
datatypesusedbyparticipantsarediversetoo,themajorityofparticipantsworkwithimageortabulardata,asusedin
ourstudy(seeFigure4).Theparticipantswerecompensatedwith25€viaTremendous1.
4.4.2 Scenario-baseddesign. Themainpartofthestudyisconstructedwithscenario-baseddesign[12]tobasethe
analysisonatangibleusagescenario.Wecreatetwoscenariosofmodeldebugginginaninteractivemock-upofamodel
developmentsuite(seeFigure5).Thechoiceofdatatypes(imageandtabulardata)isbasedonthedominantmodalities
ofinterviewparticipants.Thestudyputsparticipantsintwoimaginaryscenarioswheretheyaremodeldevelopers
inacompanythatbuilds(1)abirdclassificationapp,and(2)acreditscoringapp.Thecompanyrecentlyacquireda
data-centrictooltohelpmodeldevelopersdebugtheirmodelsbyunderstandingerrorsandidentifyingtrainingdata
relevanttothoseerrors.Thetooliscustomisabletoadapttothedeveloper’spreferences.Thecustomisationchoices,
basedontheTDAdesignspace(seeFigure3)are:
1https://www.tremendous.com/
Preprint.Underreview.12 Nguyen,etal.
Fig.5. Screenshotoftheinterfaceusedinthebirdclassificationscenario.Thedarkpartsideshowsthemaininterfaceconsisting
oftheleftpanel(1)whichshowsinformationaboutthetesterrorandisstatic,andtherightpanel(2)whichshowsinformation
aboutthetrainingdataanalysisandisdynamic.Theinformationin(2)changesbasedonthechosensettingusingthecustomisation
controls(3)(expandablemenuwithlightbackground).
(1) Actiondefiningrelevance:(a)Removal,(b)Labelchange(tothenextmostlikelyclass),(c)Upweighting
(implementedwithafactorof10).Weomitnewdatacollectionbecauseitisdifficulttopredictwhatkindof
dataparticipantswouldliketoadd.Instead,wetakeupweightingasanapproximationofaddingnewdata.
(2) Metric:(a)Loss,(b)Groundtruthclassprobability,(c)Predictedclassprobability.
(3) Numberoftrainingsamples:Participantscanchoosebetweenthe1–10trainingsamplestoinspect.We
limitthenumberto10toexplorepreferencesformoretrainingsampleswhilekeepingcomputationeffortslow.
Inbothscenarios,participantsarepresentedwithaspecificmisclassificationasthemodelerror(leftsideofFigure5).
Thiserrorisrandomisedacrossparticipantstopreventbiasfromaspecificsample.Participantsareaskedtochoose
whichtypeoftrainingdata-relatedinformation(rightsideofFigure5)ismostusefultounderstandthereasonsforthe
error.Thisway,weaimtoelicitparticipants’intuitionsaboutthemostactionableinformationfordebuggingthemodel
error.Participantsareencouragedtoexploredifferentsettingsandsubmittheirdesiredcustomisationtocompletethe
task.Thedataforthesescenarioswasgeneratedusingrealmachinelearningmodelsandopenlyavailabledatasets.We
detailthedatagenerationprocessinAppendixC.
4.4.3 Surveystructure. ThesurveystructureisshowninFigure6.Participantsarefirstbriefedonthestudy’sobjective
anddataprocessing.Afterprovidingconsentandconfirmingtheymeetinclusioncriteria,theyareaskedpreliminary
demographicquestionsforcontexttothelateranalysis.Intheremainingstudy,weaimtoextracttheparticipant’s
preferences through a usage scenario (§ 4.4.2). The participants are presented with the scenario description and
promptedwith“Imagineyouareamodeldeveloperinacompany[...]”toimmersethemintheusecase.Then,weask
theparticipantsfollow-upquestionstounderstandthereasoningbehindtheirchoicesthroughfree-textquestions.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 13
Fig.6. Structureofthesurvey.
Thesefree-textquestionsareaboutunderstandingtheparticipants’intuitionsofwhythemodelmayhavemadean
error,andhowtheywouldfixit.Aftercompletingoneusecase,theparticipantsarepresentedwiththeotherusecase,
wheretheorderisrandomisedacrossuserstopreventanorderbias.
4.4.4 Dataanalysis. Weanalysethesurveystudybothquantitativelyandqualitatively.Forthequantitativeanalysis,
weaimtounderstandwhetheraspecificnotionofTDAispreferredacrossparticipantsbecausepreviousTDAstudies
havebeencentredaroundasinglenotionofTDA(§3).SincethetraditionalTDAsettingisalreadyapartofthedesign
space,studyingpreferencesgivesananswertowhetherparticipantsreallypreferredthisparticularscenario.Wefurther
assessifparticipantspreferaspecificscenario—-ifnot,itisastrongsignalthattheresearchshouldbediversifiedinto
multiplepossiblescenariosservingdifferentuserneeds.
To this end, we compute the distribution of the participants’ choices (action, metric and number of samples).
Furthermore,wetestwhetherthecollecteddataindicatesastatisticallysignificantpreferenceforaspecificsetting.We
performa𝜒2testasthedataiscategorical[58].Forthenumberoftrainingsamplesaxis,weperformFisher’sexacttest
asthechoicefrequenciesarelow[17].Specifically,ourhypothesesare:
𝐻 0:ThereisnoclearpreferenceforaspecificTDAsetting.
𝐻 1:ThereisaclearpreferenceforaspecificTDAsetting.
Inotherwords,wetestthegoodnessoffitofourobservationsagainstauniformdistributionacrosscategoriesofan
axis.Sinceweconductmultipletestsonthesamedata,weapplyaBonferronicorrection[79]anddefinestatistical
significanceat𝑝 <0.05.Additionally,wecomputeeachaxiscategory’sentropyH(X)andnormalisedentropyH(X)
norm
(normalisedbylog (𝑘)with𝑘asthenumberofcategoriesinanaxis,e.g.threeforthemetricaxis)togetanindicator
2
ofthediversityofpreferences[3].
∑︁
H(X)= 𝑝(𝑥)log𝑝(𝑥) (2)
𝑥∈X
Iftheentropyishigh,theparticipant’spreferencesarehighlydiverse,meaningthereisnoagreementonacertain
preferrednotionoftherelevanceoftrainingdata.
Thequalitativeanalysisaimstounderstandthereasonsbehindparticipantchoicesandgetdeeperinsightinto
userpreferences.Thefree-textresponsesinthefollow-upquestionsareanalysedusinginductivethematiccoding[9]
bytwocoders.Perquestion,weanalysethecommonthemesamongparticipantstoextractthereasonsbehinduser
preferencesandneeds.TheanalysisconsistsofseveralcodingworkshopsandisdepictedinFigure7.Wemeasure
interrateragreementbythepercentageofoverlappingthemes.Thefinalagreementis97.1%.
Preprint.Underreview.14 Nguyen,etal.
Fig.7. Iterativethematicanalysisprocessshowingtheevolvementofthemesandinterrateragreement.
4.5 Surveyfindings
WeconductthesurveystudytoanswerRQ2–WhatdousersneedfromTDAexplanations?Thesurveydata
analysisindicatesaclearconnectionbetweenusers’intuitionofwhatcausesamodelerrorandtheirTDApreferences.
Weelaboratefurtherinthefollowing.
4.5.1 Quantitativeresults. Thequantitativeanalysisbuildsonthecustomisationchoicesofthedebugginginterface
(seeQuantitativedatacollectioninFigure6).Table3showsthefrequencyofselectionsandtheassociatedp-values.
Wetestifthereexistsasettingofaction,metricandnumberoftrainingsampleswhichisconsistentlychosenand
particularlyusefultomodeldevelopers.Weareespeciallyinterestedinwhetherthereisaclearpreferenceforremoval,
lossandonetrainingsampleasthesecorrespondtothetraditionalnotionofTDAintroducedin§3.Fortheaction
axis,thereisnostatisticallysignificantpreferenceforanychoiceandthedistributionisratheruniformacrosschoices.
Whiletheresultsmayshowahigherfrequencyofparticipantschoosinglossasametric,weobservenostatistically
significantpreference.Hence,wefailtoreject𝐻 0fortheactionandmetricaxesandconcludethatthereisnodominant
preferenceforaparticularTDAsetting.Forthenumberofsamplesaxis,however,wefindastatisticallysignificant
preferenceforagroupof10samples.
Theentropyanalysissupportsthisconclusion(seeTable4).Asameasureofdiversity,normalisedentropyscores
rangefrom0.588to0.997,showingahighlydiverse(>0.5)distributionofchoices.ThisisespeciallytruefortheAction
definingrelevanceandMetricaxeswithhighscores(>0.8).Thereislessdiversityinthenumberoftrainingsamplesbut
aclearpreferenceforchoosinggroupsofsamples,confirmingIlyasetal.’s[33]intuitionsforstudyinggroupattribution.
In conclusion, the quantitative analysis reveals that the preferred TDA explanations represent highly diverse
informationwithaclearneedforgroupattribution.
4.5.2 Qualitativeresults. Theinductivethematiccodinganalysisofthefree-textanswersresultedinfourthematic
areasandthemetypescovering30themes(seeFigure8):(1)Actiondependsontheuser’shypothesis,(2)Individual
metricpreferences,(3)Groupattributionpreferences,and(4)Reliabilityofexplanations.Forthethemetypes,we
findthemesthatcorrespondtotheuser’shypothesisabouttheerrorandobservethattheseareoftencodedtogether
withacorrespondingproposedaction.However,preferredmetricsandpreferrednumberoftrainingsamplesdonot
correspondtotheuser’shypothesis.Additionally,weidentifyfourthemesthatdonotcorrespondtoanycategorybut
giveinterestinginsightsandcontexttotheanalysis.ThefulldescriptionofeachthemeisinAppendixD.
Actiondependsonuser’shypotheses. Thethematicanalysiscomplementsourquantitativefindings:Userpreferences
inmodeldebuggingarehighlyindividual.Theanalysisprovidesareason:Individualpreferencesareoftenlinkedtothe
user’sunderstandingandintuitions,inotherwords,theirhypothesisaboutanerror.Theuser’shypothesisdetermines
theircourseofaction.Hypothesesarehighlyindividualbecauseusersformulatethembasedontheirexpertiseandpast
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 15
Table3. Quantitativeanalysisofaxeschoicesacrossparticipantsinthefrequencyofchoice(%)fortheimageandtabularusecase,as
wellastogether.𝑝denotestheBonferroni-correctedp-valuecomputedfromthe𝜒2testforstatisticalsignificance.GT=Groundtruth.
NumberofSamples
ActionandMetric
Image Tabular Both
Image Tabular Both Choice % 𝑝 % 𝑝 % 𝑝
Choice % 𝑝 % 𝑝 % 𝑝
Num.ofsamples
Action
1 0.00% 1 0.00% 1 0.00% 1
Removal 33.33% 1 41.97% 1 37.70% 1 2 0.00% 1 0.00% 1 0.00% 1
LabelChange 30.00% 1 16.13% 1 22.95% 1 3 3.33% 1 9.68% 1 6.56% 1
Upweighting 36.67% 1 41.94% 1 39.34% 1 4 6.67% 1 3.23% 1 4.92% 1
5 13.33% 1 19.35% 1 16.39% 1
Metric
6 3.33% 1 3.23% 1 3.28% 1
Loss 60.00% 1 35.48% 1 47.54% 1 7 0.00% 1 3.23% 1 1.64% 1
Pred.cls.prob. 10.00% 1 41.94% 1 26.23% 1 8 3.33% 1 0.00% 1 1.64% 1
GTclassprob. 30.00% 1 22.58% 1 26.23% 1 9 3.33% 1 0.00% 1 1.64% 1
10 66.67% <0.001 61.29% 0.002 63.93% <0.001
Table4. Resultsoftheentropyanalysisperaxisasameasureofdiversity.
Image Tabular Both
Axis H Hnorm H Hnorm H Hnorm
Action 1.095 0.997 1.023 0.931 1.073 0.976
Metric 0.898 0.817 1.068 0.972 1.056 0.961
Num.samples 1.173 0.603 1.176 0.657 1.224 0.588
experiences.Forexample,weidentifiedthethemeoflowdatasetdiversityasahypothesisparticipantshaveabouta
modelerror:“[Images][...]inthetrainingsetarenotdiverseenough”,“[Oneclass]wasnotrepresentativeenough”.
Correspondingtothishypothesis,participantsoftensuggestedaddingnewdataorapplyingdataaugmentationsto
diversifythetrainingset,whichweidentifiedascollectspecificnewdataandsynthesise/augmentdatathemes.
Individualmetricpreferences. Forindividualmetricpreferences,weidentifyalinkwiththetaskathand.Inthecase
ofbinaryclassification,participantsshowedapreferenceforprobabilitymetrics,asitiseasiertounderstandthanthe
lossandallowsaninspectionofthedecisionboundary(“Thelossisnotveryintuitive”).Inmulti-classclassification,
moreparticipantspreferredthelossasitconsidersallpossibleclasses(“[Theloss]containsinformationonallclasses”).
However,asthequantitativeanalysisshows,thesedifferencesinpreferencearenotstatisticallysignificant.Therefore,
themetricpreferencesarelikelyindividualtotheuserandtheirhabits.
Groupattributionpreferences. Thequantitativestudyshowsaclearpreferenceforattributiontogroupsoftraining
samplesasopposedtoindividualtrainingsamples.Thequalitativeanalysisfindsthatthisisduetotheuser’sneedfor
havingagoodoverviewofthemodelerror.Inspectingagroupoftrainingsamplesprovidesabetteroverviewthana
singlesample,andallowstheusertounderstandwhethertheirhypothesisabouttheerrorisvalidornot(Groupfor
overviewoftheerror).Asecondthemehighlightsanotherangle:Whilevarietyinthegroupisdesiredforagood
overviewoftheerror(e.g.groupconsistingofsampleswithdiversefeatures),thegroupshouldbeconciseenoughto
“keeptheanalysismanageable”(Balancebetw.varietyandconciseness).
Preprint.Underreview.16 Nguyen,etal.
Fig.8. Themeoverviewfromthequalitativeanalysisofthesurvey.Thethemesgiveinsightintoparticipants’reasonsfortheirchoices
andneedsforreliabilityandacomprehensiveunderstandingoftheerror.Wefinddifferentthemetypes,indicatedbycoloursand
shapes:Hypothesesabouttherootcauseofmodelerroraremarkedwithacircle,preferredactionswithaplus,preferredmetrics
withastar,preferrednumberoftrainingsampleswithatriangle.FulldescriptionsofthethemesinAppendixD.
Reliabilityofexplanations. Ouranalysisfindsthatsomethemesarerelatedtotheoverallconceptofexplanation
reliability,whereparticularlythechoiceofhowmanytrainingsamplestoinspectisassociatedwithreliability.Partic-
ipantsstatedthatgroupsizesshouldbelargeenoughfortheattributionscorestobereliable.Atthesametime,
hegroupsizeshouldbesmallenoughtoensurereliableattributionscores,aschangingthedatasetcouldchangethe
model’sreasoning(Smallgrouptopreventreasoningchange).Weinterpretthisneedforreliabilitytoreflectin
themotivationtouncovercausaleffects(“Byremoving[...]Icandetermineif[thetrainingsamples]werecausing
confusionwithinthemodel”).
Unintendedthemes. Weidentifiedfourunintendedthemesoutsidethestudydesignthatprovideadditionalcontext.
Wenoticedthatparticipantsfocusedeitheronthemodelerror(Focusonmodelerror)orthefinalaccuracy(Focuson
finalaccuracy).Therefore,someoftheparticipantsexploredallchoiceoptionsinthesurveyandsubmittedthesetting
withthelargestperformancegain.Thisindicatesthattheendgoalofperformanceimprovementinthetaskishighly
valued.Someparticipantsmentionedthatthestudyinterfaceisunfamiliar(Unfamiliarstudyinterface),whichcan
beconfusing.Weconsideredthispointintheanalysisthroughdiscussionsatthecodingworkshops.However,italso
indicatesthatparticipantswereunfamiliarwithTDAexplanationsoverallastheyarenotusedinpracticeyet.Thelast
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 17
themehighlightstheimportanceofgroupingerroneoustestsamples.Participantsnotedthatasingleerroneoustest
samplemayrepresentabroaderissue,andunderstandingthelinkbetweentrainingdataandgroupsoftestsamples
withsimilarerrorscouldenhancedebugging.
5 DISCUSSION
ThisworkpresentsaneedfindingstudywithAIpractitionersfortrainingdataattribution(TDA)explanationstoinform
user-focusedTDAresearchinatop-downapproach.Wesummariseourfindingstoprovideanswerstotheinitial
researchquestions(§5.1),identifyresearchgapsthatneedtobeaddressedformoreuser-focusedTDA(§5.2)and
discusslimitations(§5.3).
5.1 Answerstotheresearchquestions
5.1.1 RQ1:WhatdousersneedTDAexplanationsfor? Toanswerthisquestion,weconductedtheinterviewstudy
(§4.1).OurfindingssuggestthatTDAasanexplanationmethodhasthepotentialtoservesimilarhigh-levelpurposes
asotherexplanationtechniques,namelyenablinguserstounderstandmodelbehaviour,especiallyunexpectedmodel
behaviour.Byofferinginsightsintomodelbehaviour,TDAcanassistend-usersincalibratingtrustbyprovidingcontext
formodeldecisionsandsupportmodeldevelopersindebuggingerrorsbyidentifyingrootcausesinthetrainingdata.
Thisdata-centricapproachisparticularlyvaluableinmodeldevelopment,leadingustoidentifymodeldevelopersas
theprimaryaudienceforTDAexplanationsandmodeldebuggingasthekeyusecase.
5.1.2 RQ2:WhatdousersneedfromTDAexplanations? Toanswerthisquestion,wedesignedasurveystudythat
extractsuserpreferencesfortheinformationrepresentedbyTDA(§4.4).Ourstudyrevealsthatusersneeddifferent
typesofinformationtounderstandmodelbehaviour,dependingontheirhypothesesofwhythemodelerrsduring
development.ThisnecessitatesTDAexplanationsthatareflexibleandadaptabletoindividualneeds.Theseneedsvary
basedontheapplicationdomainandtheuser’slevelofexpertise.Experiencedusers,mayformhypothesesaboutmodel
errorsbasedontheirpastexperiences.Incontrast,lessexperiencedusersmayformhypothesesbasedonwhatthey
learntpreviouslyaboutmachinelearningmodels.Usershaveapreferenceforgroupattribution,asgroupsprovide
moreinformationthanindividualsamples.Additionally,usersneedTDAexplanationstobereliableconsideringhow
data-centricactionsmightaffectthemodelasawhole.Reliabilityentailstwomainaspects:First,theinformationneeds
tobereliableforittobeactionableandeffectiveforthetask(i.e.,modeldebugging).Second,TDAexplanationsshould
alsoaccountforanybroaderchangesinthemodel’sbehaviourthatmayaffecttheattributiontotrainingsamples.
5.1.3 RQ3:TowhatextentdoexistingTDAapproachesalignwithuserneeds? Toanswerthisquestion,wereflecton
existingTDAapproachesinlightoftheidentifiedneeds:TDAexplanationsneedtobeadaptabletotheuserandprovide
reliableandactionableinsightwhilemaintainingconsistencywiththeoverallmodelbehaviour.Fromtheseneeds,we
identifydifferentTDAtasksthatusersneed,nexttotheoverarchingneedforreliability(seeTable5).
TraditionalTDAmeasurestheinfluenceofatrainingsampleonmodelpredictionsbyanalysingtheimpactofits
removalthroughleave-one-outretraining[30].Thismethodessentiallyevaluatesmodelpredictionsinthecontextofa
counterfactualchangeinthetrainingdata.Ithasbeenstudiedacrossdifferenttasks,suchasidentifyingmislabelleddata,
understandingadversarialvulnerabilities,anddetectingdomainmismatches[41].Mislabelidentification,inparticular,
isacommonevaluationstrategyemployedinseveralstudies[54,61,66].Consequently,traditionalTDApartially
addressestheneedforadaptabilitytodifferentusecases.However,sinceTDAquantifiestherelevanceofatraining
samplebyitsremoval,itisparticularlysuitedforscenarioswheredataeliminationisnecessary,suchasmalicious
Preprint.Underreview.18 Nguyen,etal.
Table5. OverviewofthetypesofTDAidentifiedinourstudyandhowoftentheywerementionedinthesurveystudy,definedby
theirspecificationintheTDAdesignspace,whereAttributingerrorswasmainlymentionedintheadditionalcomments.Citedworks
addressthistypeofTDA.
Attributiontype Action Metric |Ztrain| |Ztest| Timeschosen
Influenceattribution(e.g.,[24,27,41,54,61,66]) Removal Sampleloss 1 1 0
Groupinfluenceattribution(e.g.,[7,42,46,54]) Removal Sampleloss >1 1 11
Attributingerrors(e.g.[34]) Any Any >1 >1 4
Lackingdataattribution Addition Any >1 >1 26
Decisionboundaryattribution Labelchange Any >1 >1 14
samples.Itremainsanopenquestionwhetheralternativeactions,suchaschanginglabelsorupsamplingadataregion,
mightprovideimprovedexplanationsintermsofactionability.Ourstudyindicatesthatusersmayhavediverseideas
regardingtherootcausesoferrors,andtraditionalTDAonlyaddressesoneoftheseperspectives.
Regardingtheneedforreliable,actionable,andeffectiveinformation,existingTDAmethodshavebeencriticisedfor
theirlowreliabilityindeeplearning[5,6,52].Inaddition,ourstudyintroducesadifferentaspectofreliabilitythat
onlybecomesapparentwhenconsideringthefullcontextoftheusecase(asweassesseduserswithinthecontextofa
specifictask).Whenadatasetismodified,theoverallmodelbehaviourcanbeaffectedandmustbeconsidered.For
TDA,thismeansthatwhenmodifyingthedatasettoaddressingaparticularerror,usersrequireexplanationsthatnot
onlysuggestaneffectivemodificationbutalsoensurethemodel’sperformanceremainsratherconsistent.
Ouranalysisunderscorestheimportanceofincorporatinguserperspectivestoidentifyneedscriticaltothereal-
world application of this technology. Traditional TDA explanations only partially meet these needs, and further
interdisciplinaryeffortsarerequiredtodevelopmethodswithimprovedactionability.
5.2 Overlookedresearchtopicsforuser-focusedtrainingdataattribution
Thisworkaddstoacollectionofhuman-centredexplainableAI(HCXAI)workscallingtocentreXAIresearcharound
theuser(e.g.,[10,19,38,46,48,65]).ByfocusingonTDAexplanationsspecifically,weidentifyseveralresearchareas
thatarenecessarytostudytoadvanceTDAresearchtowardsafocusonusers.
• MentalmodelsandTDA:Ourstudysupportspreviouswork[38,65]thatthemostusefulexplanationsdepend
ontheuser’smentalmodelofwhythemodelerrs:Wefindthatwhatinformationisactionabletousersdepends
intheirhypothesisforreasonsofmodelbehaviour(Themearea:Actiondependsonuser’shypothesis).
Therefore,futureresearchshouldexplorehowTDAinfluencesandisinfluencedbymentalmodels,aswellas
howTDAcanbeadaptedtoreflectmentalmodels(e.g.bydefiningrelevancethroughtheactionofupweighting
asopposedtoremoval),potentiallyleadingtomorealignedandactionableexplanationsthatarewell-defined.
• User-centredgroupattribution:Thesurveyfindingsrevealaclearneedforattributingmodelbehaviour
togroupsoftrainingsamples,asitprovidesmoreinformativeinsights(Themearea:Groupattribution
preference).Whileexistingapproaches[7,42,54]addressthis,ourfindingshighlighttheneedforcreating
groupingsthatmakesensetousers(e.g.,basedongroundtruthorpredictedclass),anaspectnotyetwidely
exploredinTDAresearch.
• Holisticunderstandingofmodelerrors:Ourthematicanalysisofsurveyresponseshighlightstheimportance
ofunderstandingthemodelerroritselfbeforeattemptingtofixit(Theme:Groupingerroneoustestsamples).
Iftherootcauseisaspuriouscorrelation,theerrorlikelyextendsbeyondthecurrenttestsampleandmay
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 19
notfullyrepresenttheissue.Werecommendfutureresearchfocusonunderstandingerrortypesratherthan
isolatedinstances(e.g.,slicediscovery[77])andonattributingmodelbehaviourongroupsoftestsamplesto
trainingdata(e.g.,[34]).
• ReliabilityofTDA:TDAquantifiestheimpactoftrainingsamplesonmodelerrorsbypredictingchangesin
modelbehaviour,servingasanexplanationtotheuser.Fortheexplanationstobeinformative,theattribution
mustbereliable.Itisessentialtounderstandhowoverallmodelbehaviourwillbeaffectedasmentionedbyour
participants(Themearea:Reliabilityofexplanations).Werecommendfutureresearchtoextendexisting
workonthefragility,reliability,andstabilityofTDA[5,6,21,52]toaddresstheseneeds.
• TDAandfeatureattribution:CombiningfeatureattributionwithTDAcouldcreateTDAexplanationsfamiliar
tomodeldeveloperswhoalreadyusefeatureattributionmethodslikeSHAP[47].Whileourparticipants
indicatedtheyfrequentlyusefeatureattribution,thereisaknownriskofmisinterpretationandoverreliance[38,
39].Providingfeatureattributionexplanationswithcontext,suchasrelevanttrainingdataidentifiedthrough
TDA,couldhelpincheckingwhethersimilarfeaturesintrainingandtestdatamightmisleadthemodel.
5.3 Limitations
Thisstudyhasseverallimitations.First,theuseofpurposiveandsnowballsamplingtechniquesinparticipantrecruitment
mayhaveintroducedselectionbias.Consequently,thesamplemaynotbefullyrepresentativeofthebroaderpopulation
ofprofessionalsworkingwithmachinelearningormodeldevelopersingeneral.Second,therelativelysmallsample
sizeinourstudieslimitstherobustnessofthequantitativeanalyses,sotheresultsshouldbeinterpretedwithcaution
andleadustofocusmorestronglyonthequalitativeanalysis.Third,wesimulatedtheuseofTDAexplanationsina
modeldebugginginterfacewhicharelab-likeconditionsforthesurveystudy.Hence,theneedfindinganalysisisnot
rootedintherealworkflowsandisboundtoourstudyconditions,includingtheinterfacedesign.
6 CONCLUSION
Thispaperproposesatop-downapproachtoconductingexplainableAI(XAI)researchwhichisdrivenbyuserneedsas
opposedtotechno-centricsolutions.Weillustratethisapproachwiththeemergingsubfieldoftrainingdataattribution
(TDA)andpresentaneedfindingstudywithAIpractitioners.Thestudyconsistsoftwostages:First,weconduct
semi-structuredinterviewswithprofessionalswhoalreadyworkwithAIsystems(N=10)togainanimpressionof
commonusecasesandchallenges.WefindthatTDAcouldespeciallybenefitmodeldevelopers,astheirworkflowsare
stronglydata-centric.WederiveadesignspaceofTDAexplanatoryinformationthatrepresentswhatrelevantdatafor
modeldebuggingcouldlooklike.Second,wedevelopaninteractiveinterfacetoextractuserpreferencesinthedesign
spaceandintegrateitintoasurveystudy(N=31)targetedatmodeldevelopers.Themixed-methodsanalysisshowsthat
theexplanatoryinformationneededfromTDAformodeldebuggingishighlydependentnotonlyontheusecasebut
alsoontheuserandtheirintuitions.Finally,wehighlightseveralresearchdirectionsinuser-focusedTDAthatare
largelyoverlookedinthecurrentlandscape.
ACKNOWLEDGMENTS
Wefirstandforemostthankallstudyparticipantswhogaveustheirtimeandinput.WealsothankAlbertCatalán,
NikitaKister,andArnasUselisforparticipatinginthepilotstudyandhelpingusimprovethestudydesign.Wethank
DustinTheobaldforsharinghissurveywebsitecodebasewhichweusedasabasis.WethankKristinaKapanova
forhelpingushostthesurveysecurely,andeveryonewhohelpedspreadthesurveystudy.Theauthorsthankthe
Preprint.Underreview.20 Nguyen,etal.
InternationalMaxPlanckResearchSchoolforIntelligentSystems(IMPRS-IS)forsupportingElisaNguyen.Thiswork
wassupportedbytheTübingenAICenter.
REFERENCES
[1] JuliusAdebayo,JustinGilmer,MichaelMuelly,IanGoodfellow,MoritzHardt,andBeenKim.2018.Sanitychecksforsaliencymaps.Advancesin
neuralinformationprocessingsystems31(2018).
[2] EkinAkyürek,TolgaBolukbasi,FrederickLiu,BinbinXiong,IanTenney,JacobAndreas,andKelvinGuu.2022.TowardsTracingKnowledgein
LanguageModelsBacktotheTrainingData.FindingsoftheAssociationforComputationalLinguistics:EMNLP2022(2022),2429–2446.
[3] JamalAlsakran,XiaokeHuang,YeZhao,JingYang,andKarlFast.2014.Usingentropy-relatedmeasuresincategoricaldatavisualization.In2014
IEEEPacificVisualizationSymposium.IEEE,81–88.
[4] JuhanBae,WuLin,JonathanLorraine,andRogerGrosse.2024.TrainingDataAttributionviaApproximateUnrolledDifferentation.arXivpreprint
arXiv:2405.12186(2024).
[5] JuhanBae,NathanNg,AlstonLo,MarzyehGhassemi,andRogerBGrosse.2022. IfInfluenceFunctionsaretheAnswer,ThenWhatisthe
Question?.InAdvancesinNeuralInformationProcessingSystems,S.Koyejo,S.Mohamed,A.Agarwal,D.Belgrave,K.Cho,andA.Oh(Eds.),Vol.35.
CurranAssociates,Inc.,17953–17967. https://proceedings.neurips.cc/paper_files/paper/2022/file/7234e0c36fdbcb23e7bd56b68838999b-Paper-
Conference.pdf
[6] SamyadeepBasu,PhilPope,andSoheilFeizi.2021. InfluenceFunctionsinDeepLearningAreFragile.InInternationalConferenceonLearning
Representations. https://openreview.net/forum?id=xHKVVHGDOEk
[7] SamyadeepBasu,XuchenYou,andSoheilFeizi.2020. Onsecond-ordergroupinfluencefunctionsforblack-boxpredictions.InInternational
ConferenceonMachineLearning.PMLR,715–724.
[8] BlairBilodeau,NatashaJaques,PangWeiKoh,andBeenKim.2024.Impossibilitytheoremsforfeatureattribution.ProceedingsoftheNational
AcademyofSciences121,2(2024),e2304406120.
[9] VirginiaBraunandVictoriaClarke.2012.Thematicanalysis.AmericanPsychologicalAssociation.
[10] AndreaBrennen.2020.WhatDoPeopleReallyWantWhenTheySayTheyWant"ExplainableAI?"WeAsked60Stakeholders..InExtendedAbstracts
ofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHIEA’20).AssociationforComputingMachinery,New
York,NY,USA,1–7. https://doi.org/10.1145/3334480.3383047
[11] Marc-EtienneBrunet,ColleenAlkalay-Houlihan,AshtonAnderson,andRichardZemel.2019.Understandingtheoriginsofbiasinwordembeddings.
InInternationalconferenceonmachinelearning.PMLR,803–811.
[12] JohnM.Carroll(Ed.).1995.Scenario-baseddesign:envisioningworkandtechnologyinsystemdevelopment.JohnWiley&Sons,Inc.,USA.
[13] GuillaumeCharpiat,NicolasGirard,LorisFelardos,andYuliyaTarabalka.2019.InputSimilarityfromtheNeuralNetworkPerspective.InAdvances
inNeuralInformationProcessingSystems,H.Wallach,H.Larochelle,A.Beygelzimer,F.d'Alché-Buc,E.Fox,andR.Garnett(Eds.),Vol.32.Curran
Associates,Inc. https://proceedings.neurips.cc/paper_files/paper/2019/file/c61f571dbd2fb949d3fe5ae1608dd48b-Paper.pdf
[14] SangKeunChoe,HwijeenAhn,JuhanBae,KewenZhao,MinsooKang,YoungseogChung,AdithyaPratapa,WillieNeiswanger,EmmaStrubell,
TerukoMitamura,etal.2024.WhatisYourDataWorthtoGPT?LLM-ScaleDataValuationwithInfluenceFunctions.arXivpreprintarXiv:2405.13954
(2024).
[15] FinaleDoshi-VelezandBeenKim.2017.Towardsarigorousscienceofinterpretablemachinelearning.arXivpreprintarXiv:1702.08608(2017).
[16] RudreshDwivedi,DevamDave,HetNaik,SmitiSinghal,RanaOmer,PankeshPatel,BinQian,ZhenyuWen,TejalShah,GrahamMorgan,etal.2023.
ExplainableAI(XAI):Coreideas,techniques,andsolutions.Comput.Surveys55,9(2023),1–33.
[17] AnthonyWFEdwards.2005.RAFischer,statisticalmethodsforresearchworkers,(1925).InLandmarkwritingsinwesternmathematics1640-1940.
Elsevier,856–870.
[18] UpolEhsan,QVeraLiao,MichaelMuller,MarkORiedl,andJustinDWeisz.2021.Expandingexplainability:Towardssocialtransparencyinai
systems.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputingsystems.1–19.
[19] UpolEhsan,SamirPassi,Q.VeraLiao,LarryChan,I-HsiangLee,MichaelMuller,andMarkORiedl.2024.TheWhoinXAI:HowAIBackground
ShapesPerceptionsofAIExplanations.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).
AssociationforComputingMachinery,NewYork,NY,USA,Article316,32pages. https://doi.org/10.1145/3613904.3642474
[20] UpolEhsanandMarkO.Riedl.2020.Human-CenteredExplainableAI:TowardsaReflectiveSociotechnicalApproach.InHCIInternational2020-
LateBreakingPapers:MultimodalityandIntelligence,ConstantineStephanidis,MasaakiKurosu,HelmutDegen,andLaurenReinerman-Jones(Eds.).
SpringerInternationalPublishing,Cham,449–466.
[21] JacobEpifano,RavichandranRamachandran,AaronJ.Masino,andGhulamRasool.2023.RevisitingtheFragilityofInfluenceFunctions.Neural
networks:theofficialjournaloftheInternationalNeuralNetworkSociety162(2023),581–588.
[22] VitalyFeldmanandChiyuanZhang.2020.Whatneuralnetworksmemorizeandwhy:Discoveringthelongtailviainfluenceestimation.Advances
inNeuralInformationProcessingSystems33(2020),2881–2891.
[23] RaymondFokandDanielSWeld.2023.Insearchofverifiability:ExplanationsrarelyenablecomplementaryperformanceinAI-adviseddecision
making.AIMagazine(2023).
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 21
[24] RogerGrosse,JuhanBae,CemAnil,NelsonElhage,AlexTamkin,AmirhosseinTajdini,BenoitSteiner,DustinLi,EsinDurmus,EthanPerez,etal.
2023.Studyinglargelanguagemodelgeneralizationwithinfluencefunctions.arXivpreprintarXiv:2308.03296(2023).
[25] GregGuest,EmilyE.Namey,andMarilynL.Mitchell.2023.CollectingQualitativeData:AFieldManualforAppliedResearch.SAGEPublications,
Ltd,55CityRoad. https://doi.org/10.4135/9781506374680
[26] RiccardoGuidotti,AnnaMonreale,SalvatoreRuggieri,FrancoTurini,FoscaGiannotti,andDinoPedreschi.2018.ASurveyofMethodsforExplaining
BlackBoxModels.ACMComput.Surv.51,5,Article93(2018),42pages. https://doi.org/10.1145/3236009
[27] HanGuo,NazneenRajani,PeterHase,MohitBansal,andCaimingXiong.2021.FastIF:ScalableInfluenceFunctionsforEfficientModelInterpretation
andDebugging.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.AssociationforComputationalLinguistics,
OnlineandPuntaCana,DominicanRepublic,10333–10350. https://doi.org/10.18653/v1/2021.emnlp-main.808
[28] SophiaHadash,MartijnC.Willemsen,ChrisSnijders,andWijnandA.IJsselsteijn.2022.Improvingunderstandabilityoffeaturecontributionsin
model-agnosticexplainableAItools.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems(NewOrleans,LA,USA)
(CHI’22).AssociationforComputingMachinery,NewYork,NY,USA,Article487,9pages. https://doi.org/10.1145/3491102.3517650
[29] ZaydHammoudehandDanielLowd.2024.Trainingdatainfluenceanalysisandestimation:Asurvey.MachineLearning113,5(2024),2351–2403.
[30] FrankR.Hampel.1974.TheInfluenceCurveanditsRoleinRobustEstimation.J.Amer.Statist.Assoc.69,346(1974),383–393. https://doi.org/10.
1080/01621459.1974.10482962
[31] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.Deepresiduallearningforimagerecognition.InProceedingsoftheIEEEconference
oncomputervisionandpatternrecognition.770–778.
[32] HansHofmann.1994.Statlog(GermanCreditData).UCIMachineLearningRepository. DOI:https://doi.org/10.24432/C5NC77.
[33] AndrewIlyas,SungMinPark,LoganEngstrom,GuillaumeLeclerc,andAleksanderMadry.2022.Datamodels:PredictingPredictionsfromTraining
Data.InProceedingsofthe39thInternationalConferenceonMachineLearning.
[34] SaachiJain,KimiaHamidieh,KristianGeorgiev,AndrewIlyas,MarzyehGhassemi,andAleksanderMadry.2024.DataDebiasingwithDatamodels
(D3M):ImprovingSubgroupRobustnessviaDataSelection.arXivpreprintarXiv:2406.16846(2024).
[35] WeinaJin,JianyuFan,DianeGromala,PhilippePasquier,andGhassanHamarneh.2023.Invisibleusers:Uncoveringend-users’requirementsfor
explainableaiviaexplanationformsandgoals.arXivpreprintarXiv:2302.06609(2023).
[36] WeiJin,HaohanWang,DaochenZha,QiaoyuTan,YaoMa,SharonLi,andSu-InLee.2024.DCAI:Data-centricArtificialIntelligence.InCompanion
ProceedingsoftheACMWebConference2024(Singapore,Singapore)(WWW’24).AssociationforComputingMachinery,NewYork,NY,USA,
1482–1485. https://doi.org/10.1145/3589335.3641297
[37] PrernaJuneja,WenjuanZhang,AlisonMarieSmith-Renner,HemankLamba,JoelTetreault,andAlexJaimes.2024.Dissectingusers’needsfor
searchresultexplanations.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).Association
forComputingMachinery,NewYork,NY,USA,Article841,17pages. https://doi.org/10.1145/3613904.3642059
[38] HarmanpreetKaur,HarshaNori,SamuelJenkins,RichCaruana,HannaWallach,andJenniferWortmanVaughan.2020.InterpretingInterpretability:
UnderstandingDataScientists’UseofInterpretabilityToolsforMachineLearning.InProceedingsofthe2020CHIConferenceonHumanFactorsin
ComputingSystems(Honolulu,HI,USA)(CHI’20).AssociationforComputingMachinery,NewYork,NY,USA,1–14. https://doi.org/10.1145/
3313831.3376219
[39] SunnieSYKim,NicoleMeister,VikramVRamaswamy,RuthFong,andOlgaRussakovsky.2022.HIVE:Evaluatingthehumaninterpretabilityof
visualexplanations.InEuropeanConferenceonComputerVision.Springer,280–298.
[40] SunnieS.Y.Kim,ElizabethAnneWatkins,OlgaRussakovsky,RuthFong,andAndrésMonroy-Hernández.2023."HelpMeHelptheAI":Understanding
HowExplainabilityCanSupportHuman-AIInteraction.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems(Hamburg,
Germany)(CHI’23).AssociationforComputingMachinery,NewYork,NY,USA,Article250,17pages. https://doi.org/10.1145/3544548.3581001
[41] PangWeiKohandPercyLiang.2017. UnderstandingBlack-boxPredictionsviaInfluenceFunctions.InProceedingsofthe34thInternational
ConferenceonMachineLearning(ProceedingsofMachineLearningResearch,Vol.70),DoinaPrecupandYeeWhyeTeh(Eds.).PMLR,1885–1894.
https://proceedings.mlr.press/v70/koh17a.html
[42] PangWeiWKoh,Kai-SiangAng,HubertTeo,andPercySLiang.2019.Ontheaccuracyofinfluencefunctionsformeasuringgroupeffects.Advances
inneuralinformationprocessingsystems32(2019).
[43] YongchanKwon,EricWu,KevinWu,andJamesZou.2023.Datainf:Efficientlyestimatingdatainfluenceinlora-tunedllmsanddiffusionmodels.
arXivpreprintarXiv:2310.00902(2023).
[44] HimabinduLakkaraju,DylanSlack,YuxinChen,ChenhaoTan,andSameerSingh.2022.Rethinkingexplainabilityasadialogue:Apractitioner’s
perspective.arXivpreprintarXiv:2202.01875(2022).
[45] Q.VeraLiao,DanielGruen,andSarahMiller.2020. QuestioningtheAI:InformingDesignPracticesforExplainableAIUserExperiences.In
Proceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(Honolulu,HI,USA)(CHI’20).AssociationforComputingMachinery,
NewYork,NY,USA,1–15. https://doi.org/10.1145/3313831.3376590
[46] ChrisLin,MingyuLu,ChanwooKim,andSu-InLee.2024.EfficientShapleyValuesforAttributingGlobalPropertiesofDiffusionModelstoData
Group.arXivpreprintarXiv:2407.03153(2024).
[47] ScottMLundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodelpredictions.Advancesinneuralinformationprocessingsystems30
(2017).
Preprint.Underreview.22 Nguyen,etal.
[48] AlexMei,MichaelSaxon,ShiyuChang,ZacharyCLipton,andWilliamYangWang.2023. Usersarethenorthstarforaitransparency. arXiv
preprintarXiv:2303.05500(2023).
[49] TimMiller.2019.Explanationinartificialintelligence:Insightsfromthesocialsciences.Artificialintelligence267(2019),1–38.
[50] MeikeNauta,JanTrienes,ShreyasiPathak,ElisaNguyen,MichellePeters,YasminSchmitt,JörgSchlötterer,MauricevanKeulen,andChristin
Seifert.2023.FromAnecdotalEvidencetoQuantitativeEvaluationMethods:ASystematicReviewonEvaluatingExplainableAI.ACMComput.
Surv.55,13s,Article295(jul2023),42pages. https://doi.org/10.1145/3583558
[51] HumzaNaveed,AsadUllahKhan,ShiQiu,MuhammadSaqib,SaeedAnwar,MuhammadUsman,NaveedAkhtar,NickBarnes,andAjmalMian.
2023.Acomprehensiveoverviewoflargelanguagemodels.arXivpreprintarXiv:2307.06435(2023).
[52] ElisaNguyen,MinjoonSeo,andSeongJoonOh.2023.ABayesianApproachToAnalysingTrainingDataAttributioninDeepLearning.InProceedings
ofthe2023ConferenceonNeuralInformationProcessingSystems.
[53] OpenAI.2022.ChatGPT-3.5. https://chat.openai.com
[54] SungMinPark,KristianGeorgiev,AndrewIlyas,GuillaumeLeclerc,andAleksanderMadry.2023.TRAK:AttributingModelBehavioratScale.In
InternationalConferenceonMachineLearning(ICML).
[55] EuropeanParliament.2023.AIAct,AnnexIII.
[56] AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,GregoryChanan,TrevorKilleen,ZemingLin,NataliaGimelshein,Luca
Antiga,AlbanDesmaison,AndreasKopf,EdwardYang,ZacharyDeVito,MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,Lu
Fang,JunjieBai,andSoumithChintala.2019.PyTorch:AnImperativeStyle,High-PerformanceDeepLearningLibrary.InAdvancesinNeural
InformationProcessingSystems32.CurranAssociates,Inc.,8024–8035. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-
performance-deep-learning-library.pdf
[57] DevPatnaikandRobertBecker.1999.Needfinding:TheWhyandHowofUncoveringPeople’sNeeds.DesignManagementJournal(FormerSeries)10,
2(1999),37–43. https://doi.org/10.1111/j.1948-7169.1999.tb00250.xarXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1948-7169.1999.tb00250.x
[58] KarlPearson.1900.X.Onthecriterionthatagivensystemofdeviationsfromtheprobableinthecaseofacorrelatedsystemofvariablesissuch
thatitcanbereasonablysupposedtohavearisenfromrandomsampling.TheLondon,Edinburgh,andDublinPhilosophicalMagazineandJournalof
Science50,302(1900),157–175.
[59] F.Pedregosa,G.Varoquaux,A.Gramfort,V.Michel,B.Thirion,O.Grisel,M.Blondel,P.Prettenhofer,R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,
D.Cournapeau,M.Brucher,M.Perrot,andE.Duchesnay.2011.Scikit-learn:MachineLearninginPython.JournalofMachineLearningResearch12
(2011),2825–2830.
[60] PouyaPezeshkpour,SarthakJain,SameerSingh,andByronWallace.2022. CombiningFeatureandInstanceAttributiontoDetectArtifacts.
InFindingsoftheAssociationforComputationalLinguistics:ACL2022.AssociationforComputationalLinguistics,Dublin,Ireland,1934–1946.
https://doi.org/10.18653/v1/2022.findings-acl.153
[61] GarimaPruthi,FrederickLiu,SatyenKale,andMukundSundararajan.2020.EstimatingTrainingDataInfluencebyTracingGradientDescent.In
AdvancesinNeuralInformationProcessingSystems,H.Larochelle,M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin(Eds.),Vol.33.CurranAssociates,
Inc.,19920–19930. https://proceedings.neurips.cc/paper_files/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf
[62] AlecRadford,JongWookKim,TaoXu,GregBrockman,ChristineMcleavey,andIlyaSutskever.2023. RobustSpeechRecognitionviaLarge-
ScaleWeakSupervision.InProceedingsofthe40thInternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch,
Vol.202),AndreasKrause,EmmaBrunskill,KyunghyunCho,BarbaraEngelhardt,SivanSabato,andJonathanScarlett(Eds.).PMLR,28492–28518.
https://proceedings.mlr.press/v202/radford23a.html
[63] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016."Whyshoulditrustyou?"Explainingthepredictionsofanyclassifier.InProceedings
ofthe22ndACMSIGKDDinternationalconferenceonknowledgediscoveryanddatamining.1135–1144.
[64] YaoRong,TobiasLeemann,Thai-TrangNguyen,LisaFiedler,PeizhuQian,VaibhavUnhelkar,TinaSeidel,GjergjiKasneci,andEnkelejdaKasneci.
2023.TowardsHuman-CenteredExplainableAI:ASurveyofUserStudiesforModelExplanations.IEEETrans.PatternAnal.Mach.Intell.46,4(nov
2023),2104–2122. https://doi.org/10.1109/TPAMI.2023.3331846
[65] HeleenRutjes,MartijnWillemsen,andWijnandIJsselsteijn.2019.ConsiderationsonexplainableAIandusers’mentalmodels.InCHI2019Workshop:
Whereisthehuman?BridgingthegapbetweenAIandHCI.AssociationforComputingMachinery,Inc.
[66] AndreaSchioppa,PolinaZablotskaia,DavidVilar,andArtemSokolov.2022.ScalingUpInfluenceFunctions.ProceedingsoftheAAAIConferenceon
ArtificialIntelligence36,8(Jun.2022),8179–8186. https://doi.org/10.1609/aaai.v36i8.20791
[67] HuaShen,Chieh-YangHuang,TongshuangWu,andTing-HaoKennethHuang.2023.ConvXAI:DeliveringHeterogeneousAIExplanationsvia
ConversationstoSupportHuman-AIScientificWriting.InCompanionPublicationofthe2023ConferenceonComputerSupportedCooperativeWork
andSocialComputing(Minneapolis,MN,USA)(CSCW’23Companion).AssociationforComputingMachinery,NewYork,NY,USA,384–387.
https://doi.org/10.1145/3584931.3607492
[68] KarenSimonyan,AndreaVedaldi,andAndrewZisserman.2013.Deepinsideconvolutionalnetworks:Visualisingimageclassificationmodelsand
saliencymaps.arXivpreprintarXiv:1312.6034(2013).
[69] DanielSmilkov,NikhilThorat,BeenKim,FernandaViégas,andMartinWattenberg.2017.Smoothgrad:removingnoisebyaddingnoise.arXiv
preprintarXiv:1706.03825(2017).
[70] MukundSundararajan,AnkurTaly,andQiqiYan.2017.Axiomaticattributionfordeepnetworks.InInternationalconferenceonmachinelearning.
PMLR,3319–3328.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 23
[71] MohammadRezaTaesiri,GiangNguyen,andAnhNguyen.2022.Visualcorrespondence-basedexplanationsimproveAIrobustnessandhuman-AI
teamaccuracy.AdvancesinNeuralInformationProcessingSystems35(2022),34287–34301.
[72] StefanoTeso,AndreaBontempelli,FaustoGiunchiglia,andAndreaPasserini.2021.InteractiveLabelCleaningwithExample-basedExplanations.In
AdvancesinNeuralInformationProcessingSystems,A.Beygelzimer,Y.Dauphin,P.Liang,andJ.WortmanVaughan(Eds.). https://openreview.net/
forum?id=T6m9bNI7C__
[73] V.Turri,K.Morrison,K.Robinson,C.Abidi,J.Forlizzi,A.Perer,andR.Dzombak.2024.TransparencyintheWild:NavigatingTransparencyina
DeployedAISystemtoBroadenNeed-FindingApproaches.ACMConferenceonFairness,Accountability,andTransparency(ACMFAccT)(2024).
[74] JuliaP.A.vonThienen,WilliamJ.Clancey,andChristophMeinel.2019. TheoreticalFoundationsofDesignThinking. SpringerInternational
Publishing,Cham,13–38. https://doi.org/10.1007/978-3-319-97082-0_2
[75] C.Wah,S.Branson,P.Welinder,P.Perona,andS.Belongie.2011.TheCaltech-UCSDBirds-200-2011Dataset.TechnicalReportCNS-TR-2011-001.
CaliforniaInstituteofTechnology.
[76] DandingWang,QianYang,AshrafAbdul,andBrianYLim.2019.Designingtheory-drivenuser-centricexplainableAI.InProceedingsofthe2019
CHIconferenceonhumanfactorsincomputingsystems.1–15.
[77] FultonWang,JuliusAdebayo,SarahTan,DiegoGarcia-Olano,andNarineKokhlikyan.2024.Errordiscoverybyclusteringinfluenceembeddings.In
Proceedingsofthe37thInternationalConferenceonNeuralInformationProcessingSystems(NewOrleans,LA,USA)(NIPS’23).CurranAssociatesInc.,
RedHook,NY,USA,Article1809,13pages.
[78] Sheng-YuWang,AaronHertzmann,AlexeiAEfros,Jun-YanZhu,andRichardZhang.2024.DataAttributionforText-to-ImageModelsbyUnlearning
SynthesizedImages.arXivpreprintarXiv:2406.09408(2024).
[79] EricWWeisstein.2004.Bonferronicorrection.https://mathworld.wolfram.com/(2004).
[80] XiaosenZheng,TianyuPang,ChaoDu,JingJiang,andMinLin.2023.Intriguingpropertiesofdataattributionondiffusionmodels.arXivpreprint
arXiv:2311.00500(2023).
Preprint.Underreview.24 Nguyen,etal.
A INCLUSIONCRITERIA:HIGH-RISKAPPLICATIONAREAS
Werefertothedefinitionofhigh-riskapplicationareasaccordingtoAnnexIIIoftheEuropeanUnion’sAIAct[55].For
readability,weincludeanoverview:
• AIapplicationsinproductsthatrequireaspecificlevelofsafety:
– Toys,
– Aviation,
– Cars,
– Medicaldevices,
– Lifts.
• Biometricidentificationandcategorisationofnaturalpersons.
• Managementandoperationofcriticalinfrastructure.
• Educationandvocationaltraining.
• Employment,workermanagementandaccesstoself-employment.
• Accesstoandenjoymentofessentialprivateservicesandpublicservicesandbenefits.
• Lawenforcement.
• Migration,asylumandbordercontrolmanagement.
• Assistanceinlegalinterpretationandapplicationofthelaw.
B INTERVIEWSTUDYTHEMES
Thethematiccodinganalysisofthesurveystudy(N=10)yielded29themescorrespondingtosixthemeareasandfour
unexpectedthemes(§4.2).Inthefollowing,wefurtherelaborateonthesethemes.
B.1 Themearea:RoleofMLsystems
Thethemearea“RoleofMLsystems”groupsthreethemesthatrepresentwhatkindofroleMLsystemstakeinour
participant’swork:
• Workassistant:MLsystemsactasworkassistantsastheytakeworkloadofftheparticipant.Chatbotsgenerally
filltheroleofaworkassistantthat“[takesworkoffoftheparticipant’shandsandmakestheirworkeasier]"
(P10)andis“availablearoundtheclock"(P10).Participantsusechatbotsystemstoimprovetheirwritingin
English(P1,P11),tosearchforinformationwherepreviouslytheywould"[ask]Google"(P1),ortoideate
researchideas(P11).Moreover,P10truststheircompany-internalchatbotenoughtoredirectsimpleemployee
questionstothechatbot.
• Decision support: As decision support systems, ML systems deliver information that acts as a basis for
decisionstakenbyend-users,e.g.diagnosissupport(P6).ThisisthemainroletakenbytheMLsystemsthat
thedeveloperparticipantsworkon(“[We]makepredictionsaboutwhereweshoulddoour[pharmaceutical]
studiesandourdevelopment."(P8),“trytoaccommodatethepolicymakerssothatthey’reabletodecide[where
morehealthservicesareneeded]"(P9)).P3usesMLsystemstoidentifyandexplainthecontributingfactors
toproductissues:“Ifwecanpredictit,wecanalsohaveanideawhatarethefactorsmostlycreatingthis
phenomenon."
• Automation:Insomecases,MLsystemsaredeployedfortheautomationofsometasks,e.g.autonomous
driving(P2)orautomatedprocessingofcamerarecordings(P4).
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 25
B.2 Themearea:WorkflowwithMLsystems
Thethemearea“WorkflowwithMLsystems”groupsfourthemesthatemergedintheinterviewsrelatedtostandardor
often-occuringworkflows:
• Collaborationwithdomainexperts:Developersandsystemuserscollaboratecloselyforbuildingand
evaluatingMLmodels,wherebugsarereportedtothedevelopersbytheend-users(P2,P3,P6,P4,P9).This
collaborationisespeciallystrongiftheMLsystemisdevelopedin-house,andlessstrongiftheMLsystemisa
productthecompanypurchased.
• Standardmodelchoices:Developersrarelybuildtheirownmodelarchitecturesbutoptforstandardones
(“[If]it’salreadyanestablishedproblem,you’reprobablynotgoingtodobetterthananalgorithmthat’salready
beenlaidouttosolvethatproblemforyou."(P8)).
• Data-focuseddebuggingprocess:Thedevelopmentworkinpracticeiscentredarounddata.Developer
participantsmentionthatmostoften,dataartefactsarethereasonforbugsinthemodel(P2,P3,P4,P7,P8,P9).
• Dataqualitychecks:Dataqualitychecksareasetpartofthedatapreprocessingpipeline(P2,P3,P4,P8).
P2andP9reportedthattheyfirstassessdataqualitybeforeinspectingthemodelindebugging.Thisincludes
lookingforanypossibledataartefacts,especiallymissingdata.
B.3 Themearea:Roleoftrainingdata
Thethemearea“Roleoftrainingdata”groupsfivethemesstemmingfromparticipant’sresponseswhentalkingabout
theroleoftrainingdataintheinterviews:
• Mostimportantvariableinamodel:Modeldeveloperparticipantsconsistentlyviewtrainingdataasthe
mostimportantvariableinamodel,e.g.“[we][...]believethat[...]themodelscanonlybeasgoodasthe[...]
datathatyoufeedin."(P4).Hence,thedebuggingprocessisfocusedarounddata(Theme:Data-focused
debuggingprocess).
• Interestingbutnocapacity:Thisthemeappliestosystemuserparticipants,inparticularP6.Theymention
thattheywouldbecuriousabouttrainingdatatounderstandwhetherthemodellearnedfromhigh-quality
databut“[it]isaluxurythat[requirestime]",highlightingthepracticalconstraintoftimepressure.
• Notinteresting:Thisthemeappliestosystemuserparticipants.Theywereunawareofwhichtrainingdata
mayhavebeenusedtotrainthemodels(P1,P10)andmentionedthatthisdoesnotmattertoomuchfortheir
workastheycannotchangeitanyhow.
• Increasingtrainingdataasabugfix:Areoccuringthemeinourinterviewsisthattrainingdataisflexible–
thetrainingsetcanbeexpanded.Thisisoftendoneinpracticewhenencounteringabug,e.g.P2explainedthat
collectingmoredataisacommonwaytoovercomemodelshortcomingsinautonomousdriving.
• Trainingdataartefactsasmainbugcauses:Inlinewithpreviousthemeshighlightingtheimportanceof
trainingdatatothedevelopmentprocess,participantsexplicitlymentionthatmostoften,trainingdataartefacts
arethecauseofbadmodelperformance.Hence,dataartefactsarealsothefirstthingthatdeveloperslookour
forwhenencounteringabug.
B.4 Themearea:ChallengesinworkingwithMLsystems
Thethemearea“ChallengesinworkingwithMLsystems”groupssixthemesrelatedtothemainpainpointsthat
participantsmentioned
Preprint.Underreview.26 Nguyen,etal.
• Trustcalibration:OurfindingsagreewithKimetal.[40]:Itisunclearhowmuchandwhenasystemcanbe
trusted.P1sometimesfindsthemselvesinadilemmainwhichtheywishtolearnsomethingfromthechatbot,
butareunabletocalibratetheirtrustintheresponseduetomissingknowledge:“Idon’tknoweverything
regardingthistopic.I[don’teven]knowwhathe’sreplyingtome."(P1).
• ValidationandEvaluation:P2mentionsthatthevalidationitselfisachallengeduetomultiplerequirements
thattheMLsystemshouldfulfil.Inpractice,thepredictiveperformanceofamodelmatters,alongwithother
objectivessuchasinferencespeed,whetherthemodelisbias-free,andmore.Inaddition,Adata-centricaspect
ofevaluationbeingchallengingisthedifficultyofevaluationwhenlabelsareabsent.
• Dataqualityissues:DataqualityissuesareamajorchallengewhenworkingwithMLsystems.InTable2,we
detailthequalityissuesmentionedbythepariticipants.
• Resource constraints: For developer participants, memory and compute constraints are relevant in the
developmentandevaluationprocessoftheirmodels,especiallytoP2andP4astheyworkwithMLsystemson
theedge.
• StochasticnatureofMLmodels:ThestochasticnatureofMLmodelsposesaspecificchallengetodeep
modelsinthedevelopmentprocessanddebuggingtasks:“[The]samedataset,samemodel,youtrainmultiple
times,youcanget[different]results."(P2).Itisthereforedifficulttounderstandifabugwastrulyfixedorifit
isaconsequenceofrandomness.
• Misuseduetolackingknow-how:P10mentionsinadequateknow-howinMLsystemusageasachallenge:
“theemployeesoftendon’tmanagetoaskthechatbottherightquestions".
B.5 Themearea:Useof(featureattribution)XAIinpractice
Thethemearea“Useof(featureattribution)XAIinpractice”groupssixthemesrelatedtohowXAIisalreadybeing
usedbytheparticipants.
• XAIisnotused:SomesystemuserparticipantswereunawareofXAIsinceexplanationsarenotapartofthe
MLtoolstheyuse(P1,P10,P11).
• XAIislittleused:Thisthemeisrelatedtothesystemusers.P6reportsthatXAItoolstheyusedinradiology
imagessofar(i.e.heatmaps)donotdeliverafullanswertothewhyquestion,ascounterfactualinformationis
missing:“[If]Ijustgetanoverallhighlightinthesebasallungregionsandthepredictionthatisatelectasis,I
stilldon’tknowwhythisisatelectasisbutnotpleuraleffusionorconsolidation."Hence,theyonlyuseitwhen
theinformationisuseful.
• Modeldevelopment:Fordeveloperparticipants,XAIismostcommonlyusedasatoolformodeldevelopment
(P2,P3,P8).Assuch,XAItools(withinourparticipants,theseareexclusivelyfeatureattributionexplanations,i.e.,
SHAP[47]orvisualisationofattention)offerexplanationsforper-exampledebuggingofe.g.wrongpredictions
(“weworkwithhands-onexamplesthatwethen[...]relatetheinputfeaturesthattakeapoororagood
prediction[to]."-P8).
• Understand real-world phenomena: P3 described the use of XAI as a tool to understand phenomena
representedbytheMLmodel:“[Building]themodel,thewholepurposeistogetsomeexplainability.Because
[...]weknowthat[aproblemis]happeningandpredictingdoesn’treallyaddvalue.Butifwecanpredictit,we
canalsohaveanideawhatarethefactorsmostlycreatingthisphenomenon."
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 27
• Getcustomerbuy-in:P8statesthatXAItoolsareusefulingettingcustomerbuy-inandconvincingthe
customersofthemodel’sdecisionsuggestion:“Will[thecustomers]behappywith[highaccuracy]?Probably.
Willtheybeconvinced?Willtheybe100%confidentthatthat’sthewaytheywanttodoit?Probablynot.So
it’sallaboutthebuy-inthatyouget,andSHAPdefinitelyhelps."
• Sanitycheckformodelreasoning:OneparticularcaseofusingXAIformodeldevelopmentisasasanity
checkformodelreasoning(“Ifit’smorelikeanideationproject,thenIwouldsaythattheexplainabilityanalysis
[isdone]tosee[...]whatisguidingthepredictionaswellas[...]howaremypredictionsonthetestset
explained?And[...]doesitalignwiththeactualvaluethatIhave?"-P8).
B.6 Themearea:UserperspectivesonTDA
Thethemearea“UserperspectivesonTDA”groupsfourthemesthatemergedintheparticipant’sanswerswhen
discussingTDA.
• UsefulnessofXAIisuse-casedependent:SomeparticipantsfindXAIonlyusefulincertainuse-casesand
undercertainconditionssuchastimeavailability,intuitivenessoftheexplanation,andthepossibilityoftaking
actionbasedontheexplanation.Whenexplanationsareusedforcommunicationwithbusinessdepartments,
theydonotdeliverusefulinformationwhentheunderlyingmodelisnothigh-performingyet(P3,P8).
• XAIisuseful:WhileparticipantsvoicedcertainconditionsfortheusefulnessofXAI,theoverallmajority
agreedthatexplanationsareusefulintheirwork(P1,P2,P3,P9,P11).
• TDAcomplementarytofeatureattribution:ParticipantsareoverallpositivetowardsTDAexplanations.
TheymentionedthatTDAcouldbecomplementarytofeatureattributionexplanationsandprovidecontext,as
featureattributioninformationisratherlocal(e.g.,comparingfeatureattributionmapsbetweentrainingand
testsamplesthatarehighlyrelatedtoeachother).
• Differentnotionsofinterestingtrainingsamples:Withinourparticipants,wefindthatthereareseveral
differentnotionsofwhataninterestingtrainingsampletoamodeloutputcouldbeamongtheparticipants.We
detailthecodesinthisthemeinTable2ofthemainpaper.
C DATAGENERATIONFORTHESURVEYSTUDY
Thesecondprobeofourstudypresentsaninteractivemock-upofamodeldevelopmentsuitewhereparticipantscan
customisewhatkindofdata-centricinformationisshown.Thisdataispre-computedusingrealmodelsandopenly
availabledatasetsforanimageclassificationandatabulardataclassificationusecase.Inthefollowing,wedescribethe
datagenerationprocess.
C.1 Usecase:Birdclassificationapp
Thesettingoftheimageclassificationusecaseisaboutacompanythatbuildsabirdclassificationapp.Thisbird
classificationappsettinghasbeenusedinpreviousHCXAIstudies,e.g.Kimetal.[40].Togeneratethedataforthisuse
case,wefinetunethepretrainedResNet18[31]checkpointinPyTorch[56]withtheCUBdataset[75].
Datapreprocessing. TheCUBdataset[75]isamulti-classimageclassificationwith200classes,and5994imagesin
trainingand5794imagesinthetestset.Whilethedatasetincludesfine-grainedannotations,weonlyutilisethetarget
labelsinthedatagenerationprocess.WesubsampleCUBtoincludeonly10classesforourapplicationtoensurethat
participantscanlearnandidentifythedifferentbirdspecieswithoutpriorknowledge.Werefertotheselectedclasses
Preprint.Underreview.28 Nguyen,etal.
astheirspeciesfamily(e.g.Grasshoppersparrow→Sparrow)forbrevity.Thetrainingsetincludes300images,andthe
testset277images.
Modeltraining. WefinetuneaResNet18modelpretrainedonImageNet(availableonthetorchvisionhub)withthe
CUBtrainingsubsetfor10epochsusingtheAdamWoptimizer,alearningrateof0.001withweightdecayfactor0.005for
thecross-entropyobjective.Sincethetrainingprocessofdeepmodelsisstochasticwhichaffectsanyretraining-based
effects[52],werecordthelastthreemodelcheckpointsforamodelensemble.Thefinalmodelachievesatestaccuracy
of0.57whichissuitableforthemodeldebuggingusecasesinthiswork.
C.2 Usecase:Loanapprovementrecommendationapp
Thesettingofthescenarioofthetabulardatausecaseisthemodeldevelopmentdepartmentofabankthatimplements
amachinelearningmodeltogiverecommendationsforloanapprovalsoftheirclients.Tobuildthisscenario,wetraina
logisticregressionmodelontheGermancreditdataset[32]whichisopenlyavailableontheUCIdatasetrepositoryand
islicensedbyCCBY4.0.
Datapreprocessing. TheGermancreditdataset[32]isamultivariatedatasetwith20featuresand1000entries.Itis
usedforbinaryclassificationandincludeslabelsofloanapprovalanddeclines.Wesplititintoatrainandtestsetusing
an80-20train-testsplit.Aswewishtodisplaythewholedataintheinterfacemock-up,wesubselectthefollowing
featuresforreadability:
(1) Thestatusofexistingcheckingaccountfeaturedescribeshowmuchmoneyisintheapplicant’schecking
accountandisacategoricalvariable.Possiblevaluesare:(a)lessthan$0,(b)lessthan$200,(c)morethan$200,
and(d)nocheckingaccount.
(2) Thedurationdescribestheloan’sdurationinmonthsandisanumericalvariable.
(3) Thecredithistorydescribestheapplicant’shistorywithloansfromthisandotherbanksasacategorical
variable.Possiblevaluesare:(a)nocreditstaken,(b)allcreditsatthisbankpaidbackduly,(c)existingcredits
paidbackdulytillnow,(d)delayinpayingoffinthepast,and(e)criticalaccount.
(4) Thecreditamountdescribesthesizeoftheloanin$andisanumericalvariable.
(5) Theinstallmentrateinpercentageoftheapplicant’sdisposableincomedescribeshowlargetheinstallment
paymentsoftheloanare.Itisanumericalfeature.
(6) Theageisanumericalfeatureanddescribestheageoftheloanapplicant.
Modeltraining. Wetrainedalogisticregressionmodelwithstochasticgradientdescentusingthescikit-learnlibrary
inPython[59].Indetail,themodelwastrainedin50epochswithL2regularisationweightedby𝛼 =10𝑒−4andthe
defaultadaptivelearningrateofthelibrary.Recordingthreecheckpointsalongthetrainingtrajectoryat30,40and50
epochsresultsinthemodelensembleweuseforcomputingthedata.Thefinalmodelaccuracyis0.68,leavingroomfor
improvementanddebugging.
C.3 Modelerrorselection
Inthesurveyprobe,theparticipantisaskedtoanalyseamodelerror,i.e.acommonmisclassification.Weselectthe
errorstoshowbyfirstunderstandingwhichtypeofmisclassificationismostcommon,i.e.whichclassAisoften
classifiedasanotherclassB.Todeterminethetesterrors,weclassifythetestsetusingthemodelensemble,grouptest
samplesaccordingtotrueandpredictedlabelsandselecttheerrorsrepresentedbythelargestgroups.Weselectthree
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 29
errortypesforthemulti-classprobleminthebirdclassificationusecase.Inthebinarytabularclassificationusecase,
onlytwoerrorsarepossible.Intheseerrorgroups,werandomlychoosethreeerroneoussampleseach,resultinginnine
andsixerroneoustestsamplesforthebirdclassificationandloanapprovalrecommendationusecases,respectively.
Thetestsamplesarerandomisedacrossparticipantsbydrawingfromauniformdistributiontopreventbiasinthe
analysisstemmingfromaspecificerrorortestsample.
C.4 Relevanttrainingsampleselection
Inthemock-upinterfaceusedinthesurveyprobe,wedisplaytheeffectofdifferenttrainingdata-basedactionsonthe
modelerrorathandandtheglobalmodelbehaviour.Weprecomputedthesevaluesusingthemodelspresentedinthe
above.Weelaborateontheprocedureofprecomputationbelow.
Determiningthetrainingsamples. Theinterfaceshowstrainingsamplesmostrelevanttothetestsamplegroupbased
ondifferentactions,i.e.removal,labelchangeandupweighting,measuredindifferentmetricsandfordifferentgroup
sizes.Todeterminewhichtrainingsamplestoshow,wewouldhavetoprecomputeallpossiblecombinationsofaction,
metricandgroupsize.Asthisiscomputationallyprohibitiveandrigorouscorrectnessisnotrequiredforourresearch
questions,weselecttherelevanttrainingsamplegroupstotheerroneoustestsamplesbasedonindividualrelevance.In
otherwords,wefirstiterativelyremove/changethelabel/upweigheachtrainingsampleandretrainthemodels(details
below).Then,werecordthedifferencesinloss/trueclassprobability/predictedclassprobabilityforeacherroneoustest
sampleexampleandcomputemean,varianceandp-valuesasin[52].Afterfilteringthetrainingsamplesthatexhibita
statisticallysignificanteffect(𝑝 <0.05),wesortthetrainingsamplemeansfrommostpositivetomostnegativeeffect
whichdiffersacrossmetrics(e.g.anincreaseinlossisnegative,whileanincreaseintrueclassprobabilityispositive).
Thetop10trainingsamplesineachsettingaretherelevanttrainingsamplesweuseintheinterface.
Actionimplementation. Implementingandcomputingtheactionsrequireselaboration:
• Removal:Theimplementationofremovalisratherstraightforward–weexcludethetrainingsamplefromthe
datasetandretrainusingthesametrainingpipeline.
• Labelchange:Changingthelabelofatrainingsamplemakessensewhenanotherlabelmayfitthesample
better.Hence,weflipthelabelinthecaseofbinaryclassification.Inthecaseofmorethantwoclasses,we
considertwocases:(1)Thetrainingsamplewasmisclassified.Assumingthatthemodellearnsallclasseswell,a
misclassificationcouldoccurbecausethepredictedlabeldescribesthedatabetter.Therefore,inthesecases,the
newlabelisthepredictedlabel.(2)Thetrainingsamplewascorrectlyclassified.Wewouldonlywanttochange
thelabelifitwaswronglylabelled.Assumingthatthemodelgenerallylearnedtheclasseswell,wechangedthe
labeltothepredictedlabelwiththesecondhighestprobability.
• Upweighting:Weimplementupweightingwithaweightfactorof10.
Computingfinaleffects. Intheinterface,weprovidesimulatedeffectsofcertaindata-centricactionsonthemodel
errors(e.g.removingcertaintrainingdatapointsleadstoanincreaseinloss).Individualeffectsdonotnecessarilyadd
uptothegroupeffect[7,42].Hence,wecomputethefinaleffectsusingtheactualremoval/labelchange/upweighting
oftrainingdatagroups.Thiscomputationisfeasiblesincethegroupsandthenumberoftimeswehavetoretrainthe
modelsarelimited.Wecomputeandshowthestandarddeviationofremoving/changingthelabel/upweightingacross
themodelcheckpointsrecorded.
Preprint.Underreview.30 Nguyen,etal.
D SURVEYSTUDYTHEMES
Thethematiccodinganalysisofthesurveystudy(N=31)yielded34themescorrespondingtofourthemeareasandfour
unexpectedthemes(§4.5).Inthefollowing,wefurtherelaborateonthesethemes.
D.1 Themearea:Actiondependsonuser’shypothesis
Thethemearea“Actiondependsonuser’shypothesis”groups21themeslinkedtothereasonsforparticipant’schoices
intheactionaxis.Wefindthattheproposeddebuggingactionsofparticipantsarehighlydependentontheirhypotheses
ofthemodelerror’srootcause.
• [Hypothesis]Mislabeleddata:Themodelmakesanerrorbecauseofmislabeleddatainthetrainingsetthat
ishighlyrelatedtotheerroneoustestsample.
• [Hypothesis]Incompletetraining:Themodelmakesanerrorbecauseithasnotfinishedtraining,orwas
trainedusingnon-optimalhyperparametersandtrainingprocedures.
• [Hypothesis]Spuriouscorrelation:Themodelmakesanerrorduetoaspuriouscorrelationbeingpresentin
thetestimage,thatthemodellearntfromthetrainingdata.
• [Hypothesis]Similarclassfeatures:Themodelmakesanerrorbecausetheerroneoustestsampleissimilar
infeaturestoanotherclassinthedataset.
• [Hypothesis]Lowdatasetdiversity:Themodelmakesanerrorbecauseitwasnotabletogeneralisefrom
trainingonadatasetwithlowdiversityinthesamples(i.e.,samplesofaclassareallsimilar,notshowingthe
breadthoftheclass).
• [Hypothesis]Classoverlap:Themodelmakesanerrorbecausetheclassoftheerroneoustestsampleis
highlyoverlappingintermsofclass-relevantfeatureswithanotherclassanddistinctivefeaturesmaynotbe
presentinthedata.
• [Hypothesis]Datasetimbalance:Themodelmakesanerrorbecauseitwasnotabletogeneralisefroman
imbalanceddataset(i.e.,classimbalance).
• [Hypothesis]Smalldatasetsize:Themodelmakesanerrorbecauseitwasnotabletogeneralisefroma
smalldataset,insteaditoverfitit.
• [Action]Removenoisydata:Toovercometheerror,noisydatasuchasmislabeleddata,isremovedfromthe
datasetandthemodelisretrained.
• [Action]Changinglabeltocorrect:Toovercometheerror,incorrectlylabelledtrainingdataiscorrected
andthemodelisretrained.
• [Action]Fixlabellingpipelineforfuturedata:Toovercometheerror,thelabellingandannotationpipeline
isinspectedtofindarootcauseforlabellingerrors.
• [Action]Trainingprocessengineering:Toovercometheerror,hyperparametersandtrainingprocess
protocolsareadjustedandtunedbeforeretraining.
• [Action]Modelarchitectureengineering:Toovercometheerror,themodelarchitectureisadjusted(e.g.
additionofanotherlayer,choosingadifferentfoundationalmodel).
• [Action]Featureengineering:Toovercometheerror,thefeatureextractorsofthedatapreprocessingpipeline
areinspected.Thisthemewasmainlyfoundforthetabulardatausecase.
• [Action]Upweighttofocusonspecificfeatures:Toovercometheerror,certaintrainingdatasamples
shouldbeupweightedsothatthemodellearnsthefeaturespresentinthesesamplesbetter.
Preprint.Underreview.TowardsUser-FocusedResearchinTrainingDataAttributionforHuman-CenteredExplainableAI 31
• [Action]Featureattributioninspection:Toovercometheerror,themisleadingfeaturesmustbeunderstood
first.Featureattributioncouldbeausefultool.
• [Action]Manualinspection:Toovercometheerror,thetrainingdataismanuallyinspectedtofindanydata
artefacts.Participantsmentionedthattheyalreadydothisaspartoftheirmodeldevelopmentpipeline.
• [Action]Collectspecificnewdata:Toovercometheerror,newdatarelatedtotheerroneoustrainingsample
shouldbecollectedandaddedtothetrainingdataset.Thiscanimprovedatasetdiversityandhelpthemodel
generalisebetter.
• [Action]Synthesise/augmentdata:Toovercometheerror,newdatasamplesshouldbesynthesisedorexisting
datasamplesshouldbeaugmentedfurther,targetingthepartsoftrainingdatathatareunderrepresented.This
themewasmentionedoftenundertheassumptionthataddingcompletelynewdataisnotpossible.
• [Action]Resample/reweightdata:Toovercometheerror,theexistingtrainingdatasetshouldberesampled,
potentiallywithaspecificweightingtoovercomeclassimbalances.
• [Action]Collectanynewdata:Toovercometheerror,themodelneedstolearnfrommoredata.Hence,
expandingthedatasetoverallwilllikelyhelpthemodelperformance.
D.2 Themearea:Individualmetricpreferences
Thethemearea“Individualmetricpreferences”groupsfourthemesandprovidesinsightintowhycertainmetricsare
preferred.
• [Action/Metric]Labelchangeandprobabilityshowsdecisionboundary:Probabilitiesarethepreferred
metric,especiallyincombinationwiththelabelchangeaction,asitgivestheuseranintuitionaboutthedecision
boundarybetweenthepredictedandground-truthclass.
• [Metric]Probabilitiesareintuitiveandshowdecisionboundaries:Probabilitiesarethepreferredmetric
becausetheyareanintuitivemetricboundedbetween0-100.Also,theygivetheuseranintuitionaboutthe
decisionboundarybetweenthepredictedandground-truthclass.
• [Metric]Groundtruthprobabilityisthetarget:Theprobabilityofthegroundtruthclassofthetestsample
ispreferredbecausethisisthetargetmetrictooptimisewhendebuggingthiserroneoustestsample.
• [Metric]Lossismostinformativeinthemulti-classcase:Thelossispreferredbecauseitentailsinformation
acrossmanyclassesandisadirectindicatorofhowwellthemodelisperformingoverall.Thisisparticularly
interestinginmulti-classclassificationcases.
D.3 Themearea:Reliabilityofexplanations
Thethemearea“Reliabilityofexplanations”groupsthreethemesrelatedtotheoverarchingneedforreliabilityofthe
attributionscores.
• [Action]Removalshowscausaleffect:Theremovalactionispreferredbecauserepresentsthecausaleffect
oftheinclusionofaspecifictrainingsample.Thiscausaleffectisassumedtobemeaningfulandtherefore
reliable.
• [Numberofsamples]Groupsizeenoughforreliableattribution:Agroup(i.e.,morethanonetraining
sample)ispreferredfortrainingdataattributionbecauseconsideringtheeffectofagroupismorereliablethan
ofsingletrainingsamples.Thegroupsizeshouldbesufficientlylargefortheattributionscoretobemeaningful
andhence,reliable.
Preprint.Underreview.32 Nguyen,etal.
• [Numberofsamples]Smallgrouptopreventreasoningchange:Whileagroupoftrainingsamplesis
preferred,thesizeofthegroupshouldbesufficientlysmallsothattheunderlyingmodelstaysratherconsistent
giventheproposedaction(e.g.,iftheattributioncorrespondstotheeffectofremoving𝑁 samples,thiswill
changethedatadistributionwhichaffectsthemodel’slearning,too).Iftheunderlyingmodelweretochange
toomuch,theattributionscorescouldbearbitraryanditisnotcertainwhetherthemodelbehaviourwillstay
similar,makingthesample-wisedebuggingprocessdifficult.
D.4 Themearea:Groupattributionpreferences
Thethemearea“Groupattributionpreferences”groupstwothemesthatelaborateondesiredsizesoftrainingdata
groupsasexplanations.Incontrasttotheotheraxesofactionandmetric,thereisaclearpreferencetowardstraining
datagroupattribution,emphasisinganeedformethodsthatservethistask.
• [Numberofsamples]Groupforanoverviewoftheerror:Agroupoftrainingsamplesispreferredin
theexplanationofthemodelerrortogetabetteroverviewoftheerror,asitisexpectedthatthesamplesof
thegroupwiththehighestattributionarerelatedtothemodelerror.Onesampleistoolittlefortheuserto
understandtheerrorandproposeanactionforwardbasedontheexplanation.
• [Numberofsamples]Balancebetweenvarietyandconciseness:Whileagroupoftrainingsamplesis
preferred,thegroupsizeshouldbelargeenoughtoshowavarietyofdifferenttrainingsamplesrelatedtothe
modelerror,whilebeingsmallenoughtobeconciseandnotoverwhelmtheuser.
D.5 Unexpectedthemes
Inadditiontothepreviousthemeareas,wefoundthreeadditionalthemeswhichwereunexpected.Theyprovide
contexttotheoverallanalysis,showtwopredominantmindsetsofdevelopersandpointtotheresearchdirectionof
groupingerroneoustestsamples,whichhaslargelybeenoverlooked.
• Focusonthemodelerrorathand:Themainfocusoftheuserduringthedebuggingprocessliesinunder-
standingthemodelerrorathand,andidentifyingawaytofixtheerror.Thisisalocalfocus.
• Focusontheoverallmodelperformance:Themainfocusoftheuserduringthedebuggingprocessisto
optimisetheoverallmodelperformance,i.e.,havingtheoverallmodelaccuracyinmind.Thisisaglobalfocus.
• Groupingerroneoustestsamples:Inthedebuggingprocess,usersseektounderstandthereasonsbehindthe
modelerror.Asingletestsampleisunlikelytobetheonlyinstanceoferroneousmodelbehaviour,e.g.spurious
correlations.Thisthemedescribestheneedforpresentingtheuserwithmultipletestinstancesthatthemodel
errsonsimilarlysothattheuserwillhaveabetterunderstandingoftheerrorwhichwillenablethemtofixit.
• Studyinterfaceunfamiliar:Inthecomments,weoccasionallyfoundremarksthattheparticipantswere
unsureaboutwhethertheyhadcorrectlyfulfilledthetask,indicatingtheoverallinfamiliaritywithsample-wise
debuggingwithTDAexplanations.
Preprint.Underreview.