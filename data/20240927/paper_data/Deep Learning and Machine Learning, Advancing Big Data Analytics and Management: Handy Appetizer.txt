Deep Learning and Machine Learning: Advancing Big
Data Analytics and Management
Benji Peng1*, Xuanhe Pan2*, Yizhu Wen3*, Ziqian Bi4*, Keyu Chen5, Ming
Li5, Ming Liu6, Qian Niu7, Junyu Liu7, Jinlang Wang2, Sen Zhang8,
Jiawei Xu6, Pohsun Feng9†
1AppCubic,2UniversityofWisconsin-Madison,3DepartmentofElectricalandComputerEngineering,University
ofHawaiiatManoa,4IndianaUniversity,5GeorgiaInstituteofTechnology,6PurdueUniversity,7KyotoUniversity,
8RutgersUniversity,9NationalTaiwanNormalUniversity
*Equalcontribution
†Correspondingauthor,41075018h@ntnu.edu.tw
4202
peS
52
]LC.sc[
1v02171.9042:viXra2Contents
0.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
0.1.1 SimplifyingDeepLearning:FromComplextoSimple . . . . . . . . . . . . . . . . 7
0.1.2 ApplicationsofMachineLearningandDeepLearning . . . . . . . . . . . . . . . . 7
Transformer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
ChatGPTandGenerativePre-trainedModels(GPT) . . . . . . . . . . . . . . . . . 8
XGBoost(eXtremeGradientBoosting) . . . . . . . . . . . . . . . . . . . . . . . . 9
AlphaGoZero . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
ResNet(ResidualNetworks) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
BERT(BidirectionalEncoderRepresentationsfromTransformers) . . . . . . . . . 10
YOLO(YouOnlyLookOnce) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
AlphaFold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
GAN(GenerativeAdversarialNetworks) . . . . . . . . . . . . . . . . . . . . . . . 11
ReinforcementLearning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
0.1.3 Pre-trainedModels:EnhancingModelPerformanceandAccuracy. . . . . . . . . 12
TheConceptofPre-trainedModels . . . . . . . . . . . . . . . . . . . . . . . . . . 12
CommonPre-trainedModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
AdvantagesofPre-trainedModels . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
FutureDevelopmentsofPre-trainedModels . . . . . . . . . . . . . . . . . . . . . 13
HowtoUsePre-trainedModelsinApplications . . . . . . . . . . . . . . . . . . . 13
0.1.4 BigDataManagementandProcessingTechnologies . . . . . . . . . . . . . . . . 13
SQLandNoSQLDatabases. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
SQLDatabases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
NoSQLDatabases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
GraphDatabasesandRelationalDataAnalysis . . . . . . . . . . . . . . . . . . . 14
GraphDatabases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
ClusterComputingandDistributedSystems . . . . . . . . . . . . . . . . . . . . . 14
ApacheHadoop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
ApacheSpark . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
0.1.5 FutureCompetitiveness:EssentialSkillsinDeepLearningandDataManagement 14
0.1.6 GoalsofThisBook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
SimplifyingComplexTechnologiestoLowertheLearningCurve . . . . . . . . . . 15
ComprehensiveCoverageofApplicationsandClassicModels . . . . . . . . . . . 15
CoreDataManagementTechnologiesandTools . . . . . . . . . . . . . . . . . . 15
VisualizationandPractice-DrivenLearning . . . . . . . . . . . . . . . . . . . . . . 15
AComprehensiveandSystematicLearningPath . . . . . . . . . . . . . . . . . . 16
34 CONTENTS
I HandyAppetizer 17
1 GettingStartedwithPython 19
1.1 WhyPython? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.1.1 WhatisPythonUsedFor? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.2 WhatisanIDE?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.3 SettingUpPython . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.3.1 Step1:DownloadPython . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
1.3.2 Step2:InstallPython . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
1.4 Step3:UsingIDLE-YourFirstPythonIDE . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.5 YourFirstPythonProgram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
1.5.1 Step-by-StepInstructions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
1.6 QuickRecap . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2 UnderstandingPythonPackagesandpip 23
2.1 WhatarePythonPackages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.2 WhyDoWeNeedPackages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.3 HowtoUsePackagesinPython . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.4 Whatispip? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.5 WhyDoWeNeedpip? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.6 Example:InstallingseabornUsingpip . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.7 Useseaborntoplot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
2.7.1 Example:UsingseaborntoCreateaSimplePlot . . . . . . . . . . . . . . . . . . . 24
2.7.2 AnotherExample:VisualizingthetipsDataset . . . . . . . . . . . . . . . . . . . 26
2.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
3 MachineLearning101 29
3.1 WhatisMachineLearning? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.2 WhatCanMachineLearningDo? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.3 UnderstandingMachineLearning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
3.4 Introducingscikit-learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.4.1 Installingscikit-learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
3.5 TrainingaLinearRegressionModelontheDiabetesDataset . . . . . . . . . . . . . . . . 30
3.5.1 Step1:LoadtheDiabetesDatasetandTrainaLinearRegressionModel . . . . . 30
3.6 VisualizingtheResult . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
3.7 TrainingaLogisticRegressionModelontheBreastCancerDataset . . . . . . . . . . . . 32
3.7.1 LoadtheBreastCancerDatasetandTrainaLogisticRegressionModel . . . . . 32
3.8 UsingChatGPTtoGenerateMachineLearningCode . . . . . . . . . . . . . . . . . . . . . 34
3.8.1 HowtoPromptChatGPTforCode . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.8.2 ExampleResponsefromChatGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.9 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
4 DeepLearning101 37
4.1 WhatisDeepLearning? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
4.2 WhatCanDeepLearningDo? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
4.3 HowDoesDeepLearningWork? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
4.4 MainstreamDeepLearningFrameworks . . . . . . . . . . . . . . . . . . . . . . . . . . . 38CONTENTS 5
4.5 Introducingtensorflow(TensorFlow2) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
4.5.1 Installingtensorflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
4.6 TrainingaNeuralNetworkontheMNISTDataset . . . . . . . . . . . . . . . . . . . . . . 40
4.6.1 Step-by-Step:TrainingaNeuralNetworkwithTensorFlow2 . . . . . . . . . . . . 40
4.7 TrainingOutputandAccuracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
4.8 Introducingtorch(PyTorch) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
4.8.1 Installingtorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
4.9 TrainingaNeuralNetworkontheMNISTDataset . . . . . . . . . . . . . . . . . . . . . . 42
4.9.1 Step-by-Step:TrainingaNeuralNetworkwithPyTorch . . . . . . . . . . . . . . . 42
4.10 UnderstandingNeuralNetworks(Simplified) . . . . . . . . . . . . . . . . . . . . . . . . . 43
4.11 UsingChatGPTtoGenerateDeepLearningCode . . . . . . . . . . . . . . . . . . . . . . . 44
4.11.1 HowtoPromptChatGPTforCode . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
TensorFlow2Version . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
PyTorchVersion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
4.12 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
5 CoolAIApplicationsThatAreChangingtheGame 47
5.1 Cutting-EdgeComputerVision(CV)Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
5.1.1 SegmentAnythingModel(SAM) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
5.1.2 DigitalAvatars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
5.2 AIinNaturalLanguageProcessing(NLP) . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.2.1 ChatGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
5.2.2 Gemini:TheAIPersonalAssistant. . . . . . . . . . . . . . . . . . . . . . . . . . . 50
5.3 AIforCreativeIndustries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
5.3.1 Flux:AIforPhotography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
5.3.2 AICodingTools:TheFutureofSoftwareDevelopment . . . . . . . . . . . . . . . 51
5.4 AIinGeospatialIntelligence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
5.4.1 Geospy.ai:GeospatialAI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
5.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
6 AnIntroductiontoGenerativeart:ABeginner’sExploration 55
6.1 WhatareDiffusionmodels? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
6.2 StableDiffusion:AGame-ChangerinAIArtGeneration . . . . . . . . . . . . . . . . . . . 55
6.3 AIArt:TheFusionofCreativityandTechnology . . . . . . . . . . . . . . . . . . . . . . . 57
6.4 TwoMainInterfaces:WebUIvs.ComfyUI . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
6.4.1 WebUI:TheUser-FriendlyOption . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
6.4.2 ComfyUI:AdvancedWorkflowCustomization . . . . . . . . . . . . . . . . . . . . 58
6.5 ComparisonofWebUIandComfyUI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
6.6 GettingStartedwithWebUI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
6.6.1 Installation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
6.6.2 GenerateYourFirstImage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
6.7 GettingStartedwithComfyUI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
6.7.1 Installation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
TryComfyUIinGoogleColab . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
6.7.2 InstallComfyUIManager . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
6.7.3 SettingUpYourDefaultWorkflow . . . . . . . . . . . . . . . . . . . . . . . . . . . 656 CONTENTS
6.7.4 GenerateYourFirstImage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
6.7.5 TryOtherModels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
6.7.6 AdvancedFeatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
6.8 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
A ImageDemos 710.1. INTRODUCTION 7
0.1 Introduction
In the pastdecade, the rapid developmentof Artificial Intelligence (AI), MachineLearning (ML), and
DeepLearning(DL)technologieshasfundamentallytransformednumerousindustries,drivingglobal
innovationandproductivitytonewheights[23].Datahasbecomethecoreassetofmodernenterprises
andorganizations[65],andtheabilitytoextractvaluableinsightsandknowledgefromvastamounts
ofdatahasbecomeakeycompetitiveadvantage[2]. Withthewidespreaduseofbigdata,machine
learning,anddeeplearninghavebecomeessentialtechnologiesforautomatingprocesses,optimizing
decisions,andimprovingefficiency[49,46,7].
Althoughdeeplearningandmachinelearninghavetremendouspotential,manypeoplefindthese
technologiescomplexanddifficulttounderstand. Thisbookaimstosimplifythesecomplexmathe-
maticalformulations,provideintuitivevisualizations,andprovidecomprehensiveexplanationsofcore
conceptsofdeeplearningandmachinelearning,allowingreaderstoeasilygraspthesetechnologies
andunderstandtheirwide-rangingapplications[54].
0.1.1 SimplifyingDeepLearning: FromComplextoSimple
Deeplearning(DL)technologybasedonartificialneuralnetworkstypicallyinvolvescomplexmathe-
maticalcomputationssuchaslinearalgebra,calculus,andprobabilitytheory.Thesetechnicalfounda-
tionshavecontributedtothesuccessofdeeplearning,butalsopresentabarrierformanybeginners.
Oneofthecoregoalsofthisbookistosimplifythesecomplexconcepts. Wewillusesimplified
mathematical derivations, practical example codes, and graphical demonstrations to make the key
conceptsofdeeplearningeasiertounderstand. Usingvisualizationtechniques,readerswillbeable
tointuitivelygrasptheworkingsofforwardpropagationandbackpropagationinneuralnetworks,how
convolutionalneuralnetworks(CNNs)[38]operate,andhowmodelparametersareoptimizedusing
gradientdescent.
Inaddition, thisbookwillprovidepracticalprojectsandcasestudiestohelpreadersunderstand
howthesetechnologiescanbeappliedinreal-worldscenarios.Thisapproachwillnotonlyhelptech-
nicalprofessionalsmasterdeeplearningbutwillalsoprovidebusinessmanagerswithinsightsinto
howtoleveragethesetechnologiesintheeraofbigdata.
0.1.2 ApplicationsofMachineLearningandDeepLearning
Machine learning and deep learning have become the foundation of modern technology systems,
driving innovation and efficiency across industries. In the following, we will introduce several clas-
sicmodelsandtechnologiesthathaveplayedanirreplaceableroleinvariousfields. Themodelsand
technologiesthatweintroducearenotlimitedtothese,buttheserepresentsomeofthemostwidely
appliedandimpactfulmodelsintheindustry.
Transformer
The Transformer is a deep learning architecture [64] based on self-attention mechanisms (Figure 1
from[64]),originallydesignedforNaturalLanguageProcessing(NLP)butnowextendedtoimagepro-
cessingandspeechrecognition.UnliketraditionalsequencemodelssuchasRNNs[47]andLSTMs[28],
the Transformer can process input sequences in parallel, making it more efficient for handling long
textsorcomplexsequences. TheTransformerarchitecture[64]isbuiltonmodelslikeGPT[42]and8 CONTENTS
Figure1:TransformerModelArchitecture
BERT[14],usedwidelyinNLPapplicationssuchaslanguagetranslation,textgeneration,andquestion
answering[70].
ChatGPTandGenerativePre-trainedModels(GPT)
ChatGPTisbasedonOpenAI’sGenerativePre-trainedTransformer(GPT)[37],trainedonvastamounts
oftextdata,capableofgeneratingcoherent,naturalconversations.Ithasbeenwidelyappliedinchat-
bots,textgeneration,andvirtualassistants[50]. TheGPTseriesofmodelshasbecomeanessential
technology in natural language processing, pushing the boundaries of language models in content
generation,automatedcustomerservice,andwritingassistance.0.1. INTRODUCTION 9
Figure2:AlphaGoZero
XGBoost(eXtremeGradientBoosting)
XGBoost[10]isadecision-tree-basedensemblemachinelearningmodelthatisparticularlysuitedfor
handlingstructureddata.Itsefficiencyandaccuracyhavemadeitapopulartool,especiallyinKaggle
competitions. Awiderangeofindustries,includingfinance,healthcare,andmarketing,useXGBoost
toanalyzestructureddata,makingitindispensable[6,35].
AlphaGoZero
AlphaGoZero[53]isanAIsystembasedondeepreinforcementlearning, whichlearnscomplexGo
strategiesthroughself-play. UnlikeearlierAlphaGoversions,AlphaGoZero(Figure2from[53])con-
tinuously improves through self-competition, eventually surpassing humans. It has applications in
autonomousdriving,roboticcontrol,andmore,anditillustratestheimmensepotentialofdeeprein-
forcementlearningforcomplexdecision-makingandautomation.10 CONTENTS
Figure3:ResidualNetworksArchitecture
Figure4:BERTPre-trainingArchitecture
ResNet(ResidualNetworks)
ResNet[26]isaspecificconvolutionalneuralnetworkmodel, thataddressesthevanishinggradient
problemindeepnetworksthroughresidualconnections(Figure3),enablingmuchdeepernetworksto
betrained. Itiswidelyappliedinmedicalimageanalysis,autonomousdriving,andvisualprocessing
in autonomous vehicles. ResNet is capable of analyzing images, detecting objects, and classifying
them.
BERT(BidirectionalEncoderRepresentationsfromTransformers)
BERT, developed by Google [15], is a bidirectional encoder model that excels at understanding the
contextualsemanticsofwordsintext(Figure4from[15]). Intaskslikesentimentanalysis,question
answering,andtextclassification,BERThasbecomeabenchmarktechnology.UnlikeGPT’sunidirec-
tionalgenerativemodel,BERT’sbidirectionalencodingcapturesrichercontextualinformation,provid-
ingpowerfulsupportforvariousNLPtasks.
YOLO(YouOnlyLookOnce)
YOLO[43,60]isareal-timeobjectdetectionmodelthatcanlocateandclassifymultipleobjectsina
singleimage(Figure5from[43]). Duetoitsoutstandingspeedandaccuracy,YOLOiswidelyusedin
real-timedetectionapplicationssuchasautonomousdriving,securitysurveillance,smartcities,and
industrialmanufacturing.0.1. INTRODUCTION 11
Figure5:YOLOModels
Figure6:Q8W3K0:Apotentialplantdiseaseresistanceprotein.MeanpLDDT82.24.
AlphaFold
AlphaFold[30]isadeeplearningmodeldevelopedbyGoogleDeepMindthatpredictsthethree-dimensional
structureofproteins(Figure6from[3]). Thismodelsolvesamajorchallengeinbiology,significantly
acceleratingdrugdiscoveryanddiseaseresearch,andbringingrevolutionarychangestolifesciences
andbiotechnology.
GAN(GenerativeAdversarialNetworks)
GenerativeAdversarialNetworks(GANs)[21,12]consistsofageneratorandadiscriminator(Figure7
from [22]), where the generator creates data and the discriminator distinguishes between real and
fake data. GANs are widely used in image generation, style transfer, image restoration, and artistic
creation,andcangeneraterealisticimages,videos,andaudio,greatlyexpandingtheapplicationsof
deeplearningincontentcreation.
Figure7:GANMechanism12 CONTENTS
Figure8:ReinforcementLearning
ReinforcementLearning
Reinforcement [34, 25, 67, 63] learning is a machine learning method focused on learning optimal
behaviorsthroughinteractionswiththeenvironment(Figure8).Throughtrialanderror,reinforcement
learningoptimizesdecision-making.Ithasshowngreatpotentialinfieldssuchasautonomousdriving,
roboticcontrol,financialmarketoptimization,andresourcemanagement.
0.1.3 Pre-trainedModels: EnhancingModelPerformanceandAccuracy
TheConceptofPre-trainedModels
Pre-trainedmodels[9]aretrainedonlargedatasetsbeforebeingappliedtospecifictasks.Inthedevel-
opmentofdeeplearning,pre-trainedmodelshavesignificantlyreducedtrainingtimewhileimproving
performanceandaccuracyontaskswithlimiteddata.
CommonPre-trainedModels
• BERT (Bidirectional Encoder Representations from Transformers): Used in natural language
processing, BERT is a bidirectional model that considers the context of a sentence from both
directionstounderstandsemantics. Pre-trainedonmassivetextdatasets, BERTiswell-suited
forvariouslanguagetasks,suchasquestion-answeringsystemsandlanguagetranslation.
• GPT(GenerativePre-trainedTransformer):GPTmodelsaregenerativemodelsusedtoproduce
text and understand context, widely applied in conversation generation and content creation.
ChatGPTisonesuchapplicationofthistechnology.
• ResNet (Residual Networks): ResNet is a pre-trained model used for image recognition. By
introducingresidualstructures,itsolvesthedegradationproblemindeepneuralnetworks.After
being pre-trained on large-scale image datasets, ResNet can be fine-tuned for specific image
recognitiontasks.
AdvantagesofPre-trainedModels
• Improved Learning Efficiency: Pre-trained models have already learned general features from
large datasets, allowing them to achieve high performance on new tasks with minimal fine-
tuning.
• Reduced Computational Cost: Compared to training models from scratch, using pre-trained
modelssavessignificantcomputationalresourcesandtime.0.1. INTRODUCTION 13
Figure9:SQLandNoSQLDatabase
• WideRangeofApplications: Pre-trainedmodelsarewidelyappliedacrossvariousfields,from
naturallanguageprocessingandimagerecognitiontomedicalimageanalysisandautonomous
driving.
FutureDevelopmentsofPre-trainedModels
Withthecontinuousexpansionofdatasetsizesandimprovementsincomputationalpower,pre-trained
modelswillplayalargerroleinmorefields,andmoreefficientarchitecturesarelikelytoemerge,such
asmodelscapableofhandlingmulti-modaldata.
HowtoUsePre-trainedModelsinApplications
Inpractice,themainmethodsforusingpre-trainedmodelsinclude:
1. TransferLearning:Fine-tuningpre-trainedweightsforspecifictasks.
2. FeatureExtraction:Usingintermediatelayersofpre-trainedmodelstoextractfeaturesfromdata
andtrainingcustommodelswiththesefeatures.
0.1.4 BigDataManagementandProcessingTechnologies
Thesuccessofdeeplearningandmachinelearningisinseparablefromthesupportofvastamounts
ofdata. However,effectivelystoring,managing,andprocessingthisdatapresentsasignificantchal-
lenge. This book will introduce the key technologies of modern data management, helping readers
understand how these tools provide the necessary support for machine learning and deep learning
models.
SQLandNoSQLDatabases
SQL Databases Traditional relational databases (such as MySQL, PostgreSQL) are well-suited for
handlingstructureddata[17,52](seetheleftsideofFigure9),especiallyinscenariosthatrequiretrans-
actional consistency and strict data management. We will demonstrate how to use SQL databases
fordatastorageandqueriesandtheirapplicationsinindustrieslikefinanceandretail.14 CONTENTS
NoSQLDatabases Tocopewiththeexplosivegrowthofunstructureddata, NoSQLdatabases[24]
(suchasMongoDB,Cassandra)provideflexiblesolutionsforstoringandprocessinglarge-scaledata
(seetherightsideofFigure9). NoSQLdatabasesarewidelyappliedinscenarioslikeIoTandsocial
mediadataanalysis.
GraphDatabasesandRelationalDataAnalysis
GraphDatabases Graphdatabases[61](suchasNeo4j)efficientlystoreandquerycomplexrelation-
shipnetworksamongnodesandedges,makingthemespeciallysuitableforuseinsocialnetworks,
recommendationsystems,andfrauddetection. Wewilldemonstratehowgraphdatabaseshelppro-
cessandanalyzecomplexrelationaldata[19].
ClusterComputingandDistributedSystems
ApacheHadoop Hadoop[51]isadistributedstorageandcomputingframeworkthatefficientlypro-
cesses large-scale data through the MapReduce model, suitable for batch processing tasks. We
will explain how to use Hadoop to handle unstructured data and demonstrate its applications in e-
commerceandfinance.
ApacheSpark Spark[72]offersafasterin-memorycomputingframeworkthanHadoop,supporting
real-timedatastreamprocessingandcomplexdataanalysistasks.Thisbookwillshowhowtolever-
ageSpark’sadvantagesinreal-timedataanalysis,machinelearning,andlarge-scaledataprocessing.
0.1.5 FutureCompetitiveness: EssentialSkillsinDeepLearningandDataManage-
ment
With the widespread adoption of AI technologies, deep learning, and big data management are no
longer tools exclusively for data scientists but have become core skills required for professionals
acrossindustries.Whetheryouareasoftwaredeveloper,enterprisemanager,orresearcher,mastering
thesetechnologieswillnotonlyhelpyoufacefuturechallengesbutwillalsoaddirreplaceablevalue
toyourwork[33].
NumerousindustrieshavealreadybeendramaticallytransformedbytherapiddevelopmentofAI
technologies.Deeplearningandbigdatamanagementskillsarebecomingincreasinglyimportantfor
technical roles. Deep learning is necessary for developing AI-driven applications, automating busi-
ness processes, and optimizing system performance. Through big data and artificial intelligence,
enterprisemanagerscanoptimizedecision-makingprocessestoimproveefficiencyanddrivedigital
transformation[46,11].
However,theriskofnotmasteringtheseskillsisevident. Asautomationsystemsandintelligent
decision-makingsystemsbecomemoreprevalent,manytraditionalroleswillbereplaced.Onlythose
whocanfullyutilizedeeplearningandbigdatatechnologieswillremaincompetitiveintheevolving
jobmarket.
Through learning this book, readers will gain the key technical skills in these two critical fields
and develop the ability to apply them practically, positioning themselves favorably for future career
success.0.1. INTRODUCTION 15
0.1.6 GoalsofThisBook
The goal of this book is to simplify complex technologies, provide intuitive visualizations, and offer
real-world case studies to help readers fully grasp the core concepts of deep learning and machine
learning while gaining a deep understanding of the key technologies in big data management and
analysis.Whetherreadersarebeginners,technicalexperts,orbusinessmanagers,thisbookwilloffer
systematiccontenttobenefiteveryoneatvariouslevels.
SimplifyingComplexTechnologiestoLowertheLearningCurve
Deeplearningandmachinelearningtypicallyinvolvecomplexmathematicalderivationsandalgorith-
micimplementations,suchaslinearalgebra,calculus,andprobabilitytheory. Thisbookaimstosim-
plifythesecomplextopics,helpingreadersunderstandtheircoreprinciples.Byusingsimplifiedmath-
ematicalformulas,intuitiveexplanations,andaccessibleanalysis,readerswillbeabletoeasilygrasp
keyconceptswithoutbeingoverwhelmedbytechnicaldetails.
ComprehensiveCoverageofApplicationsandClassicModels
To help readers fully understand the practical applications of deep learning and machine learning,
thisbookwillcoverawiderangeofscenarios,fromnaturallanguageprocessing(NLP)tocomputer
vision, reinforcementlearning, and generativeadversarial networks (GANs) [21]. Wewill provide de-
tailedexplanationsofclassicmodelssuchasTransformer,ChatGPT[36],AlphaGoZero[53],BERT[15],
ResNet[26],andYOLO[43],andshowhowthesemodelsworkinpractice,coveringreal-worldappli-
cationsinindustriessuchasfinance,healthcare,autonomousdriving,andsecurity.
Thesemodelswillbepresentedinorderoftheirimpactontheindustry,helpingreadersprioritize
the most important technologies. Through rich case studies and real-world application examples,
readers will gain a clear understanding of how these technologies are transforming workflows and
decision-makingprocessesinvariousindustries.
CoreDataManagementTechnologiesandTools
The efficient operation of these models is dependent on modern data management technologies,
which go beyond deep learning and machine learning. This book will explain in detail how to use
SQLandNoSQLdatabasestostoreandmanagelarge-scaledata, howtohandlecomplexrelational
datawithgraphdatabases(suchasNeo4j),andhowtoprocessvastamountsofdatausingcluster
computingframeworks(suchasHadoop[51]andSpark[72]).
Through real-world case studies, we will demonstrate how to integrate these data management
technologieswithdeeplearningtobuildscalablesolutions,helpingreadersmastertheentireprocess
ofbigdataanalysis,fromdatacollection,storage,andcleaningtomodelingandprediction.
VisualizationandPractice-DrivenLearning
Byusingvisualizationtoolsthroughoutthebook,readerswillgainabetterunderstandingofhowneural
networklayersfunction,howCNNsprocessimages,andhowmodelparametersareoptimizedusing
gradientdescent. Thiscomplexalgorithmcanbeintuitivelyunderstoodbyusingdiagramsanddata
visualizations.16 CONTENTS
Inaddition,thisbookwillprovidepracticalprojectsandcodeexamplestodemonstratehowtheory
canbeappliedinpractice.Whetherit’strainingmachinelearningmodelsorbuildingbigdataplatforms,
readers will be guided step by step through the entire process, easily mastering the transition from
theorytoapplication. Eachkeyconceptwillbeaccompaniedbyconcreteexamples,helpingreaders
applywhattheyhavelearnedinreal-worldscenarios.
AComprehensiveandSystematicLearningPath
The content of this book spans from foundational theory to cutting-edge technologies, striving for
comprehensivecoverage.Readerswillfollowasystematiclearningpath,startingfromthebasictheo-
riesofmachinelearninganddeeplearning,andgraduallyprogressingtobigdatamanagement,model
optimization,andclustercomputing.Whetheryouareabeginneroranexperiencedprofessional,you
willfindcontenttailoredtoyourneedsandgraduallymastertheentiretechnologicalecosystem.
Thisbookprovidesreaderswithacomprehensiveunderstandingofthebigdatamanagementand
analysisecosystem,suchasdeeplearningandmachinelearning.Whetheryouarelookingtoenhance
yourcurrentskillsorprepareforfuturecareergrowth,thisbookwillprovideyouwithacompleteset
ofknowledgeandskillstohelpyoustaycompetitiveinanAI-drivenera.Part I
Handy Appetizer
17Chapter 1
Getting Started with Python
1.1 Why Python?
Pythonisoneoftheeasiestprogramminglanguagestolearn. It’sknownforitsclean,readablesyn-
tax—writingPythonisalmostlikewritingEnglish. Whetheryou’reinterestedindatascience,building
websites,orcreatingmachinelearningmodels,Python[18]istheperfectstartingpoint.
1.1.1 WhatisPythonUsedFor?
• DataScience:Analyzelargedatasetswithlibrarieslikepandasandnumpy.
• WebDevelopment:BuildwebapplicationsusingframeworkslikeFlaskandDjango.
• MachineLearning:Createpredictivemodelswithlibrariessuchasscikit-learnandTensorFlow.
• Automation:Automaterepetitivetaskslikerenamingfilesorscrapingdatafromwebsites.
1.2 What is an IDE?
AnIntegratedDevelopmentEnvironment(IDE)isatoolthathelpsyouwrite,run,andtestcode.Python
comeswithabuilt-inIDEcalledIDLE.It’ssimple,easytouse,andperfectforbeginners. Whilethere
areotherIDEsavailable,suchasVSCodeandPyCharm,wewillfocusonIDLEfornow.
Infuturechapters,we’llexploreotherIDEsandtoolsthatmightbemoresuitableforlargerprojects.
1.3 Setting Up Python
Let’sgetPythonupandrunningonyourcomputer.Theseinstructionsareforcompletebeginners,so
followalongstepbystep.
1.3.1 Step1: DownloadPython
1. OpenyourwebbrowserandgototheofficialPythonwebsite:python.org/downloads.
2. Dependingonyouroperatingsystem,choosetheappropriateversiontodownload:
1920 CHAPTER1. GETTINGSTARTEDWITHPYTHON
• ForWindows,clickthelargebuttonthatsaysDownloadPython3.x.x(e.g.,Python3.12.6)
asshownintheimagebelow.
• ForMacOS,followthislink:macOSversion.Choosethelateststablereleaseanddownload
theuniversalinstaller,asshowninthetwoimagesbelow.
3. MakesureyoudownloadtheversionmarkedasPython3.x(e.g.,Python3.11).
1.3.2 Step2: InstallPython
ForWindows:
1. Oncethedownloadiscomplete,runtheinstallerbydouble-clickingonit.
2. Beforeproceeding,checktheboxthatsaysAddPythontoPATH.Thisisimportant!
3. ClickInstallNowandwaitfortheinstallationtocomplete.You’llseeamessagethatsaysSetup
wassuccessful.
ForMacOS:
1. Openthedownloaded.pkgfile.
2. FollowthepromptsbyclickingContinueandAgree.
3. Once the installation is finished, open Terminal and type the following to verify Python is in-
stalled:
python3 --version
ForLinux:
1. Many Linux distributions come with Python pre-installed. You can check by opening Terminal
andtyping:
python3 --version
2. IfPythonisnotinstalled,usethefollowingcommand:
sudo apt-get install python31.4. STEP3:USINGIDLE-YOURFIRSTPYTHONIDE 21
1.4 Step 3: Using IDLE - Your First Python IDE
Python comes with its own built-in IDE called IDLE (Integrated Development and Learning Environ-
ment).Youdon’tneedtoinstallanythingextra!OncePythonisinstalled,youcanstartusingIDLEright
awaytowriteandrunPythoncode.
• WindowsandMac:AfterinstallingPython,searchforIDLEinyourstartmenu(orFinderonMac)
andopenit.TheimagebelowshowshowitlooksonaWindowsmachine:
• Linux:OpenTerminalandtypeidle3.
InIDLE,youcantypePythoncodeandrunitinstantly.It’saperfectwaytogetfamiliarwithPython,
especiallyifyou’veneverprogrammedbefore.
1.5 Your First Python Program
NowthatyouhavePythoninstalledandIDLEopen,let’swriteyourfirstPythonprogram! Thiswillbe
thesimplestprogramyoucanimagine,butit’sagreatwaytoseePythoninaction.22 CHAPTER1. GETTINGSTARTEDWITHPYTHON
1.5.1 Step-by-StepInstructions
1. OpenIDLE.
2. IntheIDLEwindow,typethefollowingcode:
1
print("Hello, World!")
3. PressEnter.
Youshouldseethefollowingoutput:
Hello, World!
That’sit! You’vejustwrittenandrunyourfirstPythonprogram. ThissimplecodetellsPythonto
printthetext"Hello, World!"onthescreen.
1.6 Quick Recap
• Pythonisabeginner-friendlylanguagethat’seasytolearnandpowerfultouse.
• YouinstalledPythonanduseditsbuilt-inIDE,IDLE,towriteandrunPythoncode.
• YousuccessfullywroteyourfirstPythonprogram!
In the next chapter, we’ll dive into real-world Python applications. You’ll see how Python can be
usedfordataanalysis,automation,andmore.Chapter 2
Understanding Python Packages and
pip
2.1 What are Python Packages?
Pythonpackagesarecollectionsofmodules(i.e.,pre-writtenPythoncode)thatprovidefunctionsand
tools for specific tasks. For example, if you need to work with data visualization, you can use the
matplotlib package. If you’re doing data analysis, pandas can be useful. Packages make coding
fasterandmoreefficientbyprovidingreusablecode.
2.2 Why Do We Need Packages?
Packages save time by providing pre-built tools, so you don’t have to write everything from scratch.
If you want to plot graphs, instead of writing your own plotting code, you can install a package like
matplotliborseabornanduseitsfunctions. Thisway,youfocusonsolvingtheproblemratherthan
buildingthetoolsfromscratch.
2.3 How to Use Packages in Python
TouseapackageinPython,youfirstneedtoinstallit.Pythonusesatoolcalledpiptodownloadand
installpackagesfromthePythonPackageIndex(PyPI).Onceinstalled,youcanimportthepackage
intoyourcode.
2.4 What is pip?
pipisapackagemanagerthatallowsyoutoinstallandmanagePythonpackages. It’sincludedwith
mostPythoninstallations,soyoudon’tneedtoinstallpipseparately[4].
2324 CHAPTER2. UNDERSTANDINGPYTHONPACKAGESANDPIP
2.5 Why Do We Need pip?
piphelpsmanagealltheexternallibrariesyouwanttouseinyourPythonprojects.Whetheryouneed
librariesfordataanalysis,machinelearning,orwebdevelopment,pipmakestheinstallationprocess
easy.
2.6 Example: Installing seaborn Using pip
Let’s say you want to use the seaborn package, which is a powerful library for creating statistical
graphics.You’llfirstneedtoinstallitusingpip.
pip install seaborn
Thefollowingscreenshotshowswhattheinstallationprocesslookslikeinacommandline:
As you can see, pip automatically downloads all the required dependencies, installs them, and
finisheswithasuccessmessage.
2.7 Use seaborn to plot
Seaborn [68] is a powerful and user-friendly Python library built on top of Matplotlib [29], designed
specifically for creating informative and attractive statistical graphics. It simplifies the process of
creatingcomplexvisualizationsbyprovidinghigh-levelinterfacesfordrawingvarioustypesofplots,
suchascategoricalplots, distributionplots, andregressionplots. Seabornalsointegrateswellwith
Pandas, allowingforeasyplottingofdatadirectlyfromDataFrames, makingitaconvenienttoolfor
dataexplorationandanalysis.Itsdefaultstylesandcolorpalettesalsoenhancetheaestheticsofthe
plotswithoutrequiringextensivecustomization.
2.7.1 Example: UsingseaborntoCreateaSimplePlot
Nowthatseabornisinstalled,let’suseittocreateasimpleplot.Here’showyoucanuseseaborninside
IDLEtogenerateaplot:
1 import numpy as np
2 import seaborn as sns
3 import matplotlib.pyplot as plt
4
# Create data for the heart shape
5
t = np.linspace(0, 2 * np.pi, 1000)
6
x = 16 * np.sin(t) ** 3
7
y = 13 * np.cos(t) - 5 * np.cos(2 * t) - 2 * np.cos(3 * t) - np.cos(4 * t)
82.7. USESEABORNTOPLOT 25
9
# Set the theme for the plot
10
11
sns.set(style="whitegrid")
12
# Create the plot
13
plt.figure(figsize=(6, 6))
14
plt.plot(x, y, color="red")
15
plt.title("Heart Shape")
16
plt.axis("equal")
17
plt.show()
18
TheimagebelowshowshowthislookswhenrunningthecodeinIDLE:
Thiscodeusesseaborntoloadasampledatasetofrestauranttipsandcreateascatterplotshow-
ingtherelationshipbetweenthetotalbillandthetipamount.
Afterrunningthiscode,youwillseethefollowingplot:26 CHAPTER2. UNDERSTANDINGPYTHONPACKAGESANDPIP
As you can see, the plot visually represents the relationship between the total bill and the tip
amount.seabornmakesitveryeasytocreatebeautifulvisualizationswithjustafewlinesofcode.
2.7.2 AnotherExample: VisualizingthetipsDataset
Thesecondexampledemonstrateshowtousetheseabornpackagetocreateasimplescatterplot
fromthepopular"tips"dataset[69],whichisincludedinseaborn. Thisdatasetcontainsinformation
aboutrestauranttips,suchastotalbill,tipamount,andvariousotherfactors.
Here’sthecodetovisualizetherelationshipbetweenthetotalbillandthetipamount:
1 import seaborn as sns
2 import matplotlib.pyplot as plt
3
# Load the 'tips' dataset
4
tips = sns.load_dataset("tips")
5
6
# Set the theme for the plot
7
8
sns.set(style="whitegrid")
9
# Create a scatter plot
10
sns.scatterplot(x="total_bill", y="tip", data=tips)
11
12
# Show the plot
13
plt.title("Scatter Plot: Total Bill vs Tip")
14
plt.xlabel("Total Bill")
15
plt.ylabel("Tip Amount")
16
plt.show()
172.8. SUMMARY 27
usermayseeoutputshownasabove.Nowwehaveseentheexampleofusingfunctionanddataset
inpackages,inthenextchapter,wewilldiveintomoreadvancedtopics,includingmachinelearning
andusingPythontobuildmodels.
2.8 Summary
• Pythonpackagesarecollectionsofcodethatallowyoutoperformvarioustasksefficiently.
• pipisthetoolusedtoinstallandmanagePythonpackages.
• Weinstalledtheseabornpackageusingpip,andusedittogenerateasimplescatterplot.28 CHAPTER2. UNDERSTANDINGPYTHONPACKAGESANDPIPChapter 3
Machine Learning 101
3.1 What is Machine Learning?
Machine Learning (ML) is a field of computer science that enables computers to learn from data
withoutbeingexplicitlyprogrammed.Thinkofitasteachingacomputertorecognizepatterns,make
decisions,orpredictoutcomesbasedonexamples(data)thatwegiveit.
Insteadofwritingrulesforthecomputertofollow,weprovideitwithdata,anditlearnstherules
byitself.
3.2 What Can Machine Learning Do?
MachineLearningiseverywherearoundus.HereareafewexamplesofwhatMLcando:
• PredictingOutcomes:MLcanpredictwhatmighthappennext.Forexample,predictingwhether
anemailisspamornot,orpredictingwhetheracustomerwillbuyaproduct.
• ImageRecognition:MLmodelscanrecognizefacesorobjectsinphotosandvideos.
• Personalization: OnlineserviceslikeNetflixorSpotifyuseMLtorecommendmoviesorsongs
basedonyourpreferences.
• Speech Recognition: Voice assistants like Siri or Alexa use ML to understand spoken com-
mands.
3.3 Understanding Machine Learning
ItiseasiesttounderstandMLbythinkingofitasteachingachild.Whenyouteachachildtorecognize
animals,youdon’texplaineveryanimal’srules.Instead,youshowthemmanypicturesofanimalsand
tell them what each one is. Eventually, they learn to recognize new animals by comparing them to
previousexamples.
ItworkssimilarlytoML.Byprovidingacomputerwithalotofdata(examples),weallowittofind
patternsonitsown.Assoonasitlearnsthosepatterns,itcanmakepredictionsbasedonnew,unseen
data.
2930 CHAPTER3. MACHINELEARNING101
3.4 Introducing scikit-learn
scikit-learn is one of the most popular and beginner-friendly packages for machine learning in
Python [40]. It provides easy-to-use tools for building machine learning models, like decision trees,
linearregression,andmore.
3.4.1 Installingscikit-learn
Toinstallscikit-learn,usepipaswedidinthepreviouschapter.Openyourterminalandrun:
pip install scikit-learn
Onceinstalled,youcanimportitanduseitinyourPythoncodetocreatemachinelearningmodels.
3.5 Training a Linear Regression Model on the Diabetes Dataset
Now,let’susescikit-learntotrainaLinearRegressionmodelontheDiabetesdataset[16].
WhatisLinearRegression?LinearRegressionisoneofthesimplestmachinelearningmodels.It’s
usedtopredictanumericalvalue(acontinuousvariable). Forexample,predictingaperson’sweight
basedontheirheight. Theideaistofindthebest-fittinglinethatrepresentstherelationshipbetween
inputfeatures(e.g.,height)andtheoutput(e.g.,weight).
Inthiscase,wewillpredictadiabetesprogressionvaluebasedoncertainmedicalfeatures.
3.5.1 Step1: LoadtheDiabetesDatasetandTrainaLinearRegressionModel
Here’sthePythoncodefortrainningaLinearRegressionmodelontheDiabetesdatasetusingscikit-learn.
Wecanloadthedatasetdirectlyfrom/textttscikit-learn.
# Import necessary libraries
1
2 import numpy as np
3 import matplotlib.pyplot as plt
4 from sklearn.datasets import load_diabetes
5 from sklearn.model_selection import train_test_split
6 from sklearn.linear_model import LinearRegression
7 from sklearn.metrics import mean_squared_error
8
# Step 1: Load the Diabetes dataset
9
diabetes = load_diabetes()
10
X = diabetes.data[:, np.newaxis, 2] # Use only one feature (BMI) for simplicity
11
y = diabetes.target # The target variable (progression of diabetes)
12
13
# Step 2: Split the data into training and testing sets
14
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
15
16
# Step 3: Create and train the Linear Regression model
17
lr = LinearRegression()
18
lr.fit(X_train, y_train)
19
20
# Step 4: Make predictions on the test set
213.6. VISUALIZINGTHERESULT 31
y_pred = lr.predict(X_test)
22
23
# Step 5: Calculate the Mean Squared Error (MSE)
24
mse = mean_squared_error(y_test, y_pred)
25
26
print(f"Mean Squared Error: {mse:.2f}")
27
# Step 6: Visualize the scatter plot and regression line
28
plt.figure(figsize=(8, 6))
29
30
# Scatter plot of the training data
31
plt.scatter(X_train, y_train, color="blue", label="Training data", alpha=0.6)
32
33
# Scatter plot of the test data
34
plt.scatter(X_test, y_test, color="green", label="Test data", alpha=0.6)
35
36
# Regression line (use entire dataset for better visualization)
37
plt.plot(X, lr.predict(X), color="red", linewidth=2, label="Regression line")
38
39
# Add labels and title
40
plt.title("Linear Regression on Diabetes Dataset (BMI vs Progression)")
41
plt.xlabel("BMI (Body Mass Index)")
42
plt.ylabel("Diabetes Progression")
43
plt.legend()
44
45
# Show the plot
46
plt.show()
47
ExplanationoftheCode:
• X = diabetes.data[:, np.newaxis, 2]: We’re selecting only one feature, BMI (Body Mass
Index),tomaketheregressionsimplerandeasiertovisualize.Thislimitsthemodeltopredicting
diabetesprogressionbasedonBMIalone.
• plt.scatter(): Creates scatter plots of the training data (in blue) and test data (in green) to
showtherelationshipbetweenBMIanddiabetesprogression.
• plt.plot(): Draws the regression line (in red) that represents the linear relationship between
BMIanddiabetesprogression.
• The plot includes clear labels, colors, and a legend to distinguish between training data, test
data,andtheregressionline.
3.6 Visualizing the Result
Thisplotvisuallyshowshowwellthelinearregressionmodelfitsthedata.Theblueandgreenpoints
representtheactualdata(BMIvsdiabetesprogression),andtheredlineisthelinearregressionline
predictedbythemodel.Thecloserthepointsaretotheredline,thebetterthemodel’spredictionsare.
• Bluepoints:Trainingdatausedtofitthemodel.32 CHAPTER3. MACHINELEARNING101
• Greenpoints:Testdata,whichthemodelhasn’tseenbefore.
• Red line: The linear regression line representing the predicted relationship between BMI and
diabetesprogression.
3.7 TrainingaLogisticRegressionModelontheBreastCancerDataset
Let’susescikit-learntotrainaLogisticRegressionmodelontheBreastCancerdataset.
WhatisLogisticRegression?LogisticRegressionisawidelyusedmachinelearningalgorithmfor
binaryclassificationtasks. Itmodelstheprobabilitythatagiveninputbelongstooneoftwoclasses
byfittingthedatatoalogisticfunction(alsoknownasthesigmoidfunction).UnlikeLinearRegression,
whichpredictscontinuousvalues,LogisticRegressionisusedtoclassifyinputsintocategories,such
as"yes"or"no"(binaryclassification).
Inthiscase,wewillusetheBreastCancerdatasetfromscikit-learntopredictwhetheratumoris
benignormalignantbasedonspecificmedicalfeatures.
3.7.1 LoadtheBreastCancerDatasetandTrainaLogisticRegressionModel
Here’sthePythoncodetotrainaLogisticRegressionmodelontheBreastCancerdataset,seeFigure
3.1forourfinalresult:
# Import necessary libraries
1
2 import numpy as np
3 import matplotlib.pyplot as plt
4 from sklearn.datasets import load_breast_cancer
5 from sklearn.model_selection import train_test_split3.7. TRAININGALOGISTICREGRESSIONMODELONTHEBREASTCANCERDATASET 33
6 from sklearn.linear_model import LogisticRegression
7 from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
8
# Step 1: Load the Breast Cancer dataset
9
cancer = load_breast_cancer()
10
X = cancer.data # Using all features for this model
11
y = cancer.target # Binary target (1: malignant, 0: benign)
12
13
# Step 2: Split the data into training and testing sets
14
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
15
16
# Step 3: Create and train the Logistic Regression model
17
lr = LogisticRegression(max_iter=10000)
18
lr.fit(X_train, y_train)
19
20
# Step 4: Make predictions on the test set
21
y_pred = lr.predict(X_test)
22
23
# Step 5: Calculate the accuracy of the model
24
accuracy = accuracy_score(y_test, y_pred)
25
26
# Step 6: Visualize the training and testing data with the decision boundary
27
28
x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
29
y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),
30
np.arange(y_min, y_max, 0.01))
31
32
plt.figure(figsize=(8, 6))
33
plt.contourf(xx, yy, Z, alpha=0.3, cmap=ListedColormap(('orange', 'blue')))
34
35
# Scatter plot for training data
36
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=50, edgecolor='k', marker='o',
37
cmap=ListedColormap(('red', 'green')), label='Training Data')
38
39
# Scatter plot for testing data
40
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, s=50, marker='s', edgecolor='k',
41
cmap=ListedColormap(('red', 'green')), label='Testing Data')
42
43
# Labels and title
44
plt.title('Logistic Regression Decision Boundary\nwith Training and Testing Data')
45
plt.xlabel(cancer.feature_names[0])
46
plt.ylabel(cancer.feature_names[1])
47
plt.legend()
48
plt.show()
49
ExplanationoftheCode:
• X = cancer.data: We are using all features available in the dataset to predict the outcome
(malignantorbenign).
• y = cancer.target: Thisrepresentsthebinaryclassificationlabels(1formalignanttumors,034 CHAPTER3. MACHINELEARNING101
Figure3.1: ThegraphdisplaysthedecisionboundaryofaLogisticRegressionmodeltrainedontwo
features from the Breast Cancer dataset. The circles represent the training data, while the squares
representthetestingdata. Colorsindicatetheclasslabels: redformalignanttumorsandgreenfor
benigntumors. Thedecisionboundaryseparatesthetwoclasses,withtheorangeandblueregions
indicating the predicted classification zones for malignant and benign cases, respectively. The plot
effectivelyvisualizeshowwellthemodeldifferentiatesbetweenthetwotumortypes.
forbenign).
• LogisticRegression(max_iter=10000): Creates a Logistic Regression model. The parameter
max_iter=10000ensuresthattheoptimizationconverges,asthedefaultvaluemaybeinsufficient
forsomedatasets.
• predict_proba(): Returns the probability estimates for the positive class (malignant tumors).
ThisisusefulforgeneratingtheROCcurve.
3.8 Using ChatGPT to Generate Machine Learning Code
ChatGPTisanAIlanguagemodeldevelopedbyOpenAI[36]. Youcanuseittoassistwithgenerating
code,understandingcomplextopics,andevendebuggingissues.Ifyou’reunsurehowtowritecertain
Python code, like training a Linear Regression model, ChatGPT can help by generating the code for
you.
TouseChatGPT,gotochat.openai.com, login(orsignupifyou’reanewuser), andthenstarta
conversationbytypingyourrequestinplainlanguage.3.9. SUMMARY 35
3.8.1 HowtoPromptChatGPTforCode
WhenyouinteractwithChatGPT,themorespecificyouareinyourprompt,themoreaccurateandhelp-
fultheresponsewillbe.TogenerateaLinearRegressiontrainingcode,youcanprovidethefollowing
instructions:
ExamplePrompt:
Can you generate Python code using scikit-learn to train a Linear Regression model on
the Diabetes dataset? Please include code to split the data into training and testing sets,
train the model, make predictions, and calculate the Mean Squared Error. Add in-line comments
to explain each step.
3.8.2 ExampleResponsefromChatGPT
Here’sanexampleofthecodeChatGPTmightgenerateforthisprompt:
# Import necessary libraries
1
2 from sklearn.datasets import load_diabetes
3 from sklearn.model_selection import train_test_split
4 from sklearn.linear_model import LinearRegression
5 from sklearn.metrics import mean_squared_error
6
# Load the Diabetes dataset
7
diabetes = load_diabetes()
8
X = diabetes.data # Features
9
y = diabetes.target # Labels
10
11
# Split the data into training and testing sets
12
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
13
14
# Create the Linear Regression model
15
lr = LinearRegression()
16
17
# Train the model
18
lr.fit(X_train, y_train)
19
20
# Make predictions on the test set
21
y_pred = lr.predict(X_test)
22
23
# Calculate and print the Mean Squared Error
24
mse = mean_squared_error(y_test, y_pred)
25
26
print(f"Mean Squared Error: {mse:.2f}")
3.9 Summary
• MachineLearningenablescomputerstolearnfromdataandmakepredictions.
• scikit-learnisapopularPythonpackageforbuildingMLmodels.36 CHAPTER3. MACHINELEARNING101
• Weusedscikit-learntotrainaLinearRegression[48]modelontheDiabetesdatasetandeval-
uateditusingMeanSquaredError.
• LinearRegressionisasimplemodelforpredictingcontinuousvaluesbasedoninputfeatures.
• ChatGPTcanbeavaluabletoolforgeneratingcodeandunderstandingmachinelearningcon-
cepts.Chapter 4
Deep Learning 101
4.1 What is Deep Learning?
Deep Learning (DL) is a type of Machine Learning that focuses on models called neural networks.
Thesemodelsareinspiredbyhowthehumanbrainworksandareverypowerfulatrecognizingpatterns
inlargeamountsofdata.
InDeepLearning,neuralnetworkshaveseverallayers(whichiswhyit’scalled"deep"). Eachlayer
learnstorepresentdatainamorecomplexway.Forexample,ifyougiveitimages,earlylayersmayrec-
ognizesimpleshapeslikeedges,whiledeeperlayersrecognizewholeobjectslikenumbersorfaces.
4.2 What Can Deep Learning Do?
DeepLearningcansolveverycomplextasksthattraditionalalgorithmsstrugglewith.Someexamples
include:
• ImageRecognition:Recognizingobjectsinpictures,likeidentifyinghandwrittendigitsorfaces.
• LanguageUnderstanding:Translatinglanguages,understandingcommands,orgeneratingtext
(e.g.,ChatGPTandGemini).
• SpeechRecognition:Turningspokenwordsintotextorunderstandingvoicecommands,likein
SiriorAlexa.
• GamePlaying: DeepLearningmodelscanlearntoplayandmastercomplexgameslikeChess
orGo.
4.3 How Does Deep Learning Work?
ThekeyideainDeepLearningistheneuralnetwork. Aneuralnetworkismadeupoflayersofcon-
nectednodes,calledneurons.Eachconnectionbetweenneuronshasaweight,whichchangesasthe
networklearnsfromdata.
3738 CHAPTER4. DEEPLEARNING101
Insimpleterms:
• InputLayer:Receivestherawdata(e.g.,imagesortext).
• HiddenLayers:Theselayersprocessthedata,learningpatternsfromit.
• OutputLayer:Producesthefinalprediction,likeclassifyinganimageasadigit.
Themorelayersanetworkhas,themorecomplexpatternsitcanlearn. However,deepnetworks
alsoneedlotsofdataandcomputingpowertoworkwell.
4.4 Mainstream Deep Learning Frameworks
Deeplearninginvolvesmanycomplexmathematicalalgorithms,whichmakesitdifficulttobuildmod-
elsfromscratch. Fortunately,therearenowseveralmainstreamframeworksthatallowustobypass
themathematicaldetailsandwritesimplecodetoimplementdeeplearningmodels.Twoofthemost
popularframeworksareTensorFlow2[1]andPyTorch[39].
Belowisatablecomparingtheprosandconsofeachframework:4.5. INTRODUCINGTENSORFLOW(TENSORFLOW2) 39
TensorFlow2 PyTorch
Pros
• Simplified API, making it more beginner- • Easiertounderstandanduse,especiallyfor
friendlycomparedtopreviousversions. researchersandthosewhowantflexibility.
• Strongsupportfordeploymentandproduc- • Dynamiccomputationgraphallowsforreal-
tionenvironments. time tracking of the model’s workflow and
• Well-documented with a large and active results.
community. • Increasingly popular in both academia and
• DevelopedbyGoogle,itupdatesquickly. industry.
• Itwasonceverypopularandwidelyused. • It is the most used architecture currently
andisstillgrowing.Verypromising.
Cons
• Despite improvements, still has a steeper • Historicallylessmatureforlarge-scalepro-
learningcurvecomparedtoPyTorch. duction and deployment compared to Ten-
• Debuggingcansometimesbelessintuitive sorFlow.
duetoitsstaticcomputationgraph. • Slightly smaller ecosystem for deployment
• Updatesaretoofastandalwaysusediffer- tools.
ent APIs, which can cause serious incom- • The code encapsulation level is low, Not
patibility issues even if they are all Tensor- verybeginnerfriendly.
Flow2.x.
• There is a lot of TensorFlow 1.x code on
themarket,buttheincompatibilitybetween
TensorFlow 1.x and TensorFlow 2.x makes
itdifficulttomigratethecode.
• The number of people using this architec-
tureisdecreasing.
*ItisstronglyrecommendedthatbeginnersfocustheirlearningonPyTorch
Table4.1:ComparisonofTensorFlow2andPyTorch
TensorFlow 2 and PyTorch APIs are quite similar, but switching between frameworks is still not
atrivialtask. However, withtheadventofAItoolslikeChatGPT,switchingframeworkshasbecome
mucheasier.ToprovidereaderswithaclearcomparisonbetweenTensorFlow2andPyTorch,wewill
presentanexampleimplementedinbothframeworksbelow, allowingyoutochoosetheframework
thatbestsuitsyourneeds.
4.5 Introducing tensorflow (TensorFlow 2)
tensorflow 2, commonlyknownasTensorFlow, isawidelyusedtoolforbuildingandtrainingdeep
learningmodels.It’sscalable,beginner-friendly,andwidelyadoptedinindustry.40 CHAPTER4. DEEPLEARNING101
4.5.1 Installingtensorflow
Togetstartedwithtensorflow,youcaninstallitusingpip:
# Install TensorFlow
pip install tensorflow
4.6 Training a Neural Network on the MNIST Dataset
TheMNISTdataset[13]consistsof70,000imagesofhandwrittendigits(0to9).Wewilluseittotrain
asimpleneuralnetworkthatcanrecognizethesedigits.
4.6.1 Step-by-Step: TrainingaNeuralNetworkwithTensorFlow2
BelowistheequivalentPythoncodefortraininganeuralnetworkontheMNISTdatasetusingTensor-
Flow2:
# Import necessary libraries
1
2 import tensorflow as tf
3 from tensorflow.keras import layers, models
4 from tensorflow.keras.datasets import mnist
5
# Step 1: Load and preprocess the MNIST dataset
6
(x_train, y_train), (x_test, y_test) = mnist.load_data()
7
8
# Normalize the images to values between 0 and 1
9
x_train, x_test = x_train / 255.0, x_test / 255.0
10
11
# Step 2: Define a simple neural network model
12
model = models.Sequential([
13
layers.Flatten(input_shape=(28, 28)), # Flatten the input image (28x28) to a 1D array
14
layers.Dense(128, activation='relu'), # Hidden layer with 128 neurons and ReLU activation
15
layers.Dense(64, activation='relu'), # Another hidden layer with 64 neurons
16
layers.Dense(10) # Output layer with 10 neurons (one for each digit)
17
])
18
19
# Step 3: Compile the model
20
21
model.compile(optimizer='adam', # Adam optimizer
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
22
metrics=['accuracy'])
23
24
# Step 4: Train the neural network
25
model.fit(x_train, y_train, epochs=5, batch_size=64)
26
27
# Step 5: Test the neural network
28
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
29
30
print(f"Accuracy: {test_acc * 100:.2f}%")
ExplanationoftheCode:4.7. TRAININGOUTPUTANDACCURACY 41
• mnist.load_data():LoadstheMNISTdataset.
• x_train / 255.0:Normalizesthepixelvaluesbetween0and1.
• Sequential():Definesasequentialmodelwherelayersareaddedonebyone.
• Flatten():Convertsthe28x28imagesintoaflatvector.
• Dense():Afullyconnectedlayer.Thelastlayerhas10neuronsforthe10digitclasses.
• compile():Specifiestheoptimizer,lossfunction,andevaluationmetrics.
• fit():Trainsthemodelonthetrainingdataforaspecifiednumberofepochs.
• evaluate():Teststhemodelandreturnsthelossandaccuracy.
4.7 Training Output and Accuracy
Duringthetrainingprocess,youwillseecontinuousupdatesonthemodel’sperformanceaftereach
batchofdata.Theseupdatesincludemetricssuchasthelossandaccuracy.Belowisanexampleof
howthisoutputlooksduringtraining,wheretheaccuracyattheendoftrainingishighlighted:
Asshowninthescreenshot,thefinalaccuracyofthemodelis97.76%.Thisaccuracyvaluerepre-
sentshowwellthemodelisperformingonthetestdatasetaftertraining. Thelowerthelossandthe
highertheaccuracy,thebetterthemodelisatmakingcorrectpredictions.
4.8 Introducing torch (PyTorch)
torch,alsoknownasPyTorch,isanotherpopulartoolforbuildingandtrainingdeeplearningmodels.
It’sflexible,easytouse,andwidelyadoptedbybothresearchersanddevelopers.42 CHAPTER4. DEEPLEARNING101
4.8.1 Installingtorch
Togetstartedwithtorch,weneedtoinstallit.Here’showyoucaninstallPyTorchusingpip:
# Install PyTorch with CPU support (no GPU needed)
pip install torch torchvision
torchvisionisanextrapackagethathelpswithhandlingimagedata,liketheMNISTdatasetwe’ll
useinthenextsection.
4.9 Training a Neural Network on the MNIST Dataset
TheMNISTdatasetisacollectionof70,000imagesofhandwrittendigits(0to9).We’lluseittotrain
asimpleneuralnetworkthatcanrecognizethesedigits.
4.9.1 Step-by-Step: TrainingaNeuralNetworkwithPyTorch
Here’saPythonexampleoftraininganeuralnetworkusingtheMNISTdatasetwithPyTorch. Wewill
loadthedataset,definethenetwork,trainit,andevaluateitsaccuracy.
# Import necessary libraries
1
2 import torch
3 import torch.nn as nn
4 import torch.optim as optim
5 from torch.utils.data import DataLoader
6 from torchvision import datasets, transforms
7
# Step 1: Prepare the MNIST dataset
8
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
9
train_data = datasets.MNIST(root='mnist_data', train=True, transform=transform, download=True)
10
test_data = datasets.MNIST(root='mnist_data', train=False, transform=transform, download=True)
11
12
# Step 2: Create data loaders for training and testing
13
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
14
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
15
16
# Step 3: Define a simple neural network
17
18 class NeuralNet(nn.Module):
19 def __init__(self):
20
super(NeuralNet, self).__init__()
21
self.fc1 = nn.Linear(28 * 28, 128) # Input layer (28x28 image = 784)
22
self.fc2 = nn.Linear(128, 64) # Hidden layer
23
self.fc3 = nn.Linear(64, 10) # Output layer (10 digits)
24
25 def forward(self, x):
x = x.view(-1, 28 * 28) # Flatten the image
26
27
x = torch.relu(self.fc1(x)) # Apply ReLU activation to input
28
x = torch.relu(self.fc2(x)) # Apply ReLU to hidden layer
29
x = self.fc3(x) # Output the result (logits)
30 return x4.10. UNDERSTANDINGNEURALNETWORKS(SIMPLIFIED) 43
31
# Step 4: Initialize the model, loss function, and optimizer
32
model = NeuralNet()
33
criterion = nn.CrossEntropyLoss() # Loss function for classification
34
optimizer = optim.Adam(model.parameters(), lr=0.001) # Optimizer to update weights
35
36
# Step 5: Train the neural network
37
epochs = 5
38
39 for epoch in range(epochs):
40 for images, labels in train_loader:
optimizer.zero_grad() # Clear gradients from previous step
41
output = model(images) # Forward pass (make prediction)
42
loss = criterion(output, labels) # Compute loss
43
loss.backward() # Backpropagation
44
optimizer.step() # Update weights
45
46
47
print(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}")
48
# Step 6: Test the neural network
49
correct = 0
50
total = 0
51
with torch.no_grad(): # No need to compute gradients during testing
52
53 for images, labels in test_loader:
output = model(images)
54
55
_, predicted = torch.max(output.data, 1) # Get predicted digit
total += labels.size(0)
56
57
correct += (predicted == labels).sum().item()
58
accuracy = 100 * correct / total
59
60
print(f"Accuracy: {accuracy:.2f}%")
ExplanationoftheCode:
• transforms.Compose():Normalizesandconvertsimagestotensors.
• DataLoader():Loadsthedatasetinbatchesforfastertraining.
• NeuralNet():Definesabasicneuralnetworkwithonehiddenlayer.
• optimizer.zero_grad():Resetsgradientsbeforeupdatingweights.
• loss.backward():Computesthegradientforbackpropagation.
• torch.max():Findsthehighestprobabilityclass(digit)foreachprediction.
4.10 Understanding Neural Networks (Simplified)
Neuralnetworksaremadeoflayersofneurons,andeachconnectionbetweenneuronshasaweight
thatthenetworkadjustsduringtraining.Here’sasimplebreakdownofhowitworks:
• InputLayer:Receivesrawdata(inthiscase,animageofadigit).44 CHAPTER4. DEEPLEARNING101
• HiddenLayer:Processestheinputandlooksforpatterns(e.g.,lines,shapes).
• OutputLayer:Producesthefinalresult(thedigitthenetworkthinksitis).
Thenetworklearnsbyadjustingitsweightsbasedontheerrorsitmakesduringtraining.Overtime,
itgetsbetteratmakingaccuratepredictions.
4.11 Using ChatGPT to Generate Deep Learning Code
Ifyou’reunsurehowtowritedeeplearningcodeorneedhelp,ChatGPTcanbeahelpfultool.Youcan
askittogeneratecodefortraininganeuralnetworkortoexplainaconceptindetail.
4.11.1 HowtoPromptChatGPTforCode
When asking ChatGPT for deep learning code, it’s important to be clear in your request. Here’s an
examplepromptyoucoulduse:
TensorFlow2Version
ExamplePrompt:
Can you generate Python code using TensorFlow 2 to train a neural network on the MNIST dataset?
Please include code to load the dataset, define a simple neural network, train it, and
evaluate its accuracy. Add in-line comments to explain each step.
ExampleResponsefromChatGPT
Here’sanexampleofwhatChatGPTmightgenerateinTensorFlow2:
# Import necessary libraries
1
2 import tensorflow as tf
3 from tensorflow.keras import layers, models
4 from tensorflow.keras.datasets import mnist
5 import numpy as np
6
# Load MNIST dataset
7
(x_train, y_train), (x_test, y_test) = mnist.load_data()
8
x_train, x_test = x_train / 255.0, x_test / 255.0
9
10
# Define the neural network
11
model = models.Sequential([
12
layers.Flatten(input_shape=(28, 28)),
13
layers.Dense(128, activation='relu'),
14
layers.Dense(64, activation='relu'),
15
layers.Dense(10)
16
])
17
18
# Compile the model
19
20
model.compile(optimizer='adam',
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
21
metrics=['accuracy'])
224.11. USINGCHATGPTTOGENERATEDEEPLEARNINGCODE 45
23
# Train the model
24
model.fit(x_train, y_train, epochs=5, batch_size=64)
25
26
# Evaluate the model
27
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
28
29
print(f'Accuracy: {test_acc:.2f}%')
PyTorchVersion
ExamplePrompt:
Can you generate Python code using PyTorch to train a neural network on the MNIST dataset?
Please include code to load the dataset, define a simple neural network, train it, and
evaluate its accuracy. Add in-line comments to explain each step.
ExampleResponsefromChatGPT
Here’sanexampleofwhatChatGPTmightgenerate:
# Import necessary libraries
1
2 import torch
3 import torch.nn as nn
4 from torchvision import datasets, transforms
5 from torch.utils.data import DataLoader
6
# Load MNIST dataset
7
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
8
train_data = datasets.MNIST(root='mnist_data', train=True, transform=transform, download=True)
9
test_data = datasets.MNIST(root='mnist_data', train=False, transform=transform, download=True)
10
11
# Create data loaders
12
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
13
test_loader = DataLoader(test_data, batch_size=64, shuffle=False)
14
15
# Define the neural network
16
17 class NeuralNet(nn.Module):
18 def __init__(self):
19
super(NeuralNet, self).__init__()
20
self.fc1 = nn.Linear(28*28, 128)
21
self.fc2 = nn.Linear(128, 64)
22
self.fc3 = nn.Linear(64, 10)
23
24 def forward(self, x):
x = x.view(-1, 28*28)
25
26
x = torch.relu(self.fc1(x))
27
x = torch.relu(self.fc2(x))
28
x = self.fc3(x)
29 return x
30
# Initialize model, loss function, and optimizer
3146 CHAPTER4. DEEPLEARNING101
model = NeuralNet()
32
criterion = nn.CrossEntropyLoss()
33
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
34
35
# Train the model
36
37 for epoch in range(5):
38 for images, labels in train_loader:
optimizer.zero_grad()
39
output = model(images)
40
loss = criterion(output, labels)
41
loss.backward()
42
optimizer.step()
43
44
# Evaluate the model
45
correct = 0
46
total = 0
47
with torch.no_grad():
48
49 for images, labels in test_loader:
output = model(images)
50
51
_, predicted = torch.max(output.data, 1)
total += labels.size(0)
52
53
correct += (predicted == labels).sum().item()
54
accuracy = 100 * correct / total
55
56
print(f'Accuracy: {accuracy:.2f}%')
4.12 Summary
• Deep Learning is a type of Machine Learning that uses neural networks to learn from large
amountsofdata.
• WeusedPyTorchtotrainaneuralnetworkontheMNISTdataset.
• Neuralnetworksconsistoflayersthatlearnpatternsindata,adjustingtheirweightstoimprove
accuracy.
• ChatGPTcanassistwithgeneratingDeepLearningcodeandexplainingconceptsstep-by-step.Chapter 5
Cool AI Applications That Are Changing
the Game
Figure5.1: Real-worldapplicationsofAIobjectdetection(byYOLOv8[62]). Noticehowmultipleob-
jects are detected, segmented, and classified in real time, showcasing the efficiency of modern CV
algorithms.
AIisn’tjusthypeanymore—it’severywhere,makingthingsthatseemedimpossiblejustafewyears
agolookeffortlesstoday. Fromgeneratingcodetoidentifyingobjectsinimagesandunderstanding
humanlanguage,AIhasbecomethebackboneofmoderntechnology. Thischapterdivesintosome
4748 CHAPTER5. COOLAIAPPLICATIONSTHATARECHANGINGTHEGAME
ofthecoolestAIapplicationsthatarenotjustimpressivebutaretransformingindustriesanddailylife
inbigways.
5.1 Cutting-Edge Computer Vision (CV) Tools
5.1.1 SegmentAnythingModel(SAM)
Ever wish you could instantly cut out an object from a picture or video, no matter how complex the
background? Segment Anything Model (SAM) [31] is making that wish come true. It lets you seg-
mentobjectsfromimagesandvideosinoneclick—perfectfordesigners,mediaeditors,orevenau-
tonomouscars. TheSAMweb-basedGUIisintuitive,allowingyoutoselectandisolateobjectswith
minimaleffort.Withasimpledragandclick,objectsaresegmented,whichmakestheeditingprocess
moreefficientandreducestheneedformanualpixel-leveladjustments.
Figure5.2: Left: OriginalimagebeforeSAMprocessing; Right: SAM’ssegmentedobjects. SAMcan
handlecomplexscenes,segmentingobjectsfromdifferentcategorieswithprecision,makingitarev-
olutionarytoolinimageprocessing.
WhatmakesSAMsofascinating: SAMispoweredbyconvolutionalneuralnetworks(CNNs)[38],
whichhavebeentrainedonmassivedatasetstorecognizeallkindsofobjects,nomattertheshape,
size,orenvironment.Itcanhandleeverythingfromcuttingoutapersoninacrowdedroomtoisolating
aproductfromashelf. Thewebinterfaceprovidesreal-timepreviews, souserscanseetheresults
instantly,makingworkflowsfaster.
Inspiration behind SAM: SAM reflects the future of AI popularization — AI that requires minimal
humaninputtoachievecomplextasks. DevelopersbehindSAMhavemadeitclearthattheirgoalis
tomakeimageeditingassimpleaspossible,takingawayhoursoftediousmanualwork.
5.1.2 DigitalAvatars
From video games to social media, AI-generated Digital Avatars [41] are here, and they look more
lifelikethanever.Theseavatarscanexpressemotions,makegestures,andevenspeak,makingthem
an integral part of virtual reality worlds, online influencers, and more. The user interface of these
avatar-creatingtoolsisoftenstraightforward,lettinguserscrafthighlyrealisticavatarswithjustafew
clicks. Whetheryou’reagameroracontentcreator,DigitalAvatarsallowforpersonalcustomization
thatmirrorsreal-worldbehaviorsandexpressions.5.2. AIINNATURALLANGUAGEPROCESSING(NLP) 49
WhyDigitalAvatarsareabigdeal: Digitalavatars, poweredbyGenerativeAdversarialNetworks
(GANs)[21],havemadeitpossibleforvirtualcharacterstobehavejustlikehumans.Inthemetaverse,
digitalavatarsrepresentyou,interactwithothers,andevenattendmeetingsonyourbehalf.Theease
of use and the ability to fine-tune details—such as facial expressions and micro-interactions—mean
anyonecancreateadigitalversionofthemselvesorafictionalcharacterwithlittletechnicalexpertise.
Virtualavatarsandinfluence:TrevorMcFedries,founderofBrud,thecompanybehindtheAIinflu-
encerLilMiquela,oncesaid,"Thefutureisaworldwherepeoplewillbeengagingwithpersonalities
thataren’tevenhuman."Thatfutureisnow,anddigitalavatarsareleadingthecharge.
5.2 AI in Natural Language Processing (NLP)
5.2.1 ChatGPT
ChatGPT [36] hardly needs an introduction. This conversational AI from OpenAI can chat with you
aboutanything—fromwritingapoemtoansweringtoughtechnicalquestions. ChatGPThasbecome
thego-totoolforcreativewriting,coding,andevenprovidinginstantcustomerservice.Thewebinter-
faceisuser-friendly,allowingforreal-timeinteractionwheretheAIrespondswithinseconds,making
ithighlyefficientforbothindividualusersandbusinesses.
Figure5.3:ChatGPTinactionansweringaquery.Theinterfaceprovidesaseamlessexperience,with
responsesgeneratedinrealtime,offeringbothcasualconversationandtechnicalsupportwithease.
The magic behind ChatGPT: ChatGPT runs on the GPT (Generative Pretrained Transformer) [71]
architecture,trainedonbillionsoftextstogeneratehuman-likeresponses.It’sincrediblyversatileand
can adapt its responses to different tones and styles, making it a powerful assistant in almost any
field. Whether you need it for professional use or casual questions, the platform’s easy-to-navigate
GUImeansanyonecanengagewiththeAIeffortlessly.
WhatSamAltmansaid:OpenAI’sCEOSamAltmanonceremarked,"AIisthemostimportanttech-
nology that humanity has ever developed." ChatGPT certainly lives up to that claim, enabling users
worldwidetoharnessthepowerofadvancedlanguagemodelswithjustafewkeystrokes.50 CHAPTER5. COOLAIAPPLICATIONSTHATARECHANGINGTHEGAME
5.2.2 Gemini: TheAIPersonalAssistant
Gemini[58]takesAIpersonalassistantstothenextlevel.AlexaandSirihelpyouwithbasictasks,but
Geminilearnsfromyourhabitsandanticipatesyourneeds.Whetheryou’redraftingemails,scheduling
meetings,orrespondingtotexts,Gemini’sintuitiveinterfacemakesorganizingyourlifesimple.
Figure 5.4: Starting a conversation with Gemini. The interface is intuitive and engaging, allowing
users to begin tasks with simple commands.Gemini responds efficiently with personalized insights
andtasks.Hereitshowsalistofactionsthatitcanhandlewithoutanyneedformanualsetup.Gemini
canperformvariousoperations,fromschedulingtoreminders,showninthisinterfaceasoptionshigh-
lightedforuserinput.Geminigeneratinganemaildraftbasedontheuser’spreferences—withouttyping
asingleword.Thisfeatureshowshowtheassistanthandlesrepetitivetaskseffortlessly.
WhatsetsGeminiapart: Unliketypicalassistants,Geminiusesreinforcementlearningtogetbet-
terthemoreyouinteractwithit. Whetheryou’replanningmeetings, answeringemails, orsettingre-
minders,Geminicanhandleallofitwithoutskippingabeat.Theinterfaceisdesignedtominimizethe
stepsrequiredtocompletetasks,makingitmuchfasterthantraditionalpersonalassistants.
Elon Musk’s take: "We’re headed toward a world where AI will assist us in almost everything."
Musk’svisionseemstocometolifewithassistantslikeGemini,whichpromiseafuturewheretech-
nologyisseamlesslywovenintoourdailytasks.
5.3 AI for Creative Industries
5.3.1 Flux: AIforPhotography
EditingphotoshasneverbeeneasierthankstoFlux[8],anAI-poweredphotographytoolthatcanen-
hanceyourimageswithasingleclick.Whetheryouwanttoadjustlighting,removeunwantedobjects,
orapplyartisticfilters,Fluxtakescareofitall.Thetool’swebinterfaceisdesignedtobeassimpleas
possible,offeringslidersandone-clickpresetsthatinstantlyimproveyourphotos.
HowFluxisreshapingphotography: Withconvolutionalneuralnetworks(CNNs)[38]asitsback-
bone,Fluxidentifieselementslikefacesandobjects,optimizingthemforperfectlighting,balance,and
color. Thismeansevenamateurphotographerscanachieveprofessionalresultsinafractionofthe5.3. AIFORCREATIVEINDUSTRIES 51
time. Thetool’sAIalsosuggestscreativeadjustments, turningordinaryshotsintovisuallystunning
images.
5.3.2 AICodingTools: TheFutureofSoftwareDevelopment
TheworldofprogrammingisbeingrevolutionizedbyAItoolsdesignedtoboostproductivityandassist
developersateverystep.Let’sdiveintothreemajorplayersintheAIcodingspace:Cursor[57],GitHub
Copilot[20],andOpenDevin[66].
Cursor:CursorisyourAIcodingbuddy—whetheryou’redebuggingorwritingcode,Cursoristhere
to help. It suggests code snippets, fixes bugs, and even generates entire functions based on your
input,makingcodingmoreefficientthanever.ThewebGUIisstreamlined,allowingdeveloperstosee
real-timecodesuggestionsanddocumentation,makingiteasytoimplementsolutionswithminimal
manualcoding.
Figure5.5:Left:Cursoranalyzingcodeandsuggestingfixes;Right:Cursor’sdetailedcodegeneration
basedonminimalinput.ThisAItoolcansignificantlyreducedebuggingandcodingtime.
GitHubCopilot: PoweredbyOpenAI’sCodexmodel,GitHubCopilotislikehavingaco-pilotwhile
youcode. Itpredictswhatyou’retryingtowrite,suggestscodecompletions,andevenwritesboiler-
platecode,freeingyoufromrepetitivetasks. ThesimplicityofGitHubCopilot’sinterfacemeansthat
evennovicedeveloperscaneasilyintegrateitintotheirworkflow.Byhoveringoverthesuggestionbox,
youcanapplyentireblocksofcodeinoneclick,increasingefficiencydramatically.52 CHAPTER5. COOLAIAPPLICATIONSTHATARECHANGINGTHEGAME
Figure5.6:GitHubCopilotinaction,suggestingcodecompletionsandwritingfunctionsautomatically
basedonuserprompts.Thissignificantlyreducesthetimespentonwritingrepetitivecode.
OpenDevin:Developedtoprovidesmartinsights,OpenDevinhelpsdevelopersidentifycodingpat-
terns,predicterrors,andgeneratecodedocumentation. Thinkofitasanintelligentassistantforen-
suringthatyourcodeisnotjustfunctionalbutalsooptimized.OpenDevin’sintuitivedashboardoffers
aholisticviewofyourcodebase,ensuringthateverypartofyourprojectisanalyzedforefficiency.
Developers’Perspectives:
• Greg Brockman, co-founder of OpenAI, once said, "The future of programming is no program-
ming."ToolslikeGitHubCopilotandCursorareturningthatvisionintorealitybydoingtheheavy
liftingfordevelopers.
• AndrejKarpathy,AIresearcherandformerdirectorofAIatTesla,hasbeenvocalabouttherole
AIwillplayinwritingandmaintainingcode."AIisfundamentallyanewwayofcreatingsoftware."
5.4 AI in Geospatial Intelligence
5.4.1 Geospy.ai: GeospatialAI
Geospatialintelligencehasbecomeacriticalpartofenvironmentalmanagement,disasterresponse,
andurbanplanning. Geospy.ai [59]usesAI toanalyzesatelliteimagery, providingreal-timeinsights
intolanduse,forestcover,andevenurbangrowth.
What Geospy.ai brings to the table: Geospy.ai is built on convolutional neural networks (CNNs)
designedtoprocessvastamountsofgeospatialdata. Itcandetectchangesininfrastructure, track
deforestation,andprovidecriticalinsightsthatwouldotherwisetakeyearstogathermanually.
Mark Zuckerberg’s view: Mark Zuckerberg once said, "In the future, every company will use AI."
Geospy.aiembodiesthatideabyintegratingAIintoindustriesthatmightnotseemobvious,likeenvi-
ronmentalconservationandcityplanning.5.5. SUMMARY 53
5.5 Summary
FromChatGPT’sconversationstoGeospy.ai’sreal-timesatelliteanalysis,AIisadvancingfasterthan
ever, transforming industries and simplifying complex tasks. Developers, designers, and everyday
usersarebenefitingfromAI’sabilitytoautomate,assist,andinspire.Whetheryou’reusingAItowrite
codewithtoolslikeCursorandGitHubCopilotorenhancingimageswithFlux,thefutureisbright,and
AIisleadingthecharge.54 CHAPTER5. COOLAIAPPLICATIONSTHATARECHANGINGTHEGAMEChapter 6
An Introduction to Generative art: A
Beginner’s Exploration
6.1 What are Diffusion models?
Itisatypeofprobabilisticmodelthathasbeengettingattentionforitsabilitytogeneratehigh-quality,
realistic images in the world of artificial intelligence (AI) and machine learning. In diffusion [27], a
simplerandomnoisedistributionisgraduallytransformedintoameaningfulstructureorimageover
time,asaresultoflearningandrefining. Thediffusionprocesscanbeunderstoodasthereverseof
howphysicalparticlesspreador"diffuse"fromanorderedstatetoadisorderedone.Asacoreprinciple
ofAI,diffusionmodelsarebasedonthereverseprocessoftakingrandomnoiseandtransformingit
intodetailed,structureddata,suchasanimage.
Insimpleterms,diffusionmodelsattempttogeneratesomethingmeaningful(likeanimage)from
randomness by learning how to reverse the natural process of noise. Through iterative refinement,
theyproducehigh-qualityresultsthatrivalotherAImethods,suchasGenerativeAdversarialNetworks
(GANs)[21],butwithgreaterstabilityandfewergenerationproblems.
6.2 Stable Diffusion: A Game-Changer in AI Art Generation
TheStableDiffusion[45]modelisastate-of-the-artdeeplearningmodeldesignedforAI-basedimage
generation. Afteritsreleasein2022,itwasquicklyrecognizedasabreakthroughinAIart. Previous
modelssuchasGANsandautoregressivemodelshadshownpromiseingeneratingrealisticimages
butoftencamewithlimitationssuchasinstability,modecollapse(repeatingthesametypeofoutput
repeatedly),andlimitedgenerationcapabilities.
StableDiffusion,asitsnamesuggests,bringsgreaterstabilityandflexibility.Ittakesthediffusion
processandappliesittogeneratehigh-resolution,coherentimagesfromrandomnoise,learningfrom
massivedatasetsofimagesandtheircorrespondingdescriptions. WhatsetsStableDiffusionapart
fromotherimage-generationtechniquesisitsabilitytocreatehighlydetailedimages,evenwhenstart-
ingfromsimpleprompts. Itcangenerateartwork, landscapes, portraits, andevenabstractimagery
basedontextdescriptions,makingitoneofthemostpowerfultoolsintheAIartworld.
Themodelworksbyiterativelyrefiningnoisyimages, usingaprocesscalleddenoisingdiffusion
probabilisticmodels(DDPM).Throughthis,itlearnstoreversethenoiseandgenerateaclear,realistic
5556 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
imagefromrandompatterns,effectively"stabilizing"thegenerationprocess.
Figure6.1:SnapshotoftheimagegenerationprocessusingStableDiffusionwithWebUI.Thesettings
andparametersusedforgeneratinghigh-qualityimagescanbeeasilyadjustedviathegraphicalinter-
face.
Figure 6.2: Animated sequence showing how Stable Diffusion refines the noise iteratively to create
coherentandhigh-qualityimages.Theseframescapturevariousstagesoftheimage-generationpro-
cess.6.3. AIART:THEFUSIONOFCREATIVITYANDTECHNOLOGY 57
Figure6.3:AdemoofStableDiffusionusingtheWebUIinterface,showcasingitsflexibilityincreating
multipleimagesatoncewithdifferentpromptsandsettings.
Figure6.4:AnothersetofanimatedframesfromtheStableDiffusionprocess,showinghowdifferent
detailsemergeduringthedenoisingprocesstocreateintricate,finalimages.
6.3 AI Art: The Fusion of Creativity and Technology
AIarthasrevolutionizedthewaywethinkaboutcreativity. Artists,designers,andhobbyistsarenow
leveragingAItoolslikeStableDiffusiontogeneratecomplex,imaginativeartworkthatpreviouslyre-
quiredyearsofskilltoproduce. Byfeedingthemodelatextualdescription,userscanseetheirideas
transformedintovividimagerywithinminutes.Thisblendofhumancreativityandmachinelearningis
shapinganeweraofdigitalart,whereAIactsasacollaborator,expandingtheboundariesofartistic
possibilities.
Artificialintelligencecancreatesurreal,abstractcompositionsaswellashyper-realisticportraits
andlandscapes.Themostexcitingthingaboutthistechnologyisthatitallowsanyonetorealizetheir
visions,regardlessoftheirartisticbackground. AsAImodelsbecomemorerefined,theyalsobegin
tolearnindividualartisticstyles,givingcreatorsgreatercontrol.58 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
6.4 Two Main Interfaces: WebUI vs. ComfyUI
Userinterfaces(GUIs)arecommonlyusedtomakecomplextechnologymoreaccessiblewhenusing
Stable Diffusion or other diffusion models to generate art. Two of the most popular interfaces are
WebUIandComfyUI.Whilebothofferaccesstodiffusionmodelsforimagegeneration,theneedsand
preferencesoftheirusersvaryslightly.
6.4.1 WebUI:TheUser-FriendlyOption
WebUI [5], short for "Web User Interface," is one of the most popular platforms for interacting with
StableDiffusion.It’sknownforbeinguser-friendlyandaccessibletoabroadaudience,frombeginners
tomoreadvancedusers.WebUIisdesignedwithsimplicityinmind,providinganintuitiveinterfacethat
allows users to easily input text prompts and generate images without needing extensive technical
knowledge.
WebUI’skeyfeaturesinclude:
• EaseofUse:Asimple,cleandesignmakesiteasytostartgeneratingimagesrightaway.
• Customization:Userscantweakvarioussettings,suchasimageresolution,samplingsteps,and
denoisingstrength,tofine-tunetheirresults.
• Compatibility:WebUIsupportsavarietyofmodels,includingthelatestversionsofStableDiffu-
sion,andintegrateswithpluginsandextensionstooffermoreadvancedfunctionality.
For many users, especially those just beginning to explore AI-generated art, WebUI is the ideal
startingpoint. Itprovidestheessentialtoolstogeneratestunningimagesquicklyandwithminimal
technicalbarriers.
6.4.2 ComfyUI:AdvancedWorkflowCustomization
WhileWebUIisexcellentforeaseofuse,ComfyUI[56]isgearedtowarduserswhowantmorecontrol
overthegenerationprocess.ComfyUIallowsforadvancedworkflowcustomization,whereuserscan
breakdowntheimagegenerationprocessintoaseriesofinterconnectedstepsor"nodes,"similarto
howyouwouldworkinavisualprogrammingenvironment.
SomekeyfeaturesofComfyUIinclude:
• Node-basedWorkflow: Userscancreatecustompipelinesforimagegenerationbyconnecting
differentprocessingsteps.Thisallowsforgreaterexperimentationandfine-tuning.
• Flexibility:ComfyUIisdesignedforuserswhowanttoexperimentwithdifferentdiffusionmod-
els and algorithms. It offers more granular control over the image creation process, enabling
userstomanipulateeveryaspectofthegenerationpipeline.
• PowerfulCustomization: Thisplatformisbestsuitedforuserswhoarecomfortablewithmore
technicalaspectsofimagegeneration,allowingthemtotestvariousparametersandmethods
toachieveuniqueandpreciseresults.
WhileComfyUIhasasteeperlearningcurvecomparedtoWebUI,it’sapowerfultoolforthosewho
wanttodivedeeperintothemechanicsofdiffusionmodelsandexperimentwithdifferentworkflows.
6.5 Comparison of WebUI and ComfyUI
ThefollowingtableprovidesacomparisonoftheprosandconsofbothWebUIandComfyUI:6.6. GETTINGSTARTEDWITHWEBUI 59
WebUI ComfyUI
Pros
• User-friendlyinterface,idealforbeginners • Node-based workflow allows for precise
• Simplesetupandminimaltechnicalknowl- control
edgerequired • Highlycustomizablepipelinesforadvanced
• Quick image generation with default set- usersondetailedcontrolovereachgenera-
tings tionstep
• Supportsvariousmodelsandplugins • Ideal for creating complex and specific
• Customizable image parameters like reso- workflows
lution,samplingsteps,anddenoising • Workflowsaretransferableandcanbefinal-
ized as a Python module to run in an auto-
maticpipeline.
Cons
• Limited customization compared to more • Steeperlearningcurve,requiresmoretech-
advancedtools nicalunderstanding
• May not offer enough control for experi- • Canbeoverwhelmingforbeginners
encedusers • Longersetupandimagegenerationprocess
• Less suited for highly technical or experi- duetothecomplexityofthepipeline
mentalworkflows • Mayrequiremoretimetofine-tuneandtest
• Thenumberofusersisshrinking parameters
*ItisstronglyrecommendedthatbeginnersfocustheirlearningonComfyUI
Table6.1:ComparisonofWebUIandComfyUI:ProsandCons
Since WebUI is relatively simple and user-friendly, it’s a great starting point for those new to AI-
generatedart.ByexploringWebUIfirst,userscanquicklygraspthebasicconceptsofdiffusionmodels
andimagegenerationwithoutbeingoverwhelmedbycomplexfeatures.Thisfoundationalexperience
willhelpinunderstandingthemoreadvancedfunctionalitiesthatComfyUIofferslateron,makingthe
transitionsmootherandmorerewardingwhenmovingtoamorepowerfulandcustomizabletoollike
ComfyUI.
6.6 Getting Started with WebUI
WebUI is a graphic interface that lets users play with diffusion-based generative models easily and
prototyping quickly. This section will walk through the process of installing WebUI and generating
yourfirstimage.
6.6.1 Installation
TogetstartedwithWebUI,youwillfirstneedtodownloadandinstallit. Followthesestepstoinstall
WebUIonyoursystem:60 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
1. Download WebUI: Head over to the official WebUI GitHub repository and clone the repository
usingthefollowingcommand:
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
Aftertheclone,youcanfollowtheinstructionsinInstallationandRunning.Keepinmindtomatch
youroperatingsystemandgraphicshardware.
2. LaunchWebUI:Onceinstalled,runthefollowingcommandtolaunchWebUIonLinux:
bash webui.sh
ForWindowsusers,youcanlaunchitusing:
webui-user.bat
Then the WebUI should be opening on your web browser.
6.6.2 GenerateYourFirstImage
WebUI comes with a stable diffusion 1.5 checkpoint, to replace any version of the diffusion model,
pleasefollowthisfolderstructuretoputyourdiffusiongenerativemodel:
stable-diffusion-webui/
|-- models/ # Contains subfolders for different model types
| |-- Stable-diffusion/ # Stable Diffusion model checkpoint files
| |-- Lora/ # LoRA model files
| |-- VAE/ # Variational AutoEncoder models
| |...
Let’sstartwiththebasicusage:generateanimagefromtext(txt2imgtab).
• Stable Diffusion Checkpoint: In this dropdown, select the stable diffusion model you want to
usefromtheStable-diffusionfolder.
• Prompts: Describe want you want to see in the Prompt text box. Within Negative Prompt text
box,youcanputthingsyoudon’twantintheimage.
• WidthandHeight: Thisisthesizeoftheoutputimage. Differentdiffusionmodelsmighthave
different output resolutions, set at least one side to 512 for v1.x stable-diffusion models, and
1024forstable-diffusionxlmodels.
• Sampling Methods: Choose the algorithm for the denoising process. You can prototype from
DPM++ 2M Karras[32]sinceitprovidesagoodbalancebetweenspeedandquality.
• Sampling Steps: The number of steps for the denoising algorithm above. When you choose
different denoising algorithms the best number of steps might change. Tweak the sampling
stepswiththemethods.
• BatchCount:Numberoftimesyouruntheimagegenerationprocess.
• BatchSize:Numberofimagestogenerateperpipelinerun.
Onceyouchooseyourpreferredparameters,clickGeneratethenwaitforyourimagestobegener-
ated.Remember,youcanalwaysleverageLLMtoimproveyourprompts!6.6. GETTINGSTARTEDWITHWEBUI 61
Figure6.5:TheWebUIInterface62 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
Figure 6.6: Prompt: A highly detailed matte painting of huge sector v treehouse by Studio Ghibli,
Makoto Shinkai, by Artgerm, by Greg Rutkowski, volumetric lighting, octane render, 4K resolution,
trendingonartstation,masterpiece
Figure6.7:Prompt:Afemalecharacterdesign,shorthairwearingheadphones,backgroundinthecity,
Pixelstyle,transparentpvcjacket6.7. GETTINGSTARTEDWITHCOMFYUI 63
Figure6.8:Prompt:Afemalecharacterdesign,shorthairwearingheadphones,backgroundinthecity,
HarajukuStyle,transparentpvcjacket
6.7 Getting Started with ComfyUI
ComfyUI is a powerful node-based interface designed for generating images using AI models like
StableDiffusion. ThissectionwillwalkthroughtheprocessofinstallingComfyUI,settingupabasic
workflow,andgeneratingyourfirstimage.
6.7.1 Installation
TogetstartedwithComfyUI,youwillfirstneedtodownloadandinstallit.Followthesestepstoinstall
ComfyUIonyoursystem:
1. DownloadComfyUI:HeadovertotheofficialComfyUIGitHubrepositoryandclonetherepository
usingthefollowingcommand:
git clone https://github.com/comfyanonymous/ComfyUI
Alternatively, youcanfollowtheRead Me pageanddownloadthestandaloneversionforWin-
dowsandextractit.
2. InstallDependencies: IfyouareusingPython,navigatetotheComfyUIdirectoryandinstallthe
requireddependenciesusing:
pip install -r requirements.txt
3. LaunchComfyUI:Onceinstalled,runthefollowingcommandtolaunchComfyUI:
python main.py
ForMacusers,youcanlaunchitusing:
python main.py --force-fp1664 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
Figure6.9:TheComfyUIManagerMenu
TryComfyUIinGoogleColab
Google Colab [44] (short for Collaboratory) is a free cloud-based service provided by Google which
allows users to write and execute Python code in a Jupyter notebook environment. Colab particu-
larlypopularfordatascience,machinelearning,andartificialintelligenceprojectsbecauseitprovides
accesstopowerfulcomputationalresourceslikeGPUsandTPUswithoutneedingalocalsetup.
To change your Google Colab notebook to use a GPU for free, follow these steps: In the Colab
interface, click on Runtime in the menu bar. Then, select Change runtime type from the dropdown
menu. Inthedialogboxthatappears,underHardware accelerator,chooseGPUfromthedropdown.
Afterselectingit,clickSave.ThiswillenabletheGPUforyoursession,allowingforfastercomputation,
particularlyfortasksinvolvingmachinelearningordeeplearningmodels.
UsethisColabnotebooktoclonetheComfyUIrepoandinstallrequiredpackages.Thesamenote-
bookcanbefoundinsidetheComfyUIGitHubrepository.Thisisawell-annotatednotebook,andwhat
eachcellisusedforshouldbewell-annotatedandself-explanatory,keepinmindthatyourfreeGPU
sessionmaysubjecttoearlytermination.
6.7.2 InstallComfyUIManager
TheComfyUI-ManagerisanextensiondesignedtoenhancetheusabilityofComfyUI.Toinstalland
usetheComfyUIManager, followthesesteps, whichwillguideyouthroughtheinstallationprocess
andthebasicusageofthemanager.ThiswillhelpyoumanagecustomnodesinComfyUIefficiently.
• First,makesureyouhaveComfyUIinstalled. Ifit’snotinstalledyet,downloaditfromtheComfyUI
GitHubrepositoryandfollowtheinstallationinstructions.
• Openaterminalorcommandprompt,andnavigatetothecustom_nodesdirectoryinyourComfyUI
folder:
cd path/to/ComfyUI/custom_nodes/
• ClonetheComfyUIManagerrepositoryintothecustom_nodesdirectoryusing:6.7. GETTINGSTARTEDWITHCOMFYUI 65
git clone https://github.com/ltdrdata/ComfyUI-Manager.git
• RestartComfyUItorecognizetheComfyUIManager.Thiscanbedonebyclosingandreopeningthe
application.
• Once ComfyUI restarts, you can find the ComfyUI Manager on the interface. Click Manager in the
mainmenutoopenthemanagementinterfaceforcustomnodes.
• IntheComfyUIManager,youcanusetheInstall Custom Nodesoptiontoautomaticallydetectand
install any missing nodes. This feature is especially helpful when uploading new workflows, as it
simplifiestheprocessbylistingmissingnodesinred.
• Additionally, theManagerallowsyoutoupdate, disable, orremovenodes. ClickonUpdate Allto
refreshandensureallnodesareuptodate.
• Ifyoucomeacrossconflictingnodes(showninyellow),theycanbedisableddirectlyfromtheCom-
fyUIManagerinterfacetoavoidissues.
6.7.3 SettingUpYourDefaultWorkflow
ThestructureoftheComfyUIfoldershouldlooklikethefollowing:
ComfyUI/
|-- custom_nodes/ # Directory for custom node files
|-- input/ # Folder where uploaded assets are stored
|-- models/ # Contains subfolders for different model types
| |-- checkpoints/ # Stable Diffusion model checkpoint files
| |-- clip/ # CLIP model files
| |-- clip_vision/ # CLIP Vision model files
| |-- controlnet/ # ControlNet models
| |-- loras/ # LoRA model files
| |-- vae/ # Variational AutoEncoder models
| |-- unet/ # UNet architecture files
| `-- upscale_models/ # Models for upscaling images
|-- notebooks/ # Jupyter Notebooks for Colab and remote executions
|-- output/ # Generated images saved here
|-- config/ # Configuration files for models and environment
|-- extra_model_paths.yaml.example # Example config file for extra model paths
|-- comfyui.log # Runtime log file
|-- README_VERY_IMPORTANT.txt # Instructions and usage details
`-- run_nvidia_gpu.bat # Script to run ComfyUI on Nvidia GPUs
OnceComfyUIisinstalled,youcanloadadefaultworkflowforgeneratingimages.Here’show:
1. Download a Model: Download a model checkpoint, such as Stable Diffusion v1.5, and place it
in the directory ComfyUI/models/checkpoints. Civitai [55] is a community-driven platform for
sharinganddiscoveringcustommodelsandassetsusedinAI-generatedart,primarilyfocused
onStableDiffusionandotherdiffusionmodels.
2. LoadtheDefaultWorkflow: OpenComfyUIandclicktheLoad Defaultbuttontoloadthebasic
workflow.IntheLoad Checkpointnode,selectthemodelyoujustdownloaded.66 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
Figure6.10:TheComfyUIinterfacewithasimpleimagegenerationworkflow
6.7.4 GenerateYourFirstImage
ComfyUI uses a node-based interface (see Figure 6.10) where all operations are performed by con-
nectingdifferentnodes.Tobegingeneratingimages:
• AddNodes: Right-clickonthecanvasandselectAdd Nodes,ordoubleleft-clickthecanvasand
searchforanode. Forimagegeneration,importantnodesincludeLoad Checkpoint,CLIP Text
Encode,andKSampler.
• Prompts and Parameters: Set your prompts in the CLIP Text Encode node (positive and neg-
ativepromptnodesareconnectedtoKSamplerrespectively)toguideimagegeneration. Adjust
parameterssuchasthenumberofdiffusionstepsandtheCFG scaleintheKSamplernode.
• QueueandGenerate:Oncethenodesareconnected,clickQueue Prompttogeneratetheimage.
Experimentwithdifferentpromptstorefinetheresults.
6.7.5 TryOtherModels
TouseothermodelsinComfyUI,followthesestep-by-stepinstructionstoensureproperinstallation
andworkflowsetup(thisexamplewillshowyouhowtousetheAnythingXLmodel):
• DownloadtheAnythingXLModel:First,downloadtheAnythingXLmodelfromaplatformlikeHug-
gingFaceorCivitAI.Makesurethefileisin.safetensorsor.ckptformat.
• PlacetheModelintheCorrectDirectory:NavigatetoyourComfyUIinstallationdirectory,andplace
thedownloadedAnythingXLmodelintheComfyUI/models/checkpointsfolder.
• Launch ComfyUI: Open ComfyUI by running the appropriate batch file depending on your system
(e.g.,run_nvidia_gpu.batforNVIDIAGPUs).6.7. GETTINGSTARTEDWITHCOMFYUI 67
• Clear the Workspace: Once ComfyUI opens, click Clear to clear any pre-loaded workflows on the
workspace.Thiswillgiveyouacleanslatetostartfromscratch.
• LoadtheAnythingXLModel: Right-clickontheworkspace,andnavigatetoAdd Node > Loaders >
Load Checkpoint.Fromtheoptionsinthedropdown,selecttheAnythingXLmodelyouplacedinthe
checkpointsfolderearlier.
• Add the KSampler Node: Right-click on the workspace again and go to Add Node > Sampling >
KSampler.Thisnodeisessentialforgeneratingimagesfromrandomnoise.
• ConnecttheModelandKSampler:ConnecttheoutputfromtheLoad Checkpointnode(MODEL)to
theinputoftheKSamplernode(model).Thislinksthemodeltothesamplingprocess.
• Set Up Prompts (Positive/Negative): To tell the model what to generate, you need to add prompt
nodes. Right-click the workspace and select Add Node > Conditioning > CLIP Text Encode
(Prompt). This will be your positive prompt node. Repeat this step for the negative prompt. Link
thepositiveprompt’soutputtotheconditioninginputoftheKSamplernode.Similarly,linktheneg-
ativeprompt’soutputtotheconditioning (negative)inputontheKSampler.
• Add Empty Latent Image: Right-click on the workspace and select Add Node > latent > Empty
Latent Image. Thisnodewillactasthestartingpointfortheimagegeneration. Connectitsoutput
tothelatentimageinputontheKSampler.
• VAEDecode: Thegeneratedlatentimageneedstobedecodedintoaviewableformat. Right-click
andselectAdd Node > latent > VAE Decode. ConnecttheKSampler’slatentoutputtothesamples
inputontheVAEDecodenode.
• SavetheImage: AddthefinalnodebyselectingAdd Node > image > Save Image. Thisnodewill
savethegeneratedimagetoyouroutputfolder. ConnecttheoutputoftheVAEDecodenodetothe
SaveImagenode.
• Adjust Parameters: You can now fine-tune your settings. Adjust the image size in the Empty La-
tent Image node to match Anything XL’s training resolution (1024x1024). You can also modify the
samplingstepsandCFGscaleintheKSamplernodetorefinetheoutput.
• GeneratetheImage: Onceallnodesareconnected,andparametersareset,clickQueue Promptto
generatetheimage.Theprocessmighttakeafewminutes,dependingonyoursystemandsettings.
• Review and Save: Aftertheimageisgenerated, itwillbesavedautomaticallyintheoutputfolder,
butyoucanpreviewandmakeanyadditionaladjustmentstoyourpromptsorsettingsifneeded.
WhenusingtheAnythingXLmodelwithComfyUI,configuringtheKSamplernodecorrectlyquite
important. Here’sanoverviewoftherecommendedKSamplersettings,alongwithanexplanationof
theirfunctions:
• Steps:Thenumberofsamplingsteps.ForAnythingXL,youtypicallywanttosetthistoaround20-40
steps. Higherstepsusuallyresultinbetterimagequalitybutwilltakelongertoprocess. Forquick
previews,youmightstartwithalowervaluelike20,butforhigh-qualityfinaloutputs,goingupto40
oreven50stepscanproducemorerefinedimages.
• CFG(Classifier-FreeGuidance)Scale:Thisparametercontrolshowmuchthemodeladherestothe
textprompts. ForAnythingXL,agoodstartingvalueis7-12. Lowervalueslike7willgivemorecre-
ativefreedomtothemodel,whilehighervalueslike12willenforcestricteradherencetotheprompt.
Startwith7.5forbalancedresults,andadjustbasedonyourneeds.
• Seed:Thisisusedfordeterministicimagegeneration.Bysettingaspecificseed,youcanregenerate
the exact same image. If you want random images each time, leave this as -1 (which stands for
randomseed).68 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATION
Figure6.11:TheComfyUIinterfacewithasimpleimagegenerationworkflow
• SamplerAlgorithm: KSampleroffersdifferentalgorithmstocontrolhowthenoiseisremovedover
time. ForAnythingXL,EulerAorDPM++2MKarrasarepopularchoicesforproducingsharperand
more detailed results. Euler A is faster but might not be as precise as DPM++ 2M Karras. If you
prioritizespeed,gowithEulerA,otherwisetryDPM++2MKarrasforhigh-qualityoutputs.
• DenoisingStrength: Thisparameterisespeciallyusefulifyou’reusingtechniqueslikeImg2Imgor
refining an existing image. A value around 0.7-0.9 works well for generating detailed results. For
text-to-imagegeneration,youusuallyleavethisat1.
YoucancheckouttheexampleinFigure6.11
6.7.6 AdvancedFeatures
ComfyUI also supports more advanced workflows, such as image-to-image (Img2Img) generation,
whereyoucaninputanexistingimagetomodify.Additionally,youcanexplorevariousnodeshortcuts
likeCTRL + dragtoselectmultiplenodes,orSHIFT + dragtomovethem.
ThissetupwillallowyoutogetstartedwithComfyUIandgenerateyourfirstbatchofAI-powered
images.
6.8 Summary
Asweexploredinthischapter,diffusionmodelsandtheirrolesinAI-drivenimagegenerationwerethe
foundationsofgenerativeart.Diffusionmodelshaveemergedasapowerfulmethodfortransforming
randomnoiseintocoherent, high-qualityimages, providingastablealternativetoearliertechniques
like Generative Adversarial Networks (GANs). The development of models like Stable Diffusion has6.8. SUMMARY 69
revolutionizedAIartgeneration, enablingartistsandhobbyistsaliketocreatedetailedandvividim-
ageryfromsimpletextprompts.
We also examined two main interfaces—WebUI and ComfyUI—through which users can interact
with diffusion models. WebUI, with its user-friendly design, offers an accessible platform for begin-
nerstogenerateAIartwithminimaltechnicalknowledge. Ontheotherhand,ComfyUIistailoredfor
moreadvancedusers, providinggranularcontroloverthegenerationprocessthroughanode-based
workflow,allowingforgreaterexperimentationandcustomization.
ThechaptershowedhowAIartmergescreativityandtechnologyinadynamicway.AsAIcontinues
topushtheboundariesofwhat’spossibleintheworldofart,evenpeoplewithouttraditionalartistic
backgroundscanexplorenewrealmsofdigitalcreativitywithtoolslikeStableDiffusion.70 CHAPTER6. ANINTRODUCTIONTOGENERATIVEART:ABEGINNER’SEXPLORATIONAppendix A
Image Demos
Thisappendixincludesvariousimagedemosthatillustratedifferentaspectsofthecontentdiscussed
inthebook.
7172 APPENDIXA. IMAGEDEMOS
FigureA.1: BirdDemo. Theseimagesshowcasegenerativemodelscreatingrealisticrepresentations
ofanimals.73
FigureA.2: CatDemo. Theseimagesshowcasegenerativemodelscreatingrealisticrepresentations
ofanimals.74 APPENDIXA. IMAGEDEMOS
FigureA.3:HouseDemo.Examplesofgenerativemodelsproducingarchitecturalandstilllifeimages
viaprompt:Beautifullakeviewvilla75
FigureA.4: FruitDemo. Examplesofgenerativemodelsproducingarchitecturalandstilllifeimages
viaprompt:VariousfruitsonthetableandFruitplatter76 APPENDIXA. IMAGEDEMOS
Figure A.5: Animation Demo 1. These frames illustrate how the model generates anima-
tions.Promt:1girl,((Sailorfuku)),brownhair,blueeyes,colorful,autumn,cumulonimbusclouds,light-
ing,bluesky,fallingleaves,flower,garden,((masterpiece)),(((bestquality))),((ultra-detailed)),((illus-
tration)),((disheveledhair))77
FigureA.6:AnimationDemo2.Theseframesillustratehowthemodelgeneratesanimations.prompt:
1girl,brownhair,greeneyes,colorful,autumn,cumulonimbusclouds,lighting,bluesky,fallingleaves,
garden78 APPENDIXA. IMAGEDEMOS
FigureA.7: AnimationDemo3. Furtherframesfromtheanimationgenerationprocess. Prompt: 1girl,
brownhair,blueeyes,colorful,autumn,cumulonimbusclouds,lighting,bluesky,fallingleaves,garden79
FigureA.8: AnimationDemo4. Furtherframesfromtheanimationgenerationprocess.Prompt:1girl,
brownhair,blueeyes,colorful,autumn,cumulonimbusclouds,lighting,bluesky,fallingleaves,garden80 APPENDIXA. IMAGEDEMOS
FigureA.9: AnimationDemo4. Furtherframesfromtheanimationgenerationprocess.Prompt:1girl,
((Sailorfuku)),brownhair,blueeyes,colorful,autumn,cumulonimbusclouds,lighting,bluesky,falling
leaves,flower,garden,((masterpiece)),(((bestquality))),((ultra-detailed)),((illustration)),((disheveled
hair))81
FigureA.10:AnimationDemo6.Thefinalframesintheanimationsequence.Prompt:1girl,((kimono)),
brownhair,blueeyes,colorful,spring,cumulonimbusclouds,lighting,bluesky,Sakura,garden,((mas-
terpiece)),(((bestquality))),((ultra-detailed)),((illustration)),((disheveledhair))82 APPENDIXA. IMAGEDEMOSBibliography
[1] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S.
Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew
Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath
Kudlur, JoshLevenberg, DanMané, RajatMonga, SherryMoore, DerekMurray, ChrisOlah, Mike
Schuster,JonathonShlens,BenoitSteiner,IlyaSutskever,KunalTalwar,PaulTucker,VincentVan-
houcke,VijayVasudevan,FernandaViégas,OriolVinyals,PeteWarden,MartinWattenberg,Martin
Wicke,YuanYu,andXiaoqiangZheng. TensorFlow: Large-scalemachinelearningonheteroge-
neoussystems,2015. Softwareavailablefromtensorflow.org.
[2] OmarA.AlghamdiandGomaaAgag. Competitiveadvantage:Alongitudinalanalysisoftheroles
ofdata-driveninnovationcapabilities,marketingagility,andmarketturbulence. JournalofRetail-
ingandConsumerServices,76:103547,2024.
[3] AlphaFoldProteinStructureDatabase. Imageofproteinstructure. https://alphafold.ebi.ac.
uk/,2024. Accessed:2024-09-22.
[4] ThePythonPackagingAuthority. pip,2023. Version23.1.2.
[5] Automatic1111. Stable diffusion webui. https://github.com/AUTOMATIC1111/
stable-diffusion-webui,2023. GitHubrepository.
[6] Rose Bain, Conor Lynch, Darren McDonnell, and Kritchai Witheephanich. An xgboost approach
forindustrialcomponentdegradationclassification. In202233rdIrishSignalsandSystemsCon-
ference(ISSC),pages1–7,2022.
[7] Chiranjib Chakraborty, Manojit Bhattacharya, Soumen Pal, and Sang-Soo Lee. From machine
learning to deep learning: Advances of the recent data-driven paradigm shift in medicine and
healthcare. CurrentResearchinBiotechnology,7:100164,2024.
[8] Li-Wen Chang, Wenlei Bao, Qi Hou, Chengquan Jiang, Ningxin Zheng, Yinmin Zhong, Xuanrun
Zhang, Zuquan Song, Ziheng Jiang, Haibin Lin, Xin Jin, and Xin Liu. Flux: Fast software-based
communicationoverlapongpusthroughkernelfusion,2024.
[9] KeyuChen,ZiqianBi,QianNiu,JunyuLiu,BenjiPeng,SenZhang,MingLiu,MingLi,XuanhePan,
JiaweiXu,JinlangWang,andPohsunFeng. Deeplearningandmachinelearning,advancingbig
dataanalyticsandmanagement:Tensorflowpretrainedmodels,2024.
[10] TianqiChenandCarlosGuestrin.Xgboost:Ascalabletreeboostingsystem.InProceedingsofthe
22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandDataMining,volume11
ofKDD’16,page785–794.ACM,August2016.
8384 BIBLIOGRAPHY
[11] Kamal Choudhary, Brian DeCost, Chi Chen, Anubhav Jain, Francesca Tavazza, Ryan Cohn,
CheolWooPark,AlokChoudhary,AnkitAgrawal,SimonJ.L.Billinge,ElizabethHolm,ShyuePing
Ong,andChrisWolverton. Recentadvancesandapplicationsofdeeplearningmethodsinmate-
rialsscience. npjComputationalMaterials,8(1):59,2022.
[12] Antonia Creswell, Tom White, Vincent Dumoulin, Kai Arulkumaran, Biswa Sengupta, and Anil A.
Bharath. Generative adversarial networks: An overview. IEEE Signal Processing Magazine,
35(1):53–65,January2018.
[13] LiDeng. Themnistdatabaseofhandwrittendigitimagesformachinelearningresearch[bestof
theweb]. IEEESignalProcessingMagazine,29(6):141–142,2012.
[14] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectionaltransformersforlanguageunderstanding,2019.
[15] JacobDevlin, Ming-WeiChang, KentonLee, andKristinaToutanova. BERT:Pre-trainingofdeep
bidirectionaltransformersforlanguageunderstanding.InJillBurstein,ChristyDoran,andThamar
Solorio,editors,Proceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAsso-
ciationforComputationalLinguistics: HumanLanguageTechnologies,Volume1(LongandShort
Papers), pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational
Linguistics.
[16] BradleyEfron,TrevorHastie,IainJohnstone,andRobertTibshirani. Leastangleregression. The
AnnalsofStatistics,32(2):407–499,2004.
[17] JoséFerreira,FernandoAlmeida,andJoséMonteiro. Buildinganeffectivedatawarehousingfor
financialsector. AutomaticControlandInformationSciences,3(1):16–25,August2017.
[18] PythonSoftwareFoundation.Pythonlanguagereference,version3.x.https://www.python.org/,
2023. Availableathttps://www.python.org/.
[19] ChenGao,YuZheng,NianLi,YinfengLi,YingrongQin,JinghuaPiao,YuhanQuan,JianxinChang,
Depeng Jin, Xiangnan He, and Yong Li. A survey of graph neural networks for recommender
systems:Challenges,methods,anddirections. ACMTrans.Recomm.Syst.,1(1),mar2023.
[20] GitHub and OpenAI. Github copilot: Your ai pair programmer. https://github.com/features/
copilot,2023. Softwaretool.
[21] Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
AaronCourville,andYoshuaBengio. Generativeadversarialnetworks,2014.
[22] GoogleDevelopers.Ganstructure[image].https://developers.google.com/machine-learning/
gan/gan_structure,2024. Accessed:2024-09-22.
[23] RossGruetzemacherandJessWhittlestone.Thetransformativepotentialofartificialintelligence.
Futures,135:102884,2022.
[24] AdityGupta,SwatiTyagi,NupurPanwar,ShellySachdeva,andUpaangSaxena.Nosqldatabases:
Criticalanalysisandcomparison. In2017InternationalConferenceonComputingandCommuni-
cationTechnologiesforSmartNation(IC3TSN),pages293–299,2017.
[25] MatthewHausknechtandPeterStone. Deeprecurrentq-learningforpartiallyobservablemdps,
2017.BIBLIOGRAPHY 85
[26] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.Deepresiduallearningforimagerecog-
nition,2015.
[27] JonathanHo,AjayJain,andPieterAbbeel. Denoisingdiffusionprobabilisticmodels,2020.
[28] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,
9:1735–80,121997.
[29] John D. Hunter. Matplotlib: A 2d graphics environment. Computing in Science & Engineering,
9(3):90–95,2007.
[30] JohnJumper,RichardEvans,AlexanderPritzel,TimGreen,MichaelFigurnov,OlafRonneberger,
KathrynTunyasuvunakool,RussBates,AugustinŽídek,AnnaPotapenko,AlexBridgland,Clemens
Meyer,SimonA.A.Kohl,AndrewJ.Ballard,AndrewCowie,BernardinoRomera-Paredes,Stanislav
Nikolov,RishubJain,JonasAdler,TrevorBack,StigPetersen,DavidReiman,EllenClancy,Michal
Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein,
David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis
Hassabis. Highlyaccurateproteinstructurepredictionwithalphafold. Nature, 596(7873):583–
589,aug2021.
[31] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,LauraGustafson,TeteXiao,
Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, and Ross Girshick. Segment
anything,2023.
[32] ChengLu,YuhaoZhou,FanBao,JianfeiChen,ChongxuanLi,andJunZhu. Dpm-solver++: Fast
solverforguidedsamplingofdiffusionprobabilisticmodels,2023.
[33] DanieleMazzeiandReshawnRamjattan. Machinelearningforindustry4.0:Asystematicreview
usingdeeplearning-basedtopicmodelling. Sensors,22(22),2022.
[34] VolodymyrMnih, KorayKavukcuoglu, DavidSilver, AlexGraves, IoannisAntonoglou, DaanWier-
stra,andMartinRiedmiller. Playingatariwithdeepreinforcementlearning,2013.
[35] Majid Niazkar, Andrea Menapace, Bruno Brentan, Reza Piraei, David Jimenez, Pranav Dhawan,
and Maurizio Righetti. Applications of xgboost in water resources engineering: A systematic
literaturereview(dec2018–may2023). EnvironmentalModelling&Software,174:105971,2024.
[36] OpenAI. Chatgpt:September2023version,2023. Largelanguagemodel.
[37] OpenAI,JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoni
Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor
Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian,
JeffBelgum,IrwanBello,JakeBerdine,GabrielBernadett-Shapiro,ChristopherBerner,LennyBog-
donoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles
Brundage,KevinButton,TrevorCai,RosieCampbell,AndrewCann,BrittanyCarey,ChelseaCarl-
son, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby
Chen,JasonChen,MarkChen,BenChess,ChesterCho,CaseyChu,HyungWonChung,DaveCum-
mings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien
Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna
Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella
Fulford, Leo Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha86 BIBLIOGRAPHY
Gontijo-Lopes,JonathanGordon,MorganGrafstein,ScottGray,RyanGreene,JoshuaGross,Shix-
iang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Jo-
hannesHeidecke,ChrisHesse,AlanHickey,WadeHickey,PeterHoeschele,BrandonHoughton,
Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, An-
gelaJiang,RogerJiang,HaozhunJin,DennyJin,ShinoJomoto,BillieJonn,HeewooJun,Tomer
Kaftan,ŁukaszKaiser,AliKamali,IngmarKanitscheider,NitishShirishKeskar,TabarakKhan,Lo-
gan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros,
Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle
Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Le-
ung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa
Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov,
YanivMarkovski, BiancaMartin, KatieMayer, AndrewMayne, BobMcGrew, ScottMayerMcKin-
ney,ChristineMcLeavey,PaulMcMillan,JakeMcNeil,DavidMedina,AalokMehta,JacobMenick,
LukeMetz,AndreyMishchenko,PamelaMishkin,VinnieMonaco,EvanMorikawa,DanielMossing,
TongMu,MiraMurati,OlegMurk,DavidMély,AshvinNair,ReiichiroNakano,RajeevNayak,Arvind
Neelakantan, RichardNgo, HyeonwooNoh, LongOuyang, CullenO’Keefe, JakubPachocki, Alex
Paino, JoePalermo, AshleyPantuliano, GiambattistaParascandolo, JoelParish, EmyParparita,
AlexPassos,MikhailPavlov,AndrewPeng,AdamPerelman,FilipedeAvilaBelbutePeres,Michael
Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong,
Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae,
AdityaRamesh,CameronRaymond,FrancisReal,KendraRimbach,CarlRoss,BobRotsted,Henri
Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather
Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jes-
sicaShieh,SarahShoker,PranavShyam,SzymonSidor,EricSigler,MaddieSimens,JordanSitkin,
KatarinaSlama,IanSohl,BenjaminSokolowsky,YangSong,NatalieStaudacher,FelipePetroski
Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil
Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-
lipeCerónUribe,AndreaVallone,ArunVijayvergiya,ChelseaVoss,CarrollWainwright,JustinJay
Wang,AlvinWang,BenWang,JonathanWard,JasonWei,CJWeinmann,AkilaWelihinda,Peter
Welinder,JiayiWeng,LilianWeng,MattWiethoff,DaveWillner,ClemensWinter,SamuelWolrich,
HannahWong,LaurenWorkman,SherwinWu,JeffWu,MichaelWu,KaiXiao,TaoXu,SarahYoo,
KevinYu,QimingYuan,WojciechZaremba,RowanZellers,ChongZhang,MarvinZhang,Shengjia
Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. Gpt-4 technical report,
2024.
[38] KeironO’SheaandRyanNash. Anintroductiontoconvolutionalneuralnetworks,2015.
[39] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
TrevorKilleen,ZemingLin,NataliaGimelshein,LucaAntiga,AlbanDesmaison,AndreasKopf,Ed-
wardYang,ZacharyDeVito,MartinRaison,AlykhanTejani,SasankChilamkurthy,BenoitSteiner,
LuFang,JunjieBai,andSoumithChintala. Pytorch: Animperativestyle,high-performancedeep
learninglibrary. AdvancesinNeuralInformationProcessingSystems,32:8024–8035,2019.
[40] FabianPedregosa,GaëlVaroquaux,AlexandreGramfort,VincentMichel,BertrandThirion,Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas,
AlexandrePassos, DavidCournapeau, MatthieuBrucher, MatthieuPerrot, andÉdouardDuches-BIBLIOGRAPHY 87
nay. Scikit-learn: Machinelearninginpython. JournalofMachineLearningResearch, 12:2825–
2830,2011.
[41] AlejandroPérez-Vereda,RamonHervas,andCarlosCanal.Digitalavatars:Aprogrammingframe-
workforpersonalizedhumaninteractionsthroughvirtualprofiles. PervasiveandMobileComput-
ing,87:101718,112022.
[42] AlecRadford,KarthikNarasimhan,TimSalimans,andIlyaSutskever. Improvinglanguageunder-
standingbygenerativepre-training. OpenAI,2018.
[43] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified,
real-timeobjectdetection,2016.
[44] GoogleResearch. Colaboratory: Collaborativedatascience. https://colab.research.google.
com/,2023.
[45] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-
resolutionimagesynthesiswithlatentdiffusionmodels,2022.
[46] IqbalH.Sarker.Deeplearning:Acomprehensiveoverviewontechniques,taxonomy,applications
andresearchdirections. SNComputerScience,2(6):420,2021. ©TheAuthor(s),underexclusive
licencetoSpringerNatureSingaporePteLtd2021.
[47] RobinM.Schmidt. Recurrentneuralnetworks(rnns):Agentleintroductionandoverview,2019.
[48] AstridSchneider,GerhardHommel,andMariaBlettner. Linearregressionanalysis: Part14ofa
series on evaluation of scientific publications. DeutschesÄrzteblattInternational, 107(44):776–
782,November2010.
[49] Hend A. Selmy, Hoda K. Mohamed, and Walaa Medhat. Big data analytics deep learning tech-
niquesandapplications:Asurvey. InformationSystems,120:102318,2024.
[50] SakibShahriarandKadhimHayawi. Let’shaveachat! aconversationwithchatgpt: Technology,
applications,andlimitations. ArtificialIntelligenceandApplications,2(1):11–20,June2023.
[51] KonstantinShvachko,HairongKuang,SanjayRadia,andRobertChansler.Thehadoopdistributed
filesystem. In2010IEEE26thSymposiumonMassStorageSystemsandTechnologies(MSST),
pages1–10,2010.
[52] YasinN.Silva,IsadoraAlmeida,andMichellQueiroz. Sql:Fromtraditionaldatabasestobigdata.
InProceedingsofthe47thACMTechnicalSymposiumonComputingScienceEducation,SIGCSE
’16,page413–418,NewYork,NY,USA,2016.AssociationforComputingMachinery.
[53] DavidSilver,JulianSchrittwieser,KarenSimonyan,IoannisAntonoglou,AjaHuang,ArthurGuez,
ThomasHubert,LucasBaker,MatthewLai,AdrianBolton,YutianChen,TimothyLillicrap,FanHui,
Laurent Sifre, George van den Driessche, Thore Graepel, and Demis Hassabis. Mastering the
gameofgowithouthumanknowledge. Nature,550(7676):354–359,2017.
[54] MohammadMustafaTaye.Understandingofmachinelearningwithdeeplearning:Architectures,
workflow,applicationsandfuturedirections. Computers,12(5),2023.
[55] CivitaiTeam. Civitai:Aimodelsharingplatform. https://civitai.com,2023.88 BIBLIOGRAPHY
[56] ComfyUITeam. Comfyui: Apowerfulandmodularstablediffusiongraphnodesystem. https:
//github.com/comfyanonymous/ComfyUI,2023. GitHubrepository.
[57] CursorTeam. Cursor: Anai-poweredcodingassistant. https://github.com/getcursor/cursor,
2023. GitHubrepository.
[58] GeminiTeam,RohanAnil,SebastianBorgeaud,Jean-BaptisteAlayrac,JiahuiYu,RaduSoricut,Jo-
hanSchalkwyk,AndrewM.Dai,AnjaHauth,KatieMillican,DavidSilver,MelvinJohnson,Ioannis
Antonoglou,JulianSchrittwieser,AmeliaGlaese,JilinChen,EmilyPitler,TimothyLillicrap,Angeliki
Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R. Barham, Tom Hennigan, Benjamin
Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer,
ElizaRutherford, EricaMoreira, KareemAyoub, MeghaGoel, JackKrawczyk, CosmoDu, EdChi,
Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, Betty Chan, Manaal Faruqui, Aliaksei Sev-
eryn,HanzhaoLin,YaGuangLi,YongCheng,AbeIttycheriah,MahdisMahdieh,MiaChen,PeiSun,
DustinTran,SumitBagri,BalajiLakshminarayanan,JeremiahLiu,AndrasOrban,FabianGüra,Hao
Zhou,XinyingSong,AurelienBoffy,HarishGanapathy,StevenZheng,HyunJeongChoe,Ágoston
Weisz,TaoZhu,YifengLu,SiddharthGopal,JarrodKahn,MaciejKula,JeffPitman,RushinShah,
EmanuelTaropa, MajdAlMerey,MartinBaeuml, ZhifengChen,LaurentElShafey,YujingZhang,
OlcanSercinoglu,GeorgeTucker,EnriquePiqueras,MaximKrikun,IainBarr,NikolaySavinov,Ivo
Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Tamara von Glehn, Lakshman Ya-
gati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, Alexandre Frechette,
CharlotteSmith,LauraCulp,LevProleev,YiLuan,XiChen,JamesLottes,NathanSchucher,Fed-
ericoLebron,AlbanRrustemi,NatalieClay,PhilCrone,TomasKocisky,JeffreyZhao,BartekPerz,
Dian Yu, Heidi Howard, Adam Bloniarz, Jack W. Rae, Han Lu, Laurent Sifre, Marcello Maggioni,
FredAlcober,DanGarrette,MeganBarnes,ShantanuThakoor,JacobAustin,GabrielBarth-Maron,
WilliamWong,RishabhJoshi,RahmaChaabouni,DeeniFatiha,ArunAhuja,GauravSinghTomar,
EvanSenter,MartinChadwick,IlyaKornakov,NithyaAttaluri,IñakiIturrate,RuiboLiu,YunxuanLi,
SarahCogan,JeremyChen,ChaoJia,ChenjieGu,QiaoZhang,JordanGrimstad,AleJakseHart-
man, XavierGarcia, ThanumalayanSankaranarayanaPillai, JacobDevlin, MichaelLaskin, Diego
deLasCasas,DashaValter,ConnieTao,LorenzoBlanco,AdriàPuigdomènechBadia,DavidRe-
itter, Mianna Chen, Jenny Brennan, Clara Rivera, Sergey Brin, Shariq Iqbal, Gabriela Surita, Jane
Labanowski,AbhiRao,StephanieWinkler,EmilioParisotto,YimingGu,KateOlszewska,RaviAd-
danki,AntoineMiech,AnnieLouis,DenisTeplyashin,GeoffBrown,ElliotCatt,JanBalaguer,Jackie
Xiang,PidongWang,ZoeAshwood,AntonBriukhov,AlbertWebson,SanjayGanapathy,SmitSang-
havi, Ajay Kannan, Ming-Wei Chang, Axel Stjerngren, Josip Djolonga, Yuting Sun, Ankur Bapna,
MatthewAitchison,PedramPejman,HenrykMichalewski,TianheYu,CindyWang,JulietteLove,
JunwhanAhn,DawnBloxwich,KehangHan,PeterHumphreys,ThibaultSellam,JamesBradbury,
VarunGodbole,SinaSamangooei,BogdanDamoc,AlexKaskasoli,SébastienM.R.Arnold,Vijay
Vasudevan, Shubham Agrawal, Jason Riesa, Dmitry Lepikhin, Richard Tanburn, Srivatsan Srini-
vasan,HyeontaekLim,SarahHodkinson,PranavShyam,JohanFerret,StevenHand,AnkushGarg,
TomLePaine, JianLi, YujiaLi, MinhGiang, AlexanderNeitz, ZaheerAbbas, SarahYork, Machel
Reid, Elizabeth Cole, Aakanksha Chowdhery, Dipanjan Das, Dominika Rogozińska, Vitaliy Niko-
laev, Pablo Sprechmann, Zachary Nado, Lukas Zilka, Flavien Prost, Luheng He, Marianne Mon-
teiro, Gaurav Mishra, Chris Welty, Josh Newlan, Dawei Jia, Miltiadis Allamanis, Clara Huiyi Hu,
Raoul de Liedekerke, Justin Gilmer, Carl Saroufim, Shruti Rijhwani, Shaobo Hou, Disha Shrivas-
tava,AnirudhBaddepudi,AlexGoldin,AdnanOzturel,AlbinCassirer,YunhanXu,DanielSohn,De-BIBLIOGRAPHY 89
vendra Sachan, Reinald Kim Amplayo, Craig Swanson, Dessie Petrova, Shashi Narayan, Arthur
Guez,SiddharthaBrahma,JessicaLandon,MiteyanPatel,RuizheZhao,KevinVillela,LuyuWang,
Wenhao Jia, Matthew Rahtz, Mai Giménez, Legg Yeung, James Keeling, Petko Georgiev, Diana
Mincu, Boxi Wu, Salem Haykal, Rachel Saputro, Kiran Vodrahalli, James Qin, Zeynep Cankara,
AbhanshuSharma,NickFernando,WillHawkins,BehnamNeyshabur,SolomonKim,AdrianHut-
ter,PriyankaAgrawal,AlexCastro-Ros,GeorgevandenDriessche,TaoWang,FanYang,Shuoyiin
Chang,PaulKomarek,RossMcIlroy,MarioLučić,GuodongZhang,WaelFarhan,MichaelSharman,
PaulNatsev,PaulMichel,YaminiBansal,SiyuanQiao,KrisCao,SiamakShakeri,ChristinaButter-
field, Justin Chung, Paul Kishan Rubenstein, Shivani Agrawal, Arthur Mensch, Kedar Soparkar,
KarelLenc,TimothyChung,AedanPope,LorenMaggiore,JackieKay,PriyaJhakra,ShiboWang,
Joshua Maynez, Mary Phuong, Taylor Tobin, Andrea Tacchetti, Maja Trebacz, Kevin Robinson,
YashKatariya,SebastianRiedel,PaigeBailey,KefanXiao,NimeshGhelani,LoraAroyo,Ambrose
Slone,NeilHoulsby,XuehanXiong,ZhenYang,ElenaGribovskaya,JonasAdler,MateoWirth,Lisa
Lee,MusicLi,ThaisKagohara,JayPavagadhi,SophieBridgers,AnnaBortsova,SanjayGhemawat,
ZafaraliAhmed,TianqiLiu,RichardPowell,VijayBolina,MarikoIinuma,PolinaZablotskaia,James
Besley,Da-WoonChung,TimothyDozat,RamonaComanescu,XianceSi,JeremyGreer,Guolong
Su,MartinPolacek,RaphaëlLopezKaufman,SimonTokumine,HexiangHu,ElenaBuchatskaya,
YingjieMiao,MohamedElhawaty,AdityaSiddhant,NenadTomasev,JinweiXing,ChristinaGreer,
HelenMiller,ShereenAshraf,AurkoRoy,ZizhaoZhang,AdaMa,AngelosFilos,MilosBesta,Rory
Blevins, Ted Klimenko, Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu, Oscar Chang, Mantas Pa-
jarskas, Carrie Muir, Vered Cohen, Charline Le Lan, Krishna Haridasan, Amit Marathe, Steven
Hansen, Sholto Douglas, Rajkumar Samuel, Mingqiu Wang, Sophia Austin, Chang Lan, Jiepu
Jiang, Justin Chiu, Jaime Alonso Lorenzo, Lars Lowe Sjösund, Sébastien Cevey, Zach Gleicher,
ThiAvrahami,AnudhyanBoral,HansaSrinivasan,VittorioSelo,RhysMay,KonstantinosAisopos,
Léonard Hussenot, Livio Baldini Soares, Kate Baumli, Michael B. Chang, Adrià Recasens, Ben
Caine, AlexanderPritzel, FilipPavetic, FabioPardo, AnitaGergely, JustinFrye, VinayRamasesh,
DanHorgan,KartikeyaBadola,NoraKassner,SubhrajitRoy,EthanDyer,VíctorCamposCampos,
AlexTomala,YunhaoTang,DaliaElBadawy,ElspethWhite,BasilMustafa,OranLang,Abhishek
Jindal,SharadVikram,ZhitaoGong,SergiCaelles,RossHemsley,GregoryThornton,Fangxiaoyu
Feng,WojciechStokowiec,CeZheng,PhoebeThacker,ÇağlarÜnlü,ZhishuaiZhang,Mohammad
Saleh,JamesSvensson,MaxBileschi,PiyushPatil,AnkeshAnand,RomanRing,KaterinaTsihlas,
ArpiVezer,MarcoSelvi,TobyShevlane,MikelRodriguez,TomKwiatkowski,SamiraDaruki,Keran
Rong, Allan Dafoe, Nicholas FitzGerald, Keren Gu-Lemberg, Mina Khan, Lisa Anne Hendricks,
Marie Pellat, Vladimir Feinberg, James Cobon-Kerr, Tara Sainath, Maribeth Rauh, Sayed Hadi
Hashemi,RichardIves,YanaHasson,EricNoland,YuanCao,NathanByrd,LeHou,QingzeWang,
Thibault Sottiaux, Michela Paganini, Jean-Baptiste Lespiau, Alexandre Moufarek, Samer Has-
san, Kaushik Shivakumar, Joost van Amersfoort, Amol Mandhane, Pratik Joshi, Anirudh Goyal,
Matthew Tung, Andrew Brock, Hannah Sheahan, Vedant Misra, Cheng Li, Nemanja Rakićević,
Mostafa Dehghani, Fangyu Liu, Sid Mittal, Junhyuk Oh, Seb Noury, Eren Sezener, Fantine Huot,
MatthewLamm,NicolaDeCao,CharlieChen,SidharthMudgal,RominaStella,KevinBrooks,Gau-
tamVasudevan,ChenxiLiu,MainakChain,NiveditaMelinkeri,AaronCohen,VenusWang,Kristie
Seymore,SergeyZubkov,RahulGoel,SummerYue,SaiKrishnakumaran,BrianAlbert,NateHur-
ley,MotokiSano,AnhadMohananey,JonahJoughin,EgorFilonov,TomaszKępa,YomnaEldawy,
JiawernLim,RahulRishi,ShirinBadiezadegan,TaylorBos,JerryChang,SanilJain,SriGayatriSun-
daraPadmanabhan,SubhaPuttagunta,KalpeshKrishna,LeslieBaker,NorbertKalb,VamsiBeda-90 BIBLIOGRAPHY
pudi,AdamKurzrok,ShuntongLei,AnthonyYu,OrenLitvin,XiangZhou,ZhichunWu,SamSobell,
AndreaSiciliano,AlanPapir,RobbyNeale,JonasBragagnolo,TejToor,TinaChen,ValentinAnklin,
FeiranWang,RichieFeng,MiladGholami,KevinLing,LijuanLiu,JulesWalter,HamidMoghaddam,
ArunKishore,JakubAdamek,TylerMercado,JonathanMallinson,SiddhinitaWandekar,Stephen
Cagle,EranOfek,GuillermoGarrido,ClemensLombriser,MaksimMukha,BotuSun,HafeezulRah-
manMohammad,JosipMatak,YadiQian,VikasPeswani,PawelJanus,QuanYuan,LeifSchelin,
OanaDavid,AnkurGarg,YifanHe,OleksiiDuzhyi,AntonÄlgmyr,TimothéeLottaz,QiLi,VikasYa-
dav,LuyaoXu,AlexChinien,RakeshShivanna,AleksandrChuklin,JosieLi,CarrieSpadine,Travis
Wolfe, Kareem Mohamed, Subhabrata Das, Zihang Dai, Kyle He, Daniel von Dincklage, Shyam
Upadhyay, Akanksha Maurya, Luyan Chi, Sebastian Krause, Khalid Salama, Pam G Rabinovitch,
PavanKumarReddyM,AarushSelvan,MikhailDektiarev,GolnazGhiasi,ErdemGuven,Himanshu
Gupta,BoyiLiu,DeepakSharma,IdanHeimlichShtacher,ShachiPaul,OscarAkerlund,François-
XavierAubet,TerryHuang,ChenZhu,EricZhu,ElicoTeixeira,MatthewFritze,FrancescoBertolini,
Liana-EleonoraMarinescu,MartinBölle,DominikPaulus,KhyattiGupta,TejasiLatkar,MaxChang,
JasonSanders,RoopaWilson,XueweiWu,Yi-XuanTan,LamNguyenThiet,TulseeDoshi,SidLall,
Swaroop Mishra, Wanming Chen, Thang Luong, Seth Benjamin, Jasmine Lee, Ewa Andrejczuk,
Dominik Rabiej, Vipul Ranjan, Krzysztof Styrc, Pengcheng Yin, Jon Simon, Malcolm Rose Har-
riott,MuditBansal,AlexeiRobsky,GeoffBacon,DavidGreene,DaniilMirylenka,ChenZhou,Obaid
Sarvana,AbhimanyuGoyal,SamuelAndermatt,PatrickSiegler,BenHorn,AssafIsrael,Francesco
Pongetti,Chih-Wei"Louis"Chen,MarcoSelvatici,PedroSilva,KathieWang,JacksonTolins,Kelvin
Guu, Roey Yogev, Xiaochen Cai, Alessandro Agostini, Maulik Shah, Hung Nguyen, Noah Ó Don-
naile, Sébastien Pereira, Linda Friso, Adam Stambler, Adam Kurzrok, Chenkai Kuang, Yan Ro-
manikhin,MarkGeller,ZJYan,KaneJang,Cheng-ChunLee,WojciechFica,EricMalmi,QijunTan,
Dan Banica, Daniel Balle, Ryan Pham, Yanping Huang, Diana Avram, Hongzhi Shi, Jasjot Singh,
ChrisHidey,NiharikaAhuja,PranabSaxena,DanDooley,SrividyaPranaviPotharaju,EileenO’Neill,
Anand Gokulchandran, Ryan Foley, Kai Zhao, Mike Dusenberry, Yuan Liu, Pulkit Mehta, Ragha
Kotikalapudi,ChalenceSafranek-Shrader,AndrewGoodman,JoshuaKessinger,EranGloben,Pra-
teekKolhar,ChrisGorgolewski,AliIbrahim,YangSong,AliEichenbaum,ThomasBrovelli,Sahitya
Potluri,PreethiLahoti,CipBaetu,AliGhorbani,CharlesChen,AndyCrawford,ShaliniPal,Mukund
Sridhar,PetruGurita,AsierMujika,IgorPetrovski,Pierre-LouisCedoz,ChenmeiLi,ShiyuanChen,
NiccolòDalSanto,SiddharthGoyal,JiteshPunjabi,KarthikKappaganthu,ChesterKwak,PallaviLV,
SarmishtaVelury,HimadriChoudhury,JamieHall,PremalShah,RicardoFigueira,MattThomas,
Minjie Lu, Ting Zhou, Chintu Kumar, Thomas Jurdi, Sharat Chikkerur, Yenai Ma, Adams Yu, Soo
Kwak,VictorÄhdel,SujeevanRajayogam,TravisChoma,FeiLiu,AdityaBarua,ColinJi,JiHoPark,
VincentHellendoorn,AlexBailey,TaylanBilal,HuanjieZhou,MehrdadKhatir,CharlesSutton,Wo-
jciechRzadkowski,FionaMacintosh,KonstantinShagin,PaulMedina,ChenLiang,JinjingZhou,
Pararth Shah, Yingying Bi, Attila Dankovics, Shipra Banga, Sabine Lehmann, Marissa Bredesen,
ZifanLin,JohnEricHoffmann,JonathanLai,RaynaldChung,KaiYang,NihalBalani,ArthurBražin-
skas,AndreiSozanschi,MatthewHayes,HéctorFernándezAlcalde,PeterMakarov,WillChen,An-
tonioStella,LiselotteSnijders,MichaelMandl,AnteKärrman,PawełNowak,XinyiWu,AlexDyck,
KrishnanVaidyanathan, RaghavenderR,JessicaMallet, MitchRudominer, EricJohnston, Sushil
Mittal,AkhilUdathu,JanaraChristensen,VishalVerma,ZachIrving,AndreasSantucci,Gamaleldin
Elsayed,ElnazDavoodi,MarinGeorgiev,IanTenney,NanHua,GeoffreyCideron,EdouardLeurent,
Mahmoud Alnahlawi, Ionut Georgescu, Nan Wei, Ivy Zheng, Dylan Scandinaro, Heinrich Jiang,
JasperSnoek,MukundSundararajan,XuezhiWang,ZackOntiveros,ItayKaro,JeremyCole,VinuBIBLIOGRAPHY 91
Rajashekhar, Lara Tumeh, Eyal Ben-David, Rishub Jain, Jonathan Uesato, Romina Datta, Oskar
Bunyan,ShimuWu,JohnZhang,PiotrStanczyk,YeZhang,DavidSteiner,SubhajitNaskar,Michael
Azzam, Matthew Johnson, Adam Paszke, Chung-Cheng Chiu, Jaume Sanchez Elias, Afroz Mo-
hiuddin, Faizan Muhammad, Jin Miao, Andrew Lee, Nino Vieillard, Jane Park, Jiageng Zhang,
JeffStanway,DrewGarmon,AbhijitKarmarkar,ZheDong,JongLee,AviralKumar,LuoweiZhou,
JonathanEvens,WilliamIsaac,GeoffreyIrving,EdwardLoper,MichaelFink,IshaArkatkar,Nanxin
Chen, IzhakShafran, IvanPetrychenko, ZheChen, JohnsonJia, AnselmLevskaya, ZhenkaiZhu,
PeterGrabowski,YuMao,AlbertoMagni,KaishengYao,JavierSnaider,NormanCasagrande,Evan
Palmer,PaulSuganthan,AlfonsoCastaño,IreneGiannoumis,WooyeolKim,MikołajRybiński,Ash-
winSreevatsa,JenniferPrendki,DavidSoergel,AdrianGoedeckemeyer,WilliGierke,MohsenJa-
fari,MeenuGaba,JeremyWiesner,DianaGageWright,YawenWei,HarshaVashisht,YanaKulizh-
skaya,JayHoover,MaigoLe,LuLi,ChimezieIwuanyanwu,LuLiu,KevinRamirez,AndreyKhorlin,
AlbertCui,TianLIN,MarcusWu,RicardoAguilar,KeithPallo,AbhishekChakladar,GingerPerng,
Elena Allica Abellan, Mingyang Zhang, Ishita Dasgupta, Nate Kushman, Ivo Penchev, Alena Re-
pina,XihuiWu,TomvanderWeide,PriyaPonnapalli,CarolineKaplan,JiriSimsa,ShuangfengLi,
OlivierDousse,FanYang,JeffPiper,NathanIe,RamaPasumarthi,NathanLintz,AnithaVijayaku-
mar, Daniel Andor, Pedro Valenzuela, Minnie Lui, Cosmin Paduraru, Daiyi Peng, Katherine Lee,
ShuyuanZhang,SomerGreene,DucDungNguyen,PaulaKurylowicz,CassidyHardin,LucasDixon,
Lili Janzer, Kiam Choo, Ziqiang Feng, Biao Zhang, Achintya Singhal, Dayou Du, Dan McKinnon,
NatashaAntropova,TolgaBolukbasi,OrgadKeller,DavidReid,DanielFinchelstein,MariaAbiRaad,
Remi Crocker, Peter Hawkins, Robert Dadashi, Colin Gaffney, Ken Franko, Anna Bulanova, Rémi
Leblond, Shirley Chung, Harry Askham, Luis C. Cobo, Kelvin Xu, Felix Fischer, Jun Xu, Christina
Sorokin,ChrisAlberti,Chu-ChengLin,ColinEvans,AlekDimitriev,HannahForbes,DylanBanarse,
ZoraTung,MarkOmernick,ColtonBishop,RachelSterneck,RohanJain,JiaweiXia,EhsanAmid,
FrancescoPiccinno,XingyuWang,PraseemBanzal,DanielJ.Mankowitz,AlexPolozov,Victoria
Krakovna, Sasha Brown, MohammadHossein Bateni, Dennis Duan, Vlad Firoiu, Meghana Tho-
takuri,TomNatan,MatthieuGeist,SertanGirgin,HuiLi,JiayuYe,OfirRoval,ReikoTojo,Michael
Kwong,JamesLee-Thorp,ChristopherYew,DanilaSinopalnikov,SabelaRamos,JohnMellor,Ab-
hishekSharma,KathyWu,DavidMiller,NicolasSonnerat,DenisVnukov,RoryGreig,JenniferBeat-
tie, EmilyCaveness, LibinBai, JulianEisenschlos, AlexKorchemniy, TomyTsai, MimiJasarevic,
Weize Kong, Phuong Dao, Zeyu Zheng, Frederick Liu, Fan Yang, Rui Zhu, Tian Huey Teh, Jason
Sanmiya, Evgeny Gladchenko, Nejc Trdin, Daniel Toyama, Evan Rosen, Sasan Tavakkol, Linting
Xue,ChenElkind,OliverWoodman,JohnCarpenter,GeorgePapamakarios,RupertKemp,Sushant
Kafle, Tanya Grunina, Rishika Sinha, Alice Talbert, Diane Wu, Denese Owusu-Afriyie, Cosmo Du,
Chloe Thornton, Jordi Pont-Tuset, Pradyumna Narayana, Jing Li, Saaber Fatehi, John Wieting,
OmarAjmeri,BenignoUria,YeongilKo,LauraKnight,AmélieHéliou,NingNiu,ShaneGu,Chenxi
Pang,YeqingLi,NirLevine,ArielStolovich,RebecaSantamaria-Fernandez,SonamGoenka,Wenny
Yustalim, RobinStrudel, AliElqursh, CharlieDeck, HyoLee, ZonglinLi, KyleLevin, RaphaelHoff-
mann,DanHoltmann-Rice,OlivierBachem,ShoArora,ChristyKoh,SoheilHassasYeganeh,Siim
Põder,MukarramTariq,YanhuaSun,LucianIonita,MojtabaSeyedhosseini,PouyaTafti,ZhiyuLiu,
AnmolGulati,JasmineLiu,XinyuYe,BartChrzaszcz,LilyWang,NikhilSethi,TianrunLi,BenBrown,
Shreya Singh, Wei Fan, Aaron Parisi, Joe Stanton, Vinod Koverkathu, Christopher A. Choquette-
Choo,YunjieLi,TJLu,AbeIttycheriah,PrakashShroff,ManiVaradarajan,SanazBahargam,Rob
Willoughby, DavidGaddy, GuillaumeDesjardins, MarcoCornero, BronaRobenek, BhavishyaMit-
tal, Ben Albrecht, Ashish Shenoy, Fedor Moiseev, Henrik Jacobsson, Alireza Ghaffarkhah, Mor-92 BIBLIOGRAPHY
ganeRivière,AlannaWalton,ClémentCrepy,AliciaParrish,ZongweiZhou,ClementFarabet,Carey
Radebaugh,PraveenSrinivasan,ClaudiavanderSalm,AndreasFidjeland,SalvatoreScellato,Eri
Latorre-Chimoto,HannaKlimczak-Plucińska,DavidBridson,DariodeCesare,TomHudson,Pier-
maria Mendolicchio, Lexi Walker, Alex Morris, Matthew Mauger, Alexey Guseynov, Alison Reid,
SethOdoom,LuciaLoher,VictorCotruta,MadhaviYenugula,DominikGrewe,AnastasiaPetrushk-
ina, Tom Duerig, Antonio Sanchez, Steve Yadlowsky, Amy Shen, Amir Globerson, Lynette Webb,
SahilDua,DongLi,SuryaBhupatiraju,DanHurt,HaroonQureshi,AnanthAgarwal,TomerShani,
MatanEyal,AnujKhare,ShreyasRammohanBelle,LeiWang,ChetanTekur,MihirSanjayKale,Jin-
liangWei,RuoxinSang,BrennanSaeta,TylerLiechty,YiSun,YaoZhao,StephanLee,PanduNayak,
DougFritz,ManishReddyVuyyuru,JohnAslanides,NidhiVyas,MartinWicke,XiaoMa,EvgeniiEl-
tyshev, Nina Martin, Hardie Cate, James Manyika, Keyvan Amiri, Yelin Kim, Xi Xiong, Kai Kang,
FlorianLuisier,NileshTripuraneni,DavidMadras,MandyGuo,AustinWaters,OliverWang,Joshua
Ainslie,JasonBaldridge,HanZhang,GarimaPruthi,JakobBauer,FengYang,RihamMansour,Ja-
sonGelman,YangXu,GeorgePolovets,JiLiu,HonglongCai,WarrenChen,XiangHaiSheng,Emily
Xue,SherjilOzair,ChristofAngermueller,XiaoweiLi,AnoopSinha,WeirenWang,JuliaWiesinger,
EmmanouilKoukoumidis,YuanTian,AnandIyer,MadhuGurumurthy,MarkGoldenson,Parashar
Shah,MKBlake,HongkunYu,AnthonyUrbanowicz,JennimariaPalomaki,ChrisanthaFernando,
KenDurden,HarshMehta,NikolaMomchev,ElaheRahimtoroghi,MariaGeorgaki,AmitRaul,Se-
bastianRuder,MorganRedshaw,JinhyukLee,DennyZhou,KomalJalan,DinghuaLi,BlakeHecht-
man, ParkerSchuh, MiladNasr, KieranMilan, VladimirMikulik, JulianaFranco, TimGreen, Nam
Nguyen,JoeKelley,AromaMahendru,AndreaHu,JoshuaHowland,BenVargas,JeffreyHui,Kshi-
tij Bansal, Vikram Rao, Rakesh Ghiya, Emma Wang, Ke Ye, Jean Michel Sarr, Melanie Moranski
Preston, Madeleine Elish, Steve Li, Aakash Kaku, Jigar Gupta, Ice Pasupat, Da-Cheng Juan, Mi-
lanSomeswar,TejviM.,XinyunChen,AidaAmini,AlexFabrikant,EricChu,XuanyiDong,Amruta
Muthal, Senaka Buthpitiya, Sarthak Jauhari, Nan Hua, Urvashi Khandelwal, Ayal Hitron, Jie Ren,
Larissa Rinaldi, Shahar Drath, Avigail Dabush, Nan-Jiang Jiang, Harshal Godhia, Uli Sachs, An-
thony Chen, Yicheng Fan, Hagai Taitelbaum, Hila Noga, Zhuyun Dai, James Wang, Chen Liang,
JennyHamer,Chun-SungFerng,ChenelElkind,AvielAtias,PaulinaLee,VítListík,MathiasCarlen,
JanvandeKerkhof,MarcinPikus,KrunoslavZaher,PaulMüller,SashaZykova,RichardStefanec,
Vitaly Gatsko, Christoph Hirnschall, Ashwin Sethi, Xingyu Federico Xu, Chetan Ahuja, Beth Tsai,
AncaStefanoiu,BoFeng,KeshavDhandhania,ManishKatyal,AkshayGupta,AtharvaParulekar,
Divya Pitta, Jing Zhao, Vivaan Bhatia, Yashodha Bhavnani, Omar Alhadlaq, Xiaolin Li, Peter Da-
nenberg, Dennis Tu, Alex Pine, Vera Filippova, Abhipso Ghosh, Ben Limonchik, Bhargava Urala,
Chaitanya Krishna Lanka, Derik Clive, Yi Sun, Edward Li, Hao Wu, Kevin Hongtongsak, Ianna Li,
KalindThakkar,KuanyshOmarov,KushalMajmundar,MichaelAlverson,MichaelKucharski,Mo-
hakPatel,MuditJain,MaksimZabelin,PaoloPelagatti,RohanKohli,SaurabhKumar,JosephKim,
Swetha Sankar, Vineet Shah, Lakshmi Ramachandruni, Xiangkai Zeng, Ben Bariach, Laura Wei-
dinger,TuVu,AlekAndreev,AntoineHe,KevinHui,SheleemKashem,AmarSubramanya,Sissie
Hsiao,DemisHassabis,KorayKavukcuoglu,AdamSadovsky,QuocLe,TrevorStrohman,Yonghui
Wu,SlavPetrov,JeffreyDean,andOriolVinyals. Gemini: Afamilyofhighlycapablemultimodal
models,2024.
[59] Geospy.aiTeam. Geospy.ai:Geospatialintelligenceplatform. https://geospy.ai,2023.
[60] JuanTerven, Diana-MargaritaCórdova-Esparza, andJulio-AlejandroRomero-González. Acom-
prehensivereviewofyoloarchitecturesincomputervision: Fromyolov1toyolov8andyolo-nas.BIBLIOGRAPHY 93
MachineLearningandKnowledgeExtraction,5(4):1680–1716,November2023.
[61] YuanyuanTian. Theworldofgraphdatabasesfromanindustryperspective,2022.
[62] Ultralytics. Yolov8:State-of-the-artobjectdetectionmodels. https://github.com/ultralytics/
ultralytics,2023. Version8.0.
[63] Hado van Hasselt, Arthur Guez, and David Silver. Deep reinforcement learning with double q-
learning,2015.
[64] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,
LukaszKaiser,andIlliaPolosukhin. Attentionisallyouneed,2023.
[65] LauraVeldkamp. ValuingDataasanAsset*. ReviewofFinance,27(5):1545–1562,012023.
[66] Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan,
YueqiSong,BowenLi,JaskiratSingh,HoangH.Tran,FuqiangLi,RenMa,MingzhangZheng,Bill
Qian,YanjunShao,NiklasMuennighoff,YizheZhang,BinyuanHui,JunyangLin,RobertBrennan,
HaoPeng,HengJi,andGrahamNeubig.Opendevin:Anopenplatformforaisoftwaredevelopers
asgeneralistagents,2024.
[67] ZiyuWang,TomSchaul,MatteoHessel,HadovanHasselt,MarcLanctot,andNandodeFreitas.
Duelingnetworkarchitecturesfordeepreinforcementlearning,2016.
[68] MichaelWaskom. Seaborn:Statisticaldatavisualization,2021. Version0.11.2.
[69] MichaelWaskom.Pythontipsdataset.https://github.com/mwaskom/seaborn-data,2023.Avail-
ableintheSeaborn-datarepository.
[70] ThomasWolf,LysandreDebut,VictorSanh,JulienChaumond,ClementDelangue,AnthonyMoi,
Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von
Platen,ClaraMa,YacineJernite,JulienPlu,CanwenXu,TevenLeScao,SylvainGugger,Mariama
Drame, Quentin Lhoest, and Alexander Rush. Transformers: State-of-the-art natural language
processing. In Qun Liu and David Schlangen, editors, Proceedings of the 2020 Conference on
EmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations,pages38–45,Online,
October2020.AssociationforComputationalLinguistics.
[71] Gokul Yenduri, Ramalingam M, Chemmalar Selvi G, Supriya Y, Gautam Srivastava, Praveen Ku-
marReddyMaddikunta,DeeptiRajG,RutvijHJhaveri,PrabadeviB,WeizhengWang,AthanasiosV.
Vasilakos,andThippaReddyGadekallu.Generativepre-trainedtransformer:Acomprehensivere-
viewonenablingtechnologies,potentialapplications,emergingchallenges,andfuturedirections,
2023.
[72] MateiZaharia, MosharafChowdhury, MichaelJ.Franklin, ScottShenker, andIonStoica. Spark:
clustercomputingwithworkingsets.InProceedingsofthe2ndUSENIXConferenceonHotTopics
inCloudComputing,HotCloud’10,page10,USA,2010.USENIXAssociation.