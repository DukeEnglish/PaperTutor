[
    {
        "title": "Optimizing Calibration by Gaining Aware of Prediction Correctness",
        "authors": "Yuchi LiuLei WangYuli ZouJames ZouLiang Zheng",
        "links": "http://arxiv.org/abs/2404.13016v1",
        "entry_id": "http://arxiv.org/abs/2404.13016v1",
        "pdf_url": "http://arxiv.org/pdf/2404.13016v1",
        "summary": "Model calibration aims to align confidence with prediction correctness. The\nCross-Entropy CE) loss is widely used for calibrator training, which enforces\nthe model to increase confidence on the ground truth class. However, we find\nthe CE loss has intrinsic limitations. For example, for a narrow\nmisclassification, a calibrator trained by the CE loss often produces high\nconfidence on the wrongly predicted class (e.g., a test sample is wrongly\nclassified and its softmax score on the ground truth class is around 0.4),\nwhich is undesirable. In this paper, we propose a new post-hoc calibration\nobjective derived from the aim of calibration. Intuitively, the proposed\nobjective function asks that the calibrator decrease model confidence on\nwrongly predicted samples and increase confidence on correctly predicted\nsamples. Because a sample itself has insufficient ability to indicate\ncorrectness, we use its transformed versions (e.g., rotated, greyscaled and\ncolor-jittered) during calibrator training. Trained on an in-distribution\nvalidation set and tested with isolated, individual test samples, our method\nachieves competitive calibration performance on both in-distribution and\nout-of-distribution test sets compared with the state of the art. Further, our\nanalysis points out the difference between our method and commonly used\nobjectives such as CE loss and mean square error loss, where the latters\nsometimes deviates from the calibration aim.",
        "updated": "2024-04-19 17:25:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.13016v1"
    },
    {
        "title": "Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling",
        "authors": "Grigory BartoshDmitry VetrovChristian A. Naesseth",
        "links": "http://arxiv.org/abs/2404.12940v1",
        "entry_id": "http://arxiv.org/abs/2404.12940v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12940v1",
        "summary": "Conventional diffusion models typically relies on a fixed forward process,\nwhich implicitly defines complex marginal distributions over latent variables.\nThis can often complicate the reverse process' task in learning generative\ntrajectories, and results in costly inference for diffusion models. To address\nthese limitations, we introduce Neural Flow Diffusion Models (NFDM), a novel\nframework that enhances diffusion models by supporting a broader range of\nforward processes beyond the fixed linear Gaussian. We also propose a novel\nparameterization technique for learning the forward process. Our framework\nprovides an end-to-end, simulation-free optimization objective, effectively\nminimizing a variational upper bound on the negative log-likelihood.\nExperimental results demonstrate NFDM's strong performance, evidenced by\nstate-of-the-art likelihood estimation. Furthermore, we investigate NFDM's\ncapacity for learning generative dynamics with specific characteristics, such\nas deterministic straight lines trajectories. This exploration underscores\nNFDM's versatility and its potential for a wide range of applications.",
        "updated": "2024-04-19 15:10:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12940v1"
    },
    {
        "title": "Probabilistic-Numeric SMC Sampling for Bayesian Nonlinear System Identification in Continuous Time",
        "authors": "Joe D. LongbottomMax D. ChampneysTimothy J. Rogers",
        "links": "http://arxiv.org/abs/2404.12923v1",
        "entry_id": "http://arxiv.org/abs/2404.12923v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12923v1",
        "summary": "In engineering, accurately modeling nonlinear dynamic systems from data\ncontaminated by noise is both essential and complex. Established Sequential\nMonte Carlo (SMC) methods, used for the Bayesian identification of these\nsystems, facilitate the quantification of uncertainty in the parameter\nidentification process. A significant challenge in this context is the\nnumerical integration of continuous-time ordinary differential equations\n(ODEs), crucial for aligning theoretical models with discretely sampled data.\nThis integration introduces additional numerical uncertainty, a factor that is\noften over looked. To address this issue, the field of probabilistic numerics\ncombines numerical methods, such as numerical integration, with probabilistic\nmodeling to offer a more comprehensive analysis of total uncertainty. By\nretaining the accuracy of classical deterministic methods, these probabilistic\napproaches offer a deeper understanding of the uncertainty inherent in the\ninference process. This paper demonstrates the application of a probabilistic\nnumerical method for solving ODEs in the joint parameter-state identification\nof nonlinear dynamic systems. The presented approach efficiently identifies\nlatent states and system parameters from noisy measurements. Simultaneously\nincorporating probabilistic solutions to the ODE in the identification\nchallenge. The methodology's primary advantage lies in its capability to\nproduce posterior distributions over system parameters, thereby representing\nthe inherent uncertainties in both the data and the identification process.",
        "updated": "2024-04-19 14:52:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12923v1"
    },
    {
        "title": "A Guide to Feature Importance Methods for Scientific Inference",
        "authors": "Fiona Katharina EwaldLudwig BothmannMarvin N. WrightBernd BischlGiuseppe CasalicchioGunnar König",
        "links": "http://arxiv.org/abs/2404.12862v1",
        "entry_id": "http://arxiv.org/abs/2404.12862v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12862v1",
        "summary": "While machine learning (ML) models are increasingly used due to their high\npredictive power, their use in understanding the data-generating process (DGP)\nis limited. Understanding the DGP requires insights into feature-target\nassociations, which many ML models cannot directly provide, due to their opaque\ninternal mechanisms. Feature importance (FI) methods provide useful insights\ninto the DGP under certain conditions. Since the results of different FI\nmethods have different interpretations, selecting the correct FI method for a\nconcrete use case is crucial and still requires expert knowledge. This paper\nserves as a comprehensive guide to help understand the different\ninterpretations of FI methods. Through an extensive review of FI methods and\nproviding new proofs regarding their interpretation, we facilitate a thorough\nunderstanding of these methods and formulate concrete recommendations for\nscientific inference. We conclude by discussing options for FI uncertainty\nestimation and point to directions for future research aiming at full\nstatistical inference from black-box ML models.",
        "updated": "2024-04-19 13:01:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12862v1"
    },
    {
        "title": "Sample-efficient Learning of Infinite-horizon Average-reward MDPs with General Function Approximation",
        "authors": "Jianliang HeHan ZhongZhuoran Yang",
        "links": "http://arxiv.org/abs/2404.12648v1",
        "entry_id": "http://arxiv.org/abs/2404.12648v1",
        "pdf_url": "http://arxiv.org/pdf/2404.12648v1",
        "summary": "We study infinite-horizon average-reward Markov decision processes (AMDPs) in\nthe context of general function approximation. Specifically, we propose a novel\nalgorithmic framework named Local-fitted Optimization with OPtimism (LOOP),\nwhich incorporates both model-based and value-based incarnations. In\nparticular, LOOP features a novel construction of confidence sets and a\nlow-switching policy updating scheme, which are tailored to the average-reward\nand function approximation setting. Moreover, for AMDPs, we propose a novel\ncomplexity measure -- average-reward generalized eluder coefficient (AGEC) --\nwhich captures the challenge of exploration in AMDPs with general function\napproximation. Such a complexity measure encompasses almost all previously\nknown tractable AMDP models, such as linear AMDPs and linear mixture AMDPs, and\nalso includes newly identified cases such as kernel AMDPs and AMDPs with\nBellman eluder dimensions. Using AGEC, we prove that LOOP achieves a sublinear\n$\\tilde{\\mathcal{O}}(\\mathrm{poly}(d, \\mathrm{sp}(V^*)) \\sqrt{T\\beta} )$\nregret, where $d$ and $\\beta$ correspond to AGEC and log-covering number of the\nhypothesis class respectively, $\\mathrm{sp}(V^*)$ is the span of the optimal\nstate bias function, $T$ denotes the number of steps, and $\\tilde{\\mathcal{O}}\n(\\cdot) $ omits logarithmic factors. When specialized to concrete AMDP models,\nour regret bounds are comparable to those established by the existing\nalgorithms designed specifically for these special cases. To the best of our\nknowledge, this paper presents the first comprehensive theoretical framework\ncapable of handling nearly all AMDPs.",
        "updated": "2024-04-19 06:24:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.12648v1"
    }
]