NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
DATA ALIGNMENT FOR ZERO-SHOT CONCEPT GENER-
ATION IN DERMATOLOGY AI
SohamGadgil∗,MahtabBigverdi∗
PaulG.AllenSchoolofComputerScienceandEngineering
UniversityofWashington
{sgadgil,mahtab}@cs.washington.edu
ABSTRACT
AIindermatologyisevolvingatarapidpacebutthemajorlimitationtotraining
trustworthyclassifiersisthescarcityofdatawithground-truthconceptlevellabels,
whicharemeta-labelssemanticallymeaningfultohumans(Lietal.,2019). Foun-
dationmodelslikeCLIP(Radfordetal.,2021)providingzero-shotcapabilities
canhelpalleviatethischallengebyleveragingvastamountsofimage-captionpairs
available on the internet. CLIP can be fine-tuned using domain specific image-
captionpairstoimproveclassificationperformance. However,CLIP’spre-training
data is not well-aligned with the medical jargon that clinicians use to perform
diagnoses. The development of large language models (LLMs) in recent years
hasledtothepossibilityofleveragingtheexpressivenatureofthesemodelsto
generaterichtext. Ourgoalistousethesemodelstogeneratecaptiontextthat
alignswellwithboththeclinicallexiconandwiththenaturalhumanlanguageused
inCLIP’spre-trainingdata. StartingwithcaptionsusedforimagesinPubMed
articles(Kimetal.,2023),weextendthembypassingtherawcaptionsthrough
anLLMfine-tunedonthefield’sseveraltextbooks. Wefindthatusingcaptions
generatedbyanexpressivefine-tunedLLMlikeGPT-3.5improvesdownstream
zero-shotconceptclassificationperformance.
1 INTRODUCTION
In dermatology, for performing a diagnosis, dermatologists often use concepts, which refer to
a clinical lexicon that is used to describe skin disease findings in the dermoscopic images. For
example,MelanomaisoftenassociatedwiththeABCDEruleincludingasymmetry,border,color,
diameterandevolving(Duarteetal.,2021). Thus,learningtheseconceptsfromanimagecanaidin
providingdiagnosticexplanationsandbuildingclassifierswhichareexplainable. However,obtaining
theseconceptlabelsfordermatologyisadifficultandtime-consumingtasksinceonlywell-trained
dermatologistscanaccuratelydescribeskindiseases. Therearedatasets(Codellaetal.,2018;Groh
etal.,2021)whichhavehigh-qualitydermoscopicimages,buttheyareeitherdevoidofmanuallabels,
notinclusiveofallconcepts,orhaveverylimitedsamplesforsomeconcepts.
Therehavebeenmanyadvancesinfully-supervisedlearningformedicalimageclassificationspanning
multipledomains(Yadav&Jadhav,2019;Islametal.,2020;Lietal.,2014). However,thesame
progresshasnotbeenachievedindermatologyimageanalysisduetolimitedavailabilityofhigh-
qualityimageswithexpertannotations. RecentlyintroducedmethodslikeCLIPprovideavenuesto
performzero-shotclassificationwithouttheneedoflabeleddatasets. PriorworkslikeMONET(Kim
etal.,2023)leverageimage-captionpairsfromPubMedarticlesandmedicaltextbookstofine-tune
CLIPmodelsfordermatology. However,thecaptionsusedintheseacademicsourcescontainmedical
termswhicharenotalignedwiththepre-trainingdataofCLIP,whichincludesimage-captionpairs
foundontheinternet. WepositthatLLMslikeGPTvariantscanbeeffectivelyusedtomodelnatural
humanlanguage. Ourcontributionsinclude(i)usingLLMsfordatagenerationbyextendingthe
originalcaptionstoalignthemwithCLIP’spre-trainingdataandimprovedownstreamperformance
onzero-shotconceptclassification,(ii)demonstratingthattheseLLMscanbefurtherfine-tunedon
thefield’stextbookstoimprovetheirexpressiveness.
∗Equalcontribuation
1
4202
rpA
91
]VC.sc[
1v34031.4042:viXraNavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
2 DATASETS
Textbooks WiththeadventofLLMs,manyopen-sourceandclosed-sourceLLMmodelspre-trained
onvastamountsofopeninternettextdataareavailable.Although,foraspecifictasklikethiswork,an
improvedandmoreinformativetextinthedermatologyfieldisrequiredthatsomeofthesepre-trained
modelscannotprovide. Therefore,fine-tuningaLLMonthedesiredtextsetisacrucialsolutionto
thisproblem. Dermatologytextbooksareagoodoptionforfulfillingthisrequirement. Wechosefour
booksforthispurpose: DifferentialDiagnosisInDermatology(Ashton&Leppard,2021),General
Dermatology (English, 2007), Top 50 Dermatology Case Studies for Primary Care (Reich et al.,
2017),andHandbookofDermoscopy(Malvehyetal.,2006). Weusedthetextfromthesetextbooks
togeneratepromptandcompletionpairsforfine-tuningtheLLMmodelsasdescribedinsection3.2.
EvaluationDataset ToevaluatethetrainedCLIPmodelforzero-shotconceptclassification,we
usedtheSKINCONdataset(Daneshjouetal.,2022). SKINCONincludes3230imagesfromthe
Fitzpatrick17kskindiseasedataset(Grohetal.,2021),denselyannotatedwith48clinicalconcepts,
22ofwhichhaveatleast50imagesrepresentingtheconcept. Theconceptsusedwerechosenby
twodermatologistsconsideringtheclinicaldescriptortermsusedtodescribeskinlesions,suchas
"plaque","scale",and"erosion"tonameafew. Thelistofconceptswasbasedontheclinicallexicon
usedbydermatologiststodescribeskinlesionsandwasdevelopedwithconsultationoftheterms
listedinoneofthemostwidelyuseddermatologytextbooks-Dermatology(Bologniaetal.,2012).
3 METHODS
3.1 EXPLORATORYANALYSIS
FortrainingCLIP,thecaptionsneedtobetokenizedusingtheCLIPtokenizerbeforethecontrastive
learningprocedure.AllCLIPmodelsuse77asthemaximumtokenizedcontextlength,eitherpadding
ortruncatingthecaptionifitisbeloworabovethatlengthrespectively.
Sincewewererestrictedto77asthemaximumnumberoftokens,wefirstdidanexploratoryanalysis
ofthetokenizedlengthsoftheoriginal44314captionsobtainedfromthePubMedarticlesutilizing
thescriptsprovidedinKimetal.(2023). Thiswouldgiveusanintuitionofhowmanytokenswere
availableforextendingthecaptionforalignment. Table2(AppendixA.2)showsthestatisticsofthe
tokenizedcaptions. Themeanlengthofcaptionsis∼35whichshowsthatmostofthecaptionsare
shortanddonotexceedthemaximumtokenlengthof77. 75%ofthecaptionshaveatokenlength
oflessthan51whichindicatesthatamajorityofcaptionsdohaveadditionaltokensavailableto
beextendedandimproved. Thereare∼13%captionswhichhavebeentruncatedatthemaxtoken
lengthof77,stillleavingaround∼38000captionsthatcanbeimprovedusingLLMs.
3.2 DATAPREPROCESSING
Fine-tuningdataforanLLMneedstobeintheformofprompt-completionpairs. Itmeantfora
specificprompt,weneededtodefinetheidealcompletionthatweexpectthemodeltooutput. Naively,
thesewouldbethesentencesthatfollowagivenpromptinthetext. However,thewholeoftheraw
textfromthebookscouldhavemisleadingphrasesandsentences,soapplyingsomepreprocessing
strategieswasessentialforfine-tuningdatapreparation.
We knew that each dermatology book had its own structure, types of references, and formatting
method. Preprocessingandextractingapropertextfromthebooksandcreatingaprompt-completion
datasetforfurtherfine-tuningwasdividedintomanualandautomaticsteps. Themanualextraction
phasewasdeletingirrelevantpageslikeglossaries,acknowledgments,andreferences. Also,notall
textinthepreservedpagesassistedincreatingprompt-completionpairs,suchastitles,footnotes,
captions,tables’text,andcitations. Figure1showssomeexamples. Wefilteredthemaintextby
pickingthelineswiththedominantfontandsizeusingthePyMuPDF1pythonlibrary. Weassumed
figures’ captions or other non-informative texts like titles are less frequent in the book and have
differentfontsandsizes. Thisassumptionwasvalidforallbooksweused. Table3(AppendixA.2)
showsthenamesofthebooksandthenumberofprompt-completionpairsobtainedforeach.
1https://github.com/pymupdf/PyMuPDF
2NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
Figure1: a)Irrelevantandconfoundingpartsoftextbooksshowninredboxesareremovedfrom
theprompt-completiondataset. b)Anexampleofapromptsentenceinbluewiththefollowingfour
sentencesinpinkasitscompletion.
3.3 FINE-TUNING
Wefine-tunedtwoLLMmodels,GPT-2(Radfordetal.,2019)andGPT-3.5(Brownetal.,2020),
whichhavebeenpre-trainedasgeneralpurposelearnersonahugeamountoftextdatascrapedfrom
theinternet. GPT-3.5isoneofthelargestautoregressivelanguagemodelsavailable,trainedwith
4096-token-long context. However, the model is close-sourced and fine-tuning comes as part of
anAPIendpoint. WefirstdecidedtouseGPT-2,whichisGPT-3.5’spredecessorwith1.5billion
parameters. Tofine-tuneGPT-2,westartedwiththeextractedpromptandcompletionpairsfrom
the preprocessing step. Then, we created the fine-tuning dataset by combining each prompt and
completionintoasinglesentenceseparatedbythepaddingtokenandtokenizedthesentenceusing
the GPT-2 tokenizer. Finally, we passed the data to the trainer with the combined prompt and
completion as the label. We used the huggingface library (Wolf et al., 2019) to implement the
GPT-2modelandfine-tuneditfortwoepochs. GPT-3.5waseasiertofine-tuneandonlyneeded
anAPIkeytodirectlycallafine-tuningendpoint. Thegpt-3.5-turbovariantofGPT-3.5was
fine-tuned for four epochs using a similar input data from the mentioned books with the format
{”prompt”:”promptA”,”completion”:”completionA”}.
Forfine-tuningCLIP,westartedbyextractingtheimage-captionpairsfromPubMedarticlesusing
thescriptsprovidedinKimetal.(2023). Wedidn’tusetextbooksheresincetherepositorydoes
nothavethelistoftextbooksused. Then,wepassedthecaptionsthroughthefine-tunedLLMto
generatedenrichedcaptionswithamaxlengthof512tokens. Table4(AppendixA.2)showssomeof
theimprovedcaptionsgeneratedusingfine-tunedGPT-2andGPT-3.5models. Wethenfine-tunedthe
pre-trainedCLIPmodelopenai/clip-vit-base-path32withabatchsizeof64usingthe
Adamoptimizer(Kingma&Ba,2014)andalearningrateof1e-5withacosineannealingscheduler
withwarmrestarts.
3.4 ZERO-SHOTCLASSIFICATIONANDEVALUATION
OncetheCLIPmodelwasfine-tuned,weusedthe3230imagesandcorrespondingconceptsfrom
theSKINCONdatasettoperformzero-shotconceptclassification. Foreachconceptkeyinthe48
SKINCON concepts, we created embeddings for the text "This is {concept_key}" and all of the
imagesinCLIP’sjointembeddingspace. Then, usingthecosinesimilarityscores, wegenerated
aReceiveroperatingcharacteristic(ROC)curveindependentlyforeachofthe48concepts. The
evaluationmetricusedwastheareaundertheROCcurve(AUC).
4 RESULTS
We evaluated using five different CLIP models: 1) The vanilla CLIP model without fine-tuning
(Vanilla)andtheCLIPmodelfinetunedusing2)OriginalPubMedimage-captionpairs(Original).
3NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
3)Alignedcaptionsfromfine-tunedGPT-24)AlignedcaptionsfromVanillaGPT-3.5. 5)Aligned
captionsfromfine-tunedGPT-3.5.
WedecidedtoincludevanillaGPT-3.5inourresultssincefromqualitativeanalysisitseemedthat
GPT-3.5byitselfhadahighenoughexpressivepowertounderstandeventechincalmedicalcontext
fromthecaptionsandgeneratecustomizations. Table1showsthemeanAUCacrossallconceptsfor
thedifferentCLIPmodelsasdefinedaboveandTable5(AppendixA.2)showstheAUCscoresfor
eachoftheconcepts.
Table1: MeanAUCacrossallconcepts
Mean
CLIPModel
AUC
Vanilla 0.572
Original 0.636
Fine-TunedGPT-2 0.642
VanillaGPT-3.5 0.639
Fine-TunedGPT-3.5 0.648
From Table 4 (Appendix A.2), it can be seen that the fine-tuned GPT-2 model is able to extend
theinputcaptionwhilekeepingthesentencegrammaticalcorrect. However, itsometimesstrays
awayfromthecontextoftheinputcaptionandcanstartconstructingsentencesbystringingtogether
medicaljargon. Thismightbearesultofsettingahighmaxtokenlengthwhichcausesthemodel
tolosecontextinlongerranges. GPT-3.5isabletomaintaincontextforalongertokenlengthand
performsbetterdataalignment.
Fine-tuning the CLIP model improves performance for most of the concepts (41 out of 48), see
Table5(AppendixA.2). Thefine-tunedGPT-3.5modelperformsthebestamongallthemodels
tested, with an AUC of 0.648 and it performs better than the original model in a majority of the
concepts(26outof48). Thisindicatesthatfine-tuningtheLLMusingdermatologytexthelpsin
improvingthedataalignmentintheextendedcaptions.
The second best performing model is the GPT-2 fine-tuned model, with an AUC of 0.642 and
performingbetterthantheoriginalmodelin25outofthe48concepts. Thisresultwasunexpected
since the GPT-3.5 model is much more powerful in terms of the model capacity as compared to
GPT-2andweexpectedtheVanillaGPT-3.5modeltooutperformthefine-tunedGPT-2model,which
wasnotthecase. Thisindicatesthatfine-tuningLLMmodelsdoesactuallyimprovethepredictive
performanceevenifthemodeldoesnothaveasmanytrainableparameters.
TheVanillaGPT-3.5modelisalsoabletooutperformtheOriginalmodelwithanAUCof0.639. This
showsthatLLMscanbeeffectivelyusedtoproducecustomizedandwell-alignedcaptionswhich
improvethelanguagesupervisionprovidedtotheCLIPtrainingprocedureresultinginimproved
performance.
5 CONCLUSION
Ourstudyrevealsthatextendingcaptionsthroughtheuseofafine-tunedLargeLanguageModel
(LLM)ondermatologytextbookseffectivelyconnectsclinicallexiconwithCLIP’spre-trainingdata,
resultinginenhanceddownstreamzero-shotconceptclassificationperformanceindermatologyim-
ages.Tosummarize,ourfindingsunderscorethepromiseofLLMsinenhancinglanguagesupervision
fordermatologyAI.TheimprovedCLIPmodelcanbefurtherusedtoannotateimageswithconcepts
thatcanbecrucialtodevelopingconcept-baseddiseaseclassifierslikeconceptbottleneckmodels
(Kohetal.,2020)thatareinterpretableandtransparent. However,furtherinvestigationisessentialto
optimizeintegrationofLLMswithdomain-specificmodels,ensuringmoreresilientapplicationsin
medicalimageanalysis.
4NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
6 ACKNOWLEDGMENT
ThisworkwasdoneaspartofthefinalprojectforthecourseCSE527(ComputationalBiology)at
theUniversityofWashington. WewouldliketothanktheprofessorDr. Su-InLeealongwiththe
teachingassistantsWeiQiuandMingyuLufortheirvaluablefeedback.
7 LIMITATIONS
Although the early findings are promising, there are many ways to extend this project. We only
used4dermatologytextbooksforextractingtheprompt-completionpairstofine-tunetheLLMs,but
therearealotmorebooksavailablewhichcanalsobepreprocessed. PubMedarticlescanbeused
togeneratetheprompt-completionpairsaswell. Also,intheextractionpipeline,wemadepairsby
gettingthefollowingfoursentencesofaparticularsentencewithoutconsideringthecontextand
paragraphswitch. Thiscouldintroduceconfoundersinthefine-tuningprocess. Forinstance,the
firstcompletionsentencecouldberelatedtomelanoma;incontrast,theotherthreecouldbefrom
thenextsectionanddiscussanotherdisease. Inaddition,pythonpdfparsersoccasionallyfailand
breaksomewordsintomeaninglesschunksthatcandoubtlesslymisleadtheLLMduringfine-tuning.
Asolutionfortheextractionissuesisaddingmoremanualandautomaticstepstoremoveandfilter
meaninglesswordsandcheckingthecontextintegration. LLMshavealsobeenknowntohallucinate
(Leeetal.,2018;Bangetal.,2023)andproperstepsneedtobetakentoensurenon-existentfactsare
notfabricatedwhichispertinentinahigh-stakesdomainlikedermatology.
Furthermore, we used the gpt-3.5-turbo variant of GPT-3.5, but there are more powerful
variantsavailablelikeGPT-4whichwedidnotuseduetobudgetconstraints. Anotherapproachto
enhancetheperformanceofthefine-tunedLargeLanguageModel(LLM)andrefinethegenerated
captionsisbyincorporatingInstructionTuningdata(Zhangetal.,2023;Liuetal.,2023;Daietal.,
2023;Ouyangetal.,2022),instruction-outputpairs,extractedfromdermatologybooksduringthe
fine-tuningprocess. Thistaskneedsacarefulplantocreateadatasetthatisusefulandgivesvaluable
insights.
Another change that could be made is the CLIP model used. We used the
openai/clip-vit-base-path32 model for CLIP training but there is a more power-
fulbaselineCLIPmodelopenai/clip-vit-large-patch14available,whichwedidnotuse
becauseofmemoryconstraintsandlongertrainingtimes. Wecanalsoemployanon-randombatch
samplingstrategy,whichincludessampleswithdifferentconceptsinonemini-batchforefficient
learningofconcepts. Anotherwaytoimprovelanguagesupervisionbyemployingwaystoincrease
thenumberoftokensfrom77,whichisCLIP’slimitations. Weanticipatethatallofthesechanges
willimprovethezero-shotclassificationperformanceofthefine-tunedCLIPmodel.
5NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
REFERENCES
RichardAshtonandBarbaraLeppard. Differentialdiagnosisindermatology. CRCPress,2021.
YejinBang,SamuelCahyawijaya,NayeonLee,WenliangDai,DanSu,BryanWilie,HolyLovenia,
ZiweiJi,TiezhengYu,WillyChung,etal. Amultitask,multilingual,multimodalevaluationof
chatgptonreasoning,hallucination,andinteractivity. arXivpreprintarXiv:2302.04023,2023.
Jean L Bolognia, Joseph L Jorizzo, and Julie V Schaffer. Dermatology e-book. Elsevier Health
Sciences,2012.
TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal. Languagemodelsare
few-shotlearners. Advancesinneuralinformationprocessingsystems,33:1877–1901,2020.
NoelCFCodella,DavidGutman,MEmreCelebi,BrianHelba,MichaelAMarchetti,StephenW
Dusza,AadiKalloo,KonstantinosLiopyris,NabinMishra,HaraldKittler,etal.Skinlesionanalysis
toward melanoma detection: A challenge at the 2017 international symposium on biomedical
imaging(isbi),hostedbytheinternationalskinimagingcollaboration(isic). In2018IEEE15th
internationalsymposiumonbiomedicalimaging(ISBI2018),pp.168–172.IEEE,2018.
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang,
BoyangLi,PascaleFung,andStevenHoi. Instructblip: Towardsgeneral-purposevision-language
modelswithinstructiontuning,2023.
RoxanaDaneshjou,MertYuksekgonul,ZhuoRanCai,RobertoA.Novoa,andJamesZou. Skincon:
Askindiseasedatasetdenselyannotatedbydomainexpertsforfine-graineddebuggingandanalysis.
InThirty-sixthConferenceonNeuralInformationProcessingSystemsDatasetsandBenchmarks
Track,2022. URLhttps://openreview.net/forum?id=gud0qopqJc4.
JiaDeng, WeiDong, RichardSocher, Li-JiaLi, KaiLi, andLiFei-Fei. Imagenet: Alarge-scale
hierarchicalimagedatabase. In2009IEEEconferenceoncomputervisionandpatternrecognition,
pp.248–255.Ieee,2009.
AnaFDuarte,BernardoSousa-Pinto,LuísFAzevedo,AnaMBarros,SusanaPuig,JosepMalvehy,
EckartHaneke,andOsvaldoCorreia. Clinicalabcderuleforearlymelanomadetection. European
JournalofDermatology,31(6):771–778,2021.
MohamedElhoseiny,YizheZhu,HanZhang,andAhmedElgammal. Linktheheadtothe"beak":
Zero shot learning from noisy text description at part precision. In Proceedings of the IEEE
ConferenceonComputerVisionandPatternRecognition,pp.5640–5649,2017.
JohnSCEnglish. GeneralDermatology. AtlasMedicalPublishingLimited,2007.
MatthewGroh,CalebHarris,LuisSoenksen,FelixLau,RachelHan,AerinKim,ArashKoochek,
andOmarBadri. Evaluatingdeepneuralnetworkstrainedonclinicalimagesindermatologywith
thefitzpatrick17kdataset. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pp.1820–1828,2021.
MdMohaimenulIslam,Hsuan-ChiaYang,TahminaNasrinPoly,Wen-ShanJian,andYu-ChuanJack
Li. Deeplearningalgorithmsfordetectionofdiabeticretinopathyinretinalfundusphotographs:
Asystematicreviewandmeta-analysis. ComputerMethodsandProgramsinBiomedicine,191:
105320,2020.
AlistairEWJohnson,TomJPollard,SethJBerkowitz,NathanielRGreenbaum,MatthewPLungren,
Chih-yingDeng,RogerGMark,andStevenHorng. Mimic-cxr,ade-identifiedpubliclyavailable
databaseofchestradiographswithfree-textreports. Scientificdata,6(1):1–8,2019.
ChanwooKim,SohamUGadgil,AlexJDeGrave,ZhuoRanCai,RoxanaDaneshjou,andSu-InLee.
Fosteringtransparentmedicalimageaiviaanimage-textfoundationmodelgroundedinmedical
literature. medRxiv,2023.
DiederikPKingmaandJimmyBa. Adam: Amethodforstochasticoptimization. arXivpreprint
arXiv:1412.6980,2014.
6NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
PangWeiKoh,ThaoNguyen,YewSiangTang,StephenMussmann,EmmaPierson,BeenKim,and
PercyLiang. Conceptbottleneckmodels. InInternationalconferenceonmachinelearning,pp.
5338–5348.PMLR,2020.
KatherineLee,OrhanFirat,AshishAgarwal,ClaraFannjiang,andDavidSussillo. Hallucinationsin
neuralmachinetranslation. 2018.
Cheng-Xu Li, Chang-Bing Shen, Ke Xue, Xue Shen, Yan Jing, Zi-Yi Wang, Feng Xu, Ru-Song
Meng,Jian-BinYu,andYongCui. Artificialintelligenceindermatology: past,present,andfuture,
2019.
QingLi,WeidongCai,XiaogangWang,YunZhou,DavidDaganFeng,andMeiChen. Medical
imageclassificationwithconvolutionalneuralnetwork. In201413thinternationalconferenceon
controlautomationrobotics&vision(ICARCV),pp.844–848.IEEE,2014.
HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee. Visualinstructiontuning,2023.
JosepMalvehy,RalphPBraun,SusanaPuig,AshfaqAMarghoob,andAlfredWKopf. Handbookof
dermoscopy. CRCPress,2006.
LongOuyang,JeffWu,XuJiang,DiogoAlmeida,CarrollL.Wainwright,PamelaMishkin,Chong
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,JohnSchulman,JacobHilton,FraserKelton,
LukeMiller,MaddieSimens,AmandaAskell,PeterWelinder,PaulChristiano,JanLeike,and
RyanLowe. Traininglanguagemodelstofollowinstructionswithhumanfeedback,2022.
TzufPaz-Argaman,YuvalAtzmon,GalChechik,andReutTsarfaty.Zest:Zero-shotlearningfromtext
descriptionsusingtextualsimilarityandvisualsummarization. arXivpreprintarXiv:2010.03276,
2020.
SarahPratt,RosanneLiu,andAliFarhadi. Whatdoesaplatypuslooklike? generatingcustomized
promptsforzero-shotimageclassification. arXivpreprintarXiv:2209.03320,2022.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,IlyaSutskever,etal. Language
modelsareunsupervisedmultitasklearners. OpenAIblog,1(8):9,2019.
AlecRadford, JongWookKim, ChrisHallacy, AdityaRamesh, GabrielGoh, SandhiniAgarwal,
GirishSastry,AmandaAskell,PamelaMishkin,JackClark,etal. Learningtransferablevisual
modelsfromnaturallanguagesupervision. InInternationalConferenceonMachineLearning,pp.
8748–8763.PMLR,2021.
DanyaReich,CorinnaEleniPsomadakis,andBobbyBuka. Top50DermatologyCaseStudiesfor
PrimaryCare. Springer,2017.
EkinTiu,EllieTalius,PujanPatel,CurtisPLanglotz,AndrewYNg,andPranavRajpurkar. Expert-
leveldetectionofpathologiesfromunannotatedchestx-rayimagesviaself-supervisedlearning.
NatureBiomedicalEngineering,pp.1–8,2022.
ThomasWolf,LysandreDebut,VictorSanh,JulienChaumond,ClementDelangue,AnthonyMoi,
Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. Huggingface’s transformers:
State-of-the-artnaturallanguageprocessing. arXivpreprintarXiv:1910.03771,2019.
SamirSYadavandShivajiraoMJadhav. Deepconvolutionalneuralnetworkbasedmedicalimage
classificationfordiseasediagnosis. JournalofBigData,6(1):1–18,2019.
ShengyuZhang,LinfengDong,XiaoyaLi,SenZhang,XiaofeiSun,ShuheWang,JiweiLi,Runyi
Hu,TianweiZhang,FeiWu,andGuoyinWang. Instructiontuningforlargelanguagemodels: A
survey,2023.
7NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
A APPENDIX
A.1 RELATEDWORK
TheCLIPnetwork(Radfordetal.,2021)learnsvisualconceptsbybeingtrainedwithimageandtext
pairsinaself-supervisedmanner,usingtextpairedwithimagesfoundacrosstheInternet. CLIPuses
acontrastivelearningproceduretogenerateamulti-modelembeddingspacebyjointlytrainingan
imageencoderandatextencoderssuchthattheembeddingsofagivenimage-textpairareclose
togetherinthejointrepresentationspace. GivenabatchofN (image,text)pairs,CLIPistrainedto
predictwhichoftheN ×N possible(image,text)pairingsacrossabatchactuallyoccurred. Thisis
donebymaximizingthecosinesimilarityoftheimageandtextembeddingsoftheN realpairsinthe
batchwhileminimizingthecosinesimilarityoftheembeddingsoftheN2−N incorrectpairings.
Thisoptimizationisdoneusingasymmetriccrossentropylossoverthesesimilarityscores. CLIPis
powerfulenoughtobeusedinzero-shotmanneronstandardimages(suchasthosefromImageNet
(Dengetal.,2009)classes). However,dermatologyimagesaresufficientlydifferentfromeveryday
imagesthatitwouldbeusefultofine-tuneCLIPwiththem.
Therehasbeenpriorworkdoneforperformingself-supervisedconstrasticelearningtasksinthe
medicaldomain. (Tiuetal.,2022)usedcontrastivelearningfortrainingaself-supervisedmodelon
chestx-rayimageslackingexplicitannotationstoperformpathology-classificationtasks. However,
the MIMIC-CXR dataset (Johnson et al., 2019) which was used to train the model consists of
expertradiologyreportsaccompanyingeachimagewhichhasrichtextualdescriptionsaboutthe
x-ray and enables the text transformer to better learn visual medical concepts and generalize to
differentpathologies. Incaseofdermatologyimages,nosuchdatasetexistscontainingimageswith
correspondingexpertreports.
Inthelanguagesupervisiondomain,severalpriorworkshaveusedtext-basedknowledgeofimage
categoriestoimproveclassificationaccuracy. Elhoseinyetal.(2017)extractsvisualinformationfrom
unstructuredtextdescriptionscollectedfromtheinternettorecognizeobjectpartsandperformzero-
shotclassification. Paz-Argamanetal.(2020)extractvisualinformationfromWikipediadescriptions
toenablebirdclassification. Theseworksshowthattextaugmentationisusefulforself-supervised
models,buttheyrelyonexternalnaturallanguagedatasetsforgeneratingdescriptions. Prattetal.
(2022)usesalargelanguagemodel(GPT-3.5)togeneratecustomizedpromptsforarangeofzero-shot
imageclassificationbenchmarks,howeveritdoesnotperformanyfine-tuningandthedatasetsdon’t
includeanyimagesfromthemedicaldomain.
Ourproposedapproachcombinesthepriorworksbyleveragingtheexpressivepowerprovidedby
LLMswiththeavailabilityofdermatologyimagesandcontrastivelearningapproachestoimprove
zero-shotconceptgenerationusingcustomizedprompts.
8NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
A.2 TABLES
Table2: Tokenizedcaptionstatistics
Statistic Value
Mean 35.394
StandardDeviation 22.801
Minimum 3
LowerQuartile 17
Median 28
UpperQuartile 51
Maximum 77
Table3: Datasetstatistics
BookName Pages Numberofpairs
Differential Diagnosis In Dermatology
466 616
(Ashton&Leppard,2021)
GeneralDermatology(English,2007) 147 286
Top50DermatologyCaseStudiesforPri-
341 851
maryCare(Reichetal.,2017)
HandbookofDermoscopy(Malvehyetal.,
106 58
2006)
Total 1811
9NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
Table4: Examplesofimprovedcaptionsusingfine-tunedGPT-2andGPT-3.5
Caption GPT-2Fine-Tuned GPT-3.5Fine-Tuned
Infection with
streptococci can cause
This long-standing
pustular psoriasis
disseminated granuloma
on the lower legs, a
annulare (DGA) on the
condition which is
left leg is likely
commonly referred to
caused by an unknown
as “sore throat on
Long-standing infection. The DGA
the legs.” Granuloma
disseminated typically presents
annulare is a common,
granuloma with a red, inflamed
self-limiting,
annulare on lump that is hard to
skin-tearing condition.
the left leg. see. It can cause
It occurs in about 10
significant pain and
% of immunocompromised
difficulty walking.
populations and occurs
Treatment typically
predominantly at sites
involves antibiotics
where skin is heavily
and/or surgery.
covered, such as the
arms and legs.’
Anakinra is a
medication used
Multiple papillary to treat certain
lesions scattered inflammatory conditions,
symmetrically over including hidradenitis
the lower abdominal suppurativa. In rare
Anakinra-induced
area with or without cases, anakinra has
sarcoidosis.
a border, sometimes been linked to an
Buttock
with or without increased risk of
erythematous
scaling. Itching developing sarcoidosis,
plaque
on palpation.The a condition that causes
eruption
clinical appearance and abnormal collections
while on
pathogenesis of sarcoid of inflammatory cells
anakinra for
vary greatly depending in the body. Signs and
hidradenitis
on the size, location symptoms of sarcoidosis
suppurativa.
and age of the patient. can vary but can
In the elderly, it is include skin rashes
typically chronic, and and lesions, such
lasts for many years. as an erythematous
plaque eruption on the
buttocks.
These frequently Atopic eczema tends to
rupture to drain a be poorly defined, but
haemopurulent discharge. with prominent warty
Individual lesions plaques. In peridial
may be often caused eczema the surface is
Interdigital by penetrating foreign dry and erythematous,
furunculosis bodies, but recurrent and is complicated by
with a lesions are more eosinophilia and by
painful, commonly associated chronic, unresponsive
erythematous with atopic dermatitis or nodular form.The
and alopecic and/or conformational differential diagnosis
nodule. problems.The discharge of peridial eczema
is red, erythematous includes solar eczema,
and itchy. It gets rubella and psoriasis
better spontaneously may turn from pink to
after few days to a deep purple with the
week. development of scabs.
10NavigatingandAddressingDataProblemsforFoundationModels(DPFM)Workshop,ICLR2024
Table5: ConceptClassificationAUC.#TrueshowsthenumberofsamplesintheSKINCONdataset
labeledwiththatconcept
Fine-
Fine- Vanilla
Tuned
Concept #True Vanilla Original Tuned GPT-
GPT-
GPT-2 3.5
3.5
Vesicle 46 0.552 0.667 0.715 0.674 0.584
Papule 1170 0.448 0.66 0.646 0.668 0.676
Macule 13 0.407 0.395 0.54 0.469 0.556
Plaque 1967 0.566 0.646 0.582 0.656 0.611
Abscess 5 0.929 0.847 0.787 0.875 0.884
Bulla 64 0.508 0.611 0.584 0.647 0.654
Patch 149 0.547 0.461 0.546 0.599 0.523
Nodule 189 0.719 0.773 0.744 0.758 0.758
Ulcer 154 0.82 0.883 0.886 0.879 0.883
Crust 497 0.559 0.666 0.635 0.671 0.727
Erosion 200 0.538 0.593 0.626 0.603 0.602
Excoriation 46 0.536 0.693 0.6 0.559 0.578
Atrophy 69 0.482 0.606 0.613 0.563 0.616
Exudate 144 0.677 0.656 0.617 0.629 0.626
Purpura/Petechiae 10 0.577 0.592 0.662 0.667 0.646
Fissure 32 0.708 0.548 0.428 0.506 0.686
Induration 33 0.594 0.559 0.528 0.573 0.553
Xerosis 35 0.41 0.735 0.737 0.744 0.547
Telangiectasia 100 0.366 0.484 0.574 0.47 0.564
Scale 686 0.485 0.474 0.434 0.417 0.521
Scar 123 0.604 0.659 0.592 0.568 0.639
Friable 153 0.629 0.576 0.628 0.555 0.377
Sclerosis 27 0.661 0.557 0.582 0.595 0.506
Pedunculated 26 0.665 0.855 0.755 0.817 0.773
Exophytic/Fungating 42 0.713 0.629 0.657 0.607 0.7
Warty/Papillomatous 46 0.71 0.591 0.592 0.636 0.691
Dome-shaped 146 0.624 0.604 0.71 0.658 0.667
Flattopped 18 0.574 0.595 0.609 0.563 0.635
Brown(Hyperpigmentation) 760 0.648 0.768 0.776 0.763 0.738
Translucent 16 0.496 0.523 0.69 0.731 0.547
White(Hypopigmentation) 257 0.596 0.686 0.718 0.715 0.737
Purple 85 0.725 0.843 0.813 0.777 0.762
Yellow 245 0.614 0.744 0.733 0.706 0.721
Black 90 0.685 0.873 0.901 0.882 0.896
Erythema 2139 0.609 0.719 0.711 0.666 0.68
Comedo 24 0.469 0.502 0.527 0.561 0.632
Lichenification 25 0.505 0.565 0.55 0.545 0.502
Blue 5 0.662 0.749 0.767 0.754 0.784
Umbilicated 49 0.57 0.683 0.567 0.663 0.751
Poikiloderma 5 0.324 0.621 0.453 0.4 0.524
Salmon 10 0.463 0.671 0.641 0.667 0.588
Wheal 21 0.507 0.796 0.775 0.666 0.693
Acuminate 8 0.444 0.279 0.588 0.654 0.606
Burrow 5 0.807 0.636 0.585 0.68 0.786
Gray 5 0.302 0.45 0.439 0.283 0.303
Pigmented 5 0.459 0.483 0.513 0.581 0.661
Cyst 6 0.521 0.745 0.883 0.79 0.827
MeanAUC 0.572 0.636 0.642 0.639 0.648
11