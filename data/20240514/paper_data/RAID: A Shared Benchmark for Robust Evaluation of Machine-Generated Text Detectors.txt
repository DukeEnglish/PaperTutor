RAID: A Shared Benchmark for Robust Evaluation
of Machine-Generated Text Detectors
LiamDugan1, AlyssaHwang1, FilipTrhlik2, JoshMagnusLudan1
AndrewZhu1, HainiuXu3, DaphneIppolito4, ChrisCallison-Burch1
UniversityofPennsylvania1 UniversityCollegeLondon2
King’sCollegeLondon3 CarnegieMellonUniversity4
{ldugan, ahwang16, jludan, andrz, ccb}@seas.upenn.edu
hainiu.xu@kcl.ac.uk, filip.trhlik.21@ucl.ac.uk, daphnei@cmu.edu
Abstract
https://www.detect-ai.com
LLaMA
Many commercial and open-source models DETECT AI:
claim to detect machine-generated text with (default) AI-GENERATED
veryhighaccuracy(99%orhigher). However,
very few of these detectors are evaluated on
sharedbenchmarkdatasetsandevenwhenthey
are,thedatasetsusedforevaluationareinsuffi- LLaMA https://www.detect-ai.com
cientlychallenging—lackingvariationsinsam- +sampling DETECT AI:
pling strategy, adversarial attacks, and open-
+penalty NOT AI-GENERATED
source generative models. In this work we
presentRAID:thelargestandmostchalleng-
ingbenchmarkdatasetformachine-generated
Figure1:Detectorsformachine-generatedtextareoften
textdetection. RAIDincludesover6million
highly performant on default model settings but fail
generationsspanning11models,8domains,11
todetectmoreunusualsettingssuchasusingrandom
adversarial attacks and 4 decoding strategies.
samplingwitharepetitionpenalty.
Using RAID, we evaluate the out-of-domain
and adversarial robustness of 8 open- and 4
closed-source detectors and find that current
theirownevaluationdatasetsandfailtotesttheir
detectors are easily fooled by adversarial at-
modelsonsharedresources—makingitdifficultto
tacks,variationsinsamplingstrategies,repeti-
verifyclaimsofaccuracyandrobustness. Thishas
tionpenalties, andunseengenerativemodels.
Wereleaseourdataset1andtoolstoencourage led to an erosion of trust in the efficacy of auto-
furtherexplorationintodetectorrobustness. maticdetectionmethodsandagenerallyfatalistic
sentimenttowardsdetectionamongresearchersand
1 Introduction practitioners(Sadasivanetal.,2023).
To combat this trend, in this work, we intro-
LargeLanguageModels(LLMs)havebeenableto
ducetheRobustAIDetection(RAID)benchmark.
foolhumansintothinkingtheiroutputsarehuman-
RAID consists of 6M+ generations spanning 11
writtenforroughlyfouryears(Duganetal.,2020;
generators,8domains,11adversarialattacks,and
Clark et al., 2021). In that short span of time we
4 decoding strategies. Using RAID, we bench-
haveseenLLM-generatedtextbeusedfortargeted
marktherobustnessof12detectors(8open-and4
phishingattacks(Bakietal.,2017;Hazell,2023),
closed-source). Wefindthatdetectorshavesubstan-
massspamandharassment(Weiss,2019),disinfor-
tial difficulty generalizing to unseen models and
mationcampaigns(Sharevskietal.,2023;Spitale
domainsandthatsimplechangessuchaschanging
et al., 2023), and spurious scientific publication
thesamplingstrategy,addingarepetitionpenalty,
(Lundetal.,2023). Inordertodocumentandeven-
andadversariallymodifyingtextleadtosubstantial
tuallymitigatesuchharms,wemustdeveloprobust
decreasesinperformance.
automaticdetectorsofmachine-generatedtext.
Manyexcitingandinventivemethodshavebeen
2 RelatedWork
proposed in recent years for detecting generated
text (Crothers et al., 2023). However, when eval-
InTable1weshowacomparisonbetweenRAID
uating these methods, authors typically generate
andotherpubliclyavailablesourcesofgenerated
1https://github.com/liamdugan/raid text. Amongthese,themostsimilarworktoours
4202
yaM
31
]LC.sc[
1v04970.5042:viXraDomain Model Sampling Multilingual Adversarial
Name Size coverage? coverage? coverage? coverage? coverage?
TuringBench(Uchenduetal.,2021) 200k
RuATD(Shamardinaetal.,2022) 215k
HC3(Guoetal.,2023) 26.9k
MGTBench(Heetal.,2023) 2817
MULTITuDE(Mackoetal.,2023) 74.1k
AuText2023(Sarvazyanetal.,2023b) 160k
M4(Wangetal.,2023b) 122k
CCD(Wangetal.,2023a) 467k
IMDGSP(Moscaetal.,2023) 29k
DeepfakeTextDetect(Lietal.,2023b) 447k
HC-Var(Xuetal.,2023) 145k
HC3Plus(Suetal.,2024) 210k
RAID(Ours) 6.2M
Table1: Acomparisonofthepubliclyavailablesourcesofgeneratedtext. Ourprovideddatasetistheonlyonethat
containsadiverseselectionofdomains,samplingstrategies,andadversarialattacksacrossrecentgenerativemodels.
is Li et al. (2023b), who create a dataset of 447k tohomoglyphattacks(Gagianoetal.,2021;Wolff,
generations from 27 language models across 10 2020; Macko et al., 2024), whitespace insertion
domainstostudytherobustnessofdetectors. Other (Cai and Cui, 2023), sentiment and factual alter-
resources typically focus on particular sub-areas ations(BhatandParthasarathy,2020),paraphrase
suchasmultilingualtext(Mackoetal.,2023;Wang attacks (Krishna et al., 2023; Sadasivan et al.,
etal.,2023b),code(Wangetal.,2023a),question- 2023),andsynonymreplacement(Kulkarnietal.,
answering (Guo et al., 2023; Xu et al., 2023; Su 2023; Pu et al., 2023a). Our work builds on this
et al., 2024), and scientific papers (Mosca et al., foundation and synthesizes many elements of ro-
2023). Additionally,sharedtaskssuchasAuText- bustnessintoonesingularsystematicstudy.
Tification (Sarvazyan et al., 2023a) and RuATD
3 DatasetCreation
(Shamardina et al., 2022) have provided datasets
andencouragedcentralizedevaluationandcompeti-
3.1 Overview
tion. Whilemanysharedresourcesdoagoodjobof
In Figure 2, we illustrate the components of the
coveringmultiplegenerativemodelsanddomains,
RAID dataset. To create RAID, we first sample
few include adversarial attacks and none include
roughly 2,000 documents of human-written text
variationindecodingstrategy—occasionallyeven
fromeachofour8targetdomains(§3.2). Foreach
failingtolistthestrategyused. Thesedatasetsare
document, we create a corresponding generation
insufficientlychallengingandpromotetheinflated
prompt using a template such as “Write a recipe
reportsofdetectoraccuracy.
for{title}”(§3.3). Wethengenerateoneoutputfor
Other ways to evaluate the robustness of
eachofour11models(§3.4),4decodingstrategies
machine-generated text detectors have tradition-
(§3.5),and11adversarialattacks(§3.6). TheRAID
ally involved varying a particular parameter of
datasetconsistsofover6Mgenerations,thelargest
somenumberofdetectorsandevaluatingthemon
datasetofgeneratedtexttodate.
a set of generations. Previous work of this kind
hasshownthatdetectorslackrobustnesstounseen 3.2 Domains
generativemodels(StiffandJohansson,2022;Pu
Since errors have been shown to be important
et al., 2023b; Chakraborty et al., 2023), domains
clues for detection (Dugan et al., 2023), we pri-
(Pagnonietal.,2022;Puetal.,2023a;Rodriguez
oritizeddomainsathighriskforabuseandwhich
et al., 2022), decoding strategies (Ippolito et al.,
were likely to induce errors from language mod-
2020;Solaimanetal.,2019),prompts(Koikeetal.,
els. Oursourcesevaluatefactualknowledge(News,
2023;Kumarageetal.,2023;Luetal.,2023),rep-
Wikipedia), generalization and reasoning (Ab-
etitionpenalties(FishchukandBraun,2023),and
stracts,Recipes),creativeandconversationalskills
humanedits(Gaoetal.,2024).
(Reddit,Poetry),andknowledgeofspecificmedia
Substantialworkspecializinginadversarialro- (Books,Reviews). Formoredetailedinformation
bustness has shown that detectors are vulnerable oneachsourcedomainseeAppendixA.1.Models Domains Decoding Strategy
GPT-4 GPT-2 XL GPT-3 Abstracts Recipes Greedy (temp. = 0)
Cohere Cohere (Chat) Sampling (temp. = 1, p = 1)
Books Reddit
MPT-30B MPT-30B (Chat)
News Reviews Repetition Penalty
Mistral-7B Mistral-7B (Chat)
ChatGPT LLaMA 2 70B (Chat) Poetry Wikipedia With (rep = 1.2)
Without (rep = 1.0)
11 models 8 domains
Detectors Adversarial Attacks
Neural Metric-Based Commercial Alternative Spelling Homoglyph
RoBERTa-B (GPT-2) GLTR GPTZero Article Deletion Number Swap
RoBERTa-L (GPT-2) Fast DetectGPT Originality Insert Paragraphs Paraphrase
RoBERTa-B (ChatGPT) Binoculars Winston Upper Lower Swap Synonym Swap
RADAR LLMDet ZeroGPT Zero-Width Space Misspelling
Whitespace Addition
12 detectors 11 attacks
Figure2: AnoverviewofthestructureoftheRAIDdataset. Wegenerate2,000continuationsforeverycombination
ofdomain,model,decoding,penalty,andadversarialattack. Thisresultsinroughly6.2milliongenerationsfor
testing. Wethenevaluateeachdetectoronallpiecesofgeneratedtextinthedataset.
3.3 Prompts Chat Writetheabstractfortheacademicpaper
titled"{title}".
We prompt our generators in a zero-shot fashion
Non-Chat Thefollowingisthefulltextoftheabstract
using “Chat” templates for models fine-tuned on
for a research paper titled "{title}" from
dialogueand“Non-Chat”templatesforcontinua- arxiv.org:
tionmodels. Eachpromptisnearlythesame,with
the exception of a “{title}” field that is dynami- Table 2: The “Chat” and “Non-Chat” templates used
for generation in the Abstracts domain. The “{title}”
cally replaced with the title of the corresponding
fieldisdynamicallyfilledinwiththetitleofthehuman-
human-writtentext. Unlikepreviouswork(Verma
writtendocumentatgenerationtime.
etal.,2023;Xuetal.,2023),weintentionallyavoid
biasing the language model towards a particular
length or generation style to better match our ex- 3.5 DecodingStrategies
pectationsofreal-worldscenarios. Weengineered
Thedecodingstrategydetermineshowtokensare
ourpromptsovermultipleroundstominimizede-
selectedfromthelanguagemodel’sprobabilitydis-
generaterepetition,unhelpfulgeneration,andmeta-
tribution. Previous work has shown that greedy
commentaryacrossallmodels(SeeAppendixA.3).
decoding reduces the diversity of text and makes
3.4 Models it easier to detect while sampling directly from
thedistributionshowstheoppositeeffect(Ippolito
We carefully chose a set of models that were
etal.,2020). Basedonthesefindings,wegenerate
maximally distinct from each other, offering us
twooutputsperprompt,onewithgreedydecoding
thewidestrangeandvariabilityofgeneratedtext.
andtheotherwithfullyrandomsampling.
We focused on varying model sizes, open/closed
We also generate two additional outputs with
source, and free/paid usage. Following work by
Keskaretal.(2019)’srepetitionpenaltywhenavail-
Sarvazyan et al. (2023a), we selected the largest
able.2 Thispenaltyworksbydown-weightingthe
modelfromeachmodelfamily. Mostimportantly,
probabilityoftokensthathavepreviouslyappeared
weexcludedthird-partyfine-tunedvariantsofbase
inthecontextwindowbysomemultiplicativefac-
modelsinfavorofthebasemodelsthemselves. We
tor θ, resulting in less repetitive output. We are
includedtheofficialchatversionswhenavailable
thefirsttoevaluatethispenaltyfordetectionand
to isolate the effects of chat fine-tuning. In total,
showthatitsignificantlyreducesthedetectability
we used four GPT models (GPT2, GPT3, GPT4,
ChatGPT),threeopen-sourcemodelsandtheirchat
2Only open-source models provide a repetition penalty.
variants (Mistral 7B, MPT 30B, LLaMA 2 70B),
Closed-sourcemodelAPIsinsteadofferslightlydifferent“fre-
andtheCoherecommand andchatmodel. quency”and“presence”penalties(seeAppendixA.5).ofoutputs. FollowingKeskaretal.(2019),weuse
Greedy Greedy + Penalty
θ = 1.2forourexperiments. 30k 60k
20k 40k
3.6 AdversarialAttacks
Whenselectingadversarialattacks,weassumethat 10k 20k
ouradversaryhasexactlyonequeryandnoknowl-
0 0
edgeofthedetector. Thus,weincludethefollow- 0 50 100 0 50 100
ing11black-box,query-freeattacksasopposedto Sampling Sampling + Penalty
gradient-basedmethods:
40k 60k
1. AlternativeSpelling: UseBritishspelling 40k
20k
2. ArticleDeletion: Delete(‘the’,‘a’,‘an’) 20k
3. AddParagraph: Put\n\nbetweensentences 0 0
0 50 100 0 50
4. Upper-Lower: Swapthecaseofwords
5. Zero-Width Space: Insert the zero-width
Figure3: Histogramofexamples(y-axis)groupedby
spaceU+200Beveryothercharacter
their repetitiveness measured via SelfBLEU score (x-
6. Whitespace: Addspacesbetweencharacters axis). Weseethatbothrandomsamplingandrepetition
7. Homoglyph: Swapcharactersforalternatives penaltygreatlyreducerepetitivenessforallmodels.
thatlooksimilar,e.g. e→e(U+0435)
8. Number: Randomlyshuffledigitsofnumbers Num. Self- PPL PPL
9. Misspelling: Insertcommonmisspellings Model Gens Toks BLEU -L7B -G2X
10. Paraphrase: Paraphrasewiththefine-tuned Human 14971 378.5 7.64 9.09 21.2
T5-11BmodelfromKrishnaetal.(2023) GPT2 59884 384.7 23.9 8.33 8.10
11. Synonym: Swap tokens with highly similar GPT3 29942 185.6 13.6 3.90 8.12
ChatGPT 29942 329.4 10.3 3.39 9.31
BERT(Devlinetal.,2019)candidatetokens
GPT4 29942 350.8 9.42 5.01 13.4
Cohere 29942 - 11.0 5.67 23.7
FollowingrecommendationsfromDyrmishietal. (+Chat) 29942 - 11.0 4.93 11.6
(2023),wemanuallyreviewedourdatatoensure Mistral 59884 370.2 19.1 7.74 17.9
(+Chat) 59884 287.7 9.16 4.31 10.3
thatadversarialattackswereinconspicuous. Thus,
MPT 59884 379.2 22.1 14.0 66.9
foreachattackonlyasmallpercentageofthetotal (+Chat) 59884 219.2 5.39 7.06 56.3
LLaMA 59884 404.4 10.6 3.33 9.76
availablemutationswereactuallycarriedout. De-
tails on the mutation percentages for each attack Total 509k - 13.7 6.61 23.8
as well as specifics about implementation can be
Table3: Statisticsforthegenerationsinthebasedataset
foundinAppendixA.4.
withoutadversarialattacks. PPL-L7Breferstomean
perplexity according to LLaMA 7B and PPL-G2X
3.7 Post-Processing
referstomeanperplexityaccordingtoGPT2XL.
Afterallgenerationswerecompleted,weremoved
prompts and left only the generated output. We
thenfilteredoutfailedgenerationsandbalancedthe meanperplexityislowerformodelsthanhumans,
datasetsuchthateachhuman-writtendocumenthas accordingtoLLaMA7BandGPT2XL.
exactly one corresponding generation per model,
4.2 ReleaseStructure
decodingstrategy,andadversarialattack.
ToaccompanytheRAIDdatasetwereleaseanoffi-
4 Dataset cialpublicleaderboard3 whichwillhosttheresults
fromouranalysisalongsideotherdetectorresults
4.1 Statistics
submittedbypubliccontributors. Theleaderboard
The non-adversarial portion of the RAID dataset
is split up into two sections—one for those who
consistsof509,014generationsand14,971human-
self-reporthavingtrainedontheRAIDdatasetand
written documents for a total of 6,287,820 texts
one for those who do not. This is important to
when including adversarial attacks. On average,
ensurethatacleardistinctionismadebetweende-
models are more repetitive than humans as mea-
tectorsthataregeneralizingtoout-of-domaindata
sured by Self-BLEU (Zhu et al., 2018) and typi-
callygenerateshorterpassages(seeTable3). The 3https://raid-bench.xyz/leaderboardandthosethatarenot. 1.0
To ensure fair competition, 10% of the RAID
dataset will be released without labels for use as
0.8
theofficialhiddentestset. Weprovidescripts4 to
easily run detectors on this test set and calculate
accuracywithrespecttothehiddenlabels. Users 0.6
can then submit their outputs to the leaderboard Originality
Binoculars
viaapullrequest. Wehopethatthisinfrastructure F-DetectGPT
0.4 Winston
encouragesmorecomparisonandsharedevaluation RADAR
GPTZero
ofdetectors. ZeroGPT
0.2 GLTR
R-B (GPT2)
5 Detectors R-L (GPT2)
R-B (C-GPT)
LLMDet
DetectorSelection Weevaluatedetectorsfrom 0.0
100% 10% 1% 0.1% 0.01%
three categories: neural, metric-based, and com-
Figure4: Detectionaccuracy(y-axis)vs. FalsePositive
mercial. Neural detectors typically involve fine-
Rate(x-axis)foralldetectors. WeseethatBinoculars
tuning a pre-trained language model such as
works significantly better than other detectors at low
RoBERTa (Liu et al., 2019) while metric-based
FPRandthatfewdetectorscanoperateatFPR<1%.
detectorstypicallycomputesomemetricusingthe
outputprobabilitiesofanexistinggenerativemodel.
While the neural and metric-based detectors are thedatasetof5%andthenreportaccuracyonthe
free and open-source, commercial detectors are machine-generatedportion.
typically offered via an API for a per-token fee.
In practical terms, accuracy at a fixed FPR of
Commercialdetectorstendtoprovidesomedocu-
5% represents how well each detector identifies
mentationoftheirperformancebutdisallowdirect
machine-generatedtextwhileonlymis-classifying
accesstothemodels. Wetestedthefollowing5:
5% of human-written text. The cost of a false
positive—ofmislabelingahuman-writtentextas
(i). Neural: RoBERTa-Base(GPT2),RoBERTa-
machine-generated—ishigh. Evaluatingdetectors
Large (GPT2), RoBERTa-Base (ChatGPT),
atafixedFPRallowsustocomparedetectorperfor-
RADAR
mancewhileunderstandingthepotentialforharm
(ii). Metric-Based: GLTR, Binoculars, Fast De-
morefully. Ourworkisoneofthefirstsharedre-
tectGPT,LLMDet
sourcestofixanddiscloseFPR,followingtherise
(iii). Commercial: GPTZero,Originality,Winston,
of this evaluation paradigm in recent robustness
ZeroGPT
research (Hans et al., 2024; Krishna et al., 2023;
Sotoetal.,2024).
Unlike Li et al. (2023b), we do not train our
ownneuralmodelsonourdatasetbecausewewish
toinvestigatethegeneralizationabilityofoff-the- 6 Findings
shelfdetectors. Forthemetric-baseddetectors,we
chosetousethedefaultgenerativemodelineach Finding 1: Detector accuracy varies substan-
repositorytoemulatethemostrealisticuse-case. tiallydependingonthefalsepositiverate(FPR)
AsshowninFigure4,thedetectorswetestedwere
DetectorEvaluation Detectorsworkbytaking
capable of achieving the high accuracies cited in
as input a sequence of tokens and outputting a
manyviralreports,butonlyatsimilarlyhighFPR.
scalar score. In order to convert this score to a
Some detectors failed to achieve the lowest FPR
binary prediction, we must select a scalar thresh-
wetested,plateauingat16.9%(ZeroGPT),0.88%
old δ such that if the score s ≥ δ the sequence is
(FastDetectGPT), and 0.62% (Originality). Most
predictedtobemachine-generated.
detectorsdroppedsteeplyasFPRdecreasedfrom
We tune the threshold for each model to yield
100%,butBinoculars(Hansetal.,2024)waspartic-
a 5% false positive rate. In other words, we en-
ularlystrongatlowFPR.Sincedetectoraccuracy
forceanerrorrateonthehuman-writtenportionof
variessomuchwithFPR,fixingandreportingFPR
4https://github.com/liamdugan/raid iscrucialforcomparable,informative,andrepro-
5SeeAppendixBformoredetailsoneachdetectortested ducibledetectionstudies.GPT2 GPT3 ChatGPT GPT4 Cohere Mistral MPT Llama Total
Chat?(Y/N) ✗ ✗ ✓ ✓ ✗ ✓ ✗ ✓ ✗ ✓ ✓ -
R-BGPT2 84.0 74.7 65.4 42.4 42.9 61.1 45.7 65.9 49.2 45.9 68.7 59.1
R-LGPT2 96.3 72.4 53.7 33.8 37.3 56.6 47.6 60.5 52.6 41.6 56.7 56.7
R-BCGPT 36.7 54.2 66.1 30.0 31.3 49.6 17.7 69.9 17.8 53.3 70.1 44.8
RADAR 64.7 88.6 82.1 76.0 51.4 77.2 54.1 83.6 58.0 76.5 78.5 70.9
GLTR 66.6 85.1 81.4 53.7 54.2 67.4 49.1 75.4 35.4 52.5 81.6 62.6
F-DetectGPT 72.1 95.4 96.1 73.9 84.7 85.1 58.2 81.3 45.3 57.1 94.0 73.6
LLMDet 48.2 40.2 18.9 27.0 32.6 35.6 31.5 35.7 28.2 21.4 55.1 35.0
Binoculars 68.9 99.2 99.6 91.9 94.8 95.4 62.3 91.7 45.2 70.8 97.6 79.6
GPTZero 38.8 70.1 99.4 97.1 43.9 74.6 28.9 95.6 24.8 85.9 98.5 66.5
Originality 99.1 98.2 98.2 89.9 78.9 90.6 71.0 95.5 58.1 76.2 94.7 85.0
Winston 47.6 77.8 99.6 98.8 63.6 86.2 46.1 94.9 24.8 79.2 97.5 71.0
ZeroGPT(*) 42.4 90.2 93.2 67.1 65.9 76.6 49.3 81.4 27.3 66.0 93.7 65.5
Table4: AccuracyatFPR=5%fordetectorsonnon-adversarialoutputsofdifferentmodels. Weseethatbasemodels
aremoredifficulttodetectthantheirchatfine-tunedcounterpartsandthatmetric-basedmethodsshowimpressive
cross-modelgeneralization. Asterisks(*)indicatethatthedetectorwasunabletoachievethetargetFPR.
1.0 HighestPerf. LowestPerf.
90 89
84 Detector (Acc@FPR=5%) (Acc@FPR=5%)
0.8
Originality ChatGPT,Sampling MPT,Greedy
69 70
66 63 (100%) +Penalty(14%)
0.6 58 RADAR GPT2,Greedy Mistral,Sampling
51
(100%) +Penalty(40.3%)
44
Binoculars GPT4,Greedy Mistral,Sampling
0.4
34
(100%) +Penalty(0.1%)
F-DetectGPT GPT4,Greedy MPT,Sampling
20
0.2 Greedy Greedy + Penalty (100%) +Penalty(0%)
Sampling Sampling + Penalty R-B(GPT2) GPT2,Greedy GPT4,Sampling
0.0 (100%) (6.7%)
Commercial Neural Metric-based
Table 5: Best to Worst Performance for the top five
Figure 5: Accuracy at FPR=5% (y-axis) vs. decod-
detectorsonnon-adversarialNewsdomaingenerations.
ing strategy across our three detector classes on non-
Weseethatseeminglystrong,robustdetectorsoftensud-
adversarialtext. Weseethatrepetitionpenaltygreatly
denlydeterioratefromperfectaccuracytototalfailure.
reducesaccuracyinbothgreedydecodingandsampling.
Finding2: Repetitionpenaltydrasticallyhurts Therearemanypossiblepenaltiesanddecoding
accuracyforalldetectors AsshowninFigure5, strategiesonecouldusewhengeneratingtextsuch
weobserveaconsistentpatternacrossdetectors,de- ascontrastivedecoding(Lietal.,2023a),etaand
tectorcategories,generators,anddomains: adding epsilondecoding(Hewittetal.,2022),andtypical
a repetition penalty decreases accuracy by up to sampling(Meisteretal.,2023)—allofwhichare
38pointsregardlessofdecodingstrategy. Thede- likelytoreducedetectoraccuracy. Wehighlyen-
codingstrategymattersaswell. Detectorsineach courage robustness studies and open evaluations
category,acrossdomainsandgenerators,perform toinvestigatehowwelldetectorscangeneralizeto
substantially better on greedy decoding than ran- alternativegenerationsettings,especiallyifgenera-
domsampling,evenwhentakingrepetitionpenalty tivemodelsarealreadytrainedonsuchoutputs.
intoaccount.
This pattern is especially concerning because Finding 3: Seemingly strong, robust detectors
paststudieshavelargelyoverlookedvariationsin canperformunexpectedlypoorly Thetopfive
decodingstrategywhenevaluatingdetectors. Fur- most accurate detectors on the news domain—
thermore,nonehavereportedresultsonrepetition FastDetectGPT,Originality,RADAR,Binoculars,
penaltybeforeourstudy. Sincesamplingwithrepe- RoBERTa-BGPT2—mayseemlikereliablesolu-
titionpenaltyresultsintextthatoftensoundsmore tions to detection in general, but they sometimes
human-like (Keskar et al., 2019), exposing these deterioratefromperfectaccuracytocompletefail-
patternsiscriticalforreliabledetection. ure (see Table 5). The changes in experimentalRoBERTa (GPT2) GPTZero RADAR
Books 0.987 0.588 0.287 0.548 0.405 1.000 1.000 0.265 0.768 0.992 0.965 0.689
News 0.996 0.694 0.415 0.640 0.280 1.000 1.000 0.190 0.810 0.999 0.999 0.663
Reddit 0.992 0.437 0.252 0.477 0.258 0.975 0.840 0.148 0.491 0.969 0.792 0.467
Reviews 0.976 0.612 0.387 0.462 0.455 0.995 1.000 0.320 0.222 0.004 0.007 0.118
Wiki 0.959 0.695 0.332 0.373 0.422 0.995 0.975 0.270 0.706 0.999 0.963 0.613
GPT2 ChatGPT GPT4 Mistral GPT2 ChatGPT GPT4 Mistral GPT2 ChatGPT GPT4 Mistral
Figure6: HeatmapmeasuringtheaccuracyoftheRoBERTaGPT2,GPTZero,andRADARdetectorsacrossmodels
anddomains. Weseeaclearbiastowardsdomainsandmodelsthatthedetectorshavetrainedon.
None Paraphrase Synonym Misspelling Homoglyph Whitespace DeleteArticles
R-LGPT2 56.7 72.9(+16.2) 79.4(+22.7) 39.5(-17.2) 21.3(-35.4) 40.1(-16.6) 33.2(-23.5)
RADAR 70.9 67.3(-3.6) 67.5(-3.4) 69.5(-1.4) 59.3(-11.6) 66.1(-4.8) 67.9(-3.0)
GLTR 62.6 47.2(-15.4) 31.2(-31.4) 59.8(-2.8) 24.3(-38.3) 45.8(-16.8) 52.1(-10.5)
Binoculars 79.6 80.3(+0.7) 43.5(-36.1) 78.0(-1.6) 37.7(-41.9) 70.1(-9.5) 74.3(-5.3)
GPTZero 66.5 64.0(-2.5) 61.0(-5.5) 65.1(-1.4) 66.2(-0.3) 66.2(-0.3) 61.0(-5.5)
Originality 85.0 96.7(+11.7) 96.5(+11.5) 78.6(-6.4) 9.3(-75.7) 84.9(-0.1) 71.4(-13.6)
Table6: AccuracyScoreatFPR=5%forselectdetectorsacrossdifferentadversarialattacks. Colorsindicatean
increase,slightincrease,slightdecrease,anddecreaseinperformance. Weseethatnotalladversarialattacksaffect
modelsequally—withsomeoccasionallyevenimprovingperformanceofdetectorsinsteadofharmingthem.
settingswerenotparticularlysophisticatedeither: tors perform better on domains and models seen
simplychangingthetextgenerator,switchingde- duringtraining. Someclosed-sourcemodelssuch
codingstrategies,orapplyingarepetitionpenalty asGPTZerodisplaysimilarbehavior,allowingus
was enough to introduce a 95+% error rate. Our to infer what data was used to train them. These
findings show that detectors tend not to general- findingsdemonstratetheneedformulti-generator
izeacrossdifferentmodelsorgenerationsettings training corpora, especially since many publicly
inthesamedomain. Compoundedbythelackof availableneuraldetectorsfocusononlyoneortwo
evaluationatdifferentfalsepositiverates,domain- generativemodels(Guoetal.,2023).
specificdetectorsforcriticalissueslikefakenews
Finding5: Differentdetectorsarevulnerableto
andeducationareparticularlyatriskofmislabeling
differentadversarialattacks InTable6,wesee
human-writtentextasmachine-generatedwithout
that Binoculars and other metric-based methods
ourawareness.
degrade as much as 36.1% when a small portion
Finding 4: Detectors perform better on do- of words are swapped with synonyms. All detec-
mains and models seen during training. Fig- torsweresensitivetohomoglyphattacksexceptfor
ure6showstheperformanceofRoBERTaGPT2, GPTZerowhichsustainedonlya0.3%lossunder
GPTZero,andRADARonacross-sectionofmod- thehomoglyphattackwhilefiveothersdroppedan
elsanddomainsfromRAID.WeseethatRoBERTa averageof40.6%. DetectorslikeRADARthatun-
GPT2 achieves 95+% accuracy on five domains derwentadversarialtraining,unsurprisingly,were
generatedbyGPT2,butitrarelyachievesbeyond much more robust to adversarial attacks. These
60% accuracy on text of the same domain from detector-dependentdifferencesinvulnerabilitysug-
differentmodels. Thisdetectorisopen-source,so gest that attacking an arbitrary detector without
weknowthatitwastrainedexclusivelyonGPT2in priorknowledgeofthedetectortypeortrainingdis-
anopen-domainsetting. Weobservesimilartrends tributionwillbedifficult. Adversariesmayrespond
with RADAR, as it performs uncharacteristically by attempting to discover what the detector was
poorlywhendetectingmoviereviewsregardlessof trainedon—whichourfindingshaveshowncould
generativemodel. bepossible—orattackingdetectorswithrepeated
Alldetectorsknowntohaveconstrainedtraining queries.
data skew heavily towards test data with similar In addition, we see that detector accuracy
characteristics, leading us to believe that detec- sometimes increases after an adversarial attack.RoBERTa GPT2, for example, improved after detectingspecificharmfulelements—likemisinfor-
texts were paraphrased with T5 and after words mation,hatespeech,andabuse—shouldtakeprece-
werereplacedwithBERT-basedsynonyms. GPT2, dence over whether or not the text was authored
RoBERTa, T5, and BERT are contemporaneous by a machine. Knowing if a text was machine-
models trained on similar data, leading us to be- generated,however,doesstillofferinsightsonthe
lievethatdetectorsbenefitfromadversarialattacks types of errors we can expect or the recency of
that inadvertently modify text to be more similar the facts cited within. We hope that our analyses
totheirtrainingdata. Ourpreviousfindingsonthe andtheRAIDdatasetareasteptowardafuturein
influenceoftrainingdataonperformancereinforce whichAIdetectiontoolsaresafelyintegratedinto
ourhypothesis. society as a multi-pronged approach to reducing
harm. Weencouragefutureworktobuildonthisby
7 Conclusion includingmoremodels,languages,andgeneration
settingsinfuturesharedresources.
Asthegenerationcapabilitiesoflanguagemodels
havecontinuedtoincrease,accuratelyandautomat- Limitations
icallydetectingmachine-generatedtexthasbecome
animportantpriority. Detectioneffortshaveeven While we attempt to cover a wide variety of do-
surpassedtheboundsofnaturallanguageprocess- mains,models,decodingstrategiesandadversarial
ingresearch,spurringdiscussionsbysocialmedia attacksinourdataset,werecognizethattherecan
companiesandgovernmentsonpossiblymandating neverbeatrulycomprehensivedatasetforrobust-
labelsformachine-generatedcontent. Despitethe ness. Inparticular,ourdatasetlackstheinclusion
protectiveintentionsofthesemandates,ourwork ofmultilingualtextandcode. Weencouragefuture
shows that such regulations would be difficult to worktoexpandonourfoundationanduseourtools
enforceeveniftheywereimplemented. Detectors tocreatetrulyrobustsharedbenchmarksinmany
arenotyetrobustenoughforwidespreaddeploy- languages.
mentorhigh-stakesuse: manydetectorswetested Furthermore,asthestate-of-the-artinlanguage
arenearlyinoperableatlowfalsepositiverates,fail modeling continues to improve, datasets of gen-
togeneralizetoalternativedecodingstrategiesor eratedtextwillnaturallyobsolesceandwillneed
repetition penalties, show clear bias towards cer- tobecontinuallymaintainedwithnewgenerations.
tainmodelsanddomains,andquicklydegradewith Thiscreatesissueswithsharedevaluationsasdetec-
simpleblack-boxadversarialattacks. torswillneedtobere-runonanynewdatasetitems
Thebulkofourfindingsmaysoundbleak, but andanyaccuracymetricswillhavetobeupdated.
we did uncover promising signs of improvement. While we believe this dataset will continue to be
Binoculars,forexample,performedimpressively usefulformanyyears,wedoacknowledgethislim-
well across models even at extremely low false itation and plan to alleviate this by occasionally
positiverates,Originalityachievedhighprecision releasingnewupdatedversions.
insomeconstrainedscenarios,andGPTZerowas Finally,andmostimportantly,theconceptofa
unusually robust to adversarial attacks. We be- publicbenchmarkforout-of-domainrobustnessis
lievethatopenlyevaluatingdetectorsonlarge,di- aninherentlylimitedone. Aspractitionersseekto
verse, shared resources is critical to accelerating improveperformanceonourbenchmarktheywill
progress—andtrust—indetection. Evaluatingro- undoubtedlyspecializetotheparticularaspectsof
bustnessisparticularlyimportantfordetection,and robustnesswecover. Thiswillleadtooverfitting,
it only increases in importance and the scale of evenifdetectorsarenotexplicitlytrainedonexam-
publicdeploymentgrows. ples. Such overfitting will result in the reappear-
Wealsoneedtorememberthatdetectionisjust anceofexactlytheproblemswewishedtoalleviate
one tool for a larger, even more valuable motiva- by creating this dataset, namely that detector ac-
tion: preventingharmbythemassdistributionof curaciesaregenerallyover-reported. Wetrustthat
text. Detectingmachine-generatedtextwasause- thisprocesswill,tosomeextent,bealleviatedby
ful proxy for identifying harmful text for a long regularreleasesofnewversionsandkeepingaset
time, but language models have improved to the ofhiddentestdataprivate. Thatbeingsaid,itdoes
point that generated text is frequently legitimate not nullify the utility of the dataset as a resource
andnotharmful(Schusteretal.,2020). Therefore, forprofilingrobustnessofclassifiers.EthicsStatement ShahryarBaki,RakeshVerma,ArjunMukherjee,and
Omprakash Gnawali. 2017. Scaling and effective-
Detectinggeneratedtextisoftenaccusatoryinna- nessofemailmasqueradeattacks: Exploitingnatural
language generation. In Proceedings of the 2017
ture and can frequently result in disciplinary or
ACMonAsiaConferenceonComputerandCommu-
punitive action taken against the accused party.
nications Security, ASIA CCS ’17, page 469–482,
Thiscancausesignificantharmevenwhendetec- New York, NY, USA. Association for Computing
torsarecorrect,butespeciallywhentheyareincor- Machinery.
rect. This is especially problematic given recent
DavidBammanandNoahA.Smith.2013. Newalign-
work by Liang et al. (2023c) showing that detec-
ment methods for discriminative book summariza-
torsarebiasedagainstnon-nativeEnglishwriters. tion.
Our results also support this and suggest that the
GuangshengBao, YanbinZhao, ZhiyangTeng, Linyi
problemoffalsepositivesremainsunsolved.
Yang,andYueZhang.2023. Fast-detectgpt:Efficient
For this reason, we are opposed to the use of zero-shot detection of machine-generated text via
detectors in any sort of disciplinary or punitive conditionalprobabilitycurvature.
context and it is our view that poorly calibrated
MeghanaMoorthyBhatandSrinivasanParthasarathy.
detectorscausemoreharmthantheysolve. There- 2020. Howeffectivelycanmachinesdefendagainst
fore, until better evaluation standards are widely machine-generated fake news? an empirical study.
In Proceedings of the First Workshop on Insights
adoptedinthedetectioncommunity,theuseofde-
fromNegativeResultsinNLP,pages48–53,Online.
tectorsinthisfashionshouldbediscouraged. We
AssociationforComputationalLinguistics.
intendforourworktobethestartofthisconversa-
tionandlookforwardtoafuturewheremachine-
MichałBien´,MichałGilski,MartynaMaciejewska,Wo-
jciech Taisner, Dawid Wisniewski, and Agnieszka
generated detectors are deployed in safe and re-
Lawrynowicz.2020. RecipeNLG:Acookingrecipes
sponsibleways. datasetforsemi-structuredtextgeneration. InPro-
ceedings of the 13th International Conference on
Acknowledgements NaturalLanguageGeneration,pages22–28,Dublin,
Ireland.AssociationforComputationalLinguistics.
This research is supported in part by the Office
StevenBirdandEdwardLoper.2004. NLTK:Thenatu-
of the Director of National Intelligence (ODNI), rallanguagetoolkit. InProceedingsoftheACLIn-
Intelligence Advanced Research Projects Activ- teractivePosterandDemonstrationSessions,pages
214–217,Barcelona,Spain.AssociationforCompu-
ity (IARPA), via the HIATUS Program contract
tationalLinguistics.
#2022-22072200005. Theviewsandconclusions
containedhereinarethoseoftheauthorsandshould PiotrBojanowski,EdouardGrave,ArmandJoulin,and
not be interpreted as necessarily representing the TomasMikolov.2017. Enrichingwordvectorswith
subwordinformation. TransactionsoftheAssocia-
official policies, either expressed or implied, of
tionforComputationalLinguistics,5:135–146.
ODNI,IARPA,ortheU.S.Government. TheU.S.
Government is authorized to reproduce and dis- TomB.Brown,BenjaminMann,NickRyder,Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
tributereprintsforgovernmentalpurposesnotwith-
Neelakantan,PranavShyam,GirishSastry,Amanda
standinganycopyrightannotationtherein.
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
References ClemensWinter,ChristopherHesse,MarkChen,Eric
Sigler,MateuszLitwin,ScottGray,BenjaminChess,
AadityaBhat.2023. Gpt-wiki-intro. Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Languagemodelsarefew-shotlearners.
EbtesamAlmazrouei,HamzaAlobeidli,AbdulazizAl-
shamsi, Alessandro Cappelli, Ruxandra Cojocaru,
Shuyang Cai and Wanyun Cui. 2023. Evade chatgpt
MérouaneDebbah,ÉtienneGoffinet,DanielHesslow,
detectorsviaasinglespace.
JulienLaunay,QuentinMalartic,DanieleMazzotta,
BadreddineNoune,BaptistePannier,andGuilherme Megha Chakraborty, S.M Towhidul Islam Tonmoy,
Penedo.2023. Thefalconseriesofopenlanguage SMMehediZaman,ShreyaGautam,TanayKumar,
models. KrishSharma,NiyarBarman,ChandanGupta,Vinija
Jain,AmanChadha,AmitSheth,andAmitavaDas.
Micael Arman. 2020. Poems dataset (nlp). 2023. CounterTuringtest(CT2): AI-generatedtext
https://www.kaggle.com/datasets/ detectionisnotaseasyasyoumaythink-introducing
michaelarman/poemsdataset. AIdetectabilityindex(ADI). InProceedingsofthe2023ConferenceonEmpiricalMethodsinNatural Rinaldo Gagiano, Maria Myung-Hee Kim, Xiuzhen
LanguageProcessing,pages2206–2239,Singapore. Zhang,andJenniferBiggs.2021. Robustnessanaly-
AssociationforComputationalLinguistics. sisofgroverformachine-generatednewsdetection.
In Proceedings of the The 19th Annual Workshop
Elizabeth Clark, Tal August, Sofia Serrano, Nikita of the Australasian Language Technology Associa-
Haduong,SuchinGururangan,andNoahA.Smith. tion,pages119–127,Online.AustralasianLanguage
2021. All that’s ‘human’ is not gold: Evaluating TechnologyAssociation.
humanevaluationofgeneratedtext. InProceedings
of the 59th Annual Meeting of the Association for ChujieGao,DongpingChen,QihuiZhang,YueHuang,
ComputationalLinguisticsandthe11thInternational YaoWan,andLichaoSun.2024. Llm-as-a-coauthor:
JointConferenceonNaturalLanguageProcessing Thechallengesofdetectingllm-humanmixcase.
(Volume1: LongPapers),pages7282–7296,Online.
AssociationforComputationalLinguistics. JiGao,JackLanchantin,MaryLouSoffa,andYanjun
Qi.2018. Black-boxgenerationofadversarialtext
NLPTeamCohere.2024. World-classai,atyourcom- sequencestoevadedeeplearningclassifiers.
mand. Accessed: 2024-02-02.
SebastianGehrmann,HendrikStrobelt,andAlexander
Rush.2019. GLTR:Statisticaldetectionandvisual-
Evan N. Crothers, Nathalie Japkowicz, and Herna L.
izationofgeneratedtext. InProceedingsofthe57th
Viktor.2023. Machine-generatedtext: Acomprehen-
AnnualMeetingoftheAssociationforComputational
sivesurveyofthreatmodelsanddetectionmethods.
Linguistics: SystemDemonstrations,pages111–116,
IEEEAccess,11:70977–71002.
Florence,Italy.AssociationforComputationalLin-
guistics.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
DerekGreeneandPádraigCunningham.2006. Practi-
deepbidirectionaltransformersforlanguageunder-
calsolutionstotheproblemofdiagonaldominance
standing. InProceedingsofthe2019Conferenceof
inkerneldocumentclustering. InProc.23rdInterna-
theNorthAmericanChapteroftheAssociationfor
tionalConferenceonMachinelearning(ICML’06),
ComputationalLinguistics: HumanLanguageTech-
pages377–384.ACMPress.
nologies,Volume1(LongandShortPapers),pages
4171–4186,Minneapolis,Minnesota.Associationfor
JesusGuerrero,GongboLiang,andIzzatAlsmadi.2022.
ComputationalLinguistics.
Amutation-basedtextgenerationforadversarialma-
chinelearningapplications.
LiamDugan,DaphneIppolito,ArunKirubarajan,and
ChrisCallison-Burch.2020. RoFT:Atoolforeval-
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang,
uating human detection of machine-generated text.
JinranNie,YuxuanDing,JianweiYue,andYupeng
InProceedingsofthe2020ConferenceonEmpirical
Wu.2023. Howcloseischatgpttohumanexperts?
Methods in Natural Language Processing: System
comparisoncorpus,evaluation,anddetection.
Demonstrations,pages189–196,Online.Association
forComputationalLinguistics.
Abhimanyu Hans, Avi Schwarzschild, Valeriia
Cherepanova, Hamid Kazemi, Aniruddha Saha,
Liam Dugan, Daphne Ippolito, Arun Kirubarajan, MicahGoldblum,JonasGeiping,andTomGoldstein.
Sherry Shi, and Chris Callison-Burch. 2023. Real 2024. Spotting llms with binoculars: Zero-shot
or fake text? investigating human ability to detect detectionofmachine-generatedtext.
boundaries between human-written and machine-
generated text. In Proceedings of the Thirty- JulianHazell.2023. Largelanguagemodelscanbeused
SeventhAAAIConferenceonArtificialIntelligence toeffectivelyscalespearphishingcampaigns. arXiv
andThirty-FifthConferenceonInnovativeApplica- preprintarXiv:2305.06972.
tionsofArtificialIntelligenceandThirteenthSympo-
sium on Educational Advances in Artificial Intelli-
XinleiHe,XinyueShen,ZeyuanChen,MichaelBackes,
gence,AAAI’23/IAAI’23/EAAI’23.AAAIPress.
andYangZhang.2023. Mgtbench: Benchmarking
machine-generatedtextdetection.
SalijonaDyrmishi,SalahGhamizi,andMaximeCordy.
2023. How do humans perceive adversarial text? John Hewitt, Christopher Manning, and Percy Liang.
a reality check on the validity and naturalness of 2022. Truncation sampling as language model
word-basedadversarialattacks. InProceedingsofthe desmoothing. InFindingsoftheAssociationforCom-
61stAnnualMeetingoftheAssociationforCompu- putationalLinguistics: EMNLP2022,pages3414–
tationalLinguistics(Volume1: LongPapers),pages 3427,AbuDhabi,UnitedArabEmirates.Association
8822–8836,Toronto,Canada.AssociationforCom- forComputationalLinguistics.
putationalLinguistics.
XiaomengHu,Pin-YuChen,andTsung-YiHo.2023.
Vitalii Fishchuk and Daniel Braun. 2023. Efficient Radar: Robustai-textdetectionviaadversariallearn-
black-box adversarial attacks on neural text detec- ing. Advances in Neural Information Processing
tors. Systems.Daphne Ippolito, Daniel Duckworth, Chris Callison- LongPapers),pages12286–12312,Toronto,Canada.
Burch, and Douglas Eck. 2020. Automatic detec- AssociationforComputationalLinguistics.
tion of generated text is easiest when humans are
fooled. InProceedingsofthe58thAnnualMeetingof Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue
theAssociationforComputationalLinguistics,pages Wang, Linyi Yang, Shuming Shi, and Yue Zhang.
1808–1822,Online.AssociationforComputational 2023b. Deepfaketextdetectioninthewild.
Linguistics.
Gongbo Liang, Jesus Guerrero, and Izzat Alsmadi.
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen- 2023a. Mutation-basedadversarialattacksonneural
sch,ChrisBamford,DevendraSinghChaplot,Diego textdetectors.
delasCasas,FlorianBressand,GiannaLengyel,Guil-
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris
laumeLample,LucileSaulnier,LélioRenardLavaud,
Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian
Marie-AnneLachaux,PierreStock,TevenLeScao,
Zhang,DeepakNarayanan,YuhuaiWu,AnanyaKu-
Thibaut Lavril, Thomas Wang, Timothée Lacroix,
mar,BenjaminNewman,BinhangYuan,BobbyYan,
andWilliamElSayed.2023. Mistral7b.
CeZhang,ChristianCosgrove,ChristopherD.Man-
NitishShirishKeskar,BryanMcCann,LavR.Varshney, ning,ChristopherRé,DianaAcosta-Navas,DrewA.
CaimingXiong,andRichardSocher.2019. Ctrl: A Hudson, Eric Zelikman, Esin Durmus, Faisal Lad-
conditionaltransformerlanguagemodelforcontrol- hak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue
lablegeneration. Wang,KeshavSanthanam,LaurelOrr,LuciaZheng,
Mert Yuksekgonul, Mirac Suzgun, Nathan Kim,
TiborKissandJanStrunk.2006. Unsupervisedmulti- NeelGuha, NiladriChatterji, OmarKhattab, Peter
lingualsentenceboundarydetection. Computational Henderson, Qian Huang, Ryan Chi, Sang Michael
Linguistics,32(4):485–525. Xie, Shibani Santurkar, Surya Ganguli, Tatsunori
Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav
DenisKocetkov, RaymondLi, LoubnaBenAllal, Jia Chaudhary,WilliamWang,XuechenLi,YifanMai,
Li,ChenghaoMou,CarlosMuñozFerrandis,Yacine Yuhui Zhang, and Yuta Koreeda. 2023b. Holistic
Jernite, Margaret Mitchell, Sean Hughes, Thomas evaluationoflanguagemodels.
Wolf,DzmitryBahdanau,LeandrovonWerra,and
HarmdeVries.2022. Thestack:3tbofpermissively Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric
licensedsourcecode. Preprint. Wu,andJamesZou.2023c. Gptdetectorsarebiased
againstnon-nativeenglishwriters.
RyutoKoike,MasahiroKaneko,andNaoakiOkazaki.
2023. Howyoupromptmatters! eventask-oriented YinhanLiu,MyleOtt,NamanGoyal,JingfeiDu,Man-
constraintsininstructionsaffectllm-generatedtext dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,
detection. Luke Zettlemoyer, and Veselin Stoyanov. 2019.
Roberta: A robustly optimized bert pretraining ap-
Kalpesh Krishna, Yixiao Song, Marzena Karpinska, proach.
John Wieting, and Mohit Iyyer. 2023. Paraphras-
ingevadesdetectorsofai-generatedtext,butretrieval NingLu,ShengcaiLiu,RuiHe,QiWang,Yew-Soon
isaneffectivedefense. Ong,andKeTang.2023. Largelanguagemodelscan
beguidedtoevadeai-generatedtextdetection.
PranavKulkarni,ZiqingJi,YanXu,MarkoNeskovic,
andKevinNolan.2023. Exploringsemanticpertur- Brady D Lund, Ting Wang, Nishith Reddy Mannuru,
bationsongrover. Bing Nie, Somipam Shimray, and Ziang Wang.
2023. Chatgptandanewacademicreality: Artificial
Tharindu Kumarage, Paras Sheth, Raha Moraffah, intelligence-written research papers and the ethics
JoshuaGarland,andHuanLiu.2023. Howreliable ofthelargelanguagemodelsinscholarlypublishing.
areai-generated-textdetectors? anassessmentframe- JournaloftheAssociationforInformationScience
workusingevasivesoftprompts. andTechnology,74(5):570–581.
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
ChiyuanZhang,DouglasEck,ChrisCallison-Burch, DanHuang, AndrewY.Ng, andChristopherPotts.
andNicholasCarlini.2022. Deduplicatingtraining 2011. Learningwordvectorsforsentimentanalysis.
datamakeslanguagemodelsbetter. InProceedings In Proceedings of the 49th Annual Meeting of the
of the 60th Annual Meeting of the Association for AssociationforComputationalLinguistics: Human
ComputationalLinguistics(Volume1: LongPapers), Language Technologies, pages 142–150, Portland,
pages8424–8445,Dublin,Ireland.Associationfor Oregon, USA. Association for Computational Lin-
ComputationalLinguistics. guistics.
XiangLisaLi,AriHoltzman,DanielFried,PercyLiang, Dominik Macko, Robert Moro, Adaku Uchendu, Ja-
Jason Eisner, Tatsunori Hashimoto, Luke Zettle- son Lucas, Michiharu Yamashita, Matúš Pikuliak,
moyer,andMikeLewis.2023a. Contrastivedecod- IvanSrba,ThaiLe,DongwonLee,JakubSimko,and
ing: Open-endedtextgenerationasoptimization. In MariaBielikova.2023. MULTITuDE:Large-scale
Proceedings of the 61st Annual Meeting of the As- multilingualmachine-generatedtextdetectionbench-
sociationforComputationalLinguistics(Volume1: mark. In Proceedings of the 2023 Conference onEmpiricalMethodsinNaturalLanguageProcessing, Xiao Pu, Jingyu Zhang, Xiaochuang Han, Yulia
pages9960–9987,Singapore.AssociationforCom- Tsvetkov,andTianxingHe.2023b. Onthezero-shot
putationalLinguistics. generalizationofmachine-generatedtextdetectors.
DominikMacko,RobertMoro,AdakuUchendu,Ivan Alec Radford, Jeff Wu, Rewon Child, David Luan,
Srba, Jason Samuel Lucas, Michiharu Yamashita, DarioAmodei,andIlyaSutskever.2019. Language
NafisIrtizaTripto,DongwonLee,JakubSimko,and modelsareunsupervisedmultitasklearners.
Maria Bielikova. 2024. Authorship obfuscation in
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
multilingualmachine-generatedtextdetection.
Lee,SharanNarang,MichaelMatena,YanqiZhou,
ClaraMeister,TiagoPimentel,GianWiher,andRyan WeiLi,andPeterJLiu.2020. Exploringthelimits
Cotterell.2023. Locallytypicalsampling. Transac- oftransferlearningwithaunifiedtext-to-texttrans-
tionsoftheAssociationforComputationalLinguis- former. TheJournalofMachineLearningResearch,
tics,11:102–121. 21(1):5485–5551.
Juan Diego Rodriguez, Todd Hay, David Gros, Zain
Eric Mitchell, Yoonho Lee, Alexander Khazatsky,
Shamsi,andRaviSrinivasan.2022. Cross-domain
Christopher D. Manning, and Chelsea Finn. 2023.
detectionofGPT-2-generatedtechnicaltext. InPro-
Detectgpt: zero-shotmachine-generatedtextdetec-
ceedingsofthe2022ConferenceoftheNorthAmer-
tionusingprobabilitycurvature. InProceedingsof
icanChapteroftheAssociationforComputational
the40thInternationalConferenceonMachineLearn-
Linguistics: HumanLanguageTechnologies,pages
ing,ICML’23.JMLR.org.
1213–1233, Seattle, United States. Association for
ComputationalLinguistics.
NLP Team MosaicML. 2023. Introducing mpt-30b:
Raisingthebarforopen-sourcefoundationmodels.
VinuSankarSadasivan,AounonKumar,SriramBala-
Accessed: 2023-06-22.
subramanian,WenxiaoWang,andSoheilFeizi.2023.
Canai-generatedtextbereliablydetected?
EdoardoMosca,MohamedHeshamIbrahimAbdalla,
PaoloBasso,MargheritaMusumeci,andGeorgGroh.
Areg Mikael Sarvazyan, José Ángel González, Paolo
2023. Distinguishing fact from fiction: A bench-
Rosso, and Marc Franco-Salvador. 2023a. Super-
markdatasetforidentifyingmachine-generatedsci-
visedmachine-generatedtextdetectors: Familyand
entificpapersintheLLMera. InProceedingsofthe
scale matters. In Experimental IR Meets Multilin-
3rdWorkshoponTrustworthyNaturalLanguagePro-
guality, Multimodality, and Interaction: 14th In-
cessing(TrustNLP2023),pages190–207,Toronto,
ternational Conference of the CLEF Association,
Canada.AssociationforComputationalLinguistics.
CLEF2023,Thessaloniki,Greece,September18–21,
2023, Proceedings, page 121–132, Berlin, Heidel-
OpenAI.2022. ChatGPT:OptimizingLanguageMod-
berg.Springer-Verlag.
elsforDialogue.
Areg Mikael Sarvazyan, José Ángel González, Marc
OpenAI.2023. Gpt-4technicalreport.
Franco-Salvador, Francisco Rangel, Berta Chulvi,
andPaoloRosso.2023b. Overviewofautextification
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
atiberlef2023: Detectionandattributionofmachine-
CarrollWainwright,PamelaMishkin,ChongZhang,
generatedtextinmultipledomains.
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
2022. Training languagemodelsto followinstruc-
TalSchuster,RoeiSchuster,DarshJ.Shah,andRegina
tions with human feedback. Advances in Neural
Barzilay. 2020. The limitations of stylometry for
InformationProcessingSystems,35:27730–27744.
detectingmachine-generatedfakenews. Computa-
tionalLinguistics,46(2):499–510.
Artidoro Pagnoni, Martin Graciarena, and Yulia
Tsvetkov.2022. Threatscenariosandbestpractices TatianaShamardina,VladislavMikhailov,DaniilCher-
to detect neural fake news. In Proceedings of the nianskii, Alena Fenogenova, Marat Saidov, Anas-
29thInternationalConferenceonComputationalLin-
tasiyaValeeva,TatianaShavrina,IvanSmurov,Elena
guistics,pages1233–1249,Gyeongju,Republicof
Tutubalina,andEkaterinaArtemova.2022. Findings
Korea. International Committee on Computational of the the ruatd shared task 2022 on artificial text
Linguistics. detectioninrussian. InComputationalLinguistics
andIntellectualTechnologies.RSUH.
Sayak Paul and Soumik Rakshit. 2021. arxiv paper
abstracts. https://www.kaggle.com/datasets/ FilipoSharevski,JenniferVanderLoop,PeterJachim,
spsayakpaul/arxiv-paper-abstracts. AmyDevine,andEmmaPieroni.2023. Talkingabor-
tion(mis)informationwithchatgptontiktok. In2023
J. Pu, Z. Sarwar, S. Abdullah, A. Rehman, Y. Kim, IEEEEuropeanSymposiumonSecurityandPrivacy
P.Bhattacharya,M.Javed,andB.Viswanath.2023a. Workshops(EuroS&PW),pages594–608.IEEE.
Deepfake text detection: Limitations and opportu-
nities. In 2023 IEEE Symposium on Security and IreneSolaiman,MilesBrundage,JackClark,Amanda
Privacy(SP),pages1613–1630,LosAlamitos,CA, Askell,ArielHerbert-Voss,JeffWu,AlecRadford,
USA.IEEEComputerSociety. Gretchen Krueger, Jong Wook Kim, Sarah Kreps,MilesMcCain,AlexNewhouse,JasonBlazakis,Kris Jian Wang, Shangqing Liu, Xiaofei Xie, and Yi Li.
McGuffie,andJasmineWang.2019. Releasestrate- 2023a. Evaluatingaigcdetectorsoncodecontent.
giesandthesocialimpactsoflanguagemodels.
YuxiaWang,JonibekMansurov,PetarIvanov,Jinyan
RafaelRiveraSoto,KailinKoch,AleemKhan,Barry Su,ArtemShelmanov,AkimTsvigun,ChenxiWhite-
Chen,MarcusBishop,andNicholasAndrews.2024. house,OsamaMohammedAfzal,TarekMahmoud,
Few-shotdetectionofmachine-generatedtextusing Alham Fikri Aji, and Preslav Nakov. 2023b. M4:
stylerepresentations. Multi-generator, multi-domain, and multi-lingual
black-boxmachine-generatedtextdetection.
GiovanniSpitale,NikolaBiller-Andorno,andFederico
MaxWeiss.2019. Deepfakebotsubmissionstofederal
Germani.2023. Aimodelgpt-3(dis)informsusbet-
public comment websites cannot be distinguished
terthanhumans. ScienceAdvances,9(26):eadh1850.
fromhumansubmissions. TechnologyScience.
Harald Stiff and Fredrik Johansson. 2022. Detecting
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
computer-generated disinformation. International
Chaumond,ClementDelangue,AnthonyMoi,Pier-
JournalofDataScienceandAnalytics,13:363–383.
ricCistac,TimRault,RémiLouf,MorganFuntow-
icz,JoeDavison,SamShleifer,PatrickvonPlaten,
ZhenpengSu,XingWu,WeiZhou,GuangyuanMa,and Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
SonglinHu.2024. Hc3plus: Asemantic-invariant Teven Le Scao, Sylvain Gugger, Mariama Drame,
humanchatgptcomparisoncorpus. QuentinLhoest,andAlexanderM.Rush.2020. Hug-
gingface’stransformers: State-of-the-artnaturallan-
EdwardTianandAlexanderCui.2023. Gptzero: To- guageprocessing.
wardsdetectionofai-generatedtextusingzero-shot
andsupervisedmethods. MaxWolff.2020. Attackingneuraltextdetectors.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- KangxiWu,LiangPang,HuaweiShen,XueqiCheng,
bert, Amjad Almahairi, Yasmine Babaei, Nikolay andTat-SengChua.2023. LLMDet: Athirdparty
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti largelanguagemodelsgeneratedtextdetectiontool.
Bhosale,DanBikel,LukasBlecher,CristianCanton InFindingsoftheAssociationforComputationalLin-
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu, guistics:EMNLP2023,pages2113–2133,Singapore.
JudeFernandes,JeremyFu,WenyinFu,BrianFuller, AssociationforComputationalLinguistics.
CynthiaGao,VedanujGoswami,NamanGoyal,An-
HanXu,JieRen,PengfeiHe,ShenglaiZeng,Yingqian
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Cui,AmyLiu,HuiLiu,andJiliangTang.2023. On
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
thegeneralizationoftraining-basedchatgptdetection
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
methods.
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
YaomingZhu,SidiLu,LeiZheng,JiaxianGuo,Weinan
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
Zhang,JunWang,andYongYu.2018. Texygen: A
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
benchmarkingplatformfortextgenerationmodels.
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama- A DatasetDetails
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu, A.1 Domains
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurelien Ro- InTable7wereporttheexactnumberofdocuments
driguez,RobertStojnic,SergeyEdunov,andThomas sampledfromeachdomain. TheReviewsdomain
Scialom.2023. Llama2: Openfoundationandfine- didnothave2,000documentsandsowesampled
tunedchatmodels.
themaximumamount. Foreachdomain, wepro-
vide a detailed list of all human-written sources
Adaku Uchendu, Zeyu Ma, Thai Le, Rui Zhang, and
Dongwon Lee. 2021. Turingbench: A benchmark withmetadataalongwiththeRAIDdatasetinthe
environmentforturingtestintheageofneuraltext supplementarymaterialsandinourGitHubreposi-
generation.
tory. Adetaileddescriptionofthecontentsofeach
domainisasfollows:
VivekVerma,EveFleisig,NicholasTomlin,andDan
Klein.2023. Ghostbuster: Detectingtextghostwrit-
PaperAbstracts (PaulandRakshit,2021)This
tenbylargelanguagemodels.
is a dataset of abstracts scraped from ArXiv to-
Michael Völske, Martin Potthast, Shahbaz Syed, and gether with paper titles. For this dataset and this
BennoStein.2017. TL;DR:MiningReddittolearn dataset only, we filter the data such that only pa-
automatic summarization. In Proceedings of the
persfrom2023orlaterarepresentinthedata. This
WorkshoponNewFrontiersinSummarization,pages
allowsustoruleoutthepossibilitythatourmodels
59–63,Copenhagen,Denmark.AssociationforCom-
putationalLinguistics. havememorizedthistext.Book summaries (Bamman and Smith, 2013) Dataset Genre Size
This dataset contains plot-centric summaries of
(PaulandRakshit,2021) Abstracts 1966
booksalongwiththeirtitles. Wechosethisdataset (BammanandSmith,2013) Books 1981
(GreeneandCunningham,2006) News 1980
duetothefirst-personnarrativestyleandbecause
(Arman,2020) Poetry 1971
weexpectgeneratorsanddetectorswithknowledge (Bien´etal.,2020) Recipes 1972
ofthesourcematerialtohaveanadvantage. (Völskeetal.,2017) Reddit 1979
(Maasetal.,2011) Reviews 1143
(AadityaBhat,2023) Wiki 1979
BBCNewsArticles (GreeneandCunningham,
2006)ThisdatasetcontainsBBCarticleswithas-
Table 7: The number of articles sampled from each
sociated titles. The articles are spread out evenly
domainwiththeircorrespondingsources
across 5 categories (sport, technology, entertain-
ment, politics, and business). This dataset was
Model Identifier
chosen since good generation requires factuality
GPT-2 gpt2-xl
andbecauseNewsisalargeareaforLLM-based
(Radfordetal.,2019)
harm.
MPT(+Chat) mpt-30b
Poems (Arman,2020)Thisdatasetcontainspo- (MosaicML,2023) mpt-30b-chat
emscollectedfrompoemhunter.comwiththeirti-
Mistral(+Chat) Mistral-7B-v0.1
tlesandgenre. Thepoemsarerandomlyspreadout (Jiangetal.,2023) Mistral-7B-Instruct-v0.1
overgenresandtopics. WehypothesizethatLLMs
LLaMAChat Llama-2-70b-chat-hf
willwritegenericandrepetitivepoetryandthatthis
(Touvronetal.,2023)
tendencyshouldbedetectable.
Cohere(+Chat) command (co.generate())
Recipes (Bien´ etal.,2020)Thisdatasetconsists (Cohere,2024) command (co.chat())
ofrecipesandtheirdishnames. Recipesareacom-
GPT-3 text-davinci-002
bination of a list of ingredients and a numbered (Ouyangetal.,2022)
listofsteps. Thisdatasetisdifficultbecauseitre-
ChatGPT gpt-3.5-turbo-0613
quiressignificantcommonsensereasoning,which (OpenAI,2022)
isdifficultformodels.
GPT-4 gpt-4-0613
(OpenAI,2023)
RedditPosts (Völskeetal.,2017)Thisdataset
contains reddit posts and their titles. We hypoth-
Table8: Thegenerativemodelsusedinourproject
esize that such data will be challenging to detect
duetothefirst-personandinformalstyle.
proprietaryAPIsfromCohere6 andOpenAI7.The
MovieReviews (Maasetal.,2011)Thisdataset
followingisadetailedlistofthegenerativemodels
containsmoviereviewsfromIMDbalongwiththe
usedintheproject.
namesofthemovies. Theformalityofthereviews
are varied and this tests model’s ability to recall GPT2 XL 1.5B (Radford et al., 2019) is a
detailsfrommoviesaswellasgenerateanddetect decoder-onlymodeltrainedontheWebTextdataset.
opinionatedtext. This dataset consists of a collection of all docu-
ments that were linked from reddit posts or com-
Wikipedia (Aaditya Bhat, 2023) This dataset
mentsthathadatleast3ormoreupvotes. Released
containsintroductionstovariousWikipediaarticles.
inFebruaryof2019andhaving1.5Bparameters,
This dataset is challenging as it tests the models
GPT2isthepredecessorofGPT3andGPT4and
abilitytoaccuratelyrecallfactsrelatingtospecific
themostpowerfulopen-sourcedOpenAIlanguage
historicalevents.
model.
A.2 GenerativeModels GPT3 (Ouyang et al., 2022) is a closed-source
languagemodelreleasedbyOpenAIonNovember
InTable8welisttheexactgenerativemodelsused
29th,2022. Themodelwasallegedlytrainedwith
in our project along with their unique identifiers.
avarietyofdataincludingtheCommonCrawl(fil-
All open-source models were run using the Hug-
gingFacetransformerslibrary(Wolfetal.,2020)
6https://docs.cohere.com/reference/about
and all closed-source models were run using the 7https://platform.openai.com/docs/introductiontered),WebText2,andWikipediadatasets(Brown for the model is not and no details have been re-
etal.,2020)butexactcompositionofthetraining leasedregardingthemakeupofthisdata.
datasetisunknown. Itisthefirstmodelshownto
MPT30B (MosaicML,2023)isadecoder-only
workwellwithpromptsandhasshowngreatzero-
modeltrainedbyMosaicandisthefirstmodelre-
andfew-shotcapabilities. Inthisstudy,weusethe
leased by the company. Released on June 22nd
text-davinci-003model. Wequeriedthemodel
2023,MPT30Bhasan8kcontextwindowandout-
fromNovember1sttoNovember2nd2023. Unfor-
performsGPT-3onvariousreasoningtasks. Train-
tunately,asofJanuary4th2024,thismodelisno
ingdataconsistsofdeduplicatedC4(Raffeletal.,
longeravailableforuseontheOpenAIAPI.While
2020; Lee et al., 2022), the RedPajama9 split of
thisdidnotaffectusaswehadalreadyfinalizedour
CommonCrawl, and selected programming lan-
dataset,itdoespreventusfromexpandingthedo-
guagesfromTheStack(Kocetkovetal.,2022).
mainsinfuturereleases. Weencourageresearchers
to keep this in mind when using OpenAI models Cohere command (Cohere, 2024) is a closed-
fortheirresearchprojects. source model trained and released by Cohere.
Whileoriginalversionsofthismodelwerequoted
ChatGPT (OpenAI,2022)isaversionofGPT- as having roughly 50 billion parameters (Liang
3.5fine-tunedusingReinforcementLearningfrom etal.,2023b),thesizeandtrainingdataofthecur-
Human Feedback (RLHF) (Ouyang et al., 2022). rentversionoftheCoheremodelisunknown. Un-
WeusetheJune13th2023checkpointofthemodel likeOpenAI,Coheredoesnotversionthecommand
(gpt-3.5-turbo-0613). Althoughthenumberof modelandso,muchlikewithtext-davinci-003
parameters is unknown, ChatGPT demonstrates we are unable to expand our dataset to new do-
outstandingcapabilityinlanguageandcodegener- mains without re-generating all generations. We
ation. queried the command model through both the
co.generate() and co.chat() endpoints from
GPT4 (OpenAI, 2023) is the latest iteration
November1sttoNovember2nd2023.
of OpenAI’s GPT family of models and is still
the largest and most powerful language model A.3 Prompts
available to date. In this study, we use the
InTable9wereporttheprompttemplatesforeach
gpt-4-0613checkpointofthemodelthroughthe
of the 8 domains used in our project. We specifi-
ChatCompletioninterface8. Wequeriedthemodel
cally avoided biasing the model towards a partic-
fromNovember1sttoNovember2nd2023.
ular length or style of generation and did not use
anyofthetextfromthehuman-writtendocuments
LLaMA 2 70B (Touvron et al., 2023) is a
otherthanthetitlewhenprompting.
decoder-only model trained by Meta (Facebook)
Todecideontheparticularformofourprompts,
andisthesecondmodelintheLLaMAseries. Re-
weconductedtworoundsofmanualreview. These
leased on July 18th 2023, LLaMA 2 is the suc-
roundsconsistedoftheauthorsdeterminingprob-
cessor to the original LLaMA model which was
lematicpromptsbymanuallyreviewing10gener-
trainedonwebpagesfromCommonCrawl,multi-
ations per model in each domain for instances of
lingualWikipedia,booksfromProjectGutenberg,
degeneraterepetition, meta-commentaryorother
andQAsfromStackExchange. Thecomposition
signsofgeneratedoutput. Inproblematicdomains,
of LLaMA 2’s training data is not known but it
weconductedindividualexplorationstodetermine
hasshownimpressiveperformanceonmanyopen-
ifthereexistedsomehighlevelpromptingconcept
sourceevaluationsandiswidelyconsideredcom-
thatremovedtheunintendedbehaviorandwhether
petitivewiththeopen-sourcestate-of-the-art.
ornotusingsuchapromptstylecausedregressions
acrossothergenerators. Afteridentifyingadesired
Mistral7B (Jiangetal.,2023)isadecoder-only
promptingchange,were-wroteourtemplatesand
modeltrainedbyMistralandisthefirstmodelre-
restartedthereviewprocess.
leased by the company. Released on September
Through this investigation, we found that
27,2023,Mistral7BoutperformsLLaMA213B
continuation-stylemodelsbenefitgreatlyfromex-
acrossvariousbenchmarksathalfthesize. While
plicitly stating the source website in the prompt
model weights are open-source, the training data
9https://www.together.ai/blog/
8https://platform.openai.com/docs/guides/chat redpajama-data-v2and that chat-stylemodels benefit from language sampleθpercentofthosespansandaddthedouble
explicitlyaskingthemnottorepeatthetitleofthe newline character \n\n in-between the sentences
article (See Table 9). While we were unable to tosimulateaparagraphbreak.
remove all instances of degenerate repetition or
NumberSwap Forthisattackweusethefollow-
meta-commentary,thisinvestigationsignificantly
ing regular expression to extract all instances of
increasedthequalityofourdatasetandweencour-
numerical digits in the generation: "\d+.?\d*".
age future work on dataset creation to conduct a
Wethenrandomlyselectθ percentofthesedigits
similarprocesswhenengineeringtheirprompts.
to modify and for each digit we randomly select
A.4 AdversarialAttacks analternatenumberbetween0and9toreplacethe
characterwith.
InTable10welisttheattacksusedalongwiththe
attackrateθandtherelevantsourcesfortheattacks. Paraphrase For paraphrasing we run the
Inthissectionwewilllisttheattacksinmorede- DIPPER-11Bmodel11 fromKrishnaetal.(2023)
tailanddiscussthevariousdesigndecisionsmade. throughHuggingFace(Wolfetal.,2020). DIPPER
Implementationsforallattackscanbefoundinour is a fine-tuned version of T5-11B (Raffel et al.,
GitHubrepository. 2020) specifically made for paraphrasing text to
avoid machine-generated text detectors. We use
Alternative Spelling We use an American to
thedefaultsettingsfromthepaper,namelyasen-
BritishEnglishdictionary10toconstructamapping
tenceintervalof3withlexicaldiversityof60and
betweenAmericanandBritishspellingsofwords.
orderdiversityof0. Sinceparaphrasesarenotin-
Wethenfindallinstancesofsuchwordsinthegen-
herently noticeable when models are correct, we
eration(defaultingtothelongestavailablematchif
areabletoapplythisattackacrosstheentiretyof
thereweremultiplesubstringmatchesforthesame
theoutputtext(θ = 100%).
token). Wethenrandomlysampleafixedpercent-
ageθ ofthepossiblemutationstomakewithaset Misspelling For this attack, we manually con-
seedandapplytheattackatthoseindices. structed a dictionary of common misspellings12
andonlyappliedtheattacktoinstancesofwords
ArticleDeletion Wesearchthroughthetextand
that have misspellings in our dictionary. We did
find every instance of the articles “a”, “an”, and
thistominimizesuspicionfromhumanreaders,as
“the”. Wethenrandomlysampleafixedpercentage
certaincommonwordssuchas‘the’or’him’are
θ ofthepossiblemutationstomakewithasetseed
rarely misspelled. Instead of randomly selecting
andapplytheattackatthoseindices.
θ percent of the possible candidate words to mis-
spell,wefollowGagianoetal.(2021)andmisspell
Homoglyph Homoglyphsarecharacterthatare
onlythetopθ percentmostlikelycandidatewords
non-standard unicode characters that strongly re-
by log likelihood as determined by GPT 2 small.
semblestandardEnglishletters. Thesearetypically
This allows us to choose only the most effective
charactersusedinCyrillicscripts. Weusetheset
misspellingstoapply.
ofhomoglyphsfromWolff(2020)whichincludes
substitutionsforthefollowingstandardASCIIchar- Synonym Forthisattackweoriginallyplannedto
acters: a, A,B,e, E,c, p, K,O,P,M,H,T,X,C, usetheDFTFooleralgorithmfromPuetal.(2023a).
y, o, x, I, i, N, and Z. We limit ourselves to only However,wefoundthecandidatesynonymstobe
homoglyphsthatareundetectabletotheuntrained oflowqualityandeasilydetectablebyourmanual
humaneye,thusweareabletouseanattackrateof analysis. Thuswedecidedtoimplementourown
θ = 100%andapplytheattackoneverypossible
algorithmbasedlargelyonDFTFooler. Ouralgo-
character. Forcharactersthathavemultiplepossi- rithmproduceshigh-qualityanddiversesynonym
blehomoglyphswerandomlychoosebetweenthe substitutions without relying on any of the large
homoglyphs. decoder-onlylanguagemodelsusedforgeneration.
Westartbyiteratingoveralltokensinthegener-
InsertParagraphs Forthisattack,weagainsplit
ation. Foreachtokeniwereplaceitwithamask
sentencesusingPunkt(KissandStrunk,2006)and
constructalistofallinter-sentencespans. Wethen 11https://huggingface.co/kalpeshk2011/
dipper-paraphraser-xxl
10https://github.com/hyperreality/ 12https://en.wikipedia.org/wiki/Commonly_
American-British-English-Translator misspelled_English_wordsContinuation-StylePrompt Chat-StylePrompt
Abstracts The following is the full text of the abstract for a Writetheabstractfortheacademicpapertitled"{ti-
researchpapertitled"{title}"fromarxiv.org: tle}".
Books Thefollowingisthefulltextofaplotsummaryfora Writethebodyofaplotsummaryforanoveltitled
noveltitled"{title}"fromwikipedia.org: "{title}".Donotgiveitatitle.
News Thefollowingisthefulltextofanewsarticletitled WritethebodyofaBBCnewsarticletitled"{title}".
"{title}"frombbc.com: Donotrepeatthetitle.
Poetry Thefollowingisthefulltextofapoemtitled"{title}" Write the body of a poem titled "{title}". Do not
frompoemhunter.com: repeatthetitle.
Recipes Thefollowingisthefulltextofarecipeforadish Writearecipefor"{title}".
called"{title}"fromallrecipes.com:
Reddit Thefollowingisthefulltextofaposttitled"{title}" WritejustthebodyofaRedditposttitled"{title}".
fromreddit.com: Donotrepeatthetitle.
Reviews The following is the full text of a review for the Write the body of an IMDb review for the movie
movie"{title}"fromIMDb.com: "{title}".Donotgiveitatitle.
Wiki Thefollowingisthefulltextofanarticletitled"{ti- WritethebodyofaWikipediaarticletitled"{title}".
tle}"fromwikipedia.com:
Table9: Thetextofthegenerationpromptsforalltendatasetsinbothcontinuationandchatstyle. Thefield{title}
wasreplacedwiththetitleofthebook,dish,ornewsarticlebeforebeingpassedintothegenerativemodel.
Attack θ Source FastText(Bojanowskietal.,2017)embeddingsfor
allcandidatesubstitutionsandrejectalltokensthat
AlternativeSpelling 100% (Liangetal.,2023c)
ArticleDeletion 50% (Liang et al., 2023a; havecosinesimilarityoflessthan0.5withtheorig-
Guerreroetal.,2022)
inaltoken. Doingthisforeachindexigivesusa
Homoglyph 100% (Wolff, 2020; Gagiano
etal.,2021) globallistofallvalidcandidateswapsacrossthe
InsertParagraphs 50% (BhatandParthasarathy, entiregeneratedpassage. Fromthislistweselect
2020)
the θ · L most likely synonym swaps according
NumberSwap 50% (BhatandParthasarathy,
2020) to BERT where L is the length (in tokens) of the
Paraphrase 100% (Krishna et al., 2023; passage.
Sadasivanetal.,2023)
Misspelling 20% (Liang et al., 2023a; Thefullcodeforthisalgorithmcanbefoundin
Gagiano et al., 2021; ourprojectrepositoryalongwiththeimplementa-
Gaoetal.,2018)
tionsoftheotheradversarialattacks.
Synonym 50% (Puetal.,2023a)
UpperLower 5% (Gagianoetal.,2021)
Whitespace 20% (Cai and Cui, 2023;
Upper-Lower Thisattackrandomlyselectssome
Gagianoetal.,2021)
Zero-WidthSpace 100% (Guerreroetal.,2022) θ percent of the tokens in the passage and swaps
the first letter of the token to be uppercase if it
Table10: Theadversarialattacksusedintheproject. θ was lowercase and lowercase if it was originally
representsthemanuallydeterminedfractionofavailable
uppercase.
attackscarriedout. Wedeterminethisfractionthrough
manualreview.
Whitespace Thisattackrandomlyselectssome
θ percent of inter-token spaces and adds an extra
tokenandgetthetop20mostlikelymask-fillcan- spacecharacterinbetweenthetokens. Thiscanoc-
didates13 accordingtoBERT(Devlinetal.,2019). casionallyresultinmultiplespacesaddedbetween
We then compute the part-of-speech tag for each twotokensassamplingisdonewithreplacement.
candidateusingNLTK(BirdandLoper,2004)and
rejectallcandidatesthatdonotmatchthepart-of- Zero-Width Space The unicode zero-width
speechoftheoriginaltoken. Wethengetthestatic space U+200B is a character that exists in text en-
codingbutisnotvisibletohumanreadersinmost
13InordertoreducecomputationtimewelimitBERTto scenarios. Thus,forthisattackweinsertthischar-
awindowof20tokensoneithersideoftheindexwhende-
acterateverypossibleopportunity(beforeandafter
terminingthemask-fillcandidates.Wefoundnoreductionin
candidatequalityfromthismodification. eachvisiblecharacterinthegeneration).A.5 RepetitionPenaltyvs. FrequencyPenalty RoBERTa(GPT2) (Solaimanetal.,2019)This
vs. PresencePenalty detector15 isaRoBERTamodel(Liuetal.,2019)
fine-tunedontheGPT2outputdataset. Thisdataset
GivenatemperatureT > 0andasetofscoresx ∈
i
Rd foreachtokeniinavocabulary,theprobability consists of outputs from GPT2 in open domain
settings with three different decoding strategies:
p ofpredictingtheithtokenisgivenby:
i
greedydecoding,top-k=50,andfullyrandomsam-
exp(x /T) pling and has been a baseline inclusion for many
i
p =
i (cid:80) exp(x /T) years. Weuseboththebaseandlargesizeofthis
j j
modelinourcomparisons.
The repetition penalty defined by Keskar et al.
RoBERTa (ChatGPT) (Guo et al., 2023) This
(2019)modifiesthisdistributionasfollows:
detector is a RoBERTa-base model (Liu et al.,
exp(x /(T ·I(i ∈ g))) 2019) fine-tuned on the HC3 dataset. HC3 con-
i
p =
i (cid:80) sists of roughly 27,000 questions paired with
exp(x /(T ·I(j ∈ g)))
j j
both human and ChatGPT answers in various
t = i ∼ p domains such as reddit, medicine, finance, and
law. We download and query the detector via
Wheregisalistofpreviouslygeneratedtokensand HuggingFace datasets with the unique identifier
I(c) = θ ifcisTrueelse1. OpenAIimplementsa Hello-SimpleAI/chatgpt-detector-roberta
form14 of this penalty (referred to as a ‘presence
penalty’) which is additive instead of multiplica- RADAR (Huetal.,2023)Thisdetectorisafine-
tive: tunedversionofVicuna7B(whichitselfisafine-
tuneofLLaMA7B).Itwastrainedinagenerative
exp((x /T)−I(i ∈ g))
i adversarial setting alongside a paraphrase model.
p =
i (cid:80)
jexp((x j/T)−I(j ∈ g)) Theparaphraserwastrainedspecificallytofoolthe
detectorandthedetectorwastrainedtoaccurately
Cohere (as of May 13th 2024) provides no docu-
detect generations from the paraphraser, human-
mentationonthenatureoftheirpresencepenalty
textfromtheWebTextdataset,andoutputsfromthe
despite requests from the authors for the proper
originallanguagemodel. Wedownloadandquery
documentation.
this detector from HuggingFace with the unique
identifierTrustSafeAI/RADAR-Vicuna-7B
A.6 Hardware
Weranourgenerationsoverthecourseof15days GLTR (Gehrmann et al., 2019) Originally in-
fromNovember1st2023toNovember15th2023 tended as an interface to help humans better de-
on 32 NVIDIA 48GB A6000 GPUs. We ran all tectgeneratedtext,GLTRhasbecomeastandard
modelswith16-bitprecisionaswefoundthatout- baselineinrobustnessstudiesofdetectorabilities.
puts were identical to full precision and it cut GLTRevaluatesthelikelihoodoftextaccordingto
our inference time in half. The amount of GPU alanguagemodelandbinstokensaccordingtotheir
hours used by each family of models is as fol- likelihoodsandusesthesebinsasfeaturesforde-
lows: LLaMA270B(+Chat)8,376hours,MPT tection. WeusethedefaultsettingsfromtheGLTR
(+Chat)5,440hours,Mistral(+Chat)672hours, repository16 namelyourcutoffsetatrank=10and
GPT2(+Chat)352hours. Intotalweused14,872 thelanguagemodelsettoGPT2small.
GPUhours(620GPUdays)togeneratetheRAID
FastDetectGPT (Bao et al., 2023) This detec-
dataset.
torisanimprovementontheoriginalDetectGPT
(Mitchelletal.,2023)—speedingupinferenceby
B DetectorDetails
340x without any reduction in accuracy. For the
B.1 Detectors scoringmodelweusetherepositorydefaultofGPT-
Neo-2.7B and for the reference model we again
Inthissectionweprovideadetaileddescriptionof
all detectors used in the evaluations of the RAID 15We download the model hosted by OpenAI from the
dataset. following link https://openaipublic.azureedge.net/
gpt-2/detector-models/v1/detector-large.pt
14https://platform.openai.com/docs/guides/ 16https://github.com/HendrikStrobelt/
text-generation/parameter-details detecting-fake-textusethedefaultofGPT-J-7B.Sinceneitherofthese B.2 Thresholds
modelswereusedtogeneratecontinuationsinour
Inordertofindthethresholdsthatachieveafixed
dataset,wefeltthatthiswasareasonablechoice.
falsepositiverateswehadtoimplementsomeba-
Binoculars (Hansetal.,2024)Thisdetectoruses sicsearchprocedure. Wesearchedourthresholds
perplexitydividedbycross-entropybetweentwo inalinearfashion: Westartatavalueof0.5and
verysimilarlanguagemodelsasthemetricforde- approachthedesiredfalsepositiverate. Ifweover-
tection. In our implementation we use the code shootthevaluewedivideourstepsizeinhalfand
fromtheofficialGitHubrepositoryandcalculate flipthesign. Wecontinuetodothisuntilthefalse
perplexityusingthedefaultmodelsfromtherepos- positive rate is within ϵ = 0.0005 of the desired
itory, namely Falcon 7B and Falcon 7B Instruct falsepositiverateoruntil50iterationsarereached.
(Almazrouei et al., 2023). Much like FastDetect- In Table 11 we list the thresholds our algorithm
GPT, since neither of these models were used to foundforeachdetectoralongwiththeexactfalse
generatecontinuations,webelievedthismadefor positiveratesthatthesethresholdsallow.
afaircomparison.
B.3 DefaultFalsePositiveRates
LLMDet (Wu et al., 2023) This detector com-
In Table 12 we report the results of the detectors
putes the proxy-perplexity of the input text from
on the human-written portion of the dataset with
10differentsmalllanguagemodelsandusesthese
commonvaluesforthresholds. Wecanseethatneu-
featuresfordetection. Theproxy-perplexityisan
ralclassifiersoftengethighfalsepositiveratesfor
approximationofthetrueperplexitycalculatedby
thesethresholds—frequentlyover10%andnever
repeatedly sampling n-grams from models rather
under1%. Thisisconcerningasitsuggeststhatin
thanbyactuallyrunningthem. Ofthemodelsused,
ordertosafelydeployanyopen-sourceneuralde-
none of them were used for generations in our
tector,onemustfirstcalibrateitonasetofhuman-
dataset,thusthiswasafaircomparison.
written data in the target domain. We encourage
GPTZero (Tian and Cui, 2023) GPTZero is a future work to investigate better methods of cali-
closed-source commercial detector and was the bratingclassifierssuchthattheyachievelowfalse
firsttoprominentlyadoptthedetection-as-a-service positiveratesatthresholdsof0.5.
business model. We queried the detector on Jan-
uary24th2024usingthev2API17 andthreshold C ExtendedFiguresandTables
onthecompletely_generated_probfield.
C.1 DatasetStatisticsandEvaluations
Originality This detector is another prominent
In Figures 7 and 8 we report extended statistics
closed-source commercial detector. We queried
aboutthedataset. Weseesomeinterestingtrends
thisdetectorfromJanuary24thto25ththroughthe
here, namely that human-written text is still sig-
v1API18 andthresholdonthe‘score’fieldinthe
nificantlylesslikelythanmachine-generatedtext
outputJSON.
according to LLaMA 2 7B and that it is also the
Winston Thisdetectoristheclosed-sourcecom- leastrepetitive. Theseresultspushbackonclaims
mercial detector that claims the highest accuracy thatlanguagemodelsareapproachinghuman-level
outofanydetector(99.98%). Wequerythismodel performance and therefore detection is unreason-
throughthev1API19 andthresholdonthe‘score’ ablydifficult.
fieldintheoutputJSON.
C.2 ExtendedHeatmaps
ZeroGPT Thisdetectoristhefinalcommercial
InFigure9weshowtheextendedheatmapsfrom
detector. Werunthisasitistheonlydetectorbe-
Figure6inthemainpaper. Weseethatthetrend
sidesGPTZerothathasbeenevaluatedinanother
holds that RoBERTa GPT2 is significantly better
benchmarkpaper. WequerytheAPIatthefollow-
onGPT2generationsandthatRADARisunchar-
inglink20 andusethe‘isHuman’returnfieldasthe
acteristicallybadonIMDbMovieReviews.
classifieroutput.
17https://api.gptzero.me/v2/predict/text C.3 ModelPerformancevs. Domain
18https://api.originality.ai/api/v1/scan/ai
19https://api.gowinston.ai/functions/v1/predict InTable13wereporttheresultsofour12detectors
20https://api.zerogpt.com/api/detect/detectText acrossalldifferentdomainsofgeneratedtext. WeChatGPT Cohere Cohere-Chat
2000
1500
3000
2000 1000 1000
1000 500
0 0 0
2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0
GPT2 GPT3 GPT4
3000
7500 2000
2000
5000
1000 1000
2500
0 0 0
2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0
Human LLaMA-Chat MPT
6000
400 7500
5000 4000
200
2500 2000
0 0 0
2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0
MPT-Chat Mistral Mistral-Chat
6000
3000
4000
4000
2000
1000 2000 2000
0 0 0
2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0 2.5 5.0 7.5 10.0 12.5 15.0
Figure7: HistogramsofperplexityaccordingtoLLaMA27Bpergenerativemodelinthedataset. Weseethatthere
isstillasignificantdifferencebetweenhuman-writtenandmachine-generatedtextwithrespecttoperplexity.
ChatGPT Cohere Cohere-Chat
3000 2000 1500
2000 1000
1000
1000 500
0 0 0
20 40 60 80 100 20 40 60 80 100 20 40 60 80
GPT2 GPT3 GPT4
2000 1500
1500
1000
1000
1000
500 500
0 0 0
20 40 60 80 100 20 40 60 80 100 10 20 30 40 50 60
Human LLaMA-Chat MPT
1000
4000 1500
1000
500 2000
500
0 0 0
20 40 60 80 100 20 40 60 80 20 40 60 80 100
MPT-Chat Mistral Mistral-Chat
4000
2000 1500
1000 2000
1000
500
0 0 0
20 40 60 80 100 20 40 60 80 100 20 40 60 80 100
Figure8: HistogramsofSelfBLEU(Zhuetal.,2018)pergenerativemodelinthedataset. Weseethatcontinuation
modelstendtobemorerepetitivethanchatmodelsandthathuman-writtentextisbyfartheleastrepetitive.RoBERTa (GPT2)
News 0.996 0.829 0.815 0.748 0.694 0.689 0.640 0.591 0.536 0.466 0.415
Recipes 0.902 0.691 0.850 0.817 0.785 0.480 0.457 0.818 0.485 0.682 0.623
Books 0.987 0.685 0.854 0.629 0.588 0.585 0.548 0.725 0.432 0.414 0.287
Reviews 0.976 0.661 0.795 0.569 0.612 0.520 0.462 0.577 0.451 0.245 0.387
Reddit 0.992 0.647 0.838 0.428 0.437 0.552 0.477 0.318 0.493 0.164 0.252
Wiki 0.959 0.647 0.670 0.715 0.695 0.412 0.373 0.759 0.449 0.546 0.332
Abstracts 0.978 0.587 0.698 0.580 0.508 0.631 0.481 0.626 0.458 0.373 0.386
Poetry 0.921 0.113 0.299 0.050 0.010 0.337 0.365 0.121 0.038 0.040 0.039
GPT2 Mistral-Chat GPT3 LLaMA-Chat ChatGPT MPT Mistral Cohere-Chat MPT-Chat Cohere GPT4
GPTZero
Abstracts 1.000 0.985 0.998 0.995 0.958 0.900 0.910 0.482 0.297 0.360 0.760
Books 1.000 1.000 1.000 1.000 0.917 0.955 0.845 0.405 0.258 0.265 0.655
News 1.000 1.000 0.990 0.970 0.863 0.415 0.330 0.280 0.205 0.190 0.135
Recipes 1.000 0.980 0.990 0.910 0.693 0.830 0.815 0.403 0.315 0.338 0.575
Reviews 0.995 1.000 0.978 0.998 0.922 0.855 0.940 0.455 0.215 0.320 0.425
Wiki 0.995 0.975 0.965 0.835 0.807 0.685 0.455 0.422 0.253 0.270 0.460
Poetry 0.990 0.990 0.995 0.992 0.845 0.885 0.695 0.400 0.275 0.422 0.390
Reddit 0.975 0.840 0.963 0.948 0.870 0.445 0.615 0.258 0.167 0.148 0.115
ChatGPT GPT4 LLaMA-Chat Mistral-Chat MPT-Chat Cohere-Chat GPT3 GPT2 MPT Mistral Cohere
RADAR
Recipes 1.000 0.999 0.985 0.994 0.789 0.988 0.908 0.893 0.799 0.946 0.640
News 0.999 0.999 0.996 0.995 0.935 0.933 0.877 0.820 0.810 0.706 0.663
Wiki 0.999 0.963 0.860 0.970 0.693 0.873 0.806 0.568 0.706 0.597 0.613
Books 0.992 0.965 0.999 0.993 0.895 0.991 0.923 0.629 0.768 0.546 0.689
Reddit 0.969 0.792 0.946 0.872 0.951 0.978 0.699 0.434 0.491 0.450 0.467
Abstracts 0.897 0.880 0.772 0.780 0.880 0.822 0.715 0.420 0.554 0.363 0.429
Poetry 0.361 0.153 0.697 0.322 0.545 0.860 0.773 0.572 0.646 0.249 0.526
Reviews 0.004 0.007 0.135 0.035 0.193 0.463 0.264 0.098 0.222 0.057 0.118
ChatGPT GPT4 Mistral-Chat LLaMA-Chat MPT-Chat GPT3 Cohere-Chat MPT GPT2 Cohere Mistral
Figure9: ExtendedheatmapofRoBERTaGPT2,GPTZero,andRADAR’sperformanceacrossallmodelsand
domainsintheRAIDdataset.News Wiki Reddit Books Abstracts Reviews Poetry Recipes
R-BGPT2 0.032 0.379 0.477 0.586 0.055 0.539 0.998 0.916
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
R-LGPT2 0.070 0.459 0.100 0.161 0.085 0.298 0.762 0.315
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.1%) (5.0%) (5.0%)
R-BC-GPT 0.987 0.983 0.219 0.996 0.007 0.371 0.295 0.998
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
RADAR 0.022 0.061 0.695 0.174 0.31 0.997 0.457 0.016
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
GLTR 0.788 0.788 0.767 0.742 0.726 0.757 0.756 0.863
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
FastDetectGPT 0.920 0.870 0.870 0.930 0.860 0.900 0.940 0.880
(4.8%) (5.1%) (5.1%) (4.9%) (4.6%) (4.8%) (5.9%) (5.5%)
LLMDet 1.000 1.000 1.000 1.000 0.999 1.000 1.000 0.998
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.1%) (5.0%) (5.0%)
Binoculars 0.077 0.093 0.099 0.085 0.092 0.097 0.084 0.094
(4.9%) (5.0%) (5.0%) (5.0%) (5.0%) (4.9%) (5.0%) (5.0%)
GPTZero 0.047 0.032 0.057 0.125 0.125 0.070 0.031 0.035
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
Originality 0.375 0.938 0.250 0.312 0.257 0.461 0.047 0.750
(5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%) (5.0%)
Winston 0.001 0.970 0.062 0.998 0.000 0.062 0.875 0.996
(4.0%) (5.0%) (5.0%) (5.0%) (6.0%) (5.0%) (5.0%) (5.0%)
ZeroGPT(*) 1.000 1.000 0.375 0.250 0.500 1.000 0.125 1.000
(29.0%) (48.0%) (1.0%) (9.0%) (4.0%) (5.0%) (5.0%) (52.0%)
Table11: ThresholdsfoundbyoursearchandtheexactFalsePositiveRatesonourdataset. WeseethatZeroGPTis
incapableofachievingthetargetFPRof5%inmanydomains.
t=0.25 t=0.5 t=0.75 t=0.95 strategiesandmodelscancausedetectoraccuracy
toplummetunexpectedly. Thisraisesseriouscon-
R-BGPT2 8.71% 6.59% 5.18% 3.38%
R-LGPT2 6.14% 2.91% 1.46% 0.25% cernsfortherobustdeploymentofdetectors.
R-BCGPT 21.6% 15.8% 15.1% 10.4%
RADAR 7.48% 3.48% 2.17% 1.23% C.5 DetectorAccuracyvs. AdversarialAttack
GLTR 100% 99.3% 21.0% 0.05%
InTable15wereportthefullversionoftheresults
F-DetectGPT 47.3% 23.2% 13.1% 1.70%
LLMDet 97.9% 96.0% 92.0% 75.3% from Table 6 in the main paper. We see similar
Binoculars 0.07% 0.00% 0.00% 0.00% trends,namelythatcertainadversarialattackswork
GPTZero 0.03% 0.00% 0.00% 0.00% betteroncertaindetectorsandthatoccasionallyad-
Originality 0.47% 0.25% 0.17% 0.07%
versarialattacksactuallyimprovedetectorperfor-
Winston 0.75% 0.55% 0.38% 0.21%
ZeroGPT 1.71% 1.42% 1.21% 0.90% manceratherthanharmit. Onenotableinclusion
here is the zero-width space attack, which seems
Table12: FalsePositiveRatesforalldetectorsatrea- toeithercausedetectorstoassignallpositiveorall
sonablechoicesofthresholds. Weseethat,forcertain negativelabels. Futureworkshouldinvestigatethis
detectors,thresholdingnaivelyresultsinunacceptably
phenomenon.
highfalsepositiverates.
D ExampleGenerations
seethatthemetric-basedmethodssuchasBinoc-
InTable16and17weprovideexampleoutputsfor
ulars and FastDetectGPT generalize surprisingly
eachgenerativemodelandadversarialattack. We
well across domains. We also see that in general
see that different generative models have signifi-
detectors perform well but occasionally perform
cantlydifferingstyles,underscoringthedifficulty
surprisinglypoorly.
ofthedetectionproblem.
C.4 DetectorAccuracyvs. DecodingStrategy
InTable14wereporttheresultsofourevaluation
brokenupbycategoryofmodelandbydecoding
strategy. MuchlikeinFigure5fromthemainpa-
per,weseethatcertaincombinationsofdecodingNews Wiki Reddit Books Abstracts Reviews Poetry Recipes
RoBERTa-BGPT2 74.3 64.7 56.3 67.9 56.3 69.1 23.9 64.6
RoBERTa-LGPT2 69.8 59.5 54.1 62.4 58.9 58.2 24.4 67.2
RoBERTa-BCGPT 45.1 48.7 44.6 53.5 72.3 65.3 32.0 5.9
RADAR 88.0 76.8 71.8 84.5 66.7 14.1 53.0 88.5
GLTR 66.9 64.3 65.7 74.0 62.0 67.3 34.8 67.2
FastDetectGPT 74.2 77.3 70.9 76.2 76.4 77.5 63.4 74.6
LLMDet 39.8 32.6 39.6 37.1 18.0 33.1 30.7 48.1
Binoculars 80.7 76.7 79.4 83.7 79.1 80.1 81.0 76.6
GPTZero 58.1 62.8 57.0 71.4 74.9 70.5 69.5 67.6
Originality 88.4 83.2 85.0 90.4 87.7 87.3 75.1 82.8
Winston 72.4 54.9 68.9 70.7 94.7 72.9 64.3 68.9
ZeroGPT(*) 72.2 70.6 65.1 73.3 60.3 68.6 50.0 63.7
Table13: AccuracyScoreatFPR=5%fordetectorsacrossdifferentdomains. Weseethatmetric-basedmethods
performsurprisinglywellacrossdomainsandthatdetectorscanperformsurprisinglypoorlyonunseendomains.
Open-Source Closed-Source
ChatModels Non-ChatModels Chat Non-Chat
(llama-c,mistral-c,mpt-c) (mistral,mpt,gpt2) (c-gpt,gpt4,cohere) (cohere,gpt3)
Dec.Strategy greedy sampling greedy sampling greedy sampling greedy sampling
Rep.Penalty? ✗ ✓ ✗ ✓ ✗ ✓ ✗ ✓ ✗ ✗ ✗ ✗
R-BGPT2 84.1 52.3 77.9 26.2 98.6 44.1 60.5 35.4 70.9 41.7 65.1 52.5
R-LGPT2 79.7 41.1 71.4 19.5 98.5 43.0 67.2 53.4 61.4 34.7 61.1 48.6
R-BCGPT 80.2 63.3 75.0 39.3 53.3 26.4 14.9 1.7 59.1 38.1 46.5 39.0
RADAR 88.8 77.4 85.6 66.4 91.8 63.8 48.3 31.8 81.6 75.3 72.2 67.7
GLTR 89.8 67.5 83.9 38.3 99.6 56.9 44.5 0.5 80.7 54.3 75.6 63.7
F-DetectGPT 98.6 74.5 96.2 40.5 97.8 56.1 79.7 0.6 96.0 74.1 93.8 86.3
LLMDet 55.5 30.2 47.5 16.5 74.8 27.0 38.4 3.7 35.8 18.5 40.0 32.9
Binoculars 99.9 86.6 99.7 60.6 99.9 62.3 72.4 0.6 99.2 92.1 99.0 95.0
GPTZero 98.8 93.7 98.4 82.5 74.7 34.6 9.4 4.8 92.3 88.5 60.6 53.4
Originality 98.6 86.3 97.7 72.5 99.9 64.1 89.0 51.2 96.8 89.0 91.7 85.4
Winston 97.2 90.1 96.6 78.3 68.2 49.0 29.5 11.3 96.1 93.7 73.2 68.1
ZeroGPT(*) 95.4 80.7 90.5 54.9 85.1 57.2 16.0 0.3 92.1 65.8 83.4 72.7
Table14: AccuracyScoreatFPR=5%foralldetectorsacrossgroupsofmodelswithdifferentsamplingstrategies.
Weseethatrandomsamplingwitharepetitionpenaltyconsistentlymakesoutputgenerationsverydifficulttodetect.
None AS AD HG IP NS PP MS SYN ULS WSA ZWS
RoB-BGPT2 59.1 55.6 37.1 7.6 56.9 55.9 68.9 43.8 71.5 18.8 45.2 99.9
RoB-LGPT2 56.7 52.4 33.2 21.3 55.1 51.7 72.9 39.5 79.4 19.3 40.1 99.9
RoB-BCGPT 44.8 43.3 38.0 0.0 5.2 44.3 49.2 42.1 39.6 31.7 0.1 0.0
RADAR 70.9 70.8 67.9 59.3 73.7 71.0 67.3 69.5 67.5 70.4 66.1 82.2
GLTR 62.6 61.2 52.1 24.3 61.4 59.9 47.2 59.8 31.2 48.1 45.8 97.2
F-DGPT 73.6 71.6 64.7 51.4 72.0 68.2 71.8 70.7 34.0 60.4 64.4 98.9
LLMDet 35.0 33.9 27.4 40.6 27.2 33.8 28.5 32.7 27.3 23.4 4.4 27.1
Binoculars 79.6 78.2 74.3 37.7 71.7 77.1 80.3 78.0 43.5 73.8 70.1 99.1
GPTZero 66.5 64.9 61.0 66.2 66.2 65.8 64.0 65.1 61.0 56.5 66.2 66.2
ZeroGPT 65.5 65.4 59.7 82.4 64.9 64.7 46.7 64.7 18.8 54.5 64.2 48.0
Originality 85.0 83.6 71.4 9.3 85.1 86.0 96.7 78.6 96.5 75.8 84.9 4.9
Winston 71.0 68.9 66.9 26.3 69.8 69.0 52.6 67.5 63.6 56.8 46.8 25.0
Table 15: Accuracy Score at FPR=5% for all detectors across different adversarial attacks. Abbrevations are:
AS:AlternativeSpelling,AD:ArticleDeletion,HG:Homoglyph,IP:InsertParagraphs,NS:NumberSwap,PP:
Paraphrase,MS:Misspelling,SYN:SynonymSwap,ULS:UpperLowerSwap,WSA:WhitespaceAddition,ZWS:
Zero-WidthSpaceAdditionDomain:Reddit,Title:VWalbumtracklist/lyricsheetinquiry?(ID:25fb9f14-c7c5-4e76-95ac-bf149780f30d)
Prompts:(Chat)WritejustthebodyofaRedditposttitled"VWalbumtracklist/lyricsheetinquiry?".
(Non-Chat):Thefollowingisthefulltextofaposttitled"VWalbumtracklist/lyricsheetinquiry?"fromreddit.com
Original Iboughta"Modernvampiresofthecity"onvinylrecently,andIwaswonderingifanyonehadinformation
RedditPost onthenatureofthetracklist?Itsonthebacksideoftheposter,anditsanormaltracklistandlyricsheet
(Human) exceptthere’ssomethingscircledandunderlinedandstuff.Ilookeditup,andIthoughtorigionallythat
itwassupposedtolooklikeaplaybook,likefootball,butitlookslikethemarksareintentionaltothe
numbersandstuffsothenIthought,maybeitwasthemplanningtheiralbum?Andtheyjustdecidedto
addsomeflairtothetracklist?Eitherway,imcurious,andaquickGooglesearchdidn’twork,soIfigured
youguyswouldknowbetterthanme.IwouldloveanyinputIcouldget
GPT-2 "Hi,thisisathreadforpeopleofanyabilitytohelpmewithaqueryrelatedtothefollowingtrack:"Cherries
OnTheWind"fromthealbum’Volkswagen’,whichwasreleasedJuly2008toAugust2009.Ihaveafew
questionsaboutallofthem(mytwobiggestquestionsare’Whosingsit?’and’Whowroteitandwhy?’):
(1)Isthesingernamed"Cherries"afemale?Ifnot,isitaboy,femaleorsomethingelse?
(2)Isitafemaleleadormalesupportingsingerintheband?
(3)WhowritesthelyricswhicharewritteninbothGermanandEnglish,inthestyleofapopsong?Isita
Germannameorisitthenameofasongartist,musicianorsongwriter?
(4)Isthereafemalevocalistintheband?Ifso,canyoushedsomelightonthesinger?ArethereGerman
soloprojectsbyher?Ifso,canyoushedsomelightonthesinger?ArethereGermansoloprojectsbyher?
http://www.youtube.com/watch?v=jY9FyMwKvCk&feature=fvrs
Ifyouneedtoaskmorequestion,justaddthemtothetopofthepostandI’llanswer.Thanksmuch!
2peoplehavevotedthismessagehelpful
Lyrics:https://www.youtube.com/watch?v=fSdWJ4Wy7k0
GPT-3 Heyall,I’mwonderingifanyonemightbeabletohelpmeoutwithsomething.I’mtryingtotrackdowna
copyofthelyricsheet/tracklistforthealbum"Volkswagen."I’vebeenabletofindafewimagesonline,
butthey’reallpartialand/orlowquality.IfanyonehasahighqualityscanorknowswhereIcanfindone,I
wouldreallyappreciateit!Thanksinadvance!
ChatGPT Helloeveryone,IrecentlygotmyhandsonavinylcopyofVW’slatestalbumandIamabsolutelyloving
it!Theproduction,themelodies,andthelyricsarejusttop-notch.I’vebeenobsessivelylisteningtoitand
can’tgetenough.However,IwaswonderingifanyonehasaccesstoorknowswhereIcanfindthetrack
listandlyricsheetforthealbum?I’vebeensearchingonlinebuthaven’thadmuchlucksofar.Iwould
reallylovetodivedeeperintothelyricsandunderstandthemeaningbehindsomeofthesongs.Ifanyone
canpointmeintherightdirectionorhasanyinformation,Iwouldgreatlyappreciateit.Thanksinadvance!
GPT-4 HellofellowVWfans! I’verecentlygotmyhandsonavintagevinylcopyofoneoftheolderVampire
Weekendalbums.However,itdidn’tcomewithatracklistorlyricsheet.It’sprovingtobeabitofataskto
identifysomeofthetracksandI’dlovetosingalongtomyfavourites.IfanyonecouldpointmetowhereI
mightfindatracklistand/oraplacewhereIcanfindthelyricstothesongs,Iwouldgreatlyappreciateit.
Letmeknoworfeelfreetomessagemedirectly.Thanksforyourhelp,guys!
Mistral >Thishasbeenbuggingmeforabit.Inevergotmycopyof"VW"(or"VWEP"-whicheveryouwantto
callit)soIneverhadachancetolookatthelyricsheet.Iknowthere’sanextendedversiononiTunes,but
Ihaven’tthefundstopurchaseitsincetheEPand"TNWT"cameoutatthesametime.ButIwouldlike
toknowthelyricstoatleast"WonderfulLife"(forwhichIknowthere’snolyricsof),"TheNewWave",
"SongofOurHits","WhatIfGodWasOneOfUs",and"TheHitsJustKeepComing".I’dliketoknow
howthesong"WhatIfGodWasOneOfUs"fitswiththestoryline(orisitrelatedatall?),aswellasthe
wholethingbehind"WhatWouldSheSay?",andtheendingsongthathastobeeitheraspoilerfor"VW"
("IAmtheWind"),orsomethingrelatingto"TNWT"(Ithinkthatlinefromthe"TNWT"lyricsheetabout
a"newpower"intheversebetween"TheHitsJustKeepComing"and"SongForOurHits"iswhatI’m
thinkingof)
MistralChat Heyeveryone,IjustgotintoTheVelvetUndergroundandI’vebeenahugefanoftheirworkeversince.
I’vebeendoingadeepdiveintotheirdiscographyandIwaswonderingifanyonehadatracklistorlyrics
sheetforthealbum"VW"?Ican’tfinditanywhereonlineandit’sdrivingmecrazy.Anyhelpwouldbe
greatlyappreciated!Thanksinadvance!
Cohere VWalbumtracklist/lyricsheetinquiry? Hello! Iwaswonderingifanyonehadscanned/digitizedthe
tracklistorlyricsheetfromtheVWalbum(oildiffuser).Iknowit’sfloatingaroundheresomewhere,but
damnedifIcanfindit.Thanks!
CohereChat Checkthisout! Beenwaitingforthisforages!! Heyall–I’verecentlyfalleninlovewithVW’slatest
album(thankyouRedditfortherecommendation!) butIcannotforthelifeofmefindthetracklistor
lyricsanywhere.Thesongsareamazingbutstillquitenewforme,soIhavenocluewhatthelyricsareand
wannaknow!!!Doesanyonehaveatracklist/lyricsheetthattheycouldshare?Anyhelpisappreciated!MPT IreadthisonRedditandthinkitbearsrepeatingandexpandingupononasitethatVWfollowersfrequent,
andIfigureditbehoovedmetogetitouttoyouguysASAPThefirstbatchoftestpressingsforthenew
VolcanoWitchalbum,whichwasrecordedduringarecenttriptoChicagobyVWmemberJohnMcEntire,
willbearrivingverysoon.Beforethishappens,thebandwantedtoknowwhetherornotourfanswillbe
interestedinatestpressinglyricsheet. Thisisaspecialedition(limitednumber)itemthatwillonlybe
madeavailabletothosesupportersthatwereveryinstrumentaltothecreation&completionofthenewVW
album.Thetestpressinglyricsheetwillfeatureall10trackswithfullhandwrittenlyricsbyJohn,whoalso
tookthetimetohandwritelyricstotwonewneverheardbeforeVWsongs,whichwillonlybeavailable
onthelyricsheet&testpressingsofthealbum.Ifourfollowersareinterestedinthisspecialeditionitem
pleasesubmitascreenshotofthebelowimagewiththeword“YES”placedinthecommentsectionof
thispost.Ifyou’reunabletosubmitascreenshotsimplyplacetheword“YES”inthecommentsection
ofthispost&I’llmakesureyou’readdedtolistforthespecialtestpressinglyricsheet. Allproceeds
fromthetestpressingwillbedonatedtoTheCenterForDiscovery,theschoolmydaughterattends,inher
honor... Inthemeantime,whilethebandwaitstohearfromtheirfans,we’regivingyouthechancetobe
oneof100luckywinnerstowinasigned“StormLord”posterthatwascreatedbytheband’slongtime
collaboratorEricAdrianLee,whoalsodesigned&madealltheartworkforthenewVolcanoWitchalbum.
Toenteryourselfintothisgiveawayallyouhavetodoissharethispost.That’sit,simpleasthat.We’ll
picktheluckywinnersonOctober2nd&thenpostthegiveawaywinnersonoursocialmedia.So...are
youinterestedinthespecialtestpressinglyricsheet?Source:http://redd.it/30fsl1Postedat10:47PMin
VolcanoWitch|Permalink|Comments(0)VolcanoWitch-"A.M.(LiveattheEmptyBottle)"
MPTChat Heyeveryone!I’mabigfanofVWandIwaswonderingifanyoneknowswhereIcanfindthealbumtrack
listandlyricsheetfortheirlatestalbum? I’vebeensearchingonlinebutcan’tseemtofinditanywhere.
Anyhelpwouldbemuchappreciated!Thanksinadvance!
LlamaChat HeyfellowRedditors,I’mhopingsomeonecanhelpmeoutwithalittleinquiryIhaveabouttheVelvet
Underground’salbum"TheVelvetUnderground&Nico".I’vebeentryingtofindatracklist/lyricsheetfor
thealbumthatincludesthebonustracksfromtheCDreissue,butIcan’tseemtofindoneanywhere.I’ve
searchedhighandlowonGoogle,butallthetracklistsIcomeacrossonlyincludetheoriginaltracklist
forthealbum,withoutthebonustracks.I’vealsocheckedthealbum’sWikipediapageandvariousother
websites,butnoluck. Doesanyoneknowofaresourceorwebsitethathasthecompletetracklist/lyric
sheetforthealbum,includingthebonustracks?I’dreallyappreciateitifsomeonecouldpointmeinthe
rightdirection. Thanksinadvanceforthehelp,andsorryifthishasbeenaskedbefore(Isearchedthe
subredditbutdidn’tfindanything).
Table16: OutputgenerationsfromeachmodelinRAIDfortheRedditposttitled“VWalbumtracklist/lyricsheet
inquiry?” usingrandomsampling(temp=1,p=1)andnorepetitionpenalty. PromptsusedarelistedinTable9Domain:Reviews,Model:Cohere,Decoding:Sampling(NoPenalty),(ID:b0aa73c4-ff31-4a43-9472-8fe7a85e2754)
Prompt:Thefollowingisthefulltextofareviewforthemovie"FastFive"fromIMDb.com:
Original Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandFurious6.BringingbackVin
(NoAttack) DieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Alternative Thisisprobablymyfavouriteactionmovieof2011,can’twaittoseeFastandFurious6.Bringingback
Spelling VinDieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Article Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandFurious6.BringingbackVin
Deletion DieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Homoglyph Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandFurious6.BringingbackVin
DieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Insert Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandFurious6.BringingbackVin
Paragraphs DieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.
[¶]
Theactionwasgreatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Number Thisisprobablymyfavoriteactionmovieof0346,can’twaittoseeFastandFurious6.BringingbackVin
Swap DieselandthelatePaulWalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Paraphrase Thisissurelythebestofalltheactionfilmsin2011. I’mreallylookingforwardtoFast&Furious6. I
lovedthattheybroughtbackVin-DieselandthelatePaul-Walker,itmadetheseriesbetterthanever.The
actionwassuspensefulandexcitingandthenewactorswereallgreat.Thisisamust-see.
Misspelling Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandFurious6.BringingbackVin
DieselandthelatePaulWalkerwasagratidea,makingthisfranchisebetterthanever. Theactionwas
grateandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Synonym Thisisalsomyfavouriteactionfilmof2011,can’twaittoseeFastandFurious6.TakingdownVinDiesel
Swap andthelateScottDaviswasagoodthing,doingthisfranchisebetterthanever.Theactionwasgoodand
suspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Upper Thisisprobablymyfavoriteactionmovieof2011,can’twaittoseeFastandfurious6.BringingbackVin
Lower DieselandthelatePaulwalkerwasagreatidea,makingthisfranchisebetterthanever.Theactionwas
greatandsuspenseful,andthenewcastmemberswereamazing.Thisisamust-see.
Whitespace Thisisprobablymyfavorite[]actionmovieof2011,can’twaittoseeFastand[]Furious6.Bringing[]
backVinDiesel[]andthelatePaulWalkerwasagreatidea,[]makingthis[]franchisebetter[]thanever.
Theactionwasgreatandsuspenseful,andthenewcastmembers[]wereamazing.Thisisamust-see.
Zero-Width T[U+200B]h[U+200B]i[U+200B]s[U+200B]i[U+200B]s[U+200B][U+200B]p[U+200B]r[U+200B]o
Space [U+200B]b[U+200B]a[U+200B]b[U+200B]l[U+200B]y[U+200B] [U+200B]m[U+200B]y[U+200B]
[U+200B]f[U+200B]a[U+200B]v[U+200B]o[U+200B]r[U+200B]i[U+200B]t[U+200B]e[U+200B]
[U+200B]a[U+200B]c[U+200B]t[U+200B]i[U+200B]o[U+200B]n[U+200B][U+200B]<...>
Table17: ExampleoutputsforeachadversarialattackinRAIDwhenappliedtotheIMDbmoviereviewfor“Fast
Five”generatedbyCohereusingrandomsampling(temp=1,p=1)andnorepetitionpenalty. Bluecolorindicates
theportionofthetextthatwaschangedbytheattack. Detaileddescriptionsofeachattackalongwiththeireffective
attacksurfacesarelistedinAppendixA.4.