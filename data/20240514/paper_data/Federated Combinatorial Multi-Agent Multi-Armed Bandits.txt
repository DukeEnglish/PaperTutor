Federated Combinatorial Multi-Agent Multi-Armed Bandits
FaresFourati1 Mohamed-SlimAlouini1 VaneetAggarwal2
Abstract 1.Introduction
TheMulti-ArmedBandits(MAB)(Slivkinsetal.,2019;Lat-
Thispaperintroducesafederatedlearningframe- timore&Szepesva´ri,2020)modelonlinedecision-making,
worktailoredforonlinecombinatorialoptimiza- where at every time step, an agent plays an arm and ob-
tionwithbanditfeedback. Inthissetting,agents serves its associated reward. In combinatorial MAB, the
select subsets of arms, observe noisy rewards agent can play a set of arms, instead of one arm, at each
for these subsets without accessing individual time step and receive a reward for that selection. When
arm information, and can cooperate and share theagentonlylearnsabouttherewardlinkedtotheplayed
information at specific intervals. Our frame-
set,itisknownasfull-banditfeedbackorbanditfeedback.
worktransformsanyofflineresilientsingle-agent If the agent gains additional insights into how each arm
(α−ϵ)-approximationalgorithm—havingacom- contributes to the overall reward, it is called semi-bandit
(cid:16) (cid:17) feedback. Dealingwithbanditfeedbackismorechallenging plexityofO˜ ψ ,wherethelogarithmisomit-
ϵβ sinceagentshavelessknowledgethaninthesemi-bandit
ted, for some function ψ and constant β—into
feedback setting. In this work, we consider bandit feed-
anonlinemulti-agentalgorithmwithmcommu-
back(Fouratietal.,2023a;Nieetal.,2023;Fouratietal.,
nicatingagentsandanα-regretofnomorethan
2024),whichhasseveralapplications,suchasrecommender
(cid:16) (cid:17)
O˜ m− 3+1 βψ3+1 βT32 ++ ββ . Ourapproachnotonly systems,revenuemaximization(Fouratietal.,2023a),influ-
eliminatestheϵapproximationerrorbutalsoen- encemaximization(Nieetal.,2023;Fouratietal.,2024),
sures sublinear growth with respect to the time anddatasummarization,asshowninthiswork.
horizon T and demonstrates a linear speedup
Federated learning (FL), an emerging machine learning
with an increasing number of communicating
paradigm,involvescollaborativelearningamongmultiple
agents. Additionally, the algorithm is notably
agents. In this process, selected agents share their local
communication-efficient,requiringonlyasublin-
updateswithacentralserver,whichthenaggregatesthese
earnumberofcommunicationrounds,quantified
(cid:16) (cid:17) updates and sends the consolidated output back to each
asO˜ ψTβ+β 1 . Furthermore,theframeworkhas participatingagent(Konecˇny` etal.,2016;McMahanetal.,
beensuccessfullyappliedtoonlinestochasticsub- 2017;Lietal.,2020;Hosseinalipouretal.,2020;Elgabli
modularmaximizationusingvariousofflinealgo- etal.,2022;Fouratietal.,2023b). Whiletheproblemhas
rithms, yielding the first results for both single- beenstudiedinthecontextofcontinuousoptimization,we
agentandmulti-agentsettingsandrecoveringspe- addresscombinatorialoptimization(Korteetal.,2011)in
cializedsingle-agenttheoreticalguarantees. We afederatedonlinestochasticsettingwithbanditfeedback.
empiricallyvalidateourapproachtoastochastic For example, the multi-agent setting under consideration
datasummarizationproblem,illustratingtheef- canbeappliedtorecommendersystems,whereeachagent
fectivenessoftheproposedframework, evenin aims to recommend a set of products and then shares its
single-agentscenarios. findingswithaserver. WeprovideageneralFLframework
toadaptcombinatorialofflinesingle-agentapproximation
algorithmstoonlinemulti-agentsettings,presentingthefirst
resultsfortheregretboundsinthissetup.
1DepartmentofComputer,ElectricalandMathematicalSci-
enceandEngineering,KingAbdullahUniversityofScienceand Weconsiderasettingwithm′ ≥1agentsconnectedthrough
Technology(KAUST),Thuwal,KSA.2SchoolofIndustrialEn-
anetwork. Amongthem,onlyarandomlyselectedsubsetof
gineering, Purdue University, West Lafayette, IN 47907, USA.
m≤m′agentscancooperateandshareinformationincom-
Correspondenceto:FaresFourati<fares.fourati@kaust.edu.sa>.
municationrounds, possiblythroughaserver. Thissetup
Proceedings of the 41st International Conference on Machine accommodatesscenariosofpartialparticipation,whichare
Learning,Vienna,Austria.PMLR235,2024.Copyright2024by morepracticalinsomereal-worldsettingsduetoinherent
theauthor(s).
1
4202
yaM
9
]GL.sc[
1v05950.5042:viXraFederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
availabilityandcommunicationconstraints. Whenm=m′, approximationalgorithm,withanapproximationfactorof
thescenariorevertstoafull-participationsetting. Allagents (α−ϵ)whereϵ≥0,andensuringresilience,canbeadapted
aimtosolvethesameonlinestochasticcombinatorialprob- to a multi-agent setting with bandit feedback. This adap-
lemwithinatimehorizonofT. Theyconductlocalexplo- tationprovidessub-linearα-regretguarantees,incontrast
rationandthen,ifselected,sharelocalestimations. Each tothesub-linear(α−ϵ)-regretguaranteesprovidedbyNie
agenticanplayanysubsetofarmsinparallelwithothers et al. (2023). This approach eliminates the ϵ error while
andreceivesnoisyrewardsforthatset. Inacombinatorial maintainingsub-linearitywithrespecttoT acrossanycom-
setting,thenumberofpossibleactionsbecomesexponen- binatorialproblem,anyreward,andunderanyconstraints.
tiallylargewiththenumberofbasearms,makingsharing
Wenotethatincontrasttopreviousworksthatdealtwithspe-
estimationsforallpossibleactionsprohibitive. Therefore,
cificassumptionsaboutrewardfunctionsandconstraintson
we consider a more practical approach wherein, in each
actions—suchasassumingstochasticsubmodularrewards
communicationround,selectedagentsshareonlyasingle
(Fouratietal.,2023a)ormonotonerewardswithcardinal-
action(subset)estimation.
ityconstraints(Nieetal.,2022;Fouratietal.,2024)—our
Ourworkisthefirsttoprovideageneralmulti-agentframe- work considers general reward functions without making
work for adapting combinatorial offline single-agent ap- anyassumptionsabouttherewardtypeorconstraints. Fur-
proximationalgorithmstoaFLsettingtosolvestochastic thermore,ourworkexplorestheuseofanyofflinealgorithm
combinatorialmulti-agentMAB(C-MA-MAB)problems A(ϵ)asasubroutinewithcomplexityinthegeneralform
withonlybanditfeedback. Theproposedapproachprovably
ofO(cid:16) ψ(cid:17) orO(cid:16)
ψ
log(cid:0)1(cid:1)(cid:17)
,whereψisafunctionofthe
achievesaregretofatmostO˜(m− 3+1 βψ3+1 βT32 ++ ββ ),which problemϵβ characterϵ iβ stics,βϵ
≥ 0someconstant,andϵisan
issub-linearinthetimehorizonT anddecreaseswithan
approximationerrorfactor,ensuringthatourresultsapply
increasing number of agents m, for some constant β and
toanyalgorithmwiththesecharacteristics.
some function ψ that govern the complexity of the con-
sidered offline approximation algorithm. The framework Inaddition,unlikepreviousworksthatfocusedoncombina-
doesnotrequiretheagentstocommunicateeverystep;in- torialsingle-agentscenarios(Fouratietal.,2023a;2024;Nie
stead,itonlyneedsO˜(ψTβ+β
1)communicationtimes. Our
etal.,2022;2023),weaddressacombinatorialmulti-agent
settingwherecollaborationispermitted,possiblywithpar-
proposedframeworkcanservetosolveonlinecombinato-
rial problems for both single-agent (m′ = m = 1) and tialparticipation,andoptimizetheworst-caseregretforany
multi-agent(m′ > 1)scenarios. Notably,ourframework agent,therebyrecoveringandgeneralizingthesingle-agent
setting. Additionally,althoughourproposedalgorithmhas
enjoysalinearspeedupwithanincreasingnumberofagents,
parameters,suchasϵ⋆andr⋆,noneareconsideredhyperpa-
translatingtodecreasedregrets.
rameters.Wederiveclosed-formvaluesfortheseparameters
Wenotethatforasingleagent,underbanditfeedback,vari- asfunctionsoftheproblemparameters,suchastherangeT,
ousoffline-to-onlinetransformationshavebeenproposedfor thenumberofavailableagentsm,andthesubroutine-related
submodularmaximization(Nieetal.,2022;Fouratietal., valueoftheconstantβ,andthefunctionψ,tominimizethe
2023a; 2024). Additionally, Nie et al. (2023) studied a expectedcumulativeα-regret.
frameworkforgeneralcombinatorialoptimizationinwhich
Contributions: We introduce a novel FL framework for
anyresilientofflinealgorithmwithanα-approximationguar-
onlinecombinatorialoptimization,adaptingsingle-agentof-
anteecanbeadaptedtoanonlinealgorithmwithsublinear
flinealgorithmstotackleonlinemulti-agentproblemswith
α-regretguarantees. Similarly,anofflineresilient(α−ϵ)-
banditfeedback. Thepaperdemonstratestheadaptabilityof
approximation algorithm can provide sublinear (α − ϵ)-
anysingle-agentsub-optimaloffline(α−ϵ)-approximation
regret guarantees for an online algorithm for any ϵ ≥ 0.
algorithm,ensuringresilience,foraC-MA-MABwithα-
This approach leads to a linear α-regret online algorithm
whenϵ>0. Recently,Fouratietal.(2024)addressedthis regret guarantees of O˜(m− 3+1 βT2 3+ +β β), lifting the ϵ error,
issueoflinearregretinthecaseofmonotonesubmodular
providingsub-linearityinthehorizonT,andensuringlin-
optimization with a cardinality constraint. They adapted earspeedupwithanincreasingnumberofagentsm. The
a sub-optimal offline (1−1/e−ϵ)-approximation algo- frameworkonlyrequiressub-linearcommunicationrounds
(cid:16) (cid:17)
rithm—whose complexity grows with log(1)—to a sub- of O˜ Tβ+β 1 , which becomes at most logarithmic with
ϵ
linear(1−1/e)-regretonlinealgorithmwithbanditfeed- respecttoT whenβ =0. Furthermore,weleverageourthe-
back, successfully eliminating the ϵ approximation error oreticalresultstoaddressonlinesubmodularmaximization,
whileensuringsub-linearitywithrespecttothehorizonT. presentthefirstspecializedregretforthenon-monotonecar-
dinalityconstraintcase,andrecoverboundsfordifferentof-
Inthiswork,wegeneralizeandextendtheresultspreviously
flinealgorithms,demonstratingtighterregretsthanprevious
established by Nie et al. (2023) and Fourati et al. (2024).
specializedworks. Finally,weshowcasetheapplicabilityof
Wedemonstratethatanysub-optimalsingle-agentoffline
2FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
ourframeworktobothsingle-agentandmulti-agentstochas- Thecumulativeα-regretR (T)israndom,giventhatitisa
i
tic data summarization problems against MAB baselines, sumofα-regrets,whicharefunctionsofstochasticrewards
highlightingitseffectivenessinpracticalscenarios. anddependonthechosensubsets. Inthiswork,weaimto
minimizetheexpectedcumulativeα-regret,wheretheex-
pectationencompassestheoraclenoiseandtherandomness
2.ProblemStatement
oftheseriesofactions.
We formally present the problem as follows. We denote
Ωasthegroundsetofnbasearms. WeconsiderasetA′
3.RelatedWork
withm′ ≥1agents,whereonlyarandomlyselectedsubset
A of m ≥ 1 agents communicates in the communication In Table 1, we provide a comprehensive overview com-
rounds. We examine decision-making problems within a paring our α-regret guarantees with existing ones across
fixedperiodT,where,ateverytimestept,agentichooses variousadaptationsofofflineapproximationsfordifferent
a subset S ⊆ Ω. Let S ⊆ 2Ω represent the set of all combinatorialproblems. Eachrowcorrespondstoacase
i,t
permittedsubsets,dependingontheproblemconstraints. involving an offline algorithm or a general class of algo-
rithms with a specified complexity form, offline approxi-
In each time step t, agent i plays an action S ∈ S and
i,t mation factor, and target online regret factor α. The last
acquiresanoisyrewardf (S ). Weassumethatthereward
t i,t twocolumnspresentpreviouslyestablishedα-regretbounds
f isarealizationofastochasticfunctionwithameanoff,
t and our own for adapting the proposed offline algorithm
boundedin[0,1]1,andi.i.d. conditionedonagivenaction.
orclassofalgorithmsasasubroutinetotheonlinesetting.
Thus,overahorizonT,agentiachievesacumulativereward
of(cid:80)T
f (S ). Wedefinetheexpectedrewardfunction
ThethirdrowpresentstheGENERALtransformation,which
t=1 t i,t generalizes the previous two cases, with a complexity of
for a given action S as f(S) = E[f (S)], hence S⋆ =
t theformO(ψ)foranyfunctionψ. Thefifthrowpresents
argmax f(S)denotetheoptimalsetinexpectation.
S⊆S theMORE GENERALcase,withacomplexityoftheform
Inofflinesettings,attentionisonthealgorithm’scomplexity O(ψlogγ(1)),whereγ ∈ {0,1},furthergeneralizingthe
ϵ
andworst-caseexpectedoutputapproximationguarantees. previouscases. Thelastrow, presentingthe MOST GEN-
Conversely,intheonlinesetting,attentionisoncumulative ERAL,encompassesallpreviousrows,withacomplexity
rewards,whereagentsseektominimizetheirexpectedcu- of the form O(ψ logγ(1)), where β ≥ 0, including the
ϵβ ϵ
mulativeregretsovertime. Onestandardmetrictoassess GENERAL whenβ = γ = 0,theMORE GENERAL when
thealgorithm’sonlineperformanceistocontrasttheagent β =0,andtheexampleinthesixthrow.
toanideallearnerthatknowsandconsistentlyplaysthebest
CombinatorialSingle-AgentExamples: Wenotethaton-
choiceinexpectationS⋆. However,thesignificanceofsuch
linesubmodularoptimizationwithbanditfeedbackhasbeen
acomparisonbecomesquestionableiftheoptimizationoff
consideredin(Nieetal.,2022;Fouratietal.,2023a;2024).
overSisNP-hard,ifthehorizonisnotexponentiallylarge
TheseresultsaredifferentiatedfromourworkinTable1.
intheproblemparameters(Fouratietal.,2023a;2024;Nie
Forsingle-agentnon-monotonesubmodularrewards(See
etal.,2023). Hence,ifapolynomialtimeofflinealgorithm
Section 6) under bandit feedback, Fourati et al. (2023a)
A(ϵ),happentobean(α−ε)-approximation2 algorithm,
adaptstheRANDOMIZEDUSMin(Buchbinderetal.,2015),
for a given error ϵ ≥ 0, and an approximation ratio of
achievingsub-linear 1-regret. Additionally,forsingle-agent
(α−ϵ) ≤ 1,forspecificcombinatorialobjectives,acom- 2
monotonesubmodularrewardsunderbanditfeedbackwitha
monapproachinvolvescomparingtheagent’scumulative
rewardto(cid:80)T (α−ϵ)f(S⋆)anddenotingthedifference cardinalityconstraintk,Nieetal.(2022)adaptstheGREEDY
t=1 in(Nemhauseretal.,1978),andFouratietal.(2024)adapts
as the (α−ϵ)-regret (Nie et al., 2023). In this work, we
theSTOCHASTIC-GREEDYin(Mirzasoleimanetal.,2015),
comparethelearner’scumulativerewardtoa(tighter)agent
thatachieves(cid:80)T αf(S⋆),andwedenotethedifference with both achieving sub-linear (1− 1 e)-regret. Our work
t=1 notonlyrecoversalltheresultsaboveinthesingle-agent
astheα-regret,whichisdefinedforeveryagentiasfollows:
settingbutalsogeneralizesthemtothemulti-agentsetting,
T
showingadecreasingregretwithafactorofm−1 3.
(cid:88)
R i(T)= (αf t(S⋆)−f t(S i,t)). (1) Multi-Agent: Previousworkshaveproposedsolutionsfor
t=1 solvingofflinedistributedsubmodularmaximization. For
1Resultscanbedirectlyextendedtoageneralfunctionf(·) example,partitioningthearmsamongtheagentsandrun-
withaminimumvaluef andamaximumvaluef byconsid- ning a greedy algorithm on each agent was proposed in
min max
eringanormalizedfunctiong(·)=(f(·)−f )/(f −f ). previousworks(Barbosaetal.,2015;Mirzasoleimanetal.,
min max min
2AnalgorithmA(ϵ)isan(α−ϵ)-approximationalgorithmfor 2013). Whilethisispracticalinsomesettings,itisdesigned
maximizingadeterministicfunctionf : S → RafterN oracle fordeterministicobjectivesandleadstolowerapproxima-
callstofsatisfiesE[f(Θ)]≥(α−ϵ)f(S⋆),whereS⋆theoptimal
tion guarantees (half the ratio for monotone submodular
subsetunderfandtheexpectationisovertherandomnessofA(ϵ).
3FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Offline Offline Online
OfflineAlgorithm Priorα-regret Ourα-regretBound
Complexity Factor Factorα
(BR ucA hN bD inO dM erIZ etE aD lU .,S 20M
15)
O(n) 1/2 1/2 O˜(cid:16) nT32(cid:17)∗ O˜(cid:16) m−1 3nT32(cid:17)
(NemhaG usR eE rE etD aY
l.,1978)
O(nk) 1− 1
e
1− 1
e
O˜(cid:16) kn1 3T2 3(cid:17)∗∗ O˜(cid:16) m−1 3kn1 3T2 3(cid:17)
ExcludG inE gN thE eR nA eL
xtrows
O(ψ) α α O˜(cid:16) δ2 3ψ1 3T2 3(cid:17)∗∗ O˜(cid:16) m−1 3δ2 3ψ1 3T2 3(cid:17)
(MS irT zO aC soH leA iS mT aI nC- eG taR lE .,E 2D 0Y
15)
O(cid:0) nlog(1 ϵ)(cid:1) 1− 1
e
−ϵ 1− 1
e
O˜(cid:16) k32n1 3T2 3(cid:17)† O˜(cid:16) m− 31k2 3n1 3T2 3(cid:17)
ExM cluO dR inE gG thE eN nE exR tA rL
ows
O(ψlogγ(1 ϵ)) α−ϵ α None O˜(cid:16) m−1 3δ2 3ψ1 3T2 3(cid:17)
(BR uA chN bD inO dM erS eA tM alP .,L 2IN 01G
7)
O(cid:0) ϵn
2
log(1 ϵ)(cid:1) 1
e
−ϵ 1
e
None O˜(cid:16) m− 51k2 5n1 5T4 5(cid:17)
MOSTGENERAL O(ψ logγ(1)) α−ϵ α None O˜(cid:16) m− 3+1 βδ3+2 βψ3+1 βT2 3+ +β β(cid:17)
Includingthepreviousrows ϵβ ϵ
Table1: Thetablesummarizestheresultsofcombinatorialoptimizationunderbanditfeedback.WeuseO˜tosimplifyexpressions.Key
parametersincludehorizonT,numberofcommunicatingagentsm,basearmcountn,andcardinalityconstraintk.Eachrowpresentsa
specificofflinealgorithmoraclasstransformationwithagivencomplexity,offlineapproximationfactor,andatargetonlinefactorα.For
thegeneralrows,weconsiderclassesofofflinealgorithms,withanapproximationerrorfactorϵ,withgeneralcomplexityforms,with
generalconstants,ψ≥0,β ≥0,γ ∈{0,1},andδ≥0.∗(Fouratietal.,2023a),∗∗(Nieetal.,2023),†(Fouratietal.,2024).
maximization). Moreover,regretanalysisformulti-agent knownasBlackwellreproducibilityontheofflinealgorithm,
(non-combinatorial)MABproblemshasbeeninvestigated inadditiontotheresilienceproperty. Acloselyrelatedwork
(Chawla et al., 2020; Wang et al., 2020; Agarwal et al., is the single-agent framework by Nie et al. (2023) called
2022). In(Chawlaetal.,2020),gossipstylecommunication C-ETC, which adapts offline algorithms with robustness
approachisusedbetweenagentstoachieveO˜((n+2)1 3T2 3) guaranteestostochasticcombinatorialsingle-agentMAB,
m
regret. Wang et al. (2020) present an algorithm for a dis- generalizing some previous works for submodular maxi-
tributed bandit setting where all the agents communicate mization(Nieetal.,2022;Fouratietal.,2023a). However,
withacentralnode,whichisshowntoachievearegretof C-ETCfailstogeneralizethemorerecentworkofFourati
O˜((cid:112)
nT/m). Agarwaletal.(2022)proposeanotheralgo- etal.(2024). Ourframeworkgeneralizesandoutperforms
rithm, which splits the arms among the different agents, theresultsofNieetal.(2023)inmanyways.First,itextends
suchthateachlearnerplaysarmsonlywithinasubsetof tothemulti-agentscenarioinvolvingm≥1communicating
arms and the best-communicated arm indices from other agents, includingthesingle-agentscenario. Additionally,
agents in the previous round. This achieves a regret of whiletheC-ETCframeworkcannotreplicatetheresultsof
O˜((cid:112) (n +m)T) while reducing the communication sig- Fourati et al. (2024) for submodular maximization, ours
m
nificantly.Wenotethattheseworksdonotdirectlyextendto not only recovers all these previous works, including the
combinatorialbanditssincetheconfidence-boundbasedap- framework,butalsoachieveseventighterregretguarantees
proachesherecannotworkforcombinatorialbanditssince thatdecreasewithanincreasingnumberofselectedagents.
O(2n) sets cannot be explored. Recent works have con-
sidered FL for contextual bandits (Li & Wang, 2022; He
4.CombinatorialMA-MABFramework
etal.,2022;Lietal.,2023);however,theseworksdonot
applytooursetting. OurworkisthefirsttopresentanFL Wefirstdefineresilientapproximationalgorithmsandthen
frameworkforgeneralcombinatorialmulti-agentMABwith presentourproposedoffline-to-onlineframework.
banditfeedback.
4.1.OfflineResilient-Approximation
Combinatorial Single-Agent Frameworks: Previous
frameworkshavebeenproposedforcombinatorialsingle- Weintroducetheconceptofresilientapproximation,amet-
agent MAB problems (Niazadeh et al., 2021; Nie et al., ricthatallowsustoevaluatehowanofflineapproximation
2023). Niazadehetal.(2021)proposesaframeworkaiming algorithm reacts to controlled variations in function eval-
toadjustaniterativegreedyofflinealgorithmintoanonline uations. We demonstrate that this specific characteristic
versionwithinanadversarialbanditsetting. However,their alonecanensurethattheofflinealgorithmcanbemodified
approach requisites the offline algorithm to possess an it- totacklestochasticC-MA-MABsettings,withonlybandit
erativegreedystructure. Incontrast,ourframeworktreats feedbackandachievingasub-linearregret. Moreover,this
theofflinealgorithmasablack-boxalgorithm. Furthermore, adaptation does not rely on the algorithm’s structure but
unlikeourwork,Niazadehetal.(2021)imposesacondition treatsitasablack-boxalgorithm.
4FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Wedefinetheξ-controlled-estimationf¯ofarewardfunction Algorithm1C-MA-MAB
f todealwithcontrolledvariations. Input: Horizon T, actions S, agents A′, number m,
Definition4.1(ξ-controlled-estimation). Forasetfunction (α,β,γ,ψ,δ)-resilient-approximationalgorithmA(ϵ)
f fun: ctS ion→ f¯R :Sd →efin Re ,d foo rv ae ξr a ≥fi 0n ,i it se ad ξo -m coa ni tn roS lle⊆ de2 stΩ im, aa tis oe nt
Initializer⋆
← m−1(cid:18) δ(cid:112) log(T)(cid:16) Tm(cid:17) β+1 1(cid:19)2 3+ +2 ββ

off if|f(S)−f¯(S)|≤ξforallS ∈S. i 

ψ 

Anestimationf¯isaξ-controlled-estimationforasetfunc- Initializeϵ⋆ ←(ψ Tr i⋆ )β+1 11 {β>0ORγ>0}.
tionf ifitconsistentlystayswithinasmallpositiverangeξ
oftheactualvaluesacrossallpossiblesetsinS. Givensuch #Multi-AgentExplorationTime
ServerstartsrunningA(ϵ⋆),j ←0
a ξ-controlled-estimation for a set function f, we define
whileA(ϵ⋆)queriesthevalueofsomeA⊆Sdo
(α,β,γ,ψ,δ)-resilient-approximationasfollows:
ServerbroadcastsactionAtotheagents,j ←j+1
Definition4.2((α,β,γ,ψ,δ)-resilientapproximation). For
ServerrandomlyselectsasetA⊆A′ofmagents
anyϵ≥0,analgorithmA(ϵ)isan(α,β,γ,ψ,δ)-resilient
foragentiinA′inparalleldo
approximationformaximizingafunctionf : S ⊆ 2Ω →
Forr⋆times,playactionA
R if, after making a number of calls N(β,γ,ψ,ϵ) to a ξ- i
controlledestimatorf¯,itsoutputΘsatisfiesthefollowing
Ifi∈A,agenttracks&uploadlocalmeanf¯
i
endfor
condition: E[f(Θ)] ≥ (α − ϵ)f(S⋆) − δξ, where S⋆ is
Servercalculatesthemeanf¯andfeedsittoA(ϵ⋆)
the optimal set under f, and the expectation is over the
endwhile
randomness of A(ϵ). Here, N(β,γ,ψ,ϵ) is defined as ψ
whenϵ=0,andasψ 1 logγ(1)otherwise.
ϵβ ϵ #Multi-AgentExploitationTime
Remark4.3. Severalofflineapproximationalgorithmsare ServerbroadcastsΘ,thefinaloutputofA(ϵ⋆)
designedtosolvespecificcombinatorialproblemsunderpar- foragentiinA′inparalleldo
ticularrewardandconstraintassumptions. InAppendixE,
forremainingtimeoftheagentido
we study various ones and demonstrate their resilience,
PlayactionΘ
characterizing each by their corresponding parameters:
endfor
α,β,γ,ψ, and δ. Given the resilience of an offline algo-
endfor
rithm,onecandirectlyapplyTheorem5.3toascertainthe
correspondingworst-caseonlineguaranteeswhenextending
thatofflinealgorithmtoonlinesettings.
Remark4.4. Anequivalentdefinitiontoresilientapproxima- achieveonlinesub-linearregretguarantees. Inwhatfollows,
tionwasproposedbyNieetal.(2023)asarobustapproxi- weexplainhowweusearesilientapproximationalgorithm
mation.However,theresilientapproximationprovidesmore A(ϵ)asasubroutineinourproposedframework.
informationaboutthealgorithm’scomplexity. Specifically,
an(α−ϵ,δ)-robust-approximationalgorithmthatrequires 4.2.Offline-to-OnlineMulti-AgentFramework
anumberoforaclecallsequalto ψ logγ(1),thenitisan
ϵβ ϵ WepresentourproposedC-MA-MABFramework;seeAl-
(α,β,γ,ψ,δ)-resilient-approximationalgorithm. Further-
gorithm 1. This framework is applicable for both single-
more,an(α,β,γ,ψ,δ)-resilient-approximationalgorithm
agentandmulti-agentsettings, whereinthedesignofour
isan(α−ϵ,δ)-robust-approximationalgorithm,withϵ≥0.
algorithmensuresthatthesingle-agentsettingissimplya
Generally,theofflinealgorithmsaredesignedfordetermin- specialcaseofthemulti-agentscenario. ForasetSofpos-
istic(noiseless)functions. However,inreal-worldapplica- sibleactions,asetofm′ ≥1agentsA′,anumberm≥1of
tions, accesstoanoiselessrewardfunctionisnotalways communicatingagents,andatimehorizonT,ouralgorithm
possible, often due to the inherently stochastic nature of canadaptanyoff-the-shelf,offlinesingle-agentcombinato-
theproblem. Forexample,recommendingthesamesetof rial(α,β,γ,ψ,δ)-resilient-approximationalgorithmA(ϵ)
products to different people, or even to the same person totheC-MA-MABsetting. Thisadaptationcomeswiththe-
atdifferenttimes,maynotyieldconsistentoutcomesand oreticalguarantees,asdetailedinTheorem5.3,applicable
rewards. Thisnoisecouldalsostemfromusingastochastic underanyrewardtypeoractionconstraint.
approximationoftheoraclefunctionforcomputationaleffi-
Whiletheofflinealgorithmmaybeafunctionofsomevari-
ciency,asseeninthecaseofstochasticdatasummarization
able ϵ ≥ 0, which trades off its complexity and approxi-
discussedinSection7. Therefore,insuchcases,resilience
mationguarantees,ourproposedalgorithmfindsϵ⋆which
againstnoisyrewardsisnecessary.
optimizesthistrade-offbasedontheproblemparameters
WedemonstrateinTheorem5.3thatresilienceis,infact,suf- anditscomplexitytominimizeregretandusesA(ϵ⋆)for
ficienttoensurethattheofflinealgorithmcanbeadjustedto explorationinstead. Furthermore,intheexplorationtime,
5FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
whenever the offline algorithm A(ϵ⋆) requests the value properinitialization. FromTheorem4in(Besson&Kauf-
oracleforactionA,eachagentofthem′ ≥1agentsplays mann,2018),itfollowsthattheregretboundpreservesthe
the action A for r i⋆ = r⋆/m times, where r⋆ is another T2 3+ +β β dependencewithonlychangesinconstantfactors.
parameterchosenbasedonthesettingandthesubroutine
complexitytominimizeregret,with
5.TheoreticalAnalysis
 (cid:32) (cid:112) (cid:18) Tm(cid:19) β+1 1(cid:33)2 3+ +2 ββ Weupper-boundtherequiredcommunicationrounds, we
r⋆ =mm−1 δ log(T) . (2)
 ψ  lower-bound the probability of the empirical mean being
 
ξ-controlled-estimationoftheexpectation(goodevent),and
Furthermore,wechooseϵ⋆asfollows: upper-boundtheexpectedcumulativeα-regret.
ψr⋆
ϵ⋆ =( Tm)β+1 11 {β>0ORγ>0}. (3) 5.1.CommunicationAnalysis
By the design of the algorithm, the m randomly selected
Onlytherandomlyselectedmagentstrackandbroadcast agents,afterlocallyestimatingthequalityofasuggestedac-
theirlocalestimationstotheserver,i.e.,eachagenti∈A tionA,communicateonlyonevalue,representingthelocal
sendsitslocalestimationf¯ i,thentheserveraggregatesthese estimationf¯ i. TheagentsexploitthedecidedsetΘduring
estimationsinoneglobalestimationf¯ofrewardsforAand theexploitationphasewithoutfurthercommunication. Dur-
thenreturnsf¯toA(ϵ⋆). Finally,intheexploitationphase, ingexploration,theselectedagentsmustcommunicatetheir
alltheagentsinA′playΘ,theoutputfromalgorithmA(ϵ⋆), local estimation for every requested action A. Therefore,
fortheremainingtime. thenumberofcommunicationroundsisupper-boundedby
Remark4.5. C-MA-MABhaslowstoragecomplexity. In the number of requested actions, i.e., the required oracle
everystep,anagentneedstostore,atmost,nindicesand
callsN(β,γ,ψ,ϵ⋆),whichweupper-boundinthefollowing
arealvaluerepresentingtheempiricalmeanofoneaction. lemma,whichweproveinAppendixB.
OnlytheactionΘisstoredduringexploitationtime,andno Lemma5.1. Thenumberofcommunicationtimes,i.e.,the
additionalcomputationisrequired.Duringexplorationtime, numberoforaclequeriesN(β,γ,ψ,ϵ⋆)ofthesubroutine
eachagentneedstostoreonlytheproposedactionAand (α,β,γ,ψ,δ)-resilient-approximationalgorithmA(ϵ⋆)sat-
updateitsassociatedempiricalmean;everythingisdeleted isfies: N(β,γ,ψ,ϵ⋆)≤O(ψTβ+β 1 logγ(T)).
oncetheserverproposesanotheraction. Furthermore,the
proposedframeworkdoesnotrequirethecombinatorialof- From Lemma 5.1 it follows that for cases where β = 0,
fline algorithm A(ϵ) to have any particular structure and whichappliestoseveralofflinealgorithms(Nemhauseretal.,
employsA(ϵ⋆)asablack-boxalgorithm. Consequently,it 1978;Khulleretal.,1999;Sviridenko,2004;Buchbinder
sharesthesamecomplexityasthesubroutineA(ϵ⋆). More- etal.,2015;Mirzasoleimanetal.,2015;Yaroslavtsevetal.,
over,A(ϵ⋆)isexecutedontheserver,alleviatingthecom- 2020),thecommunicationroundsareatmostO(cid:101)(ψ),scaling
putationaloverheadfortheagents. at most logarithmically with T. For example, as shown
Remark4.6. Inthemulti-agentsetting,weassumethatthe inCorollary6.1,withnarmsandusingRandomizedUSM
servercaneitherbeaseparateentityoroneoftheagents (Buchbinderetal.,2015)asasubroutine(whereψisn,β
playing the role of the server. In the single-agent setting, iszero,andγ iszero),ourframeworkguaranteesacommu-
withoutlossofgenerality,thesoleagentcanbeconsidered nicationcomplexityofO(n),notscalingwithT.
astheserver. Theserverorchestratescommunicationbyse-
BydesignoftheC-MA-MABalgorithm,aftereveryaction
lectingclientsandrecommendingwhichactionstoexplore,
queriedbythesubroutine,theagentshavetoexploreand
basedontheofflinesubroutine,inasynchronizedmanner.
estimatethevaluesoftheproposedaction. Todothat,each
Recentstudieshaveexploredfederatedlinearandkernelized agenthastoplaytheproposedactionforr⋆ times. There-
i
contextualbanditswithasynchronouscommunication(Li&
fore, using the result from Lemma 5.1 on the number of
Wang,2022;Heetal.,2022;Lietal.,2023).Futureresearch requiredcommunicationroundsandbythedefinitionofr⋆,
i
mightinvestigategeneralcombinatorialoptimizationwith
wecanderivethattherequiredexplorationstepsforevery
asynchronouscommunication. agent,i.e.,O(r⋆ψTβ+β
1
logγ(T)),whichisdecreasingwith
Remark4.7. TheproposedC-MA-MABusesthetimehori- i
anincreasingnumberofagentsm.
zonT tocomputer⋆andϵ⋆. Whentheexacttimehorizon
isunknown,theresultscanbeenhancedbyemployingthe
5.2.EstimationAnalysis
concept of an anytime algorithm through the use of the
geometric doubling trick by establishing a geometric se- InC-MA-MAB,everyagentplayseachactionqueriedby
quenceoftimeintervals,denotedasT ,whereT = T 2i the subroutine A(ϵ⋆) the same number of times. These
i i 0
fori ∈ N,whereT isasufficientlylargevaluetoensure repetitionsprovideanestimationoftheactionvalues. We
0
6FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
define a good event E when the empirical mean estima- Remark 5.4. Linear speedup is evident in our ap-
tion f¯is a ξ-controlled-estimation of the reward expec- proach, as the collective regret across m agents is
(cid:16) (cid:17)
tation f, o (cid:112)n the played actions during exploration time, O˜ δ3+2 βψ3+1 β(Tm)2 3+ +β β . This mirrors the regret one
withξ := log(T)/r⋆. Foreverycommunicationround
wouldobserveifallmagentscollaborated,sharingatotalof
j, each action A queried by the (α,β,γ,ψ,δ)-resilient-
j Tmtimeforthecentralagent.Consequently,thedistributed
approximationA(ϵ⋆),wherej ∈ {1,··· ,N(β,γ,ψ,ϵ⋆)},
setupincursnoloss, witheachagentinteractingwiththe
wedefinetheeventE as:
j environmentT times,andthecombinedregretreflectsthat
E
j
≜{(cid:12) (cid:12)f¯(A j)−f(A j)(cid:12) (cid:12)≤ξ}. (4) ofasingleagentallocatedTmtimeforinteraction.
Remark5.5. Theδfunctiondependsontheofflinealgorithm
andreferstoageneralfunctionofthecombinatorialproblem
Therefore, the good event E, which considers the em-
pirical mean estimation f¯ is a ξ-controlled estimate of parameters,suchasthenumberofmainarms,n,orthecardi-
nalityconstraint,k.Thisfunctionservesasthescalingfactor
therewardexpectationf foreverycommunicationround
fortheradiusξinthelowerboundontheexpectedreward,
j, i.e., considers the realization of E for every j ∈
j asgivenby(E[f(Θ)]≥(α−ϵ)f(S⋆)−δξ),asdefinedin
{1,··· ,N(β,γ,ψ,ϵ⋆)},whichisexpressedasfollows:
Definition4.2for(α,β,γ,ψ,δ)-resilient-approximational-
E =E ∩···∩E . (5) gorithms. Insomeofflinealgorithms,wehavedemonstrated
1 N(β,γ,ψ,ϵ⋆)
that this scaling function depends on the cardinality con-
EachactionAqueriedbytheofflinealgorithmhavebeen
straintk. Forexample,LemmaE.4showsthatδequals4k
exploredforr⋆numberoftimesamongtheagents. These forRANDOMSAMPLING. Inothercases,thefunctionmay
r⋆ rewards are i.i.d. with expectation f(A) and confined dependsolelyonthenumberofmainarmsn. Forinstance,
within the [0,1] range. Consequently, we can bound the LemmaE.1establishesthatδ is 5 2nforthe RANDOMIZE-
deviationoftheempiricalmeanf¯(A )fromtheexpected DUSM.Ouranalysisaccommodatesanyδfunctiondefined
j
valuef(A )foreveryactionundertaken. Thus,weupper intermsoftheproblemparameters.
j
bound the probability of the good event in the following Remark 5.6. When algorithm approximations do not de-
lemma,whichweproveinAppendixC. pend on ϵ, it implies that their complexity is of the form
O˜(ψ), hence β = γ = 0. It follows that using such an
Lemma5.2. TheprobabilityofthegoodeventE,(5),when
(α,0,0,ψ,δ)-resilient-approximation algorithm as a sub-
usingan(α,β,γ,ψ,δ)-resilient-approximationalgorithm
(cid:16) (cid:17)
A(ϵ⋆)asasubroutinesatisfies: routineachievesaregretofatmostO˜ m−1 3δ2 3ψ31T2 3 .
Remark5.7. Alowerboundremainsanopenquestionfor
P(E)≥1−2N(β,γ,ψ,ϵ⋆)T−2.
generalcombinatorialstochasticrewardsunderbanditfeed-
back. Alowerboundismissingevenforthespecialcases
Combining both results of Lemma 5.1 and Lemma 5.2 it
of stochastic submodular rewards under bandit feedback.
followsthatthebadeventhappenswithaprobabilityofat
Somelowerboundshavebeenproposedinrestrictivespe-
mostO˜(ψTβ+β 1−2),decreasingasT increases. cialsettings. Forexample,Niazadehetal.(2021)showed
aΩ˜(T2 3)lowerboundforadversarialsubmodularrewards,
5.3.RegretAnalysis wheretherewardcouldonlybeobservedinuser-specified
explorationrounds. Moreover,Tajdinietal.(2023)demon-
Weanalyzetheexpectedcumulativeα-regretfortheC-MA-
strated that for monotone stochastic submodular bandits
MAB(Algorithm1),withmcommunicatingagents.
with a cardinality constraint, for small time horizon T, a
Theorem5.3. Forthesequentialcombinatorialdecision- regretscalinglikeT2 3 isinevitablewhencomparedtothe
making problem defined in Section 2, with T ≥ greedyalgorithmin(Nemhauseretal.,1978). However,it
max{ψm,ψm1+ 2β/δβ+1}, the expected cumulative α- doesnotprovidealowerboundon(1−1/e)-regret.
regretoftheC-MA-MABpresentedinAlgorithm1usingan
(α,β,γ,ψ,δ)-resilient-approximationalgorithmA(ϵ⋆)as Inthefollowing,weprovideasketchoftheproofandleave
(cid:16) (cid:17) adetailedoneinAppendixD.Weseparatetheproofinto
subroutineisatmostO˜ m− 3+1 βδ3+2 βψ3+1 βT32 ++ ββ .
twocases. OnecasewhenthegoodeventE happens,which
weshowinLemma5.2happenswithhighprobabilityand
Theabovetheoremimpliesthatanofflinealgorithmdoesnot
thenwegeneralizetheresultunderanyevent.
needtohaveanα-approximationguaranteetobeadaptedto
achievesublinearα-regretguarantees. Infact,an(α−ϵ)-
5.3.1.REGRETOFANAGENTUNDERTHEGOODEVENT
approximationalgorithm,denotedasA(ϵ)withϵ>0,ifit
isa(α,β,γ,ψ,δ)-resilient-approximation,canbeextended Weupper-boundtheexpectedα-regretconditionedonthe
toasub-linearα-regretalgorithm. Later,inSection6,we goodeventE. However,forsimplicityinnotation,weem-
applytheabovetheoremtospecialcombinatorialcases. ploy E[·] rather than E[·|E] in certain instances. We de-
7FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
compose and then bound the expected α-regret into two whenβ =0andγ =1,andthethirdwhenβ >0. Forall
components: oneaddressingtheregretstemmingfromex- thecases,whenthegoodeventE happens,theexpectedα-
ploration(P )andtheotherfromexploitation(P ). regretofourC-MA-MABwithan(α,β,γ,ψ,δ)-resilient-
1 2
approximationassubroutinewehave
T
(cid:88)
E[R i(T)|E]= (αf(S⋆)−E[f(S i,t)]) (6) E[R i(T)|E]≤O˜(cid:16) δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β(cid:17) . (12)
t=1
N(β,γ,ψ,ϵ⋆)
(cid:88)
= r⋆(αf(S⋆)−E[f(A )]) 5.3.2.REGRETOFANAGENTUNDERANYEVENT
i j
j=1
Given that the reward f (·) is upper bound by 1, the ex-
(cid:124) (cid:123)(cid:122) (cid:125) t
α-regretfromexploration(P1) pectedcumulativeα-regretwhentheeventE¯happensover
T arangeT isupper-boundedasfollows: E[R (T)|E¯] ≤ T.
(cid:88) i
+ (αf(S⋆)−E[f(Θ)]) (7) Combiningtheresultswhengoodeventhappensanddoes
t=TN(β,γ,ψ,ϵ⋆)+1 nothappen,usingthelawoftotalexpectation,andusingEq.
(cid:124) (cid:123)(cid:122) (cid:125) (12),Lemma5.1,Lemma5.2,andT ≥mψ:
α-regretfromexploitation(P2)
E[R (T)]=E[R (T)|E]·P(E)+E[R (T)|E¯]·P(E¯)
i i i
Webeginwithboundingregretfromexplorationandusing
(cid:16) (cid:17)
thattherewardsarewithintheinterval[0,1], ≤O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β .
N(β (cid:88),γ,ψ,ϵ⋆) r⋆ r⋆ ThisestablishestheresultinTheorem5.3.
P ≤ α≤N(β,γ,ψ,ϵ⋆) . (8)
1 m m
j=1
6.ApplicationtoSubmodularMaximization
When the good event E occurs, we know that |f¯(A) −
WeuseourC-MA-MABframeworktoaddressscenarios
f(A)| ≤ ξ for all considered action A. Using an
involvingstochasticsubmodular3rewards,withbanditfeed-
(α,β,γ,ψ,δ)-resilient-approximation A(ϵ⋆), with output
back. Submodularmaximization(SM)isanNP-hardprob-
Θ,wehave
lem (Nemhauser et al., 1978; Feige et al., 2011), which
αf(S⋆)−E[f(Θ)]≤δξ+ϵ⋆f(S⋆). (9) recentlyhasshowngrowinginterestinstudyingcombina-
torialMAB(Chenetal.,2018;Niazadehetal.,2021;Nie
Therefore,withf(S⋆)<1,wehave: etal.,2022;Fouratietal.,2023a;2024).Inthefollowing,we
presentourresultsforSMformonotone4andnon-monotone
(cid:88)T rewardswithandwithoutacardinalityconstraintandleave
P ≤ (δξ+ϵ⋆)≤T(δξ+ϵ⋆). (10)
2 theknapsackconstraintinAppendixE.4.
t=TN(β,γ,ψ,ϵ⋆)+1
ForunconstrainedSM(USM),Buchbinderetal.(2015)pro-
Therefore, usingEq. (8)andEq. (10), thetotalexpected posedRANDOMIZEDUSM,achievinga 1-approximation.
2
cumulativeregretinEq. (7)canbeboundedas: InLemmaE.1inAppendixE,wegeneralizeCorollary2in
(Fouratietal.,2023a)toshowitsresilienceandpresentthe
r⋆
E[R (T)|E]≤N(β,γ,ψ,ϵ⋆) +T(δξ+ϵ⋆). (11) followingcorollary, whichrecoverstheguaranteesofthe
i m
onlinealgorithmin(Fouratietal.,2023a)forasingleagent
Using the confidence radius ξ = (cid:112) log(T)/r⋆ and andgeneralizesitformulti-agentsetting.
N(β,γ,ψ,ϵ⋆)=ψ 1 logγ(1),wehave Corollary6.1. C-MA-MAB,usingtheRANDOMIZEDUSM
ϵ⋆β ϵ⋆
asasubroutine,needsatmostO(n)communicationtimes
E[R i(T)|E]≤ ψr⋆ ϵl ⋆o βg mγ( ϵ1 ⋆) +T((cid:114) δ2lo rg ⋆(T) +ϵ⋆). andits 1 2-regretisatmostO˜(cid:16) m−1 3nT2 3(cid:17) forUSM.
ForSMunderacardinalityconstraintk(SMC)withmono-
Wenotethattheaboveinequalityiscorrectforallvaluesof
r⋆ ≥mandϵ⋆ ≥0withtheconventionthat00 =1. Inour tonerewards,theGREEDYin(Nemhauser&Wolsey,1978)
algorithm,wechoosethevaluesofr⋆andϵ⋆asfunctionsof achieves1−1/e. Incontrast,theSTOCHASTIC-GREEDY
theproblemparametersandonthesubroutinecomplexity 3Afunctionf : 2Ω → R, overafinitesetΩ, isconsidered
parameters. Wechooser⋆ asdefinedinEq. (2)andϵ⋆ as submodularifitdisclosesthecharacteristicofdiminishingreturns:
definedinEq. (3). foranyA⊆B ⊂Ωandv∈Ω\B,theinequalityf(A∪{v})−
f(A)≥f(B∪{v})−f(B)isverified.
Recallthatβ ≥ 0andγ ∈ {0,1}. Therefore,weconsider 4Afunctionf : 2Ω → R, overafinitesetΩ, isconsidered
allthepossiblecases,thefirstwhenβ =γ =0,thesecond monotoneifforanyA⊆B ⊆Ωwehavef(A)≤f(B).
8FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
7.ExperimentswithDataSummarization
2000 C-ETC-N
UCB1
1750 C-MA-MAB (m = 1) WeemployourC-MA-MABondatasummarization,apri-
C-MA-MAB (m = 4)
1500 C-MA-MAB (m = 8) marychallengeinmachinelearning(Mirzasoleimanetal.,
C-MA-MAB (m = 16) 2013),mainlywhendealingwithalargedataset. Whilethis
1250 C-MA-MAB (m = 32)
problemhasbeenwidelystudiedwithaccesstoadeterminis-
1000
ticoracle(Lin&Bilmes,2011;Mirzasoleimanetal.,2013;
750
2015;2020;Sivasubramanianetal.,2024),thisworkisthe
500 firsttoaddressonlinedatasummarizationunderastochastic
250 objectivefunction. WerunexperimentsonFMNIST(Xiao
0 etal.,2017)andCIFAR10(Krizhevskyetal.,2009),present
0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 thelatterinthemainpaper,andrelegatemoredetailsand
Time Horizons 1e4
resultstoAppendixF.
Figure1: CumulativeregretsofsummarizingimagesfromCI-
Indatasummarization,anactionAconsistsofasetofat
FAR10fordifferenthorizonsT usingourC-MA-MABframework
withdifferentnumberofagentsm,againstC-ETC-NandUCB1. most k images to summarize a large dataset D. Adding
moreimagesachievesbettersummarizationbutfollowsa
diminishingreturnproperty. Thus,itfallsinthemonotone
in(Mirzasoleimanetal.,2015)achieves1−1/e−ϵ,where SMC(Mirzasoleimanetal.,2015). Evaluatingagivenac-
ϵ is a parameter balancing accuracy and complexity. We tion A against a dataset D may become expensive with
providetheresilienceofthesetwoalgorithmsinAppendix a large dataset. Thus, we consider a stochastic objective
Eandpresentthefollowingresults. where the chosen subset is compared only to a random
subset R ⊆ D drawn uniformly at random from D, us-
Corollary6.2. C-MA-MAB,usingtheGREEDYasasubrou-
ing a similarity metric C, resulting in noisier but lower
tine,needsO(nk)communicationtimesandits(1−1/e)-
(cid:16) (cid:17) complexity evaluations. We do not solve the problem
regretisatmostO˜ m−1 3kn1 3T32 formonotoneSMC. for a given realization R, but we solve it in expectation:
argmax E (cid:2)(cid:80) max C(i,v)(cid:3) .
Corollary 6.3. C-MA-MAB, using the STOCHASTIC- R i∈R v∈A
A⊆D:|A|≤k
GREEDY,needsO˜(n)communicationtimesandits(1−1)-
(cid:16) (cid:17) e WetestourmethodwhenusingtheSTOCHASTIC-GREEDY
regretisatmostO˜ m−1 3k2 3n31T2 3 formonotoneSMC. algorithmasasubroutine(Mirzasoleimanetal.,2015)for
one agent and multiple agents and compare it to the pro-
TheSTOCHASTIC-GREEDYalgorithmhassub-optimalap- posedalgorithminC-ETCframeworkforSMC(C-ETC-N)
proximationguaranteesof(1−1/e−ϵ);thus,usingtheC- (Nieetal.,2023),andtheupperconfidencebound(UCB1)
ETCframeworkfrom(Nieetal.,2023)canonlyguarantee algorithm(Aueretal.,2002).
sub-linear(1−1/e−ϵ)-regret. Consequently,(1−1/e)-
TheC-MA-MABdemonstratessub-linearregretguarantees
regretwillbelinearinT. However,ourC-MA-MABguar-
asdepictedinFig. 1. Additionally,itisapparentthat,for
antees sublinear (1 − 1/e)-regret, recovering the single
varyingvaluesofm,theC-MA-MABconsistentlyoutper-
agent’sresultsin(Fouratietal.,2024).Furthermore,thetwo
formsbothC-ETC-NandUCB1,evenwithasingleagent,
corollariesabovedemonstratethatemployingasub-optimal
exhibitinglowerregretsoverdiversetimehorizons.Notably,
approximationalgorithmintermsoftheapproximationfac-
anincreaseinthenumberofagentscorrelateswithareduc-
tor, rather than one that achieves optimal approximation
tioninregretfortheseagents. Theseobservationsreinforce
guarantees,doesnotnecessarilyimplylowerregretguaran-
thesameconclusionsdrawnfromthetheoreticalanalysis.
tees,asshownin(Fouratietal.,2024).
For non-monotone SMC, the RANDOMSAMPLING algo-
Conclusion
rithmin(Buchbinderetal.,2017)achieves1/e−ϵ,where
ϵ is a parameter balancing accuracy and complexity. We WeintroduceC-MA-MAB,aframeworkforsingle-agent
providetheresilienceofthisalgorithminAppendixEand andmulti-agentonlinestochasticcombinatorialproblems,
derivethefirstresultforsingle-agentandmulti-agentonline whichadaptsresilientoffline(α−ϵ)-approximationalgo-
stochasticnon-monotoneSMCwithsublinearregrets. rithmstoonlinealgorithmsunderbanditfeedback,achiev-
ingsublinearα-regretboundswithrespecttothetimehori-
Corollary 6.4. C-MA-MAB, using the RANDOM SAM-
zonT,eliminatingtheϵerror,andensuringalinearspeedup.
PLINGin(Buchbinderetal.,2017)asasubroutine,needs
O˜(nT2 3)communicationtimesandits(1)-regretisatmost WealsopresentspecializedboundsforSMwithandwithout
(cid:16) (cid:17) e constraintsandapplyC-MA-MABtoonlinestochasticdata
O˜ m−1 5k2 5n1 5T4 5 fornon-monotoneSMC. summarization.
9
stergeR
evitalumuCFederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
ImpactStatement federatedlearning. InInternationalConferenceonMa-
chineLearning,pp.5861–5877.PMLR,2022.
Thispaperpresentsworkwhosegoalistoadvancethefield
of Machine Learning. There are many potential societal Feige,U. Athresholdoflnnforapproximatingsetcover.
consequences of our work, none which we feel must be JournaloftheACM(JACM),45(4):634–652,1998.
specificallyhighlightedhere.
Feige, U., Mirrokni, V. S., and Vondra´k, J. Maximizing
non-monotonesubmodularfunctions. SIAMJournalon
References
Computing,40(4):1133–1153,2011.
Agarwal,M.,Aggarwal,V.,andAzizzadenesheli,K. Multi-
Fourati, F., Aggarwal, V., Quinn, C., and Alouini, M.-S.
agentmulti-armedbanditswithlimitedcommunication.
Randomizedgreedylearningfornon-monotonestochas-
TheJournalofMachineLearningResearch,23(1):9529–
ticsubmodularmaximizationunderfull-banditfeedback.
9552,2022.
InInternationalConferenceonArtificialIntelligenceand
Statistics,pp.7455–7471.PMLR,2023a.
Auer, P., Cesa-Bianchi, N., and Fischer, P. Finite-time
analysis of the multiarmed bandit problem. Machine
Fourati, F., Kharrat, S., Aggarwal, V., Alouini, M.-S.,
learning,47(2):235–256,2002.
and Canini, M. FilFL: Client filtering for optimized
Balakrishnan, R., Li, T., Zhou, T., Himayat, N., Smith, clientparticipationinfederatedlearning. arXivpreprint
V.,andBilmes,J. Diverseclientselectionforfederated arXiv:2302.06599,2023b.
learningviasubmodularmaximization. InInternational
Fourati, F., Quinn, C. J., Alouini, M.-S., and Aggarwal,
ConferenceonLearningRepresentations,2022.
V. Combinatorialstochastic-greedybandit. InProceed-
Barbosa,R.,Ene,A.,Nguyen,H.,andWard,J. Thepower ings of the AAAI Conference on Artificial Intelligence,
ofrandomization: Distributedsubmodularmaximization volume38,pp.12052–12060,2024.
on massive datasets. In International Conference on
Goemans,M.X.andWilliamson,D.P. Improvedapprox-
MachineLearning,pp.1236–1244.PMLR,2015.
imation algorithms for maximum cut and satisfiability
Besson, L. and Kaufmann, E. What doubling tricks can problems using semidefinite programming. Journal of
and can’t do for multi-armed bandits. arXiv preprint theACM(JACM),42(6):1115–1145,1995.
arXiv:1803.06971,2018.
He,J.,Wang,T.,Min,Y.,andGu,Q. Asimpleandprovably
Buchbinder,N.,Feldman,M.,Seffi,J.,andSchwartz,R. A efficientalgorithmforasynchronousfederatedcontextual
tightlineartime(1/2)-approximationforunconstrained linearbandits.Advancesinneuralinformationprocessing
submodularmaximization. SIAMJournalonComputing, systems,35:4762–4775,2022.
44(5):1384–1402,2015.
Hoeffding,W. Probabilityinequalitiesforsumsofbounded
Buchbinder,N.,Feldman,M.,andSchwartz,R. Comparing random variables. In The collected works of Wassily
applesandoranges: Querytrade-offinsubmodularmax- Hoeffding,pp.409–426.Springer,1994.
imization. MathematicsofOperationsResearch,42(2):
Hosseinalipour,S.,Brinton,C.G.,Aggarwal,V.,Dai,H.,
308–329,2017.
and Chiang, M. From federated to fog learning: Dis-
Chawla,R.,Sankararaman,A.,Ganesh,A.,andShakkottai, tributed machine learning over heterogeneous wireless
S. The gossiping insert-eliminate algorithm for multi- networks. IEEECommunicationsMagazine,58(12):41–
agentbandits. InInternationalconferenceonartificial 47,2020.
intelligenceandstatistics,pp.3471–3481.PMLR,2020.
Iwata, S., Fleischer, L., and Fujishige, S. A combinato-
Chen,L.,Xu,J.,andLu,Z. Contextualcombinatorialmulti- rialstronglypolynomialalgorithmforminimizingsub-
armedbanditswithvolatilearmsandsubmodularreward. modularfunctions. JournaloftheACM(JACM),48(4):
AdvancesinNeuralInformationProcessingSystems,31: 761–777,2001.
3247–3256,2018.
Khuller,S.,Moss,A.,andNaor,J.S. Thebudgetedmaxi-
Edmonds,J. Submodularfunctions,matroids,andcertain mumcoverageproblem. Informationprocessingletters,
polyhedra. InCombinatorialOptimization—Eureka,You 70(1):39–45,1999.
Shrink!,pp.11–26.Springer,2003.
Konecˇny`, J., McMahan, H. B., Yu, F. X., Richta´rik, P.,
Elgabli, A., Issaid, C. B., Bedi, A. S., Rajawat, K., Ben- Suresh,A.T.,andBacon,D. Federatedlearning: Strate-
nis,M.,andAggarwal,V. Fednew: Acommunication- gies for improving communication efficiency. arXiv
efficientandprivacy-preservingnewton-typemethodfor preprintarXiv:1610.05492,2016.
10FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Korte,B.H.,Vygen,J.,Korte,B.,andVygen,J. Combina- setfunctions—i. Mathematicalprogramming,14(1):265–
torialoptimization,volume1. Springer,2011. 294,1978.
Krizhevsky, A., Hinton, G., et al. Learning mul- Niazadeh, R., Golrezaei, N., Wang, J. R., Susan, F., and
tiple layers of features from tiny images. Cana- Badanidiyuru,A. Onlinelearningviaofflinegreedyalgo-
dian Institute for Advanced Research, 2009. URL rithms: Applicationsinmarketdesignandoptimization.
http://www.cs.toronto.edu/kriz/cifar.html,2009. In Proceedings of the 22nd ACM Conference on Eco-
nomicsandComputation,pp.737–738,2021.
Lattimore,T.andSzepesva´ri,C. Banditalgorithms. Cam-
bridgeUniversityPress,2020. Nie,G.,Agarwal,M.,Umrawal,A.K.,Aggarwal,V.,and
Quinn,C.J. Anexplore-then-commitalgorithmforsub-
Li,C.andWang,H. Asynchronousupperconfidencebound modularmaximizationunderfull-banditfeedback.InThe
algorithmsforfederatedlinearbandits. InInternational 38thConferenceonUncertaintyinArtificialIntelligence,
Conference on Artificial Intelligence and Statistics, pp. 2022.
6529–6553.PMLR,2022.
Nie,G.,Nadew,Y.Y.,Zhu,Y.,Aggarwal,V.,andQuinn,
Li,C.,Wang,H.,Wang,M.,andWang,H. Learningkernel- C. J. A framework for adapting offline algorithms to
izedcontextualbanditsinadistributedandasynchronous solvecombinatorialmulti-armedbanditproblemswith
environment. InInternationalConferenceonLearning banditfeedback. InternationalConferenceonMachine
Representation,2023. Learning,2023.
Li,T.,Sahu,A.K.,Zaheer,M.,Sanjabi,M.,Talwalkar,A., Sivasubramanian,D.,Nagalapatti,L.,Iyer,R.,andRamakr-
andSmith,V. Federatedoptimizationinheterogeneous ishnan, G. Gradient coreset for federated learning. In
networks.ProceedingsofMachineLearningandSystems, ProceedingsoftheIEEE/CVFWinterConferenceonAp-
2:429–450,2020. plicationsofComputerVision,pp.2648–2657,2024.
Lin, H. and Bilmes, J. A class of submodular functions Slivkins, A. et al. Introduction to multi-armed bandits.
fordocumentsummarization. InProceedingsofthe49th Foundations and Trends® in Machine Learning, 12(1-
annualmeetingoftheassociationforcomputationallin- 2):1–286,2019.
guistics: human language technologies, pp. 510–520,
2011. Sviridenko, M. A note on maximizing a submodular set
function subject to a knapsack constraint. Operations
McMahan,B.,Moore,E.,Ramage,D.,Hampson,S.,and ResearchLetters,32(1):41–43,2004.
yArcas,B.A. Communication-efficientlearningofdeep
networks from decentralized data. In Artificial intelli- Tajdini, A., Jain, L., and Jamieson, K. Minimax optimal
genceandstatistics,pp.1273–1282.PMLR,2017. submodular optimization with bandit feedback. arXiv
preprintarXiv:2310.18465,2023.
Mirzasoleiman, B., Karbasi, A., Sarkar, R., and Krause,
A. Distributed submodular maximization: Identifying Takemori,S.,Sato,M.,Sonoda,T.,Singh,J.,andOhkuma,
representative elements in massive data. Advances in T. Submodularbanditproblemundermultipleconstraints.
NeuralInformationProcessingSystems,26,2013. InConferenceonUncertaintyinArtificialIntelligence,
pp.191–200.PMLR,2020.
Mirzasoleiman,B.,Badanidiyuru,A.,Karbasi,A.,Vondra´k,
Wang,P.-A.,Proutiere,A.,Ariu,K.,Jedra,Y.,andRusso,A.
J.,andKrause,A. Lazierthanlazygreedy. InProceed-
Optimalalgorithmsformultiplayermulti-armedbandits.
ings of the AAAI Conference on Artificial Intelligence,
InInternationalConferenceonArtificialIntelligenceand
volume29,2015.
Statistics,pp.4120–4129.PMLR,2020.
Mirzasoleiman,B.,Bilmes,J.,andLeskovec,J. Coresets
Xiao, H., Rasul, K., and Vollgraf, R. Fashion-mnist: a
for data-efficient training of machine learning models.
novelimagedatasetforbenchmarkingmachinelearning
In International Conference on Machine Learning, pp.
algorithms. arXivpreprintarXiv:1708.07747,2017.
6950–6960.PMLR,2020.
Yaroslavtsev,G.,Zhou,S.,andAvdiukhin,D. “bringyour
Nemhauser,G.L.andWolsey,L.A. Bestalgorithmsforap-
own greedy”+ max: Near-optimal 1/2-approximations
proximatingthemaximumofasubmodularsetfunction.
forsubmodularknapsack. InInternationalConference
Mathematicsofoperationsresearch,3(3):177–188,1978.
onArtificialIntelligenceandStatistics,pp.3263–3274.
Nemhauser, G. L., Wolsey, L. A., and Fisher, M. L. An PMLR,2020.
analysisofapproximationsformaximizingsubmodular
11FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
A.Notation
In the following, for a given agent i when we discuss any feasible action denoted as A, we use f (A) to represent the
t
realizationofthestochasticrewardattimetwhentakingthataction. Wedenotetheexpectationoftherewardofplaying
thatactionasf(A). Wealsointroducef¯(A),whichistheempiricalmeanofrewardsreceivedfromplayingactionAupto
t
andincludingtimet.
Weomitthesubscripttwhenwewritef¯(A),assumingitisclearthatactionAhasbeenplayedr⋆times. WeuseA ,with
j
j rangingfrom1tothetotalnumberoftheapproximationalgorithmqueriesN(β,γ,ψ,ϵ⋆),torefertothej-thactionthe
algorithmqueries. Additionally,wedefineT ,wherejalsovariesfrom1tothetotalnumberoftheofflinealgorithmqueries
j
N(β,γ,ψ,ϵ⋆),asthetimestepwhenA hasbeenplayedr⋆times.
j
B.CommunicationRoundsAnalysis
In this subsection we prove Lemma 5.1 which upperbounds the number of oracle queries N(β,γ,ψ,ϵ⋆) of the offline
algorithmA(ϵ⋆)asfollows:
N(β,γ,ψ,ϵ⋆)≤O(ψTβ+β
1
logγ(T))
Weprovideexamplesoftheresultingnumberoforaclequeriesfordifferentofflinealgorithmsorclasstransformationsin
Table2,asshowninLemma5.1.
Proof. Usingan(α,β,γ,ψ,δ)-robustapproximationassubroutine,wehaveafterN(β,γ,ψ,ϵ)=ψ 1 logγ(1)oraclecalls,
ϵβ ϵ
forϵ≥0,β ≥0,andγ ∈{0,1}.
Recallthatϵ⋆isasfollows:
ψr⋆
ϵ⋆ =( Tm)β+1 11 {β>0ORγ>0}. (13)
Recallthatβ ≥ 0andγ ∈ {0,1}. Therefore,weconsiderallthepossiblecases(three),thefirstwhenβ = γ = 0,the
secondwhenβ =0andγ >0,andthethirdwhenβ >0.
Case1: β =γ =0. UsingEq.(3),ϵ⋆becomesthefollowing
ϵ⋆ =0. (14)
N(β,γ,ψ,ϵ⋆)=2ψ
=O(ψTβ+β 1 logγ(T)) (15)
Case2: β =0andγ ̸=0. Wehaveγ ̸=0andγ ∈{0,1},thusγ =1.
UsingEq.(3),ϵ⋆becomesthefollowing
ψr⋆
ϵ⋆ = . (16)
Tm
12FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Offline C-MA-MABResulted
OfflineAlgorithm
Complexity CommunicationComplexity
RANDOMIZEDUSM
O(n) O(n)
(Buchbinderetal.,2015)
GREEDY
O(nk) O(nk)
(Nemhauseretal.,1978)
GENERAL
O(ψ) O(ψ)
Excludingthenextrows
STOCHASTIC-GREEDY O(cid:0) nlog(1)(cid:1)
O(nlog(T))
(Mirzasoleimanetal.,2015) ϵ
MOREGENERAL
O(ψlogγ(1)) O(ψlogγ(T))
Excludingthenextrows ϵ
(BR uA chN bD inO dM erS eA tM alP .,L 2IN 01G 7) O(cid:0) ϵn 2 log(1 ϵ)(cid:1) O(ψT2 3 log(T))
MOSTGENERAL O(ψ logγ(1)) O(ψTβ+β 1 logγ(T))
Includingthepreviousrows ϵβ ϵ
Table2: Thetableshowstheresultedcommunicationcomplexitywithdifferentofflinealgorithms.WeuseO˜tosimplifyexpressions.
KeyparametersincludehorizonT,numberofcommunicatingagentsm,basearmcountn,andcardinalityconstraintk.Eachrowpresents
aspecificofflinealgorithmoraclasstransformationwithagivenofflinecomplexity.Forthegeneralrows,weconsiderclassesofoffline
algorithms,withanapproximationerrorfactorϵ,withgeneralcomplexityforms,withgeneralconstants,ψ≥0,β ≥0,andγ ∈{0,1}.
1 1
N(β,γ,ψ,ϵ⋆)=2ψ( )βlogγ( )
ϵ⋆ ϵ⋆
1
=2ψlog( )
ϵ⋆
Tm
=2ψlog( )
ψr⋆
T
=2ψlog( )
ψr⋆
i
≤2ψlog(T)
=O(ψlog(T))
=O(ψTβ+β 1 logγ(T)) (17)
Case3: β >0. UsingEq.(3),ϵ⋆becomesthefollowing
ψr⋆
ϵ⋆ =( )β+1 1. (18)
Tm
Therefore,
1 1
N(β,γ,ψ,ϵ⋆)=2ψ( )βlogγ( )
ϵ⋆ ϵ⋆
1 Tm Tm
=2ψ( )γ( )β+β 1 logγ( )
β+1 ψr⋆ ψr⋆
1 T T
=2ψ( )γ( )β+β 1 logγ( )
β+1 ψr⋆ ψr⋆
i i
1
≤2ψ( )γ(T)β+β 1 logγ(T)
β+1
=O(ψTβ+β 1 logγ(T)) (19)
13FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
C.EstimationAnalysis
Hoeffding’sinequality(Hoeffding,1994)isapowerfultechniqueforboundingprobabilitiesofboundedrandomvariables.
Westatetheinequality,thenweuseittoshowthatE happenswithhighprobability.
LemmaC.1(Hoeffding’sinequality). LetX ,··· ,X beindependentrandomvariablesboundedintheinterval[0,1],and
1 n
letX¯ denotetheirempiricalmean. Thenwehaveforanyξ >0,
P(cid:0)(cid:12) (cid:12)X¯ −E[X¯](cid:12) (cid:12)≥ξ(cid:1) ≤2exp(cid:0) −2nξ2(cid:1) . (20)
WeusetheaboveLemmatoproveLemma5.2whichboundstheprobabilityofthegoodeventE asfollows:
2N(β,γ,ψ,ϵ⋆)
P(E)≥1− .
T2
Proof. ApplyingtheHoeffdingboundinLemmaC.1totheempiricalmeanf¯(A )ofA resultedfromr⋆ independent
i i
(cid:112)
rewardsandwithξ = log(T)/r⋆provides
P(E¯ i)=P(cid:2)(cid:12) (cid:12)f¯(A i)−f(A i)(cid:12) (cid:12)≥ξ(cid:3)
≤2exp(cid:0) −2r⋆ξ2(cid:1)
=2exp(−2r⋆(log(T)/r⋆))
=2exp(−2log(T))
2
= . (21)
T2
Then,wecanboundtheprobabilityofthegoodeventasfollows:
P(E)=P(E ∩···∩E )
1 N(β,γ,ψ,ϵ⋆)
=1−P(E¯ ∪···∪E¯ ) (DeMorgan’sLaw)
1 N(β,γ,ψ,ϵ⋆)
N(β,γ,ψ,ϵ⋆)
≥1− (cid:88) P(E¯) (unionbounds)
i
i=1
2N(β,γ,ψ,ϵ⋆)
≥1− . (using(21))
T2
D.regretAnalysis
WeestablishTheorem5.3outlinedinSection4.1ofthemainpaper. Thistheoremassertsthatforthesequentialdecision-
makingscenariodelineatedinSection2,theexpectedcumulativeα-regretoftheC-MA-MAB,employingan(α,β,γ,ψ,δ)-
(cid:16) (cid:17)
resilient-approximationalgorithmA(ϵ)asacomponent,isboundedbyO˜ δ3+2 βψ3+1 βm−1 3+ +β βT2 3+ +β β .
Weseparatetheproofintotwocases. OnecasewhenthegoodeventE happens,whichweshowinLemma5.2happenswith
highprobabilityandthenwegeneralizetheresultunderanyevent.
D.1.regretofanAgentundertheGoodEvent
We upper-bound the expected α-regret given the occurrence of the good event E. All expectations are conditioned on
E throughoutthissection. However, forthesakeofsimplicityinnotation, weemployE[·]ratherthanE[·|E]incertain
instances.
Webreakdowntheanticipatedα-regretgivenE intotwoparts: onedealingwithregretarisingfromexplorationandthe
otherfromexploitation. Itiscrucialtorememberthatf (A )denotesthestochasticrewardobtainedbyselectingactionA ,
t t t
14FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
avariabledependentonthehistoricalmeansofactionsinpreviousrounds.
T
(cid:88)
E[R (T)|E]= (αf(S⋆)−E[f (S )])
i t i,t
t=1
T
(cid:88)
= (αf(S⋆)−E[E[f (S )|S ]]) (22)
t i,t i,t
t=1
T
(cid:88)
= (αf(S⋆)−E[f(S )]) (f(·)definedasexpectedreward)
i,t
t=1
N(β,γ,ψ,ϵ⋆) T
(cid:88) (cid:88)
= r⋆(αf(S⋆)−E[f(A )])+ (αf(S⋆)−E[f(A )])
i j t
j=1 t=TN(β,γ,ψ,ϵ⋆)+1
N(β,γ,ψ,ϵ⋆) T
(cid:88) (cid:88)
= r⋆(αf(S⋆)−E[f(A )])+ (αf(S⋆)−E[f(Θ)]). (23)
i j
j=1 t=TN(β,γ,ψ,ϵ⋆)+1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
AgentiExplorationregret AgentiExploitationregret
Weestablishdistinctboundsfortheregretstemmingfromexplorationandexploitationindividually.
Boundingtheagentiexplorationregret:
N(β (cid:88),γ,ψ,ϵ⋆) N(β (cid:88),γ,ψ,ϵ⋆) r⋆
r (αf(S⋆)−E[f(A )])≤ (α−0) (rewardsin[0,1])
i i m
j=1 j=1
r⋆
≤N(β,γ,ψ,ϵ⋆) . (24)
m
Bounding exploitation regret: When the good event E occurs, we know that |f¯(A)−f(A)| ≤ ξ for all considered
actionA. ForC-MA-MABframework,withexploitationsetΘ,withan(α,β,γ,ψ,δ)-resilient-approximationA(ϵ)asa
subroutine,wehaveafterN(β,γ,ψ,ϵ)=ψ 1 logγ(1)oraclecalls,forϵ≥0,β ≥0,andγ ∈{0,1},
ϵβ ϵ
E[f(Θ)]≥(α−ϵ)f(S⋆)−δξ. (25)
Therefore,usingϵ⋆,wehave
αf(S⋆)−E[f(Θ)]≤δξ+ϵ⋆f(S⋆). (26)
Therefore,wecanboundtheexploitationregretasfollows:
T T
(cid:88) (cid:88)
(αf(S⋆)−E[f(S)])≤ (δξ+ϵ⋆f(S⋆)) (using(26))
t=TN(β,γ,ψ,ϵ⋆)+1 t=TN(β,γ,ψ,ϵ⋆)+1
T
(cid:88)
≤ (δξ+ϵ⋆) (rewardsareboundedin[0,1])
t=TN(β,γ,ψ,ϵ⋆)+1
≤T(δξ+ϵ⋆). (27)
Boundingtotalregret:
N(β (cid:88),γ,ψ,ϵ⋆) r⋆ (cid:88)T
E[R (T)|E]= (αf(S⋆)−E[f(A )])+ (αf(S⋆)−E[f(S)]) (copying(23))
i m i
i=1 t=TN(β,γ,ψ,ϵ⋆)+1
r⋆
≤N(β,γ,ψ,ϵ⋆) +T(δξ+ϵ⋆) (using(24),(27))
m
15FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
(cid:112)
Usingthedefinedconfidenceradiusξ = log(T)/r⋆,wehave
r⋆ (cid:112)
E[R (T)|E]≤N(β,γ,ψ,ϵ⋆) +ϵ⋆T +Tδ log(T)/r⋆
i m
≤ψ 1 logγ( 1 )r⋆ +ϵ⋆T +Tδ(cid:112) log(T)/r⋆ (28)
ϵ⋆β ϵ⋆ m
WenotethattheinequalityinEq.(28)iscorrectforallvaluesofr⋆ ≥mandϵ⋆ ≥0withtheconventionthat00 =1.
Inouralgorithm,wechoosethefollowingvaluesofr⋆andϵ⋆asfunctionsoftheproblemparameterssuchastherangeT
andthenumberofavailableagentsmaswellasonthesubroutinealgorithmapproximationresilienceparameterguarantees,
thatareβ,γ,ψ,andδ. Specifically,usingan(α,β,γ,ψ,δ)-robustapproximationassubroutine,wechooser⋆asfollows:
 (cid:32)
(cid:112)
(cid:18) Tm(cid:19) β+1 1(cid:33)2 3+ +2 ββ
r⋆ =mm−1 δ log(T) , (29)
 ψ 
 
Forclarityinthefollowingstepswefurtherdefinezasfollows:
(cid:32)
(cid:112)
(cid:18) Tm(cid:19) β+1 1(cid:33)2 3+ +2 ββ
z = δ log(T) , (30)
ψ
Moreover,wechooseϵ⋆asfollows:
ψr⋆
ϵ⋆ =( Tm)β+1 11 {β>0ORγ>0}. (31)
Therefore,fromEq. (28),
E[R (T)|E]≤ψ( 1 )βlogγ( 1 )r⋆ +ϵ⋆T +Tδ(cid:112) log(T)/r⋆ (32)
i ϵ⋆ ϵ⋆ m
(cid:114)
1 1 (cid:108) z (cid:109) (cid:108) z (cid:109)
≤ψ( )βlogγ( ) +ϵ⋆T +Tδ log(T)/(m ) (33)
ϵ⋆ ϵ⋆ m m
(cid:114)
1 1 (cid:108) z (cid:109) z
≤ψ( )βlogγ( ) +ϵ⋆T +Tδ log(T)/(m ) (Since⌈z/m⌉≥z/m)
ϵ⋆ ϵ⋆ m m
≤2ψ( 1 )βlogγ( 1 ) z +ϵ⋆T +Tδ(cid:112) log(T)/z (Sincez ≥m,⌈z/m⌉≤2z)
ϵ⋆ ϵ⋆ m
1+β
wherethelastinequalityfollowswhenz ≥m,whichholdsforT ≥ ψm 2 .
δβ+1
Therefore,
E[R (T)|E]≤2ψ( 1 )βlogγ( 1 ) z +ϵ⋆T +Tδ(cid:112) log(T)/z (34)
i ϵ⋆ ϵ⋆ m
Recallthatβ ≥ 0andγ ∈ {0,1}. Therefore,weconsiderallthepossiblecases(three),thefirstwhenβ = γ = 0,the
secondwhenβ =0andγ >0,andthethirdwhenβ >0.
Case1: β =γ =0.
InthiscaseusingEq. (30),zbecomesthefollowing
(cid:18) (cid:18) (cid:19)(cid:19)2
(cid:112) Tm 3
z = δ log(T) . (35)
ψ
Moreover,usingEq.(3),ϵ⋆becomesthefollowing
ϵ⋆ =0. (36)
16FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
FromEq.(34)wehave
2ψ
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19) 32
(cid:112)
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19)−1
3
E[R (T)|E]≤ δ log(T) +Tδ log(T) δ log(T) (37)
i m ψ ψ
≤2
ψ m32
δ2 3 log(T)1 3T2 3 +T32δ2 3 log(T)31m−1 3ψ1 3 (38)
ψ2
3
m
(cid:16) (cid:17)
=O δ2 3ψ1 3m− 31T2 3 log(T)31 . (39)
(cid:16) (cid:17)
=O˜ δ2 3ψ1 3m− 31T2 3 (40)
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β . (Giventhatβ =0)
Case2: β =0andγ ̸=0.
Wehaveγ ̸=0andγ ∈{0,1},thusγ =1. InthiscaseusingEq. (30),zbecomesthefollowing
(cid:18) (cid:18) (cid:19)(cid:19)2
(cid:112) Tm 3
z = δ log(T) . (41)
ψ
Moreover,usingEq.(3),ϵ⋆becomesthefollowing
ψr⋆
ϵ⋆ = . (42)
Tm
FromEq. (34)wehave
2ψ Tm ψr⋆ (cid:112) (cid:18) (cid:112) (cid:18) Tm(cid:19)(cid:19)− 31
E[R (T)|E]≤ log( )z+ T +Tδ log(T) δ log(T) (43)
i m ψr⋆ Tm ψ
2ψ Tm 2ψ (cid:112)
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19)−1
3
≤ log( )z+ z+Tδ log(T) δ log(T) (44)
m ψr⋆ m ψ
2ψ 2ψ (cid:112)
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19)−1
3
≤ log(T)z+ z+Tδ log(T) δ log(T) (45)
m m ψ
4ψ
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19) 32
(cid:112)
(cid:18)
(cid:112)
(cid:18) Tm(cid:19)(cid:19)− 31
≤ log(T) δ log(T) +Tδ log(T) δ log(T) (46)
m ψ ψ
(cid:16) (cid:17)
=O˜ δ2 3ψ31m−1 3T32 (47)
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β . (Giventhatβ =0)
Case3: β >0. InthiscaseusingEq. (30),zbecomesthefollowing
(cid:32)
(cid:112)
(cid:18) Tm(cid:19) β+1 1(cid:33)2 3+ +2 ββ
z = δ log(T) . (48)
ψ
Moreover,usingEq.(3),ϵ⋆becomesthefollowing
ψr⋆
ϵ⋆ =( )β+1 1. (49)
Tm
FromEq.(34)wehave
E[R i(T)|E]≤ 2 mψ ( ϵ1 ⋆)βlogγ( ϵ1 ⋆)z+ϵ⋆T +Tδ(cid:112) log(T)(z)− 21 (50)
17FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Therefore,withβ >0itexistsaconstantC sufficientlylargesuchas:
E[R i(T)|E]≤ 2C mψ ( ϵ1 ⋆)βz+ϵ⋆T +Tδ(cid:112) log(T)(z)− 21 (51)
≤ 2Cψ (Tm )β+β 1z+(ψr⋆ )β+1 1T +Tδ(cid:112) log(T)(z)− 21 (52)
m ψr⋆ Tm
≤ 2Cψ (Tm )β+β 1z+(2ψz )β+1 1T +Tδ(cid:112) log(T)(z)− 21 (53)
m ψz Tm
≤Dψ (Tm )β+β 1z+Tδ(cid:112) log(T)(z)− 21 (54)
m ψz
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β .
Inconclusion,forallthecases,ifthebadeventE happens,theexpectedα-regretofourC-MA-MABwithan(α,β,γ,ψ,δ)-
resilient-approximationasasubroutineisupperboundedbyasfollows:
(cid:16) (cid:17)
E[R i(T)|E]≤O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β . (55)
D.2.RegretofanAgentunderAnyEvent
ByLemma5.2,theprobabilityofthebadeventisupper-boundedasfollows
2N(β,γ,ψ,ϵ⋆)
P(E¯)≤ . (56)
T2
Sincetherewardfunctionf (·)isupperboundedby1,theexpectedα-regretincurredunderE¯forarangeT islimitedtoa
t
maximumofT,
E[R (T)|E¯]≤T. (57)
i
Combiningtheresultswhenbadeventhappensanddoesnothappen,wehave
E[R (T)]=E[R (T)|E]·P(E)+E[R (T)|E¯]·P(E¯) (Lawoftotalexpectation)
i i i
(cid:16) (cid:17) 2N(β,γ,ψ,ϵ⋆)
≤O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β 1+T · (using(55),(56),and(57))
T2
(cid:16) (cid:17) 2N(β,γ,ψ,ϵ⋆)
≤O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β 1+ (58)
T
≤O˜(cid:16)
δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β
β(cid:17)
1+
O˜(ψ3+1 βψ2 3+ +β βTβ+β 1)
(usingLemma5.1)
T
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β +O˜(ψ3+1 βψ2 3+ +β βT− β+1 1) (59)
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β +O˜(ψ3+1 βT2 3+ +β βm−2 3+ +β βT− β+1 1) (usingT ≥mψ)
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β +O˜(ψ3+1 βm− 3+1 β−1 3+ +β βT2 3+ +β β− β+1 1) (60)
(cid:16) (cid:17)
=O˜ δ3+2 βψ3+1 βm− 3+1 βT2 3+ +β β .
Thisconcludestheproof.
18FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
E.ApplicationtoSubmodularMaximization
Weapplyourgeneralframeworktoonlinestochasticsubmodularmaximization. Inthefollowing,weprovideexamplesof
submodularmaximizationproblems.Weprovideresultsforunconstrained,undercardinality,andunderknapsackconstraints,
byshowingtheresilienceofdifferentofflinealgorithmsinthesesettings.
E.1.SubmodularMaximizationExamples
Submodularityarisesincriticalcontextswithincombinatorialoptimization,suchasgraphcuts(Goemans&Williamson,
1995;Iwataetal.,2001),rankfunctionsofmatroids(Edmonds,2003),andsetcoveringproblems(Feige,1998).Furthermore,
recentworkshavedemonstratedthatvariousreal-worldproblemsexhibitsubmodularity,includingdatasummarizationand
coresetselectionformodeltraining(Mirzasoleimanetal.,2015;2020),clientparticipationoptimizationinFL(Balakrishnan
etal.,2022;Fouratietal.,2023b),recommendationsystems(Takemorietal.,2020),crowdsourcing,crowdsensing,and
influencemaximization(Fouratietal.,2024).
E.2.UnconstrainedSubmodularMaximization
LemmaE.1(GeneralizationofCorollary2of(Fouratietal.,2023a)). RANDOMIZEDUSM(Buchbinderetal.,2015)isa
(1,0,0,4n,5n)-resilient-approximationalgorithmforunconstrainednon-monotoneSM.
2 2
Proof. TheofflineRandomizedUSM 1-approximationalgorithmproposedin(Buchbinderetal.,2015)requires4noracle
2
calls,thusα=1/2,ψ =4n,γ =0,andβ =0. Furthermore,asshowninCorollary2of(Fouratietal.,2023a),usinga
ξ-controlled-estimationf¯ofthefunctionf,
1 5
E[f(X )]≥ E[f(OPT)]− nξ. (61)
n 2 2
Therefore,theRandomizedUSMisan(1,0,0,4n,5n)-resilient-approximationalgorithmforunconstrainednon-monotone
2 2
submodularmaximizationproblem.
E.3.SubmodularMaximizationwithCardinalityConstraint
Lemma E.2 (Generalization of Corollary 4.3 of (Nie et al., 2022)). GREEDY in (Nemhauser et al., 1978) is a (1−
1,0,0,nk,2k)-resilient-approximationalgorithmformonotoneSMunderacardinalityconstraintk.
e
Proof. TheofflineGREEDY(1−1/e)-approximationalgorithmproposedin(Nemhauseretal.,1978)requiresnkoracle
calls,thusα=(1−1/e),ψ =nk,γ =0,andβ =0. Furthermore,asshowninCorollary4.3of(Nieetal.,2022),usinga
ξ-controlled-estimationf¯ofthefunctionf,
E[f(X )]≥(1−1/e)E[f(OPT)]−2kξ. (62)
n
Therefore,theGREEDYisan(1− 1,0,0,nk,2k)-resilient-approximationalgorithmalgorithmformonotonesubmodular
e
maximizationunderak-cardinalityconstraint.
LemmaE.3(GeneralizationofCorollary1of(Fouratietal.,2024)). STOCHASTIC-GREEDY in(Mirzasoleimanetal.,
2015)isa(1− 1,0,1,n,2k)-resilient-approximationalgorithmformonotoneSMunderacardinalityconstraintk.
e
Proof. TheofflineSTOCHASTIC-GREEDY(1−1/e−ϵ)-approximationalgorithmproposedin(Mirzasoleimanetal.,2015)
requiresnlog(1)oraclecalls,thusα = (1−1/e),ψ = n,γ = 1,andβ = 0. Furthermore,asshowninCorollary1of
ϵ
(Fouratietal.,2024),usingaξ-controlled-estimationf¯ofthefunctionf,
E[f(X )]≥(1−1/e)E[f(OPT)]−2kξ. (63)
n
Therefore,theSTOCHASTIC-GREEDYisan(1− 1,0,1,n,2k)-resilient-approximationalgorithmalgorithmformonotone
e
submodularmaximizationunderak-cardinalityconstraint.
19FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
LemmaE.4. RANDOMSAMPLINGin(Buchbinderetal.,2017)isa(1,2,1,n,4k)-resilient-approximationalgorithmfor
e
non-monotoneSMunderacardinalityconstraintk.
Proof. TheofflineRANDOMSAMPLING(1/e−ϵ)-approximationalgorithmproposedin(Buchbinderetal.,2017)requires
n1 log(1)oraclecalls,thusα=(1/e),ψ =n,γ =1,andβ =2.
ϵ2 ϵ
Bydesignofthealgorithm,wehave
f(S )−f(S )≥f¯(S )−f¯(S )−2ξ (usingξ-controlledestimation)
i i−1 i i−1
=max(cid:8) f¯(S ∪{u })−f(S ),0(cid:9) −2ξ (byalgorithm)
i−1 i i−1
Similartothestepsin(Buchbinderetal.,2017),letA representaneventencompassingallrandomdecisionsmadeby
i
thealgorithmuptoiterationi(excludingit). Intheinitialsegmentoftheproof,weselectaspecificiteration1 ≤ i ≤ k
andanassociatedeventA . AllprobabilitiesandexpectationswithinthisproofportionareimplicitlyconditionedonA .
i i
Itisimportanttonotethat,whenconditionedonA ,thesetS becomesdeterministic. Weusev ,v ,...,v todenote
i i−1 1 2 k
thekelementsofN (includingS )withthehighestmarginalcontributiontoS ,arrangedinnon-increasingorderof
i−1 i−1
marginalcontribution. Additionally,letX beanindicatorfortheeventu =v .
j i j
E[f(S )−f(S )]=E(cid:2) max(cid:8) f¯(S ∪{u })−f¯(S ),0(cid:9)(cid:3) −2ξ (64)
i i−1 i−1 i i−1
k
≥(cid:88)(cid:2)E[X ]·max(cid:8) f¯(S ∪{v })−f¯(S ),0(cid:9)(cid:3) −2ξ (65)
j i−1 j i−1
j=1
(cid:80)k E[X ]·(cid:80)k max(cid:8) f¯(S ∪{v })−f¯(S ),0(cid:9)
≥ j=1 j j=1 i−1 j i−1 −2ξ. (66)
k
Where the last inequality holds by Chebyshev’s sum inequality since max(cid:8) f¯(S ∪{v })−f¯(S ),0(cid:9) is non-
i−1 j i−1
increasinginj bydefinitionandE[X ]isnon-increasinginj byLemma4.2in(Buchbinderetal.,2017). Therefore,
j
k
(cid:88) max(cid:8) f¯(S ∪{v })−f¯(S ),0(cid:9) ≥ (cid:88) f¯(S ∪{u})−f¯(S ) (bydefinitionofv )
i−1 j i−1 i−1 i−1 j
j=1 u∈OPT
(cid:88)
≥ (f(S ∪{u})−f(S )−2ξ) (byξ-controlledestimation)
i−1 i−1
u∈OPT
(cid:88)
≥ (f(S ∪{u})−f(S ))−2kξ (|OPT|≤k)
i−1 i−1
u∈OPT
≥f(OPT ∪S )−f(S )−2kξ. (bysubmodularityoff)
i−1 i−1
ByLemma4.1in(Buchbinderetal.,2017),wehaveE[X ]≥1−ε. Therefore,
j
f(OPT ∪S )−f(S )
E[f(S )−f(S )]≥(1−ε)· i−1 i−1 −4ξ. (67)
i i−1 k
First,sincetheaboveequationholdsforeverygiveneventA ,italsoholdsinexpectationunconditionally. Moreformally,
i
wegetforevery1≤i≤k,
E[f(OPT ∪S )]−E[f(S )]
E[f(S )−f(S )]≥(1−ε)· i−1 i−1 −4ξ.
i i−1 k
LetuslowerboundE[f(OPT ∪S i−1)]. RANDOMSAMPLINGaddseachelementtoitssolutionwithprobabilityatmost
(⌈pn⌉/n)/s = 1/k. Hence, each element belongs to S with probability at most 1 − (1 − 1/k)i−1. Let h(S) =
i−1
h(S∪OPT). Sincehisanonnegativesubmodularfunction,wegetbyLemma2.2,
E[f(OPT ∪S )]=E[h(S )]≥(1−1/k)i·h(∅)=(1−1/k)i·f(OPT).
i i
20FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Combiningthetwoaboveinequalitiesyields,
(1−1/k)i−1·f(OPT)−E[f(S )]
E[f(S )−f(S )]≥(1−ε)· i−1 −4ξ
i i−1 k
(cid:2) (1−1/k)i−1−ε(cid:3) ·f(OPT)−E[f(S )]
i−1
≥ −4ξ.
k
Weprovebyinductionthefollowing:
E[f(S )]≥ i ·(cid:2) (1−1/k)i−1−ε(cid:3) ·f(OPT)−4iξ.
i k
Fori=0,thecorollaryholdssincef(S
)≥0=(0/k)·(cid:2) (1−1/k)−1−ε(cid:3)
·f(OPT)-0. Assumethecorollaryholdsfor
0
i−1≥0,letusproveitfori:
(cid:2) (1−1/k)i−1−ε(cid:3) ·f(OPT)−E[f(S )]
E[f(S )]≥E[f(S )]+ i−1 −4ξ
i i−1 k
(cid:2) (1−1/k)i−1−ε(cid:3)
·f(OPT)
=(1−1/k)·E[f(S )]+ −4ξ
i−1 k
≥(1−1/k)·(cid:18) i−1 ·(cid:2) (1−1/k)i−2−ε(cid:3) ·f(OPT)−4(i−1)ξ(cid:19)
+
(cid:2) (1−1/k)i−1−ε(cid:3) ·f(OPT)
−4ξ
k k
≥(1−1/k)·(cid:18) i−1 ·(cid:2) (1−1/k)i−2−ε(cid:3) ·f(OPT)(cid:19)
+
(cid:2) (1−1/k)i−1−ε(cid:3) ·f(OPT)
−4(i−1)ξ−4ξ
k k
≥
i ·(cid:2) (1−1/k)i−1−ε(cid:3)
·f(OPT)−4iξ.
k
Pluggingi=kintotheabovecorollaryyields
E[f(S )]≥(cid:2) (1−1/k)k−1−ε(cid:3) ·f(OPT)−4kξ ≥(cid:0) e−1−ε(cid:1) ·f(OPT)−4kξ.
k
Therefore,theRANDOMSAMPLINGisan(1,2,1,n,4k)-resilient-approximationalgorithmalgorithmfornon-monotone
e
submodularmaximizationunderak-cardinalityconstraint.
E.4.SubmodularMaximizationwithKnapsackConstraint
Weassumethatthecostfunctionc:Ω→R isbothknownandlinearregardingknapsackconstraints. Inthisframework,
>0
(cid:80)
thecostlinkedwithasubsetisthetotalofthecostsofitselements,denotedasc(A)= c(v). Themarginaldensityis
v∈A
symbolizedasρ(e|A)= f(A∪e)−f(A) foranysubsetA⊆Ωandelemente∈Ω\A. Wedon’tconsiderscenarioswithlarge
c(e)
(cid:80)
budgetsB > c(v)andpresumethatallitemshavenon-zerocosts,meeting0<c(v)≤B. Acardinalityconstraint
v∈Ω
representsaparticularcasewithunitcosts. Additionally,q = B .
cmin
LemmaE.5(GeneralizationofTheoremin(Nieetal.,2023)). PARTIALENUMERATIONin(Sviridenko,2004;Khulleretal.,
1999)isa(1− 1,0,0,n5,4+2K˜ +2q)-resilient-approximationalgorithmformonotoneSMunderaknapsackconstraint.
e
Proof. Asshownin(Nieetal.,2023),thePARTIALENUMERATION(Sviridenko,2004;Khulleretal.,1999)isa(1− 1,4+
e
2K˜ +2q)-robustapproximationalgorithmformonotoneSMunderaknapsackconstraint. Furthermore,itrequiresO(n5)
oraclecalls,thusitisa(1− 1,0,0,n5,4+2K˜ +2q)-resilient-approximationalgorithm.
e
CorollaryE.6. C-MA-MABusingthePARTIALENUMERATIONin(Sviridenko,2004;Khulleretal.,1999)asasubroutine
(cid:16) (cid:17)
requiresatmostO˜(n5)communicationtimesandyieldsa(1− 1)-regretofatmostO˜ m− 31K˜ 32q2 3n5 3T32 formonotone
e
SMunderaknapsackconstraint.
21FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
Lemma E.7 (Generalization of Theorem in (Nie et al., 2023)). GREEDY+MAX in (Yaroslavtsev et al., 2020) is a
(1,0,0,nK˜,1 +K˜ +2q)-resilient-approximationalgorithmformonotoneSMproblemunderaknapsackconstraint.
2 2
Proof. Asshownin(Nieetal.,2023),GREEDY+MAX(Yaroslavtsevetal.,2020)isa(1,1+K˜+2q)-robustapproximation
2 2
algorithmformonotoneSMunderaknapsackconstraint. Furthermore,itrequiresatmostO(nK˜)oraclecalls,thusitisa
(1,0,0,nK˜,1 +K˜ +2q)-resilient-approximationalgorithm.
2 2
CorollaryE.8. C-MA-MABusingtheGREEDY+MAXin(Yaroslavtsevetal.,2020)asasubroutinerequiresatmostO˜(nK˜)
(cid:16) (cid:17)
communication times and yields a (1/2)-regret of at most O˜ m−1 3q2 3K˜n31T2 3 for monotone SM under a knapsack
constraint.
LemmaE.9(GeneralizationofTheoremin(Nieetal.,2023)). GREEDY+in(Khulleretal.,1999)isa(1(1−1),0,0,n2,2+
2 e
K˜ +q)-resilient-approximationalgorithmformonotoneSMproblemunderaknapsackconstraint.
Proof. Asshownin(Nieetal.,2023),theGREEDY+(Khulleretal.,1999)isa(1(1−1),2+K˜ +q)-robustapproximation
2 e
algorithm for monotone SM under a knapsack constraint. Furthermore, it requires at most n2 oracle calls, thus it is a
(1(1− 1),0,0,n2,2+K˜ +q)-resilient-approximationalgorithm.
2 e
Corollary E.10. C-MA-MAB using the GREEDY+ in (Khuller et al., 1999) as a subroutine requires at most O˜(n2)
(cid:16) (cid:17)
communicationtimesandyieldsa(1(1− 1))-regretofatmostO˜ m−1 3q2 3K˜ 32n2 3T2 3 formonotoneSMunderaknapsack
2 e
constraint.
F.ExperimentsonDataSummarization
Weconductexperimentsonstochasticdatasummarization.
F.1.MotivationforStochasticDataSummarization
Datasummarizationisaprimarychallengeinmachinelearning, mainlywhendealingwithalargedataset. Whilethis
problemhasbeenextensivelystudiedinthedeterministiccase,i.e.,withaccesstoadeterministicoracle(Mirzasoleiman
etal.,2015;2020;Sivasubramanianetal.,2024),thisworkisthefirsttoaddressonlinedatasummarizationunderanoisy
stochasticobjectivefunction.
F.1.1.DETERMINISTICDATASUMMARIZATION
Indatasummarization, agentsmustplayanactionAofatmostk imagestosummarizealargedatasetD. Basedona
similaritymetricC betweentwoimages,thedeterministicobjectiveis:
(cid:88)
argmax maxC(i,v). (68)
A⊆D:|A|≤k v∈A
i∈D
Adding more images always increases this objective, and it follows a diminishing return property. Thus, it falls in the
monotoneSMunderacardinalityconstraintk(Mirzasoleimanetal.,2015).
F.1.2.STOCHASTICDATASUMMARIZATION
NoticethatevenevaluatingtheabovedeterministicobjectiveforagivenactionAmaybecomeveryexpensivewithalarge
datasetD;moreprecisely,theevaluationforoneactionhasacomplexityofO(|A||D|). Weproposeastochasticversionof
theaboveoptimizationproblemandsolveitthroughourframework. Weconsiderastochasticobjectivewherethechosen
subsetiscomparedonlytoarandomsubsetR ⊆ DdrawnuniformlyatrandomfromthelargedatasetD,resultingina
noisierbutlowercomplexityevaluationsofO(|A||R|). WedonotsolvetheproblemforagivenrealizationR,butwesolve
itinexpectation:
(cid:34) (cid:35)
(cid:88)
argmax E maxC(i,v) . (69)
R
A⊆D:|A|≤k v∈A
i∈R
22FederatedCombinatorialOptimizationwithMulti-AgentMulti-ArmedBandits
4000
C-ETC-N
3500 UCB1
C-MA-MAB (m = 1)
C-MA-MAB (m = 4)
3000 C-MA-MAB (m = 8)
C-MA-MAB (m = 16)
2500 C-MA-MAB (m = 32)
2000
1500
1000
500
0
0.0 0.2 0.4 0.6 0.8 1.0 1.2
Time Horizons 1e4
Figure2: CumulativeregretsofsummarizingimagesfromFMNISTfordifferenttimehorizonsT usingourframeworkwithdifferent
numberofagentsagainstC-ETCframeworkandUCB.
2.75 2.75
2.50 2.50
2.25 2.25
2.00 2.00
OPT OPT
1.75 1.75
C-ETC-N C-ETC-N
UCB1 UCB1
1.50 1.50
C-MA-MAB (m = 1) C-MA-MAB (m = 1)
C-MA-MAB (m = 4) C-MA-MAB (m = 4)
1.25 1.25
C-MA-MAB (m = 8) C-MA-MAB (m = 8)
C-MA-MAB (m = 16) C-MA-MAB (m = 16)
1.00 1.00
C-MA-MAB (m = 32) C-MA-MAB (m = 32)
0 200 400 600 800 1000 0 200 400 600 800 1000
Time Step Time Step
(a)CIFAR10 (b)FMNIST
Figure3: ComparetheinstantaneousrewardsofsummarizingimagesfromCIFAR10andFMNISTfordifferenttimehorizonsT using
ourframeworkwithone,two,four,sixteen,andthirtytwoagentsagainstC-ETC-N,UCB1,andOPT.
F.2.ExperimentalDetails
We test our method when using the STOCHASTIC-GREEDY algorithm as a subroutine (Mirzasoleiman et al., 2015) for
oneagentandmultipleagentsandcompareittotheproposedalgorithminC-ETCframeworkforSMC(C-ETC-N)(Nie
etal.,2023),andtheupperconfidencebound(UCB1)algorithm(Aueretal.,2002). Weconsidersettingswithone,four,
eight, sixteen, and thirty-two agents. We resize the images to have sixteen pixels. We set a cardinality constraint of
k = 5. Our goal is to summarize information from fifteen images, and instead of comparing it to all the images, we
onlyconsiderarandombatchRof3images. Weruntheexperiments100times. Wetestforseveraltimehorizonsin
{125,250,500,1000,2000,4000,8000,12000,16000,20000}.
F.3.AdditionalResults
AsdepictedinFig. 1,theC-MA-MABdemonstratessub-linearregretguaranteesacrossdifferentagentscenarioswithin
a time horizon T. Additionally, it is apparent that, for varying values of m, including the single-agent scenario, the
C-MA-MAB consistently outperforms both C-ETC-N and UCB1, exhibiting lower regrets over diverse time horizons.
Notably, anincreaseinthenumberofagentscorrelateswithareductioninregretfortheseagents. Theseobservations
reinforcethesameconclusionsdrawnfromthetheoreticalanalysis.
23
sdraweR
dehtoomS
stergeR
evitalumuC
sdraweR
dehtoomS