[
    {
        "title": "Localized Adaptive Risk Control",
        "authors": "Matteo ZecchinOsvaldo Simeone",
        "links": "http://arxiv.org/abs/2405.07976v1",
        "entry_id": "http://arxiv.org/abs/2405.07976v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07976v1",
        "summary": "Adaptive Risk Control (ARC) is an online calibration strategy based on set\nprediction that offers worst-case deterministic long-term risk control, as well\nas statistical marginal coverage guarantees. ARC adjusts the size of the\nprediction set by varying a single scalar threshold based on feedback from past\ndecisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC),\nan online calibration scheme that targets statistical localized risk guarantees\nranging from conditional risk to marginal risk, while preserving the worst-case\nperformance of ARC. L-ARC updates a threshold function within a reproducing\nkernel Hilbert space (RKHS), with the kernel determining the level of\nlocalization of the statistical risk guarantee. The theoretical results\nhighlight a trade-off between localization of the statistical risk and\nconvergence speed to the long-term risk target. Thanks to localization, L-ARC\nis demonstrated via experiments to produce prediction sets with risk guarantees\nacross different data subpopulations, significantly improving the fairness of\nthe calibrated model for tasks such as image segmentation and beam selection in\nwireless networks.",
        "updated": "2024-05-13 17:48:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07976v1"
    },
    {
        "title": "Sensitivity Analysis for Active Sampling, with Applications to the Simulation of Analog Circuits",
        "authors": "Reda ChhaibiFabrice GamboaChristophe OgerVinicius OliveiraClément PellegriniDamien Remot",
        "links": "http://arxiv.org/abs/2405.07971v1",
        "entry_id": "http://arxiv.org/abs/2405.07971v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07971v1",
        "summary": "We propose an active sampling flow, with the use-case of simulating the\nimpact of combined variations on analog circuits. In such a context, given the\nlarge number of parameters, it is difficult to fit a surrogate model and to\nefficiently explore the space of design features.\n  By combining a drastic dimension reduction using sensitivity analysis and\nBayesian surrogate modeling, we obtain a flexible active sampling flow. On\nsynthetic and real datasets, this flow outperforms the usual Monte-Carlo\nsampling which often forms the foundation of design space exploration.",
        "updated": "2024-05-13 17:47:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07971v1"
    },
    {
        "title": "Distribution Learning Meets Graph Structure Sampling",
        "authors": "Arnab BhattacharyyaSutanu GayenPhilips George JohnSayantan SenN. V. Vinodchandran",
        "links": "http://arxiv.org/abs/2405.07914v1",
        "entry_id": "http://arxiv.org/abs/2405.07914v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07914v1",
        "summary": "This work establishes a novel link between the problem of PAC-learning\nhigh-dimensional graphical models and the task of (efficient) counting and\nsampling of graph structures, using an online learning framework.\n  We observe that if we apply the exponentially weighted average (EWA) or\nrandomized weighted majority (RWM) forecasters on a sequence of samples from a\ndistribution P using the log loss function, the average regret incurred by the\nforecaster's predictions can be used to bound the expected KL divergence\nbetween P and the predictions. Known regret bounds for EWA and RWM then yield\nnew sample complexity bounds for learning Bayes nets. Moreover, these\nalgorithms can be made computationally efficient for several interesting\nclasses of Bayes nets. Specifically, we give a new sample-optimal and\npolynomial time learning algorithm with respect to trees of unknown structure\nand the first polynomial sample and time algorithm for learning with respect to\nBayes nets over a given chordal skeleton.",
        "updated": "2024-05-13 16:47:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07914v1"
    },
    {
        "title": "RLHF Workflow: From Reward Modeling to Online RLHF",
        "authors": "Hanze DongWei XiongBo PangHaoxiang WangHan ZhaoYingbo ZhouNan JiangDoyen SahooCaiming XiongTong Zhang",
        "links": "http://arxiv.org/abs/2405.07863v1",
        "entry_id": "http://arxiv.org/abs/2405.07863v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07863v1",
        "summary": "We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM, SFR-Iterative-DPO-LLaMA-3-8B-R,\nachieves impressive performance on LLM chatbot benchmarks, including\nAlpacaEval-2, Arena-Hard, and MT-Bench, as well as other academic benchmarks\nsuch as HumanEval and TruthfulQA. We have shown that supervised fine-tuning\n(SFT) and iterative RLHF can obtain state-of-the-art performance with fully\nopen-source datasets. Further, we have made our models, curated datasets, and\ncomprehensive step-by-step code guidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.",
        "updated": "2024-05-13 15:50:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07863v1"
    },
    {
        "title": "Uniform Inference for Subsampled Moment Regression",
        "authors": "David M. RitzwollerVasilis Syrgkanis",
        "links": "http://arxiv.org/abs/2405.07860v1",
        "entry_id": "http://arxiv.org/abs/2405.07860v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07860v1",
        "summary": "We propose a method for constructing a confidence region for the solution to\na conditional moment equation. The method is built around a class of algorithms\nfor nonparametric regression based on subsampled kernels. This class includes\nrandom forest regression. We bound the error in the confidence region's nominal\ncoverage probability, under the restriction that the conditional moment\nequation of interest satisfies a local orthogonality condition. The method is\napplicable to the construction of confidence regions for conditional average\ntreatment effects in randomized experiments, among many other similar problems\nencountered in applied economics and causal inference. As a by-product, we\nobtain several new order-explicit results on the concentration and normal\napproximation of high-dimensional $U$-statistics.",
        "updated": "2024-05-13 15:46:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07860v1"
    }
]