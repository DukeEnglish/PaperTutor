[
    {
        "title": "PyZoBot: A Platform for Conversational Information Extraction and Synthesis from Curated Zotero Reference Libraries through Advanced Retrieval-Augmented Generation",
        "authors": "Suad AlshammariLama BasalelahWalaa Abu RukbahAli AlsuhibaniDayanjan S. Wijesinghe",
        "links": "http://arxiv.org/abs/2405.07963v1",
        "entry_id": "http://arxiv.org/abs/2405.07963v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07963v1",
        "summary": "The exponential growth of scientific literature has resulted in information\noverload, challenging researchers to effectively synthesize relevant\npublications. This paper explores the integration of traditional reference\nmanagement software with advanced computational techniques, including Large\nLanguage Models and Retrieval-Augmented Generation. We introduce PyZoBot, an\nAI-driven platform developed in Python, incorporating Zoteros reference\nmanagement with OpenAIs sophisticated LLMs. PyZoBot streamlines knowledge\nextraction and synthesis from extensive human-curated scientific literature\ndatabases. It demonstrates proficiency in handling complex natural language\nqueries, integrating data from multiple sources, and meticulously presenting\nreferences to uphold research integrity and facilitate further exploration. By\nleveraging LLMs, RAG, and human expertise through a curated library, PyZoBot\noffers an effective solution to manage information overload and keep pace with\nrapid scientific advancements. The development of such AI-enhanced tools\npromises significant improvements in research efficiency and effectiveness\nacross various disciplines.",
        "updated": "2024-05-13 17:44:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07963v1"
    },
    {
        "title": "AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments",
        "authors": "Samuel SchmidgallRojin ZiaeiCarl HarrisEduardo ReisJeffrey JoplingMichael Moor",
        "links": "http://arxiv.org/abs/2405.07960v1",
        "entry_id": "http://arxiv.org/abs/2405.07960v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07960v1",
        "summary": "Diagnosing and managing a patient is a complex, sequential decision making\nprocess that requires physicians to obtain information -- such as which tests\nto perform -- and to act upon it. Recent advances in artificial intelligence\n(AI) and large language models (LLMs) promise to profoundly impact clinical\ncare. However, current evaluation schemes overrely on static medical\nquestion-answering benchmarks, falling short on interactive decision-making\nthat is required in real-life clinical work. Here, we present AgentClinic: a\nmultimodal benchmark to evaluate LLMs in their ability to operate as agents in\nsimulated clinical environments. In our benchmark, the doctor agent must\nuncover the patient's diagnosis through dialogue and active data collection. We\npresent two open benchmarks: a multimodal image and dialogue environment,\nAgentClinic-NEJM, and a dialogue-only environment, AgentClinic-MedQA. We embed\ncognitive and implicit biases both in patient and doctor agents to emulate\nrealistic interactions between biased agents. We find that introducing bias\nleads to large reductions in diagnostic accuracy of the doctor agents, as well\nas reduced compliance, confidence, and follow-up consultation willingness in\npatient agents. Evaluating a suite of state-of-the-art LLMs, we find that\nseveral models that excel in benchmarks like MedQA are performing poorly in\nAgentClinic-MedQA. We find that the LLM used in the patient agent is an\nimportant factor for performance in the AgentClinic benchmark. We show that\nboth having limited interactions as well as too many interaction reduces\ndiagnostic accuracy in doctor agents. The code and data for this work is\npublicly available at https://AgentClinic.github.io.",
        "updated": "2024-05-13 17:38:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07960v1"
    },
    {
        "title": "Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM",
        "authors": "Xiaoyu ChenChangde DuChe LiuYizhe WangHuiguang He",
        "links": "http://arxiv.org/abs/2405.07840v1",
        "entry_id": "http://arxiv.org/abs/2405.07840v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07840v1",
        "summary": "Decoding language information from brain signals represents a vital research\narea within brain-computer interfaces, particularly in the context of\ndeciphering the semantic information from the fMRI signal. However, many\nexisting efforts concentrate on decoding small vocabulary sets, leaving space\nfor the exploration of open vocabulary continuous text decoding. In this paper,\nwe introduce a novel method, the \\textbf{Brain Prompt GPT (BP-GPT)}. By using\nthe brain representation that is extracted from the fMRI as a prompt, our\nmethod can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we\nintroduce a text-to-text baseline and align the fMRI prompt to the text prompt.\nBy introducing the text-to-text baseline, our BP-GPT can extract a more robust\nbrain prompt and promote the decoding of pre-trained LLM. We evaluate our\nBP-GPT on the open-source auditory semantic decoding dataset and achieve a\nsignificant improvement up to $4.61\\%$ on METEOR and $2.43\\%$ on BERTScore\nacross all the subjects compared to the state-of-the-art method. The\nexperimental results demonstrate that using brain representation as a prompt to\nfurther drive LLM for auditory neural decoding is feasible and effective.",
        "updated": "2024-05-13 15:25:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07840v1"
    },
    {
        "title": "Adaptive Human-Swarm Interaction based on Workload Measurement using Functional Near-Infrared Spectroscopy",
        "authors": "Ayodeji O. AbioyeAleksandra LandowskaWilliam HuntHoria MaiorSarvapali D. RamchurnMohammad NaisehAlec BanksMohammad D. Soorati",
        "links": "http://arxiv.org/abs/2405.07834v1",
        "entry_id": "http://arxiv.org/abs/2405.07834v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07834v1",
        "summary": "One of the challenges of human-swarm interaction (HSI) is how to manage the\noperator's workload. In order to do this, we propose a novel neurofeedback\ntechnique for the real-time measurement of workload using functional\nnear-infrared spectroscopy (fNIRS). The objective is to develop a baseline for\nworkload measurement in human-swarm interaction using fNIRS and to develop an\ninterface that dynamically adapts to the operator's workload. The proposed\nmethod consists of using fNIRS device to measure brain activity, process this\nthrough a machine learning algorithm, and pass it on to the HSI interface. By\ndynamically adapting the HSI interface, the swarm operator's workload could be\nreduced and the performance improved.",
        "updated": "2024-05-13 15:20:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07834v1"
    },
    {
        "title": "Understanding Data Understanding: A Framework to Navigate the Intricacies of Data Analytics",
        "authors": "Joshua HolsteinPhilipp SpitzerMarieke HoellMichael VössingNiklas Kühl",
        "links": "http://arxiv.org/abs/2405.07658v1",
        "entry_id": "http://arxiv.org/abs/2405.07658v1",
        "pdf_url": "http://arxiv.org/pdf/2405.07658v1",
        "summary": "As organizations face the challenges of processing exponentially growing data\nvolumes, their reliance on analytics to unlock value from this data has\nintensified. However, the intricacies of big data, such as its extensive\nfeature sets, pose significant challenges. A crucial step in leveraging this\ndata for insightful analysis is an in-depth understanding of both the data and\nits domain. Yet, existing literature presents a fragmented picture of what\ncomprises an effective understanding of data and domain, varying significantly\nin depth and focus. To address this research gap, we conduct a systematic\nliterature review, aiming to delineate the dimensions of data understanding. We\nidentify five dimensions: Foundations, Collection & Selection,\nContextualization & Integration, Exploration & Discovery, and Insights. These\ndimensions collectively form a comprehensive framework for data understanding,\nproviding guidance for organizations seeking meaningful insights from complex\ndatasets. This study synthesizes the current state of knowledge and lays the\ngroundwork for further exploration.",
        "updated": "2024-05-13 11:39:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.07658v1"
    }
]