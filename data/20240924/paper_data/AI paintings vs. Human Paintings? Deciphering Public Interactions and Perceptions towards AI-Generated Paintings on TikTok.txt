AI paintings vs. Human Paintings? Deciphering Public Interactions and
Perceptions towards AI-Generated Paintings on TikTok
JiajunWang*,XiangzheYuan*,SiyingHu,ZhicongLu
1DepartmentofComputerScience,CityUniversityofHongKong,HongKong,China
jiajwang02@gmail.com,yuanxiangzhe9@gmail.com,siyinghu-c@my.cityu.edu.hk,zhiconlu@cityu.edu.hk
Abstract ing “NO TO AI-GENERATED IMAGES”2 and called for a
globalboycottofAI-generatedpaintings(AIGP).Thisinci-
WiththedevelopmentofgenerativeAItechnology,avastar- dent started because some artists felt that AI paintings had
rayofAI-generatedpaintings(AIGP)havegoneviralonso- plagiarized their paintings without consent and their copy-
cialmedialikeTikTok.However,somenegativenewsabout
rights had been violated. This struggle lasted for nearly a
AIGP has also emerged. For example, in 2022, numerous
year,anduntilnowmanypaintersarestillcallingforaban
paintersworldwideorganizedalarge-scaleanti-AImovement
onuploadingAI-generatedpaintingsonsocialmedia.
becauseoftheinfringementingenerativeAImodeltraining.
Thiseventreflectedasocialissuethat,withthedevelopment AsAIGCcirculateswidelyonsocialmedia,scholarshave
and application of generative AI, public feedback and feel- investigatedhowfactorsliketextquality(ZhangandGosline
ingstowardsitmayhavebeenoverlooked.Therefore,toin- 2023) and AI usage (Messer 2024) affect viewers’ percep-
vestigate public interactions and perceptions towards AIGP tions. However, many overlook AI’s painting capabilities
onsocialmedia,weanalyzeduserengagementlevelandcom- and the aesthetic quality of AIGP on viewer participation
mentsentimentscoresofAIGPusinghumanpaintingvideos and attitudes. Ragot et al. found significant cognitive bias
asabaseline.Inanalyzinguserengagement,wealsoconsid-
in public perceptions of AIGP but did not consider Image
ered the possible moderating effect of the aesthetic quality
Aesthetic Quality (IAQ) as a variable (Ragot, Martin, and
of Paintings. Utilizing topic modeling, we identified seven
Cojean 2020). Other studies (Bhandari, Chang, and Neben
reasons, including looks too real, looks too scary, ambiva-
2019; Shi, Huo, and Hou 2021) have shown that aesthetic
lence, etc., leading to negative public perceptions of AIGP.
Ourworkmayprovideinstructivesuggestionsforfuturegen- qualitysignificantlyinfluencesdecision-makingandpercep-
erativeAItechnologydevelopmentandavoidpotentialcrises tions.Therefore,weincludedIAQasapotentialmoderating
inhuman-AIcollaboration. variableaffectinguserengagement.
Thispaperpresentedacomprehensiveanalysisofpublic
perceptionstowardsAIGPbasedonuserengagement,com-
Introduction ment sentiment scores, and topic modeling. User engage-
ment is a multidimensional concept that encompasses not
WiththeriseofvariousGenerativeAItechnologiessuchas
just behavioral aspects (actions) but also emotional aspects
“Midjourney”, “stable diffusion” and “ChatGPT” in 2022,
(feelings)(Khan2017;Hollebeek2011).However,highlev-
a vast array of AI-generated content (AIGC), such as im-
els of engagement can only show users’ interaction inten-
ages, texts, sounds, and even videos, has widely spread
tion while cannot indicate completely positive perceptions.
acrossmajorsocialmediaplatforms.AIGC’spowerfulfunc-
Consideringthis,wealsoadoptedcommentsentimentanal-
tions and ease of use have gained the favor of many indus-
ysistocomparetheemotionalscoresofcommentsbetween
tries, particularly the art industry (Hitsuwari et al. 2023).
AIGP and human paintings for further perception analysis.
Manyfamousartists,suchasSougwenChung,HelenaSarin,
Basedontheaboveresearchmotivationsandfeasibility,we
Refik Anadol, etc., created advanced and groundbreaking
formulatedourresearchquestionsasfollows:
artworks in cooperation with generative AI. As Sougwen
Chungsaid1,“AsanartistworkingwiththeseAI-generated
RQ1: How are people’s intentions to engage with AIGP
tools,theprospectofartificialintelligenceoffersmeafresh
onsocialmediaplatforms?
perspective.” The AIGC has given the art industry a lot of
newopportunitiesandprovidedartistswithmotivation. RQ2: How doesthe imageaesthetic quality(IAQ) mod-
eratepeople’sengagementintentionswithAIGP?
However,thepublichasshownresistancetowardsgenAI
art.InDecember2002,manypaintersuploadedimagesstat- RQ3: How are public sentiments toward AIGP? What
factors motivate people’s negative attitudes toward AIGP?
*Theseauthorscontributedequally.
Copyright©2025,AssociationfortheAdvancementofArtificial 2https://arstechnica.com/information-
Intelligence(www.aaai.org).Allrightsreserved. technology/2022/12/artstation-artists-stage-mass-protest-against-
1https://zhuanlan.zhihu.com/p/149217204 ai-generated-artwork/
4202
peS
81
]CH.sc[
1v11911.9042:viXraManyresearchershavealsostudiedtheattitudesof various
groupsofpeopletowardsgenerativeAItechnologyinrecent
years.GrassiniSetal.(Grassini2023)developedandvali-
dated an Artificial Intelligence Attitude Scale (AIAS) de-
signedtoassesspublicperceptionsofAItechnology.Vasil-
jevaTetal.(Vasiljeva,Kreituss,andLulle2021)foundthat
attitudestowardsAIvariedwidelyacrossindustries.Asig-
nificant difference in attitudes towards AI was found be-
tween employees of organizations implementing AI solu-
tions and those without the intention of implementing AI
solutions. Pinto et al.’s (Pinto dos Santos et al. 2019) sur-
veyof263medicalundergraduatesfoundthatundergraduate
medicalstudentswerenotconcernedaboutAIreplacinghu-
manradiologists,andtheyunderstoodthepotentialapplica-
Figure1:UserinterfacesofTikTok tionsandimpactofAIonradiologyandmedicine.YILDIZ
. T et al. (YILDIZ 2023)found that language learners were
delighted and favored using AI in the learning process. All
in all, people seem to have different attitudes towards AI
technologybasedondifferentusagescenariosanddifferent
populations.
To answer these questions, we used human paintings as AIGP, as the hot AI field of the moment, is develop-
the baseline and compared the differences in user engage- ing at an astonishing rate, and the Paintings AI produces
mentlevelsandcommentsentimentsbetweenAIGPandhu- are already comparable to or surpass those created by hu-
man paintings. To conduct the comparisons, we compiled mans.Thetechnologynotonlybringsusirreplaceablepro-
a dataset with 207 AIGP and 210 human-painting image- ductivity and convenience (Xu 2019), but also the poten-
textvideosandover80,000commentsonthesevideosfrom tial threat of indistinguishable deepfake problems (Bregler,
TikTok. Image-text video is a format similar to PPT, con- Covell, and Slaney 2023), and Substitution of work (Ben-
tainingonlyimagesandtext,whereusersswipeleftorright del 2023). Therefore, to determine the direction of future
toswitchbetweenimagesinthevideo.ToanswerRQ1,We AItechnologicaldevelopmentandpeople’sneeds,itiscru-
usedaformulatoevaluatetheuserengagementlevelforev- cial and necessary to research the acceptance of artworks
ery painting video. To answer RQ2, we adopted improved- created by AI (Colton, Pease, and Saunders 2018). Many
aesthetic-predictor (LAION-Aesthetics V23) as the image scholarshaveconductedsocialsurveysonpeople’sattitudes
aesthetic quality assessment (IAQA) model to assess the towards AI-related work. Simon Colton (Colton 2008) was
IAQ of each painting for further comparison. To answer concernedabouttheperceivedrejectionofcreativecomput-
RQ3, we leveraged Natural Language Processing (NLP) ers,buttheevidencewasunclear.MoffatandKelly(Moffat
techniques for sentiment analysis and topic modeling. The and Kelly 2006) proved that significant bias for computer-
findings revealed that people still express stronger interac- generatedmusicexisted.MartinRagotetal.(Ragot,Martin,
tion intentions when browsing human paintings and that and Cojean 2020) invited 565 participants to rate paintings
theIAQdoesnotsignificantlyaffectengagementintentions. createdbygenerativeAItoolsandhumans,respectively,and
We also found that people have more negative attitudes to- theresultspresentedthatthescoresofhumanpaintingswere
wardAIGPthanhumanpainting.Theresultsoftopicmod- significantly higher than AI paintings. However, the Paint-
eling listed seven main reasons for the negative sentiment. ing quality question in this study has not been solved, and
EarlyanalysisofthepublicperceptionofAIGPwillhelpthe the generative tools were incomplete. So, few studies con-
ICWSM research communities understand needs and artic- structed a complete process to analyze the attitude toward
ulatedesignsandinteractivetechnologiesthatreduceplau- AIGP,primarilyfocusingonthepaintingartworkcirculating
siblesocietalharm. onsocialmedia.Inthisresearch,westudiedthesocialper-
ceptiontowardAIGPvideospostedonsocialmediaandan-
Backgroundandrelatedwork alyzedviewers’sentimentsfromtheinteractionbehaviors.
Inthissession,webrieflydiscussthecurrentbackgroundof
ImageAestheticQualityAssessment(IAQA)
AIGPtechnologydevelopment,whatpeoplethinkaboutthe
appearance of AIGP, and what the image aesthetic quality With the surge in visual artwork created by computers,
mentionedinthisarticleis.Wealsoprovidedloadsofprevi- wehavewitnessedAI-generatedPaintingsofvaryingqual-
ousstudiestosupportourresearch’sobjectiveandnecessity. ity (Ramesh et al. 2021). Meanwhile, it is increasingly
challenging to filter and distinguish the chaotic and topic-
SocialAttitudestowardGenerativeAI(Gen-AI) unrelated images for some social media platforms. There-
fore, how to efficiently and automatically evaluate the aes-
With the rapid development of AI, it has become increas-
thetic quality of images spread on social media platforms
ingly important to study societal attitudes towards Gen-AI.
hasbecomeanincreasinglycrucialproblem.
3https://laion.ai/blog/laion-aesthetics/ Aesthetics, a significant branch of the visual arts, delvesinto exploring aesthetic categories such as beauty and its Hypotheses
counterpart, ugliness (Zhu 2010). The aesthetic appeal of
Previous research has indicated that people generally hold
an image is evaluated based on universally accepted prin-
negativeattitudestowardsAI-generatedcontent,particularly
ciplesofphotography.Thisappealcanbeinfluencedbyvar-
in the realm of artworks. Therefore, our Hypotheses 1 and
ious elements, such as the strategic use of colors (Freeman
3 are also based on this perspective, but we have narrowed
2007),thecarefulmanipulationofcontrast(Itten1975),and
thescopetoAI-generatedpaintings(Wuetal.2020).Mean-
thethoughtfularrangementoftheimagecomposition.Chat-
while,visualaestheticqualityhasbeenshowntobeasignif-
terjeeandLederetal.(Lederetal.2004)introducedafive-
icantfactorinpromotinguserbehaviorssuchasdownload-
stage, multi-level information processing model for image
ing and rating items on the Internet (Bhandari, Chang, and
aesthetics.Thismodelencompassedtheperceptionof low-
Neben2019).Consequently,basedonpriorstudies,wealso
level information such as color, contrast, and complexity,
posit that the aesthetic quality of AIGP positively impacts
the implicit integration of personal experiences and mem-
user engagement willingness (H2). To answer the research
ories, explicit classification, cognitive mastery, and evalu-
questions,weproposedthefollowingthreehypotheses:
ation, culminating in aesthetic judgment and the genera-
tionofaestheticemotions.However,computationallymod-
H1:Peoplearemorewillingtointeractwithhumanpaint-
eling this sequence for visual art images presents a signif-
ingsthanwithAIGPonsocialmediaplatforms.
icantchallenge.Subsequently,MicrosoftAsiaResearchIn-
H2: AIGPs with high aesthetic quality scores lead to
stituteandTsinghuaUniversitycollaboratedonamethodto
higheruserengagement.
automaticallydifferentiatephotographscapturedbyprofes-
H3:Peopleexpressmorenegativeemotionsincomments
sional photographers from those taken by customers (Tong
onAIGPthanhumanpaintingsonsocialmedia.
et al. 2005). This study is widely recognized as the ear-
liest research in the field of IAQA. The researchers em-
ResearchSite
ployed a set of 21-class, 846-dimensional low-level global
featurestotrainaclassificationmodelforaestheticallycat- TikTok is the fastest growing social network in the post-
egorizing the test images. Until 2014, with the emergence pandemic era, allowing users to publish and share short
of AVA, a large-scale image aesthetic analysis dataset, im- videos ranging from 15 to 60 seconds. It had 1506 million
age aesthetic analysis has been given an enormous boost downloadsin2021andhasbeenthemostdownloadedsocial
based on deep learning technology (Jin et al. 2019). Lu X mediaapplicationglobally,surpassingInstagram,whichhad
et al. (Lu et al. 2014) employed a dual-channel deep neu- 1048milliondownloads(Bartaetal.2023).In2022,theav-
ral network to process local and global image blocks sepa- erage daily time spent on the TikTok mobile app by users
rately.KongSetal.(Kongetal.2016)developedtheAADB worldwide was almost equivalent to that of Facebook and
aesthetic database, rated by human evaluators, and utilized Instagram combined (Zhang et al. 2023). There are three
deep CNN for aesthetic ranking and categorization of im- main reasons for choosing TikTok as the survey platform
ages. Chang KY et al. (Chan et al. 2019) created an aes- forthisstudy.First,asofDecember15,2023,videosunder
thetic dataset, PCCD, and introduced a CNN and LSTM- the tags related to AI painting on TikTok, such as “aiart”,
based deep neural network capable of generating aesthetic “midjourny”, and “stable diffusion”, have received 10.7B,
linguisticcommentsonimages.JinXetal.(Jinetal.2019) 7.5B, and 2.3B views. This not only indicates that a large
designed a novel deep convolutional neural network, IL- amount of content related to AIGP has been widely dis-
GNet, for distinguishing between images of high and low seminatedontheTikTokplatform,butalsoshowsthatusers
aestheticquality.SomefamousdatasetssuchasAVA(Aes- haveahighdegreeofmotivationandwillingnessto partic-
theticVisualAnalysis)(Murray,Marchesotti,andPerronnin ipate in discussions about AI-related topics. Second, based
2012),AADB(AestheticsandAttributesDatabase)(Kong onTikTok’srecommendationalgorithms,theplatformana-
et al. 2016) and CUHK-PQ (CUHK-Photo-Quality) (Ke, lyzesusers’viewingpreferencesanddirectlypushesvideos
Tang,andJing2006)havecollectedbillionsofimagesam- to them on the “For you” page (Zhao 2020). In this pro-
ples.Therefore,usingtheaestheticqualityassessmentmod- cess, the viewer has no idea what the next video is about,
els trained based on these datasets to evaluate the IAQ has thusavoidingtheinfluenceofusers’utilitarianparticipation
beenagoodchoice. on the video views in the experimental data. According to
theAuthenticSelfTheory,individualsaremorelikelytoex-
hibitgenuinereactionswhenconfrontedwithrandomevents
DataandMethodology
because they have limited time to prepare or control their
responses (Vannini and Franzese 2008). Therefore, when a
Weintegratedseveralquantitativemethodstosolveandan- videowithuncertaincontentliketheoneinTikToksuddenly
swertheproposedresearchquestions.Wecompareduseren- “popsup”infrontoftheuser,theuser’sreactionsaremore
gagementandcommentsentimentbetween207shortvideos likelytobegenuine.Lastbutnotleast,accordingtoTikTok’s
relatedtoAIGPsand210shortvideosshowinghumanpaint- platform management guidelines, all videos involving AI-
ings. Additionally, to identify prominent reasons for nega- generatedcontentmustbelabeled,andvideoswithoutlabels
tive comments, topic modeling was adopted to analyze the willnotpasstheplatform’sreview.Therefore,comparedto
42199 comments for AIGPs and 39763 comments for hu- othersocialmediaplatformssuchasReddit,Instagram,and
manpaintings,respectively. Twitter,TikTokisundoubtedlythemostappropriatechoice.Figure3:ImageAestheticQualitySchematic
.
This refined our dataset to 778 AIGP videos and 935 hu-
manpaintingvideos.Toavoidfavorsorbiasfromusersto-
ward specific creators and repetitive Paintings, we adopted
thesame-authoravoidanceprinciple,ensuringnomorethan
Figure2:VideoFilteringFlowchart fiveworksfromthesameauthorinoursampleandexcluding
. videoswithrepetitivePaintingswithinthePainting.Finally,
after filtering based on these basic rules, we obtained 207
AIGPimage-textvideosand210humanpaintingimage-text
DataCollectionandPreprocessing videos.
In our preliminary survey, we discovered that paintings
on TikTok are presented in two formats: short videos and UserEngagementAnalysis(RQ1)
image-textvideos.Inshortvideos,manycreatorssharetheir
In this work, we define user engagement as the interactiv-
motivationforcreating,recordthecreativeprocess,orpro-
ity between users and videos (O’Brien and Toms 2008),
vide step-by-step painting tutorials. In these videos, user
reflecting the audience’s genuine interest and interaction
engagement is influenced by many factors unrelated to the
with the videos. This is considered an indicator of the
artwork itself, such as the creator’s voice and behavior, the
level of trust users have in a creator and their skill level.
video’slength,etc.(Yangetal.2022),whichmeansthatitis
We adopted a formula for calculating TikTok user en-
difficulttocapturepeople’sactualattitudestowardsthetwo
gagement on the HypeAuditor platform, an AI-driven an-
typesofpaintingsfromthesevideos.Therefore,weselected
alytical and discovery tool for Instagram, YouTube, Tik-
image-textvideosasourexperimentalobjectives,whichare
Tok, Twitter, and Twitch. It helps to find relevant influ-
similar to PPT format and contain only images and text.
encers, understand their audience, increase the ROI of ad-
Users swipe left or right to switch between images in the
vertisers, and maintain the authenticity of influencer mar-
video. In this kind of video, creators act more as sharers
keting. Many previous studies on social media data anal-
than narrators, only sharing their creations or AI-generated
ysis have used this tool(Rogers; Gil-Mun˜ana and Sa´ez-
paintings. Thus, user engagement depends entirely on their
Linero 2023). The formula for TikTok user engagement
understandingandfeelingstowardstheartwork,unaffected
on Hype is [(numberoflikes + numberofcomments +
by the creator’s value output. Therefore, choosing image-
numberofshares)/numberofviews]X100%4.
text videos for comparative analysis perfectly aligns with
our research theme, making our experimental results more
ImageAestheticQualityAssessment(IAQA)(RQ2)
scientificandreliable.
Fig.2ashowstheinitialstepsforvideocollectionandpre- Videoqualityisanimportantcontrolvariableinthispaper,
processing.WecreatedanewaccountontheTikTokvideo- and its impact on user engagement has been confirmed by
sharingsocialmediaplatformspecificallyforthisstudy.By manypreviousstudies(Diallo,Fieau,andHennequin2014).
searching for tags related to AIGP and human paintings So, in the process of sample preprocessing, we also con-
on TikTok, such as “Stable diffusion”, “Midjourney”, “AI sidered the video quality and the flowchart is presented in
paintings”,“Procreate”and“SAI”andscrapingtheweb,we Fig.2b.Sinceimage-textvideosonlycontainPaintingsand
selected 2667 AI-labeled image-text videos and 1729 hu- text, all videos have the same page layout and presentation
man painting image-text videos as of November 15, 2023. method,sohere,videoqualityisequivalenttotheaesthetic
Considering videos with low views might not be represen- qualityofthePaintingsinthevideos.Firstly,wedownloaded
tative, and some creators might restrict comment permis-
sions,weexcludedvideoswithfewerthan10kviews,irrel- 4https://hypeauditor.com/blog/what-is-tiktok-engagement-rate-
evant content to the painting, and less than five comments. why-brands-should-take-note/allthePaintingsfromthetwotypesofvideos,removeddu- sentiments-student” 7. It’s an open-source model based on
plicatePaintingswithinthesamevideo,andobtained2383 distilbert (Sanh et al. 2019) training designed for multilin-
AIpaintingsand1153humanpaintings.Inourresearch,we gual applications, capable of recognizing twelve languages
used the improved-aesthetic-predictor (LAION-Aesthetics andinterpretingsentimentsaspositive,neutral,ornegative.
V2)5 as the IAQA model. The model’s training process is As of December 30, 2023, it has been downloaded over
divided into two steps: embedding the input images using 7 million times on Hugging Face. Since the model rec-
Clip ViT/14 (Radford et al. 2021) and then using MLP to ognizes only twelve languages, ChatGPT 4.0 was used to
traintheimagedatafromthreewell-knowndatasets,namely, translatethecommentsoutsideofthetwelvelanguagesinto
176,000 image-text pairs from SAC (Pressman, Crowson, English.Themodel’soutputcategorizedpositivesentiment
and Contributors 2023) dataset, 15,000 image-text pairs comments as 1, neutral comments as 0, and negative com-
LAION-Logos dataset with aesthetic scores from 1 to 10, mentsas-1.Sincethefinalresultsdidnotconformtoanor-
and 250,000 photos from the AVA dataset with aesthetic mal distribution, the Wilcoxon test was chosen to compare
scores from 1 to 10. The data after aesthetic quality scor- thesentimentscoresofthetwotypesofvideos.
ingof2.73billionimagesintheLAION5Bdataset(Schuh- Fortopicmodeling,weinitiallyfilteredthecommentson
mannetal.2022)bythisPredictortrainedStableDiffusion AIGP videos to extract all negative comments, resulting in
V16 ,oneofthemostprofessionalAIGCmodelscurrently. 19,071comments.Thesecommentsweresubjectedtotopic
Therefore,thismodel’scomprehensivereliabilityandaccu- modelinginthisstudy.Aftercomparingseveralmainstream
racyinassessingimageaestheticqualityarelikelythebest topicmodelingmethods,suchasLatentDirichletAllocation
nowavailable. (LDA),LatentSemanticAnalysis(LSA),andNon-Negative
To control the quality of the two types of videos at the Matrix Factorization (NMF), we opted for the NMF model
same level and avoid the interference of extreme values, because our data contained amount of short texts but not
weexcludedvideoswithlessthan4.5andmorethan6.5av- longdocuments(Gamageetal.2022).WetrainedtheNMF
erage image aesthetic quality scores, ultimately obtaining modelfordifferentnumbersoftopicsfromk=1to15,and
207 AIGP videos and 210 human painting videos. The in- wecalculatedthemeantopiccoherenceacrossalltopicsto
dependent sample T-test results (Table 3 in Appendices) determinetheoptimalnumberoftopicsautomatically(Fig-
also confirmed that there was no significant difference in ure.6inAppendices).Semanticcoherenceinvolvesexam-
IAQA values between the two types of videos (t=1.499, P ining the co-occurrence of words within a document to en-
=0.135 >0.05).Wethendividedthevideosintofourqual- surethatthetopicsgeneratedbythemodelpossesssemantic
ity intervals: Q1: (4.5,5.0], Q2: (5.0,5.5], Q3: (5.5,6.0] and cohesion (WangandLu2023),amainstreammethodforas-
Q4: (6.0, 6.5]. We illustrate some Paintings from different sessing topic quality. When k = 1, semantic coherence was
aesthetic intervals in Fig.3. By counting the total number thehighest,butasingletopiccouldnotaccuratelysumma-
ofviews ofthetwotypes ofvideos,we findthattheir total rizeourcollectedcommentdata.Hence,wechose14topics
number of views has reached hundreds of millions, which for the final training phase, as this number demonstrated a
indicates that a large number of users are viewing similar relativelyhighlevelofsemanticcoherence.
videos on TikTok. Therefore, our sample data is universal
andreliable. Results
Informedbyourhypotheses,alltestsinthestudywerecon-
SentimentAnalysisandTopicModeling(RQ3)
ducted using one-tailed comparisons. The analysis of our
In this study, sentiment analysis was conducted on com- data and manipulation checks utilized independent T-tests,
mentsfromtwotypesofvideostoreflectthegenuineinner Wilcoxontests,orone-wayANOVA,dependingonwhether
feelings of users, thereby revealing people’s real attitudes thedatadistributionwasnormal.Ournormalitytestsonuser
towards AIGP on social media. Fig.5 shows the flowchart engagement for both types of videos revealed that the data
of comment sentiment analysis and comparison. We ex- didnotconformtoanormaldistribution.Asaresult,weem-
tracted all comments from the sample videos, resulting in ployedtheWilcoxontesttocomparetheuserengagementof
392,812 comments for AIGP videos and 63,445 for Hu- thetwosampletypes,asdetailedinTable1 (Huetal.2022).
manpaintingvideos.First,weusedtheopen-sourcemodel Table 2 compares the comment sentiment of two types of
’Hello-SimpleAI/chatgpt-detector-roberta’(Guoetal.2023) videos. The results supported hypotheses H1 and H3, in-
onHuggingFacetodetectifanycommentsweregenerated dicating that people’s user engagement (W = -13.774, P =
by bots, and then we removed those comments. Comments 0.00) and sentiment scores for comments (W = -36.725, P
thatwereonly“@”orhadreceivednolikeswereremoved =0.00)onhumanpaintingvideosweresignificantlyhigher
too. After filtering, 42,199 comments from AIGP videos thanthoseforAIGPvideos.ThesefindingsaddressRQ1and
and29,763commentsfromHumanpaintingvideoswerere- RQ3-part1posedinthepaper.
tained.Thesecommentsweretheninputtedintoasentiment Regarding the impact of video aesthetic quality on user
analysis model named “distilbert-base-multilingual-cased- engagement, the videos’ average aesthetic quality was di-
vided into high, medium, and low ranges according to the
5https://laion.ai/blog/laion-aesthetics/ LAION 5B (Schuhmann et al. 2022) divisions for IAQA:
6https://github.com/CompVis/stable-
diffusion/tree/ce05de28194041e030ccfc70c635fe3707cdfc30#stable- 7https://huggingface.co/lxyuan/distilbert-base-multilingual-
diffusion-v1 cased-sentiments-studentTable1:Theuserengagementcalculatedbytraditionalformula.Thenormality(N)ofthedatawasassessedusingtheShapiro-
Wilktest.WeusedanindependentT-testifthedifferenceisnormallydistributedandWilcoxontestotherwise.
Measures Normality Testtypes Items Mean Std W p
AIGPvideos(N=207) 0.12 0.07 0.00***
Userengagement N Wilcoxontest -13.774
HPvideos(N=210) 0.23 0.08
Table2:Acomparisonofthecommentsentimentscores.Thenormality(N)ofthedatawasassessedusingtheShapiro-Wilk
test.WeusedanindependentT-testifthedifferenceisnormallydistributedandtheWilcoxontestotherwise.
Measures Normality Testtypes Items Mean Std W p
AIGPvideos(N=207) 0.3 0.93
Sentimentscores N Wilcoxontest -36.725 0.00***
HPvideos(N=210) 0.53 0.83
(5.5, 6.5], (5.0, 5.5], and (4.5, 5.0]. We then assessed the technology,andthespeedofitsdevelopmentisalsoshock-
impact of these quality ranges on user engagement, as de- ingto peoplewho wantto shareit anddiscuss itwith their
tailed in Table 4 in Appendices. As this involved compar- friends.However,aswithcomments,wearenotclearabout
isonsamongthreesamples,weconductedone-wayANOVA users’motivationsforsharing,whichcanbepositivesignals
testsonuserengagementcorrespondingtodifferentquality ornegative.Therefore,weanalyzedthecommentmotivation
intervals for AIGP videos and human drawing videos, re- specificallyinalatersection.
spectively.Theresultsindicatedthatimageaestheticquality
doesnotsignificantlyaffectuserengagement(F=2.056,P RQ2:Howdoestheimageaestheticquality(IAQ)
= 0.131; F = 1.663, P = 0.192). Moreover, we found that moderatepeople’sengagementintentionswith
thedifferenceinuserengagementbetweenthetwotypesof
AIGP?
videosindifferentqualityintervalsisalsoveryclosetoeach
other. The difference in high IAQ is 0.123, in middle IAQ Wecomparedtheimpactofdifferentaestheticqualityinter-
is0.122,andinlowIAQis0.133.Hence,theexperimental vals of Paintings on user engagement for both video types,
results indicate that hypothesis H2 is supported, and RQ2 andthefinalresultsfoundnosignificantcorrelationbetween
posedinthepaperisanswered. the two. This suggests that when browsing different art-
worksonsocialmedia,peoplemaybemoreconcernedwith
RQ1:Howarepeople’sintentionstoengagewith the intrinsic meaning and value of the paintings than their
AIGPonsocialmediaplatforms? glossy appearance. Moreover, we noticed that the engage-
ment with human painting videos increases slightly as aes-
As seen in Table 1, when the quality of the video content
theticqualitydecreases.Observingthecommentsonhuman
is the same, people are more willing to interact with hu-
painting videos, there appears to be a lot of positive social
man painting videos than with AIGP videos. Because our
supportforthecreators,suchaswhenamateurpaintersup-
experimentaldatacollectionandpre-processingprocesshas
loadless-than-perfectpaintingsanddrawingsonTikTok.In-
eliminated the interference of most other variables, in such
terestingly,manyusersofferencouragementratherthancrit-
a situation, the response made by the user to the video can
icism.Someexamplesareasfollows:
almost be equated with the user’s real attitude towards the
paintings. So, the users’ behaviors and decisions are solely
“TheDrawingLooksBetterThanTheOriginal!”
basedonthepaintings,suchasliking,commenting,favorit-
“yourartjustgetsbetterandbetterI’mamazed!”
ing, and sharing. We can see that although there is a lot of
AIGP-related content on social media and there are many “YOUROLDARTISSOPRETTYBUTYOURCUR-
people who have viewed AIGP works, users still prefer to RENTARTISEVENBETTER!!You’vedefinitelyim-
browse and interact with human paintings on social media provedI’mobsessedwithyourstyle.”
platforms.
Such emotional support (e.g., encouragement, intimacy,
Stronger Desire to Share AIGP We calculated the like, compliment, and empathy) can give individuals a sense of
comment, favorite, and share ratios of each video based on respectandachievement,strengtheningcommunitytiesand
viewsinTable5.Wefoundthatthelike,comment,andfa- member engagement (Wang, Kraut, and Levine 2012). At
voriteratiosforhumanpaintingvideossignificantlyexceed thesametime,viewerbehaviorsmayalsobeinfluencedby
those for AIGP videos, particularly in the comment ratios the herd effect (Yen et al. 2023), following the content of
of 0.001 (AIGP) and 0.003 (HP). These data corroborate the majority’s comments and involuntarily giving a steady
our previous results on user engagement comparison, and stream of support to the art creator. This emotional value
alsoshowthatusingmachinelearningmethodstocalculate then stimulates the creator’s willingness to create. So this
userengagementisreliable.Interestingly,theshareratioof maybeoneofthereasonswhythelowertheaestheticqual-
AIGP videos is much higher than that of human painting ity of the Painting, the higher the engagement of human
videos.Basedonourspeculation,thepossiblereasonisthat painting videos. But we don’t find such a large-scale phe-
the ability of AI painting breaks people’s perception of AI nomenoninAIpaintingvideos.RQ3:HowarepublicsentimentstowardAIGP? areindeedattractedbythefinecharacterportrayal,richcolor
Whatmotivatespeople’snegativeattitudestoward palette,andotherartisticfeatures,butwhentheyseetheAI
AIGP? tags underneath the video, they start to hesitate and sway
fromsidetosideorevenfeeldisgustedandashamedofthe
After comparing the comment sentiment scores of both
paintings,likethesetypicalcomments:
video types, we found in Table 2 that human painting
videos have significantly more positive comments than “Thislookssogorgeous!Shameit’sAIArttho”
AIGP videos. It is undeniable that the number of positive “DisappointedwhenIrealisedit’sAIart,stoptaking
comments about both types of paintings is higher than the fromthecommunityandfakingart”
number of negative comments, and this data suggests, to a ”thewaymysmilewentawaywheninoticeditsAI”
certainextent,thatmanypeoplehavealreadyacceptedthat
Users have already recognized the painting and think it is
AIpaintingexists.SomeAI-createdartworksarealsowell-
reallygoodartwork,butconsideringtheAItechnologybe-
liked. However, compared to human artworks, some peo-
hindtheartwork,theyturnfromapositivetoanegativeat-
pletendtoharbormorenegativeemotionswhendiscussing
titude. Therefore, the keywords “cute” and “interesting” in
AIGPcontentonsocialmedia.Overall,peoplestillpreferto
this topic do not represent a positive emotion but mockery
see human artworks on social media platforms rather than
andself-congratulation.
AI-generatedones.
This section addresses RQ3-part 2 by identifying seven I am not acceptable for AI paintings, and it’s not art.
types of negative comments and reasons for reluctance to Topic3illustratesthatsomeusershaveacognitivebiasto-
interact with or express negative sentiments toward AIGPs wardsAIart,atendencyorpreferencebasedsolelyonsub-
on social media. The topic modeling revealed 14 common jective perceptions and thought patterns and that other fac-
topicswithinthedataset,amongwhichthetop7topicswith tors do not influence this bias. This cognitive bias has also
thehighestproportionarelistedinTable6.Toavoidthein- beenconfirmedinpreviousresearchonAIpaintings(Ragot,
fluenceofpositivecomments,alltopicswereextractedfrom Martin,andCojean2020).Suchaphenomenonissimilarly
19,071negativecommentsaboutAIGPpostedonTikTok. confirmedinthispaper.Intheirperception,AIGPcannever
becalledart,asthiscommentsays:
Itistooreal/appallingtobeunacceptable Afteranalyz-
ingthetopics,wefoundaslightoverlapbetweenTopic1and “Sadly AI art isn’t art, this is just slide after slide of
Topic 7, and we discussed these two topics together. These dogshit”
topics reflected that the reason for people’s negative atti- “ifit’smadebyAIit’snotart”
tudetowardAIGPisthatAIGPhasbecometoorealisticand
Thus,thenegativeattitudeofthiscategorytowardsAIGPis
is perceived likely to affect our lives in the future. Indeed,
entirelyunjustified,atleastonsocialmedia,wheretheydo
theadvancementofAItechnologyhasbecomeincreasingly
not indicate the reason for their distaste for AIGP. Further-
unpredictable, and we are facing a dilemma that it is dif-
more,thisunjustifiednon-acceptancemaynotbelimitedto
ficult to distinguish between human paintings and AIGPs.
reviewsonAIGPbutonallthingsrelatedtoAI,suchas:
Thisdilemmawillbecomeincreasinglychallengingtobreak
free from, along with the development of AI technology. “Ihateaisoomuch”
Onecontroversialincidentinvolvedusingadeepfakevoice “The fact that its AI generated makes it boring and
inthedocumentaryfilm“Roadrunner”aboutcelebritychef empty”
Anthony Bourdain (Gamage et al. 2022). The film incor-
It is not good enough to meet my expectations. Many
porated an artificially artificial voice to simulate Bourdain
AIGPsaregeneratedbasedonrealpeople,animecharacters,
speaking, which he never originated or consented to. This
orclassicscenes.TheconceptofTopic4isthatmanypeople
means that we may not even know when others have pri-
thinkthatAI-generatedcharactersinPaintingsdon’tliveup
vately used our voices and likenesses. So when users are
totheirexpectationsordon’tcapturesomeofthecharacter’s
browsingtheseAIGPs,it’shardforthemnottoconjureup
traits, which leads to their negative attitudes about AIGP.
Paintingsofthedaywhenwecannolongertellwhichones
Somecommentsaregivenbelow:
are AI-generated and which ones are human’s own. Exam-
plesaregivenbelow: “ithinkAIdidkyonyukidirtynooo”
“AIinconsistencywhenitcomestoskincolour”
“Ifyoudon’tsayAI,youwon’tknowAI.”
“IamafraidthattheuniquefeelingofAIwillbeelim- These comments highlight the conflict and mismatch be-
inatedbyrefiningsomeoftherealones.” tween the AI-generated characters and the Painting of the
characterinpeople’sminds.Someavidfansofanimechar-
“Finally,it’sgettingharderforAItodiscriminate...”
acters consider that AI ruined their favorite characters, and
TheyallexpressdeepconcernaboutthedevelopmentofAI as a result, they show strong resentment and anger in the
and the future of deepfake. This is, therefore, one of the comments.
most important reasons for users to oppose AI, accounting
It is so scary and weird. There are two meanings we
for12.82percent.
cangetfromTopic5.Firstly,theword“dark”indicatesthat
I feel like I’m in a spiral of self-contradictions Topic theremaybemoredarkandeerietypesofAIGPsonTikTok,
2expressestheideathatwhenmanyusersseeAIGPs,they andthisstyleofdrawingmakespeoplefeeluncomfortable.Ontheotherhand,AI-generatedtechnologyhasalwayshad thefactthattheremaystillbeanunacceptableattitudeand
somecomplextechnicaldifficulties,suchasthedrawingof mistrustinregardtothegenerativeAItechnologyitself.In-
humanlimbsandskincolor: troducingtheFeartheoryintotheAI-relatedresearch,sev-
eralstudieshaveacknowledgedthatnewtechnologyisfre-
“AIisprettyinconsistentwhenitcomestodarkerskin
quentlyperceivedasapotentialthreatduetotherisksitmay
colorsandthehairaccuracy...shamebutithasnoth-
pose to individuals or society as a whole. (Osiceanu 2015;
ingtodowithme”
Khasawneh 2018). Regarding AI specifically, we are cur-
Someofthekeywordsinthistopic,like“potter”and“hand” rentlyundergoingashifttowardscitiesandsocietiesthatare
indicate that some human-themed AIGPs on social media governed by various artificial intelligences (Cugurullo and
have weird limbs or postures. These Paintings are likely to Acheampong2023).However,theoverallrisksofthistran-
horrifyanddisturbusers,leadingtonegativecomments. sitionarestillnotfullyunderstood(Yigitcanlaretal.2020).
Based on these previous unresolved questions, this paper
It’s plagiarism The reason for the negative attitude to-
contributesinterestingempiricalfindingstoresearchrelated
wardsAIGP,asexplainedinTopic6,isthatAIGP’screative
togenerativeAIrisksandsocialattitudes.Wederivedseven
processisperceivedasaformofplagiarism,andtherefore,
topicsfromusers’commentsonAIGPtouncoverwhynega-
peoplefeelcheated.Sometypicalexamplesasfollows:
tiveattitudesstillexist.Amongthetopics,anegativeattitude
“idk if im impressed or scared like these ai art are duetothefearofAIGPwasconfirmedinthisstudy.Wealso
STEALINartistsartomd” findthatambivalenceandlookingtoorealweretypicalrea-
“manyAIsthatseektodrawthehuman,whattheydo sonsthatledtonegativeattitudes.
isplagiarisetheartofalistofauthors,isjustcoming
out.” InfluenceofAIGPtoArt
“AIartistheft” There is no doubt that AIGP has had a significant impact
on the art industry, as can be seen from the results of topic
PeoplethinkthatwhyAIcangeneratehigh-qualitypaintings
modeling,withTopic1andTopic7 allhighlightingthefact
because of plagiarising the artists’ paintings, which are not
that today’s AIGPs are so similar to human paintings that
thoughtoutbythemselves,andtherefore,AIpaintingshould
wecannotdistinguishsomeofthehigh-qualityAIGPsfrom
notbeacceptedandspread.
human paintings. On December 6, 2023, a post made it to
thetopofWeibo(oneofChina’smostfamoussocialmedia
Discussion
platforms, similar to Twitter) hotlist, which was along the
HumansandAIhavebecomeinextricablylinked.Manyex- lines of the mascot for the Spring Festival Gala announced
amplesandstudieshaveshownthathuman-AIcollaboration by China Central Broadcasting Television (CCTV) being
willleadtobettercreativityinmanyindustries(Maertenand thought to have been generated by AI. Some users even
Soydaner2023).However,accordingtosomenegativenews, posted long posts analyzing various details to prove that it
public feelings seem to be ignored, while generative AI is was generated by AI. Although an official announcement
increasinglywidelyusedforcreativeactivities.Suchdiscus- wasmadetoreplytothechallengeandthedesigner’sorig-
sionsaboutpublicconsciousnessandawarenesswhenliving inal design was released, users still firmly believed it was
withAIGCareverycritical,whichensurethecompetencyof AI-generated and accused of this behavior. As a result, the
AIimplementedresponsiblyandjudiciously(Sengupta,Sri- emergence of AIGP has added many burdens to artists. As
vastava,andMcneese2024).Therefore,thepurposeofthis far as painters are concerned, they not only have to design
studyistoanalyzeusers’discussioncontentandmotivations creative and high-quality artworks but also need to worry
towardAIGPonsocialmedia. whether their works will be labeled as AI and blamed. Es-
pecially,somehigh-levelpaintershaveabsoluteconfidence
HesitationandTentativenessinInteractionwith
thattheirpaintingscanbebetterthanAIGPs.Still,theyare
AIGP afraidthatthepaintingstheyspentalotoftimeandenergyto
AccordingtoNadarzynski’sstudyofthepublicresponseto createwillberegardedasAI-generated.Therefore,thismay
AI-ledchatbotservices,“AIhesitancy”wasprevalentduring beoneofthereasonswhyAIGPislikelytocausemanyex-
users’ interaction with chatbots (Nadarzynski et al. 2019). cellentartiststolosetheircreativedriveandsupportanti-AI
Itdemonstratedthatasubstantialnumberofpeoplemayfeel events.
hesitanttouseAImodules,consideringtheaccuracyandse-
Implicationsforsocialmediaplatformdesign
curityofthese services. Bycomparingthedegreeof users’
interactionbetweentheAIGPvideoandthehumanpainting This paper explored the effect of image aesthetic quality
video,wefoundthatpeoplestillfeelditherywhenrespond- onuserengagement,andtheexperimentalresultsconfirmed
ing to the AIGP on social media, although the interaction thattheimageaestheticqualityofpaintingsonTikTokdoes
doesnotinvolveservicesordeviceusage.Thislowlevelof not have a significant impact on users’ interactions. We
willingnesstoengageisreflectedinthelikes,favorites,and foundthatusersshowedmorerobustemotionalsupportand
commentsonAIGP-typevideos.Takingintoaccountpossi- willingnesstointeractwithsomehumanpaintingswithrela-
bleexistingtechnicalreasonsforgenerativeAI,wealsocon- tivelylowaestheticquality.Thisindicatesthatwhenbrows-
trolledthemoderatingvariableofIAQ.However,themod- ing paintings on social media, users prefer to see the cre-
eratingroleofIAQisnotsignificant.Thisfindingreinforces ator’scontinuousimprovementprocess,eveniftheworkisnot perfect. However, in AI-generated paintings, we rarely Conclusion
seesuchemotionalsupport.Therefore,thisfindingcanpro-
Because of TikTok’s huge user groups and development
videsomevaluableinsightsintothestudyofsocialsupport
speed far exceeding that of other platforms such as Face-
in online communities, an important topic in social media
book and Twitter, people’s interactions and perceptions to-
research.
wardsAIGPontheTikTokplatformcanreflectasocialphe-
In addition, we analyzed and compared the sentiment
nomenon to a certain extent. Therefore, this paper investi-
of comments on AIGP and human paintings. The results
gatestheuserengagementandemotionaltendencyofcom-
showed that positive comments generally dominated peo-
ments on AIGP on social media based on the TikTok plat-
ple’s comments on both types of paintings, but the rate of
form and compares it with human drawings. Finally, it is
negativecommentsonAIGPvideoswassignificantlyhigher
concluded that people are more willing to interact with the
thanthatonvideosofhumanpaintings.Itmeansthatthere
contentofhumanpaintingsonsocialmediaandhavehigher
are still a lot of people who have a negative attitude to-
positivity towards their comments. We also considered the
wardsAIGP,andmanypeoplearelikelyunwillingtoseeAI-
potentialmoderatingroleoftheIAQinhuman-AIGPinter-
generated Paintings on social media platforms. Therefore,
actions, and the results did not support this hypothesis. Fi-
inordertofurtherexplorewhatmakespeopleholdnegative
nally, seven main themes derived from the topic modeling,
attitudes towards AIGP content on TikTok, we conducted
including looks too real, ambivalence, etc., indicated why
topic modeling of negative AIGP comments and finally
somepeoplestillhavenegativeperceptionstowardsAIGP.
identified seven main reasons. These reasons provide sug-
gestions and guidance for optimizing future AI-generated
References
models, from which we can analyze people’s preferences
Barta, S.; Belanche, D.; Ferna´ndez, A.; and Flavia´n, M.
to determine which AIGP to put on social media to attract
2023. Influencer marketing on TikTok: The effectiveness
users’attentionandpromoteanintimateconnectionbetween
ofhumorandfollowers’hedonicexperience. JournalofRe-
theplatformandusers.
tailingandConsumerServices,70:103149.
Oneofourfindingsisthatpeoplepreferviewinghuman-
created paintings. This suggests that platforms can moder- Bendel,O.2023. Imagesynthesisfromanethicalperspec-
atelyreducethepromotionofAIGPandencourageartiststo tive. AI&SOCIETY,1–10.
uploadtheirownwork,whichcanincreaseuserengagement. Bhandari,U.;Chang,K.;andNeben,T.2019. Understand-
Ontheotherhand,wefindthatpeople’scommentsonAIGP ingtheimpactofperceivedvisualaestheticsonuserevalu-
videosexpressmorenegativeemotions,whichsuggeststhat ations: An emotional perspective. Information & manage-
platforms may need to pay more attention to comments re- ment,56(1):85–93.
latedtosuchvideostoavoidviciousincidents.
Bregler,C.;Covell,M.;andSlaney,M.2023.Videorewrite:
Drivingvisualspeechwithaudio. InSeminalGraphicsPa-
LimitationsandFutureWork
pers:PushingtheBoundaries,Volume2,715–722.
This study uses user-generated content (UGC) on the Tik-
Chan,C.;Ginosar,S.;Zhou,T.;andEfros,A.A.2019. Ev-
Tokplatformasthesourceofexperimentaldata,sodatacol-
erybodydancenow. InProceedingsoftheIEEE/CVFinter-
lection was done on a single social media platform. How-
nationalconferenceoncomputervision,5933–5942.
ever,whetherthereisadifferenceintheperceptionofAIGP
among users of different platforms, such as Twitter, Face- Colton,S.2008.CreativityVersusthePerceptionofCreativ-
book, Reddit, etc., is an area not considered in this paper. ityinComputationalSystems. InAAAIspringsymposium:
However,itisundeniablethatthenumberofactiveuserson creativeintelligentsystems,volume8,7.PaloAlto,CA.
TikTokisstillthehighestofallsocialmediaplatforms,and Colton,S.;Pease,A.;andSaunders,R.2018. Issuesofau-
allAIGPvideoshavetobetaggedwith“ai”,whichveryfew thenticityinautonomouslycreativesystems.InProc.ICCC,
platforms do. We also tried to spread our survey to other 272–279.
mainstream social media. Still, we found that many plat- Cugurullo, F.; and Acheampong, R. A. 2023. Fear of AI:
formsarenotopenandtransparentabouttheirdata,suchas aninquiryintotheadoptionofautonomouscarsinspiteof
thenumberofvideovideosorpostviews,whichisanessen- fear, and a theoretical framework for the study of artificial
tial measure of user engagement in this experiment. Thus, intelligencetechnologyacceptance. AI&SOCIETY,1–16.
this can cause significant difficulties in collecting data for
Diallo,M.T.;Fieau,F.;andHennequin,J.-B.2014. Impacts
ourexperiment,andtheaccuracyofthedatacannotbeguar-
ofvideoqualityofexperienceonuserengagementinalive
anteed.Atthesametime,wedidnotfocusonlyonnumer-
event. In2014IEEEInternationalConferenceonMultime-
ical data on the platform. We also processed and analyzed
diaandExpoWorkshops(ICMEW),1–7.IEEE.
tensofthousandsofcomments,whichreflecttheactualatti-
tudesandemotionsofplatformuserstowardsthetwotypes Freeman, M. 2007. The complete guide to light & lighting
of paintings. Consequently, integrating these several meth- indigitalphotography. SterlingPublishingCompany,Inc.
odsanddatacanguaranteetherigoroftheexperimentalre- Gamage,D.;Ghasiya,P.;Bonagiri,V.;Whiting,M.E.;and
sults. To further validate our findings, our future work will Sasahara, K. 2022. Are deepfakes concerning? analyzing
nolongerbelimitedtosocialmediaplatforms,andwehope conversationsofdeepfakesonredditandexploringsocietal
toinvestigateandanalyzetheseissuesinthispaperinmore implications. In Proceedings of the 2022 CHI Conference
detailthroughquestionnairesorreal-lifeinterviews. onHumanFactorsinComputingSystems,1–19.Gil-Mun˜ana, L.; and Sa´ez-Linero, C. 2023. Is this an ad? Messer, U. 2024. Co-creating art with generative artificial
How influencers disclose paid content after a change in intelligence:Implicationsforartworksandartists. Comput-
the law. methaodos. revista de ciencias sociales, 11(2): ersinHumanBehavior:ArtificialHumans,2(1):100056.
m231102a16–m231102a16.
Moffat,D.;andKelly,M.2006. Aninvestigationintopeo-
Grassini, S. 2023. Development and validation of the AI ple’sbiasagainstcomputationalcreativityinmusiccompo-
attitudescale(AIAS-4):abriefmeasureofgeneralattitude sition. Assessment,13(11):1–8.
towardartificialintelligence. FrontiersinPsychology,14.
Murray,N.;Marchesotti,L.;andPerronnin,F.2012. AVA:
Guo,B.;Zhang,X.;Wang,Z.;Jiang,M.;Nie,J.;Ding,Y.; Alarge-scaledatabaseforaestheticvisualanalysis. In2012
Yue,J.;andWu,Y.2023.Howcloseischatgpttohumanex- IEEE conference on computer vision and pattern recogni-
perts?comparisoncorpus,evaluation,anddetection. arXiv tion,2408–2415.IEEE.
preprintarXiv:2301.07597.
Nadarzynski,T.;Miles,O.;Cowie,A.;andRidge,D.2019.
Hitsuwari, J.; Ueda, Y.; Yun, W.; and Nomura, M. 2023. Acceptability of artificial intelligence (AI)-led chatbot ser-
Does human–AI collaboration lead to more creative art? vicesinhealthcare:Amixed-methodsstudy. Digitalhealth,
Aesthetic evaluation of human-made and AI-generated 5:2055207619871808.
haikupoetry. ComputersinHumanBehavior,139:107502.
O’Brien, H. L.; and Toms, E. G. 2008. What is user en-
Hollebeek,L.2011. Exploringcustomerbrandengagement: gagement? A conceptual framework for defining user en-
definitionandthemes.JournalofstrategicMarketing,19(7): gagementwithtechnology. JournaloftheAmericansociety
555–573. forInformationScienceandTechnology,59(6):938–955.
Hu,Y.;Qu,Y.;Maus,A.;andMutlu,B.2022. Politeordi- Osiceanu, M.-E. 2015. Psychological implications of
rect?Conversationdesignofasmartdisplayforolderadults modern technologies:“technofobia” versus “technophilia”.
basedonpolitenesstheory. InProceedingsofthe2022CHI Procedia-SocialandBehavioralSciences,180:1137–1144.
ConferenceonHumanFactorsinComputingSystems,1–15.
Pinto dos Santos, D.; Giese, D.; Brodehl, S.; Chon, S.-H.;
Itten, J. 1975. Design and form: The basic course at the Staab, W.; Kleinert, R.; Maintz, D.; and Baeßler, B. 2019.
Bauhausandlater. JohnWiley&Sons. Medical students’ attitude towards artificial intelligence: a
multicentresurvey. Europeanradiology,29:1640–1646.
Jin, X.; Wu, L.; Li, X.; Zhang, X.; Chi, J.; Peng, S.; Ge,
S.; Zhao, G.; and Li, S. 2019. ILGNet: inception modules Pressman,J.D.;Crowson,K.;andContributors,S.C.2023.
withconnectedlocalandglobalfeaturesforefficientimage Simulacraaestheticcaptions.
aestheticqualityclassificationusingdomainadaptation.IET
Radford,A.;Kim,J.W.;Hallacy,C.;Ramesh,A.;Goh,G.;
computervision,13(2):206–212.
Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.;
Ke,Y.;Tang,X.;andJing,F.2006. Thedesignofhigh-level et al. 2021. Learning transferable visual models from nat-
features forphoto quality assessment. In 2006 IEEECom- ural language supervision. In International conference on
puter Society Conference on Computer Vision and Pattern machinelearning,8748–8763.PMLR.
Recognition(CVPR’06),volume1,419–426.IEEE.
Ragot, M.; Martin, N.; and Cojean, S. 2020. Ai-generated
Khan, M. L. 2017. Social media engagement: What mo- vs. human artworks. a perception bias towards artificial in-
tivates user participation and consumption on YouTube? telligence? In Extended abstracts of the 2020 CHI confer-
Computersinhumanbehavior,66:236–247. enceonhumanfactorsincomputingsystems,1–10.
Khasawneh,O.Y.2018. Technophobia:Examiningitshid- Ramesh, A.; Pavlov, M.; Goh, G.; Gray, S.; Voss, C.; Rad-
den factors and defining it. Technology in Society, 54: 93– ford,A.;Chen,M.;andSutskever,I.2021.Zero-shottext-to-
100. imagegeneration. InInternationalConferenceonMachine
Learning,8821–8831.PMLR.
Kong,S.;Shen,X.;Lin,Z.;Mech,R.;andFowlkes,C.2016.
Photo aesthetics ranking network with attributes and con- Rogers, R. ???? 1 “Serious queries” and “editorial episte-
tentadaptation. InComputerVision–ECCV2016:14thEu- mologies”. edia,9.
ropean Conference, Amsterdam, The Netherlands, October
Sanh,V.;Debut,L.;Chaumond,J.;andWolf,T.2019. Dis-
11–14,2016,Proceedings,PartI14,662–679.Springer.
tilBERT,adistilledversionofBERT:smaller,faster,cheaper
Leder, H.; Belke, B.; Oeberst, A.; and Augustin, D. 2004. andlighter. arXivpreprintarXiv:1910.01108.
Amodelofaestheticappreciationandaestheticjudgments.
Schuhmann, C.; Beaumont, R.; Vencu, R.; Gordon, C.;
Britishjournalofpsychology,95(4):489–508.
Wightman, R.; Cherti, M.; Coombes, T.; Katta, A.; Mullis,
Lu, X.; Lin, Z.; Jin, H.; Yang, J.; and Wang, J. Z. 2014. C.; Wortsman, M.; et al. 2022. Laion-5b: An open large-
Rapid: Rating pictorial aesthetics using deep learning. In scale dataset for training next generation image-text mod-
Proceedings of the 22nd ACM international conference on els. Advances in Neural Information Processing Systems,
Multimedia,457–466. 35:25278–25294.
Maerten,A.-S.;andSoydaner,D.2023. Frompaintbrushto Sengupta,S.;Srivastava,S.;andMcneese,N.2024. Public
pixel:AreviewofdeepneuralnetworksinAI-generatedart. Perceptions, Critical Awareness and Community Discourse
arXivpreprintarXiv:2302.10913. onAIEthics:EvidencefromanOnlineDiscussionForum.Shi, A.; Huo, F.; and Hou, G. 2021. Effects of design aes- Zhao, Y. 2020. Analysis of TikTok’s success based on its
theticsontheperceivedvalueofaproduct. FrontiersinPsy- algorithmmechanism. In2020InternationalConferenceon
chology,12:2790. BigDataandSocialSciences(ICBDSS),19–23.IEEE.
Tong, H.; Li, M.; Zhang, H.-J.; He, J.; and Zhang, C. Zhu, L. 2010. Aesthetic Dictionary. Shanghai, China:
2005. Classification of digital photos taken by photogra- ShanghaiLexicographicalPublishingHouse.
phers or home users. In Advances in Multimedia Informa-
tionProcessing-PCM2004:5thPacificRimConferenceon
Multimedia,Tokyo,Japan,November30-December3,2004.
Proceedings,PartI5,198–205.Springer.
Vannini,P.;andFranzese,A.2008. Theauthenticityofself:
Conceptualization,personalexperience,andpractice. Soci-
ologycompass,2(5):1621–1637.
Vasiljeva, T.; Kreituss, I.; and Lulle, I. 2021. Artificial in-
telligence: the attitude of the public and representatives of
various industries. Journal of Risk and Financial Manage-
ment,14(8):339.
Wang, Y.; and Lu, Z. 2023. Making Sense of Post-match
FanBehaviorsintheOnlineFootballCommunities. InPro-
ceedingsofthe2023CHIConferenceonHumanFactorsin
ComputingSystems,1–17.
Wang, Y.-C.; Kraut, R.; and Levine, J. M. 2012. To stay
or leave? The relationship of emotional and informational
supporttocommitmentinonlinehealthsupportgroups. In
ProceedingsoftheACM2012conferenceoncomputersup-
portedcooperativework,833–842.
Wu, Y.; Mou, Y.; Li, Z.; and Xu, K. 2020. Investigating
American and Chinese subjects’ explicit and implicit per-
ceptionsofAI-generatedartisticwork.Computersinhuman
behavior,104:106186.
Xu, W. 2019. Toward human-centered AI: a perspective
fromhuman-computerinteraction. interactions,26(4):42–
46.
Yang,S.;Brossard,D.;Scheufele,D.A.;andXenos,M.A.
2022. ThescienceofYouTube:Whatfactorsinfluenceuser
engagement with online science videos? Plos one, 17(5):
e0267697.
Yen,C.-H.;Cheng,H.;Xia,Y.;andHuang,Y.2023. Crow-
dIDEA:BlendingCrowdIntelligenceandDataAnalyticsto
Empower Causal Reasoning. In Proceedings of the 2023
CHIConferenceonHumanFactorsinComputingSystems,
1–17.
Yigitcanlar, T.; Butler, L.; Windle, E.; Desouza, K. C.;
Mehmood,R.;andCorchado,J.M.2020. Canbuilding“ar-
tificially intelligent cities” safeguard humanity from natu-
ral disasters, pandemics, and other catastrophes? An urban
scholar’sperspective. Sensors,20(10):2988.
YILDIZ, T. 2023. Measurement of Attitude in Language
Learning with AI (MALL: AI). Participatory Educational
Research,10(4):111–126.
Zhang,Y.;andGosline,R.2023. Humanfavoritism,notAI
aversion:People’sperceptions(andbias)towardgenerative
AI, human experts, and human–GAI collaboration in per-
suasivecontentgeneration.JudgmentandDecisionMaking,
18:e41.
Zhang,Y.;Nguyen,H.W.;Jung,Y.H.;andRen,I.Y.2023.
Thesocialmediaindustry:whereisitheading? Journalof
BusinessStrategy.Appendices
Figure6:MeanCoherenceofComments
Figure 4: lowchart for calculating and comparing user en-
gagement
.
Figure5:SentimentAnalysisFlowchart
.Measures Normality Testtypes Items Mean Std Videoviews t p
AIvideos(N=207) 5.48 0.46 259088700
IAQA Y IndependentT-test 1.499 0.135
HPvideos(N=210) 5.41 0.48 40870900
Table 3: A comparison of IAQA between AIGP videos and human painting (HP) videos. The normality (N) of the data was
assessedusingtheShapiro-Wilktest.WeusedanindependentT-testifthedifferenceisnormallydistributedandtheWilcoxon
testotherwise.
AIGPvideos(N=207) Humanpaintingvideos(N=210)
Sample Sample
Measures Testtypes IAQA Mean std F P Mean std F P Difference
size size
One-way
User (5.5,6.5] 109 0.13 0.068 84 0.23 0.072 0.1
ANOVA
engagement 1.788 0.17 0.016 0.984
One-way
(Formula) (5.0,5.5] 66 0.11 0.069 80 0.22 0.081 0.11
ANOVA
(4.5,5.0] 32 0.12 0.069 46 0.22 0.09 0.1
Table4:Acomparisonoftheuserengagementfromdifferentvideoqualityintervals.WeusedtheOne-wayANOVAtestfor
threesamples.
Like-to-view Comment-to-view Favorite-to-view Share-to-view
Items
ratio ratio ratio ratio
AIGvideos(N=207) 0.10107 0.00101 0.02057 0.00224
HPvideos(N=210) 0.19388 0.0029 0.02779 0.00081
Table5:Likeratio,commentratio,favoriteratio,andshareratio
Topics Description Keywords Proportion
Tooreal(Topic1) TheAI-generatedimageslooklikeauthen- like,looks,artist,sick,cute, 12.82%
ticartworkcreatedbytruepainters. real, bad, feel, movies, girl,
style
Ambivalent(Topic2) Users shift their behavior from praise to damn, hate, shame, fuck, 12.72%
criticismwhentheyseeitwasgeneratedby cute, insane, great, dis-
AI,althoughitisgorgeous. appoint, interesting, cool,
pretty
Unacceptable (Topic The complete lack of recognition and ac- ai,art,generated,crazy,real, 11.43%
3) ceptanceofAI-generatedart fuck, hate, sad, bad, shit,
program
Not meet expecta- The AI-generated image content did not damage, hand, emotional, 8.99%
tions(Topic4) meettheuser’sexpectations. hear,remix,eyes,expecting,
brain,think,forget,remem-
ber
Scary(Topic5) The AI-generated images are horrifying dark,scary,souls,minecraft, 8.53%
andirrational. wars, hand, terraria, style,
fortnite,potter,art
Stealing(Topic6) UsersthinktheAIstoletheartist’swork, did, use, make, theft, dirty, 7.65%
sotheyfeelcheated. discord, program, wrong,
cheating,steal,generate
Appalling(Topic7) AIpaintingabilityissostrongthatithas hard,crazy,pic,insanely,in- 6.50%
surpassedhumanpainters. credibly, unbelievably, side,
hit,monkey,doom,shit
Table6:Resultsoftopicmodeling