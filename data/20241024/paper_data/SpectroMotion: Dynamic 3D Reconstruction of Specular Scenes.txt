SPECTROMOTION: DYNAMIC 3D RECONSTRUCTION
OF SPECULAR SCENES
Cheng-DeFan1,Chen-WeiChang1,Yi-RueiLiu2,Jie-YingLee1,
Jiun-LongHuang1,Yu-CheeTseng1,Yu-LunLiu1
1NationalYangMingChiaoTungUniversity,2UniversityofIllinoisUrbana-Champaign
https://cdfan0627.github.io/spectromotion/
ABSTRACT
WepresentSpectroMotion,anovelapproachthatcombines3DGaussianSplat-
ting (3DGS) with physically-based rendering (PBR) and deformation fields to
reconstructdynamicspecularscenes. Previousmethodsextending3DGStomodel
dynamic scenes have struggled to accurately represent specular surfaces. Our
methodaddressesthislimitationbyintroducingaresidualcorrectiontechnique
foraccuratesurfacenormalcomputationduringdeformation,complementedby
a deformable environment map that adapts to time-varying lighting conditions.
Weimplementacoarse-to-finetrainingstrategythatsignificantlyenhancesboth
scene geometry and specular color prediction. We demonstrate that our model
outperformspriormethodsforviewsynthesisofscenescontainingdynamicspecu-
larobjectsandthatitistheonlyexisting3DGSmethodcapableofsynthesizing
photorealisticreal-worlddynamicspecularscenes,outperformingstate-of-the-art
methodsinrenderingcomplex,dynamic,andspecularscenes.
1 INTRODUCTION
3DGaussianSplatting(3DGS)(Kerbletal.,2023)hasemergedasagroundbreakingtechniquein3D
scenereconstruction,offeringfasttrainingandreal-timerenderingcapabilities. Byrepresenting3D
spaceusingacollectionof3DGaussiansandemployingapoint-basedrenderingapproach,3DGShas
significantlyimprovedefficiencyinnovel-viewsynthesis. However,extending3DGStoaccurately
model dynamic scenes, especially those containing specular surfaces, has remained a significant
challenge.
Existingextensionsof3DGShavemadeprogressineitherdynamicscenereconstructionorspecular
object rendering, but none have successfully combined both aspects. Methods tackling dynamic
scenes often struggle with accurate representation of specular surfaces, while those focusing on
specularrenderingarelimitedtostaticscenes. Thisgapincapabilitieshashinderedtheapplication
of3DGStoreal-worldscenarioswherebothmotionandspecularreflectionsarepresent.
Normal RGB Normal RGB Normal RGB
NeRF-DS Deformable 3DGS Ours Ground truth
Figure 1: Our method, SpectroMotion, recovers and renders dynamic scenes with higher-
qualityreflectionscomparedtopriorwork. Itintroducesphysicalnormalestimation,deformable
environment maps, and a coarse-to-fine training strategy to achieve superior results in rendering
dynamicsceneswithreflections. Herewepresentarenderedtestimagealongwithitscorresponding
normal maps and a ground-truth image. For Deformable 3DGS, we use the shortest axes of the
deformed3DGaussiansasthenormals. Wehavehighlightedthespecularregionsforascenefrom
theNeRF-DSdataset(Yanetal.,2023)todemonstratetheeffectivenessofourapproach.
1
4202
tcO
22
]VC.sc[
1v94271.0142:viXraWepresentSpectroMotion,anovelapproachthataddressestheselimitationsbycombining3DGaus-
sianSplattingwithphysically-basedrendering(PBR)anddeformationfields. Ourmethodintroduces
threekeyinnovations:aresidualcorrectiontechniqueforaccuratesurfacenormalcomputationduring
deformation,adeformableenvironmentmapthatadaptstotime-varyinglightingconditions,anda
coarse-to-finetrainingstrategythatsignificantlyenhancesbothscenegeometryandspecularcolor
prediction.
OurevaluationsdemonstratethatSpectroMotionoutperformspriormethodsinviewsynthesisof
scenescontainingdynamicspecularobjects,asillustratedinFigure1. Itistheonlyexisting3DGS
methodcapableofsynthesizingphotorealisticreal-worlddynamicspecularscenes,surpassingstate-of-
the-arttechniquesinrenderingcomplex,dynamic,andspecularcontent. Thisadvancementrepresents
asignificantleapin3Dscenereconstruction,particularlyforchallengingscenariosinvolvingmoving
specularobjects.
Insummary,wemakethefollowingcontributions:
• WeproposeSpectroMotion,aphysically-basedrendering(PBR)approachcombiningdefor-
mationfieldsand3DGaussianSplattingforreal-worlddynamicspecularscenes.
• Weintroducearesidualcorrectionmethodforaccuratesurfacenormalsduringdeformation,
coupledwithadeformableenvironmentmaptohandletime-varyinglightingconditionsin
dynamicscenes.
• Wedevelopacoarse-to-finetrainingstrategyenhancingscenegeometryandspecularcolor
prediction,outperformingstate-of-the-artmethods.
2 RELATED WORK
DynamicSceneReconstruction. RecentworkshaveleveragedNeRFrepresentationstojointly
solveforcanonicalspaceanddeformationfieldsindynamicscenesusingRGBsupervision(Guo
etal.,2023;Lietal.,2021;Parketal.,2021a;b;Pumarolaetal.,2020;Tretschketal.,2021;Xian
etal.,2021;Liuetal.,2023a). Furtheradvancementsindynamicneuralrenderingincludeobject
segmentation(Songetal.,2023),incorporationofdepthinformation(Attaletal.,2021),utilizationof
2DCNNsforscenepriors(Linetal.,2022;Pengetal.,2023),andmulti-viewvideocompression(Li
etal.,2022). However,theseNeRF-basedmethodsarecomputationallyintensive. Toaddressthis,
recentresearchhasadapted3DGaussiansfordynamicscenes(Yangetal.,2023c;Wuetal.,2023;
Huangetal.,2024;Liangetal.,2023c;Wangetal.,2024;Mihajlovicetal.,2024;Stearnsetal.,
2024),primarilyfocusingondeformingspatialcoordinatesthroughdeformationfields. Nevertheless,
these approaches do not explicitly account for changes in object surface during the deformation
process. Ourworkextendsthislineofresearchbycombiningspecularobjectrenderingbasedon
normalestimationwithadeformationfield,enablingeach3DGaussiantoeffectivelymodeldynamic
specularscenes.
ReflectiveObjectRendering. Whilesignificantprogresshasbeenmadeinrenderingreflective
objects,challengesarisingfromcomplexlightinteractionspersist. Recentyearshaveseennumerous
studies addressing these issues, primarily by decomposing appearance into lighting and material
properties (Bietal.,2020;Bossetal.,2021;Li&Li,2022;Srinivasanetal.,2020;Zhangetal.,
2021b;Munkbergetal.,2022;Zhangetal.,2021a;Verbinetal.,2024a;Zhaoetal.,2024). Building
onthisfoundation,someresearchhasfocusedonimprovingthecaptureandreproductionofspecular
reflections (Verbinetal.,2022;Maetal.,2023;Verbinetal.,2024b),whileothershaveleveraged
signeddistancefunctions(SDFs)toenhancenormalestimation (Geetal.,2023;Liangetal.,2023a;b;
Liuetal.,2023b;Zhangetal.,2023). Theemergenceof3DGaussianSplatting(3DGS)hassparked
anewwaveoftechniques (Jiangetal.,2023;Liangetal.,2023d;Yangetal.,2024;Yeetal.,2024;
Zhuetal.,2024;Shietal.,2023)thatintegrateGaussiansplattingwithphysically-basedrendering.
Nevertheless, accurately modeling dynamic environments and time-varying specular reflections
remainsasignificantchallenge. Toaddressthislimitation,ourworkintroducesanovelapproach
incorporatingadeformableenvironmentmapandadditionalexplicitGaussianattributes,specifically
designedtocapturespecularcolorchangesovertime.
2Time 𝒕
𝜃𝐺
GV aa un si sll ia a n3 sD 𝐆 Render Image C Ga an uo ssn ii ac na sl 3 𝐆D GD ae uf so sr im ana b Ml Le P D Ge af uo sr sm iae nd s 3 𝐆D 𝑡 Render Image
ℒcolor ℒcolor
Computation Physical Normal
Rendering Estimation (Sec 3.3)
Loss
Ground Truth
ℒnormal 𝐧𝑡
Ground Truth
Normal
Stage 1: Static stage (Sec 3.2) Render Depth Map 𝐃𝑡 Render Normal Map 𝐍𝑡 Stage 2: Dynamic stage (Sec 3.2)
Time 𝒕
Color Combination
ℒcolor
𝜃𝐺 𝐜𝐟𝑡 𝐢𝐧𝐚𝐥=𝐜𝑑+𝐜𝑠𝑡⊙𝐬𝐭𝐢𝐧𝐭
Canonical 3D Deformable Deformed 3D
Gaussians 𝐆 Gaussian MLP Gaussians 𝐆𝑡 Render Image
Physical Normal Ground Truth
Estimation (Sec 3.3) Time 𝒕
ℒnormal
No𝐧 rm𝑡
al
𝜔𝑟𝑡=2R 𝜔ef 𝑜𝑡le ∙c 𝐧ti 𝑡on 𝐧𝑡−𝜔𝑜𝑡 𝜃𝑅 𝜔ഥ 𝑟𝑡
Render Depth Map 𝐃𝑡 Render Normal Map 𝐍𝑡 Stage 3: Specular stage (Sec 3.2) ReD fe lefo cr tm iona b Mle L PD Ree ff lo er cm tie od n C Ena vn . o Mn aic pal
Figure2: MethodOverview. Ourmethodstabilizesthescenegeometrythroughthreestages. In
thestaticstage,westabilizethegeometryofthestaticscenebyminimizingphotometriclossL
color
betweenvanilla3DGSrendersandgroundtruthimages. Thedynamicstagecombinescanonical3D
GaussiansGwithadeformableGaussianMLPtomodeldynamicsceneswhilesimultaneouslymini-
mizingnormallossL betweenrenderednormalmapNtandgradientnormalmapfromdepth
normal
mapDt,thusfurtherenhancingtheoverallscenegeometry. Finally,thespecularstageintroducesa
deformablereflectionMLPtohandlechangingenvironmentlighting,deformingreflectiondirections
ωt toqueryacanonicalenvironmentmapforspecularcolorct. Itisthencombinedwithdiffuse
r s
colorc (usingzero-ordersphericalharmonics)andlearnablespeculartints per3DGaussianto
d tint
obtainthefinalcolorct . Thisapproachenablesthemodelingofdynamicspecularscenesand
final
high-qualitynovelviewrendering.
3 METHOD
Overviewoftheapproach. TheoverviewofourmethodisillustratedinFig. 2. Givenaninput
monocular video sequence of frames and corresponding camera poses, we design a three-stage
approachtoreconstructthedynamicspecularscene,asdetailedinSection3.2. Accuratespecular
reflectionrequiresprecisenormalestimation,soSection3.3elaboratesonhowweestimatenormalsin
dynamicscenes. Finally,weintroducethelossesusedthroughoutthetrainingprocessinSection3.4.
3.1 PRELIMINARY
3DGaussianSplatting. Each3DGaussianisdefinedbyacenterpositionx∈R3andacovariance
matrixΣ. 3DGaussianSplatting(Kerbletal.,2023)optimizesthecovariancematrixusingscaling
factorss ∈ R3 androtationunitquaternionr ∈ R4. Fornovel-viewrendering,3DGaussiansare
projectedonto2Dcameraplanesusingdifferentiablesplatting(Yifanetal.,2019):
Σ′=JWΣWTJT. (1)
Pixelcolorsarecomputedusingpoint-basedvolumetricrendering:
C = (cid:88) T iα ic i, α
i
=σ ie− 21(x)TΣ′(x), (2)
i∈N
whereT =
(cid:81)i−1(1−α
)isthetransmittance, σ istheopacity, andc isthecolorofeach3D
i j=1 j i i
Gaussian.
33.2 SPECULARRENDERING
Limitationsofexistingmethods. ThecurrentDynamic3DGS-basedmethods(Wuetal.,2023;
Yangetal.,2023c;b)encounterlimitationsinaccuratelymodelingenvironmentsthatincludespecular
objects. This issue arises from the inherent low-frequency characteristics of low-order spherical
harmonics(SH),whichareinadequateforcapturingcomplexvisualeffectssuchasspecularhighlights.
Incontrast, otherspecialized3DGS-basedmethodsforstaticspecularobjectscenes(Jiangetal.,
2023; Liang et al., 2023d) often incorporate environment maps to model lighting, which is then
combined with BRDF to simulate the entire scene. However, vanilla environment maps are not
suitableformodelinglightingscenariosthatinvolvetime-variantelements.Thisresultsintheexisting
3DGS-basedmethodsbeinginsufficientforeffectivelymodelingdynamicspecularobjectscenes.
Proposedsolutionoverview. Toaddressthesechallenges,weintroducephysicalnormalestimation
(Section3.3)anddeformableenvironmentmapstomodelthespecularcolorofreal-worlddynamic
scenes. However,thisapproachaloneisinsufficient,asprecisescenegeometryiscrucialforaccurate
reflections. Therefore,weintroduceourcoarse-to-finetrainingstrategy,whichhelpsstabilizescene
geometrywhilesimultaneouslypredictingaccuratespecularcolor.Ourcoarse-to-finetrainingstrategy
isdividedintothreestages:thestaticstage,thedynamicstage,andthespecularstage.Inthefollowing
paragraphs,wewillintroduceeachofthesestagesindetail.
3.2.1 COARSE-TO-FINETRAININGSTRATEGY
Static stage. In the static stage, we employ vanilla 3DGS (Kerbl et al., 2023) for static scene
reconstructiontostabilizethegeometryofthestaticscene. Specifically,weoptimizethepositionx,
scalings,rotationr,opacityα,andcoefficientsofsphericalharmonics(SH)ofthe3DGaussiansby
minimizingthephotometriclossL betweentherenderedimageandthecorrespondingimage:
color
L =(1−λ )L +λ L . (3)
color D-SSIM 1 D-SSIM D-SSIM
Dynamic stage. Following the static stage, we address dynamic objects using Deformable
3DGS (Yang et al., 2023c). For each 3D Gaussian in canonical 3D Gaussians G, we input its
position x and time t into a deformable Gaussian MLP with parameters θ to predict position,
G
rotation,andscalingresiduals:
(∆xt,∆rt,∆st)=F (γ(x),γ(t)), (4)
θG
whereγ denotespositionalencoding. Attributesofthecorresponding3DGaussianindeformed3D
GaussiansGtattimetisobtainedby:
(xt,rt,st)=(∆xt,∆rt,∆st)+(x,r,s). (5)
This approach separates motion and geometric structural learning, allowing accurate simulation
of dynamic behaviors while maintaining a stable geometric reference. To further enhance scene
geometry,weestimatenormalsofdeformed3DGaussiansandoptimizethemusing:
L =1−Nt·Nˆt, (6)
normal
whereNt istherenderednormalmapandNˆt isthenormalmapderivedfromtherendereddepth
mapDt. Thisprocessimproveslocalassociationsamong3DGaussiansandoptimizesbothdepth
andnormalinformationacrosstheentirescene.
Specularstage. Weadoptanimage-basedlighting(IBL)modelwithalearnablecubemap.Inspired
bytherenderingequation(Kajiya,1986),split-sumapproximation(Karis&Games,2013;Munkberg
et al., 2022), and Cook-Torrance reflectance model (Cook & Torrance, 1982), we formulate the
outgoingradianceofthespecularcomponentL as:
s
(cid:90) DGF (cid:90)
L = (ω ·nt)dω L (ω )D(ω ,ωt)(ω ·nt)dω , (7)
s 4(ωt ·nt)(ω ·nt) i i i i i o i i
Ω o i Ω
whereΩisthehemispherearoundthesurfacenormalnt. D,G,andF representtheGGXnormal
distributionfunction(Walteretal.,2007),geometricattenuation,andFresnelterm,respectively. ωt is
o
theviewdirection,andL (ω )istheincidentradiance.Thefirstterm,representingthespecularBSDF
i i
withasolidwhiteenvironmentlight,isprecomputedandstoredinalook-uptable. Thesecondtermis
4pre-integratedinafilteredcubemap,whereeachmip-levelcorrespondstoaspecificroughnessvalue.
Roughnessρ∈[0,1]isalearnableparameterforeach3DGaussian. Afterthestaticanddynamic
stages,thegeometryiswell-defined. Thisallowsustoaccuratelycalculatereflectiondirectionsωt:
r
ωt =2(ωt ·nt)nt−ωt. (8)
r o o
Reflectiondirectionscanquerytheenvironmentmapforthespecularcolorofstaticenvironment
light. Tohandletime-varyinglightingindynamicscenes,weintroduceadeformableenvironment
map,detailedinthefollowingsection.
3.2.2 DEFORMABLEENVIRONMENTMAPFORDYNAMICLIGHTING.
Theconceptofadeformableenvironmentmapinvolvestreatingthevanillaenvironmentmapasa
canonicalenvironmentmapandcombiningitwithadeformationfield. Thisapproachenablesus
tomodeltime-varyinglightingconditionseffectively. Toimplementthis,wefirstapplypositional
encoding to the reflection direction ωt and time t. These encoded values are then input into a
r
deformable reflection MLP with parameters θ . This process allows us to obtain the deformed
R
reflectionresidual∆ω¯t foreachspecifiedtimet:
r
∆ω¯t =F (γ(ωt),γ(t)). (9)
r θR r
Subsequently,weaddthedeformedreflectionresidual∆ω¯t tothereflectiondirectionωt,yielding
r r
thedeformedreflectiondirectionω¯t. Thiscanbeexpressedas:
r
ω¯t =∆ω¯t +ωt (10)
r r r
We can then use this deformed reflection direction ω¯t to query the canonical environment map,
r
allowingustoobtaintime-varyingspecularcolorct. Thisapproacheffectivelycapturesthedynamic
s
natureoflightinginthescenewhilemaintainingastablecanonicalreference.
3.2.3 COLORDECOMPOSITIONANDSTAGEDTRAININGSTRATEGY.
We decompose the final color ct into diffuse and specular components to better distinguish
final
betweenhighandlow-frequencyinformation:
ct =c +ct ⊙s , (11)
final d s tint
where c is the diffuse color (using zero-order spherical harmonics as view-independent color),
d
s ∈[0,1]3isthelearnablespeculartintstoredineach3DGaussian,andc tistheview-dependent
tint s
colorcomponent. Tomanagethetransitionfromsphericalharmonicstoct andmitigatepotential
final
geometrydisruptions,intheearlyspecularstage,wefixthedeformableGaussianMLPandmost3D
Gaussianattributes,optimizingonlyzero-orderSH,speculartint,androughness. Wetemporarily
suspenddensificationduringthisphase. Asct becomesmorecomplete,wegraduallyresume
final
optimizationofallparametersandreinstatethedensificationprocess.
Wefurthersplitthespecularstageintotwoparts,applyingacoarse-to-finestrategytotheenvironment
map. In the first part, we focus on optimizing the canonical environment map for time-invariant
lighting. Thisestablishesastablefoundationfortheoveralllightingstructure. Inthesecondpart,we
proceedtooptimizethedeformablereflectionMLPfordynamicelements. Thisapproachensuresa
morerobustlearningprocess,allowingustocapturethestaticlightingconditionsbeforeintroducing
thecomplexitiesofdynamiccomponents.
3.3 PHYSICALNORMALESTIMATION
Challengesinnormalestimationfor3DGaussians. Normalestimationiscrucialformodeling
specularobjects,asitdirectlyaffectssurfacereflections.However,thediscretenatureof3DGaussians
makesthisprocesschallenging,asittypicallyrequiresacontinuoussurface. GaussianShader(Jiang
etal.,2023)observedthat3DGaussianstendtoflattenduringtraining, leadingtotheuseofthe
shortestaxisasaninitialapproximationofthesurfacenormal. Toimproveaccuracy,theyintroduced
aresidualnormal∆nforeach3DGaussiantocompensateforerrorsinthisapproximation. However,
this method alone is insufficient for deformed 3D Gaussians, as the residual should vary at each
timestep. Astraightforwardapproachofrotatingtheresidualbasedonthequaterniondifference
betweencanonicalanddeformedGaussiansprovesinadequate,asitfailstoaccountforshapechanges
duringdeformation. Iftheshortestaxisofthecanonical3DGaussianisnolongertheshortestafter
deformation,thismethodresultsinincorrectrotation. Consequently,amoresophisticatedapproach
isneededtoaccuratelymodelthenormalsofdeformed3DGaussians. Thisapproachmustconsider
boththerotationandthechangeinshapeduringthedeformationprocess,ensuringaccuratenormal
estimationfordynamicspecularobjects.
5(a) Scene surface Surface normal (b) 𝐯𝑡1 𝚫𝐧𝑡1= 𝛽 ∗𝐑𝑡1∗𝚫𝐧 (c)
Shortest axis 3D Gaussian ∆𝐧 𝐧𝑡1 𝛽𝑡1
𝐯 𝐧 𝑡=𝑡1
𝑡=𝑡2
𝐯𝑡2
𝚫𝐧𝑡2=
𝛽𝛽
𝑡2∗𝐑𝑡2∗𝚫𝐧
Canonical 3D Gaussian
𝐧𝑡2
Deformed 3D Gaussian
Figure3: Normalestimation. (a)showsthatflatter3DGaussiansalignbetterwithscenesurfaces,
theirshortestaxiscloselymatchingthesurfacenormal. Incontrast,lessflat3DGaussiansfitless
accurately, with their shortest axis diverging from the surface normal. (b) shows that when the
deformed3DGaussianbecomesflatter(t = t ),normalresidual∆nisrotatedbyRt andscaled
1 1
downby β ,asflatterGaussiansrequiresmallernormalresiduals. Conversely,whenthedeformation
βt
1
results in a less flat shape (t = t ), ∆n is rotated by Rt and amplified by β , requiring a larger
2 2 βt
2
correction to align the shortest axis with the surface normal. (c) shows how γk changes with w
(wherew = |v st|)fork =1,k =5,andk =50. LargerwindicateslessflatGaussians,whilesmaller
|vt|
l
w representsflatterGaussians. Ask increases, γk decreasesmoresteeplyasw rises. Fork = 5,
weobserveabalancedbehavior: γk approaches1forlowwand0forhighw,providinganuanced
penaltyadjustmentacrossdifferentGaussianshapes.
Improved rotation calculation for deformed 3D Gaussians. To overcome the limitations of
naivemethodsandaccuratelymodelthenormalofdeformed3DGaussians,weproposeusingboth
theshortestandlongestaxesofcanonicalanddeformedGaussianstocomputetherotationmatrix.
Thisapproachaccountsforbothrotationandshapechangesduringdeformation. Wefirstalignthe
deformedGaussian’saxeswiththoseofthecanonicalGaussianusingthefollowingmethod:
(cid:26) vt ifv ·vt >0, (cid:26) vt ifv ·vt >0,
vt = s s s , vt = l l l , (12)
s −vt otherwise. l −vt otherwise.
s l
wherev andv representtheshortestandlongestaxesofcanonical3DGaussians,whilevt and
s l s
vtdenotethesamefordeformed3DGaussians. Wethenconstructorthogonalmatricesusingthese
l
alignedaxesandtheircrossproducts:
U=[v v v ×v ], Vt =(cid:2) vt vt vt ×vt(cid:3) . (13)
s l s l s l s l
Finally,wederivetherotationmatrix:
Rt =VtU⊤. (14)
Thismethodprovidesarobustsolutionforcalculatingtherotationofdeformationprocess,ensuring
accuratenormalestimationfordynamicspecularobjects.
Adjustingnormalresidualsandensuringaccuracy. Toaccountforshapechangesduringde-
formation,wescalethenormalresidualbasedontheratioofoblateness β betweencanonicaland
βt
deformed3DGaussians.
|v |−|v | |vt|−|vt|
β = l s , βt = l s , (15)
|v | |vt|
l l
whereβ andβtrepresenttheoblatenessofcanonicalanddeformed3DGaussians,respectively. This
isbecauseflatter3DGaussianstendtoalignmorecloselywiththesurface,meaningtheirshortest
axis becomes more aligned with the surface normal, as shown in Fig. 3(a). In such cases, less
compensation from the normal residual is needed. Conversely, less flat Gaussians require more
compensation,asillustratedinFig. 3(b). Wethenobtaindeformednormalresiduals:
β
∆nt = Rt∆n. (16)
βt
Thefinalnormalnt iscomputedbyaddingthisresidualtotheshortestaxisandensuringoutward
orientation:
(cid:26) nt ifnt·ωt >0,
nt =∆nt+vt, nt = o (17)
s −nt otherwise.
ThisapproachadjustsforGaussianflatnessandensuresaccuratenormalestimation.
6Table 1: Quantitative comparison on the NeRF-DS (Yan et al., 2023) dataset. We report the
averagePSNR,SSIM,andLPIPS(VGG)ofseveralpreviousmodelsontestimages. The best,the
secondbest,and thirdbest resultsaredenotedbyred,orange,yellow.
As Basin Bell Cup
Method PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓
Deformable3DGS(Yangetal.,2023c) 26.04 0.8805 0.1850 19.53 0.7855 0.1924 23.96 0.7945 0.2767 24.49 0.8822 0.1658
4DGS(Wuetal.,2023) 24.85 0.8632 0.2038 19.26 0.7670 0.2196 22.86 0.8015 0.2061 23.82 0.8695 0.1792
GaussianShader(Jiangetal.,2023) 21.89 0.7739 0.3620 17.79 0.6670 0.4187 20.69 0.8169 0.3024 20.40 0.7437 0.3385
GS-IR(Liangetal.,2023d) 21.58 0.8033 0.3033 18.06 0.7248 0.3135 20.66 0.7829 0.2603 20.34 0.8193 0.2719
NeRF-DS(Yanetal.,2023) 25.34 0.8803 0.2150 20.23 0.8053 0.2508 22.57 0.7811 0.2921 24.51 0.8802 0.1707
HyperNeRF(Parketal.,2021b) 17.59 0.8518 0.2390 22.58 0.8156 0.2497 19.80 0.7650 0.2999 15.45 0.8295 0.2302
Ours 26.80 0.8851 0.1761 19.75 0.7922 0.1896 25.46 0.8497 0.1600 24.65 0.8879 0.1588
Plate Press Sieve Mean
Method PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓
Deformable3DGS(Yangetal.,2023c) 19.07 0.7352 0.3599 25.52 0.8594 0.1964 25.37 0.8616 0.1643 23.43 0.8284 0.2201
4DGS(Wuetal.,2023) 18.77 0.7709 0.2721 24.82 0.8355 0.2255 25.16 0.8566 0.1745 22.79 0.8235 0.2115
GaussianShader(Jiangetal.,2023) 14.55 0.6423 0.4955 19.97 0.7244 0.4507 22.58 0.7862 0.3057 19.70 0.7363 0.3819
GS-IR(Liangetal.,2023d) 15.98 0.6969 0.4200 22.28 0.8088 0.3067 22.84 0.8212 0.2236 20.25 0.7796 0.2999
NeRF-DS(Yanetal.,2023) 19.70 0.7813 0.2974 25.35 0.8703 0.2552 24.99 0.8705 0.2001 23.24 0.8384 0.2402
HyperNeRF(Parketal.,2021b) 21.22 0.7829 0.3166 16.54 0.8200 0.2810 19.92 0.8521 0.2142 19.01 0.8167 0.2615
Ours 20.84 0.8180 0.2198 26.49 0.8665 0.1889 25.22 0.8712 0.1513 24.17 0.8529 0.1778
etalP
n
isaB
sA
Ground truth Ours Deformable 3DGS 4DGS GaussianShader GS-IR NeRF-DS HyperNeRF
Figure4: QualitativecomparisonontheNeRF-DSYanetal.(2023)dataset.
3.4 LOSSFUNCTIONS
Normalregularization. Toallowthenormalresidualtocorrectthenormalwhilenotexcessively
influencingtheoptimizationoftheshortestaxistowardsthesurfacenormal,weintroduceapenalty
termforthenormalresidual:
(cid:115)
|vt|2
L =γk∥∆n∥2 where γ = 1− s . (18)
reg 2 |vt|2
l
Inourexperiments,wesetk = 5. Whenk = 5,lessflatter3DGaussianshaveγk approaching0.
Theirshortestaxisalignspoorlywiththesurfacenormal,requiringmorenormalresidualcorrection
andsmallerpenalties. Conversely,flatterGaussianshaveγk near1. Theirshortestaxisalignsbetter
withthesurfacenormal,needinglessnormalresidualcorrectionandallowinglargerpenalties,as
showninFig. 3(c).
Totaltrainingloss. Torefineallparametersinthedynamicandspecularstages,weemploythe
totaltrainingloss:
L=L +λ L +L , (19)
color normal normal reg
where L and L are obtained as described in Section 3.2.1. In our experiments, we set
color normal
λ =0.01.
normal
4 EXPERIMENTS
4.1 EVALUATIONRESULTS
We evaluate our method on two real-world datasets: NeRF-DS dataset (Yan et al., 2023) and
HyperNeRFdataset(Parketal.,2021b).
7Table2:QuantitativecomparisonontheNeRF-DS(Yanetal.,2023)datasetwithourlabeleddy-
namicspecularmasks. WereportPSNR,SSIM,andLPIPS(VGG)ofpreviousmethodsondynamic
specularobjectsusingthedynamicspecularobjectsmaskgeneratedbyTrackAnything(Yangetal.,
2023a). The best,the secondbest,and thirdbest resultsaredenotedbyred,orange,yellow.
As Basin Bell Cup
Method PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓
Deformable3DGS(Yangetal.,2023c) 24.14 0.7432 0.2957 17.45 0.5530 0.3138 19.42 0.5516 0.2940 20.10 0.5446 0.3312
4DGS(Wuetal.,2023) 22.70 0.6993 0.3517 16.61 0.4797 0.4084 14.64 0.2596 0.4467 18.90 0.4132 0.4032
GaussianShader(Jiangetal.,2023) 19.27 0.5652 0.5232 15.71 0.4163 0.5941 12.10 0.1676 0.6764 14.90 0.3634 0.6146
GS-IR(Liangetal.,2023d) 19.32 0.5857 0.4782 15.21 0.4009 0.5644 12.09 0.1757 0.6722 14.80 0.3445 0.6046
NeRF-DS(Yanetal.,2023) 23.67 0.7478 0.3635 17.98 0.5537 0.4211 14.73 0.2439 0.5931 19.95 0.5079 0.3494
HyperNeRF(Parketal.,2021b) 17.37 0.6934 0.3834 18.75 0.5671 0.4125 13.93 0.2292 0.6051 15.07 0.4860 0.4183
Ours 24.51 0.7534 0.2896 17.71 0.5675 0.3048 19.60 0.5680 0.2862 20.28 0.5473 0.3176
Plate Press Sieve Mean
Method PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓
Deformable3DGS(Yangetal.,2023c) 16.12 0.5192 0.3544 19.64 0.6384 0.3268 20.74 0.5283 0.3109 19.66 0.5826 0.3181
4DGS(Wuetal.,2023) 13.93 0.4095 0.4229 20.17 0.5434 0.4339 19.70 0.4498 0.3879 18.09 0.4649 0.4078
GaussianShader(Jiangetal.,2023) 9.87 0.2992 0.6812 16.84 0.4408 0.6093 16.19 0.3241 0.5862 14.98 0.3681 0.6121
GS-IR(Liangetal.,2023d) 11.09 0.3254 0.6270 16.43 0.4083 0.5776 16.42 0.3339 0.5749 15.05 0.3678 0.5856
NeRF-DS(Yanetal.,2023) 14.80 0.4518 0.3987 19.77 0.5835 0.5035 20.28 0.5173 0.4067 18.74 0.5151 0.4337
HyperNeRF(Parketal.,2021b) 16.03 0.4629 0.3775 14.10 0.5365 0.5023 18.39 0.5296 0.3949 16.23 0.5007 0.4420
Ours 16.53 0.5369 0.3041 21.70 0.6630 0.3252 20.36 0.5089 0.3190 20.10 0.5921 0.3066
ve
eiS
p
u
C
leBl
Ground truth Ours Deformable 3DGS 4DGS GaussianShader GS-IR NeRF-DS HyperNeRF
Figure5: QualitativecomparisononNeRF-DSdatasetwithlabeleddynamicspecularmasks.
EntiresceneoftheNeRF-DSdataset. TheNeRF-DSdataset(Yanetal.,2023)isamonocular
videodatasetcomprisingsevenreal-worldscenesfromdailylife,featuringvarioustypesofmoving
or deforming specular objects. We compare our method with the most relevant state-of-the-art
approaches. AsshowninTab. 1andFig. 4,thequantitativeresultsdemonstratethatourmethod
decisivelyoutperformsbaselinesinreconstructingandrenderingreal-worldhighlyreflectivedynamic
specularscenes.
DynamicspecularobjectofNeRF-DSdataset. SinceeachsceneintheNeRF-DSdataset(Yan
etal.,2023)containsnotonlydynamicspecularobjectsbutalsostaticbackgroundobjects,weuse
TrackAnything(Yangetal.,2023a)toobtainmasksforthedynamicspecularobjects. Thisallowsus
toevaluateonlythedynamicspecularobjects.AsshowninTab.2andFig.5,ourmethodoutperforms
baselineswhenevaluatingthedynamicspecularobjectsinthesemonocularsequences.
HyperNeRFdataset. TheHyperNeRFdataset,whilealsocontainingreal-worlddynamicscenes,
doesnotincludespecularobjects. AsshowninTab. 3andappendixFig. 14,theresultsdemonstrate
that we are on par with state-of-the-art techniques for rendering novel views and our method’s
performanceisnotlimitedtoshinyscenes.
Thisstrongperformanceacrossdifferenttypesofreal-worlddatasetsfurtherconfirmstheeffectiveness
ofourapproachinhandlingawiderangeofscenecharacteristics. Thesuccesscanbeattributed
toourkeyinnovations: physicalnormalestimation,deformableenvironmentmap,andcoarse-to-
finetrainingstrategy,whichtogetherenablerobustreconstructionandrenderingofdiversescenes.
Notably,unlikeNeRF-DS,ourapproachdoesnotrequiremasksupervisiontoclearlydistinguish
between static and dynamic objects, as illustrated in Fig. 6. Additionally, Fig. 7 illustrates our
method’sdecompositionresults. Asshown,ourapproachconsistentlyachievesarealisticseparation
ofspecularanddiffusecomponentsacrossdifferentscenesintheNeRF-DSdataset.
8Table3: QuantitativecomparisonontheHyperNeRF(Parketal.,2021b)dataset. Wereportthe
averagePSNR,SSIM,andLPIPS(VGG)ofseveralpreviousmodels. The best,the secondbest,
and thirdbest resultsaredenotedbyred,orange,yellow.
Broom 3Dprinter Chicken PeelBanana Mean
Method PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓
Deformable3DGS(Yangetal.,2023c) 22.35 0.4952 0.5148 21.47 0.6921 0.2147 23.55 0.6747 0.2334 21.28 0.5302 0.4472 22.16 0.5981 0.3525
4DGS(Wuetal.,2023) 21.21 0.3555 0.5669 21.90 0.6993 0.3198 28.69 0.8143 0.2772 27.77 0.8431 0.2049 24.89 0.6781 0.3422
GaussianShader(Jiangetal.,2023) 17.21 0.2263 0.5812 17.31 0.5926 0.5054 19.70 0.6520 0.5004 19.99 0.7097 0.3308 18.55 0.5452 0.4795
GS-IR(Liangetal.,2023d) 20.46 0.3420 0.5229 18.24 0.5745 0.5204 20.64 0.6592 0.4536 20.15 0.7159 0.3021 19.87 0.5729 0.4498
NeRF-DS(Yanetal.,2023) 22.37 0.4371 0.5694 22.16 0.6973 0.3134 27.32 0.7949 0.3139 22.75 0.6328 0.3919 23.65 0.6405 0.3972
HyperNeRF(Parketal.,2021b) 20.72 0.4276 0.5773 21.94 0.7003 0.3090 27.40 0.8013 0.3052 22.36 0.6257 0.3956 23.11 0.6387 0.3968
Ours 22.04 0.5145 0.4494 19.96 0.6444 0.2397 22.20 0.6203 0.1970 27.34 0.8895 0.1290 22.89 0.6672 0.2538
Table4: Ablationstudiesondif-Table 5: Ablation study onTable6: AblationstudiesonSH,
ferent coarse to fine trainingcoarse-to-fineandlosses. Static and Deformable environ-
strategystages. C2FLnormalLregγkPSNR↑SSIM↑LPIPS↓ mentmap.
Stage PSNR↑SSIM↑LPIPS↓ ✓ ✓ ✓ 23.16 0.8294 0.2156 PSNR↑SSIM↑LPIPS↓
✓ 23.40 0.8277 0.2278
Static 20.26 0.7785 0.2953 ✓ ✓ 24.15 0.8510 0.1845 SH 23.63 0.8453 0.1844
St.+Dynamic 24.02 0.8508 0.1831 ✓ ✓ ✓ 24.09 0.8515 0.1818 StaticEnv.map 24.02 0.8508 0.1831
St.+Dy.+Specular 24.17 0.8529 0.1778 ✓ ✓ ✓ ✓ 24.17 0.8529 0.1778 DeformableEnv.map 24.17 0.8529 0.1778
(a) Ground truth dynamic masks (b) Our rendered deformation magnitudes
Figure6: Visualizationourdeformationmagnitudes. (a)Theleftsideshowsthegroundtruthof
thedynamicobject,while(b)ontherightside,werenderthemagnitudeoftheoutputoftheposition
residualbyourdeformableGaussianMLP.Thebrighterareasindicategreatermovementofthe3D
Gaussians. Thefigureshowsthatevenwithoutmasksupervision,ourmethodcanstilleffectively
distinguishwhichobjectsaredynamic.
4.2 ABLATIONSTUDY
Differentcoarsetofinetrainingstrategystages. AsshownintheTab. 4andFig. 8,eachstage
contributeseffectivelytothemodel’sperformance. TheDynamicstageenhancesobjectstability
comparedtotheStaticstagealone,whiletheSpecularstageimprovesreflectionclaritybeyondthe
combinedStaticandDynamicstages. Thiscoarse-to-fineapproachestablishesastablegeometric
foundationbeforeaddressingcomplexspeculareffects. Notethatthetotaliterationsforeachrowin
theTab. 4are40,000.
Ablationstudyoncoarse-to-fine,andlossfunction. Themodel’sperformancewasevaluated
withoutkeycomponents: thecoarse-to-finetrainingstrategy,normallossL ,normalregulariza-
normal
tionL ,andγk. Fig.9andTab. 5illustratetheeffectsoftheseomissions. Withoutthecoarse-to-fine
reg
approach, themodel, traineddirectlyatthespecularstage, producesincompletescenegeometry,
affectingenvironmentmapqueriesforspecularcolor. OmittingnormallossL removesdirect
normal
supervisiononnormals,impedinggeometricrefinementandreducingrenderingquality. Thisalso
leadstoinaccuratereflectiondirectionsandlessprecisespecularcolors. Removingnormalregular-
izationL allowsthenormalresidualtodominatenormaloptimization, resultingininsufficient
reg
optimizationofthe3DGaussians’shortestaxistowardsthecorrectnormal,whichinturnreduces
therenderingquality. Withoutγk innormalregularization,thenormalresidualdecreasesforboth
non-flattenedandflatGaussians. Thisparticularlyaffectslessflat3DGaussianswhoseshortestaxis
significantlydeviatesfromthesurfacenormal. Theinsufficientnormalresidualcorrectioncauses
these3DGaussians’shortestaxestodeviategreatlyfromtheiroriginaldirectioninanattemptto
alignwiththesurfacenormal,ultimatelyreducingrenderingquality.
AblationstudyonSH,Staticenvironmentmap,andDeformableenviormentmap. Fig.10and
Tab. 6demonstratethesuperiorityofthedeformableenvironmentmapoverthestaticenvironment
9s
A
n
is
a
B
Ground truth Render test image Specular color Diffuse color
Figure7: Visualizationourspecularanddiffusecolor. Specularregionsareemphasizedwhile
non-specularareasaredimmedtohighlighttheresultsofspecularregioncolordecomposition.
Static Static + Dynamic Static + Dynamic + Specular Ground-truth
Figure8: Qualitativecomparisonofeachtrainingstageinourcoarse-to-fineapproach.
Full model Full model Full model Full model
w/o Coarse-to-fine w/o ℒ normal w/o ℒ reg w/o 𝛾𝑘
Figure9: Qualitativecomparisonofablationstudywithoutdifferentcomponents.
Spherical Harmonics (SH) Static Env. map Deformable Env. map (Full model) Ground-truth
Figure 10: Qualitative comparison of ablation study on SH, Static environment map, and
Deformableenviormentmap.
map,whichinturnoutperformsSphericalHarmonics(SH).SHstrugglestoaccuratelymodelhigh-
frequencyspecularcolors. Whilethestaticenvironmentmapcanmodelhigh-frequencycolors,it
isbestsuitedforstaticlightingconditions. Incontrast,thedeformableenvironmentmapexcelsin
modelingtime-varyinglighting,offeringsuperiorperformancefordynamicscenes.
5 CONCLUSION
SpectroMotionenhances3DGaussianSplattingfordynamicspecularscenesbycombiningspecular
renderingwithdeformationfields. Usingnormalresidualcorrection, coarse-to-finetraining, and
deformableenvironmentmap,itachievessuperioraccuracyandvisualqualityinnovelviewsynthesis,
outperformingexistingmethodswhilemaintaininggeometricconsistency.
Limitations. Though we stabilize the entire scene’s geometry using a coarse-to-fine training
strategy,somefailurecasesstilloccur. Pleaserefertotheappendixforvisualresultsoffailurecases.
10REFERENCES
BenjaminAttal,EliotLaidlaw,AaronGokaslan,ChangilKim,ChristianRichardt,JamesTompkin,
andMatthewO’Toole. To¨rf:Time-of-flightradiancefieldsfordynamicsceneviewsynthesis,2021.
2
SaiBi,ZexiangXu,PratulSrinivasan,BenMildenhall,KalyanSunkavalli,MilosˇHasˇan,Yannick
Hold-Geoffroy,DavidKriegman,andRaviRamamoorthi. Neuralreflectancefieldsforappearance
acquisition,2020. 2
MarkBoss,VarunJampani,RaphaelBraun,CeLiu,JonathanT.Barron,andHendrikP.A.Lensch.
Neural-pil: Neuralpre-integratedlightingforreflectancedecomposition,2021. 2
Robert L Cook and Kenneth E. Torrance. A reflectance model for computer graphics. ACM
TransactionsonGraphics(ToG),1(1):7–24,1982. 4
WenhangGe,TaoHu,HaoyuZhao,ShuLiu,andYing-CongChen. Ref-neus: Ambiguity-reduced
neuralimplicitsurfacelearningformulti-viewreconstructionwithreflection,2023. 2
XiangGuo,JiadaiSun,YuchaoDai,GuanyingChen,XiaoqingYe,XiaoTan,ErruiDing,Yumeng
Zhang,andJingdongWang. Forwardflowfornovelviewsynthesisofdynamicscenes,2023. 2
Yi-HuaHuang,Yang-TianSun,ZiyiYang,XiaoyangLyu,Yan-PeiCao,andXiaojuanQi. Sc-gs:
Sparse-controlledgaussiansplattingforeditabledynamicscenes,2024. 2
YingwenqiJiang,JiadongTu,YuanLiu,XifengGao,XiaoxiaoLong,WenpingWang,andYuexin
Ma. Gaussianshader: 3dgaussiansplattingwithshadingfunctionsforreflectivesurfaces. arXiv
preprintarXiv:2311.17977,2023. 2,4,5,7,8,9
JamesTKajiya. Therenderingequation. InProceedingsofthe13thannualconferenceonComputer
graphicsandinteractivetechniques,pp.143–150,1986. 4
Brian Karis and Epic Games. Real shading in unreal engine 4. Proc. Physically Based Shading
TheoryPractice,4(3):1,2013. 4
BernhardKerbl,GeorgiosKopanas,ThomasLeimku¨hler,andGeorgeDrettakis. 3dgaussiansplatting
forreal-timeradiancefieldrendering,2023. 1,3,4,13
JunxuanLiandHongdongLi. Neuralreflectanceforshaperecoverywithshadowhandling,2022. 2
Tianye Li, Mira Slavcheva, Michael Zollhoefer, Simon Green, Christoph Lassner, Changil Kim,
Tanner Schmidt, Steven Lovegrove, Michael Goesele, Richard Newcombe, and Zhaoyang Lv.
Neural3dvideosynthesisfrommulti-viewvideo,2022. 2
ZhengqiLi,SimonNiklaus,NoahSnavely,andOliverWang. Neuralsceneflowfieldsforspace-time
viewsynthesisofdynamicscenes,2021. 2
RuofanLiang,HuitingChen,ChunlinLi,FanChen,SelvakumarPanneer,andNanditaVijaykumar.
Envidr: Implicitdifferentiablerendererwithneuralenvironmentlighting,2023a. 2
RuofanLiang,JiahaoZhang,HaodaLi,ChenYang,YushiGuan,andNanditaVijaykumar. Spidr:
Sdf-basedneuralpointfieldsforilluminationanddeformation,2023b. 2
YiqingLiang,NumairKhan,ZhengqinLi,ThuNguyen-Phuoc,DouglasLanman,JamesTompkin,
andLeiXiao. Gaufre: Gaussiandeformationfieldsforreal-timedynamicnovelviewsynthesis,
2023c. 2
ZhihaoLiang,QiZhang,YingFeng,YingShan,andKuiJia. Gs-ir: 3dgaussiansplattingforinverse
rendering. arXivpreprintarXiv:2311.16473,2023d. 2,4,7,8,9
HaotongLin,SidaPeng,ZhenXu,YunzhiYan,QingShuai,HujunBao,andXiaoweiZhou. Efficient
neuralradiancefieldsforinteractivefree-viewpointvideo,2022. 2
Yu-LunLiu,ChenGao,AndreasMeuleman,Hung-YuTseng,AyushSaraf,ChangilKim,Yung-Yu
Chuang,JohannesKopf,andJia-BinHuang. Robustdynamicradiancefields. InCVPR,2023a. 2
11Yuan Liu, Peng Wang, Cheng Lin, Xiaoxiao Long, Jiepeng Wang, Lingjie Liu, Taku Komura,
andWenpingWang. Nero: Neuralgeometryandbrdfreconstructionofreflectiveobjectsfrom
multiviewimages,2023b. 2
LiMa,VasuAgrawal,HaithemTurki,ChangilKim,ChenGao,PedroSander,MichaelZollho¨fer,
andChristianRichardt. Specnerf: Gaussiandirectionalencodingforspecularreflections. arXiv
preprintarXiv:2312.13102,2023. 2
Marko Mihajlovic, Sergey Prokudin, Siyu Tang, Robert Maier, Federica Bogo, Tony Tung, and
EdmondBoyer. Splatfields: Neuralgaussiansplatsforsparse3dand4dreconstruction. arXiv
preprintarXiv:2409.11211,2024. 2
JacobMunkberg,JonHasselgren,TianchangShen,JunGao,WenzhengChen,AlexEvans,Thomas
Mu¨ller,andSanjaFidler. ExtractingTriangular3DModels,Materials,andLightingFromImages.
InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),
pp.8280–8290,June2022. 2,4
KeunhongPark,UtkarshSinha,JonathanT.Barron,SofienBouaziz,DanBGoldman,StevenM.
Seitz,andRicardoMartin-Brualla. Nerfies: Deformableneuralradiancefields,2021a. 2
KeunhongPark,UtkarshSinha,PeterHedman,JonathanT.Barron,SofienBouaziz,DanBGoldman,
RicardoMartin-Brualla,andStevenM.Seitz. Hypernerf: Ahigher-dimensionalrepresentationfor
topologicallyvaryingneuralradiancefields,2021b. 2,7,8,9,15
SidaPeng,YunzhiYan,QingShuai,HujunBao,andXiaoweiZhou. Representingvolumetricvideos
asdynamicmlpmaps,2023. 2
AlbertPumarola,EnricCorona,GerardPons-Moll,andFrancescMoreno-Noguer. D-nerf: Neural
radiancefieldsfordynamicscenes,2020. 2
YahaoShi,YanminWu,ChenmingWu,XingLiu,ChenZhao,HaochengFeng,JingtuoLiu,Liangjun
Zhang, Jian Zhang, Bin Zhou, et al. Gir: 3d gaussian inverse rendering for relightable scene
factorization. arXivpreprintarXiv:2312.05133,2023. 2
LiangchenSong,AnpeiChen,ZhongLi,ZhangChen,LeleChen,JunsongYuan,YiXu,andAndreas
Geiger. Nerfplayer: Astreamabledynamicscenerepresentationwithdecomposedneuralradiance
fields,2023. 2
PratulP.Srinivasan,BoyangDeng,XiumingZhang,MatthewTancik,BenMildenhall,andJonathanT.
Barron. Nerv: Neuralreflectanceandvisibilityfieldsforrelightingandviewsynthesis,2020. 2
ColtonStearns,AdamHarley,MikaelaUy,FlorianDubost,FedericoTombari,GordonWetzstein,
andLeonidasGuibas. Dynamicgaussianmarblesfornovelviewsynthesisofcasualmonocular
videos. arXivpreprintarXiv:2406.18717,2024. 2
Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael Zollho¨fer, Christoph Lassner, and
ChristianTheobalt. Non-rigidneuralradiancefields: Reconstructionandnovelviewsynthesisofa
dynamicscenefrommonocularvideo,2021. 2
DorVerbin,PeterHedman,BenMildenhall,ToddZickler,JonathanTBarron,andPratulPSrinivasan.
Ref-nerf: Structuredview-dependentappearanceforneuralradiancefields. In2022IEEE/CVF
ConferenceonComputerVisionandPatternRecognition(CVPR),pp.5481–5490.IEEE,2022. 2
DorVerbin,BenMildenhall,PeterHedman,JonathanTBarron,ToddZickler,andPratulPSrinivasan.
Eclipse: Disambiguatingilluminationandmaterialsusingunintendedshadows. InProceedingsof
theIEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.77–86,2024a. 2
DorVerbin,PratulPSrinivasan,PeterHedman,BenMildenhall,BenjaminAttal,RichardSzeliski,
and Jonathan T Barron. Nerf-casting: Improved view-dependent appearance with consistent
reflections. arXivpreprintarXiv:2405.14871,2024b. 2
BruceWalter,StephenRMarschner,HongsongLi,andKennethETorrance. Microfacetmodelsfor
refractionthroughroughsurfaces. Renderingtechniques,2007:18th,2007. 4
12QianqianWang,VickieYe,HangGao,JakeAustin,ZhengqiLi,andAngjooKanazawa. Shapeof
motion: 4dreconstructionfromasinglevideo. arXivpreprintarXiv:2407.13764,2024. 2
GuanjunWu,TaoranYi,JieminFang,LingxiXie,XiaopengZhang,WeiWei,WenyuLiu,QiTian,
andXinggangWang. 4dgaussiansplattingforreal-timedynamicscenerendering. arXivpreprint
arXiv:2310.08528,2023. 2,4,7,8,9
WenqiXian,Jia-BinHuang,JohannesKopf,andChangilKim. Space-timeneuralirradiancefields
forfree-viewpointvideo,2021. 2
Zhiwen Yan, Chen Li, and Gim Hee Lee. Nerf-ds: Neural radiance fields for dynamic specular
objects. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition,
pp.8285–8295,2023. 1,7,8,9
JinyuYang, MingqiGao, ZheLi, ShangGao, FangjingWang, andFengZheng. Trackanything:
Segmentanythingmeetsvideos. arXivpreprintarXiv:2304.11968,2023a. 8
ZeyuYang,HongyeYang,ZijiePan,XiatianZhu,andLiZhang. Real-timephotorealisticdynamic
scenerepresentationandrenderingwith4dgaussiansplatting. arXivpreprintarXiv:2310.10642,
2023b. 4
Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin. De-
formable3dgaussiansforhigh-fidelitymonoculardynamicscenereconstruction. arXivpreprint
arXiv:2309.13101,2023c. 2,4,7,8,9
Ziyi Yang, Xinyu Gao, Yangtian Sun, Yihua Huang, Xiaoyang Lyu, Wen Zhou, Shaohui Jiao,
XiaojuanQi,andXiaogangJin. Spec-gaussian: Anisotropicview-dependentappearancefor3d
gaussiansplatting,2024. 2
KeyangYe,QimingHou,andKunZhou. 3dgaussiansplattingwithdeferredreflection. InACM
SIGGRAPH2024ConferencePapers,pp.1–10,2024. 2
WangYifan,FeliceSerena,ShihaoWu,CengizO¨ztireli,andOlgaSorkine-Hornung. Differentiable
surfacesplattingforpoint-basedgeometryprocessing. ACMTransactionsonGraphics(TOG),38
(6):1–14,2019. 3
JingyangZhang,YaoYao,ShiweiLi,JingboLiu,TianFang,DavidMcKinnon,YanghaiTsin,and
LongQuan. Neilf++: Inter-reflectablelightfieldsforgeometryandmaterialestimation,2023. 2
KaiZhang,FujunLuan,QianqianWang,KavitaBala,andNoahSnavely. Physg: Inverserendering
withsphericalgaussiansforphysics-basedmaterialeditingandrelighting. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,pp.5453–5462,2021a. 2
Xiuming Zhang, Pratul P. Srinivasan, Boyang Deng, Paul Debevec, William T. Freeman, and
JonathanT.Barron. Nerfactor: neuralfactorizationofshapeandreflectanceunderanunknown
illumination.ACMTransactionsonGraphics,40(6):1–18,December2021b.ISSN1557-7368.doi:
10.1145/3478513.3480496. URL http://dx.doi.org/10.1145/3478513.3480496.
2
XiaomingZhao,PratulPSrinivasan,DorVerbin,KeunhongPark,RicardoMartinBrualla,andPhilipp
Henzler. Illuminerf: 3drelightingwithoutinverserendering. arXivpreprintarXiv:2406.06527,
2024. 2
Zuo-Liang Zhu, Beibei Wang, and Jian Yang. Gs-ror: 3d gaussian splatting for reflective object
relightingviasdfpriors. arXivpreprintarXiv:2406.18544,2024. 2
A APPENDIX / SUPPLEMENTAL MATERIAL
A.1 IMPLEMENTATIONDETAILS
WeusePyTorchasourframeworkand3DGS(Kerbletal.,2023)asourcodebase. Ourcoarse-to-fine
approachisdividedintothreesequentialstages: static,dynamic,andspecular. Inthestaticstage,we
132
Positionalencoding
5 Δ𝑥
(𝑥,𝑦,𝑧) 6
Gaussian center
2 2 2 2 2 2 2 2 2
5 5 5 5 5 5 5 5 5 Δ𝑟
6 6 6 6 6 6 6 6 6
𝑡
Time 2
Positionalencoding 5 Δ𝑠
6
Figure11: ArchitectureofthedeformableGaussianMLP
Positionalencoding
𝜔𝑡
𝑟
Reflection direction
2 2 2 2 2 2 2 2 2
5 5 5 5 5 5 5 5 5 Δ𝜔ഥ𝑟𝑡
6 6 6 6 6 6 6 6 6
𝑡
Time
Positionalencoding
Figure12: ArchitectureofthedeformablereflectionMLP
trainthevanilla3DGaussianSplatting(3DGS)for3000iterationstostabilizethestaticgeometry.
The dynamic stage then introduces a deformable Gaussian MLP to model dynamic objects. We
firstoptimizeboththecanonicalGaussiansandthedeformableGaussianMLPfor3000iterations
untilthescenebecomesrelativelystable. Subsequently,weintroduceL ,enablingsimultaneous
normal
optimizationofthescene’snormalanddepth,furtherrefiningthegeometryforanother3000iterations.
Afterthedynamicstageconcludes,wetransitiontothespecularstage,whichinvolveschangingthe
colorrepresentationfromcompletesphericalharmonicstoc . Tomitigatepotentialgeometry
final
disruptions due to the initially incomplete c , we fix the deformable Gaussian MLP and all
final
3DGaussianattributesexceptforzero-orderSH,speculartint,androughness,whiletemporarily
suspendingdensification. After6000iterations, oncec becomesmorecomplete, weresume
final
optimizationofallparametersandreinstatethedensificationprocess. Concurrently,duringthefirst
2000 iterations of the specular stage, we optimize only the canonical environment map to learn
time-invariantlighting. Forthecanonicalenvironment,weuse6×128×128learnableparameters.
Subsequently,webeginoptimizingthedeformablereflectionMLPtocapturetime-varyinglighting
effects. Wetraintotaliterations40,000. AlltrainingandrenderingareconductedonanNVIDIA
RTX4090GPU.
A.1.1 NETWORKARCHITECTUREOFTHEDEFORMABLEGAUSSIANMLPANDDEFORMABLE
REFLECTIONMLP
We use deformable Gaussian MLP to predict each coordinate of 3D Gaussians and time to their
correspondingdeviationsinposition,rotation,andscaling. AsshowninFig. 11,theMLPinitially
processestheinputthrougheightfullyconnectedlayersthatemployReLUactivations,featuring
256-dimensionalhiddenlayers,andoutputsa256-dimensionalfeaturevector. Thisvectoristhen
passedthroughthreeadditionalfullyconnectedlayerscombinedwithReLUactivationtoseparately
outputtheoffsetsovertimeforposition,rotation,andscaling. Notably,similartoNeRF,thefeature
vectorandtheinputareconcatenatedinthefourthlayer. ForthedeformablereflectionMLP,we
utilizethesamenetworkarchitecture,asshowninFig.12.
14A.2 ADDITIONALEXPERIMENTRESULTS
WeprovideanHTMLinterfaceinthesupplementarymaterialzipfileforbrowser-renderedvideo
resultsofallcomparedmethods. ThisincludesqualitativecomparisonsontheNeRF-DSdataset
foreachscene,asshowninFig. 13,aswellasqualitativecomparisonsontheNeRF-DSdatasetfor
eachscenewithlabeleddynamicspecularmasks,asshowninFig. 15. Additionally,failurecasesare
presentedinFig. 16.
ev
eiS
sse
Pr
etalP
p
u
C
leBl
n
isaB
sA
Ground truth Ours Deformable 3DGS 4DGS GaussianShader GS-IR NeRF-DS HyperNeRF
Figure13: QualitativecomparisononNeRF-DSdatasetper-scene.
a
n
a
n
a
B
le
e
P
Ground truth Ours Deformable 3DGS 4DGS GaussianShader GS-IR NeRF-DS HyperNeRF
Figure14: QualitativecomparisonontheHyperNeRFParketal.(2021b)dataset.
15ev
eiS
sserP
etalP
p
u
C
lleB
n
isaB
sA
Ground truth Ours Deformable 3DGS 4DGS GaussianShader GS-IR NeRF-DS HyperNeRF
Figure15:QualitativecomparisononNeRF-DSdatasetper-scenewithlabeleddynamicspecular
masks.
Dramatic scenes
Figure16: Failurecases. Insomedramaticscenes,relyingsolelyontheDeformableGaussianMLP
isinsufficient,suchaswhenanarmentersorexitsthescene,leadingtomanyfloatersoccurring.
16