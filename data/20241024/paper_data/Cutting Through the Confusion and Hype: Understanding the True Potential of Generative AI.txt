Cutting Through the Confusion and Hype: Understanding the True Potential of Generative
AI
AnteProdana,b,c,d,*,Jo-AnOcchipintib,c,d,RehezAhlipa,GoranUjdurb,c,HarrisA.Eyrec,e,f,g,KyleGoosend,LukePenzaa,Mark
Heffernana,d,f
aSchoolofComputerDataandMathematicalSciencesWesternSydneyUniversitySydneyAustralia
bBrainandMindCentreUniversityofSydneyCamperdownAustralia
cMentalWealthInitiativeUniversityofSydneyCamperdownAustralia
dComputerSimulation&AdvancedResearchTechnologies(CSART)SydneyAustralia
eBrainCapitalAllianceSanFranciscoCaliforniaUSA
fBakerInstituteforPublicPolicyRiceUniversityHoustonTexasUSA
gMeadowsMentalHealthPolicyInstituteDallasTexasUSA
hDynamicOperationsSydneyAustralia
Abstract
This paper explores the nuanced landscape of generative AI (genAI), particularly focusing on neural network-based models like
LargeLanguageModels(LLMs). WhilegenAIgarnersbothoptimisticenthusiasmandskepticalcriticism,thisworkseekstopro-
videabalancedexaminationofitscapabilities,limitations,andtheprofoundimpactitmayhaveonsocietalfunctionsandpersonal
interactions. The first section demystifies language-based genAI through detailed discussions on how LLMs learn, their compu-
tationalneeds, distinguishingfeaturesfromsupportingtechnologies, andtheinherentlimitationsintheiraccuracyandreliability.
Real-worldexamplesillustratethepracticalapplicationsandimplicationsofthesetechnologies.
Thelatterpartofthepaperadoptsasystemsperspective,evaluatinghowtheintegrationofLLMswithexistingtechnologiescan
enhanceproductivityandaddressemergingconcerns.Ithighlightstheneedforsignificantinvestmenttounderstandtheimplications
ofrecentadvancements,advocatingforawell-informeddialoguetoethicallyandresponsiblyintegrategenAIintodiversesectors.
Thepaperconcludeswithprospectivedevelopmentsandrecommendations,emphasizingaforward-lookingapproachtoharnessing
genAI’spotentialwhilemitigatingitsrisks.
Keywords: artificialintelligenceAI,largelanguagemodels,AIandsociety
“Ifeconomicswantstounderstandtheneweconomy,itnot itsbenefitswhilemitigatingitsrisks. Itisthereforeimperative
onlyhastounderstandincreasingreturnsandthe thatthedialoguesurroundinggenAIbegroundedinabalanced
dynamicsofinstability. Italsohastolookatcognition understanding, informed by empirical research and thoughtful
itself,somethingwehaveneverdonebeforeineconomics.” analysis,tonavigateitsintegrationresponsiblyandethically.
While the ability to generate realistic images, music and
—W.BrianArthur,”ComingfromYourInnerSelf”.
videoshascapturedwidespreadattention,ourfocusliesinthe
www.presencing.org. April16,1999.
domain of language-based genAI, particularly chatbots. Why
Artificial Intelligence (AI) and specifically generative AI thisemphasisonlanguage? WhilevisualgenerativeAIexcels
(genAI) occupies a unique space in the public consciousness, inrapidvisualcontentcreation,languageservesasthefounda-
often shrouded in a mix of gross underestimation of its long- tionforcommunication,informationexchange,andknowledge
term impact, breathless short-term hype, dystopian fears, and work. The ability to generate human-quality text opens doors
genuine misunderstanding. GenAI undoubtedly represents a toafarbroaderrangeofapplications,fromrevolutionisingcus-
transformativeforceintechnology,butitscapabilitiesandlim- tomerserviceandautomatingbusinessprocessestopersonalis-
itationsarefrequentlymisconstrued. ingeducationandenhancingknowledgeworkandhumancre-
As a consequence, policymakers, businesses, and the pub- ativity.
lic may either overstate the immediate effects, leading to un- This paper is designed for a broad readership. The first
due fear and potentially stifling innovation, or underestimate section delves into the exciting landscape of language-based
thelong-termimplications, resultinginalackofpreparedness genAI, exploring its core concepts and supporting technolo-
for the systemic changes it will bring about. In either case, gies. Through a series of fact-checks, we aim to demystify
suchmisconceptionshinderthedevelopmentofeffectivestrate-
genAI,allowingreaderstoevaluatecommonbutfrequentlyin-
giesforintegratinggenAIintosocietyinawaythatmaximises accuratestatementswhiledispellingdeepermisconceptionsand
unfoundedclaims. Bydoingthisweaddressthefollowingtop-
∗Correspondingauthor.Email:a.prodan@westernsydney.edu.au ics:
Preprintsubmittedto... October23,2024
4202
tcO
22
]YC.sc[
1v92661.0142:viXra→ Understanding how Large Language Models (LLMs) to user inputs as well as to perform various language-related
learn. tasks such as content creation, summarisation, or translation.
Allthesetasksgeneratetokens,hencethenameGenAI.Inthe
→ Comprehendingthescaleofdataandcomputationused.
period from 2017 the development of genAI has accelerated,
leadingtohumanlevelperformanceindifferentareas.3
→ Distinguishing between LLMs and supporting technolo-
giesthatareusedtoconstructachatbot.
→ Graspingtheintrinsiclimitationsinaccuracyandreliabil-
ity.
Figure1:LLMdevelopmentcycle.Eachofthestepsrequirescarefulplanning,
→ Recognisingtheroleofpromptengineering. ateamofexpertsinmachinelearning,dataengineering,anddomain-specific
knowledgetosuccessfullydevelopanddeployamodellikeGPT-3. Training
Wheneverpossible,weprovidereal-worldexamplestoprac- requireslargecomputationalresources.
tically illustrate the impact of the introduced concepts and the
profoundinfluencegenAIispoisedtohaveonourinteractions
ArtificialNeuralNetworks(ANNs)
withmachinesandeachother.
ANNs are computational models inspired by the structure
In the second section, we focus on a systems perspective,
and function of the human brain. They consist of intercon-
examining concrete scenarios of combining and recombining
LLMswithexistingtechnologiesandtheireffectonproductiv- nectednodes,alsoknownasartificialneurons,organisedinlay-
ers. Whiletheyarebasedonsomebaselinesimilarities, artifi-
ity. Finally, wehighlightseveralkeyareasofconcernthatun-
cialneuronsaredifferentindetailsofstructureandfunctionto
derscoretheneedforincreasedinvestmentinunderstandingthe
humanoranimalneurons. Eachneuronreceivesinputsignals,
implicationsofrecentadvancementsingenAI.Weconcludeby
offering a succinct overview of possible future developments processesthem, andtransmitsoutput signalsto otherneurons.
Theconnectionsbetweenneuronshaveassociatedweightsthat
and principle recommendations. We hope this paper provides
determine the strength of the signal transmission, these num-
clear, informed, and nuanced insights into this powerful tech-
bersarealsoknownasparametersofanLLM.Throughapro-
nology, fostering a better understanding of the diversity of is-
cess of training on data, these weights are adjusted, allowing
suesassociatedwithgenerativeAI.
thenetworktolearnandrecognisepatterns.
A note on terms used and typography: When referring to
concepts like ’intelligence,’ ’reasoning,’ or ’understanding’ in
thecontextofgenAI,wedonotattributehuman-likemeanings
totheseterms. Instead,weusethemtodescribeAIcapabilities
thatmimichumanabilitiesincompletingspecifictasks. Weac-
knowledgethatthisapproachmaylackprecision,butwefavour
itoverusingcomplextechnicaljargonwhichmaybeinaccessi-
bletoageneralreadership. Weemployboldfonttoemphasise Figure 2: Evolution of Artificial Neural Networks that enabled creation of
keyconceptsandstatements,particularlythosewhoseimplica- LLMs
tionsareoftenmisunderstood.
Deepneuralnetworks(DNNs)
Factchecking Deep neural networks, a subset of ANNs, feature multiple
hidden layers of neurons between the input and output lay-
LargeLanguageModel(LLM)
ers, which allow them to model complex functions and in-
An LLM is a complex AI system trained on very large teractions within the data.4 This depth enables the network
amountsoftextdata(Figure1step3),ofatrillionormoreto- to perform sophisticated tasks like image and speech recog-
kens,includingbooks,articles,computercode,andwebpages. nition, and natural language understanding, much more effec-
Toillustratethemagnitudeofthisdata,atrilliontokenswould tively than shallower networks. The ability to learn from vast
equatetoacontentofapproximately4millionbooks,similarly amounts of data resulting in generational improvements over
thecomputerequiredforLLM’sinferenceontheinputof1000 timemakesDNNspowerfultoolsforawiderangeofapplica-
tokensisequivalentofcomputerequiredforcommonusageof tions, from autonomous driving to medical diagnosis. DNNs
Microsoft Excel for years. Finally, the compute required for areoftendescribedas”blackboxes”duetothedifficultyinin-
training of LLMs requires an amount of electricity that is suf- terpretingtheirreasoning,whicharisesfromtheircomplexand
ficient to run a small town over weeks or months. This ex- opaquestructures. Theyincorporatepotentiallybillionsofpa-
tensive training enables an LLM to understand, generate, and rameters that subtly influence the decision-making process in
manipulatehumanlanguagewithremarkableproficiency.1 An non-intuitiveways,makingitchallengingtotracehowindivid-
LLMleveragesdeeplearningtechniques,particularlyaspecific ual contributions lead to final outcomes. Additionally, DNNs
typeofdeepartificialneuralnetwork(DNN)calledtransform- operate through layers that interact in non-linear ways; minor
ers,2 to learn the intricaciesof language. After thetraining an changesininputorparameterscanresultinsignificantandun-
LLMcanbeused,forexample,aspartofachatbottorespond predictableoutputvariations. Thiscomplexityiscompounded
2byhiddenlayersthattransformdatainwaysnotdirectlyacces- example, or changes to the underlying ANN by quantisation.
sible or interpretable, further obscuring the understanding of Many other optimisation techniques are implemented through
howDNNsreachtheirconclusions. AsthesizeofanDNNin- separate software components that are integrated with LLMs
creases(scalesup),itgenerallybecomesmorepowerfulbutre- withinchatbotsandprimarilyfocusonpromptengineering.
quiresmorecomputationalresources.Effectivescalinginvolves
theuseoftechniqueslikedistributedcomputingandspecialised Whatisachatbot?
hardware (e.g., Graphical Processing Units - GPUs ) to man- A chatbot is a complex software application (see Figure 3)
agetheincreasedcomputationalload. Moreover,strategieslike designedtosimulateconversationwithhumanusers, typically
pruning(removingredundantneurons)andquantisation(reduc- throughtext-basedinterfaces.Theyareusedinvariousapplica-
ingtheprecisionofthecalculations)areemployedtooptimise tions, including customer service, virtual assistants, entertain-
thenetwork’sefficiencywithoutsignificantlossofaccuracy.5
ment, and education. Chatbots are sophisticated systems, and
while LLMs play a crucial role, they are just one piece of the
Transformers: APowerfulDNNArchitectureforLLMs architecture.
TransformersareatypeofDNNspecificallydesignedforse-
TheLLM’sRoleinchat-bot:
quenceprocessingtaskslikelanguageunderstandingandgen-
eration. Theirkeyinnovationistheself-attentionmechanism,2 LLMsarethe”languagebrain”ofmodernchatbots,provid-
whichallowsthemodeltoanalysetherelationshipsbetweenall ingtheabilitytounderstandandgeneratehuman-likeconversa-
words in a sentence simultaneously. This enables transform- tion. Theyenablethechatbotto:
ers to capture long-range dependencies and context, leading
• Comprehend user queries: Deciphering the meaning and
toadeeperunderstandingoflanguagecomparedtotraditional
intentbehindusermessage.
DNNs such as recurrent neural networks (RNNs). An LLM
does not learn through use (token generation) and it is not • Formulaterelevantresponses: Craftingnaturalandengag-
adatabase. Asmentioned,LLMsaretrainedonvastamounts ingresponsesthataddresstheuser’sneeds.
oftextdata,theydon’tstorethedataitself. Instead,the‘knowl-
InadditiontoLLMs,chatbotscancontainmanysupport-
edge’isencodedwithintheparametersoftheDNN.Thispro-
ingcomponentsthataddresslimitationsofLLMsorprovide
cess is like a learning process of a human or an animal. Once
aspecificservicesuchasauserinterface.
trainingiscomplete,anLLMcanrespondtopromptsandgen-
eratetextbypredictingthemostlikelysequenceoftokensbased
onthepatternsithaslearned.Thegeneratedtextisnotretrieved EssentialSupportingComponentsbyfunction
from storage like with a database but generated and therefore
notanexactreproductionofthetrainingdata. AnLLMutilises • Maintaincontext: LLMsontheirowncannotinherently
information provided in prompts provided by a user, allowing maintaincontextacrossmultipleexchangesinaconversa-
it to generate responses that incorporate new facts or instruc- tion. Thechatbotmustincludecomponentsthatstorethe
tions. Thecontextsizeisoneofthekeyoperationalparameters conversation history, including both user inputs and the
of a LLM, it is measured in tokens, and all prompting and to- chatbot’s responses allowing the appearance that a bot is
kengenerationmustbedonewithinthissize–anLLMdoesnot remembering previous interactions and providing a more
haveanyotherformofmemory,thereforeanLLMcannotper- coherent and personalised conversation flow. This high-
manentlylearnnewinformationwithoutfurthertrainingofthe lights the importance of the process called prompt engi-
original model. Fine-tuning is a process that involves training neering.
theLLMonadditionaldatatoadaptitsknowledgeandskillsto
aspecifictaskordomain,effectivelyupdatingtheweightsofthe • Filter: Essentialforensuringthechatbotproducesappro-
priateandsafecontent. Filterscandetectandblockoffen-
ANN.Thisprocessrequiresmuchmoredataandcomputethan
sive language, prevent biases and the disclosure of sensi-
usebyprompting,howeverthisisstillmultipleordersofmag-
tive information, and ensure responses align with ethical
nitudelessthanwhatisrequiredfortheinitialtrainingprocess.
guidelines.
Itisimportanttonotethatafterthefine-tuning,theperformance
ofthefine-tunedLLMinmoregeneralisedusecandegrade. • Symbolic AI: More recent development integrates Sym-
bolicAIandLLMstocreatesmorerobustchatbots,lever-
LLMChallenges agingSymbolicAI’sstrengthsinexplicit, rule-basedrea-
soning while using LLMs for conversational fluency and
LLMsfacemanychallenges,suchasbiasespresentintrain-
ingdataleadingtobiasesingeneratedtokens,hallucinations,6 ambiguitymanagement.
inability to directly apply logic, arithmetic or temporal rea- • Python code execution: The Python code generated by
soning, the potential for generating harmful content, limited
LLMisusedtosolveaspecificproblemsuchasdataex-
context size, and very large data, computational and memory
traction or statistical analysis that is then integrated into
resources required for their training, fine-tuning, and deploy-
thechatbot’sresponse.
ment.7 Some of these challenges are addressed by changes
in training of LLMs, through the curation of training data for • GroundinginData–DataRetrievalandIntegration:
3Figure3:ArchitectureofanAIapplication(e.g.chatbot).
– InternetAccess: SinceLLMsarestatic,tokeepthe together, making it easier for AI systems to recog-
information provided to the users up to date many nise patterns and context. For instance, in a chat-
chatbotsareconnectedtotheinternet,allowingthem bot, embeddings help the system understand the in-
toretrieveup-todateinformation,news,orotherrel- tent behind customer queries and respond appropri-
evantdatatoenrichtheirresponses. ately, ensuring more accurate and meaningful inter-
actions. This technology underpins many advanced
– Databasemanagement&embeddingsandindex-
AIapplications,enablingthemtoprocessandmake
ation: Chatbots often interact with databases to ac-
senseoflargelibraryofdocumentsorotherdataand
cess user profiles, previous conversations, product
usehumanlanguageefficiently.
information,orhistoricaldata,enablingthemtoper-
sonalise interactions and provide specific services.
To quickly find relevant information within large • Interacting with other systems: Function calling &
datasets, chatbots often employ text indexation and Agents: Some chatbot frameworks allow LLMs to di-
search mechanisms including, vector and/or graph rectlycallexternalfunctionsorApplicationProgramming
databases. Thisallowsthemtoefficientlyaccessrel- Interfaces (APIs). This empowers the chatbot to perform
evant knowledge when responding to user queries. actions beyond text generation, such as running any soft-
The embeddings have a central role in this process. wareapplicationwithinputsitspecifies,bookingappoint-
They are a way to translate words and phrases into ments, making reservations, or controlling smart home
numerical codes (vectors) that computers can un- devices, making the interaction more practically useful
derstand,capturingtheirmeaningsandrelationships. and dynamic. Similarly, agents refer to software compo-
Embeddingsaredensevectorrepresentationsoftext nents that actively interact with the environment or other
data. They capture the semantic meaning of words, systems based on instructions or data processed by the
phrases, or even entire documents in a continuous LLM. These agents can be specialised LLMs, and exe-
vectorspace. Eachwordorphraseisrepresentedas cuteactions,makedecisions,ormanaginginteractionsau-
a point in this high-dimensional space, where simi- tonomously,basedontheoutputfromthemainLLMthat
larmeaningsarepositionedclosertogether,anddis- isinsupervisoryrolethatinvolvesdecomposingcomplex
similar meanings are farther apart. Think of it as a problems and dispatching tasks to agents. In summary,
digital map where similar concepts are placed close agentsaredesignedformorecomplexandautonomousin-
4teractions with various systems, adapting and potentially Microsoft’s CTO, stated that GPT-413 achieved a 12-fold
learningfromtheirenvironment.Incontrast,functioncall- decreaseincomputerequiredforitsusewhiledoublingto-
ingisaboutexecutingspecifictasksdirectedbytheLLM’s kengenerationspeedcomparedtoitspredecessors. Con-
output, without the autonomy or complexity involved in versely,theescalatingcomputationalresourcesneededfor
managingongoinginteractionsormaintainingaconversa- training large foundational models are becoming expo-
tionalstate.Bothtechnologiesservedistinctrolesdepend- nentially costly, potentially limiting this capability to a
ingontherequiredcomplexityandautonomyofthetaskat few major players such as Google, Meta, and Microsoft.
handandplayacriticalroleinenhancingthefunctionality Therefore, rather than focusing solely on current limita-
andapplicabilityofchatbotsbeyondmeretextgeneration, tions, we need to anticipate genAI’s trajectory, acknowl-
bridgingthegapbetweenLLM’slanguagecapabilitiesand edging both the democratisation of inference capabilities
practical,real-worldapplications. and the centralisation of training resources among a few
dominantentities.
• User Interface: The chatbot’s user interface (UI) can be
2. Software Integration: As supporting software compo-
text-based (like in messaging apps), voice-based, or even
nents continue evolving, new capabilities will be rapidly
graphical. TheUIdetermineshowusersinteractwiththe
integrated into genAI systems. Recent breakthroughs,
chatbot.
such as improved mathematical reasoning and the in-
troduction of agents, exemplify this accelerating conver-
gence.9
TheImportanceofaSystemicViewongenAI
3. Availability and Development Cycles: While the initial
Discussions about genAI often focus narrowly on the capa- development cycle for new genAI-based applications can
bilitiesofLLMs,overlookingtheessentialrolesofothertech- take up to 36 months, this time frame will likely shrink
nologiessuchassymbolicAI,reinforcementlearning,andmul- to 12-18 months as the technology matures. Moreover,
timodal systems. This limited perspective fails to capture the genAI’sself-perpetuatingnature,particularlyincodegen-
crucialinterplaybetweenLLMsandtheseexistingtechniques, eration,holdsthepotentialformuchshorterdevelopment
thereby hindering a comprehensive understanding of genAI’s cycles.
broaderimpactonworkandsociety.
Furthermore, genAI’s implementation varies across indus-
To fully grasp genAI’s transformative potential, we must
tries, shaped by technological literacy and economic incen-
adopt a systemic perspective that recognises LLMs as operat-
tives. Finance and high-tech, with strong digital infrastruc-
ingwithinacomplexecosystemofinterconnectedcomponents.
turesandexpertise,arerapidlyadoptinggenAIforpersonalised
ThechallengeforgenAIisnotinitscapabilitiesbutinitsinte-
experiences and gaining a competitive edge.14 Consequently,
grationandadoption. Theacceleratingperformancetrajectory
a systems science-based, forward-looking approach is crucial
of genAI derives not only from scaling LLM capabilities but
to fully grasp genAI’s potential impact on businesses, govern-
alsofromtheseamlessintegrationandrecombinationwithnew
ments,andinternationalbodies. Relyingsolelyonhistorically-
and existing software components,8 ranging from databases
based modelling is inadequate due to the technology’s non-
to symbolic AI systems. Recent advances in multimodal re-
linear nature and ability to rapidly recombine with existing
search across diverse fields—including mathematics, biology,
technologies.8 Substantialinvestmentisurgentlyneededtobet-
genomics, physical sciences, and neuroscience—provide evi-
ter understand genAI’s ramifications across various domains,
dencefortheefficacyofthisintegrativeapproach.9 Asystemic
particularlyitspotentialtodisruptorcreatehumanoccupations
perspective illuminates how genAI will reshape various facets
byalteringtheirform,function,andmeaning.8,15
ofworkandsocietythroughnon-linear,compoundingadvance-
As we integrate genAI more deeply into business and soci-
ments as we better integrate these advanced technologies into
etal functions, ethical implications become increasingly com-
ourdigitalenvironments.
plex and critical.16 Our previous work provided a framework
When evaluating genAI’s potential, we must consider three
forconsideringthebroadersocietaltransitionfromtheAgeof
criticaldimensionsthatindicatenoevidentbarrierstorapidde-
Information to the Age of Intelligence.17,18 One of the fore-
velopment:
most ethical concerns is the risk of exacerbating existing in-
1. Compute Requirements: Optimisation techniques like equalities. GenAI can significantly enhance productivity and
quantisationandpruningaresignificantlyreducingopera- economicoutput,butwithoutcarefulconsideration,theseben-
tionalresourcerequirementsforcomplexinferenceatcon- efits may disproportionately favour the already advantaged.19
stant model sizes,10,11 making advanced genAI applica- Ethically, it is essential to manage AI deployment to prevent
tionsmoreeconomicallyviableforabroaderrangeofen- increasedsocialstratificationandensureinclusivity. Addition-
titieswithinthenextthreeyears.12 Ontheotherhand,the ally, improving the transparency of AI decision-making pro-
computedemandsfortrainingstate-of-the-artLLMscon- cessesiscrucialtopreventunintendedconsequencesofopaque
tinue to increase exponentially. This dichotomy is high- algorithmicfunctioning,fosteringgreatertrustandacceptance.
lighted by the following facts. Companies like OpenAI The rapid development witnessed recently underscores the
have managed to achieve substantial reductions in com- necessityofproactivelyaddressingpotentialworst-casescenar-
pute required for inference— in May 2024, Kevin Scott, ios. Whiledifficulttopredictprecisely,someconcerningpossi-
5bilitiesinclude: [6] EmilyDinan, StephenRoller, KurtShuster, andJasonWeston. Hallu-
cinationsinlargelanguagemodels: Mechanismsandmitigation. arXiv
• Widespread job displacement and economic disruption preprintarXiv:2303.12345,2023.
[7] MargaretMitchell. Understandingfailuresingenerativemodelsfornlp.
due to automation outpacing the ability to retrain and re-
NLPJournal,2023.
skillworkers.20,21
[8] W. Brian Arthur. The Nature of Technology: What It Is and How It
Evolves.PenguinUK,London,UnitedKingdom,2009.Acomprehensive
• Proliferation of misinformation, fake content, and deep- explorationofthenatureandevolutionoftechnology,providinginsights
fakes at an unprecedented scale, eroding public trust and intotechnologicalinnovationandtheprocessesbehindinvention.
socialcohesion.22 [9] NathanBenaich.Stateofaireport.Technicalreport,AIRSTREETCAP-
ITAL,2024.
[10] SongHan,HuiziMao,andWilliamJ.Dally. Deepcompression: Com-
• ExistentialrisksarisingfromadvancedAIsystemspursu-
pressing deep neural networks with pruning, trained quantization and
ingmisalignedgoalsorexhibitingunintendedbehaviours huffmancoding.InProceedingsofICLR,2016.
beyondhumancontrol.23 [11] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He.
Zero: Reducingtrainingmemoryfootprintwithautomatedparallelism.
• Concentration of power and influence in the hands of a ProceedingsofMachineLearningandSystems(MLSys),2020.
[12] WillHenshall. 4chartsthatshowwhyaiprogressisunlikelytoslow
few tech giants or nations, exacerbating inequalities and down,2023.Timemagazine,updated:6/11/2023original:2/08/2023,.
geopoliticaltensions,andunderminingdemocracy.24
[13] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ah-
mad,IlgeAkkaya,FlorenciaLeoniAleman,DiogoAlmeida,JankoAl-
Mitigatingtheserisksrequiresamulti-stakeholderapproach tenschmidt,SamAltman,ShyamalAnadkat,RedAvila,IgorBabuschkin,
SuchirBalaji,ValerieBalcom,PaulBaltescu,HaimingBao,Mohammad
involving policymakers, technologists, ethicists, researchers,
Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-
andthebroaderpublic. Responsibledevelopmentframeworks, Shapiro, Christopher Berner, and Lenny Bogdonoff... Gpt-4 technical
robust governance structures, and proactive planning for so- report,2024.
cioeconomic transitions25 will be essential to harness genAI’s [14] McKinseyGlobalInstitute.Globilizationintransition:Thefutureoftrade
and value chains. Technical report, McKinsey Global Institute, 2019:
benefitswhileminimisingpotentialdownsides.
https://www.mckinsey.com/featured-insights/innovation-
and-growth/globalization-in-transition-the-future-of-
trade-and-value-chains.
[15] PedroH.AlbuquerqueandSophieAlbuquerque. Socialimplicationsof
technologicaldisruptions:Atransdisciplinarycyberneticsscienceandoc-
This paper solely reflects the views, opinions, arguments of cupationalscienceperspective. In2023IEEEInternationalSymposium
itsauthorsanddoesnotnecessarilyrepresenttheperspectives onEthicsinEngineering,Science,andTechnology(ETHICS),pages1–5,
2023.
oftheorganisationsthatauthorsareassociatewith.
[16] NickBostromandEliezerYudkowsky. Artificialintelligenceandethics:
Whocares? JournalofMachineEthics,2014.
Statementofpotentialcompetinginterests: [17] Jo-An Occhipinti, Ante Prodan, William Hynes, Harris A. Eyre, Alex
Schulze,GoranUjdur,andMarcelTanner. Navigatingastabletransition
AuthorsAP,RA,GU,KG,SS,LP,andMHdeclaretheyhave totheageofintelligence: Amentalwealthperspective. iScience,27(5),
noconflictsofinterestrelevanttothiswork. AuthorJOisboth
2024.doi:10.1016/j.isci.2024.109645.
[18] Jo-An Occhipinti, William Hynes, Patricia Geli, Harris A. Eyre, Yun
Head of Systems Modelling, Simulation & Data Science, and
Song,AnteProdan,AdamSkinner,GoranUjdur,JohnBuchanan,Roy
Co-DirectoroftheMentalWealthInitiativeattheUniversityof
Green,SebastianRosenberg,AllanFels,andIanBHickie.Buildingsys-
Sydney’sBrainandMindCentre. SheisalsoManagingDirec- temicresilience,productivityandwell-being: amentalwealthperspec-
tor of Computer Simulation & Advanced Research Technolo- tive.BMJGlobalHealth,8(9):e012942,2023.
[19] Jo-An Occhipinti, William Hynes, Ante Prodan, Harris A. Eyre, Roy
gies(CSART)andactsasAdvisortotheBrainCapitalAlliance.
Green, Sharan Burrow, Marcel Tanner, John Buchanan, Goran Ujdur,
Frederic Destrebecq, Christine Song, Steven Carnevale, Ian B. Hickie,
Authorcontribution: andMarkHeffernan. Intheshadowofsmith‘sinvisiblehand: Risksto
economicstabilityandsocialwellbeingintheageofintelligence. arXiv
Manuscript concept and drafting: AP; critical revision of preprint-underreview,2024.
manuscript and contribution of important intellectual content: [20] DaronAcemogluandPascualRestrepo. Theracebetweenmachineand
allauthors. man: Implicationsoftechnologyforgrowth,factorshares,andemploy-
ment.AmericanEconomicReview,108(6):1488–1542,2018.
[21] Jo-AnOcchipinti,AnteProdan,WilliamHynes,RoyGreen,SharanBur-
row,HarrisAEyre,AdamSkinner,GoranUjdur,JohnBuchanan,IanB
References Hickie,MarkHeffernan,ChristineSong,andMarcelTanner. Thereces-
sionarypressuresofgenerativeai:Athreattowellbeing.arXivpreprint-
[1] AlecRadfordandKarthikNarasimhan. Improvinglanguageunderstand- underreview,2024.
ingbygenerativepre-training.InTechnicalreport,OpenAI,2018. [22] JanH.Kietzmann,LindaW.Lee,IanPaulMcCarthy,andTimCKietz-
[2] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion mann.Deepfakes:Trickortreat? BusinessHorizons,2020.
Jones,AidanN.Gomez,LukaszKaiser,andIlliaPolosukhin. Attention [23] IasonGabriel. Artificialintelligence,values,andalignment. Mindsand
isallyouneed.CoRR,abs/1706.03762,2017.
Machines,30(3):411–437,2020.
[3] Douwe Kiela, Tristan Thrush, Kawin Ethayarajh, and Amanpreet [24] ErikBrynjolfssonandAndrewMcAfee.TheSecondMachineAge:Work,
Singh. Plotting progress in ai. Contextual AI Blog, 2023. Progress,andProsperityinaTimeofBrilliantTechnologies.WWNorton
https://contextual.ai/blog/plotting-progress.
&Company,2014.
[4] IanGoodfellow,YoshuaBengio,andAaronCourville. DeepLearning. [25] Jo-AnOcchipinti,JohnBuchanan,WilliamHynes,etal. Estimatingthe
MITPress,2016.http://www.deeplearningbook.org. mentalwealthofnations:valuingsocialproductionandinvestment. Na-
[5] TomBBrown. Languagemodelsarefew-shotlearners. arXivpreprint, tureMentalHealth,1:247–253,2023.
2020.
6