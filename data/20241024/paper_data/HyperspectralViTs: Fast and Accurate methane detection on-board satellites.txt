PREPRINT.UNDERREVIEW. 1
HyperspectralViTs: Fast and Accurate methane
detection on-board satellites
V´ıt Ru˚zˇicˇka, Andrew Markham
Abstract—On-board processing of hyperspectral data with methods and benchmark the model in limited compute envi-
machine learning models would enable unprecedented amount ronment which serves as a proxy to the hardware available on
of autonomy for a wide range of tasks, for example methane
the satellite.
detection or mineral identification. Methane is the second most
Methane detection is an important task, which could lead
important greenhouse gas contributor to climate change, and
it’s automated detection on-board of satellites using machine to the reduction of anthropogenic methane in atmosphere -
learning models would allow for early warning system and this has been identified as one of the fastest pathways to
could enable new capabilities such as automated scheduling reduce global warming in United Nations Global Methane
inside constellations of satellites. Classical methods for methane
Assessment report [3]. In practice, the detection of methane
detection suffer from high false positive rates and previous deep
leaksremainstobemanual,astheoutputsofexistingmethods
learning models exhibit prohibitive computational requirements.
We propose fast and accurate machine learning architectures can be quite noisy. For large scale automation of this process,
which support end-to-end training with data of high spectral reliable and accurate models are needed to sift through the
dimension. We evaluate our models on two tasks related to increasing deluge of data from newly deployed hyperspectral
hyperspectral data processing - methane leak detection and
sensors.
mineral identification. With our proposed general architectures,
Mineral identification is a task related to scene decompo-
weimprovetheF1scoreofthepreviousmethanedetectionstate-
of-the-artmodelsbymorethan27%onanewlycreatedsynthetic sition into individual endmembers from a spectral library. On
dataset and by almost 13% on the previously released large itsownitcouldserveasastronggeneraltaskshighlyrelevant
benchmarkdataset.Wealsodemonstratethattrainingmodelson forfutureFoundationmodelsworkingwithhyperspectraldata.
the synthetic dataset improves performance of models finetuned
We note that one of the example downstream tasks of interest
onthedatasetofrealeventsby6.9%inF1scoreincontrastwith
could also be methane detection, as it has been shown that
training from scratch. On a newly created dataset for mineral
identification, our models provide 3.5% improvement in the F1 having information about scene background is beneficial for
score in contrast to the default versions of the models. With separation of methane leak events from confounders [4].
ourproposedmodelsweimprovetheinferencespeedby85.19% Autonomy on-board of satellites is needed to enable rapid
in contrast to previous classical and deep learning approaches
response, alerting and automatic scheduling within a constel-
by removing the dependency on classically computed features.
lation of satellites [5], [6]. Recent works have shown that
Namely, one capture from the EMIT sensor can be processed
in only 30 seconds on a realistic proxy hardware used on the detection of events of interest (such as floods) can be done
ION-SCV 004 satellite. directly in space with on-board machine learning models,
reducing the quantity of data for downlinking [7].
Index Terms—Hyperspectral Machine Learning, Methane De-
tection, Mineral Identification, On-board Deployment, Efficient We note that the proposed architecture is aimed at the
MachineLearning,MachineLearningforImagingSpectroscopy general problem of processing hyperspectral data and as such
can be used outside of the domain of remote sensing. By
framing the problem as an end-to-end semantic segmentation,
we disentangle the proposed architecture from the task of
I. INTRODUCTION
methane leak detection and retain generality.
IN this paper, we introduce HyperspectralViTs, new adap- Developing machine learning architecture for hyperspectral
tations of Transformer based machine learning models for dataiswelltimedandnecessaryformanydownstreamapplica-
semantic segmentation of hyperspectral data (also refered to tions.Hyperspectralremotesensingdataisusedinmineralogy
as imaging spectroscopy data) for low compute environments. [8] and agriculture [9]. Sensors with high spectral dimension
Wedemonstratetheseadaptationsontworecentarchitectures, aredeployedondevicesusedfordeepspaceexploration[10]–
SegFormer[1]andEfficientViT[2]andfortworelevanttasks, [12] and on hand-held devices [13] including mobile phones
methaneleakdetectionandmineralidentification.Wedescribe [14].
the existing landscape of approaches used to detect methane Our main contribution is the proposal of a new family
leaks and minerals in remote sensing data and outline several of models called HyperspectralViTs, architectures adapted to
limitations to these methods. We then use these as motivation handle hyperspectral data without informational losses due
to propose changes to the Transformer based architectures. to reliance on classically computed intermediate products, or
We improve the accuracy and inference speed of the existing due to informational bottlenecks in the original architectures
as illustrated on Figure 1. We analyse the limitations of
UniversityofOxford,Oxford,UK.Email:firstname.lastname@cs.ox.ac.uk existing machine learning architectures without adaptations
This work has been submitted to the IEEE for possible publication.
for hyperspectral data and show that we can improve their
Copyright may be transferred without notice, after which this version may
nolongerbeaccessible. performance with several simple steps.
4202
tcO
22
]IA.sc[
1v84271.0142:viXraPREPRINT.UNDERREVIEW. 2
Hyperspectral Classical machine Off-the-shelf deep Our proposal: in the desired area of interest, but only large methane leak
data learning approach learning approach adapted model
events can be detected and validation requires human expert
intervention.
C RGB Hyperspectral data provides more information for the task
of detecting methane signal, this is due to the improved
Default Default HyperspectralViT
T model model architectures sampling in spectral ranges where methane is visible (namely
Matched
T filter between 1600-1800nm and 2100-2500nm). This task has
been classically addressed with matched filter approaches
T C wx > hT e > rx e T C ! oL d no u cs es l a to so sf idi cn e af p lo e pr nm rd oa e dt n ui co cyn ts ! dI in mf do eur nm e s ita oot n i ao h ln i ig ta h yl b osp fo et tt c hl te ern a de l ac tk a ✓ aI nm dp r inov fee rd e na cc ec u spra ec ey d [20] which compare the observed data against the target
signature of methane. The resulting matched filter product,
Fig. 1: Illustration of the limitations of previous approaches
sometimes called “methane enhancement”, is quite noisy, as
and our proposed HyperspectralViTs, adapted Transformer
other confounder materials (for example rooftops, roads and
based architecture.
solar panels) get detected as well. Iterative matched filter
approaches, such as the mag1c filter [21] attempt to improve
Namely, we propose the HyperSegFormer and HyperEffi- the clarity of the product. Other works depend on matched
cientViT variants of the default models and evaluate them filter variants using wider spectral windows [22]. Up until
on a newly created dataset of synthetic methane leak events recently, these methane enhancement products were manually
in the data from the near global hyperspectral sensor EMIT inspected, and trained experts were tasked to create final
[15]. We then demonstrate that these gains translate over to detections.
a newly created dataset of real methane leak events from Mineral detection in remote sensing data has been ap-
the same sensor. We show that we are able to improve the proached with a wide range of classical methods which are
accuracy and the inference speed of the existing classical and described in the overview of [23], and only a subset of these
machine learning approaches by removing their dependency useshyperspectraldata.Mineralidentificationinhyperspectral
on the classical matched filter product. datacanbeformalisedasspectralunmixing,thatisidentifying
Finally,wedemonstratethatourmodelsarerelevantalsofor whichindividualendmembersfromaspectrallibraryofchem-
other tasks of interest on a newly created dataset for mineral ical and mineral constituents create the observed signature.
identification. One classical approach is the Tetracoder program [24] which
usesacascadeofmanuallyderivedrulestocompareobserved
spectral feature with a reference spectral library of minerals.
A. Literature review
It isolates discriminative portions of spectra known for each
In this paper we primarily tackle the tasks of methane leak
mineral using continuum removal techniques [25] and then
detection,assuchmostoftherelevantliteraturefocusesonthis
computes degree of fit metrics for each item in the library.
discipline. We however also keep a brief section on methods
It has been described as a simulation of the process a trained
used for mineral identification.
mineralogistwoulddowhenlookingatthehyperspectraldata.
The task of methane leak detection can be more generally
This task can also be formalised as semantic segmentation,
described as semantic segmentation of remote sensing images
using “multi-hot” labels (multiple minerals can be present in
and has recently seen increased interest from the machine
each pixel).
learning community [16].
Wenotethatdatasetsforglobalmineralidentificationacross
the entire globe are missing. Works such as [26] evaluate
their methods on just two airborne hyperspectral captures.
Works such as [24] compare their methods against several
wellstudiedscenessuchastheCupriteorAluniteHillscenes-
thesehavebeensparselyin-situsampledtoprovideverification
data. Note that large scale differences exist when comparing
in-situmeasurementsandspacebasedinstruments(whereone
pixel can cover over e.g. 60x60m area). Therefore, existing
worksmostlyremainlocalintheirscope,andtheuseddatasets
Fig. 2: Methane gas signature (shown through the methane
are quite small. Machine learning models adapted to handle
transmittance)incomparisonwiththebandrangesoftypically
hyperspectral data such as [27], [28] were typically trained
used multispectral and hyperspectral satellites.
onlyonverysmalldatasets.Withourworkweaimtotrainour
Figure 2 shows the wavelength range of typically used proposed models on much larger and more diverse datasets,
multispectral and hyperspectral satellites alongside with the while using multiple tasks.
target signature of methane (modelled from the HITRAN As has been identified by [29] and several overview papers
2012 database [17]). The multispectral satellite Sentinel-2 has [30]–[32], research in machine learning for processing hyper-
been previously used to monitor large methane leaks in [18], spectral data has been limited mainly due to the lack of large,
however multi-temporal passes over the same location were publiclyavailabledatasetswithhighqualityannotations.Many
needed to detect weaker events. The work of [19] uses data works still use very small datasets such as Indian Pines [33],
from the WorldView-3 satellite, which has multiple bands University of Pavia, Houston or Salinas, all of which containPREPRINT.UNDERREVIEW. 3
onlyafewdatacaptures.Asfurthernotedby[30],thisdatais
often divided into almost equal train and test subsets, which
leadstomodeloverfittingandresultswithveryhighaccuracies
almostregardlessoftheusedmodel.Inthedomainofmethane
leak detection, only the recent works of [4], [34] release
processed datasets from raw data captures, [34] furthermore
refines the available labels. The works of [35], [36] propose
machine learning models for detection and quantification of
Train
methane leak events in hyperspectral data, however the used Val
Test
datasets and codes aren’t published. In contrast, we publish
all our used code and trained models and present the created (a)OxHyperSyntheticCH4,OxHyperMinerals
datasets in a machine learning ready format.
Contributionofourworkcomparedtothepriorworksisthe
focus on the low compute environment and the corresponding
need for highly efficient models. We propose our models with
this constraint in mind and we also test them on limited
compute devices that serve as proxies to the computational
environment on-board of satellites [5], [37]. We note that one
could use off-the-shelf efficient machine learning models [2]
or apply methods such as pruning [38] to existing machine Train
Val
learning architectures to improve the inference speed of the Test
system. However, this would not address the problem of
(b)OxHyperRealCH4
informational loss either due to the reliance on classical
products, or due to informational bottlenecks encountered in Fig. 3: Locations of tiles used to create the OxHyper datasets
not adapted architectures. of EMIT data. We note that the same source tiles (including
Deployment of machine leaning models on-board of satel- the same dataset splits) are used for the minerals (where
lites with hyperspectral sensors was shown in [39] to filter they contain more spectral bands) and the synthetic methane
cloudydatacaptures.ThedemonstratorEarthObserver1(EO- datasets (where the methane leak events are added into the
1) mission by NASA hosted simple thresholding models that clean datacubes).
processed hyperspectral data on-board to detect clouds and
pre-classicy scenes [40] and later used models for mineral
identification in [41]. On-board deployment of unsupervised A. Methane leak event simulation
models to detect anomalous events in multispectral data was
In one of our datasets, we simulate synthetic methane
proposedin[42]andlatertestedon-boardofarealsatellitein
leak events in the clean hyperspectral datacubes, given the
[43].Theseexamplesmotivateusthatmethanedetectionusing
knowledge of the expected signal of methane and plume
deep learning models on the current generation of hardware
concentration data from real events. Unlike previous study of
ontoday’ssatelliteswouldbefeasible.Theyalsohighlightthe
[44], which used plume shapes simulated using the expansive
potential benefits from autonomy on-board.
Large Eddy Simulation (LES) [45], we use real methane leak
events from the similar hyperspectral sensor AVIRIS-NG, to
inform the simulation. Namely, we use the STARCOP dataset
II. DATA [34],givenit’simprovedandmanuallyrefinedlabelsandhigh
diversity of plume sizes.
Mathematically, we can describe the relation between a
In order to train machine learning models, which would
datacube with and without methane leak event using the
be able to generalise globally around the world, we primarily
Beer–Lambert absorption law [21] as:
need global and large datasets with high quality labels. As
we already noted, many of the typically used hyperspectral
datasetsareverysmall.Recentmethaneleakdatasetsfrom[4], L (α,s)=L ∗e−α∗s (1)
simulated clean
[34] are large enough to train deep learning models, however
theybothusedatafromtheaerialAVIRIS-NGsensor,whichis Where L refers to at sensor radiances in the hyperspectral
relativelylocalinscope(e.g.theFourCornersregionofUSA). datacubes (clean and resulting simulated one), α to the con-
Instead, we use the data from the recent hyperspectral sensor centration of methane at given location and s the methane
Earth Surface Mineral Dust Source Investigation (EMIT), absorptionatgivenwavelength.Wenotethatthequantityαis
which is deployed on the International Space Station and has usually the one we are trying to estimate with matched filter
near global coverage of the arid regions of the Earth [15]. In approaches [21]. As such, we can use existing matched filter
totalwecreatethreenewdatasetsfromEMITdata,theirglobal productsassourcesforthisquantitywhensimulatingsynthetic
coverage is demonstrated in Figure 3 and they are described events. For s we query the values of the methane signature at
in detail in Table I. the wavelength of each band as plotted on Figure 2.PREPRINT.UNDERREVIEW. 4
TABLEI:Overviewofdatasetscreatedinthispaper.Wereport
We then recompute the matched filter product from the
the number of large tiles of 512x512 px, note that we usually
simulateddatacubes,thisproductnowcontainsboththesimu-
further tile these into 64x64px tiles with 32px overlap.
lated event and the background profile of the scene (including
confounder noise).
OxHyper- Bands Spectralrange(nm) Train Val Test
SyntheticCH4 86 1573-1699,2004-2478 796 198 200
B. Mineral aggregation RealCH4 86 1573-1699,2004-2478 279 91 98
Minerals 285 381-2492 796 198 200
STARCOP[34] 125 RGB,1573-1699,2004-2480 3425 N/A 342
Example 3-mineral
components: Aggregated 3-mineral composite
RGB Hematite composite (binary mask)
inthevalidationdatasetand200inthetestdataset.Eachsubset
is made from completely non-overlapping sources of data
(cleanEMITdatacubesandlabelsfromtheSTARCOPdataset
from AVIRIS-NG data). In each subset we uniformly sample
the available plume sizes, so that we have similar distribution
of event sizes. Half of these tiles contain simulated events
while the other half is kept event free to provide negative
samples. We note that these large tiles (of 512x512 px) are
further tiled when training the models. When using the tile
sizeof64pixelswithanoverlapof32pixels,wefinallygeta
training dataset of 174341 samples. The total size of this data
hematif te e2 _+ wf ee a3 thering hemfe a3 tite hemfe a3 tite 0.0 0.1 0.2 is 228 GB.
nano.BR34b2 nano.BR34b2b
Secondly,wecreatethe“OxHyperRealCH4”datasetofreal
Fig. 4: Aggregation of mineral components into mineral methane leak events. In total we have 279 large tiles in the
classes. From left to right we show a RGB visualisation of training dataset, 91 in the validation dataset and 98 in the
the scene, binary mask of three common components for test dataset. These have reliable ground truth labels, which
Hematite, the aggregated Hematite product (using in total 14 we calculated from the original labels provided on the EMIT
components) and visualisations of a 3-minerals composites. data portal and consequentially manually checked. We note
Weshowthe“Goethite”,“Hematite”and“Kaolinite”compos- that this dataset is smaller than the other ones and training a
ite and the binary maps used for training (in the last column). machine learning model from scratch could lead to overfitting
andpoorgeneralisation,howeveritcanalsobeusedformodel
fine-tuning and to test generalisation ability of models trained
To create our new mineral dataset, we adapt the steps on other datasets. The total size of this data is 47 GB.
described in the Theoretical basis document [46] released Thirdly, we create “OxHyperMinerals”, a completely new
alongside the “EMITL2BMIN.001” product [47] computed dataset for mineral identification, with labels of 3 selected
from the raw EMIT data. This data contains identifications mineral classes and source annotation for all 381 constituents
of 381 individual components (separated into two groups). (separated into two groups). In total we have 796 large tiles
These can be aggreggated into larger mineral classes, for this in the training dataset, 198 in the validation and finally 200
we select the so-called “EMIT10” subset defined in [46]. The in the test dataset. These large tiles exactly match the tiles
aggregation process is shown on Figure 4. We note that we used in the synthetic methane events dataset, however they
use only the binary maps of three selected mineral classes out do not contain the simulated events and contain more bands.
ofthetotal10.WechosethesubsetM={Goethite,Hematite, Themineraldatasetcontainsall285spectralbandsinbetween
Kaolinite}, as these classes were abundant in the locations spectral range of 381-2492nm. The total size of this data is
sampledinourdataset.Weusethereleasedannotationswhich 372 GB.
were computed using the Tetracorder method [24], and as Finally, we also use a variant of the STARCOP dataset
such we can’t really use Tetracorder as a classical baseline from [34] with all relevant spectral bands extracted from the
(as it would unfairly obtain perfect scores). Therefore, we source data. We train our models and compare them on this
consider the created dataset as having pseudo-ground truth benchmark dataset with the previously reported results.
labels, and our results only as initial. We however note, that
given any manually validated dataset, our models could easily III. METHODOLOGY
be retrained with the new data.
A. Limitations of existing approaches
We are using three different semantic segmentation archi-
C. Final created datasets
tectures with the created dataset of hyperspectral datacubes
Firstly, we created the “OxHyperSyntheticCH4” dataset of - the commonly used U-Net model [48] and the newer Seg-
synthetically simulated methane leak events using the labels Former [1] and EfficientViT [2] models. These models can be
of the STARCOP dataset with newly downloaded near-global understood in terms of the encoder-decoder layout. The U-
hyperspectral datacubes from the EMIT sensor. In total we Net model consists of downsampling convolutional layers in
keep796largetiles(of512x512px)inthetrainingdataset,198 the encoder network, and upsampling layers in the decoder,PREPRINT.UNDERREVIEW. 5
while also using skip-connections to communicate across the Encoder Decoder
1 1 1 1 1 1 1
samespatialresolutionofthedata.TheSegFormermodeluses 2 4 8 16 2
Transformer blocks in its encoder network, concatenates the MMMLLLPPP
LLLaaayyyeeerrr
features from different resolution levels and then uses a MLP Upscale Layer
blockinthedecodernetwork.TheEfficientViTmodelsfurther *) First conv.
stride =2 proposes changes to make the model run faster on limited
hardware. In all models the spatial resolution is initially re- concat
ducedandthenreconstructedinthedecoder,whileinformation
at different scales is kept with the use of skip-connections, or
when concatenating the features together.
We are interested in training these architectures in an end-
to-end manner on the raw hyperspectral datacubes. In the
methane detection task, this allows us to not depend on the
classicalmatchedfilterproduct,whichcanbeslowandwhich
Fig.5:IllustrationoftheHyperSegFormermodelforsemantic
contains false detections of confounder materials. Models
segmentation of methane plumes in Hyperspectral data. We
designed with typical computer vision data in mind (with one
highlight in blue the three proposed modular adjustments: 1.)
tothreebands)howeversufferfromwhatwecallinformational
Spectral layers (denoted as “1x1 Conv”) in the Transformer
bottleneck when they are used with data with large spectral
blocks,2.)Upscalinglayerinthedecodernetwork(denotedas
dimensionality. As an example, if we select 86 bands of data
“Upscalelayer”)andfinally3.)adjustingthestrideofthefirst
which are relevant for our task of methane detection, the first
Transformer block to 2 (denoted as “Stride”). In red we show
layer in the vanilla versions of the used models reduces the
an example of the progressive decimation of the resolution
datavolumeby−95.34%inthecaseofeithertheSegFormer,
throughout the model (using all three adjustments).
EfficientViT or U-Net (instead of increasing this volume by
+33% as is common with RGB data). We claim that this
that it is quite effective, and it doesn’t significantly increase
informationalbottleneckforcesthemodeltogetridofmostof
the computational requirements of the model.
the potentially valuable information right at the entry point to
Secondly, we address the reduction of the spatial resolution
themodel,whichmeansthatthelaterlayerscannoteffectively
ofthedata.WeimplementasimilarUpscalinglayertotheone
extract high level compressed information, as this extraction
used in the U-Net architecture at the end of the Transformer
has to occur in the first convolutional layer.
basedmodels,justbeforetheirclassificationheads.Thisblock
Furthermore, we note that the SegFormer and EfficientViT
iscomposedoutoftworepeated2Dconvolutionallayerswith
architectures reduce the spatial resolution of the input data by
kernel size of (3,3), padding and stride of 1, each followed by
thefactorof4,andusenon-parametricbilinearinterpolationto
a ReLu activation layer and Batch normalisation layer.
scalethepredictedoutputtotheoriginalresolution.Incontrast,
As an additional solution for the recovery of the lost
the U-Net architecture reduces the spatial dimension of the
resolution, we also explore the change to the hyperparameters
dataonlybythefactorof2,andusesalearnedUpscalinglayer
of the original architectures, namely changing the stride of
at the end of the model to reconstruct the original resolution.
the first convolutional layer (e.g. in SegFormer from 4 to 2).
This change effectively increases the spatial size reduction of
B. Proposed architecture the data propagated through the network by the factor of 2.
Thisdoesn’tchangethenumberofparametersoftheresulting
We propose three modular changes to the selected ar-
model, but as the effect of this change influences the whole
chitectures to allow for better handling of data with high
model, the impact on the inference speed is larger than with
spectraldimension(suchasdatafromhyperspectralsatellites)
the Upscaling layer.
as illustrated on Figure 5.
These three proposed changes are modular and can be
Firstly, to aid with the spectral dimensionality of the data,
evaluated in isolation or used all together – the resolution of
we propose an addition of a special spectral layer into all
theoutputproductwilleitherbe¼,½,or1timestheresolution
Transformer blocks throughout the encoder networks. We add
of the input.
aConvolutionallayerwithkernelsizeof(1,1),strideof1and
padding of 0, keeping the output of each layer with the same
C. Baselines
spectral dimension as on its input. This allows for learning
operations that occur merely on the spectral data, on its own As a classical baseline approach for methane detection in
these allude to pixel-by-pixel operations of classical methods. hyperspectral data, we use the matched filter product (using
While in theory the original convolutional layers with larger the iterative variant mag1c [21]) with the threshold of 500
kernel sizes could learn similar operations, by restricting the ppm×m. Additionally, we apply an opening morphological
operationtojustthe1x1convolutions,weobtainmuchsharper filter to remove isolated noisy pixels in the product. As a
outputs. Effectively, this also allows the model to weight classical machine learning baseline, we implement the Hyper-
different input bands with a mechanism similar to attention, STARCOP model based on the U-Net architecture proposed
thus selecting only the relevant information for the task of by [34] and train it on our new methane datasets. This model
interest. While this is a simple addition to the model, we note uses the pre-computed matched filter product alongside the
Block
1
Transformer
Spectral
Layer,
1x1
conv.
Spectral
Overlap
Patch
Embedding
Block
2
SegFormer
Attention
Transformer
Mix
FFN
Spectral
N×
SegFormer
block:
Overlap
Patch
Merging
Block
3
Transformer Spectral
Block
4
Transformer Spectral
SpectraMl
LLPay Lerin,
e1axr1
conv.
OverlapU
Ppa, tbcihli
nEemarbedding
MLP
classifierPREPRINT.UNDERREVIEW. 6
RGB bands of the input data and effectively learns to clean 20epochswithtilesof64pxwith32pxoverlap.Inthiscase,
the classical methane enhancement product. We note, that if trained models use all 285 bands of the available EMIT data
the matched filter product misses a methane leak event, this (381-2492 nm). In this case, the data loader is not balancing
modelhasnowayofaccessingtheoriginalinformationinthe the samples and losses are not weighted.
hyperspectral datacube to recover the detection.
For the task of mineral identification, we can’t use the
A. Hardware Restrictions
classical method of Tetracorder as a baseline, as we used it
For training, we use a high performance computing cluster
to generate our pseudo-ground truth labels. When inspecting
with Tesla V100 GPUs with 32GB GPU memory and the
other baseline approaches such as for example the spectral
Intel Platinum 8628 (Cascade Lake), 2.90GHz CPU with
angle mapper (SAM) [49], we noted significant disagreement
384GB RAM. This type of machine is typically much more
between the two methods. As such, for the task of mineral
computationally capable than the hardware later used for
identification, we chose to only compare different versions
deployment.
of our adapted models against their default out-of-the-shelf
Therefore, with several tested model variants, we also
version which we treat as a deep learning baseline.
conducted experiments measuring the runtime on compute
IV. EXPERIMENTALSETUP constrained hardware, namely on the flatbed hardware pro-
vided by Unibap and D-Orbit [37]. These machines serve as
When training machine learning models on our newly cre-
a proxy to match the computational in-space environment of
ated datasets, we use the following settings and hyperparame-
a D-Orbit’s ION-SCV004 satellite, which is equipped with:
ters.Wetrainourmodelsonthetaskofsemanticsegmentation,
quad-core 1.2GHz, AMD GX-412HC SOC CPU processor,
in methane detection with two exclusive classes (“plume”
the Intel Movidius Myriad X VPU and 2GB of RAM. Similar
and “no plume”) and in mineral detection with a multi-hot
compute environments leveraging Myriad chips were used on
label (which allows no detection or potentially multiple active
prior missions such as ESA’s PhiSat-1 [51] and PhiSat-2 [52].
classes of “Goethite”, “Hematite” and “Kaolinite”).
We have also selected two other devices typically used
During training on the methane datasets, to balance the
for Internet-of-Things (IoT) applications, the CPU powered
data distribution, we oversample the instances with plume
Raspberry Pi boards and the GPU equipped NVIDIA Jetson
pixels by using the WeightedRandomSampler provided by the
AGX Xavier board. As has been noted by NASA’s guidelines
PyTorch library. We use the Adam optimiser with learning
on using Raspberry Pi’s in space [53], they are not suggested
rate of 0.001 for the U-Net architectures and 0.00006 for the
fordeploymentinanymissioncriticaltasksduetotheirlower
SegFormer and EfficientViT architectures. U-Net models use
robustness in extreme environments. They have been however
the MobileNet-v2 backbone [50] in the encoder, SegFormer
usedasaproxiesfordevicesofsimilarcomputepowerin[54].
uses the B0 backbone architecture and EfficientViT the B1
We then use the more powerful NVIDIA Jetson AGX Xavier
backbone architecture. We use the batch size of 32 with U-
board equipped with an 8-core NVIDIA Carmel ARMv8.2
Net models and 16 with SegFormer models, due to memory
CPU at 2.265 GHz and a GV10B GPU based on the Volta
limitations while training.
architecture with 16GB memory (shared between CPU and
Onthe“OxHyperSyntheticCH4”datasetwetrainallmodels
GPU).WeusedbothONNXRuntimepythonlibrariesandthe
for 50 epochs. When training we use the loss on the set aside
Tensor RT inference engine (using the trtexec command), as
validation subset to select the best performing models. When
was also used in the work of [2]. While initial tests of the
fine-tuningthemodelsonthe“OxHyperRealCH4”dataset,we
effects of radiation on NVIDIA’s Jetson devices was explored
train the models for further 10 epochs from the best reached
in [55] and proposed for space applications in [56], these
checkpoint.Whentrainingmodelsfromscratchonthissmaller
works also state that a careful examination and future tests
dataset, we keep the number of epochs to 50. End-to-end
are still needed.
models use 86 bands of the EMIT data (RGB and bands
between 1573-1699nm and 2004-2478nm).
To compare the newly proposed models with the Hyper- V. RESULTS
STARCOP “RGB+MF” model from [34], we also train them
In this section, we first compare the results from different
on the AVIRIS-NG STARCOP dataset. Here we train the
usedmodelsonthetaskofmethanedetectioninhyperspectral
models for 15 epochs using a batch size of 16 and tile size
datafromtwoexploredsensors.Secondly,wereporttheresults
of 128 px with an overlap of 64 px. Except for the batch size
fromusingourproposedmodelsonanoveldatasetformineral
(original was 32), these hyperparameters are kept the same as
identification. Finally, we also report measurements of the
in the original paper. We also weight the model loss by the
inference time needed to use these models on a compute
MF product, as was done with the original HyperSTARCOP
constrained hardware of the Unibap flatsats. These will serve
models. As there is no validation subset, we use the model
as an approximate proxy to the runtime needed on-board of
from the last epoch. All end-to-end models use 60 bands of
potential satellites.
AVIRIS-NG(namelybandsbetween2104-2400nm).Thiswas
chosentomatchtherangetypicallyusedbythematchedfilter
A. Methane detection on EMIT
as shown in Figure 2.
Finally, when training models on the “OxHyperMinerals” Figure 6 shows the comparison on the selected methods
datasetonthetaskofmineraldetection,wetrainallmodelsfor - classical baseline, U-Net based model from [34] and ourPREPRINT.UNDERREVIEW. 7
TABLE II: Quantitative results on the OxHyperSyntheticCH4 dataset. We show the average of training 5 runs of our models.
We also compare the results against the HyperSTARCOP model from [34].
AUPRC↑ F1↑ Precision↑ Recall↑ IoU↑ FPRbytile↓
Baseline,mag1c+morpho. N/A 37.65 31.69 46.37 23.19 89.0
HyperSTARCOPMF+RGB[34] 68.10±4.7 58.08±5.3 48.44±6.7 73.31±2.8 41.12±5.2 65.6±6.7
SegFormerbase 67.76±2.6 60.26±1.7 53.14±4.9 70.70±5.8 43.15±1.7 27.2±3.1
SegFormerConvUp 78.14±3.0 71.02±3.4 68.72±7.4 74.17±3.2 55.18±4.2 25.2±7.2
SegFormerConvUpStride 82.24±2.7 74.27±2.9 74.15±4.0 74.88±6.0 59.15±3.7 18.4±2.4
EfficientViTbase 74.29±7.3 68.40±6.9 65.54±10.3 72.75±6.0 52.39±7.8 25.0±5.0
EfficientViTConvUp 77.86±3.4 70.89±3.1 68.31±5.8 74.06±3.1 55.00±3.7 40.2±9.2
EfficientViTConvUpStride 78.94±5.3 72.26±4.9 72.63±6.3 72.19±5.5 56.80±6.0 31.8±5.9
MF product MF thr. baseline U-Net RGB+M Hyper SegFormer with classical machine learning approach of [34] and baseline
ConvUpStride
method using [21]. We note that all of the deep learning
TP approaches significantly outperform the classical baseline.
FP
FN Furthermore, our proposed HyperSegFormer (ConvUpStride
TN
variant)gainsover43.85%intheIoUscore(and27.88%inF1
and 20.7% in AUPRC) over the HyperSTARCOP MF+RGB
model. Our model also achieves over 155% in IoU score
TP
F FP N (and 96.9% in F1 score) over the classical matched filter
TN
baseline.These improvements hold over all measured met-
rics. We see increasing scores when implementing proposed
adaptations in both the SegFormer (from 60.26 F1 score to
TP
FP 74.27)andEfficientViT(from68.40F1scoreto72.26)ofour
FN
TN HyperspectralViT models.
TP MF Baseline ZeroShot FineTuned (10 ep) From Scratch (50 ep)
FP
FN 60
TN
TP 40
FP
FN
TN
0 3500 20
Fig. 6: Qualitative results on the OxHyperSyntheticCH4
dataset showing the computed matched filter in the first
column and comparing the performance of the matched filter
0
baseline, U-Net based model from [34] and our proposed Baseline MF Seg bF ao sr emer Se Cg oF no vr Um per CS oe ng vUFo pr Sm tre idr e Effi bci ae sn etViT Ef Cfic oi ne vn UtV piT CE of nfi vc Uie pn StV tri iT d e
Hyper SegFormer model (“ConvUpStride” variant).
Fig. 7: Quantitative results on the OxHyperRealCH4 dataset
showing the F1 score. We compare the MF baseline against
proposed Hyper SegFormer model (using the “1x1 Conv, Up, zero-shot generalisation, fine-tuning or training from scratch
Stride” variant). We illustrate the advantage of our proposed forbothproposedmodels.Resultsareaveragedfrom5training
solution.ThebaselineandtheU-Netbasedmodelsdependon runs, and the values on top of individual bars are rounded for
thematchedfilterproduct(alsoshowninthefirstcolumn),and better clarity.
as such, if this product doesn’t capture the full extent of the
methaneplumepresentinthedata,thesemodelsaren’tableto In Figure 7 we evaluate our adapted SegFormer and Ef-
correctly reconstruct it. Meanwhile, our proposed model has ficientViT models on the OxHyperRealCH4 dataset of real
access to the original source data and can extract information methane leak events captured by the EMIT sensor. Figure 8
which would be lost when using the matched filter product. shows the qualitative results on this dataset. Here, we use
Weshowthisinthefirstfourrows.Thelastrowdemonstrates the models pre-trained on the synthetic dataset (which uses
that if the matched filter product contains false detections data of the same input/output shapes and uses the same data
(confounder materials such as roads, and building outlines), normalisation) and test their zero-shot generalisation on the
both learned models can filter these out. datasetof real events. Furthermore, wefine-tune thesemodels
Table II shows the results of several tested model variants onthesmallerdatasetofrealevents.Finally,wealsocompare
for both SegFormer and EfficientViT architectures compared these results with training models from scratch only on thePREPRINT.UNDERREVIEW. 8
TABLE III: Quantitative results on the benchmark STARCOP dataset. We show the average of training 5 runs of our models.
AUPRC↑ F1↑ F1(strong)↑ F1(weak)↑ Precision↑ Recall↑ IoU↑ FPRbytile↓
Baseline,mag1c+morpho. N/A 40.14 67.50 39.95 30.57 58.42 25.11 75.43
HyperSTARCOPMF+RGB[34] 51.99±2.8 50.26±3.8 81.96±3.7 43.42±5.7 37.53±5.8 78.39±6.6 33.63±3.4 43.66±7.4
SegFormerbase 48.84±3.3 37.88±6.5 68.20±3.2 17.91±4.7 25.71±6.3 75.58±4.0 23.52±5.0 32.80±12.5
SegFormerConvUp 57.91±5.6 53.17±6.5 71.53±4.0 39.37±8.7 44.93±10.8 68.16±5.9 36.42±6.0 32.34±20.2
SegFormerConvUpStride 60.98±4.5 56.75±3.7 73.16±1.9 45.65±3.0 50.87±7.7 65.73±5.8 39.69±3.5 19.89±6.1
RGB MF product MF thr. baseline default, scratch H Cy op ne vr U E pf ,f i fc inie en tutV ni eT withtheEfficientViTmodels.Overall,wesee,thatonthetask
ofdetectingrealmethaneleakeventsinEMITdata,webenefit
TP from pre-training our models on a dataset of synthetically
FP
FN
TN created events (especially in cases similar to ours, where the
dataset of real events is relatively small).
TP
FP
F TN N B. Methane detection on AVIRIS-NG
In Table III we evaluate our newly proposed end-to-end
models on the benchmark dataset STARCOP [34] of real
TP
FP
FN methane leak events in data from the aerial AVIRIS-NG. We
TN
train our proposed end-to-end models from scratch matching
the settings used in the original work of [34].
T FPP When training our proposed models on the previously
FN
TN created benchmark dataset of real methane leak events in
AVIRIS-NG data, we see some interesting mixed outcomes.
While the performance of our models drops on F1 score
TP
FP
FN of strong methane leak events (plume emissions larger than
TN
1000 kg/h) in contrast to the HyperSTARCOP “MF+RGB”
0 3500 model, on the metrics that aggregate all event sizes together,
Fig. 8: Qualitative results on the OxHyperRealCH4 dataset. weseeimprovements.Namely,theHypeSegFormer(ConvUp-
From left to right we show the predictions of the classical Stride variant) outperforms the HyperSTARCOP “MF+RGB”
baselines, models trained from scratch and models pre-trained baseline by 12.9% in F1 score and by 18% in IoU score.
on the synthetic dataset (using the HyperEfficientViT model, The threshold-less AUPRC metric is also improved by over
ConvUpvariant).Wenotethatblackpartsaretheno-dataareas 17%.ThehighperformanceofpreviousSTARCOPmodelson
created upon orthorectification. strongmethaneleakeventscouldbeexplainedbythefactthat
the used matched filter method, mag1c, works better for large
plumes (as it is iteratively increasing the contrast of positive
dataset of real events. We note that this experiment resembles
pixels - this could however lead to lowered performance for
a real-world scenario, where we want to train models for a
weaker events).
newlydeployedsensor,whichhasn’tyetseenenoughofthese
We have encountered very large gains on the synthetic and
rare events. We try to answer the question of if pre-training
real EMIT datasets, however smaller ones on the benchmark
onasyntheticallycreateddatasethelpsthefinalmodelsdetect
dataset of AVIRIS-NG data. We note that perhaps better
events on a real but small dataset.
versions of the MF product could lead to stronger baselines
Interestingly, when evaluating the models pre-trained on
also in the EMIT data. For example [57] explores scene
the dataset with synthetic events on a new dataset of real
specific adaptation of MF products, and similarly there could
methane leak events collected by EMIT, we observe that the
besomeEMITspecificimprovementsforcalculatingMF.This
zero-shot generalisation performance is low (only two model
difference could also be caused by the number of used bands
variants reach the MF baseline). We however see that with
- while on the STARCOP dataset the end-to-end models use
fine-tuningfor10epochs,weareablesignificantlyoutperform
60 bands, on the new EMIT datasets we use 86 bands which
boththeclassicalbaselinesandallmodelvariantstrainedfrom
also demonstrate a wider spectral range coverage.
scratch. Namely the HyperSegFormer (ConvUpStride variant)
improves the performance of the MF baseline by 12.9% in F1
C. Mineral identification
score (and 17.1% in IoU) and the same version of the model
trained from scratch by over 6.9% in F1 score (and 8.8% in In Table IV, we show the results of training the proposed
IoU). The HyperEfficientViT (ConvUp variant) outperforms machine learning architectures on the mineral dataset OxHy-
the MF baselines by more than 23% in F1 (31.5% in IoU) perMinerals.WeshowtheindividualF1scoresforeachofthe
and the same model variant trained from scratch by 19.2% three mineral classes alongside the aggregated scores (which
in F1 (and 25.6% in IoU). Interestingly, the ConvUp variant are support weighted by the number of pixels belonging to
slightlyoutperformstheConvUpStridevariantsonthisdataset each class). In Figure 9 we also show examples of modelPREPRINT.UNDERREVIEW. 9
TABLE IV: Quantitative results on the mineral dataset OxHyperMinerals. We show the average of training 5 runs of our
models.
F1 Precision Recall F1Goethite F1Hematite F1Kaolinite
SegFormerbase 81.77±1.54 77.33±3.58 86.92±1.79 79.31±1.08 80.88±0.66 85.79±3.84
SegFormerConvUp 82.99±0.92 80.55±1.01 85.64±2.26 79.36±1.55 81.47±1.82 89.15±0.89
SegFormerConvUpStride 84.70±0.70 83.42±2.69 86.14±1.98 81.19±1.03 83.59±1.41 90.35±0.80
EfficientViTbase 77.08±0.74 79.37±3.73 75.28±3.99 69.88±3.09 77.89±1.09 85.25±1.05
EfficientViTConvUp 79.73±0.92 82.66±2.32 77.11±2.39 74.59±1.28 79.74±0.67 86.55±1.30
EfficientViTConvUpStride 79.18±1.16 84.03±2.74 74.96±2.17 73.57±1.20 77.93±2.70 87.24±1.22
RGB Minerals GT Hyper bS ae sg eFormer Hype Cr oS ne vg UF pormer Hy Cp oe nr v S Ue pg SF to rir dm eer D. Inference times on low compute hardware
G Heo met ah tit ite TableVshowsthemodelinferencetimesneededtoprocess
Kaolinite
None a full EMIT scene capture of 1280x1242 px with our models
for methane leak detection. These measurements show the IO
Goethite time needed to load the hyperspectral datacube and the model
Hematit
K Na oo nl einite inferencetime-forbaselinesthisalsoincludesthetimeneeded
to calculate the MF product.
Goethite We note that the matched filter computation is the slowest
Hematit
K Na oo nl einite step influencing both the classical baselines and the Hyper-
STARCOP models. Our proposed end-to-end model variants
avoidthisstepgainingvastlyreducedinferencetime.Namely,
Goethite
H Kae om lia nt ii tt e our proposed HyperSegFormer ConvUp variant reduces the
None
required time by over 85%, while the ConvUpStride variant
reduces the time by over 41% - both compared against the
Goethite
Hematit HyperSTARCOP model and effectively also the classical MF
Kaolinite
None
baseline.
Whenconsideringotherdevices,theMFcalculationremains
Fig. 9: Qualitative results comparing our new models on
to be the bottleneck and the end-to-end models are faster.
the mineral dataset OxHyperMinerals showing our proposed
While using the CPU of the Raspberry Pi 3B+ the runtime
Hyper SegFormer model variants (with output resolution
isslowerthanontheUnibapflatbed,RaspberryPi4Breaches
degradationindefault¼x,“ConvUp”½x,and“ConvUpStride”
similar performance. Finally, the most powerful CPU of the
full 1x).
NVIDIA’s Jetson AGX Xavier board shows the fastest run-
times of the tested CPU devices.
If we use our proposed HyperSegFormer ConvUp model
predictions next to the pseudo-ground truth generated by
on the Jetson AGX Xavier GPU, we achieve over 47x times
the Tetracorder system. Note the gradual increase of output
speed-upovertheUnibap’smachineCPU(e.g.0.64insteadof
resolution depending on the used adaptations.
30.1 seconds per capture) and 317x times speed-up over the
Whenexploringtheresultsofmodelstrainedonthedataset
HyperSTARCOP model (203.3 seconds per capture). Using
of minerals, we note smaller but sustained gains in perfor-
the GPU of the Jetson AGX Xavier board provides the fastest
manceduetotheproposedadaptations.NamelytheHyperSeg-
runtimesfromalltesteddevices.Weobservedfurtherspeedup
Former(ConvUpStridevariant)improvestheF1scorebyover
when using the Tensor RT engine (using the “trtexec” tool)
3.5%incontrasttothevanillamodel(andprecisionby7.9%).
and compiling the neural network directly on the device with
The HyperEfficientViT demonstrates weaker performance for
allowed post-training mixed precision quantization (allowing
both base and adapted versions, however the used adaptations
float32 and float16) - in the case of the HyperSegFormer
doimprovethisperformance-theConvUpvariantscores3.4%
ConvUp,thisisbyover70%incontrasttousingtheOnnxrun-
improvement in the F1 score.
timelibrary(withoutcompilationandwithoutmixedprecision
Perhaps better improvement can be seen on the qualitative mode).
comparison between the models on Figure 9, where we show
When using the Tensor RT inference engine, we also
the effect of gradually improving output resolution with the
experience faster inference times when using the adapted
HyperSegFormer model. The model variants using “Up” and
EfficientViT architecture instead of the adapted SegFormer
“Stride” adaptations (and their combination) show sharper
architecture - this is consistent with the fact the EfficientViT
predictions than the vanilla version of the model (as that one
was optimised for fast inference speed in [2]. Namely for
is limited to the output size reduced by the factor of 4).
theConvUpStridevariants,theHyperEfficientViThasruntime
We note that our experiments with mineral identification lower by about 64% in contrast with the HyperSegFormer
are initial, as we had to rely on pseudo-ground truth labels models. Similar reduction can also be observed on the CPU
generated by Tetracorder. of the Raspberry Pi devices.PREPRINT.UNDERREVIEW. 10
TABLE V: Timing of models on different devices. We estimate the time in seconds for processing a full granule of EMIT data
(1280x1242px tiled into 100 tiles of 128x128px). EfficientViT models weren’t evaluated on the Unibap machine. IO time to
load the hyperspectral tiles is kept separate in the last row.
UnibapCPU Rasp3CPU Rasp4CPU XavierCPU X.GPU(onnx) X.GPU(trtexec)
HyperSTARCOPMF+RGB[34] 203.3 1025.25 286.57 377 371.17 370.27
SegFormerBase 15.3 38.82 9.19 7.87 1.62 0.49
SegFormerUpConv 30.1 105.43 28.7 13.92 1.97 0.64
SegFormerUpConvStride 119.5 399.76 107.87 48.38 2.95 1.37
EfficientViTBase N/A 39.96 9.45 9.39 2.36 0.37
EfficientViTConvUp N/A 47.73 13.81 9.99 2.00 0.55
EfficientViTConvUpStride N/A 91.07 21.26 18.09 2.10 0.5
IO 4 39.99 12.88 6.13 6.13 6.13
For reference, the EMIT sensor collects up to 300 granules off-the-shelf performance, our proposed Hyperspectral variant
per day (and usually much less), and the NASA’s planned of the SegFormer model improves the F1 score by over 23%
SBGmission[58]willproduceanestimateofabout10xmore. on this synthetic dataset. We confirm our findings also on a
These granules have 1280x1242 px and can be tiled into 100 benchmark dataset released by [34], where we improve the
tiles of 128x128 which we used as reference when measuring overallF1scorebyalmost13%andtheAUPRCscorebymore
modelruntimes.Withtheestimated300granulesandusingthe than 17%. Finally, on a newly created dataset of real methane
measurementsfromtheUnibapmachines,themag1cmatched leak events recorded by the EMIT sensor, we demonstrate,
filterbaselinewouldrunforalmost17hours(with203seconds that it is possible to leverage models pretrained on synthetic
for each capture), while the proposed ConvUp variant of our data by fine-tuning them on smaller real datasets. Using the
HyperSegFormer would take just 2.5 hours (with 30 seconds best performing model variant, we show that the finetuned
for each capture). This time makes it more feasible to catch model improves the F1 score by 6.9% over models trained
up with the estimated rate of data capture, we also assume from scratch.
that data loading could be handled on another thread in a On a newly created dataset for the task of mineral iden-
delayedpipelineasin[59].Furtherreductiontojustestimated tification, we note that our HyperSegFormer (ConvUpStride
3.2 minutes (with 0.64 seconds for each capture) could be variant) improves the F1 score by over 3.5% in contrast to
achievedwhenusingtheGPUontheJetsonXavierboard.This thevanillamodel.Morenotably,weshowtheinfluenceofthe
outlines the potential speed-up future space missions could retained output resolution. While the default versions of the
leverage if using high-power compute units (even if these are Transformerbasedmodelslosedetailsinpredictedscenes,our
turned on just for short periods of time). adaptations greatly improve the quality of the predictions. We
Finally, we note that while the reported results measure note that our results are conducted on an initial dataset with
inference times of the methane leak detection models, these pseudo-ground truth labels made by the Tetracorder method
findings also generalise to our mineral identification models. [24]. However, with a manually verified dataset, it will be
Slower inference times can be expected due to the increased easy to retrain our models. Our initial results pave the path
spectral dimensionality of the used data (285 bands for the forfutureexperiments-tosupportthis,wereleaseourdataset
mineral identification models in contrast to 86 bands used by with labels for all separate constituents.
the models for methane detection). Furthermore, our models could be leveraged as Foundation
modelsinitiallytrainedonthedetectionofindividualchemical
components and later finetuned or adapted for a variety of
VI. CONCLUSION
downstream tasks (methane leak detection included). Gained
To summarise, our results indicate several interesting find- performance on the general detection task could also help the
ings. Firstly, we release HyperspectralViTs, the Transformer othertasksofinterest,aswasexemplifiedinthecaseofmulti-
based architectures adapted for the domain of hyperspectral task learning [60].
data. The adapted models outperform the default versions and In terms of inference speed, we achieve a 85.19% faster
baselines both in accuracy scores and in inference speeds performing model against the previously reported models and
on-board of devices that serve as a proxy for the compute baselines of [34]. We report the inference times measured on
environment of the ION-SCV004 satellite. hardwarewhichisarealisticproxytothecurrentlyflyingION-
To conclude, we demonstrate new state-of-the-art results SCV004satellite.Wehighlightthatwithourmodel,onescene
in methane detection using our end-to-end machine learning can be processed in around half a minute (6.7x times speedup
architectures adapted for hyperspectral data. Namely, on a against the baseline). We also measure our models on several
newly created dataset of synthetic events in data from the commercialoff-the-shelf(COTS)devices,theseexhibitfurther
EMIT sensor, we improve the F1 score by more than 27% potential speedups and have started to be explored for space
against the prior models depending on classical methane missions in [61]. Namely, we show over 317x times speedup
enhancementproductsfrom[34]andbyover97%inF1score when using GPUs on the NVIDIA Jetson AGX Xavier board.
over classical matched filter baselines. When comparing with As a potential limitation of the proposed end-to-end HyperPREPRINT.UNDERREVIEW. 11
SegFormermodel,itoperatesdirectlyontherawhyperspectral [6] J. Parr, G. Acciarini, C. Bridges, G. Mateo-Garc´ıa, E. Portales-Julia,
data and as such, it can’t be used for zero-shot generalisation C. Purcell, V. Ru˚zˇicˇka, A. Spalding, and J. Veitch-Michaelis, “Live
twinning: A vision of ml enabled assets in leo for rapid response
as for example the model of [34]. We however note, that a
to natural catastrophes,” in IGARSS 2024 - 2024 IEEE International
similar simulated dataset can be created from representative GeoscienceandRemoteSensingSymposium,2024,pp.685–688. 1
data for any other satellite and later used to train end-to-end [7] G.Mateo-Garcia,J.Veitch-Michaelis,L.Smith,S.V.Oprea,G.Schu-
mann, Y. Gal, A. G. Baydin, and D. Backes, “Towards global flood
models. Secondly, our model doesn’t support additional tasks
mapping onboard low cost satellites with machine learning,” Scientific
such as plume quantification or source point estimation. We reports,vol.11,no.1,pp.1–12,2021. 1
however note, that the prediction of our model can be used [8] S.PeyghambariandY.Zhang,“Hyperspectralremotesensinginlitho-
logical mapping, mineral exploration, and environmental geology: an
as a binary mask to clean the noisy methane enhancement
updatedreview,”JournalofAppliedRemoteSensing,vol.15,no.3,pp.
products,afterwhichclassicalpipelinesforthesetaskscanbe 031501–031501,2021. 1
used [62]. [9] B. Lu, P. D. Dao, J. Liu, Y. He, and J. Shang, “Recent advances
of hyperspectral imaging technology and applications in agriculture,”
For future research, we’d like to explore further steps to
RemoteSensing,vol.12,no.16,p.2659,2020. 1
make the models more efficient. Our proposed changes to [10] D. L. Blaney, C. Hibbitts, R. Green, R. Clark, J. Dalton, A. Davies,
the Transformer based models model can be combined with Y. Langevin, J. Lunine, M. Hedman, T. McCord et al., “The europa
clipper mapping imaging spectrometer for europa (mise): using com-
pruning reported in [38], [63]. Secondly, we’d also like to
positional mapping to understand europa,” in 50th Annual Lunar and
explore extension of our models with methods for uncertainty PlanetaryScienceConference,no.2132,2019,p.2218. 1
estimation. Methods such as model ensembles [64], or Monte [11] B. L. Ehlmann, R. L. Klima, C. L. Bennett, D. Blaney, N. Bowles,
S.Calcutt,J.Dickson,K.DonaldsonHanna,C.S.Edwards,R.Green
Carlo Dropout [65] could be easily added to the proposed se-
et al., “Lunar trailblazer: A pioneering smallsat for lunar water and
mantic segmentation models, as was previously demonstrated lunargeology,”inProceedingsofthe52ndLunarandPlanetaryScience
in [66]. Thirdly, we note that the existing archives of EMIT Conference,vol.2548,2021. 1
[12] R. Green, C. Pieters, P. Mouroulis, M. Eastwood, J. Boardman,
data (currently with more than 107k captures totaling more
T. Glavich, P. Isaacson, M. Annadurai, S. Besse, D. Barr et al., “The
than 215 TB of data) offer unique opportunities to train large moonmineralogymapper(m3)imagingspectrometerforlunarscience:
general foundation models on hyperspectral data, where one Instrumentdescription,calibration,on-orbitmeasurements,sciencedata
calibration and on-orbit validation,” Journal of Geophysical Research:
of the example tested tasks could also be methane detection.
Planets,vol.116,no.E10,2011. 1
Models proposed in this paper could likely be leveraged for [13] A. P. Ravikumar, J. Wang, and A. R. Brandt, “Are optical gas imag-
generallearningtasks(inthedirectionoutlinedbyourmineral ing technologies effective for methane leak detection?” Environmental
science&technology,vol.51,no.1,pp.718–724,2017. 1
identificationtask),butalsoforotherdownstreamapplications
[14] Spectracity, “See the world in true colors: the first smartphone with
highlighted by the future planned missions such as NASA’s multispectral imaging camera makes its global debut at ces,” https://
SBG [58] or ESA’s CHIME [67]. spectricity.com/,accessed:2024-09-29. 1
[15] R.Green,“EMITL1BAt-SensorCalibratedRadianceandGeolocation
Finally, we are releasing the three newly created datasets
Data 60 m V001,” Distributed by NASA EOSDIS Land Processes
on [TBR], [TBR] and [TBR] and the code and the pre-trained DistributedActiveArchiveCenter,2022,accessed2024-09-29.[Online].
models on Github at [TBR]. Available:https://doi.org/10.5067/EMIT/EMITL1BRAD.001 2,3
[16] E.Tiemann,S.Zhou,A.Kla¨ser,K.Heidler,R.Schneider,andX.X.Zhu,
“Machinelearningformethanedetectionandquantificationfromspace
- a survey,” 2024. [Online]. Available: https://arxiv.org/abs/2408.15122
ACKNOWLEDGMENTS 2
[17] L. Brown, K. Sung, D. Benner, V. Devi, V. Boudon, T. Gabard,
We would like to thank D-Orbit and Unibap for access C. Wenger, A. Campargue, O. Leshchishina, S. Kassi, D. Mondelain,
to the SpaceCloud® Hardware when measuring our models L. Wang, L. Daumont, L. Re´galia, M. Rey, X. Thomas, V. G.
Tyuterev, O. Lyulin, A. Nikitin, H. Niederer, S. Albert, S. Bauerecker,
inference speeds on realistic hardware proxy of a real satellite M.Quack,J.O’Brien,I.Gordon,L.Rothman,H.Sasada,A.Coustenis,
environment. M. Smith, T. Carrington, X.-G. Wang, A. Mantz, and P. Spickler,
“Methane line parameters in the hitran2012 database,” Journal of
Quantitative Spectroscopy and Radiative Transfer, vol. 130, pp.
201–219, 2013, hITRAN2012 special issue. [Online]. Available: https:
REFERENCES
//www.sciencedirect.com/science/article/pii/S0022407313002744 2
[18] D. J. Varon, D. Jervis, J. McKeever, I. Spence, D. Gains, and
[1] E. Xie, W. Wang, Z. Yu, A. Anandkumar, J. M. Alvarez, and P. Luo, D. J. Jacob, “High-frequency monitoring of anomalous methane
“Segformer: Simple and efficient design for semantic segmentation point sources with multispectral Sentinel-2 satellite observations,”
withtransformers,”AdvancesinNeuralInformationProcessingSystems, Atmospheric Measurement Techniques, vol. 14, no. 4, pp. 2771–
vol.34,pp.12077–12090,2021. 1,4 2785, Apr. 2021, publisher: Copernicus GmbH. [Online]. Available:
[2] H. Cai, J. Li, M. Hu, C. Gan, and S. Han, “Efficientvit: Lightweight https://amt.copernicus.org/articles/14/2771/2021/ 2
multi-scaleattention forhigh-resolutiondense prediction,” inProceed- [19] E. Sa´nchez-Garc´ıa, J. Gorron˜o, I. Irakulis-Loitxate, D. J. Varon, and
ings of the IEEE/CVF International Conference on Computer Vision, L. Guanter, “Mapping methane plumes at very high spatial resolution
2023,pp.17302–17313. 1,3,4,6,9 withtheWorldView-3satellite,”AtmosphericMeasurementTechniques,
[3] J.C.Kuylenstierna,E.Michalopoulou,andC.Malley,“Globalmethane vol.15,no.6,pp.1657–1674,Mar.2022,publisher:CopernicusGmbH.
assessment:Benefitsandcostsofmitigatingmethaneemissions,”2021. [Online].Available:https://amt.copernicus.org/articles/15/1657/2022/ 2
1 [20] D.R.Thompson,I.Leifer,H.Bovensmann,M.Eastwood,M.Fladeland,
[4] S.Kumar,I.Arevalo,A.Iftekhar,andB.Manjunath,“Methanemapper: C. Frankenberg, K. Gerilowski, R. O. Green, S. Kratwurst, T. Krings,
Spectralabsorptionawarehyperspectraltransformerformethanedetec- B. Luna, and A. K. Thorpe, “Real-time remote detection and
tion,”inProceedingsoftheIEEE/CVFConferenceonComputerVision measurement for airborne imaging spectroscopy: a case study with
andPatternRecognition,2023,pp.17609–17618. 1,3 methane,” Atmospheric Measurement Techniques, vol. 8, no. 10,
[5] G. Furano, G. Meoni, A. Dunne, D. Moloney, V. Ferlet-Cavrois, pp. 4383–4397, 2015. [Online]. Available: https://amt.copernicus.org/
A. Tavoularis, J. Byrne, L. Buckley, M. Psarakis, K.-O. Voss et al., articles/8/4383/2015/ 2
“Towardstheuseofartificialintelligenceontheedgeinspacesystems: [21] M. D. Foote, P. E. Dennison, A. K. Thorpe, D. R. Thompson, S. Jon-
Challengesandopportunities,”IEEEAerospaceandElectronicSystems garamrungruang, C. Frankenberg, and S. C. Joshi, “Fast and Accurate
Magazine,vol.35,no.12,pp.44–56,2020. 1,3 Retrieval of Methane Concentration From Imaging Spectrometer DataPREPRINT.UNDERREVIEW. 12
Using Sparsity Prior,” IEEE Transactions on Geoscience and Remote [41] D.R.Thompson,B.J.Bornstein,S.A.Chien,S.Schaffer,D.Tran,B.D.
Sensing, vol. 58, no. 9, pp. 6480–6492, Sep. 2020, conference Name: Bue, R. Castano, D. F. Gleeson, and A. Noell, “Autonomous spectral
IEEETransactionsonGeoscienceandRemoteSensing. 2,3,5,7 discoveryandmappingonboardtheeo-1spacecraft,”IEEETransactions
[22] J.Roger,L.Guanter,J.Gorron˜o,andI.Irakulis-Loitxate,“Exploitingthe onGeoscienceandRemoteSensing,vol.51,no.6,pp.3567–3579,2012.
entirenear-infraredspectralrangetoimprovethedetectionofmethane 3
plumeswithhigh-resolutionimagingspectrometers,”AtmosphericMea- [42] V. Ru˚zˇicˇka, A. Vaughan, D. De Martini, J. Fulton, V. Salvatelli,
surementTechniquesDiscussions,vol.2023,pp.1–21,2023. 2 C. Bridges, G. Mateo-Garcia, and V. Zantedeschi, “Ravæn: unsuper-
[23] H.Shirmard,E.Farahbakhsh,R.D.Mu¨ller,andR.Chandra,“Areview visedchangedetectionofextremeeventsusingmlon-boardsatellites,”
of machine learning in processing remote sensing data for mineral Scientificreports,vol.12,no.1,p.16939,2022. 3
exploration,”RemoteSensingofEnvironment,vol.268,p.112750,2022. [43] V. Ru˚zˇicˇka, G. Mateo-Garc´ıa, C. Bridges, C. Brunskill, C. Purcell,
2 N.Longe´pe´,andA.Markham,“Fastmodelinferenceandtrainingon-
[24] R. N. Clark, G. A. Swayze, K. E. Livo, R. F. Kokaly, S. J. Sutley, boardofsatellites,”IGARSSSession:TheAgeofAIandEdgeComputing
J.B.Dalton,R.R.McDougal,andC.A.Gent,“Imagingspectroscopy: inSpaceHasCome,2023. 3
Earthandplanetaryremotesensingwiththeusgstetracorderandexpert [44] S.Jongaramrungruang,A.K.Thorpe,G.Matheou,andC.Frankenberg,
systems,”JournalofGeophysicalResearch:Planets,vol.108,no.E12, “MethaNet – An AI-driven approach to quantifying methane
2003. 2,4,10 point-source emission from high-resolution 2-D plume imagery,”
[25] R.Clark,“N.,1999.spectroscopyofrocksandminerals,andprinciples Remote Sensing of Environment, vol. 269, p. 112809, Feb. 2022.
ofspectroscopy,”ManualofRemoteSensing.JohnWiley&Sons,New [Online]. Available: https://www.sciencedirect.com/science/article/pii/
York,pp.3–58,1999. 2 S0034425721005290 3
[26] Y.-q.Wan,Y.-h.Fan,andM.-s.Jin,“Applicationofhyperspectralremote [45] G.MatheouandD.Chung,“Large-eddysimulationofstratifiedturbu-
sensing for supplementary investigation of polymetallic deposits in lence. part ii: Application of the stretched-vortex model to the atmo-
huaniushanoreregion,northwesternchina,”ScientificReports,vol.11, sphericboundarylayer,”JournaloftheAtmosphericSciences,vol.71,
no.1,p.440,2021. 2 no.12,pp.4439–4460,2014. 3
[27] H. Sun, X. Zheng, X. Lu, and S. Wu, “Spectral–spatial attention [46] R. N. Clark, G. A. Swayze, V. J. Realmuto, P. G. Brodrick, and
network for hyperspectral image classification,” IEEE Transactions on D.R.Thompson,“EMITL2bAlgorithm:MineralDetectionandRelated
GeoscienceandRemoteSensing,vol.58,no.5,pp.3232–3245,2019. ProductsatthePixelScale[ATBDv0.2],”DistributedbyNASA,April
2 2020,accessed2020-04-15. 4
[28] D.Hong,Z.Han,J.Yao,L.Gao,B.Zhang,A.Plaza,andJ.Chanus- [47] R.Green,“EMITL2BEstimatedMineralIdentificationandBandDepth
sot,“Spectralformer:Rethinkinghyperspectralimageclassificationwith and Uncertainty 60 m V001,” Distributed by NASA EOSDIS Land
transformers,” IEEE Transactions on Geoscience and Remote Sensing, Processes Distributed Active Archive Center, 2023, accessed 2024-08-
vol.60,pp.1–15,2021. 2 16. [Online]. Available: https://doi.org/10.5067/EMIT/EMITL2BMIN.
[29] D. R. Thompson and P. G. Brodrick, “Realizing machine learning’s 001 4
promiseingeoscienceremotesensing,”EOS,vol.102,Jul.2021. 2
[48] O.Ronneberger,P.Fischer,andT.Brox,“U-net:Convolutionalnetworks
[30] A. Signoroni, M. Savardi, A. Baronio, and S. Benini, “Deep learning
for biomedical image segmentation,” in International Conference on
meetshyperspectralimageanalysis:Amultidisciplinaryreview,”Journal
Medicalimagecomputingandcomputer-assistedintervention. Springer,
ofImaging,vol.5,no.5,p.52,2019. 2,3
2015,pp.234–241. 4
[31] M. Paoletti, J. Haut, J. Plaza, and A. Plaza, “Deep learning classifiers
[49] R.H.Yuhas,A.F.Goetz,andJ.W.Boardman,“Discriminationamong
forhyperspectralimaging:Areview,”ISPRSJournalofPhotogrammetry
semi-aridlandscapeendmembersusingthespectralanglemapper(sam)
andRemoteSensing,vol.158,pp.279–317,2019. 2
algorithm,” in JPL, Summaries of the Third Annual JPL Airborne
[32] U.B.Gewali,S.T.Monteiro,andE.Saber,“Machinelearningbasedhy-
GeoscienceWorkshop.Volume1:AVIRISWorkshop,1992. 6
perspectralimageanalysis:asurvey,”arXivpreprintarXiv:1802.08701,
[50] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen,
2018. 2
“Mobilenetv2:Invertedresidualsandlinearbottlenecks,”inProceedings
[33] M.F.Baumgardner,L.L.Biehl,andD.A.Landgrebe,“220bandaviris
of the IEEE conference on computer vision and pattern recognition,
hyperspectralimagedataset:June12,1992indianpinetestsite3,”Sep
2018,pp.4510–4520. 6
2015.[Online].Available:https://purr.purdue.edu/publications/1947/1 2
[51] G. Giuffrida, L. Fanucci, G. Meoni, M. Baticˇ, L. Buckley, A. Dunne,
[34] V.Ru˚zˇicˇka,G.Mateo-Garcia,L.Go´mez-Chova,A.Vaughan,L.Guanter,
C. Van Dijk, M. Esposito, J. Hefele, N. Vercruyssen et al., “The ϕ-
and A. Markham, “Semantic segmentation of methane plumes with
sat-1 mission: The first on-board deep neural network demonstrator
hyperspectral machine learning models,” Scientific Reports, vol. 13,
for satellite earth observation,” IEEE Transactions on Geoscience and
no.1,p.19999,2023. 3,4,5,6,7,8,10,11
RemoteSensing,vol.60,pp.1–14,2021. 6
[35] P.Joyce,C.RuizVillena,Y.Huang,A.Webb,M.Gloor,F.H.Wagner,
[52] A. Marin, C. Coelho, F. Deconinck, I. Babkina, N. Longepe, and
M.P.Chipperfield,R.BarrioGuillo´,C.Wilson,andH.Boesch,“Using
M. Pastena, “Phi-sat-2: Onboard ai apps for earth observation,” Proc.
a deep neural network to detect methane point sources and quantify
SpaceArtif.Intell,2021. 6
emissions from PRISMA hyperspectral satellite images,” EGUsphere,
pp.1–22,Nov.2022,publisher:CopernicusGmbH.[Online].Available: [53] S.M.Guertin,“Raspberrypisforspaceguideline,”NASA:Washington,
https://egusphere.copernicus.org/preprints/2022/egusphere-2022-924/ 3 DC,USA,2022. 6
[36] I.Jahan,M.Mehana,G.Matheou,andH.Viswanathan,“Deeplearning- [54] E.W.GretokandA.D.George,“Onboardmulti-scaletileclassification
basedquantificationsofmethaneemissionswithfieldapplications,”In- for satellites and other spacecraft,” in 2021 IEEE Space Computing
ternationalJournalofAppliedEarthObservationandGeoinformation, Conference(SCC). IEEE,2021,pp.110–121. 6
vol.132,p.104018,2024. 3 [55] W.S.Slater,N.P.Tiwari,T.M.Lovelly,andJ.K.Mee,“Totalionizing
[37] O. Flordal, A. Synodinos, M. Herlitz, H. Magnusson, D. Steenari, doseradiationtestingofnvidiajetsonnanogpus,”in2020IEEEHigh
K.Fo¨rster,M.Castorina,T.George,I.Troxel,S.Reidetal.,“Spacecloud Performance Extreme Computing Conference (HPEC). IEEE, 2020,
cloudcomputingandin-orbitdemonstration,”inEuropeanWorkshopon pp.1–3. 6
On-BoardDataProcessing(OBDP),2021. 3,6 [56] M. Lofqvist and J. Cano, “Accelerating deep learning applications in
[38] C. Yang, P. Zhao, Y. Li, W. Niu, J. Guan, H. Tang, M. Qin, B. Ren, space,”arXivpreprintarXiv:2007.11089,2020. 6
X.Lin,andY.Wang,“Pruningparameterizationwithbi-leveloptimiza- [57] M.D.Foote,P.E.Dennison,P.R.Sullivan,K.B.O’Neill,A.K.Thorpe,
tionforefficientsemanticsegmentationontheedge,”inProceedingsof D.R.Thompson,D.H.Cusworth,R.Duren,andS.C.Joshi,“Impact
theIEEE/CVFConferenceonComputerVisionandPatternRecognition, ofscene-specificenhancementspectraonmatchedfiltergreenhousegas
2023,pp.15402–15412. 3,11 retrievalsfromimagingspectroscopy,”RemoteSensingofEnvironment,
[39] G. Giuffrida, L. Diana, F. de Gioia, G. Benelli, G. Meoni, M. Donati, vol.264,p.112574,2021. 8
andL.Fanucci,“Cloudscout:adeepneuralnetworkforon-boardcloud [58] K.Cawse-Nicholson,P.A.Townsend,D.Schimel,A.M.Assiri,P.L.
detectiononhyperspectralimages,”RemoteSensing,vol.12,no.14,p. Blake,M.F.Buongiorno,P.Campbell,N.Carmon,K.A.Casey,R.E.
2205,2020. 3 Correa-Pabo´n et al., “Nasa’s surface biology and geology designated
[40] S. Chien, R. Sherwood, D. Tran, B. Cichy, G. Rabideau, R. Castano, observable: A perspective on surface imaging algorithms,” Remote
A. Davis, D. Mandl, S. Frye, B. Trout et al., “Using autonomy flight sensingofenvironment,vol.257,p.112349,2021. 10,11
softwaretoimprovesciencereturnonearthobservingone,”Journalof [59] V.Ru˚zˇicˇkaandF.Franchetti,“Fastandaccurateobjectdetectioninhigh
AerospaceComputing,Information,andCommunication,vol.2,no.4, resolution4kand8kvideousinggpus,”in2018IEEEHighPerformance
pp.196–216,2005. 3 extremeComputingConference(HPEC). IEEE,2018,pp.1–7. 10PREPRINT.UNDERREVIEW. 13
[60] I.Kokkinos,“Ubernet:Trainingauniversalconvolutionalneuralnetwork
forlow-,mid-,andhigh-levelvisionusingdiversedatasetsandlimited
memory,” in Proceedings of the IEEE conference on computer vision
andpatternrecognition,2017,pp.6129–6138. 10
[61] J. Swope, F. Mirza, E. Dunkel, Z. Towfic, S. Chien, D. Russell,
J.Sauvageau,D.Sheldon,M.Fernandez,andC.Knox,“Benchmarking
remote sensing image processing and analysis on the snapdragon pro-
cessor onboard the international space station,” in IGARSS 2022-2022
IEEEInternationalGeoscienceandRemoteSensingSymposium. IEEE,
2022,pp.5305–5308. 10
[62] A. K. Thorpe, C. Frankenberg, A. Aubrey, D. Roberts, A. Nottrott,
T. Rahn, J. Sauer, M. Dubey, K. Costigan, C. Arata et al., “Mapping
methaneconcentrationsfromacontrolledreleaseexperimentusingthe
next generation airborne visible/infrared imaging spectrometer (aviris-
ng),”RemoteSensingofEnvironment,vol.179,pp.104–115,2016. 11
[63] H.Bai,H.Mao,andD.Nair,“Dynamicallypruningsegformerforeffi-
cientsemanticsegmentation,”inICASSP2022-2022IEEEInternational
Conference on Acoustics, Speech and Signal Processing (ICASSP).
IEEE,2022,pp.3298–3302. 11
[64] W. H. Beluch, T. Genewein, A. Nu¨rnberger, and J. M. Ko¨hler, “The
power of ensembles for active learning in image classification,” in
Proceedings of the IEEE conference on computer vision and pattern
recognition,2018,pp.9368–9377. 11
[65] Y. Gal and Z. Ghahramani, “Dropout as a bayesian approximation:
Representing model uncertainty in deep learning,” in international
conferenceonmachinelearning. PMLR,2016,pp.1050–1059. 11
[66] V.Ru˚zˇicˇka,S.D’Aronco,J.D.Wegner,andK.Schindler,“Deepactive
learning in remote sensing for data efficient change detection,” arXiv
preprintarXiv:2008.11201,2020. 11
[67] M. Rast, J. Nieke, J. Adams, C. Isola, and F. Gascon, “Copernicus
hyperspectral imaging mission for the environment (chime),” in 2021
IEEEinternationalgeoscienceandremotesensingsymposiumIGARSS.
IEEE,2021,pp.108–111. 11