Covariance estimation using Markov chain Monte Carlo
Yunbum Kook∗ Matthew S. Zhang†
October 23, 2024
Abstract
We investigatethe complexityofcovariancematrixestimationforGibbs distributionsbased
ondependentsamplesfromaMarkovchain. WeshowthatwhenπsatisfiesaPoincaréinequality
and the chain possesses a spectral gap, we can achieve similar sample complexity using MCMC
ascomparedtoanestimatorconstructedusingi.i.d. samples,withpotentiallymuchbetterquery
complexity. As an applicationof our methods, we show improvements for the query complexity
in both constrained and unconstrained settings for concrete instances of MCMC. In particular,
weprovideguaranteesregardingisotropicroundingproceduresforsamplinguniformlyonconvex
bodies.
1 Introduction
We focus on the problem of mean and covariance estimation using Markov chain Monte Carlo
(MCMC) methods. One setting which often arises in practice is when we want to approximately
estimate these statistics for a distribution π exp( V), where we are only given query access to
∝ −
V : Rd R and its gradient. For example, this occurs when π is given by a Bayesian posterior for
→
a large dataset. As it is impossible in general to obtain the normalizing constant for the measure,
one can only hope to obtain approximate samples from π via a MCMC procedure.
Precisely, suppose we are given some π-stationary Markov kernel P : Rd (Rd) R, with
×B →
P(A x) := P(x,A) and an initial tractable probability measure π . Then, the MCMC scheme
0
|
corresponding to (π ,P) generates the sequence X through the procedure
0 k k [N]
{ } ∈
X π , X P( X ) for all k = 1,...,N . (1.1)
0 0 k k 1
∼ ∼ ·| −
The cost for this algorithm is quantified by the total number N of queries; we are interested in
tot
its dependence on d and other problem parameters to be defined later.
While the standard theory for covariance estimation assumes independent and identically dis-
tributed (i.i.d.) samples, in practice statisticians take them from a sequence generated by some
Markov chain (despite the loss of the i.i.d. property); they use the iterates X to
{
Nburn+k }k ≤Nsamp
construct their estimates, with the “burn-in” time N needed to generate a good initial sample.
burn
From this, the next N samples are collected and used for the statistical estimation process,
samp
with N chosen so that we can construct an estimator that is suitably concentrated around the
samp
quantity of interest. Given that in most circumstances the cost of generating a warm-start (i.e.,
finding a π that is (1)-close to π) dominates that of bringing π to π within desired accuracy
0 0
O
∗School of Computer Science, Georgia Instituteof Technology, yb.kook@gatech.edu
†Dept. of Computer Science, Universityof Toronto, and VectorInstitute,matthew.zhang@mail.utoronto.ca
1
4202
tcO
22
]TS.htam[
1v74171.0142:viXra(i.e. N N ), it is much more cost-effective to continue evolving the Markov chain from the
burn samp
≫
previous sample, rather than restarting from ground up.
However, naïvely applying the standard i.i.d. concentration analysis for the resulting estimands
constructed with dependent samples does notlead to ausefulbound. Indeed,withoutleveraging an
additionalstructuralpropertyforP suchasspectralgap,thentheestimandcouldneverconcentrate
even as N (for instance when P = id).
samp
→ ∞
Recent years have seen a wealth of results establishing convergence guarantees for various
MCMC algorithms; see [Che24] for a thorough exposition. These results generally show the expo-
nential convergence1 of law(X ) to π in various strong notions of “distance”, so long as π satisfies a
k
suitablefunctional inequality. Thepresentworkoperatesinthesettingwhereπ satisfiesaPoincaré
inequality (PI) with constant C , and also assumes that P possesses a spectral gap of λ > 0.
PI
See §2.2 for precise definitions of these two concepts; intuitively, the Poincaré inequality says that
the tail of π should decay on the order of exp( x /√C ), while the spectral gap guarantees that
PI
−k k
law(X ) converges exponentially to π in an L2 sense.
k
While these two assumptions may appear unrelated at a first glance, for many settings they
are actually equivalent. The model example is the Langevin diffusion with target distribution π, a
stochastic process whose discretizations form the bedrock for many sampling algorithms. In this
case, spectral gap of thediffusionrunto atime his equivalent to aPoincaré inequality on its target.
Another case is the proximal sampler [LST21, CCSW22]. Running this sampler with step size h
ensuresthatχ2(µPk π) (1+h/C (π)) 2kχ2(µ π). Iterating thish 1C (π)times consecutively
PI − − PI
k ≤ k
will generate a Markov kernel with spectral gap arbitrarily close to 1.
Although there areother known approaches for handlingdependenceof samples (e.g., α-mixing,
see§1.2),thispairofassumptionswillturnouttobehandysincetheycapturemanysettingsofinter-
est. Firstly, the Poincaré inequality holds across a broad class of distributions. In particular, a cele-
brated recent result in functional analysis shows that (PI) holds with constant ( Cov(π) logd)
op
O k k
for any log-concave distribution [Kla23], which includes the uniform distribution over a convex
body. Secondly, many standard MCMC algorithms [LV06a, CCSW22, KVZ24] yield kernels with
spectral gaps under (PI). Thus, determining the sample and query complexity needed for accurate
statistical estimation under these assumptions is of paramount importance.
Encouragingly, [NSW23] shows that under suitable assumptions on spectral gap, the sum of a
Markovian sequence of matrices will satisfy a Bernstein-type inequality. Motivated by these efforts,
we investigate the following research question:
Question: What is the sample and query complexity of covariance estimation for a probability
measure π which satisfies a Poincaré inequality (PI)?
1.1 Results
Covariance estimation via MCMC. We demonstrate that MCMC methods for distributions
satisfying (PI) reduce the query complexity by a significant factor, compared to an estimator
constructed using i.i.d. samples. We summarize our main result in the theorem below. A similar
guarantee also holds for the mean vector X := N 1 N X E X.
− i=1 i ≈ π
Theorem 1 (Informal; see Theorem 8). Assume thPat π satisfies a Poincaré inequality and P has
a spectral gap. For ε > 0 and δ (0,d), the estimator Σ := 1 N (X X) 2 satisfies with high
∈ N i=1 i − ⊗
probability that Σ Cov(π) εΣ+δI , so long as N =
(trΣ+CPI(π)
).
| − | (cid:22)
d
O
Pεδ
1Up to a numerical error term induced by thediscretization of theeprocedure.
2We also provide a multiplicative form in Corollary 10. To the best of our knowledge, we are the
first work to give a theory of covariance estimation using MCMC under the standard assumptions
of a Poincaré inequality and a spectral gap.
Applications. To illustrate the broad applicability of our results, we provide several domains
where our bounds can be leveraged for significant improvements in query complexity.
The first occurs when sampling uniformly from a convex body Rd (i.e., π ). This
K ⊂ ∝ K
problem initiated the quantitative study of covariance estimation in theoretical computer science
(see §1.2). We demonstrate that, when is well-rounded, E [ 2] . d, we can estimate the
π
K k · k
covariance up to a constant factor with probability 1 (1/d), using roughly d3 oracle queries in
−O
expectation (Lemma 15). This contrasts with the best known complexity of roughly d4 in the
setting using i.i.d. samples. Using this, we can therefore convert a well-rounded convex body to a
near-isotropic one with the same complexity (Lemma 18). This is a key ingredient in the isotropic
rounding procedure of [JLLV21], needed for the state-of-the-art complexity in uniform constrained
sampling. Alongside this, we provide a simpler proof of the rounding algorithm therein (see §4.1).
Secondly, we show that for unconstrained sampling π exp( V), when π satisfies (PI) with
∝ −
constant α 1 and V is β-smooth, there exists an algorithm with query complexity (κd3/2/ε2) for
−
O
κ := β/α which achieves a covariance estimate Σ Σ ε Σ . If instead one were to use i.i.d.
k − k ≤ k k
samples, then the best known complexity is (κd5/2/ε2), which is worse by a dimeensional factor.
O
See Theorem 27 for more details.
1.2 Related work
Covariance estimation. Covariance estimation has long been studied in statistics. We concen-
trate on the following setting: given random i.i.d. samples (X ) from a centered distribution
i i N
≤
π with Σ := Cov(π), bound the number N of samples for which the following holds with high
probability
N
1 1
X 2 Σ Σ . (1.2)
N
i⊗
− ≤ 10k k
(cid:13) Xi=1 (cid:13)
(cid:13) (cid:13)
In this framework, the problem was(cid:13)first addressed b(cid:13)y [KLS97], obtaining N = (d2) for a uniform
O
distribution over a convex body. Their analysis occurred in the context of isotropic rounding of a
convex body, which was one of the subroutines in their volume-computation algorithm. This was
improved for general distributions by [Bou96, Rud99], and by [Pao06] for a convex body. The main
technique used by all of these works was a noncommutative moment inequality. Then, the seminal
workof[ALPTJ10]showedviaachainingargumentthatN = (d)foranylog-concave distribution.
O
They also showed that this holds for a sub-exponential distribution if additionally X . d1/2 (see
k k
Remark 4.11 therein). This bound without logarithmic overhead was further extended by [SV13]
under a bounded moment condition.
Another line of work follows from the matrix Laplace transform method, pioneered by [AW02]
andfurtherdevelopedin[Oli09,Ver12,Tro12]. TheeventualboundobtainedisalsoN = (dlogd),
O
where logarithmic oversampling is in general unavoidable. For a more comprehensive survey of the
literature, see the following monographs [Ver12, Ver18, RH23].
Concentration inequalities under dependence. Concentration inequalities such as the ma-
trix Bernstein inequality serves as a general arsenal for establishing the sample complexity of this
type of problem in the setting of i.i.d. data. We refer readers to [Tro15] for a comprehensive
overview of this topic. By contrast, the setting where X ,...,X are correlated has been com-
1 n
{ }
paratively understudied. Beginning with [Gil93], several works [Lez98, Pau15, JSF18, FJS21] have
proven concentration inequalities for (scalar) functions of iterates arising from a Markov process.
3
1MatrixconcentrationresultsunderMarkovianassumptionshaveonlyrecentlybeenstudied[GLSS18,
QWL+20]. Most relevant to our work is that of [NSW23], which establishes a Bernstein inequality
in the Frobenius norm, assuming that each sample is bounded and that the Markov chain has a
spectral gap. We also note that other literature has shown concentration for correlated iterates
under conditions other than a spectral gap [MJC+14, PMT16]. In particular, Bernstein inequali-
ties have been established under other assumptions such as the β-mixing or τ-mixing of the chain.
Under these properties, the representative works [MPR09, MPR11, BMY16] show a Bernstein-like
matrix concentration inequality, analogous to [NSW23]. However, in our applications it is difficult
to verify these conditions, unlike the spectral gap condition considered in our work.
Although matrix Bernstein inequalities are indeed very strong, they need to be combined with
a tail estimate in order to be usable in our setting. [ALPTJ10] shows that this is possible under
a log-concavity assumption of the target distribution. However, their argument cannot be applied
out-of-the-box to Markovian iterates, and requires some additional adjustments to remain valid.
Sampling under functional inequalities. The relationship between Markov chain methods
and spectralgaps dates back to the early theory of MCMC [Mih89, Fil91], and has beenthoroughly
characterized in discrete-space settings.
In continuous state-space, however, the problem is complicated by the need to ensure imple-
mentability of the resulting algorithm. Early results characterized the convergence under log-
concavityorlog-Sobolevconditions[DT12,Dal17,DMM19,VW19]. Whilethecontinuous-timecon-
vergence of many idealized processes can bederived easily fromPoincaré-type inequalities [BGL14],
only recently were results proven under (PI) for implementable samplers such as the Langevin
Monte Carlo algorithm or the proximal sampler [Leh23, CEL+22, CCSW22, AC24]. These works
demonstrate that when π satisfies (PI), the law of the iterates generated by the sampler achieves
ε-accuracy in χ2( π) with mild complexity, and that the proximal sampler actually contracts in
·k
saiddivergenceforany inputmeasure. Thisisequivalent toaspectralgap fortheproximalsampler.
As a result, we focus our attention on the proximal sampler, since merely guaranteeing ε-accuracy
in χ2-divergence is not sufficient to establish the concentration of an estimand constructed from
Markovian iterates.
For constrained targets such as uniform distributions over convex bodies, Ball walk [LS93,
KLS97]andHit-and-run[Smi84,Lov99]wereshownto have mixingtimes dependingontheCheeger
isoperimetric constant of the target. Only recently, [KVZ24, KZ25] proposed a sampler with Rényi-
infinity guarantees which directly quantify the dependence on the Poincaré constant; this in turn
depends on the degree of isotropy of the target, i.e., how close its covariance matrix is to the
identity.
A related line of research [LV06b, CV18, JLLV21] discovered a procedurewhich could place any
convex bodyin isotropic position. They iteratively estimate the covariance matrix of subsets of the
convex body, and then sample from it with only (d3.5) complexity. To achieve their complexity,
O
they rely on a Markovian covariance estimator subroutine, which we also study in the present work.
e
1.3 Organization
The paper is organized as follows. In §2, we provide some preliminaries needed for our main result.
In §3, we state our main bound on the concentration of covariance matrices generated by a Markov
chain, and present a brief proof sketch. §4 then gives our two primary applications for covariance
estimation, and includes some additional details for the isotropic rounding algorithm. §5 and §6
contain the proofs for the results of the previous sections. We conclude by summarizing future
directions along this line of research.
42 Preliminaries
2.1 Notation
We use for the ℓ -norm on Rd, and for the operator normon Rd d, while indicates the
2 × F
k·k k·k k·k
Frobenius norm. For a vector u Rd, we denote its outer product by u 2 := uuT. Next, a = (b)
⊗
∈ O
or a . b signifies that a cb for an absolute constant c > 0. Similarly, a & b,a = Ω(b) signifies
≤
a cb, while a = Θ(b) signifies a . b,b . a simultaneously. We also use a = (b) to denote
≥ O
a = (b) up to a polylogarithmic factor. When comparing matrices, we write A B for two
O | | (cid:22)
matrices A,B Rd d to denote B A B. We conflate a measure and its denseity throughout
×
∈ − (cid:22) (cid:22)
the work where there is no confusion. Lastly, (Rd) indicates the set of probability measures over
P
Rd.
Since we are primarily concerned with the high-dimensional complexity of the algorithm, many
of our results involve algebraic simplifications that are valid only when the dimension d 200 is
≥
sufficiently large. In quantifying failure probabilities for our algorithm, we introduce a constant p
which may change from line to line, but is always some universal constant that does not depend on
d,ε or any other parameter of interest.
2.2 Background
We now formalize key notions needed for our main results.
Definition 2. We say that a probability measure π on Rd satisfies a Poincaré inequality (PI) with
parameter C (π) 0 if for all smooth functions f :Rd R,
PI
≥ →
var f C (π)E [ f 2], (PI)
π PI π
≤ k∇ k
where var f := E [f E f 2].
π π π
| − |
In particular, (PI) implies that any 1-Lipschitz function f concentrates around its mean E f
π
in a sub-exponential manner:
t
P (f E f t) 3exp for all t 0. (2.1)
π π
− ≥ ≤ − C (π) ≥
PI
(cid:0) (cid:1)
Definition 3. Let P :Rd (Rd) R be a Marp kov kernel, i.e., P( x) (Rd) for every x Rd.
×B → ·| ∈ P ∈
For the stationary measure π (Rd) of the Markov kernel, P is said to have a spectral gap
∈ P
λ (0,1] if for every f :Rd R with f L2(π) and E f = 0, we have
π
∈ → ∈
Pf 2 := E E [f(Y)] 2 (1 λ)2 f 2 .
k
kL2(π) X ∼π Y ∼P( ·|X)
≤ − k
kL2(π)
(cid:2)(cid:0) (cid:1) (cid:3)
A kernel P is reversible if Pf,g = f,Pg for all f,g L2(π).
L2(π) L2(π)
h i h i ∈
Wesayasequence(X ,X ,...)isdriven by P withinitialdistributionπ ifitisgeneratedbythe
0 1 0
procedure in (1.1). The following metrics2 between probability measures will be useful throughout
our work, particularly for the applications.
Definition 4 (Probability divergences). For µ,ν (Rd), the χq-divergence is defined by
∈ P
dµ
χq(µ ν):= q dν 1 if µ ν, and otherwise.
k dν − ≪ ∞
Z
(cid:0) (cid:1)
2Although not all of these are proper metrics, we still refer to them as such in sense of “performance metric”.
5In particular, χ2(µ ν)= (dµ 1)2dν. The q-Rényi divergence is given by
k dν −
R R (µ ν) := 1 log χq(µ ν)+1 .
q k q 1 k
−
Additionally, the total variation distance between t(cid:0)he two measur(cid:1)es is given by
µ ν := sup µ(B) ν(B) ,
TV
k − k | − |
B
∈F
where is the set of all measurable subsets of Rd.
F
3 Covariance estimation using dependent samples
We state our primary assumption below.
Assumption 5. P is a reversible Markov kernel on Rd with stationary distribution π and spectral
gap λ (Definition 3). Let (X ,...,X ) be a sequence driven by P with initial distribution π = π.
1 N 0
Note thatthechoiceof π = π can beremoved atthecostof amultiplicative factor 1+χ2(π π)
0 0
k
in our failure probabilities (see Lemma 29).
The following result will be instrumental in establishing our covariance bounds.
Theorem 6 ([NSW23], Theorem 2.2). Under Assumption 5, suppose that F : Rd Rd d,3
i ×
→
for i [N] is a sequence of functions each mapping to real symmetric d d matrix satisfying
∈ ×
E [F ()] = 0, E [F2()] , and sup F () . For σ2 := N , it holds that
π i · k π i · k ≤ Vi Rd k i · k ≤ M i=1Vi
N t2/(32/P π2)
P F (X ) t d2 π/4exp ,
i i F ≥ ≤ − −α(λ)σ2 +β(λ) t
(cid:16)(cid:13)Xi=1 (cid:13) (cid:17) (cid:16) M (cid:17)
(cid:13) (cid:13)
where α(λ) = 2 λ
and(cid:13)
β(λ) =
8/π(cid:13)
.
−λ λ
When λ is some absolute constant bounded away from 0, the quantity in the exponential is
(min(t2/σ2,t/ )), i.e., quadratic for small t and linear for large t.
O M
As a corollary, we can deduce similar guarantees for vectors/non-square matrices (see §5.1).
Corollary 7. Under Assumption 5, suppose that E X = 0, E [ X 2] , and X
π i π i i i
k k ≤ V k k ≤ M
almost surely for i [N]. Then, denoting σ2 = N and where α,β are as in Theorem 6, the
∈
i=1Vi
following holds for all t 0,
≥ P
N t2/(32/π2)
P X t (d+1)2 π/4exp .
i ≥ ≤ − −α(λ)σ2 +β(λ) t
(cid:16)(cid:13) (cid:13)Xi=1 (cid:13) (cid:13) (cid:17) (cid:0) M (cid:1)
(cid:13) (cid:13)
3.1 Main results
Suppose our Markov chain is nice enough that the spectral gap is λ 0.99, which can always be
≥
done by composing a sufficient number of iterations of a more tractable chain with smaller spectral
gap. Then our estimators for the mean and covariance are respectively
N N N
1 1 1
X :=
N
X i, Σ :=
N
(X
i
−X) ⊗2 =
N
X i⊗2 −X⊗2 .
i=1 i=1 i=1
X X X
We state our covariance estimation results in both additive and multiplicative forms.
3This is valid even for arbitrary input state spaces, but thiswill not concern usin this work.
6Theorem 8 (Additive form). Under Assumption 5, if π also satisfies (PI) and P has a spectral
gap λ 0.99, the covariance estimator Σ = 1 N (X X) 2 satisfies that for any ε > 0 and
≥ N i=1 i − ⊗
δ (0,d), with probability at least 1 p/d,
∈ − P
Σ Σ εΣ+δI ,
d
| − |(cid:22)
so long as N trΣ+CPI(π) log2 dmax(d,CPI(π)+trΣ) log2d.
≍ εδ δ
One can establish multiplicative and spectral forms as well.
Theorem 9 (Multiplicative form). In the setting of Theorem 8, Σ satisfies that for any ε (0,1),
∈
with probability at least 1 p/d,
−
Σ Σ ε Σ
k − k≤ k k
so long as N d trΣ+CPI(π) log2 d(CPI(π)+trΣ) log2d.
≍ ε2 trΣ ε Σ
k k
Corollary 10 (Multiplicative form; spectral). In the setting of Theorem 8, Σ satisfies for any
ε (0,1), with probability at least 1 p/d,
∈ −
Σ Σ εΣ,
| − |(cid:22)
so long as N d+CPI(ν) log2 d(d+CPI(ν)) log2d, where ν := (Σ 1/2) π.
≍ ε2 ε − #
Remark 11 (Poincaré constant of ν). For ν = (Σ 1/2) π, it holds in general that C (ν)
− # PI
≤
λ 2C (π) for the smallest eigenvalue λ of Σ. In particular, it is well-known by [Kla23] that a
−1 PI 1
log-concave distribution π satisfies
Σ C (π) . Σ logd.
op PI op
k k ≤ k k
Remark 12 (Independent samples). As a corollary, we can obtain an analogous result when the
samples are independent by considering the case where the kernel P( x) = π identically. In this
·|
case, the spectral gap is 1, and the previous results can apply without alteration. As far as we
can tell, this is the first time that such a result has been explicitly presented for distributions
satisfying (PI), which may be of independent interest.
Proof sketch We sketch a proof for Theorem 8 below, deferring the detailed analysis to §5. In
our analysis, we show that the error can be divided into two terms
N
1
Σ Σ = (X µ) 2 Σ (X µ) 2.
i ⊗ ⊗
− N − − − −
i=1
X(cid:0) (cid:1)
The techniques we use for the mean and covariance error terms will be similar, so we shall concen-
trate on theargumentfor thefirstterm. We splitthisinto threesub-terms, similar to theargument
in [ALPTJ10], where B RN d will be some suitably “nice” set,
×
⊆
N N
1 1 1
X 2 Σ = (X 21 E[X 21 ])+ X 21 E[X 21 ] .
N
i⊗
− N
i⊗ B
−
i⊗ B
N
i⊗ Bc
−
⊗ Bc
i=1 i=1
X X X =:A
3
=:A
1
=:A
2 | {z }
Since the first term relates|to the conce{nztration of a}bou|nded{mzatrix}around its mean, it can
be handled using Theorem 6 after some detailed calculations (Lemma 35). As for the rest, we
would like to use a concentration inequality under (PI) to ensure that A ,A are small. While the
2 3
argument of [ALPTJ10] uses independence of the iterates to establish an exponential tail decay
of X , we are only able to establish a polynomial decay of X under Markovian assumptions
k k k k
(Lemma 36). This is sufficient for Theorem 8. Nonetheless, we also show a slightly improved tail
bound in §A, and it may be possible to sharpen this in the future.
74 Applications
4.1 Isotropic rounding via uniform sampling
As a first application, we consider a version of the “sampling-and-rounding” scheme used in
[JLLV21], and simplify analysis of their algorithm. This is summarized in the following problem,
which is a keystone in rounding schemes for general convex bodies (see Remark 19).
Problem 13. Let Rd be a well-rounded convex body containing a ball of radius 1 (i.e.,
K ⊂
B (0) and E [ 2] . d for the uniform distribution π over ). Can we find an algorithm
1 π
⊂ K k·k K
that makes c-isotropic for c 1 (i.e., c 1I Cov(π) cI ) using at most (d3) queries to the
− d d
K ≈ (cid:22) (cid:22) O
membership oracle4 of ?
K
e
We note that if we obtain the mean µ and covariance Σ of π, then the transformed convex body
Σ 1/2( µ) is isotropic (i.e., EX = 0 and E[X 2] = I ); this procedure is termed rounding. As
− ⊗ d
K−
elaborated in the sequel, it takes roughly d3 queries to get a single (approximately) uniform sample
from , and one needs roughly d independent samples in general to obtain an accurate estimator.
K
In the case where the samples are required to be i.i.d., it is inevitable that we pay d4 queries in
total, which would answer Problem 13 in the negative.
To circumvent this, an algorithm proposed by [JLLV21] repeats ‘sampling approximate
→
covariance estimation rounding’, which gradually isotropizes . We provide details of their
→ K
argument in §4.1.2, where we compare against our approach.
4.1.1 Algorithm
Uniform sampling by In-and-Out. [KVZ24] proposes In-and-Out, which is essentially the prox-
imal sampler for uniformly sampling from a convex body containing a ball of radius r. This
K
iterates two stepsforsomesuitableh r2/d2: (1) y (x ,hI )and(2) x (y ,hI ) ,
i+1 i d i+1 i+1 d
≍ ∼ N ∼ N |K
where the second step is implemented by rejection sampling with proposal z (y ,hI ).
i+1 d
∼ N
They show that from an (1)-warm start, In-and-Out iterates n = (qr 2d2C (π)polylog 1) =
O O − PI ε
(qr 2d2 Σ polylog 1) times to find a sample X with R (law(X ) π) ε, using (n) mem-
O − k kop ε n q n ek ≤ O
bership queries in expectation for success probability at least 1 δ. In particular, denoting by P
−
tehe Markov kernel of one iteration, they showed an exponential contraction of In-and-Ouet in χ2,
χ2(µ π)
χ2(µP π) k . (4.1)
k ≤ (1+h/C (π))2
PI
The spectral gap of this step is roughly lower bounded by Ω(hC 1) = Ω(r2d 2C 1). Therefore,
P−I − P−I
defining a new Markov kernel by P := Pn for n = (r 2d2C (π)), we can ensure that the spectral
− PI
O
gap of the new kernel P is at least 0.99. We denote In-and-Out (µ,ν,h) for the Markov chain with
N
kernel PN, initial distribution ν, and target distribution µ.
High-level description. Let π denote the uniform distribution over a convex body , and
K K
r := inrad( ) denote the radius of the largest ball contained in . Recall that In-and-Out needs
K K
roughly d2 Σ /r2 queries per sample from a warm start, which indicates that the mixing of the
op
k k
sampler suffers from the skewness of (i.e., how far Σ is from I ).
d
K
Algorithm 1, a modified version of [JLLV21, Algorithm 2], starts off by generating a warm
start via Gaussian cooling [KZ25] using d3 membership queries. Then it follows the sampling-and-
rounding scheme as described earlier, initialized at this warm start. It draws r2 many samples
4A membership oracle for K answers YES or NO to the queryof the form “x∈K”?
8to get a rough estimate of the covariance up to a d-additive error (i.e., Σ Σ dI ), using
d
| − | (cid:22)
r2 d2 Σ /r2 = d2 Σ queries in total. Then, the subspace corresponding to eigenvalues of the
op op
· k k k k
covariance Σ that are smaller than d is doubled, which almost doubles inrad( ) as well. Hence,
K
even though the algorithm requires nearly four times as many samples in the next iteration, this
increase is exactly balanced by the reduced query complexity per sample. This is repeated until
r2 reaches roughly d, which implies that the total number of iterations is (logd), since r almost
O
doubles every iteration. Furthermore, the largest eigenvalue of the covariance, Σ , increases at
op
k k
most roughly by d every iteration. Since the operator norm of the initial covariance is at most d,
the largest eigenvalue remains (d) throughout. Thus, the total query complexity per iteration is
O
(d3); the query complexity of the algorithm is the same with only a logarithmic overhead.
O
In the algorithm, let π denoete π , and Σ be its covariance.
e
i Ki i
Algorithm 1 Isotropize
Input: convex body Rd and T
1
Rd ×d such that
1
:= T
1
satisfies 1/4 inrad( 1) and
K ⊂ ∈ K K ≤ K
E [ 2] C2d for constant C > 0.
πK
1 k·k ≤
Output: (µ,Σ 1/2).
−
1 2:
:
R Leu tn rG 1a =us 1s /bia 4n
,b
πco 1o :l =ing πto 1,o ab nt dai in =X 10
.∈
K1 with R ∞(law(X 0) kπ K1)
≤
log2.
3: while r2 d dK o
i ≤ 210log4d
4: Set k i = 10cr i2C2log6C2d for some universal constant c.
5: Draw {X j }j ∈[ki] ← In-and-Out Ni π i,δ X0, 210d2lor gi2 (Ccrid) with N i = 210C2d3 r i2log(Ccd) .
6: Compute µ i = k1
i
k j=i 1X j and Σ(cid:0) i = k1
i
k j=i 1(X j −µ i)(cid:1) ⊗2.
7: Compute M i = I dP+P i, where P i is th Pe orthogonal projection to the subspace spanned by
eigenvectobrs of Σ with eigenvalbue at most d. b
i
8: Set T i+1 = M iT i, i+1 = M i i, X 0 M iX 0, r i+1 = 2r i(1 1/logd), and i i+1.
K K ← − ←
9: end while b
10: Draw c ′dlog6d outputs from In-and-Out N(π i,δ X0, 220dlog1 (Ccrid)) with N i = 220C2d2log5(Ccd)
(for some universal constant c), and use them to compute the mean µ and covariance Σ.
′
b b
4.1.2 Comparison between approaches
[JLLV21] used Ball walk (implemented using Speedy walk, followed by a rejection step) started
at an initial distribution µ, whose query complexity for obtaining a ε-close sample (to π) in TV
is (Md2ψ2 log (1) 1), where M = sup µ is a warmness parameter, and ψ is defined by
ψ
O
1 =
infKLS O π+(Sε
) . As for the
apK prπ
oximate covariance estimation,
theK yLS
took the same
K−LS S Rd π(S) π(Sc)
approach as u⊂ s; they∧draw a few samples to detect a subspaceof small eigenvalues of the covariance
matrix, followed by the upscaling of this ‘skewed’ subspace.
When drawing samples used for a covariance estimation, they generate an (1)-warm sample
O
and then initialize several parallel independent threads of Ball walk, with the warm sample used
as an initial distribution. Therefore, these ε-accurate samples are independent conditioned on
the warm sample, but still dependent overall. Then, they rely on a covariance estimation lemma
assumingindependence of these samples,justifyingtheirargumentviaareferencetoµ-independence
(also known as the α-mixing in the statistic literature). They mention that with probability 1 δ,
−
this procedure, iterated (log 1) more times, can succeed in estimating the covariance. We refer
O δ
interested readers to their paper [JLLV21, Computational Model], which references [LV06b, §3.2].
We introduce two main changes to their approach – (1) we take sequential samples instead
9of maintaining several independent threads and (2) we use In-and-Out instead of Ball walk. We
believe this is more principled in that the query complexity (Md2C (π)log (1) 1) of In-and-Out
O PI O ε
neededforconvergence inχ2 hasadirectconnection tothePoincaréconstant C (π)of theuniform
PI
distribution. Thus, if we take (d2C (π)) iterations of In-and-Out as a single iteration of a new
PI
O
Markov chain, then it immediately follows that the spectral gap of the new chain can be made at
least 0.99 (or any constant as close to 1 as desired). This allows us to use our result developed
in §3, streamlining analysis for statistical estimation using dependent samples. In addition to this,
by incorporating the recent improvement of C (π) [Kla23] (or equivalently ψ2 ) from do(1) Σ
PI KLS k kop
to Σ logd, we bypass the anisotropic KLS bound developed in [JLLV21]. Combining all these
op
k k
changes streamlines our analysis significantly.
4.1.3 Analysis
We analyze each algorithmic component under the event that all the previous subroutines succeed.
All the proofs for this section are deferred to §6.1.
(1) Guarantees of the sampler. First,weensurethatIn-and-OutindeedsatisfiesAssumption5,
which is a consequence of the convergence rates established in earlier work [KVZ24].
Lemma 14. In-and-Out Ni(π i, ·, 210d2lor gi2 (Ccrid)) with N
i
= 210C2d3r i−2logd has a spectral gap of at
least 0.99 (or any desired constant approaching 1).
We present a version of Theorem 8 tailored to this application. Its proof essentially follows
that of Theorem 8, using the spectral-gap condition of In-and-Out and the fact that the initial
distribution law(X ) is close to π (see Line 1).
0 1
Lemma 15. There exists a universal constant c > 0 such that when In-and-Out successfully
Ni
iterates without failure, each while-loop ensures that with probability at least 1 p/d
−
9 d 11 d
Σ I Σ Σ + I if N cd 1trΣ log6C2d.
i d i i d − i
10 − 100 (cid:22) (cid:22) 10 100 ≥
Leveraging this, we can applybour Markovian covariance estimation machinery in the form of
Corollary 10 to obtain a covariance concentration bound for Line 10.
(2) Control over trace and operator norm. The following lemma establishes quantitative
control over changes of the trace and operator norm of the covariance Σ at each iteration. We
i
present a simpler proof of [JLLV21, Lemma 3.1], bypassing the need for an anisotropic KLS bound.
Lemma 16 (Control over covariance). The while-loop iterates at most 2logd times. Also,
1. Σ = trΣ 10r2C2d.
k i k1 i ≤ i
2. Σ d(C2+6i).
i op
k k ≤
Lastly, we prove that the inner radius inrad( ) almost doubles every iteration, providing a
i
K
rigorous proof of [JLLV21, Lemma 3.2].
Lemma 17 (Control over inrad). Under r
i+1
= 2(1 1/logd)r i, each while-loop ensures r
i
− ≤
inrad( ).
i
K
Putting all of the aforementioned results together, we conclude that Algorithm 1 returns µ and
Σ such that Σ 1/2( µ) is nearly isotropic with high probability.
−
K−
b
b b b
10Lemma 18. Algorithm 1 returns (µ,Σ) such that Σ 1/2( µ) is 2-isotropic with probability at
−
K−
least 1 p/√d, using (C4d3) membership queries in expectation.
− O
b b b b
Remark 19 (Generael bodies). Now we can design a rounding algorithm with roughly d3.5 query
complexity for a general convex body containing a unit ball, which combines Algorithm 1 with the
annealing algorithm in [JLLV21]. Given a well-rounded uniform distribution over T( B (0)) for
r
K∩
some r 1 and affine map T : Rd d Rd, Algorithm 1 will find a new affine map T such that
× ′
≥ →
T ( B (0)) is nearly isotropic with high probability. The annealing algorithm then moves to
′ r
K ∩
the uniform distribution over T ( B (0)), which can be shown to be well-rounded by
′
K ∩
r(1+d−1/2)
[JLLV24, Lemma 3.4]. This annealing algorithm begins with a ball of radius r = 1 (which is surely
well-rounded) and repeats the procedure above until the radius reaches the diameter D of . The
K
total number of iterations for this annealing procedure is d1/2logD. Multiplying by the complexity
of Algorithm 1, we find that the total complexity of the entire rounding algorithm is (d3.5logD).
O
e
4.2 Covariance estimation in unconstrained sampling
In a similar vein, we state and prove a guarantee for covariance estimation when the target is an
unconstrained distribution satisfying a Poincaré inequality. Briefly, we note that the analysis of
Proximal sampler (for which In-and-Out is the constrained equivalent) elegantly relates the mixing
of the sampler in various divergences to the isoperimetric constants of the target π; in particular,
there is a fundamental relationship between the Poincaré constant of π and the mixing rate in χ2.
The Proximal sampler for unconstrained distributions. Below, we recall the Proximal sampler
when sampling from an unconstrained distribution π exp( V). Proximal sampler iterates, for
∝ −
some step size h > 0: (Forward) y (x ,hI ) and (Backward) x Q ( y ), where Q
i+1 i d i+1 h i+1 h
∼ N ∼ ·|
has density
1
Q ( y ) exp V() y 2 .
h i+1 i+1
·| ∝ − · − 2h k·− k
Similar to In-and-Out, this procedure can be(cid:0) seen as Gibbs sampling(cid:1) . However, unlike In-and-Out,
the implementation of the reverse step is not straightforward and requires some additional effort.
For their state-of-the-art result, the full methodology of [AC24] uses a composite algorithm
to (approximately) implement the backwards step. The composite algorithm consists of (1) the
Metropolis adjusted Langevin algorithm (MALA), a high-accuracy sampler which performs well
when given a warm start, and (2) the low-accuracy underdamped Langevin Monte Carlo (ULMC)
sampler in order to generate that warm start. We do not explicitly give the construction of this
proposal in this work, and invite the reader to peruse [AC24] for additional details.
An important detail is that this only generates approximate samples from the distribution Q
h
of the backwards step, with some chosen error tolerance ̺ so that the final output is close to Q .
h
We refer to thecomposition of theexact forward kernelwith the inexact reverse kernel as Pˆ . The
h,̺
overall methodology is summarized in Algorithm 2.
Finally, we note that the approximate kernels used at different steps are allowed to be different,
andtheuseris freetochoosetheerrortolerance ateach stepsothattheirfinalguarantee issuitably
strong. For notational simplicity, we assume that the error tolerances do not differ from step to
step.
Results. In this setting, we will primarily operate with the following standard assumptions.
Assumption 20. The target distribution π exp( V) satisfies (PI) and V is β-smooth;
∝ −
V(x) V(y) β x y for all x,y Rd.
k∇ −∇ k ≤ k − k ∈
11Algorithm 2 Covariance estimation in the unconstrained setting
Input: π exp( V) (Rd) such that V is β-smooth and C (π) < , target error ε> 0.
2 PI
∝ − ∈ P ∞
Output: (µˆ,Σˆ).
1: Let K = cK ε2dφ log2 d εφ log4d, h = 21 β, n 0 = c n0κ(d ∨β)log(κd), n = c nκ, ̺ = c̺(Kn d+n0) , where
c ,c ,c ,c are all positive universal constants, Σ = Cov(π),φ := trΣ+CPI(π) , κ := βC (π).
K n0 n ̺ trΣ PI
2: Obtain X 0 (0,β −1I d).
∼ N
3: for j [K] do
∈
4: Draw X j
∼
δ Xj−1Pˆ hn ,̺.
5: end for
6: Compute the sample mean and covariance µˆ
←
K1 K j=1X j, Σˆ
←
K1 K j=1(X j −µˆ) ⊗2.
P P
For instance, when π exp( 1+ x 2), we have by [Bob03] that C (π) = (d). The
PI
∝ − k k O
perturbation principle of Holley and Stroock [HS87] also states that for π˜ exp( V +f), where
p ∝ −
f < and V is everywhere finite, a Poincaré inequality continues to hold for π˜ with constant
k k∞ ∞
depending on f . In the sequel, we will denote the “condition number” by κ := C (π)β, which
PI
k k∞
recovers the standard condition number β/α when π is α-strongly log-concave.
Lemma 21 ([CCSW22], Theorem 4). Suppose π satisfies Assumption 20. Let P be the Markov
h
kernel corresponding to Proximal sampler with stationary measure π (Rd) and step size h. Then,
∈ P
P satisfies, for any initial measure µ (Rd)
h
∈ P
χ2(µ π)
χ2(µP π) k .
h k ≤ (1+h/C (π))2
PI
In the sequel, we will also impose the following standard oracle model.
Assumption 22. Assume that we have access to oracles for V, V, and also that we have ac-
∇
cess to the proximal oracle with step size h = 1/2β for V, which given a point y Rd returns
∈
argmin V(x)+ 1 x y 2 .
x ∈Rd { 2hk − k }
Remark 23. The proximal oracle is not strictly necessary, and can be removed by following the
same techniques as [AC24], at the possible cost of additional polylogarithms in the bound.
In this section, when we speak about expected query complexity, we are referring to the sum
total of queries either to oracles for V, V or to the proximal oracle given above. Hereafter we will
∇
also suppress the subscripts for h,̺ in the kernel, as these remain fixed throughout the algorithm.
The query complexity guarantees from [AC24] are summarized below.
Lemma 24 (Adapted from [AC24, Theorem D.1]). In the setting of Lemma 21, under Assump-
tions 20 and 22, there exists an algorithm which, given any initial point x Rd, returns a
∈
point z δ xPˆ, with KL(δ xPˆ δ xP) ̺ for any ̺ (0,1/2]. Its expected query complexity is
∼ k ≤ ∈
N = d1/2log3 1 .
O ̺
(cid:0) (cid:1)
Remaerk 25. Due to its reliance on an inexact implementation of the proximal sampler, we do
not know if the algorithm can be written in the form of a kernel possessing a spectral gap. As a
result, we cannot apply Theorem 9 directly to this algorithm. Nonetheless, the error guarantees
are sufficient to retain the concentration results developed in this work.
We can now convert this error into a total variation bound on the entire chain, as below.
12Lemma 26. In the setting of Lemma 24, set ν = µ Pn0 and νˆ = µ Pˆn0 for any initialization µ
0 0 0
and n
0
∈
N, where ̺
≍
δ/(Kκ+n0) is chosen in Lemma 24, and K
∈
N. For n = O(κ), let ν 1:K,νˆ
1:K
be the joint laws of K iterates drawn from Markov chains with initial distributions ν,νˆ and kernels
Pn,Pˆn respectively. Then, for a given δ (0,1/2], we can guarantee that ν
1:K
νˆ
1:K TV
δ. The
∈ k − k ≤
expected query complexity of implementing the chain corresponding to νˆ is
1:K
K n
N = n d1/2log3 + Kκd1/2log3 0 .
0
O δ O δ
(cid:0) (cid:1) (cid:0) (cid:1)
We will take δ 1/d. Lemmea 21 suggests that wee set n
0
= κlogχ2(µ
0
π), and so we need
≍ k
(κd1/2logχ2(µ π)polylogK) queries to obtain a sample whose law is (1)-close to π in χ2-
0
O k O
divergence. Under standard assumptions (Lemma 39), logχ2(µ π) (d β), so this complexity
0
k ≍ O ∨
weould be (κd1/2(d β)). For therequisite K independent samples, we repeat the whole procedure
O ∨
fromscratch, expecting (κd1/2(d β)polylog(K+n ))queriespersampeletoconstructanaccurate
0
O ∨
covarianceeestimate.
Incontrast, afterusineg (κd1/2(d β)polylogK)queriestoobtainawarmsample, anestimator
O ∨
based on Markovian iterates needs (κd1/2polylog(K +n )) for each further sample.
0
O
e
Theorem 27 (Covariance estimation in unconstrained sampling). In addition to Assumptions 20
e
and 22, assume that V(0) minV . d, E = poly(κ,d), and V(0) = 0. We then have with
π
− k·k ∇
probability 1 p/d that the matrix obtained by Algorithm 2 satisfies
−
Σˆ Σ ε Σ .
op op
k − k ≤ k k
In particular, the total query complexity is bounded in expectation as
φ κd3/2φ
N = max κd1/2(d β)log3 , .
O ∨ ε ε2
(cid:0) (cid:8) (cid:9)(cid:1)
e κd3/2(d β)φ
Remark 28. It can be seen that using d i.i.d. samples would require O( ε2∨ ) queries in
expectation. Thisisalwaysworsethantherateabovebyafactorofatleastd. NotethatTheorem27
alsoimpliesaconcentration resultforthemean,andasimilarproofwillyieledguarantees resembling
that of Theorem 8, albeit with additional terms in the query complexity.
5 Details for the main results
5.1 Matrix Bernstein inequality under spectral gap of a Markov chain
Proof of Corollary 7. We deduce this from Theorem 6. Consider the matrix
0 XT
F(X ) := i .
i X 0
" i d d #
×
Clearly, E[F(X )] = 0. Next, its operator norm is bounded as follows: for (v,w) R Rd with
j
∈ ×
(v,w) = 1,
k k
F(X ) = 2 sup vXTw 2sup v w X X ,
k j k j ≤ | |k kk j k ≤ k j k ≤ M
(v,w) =1
k k
and the supremum is achieved by v = 1/√2 and w = X /(√2 X ). Also, observe that
j j
k k
E[ X 2] 0
E[F(X )2] = k j k E[ X 2] I ,
j " 0 E[X jX jT] # (cid:22) k j k · d+1
13wheretheinequality followsfromE[X XT] E[ X 2] I . Therefore, E[F(X )2 E[ X 2] .
j j (cid:22) k j k · d k j k≤ k j k ≤ V
Noting that the operator norm of
n 0 XT
F(X ) = j
j
X 0
j=1 " j P #
X
P
is X , and using Theorem 6,
j
k k
P n n t2/(32/π2)
P X
j ≥
t = P F(X j)
≥
t
≤
(d+1)2 −π/4exp α(λ−
)σ2 +β(λ) t
,
(cid:16)(cid:13)j X=1 (cid:13) (cid:17) (cid:16)(cid:13)j X=1 (cid:13) (cid:17) (cid:16) M (cid:17)
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13) (cid:13) (cid:13) (cid:13)
which completes the proof.
The following lemma allows us to perform most of our calculations at stationarity, paying only
a small overhead.
Lemma 29 (Change of measure). Suppose a Markov chain with kernel P starts from ν instead of
the stationary measure π. Then, the probability of aneventhasamultiplicative factor of 1+χ2(ν π).
k
Proof. Let A be the bad event we want to bound. Let us denote π := law(s ,...,s ) for s π
1:n 1 n 1
∼
and ν := law(s ,...,s ) for s ν, where s P( s ). Then,
1:n 1 n 1 i+1 i
∼ ∼ ·|
dν
ν (A) = 1 dν = 1 1:n dπ 1+χ2(ν π ) π (A).
1:n A 1:n A 1:n 1:n 1:n 1:n
dπ ≤ k ·
Z Z 1:n
(cid:0) (cid:1)
Note that
ν 2 ν 2 ν 2
1+χ2(ν 1:n kπ 1:n)=
Z
(cid:16)π1 1: :n
n (cid:17)
dπ 1:n =
Z Z
(cid:16)π1 1: :n n− −1
1 (cid:17)
(cid:16)πn n| |− −n
n (cid:17)
dπ n |−ndπ 1:n −1
ν 2 ν 2
1:n 1 nn 1
= − | − dπ nn 1dπ 1:n 1
(i) Z Z (cid:16)π 1:n −1 (cid:17) (cid:16)π n |n −1 (cid:17) | − −
ν 2
1:n 1
= − dπ 1:n 1
(ii) Z (cid:16)π 1:n −1 (cid:17) −
ν 2
= 1 dπ = 1+χ2(ν π ),
1 1 1
(iii) Z (cid:16)π 1 (cid:17) k
where (i) follows from P being a Markov chain, (ii) follows from ν = π , and (iii) follows
nn 1 nn 1
| − | −
from induction.
5.2 Moments under Poincaré
We can establish concentration of the target measure around its mean.
Lemma 30. Suppose that π (Rd) satisfies (PI). Then, letting µ Rd denote the mean of π,
∈ P ∈
for all t 1 we have
≥
trΣ
P( X µ t√trΣ) exp (t 1) 1/2 .
k − k≥ ≤ − − C (π)
PI
(cid:16) (cid:0) (cid:1) (cid:17)
14Proof. Wenotethatf(x) = x µ is1-Lipschitz. Hence,itfollowsfromtheLipschitzconcentration
k − k
property in (2.1) that for all t 0,
≥
t
P( X µ t+E X µ ) 3exp .
k − k ≥ k − k ≤ − C (π)
PI
(cid:0) (cid:1)
Since E X µ (E[ X µ 2)1/2 = √trΣ, we can deduce thap t
k − k≤ k − k
t
P( X µ t+√trΣ) 3exp ,
k − k≥ ≤ − C (π)
PI
(cid:0) (cid:1)
which completes the proof. p
One can also bound the fourth-moment under the Poincaré inequality:
Lemma 31. Suppose that π (Rd) satisfies (PI). Then,
∈ P
E[ X µ 4] (4C (π)+trΣ)trΣ.
PI
k − k ≤
Proof. Let us assume that µ = 0 by translation. Taking f(x) := x 2 in (PI), we have from
k k
f(x)= 2x and E[ X 2]= trΣ that
∇ k k
E[ X 4] 4C (π)E[ X 2]+(E[ X 2])2 =trΣ(4C (π)+trΣ).
PI PI
k k ≤ k k k k
5.3 Proof details
5.3.1 Mean estimation
Theproofofthemeanestimation resultclosely mirrorsthatofthesucceedingcovariance estimation
bound.
Lemma 32. Under Assumption 5, if λ 0.99, then with probability at least 1 p/d we have that
≥ −
for any ε (0,d),
∈
X µ 2 ε,
k − k ≤
so long as N trΣ+CPI(π) log2 dmax(d,trΣ) log2d.
≍ ε ε
Proof. By translation, we may assume that π is centered (i.e., µ = E X = 0). Let B := x Rd :
π t
{ ∈
x t√trΣ , where t > 0 are parameters to be determined, and we drop the subscript t where
k k ≤ }
there is no confusion. Then, we have the following decomposition:
1 1 1
X = (X 1 E[X 1 ])+ X 1 E[X1 ] .
i i B i B i Bc Bc
N N − N −
X X
=:B
1
X
=:B
2
=:B
3
| {z }
Term B : As for this term,| we essentia{ llz y work with} th| e trun{z cated} variables X 1 . Let F (X )=
1 i B i i
1(X 1 E[X 1 ]) for some parameter λ> 0. Clearly, E[F (X )]= 0, and
N i B − i B i i
1 1 2
F (X ) X 1 + E X 1 t√trΣ.
i i i B i B
k k ≤ Nk k N k k ≤ N
For the variance, using the identity (a+b)2 2(a2 +b2) for a,b R,
≤ ∈
2 2
E[ F (X ) 2] E[ X 1 2]+ E[X 1 ] 2
k i i k ≤ N2 k i B k N2k i B k
154 4t2trΣ
E[ X 1 2] .
≤ N2 k i B k ≤ N2
Hence, we can substitute = 2t√trΣ, = 4t2trΣ, and σ2 = 4t2trΣ into Corollary 7, finding that
M N Vi N2 N
for α(λ) = 2 λ and β(λ) = 8/π ,
−λ λ
1 N π2ℓ2/32
P X 1 E[X 1 ] ℓ (d+1)2 π/4exp .
N i B − i B ≥ ≤ − −α(λ)σ2 +β(λ) ℓ
(cid:16)(cid:13) Xi=1 (cid:13) (cid:17) (cid:16) M (cid:17)
(cid:13) (cid:13)
(cid:13) (cid:13)
Since α(λ) and β(λ) are absolute constants, we have that with probability 1 p/d,
−
1 N t√trΣlogd
X 1 E[X 1 ] . ( +σ)logd . .
i B i B
N − M √N
(cid:13) Xi=1 (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
Terms B and B : As for B , we use Markov’s inequality,
2 3 2
1 1 1
P X 1 sE X 1 for any s > 0.
i Bc i Bc
N ≥ N ≤ s
(cid:16)(cid:13) X (cid:13) h(cid:13) X (cid:13)i(cid:17)
(cid:13) (cid:13) (cid:13) (cid:13)
Using Lemma 30 fo(cid:13)r t 2 in the(cid:13)second l(cid:13)ast line below(cid:13),
≥
N
1 1
E X 1 E X 1 = E [ X 1 ] E[ X 2] P( X t√trΣ)
i Bc i Bc π Bc
N ≤ N k k k k ≤ k k k k ≥
h(cid:13) X (cid:13)i h Xi=1 i q q
(cid:13) (cid:13)
(cid:13) (cid:13) 3√trΣ exp (t −1)√trΣ 3√trΣexp t trΣ 1/2 .
≤ · − C PI(π) ≤ −2 C PI(π)
(cid:16) (cid:17) (cid:16) (cid:0) (cid:1) (cid:17)
This bounds the norm of Term B as well bypthe same argument, since
3
t trΣ
E[X1 ] E[ X 1 ] 3√trΣexp 1/2 .
Bc Bc
k k ≤ k k ≤ −2 C (π)
PI
(cid:16) (cid:0) (cid:1) (cid:17)
Combining all bounds on the three terms, it follows that with probability 1 p/s p/d,
− −
1 N t√trΣlogd t trΣ
X . +(s+1)√trΣexp 1/2 .
i
N √N −2 C PI(π)
(cid:13) (cid:13) Xi=1 (cid:13) (cid:13) (cid:16) (cid:0) (cid:1) (cid:17)
(cid:13) (cid:13)
Taking s = 8d and t (trΣ+CPI(π) )1/2log dmax(d,trΣ) , we have
≍ trΣ ε
1 N trΣ+C (π) d2trΣ
X . ε1/2+ PI 1/2 logdlog .
i
N N ε
(cid:13)
(cid:13)
Xi=1 (cid:13)
(cid:13) (cid:0) (cid:1)
(cid:13) (cid:13)
Therefore, it suffices to take N trΣ+CPI(π) log2dlog2 dmax(d,trΣ) and then revert the translation
≍ ε ε
for centering.
For the multiplicative version, we can just work with the relative error ε Σ in place of ε.
op
k k
Corollary 33. Under Assumption 5, if λ 0.99, then with probability at least 1 p/d we have that
≥ −
for any ε (0,d),
∈
X µ 2 ε Σ ,
op
k − k ≤ k k
so long as N d(1 CPI(π) log2 d)log2d.
≍ ε ∨ trΣ ε
165.3.2 Covariance estimation
Additive version. Weextend[JLLV21,LemmaA.2],provenforindependentsamplesdistributed
according to any log-concave distribution. The following lemma contains the bound for the covari-
ance part of our problem.
Lemma 34. Under Assumption 5, if λ 0.99, then with probability at least 1 p/d we have
≥ −
1
(X µ) 2 Σ εΣ+δI
i ⊗
N − − (cid:22)
(cid:12) X (cid:12)
so long as N trΣ+CPI(π) log2 dm(cid:12) (cid:12) ax(d,CPI(π)+trΣ) log2d.(cid:12) (cid:12)
≍ εδ δ
In the analysis, we can make π centered (i.e., µ = 0) by translation and work with a truncated
region B ρ,t := x Rd : x (ρΣ+I)−1 t√trΣ with t and ρ to be determined; we again suppress
{ ∈ k k ≤ }
the subscripts. Recall from §3 that we have the following decomposition:
1 1 1
X 2 Σ = (X 21 E[X 21 ])+ X 21 E[X 21 ] .
N
i⊗
− N
i⊗ B
−
i⊗ B
N
i⊗ Bc
−
⊗ Bc
X X
=:A
1
X
=:A
2
=:A
3
| {z }
We now bound each term se|parately. {z } | {z }
Lemma 35 (Term A 1). With probability at least 1 p/d, for t 2,
− ≥
1 t2trΣlog2d
(X 21 E[X 21 ]) εΣ+ I.
N
i⊗ B
−
i⊗ B
(cid:22) O εN
Proof. We use Theor(cid:12) (cid:12) (cid:12)emX 6, setting F i(X i) = N1(ρΣ(cid:12) (cid:12) (cid:12) +I) −1/2(X(cid:0) i⊗21 B −E[X(cid:1) i⊗21 B])(ρΣ+I) −1/2 for
i [N]. We will only use the guarantees of Theorem 6 in the form of boundson the operator norm,
∈
since this will suffice for our purposes. Denoting X 2/(ρΣ+I) := (ρΣ+I) 1/2X 2(ρΣ+I) 1/2,
i⊗ − i⊗ −
we have
1 X 2 1 X 2
F (X ) B i⊗ + E i⊗ 1
i i B
k k ≤ N ρΣ+I N ρΣ+I
(cid:13) (cid:13) h(cid:13) (cid:13) i
1 (cid:13) (cid:13) (cid:13)1 (cid:13)
= (cid:13)X 2 (cid:13) 1 +(cid:13) E[ X(cid:13)2 1 ]
Nk
i k(ρΣ+I)−1 B
N k
i k(ρΣ+I)−1 B
2
t2trΣ,
≤ N
where the last line follows from the definition of B. Hence, we set = 2t2trΣ/N in the theorem.
M
As for the variance,
2 X 2 2 X 2
E[F (X )2] E i⊗ 21 + E i⊗ 1 2
i i (cid:22) N2 ρΣ+I B N2 ρΣ+I B
(i)
(cid:2)(cid:0) (cid:1) (cid:3) (cid:0) (cid:2) (cid:3)(cid:1)
2 X 2 2 X 2 X 2
E X 2 i⊗ 1 + E i⊗ 1 E i⊗ 1
(cid:22) N2 k i k(ρΣ+I)−1ρΣ+I B N2 ρΣ+I B ρΣ+I B
(ii)
(cid:2) (cid:3) (cid:13) (cid:2) (cid:3)(cid:13) (cid:2) (cid:3)
2t2trΣ Σ 2t2trΣ Σ (cid:13)2 Σ (cid:13)
+ = M ,
(cid:22) N2 ρΣ+I N2 ρΣ+I N ρΣ+I
(iii)
where in (i) we used (A B)2 2(A2 +B2) for matrices A and B, in (ii) used A2 A A for a
− (cid:22) (cid:22) k k
positive semidefinite matrix A, and (iii) follows from E[X 2]= Σ and the definition of B. Hence,
i⊗
2 Σ
E[F (X )2] M ,
i i
k k ≤ N ρΣ+I
(cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13) (cid:13)
17so we can set = 2 Σ/(ρΣ+I) /N and σ2 = 2 Σ/(ρΣ+I) .
i
V Mk k Mk k
Using Theorem 6 with α(λ),β(λ) = (1), we have
O
1
P (ρΣ+I) 1/2 (X 21 E[X 21 ])(ρΣ+I) 1/2 ℓ
N
− i⊗ B
−
i⊗ B −
≥
(cid:16)(cid:13)
(cid:13)
X ℓ2/(32/π2) (cid:13)
(cid:13)
(cid:17)
(cid:13) d2 π/4exp . (cid:13)
−
≤ −α(λ)σ2 +β(λ) ℓ
(cid:16) M (cid:17)
Hence, with probability at least 1 p/d, using Young’s inequality with any c > 0,
−
Σ
(ρΣ+I) 1/2A (ρΣ+I) 1/2 . ( +σ)logd + 2 logd
− 1 −
k k M ≤ M s M ρΣ+I
(cid:16) (cid:13) (cid:13)(cid:17)
1 Σ (cid:13) (cid:13)
. (1+c) + log(cid:13)d (cid:13)
M c ρΣ+I
(cid:16) (cid:13) (cid:13)(cid:17)
t2trΣ (cid:13) 1 (cid:13)
(1+c) +(cid:13) log(cid:13)d
≤ N cρ
(cid:0) (cid:1)
Therefore, with probability at least 1 p/d,
−
t2trΣ 1
A - (1+c) + logd (ρΣ+I).
1
N cρ ·
(cid:0) (cid:1)
By solving logd = ε and ct2trΣ = 1 for c and ρ, there exist multiples of c and ρ such that
c N cρ
t2trΣlog2d
A εΣ+ I.
1
(cid:22) O εN
(cid:0) (cid:1)
Under the same event, we also have A εΣ+
(t2trΣlog2d)I
in a similar manner.
− 1 (cid:22) O εN
Lemma 36 (Term A
2
and A 3). For s > 0 and t 2, with probability at least 1 p/s,
≥ −
1 t trΣ
X 21 sE[X 21 ] 3s 4C (π)+trΣ trΣexp 1/2 .
N
i⊗ Bc
≤
⊗ Bc
≤
PI
−2 C (π)
PI
(cid:13) (cid:13) X (cid:13) (cid:13) q (cid:0) (cid:1) (cid:16) (cid:0) (cid:1) (cid:17)
Proof. U(cid:13)sing Markov’s(cid:13)inequality, we have
1 1 1
P X 21 sE X 21 for any s > 0.
N
i⊗ Bc
≥ N
i⊗ Bc
≤ s
(cid:16)(cid:13) X (cid:13) h(cid:13) X (cid:13)i(cid:17)
(cid:13) (cid:13) (cid:13) (cid:13)
The expectation c(cid:13)an be bounded(cid:13)by (cid:13) (cid:13)
1 1
E X 21 E X 21 = E[ X 21 ]
N
i⊗ Bc
≤ N k
i
k
Bc
k k
Bc
h(cid:13) X (cid:13)i h Xi i
(cid:13) (cid:13)
(cid:13) (cid:13) E[ X 4] P X t√trΣ
≤ k k k k ≥
q q (cid:0) (cid:1) t trΣ 1/2
3 4C (π)+trΣ trΣexp for any t 2,
PI
≤ −2 C (π) ≥
PI
q (cid:0) (cid:1) (cid:16) (cid:0) (cid:1) (cid:17)
wheretheboundsonthefirstandthesecondtermfollowfromLemma31andLemma30respectively.
Since A = E[X 21 ] E[ X 21 ], it is also bounded by the last bound above.
3 ⊗ Bc Bc
k k k k ≤ k k
18Proof of Lemma 34. Putting these bounds together with s= d, with probability at least 1 p/d,
−
1 t2trΣlog2d t trΣ
X 2 Σ εΣ+ +d C (π)+trΣ exp 1/2 I.
N
i⊗
− (cid:22) O εN
PI
−2 C (π)
PI
(cid:12) (cid:12) X (cid:12) (cid:12) (cid:16) (cid:0) (cid:1) (cid:16) (cid:0) (cid:1) (cid:17)(cid:17)
(cid:12) (cid:12) =:(#)
By setting t 2(trΣ+CPI(π) )1/2log dmax(d,CPI(π)+trΣ|) , we can make (#{ )z . δ. The claim th} en follows
≍ trΣ δ
by taking
trΣ+C (π) dmax(d,C (π)+trΣ)
N PI log2 PI log2d,
≍ εδ δ
which completes the proof.
Proof of Theorem 8. Consider Σ = 1 (X µ) 2 = 1 X 2 XµT µXT +µµT, where µ
′ N i i − ⊗ N i i⊗ − −
is the true mean E X. Now, we have
π P P
N N
Σ −Σ
′
= N1 X i⊗2 −X⊗2
−
N1 X i⊗2 −XµT −µXT +µµT = −(X −µ) ⊗2.
Xi=1 (cid:16) Xi=1 (cid:17)
For the true covariance Σ = E[X 2] µ 2, observe that
⊗ ⊗
−
N
1
Σ Σ = Σ Σ +Σ Σ = (X µ) 2 Σ (X µ) 2 .
′ ′ i ⊗ ⊗
− − − N − − − −
i=1
X(cid:0) (cid:1) =:B
=:A
| {z }
It suffices therefore to separately control t|he error f{ozr the cent}red covariance estimator in A
(Lemma 34), and the mean estimation error in B (Lemma 32).
The theorem then follows immediately upon combining Lemma 32 and 34.
Multiplicative version. The proof of this version is similar in overall with the previous one,
proceeding with a truncated region B := x Rd : x t√trΣ instead of B .
t ρ,t
{ ∈ k k ≤ }
Lemma 37. Under Assumption 5, if λ 0.99, then with probability at least 1 p/d we have
≥ −
1
X 2 Σ ε Σ
N
i⊗
− ≤ k k
(cid:13) X (cid:13)
so long as N d trΣ+CPI(π) log2 d(C(cid:13) (cid:13)PI(π)+trΣ) log2d. (cid:13) (cid:13)
≍ ε2 trΣ ε Σ
k k
Proof. Following the proof of Lemma 35 with ρ= 0, we have that with probability at least 1 p/d,
−
using Young’s inequality with c= logd,
ε
t2trΣ 1 t2trΣlog2d
A . (1+c) + Σ logd ε Σ + .
1
k k N c k k ≤ k k εN
(cid:0) (cid:1)
Combining this with the bounds for terms A and A in Lemma 36, it follows that
2 3
1 t2trΣlog2d t trΣ
X 2 Σ . ε Σ + +d C (π)+trΣ exp 1/2 .
N
i⊗
− k k εN
PI
−2 C (π)
PI
(cid:13) (cid:13) X (cid:13) (cid:13) (cid:0) (cid:1) (cid:16) (cid:0) (cid:1) (cid:17)
We can(cid:13)bound the third(cid:13)term by ε Σ by setting t 2 (CPI(π) )1/2log d(CPI(π)+trΣ) . Under this
k k ≥ ∨ trΣ ε Σ
k k
choice t, the second term can be bounded by ε Σ if we take
k k
N
t2dlog2d d
1
C PI(π)
log2
d C PI(π)+trΣ
log2d.
≍ ε2 ≍ ε2 ∨ trΣ ε Σ
(cid:0) (cid:1)
(cid:16) k k (cid:17)
19Proof of Theorem 9. As in the proof of Theorem 8, we just combine the two bounds (i.e., errors
for the mean and covariance) from Corollary 33 and Lemma 37.
Proof of Corollary 10. We just apply Theorem 9 after transforming the whole system by x
Σ 1/2x. Then,thecovariancebecomesΣ= I,andweobtainthatforN d+CPI(ν) log2 d(d+CPI(ν)) l7→ og2d,
− ≍ ε2 ε
Σ 1/2ΣΣ 1/2 I εI,
− −
| − |(cid:22)
from which the claim follows by conjugating both sides by Σ1/2.
6 Details for the applications
6.1 Isotropic rounding
We show that In-and-Out (π , ,h ) has a spectral gap at least 0.99.
Ni i
·
i
Proof of Lemma 14. Within each while-loop, In-and-Out iterates k N = (cC4d3) times, and the
i i
O
number of while-loops is at most 2logd, as we will show later in Lemma 16. Therefore, the total
numberofiterations ofIn-and-OutthroughoutAlgorithm1isT := (cC4d3e). Withthetotalfailure
O
probability of In-and-Out (throughout the entire algorithm) set to η = 1/d, [KVZ24, Theorem 27]
requires the variance h of In-and-Out to be smaller than r2(2d2loeg 18T) 1 = r2(2d2log18dT) 1,
i η − i −
justifying the choice of h in Line 5.
i
By (4.1) (or [KVZ24, Theorem 23]), it suffices for In-and-Out to iterate N . h 1C (π )
i −i PI i
times to ensure the spectral gap is at least 0.99. Since C (π ) . Σ logd (Remark 11) and
PI i i op
k k
Σ . C2dlogd (Lemma 16), In-and-Out (π , ,h ) with N = 210C2d3r 2log(Ccd) has the
k
i kop Ni i
·
i i i−
desired spectral gap. The choices of h and N in Line 10 can be justified in a similar way.
Covariance estimation. RecallthatTheorem8assumesthattheinitialdistributionofaMarkov
chain is already stationary, though the actual initial distribution ν = law(X ) of Algorithm 1 is
0
different from π . We address this in Lemma 15; the conclusion is that we only pay a small
K
additional factor in order to handle this initial bias, which can be absorbed into the other terms.
Proof of Lemma 15. Let ν = law(X ) be the law of the warm start generated by Gaussian cooling
0
in Line 1. As R (ν π ) log2, then we have ν 2 almost surely over . Following a similar
∞ k K1 ≤ πi ≤ K1
argument as in Lemma 29, we note that all the required bounds on bad events in the proof of
Theorem 8 are multiplied by at most 3, and that E [ X i] 3E [ X i] for i = 2,4. Therefore,
ν
k k ≤
πK
1 k k
we still have that Σ Σ εΣ+δI for sufficiently many samples N.
d
| − | (cid:22)
As shown later in Lemma 16, trΣ . C2d2 throughout the algorithm, and it is well-known that
C (π ) . trΣ (dube to the log-concavity of π ). Hence, with ε = 0.1 and δ = d/100, there exists a
PI i i i
universal constant c such that so long as N cd 1trΣlog6Cd,
−
≥
1 d
Σ Σ Σ+ I ,
d
| − | (cid:22) 10 100
which completes the proof. b
We provide quantitative control of subroutines executed within each while-loop.
20Proof of Lemma 16. The inner radius r increases by a factor of at least 3/2 each iteration. Since
i
the algorithm starts with r =1/4 and ends before r √d, it takes fewer than 2logd iterations.
1 j
≤
Now we analyze how the trace and operator norm of the covariance changes each iteration.
(1) As per the algorithm, we have
Σ = M Σ M (6.1)
i+1 i i i
Since P is an orthogonal projection matrix,
i
trΣ =
tr(Σ1/2 M2Σ1/2
) = tr
Σ1/2
(I +3P
)Σ1/2
4trΣ .
i+1 i i i i i i ≤ i
As r
i+1
= 2(1 −log −1d)r i, we have that trΣi/r i2 in(cid:0) creases by a factor(cid:1) of (1 −1/logd) −2 per iteration.
Thus, it can increase by up to 10 times since there are 2logd many iterations. Therefore, we have
trΣ 10r2trΣ = 10r2C2d for all i.
i ≤ i 1 i
(2) Note that Σ trΣ C2d. Recall that ATA and AAT share the same spectrum (i.e.,
1 op 1
k k ≤ ≤
the same set of non-zero eigenvalues). Hence, it follows from (6.1) that
Σ = M Σ M =
Σ1/2 M2Σ1/2
=
Σ1/2
(I +3P
)Σ1/2
k i+1 kop k i i i kop k i i i kop k i i i kop
1/2 1/2
Σ +3 Σ P Σ = Σ +3 P Σ P . (6.2)
≤ k i kop k i i i kop k i kop k i i i kop
Using k = 10cr2C2log6C2d many samples (which is at least cd 1trΣ log6Cd due to (2)),
i i − i
Lemma 15 ensures that 0.9Σ
i −
1d
00
I
d (cid:22)
Σ
i (cid:22)
1.1Σ
i
+ 1d
00
I
d
with probability at least 1
−
p/d.
Conjugating by the projection matrix P , we have using a somewhat lazy bound that
i
b
3 d
P Σ P P Σ P + P .
i i i i i i i
(cid:22) 2 50
b
Let Σ = UTDU be its spectral decomposition with orthogonal matrix U. Then, under this
i
decomposition, both UP UT and D = UΣ UT are diagonal, where the entry in UP UT’s diagonal
i i i
is setbto 0 if the corresponding diagonal entry of UΣ UT is larger than d, and 1 otherwise. Letting
i
min(dI ,D) be the entry-wise minimum obf dI and D, we have that
d d
b
3 d
UP Σ P UT min(dI ,D)+ I 2dI ,
i i i d d d
(cid:22) 2 50 (cid:22)
and P Σ P 2d. Substitutingthis back to (6.2), weobtain Σ Σ +6d. Therefore,
i i i op i+1 op i op
k k ≤ k k ≤ k k
the claim follows from recursing i times.
Doubling of the inner radius. We recall an additional technical lemma.
Lemma 38 ([LV06b], Lemma 3.4). Let be convex in Rd with centroid µ and covariance Σ
K
satisfying r2I Σ R2I . Then,
d d
(cid:22) (cid:22)
B (µ) B (µ).
r Rd
⊂K ⊂
Lastly, we show that under the update rule of r
i+1
2(1 1/logd)r i, the inner radius actually
← −
almost doubles if all the covariance estimations thus far have been accurate.
Proof of Lemma 17. We show that when B (c ) for some c , there exists some center
ri i
⊆
Ki i
∈
Ki
c
i+1
∈
Ki+1
such that
Ki+1
contains B ri+1(c i+1) with r
i+1
= 2(1 −1/logd)r i. By Lemma 38,
Ki
also
21contains the ellipsoid x : x µ 2 1 for the mean µ and covariance Σ of with respect
{ k −
i kΣ−1
≤ }
i i Ki
i
to π . Recall that
i
M = I +P , T = M T , Σ = M Σ M .
i i i+1 i i i+1 i i i
We first focus on the case where the two centers c and µ are different.
i i
LetΣ = UTD U bethespectraldecomposition oftheestimated covariance Σ ,whereU Rd d
i i i ×
∈
is an orthogonal matrix, and D Rd d is a diagonal matrix with eigenvalues on the diagonal in
i ×
∈
decreasibng order. Under the transformation x y := M x (i.e., ), thbe new convex body
i i i+1
7→ K → K
contains two ellipsoids: defining c := M c and µ := M µ (= µ ),
Ki+1 ′i i i ′i i i i+1
: y Rd : (y c )T(I+P ) 2(y c ) r2 , and : y Rd : (y µ )TΣ 1 (y µ ) 1 .
A { ∈ − ′i i − − ′i ≤ i} B { ∈ − ′i −i+1 − ′i ≤ }
We now work with a new coordinate system in z := Uy for the ease of analysis. Under this new
system, there exists 0 r d such that the r largest eigenvalues of UΣ UT = D (corresponding
i i
≤ ≤
to bases e ,...,e ) are larger than the threshold d and that the remaining d r eigenvalues are
1 r
{ } −
smaller than d. Note that under the z-coordinate system, P is given byb
i
0 [ d]
UP iUT = r ×r 1 since D i = ≥ r ×r [< d] .
" (d r) (d r) # " (d r) (d r) #
− × − − × −
Hence, under the z-coordinate system, the two ellipsoids above can be written as
2
1
(I +P i)2
→
(I +UP iUT)2 =
"
r ×r
2 (d r) (d r) #
, (6.3)
− × −
Σ UΣ UT = U(I +P )UT UΣ UT U(I +P )UT
i+1 i+1 i i i
→ · ·
1 1
= r ×r
2
UΣ iUT r ×r
2
. (6.4)
" (d r) (d r) # " (d r) (d r) #
− × − − × −
=:D
| {z }
Let c and c denote the centers of -ellipsoid and -ellipsoid in the z-coordinate system. We
A B A B
define = span( e ,...,e ) (i.e. the span of the deficient axes) and = span( e ,...,e )
r+1 d ⊥ 1 r
S { } S { }
(i.e. the span of the sufficient axes).
Case I: 0 < r < d. We first show that in the z-coordinate system, contains two lower-
i+1
K
dimensional balls
B
S
:= B 2lri(c l)
∩S
& B S⊥ := B 9(1 1− 0l)d1/2(c l) ∩S⊥,
where c
l
:= lc +(1 l)c and l := (1 1/logd)1/2.
A − B −
By (6.3), the part of the -ellipsoid along (i.e., ( +c )) contains B (c ). By convexity
A S A∩ S A
2ri
A
of , it contains B (c ) along the hyperplane +c , since contains c . As for , by
LemK
mi+ a1
15, with
prob2 al bri ilitl
y at least 1 d 1, Σ S
11Σℓ
+ d IK
.i+ C1
onjugatingB by UTD,S
t⊥
his is
− − i (cid:22) 10 i 100 d
equivalent to
11 db 11 d
DD D DUΣ UTD+ D2 = UΣ UT+ D2 .
i i i+1
(cid:22) 10 100 (6.4) 10 100
Then the projection onto (i.e., taking the top-left r r block matrix) results in
⊥
S ×
9
(UΣ i+1UT) ⊥ dI r,
|S (cid:23) 10
22so the -ellipsoid along contains B (c ). Since the -ellipsoid along contains B (c )
B
S⊥ 0.9d1/2
B A
S⊥ ri
A
as seen in (6.3), the convexity of implies that it contains a ball centered at c of radius
i+1 l
K
lr i+(1 −l)
·
19 0d1/2
≥
9(1 1− 0l) d1/2.
We now prove that contains a ball of radius roughly 2r centered at c , by showing that
i+1 i l
K
any point in such a ball can be written as a convex combination of B and B ⊥. More specifically,
S S
we may assume c =0 by translation and denote by P the projection to = +c. For any x with
l l
S S
x 2clr and c to be determined, we write
i
k k ≤
(I P)x Px
x= (1 t) − +t for t (0,1).
− 1 t t ∈
−
For u:= (I P)x and v := Px, we will show that if u 2 + v 2 = x 2 4c2l2r2, then
− k k k k k k ≤ i
u 9(1 l) v
t (0,1) : k k − d1/2 and k k 2lr
i
∃ ∈ 1 t ≤ 10 t ≤
−
v 10 u
t (0,1) : k k t 1 k k
⇐⇒ ∃ ∈ 2lr ≤ ≤ − 9(1 l)d1/2
i
−
10 u v 20lr u v
i
k k + k k = a+b 1 for a:= k k and b := k k .
⇐⇒ 9(1 l)d1/2 2lr 9(1 l)d1/2 ≤ 2lr 2lr
i i i
− −
To this end, it suffices to show that the maximum of the following problem is at most 1:
20lr
max i a+b subject to a2+b2 = c2.
9(1 l)d1/2
−
Using the Lagrange multiplier method, the maximum is attained if (a,b) = λ( 20lri ,1) for some
9(1 l)d1/2
λ > 0. Solving a2 + b2 = c2 with this condition, we have λ = c(1 +
400l2r i2−
) 1/2. Thus, the
81(1 l)2d −
maximum is −
20lr 400l2r2
i a+b = c 1+ i 1/2 ,
9(1 l)d1/2 81(1 l)2d
− −
(cid:0) (cid:1)
which can be bounded by 1 by setting c = (1+
400l2r i2
) 1/2.
81(1 l)2d −
We now show that c −2
≤
l −2 (so c
≥
l). Using 2−10r i2log4d
≤
d and l
≤
1 −1/2logd
≤
1, we have
400l2r2 400l2 1
c 2 = 1+ i 1+ 1+ .
− 81(1 l)2d ≤ 81 210(1 l)2log4d ≤ 12log2d
− · −
As l 2 = 1+ 1 , we clearly have c 2 l 2. Therefore,
− logd 1 − ≤ −
−
inrad( ) 2clr 2l2r .
i+1 i i
K ≥ ≥
Case II: r = 0 or d. When r = 0, the -ellipsoid is simply the d-dimensional B (c ). If
A
2ri
A
r = d, then it means that the -ellipsoid contains the d-dimensional ball B (c ). Since
B
19 0d1/2
B
210r2log4d d, we have 9 d1/2 2l2r , where l is as before. Combining these two cases justifies
i ≤ 10 ≥ i
inrad( ) 2l2r .
i+1 i
K ≥
Lastly, if the two centers c and µ are thesame, then c = c . In such case, thesame argument
i i
A B
goes through (with an even larger radius).
23Final guarantee. Putting these together, we can prove our main result in this section.
Proof of Lemma 18. We would like to exclude three bad events — (1) failure of Gaussian cooling in
Line 1, (2) failure of In-and-Out throughout the algorithm, and (3) failure of covariance estimation
in Line 6 within each while-loop and in Line 10.
As for (1), we can simply set the failure of the warm-start generation to p/d with logarithmic
overhead in d [KZ25]. As for (2), we already picked h and N in Line 5 so that the total failure
i i
probability of In-and-Out is at most p/d (see the proof of Lemma 14). As for (3), by Lemma 16, the
failure probability throughoutthe while-loop is at most plogd/d by the unionbound. As for the final
covariance estimation in Line 10, by the multiplicative form of covariance estimation guarantees
(Corollary 10), there exists a universal constant c > 0 such that Σ Σ 1 Σ with probability
at least 1 p when N cdlog6d. ′ | − | (cid:22) 10
− d ≥ ′
Putting all things together, the algorithm succeeds with probabbility at least 1 plogd/d p/d
− − ≥
1 p/√d, ensuring that the covariance of the transformed convex body satisfies
−
9 11
I Σ 1/2ΣΣ 1/2 I .
d − − d
10 (cid:22) (cid:22) 10
Therefore, Σ 1/2( µ) is 2-isotropic. b b
−
K−
As for the query complexity, Algorithm 1 starts with Gaussian cooling for the warm-start gener-
ation, usingb (C2d3) mbembershipqueries. In each while-loop, since In-and-Out froman (1)-warm
O O
start iterates k N = (cC4d3) = (C4d3) times, it uses (C4d3) membership queries. Since the
i i
O O O
number of wheile-loops is at most 2logd, the total query complexity is (C4d3).
O
e e e
e
6.2 Covariance estimation for unconstrained distributions
The following ensures that we can tractably initialize our algorithm not too far from the target.
Lemma 39 (Initialization, [CEL+22, Lemma 32]). Suppose V(0) = 0 and V is β-smooth (As-
∇
sumption 20). Let π exp( V) and m = E . Then, initialization µ = (0, 1 I ) satisfies
∝ − π k·k 0 N 2β d
logχ2(µ π) . 1+β +V(0) minV +dlog(m2β).
0
k −
Theassumption that V(0) =0 is standard, as alocal extremum can befound by optimization
∇
algorithms, which have complexity dominated by that of the sampling procedure. Assuming mild
values for all parameters of interest, this gives a bound of (d β).
O ∨
Proof of Lemma 24. Here, we elucidate a few details whene adapting the results of [AC24]. The
following steps are already present in their analysis of the proximal sampler, but we reemphasize
the derivation here for full clarity. Namely, by the analysis of [AC24, Appendix D.4], the condition
number of the backwards part of the proximal sampler is Θ(1). Furthermore, since the forward
part of the proximal sampler is implemented exactly, then denoting P ,P for the two
forward backward
exact kernels with step size h 1/β, and Pˆ for the approximate kernel from [AC24],
backward
≍
KL(δ Pˆ δ P) KL(δ P δ P )+E KL(δ Pˆ δ P ) ε,
x
k
x
≤
x forward
k
x forward y ∼δxPforward y backward
k
y backward
≤
using [AC24, Theorem D.1] as claimed.
Proof of Lemma 26. For any z Rd and m N, using the data-processing inequality and then
1
∈ ∈
the chain rule for KL,
KL(δ Pˆm δ Pm) KL(δ Pˆ δ P)+E KL(δ Pˆ δ Pˆ)
z1 k z1 ≤ z1 k z1 z2 ∼δz1Pˆ z2 k z2
24+ +E KL(δ Pˆ δ Pˆ).
··· zm ∼δz1Pˆm−1 zm k zm
This heavily uses the fact that the joint distribution arises from a Markov chain.
The query complexity to bound the left side by ς (0,1/2] is (md1/2log3 1), obtained by
∈ O ς
choosing an error of ς/m for the kernel and then applying Lemma 24 m-times. Then,
e
2 ν νˆ 2 KL(νˆ ν )
1:K 1:K TV 1:K 1:K
k − k ≤ k
KL(νˆ ν)+E KL(δ Pˆn δ Pn)
≤ k
x1 ∼νˆ x1
k
x1
+ +E KL(δ Pˆn δ Pn).
···
xK−1∼νˆPˆ(K−1)n xK−1
k
xK−1
Therefore,thequerycomplexityofboundingtheleftsideby2δ2 is ((Kn+n )d1/2log3 Kn+n0).
O 0 δ
Proof of Theorem 27 and Remark 28. For thechoices of h 1/β,en = (κ) given, thespectral gap
≍ O
of Pn will be bounded below by 0.99. Thus, choosing K = Θ(dφ), the covariance estimator using
ε2
samples from the exact kernel Pn will concentrate around Σ. Precisely, if
e
K K
1 1 2
Σ = Y Y ⊗ =:F(Y ,...,Y ),
j k 1 K
K − K
j X=1(cid:16) k X=1 (cid:17)
where Y ν and Y δ Pn, then Theorem 9 combined with Lemma 29 tell us for our choice
1
∼
i+1
∼
Yi
of parameters that with probability 1 2/3d,
−
Σ Σ ε Σ .
op op
k − k ≤ k k
Here, we use that our initial distribution ν = µ Pn0 comes from applying P enough iterations that
0
χ2(ν π) . 1, and so via Lemma 39 our choice of n is sufficient. Note that we can also write
0
Σˆ = Fk (X ,...,X ), where X is generated using Pˆn instead.
1 k j j K
Denote the undesirable{ even} t≤ on RK d by
×
:= (X ,...,X ) Rd K : F(X ,...,X ) Σ > ε Σ .
1 K × 1 K op op
A ∈ k − k k k
(cid:8) (cid:9)
Under the approximate kernel Pˆn, we have via Lemma 26 and the definition of the TV distance
that
νˆ ( ) ν ( )+ ν ( ) νˆ ( ) ν ( )+ ν νˆ .
1:K 1:K 1:K 1:K 1:K 1:K 1:K TV
A ≤ A | A − A | ≤ A k − k
Choosing δ p/d in Lemma 26 to make this TV distance bounded by p/d, and adding it to our
≍
boundunder ν
1:K
from earlier, we obtain a boundof 1 p/d on the probability of failing to estimate
−
the covariance under the approximate implementation of the kernel.
The total expected query complexity is then given by
N Kκd1/2log3(K +n ) + n d1/2log3(K +n ) ,
0 0 0
≤ O O
(cid:0) (cid:1) (cid:0) (cid:1)
where the second term is tehe cost of generating the ineitial iterate, and the first term comes from
the generation of the remaining iterates. Putting all these together concludes the proof.
For the boundgiven in Remark 28, we note that we will again need K = Θ(dφ) iterates in total.
ε2
By the same principle as Lemma 26, it suffices that each iterate is ( 1 ) close to the target in
O Kd
√KL, and we should again choose ̺ identically to the Markovian case. To pre oduce a single iterate,
we require (n d1/2polylog(K +n )) queries in expectation. Putting these all together concludes
0 0
O
the proof.
e
257 Concluding remarks
In summary, we have established in this work that Markov chains can estimate the covariance of a
target distribution under the joint assumptions of (PI) and a spectral gap. We demonstrated two
applications wherethishasasubstantialbenefitintermsofquerycomplexity bounds. Inparticular,
we demonstrated its relevance to an iterative rounding algorithm, which is a cornerstone of the
literature for convex body sampling.
Weforeseeseveralprimaryextensionstooureffortsthatmaybeworthwhile. Firstly,intheproof
of Lemma 36, we only obtained a polynomial tail bound via Markov’s inequality inequality due to
dependence of samples, whereas [ALPTJ10] was able to find a subexponential bound. Closing this
gap would render our result completely analogous with the prior literature in the i.i.d. setting.
An interesting complementary approach may be to establish a Poincaré inequality or other
functional inequality directly on the joint distribution of the iterates X . Note that in the
j j N
{ } ≤
i.i.d. case, a Poincaré inequality follows immediately by tensorization.
Finally, one may extend this to higher-order moment tensors, or even to exponential quantities.
To this end, it may be interesting to consider what additional guarantees may follow as a result
of a log-Sobolev inequality (LSI). LSIs are the other primary functional inequality considered in
sampling, and generally lead to stronger concentration results.
References
[AC24] Jason M Altschuler and Sinho Chewi. Faster high-accuracy log-concave sampling via
algorithmic warm starts. Journal of the ACM (JACM), 71(3):1–55, 2024.
[ALPTJ10] RadosławAdamczak, Alexander Litvak, AlainPajor, andNicole Tomczak-Jaegermann.
Quantitative estimates of the convergence of the empirical covariance matrix in log-
concave ensembles. Journal of the American Mathematical Society (JAMS),23(2):535–
561, 2010.
[AW02] Rudolf Ahlswede and Andreas Winter. Strong converse for identification via quantum
channels. IEEE Transactions on Information Theory, 48(3):569–579, 2002.
[BGL14] Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and geometry of Markov
diffusion operators, volume 103. Springer, 2014.
[BMY16] Marwa Banna, Florence Merlevède, and Pierre Youssef. Bernstein-type inequality for
a class of dependent random matrices. Random Matrices: Theory and Applications,
5(02):1650006, 2016.
[Bob03] Sergey G Bobkov. Spectral gap and concentration for some spherically symmetric
probability measures. In Geometric Aspects of Functional Analysis (GAFA), pages
37–43. Springer, 2003.
[Bou96] Jean Bourgain. Random points in isotropic convex sets. Convex Geometric Analysis,
34:53–58, 1996.
[CCSW22] Yongxin Chen, Sinho Chewi, Adil Salim, and Andre Wibisono. Improved analysis for
a proximal algorithm for sampling. In Conference on Learning Theory (COLT), pages
2984–3014. PMLR, 2022.
26[CEL+22] Sinho Chewi, Murat A Erdogdu, Mufan Li, Ruoqi Shen, and Shunshi Zhang. Analysis
of Langevin Monte Carlo from Poincaré to log-Sobolev. In Conference on Learning
Theory (COLT), pages 1–2. PMLR, 2022.
[Che24] Sinho Chewi. Log-concave sampling. Book draft available at
https://chewisinho.github.io, 2024.
[CV18] Ben Cousins and Santosh S Vempala. Gaussian cooling and O (n3) algorithms for
∗
volume and Gaussian volume. SIAM Journal on Computing (SICOMP), 47(3):1237–
1273, 2018.
[Dal17] Arnak S Dalalyan. Further and stronger analogy between sampling and optimiza-
tion: Langevin Monte Carlo and gradient descent. In Conference on Learning Theory
(COLT), pages 678–689. PMLR, 2017.
[DMM19] AlainDurmus,SzymonMajewski,andBłażejMiasojedow. AnalysisofLangevinMonte
Carlo via convex optimization. The Journal of Machine Learning Research (JMLR),
20(1):2666–2711, 2019.
[DT12] Arnak S Dalalyan and Alexandre B Tsybakov. Sparse regression learning by aggrega-
tion and Langevin Monte-Carlo. Journal of Computer and System Sciences (JCSS),
78(5):1423–1443, 2012.
[Fil91] James Allen Fill. Eigenvalue bounds on convergence to stationarity for nonreversible
Markov chains, with an application to the exclusion process. The Annals of Applied
Probability, pages 62–87, 1991.
[FJS21] Jianqing Fan, Bai Jiang, and Qiang Sun. Hoeffding’s inequality for general Markov
chains and its applications to statistical learning. Journal of Machine Learning Re-
search (JMLR), 22(139):1–35, 2021.
[Gil93] David Wallace Gillman. Hidden Markov chains: convergence rates and the complexity
of inference. PhD thesis, Massachusetts Institute of Technology, 1993.
[GLSS18] Ankit Garg, Yin Tat Lee, Zhao Song, and Nikhil Srivastava. A matrix expander
Chernoff bound. In Symposium on Theory of Computing (STOC), pages 1102–1114,
2018.
[HS87] Richard Holley and Daniel Stroock. Logarithmic Sobolev inequalities and stochastic
Ising models. Journal of Statistical Physics, 46:1159–1194, 1987.
[JLLV21] He Jia, Aditi Laddha, Yin Tat Lee, and Santosh S Vempala. Reducing isotropy and
volumetoKLS:anO (n3ψ2)volumealgorithm. InSymposium onTheory ofComputing
∗
(STOC), pages 961–974, 2021.
[JLLV24] HeJia, AditiLaddha,YinTatLee, andSantosh SVempala. Reducingisotropy andvol-
umetoKLS:Fasterroundingandvolumealgorithms. arXiv preprint arXiv:2008.02146,
2024.
[JSF18] Bai Jiang, Qiang Sun, and Jianqing Fan. Bernstein’s inequality for general Markov
chains. arXiv preprint arXiv:1805.10721, 2018.
27[Kla23] Boáz Klartag. Logarithmic bounds for isoperimetry and slices of convex sets. Ars
Inveniendi Analytica, 2023.
[KLS97] RaviKannan,LászlóLovász,andMiklósSimonovits. RandomwalksandanO (n5)vol-
∗
ume algorithm for convex bodies. Random Structures & Algorithms (RS&A), 11(1):1–
50, 1997.
[KVZ24] Yunbum Kook, Santosh S Vempala, and Matthew S Zhang. In-and-Out: Algorithmic
diffusion for sampling convex bodies. In To appear in Advances in Neural Information
Processing Systems (NeurIPS), 2024.
[KZ25] Yunbum Kook and Matthew S Zhang. Rényi-infinity constrained sampling with d3
membership queries. In To appear in Symposium on Discrete Algorithms (SODA),
2025.
[Leh23] Joseph Lehec. The Langevin Monte Carlo algorithm in the non-smooth log-concave
case. The Annals of Applied Probability, 33(6A):4858–4874, 2023.
[Lez98] Pascal Lezaud. Chernoff-type bound for finite Markov chains. The Annals of Applied
Probability, pages 849–867, 1998.
[Lov99] László Lovász. Hit-and-run mixes fast. Mathematical Programming, 86:443–461, 1999.
[LS93] LászlóLovászandMiklósSimonovits. Randomwalksinaconvexbodyandanimproved
volume algorithm. Random Structures & Algorithms (RS&A), 4(4):359–412, 1993.
[LST21] Yin Tat Lee, Ruoqi Shen, and Kevin Tian. Structured logconcave sampling with a
restricted Gaussian oracle. In Conference on Learning Theory (COLT), pages 2993–
3050. PMLR, 2021.
[LV06a] László Lovász and Santosh S Vempala. Hit-and-run from a corner. SIAM Journal on
Computing (SICOMP), 35(4):985–1005, 2006.
[LV06b] László Lovász and Santosh S Vempala. Simulated annealing in convex bodies and
an O (n4) volume algorithm. Journal of Computer and System Sciences (JCSS),
∗
72(2):392–417, 2006.
[Mih89] Milena Mihail. Conductance and convergence of Markov chains-a combinatorial treat-
ment of expanders. In Symposium on Foundations of Computer Science (FOCS), vol-
ume 89, pages 526–531, 1989.
[MJC+14] Lester Mackey, Michael I Jordan, Richard Y Chen, Brendan Farrell, and Joel A Tropp.
Matrix concentration inequalities via the method of exchangeable pairs. The Annals
of Probability, pages 906–945, 2014.
[MPR09] Florence Merlevedé, Magda Peligrad, and Emmanuel Rio. Bernstein inequality and
moderate deviations under strong mixing conditions. In High dimensional probability
V: the Luminy volume, volume 5, pages 273–293. Institute of Mathematical Statistics,
2009.
[MPR11] Florence Merlevède, Magda Peligrad, and Emmanuel Rio. A Bernstein type inequal-
ity and moderate deviations for weakly dependent sequences. Probability Theory and
Related Fields, 151:435–474, 2011.
28[NSW23] Joe Neeman, Bobby Shi, and Rachel Ward. Concentration inequalities for sums of
Markov dependent random matrices. arXiv preprint arXiv:2303.02150, 2023.
[Oli09] Roberto Imbuzeiro Oliveira. Concentration of the adjacency matrix and of the Lapla-
cian in random graphs with independent edges. arXiv preprint arXiv:0911.0600, 2009.
[Pao06] Grigoris Paouris. Concentration of mass on convex bodies. Geometric and Functional
Analysis (GAFA), 16(5):1021–1049, 2006.
[Pau15] Daniel Paulin. Concentration inequalities for Markov chains by Marton couplings and
spectral methods. Electronic Journal of Probability (EJP), 20:79, 2015.
[PMT16] Daniel Paulin, Lester Mackey, and Joel A Tropp. Efron–Stein inequalities for random
matrices. The Annals of Probability, 44(5):3431–3473, 2016.
[QWL+20] Jiezhong Qiu, Chi Wang, Ben Liao, Richard Peng, and Jie Tang. A matrix Chernoff
bound for Markov chains and its application to co-occurrence matrices. Advances in
Neural Information Processing Systems (NeurIPS), 33:18421–18432, 2020.
[RH23] PhilippeRigolletandJan-ChristianHütter. High-dimensionalstatistics. arXiv preprint
arXiv:2310.19244, 2023.
[Rud99] Mark Rudelson. Random vectors in the isotropic position. Journal of Functional
Analysis, 164(1):60–72, 1999.
[Smi84] Robert L Smith. Efficient Monte Carlo procedures for generating points uniformly
distributed over bounded regions. Operations Research, 32(6):1296–1308, 1984.
[SV13] Nikhil Srivastava and Roman Vershynin. Covariance estimation for distributions with
2+ε moments. The Annals of Probability, 41(5):3081–3111, 2013.
[Tro12] Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of
Computational Mathematics (FoCM), 12:389–434, 2012.
[Tro15] Joel A Tropp. An introduction to matrix concentration inequalities. Foundations and
Trends® in Machine Learning, 8(1-2):1–230, 2015.
[Ver12] Roman Vershynin. Introduction to the non-asymptotic analysis of random matrices.
Compressed Sensing, pages 210–268, 2012.
[Ver18] Roman Vershynin. High-dimensional probability: An introduction with applications in
data science, volume 47. Cambridge university press, 2018.
[VW19] Santosh S Vempala and Andre Wibisono. Rapid convergence of the unadjusted
Langevin algorithm: Isoperimetry suffices. Advances in Neural Information Processing
Systems (NeurIPS), 32, 2019.
A Finer bound on the tail
Lemma 40. Under the same assumptions as Lemma 35, we in fact have the improved bound
1 1 1
P X 21 E X 21 sρ .
N k i k Bc − N k i k Bc ≥ ≤ s2
(cid:16) Xi h Xi i (cid:17)
Here, ρ can be bounded as ρ2 1(1+ 2)(trΣ+C (π))2e t/2.
≤ N λ PI −
29Proof. Note that
1 1 1
X 21 sup X v 21 = X 21 .
N
i⊗ Bc
≤ N v |
i
· |
Bc
N k
i
k
Bc
(cid:13) X (cid:13) X Xi
(cid:13) (cid:13)
Consider the cente(cid:13) red function f(X(cid:13) ):= X 21 E X 21 , in which case we can write
i i Bc i Bc
{k k − k k }
N N
1 1 2
E X 21 E X 21
i Bc i Bc
N k k − N k k
hn Xi=1 h Xi=1 io i
N N N
1 1 2
= E[( f(X ))2]= E[(f(X ))2]+ E[ f(X )f(X )]
N2 i N2 i N2 i j
i=1 i=1 i=1 j>i
X X X X
j [N]
∈
N
1 2
= E[(f(X ))2]+ E[f(X ) E[f(X )X ]]
N i N2 i j | i
i=1 j>i
X X
j [N]
∈
N
1 2
= E[(f(X ))2]+ E[f(X ) Pkf(X )].
N i N2 i i
i=1 k>0
X X
k [N i]
∈ −
Consider just the second term. If we observe just the even summands, we see that they can be
bounded as
1
E f(X ) P2kf(X ) = E[Pkf 2] λkE[f 2]= E[f 2],
i i
| | ≤ | | 1 λ | |
h k X>0 i k X>0 k X>0 −
k [N i] k [ N i ]
∈ − ∈⌊ −⌋
Theodd terms can be handled via Cauchy–Schwarz, E[fPk+1f] Ef2E[(P2k+2f)2] λk+1E[f2].
≤ ≤
Thus, the effect is to approximately double the bound above. q
Note that E[(f(X ))2] can be bounded by
i
E[ X 41 ]= E[ X 41 ] E[ X 8] P X t√trΣ
i Bc Bc
k k k k ≤ k k k k ≥
. trΣ+C (π) q2 e t/2, q (cid:0) (cid:1)
PI −
·
since (cid:0) (cid:1)
t
P( X E X > t) . exp ,
k k− k k − C (π)
PI
(cid:0) (cid:1)
and integrating, bounding E X . √trΣ. The mean can bpe bounded by
k k
1
E X 21 = E[ X 21 ] E[ X 4] P X t√trΣ . trΣ e t/2.
i Bc Bc −
N k k k k ≤ k k k k ≥ ·
h Xi i q q (cid:0) (cid:1)
This implies that
N
1 1 2
ρ2 := var f 1+ trΣ+C (π) 2 e t/2.
PI −
N ≤ N λ
(cid:16) Xi=1 (cid:17)
(cid:0) (cid:1)(cid:0) (cid:1)
Recall that λ is an absolute constant which is bounded away from zero.
Finally, by Chebyshev’s inequality,
1 1 1
P X 21 E X 21 sρ .
N k i k Bc − N k i k Bc ≥ ≤ s2
(cid:16) Xi h Xi i (cid:17)
30