[
    {
        "title": "IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation",
        "authors": "Luke Melas-KyriaziIro LainaChristian RupprechtNatalia NeverovaAndrea VedaldiOran GafniFilippos Kokkinos",
        "links": "http://arxiv.org/abs/2402.08682v1",
        "entry_id": "http://arxiv.org/abs/2402.08682v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08682v1",
        "summary": "Most text-to-3D generators build upon off-the-shelf text-to-image models\ntrained on billions of images. They use variants of Score Distillation Sampling\n(SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation\nis to fine-tune the 2D generator to be multi-view aware, which can help\ndistillation or can be combined with reconstruction networks to output 3D\nobjects directly. In this paper, we further explore the design space of\ntext-to-3D models. We significantly improve multi-view generation by\nconsidering video instead of image generators. Combined with a 3D\nreconstruction algorithm which, by using Gaussian splatting, can optimize a\nrobust image-based loss, we directly produce high-quality 3D outputs from the\ngenerated views. Our new method, IM-3D, reduces the number of evaluations of\nthe 2D generator network 10-100x, resulting in a much more efficient pipeline,\nbetter quality, fewer geometric inconsistencies, and higher yield of usable 3D\nassets.",
        "updated": "2024-02-13 18:59:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08682v1"
    },
    {
        "title": "Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance",
        "authors": "Linxi ZhaoYihe DengWeitong ZhangQuanquan Gu",
        "links": "http://arxiv.org/abs/2402.08680v1",
        "entry_id": "http://arxiv.org/abs/2402.08680v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08680v1",
        "summary": "The advancement of Large Vision-Language Models (LVLMs) has increasingly\nhighlighted the critical issue of their tendency to hallucinate non-existing\nobjects in the images. To address this issue, previous works focused on using\nspecially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the\noutputs of LVLMs. However, these approaches require either expensive\ntraining/fine-tuning or API access to advanced LLMs to correct the model's\noutput post-generation. In this paper, we tackle this challenge by introducing\na framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE\n(MARINE), which is both training-free and API-free, and can effectively and\nefficiently reduce object hallucinations during the generation process.\nSpecifically, MARINE enriches the visual context of LVLMs by integrating\nexisting open-source vision models, and employs classifier-free guidance to\nincorporate the additional object grounding features to improve the precision\nof LVLMs' generations. Through comprehensive evaluations across $6$ popular\nLVLMs with diverse evaluation metrics, we demonstrate the effectiveness of\nMARINE, which even outperforms existing fine-tuning-based methods. Remarkably,\nit not only reduces hallucinations but also improves the detailedness of LVLMs'\ngenerations, as assessed by GPT-4V.",
        "updated": "2024-02-13 18:59:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08680v1"
    },
    {
        "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability",
        "authors": "Xingang GuoFangxu YuHuan ZhangLianhui QinBin Hu",
        "links": "http://arxiv.org/abs/2402.08679v1",
        "entry_id": "http://arxiv.org/abs/2402.08679v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08679v1",
        "summary": "Jailbreaks on Large language models (LLMs) have recently received increasing\nattention. For a comprehensive assessment of LLM safety, it is essential to\nconsider jailbreaks with diverse attributes, such as contextual coherence and\nsentiment/stylistic variations, and hence it is beneficial to study\ncontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In this\npaper, we formally formulate the controllable attack generation problem, and\nbuild a novel connection between this problem and controllable text generation,\na well-explored topic of natural language processing. Based on this connection,\nwe adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a\nstate-of-the-art, highly efficient algorithm in controllable text generation,\nand introduce the COLD-Attack framework which unifies and automates the search\nof adversarial LLM attacks under a variety of control requirements such as\nfluency, stealthiness, sentiment, and left-right-coherence. The controllability\nenabled by COLD-Attack leads to diverse new jailbreak scenarios which not only\ncover the standard setting of generating fluent suffix attacks, but also allow\nus to address new controllable attack settings such as revising a user query\nadversarially with minimal paraphrasing, and inserting stealthy attacks in\ncontext with left-right-coherence. Our extensive experiments on various LLMs\n(Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) show COLD-Attack's broad\napplicability, strong controllability, high success rate, and attack\ntransferability. Our code is available at\nhttps://github.com/Yu-Fangxu/COLD-Attack.",
        "updated": "2024-02-13 18:58:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08679v1"
    },
    {
        "title": "Model Assessment and Selection under Temporal Distribution Shift",
        "authors": "Elise HanChengpiao HuangKaizheng Wang",
        "links": "http://arxiv.org/abs/2402.08672v1",
        "entry_id": "http://arxiv.org/abs/2402.08672v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08672v1",
        "summary": "We investigate model assessment and selection in a changing environment, by\nsynthesizing datasets from both the current time period and historical epochs.\nTo tackle unknown and potentially arbitrary temporal distribution shift, we\ndevelop an adaptive rolling window approach to estimate the generalization\nerror of a given model. This strategy also facilitates the comparison between\nany two candidate models by estimating the difference of their generalization\nerrors. We further integrate pairwise comparisons into a single-elimination\ntournament, achieving near-optimal model selection from a collection of\ncandidates. Theoretical analyses and numerical experiments demonstrate the\nadaptivity of our proposed methods to the non-stationarity in data.",
        "updated": "2024-02-13 18:54:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08672v1"
    },
    {
        "title": "Are Semi-Dense Detector-Free Methods Good at Matching Local Features?",
        "authors": "Matthieu VilainRémi GiraudHugo GermainGuillaume Bourmaud",
        "links": "http://arxiv.org/abs/2402.08671v1",
        "entry_id": "http://arxiv.org/abs/2402.08671v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08671v1",
        "summary": "Semi-dense detector-free approaches (SDF), such as LoFTR, are currently among\nthe most popular image matching methods. While SDF methods are trained to\nestablish correspondences between two images, their performances are almost\nexclusively evaluated using relative pose estimation metrics. Thus, the link\nbetween their ability to establish correspondences and the quality of the\nresulting estimated pose has thus far received little attention. This paper is\na first attempt to study this link. We start with proposing a novel structured\nattention-based image matching architecture (SAM). It allows us to show a\ncounter-intuitive result on two datasets (MegaDepth and HPatches): on the one\nhand SAM either outperforms or is on par with SDF methods in terms of\npose/homography estimation metrics, but on the other hand SDF approaches are\nsignificantly better than SAM in terms of matching accuracy. We then propose to\nlimit the computation of the matching accuracy to textured regions, and show\nthat in this case SAM often surpasses SDF methods. Our findings highlight a\nstrong correlation between the ability to establish accurate correspondences in\ntextured regions and the accuracy of the resulting estimated pose/homography.\nOur code will be made available.",
        "updated": "2024-02-13 18:53:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08671v1"
    }
]