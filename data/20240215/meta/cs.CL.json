[
    {
        "title": "Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance",
        "authors": "Linxi ZhaoYihe DengWeitong ZhangQuanquan Gu",
        "links": "http://arxiv.org/abs/2402.08680v1",
        "entry_id": "http://arxiv.org/abs/2402.08680v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08680v1",
        "summary": "The advancement of Large Vision-Language Models (LVLMs) has increasingly\nhighlighted the critical issue of their tendency to hallucinate non-existing\nobjects in the images. To address this issue, previous works focused on using\nspecially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the\noutputs of LVLMs. However, these approaches require either expensive\ntraining/fine-tuning or API access to advanced LLMs to correct the model's\noutput post-generation. In this paper, we tackle this challenge by introducing\na framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE\n(MARINE), which is both training-free and API-free, and can effectively and\nefficiently reduce object hallucinations during the generation process.\nSpecifically, MARINE enriches the visual context of LVLMs by integrating\nexisting open-source vision models, and employs classifier-free guidance to\nincorporate the additional object grounding features to improve the precision\nof LVLMs' generations. Through comprehensive evaluations across $6$ popular\nLVLMs with diverse evaluation metrics, we demonstrate the effectiveness of\nMARINE, which even outperforms existing fine-tuning-based methods. Remarkably,\nit not only reduces hallucinations but also improves the detailedness of LVLMs'\ngenerations, as assessed by GPT-4V.",
        "updated": "2024-02-13 18:59:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08680v1"
    },
    {
        "title": "COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability",
        "authors": "Xingang GuoFangxu YuHuan ZhangLianhui QinBin Hu",
        "links": "http://arxiv.org/abs/2402.08679v1",
        "entry_id": "http://arxiv.org/abs/2402.08679v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08679v1",
        "summary": "Jailbreaks on Large language models (LLMs) have recently received increasing\nattention. For a comprehensive assessment of LLM safety, it is essential to\nconsider jailbreaks with diverse attributes, such as contextual coherence and\nsentiment/stylistic variations, and hence it is beneficial to study\ncontrollable jailbreaking, i.e. how to enforce control on LLM attacks. In this\npaper, we formally formulate the controllable attack generation problem, and\nbuild a novel connection between this problem and controllable text generation,\na well-explored topic of natural language processing. Based on this connection,\nwe adapt the Energy-based Constrained Decoding with Langevin Dynamics (COLD), a\nstate-of-the-art, highly efficient algorithm in controllable text generation,\nand introduce the COLD-Attack framework which unifies and automates the search\nof adversarial LLM attacks under a variety of control requirements such as\nfluency, stealthiness, sentiment, and left-right-coherence. The controllability\nenabled by COLD-Attack leads to diverse new jailbreak scenarios which not only\ncover the standard setting of generating fluent suffix attacks, but also allow\nus to address new controllable attack settings such as revising a user query\nadversarially with minimal paraphrasing, and inserting stealthy attacks in\ncontext with left-right-coherence. Our extensive experiments on various LLMs\n(Llama-2, Mistral, Vicuna, Guanaco, GPT-3.5) show COLD-Attack's broad\napplicability, strong controllability, high success rate, and attack\ntransferability. Our code is available at\nhttps://github.com/Yu-Fangxu/COLD-Attack.",
        "updated": "2024-02-13 18:58:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08679v1"
    },
    {
        "title": "Improving Generalization in Semantic Parsing by Increasing Natural Language Variation",
        "authors": "Irina SaparinaMirella Lapata",
        "links": "http://arxiv.org/abs/2402.08666v1",
        "entry_id": "http://arxiv.org/abs/2402.08666v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08666v1",
        "summary": "Text-to-SQL semantic parsing has made significant progress in recent years,\nwith various models demonstrating impressive performance on the challenging\nSpider benchmark. However, it has also been shown that these models often\nstruggle to generalize even when faced with small perturbations of previously\n(accurately) parsed expressions. This is mainly due to the linguistic form of\nquestions in Spider which are overly specific, unnatural, and display limited\nvariation. In this work, we use data augmentation to enhance the robustness of\ntext-to-SQL parsers against natural language variations. Existing approaches\ngenerate question reformulations either via models trained on Spider or only\nintroduce local changes. In contrast, we leverage the capabilities of large\nlanguage models to generate more realistic and diverse questions. Using only a\nfew prompts, we achieve a two-fold increase in the number of questions in\nSpider. Training on this augmented dataset yields substantial improvements on a\nrange of evaluation sets, including robustness benchmarks and out-of-domain\ndata.",
        "updated": "2024-02-13 18:48:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08666v1"
    },
    {
        "title": "Tandem Transformers for Inference Efficient LLMs",
        "authors": "Aishwarya P SPranav Ajit NairYashas SamagaToby BoydSanjiv KumarPrateek JainPraneeth Netrapalli",
        "links": "http://arxiv.org/abs/2402.08644v1",
        "entry_id": "http://arxiv.org/abs/2402.08644v1",
        "pdf_url": "http://arxiv.org/pdf/2402.08644v1",
        "summary": "The autoregressive nature of conventional large language models (LLMs)\ninherently limits inference speed, as tokens are generated sequentially. While\nspeculative and parallel decoding techniques attempt to mitigate this, they\nface limitations: either relying on less accurate smaller models for generation\nor failing to fully leverage the base LLM's representations.\n  We introduce a novel architecture, Tandem transformers, to address these\nissues. This architecture uniquely combines (1) a small autoregressive model\nand (2) a large model operating in block mode (processing multiple tokens\nsimultaneously). The small model's predictive accuracy is substantially\nenhanced by granting it attention to the large model's richer representations.\nOn the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko\ndemonstrates a 3.3% improvement in next-token prediction accuracy over a\nstandalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter\nmodel with comparable downstream performance. We further incorporate the tandem\nmodel within the speculative decoding (SPEED) framework where the large model\nvalidates tokens from the small model. This ensures that the Tandem of\nPaLM2-Bison and PaLM2-Gecko achieves substantial speedup (around 1.14x faster\nthan using vanilla PaLM2-Gecko in SPEED) while maintaining identical downstream\ntask accuracy.",
        "updated": "2024-02-13 18:24:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08644v1"
    },
    {
        "title": "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 14 Languages",
        "authors": "Nedjma OusidhoumShamsuddeen Hassan MuhammadMohamed AbdallaIdris AbdulmuminIbrahim Said AhmadSanchit AhujaAlham Fikri AjiVladimir AraujoAbinew Ali AyelePavan BaswaniMeriem BeloucifChris BiemannSofia BourhimChristine De KockGenet Shanko DekeboOumaima HourraneGopichand KanumoluLokesh MadasuSamuel RutundaManish ShrivastavaThamar SolorioNirmal SurangeHailegnaw Getaneh TilayeKrishnapriya VishnubhotlaGenta WinataSeid Muhie YimamSaif M. Mohammad",
        "links": "http://arxiv.org/abs/2402.08638v2",
        "entry_id": "http://arxiv.org/abs/2402.08638v2",
        "pdf_url": "http://arxiv.org/pdf/2402.08638v2",
        "summary": "Exploring and quantifying semantic relatedness is central to representing\nlanguage. It holds significant implications across various NLP tasks, including\noffering insights into the capabilities and performance of Large Language\nModels (LLMs). While earlier NLP research primarily focused on semantic\nsimilarity, often within the English language context, we instead investigate\nthe broader phenomenon of semantic relatedness. In this paper, we present\nSemRel, a new semantic relatedness dataset collection annotated by native\nspeakers across 14 languages:Afrikaans, Algerian Arabic, Amharic, English,\nHausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern\nStandard Arabic, Punjabi, Spanish, and Telugu. These languages originate from\nfive distinct language families and are predominantly spoken in Africa and Asia\n-- regions characterised by a relatively limited availability of NLP resources.\nEach instance in the SemRel datasets is a sentence pair associated with a score\nthat represents the degree of semantic textual relatedness between the two\nsentences. The scores are obtained using a comparative annotation framework. We\ndescribe the data collection and annotation processes, related challenges when\nbuilding the datasets, and their impact and utility in NLP. We further report\nexperiments for each language and across the different languages.",
        "updated": "2024-02-14 09:49:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.08638v2"
    }
]