Logic of Awareness for Nested Knowledge
Yudai Kubono
Graduate School of Science and Technology, Shizuoka University,
Ohya, Shizuoka 422-8529, Japan
yudai.kubono@gmail.com
February 1, 2024
Abstract
Reasoning abilities of human beings are limited. Logics that treat logical inference for
human knowledge should reflect these limited abilities. Logic of awareness is one of those
logics. Inthelogic,whatanagentwithalimitedreasoningabilityactuallyknowsatagiven
moment(explicitknowledge)isdistinguishedfromtheidealknowledgethatanagentobtains
by performing all possible inferences with what she already knows (implicit knowledge) [7].
Thispaperproposesalogicforexplicitknowledge. Inparticular,wefocusmoreonnested
explicit knowledge, which means another agent’s knowledge that an agent actually knows
atagivenmoment. WedevelopeanewformalizationoftwoideasandproposeKripke-style
semantics. Thefirstideaistheeffectonanagent’sreasoningabilitybyastateofanagent’s
awareness. Weincorporatearelationonpossibleworldscalledanindistinguishable relation
to represent ignorance due to lack of awareness. The second idea is a state of each agent’s
awareness in the other agent’s mind. We incorporate a non-empty finite sequence of agents
called a chain of belief for awareness. Our logic is called Awareness Logic with Partitions
and Chains (ALPC). Employing an example, we show how nested explicit knowledge is
formalizedwithourlogic. Thereafter,weproposetheproofsystemandprovethecomplete-
ness. Finally, wediscussdirectionsforextendingandapplyingourlogicandconclude. Our
logic offers a foundation for a formal representation of human knowledge. We expect that
the logic can be applied to computer science and game theory by describing and analyzing
strategic behavior in a game and practical agent communication.
Keywords: Awareness, Explicit knowledge, Epistemic Logic, Modal logic, Multi-agent sys-
tems.
1
4202
beF
31
]AM.sc[
1v28280.2042:viXra1 Introduction
Epistemic Logic (EL), also known as the logic of knowledge, formalizes logical inference for
knowledge. The original interest is to elucidate the properties of knowledge. More recently,
researchers in fields such as computer science and economics have become interested in the logic
as a tool to formally analyze the effect of communicative protocols on knowledge of systems and
strategicsituationswhereaplayermakesadecisionwithknowledgeoftheother’saction[4]. One
of the research directions is formalizing the knowledge of beings with limited reasoning abilities,
such as humans and computers, rather than abstract entities. Another direction is formalizing
knowledge of another agent’s knowledge in multi-agent cases, called nested knowledge. This
paper proposes a logic for nested knowledge of human beings. We expect that our logic offers a
foundation for theoretical research in computer science and game theory.
ELisdefinedasamodallogic, whereanecessityoperatorinamodallogicisinterpretedasa
knowledgeoperator. Thismeansthattheknowledgeoperatorinheritslogicalpropertiesthatthe
necessity operator possesses. Propositions are denoted by φ,ψ and a knowledge operator with
agent a is denoted by K , which together with a proposition reads “a knows φ.” We may write
a
Kφ anonymously. In epistemic logic, as well as modal logic, we employ Modus Ponens (MP)1,
RN2, and K3 for logical inference. This means that when agent a knows φ, and φ → ψ is the
truth, ψ must be her knowledge. This property does not matter when an agent is interpreted
as an abstract entity. However, when the concept of an agent is applied to a human being, it
matters. A real human’s reasoning ability is limited and does not obtain knowledge through
such exhaustive reasoning. The gap between knowledge in EL and human knowledge is called
the problem of logical omniscience.
Logic of awareness is one of the solutions to the problem. Awareness Logic [3], which is the
seminal study in this field, distinguishes between knowledge that an agent can actually use for
their inference at a given moment and knowledge that an agent cannot actually use for it. The
former is called explicit knowledge, which means what an agent with a limited reasoning ability
actually knows at a given moment. On the other hand, the latter is called implicit knowledge,
1Fromφandφ→ψ,weconcludeψ.
2RN: Ifφisvalid,thenagentaknowsφ.
3K: K(φ→ψ)→(Kφ→Kψ).
2which means the ideal knowledge that an agent obtains by performing all possible inferences
with what she already knows. We can say that “implicit knowledge is the best an agent can do
if she were omniscient” [7, p.38]. In the logic, even if an agent knows φ, and φ→ψ is the truth,
ψ is not necessarily her knowledge anymore because φ or φ→ψ may not be explicit knowledge.
She may not actually know these propositions at a given time. Agent a’s explicit knowledge is
denoted as E , and the implicit knowledge is denoted as I . The logic has been developed in
a a
various fields such as philosophy, computer science, and economics to analyze an agent’s limited
reasoning [20].
Before going into detail about logic of awareness, we explain the semantical idea in EL. Its
semantics are given by a Kripke model. The model is a tuple consisting of a set of possible
worlds W, an equivalent relation R on W for each agent a called an accessibility relation, and
a
a valuation V. The truth of a formula K φ at a world w is defined by for all possible worlds
a
accessibleon R fromw, φistrue. Apossibleworldrepresentsapossibility, andpossibleworlds
a
accessiblefromwonR representallthepossibilitiesthatagentaconsiders. Thismeansabinary
a
relation can be interpreted as a representation of an agent’s reasoning ability. If an agent can
access only the actual world, she knows everything that holds in actuality. As a human being,
an agent accesses possibilities other than the actual one. If an agent accesses a world where φ is
false, ¬K φ holds at w, which means “agent a does not know φ.”
a
In Awareness Logic [3], an awareness set is incorporated to a Kripke model. This set repre-
sentsastateofanagent’sawarenessforformalizingexplicitandimplicitknowledge. Inthelogic,
implicit knowledge is defined in the same way as the knowledge in EL, and explicit knowledge
is defined by implicit knowledge contained in an awareness set, which means implicit knowledge
of which an agent is aware. “φ is explicit knowledge” equals the conjunction of “φ is implicit
knowledge” and “φ is an aware proposition.” This idea is simple and intuitive and has become
one of the main approaches in logic of awareness.
Nested knowledge, which is knowledge of another agent’s knowledge, appears in multi-agent
cases. Among such knowledge, common knowledge has a distinctive property. This knowledge
is defined by infinite iterations of “every agent knows.” It is because that “everyone knows’ is
notenough,butamutualacknowledgmentof“everyoneknows’isnecessary[4]. Itisknownthat
common knowledge plays a significant role in people’s agreement in economic [1].
3Weformalizenestedexplicitknowledgeinthefieldoflogicofawareness. Wearguethatthere
are two ideas to formalize to represent such knowledge, and we propose a new formalization
incorporating these ideas. Note that the scope of this paper is limited to the formalization of
nested explicit knowledge, which means it does not include that of common knowledge.
Thefirstoneistheeffectofanagent’sawarenessonherownreasoning. Anagent’sawareness
affects not only whether she is aware of propositions but also her reasoning ability, which means
asetofpossibleworldsthatshecanaccess. Thepreviousstudycapturedonlytheformer. When
agent a is not aware of q and ¬q, she cannot consider two possibilities: the worlds with only a
different valuation for q. It is because she should not identify the distinction in the first place.
The states of awareness of a and b may differ, in which case a’s reasoning ability R limited by
a
the state of a’s own awareness may differ from R reflecting the state of b’s awareness. In the
a
model depicted in Figure 1, a herself distinguishes between w and w , but an imaginary a with
1 2
the same awareness as b does not distinguish them. Thus, the notion of an accessible relation
needs to be extended.
(cid:3) (cid:0) (cid:3) (cid:0) (cid:7) (cid:4)
p , q p , ¬q a,b ¬p , ¬q
(cid:2) (cid:1) (cid:2) (cid:1) (cid:6) (cid:5)
w w w
1 2 3
Figure1: Atwomulti-agentmodelinwhichasetofpossibleworldsis{w ,w ,w }. Propositions
1 2 3
inside a possible world are true propositions in the world. An arrow represents an accessibility
relation. Reflexive arrows are omitted. Agent a is aware of p and q, but agent b is only aware of
p. Rounded rectangles that contain a proposition refer to that b is aware of the proposition. A
rounded rectangle that contains worlds refers to b does not distinguish the worlds.
The second one is a state of each agent’s awareness in the other agent’s mind. We consider
the meaning of nested explicit knowledge and take E E p for the example.“Agent a explicitly
a b
knows that b explicitly knows p” means “for all possible worlds accessible for a, for all possible
worlds accessible for b, p is ture.” Their awareness limits agents’ reasoning abilities. In EL, it is
assumedthatbothagentshavethesamestatesofawareness. However,thereisalsoacasewhere
adoesnothaveafullgraspofb’sstateofawareness. Forexplicitknowledgeinsuchasituation,it
isnecessarytointroduceb’sstateofawarenessina’smindinthissentencewhereaisthesubject.
This paper interprets agent b’s state of awareness in a’s mind as what a believes b is aware of,
4and this state of awareness can differ from the actual b’s state of awareness. To formalize such
a nested explicit knowledge, we should introduce a new notation E to represent b’s explicit
(a,b)
knowledge based on a’s belief in b’s state of awareness. This knowledge is different from b’s
explicit knowledge E .
b
The question arises whether such a knowledge E , b’s explicit knowledge based on a’s
(a,b)
belief in b’s state of awareness, is a mere a’s belief. The answer is in the negative. It is because
this information has a property of knowledge in EL. For example, E E φ → E φ holds
(a) (a,b) (a,b)
in our logic. This is called T-axiom in modal logic, which is one of the features of knowledge.
Thus, such information should be interpreted as knowledge, not belief.
Thefollowingisaconcreteexampleofnestedexplicitknowledge. Weusetheexamplein[16]
as a reference.
Example 1. Let agent a be the owner of the store A and agent b be the owner of the store B
considering opening their new store in an area. Product costs have risen due to poor harvests,
and a reckless expansion leads to a significant loss. Only a is aware of a new wholesaler that
supplies the product at half the current price. She believes that b is also aware of the wholesaler
as well as herself and believes that b believes she is not aware of the wholesaler. Agent b is not
aware of the wholesaler in actuality.
Let p denote “a/b opens a new stores” and q denote “there is the wholesaler.” In this
a/b
setting, both owners explicitly know their own decisions. Agent a actually knows that if q is
true, then p and p should be true. It is because she is aware of the wholesaler, and if such a
a b
wholesalerexistsinactuality, theyshouldexpandtheirtradearea. However, itisnotb’sexplicit
knowledge because b does not have any clue to know about a’s decision (p or ¬p ) and does
a a
not actually know a’s decision. Moreover, if a actually knows that q is true, imaginary b with
the same awareness as a explicitly knows a’s decision. The same idea applies to a’s belief in b’s
belief in a’s state of awareness and b’s belief in a’s state of awareness. Each owner’s knowledge
can be organized as follows.
• E p and E p : a and b explicitly know their own decision,
(a) a (b) b
• E q →E p : if a explicitly knows that q is true, a explicitly knows b’s decision,
(a) (a) b
5• ¬E q →¬E p : if a does not explicitly know that q is true, a does not explicitly know
(a) (a) b
b’s decision,
• ¬E p : in any case, b does not explicitly know a’s decision,
(b) a
• E q →E E p : ifaexplicitlyknowsthatqistrue,aexplicitlyknowsthatbexplicitly
(a) (a) (a,b) a
knows a’s decision,
• E ¬E p : in any case, b explicitly knows that a does not explicitly know b’s decision,
(b) (b,a) b
• ¬E p : inanycase,imaginaryawiththesameawarenessasbdoesnotexplicitlyknow
(a,b,a) b
a’s decision,
• E E ¬E p : inanycase,aexplicitlyknowsthatbexplicitlyknowsthataexplicitly
(a) (a,b) (a,b,a) b
knows a’s decision.
The previous logic cannot represent some explicit knowledge that is seemingly contradictory
but is both true, such as E p and ¬E p . Our logic can represent such knowledge, and we
(a,b) a (b) a
show it in a later section.
Suchknowledgeiscomplicatedbutvaluablewhenitcomestodescribingandanalyzingagame
ingametheory. Theconceptofawarenesshasbeenpaidattentiontoanalyzinghumanbehaviors
in game theory. There are several formalizations and solution concepts of a game where players
have different states of awareness, also known as game with incomplete awareness/unawareness
[5]. In a two-player game with incomplete awareness, a player a reasons another player b’s
reasoning under the conditions that b may not be aware of all her possible actions, and b may
perceive a is not aware of b’s possible actions, and so on. The example provided in [5] shows
that another player’s awareness that a player actually uses on her reasoning affects selecting a
strategy. A game that a player perceives she plays may differ by her state of awareness, and
Nash equilibrium may also differ. Another player’s choice changes according to another player’s
awareness that a player actually uses on her reasoning.
Modelsthatcandistinguishbetweenawareness of andawareness that havebeenproposedin
the field of philosophy[8, 10]. The models allow us to represent the relation between the concept
of knowledge and awareness more accurately. The former, which is “awareness of”, expresses
the notion of awareness in the sense of being able to refer to the information. The latter is the
6notionofawarenessinthesenseofacknowledgingthattheinformationistruethroughreasoning
or observation. Although both notions are similar, they have different properties. Even if an
agentcanrefertoanappleonadesk,anagentdoesnotnecessarilyacknowledgethatanappleis
actually on the desk. In previously proposed logic, explicit knowledge was defined by combining
these two notions. In this paper, we focus on “awareness of.” This is because the notion is more
relevant to the example, and we do not need to consider the other one.
Overview The paper is structured as follows. In Section 2, we define Awareness Logic with
Partitions and Chains (ALPC). Its semantics are given in the Kripke-style. The semantics has
the standard Kriple model for knowledge, and we add an extended awareness set and another
equivalence relation. The relation changes depending on an agent’s belief in a state of another
agent’s awareness. The notion of the relation was proposed in [16]. Besides, we show how our
logic works with the example introduced in Section 1. In Section 3, we give the proof system
ALPC in Hilbert style. For proving the completeness theorem, we use techniques of logic of
the modality for transitive closure [26] and the idea of a generated model [2]. In Section 4,
we introduce several related work to our logic. Lastly, we discuss possible future directions for
extending and applying our logic and conclude.
2 Awareness Logic with Partitions and Chains
This section defines our logic Awareness Logic with Partitions and Chains (ALPC) and demon-
strates to represent the knowledge of the example in Section 1. The logic is based on Awareness
Logic [3] and designed to incorporate the two ideas mentioned in Section 1, which are the effect
of an agent’s awareness on her own reasoning and a state of each agent’s awareness in the other
agent’s mind. For the former, we extend the equivalence relation in [16]. As for the latter, we
introduce a sequence of agents and extend an awareness set in [3].
2.1 Language
First, we define what represents the second idea, which is a state of each agent’s awareness in
theotheragent’smind. Wecallitachain of belief for awareness. Thischainisdefinedasanon-
7empty finite sequence of agents (i ,...,i ). The length of the chain (i ,...,i ) is n. Moreover,
1 n 1 n
an order ⪯ on a set of chains Θ is defined as a partial order satisfying the following conditions:
• θ ⪯θ′ for θ′ =θ·θ′′ or θ =θ′;
• θ ⪯θ′andθ′ ⪯θforθ =(i ,...,i ,i ,...i )suchthati =i ,andθ′ =(i ,...,i ,...i ),
1 k k+1 n k k+1 1 k n
where θ,θ′,θ′′ ∈ Θ, and · refers to a concatenation of sequences. The condition of θ ⪯ θ′ and
θ′ ⪯θ isdenotedasθ ≃θ′. Anorder≺isdefinedintheusualway: θ ≺θ′ iff θ ⪯θ′ andθ′ ̸⪯θ.
The second condition means that if the same agent sequentially occurs in a chain θ, it is said to
be symmetric to the chain in which one of the agents is removed θ′. For instance, if θ =(a,b,c)
and θ′ =(a,b), then θ′ ≺θ; if θ =(a,b,b) and θ′ =(a,b), then θ ≃θ′, even though θ ̸=θ′.
Next, we define the language. Let P be a countable set of atomic propositions, G be a finite
set of agents, and Θ be a finite set of chains of belief for awareness. The language L is
(P,G,Θ)
the set of formulas generated by the following grammar:
L ∋φ::=p|¬φ|φ∧φ|I φ|[≈] φ|C φ|△ φ,
(P,G,Θ) i θ θ θ
where p ∈ P, i ∈ G, θ ∈ Θ, △ ∈ {A,K}, and for △ , if the form of △ ψ occurs in φ, then
θ θ′
θ ⪯ θ′. Other logical connectives ∨, →, and ↔ are defined in the usual manner. A , I , and
θ i
E are called an awareness operator, an implicit knowledge operator, and an explicit knowledge
θ
operator respectively. Let θ be (i ,...,i ). Notationally,
1 n
• A φ reads “i believes ··· i believes that i is aware of φ.”
(i1,...,in) 1 n−1 n
• I φ reads “i knows φ implicitly.”
i
• E φreads“imaginaryi withtheawarenessthati believes··· i believesthat
(i1,...,in) n 1 (n−1)
i has explicitly knows φ.”
n
The operators [≈] and C are special operators. These are used to define explicit knowledge
θ θ
and used in proofs in a later section. The operator [≈] can be interpreted as an operator
(i1,...,in)
that refers to true information in all the worlds where imaginary i with the awareness that
n
i believes ··· i believes that i has does not distinguish. The operator C can be
1 (n−1) n (i1,...,in)
interpretedasanoperatorthatreferstoakindofi ’simplicitknowledge. Asthedifferencefrom
n
8I operator, I refers to i’s knowledge that i can obtain in the case where i is aware of all the
i i
propositions. On the other hand, C refers to imaginary i ’s knowledge in the case where
(i1,...,in) n
she is only aware of what i believes ··· i believes that she has. Besides, “the awareness
1 (n−1)
that i believes ··· i believes that i has” is simpliy denoted by “with the awareness of θ.”
1 (n−1) n
We take up some formulas to understand the language and the meanings of operators. The
formula E p is an element of the language and means “i explicitly knows p.” The formula
(i)
E E pisalsoanelementandmeams“iexplicitlyknowsthatimaginaryj withtheawareness
(i) (i,j)
of (i) explicitly knows p,” which is “i explicitly knows that j explicitly knows p.” By contrast,
E E pisnotanelementofthelanguage. Itmeans“iexplicitlyknowsthatimaginaryk with
(i) (j,k)
theawarenessof(j)explicitlyknowsp.” Althoughwhatfollowsthefirst“that”shouldunfoldin
i’smind,itunfoldsonlyinj’smind. Oursyntaxisdesignedtoremovesuchstrangepropositions.
2.2 Semantics
We move on to define the semantics. The semantics are given in the Kripke-style. It has the
standard Kriple model for knowledge and is based on the awareness structure [3]. We extend
an awareness set and the equivalence relation in [16] with a chain of belief for awareness and
incorporate to a model.
Definition1. AnepistemicmodelwithawarenessM isatuple⟨W,{∼ } ,V,{A } ⟩,where:
i i∈G θ θ∈Θ
• W is a non-empty set of possible worlds;
• ∼ is an equivalence relation on W;
i
• V :P →2W;
• A is a non-empty set of atomic propositions satisfying the condition:
θ
– If θ′ ⪯θ, then A ⊆A for every θ′ ∈Θ.
θ θ′
The part of ⟨W,{∼ } ,V⟩ is a Kripke model that corresponding to S5. A set A is called an
i i∈G θ
awareness set of θ. Let θ be (i ,...,i ), and A represents a set of propositions of which
1 n (i1,...,in)
i believes ··· i believes that the last member i is aware. The condition in the definition
1 (n−1) n
of an awareness set means that if a chain θ is greater than equal to another chain θ′, then the
9awareness set of θ′ is included in the awareness set of θ. This reflects an intuition that i should
be aware of all the propositions of which i believes that j is aware or imaginary j in i’s mind is
aware. As for the pair A and A , we may need to supplementary explain. In this case,
(i,i) (i·θ·j)
A ⊆ A holds because (i) ≃ (i,i) ≺ (i·θ·j) by the definition of the order. In the case
(i·θ·j) (i,i)
of a symmetric order between θ and θ′, the two awareness sets of θ or θ′ are identical. The pair
(M,w) with M and w ∈W is called a pointed model.
We define another equivalence relation to formalize the effect of an agent’s awareness on her
own reasoning. The relation is given depending on an epistemic model with awareness.
Definition 2. For each θ, a relation ≈ on W is defined by (w,v)∈≈ iff, w ∈V(p) iff v ∈
θ θ
V(p) for every p∈A .
θ
Therelation≈ iscalledtheindistinguishable relation ofθ. Therelationoccursbetweenpossible
θ
worlds with different valuations only for unaware propositions. It means the relation appears or
disappears in conjunction with an awareness set. It is one of the properties between the relation
and an awareness set that A ⊆A implies ≈ ⊆≈ . The last member with the awareness of
θ θ′ θ′ θ
θ cannot distinguish such possible worlds because of her lack of awareness. This relation is an
equivalence relation and constructs partitions on W. Possible worlds collapsed by the relation
as one equivalence class can be interpreted as one world for the last member with the awareness
of θ.
Next,wemoveontodefinethesatisfactionrelation. Beforethedefinition,weintroducesome
notations: a set At(φ) denotes the set of atomic propositions that occur in φ; a relation ∼ ◦≈
i θ
denotes a sequential composition of ≈ and ∼ ; for a binary relation R, a relation R+ denotes
θ i
the transitive closure of R. The closure R+ is the smallest set such that R ⊆ R+, and for all
x,y,z, if (x,y)∈R+ and (y,z)∈R+, then (x,z)∈R+.
Definition 3. For any epistemic models with awareness M and possible worlds w ∈ W, a
10satisfaction relation ⊨ is given as follows:
M,w ⊨p iff w ∈V(p);
M,w ⊨¬φ iff M,w ⊭φ;
M,w ⊨φ∧ψ iff M,w ⊨φ, and M,w ⊨ψ;
M,w ⊨A φ iff At(φ)⊆A ;
θ θ
M,w ⊨I φ iff M,v ⊨φ for all v such that (w,v)∈∼ ;
i i
M,w ⊨[≈] φ iff M,v ⊨φ for all v such that (w,v)∈≈ ;
θ θ
M,w ⊨C φ iff M,v ⊨φ for all v such that (w,v)∈(∼ ◦≈ )+;
θ i θ
M,w ⊨E φ iff M,w ⊨A φ, and M,w ⊨C φ,
θ θ θ
From Definition 1, if both an indistinguishable relation ≈ and an accessibility relation ∼ is
θ i
an equivalence relation, (∼ ◦≈ )+ is also an equivalence relation. This is because the reverse
i θ
direction on the composition is also reachable, although it consumes a few extra steps. Thus,
(∼ ◦≈ )+ gives a new partition of possible worlds. This partition corresponds to imaginary i’s
i θ
reasoning limited by the awareness of θ. We can formalize knowledge taking into account the
propositions of which the agent is aware. We can also find that [≈] I φ corresponds to ∼ ◦≈ .
θ i i θ
In contrast, this relation is not equivalent, unlike its transitive closure.
The validity is defined in the usual way.
Definition 4. A formula φ is valid at M, if φ holds at every pointed model M,w in M, which
is denoted by M ⊨ φ. A formula φ is valid if φ holds at every pointed model M,w, which is
denoted by ⊨φ.
Note that there are local and global definitions of an awareness set. The former defines
an awareness function that takes a possible world as an argument and changes elements of
an awareness set for each possible world. The latter defines an awareness set as the same in all
possibleworlds. Generally,astateofanagent’sawarenessshouldbefixedwithinasetofpossible
worlds that she considers. The global definition is used in the logic that does not consider the
outside of a specific agent’s accessible worlds, such as a single-agent case. On the other hand,
a local definition is used to represent possible worlds outside of an agent’s accessible worlds. It
is possible to express that a state of an agent’s awareness differs between the agent and another
11agent.
Ourlogicadoptstheglobalone. Byincorporatingthenotionofachainofbeliefforawareness,
it is possible to represent the advantage of the local definition: to express a state of an agent’s
awareness that another agent thinks may differ from that of the agent’s actual awareness. This
is because a state of an agent’s awareness is separately set for each agent. However, another
feature of the local one is not represented in our logic. A situation where an agent does not
haveanybeliefatallmaybeinteresting. Knowledgeinsuchasituationisonlyforthelocalone.
In order to consider such a situation, we can modify the definition of an awareness set into an
awareness function in our logic.
2.3 Properties
In this section, we discuss some properties of our logic.
Asourlogictreats“awarenessof,”thepropertyof“awarenessof”issatisfied[20]: ifanagent
is aware of atomic propositions, she is aware of more complex formulas produced by the atomic
propositions. This means if an agent is aware of φ, that is, she can refer to φ, then she is also
aware of ¬φ.
• ⊨A φ↔A ¬φ,
θ θ
• ⊨A (φ∧ψ)↔A φ∧A ψ,
θ θ θ
• ⊨A φ↔A A φ,
θ θ θ′
• ⊨A φ↔A [≈] φ,
θ θ θ′
• ⊨A φ↔A C φ,
θ θ θ′
• ⊨A φ↔A I φ,
θ θ i
• ⊨A φ↔A K φ.
θ θ θ′
Because of the definition of an awareness set, when a sequential iteration of an agent occurs
inachain, theawarenesssetofthechainisthesameastheawarenesssetofthechainwherethe
iterated part is removed.
12• ⊨A φ↔A φ.
(i,j,j) (i,j)
• ⊨[≈] φ↔[≈] φ.
(i,j,j) (i,j)
• ⊨E φ↔E φ.
(i,j,j) (i,j)
Thethirdformulameansthatexplicitknowledgeofj withtheawarenessthatibelievesj believes
that j has equals to explicit knowledge of j with the awareness that i believes that j has.
We can also say:
• ⊨A φ→A φ,
(i,j,k) (i,j)
• ⊨[≈] φ→[≈] φ,
(i,j,k) (i,j)
• ⊭E φ→E φ.
(i,j,k) (i,j)
Thefirstandsecondexpressionsarenatural. Thisisbecausethepropositionsofwhichibelieves
j believesthatkisawarenecessarilyarethoseofwhichibelievesthatj isaware. Incontrast,the
third formula is not valid. Accessibility relations do not change in conjunction with awareness
sets. Even if the indistinguishable relation of (i,j,k) includes indistinguishable of (i,j), the
formula can be false at some worlds accessible on j’s accessibility relation from the evaluate
world.
In logic of awareness, it is regarded that the negative introspection for unawareness holds,
whichmeansanagentneverknowsanypropositionofwhichtheagentisnotaware. Ourlogichas
the property because explicit knowledge of a proposition requires awareness of the proposition.
• ⊨¬E ¬A φ.
θ θ
As for implicit knowledge, the formula L ¬A φ may be true.
θ θ
To understand nested knowledge in our logic, we also give some formulas.
• ⊭E φ→E E φ,
(i,j) (i) (i,j)
• ⊨E E φ→E φ.
(i) (i,j) (i,j)
This means that i’s explicit knowledge that imaginary j with the awareness of (i,j) explicitly
knows φ knows coincides with the explicit knowledge of imaginary j with the awareness that i
13believes that j has. Our logic distinguishes the sentence that i explicitly knows that j explicitly
knows φ from the sentence that j with the awareness that i believes j has explicitly knows φ.
As stated in Section 1, our explicit knowledge operator has properties of knowledge in EL.
• ⊨E E φ→E φ,
(i) (i,j) (i,j)
• ⊭E E φ→E φ,
(i) (i,j) (j)
• ⊨¬E φ→¬E φ.
(i) (i,j,i)
ThefirstformulaisTaxiominmodallogic,whichisapropertyofknowledgeinEL. Thesecond
formuladoesnotholdbecauseifiexplicitlyknowsthatj explicitlyknowsφ,thatdoesnotmean
that j herself explicitly knows φ. However, that means that imaginary j with the awareness in
i’s belief in j’s belief explicitly knows φ as the first expression shows. The third formula means
if a does not explicitly know p, then an imaginary a with the state of a’s awareness in b’s mind
in a’s mind does not explicitly know p. The set of imaginary the state of a’s awareness in b’s
mind in a’s mind should be smaller than the set of what a herself is aware of.
Asforimplicitknowledge, ithasthesamepropertiesasthenecessityoperatorinmodallogic
S5, such as I φ → φ, I φ → I I φ, and ¬I φ → I ¬I φ. The relation between I operator and
i i i i i i i i
C operator stated in syntax is represented as C φ→I φ.
θ θ i
2.4 Formalization of The Example
This subsection gives the formalization of the example introduced in Section 1 with our logic.
Let Θ be {(a),(b),(a,b),(b,a),(a,b,a)}. In the example, only a is aware of all the atomic
propositions. Formally, we write A = {p ,p ,q}, and A = {p ,p }. Owner a believes
(a) a b (b) a b
that b is also aware of the wholesaler, which is formalized as A = {p ,p ,q}. By con-
(a,b) a b
trast, b believes that a is not aware of the wholesaler as well as herself, which is formal-
ized as A = {p ,p }. Finally, a believes b believes that a is not aware of the whole-
(b,a) a b
saler, which is formalized as A = {p ,p }. Then, there are indistinguishable relations
(a,b,a) a b
≈ , ≈ , and ≈ between possible worlds with different valuation only for q. Formally,
(b) (b,a) (a,b,a)
≈ =≈ =≈ ={(w ,w ),(w ,w ),(w ,w ),...,(w ,w )} in Figure 2.
(b) (b,a) (a,b,a) 1 2 2 1 1 1 5 5
14InFigure2,theequivalenceclassesoftheindistinguishablerelation≈ ,whichisthesame
(a,b,a)
as≈ and≈ ,arerepresentedbythelightgreybackground. Byinterpretingtheequivalence
(b) (b,a)
class as one possible world for a with the awareness of (a,b,a), the figure represents the same
graph as the Kripke model that is only for p and p (Figure 3), in terms of possible worlds and
a b
accessibility relations.
In the model M in Figure 2, all the formulas are consistent with each knowledge stated in
Section1. Amongthose,wefocusona’snestedknowledgehere,whichis1:E q →E p ,and
(a) (a) b
2:E E ¬E p . Thisknowledgeisseeminglycontradictory,buttheycorrectlyrepresent
(a) (a,b) (a,b,a) b
the knowledge of agents with a different awareness.
• M ⊨E q →E p
(a) (a) b
• M ⊨E E ¬E p
(a) (a,b) (a,b,a) b
As for 1, it is vacuously true in the other worlds than w . Since p ∈ A a), w is only world
1 b ( 1
reachable on ∼ and ≈ from w , and p is true in w , then E q → E p is true for all
(a) (a) 1 b 1 (a) (a) b
worlds. Asfor2,theformulaintheotherworldsthanw requiresthatp istrueinalltheworlds
1 b
because all the worlds are reachable on three relations ∼ , ∼ , ≈ . Moreover, w , where p
a b (a,b,a) 3 b
is false, is reachable on ≈ from w . Thus, E E ¬E p is true for all worlds.
(a,b,a) 1 (a) (a,b) (a,b,a) b
Our logic ALPC correctly represented both owners’ explicit knowledge including nested one
in the example. We can say that this logic is one of formalizations to represent and analyze
nested explicit knowledge.
3 Hilbert System of ALPC
We move on to the proof theory for our logic. The Hilbert system of ALPC is given in Table
1. Axiom AN, ACN, AA, AL, A[≈], ACM, and AK mean that if an agent is aware of atomic
propositions, the agent is aware of more complex formulas produced by the atomic propositions
and correspond to the notion of “awareness of.” Axiom AI corresponds to the condition in the
definition of an awareness set. Axiom KA and NKA reflect the global definition of an awareness
set. For K ,T ,5 ,K ,T , and 5 , we adopt K,T, and 5 in modal logic. 5 called negative
L L L [≈] [≈] [≈] L
introspection in EL means that an agent always knows what the agent does not know. This
15p p p p p ¬p
a b a b a a b
q ¬q ¬q
p a p b a p a ¬p b
w w w
1 2 3
b b w′ w′
1 2
b b
¬p p ¬p ¬p
a b a a b
¬q ¬q
¬p a p b a ¬p a ¬p b
w w
4 5
w′ w′
3 4
Figure2: Atwomulti-agentmodelwhereasetof
possibleworldsis{w ,w ,w ,w ,w }. Reflexive
1 2 3 4 5 Figure 3: A model only concering p and p
a b
arrows are omitted. Grey backgrounds refer to
equivalence classes of ≈ .
(a,b,a)
axiom also characterizes logical omniscience. In our logic, as with most logics of awareness, this
formula does not hold for an explicit knowledge operator. Instead, ¬E φ∧A ¬E φ→E ¬E φ
θ θ θ θ θ
is valid. K ,IND, and MIX are based on axioms of logic with common knowledge because both
C
logics use a transitive closure. KAC corresponds to the constitution of E φ on the satisfaction
θ
relation, which is explicit knowledge is the knowledge that meets a kind of implicit knowledge
represented by C and an aware proposition.
θ
Definition 5. A system ALPC is a set of formulas that contains the axioms in Table 1 and is
closed under inference rules in the table. We write ⊢φ if φ∈ ALPC. Let Γ be a set of formulas
in L and (cid:86) Γ be an abbreviation of (cid:86) φ. If there is a finite subset Γ′ of Γ such that
(P,G,Θ) φ∈Γ
⊢(cid:86) Γ′ →φ, we write Γ⊢φ and call it that φ is deducible from Γ.
3.1 Soundness
We prove that all the theorems are valid, which is the soundness of the logic.
Theorem 1. If ⊢φ, then ⊨φ.
Proof. We prove it for any formulas by induction on the structure of ALPC. First, we prove
that all the axioms are valid. For I and [≈] , it is proven in a similar way in S5 because both
i θ
accessibility relations and indistinguishable relations are equivalence relations. For A , we show
θ
16Table 1: Table 1: Axiom schemas and inference rules of ALPC
Axiom schemata
TAUT The set of propositional tautologies
AN A φ↔A ¬φ
θ θ
ACN A (φ∧ψ)↔A φ∧A ψ
θ θ θ
AA A φ↔A Aθ′φ
θ θ j
AL A φ↔A I φ
θ θ j
A[≈] A φ↔A [≈]θ′φ
θ θ j
ACM A φ↔A Cθ′φ
θ θ j
AK A φ↔A Kθ′φ
θ θ j
AN[≈] A p∧p→[≈] p
θ θ
AI A φ→A φ
θ θ′
(cid:86)
KA A φ→ C A φ
θ θ′∈Θ θ′ θ
(cid:86)
NKA ¬A φ→ C ¬A φ
θ θ′∈Θ θ′ θ
K I (φ→ψ)→(I φ→I ψ)
L i i i
T I φ→φ
L i
5 ¬I φ→I ¬I φ
L i i i
K [≈] (φ→ψ)→([≈] φ→[≈] ψ)
[≈] θ θ θ
T [≈] φ→φ
[≈] θ
5 ¬[≈] φ→[≈] ¬[≈] φ
[≈] θ θ θ
K C (φ→ψ)→(C φ→C ψ)
C θ θ θ
MIX C φ→φ∧[≈] I C φ
θ θ i θ
IND C (φ→[≈] I φ)→(φ→C φ)
θ θ i θ
KAC E φ↔A φ∧C φ
θ θ θ
Inference Rules
MP If ⊢φ and ⊢φ→ψ, then ⊢ψ
LG If ⊢φ then ⊢I φ
i
[≈]G If ⊢φ then ⊢[≈] φ
θ
CG If ⊢φ then ⊢C φ
θ
only AN and AN[≈] here. Axioms ACN, AA, AL, A[≈], ACM, and AK are proven in the same
way as these two axioms. For AI, KA, and NKA, it is proven quickly from the definition. For
KAC, the proof is trivial.
• For AN, suppose that M,w ⊨ A φ, then At(φ) ⊆ A . Since At(φ) = At(¬φ), At(¬φ) ⊆
θ θ
A . Thus, M,w ⊨A ¬φ. The reverse direction is proven similarly.
θ θ
• For AN[≈], suppose that M,w ⊨ A p∧p, then p ∈ A and w ∈ V(p). We consider an
θ θ
arbitaryv suchthatforeveryatomicpropositionq ∈A , w ∈V(q)ifandonlyifv ∈V(q).
θ
From the assumptions, M,v ⊨p. Thus, M,w ⊨[≈] p.
θ
• For K , suppose that M,w ⊨ C (φ → ψ) and M,w ⊨ C φ. For all v such that (w,v) ∈
C θ θ
17(∼ ◦≈ )+, M,v ⊨φ→ψ and M,v ⊨φ. M,v ⊨ψ. Thus, M,w ⊨C ψ.
i θ θ
• For MIX, suppose that M,w ⊨ C φ. Since (∼ ◦≈ )+ is equivalent and the transitive
θ i θ
closure, M,w ⊨φ∧[≈] I C φ.
θ i θ
• For IND, suppose that M,w ⊨ C (φ → [≈] I φ) and M,w ⊨ φ, then for all v such that
θ θ i
(w,v)∈(∼ ◦≈ )+,M,v ⊨φ→[≈] I φ. Thus,M,w ⊨[≈] I φ. φholdsatallthepossible
i θ θ i θ i
worlds from w on ∼ ◦≈ , and [≈] I φ holds even at that worlds. Therefore, M,w ⊨C φ.
i θ θ i θ
The remaining task is to prove that if the assumptions are valid, they are also valid for all the
inference rules. All of them are straightforward.
3.2 Completeness
We prove the reverse direction: all the valid formulas are the theorems. We use the idea of
a canonical model in the proof on modal logic [2]. In ALPC, we can take a set of formulas,
such as Φ = {([≈] I )nφ | n ∈ N}∪{¬C φ} for each θ ∈ Θ, where ([≈] I )n is n iterations of
θ i θ θ i
[≈] I . Therefore, our logic is no longer compact. It is necessary to restrict a canonical model to
θ i
a specific set of formulas. This technique is used in the proof on logic with common knowledge
defined by the reflexive-transitive closure of relations. We customize the tools and techniques in
[26] for our logic in a similar to [16]. Moreover, we cannot construct a unique canonical model,
unlike the standard strategy on modal logic. Because of the global definition, the truth value
of A φ is the same within the domain in a model, and then we construct multiple models with
θ
different domains based on the idea of a canonical model, called divided models.
It is necessary to restrict a maximal consistent set used in constructing a divided model to a
specific set of formulas. At first, we define a closure as a restricted set of formulas.
Definition 6. Let cl : L → 2L be the function such that for every φ ∈ L, cl(φ) is the smallest
set satisfying that:
1. φ∈cl(φ);
2. If ψ ∈cl(φ) then sub(ψ)⊆cl(φ), where sub(ψ) is the set of subformulas of ψ;
3. If ψ ∈cl(φ) and ψ is not a form of negation, then ¬ψ ∈cl(φ);
184. If A ψ ∈cl(φ), then C A ψ,C ¬A ψ ∈cl(φ) for each chain θ′ ∈Θ;
θ θ′ θ θ′ θ
5. If A ψ ∈cl(φ), then [≈] p,A χ,A ψ ∈cl(φ) for each chain θ′ ∈Θ, where χ∈sub(ψ) and
θ θ θ θ′
p is an atomic proposition in cl(φ);
6. If I ψ ∈sub(φ), then I I ψ, I ¬I ψ ∈cl(φ);
i i i i i
7. If [≈] ψ ∈sub(φ), then [≈] [≈] ψ, [≈] ¬[≈] ψ ∈cl(φ);
θ θ θ θ θ
8. If C ψ ∈cl(φ), then [≈] I C ψ ∈cl(φ);
θ θ i θ
9. If I C ψ ∈cl(φ), then I I C ψ, I ¬I C ψ ∈cl(φ);
i θ i i θ i i θ
10. If [≈] I C ψ ∈cl(φ), then [≈] [≈] I C ψ ,[≈] ¬[≈] I C ψ ∈cl(φ);
θ i θ θ θ i θ θ θ i θ
11. If E ψ ∈cl(φ), then A ψ, C ψ ∈cl(φ).
θ θ θ
Lemma 1. For every φ, cl(φ) is finite.
Proof. We prove it by induction on the structure of cl(φ). It is easily provable for all the
conditions because a set of agent P and a set of chains Θ is finite.
We define a consistent set and a maximal consistent set in a closure. A set of the latter is
used as a domain of a divided model.
Definition 7. Let Φ be the closure of a formula. Γ is a consistent set in Φ iff
• Γ⊆Φ,
• Γ⊬⊥.
Moreover, Γ is a maximal consistent set in Φ iff
• Γ is a consistent set,
• There is no Γ′ ⊆Φ such that Γ⊂Γ′ and Γ′ ⊬⊥.
We prove that a consistent set can always expand a maximal consistent set that includes the
original set.
19Lemma 2. Let Φ be the closure of a formula. If Γ is a consistent set in Φ, then there exists a
maximal consistent set ∆ in Φ such that Γ⊆∆.
Proof. It is proven in the same way as Lindenbaum’s lemma. We obtain a maximal consistent
set by adding formulas in Φ to Γ so as to preserve the consistency.
Furthermore, we prove a corollary of Lemma 2.
Lemma 3. Let Φ be the closure of a formula. For every φ ∈ Φ, Γ ⊢ φ iff φ ∈ ∆ for every
maximal consistent set ∆ in Φ such that Γ⊆∆.
Proof. From left to right, suppose that Γ⊢φ, Γ⊆∆, and ∆∈W∗. There exists a finite subset
Λ
Γ′ ⊆ Γ such that ⊢ (cid:86) Γ′ → φ. Since Γ ⊆ ∆ and ∆ is a maximal consistent set, φ ∈ ∆. From
right to left, we prove it by contraposition. It is sufficient to prove that if Γ ⊬ φ, then there
exists a maximal consistent set ∆ such that Γ ⊆ ∆ and φ ̸∈ ∆. By the assumption, Γ∪{¬φ}
is consistent set in Φ. Thus, we obtain a maximal consistent set ∆ in Φ such that Γ ⊆ ∆ and
φ̸∈∆ by Lemma 2.
In this paper, we have adopted the global definition. This means that we cannot construct
the unique canonical model with the domain that is the whole set of maximal consistent sets.
We need to divide the whole set into some groups so that the truth value of A φ is the same
θ
within the group. At first, we define a base model restricted by a set of formulas.
Definition8. LetΦbetheclosureofaformula. ThebasemodelM∗ forΦisatuple⟨W∗,{(∼ )∗} ,V∗⟩,
i i∈G
where:
• W∗ :={Γ|Γ is a maximal consistent set in Φ},
• (Γ,∆)∈(∼ )∗ iff {φ|I φ∈Γ}⊆∆,
i i
• V∗(p):={Γ|p∈Γ}.
We define a relation (≈ )∗ on the model M∗ for a closure.
θ
Definition 9. Let Φ be the closure of a formula. For each θ ∈ Θ, a relation (≈ )∗ on W∗ is
θ
defined by (Γ,∆)∈(≈ )∗ iff {φ|[≈] φ∈Γ}⊆∆.
θ θ
20Now,wearereadytodefineadividedmodelforasetofformulas. Adividedmodelisdefined
as the model generated by a maximal consistent set from the base model for a set of formulas.
Definition 10. Let Φ be the closure of a formula and Λ be a maximal consistent set in Φ. The
divided model M∗ by Λ for Φ is a tuple ⟨W∗,{(∼ )∗} ,V∗,{(A )∗} ⟩, where:
Λ Λ i Λ i∈G Λ θ Λ θ∈Θ
• W∗ :={Γ|Γ is a maximal consistent set in Φ, and (Λ,Γ)∈(cid:83) ((∼ )∗◦(≈ )∗)+};
Λ i∈G,θ∈Θ i θ
• (∼ )∗ :=(∼ )∗∩(W∗×W∗);
i Λ i Λ Λ
• V∗(p):=V∗(p)∩W∗;
Λ Λ
• (A )∗ :={p|for all Γ∈W∗,A p∈Γ};
θ Λ Λ θ
We prove that every divided model for Closures is an epistemic model with awareness.
Lemma 4. Let Λ be a maximal consistent set in Φ. For every φ, each divided model by Λ for
the closure of φ is an epistemic model with awareness.
Proof. We prove that each divided model for the closure of φ satisfies the definition of an epis-
temic model with awareness. For W∗ and V∗, the proofs are trivial.
Λ Λ
• For (∼ )∗, it can be proven in a similar way as S5. For reflexivity, it is sufficient to prove
i Λ
(w,w) ∈ (∼ )∗ for all w ∈ W∗. It follows from K . For symmetricity, it is sufficient to
i Λ Λ T
prove that for all w,v ∈W, if (w,v)∈(∼ )∗, then (v,w)∈(∼ )∗. It follows from T and
i Λ i Λ L
5 . For transitivity, it is sufficient to prove that for all w,v,u∈W∗, if (w,v)∈(∼ )∗ and
L Λ i Λ
(v,u) ∈ (∼ )∗, then (w,u) ∈ (∼ )∗. It follows through I φ → I I φ from K ,T ,5 , and
i Λ i Λ i i i L L L
LG.
• For (A )∗, it is sufficient to prove that for every θ′ ∈ Θ, if θ′ ⪯ θ, then (A )∗ ⊆ (A )∗,
θ Λ θ Λ θ′ Λ
which means that for all w, if A p∈w, then A p∈w. Suppose that A p∈w. It follows
θ θ′ θ
that A p∈w from AI.
θ′
Moreover, we also define a relation (≈ )∗ on a divided model M∗ for a closure Φ similarly.
θ Λ Λ
Definition 11. Let Φ be the closure of a formula. For each θ ∈ Θ, a relation (≈ )∗ on W∗ is
θ Λ Λ
defined as (≈ )∗ ∩(W∗×W∗).
θ Λ Λ Λ
21Lemma 5. A relation (≈ )∗ on each divided model is an indistinguishable relation ≈ on an
θ Λ θ
epistemic model with awareness.
Proof. At first, it is needed to prove that (≈ )∗ is an equivalence relation. This is proven in
θ Λ
the same way as (∼ )∗ because both relations are defined essentially in the same way and both
i Λ
operators have the axioms corresponding to K,T, and 5. It is sufficient to prove that for all
(w,v)∈(≈ )∗ and every p∈(A )∗, if w ∈V∗(p), then v ∈V∗(p), and vice versa. From left to
θ Λ θ Λ Λ Λ
right, suppose that w ∈ V∗(p) for every p ∈ (A )∗. Thus, A p ∈ w because of the definition of
Λ θ Λ θ
(A )∗. It follows that p∈v from AN[≈]. The reverse direction is proven by using that (≈ )∗ is
θ Λ θ Λ
an equivalence relation.
The next task is to define a (C ) -path on a divided model M∗ for a closure.
θ Λ Λ
Definition 12. Let Φ be the closure of a formula. A (C ) -path from Γ is a sequence Γ ,...,Γ
θ Λ 0 n
of maximal consistent sets in Φ such that (Γ ,Γ ) ∈ (∼ )∗ ◦(≈ )∗ for all k, where i is the
k k+1 i Λ θ Λ
last member of θ, 0≤k ≤n, and Γ =Γ. The length of Γ ,...,Γ is n. A φ-path is a sequence
0 0 n
Γ ,...,Γ of maximal consistent sets in Φ such that φ∈Γ for all k, where 0≤k ≤n.
0 n k
Lemma 6. Let Φ be the closure of a formula; M∗ be a divided model for Φ; Γ, ∆ be maximal
Λ
consistent sets in W∗; i be the last member of θ. If (cid:86) Γ ∧ ¬[≈] I ¬(cid:86) ∆ is consistent, then
Λ θ i
(Γ,∆)∈((∼ )∗ ◦(≈ )∗) for each divided model M∗ for Φ.
i Λ θ Λ Λ
(cid:86) (cid:86)
Proof. It is sufficient to prove that we suppose that Γ∧¬[≈] I ¬ ∆ is consistent and [≈
θ i
] I φ ∈ Γ for every φ, and we obtains φ ∈ ∆. We prove it by the contradiction. By the
θ i
(cid:86)
assumptions,[≈] I φ∧¬[≈] I ¬ ∆isconsistent. Supposethatφ̸∈∆,then¬φ∈∆. Itfollows
θ i θ i
that [≈] I φ∧¬[≈] I φ is consistent. This is the contradiction. Thus, φ∈∆.
θ i θ i
Lemma 7. Let Φ be the closure of a formula and M∗ be a divided model for Φ. If C φ∈Φ and
Λ θ
Γ∈W∗, then C φ∈Γ iff every (C ) -path from Γ is a φ-path and a C φ-path.
Λ θ θ Λ θ
Proof. (⇒) We prove it by induction on the length of a (C ) -path.
θ Λ
• For the base case, suppose that the length of a (C ) -path is 0, C φ ∈ Φ, and C φ ∈ Γ.
θ Λ θ θ
Γ=Γ =Γ . By MIX, φ∈Γ.
0 n
22• For induction steps, suppose that the length of a (C ) -path is k + 1, C φ ∈ Φ, and
θ Λ θ
C φ ∈ Γ. By the induction hypothesis, C φ ∈ Γ . From MIX and the definition of (∼ )∗
θ θ k i Λ
and (≈ )∗, it follows that φ and C φ∈Γ .
θ Λ θ k+1
(⇐)LetS((C ) ,φ)beasetofmaximalconsistentsets∆inW∗ suchthatevery(C ) -path
θ Λ Λ θ Λ
from ∆ is a φ-path. We introduce a special formula:
(cid:95) (cid:94)
χ= ∆.
∆∈S((Cθ)Λ,φ)
Suppose that every (C ) -path from Γ is a φ-path. First, we need to prove these three:
θ Λ
(cid:94)
(1) ⊢ Γ→χ; (2) ⊢χ→φ; (3) ⊢χ→[≈] I χ,
θ i
where i is the last member of θ.
• For (1), Γ∈S((C ) ,φ) by the assumption. Thus, ⊢(cid:86) Γ→χ.
θ Λ
• For (2), since every (C ) -path from ∆ is a φ-path, φ ∈ ∆ for every ∆ ∈ S((C ) ,φ).
θ Λ θ Λ
Thus, φ is derived from χ.
• For(3), weproveitbycontradiction. Supposeχ∧¬[≈] I χisconsistent. Bytheconstruc-
θ i
tion of χ, there exists ∆ such that (cid:86) ∆∧¬[≈] I χ is consistent. W∗ can be interpreted as
θ i Λ
the whole set of combinations of formulas in Φ that satisfies the condition, and χ can be
(cid:87) (cid:86)
interpretedasaparticularsetofcombinations. Theformula¬ Λisequiv-
Λ∈W Λ∗\S(Cθ,φ)
alent to χ because the negation of the other combinations can represent a particular set of
(cid:86) (cid:87) (cid:86)
combinationsrepresentedbyχ. Therefore, ∆∧¬[≈] I ¬ Ξisconsistent.
θ i Ξ∈W Λ∗\S(Cθ,φ)
ThereisΞsuchthat(cid:86) ∆∧¬[≈] I ¬(cid:86) Ξisconsistent. ByLemma6,(∆,Ξ)∈(∼ )∗◦(≈ )∗
θ i i Λ θ Λ
for every divided model M∗. There exists a (C ) -path from ∆ that is not a φ-path. This
Λ θ Λ
is a contradiction. Thus, ⊢χ→[≈] I χ.
θ i
By (3) and CG, ⊢ C (χ → [≈] I χ). It follows that ⊢ χ → C χ from IND. By (1) and (2),
θ θ i θ
(cid:86)
⊢ Γ→C φ. Thus, C φ∈Γ.
θ θ
The next task is the proof of the truth lemma, which is that for every divided model, a true
formula at a world in a model is included in the world.
23Lemma 8. Let Φ be the closure of a formula and M∗ be a divided model for Φ. For all w ∈W∗
Λ Λ
and every φ∈Φ, M∗,w ⊨φ iff φ∈w.
Λ
Proof. Weproveitbyinductiononthestructureofformulas. Proofsofthebasecaseandlogical
connectives are straightforward.
• For the case of A φ, we prove it by induction on the structure of φ.
θ
– For the base case, suppose that M∗,w ⊨ A p, then p ∈ {q | for all w,A q ∈ w}.
Λ θ θ
Thus, A p∈w. As for the reverse direction, suppose that A p∈w. From KA,NKA,
θ θ
(cid:86) C A p ∈ w. It follows that for all v in W∗, A p ∈ v from MIX. Thus,
θ′∈Θ θ′ θ Λ θ
M∗,w ⊨A p.
Λ θ
– For the other cases, we obtain the desired proof by induction hypothesis and decom-
posingtheformulausingcorrespondingaxioms: AN,ACN,AA,AL,A[≈],ACM,and
AK. We show the strategy by taking AN as an example.
∗ For the case of ¬ψ, suppose that M∗,w ⊨ A ¬ψ, which means that At(¬ψ) ⊆
Λ θ
{q | for all w,A q ∈ w}. Since At(¬ψ) = At(ψ), M∗,w ⊨ A ψ. A ¬ψ ∈ w by
θ Λ θ θ
induction hypothesis and AN. The reverse direction is proven similarly.
• For the case of I φ and [≈] φ, it is proven in a similar strategy as S5. We show only the
i θ
case of I φ here. From left to right, suppose that M∗,w ⊨I φ, which means that for all v
i Λ i
such that {ψ | I ψ ∈ w} ⊆ v, M∗,v ⊨ φ. By induction hypothesis, it follows that for all
i Λ
v such that {ψ | I ψ ∈ w} ⊆ v, φ ∈ v. By Lemma 3, {ψ | I ψ ∈ w} ⊢ φ. There exists a
i i
finite subset {ψ ,...,ψ } of {ψ |I ψ ∈w} such that ⊢(ψ ∧···∧ψ )→φ. It follows that
1 n i 1 n
⊢ (I ψ ∧···∧I ψ ) → I φ from LG and K . Since a set {I ψ ,...,I ψ } is included in
i 1 i n i L i 1 i n
w, w ⊢I φ. Thus, I φ∈w. The reverse direction is straightforward.
i i
• ForthecaseofC ,supposethatM∗,w ⊨C φ. Forallvsuchthat(w,v)∈((∼ )∗◦(≈ )∗)+,
θ Λ θ i Λ θ Λ
M∗,v ⊨φ. It means every (C ) -path from w is a φ-path. By Lemma 7, C φ∈w.
Λ θ Λ θ
• ForthecaseofE ,itisprovenbydecomposingintoA andE . SupposethatM∗,w ⊨E φ,
θ θ θ Λ θ
thenM∗,w ⊨A φandM∗,w ⊨C φ. ItfollowsfromtheproofsforA andC thatA φ∈w
Λ θ Λ θ θ θ θ
and C φ∈w. By KAC, E φ∈w
θ θ
24Lemma 9. Let Φ be the closure of a formula and Γ be a maximal consistent set in Φ. For every
φ∈Φ, if φ∈Γ for every maximal consistent set Γ in Φ, then ⊢φ.
Proof. We prove it by contraposition. Suppose ⊬ φ, then {¬φ} is a consistent set in Φ. By
Lemma 2, there is a maximal consistent set in Φ that does not contain φ.
Finally, we prove the completeness theorem. To prove that a formula is a theorem, it is
necessary that every maximal consistent set in the closure of the formula includes the formula.
Sincetheassumptionofthetheoremleadstotheformulabeingtrueatallworldsineverydivided
model for the closure of the formula, we obtain the desired fact.
Theorem 2. For every φ∈L , if ⊨φ, then ⊢φ.
(P,G,Θ)
Proof. Suppose that ⊨ φ. For every divided models M∗ for the closure of φ, M∗,w ⊨ φ by
Λ Λ
Lemma 4. Thus, for every maximal consistent set w in Φ, φ ∈ w by Lemma 8. Therefore, ⊢ φ
by Lemma 9.
4 Related Work
Thereareseveralstudiesthatarebasedonasimilarideaasthispaper,whichistoconnectastate
of an agent’s awareness with a distinction of possible worlds. [23, 24, 25] provided awareness
bisimilation. This depends on a set of atomic propositions and is defined between the models
that cannot be distinguished by formulas consisting only of the atomic propositions. Their logic
represents the indistinguishment of possible worlds by lack of awareness, as with our logic. The
main difference is the definition of explicit knowledge. On the definition of explicit knowledge
in our logic, an agent considers from an evaluate world w not only to a world s with a different
valuation only for propositions of which an agent is not aware but also to a world t accessible
from s, unlike their logic. [16] defined an indistinguishable relation and proposed a different
definition of explicit knowledge from [3]. Those ideas are used as the basis of our logic. They
also incorporated the notion of an agent’s viewpoint to represent what “an agent is aware of a
proposition from another agent’s viewpoint,” which is represented as Aiφ. Our logic proposes
j
25the notion of a’s belief in b’s awareness instead of the notion of agent b’s awareness from a’s
viewpoint. Moreover, their logic does not handle a chain of viewpoints with a depth of more
than 3, but our logic handles a chain of belief for awareness with a finite depth.
Purelysemanticapproachestoawarenessareactiveinthefieldofeconomics. Itisalsocalled
the event-based approach, in which the notion of events that are represented as a set of possible
worlds is employied. An agent’s awareness and knowledge are expressed as an operator on
events. The logic system proposed in [17, 18] is the early work of the approach. [11] found it to
beequivalenttoapartofthelogicin[3]. [12,13]proposedunawarenessframe thatisalatticeon
disjointstate-spaceswithapartialorder. Onedisjointstate-spacecapturesoneparticularhorizon
ofpropositionsandworksarestrictionofpropositionsinsteadofanawarenessset. Astate-space
S is greater than S′ means that states of S describe situations with a richer vocabulary than
states of S′. One state-space can be interpreted as subjective descriptions of situations in an
agent’s mind. The formalization is applied to a generalization of [1] [14]. Although this study
does not explicitly have a chain concerning awareness, we may find some relation to our logic.
In game theory, a formalization of the concept of awareness/unawareness has been studied
in order to incorporate it into games. [5, 6] defined a game with incomplete awareness and also
defined a higher order awareness or views as a sequence of agents, which are an iteration of
agents’ awareness or views.
Epistemic worlds semantics provided in [15] is for epistemic logic of shallow depths in which
nested occurrences of belief operators are bounded. The domain in the semantics is the disjoint
union of a set W of possible worlds indexed by a sequence of agents, and a nested belief is
e
evaluated within the set of possible worlds indexed by the sequence of agents corresponding
to the order of agents in the nested belief. Although thier study does not treat the concept of
awareness,theideathatthesubjectinanestedbelieforknowledgeboundsthemissimilarasour
logic. Thelogicin[9]hasanoperator[X]representingthatapropositionholdsatallthepossible
worldswiththesamevaluationforalltheelementsofagivensetX ofatomicpropositions. Team
semantics [19] used in dependence logic formalizes that an atomic proposition is true at all the
elements of a given subset of possible worlds. This subset called a term, supports a formula.
265 Conclusion
ThispaperprovidedAwarenessLogicwithPartitionsandChains(ALPC)forformalizingnested
explicit knowledge. We incorporated an indistinguish relation on possible worlds that changes
in conjunction with a state of awareness and a chain of belief for awareness. These reflect two
ideas: theeffectofanagent’sawarenessonherownreasoningandastateofanagent’sawareness
in another agent’s mind. Employing this framework, we demonstrated an example where each
agent’s knowledge that each other agent who has different states of awareness actually knows at
a given moment, which is nested explicit knowledge, could be logically represented.
Our contributions of this logic are two-fold. From a logical viewpoint, we defined the syntax
and the semantics of ALPC and proved its completeness. From the viewpoint of applicability
to the real world, we showed the architecture to explain the strategic behavior of a rational
agent in society or game theory. We expect that the logic can be applied to computer science
and game theory by describing and analyzing strategic behavior in a game and practical agent
communication.
There are several directions in the future. Extending our logic to represent knowledge of a
group is one direction. In particular, formalizing common knowledge is an interesting topic. In
decision-making in strategic situations where a player makes a decision with knowledge of the
other’s action, it is valuable that a proposition is common knowledge from the perspective of
an outside observer with complete awareness. However, it is equally valuable that a proposition
is common knowledge from the perspective of an agent with incomplete awareness. Our logic
can be used to represent such common knowledge. Furthermore, incorporating an epistemic
actionthatchangesastateofawarenessisanotherdirection. Thisextensionmakesitpossibleto
formalize changing knowledge by communicative actions [21]. There are already several studies
on dynamics of awareness [8, 10, 22], and we can refer to those results. On the technical side,
exploring a relationship to other related logic mentioned in Section 5 is one of the directions.
In addition, our logic is applicable to the studies dealing with multiple agents’ reasoning, such
as a description and analysis of a game that takes into account players’ awareness of possible
strategies.
27Acknowledgements
I thank Nobu-Yuki Suzuki, Satoshi Tojo, and Kosuke Udatsu for their insightful comments.
References
[1] R. J. Aumann. Agreeing to disagree. The Annals of Statistics, pages 1236–1239, 1976.
[2] B. F. Chellas. Modal logic: an introduction. Cambridge University Press, 1980.
[3] R.FaginandJ.Y.Halpern. Belief,awareness,andlimitedreasoning. Artificial Intelligence,
34:39–76, 1988.
[4] R. Fagin, J. Y. Halpern, Y. Moses, and M. Vardi. Reasoning About Knowledge. MIT Press,
1995.
[5] Y.Feinberg.Gameswithincompleteawareness.Technicalreport,TechnicalReportResearch
Paper Series# 1894, Stanford Graduate School of Business, 2005.
[6] Y. Feinberg. Games with unawareness. The B.E. Journal of Theoretical Economics,
21(2):433–488, 2021.
[7] C. Fern´andez-Fern´andez. Awareness in Logic and Epistemology: A Conceptual Schema and
Logical Study of the Underlying Main Epistemic Concepts. Springer, 2021.
[8] C. Fern´andez-Fern´andez and F. R. Vel´azquez-Quesada. Awareness of and awareness that:
their combination and dynamics. Logic Journal of the IGPL, 29(4):601–626, 2021.
[9] D.Grossi,E.Lorini,andF.Schwarzentruber. Theceterisparibusstructureoflogicsofgame
forms. Journal of Artificial Intelligence Research, 53:91–126, 2015.
[10] D.GrossiandF.R.Vel´azquez-Quesada. Syntacticawarenessinlogicaldynamics. Synthese,
192(12):4071–4105, 2015.
[11] J. Y. Halpern. Alternative semantics for unawareness. Games and Economic Behavior,
37(2):321–339, 2001.
28[12] A. Heifetz, M. Meier, and B. C. Schipper. Interactive unawareness. Journal of Economic
Theory, 130(1):78–94, 2006.
[13] A. Heifetz, M. Meier, and B. C. Schipper. A canonical model for interactive unawareness.
Games and Economic Behavior, 62:304–324, 2008.
[14] A. Heifetz, M. Meier, and B. C. Schipper. Unawareness, beliefs, and speculative trade.
Games and Economic Behavior, 77(1):100–121, 2013.
[15] M. Kaneko and N.-Y. Suzuki. Epistemic models of shallow depths and decision making in
games: Horticulture. The Journal of Symbolic Logic, 68(1):163–186, 2003.
[16] Y. Kubono, T. Racharak, and S. Tojo. Logic of awareness in agent’s reasoning. In Proceed-
ings of the 15th International Conference on Agents and Artificial Intelligence - Volume 1:
ICAART, pages 207–216. SciTePress, 2023. [Errata arXiv:2309.09214].
[17] S.ModicaandA.Rustichini. Awarenessandpartitionalinformationstructures. Theory and
Decision, 37(1):107–124, 1994.
[18] S. Modica and A. Rustichini. Unawareness and partitional information structures. Games
and Economic Behavior, 27(2):265–298, 1999.
[19] K. Sano and J. Virtema. Axiomatizing propositional dependence logics. In 24th EACSL
Annual Conference on Computer Science Logic (CSL 2015), volume 41, pages 292–307.
Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, 2015.
[20] B. C. Schipper. Awareness. In H. van Ditmarsch, W. van der Hoek, J. Y. Halpern, and
B. Kooi, editors, Handbook of epistemic logic. College Publications, 2015.
[21] J. Van Benthem. Logical dynamics of information and interaction. Cambridge University
Press, 2011.
[22] J. van Benthem and F. R. Vel´azquez-Quesada. The dynamics of awareness. Synthese,
177(1):5–27, 2010.
29[23] H. van Ditmarsch and T. French. Awareness and forgetting of facts and agents. In 2009
IEEE/WIC/ACMInternationalJointConferenceonWebIntelligenceandIntelligentAgent
Technology, pages 478–483. IEEE, 2009.
[24] H.vanDitmarschandT.French. Becomingawareofpropositionalvariables. InM.Banerjee
and A. Seth, editors, Logic and Its Applications, pages 204–218. Springer, 2011.
[25] H. van Ditmarsch, T. French, F. R. Vel´azquez-Quesada, and Y. N. W´ang. Implicit, explicit
and speculative knowledge. Artificial Intelligence, 256:35–67, 2018.
[26] H. van Ditmarsch, W. van Der Hoek, and B. Kooi. Dynamic Epistemic Logic. Springer
Science & Business Media, 2007.
30