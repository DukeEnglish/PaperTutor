Group Decision-Making among Privacy-Aware Agents
MARIOSPAPACHRISTOU,CornellUniversity,USA
M.AMINRAHIMIAN,UniversityofPittsburgh,USA
Howcanindividualsexchangeinformationtolearnfromeachotherdespitetheirprivacyneedsandsecurity
concerns? For example, consider individuals deliberating a contentious topic and being concerned about
divulgingtheirprivateexperiences.Preservingindividualprivacyandenablingefficientsociallearningare
bothimportantdesideratabutseemfundamentallyatoddswitheachotherandveryhardtoreconcile.We
dosobycontrollinginformationleakageusingrigorousstatisticalguaranteesthatarebasedondifferential
privacy(DP).Ouragentsuselog-linearrulestoupdatetheirbeliefsaftercommunicatingwiththeirneighbors.
Adding DPrandomizationnoisetobeliefs providescommunicating agentswithplausibledeniability with
regardtotheirprivateinformationandtheirnetworkneighborhoods.Weconsidertwolearningenvironments
onefordistributedmaximum-likelihoodestimationgivenafinitenumberofprivatesignalsandanotherfor
onlinelearningfromaninfinite,intermittentsignalstream.Noisyinformationaggregationinthefinitecase
leadstointerestingtradeoffsbetweenrejectinglow-qualitystatesandmakingsureallhigh-qualitystatesare
acceptedinthealgorithmoutput.Our resultsflesh outthenatureofthetrade-offsin bothcasesbetween
thequalityofthegroupdecisionoutcomes,learningaccuracy,communicationcost,andthelevelofprivacy
protectionsthattheagentsareafforded.
AdditionalKeyWordsandPhrases:distributedestimation,distributedlearning,onlinelearning,differential
privacy,groupdecision-making
1 INTRODUCTION
Inmanyinformationenvironments,participatingagentshaveprivacyandsecurityneedsthatpre-
vent them from engaging in information exchangeat their socially optimal levels (for optimum
collective decision-making and social learning), e.g., when bound by client confidentiality, obli-
gatedbyuserprivacylaws,orneedingtosafeguardtheirinformationsources.Inothersocialand
business settings,theparticipants maybereluctanttoexpressunpopularopinionsoropenlyde-
liberateoncontentiousorcontroversialissues.Evenintheabsenceofsuchprivacy,legal,security,
or safety concerns,strategic andcompetitive considerations canleadto suboptimal information
sharingatequilibrium.Differential privacy(DP)isaversatileframeworkfordevelopingprivacy-
preservingalgorithms,andithasbeencardinalinlarge-scaleandhigh-profilecasessuchastheU.S.
decennialcensus[Garfinkel,2022]andthetechindustry [AppleDifferentialPrivacyTeam,2017,
Erlingsson,2014].EarlierworkalsopointstothepotentialofDPinalleviatingmisalignedincen-
tivesandreducingcompetitiveinefficienciesingame-theoreticequilibria[Kearnsetal.,2014].
Privacyispivotal inmanygroupdecisionscenarios.Forexample,considerintelligenceopera-
tives from alliedcountries who needto exchangeinformation to reach a consensus on mission-
criticalobjectiveswhilesafeguardingtheirinformationsourcesforthesustainability oftheirop-
erations. This emphasis on privacy extends to public discourse in democracies, where the free
exchangeofinformationiscrucialforeffectivedeliberationbutmayneverberealizedifindividu-
alsfaceundueprivacyrisks.Privacyprotectionscanenhancethequalityofinformationaggrega-
tionforcollectivedecision-making,particularlyinenvironmentswhereindividualsharborreason-
ableconcernsaboutcompromisingtheirprivateinformation.Forinstance,whendiscussingtopics
suchassubstanceabuse,mentalhealth,gunviolence,orabortion,privacyconcernsmaydeteref-
ficientparticipationtotheextentthatindividuals’opinionsreflecttheirpersonalexperiences.In
othercircumstances,individualsmayfacecommunityretaliationsorlegalprecautionsthatprevent
themfromexpressingunpopularbeliefsinpublicdebatesoncontentioustopics.Inothersettings,
non-profitandfor-profitorganizations,whilelegallyobligatedtoprotectclientdata,canenhance
service quality and operational profitability through responsible information sharing. Hospitals
4202
beF
31
]GL.sc[
1v65180.2042:viXraMariosPapachristouandM.AminRahimian 1
sharing healthrecordscanimprove carequality andidentify optimal treatment optionsfor rare
diseases,whilebankscollaboratingonloanapplicantrecordscanenhancescreeningprocessesand
mitigatetheriskofloandefaults.
OurContribution
Inthiswork,weproposeadifferentiallyprivate1,distributed,hypothesis-testingmodelforlearn-
ingamongagroupofagentsendowedwithprivatesignalsandexchangingbeliefstoinferatrue
stateoftheworldoragreeonasetofbestalternatives.Ouragentsarewaryofrevealingtheirpri-
vatesignalsornetworkneighborhoodstoeachother.Theprivatesignalsaregeneratedaccording
tothetruestate,whichisunknownbutcommontoallagents.Weproposenon-Bayesianbeliefex-
changemodelsthatprotectprivatesignalsandnetworkneighborhoodswhileachievingcollective
learningasymptotically.
WecharacterizethequalityoflearningsubjecttoDPbudgetconstraintsandquantifythetrade-
offbetweenlearningrateandprivacy:learninginprivacy-criticalenvironmentscanbesustained
atareasonablecosttocommunicationcomplexityandaccuracy.Weshowthatnon-Bayesiansocial
learningmodelsbasedonlog-linearbeliefupdate[GilardoniandClayton,1993,Rufoetal.,2012]
arehighlyreceptivetotheprivacyneedsoftheparticipatingagentsandcanaccommodatestrict
privacy requirements at a reasonable cost to social learners and their quality of group decision
making.
DPconstraintsinouralgorithmsaresatisfiedbyaddingnoisetobeliefupdatesatanappropriate
levelthatprotectsindividualsignalsornetworkneighborhoods,respectingtheDPbudget.Inthe
onlinelearningsettingwhereagentshaveaccesstoaninfinite,intermittentstreamofsignals,the
effectofnoisevanishesasymptotically,butDPnoisingslowsdownthebeliefdynamics,requiring
more communication rounds than the non-private baseline to achieve the same accuracy level.
Our non-asymptotic (finite-time) analysis allows us to delineate the trade-offs between privacy
budget,communicationcomplexity,anderrorprobabilityintheonlinelearningcase.Whenagents
haveaccessto onlyfinitely manyprivate signals, they aim to agreeona set ofalternatives that
best explains their collective observations using a distributed, maximum-likelihood estimation
(distributed MLE). The crux of our analysis in this case lies in the fact that DP noising makes
ourdistributed MLEalgorithmnon-deterministic. Hence,toachievea desiredaccuracylevel we
needtorepeatthedistributedMLEalgorithmin𝐾 rounds.OurapproachforDPdistributedMLE
opensa newdesigndimension todecidehowbest toaggregatetheoutcomeofdifferent rounds
forareliableMLEoutput.WeproposetwomethodsforaggregatingthedistributedMLErounds
thateachofferdistinctadvantagesintermsofcommunicationcomplexityandtheirflexibilityto
controlerrorprobabilities.
Ourfirstmethodisbasedonarithmeticandgeometricaveragingofbeliefsacrossrounds.Specif-
ically,itutilizesarithmeticaveragingasawaytoensurethatallgoodalternativesmaketheirway
totheidentifiedsetandofferawaytocontrolthefalsepositiverate(Type-Ierrors).Ontheother
hand,geometricaveragingoffersawaytocontrolmisseddetectionrate(Type-IIerrors),ensuring
thatnobadalternativesareincludedintheMLEoutput.
Oursecondaggregationmethodisbasedonthresholding.Specifically,itkeepstrackofthefre-
quencies that the beliefs in each round exceed a specific threshold. It then uses two thresholds
to construct sets containing the states whose frequencies exceed either of the thresholds. This
algorithm works analogously to the averaging algorithm and relies on the concentration of the
frequencies to control Type-I or Type-II errors with either of the thresholds. The advantage of
1Inthesequel,weuseDPtosignifyanyofthephrases“differentiallyprivate”,“differentiallyprivately”,and“differential
privacy”withorwithoutahyphenbetweenthewordsasappropriate.MariosPapachristouandM.AminRahimian 2
thethresholdingmethodofaggregatingovertheaveragingoneisthatitoffersmoreflexibilityto
controlType-IandType-IIerrorratesindividually;however,thiscomesatacosttoruntimeand
increasedcommunicationcomplexity.
Dependingontheapplication,decision-makerscanoptfortheirmostsuitableaggregators.For
example,indealingwithrareandintractablediseases,healthpractitionersmaybeprimarilycon-
cerned with identifying treatment options with the potential to improve patient outcomes and,
thus,lessconcernedwithfalsepositives(inclusionofpotentiallyineffectivetreatmentoptionsin
their identified alternatives). Ontheother hand,when screening loanapplicants, financial insti-
tutionsmaybeprimarilyconcernedwithavoidingloandefaultsandmaybeopentomissedloan
opportunitiestoreducetheriskofbadinvestments.Inthelattercase,itwouldbedesirabletohave
anaggregationmethodthatensures allbadstates arefilteredoutwith a lever to controlmissed
detectionrates.
InSection2,wedescribeournetworkedinformationenvironmentforgroupdecision-making
andprovidenon-privatealgorithmsfordistributedMLEandonlinelearningthatactasbaselines
fortheremainderofthepaper.InSection3,weprovideDPversionsofthesealgorithmsandoffer
performanceanalyses thatdelineate the trade-offs between communicationcomplexity, privacy,
andaccuracyineachcase.InSection4,weprovideadetailedliteraturereviewthatcontextualizes
ourresults,followedbydiscussionsofbroaderimplicationsandconclusionsinSection5.Mathe-
maticalderivationandproofdetailsareprovidedintheAppendix.
2 PRELIMINARIES
2.1 NetworkStructure
We consider a set of 𝑛 agents, denoted by the set 𝑛 = 1,...,𝑛 , connected according to an
[ ] { }
undirectedgraph 𝑛 , withoutself-loops.Theneighborhoodofagent𝑖 isdenotedby and
𝑖
G([ ] E) N
correspondstoalloftheagentsthatagent𝑖canlocallyexchangeinformationwith.Thegraphcor-
respondstoadoubly-stochasticadjacencymatrix𝐴 = 𝑎 withweights𝑎 =0whenever
𝑖𝑗 𝑖,𝑗 𝑛 𝑖𝑗
𝑖,𝑗 ∉ andweight𝑎 > 0forall 𝑖,𝑗 ,andmoreover ∈[ ] 𝑎 =1.Theadjacencymatrix
𝐴( is) assE ociated with 𝑛𝑖 e𝑗 igenvalues( 𝜆 𝐴) ∈ E 𝜆 𝐴 (cid:2) (cid:3) 𝜆𝑖 ∈[𝑛 𝐴] 𝑖 a𝑗 nd a set of bi-orthonormal
1 2 𝑛
eigenvectors 𝒍 ,𝒓 satisfying 𝒍 ( =) ≥ 𝒓 ( =) 𝒍𝑇≥ 𝒓 =·· 1· f≥ oÍ rall( 𝑖 ) 𝑛 and𝒍𝑇𝒓 =0forall𝑖 ≠ 𝑗.
{𝑖 𝑖 }𝑖 ∈[𝑛 ] k 𝑖 k2 k 𝑖 k2 𝑖 𝑖 ∈ [ ] 𝑖 𝑗
Theweights𝐴canbechoseninmanyways.Oneofthewaystochoosetheweightsistofollow
theMetropolis-Hastingsalgorithmandset𝑎 = 1 max deg 𝑗 ,deg 𝑖 forall 𝑖,𝑗 andalso
𝑖𝑗
/ { ( ) ( )} ( ) ∈ E
𝑎 =1 𝑎 .
𝑖𝑖
−
𝑗≠𝑖 𝑖𝑗
2.2 NonÍ-PrivateAlgorithms
Weconsidertwotypesoflearningregimes:inthefirstsetting,weareconcernedwiththecalcula-
tionofthemaximumlikelihoodstatesinadistributedwaybasedonasetofinitialobservations,
andinthesecondsetting, weconsider learning theMLEstates inanonlinemannerthroughre-
peatedlyobservingdatastreams.Inthesequel,wepresentthetwosettingsandthecorresponding
non-privatealgorithms,whichserveasbenchmarksfortheDPregime.
Both algorithms are based on a log-linear update rule, in which an agent forms its belief by
combiningthelikelihoodoftheobservedsignals,thebeliefoftheagentfromthepreviousiteration,
andthebeliefsofitsneighbors.Wealsonotethatotherupdateschemes,suchaslinear updates,
arepossible;however,theysufferfromslowerconvergence[Kayaalpetal.,2022,Proposition1].
DistributedMLE.Inthedistributedmaximumlikelihoodestimation(MLE)estimationtask,there
isasetoflikelihoodmaximizersΘ★ ΘarbitrarilychosenbynaturefromastatespaceΘ,which
ispubliclyknowntotheagents.The⊂ agentsaimtodetermineΘ★
collectivelybycombiningtheir
owninformationandinformationfromtheirlocalneighbors.Specifically,eachagenthasaccesstoMariosPapachristouandM.AminRahimian 3
adataset𝑺 of𝑛 i.i.d.observations𝑺 = 𝒔 ,...,𝒔 where𝒔 ,...,𝒔 obeyastatisticalmodel
𝑖 𝑖 𝑖
(
1 𝑛𝑖) 1 𝑛𝑖
∈S
determinedbythelikelihoodfunction
𝑛𝑖
ℓ 𝑺 𝜃ˆ = ℓ 𝒔 𝜃ˆ .
𝑖 𝑖 𝑖 𝑗
( | ) ( | )
𝑗=1
Ö
Ourtaskis,givensignals𝑺 foreachagent𝑖 𝑛 ,tofindthesetoflikelihoodmaximizers,i.e.,
𝑖
∈ [ ]
𝑛
Θ★=argmaxΛ 𝜃ˆ , whereΛ 𝜃ˆ = log ℓ 𝑺 𝜃ˆ .
𝑖 𝑖
( ) ( ) ( | )
𝜃ˆ ∈Θ Õ𝑖=1
(cid:16) (cid:17)
We define Θ¯ = Θ Θ★ as theset of non-optimal states. We let 𝑓★ represent the density of MLE
states,i.e., 𝑓★= Θ\★ Θ.
| |/| |
Inthenon-privateregime,theagentsformbeliefs𝝁 𝜃ˆ overiteration𝑡andstatesandexchange
𝑖,𝑡
( )
theirbeliefswiththeirneighborsuntiltheycandetecttheMLE.Theworkof[RahimianandJadbabaie,
2016b]givesanalgorithmforbeliefexchangethatprovablyconvergestothetrueMLEafterafinite
numberofsteps(seeTheorem1intheirpaper).ThealgorithmisgiveninAlgorithm1.
Algorithm1. Non-PrivateDistributedMLE
Theagentsbeginbyforming:𝜸 𝜃˜ = 𝑛𝑖 ℓ 𝒔 𝜃˜ ,andinitializingtheirbeliefsto𝝁 𝜃ˆ =
𝑖 ( ) 𝑗=1 𝑖 ( 𝑗 | ) 𝑖,0 ( )
𝜸 𝜃ˆ 𝜸 𝜃˜ .Inanyfuturetimeperiod,theagentsupdatetheirbeliefaftercommunica-
𝑖 ( )/ 𝜃˜ Θ 𝑖 ( ) Î
tionwith∈ theirneighboringagents,andaccordingtothefollowingupdateruleforany𝜃ˆ:
Í
𝝁 𝑖1 ,+𝑡𝑎𝑖 1𝑖 (𝜃ˆ
)
𝝁𝑎 𝑗,𝑖 𝑡𝑗 1(𝜃ˆ
)
𝝁 𝜃ˆ = − 𝑗 ∈N𝑖 − (1)
𝑖,𝑡 ( ) 𝝁 𝑖1 ,+𝑡𝑎𝑖 1𝑖 (𝜃˜ )Î 𝝁𝑎 𝑗,𝑖 𝑡𝑗 1(𝜃˜ )·
𝜃˜ Í∈Θ − 𝑗 Î∈N𝑖 −
Theconvergenceofthisalgorithmreliesonstudyingthebehaviorofthelog-beliefratiobetween
twostates𝜃ˆand𝜃ˇ,whosedynamicsaregovernedbythepowersoftheprimitivematrix𝐴 𝐼 (see
+
[RahimianandJadbabaie,2016b,Theorem1])withorderedeigenvalues𝛼 =𝜆 𝐴 𝐼 .Specifically,
𝑖 𝑖
( + )
Theorem 1 of [RahimianandJadbabaie, 2016b] states that there is a dominant term due to the
maximum eigenvalue 𝛼 = 2 that dominates the log-belief ratios for large 𝑡, and 𝑛 1 terms
1
thatareexponentially decayingwith rate𝛼★ = 1 2 max 𝛼 , 𝛼 < 1.Thedominan− ttermon
𝑛 ( / ) { 2 | 𝑛 |}
each state depends on the difference of the log-likelihoods between the states 𝜃ˆ and𝜃ˇ, namely
Λ 𝜃ˆ,𝜃ˇ = Λ 𝜃ˆ Λ 𝜃ˇ . Subsequently, the log-belief ratio approaches as𝑡 whenever
𝜃ˇ( Θ★) ,and( we) c− anr( ec)
overtheMLEs.
−∞ → ∞
∈
OnlineLearningfromIntermittentStreams.Wenextconsideranetworkofagentsthatmake
streamsofobservationsintermittentlyandcommunicatetheirbeliefsateverytimeperiod.Atany
iteration 𝑡, agent𝑖 makes𝑛 i.i.d. observations 𝒔1 , ..., 𝒔𝑛𝑖,𝑡 that are distributed according to a
𝑖,𝑡 𝑖,𝑡 𝑖,𝑡
parametricmodelℓ 𝜃ˆ ;andthenumbersofobservationsateachtimeperiod 𝑛 i.i.d. which
𝑖 𝑖,𝑡 𝑖
(·| ) { } ∼ P
arei.i.d. distributed over timewith distribution foreachagent𝑖 𝑛 with E 𝑛 = 𝜈 and
𝑖 𝑖,𝑡 𝑖
V 𝑛 = 𝜉 .TheagentsaimtodeterminetheMP LEstatesΘ★ from∈ the[ ir] stream ofobservations
𝑖,𝑡 𝑖 (cid:2) (cid:3)
usingAlgorithm2,introducedin[RahimianandJadbabaie,2016b].
(cid:2) (cid:3)
For this algorithm, [RahimianandJadbabaie, 2016b] proves that it converges to learning the
MLEstatesasymptotically.Theirargumentreliesonthefactthattheaveragelog-beliefratiobe-
tween a pair of states𝜃ˆ,𝜃ˇ Θ converges to the weighted sum of the KL divergences of all the
∈
agents.MariosPapachristouandM.AminRahimian 4
Algorithm2. Non-PrivateDistributedOnlineLearning
Everytime𝑡 N ,eachagentformsthelikelihoodproductofthesignalsthatithasreceived
0
atthatiteratio∈ n:𝜸 𝜃ˆ = 𝑛𝑖,𝑡 ℓ 𝒔𝑗 𝜃ˆ ,if𝑛 1,and𝛾 𝜃ˆ =1if𝑛 =0.Theagentthen
𝑖,𝑡 ( ) 𝑗=1 𝑖 ( 𝑖,𝑡| ) 𝑖,𝑡 ≥ 𝑖,𝑡 ( ) 𝑖,𝑡
updatesitsbeliefaccordingto:
Î
𝜸 𝜃ˆ 𝝁𝑎𝑖𝑖 𝜃ˆ 𝝁𝑎𝑖𝑗 𝜃ˆ
𝝁 𝑖,𝑡 (𝜃ˆ ) =
𝜃˜
Θ𝑖 𝜸,𝑡 𝑖( ,𝑡 () 𝜃˜ )𝑖 𝝁,𝑡 − 𝑖𝑎 ,𝑖 𝑡1 𝑖 −( 1() 𝜃˜ Î
)
𝑗 ∈ 𝑗N ∈𝑖 N𝑖𝑗 𝝁,𝑡 𝑎− 𝑗,𝑖 𝑡1 𝑗 −( 1() 𝜃˜ ), (2)
Í∈ Î
initializedby:𝝁 𝜃ˆ =𝜸 𝜃ˆ 𝜸 𝜃˜ .
𝑖,0
( )
𝑖,0
( )/
𝜃˜ Θ 𝑖,0
( )
∈
Í
2.3 NetworkDynamicsandDifferentialPrivacy
LearningDynamics.WeconsidertwomethodsfordifferentialprivacyandrefertothemasSig-
nal/DataDifferentialPrivacy(Signal/DataDP)andNetworkDifferentialPrivacy(NetworkDP).Both
algorithmsarelocalinprinciple;theagentssimplyaddmultiplicativenoisetotheirestimatesto
achieveadesiredprivacyguarantee.Roughly,SignalDPaddsnoisetoprotecttheprivatesignals
ofeachagent,𝑺 ,andNetwork DP addsnoise to protectitsown privatesignals, 𝑺 , aswell as
𝑖,𝑡 𝑖,𝑡
thebeliefs 𝝂 𝜃ˆ ofitsneighborsfromround𝑡 1.Weassumethatthenon-private
networkdy{ na𝑗 m,𝑡 − i1 c( se) v} o𝑗 l∈vNe𝑖, a𝜃ˆ c∈cΘ ordingtoamultiplicativeupdat−
erule:
𝝁 𝜃ˆ 𝐹 𝝁 𝜃ˆ 𝐺 𝝁 𝜃ˆ 𝐻 𝑺 𝜃ˆ , (3)
𝑖,𝑡 𝑖,𝑡 𝑖,𝑡 1 𝑖,𝑡 𝑗,𝑡 1 𝑖,𝑡 𝑖,𝑡
( ) ∝ ( − ( ))· (cid:18)n − ( ) o𝑗 ∈N𝑖(cid:19) · ( | )
forall𝜃ˆ Θ,foreachagent𝑖 𝑛 ,and𝑡 1,where𝐹
𝑖,𝑡
: R 0, ,𝐺
𝑖,𝑡
: R𝑑𝑖 0, ,
∈ ∈ [ ] ≥ → ( +∞) → ( +∞)
and𝐻
𝑖,𝑡
: 𝑛𝑖,𝑡 0, arefunctionsdeterminedbythelearningalgorithm,andcorrespondto
S → ( +∞)
theinformationfromtheagent’sownestimate,theinformationfromtheneighboringestimates,
andtheinformationfromtheagent’sprivatesignalrespectively.
To achieve differential privacy, each agent adds some amount of noise 𝒅 𝜃ˆ drawn from a
𝑖,𝑡
( )
distribution 𝜃ˆ totheirestimateandreportsthenoisyestimatetotheirneighbors.Thenoise
𝑖,𝑡
D ( )
is independent among the states and the agents. The agent can either aim to protect only their
privatesignal—whichwecallSignalDPanddenoteby 𝑆,orprotecttheirnetworkconnections
M
andtheirprivatesignal—whichwecallNetworkDPanddenoteby 𝑁.Thenoisydynamicsare
M
SignalDP 𝑆
M 𝑖,𝑡
𝝂
𝑖,𝑡
𝜃ˆ 𝐹
𝑖,𝑡
𝝂
𝑖,𝑡 1
𝜃ˆ 𝐺
𝑖,𝑡
𝝂
𝑗,𝑡 1
𝜃ˆ 𝐻
𝑖,𝑡
𝑺
𝑖,𝑡
𝜃ˆ 𝑒𝒅𝑖,𝑡(𝜃ˆ ). (4)
( ) ∝ ( − ( ))· (cid:18) n − ( ) o 𝑗 ∈N 𝑖 (cid:19) · z ( } | | {) ·
NetworkDP 𝑁
M𝑖,𝑇
| {z }
Formally,thetwotypesofmechanismscanalsobewrittenas
𝜓 M𝑖𝑆 ,𝑡(𝑺 𝑖,𝑡
)
= 𝐻 𝑖,𝑡 (𝑺 𝑖,𝑡 |𝜃ˆ )·𝑒𝒅𝑖,𝑡(𝜃ˆ ) 𝜃ˆ ∈Θfor M𝑖𝑆 ,𝑡,
and (cid:0) (cid:1)
𝜓 M𝑖𝑁 ,𝑇 𝑺 𝑖,𝑡, 𝝂 𝑗,𝑡 −1 𝑗 ∈N𝑖 = 𝐻 𝑖,𝑡 (𝑺 𝑖,𝑡 |𝜃ˆ )·𝐺 𝑖,𝑡 {𝝂 𝑗,𝑡 −1 (𝜃ˆ )}𝑗 ∈N𝑖)·𝑒𝒅𝑖,𝑡(𝜃ˆ ) 𝜃ˆ ∈Θ for M𝑖𝑁 ,𝑇.
Moreover,(cid:0)fora(cid:8)single(cid:9)samp(cid:1)le𝒔(cid:0) ,thedefinitio(cid:0)nof 𝜀,𝛿 -differentialpri(cid:1)vacyisgivenbelow
∈S ( )MariosPapachristouandM.AminRahimian 5
Definition2.1(SignalDP). Amechanismissaidtobe 𝜀,𝛿 -DPwithrespecttothesignalifand
( )
onlyifforall𝑋 Rwehavethat
⊆
P [𝜓 M𝑖𝑆 ,𝑡(𝒔 𝑖,𝑡 ) ∈𝑋 ] ≤𝑒𝜀P [𝜓 M𝑖𝑆 ,𝑡(𝒔 𝑖′,𝑡) ∈𝑋 ]+𝛿, forall𝒔 𝑖,𝑡,𝒔 𝑖′,𝑡 ∈S𝑖, s.t. 𝒔 𝑖,𝑡 −𝒔 𝑖′,𝑡 1 ≤ 1.
Definition2.2(NetworkDP). Amechanismissaidtobe 𝜀,𝛿 -DPwithres(cid:13)pecttoth(cid:13)enetworkif
( ) (cid:13) (cid:13)
andonlyifforall𝑋 Rwehavethat
⊆
P 𝜓 M𝑖𝑁 ,𝑇 𝒔 𝑖,𝑡, 𝝂 𝑗,𝑡 −1 𝑗 ∈N𝑖 ∈𝑋 ≤𝑒𝜀P 𝜓 M𝑖𝑁 ,𝑇 𝒔 𝑖′,𝑡, 𝝂 𝑗′,𝑡 −1 𝑗 ∈N𝑖 ∈𝑋 +𝛿
forall 𝒔 , 𝝂(cid:2) (cid:0) ,(cid:8)𝒔 , 𝝂(cid:9) (cid:1) (cid:3) (cid:2)Rdeg 𝑖(cid:0),s.t.(cid:8) (cid:9) (cid:1) (cid:3)
𝑖,𝑡 𝑗,𝑡 −1 𝑗 ∈N𝑖 𝑖′,𝑡 𝑗′,𝑡 −1 𝑗 ∈N𝑖 ∈S𝑖 × ( )
(cid:0) (cid:8) (cid:9) (cid:1) (cid:0) 𝒔 𝑖,𝑡,(cid:8)𝝂 𝑗,𝑡 −1(cid:9) 𝑗 ∈N𝑖(cid:1) − 𝒔 𝑖′,𝑡, 𝝂 𝑗′,𝑡 −1 𝑗 ∈N𝑖 1 ≤ 1.
Sensitivity.Theglobalℓ 1(cid:13) (cid:13)-s(cid:0)ensit(cid:8)ivityo(cid:9)fthes(cid:1)am(cid:0)plelo(cid:8)g-like(cid:9)lihood(cid:1)(cid:13) (cid:13)ofthe𝑖-thagentandstate𝜃ˆ Θ
∈
isdefinedtobe
𝑔
𝑖
(𝜃ˆ
)
=
𝒔,𝒔
′∈Sm
:
k𝒔a −x
𝒔 ′k1≤1
logℓ
𝑖
(𝒔 |𝜃ˆ )−logℓ
𝑖
(𝒔′ |𝜃ˆ
)
1.
Thesensitivity of thejoint log-likelihoodis𝑛(cid:13) (cid:13)𝑖,𝑡𝑔
𝑖
𝜃ˆ since each agent(cid:13) (cid:13)has accessto𝑛
𝑖,𝑡
i.i.d. ob-
( )
servations ateach pointin time (inthegeneral case) andeachobservation haspointsensitivity
𝑔 𝜃ˆ .
𝑖
( )
InthecontextofSignalDP,thesensitivityofagent𝑖 atiteration𝑡 isdefinedtobe
Δ =𝑛 max𝑔 𝜃ˆ ,
𝑖,𝑡 𝑖,𝑡 𝑖
· 𝜃ˆ Θ ( )
∈
astheworst-casesensitivityoverthestatespace2.InthecontextofNetworkDP,thesensitivityof
agent𝑖 atiteration𝑡 isinsteaddefinedtobe
Δ =max 𝑛 max𝑔 𝜃ˆ ,1 max𝑎 .
𝑖,𝑡 𝑖,𝑡 𝑖 𝑖𝑗
(cid:26)
· 𝜃ˆ ∈Θ ( ) + 𝑗≠𝑖
(cid:27)
Forbothcases,wedefinetheworst-casesensitivity tobeΔ 𝑛,Θ =max 𝑖 𝑛 ,𝑡 NΔ 𝑖,𝑡.
∈[ ] ∈
3 DIFFERENTIALLYPRIVATEALGORITHMS
3.1 PerformanceAnalysisFramework
Inthesequel,wepresentourDPalgorithmsfordistributed MLEandonlinelearningofthetrue
statefromintermittentsignals.WefollowasimilarapproachforbothdistributedMLEandonline
learning by adding noise in the log domain. However, in the case of MLE, this noise makesthe
algorithmoutputrandom,sothealgorithmneedstoberepeatedtoachievethedesiredaccuracy
level.Intheonlinelearningregime,thealgorithmhasaccesstoastreamofnoisysignals;therefore,
theDPnoiseaveragesoutovertime.Inthelattercase,weonlyneedtoexecutethealgorithmonce.
InadditiontoafixedDPbudget𝜀 >0,ourdistributedMLEalgorithmsalsorespectfixedType-I
andType-IIerrorprobabilities, denotedby𝜂 ,𝜂 0,1 .Thelattertwoparametersarebecause
1 2
∈ ( )
ourrandomizedDPalgorithmsfordistributedMLEcanmaketwotypesoferrors,whichwecontrol
andboundinouranalysis.ForadistributedMLEalgorithm whichreturnsanestimatorΘˆ ,we
A
definetheType-Ierror𝜂 astheprobabilitythat Θ★ * Θˆ A ,whichcanbecontrolledbybounding
1 A
P Θ★ Θˆ 1 𝜂 .Similarly,wedefinetheType-II error𝜂 tobetheprobabilityoftheevent
⊆ A ≥ − 1 (cid:8) (cid:9) 2
Θ★ * Θˆ ,whichcanbecontrolledbyensuringthatP Θ★ Θˆ 1 𝜂 .AType-Ierroroccurs
(cid:2) A (cid:3) ⊆ A ≥ − 2
asthealgorithmsmorestatesthanthetrueMLEsetintoitsoutput.AType-IIerroroccursasthe
(cid:8) (cid:9) (cid:2) (cid:3)
2Ifwewanttoprotectthenumberofsignals,thenwecantakeamaxoverallofthesensitivitiesΔ 𝑛,Θ=max𝑖 𝑛,𝑡 NΔ 𝑖,𝑡.
Moreover,eventhoughwearenotprotectingthestates,takingthemaximumoverΘsimplifiesthetheoret∈ic[al]a∈nalysis
significantly(attheexpenseofaddingmorenoise).MariosPapachristouandM.AminRahimian 6
𝑥 Scalar
𝒙 Vector
𝒙 Elementofvector𝒙
𝒙 𝑝 ℓ𝑝-normof𝒙
k k
𝑋 Matrix
𝑛 Numberofagents
𝜀/𝛿 Privacybudgetandleakageprobability
𝜂1/𝜂2 Type-I/Type-IIerrorprobabilities
𝐴 Communicationmatrix
Θ Setofstates
Θ★ /Θ¯ SetofMLE/non-MLEstates
𝜃★ /𝜃¯ MLE/non-MLEstate
𝑓★ DensityofMLEstates(𝑓★= Θ★ Θ)
ℓ𝑖 𝒔𝜃ˆ Likelihoodofagent𝑖givensig| nal|/ 𝒔| at| state𝜃ˆ
( | )
𝑇 /𝐾 Numberofiterations/rounds
𝜸𝑖,𝑡 𝜃ˆ JointLikelihoodofagent𝑖givendata𝑺𝑖,𝑡 ofsize𝑛𝑖,𝑡 atstate𝜃ˆinthenon-privateregime
𝝈𝑖,𝑡( 𝜃ˆ) JointLikelihoodofagent𝑖givendata𝑺𝑖,𝑡 ofsize𝑛𝑖,𝑡 atstate𝜃ˆintheprivateregime
𝝁𝑖,𝑡( 𝜃ˆ) Beliefofagent𝑖atiteration𝑡onstate𝜃ˆinthenon-privateregime
Δ𝝂𝑖 𝑖, ,𝑘 𝑡,( 𝑡(𝜃)ˆ ) SB ee nli se if tio vf ita yg oen ft ag𝑖 ea nt tit 𝑖e ara tt ii to en ra𝑡 tia ot nr 𝑡ound𝑘onstate𝜃ˆintheprivateregime
𝒅 D𝑖, 𝑖𝑡 ,𝑡( (𝜃ˆ 𝜃ˆ) ;𝜀/ )𝒅 /𝑖,𝑘 D(𝜃 𝑖ˆ ,𝑘) (𝜃ˆ;𝜀
)
NN oo ii ss ee dva isr ti ra ib bl ue tif oo nra fog ren at ge𝑖, ns tt 𝑖a ,te st𝜃 aˆ t, ea 𝜃n ˆd ,ai nte dra itt eio ran ti𝑡 o/r no 𝑡u /n rod u𝑘 nd𝑘
𝜈𝑖 Expectedvalueofnumberofsignalsthat𝑖observes
𝜉𝑖 Varianceofnumberofsignalsthat𝑖observes
𝛽★ Second-largesteigenvaluemodulusof𝐴
𝑛
𝛼★ Second-largesteigenvaluemodulusof 𝐴 𝐼 2
𝑛 ( + )/
Γ 𝑛,Θ Largestlikelihoodmagnitude
Δ 𝑛,Θ Globalsensitivity
𝑙𝑛,Θ MinimumKL-divergencebetweenanynon-MLEstateandanMLEstate
Ξ 𝑛 Sumofvariancesofnumbersofsignalsaccrossallagents
𝑉𝑛,Θ Sumofstandarddeviationsofthenoisesoverallagents
𝑄𝑛,Θ MaximumstandarddeviationofKL-divergenceforanyagentandanypairofstates
Table1. Notationtable.
algorithmfiltersouttoomanystates,missingsomeMLEstatesinitsoutput.InSection1wegave
examplesofcasesinmedicaldecisionmakingandloanapplicationscreeningwherestakeholders
maybeinterested inensuring noMLEstatesareleftoutwhendealingwith intractablediseases
(withaboundonfalsepositiverate)orinensuringthatallbadstatesarefilteredouttoavoidloan
defaults(withalevertocontrolmisseddetectionrate).Similarscenariosariseinotherapplication
too,e.g.,inbusinessormilitarystrategyonemayprioritizeremovingfalsepositive/type-Ierrorsto
avoidlaunchingattackswithoutconclusiveevidence,orotherwise,avoidmissingtheopportunity
tocapturehigh-valuetargetsbyremovingmisseddetection/type-IIerrors.
ToachieveguaranteesontheDPbudgetandthetwoerrorprobabilities,thealgorithmneedsto
berun𝑇 𝜀,𝜂 iterationsand𝐾 𝜀,𝜂 rounds,where𝜂herecorrespondstoeither𝜂 or𝜂 (depending
1 2
( ) ( )
onthealgorithm).
Wedefinethecommunicationcomplexity ofanalgorithm tocorrespondtothetotalnumber
A
ofbeliefupdates,whichequals𝐾 𝜀,𝜂 𝑇 𝜀,𝜂 inthedistributedMLEcaseand𝑇 𝜀,𝜂 intheonline
( )· ( ) ( )
learningcase.Table2showsthesummaryofourresultsforthetwotypesoflearningregimesforMariosPapachristouandM.AminRahimian 7
afixederrorprobability𝜂 (whicheithercorrespondstotheType-IortheType-IIerror)andfixed
privacybudget𝜀.
Beyondtheprivacybudget𝜀,theerrorprobability𝜂,andthenumberofagents𝑛,theresultsof
Table2alsodependonthestatisticalpropertiesoftheinformationenvironmentandthenetwork
structure,asdescribedbelow:
Regardingtheprivatesignalstrcutures,theboundsdependonthelargestlog-likelihoodmag-
•
nitude
Γ 𝑛,Θ = max log𝜸 𝑖,𝑡 𝜃ˆ ,
𝑖 𝑛 ,𝜃ˆ Θ| ( )|
∈[ ] ∈
theminimumdivergencebetweenanynon-MLEstateandanMLEstate
𝑛
𝑙 𝑛,Θ = min 𝜈 𝑖𝐷 𝐾𝐿 ℓ 𝑖 𝜃¯ ℓ 𝑖 𝜃★ ,
theglobalsensitivityΔ 𝑛,Θ =𝜃¯ ∈ mΘ¯,𝜃 a★ x∈ 𝑖Θ★ 𝑛(cid:12) (cid:12) (cid:12) (cid:12)Õ ,𝑖 𝑡=1 NΔ 𝑖,𝑡,th(cid:0) es( u·| m)| of( v· a| ria) n(cid:1)(cid:12) (cid:12) (cid:12) (cid:12)cesofthenumberofsignals
Ξ = 𝑛 𝜉 ,andthemaximumde∈ v[ ia(cid:12)] ti∈ onoftheKLdivergence3(cid:12)
𝑛 𝑖=1 𝑖
Í ℓ 𝜃¯
𝑄 𝑛,Θ =
𝑖 ∈[𝑛
],𝜃m
¯
∈a Θ¯x
,𝜃★
∈Θ★sV (cid:20)log
(cid:18)ℓ
𝑖𝑖 (( ·· |𝜃| ★) )(cid:19)(cid:21).
Regardingthegraphstructure,ourboundsdependonthesecond-largesteigenvaluemodulus
•
(SLEM)of𝐴,
𝛽★=max
𝜆 𝐴 , 𝜆 𝐴 ,
𝑛 { 2 ( ) | 𝑛 ( )|}
andtheSLEMof 𝐴 𝐼 2,
( + )/
𝛼★=
1 2 max 𝜆 𝐴 𝐼 , 𝜆 𝐴 𝐼 .
𝑛 ( / ) { 2 ( + ) | 𝑛 ( + )|}
3.2 DistributedMLE
InAlgorithm3,weproposeaDPversionofAlgorithm1fordistributedMLE.Thefirstideabehind
the new algorithm is to introduce multiplicative noise subjectto DP to the likelihoodfunctions
𝜸 𝜃ˆ .Addingmultiplicativenoise–whichcorrespondstoadditivenoiseinthelogdomain–en-
𝑖
( )
suresprivacy.Then,theagentscommunicatetheirbeliefsoverthestateswiththeirlocalneighbors
andformestimatesofthetrueMLEacrosstime.However,introducingnoisemakesthealgorithm
randomized– comparedto Algorithm1,whichis thedeterministic counterpart– andtherefore,
theagentsmaymisidentifytheMLEwithanon-trivialprobability.Toovercomethisproblem,we
run the algorithm for 𝐾 independent rounds and combine these 𝐾 estimates to produce the fi-
nal beliefs. By setting 𝐾 accordingly, we can reduce the algorithm’s error𝜂, which we show in
Theorem3.1.
Toproducethefinal estimates, werely ontwo waysofaggregatingthe𝐾 roundsofthealgo-
rithm:Thefirstapproachistotakethearithmeticmeanofthe𝐾 roundstoproducethefinalbelief,
whichwecalltheAM-Estimator.ThebenefitofAM-Estimatoristhatitcanaccuratelyw.h.p.iden-
tifyalltheMLEstates,i.e.,wecancontrolitsType-IIerrorprobability:P Θ★ * ΘˆAM 𝜂 .This
𝑖,𝑇 ≤ 2
estimatorhashighrecallbuthaslowprecisionsinceitcanrecoverasupehrsetofΘ★
.iThesecond
waytocombinethe𝐾 roundsistotakethegeometricmean,whichwecalltheGM-Estimator.For
theGM-Estimator wecancontroltheType-Ierror probability, P ΘˆGM * Θ★ 𝜂 ,to ensureit
𝑖,𝑇 ≤ 1
recoversasubsetofΘ★
w.h.p. h i
3Byapplyingthemainresultof[Ghosaletal.,2000],onecanrelate𝑄𝑛,Θtostatisticaldistances.MariosPapachristouandM.AminRahimian 8
Algorithm WithDP(ours) WithoutDP[RahimianandJadbabaie,2016b]
CommunicationComplexitywithrespectto𝜀,𝜂
M ML LE E( (A ThM r/ eG shM o) ld) O|Θ |,𝑛O|Θ lo|, g𝑛 𝜋(1 2( /l 𝜂o )g (( l1 o/ g𝜂 (1) /(l 𝜂o )g +(1 l/ o𝜂 g) (1+ /l 𝜀o )g +(1 l/ o𝜀 g) () 1) /𝑞
))
OO || ΘΘ || ,, 𝑛𝑛 (( 11 ))
OnlineLearning (cid:16) O|Θ |,𝑛 (cid:18)𝜂1 q𝜀1
(cid:19)
(cid:17) O|Θ |,𝑛(1 )
CommunicationComplexitywithrespectto𝑛
M ML LE E( (A ThM r/ eG shM o)
ld)
O|O
Θ
|| ,Θ 𝜀,| 𝜂,𝜀 ©,𝜂
𝜋1
2m max ax( lo lg og(cid:16)𝑙 (cid:16)𝑛𝑛 𝑙, 𝑛Θ
𝑛
,Θ(cid:17) (cid:17), ,lo lg o(cid:16) g𝑛 l (cid:18)o( 𝑛gΓ l𝑛 o( (1 gΓ,Θ 𝑛/ (𝛼 1,+
Θ
/𝑛★Δ
𝑞
𝛼+𝑛 ) 𝑛★Δ,Θ
𝑛
),) Θ(cid:17) )) (cid:19)!
ª
OO || ΘΘ || mm aa xx (( ll oo gg (cid:16)(cid:16)𝑙 𝑙𝑛 𝑛𝑛𝑛 , ,Θ Θ(cid:17) (cid:17), ,l ll lo oo og gg g(cid:16) (cid:16)( (𝑛 𝑛1 1/ /Γ Γ𝑛 𝑛𝛼 𝛼, ,𝑛 𝑛★ ★Θ Θ) )(cid:17) (cid:17)) )!
!
OnlineLearning O|Θ |, «𝜀,𝜂 s𝑛2  (max𝑖 ∈[ 𝑙𝑛 𝑛] ,Θ𝜈𝑖 (+ 1 −√Ξ (𝛽𝑛 𝑛★) )(cid:16)𝑄 2 )𝑛,Θ +Δ𝑛,Θ (cid:17)  ® ¬ O|Θ | r𝑛2 (ma 𝑙x 𝑛𝑖 ∈ ,Θ[𝑛 (1] −𝜈 (𝑖 𝛽+ 𝑛★√ )Ξ 2𝑛 ))𝑄𝑛,Θ !
© ª
CommunicationCom®plexitywithrespectto Θ
| |
M ML LE E( (A ThM r/ eG shM o) ld) O𝑛,𝜀 O,𝜂 𝑛,(cid:0)𝜀| ,Θ 𝜂|l lo o 𝜋gg 2|Θ« |Θ || l (cid:0)olo gg |Θ|Θ || ++ lolo gg (ΓΓ 𝑛𝑛 ,, ΘΘ ++ |Θ ||lΘ 𝑞og| |l Θo |g Δ𝑛| ,Θ Θ|¬ )Δ 𝑛,Θ ) (cid:1)(cid:1) O O𝑛 𝑛(cid:0)l lo og gΓ Γ𝑛 𝑛, ,Θ Θ(cid:1)
OnlineLearning (cid:16) O𝑛,(cid:16) 𝜀,𝜂 |Θ | (𝑄𝑛(cid:16),Θ 𝑙+ 𝑛| ,Θ Θ|Δ𝑛,Θ ) (cid:17)(cid:17)(cid:17) O𝑛 (cid:0) 𝑄 𝑙𝑛𝑛 ,Θ,Θ(cid:1)
(cid:18) r (cid:19) (cid:18)r (cid:19)
Table 2. Summary of estimators for a fixed privacy budget 𝜀 > 0 and target error 𝜂 0,1 . We use
∈ ( )
O𝑎1,...,𝑎𝑁 (·)todenotethebig-Onotationwheretheconstantsareallowedtodependon𝑎1,...,𝑎𝑁.Inoural-
gorithms,wehavesetthethreshold𝜚tobeaconstant.Theoverheadofintroducingprivacyisoutlinedinred.
Forcompactnessinnotation,𝜂referstomax 𝜂1,𝜂2 ,𝜋 referstomin 𝜋2,𝜋1 ,and𝑞referstomin 1 𝑞2,𝑞1
{ } { } { − }
(seeTheorems3.2and3.5).TheAM/GMalgorithmshavematchingcommunicationcomplexitieswhenever
𝑞=𝑂 1 and𝜋 =𝑂 1 Θ .
( ) ( / | |)
p
We first start with a result on the asymptotic behavior of Algorithm 3. Specifically, we show
that by repeating the algorithm, we can recover the MLE with high probability. The reason for
repeating the algorithm is that now the algorithm is randomized compared to the non-private
version,andtherefore,thealgorithmifrunfor𝐾 = 1rounds,canfailwithapositiveprobability
sinceaddingnoisetothelogdomaincanchangethesignofthelog-beliefratiobetweenanon-MLE
state𝜃¯ Θ¯ andanMLEstate𝜃★ Θ★ withpositiveprobability.Werepeatthealgorithm𝐾 times
∈ ∈
andconstructtwoestimatorstoaggregatetheresultstoachievethis.Wepresentthetheorem:
Theorem3.1. ForAlgorithm3,distributions 𝜃ˆ;𝜀 = 𝜀 thatsatisfy𝜀-DPanddonotdepend
𝑖 𝑖
D ( ) D ( )
onthestate𝜃ˆ,wehavethatas𝜚 ,
→∞
for𝐾 Θ¯ log Θ★ 𝜂 ,wehavethatlim P Θ★ ΘˆAM 1 𝜂 forall𝑖 𝑛 .
• ≥ | | (| |/ 2 ) 𝑇 →∞ ⊆ 𝑖,𝑇 ≥ − 2 ∈ [ ]
for𝐾 Θ★ log Θ¯ 𝜂 ,wehavethatlim PhΘˆGM Θ★i 1 𝜂 forall𝑖 𝑛 .
• ≥ | | (| |/ 1 ) 𝑇 →∞ 𝑖,𝑇 ⊆ ≥ − 1 ∈ [ ]
h i
ProofSketch.AtahighlevelfortheAM-Estimator,weshowthattheprobabilitythatanMLEstate
𝜃★ Θ★ endsupwithanon-zerobeliefatagivenround𝑘 𝐾 isatleast1 Θ¯ ,andtherefore
∈ ∈ [ ] /| |
we can show that the probability that the AM-Estimator gives a zero value to an MLE state is
exponentially small, i.e., at most𝑒 𝐾 Θ¯ , since thealgorithm is repeated𝐾 times independently.
− /| |
Therefore, the probability that any MLE state is misclassified by the AM-Estimator is at most
Θ★ 𝑒 𝐾 Θ¯ bytheunionbound.Makingthisprobabilityatmost𝜂 yieldsthevalueof𝐾.Asimilar
− /| | 2
a| rgu| mentcanworkfortheGM-Estimator. (cid:3)MariosPapachristouandM.AminRahimian 9
Algorithm3. PrivateDistributedMLE(AM/GM)
Inputs:Privacybudget𝜀,Errorprobabilities𝜂 ,𝜂 ,Log-beliefThreshold𝜚 > 0.
1 2
Initialization:Setthenumberofiterations𝑇 andthenumberofrounds𝐾 asindicatedby
Theorem 3.2 (for the non-asymptotic case) or Theorem 3.1 (for the asymptotic case), and
𝜏 =1 1 𝑒𝜚 .
/( + )
Procedure:Thefollowingisrepeatedin𝐾roundsindexedby𝑘 𝐾 .Ineachround𝑘,agents
∈ [ ]
beginbyforming noisy log-likelihoods𝝈
𝑖,𝑘
(𝜃ˆ
)
= 𝑒𝒅𝑖,𝑘(𝜃ˆ )𝜸
𝑖
(𝜃ˆ ),where𝜸
𝑖
(𝜃ˆ
)
= 𝑛 𝑗=𝑖 1ℓ
𝑖
(𝒔 𝑖𝑗 |𝜃˜
)
and 𝒅 𝜃ˆ 𝜃ˆ;𝜀 independently across agents𝑖 𝑛 and states 𝜃ˆ Θ. The agents
𝑖,𝑘 ( ) ∼ D𝑖 ( ) ∈ [ ] ∈ Î
initializetheirbeliefsto𝝂 𝜃ˆ =𝝈 𝜃ˆ 𝝈 𝜃˜ ,andoverthenext𝑇 timesteps,they
𝑖,𝑘,0
( )
𝑖,𝑘
( )/
𝜃˜ Θ 𝑖,𝑘
( )
communicatewith their neighborsand updat∈e their beliefs according to thefollowing rule
forany𝜃ˆand𝑡 𝑇 : Í
∈ [ ]
𝝂1 +𝑎𝑖𝑖 𝜃ˆ 𝝂𝑎𝑖𝑗 𝜃ˆ
𝑖,𝑘,𝑡 1( ) 𝑗,𝑘,𝑡 1( )
𝝂 𝜃ˆ = − 𝑗 ∈N𝑖 − (5)
𝑖,𝑘,𝑡 ( ) 𝝂1 +𝑎𝑖𝑖 𝜃˜Î 𝝂𝑎𝑖𝑗 𝜃˜ ·
𝑖,𝑘,𝑡 1( ) 𝑗,𝑘,𝑡 1( )
𝜃˜ Í∈Θ − 𝑗 Î∈N𝑖 −
After𝐾 rounds,theagentsaggregatetheoutcomeoftheroundsforevery𝜃ˆ Θasfollows:
∈
𝝂 𝜃ˆ 𝝂 𝜃ˆ 1 𝐾
𝝂AM 𝜃ˆ = 𝑘 ∈[𝐾 ] 𝑖,𝑘,𝑇 ( ), 𝝂GM 𝜃ˆ = 𝑘 ∈[𝐾 ] 𝑖,𝑘,𝑇 ( ) / (6)
𝑖,𝑇 ( ) Í 𝐾 𝑖,𝑇 ( ) 𝜃˜Î ∈Θ 𝑘 ∈[𝐾 ]𝝂 𝑖,𝑘,𝑇 (𝜃˜ )1 /𝐾·
Outputs:Return Í Î
ΘˆAM = 𝜃ˆ Θ:𝝂AM 𝜃ˆ 𝜏 , ΘˆGM = 𝜃ˆ Θ:𝝂GM 𝜃ˆ 𝜏
𝑖,𝑇 ∈ 𝑖,𝑇 ( ) ≥ 𝑖,𝑇 ∈ 𝑖,𝑇 ( ) ≥ ·
n o n o
Thefirst observation is that when 𝑓★ > 1 2,namely theMLEstates “dominate”Θ, using the
AM-Estimator requires fewer rounds than th/ e GM-Estimator, and whenever 𝑓★ < 1 2, namely
thenon-MLEstates“dominate”Θ,runningtheGM-Estimatorrequiresfewerroundsth/
antheAM-
Estimator,andwhen 𝑓★ = 1 2bothestimatorsneedtoberepeatedthesamenumberoftimesto
/
gettheguarantee.
Asasecondobservation,whenthereisamajorityofMLEstates, recoveringasupersetofthe
MLEstateswiththeAM-Estimatorguaranteesaccuracyofatleast50%duetoalowType-IIerror,
and, on the other hand, when the non-MLE states are a majority, the using the GM-Estimator
guaranteesaccuracyofatleast50%inrejectingthenon-MLEstatesduetoalowType-Ierror.
Finally,repeatingAlgorithm3for𝐾 Θ log Θ min 𝜂 ,𝜂 iterations,oneisabletoassert
1 2
thatΘˆGM Θ★ ΘˆAM as𝑡 withp≥ ro| ba| bilit( y| 1|/ 𝜂 { 𝜂 wi} t) houtknowledgeof𝑓★ .
𝑖,𝑡 ⊆ ⊆ 𝑖,𝑡 →∞ − 1 − 2
It is interesting to point out that the above theorem holds regardless of the noise (as long as
thenoisedistributiondoesnotdependonthestateforagivenagent)andshowsthatrandomizing
thealgorithmbyaddingnoisedeemstherepetitionofthealgorithmessentialforitbeingableto
succeedw.h.p.,contrarytothenon-privateversionwhichisdeterministic.Furthermore,choosing
D𝑖
(𝜀
)
=Lap 𝐾 |Θ 𝜀|Δ 𝑖 satisfies𝜀-DPandtheassumptionsofTheorem3.1.
Theprevio(cid:16)usanal(cid:17)ysisfocusedontheregimewhere𝑡 .Thenextquestionthatsurfacesis
→ ∞
studyingthebehaviorofAlgorithm3forfinite𝑡.Asonewouldexpect,thespeedofconvergence
dependsonthesumofstandarddeviationsofthenoise,i.e.,𝑉 𝑛,Θ = 𝑛 𝑖=1 V 𝒅𝑖∼D𝑖(𝜀
)
[𝒅 𝑖 ].
Í pMariosPapachristouandM.AminRahimian 10
Following,we give ahigh-probability boundonrecovering two sets ΘˆGM andΘˆAM,such that
𝑖,𝑇 𝑖,𝑇
ΘˆGM Θ★ ΘˆAM:
𝑖,𝑇 ⊆ ⊆ 𝑖,𝑇
Theorem3.2. ThefollowingholdforAlgorithm3:
•
For 𝑇
≥
max log lo(cid:16)g𝑙2 𝑛𝜚 2,Θ𝑛 (cid:17),log (cid:18)|Θ |2 (𝑛 lo− 2 g1 l (o)𝐾 1g /(( 1 𝛼𝑛 /𝜂 𝑛Γ ★𝑛 2 ), )Θ 𝜚+𝑉𝑛,Θ ) (cid:19)

and 𝐾
≥
|Θ¯ |log (|Θ★ |/𝜂 2 ), we have that
P Θ★ ΘˆAM 1 2𝜂 .
•
ΘFo[
★r𝑇
≥⊆ 1ma𝑖, 2𝑇
x
𝜂] .l≥ o
 g lo(cid:16)g𝑙2
𝑛𝜚−
2,𝑛 Θ
(cid:17),2
log (cid:18)|Θ |2 l( o𝑛 g− (21 𝜂 1)( 1 /𝑛 𝜚 𝛼Γ √𝑛 𝑛★𝐾,Θ )+𝑉𝑛,Θ ) (cid:19)
an
 d𝐾
≥
|Θ★ |log (|Θ¯ |/𝜂 1 ),wehavethatP [Θˆ 𝑖G ,𝑇M
⊆
1
The] o≥ ptim− aldistributionsthatminimizetheconvergencetime𝑇 forbothestimators,are ★ 𝜀 =
•   D𝑖 ( )
Lap Δ 𝑖𝐾 |Θ | .
𝜀
(cid:16) (cid:17)
ProofSketch.Toderivethenon-asymptoticresult,weconsiderthelog-beliefratiodynamics,which
arelinearwith respecttotheprimitive matrix𝐴 𝐼.Foreachround𝑘 𝐾 ,wecanshowthat
+ ∈ [ ]
thelog-beliefratiobetweenanypairofstates𝜃ˆ,𝜃ˇ Θhastwoterms:Thefirsttermthatdepends
∈
ontheprincipaleigenvalue𝛼 =2ofthematrix𝐴 𝐼 andthenoisylog-likelihoodratio𝑍 𝜃ˆ,𝜃ˇ =
1 𝑘
Λ 𝜃ˆ,𝜃ˇ 𝑛 𝒅 𝜃ˆ 𝑛 𝒅 𝜃ˇ , and the seco+ nd term decays with rate 𝛼★ and depe( nds) on
Γ 𝑛( ,Θ an) d+ 𝑉 𝑛,Θ𝑖= .1 To𝑖,𝑘 fi( nd) − the c𝑖= o1 nv𝑖 e,𝑘 r( ge) nce time𝑇 for each estimator, we first con𝑛 dition on the fact
that𝑍 𝜃ˆ,Í 𝜃ˇ and Λ 𝜃ˆ,𝜃ˇÍ have thesame sign which yields a value for𝐾 similar to Theorem3.1,
𝑘
( ) ( )
andthen conditioned onthis “good”event happening,we give a high-probability bound onthe
log-beliefratiobetweenanMLEstate𝜃★ andanon-MLEstate𝜃¯whichwemaketobeatleast𝜚,
andthereforethechoiceofthreshold𝜏 canreturnthedesiredsets(ΘˆGM Θ★ ΘˆAM)w.h.p.The
𝑖,𝑇 ⊆ ⊆ 𝑖,𝑇
distributionsthatoptimizetheruntimecanbefoundbyminimizing𝑉 𝑛,ΘsubjecttoDPconstraints
andareproventobeLaplacewithparametersΔ𝐾 Θ 𝜀 whereΔ isthesensitivityofagent𝑖,and
𝑖 𝑖
𝜀 𝐾 Θ istheprivacybudgetthatcorrespondseac| h| r/ oundandeachstateduetothecomposition
th/ e( or| em|) . (cid:3)
Remarkaboutthethreshold𝜚.Tominimizethecommunicationcomplexity,itsufficestopick
★
the optimal threshold𝜚 to be the one that makes the terms inside the maximum equal – and,
hence,themaximumisminimized–whichcorrespondstothefollowingtwooptimalthresholds:
★
𝜚★ = |Θ |2 (𝑛 −1 )𝐾 (𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ) log (lo 2g /𝛼2 𝑛★ ) 𝑙 𝑛,Θ l lo og g( (1 2/ /𝛼 𝛼𝑛 𝑛★) ) ,
AM 2log 1 𝜂 2𝑛
(cid:18) ( / 2 ) (cid:19) (cid:18) (cid:19)
𝜚★ = |Θ |2 (𝑛 −1 )(𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ) log (lo 2g /𝛼2 𝑛★ ) 𝑙 𝑛,Θ ll oo gg (( 21 // 𝛼𝛼 𝑛𝑛★★ )) .
GM 2𝜂 1√𝐾 ! (cid:18) 2𝑛 (cid:19)
Forsimplicity ofexposition,theresultspresentedinTable2correspondto𝜚 beingaconstant
number.
3.3 ATwo-ThresholdAlgorithmforRecoveringtheMLE
InAlgorithm4weprovideatwo-thresholdalgorithmtosimultaneouslycontrolbothtype-Iand
type-IIerrorprobabilities,withmoredesignflexibilitythatcomesatanincreasedcommunication
cost.MariosPapachristouandM.AminRahimian 11
Algorithm4. PrivateDistributedMLE(Two-ThresholdAlgorithm)
Inputs:Privacybudget𝜀,Errorprobabilities𝜂 ,𝜂 ,Log-beliefThreshold𝜚 > 0.
1 2
Initialization:Setthenumberofiterations𝑇 andthenumberofrounds𝐾,andthethresholds
𝜏thres,2,𝜏thres,1 asindicatedbyTheorem3.5(forthenon-asymptoticcase)orTheorem3.3(for
theasymptoticcase),and𝜏 =1 1 𝑒𝜚 .
/( + )
Procedure: The following is repeated in 𝐾 rounds indexed by 𝑘 𝐾 . In each round 𝑘,
∈ [ ]
theagentsbeginbyformingthenoisylog-likelihoods𝝈
𝑖,𝑘
𝜃ˆ =𝑒𝒅𝑖,𝑘(𝜃ˆ )𝜸
𝑖
𝜃ˆ ,where𝜸
𝑖
𝜃ˆ =
( ) ( ) ( )
𝑛𝑖 ℓ 𝒔𝑗 𝜃˜ and𝒅 𝜃ˆ 𝜃ˆ;𝜀 independently across agents𝑖 𝑛 and states𝜃ˆ Θ.
𝑗=1 𝑖 ( 𝑖| ) 𝑖,𝑘 ( ) ∼ D𝑖 ( ) ∈ [ ] ∈
The agents initialize their beliefs to 𝝂 𝜃ˆ = 𝝈 𝜃ˆ 𝝈 𝜃˜ . Over the next𝑇 time
Î 𝑖,𝑘,0 ( ) 𝑖,𝑘 ( )/ 𝜃˜ Θ 𝑖,𝑘 ( )
steps,theagentsupdatetheirbeliefaftercommunicatingwit∈htheirneighbors,andaccording
tothefollowingupdateruleforany𝜃ˆandall𝑡 𝑇 : Í
∈ [ ]
𝝂1 +𝑎𝑖𝑖 𝜃ˆ 𝝂𝑎𝑖𝑗 𝜃ˆ
𝑖,𝑘,𝑡 1( ) 𝑗,𝑘,𝑡 1( )
𝝂 𝜃ˆ = − 𝑗 ∈N𝑖 − (7)
𝑖,𝑘,𝑡 ( ) 𝝂1 +𝑎𝑖𝑖 𝜃˜Î 𝝂𝑎𝑖𝑗 𝜃˜ ·
𝑖,𝑘,𝑡 1( ) 𝑗,𝑘,𝑡 1( )
𝜃˜ Í∈Θ − 𝑗 Î∈N𝑖 −
After𝐾 rounds,eachagentaggregatestheoutcomeoftheroundsforevery𝜃ˆ Θasfollows:
∈
1
𝑵 𝜃ˆ = 1 𝝂 𝜃ˆ >𝜏 (8)
𝑖,𝑇 𝑖,𝑘,𝑇
( ) 𝐾 ( ) ·
𝑘Õ∈[𝐾 ] n o
Outputs:Return
Θˆthres,1 = 𝜃ˆ Θ:𝑵 𝜃ˆ 𝜏thres,1 , Θˆthres,2 = 𝜃ˆ Θ: 𝑵 𝜃ˆ 𝜏thres,2
𝑖,𝑇 ∈ 𝑖,𝑇 ( ) ≥ 𝑖,𝑇 ∈ 𝑖,𝑇 ( ) ≥ ·
n o n o
TheanalysisofTheorem3.1showsthatinagivenround𝑘,theprobabilityanMLEstate𝜃★ Θ
ends uppositive as𝑡 is atleast 1 Θ¯ , so inexpectationat least𝐾 Θ¯ rounds will yiel∈ da
positive
belief.Onthe→ oth∞ erhand,wek/ n| ow| thatforanon-MLEstate𝜃¯,/ o| ne|
xpectation,atmost
1 1 Θ★ 𝐾 trials will come up heads in expectation. For brevity, we define 𝑝 = 1 Θ¯ and
2
𝑝( =− 1/|
1
|Θ) ★
.
/| |
1
− /| |
Since𝑵 𝜃ˆ isanaverageofindependentindicatorvariablesforall𝜃ˆ Θ,theChernoffbound
𝑖,𝑇
( ) ∈
indicatesthatitconcentratesarounditsmeanE 𝑵 𝜃ˆ .Thispromptsthedevelopmentofthefol-
𝑖,𝑇
( )
lowingsimplealgorithm,whichresemblesboosthingalgoriithmssuchasAdaBoost[FreundandSchapire,
1997].Thealgorithmusestwothresholds𝜏thres,2,𝜏thres,1toestimatethetruestatesasthestatesfor
which the number of times their beliefs have exceeded a threshold𝜏 exceeds𝜏thres,2 and𝜏thres,1
respectively.ThealgorithmissummarizedinAlgorithm4.
Ourfirstresultconsiderstheasymptoticregimewherethenumberofiterations𝑇 goestoinfinity.
Wepresentthetheorembelow:
Theorem3.3. ForAlgorithm4,distributions 𝜃ˆ;𝜀 = 𝜀 that are𝜀-DPand donotdepend
𝑖 𝑖
D ( ) D ( )
onthestate𝜃ˆ,wehavethatas𝜚 ,
→∞
•
forany𝜋 1 > 0,𝜏thres,1 = (1 +𝜋 1 )𝑝 1,and𝐾
≥
log ( 2|Θ 𝜋¯ 1|2/𝜂1),wehavethat
lim P Θˆthres,1 Θ★ 1 𝜂 ,
𝑇 𝑖,𝑇 ⊆ ≥ − 1
→∞ h i
forall𝑖 𝑛 .
∈ [ ]MariosPapachristouandM.AminRahimian 12
•
forany𝜋 2 > 0,𝜏thres,2 = (1 −𝜋 2 )𝑝 2,and𝐾
≥
log (| 2Θ 𝜋★ 2|/𝜂2),wehavethat
2
lim P Θ★ Θˆthres,2 1 𝜂 ,
𝑇 ⊆ 𝑖,𝑇 ≥ − 2
→∞ h i
forall𝑖 𝑛 .
∈ [ ]
Proof Sketch. The proof is very similar to Theorem 3.1, with the only difference that instead of
relyingonindependentevents,weusetheChernoffboundon𝑵 𝜃ˆ . (cid:3)
𝑖,𝑇
( )
SimilarlytoTheorem3.1,theestimatorΘˆ1,threshasalowType-IerrorandtheestimatorΘˆ2,thres
𝑖,𝑇 𝑖,𝑇
hasalowType-IIerror.Iftheagentsdonothaveknowledgeof
Θ★
theycanusethethresholds
| |
𝜏thres,1′ = 1 𝜋
1
𝑝
1
𝜏thres,1 and𝜏thres,2′ = 1 𝜋
2
𝑝
2
𝜏thres,2 andobtainthesameguarantee.
( + ) ≥ ( − ) ≤
Also,runningthealgorithmfor𝐾 max
log (|Θ |/𝜂1),log (|Θ |/𝜂2)
wecanguaranteethatas𝑇 ,
≥ 2𝜋2 2𝜋2 →∞
1 2
wehaveΘthres,2 Θ★ Θthres,1 withprobnabilityatleast1 𝜂 o 𝜂 .
𝑖,𝑇 ★⊆ ⊆ 𝑖,𝑇 − 1 − 2
Since𝑵 𝜃 fortheMLEstatesareconcentratedaroundadistributionwithameanthatisat
𝑖,𝑇
least1 Θ¯ an( d,s) imilarly,𝑵 𝜃¯ forthenon-MLEstatesareconcentratedaroundtheirexpectation
𝑖,𝑇
which/ i|
s
a|
t most 1 1
Θ★ ,( on)
e may rightly question whether it is possible to achieve perfect
predictionofΘ★ ass− um/ in| gt|
hetwomodesare“sufficiently”well-separated.Theanswertothisis
affirmativeaslongas𝑝 >𝑝 andisgivenbythefollowingCorollary:
2 1
Corollary3.4(ExactRecoverywithaSingleThreshold). IfthedensityofMLEstates 𝑓★
satisfies
0 < 𝑓★ 1, if1 < Θ 4
≤ | | ≤ , (9)
(0 < 𝑓★
≤
1
2 −
21 |Θ Θ|−4
∨
21
+
1
2
|Θ Θ|−4 < 𝑓★
≤
1, otherwise
| | | |
thetwothresholds areseteqq ual,i.e.,𝜏thres,2 = 𝜏thq res,1 whichcorrespondstoΘˆthres,2 = Θˆthres,1 and
𝑖,𝑇 𝑖,𝑇
𝜋 1 = (1 −𝜋 2 )𝑝𝑝 12 −𝑝 1forsome𝜋 2 > 0,and𝐾 ≥ max log ( 2|Θ 𝜋 12|/𝜂1),log ( 2|Θ 𝜋 2| 2/𝜂2) wehavethat
n o
lim P Θˆthres,2 =Θ★ 1 𝜂 𝜂 .
𝑇 𝑖,𝑇 ≥ − 1 − 2
→∞ h i
ProofSketch.Therangeof 𝑓★ isderivedbysolvingtheinequality 1 > 1 1 ,andthe
1 𝑓★ Θ − 𝑓★Θ
restfollowsbyapplyingTheorem3.3. ( − )| | | | (cid:3)
Furthermore,byperformingananalysissimilartoTheorem3.2,wecanderiveanon-asymptotic
result:
Theorem3.5. Let𝑞 ,𝑞 0,1 .ThenforAlgorithm4thefollowinghold:
1 2
∈ ( )
•
For any 𝜋 1 > 0,𝜏thres,1 = (1 +𝜋 1 )𝑞 1,𝑇
≥
max
log lo(cid:16)g𝑙2 𝑛𝜚 2,𝑛
Θ
(cid:17),log (cid:18)|Θ |2 l( o𝑛 g− (1 ) 12( /𝑞𝑛 𝛼1Γ 𝜚𝑛 𝑛★,Θ )+𝑉𝑛,Θ )
(cid:19) , and 𝐾
≥
log ( 2|Θ 𝜋¯ 1| 2/𝜂1),wehavethatP Θˆ 𝑖th ,𝑇res,1
⊆
Θ★
≥
1 −𝜂 1.

•
For any 𝜋
2
> 0,𝜏thres,2 =h (1 −𝜋
2
)𝑞 2,𝑇i
≥
max log lo(cid:16)g𝑙2 𝑛𝜚 2,𝑛 Θ (cid:17),log (cid:18)|Θ |2 l( o𝑛 g− 2 (1 () 11( /−𝑛 𝛼𝑞Γ𝑛 2 𝑛★),Θ )𝜚+𝑉𝑛,Θ ) (cid:19) , and 𝐾
≥
Tlo hg e(| 2Θ o𝜋 p★ 22 t|/ i𝜂 m2) a, lw die sth ria bv ue tit oh na st tP hahΘ tm★ i⊆ nimΘˆ i𝑖th , z𝑇r ees t, h2 eic≥ on1 ve− rg𝜂  e2 n.
cetime𝑇
forbothestimators,
are ★ 𝜀 =
• D𝑖 ( )
Lap Δ 𝑖𝐾 |Θ | .
𝜀
(cid:16) (cid:17)MariosPapachristouandM.AminRahimian 13
ProofSketch.TheproofutilizestheconvergenceresultsprovedinTheorem3.2,andtheconcentra-
tionof𝑵 𝜃ˆ similarlytoTheorem3.3. (cid:3)
𝑖,𝑇
( )
Remarks.Wecanpickthelog-beliefthresholdsas
𝜚★ = |Θ |2 (𝑛 −1 )(𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ) log (lo 2g /𝛼2 𝑛★ ) 𝑙 𝑛,Θ ll oo gg (( 21 // 𝛼𝛼 𝑛𝑛★★ )) ,
thres,1 2𝑞 1√𝐾 ! (cid:18) 2𝑛 (cid:19)
𝜚★ = |Θ |2 (𝑛 −1 )(𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ) log (lo 2g /𝛼2 𝑛★ ) 𝑙 𝑛,Θ ll oo gg (( 21 // 𝛼𝛼 𝑛𝑛★★ )) ,
thres,2 2 (1 −𝑞 2 )√𝐾 ! (cid:18) 2𝑛 (cid:19)
tominimizethenumberofiterations.
Further,wecanshowthatwecanachieveperfectrecoveryaslongas𝑞 > 𝑞 .Moreover,itis
2 1
easytoobservefromtheabovethatthecommunicationcomplexitycanbeminimizedbysetting
1 𝑞 ascloseaspossibleto𝑞 .However,achievingperfectrecoveryoftheMLEcomesatacost
2 1
−
tothecommunicationcomplexity,whichhasapolylogarithmicdependenceontheinverseofthe
gap 1 𝑞 𝑞 .
2 1
| − − |
3.4 OnlineLearningfromIntermittentStreams
InAlgorithm5,weintroducetheonlineversion,wheretheagentshaveaccesstoadatastreamat
everyiteration.Inthiscase,thelog-beliefratiobetweenanMLEstate𝜃★ andanon-MLEstate𝜃¯
isgoing toconvergeto 1 𝑛 𝑛 𝜈 𝐷 ℓ 𝜃¯ ℓ 𝜃★ as𝑡 andtheeffectofDP noise
(− / )
𝑖=1 𝑖 𝐾𝐿 𝑖
(·| )|
𝑖
(·| ) → ∞
is going to vanish as a consequence of the Césaro mean. The weak law of large numbers, and
Í (cid:0) (cid:1)
therefore the agents are going to learn the MLE states exponentially fast without the need to
repeatthealgorithmmultipletimes.Thenexttheoremcharacterizesthenon-asymptoticbehavior
ofAlgorithm5:
Algorithm5. PrivateOnlineLearning
Inputs:Privacybudget𝜀,Errorprobabilities𝜂,Log-beliefThreshold𝜚 >0.
Initialization:Setthenumberofiterations𝑇 asinTheorem3.6,and𝜏 =1 1 𝑒𝜚 .
/( + )
Procedure:Every time𝑡 N ,eachagentformsthelikelihoodproductofthesignalsthat
0
it has received at that tim∈ e period:𝜸 𝜃ˆ = 𝑛𝑖,𝑡 ℓ 𝒔𝑗 𝜃ˆ , if 𝑛 1, and𝛾 𝜃ˆ = 1 if
𝑖,𝑡 ( ) 𝑗=1 𝑖 ( 𝑖,𝑡| ) 𝑖,𝑡 ≥ 𝑖,𝑡 ( )
𝑛 = 0. The agent then draws a noise variable 𝒅 𝜃ˆ 𝜃ˆ;𝜀 for all 𝑖 𝑛 ,𝜃ˆ Θ
𝑖,𝑡 Î 𝑖,𝑡 ( ) ∼ D𝑖,𝑡 ( ) ∈ [ ] ∈
independently and forms 𝝈
𝑖,𝑡
𝜃ˆ = 𝑒𝒅𝑖,𝑡(𝜃ˆ )𝜸
𝑖,𝑡
𝜃ˆ for all𝜃ˆ Θ. The agent then updates its
( ) ( ) ∈
belieffor𝑇 iterationsaccordingto:
𝝈 𝜃ˆ 𝝂𝑎𝑖𝑖 𝜃ˆ 𝝂𝑎𝑖𝑗 𝜃ˆ
𝝂 𝑖,𝑡 (𝜃ˆ ) =
𝜃˜
Θ𝑖 𝝈,𝑡 𝑖( ,𝑡 () 𝜃˜ )𝑖, 𝝂𝑡 − 𝑖𝑎 ,𝑡𝑖1 𝑖 −( 1() 𝜃˜ Î
)
𝑗 ∈ 𝑗N ∈𝑖 N𝑖𝑗 𝝂,𝑡 − 𝑎 𝑗,𝑖 𝑡1 𝑗 −( 1() 𝜃˜ ), (10)
Í∈ Î
initializedby:𝝂 𝜃ˆ =𝝈 𝜃ˆ 𝝈 𝜃˜ .
𝑖,0
( )
𝑖,0
( )/
𝜃˜ Θ 𝑖,0
( )
∈
Outputs:After𝑇 iterations,retÍurnΘˆOL = 𝜃ˆ Θ:𝝂 𝜃ˆ 𝜏 .
𝑖,𝑇 ∈ 𝑖,𝑡 ( ) ≥
n oMariosPapachristouandM.AminRahimian 14
Theorem3.6. RunningAlgorithm5,for
𝑇 =
O
(cid:18)smax (cid:26)𝑛 |Θ |2 (𝑛𝑄 𝑛,Θ 2+
𝑙
𝑛𝑉 ,Θ𝑛, 𝜂Θ () 1(m −a (x 𝛽𝑖 𝑛★∈ )[𝑛
2
)]𝜈 𝑖 + pΞ 𝑛 /𝜂 ), r𝑙𝑛 𝑛,𝜚
Θ
(cid:27)(cid:19)
iterations,yieldsP Θ★ ΘˆOL 1 2𝜂.Subsequently,thedistributionsthatoptimizetheruntime
⊆ 𝑖,𝑇 ≥ −
are ★ =Lap Δ 𝑖,𝑡h |Θ | . i
D𝑖,𝑡 𝜀
(cid:16) (cid:17)
ProofSketch.Inthiscase,wecansimilarlyprovethatthedynamicsinthelog-beliefratiospaceare
linear. Theproof starts byshowing thatthedeviation of 1 𝑡 𝑡 1𝑛 from𝜈 isno morethan
( / )
𝜏−=0 𝑖,𝜏 𝑖
Ξ 𝜂𝑡 withprobabilityatleast1 𝜂.Subsequently,conditionedonthis“good”event,weshow
𝑛
/( ) − Í
pthatthedistancebetweentheaveragelog-beliefratio 1 𝑡 log 𝝂
𝑖,𝑡
𝜃ˆ 𝝂
𝑖,𝑡
𝜃ˇ betweenanypair
( / ) ( )/ ( )
ofstatesconvergesto 1 𝑛 𝑛 𝜈 𝐷 ℓ 𝜃ˆ ℓ 𝜃ˇ isinvers(cid:16)elyproportion(cid:17)alto√𝑡,1 𝛽★ 2,
( / ) 𝑖=1 𝑖 𝐾𝐿 𝑖 (·| )| 𝑖 (·| ) −( 𝑛)
andisproportionaltothesta Índarddevia(cid:16)tionoftheK(cid:17)Ldivergence𝑄 𝑛,Θ aswellas𝑉 𝑛,Θ.Similarly
toTheorem3.2,wethresholdthelog-beliefratiobetweenanMLEstateandanon-MLEstateand
obtaintheconvergencetime𝑇.TheoptimaldistributionsarederivedsimilarlytoTheorem3.2. (cid:3)
4 RELATEDWORK
In this section, we review the following collections of literature on privacy and group-decision
making: (i) differential privacy, (ii) works at the intersection of group decision-making and so-
ciallearning,(iii)privacyprotectionsinsocialnetworkcontexts,and(iv)literatureindistributed
learningandestimation.
4.1 DifferentialPrivacy
Dataprivacyhasevolvedtoincorporatevariousconcepts,including𝐾-anonymity.Inthemodern
definition,amechanismisconsidereddifferentiallyprivateifitassignssimilarrecordstothesame
valuewithequallikelihood.Thisdefinition hasa significantimplication: itensures thattheout-
comeofastatisticalanalysisremainsconsistentregardlessofanindividual’sparticipationinthe
social learning process. Numerous existing mechanisms,such as randomized response [Warner,
1965], the Laplacemechanism, and the Gaussian mechanism, canbe demonstrated to adhere to
differential privacy principles. Randomized response, for example, introduces random perturba-
tionstobinaryresponses,enablingtheretrievalofthepopulationmeanswhileallowingindividual
respondentstomaintainplausibledeniability.Itservesasanexampleofaddingnoisetodata.
Whenitcomestohandlingdonateddataforpurposeslikeprovidingrecommendationstopublic
policy agencies or submitting online product reviews on e-commerce platforms, it is crucial to
protecttheprivacyofdatadonors.Thisisbecausecommonanonymizationtechniquesusedinsuch
scenariosaresusceptibletodifferenttypesofattacks,includingidentificationrisks[Barbaroetal.,
2006], linkage and cross-referencing vulnerabilities [Sweeney, 1997, 2015], as well as statistical
differenceandre-identificationattacks[Kumaretal.,2007].Therefore,safeguardingtheprivacyof
donors’informationbecomesanessentialaspectofstatisticaldisclosurecontrolinthesecontexts.
OurworkcontributestotheliteratureonDPbyutilizingDPtechniquestoenablegroupdecision-
makingindistributedenvironments.
4.2 GroupDecision-MakingandSocialLearning
Theproblemofaggregatingdifferentindividuals’opinionsandobservationsintoacoherentcollec-
tiveoptionarisesnaturallyinjurydeliberations,expertcommittees,medicaldiagnoses,orboard
meetings where several stakeholdershave to agree ona factual basis despite heterogeneity andMariosPapachristouandM.AminRahimian 15
uncertaintyoftheir opinionsandprivateinformation.Acommonwaytoresolvedisagreements
insuchcontextsistoengageinrepeatedpeerinteractions.Subsequently,alonglineofliterature
goingbacktoseminalworksof[Aumann,1976,DeGroot,1974,GeanakoplosandPolemarchakis,
1982]investigatestheformationandevolutionofBayesianandnon-Bayesianbeliefstowardscon-
sensusagreement.Thisproblemhascloseparallelsindistributedestimation[BorkarandVaraiya,
1982,TsitsiklisandAthans,1984],datafusion[McLaughlinetal.,2003],aswellasconsensusand
coordinationindistributedcontrol[Jadbabaieetal.,2003,MesbahiandEgerstedt,2010].Thefor-
mation, evolution, and aggregation of beliefs in distributed environments have attracted a lot
ofinterestinstatistics[Garthwaiteetal.,2005,Genestetal.,1984,GenestandZidek,1986],engi-
neering[BorkarandVaraiya,1982,Boydetal.,2006,Cortesetal.,2005,HatanoandMesbahi,2005,
Kayaalpetal., 2022, Moreau, 2005, Rabbatetal., 2005, RenandBeard, 2005, Shahrampouretal.,
2015,Tanneretal.,2007,TsitsiklisandAthans,1984,Xiaoetal.,2005],philosophy[Conradtetal.,
2013,Dietrichetal.,2016,LehrerandWagner,1981,ListandPuppe,2009],sociology[FriedkinandJohnsen,
1990,HegselmannandKrause,2002],machinelearning[StoicaandPapadimitriou,2021],andeco-
nomics[Banerjeeetal.,2021,DeMarzoetal.,2003,GolubandJackson,2010,2012,Jadbabaieetal.,
2012],amongothers.
Ofparticularinteresttousinthispaperisthegrowingliteratureonnon-Bayesianinformation
aggregation and opinion pooling, going back to the classical work of DeGroot [DeGroot, 1974],
whoproposeslinearopinionpoolsbyaveragingthelatestbeliefsofeachagentwiththatoftheir
neighbors.Several asymptotic properties andextensions of this model,including streams of pri-
vatesignalsovertime,arestudiedintheliterature[DeMarzoetal.,2003,GolubandJackson,2010,
Jadbabaieetal., 2012]. To combine beliefs on a finite set of alternatives, we use geometric aver-
aging and logarithmic opinion pools which also have a long history in Bayesian analysis and
behavioral decision models [GilardoniandClayton, 1993, Rufoetal., 2012] and they can be jus-
tifiedunderspecificaxioms[Molavietal.,2018]orderivedasano-recall,behavioralupdaterule
[RahimianandJadbabaie,2015,2016a,Rahimianetal.,2015].Inthispaper,weaskhowoneshould
limittheinformationrequirementofanon-Bayesianupdatetoguaranteedifferentialprivacyand
stillensureconsensusagreementandasymptoticlearningfortheagents.
4.3 PrivacyinSocialNetworkContexts
WithourformulationofDPfordistributedlearningenvironments,wecanfocusonprivacyleaks
through information flow on the network rather than the underlying network structure. More
broadly, the fundamental relationship between information flow and privacy is well noted, cf.,
contextual integrity [BenthallandCummings, 2022, Nissenbaum, 2009] or how social network
contexts affect link formation and information sharing behaviors [Acemogluetal., 2017, 2022].
Notwithstanding,theprivacyimplicationsofinformationdiffusionandalgorithmicintervention
onsocialnetworksarelargelyunexplored,exceptinafewstudies[Liell-Cocketal.,2020,Rahimianetal.,
2023a,b]. The existing work looks at this issue in specific, highly stylized scenarios. One study
showsthatitisextremelyhardtohidetheexistenceofagiant,connectedcomponentofinfected
nodes under an independent cascademodel,and a simple inference attack canreveal the status
of a good fraction of nodes [Rezaeietal., 2021]. In another study, the authors propose a decay-
ingpseudo-noisethatisaddedlocallytomasktheinfluencestructureagainstanexternalobserver
withaccesstotheentireinformationflowundertheFriedkin-Johnseninfluencepropagationmodel
[Liell-Cocketal.,2020].
4.4 LiteratureinDistributedLearningandEstimation
Animportantdistinctionbetweenestimatingacontinuousquantityin[Kangetal.,2023,Lietal.,
2018,PapachristouandRahimian,2023]andchoosingfromadiscretesetinthisworkisinthefactMariosPapachristouandM.AminRahimian 16
thatDPrandomizationinthelattercaseinducesanon-trivialfailureprobabilitythatisbounded
awayfromzerowithincreasingnumberofiterations.Hence,inourwork,tosatisfactorilycontrol
the quality of the group decision outcome, we need the agents to repeat their deliberations in
multiple rounds and then aggregate the outcome of several rounds towards a collective belief.
Different aggregation schemes are possible (e.g., based on arithmetic or geometric averaging of
thebeliefsandusingdifferentthresholdrulestoidentifytheselectedalternatives),whichleadto
differentfalsepositiveandmisseddetectionratesandcomewiththeirownprivacyguaranteeand
communicationcomplexityrequirements.
5 DISCUSSIONSANDCONCLUSIONS
First,fortheAM/GMestimators,weconcludethatintroducingprivacyinthedistributedMLEtask
incursapolylog 1 𝜀,1 𝜂 costcomparedto thenon-privatebenchmarkwithrespectto𝜀 and𝜂,
aswellasapoly(Θ/ ,lo/ g)Δ 𝑛,Θ costcomparedtothenon-privatebenchmarkwithrespectto Θ.
| | ( ) | |
Second,inthetwo-thresholdregime,thedistributedMLEtaskincursapolylog 1 𝜀,1 𝜂,1 𝑞 cost
withrespectto𝜀(cid:0) and𝜂,aswell(cid:1) asapoly 1 𝜋, Θ,Δ 𝑛,Θ,log 1 𝑞 overheadwit( hr/ esp/ ectto/ )Θ.
/ | | ( / ) | |
Weobservethefollowingtrade-offbetweentheAM/GMalgorithm(Algorithm3)andthetwo-
(cid:0) (cid:1)
thresholdalgorithm(Algorithm4):whilethetwo-thresholdalgorithmhasmorefreeparameters
andisthereforemoreflexiblethantheAM/GMalgorithm,theaddedflexibilityofthetwo-threshold
algorithmcomesatacosttoitscommunicationcomplexity.
Moreover,intheonlinelearningregime,weenduphavingapoly 1 𝜀,1 𝜂 dependencycom-
pared to the non-private benchmark with respect to 𝜀 and𝜂, and a
p( o/
ly
Θ/ ,)Δ
𝑛,Θ dependency
withrespectto
Θ.Thisshowsthatachievingthesameprivacyandaccura| cy|
levelsintheonline
| | (cid:0) (cid:1)
caserequiresmanymorecommunicationroundsthanintheMLEcase.
Theaboveresultsprovetheutilityoflog-linearopinionpoolsforgroupdecisionmakingwhen
choosingfromasetofalternatives inprivacy-criticalenvironments. Our algorithmscanprotect
both private signals as well as the network neighborhoods(Signal and Network DP). Although
signalDPcanbeachievedefficientlyovertime,protectionofnetworkneighborhoodislimitedto
aone-timeattackbyaneavesdropper.Thisisduetothefactthatbeliefsarecorrelatedovertime
andacrossnetworkneighborhoods,whereasprivatesignalsareindependentandremainprotected
at the𝜀-DP level by thepost-processing immunity [DworkandRoth, 2014, Proposition 2.1].Ex-
tendingnetworkprotectionsoverafinite(𝑁)numberofattacksispossibleusingthecomposition
property [DworkandRoth, 2014, Chapter3] andby reducing theprivacy budgetto𝜀 𝑁, which
/
requireslargenoiselevelsandcomesatahighcosttocommunicationandaccuracy.
In summary, our paper touches on topics at the intersections of group-decision making and
privacy. While our work is purely theoretical in nature and does not pose – to the best of our
knowledge – specific ethical challenges, the societal and policy impact of our work should be
highlighted.Our work hasapplications for distributed hypothesis testing problems, such as, for
example,testingdrugtreatmentsandloanscreening,atwhichmultipleentitieswanttoestimate
thetruestateofnaturebasedonobservations fromtheirneighborswithoutexposingtheir own
informationandprovideprotocolsforinformationfusiondependingontheapplication.
Work on such sensitive applications may necessitate developing or adapting privacy regula-
tions.Policymakersmayneedtoconsiderbalancingthebenefitsofcollaborativedecision-making
withprotectingindividualprivacyandintellectualproperty,especiallygiventhatouralgorithms
providethecorrectanswerwithahighprobability(butarestillsusceptibletonegligibleerrors).
Ourpaper’sapproachallowsentitiestobenefitfromeachother’sprivateinformationwithout
compromising data security. Asa result, organizationscanimprove thequality of their services
through enhanced decision-making without violating privacy obligations, positively impactingMariosPapachristouandM.AminRahimian 17
efficiencyandcostsavings.Forinstance,collaborativehypothesistestingindrugtreatmentsmight
streamlineresearch,reducingredundanteffortsandcosts.
ACKNOWLEDGMENTS
M.P. was partially supported by a LinkedIn Ph.D. Fellowship, an Onassis Fellowship (ID: F ZT
056-1/2023-2024),andgrantsfromtheA.G.Leventis Foundation andtheGerondelis Foundation.
M.A.R.waspartiallysupportedbyNSFSaTC-2318844.Theauthorswouldliketothanktheseminar
participantsatRutgersBusinessSchool,JalajUpadhyay,JonKleinberg,KateDonahue,andVasilis
Charisopoulosfortheirvaluablediscussionsandfeedback.
REFERENCES
DaronAcemoglu,AliMakhdoumi,AzarakhshMalekian,andAsumanOzdaglar.2017.Privacy-constrainednetworkforma-
tion.GamesandEconomicBehavior105(2017),255–275.
DaronAcemoglu,AliMakhdoumi,AzarakhshMalekian,andAsuOzdaglar.2022.Toomuchdata:Pricesandinefficiencies
indatamarkets.AmericanEconomicJournal:Microeconomics14,4(2022),218–256.
AppleDifferentialPrivacyTeam.2017.LearningwithPrivacyatScale.https://machinelearning.apple.com/research/learning-with-privacy-at-
Accessed:2023-05-18.
R.J.Aumann.1976.Agreeingtodisagree.Theannalsofstatistics(1976),1236–1239.
AbhijitBanerjee,EmilyBreza,ArunGChandrasekhar,andMarkusMobius.2021.Naivelearningwithuninformedagents.
AmericanEconomicReview111,11(2021),3540–3574.
MichaelBarbaro,TomZeller,andSaulHansell.2006. AfaceisexposedforAOLsearcherno.4417749. NewYorkTimes9,
2008(2006),8.
SebastianBenthallandRachelCummings.2022. Integratingdifferentialprivacyandcontextualintegrity.In2022USENIX
ConferenceonPrivacyEngineeringPracticeandRespect(SantaClara,CA,USA).
V.BorkarandP.P.Varaiya.1982.Asymptoticagreementindistributedestimation.IEEETrans.Automat.Control27,3(Jun
1982),650–655.
StephenBoyd,ArpitaGhosh,BalajiPrabhakar,andDevavratShah.2006.Randomizedgossipalgorithms.IEEETransactions
onInformationTheory52,6(2006),2508–2530.
LarissaConradt,ChristianList,andTimothyJRoper.2013. Swarmintelligence:Whenuncertaintymeetsconflict. The
AmericanNaturalist182,5(2013),592–610.
J.Cortes,S.Martinez,andF.Bullo.2005. Analysisanddesigntoolsfordistributedmotioncoordination.InProceedingsof
theAmericanControlConference.Portland,OR,1680–1685.
M.H.DeGroot.1974.Reachingaconsensus.JournalofAmericanStatisticalAssociation69(1974),118–121.
P.M.DeMarzo,D.Vayanos,andJ.Zwiebel.2003. Persuasionbias,socialinfluence,andunidimensionalopinions. The
QuarterlyJournalofEconomics118(2003),909–968.
FranzDietrich,ChristianList,andRichardBradley.2016. Beliefrevisiongeneralized:AjointcharacterizationofBayes’
andJeffrey’srules.JournalofEconomicTheory162(2016),352–371.
CynthiaDworkandAaronRoth.2014. Thealgorithmicfoundationsofdifferentialprivacy. FoundationsandTrends®in
TheoreticalComputerScience9,3–4(2014),211–407.
UErlingsson.2014.Learningstatisticswithprivacy,aidedbytheflipofacoin.GoogleSecurityBlog,October(2014).
YoavFreundandRobertESchapire.1997. Adecision-theoreticgeneralizationofon-linelearningandanapplicationto
boosting.Journalofcomputerandsystemsciences55,1(1997),119–139.
NoahEFriedkinandEugeneCJohnsen.1990. Socialinfluenceandopinions. JournalofMathematicalSociology15,3-4
(1990),193–206.
SimsonGarfinkel.2022. Differentialprivacyandthe2020UScensus. TechnicalReport.MITSchwarzmanCollegeofCom-
puting.
PaulHGarthwaite,JosephBKadane,andAnthonyO’Hagan.2005.Statisticalmethodsforelicitingprobabilitydistributions.
J.Amer.Statist.Assoc.100,470(2005),680–701.
J.D.GeanakoplosandH.M.Polemarchakis.1982. Wecan’tdisagreeforever. JournalofEconomicTheory28,1(1982),
192–200.
ChristianGenest,SamaradasaWeerahandi,andJamesVZidek.1984. Aggregatingopinionsthroughlogarithmicpooling.
TheoryandDecision17,1(1984),61–70.
ChristianGenestandJamesVZidek.1986.Combiningprobabilitydistributions:Acritiqueandanannotatedbibliography.
Statist.Sci.(1986),114–135.MariosPapachristouandM.AminRahimian 18
SubhashisGhosal,JayantaKGhosh,andAadWVanDerVaart.2000.Convergenceratesofposteriordistributions.Annals
ofStatistics(2000),500–531.
G.L.GilardoniandM.K.Clayton.1993.OnreachingaconsensususingDeGroot’siterativepooling.TheAnnalsofStatistics
(1993),391–401.
B.GolubandM.O.Jackson.2010. NaïveLearninginSocialNetworksandtheWisdomofCrowds. AmericanEconomic
Journal:Microeconomics2,1(Feb.2010),112–149.
BenjaminGolubandMatthewO.Jackson.2012. HowHomophilyAffectstheSpeedofLearningandBest-ResponseDy-
namics. TheQuarterlyJournalofEconomics127,3(2012),1287–1338.
Y.HatanoandM.Mesbahi.2005.Agreementoverrandomnetworks.IEEETrans.Automat.Control50,11(2005),1867–1872.
R.HegselmannandU.Krause.2002.Opiniondynamicsandboundedconfidencemodels,analysisandsimulation.Journal
ofSocietiesandSocialSimulation5,3(2002).
A.Jadbabaie,J.Lin,andA.S.Morse.2003. Coordinationofgroupsofmobileautonomousagentsusingnearestneighbor
rules.IEEETrans.Automat.Control48,6(2003),988–1001.
A.Jadbabaie,P.Molavi,A.Sandroni,andA.Tahbaz-Salehi.2012. Non-Bayesiansociallearning. GamesandEconomic
Behavior76,1(2012),210–225.
JustinKang,RamtinPedarsani,andKannanRamchandran.2023. TheFairValueofDataUnderHeterogeneousPrivacy
Constraints.arXivpreprintarXiv:2301.13336(2023).
MertKayaalp,YunusInan,EmreTelatar,andAliHSayed.2022. Onthearithmeticandgeometricfusionofbeliefsfor
distributedinference.arXivpreprintarXiv:2204.13741(2022).
MichaelKearns,MalleshPai,AaronRoth,andJonathanUllman.2014. Mechanismdesigninlargegames:Incentivesand
privacy.InProceedingsofthe5thconferenceonInnovationsintheoreticalcomputerscience.403–410.
FragkiskosKoufogiannis,ShuoHan,andGeorgeJPappas.2015.Optimalityofthelaplacemechanismindifferentialprivacy.
arXivpreprintarXiv:1504.00065(2015).
RaviKumar,JasmineNovak,BoPang,andAndrewTomkins.2007. Onanonymizingquerylogsviatoken-basedhashing.
InProceedingsofthe16thinternationalconferenceonWorldWideWeb.629–638.
KeithLehrerandCarlWagner.1981.RationalConsensusinScienceandSociety,APhilosophicalandMathematicalStudy.D.
ReidelPublishingCompany,Dordrecht,Holland.
ChenchengLi,PanZhou,LiXiong,QianWang,andTingWang.2018. Differentiallyprivatedistributedonlinelearning.
IEEETransactionsonKnowledgeandDataEngineering30,8(2018),1440–1453.
JackLiell-Cock,IanRManchester,andGuodongShi.2020.PreservingprivacyoftheinfluencestructureinFriedkin-Johnsen
systems.In202059thIEEEConferenceonDecisionandControl(CDC).IEEE,6254–6259.
ChristianListandClemensPuppe.2009.Judgmentaggregation:Asurvey.HandbookofRationalandSocialChoice(2009).
SamuelMcLaughlin,VikramKrishnamurthy, andSubhashChalla.2003. Managingdataincestinadistributedsensor
network.InIEEEInternationalConferenceonAcoustics,Speech,andSignalProcessing(ICASSP’03),Vol.5.IEEE,V–269.
M.MesbahiandM.Egerstedt.2010.GraphTheoreticMethodsinMultiagentNetworks.PrincetonUniversityPress.
PooyaMolavi,AlirezaTahbaz-Salehi,andAliJadbabaie.2018.Atheoryofnon-Bayesiansociallearning.Econometrica86,
2(2018),445–490.
L.Moreau.2005. StabilityofMultiagentSystemsWithTime-DependentCommunication Links. IEEETrans.Automat.
Control50,2(2005),169–182.
HelenNissenbaum.2009.Privacyincontext.InPrivacyinContext.StanfordUniversityPress.
MariosPapachristou andMAminRahimian.2023. DifferentiallyPrivateDistributedEstimationandLearning. arXiv
preprintarXiv:2306.15865(2023).
MichaelGRabbat,RobertDNowak,andJamesABucklew.2005.Generalizedconsensuscomputationinnetworkedsystems
witherasurelinks.InSignalProcessingAdvancesinWirelessCommunications,2005IEEE6thWorkshopon.IEEE,1088–
1092.
M.A.RahimianandA.Jadbabaie.2015. LearningwithoutRecall:ACaseforLog-LinearLearning. 5thIFACWorkshopon
DistributedEstimationandControlinNetworkedSystems(2015).
MAminRahimianandAliJadbabaie.2016a.Bayesianlearningwithoutrecall.IEEETransactionsonSignalandInformation
ProcessingoverNetworks3,3(2016),592–606.
MAminRahimianandAliJadbabaie.2016b. Distributedestimationandlearningoverheterogeneousnetworks.InCom-
munication,Control,andComputing(Allerton),201654thAnnualAllertonConferenceon.IEEE,1314–1321.
M.A.Rahimian,S.Shahrampour,andA.Jadbabaie.2015. LearningwithoutRecallbyRandomWalksonDirectedGraphs.
IEEEConferenceonDecisionandControl(CDC)(2015).
MAminRahimian,Fang-YiYu,andCarlosHurtado.2023a. DifferentiallyPrivateNetworkDataCollectionforInfluence
Maximization.InProceedingsofthe2023InternationalConferenceonAutonomousAgentsandMultiagentSystems.2795–
2797.MariosPapachristouandM.AminRahimian 19
MAminRahimian,Fang-YiYu,andCarlosHurtado.2023b.SeedingwithDifferentiallyPrivateNetworkInformation.arXiv
preprintarXiv:2305.16590(2023).
W.RenandRWBeard.2005.Consensusseekinginmultiagentsystemsunderdynamicallychanginginteractiontopologies.
IEEETrans.Automat.Control50,5(2005),655–661.
AriaRezaei,JieGao,andAnandDSarwate.2021. InfluencersandtheGiantComponent:TheFundamentalHardnessin
PrivacyProtectionforSociallyContagiousAttributes.InProceedingsofthe2021SIAMInternationalConferenceonData
Mining(SDM).SIAM,217–225.
M.J.Rufo,J.Martin,C.J.Pérez,etal.2012.Log-LinearPooltoCombinePriorDistributions:ASuggestionforaCalibration-
BasedApproach. BayesianAnalysis7,2(2012),411–438.
ShahinShahrampour,AlexanderRakhlin,andAliJadbabaie.2015. Distributeddetection:Finite-timeanalysisandimpact
ofnetworktopology. IEEETrans.Automat.Control61,11(2015),3256–3268.
Ana-AndreeaStoicaandChristosPapadimitriou.2021.Strategicclustering.InLearninginthepresenceofstrategicbehaviour
Workshop(StratML),inNeuralInformationProcessingSystems.
LatanyaSweeney.1997.Weavingtechnologyandpolicytogethertomaintainconfidentiality.TheJournalofLaw,Medicine
&Ethics25,2-3(1997),98–110.
LatanyaSweeney.2015.Onlyyou,yourdoctor,andmanyothersmayknow.TechnologyScience2015092903,9(2015),29.
H.Tanner,A.Jadbabaie,andG.Pappas.2007.FlockinginFixedandSwitchingNetworks.IEEETrans.Automat.Control52,
5(2007),863–868.
J.N.TsitsiklisandM.Athans.1984. Convergenceandasymptoticagreementindistributeddecisionproblems. Automatic
Control,IEEETransactionson29,1(1984),42–50.
StanleyLWarner.1965. Randomizedresponse:Asurveytechniqueforeliminatingevasiveanswerbias. J.Amer.Statist.
Assoc.60,309(1965),63–69.
L.Xiao,S.Boyd,andS.Lall.2005. Aschemeforrobustdistributedsensorfusionbasedonaverageconsensus.InFourth
InternationalSymposiumonInformationProcessinginSensorNetworks(IPSN).63–70.MariosPapachristouandM.AminRahimian 20
A DISTRIBUTEDMLE
A.1 Log-BeliefRatioNotations
Let𝝁 𝜃ˆ bethebeliefsforthenon-privatesystem,andlet𝝂 𝜃ˆ betheprivateestimatesfor
𝑖,𝑡 𝑖,𝑘,𝑡
( ) ( )
agent𝑖 𝑛 ,round𝑘 𝐾 andround𝑡 0.For thenon-private algorithm (Algorithm1) all
∈ [ ] ∈ [ ] ≥
p anai drs th𝜃ˆ e,𝜃ˇ
lo∈
g-lΘ ikew lie hole ot d𝝓 r𝑖, a𝑡
t(
i𝜃 oˆ, s𝜃ˇ
r)
es= pelo ctg iv(cid:16)e𝝁𝝁 l𝑖𝑖 y,, 𝑡𝑡 (( f𝜃𝜃 ˇˆ o)) r(cid:17)aa gn ed nt𝝀 𝑖 𝑖(𝜃ˆ,𝜃ˇ
)
𝑛= rl oo ug n(cid:16)d𝜸 𝜸𝑖
𝑖
𝑡( (𝜃 𝜃ˆ ˇ)
)
(cid:17)0b .e Ft oh re tl ho eg pb re ivli ae tf era at li go os
-
∈ [ ] ≥
𝒅rithm 𝜃ˆ(Al 𝒅gorit 𝜃h ˇm be3) thw ee pl re ivt a𝝍 te𝑖,𝑘 l, o𝑡
(
g𝜃 -ˆ, b𝜃 eˇ
)
lie= frl ao tg io(cid:16),𝝂𝝂 lo𝑖𝑖 ,, 𝑘𝑘 g,, 𝑡𝑡 -(( l𝜃𝜃 iˇˆ k)) e(cid:17)l, i𝜻 h𝑖
o(
o𝜃ˆ d,𝜃ˇ
r)
at= ioalo ng d(cid:16)n𝝈𝝈 o𝑖𝑖 ,, 𝑘𝑘 is(( e𝜃𝜃 ˇˆ )) d(cid:17)iff, ea rn ed nc𝜿 e𝑖,𝑘
r(
a𝜃 tˆ i, o𝜃ˇ
s)
re=
-
𝑖,𝑘 𝑖,𝑘
( )− ( )
spectivelyforagent𝑖 𝑛 ,round𝑘 𝐾 andround𝑡 0.Wealsoletthevectorizedversions
∈ [ ] ∈ [ ] ≥
𝝓 𝜃ˆ,𝜃ˇ ,𝝍 𝜃ˆ,𝜃ˇ ,𝝀 𝜃ˆ,𝜃ˇ ,𝜻 𝜃ˆ,𝜃ˇ respectively,wherethevectorizationisovertheagents𝑖 𝑛 .
𝑡( ) 𝑘,𝑡( ) ( ) 𝑘( ) ∈ [ ]
WedefineΛ 𝜃ˆ,𝜃ˇ =1𝑇𝝀 𝜃ˆ,𝜃ˇ ,𝑍 𝜃ˆ,𝜃ˇ =1𝑇𝜻 𝜃ˆ,𝜃ˇ =1𝑇 𝝀 𝜃ˆ,𝜃ˇ 𝜿 𝜃ˆ,𝜃ˇ .
( ) ( ) 𝑘 ( ) 𝑘( ) ( )+ 𝑘 ( )
Wesaythatastochasticprocess 𝑋 𝑡 𝑡 N
convergesin𝐿(cid:16)
2
to𝑋,andwrite𝑋(cid:17)
𝑡
𝐿2
𝑋,ifandonly
{ } ∈ → 𝑝
iflim E 𝑋 𝑋 =0.Convergencein𝐿 impliesconvergenceinprobability(i.e.,𝑋 𝑋)
𝑡 𝑡 2 2 𝑡
→∞ [k − k ] →
duetoMarkov’sinequality.
A.2 AuxiliaryLemmas
Toprovetheresultsweneedthefollowingauxiliarylemma:
LemmaA.1. Let𝑋 ,...,𝑋 bei.i.d.randomvariablesdrawnfromadistribution .Then,forevery
1 𝑛
D
𝑖 𝑛 ,wehavethatP 𝑋
𝑖
max 𝑗≠𝑖𝑋
𝑗
=1 𝑛.
∈ [ ] [ ≥ ] /
Proof. Let𝐸
𝑖
= 𝑋
𝑖
max 𝑗≠𝑖𝑋
𝑗
.Notethatbecause𝑋 1,...,𝑋
𝑛
arei.i.d.P 𝐸
1
=P 𝐸
2
= =
{ ≥ } [ ] [ ] ···
P 𝐸 .Moreover,notethatsincethemaximumisunique,wehavethat𝐸 ,...,𝐸 areapartition
𝑛 1 𝑛
of[ the] samplespace.Therefore,wegetthat P 𝐸 =1,andsubsequentlyP 𝐸 =1 𝑛. (cid:3)
𝑖 ∈[𝑛 ] [ 𝑖 ] [ 𝑖 ] /
A.3 ProofofTheorem3.1 Í
Proof. Similarlyto[RahimianandJadbabaie,2016b,Theorem1],wehavethatforany𝑘 𝐾
∈ [ ]
2𝑡 𝑛 𝛼 𝑡
𝝍 𝜃ˆ,𝜃ˇ 𝑍 𝜃ˆ,𝜃ˇ 1 = 𝑖 𝒍 𝒓𝑇𝜻 𝜃ˆ,𝜃ˇ
(cid:13) (cid:13) (cid:13) (cid:13) 𝑘,𝑡( )− 𝑛 𝑘 ( ) (cid:13) (cid:13) (cid:13) (cid:13)2 (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)Õ 𝑛𝑖=2 𝛼(cid:16) 𝑖2 𝑡(cid:17) 𝒍 𝑖 𝑖 𝒓𝑇𝑘 𝜻( 𝜃ˆ) ,(cid:13) (cid:13) (cid:13) (cid:13) (cid:13)𝜃ˇ2
≤ 2 k 𝑖 k2 𝑖 𝑘( )
Õ𝑖=2(cid:12)
(cid:12) (cid:12) (cid:12)
𝑛 (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)𝛼 𝑖(cid:12)𝑡
𝜻
𝜃ˆ(cid:12) ,𝜃ˇ (cid:12)
≤ 2 𝑘( ) 2
Õ𝑖=2(cid:12)
(cid:12) (cid:13) (cid:13)
𝑛 (cid:12) (cid:12) (cid:13) (cid:13)
(cid:12)𝛼 𝑖(cid:12)𝑡(cid:13) 𝝀 𝜃ˆ,𝜃ˇ (cid:13) 𝜿 𝜃ˆ,𝜃ˇ .
𝑘
≤ 2 ( ) 2+ ( ) 2
Õ𝑖=2(cid:12)
(cid:12) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
TakingexpectationsandapplyingJensen’sineq(cid:12)ual(cid:12)ity,(cid:13)wecan(cid:13)bou(cid:13)ndtheab(cid:13)oveas
(cid:12) (cid:12) (cid:13) (cid:13) (cid:13) (cid:13)
E 𝝍 𝑘,𝑡(𝜃ˆ,𝜃ˇ
)−
2 𝑛𝑡 𝑍 𝑘 (𝜃ˆ,𝜃ˇ )1
≤
2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 𝑛Γ 𝑛,Θ
+
𝑛 V 𝒅 𝑖,𝑘 (𝜃ˆ
)
, (11)
(cid:20)(cid:13)
(cid:13)
(cid:13) (cid:13)2(cid:21) " Õ𝑖=1r
h
i#
whereΓ 𝑛,Θ =(cid:13) (cid:13)max 𝑖 𝑛 ,𝜃ˆ Θ |log𝜸 𝑖 (𝜃ˆ )|.N(cid:13) (cid:13)otethattheright-handsideinEquation(11)goesto0as
∈[ ] ∈
𝑡 ,whichimpliesthat(byMarkov’sInequality)𝝍 𝜃ˆ,𝜃ˇ 𝐿2 2𝑡 𝑍 𝜃ˆ,𝜃ˇ 1.
→∞ 𝑘,𝑡( ) → 𝑛 𝑘 ( )MariosPapachristouandM.AminRahimian 21
Let𝜃★ Θ★ and𝜃¯ Θ¯.BasedonourdefinitionofΛ , weshouldhaveΛ 𝜃¯,𝜃★ < 0andthe
correspon∈ dingnon-pr∈
ivatealgorithmwouldhave𝜙
𝜃¯( ,· 𝜃★·) forevery𝜃(¯ Θ¯) and𝜃★ Θ★
.
𝑖,𝑡
( ) →−∞ ∈ ∈
However, when noise is introduced, there could be mistakes introduced in the log-belief ratios,
evenifΛ 𝜃¯,𝜃★ <0wehavethat𝑍 𝜃¯,𝜃★ 0whichwillimplythat𝝍 𝜃¯,𝜃★ .
𝑘 𝑖,𝑘,𝑡
AM-Es( tima) tor.For all𝜃ˆ Θ we( let 𝒀) ≥ 𝜃ˆ = 𝑛 𝒅 𝜃ˆ . We focus on( a sin) g6→ le𝜃−★∞ Θ★ . It
∈
𝑗
( )
𝑖=1 𝑖,𝑘
( ) ∈
iseasytoshowthatbecausethenoiseisindependentontheagents,andi.i.d.onthestatesfora
givenagent𝑖,then𝒀 𝜃¯ and𝒀 𝜃★ arealso i.i.d.Í forall𝜃¯ Θ¯,andthereforewehavethat(see
𝑗 𝑗
( ) ( ) ∈
TheoremA.1)
lim P 𝝂 𝜃★ > 0 P 𝒀 𝜃¯ 𝒀 𝜃★ = 1
𝑇 →∞
(cid:2)
𝑖,𝑘,𝑇 ( )
(cid:3)
≥ " 𝜃Ù¯ ∈Θ¯
(cid:8)
𝑘 ( ) ≤ 𝑘 ( ) (cid:9)# |Θ¯ |
Therefore,fortheAMestimatorwehavethat
𝑇lim P 𝝂 𝑖A ,𝑇M (𝜃★
)
=0 = 𝑇lim P 𝝂
𝑖,𝑘,𝑇
(𝜃★
)
=0
≤
1
−
Θ1
¯
𝐾 ≤𝑒− |𝐾 Θ¯
|
(12)
→∞
(cid:2) (cid:3)
→∞  𝑘Ù∈[𝐾
](cid:8)
(cid:9)

(cid:18) | |(cid:19)
 
andthefailureprobabilityoftheAMestimatorcanbecalculatedbyapplyingtheunionbound
 
as  
lim P Θ★ * ΘˆAM = lim P 𝜃★ Θ★ :𝝂AM 𝜃★ =0
𝑇 𝑖,𝑇 𝑇 ∃ ∈ 𝑖,𝑇 ( )
→∞ →∞
(cid:2) (cid:3) lim (cid:2) P 𝝂AM 𝜃★ =0 (cid:3)
≤𝑇 𝑖,𝑇 ( )
→∞𝜃★ Õ∈Θ★
(cid:2) (cid:3)
Θ★ 𝑒−𝐾
Θ¯ .
≤ | | | |
Setting𝐾 = Θ¯ log Θ★ 𝜂 ,theType-IIerrorisatmost𝜂 .
2 2
| | (| |/ )
GM-Estimator.Similarly,for𝝂GM wehavethat
𝑖,𝑇
1
lim P 𝝂 𝜃¯ =0 P 𝒀 𝜃¯ 𝒀 𝜃★ =
𝑇 →∞ 𝑖,𝑘,𝑇 ( ) ≥ " 𝜃★ Θ★ 𝑘 ( ) ≤ 𝑘 ( ) # |Θ★ |
(cid:2) (cid:3) Ù∈ (cid:8) (cid:9)
forall𝜃¯ Θ¯ andsubsequently
∈
𝑇lim P 𝝂 𝑖G ,𝑇M (𝜃¯
)
>0 = 𝑇lim P 𝝂
𝑖,𝑘,𝑇
(𝜃¯
)
> 0
≤
1
−
Θ1
★
𝐾 ≤𝑒− |Θ𝐾 ★ |,
→∞
(cid:2) (cid:3)
→∞  𝑘Ù∈[𝐾
](cid:8)
(cid:9)

(cid:18) | |(cid:19)
 
and  
 
 
lim P ΘˆGM * Θ★ = lim P ΘˆGM Θ¯ ≠
𝑇 𝑖,𝑇 𝑇 𝑖,𝑇 ∩ ∅
→∞ →∞
(cid:2) (cid:3) = lim P(cid:2) 𝜃¯ Θ¯ :𝝂GM(cid:3)𝜃¯ > 0
𝑇 ∃ ∈ 𝑖,𝑇 ( )
→∞
lim (cid:2) P 𝝂GM 𝜃¯ >0 (cid:3)
≤𝑇 𝑖,𝑇 ( )
→∞𝜃Õ¯ ∈Θ¯
(cid:2) (cid:3)
Θ¯ 𝑒− Θ𝐾 ★ .
≤ | | | |MariosPapachristouandM.AminRahimian 22
Therefore,picking𝐾 = Θ★ log Θ¯ 𝜂 makestheType-Ierroratmost𝜂 .
1 1
| | (| |/ ) (cid:3)
A.4 ProofofTheorem3.2
Proof. GM-Estimator.Welet𝒀 𝜃ˆ = 𝒅 𝜃ˆ .
Wedefinetheevent𝐹 = 𝑘 𝐾𝑘 ( ,𝜃) ¯ Θ¯,𝑖 𝜃∈★[𝑛 ] Θ𝑖,𝑘 ★( :) 𝑍GM 𝜃¯,𝜃★ > Λ 𝜃¯,𝜃★ .Wehavethat
∃ ∈ [ ] ∈ Í ∈ ( ) ( )
(cid:8) (cid:9)
P 𝐹 (i) P 𝑘 𝐾 ,𝜃★ Θ★ :𝑍 𝜃¯,𝜃★ >Λ 𝜃¯,𝜃★
𝑘
[ ] ≤ ∃ ∈ [ ] ∈ ( ) ( )
𝜃Õ¯ ∈Θ¯
(cid:2) (cid:3)
( =ii) 1 P 𝜃★ Θ★ :𝑍 𝜃¯,𝜃★ Λ 𝜃¯,𝜃★ 𝐾
1
− ∀ ∈ ( ) ≤ ( )
𝜃Õ¯ ∈Θ¯
(cid:0) (cid:2) (cid:3)(cid:1)
𝐾
(iii) Θ¯ 1 P 𝒀 𝜃¯ 𝒀 𝜃★
1 1
≤ | | − ( ) ≤ ( )
" 𝜃Ù¯ ∈Θ¯
(cid:8)
(cid:9)#!
𝐾
(iv) 1
Θ¯ 1
≤ | | − Θ★
(cid:18) | |(cid:19)
(v) Θ¯ 𝑒 𝐾 Θ★ ,
− /| |
≤ | |
wheretheabovefollows(i)fromtheapplicationoftheunionbound,(ii)usingthefactthatthe𝐾
r tho au Ftn o{d r𝒀s
e𝑘
aa
(
cr 𝜃¯e h)}i rn
𝜃
o¯d
∈
uΘe
¯
np dae nn 𝑘dd oe
𝒀
fn
𝑘
tt
(
h,
𝜃
e( ★ii
)
ai)
la
gt
r
oh
e
re
ii
t.f
i
h.a
d
mc .t
,
a(t ih nva d)t
T
e{
h
a𝑍 ce1 ho( r𝜃 p¯ e, am𝜃 ir★ A)
o.
f1≤
s,
taΛ
an
t( ed𝜃¯ s, (v𝜃 𝜃ˆ)★ ,𝜃1) ˇ} +⊇
𝑥 ΘÑ≤
,t𝜃 h𝑒¯ ∈𝑥 eΘ¯
f fo o(cid:8)r
l𝒀 l𝑘 oa( wll𝜃¯ i𝑥) n≤
g∈
hR𝒀 o𝑘
.
l( d𝜃 s★ f)
o(cid:9)
ra tn hd
e
∈
log-beliefratioofthegeometricallyaveragedestimates:
1
𝝍GM 𝜃ˆ,𝜃ˇ = 𝝍 𝜃ˆ,𝜃ˇ .
𝑖,𝑡 ( ) 𝐾 𝑖,𝑘,𝑡 ( )
𝑘Õ∈[𝐾
]
Welet𝑍GM 𝜃ˆ,𝜃ˇ = 1 𝐾 𝑍 𝜃ˆ,𝜃ˇ .BythetriangleinequalityandTheorem3.1
( ) 𝐾 𝑘=1 𝑘 ( )
Í
2𝑡 1 𝐾 2𝑡
E 𝝍 𝜃ˆ,𝜃ˇ 𝑍GM 𝜃ˆ,𝜃ˇ 1 E 𝝍 𝜃ˆ,𝜃ˇ 𝑍 𝜃ˆ,𝜃ˇ 1 . (13)
𝑡( )− 𝑛 ( ) ≤ √𝐾 𝑘,𝑡( )− 𝑛 𝑘 ( )
(cid:20)(cid:13)
(cid:13)
(cid:13) (cid:13)2(cid:21) Õ𝑘=1 (cid:20)(cid:13)
(cid:13)
(cid:13) (cid:13)2(cid:21)
Foreveryro(cid:13)und𝑘 𝐾 , (cid:13) (cid:13) (cid:13)
(cid:13) ∈ [ ] (cid:13) (cid:13) (cid:13)
2𝑡 𝑛 𝛼 𝑡
𝝍 𝜃ˆ,𝜃ˇ 𝑍 𝜃ˆ,𝜃ˇ 1 = 𝑖 𝒍 𝒓𝑇𝜻 𝜃ˆ,𝜃ˇ
(cid:13) (cid:13) 𝑘,𝑡( )− 𝑛 𝑘 ( ) (cid:13) (cid:13)2 (cid:13) (cid:13)Õ𝑖=2 (cid:16) 2 (cid:17) 𝑖 𝑖 𝑘( )(cid:13) (cid:13)2
(cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)𝑛 𝛼 𝑖 𝑡 𝒍 𝒓𝑇𝜻 𝜃ˆ,(cid:13) (cid:13) (cid:13)𝜃ˇ
≤ 2 k 𝑖 k2 𝑖 𝑘( )
Õ𝑖=2(cid:12)
(cid:12) (cid:12) (cid:12)
𝑛 (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)𝛼 𝑖(cid:12)𝑡
𝜻
𝜃ˆ(cid:12) ,𝜃ˇ (cid:12)
≤ 2 𝑘( ) 2
Õ𝑖=2(cid:12)
(cid:12) (cid:13) (cid:13)
𝑛 (cid:12) (cid:12) (cid:13) (cid:13)
(cid:12)𝛼 𝑖(cid:12)𝑡(cid:13) 𝝀 𝜃ˆ,𝜃ˇ (cid:13) 𝜿 𝜃ˆ,𝜃ˇ .
𝑘
≤ 2 ( ) 2+ ( ) 2
Õ𝑖=2(cid:12)
(cid:12) (cid:16)(cid:13) (cid:13) (cid:13) (cid:13) (cid:17)
(cid:12) (cid:12) (cid:13) (cid:13) (cid:13) (cid:13)
(cid:12) (cid:12) (cid:13) (cid:13) (cid:13) (cid:13)MariosPapachristouandM.AminRahimian 23
TakingexpectationsandapplyingJensen’sinequality,wecanboundtheaboveas
2𝑡 𝑛
E 𝝍 𝑘,𝑡(𝜃ˆ,𝜃ˇ
)−
𝑛𝑍 𝑘 (𝜃ˆ,𝜃ˇ )1
≤
2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 𝑛Γ 𝑛,Θ
+
V 𝒅 𝑖,𝑘 (𝜃ˆ
)
,
(cid:20)(cid:13)
(cid:13)
(cid:13) (cid:13)2(cid:21) " Õ𝑖=1r
h
i#
ThereforeE(cid:13)quation(13)becomes (cid:13)
(cid:13) (cid:13)
E 𝝍 𝜃ˆ,𝜃ˇ 2𝑡 𝑍GM 𝜃ˆ,𝜃ˇ 1 2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 [𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ]. (14)
𝑡( )− 𝑛 ( ) ≤ √𝐾
(cid:20)(cid:13) (cid:13)2(cid:21)
(cid:13) (cid:13)
ByMarkov’sineq(cid:13)ualityandEquation(13),w(cid:13)egetthatforevery𝑧 > 0
(cid:13) (cid:13)
P 𝝍GM 𝜃ˆ,𝜃ˇ 2𝑡 𝑍GM 𝜃ˆ,𝜃ˇ 1 >𝑧 2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 [𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ].
𝑡 ( )− 𝑛 ( ) ≤ 𝑧√𝐾
(cid:20)(cid:13) (cid:13)2 (cid:21)
(cid:13) (cid:13)
WelettheRHS(cid:13) (cid:13)beequalto𝜂 1 /(|Θ★ ||Θ¯ |,whi(cid:13) (cid:13)chcorrespondstoletting𝑧 = |Θ¯ ||Θ★ |2 (𝑛 −1 )(𝛼 𝑛★ 𝜂) 1𝑡 √[ 𝐾𝑛Γ 𝑛,Θ +𝑉𝑛,Θ ].
ByapplyingaunionboundoverΘ¯ andΘ★ wehavethatforevery𝜃¯ Θ¯ and𝜃★ Θ★ ,withprob-
∈ ∈
abilityatleast1 𝜂 ,
1
−
𝝍GM 𝜃¯,𝜃★ 2𝑡 𝑍GM 𝜃¯,𝜃★ Θ¯ Θ★ 2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 [𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ]. (15)
𝑖,𝑡 ( ) ≤ 𝑛 ( )+| || | 𝜂 √𝐾
1
Conditioningon𝐹𝑐,theabovebecomes
𝝍GM 𝜃¯,𝜃★ 2𝑡 Λ 𝜃¯,𝜃★ Θ¯ Θ★ 2 (𝑛 −1 )(𝛼 𝑛★ )𝑡 [𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ]
𝑖,𝑡 ( ) ≤ 𝑛 ( )+| || | 𝜂 √𝐾
1
2𝑡
𝑙 𝑛,Θ
Θ2(𝑛 −1 )(𝛼 𝑛★ )𝑡 [𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ
]. (16)
≤ −𝑛 +| | 2𝜂 √𝐾
1
TomakeEquation(16)atmost 𝜚 forsome𝜚 >0,weneedtoset
−
log 2𝜚𝑛 log |Θ |2 (𝑛 −1 )(𝑛Γ 𝑛,Θ +𝑉𝑛,Θ )
𝑡 max
𝑙𝑛,Θ
,
2𝜂1𝜚√𝐾
=𝑇.
≥  lo(cid:16)g2 (cid:17) (cid:16) log (1 /𝛼 𝑛★
)
(cid:17) 
𝑒𝜚𝝂The lo 𝜃¯g- .b Te oli def etr ea rt mio inth er te hs eh bo el d lieim ftp hl ri ee ss ht oh la dt 𝜏f ,o nr oa tl el t𝜃 h★
at∈
Θ★ ,𝜃¯
∈
Θ ¯ we have that𝝂
𝑖,𝑘,𝑇
(𝜃★
) ≥
𝑖,𝑘,𝑇
( )
1= 𝝂 𝜃ˆ 𝝂 𝜃ˆ 1 𝑒𝜚 max 𝝂 𝜃ˆ
𝑖,𝑘,𝑇 𝑖,𝑘,𝑇 𝑖,𝑘,𝑇
𝜃ˆ ∈ÕΘˆ 𝑖G ,𝑇M
( )+
𝜃ˆ∉ÕΘˆ 𝑖G ,𝑇M
( ) ≥ ( + ) 𝜃ˆ∉Θ 𝑖G ,𝑇M ( )
1
= max 𝝂 𝜃ˆ .
⇒ 𝜃ˆ∉ΘGM 𝑖,𝑘,𝑇 ( ) ≤ 1 𝑒𝜚
𝑖,𝑇 +
Moreover,wecanprovethatmin 𝝂 𝜃ˆ 1 1 since𝜚 > 0whichshowsthat
𝜃ˆ ∈Θˆ 𝑖G ,𝑇M 𝑖,𝑘,𝑇 ( ) ≥ 1 +𝑒 −𝜚 ≥ 1 +𝑒𝜚
any value in 1 1 𝑒𝜚 ,1 1 𝑒 𝜚 is a valid threshold. This yields that P ΘˆGM Θ★ 𝐹𝑐 =
[ /( + ) /( + − )] [ 𝑖,𝑇 ⊆ | ]MariosPapachristouandM.AminRahimian 24
P ΘˆGM Θ¯ = 𝐹𝑐 = P 𝜃¯ Θ¯ : 𝝂GM 𝜃¯ > 𝜏 𝐹𝑐 1 𝜂 . Subsequently, by letting 𝐾 =
[ 𝑖,𝑇 ∩ ∅| ] [∃ ∈ 𝑖,𝑇 ( ) | ] ≥ − 1
Θ★ log Θ¯ 𝜂 ,wegetthat
1
| | (| |/ )
P ΘˆGM Θ★ P ΘˆGM Θ★ 𝐹𝑐 P 𝐹𝑐 1 𝜂 2 1 2𝜂 .
[ 𝑖,𝑇 ⊆ ] ≥ [ 𝑖,𝑇 ⊆ | ] [ ] ≥ ( − 1 ) ≥ − 1
AM-Estimator.We let𝐸 = 𝑘 𝐾 ,𝜃¯ Θ¯,𝜃★ Θ★ :𝑍 𝜃★ ,𝜃¯ <Λ 𝜃★ ,𝜃¯ . Using similar ar-
𝑘
∃ ∈ [ ] ∈ ∈ ( ) ( )
gumentstoTheorem3.2,wecandeducethatP 𝐸 Θ★ 𝑒 𝐾 Θ¯ .Bysetting𝐾 = Θ¯ log Θ★ 𝜂 ,
(cid:8) [ ] ≤ | | − /| | (cid:9) | | (| |/ 2 )
wemakeP 𝐸 𝜂 .
2
[ ] ≤
Conditionedon𝐸𝑐 andbyapplyingMarkov’sinequalitysimilarlytoTheorem3.2,wehavethat
forall𝜃★ Θ★ ,𝜃¯ Θ¯ andrun𝑘 𝐾
∈ ∈ ∈ [ ]
𝝍 𝜃★ ,𝜃¯ 2𝑡 𝑍 𝜃★ ,𝜃¯ Θ★ Θ¯ 2 (𝑛 −1 )(𝛼★ )𝑡 (𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ ) (17)
𝑖,𝑘,𝑡 𝑘
( ) ≥ 𝑛 ( )−| || | 𝜂
2′
2𝑡 Λ 𝜃★ ,𝜃¯ Θ2(𝑛 −1 )(𝛼 𝑛★ )𝑡 (𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ )
≥ 𝑛 ( )−| | 2𝜂
2′
2𝑡
𝑙 𝑛,Θ
Θ22 (𝑛 −1 )(𝛼 𝑛★ )𝑡 (𝑛Γ 𝑛,Θ +𝑉 𝑛,Θ
),
≥ 𝑛 −| | 2𝜂
2′
withprobability1 𝜂 forsome𝜂 0,1 .Tomaketheaboveatleast𝜚 forsome𝜚 >0itsuffices
−
2′ 2′
∈ ( )
topick
log 2𝜚𝑛 log |Θ |2 (𝑛 −1 )(𝑛Γ 𝑛,Θ +𝑉𝑛,Θ )
𝑡 max
𝑙𝑛,Θ
,
2𝜂 2′𝜚
=𝑇.
≥ lo(cid:16)g2 (cid:17) (cid:16) log 1 𝛼★ (cid:17)
 ( / 𝑛 ) 
The log-belief ratio threshold implies that for all 𝜃★ Θ★ ,𝜃¯ Θ¯ we have that𝝂 𝜃★
𝑒𝜚𝝂
𝑖,𝑘,𝑇
𝜃¯
.Similarly,anyvalue
in 1 1 𝑒𝜚 ,1 1 𝑒 −𝜚∈ isava∈
lid threshold,wecan𝑖,𝑘 s, h𝑇
o( wt) ha≥ t
( ) [ /( + ) /( + )]
P Θ★ ΘˆAM 𝐸𝑐 =P 𝜃★ Θ★ :𝝂AM 𝜃★ >𝜏 𝐸𝑐
[ ⊆ 𝑖,𝑇 | ] ∀ ∈ 𝑖,𝑇 ( )
(cid:20) (cid:12) (cid:21)
(cid:12)
(cid:12)
P 𝜃★ Θ★ :𝝂 𝜃(cid:12)★ >𝜏 𝐸𝑐
𝑖,𝑘,𝑇
≥ ∀ ∈ ( )
 𝑘Ø∈[𝐾
](cid:8)
(cid:9)(cid:12)
(cid:12)


 (cid:12) 
 (cid:12) 
=1  P 𝜃★ Θ★ :𝝂
𝑖,𝑘,𝑇
𝜃★ <𝜏  𝐸𝑐
− ∃ ∈ ( )
 𝑘Ù∈[𝐾
](cid:8)
(cid:9)(cid:12)
(cid:12)


 𝐾 (cid:12) 
=1 P  𝜃★ Θ★ :𝝂 𝜃★ <𝜏 𝐸𝑐 (cid:12)  
−  ∃ ∈ 𝑖,𝑘,𝑇 ( ) 
(cid:18) (cid:20) (cid:12) (cid:21)(cid:19)
(cid:12) 𝐾
=1 1 P 𝜃★ Θ★ :𝝂 𝜃★ (cid:12) (cid:12)>𝜏 𝐸𝑐
𝑖,𝑘,𝑇
− − ∀ ∈ ( )
(cid:18) (cid:20) (cid:12) (cid:21)(cid:19)
=1 −(1 −𝜂 2′ )𝐾 (cid:12) (cid:12)
(cid:12)
1 𝑒 −𝜂 2′𝐾.
≥ −
Weset𝜂 =log 1 𝜂 𝐾 andhavethat
2′
( /
2
)/
P Θ★ ΘˆAM P 𝐸𝑐 P Θ★ ΘˆAM 𝐸𝑐 1 𝜂 2 1 2𝜂 .
[ ⊆ 𝑖,𝑇 ] ≥ [ ] [ ⊆ 𝑖,𝑇 | ] ≥ ( − 2 ) ≥ − 2
ThesefinallyyieldMariosPapachristouandM.AminRahimian 25
log 2𝜚𝑛 log |Θ |2 (𝑛 −1 )𝐾 (𝑛Γ 𝑛,Θ +𝑉𝑛,Θ )
𝑇 =max
𝑙𝑛,Θ
,
2log (1 /𝜂2)𝜚
.
lo(cid:16)g2 (cid:17) (cid:16) log 1 𝛼★ (cid:17)
 ( / 𝑛 ) 
Privacy(forbothestimators).Minimizingtheconvergencetime𝑇correspondstominimiz-
ing𝑉 𝑛,Θ.Since𝑉 𝑛,Θ isseparableover theagents’distributions, itsufficestosolvetheproblemof
minimizingthevarianceofeachnoisevariableindependently.
Ifanadversarycaneavesdroponlyonceandhasaccesstoanyround𝑘 𝐾 ,andwehave Θ
states, by the composition theorem, the budget𝜀 should be divided
by𝐾∈Θ[
.
T]
hus, the
proble| m|
of finding the optimal distribution 𝜀 (with PDF say 𝑝 𝑥 Δ R| )| corresponds to the
D𝑖
( )
D𝑖(𝜀
)( ) ∈ ( )
followingoptimizationproblemstudiedin[Koufogiannisetal.,2015,PapachristouandRahimian,
2023],forall𝑘 𝐾 :
∈ [ ]
min V 𝒅 (18)
𝑝 D𝑖(𝜀 )(·)∈Δ (R )
𝒅𝑖,𝑘∼D𝑖(𝜀
)
𝑖,𝑘
𝜀(cid:2) (cid:3)
s.t. 𝜀 is -DPandE 𝒅 =0.
D𝑖 ( ) 𝐾 Θ 𝒅𝑖,𝑘∼D𝑖(𝜀 ) 𝑖,𝑘
| |
(cid:2) (cid:3)
Theoptimalsolutionofthisproblemisgivenin[Koufogiannisetal.,2015,PapachristouandRahimian,
2023].FortheSignalDPproblem,thiscorrespondstoselecting D𝑖★ (𝜀
)
=Lap Δ 𝑖𝐾 𝜀|Θ | whereΔ 𝑖 is
thesensitivityofthelog-likelihoodofthe𝑖-thagent. (cid:16) (cid:17)
(cid:3)
A.5 ProofofTheorem3.3
Proof. Forbrevity,wedefine𝑝 =1 Θ¯ and𝑝 =1 1 Θ★ .
2 1
/| | − /| |
Type-IIEstimator(Θˆthres,2).TodeterminetheasymptoticType-IIerrorprobability𝜂 ofΘˆthres,2,
𝑖,𝑇 2 𝑖,𝑇
weassumethatthethresholdtakestheform𝜏thres,2 = 1 𝜋 𝑝 .Then
2 2
( − )
lim P Θ★ * Θˆthres,2 ( =i) lim P 𝜃★ Θ★ :𝜃★∉Θthres,2 (19)
𝑇 𝑖,𝑇 𝑇 ∃ ∈ 𝑖,𝑇
→∞ h i →∞ h i
(ii)
lim P
𝜃★∉Θthres,2
≤ 𝑇 𝑖,𝑇
→∞𝜃★ Õ∈Θ★
h i
(iii) lim P 𝑵 𝜃★ 𝜏thres,2
𝑖,𝑇
≤ 𝑇 ( ) ≤
→∞𝜃★ Õ∈Θ★
(cid:2) (cid:3)
(iii) lim P 𝑵 𝜃★ 1 𝜋 𝑝
𝑖,𝑇 2 2
≤ 𝑇 ( ) ≤ ( − )
→∞𝜃★ Õ∈Θ★
(cid:2) (cid:3)
(iv) ★ ★
lim P 𝑵 𝜃 1 𝜋 E 𝑵 𝜃
𝑖,𝑇 2 𝑖,𝑇
≤ 𝑇 ( ) ≤ ( − ) ( )
→∞𝜃★ Õ∈Θ★
(cid:2) (cid:2) (cid:3)(cid:3)
(v) Θ★ 𝑒 −2𝐾𝜋 22 ,
≤ | |
wheretheresultisderivedbyapplying(i)thedefinitionofΘˆthres,2,(ii)unionbound,(iii)thedef-
𝑖,𝑇
inition ofthethreshold𝜏thres,2 = 1 𝜋 𝑝 ,(iv)thefactthatE 𝑵 𝜃★ 𝑝 forall𝜃★ Θ★
2 2 𝑖,𝑇 2
( − ) ( ) ≥ ∈
(cid:2) (cid:3)MariosPapachristouandM.AminRahimian 26
as𝑇 ,and(v)theChernoffboundon 𝑵 𝜃ˆ .Therefore,to maketheabovelessthan𝜂 ,it
𝑖,𝑇 2
suffic→ est∞ ochoose𝐾 = log ( 2|Θ 𝜋¯ 2|/𝜂2). ( )
2
Type-IEstimator(Θˆthres,1).TodeterminetheasymptoticType-IIerror𝜂 ofΘˆthres,1,weassume
𝑖,𝑇 1 𝑖,𝑇
thatthethresholdtakestheform𝜏thres,1 = 1 𝜋 𝑝 .Then
1 1
( + )
lim P Θˆthres,1 * Θ★ (=i) lim P 𝜃¯ Θ¯ :𝜃¯ Θˆthres,1 (20)
𝑇 𝑖,𝑇 𝑇 ∃ ∈ ∈ 𝑖,𝑇
→∞ h i →∞ h i
(ii)
lim P 𝜃¯ Θˆthres,1
≤ 𝑇 ∈ 𝑖,𝑇
→∞𝜃Õ¯ Θ¯ h i
∈
(iii)
lim P 𝑵 𝜃¯ 𝜏thres,1
𝑖,𝑇
≤ 𝑇 ( ) ≥
→∞𝜃Õ¯ ∈Θ¯
(cid:2) (cid:3)
lim P 𝑵 𝜃¯ 1 𝜋 𝑝
𝑖,𝑇 1 1
≤𝑇 ( ) ≥ ( + )
→∞𝜃Õ¯ ∈Θ¯
(cid:2) (cid:3)
(iv)
lim P 𝑵 𝜃¯ 1 𝜋 E 𝑁 𝜃¯
𝑖,𝑇 1 𝑖,𝑇
≤ 𝑇 ( ) ≥ ( + ) ( )
→∞𝜃Õ¯ ∈Θ¯
(cid:2) (cid:2) (cid:3)(cid:3)
(v) Θ¯ 𝑒−2𝐾𝜋 12 ,
≤ | |
wheretheresultisderivedbyapplying(i)thedefinitionofΘˆthres,1,(ii)unionbound,(iii)thedef-
𝑖,𝑇
inition of the threshold𝜏thres,1 = 1 𝜋 𝑝 ,(iv) thefactthat E 𝑵 𝜃¯ 𝑝 for all𝜃¯ Θ¯ as
1 1 𝑖,𝑇 1
( + ) ( ) ≤ ∈
𝑇 ,andtheChernoffboundon𝑵 𝜃¯ .Therefore,tomaketheabove𝜂 ,itsufficestochoose
𝐾→ = lo∞ g
(
2|Θ 𝜋¯ 2|/𝜂1). 𝑖,𝑇 ( ) (cid:2) (cid:3) 1
1 (cid:3)
A.6 ProofofTheorem3.5
Type-IIestimator.FromtheanalysisofTheorem3.2(seeEquation(17)),setting
log 2𝜚𝑛 log (𝑛 −1 )|Θ |2 (𝑛Γ 𝑛,Θ +𝑉𝑛,Θ )
𝑡 max
𝑙𝑛,Θ
,
2 (1 −𝑞2)𝜚
=𝑇
≥ lo(cid:16)g2 (cid:17) (cid:16) log 1 𝛼★ (cid:17)
 ( / 𝑛 ) 
guarantees that E 𝑵
𝑖,𝑇
(𝜃★ = P 𝝂
𝑖,𝑘,𝑇
(𝜃★
)
>𝜏
≥
𝑞
2
for all𝜃★ ∈Θ★ . Then by following the
analysis similar to Theorem 3.5by utilizing the union bound and the Chernoff bound, we can
provethatP [Θ★ *(cid:2) Θ 𝑖th ,𝑇res,2 ](cid:3)
≤
|Θ★(cid:2) |𝑒 −2𝐾𝜋 22 .Subse(cid:3) quently,setting𝐾
≥
log (| 2Θ 𝜋★ 22|/𝜂2) makestheerror
atmost𝜂 .
2
Type-Iestimator.FromtheanalysisofTheorem3.2(seeEquation(16)),setting
log 2𝜚𝑛 log (𝑛 −1 )|Θ |2 (𝑛Γ 𝑛,Θ +𝑉𝑛,Θ )
𝑡 max
𝑙𝑛,Θ
,
𝑞1𝜚
=𝑇
≥ lo(cid:16)g2 (cid:17) (cid:16) log 1 𝛼★ (cid:17)
 ( / 𝑛 ) 
guaranteesthatE 𝑵
𝑖,𝑇
(𝜃¯
)
=P 𝝂
𝑖,𝑘,𝑇
(𝜃¯
)
≤𝜏 ≤𝑞 1forall𝜃¯ ∈Θ¯.Thenbyfollowingtheanalysis
similar toTheorem3.5byutilizing theunionboundandtheChernoffbound,wecanprovethat
P [Θ 𝑖th ,𝑇res,1
⊆
Θ★
]
≤(cid:2) |Θ¯ |𝑒 −2𝐾(cid:3) 𝜋 12 .Sub(cid:2) sequentlyse(cid:3) tting𝐾
≥
log (| 2Θ 𝜋★ 12|/𝜂1) makestheerroratmost𝜂 1.
OptimalDistributions.TheproofisexactlythesameasinTheorem3.2.MariosPapachristouandM.AminRahimian 27
B ONLINELEARNING
B.1 Log-BeliefRatioNotations
Let 𝝁 𝜃ˆ be the beliefs for the non-private system, and let𝝂 𝜃ˆ be the private estimates for
𝑖,𝑡 𝑖,𝑡
( ) ( )
agent𝑖 𝑛 andround𝑡 0.Forthenon-privatealgorithm(Algorithm2)allpairs𝜃ˆ,𝜃ˇ Θwelet
∈ [ ] ≥ ∈
r𝝓 a𝑖, t𝑡
i(
o𝜃 sˆ, r𝜃ˇ
e)
sp= el co tg iv(cid:16)el𝝁𝝁 y𝑖𝑖 ,, 𝑡𝑡 f(( o𝜃𝜃 ˇˆ )) r(cid:17)agan end t𝝀 𝑖𝑖,𝑡 (𝜃ˆ, 𝑛𝜃ˇ
)
r= oul no dg 𝑡(cid:16)𝜸𝜸 𝑖𝑖 ,, 𝑡𝑡 (( 0𝜃𝜃 ˇˆ .)) F(cid:17)ob re tt hh ee plo rig vab te eli ae lf gr oa rt ii to hs man (Ad lt gh oe ril to hg m-lik 5)el wih eo lo ed
t
∈ [ ] ≥
l𝝍 o𝑖 g,𝑡 -( b𝜃ˆ e, l𝜃 iˇ e) f= ratlo iog ,l(cid:16)o𝝂 𝝂 g𝑖 𝑖, ,𝑡 𝑡 -l( (𝜃 𝜃 iˆ ˇ k) )e(cid:17)l, ih𝜻 o𝑖,𝑡 o( d𝜃ˆ r,𝜃 aˇ t) io= ,al no dg n(cid:16)o𝝈 𝝈𝑖 𝑖 i, , s𝑡 𝑡 e( (𝜃 𝜃ˆ ˇ d) ) (cid:17)iff, ea rn ed nc𝜿 e𝑖, r𝑡 a(𝜃 tˆ i, o𝜃ˇ s) re= sp𝒅 e𝑖, c𝑡 t( i𝜃 vˆ ) el− yf𝒅 o𝑖, r𝑡 ( a𝜃 gˇ ) enb te 𝑖the 𝑛pri ,v aa nt de
∈ [ ]
round𝑡 0. We also let the vectorized versions 𝝓 𝜃ˆ,𝜃ˇ ,𝝍 𝜃ˆ,𝜃ˇ ,𝝀 𝜃ˆ,𝜃ˇ ,𝜻 𝜃ˆ,𝜃ˇ respectively,
≥ 𝑡( ) 𝑡( ) 𝑡 ( ) 𝑡( )
where the vectorization is over the agents 𝑖 𝑛 . Finally, for each agent𝑖 𝑛 and pair of
∈ [ ] ∈ [ ]
states𝜃ˆ,𝜃ˇ
∈
Θwe define the KL divergencebetween thestates Λ 𝑖 (𝜃ˆ,𝜃ˇ
)
= E 𝜃 log ℓℓ 𝑖𝑖 (( 𝒔𝒔 𝑖𝑖 ,, 00 || 𝜃𝜃 ˇˆ )) =
𝐷 ℓ 𝜃ˆ ℓ 𝜃ˇ . h (cid:16) (cid:17)i
𝐾𝐿 𝑖 𝑖
(·| )| (·| )
(cid:16) (cid:17)
B.2 AuxiliaryLemmas
Beforeprovingthemainresultforonlinelearning,weprovethefollowingLemmaregardingthe
rateofconvergenceoftheCésaromeans.
Lemma B.1. Let 𝑿 ,...,𝑿 be i.i.d. random variables, let 𝐴 be a doubly-stochastic matrix with
1 𝑡
largestmagnitudeofthenon-trivialeigenvalue𝛽★=max 𝜆 𝐴 , 𝜆 𝐴 andlet𝒙 = 11𝑇𝑿 ,with
𝑛 { 2 ( ) | 𝑛 ( )|} 𝜏 𝑛 𝜏
max V 𝒙 𝑉.Then
1 𝜏 𝑡 𝜏
≤ ≤ [ ] ≤
p
𝑡 1 𝑡 1
E
"(cid:13)
(cid:13)1
𝑡
Õ𝜏− =0𝐴𝑡 −𝜏𝑿
𝜏
−
1
𝑡
Õ𝜏− =0𝒙
𝜏
!1
(cid:13) (cid:13)2# ≤ (1
−(𝑛 (−
𝛽
𝑛★1 )) 2𝑉 )√𝑡.
(cid:13) (cid:13)
Proof. Wehavethat (cid:13) (cid:13)
(cid:13) (cid:13)
𝑛
E
(cid:2)(cid:13)
(cid:13)𝐴𝑡 −𝜏𝑿
𝜏
−𝒙 𝜏1
(cid:13)
(cid:13)2
(cid:3)
=E
"(cid:13)
(cid:13)
(cid:13)𝑛1 11𝑇𝑿
𝑛𝜏 +
Õ𝑖=2𝜆
𝑖
(𝐴 )𝑡 −𝜏𝒓 𝑖𝒍𝑇
𝑖
𝑿
𝜏
−𝒙1
(cid:13)
(cid:13)
(cid:13)2#
=E "(cid:13) (cid:13)
(cid:13)
(cid:13)𝒙 𝜏1
+
Õ𝑖=2𝜆
𝑖
(𝐴 )𝑡 −𝜏𝒓 𝑖𝒍𝑇
𝑖
𝑿
𝜏
−𝒙 𝜏1
(cid:13) (cid:13)2#
(cid:13) (cid:13)
𝑛 (cid:13) (cid:13)
(cid:13) (cid:13)
(cid:13)𝜆
𝑖
𝐴 𝑡 −𝜏 𝒓
𝑖 2
𝒍
𝑖
2E 𝑿
𝜏 2
(cid:13)
≤ ( ) k k k k k k
𝑖=2
≤
Õ (𝑛 −(cid:12) (cid:12)1 )(𝛽 𝑛★ )𝑡 −(cid:12) (cid:12)𝜏E k𝑿
𝜏 k2
(cid:2) (cid:3)
≤
(𝑛 −1 )(𝛽 𝑛★ )𝑡 −𝜏E(cid:2) k𝑿 0 k2(cid:3)
≤
(𝑛 −1 )(𝛽 𝑛★ )𝑡 −𝜏𝑉.(cid:2) (cid:3)
Therefore,
𝑡 1 𝑡 1
E
"(cid:13)
(cid:13)1
𝑡
Õ𝜏− =0𝐴𝑡 −𝜏𝑿
𝜏
−
1
𝑡
Õ𝜏− =0𝒙
𝜏
!1
(cid:13) (cid:13)2# ≤ (1
−(𝑛 (−
𝛽
𝑛★1 )) 2𝑉 )√𝑡.
Since 𝜏𝑡 =0(𝛽 𝑛★ )𝑡 −𝜏 ≤ (cid:13) (cid:13) (cid:13)𝜏 ≥0(𝛽 𝑛★ )𝜏 = 1 −(1 𝛽𝑛★ )2. (cid:13) (cid:13) (cid:13)
Í ÍMariosPapachristouandM.AminRahimian 28
(cid:3)
Inthesequel,weshowthemainresultforonlinelearning
B.3 ProofofTheorem3.6
Proof. WeletΞ =V 𝑛 𝑛 = 𝑛 𝜉 .Wedefinethefollowingsequenceof“bad”events:
𝑛 𝑖=1 𝑖,𝜏 𝑖=1 𝑖
(cid:2)Í (cid:3) Í
𝐵 = max
1 𝑡 −1
𝑛 𝜈
Ξ
𝑛 .
𝑛,𝑡 𝑖,𝜏 𝑖
(𝑖 ∈[𝑛 ](cid:12) (cid:12)𝑡 Õ𝜏=0 − (cid:12)
(cid:12)
≥ s𝜂𝑡 )
(cid:12) (cid:12)
ByapplyingtheunionboundandCheby(cid:12)shev’sinequa(cid:12)lity,wecanshowthatP 𝐵
𝑛,𝑡
𝜂.
Weconditiononthe“bad”event𝐵 no(cid:12) thappening.W(cid:12) ecanprovethat,condit[ ione] d≤ on𝐵𝑐 ,
𝑛,𝑡 𝑛,𝑡
𝑉 𝑛′,Θ = 𝜃¯ ∈Θ¯m ,𝜃a ★x ∈Θ★vutV "𝑛1 𝑡 Õ𝑖=𝑛 1 Õ𝜏𝑡 − =01 𝑛 𝑖,𝜏𝜻 𝑖,𝜏 (𝜃ˆ,𝜃ˇ ) (cid:12) (cid:12)𝐵𝑐 𝑡 # ≤ √ 𝑛2 (𝑛𝑄 𝑛,Θ +𝑉 𝑛,Θ ) 𝑖m ∈[a 𝑛x ]𝜈 𝑖 +sΞ 𝜂𝑡𝑛 !.
whT eh ree 𝜻dyn 𝜃a ˆ,m 𝜃ˇic =so 𝝀fth 𝜃ˆe ,𝜃l ˇog-b 𝜿elie 𝜃ˆf ,r 𝜃ˇat .io Wo eb ae py p𝝍
ly𝑡(
T𝜃ˆ h,(cid:12) (cid:12)𝜃 eˇ
o)
r= em𝐴𝝍
B𝑡 .1− ,1
a(𝜃 nˆ, d𝜃ˇ
g) e+
t𝜻
th𝑡(
a𝜃 tˆ,𝜃ˇ
)
= 𝜏𝑡 −=01𝐴𝑡 −𝜏𝜻 𝜏(𝜃ˆ,𝜃ˇ ),
𝜏( ) 𝜏 ( )+ 𝜏 ( ) Í
E 1 𝝍 𝜃ˆ,𝜃ˇ 1 𝑡 −1 𝑛 𝑛 𝜻 𝜃ˆ,𝜃ˇ 1 𝐵𝑐 (𝑛 −1 )𝑉 𝑛′,Θ .
Moreover "(cid:13) (cid:13) (cid:13) (cid:13) (cid:13)𝑡 𝑡( )− 𝑛𝑡 Õ𝜏=0 Õ𝑖=1 𝑖,𝜏 𝑖,𝜏 ( ) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13)2(cid:12) (cid:12) (cid:12) (cid:12) 𝑛,𝑡 # ≤ √𝑡 (1 −(𝛽 𝑛★ )2 )
E 1 𝑡 −1 𝑛 𝑛 𝜻 𝜃ˆ,𝜃ˇ 1 𝑛 𝜈 Λ 𝜃ˆ,𝜃ˇ 𝐵𝑐 𝑉 𝑛′,Θ .
Therefore,byMar" k(cid:13) (cid:13)
(cid:13)
(cid:13)o𝑛 v𝑡 ’sÕ𝜏 i= n0 eÕ𝑖 q= u1 ali𝑖 t,𝜏 ya𝑖,𝜏 n( dthe)− tri𝑛 anÕ𝑖 g= l1 ein𝑖 e𝑖 q( ualit) y(cid:13) (cid:13)
(cid:13)
(cid:13),2 w(cid:12)
(cid:12) (cid:12)
e𝑛, g𝑡 e# t≤ tha√ t𝑡
forevery𝑧 >0
(cid:13) (cid:13) (cid:12)
P 1 𝝍 𝜃ˆ,𝜃ˇ 1 𝑛 𝜈 Λ 𝜃ˆ,𝜃ˇ 1 >𝑧𝐵𝑐 𝑉 𝑛′,Θ .
Therefore,weca"(cid:13) (cid:13)
(cid:13)
(cid:13)n𝑡 sho𝑡 w( th) at− b𝑛 yaÕ𝑖 p=1 ply𝑖 in𝑖 g( aun) io(cid:13) (cid:13)
(cid:13)
(cid:13)n2 bou(cid:12)
(cid:12)
(cid:12)nd𝑛, o𝑡 # ve≤ rΘ𝑧 ★(1 ,w− e(𝛽 h𝑛★ av)2 e) t) h√ a𝑡
twithprobability
1 𝜂,forall𝜃★ Θ(cid:13) and𝜃¯ Θ¯ (cid:13) (cid:12)
− ∈ ∈
𝝍 𝑖,𝑡 (𝜃★ ,𝜃¯ ) ≥ 𝑛𝑡 𝑙 𝑛,Θ − 2𝜂|Θ 1|2𝑉 𝑛′,Θ 𝛽★√𝑡 2 .
𝑛
( −( ) )
TomaketheRHSatleastthelog-beliefthreshold𝜚,werequire𝑡 𝑇 wherewecancalculate𝑇
≥
tobe
𝑇 =
O vut𝑙
𝑛𝑛
,Θ
max (|Θ |2 (𝑛𝑄 𝑛,Θ +𝑉 2𝑛 𝜂,Θ (1)( −m (a 𝛽x 𝑛★𝑖 ∈ )2[𝑛 )]𝜈 𝑖 + pΞ 𝑛 /𝜂 ), r𝑙 𝑛, 𝑛Θ𝜚
)
.
© ª
Therefore,byse ttingthebeliefthresholdasa𝜏 =1 1 𝑒𝜚 asinTheorem3.2,we®getthat
/( +
P«Θ★ ΘˆOL P 𝐵𝑐 P Θ★ ΘˆOL 𝐵𝑐 1 𝜂 2 1 2𝜂. ¬
⊆ 𝑖,𝑇 ≥ [ 𝑛,𝑇] ⊆ 𝑖,𝑇| 𝑛,𝑇 ≥ ( − ) ≥ −
(cid:2) (cid:3) (cid:2) (cid:3)MariosPapachristouandM.AminRahimian 29
Privacy.SimilarlytoTheorem3.2,theoptimaldistributionsaretheonesthatminimizethevari-
ancesubjectto privacyconstraints.Sincethereare Θ states, thebudget𝜀 shouldbedivided by
| |
Θ,yielding ★ 𝜀 =Lap Δ 𝑖,𝑡|Θ | .
| | D𝑖,𝑡( ) 𝜀
Remark.Wenoteheretha(cid:16)tifwe(cid:17)alsowanttoprotectthenumberofsignalseachagentisgetting
–thusextendingthedefinitionofSignalDPtothewholedataset–oneshouldtakethemaximum
overΔ anduseitassensitivity.
𝑖,𝑡
(cid:3)