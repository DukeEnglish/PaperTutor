ASSESSING THE PRIVACY RISK OF CROSS-PLATFORM IDENTITY
LINKAGE USING EYE MOVEMENT BIOMETRICS
SamanthaAziz OlegKomogortsev
DepartmentofComputerScience DepartmentofComputerScience
TexasStateUniversity TexasStateUniversity
SanMarcos,TX78666 SanMarcos,TX78666
sda69@txstate.edu ok@txstate.edu
ABSTRACT
Therecentemergenceofubiquitous,multi-platformeyetrackinghasraiseduserprivacyconcerns
overre-identificationacrossplatforms,whereapersonisre-identifiedacrossmultipleeyetracking-
enabled platforms using personally identifying information that is implicitly expressed through
theireyemovement. Wepresentanempiricalinvestigationquantifyingamoderneyemovement
biometricmodel’sabilitytolinksubjectidentitiesacrossthreedifferenteyetrackingdevicesusing
eyemovementsignalsfromeachdevice. Weshowthatastate-of-thearteyemovementbiometrics
modeldemonstratesabove-chancelevelsofbiometricperformance(34.99%equalerrorrate,15%
rank-1 identification rate) when linking user identities across one pair of devices, but not for the
other. Consideringthesefindings,wealsodiscusstheimpactthateyetrackingsignalqualityhason
themodel’sabilitytomeaningfullyassociateasubject’sidentitybetweentwosubstantiallydifferent
eyetrackingdevices. Ourinvestigationadvancesafundamentalunderstandingoftheprivacyrisks
for identity linkage across platforms by employing both quantitative and qualitative measures of
biometricperformance,includingavisualizationofthemodel’sabilitytodistinguishgenuineand
imposterauthenticationattemptsacrossplatforms.
Keywords eyetracking·privacy·reidentification·biometrics
1 Introduction
Eyetrackingisbecomingincreasinglyubiquitousduetotherecentlarge-scaleintegrationofeyetrackingfunctionalityin
mainstreamconsumerdevices,includinglaptopsandvirtualrealityheadsets.Whileeyetrackingcanenhanceday-to-day
activitiesbyenablingfunctionalitiessuchasfoveatedrendering[23]andintuitivegaze-basedinteraction[24],italso
raisesconcernsforuserprivacy. Eyemovementsareproducedbyacomplexinterplaybetweenthebrain’sphysical
structureandvariousneurologicalprocesses,andimplicitlycontainsignaturesofpersonalcharacteristicssuchasa
user’sidentity,gender,andhealthstatus[12]. Becausethesetraitsareexpressedunconsciouslythrougheyemovement,
itisinfeasibleforindividualuserstovoluntarilywithholdthisinformationfromtheireyemovementsignals. Thisraises
concernsforthepotentialofanadversaryexploitinginformationencodedineyemovementstoinfersensitiveuser
characteristics.
Amid the growing discussions of privacy within the eye tracking research community [5, 12, 13, 14, 15, 29], one
potentialnewthreathasemergedwiththegrowingubiquityofeyetrackingdevices: cross-platformidentitylinkage.
Becauseeyetrackingisbeingemployedincontextsinvolvinglaptops[20],virtual/augmentedreality[23],andeven
vehicles[27],asinglepersonmayutilizemultipleeyetracking-enabledplatformsthroughoutthecourseoftheirday. In
asettingwhereeyetrackingispervasiveandubiquitous,thisperson’sidentitymaybelinkedacrosstheseplatforms
againsttheirwillusingthepersonallyidentifyinginformationencodedintheireyemovementsignals. Thishasboth
privacyimplicationsforbothindividualusersandsecurityimplicationsforsystemsthatuseeyemovementbiometrics
asameansofaccesscontrol.
4202
beF
31
]CH.sc[
1v55680.2042:viXraAssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
Empiricalinvestigationsquantifyingtheriskofcross-platformidentitylinkagehavebeenabsentinliteraturebecause,
untilrecently,theeyetrackingresearchcommunitylackedthedataneededtosupportsuchaninvestigation. Withthe
recentemergenceofpubliclyavailableeyetrackingdatasetsdrawnfromthesamepopulationofsubjects[1,2,16],itis
nowpossibletoinvestigatetheriskofcross-platformidentitylinkageusingeyemovementdata.
Thisworkexploresthepossibilitythatausercanbere-identifiedacrosseyetrackingdeviceswhenusingstate-of-the-art
eyemovementbiometrics(EMB)models. Thisstudymakesthefollowingspecificcontributions:
1. Wepresentthefirstanalysisofcross-platformidentitylinkageforEMBemployingEyeKnowYouToo[18],a
state-of-the-arteyemovementbiometricauthenticationmodel,includingabriefdiscussionofitsprivacyand
securityimplications.
2. WeshowthatamodernEMBmodelcansuccessfullylinkuseridentitiesacrosstwoofthethreeeyetracking
platformsstudiedwithabove-chanceaccuracyduringbothbiometricverificationandidentification.
3. Weusebothquantitativeandqualitativeevaluationsofbiometricperformancetodiscussfactorsthataffectan
EMBmodel’sabilitytoperformcross-platformre-identification,includingtheeffectofeyetrackingsignal
qualityandtheamountofdataprovidedtotheEMBmodel.
2 BackgroundandPriorWork
2.1 EyeMovementBiometrics(EMB)
FirstproposedasabiometricbyKasprowskiandOber[11], eyemovementhasemergedasanincreasinglyviable
modalityforbiometricauthentication. Becauseeyemovementsareproducedbylargelyinvoluntarymechanismsofthe
oculomotorsystem,theyarebothperson-specificandnaturallyresistanttospoofing.
SubstantialresearchhasbeenconductedexploringtheviabilityofEMBtoperformbothverification[8,9,7,21,18,17]
andidentification[3,9,18,10,21]. PriorworkinEMBdistinguishesindividualsbygeneratingbiometrictemplates
basedonfeaturesextractedfromeyemovementsignals,suchasaveragefixationduration,averagesaccadeamplitude,
andpeaksaccadevelocity[8,9,7]oronpupillaryfeaturessuchaspupildiameter[3]. TheseEMBauthentication
modelsrelyoncarefulextraction,fusion,andanalysisofhandcraftedfeaturestoreachverificationerrorratesaslowas
2.59%[7]andidentificationratesashighas83.7%[9].
State-of-the-art EMB models employ end-to-end deep learning [21, 18, 10] to automatically extract features that
meaningfulforbiometricauthentication,ratherthanrelyingonstaticfeatureextractionandanalysis. Theseend-to-end
approachesreliablyachieveverificationerrorratesbelow4%[18,21]andidentificationratesexceeding90%[18]on
eyemovementdatasetscontaininghundredsofuniquesubjectidentities.
Eye tracking signal quality metrics such as spatial accuracy, spatial precision, and sampling frequency affects eye
movementbiometricperformance,asitismoredifficulttoextractmeaningfulbiometricfeaturesfromlowerqualityeye
movementdata. Whilestate-of-the-artapproachesdemonstratesomelevelofrobustnesstocertaintypesofeyetracking
signalqualitydegradationwithinasingledevice[25,18],itisunknownwhethertheyarerobusttodifferencesineye
trackingsignalqualitywhendatafromtwodifferenteyetrackingdevicesispresented. Asaresult,itisanopenresearch
questionwhetherstate-of-the-artEMBmodelscanmeaningfullyre-identifythesameusersacrossmultipleeyetracking
platforms.
2.2 PrivacyImplicationsofPervasiveEyeTracking
Eyemovementsimplicitlycontaininformationaboutsensitiveuserattributessuchastheiridentity,gender,age,and
healthstatus[12]. Theprimaryprivacyconcernthatweaddressinthisworkiswhetherauser’sidentitymaybelinked
acrosstheseplatformsusingtheeyemovementdatacapturedbytheirrespectiveeyetrackingdevices. Thetheoretical
opportunityforanadversarytobuildsuchanassociationbetweendevicesisbecomingincreasinglylikelyduetothe
growingubiquityofeyetrackingfunctionalityinmainstreamcomputingdevices.
Thisidentitylinkagecanhaveimplicationsforindividualusers. Forexample,considerauserwhousesbothalaptop
andavehiclewitheyetrackingfunctionality. Ifaremoteadversarysuccessfullylinkstheuser’sidentitybetweentheir
laptopandtheirvehicle,theycouldexploitthecar’sGPSsystemtotracktheirvictim’smovement. Alternatively,it
maybepossibleforanadversarytocovertlycaptureavictim’seyemovementsinonedevice,thenuseittobypass
anEMB-basedauthenticationmechanismin another systemwherethevictimisenrolled. Thishaslargersecurity
implications,asthisauthenticationmechanismmaybeprotectingsensitiveinformationsuchasthevictim’spersonal
bankaccountorsensitivecompanyinformationheldinthevictim’sdigitalworkplaceplatform.
2AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
Figure1: Anexampleofanattackdescribedbyourthreatmodel. Bluearrowsindicatebenignactivity,andredarrows
indicatemaliciousactivity.
Althoughtheconsequencesofcross-platformidentitylinkagehavebeendescribedbotheyetrackingliterature[5]and
ingeneralbehavioralbiometricresearch[6],theempiricalriskofsuchviolationsoccurringwitheyetrackingdata
specificallyareunderexplored. Ourworkaimstocontributetoagrowingunderstandingoftheprivacyimplicationsof
pervasiveeyetrackingbypresentinganexplorationofcross-platformidentitylinkageusingthreeeyetrackingdevices
ofvaryingsignalquality. Indoingso,weaimtoencouragethedevelopmentofdefensemechanismsthatrealistically
addresstouserprivacyconcernsthatemergefromubiquitous,multi-platformeyetracking.
3 Methodology
3.1 ThreatModel
ThisinvestigationconcernsanattackscenariowhereanadversaryattemptstobypassanEMB-basedauthentication
systembypresentinganenrolleduser’seyemovementdatacapturedbyadeviceotherthanthetargetsystem’seye
trackinghardware. Figure1showsanoverviewofthisattack.
Inthismodel,thereexistsasecureSystemAthatemploysEMB-basedauthenticationasaformofaccesscontrol,and
cannotbeaccessedbyanyothermeans. Thisauthenticationmodelacceptseyemovementsignalsasinput,whichare
representedastime-seriesdataexpressedasasequenceof(x,y)coordinatesrespectivelydenotingthehorizontaland
verticalpositionoftheuser’sgazeonthescreen. Thesystemdoesnotemployauxiliaryinformationsuchasimagesof
theirisorperiocularfeaturesforauthentication.
Whenauthenticatinganenrolleduser,theauthenticationmodulecompareseyemovementsignalspresentedbytheuser
toanenrollmenttemplate,andgrantsaccessifthetwoaresufficientlysimilar. Theauthenticationmoduleoperatesas
intendedandcannotbemodifiedorviewedbyanymeans(e.g.,themodelcannotbere-trainedorfine-tuned,itsweights
cannotbereverse-engineered,andenrollmenttemplatescannotbeviewedoraltered).
WeassumethatavictimenrolledinSystemAarealsoenrolledinasecond,lesssecureSystemBthatincorporateseye
trackingfunctionalitywithitsowneyetrackingdevice. Thissystemcaneitherbeanactualcomputingenvironmentwith
eyetrackingfunctionalitywhoseinsecuritiescanbeexploitedtoobtaineyemovementdata(e.g.,avictim’spersonal
virtualrealityheadset)oraneyetrackingdatasetusedforresearchpurposesthattheadversaryobtainsfrompublicly
availablesources[4]. Ineithercase,anadversaryobtainsthevictim’seyemovementdatacapturedbySystemB’seye
trackingdevice. TheadversarythenattemptstogainaccesstoSystemAbypresentingthisstolendatatotheSystem
A’sauthenticationmodule. Ifthebiometricfeaturesexpressedinthevictim’seyemovementaresufficientlysimilar
betweeneachsystem’seyetrackingdevice, theadversaryisableusethevictim’sdataobtainedfromSystemBto
infiltrateSystemAundertheiridentity. Becausethestoleneyemovementdataisbothgenuineandwasneverpreviously
3AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
Name Dataset Device SpatialAccuracy SpatialPrecision Task(Duration)
EyeLink SynchronEyes EyeLink1000 0.63◦ 0.09◦ TEX,RAN(60s)
MindLink SynchronEyes AdHawkMindLink 2.09◦ 0.18◦ TEX(60s)
Vive GazeBaseVR SMIEyeTracker 1.0◦ 0.03◦ TEX(27-67s,mean47s)
Table1: Summaryoftheeyemovementdataemployedinthisstudy. TEXreferstoareadingtaskandRANreferstoa
jumpingdotstask.
encounteredbySystemA,mechanismsfordetectingspoofingandreplayattacksforeyemovementarenotsufficientto
addressthisthreat.
3.2 BiometricModel
WeselectedEyeKnowYouToo(EKYT),anend-to-enddeeplearningapproachforEMBauthentication,toserveas
the secure biometric authentication module described in our threat model. EKYT comprises an ensemble of four
DenseNet-basedconvolutionalneuralnetworkstrainedtoextractmeaningfulfeaturesforbiometricauthenticationfrom
avarietyofeyemovementtasks. Wechosethismodelbecauseitisrobusttotemplateagingupto37months,which
mitigatesthepotentialimpactofthelargetimeintervalexhibitedbythedataweuse(describedinSection3.2)onthe
resultsofourcurrentinvestigation.
For this investigation, we use pre-trained models from EKYT’s public release. These models were trained on eye
movementdatafromanEyeLink1000eyetrackingdevicethatwastemporallydownsampledto250Hz. Furtherdetails
onEKYT’strainingmethodologyaredescribedin[18],andthepre-trainedmodelsemployedinthisstudyarepublicly
availableat[19].
3.3 Datasets
Weemployeyemovementdatacollectedfrom21participantsacrossthreedifferenteyetrackingdevices. Thisdata
istakenfromasubsetoftwopubliclyavailableeyetrackingdatasets: GazeBaseVR[16]andSynchronEyes[2]. A
summaryoftheeyetrackingsignalqualitiesexhibitedbyeachdatasetispresentedinTable1.
GazeBaseVRcontainseyemovementdatacollectedwithaSensoMotoricInstruments(SMI)eyetrackerembedded
withinahead-mountedHTCVivevirtualrealitydeviceata250Hzsamplingrate. Weemployeyemovementdata
capturedfromtherighteyeduringtheTEXtaskcollectedduringRound1,Session2,whereparticipantscompleteda
self-pacedreadingtask. Thedurationofthistaskvariedbetween27and66seconds,withameanreadingtimeof47
seconds. ThedatathatweusefromGazeBaseVRwillbereferredtoasdatafromthe“Vive”device.
SynchronEyescontainseyemovementdatacollectedsimultaneouslyintwoeyetrackers. Thefirsteyetrackerisan
EyeLink1000collectingmonocular(lefteye)dataatasamplingrateof1000Hz,knownhereonasthe“EyeLink”data.
ThesecondeyetrackerisanAdHawkMindLinkcollectingmonocular(righteye)dataatasamplingrateof500Hz,
knownhereonas“MindLink”data. WeemployreadingdatafromtheTEXtaskcollectedduringSession2,where
eyemovementswerecapturedsimultaneouslyinbotheyetrackingdevices. Thedurationofthisreadingtaskwas60
secondsforallparticipants. Forportionsofthisinvestigation,wealsousedeyemovementdatafromtheRANtask
collectedbytheEyeLinkduringSession2,whereparticipantstrackedajumpingdot.
GazeBaseVRandSynchronEyeswerecreatedapproximately23monthsapart,whichintroducespotentialeffectsof
agingonbiometricperformance. Agingeffectsoneyemovements[28]canimpactthetemporalpersistenceoffeatures
thatareinformativeforbiometricauthentication,whichinturnaffectsthelong-termreliabilityofabiometricsystem.
EKYT’srelativerobustnessagainsttemplateagingeffectsmakesitthemosteffectivechoiceformitigatingthepotential
effectsofagingthatmaybeobservedbetweenGazeBaseVRrecordingsandSynchronEyesrecordings,asthe23-month
intervalbetweenthetwodatasetsiswellwithinthe37-monthtimeframeexploredinLohrandKomogortsev’soriginal
work[18].
3.4 DataPreprocessing
ToenableuseoftheeyemovementdataweemploywithEKYT,eyemovementdatawereprocessedusingthetechniques
described in Lohr and Komogortsev [18]. Because we are employing a version of EKYT appropriate for 250 Hz
samplingfrequencies,datawerefirsttemporallydownsampledtoasamplingrateof250Hz.
WeestimatevelocityfromthepositionalgazedatausingaSavitzky-Golaydifferentiationfilter[26]withorder2anda
windowsizeof7. Thisvelocitydatawasthensplitintonon-overlappingwindowsof5seconds. Withineachwindow,
4AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
weclampedvelocitiestophysiologicallyfeasiblemovementspeedsof±1000◦/sectoreducetheimpactofnoise,then
z-scoredvelocityusingthemeanandstandarddeviationofeyemovementvelocitiesderivedfromEKYT’soriginal
trainingdataandreplacedNaNvalueswith0. Theseprocessedvelocitywindowsarethenfedintothepre-trained
EKYTmodel. Wenotethat,exceptfordownsamplingdatato250Hz,allofthisdataprocessingwouldbecompletedby
thebiometricauthenticationmodulewhenabiometricsampleispresentedtothesystemforauthentication;itwouldnot
beanadversary’sresponsibilitytoimplementthedataprocessingtechniquesdescribedhere.
3.5 EvaluationMethodology
EKYTtransformsasequenceofeyemovementwindowsintoa128-dimensionalembeddingvectors(knownhereon
as “embeddings”) that represent subject identity. We generate embeddings using 5 and 60 seconds’ worth of data
respectivelyforconsistencywithexistingEMBliterature[21,18]. Wegenerateoneembeddingperrecordinginthedata
set,andassociateitwithboththedeviceandthesubjectidentitythatproducedtheoriginaleyemovementsequence.
After generating these embeddings, we compute all pairwise similarity scores by calculating the cosine similarity
between each embedding in the enrollment and the authentication sets. These similarity scores are then used to
determinebiometricperformanceinbothaverificationandidentificationsetting.
For biometric verification, the biometric system determines whether the embedding generated from the provided
biometricsampleissufficientlysimilartotheenrollmenttemplateoftheclaimedidentity. Verificationperformance
acrosstheentiredatasetisevaluatedusingEqualErrorRate(EER),orthepointatwhichtheFalseAcceptanceRate
andtheFalseRejectionRateareequal. Becausebiometricverificationonlyhastwooutcomes(i.e.,theverification
attemptisacceptedorrejected),chancelevelperformanceis50%EER.
Forbiometricidentification,thebiometricsystemreturnstheidentityofthesubjectwhoseembeddingismostsimilar
totheembeddingofthebiometricsamplepresentedforauthentication. Identificationperformanceisevaluatedusing
rank-1identificationrate(IR),whichmeasureshowoftentheidentitiesoftheenrollmentandauthenticationembeddings
match. Forbiometricidentification,chancelevelperformanceis1/N,whereNisthenumberofenrolledusers.
BecauseEKYTwastrainedondatafromanEyeLink1000eyetrackingdevice[18],weusetheembeddingscreated
fromtheEyeLinkportionofthedataasenrollmenttemplates. PresentingdatafromtheEyeLinkforauthentication
simulatesnormaloperationofthebiometricsystem,andpresentingdatafromtheViveorMindLinkforauthentication
simulateanadversary’sattempttobypassthebiometricsystemusingtheeyemovementobtainedfromanothereye
trackingdevice. Weassessbiometricperformancewhenpresentingboth“legitimate”EyeLinkdataandthe“stolen”
MindLinkorVivedataforauthentication.
4 Results
Ineachevaluationsettingdescribedherein,weusereadingdatafromtheEyeLinkastheenrollmentset. Weobserve
the biometric performance of the model when employing data from each device as the authentication set. When
usingEyeLinkdataforbothenrollmentandauthentication,weintroduceadditionaldatafromSynchronEyescollected
duringajumpingdotstasktoserveastheauthenticationset. Thisevaluationservesasabaselineforcomparisonwhen
authenticatingwithotherdevices. Otherwise,allenrollmentandauthenticationisdoneusingareadingtasktakenfrom
eachdevice’srespectivedataset.
Verification and identification results are presented separately for 5-second and 60-second embeddings. For this
investigation,achance-levelverificationrateis50%EERandachance-levelidentificationrateis1/21≈4.8%IR.
4.1 Cross-PlatformVerification
Table2showsverificationperformanceforeachdevicewhenenrollingandauthenticatingon5-secondembeddings.
EKYT achieves a EER of 5.61% when authenticating with EyeLink data, demonstrating that it can meaningfully
distinguishbetweengenuineandimposteridentitieswhenenrollingandauthenticatingondatafromthesamedevice.
In the context of our threat model, this means that the biometric authentication module achieves acceptably high
biometricperformanceundernormal,benignoperatingconditions. EERdeterioratessignificantlywhenauthenticating
ondatafromnon-EyeLinkdevices. WhenusingVivedataastheauthenticationset,EERdegradesto32.23%,which
is significantly worse but well above chance-level performance. On the other hand, using MindLink data as the
authenticationsetreducesbiometricperformancetochance-levelperformanceof49.13%,indicatingthatMindLink
embeddingsaregenerallynotmeaningfulforbiometricverificationinthissetting.
5AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
Enrollment Authentication EER(%)↓
EyeLinkRAN 5.61
EyeLinkTEX ViveTEX 32.23
MindLinkTEX 49.13
Table2: Biometricverificationresultswhenenrollingandauthenticatingon5secondsofdata.
Enrollment Authentication EER(%)↓
EyeLinkRAN 2.89
EyeLinkTEX ViveTEX 34.99
MindLinkTEX 44.79
Table3: Biometricverificationresultswhenenrollingandauthenticatingon60secondsofdata.
Weobservesimilarresultswhenevaluatingverificationperformanceon60-secondembeddings,asshowninTable3.
Biometric verification performance generally improves when the authentication system is provided with longer
sequencesofeyemovementdata—weobservethatEERscoresfortheEyeLinkandMindLinkimproverelativeto
the5-secondembeddings. TheonlyexceptiontothisobservationistheViveauthenticationset,butwenotethatthis
degradationinEERlikelyoccursbecausemanysubjectsintheVivedatahavefewerthan60seconds’worthofreading
dataavailableforanalysis,meaningthattheresultingembeddingsdonotrepresentafull60secondsofeyemovement.
Overall,itappearsthatEKYTismostcapableofachievinghighbiometricverificationperformanceonauthentication
setsthataresimilartothedatausedforenrollment,andislesscapableofcorrectlydistinguishinggenuinematches
fromimposterswhenauthenticatingwithdatafromdifferentdevices. TheROCcurvesgeneratedforeachverification
settingaredisplayedinFigure2.
4.2 Cross-PlatformIdentification
Tables4and5showidentificationresultsacrossdeviceswhenemploying5-and60-secondembeddings,respectively.
UsingEyeLinkdataforauthenticationproducesanIRof73.91%for5-secondembeddingsand95.65%for60-second
embeddings, meaning that 16 and 19 of the 21 subjects were correctly identified. EKYT exhibits cross-platform
identificationratesthatareslightlyabovechancelevelswhenauthenticatingontheVivedata;weobserveidentification
ratesof5%and15%forthe5-secondand60-secondembeddings,respectively. Whileidentificationperformanceusing
5-secondembeddingsproduceschancelevel-performance,weobservethatEKYTisstillabletoproduceabove-chance
identificationrateswith60-secondembeddings. Similartotheverificationsetting,EKYTdemonstratesnoabilityto
re-identifyusersusingtheMindLinkdataastheauthenticationsetwhenusingeither5-or60-secondembeddings,
producinganIRof0.0%inbothcases.
Figure2: ROCcurvesforbiometricverificationon5-secondenrollment(left)and60-secondenrollment(right)across
thethreedevices.
6AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
(a)EyeLink,5-seconds. (b)EyeLink,60-seconds.
(c)Vive,5-seconds. (d)Vive,60-seconds.
(e)MindLink,5-seconds. (f)MindLink,60-seconds.
Figure3: Similaritydistributionsforgenuineandimpostersubjectsforembeddingscreatedwith5secondsand60
secondsofdata.
4.3 DevicevsSubjectEffectsonEmbeddingSpace
Onepossibleexplanationfortheobserveddiscrepancyinbiometricperformancebetweendevicesisthatthedifference
indataqualitybetweendevicesaremoreprominentthanthesimilaritiesfoundinsubject-specificcharacteristicswhen
enrollingandauthenticatingondifferentdevices.
Figure3showsthedistributionofsimilarityscoresforgenuineandimposterembeddingsforeachexperimentalsetting.
Themoreseparatedthegenuineandimposterdistributionsare,thebetterbiometricperformancethemodelachieves.
ThesimilarityscoredistributionswhenauthenticatingwithEyeLinkdata(Figures3aand3b)areverywellseparated;
theoveralldistributionofallsimilarityscoresisdistinctlybimodal,withlittleoverlapbetweenthegenuineandimposter
distributions. On the other hand, similarity distributions when authenticating with Vive (Figures 3c and 3d) and
MindLink(Figures3eand3f)datafeaturenotablylessseparationbetweengenuineandimposterscores. Becausethe
genuinesubjectembeddingsfromthesedevicesproducelowersimilarityscores,thereissignificantoverlapbetweenthe
genuineandimpostersimilarityscoredistributions. Thismakesitharderforthemodeltodistinguishbetweengenuine
andimpostersubjects,whichinturncontributestothepoorbiometricperformanceobserved.
Figure4showsaDensMap[22]visualizationoftheembeddingspacefortheembeddingsproducedbyEKYT.This
embeddingspacefeaturesthreedistinct,well-separatedclusterscorrespondingtodevice(Figure4a),andaremore
looselyconcentratedbysubjectidentitywithintheseprimarygroups(Figure4b). Whilethisvisualizationshowsthat
EKYTcanmeaningfullydistinguishbetweensubjectembeddingswithinadevice,italsosuggeststhatdevicetypehasa
muchstrongerinfluenceovertheshapeoftheembeddingspacethansubjectidentity.
7AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
Enrollment Authentication IR(%)↑
EyeLinkRAN 73.91
EyeLinkTEX ViveTEX 5.00
MindLinkTEX 0.00
Table4: Biometricidentificationresultswhenenrollingandauthenticatingon5secondsofdata.
Enrollment Authentication IR(%)↑
EyeLinkRAN 95.65
EyeLinkTEX ViveTEX 15.00
MindLinkTEX 0.00
Table5: Biometricidentificationresultswhenenrollingandauthenticatingon60secondsofdata.
5 Discussion
Overall, our results substantiate privacy concerns for cross-platform identity linkage using EMB. We demonstrate
thatthestate-of-the-artEKYTbiometricmodelachievesabove-chancecross-platformverificationandidentification
performanceforatleastoneofthedevicesexamined. Wealsoobservethateyetrackingsignalqualitymaybean
obstacletoEKYT’sabilitytoreliablylinksubjectidentitiesbetweendevices,whichmaybeendemictoourchoiceof
biometricmodel.
EKYTwastrainedtoextractmeaningfulbiometricfeaturesfromhigh-qualitydatacapturedbyaresearch-gradeeye
tracker,theEyeLink1000. OurresultssuggestthatthefeaturesthatEKYTlearnedtoextractmaynotgeneralizewellto
avarietyofeyetrackingsignalqualities,asbiometricperformancedegradessignificantlywhenauthenticatingwithdata
fromlowerqualityeyetrackingdevices. However,EKYTmeaningfullyre-identifiedsubjectsusingdatafromtheVive,
whoseeyetrackingsignalqualityissignificantlyclosertotheEyeLink’sthantheMindLink’s. Whilebetterbiometric
authenticationresultscouldhavebeenachievedbyfine-tuningthemodelwithdatafromallthreedevices,ourthreat
modelassumesthatanadversaryisnotcapableofaccessingoralteringthebiometricmodeltoincreasetheirchanceof
successfullyinfiltratingthetargetsystem. Becausetheobjectiveofthisstudyistoestablishabaselineoftheriskfor
cross-platformre-identification,alteringEKYTtomaximizebiometricperformanceacrossallthreedevicesisoutside
thescopeofourstudy.
(a)Embeddingslabeledbydevice(N=3). (b)Embeddingslabeledbysubject(N=21).
Figure4: ADensMapvisualizationoftheembeddingspaceforall60-secondembeddingsgeneratedbyEKYT.
8AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
OurinvestigationfirstconfirmsthatEKYTachievessimilarverificationandidentificationperformanceontheEyeLink
asEKYT’soriginalevaluation. LohrandKomogortsev[18]originallyachieveanEERof3.5%andanIRof91%when
using5-secondembeddingsunderasimilarevaluationparadigmasTables2and4,meaningthatourinvestigation
producesonlyanominaldegradationinbiometricperformancerelativetotheproportionofsubjectsthatareincorrectly
verifiedoridentified.
Wealsoobserveabove-chanceverificationrateswhenusingtheVivedataastheauthenticationset,indicatingthat
subject-specificcharacteristicsthataresharedinbothsubsetsofeyetrackingdatacanbemeaningfullyextractedand
linked. IdentificationrateswhenusingtheVivedatadonotmeaningfullyexceedchance-levelperformancewhenusing
5-secondembeddings. However,weobserveabove-chanceidentificationrateswhenusing60-secondembeddingsfrom
theVivedata,whichindicatesthatmeaningfulbiometricidentificationacrossdevicesispossiblegivenasufficient
volumeofdata.
WhenusingtheMindLinkdataforauthentication,weobservebiometricverificationperformanceapproachingchance
levels,meaningthatdatafromtheMindLinkdidnotenablecross-platformidentitylinkage. UsingtheMindLinkfor
biometricidentificationproducessimilarresults—whenusingboth5-secondembeddingsand60-secondembeddings,
the MindLink data produced a 0% identification rate. This finding is particularly interesting, as the EyeLink and
MindLinkdatausedforenrollmentandauthenticationwerecollectedsimultaneouslyfromthesamesubjectsatthesame
time. Theoretically,theonlydifferencesinthedatafromthesetwodevicesaretheeyethatdatawascollectedfrom
anddifferencesineyetrackingsignalqualityproducedbyeachdevice’sgazeestimationpipeline. Itispossiblethat,
althoughthepre-trainedEKYTmodelcanidentifyuniquesubjectcharacteristicswithinunseendevices,thedifferences
ineyetrackingsignalqualitybetweendeviceshindersitsabilitytosuccessfullyassociateembeddingsbelongingtothe
sameidentityacrosstwodevices.
The distribution of similarity scores shown in Figure 3 further illustrates the discrepancy in performance between
devices.Thelowdegreeofseparationbetweengenuineandimposterauthenticationattemptscontributestotherelatively
poorbiometricperformancefortheViveandtheMindLink.
WefurtherillustratethebehaviorofthemodelbyvisualizingtheembeddingspaceforallembeddingsinFigure4.
WhilewewouldexpectEKYTtoeffectivelydistinguishEyeLinkdatafromnon-EyeLinkdata,wedidnotexpectitto
alsoclearlydistinguishbetweendatacollectedfromtheViveandtheMindLink,despiteneverbeingexposedtodata
fromeitherdeviceduringtraining.
Theseresultssuggestthattherelativedifferencesineyemovementsignalqualitybetweendevicesaffectsthemodel’s
abilitytomeaningfullylinkidentitiesacrossdevices. TheVivedataandtheEyeLinkdataarerelativelymoresimilar
intermsofspatialaccuracyandprecisionthantheMindLink(Table1),whichmaycontributetothebetterbiometric
performanceobservedwhenusingVivedataforauthentication.Itisanopenresearchquestionwhethertheauthentication
modeladditionallyidentifiesartifactsinthedataspecifictoadevice’sgazeestimationpipeline,ratherthanthesignal
qualityitself. ThisraisesthequestionofwhetheranEMBauthenticationsystemwouldbesusceptibletocross-platform
identitylinkageifthetwodifferenteyetrackingdevicesfeatureddifferentlevelsofsignalquality,butwerecreatedby
thesamemanufacturer.
6 Limitations
Weacknowledgethatthisstudyhassomelimitationsthatmayhaveaffectedoverallbiometricperformance,largely
stemmingfromtheavailabilityofpairedeyemovementdata.
Firstly,thedatasetemployedforthisinvestigationcontainsaverysmallnumberofsubjects. Pairedeyemovementdata
islimitedinavailabilityandcanbecostlytoproduce;ifalargerdatasetofpairedeyemovementemerges,futurework
shouldre-evaluatetheresultsobtainedinthisinvestigationwithalargercohortofsubjects. Secondly,thedatafrom
eachdeviceusedinthisinvestigationwerecollectedfromdifferenteyes;theEyeLinkportionwascapturedfromtheleft
eye,whiletheMindLinkandViveportionswerecapturedfromtheright. Whilegazepositionsbetweenthetwoeyesare
typicallyhighlycorrelated[2],usingdatastreamsfromdifferenteyesmayaffectoverallbiometricperformancewhen
usingeyemovementtaskslikereading,whichinvolveleft-to-righteyemovementpatterns. Additionally,downsampling
theEyeLinkandMindLinkdatato250Hzcouldhavealsoaffectedbiometricperformance. However, wesuggest
thatthepotentialimpactofdownsamplingdataonourresultsisminimal,aswesuccessfullyreplicatethebiometric
performanceobservedintheEKYT’soriginalinvestigationusingtheEyeLinkportionofthedata. Adevice’snativeeye
trackingsignalqualitylikelyhasalargereffectonbiometricperformancethandownsamplingdoes.
9AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
7 ConclusionsandFutureWork
This work explores the privacy implications of ubiquitous eye tracking, a topic that is often discussed but seldom
investigatedineyetrackingliterature. Specifically,wequantifyamodernEMB-basedauthenticationmodel’sability
to perform cross-platform identity linkage, where a user’s identity is connected across different devices that use
eyetrackingtechnology. WeshowthatamodernEMBsystemcanachieveabove-chancebiometricauthentication
performancewhenusingdatafromtwodifferenteyetrackingdevices,therebysubstantiatingconcernsforuserprivacy
inenvironmentswithubiquitouseyetracking.
Thisinvestigationadvancesafundamentalunderstandingoftheprivacyriskofcross-platformidentitylinkageforeye
tracking. Bydemonstratinganappreciableriskforcross-platformidentitylinkageviaeyetracking, ourstudycan
guidethedevelopmentofpracticaldefensesandprivacypreservingtechniquesthatpreventbothEMBsystemsandeye
tracking-enabledplatformsfrombeingexploitedtoviolateuserprivacy. Futureworkineyetrackingprivacycanshed
furtherlightonthisprivacyriskbyinvolvingalargerpopulationofusersacrossavarietyofeyetrackingdevicesof
varyinglevelsofsimilarity.
8 Acknowledgements
ThismaterialisbaseduponworksupportedbytheNationalScienceFoundationGraduateResearchFellowshipunder
GrantNo. DGE-1840989. Anyopinion,findings,andconclusionsorrecommendationsexpressedinthismaterialare
thoseoftheauthors(s)anddonotnecessarilyreflecttheviewsoftheNationalScienceFoundation.
References
[1] SamanthaAzizandOlegKomogortsev. Anassessmentoftheeyetrackingsignalqualitycapturedinthehololens
2. In 2022 Symposium on Eye Tracking Research and Applications, ETRA ’22, New York, NY, USA, 2022.
AssociationforComputingMachinery.
[2] SamanthaAziz,DillonJLohr,andOlegKomogortsev. Synchroneyes: Anovel,paireddatasetofeyemovements
recordedsimultaneouslywithremoteandwearableeye-trackingdevices. In2022SymposiumonEyeTracking
ResearchandApplications,ETRA’22,NewYork,NY,USA,2022.AssociationforComputingMachinery.
[3] RomanBednarik,TomiKinnunen,AndreiMihaila,andPasiFränti. Eye-movementsasabiometric. InImage
Analysis,pages780–789,Berlin,Heidelberg,2005.SpringerBerlinHeidelberg.
[4] B.David-John,K.Butler,andE.Jain. Privacy-preservingdatasetsofeye-trackingsampleswithapplicationsinxr.
IEEETransactionsonVisualization&ComputerGraphics,29(05):2774–2784,may2023.
[5] BrendanDavid-John,DianeHosfelt,KevinButler,andEaktaJain. Aprivacy-preservingapproachtostreaming
eye-trackingdata. IEEETransactionsonVisualizationandComputerGraphics,2021.
[6] S.Eberz,G.Lovisotto,A.Patane,M.Kwiatkowska,V.Lenders,andI.Martinovic. Whenyourfitnesstracker
betraysyou: Quantifyingthepredictabilityofbiometricfeaturesacrosscontexts. In2018IEEESymposiumon
SecurityandPrivacy(SP),pages889–905,LosAlamitos,CA,USA,may2018.IEEEComputerSociety.
[7] Anjith George and Aurobinda Routray. A score level fusion method for eye movement biometrics. Pattern
RecognitionLetters,82:207–215,2016. Aninsightoneyebiometrics.
[8] CoreyHollandandOlegV.Komogortsev. Biometricidentificationviaeyemovementscanpathsinreading. In
2011InternationalJointConferenceonBiometrics(IJCB),pages1–8,2011.
[9] CoreyD.HollandandOlegV.Komogortsev. Complexeyemovementpatternbiometrics: Analyzingfixationsand
saccades. In2013InternationalConferenceonBiometrics(ICB),pages1–8,2013.
[10] ShaohuaJia,DoHyongKoh,AmandaSeccia,PashaAntonenko,RichardLamb,AndreasKeil,MatthewSchneps,
andMarcPomplun. Biometricrecognitionthrougheyemovementsusingarecurrentneuralnetwork. In2018
IEEEInternationalConferenceonBigKnowledge(ICBK),pages57–64,2018.
[11] PawelKasprowskiandJózefOber. Eyemovementsinbiometrics. InDavideMaltoniandAnilK.Jain,editors,
BiometricAuthentication,pages248–258,Berlin,Heidelberg,2004.SpringerBerlinHeidelberg.
[12] JacobLeonKröger,OttoHans-MartinLutz,andFlorian"Müller. WhatDoesYourGazeRevealAboutYou? On
thePrivacyImplicationsofEyeTracking,pages226–241. SpringerInternationalPublishing,Cham,2020.
[13] JingjieLi,AmritaRoyChowdhury,KassemFawaz,andYounghyunKim. Kaleido: Real-Timeprivacycontrolfor
Eye-Trackingsystems. In30thUSENIXSecuritySymposium(USENIXSecurity21),pages1793–1810.USENIX
Association,August2021.
10AssessingthePrivacyRiskofCross-PlatformIdentityLinkageusingEyeMovementBiometrics
[14] DanielJ.LieblingandSörenPreibusch. Privacyconsiderationsforapervasiveeyetrackingworld. InProceedings
ofthe2014ACMInternationalJointConferenceonPervasiveandUbiquitousComputing: AdjunctPublication,
UbiComp’14Adjunct,page1169–1177,NewYork,NY,USA,2014.AssociationforComputingMachinery.
[15] AoLiu,LirongXia,AndrewDuchowski,ReynoldBailey,KennethHolmqvist,andEaktaJain. Differentialprivacy
foreye-trackingdata. InProceedingsofthe11thACMSymposiumonEyeTrackingResearch&Applications,
ETRA’19,NewYork,NY,USA,2019.AssociationforComputingMachinery.
[16] DillonLohr,SamanthaAziz,LeeFriedman,andOlegV.Komogortsev. Gazebasevr,alarge-scale,longitudinal,
binoculareye-trackingdatasetcollectedinvirtualreality. ScientificData,10(1):177,Mar2023.
[17] DillonLohr,HenryGriffith,andOlegV.Komogortsev. Eyeknowyou: Metriclearningforend-to-endbiometric
authenticationusingeyemovementsfromalongitudinaldataset. IEEETransactionsonBiometrics,Behavior,and
IdentityScience,4(2):276–288,2022.
[18] DillonLohrandOlegV.Komogortsev. Eyeknowyoutoo: Towardviableend-to-endeyemovementbiometrics
foruserauthentication. IEEETransactionsonInformationForensicsandSecurity,17:3151–3164,2022.
[19] DillonLohrandOlegVKomogortsev. SourceCodeandPretrainedModelsforEyeKnowYouToo,2022.
[20] PäiviMajarantaandAndreasBulling. EyeTrackingandEye-BasedHuman–ComputerInteraction,pages39–65.
SpringerLondon,London,2014.
[21] SilviaMakowski,PaulPrasse,DavidR.Reich,DanielKrakowczyk,LenaA.Jäger,andTobiasScheffer. Deep-
eyedentificationlive: Oculomotoricbiometricidentificationandpresentation-attackdetectionusingdeepneural
networks. IEEETransactionsonBiometrics,Behavior,andIdentityScience,3(4):506–518,2021.
[22] AshwinNarayan,BonnieBerger,andHyunghoonCho. Density-preservingdatavisualizationunveilsdynamic
patternsofsingle-celltranscriptomicvariability. bioRxiv,2020.
[23] AnjulPatney,MarcoSalvi,JoohwanKim,AntonKaplanyan,ChrisWyman,NirBenty,DavidLuebke,andAaron
Lefohn. Towardsfoveatedrenderingforgaze-trackedvirtualreality. ACMTrans.Graph.,35(6),dec2016.
[24] ThammathipPiumsomboon,GunLee,RobertW.Lindeman,andMarkBillinghurst. Exploringnaturaleye-gaze-
basedinteractionforimmersivevirtualreality. In2017IEEESymposiumon3DUserInterfaces(3DUI),pages
36–39,2017.
[25] PaulPrasse,LenaA.Jäger,SilviaMakowski,MoritzFeuerpfeil,andTobiasScheffer. Ontherelationshipbetween
eyetrackingresolutionandperformanceofoculomotoricbiometricidentification. ProcediaComputerScience,
176:2088–2097,2020. Knowledge-BasedandIntelligentInformation&EngineeringSystems: Proceedingsofthe
24thInternationalConferenceKES2020.
[26] Abraham. Savitzky and M. J. E. Golay. Smoothing and differentiation of data by simplified least squares
procedures. AnalyticalChemistry,36(8):1627–1639,Jul1964.
[27] HardeepSingh,J.S.Bhatia,andJasbirKaur. Eyetrackingbaseddriverfatiguemonitoringandwarningsystem.
InIndiaInternationalConferenceonPowerElectronics2010(IICPE2010),pages1–6,2011.
[28] JosephWSpooner,SusanMSakala,andRobertWBaloh. Effectofagingoneyetracking. ArchivesofNeurology,
37(9):575–576,1980.
[29] JulianSteil,InkenHagestedt,MichaelXuelinHuang,andAndreasBulling. Privacy-awareeyetrackingusing
differentialprivacy. InProceedingsofthe11thACMSymposiumonEyeTrackingResearch&Applications,ETRA
’19,NewYork,NY,USA,2019.AssociationforComputingMachinery.
11