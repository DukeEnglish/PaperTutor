SemRel2024: A Collection of Semantic Textual Relatedness Datasets
for 14 Languages
NedjmaOusidhoum∗1,ShamsuddeenHassanMuhammad∗2,MohamedAbdalla,IdrisAbdulmumin3,
IbrahimSaidAhmad4,SanchitAhuja5,AlhamFikriAji6,VladimirAraujo7,AbinewAliAyele8,9,
PavanBaswani10,MeriemBeloucif11,ChrisBiemann8,SofiaBourhim,ChristineDeKock12,
GenetShankoDekebo13,OumaimaHourrane,GopichandKanumolu10,LokeshMadasu10,SamuelRutunda14,
ManishShrivastava10,ThamarSolorio6,NirmalSurange10,HailegnawGetanehTilaye15,
KrishnapriyaVishnubhotla16,GentaWinata17,SeidMuhieYimam8,SaifM.Mohammad18
1CardiffUniversity,2ImperialCollegeLondon,3DataScienceforSocialImpactResearchGroup,UniversityofPretoria,
4InstituteForExperientialAI,NortheasternUniversity,5BITSPilani,6MBZUAI,7KULeuven,
8UniversitätHamburg,LanguageTechnologyGroup,9BahirDarUniversity,FacultyofComputing,10IIITHyderabad,
11UppsalaUniversity,12TheUniversityofMelbourne,13AdamaScienceandTechnologyUniversity,14DigitalUmuganda,
15KotebeUniversityofEducation,16UniversityofToronto,17HKUST,18NationalResearchCouncilCanada
OusidhoumN@cardiff.ac.uk
Abstract
Semantic Relatedness Dataset Language Families
Exploringandquantifyingsemanticrelatedness Afro-Asiatic Indo-European
is central to representing language. It holds
significant implications across various NLP Amharic Afrikaans
tasks, including offering insights into the ca-
Arabic English
pabilitiesandperformanceofLargeLanguage
Algerian Arabic Hindi
Models(LLMs). WhileearlierNLPresearch
primarily focused on semantic similarity, of- Hausa Marathi
ten within the English language context, we
Moroccan Arabic Punjabi
instead investigate the broader phenomenon
of semantic relatedness. In this paper, we Spanish
Austronesian
present SemRel, a new semantic relatedness
datasetcollectionannotatedbynativespeakers Indonesian Niger-Congo
across14languages: Afrikaans,AlgerianAra-
Kinyarwanda
bic,Amharic,English,Hausa,Hindi,Indone- Dravidian
sian,Kinyarwanda,Marathi,MoroccanArabic,
Modern Standard Arabic, Punjabi, Spanish, Telugu
and Telugu. These languages originate from
Figure1:SemRel2024languagesandlanguagefamilies.
fivedistinctlanguagefamiliesandarepredom-
inantly spoken in Africa and Asia – regions
characterisedbyarelativelylimitedavailability
ofNLPresources. EachinstanceintheSem-
text representations. Within this context, seman-
Reldatasetsisasentencepairassociatedwith
tic textual relatedness (STR) aims to capture the
ascorethatrepresentsthedegreeofsemantic
degree to which two linguistic units (e.g., words
textualrelatednessbetweenthetwosentences.
or sentences, etc.) are close in meaning. Two
Thescoresareobtainedusingacomparativean-
notationframework. Wedescribethedatacol- unitsmayberelatedinavarietyofdifferentways
lectionandannotationprocesses,relatedchal- (e.g.,byexpressingthesameview,originatingfrom
lenges when building the datasets, and their the same time period, elaborating on each other,
impact and utility in NLP. We further report etc.). On the other hand, semantic textual simi-
experimentsforeachlanguageandacrossthe
larity (STS) considers only a narrow view of the
differentlanguages.
relationshipthatmayexistbetweentexts(suchas
equivalenceorparaphrase)whichdoesnotincorpo-
1 Introduction
rateotherdimensionsofrelatednesssuchasentail-
Characterisingtherelationshipbetweentwounits ment,topicorviewsimilarity,ortemporalrelations
oftextisanimportantcomponentofconstructing (Abdalla et al., 2023). For example, ‘She scored
manygoals.’ and‘Theteammovedontothefinals.’
*Equalcontributionfromthefirstandsecondauthors.Au-
thors3to26arelistedinalphabeticalorder. wouldreceivealowsimilarityscore,despitethere
4202
beF
41
]LC.sc[
2v83680.2042:viXrabeing a strong intuitive relatedness. In this work, home to over 5,000 languages from over 20
weinvestigatethebroaderconceptofsemantictex- language families and have the highest lin-
tualrelatedness. guistic diversity among all continents, there
STRiscentraltounderstandingmeaningintext is little publicly available data on these lan-
(Hasan and Halliday, 1976; Miller and Charles, guages.
1991;MorrisandHirst,1991)anditsautomation
2. Wediscussgeneralandlanguage-specificchal-
canbenefitvariousdownstreamtaskssuchasevalu-
lengesrelatedtothedatacollectionandanno-
atingsentencerepresentationmethods,questionan-
tationoftheSemReldatasets.
swering,andsummarisation(Abdallaetal.,2023;
Wangetal.,2022). 3. We present baseline experiments conducted
Prior NLP work has predominantly focused indifferentmonolingualandcrosslingualset-
on semantic textual similarity, largely due to a tingstodemonstratetheusefulnessandpoten-
dearth of relatedness datasets. Of the existing tialofourdatasetcollection.
STRandSTSdatasets,mostareintheEnglishlan-
Topromoteresearchinthefieldofsemanticre-
guage. ThefewSTRandSTSresourceswhichexist
latedness, we publicly released the SemRel2024
fornon-highresourcelanguagesarecomposedof
datasetaspartoftheSemEval2024sharedtask1.*
word-levelorphrase-levelpairings. Toaddressthis
Thetaskattractedatotalof162participants,with
gap,wecurate14newmonolingualSTRdatasets
alargeinterestindifferentlow-resourcelanguages.
for Afrikaans (afr), Amharic (amh), Modern
Thisstrongparticipationandinterestshowtherele-
Standard Arabic (arb), Algerian Arabic (arq),
vanceandsignificanceofthesemanticrelatedness
Moroccan Arabic (ary), English (eng), Span-
taskintheNLPcommunity.
ish(esp),Hausa(hau),Hindi(hin),Indonesian
(ind),Kinyarwanda(kin),Marathi(mar),Pun-
2 RelatedWork
jabi(pan),andTelugu(tel).
The datasets are composed of sentence pairs,
The field of semantic relatedness in natural lan-
eachassignedarelatednessscorebetween0(com-
guage processing covers a variety of approaches
pletelyunrelated)and1(maximallyrelated). With
and techniques designed to measure the close-
theaimofcuratingdiverseSTRdatasets,thepairs
nessinmeaningbetweenunits,specificallywords
ofsentenceswerefirstselectedfrompre-existing
(Miller,1994),orsentences(Abdallaetal.,2023).
datasetscoveringvarioustopicsandformalitylev-
As noted previously, most prior work focuses
els,e.g.,newsdata,Wikipedia,andconversational
on STS, a narrower subset of STR, and often
data. Additionally,weselectedpairswithalarge
only covers high-resource languages such as En-
rangeofexpectedrelatednessvaluesbyconsidering
glish(Agirreetal.,2012,2013,2014,2015,2016;
lexicaloverlap,contiguity,topiccoverage,andran-
Marelli et al., 2014), Arabic, German, Spanish,
dompairings. Togeneratetherelatednessscores,
Turkish (Ahmed et al., 2020; Cer et al., 2017b),
the sentence pairs were then annotated by native
andItalian(Glavašetal.,2018)withtheonlyex-
speakerswhoperformedcomparisonsbetweendif-
ceptionbeingCroatian(Glavašetal.,2018)orFarsi
ferentpairsofsentencesusingBest-WorstScaling
(Vulic´ et al., 2020). To overcome the scarcity of
(BWS).BWSisknowntoavoidknownlimitations
available resources, Tang et al. (2018) proposed
oftraditionalratingscaleannotationmethods(Kir-
sentence-level,encoder-basedmethodsleveraging
itchenkoandMohammad,2017). Theannotation
EnglishdatatocreateArabic,Spanish,Thai,and
processledtothehighreliabilityofthefinalrelated-
Indonesian datasets, whereas Pandit et al. (2019)
nessrankingsinthedifferentSemReldatasets. Our
usetraditionaldataaugmentationmethodstocreate
maincontributionscanbesummarisedasfollows:
Bangladata.
Bycomparison,thisworkisfocusedonthecre-
1. We present the first benchmark on semantic
ationofresourcesforsentence-levelSTRinmulti-
distance (similarity or relatedness) that in-
plelow-resourcelanguages. Here,thefewworks
cludes low-resource African and Asian lan-
whichdoexistfornon-high-resourcelanguagesare
guagesfromfivedifferentlanguagefamilies
atthewordlevel(e.g.,Yumetal.,2021forKorean).
(see Figure 1) such as Hausa, Amharic, In-
donesian,Marathi,Telugu,MoroccanandAl-
*https://semantic-textual-relatedness.github.
gerianArabic. AlthoughAfricaandAsiaare ioLang. Sentence 1 Sentence 2 Score
tel ఇపప్టికే ధోనీ టెసుట్ కిర్కెట్ కు గుడ్ బౖె చెపిప్న అంతకు ముందు జరిగిన మరో రోడుడ్ 0.02
విషయంతెలిసిందే� పర్మాదంలోఏడుగురుమరణించగా���మంది
గాయపడాడ్రు�
afr My eerste stukkie advies is dat jy Dit bring tot n einde die maan- 0.19
realistiesmoetweesoordieafstand verkenningsprogram van die
watjywilhengel. VerenigdeState..
esp Costo monetario para mantener el Todavía nos quedan más de 0.27
microondaspor$6. 200.000$ por recaudar de suscrip-
toresydonantescomousted.
mar ठाकरेसरकारच्यामंत्िरमंडळात25कॅिबनेट त्यामुळेगुढीपाडवामेळाव्यामध्येराजठाकरे 0.42
मंत्रीअसणारआहेत. काय बोलणार याकडे सर्वांचे लक्ष लागून
रािहलेआहे.
arq ينوﻙﺕ وﻉاﺕ ىنغلا يﻑ مهلوقي تايﺏﺃلا ﺩﺡاو نياﻙ يلاﺥحوﺭلانﻡاينﺩلايﻑشاهزاﻡيللا 0.50
مهيﻑﺭﻉﺕ
pan ਪੰਜਾਬਤੋਂਦੂਜੀਵਾਰਿਵਧਾਇਕਬਣੇਅਮਨਅਰੋੜਾ ਇਨ੍ਹਾਂ ਿਵੱਚ ਦੂਜੀ ਵਾਰ ਿਵਧਾਇਕ ਬਣੇ ਪੋ੍ਰ. 0.56
ਦਾਮੰਤਰੀਬਣਨਾਤੈਅਹੈ. ਬਲਿਜੰਦਰਕੌਰਜਾਂਸਰਵਜੀਤਮਾਣੂੰਕੇਨੰੂਵੀਮੰਤਰੀ
ਬਣਾਇਆਜਾਸਕਦਾਹੈ
arb يﻑوداﺹﺕقﺍلاخيراﺕنﻉﺓﺡﻡلىلإمﻙﺏلقﺕنانﺁلا ﺭﺏﻙأ نﻡ ناﺕيﺡلا ﺩيﺹ ناﻙ ٠٥٨١ ماﻉ يلاوﺡ 0.62
.ةﺩيﻑﻡنوﻙﺕﺩقيﺭظن ةﺩﺡﺕﻡلاتايﺍلولايﻑتاﻉانﺹلا
hin देशमेंकोरोनावायरससेमौतकाआंकडा़ 100 देशमेंकोरोनावायरसकाकहरतेजीसेबढत़ ा 0.72
के पारपहुंचा, िपछले12घंटे में26कीगई जारहाहै।
जान.
kin Duhugukire kwandika neza Ikin- Duhugukire kwandika neza Ikin- 0.75
yarwanda Mu myandikire y’Ikin- yarwanda (igice cya gatatu) Mu
yarwanda hari amakosa akunda myandikire y’Ikinyarwanda, hari
gukorwa ashingiye ku ifatana amagambo afatana n’andi atan-
n’itandukanary’amagambo. dukana.
ary ٣٧ـﺏاﺩﺏﺕيداغةراﺭﺡلا..ناضﻡﺭلموﻙﺱاروﺩجو اﺩﺏﺕيداغةراﺭﺡلا ..لﻉشﺕيهوناضﻡرجﺭﺥﺭيغ 0.75
قطانﻡلاداهﻑﺓجرد قطانﻡلاداهﻑﺓجرد٤٠ـللﺹوﺕيداغو
ind PendidikanDesaPusakamemiliki4 Pendidikan Desa Serumpun Buluh 0.83
sekolah. memiliki4sekolah.
amh እኛንከዚህጉዳይጋርየምንገናኝበትቅንጣት እኛንቅንጣትታህልከዚህጉዳይጋየሚያገና 0.89
ታክልግንኙነትየለም ኘንነገርየለም
hau Hakayafurtaacikinjawabinsana Ya yi wannan i�irarin e a cikin 0.94
murnar cikar Najeriya shekaru 61 jawabin sa na murnar cikar Na-
dasamun‘yanci. jeriya 61 da samun ‘yanci a ranar
Juma’a.
eng I’vebeensearchingtheentireabbey I’m looking for you all over the 1.00
foryou. abbey.
Table 1: Examples of sentence pairs and their corresponding scores (from 0 to 1) in the various SemRel2024
languages. Examplesaresortedbyscoreandrowswithhigherdegreesofrelatednessarelightercolored. The
translationscanbefoundintheappendix.
To our knowledge, the only corpora specially de- andseveralchallengeshadtobeaddressedwhen
signed for semantic textual relatedness between workingwithless-resourcedlanguages.
pairs of sentences was created by Abdalla et al.
(2023)forEnglish. Abdallaetal.(2023)curateda 3 STRData
datasetof5,500Englishsentencepairsannotated
3.1 Datacollection
usingacomparativeannotationframework. Their
datasethassincebeenusedtoevaluateembedding Akeystepinthedatacreationprocesswasidentify-
approaches (Wangand Li, 2022) and other meth- ingsourcesoftextforeachlanguageandselecting
ods(Wangetal.,2022). ThecoreofAbdallaetal. sentence pairs. This was especially challenging
(2023)approachservesasthemodelfordataanno- for low-resource languages such as Hausa, Kin-
tationsinthisproject. However,ourworkaddition- yarwanda,andAlgerianArabic. Sincearbitrarily
allyexploresnewwaysofdatacollection–curation, selecting sentences and pairing them would leadLang. Curationtechnique DataSources
afr Overlap,Randomselection,Manualcheck Newsdata,reviews,recipes,blogs.
amh Overlap,Similarity,Randomselection,Manualcheck Newsdata,crawling.
arb Overlap,Contiguity,Randomselection,Manualcheck Tedtalksubtitles,newsdata.
arq Overlap,Contiguity,Randomselection,Manualcheck YouTubecomments,conversationaldata.
ary Overlap Newsdata.
eng Overlap,Similarity,Paraphrases,Contiguity,Randomness Bookreviews,newsdata,tweets,other.
esp Overlap,Contiguity,Similarity Moviereviews,newsdata,other.
hau Overlap Newsdata.
hin Overlap,Similarity,Contiguity,Paraphrase,Randomness Newsdata,other.
ind Overlap Wikipedia,newsdata.
kin Overlap Newsdata.
mar Overlap,Similarity,Contiguity,Paraphrase,Randomness Newsdata,other.
pan Overlap Newsheadlines.
tel Overlap,Similarity,Contiguity,Paraphrase,Randomness Newsdata,other.
Table2: Thecurationtechniquesusedfordatacreation. Welistthemaintextualsourcespresentinthedatasetswe
usedforinstancecreation(i.e.,sentencepairing). MoredetailsaresharedinSection3.1.1.
tomanyunrelatedinstances,wereliedonseveral different formality collected from the Formality
heuristics,discussedinSection3.1.2,toensurea dataset (Rao and Tetreault, 2018), book reviews
widerangeofscoresforeachlanguage. Sincethese fromGoodreads(WanandMcAuley,2018),para-
methodsarehighlycorpus-andlanguage-specific, phrasesfrommachinetranslationsystemsextracted
theapproachesusedperlanguageweredetermined fromtheParaNMTdataset(WietingandGimpel,
bynativespeakers. Weprovidethedataoriginand 2017),pairsofpremisesandhypothesesfromthe
thepairingapproachesusedforeachlanguagein SNLI dataset (Bowman et al., 2015), sentences
Section 3.1.1. The composition of the resulting withsemanticsimilarityscores(Ceretal.,2017a),
datasetissummarisedinTable2andthedistribu- andtweets(Mohammadetal.,2017).
tion of the relatedness scores across the datasets Similarly, for Spanish, sentence pairs were se-
areillustratedinFigure2. lected from semantic similarity datasets (Agirre
et al., 2014, 2015; Cer et al., 2017a), entailment
3.1.1 Datacuration
datasetssuchasSICK-es(Huertas-Tatoetal.,2021)
Since most of the SemRel languages are low- and NLI-es (Araujo et al., 2022). Additionally,
resource,thedomain,(in)formality,anddiversity contiguoussentencesweresampledfromthesum-
ofthesentencepairswerehighlydependentonthe marization dataset XL-Sum (Hasan et al., 2021),
publicly available corpora. We aimed to collect DiscoEvalSpanish(Araujoetal.,2022),andques-
datasetswithaverage-lengthsentences,freeofof- tionsofdifferenttypesweresampledfromSpanish
fensiveutterances,andasdiverseaspossible. As QC(Á.GarcíaCumbrerasetal.,2006).
such, data instances were extracted for each lan-
Arabic Variations: Modern Standard Ara-
guage using a tailored combination of the heuris-
bic, Algerian, and Moroccan Arabic Arabic
tics described in Section 3.1.2. We used further
isknownfordiglossia(Ferguson,1959),meaning
pre-processing,post-processing,anddataanalysis
thatArabicvarietiesareusedfordifferentcontexts.
methods (discussed below) to avoid incoherence
For instance, Modern Standard Arabic is usually
andunnaturalness.
usedinformalandacademiccommunicationwhile
English and Spanish As English and Spanish dialectsaretypicalforconversationalsettings. The
arehigh-resourcelanguages,wesampledsentences various sources of the Arabic data are somewhat
from various sources to capture a wide variety reflectiveofthedistinctlanguageusagescenarios.
ofsentencestructure,formality,andgrammatical- Therefore,forModernStandardArabic(MSA),
ity in texts. As shown in Table 2 for both lan- weusedtwodatasetsfromdifferentdomains: TED
guages, we paired sentences from seven English Talk subtitles on science, society, and art (Zong,
andtenSpanishsourcesinanumberofwaysthat 2015)andnewsarticlesoneconomics(Al-Dulaimi,
includelexicaloverlap,entailment,similarityand 2022). Inadditiontosentenceswithlexicaloverlap,
paraphrases. For instance, the English dataset in- weselectedcontiguoussentencesinTedTalksubti-
cludes sentences having the same meaning but a tlestoincludedifferentdegreesofrelatedness,andassomesentencesinthesubtitleswereslightlyun- 2018)datasets. IndoSumisahuman-writtensum-
grammatical,wecorrectedthembasedonthestan- marizationdatasetconsistingofpairsofnewsarti-
dardArabicgrammarrules. ForAlgerianArabic, cleswiththeirabstractivesummaries. Weparsed
weusedCalYou(Abidietal.,2017),adatasetcom- bothcorporaatasentence-level. Then,aswenoted
posedofYouTubecommentscollectedfrommajor manyerroneousparsesduetocommonIndonesian
AlgerianYouTubechannelsby2017,andtheAlge- abbreviations that involve ’.’, which the sentence
rianinstancesspokenintwomajorAlgeriantowns parsermistakenlydetectsastheendofasentence,
(AlgiersandAnnaba)presentinPADIC:Parallel weaddednewabbreviationsforparsing. Weonly
ArabicDialectCorpus(Meftouhetal.,2015). We selectedsentencesthatarecomposedoffivetofif-
usedlexicaloverlaptopairsentences,pickedcon- teenwords.
tiguousonesinaconversationinPADIC,andadded
randomly or manually selected sentence pairs to Hindi,Marathi,Telugu,andPunjabi Asthese
balance the relatedness score distribution in the four languages lack publicly available resources,
dataset. For both MSA and Algerian Arabic, we especially Marathi, Telugu and Punjabi, we used
allowedshortsentencesasArabicishighlyinflec- onedatasetperlanguagetocreatesentencepairs,
tional. For Moroccan Arabic, we used headlines namely: (1)Mukhyansh(Madasuetal.,2023)for
fromtheGoud.madatasetintroducedbyIssamand Hindi, Marathi and Telugu, composed of news
Mrini(2022)andtheMoroccanArabicsentences headlinesandtheircorrespondingarticles,and(2)
werepairedbasedonlexicaloverlap. Varta(Aralikatteetal.,2023)forPunjabicomposed
ofnewsheadlines. Thetwodatasetsarediversein
Afrikaans TheOscardataset(OrtizSuárezetal.,
nature.
2020)wasusedasbasisfortheAfrikaanscorpus.
ForPunjabi,instanceswerecreatedusinglexical
Wechosesentencesfromnewsarticles,blogs,re-
overlap. For Hindi, Marathi, and Telugu we also
views, and recipes. We also excluded sentences
createdinstancesbygeneratingparaphrases,select-
from religious texts and academic articles after
ingcontiguoussentencesinanewsarticle,pairing
observingthatthesedidnotproducehigh-quality
sentencesfromheadlineswithsomeintheircorre-
pairs. Wefurtherexcludedanumberofadvertorial
sponding articles, and picking random sentences
textsthatappeartobelow-qualitytranslations. All
fromdifferentarticlestobalancethedatasets.
instances were then manually assessed for gram-
marandungrammaticalsentenceswerediscarded. 3.1.2 Sentencepairingheuristics
Sentenceswerepairediftheyhadanoverlapofat
Given a set of texts in a target language, careful
leastfivetokensandatleastthreenon-overlapping
considerationwasgiventotheconstructionofsen-
tokenswithmatcheswithinthesamearticleonly.
tence pairs to ensure that the pairs would exhibit
Randomsentencepairswerealsoincludedtocali-
relatednessscoresvaryingfromcompletelyunre-
bratethedataset.
latedtoveryrelated. Sincerandomselectionwould
Amharic,Hausa,Kinyarwanda ForAmharic, resultinmanyunrelatedpairs,wepairedsentences
wepairedsentencespresentinnewsarticlesfrom mainlybasedonfivemethodspreviouslydefined
different Ethiopian news outlets (Yimam et al., byAbdallaetal.(2023)(describedbelow).
2021). Similarly, the Hausa and Kinyarwanda
Lexicaloverlap Pairsareselectedwithvarious
datasets include pairs of sentences from news ar-
amounts of lexical overlap. That is, one or more
ticles collected by Abdulmumin and Galadanci
words/tokens in common, with or without using
(2019) and Niyongabo et al. (2020), respectively.
TF/IDFnormalisation. Thismethodisexpectedto
Sentencesshorterthanfivewordsandlongerthan
produce a wide range of relatedness values, and
20 were excluded and pairs were created using
wasusedinmostlow-resourcelanguages.
lexicaloverlap. Additionally,forAmharic,weex-
cluded sentences with mixed languages to avoid
Contiguity/Entailment We select pairs of sen-
confusingtheannotators.
tencesthatappearoneaftertheotherinaparagraph
Indonesian For Indonesian, we collected sen- orasocialmediathread. Thismethodislikelyto
tencesfromWikipediatextspresentintheROOTS produce pairs of sentences that are somewhat re-
split(Laurençonetal.,2022;SetyaandMahendra, latedandcancontributetorepresentingthelowto
2018)andtheIndoSum(KurniawanandLouvan, mediumrangesofrelatedness.Language afr amh arb arq ary eng esp hau hin ind kin mar pan tel
#Ann/tuple 2 4 2-3 2 2 2-4 2-4 2-4 4 2 2 2-3 2 4
SHRtrain/dev 0.85 0.90 0.86 0.64 0.77 0.84 0.70 0.74 0.93 0.68 0.74 0.92 0.65 0.79
SHRtest 0.85 0.90 0.86 0.64 0.77 0.80 0.70 0.74 0.94 0.68 0.74 0.96 0.65 0.96
Table3: SHR(split-halfreliability)scoresforeachofthecreateddatasetsplitsandnumbersofuniqueannotations
pertuple(#Ann/tuple). Assomelanguages(eng,hin,mar,andtel)hadsplitsannotatedindependently,wereport
theSHRscoresforboth.
ParaphrasesorMachineTranslation(MT)para-
phrases Thismethodconsistsofselectingpairs
of sentences from paraphrase or MT data. For
MT, we pivot across the translation and back to
the source language to generate a new sentence
andpairitwiththeoriginal. However,manylow-
resourceAsianandAfricanlanguageslackreliable
MTresources.
Semantically similar instances Semantically
similarsentencesareselectedfromapubliclyavail-
able dataset such as the STS dataset by Cer et al.
(2017a)ormanuallyidentifiedbyanativespeaker
Figure2: Violinplotsrepresentingthedistributionsof
in order to include highly related instances and
therelatednessscoresinthevariousdatasets. Weshow
balancethedataset.
how scores vary and spread across the datasets. For
Random selection Random sentences are se- instance,thedistributionoftheArabic(arb)datasetis
unimodal,Marathi’s(mar)isbimodal,andtheIndone-
lected, which are expected to represent the low
sian(ind)dataset’sistrimodal.
tomediumrangesofrelatedness.
Manualcheck Incaseswherethepairsproduced
pairs of sentences) p 0 ≤ i < 4: for a tuple:
bytheabovemethodswerequalitativelyjudgedto i
⟨p ,p ,p ,p ⟩,ifp ismarkedasmostrelatedand
be insufficiently varied, instances were manually 0 1 2 3 0
p as least related, then we know that p > p ,
selectedtobalancethedata. Thiscanapplytoany 3 0 1
p > p , p > p , p > p3,and p > p3. < and
range of relatedness (i.e., high, medium, low, or 0 2 0 3 1 2
>refertolessandmorerelated,respectively. We
unrelated).
thenusetheseinequalitiestocomputereal-valued
3.2 Dataannotationandchallenges scoresthatconsistofthefractionoftimesapairp
i
waschosenasthemostrelatedminusthefraction
Annotation process Similarly to Abdalla et al.
oftimesp waschosenastheleastrelated. Then,
(2023), we used BWS to annotate our data in- i
an ordinal ranking of sentence pairs is generated
stances and generate an ordinal ranking of in-
stances*. Althoughpairwisecomparisonsaremore (Orme,2009;FlynnandMarley,2014).
reliablethansimplylabellingthesentencepairsas Furthermore, the notions of related and unre-
related or unrelated, it is a time-consuming pro- lated have fuzzy boundaries with no singular ac-
cessifperformedonalargedatasetasitrequires cepteddefinitionintheliterature. Differentpeople
N × N = N2 comparisons if performed on a anddifferentlanguageculturesmayhaveseveral
dataset of N instances. Best-worst scaling miti- intuitionsofwheresuchaboundaryexists. There-
gatesthisissueaccordingtoKiritchenkoandMo- fore,byusingcomparativeannotationsandrelying
hammad(2017)asitleadstoreliablescoresfrom on the intuitions of fluent speakers for each lan-
about2×N comparisonsof4-instancetuples. guage to choose between sentence pairs, we can
BWSrequiresfewerlabels(LouviereandWood- avoid fuzzy ill-defined categories. This is in line
worth,1991),inourcase,givenfourinstances(i.e., with our goal of capturing common perceptions
of semantic relatedness (i.e., what is believed by
*The tuples were generated using the BWS scripts pro-
the vast majority) instead of “correct” or “right”
vided by (Kiritchenko and Mohammad, 2017): http://
saifmohammad.com/WebPages/BestWorst.html. rankings.Data afr amh arb arq ary eng esp hau hin ind kin mar pan tel
Train - 992 - 1,262 925 5,500 1,562 1,763 - - 778 1,155 - 1,146
Dev 375 95 32 92 70 250 140 212 288 144 102 293 242 130
Test 375 171 595 584 427 2,500 600 603 968 360 222 298 634 297
Total 750 1,258 627 1,938 1,422 8,250 2,299 2,578 1,256 504 1,102 1,746 876 1,573
Table4: Numberofinstancesinthetraining,dev,andtestsetsforthedifferentdatasets. Thelanguageswithno
trainingdata(afr, arb, hin, ind, pan)wereonlyusedinunsupervisedandcross-lingualsettings.
Instructions Weselectednativespeakerstoan- (SHR) (Cronbach, 1951; Kuder and Richardson,
notatethesentencepairs. Then,givenasetoffour 1937) scores for each of the datasets. SHR mea-
sentencepairs,annotatorsweretaskedwithreport- suresthedegreetowhichrepeatingtheannotations
ingontheirrelativerelatedness. Concretely,given resultsinsimilarrelativerankingsoftheinstances.
4sentencepairs,eachoftheform[sentenceA,sen- First,itsplitsthe4-tupleannotationsintotwobins.
tence B], the task was to select the sentence pair Then,theannotationsforeachbinareusedtogen-
thatisthemostrelated (i.e.,sentenceAisclosest eratetwodifferentindependentrelatednessscores,
in meaning to sentence B) and the sentence pair andtheSpearmancorrelationbetweenthetwosets
thatistheleastrelated (i.e.,sentenceAisfarthest of scores is calculated to estimate the closeness
in meaning to sentence B). The full instructions ofthetworankings. Ahighcorrelationindicates
canbefoundintheAppendix. that the annotations are reliable. This process is
Intheguidelines,itwasnotedthatsentencepairs repeated1,000timesandthecorrelationscoresare
that are more specific in what they share tend to averagedsimilarlytoAbdallaetal.(2023). Overall
be more related than sentence pairs that are only thescoresinTable3varybetween0.64and0.96,
looselyaboutthesametopic. Furthermore,ifone whichindicatesahighannotationreliability.
or both sentences have more than one interpreta-
Disagreements Disagreementsamongstannota-
tion, the annotators have to consider the closest
tors on a 4-tuple can be a useful signal in BWS
meanings.
annotation since it indicates the closeness of one
Overall,bymanuallyexaminingtheannotations,
sentence pair to another. On the other hand, if a
we noted that the BWS framework does lead to
sentence pair consistently occurs in 4-tuples that
more robust annotations. However, a downside
haveverylowannotatoragreement,thenitislikely
isthefactthatannotatingoneinstancecouldtake
thatthesentencepairisthesourceofdisagreement
morethanoneminuteandthetaskcanbechalleng-
and not the closeness of one sentence pair to an-
ing since many instances to be compared can be
other. Thiscanbeduetovariousreasonssuchas
similarly(un)related.
the language use, code-switching, or the annota-
tor’s familiarity with the topics discussed in the
Pilot data annotation To assess the different
instances.
pairing techniques and the potential annotation
Besidessharingourdatasetswiththecommunity,
challenges, we run a pilot annotation task on 20
wealsomakethefull4-tupleannotationspublic.
to100pairsofsentencesforeachlanguagebefore
proceeding with larger annotation batches. This
3.3 Finalpostprocessinganddataquality
helped us assess the difficulties related to the an-
notation task and the choices to be made for the For our final dataset, we carried a data post-
finaldata processingstep. Forinstance, if highly processingsteptoensurethat:
relatedandunrelatedpairswereoccurringtoooften • noinstancesarerepeated;
inthetuples,wereducedthepercentagesofboth • thedatadoesnotincludeinvisiblecharacters,
highlyrelatedandunrelatedpairsbychangingor incorrectlyrenderedemoticons,orgarbleden-
calibrating the data sources if possible, prioritis- codingcharacters;
ingotherpairingtechniques,orincludinganextra • texts are fully anonymised (deleting emails
preprocessingstep(e.g.,paraphrasedetection). and IDs if they occur, replacing @mentions
with@<username>,andreplacinganyURLs
Annotationreliability InTable3,wereportthe withnon-identifiableplaceholder);
numberofannotatorsandthesplit-halfreliability • the data does not include a high amount ofexpletivesorinappropriatelanguage;and 4.4 SupervisedandCrosslingualsettings
• thedataisbalanced.
We use LaBSE (Label Agnostic BERT Sentence
Finally,ateamofnativespeakersmanuallyex-
Embeddings) (Feng et al., 2020) which can map
aminedthescoresforasmanyinstancesaspossible
109languagesintoasharedvectorspace. Withthe
tomakesurethattherelatednessscoresmadesense
embeddingscoveringalltheSemRellanguages,we
andtosupplementthequantitativeevaluationbased
report baseline results using the default hyperpa-
onSHR.
rameters set in the sentence-transformers reposi-
tory*. Ourexperimentsareconducted:
4 Experiments
• usingthepredefinedsetupwithoutfurtherfine-
4.1 Data tuning,
WeusethesplitsreportedinTable4. Forthelan- • byfine-tuningtheLaBSEmodelonourtrain-
guageswithouttrainingdata(afr,arb,hin,ind,pan), ingdatausingacosinesimilarityloss.
we only report experiments in unsupervised and Wereportthescoresonthetestsetsinbothsetups
crosslingualsettings. ForEnglish,weusetheSTR- inAppendixA,Table11.
2022dataset(Abdallaetal.,2023)fortrainingand For the crosslingual baselines, we fine-tune
weuseournewlycreateddatasetfortesting. LaBSEontheEnglishtrainingsetandtestonall
the other datasets except English. On the other
4.2 Experimentalsetup
hand,whentestingontheEnglishdataset,weuse
WereporttheSpearmancorrelationscoresbetween theSpanishtrainingsettofine-tuneLaBSE.
thepredictedlabelsandthegoldstandardonesfor
4.5 Unsupervisedsettings
thedifferentlanguagesinthreemainsettings:
• Supervisedsystemstrainedonlabeledtrain- We use standard encoder-based monolingual and
ingdatasetsprovided. multilinguallanguagemodelsonourdatasets*. We
• Unsupervisedsystemsdevelopedwithoutthe experimentwith:
use of labeled datasets pertaining to seman- • Multilingual BERT (mBERT) (Devlin et al.,
ticrelatednessorsemanticsimilaritybetween 2019),XLMRoberta(XLMR)(Conneauetal.,
unitsoftextofmorethantwowordslongin 2020)forall14languages,
anylanguage. • Monolingualmodels:
• Crosslingualsystemsdevelopedwithoutthe – AfroXLMR (Alabi et al., 2022) for
use of any labeled semantic similarity or se- Afrikaans, Amharic, Hausa, Kin-
mantic relatedness datasets in the target lan- yarwanda,
guage and with the use of data from at least – Indic-BERT (Kakwani et al., 2020) for
oneotherlanguageincludedinSemRel. Hindi,Punjabi,Marathi,andTelugu,
Inourexperiments,weuse: – BERT(Devlinetal.,2019)forEnglish,
• a simple baseline based on the number of – MARBERT,ARBERT(Abdul-Mageed
sharedwords(lexicaloverlap), et al., 2021) and Arabic BERT (Safaya
• sentence embeddings (LaBSE (Feng etal.,2020)forArabic,
et al., 2020), SentenceBERT (Reimers and – BETO (Cañete et al., 2020), ALBETO
Gurevych,2019)),and (Cañete et al., 2022), and RoBERTa-
• standardencoder-basedembeddings. BNE(Fandiñoetal.,2022)forSpanish,
– AmharicRoBERTa(AmRoBERTa)(Yi-
4.3 LexicalOverlap
mametal.,2021)forAmharic,
As shown in Table 5, we report a simple lexical – DziriBERT (Abdaoui et al., 2021) for
overlapbaselinewhichconsistsoftheDicecoeffi-
AlgerianArabic,
cientbetweentwosentencesAandB:thenumber – RoBERTabasedmodel(HauRoBERTa)
of unique unigrams occurring in both sentences,
forHausa(Adelanietal.,2022).
adjustedbytheirlengths(Abdallaetal.,2023). It
We report the Spearman correlation scores with
isdefinedasfollows:
cosine similarity scores for all the BERT-based
*https://github.com/UKPLab/used-transformers
2×|unigram(A)∩unigram(B)| *We use the standard models from HuggingFace (Wolf
(1)
|unigram(A)+unigram(B)| etal.,2020).afr amh arb arq ary eng esp hau hin ind kin mar pan tel
Overlap 0.71 0.63 0.32 0.40 0.63 0.67 0.67 0.31 0.53 0.55 0.33 0.62 -0.27 0.70
Unsupervised(Multilingual)
mBERT 0.74 0.13 0.42 0.37 0.27 0.68 0.66 0.16 0.62 0.50 0.12 0.65 -0.16 0.66
XLMR 0.56 0.57 0.32 0.25 0.17 0.60 0.69 0.04 0.51 0.47 0.13 0.60 -0.07 0.58
Unsupervised(Monolingual)
AfroXLMR 0.45 0.40 0.18 - - 0.30 - 0.07 - - 0.16 - - -
ALBETO - - - - - - 0.62 - - - - - - -
AmRoBERTa - 0.72 - - - - - - - - - - - -
ARBERT - - 0.56 - - - - - - - - - - -
arbBERT - - 0.31 - - - - - - - - - - -
BETO - - - - - - 0.68 - - - - - - -
DziriBERT - - - 0.43 - - - - - - - - -
Indic-BERT - - - - - - - - 0.40 - - 0.46 -0.16 0.41
MARBERT - - 0.29 - - - - - - - - - - -
RoBERTa-BNE - - - - - - 0.66 - - - - - - -
HauRoBERTa - - - - - - - 0.12 - - - - - -
Supervised
LaBSE - 0.85 - 0.60 0.77 0.83 0.70 0.69 - - 0.72 0.88 - 0.82
Crosslingual
LaBSE 0.79 0.84 0.61 0.46 0.40 0.80 0.62 0.62 0.76 0.47 0.57 0.84 -0.05 0.82
Table5:Spearmancorrelationscoresfordifferentfine-tunedmodelsinthethreesettingsthatwedescribe(supervised,
unsupervised,andcrosslingual)inadditiontoasimplelexicaloverlapbaseline(Overlap).
models in Table 5 and additional results using smallerthantheotherlanguages’. Forthelanguage-
BERTScore(Zhang*etal.,2020)formBERTand specific models, the results are highly tied to the
XLMRintheAppendix(seeTable12). language. IncasessuchasAmharicforexample,
AmRoBERTasignificantlyimprovedthescoreby
4.6 Experimentalresults 0.27points,whereasAfroXLMRseemstohurtthe
Table5showstheSpearmancorrelationscoresfor performanceforallAfricanlanguages.
the three setups: supervised, unsupervised, and Forthesupervisedandcrosslingualsettings,we
crosslingualforallfourteenlanguages. Fortheun- reportrelativelyhighcorrelationscoresasopposed
supervisedmodels,wereporttheresultsusingall to the unsupervised ones with scores varying be-
pretrainedmodelsincludingmBERT(Devlinetal., tween0.50and0.83. Asimilartrendastheunsu-
2019) and XLMR (Conneau et al., 2020). Addi- pervisedsetup: high-resourcelanguageshavethe
tionally, we report the Spearman correlation for highestscores,whereasthelow-resourcelanguages
experiments with monolingual language-specific get the lowest scores. The only exception for all
modelsforeachlanguage–modelsthathavebeen setupsisPunjabi,whereweachieveminusresults
trainedineachlanguage. inallsetups.
For the general setup, we note that, except for
5 Conclusion
Amharic, mBERT outperforms XLMR in all lan-
guages by a significant margin. For Amharic, WepresentedSemRel,anewcollectionofsemantic
mBERT’scorrelationscorewiththegoldlabelsis textual relatedness datasets in 14 languages with
0.13,whereasXLMR’sisthreetimeshigherwitha themajoritypredominantlyspokeninAfricaand
0.57correlationscore. Asia and considered low-resource. The sentence
Except for Arabic, all the high-resource lan- pairscontainedinthedatasetsareannotatedbyna-
guageshaveabove-averagecorrelationscores,with tivespeakersandareassociatedwithfine-grained
Spanishachievingthebestresults(0.69/0.60). Sur- relatednessscores. Wereportedthedetailsrelated
prisingly, even though Arabic is a high-resource to the data collection and annotation and empha-
language, the Spearman correlation is relatively sisedthechallengesfacedwhendealingwithlow-
lowincomparisontootherlanguages. Thiscould resourcelanguages.
be due to the size of the Arabic data which is Wepubliclyreleasethedatasetsaswellasotherresources, such as the annotation guidelines and References
fulllabelsfortheresearchcommunityinterestedin
MiguelÁ.GarcíaCumbreras,L.AlfonsoUreñaLópez,
semanticrelatedness,low-resourcelanguages,and and Fernando Martínez Santiago. 2006. BRUJA:
disagreements. QuestionclassificationforSpanish.usingmachine
translationandanEnglishclassifier. InProceedings
6 Limitations oftheWorkshoponMultilingualQuestionAnswering
-MLQA‘06.
Weacknowledgethatthereisnoformaldefinition
MohamedAbdalla,KrishnapriyaVishnubhotla,andSaif
of what constitutes semantic relatedness. Hence,
Mohammad.2023. Whatmakessentencessemanti-
the annotations may be subjective. To mitigate
callyrelated? atextualrelatednessdatasetandem-
the issue we share our guidelines and annotated piricalstudy. InProceedingsofthe17thConference
instancessoresearchersinthecommunitycanex- oftheEuropeanChapteroftheAssociationforCom-
putationalLinguistics, pages782–796, Dubrovnik,
pandonourwork,replicate,andstudythedisagree-
Croatia.AssociationforComputationalLinguistics.
mentsinourdata. Wearealsoawareofthelimited
number of data sources and data variety in some AmineAbdaoui,MohamedBerrimi,MouradOussalah,
low-resourcelanguagesinvolved. Wedonotclaim and Abdelouahab Moussaoui. 2021. Dziribert: A
pre-trainedlanguagemodelfortheAlgeriandialect.
that the datasets released represent all variations
arXivpreprintarXiv:2109.12346.
oftheselanguagesbuttheyremainagoodstarting
pointastheywerecarefullypicked,labelled,and Muhammad Abdul-Mageed, AbdelRahim Elmadany,
andElMoatezBillahNagoudi.2021. ARBERT&
processedbynativespeakers.
MARBERT:DeepbidirectionaltransformersforAra-
Although our collection is comprised of multi-
bic. InProceedingsofthe59thAnnualMeetingofthe
ple datasets, the size of the data is limited, thus Association for Computational Linguistics and the
it cannot be the only source used for tasks that 11thInternationalJointConferenceonNaturalLan-
require a large amount of data such as language guageProcessing(Volume1: LongPapers),pages
7088–7105,Online.AssociationforComputational
identification.
Linguistics.
7 EthicalConsiderations
IdrisAbdulmuminandBashirShehuGaladanci.2019.
hauwe:Hausawordsembeddingfornaturallanguage
Alltheannotatorsinvolvedinthisstudywereeither
processing. In20192ndInternationalConferenceof
volunteers or were paid more than the minimum theIEEENigeriaComputerChapter(NigeriaCom-
wage per hour. Further, data that was previously putConf).IEEE.
availableandfurtherannotatedwaspubliclyavail-
KarimaAbidi,MohamedAmineMenacer,andKamel
ableandiscitedinourpaper.
Smaili.2017. CALYOU:AcomparablespokenAlge-
SimilarlytoAbdallaetal.(2023),weacknowl- riancorpusharvestedfromYouTube. In18thAnnual
edgeallthepossiblesocio-culturalbiasesthatcan ConferenceoftheInternationalCommunicationAs-
sociation(Interspeech).
comewithourdata,duetothedatasourcesorthe
annotationprocess. Whenbuildingourdatasets,we David Adelani, Graham Neubig, Sebastian Ruder,
didavoidinstanceswithinappropriateoroffensive ShrutiRijhwani,MichaelBeukman,ChesterPalen-
utterances but we might have missed some. Our Michel,ConstantineLignos,JesujobaAlabi,Sham-
suddeen Muhammad, Peter Nabende, Cheikh
goalwastoidentifycommonperceptionsofseman-
M. Bamba Dione, Andiswa Bukula, Rooweither
ticrelatednessbynativespeakersandourlabelsfor Mabuya,BonaventureF.P.Dossou,BlessingSibanda,
eachlanguagearenotmeanttobestandardisedfor HappyBuzaaba,JonathanMukiibi,GodsonKalipe,
any given language. Note that we build datasets Derguene Mbaye, Amelia Taylor, Fatoumata Ka-
bore,ChrisChinenyeEmezue,AnuoluwapoAremu,
forlow-resourcelanguagesbutwedonotclaimin
Perez Ogayo, Catherine Gitau, Edwin Munkoh-
anywaythatthesearefullyrepresentativeoftheir
Buabeng, Victoire Memdjokam Koagne, Allah-
usage. seraAugusteTapo,TebogoMacucwa,VukosiMari-
vate, Mboning Tchiaze Elvis, Tajuddeen Gwad-
Acknowledgements abe, Tosin Adewumi, Orevaoghene Ahia, Joyce
Nakatumba-Nabende, Neo Lerato Mokono, Ig-
Wethankourannotatorsforlabellingthedataand natiusEzeani,ChiamakaChukwuneke,Mofetoluwa
forprovidinginsightfulcomments. Oluwaseun Adeyemi, Gilles Quentin Hacheme,
Idris Abdulmumin, Odunayo Ogundepo, Oreen
ThankstoDimosthenisAntypas,JoanneBoisson
Yousuf,TatianaMoteu,andDietrichKlakow.2022.
andHsuvasBorkakotyforthehelpfulfeedback.
MasakhaNER 2.0: Africa-centric transfer learning
for named entity recognition. In Proceedings ofthe2022ConferenceonEmpiricalMethodsinNat- multilingualadaptivefine-tuning. InProceedingsof
uralLanguageProcessing,pages4488–4508,Abu the29thInternationalConferenceonComputational
Dhabi,UnitedArabEmirates.AssociationforCom- Linguistics,pages4336–4349,Gyeongju,Republic
putationalLinguistics. ofKorea.InternationalCommitteeonComputational
Linguistics.
EnekoAgirre,CarmenBanea,ClaireCardie,DanielCer,
Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, RahulAralikatte,ZilingCheng,SumanthDoddapaneni,
InigoLopez-Gazpio, MontseMaritxalar, RadaMi- and Jackie Chi Kit Cheung. 2023. Varta: A large-
halcea,etal.2015. SemEval-2015task2: Semantic scaleheadline-generationdatasetforIndiclanguages.
textualsimilarity,English,Spanishandpilotoninter- In Findings of the Association for Computational
pretability. InProceedingsofthe9thinternational Linguistics: ACL2023,pages3468–3492,Toronto,
workshoponsemanticevaluation(SemEval2015), Canada.AssociationforComputationalLinguistics.
pages252–263,Denver,Colorado.Associationfor
VladimirAraujo,AndrésCarvallo,SouvikKundu,José
ComputationalLinguistic.
Cañete,MarceloMendoza,RobertE.Mercer,Felipe
EnekoAgirre,CarmenBanea,ClaireCardie,DanielCer, Bravo-Marquez,Marie-FrancineMoens,andAlvaro
Mona Diab, Aitor Gonzalez-Agirre, Weiwei Guo, Soto.2022. EvaluationbenchmarksforSpanishsen-
RadaMihalcea,GermanRigau,andJanyceWiebe. tence representations. In Proceedings of the Thir-
2014. SemEval-2014task10: Multilingualsemantic teenthLanguageResourcesandEvaluationConfer-
textualsimilarity. InProceedingsofthe8thinterna- ence,pages6024–6034,Marseille,France.European
tional workshop on semantic evaluation (SemEval LanguageResourcesAssociation.
2014),pages81–91,Dublin,Ireland.Associationfor
SamuelR.Bowman,GaborAngeli,ChristopherPotts,
ComputationalLinguistics.
and Christopher D. Manning. 2015. A large anno-
tatedcorpusforlearningnaturallanguageinference.
EnekoAgirre,CarmenBanea,DanielCer,MonaDiab,
In Proceedings of the 2015 Conference on Empiri-
Aitor Gonzalez Agirre, Rada Mihalcea, German
calMethodsinNaturalLanguageProcessing,pages
RigauClaramunt,andJanyceWiebe.2016. SemEval-
632–642,Lisbon,Portugal.AssociationforCompu-
2016Task1: Semantictextualsimilarity,monolin-
tationalLinguistics.
gualandcross-lingualevaluation. InSemEval-2016.
10th International Workshop on Semantic Evalua-
JoséCañete,SebastianDonoso,FelipeBravo-Marquez,
tion;2016Jun16-17;SanDiego,CA.Stroudsburg
Andrés Carvallo, and Vladimir Araujo. 2022. AL-
(PA):ACL;2016.p.497-511.ACL(Associationfor
BETO and DistilBETO: Lightweight Spanish lan-
ComputationalLinguistics).
guagemodels. InProceedingsoftheThirteenthLan-
guageResourcesandEvaluationConference,pages
Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
4291–4298,Marseille,France.EuropeanLanguage
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A
ResourcesAssociation.
pilotonsemantictextualsimilarity. In*SEM2012:
TheFirstJointConferenceonLexicalandCompu- JoséCañete,GabrielChaperon,RodrigoFuentes,Jou-
tational Semantics–Volume 1: Proceedings of the HuiHo,HojinKang,andJorgePérez.2020. Spanish
MainConferenceandtheSharedTask,andVolume pre-trained BERT model and evaluation data. In
2: ProceedingsoftheSixthInternationalWorkshop PML4DCatICLR2020.
onSemanticEvaluation(SemEval2012),pages385–
393. Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-
Gazpio, and Lucia Specia. 2017a. Semeval-2017
EnekoAgirre,DanielCer,MonaDiab,AitorGonzalez- task1: Semantictextualsimilarity-multilingualand
Agirre,andWeiweiGuo.2013. *SEM2013shared cross-lingual focused evaluation. arXiv preprint
task: Semantic textual similarity. In Second Joint arXiv:1708.00055.
Conference on Lexical and Computational Seman-
tics (*SEM), Volume 1: Proceedings of the Main Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-
ConferenceandtheSharedTask: SemanticTextual Gazpio, and Lucia Specia. 2017b. SemEval-2017
Similarity,pages32–43. task1: Semantictextualsimilaritymultilingualand
crosslingual focused evaluation. In Proceedings
MahtabAhmed,ChahnaDixit,RobertEMercer,Atif of the 11th International Workshop on Semantic
Khan,MuhammadRifayatSamee,andFelipeUrra. Evaluation(SemEval-2017),pages1–14,Vancouver,
2020. Multilingual corpus creation for multilin- Canada.AssociationforComputationalLinguistics.
gualsemanticsimilaritytask. InProceedingsofthe
TwelfthLanguageResourcesandEvaluationConfer- AlexisConneau,KartikayKhandelwal,NamanGoyal,
ence,pages4190–4196. Vishrav Chaudhary, Guillaume Wenzek, Francisco
Guzmán, Edouard Grave, Myle Ott, Luke Zettle-
Ahmed Hashim Al-Dulaimi. 2022. Ultimate Arabic moyer,andVeselinStoyanov.2020. Unsupervised
NewsDataset. cross-lingualrepresentationlearningatscale. InPro-
ceedings of the 58th Annual Meeting of the Asso-
Jesujoba O. Alabi, David Ifeoluwa Adelani, Marius ciationforComputationalLinguistics,pages8440–
Mosbach,andDietrichKlakow.2022. Adaptingpre- 8451, Online. Association for Computational Lin-
trained language models to African languages via guistics.LeeJCronbach.1951. Coefficientalphaandtheinternal Svetlana Kiritchenko and Saif M Mohammad. 2017.
structureoftests. psychometrika,16(3):297–334. Best-worstscalingmorereliablethanratingscales:
Acasestudyonsentimentintensityannotation. arXiv
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and preprintarXiv:1712.01765.
Kristina Toutanova. 2019. BERT: Pre-training of
deepbidirectionaltransformersforlanguageunder- GFredericKuderandMarionWRichardson.1937. The
standing. InProceedingsofthe2019Conferenceof theoryoftheestimationoftestreliability. Psychome-
theNorthAmericanChapteroftheAssociationfor trika,2(3):151–160.
ComputationalLinguistics: HumanLanguageTech-
KemalKurniawanandSamuelLouvan.2018. Indosum:
nologies,Volume1(LongandShortPapers),pages
AnewbenchmarkdatasetforIndonesiantextsumma-
4171–4186,Minneapolis,Minnesota.Associationfor
rization. In2018InternationalConferenceonAsian
ComputationalLinguistics.
LanguageProcessing(IALP),pages215–220.IEEE.
AsierGutiérrezFandiño,JordiArmengolEstapé,Marc Hugo Laurençon, Lucile Saulnier, Thomas Wang,
Pàmies,JoanLlopPalao,JoaquinSilveiraOcampo, ChristopherAkiki,AlbertVillanovadelMoral,Teven
CasimiroPioCarrino,CarmeArmentanoOller,Car- LeScao, LeandroVonWerra, ChenghaoMou, Ed-
losRodriguezPenagos,AitorGonzalezAgirre,and uardoGonzálezPonferrada,HuuNguyen,etal.2022.
MartaVillegas.2022. Maria: Spanishlanguagemod- Thebigsciencerootscorpus: A1.6tbcompositemul-
els. ProcesamientodelLenguajeNatural,68. tilingual dataset. Advances in Neural Information
ProcessingSystems,35:31809–31826.
Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen
Arivazhagan, and Wei Wang. 2020. Language- Jordan J Louviere and George G Woodworth. 1991.
agnosticBERTsentenceembedding. arXivpreprint Best-worstscaling:Amodelforthelargestdifference
arXiv:2007.01852. judgments. Technicalreport,Workingpaper.
Lokesh Madasu, Gopichand Kanumolu, Nirmal
CharlesAFerguson.1959. Diglossia. word,15(2):325–
Surange,andManishShrivastava.2023. Mukhyansh:
340.
A headline generation dataset for Indic languages.
InProceedingsofthe37thPacificAsiaConference
Terry N Flynn and Anthony AJ Marley. 2014. Best-
onLanguage,InformationandComputation,pages
worst scaling: Theory and methods. Ph.D. thesis,
620–634,HongKong,China.AssociationforCom-
EdwardElgarWorcester,UK.
putationalLinguistics.
Goran Glavaš, Marc Franco-Salvador, Simone P
MarcoMarelli,StefanoMenini,MarcoBaroni,Luisa
Ponzetto,andPaoloRosso.2018. Aresource-light
Bentivogli,RaffaellaBernardi,RobertoZamparelli,
methodforcross-lingualsemantictextualsimilarity.
etal.2014. ASICKcurefortheevaluationofcom-
Knowledge-basedsystems,143:1–9.
positional distributional semantic models. In Pro-
ceedingsoftheEleventhInternationalConferenceon
RuqaiyaHasanandMichaelAKHalliday.1976. Cohe-
LanguageResourcesandEvaluation(LREC2014),
sioninEnglish. London,1976;MartinJR.
pages216–223.Reykjavik.
TahmidHasan,AbhikBhattacharjee,MdSaifulIslam, Karima Meftouh, Salima Harrat, Salma Jamoussi,
KaziSamin,Yuan-FangLi,Yong-BinKang,MSohel MouradAbbas,andKamelSmaili.2015. Machine
Rahman,andRifatShahriyar.2021. Xl-sum: Large- translationexperimentsonPADIC:AparallelArabic
scalemultilingualabstractivesummarizationfor44 dialect corpus. In Proceedings of the 29th Pacific
languages. arXivpreprintarXiv:2106.13822. Asiaconferenceonlanguage,informationandcom-
putation,pages26–34.
JavierHuertas-Tato,AlejandroMartín,andDavidCa-
macho.2021. Silt: Efficienttransformertrainingfor GeorgeA.Miller.1994. WordNet: Alexicaldatabase
inter-lingualinference. forEnglish. InHumanLanguageTechnology: Pro-
ceedings of a Workshop held at Plainsboro, New
AbderrahmaneIssamandKhalilMrini.2022. Goud.ma: Jersey,March8-11,1994.
anewsarticledatasetforsummarizationinMoroc-
GeorgeAMillerandWalterGCharles.1991. Contex-
can Darija. In 3rd Workshop on African Natural
tualcorrelatesofsemanticsimilarity. Languageand
LanguageProcessing.
cognitiveprocesses,6(1):1–28.
Divyanshu Kakwani, Anoop Kunchukuttan, Satish
Saif M Mohammad, Parinaz Sobhani, and Svetlana
Golla,GokulN.C.,AvikBhattacharyya,MiteshM.
Kiritchenko.2017. Stanceandsentimentintweets.
Khapra,andPratyushKumar.2020. IndicNLPSuite: ACM Transactions on Internet Technology (TOIT),
Monolingual corpora, evaluation benchmarks and
17(3):1–23.
pre-trainedmultilinguallanguagemodelsforIndian
languages. InFindingsoftheAssociationforCom- JaneMorrisandGraemeHirst.1991. Lexicalcohesion
putationalLinguistics: EMNLP2020,pages4948– computedbythesauralrelationsasanindicatorofthe
4961, Online. Association for Computational Lin- structureoftext. Computationallinguistics,17(1):21–
guistics. 48.RubungoAndreNiyongabo,QuHong,JuliaKreutzer, Bar, Matt Malone, Thierry Poibeau, et al. 2020.
and Li Huang. 2020. KINNEWS and KIRNEWS: Multi-simlex: A large-scale evaluation of multi-
Benchmarking cross-lingual text classification for lingualandcrosslinguallexicalsemanticsimilarity.
Kinyarwanda and Kirundi. In Proceedings of the ComputationalLinguistics,46(4):847–897.
28thInternationalConferenceonComputationalLin-
guistics, pages 5507–5521, Barcelona, Spain (On- Mengting Wan and Julian McAuley. 2018. Item rec-
line).InternationalCommitteeonComputationalLin- ommendation on monotonic behavior chains. In
guistics. Proceedingsofthe12thACMconferenceonrecom-
mendersystems,pages86–94.
BryanK.Orme.2009. Maxdiffanalysis: Simplecount-
ing,individual-levellogit,andhb.
BinWang,C.-C.JayKuo,andHaizhouLi.2022. Just
rank: Rethinkingevaluationwithwordandsentence
PedroJavierOrtizSuárez,LaurentRomary,andBenoît
similarities. InProceedingsofthe60thAnnualMeet-
Sagot.2020. Amonolingualapproachtocontextual-
ingoftheAssociationforComputationalLinguistics
izedwordembeddingsformid-resourcelanguages.
(Volume1: LongPapers),pages6060–6077,Dublin,
InProceedingsofthe58thAnnualMeetingoftheAs-
Ireland.AssociationforComputationalLinguistics.
sociationforComputationalLinguistics,pages1703–
1714,Online.AssociationforComputationalLinguis-
tics. BinWangandHaizhouLi.2022. Relationalsentence
embedding for flexible semantic matching. arXiv
RajatPandit,SaptarshiSengupta,SudipKumarNaskar, preprintarXiv:2212.08802.
Niladri Sekhar Dash, and Mohini Mohan Sardar.
2019. Improving semantic similarity with cross- JohnWietingandKevinGimpel.2017. Paranmt-50m:
lingual resources: A study in Bangla—a low re- Pushingthelimitsofparaphrasticsentenceembed-
sourcedlanguage. InInformatics,volume6,page19. dingswithmillionsofmachinetranslations. arXiv
MDPI. preprintarXiv:1711.05732.
SudhaRaoandJoelTetreault.2018. Dearsirormadam,
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
mayIintroducetheGYAFCdataset: Corpus,bench-
Chaumond,ClementDelangue,AnthonyMoi,Pier-
marks and metrics for formality style transfer. In
ricCistac,TimRault,RemiLouf,MorganFuntow-
Proceedings of the 2018 Conference of the North
icz,JoeDavison,SamShleifer,PatrickvonPlaten,
AmericanChapteroftheAssociationforComputa-
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
tionalLinguistics: HumanLanguageTechnologies,
Teven Le Scao, Sylvain Gugger, Mariama Drame,
Volume 1 (Long Papers), pages 129–140, New Or-
QuentinLhoest,andAlexanderRush.2020. Trans-
leans,Louisiana.AssociationforComputationalLin-
formers:State-of-the-artnaturallanguageprocessing.
guistics.
InProceedingsofthe2020ConferenceonEmpirical
Methods in Natural Language Processing: System
Nils Reimers and Iryna Gurevych. 2019. Sentence-
Demonstrations,pages38–45,Online.Association
BERT:SentenceembeddingsusingsiameseBERT-
forComputationalLinguistics.
networks. InProceedingsofthe2019Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing.
AssociationforComputationalLinguistics. Seid Muhie Yimam, Abinew Ali Ayele, Gopalakrish-
nan Venkatesh, Ibrahim Gashaw, and Chris Bie-
Ali Safaya, Moutasem Abdullatif, and Deniz Yuret. mann.2021. Introducingvarioussemanticmodels
2020. KUISAILatSemEval-2020task12: BERT- forAmharic: Experimentationandevaluationwith
CNNforoffensivespeechidentificationinsocialme- multipletasksanddatasets. FutureInternet,13(11).
dia. InProceedingsoftheFourteenthWorkshopon
SemanticEvaluation,pages2054–2059,Barcelona YunjinYum,JeongMoonLee,MoonJoungJang,Yoo-
(online).InternationalCommitteeforComputational joong Kim, Jong-Ho Kim, Seongtae Kim, Unsub
Linguistics. Shin, Sanghoun Song, and Hyung Joon Joo. 2021.
A word pair dataset for semantic similarity and re-
Ken Nabila Setya and Rahmad Mahendra. 2018.
latednessinKoreanmedicalvocabulary: Reference
Semi-supervised textual entailment on Indonesian
developmentandvalidation. JMIRMedicalInformat-
wikipediadata. InInternationalConferenceonCom-
ics,9(6):e29667.
putationalLinguisticsandIntelligentTextProcessing,
pages416–427.Springer.
TianyiZhang*,VarshaKishore*,FelixWu*,KilianQ.
Weinberger,andYoavArtzi.2020. Bertscore: Eval-
Xin Tang, Shanbo Cheng, Loc Do, Zhiyu Min, Feng
uatingtextgenerationwithBERT. InInternational
Ji,HengYu,JiZhang,andHaiqinChen.2018. Im-
ConferenceonLearningRepresentations.
provingmultilingualsemantictextualsimilaritywith
sharedsentenceencoderforlow-resourcelanguages.
arXivpreprintarXiv:1810.08740. ChengqingZong.2015. ImprovingSMTbymodelfil-
teringandphraseembedding. InProceedingsofthe
Ivan Vulic´, Simon Baker, Edoardo Maria Ponti, Ulla 12th International Workshop on Spoken Language
Petti,IraLeviant,KellyWing,OlgaMajewska,Eden Translation: Keynotes,DaNang,Vietnam.Appendix A.3.1 A1
A AnnotationGuidelines ThemostrelatedpairisPair3becausebothsen-
tencesaretalkingaboutagroupsitting/restingin
A.1 SummaryInstructions
grass.
Youwillbegivenfoursentencepairs(i.e.,4pairs The least related is Pair 4 because Pair 4 sen-
oftheform[sentenceA,sentenceB]).Yourtaskis tencesarecompletelyunrelated,whereastheother
to judge the relatedness of each pair (sentence A pairshavesomerelatedness.
andsentenceB)andtellus:
A.3.2 Note(A1)
• the sentence pair that is the MOST related
(i.e.,sentenceAisclosestinmeaningtosen- Pair1sentencesaresomewhatrelated,astheytalk
tenceB). about Narnia/characters in that world (Aslan and
BreearecharactersinNarnia). However,thecon-
• thesentencepairthatistheLEASTrelated
tent of this sentence pair is not as related as Pair
(i.e.,sentenceAisfarthestinmeaningtosen-
3.
tenceB).
Pair2sentencesarebothtalkingaboutromantic
Sentencepairscanberelatedinmanyways.
relationships.
I.e., sentence A and sentence B can be related in
differentways. Thefirstpairofsentencesarethe
A.4 Examples(Q2)
most related than the second one below. Often,
Which of the four sentence pairs in Table 9 is
sentencepairsthataremorespecificinwhatthey
MOST RELATED? Which pair is LEAST RE-
share tend to be more related than sentence pairs
LATED?
thatareonlylooselyaboutthesametopic.
If a sentence has more than one interpretation,
A.4.1 A2
considerthatmeaningwhichisclosesttothemean-
ing of the other sentence in the pair. If both sen- The most related pair is Pair 4. Both sentences
tenceshavemultiplemeanings,thenconsiderthose aretalkingaboutthesamecityandmentionthatit
meaningsthatareclosesttoeachother. isonthebankofriverSarayu. Theleastrelated
If in the given set of four pairs, two (or more) pairisPair2becausethesentencesarecompletely
sentence pairs are equally related to each other unrelated.
andtheyarealsothemostrelatedpairs,thenselect
either one of them as the most related (i.e., ran- A.4.2 Note(A2)
domly). Similarly,iftwo(ormore)equallyrelated
Pair3sentencesbothrefertoatleastonewoman
pairs are also the least related pairs, then select
outside.
eitheroneofthemastheleastrelated. (SeeTable
Pair 1 sentences refer to kids or kid-related
2.)
things(makingthemslightlycloseinmeaning).
Youcannotselectthesamesentencepairfor
bothcategories. A.5 Examples(Q3)
Trynottooverthinktheanswer. Letyourinstinct
Which of the four sentence pairs in Table 10 is
guideyou.
MOST RELATED? Which pair is LEAST RE-
A.2 Notes LATED?
Sentencepairscanberelatedinmanyways. Con-
A.5.1 A3
sider the entire meaning of the sentences before
selectingthemostrelated. Thesentencesincluded The most related pair is Pair 4. Both sentences
inthistaskmaycontainfoullanguage,thoughwe areparaphrasesofeachother. (Pair1andPair2are
haveattemptedtolimitthis. quite related but not as exact paraphrases as Pair
4.)
A.3 Examples(Q1)
TheleastrelatedpairisPair3. Pair3sentences
Which of the four sentence pairs in Table 8 is aresomewhatrelatedastheytalkabouthousefur-
MOST RELATED? Which pair is LEAST RE- nishings. However,theyarestilllessrelatedthan
LATED? alltheotherpairs.MOSTRelatedPair S1:Theboyenjoyedreadingunderthelemontree
S2:Thereisalemontreenexttothehouse
LEASTrelatedPair S1:Theboyenjoyedreadingunderthelemontree
S2:Theboywasanexcellentfootballplayer
Table6: ExampleintheGuidelines. Examplesoftwopairsofsentenceswithdifferentdegreesofrelatednessfrom
Abdallaetal.(2023).
Pair1 S1:Theboyenjoyedreadingunderthelemontree
S2:Ihaveagreenhat
Pair2 S1:Theboyenjoyedreadingunderthelemontree
S2:Shewasanexcellentfootballplayer
Table7: ExampleintheGuidelines. Examplesoftwopairsofsentencesthathavesimilardegreesofrelatedness
whereonecanchooserandomlythemostvs. leastrelatedpairs(i.e.,eitherPair1orPair2).
Pair1 S1:MypersonalfavoritesfromNarniaweretheconversationsbetweenAslanandBree.
S2:ThismarksmyprogressthroughtheChronicles,pickedupafterreadingTheNarniaCodeandPlanetNarnia.
Pair2 S1:whywon’tsheaskmeout?
S2:andafterallthatyouwonthavetoworryaboutgettingagirltolikeyou.
Pair3 S1:Agroupofpeoplearesittingonthegrassoutsideofarusticbuilding.
S2:Groupsittingonagrassyhillresting.
Pair4 S1:Ifyouchangemeback,Iwillfeedeachoneofyoursnakesalargemouse!
S2:Offerpeoplewhojoincashandcoupons.
Table8: Q1ExampleintheGuidelines.
Pair1 S1:Thatandakidsmeal.
S2:Mytwokids,ages5and3!
Pair2 S1:Thespines,whichmaybeupto50mmlong,aremodifiedhairs,mostlymadeofkeratin.
S2:ThesimplestshapeisthelongopeningwithapointedarchknowninEnglandasthelancet.
Pair3 S1:Awomanwearingawhiteshirtandaredheadbandissittingoutside.
S2:Twowomenstandoutsidealibrary.
Pair4 S1:Ayodhya,capitalofKingRamaismentionedonthebanksofSarayuriver.
S2:RamayanamentionsthatcityofAyodhyawassituatedonthebankofSarayuriver.
Table9: Q2ExampleintheGuidelines.
Pair1 S1:IBMhasnotshifteditsfocusfrommainframestocompetewithWindows
S2:In3years,IBMhasnotbeeninterestedinthePC.
Pair2 S1:IwantedtoseethescenewhereQuinntoldthebrotherhoodhewasinlovewithBlay.
S2:IalsowouldhavelikedtoseethescenewhereQhuinnasksBlay’sdadforpermissiontoproposetoBlay.
Pair3 S1:Jeremydesperatelyneedsastablehome.
S2:Furnishingswereananglebed,astool,andachamberpotonthedirtfloor.
Pair4 S1:That’sdifficult.They’rebothgreat
S2:that’sreallyhardtheyarebothgreat!
Table10: Q3ExampleintheGuidelines.
A.5.2 Note(A3) andtheirromanticsituation.
Pair1sentencesbothrefertoIBMandtheirbusi-
nessstrategy. Weconsiderthistobemorerelated
thanPair3becauseit’smorespecificinthedetails
theyshare.
Pair2sentencestalkaboutthesamecharactersB Pre-trainedmodelsused
Language mBERT XLMR
Welistdownthevariouspre-trainedHuggingFace afr 0.77 0.76
modelsusedforourexperimentsbelow: amh 0.12 0.69
arb 0.40 0.42
1. mBERT
arq 0.28 0.32
ary 0.53 0.50
2. XLMR
eng 0.71 0.74
3. AfroXLMR esp 0.67 0.68
hau 0.32 0.31
4. ALBETO
hin 0.64 0.63
ind 0.54 0.54
5. AmRoBERTa
kin 0.25 0.30
6. ARBERT mar 0.78 0.75
pan -0.26 -0.20
7. arbBERT
tel 0.77 0.78
8. BETO
Table 12: Spearman correlation of the BERTScore
9. DziriBERT (Zhang*etal.,2020)withmBERTandXLMRonthe
differentlanguages.
10. Indic-BERT
11. MARBERT
12. RoBERTa-BNE
13. HauRoBERTa
14. LaBSE
Language Base Finetuned
afr 0.76 0.79
amh 0.79 0.85
arb 0.55 0.62
arq 0.40 0.60
ary 0.38 0.77
eng 0.82 0.83
esp 0.65 0.70
hau 0.48 0.69
hin 0.71 0.77
ind 0.53 0.50
kin 0.45 0.72
mar 0.82 0.88
pan -0.11 -0.05
tel 0.80 0.82
Table11: SpearmancorrelationscoresonLaBSEmod-
elswithandwithoutfurtherfine-tuningonourtraining
data(Baseandfine-tuned,respectively).Lang. Sentence 1 Sentence 2 Score
tel ఇపప్టికేధోనీటెసుట్ కిర్కెట్కుగుడ్బౖెచెపిప్నవిషయం అంతకు ముందు జరిగిన మరో రోడుడ్ పర్మాదంలో 0.02
తెలిసిందే� ఏడుగురుమరణించగా���మందిగాయపడాడ్రు�
Gloss: It is already known that Dhoni Gloss: Sevenpeoplewerekilledand12
has said goodbye to Test cricket. injuredinanotherroadaccidentearlier.
afr My eerste stukkie advies is dat jy real- Dit bring tot n einde die maanverken- 0.19
isties moet wees oor die afstand wat jy ningsprogramvandieVerenigdeState..
wil hengel.
Gloss: My first piece of advice is to be Gloss: This brings to an end the lu-
realisticaboutthedistanceyouwantto nar exploration program of the United
fish. States.
esp Costo monetario para mantener el Todavía nos quedan más de 200.000$ 0.27
microondas por $6. porrecaudardesuscriptoresydonantes
como usted.
Gloss: Monetary cost to maintain the Gloss: We still have over $200,000 left
microwave is $6. to raise from subscribers and donors
like you.
mar ठाकरे सरकारच्या मंत्िरमंडळात 25 कॅिबनेट त्यामुळे गुढी पाडवा मेळाव्यामध्ये राज ठाकरे 0.42
मंत्रीअसणारआहेत. कायबोलणारयाकडेसर्वांचेलक्षलागूनरािहले
आहे.
Gloss: Thackeray government will Gloss: Therefore, everyone’s attention
have 25 cabinet ministers. is on what Raj Thackeray will say in
the Gudi Padwa gathering..
arq مهيﻑﺭﻉﺕينوﻙﺕوﻉاﺕىنغلايﻑمهلوقيتايﺏﺃلاﺩﺡاونياﻙ يلاﺥحوﺭلانﻡاينﺩلايﻑشاهزاﻡيللا 0.50
Gloss: There’s a couplet in one of his Gloss: "He who did not feel joy in this
songs that you may know. world is empty-spirited/has no soul" [a
couplet]
pan ਪੰਜਾਬਤੋਂਦੂਜੀਵਾਰਿਵਧਾਇਕਬਣੇਅਮਨਅਰੋੜਾਦਾ ਇਨ੍ਹਾਂ ਿਵੱਚ ਦੂਜੀ ਵਾਰ ਿਵਧਾਇਕ ਬਣੇ ਪੋ੍ਰ. 0.56
ਮੰਤਰੀਬਣਨਾਤੈਅਹੈ. ਬਲਿਜੰਦਰ ਕੌਰ ਜਾਂ ਸਰਵਜੀਤ ਮਾਣੂੰਕੇ ਨੰੂ ਵੀ ਮੰਤਰੀ
ਬਣਾਇਆਜਾਸਕਦਾਹੈ
Gloss: Aman Arora, who became Gloss: Amongstthem, Prof. Baljinder
MLA from Punjab for the second time, Kaur or Sarawjeet Maanooke could be
is set to be a minister now. made MLAs for the second time.
arb يﺭظنيﻑوداﺹﺕقﺍلاخيراﺕنﻉﺓﺡﻡلىلإمﻙﺏلقﺕنانﺁلا ﺭﺏﻙأ نﻡ ناﺕيﺡلا ﺩيﺹ ناﻙ ٠٥٨١ ماﻉ يلاوﺡ 0.62
.ةﺩيﻑﻡنوﻙﺕﺩق ةﺩﺡﺕﻡلاتايﺍلولايﻑتاﻉانﺹلا
Gloss: Now, I will take you to a Gloss: Around 1850, whaling was one
glimpse of the history of economics, of the largest industries in the United
which in my opinion may be useful. States.
hin देशमेंकोरोनावायरससेमौतकाआंकडा़ 100के देशमेंकोरोनावायरसकाकहरतेजीसेबढत़ ाजा 0.72
पारपहुंचा,िपछले12घंटे में26कीगईजान. रहाहै।
Gloss: Death toll due to Corona virus Gloss: The havoc of Corona virus is
in the country crossed 100, 26 people increasing rapidly in the country.
lost their lives in the last 12 hours.
Continued on next pageTable 13 – continued from previous page
Lang. Sentence 1 Sentence 2 Score
kin Duhugukire kwandika neza Ikin- Duhugukire kwandika neza Ikin- 0.75
yarwanda Mu myandikire yIkin- yarwanda (igice cya gatatu) Mu
yarwanda hari amakosa akunda guko- myandikire yIkinyarwanda, hari am-
rwa ashingiye ku ifatana nitandukana agambo afatana nandi atandukana.
ryamagambo.
Gloss: Let’s learn to write well in Gloss: Let’s practice writing well
Ikinyarwanda In writing Ikinyarwanda in Ikinyarwanda (part three) In Ikin-
there are mistakes that are often made yarwanda writing, there are words that
basedontheconnectionandseparation go together and others that are differ-
of words. ent.
ary ٣٧ـﺏ اﺩﺏﺕ يداغ ةراﺭﺡلا ..ناضﻡﺭل موﻙﺱار وﺩجو اﺩﺏﺕ يداغ ةراﺭﺡلا ..لﻉشﺕ يهو ناضﻡر جﺭﺥ ﺭيغ 0.75
قطانﻡلاداهﻑﺓجرد قطانﻡلاداهﻑﺓجرد٤٠ـللﺹوﺕيداغو
Gloss: Prepare yourselves for Ra- Gloss: Since Ramadan, the weather
madan,thetemperaturewillstartat37 has been very hot. Temperatures are
degrees in these regions. rising and they will reach 40 degrees in
these regions.
ind Pendidikan Desa Pusaka memiliki 4 Pendidikan Desa Serumpun Buluh 0.83
sekolah. memiliki 4 sekolah.
Gloss: Pusaka Village Education has Gloss: Serumpun Buluh Village Edu-
4 schools. cation has 4 schools.
amh እኛንከዚህጉዳይጋርየምንገናኝበትቅንጣትታ እኛንቅንጣትታህልከዚህጉዳይጋየሚያገናኘን 0.89
ክልግንኙነትየለም ነገርየለም
Gloss: Thereisnothingofaconnection Gloss: There is nothing that concern
that concern us with this issue. us with this issue.
hau Haka ya furta a cikin jawabin sa na Yayiwannanikirarinneacikinjawabin 0.94
murnar cikar Najeriya shekaru 61 da sa na murnar cikar Najeriya 61 da
samun yanci. samun yanci a ranar Jumaa.
Gloss: That is what he said in the Gloss: He made this assertion in his
speech for celebrating Nigeria’s 61 in- speech celebrating Nigeria’s 61 inde-
dependence day celebration. pendence day celebration on Friday.
eng I’vebeensearchingtheentireabbeyfor I’m looking for you all over the abbey. 1.00
you.
Table13: ExamplesofSemReldatainstancesandtheirtranslations