Improving Generalization in Semantic Parsing
by Increasing Natural Language Variation
IrinaSaparina and MirellaLapata
InstituteforLanguage,CognitionandComputation
SchoolofInformatics,UniversityofEdinburgh
10CrichtonStreet,EdinburghEH89AB
i.saparina@sms.ed.ac.uk mlap@inf.ed.ac.uk
Abstract queries,anddatabasesfromvariousdomains. Im-
portantly,itexemplifiesacross-domaingeneraliza-
Text-to-SQL semantic parsing has made sig- tionsetting,i.e.,modelstrainedonSpiderareex-
nificantprogressinrecentyears,withvarious
pectedtoparsenaturallanguagequestionsforany
modelsdemonstratingimpressiveperformance
givendatabase,eveninpreviouslyunseendomains.
on the challenging Spider benchmark. How-
Inpractice,modelstrainedonSpiderdegradesig-
ever,ithasalsobeenshownthatthesemodels
nificantlywhentestedondifferentdatabasesfrom
often struggle to generalize even when faced
with small perturbations of previously (accu- other datasets, for example, on real-world data
rately)parsedexpressions. Thisismainlydue fromKaggleandStackExchangewebsites(Suhr
to the linguistic form of questions in Spider etal.,2020;Leeetal.,2021;Hazoometal.,2021).
which are overly specific, unnatural, and dis- ThelinguisticcompositionofquestionsinSpider
play limited variation. In this work, we use
contributes to this performance gap. Unlike real-
data augmentation to enhance the robustness
world applications where user questions may be
oftext-to-SQLparsersagainstnaturallanguage
concise,ambiguous,andnecessitatecommonsense
variations. Existingapproachesgenerateques-
tion reformulations either via models trained reasoningordomain-specificknowledge,questions
onSpideroronlyintroducelocalchanges. In in Spider are often overly explicit, directly men-
contrast,weleveragethecapabilitiesoflarge tioningdatabaseentitiesevenwhensuchinforma-
languagemodelstogeneratemorerealisticand tion is unnecessary for inferring the underlying
diversequestions. Usingonlyafewprompts,
intent. AnexampleisshowninFigure1,thefirst
weachieveatwo-foldincreaseinthenumberof
questionincludesredundantdetails(e.g.,customer,
questionsinSpider.Trainingonthisaugmented
first name, last name) which serve as references
dataset yields substantial improvements on a
todatabasesentities. Omittingthesedetailswould
rangeofevaluationsets,includingrobustness
benchmarksandout-of-domaindata.1 notchangethemeaningofthequestionbutrather
makeitmorecolloquial. Duetothelimiteddiver-
1 Introduction sity of questions, Spider falls short in providing
enoughexamplesforlearningessentialskillssuch
Semantic parsing is the task of mapping natural
as grounding and reasoning. As a result, models
language utterances to machine-interpretable ex-
tendtooverfittoSpider-stylequestions,andeven
pressionssuchasSQLqueriesorlogicalforms. It
minorperturbationsinhowquestionsarephrased
hasemergedasanimportantcomponentinmany
leadtoconsiderableperformancedecrease,some-
natural language interfaces (O˝zcan et al., 2020)
times up to 22% (Gan et al., 2021b; Deng et al.,
withapplicationsinrobotics(Dukes,2014),ques-
2021;Pietal.,2022;Changetal.,2023).
tionanswering(Zhongetal.,2017;Yuetal.,2018),
Effortstoautomaticallyincreaseitsdiversityof-
dialogue systems (Artzi and Zettlemoyer, 2011),
ten rely on text generation models trained on the
andtheInternetofThings(Campagnaetal.,2017).
sameSpiderdataandunavoidablyinherititschar-
ThereleaseoftheSpiderdataset(Yuetal.,2018)
acteristics(Zhongetal.,2020b;Wangetal.,2021;
markedanimportantmilestoneintext-to-SQLse-
Wu et al., 2021; Jiang et al., 2022). In this work,
mantic parsing. Apart from its considerable size,
weproposetoaugmentthetrainingdatafortext-to-
Spiderstandsoutforincludingcomplexandnested
SQLparserswithmorerealisticanddiverseques-
tionreformulations. Weleveragethecapabilitiesof
1Modelcheckpointsanddataareavailableatgithub.com/
saparina/Text2SQL-NLVariation largelanguagemodelsforrewritingutterancesand
4202
beF
31
]LC.sc[
1v66680.2042:viXradevisepromptsdesignedtoenhancemodelrobust- worldchallengeswithlarge-scaledatabaseswhich
nessagainstlinguisticvariations. Ourpromptscon- often contain dirty and noisy values and how to
sistsolelyofinstructionsandquestionsandareeasy expressSQLqueriestoimproveexecutionspeed.
touse. Wetrainthreestate-of-the-arttext-to-SQL Theyshowthatincorporatingmanuallyannotated
parsersonSpider(Yuetal.,2018)withaugmenta- external knowledge that includes synonyms im-
tionsgeneratedbyourapproach. Extensiveexperi- proves performance. Our augmentations can be
mentsshowthatatwo-foldincreaseinthenumber viewedasanalternativetothisapproach;welearn
of questions substantially improves model gener- languagevariationswithoutoracleknowledge.
alization ability. Our augmentations increase ro-
RobustnesstoPerturbations Anotherchallenge
bustnessagainstquestionperturbationswhenmod-
fortext-to-SQLparsersisrobustnesstosmallper-
elsareevaluatedonthechallengingDr.Spidersets
turbations. Previousstudiesevaluaterobustnessin
(Changetal.,2023)anddeliverimprovementsina
thesingle-domainsetting(Huangetal.,2021)and
zero-shotsetting,whenmodelsaretestedonout-of-
across databases, e.g., by removing or paraphras-
domaindatasetslikeGeoQuery(ZelleandMooney,
ingexplicitmentionsofdatabaseentities(Spider-
1996)andKaggleDBQA(Leeetal.,2021).
Realistic;Dengetal.2021)orbysubstitutingsuch
Ourcontributionsarethree-fold: aproposalof
mentions with synonyms (Spider-Syn; Gan et al.
rewriteoperationstorenderquestionsmorediverse
2021a). Otherworkexplorestheeffectofperturba-
andnatural;amethodologyforaugmentingexist-
tionsinthedatabaseschema(Pietal.,2022)and
ingdatasetsbasedontheproposedreformulations;
alsoinquestions(MaandWang,2021). Recently,
andempiricalresultsvalidatingourapproachim-
Changetal.(2023)releasedDr.Spider,acompre-
provesgeneralizationacrossmodelsanddatasets.
hensiverobustnessbenchmarkwithawiderange
ofperturbationsinthedatabaseschema,questions,
2 RelatedWork
andSQLsemantics. Weevaluateourapproachon
Out-of-domainGeneralization Severaldatasets their“questionsets”whichcoverabroaderrangeof
languagevariationscomparedtopreviousefforts.
havebeenreleasedtofacilitatethedevelopmentof
modelswithgeneralizationcapabilities. WikiSQL
DataAugmentation Severaldataaugmentation
(Zhong et al., 2017) is a large-scale benchmark
andadversarialtrainingtechniqueshavebeenpro-
with different databases but only one table. As
posedtosupportSQLqueriesexecutedonasingle
a result, WikiSQL queries are relatively easy to
table(Lietal.,2019;Radhakrishnanetal.,2020)
parseduetotheuseofalimitedsetofoperations.
and multiple tables (Zhong et al., 2020b; Wang
Spider (Yu et al., 2018), contains multiple tables
etal.,2021;Wuetal.,2021;Dengetal.,2021;Wu
perdatabasewhichresultincomplexSQLqueries.
etal.,2021;Jiangetal.,2022). Augmentationsin
Suhr et al. (2020) examine the performance of
earlierwork(Ganetal.,2021a;Dengetal.,2021;
Spider-trainedmodelsondatasetsvaryinginterms
Ma and Wang, 2021; Huang et al., 2021) target
ofthequestionsbeingasked,thedatabasestructure,
specific linguistic expressions like synonyms or
andSQLstyle. Theydiscoverthatakeychallenge
paraphrases. Weleveragethecapabilitiesof(very)
inachievinggeneralizationliesinlinguisticvaria-
largelanguagesmodels(LLMs;Brownetal.2020;
tion,andproposeaugmentingSpider’strainingset
Chowdheryetal.2022)togeneratelinguistically
withWikiSQLdata. Ourworkaddressestheprob-
diversenaturallanguagequestions. Recentefforts
lemofquestiondiversityinSpider, withoutcom-
(Daietal.,2023;Heetal.,2023)haveshownthat
promising its complex query structures or multi-
LLMscanserveasannotatorswhengivensufficient
table database nature. We evaluate our approach
guidanceandexamplesmainlyfortextclassifica-
onGeoQuery(ZelleandMooney,1996),adataset
tiontasks.
similar to Spider in terms of database structure
andSQLqueriesbutdifferentinthestyleofques- 3 Motivation
tions. WealsoreportresultsonKaggleDBQA(Lee
3.1 ProblemFormulation
et al., 2021), a dataset with real-world databases
andquestionscreatedbyuserswithaccesstofield Semantic parsing aims to translate a natural lan-
descriptionsratherthandatabaseschemas. guageutteranceintoaformalrepresentationofits
BIRD (Lietal.,2023b)isarecentlyreleaseda meaning. Wefocusonmeaningrepresentationsin
text-to-SQLbenchmark,aimingtohighlightreal- the form of SQL queries that can be executed insomedatabasetoretrieveananswerordenotation. Database: driving_school
Customers
Inthecross-domainsetting,theparserisnotlimited customer_id ... first_name last_name ... email_address
toaspecificdatabaseandcanbeintheoryapplied
Lessons
to arbitrary databases and questions. In practice, lesson_id ... customer_id lesson_time ... price
thistaskismoreorlesscomplexdependingonthe
Prior
database in hand, i.e., the number of tables and Questions SQL DB
values,thenamingconventionsusedfortablesand 1. Calculatethetotalsumoflessontimesfiltering ✓ ✓
theresultsbyselectingthecustomerwiththefirst
columns, the way values are formatted, and spe-
name"Rylan"andthelastname"Goodwin".
cific domain characteristics. We do not consider
thesechallengesinthiswork,focusinginsteadon 2. HowlongdidRylanGoodwin’slessonlast? X X
generalizationissuesthatarisefromthevariation
3. Howlongisthetotallessontimetakenbyacus- X ✓
ofquestionsinnaturallanguage. tomerwithafirstnameasRylanandalastname
asGoodwin?
3.2 TypesofUtterancesinSemanticParsing
SQL Query
SELECT sum(T1.lesson_time) FROM Lessons AS T1 JOIN
Recentworkhasdemonstratedtheimportanceof
Customers AS T2 ON T1.customer_id = T2.customer_id WHERE
wordinginsemanticparsing,indicatingthatcertain T2.first_name = "Rylan" AND T2.last_name = "Goodwin".
questionformulationscanbemoredifficulttoparse
Figure1: Differenttypesofquestionsthatarerelatedto
thanothers(Radhakrishnanetal.,2020;Ganetal.,
thesamedatabase(onlyrelevanttablesandcolumnsare
2021a;Dengetal.,2021;Changetal.,2023).
shown)andmaptothesameSQLquery.
Thelevelofdifficultyforaquestioncanbeinflu-
encedbytheamountoftask-specificbackground
knowledgeusedtoformulateit. Forinstance,users program, but are often ambiguous, requiring ad-
familiarwithSQLandtheunderlyingdatabasewill ditional reasoning based on domain or common
have some idea of the desired program, and will sense knowledge. In the examples shown in Fig-
beabletoarticulatetheirintentionsmoreprecisely, ure1,thesecondquestionbelongstothiscategory,
e.g.,byprovidingexplicitinstructions. Incontrast, itislaconic,underspecified,andinherentlynatural.
users unfamiliar with the task are more likely to Thesetypesofutterancesrepresenttwoimpor-
askgeneralquestionsinacolloquialstyle. Figure1 tantedgecasesbutdonotcoverallpossibilities. In
illustratesdifferentquestionformulationswiththe thecontextoftext-to-SQLsemanticparsing,infor-
same intent. The first question could have been mationaboutthedatabaseschemaanditscontents
posed by a user who is well-versed in SQL and canalsobeusefulwhenformulatingquestions. We
has knowledge of the database; it mentions spe- thusintroduceathirdcategorythatfallsbetween
cificdatabaseentitiesandoperationslikesumma- havingtask-specificknowledgeandnoneatall.
tionandfiltering,unlikethesecondquestionwhich
Utteranceswhichdemonstrateknowledgeofthe
doesnothaveanysuchdetails. Moreformally,we
database schema are general descriptions of in-
distinguishbetweentwotypesofutterances:
tentbutwithexplicitreferencestorelateddatabase
entities. This category differs from the previous
Utteranceswhichdemonstratepriorknowledge
two in the type of prior knowledge used; users
arecloselyalignedwiththedesiredprograms,high-
are familiar with the database schema and pos-
lightlogicalstructureoperations,andexplicitref-
sibly database content but have no expertise in
erences to database entities. Such utterances re-
queryconstruction. ThethirdquestioninFigure1
sembleinstructions,suggestingtheuserhassome
includes explicit references to the database table
understandingofthedesiredprogram. InFigure1,
thefirstquestionfallsunderthiscategory,presup-
(e.g.,customers)anditscolumns(e.g.,lesson_time,
posingknowledgeofsummationandfilteringoper-
first_name, last_name). Becauseofthat, questions
ationsandthenamesofentities(e.g.,first_name, maybelesscoherentandnatural. Inourexample,
last_name)usedinthetargetSQLquery. thequestioncontainsredundantdetailssuchasfirst
name,lastname,andcustomer.
Utterances which do not demonstrate prior Questions in Spider (Yu et al., 2018) often in-
knowledge aregeneraldescriptionsofintent,ex- cludeexplicitmentionsofdatabaseelements(Deng
pressed in a simple, colloquial language. They et al., 2021). This is a by-product of Spider’s
donotprovideintentionalhintsaboutthedesired creationprocesswhichencouragedannotatorsfa-miliarwithSQLtoformulatethequestionsmore 1.Instruction: Simplify
clearly and explicitly. In contrast, other datasets Original Whichclubhasthemostfemalestudentsas
Question theirmembers?Givemethenameofthe
likeGeoQuery(ZelleandMooney,1996)orcross-
club.
domain KaggleDBQA (Lee et al., 2021) contain
Output Whichclubhasthemostfemalestudents?
lessexplicitquestionswithasmallerpercentageof
2.Instruction: Simplify by hiding details
database entity mentions. In this work, we auto-
Original Whatisthetitleandcreditsofthecoursethat
maticallyaugmentSpider’strainingsetwithmore
Question istaughtinthelargestclassroom(withthe
generalandnaturalquestionsaimingtodevelopse- highestcapacity)?
manticparsingmodelsthatcaneffectivelyhandle Output Whatcourseistaughtinthebiggest
classroomandwhatareitscredits?
alltypesofutterancesmentionedabove.
3.Instruction: Simplify using synonyms
4 DataGeneration Original Whatistheaveragedurationinmilliseconds
Question oftracksthatbelongtoLatinorPopgenre?
We augment the training set of Spider (Yu et al.,
Output Whatisthemeanlengthinmillisecondsof
2018)byleveraginglargelanguagemodels. Specif- LatinorPopsongs?
ically, we exploit ChatGPT’s2 text generation ca- 4.Instruction: Simplify using substitutions
pabilities (gpt-3.5-turbo-0301) and ask it to Original Whatarethelocationsthathavegasstations
rephrase Spider questions (no SQL- or database- Question ownedbyacompanywithamarketvalue
greaterthan100?
specificinformationisprovided;seeTable1),using
Output Wherearethegasstationsownedbya
threetypesofrewriteoperations:
companyworthmorethan100?
1. Deletion of words or phrases which are redun- 5.Instruction: Express in a different way
dantforunderstandingthequestion’sintent. For Original Whatisthenumberofroutesoperatedbythe
this purpose, we use two instructions: the first Question airlineAmericanAirlineswhosedestinations
areinItaly?
onesimplifiesthequestion,whilethesecondone
Output HowmanyroutesdoesAmericanAirlines
explicitlyhidesunnecessarydetailsthatdonot
havethatflytoItaly?
changethemeaning. Thefirstinstructionaffords
6.Instruction: Examples of the question
ChatGPTmorefreedominrewritingthequestion. simplification: <...>
InTable1,examples1–2showhowSpiderques- Original Whatarethenamesofbodybuilderswhose
tionsarereformulatedwiththeseinstructions. Question totalscoreishigherthan300?
2. Substitution of words or phrases with simpler Output Whoarethebodybuilderswithascoreover
300?
ones. We instruct ChatGPT to replace words
7.Instruction: Paraphrase
withtheirsynonymsandalsotomoregenerally
Original Returnthecategoriesofmusicfestivalsthat
attempttosimplifybysubstitutingafewwordsin
Question havetheresult"Awarded".
thequestion. InTable1,examples3–4showhow
Output Listthecategoriesofmusicfestivalsthat
questionsarerewrittenwiththeseinstructions. havebeenrecognizedwithawards.
3. Rewriting of the entire question. Some ques-
tionscanhavethesamemeaning,despitebeing Table1: Differenttypesofaugmentationgeneratedfor
Spiderquestions. Thefullversionoftheinstructionsfor
significantly dissimilar in their surface realisa-
generationisshowninAppendixA,Table6.
tion. Forexample,thequestionsWheredomost
people live? and Which cities have the largest
population? are related to the same database
aboutcitiesandexpressthesameintentbuthave
beviewedasageneralizationofpreviousreformu-
no words in common. We instruct ChatGPT to
lations, however, in practice it is only somewhat
providedifferentwaysofexpressingaquestion.
helpful. ChatGPToftengeneratesverysimilarver-
WeempiricallyfindthatChatGPTcanbetoocon-
sions of the original question, retaining the same
servativeattimesandalsoincludeapromptwith
details, style and structure following this instruc-
examples to encourage more drastic reformula-
tion. We consider this conservative paraphrasing
tions. In Table 1, questions 5–6 show example
strategytobeanadvantageasalmostallmachine-
outputsfortheseinstructions.
generated questions preserve the meaning of the
WealsoaskChatGPTtoparaphrasequestions
original question. To verify the quality of gener-
(see example 7 in Table 1). This instruction may
atedparaphrases,wecomputethecosinesimilarity
2chat.openai.com betweentheoriginalandgeneratedquestions.AugmentationType #examples
Simplify 774
Simplifybyhidingdetails 1,136
Simplifyusingsynonyms 1,285
Simplifyusingsubstitutions 1,316
Paraphrase 1,130
Expressinadifferentway 1,065
Promptwithexamples 1,256
Total 7,962
Table2: QuestionreformulationsgeneratedforSpider; Figure 2: Distribution of cosine similarities between
numberofgenerationsperinstruction. Spiderquestionsandgeneratedreformulations.
5 ExperimentalSetup oldof0.5,obtainedbestresults. Additionally,we
manuallyinspected100reformulationsandfound
Ourexperimentsaimtoevaluatetheperformance
only6%tobeincorrect(i.e.,inaccurateexpressions
of models trained specifically for cross-database
ofintent). AnalysisinAppendixBfurthershows
text-to-SQLparsing. Weareinterestedintwotypes
thatouraugmentationsdonotaffectthenatureof
of generalization: robustness to controllable per-
parsingerrors.
turbationsinutterancesandadaptationtonewdo-
The resulting training set contains 14,954 in-
mainswithdifferentquestionstyles. Perturbations
stances;statisticsforeachcategoryareinTable2
allow us to study more closely the impact of lan-
andexamplesinAppendixE.Thecostofcalling
guage variations, while new domains provide a
the ChatGPT API to obtain our augmentations is
more realistic and challenging setting. We first
approximately7.5$.
describethedatasetsweusefortrainingandevalu-
ationandthenbrieflydiscussthesemanticparsing 5.2 EvaluationDatasets
modelsandmetricsweemployinourexperiments.
TheSpiderdevelopmentsetconsistsof1,034ques-
5.1 TrainingDatasets tionsto20databasesand564targetSQLTraining
Datasets. Since these questions share the same
Our primary training dataset is Spider (Yu et al.,
styleandlevelofdetailasthetrainingset, wein-
2018),whichcontains7,000questionsto140differ-
stead focus on evaluation sets with more natural
entdatabasesand3,981targetqueries.3 Although
anddiverselanguage. Specifically,wepresentre-
therecanbemorethanonequestionforthesame
sults on two groups of evaluation sets. The first
intent(usuallytwo),linguisticvariationstendtobe
grouparedatasetsderivedfromtheSpiderdevelop-
scanty and limited. We augment Spider with ad-
mentset,featuringidenticalSQLTrainingDatasets
ditionalquestionsusingChatGPTasanautomatic
anddatabaseswhichallowustoassessthemodel’s
annotator. Foreachintentintheoriginaltraining
resiliencetovariationsinlinguisticexpression. The
set,wegeneratetwoquestionreformulationsbased
secondgroupareindependentdatasetswhichnot
onthetypesspecifiedinSection4. Wechoosethe
onlydifferinlanguageusagebutalsoinSQLstyle
augmentationtypesrandomlyanddonotacceptdu-
anddatabasespecifics. Thisallowsustoevaluate
plicates. Figure2showsthedistributionofcosine
modelperformanceinmorerealisticconditions.
similaritiesbetweentheoriginalSpiderquestions
andthegeneratedreformulations. Wemeasureco- Datasets Based on Spider Chang et al. (2023)
sinesimilaritybasedontheSimCSEembeddings haverecentlyreleasedDr.Spider,acomprehensive
ofGaoetal.(2021). Ascanbeseen,themajorityof robustnessbenchmarkwhichincludes9evaluation
paraphrasesaresemanticallysimilartotheSpider sets with 7,593 examples of perturbations in nat-
question(themeansimilarityis0.88). Experiments ural language questions (NLQ sets). They have
withdifferentfilteringthresholds(rangingfrom0.5 alsocreatedevaluationsetsfordatabaseandSQL
to0.7withastepof0.05)revealedthatstoringall perturbationswhichareoutofscopeforthiswork.
generatedexamples,effectivelyadoptingathresh- NLQperturbationsetsarebasedontheSpiderde-
velopment set, they contain the same databases
3Weexcludethesingle-domaindatasetsYuetal.(2018)
employinadditiontotheirdata. andgoldTrainingDatasets,deviatingonlyintermsof the questions asked. They are generated with 5.3 Models
OPT (Zhang et al., 2022), a large pretrained lan-
guagemodel,andmanuallyfilteredbySQLexperts. Currentapproachesframetext-to-SQLparsingas
There are three main categories of perturbations: asequence-to-sequenceproblem. Theinputisthe
changeoneorafewwordsthatrefertoSQLkey- concatenation of question and database entities,
words (for example, replace the word maximum includingtableandcolumnnames,andcontentval-
referringtothemaxSQLfunctionwiththelargest), ues extracted based on string matching, and the
change references to columns (for example, re- outputisanSQLquery. Shawetal.(2021)show
place name of the countries referring to column thatapre-trainedT5-3Bmodel(Raffeletal.,2020)
CountryName with which countries) and change fine-tuned on Spider (Yu et al., 2018) is a com-
referencestodatabasevalues(forexample,replace petitivetext-to-SQLparser. Scholaketal.(2021)
players from the USA referring to the value USA buildonthisapproachwithPICARD,amethodfor
with American players). Changes are made by constraineddecodingthatfiltersthebeamateach
replacing words with their synonyms or carrier generation step, taking into account task-specific
phrases(e.g.,nameofthecountriesandwhichcoun- constraints such as grammatical correctness and
tries). Note that our augmentations target solely consistency with the database. Recently, Li et al.
language variations and do not manipulate gold (2023a)proposeRESDSQL,anapproachthatde-
SQLqueries. couplesschemalinkingfromSQLparsing. They
first filter relevant database entities and then use
T5-3B to generate a sketch (i.e., SQL keywords)
andthentheactualSQLquery. Weusethebestver-
OtherDatasets GeoQuery(ZelleandMooney,
sionoftheirmodelwhichalsoleveragesNatSQL
1996)isasingle-domainsemanticparsingdataset
intermediaterepresentations(Ganetal.,2021c).
withquestionstoadatabaseofUSgeography. We
use a version with SQL queries as logical forms WeusetheimplementationsfromScholaketal.
andquery-basedsplits(Finegan-Dollaketal.,2018) (2021) and Li et al. (2023a) for training models
with a test set of 182 examples. GeoQuery ques- onaugmenteddataandtheirreleasedcheckpoints
tionsareconciseandtheirinterpretationoftende- fortrainingontheoriginalSpider. Allmodelsare
pendsondomainknowledge. Forexample,inthe trainedfor100epochs;weuseabatchsizeof200
questionwhatisthelargestcityinthesmalleststate for the base T5-3B to reduce the computational
intheusa,thelargestcity impliesthecitywiththe cost,leavingallotherhyperparametersunchanged.
largestpopulationbutthesmalleststate impliesthe WetrainonasingleNVIDIAA100GPU.
statewiththesmallestarea.
Ourapproachtodataaugmentationismodelag-
KaggleDBQA (Lee et al., 2021) is a cross- nosticbutourexperimentsfocusonsettingswhere
domaintext-to-SQLdatasetfortestingmodelsun- the model is specifically trained or fine-tuned on
der more realistic conditions. It contains 272 ex- text-to-SQLdata. Analternativeislargelanguage
amples related to 8 real-world databases which modelswhicharetrainedonhugetextcollections
canhaveabbreviatedtableandcolumnnamesand (includingcode)andabletotranslatenaturallan-
“dirty”values. Questionswerecollectedwithanno- guagetoSQL,withoutfurtherfine-tuningontask-
tators having access to column descriptions only, specific data (Rajkumar et al., 2022). Since our
ratherthantheactualdatabaseschema(thedataset augmentationsaregeneratedbyChatGPT,amodel
providesthesedescriptionsbutwedonotusethem). trained with Reinforcement Learning for Human
Thissimulatesrealisticdatabaseusagebutalsocre- Feedback(Christianoetal.,2017),weincludeitas
atesachallengeforsemanticparsersasquestions astandalonebaseline. FollowingLiuetal.(2023),
cannotbeeasilyalignedtotargetSQLqueries. For wepromptChatGPTinazero-shotsettingwiththe
example,thequestionWhichartist/groupismost descriptionofthedatabaseschemafollowedbythe
productive? toadatabasewithinformationonhip question(thefullpromptisshowninAppendixC).
hop torrents should be parsed into query SELECT LargelanguagemodelslikeChatGPTdifferfrom
artist FROM torrents GROUP BY artist ORDER task-specific models in many respects, including
BY count(groupName) DESC LIMIT 1,asproduc- potential use cases, resource requirements, trans-
tive refers to the number of releases and column parency,andaccessibilityandthusanycomparison
groupNamecontainsreleasedtitles. shouldbeinterpretedwithagrainofsalt.5.4 Metrics Dr.SpiderNLQ
We report performance as execution accuracy Model SpiderDev↑ Pre↑ Post↑ Diff↓
whichcomparestheexecutionresultsofgoldand T5-3B 74.4 70.3 58.9 11.4
predicted queries (using the implementation of +Augmented 75.3 72.6 62.7 9.9
Zhongetal.2020a). PICARD 79.3 76.0 65.0 11.0
Firstly,weevaluatemodelrobustnesstopertur- +Augmented 79.3 76.7 68.3 8.4
bationsinquestions,byconsideringzero-shotpars-
RESDSQL 84.1 84.7 69.3 15.4
ing on Dr.Spider. Evaluation sets for Dr.Spider
+Augmented 84.0 84.6 72.5 12.1
NLQ fall in two categories: pre-perturbed sets
ChatGPT 72.2 73.8 57.9 15.9
are subsets of the Spider development set, while
post-perturbedsetsarethesamesubsetsbutwith Table 3: Execution Accuracy on Spider development
rewritten questions instead of the original Spi- setandDr.SpiderNLQsubsets,before(Pre)andafter
der ones. Execution accuracy on post-perturbed perturbations (Post: absolute robustness) and the gap
sets measures absolute robustness, while the dif- betweenthem(Diff: relativerobustness). Allmodels
aretestedinazero-shotsetting;+Augmentedrefersto
ference in execution accuracy between pre- and
modelsfine-tunedontheaugmentedSpiderdata.
post-perturbed sets measures relative robustness.
Wealsoevaluateout-of-domaingeneralizationby
considering the execution accuracy of zero-shot models compared to base models in almost all
parsersonGeoQueryandKaggleDBQA. cases. Moreover, the performance gap on pre-
andpost-perturbeddatadecreaseswhichindicates
6 Results
better relative robustness for augmented models.
Augmented RESDSQL delivers the highest post-
Our experiments compare models trained on the
perturbationaccuracyof72.5%andaugmentedPI-
originalSpidertrainingdataagainstmodelstrained
CARDdemonstratesthesmallestgapbetweenpre-
onSpiderwithouraugmentations. Wealsoreport
andpost-perturbationsof8.4%confirmingthatour
results for ChatGPT tested in a zero-shot mode.
augmentationsimprovebothabsoluteandrelative
AppendixDprovidesadditionalresults(onmore
robustness.
evaluationsets)anddetailedversionsofalltables.
Augmented models do not have an advantage
6.1 RobustnesstoQuestionPerturbations over base models on the original Spider develop-
ment set (see the last row in Table 3). There are
Table3reportsaverageexecutionaccuracyoneval-
tworeasonsforthis: firstly,weaugmentquestions
uationsetsfromDr.Spider(Changetal.,2023)con-
only without adding new SQL queries, and sec-
tainingperturbationsinnaturallanguagequestions.
ondly, augmentations shift the language distribu-
WealsopresentresultsontheoriginalSpiderdevel-
tion by removing specific details and rendering
opmentset. Pre/Postrefertosubsetsbefore/after
questions more natural, but the development set
perturbations(post-perturbationsetsarethesame
remainsclosertotheoriginaltrainingset.
Spidersubsetsbutwiththequestionsrewritten;ab-
Augmented models do not have an advantage
soluterobustness).
over base models on the original Spider develop-
WecompareT5-3BwithandwithoutPICARD
ment set (see the last row in Table 3). There are
andRESDSQLmodelsfine-tunedontheoriginal
tworeasonsforthis: firstly,weaugmentquestions
Spider data and our augmentations; we also pro-
only without adding new SQL queries, and sec-
videresultsforChatGPTevaluatedinthezero-shot
ondly, augmentations shift the language distribu-
setting. Our results show that ChatGPT is most
tion by removing specific details and rendering
vulnerable to question reformulations among all
questions more natural, but the development set
models. Changetal.(2023)reachsimilarconclu-
remainsclosertotheoriginaltrainingset.
sionswithCodex(Chenetal.,2021),anotherlarge
pre-trainedlanguagemodel,andhypothesizethis
6.2 GeneralizationtoOtherDatasets
is due to the training data being biased towards
docstrings (which is what most natural language Table 4 summarizes our results in the more chal-
utteranceslooklikeonwebsiteslikeGitHub). lengingzero-shotsetting. Specifically,weevaluate
Absoluterobustness(accuracyonpost-perturbed modelperformanceontwoout-of-domaindatasets,
sets) improves by more than 3% for augmented namelyGeoQuery(ZelleandMooney,1996)andKaggleDBQA
Model GeoQuery Nuclear Crime Pesticide Math Baseball Fires WhatCD Soccer Avg
T5-3B 54.4 59.4 48.2 16.0 7.1 20.5 43.2 7.3 16.7 27.3
+Augmented 60.4 56.3 48.2 18.0 7.1 20.5 43.2 26.8 22.2 30.3
PICARD 56.6 59.4 51.9 18.0 10.7 25.6 43.2 9.8 22.2 30.1
+Augmented 62.6 56.3 48.1 22.0 14.3 25.6 43.2 24.4 27.8 32.7
RESDSQL 56.6 59.4 48.1 16.0 25.0 23.1 43.2 17.1 22.2 31.8
+Augmented 59.3 65.6 44.4 24.0 25.0 23.1 43.2 19.5 27.8 34.1
ChatGPT 20.9 34.4 18.5 16.0 10.7 15.4 27.0 4.9 16.7 17.9
Table4: ExecutionaccuracyonGeoQuerytestset(querysplits)anddifferentdatabasesfromKaggleDBQA.All
modelsaretestedinazero-shotsetting;+Augmentedreferstomodelsfine-tunedontheaugmentedSpiderdata.
KaggleDBQA (Lee et al., 2021). Both datasets fordatagenerationbutusesonlyoneprompt: pro-
differfromSpiderinmanyrespects,i.e.,thetypes videdifferentwaysofexpressingaquestion.
ofquestionsbeingasked,thestyleofSQLqueries,
Table5showstheexecutionaccuracyofT5-3B
andthedatabasestructure.
trained with and without augmentations pertain-
WefindChatGPTperformsverypoorlyonthese ingtoDeletion,Substitution,Rewriting,andPara-
datasets compared to models fine-tuned on Spi- phrasing. We also include results with All aug-
der with or without augmentations. In all cases, mentations combined. The ablation study shows
augmented models improve execution accuracy that different types of augmentation are helpful
compared to base models. PICARD trained with fordifferentdatasets. OnGeoQuery,modelsaug-
augmentationsperformsbestonGeoQueryreach- mented with deletions and substitutions perform
inganaccuracyof62.6%(a6%differenceagainst best; substitutions also perform best on the NLQ
thebasemodel). AugmentedRESDSQLperforms setsofDr.SpiderandKaggleDBQA.Paraphrasing-
bestonKaggleDBQA,whichismorechallenging, basedaugmentationsarebestfortheoriginalSpider
reachinganaverageaccuracyof34.1%. Augmenta- development set, with Rewriting trailing behind.
tionsaregenerallyhelpfulbutnotacrossallindivid- Results obtained with a single prompt (express
ualcategories(notethatcategoriesarerepresented in a different way)furtherillustratetheneed
by a limited number of examples per database for diverse instructions. We also trained T5-3B
andevenasmallnumberoferrorscanresultina with augmentations from Spider-Syn (Gan et al.,
dropofseveralpercentagepoints). Wesuspectthe 2021a)andMT-TEQL(MaandWang,2021). For
lowaccuracyonKaggleDBQAisprimarilydueto afaircomparison,werandomlysample MT-TEQL
challengesthatareunrelatedtolanguagevariation. exampleswithquestiontransformationstomatch
In particular, its databases contain abbreviations the training size obtained through our augmenta-
whichmightbedifficulttoparseandSQLqueries tions (Spider-Syn and one-prompt baselines also
exemplifyoperationswhicharenotpresentinSpi- matchourtrainingsize). AscanbeseeninTable5,
der(e.g.,arithmeticoperatorsbetweencolumns). our combined augmentations outperform models
trained on Spider-Syn and MT-TEQL on all eval-
6.3 AblationsandAnalysis uationsets(Dr.SpiderNLG,GeoQuery,andKag-
gleDBQA)andtheimprovementcomesfromrefor-
Wenextinvestigatetheimpactofdifferenttypesof
mulating the questions rather than increasing the
question reformulations introduced in Section 4,
trainingset.
and also compare against related augmentation
methods: Gan et al. (2021a) manually annotate The results in Table 5 reaffirm the observation
Spider-Syn with synonym substitutions, whereas that different evaluation sets exemplify different
MaandWang(2021)introduceMT-TEQL,aframe- linguisticvariationsandthatthereisnosingletype
workforgeneratingsemantics-preservingvariants of augmentation that represents them all. Rather,
ofutterancesanddatabaseschemas. Weuseaver- acombinationofaugmentationsisneededtoper-
sionofMT-TEQLthatchangesprefixesandaggre- form well across datasets. This in turn suggests
gatormentionsinSpiderquestions. Additionally, thatamodelcanacquireusefulknowledgebybe-
weincludeabaselinewhichfollowsourprocedure ingexposedtoadiverserangeoflinguisticvaria-Dr.SpiderNLQ
Model SpiderDev↑ Post↑ Diff↓ GeoQuery↑ KaggleDBQA↑
T5-3B 74.4 58.9 11.4 54.4 27.3
+Deletion 74.7 59.7 11.5 56.0 28.7
+Substitution 75.1 62.9 9.8 56.0 31.2
+Rewriting 75.0 62.3 11.2 53.8 27.4
+Paraphrase 75.3 61.4 11.6 41.8 25.9
+All(ours) 75.3 63.2 9.9 60.4 30.3
+OnePrompt 74.4 60.4 15.4 40.7 29.2
+Spider-Syn 75.6 59.2 13.2 49.5 27.0
+MT-TEQL* 75.0 62.0 11.1 47.8 29.2
Table5: ExecutionaccuracyonSpiderdevelopmentset,Dr.SpiderNLQ(Post: absoluterobustness;Diff: relative
robustness), GeoQuery, and KaggleDBQA for T5-3B base and trained with different augmentations including
Spider-Syn(Ganetal.,2021a)andsub-sampled(diacritic*)versionofMT-TEQL(MaandWang,2021).
tions. Wealsoobservethatamodeltrainedoncom- academic purposes. Our augmentations are un-
binedaugmentationsoutperformsmodelstrained filtered and may add a small amount of noise to
onmorespecializeddatasets(i.e.,Spider-Synand trainingdata. Moreover,eventhoughourproposed
MT-TEQL)whichconfirmsthatrelyingsolelyon rewrite operations are diverse, they may still not
localtransformationsofthequestionsisnotsuffi- coverallpossiblereformulations. Infact,wefound
cientforbettergeneralization. itchallengingforChatGPTtogeneratewildlydif-
ferent expressions of the original intent. Finally,
7 Conclusion
thisworkdoesnotconsidermultilingualorconver-
sationalsemanticparsingwhichwehopetoexplore
We propose to enhance the generalization capa-
inthefuture.
bilities of text-to-SQL parsers by increasing nat-
ural language variation in the training data. We
Acknowledgments
leveragealargelanguagemodellikeChatGPTto
We thank the meta-reviewer and anonymous re-
automaticallygenerateavarietyofquestionrefor-
viewers for their constructive feedback. The au-
mulations, thereby augmenting existing datasets
thors also thank Hao Zheng for insightful com-
withmorenaturalanddiversequestions. Weeval-
ments on earlier versions of this work. We grate-
uatestate-of-the-artmodelstrainedwithandwith-
fullyacknowledgethesupportoftheUKEngineer-
outouraugmentationsonavarietyofchallenging
ingandPhysicalSciencesResearchCouncil(grant
datasetsfocusingonrobustness(toperturbations)
EP/L016427/1).
andout-of-domaingeneralization. Acrossmodels
and datasets we find that augmentations improve
performancebyawidemargin. Ourexperiments References
further underscore the need for a broad range of
YoavArtziandLukeZettlemoyer.2011. Bootstrapping
augmentations representing the full spectrum of
semanticparsersfromconversations. InProceedings
rewrite operations. In the future, we plan to ex-
of the 2011 Conference on Empirical Methods in
plore the potential of large language models for NaturalLanguageProcessing,pages421–432,Edin-
multilingualsemanticparsing. burgh,Scotland,UK.AssociationforComputational
Linguistics.
Limitations
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Ourworkaimstoincreasetherobustnessofseman-
Neelakantan,PranavShyam,GirishSastry,Amanda
tic parsers against natural language variation but Askell, Sandhini Agarwal, Ariel Herbert-Voss,
doesnothandleproblemsrelatedtoSQLqueries Gretchen Krueger, Tom Henighan, Rewon Child,
anddatabasestructuresthatarealsoimportantfor AdityaRamesh,DanielZiegler,JeffreyWu,Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
out-of-domaingeneralization. Weobtainaugmen-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
tations using ChatGPT, a black-box model pro-
Clark, ChristopherBerner, SamMcCandlish, Alec
vided by OpenAI, which limits its usage for non- Radford, Ilya Sutskever, and Dario Amodei. 2020.Languagemodelsarefew-shotlearners. InProceed- KaisDukes.2014. SemEval-2014task6: Supervised
ingsofthe33stAnnualConferenceonNeuralInfor- semantic parsing of robotic spatial commands. In
mationProcessingSystems,volume33,pages1877– Proceedings of the 8th International Workshop on
1901.CurranAssociates,Inc. SemanticEvaluation(SemEval2014),pages45–53,
Dublin,Ireland.AssociationforComputationalLin-
Giovanni Campagna, Rakesh Ramesh, Silei Xu, guistics.
Michael Fischer, and Monica S. Lam. 2017. Al-
mond: Thearchitectureofanopen, crowdsourced, Catherine Finegan-Dollak, Jonathan K. Kummerfeld,
privacy-preserving,programmablevirtualassistant. LiZhang,KarthikRamanathan,SeshSadasivam,Rui
InProceedingsofthe26thInternationalConference Zhang,andDragomirRadev.2018. Improvingtext-
onWorldWideWeb,WWW’17,page341–350,Re- to-SQL evaluation methodology. In Proceedings
public and Canton of Geneva, CHE. International of the 56th Annual Meeting of the Association for
WorldWideWebConferencesSteeringCommittee. ComputationalLinguistics(Volume1: LongPapers),
pages351–360,Melbourne,Australia.Association
Shuaichen Chang, Jun Wang, Mingwen Dong, Lin forComputationalLinguistics.
Pan, Henghui Zhu, Alexander Hanbo Li, Wuwei
Lan, Sheng Zhang, Jiarong Jiang, Joseph Lilien, Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew
SteveAsh,WilliamYangWang,ZhiguoWang,Vit- Purver, John R. Woodward, Jinxia Xie, and Peng-
torio Castelli, Patrick Ng, and Bing Xiang. 2023. sheng Huang. 2021a. Towards robustness of text-
Dr.spider: A diagnostic evaluation benchmark to- to-SQL models against synonym substitution. In
wardstext-to-SQLrobustness. InThe11thInterna- Proceedingsofthe59thAnnualMeetingoftheAsso-
tionalConferenceonLearningRepresentations. ciationforComputationalLinguisticsandthe11th
InternationalJointConferenceonNaturalLanguage
MarkChen,JerryTworek,HeewooJun,QimingYuan, Processing (Volume 1: Long Papers), pages 2505–
Henrique Ponde de Oliveira Pinto, Jared Kaplan, 2515, Online. Association for Computational Lin-
HarriEdwards,YuriBurda,NicholasJoseph,Greg guistics.
Brockman,AlexRay,RaulPuri,GretchenKrueger,
MichaelPetrov,HeidyKhlaaf,GirishSastry,Pamela YujianGan,XinyunChen,andMatthewPurver.2021b.
Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Exploringunderexploredlimitationsofcross-domain
MikhailPavlov,AletheaPower,LukaszKaiser,Mo- text-to-SQL generalization. In Proceedings of the
hammadBavarian,ClemensWinter,PhilippeTillet, 2021ConferenceonEmpiricalMethodsinNatural
Felipe Petroski Such, Dave Cummings, Matthias LanguageProcessing,pages8926–8931,Onlineand
Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Punta Cana, Dominican Republic. Association for
Herbert-Voss, Guss, et al. 2021. Evaluating large ComputationalLinguistics.
languagemodelstrainedoncode.
YujianGan,XinyunChen,JinxiaXie,MatthewPurver,
AakankshaChowdhery,SharanNarang,JacobDevlin, JohnR.Woodward,JohnDrake,andQiaofuZhang.
MaartenBosma,GauravMishra,AdamRoberts,Paul 2021c. Natural SQL: Making SQL easier to infer
Barham,HyungWonChung,CharlesSutton,Sebas- from natural language specifications. In Findings
tianGehrmann,etal.2022. Palm: Scalinglanguage of the Association for Computational Linguistics:
modelingwithpathways. EMNLP 2021, pages 2030–2042, Punta Cana, Do-
minican Republic. Association for Computational
PaulFChristiano,JanLeike,TomBrown,MiljanMar- Linguistics.
tic, Shane Legg, and Dario Amodei. 2017. Deep
reinforcementlearningfromhumanpreferences. In Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.
Proceedingsofthe31stAnnualConferenceonNeural SimCSE:Simplecontrastivelearningofsentenceem-
InformationProcessingSystems, volume30, Long beddings. In Proceedings of the 2021 Conference
Beach,CA,USA.CurranAssociates,Inc. onEmpiricalMethodsinNaturalLanguageProcess-
ing,pages6894–6910,OnlineandPuntaCana,Do-
HaixingDai,ZhengliangLiu,WenxiongLiao,Xiaoke minican Republic. Association for Computational
Huang,YihanCao,ZihaoWu,LinZhao,Shaochen Linguistics.
Xu,WeiLiu,NinghaoLiu,ShengLi,DajiangZhu,
HongminCai,LichaoSun,QuanzhengLi,Dinggang MosheHazoom,VibhorMalik,andBenBogin.2021.
Shen, TianmingLiu, andXiangLi.2023. Auggpt: Text-to-SQL in the wild: A naturally-occurring
Leveragingchatgptfortextdataaugmentation. datasetbasedonstackexchangedata. InProceedings
ofthe1stWorkshoponNaturalLanguageProcessing
Xiang Deng, Ahmed Hassan Awadallah, Christopher for Programming (NLP4Prog 2021), pages 77–87,
Meek,OleksandrPolozov,HuanSun,andMatthew Online.AssociationforComputationalLinguistics.
Richardson. 2021. Structure-grounded pretraining
for text-to-SQL. In Proceedings of the 2021 Con- XingweiHe,ZhenghaoLin,YeyunGong,A-LongJin,
ferenceoftheNorthAmericanChapteroftheAsso- HangZhang,ChenLin,JianJiao,SiuMingYiu,Nan
ciationforComputationalLinguistics: HumanLan- Duan,andWeizhuChen.2023. Annollm: Making
guageTechnologies,pages1337–1350,Online.As- large language models to be better crowdsourced
sociationforComputationalLinguistics. annotators.ShuoHuang,ZhuangLi,LizhenQu,andLeiPan.2021. Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun
On robustness of neural semantic parsers. In Pro- Li,andJian-GuangLou.2022. Towardsrobustness
ceedings of the 16th Conference of the European oftext-to-SQLmodelsagainstnaturalandrealistic
Chapter of the Association for Computational Lin- adversarialtableperturbation. InProceedingsofthe
guistics: Main Volume, pages 3333–3342, Online. 60thAnnualMeetingoftheAssociationforCompu-
AssociationforComputationalLinguistics. tationalLinguistics(Volume1: LongPapers),pages
2007–2022,Dublin,Ireland.AssociationforCompu-
JiarongJiang,YiqunHu,WuweiLan,HenryZhu,Anuj tationalLinguistics.
Chauhan,AlexanderLi,LinPan,JunWang,Chung-
WeiHang,ShengZhang,MarvinDong,JoeLilien, KarthikRadhakrishnan,ArvindSrikantan,andXiVic-
Patrick Ng, Zhiguo Wang, Vittorio Castelli, and toriaLin.2020. ColloQL:Robusttext-to-SQLover
BingXiang.2022. Importanceofsynthesizinghigh- search queries. In Proceedings of the First Work-
qualitydatafortext-to-sqlparsing. InNeurIPS2022 shoponInteractiveandExecutableSemanticParsing,
WorkshoponSyntheticData4ML. pages34–45,Online.AssociationforComputational
Linguistics.
Chia-Hsuan Lee, Oleksandr Polozov, and Matthew
Colin Raffel, Noam Shazeer, Adam Roberts, Kather-
Richardson. 2021. KaggleDBQA: Realistic evalu-
ine Lee, Sharan Narang, Michael Matena, Yanqi
ationoftext-to-SQLparsers. InProceedingsofthe
Zhou,WeiLi,andPeterJ.Liu.2020. Exploringthe
59thAnnualMeetingoftheAssociationforCompu-
limitsoftransferlearningwithaunifiedtext-to-text
tationalLinguisticsandthe11thInternationalJoint
transformer. JournalofMachineLearningResearch,
Conference on Natural Language Processing (Vol-
21(140):1–67.
ume1: LongPapers),pages2261–2273,Online.As-
sociationforComputationalLinguistics. Nitarshan Rajkumar, Raymond Li, and Dzmitry Bah-
danau.2022. Evaluatingthetext-to-sqlcapabilities
HaoyangLi,JingZhang,CuipingLi,andHongChen. oflargelanguagemodels.
2023a. Resdsql: Decoupling schema linking and
skeleton parsing for text-to-sql. In Proceedings of TorstenScholak,NathanSchucher,andDzmitryBah-
the37thAAAIConferenceonArtificialIntelligence, danau. 2021. PICARD: Parsing incrementally for
pages13067–13075,Washington,DC,USA.AAAI constrainedauto-regressivedecodingfromlanguage
Press. models. InProceedingsofthe2021Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,
JingjingLi,WenluWang,Wei-ShinnKu,YingtaoTian, pages9895–9901,OnlineandPuntaCana,Domini-
and Haixun Wang. 2019. Spatialnli: A spatial do- can Republic. Association for Computational Lin-
mainnaturallanguageinterfacetodatabasesusing guistics.
spatialcomprehension. InProceedingsofthe27th
ACMSIGSPATIALInternationalConferenceonAd- PeterShaw,Ming-WeiChang,PanupongPasupat,and
vancesinGeographicInformationSystems,SIGSPA- KristinaToutanova.2021. Compositionalgeneraliza-
TIAL’19,page339–348,NewYork,NY,USA.As- tionandnaturallanguagevariation: Canasemantic
sociationforComputingMachinery. parsingapproachhandleboth? InProceedingsofthe
59thAnnualMeetingoftheAssociationforCompu-
JinyangLi,BinyuanHui,GeQu,BinhuaLi,JiaxiYang, tationalLinguisticsandthe11thInternationalJoint
BowenLi,BailinWang,BowenQin,RongyuCao, Conference on Natural Language Processing (Vol-
RuiyingGeng,NanHuo,ChenhaoMa,KevinC.C. ume1: LongPapers),pages922–938,Online.Asso-
Chang,FeiHuang,ReynoldCheng,andYongbinLi. ciationforComputationalLinguistics.
2023b. Canllmalreadyserveasadatabaseinterface?
Alane Suhr, Ming-Wei Chang, Peter Shaw, and Ken-
abigbenchforlarge-scaledatabasegroundedtext-
tonLee.2020. Exploringunexploredgeneralization
to-sqls.
challengesforcross-databasesemanticparsing. In
Proceedingsofthe58thAnnualMeetingoftheAsso-
Aiwei Liu, Xuming Hu, Lijie Wen, and Philip S. Yu.
ciationforComputationalLinguistics,pages8372–
2023. Acomprehensiveevaluationofchatgpt’szero-
8388, Online. Association for Computational Lin-
shottext-to-sqlcapability.
guistics.
PingchuanMaandShuaiWang.2021. Mt-teql: Eval- BailinWang,WenpengYin,XiVictoriaLin,andCaim-
uating and augmenting neural nlidb on real-world ing Xiong. 2021. Learning to synthesize data for
linguisticandschemavariations. Proceedingsofthe semanticparsing. InProceedingsofthe2021Con-
VLDBEndowment,15(3):569–582. ferenceoftheNorthAmericanChapteroftheAsso-
ciationforComputationalLinguistics: HumanLan-
FatmaO˝zcan,AbdulQuamar,JaydeepSen,ChuanLei,
guageTechnologies,pages2760–2766,Online.As-
and Vasilis Efthymiou. 2020. State of the art and sociationforComputationalLinguistics.
openchallengesinnaturallanguageinterfacestodata.
In Proceedings of the 2020 ACM SIGMOD Inter- KunWu,LijieWang,ZhenghuaLi,AoZhang,Xinyan
nationalConferenceonManagementofData,SIG- Xiao, Hua Wu, Min Zhang, and Haifeng Wang.
MOD ’20, page 2629–2636, New York, NY, USA. 2021. Data augmentation with hierarchical SQL-
AssociationforComputingMachinery. to-questiongenerationforcross-domaintext-to-SQLparsing. InProceedingsofthe2021Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,
pages8974–8983,OnlineandPuntaCana,Domini-
can Republic. Association for Computational Lin-
guistics.
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,
DongxuWang,ZifanLi,JamesMa,IreneLi,Qingn-
ingYao,ShanelleRoman,ZilinZhang,andDragomir
Radev.2018. Spider: Alarge-scalehuman-labeled
datasetforcomplexandcross-domainsemanticpars-
ingandtext-to-SQLtask. InProceedingsofthe2018
Conference on Empirical Methods in Natural Lan-
guageProcessing,pages3911–3921,Brussels,Bel-
gium.AssociationforComputationalLinguistics.
John M Zelle and Raymond J Mooney. 1996. Learn-
ingtoparsedatabasequeriesusinginductivelogic
programming. InProceedingsofthe13thAAAICon-
ference on Artificial Intelligence, volume 2, pages
1050–1055,Portland,Oregon.AAAIPress.
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
Artetxe,MoyaChen,ShuohuiChen,ChristopherDe-
wan,MonaDiab,XianLi,XiVictoriaLin,TodorMi-
haylov,MyleOtt,SamShleifer,KurtShuster,Daniel
Simig, Punit Singh Koura, Anjali Sridhar, Tianlu
Wang,andLukeZettlemoyer.2022. Opt: Openpre-
trainedtransformerlanguagemodels.
RuiqiZhong,TaoYu,andDanKlein.2020a. Semantic
evaluationfortext-to-SQLwithdistilledtestsuites.
InProceedingsofthe2020ConferenceonEmpirical
MethodsinNaturalLanguageProcessing(EMNLP),
pages 396–411, Online. Association for Computa-
tionalLinguistics.
Victor Zhong, Mike Lewis, Sida I. Wang, and Luke
Zettlemoyer.2020b. Groundedadaptationforzero-
shot executable semantic parsing. In Proceedings
of the 2020 Conference on Empirical Methods in
NaturalLanguageProcessing(EMNLP),pages6869–
6882, Online. Association for Computational Lin-
guistics.
Victor Zhong, Caiming Xiong, and Richard Socher.
2017. Seq2SQL:Generatingstructuredqueriesfrom
naturallanguageusingreinforcementlearning.A DataGeneration T5modelwastrainedwithaugmentations. Based
onasampleof60instances,weobservedthatthe
Table6showsthefullversionsofthepromptswe
majorityoferrorsaresimilarinnatureandsymp-
usetogeneratetheaugmentationsdefinedinSec-
tomaticofaT5-trainedsemanticparser,e.g.,errors
tion4fortheSpidertrainingset.
intheoutputcolumnsorjoinoperation.
1.Instruction: Simplify Theonlytypeoferrorthatmightbeduetoour
Fullversion Simplifythefollowingsentence:... augmentationsconcernsminorchangesinvalues.
2.Instruction: Simplify by hiding details BaselineT5almostalwayscopiesvaluesfromthe
Fullversion Simplifythesentencebyhidingunnecessary question but T5 trained with augmentations can
detailsthatdonotchangethemeaning:... slightly change them, e.g., use the full name in-
3.Instruction: Simplify using synonyms stead of an abbreviation or lowercase instead of
Fullversion Simplifythefollowingsentenceusing uppercase. Wefoundthisoccursin10%ofcases.
synonyms:...
DatabasevaluesarementionedverbatiminSpider
4.Instruction: Simplify using substitutions questionsbutthiscouldbedifferentinreal-world
Fullversion Makethesentencesimplerbysubstituting settingsorotherdatasetswheresometoleranceto
somewordsin...
surfacevariationsmightbeadvantageous.
5.Instruction: Express in a different way
Fullversion Whataredifferentwaysofexpressingthis C ChatGPTZero-ShotPrompt
question:...
Belowweshowthepromptweusedwhenevaluat-
6.Instruction: Examples of the question
simplification: <...> ingthezero-shotChatGPTontext-to-SQLdatasets
Fullversion Examplesofthequestionsimplification: followingLiuetal.(2023):
Original:Findthenamesofstadiumswhose ### SQL tables, with their properties:
capacityissmallerthantheaveragecapacity. #
Simplified:Whichstadiumsaresmallerthan # stadium(Stadium_ID, Location, Name,
theaverage? Capacity, Highest, Lowest, Average)
# singer(Singer_ID, Name, Country,
Original:Showthefleetseriesofaircraft
Song_Name, Song_release_year, Age,
flownbypilotsyoungerthan34.
Is_male)
Simplified:Returnthefleetseriesofthe # concert(concert_ID, concert_Name,
planeswhosecaptainsareyoungerthan34. Theme, Stadium_ID, Year)
Original:Whichcitieshavethelargest # singer_in_concert(concert_ID,
population? Singer_ID)
#
Simplified:Wheredomostpeoplelive?
### How many singers do we have? Return
Original:Inwhichyearwasmostoftheships only a SQL query.
built? SELECT
Simplified:Whenweremostoftheships
constructed?
D AdditionalResults
Original:Tellmethenumberoforderswith
"Secondtime"astheorderdetail. Table7showsourresultsonallDr.Spiderpertur-
Simplified:Howmanyordershave"Second
bationsubsets(NLQreferstosubsetswithpertur-
time"asanorderdetail?
bations in natural language questions, SQL and
Original:...
DBareperturbationsinSQLanddatabasetokens).
Simplified:
Wecomparethreemodelstrainedwithandwithout
7.Instruction: Paraphrase
augmentations: T5-3B,PICARD,andRESDSQL.
Fullversion Givemeaparaphraseofthefollowing
question:... We also employ ChatGPT in a zero-shot setting.
Overall, thebestmodelisaugmentedRESDSQL
Table6: Promptsusedfordatageneration. (74.1%) which is better than the base version by
morethan2%onpost-perturbedsets. Augmented
T5-3BandPICARDalsoimproverobustnesscom-
B ErrorAnalysis
paredtobasemodels. AugmentedRESDSQLde-
In order to verify that our augmentations do not livers the best average results for all three types
introducenewparsingerrors,weexaminedexam- of perturbations and performs best on the major-
plesintheSpiderdevelopmentsetwhichwerecor- ityofindividualcategories,eventhoughouraug-
rectly parsed by a T5 model trained without aug- mentationsarenotdesignedtoimproverobustness
mentations but rendered incorrect after the same againstSQLandDBperturbations.Augmented Augmented Augmented
T5-3B T5-3B PICARD PICARD RESDSQL RESDSQL ChatGPT
PerturbationSet Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post Pre Post
Keyword-synonym 70.2 62.6 73.8 65.4 72.6 66.3 75.3 69.4 81.5 72.4 84.2 74.7 64.7 55.7
Keyword-carrier 82.7 76.4 83.0 79.2 85.0 82.7 88.7 84.0 89.0 83.5 87.5 85.0 85.0 82.0
Column-synonym 63.9 51.3 66.3 54.2 71.0 57.2 68.7 59.7 78.7 63.1 77.4 66.1 66.1 48.8
Column-carrier 83.1 61.7 82.0 70.5 86.9 64.9 85.0 73.1 86.5 63.9 86.4 76.3 82.2 52.0
NLQ
Column-attribute 49.6 48.7 60.5 58.8 58.8 56.3 63.9 62.2 82.4 71.4 82.4 71.4 77.3 62.2
Column-value 69.1 58.6 76.3 58.9 82.9 69.4 83.2 70.4 96.4 76.6 95.1 77.6 74.0 57.9
Value-synonym 68.6 46.4 68.6 53.0 72.5 53.0 70.8 57.1 79.2 53.2 79.6 55.1 69.0 45.8
Multitype 70.1 51.1 71.4 56.3 74.4 57.1 74.0 61.4 83.8 60.7 83.8 65.7 71.9 49.8
Others 75.3 73.1 76.6 72.7 79.6 78.3 80.9 77.6 85.2 79.0 84.8 80.2 74.0 66.4
Average 70.3 58.9 73.2 63.2 76.0 65.0 76.7 68.3 84.7 69.3 84.6 72.5 73.8 57.9
Comparison 62.9 62.4 71.3 66.3 68.0 68.0 74.2 70.8 80.9 82.0 84.3 83.7 73.6 64.0
Sort-order 75.0 70.3 76.0 75.5 79.2 74.5 78.1 76.6 88.0 85.4 88.5 83.3 66.7 57.8
SQL NonDB-number 77.1 73.3 71.8 77.1 83.2 77.1 73.3 77.9 87.8 85.5 90.8 90.8 90.8 90.1
DB-text 59.5 58.3 59.9 61.6 64.7 65.1 66.2 66.7 77.2 74.3 91.5 75.0 67.5 68.2
DB-number 83.9 83.7 79.8 78.8 86.3 85.1 84.6 83.2 88.8 88.8 91.5 91.2 82.7 79.8
Average 71.7 69.6 71.8 71.9 76.3 74.0 75.3 75.0 84.5 83.2 89.3 84.8 76.3 72.0
Schema-synonym 66.4 46.9 67.8 52.8 73.0 56.5 73.4 61.9 81.3 68.3 80.9 70.4 67.6 56.0
DB Schema-abbreviation 69.5 53.3 71.0 55.5 74.9 64.7 75.2 65.3 82.4 70.0 81.8 71.7 68.8 63.5
Content-equivalence 84.6 40.8 72.3 46.1 88.7 43.7 86.9 37.2 90.3 40.1 91.9 41.4 81.2 46.3
Average 73.5 47.0 72.3 46.1 78.9 55.0 78.5 54.8 84.7 59.5 84.9 61.1 72.5 55.3
All 71.3 59.9 72.6 62.7 76.6 65.9 76.6 67.9 84.7 71.7 86.0 74.1 74.3 61.5
Table7: ExecutionAccuracyonsubsetstakenfromDr.Spider(NLQ,DB,andSQLsets);modelperformanceis
shownbefore(Pre)andafterperturbations(Post). WecompareT5-3B,T5-3B+PICARD,andRESDSQLfine-tuned
withandwithoutaugmentations,andzero-shotChatGPT.
Augmented Augmented Augmented
Dataset T5-3B T5-3B PICARD PICARD RESDSQL RESDSQL ChatGPT
Realistic 64.2 66.7 71.4 79.3 80.7 84.0 63.4
Spider-Syn 62.4 70.8 69.8 72.8 76.9 79.2 58.6
GeoQuerydev 59.1 64.2 64.2 68.6 59.7 54.1 25.8
Table8: ExecutionaccuracyonSpider-Realistic,Spider-SynandGeoQuerydevsetforT5-3Bwithandwithout
PICARDandRESDSQLtrainedwithorwithoutaugmentations.
Table 8 shows results on the additional eval- theGeoQuerydevelopmentset,thebestmodelis
uation sets, Spider-Realistic, (Gan et al., 2021a) augmentedPICARDwith68.6%accuracy. Across
Spider-Syn with 1,034 examples, and GeoQuery allbenchmarks,fine-tunedtext-to-SQLparserssig-
devsetwith152examples(querysplitsofFinegan- nificantlyoutperformzero-shotChatGPT.
Dollaketal.2018). Bothevaluationsetsarebased
E ExamplesofSpiderAugmentations
ontheSpiderdevelopmentset,aimingtoremove
fromthequestionsexplicitreferencestodatabase
WeprovidesamplesoftheaugmentedSpidertrain-
entities. Thesereferencesweremanuallydeletedor
ing set. Questions are grouped based on intent;
paraphrasedinSpider-Realisticandreplacedwith
typesindicatewhethertheyareintheoriginalSpi-
synonymsinSpider-Syn. AugmentedRESDSQL
dertrainingsetorweregeneratedwithinstructions:
obtains best results on both datasets (84.0% on
simplify, simplify by hiding details, simplify by
Spider-Realisticand79.2%onSpider-Syn)andis
synonyms,simplifybysubstitutions,expressdiffer-
betterthanthebaseversionbymorethan4%. On
ently,paraphrase,orbyshowingexamples.1. SQLquery SELECT personal_name FROM Students EXCEPT SELECT T1.personal_name FROM
Students AS T1 JOIN Student_Course_Enrolment AS T2 ON T1.student_id = T2.student_id
Questions Findthepersonalnamesofstudentsnotenrolledinanycourse. Type:original
Whichstudentsnotenrolledinanycourse?Findtheirpersonalnames. Type:original
Findnamesofunenrolledstudents. Type:hide-details
Canyouprovidemewiththenamesofthestudentswhoarenotcurrentlyregistered Type:paraphrase
inanycourse?
2. SQLquery SELECT donator_name , sum(amount) FROM endowment GROUP BY donator_name
ORDER BY sum(amount) DESC
Questions Listeachdonatornameandtheamountofendowmentindescendingorderofthe Type:original
amountofendowment
Enumeratecontributorsandtheirendowmentsumsindecreasingorder Type:synonyms
Listdonorsandtheirendowmentsindescendingorder Type:hide-details
3. SQLquery SELECT count(*) FROM CLASS AS T1 JOIN enroll AS T2 ON T1.class_code = T2.class_code
WHERE T1.crs_code = ’ACCT-211’
Questions HowmanystudentsenrolledinclassACCT-211? Type:original
WhatarethetotalnumberofstudentsenrolledinACCT-211? Type:original
HowmanypupilsregisteredforcourseACCT-211? Type:synonyms
HowmanystudentsareenrolledinACCT-211? Type:from-examples
4. SQLquery SELECT T2.roomName FROM Reservations AS T1 JOIN Rooms AS T2 ON T1.Room = T2.RoomId
WHERE firstname LIKE ’%ROY%’
Questions FindthenameofroomsbookedbysomecustomerswhosefirstnamecontainsROY. Type:original
Whatarethenameofroomsbookedbycustomerswhosefirstnamehas"ROY"in Type:original
part?
Whataretheroomnamesthathavebeenreservedbycustomerswith"ROY"intheir Type:paraphrase
firstname?
Whatroomsdidcustomerswith"ROY"intheirfirstnamebook? Type:substitutions
5. SQLquery SELECT T1.account_name , T1.other_account_details FROM Accounts AS T1 JOIN
Customers AS T2 ON T1.customer_id = T2.customer_id WHERE
T2.customer_first_name = ’Meaghan’ AND T2.customer_last_name = ’Keeling’
Questions Showtheaccountnameandotheraccountdetailforallaccountsbythecustomer Type:original
withfirstnameMeaghanandlastnameKeeling.
Whatarethenamesandotherdetailsforaccountscorrespondingtothecustomer Type:original
namedMeaghanKeeling?
WhatareMeaghanKeeling’saccountnamesanddetails? Type:simplify
IamlookingfortheaccountdetailsandnamesassociatedwithMeaghanKeeling. Type:paraphrase
Canyouhelpmewiththat?
6. SQLquery SELECT sum(acc_bal) FROM customer WHERE state = ’Utah’ OR state = ’Texas’
Questions FindthetotalaccountbalanceofeachcustomerfromUtahorTexas. Type:original
WhatarethetotalaccountbalancesforeachcustomerfromUtahorTexas? Type:original
AdduptheaccountbalancesofcustomerswholiveinUtahorTexas. Type:express-differently
WhatisthetotalaccountbalanceforcustomersfromUtahorTexas? Type:from-examples
7. SQLquery SELECT date_of_enrolment , date_of_completion FROM Student_Course_Enrolment
Questions Listallthedatesofenrollmentandcompletionofstudents. Type:original
Whatareallthedatesofenrollmentandcompletioninrecord? Type:original
Providearecordoftheenrollmentandcompletiondatesforallstudents. Type:paraphrase
Whataretheenrollmentandcompletiondatesofallstudents? Type:from-examples
8. SQLquery SELECT headquarter FROM manufacturers WHERE founder = ’James’
Questions WhereistheheadquarterofthecompanyfoundedbyJames? Type:original
WhatistheheadquarterofthecompanywhosefounderisJames? Type:original
WherewasthecompanyfoundedbyJamesheadquartered? Type:express-differently
WhereisthemainofficeofthecompanyestablishedbyJames? Type:paraphrase9. SQLquery SELECT max(Price) , max(Score) FROM WINE WHERE Appelation = ’St. Helena’
Questions WhatarethemaximumpriceandscoreofwinesproducedbySt.Helena Type:original
appelation?
GivethemaximumpriceandscoreforwinesproducedintheappelationSt.Helena. Type:original
WhatisthetopmostpriceandscorethatcanbeobtainedbywinesproducedinSt. Type:paraphrase
Helena?
WhatisthehighestpriceandscoreforSt.Helenawines? Type:simplify
10. SQLquery SELECT degrees FROM campuses AS T1 JOIN degrees AS T2 ON t1.id = t2.campus
WHERE t1.campus = ’San Francisco State University’ AND t2.year = 2001
Questions Whatarethedegreesconferredin"SanFranciscoStateUniversity"in2001. Type:original
WhatdegreeswereconferredinSanFranciscoStateUniversityintheyear2001? Type:original
WhatdiplomasweregrantedatSFStatein2001? Type:synonyms
WhatdegreesweregivenatSanFranciscoStateUniversityin2001? Type:substitutions
11. SQLquery SELECT membership_card FROM member WHERE address = ’Hartford’ INTERSECT
SELECT membership_card FROM member WHERE address = ’Waterbury’
Questions WhatisthemembershipcardheldbybothmemberslivinginHartfordandones Type:original
livinginWaterburyaddress?
WhatisthemembershipcardforpeopleinHartfordandWaterburycalled? Type:substitutions
IsthereamembershipcardthatisvalidforbothHartfordandWaterburyresidents? Type:express-differently
12. SQLquery SELECT kids FROM Reservations WHERE FirstName = ’ROY’ AND LastName = ’SWEAZY’
Questions HowmanykidsstayintheroomsreservedbyROYSWEAZY? Type:original
FindthenumberofkidsstayingintheroomsreservedbyapersoncalledROY Type:original
SWEAZ.
HowmanychildrenarestayinginROYSWEAZY’sreservedrooms? Type:from-examples
HowmanykidsareinRoySweaz’sreservedrooms? Type:hide-details
13. SQLquery SELECT count(*) FROM products AS t1 JOIN product_characteristics AS t2
ON t1.product_id = t2.product_id JOIN CHARACTERISTICS AS t3
ON t2.characteristic_id = t3.characteristic_id WHERE t1.product_name = ’laurel’
Questions Howmanycharacteristicsdoestheproductnamed"laurel"have? Type:original
Countthenumberofcharacteristicsoftheproductnamed’laurel’. Type:original
Howmanyfeaturesdoes"laurel"have? Type:simplify
Howmanyqualitiesdoestheproduct"laurel"have? Type:substitutions
14. SQLquery SELECT customer_name FROM customers WHERE payment_method = (SELECT payment_method
FROM customers GROUP BY payment_method ORDER BY count(*) DESC LIMIT 1)
Questions Whatarethenamesofcustomersusingthemostpopularpaymentmethod? Type:original
Findthenameofthecustomerswhousethemostfrequentlyusedpaymentmethod. Type:original
Whoarethecustomersusingthepopularpaymentmethod? Type:hide-details
Whoarethecustomersutilizingthemostfavoredpaymentoption? Type:synonyms
15. SQLquery SELECT TYPE FROM ship WHERE Tonnage > 6000 INTERSECT SELECT TYPE FROM ship
WHERE Tonnage < 4000
Questions Showthetypesofshipsthathavebothshipswithtonnagelargerthan6000and Type:original
shipswithtonnagesmallerthan4000.
Whatarethetypesoftheshipsthathavebothshiipswithtonnagemorethan6000 Type:original
andthosewithtonnagelessthan4000?
Displayshipswithtonnageabove6000andbelow4000. Type:simplify
Whichtypesofshipshavetonnageexceeding6000andalsolessthan4000? Type:express-differently
16. SQLquery SELECT customer_name FROM customers EXCEPT SELECT t1.customer_name FROM customers AS t1
JOIN customer_addresses AS t2 ON t1.customer_id = t2.customer_id JOIN addresses AS t3
ON t2.address_id = t3.address_id WHERE t3.state_province_county = ’California’
Questions FindthenamesofcustomerswhoarenotlivinginthestateofCalifornia Type:original
Discoverthenamesofnon-Californiacustomers. Type:substitutions
WhoarethecustomersnotresidinginCalifornia? Type:from-examples