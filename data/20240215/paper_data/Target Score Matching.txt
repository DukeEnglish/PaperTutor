Target Score Matching
Valentin De Bortoli∗1, Michael Hutchinson2, Peter Wirnsberger2, and Arnaud Doucet1
1Google DeepMind
2Isomorphic Labs
Abstract
DenoisingScoreMatchingestimatesthescoreofa“noised”versionofatargetdistributionby
minimizing a regression loss and is widely used to train the popular class of Denoising Diffusion
Models. A well known limitation of Denoising Score Matching, however, is that it yields poor
estimates of the score at low noise levels. This issue is particularly unfavourable for problems
in the physical sciences and for Monte Carlo sampling tasks for which the score of the “clean”
originaltargetisknown. Intuitively,estimatingthescoreofaslightlynoisedversionofthetarget
should be a simple task in such cases. In this paper, we address this shortcoming and show that
itisindeedpossibletoleverageknowledgeofthetargetscore. WepresentaTargetScoreIdentity
andcorrespondingTargetScoreMatchingregressionlosswhichallowsustoobtainscoreestimates
admitting favourable properties at low noise levels.
1 Introduction and Motivation
1.1 Denoising Score Identity and Denoising Score Matching
Consider a Rd-valued random variable X ∼p and let Y|(X =x)∼p (·|x) be a “noisy” version of
X Y|X
X. Wedenotethejointdensityof(X,Y)byp (x,y)=p (x)p (y|x)andrefertoexpectationand
X,Y X Y|X
variance w.r.t. to this distribution as E and Var , respectively. We are interested in estimating
X,Y X,Y
the score of the distribution of Y, that is ∇logp (y), where
Y
(cid:90)
p (y)= p (x)p (y|x)dx. (1)
Y X Y|X
Evaluating this score is particularly useful for denoising tasks, especially Denoising Diffusion Models
(DDM) which require estimates at different noise levels (Sohl-Dickstein et al., 2015; Ho et al., 2020;
Song et al., 2021). A standard derivation shows that the identity
(cid:90)
∇logp (y)= ∇logp (y|x) p (x|y)dx (2)
Y Y|X X|Y
holds under mild regularity assumptions, where henceforth ∇logp (y|x) denotes the gradient with
Y|X
respect to y and
p (x)p (y|x)
X Y|X
p (x|y)=
X|Y p (y)
Y
is the posterior density of X given Y = y (see, for example, Vincent (2011)). We will refer to (2) as
the Denoising Score Identity (DSI). In scenarios where it is possible to compute ∇logp (y|x) and
Y|X
p (x|y) is known up to a normalizing constant, the score can then be approximated by estimating
X|Y
∗vdebortoli@google.com,mhutchin@google.com,pewi@google.com,arnauddoucet@google.com
1
4202
beF
31
]GL.sc[
1v76680.2042:viXrathe expectation in (2) using Markov chain Monte Carlo (MCMC); see e.g. Appendix D.3 in (Vargas
et al., 2023a) and (Huang et al., 2024).
However,inmoststandardgenerativemodelingapplications,weonlyhaveaccessto∇logp (y|x)
Y|X
and i.i.d. samples (X ,Y )n from p (x,y) and do not know p (x|y). In this context, Denoising
i i i=1 X,Y X|Y
Score Matching (DSM) (Vincent, 2011) leverages DSI (2) by approximating ∇logp (y) using some
Y
function sθ (y) whose parameters are obtained by minimizing the regression loss
Y
ℓ (θ)=E [||sθ (Y)−∇logp (Y|X)||2], (3)
DSM X,Y Y Y|X
which is in practice approximated using samples (X ,Y )n . DSM is an alternative to Implicit Score
i i i=1
Matching (Hyv¨arinen, 2005) which only requires access to noisy samples (Y )n from p (y) but is
i i=1 Y
computationally more expensive in high dimensions as optimizing the corresponding loss requires
computing the gradient of the divergence of a d-dimensional vector field.
1.2 Limitations
Consider the case where Y is obtained by adding some independent noise W to X, i.e.
Y =X+W, W ∼p (·). (4)
W
If one can sample from p (x|y), DSI (2) suggests a Monte Carlo estimator of the score ∇logp (y)
X|Y Y
obtained by averaging ∇logp (y|X) over samples X ∼ p (·|y). In the case of Gaussian noise,
Y|X X|Y
p (w) = N(w;0,σ2I), we have that (cid:80)d Var ((∇logp (Y|X)) ) ∼ dσ−2 as σ → 0. So the
W i=1 X|Y Y|X i
variance of such an estimator is higher for low noise levels.
The high variance of the Monte Carlo estimator for low noise levels is an independent issue to the
highvarianceoftheDSMregressionlossusedtoapproximatethisestimator. Indeed,whiletheoriginal
DSM loss also exhibits high variance at low noise levels, we can re-arrange (2) to obtain the so-called
Tweedie identity (Robbins, 1956; Miyasawa, 1961; Raphan and Simoncelli, 2011)
E[X|Y =y]=y+σ2∇logp (y).
Y
This identity provides us with an alternative way for computing the score by estimating E[X|Y =y],
usingaregressionlossoftheformE [||xθ(Y)−X||2]. Inthiscase, theregressiontargetissimplyX
X,Y
and therefore does not exhibit exploding variance as σ → 0. However, this approximation xθ is used
to compute the score as
sθ(y)=(xθ(y)−y)/σ2.
Hencetheerrorofxθ isamplifiedasσ →0. Infact,thisapproachissimplyequivalenttoarescalingof
the DSM loss as E [||xθ(Y)−X||2]=σ4ℓ (θ). In the DDM literature, this reparameterisation is
X,Y DSM
sometimes called the x -prediction. Many other regression targets have been proposed in the context
0
of diffusion models, see Salimans and Ho (2022) for instance. All these parameterisations exhibit the
same issues as the direct score prediction or the x -prediction, since the resulting score approximation
0
s exhibits exploding variance as σ →0.
θ
Other techniques have also been proposed in order to derive better behaved regression losses, see
forexampleWangetal.(2020)andKarrasetal.(2022). Whiletheseworksmitigatethehighvariance
of the regression target, we emphasize that they fail to address the fundamental variance issue of the
score estimator itself.
2 Target Score Identity and Target Score Matching
We will focus hereafter on scenarios where the score ∇logp (x) of the “clean” target p (x) can be
X X
computedexactly. Asmentionedearlier,thisisnotthecaseformostgenerativemodelingapplications
where p (x) is only available through samples. However, the score ∇logp (x) is known in many
X X
2physical science applications and Monte Carlo sampling tasks that are actively investigated using
denoisingtechniques;seee.g. ZhangandChen(2022);Artsetal.(2023);CotlerandRezchikov(2023);
Herron et al. (2023); Vargas et al. (2023a,b); Wang et al. (2023); Zhang et al. (2023); Zheng et al.
(2023);Akhound-Sadeghetal.(2024);Huangetal.(2024);Phillipsetal.(2024);Richteretal.(2024).
Foreaseofpresentation,werestrictourselvestotheadditivenoisemodel(4)inthissectionanddis-
cussamoregeneralsetupinthenextsection. Atlownoiselevels,weexpect∇logp (y)≈∇logp (y)
Y X
yet neither the DSI (2) nor the DSM loss (3) take advantage of this fact. On the contrary, the Target
ScoreIdentity (TSI)andtheTargetScoreMatching (TSI)lossthatwepresentbelowaddressthisshort-
coming and leverage explicit knowledge of ∇logp (x). Henceforth, we assume that all the regularity
X
conditions allowing us to differentiate the densities and interchange differentiation and integration are
satisfied.
Proposition 2.1. For the additive noise model (4), the following Target Score Identity holds
(cid:90)
∇logp (y)= ∇logp (x) p (x|y)dx. (5)
Y X X|Y
Corollary 2.2. By symmetry, we also have
(cid:90) (cid:90)
∇logp (y)= ∇logp (w) p (w|y)dw = ∇logp (y−x) p (x|y)dx,
Y W W|Y W X|Y
which is DSI for (4).
The proof of this result and all other results in the main paper are given in Appendix A. An
alternative proof of this identity for additive Gaussian noise relying on the Fokker–Planck equation is
provided in Appendix B.
This result is not new, which is to be expected given its simplicity. It is part of the folklore in
information theory and can be found, for example, in (Blachman, 1965)1. However, to the recent
exception of Phillips et al. (2024), the remarkable computational implications of this identity do not
appear to have been exploited previously. As discussed further, Akhound-Sadegh et al. (2024) also
rely implicitly on this identity. TSI shows that, if p (x|y) is known pointwise up to a normalizing
X|Y
constant, then the score can be estimated by using an Importance Sampling (IS) or MCMC approx-
imation of p (x|y) to compute the expectation (5). The integrand ∇logp (x) will typically have
X|Y X
much smaller variance under p than the integrand ∇logp (y|x) appearing in (2) at low noise
X|Y Y|X
levels.
Having access to samples (X ,Y )n from p , we can also can estimate the score ∇logp (y) by
i i i=1 X,Y Y
minimizing the following Target Score Matching (TSM) regression loss.
Proposition 2.3. Consider a class of regression functions sθ :Rd →Rd for θ ∈Θ. For the additive
Y
noise model (4), we can estimate the score ∇logp (y) by minimizing the following regression loss
Y
ℓ (θ)=E [||sθ (Y)−∇logp (X)||2].
TSM X,Y Y X
Additionally, the TSM loss ℓ (θ) and the DSM loss ℓ (θ) satisfy
TSM DSM
(cid:90) (cid:90)
ℓ (θ)=ℓ (θ)+ ∥∇logp (x)∥2p (x)dx− ∥∇logp (y|x)∥2p (x,y)dxdy. (6)
TSM DSM X X Y|X X,Y
Contrarytoℓ (θ),ℓ (θ)doesnotrequirehavingaccessto∇logp (y|x)=∇logp (y−x).
DSM TSM Y|X W
This can be useful when the score of the noise distribution is not analytically tractable; see e.g.
Section 3 for applications to Riemmanian manifolds. Finally, we note that the relationship (6) shows
thatℓ (θ)takeslargevaluescomparedtoℓ (θ)atlownoiselevelsasbothquantitiesarepositive
DSM TSM
and the expected conditional Fisher information, E [∥∇logp (Y|X)∥2], takes large values.
X,Y Y|X
1In machine learning, it was used (and derived independently) in Appendix C.1.3. of (De Bortoli et al., 2021) to
establishsometheoreticalpropertiesofDDM.
3Corollary 2.4. In many applications, the observation model of interest is of the form
Y =αX+W (7)
for α̸=0 and W independent of X. In this case, TSI becomes
(cid:90)
∇logp (y)=α−1 ∇logp (x) p (x|y)dx, (8)
Y X X|Y
while TSM is given by
ℓ (θ)=E [||sθ (Y)−α−1∇logp (X)||2].
TSM X,Y Y X
For model (7), if the score is estimated through TSM, it is thus sensible to use a parameterization
for sθ of the form sθ (y)=α−1∇logp (y)+ϵθ(y).
Y Y X
In practice, we can consider any convex combination of DSI (equation (2)) and TSI (equation
(8)) to obtain another score identity which we can use to derive a score matching loss2. The score
identityconsideredbyPhillipsetal.(2024)andcorrespondingscorematchinglossfollowthisapproach.
Therein one considers a variance preserving denoising diffusion model (Song et al., 2021) where Y =
t
(cid:112)
α X+ 1−α2ϵ for ϵ∼N(0,I) and (α ) a continuous decreasing function such that α =1 and
t t t t∈[0,1] 0
α ≈0. In this case, α−1∇logp (x) will typically be better behaved than ∇logp (y|x) for t close
1 t X Yt|X
to 0 and vice-versa for t close to 1. Phillips et al. (2024) exploits this behaviour to propose the score
identity
(cid:90)
∇logp (y)= [α (x+∇logp (x))−y] p (x|y)dx, (9)
Yt t X X|Yt
which is the sum of α2 times TSI (equation (8)) and 1−α2 times DSI (equation (2)). They use the
t t
integrandin(9)todefineascorematchingloss. Therationaleforthischoiceisthattheintegrandwill
beclosetothetruescorefort≈0andt≈1whenX ∼p . Inpractice,the“best”lossfunctionone
X|Yt
can consider will be a function of the target p , “noise” p and α. In Appendix D, we follow the
X Y|X
analysis Karras et al. (2022) to derive a loss admitting desirable properties in a simplified Gaussian
setting.
Wefinallynotethattheveryrecentscoreestimateproposedin(Akhound-Sadeghetal.,2024)(see
Eq. (8) therein) can be reinterpreted as a self-normalized IS approximation in disguise of TSI. It
considers for the model (4) and W ∼ N(0,σ2I) the IS proposal distribution q(x) = N(x;y,σ2I) =
p (y −x) to approximate p (x|y) ∝ p (x)p (y −x). For σ ≪ 1, this importance distribution
W X|Y X W
will perform well as p (x|y) is concentrated around y. For larger σ, the variance of the resulting IS
X|Y
estimate could be significant.
3 Extensions
Next, we present a few extensions of TSI and TSM.
3.1 Extension to non-Additive Noise
We consider here a general noising process defined by
p (y|x)=F(Φ(y,x)), (10)
Y|X
where we assume that Φ(y,·) is a C2-diffeomorphism for any y ∈ Rd and that Φ is smooth. We
denote by ∇ , respectively ∇ , the gradient of Φ or Φ−1 with respect to its first, respectively second,
1 2
argument.
2WecanalternativelyconsideraconvexcombinationoftheDSMandTSMlosses.
4Proposition 3.1. For the noise model (10), the following Target Score Identity holds
(cid:90)
∇logp (y)= [∇ Φ−1(y,Φ(y,x))⊤∇logp (x)+∇ log|det(∇ Φ−1(y,·))|(Φ−1(y,x))]p (x|y)dx.
Y 1 X y 2 X|Y
For Φ(y,x) = y−αx and F(w) = p (w), we have Φ−1(y,z) = (y−z)/α and therefore one has
W
∇ Φ−1(y,Φ(y,x))⊤ = Id/α and ∇ log|det(∇ Φ−1(y,·))| = 0. Hence, we recover (8). We can thus
1 y 2
estimate the score by minimizing the following TSM loss
ℓ (θ)=E [||sθ (Y)−[∇ Φ−1(Y,Φ(Y,X))⊤∇logp (X)+∇ log|det(∇ Φ−1(Y,·))|(Φ−1(Y,X))]||2].
TSM X,Y Y 1 X y 2
3.2 Extension to Lie groups
Consider a Lie group G which admits a bi-invariant metric. We denote by µ the (left) Haar measure
on G. Let p denotes the density of X w.r.t. µ. We assume the following additive model on the Lie
X
group, i.e. Y =X+ W, where + is the group addition on G and W ∼p with density p w.r.t.
G G W W
µ. If G=Rd, we recover the Euclidean additive model of Section 2. For any smooth f : G→G and
x∈G, we denote df(x): T G→T G, the differential operator of f evaluated at x. Similarly, for
x f(x)
any smooth f : G→R, we denote ∇f(x) its Riemannian gradient.
Proposition 3.2. For a Lie group, the following Target Score Identity holds
(cid:90)
∇logp (y)= dR (x)∇logp (x) p (x|y)dµ(x),
Y x−1y X X|Y
where R (y)=yx for any x,y ∈G. In particular, if G is a matrix Lie group, we have
x
(cid:90)
∇logp (y)= ∇logp (x)x−1y p (x|y)dµ(x).
Y X X|Y
DSI and DSM have been extended to Riemannian manifolds in (De Bortoli et al., 2022; Huang
et al., 2022); see e.g. Watson et al. (2023) for an application to protein modeling. Leveraging the Lie
group structure to obtain a tractable expression of the heat kernel defining p and therefore obtain
Y|X
moreamenableDSIandDSMwasconsideredin(Yimetal.,2023;Louetal.,2023;Leachetal.,2022).
Contrary to these works, we do not need to know the exact form of the additive noising process p .
W
AdaptingDSIandDSMtoRiemmanianmanifoldssimplyrequiresreplacingtheEuclideangradient
by the Riemannian gradient. This is not the case for TSI, i.e. Proposition 3.2 is not obtained by
replacingtheEuclideangradientbytheRiemanniangradientinProposition2.1. Thisisbecause,while
sθ (y)∈T G,whereT GisthetangentspaceofGaty. However,wehavethat∇logp (x)∈T Gand
Y y y X x
thereforethesetwoquantitiesarenotimmediatelycomparableandweusedR (x)whichtransports
x−1y
T G onto T G. In contrast, in the case of DSI, both sθ (y)∈T G and ∇ logp (y|x)∈T G. It is
x y Y y y Y|X y
also possible to extend straightforwardly Proposition 2.3 to the context of Lie groups.
Proposition 3.3. Consider a class of regression functions such that for any y ∈G, s (y)∈T G for
θ y
θ ∈Θ. We can estimate the score ∇logp (y) by minimizing the TSM regression loss
Y
ℓ (θ)=E [||sθ (Y)−dR (X)∇logp (X)||2],
TSM X,Y Y X−1Y X
where R (y)=yx for any x,y ∈G.
x
3.3 Extension to Bridge Matching
Let Y be given by
Y =αX +(1−α)X +W, (11)
0 1
5where X ∼p , X ∼p , W ∼p are independent and 0<α<1. We are interested in evaluating
0 X0 1 X1 W
thescore∇logp (y). Inthecontextofgenerativemodeling,(11)appearswhenonebuildsatransport
Y
map bridging p to p ; see e.g. (Peluchetti, 2021; Liu et al., 2022; Albergo et al., 2023; Lipman
X0 X1
et al., 2023). We are again considering here a scenario where we have access to the exact scores of p
X0
and p .
X1
Proposition 3.4. For the model (11), the following Target Score Identity holds
(cid:90)
∇logp (y)=α−1 ∇logp (x ) p (x ,x |y)dx dx (12)
Y X0 0 X0,X1|Y 0 1 0 1
(cid:90)
=(1−α)−1 ∇logp (x ) p (x ,x |y)dx dx , (13)
X1 1 X0,X1|Y 0 1 0 1
where p (x ,x |y)∝p (x )p (x )p (y−αx −(1−αx )) is the posterior density of X ,X
X0,X1|Y 0 1 X0 0 X1 1 W 0 1 0 1
given Y =y.
A convex combination of (12) and (13) yields the elegant identity
(cid:90)
∇logp (y)= (∇logp (x )+∇logp (x )) p (x ,x |y)dx dx . (14)
Y X0 0 X1 1 X0,X1|Y 0 1 0 1
WecanusethesescoreidentitiestocomputethescoreusingMCMCifp (x ,x |y)isavailableup
X0,X1|Y 0 1
toanormalizingconstant. Alternatively,givensamplesfromthejointdistributionp (x ,x ,y)=
X0,X1,Y 0 1
p (x )p (x )p (y|x ,x ), we can approximate the score by minimizing a regression loss, e.g.
X0 0 X1 1 Y|X0,X1 0 1
for (15)
ℓ (θ)=E [||sθ (Y)−(∇logp (X )+∇logp (X ))||2]. (15)
TSM X0,X1,Y Y X0 0 X1 1
4 Experiments
4.1 Analytic estimators
We explore experimentally the benefits of these novel score estimators by considering 1-d mixture of
Gaussian targets defined by
N
(cid:88)
p (x )= π N(x ;µ ,σ2).
0 0 i 0 i i
i=1
Motivated by DDM, the noising process is defined by a “noising” diffusion
dX =f X dt+g dB , (16)
t t t t t
where f = d logα and g2 = dσ2 − 2f σ2 and B is a standard Brownian motion. Initialized
t dt t t dt t t t t
at X = x , (16) defines the following conditional distribution of X given X = x , p (x |x ) =
0 0 t 0 0 t|0 t 0
N(x ;α x ,σ2). In what follows, we focus on the cosine schedule where α = cos((π/2)t) and σ =
t t 0 t t t
sin((π/2)t). Consider X ∼p then the distribution of X is given by
0 0 t
N
(cid:88)
p (x )= π N(x ;µ ,σ2 ), µ =α µ , σ2 =α2σ2+σ2.
t t i t i,t i,t i,t t i i,t t i t
i=1
The posterior distribution of X given X =x is given by another mixture of Gaussians,
0 t t
N
(cid:88)
p (x |x )= π N(x ;ν ,γ2 ), (17)
0|t 0 t i,t 0 i,t i,t
i=1
6with π ∝π √ 1
exp(cid:16) −(xt−µi,t)2(cid:17)
,ν =µ +
c2
i,t(x −µ ),γ2 =σ2−
c4
i,t and c2 =α (σ2+
i,t i 2πσ i2 ,t 2σ i2 ,t i,t i,t σ i2 ,t t i,t i,t i σ i2 ,t i,t t i
µ2)−µ µ .
i i i,t
For convenience, we define the following quantities
L (x ,x ,t)=∇logp (x |x ), Denoising
DSI 0 t t|0 t 0
L (x ,x ,t)=α−1∇logp (x ), Target
TSI 0 t t 0 0
L (x ,x ,t)=w L (x ,x ,t)+(1−w )L (x ,x ,t), A w mixture
wt 0 t t DSI 0 t t TSI 0 t t
where w ∈ [0,1] for any t ∈ [0,1] is a mixture weight. As described before, for any of these targets
t
denoted L∈{L ,L ,L }, we have
DSI TSI wt
(cid:90)
∇logp (x )= L(x ,x ,t)p (x |x )dx .
t t 0 t 0|t 0 t t
We can then estimate ∇logp (x ) via the Monte Carlo estimate
t t
N
1 (cid:88)
∇logp (x )≈ L(Xi,x ,t) Xi ∼p (·|x ), (18)
t t N 0 t 0 0|t t
i=1
since p (x |x ) given by (17) is easy to sample from. Note that in more complicated scenarios, we
0|t 0 t
would have had to use MCMC or IS. In addition, we consider the score matching loss
(cid:90) 1
∇logp (x )≈argmin λ E (cid:2) ||L(X ,X ,t)−sθ(X ,t)||2(cid:3) dt, (19)
t t
sθ
0
t X0,Xt 0 t t
whereλ isaweightingfunctionovertimeandthisapproximationholdstruejointlyoverallt. Picking
t
L within (19) gives us the usual DSM loss, and picking the other identities give a series of novel
DSI
score matching losses. In what follows, we explore two key quantities:
1. The variance of the Monte Carlo estimates (18) of the score and
2. the distribution of the estimated score matching loss functions around the true score, estimated
using Monte Carlo.
We investigate these quantities on a series of target distributions.
1. A unit Gaussian,
2. a gentle mixture of Gaussians,
3. a hard mixture of Gaussians with very separated modes, with the same mode variances,
4. a hard mixture of Gaussians with very separated modes, with the different mode variances.
The unit Gaussian case we use to find appropriate values for the mixture weights w . Assuming that
t
we have a target density N(0,σ2 I) it is possible to compute the w that minimises the variance of
data t
the mixture estimator. For this we recover
σ2
κ := t ,
t σ2+α2 σ2
t t data
see Appendix C. In addition we can define another mixing weight
σ2
κ¯ := t .
t σ2+α2 σ2
t t datamode
7Hard Mixture Hard Mixture
Unit Gaussian Easy Mixture Same Variance Different Variance
p
0
2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5 2.5 0.0 2.5
− − − −
1.0
(t)
¯(t)
0.5
0.0
0.0 0.5 1.0 0.0 0.5 1.0 0.0 0.5 1.0 0.0 0.5 1.0
t t t t
Figure 1: Target distributions (top panel), and the mixture weights κ and κ¯ through time induced
t t
by these targets (bottom panel).
The difference between these two is that one used the variance of the whole target distribution, and
theotherusedthemixture-weightedaverageofthevarianceofeachmodeinthemixture,σ2 =
datamode
(cid:80) π σ2. WhileκisoptimalfortheunimodalGaussian,wewillseethatκ¯ performssignificantlybetter
i i i
for mixtures of Gaussians.
Figure1showsthesedistributions,andthemixtureweightingsκ andκ¯ forthesedistributions. In
t t
Figure 2 reports the variance of the Monte Carlo estimators of the score (18) through time. For each
time t, we sample 10,000 samples from p . For each of these, we estimate the score with 100 Monte
t
Carlo samples from p . We then compute the variance of these samples of the estimator.
0|t
In this we see a few points of note. On the Unit Gaussian example, the Monte Carlo estimates
basedonDSIandTSIperformexactlyoppositely,withalternativelylargeandsmallvariancesatt≈0
andt≈1. Theκ andκ¯ estimatorsperformthesameasσ andσ arethesame. Theyalso
t t data datamode
have approximately zero variance, as for this simple case the optimal mixture of the two estimators in
fact gives exactly the score.
In the easy mixture case, we see the expected story. Again the DSI and TSI estimators perform
oppositealongtime,withvarianceblowingupatt=0andt=1respectively. Thereishoweverashift
in when the one becomes better than the other towards t=0. The κ and κ¯ estimators both perform
t t
well, with neither showing a variance blowup near t=0 or t=1. The κ mixture is not quite as good
t
as the DSI estimator for t≥0.2, but the κ¯ performs exactly as well, showing that this is the correct
t
optimal mixture.
In the hard mixture cases, we see again the optimal switching point between DSI and TSI move
further towards t=0. We again see that the κ mixture is not optimal, but that κ¯ gives us the best
t t
of both DSI and TSI. Even though the time frame in which TSI is better than DSI is small, in this
region we see that the DSI variance blows up and would cause difficulty estimating the score well.
One thing of note is that in the hard mixture with the same mode variance the κ¯ estimator variance
t
becomes almost zero. In this case as the modes are so far separated that as t → 0, p effectively
0|t
becomes uni-model, bringing us back to the optimal mixture case.
Next we investigate the variance in the score matching loss functions derived from the score iden-
tities discussed. In this case we need to pick a weighting scheme λ across time for the score matching
t
8
erutxiM
thgiew
ytisneDUnit Gaussian Hard Mixture - Same Variance
10−1
10−12
10−23
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
Easy Mixture Hard Mixture - Different Variance
104
10−1
10−6
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
t t
DSI TSI SI ¯SI
Figure 2: The estimated variance of each estimator based the score identities. Computed using 10,000
samples of the estimator. For each estimator sample, X is sampled from p . For each X , we use 100
t t t
samples from p to estimate the score.
0|t
losses. We investigate four weighting schemes here:
• The weighting from Song et al. (2021), λ = 1 .
t σ2
t
• The weighting from Karras et al. (2022) which ensures for a Gaussian target that the variance
of the DSM loss at initialization is 1, given by
σ2
λ = t (σ2+σ2 ).
t σ2 t data
data
We refer to this as the DSM optimal weighting.
• A new weighting derived in the spiritof Karras et al. (2022) which ensuresfor a Gaussian target
that the variance of the TSM loss is 1 at initialization, given by
α2σ2
λ = t data(σ2+α2σ2 ).
t σ2 t t data
t
We refer to this as the TSM optimal weighting (see Appendix D).
• The uniform weighting, λ =1.
t
Inaddition,wenumericallynormalisetheseschedulessothattheyintegrateto1. Thiswillnotchange
the properties of the loss function, but will re-scale the overall value of the loss, and is done to better
comparebetweenlosses. Figure3depictsthedifferentweightingfunctionsacrosstime,foraσ2 =1,
data
which we ensure all the densities we employ have. From Figure 3, we observe that the DSM and
TSM optimal weightings respectively up- and down-weight times where Figure 2 shows that the DSI
and TSI estimators had larger variances. Figure 4 is produced by looking at the 43 combinations of
9
rotamitsE
rotamitsE
ecnairav
ecnairav103
100
10−3
10−6
0.0 0.2 0.4 0.6 0.8 1.0
t
Original DSM optimal TSM optimal Uniform
Figure 3: The different weighting functions across time, for a σ2 =1
data
the 4 targets, 4 weighting functions and 4 score matching losses. For each histogram in the chart,
we estimate the loss function at the true score setting s (x ,t)=∇logp (x ) 10,000 times, using 100
θ t t t
samples from the combined time integral (sampling t uniformly) and expectations. The distribution
of these losses is plotted.
4.2 Trained score models
Finally, we train our models on a 2 dimensional Gaussian mixture model to illustrate some of the
advantagesofourapproach. WeconsiderthefourdifferentsettingsofDSM,TSM,κandκ¯asdescribed
before. Toparameterizes weconsideraMLPwiththreelayersofsize128,sinusoidaltimeembedding
θ
with embedding dimension 128. We used the ADAM optimizer with learning rate 10−4.
In Figure 5 (left), we let L∈{L ,L ,L ,L } and compute the mean of the regression loss
DSM TSM κt κ¯t
∥s (t,X )−L∥2. Weconsiderauniformweightingstrategyforalltheselosses. Theexplodingbehavior
θ t
of the DSM loss at time 0 and the exploding behavior of the TSM loss at time 1 is coherent with the
theoretical results of Section 1.2 and Section 2. Note that only the mixture of targets κ and κ¯ achieve
a non-exploding behavior for all times. In Figure 5 (right), we show the empirical MMD distance
between the empirical data distribution and generated samples with score s for a RBF kernel. We
θ
emphasize the faster convergence of the mixture of targets with κ and κ¯.
References
Akhound-Sadegh, T., Rector-Brooks, J., Bose, A. J., Mittal, S., Lemos, P., Liu, C.-H., Sendera, M.,
Ravanbakhsh, S., Gidel, G., Bengio, Y., Malkin, N., and Tong, A. (2024). Iterated denoising energy
matching for sampling from Boltzmann densities. arXiv preprint arXiv:2402.06121.
Albergo, M. S., Boffi, N. M., and Vanden-Eijnden, E. (2023). Stochastic interpolants: A unifying
framework for flows and diffusions. arXiv preprint arXiv:2303.08797.
Arts, M., Garcia Satorras, V., Huang, C.-W., Zugner, D., Federici, M., Clementi, C., Noe, F., Pinsler,
R., and van den Berg, R. (2023). Two for one: Diffusion models and force fields for coarse-grained
molecular dynamics. Journal of Chemical Theory and Computation, 19(18):6151–6159.
Blachman, N.(1965). Theconvolutioninequalityforentropypowers. IEEE Transactions on Informa-
tion Theory, 11(2):267–271.
10
)t(λHard Mixture Hard Mixture
Unit Gaussian Easy Mixture Same Variance Different Variance
100
10−4
10−8
10−2
10−5
10−8
104
100
10−4
10−8
10−2
10−5
10−8
101 106 101 106 101 106 101 106
DSM TSM SM ¯SM
Figure4: Comparisonofthedistributionoftraininglossesforthecombinationsofthe4targetdensities,
4 training losses, and 4 weighting functions.
11
MSD
MST
lanigirO
lamitpo
lamitpo
mrofinUFigure 5: (Left) Mean of the regression loss ∥s (t,X ) − L∥2 with ∥s (t,X ) − L∥2 with L ∈
θ t θ t
{L ,L ,L ,L } across training iterations. (Right) MMD distance between the empirical data
DSM TSM κt κ¯t
distribution and generated samples with score s for a RBF kernel.
θ
Cattiaux, P., Conforti, G., Gentil, I., and L´eonard, C. (2023). Time reversal of diffusion processes
underafiniteentropycondition. Annalesdel’InstitutHenriPoincar´e(B)Probabilitesetstatistiques,
59(4):1844–1881.
Cotler,J.andRezchikov,S.(2023). Renormalizingdiffusionmodels. arXiv preprint arXiv:2308.12355.
De Bortoli, V., Mathieu, E., Hutchinson, M., Thornton, J., Teh, Y. W., and Doucet, A. (2022).
Riemannianscore-basedgenerativemodelling. Advances in Neural Information Processing Systems,
35:2406–2422.
De Bortoli, V., Thornton, J., Heng, J., and Doucet, A. (2021). Diffusion Schr¨odinger bridge with
applications to score-based generative modeling. In Advances in Neural Information Processing
Systems.
Herron, L., Mondal, K., Schneekloth, J. S., and Tiwary, P. (2023). Inferring phase transitions
and critical exponents from limited observations with thermodynamic maps. arXiv preprint
arXiv:2308.14885.
Ho, J., Jain, A., and Abbeel, P. (2020). Denoising diffusion probabilistic models. In Advances in
Neural Information Processing Systems.
Huang, C.-W., Aghajohari, M., Bose, J., Panangaden, P., and Courville, A. C. (2022). Riemannian
diffusion models. In Advances in Neural Information Processing Systems.
Huang, X., Dong, H., Hao, Y., Ma, Y., and Zhang, T. (2024). Reverse diffusion Monte Carlo. In
International Conference on Learning Representations.
Hyv¨arinen, A. (2005). Estimation of non-normalized statistical models by score matching. Journal of
Machine Learning Research, 6:695–709.
Karras, T., Aittala, M., Aila, T., and Laine, S. (2022). Elucidating the design space of diffusion-based
generative models. In Advances in Neural Information Processing Systems.
Leach, A., Schmon, S. M., Degiacomi, M. T., and Willcocks, C. G. (2022). Denoising diffusion prob-
abilistic models on so(3) for rotational alignment. In ICLR 2022 Workshop on Geometrical and
Topological Representation Learning.
Lipman, Y., Chen, R.T., Ben-Hamu, H., Nickel, M., andLe, M.(2023). Flowmatchingforgenerative
modeling. In International Conference on Learning Representations.
12Liu, X., Wu, L., Ye, M., and Liu, Q. (2022). Let us build bridges: Understanding and extending
diffusion generative models. arXiv preprint arXiv:2208.14699.
Lou, A., Xu, M., and Ermon, S. (2023). Scaling Riemannian diffusion models. arXiv preprint
arXiv:2310.20030.
Miyasawa, K. (1961). An empirical Bayes estimator of the mean of a normal population. Bull. Inst.
Internat. Statist, 38(181-188):1–2.
Peluchetti, S. (2021). Non-denoising forward-time diffusions. https://openreview.net/forum?id=
oVfIKuhqfC.
Phillips, A., Dang, H. D., Hutchinson, M., De Bortoli, V., Deligiannidis, G., and Doucet, A. (2024).
Particle denoising diffusion sampler. arXiv preprint arXiv:2402.06320.
Raphan, M. and Simoncelli, E. P. (2011). Least squares estimation without priors or supervision.
Neural Computation, 23(2):374–420.
Richter, L., Berner, J., and Liu, G.-H. (2024). Improved sampling via learned diffusions. In Interna-
tional Conference on Learning Representations.
Robbins, H. E. (1956). An empirical Bayes approach to statistics. In Proc. 3rd Berkeley Symp. Math.
Statist. Probab., 1956, volume 1, pages 157–163.
Salimans, T. and Ho, J. (2022). Progressive distillation for fast sampling of diffusion models. arXiv
preprint arXiv:2202.00512.
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S. (2015). Deep unsupervised
learning using nonequilibrium thermodynamics. In International Conference on Machine Learning.
Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021). Score-
basedgenerativemodelingthroughstochasticdifferentialequations. InInternational Conference on
Learning Representations.
Vargas, F., Grathwohl, W., and Doucet, A. (2023a). Denoising diffusion samplers. In International
Conference on Learning Representations.
Vargas, F., Ovsianas, A., Fernandes, D., Girolami, M., Lawrence, N. D., and Nu¨sken, N. (2023b).
Bayesian learning via neural Schr¨odinger–F¨ollmer flows. Statistics and Computing, 33(1):3.
Vincent, P. (2011). A connection between score matching and denoising autoencoders. Neural Com-
putation, 23(7):1661–1674.
Wang, L., Aarts, G., and Zhou, K. (2023). Generative diffusion models for lattice field theory. arXiv
preprint arXiv:2311.03578.
Wang, Z., Cheng, S., Yueru, L., Zhu, J., and Zhang, B. (2020). A Wasserstein minimum velocity
approach to learning unnormalized models. In International Conference on Artificial Intelligence
and Statistics.
Watson,J.L.,Juergens,D.,Bennett,N.R.,Trippe,B.L.,Yim,J.,Eisenach,H.E.,Ahern,W.,Borst,
A. J., Ragotte, R. J., Milles, L. F., et al. (2023). De novo design of protein structure and function
with RFdiffusion. Nature, 620(7976):1089–1100.
Yim, J., Trippe, B. L., De Bortoli, V., Mathieu, E., Doucet, A., Barzilay, R., and Jaakkola, T. (2023).
Se(3) diffusion model with application to protein backbone generation. In International Conference
on Machine Learning.
13Zhang,D.,Chen,R.T.Q.,Liu,C.-H., ,A.,andBengio,Y.(2023). Diffusiongenerativeflowsamplers:
Improvinglearningsignalsthroughpartialtrajectoryoptimization.arXivpreprintarXiv:2310.02679.
Zhang, Q. and Chen, Y. (2022). Path integral sampler: a stochastic control approach for sampling. In
International Conference on Learning Representations.
Zheng, S., He, J., Liu, C., Shi, Y., Lu, Z., Feng, W., Ju, F., Wang, J., Zhu, J., Min, Y., Zhang, H.,
Tang, S., Hao, H., Jin, P., Chen, C., No´e, F., Liu, H., and Liu, T.-Y. (2023). Towards predicting
equilibriumdistributionsformolecularsystemswithdeeplearning.arXivpreprintarXiv:2306.05445.
Appendix
InAppendixA,wepresenttheproofsofallthePropositionspresentedinthemainpaper. InAppendix
B, we present another proof of TSI (equation (5)) for additive Gaussian noise based on diffusion
techniques. In Appendix C we derive the variance of Monte Carlo estimates of the score based on
DSI and TSI in the Gaussian case. In Appendix D, we transpose the analysis of Karras et al. (2022)
developed to obtain a stable training loss for DDM to the TSM loss.
A Proofs of the Main Results
A.1 Proof of Proposition 2.1
For completeness, we present two proofs of this result (without any claim for originality).
First proof. We have Y =X+W, X and W being independent, so
(cid:90)
p (y)= p (y−w)p (w)dw,
Y X W
hence
(cid:90)
∇p (y)= ∇logp (y−w) p (y−w)p (w)dw.
Y X X W
It follows that
(cid:90) p (y−w)p (w)
∇logp (y)= ∇logp (y−w) X W dw
Y X p (y)
Y
(cid:90) p (x)p (y−x)
= ∇logp (x) X W dx
X p (y)
Y
(cid:90)
= ∇logp (x) p (x|y)dx.
X X|Y
Second proof. For this alternative proof, it is essential for clarity to emphasize notationally which
variable we differentiate with respect to. This proof starts from DSI and shows that we can recover
TSI. We have p (y|x)=p (y−x) so by the chain rule
Y|X W
∇ logp (y|x)=−∇ logp (y|x). (20)
y Y|X x Y|X
Now by Bayes rule, we have
logp (y|x)=logp (x|y)+logp (y)−logp (x). (21)
Y|X X|Y Y X
14Hence, from (21) and (20), we obtain directly
∇ logp (y|x)=∇ logp (x)−∇ logp (x|y). (22)
y Y|X x X x X|Y
Additionally, we have by the divergence theorem
(cid:90)
∇ logp (x|y) p (x|y)dx=0. (23)
x X|Y X|Y
The identity (5) follows directly by combining (2) with (22) and (23).
A.2 Proof of Proposition 2.3
We have
(cid:90)
ℓ (θ)= ∥sθ (y)−∇logp (y|x)∥2p (x,y)dxdy
DSM Y Y|X X,Y
(cid:90) (cid:90)
= ∥sθ (y)∥2p (y)dy−2 ⟨sθ (y),∇logp (y|x)⟩p (x,y)dxdy
Y Y Y Y|X X,Y
(cid:90)
+ ∥∇logp (y|x)∥2p (x,y)dxdy.
Y|X X,Y
From (22) and (23), we get
(cid:90) (cid:90)
⟨sθ (y),∇logp (y|x)⟩p (x,y)dx= ⟨sθ (y),∇logp (x)⟩p (x,y)dx
Y Y|X X,Y Y X X,Y
so it follows that
(cid:90) (cid:90)
ℓ (θ)= ∥sθ (y)∥2p (y)dy−2 ⟨sθ (y),∇logp (x)⟩p (x,y)dxdy
DSM Y Y Y X X,Y
(cid:90)
+ ∥∇logp (y|x)∥2p (x,y)dxdy
Y|X X,Y
(cid:90) (cid:90)
= ∥sθ (y)−∇logp (x)∥2p (y)dy− ∥∇logp (x)∥2p (x)dx
Y X Y X X
(cid:90)
+ ∥∇logp (y|x)∥2p (x,y)dxdy.
Y|X X,Y
The first term on the r.h.s. is equal to ℓ (θ) so the result follows.
TSM
A.3 Proof of Proposition 3.1
Combining (1) and (10), one has
(cid:90)
p (y)= p (x)F(Φ(y,x))dx
Y X
(cid:90)
= p (Φ−1(y,z))F(z)|det(∇ Φ(y,Φ−1(y,z))−1)|dz
X 2
(cid:90)
= p (Φ−1(y,z))|det(∇ Φ−1(y,z))|F(z)dz
X 2
15where we use the change of variables z =Φ(y,x). Hence, we have by the chain rule and the change of
variables x=Φ−1(y,z)
(cid:90)
∇logp (y)= [∇ Φ−1(y,z)⊤∇logp (Φ−1(y,z))+∇ log|det(∇ Φ−1(y,z))|]
Y 1 X y 2
×p (Φ−1(y,z))|det(∇Φ−1(y,z))|F(z)/p (y)dz
X Y
(cid:90)
= [∇ Φ−1(y,Φ(y,x))⊤∇logp (x)
1 X
+∇ log|det(∇ Φ−1(y,·))|(Φ−1(y,x))]p (x|y)dx.
y 2 X|Y
A.4 Proof of Proposition 3.2
Using that µ is left-invariant
(cid:90) (cid:90)
p (y)= p (x)F(y−1x)dµ(x)= p (R (y))F(x)dµ(x), (24)
Y X X x
where R (y) = yx for any x,y ∈ G. We have that dR (y)dR (yx) = Id. Therefore for any y ∈ G
x x x−1
and h∈T (G) we have
y
d(p ◦R )(y)(h)=dp (yx)dR (y)(h)=⟨∇p (yx),dR (y)(h)⟩=⟨dR (y)dR (yx)∇p (yx),dR (y)(h)⟩.
X x X x X x x x−1 X x
Finally, using that ⟨·,·⟩ is right-invariant we get for any y ∈G and h∈T (G)
y
d(p ◦R )(y)(h)=⟨dR (yx)∇p (yx),h⟩.
X x x−1 X
Combining this result and (24) we have
(cid:90)
∇p (y)= dR (yx)∇logp (yx)p (yx)F(x)dµ(x)
Y x−1 X X
(cid:90)
= dR (x)∇logp (x)p (x)F(y−1x)dµ(x).
x−1y X X
Hence, we get that
(cid:90)
∇logp (y)= dR (x)∇logp (x)p (x|y)dµ(x).
Y x−1y X X|Y
A.5 Proof of Proposition 3.4
It follows directly from (11) that
(cid:90)
p (y)= p (y−αx −(1−αx ))p (x )p (x )dx dx .
Y W 0 1 X0 0 X1 1 0 1
So by considering the change of variables w =y−αx −(1−α)x , i.e. x =α−1(y−(1−α)x −w),
0 1 0 1
we obtain
(cid:90)
p (y)=α−1 p (α−1(y−(1−α)x −w))p (w)p (x )dwdx .
Y X0 1 W X1 1 1
so, emphasizing here which variable we differentiate with for clarity, we get
∇ logp (y)
y Y
(cid:90) p (α−1(y−(1−α)x −w))p (w)p (x )
=α−1 ∇ logp (α−1(y−(1−α)x −w)) X0 1 W X1 1 dwdx
y X0 1 p (y) 1
Y
(cid:90) p (α−1(y−(1−α)x −w))p (w)p (x )
=α−2 ∇ logp (α−1(y−(1−α)x −w)) X0 1 W X1 1 dwdx
x0 X0 1 p (y) 1
Y
(cid:90) p (x )p (x )p (y−αx −(1−αx ))
=α−1 ∇ logp (x ) X0 0 X1 1 W 0 1 dx dx .
x0 X0 0 p (y) 0 1
Y
16The result (12) follows immediately and (13) is obtained similarly.
B Fokker–Planck derivation
So far our derivation of TSI (5) relies on ∇ logp (y|x) = −∇ logp (y|x). This identity is due
y Y|X x Y|X
to the additive nature of the noising process, i.e. Y = X +W with W independent from X. The
change of variables used in Proposition 3.1 uses implicitly the same property in the case of additive
noise. In what follows, we provide another derivation of TSI leveraging instead the Fokker-Planck
equation, the time-reversal of diffusions and backward Kolmogorov equation. We consider the case
where Y =X+W with W ∼N(0,σ2I).
In our setting, Y = X with t = σ, X = X and dX = dB , where (B ) is a d-dimensional
t0 0 0 t t t t≥0
Brownian motion. For any t ≥ 0, we denote by p the density of X . The Fokker-Planck equation
t t
shows that (p (x)) satisfies the heat equation
t t∈[0,t0]
∂p (x)= 1∆p (x), p (x)=p (x).
t 2 t 0 X
Hence, we have that
∂logp (x)= 1∆p (x)/p (x) (25)
t 2 t t
= 1∥∇logp (x)∥2+ 1∆logp (x).
2 t 2 t
If we denote F (x)=∇logp (x) then we obtain by differentiating (25) w.r.t. x that for any x∈Rd
t t0−t
and t∈[0,t ]
0
∂F (x)+∇F (x)F (x)+ 1∆F (x)=0.
t t t 2 t
Hence, using the backward Kolmogorov equation we get that for any y ∈Rd
F (y)=E[F (Z ) |Z =y], dZ =F (Z )dt+dB =∇logp (Z )dt+dB .
t t0 t0 t t t t t t0−t t t
As F =∇logp and F =∇logp , we get that
0 Y t0 X
∇logp (y)=F (y)=E[F (Z ) |Z =y]=E[∇logp (Z ) |Z =y]. (26)
Y 0 t0 t0 0 X t0 0
Finally, we notice that (Z ) =(X ) is the time-reversal of dX =dB (Cattiaux et al.,
t t∈[0,t0] t0−t t∈[0,t0] t t
2023). Hence, wegetthat(Z ,Z )admitsthesamedistributionas(Y,X). Combiningthisresultand
0 t0
(26) we obtain
∇logp (y)=E [∇logp (X)],
Y X|Y X
which corresponds to TSI.
C Combinining DSI and TSI Monte Carlo estimates
We consider a Gaussian target p (x) = N(x;0,σ2 I) as well as additive Gaussian noise p (x) =
X tar W
N(w;0,σ2I). Forα>0,wesetY =αX+W ∼N(0,(α2σ2 +σ2)I). Theposteriordensityappearing
tar
in DSI and TSI is given in this case by
p (x|y)=N(x;ασ2 /(α2σ2 +σ2)y,σ2σ2 /(α2σ2 +σ2)I).
X|Y tar tar tar tar
WecomputethevarianceoftheMonteCarloestimatesofthescoreobtainingbyaveraging∇logp (y|Xi)
Y|X
(DSI estimate) and ∇logp (Xi)/α (TSI estimate) over samples Xi ∼p (·|y). We have that
X X|Y
d d
(cid:88) (cid:88)
Var (∇ logp (y|X))= Var ((αX−y)/σ2)
X|Y i Y|X X|Y
i=1 i=1
=dα2(σ /σ)2/(α2σ2 +σ2).
tar tar
17On the other hand, we have that
d d
(cid:88) (cid:88)
Var (∇ logp (X)/α)= (1/α2)Var (−X/σ2 )
X|Y i X X|Y tar
i=1 i=1
=d(σ/σ )2/(α2σ2 +σ2).
tar tar
Hence we have
d d
(cid:88) (cid:88)
Var (∇ logp (y|X))≤ Var (∇ logp (X)/α)
X|Y i Y|X X|Y i X
i=1 i=1
if and only if σ2 ≤σ2/α. Again, this is aligned with our previous observations. For σ ≫1 then the
tar
variance of the DSI estimator is lower than the variance of the TSI estimator. For σ ≪ 1 then the
variance of the TSI estimator is lower than the variance of the DSI estimator.
We now consider any convex combination of the integrands appearing in DSI and TSI
Z =κ∇logp (Y|X)+(1−κ)∇logp (X)/α
Y|X X
=καX/σ2−(1−κ)X/(ασ2 )−κY/σ2
tar
=(κα/σ2−(1−κ)/(ασ2 ))X−κY/σ2
tar
=(1/ασ2 )(κ(1+α2σ2 /σ2)−1)X−κY/σ2.
tar tar
By construction, the expectation of Z under p (x|y) is equal to the score ∇ logp (y). In order to
X|Y y Y
minimize the variance of Z under p (x|y), we set κ = 1/(1+α2σ2 /σ2). Hence when σ ≫ 1 we
X|Y tar
get that κ=1 and when σ ≪1 we get that κ=0. In this specific Gaussian setting we have that the
estimator has actually zero variance since Z =−Y/(α2σ2 +σ2)=∇ logp (Y).
tar y Y
D Preconditioning the training loss
Inthissection,wefollowtheanalysis(Karrasetal.,2022,AppendixB.6)andderivearescaledtraining
loss for TSM from first principles for the additive model Y =αX+W.
In Karras et al. (2022), the input of the network is scaled by c and the output is scaled by c . An
i o
additional skip-connection is considered with weight c . Hence we have
s
sθ (y)=c F (σ,c y)+c y.
Y o θ i s
The total loss is weighted by λ>0 and we have
L(θ)=λℓ (θ)=λE [∥c F (σ,c Y)+c Y −α−1∇logp (X)∥2].
TSM X,Y o θ i s X
In (Karras et al., 2022, Appendix B.6) the hyperparameters λ,c ,c ,c are computed in the case of
i o s
the DSM loss with x -prediction using the following principles
0
(i) the input of the network F should have unit variance,
θ
(ii) the target of the regression loss should have unit variance,
(iii) the effective weighting of the loss defined as λc2 should be equal to one,
0
(iv) we choose c to minimize c so that the errors of the network are not amplified.
s o
For simplicity, we assume that p = N(0,σ2 I) and W ∼ N(0,σ2I). In this case, we have that
X tar
∇logp (x)=−x/σ2 . We then obtain
X tar
L(θ)=λE [∥c F (σ,c Y)+c Y +X/(ασ2 )∥2]
X,Y o θ i s tar
=λ/(ασ )4E [∥−(ασ )2c F (σ,c Y)−(ασ )2c Y −αX∥2]
tar X,Y tar o θ i tar s
=λ′E [∥c′F (σ,c′Y)+c′Y −αX∥2],
X,Y o θ i s
18where
λ′ =λ/(ασ )4, c′ =−(ασ )2c , c′ =−(ασ )2c , c′ =c . (27)
tar o tar o s tar s i i
We emphasize that λ′(c′)2 =λc2. Therefore, the rescaled effective weight is the same as the effective
o o
weight described in Karras et al. (2022).
Using (Karras et al., 2022, (117), (131), (138),(144)), we get
λ′ =(σ2+α2σ2 )/(ασσ )2, c′ =ασσ /(σ2+α2σ2 )1/2,
tar tar o tar tar
(cid:113)
c′ =α2σ2 /(α2σ2 +σ2), c =1/ σ2+α2σ2 .
s tar tar i tar
Hence, combining this result and (27) we get that
λ=α2σ2 (σ2+α2σ2 )/σ2, c =−σ/[ασ (σ2+α2σ2 )1/2],
tar tar o tar tar
(cid:113)
c =−1/(σ2+α2σ2 ), c =1/ σ2+α2σ2 .
s tar i tar
Using (Karras et al., 2022, (151)), we get that the variance of λ∥c F (σ,c y)+c y+x/(ασ2 )∥2 is
o θ i s tar
equal to one for every time σ,α > 0, at initialization for F = 0. In the general case, using the
θ
hyperparameters λ,c ,c ,c we get
i s o
L(θ)=σ2 (σ2+α2σ2 )/σ2E [∥σF (σ,Y/(σ2+α2σ2 )1/2)/[σ (σ2+α2σ2 )1/2]
tar tar X,Y θ tar tar tar
+αY/(σ2+α2σ2 )+∇logp (X)∥2].
tar X
The score network is then given by
sθ (y)=−(1/α)[σF (σ,y/(σ2+α2σ2 )1/2)/σ (σ2+α2σ2 )1/2+α2y/(α2σ2 +σ2)].
Y θ tar tar tar tar
19