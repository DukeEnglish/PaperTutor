: A Hierarchical Framework for
Aggregation of Reasoning
Enhancing Answer Selection in Large Language Models
Zhangyue Yin♢, Qiushi Sun♡, Qipeng Guo⋆, Zhiyuan Zeng♢
Xiaonan Li♢,Tianxiang Sun♢,Cheng Chang♢,Qinyuan Cheng♢,
Ding Wang♣,Xiaofeng Mou♣,Xipeng Qiu♢(cid:0),Xuanjing Huang♢
♢SchoolofComputerScience,FudanUniversity♡NationalUniversityofSingapore
⋆ShanghaiAILaboratory♣MideaAIResearchCenter
{yinzy21,cengzy23,changc21,chengqy21}@m.fudan.edu.cn qiushisun@u.nus.edu
guoqipeng@pjlab.org.cn {ding2.wang, mouxf}@midea.com
{lixn20,txsun19,xpqiu,xjhuang}@fudan.edu.cn
Abstract
RecentadvancementsinChain-of-ThoughtpromptinghavefacilitatedsignificantbreakthroughsforLargeLanguage
Models(LLMs)incomplexreasoningtasks. CurrentresearchenhancesthereasoningperformanceofLLMsby
samplingmultiplereasoningchainsandensemblingbasedontheanswerfrequency. However,thisapproachfailsin
scenarioswherethecorrectanswersareintheminority. Weidentifythisasaprimaryfactorconstrainingthereasoning
capabilitiesofLLMs,alimitationthatcannotberesolvedsolelybasedonthepredictedanswers. Toaddressthis
shortcoming,weintroduceahierarchicalreasoningaggregationframeworkAoR(AggregationofReasoning),which
selectsanswersbasedontheevaluationofreasoningchains. Additionally,AoRincorporatesdynamicsampling,
adjustingthenumberofreasoningchainsinaccordancewiththecomplexityofthetask. Experimentalresultson
aseriesofcomplexreasoningtasksshowthatAoRoutperformsprominentensemblemethods. Furtheranalysis
revealsthatAoRnotonlyadaptsvariousLLMsbutalsoachievesasuperiorperformanceceilingwhencomparedto
currentmethods.
Keywords:LargeLanguageModels,ComplexReasoning,ReasoningChainsEvaluation
1. Introduction
Question: The difference between simple interest and C.I. at the
same rate for Rs.5000 for 2 years in Rs.72. The rate of interest is?
Large Language Models (LLMs) have driven re- Answer Choices: (A) 10% (B) 12% (C) 6% (D) 8% (E) 4%
markable advancements across various Natural
: Let the rate of interest be r%. : Let the rate of interest be
LanguageProcessing(NLP)tasks(OpenAI,2023; The compound interest would be r. ..|(5000 * r / 100) * 2 - 5000 *
Chowdhery et al., 2022; Touvron et al., 2023a,b; 5𝑹𝑹0𝟏𝟏 00[(1 + r/100)^2 - 1]… Solving 𝑹𝑹( (𝟐𝟐 1 + r/100)^2 - 1)| = 72.
this quadratic equation gives us r Simplifying this equation gives r =
Huangetal.,2022;Zhaoetal.,2023). Nonetheless, = 10%. So the answer is (A). 12. So the answer is (B). 
thereremainsadiscerniblegapbetweentheperfor-
: Let the rate of interest be r. : Let the rate of interest be x%.
manceofthesemodelsandhuman-levelexpertise The difference between simple The simple interest for 2 years
inreasoningtasks(Cobbeetal.,2021;Valmeekam
𝑹𝑹in𝟑𝟑
terest and compound interest
𝑹𝑹w𝟒𝟒
ould be (5000 * 2 * x) / 100 =
at the same rate for 2 years… 100x… So, 5000 * (1 + x/100)^2 -
et al., 2022), which cannot be bridged merely by
Since the rate of interest cannot 5000 - 100x = 72. Solving this
increasingthemodel’sscale(Raeetal.,2022). In
be negative, the answer is 6%. So equation, we get x = 6%. So the
thiscontext,theadventofChain-of-Thought(CoT) the answer is (C). answer is (C).
prompting(Weietal.,2022b)techniqueheraldsa : C.I. - Simple Interest = 72…
Correct Answer: (B).
Since interest cannot be negative,
stridetowardsmitigatingthisdisparity. Ratherthan 𝑹𝑹w𝟓𝟓 e take the solution r = 8%. So Majority Vote: (C).
employing“answer-only”prompts,CoTdrivesLLMs the answer is (D).
togenerateaseriesofintermediatestepsthatlead
to the final answer. By decoupling the problem- Figure1: AnillustrativeexamplefromAQuA(Ling
solvingprocess,CoTnotonlysimplifiesthecom- et al., 2017), with 5 reasoning chains generated
plexityofeachstepbutalsooffersanovelperspec- through temperature sampling. Although LLM is
tivetoaddressingcomplexreasoningtasks. abletogeneratethecorrectanswer,majorityvoting
Beyond the inherent limitations of LLMs (Yin ultimately selects an incorrect answer due to the
et al., 2023b), Wang et al. (2023d) observe that abundanceofincorrectanswers.
theCoTexhibitsrandomnesswhenutilizingasin-
gle reasoning chain. As a remedy, they propose
Thisensembleapproachbasedonmajority-voting
modulatingthesamplingtemperaturetocollecta
has not only elevated the reasoning capability of
diverse set of reasoning chains, and then select
LLMs but has also emerged as the predominant
themostconsistentanswerasthefinalprediction.
paradigmforLLMsinreasoningtasks(Chuetal.,
2023;Yuetal.,2023).
(cid:0) Correspondingauthor.
4202
yaM
12
]LC.sc[
1v93921.5042:viXraw. Correct Answers w/o. Correct Answers
18.4%
3.9% 7.0% 3.7%
AQuA CSQA Date Understanding Penguins
(Arithmetic) (Commonsense) (Symbolic) (Symbolic)
96.1% 93.0% 96.3%
81.6%
Figure2: ProportionofsamplesthatcorrectanswersappearinginLLMs’generationsamongthosewhere
majorityvotingresultsinanincorrectoutcomeacrossvariousreasoningtasks.
However, when confronted with more complex process. In the first phase: local-scoring, chains
questions, LLMs often waver among multiple an- yielding identical answers are evaluated. Since
swers. A dilemma arises when the incorrect an- theanswersareconsistent,theevaluationplaces
swersoutnumberthecorrectones. EveniftheLLM greateremphasisonthesoundnessofthereason-
iscapableofgeneratingtherightanswer,themajor- ingprocessandtheappropriatenessofthereason-
ityvotingmechanismremainssusceptibletoskew- ingsteps. Forthesecondphase: global-evaluation,
ingthefinalpredictiontowardsanerroneousone. themostlogicallycoherentandmethodicallyvalid
Figure1showcasesanillustrativeexamplefromthe chainsfromdifferentanswergroupsarejointlyas-
AQuAdataset(Lingetal.,2017). Amongthefive sessed. Theobjectiveistoidentifythereasoning
sampledreasoningchains,fourcandidateanswers: chainthatbestexhibitscoherenceandconsistency
(A),(B),(C),and(D)aregenerated. WhiletheLLM betweenthereasoningprocessanditscorrespond-
is capable of generating the correct answer (B) inganswer,therebydesignatingthisanswerasthe
in R , the overwhelming presence of erroneous finaloutput.
2
candidates eventually led to the selection of the Furthermore,leveragingthescoresderivedfrom
incorrectanswer(C). theglobalevaluationphase,AoR canestimatethe
Toexplorethisphenomenon,weconductapilot currentconfidenceleveloftheLLMinitsoptimal
analysisonsamplesspanningvariousreasoning reasoning process and answer. This allows AoR
tasks, where the majority voting results in incor- to dynamically decide whether it is necessary to
rectpredictions. AsdepictedinFigure2,over80% sampleadditionalreasoningchains. Experimental
of the samples that LLM has the potential to an- resultsacrossvariousreasoningtasksdemonstrate
swercorrectly,butmajorityvotingfails. Notably,in AoR’seffectivenessinsignificantlyenhancingthe
AQuA (Ling et al., 2017) and Penguins (Suzgun reasoning performance of LLMs. Benefited from
etal.,2023)datasets,thisproportionexceeds95%. dynamicsampling,whichdeterminesthenumber
Thesefindingsindicatethatensemblingreasoning ofsamplingandevaluationsbydistinguishingbe-
chains,whichreliesonthefrequencyofanswers, tween easy and challenging samples, AoR also
stillhassignificantroomforimprovement. effectivelycurtailstheLLM’sreasoningoverhead,
Motivatedbytheobservedlimitations,wepose establishingabalancebetweenperformanceand
thecentralresearchquestionofthiswork: “When computationalcost.
LLMsarecapableofgeneratingthecorrectanswer, Themaincontributionsarelistedbelow:
howcanwemitigatetheinterferenceofincorrect
• Weidentifythattheexistingensemblemech-
answerstoaccuratelyselecttherightone?” Insitu-
anism, which solely relies on the frequency
ationspollutedbyamyriadoferroneouspredictions,
of answers, is insufficient. This observation
relyingexclusivelyontheanswersthemselvespro-
underscorestheimportanceofincorporating
videslimitedinsightforenhancedaccuracy. Con-
thereasoningprocess,leadingtothedesign
sequently,itbecomesbothessentialandpromising
of our hierarchical reasoning process aggre-
tofocusontheprocessleadingtotheseanswers:
gationframeworkAoR.
the reasoning chains. Thus, we introduce a hi-
erarchicalreasoningaggregationframeworkAoR • Leveragingtheevaluationscoresof theopti-
(AggregationofReasoning),designedtoharness malreasoningchains,AoR integratestheabil-
theLLM’sabilitytoevaluatereasoningprocesses ity to dynamically sample reasoning chains,
inordertoimprovetheselectionofthefinalanswer. efficientlyminimizingthereasoningoverhead.
Specifically,giventheconstraintsofLLM’scon-
• Extensive experimental results demonstrate
textwindow(Liuetal.,2023a)thatpreventssimul-
AoR’s superior performance and cost effi-
taneousevaluationofallreasoningchains,AoRini-
ciencycomparedtoexistingreasoningchain
tiatesbyaggregatingchainsbasedontheirrespec-
ensemblemethods.
tive answers followed by a two-phase evaluationAoR Self-Consistency ComplexSC PHP DiVeRSe
Feature
(ourwork) (Wangetal.,2023d) (Fuetal.,2023b) (Zhengetal.,2023) (Lietal.,2023b)
TaskAgnostic? ✓ ✓ ✓ ✗ ✓
Training-Free? ✓ ✓ ✓ ✓ ✗
Plug-and-Play? ✓ ✓ ✓ ✗ ✗
DynamicSampling? ✓ ✗ ✗ ✓ ✗
Table1: AcomparisonofAoR tootherreasoningchainsensemblemethods.
2. Related work emergence of strategies encouraging interaction
among reasoning chains (Yin et al., 2023a) or
Reasoning with Chain-of-Thought. Chain-of-
transformingLLMsintomultipleagentstobenefit
Thought (CoT; Wei et al., 2022b) prompting has
fromdiversecognitiveprocesses(Sunetal.,2023).
emerged as a pivotal technique for eliciting rea-
A comparison of AoR with some representative
soning capabilities in LLMs (Zhao et al., 2023;
reasoningchainensemblemethodsispresented
Liangetal.,2023). Whenguidedbysamplesen-
in Table 1. Notably, our method is task-agnostic
richedwithexplicitreasoningsteps,LLMscanpro-
and does not require additional annotation for
duce a series of intermediate steps culminating
training. Thisplug-and-playcharacteristic,coupled
in a multi-step solution (Zhou et al., 2023). Re-
with dynamic sampling, ensures the functionality
markably, CoT can enhance the performance of
andcost-effectivenessofourmethod.
LLMsinreasoningtaskswithoutnecessitatingad-
ditionaltraining(HuangandChang,2022;Minetal.,
2022). This characteristic has swiftly garnered EvaluationCapabilityofLLMs. Theautomated
widespreadattention(Qiaoetal.,2023;Chuetal., evaluationcapabilityofLLMshasrecentlybecome
2023), with several studies attributing this phe- aprominentpointofresearch(Hackletal.,2023;
nomenontotheemergentcapabilitiesintrinsicto Hada et al., 2023; Zhu et al., 2023). Liu et al.
LLMs(Weietal.,2022a;Kaplanetal.,2020). Sub- (2023d)andWangetal.(2023a)discoverthatLLMs
sequentresearchhasconcentratedonstrengthen- have the potential to produce evaluation results
ingtheconsistencybetweenreasoningpathsand consistentwithhumanexperts. ChiangandyiLee
answers(Chenetal.,2022;Gaoetal.,2022),au- (2023a)andShenetal.(2023)furtherunderscores
tomatingtheconstructionofprompts(Zhangetal., the stability and reliability of assessments gener-
2023;Lietal.,2023a;Diaoetal.,2023),eliciting atedbyLLMs. KocmiandFedermann(2023)and
externalknowledge(Wangetal.,2023b;LiandQiu, Liuetal.(2023c)conductacomparativestudybe-
2023)andprogressivelyrefiningthereasoningpro- tweenLLM-basedevaluationmethodsandexisting
cesses (Yao et al., 2023; Besta et al., 2023; Sel automatedevaluationmetrics. Theirresultsshow-
etal.,2023;Hanetal.,2023;Liuetal.,2023b). casethatevaluationsderivedfromLLMssurpassed
allcurrentautomatedbenchmarks,indicatingthe
exceptionalevaluationcapabilitiesofLLMs. More-
Ensemble of Multiple Reasoning Chains.
over,theutilizationofLLMsforassessmentoffers
Wang et al. (2023d) identify the randomness in
several advantages including customizability (Fu
the CoT’s single-chain sampling process and
et al., 2023a), a diversity of evaluation perspec-
subsequently propose the Self-Consistency
tives (Chen et al., 2023), and training-free (Luo
method. Thisapproachentailssamplingmultiple
et al., 2023). Given the remarkable evaluation
reasoningchainsandselectingthemostfrequently
prowessofLLMs(Chanetal.,2023;Chiangand
occurring answer as the final output, which lays
yiLee,2023b;Gaoetal.,2023),weintegratethis
the foundation for a series of reasoning chain
capabilityintotheaggregationofreasoningchains,
ensemble methods. Fu et al. (2023b) observe
enablingamoreaccurateassessmentandselec-
a positive correlation between the complexity of
tionofthereasoningprocessesandanswers.
reasoning chains and the accuracy of generated
answers. Based on this insight, they propose
filteringreasoningchainsbasedontheircomplexity
3. Preliminary
beforeemployingamajorityvotingmechanismfor
theanswers. Furthermore,Lietal.(2023b)traina
verifiertoscoreeachreasoningchain. Theanswer Inthissection,weprovidedefinitionsforstandard
corresponding to the highest-scoring reasoning prompting and CoT Prompting. Additionally, we
chain is selected as the final output. From a detail the voting procedure of Self-Consistency.
differentperspective,Zhengetal.(2023)suggest These foundational concepts serve as a ground-
using previously generated answers as hints to workforAoR.Consideringascenariowherethere
guide LLMs toward producing accurate answers. isaquestion,denotedasQ,alongwithaprompt,
Furthermore,recentadvancementshaveseenthe denotedasT,andaLLM,denotedasP .
MQQuueessttiioonn:: TThhee ddiiffffeerreennccee bbeettwweeeenn ssiimmppllee iinntteerreesstt aanndd CC..II.. aatt tthhee ssaammee rraattee ffoorr RRss..55000000 ffoorr 22 yyeeaarrss iinn RRss..7722.. TThhee rraattee ooff iinntteerreesstt iiss??
AAnnsswweerr CChhooiicceess:: ( (AA)) 1 100%% ( (BB)) 1 122%% ( (CC)) 6 6%% ( (DD)) 8 8%% ( (EE)) 4 4%%
: Let the rate of interest be : Let the rate of interest be r. Local-Scoring
r%. The compound interest Then, according to the given
𝑹𝑹w𝟏𝟏o uld be 5000[(1 + r/100)^2 - 𝑹𝑹in𝟐𝟐formation, |(5000 * r / 100) * 2 Prompt: Evaluate the solution process for the problem using the criteria below, with a
1]… So the answer is (A). - 5000 * ( (1 + r/100)^2 - 1) |= maximum score of 10 points:
72… So the answer is (B). • Logical Consistency (3 points)
• Appropriateness of Method (3 points)
• Completeness and Clarity (2 points)
• Application of Knowledge (2 points)
𝑹𝑹𝟎𝟎
𝑹𝑹𝟏𝟏
𝑹𝑹𝟔𝟔
𝑹𝑹𝟐𝟐
R Re ea spso on ni sn eg
:
(Cha ,i n 8:
) ,
(、
, 7).
𝑹𝑹𝟏𝟏 Answer: (A) 𝑹𝑹𝟐𝟐Answer: (B) 𝑹𝑹𝟐𝟐 𝑹𝑹𝟐𝟐 𝑹𝑹𝟔𝟔𝑹𝑹𝟔𝟔 𝜀𝜀≤ 𝑺𝑺𝟔𝟔 < 𝑺𝑺𝟐𝟐 𝑹𝑹𝟐𝟐
Global-Evaluation
: The difference between : The interest earned after 2
𝑹𝑹s inim 𝟑𝟑tep rele s ti n at te tr he est s a an md e c ro am tep fo ou rn 2d 𝑹𝑹y 5e 0𝟖𝟖a r,r …s w 5ro /u 2l d - 5b 0e 0 5 00 =0 0 7 2r …/100 = P Or no lym op nt: e M ofu tl hti ep sle e s ao nl su wti eo rn s p isr o cc oe rs rese cts . a Er ve a p lur ae ts ee n et ae cd h b se ol lo uw ti, o e na pc rh o l ce ea sd s i bn ag s t eo d a o d ni :fferent answer.
years… So the answer is (C). r = 8%. So the answer is (D). • Validity of Approach (3 points)
• Consistency of Steps and Answer (3 points)
• Completeness and Clarity (2 points)
• Application of Knowledge (2 points)
𝑹𝑹𝟑𝟑 𝑹𝑹𝟓𝟓 Reasoning Chain: 、 、 、
𝑹𝑹𝟕𝟕 𝑹𝑹𝟑𝟑 𝑹𝑹𝟖𝟖 𝑹𝑹𝟖𝟖 Response: ( , 5),
𝑹𝑹
(
𝟏𝟏
, 𝑹𝑹7 𝟐𝟐), ( 𝑹𝑹𝟑𝟑, 6),
𝑹𝑹
(
𝟖𝟖
, 5). 𝒁𝒁𝟏𝟏 = 𝒁𝒁𝟖𝟖 < 𝒁𝒁𝟑𝟑 < 𝒁𝒁𝟐𝟐
𝑹𝑹𝟒𝟒 Answer: (C) 𝑹𝑹A𝟗𝟗nswer: (D) 𝑹𝑹𝟏𝟏 𝑹𝑹𝟐𝟐 𝑹𝑹𝟑𝟑 𝑹𝑹𝟖𝟖
𝒁𝒁𝟐𝟐 − 𝒁𝒁𝟑𝟑 <𝜽𝜽
Figure3: AnillustrativeexampledetailingtheAoR workflow. Initially,10reasoningchainsaresampled.
During the local-scoring phase, reasoning chains with identical answers are compared, filtering out
high-qualitychainsR ,R ,R ,andR forglobalevaluation. Intheglobal-evaluationphase,R receives
1 2 3 8 2
thehighestscore,butthescoremarginbetweenR andR failstosurpassthethresholdθ.
2 3
Standard Prompting. Under standard prompt- {(R ,A ),(R ,A ),...,(R ,A )}. Wedefinethe
1 1 2 2 n n
ing,LLMtakesthequestionQandthepromptT as set of answers as {A} = {A ,A ,...,A }. The
1 2 n
inputs. Itthensequentiallygenerateseachtoken finalanswerA∗ isdeterminedbyselectingthean-
oftheanswerA,aimingtomaximizethelikelihood swerthatappearsmostfrequentlywithin {A}.
ateachstep.
A∗ =argmax∣{(R ,A )∣A =a}∣ (5)
i i i
∣A∣ a
P(A∣T,Q)=∏P M(a
i
∣T,Q,a <i) (1)
i=1 4. Methodology
CoT Prompting. CoT (Wei et al., 2022b) en- 4.1. Overview
hances the prompt T by integrating the problem-
solvingprocessandguidingtheLLMtogeneratea The AoR approach to aggregating reasoning
rationaleRbeforegeneratingtheanswerA. We primarily unfolds in two stages: local-scoring
refertothepair (R,A)asareasoningchain. and global-evaluation. Firstly, we utilize CoT
to sample n reasoning chains, represented as
{(R ,A ),(R ,A ),...,(R ,A )}. Supposing
1 1 2 2 n n
P(R,A∣T,Q)=P(A∣T,Q,R)P(R∣T,Q), there are m unique answers generated, denoted
(2) as {a ,a ,...,a }, we categorize them into m
1 2 m
distinct buckets. The jth bucket is defined as
whereP(R∣T,Q)andP(A∣T,Q,R)aredefined {(R ,A ) ∣ A = a }. In the local-scoring phase,
i i i j
asfollows: wescorethereasoningchains (R ,A )withineach
i i
bucket. The top k chains, based on their scores,
areselectedasrepresentativesforthebucket. In
∣R∣
theglobal-evaluationphase,arepresentativeisse-
P(R∣T,Q)=∏P M(r
i
∣T,Q,r <i) (3)
lected from each of the buckets for assessment.
i=1
Afterk roundsofevaluations,thebucketwiththe
∣A∣
highestaveragescoredeterminesthefinaloutput.
P(A∣T,Q,R)=∏P M(a
i
∣T,Q,R,a <j) (4)
Figure3providesanillustrativeexample. Although
j=1
incorrectanswers(C)and(D)areinthemajority,
thetwo-phaseprocessoflocal-scoringandglobal-
Self-Consistency. Self-Consistency(Wangetal., evaluation accurately discerns and attributes the
2023d)employsCoTtosamplenreasoningchains: highestscoretothecorrectanswer(B).Let the rate of interest be r%. Then, the simple Criteria: Logical Consistency … Prompt: Multiple solution processes are
𝑹𝑹𝟏𝟏𝟏𝟏 interest for 2 years would be (5000 * 2 * r) / 100 = presented below, …
Demonstration: ,
100r. The compound interest for 2 years would be … Criteria: Validity of Approach (3 points),
Response:
So the answer is (A). (𝑹𝑹𝟏𝟏,𝟓𝟓) 𝑹𝑹𝟏𝟏,𝟕𝟕 Consistency of Steps and Answer (3 points),
𝑹𝑹𝟏𝟏𝟏𝟏,𝟔𝟔 Completeness and Clarity (2 points),
𝑺𝑺𝟏𝟏𝟏𝟏 < 𝑺𝑺𝟏𝟏 Application of Knowledge (2 points) …
Let the rate of interest be x%. The simple interest
Criteria: Logical Consistency …
𝑹𝑹𝟏𝟏𝟏𝟏for 2 years would be 5000 * x * 2 / 100 = 100x. The
Demonstration: ,
compound interest for 2 years would be … So the Response: ( , 9). R𝑹𝑹 es𝟏𝟏 pons𝑹𝑹 e:𝟏𝟏 𝟏𝟏 𝑹𝑹𝟑𝟑 𝑹𝑹𝟖𝟖 𝑹𝑹𝟏𝟏𝟏𝟏
answer is (B). (𝑹𝑹𝟏𝟏,𝟖𝟖) 𝑹𝑹𝟔𝟔,𝟕𝟕
𝑹𝑹𝟏𝟏𝟏𝟏
𝑺𝑺𝟖𝟖 < 𝑺𝑺𝟏𝟏𝟏𝟏 𝑹𝑹𝟏𝟏,𝟔𝟔 , 𝑹𝑹𝟏𝟏𝟏𝟏,𝟗𝟗 , 𝑹𝑹𝟑𝟑,𝟓𝟓 , 𝑹𝑹𝟖𝟖,𝟓𝟓 , 𝑹𝑹𝟏𝟏𝟏𝟏,𝟕𝟕
𝑹𝑹𝟏𝟏𝟏𝟏Let the rate of interest be r. Then we know that … Criteria: Logical Consistency … 𝒁𝒁𝟑𝟑 = 𝒁𝒁𝟖𝟖 < 𝒁𝒁𝟏𝟏 < 𝒁𝒁𝟏𝟏𝟏𝟏 < 𝒁𝒁𝟏𝟏𝟏𝟏
So the rate of interest is 1.2%. Therefore, the Demonstration: 
answer is (E). Response: ( , 7).
𝑹𝑹𝟏𝟏𝟏𝟏𝑵𝑵𝑵𝑵𝑵𝑵𝑵𝑵 𝒁𝒁𝟏𝟏𝟏𝟏 − 𝒁𝒁𝟏𝟏𝟏𝟏 ≥𝜽𝜽 𝑹𝑹𝟏𝟏𝟏𝟏
𝜀𝜀≤ 𝑺𝑺𝟏𝟏𝟏𝟏
Sampling Local-Scoring Global-Evaluation
Figure4: Illustrationofthedynamicsamplingprocess,wheresolidcirclesrepresentreasoningchains
and hollow circles their respective scores. Due to the minimal score difference between R and R ,
2 3
threeadditionalchainsR ,R ,andR aresampled,yieldinganswers(A),(B),and(E).R andR
10 11 12 10 11
are compared against chains with matching answers. R fails to outscore R , while R surpasses
10 1 11
R , advancing to global evaluation. R , introducing a new answer (E), exceeds the threshold ϵ and
8 12
progresses. In the global evaluation, R outperforms others, and with its score difference with R
11 12
exceedingθ,thusanswer(B)isselectedasthefinaldecision.
Local-Scoring. Local-scoringfocusesonselect- b(j) =(R(j),A(j) ).
ing high-quality reasoning chains within a group Representativesfromeachbucketaresequen-
sharingthesameanswer. Whilefixingtheanswer, tially chosen for k rounds of scoring. Ultimately,
the evaluation can place a heightened emphasis thebucketj∗ withthehighestaveragescoredeter-
on the rigor of the rationale logic and the appro- minesthefinalanswer. Ifthenumberofrepresenta-
priateness of the reasoning steps. Let’s assume tivesinabucketislessthank,previouslyselected
there are n reasoning chains leading to the an- itemsareresampledtomeettherequiredcount.
j
swer a , denoted as (R(j),A(j) ),...,(R(j),A(j) ),
collectij velyformingbuck1
etj.
1 nj nj
muW ltah ne en ot uh se ls ye ,gn uj idit ee dm bs ya ere vain lup au tit oi nnt co rit th ee riaLL inM ths ei- j∗ =arg jmax k1 ∑ t=k 1Z t(j) (6)
prompt T , the LLM assigns a score S(j) to each It’sworthnotingthatrepresentativesfromeach
1 i
R(j). Based on a predefined threshold ϵ, high- bucketarehigh-qualityreasoningchainsbearing
i
qualitychainsareidentifiedas {(R(j),A(j) )∣S(j) ≥ scores that are identical or closely aligned, each
i i i showcasingitsuniqueadvantages. Consequently,
ϵ}. From this refined set, the top k items are se-
conductingmultipleroundsofscoringnotonlymiti-
lectedasrepresentativesofbucketj,denotedas
gatestherandomnessinsingle-roundevaluations
B(j) . If no item satisfies S(j) ≥ ϵ, then B(j) is
topk i topk butalsoensuresacomprehensiveassessment.
an empty set, and items from this bucket will be
excludedfromtheglobal-evaluationphase.
4.2. Dynamic Sampling
Global-Evaluation. Global-evaluationistasked Leveragingthescoresfromtheglobal-evaluation
with distinguishing and selecting the reasoning phase, AoR dynamically adjusts the sampling of
chainamongdifferentanswers,aimingtopinpoint reasoningchainsbasedontheLLM’sconfidence
theonethatdemonstratesoptimalcoherenceand in the optimal reasoning chain. This process be-
consistency between the reasoning process and ginsbyidentifyingtwokeyanswers: Aα,whichhas
itsoutcome. Assumingthatwehavembuckets. A the highest average score Z¯α, and Aβ, with the
representativeischosenfromeachbucket,form- second-highestaveragescoreZ¯β. Drawinginspi-
ing a set ⋃m {b(j) ∣b(j) ∈ B(j) }. When these rationfromRothandSmall(2006),weconsiderthe
j=1 topk
m representatives are fed into the LLM concur- margin Z¯α−Z¯β. If thismarginexceedsaprede-
rently,guidedbyevaluationcriteriaencapsulated fined threshold θ, it signifies a substantial quality
inpromptT ,theLLMassignsascoreZ(j) toeach discrepancybetweenthetoptworeasoningchains,
2leadingtotheselectionofAα asthefinalanswer Baselines. WecompareAoRwithseveralstrong
andterminatingthesamplingprocess. baselines detailed in Section 2. These include
IfZ¯α−Z¯β <θ,AoRproceedstosampleanad- Chain-of-Thought prompting (CoT; Wei et al.,
ditionaldreasoningchains. Thesenewchainsun- 2022b), Complexity-based prompting (Complex-
dergoevaluationagainstestablishedbenchmarks CoT;Fuetal.,2023b),Self-Consistency(SC;Wang
to calculate their scores {S n+1,S n+2,...,S n+d}. etal.,2023d),Complexity-basedConsistency(CC;
Thesescoresdeterminetheirinfluenceontheex- Fuetal.,2023b),Progressive-HintPrompting(PHP;
isting answer hierarchy. If S n+1 is either beneath Zhengetal.,2023)andDiVeRSe(Lietal.,2023b).
thethresholdθ ordoesnotsurpasstheminimum Inourexperiments,weadheretothesettingsof
score within the top k scores of its answer cate- Self-Consistency (Wang et al., 2023d) and sam-
gory, the sampled chain (R n+1,A n+1) does not pled 40 reasoning chains, denoted as (40). Re-
affecttheoverallranking. Conversely,ifasampled gardingnotations,CoTandComplexCoTrepresent
chainintroducesanewanswerA n+1 = a m+1 sat- prompt exemplars with different reasoning com-
isfied threshold θ or significantly alters the score plexities,whileSC,CC,PHP,andDiVeRSesignify
ranking within B , a re-evaluation during the variousmethodsofreasoningchainensemble. For
topk
global-evaluation phase is necessitated to recal- instance,thenotationCoT-SC(40)signifiesthat40
ibratescores. reasoningchainsaregeneratedusingCoTprompts,
Dynamicsamplingceasesoncetheconfidence followedbytheapplicationoftheSelf-Consistency
margin between the two leading answers meets method. For all baselines, we follow their official
orexceedsθ orwhenthetotalnumberofsampled implementationsforfaircomparison.
chainsreachesapredefinedmaximumn . As
max
illustratedinFigure4,wepresentastraightforward BackboneLLMs. Inthemainexperiments, we
instanceofdynamicsampling,inwhichtheaccu- employ GPT-3.5-Turbo-0301. In the discus-
racyofthefinaldecisionisenhancedbyintegrating sion part, we introduce a broader variety of
anadditionalreasoningchain,confidentlypinpoint- models, including GPT-4-0314, Claude-2, and
ing answer B during the global evaluation phase. theopen-sourcemodelLLaMA-2-70B-Chatand
This flexible method guarantees a more efficient Mixtral-8x7B.WeaccessmodelsfromOpenAI
assessment,reducingunnecessarycomputational and Anthropic using their official APIs, while for
effortsonclear-cutcasesandfocusingmorerigor- LLaMA-2-70B-ChatandMixtral-8x7B,weuti-
ouslyonanalyzingqueriesthatarecomplexorhave lizedmodelweightsandcodeprovidedbyTouvron
ambiguousinterpretations. Byadjustingthedepth etal.(2023b)andJiangetal.(2024).
ofevaluationaccordingtotheestimatedcomplex- When sampling various reasoning chains, we
ityofeachtask,AoR efficientlybalancesprecision configurethetemperaturesettingdifferentlyacross
initsoutcomeswithoptimaluseofcomputational modelstooptimizetheirperformance. Specifically,
resources. forGPT-3.5-Turbo,GPT-4,andClaude-2,we
maintain a temperature of 1. For LLaMA, we ad-
heretoitsofficialrecommendationbysettingthe
5. Experiment
temperatureat0.6,andforMistral,weoptfora
temperatureof0.7toachieveoptimalperformance.
5.1. Experimental Setup
By default, AoR initially samples 20 reasoning
TasksandDatasets. Weconductacomprehen- chains, implementing a dynamic sampling strat-
sive evaluation of AoR across three types of rea- egywith anupperlimit ofn = 40 anda batch
max
soning tasks. (1) Mathematical reasoning in- size b = 5, collectively referred to as AoR(20,40).
corporates six representative datasets, namely Duringthelocalscoringphase,wedefinearepre-
GSM8K(Cobbeetal.,2021),MultiArith(Royand sentative count of k = 3 and a scoring threshold
Roth, 2015), SingleEQ (Koncel-Kedziorski et al., of ϵ = 6. For dynamic sampling, we establish a
2016),SVAMP(Pateletal.,2021),AddSub(Hos- terminationcriterionwithathresholdofθ =2,and
seini et al., 2014), and AQuA (Ling et al., 2017). witheachiteration,wesampleanadditional5rea-
(2) Commonsense reasoning covers Strate- soning chains. Moreover, we utilize the best and
gyQA (Geva et al., 2021), CommonsenseQA worst reasoning chains within the same answer
(CSQA; Talmor et al., 2019), BoolQ (Clark et al., as evaluation benchmarks to evaluate the newly
2019), and AI2 Reasoning Challenge (ARC- sampled reasoning chains. Our implementation
C) (Clark et al., 2018). (3) Symbolic reason- detailsandhyperparametersanalysisareavailable
ing comprises four datasets derived from Big- inAppendixA.2and A.3.
Bench(benchauthors,2023;Suzgunetal.,2023),
includingDateUnderstanding,PenguinsinaTable,
5.2. Main Results
Colored Objects, and Object Counting. A com-
prehensiveoverviewandstatisticalanalysisofthe Mathematical Reasoning. The results for the
datasetispresentedinAppendixA.1. mathematicalreasoningtasksarepresentedinTa-GSM8K MultiArith SingleEQ SVAMP AddSub AQuA Avg
CoT 80.0 97.7 91.9 78.1 86.6 54.7 81.50
CoT-PHP 84.6 98.3 93.9 83.9 86.1 65.4 85.37
CoT-SC(40) 88.9 99.3 94.5 85.9 87.6 68.7 87.48
CoT-CC(40) 88.7 99.2 94.3 86.1 87.8 69.3 87.57
CoT-Diverse(40) 89.2 99.3 94.5 86.6 88.7 70.9 88.20
CoT-AoR (20,40) 91.8 99.8 95.5 89.8 90.6 75.9 90.57
ComplexCoT 82.8 97.5 92.5 81.0 85.5 57.4 82.78
ComplexCoT-PHP 85.1 98.0 92.9 83.1 85.3 60.6 84.16
ComplexCoT-SC(40) 90.6 98.5 94.9 87.5 87.5 70.5 88.25
ComplexCoT-CC(40) 90.5 98.3 93.3 87.2 87.5 70.0 87.80
ComplexCoT-DiVeRSe(40) 90.8 98.7 94.3 87.8 88.2 72.9 88.78
ComplexCoT-AoR (20,40) 92.9 99.5 95.3 91.0 89.1 76.4 90.70
Table2: Comparisonofperformance(accuracy%)betweenAoR andseveralstrongbaselinesacrosssix
mathematicalreasoningdatasets. Thehighestaccuracyscoresareunderlined. Withinthesameprompt,
standoutresultsarehighlightedinbold. AllmethodsemployaGPT-3.5-Turbo-0301backbonefora
faircomparison. ResultsforComplexCoTandComplexCoT-PHParesourcedfromZhengetal.(2023).
Theaverageperformanceacrossdatasetsisprovidedforanoverallcomparison.
100 CoT CoT-SC CoT-CC CoT-AoR 100 CoT CoT-SC CoT-CC CoT-AoR
95
95
90
85 90
80
85
75
70 80
65
75
60
CSQA StrategyQA BoolQ ARC-C Date Penguins Colored Obj. Obj. Counting
(a)CommonsenseReasoningTasks. (b)SymbolicReasoningTasks.
Figure5: PerformancecomparisonofAoRandvariousstrongbaselinesoncommonsensereasoningand
symbolicreasoningtasks.
ble2. Acrosssixdatasets,AoRsurpassesallbase- ods. In contrast, AoR effectively enhances the
lineapproaches. UndertheCoTprompt,whencom- LLM’sperformanceonStrategyQA.Moreover,AoR
pared to the competitive DiVeRSe method, AoR consistentlyachievessignificantperformanceim-
achievesanaverageperformanceboostof2.37% provements in symbolic reasoning tasks. When
acrosssixdatasets. Furthermore,theaverageper- compared to the SC method, there are improve-
formance shows an improvement of 3.09% com- mentsof5.8%and8.9%ontheDateUnderstand-
paredtotheSCmethod,withasignificantincrease ingandPenguinsdatasets.
of 7.2% on the AQuA dataset. When employing
ComplexCoT prompt, AoR maintains its compet- DynamicSampling. Figures6aand6billustrate
itive advantage. It shows average performance the progression of sample counts during the dy-
enhancementsof2.45%,2.90%,and1.92%com- namicsamplingprocessontheAQuAandGSM8K
paredtotheSC,CC,andDiVeRSemethod. datasets. The color scheme represents the vari-
anceinanswercountswithinthedataset,transition-
CommonsenseandSymbolicReasoning. Fig- ingfromlighttodarkshadestoillustratetherange
ures5aand5billustratetheperformanceofAoR fromsingulartomultipleansweroccurrences. The
incommonsensereasoningandsymbolicreason- majority of samples conclude satisfactorily after
ingtasks. Forcommonsensereasoningtasks,AoR the first round, with only a select group of more
demonstrateanaverageperformanceimprovement complexsamplesnecessitatingfurtherreasoning
of8.45%and8.27%comparedtoSCandCCmeth- chains. Witheachsubsequentroundofsampling,
ods. Notably,onStrategyQA,whichemphasizes there’sanoticeabledeclineinthetotalnumberof
implicitreasoningstrategies,bothSCandCCdo samples,indicatingthatthenewlyaddedreasoning
notsignificantlyoutperformthebaselineCoTmeth- chainscontributetothefinalanswer’sdetermina-
)%(
ycaruccA
)%(
ycaruccA5 10+
 Ϯ Ϭ  Z Ă ǁ  Ϯ Ϭ  Z Ă ǁ 9
 Ϯ Ϭ 4  Ϯ Ϭ 8
7
 Ϯ ϱ  Ϯ ϱ
6
3
 ϯ Ϭ  ϯ Ϭ 5
4
 ϯ ϱ 2  ϯ ϱ 3
 ϰ Ϭ  ϰ Ϭ 2
 Ϭ  ϱ Ϭ  ϭ Ϭ Ϭ  ϭ ϱ Ϭ  Ϯ Ϭ Ϭ  Ϯ ϱ Ϭ 1  Ϭ  Ϯ Ϭ Ϭ  ϰ Ϭ Ϭ  ϲ Ϭ Ϭ  ϴ Ϭ Ϭ  ϭ Ϭ Ϭ Ϭ  ϭ Ϯ Ϭ Ϭ 1
  Ă ƚ Ă  Y Ƶ Ă Ŷ ƚ ŝ ƚ Ǉ   Ă ƚ Ă  Y Ƶ Ă Ŷ ƚ ŝ ƚ Ǉ
(a)AQuA. (b)GSM8K.
Figure6: CorrelationofsamplevolumetodynamicsamplingiterationsinAQuAandGSM8Kdatasets.
Thex-axisrepresentsthesamplecount,whilethey-axisindicatestheroundsofsampling. Colorvariations
denotetherangeofanswersidentifiedintheglobal-evaluationphaseacrossdifferentdatasamples,with
”20Raw”indicatingtheinitialdistributionofanswercounts.
CoT CoT-SC CoT-CC CoT-AoR CoT-AoR(w.GPT4) 100 CoT-SC CoT-CC CoT-AoR CoT-AoR(w.GPT4)
90
80 90
70 80
60 70
50 60
40
50
30
40
20
30
10
GPT-4 Claude-2 LLaMA-2 Mistral AQuA CSQA Date Penguin
Figure 7: Performance of AoR using different Figure8: Proportionofsamplesleadtoincorrect
LLMsforbothbackbonesandevaluatorswhen finalpredictionthatcontainatleastonecorrect
solvingAQuAproblems. candidateanswer.
tion. ComparedtotheAQuAdataset,whichuses Notably, with the LLaMA-2 model, the improve-
optionsasanswers,theopen-endednatureofthe ment is notably significant, attaining a 16.6% in-
GSM8Kdatasetresultsinabroaderdistributionof creasecomparedtoSC.Moreover,weconductan
initialanswers. Byobservingthedistributionofan- analysisoftheevaluationmodelsandobversethat
swersinthe“20Raw”and“20”phases,itisevident integratingGPT-4intothelocal-scoringandglobal-
thatinthelocal-scoringphase,afterfilteringouta evaluationphasesresultsinperformanceimprove-
substantialnumberoflow-qualityreasoningchains, mentsof2.4%,3.6%and5.1%ontheClaude-2,
significantlyreducesthenumberofcandidatean- and LLaMA-2, and Mistral models. This high-
swers,enablingamoreaccuratefinalanswerse- lightsthepotentialforasuperiorevaluationmodel
lectionintheglobalevaluation. toenhancetheeffectivenessofAoR.
5.3. Discussion Analysis of Incorrect Samples. In Section 1,
we analyze the erroneous samples from the SC
In this section, we delve into the advantages of
method,revealingthatamajorityofthesesamples
theAoR method,dissectingthereasonsbehindits
did not arise from LLM’s inability to produce the
performanceimprovementsfromfourperspectives.
correctanswer. Instead,themajorityvotingmech-
anismfailedtoidentifytherightanswer. Adopting
AoR onVariousLLMs. Figure9depictstheen- a similar analytical approach for AoR’s incorrect
hancedperformanceofAoR whenappliedtofour samples, as depicted in Figure 8, we discover a
different LLMs. In comparison with SC and CC, significantreductionintheproportionofsamples
AoR achieves an average improvement of 8.1% whereAoRfailedtoselectthecorrectanswer. This
and7.6%. Ourevaluationextendstotwoprominent underscoresAoR’sefficiencyinleveragingthein-
open-source models: the dense model LLaMA- formationfromreasoningchainstoboostthelike-
2-70B-Chat and the Mixture-of-Experts (MoE) lihood of selecting the correct answer. Moreover,
modelMixtral-8x7B.AoR achievesconsistent thisproportioncanbefurtherreducedbyemploying
improvements across various LLM architectures. amorediscerningevaluator.
 Ɛ Ě Ŷ Ƶ Ž Z  Ő Ŷ ŝ ů Ɖ ŵ Ă ^
ycaruccA
egatnecreP
 Ɛ Ě Ŷ Ƶ Ž Z  Ő Ŷ ŝ ů Ɖ ŵ Ă ^CoT-AoR(60, 80) None Two Random Two Best Two Worst Best&Worst
80 93
CoT-AoR(20, 40)
92
75 CoT-AoR(40, 60) SC(80) SC(100)
SC(60)
C-SC(40) 91
C-SC(20)
70 C-SC(60) C-SC(80) C-SC(100) 90
SC(20) SC(40)
65 89
88
60
87
ComplexCoT
55 CoT 86
0 2 4 6 8 10 85
Cost($) GSM8K ARC-C Date Penguin
Figure 9: Analysis of cost and performance. Figure10: Evaluationofdemonstrationselec-
The x-axis represents the cost, the y-axis in- tionsduringthelocal-scoringphaseofdynamic
dicates accuracy, and the size of each point sampling. “Best”and“Worst”denotethereason-
correspondstothenumberofreasoningchains. ingchainswiththehighestandlowestscores,
Forbrevity,weuse“SC”torepresent“CoT-SC”, respectively,amongthoseyieldingidenticalan-
and“C-SC”todenote“Complexity-SC.” swers.
Cost and Performance Analysis. A potential thehighestandlowestscoringchainsasdemon-
concernrevolvesaroundtheadditionaloverheadin- strationsachievesthebestperformance,likelybe-
troducedbyAoR’sevaluationandwhetherdynamic causetheyofferacomprehensiveviewofthescore
samplingcaneffectivelyreducereasoningcosts. In range,aidingthemodelinmoreaccuratelyscoring
Figure9,weanalyzethecostandperformanceof newchains. However,usingthetwolowestscoring
AoRandSContheAQuAdatasetusingGPT-3.5. chains as examples tends to bias the model to-
Notably,CoT-AoR (20,40)notonlysurpassesCoT- wards lower scores, often preventing these new
SC(40)witha7.2%boostinperformancebutalso chains from advancing to the global evaluation
achievesasignificant20%reductioninoverhead. phase and thus impairing performance. Conse-
Furthermore,CoT-AoR (20,40)outperformseven quently,weutilizeboththebestandworstreason-
CoT-SC(100), indicating that compared to major- ing chains within the same answer as evaluation
ityvoting,AoR’sevaluationofreasoningchainsis benchmarksmentionedinSection4.2.
amoreefficientmethodforanswerselection. It’s
noteworthythattheSCmethodexhibitssaturation:
6. Conclusion
there is no significant performance improvement
whenthenumberofreasoningchainsexceeds60.
Inthisstudy,weintroduceAoR(AggregationofRea-
Incontrast,AoR continuestoshownoticeableper-
soning),apioneeringframeworkthatenhancesthe
formanceenhancementsatsamplingchainsof40
ensemblemethodsforreasoningchainsbymetic-
and60. ThissuggeststhatAoRpossessesasu-
ulouslyevaluatingandaggregatingthereasoning
perior performance ceiling in comparison to SC
processes. AoR employsatwo-phaseevaluation
approaches,underliningitscost-effectivenessand
approach, assessing reasoning chains from mul-
higherpotentialforaccuracyimprovement.
tipleperspectives,ensuringtheevaluation’svalid-
ityandcomprehensiveness. Notably,AoR allows
Analysis of Evaluation Benchmarks. In the forthedynamicadjustmentofthenumberofrea-
local-scoring phase of dynamic sampling, evalu- soning chains according to the complexity of the
atedreasoningchainsareleveragedtoscorenewly task,substantiallyminimizingunnecessarycompu-
added chains. Figure 10 assesses the impact of tational overhead. Experimental results illustrate
usingnodemonstrationsversusvariousdemonstra- thatAoR significantlyimprovesthereasoningabil-
tionstrategiesonthefinalansweracrossdifferent ities of LLMs, outperforming several established
datasets. Strategiesincludeselectingnoreason- baselines. Furthermore, our in-depth analysis in-
ing chains, two random chains, the two highest, dicatesthatAoR’sadaptabilityextendsacrossvar-
the two lowest, and a combination of the highest ious LLM architectures, with potential for further
andlowestscoringchainsfordemonstration. While enhancementsthroughintegratingamorerobust
thisprimarily affectsdynamicallysampledcases, evaluator and an increased volume of reasoning
demonstrations consistently enhance model per- chains. Comparedtotheexistingensemblemeth-
formance across datasets. This improvement is ods, AoR not only presents benefits in terms of
likelybecausedemonstrationsprovidethemodel performanceandefficiencybutalsoeffectivelymiti-
withinsightintothecurrentscoredistribution,en- gatestheriskofaccurateanswersbeingovershad-
ablingmoreinformedscoring. Notably,employing owedbymorefrequentbutincorrectpredictions.
ycaruccA
ycaruccAEthical Statement batchesofreasoningchains,substantiallyreducing
computationalcostsandenhancingefficiency.
In developing the AoR framework, our team has
prioritizedethicalconsiderationstoensureourwork
Acknowledgements
respects privacy and promotes fairness. Specifi-
cally, the AoR methodology does not involve the ThisworkwassupportedbytheNationalNatural
collection or utilization of any personally identifi-
ScienceFoundationofChina(No. 62236004). We
able information. The design of our experimen-
aregratefultothereviewersfortheirinsightfulcom-
talpromptshasbeenmeticulouslycraftedtopre-
ments and suggestions, which have significantly
ventanyformofdiscriminationagainstindividuals
improvedthequalityofthismanuscript.
or groups, thereby safeguarding against privacy
breachesandpotentialsocio-ethicalimplications.
Bibliographical References
Furthermore, we have conducted an in-depth re-
view of the licenses for all datasets employed in
ourresearch,asoutlinedinAppendixA.1.
Maciej Besta, Nils Blach, Ales Kubicek, Robert
Limitations Gerstenberger,LukasGianinazzi,JoannaGajda,
Tomasz Lehmann, Michal Podstawski, Hubert
Manual Demonstration Construction for Lo- Niewiadomski, Piotr Nyczyk, and Torsten Hoe-
cal-Scoring and Global-Evaluation. Our ap- fler.2023. Graphofthoughts: Solvingelaborate
proachreliesonmanuallycrafteddemonstrations problemswithlargelanguagemodels.
toguidethemodelingeneratingoutputsinthede-
sired formatforextractingscores. Thismethod’s Chi-MinChan,WeizeChen,YushengSu,Jianxuan
efficacyiscontingentonthemodel’sabilitytoac- Yu, Wei Xue, Shanghang Zhang, Jie Fu, and
curately interpret these demonstrations and pro- ZhiyuanLiu.2023. Chateval: Towardsbetterllm-
duce outputs as anticipated. In instances where basedevaluatorsthroughmulti-agentdebate.
themodelfailstocomprehendthedemonstrations
Wenhu Chen, Xueguang Ma, Xinyi Wang, and
adequately or deviates from the expected output
William W. Cohen. 2022. Program of thoughts
format,theperformanceofAoRbecomesunstable,
prompting: Disentanglingcomputationfromrea-
potentiallyhinderingthecompletionofitsprocess.
soningfornumericalreasoningtasks.
Nonetheless,weareoptimisticthattheevolutionof
LLMswillbolstertheircomprehension(Chengetal., Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi,
2024;Naveedetal.,2024)andoutputformatting andRuifengXu.2023. Exploringtheuseoflarge
capabilities (Liang et al., 2024; Dekoninck et al., languagemodelsforreference-freetextquality
2024),therebymitigatingthisissueovertime. evaluation: Anempiricalstudy.
Daixuan Cheng, Shaohan Huang, and Furu Wei.
ModelContextWindowSizeLimitations. The
2024. Adaptinglargelanguagemodelsviaread-
limitationsimposedbythemodel’scontextwindow
ingcomprehension.
size restrict the number of examples that can be
processedsimultaneously. Atpresent,modelsface Cheng-HanChiangandHungyiLee.2023a. Can
challenges in handling an extensive array of rea- largelanguagemodelsbeanalternativetohu-
soning chains, necessitating a balance between manevaluations?
performance assessment and computational ex-
Cheng-Han Chiang and Hung yi Lee. 2023b. A
penditure. While smaller parameter models can
closerlookintoautomaticevaluationusinglarge
navigatethroughtheAoRprocess, theirabilityis
languagemodels.
oftenlimitedtoevaluatingsinglereasoningchains,
therebyescalatingthecomputationaldemandsof
Aakanksha Chowdhery, Sharan Narang, Jacob
AoR.However,webelievethistobeatemporary
Devlin,MaartenBosma,GauravMishra,Adam
constraint. Recent models like Mistral (Jiang Roberts, Paul Barham, Hyung Won Chung,
et al., 2023) and InternLM (Team, 2023) have Charles Sutton, Sebastian Gehrmann, et al.
demonstratedevaluationcapacitiescomparableto
2022. Palm: Scaling language modeling with
those of GPT with appropriate prompting. More- pathways.
over,weareencouragedbyrecentadvancements
thathavesignificantlyexpandedthemodels’con- Zheng Chu, Jingchang Chen, Qianglong Chen,
text windows (Xiao et al., 2023; Liu et al., 2024). Weijiang Yu, Tao He, Haotian Wang, Weihua
Aslong-contextmodelscontinuetoevolve(Ratner Peng,MingLiu,BingQin,andTingLiu.2023. A
etal.,2023;Wangetal.,2023c),weanticipatethat surveyofchainofthoughtreasoning: Advances,
AoRwillbeabletoconductevaluationsonlarger frontiersandfuture.Karl Cobbe, Vineet Kosaraju, Mohammad Bavar- Jie Huang and Kevin Chen-Chuan Chang. 2022.
ian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Towardsreasoninginlargelanguagemodels: A
Matthias Plappert, Jerry Tworek, Jacob Hilton, survey. arXivpreprintarXiv:2212.10403.
ReiichiroNakano,ChristopherHesse,andJohn
Albert Q. Jiang, Alexandre Sablayrolles, Arthur
Schulman.2021. Trainingverifierstosolvemath
Mensch,ChrisBamford,DevendraSinghChap-
wordproblems.
lot, Diego de las Casas, Florian Bressand,
Jasper Dekoninck, Marc Fischer, Luca Beurer- Gianna Lengyel, Guillaume Lample, Lucile
Kellner, and Martin Vechev. 2024. Controlled Saulnier, Lélio Renard Lavaud, Marie-Anne
textgenerationvialanguagemodelarithmetic. Lachaux,PierreStock,TevenLeScao,Thibaut
Lavril, Thomas Wang, Timothée Lacroix, and
Shizhe Diao, Pengcheng Wang, Yong Lin, and WilliamElSayed.2023. Mistral7b.
TongZhang.2023. Activepromptingwithchain-
Albert Q. Jiang, Alexandre Sablayrolles, Antoine
of-thoughtforlargelanguagemodels.
Roux, Arthur Mensch, Blanche Savary, Chris
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Bamford,DevendraSinghChaplot,Diegodelas
PengfeiLiu.2023a. Gptscore: Evaluateasyou Casas,EmmaBouHanna,FlorianBressand,Gi-
desire. annaLengyel,GuillaumeBour,GuillaumeLam-
ple,LélioRenardLavaud,LucileSaulnier,Marie-
YaoFu,HaoPeng,AshishSabharwal,PeterClark, AnneLachaux,PierreStock,SandeepSubrama-
and Tushar Khot. 2023b. Complexity-based nian,SophiaYang,SzymonAntoniak,TevenLe
prompting for multi-step reasoning. In The Scao,ThéophileGervet,ThibautLavril,Thomas
EleventhInternationalConferenceonLearning Wang,TimothéeLacroix,andWilliamElSayed.
Representations. 2024. Mixtralofexperts.
AndrewGao.2023. Promptengineeringforlarge Jared Kaplan, Sam McCandlish, Tom Henighan,
languagemodels. AvailableatSSRN4504303. Tom B. Brown, Benjamin Chess, Rewon Child,
ScottGray,AlecRadford,JeffreyWu,andDario
LuyuGao,AmanMadaan,ShuyanZhou,UriAlon, Amodei.2020. Scalinglawsforneurallanguage
Pengfei Liu, Yiming Yang, Jamie Callan, and models.
GrahamNeubig.2022. Pal: Program-aidedlan-
TomKocmiandChristianFedermann.2023. Large
guagemodels. arXivpreprintarXiv:2211.10435.
languagemodelsarestate-of-the-artevaluators
MingqiGao,JieRuan,RenliangSun,XunjianYin, oftranslationquality.
ShipingYang,andXiaojunWan.2023. Human-
XiaonanLi,KaiLv,HangYan,TianyangLin,Wei
likesummarizationevaluationwithchatgpt.
Zhu,YuanNi,GuotongXie,XiaolingWang,and
Xipeng Qiu. 2023a. Unified demonstration re-
VeronikaHackl,AlexandraElenaMüller,Michael
Granitzer,andMaximilianSailer.2023. Isgpt-4 triever for in-context learning. In Proceedings
areliablerater? evaluatingconsistencyingpt-4 of the 61st Annual Meeting of the Association
textratings. forComputationalLinguistics(Volume1: Long
Papers), pages 4644–4668, Toronto, Canada.
Rishav Hada, Varun Gumma, Adrian de Wyn- AssociationforComputationalLinguistics.
ter,HarshitaDiddee,MohamedAhmed,Monojit
XiaonanLiandXipengQiu.2023. MoT:Memory-
Choudhury,KalikaBali,andSunayanaSitaram.
of-thoughtenablesChatGPTtoself-improve. In
2023. Arelargelanguagemodel-basedevalua-
Proceedingsofthe2023ConferenceonEmpir-
torsthesolutiontoscalingupmultilingualevalu-
ical Methods in Natural Language Processing,
ation?
pages 6354–6374, Singapore. Association for
ComputationalLinguistics.
ChengchengHan,XiaoweiDu,CheZhang,Yixin
Lian, Xiang Li, Ming Gao, and Baoyuan Wang. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu,
2023. DialCoTmeetsPPO:Decomposingand Bei Chen, Jian-Guang Lou, and Weizhu Chen.
exploring reasoning paths in smaller language 2023b. Makinglanguagemodelsbetterreason-
models. InProceedingsofthe2023Conference erswithstep-awareverifier.InProceedingsofthe
onEmpiricalMethodsinNaturalLanguagePro- 61stAnnualMeetingoftheAssociationforCom-
cessing,pages8055–8068,Singapore.Associa- putationalLinguistics(Volume1: LongPapers),
tionforComputationalLinguistics. pages5315–5333,Toronto,Canada.Association
forComputationalLinguistics.
JiaxinHuang,ShixiangShaneGu,LeHou,Yuexin
Wu,XuezhiWang,HongkunYu,andJiaweiHan. Percy Liang, Rishi Bommasani, Tony Lee, Dim-
2022. Largelanguagemodelscanself-improve. itris Tsipras, Dilara Soylu, Michihiro Yasunaga,Yian Zhang, Deepak Narayanan, Yuhuai Wu, Zheheng Luo, Qianqian Xie, and Sophia Anani-
Ananya Kumar, Benjamin Newman, Binhang adou.2023. Chatgptasafactualinconsistency
Yuan, Bobby Yan, Ce Zhang, Christian Cos- evaluatorfortextsummarization.
grove,ChristopherD.Manning,ChristopherRé,
SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,
DianaAcosta-Navas,DrewA.Hudson,EricZe-
Mike Lewis, Hannaneh Hajishirzi, and Luke
likman, Esin Durmus, Faisal Ladhak, Frieda
Zettlemoyer.2022. Rethinkingtheroleofdemon-
Rong,HongyuRen,HuaxiuYao,JueWang,Ke-
strations: Whatmakesin-contextlearningwork?
shavSanthanam,LaurelOrr,LuciaZheng,Mert
Yuksekgonul,MiracSuzgun,NathanKim,Neel
InProceedingsofthe2022ConferenceonEm-
Guha,NiladriChatterji,OmarKhattab,PeterHen-
piricalMethodsinNaturalLanguageProcessing,
pages11048–11064.
derson, Qian Huang, Ryan Chi, Sang Michael
Xie,ShibaniSanturkar,SuryaGanguli,Tatsunori
HumzaNaveed,AsadUllahKhan,ShiQiu,Muham-
Hashimoto,ThomasIcard,TianyiZhang,Vishrav
madSaqib,SaeedAnwar,MuhammadUsman,
Chaudhary, William Wang, Xuechen Li, Yifan
Naveed Akhtar, Nick Barnes, and Ajmal Mian.
Mai, Yuhui Zhang, and Yuta Koreeda. 2023.
2024. A comprehensive overview of large lan-
Holisticevaluationoflanguagemodels.
guagemodels.
Xun Liang, Hanyu Wang, Shichao Song, Mengt- OpenAI.2023. GPT-4technicalreport.
ing Hu, Xunzhi Wang, Zhiyu Li, Feiyu Xiong,
ShuofeiQiao,YixinOu,NingyuZhang,XiangChen,
andBoTang.2024. Controlledtextgeneration
Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei
forlargelanguagemodelwithdynamicattribute
Huang,andHuajunChen.2023. Reasoningwith
graphs.
language model prompting: A survey. In Pro-
WangLing,DaniYogatama,ChrisDyer,andPhil ceedingsofthe61stAnnualMeetingoftheAs-
Blunsom.2017. Programinductionbyrationale sociationforComputationalLinguistics(Volume
generation: Learningtosolveandexplainalge- 1: Long Papers), pages 5368–5393, Toronto,
braicwordproblems. InProceedingsofthe55th Canada.AssociationforComputationalLinguis-
tics.
AnnualMeetingoftheAssociationforComputa-
tionalLinguistics,ACL2017,Vancouver,Canada,
JackWRae,SebastianBorgeaud,TrevorCai,Katie
July 30 - August 4, Volume 1: Long Papers,
Millican,JordanHoffmann,FrancisSong,John
pages158–167.AssociationforComputational
Aslanides,SarahHenderson,RomanRing,Su-
Linguistics.
sannah Young, et al. 2022. Scaling language
models: Methods,analysis&insightsfromtrain-
Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin
inggopher.
Paranjape, Michele Bevilacqua, Fabio Petroni,
andPercyLiang.2023a. Lostinthemiddle: How
Nir Ratner, Yoav Levine, Yonatan Belinkov, Ori
languagemodelsuselongcontexts.
Ram, Inbal Magar, Omri Abend, Ehud Karpas,
AmnonShashua,KevinLeyton-Brown,andYoav
TengxiaoLiu,QipengGuo,YuqingYang,Xiangkun
Shoham. 2023. Parallel context windows for
Hu,YueZhang,XipengQiu,andZhengZhang.
large language models. In Proceedings of the
2023b. Plan,verifyandswitch: Integratedrea-
61stAnnualMeetingoftheAssociationforCom-
soningwithdiverseX-of-thoughts. InProceed-
putationalLinguistics(Volume1: LongPapers),
ingsofthe2023ConferenceonEmpiricalMeth-
pages6383–6402,Toronto,Canada.Association
ods in Natural Language Processing, pages
forComputationalLinguistics.
2807–2822,Singapore.AssociationforCompu-
tationalLinguistics. Dan Roth and Kevin Small. 2006. Margin-based
activelearningforstructuredoutputspaces. In
XiaoranLiu,HangYan,ShuoZhang,ChenxinAn,
MachineLearning: ECML2006: 17thEuropean
XipengQiu,andDahuaLin.2024. Scalinglaws
Conference on Machine Learning Berlin, Ger-
ofrope-basedextrapolation.
many,September18-22,2006Proceedings17,
pages413–424.Springer.
YangLiu,DanIter,YichongXu,ShuohangWang,
Ruochen Xu, and Chenguang Zhu. 2023c. G- Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khat-
eval: Nlgevaluationusinggpt-4withbetterhu- tar, Ruoxi Jia, and Ming Jin. 2023. Algorithm
manalignment. of thoughts: Enhancing exploration of ideas in
largelanguagemodels.
YuxuanLiu,TianchiYang,ShaohanHuang,Zihan
Zhang,HaizhenHuang,FuruWei,WeiweiDeng, Chenhui Shen, Liying Cheng, Yang You, and Li-
Feng Sun, and Qi Zhang. 2023d. Calibrating dong Bing. 2023. Are large language models
llm-basedevaluator. goodevaluatorsforabstractivesummarization?QiushiSun,ZhangyueYin,XiangLi,ZhiyongWu, Jason Wei, Yi Tay, Rishi Bommasani, Colin Raf-
Xipeng Qiu, and LingpengKong.2023. Corex: fel,BarretZoph,SebastianBorgeaud,DaniYo-
Pushing the boundaries of complex reasoning gatama,MaartenBosma,DennyZhou,Donald
throughmulti-modelcollaboration. Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol
Vinyals,PercyLiang,JeffDean,andWilliamFe-
MiracSuzgun,NathanScales,NathanaelSchärli, dus.2022a. Emergentabilitiesoflargelanguage
SebastianGehrmann,YiTay,HyungWonChung, models. TransactionsonMachineLearningRe-
AakankshaChowdhery,QuocLe,EdChi,Denny search.
Zhou, and Jason Wei. 2023. Challenging BIG-
benchtasksandwhetherchain-of-thoughtcan Jason Wei, Xuezhi Wang, Dale Schuurmans,
solve them. In Findings of the Association for MaartenBosma,brianichter,FeiXia,EdH.Chi,
Computational Linguistics: ACL 2023, pages QuocVLe,andDennyZhou.2022b. Chainof
13003–13051,Toronto,Canada.Associationfor thoughtpromptingelicitsreasoninginlargelan-
ComputationalLinguistics. guagemodels.InAdvancesinNeuralInformation
ProcessingSystems.
InternLMTeam.2023. Internlm: Amultilinguallan-
guagemodelwithprogressivelyenhancedcapa- Guangxuan Xiao, Yuandong Tian, Beidi Chen,
bilities. https://github.com/InternLM/ Song Han, and Mike Lewis. 2023. Efficient
InternLM. streaminglanguagemodelswithattentionsinks.
Hugo Touvron, Thibaut Lavril, Gautier Izacard,
YuxiXie,KenjiKawaguchi,YiranZhao,JamesXu
XavierMartinet,Marie-AnneLachaux,Timothée
Zhao, Min-Yen Kan, Junxian He, and Michael
Lacroix, Baptiste Rozière, Naman Goyal, Eric
Xie.2023. Self-evaluationguidedbeamsearch
Hambro,FaisalAzhar,etal.2023a.Llama: Open
forreasoning. InAdvancesinNeuralInformation
andefficientfoundationlanguagemodels. arXiv ProcessingSystems,volume36,pages41618–
preprintarXiv:2302.13971.
41650.CurranAssociates,Inc.
Hugo Touvron, Louis Martin, Kevin Stone, Peter
ShunyuYao,DianYu,JeffreyZhao,IzhakShafran,
Albert,AmjadAlmahairi,YasmineBabaei,Niko-
Thomas L. Griffiths, Yuan Cao, and Karthik
layBashlykov,SoumyaBatra,PrajjwalBhargava,
Narasimhan.2023. TreeofThoughts: Deliberate
et al. 2023b. Llama 2: Open foundation and
problemsolvingwithlargelanguagemodels.
fine-tunedchatmodels.
ZhangyueYin,QiushiSun,ChengChang,Qipeng
KarthikValmeekam,AlbertoOlmo,SarathSreedha-
Guo, Junqi Dai, Xuanjing Huang, and Xipeng
ran,andSubbaraoKambhampati.2022. Large
Qiu. 2023a. Exchange-of-thought: Enhancing
languagemodelsstillcan’tplan(abenchmarkfor
largelanguagemodelcapabilitiesthroughcross-
llmsonplanningandreasoningaboutchange).
model communication. In Proceedings of the
arXivpreprintarXiv:2206.10498.
2023ConferenceonEmpiricalMethodsinNatu-
Jiaan Wang, Yunlong Liang, Fandong Meng,
ralLanguageProcessing,pages15135–15153,
Singapore. Association for Computational Lin-
ZengkuiSun,HaoxiangShi,ZhixuLi,JinanXu,
guistics.
JianfengQu,andJieZhou.2023a. Ischatgpta
goodnlgevaluator? apreliminarystudy.
Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen
JianingWang,QiushiSun,XiangLi,andMingGao. Wu, Xipeng Qiu, and Xuanjing Huang. 2023b.
2023b. Boosting language models reasoning Dolargelanguagemodelsknowwhattheydon’t
withchain-of-knowledgeprompting. know? InFindingsoftheAssociationforCom-
putationalLinguistics: ACL2023,pages8653–
Weizhi Wang, Li Dong, Hao Cheng, Xiaodong 8665,Toronto,Canada.AssociationforCompu-
Liu, Xifeng Yan, Jianfeng Gao, and Furu Wei. tationalLinguistics.
2023c. Augmentinglanguagemodelswithlong-
termmemory. ZihanYu,LiangHe,ZhenWu,XinyuDai,andJiajun
Chen. 2023. Towards better chain-of-thought
Xuezhi Wang, Jason Wei, Dale Schuurmans, promptingstrategies: Asurvey.
Quoc V Le, Ed H. Chi, Sharan Narang,
AakankshaChowdhery,andDennyZhou.2023d. ZhuoshengZhang,AstonZhang,MuLi,andAlex
Self-consistencyimproveschainofthoughtrea- Smola.2023.Automaticchainofthoughtprompt-
soning in language models. In The Eleventh inginlargelanguagemodels. InTheEleventh
InternationalConferenceonLearningRepresen- InternationalConferenceonLearningRepresen-
tations. tations.WayneXinZhao,KunZhou,JunyiLi,TianyiTang, Hosseini,MohammadJavadandHajishirzi,Han-
Xiaolei Wang, Yupeng Hou, Yingqian Min, Be- naneh and Etzioni, Oren and Kushman, Nate.
ichen Zhang, Junjie Zhang, Zican Dong, Yifan 2014. LearningtoSolveArithmeticWordProb-
Du, Chen Yang, Yushuo Chen, Zhipeng Chen, lemswithVerbCategorization. Associationfor
JinhaoJiang,RuiyangRen,YifanLi,XinyuTang, ComputationalLinguistics.
ZikangLiu,PeiyuLiu,Jian-YunNie,andJi-Rong
Rik Koncel-Kedziorski, Subhro Roy, Aida Amini,
Wen.2023. Asurveyoflargelanguagemodels.
NateKushman,andHannanehHajishirzi.2016.
ChuanyangZheng,ZhengyingLiu,EnzeXie,Zhen- MAWPS: A math word problem repository. In
guoLi,andYuLi.2023. Progressive-hintprompt- Proceedingsofthe2016ConferenceoftheNorth
ingimprovesreasoninginlargelanguagemodels. AmericanChapteroftheAssociationforCompu-
ArXivpreprint,abs/2304.09797. tationalLinguistics: HumanLanguageTechnolo-
gies,pages1152–1157,SanDiego,California.
Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, AssociationforComputationalLinguistics.
Guangjing Wang, Kai Zhang, Cheng Ji, Qiben
Yan, Lifang He, et al. 2023. A comprehen- Wang Ling and Dani Yogatama and Chris Dyer
sive survey on pretrained foundation models: andPhilBlunsom.2017. ProgramInductionby
A history from bert to chatgpt. arXiv preprint Rationale Generation: Learning to Solve and
arXiv:2302.09419. ExplainAlgebraicWordProblems. Association
forComputationalLinguistics.
Yiming Zhu, Peixian Zhang, Ehsan-Ul Haq, Pan
Patel, Arkil and Bhattamishra, Satwik and Goyal,
Hui,andGarethTyson.2023. Canchatgptrepro-
ducehuman-generatedlabels? astudyofsocial
Navin.2021.AreNLPModelsreallyabletoSolve
computingtasks. Simple Math Word Problems? Association for
ComputationalLinguistics.
SubhroRoyandDanRoth.2015. SolvingGeneral
Language Resource References ArithmeticWordProblems. TheAssociationfor
ComputationalLinguistics.
Suzgun, Mirac and Scales, Nathan and Schärli,
Nathanael and Gehrmann, Sebastian and Tay,
BIG-bench authors. 2023. Beyond the Imitation
Yi and Chung, Hyung Won and Chowdhery,
Game: Quantifyingandextrapolatingthecapa-
AakankshaandLe,QuocandChi,EdandZhou,
bilitiesoflanguagemodels.
DennyandWei,Jason.2023. ChallengingBIG-
Clark, Christopher and Lee, Kenton and Chang, BenchTasksandWhetherChain-of-ThoughtCan
Ming-Wei and Kwiatkowski, Tom and Collins, SolveThem. AssociationforComputationalLin-
MichaelandToutanova,Kristina.2019. BoolQ: guistics.
Exploring the Surprising Difficulty of Natural
Talmor, Alon and Herzig, Jonathan and Lourie,
Yes/No Questions. Association for Computa-
tionalLinguistics. NicholasandBerant,Jonathan.2019. Common-
senseQA:AQuestionAnsweringChallengeTar-
Peter Clark and Isaac Cowhey and Oren Etzioni getingCommonsenseKnowledge. Association
and Tushar Khot and Ashish Sabharwal and forComputationalLinguistics.
Carissa Schoenick and Oyvind Tafjord. 2018.
ThinkyouhaveSolvedQuestionAnswering? Try
ARC,theAI2ReasoningChallenge.
KarlCobbeandVineetKosarajuandMohammad
BavarianandMarkChenandHeewooJunand
LukaszKaiserandMatthiasPlappertandJerry
TworekandJacobHiltonandReiichiroNakano
and Christopher Hesse and John Schulman.
2021.TrainingVerifierstoSolveMathWordProb-
lems.
Geva,MorandKhashabi,DanielandSegal,Elad
and Khot, Tushar and Roth, Dan and Berant,
Jonathan. 2021. Did Aristotle Use a Laptop?
AQuestionAnsweringBenchmarkwithImplicit
ReasoningStrategies. MITPress.A. Appendices • Completeness and Clarity (2 points): Es-
sentialstepsaredelineatedandpresentedun-
A.1. Dataset Statistics ambiguously,maintainingclaritythroughout.
In our experiment, we meticulously select 14 • ApplicationofKnowledge(2points): The
datasetsencompassingmathematicalreasoning, precision and appropriateness in the use of
commonsensereasoning,andsymbolicreasoning formulas,theorems,orfactsareverified.
domains. The specifics and statistical details of
eachdataset,includingthedatasource,tasktype, InlinewiththefindingsofGao(2023),providingas
answertype,numberofpromptsamples,totaltest muchdetailedinformationaspossibleintheinput
samples, and dataset licenses, are comprehen- facilitates the generation of the desired outcome.
sivelyoutlinedinTable3. Thus,additionalstatisticalinformation,suchasthe
number of reasoning chains within a bucket and
thenumberofcandidateanswers,isincorporated
A.2. Implementation Details
intotheprompt. Forthecompleteprompt,please
PromptingExemplars. AoRutilizestheWeietal. refertoourGithubrepository.
(2022b)andFuetal.(2023b)providedpromptex-
emplarstosamplereasoningchains,withthenum-
Evaluation. Weemployaccuracyasthemetricto
berofpromptexemplarsforeachdatasetdetailed
assessperformanceacrosstasksinvolvingmathe-
inTable3. Inthelocalscoringphase,giventhatthe
maticalreasoning,commonsensereasoning,and
answersareidentical,ourevaluationfocusesmore
symbolic reasoning. For datasets where the an-
onthesoundnessofthereasoningprocessandthe
swerisnumerical,suchasGSM8K,weutilizeregu-
correctnessofthereasoningmethod. Specifically,
larexpressionstoextracttheanswerfollowingthe
werequiretheLLMtoevaluatereasoningchains
phrase “the answer is” and conduct a numerical
thatsharethesameanswerfromfourperspectives
comparisonwiththeprovidedanswer. Fordatasets
asfollows:
where the answers are choices, such as AQuA,
wecomparetheextractedchoicewiththecorrect
• LogicalConsistency(3points): Thecoher-
option to verify consistency. In cases where the
enceandsoundnessofthereasoningareeval-
datasetanswersarebinary(yes/no),suchasStrat-
uatedtoensurelogicalprogression.
egyQA,weevaluatewhethertheextractedresult
• AppropriatenessofMethod(3points): The alignswiththeprovidedlabel. Ifareasoningchain
suitabilityoftheusedmethodisverified,em- fails to correctly extract an answer, it is excluded
phasizingthattheapproachisnotunnecessar- fromfurtherconsideration. Similartotheapproach
ilycomplex. byXieetal.(2023),wefine-tunetask-specificver-
ifierstoassignweightstothesampledreasoning
• Completeness and Clarity (2 points): All
chainstoimplementtheDiVeRSe(Lietal.,2023b).
necessarystepsmustbeclearlyshownwithout
omission,ensuringeasyfollow-through.
Computation Cost. Computational costs are
• ApplicationofKnowledge(2points): The quantified based on OpenAI’s official pricing
correct and relevant application of formulas, for the GPT-3.5-Turbo-0301 API, calcu-
theorems,orfactsisassessed. lated as follows: InputTokens × 0.0015/1000 +
OutputTokens×0.002/1000.
The global-evaluation phase prioritizes the cor-
Our primary experiments, as outlined in Sec-
rectness of the method and the consistency be-
tion 5.2 were conducted from July to September
tween reasoning steps and the answer, enabling
2023. DiscussioninSection5.3andtheAblation
themodeltofilteroutthecorrectreasoningchain
Study in Appendix A.3 for both commercial and
fromthosewithdifferinganswers. Specifically,we
open-sourcemodelswerecompletedbetweenOc-
requiretheLLMtoevaluatereasoningchainswith
toberandDecember2023.
differentanswersfromthefollowingfourperspec-
Duetoratelimitsandbudgetconstraints,weset
tives:
anupperlimitonoursamplesizeforeachanalysis.
• Validity of Approach (3 points): The em- Consequently,ouranalysisisbasedonamaximum
ployedmethodeffectivelyaddressestheprob- of500samplesperrun.
lem,confirmingtheappropriatenessoftheap-
proach. A.3. Ablation Study
• Consistency of Steps and Answer (3 Tofacilitatetheintricatereasoningchainaggrega-
points): It is ensured that all steps are not tionprocessinAoR,weestablishessentialhyper-
onlycorrectbutalsoconsistentwiththefinal parametersduringthelocalscoringandglobaleval-
answer. uation phases, such as the representative countDataset ReasoningTask AnswerType #Prompts #Test License
GSM8K(Cobbeetal.,2021) Arithmetic Number 8 1,319 MITLicense
MultiArith(RoyandRoth,2015) Arithmetic Number 8 600 Unspecified
SingleEQ(Koncel-Kedziorskietal.,2016) Arithmetic Number 8 508 Unspecified
AddSub(Hosseinietal.,2014) Arithmetic Number 8 395 Unspecified
SVAMP(Pateletal.,2021) Arithmetic Number 8 1,000 MITLicense
AQUA(Lingetal.,2017) Arithmetic Multi-choice 4 254 Apache-2.0
StrategyQA(Gevaetal.,2021) Commonsense T/F 6 2,290 MITlicense
CommonsenseQATalmoretal.,2019 Commonsense Multi-choice 7 1,221 Unspecified
BoolQ(Clarketal.,2019) Commonsense T/F 4 3,270 CCBY-SA3.0
ARC-C(Clarketal.,2018) Commonsense Multi-choice 4 299 CCBY-SA4.0
DateUnderstanding(Suzgunetal.,2023) Symbolic Multi-choice 3 250 MITlicense
PenguinsinaTable(Suzgunetal.,2023) Symbolic Multi-choice 3 146 MITlicense
ColoredObjects(Suzgunetal.,2023) Symbolic Multi-choice 3 250 MITlicense
ObjectCounting(Suzgunetal.,2023) Symbolic Multi-choice 3 250 MITlicense
Table3: Overviewofdatasetsutilizedinourexperiments. #PromptsindicatesthenumberofChain-of-
Thought(CoT)(Weietal.,2022b)promptingexemplarsusedforfew-shotprompting. #Testdenotesthe
totalcountoftestsamplesineachdataset.
AQuA CSQA Date Penguin
95 2500
90 2000
85 1500
80 1000
75 500
70 0
1 2 3 4 5 0 2 4 6 8 10
Representative Count k Evaluation Score
Figure11: Ablationonrepresentativecountk Figure12: Distributionofevaluationscoresin
onvariousreasoningdatasets. thelocal-scoringphaseontheGSM8Kdataset.
k,scorethresholdϵ,terminationthresholdθ,and phaseontheGSM8Kdataset,whereweobserve
batch size b. Below, we conduct ablation experi- a normal distribution of scores. The model sel-
ments using the GPT-3.5 model to examine the domassignsverylowscores(0-2points). Alower
impactofeachhyperparameterontheoverallper- scorethresholdϵleadstoanexcessivenumberof
formance. reasoningchainsproceedingtoglobalevaluation;
for instance, setting ϵ to 3 results in over 95% of
AnalysisofRepresentativeCountk. Weana- reasoningchainsmovingtoglobalevaluation. Con-
lyzefourdatasetstoinvestigatehowtherepresen- versely, a higher ϵ enforces stricter filtering; set-
tativecountk impactsaccuracy,asshowninFig- tingϵto8resultsinfewerthan10%ofreasoning
ure11. Whenk =1,onlythehighest-scoringrea- chainsmovingforwardtoglobalevaluation,lead-
soningchainfromeachbucketisevaluated,which ing to many samples having only one reasoning
putsrigorousdemandsonthescoringmodeland chainintheglobal-evaluationphase. Somesam-
canresultinfluctuatingoutcomes. Selectingmore ples might even finish dynamic sampling without
representatives from each bucket enhances the anyreasoningchainsproceedingtoglobalevalua-
comprehensivenessandstabilityoftheevaluation, tion. Therefore,wedeterminethescorethreshold
harmonizingthequalityanddiversityofreasoning ϵ to be 6, which ensures a balance by maintain-
chains. However,ourfindingssuggestthatincreas- ing high-quality reasoning chains and allowing a
ingthenumberofrepresentativeswhenk >3does sufficientnumbertoundergoglobalevaluation.
notleadtosignificantperformancegainsbutdoes
incuradditionalcomputationaloverhead. Asare- AnalysisofTerminationThresholdθ. Figure13
sult,wechosek =3asitstrikesanoptimalbalance demonstrates the impact of various termination
betweenperformanceandcomputationalcost. thresholds(θ)onaccuracyandcomputationalcost.
A threshold of θ = 0 implies that we select the
AnalysisofScoreThresholdϵ. Figure12illus- answer associated with the highest-scoring rea-
tratesthescoredistributionduringthelocal-scoring soningchainasthefinalanswerwithoutsampling
ycaruccA
ytitnauQ91.75 8 86.50
3
91.50 86.25
6
91.25 86.00
2 91.00 4 85.75
90.75 85.50 1
2
90.50 85.25
90.25 0 0
0 1 2 3 4 0 1 2 3 4
(a)GSM8K. (b)CSQA.
Figure 13: The effect of varying termination thresholds θ on accuracy and computational cost for the
GSM8KandCSQAdatasets. Linegraphsillustrateaccuracy,whilebargraphsdepictcomputationalcosts.
91.8 Accuracy 10 Accuracy
86 4
91.6 8
91.4 85 3
6
91.2
84 2
4
91.0
83
90.8 2 1
90.6 82
0 0
1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 8
(a)GSM8K. (b)CSQA.
Figure14: TheimpactofbatchsizebvariationsonaccuracyandcomputationalcostontheGSM8Kand
CSQAdatasets. Linegraphsrepresentaccuracy,whilebarchartsindicatecomputationalcosts.
additionalreasoningchains. Whilethisapproach possible explanation is that evaluating samples
incurslowercosts,itresultsinthepoorestperfor- together allows the LLM to compare differences
mance on both the GSM8K and AQuA datasets. acrossreasoningchains,therebyprovidingmore
This suggests that relying solely on the model’s reliable scores. As the batch size increases, ac-
confidenceinthehighest-scoringreasoningchain curacyimprovesgraduallyuntilitreachesabatch
doesnotguaranteeitscorrectness. Asthethresh- size of 6, beyond which accuracy begins to fluc-
oldincreases,weobserveagradualimprovement tuateandevendecline. Atthispoint,themodel’s
inaccuracy. Thisindicatesthatimposingadditional outputbecomesunstable,withsomesamplesex-
constraintsandintroducingnewreasoningchains ceeding the model’s context window, resulting in
whennecessarycanaidthemodelinselectingthe failedevaluations. Concurrently,wenotedagrad-
correctreasoningprocess. However,performance ualdecreaseincomputationalcostswithincreasing
tendstosaturatebeyondathresholdof2. Wenote batchsize, attributedtothereducedoverheadof
thatatathresholdof4,morethan15%ofsamples repetitive prompts. However, this trend starts to
intheGSM8Kdatasetfailtoproduceafinalanswer slowdownwhenb > 2. Therefore,weselecteda
evenuponreachingthemaximumnumberofsam- batchsizeofb=5,whichnotonlyachievesoptimal
pledreasoningchains. Furthermore,excessively accuracyandlowercomputationalcostsbutalso
highthresholdsalsoleadtosignificantincreasesin avoidsevaluationfailuresduetosamplesexceed-
computationalcosts. Therefore,weestablishthe ingthemodel’scontextwindow.
terminationthresholdθ at2,achievinganoptimal
balancebetweentheaccuracyoftheoutputsand
thesamplingcostsofreasoningchains.
Analysis of Batch Size b. Figure 14 illustrates
theimpactofvaryingbatchsizes(b)onaccuracy
andcomputationalcosts. Duringouranalysis,sam-
plesexceedingthecontextwindowareexcluded.
Weobserveconsistentperformanceimprovements
on both the GSM8K and AQuA datasets when
evaluatingmultiplesamplessimultaneously,asop-
posedtoassessingeachsampleindividually. One
)%(
ycaruccA
)%(
ycaruccA
)$(
tsoC
)$(
tsoC
)%(
ycaruccA
)%(
ycaruccA
)$(
tsoC
)$(
tsoC