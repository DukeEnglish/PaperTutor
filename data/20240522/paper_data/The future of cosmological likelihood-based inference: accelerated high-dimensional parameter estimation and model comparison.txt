The Open Journal of Astrophysics
PreprinttypesetusingLATEXstyleopenjournalv.09/06/15
THE FUTURE OF COSMOLOGICAL LIKELIHOOD-BASED INFERENCE:
ACCELERATED HIGH-DIMENSIONAL PARAMETER ESTIMATION AND MODEL COMPARISON
Davide Piras⋆†1,2, Alicja Polanska†3, Alessio Spurio Mancini4,3, Matthew A. Price3, Jason D. McEwen3,5
1 CentreUniversitaired’Informatique,Universit´edeGen`eve,7routedeDrize,1227Gen`eve,Switzerland
2 D´epartementdePhysiqueTh´eorique,Universit´edeGen`eve,24quaiErnestAnsermet,1211Gen`eve4,Switzerland
3 MullardSpaceScienceLaboratory,UniversityCollegeLondon,HolmburySt.Mary,Dorking,Surrey,RH56NT,UK
4 DepartmentofPhysics,RoyalHolloway,UniversityofLondon,EghamHill,Egham,UKand
5AlanTuringInstitute,London,NW12DB,UK
(Dated: 22nd May 2024)
submitted XXX; accepted YYY
Abstract
We advocate for a new paradigm of cosmological likelihood-based inference, leveraging recent de-
velopments in machine learning and its underlying technology, to accelerate Bayesian inference in
high-dimensional settings. Specifically, we combine (i) emulation, where a machine learning model is
trained to mimic cosmological observables, e.g. CosmoPower-JAX; (ii) differentiable and probabilistic
programming, e.g. JAX and NumPyro, respectively; (iii) scalable Markov chain Monte Carlo (MCMC)
sampling techniquesthatexploitgradients,e.g.HamiltonianMonteCarlo;and(iv)decoupledandscal-
able Bayesian model selection techniques that compute the Bayesian evidence purely from posterior
samples, e.g. the learned harmonic mean implemented in harmonic. This paradigm allows us to carry
outacompleteBayesiananalysis,includingbothparameterestimationandmodelselection,inafrac-
tion of the time of traditional approaches. First, we demonstrate the application of this paradigm on
a simulated cosmic shear analysis for a Stage IV survey in 37- and 39-dimensional parameter spaces,
comparing ΛCDM and a dynamical dark energy model (w w CDM). We recover posterior contours
0 a
andevidenceestimatesthatareinexcellentagreementwiththosecomputedbythetraditionalnested
samplingapproachwhilereducingthecomputationalcostfrom8monthson48CPUcoresto2dayson
12 GPUs. Second, we consider a joint analysis between three simulated next-generation surveys, each
performinga3x2ptanalysis,resultingin157-and159-dimensionalparameterspaces.Standardnested
sampling techniques are simply not feasible in this high-dimensional setting, requiring a projected 12
years of compute time on 48 CPU cores; on the other hand, the proposed approach only requires 8
days of compute time on 24 GPUs. All packages used in our analyses are publicly available.
1. INTRODUCTION inference, stretching the capabilities of traditional infer-
ence methods.
The evolution of cosmological likelihood-based data
We advocate for a new paradigm of cosmological
analysis is heading towards a high-dimensional future.
likelihood-based inference to tackle the challenges of
Fueled by the acquisition of ever more constraining ob-
next-generation surveys. This approach leverages recent
servational data thanks to ongoing and upcoming sur-
veys like Euclid (Laureijs et al. 2011)1, the Dark En- developments inmachinelearning(ML)anditsunderly-
ing technology to accelerate both parameter estimation
ergySpectroscopicInstrument(DESI,Levietal.2019)2,
and model selection — the fundamentals of Bayesian in-
the Nancy Grace Roman Space Telescope (Spergel et al.
ference—inhigh-dimensionalsettings.Wesuggestcom-
2015)3, the Simons Observatory (Ade et al. 2019)4 and
bining (i) emulation; (ii) differentiable and probabilistic
the Vera Rubin Observatory (Ivezi´c et al. 2019)5, this
programming; (iii) scalable Markov chain Monte Carlo
trajectory simultaneously entails more stringent accur-
(MCMC) sampling techniques that exploit gradient in-
acy requirements and a subsequently higher number of
formationand(iv)decoupledandscalableBayesianmodel
parameterstodescribevarioussystematiceffects.Atthe
selection techniques computing the Bayesian evidence
same time, the ΛCDM model of cosmology is put un-
purely from posterior samples. At the basis of these de-
derextremepressure,withevermorecomplextheoretical
velopmentsistheabilitytoexploitmodernhardwareac-
models being developed to explain tensions in the values
celerators,suchasgraphicsprocessingunits(GPUs)and
of cosmological parameters, thus growing the size of the
tensorprocessingunits(TPUs),toprovideahighdegree
parameter space. While these developments promise sig-
of parallelization for significant computational accelera-
nificant advancements in our understanding of the Uni-
tion.
verse, they present a formidable challenge for Bayesian
Emulation is based on statistical and ML models
trained to replicate cosmological quantities of interest
⋆ E-mail:davide.piras@unige.ch with high accuracy in a fraction of the time required
† Jointfirstauthors
by traditional methods. By replacing slow forward mod-
1 https://www.euclid-ec.org/
2 https://www.desi.lbl.gov/ els underlying the likelihood function with, e.g. neural
3 https://roman.gsfc.nasa.gov/ networks, which efficiently run on GPUs, accurate phys-
4 https://simonsobservatory.org/ icalsimulationscanbecomputedwithsignificantlyfewer
5 https://www.lsst.org/ computational resources, providing massive speed-ups.
4202
yaM
12
]OC.hp-ortsa[
1v56921.5042:viXra2 Piras et al.
Additionally, one can pair emulators with a likeli- (McEwen et al. 2021).
hood fully written using differentiable and probabil- Wedemonstratethisparadigmontwoscenarios.First,
istic programming languages. This unlocks the acceler- we sample the posterior distribution for a simulated
ationprovidedbyMLenvironmentssuchasTensorFlow Stage IV cosmic shear survey configuration using NUTS
(Abadi et al. 2015)6, PyTorch (Paszke et al. 2019)7 and and a fully differentiable pipeline. We then compute the
JAX (Bradbury et al. 2018)8 to enable GPU execution evidence from the posterior chains using harmonic and
and differentiability of the likelihood with respect to the compare the estimate with that obtained using a nes-
input parameters. Moreover, probabilistic programming ted sampler. We perform this operation for two com-
languages can be used, e.g. to easily formulate complex peting cosmological models, with the goal of performing
hierarchical models. Bayesian model comparison, obtaining results in excel-
Differentiability also unlocks gradient-based sampling lent agreement with nested sampling, but taking only a
algorithms, such as Hamiltonian Monte Carlo (HMC, fraction of the time. We also showcase joint inference on
Duane et al. 1987; Neal 1996) and its variants, which three simulated next-generation surveys, each perform-
representapromisingavenuetoaddressthechallengesof inga3x2ptanalysis,obtainingvaluesoftheBayesfactor
high-dimensional inference. These techniques allow one in 8 days, as opposed to the 12 years estimated for the
to efficiently explore the complex parameter spaces that same result to be obtained by traditional techniques.
characterize cosmological data analyses. Yet, they cru- Thispaperisstructuredasfollows.WebegininSect.2
cially rely on having access to the derivatives of the like- with some background on parameter estimation and
lihood function with respect to input parameters, which modelcomparison,highlightingthechallengesassociated
are in general expensive and inaccurate, especially when withthelargeparameterspacescharacterizingupcoming
computed by finite differences. This obstacle is being surveys.WethenoutlineinSect.3eachofthefourpillars
overcomethroughthedevelopmentoffully-differentiable oftheproposednewparadigmofcosmologicallikelihood-
frameworksforcosmologicaldataanalysis,whichalsobe- basedinferenceforcompleteBayesiananalysis,including
nefit from the acceleration provided by the same dedic- both parameter estimation and model selection, in high-
ated hardware of ML models. dimensional settings. In Sect. 4 and Sect. 5 we introduce
The complexity of cosmological data analysis is not two simulated survey scenarios, to validate and demon-
limitedtoparameterestimationinhigh-dimensionalset- strateourframeworkforBayesianinference.Weconclude
tings; it also encompasses the task of model compar- in Sect. 6.
ison.Thisisparticularlyimportantforcosmology,whose
2. BACKGROUND
main goal is the identification of the most accurate
Bayesian analyses are the backbone of modern cosmo-
cosmological model of our Universe given observational
logy, providing a principled framework to obtain cosmo-
data. Bayesian model comparison requires the compu-
logical parameter constraints and compare models. Here
tation of the model evidence (also known as the mar-
we review the basics of Bayesian inference, discussing
ginal likelihood) for different models. Consequently, in
both parameter estimation and model comparison.
order to meaningfully and efficiently compare compet-
ing cosmological models in light of new data, it be- 2.1. Parameter estimation
comes imperative to develop novel methodologies that
The fundamental goal of Bayesian parameter estima-
enable evidence estimation for model comparison in the
tion is to recover an accurate estimate of the posterior
high-dimensional landscapes that will characterize next-
distribution p(θ|d,M), which encapsulates our under-
generation surveys. Such methodologies should not be
standing of the parameters θ given observed data d and
necessarily bound to a particular sampling method in
amodelM.ByemployingBayes’theorem,thisdistribu-
order to provide full flexibility. Being able to compute
tion is related to the prior distribution p(θ|M) ≡ π(θ),
the evidence from posterior chains independently from
the likelihood function p(d|θ,M)≡L(θ), and the model
thesamplingalgorithmisthusofparamountimportance
evidence p(d|M)≡z through the relation:
forenablingnext-generationcosmologicalmodelcompar- M
ison. p(d|θ,M)p(θ|M) L(θ)π(θ)
This paper focuses on both parameter estimation and p(θ|d,M)= = . (1)
p(d|M) z
model comparison in the context of Stage IV likelihood- M
based cosmological analyses, proposing a comprehensive Estimating the posterior distribution through its dir-
approach towards cosmological inference from upcoming ect evaluation on a grid of parameters is computation-
next-generation datasets. We particularly highlight how ally infeasible due to the curse of dimensionality, which
parameterestimationandmodelcomparisoncanbeper- becomes a prohibitive factor even in spaces of moder-
formed from posterior samples obtained using the No ate dimension. Additionally, the likelihood function of-
U-Turn Sampler (NUTS, Hoffman & Gelman 2014), a ten involves solving intricate physical models or running
highly efficient and adaptive variant of HMC. The ex- detailedsimulations,andtheposteriorlandscapemaybe
pensive cosmological Boltzmann solvers are replaced by multi-modal or have complex correlations between para-
the CosmoPower-JAX emulators (Spurio Mancini et al. meters.Agrid-basedevaluationmightmissimportantre-
2022; Piras & Spurio Mancini 2023), and evidence es- gions of the parameter space or require an impractically
timation is performed using harmonic, a software im- fine grid to capture these features. Sampling algorithms
plementation of the learned harmonic mean estimator such as MCMC methods, on the other hand, provide a
stochasticexplorationthatcanadapttotheshapeofthe
6 https://www.tensorflow.org/ distribution, and allocate computational resources more
7 https://pytorch.org/ efficiently by focusing on the regions of parameter space
8 https://github.com/google/jax with high posterior density.The future of likelihood-based cosmology 3
Commonly used MCMC algorithms in cosmology in- sampling, although this is only applicable for log-convex
clude the Metropolis-Hastings (Lewis & Bridle 2002; likelihoods; Cai et al. 2022).
Lewis 2013), affine-invariant ensemble (Goodman & Recently, methods to compute the evidence that are
Weare 2010; Foreman-Mackey et al. 2013), and nes- agnostictothesamplingtechniqueandonlyrequirepos-
ted sampling algorithms (Skilling 2006; Feroz & Hobson terior samples have gained popularity (McEwen et al.
2008; Feroz et al. 2009, 2019; Handley et al. 2015a,b), 2021; Srinivasan et al. 2024; Rinaldi et al. 2024). Among
which have found widespread use thanks to their clear them, the learned harmonic mean estimator (McEwen
formulations and publicly available implementations. et al. 2021) has been shown to provide robust estim-
Another sampling technique is HMC (Duane et al. 1987; ates of the Bayesian evidence in a variety of scenarios,
Neal1996),whichisamoreefficientalgorithmexploiting both in likelihood- and simulation-based inference (Po-
Hamiltonian dynamics. By leveraging the information lanska et al. 2023, 2024; Spurio Mancini et al. 2023). In
coming from the gradients of the likelihood with respect particular, Polanska et al. (2024) integrated normalizing
to the input parameters, HMC concentrates sampling in flowsintothelearnedharmonicmeanframeworktolearn
regions of high posterior mass (the so-called typical set), theinternalimportancesamplingtargetdistribution,en-
resultinginamoreefficientsampler,particularlyinhigh- hancing the robustness and scalability of the estimator.
dimensional settings. A significantly improved version of In contrast to the learned harmonic mean, alternative
HMC is NUTS (Hoffman & Gelman 2014), which over- approaches (Srinivasan et al. 2024; Rinaldi et al. 2024)
comes the required tuning of hyperparameters for the compute the evidence for a surrogate of the posterior,
numerical integration of Hamilton equations by prevent- limiting their accuracy (see Polanska et al. 2024 for fur-
ing the sampler from taking U-turns. By exploring the ther discussion).
parameter space in a more efficient way, NUTS results
3. METHODOLOGY
in a significantly higher acceptance rate, and has thus
found widespread use. We outline the four pillars of a new paradigm of cos-
mological likelihood-based inference that will be key to
2.2. Model comparison successfully tackling the challenges set by Stage IV cos-
ForBayesianmodelcomparisonitisnecessarytocom- mological surveys, including emulation (typically based
pute the Bayesian evidence onneuralnetworks),differentiableandprobabilisticpro-
gramming, scalable gradient-based MCMC sampling,
(cid:90)
and scalable evidence estimation that is agnostic to
z = p(d|θ,M)p(θ|M)dθ , (2)
M
sampling.Allofthesepillarsprovidetheabilitytoexploit
modernhardwareaccelerators,suchasGPUs,toprovide
which is a challenging computational problem even in
high degrees of parallelization for significant computa-
moderate dimensional settings. From the Bayesian evid-
tional acceleration.
ence it is possible to compute the Bayes factor (BF ), a
12
crucialquantityusedtoassesswhichmodel(M orM )
1 2 3.1. Emulation: CosmoPower-JAX
is favored given current data d and defined as:
ThetypicalbottleneckinastandardBayesiananalysis
BF ≡ p(d|M 1) = z M1 . (3) is the likelihood function, since it incorporates the en-
12 p(d|M ) z tire physical knowledge on the observable being probed.
2 M2
Thousands or even millions of likelihood evaluations are
In the common case where the models have equal prior
neededtoexploretheposteriordistributioninacomplete
probabilities, i.e. p(M ) = p(M ), the Bayes factor re-
1 2 manner, especially in high-dimensional settings. Even in
duces to the posterior model odds:
low-dimensionalsettings,though,theforwardmodelcan
p(M |d)p(M ) p(M |d) be computationally expensive since it describes increas-
BF 12 = p(M1 |d)p(M2 ) = p(M1 |d) . (4) ingly complex physical models, and extensions to the
2 1 2 ΛCDM model might introduce additional correlations
Estimating the evidence robustly and efficiently can among an increasing number of parameters. Each call
therefore unlock the full potential of Bayesian analyses, to the likelihood function thus has to be fast.
in that it allows one to assess which model is preferred Emulation based on ML techniques, and neural net-
by observational data. worksinparticular,havealreadyshownpromisingresults
Nested sampling, introduced by Skilling (2006), to accelerate the forward model, while providing excel-
providesastrategytoestimatetheevidenceforBayesian lent agreement with traditional techniques in a fraction
modelcomparison.Byacleverreparameterizationofthe of the computational time. Neural networks are trained
likelihood in terms of the enclosed prior volume, nested once on a dataset of key quantities that represent a bot-
sampling allows the evidence to be computed by a one- tleneck in the forward model, and then can be easily
dimensional integral. While nested sampling targets the integrated into the likelihood function, providing signi-
evidence,asaby-productposteriorinferencescanalsobe ficant acceleration while retaining the accuracy of the
calculatedbyappropriateimportanceweighting(Skilling predictions.Oneadditionaladvantageofneuralnetworks
2006). While highly successful, nested sampling places is that they effectively exploit the highly parallel com-
tightconstraintsonhowsamplingisperformed(sampling puting provided by modern hardware accelerators, such
the prior subject to likelihood isocontour constraints). as GPUs. This allows for faster training, batch predic-
Nested sampling couples the sampling strategy to the tionandscalablearchitectureswithevermoreexpressive
evidence calculation, limiting flexibility and scalabilty power.
to high-dimensional parameter spaces (a notable excep- ML-based emulation has found widespread use in cos-
tion for high-dimensional inference is proximal nested mology (see e.g. Auld et al. 2007; Auld et al. 2008;4 Piras et al.
Manrique-Yus & Sellentin 2019; Angulo et al. 2021; In this work we use NumPyro (Phan et al. 2019)11, the
Aric`o et al. 2022; Nygaard et al. 2022; Zennaro et al. NumPy backend for Pyro (Bingham et al. 2019). NumPyro
2023; Bonici et al. 2022, 2024). In this work, we em- is well-documented and easily interfaces with JAX, thus
ploytheCosmoPower-JAXpackage(Piras&SpurioMan- providing a mature framework to build a gradient-based
cini 2023)9, a JAX version of the CosmoPower framework inference pipeline. We implement the likelihood for the
(Spurio Mancini et al. 2022)10. These dense neural net- problems considered (see Sect. 4 and Sect. 5) in the
works were trained to map cosmological parameters to NumPyro PPL, which requires a separate likelihood im-
linear and nonlinear matter power spectra, serving as plementation. Critically, the likelihood must be differen-
an efficient replacement for the Boltzmann solvers CAMB tiable:CosmoPower-JAXprovidesemulationofthematter
(Lewis & Challinor 2011) or CLASS (Blas et al. 2011) power spectrum that is differentiable, and we couple it
to integrate into the likelihood. By replacing Boltzmann with jax-cosmo (Campagne et al. 2023)12 for differenti-
solvers with accurate neural networks, we accelerate the ablecosmologicalmodelstosimulateobservablespectra.
likelihood evaluations and thus solve the first significant
bottleneck of next-generation surveys. 3.3. Scalable MCMC sampling: NUTS
HMC is a gradient-based sampling algorithm that is
3.2. Differentiable and probabilistic programming: scalable to high-dimensional parameter spaces and does
JAX and NumPyro not suffer from the low acceptance rate of the stand-
ard Metropolis-Hastings algorithm. NUTS further im-
Within the current ML paradigm, models are trained
proves on the acceptance rate of HMC by preventing
usingoptimizersthatleveragegradientscomputedbythe
the sampling trajectory from returning to previously-
backpropagation of gradient information through auto-
visitedregionsoftheparameterspace.Thoughitrequires
matic differentiation (Baydin et al. 2018). Consequently,
a higher number of model evaluations, NUTS typically
each operation upon which a model may be built must
leads to more reliable convergence, and is thus ideal for
necessarily be differentiable; that is, rules by which tan-
sampling in the context of Stage IV surveys.
gent and cotangent vectors propagate under the operat-
Traditionally, the gradients required for HMC
ors’Jacobianmustbedefined(Wengert1964;Rumelhart
sampling are computed by finite differences, which is
et al. 1986; Baydin et al. 2018).
computationally costly and inaccurate. Since we have
ModernMLecosystems,suchasJAXandPyTorch,are
a differentiable pipeline, gradients can be computed by
constructed with this in mind, requiring that each prim-
automaticdifferentiation,providingaccelerationandim-
itiveoperationwithintheirlibrariesiscoupledwithasso-
provedaccuracy.Inthefuture,newsamplersthatfurther
ciatedgradientrules.Inthisway,usingthechainruleone
improvetheconvergencerateleadingtoevenmorerobust
can construct more complex operations, which are auto-
inferencecanbestraightforwardlyincorporatedintothis
matically differentiable (Bartholomew-Biggs et al. 2000;
paradigm.
Margossian 2019). By automatic differentiation gradi-
ents can then be computed efficiently and accurately
3.4. Decoupled and scalable Bayesian model
for complex operations, replacing numerical approxim-
comparison: learned harmonic mean
ations of the derivatives, which are typically slow and
unstable.Primarilyduetoitsrelativematurity,PyTorch The learned harmonic mean (McEwen et al. 2021)
provides a larger bank of primitive operations. However, provides a robust and scalable estimator of the Bayesian
JAXprovidesamoreflexibleecosystemthatisfunctional evidence that is decoupled from the sampling strategy.
in nature (Wadler 1992) and thus well suited to the im- It only requires samples from the posterior, and their
plementation of general physical models. In JAX com- corresponding unnormalized probability density. Hence,
plex operations may more easily be expressed, making it it can be used with posterior samples obtained through
thenaturalecosystemfortheintegrationofdifferentiable whatevermethodisbestsuitedfortheproblemathand.
programming in, e.g. cosmological models (Campagne This property allows the use of the efficient and scal-
et al. 2023), cosmological simulations (Li et al. 2024) or able NUTS sampler, while still being able to estimate
underlyingmathematicalmethods,suchassphericalhar- the evidence for Bayesian model comparison.
monic transforms (Price & McEwen 2024). The learned harmonic mean provides an estimator of
Recently,probabilisticprogramminglanguages(PPLs) the reciprocal evidence ρ=z−1, defined by
havebeenconstructedleveragingthesedifferentiablepro-
N
gramming ecosystems. Through PPLs, statistical opera-
ρˆ=
1 (cid:88) φ(θ i)
, θ ∼p(θ|d), (5)
tionssuchassamplingandconditioningcanbeexpressed N L(θ )π(θ ) i
i i
using a familiar and intuitive Python syntax, whilst also i=1
inheriting the differentiability of the underlying ecosys- where φ(θ) is an arbitrary normalized probability dens-
tems upon which they are constructed. For instance, ity. The estimator can be viewed through the lens of
PPLs allows one to easily formulate Bayesian hierarch- importance sampling, with the posterior acting as the
icalmodels,whicharewidelyusedincosmology(seee.g. sampling density and φ(θ) as the target density (e.g.
Mandeletal.2011;Shariffetal.2016;Alsingetal.2016, McEwen et al. 2021). If the importance sampling tar-
2017; Hinton et al. 2019; Porqueres et al. 2021; Mandel get density has fatter tails than the sampling density,
et al. 2022; Porqueres et al. 2023; Loureiro et al. 2023; the variance will grow large (even catastrophically) and
Sellentin et al. 2023). the estimator will fail. The key to preventing this issue
9 https://github.com/dpiras/cosmopower-jax 11 https://num.pyro.ai/en/stable/
10 https://github.com/alessiospuriomancini/cosmopower 12https://github.com/DifferentiableUniverseInitiative/jax cosmoThe future of likelihood-based cosmology 5
is to find an appropriate target φ(θ) that is normalized 4. COSMICSHEARANALYSISWITH37AND39
and contained within the posterior. The optimal target PARAMETERS
density is the normalized posterior itself (McEwen et al. We first demonstrate the application of the proposed
2021), although this requires knowledge of its normal- paradigm for a simulated next-generation survey per-
izing constant, which is precisely the quantity we are forming a power spectrum cosmic shear analysis. Our
attempting to estimate. In the learned harmonic mean goal is to estimate the Bayes factor between the ΛCDM
the target is learned to approximate the posterior from andw w CDMmodelsinhigh-dimensionalscenarios,ex-
0 a
posterior samples, subject to the constraint that it has posing the challenges of next-generation surveys if ap-
narrower tails. Several benchmark examples have been proached with traditional methods, while validating and
considered where the learned harmonic mean has been showcasing the scalability of our approach.
demonstrated to provide precise and accurate evidence
estimates (McEwen et al. 2021). 4.1. Likelihood
More recently, normalizing flows have been integrated
The likelihood details are the same as in Piras &
within the learned harmonic mean framework for the in-
SpurioMancini(2023),whichwesummarizehere,follow-
ternal machine learning technique to learn the import-
ing the notation of Spurio Mancini et al. (2022). We as-
ance target distribution (Polanska et al. 2023, 2024).
sume a tomographic survey with N =10 bins, where
Normalizingflows(Papamakariosetal.2021)canbeeleg- bins
each galaxy is placed in a bin according to its estimated
antlycoupledwiththelearnedharmonicmeantoprovide
photometric redshift z. We compute the angular power
an approach that is more robust, flexible and scalable
spectra between pairs of redshift bins i,j = 1,...,N
thanthemachinelearningmodelsconsideredpreviously. bins
andfordifferentprobes.Thecosmicshearangularpower
Normalizing flows work by taking a simple base dis- spectrum Cϵϵ(ℓ) is defined as:
tribution, often a standard Gaussian, through a series of ij
invertibletransformationswithlearnedparameters.Typ- Cϵϵ(ℓ)=Cγγ(ℓ)+CγI(ℓ)+CIγ(ℓ)+CII(ℓ) , (6)
ically, in order to train the model the Kullback-Leibler ij ij ij ij ij
divergence between the unknown target and the flow is whichincludesthecontributionsfrompureshear(γ)and
minimized,resultingintrainingbymaximumlikelihood. intrinsic alignment (I). Assuming the extended Limber
Usingnormalizingflowsitispossibletoapproximatepo- approximation(LoVerde&Afshordi2008),wecanwrite:
tentiallycomplexprobabilitydistributions,drawsamples
from them and evaluate their normalized density. CAB(ℓ)=(cid:90) χH W iA(χ)W jB(χ)
P
(cid:18)
k =
ℓ+1/2 ,z(cid:19)
dχ,
Once the flow is trained, its probability density can ij χ2 δδ χ
0
thenbeconcentratedbyreducingthe“temperature”T of (7)
itsbasedistribution.Specifically,thisisachievedbyscal- where P (k,z) is the matter power spectrum, χ =
δδ H
ingthebasedistribution’svariancebyafactorT ∈(0,1). c/H (with c the speed of light and H the Hubble con-
0 0
This has the effect of concentrating the base distribu- stant today) is the Hubble radius, and W(χ) indicates
tion’s density, and in turn the trained flow’s density due a window function for each probe {A,B} = {γ,I} as a
to the continuity and differentiability of the flow (Po- function of the comoving distance χ.
lanska et al. 2024). The concentrated flow is then a nor- For the pure cosmic shear γ the window function can
malized approximation of the posterior, maintaining a be written as:
goodtopologicalagreementwhilehavingthinnertails—
3Ω H2χ(cid:90) χH χ′−χ
a perfect candidate for the target φ(θ). Estimates of the Wγ(χ)= m 0 n (χ′) dχ′ , (8)
evidence error and other sanity checks can also be com- i 2c2 a i,source χ′
χ
puted (McEwen et al. 2021; Polanska et al. 2024). The
where a is the scale factor, Ω is the matter density
learnedharmonicmeanhasalreadybeenthoroughlyval- m
parameter today and n (z) represents the tomo-
idated against nested sampling for numerous cosmolo- i,source
graphicredshiftbindistribution ofthesourcesbeingob-
gicalproblems(McEwenetal.2021;Polanskaetal.2023,
served. For the intrinsic alignment field, we consider the
2024), and is implemented in the harmonic open-source
non-linearalignmentmodel(NLA,Hirata&Seljak2004;
Pythonpackage13.ThecodeiswritteninJAX(Bradbury
Joachimietal.2011)modifiedasinPiras&SpurioMan-
et al. 2018) to provide automatic differentiation and an
cini (2023):
efficient and scalable implementation that can be run on
accelerators such as GPUs. C ρ Ω
WI(χ)=−A 1 cr mn (χ) , (9)
Critically,thisapproachdecouplessamplingfromevid- i IA,i D(χ) i,source
ence calculation, allowing the use of scalable MCMC
sampling techniques (e.g. NUTS). By integrating nor- where D(χ) is the linear growth factor, ρ cr is the crit-
malizing flows inside the overarching statistical frame- ical density of the Universe, C 1 is a constant, and with
work of the learned harmonic mean we recover a robust one intrinsic alignment amplitude for each redshift bin
estimator of the evidence that is also computationally A IA,i, to allow for more flexibility in the modeling. For
scalable, proving the missing final component of a com- each redshift bin we also include a multiplicative bias
plete Bayesian analysis. m i (Huterer et al. 2006; Amara & R´efr´egier 2008; Kit-
ching et al. 2015; Taylor & Kitching 2018; Mandelbaum
et al. 2018), which rescales the cosmic shear power spec-
trumbyafactor(1+m )(1+m ),andashiftparameter
i j
D (Eifler et al. 2021), which shifts the mean of
zi,source
the binredshift distribution so thatwe actually consider
13 https://github.com/astro-informatics/harmonic/ n′ (z)=n (z−D ).
i,source i,source zi,source6 Piras et al.
Table 1: Evidence and Bayes factors for the two analyses considered in this work. The evidence values obtained with
nested sampling are the mean and standard deviation across three independent runs with different seeds, while the
computation time is the typical one for a single run, and includes sampling and evidence estimation. The likelihood
functionssampledwithnestedsamplingandtheNoU-TurnSampler(NUTS)areimplementedusingdifferentpackages
and include different normalizations; despite these differences, we recover consistent values of the Bayes factor (BF)
between ΛCDM and w w CDM.
0 a
(a) Cosmic shear with 37 (ΛCDM) and 39 (w w CDM) parameters, described in Sect. 4.
0 a
Method log(zΛCDM) log(zw0waCDM) logBF Totalcomputationtime
CAMB+nestedsampling −107.03±0.27 −107.81±0.74 0.78±0.79 ∼8months(48CPUs)
2days(sampling,12GPUs)+
CosmoPower-JAX+NUTS+harmonic 40956.55±0.06 40955.03±0.04 1.53±0.07
12minutes(evidence,1GPU+48CPUs)
na¨ıveflow
CosmoPower-JAX+NUTS+ 400958±5 40957±4 1±6 Similartoharmonic
estimator
(b) 3x(3x2pt) with 157 (ΛCDM) and 159 (w w CDM) parameters, described in Sect. 5.
0 a
Method log(zΛCDM) log(zw0waCDM) logBF Totalcomputationtime
CAMB+nestedsampling Unfeasible Unfeasible Unfeasible 12years(projected,48CPUs)
CosmoPower-JAX+NUTS+harmonic 406689.6+0.5 406687.7+0.5 1.9+0.7 8days(sampling,24GPUs)+
−0.3 −0.3 −0.5 17minutes(evidence,1GPU+48CPUs)
na¨ıveflow
CosmoPower-JAX+NUTS+ 406703±39 406701±62 2±73 Similartoharmonic
estimator
Finally, we model the redshift distributions with ker- proach, the proposed “future” paradigm, and an ap-
nel density estimation (KDE), and consider a Gaussian proach based on a na¨ıve flow estimation of the evidence
likelihood with a simulated covariance matrix as in Tu- for comparison (discussed in Spurio Mancini et al. 2023;
tusaus et al. (2020), with surface density of galaxies Polanska et al. 2024).
n = 30 galaxies/arcmin2, observed ellipticity dis- First, we use the nested sampler PolyChord (Hand-
source
persion σ =0.3, and sky fraction f =0.35. We com- ley et al. 2015a,b) to sample the posterior distribution
ϵ sky
pute each C(ℓ) spectrum for 30 log-spaced bin values and run the inference pipeline within Cobaya (Torrado
between ℓ = 30 and ℓ = 3000. To compute the & Lewis 2021), using CAMB to predict the matter power
min max
theoretical predictions for the cosmological observables spectrum. We run PolyChord with default settings on
we use the Core Cosmology Library (CCL, Chisari et al. 48 CPU cores twice, each time assuming either ΛCDM
2019). or w 0w aCDM. Since we found the values of the evidence
to fluctuate significantly between different runs, we re-
4.2. Models peated the process three times for each model, quoting
themeanandstandarddeviationofthelogevidence,and
We compare two cosmological models, namely the
the average time to obtain the Bayes factor.
fiducial ΛCDM model (considered also in Piras &
Second, we compare this “traditional“ approach with
Spurio Mancini 2023) and the w w CDM model, where
0 a our “future” paradigm, which replaces CAMB with the
in the latter we assume that the dark energy equation of
CosmoPower-JAX emulator, rewrites the likelihood in
state evolves with cosmic time according to:
the auto-differentiable language JAX, making use of
w(a)=w +(1−a)w , (10) jax-cosmo, samples the posterior distribution with
0 a
NUTS implemented in NumPyro, accelerated by auto-
which is the most common parametrization (also known
matic differentiation, and computes a robust estimate of
as the CPL parametrization) for dynamic dark en-
the evidence from posterior samples using the learned
ergy (Chevallier & Polarski 2001; Linder 2003). The
harmonic mean implemented in harmonic. We run the
w w CDM model introduces two extra parameters (w
0 a 0 NUTS chains in parallel on 12 A100 80GB GPUs,
and w ), and ΛCDM is recovered for w = −1 and
a 0 collecting 60 chains of 2000 samples each (after 400
w = 0. The simulated data vector is generated assum-
a samples of warm-up) for both ΛCDM and w w CDM.
ing a ΛCDM model, so we expect that the Bayes factor 0 a
For harmonic, we train a rational-quadratic spline flow
should favor this hypothesis. The prior distributions on
(Durkan et al. 2019), consisting of 4 layers and 64 spline
the cosmological and nuisance parameters are the same
bins, on a single GPU. We separate the NUTS samples
as those in Piras & Spurio Mancini (2023), with the ad-
intoatrainingsettheflowistrainedonandaninference
dition of uniform distributions for w and w between
0 a set that is used for estimation. We use 30% of chains for
(−1.5,−0.5)and(−0.5,0.5),respectively.Thetotalnum-
trainingandtheremaining70%forinferencetocompute
ber of parameters being sampled is thus 37 and 39 for
the evidence on 48 CPUs with temperature T =0.8.
ΛCDM and w w CDM, respectively.
0 a Third, the evidence can also be estimated directly
from the normalizing flow in an approach introduced by
4.3. Computational approaches
Spurio Mancini et al. (2023), and further discussed in
We compare three approaches to perform parameter Polanska et al.(2024), called the “na¨ıve flowestimator”.
estimation and model comparison: the “traditional” ap-The future of likelihood-based cosmology 7
Figure 1. Corner plot for the 37-dimensional ΛCDM model, showing the posterior contours obtained with
CosmoPower-JAX in red and the concentrated flow with temperature T =0.8 in blue.
Since the flow is a normalized approximation of the pos- cingharmonicwiththena¨ıveflowestimatoronthesame
terior, the expectation of the ratio of the unnormalized NUTS samples and hardware.
posteriordensityandtheflowdensityshouldbetheevid-
ence itself. This can be estimated via a Monte Carlo 4.4. Results
expectation as the mean of the ratios evaluated across The results are reported in Table 1(a). The values
samples from the posterior. In contrast to the learned of the evidence when using CAMB + nested sampling
harmonic mean, this approach is highly sensitive to the and CosmoPower-JAX + NUTS + harmonic use differ-
flow being a close approximation of the posterior and ent implementations of the likelihood (the latter imple-
consequently can suffer from a large bias and variance. mented in a probabilistic programming framework), in-
We also consider this method of estimating the evidence cluding different normalizations, so their values cannot
to demonstrate the need for an alternative principled be compared directly. Nevertheless, the log BFs are in
estimator of the evidence, as provided by the learned good agreement between the different approaches, with
harmonic mean. We compare the results obtained repla- 0.78 ± 0.79 for nested sampling and 1.53 ± 0.07 for8 Piras et al.
Figure 2. Same as Fig. 1 for the 39-dimensional w 0w aCDM model.
harmonic. Note that the evidence values correctly fa- for this analysis are shown in Fig. 1 and Fig. 2 for the
vourthegroundtruthmodelconsideredforthesimulated ΛCDM and w w CDM models respectively. Note that
0 a
data. Whilethe evidence computed by the na¨ıve flow es- the flow is contained within the posterior.
timator is also in agreement with a value of 1±6, notice
that its error is considerably larger than the other es- 5. 3X2PTANALYSISWITH157AND159PARAMETERS
timators, as anticipated. While the evidence values com- We further showcase the scalability and robustness
puted by the “traditional” and “future” paradigms are of our proposed paradigm by considering three differ-
incloseagreement,computationaltimesaredramatically ent next-generation simulated surveys, each performing
different, with the “future” paradigm being two orders a 3x2pt analysis, where information on cosmic shear,
of magnitude faster, taking 2 days (with only 12 addi- galaxy clustering and their cross-correlation is combined
tionalminutesrequiredtocomputetheevidence)instead to obtain more stringent constraints on the cosmological
of roughly 8 months. parameters (Joachimi & Bridle 2010). We refer to this
The contours for the posterior samples (red) alongside application as a 3x(3x2pt) analysis. We present the like-
theconcentratedflowatT =0.8(blue)usedforinference lihood and results below; the cosmological models andThe future of likelihood-based cosmology 9
computational approaches are the same as Sect. 4, al-
CosmoPower-JAX + NUTS
though as we discuss in Sect. 5.2 we are not able to run
Concentrated flow (T=0.8)
the “traditional” approach in this high-dimensional set-
ting.
0.125
5.1. Likelihood 0.115
The galaxy clustering field (n) power spectrum Cnn(ℓ)
ij 0.69
can be expressed using Eq. (7) assuming that galaxies 0.67
are a linearly-biased tracer of dark matter, with a free
parameter b for each redshift bin. The corresponding
i 0.97
window function can then be written as:
0.96
W in(χ)=b in i,lens(χ) , (11) 3.08
where n i,lens is a different sample of redshift distribu- 3.02
tions, also including a shift for each bin D . Finally,
zi,lens 2.65
the cross power spectrum between the shear field and
the galaxy clustering field, also called the galaxy-galaxy 2.55
lensing power spectrum, is written as: 0.705
Cnϵ(ℓ)=Cnγ(ℓ)+CnI(ℓ) . (12)
ij ij ij 0.695
0.020 0.0250.1160.124 0.660.68 0.958 0.9743.013.05 2.55 2.65 0.696 0.704
Thetotalnumberofparametersforthiscross-surveyana-
b cdm
h ns ln(1010A s)c
min 0
lysisis157forΛCDMand159forw w CDM,sinceeach
0 a
survey comes with its own 50 nuisance parameters, and Figure 3. Cornerplotofthesubsetofcosmologicalpara-
all surveys share 7 (or 9) cosmological parameters. The meters for the 157-dimensional ΛCDM model, showing
specific details of every survey are reported in Piras & the posterior contours in red and the concentrated flow
Spurio Mancini (2023). with temperature T =0.8 in blue.
5.2. Results
CosmoPower-JAX + NUTS
All numerical results for this higher dimensional ana-
Concentrated flow (T=0.8)
lysisarereportedinTable1(b).Thehighnumberofpara-
meters and the need to consider multiple probes pose a 0.125
significant challenge for “traditional” methods, despite 0.115
being quite realistic for next-generation surveys. We es- 0.70
timatedthatthecomputationoftheBayesfactorinsuch
ascenariowouldrequireabout12yearson48CPUcores, 00 .. 96 85
making it effectively impossible to perform model selec-
0.96
tion in a reasonable time.
3.1
On the other hand, the proposed “future” paradigm
provides an estimate of the Bayes factor based on 40 3.0
(45)convergedchainsfortheΛCDM(w 0w aCDM)model, 2.65
totalling 8 days on 24 GPUs, with only 17 additional
2.55
minutes required to compute the evidence. In this case,
0.705
the flow model we consider is constructed from 2 layers
0.695
and 128 spline bins. The log Bayes factor computed by
0.97
harmonic is 1.9+0.7, which correctly favours the ground
−0.5
truthmodelconsideredforthesimulateddata.Theevid- 1.03
0.1
encecomputedbythena¨ıveflowestimatoris2±73:itser-
ror is very large, as anticipated, rendering this approach 0.1
unusable in practice. 0.020 0.025 0.115 0.125 0.66 0.700.9550.970 3.01 3.09 2.55 2.65 0.695 0.705 1.02 0.98 0.1 0.1
b cdm h ns ln(1010A s)c min 0 w 0 wa
The contours plots for the posterior samples (red)
alongside the concentrated flow at T = 0.8 (blue) used Figure 4. Same as Fig. 3 for the 159-dimensional
for inference for this analysis are shown in Fig. 3 and w 0w aCDM model.
Fig. 4 for the ΛCDM and w w CDM models respect-
0 a
ively. Fig. 5 and Fig. 6 show the one-dimensional mar- probabilistic programming, high-dimensional sampling
ginal plots of the posterior samples (red) alongside the and robust statistical estimation to tackle the Bayesian
concentrated flow at T = 0.8 (blue), for all the model likelihood-based cosmological analyses of the future.
parameters for ΛCDM and w w CDM respectively. It Instead of relying on nested sampling with stand-
0 a
can be seen that the flow is indeed contained within the ard Boltzmann solvers, we leverage ML-based emu-
posterior as required by the learned harmonic mean. lation (CosmoPower-JAX), differentiable programming
(JAX), probabilistic programming (NumPyro), more effi-
6. CONCLUSIONS cient samplers (NUTS), and robust evidence estimation
We propose a combination of state-of-the-art tech- (harmonic)toperformend-to-endcosmologicalanalyses
niques from machine learning (ML), differentiable and includingparameterestimationandmodelcomparisonin
mdc
h
sn
)sA0101(nlnimc
0
mdc
h
sn
)sA0101(nlnimc
0
0w
aw10 Piras et al.
0.020 0.025 0.115 0.125 0.65 0.70 0.96 0.98 3.0 3.1 2.55 2.65 0.695 0.705 0.89 0.91 0.79 0.81 0.69 0.71
b cdm h ns ln(1010As) cmin 0 A IS A1 ,1 A IS A1 ,2 A IS A1 ,3
0.59 0.61 0.49 0.51 0.39 0.41 0.29 0.31 0.19 0.21 0.090.11 0.02 0.02 0 4 2 2 2 2
AS1 AS1 AS1 AS1 AS1 AS1 AS1 DS1 ×104 DS1 ×104 DS1 ×104
IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source z2,source z3,source
2 2 2 2 2 2 2 2 2 2 0 4 2 2 1 1 1 1 1 1
DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 mS1×104 mS1×104 mS1×104
z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1 2 3
1 1 1 1 1 1 1 1 1 1 2 2 2 2 0.00 0.02 0.005 0.015 0.007 0.013
mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 DS1 DS1 DS1
4 5 6 7 8 9 10 z1,lens z2,lens z3,lens
0.0080.012 0.010 0.014 0.008 0.012 0.008 0.012 0.008 0.012 0.008 0.012 0.008 0.012 0.995 1.005 0.997 1.003 0.997 1.003
DS1 DS1 DS1 DS1 DS1 DS1 DS1 bS1 bS1 bS1
z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1 2 3
0.997 1.003 0.997 1.003 0.9981.002 0.9981.002 0.9981.002 0.9981.002 0.9981.002 5.9 6.0 5.4 5.5 4.8978 4.9979
bS1 bS1 bS1 bS1 bS1 bS1 bS1 AS2 AS2 AS2
4 5 6 7 8 9 10 IA,1 IA,2 IA,3
4.3987 4.50136.90201 3.999831.39916 3.496622.90771 3.002324.40204 2.498214.9010 2.0026 1.4 1.5 0.001 0.001 0.001 0.001 0.001 0.001
AS2 AS2 AS2 AS2 AS2 AS2 AS2 DS2 DS2 DS2
IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source z2,source z3,source
0.001 0.001 0.001 0.001 0.002098 0.0021300.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 5 5 0.000 0.001 4 4
DS2 DS2 DS2 DS2 DS2 DS2 DS2 mS2×104 mS2 mS2×104
z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1 2 3
0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 9 9 0.002 0.002 0.002 0.002 0.005 0.005 0.005 0.005 0.005 0.005
mS2 mS2 mS2 mS2 mS2×104 mS2 mS2 DS2 DS2 DS2
4 5 6 7 8 9 10 z1,lens z2,lens z3,lens
0.003 0.003 0.004 0.004 0.003 0.003 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 1.295 1.305 1.400 1.408 1.495 1.505
DS2 DS2 DS2 DS2 DS2 DS2 DS2 bS2 bS2 bS2
z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1 2 3
1.595 1.605 1.695 1.705 1.795 1.805 1.90 1.91 1.99 2.01 2.09 2.11 2.19 2.21 0.99 1.01 0.89 0.91 0.79 0.81
bS2 bS2 bS2 bS2 bS2 bS2 bS2 AS3 AS3 AS3
4 5 6 7 8 9 10 IA,1 IA,2 IA,3
0.69 0.71 0.59 0.61 0.49 0.51 0.39 0.41 0.29 0.31 0.19 0.21 0.100 0.1250.002137 0.002125 9 9 0.001 0.001
AS3 AS3 AS3 AS3 AS3 AS3 AS3 DS3 DS3 ×104 DS3
IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source z2,source z3,source
0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.002 0.002 0.002 0.002 0.002 0.002 3 3 5 5 5 5
DS3 DS3 DS3 DS3 DS3 DS3 DS3 mS3×104 mS3×104 mS3×104
z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1 2 3
5 5 5 5 5 5 5 5 5 5 0 8 5 5 0.00996 0.01112 0.005 0.005 0.003 0.003
mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3 ×104 DS3 DS3 DS3
4 5 6 7 8 9 10 z1,lens z2,lens z3,lens
0.004 0.004 0.003 0.003 0.003 0.003 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 1.295 1.305 1.345 1.355 1.395 1.405
DS3 DS3 DS3 DS3 DS3 DS3 DS3 bS3 bS3 bS3
z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1 2 3
1.445 1.455 1.495 1.505 1.545 1.555 1.595 1.605 1.645 1.655 1.695 1.705 1.745 1.755
bS3 bS3 bS3 bS3 bS3 bS3 bS3
4 5 6 7 8 9 10
Figure 5. Marginaldistributionsofallparametersforthe157-dimensionalΛCDMmodel,withtheposteriordistribution
obtained with CosmoPower-JAX in red, and the concentrated flow with temperature T =0.8 in blue.The future of likelihood-based cosmology 11
0.020 0.025 0.11 0.13 0.65 0.70 0.96 0.98 3.0 3.1 2.55 2.65 0.695 0.705 1.03 0.97 0.1 0.1 0.89 0.91
b cdm h ns ln(1010A s) c min 0 w 0 wa A IS A1 ,1
0.79 0.81 0.69 0.71 0.59 0.61 0.49 0.51 0.39 0.41 0.275 0.300 0.190.21 0.090.11 0.02 0.02 2 2
AS1 AS1 AS1 AS1 AS1 AS1 AS1 AS1 AS1 DS1 ×104
IA,2 IA,3 IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source
2 2 2 2 2 2 2 2 2 2 0 4 2 2 2 2 4 0 1 1
DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 DS1 ×104 mS1×104
z2,source z3,source z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1
1 1 0 2 1 1 1 1 1 1 1 1 1 1 2 2 2 2 0.00 0.02
mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 mS1×104 DS1
2 3 4 5 6 7 8 9 10 z1,lens
0.005 0.015 0.007 0.013 0.007 0.013 0.008 0.012 0.008 0.012 0.008 0.012 0.008 0.012 0.008 0.012 0.008 0.012 0.995 1.005
DS1 DS1 DS1 DS1 DS1 DS1 DS1 DS1 DS1 bS1
z2,lens z3,lens z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1
0.995 1.005 0.995 1.005 0.995 1.005 0.995 1.005 0.995 1.005 1.000 1.008 0.995 1.005 0.995 1.005 0.995 1.005 5.9 6.0
bS1 bS1 bS1 bS1 bS1 bS1 bS1 bS1 bS1 AS2
2 3 4 5 6 7 8 9 10 IA,1
5.4 5.5 4.9 5.0 4.4 4.5 3.9 4.0 3.4 3.5 2.9 3.0 2.4 2.51.8991 2.0061 1.4 1.5 0.001075 0.001099
AS2 AS2 AS2 AS2 AS2 AS2 AS2 AS2 AS2 DS2
IA,2 IA,3 IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source
0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.002 0.0020.002 0.002 0.002 0.002 0.000 0.003 0.002 0.002 5 5
DS2 DS2 DS2 DS2 DS2 DS2 DS2 DS2 DS2 mS2×104
z2,source z3,source z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1
5 5 0.000 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.002 0.002 0.002 0.002 0.002 0.002 0.005 0.005
mS2×104 mS2 mS2 mS2 mS2 mS2 mS2 mS2 mS2 DS2
2 3 4 5 6 7 8 9 10 z1,lens
0.005 0.005 0.003 0.003 0.003 0.003 0.004 0.004 0.003 0.003 0.003 0.003 0.002 0.002 0.002 0.002 0.002 0.002 1.295 1.305
DS2 DS2 DS2 DS2 DS2 DS2 DS2 DS2 DS2 bS2
z2,lens z3,lens z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1
1.39 1.41 1.49 1.51 1.59 1.61 1.69 1.71 1.79 1.81 1.89 1.91 1.99 2.01 2.10 2.12 2.19 2.21 1.000 1.025
bS2 bS2 bS2 bS2 bS2 bS2 bS2 bS2 bS2 AS3
2 3 4 5 6 7 8 9 10 IA,1
0.89 0.91 0.79 0.81 0.69 0.71 0.59 0.61 0.49 0.51 0.39 0.41 0.29 0.31 0.19 0.21 0.0750.100 0.001957 0.001860
AS3 AS3 AS3 AS3 AS3 AS3 AS3 AS3 AS3 DS3
IA,2 IA,3 IA,4 IA,5 IA,6 IA,7 IA,8 IA,9 IA,10 z1,source
0.002108 0.0021390.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 9 9 0.002 0.002 0.002 0.002 0.002 0.002 0 6
DS3 DS3 DS3 DS3 DS3 DS3 ×104 DS3 DS3 DS3 mS3×104
z2,source z3,source z4,source z5,source z6,source z7,source z8,source z9,source z10,source 1
5.44 5.57 5 5 0 6 0 6 5 5 5 5 7.00 7.49 5 5 5 5 0.00 0.01
mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3×104 mS3 ×104 DS3
2 3 4 5 6 7 8 9 10 z1,lens
0.005 0.005 0.003 0.003 0.0000.004 0.003 0.003 0.003 0.003 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 1.295 1.305
DS3 DS3 DS3 DS3 DS3 DS3 DS3 DS3 DS3 bS3
z2,lens z3,lens z4,lens z5,lens z6,lens z7,lens z8,lens z9,lens z10,lens 1
1.345 1.355 1.395 1.405 1.44 1.46 1.49 1.51 1.54 1.56 1.59 1.61 1.64 1.66 1.69 1.71 1.74 1.76
bS3 bS3 bS3 bS3 bS3 bS3 bS3 bS3 bS3
2 3 4 5 6 7 8 9 10
Figure 6. Same as Fig. 5 for the 159-dimensional w 0w aCDM model.12 Piras et al.
two challenging cosmological scenarios scaling up to 159 AbadiM.,etal.,2015,TensorFlow:Large-ScaleMachineLearning
parameters. onHeterogeneousSystems,https://www.tensorflow.org/
We first computed the Bayes factor for a simulated AdeP.,etal.,2019,JournalofCosmologyandAstroparticle
Physics,2019,056–056
Stage IV cosmic shear analysis comparing the ΛCDM
AlsingJ.,HeavensA.,JaffeA.H.,KiesslingA.,WandeltB.,
model with 37 parameters and a dynamical dark energy
HoffmannT.,2016,MNRAS,455,4452
modelw 0w aCDMwith39parameters.Wedemonstrated AlsingJ.,HeavensA.,JaffeA.H.,2017,MNRAS,466,3272
excellent agreement with nested sampling despite differ- AmaraA.,R´efr´egierA.,2008,MonthlyNoticesoftheRoyal
ent implementations of the likelihood, while requiring AstronomicalSociety,391,228
AnguloR.E.,ZennaroM.,ContrerasS.,Aric`oG.,
twoordersofmagnitudelesscomputationaltime.Wead-
Pellejero-Iban˜ezM.,Stu¨ckerJ.,2021,MNRAS,507,5869
ditionally demonstrated the scalability of our approach Aric`oG.,AnguloR.,ZennaroM.,2022,OpenResearchEurope,1
by considering the joint analysis of three Stage IV sur- AuldT.,BridgesM.,HobsonM.P.,GullS.F.,2007,MNRAS,
veys, each performing a 3x2pt analysis, totalling either 376,L11
157 (ΛCDM) or 159 (w w CDM) parameters. We com- AuldT.,BridgesM.,HobsonM.P.,2008,MonthlyNoticesofthe
0 a RoyalAstronomicalSociety,387,1575
putedtheBayesfactorobtainingresultsrequiringonly8
Bartholomew-BiggsM.,BrownS.,ChristiansonB.,DixonL.,
days on 24 GPUs, while projecting that a “traditional” 2000,JournalofComputationalandAppliedMathematics,
analysis on 48 CPU cores would require 12 years, as- 124,171
suming nested sampling is capable of scaling to such a BaydinA.,PearlmutterB.,RadulA.,SiskindJ.,2018,Journalof
high-dimensional setting. MachineLearningResearch,18,1
BinghamE.,etal.,2019,J.Mach.Learn.Res.,20,28:1
We advocate for a combination of ML emulation,
BlasD.,LesgourguesJ.,TramT.,2011,JournalofCosmology
differentiable and probabilistic programming, scalable andAstroparticlePhysics,2011,034–034
samplingandrobustevidenceestimationtotackleforth- BoniciM.,BiggioL.,CarboneC.,GuzzoL.,2022,arXive-prints,
comingcosmologicallikelihood-basedanalyses.This“fu- p.arXiv:2206.14208
BoniciM.,BaxterE.,BianchiniF.,Ruiz-ZapateroJ.,2024,The
ture”paradigmunlocksparameterestimationandmodel
OpenJournalofAstrophysics,7,10
comparison for Stage IV cosmological surveys with an
BradburyJ.,etal.,2018,JAX:composabletransformationsof
unprecedented number of parameters. Given that all Python+NumPyprograms,http://github.com/google/jax
packages used in our analysis are already publicly avail- CaiX.,McEwenJ.D.,PereyraM.,2022,Statisticsand
able, we envision this approach could become the stand- Computing,32
CampagneJ.-E.,etal.,2023,OpenJ.Astrophys.,6,1
ardinfuturelikelihood-basedanalyses,allowingthecom-
ChevallierM.,PolarskiD.,2001,InternationalJournalofModern
munity to extract the maximal amount of information
PhysicsD,10,213
from upcoming observations in a practical timescale. ChisariN.E.,etal.,2019,TheAstrophysicalJournalSupplement
Series,242,2
DuaneS.,KennedyA.,PendletonB.J.,RowethD.,1987,Physics
AUTHORCONTRIBUTIONS
LettersB,195,216
DP: conceptualization; formal analysis; investiga- DurkanC.,BekasovA.,MurrayI.,PapamakariosG.,2019,
tion;methodology;validation;software;visualization;re- Advancesinneuralinformationprocessingsystems,32
sources; writing – original draft. AP: formal analysis; EiflerT.,etal.,2021,MonthlyNoticesoftheRoyalAstronomical
Society,507,1514
methodology; validation; software; visualization; writ-
FerozF.,HobsonM.P.,2008,MonthlyNoticesoftheRoyal
ing – original draft. ASM: conceptualization; method- AstronomicalSociety,384,449
ology; validation; software; supervision; writing – review FerozF.,HobsonM.P.,BridgesM.,2009,MonthlyNoticesofthe
& editing. MAP: software; valididation; writing – re- RoyalAstronomicalSociety,398,1601
FerozF.,HobsonM.P.,CameronE.,PettittA.N.,2019,The
view & editing. JDM: conceptualization; methodology;
OpenJournalofAstrophysics,2
software; validation; project administration; funding ac-
Foreman-MackeyD.,HoggD.W.,LangD.,GoodmanJ.,2013,
quisition; supervision; writing – review & editing. PublicationsoftheAstronomicalSocietyofthePacific,125,306
GoodmanJ.,WeareJ.,2010,CommunicationsinApplied
MathematicsandComputationalScience,5,65
ACKNOWLEDGEMENTS
HandleyW.J.,HobsonM.P.,LasenbyA.N.,2015a,Monthly
DPwassupportedbyaSwissNationalScienceFound- NoticesoftheRoyalAstronomicalSociety:Letters,450,L61
ation (SNSF) Professorship grant (No. 202671), and by HandleyW.J.,HobsonM.P.,LasenbyA.N.,2015b,Monthly
theSNFSinergiagrantCRSII5-193826“AstroSignals:A NoticesoftheRoyalAstronomicalSociety,453,4384
HintonS.R.,etal.,2019,ApJ,876,15
New Window on the Universe, with the New Generation
HirataC.M.,SeljakU.,2004,Phys.Rev.D,70,063526
of Large Radio-Astronomy Facilities”. AP is supported HoffmanM.D.,GelmanA.,2014,J.Mach.Learn.Res.,15,
bytheUCLCentreforDoctoralTraininginDataIntens- 1593–1623
iveScience(STFCgrantnumberST/W00674X/1).ASM HutererD.,TakadaM.,BernsteinG.,JainB.,2006,Monthly
acknowledges support from the MSSL STFC Consolid- NoticesoftheRoyalAstronomicalSociety,366,101
Ivezi´cZˇ.,etal.,2019,ApJ,873,111
ated Grant ST/W001136/1. MAP and JDM are suppor-
JoachimiB.,BridleS.L.,2010,A&A,523,A1
ted in part by EPSRC (grant number EP/W007673/1). JoachimiB.,MandelbaumR.,AbdallaF.B.,BridleS.L.,2011,
The authors are pleased to acknowledge that part of the A&A,527,A26
work reported on in this paper was performed using the KitchingT.D.,TaylorA.N.,CropperM.,HoekstraH.,HoodR.
K.E.,MasseyR.,NiemiS.,2015,MonthlyNoticesoftheRoyal
Princeton Research Computing resources at Princeton
AstronomicalSociety,455,3319
University which is a consortium of groups led by the
LaureijsR.,etal.,2011,arXive-prints,p.arXiv:1110.3193
Princeton Institute for Computational Science and En- LeviM.,etal.,2019,inBulletinoftheAmericanAstronomical
gineering (PICSciE) and Office of Information Techno- Society.p.57(arXiv:1907.10688),
logy’s Research Computing. doi:10.48550/arXiv.1907.10688
LewisA.,2013,Phys.Rev.D,87,103529
LewisA.,BridleS.,2002,Phys.Rev.D,66,103511
REFERENCESThe future of likelihood-based cosmology 13
LewisA.,ChallinorA.,2011,CAMB:CodeforAnisotropiesin PolanskaA.,PriceM.A.,SpurioManciniA.,McEwenJ.D.,
theMicrowaveBackground,AstrophysicsSourceCodeLibrary, 2023,PhysicalSciencesForum,9
recordascl:1102.026(ascl:1102.026) PolanskaA.,PriceM.A.,PirasD.,ManciniA.S.,McEwenJ.D.,
LiY.,ModiC.,JamiesonD.,ZhangY.,LuL.,FengY.,Lanusse 2024,LearnedharmonicmeanestimationoftheBayesian
F.,GreengardL.,2024,AstrophysicalJournal,Supplement evidencewithnormalizingflows(arXiv:2405.05969)
Series,270 PorqueresN.,HeavensA.,MortlockD.,LavauxG.,2021,
LinderE.V.,2003,Phys.Rev.Lett.,90,091301 MNRAS,502,3035
LoVerdeM.,AfshordiN.,2008,PhysicalReviewD,78 PorqueresN.,HeavensA.,MortlockD.,LavauxG.,Makinen
LoureiroA.,WhitewayL.,SellentinE.,SilvaLafaurieJ.,Jaffe T.L.,2023,arXive-prints,p.arXiv:2304.04785
A.H.,HeavensA.F.,2023,TheOpenJournalofAstrophysics, PriceM.A.,McEwenJ.D.,2024,JournalofComputational
6,6 Physics,p.113109
MandelK.S.,NarayanG.,KirshnerR.P.,2011,ApJ,731,120 RinaldiS.,DemasiG.,DelPozzoW.,HannukselaO.A.,2024,
MandelK.S.,ThorpS.,NarayanG.,FriedmanA.S.,AvelinoA., arXive-prints,p.arXiv:2405.07504
2022,MNRAS,510,3939 RumelhartD.E.,HintonG.E.,WilliamsR.J.,1986,Nature,
MandelbaumR.,etal.,2018,MonthlyNoticesoftheRoyal 323,533
AstronomicalSociety,481,3170 SellentinE.,LoureiroA.,WhitewayL.,LafaurieJ.S.,Balan
Manrique-YusA.,SellentinE.,2019,MonthlyNoticesofthe S.T.,OlamaieM.,JaffeA.H.,HeavensA.F.,2023,TheOpen
RoyalAstronomicalSociety JournalofAstrophysics,6,31
MargossianC.C.,2019,WIREsDataMiningandKnowledge ShariffH.,JiaoX.,TrottaR.,vanDykD.A.,2016,ApJ,827,1
Discovery,9,e1305 SkillingJ.,2006,BayesianAnalysis,1,833
McEwenJ.D.,WallisC.G.R.,PriceM.A.,ManciniA.S.,2021, SpergelD.,etal.,2015,arXive-prints,p.arXiv:1503.03757
MachinelearningassistedBayesianmodelcomparison:learnt SpurioManciniA.,PirasD.,AlsingJ.,JoachimiB.,Hobson
harmonicmeanestimator(arXiv:2111.12720) M.P.,2022,MonthlyNoticesoftheRoyalAstronomical
NealR.M.,1996,BayesianLearningforNeuralNetworks,Vol. Society,511,1771–1788
118ofLectureNotesinStatistics.Springer-Verlag SpurioManciniA.,DochertyM.M.,PriceM.A.,McEwenJ.D.,
NygaardA.,BrinchHolmE.,HannestadS.,TramT.,2022,arXiv 2023,RASTechniquesandInstruments,2,710
e-prints,p.arXiv:2205.15726 SrinivasanR.,CrisostomiM.,TrottaR.,BarausseE.,BreschiM.,
PapamakariosG.,NalisnickE.,RezendeD.J.,MohamedS., 2024,arXive-prints,p.arXiv:2404.12294
LakshminarayananB.,2021,TheJournalofMachineLearning TaylorA.N.,KitchingT.D.,2018,MonthlyNoticesoftheRoyal
Research,22,2617 AstronomicalSociety,477,3397
PaszkeA.,etal.,2019,in,AdvancesinNeuralInformation TorradoJ.,LewisA.,2021,JournalofCosmologyand
ProcessingSystems32.CurranAssociates,Inc.,pp8024–8035, AstroparticlePhysics,2021,057
http: TutusausI.,etal.,2020,A&A,643,A70
//papers.neurips.cc/paper/9015-pytorch-an-imperative- WadlerP.,1992,inProceedingsofthe19thACM
style-high-performance-deep-learning-library.pdf SIGPLAN-SIGACTsymposiumonPrinciplesofprogramming
PhanD.,PradhanN.,JankowiakM.,2019,arXivpreprint languages.pp1–14
arXiv:1912.11554 WengertR.E.,1964,Commun.ACM,7,463–464
PirasD.,SpurioManciniA.,2023,TheOpenJournalof ZennaroM.,AnguloR.E.,Pellejero-Iba´n˜ezM.,Stu¨ckerJ.,
Astrophysics,6 ContrerasS.,Aric`oG.,2023,MNRAS,524,2407
provides fast and easy peer review for new papers in the
astro-phsectionofthearXiv,makingthereviewingpro-
This paper was built using the Open Journal of As- cesssimplerforauthorsandrefereesalike.Learnmoreat
trophysics LATEX template. The OJA is a journal which http://astro.theoj.org.