Enabling Additive Manufacturing Part Inspection of
Digital Twins via Collaborative Virtual Reality
Vuthea Chheang1,*, Saurabh Narain1, Garrett Hooten1, Robert Cerda1, Brian Au1, Brian
Weston1, Brian Giera1, Peer-Timo Bremer1, and Haichao Miao1
1LawrenceLivermoreNationalLaboratory,Livermore,CA,94550,UnitedStates
*chheang1@llnl.gov
ABSTRACT
Digitaltwins(DTs)areanemergingcapabilityinadditivemanufacturing(AM),settorevolutionizedesignoptimization,inspection,
insitumonitoring,androotcauseanalysis. AMDTstypicallyincorporatemultimodaldatastreams,rangingfrommachine
toolpathsandin-processimagingtoX-rayCTscansandperformancemetrics.DespitetheevolutionofDTplatforms,challenges
remainineffectivelyinspectingthemforactionableinsights,eitherindividuallyorinamultidisciplinaryteamsetting. Quality
assurance,manufacturingdepartments,pilotlabs,andplantoperationsmustcollaboratecloselytoreliablyproduceparts
atscale. ThisisparticularlycrucialinAMwherecomplexstructuresrequireacollaborativeandmultidisciplinaryapproach.
Additionally,thelarge-scaledataoriginatingfromdifferentmodalitiesandtheirinherent3Dnatureposesignificanthurdlesfor
traditional2Ddesktop-basedinspectionmethods. ToaddressthesechallengesandincreasethevaluepropositionofDTs,we
introduceanovelvirtualreality(VR)frameworktofacilitatecollaborativeandreal-timeinspectionofDTsinAM.Thisframework
includesadvancedfeaturesforintuitivealignmentandvisualizationofmultimodaldata,visualocclusionmanagement,streaming
large-scalevolumetricdata,andcollaborativetools,substantiallyimprovingtheinspectionofAMcomponentsandprocessesto
fullyexploitthepotentialofDTsinAM.
Introduction
Additivemanufacturing(AM)hasbeenrevolutionizingtheproductionofcomplexpartsacrossvariousindustries. AMinvolves
creatinganobjectinalayerwise1orvolumetricfashion2,usingeitherpolymeric,ceramic,metallic,ormulti-materialprinting.
AcriticalchallengecommontoallAMtechniquesistoensurethatthefinalpartmeetsthedesigncriteria. DefectsinAM,
suchasexcessiveorinsufficientmaterialdeposition,internalvoids,orporositydefectsareoftenconcealedinsidethepartand
notaccessibletotraditionalinspectionmethods3,4. Detectingsuchdefectsrequiresexpensiveandtime-consumingcomputed
tomography(CT)scanswhicharesubsequentlychallengingtoprocessduetotheirsize,complexity,andinherentspatialnature.
Nevertheless,inspectionisanunavoidablestepintheoverallmanufacturingprocess.
Giventheubiquitouschallengesassociatedwithprocessmonitoring,partinspection,andpartperformanceverification,
industrialandcommercialsectorsarebuildingdigitaltwins(DTs)ofAMplatformstomitigatetheseissues5–7. Whilethere
exist various definitions of what constitutes a DT in AM, the most common notions include a variety of rich multimodal
datastreamscoveringtheentireproductioncyclefromdesigntoprinting,toinspectionandlifecyclemanagement. Inthis
context,AMdataiscollectedfromvarioussources,suchasdesignfiles,sensingsuites,images,prescribedtoolpaths,machine
kinematicsandhealthmonitoring,CTscans,andotherperformancemeasurements. However,fewapproachesexistthatcan
automaticallyandjointlyprocessalldifferentmodalitiesandoftenthefirstchallengeusersfaceishowtoproductivelyexplore
theDTdatainacoherentfashion8,9. Here,wecontendthatcarefullydesignedvisualizationsandintuitiveinteractionscoupled
toasharedvirtualenvironmentcanmakeDTssignificantlymoreeffective. Nevertheless,designingsuchvisualizationsforthe
data-intensiveandmultimodalstreamsinanintuitiveandscalablemannerremainsachallenge10,11. Forexample,CTscans,
whileindispensableforensuringthestructuralintegrityandaccuracyofthesecomplexparts,producelarge-scaleandcomplex
volumes. Thethree-dimensionalanddensenatureofthesedatasetsmakesthemnotonlydifficulttoinspectbutalsochallenging
to interpret, especially when considering the boutique or low-volume production typical of AM applications. In addition,
expertsfromdesign,production,andrelatedteamsneedtobeinvolvedtoensureitsaccuracy,reliability,andusability12–14.
Traditionalapproachesanddesktoptoolsprovideonlylimitedvisualizationandinteractionopportunitiesforeffectively
handlingthespatialnatureofAMcomponentsandtheirDTrepresentations15,16. Comparedtodesktop-basedsystems,virtual
reality(VR)providesbenefitstodealwithseveralchallengesinAM,includingoptimizingprocess,maintenance,partquality,
andinspection17,18. ThespatialnatureofAMpartsandprocessesrequiresanewsetofcapabilitiesbyleveragingtheadvantages
4202
yaM
12
]CH.sc[
1v13921.5042:viXraAdditive Manufacturing (AM) and Collaborative Virtual Reality Environment and Part-Level Digital Twins
Multimodal Data
Multi-User Collaboration Multimodal Data Visualization Streaming Large-Scale Data
X-ray CT Scans
Physical AM and Printed Results
Experts and data are distributed in Occlusion and Volumetric Rendering Alignment Features for Team Collaboration
various locations
CAD Model
In-process Images Prescribed Toolpaths Machine Data
Figure1. OverviewoftheproposedframeworkaimedtoenhanceAMpartinspectionofDTsviacollaborativeVR.Itsupports
multimodaldataalignmentandvisualization,streaminglarge-scaleandmulti-resolutionvolumetricdata,visualocclusion
management,aswellasteamcollaborationfeatures. Furthermore,itallowsmultipleuserseitherco-locatedorremoteto
collaborateinasharedvirtualenvironment.
ofVRtofacilitateamoreintuitiveandimmersiveinspectionprocessandmeetthespecificdemandsofAM,suchasmultimodal
datahandlingandalignment,occlusionmanagementforinspectinginternaldefects,streaminglarge-scalevolumetricdata,and
real-timesynchronizationfordistributedexpertcollaboration19–21.
Inresponsetothesechallenges,weintroduceanovelcollaborativeVRframeworkdesignedtoenhancetheinspectionand
analysisofAMpartsthroughmultimodaldata(seeFigure1). Ourframeworknotonlyfosterscollaborativeinteractionsamong
geographicallydistributedusersbutalsoincorporatesseveralinnovativeapproachesaimedatimprovingtheunderstanding
andinspectionofcomplexAMpartsandprocesses. ThesefeaturesincludeintuitivealignmentcapabilitieswithintheVR
environment, visualization strategies for effective visual occlusion management, and VR-based volume rendering of the
volumetricdata. Moreover,ourframeworkprovidestheabilitytoseamlesslystreamlarge-scalevolumetricdataaddressingthe
criticalissueofhandlingthemassivedatasetsgeneratedbyCTscans,furtheraugmentedbyfeaturesforteamcollaboration,
e.g.,annotationfunctionalities,thatenhancethecollaborativeinspectionprocess.
Ourframeworkisdesignedtoalignseamlesslywiththespatiallycomplex,multimodaldataintegraltoAMDTs,fostering
novelteamcollaboration. Itrepresentsaparadigmshiftinhowusersinteractwith,analyze,andderiveactionableinsights
fromcomplexmanufacturingdata,settinganewbenchmarkinthisemergentfieldandpushingtheboundariesofcurrentDT
inspectionmethods.
Materials and Methods
AM DTs are described by multimodal data streams collected from the processes, including prescribed toolpaths used for
instructingtheprinter,machinetoolpathsdescribingtheactualprintinglocations,X-rayCTusedforinvestigatinginternal
materialdensities,andin-processimagesforlayerwiseverification. Toprovideacomprehensiveinspectiontoolforthose
modalities,however,therearemultiplestepstoachievethisgoal.Wefirstneedtoalignthosemodalitiesandprovidemultimodal
datavisualization. SinceX-rayCTscansarecrucialforinspection,occlusionmanagementplaysavitalroleinconveying
depth information of volumetric rendering for inner-structure inspection. Moreover, X-ray CT scans are often large and
challengingtomanageandsharebetweenusers. Hence,asolutionisneededtostoreandprovideflexibledatamanagement.
Teamcollaborationisnotonlysharinga2Dscreen,buttheusersneedtostepintothesharedimmersiveenvironmenttoexplore
andinspectthoseDTrepresentations.
Inthefollowingsections,wedescribecollaborativeVR-basedapproachesdesignedanddevelopedtoenhancetheinspection
andanalysisofAMparts. Theproposedframeworkallowsindividualordistributeduserstoperformdataexplorationand
inspectioninthesharedvirtualenvironmentviareal-timesynchronization. Moreover,theframeworkincorporatesseveralnew
approaches: intuitivealignment,multimodaldatavisualization,comprehensiveocclusionmanagement,streaminglarge-scale
volumetricdata,andfeaturesforsynchronousteamcollaboration.
2/10(a) (b) (c) (d)
Figure2. Multimodaldatavisualizationtosupporttheprocessofdatainspectionandanalysis: (a)userscanloadandexplore
datafrommultipledatastreamsinthevirtualenvironment,(b)datarepresentationsbasedonprintedlayer,includingprescribed
toolpath(green),machinetoolpath(yellow),anderror(red),(c)userscanenablein-processimagingtofurtherinspectthedata,
and(d)volumetricdatavisualizationfromX-rayCTscanswithmachinetoolpaths.
IntuitiveAlignment
ComparingdifferentmodalitiesofAMDTsiscrucialforinspection,e.g.,comparingbetweenprescribedandactualtoolpathsor
X-rayCTscansaftertheprintingtotheintendeddesign. Valuableinsightscanbegainedfromthesecomparisonstohighlight
andinspectdeviationsbetweenmodalitiesandpotentialdefects. ThefundamentalchallengeprevalentinmanyDTapplications
isthateachmodalityhasitsownformat,units,andcoordinatesystems. Withoutproperalignment,thosemodalitiescannot
becomparedandintegratedeffectively. Forinstance,additionaladjustmentsarerequiredtoaligntheprescribedtoolpaths,
machinetoolpaths,in-processimages,andtheX-rayCTvolumetoensureaccuratevisualizationandinterpretation. Inthiscase,
inspectinghowalocationinonemodality,i.e.,in-processimages,overlaysinanothermodality,i.e.,X-rayCTvolume,would
notbepossiblewithoutproperlyaligningthedata. WebelievethattheVR-basedalignmentcouldbeacrucialtooltooptimize
thesemodalities’visualizationandsupportthemultimodalanalysis.
Whilemid-airinteractionisacommonapproachforinteractingandmanipulatingobjectsinVR,suchinteractionscouldalso
sufferfromhandinstability,e.g.,unnoticeabletremor,whichintroducesinaccuracieswhentryingtoalignatahighprecision.
Toachievethisgoal,wedevelopedaVR-basedalignmenttoolwithanadaptationandenhancementofaprecisealignment
techniqueproposedbyRodriguesetal.22. Insteadofadirectlinearmappingbetweencontrollerandobjectmovement,this
approachutilizesanon-linearmappingthatadaptstotheaccelerationofthecontrollertodeterminetheobjectmovement,e.g.,
theobjectmovesmorewherethecontrollerismovingfasterandviceversa. Withslowcontrollermovementsmappingto
smallobjectmovement,weutilizethistechniquetoachievehigh-precisionalignmentofmultimodaldata. Sincetheprinting
processoftenpresentsbothlocalandglobaldefectsthatgobeyondtherigidbodyalignment,wefurtherintegratedafree-form
deformationtechnique23 toprovideaflexibleandintuitivealignmentfornon-lineardeformation. Itfirstdefinesthecontrol
pointsbasedontheboundingboxorgridstructureofthemodel. Eachcontrolpointhasitspositionandactsasahandlefor
deformingtheobject. Theusercanadjustthedeformationbyinteractingwiththecontrolpoints. Oncethecontrolpointis
moved,theinterpolationmethodiscomputedforaffectednearbyverticestosmoothlydeformtheobject. Thesetransformations
canbesavedforrevisitingthealignmentorexportingtoothertoolsforfurtherregistration.
MultimodalDataVisualization
TofullyunderstandandanalyzethecomplexbehaviorofAMDTs,relyingsolelyonasingletypeofdatavisualizationisoften
insufficient. Whiletherearepossibilitiestogathernewformsofdatafromphysicalassets,theabilitytoprocessandvisualize
themintovaluableinsightsandsituationalawareness,suchascorrespondinglocationsindifferentmodalities,ischallengingas
onemodalitywouldvisuallyoccludeanotherwhentheyaresuperimposed. Themainbenefitofmultimodaldatavisualization
forAMinspectionandanalysisistoprovideacomprehensivecomparisonacrossdifferentdatastreams,e.g.,beforevsafter,
pre-curevspost-cure,ornominalvsactualprintingpart. Onepossiblesolutionistosuperimposethevisualizationofone
modalityoveranother,e.g.,computer-aideddesign(CAD)modelandX-rayCTscans24. However,thisintroducestheissuesof
occlusionandrobustnessbetweenmodalities.
Inthiswork,weincorporateseveralmodalities,rangingfromtoolpathsandin-processimagestoX-rayCTscans. For
instance, overlaying additional modalities, i.e., machine toolpaths on top of the CT scans and in-process images can help
identifyareasofdefectsandprovideamorecomprehensiveunderstandingoftheprintingprocessandbehavior(seeFigure2).
Currentsupporteddatastreamsincludedesignmodels,prescribedtoolpaths(.pgm),machinedata(.hdf5),includingmachine
toolpathsanderrors,in-processimages,X-rayCTscans,and3Dreconstructedmodels. Theproposedframeworkcanbeused
toloadthosedatatypesandvisualizethemintheimmersivevirtualenvironment. Hence,userscanintuitivelyexplore,analyze,
and gain a comprehensive understanding of the process, which can make informed decisions to optimize the process and
quality. Wealsoimplementedoptionstosupportmultimodalexplorationandanalysis. Theuserscaninspectitlayerbylayer,
3/10(a) (b) (c) (d) (e)
Figure3. OcclusionmanagementwithvolumetricrenderinginimmersiveVR.Weimplementedthecolorizedvolumewith
thetransferfunctionsandcolormaps. Withthecuttingobjects,itallowsuserstoexploretheinnerstructuresofthevolumetric
datasmoothly,e.g.,usingacross-sectionplane(a),sphere(bandc),orbox(dande)cutoutwithinclusiveandexclusivemodes,
respectively.
enable/disableoneofthedatastreams,andcompareitwithdifferentmodalities. AsshowninFigure2,prescribedtoolpaths,
whichareusedtoinstructthe3Dprinter(G-Codecommands)arevisualizedasgreenlineswithcorrespondingpositions(green
dots). Theactualpathsgeneratedbythe3Dprinterarevisualizedwithyellowlines,anderrorsbetweenprescribedandmachine
toolpathsaredisplayedinred. Theusersalsohaveoptionstoenableandoverlayin-processimagesaswellasvolumetric
renderingoftheX-rayCTscansforfurtherinspectionandanalysis.
OcclusionManagementandVolumetricRendering
Volume rendering is used to visualize final part volumetric data obtained from X-ray CT scans. Since our AM lattice
strucutresaredense,itischallengingtodistinguishandidentifytheinner-structuredetailsofvolumetricdatawithoutocclusion
management. Itisalsocrucialtoenhancethedepthperceptionandshapeoftherenderedobjectexposedtoitssurrounding
environment. Toreduceocclusioninvolumes,acommonapproachistoapplyatransferfunctionallowingtheusertospecify
structures to be visualized and manipulate the opacity and color of the voxels belonging to the structures25. For instance,
thetransferfunctioncanbeusedtocontrolthevisualizationofthestructuresthatoccludetheregionsofinterest. However,
adjustingonlythetransferfunctiondoesnotallowforglobaladjustmentsofvisibility.
WeenhancedUnityVolumeRenderingtocomputeandvisualizevolumetricdatainUnity. Thetransferfunctionandcolor
mappingwereadaptedandintegratedintotheproposedframeworktoimprovetheocclusionandlightingmanagementinVR.
Tohaveaglobalwaytoadjustvisibilityandinspecttheinnerstructureofvolumetricdatawhilemaintaininglocaladjustments,
weintegratedcuttinggeometries,suchascross-sectionplane,box,andspherecutoutssimilartothetechniqueproposedby
Titovetal.26. Thecutoutfunctionsupplementswithinclusiveandexclusivemodes,whichcaneithermaketheinsidevisibleor
invisible(seeFigure3). Thiswayallowsforaflexibleadjustmentofvisibility,thus,theinnerstructuresinsidethevolumetric
datacanbeexploredandinspected. TheusersinVRcaninteractivelymovethecuttingobjectaroundandchoosethecutout
modetocroptheregionofinterest,e.g.,tofurtherinspectanddiscussthedatawiththeircollaboratorsaccordingly.
StreamingLarge-ScaleVolumetricData
X-rayCTscansarecrucialfortheAMinspectionprocesstoanalyzedefectsandensuretheoverallqualityandreliabilityofthe
printedparts. Theyprovideanon-invasiveandnon-destructivewaytocharacterizeandinspectinternalmaterialdensitiesofthe
AMparts,particularlycomplexinternalstructuresthatarenotaccessiblebyotherinspectionmethods. However,X-rayCT
scansareoftenlarge,whichcannotbeeasilysharedwithcollaboratorsandalsoimposecomputationandrenderingchallenges
forVR.
One of the key features of our proposed framework is the ability to utilize large-scale data management and stream
multi-resolution volumetric data remotely during runtime. We utilized the data management approach using OpenViSUS
forefficientqueryingandmanaginglarge-scaledata27,28. Thedatasetsarestoredonaserverandcanbestreamedwithour
developedWebAPI toprovideflexibledatastreaming,e.g.,filtering,cropping,andmulti-resolutiondataquery. Thisway,we
caninstantlygetasubsampledversionorahigh-resolutionsubspaceofthedata,sothatinteractiveinspectionisguaranteed
andnotinhibitedbythelarge-scalenature. Furthermore,weincorporatedthedevelopmentwithmultithreadingtosupportthe
massivecomputationsinthebackground. Thus,themainthreadcouldbeusedtomaintainthecomputationallogicforVR
rendering.
Multi-UserandCollaborativeInspection
Conventionally,designers,productionteams,domainexperts,andsometimescustomersdirectlyinteractwiththephysical
objects after the AM part has been produced, often requiring the shipping of physical components or experts traveling to
differentlocations. OnenotablecharacteristicofthepartsproducedthroughAMistheintricateinternalgeometricstructures.
4/10Figure4. Variousfeaturesfordataexplorationandinspectionaswellasrelatedfeaturestoimproveteam-basedcollaboration:
thosefeaturesincludeadjustingCTwindowwidth/level,usingcross-sectionplaneandaxissliceview(axial,coronal,and
sagittal)toexploreandinspectdata,drawingannotations,aligningandvisualizingmultimodaldata,streamingmulti-resolution
CTvolume,loadingandinteracting3Dscannedmodels,anddrawingonthevirtualwhiteboard.
Inspectingthesestructuresrequiresvolumetricimaging,i.e.,CTscansthatleadtothewell-knownchallengesofvisualizingit
through2Dinterfaces,anddomainknowledgebymultipleexperts20,24. CollaborativeVRoffersextrabenefitsbyenabling
real-timecommunication,jointlysharedinspectionandanalysis,andfacilitatingteam-baseddiscussion.
The proposed framework provides exploration and inspection features via real-time synchronization. Figure 4 shows
featuresdevelopedtosupporttheteaminexploringandinspectingAMparts. Avirtualtabletwasdesignedtoprovideuser
interfaceinteractions. Theuserscanchangedifferentdatasets,adjustvolumeintensity,i.e.,CTwindowwidthandlevel,and
usedataexplorationfeatures,suchascross-sectionplaneandslicingviewsfromdifferentaxes,includingaxial,coronal,and
sagittalviews. DrawingannotationsincollaborativeVRcanbeessentialforteamdiscussion. Itcanbeusedtoenhancethe
collaborationbetweenteammembersmoreeffectively. Theuserscandrawannotationstospecifytheregionofinterestonthe
datasetandinitiatethediscussionaccordingly. ThedrawingwasimplementedbyusingaVRraycastingtechniquemapped
withtheindexfingertipofthevirtualhand. Moreover,wedevelopedavirtualwhiteboardtosupporttheteamdiscussion. The
userscanuseavirtualmarkertodrawtheirillustrationsonthewhiteboardinasimilarwaythattheyperforminthephysical
world.
Toprovideanengagedenvironmentforteamcommunication,wedesignpersonalizeduseravatarrepresentations,including
anavatarheadgeneratedfromaheadshot,animatedVRhands,facialblendshapes,andthevoiceiconthatappearswhentheuser
engagesinvoicecommunication. Figure5showscollaborativeusersexploreandinspectAMdatainthevirtualenvironment.
WhiletheenvironmentisdesignedanddevelopedforVRusersusinghead-mounteddisplays(HMD),non-VRuserscanalso
joinintheenvironmentasaspectatormodeusingconventionalinputssuchasmouseandkeyboard. Thisfeaturewouldbe
essentialtoallowotherusers,e.g.,trainees,toobserveandquicklyjointhediscussioninthevirtualenvironment.
WedevelopedthecollaborativeVRenvironmentusingaclient-serverapproach. Forinstance,aclientsendsanupdate
throughtheserver,andtheservermulticaststheupdatetootherclientsforreal-timesynchronization. Thisapproachcould
provide a stable and secure solution for network communication and avoid common connection issues compared to the
peer-to-peerapproach,e.g.,scalabilityandover-distanceconnection. Furthermore,itisbeneficialtoallowclientswhojoinlate
orarerequiredtoreconnectintheenvironmenttoloadprevioussynchronizationupdatesthroughtheserver. AUnitygame
engine(UnitySoftwareInc.,CA,USA)version2019.4.20f1wasusedasadevelopmentenvironment. WeusedaPhotonUnity
Networking(ExitGamesGmbH,Germany)toprovideload-balancingservicesandsharednetworksessionsbetweentheusers.
PhotonVoice2wasalsoutilizedforvoicecommunication. Sincetheclient’scomputerspecificationandnetworkconditions
couldaffecttheconnections,weimplementedthemechanismfordatasynchronizationsuggestedbySinghalandZyda29to
optimizethenetworklatency. Aremoteprocedurecall(RPC)approachwasusedtosendrequestsanddistributedata. Sending
largeamountsofdatainonechunkisavoided. Topreventtheserver’sbottleneck,clientsarealsoresponsibleforindividual
5/10(a) (b)
Figure5. Multi-usercollaborationforAMdataexplorationandinspection: (a)collaborativeusersvirtuallyjoinandexplore
AMdata,i.e.,X-rayCTvolume,inasharedvirtualenvironment,and(b)userscaninspectfurtherdetailsofthedatausing
variousinspectionfeatures,i.e.,across-sectionplane. Theinteractionsbetweenusersaresynchronizedinrealtime.
graphicalrendering. Moreover,theclientsareresponsibleforstoringobjectstateslocally,whileonlysendingupdatesoftheir
periodicdata,e.g.,theobject’spositions,rotations,andscalesduringtheinteractionandactivestate.
Apparatus TwoVR-readycomputerswereusedduringthetestingandevaluation. TheywereRAZERBLADE16laptops
equippedwith13thGenIntel(R)Core(TM)i9-13950HX(32CPUs)processor,NVIDIAGeForceRTX4090(16GBVRAM)
graphicscard,and32GBRAM.OneuserconnectedwithaVIVEXREliteVRheadset,whichhas1920×1920pixelspereye
(3840x1920pixelscombined),110-degreefieldofview(FOV),and90Hzrefreshrate. AnotheruserusedaMetaQuest3
headsetthathas2064×2208pixelspereye,110-degreeFOV,andupto120Hzrefreshrate. BothVRheadsetswereconnected
asPCVR.Thespeedofinternetconnectionwasapproximately247.58Mbps(download)and248.41Mbps(upload).
Evaluation and Expert Feedback
ThisworkwasreviewedandapprovedbyLawrenceLivermoreNationalLaboratory’sreviewcommitteeunderLLNL-JRNL-
861091. Allmethodswerecarriedoutinaccordancewithrelevantguidelinesandregulations. Todemonstratetheusability
ofourframework,weperformedevaluationswithdomainexperts. Twoexploratorystudieswereconducted: thefirststudy
aimedtoassesstheapplicabilityandpotentialbenefitsoftheproposedframework,andthesecondstudyfocusedthoroughlyon
acasestudyofinspectionandanalysiswithrealdatacollectedfromAMprocesses. Thefirststudywasconductedwithsix
domainexperts(threewerecomputerscientistsandtheotherthreewereengineeringandmaterialscientists). Theyallhad
experienceworkingwithAM.Onereportedhavingnineyearsofworkingexperience,threereportedbetweenthreetofiveyears,
andtheothertworatedashavingbetweenonetotwoyearsofworkingexperience. Thesecondstudywasconductedwith
twoAMexperts(twoandsixyearsofworkingexperience). Exploratoryandsemi-structuredinterviewswereconductedto
assesstheproposedframeworkandcollecttheirqualitativefeedback. Alltheparticipantswereinformedabouttheobjective
andprocedureofthestudy,andtheirverbalinformedconsentwascollected.
ApplicabilityandPotentialBenefits Allexpertsexpressedtheirpositivefeedback. Theyconfirmedthepotentialbenefitsand
itsapplicability. TheframeworkcanbeapowerfultooltoenhancetheinspectionprocessofAMDTs. Theexpertsstatedthat
usingcollaborativeVRisbeneficialtovisualizeandguidetheircollaborators,e.g.,betweenthedesignandproductionteams,
throughthemachine,installationsetups,andexperimentaldata. Allowingcollaborationamongexpertsandinterdisciplinary
teamsacrossgeographicallocationscouldenhanceefficiency,particularlytheinspectionandanalysis,whilealsoestablishing
anewbenchmarkforincorporatingDTs. Itisextremelyusefulwhenphysicaltravelisrestricted,i.e.,duringtheCOVID-19
pandemic. Developedfeaturesfordataexplorationandinspectionwereassessedasusefulwithreal-timesynchronization,
whichisbeneficialforteamcommunicationanddiscussioncycles. Scalingandslicingthroughthedatawereratedasthemost
usefulfeatures. VRprovidesanimmersivewaytoinspectandanalyzecomplexstructuresofAM.Itisparticularlypronounced
sinceitischallengingtoperformthesetaskson2Ddesktopscreens. Thiscouldleadtobetter-informeddecisionsandoptimize
thedesignandproductionaccordingly. Thespectatormodeusingconventionalinputdeviceswasalsoratedashelpfulfor
someusers,e.g.,traineesorseniorsupervisorstopromptlyjoininthediscussion. TherewerenopotentialissuesregardingVR
discomfortorcybersicknessobserved. Theymentionedtheframeworkcanbeeasilyadaptedbytheirteamalthoughtheremight
beasmalllearningcurveofusingthistechnology.
OneexpertexpressedthatdrawingannotationinVRisintuitiveandextremelyusefultohighlightthepointofinterestin
thedatatotheircollaborators. Inthisway,theycouldspeeduptheprocess,definemultipleregionsofdefects,andinitiate
6/10(a) (b) (c) (d)
Figure6. InspectionandanalysisofadditivelymanufacturedpartsusingcollaborativeVRandDTs: (a)AMandcollected
multimodaldataduringtheprintingprocess,(b)resultsofprintedpart(25mmsquarelattice)inthephysicalworld,(c)usersuse
ourproposedVRframeworktoinspectdifferentmultimodaldatarepresentations,e.g.,markingannotations,and(d)theycan
compareresultsbetweenpost-curingvolumeofCTscans(top)andlayer-by-layerimagesduringtheprintingprocess(bottom).
thediscussion. Theexpertssuggestedaddingdifferentcolorsforannotationdrawingsoreachuserhasauniquecolorfor
themselves. Besidesdrawinginthe3Dspace,theyalsosuggestedimplementingtheannotationdrawingsontheslicingplane.
Thiswouldbebeneficialtoexplorethedataslicebyslice. Additionalfeatures,suchasavatarrepresentationsandinteractions
withthevirtualwhiteboard,weredevelopedtosupportteamcommunicationanddiscussion. VRhandrepresentationswith
animationswhenpressingthecontrollerbuttonswereassessedassupportive. Theexpertssuggestedaddingahelpbuttonor
tooltipstoshowthebutton-mappedfunctions. However,theystatedthatitisalearningcurveofusingthetechnology. The
expertshighlightedafewchallengesofintegratingitintotheirworkflow,e.g.,logisticsandaccessibility. Theyalsomentioned
aboutsafetywhileusingVRheadsetsinalimitedspaceintheirworkingsetting. Besidesusingtheframeworkforinspection
andanalysis,theexpertsconfirmedemployingitforteamtrainingandskilldevelopmentusingvirtualenvironments.
CaseStudy Inadditiontocollaborativeaspects,utilizingandvisualizingmultipledatastreamsoftheAMprocesseswas
evaluated as essential for diagnostic and enhancing the AM inspection process. Figure 6 shows a case study of using the
frameworktoinspectandanalyzeAMdefectsthroughmultimodaldatavisualization. Arealdatasetofadditivelymanufactured
partswasusedinthisstudy. Thesizeofthephysicalpartwasa25mmsquarelattice. ThetwoAMexpertsmentionedthatthe
datacanbecollectedfromvarioussourcesduringtheprintingprocess. Atthecurrentstageoftheirworkflow,however,thereis
nobestapproachtointegratethedatatogether. Itisalsolimitedtovisualizingandinteractingwiththosedataonthedesktop
screen. Hence,itisadvantageoustocombineandvisualizetheminanimmersiveenvironment. Itisnotonlybeneficialfor
explorationbutitiscrucialforinspectinganddefiningdefects,e.g.,evaluatingeachstepandlayerwiseoftheprintingprocess,
suchasprescribedandmachinetoolpaths,volumeofCTscans,andin-processimages.
Theystatedthatitischallengingtodefinedefectsviavisualinspectionordesktop-basedsystemsbecausethepartscanbe
verysmall. WithourVRframework,theycanenlargeandinspectthemwithadditionalinformation. Asanexampleonthis
dataset,theyfoundthatsomethingpokedthefirstlayerofthepre-cureprocessresultingindefects. Theframeworkwashelpful
bysupportingdifferentdatamodalities,andthedatawasaligned. Theystatedthatitprovidesacomprehensivewaytoexplore
andinspectthepart,e.g.,duringthepre-cureandpost-cureprocess. Hence,theycouldcomparein-processimageswiththe
post-curevolumeobtainedfromCTscanswithothermodalitiesoverlaidontop,suchasprescribedandmachinetoolpaths.
Inthiscase,theycanseethatthetoolpathswereactuallygoingthroughthehole. Thatmeansthedefectwastherebeforethe
post-cureprocess,andtheycouldevaluatethelayers,whichwereaffected. Theannotationwashelpfulinhighlightingthe
defectacrossmultiplemodalities. Theycouldfurtherusethecross-sectionplaneandslicingfeaturetoassessthearea. All
interactionsweresynchronizedinrealtime,anditwasbeneficialtocollaborateandcommunicatewiththeircollaboratorsin
thesamesharedenvironment. Forfurtherimprovements,theexpertssuggestedaddingadditionalmetadatainformationto
thevisualization,suchasstrutdiameters,dispenserates,andscalingunits. Providingaheatmapforvelocityalongwiththe
multimodaldatavisualizationcouldbeusefulaswell. Furthermore,theysuggesteddevelopingameasurementtoolinVRto
measurethelengthbetweentwopoints.
Discussion and Future Work
DTsareincreasinglyusedinmanufacturingsettings. WetacklethecriticalneedsandexploretheusecaseofemergingDTs,
whichrequireshandlingmultimodaldatainanintuitiveandcollaborativeway.Wedemonstrateusingourproposedcollaborative
VRframeworkfortheinspectionofAMDTs. Theproposedframeworkshowsthatthetraditionaldesktop-basedapproach
7/10mightbenotappropriateforteam-basedcollaborationandprovidingtheinspectionandanalysisintuitivelyandimmersively.
Our collaborative VR framework addresses these challenges with advanced visualization and interaction techniques. The
frameworkwasevaluatedwithdomainexpertsintheAM.Theresultsdemonstratetheusability,applicability,andpotential
benefits. Allexpertsfoundtheframeworkintuitiveandeffective,anditopensnewwaystoqualifytheAMparts.
ToprovideacomprehensivetoolfortheinspectionofAMDTs,weaddressthechallengesrangingfromthealignmentof
multipledatastreamscollectedfromtheAMprocesses,multimodaldatavisualization,occlusionmanagement,andstreaming
large-scaledatatocollaborativeinspection. Thealignmentwasratedashelpfultomapalldatamodalitiesinoneplacefor
comparison.Itisacrucialcomponentformultimodaldatavisualization.Thealignmentcanbeimprovedbyprovidingadditional
information,suchasscalingunitsandameasurementtooltoestimatethelengthoftwopoints. Differentmodalities,including
sensordata,pressure,velocity,andothers,willbeincorporatedinfuturework. Investigatingvisualizationtechniquesfornew
datastreams,suchasheatmapandmultiscalevisualization,wouldbeinterestingaswell.
ItisessentialduringtheinspectionandanalysistoconsidertheocclusionandcolormapsforvolumetricrenderinginVR.
Ononehand,itprovidesanintuitivewaytoexplorevolumetricdataandgraspthespatialrelationshipsofcomplexinternal
structures. Ontheotherhand,thepossibilityofworkingasateamtojointlyexploredataandfacilitatecollaborativeanalysis
withreal-timesynchronizationisadvantageous. However,thereareseveralchallengesinvisualizingandrenderingvolumetric
datatoavoiddiscomfortinVR.Itincludeshardwarerequirements,whichrequireapowerfulcomputerwithabettergraphic
cardtorenderandmaintainahighlevelofVRimmersion. Futureresearchshouldfurtherinvestigateocclusiontechniques,
suchascontextualambientocclusion26,toimprovetheperformanceandquality.
VolumetricdatafromX-rayCTscanscanbeextremelylarge,thus,achievinghigh-resolutionanddetailedvisualization
canbechallenging. Moreover,dataformatsanddatatransferforcollaborativeVRcanposeasignificantchallenge. Todeal
withlarge-scaleandmulti-resolutionvolumetricdata,wedevelopedanapproachtostreamandhandlethosemassivedatasets.
ByutilizingOpenVisusfordatamanagement,theprocessofmanagingandfilteringdataisenhanced. Thiscouldsolvethe
issuesofdistributingandstoringdatalocallyforcollaborativeusers. Moreover,dealingwithparallelcomputingiscrucial
forVRsinceitisimportanttomaintaintheVRrenderingwhileothercomputationsshouldbeprocessedinthebackground.
Nonetheless,itcanbedifficulttopredicttheexacttimeuntilitisfullyrendered. Italsorequiressignificantcomputational
resourcestoachievesmoothandresponsiveperformance. Theproposedframeworkallowsuserstoadjustthequalityofthe
volumetricdata. Furtherinvestigationwithaprogressiverenderingwouldbeadvantageous. Thus,insteadofwaitingforthe
entirevolumetoberendered,itprovidesaninitiallow-resolutionandaroughapproximationrenderingtotheuseruntilthe
computationalresourcesbecomeavailable.
DTsintheIndustrialMetaverseisanemergentconcept,whichpromisesvariousbenefitsfortheDTsecosystem. Itopens
newresearchdirectionswheredigitalrepresentationsandvirtualcollaborationamongusersintheimmersiveenvironmentwould
becomepowerfultoolsfordesign30,instructionandmaintenance31,32,inspection,optimization,andtraining33,34. Itenhances
collaboration,interactivity,andteamcommunicationviareal-timesynchronization. Futureworkcanfocusonminimizing
latencytoensuresmoothandsynchronouscommunicationbetweenusers. SinceAMDTsinvolvevariouspropertiessuchas
materials,thermalconductivityandresistivity,sensordata,andotherphysicalproperties,investigatingandleveragingartificial
intelligence(AI)anddata-driventechniqueswouldbeessentialforpredictingandoptimizingdata35. Forinstance,usingdeep
conventionalneuralnetworkstoextractlayer-wiseimagemeasurementsofthefilamentthicknessandspacingtovalidatethe
part-scalereconstruction. Furthermore,AI-assistedinspectioninthevirtualenvironmentwouldbeaninterestingresearch
directiontoassisttheusersinanalyzing,highlighting,andfurtherinvestigatingpotentialdefects.
ApartfromtheimmersiveVRenvironment,team-basedcollaborationcanbeappliedtosituatedanalyticsinamixed-reality
environmentofmanufacturingsettingsandacrossvariousfields36,37. Itcouldalsoprovideanewapproachtoincorporatesensor
integrationofthephysicalsystemstomonitor,diagnose,andleadtomoreaccurateanddynamicsimulations. Futurework
includesincreasingdatastreams,includingprocess-leveldataofthesensors,andinvestigatingvisualizationapproachesto
tacklenewdatamodalities. WhiletheuserscancommunicateinVR,wehavetoacknowledgethattheymayhaveasymmetric
knowledgeregardingthedata. Futureworkalsoaimstoprovideoptionstosavetheannotationsandresultsfromtheinspection
aswellastheirdiscussion,e.g.,drawingsonthevirtualwhiteboard.
Conclusion
DTshavebecomepervasiveandincreasinglyusedinindustrialmanufacturing. Whilemostresearchfocusedonautomation,
3Dmodeling,andinteroperabilityofDTs,criticalneedsofhandlingandinspectingDTsdatawithintuitiveandimmersive
approachesremain. Moreover,DTsarebecomingincreasinglycomplexwithvariousdatastreams,whichoftenrequiremultiple
expertstogetinvolvedforeffectiveinspection. Inthiswork,weexploretheusecaseofDTsinAMpartinspection. Wepresent
anddemonstratetheuseofourproposedcollaborativeVRframeworktoenableandenhancetheinspectionprocessofAM
DTs. Theframeworknotonlyfocusesoncollaborativeinteractionsbutalsoprovidesseveralinnovativecomponentstoimprove
theinspectionandunderstandingofcomplexDTdatainAM.ThosecomponentsincludeVR-basedinteractivealignment,
8/10multimodaldatavisualization,comprehensiveocclusionmanagementandrendering,streaminglarge-scalevolumetricdata,
andfeaturesforteam-basedinspectionandcollaboration. Exploratoryandsemi-structuredinterviewswereconductedwith
domainexpertstoevaluatetheusability,applicability,andpotentialbenefits. AcasestudyofAMinspectionusingrealdata
collectedfromtheAMprocesswasalsopresented. Theproposedframeworkisapromisingtooltosignificantlyenhancethe
inspectionprocessbyreducinginspectiontimeandimprovingefficiencyandaccuracy. Itprovidesanaturalwaytointeract
withDTrepresentationsbyimprovingspatialawareness,enablingreal-timecommunication,sharingexplorationofcomplex
structures,andremoteinspectionwithmultipleusers. TheframeworkoffersanewbenchmarkforemergingDTsandpushesthe
boundariesofcurrentAMDTsinspectionmethods. Moreover,itopensnewresearchdirectionsandoffersnewopportunities
forintegratingwithotherDTdomains,includingthemedical,aerospace,andconsumerproductsindustries.
References
1. Stawski,W.,Skorupska,K.H.&Kopec,W. 3dprintinganddesigninisolation: Acasefromasimulatedlunarmission. In
CHIEA,1–6(2023).
2. Kelly,B.E.etal. Volumetricadditivemanufacturingviatomographicreconstruction. Science363,1075–1079(2019).
3. Brennan, M., Keist, J. & Palmer, T. Defects in metal additive manufacturing processes. J. Mater. Eng. Perform. 30,
4808–4818(2021).
4. Maconachie,T.etal. Slmlatticestructures: Properties,performance,applicationsandchallenges. Mater.&Des.183,
108137(2019).
5. Tao,F.,Zhang,H.&Liu,A. Digitaltwininindustry: State-of-the-art. IEEETransactionsonindustrialinformatics15,
2405–2415(2018).
6. Attaran,M.&Celik,B.G. Digitaltwin: Benefits,usecases,challenges,andopportunities. Decis.Anal.J.100165(2023).
7. Gunasegaram,D.R.,Murphy,A.B.,Matthews,M.&DebRoy,T.Thecasefordigitaltwinsinmetaladditivemanufacturing.
J.Physics: Mater.4,040401(2021).
8. Lu,Y.etal. Digitaltwin-drivensmartmanufacturing: Connotation,referencemodel,applicationsandresearchissues.
Roboticscomputer-integratedmanufacturing61,101837(2020).
9. Liu,M.,Fang,S.,Dong,H.&Xu,C. Reviewofdigitaltwinaboutconcepts,technologies,andindustrialapplications. J.
Manuf.Syst.58,346–361(2021).
10. Gunasegaram,D.R.etal. Towardsdevelopingmultiscale-multiphysicsmodelsandtheirsurrogatesfordigitaltwinsof
metaladditivemanufacturing. Addit.Manuf.46,102089(2021).
11. Liu,A.etal. Digitaltwinfordata-drivenengineeringdesign. Data-DrivenEng.Des.149–172(2022).
12. Scime,L.,Singh,A.&Paquit,V. Ascalabledigitalplatformfortheuseofdigitaltwinsinadditivemanufacturing. Manuf.
Lett.31,28–32(2022).
13. Phua,A.,Davies,C.&Delaney,G. Adigitaltwinhierarchyformetaladditivemanufacturing. Comput.Ind.140,103667
(2022).
14. Havard,V.,Jeanne,B.,Lacomblez,M.&Baudry,D. Digitaltwinandvirtualreality: aco-simulationenvironmentfor
designandassessmentofindustrialworkstations. Prod.&Manuf.Res.7,472–489(2019).
15. Pantelidakis,M.,Mykoniatis,K.,Liu,J.&Harris,G. Adigitaltwinecosystemforadditivemanufacturingusingareal-time
developmentplatform. TheInt.J.Adv.Manuf.Technol.120,6547–6563(2022).
16. Yan,D.etal. Digitaltwinandparametercorrelation-enabledvariantdesignofproductionlines. Int.J.Comput.Integr.
Manuf.1–22(2023).
17. Akpan,I.J.&Offodile,O.F. Theroleofvirtualrealitysimulationinmanufacturinginindustry4.0. Systems12,26(2024).
18. Kobara,Y.M.&Akpan,I.J. Bibliometricperformanceandfuturerelevanceofvirtualmanufacturingtechnologyinthe
fourthindustrialrevolution. Systems11,524(2023).
19. Wang,Y.,Wang,X.,Liu,A.,Zhang,J.&Zhang,J. Ontologyof3dvirtualmodelingindigitaltwin: areview,analysisand
thinking. J.Intell.Manuf.1–51(2023).
20. Pirker, J., Loria, E., Safikhani, S., Künz, A.&Rosmann, S. Immersivevirtualrealityforvirtualanddigitaltwins: A
literaturereviewtoidentifystateoftheartandperspectives. InIEEEVRW,114–115(2022).
21. Litvinova,Y.,Rehm,S.-V.,Goel,L.C.&Junglas,I. Collaboratinginvirtualrealitybyusingdigitaltwins. InISPIM
InnovationSymposium,1–10(2018).
9/1022. Rodrigues,F.etal. Amp-itandwisdom: Improving3dmanipulationforhigh-precisiontasksinvirtualreality. InIEEE
ISMAR,303–311(2023).
23. Sederberg,T.W.&Parry,S.R. Free-formdeformationofsolidgeometricmodels. InProceedingsofthe13thannual
conferenceonComputergraphicsandinteractivetechniques,151–160(1986).
24. Klacansky,P.etal. Virtualinspectionofadditivelymanufacturedparts. InIEEEPacificVis,81–90(2022).
25. Tian, Y. et al. Occlusion handling using moving volume and ray casting techniques for augmented reality systems.
Multimed.ToolsAppl.77,16561–16578(2018).
26. Titov,A.,Kersten-Oertel,M.&Drouin,S. Contextualambientocclusion: Avolumetricrenderingtechniquethatsupports
real-timeclipping. Comput.&Graph.(2024).
27. Zhou,N.etal. Orchestrationofmaterialsscienceworkflowsforheterogeneousresourcesatlargescale. TheInt.J.High
Perform.Comput.Appl.37,260–271(2023).
28. Pascucci, V. et al. The visus visualization framework. In High Performance Visualization, 439–452 (Chapman and
Hall/CRC,2012).
29. Singhal, S. & Zyda, M. Networked virtual environments: design and implementation (ACM Press/Addison-Wesley
PublishingCo.,1999).
30. Mourtzis,D.,Angelopoulos,J.&Panopoulos,N. Collaborativemanufacturingdesign: amixedrealityandcloud-based
frameworkforpartdesign. ProcediaCIRP100,97–102(2021).
31. ThoraviKumaravel,B.,Anderson,F.,Fitzmaurice,G.,Hartmann,B.&Grossman,T. Loki: Facilitatingremoteinstruction
ofphysicaltasksusingbi-directionalmixed-realitytelepresence. InACMUIST,161–174(2019).
32. Oppermann,L.,Buchholz,F.&Uzun,Y. Industrialmetaverse: Supportingremotemaintenancewithavatarsanddigital
twinsincollaborativexrenvironments. InCHIEA,1–5(2023).
33. Kuts, V., Otto, T., Bondarenko, Y.&Yu, F. Digitaltwin: Collaborativevirtualrealityenvironmentformulti-purpose
industrialapplications. InASMEInt.MechanicalEng.CongressandExposition(2020).
34. Ostrander,J.K.,Tucker,C.S.,Simpson,T.W.&Meisel,N.A. Evaluatingtheuseofvirtualrealitytoteachintroductory
conceptsofadditivemanufacturing. J.Mech.Des.142,051702(2020).
35. Tao,F.,Qi,Q.,Liu,A.&Kusiak,A. Data-drivensmartmanufacturing. J.Manuf.Syst.48,157–169(2018).
36. Tian,H.,Lee,G.A.,Bai,H.&Billinghurst,M. Usingvirtualreplicastoimprovemixedrealityremotecollaboration. IEEE
TransactionsonVis.Comput.Graph.29,2785–2795(2023).
37. Lee,Y.&Yoo,B. Xrcollaborationbeyondvirtualreality: Workintherealworld. J.Comput.Des.Eng.8,756–772(2021).
Acknowledgements
ThisworkwasperformedundertheauspicesoftheU.S.DepartmentofEnergybyLawrenceLivermoreNationalLaboratory
underContractDE-AC52-07NA27344. TheprojecthasbeensupportedbyLLNLLDRD(23-SI-003). Theworkwasinternally
reviewedandreleasedunderLLNL-JRNL-861091-DRAFT.
Author contributions
V.C.,S.N.,andG.H.developedtheframework. V.C.andH.M.conductedtheexperiments. R.C.,B.A.,andB.W.contributedto
theuserstudy. V.C.andH.M.preparedtheoriginaldraft. B.G.,P.B.,andH.M.providedresourcesandsupervision. Allauthors
reviewedthemanuscript.
Competing interests
Theauthorsdeclarenocompetinginterests.
Data availability
Supplementaryvideoisattached. Thedatageneratedduringand/oranalysedduringthecurrentstudyareavailablefromthe
correspondingauthoronreasonablerequest.
10/10