Human-Robot Interface for Teleoperated Robotized
Planetary Sample Collection and Assembly
Lorenzo Pagliara*, Vincenzo Petrone*, Enrico Ferrentino and Pasquale Chiacchio
Department of Computer Engineering, Electrical Engineering and Applied Mathematics (DIEM)
University of Salerno
84084 Fisciano, Italy
e-mail: {lpagliara, vipetrone, eferrentino, pchiacchio}@unisa.it
Abstract—As human space exploration evolves toward longer
voyagesfartherfromourhomeplanet,in-situresourceutilization
(ISRU)becomesincreasinglyimportant.Hapticteleoperationsare
oneofthetechnologiesbywhichsuchactivitiescanbecarriedout
remotelybyhumans,whoseexpertiseisstillnecessaryforcomplex
activities. In order to perform precision tasks with effectiveness,
the operator must experience ease of use and accuracy. The (a)Pre-collection (b)Resourcecollection (c)Post-collection
same features are demanded to reduce the complexity of the
trainingproceduresandtheassociatedlearningtimeforoperators
without a specific background in robotic teleoperations. Haptic
teleoperation systems, that allow for a natural feeling of forces,
need to cope with the trade-off between accurate movements
and workspace extension. Clearly, both of them are required for
typical ISRU tasks. In this work, we develop a new concept of (d)Pre-utilization (e)Resourceutilization (f)Post-utilization
operationsandsuitablehuman-robotinterfacestoachievesample
Fig. 1: Example of ISRU mission operations pipeline [6]
collection and assembly with ease of use and accuracy. In the
proposed operational concept, the teleoperation space is extended
byexecutingautomatedtrajectories,offlineplannedatthecontrol
station. In three different experimental scenarios, we validate the example of which is shown in Figure 1. The use of in-
end-to-end system involving the control station and the robotic situ resources can significantly reduce the cost of logistical
asset, by assessing the contribution of haptics to mission success, challenges of space exploration and colonization by allowing
thesystemrobustnesstoconsistentdelays,andtheeaseoftraining
for local production of rocket fuel, extraction of water, and
new operators.
mining of minerals and other materials for use in construction
Index Terms—aerospace robotics, in situ resource utilization
(ISRU), human-robot interface, rovers concept of operations and manufacturing.
(CONOPS) Accessing, extracting, and using such resources can be
particularly dangerous for humans because of the hostile
I. INTRODUCTION environments on the surface of extraterrestrial planets. For
Many space agencies and organizations around the world this reason, a common solution for achieving such goals is
havealong-termobjectiveofsendinghumansintodeepspaceto the use of telerobots. They have been used since the earliest
explore destinations like Mars and beyond. Such a challenging space missions and allowed performing a range of works to
goal requires intensive study in terms of evaluating possible increase the productivity of space exploration. Because of
scenarios, strategies, architectures, and mission elements [1], communication delays, space agencies have been working to
aswellassolidinternationalcooperationandcollaboration.An develop robots that can be remotely controlled on the surface
innovative effort in this direction is NASA’s Artemis program of planets by astronauts in orbiting spacecrafts rather than
[2], which by 2024 plans to land the first woman and the ground stations on Earth.
next man on the lunar South Pole, establishing a sustainable First, NASA and ESA, with the HET and METERON
infrastructure on the surface [3] and in the lunar orbit [4], [5]. projects, respectively, conducted teleoperation experiments of
Thiswillenablethecrewtospendmoretimeandexploremore robots on Earth by astronauts orbiting in the ISS [7]. The
of the Moon than ever before, gaining invaluable knowledge METERON Haptics experiments investigated the effects of
and experience for future human missions. microgravity on haptic feedback perception using a 1-DOF
One key aspect of space exploration and colonization is the force-feedback joystick to teleoperate a robot on Earth from
use of resources that are available on other celestial bodies, a the ISS [8]. The experiments demonstrated the absence of
practice defined as in-situ resources utilization (ISRU), an significant alterations in flight when compared to ground
data, hence the feasibility of bilateral control with force
* L.PagliaraandV.Petroneareco-firstauthors feedback,withtimedelaysintheorderof820ms[9].Usingthe
4202
nuJ
31
]OR.sc[
1v64980.6042:viXrasame experimental setup, the METERON Interact experiment Ground station
employed force-feedback teleoperation to complete a sub-
millimeter peg-in-hole task [10]. During the experiment, the
astronautwassupportedbyvisualmarkersandpredictivevideo
information of pending commands.
During the experiments of the KONTUR-2 mission [11]–
Direct communication Wi-Fi network Direct communication
[13], astronauts used a 2-DOF force-feedback joystick to
Fig. 2: High-level overview of the system architecture
control surface robots and feel the forces of interaction with
the environment, using an Earth-ISS communication link
characterized by a latency of 20–30 ms. The bilateral control,
In this work, we tackle this trade-off by designing a set
based on the Time Domain Passivity Control approach, used
of software tools, supporting an operational concept where
duringtheexperiments,enabledstabilityandperformanceeven
the robot task space, subject to 1:1 position mapping, is
in the presence of jitter and data losses, demonstrating the
extended through offline-planned point-to-point trajectories.
effectiveness of haptic teleoperation with force feedback for
Therefore, through the alternation of haptic teleoperations
deploying robots in prior unknown situations, even with delays
and autonomously planned collision-aware trajectories, we
up to 1s.
aim at facilitating the accomplishment of mission goals,
More recently, during the Analog-1 experiments, a mobile
simplifyingtrainingprocedures,andreducingthelearningtime
manipulator was commanded on Earth, via a 6-DOF force-
for new operators without previous experience with robotic
feedback haptic device, to complete a rock-collecting task
teleoperations. Supported by quasi-real-time visual and force
[14]. The experiment demonstrated the effectiveness of haptic
feedback, as well as suitable planning tools integrated into an
telemanipulation even with a constant communication delay of
all-encompassingHRI,theoperatorcancompleteourvalidation
about 850ms.
objectives with ease, which consist in fetching a resource from
Parallel to the investigation of haptic teleoperations, ME-
the planetary soil and assembling it on board.
TERON SUPVIS-E and METERON SUPVIS-M experiments
explored supervised autonomy as a modality of telerobotic II. HRIFORHAPTICCONTROLINISRUMISSIONS
control. In this context, the operational concept was based on
A. System Design
theemploymentofintuitiveGUIstoperformteleoperationwith
task-level commands [15], [16]. This concept offers two main We assume a typical system setup as in Figure 2, including
advantages: it ensures the reliability of teleoperations even in a control station and two robots, which we term Exploration
the presence of extreme delays in the communication link, and Robot (ER) and Manipulation Robot (MR), with the latter
reduces the physical and mental workload of astronauts during mounted on the former. Our MR is a Panda arm by Franka
teleoperation phases, significantly facilitating the training of Emika [21] equipped with a two-finger gripper: it is the
new inexperienced operators [17]. More recent developments entity that physically interacts with the resource, actually
of this operational concept integrated haptic teleoperations performing the sample collection and assembly tasks. Our
as a modality of robot commanding, allowing astronauts to ER is a customized version of Husky by Clearpath Robotics
complete complex tasks where human cognitive capabilities [22]. It is a wheeled Unmanned Ground Vehicle (UGV): it
and operational flexibility and dexterity are crucial [18]. serves as an exploration agent that drives toward the resource
Carrying out such activities effectively requires expertise to manipulate. It is provided with cameras framing the points
and long training sessions for astronauts [19]. In particular, in which fetching and assembly operations are performed.
missions with robotic co-workers often require additional The MR is subject to Cartesian impedance control. First, it
training of astronauts, often supported by hardware-in-the- guarantees stability, even in case of communication loss since,
loop VR simulation systems [20]. Motivated by this, in the in case of missing references, the controller keeps tracking the
present work, we specifically target those elements of typical last position received. Second, it prevents damage to the arm
teleoperationsystemsthatnegativelyaffecttheeaseoflearning structure or the manipulated sample, as it adapts the received
and use. Then, we propose a new operational concept and referencestoensuresafeinteractionwiththesurroundings[23].
associated Human-Robot Interface (HRI) to overcome such Thecontrolstationfeaturesaworkstationandahapticdevice
limitations. [24], with a stylus at its tip, installed in a laboratory, with the
In haptic teleoperations, usability is mainly affected by robotslocatedoutdoors.Thecontrolstationcommunicatesover
command mapping between the master haptic device and a Wi-Fi network with the ER, which accounts for forwarding
the slave robot. In position mapping, 1:1 (or lower) scaling the commands to the MR through its onboard computer.
is paramount for accurate operations, but the robot’s task The proposed HRI is made of two components, namely
space is confined to be not larger than the haptic device’s, Haptic Control System (HCS) and Robot Visualization &
which limits the manipulator’s reachability. On the other hand, Planning (RVP), whose name is inspired by [25]. HCS
mapping the haptic device’s velocity, or adopting a workspace- establishes the mapping between the haptic device stylus’ and
extending position scaling would negatively affect accuracy robot end-effector’s poses and renders at the stylus the force
and ease of use, both for precision and large movements. feedback perceived at the MR’s flange so that they can be feltHaptic controller
pose commands haptic pose robot end-effector pose
Pose converter Internal c io nn pt uro tl
Haptic converter imCa pr et des ai na cn e
Force converter controller
robot pose
force feedbacks haptic force robot end-effector force
(a)Rearcameraframingthesample (b)Frontcameraframingtheslotin
Fig. 3: Haptic Control System block scheme
inthecollectionphase theutilizationphase
Fig. 4: Onboard camera images during teleoperations
bythehumanoperator.ItslogicisillustratedinFigure3,where
arrows indicate the data flow between the human, the robot,
4) Pre-utilization: the MR moves in the proximity of the
and the haptic device. RVP supports autonomous planning
location where resource utilization can happen, which
and validation of trajectories and manages transitions from
possibly is in a different region of the MR’s workspace.
autonomous mode to haptic teleoperations. Their goals and
Thus, workspace extension is necessary, while human
functions are explained in Section II-C and Section II-D,
expertiseisnotrequired.Thedesiredworkspaceextension
respectively, after introducing our mission operations concept
is obtained by means of autonomous collision-aware
in Section II-B.
planning through RVP.
5) Utilization: the MR inserts the resource in its assembly
B. Mission Operations Concept
slot.Here,humanexpertiseiscrucialforsafeandaccurate
Our ISRU mission includes a peg-in-hole teleoperated task, assembly. 1:1 position mapping, implemented by HCS,
in which the MR collects a metal parallelepipedon and places with arm visualization from both cameras and the 3D
itina3D-printedslot,providedwithaholeofthesamesizeas model, implemented by RVP, help the operator guide the
the sample (tolerance: 0.002m). During the whole experiment, robot near the hole (as in Figure 4b). Then, by sensing
the robot is placed outdoors and communicates remotely with the force feedback on the haptic device, they can have a
the indoor ground station, hence the human operator can natural and comfortable feeling of the hole’s walls, which
control the arm only via quasi-real-time visualization and allows for completing insertion with ease.
teleoperations, monitoring the actual state of the mission 6) Post-utilization: the MR opens the gripper’s fingers,
throughvisualfeedbackconsistingofthecameras’streamsand releasingthesampleinsideitsassemblyslotandachieving
3D reconstruction of the robot state, both displayed in RVP. the mission goal.
The proposed mission operations concept consists of the
following phases, illustrated in Figure 1: C. Haptic Control System
1) Pre-collection: the MR moves in the proximity of the In teleoperations through haptic devices, various scaling
sample to collect. In our concept, it suffices that the and mapping techniques have been proposed in the literature
sample is framed in the rear cameras, without a precise [26], such as position control and rate control. In rate control,
knowledge of its pose. Haptic teleoperations compensate the displacement of the haptic device is interpreted as a
for inaccuracies at the next step thanks to the visual velocity command, while position control consists of some
feedback from the rear camera (an example is shown in linear position mapping from the haptic device’s tip to the
Figure 4a). At the control station, this phase is supported robot’s end-effector.
by RVP, which assists the operator in planning collision- In our design for ISRU, we connect the master and slave
free trajectories. devices with 1:1 position mapping: this particular choice is
2) Collection: the MR precisely moves to the actual sample especially important for the peg-in-hole task, as it yields
location. This step is performed via HCS: the human the most direct, simple, and accurate transfer from human
operator drives the robot towards a configuration where commands to robot motion. The linear mapping undergoes
thegripper’sfingerscansafelyclosetocollecttheresource. transformationstoprovidetheuserwiththefeelingofoperating
1:1hapticpositionmappingallowsfornaturalandaccurate the MR from the ER cameras. Therefore, all displacements in
placement in a neighborhood of the resource, while the the haptic device’s workspace are relatively mapped in either
force feedback allows the user to feel the actual contact rear or front camera frames (depending on the mission phase),
with the resource, thus inherently yielding a more reliable so as to increase the naturalness of teleoperated control. In our
grasp and a safer motion. This phase ends when the MR design, the drawbacks of 1:1 position mapping, i.e. a limited
closes the gripper’s fingers, actually grasping the sample. workspaceandslowmotions,arecompensatedbytheexecution
3) Post-collection: the MR retracts from the soil (or fetching of autonomous trajectories.
location). In real scenarios, this phase possibly requires Concerning forces, we adopt linear mapping to transfer the
theERtonavigatetowardadifferentlocationforresource force sensed at the robot’s end-effector, in the order of tens
exploitation. of Newtons, to the haptic device, so as to be in the order of(a)Planfrominitialconfigurationto (b) Plan from fetching location to (a)Engagementatthefetchingloca- (b)Engagementattheassemblyloca-
fetchinglocation assemblylocation tion tion
Fig. 5: Point-to-point trajectory planning in RVP. Together Fig. 6: Engagement procedure in RVP. The haptic device
with ER and MR meshes, additional collision objects (in light moving frame is shown with solid colors, while the fixed
green)areaddedtoreplicate(1)theER’santennas,(2)thehole robot’s end-effector frame is displayed as shaded.
in which the sample is assembled, and (3) the front camera,
modeledasaboxtoaccountforallpossibleorientations(being
thefrontcamerapairmountedonapassivepan-tiltunit,without III. RESULTS
encoders).
This section reports the results of rehearsing the operations
of Section II with the proposed HRI. The end-to-end system
is shown deployed in a remote ISRU mission in [6], while
units. This is crucial to naturally and successfully perform a this section’s focus is on performing a formal assessment of
contact-rich manipulation task. different aspects of the system. With the aim to confirm the
HCS also features gravity compensation of the robot’s impactofhapticcontrolonmissionoperations,inSectionIII-A
payload, as well as filtering of human tremors to generate we compare trials with force and visual feedback with trials
stable poses for the robot and increase accuracy. with visual feedback only. In Section III-B, we assess the end-
to-end system in case of communication delays. Such trials are
performed by the same experienced operator on the same day.
D. Robot Visualization & Planning Theoperatorhaspreviousexperiencewithhapticteleoperations
for robotic interaction tasks and interaction control in general
RVP is designed to accomplish three goals:
and a deep knowledge of how to operate the MR.
1) Visualizeandassesstherobotstate,i.e.itsjointconfigura- Finally, in Section III-C, we assess the ease of learning to
tion,inreal-time.Iftherobotstateiscontinuouslyupdated use the system to achieve the intended goal. These trials are
and replayed in a 3D scene, the operator can assess the therefore performed by operators with some knowledge of
results of the commands, remotely sent from the control robotics, yet without any expertise in either the specific task
station. For complete awareness, cross-verification with or haptic teleoperations in general.
camera streams is also possible through the RVP GUI. All the trials are conducted in a controlled environment, i.e.
2) Plan, rehearse, and validate point-to-point collision-aware a laboratory room (yet with the robot not in the view of the
trajectories during pre-collection (see Section II-B, step operator), with the workstation connected to the ER’s wireless
1) and pre-utilization phases (see Section II-B, step 4). network. For each trial, the parallelepipedon to collect (see
Eventually, the planned trajectories (depicted in Figure 5) Figure 4a) is approximately placed in front of the camera, with
are uplinked to the robot. This is the feature that allows little variations of the samples’ pose across the trials.
extending the teleoperated robot’s workspace: indeed,
differently from [18], our HRI, together with assisting the A. Haptic control assessment
operator by providing visual feedback, allows combining
The task to perform is composed of two human-driven
accurate teleoperation positioning with a large workspace.
sub-tasks (i.e., Fetching and Assembly), both requiring haptic
3) Manage the transitions between autonomous trajectories
teleoperations. With reference to the pipeline presented in
andteleoperations,i.e.supporttheoperatorinengagingthe
Section II-B, Fetching includes steps 2–3, while Assembly
MRwiththehapticdevicewhenitsstylus’andtherobot’s
corresponds to steps 5–6. Fetching is considered successful
end-effector’s orientations match, as visible in Figure 6.
if the object is stably grasped, and the arm is lifted with the
This component is crucial to activating teleoperations at
sample firmly held by the fingers. Assembly is considered
different workspace locations with ease; indeed, without a
successfulifthesampleisassembledinitsslot,andthefingers
visual assistive tool, the engagement would be practically
are open. If, in any sub-task, the measured forces exceed a
unfeasible.
safety threshold (above which the sample is considered asTABLE I: Success rate of the mission operations out of 20 TABLE II: Training time of 3 different operators
trials in different scenarios
Operator Numberofattempts Totaltrainingtime
Scenario Forcefeedback Delayd Fetching Assembly 1 9 1h38min
A ✗ 0s 85% 40% 2 5 35min
B ✓ 0s 95% 90% 3 10 1h20min
C ✓ 0.5s 95% 90%
D ✓ 1.0s 95% 65%
C. Ease of training new operators
In order to assess the proposed HRI’s ease of use in view
damaged), the MR controller stops and the Task is counted as
of training new operators, we select three subjects with no
failed.
experience with haptic teleoperations. Each participant is first
We exercise the whole operational procedure 20 times
explained procedures and tools, then they exercise the entire
excluding the haptic feedback (Scenario A), and 20 times
operationalprocedureseveraltimes.Weconsiderthetrainingto
including the haptic feedback (Scenario B); in the former case,
becompletewhentheoperatorisabletoperform5consecutive
the user can solely rely on visual feedback. The overall results
successful trials.
are reported in Table I in terms of the success rate of the
The experiments foresee haptic feedback and no communi-
Fetching and Assembly sub-tasks.
cation delays. We consider two metrics for the evaluation of
The results show that considerable improvements are ease of training, i.e. the total training time and the number of
achieved when perceiving the forces: indeed, the Assembly attempts. The results are shown in Table II.
success rate is increased by a factor of 2.25, while sensible im- Although the number of involved subjects is not enough
provements(thesuccessrateis1.06timeshigher)areobserved to draw general conclusions, our preliminary results suggest
for Fetching too, hence almost nullifying the probability of a that combining haptic teleoperations with suitable HRI and
failure, highlighting how the implicit compliance delivered by operational procedures might greatly simplify the training
the human-in-the-loop is fundamental for the sample integrity. process for completely inexperienced operators. Therefore, we
aim at extending our trials to a larger audience, possibly made
of subjects with heterogeneous backgrounds.
B. Analysis of the system in case of communication delays
Since we aim at replicating a planetary manipulation task, IV. CONCLUSIONS
we test the robustness of our system by introducing, via
This work proposes a new concept of operations and
software, a delay in the communication link between the
associated HRI to assist human operators in the control of
MR and the workstation. Given a delay d, if an operator
remote robotized systems for planetary ISRU missions. We
forwards a command by moving the haptic device at time t,
adopt a haptic control system to allow for accurate remote
the MR receives the reference at time t+d, and the resulting
manipulation, and a set of software tools and interfaces to
forces produced by the motion are fed back to the operator at
plan and command trajectories from the control station. By
approximately t+2d.
alternating off-line planned trajectories and quasi-real-time
We perform 20 experiments with d = 0.5s (Scenario C), teleoperations,thehapticcontrolworkspaceisextendedwithout
and 20 experiments with d = 1.0s (Scenario D), exercising, sacrificing accuracy. At the same time, the proposed HRI
in both scenarios, the procedure detailed in Section II-B, as preserves the system’s ease of use.
before. We assume no inherent delay in the communication, Through the rehearsal across multiple trials of an ISRU
besides the one introduced via software. The operator can rely scenarioincludingapeg-in-holemanipulationtask,weconfirm
on both visual and haptic feedback to perform the task, with that haptic control improves both safety and performance of
the state of the robot displayed by RVP. the considered task, prevents damage to the collected sample,
The results of the trials in Scenarios C and D are reported therobot,anditssurroundings,increaseshumanawarenessand
in Table I. Although a round-trip delay of 2d = 1.0s, the allows compensating for communication delays. In addition,
performances of Scenario A are preserved. On the other hand, our preliminary results suggest that inexperienced operators
a remarkable decrease in performance is registered in Scenario couldbeefficientlytrainedtocompletethetaskwithease.This
D. In particular, because of the round-trip delay 2d = 2.0s, motivates further investigations involving a larger audience of
the success rate of the Assembly phase drops from 90% to operators with a heterogeneous background.
65%, as the user’s comfort during the peg-in-hole operation ThroughtheemploymentoftheproposedHRI,weassessthe
is degraded by the delayed perception of the contact forces impactofthehapticfeedbackonmissionsuccess:aninteraction
between the sample and the assembly slot. taskrequiringanelevateddegreeofaccuracycanbeperformed
Although successful trials in Scenario D are twice more 2.25 times more successfully when compared to a system
frequent than failures, a success rate of 65% is not enough to in which classical position-based teleoperations are adopted.
consider the system’s performance acceptable in the case of Also, the system is robust to round-trip communication delays
d=1.0s. Therefore, we consider d=0.5s as the limit case, up to 1.0s and can be further improved by adopting more
confirming the results of [10], [14]. sophisticated state-of-art teleoperation techniques.ACKNOWLEDGMENT [18] P.Schmaus,D.Leidner,T.Krueger,J.Grenouilleau,A.Pereira,A.S.
Bauer,N.Bechtel,S.B.Gomez,A.Köpken,F.S.Lay,M.Sewtz,N.Batti,
The authors would like to thank Francesco Avallone for E.Ferreira,E.denExter,R.Bayer,B.Pleintinger,R.Holderried,P.H.
refining the controller implementation, making this work Pavelski,andN.Y.-S.Lii,“Onrealizingmulti-robotcommandthrough
extendingtheknowledgedriventeleoperationapproach,”inProc.73rd
possible.
Int.Astronaut.Congr.IAC,Sep.2022.
[19] H.SteimleandC.Norberg,“Astronautselectionandtraining,”inHuman
REFERENCES SpaceflightandExploration,ser.SpringerPraxisBooks,C.Norberg,Ed.
Berlin,Heidelberg:Springer,2013,pp.255–294.
[1] M.A.Viscio,E.Gargioli,J.A.Hoffman,P.Maggiore,A.Messidoro, [20] A.D.Garcia,J.Schlueter,andE.Paddock,“TrainingAstronautsusing
andN.Viola,“Amethodologytosupportstrategicdecisionsinfuture Hardware-in-the-LoopSimulationsandVirtualReality,”inAIAAScitech
humanspaceexploration:Fromscenariodefinitiontobuildingblocks 2020Forum. AmericanInstituteofAeronauticsandAstronautics.
assessment,”ActaAstronautica,vol.91,pp.198–217,2013. [21] FrankaEmika,“FrankaEmika-NextGenerationRobotics,”https://www.
[2] NASA, “Artemis,” https://www.nasa.gov/specials/artemis/index.html, franka.de/,2022.
2022. [22] Clearpath Robotics, “Husky UGV - Outdoor Field Re-
[3] ——, “Lunar living: Nasa’s artemis base camp con- search Robot by Clearpath,” https://clearpathrobotics.com/
cept – artemis,” https://blogs.nasa.gov/artemis/2020/10/28/ husky-unmanned-ground-vehicle-robot/,2022.
lunar-living-nasas-artemis-base-camp-concept/,2022. [23] M.T.Mason,“ComplianceandForceControlforComputerControlled
[4] ——,“Gateway,”https://www.nasa.gov/gateway,Dec.2019. Manipulators,”IEEETrans.Syst.ManCybern.,pp.418–432,Jun.1981.
[5] K.Coderre,C.Edwards,T.Cichan,D.Richey,N.Shupe,D.Sabolish, [24] 3D Systems, “Touch - Haptic Device,” https://www.3dsystems.com/
S.Ramm,B.Perkes,J.Posey,W.Pratt,andE.Liu,“Conceptofoperations haptics-devices/touch,Jun.2016.
forthegateway,”inSpaceOperations:InspiringHumankind’sFuture. [25] F.M.Fadrique,R.S.-B.Fernández,M.Barrera,P.Franceschetti,and
Cham:SpringerInternationalPublishing,2019,pp.63–82. L.Joudrier,“ExoMars2020:RoverOperationsControlSystemDesign
[6] L.Pagliara,V.Petrone,E.Ferrentino,andP.Chiacchio,“Autonomous aspartoftheRoverOperationsControlCenter(ROCC),”inSpaceOps
planningandhapticteleoperationsinrobotizedplanetarysamplecollec- Conf.,May2018.
tionandassembly,”https://youtu.be/YNFft1pYCmE,Dec.2022,Youtube. [26] M. Radi, Workspace scaling and haptic feedback for industrial telep-
[7] M.Bualat,W.Carey,T.Fong,K.Nergaard,C.Provencher,A.Schiele, resence and teleaction systems with heavy-duty teleoperators, ser.
P.Schoonejans,andE.Smith,“PreparingforCrew-ControlofSurface Forschungsberichte IWB. München: Herbert Utz Verlag, 2012, no.
RobotsfromOrbit,”https://ntrs.nasa.gov/citations/20190001339,Wash- 261,https://www.utzverlag.de/catalog/book/44195.
ington,DC,Jan.2014.
[8] A.Schiele,M.Aiple,T.Krueger,F.vanderHulst,S.Kimmer,J.Smisek,
andE.denExter,“Haptics-1:PreliminaryResultsfromtheFirstStiffness
JNDIdentificationExperimentinSpace,”inHaptics:Percept.,Devices,
Control,andAppl.,Cham,2016,pp.13–22.
[9] A.Schiele,T.Krüger,S.Kimmer,M.Aiple,J.Rebelo,J.Smisek,E.den
Exter, E. Mattheson, A. Hernandez, and F. van der Hulst, “Haptics-2
—Asystemforbilateralcontrolexperimentsfromspacetogroundvia
geosynchronoussatellites,”inProc.IEEEInt.Conf.Syst.ManCybern.,
Oct.2016,pp.892–897.
[10] A. Schiele, J. Smisek, E. Den, E. Matheson, T. Krueger,
F. van der Hulst, J. Rebelo, S. Kimmer, M. Damen, N. Mol,
and M. Aiple, “Towards the Interact Space Experiment:
Controlling an Outdoor Robot on Earth’s Surface from Space,”
https://www.researchgate.net/publication/329153096_Towards_the_
Interact_Space_Experiment_Controlling_an_Outdoor_Robot_on_Earth,
May2015.
[11] B. Weber, R. Balachandran, C. Riecke, F. Stulp, and M. Stelzer,
“TeleoperatingRobotsfromtheInternationalSpaceStation:Microgravity
EffectsonPerformancewithForceFeedback,”inProc.IEEEInt.Conf.
Intell.RobotsSystems.,Macau,China,Nov.2019,pp.8144–8150.
[12] J.Artigas,R.Balachandran,C.Riecke,M.Stelzer,B.Weber,J.-H.Ryu,
andA.Albu-Schaeffer,“KONTUR-2:Force-feedbackteleoperationfrom
theinternationalspacestation,”inProc.IEEEInt.Conf.onRobot.and
Autom.,Stockholm,Sweden,May2016,pp.1166–1173.
[13] M.Stelzer,B.-M.Steinmetz,P.Birkenkampf,J.Vogel,B.Brunner,and
S.Kühne,“SoftwarearchitectureanddesignoftheKontur-2mission,”
inIEEEAerosp.Conf.,Mar.2017,pp.1–17.
[14] M.Panzirsch,A.Pereira,H.Singh,B.Weber,E.Ferreira,A.Gherghescu,
L. Hann, E. den Exter, F. van der Hulst, L. Gerdes, L. Cencetti,
K. Wormnes, J. Grenouilleau, W. Carey, R. Balachandran, T. Hulin,
C.Ott,D.Leidner,A.Albu-Schäffer,N.Y.Lii,andT.Krüger,“Exploring
planetgeologythroughforce-feedbacktelemanipulationfromorbit,”Sci.
Robot.,vol.7,Apr.2022.
[15] P.Schmaus,D.Leidner,T.Krüger,A.Schiele,B.Pleintinger,R.Bayer,
and N. Y. Lii, “Preliminary Insights From the METERON SUPVIS
JustinSpace-RoboticsExperiment,”IEEERobot.Autom.Lett.,vol.3,
Oct.2018.
[16] P.Schmaus,D.Leidner,R.Bayer,B.Pleintinger,T.Krüger,andN.Y.Lii,
“ContinuedAdvancesinSupervisedAutonomyUserInterfaceDesignfor
METERONSUPVISJustin,”in2019IEEEAerospaceConference,Mar.
2019,pp.1–11.
[17] P.Schmaus,D.Leidner,T.Krüger,R.Bayer,B.Pleintinger,A.Schiele,
andN.Y.Lii,“KnowledgeDrivenOrbit-to-GroundTeleoperationofa
RobotCoworker,”IEEERobot.Autom.Lett.,2020.