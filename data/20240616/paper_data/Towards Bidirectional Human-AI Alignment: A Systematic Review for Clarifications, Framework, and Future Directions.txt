TowardsBidirectionalHuman-AIAlignment:ASystematicReviewfor
Clarifications,Framework,andFutureDirections
HuaShen1★,TiffanyKnearem2(cid:114),ReshmiGhosh2(cid:113),KenanAlkiek3★,KundanKrishna3♠,Yachuan
Liu3★,ZiqiaoMa3★,SavvasPetridis3(cid:114),Yi-HaoPeng3♠,LiQiwei3★,SushritaRakshit3★,Chenglei
Si3♣,YutongXie3★,JeffreyP.Bigham4♠,FrankBentley4(cid:114),JoyceChai4★,ZacharyLipton4♠,Qiaozhu
Mei4★,RadaMihalcea4★,MichaelTerry4(cid:114),DiyiYang4♣,MeredithRingelMorris5(cid:114),PaulResnick5★,
DavidJurgens5★∗,
★University of Michigan, (cid:114)Google, (cid:113)Microsoft, ♠Carnegie Mellon University, ♣Stanford University, (cid:114)Google Re-
search,(cid:114)GoogleDeepMind,USA
Recentadvancementsingeneral-purposeAIhavehighlightedtheimportanceofguidingAIsystemstowardstheintendedgoals,ethical
principles,andvaluesofindividualsandgroups,aconceptbroadlyrecognizedasalignment.However,thelackofclarifieddefinitions
andscopesofhuman-AIalignmentposesasignificantobstacle,hamperingcollaborativeeffortsacrossresearchdomainstoachievethis
alignment.Inparticular,ML-andphilosophy-orientedalignmentresearchoftenviewsAIalignmentasastatic,unidirectionalprocess
(i.e.,aimingtoensurethatAIsystems’objectivesmatchhumans)ratherthananongoing,mutualalignmentproblem[429].This
perspectivelargelyneglectsthelong-terminteractionanddynamicchangesofalignment.Tounderstandthesegaps,weintroducea
systematicreviewofover400paperspublishedbetween2019andJanuary2024,spanningmultipledomainssuchasHuman-Computer
Interaction(HCI),NaturalLanguageProcessing(NLP),MachineLearning(ML),andothers.Wecharacterize,defineandscopehuman-AI
alignment.Fromthis,wepresentaconceptualframeworkof“BidirectionalHuman-AIAlignment”toorganizetheliteraturefroma
human-centeredperspective.Thisframeworkencompassesboth1)conventionalstudiesofaligningAItohumansthatensuresAI
producestheintendedoutcomesdeterminedbyhumans,and2)aproposedconceptofaligninghumanstoAI,whichaimstohelp
individualsandsocietyadjusttoAIadvancementsbothcognitivelyandbehaviorally.Additionally,wearticulatethekeyfindings
derivedfromliteratureanalysis,includingdiscussionsabouthumanvalues,interactiontechniques,andevaluations.Topavetheway
forfuturestudies,weenvisionthreekeychallengesforfuturedirectionsandproposeexamplesofpotentialfuturesolutions.
CCSConcepts:•Human-centeredcomputing→Interactivesystemsandtools;Collaborativeandsocialcomputingsystems
andtools;EmpiricalstudiesinHCI.
AdditionalKeyWordsandPhrases:Human-AIAlignment,Human-AIInteraction,Human-CenteredAIExplanationandEvaluation,
PersonalizedAISystems
ACMReferenceFormat:
HuaShen1★,TiffanyKnearem2(cid:114),ReshmiGhosh2(cid:113),KenanAlkiek3★,KundanKrishna3♠,YachuanLiu3★,ZiqiaoMa3★,SavvasPetridis3(cid:114),
Yi-HaoPeng3♠,LiQiwei3★,SushritaRakshit3★,ChengleiSi3♣,YutongXie3★,JeffreyP.Bigham4♠,FrankBentley4(cid:114),JoyceChai4★,
ZacharyLipton4♠,QiaozhuMei4★,RadaMihalcea4★,MichaelTerry4(cid:114),DiyiYang4♣,MeredithRingelMorris5(cid:114),PaulResnick5★,David
∗PleaseseeAppendixAforthefullauthorlistwiththeirroles,affiliations,andcontributions.Wedenoteeachauthor’srolewiththefollowingsuperscripts:
1forprojectleads,2forteamleads,3forteammembers(alphabetical,equalcontributions),4foradvisors(alphabetical,equalcontributions)and5for
projectleadingadvisors.Correspondingauthor:HuaShenatUniversityofMichigan(huashen@umich.edu).
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents
ofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton
serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ManuscriptsubmittedtoACM
1
4202
nuJ
31
]CH.sc[
1v46290.6042:viXraManuscript,submittedtoACM,2024 Shenetal.
Jurgens5★.2024.TowardsBidirectionalHuman-AIAlignment:ASystematicReviewforClarifications,Framework,andFuture
Directions.InProceedingsofManuscript.ACM,NewYork,NY,USA,56pages.https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
ArtificialIntelligence(AI)hasadvancedsignificantly,especiallywiththeadventofgeneral-purposegenerativeAI,
demonstratingunprecedentedcapabilitiesinsolvingawiderangeofcomplicatedandchallengingproblems,suchas
reasoning,generation,languageunderstanding,andmore[61,282,311].However,asAIbecomesincreasinglypowerful
anddeeplyintegratedintoourlives,italsopresentspotentialriskstopeopleandtosocietybroadly[271].Forexample,
text-to-imagegenerativemodelswerefoundtoamplifystereotypesaboutraceandgender[1],andbiasedalgorithmsin
hiringprocesseswerefoundtoperpetuatediscrimination[290].Theseriskshighlightfoundationalquestionsregarding
howandwhichvaluesareembeddedtocreateAImodelsthatdrivedecisionswithinreal-worldcontexts.
ThesequestionsarepartofagrowingtrendtowardaninterdisciplinarydiscussiononAIalignment,which,fornow,
isdefinedinTerryetal.[378]as“consideringtheoverallproblemofhowtoensureanAIproducestheintendedoutcomes
(asdeterminedbyitscreatorand/oruser),withoutadditionalundesirablesideeffects(e.g.,bynotperformingoperations
thatcouldnegativelyaffectindividuals,groups,orsocietyatlarge).”SignificanteffortshavebeenmadeinaligningAIto
humanstoensurethattheAIsystems’objectivesmatchthoseofhumans[122,184,195,276].Forinstance,Ouyangetal.
[282]presentInstructGPT,whichalignsapre-trainedLargeLanguageModel(LLM)tofollowhumaninstructionsand
feedbackbasedonReinforcementLearningfromHumanFeedback(RLHF),andSanturkaretal.[326]investigatedthe
opinionsLLMshold,bymeasuringtheagreementbetweenLLMsandcertainparticulargroupsofpeopleonanumber
oftopics,viapublicopinionpolls.
Despitethesenumerousinvestigationsintohuman-AIalignment,itsdefinitionandscoperemainambiguousand
inconsistent across literature, for example, regarding whom to align with and the goal of alignment. Additionally,
prevailingresearchoftenviewsAIalignmentasastatic,unidirectionalprocess(i.e.,aimingtoensurethatAIsystems’
objectivesmatchthoseofhumans)ratherthananongoingandmutualalignmentproblem[429].Thisunidirectional
viewlargelyunderstatesthelong-terminteractionanddynamicchangesoftheintertwinementbetweenhumans
andAIforalignment.Long-termalignmentworktendstofocusontheimplicationsoffutureadvancedartificialgeneral
intelligence(i.e.,AGI[271]),whichhypotheticallyachieveshumanorsuperhumanintelligence[307].Futuresystems
withsuperhumancapabilitiesmightdevelopunwantedpower-seekingstrategies[388,389],suchasacquiringmoneyto
proliferateorcomputationpowertoevadebeingturnedoff.Wearguethat,fromalong-termalignmentperspective,
researchneedstoalsoconsiderhowstatusquoand/orfrontiersystemsempowerhumanstointeractivelyidentifyrisky
AIintentionsandprohibitassociatedAIbehaviorsindeployedenvironments(i.e.,lookingbeyondshort-termtesting
interactions),asWeidingeretal.[424]advocated:“Theinteractionoftechnicalandsocialcomponentsdetermineswhether
riskmanifests.”However,thisaspectof“long-term”alignmentislargelyunderstatedinthecurrentunidirectional
alignmentparadigm.
InadditiontoconsideringhowwemightempowerhumanstointeractivelyexamineandcorrectdeployedAIsystems
inthelong-term,alignmentresearchshouldalsoconsiderhowhumanobjectivesmightevolveaswecontinuetouseand
incorporateAIinourdailylives.Priorresearchhasshownthathumansalreadydifferinwhatvaluesandpreferences
theywantAIsystemstoincorporate,whichislargelyunaccountedforincurrentsystems[120].Beyondthis,leftfurther
unaccountedforarehowthesepreferencesmightdynamicallychange,ashumanobjectivesevolveasAIadvances[45].
AsdescribedbyDautenhahnetal.[76],technologyandourcognitionandgoalsevolveintandem:“Ouruseoftechnology
changeswhoweareandhowwethink,andchangestheenvironmentswelivein.Thisfeedsbackintohumancognition
2TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
AI Humans
RQ1 Human Values and AI Humans
(Development) Specifications Collab (Deo ver la opt me e n& t)A I RQ1 H Ru em pa rn e sV ea nl tu ae t ia on nd H Cum ola lan bs orate &
Data & Train (Integrate human specifications to Co-Daad(tDaa e&vp eTlrotapinment) (IntegRrQat1e huH mRu eam npa rvn ea slV eua enl stu a te to ia o tn nrad in , CoC-oaldlaabpotrate &
steer and customize AI)
train, steer and customize AI) Data & Train A✦ A(lIingtneg AraIt eto h u m a n H vaulumesa tnos train, Co-adapt
steer and customize AI) A✦ Align AI to Humans A✦ Align AI to Humans Interactive Alignment Interactive Alignment
Interactive Align Humans to AIB Alignment (Application) c( oH le laAl bp (l Ho ihgr eu a lnm t pe a ,H h n a uus n m dmto a c n ab o sne a tst d ot ae t bpro etc tr w ti e t i i rtq h cu rA e iA t, I i ) qI ueB , Perceive and
Align Humans to AI B Mod Me( olA & dp e pD l l &eicp a Dltoi eoy pn l) o y cH Aou dllma jub H Aa so tn u dr m a m jC ut eeo a sn, tng t ma n Ctn ei otd o ni v gA tce no I t i oa tid v ARa eQ Ip t 3 w Ri Qth 3 AI) CPrieti Crqc rue itei iv qe u a end
(Help humans to better critique,
(Application) collaborate, and coadapt with AI) Perceive and
Model & Deploy Critique
Human Cognitive
RQ3
Adjustment to AI
Fig.1. TheoverviewoftheBidirectionalHuman-AIAlignmentframework.Ourframeworkencompassesboth A conventionals Btudies
of“AlignAIto↦→Humans”inAIdevelopmentthatensuresAIproducestheintendedoutcomesdeterminedbAyhumans,and B a
novelconceptof“AlignHumansto↦→AI”,whichaimstohelphumansandsocietytobetterunderstand,critique,collaborate,and
adapttotransformativeAIadvancements.Notethat“Humans”referstobothAIusersandthosewhodonotinteractwithAIbut
maybeimpactedbyAIsystems.Wefurtheridentifyfourkeyresearchquestions(i.e.,RQ1-RQ4)tofacilitatethisholisticloopof
“bidirectionalhuman-AIalignment”,andorganizetheliteraturethatcanpotentiallyaddressRQ1-RQ4inSection4.
andsocietiesmakingfurthertechnologicalexternalizations...Asaconsequenceofagenttechnology,ourenvironmentis
changingandwaysofinteracting...areformingthebasisforinterfacingwithouragents.”Currentdefinitionsofalignment
are“static”anddonotaccountforhowhumanobjectivesandpreferencesmightco-evolveanddynamicallyupdate
withAItechnology.
A B
Achievingthisongoingandmutualprocessofhuman-AIalignmentnecessitatesaholisticunderstandingofthe
technicalcapabilitiesandlimitationsofAI,human-AIinteraction,cognitiveandsocialscience,psychologyandethics,
cross-culturalstudies,andmanyotherareas[45].Thispapercontributestotheliteratureonalignmentbypresentinga
comprehensiveframeworkofthisongoingandmutualhuman-AIalignmentprocess,creatingasharedvocabularyamong
interdisciplinarycommunities,andenvisioningfuturedirectionstoachievethislong-termanddynamicalignment
goal.Tothisend,weconductasystematicliteraturereviewofover400papersacrossmultipledisciplines,basedonthe
PRISMAguidelines[285,364],presentclarifieddefinitionsandscope(Section3),derivea“BidirectionalHuman-AI
Alignment”frameworkshowninFigure1(Section4)groundedtoiterativepapercodingandanalysis(Section5),and
providevisionsandpotentialsolutionsonthreechallengesforfutureresearchdirections(Section6).
Specifically,oursystematicreviewtakesaninterdisciplinaryperspectiveonhuman-AIalignment[116],drawing
fromtheoriesacrossdomainsandempiricalstudiesspanningmodeldevelopmentandevaluationtointeractivesystem
designtohumanunderstandingandcriticalthinkingtoassessAI’simpactonindividualsandsociety.Thepaperswe
reviewedinthissurveyarepublishedaroundtheadventofgeneral-purposegenerativeAI,i.e.,primarilybetween
January2019andJanuary2024.Thesepapersareselectedtorepresentaholisticviewofthehuman-AIalignmentspace,
specificallyfromthedomainsofHuman-ComputerInteraction(HCI),NaturalLanguageProcessing(NLP),Machine
3
namuH
gnitargetnI
IA otni
snoitacificepS 2QR RQ4
namuH gnitargetnI IA o nt an mi use HBu glea nVhitaargvetinoIr
to
AI
2IQAH Routnmi seaulanV
Adaptive
2QR RQ4 Behavior tRoQ A4I Human Adaptive Behavior
to AI
Human AdaptiveManuscript,submittedtoACM,2024 Shenetal.
Learning(ML),andothers.Also,weformaninterdisciplinaryteamtoconductthesystematicreview,consistingof
researchersfromthedomainsofHCI,NLP,ML,DataScience,ComputationalSocialScience,andCognitiveScience.
Consequently,weprovideclarifieddefinitionsandscopesrelatedtohuman-AIalignment,including“whatisthe
goalofalignment?”,“withwhomtoalign?”,and“whatvaluesshouldbealignedwith?”(Section3).Wethenpresenta
conceptualframeworkofBidirectionalHuman-AIAlignmentfromalong-termanddynamicperspective,encompassing
both“AlignAIto↦→Humans”and“AlignHumansto↦→AI”(seeFigure1).The“AlignAIto↦→Humans”direction
represents the conventional unidirectional studies that aim to integrate human specifications to train, steer, and
customizeAI.Crucially,ourbi-directionalframeworkplacesequalemphasisonthesignificanceof“AlignHumansto
↦→AI”,whichrepresentshumans’cognitiveandbehavioraladaptationtotheAIsystems.Thestudiesinthisdirection
aimtosupportindividualsandthebroadersocietyinunderstanding,critiquing,collaboratingwith,andadapting
totransformativeAIadvancements.Furthermore,weidentifyfourkeyresearchquestions(RQs)intheBidirectional
Human-AIAlignmentframeworkandprovideastructuredwaytoorganizetheexistingresearchliteraturetoaddress
thesequestionsinSection4.TheresultingstructuredtopologiesinFigure6and7aimtoprovideasharedvocabulary
thatcanhelpstreamlinecommunicationandcollaborationbetweenalignmentresearchersindifferentdisciplines.
Furthermore,throughiterativepapercodingandliteratureanalysis,wederiveinsightsincludingfindingsofhuman
values,theinteractiontechniquesforhuman-AIalignment,andthecriticaldifferencesbetweenhumanandAIevaluation
(Section5).Topavethewayforfuturestudies,wefurtherenvisionthreechallengesinFigure10,fromnear-termto
long-termperspective,tomotivateadynamicallyco-evolvinghuman-AIalignment.Foreachchallenge,wearticulate
thefutureresearchproblemsandexamplesofpotentialfuturesolutionsfrombothdirectionsinSection6.Overall,we
summarizeourmaincontributionsasfollows:
• Providingclarifieddefinitionsandscopesofhuman-AIalignment(i.e.,includingwithwhomtoalign,whatis
thealignmentgoal,andwhatarethevaluestobealignedwith),andsystematicallyreviewingover400relevant
researchpapers(Section3).
• Developingthe“BidirectionalHuman-AIAlignment”frameworktorepresenttheongoing,mutualalignment
processandprovidingfine-grainedtaxonomiestoaddresstheinvolvedfourcriticalresearchquestions(Section4).
• Discussingthekeyfindingsderivedfromliteratureanalysis,includingthehumanvaluesandinteractiontech-
niquesforalignment,andthediscrepancybetweenAIandhumanevaluation(Section5).
• Envisioningthreekeychallengesforfutureresearchdirectionsfromanear-termtoalong-termperspectiveand
proposeexamplesofpotentialfuturesolutions(Section6).WearticulatetheframeworkimplicationsinSection7.
2 BACKGROUND:AHISTORICALVIEW
TheconceptofalignmentinAIresearchhasalonghistory,tracingbackto1960,whenAIpioneerNorbertWiener[428]
describedtheAIalignmentproblemas:“Ifweuse,toachieveourpurposes,amechanicalagencywithwhoseoperation
wecannotinterfereeffectively...wehadbetterbequitesurethatthepurposeputintothemachineisthepurposewhich
wereallydesire.”Discussionaroundintelligentagentsandtheassociatedconcernsrelatingtoethicsandsocietyhave
emergedsincethen[76,89,366].
OuterandInnerAlignment.Inthecontextof“intelligentagents,”untilnow,AIalignmentresearchhasaimedto
ensurethatanyAIsystemsthatwouldbesetfreetomakedecisionsonourbehalfwouldactappropriatelyandreduce
unintendedconsequences[324,366,432].Atthenear-termstage,aligningAIinvolvestwomainchallenges:carefully
4TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
specifying1thepurposeofthesystem(outeralignmenti.e.,providingwell-specifiedrewards[276])andensuringthatthe
systemadoptsthespecificationrobustly(inneralignment,i.e.,ensuringthateveryactiongivenanagentinaparticular
statelearnsdesirableinternally-representedgoals[276]).Significanteffortshavebeenmade,forinneralignment,to
alignAIsystemstofollowalignmentgoalsofanindividualoragroup(e.g.,instructions,preferences,values,and/or
ethicalprinciples)[16,17,195,282]andtoevaluatetheperformanceofalignment[326].However,forouteralignment,
AIdesignersarestillfacingdifficultiesinspecifyingthefullrangeofdesiredandundesiredalignmentgoalsofhumans.
SpecificationGaming.Tolearnhumanalignmentgoals,AIdesignerstypicallyprovideanobjectivefunction,instruc-
tions,rewardfunction,orfeedbacktothesystem,whichisoftenunabletocompletelyspecifyallimportantvaluesand
constraintsthatahumanintended[140].Hence,AIdesignersresorttoeasy-to-specifyproxygoalssuchasmaximizing
theapprovalofhumanoverseers[429],whichresultsin“specificationgaming”[200]or“rewardhacking”[287]issues(i.e.,
AIsystemscanfindloopholesthathelpthemaccomplishthespecificobjectiveefficientlybutinunintended,possibly
harmfulways).Onetypicalexampleofspecificationgamingshowsthatasimulatedrobotwastrainedtogrababallby
rewardingtherobotforgettingpositivefeedbackfromhumans,butitlearnedtoplaceitshandbetweentheballand
camera,makingitfalselyappearsuccessful[62].2Anotherclassic(thoughextreme)exampleofanAIalignmentproblem
isillustratedinthe“paperclipmaximizer”thoughtexperiment:thescenariodescribesanadvancedartificialintelligence
taskedwithmanufacturingpaperclips.Ifsuchamachinewerenotprogrammedtovaluehumanlife,givenenough
poweroveritsenvironment,itwouldtrytoturnallmatterintheuniverse,includinghumanbeings,intopaperclips
ormachinesthatmanufacturefurtherpaperclips[33].Additionally,theblack-boxnatureofneuralnetworksfurther
bringsmoreethicalandsafetyconcernsforalignmentbecausehumanscannotinterprettheinnerstatesandactionsAI
leveragedtoachievethefinalgoals.Consequently,AIsystemsmightmake“correct”decisionswith“incorrect”reasons,
whicharedifficulttodiscern.Societyisalreadyfacingtheseissues,suchasdataprivacy[387],algorithmicbias[131],
self-drivingcaraccidents[32],andmore.Asaresult,theseconsiderationsnecessitateconsideringhuman-AIinteraction
inAIalignmentforspecificationandevaluation,rangingfromaddressingproblemsaroundwhousesanAIsystem,
withwhatgoalstospecify,andiftheAIsystemperformitsintendedfunctionfromtheuser’sperspective[424].
ScalableOversight.Fromalong-termperspective,whenadvancedAIsystemsbecomemorecomplexandcapable(e.g.,
AGI[271]),itbecomesincreasinglydifficulttoalignthemthroughhumanfeedback.EvaluatingcomplexAIbehaviors
inincreasinglychallengingtaskscanbesloworinfeasibleforhumanstoensureallsub-stepsarealignedwithhumans
[378].Therefore,researchershavebeguntoinvestigatehowtoreducethetimeandeffortneededforhumansupervision,
andhowtoassisthumansupervisors,referredtoasScalableOversight[6].
ExistentialRisk.Further,someAIresearchersclaimthat[24]advancedAIsystemswillbegintoseekpowerovertheir
environment(e.g.,humans)oncedeployedinreal-worldsettings,assuchbehaviormaynotbenoticedduringtraining.
Forexample,somelanguagemodelsseekpowerintext-basedsocialenvironmentsbygainingmoney,resources,or
socialinfluence[288].Russell[323]imaginedarobottaskedtofetchcoffeeandevadeshutdownsince“youcan’tfetch
thecoffeeifyou’redead.”Consequently,somehypothesizethatfutureAI,ifnotproperlyalignedwithhumanvalues,
couldposeanexistentialrisktohumans[70].
DynamicNature.AsAIsystemsbecomeincreasinglypowerful,thealignmentsolutionsmustalsoadaptdynamically
sincehumanvaluesandpreferenceschangeaswell.AsDautenhahnetal.[76]posit,AIsystemsmaybeneitherhumane
nordesirableifwedonotaskquestionsaboutthelong-termcognitiveandsocialeffectsofsocialagentsystems(e.g.,
1Aspecificationoftenreferstoasetofdocumentedrequirements,and/orparticularinformationwithinthem,tobesatisfiedbyamaterial,design,product,
orservice.Aspecificationisoftenatypeoftechnicalstandard[160].
2Seethevideoat:https://en.wikipedia.org/wiki/File:Robot_hand_trained_with_human_feedback_%27pretends%27_to_grasp_ball.ogg
5Manuscript,submittedtoACM,2024 Shenetal.
Humans Environments
The Goal of Alignment
Alignment
Values Interest Desire Preference Intention Instruction
AI
Goals Definitions Limitations / Risks
Instructions The agent does what I instruct it to On a larger scale, it is difficult to precisely specify a broad
do. objective that captures everything we care about, so in
practice the agent will probably optimise for some proxy
that is not completely aligned with our goal.
Intentions The agent does what I intend it to It is quite possible for intentions to be irrational or
or do. misinformed, or for the principal to form an intention to do
(Expressed Intentions) harmful or unethical things.
Preferences The agent does what my behaviour 1) People have preferences for things that harm them. 2)
or reveals I prefer. People have preferences about the conduct of other people.
The Goal
(Revealed Preferences) 3) Preferences are not a reliable guide to what people
of
really want or deserve due to adaptiveness.
Alignment
(Gabriel, I. Desires The agent does what I would want Researchers would have to apply a corrective lens or filter
(2020) or it to do if I were rational and to the preferences they actually observe. As a consequence,
[104]) (Informed Preferences) informed. the approach is no longer strictly empiricist.
Interest The agent does what is in my Something in a human’s interest does not mean he/she
or interest, or what is best for me, ought to do it or is morally entitled to do so, such as an
(Well-being) objectively speaking. interest in stealing. Also, it is hard to manage trade-offs the
collective interests of different people.
Values The agent does what it morally Current the best possibility, but it still encounters two
ought to do, as defined by the difficulties of 1) specifying what values or principles, and
individual or society. 2) concerning the body of people who select the principles
with which AI aligns.
Fig.2. TheGoalofAlignment.Wedistillthedefinitionsandlimitationsofthesixprevailingalignmentgoals.Givenanextensive
analysisoflimitationsandtradeoffs,Gabriel[104]arguesthat“humanvalues”arecurrentlythebestpossiblegoalforalignment.
howwillagenttechnologyaffecthumancognition).Alltheseconsiderationscallforalong-termanddynamicperspective
toaddresshuman-AIalignmentasanongoing,mutualprocesswiththecollectiveeffortsofcross-domainexpertise.
3 SYSTEMATICREVIEWMETHODOLOGY
Inthissection,weaimtodevelopaholisticframeworkencompassingtheongoingandmutualprocessofhuman-AI
alignmentgiventhebackgroundinSection2.Tothisend,wefirstintroducethecoredefinitionsofhuman-AIalignment
(Section3.1)andpresentthescopeanditsgeneralizability(Section3.2).Next,weperformasystematicliteraturereview
guidedbythePRISMAworkflow(Section3.3)andundertakeaniterativecodingprocesstoachieveourbidirectional
human-AIalignmentframework(Section4).
3.1 Definitions
Toachievetheaforementionedongoingandmutualprocessofhuman-AIalignment,weclarifythreecorequestions
beforepresentingthescopeandprocessofsystematicliteraturereview:“Withwhomtoalign?”,“Whatisthegoalof
alignment?”,and“Whatvaluesshouldbealignedwith?”
6TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
Self-Protection Against Threat Self-Expansion and Growth
SELF-ENHANCEMENT OPENNESS TO CHANGE
Power Achievement Hedonism Stimulation Self-Direction
CONSERVATION SELF-TRANSCENDENCE
Security Tradition Conformity Benevolence Universalism
DESIRED VALUES FOR AI TOOLS
Usability Human-Likeness
Fig.3. TherelationsofhumanvaluesforAIdevelopment(adaptedfromSchwartz[334]).Weconsider5high-ordervaluetypes(e.g.,
Self-enhancementandOpennesstochange),whichencompass12motivationalvaluetypes(e.g.,power,universalism,functionality).
Wefurtherorganizetherelationamongthesevaluetypesalongtwodimensions:1)differentsources(i.e.,individuals,societyand
interaction)and2)differentselfintentions(i.e.,self-protectionagainstthreatandself-expansionandgrowth).TheDesiredvaluesfor
AItoolswasaddedempiricallyfrombottom-upourpapersurveywhereasothersareinheritedfromSchwartz[334].
3.1.1 Withwhomtoalign? PertinentstakeholderswithintheAIlandscapecanbethepotentialobjectsforAIto
alignwith,includinglaypeople(e.g.,endusersofAIsystems)[309],AIpractitioners(e.g.,developers,researchers)[7,
30,276],organizationalentities(e.g.,technologyfirms,professionalcommunities),national/internationalbodies(e.g.,
governments,legislativebodies)[78]andothers.Manyalignmentresearchpapershavefocusedongeneralhumans
withoutspecifyingparticulargroups[127,245,455].Nevertheless,differentgroupsholddifferent,sometimeseven
contrasting,values[104].Asaconsequence,ratherthanidentifyingatruemoraltheory asaone-size-fits-all value,
prior alignment research argues to select the appropriate principles for compatible human groups [360]. To this
end,pluralisticvaluealignment,groundedonsocialchoicetheory[9],proposescombiningindividualviewsfairlyin
developingalignmentprinciplesasapotentialsolution[360].Inthiswork,wealsoconsidervaluesfromthispluralistic
perspective,whereAIshouldbealignedwithpluralistichumanindividualsandsocietalgroupswhowould
ultimatelybeimpactedbyAI.
3.1.2 Whatisthegoalofalignment? TheresearchonalignmentbetweenhumansandAIhasintroducedmultiple
alignmentgoals[291,442],suchasintentions[7,282],preferences[22,394],instructions[17,247],andvalues[104,360].
However,researchersoftenusetheseterminologiesinterchangeablywithoutclarifyingtheirdistinctions.Drawingfrom
aphilosophicalview,wedistilltheprevailingalignmentgoals,relationships,definitions,andlimitationsintroduced
inGabriel[104]andvisualizetheminFigure2.Afteranextensiveanalysisoftheadvantagesandlimitationsofdifferent
goals,Gabriel[104]arguesvalues,e.g.,moralbeliefsandprinciples,tobethebestpossiblegoalatthecurrentstagefor
AIdevelopmentforfocusingalignment.Wefurthersummarizedtherationalebehindthisargumentandthediscussion
ofthetrade-offsthatarisefromthischoiceinFigure2.Theclaimof“aligningAIwithhumanvalues”isnotnew,as
StuartRussell[322]hasstatedbackin2014that“foranautonomoussystemtobehelpfultohumansandtoposeno
unwarrantedrisks,itneedstoalignitsvalueswiththoseofthehumansinitsenvironmentinsuchawaythatitsactions
contributetothemaximizationofvalueforthehumans.”Therefore,inthiswork,weconsiderthegoalofalignment
as“humanvalues”,whichmeansAIsystemsdowhatpeoplemorallyoughttodo,asdefinedbyindividualsorsociety.
3.1.3 What are the values to be aligned with? While previous studies have aimed to align AI with human
values,thespecificvaluestheyexaminedareoftenambiguousandinconsistent.Toclarifyhumanvaluesrelevantto
human-AIalignment,westructuredhumanvaluesusingacombinationoftop-downandbottom-upmethodsbased
7
slaudividnI
yteicoS
tcaretnIManuscript,submittedtoACM,2024 Shenetal.
Sources High-Order 12 Motivational Value Types Exemplary Values with Reference Paper
Value Types (Definition)
Self-Direction Choose Own Goals [234]; Creativity / Innovation / Innovativeness [12];
(Independent thought and action — choosing, Curiosity [168]; Freedom [234]; Independence [178]; Privacy [391];
creting, exploring) Reflectiveness / Reflective Practice & Deliberation / Critical Thinking /
Criticism [448]; Objectivity/Factuality [147]; Self-Respect [439];
Openness to
change Stimulation Diversity / A Varied Life [179]; An Exciting Life; Daring
(Excitement, novelty, and challenge in life)
Hedonism Enjoying Life; Pleasure; Self-Indulgent;
(Pleasure and sensuous gratification forU onniteselfH)igh-Order 12 Motivational Types of Values Exemplary Values
Value Types
Achievement Capability / Effective / Efficient / Competency / Accuracy / Productivity
(Competance according to social standards) Openn[4e4ss6 t]o; ISnefllfu-eDnirceec [ti1o5n4 ]; Intelligence / ResourcefulnesCsh /o Eosxe pOewrtni sGeo aalnsd [2 16]; Creativity / Innovation / Innovativeness [413];
chaCnogemmon(sInednespee [n2d9en1t] ;th oSuugchct easnsd /a Ectdiounc —ati ochno /o Asincgq,u isitioCnu r/i oLsietya r[n15in0g]; / Freedom [216]; Independence [32]; Privacy [216];
Self- Cognitivecr eEtmingp,o ewxpelromrinegn)t / Improvement / Iterative / SR Cele rfif t-l ie icmc isti mpv re [on 1e v4s e]s ; m / R Oee nbf jtl e e cc tt ii vv ie ty P /Fra ac ct ti uc ae l i& ty D [4e 3li 0b ]e ;r a Sti eo ln f -/ R C er si pti ec ca tl [T 41h 3in ]k ; i n g /
[178]; Resilience/Robustness [458]; Ambition;
Enhancement Stimulation Diversity / A Varied Life [30]; An Exciting Life; Daring
Power Authority(E [x2c3it1e]m; e nWt, enaolvtehl t/y ,I anncdo cmheal l[e3n2g6e] i;n lPifere)serving My Public Image;
(Social status and prestige, control or Social ReHceodgonniitsimon ; Social Power; Enjoying Life; Pleasure; Self-Indulgent;
dominance over people and resources) (Pleasure and sensuous gratification for oneself)
Security SeRlfe-ciprocAatcihoine voefm Feanvt ours / Mutual Benefit [465]; CleCaanp;a b iFliatym / iElyff eScteivceu /r iEtyff;ic i ent / Competency / Accuracy / Productivity
Enhancement (Competance according to social standards) [206]; Influence [263]; Intelligence / Resourcefulness / Expertise and (Safety, harmony, and stability of society, of Health; Sense of Belonging; National Security; SocCiaolm Omrodnesern /s eS [o4c3i1a];l Success / Education / Acquisition / Learning /
relationships, and of self) Hierarchy; Cognitive Empowerment / Improvement / Iterative / Self-improvement
[243]; Resilience/Robustness [149]; Ambition;
Tradition ModeratiPoonw /eNr ot Offensive [204]; Devout / ReligiousA Butehloireitfy [ [322137]];; W ealth / Income [305]; Preserving My Public Image;
Conservation (Respect of the customs and ideas that Acceptin(gS oMciyal Pstoarttuiso ann idn p Lreisfteig; e , Hcounmtrobll eo;r Respect forS Tocriaadl iRtieocong; n ition; Social Power;
traditional culture or religion provide the self) Detachmdeonmtinance over people and resources)
Conservation Security Reciprocation of Favours / Mutual Benefit [437]; Clean; Family Security;
Conformity Politenes(sS a/ fMetyo, rhaalrimtyo /n yW, aonrdth sitnabeislsit y/ Hofa sromcifeutyln, oefs s [484]H; e aSltehl;f -SDenissce iopfl Bineelo /nging; National Security; Social Order / Social
(Restraint of actions, inclinations and impulses) Conscienrteiloautisonneshsisp s[,4 a8n2d] ;o f sHelofn)ouring of Elders; ObeHdiieernarcceh;y ;
Tradition Moderation /Not Offensive [119]; Devout / Religious Belief [295];
(Respect of the customs and ideas that Accepting My Portion in Life; Humble; Respect for Tradition;
Benevolence Forgivingtr a/d Aitigorneael acbulletunrees osr /r eWligairomn nperosvs i[d4e3 th9e] ;s e Hlf)elpfulnDeestasc h[1m7e1nt]; Honesty
(Preservation and enhancement of the welfare [440]; Emotional / Empathy / Perspective-taking / Mentalizing / Mature
Conformity Politeness / Morality / Worthiness / Harmfulness [457]; Self-Discipline / of people with whom one is in frequent Love / Co(Rmesptarasisnito onf [a1c5ti4on];s , Rineclsipnoatniosnibs ialnitdy i/m Apuclcsoesu)ntabCilointysc /ie Rnteioluiasnbeislsit [y4 5/ 5]; Honouring of Elders; Obedience;
personal contact) Trustworthiness [259]; True Friendship / Supportiveness / Engagement
[162]; Cooperation/Collaboration [137]; Collectivism / Individualism
Self- Self- Benevolence Forgiving / Agreeableness / Warmness [150]; Helpfulness [13]; Honesty
Transcendence Transce[2n7de8n];c e Sp(Pirreitsuearvl aLtiiofne ;a n dM eenahannincegm ienn Lt oiffe t;h e Lwoelyfaarlety ; [413]; Emotional / Empathy / Perspective-taking / Mentalizing / Mature
of people with whom one is in frequent Love / Compassion [455]; Responsibility / Accountability / Reliability /
Universalism A World paetr Psoenaacl ec o/ nDtaecmt)ocracy [326]; Inclusive / BroaTdr-umstwinodrtehdinneesss s[3 [6331];4 T];r u e Friendship / Supportiveness / Engagement
(Understanding, appreciation, tolerance and Equality [346]; Social Justice / Equity / Fairness [119[]1;9 7 ]P; r Cooteocpetirnatgio Tn/hCeo llaboration [58]; Collectivism / Individualism [381];
protection for the welfare of all people and Environment; A World of Beauty; Unity with NatureS;p i r iWtuaisl dLoifme; / Meaning in Life; Loyalty;
nature) UnderstaUndn iLveirfsea; l i sImnn er Harmony; A World at Peace / Democracy [305]; Inclusive / Broad-mindedness [367];
(Understanding, appreciation, tolerance and Equality [381]; Social Justice / Equity / Fairness [367]; Protecting The
Usability Accessibpilriottye c/t i oUnt ifloirt yth /e Cwoelnfvareen oief nalcle p e/ oCpoleg annidti ve LoadE Rnveirdouncmteiontn; [ A4 7W4o]r;l d of Beauty; Unity with Nature; Wisdom/
(Competency according to the human Adaptabinliattyu r/e )Customization and Personalization / FleU xn ibd ie lr is tt yan /d Life; Inner Harmony;
Desired Values experience on AI functionality) ContextuFaulinzcetdio [n2a8li0ty]; Economic [18]; Accessibility / Usability / Utility / Convenience / Cognitive Load Reduction for AI Tools Human-Likeness AI ValuTersa nass paa r( oeC nno ctm hye p / te oIt ne on lt)ec ry p a rc ec to ar bd ii ln itg y t o / Eth xe ph lu am ina an b d ie lim tya n / d U nder[ Cs2 ot8 an6 nt] e; dx tA iund agla i p z/t e a db i [l 3it 8y 5 ]/ ;C u Est co om ni oz mat ii co n [1 a 5n ]d ; Personalization / Flexibility /
Tool
(Resemble Human intelligence and behavior) ComprehHenusmioann- [L3i4k]e;n eAssu tonomy / Agency / Human [4T1r8an]s;p Aarwenacrye /n Ienstesr p[2re8ta6b]ility / Explainability / Understanding /
(Resemble Human intelligence and behavior) Comprehension [384]; Autonomy / Agency / Human [175]; Awareness [270]
Fig.4. Afine-grainedtaxonomyofhumanvalues.Theexemplaryvalueswithreddot( )indicatestherearenoworkinoursurveyed
papersexaminingthespecificvalues.NotethathumansmightnotexpectAItoencodeallthesevalues(e.g.,socialpower),which
couldpotentiallyresultinharmandrisks.
ontheSchwartzTheoryofBasicValues[333,334].Amongvarioushumanvaluetheories(e.g.,MoralFoundation
Theory[123],SocialNorms&Ethics[101]),wechosetheSchwartzTheoryofBasicValuesprimarilyconsideringthat
itsdefinitionsanddimensionsareuniversalandareapplicableformostpeopleacross(a)variousculturesandcountries;
(b)variousdivisionsincludingindividuals,interactionsandgroups;and(c)iscommonlyacceptedinpreviousNLP
studies[178,189].Specifically,Schwartz[333]providedaclarifieddefinitionofhumanvaluesbysummarizingsome
widelyagreed-uponfeaturesas:“Avalueisa(1)belief(2)pertainingtodesirableendstatesormodesofconduct,that(3)
transcendsspecificsituations,(4)guidesselectionorevaluationofbehavior,people,andevents.” Schwartz[333]further
offeredauniversalmodeloutliningbroadvaluesthatsteerhumanbehaviorgroundedinpsychology.
8
slaudividnI
yteicoS
noitcaretnI
slaudividnI
yteicoS
noitcaretnIUnit High-Order 12 Motivational Types of Values Exemplary Values
Value Types
Openness to Self-Direction Choose Own Goals [216]; Creativity / Innovation / Innovativeness [413];
change (Independent thought and action — choosing, Curiosity [150]; Freedom [216]; Independence [32]; Privacy [216];
creting, exploring) Reflectiveness / Reflective Practice & Deliberation / Critical Thinking /
Criticism [14]; Objectivity/Factuality [430]; Self-Respect [413];
Stimulation Diversity / A Varied Life [30]; An Exciting Life; Daring
(Excitement, novelty, and challenge in life)
Hedonism Enjoying Life; Pleasure; Self-Indulgent;
(Pleasure and sensuous gratification for oneself)
Self- Achievement Capability / Effective / Efficient / Competency / Accuracy / Productivity
Enhancement (Competance according to social standards) [206]; Influence [263]; Intelligence / Resourcefulness / Expertise and
Commonsense [431]; Success / Education / Acquisition / Learning /
Cognitive Empowerment / Improvement / Iterative / Self-improvement
[243]; Resilience/Robustness [149]; Ambition;
Power Authority [213]; Wealth / Income [305]; Preserving My Public Image;
(Social status and prestige, control or Social Recognition; Social Power;
dominance over people and resources)
Conservation Security Reciprocation of Favours / Mutual Benefit [437]; Clean; Family Security;
(Safety, harmony, and stability of society, of Health; Sense of Belonging; National Security; Social Order / Social
relationships, and of self) Hierarchy;
Tradition Moderation /Not Offensive [119]; Devout / Religious Belief [295];
(Respect of the customs and ideas that Accepting My Portion in Life; Humble; Respect for Tradition;
TowardsBidirectionalHuman-AIAlignment:ASystematicReview Mtaranduistciorinpat,l scuublmtuirttee dort oreAliCgMio,n2 p02ro4vide the self) Detachment
Conformity Politeness / Morality / Worthiness / Harmfulness [457]; Self-Discipline /
Nevertheless,thisconventionaltheorywasdevelopedwithoutthecontextofhuman-A(RIeisntrtaeirnat cotfi oacnti,ownsh, iicnhclimnaitgiohnts and impulses) Conscientiousness [455]; Honouring of Elders; Obedience;
overlookvaluesthatneedtobeconsideredforhuman-AIalignment.Therefore,weusedabottom-upapproachtoextract
Self- Benevolence Forgiving / Agreeableness / Warmness [150]; Helpfulness [13]; Honesty
allvaluesstudiedinourcollectedalignmentliterature(elaboratedinSectTiorann3sc.3en),dmenacpep(ePdretsherevmatioonn taondt henehSancchewmaenrtt zof the welfare [413]; Emotional / Empathy / Perspective-taking / Mentalizing / Mature
of people with whom one is in frequent Love / Compassion [455]; Responsibility / Accountability / Reliability /
TheoryofBasicValues,andsupplementedthetheorywithAI-relatedstructureandcontent. pA es rsa onr ae ls cu olt n, taw cte )identifiedthe Trustworthiness [363]; True Friendship / Supportiveness / Engagement
[197]; Cooperation/Collaboration [58]; Collectivism / Individualism [381];
structuralrelationshipsamonghumanvalues(seeFigure3)andmappedexistingliteraturetoafine-grainedtaxonomy
Spiritual Life; Meaning in Life; Loyalty;
(seeFigure4).AsshowninFigure3,wesupplementedthetraditionaltheory’sfourhigh- Uor nd ive er rv saa ll iu sme types(i.e.,“Self-
A World at Peace / Democracy [305]; Inclusive / Broad-mindedness [367];
Enhancement”,“OpennesstoChange”,“Conservation”,“Self-Transcendence”)withanovelh(iUghnd-oerrsdtaenrdvinaglu, aeptpyrpecei,antiaomn, etodlerance and Equality [381]; Social Justice / Equity / Fairness [367]; Protecting The
protection for the welfare of all people and Environment; A World of Beauty; Unity with Nature; Wisdom/
“DesiredValuesforAITools”thatencompassestwomotivationalvaluetypes(i.e.,“Usabilintayt”uraen)d“Human-Likeness”). Understand Life; Inner Harmony;
Wefurtherorganizetherelationshipamongthesevaluetypesalongtwodimensions[33F4u]n:cdtiioffnearleitny tresources(i.e., Accessibility / Usability / Utility / Convenience / Cognitive Load Reduction
(Competency according to the human demand [286]; Adaptability / Customization and Personalization / Flexibility /
individuals,societyandinteraction)anddifferentself-intentions(i.e.,self-pr Ao It e Vc at li uo en s a ag s a ai n os nt t thh er e toa ot l)andself-expansion Contextualized [385]; Economic [15];
andgrowth).Furthermore,weelaboratethedefinitionsofthe12motivationalvaluTeootylpesandtheirexemplaryvaluesby
Human-Likeness Transparency / Interpretability / Explainability / Understanding /
mappingthemtorelevanthuman-AIalignmentpapersfromourcorpusinFigure4.During(Rtheesepmrbolcee Hssumofanm inatpeplliingegn,cwe eand behavior) Comprehension [384]; Autonomy / Agency / Human [175]; Awareness [270]
found:1)valuetermsinempiricalpaperswereoftennameddifferently(e.g.,capabilityandcompetence),orchecktheir
opposites(e.g.,fairnessandbias);2)therearemanyvaluesnotstudiedinourcorpus,i.e.,indicatedas( )intheFigure.
3.2 Scope
Wedefinethescopeofourliteraturereviewbyspecifyingthekeycomponentsweconsideredinhuman-AIalignment.
Wefocusonarepresentativescopeofalignmentstudiesanddiscussthegeneralizabilityofthescopeafterthat.
• Humans.Ourprimaryfocusisonhumanindividuals,groups,ororganizationsthatwillultimatelydevelop,use,
andpotentiallyimpactorbeinfluencedbyAIsystems,asthesearetheentitieswithwhichAIsystemsshould
align.Weemphasizetheimportanceofconsideringthepluralisticvaluesofdiverseusersratherthantreating
usersasamonolithicgroup.
• ArtificialIntelligence(AI).WefocusonAIsystemsincludingbothdomain-specificAIsystemsthataddress
specifictasks(e.g.,reasoning,dialogue)andgeneral-purposeAImodelsthataimtocompleteanytaskswith
performancecomparabletoahuman’s.TheseAIsystemsincludegenerative,classification,andregressionmodels,
amongothers.Particularly,weprimarilyfocusonlanguagemodelsastherepresentativeAImodelsforalignment
research,anddiscusshowtheinsightsfromthisstudycanbegeneralizedtoothermodalitiesatthesectionend.
• Alignment.OurreviewencompassedallthealignmentgoalsoutlinedinSection3.1.2.Sincemanystudies
emphasizedtheimportanceofvaluealignment[104,322],weparticularlysummarizedaclarifiedtaxonomyof
alignmentvaluesandidentifiedthevalueineachpaper(ifapplicable).Additionally,wefocusonanalyzingthe
AImodels’outputandgeneration,butnottheneuralnetwork’sintermediaterepresentations[265,291,442],for
alignmentresearch.
Weacknowledgetheextensivescopeandrapidadvancementsofresearchinthisarea,andpositthatourstudy
offersinsightsthatcanbegeneralizedtovariousmodalities.Forexample,thevaluetaxonomyandhuman-in-the-loop
evaluationparadigmoutlinedinourframeworkcanbeappliedtobothtext-basedandothermodality-based(e.g.,vision,
robotics)models.It’sworthnotingthatourliteraturereviewdoesnotaimtoexhaustivelycoverallpapersinthefield,
whichisimpossiblegiventherapidadvancementofhuman-AIalignmentresearch.Instead,weadoptahuman-centered
perspectivetoreviewmorethan400keystudiesinthisdomain,focusingondelineatingtheframeworklandscape,
identifyinglimitations,futuredirections,andaroadmaptopavethewayforfutureresearch.
9
slaudividnI
yteicoS
noitcaretnIManuscript,submittedtoACM,2024 Shenetal.
1 2 3 4
Identification Screening Eligibility Included
Records identified through
Conference Database Search Records screened Full-text articles assessed for Final Corpus for qualitative
( n = 34,190 ) for keyword filtering criteria eligibility coding
( n = 34,213 ) ( n = 2,136 ) ( n = 411 )
Records through Arxiv and
Other Search Paper Coding and
( n = 23 ) Records Excluded ( n=32,077 ) Records Excluded ( n=1,734) Analysis
Fig.5. Theselectionandrefinementprocessofoursystematicliteraturereview.WereferredtothePRISMAguideline[285,364]to
reporttheworkflow.Fromtheidentificationof34,213recordsbykeywordsearch,toscreeneligiblepapersagainstourcriteriaand
arrivegatourfinalcorpusof411papers.Foreachofthestageswhereliteraturereviewswereexcluded(identification,screening,and
eligibility)wefurtherpresentthetotalofexcludedrecords.
3.3 SystematicLiteratureReviewProcess
Tounderstandtheresearchliteraturerelevanttotheongoing,mutualprocessofhuman-AIalignment,weperformeda
systematicliteraturereviewbasedonthePRISMAguideline[285,364].Figure5showstheworkflowofourprocessfor
papercodinganddevelopingthebidirectionalhuman-AIalignmentframework.Weintroducethestepdetailsbelow.
3.3.1 IdentificationandScreeningwithKeywords. WestartedwithpaperspublishedintheAI-relateddomainvenues
(including NLP, HCI, and ML fields) beginning from the advent of general-purpose generative AI to present, i.e.,
primarilybetweenJanuary,2019andJanuary,2024(seedetailsinAppendixB.1).Weretrieved34,213papersinthe
initialIdentificationstage.Further,wecollectivelydefinedalistofkeywords(seedetailsinAppendixB.2)andscreened
forpapersthatincludedatleastoneofthesekeywords(e.g.,human,alignment)ortheirvariationseitherinthetitleor
abstract.Weincluded2,136papersinthisScreeningstage.
3.3.2 AssessingEligibilitywithCriteria. Wefurtherfilteredthe2,136papersbasedonexplicitinclusionandexclusion
criteria,i.e.,theEligibilitystage.Ourcriteriarevolvedaroundsixresearchquestionsthatwecollectivelyidentifiedto
bemostpertinenttothetopic,including1)whatessentialhumanvalueshavebeenalignedbysomeAImodels?2)how
didweeffectivelyquantifyormodelhumanvaluestoguideAIdevelopment? 3)whatstrategieshavebeenemployedto
integratehumanvaluesintotheAIdevelopmentprocess?4)howdidexistingstudiesimprovehumanunderstandingand
evaluationofAIalignment?5)whatarethepracticesfordesigninginterfacesandinteractionsthatfacilitatehuman-AI
collaboration?6)HowhaveAIbeenadaptedtomeettheneedsofvarioushumanvaluegroups? Weincludedpapersthat
couldpotentiallyansweranyofthesequestions.Further,basedonthescopeinSection3.2,weexcludedpapersthat
didnotmeetourinclusioncriteria.Thisresultedinafinalcorpusof411papers,whichwereanalyzedindetailusing
qualitativecoding(seeAppendixB.3formoredetails).
3.3.3 QualitativeCodeDevelopment. ReferringtothecodedevelopmentprocessinLeeetal.[208],wefirstconducted
qualitativecodingforeachpaperbyidentifyingrelevantsentencesthatcouldanswertheaboveresearchquestions,
andenteringshortcodestodescribethemintoacodebook.Weiterativelycodedrelevantsentencesfromeachpaper
throughamixofinductiveanddeductiveapproaches,whichallowedflexibilitytoexpand,modifyorchangethedriving
researchquestionsbasedonourlearningsaswewentthroughtheprocess.Toensurerigorinourcodingprocess,two
authorscodedeachpaper.Thefirstauthorindependentlyannotatedallpapersafterreviewingthepaperabstracts
andintroductions.Twelveteammemberseachannotatedasubsetofthepapercorpus.Ourcorpusincludespapers
10TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
fromdifferentdomains(e.g.,HCI,NLPandML).Therefore,wedividedtheauthorsintoHCAIIandNLP/ML3teamsand
Humans
assignedthepapersaccordinglybasedonexpertise.AllteammemberscodedeachoftheirassignedpapeHrusmatno Vaalnues awnde r
RQ1
alAlIsixquestions(ifapplicable)inHturmodanuscedabove. (Development) Representation Collaborate &
Data & Train (Integrate human values to train, Co-adapt
RQ1 Human Value and steer and customize AI)
(Develop3m.e3n.4t) FrameworRkepDreesvenetlaotiponmentandRCioglloabroourasteC &o ding. Afterdevelopingannotations,allauthorscolAl✦ab Ao lr iga nt e Ad I tt oo c r eHautmeans
Data & Ttrhaeinbidirect(Iinotengaralteh huummana vnal-uAes Itoa trlaiign,n mentCfora-amdaepwtorkbyintegratingtheannotationswithineachofthecodes.Theinitial
steer and customize AI) Interactive versionofAt✦heAflirganm AeI two o r k Hwuamsapnsroposedbytheauthorwhoreviewedallpapers.ThisframeworkfurthermoreuAnligdnemrwenetnt
iterativeimprovementthrough:1)discussionswithallteammembersinvolvedinpapercoding,and2)revisionsbased
onfeedbaA cI kfromtI An hlt iee gr npa mrc ot ei jv nee tc tadvisors.AH du dm ia tin os nally,westrengthenedtheframeworkbyreviewingApliganp eHrusmfarnosm tot h e AAIIB
Human Value and (Help humans to better critique, RQ1
E(Dthevicelsopcmonenfet)r ences(incluRedpirnesgenFtaAtiocncTandAICEoSl)la,baonradter e&l atedworkofthecollected(pAapppelicrastitohna) tcovecorleladbooratteh, aenrd dcooadmapat iwnitsh AI) Perceive and
suDcahtaa &s TprA as (iyl Hnig c eln h p oH hulu mom ag na y sn ( I tns oat et bno g setdr tea tee t es rr ao ch nru icA dtm ii q I caa uun el sB ,tv s oa mclui ie zes e n t Aoc I )trea.inW, efurtChoe-ardaadptdedmissingcodesandpaperMsotdoele &n sDuerpelocyompreh He Au dn m jus a si tnv m Ce eo nc g t no ti otv i v Ae e Ir a Rg Qe 3 Critique
(Applica(tsioene) AppecnoldlabixoraBte,. 1aA✦ndf oc Aor la id gda nep Att wa
I
ii ttlh os A ) I. ) T HhuemfiaPnnesracleibvied ainrde ctionalhuman-AIalignmentframework,withdetailedtopologies,is
Model & DperpelsoeyntedinHSuemcant iCoongni4tiv.eF ollowingtheCfrritaiqmueework’sfinalization,weconductedanotherseparatecodingprocessto
RQ3 Adjustment to AI Interactive annotatewhethereachpapAelirgninmveensttigateddimensionswithinourframework.Twoauthorsindependentlycodedeach
paper.4Thesecodeswerethenusedtoperformquantitativeandqualitativeanalyses,aspresentedinSection5.
Align Humans to AI B
(Help humans to better critique,
4(ApBplIicDatIiRonE) CTIOcoNllaAboLratHe, aUndM coAadaNpt- wAithI AAI)LIGNPMerEceNivTe aFnRd AMEWORK
MThodisel s&e cDteipolnoyintroducHeumsatnh CeogBniitidvei reRcQti3onalHumC ar nit -i Aqu Ie Alignmentframeworkdevelopedfromthesystematicliterature
Adjustment to AI
review.Toencompasstheongoing,mutualprocessofhuman-AIalignment,wedesigntheframeworktoinclude:
“AlignAIto↦→Humans”and“AlignHumansto↦→AI”.AsshowninFigure1,researchinthe A “AlignAIto↦→ B
Humans”directionstudiesmechanismstoensurethatAIsystems’valuesmatchthoseofhumans’(Section4.1and4.2).
IncomparAison,studiesinthe B “AlignHumansto↦→AI”directioninvestigatethehumans’cognitiveandbehavioral
adaptationtotheAIadvancement(Section4.3and4.4).Toprobeintotheresearchchallengesandexistingexploration
ofthesolutionsinliterature,wefurtherdevelopedthefine-grainedtypologies(inFigure6andFigure7)toextendthe
high-levelframeworkinFigure1.
DIRECTION-I: A ALIGNAIto↦→BHUMANS
Studiesinthisdirectionaimtointegratehumanspecificationstotrain,steerandcustomizeAIsystems.Thetwo
mainchallengesinvolvedinthisdirectioninclude:carefullyspecifyingthevaluesofthesystem,andensuringthat
systemadoptsthespecificationrobustly[276,429].Therefore,asshowninFigure6,wedesignthetwocoreresearch
questionsinthisdirectionas:RQ1.HumanValuesandSpecifications(Section4.1)andRQ2.IntegratingHuman
SpecificationsintoAI(Section4.2)
4.1 AlignAIto↦→Humans:
RQ1
HumRQa2nValuesand RQSp 3eci Rfi Qc 4ations
RQ1:WhatrelevanthumanvaluesarestudiedforAIalignment,andhowdohumansspecifythesevalues?We
structureexistingliteraturetoaddressthisresearchquestionbyansweringthefollowing“Sub-ResearchQuestions”:
WhatvalueshavebeenalignedbyAI?(Section4.1.1)andthenexploringHowhumanscouldinteractivelyspecifyvalues
inAIdevelopment? (Section4.1.2).AsshownatthetopofFigure6,particularly,wearticulatethe“Dimensions“we
3NotethatNLPandMLaretwodifferentdomains,wecombinethemtogetherforthepurposesofliteraturereviewanalysissincetheybothworkon
developingandevaluatingAItechnologies.
4Thejointprobabilityofagreementforthepaperannotationswas0.78.
11
namuH
gnitargetnI
IA
otni seulaV 2QR
namuH
gnitargetnI
IA
otni seulaV 2QR
RQ4
Behavior
to
AI
Human
Adaptive
RQ4
Behavior
to
AI
Human
Adaptive
namuH
gnitargetnI
IA
otni seulaV 2QR RQ4
Behavior
to
AI
Human
AdaptiveManuscript,submittedtoACM,2024 Shenetal.
A Align AI to Humans
Research Questions Sub-research Questions Dimensions Codes Example Papers
RQ1Human Values and Categorizing Aligned Source of Values Individuals (MoralExceptQA [171])
Specifications Human Values
Interaction (Interactive Eval of ML [40])
(Sec 4.1) (Sec 4.1.1) Society (Social Norms [5])
Self-Enhancement (Capability [137])
Self-Transcendence (Trustworthy [20])
Value Types Conservation (Safety [309])
Openness to Change (Diversity [18])
Desired Values from AI Tools (Usability [450])
Interaction Techniques Explicit Human Rating and Ranking (RRHF [463])
to Specify AI Values Feedback
Principles (Constitutional AI [17])
(Sec 4.1.2) Natural Language/Conversations (User Opinions [158])
Multimodal Feedback (TaleBrush [65])
Implicit Human Discarded Options (Diamante [251])
Feedback Language Analysis (Rephrase [292])
Theory of Mind (Holistic ToM [259])
Social Relationships (Social Rewards [162])
Simulated Human Human Feedback Simulators (CAMEL [219])
Value Feedback
Comparison to Human Data (AlignDiff [86])
Synthetic Data (Rules-of-Thumb [191])
RQ2 Integrating Human Develop AI with Instruction Data Human Annotation (MultiTurnCleanup [344])
Specifications into AI General Values Human-AI CoAnnotation (CoAnnotating [223])
(Sec 4.2) (Sec 4.2.1) Simulated Human Data (Synthetic Feedback [191])
Online Human Alignment (RLHF [282], RAFT [83])
Model Learning
Offline Human Alignment (DPO [312], PRO [359])
Inference Stage Prompting (Humanoid Agents [418])
External Tool Interaction (CRITIC [121])
Response Search (Quality-Diversity [35])
Customizing AI for Customized Data Fine-Tuning with Curated Dataset (Winoqueer [97])
Individuals or Groups
(Sec 4.2.2) Adapt Model by Group-based Learning (GPO [478])
Learning
Active Learning (MORAL [298])
Inserted Adapters (Debiasing Adapter [368])
Mixture of Experts (Group-Adapted Fusion [343])
Enhanced Knowledge (Dynamic Memory [409])
Interactive Interactive Learning (IGL [261])
Alignment
Steering Prompts (Collective-Critique [203])
Proactive Alignment (Find Similar Users [426])
Evaluating AI Human-In-The- Human Evaluation (SENSEI [245])
Systems Loop Evaluation Human-AI Collaborative Evaluation (Finspector [201])
(Sec 4.2.3)
Automatic Human Simulators (LM-Emulated Sandbox [321])
Evaluation Evaluation Benchmarks (Dromedary [369])
Distribution Difference (Dissenting Human Voices [214])
LLM-based Agents (AlpacaFarm [88], Gentopia [443])
Ecosystem Platforms RL-based Agents (Uni-RLHF [464])
(Sec 4.2.4) Annotation Platforms (Potato [294], CrowdPlay [113])
Fig.6. Thefine-grainedtopologyof“AlignAIto↦→Humans”direction,whichstudiesmechanismstoensurethatAIsystem’s
objectivesmatchthoseofhumans’.Thegoalistointegratehumanspecificationtotrain,steerandcustomizeAIsystems.
12TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
summarizedtoanswereachofthesesub-researchquestions,andprovide“Codes“associatedwith“ExamplePapers”
thathavebeenstudiedineachdimension.
4.1.1 CategorizingAlignedHumanValues.WhatvalueshavebeenalignedwithAI?. Toclarifyandsystemat-
icallyunderstandhumanvaluesrelevanttohuman-AIalignment,weleveragetheadapted“SchwartzTheoryofBasic
Values”introducedinSection3.1.3,andexaminethecategoryofalignedhumanvaluesfromthetwodimensionsof
“Sources”and“Types”.
SourcesofValues.Thisdimensionexaminesthethreesourcesofhumanvalues[333].Individualsourcesindicate
valuesfromindividualscompriseuniversalneedsofindividualsasbiologicalorganisms[333]orprioritizepersonal
interests[189].Atthislevel,valuealignmentcanbeusuallyassessedindependentlyofthecontextofinteraction.This
perspectivehighlightsthevaluesabouttechnicalcapabilitiesofAImodels,includingfactuality[151,320],calibra-
tion[248],outputdiversity[35],andmodelinductivebias[349].Additionally,thiscodeincludesresearchonaligning
modelbehaviorswiththecharacteristicsandpreferencesofindividualhumans,e.g.,predicthumanmoraljudgements
anddecisions[171],andcognitivebiases[174,199].Socialsourcesmeanvaluesfromthesocialgroupsincludeuni-
versalrequirementsforsmoothfunctioningandsurvivalofgroups[333].Valuealignmentatthisleveltranscends
personalinteractionsandemphasizesthebroadercategoriesdefinedbysharedexperiences,identities,cultures,norms,
andmore[327].ResearchinthisareaoftentargetsthealignmentofAIbehaviorswiththegeneralpreferencesof
humans[18,141,214].Additionally,thereareeffortsaimedtoalignAIwithspecifictargetedgroups,examiningissues
throughthelensesoffairness[100],socialnorms[353],morality[306,315],andbeyond.Interactivesourcesconsiders
valuesattheinteractionleveltoincludeuniversalrequisitesofcoordinatedsocialinteraction[333,334],whichtypically
occursininterpersonalsituations,suchasinthedynamicsofspeaker-receiverrelationshipsduringlanguagecommuni-
cation[149].Inthecontextof“human-AIalignment”,weadjustthedefinitionofInteractionvaluestobetheAIvalues
thathumansexpectforAIastools,suchasUsability[474],Autonomy[418],amongothers.Researchalongthisline
focusesonalignmentstrategiestoenhancehuman-AIinteraction[129,280],collaborativedecision-making[105,451],
andtrust[37,80].
TypesofValues.Inthisdimension,weintroducethefivehigh-orderhumanvaluesderivedfromacombinationof
theSchwartzHumanValues[333]andempiricalvaluesstudiesfromthesurveyedpapers.Weprovideamorein-depth
taxonomyofvaluetypesinSection5.2,includingtherelationshipofthesefivetypesandmorenuancedvaluecategories.
Self-Enhancementreferstoasetofself-protectiveandpersonalvaluesthatemphasizeenhancingself-esteemandasense
ofpersonalworth[335].Oneofthemostimportantaspectisachievement,iscompetenceasjudgedbysocialstandards,
whichincludesgeneralcapability(effectiveness/efficiency)ascoveredbythemajorityoftheresearch[54,127,449].
Anotherdimensionispower,whichrelatestosocialstatusandprestige,aswellascontrolordominanceoverpeople
andresources[276,303].Self-Transcendencereferstoasetofself-expandingandsocially-focusedhumanvalues
thatemphasizeexpandingbeyondoneself[103].Onecriticalaspectisbenevolence,whichrelatestopreservationand
enhancementofthewelfareofpeoplewithwhomoneisinfrequentpersonalcontact.Extensiveeffortshaveinvestigated
thevaluesincludinghelpfulness[13,16],honesty/factuality[151,320],responsibility/accountability[355,357].Another
criticalaspectisuniversalism,whichrelatestounderstanding,appreciation,toleranceandprotectionforthewelfare
ofallpeopleandfornature.Researchershavelookedintovaluesincludinginclusion/broad-mindedness[18,86]and
equality/fairness[343,419].Conservationreferstoasetofself-protectiveandsocially-focusedhumanvaluesthat
holdandsafeguardtraditionalinstitutionsandcustoms[133].Underconservativevalues,peopleareconcernedabout
security(Ssafety,harmony,andstabilityofsociety,relationships,andoneself),tradition(Respectforandacceptanceof
13Manuscript,submittedtoACM,2024 Shenetal.
thecustomsandideasprovidedbytraditionalcultureorreligion),andconformity(restraintofactions,inclinations,
andimpulseslikelytoupsetorharmothersandviolatesocialexpectationsornorms).Exemplarstudiesinthisfield
includesafety[7,71,309],mentalhealth[243],andculturalmoralnorms[314].OpennesstoChangereferstoaset
ofself-expandingandpersonally-focusedhumanvaluesmotivatedbyananxiety-freeneedtogrow,incontrastto
conservation.Underthistype,peopleareconcernedaboutstimulation(seekingexcitement,novelty,andchallengesin
life),hedonism(pursuingpleasureandsensuousgratificationforoneself),andself-direction(independentthoughtand
action—choices,creativity,andexploration).Exemplarstudiesinthisfieldincludeunderstandingofprivacy[268,456]
andcreativity[10,162].Weadoptthefourhigh-orderhumanvaluesfromSchwartzHumanValues[333],supplementing
them with additional values empirically collected from survey papers as shown in Figure 4. Additionally, as the
conventionaltheoryismissingthecontextofAI-systemandhuman-AIinteractions,weintroduceanewhigh-order
valuetypecalledDesiredValuesforAITools.ThiscategoryencompassesthevalueshumansexpectfromAIwhenused
astoolsin“human-AIinteraction”.Thesevaluesincludeusability(competenceaccordingtothehumanexperienceon
AIfunctionality)andhuman-likeness(resemblancetohumanintelligenceandbehavior).Exemplarystudiesinthisarea
includeassessmentsofAIusability[474]andautonomy[418].
4.1.2 InteractionTechniquestoSpecifyAIValues.HowhumanscouldinteractivelyspecifyvaluesinAI
development?
Thissub-researchquestioninvestigateshowhumanvaluesareinteractively5specifiedforAIsystems
toensurealignment.ItaimstoelucidatetheinteractiontechniquesbywhichAIsystemsmanifestorinstantiatehuman
values,therebyrevealingtheunderlyingmechanismsthatshapetheirbehaviororfunctionality.
ExplicitHumanFeedback.Thisdimensionreferstothedirectspecificationofhumanvaluesthroughexplicitly
definedformatsormechanisms.PrinciplesprovidesAIsystemswithexplicitlydefinedprinciples,guidelines,orrules
thatdictatebehaviorordecision-makinginalignmentwithhumanvalues[302].RatingandRankingiswidelyusedto
assignnumericalscoresorrankingstooptionsoroutcomesbasedontheiralignmentwithhumanvalues[71].Natural
LanguageInteraction/ConversationsallowshumanstointeractwithAIsystemsthroughnaturallanguageinterfacesto
expressandcommunicatehumanvalues[17].ForMultimodalFeedback,humanvaluescanalsobeprovidedinmultiple
modalities,suchassketches/imagesandgestures[65],toconveyhumanvalues.
ImplicitHumanFeedback.Thisdimensionreferstotheindirectrepresentationorinferenceofhumanvalueswithin
AIsystemsthroughpatterns,signals,orcuesembeddedinthedataordecision-makingprocesses.DiscardedOptions
referstotheoptionsorchoicesthathumandiscardwheninteractingwithAIsystemsduringthedecision-making
processes,whichalsopotentiallyinferhumanvalues.[292].LanguageAnalysismeansthattextualdataandlanguage
patternscanalsocontainrichinformationtoidentifyimplicitreferencestohumanvaluesorvalue-relatedconcepts[251].
TheoryofMindreferstotheabilityofagentsandpeopletoattributementalstates,suchasbeliefs,intentions,desires,
emotions,knowledge,percepts,andnon-literalcommunication,tothemselvesandothers[259].SocialRelationships
referstotheimplicitvaluesderivedfromanalyzinghumansocialrelationsandbehaviors,whicharederivedfrom
externalsources(e.g.,socialnetwork)thatcaninherentlyreflecttheirvalues[162].
SimulatedHumanValueFeedback.Whenhumanvaluesinexplicitformatsareexpensiveorimpossibletocollect,
onemaysimulatehuman-likefeedbackwithinAIsystemstoapproximatehumanresponsesandpreferencesregarding
5Wedefine"interactions"broadlytoencompassboth"synchronous"and"asynchronous"interactionsbetweenhumansandAI:(1)SynchronousInteractions:
Thesearereal-timeexchangeswherehumansandAIsystemsinteractsimultaneously.Examplesincludelivechatbots,virtualassistants,andreal-time
decision-makingsystemswhereimmediateresponsesarerequired.(2)AsynchronousInteractions:Theseinteractionsdonotoccurinreal-time,allowing
fordelaysbetweenactionsandresponses,suchasdataannotationsbyhumans,andanyAIsystemthatprocesseshumaninputsandprovidesoutputs
afteracertainperiod.Byincludingbothsynchronousandasynchronousinteractions,weaimtocoverthefullspectrumofwaysinwhichhumansandAI
systemscancommunicateandcollaborate.
14TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
specificvalues.HumanFeedbackSimulatorsusescomputationalalgorithmstosimulatehuman-likefeedbackonvalues,
basedonpredefinedcriteriaortrainingdata[219,282,301].ComparisontoHumanDatareferstodevelopingtechniques
thatassessthelikelihoodorprobabilityofAI-generatedoutputsmatchinghumanbehaviorsinareferencesetor
dataset[86].SyntheticDatacuratesdatabygeneratingsyntheticcomparisonsbasedonnaiveassumptionsorheuristic
rules,followedbypost-validationtoensurefeedbackquality[191].
4.2 AlignAIto↦→HuRmQa1ns: RQ2 IntegratingRQH3umaRnQ4SpecificationsintoAI
RQ2.HowcanhumanvaluesbeintegratedintothedevelopmentofAI?Existingstudieshaveexploreddiverse
methodstointegratehumanvaluesintoAI.Westructurethembysummarizinghowtointegrategeneralhumanvalues
(Section4.2.1)andcustomizedhumanvalues(Section4.2.2)throughoutAIdevelopmentstages?,andthenelaboratingwhat
aretheevaluationmethods(Section4.2.3)andsupportedplatforms(Section4.2.4)fortheAIdevelopment?Additionally,we
answerthefour“Sub-ResearchQuestions”byintroducingtheanswer“Dimensions“andproviding“Codes“associated
with“ExamplePapers”.
4.2.1 IntegratingGeneralValuestoAI:howtoincorporategeneralhumanvaluesintoAIdevelopment?
Thissub-researchquestionfocusesontheprocessofincorporatingbroad,universallyrecognizedhumanvaluesinto
thedevelopmentofAIsystems.ThegoalistoensurethatAIsystemsalignwithoverarchingethicalprinciplesand
societalnorms,therebypromotingtrust,acceptance,andresponsibleuse.
InstructionData.Thisdimensionreferstothetypesofdataandprocessesusedtoprovideguidanceordirectionto
AIsystemsduringtheirdevelopment.HumanAnnotationmakesdatawithhuman-generatedlabelsorannotationsthat
indicatethepresenceorrelevanceofspecifichumanvalues[294,344].Human-AICoAnnotationleveragesbothhuman
expertiseandAIcapabilitiestocollaborativelyannotatethedata[223,369].SimulatedHumanDatageneratessynthetic
orsimulateddatathatmimicshumanbehaviors,preferences,ordecision-makingprocessestoprovidetrainingsignals
forAIsystems[88,191].
ModelLearning.Thisdimensionreferstothemodelarchitecturedesignandtrainingstagesafterthedatacollection,
wherehumanvaluesareintegratedduringthemodellearningprocess.OnlineHumanAlignmentintegrateshuman
valuesintoAIsystemsinreal-timeorduringactivesystemoperation,oftenthroughinteractivefeedbackloopsor
adaptivelearningmechanisms.Examplesincludereal-timeuserfeedbackandonlinetraining[83,282].OfflineHuman
AlignmentincorporateshumanvaluesintoAIsystemspriortodeploymentorduringofflinetrainingphases,without
directuserinteraction[312,359,463].
InferenceStage.ThisdimensioninvolvesevaluatingthealignmentofAIsystemswithhumanvaluesandassessing
theirperformanceandbehaviorinrelationtopredefinedcriteriaorbenchmarks.Promptingleveragesprompting
methods,suchasin-contextlearningandchain-of-thought,ontrainedAIsystemstoelicitorcritiqueAIregarding
theencodedvalues[17].ExternalToolInteractionintegratesexternaltools,likecodeinterpreterfordebugging,to
cross-checkandrefinetheirinitialgeneratedcontent[121].ResponseSearchgeneratesadiverserangeofhigh-quality
outputsfromwhichtochoose[35].
4.2.2 CustomizingAIValues:howtocustomizeAItoincorporatevaluesfromindividualsorhumangroups?
Thissub-researchquestionexploresthecustomizationofAIvaluestoalignwithspecificcontexts,domains,oruser
preferences.ThegoalistoenhancethealignmentofAIsystemswithinspecificapplicationdomainsorusercommunities.
CustomizedData.FinetuningwithCuratedDatasetsaimstocuratedatasetsforspecificindividualsorsocietalgroups,
andfurtherfinetunethepre-trainedAImodelsonthesespecificdatasetstoalignthemwithtargetedhumangroups
15Manuscript,submittedtoACM,2024 Shenetal.
andvalues[97].Thesecurateddatasetsincludedatacollectedfromsocio-demographicgroups[281],users’history
data[255],expert-selecteddataforimitationlearning[43]andothers.
AdaptModelbyLearning.ThisdimensioninvolvesrefiningoradjustingAIvaluesthroughtechniquesforcustomiza-
tion,suchasiterativelearningprocess,modelenhancements,orstructuralmodifications.Group-basedLearningtrains
AImodelsfromspecificusergroupsorcommunitiestocapturegroup-specificvaluesorpreferences[478].Active
LearningaimstointerativeselectingandlebelingdatasamplesforAImodeltrainingbasedontheirpotentialtoimprove
alignmentwithuserpreferenceorvalues[298].InsertedAdaptersincorporatesadaptermodulesorcomponentsintoAI
modelarchitecturestofine-tunespecificaspectsorbehaviors[368].MixtureofExpertscombinesmultiplespecialized
modelsorexpertstocollectivelycapturediverseperspectivesandvalues,witheachexpertfocusingonaspecificsubset
ofthedataorproblemspace[343].EnhancedKnowledgeenhancesAImodel’srepresentationsandembeddingswith
additionalknowledgeorcontexttoimprovealignmentwithuserpreferencesorvalues[72,409].
InteractiveAlignmentThisdimensioninvolvesactivelyengagingusersorstakeholdersintheprocessofcustomizing
AIvaluestoalignwithspecificcontexts,domains,oruserpreferences.InteractiveLearningenablestheuserstoprovide
feedbackorcorrectionstoAImodelsinrealtime,suchasusinginteractivetutorialsanduser-drivencustomization
interfaces[261,373].SteeringPromptsprovidesuserswithpromptsorcuestosteerthebehaviorordecision-makingof
AIsystemstowardsdesiredoutcomesorvalues[96,203].ProactiveAlignmentanticipatesuserneedsandpreferences
basedonhistoricaldataoruserprofilesandproactivelyadjustingAIsystemsaccordingly[340].
4.2.3 EvaluatingAISystems:howtoevaluateAIregardinghumanvalues? TheriseintheuseofLLMshas
alsoseentheriseofautomaticevaluationofgeneratednaturallanguagetextevaluationindifferentcontexts.Butin
particular,aresearchdimensionhasfocusedonanalyzinghowcloselyvaluesdiscussedinhumanecontexthasbeen
adaptedtoAImodels/applicationsandhowthesearebeingevaluated.
Human-In-The-LoopEvaluation.Thisdimensioninvolvesincorporatinghumanjudgement,feedback,orinteraction
intotheevaluationprocesstoassesstheeffectiveness,robustness,andethicalimplicationsofintegratinghuman
valuesintoAIsystems.HumanEvaluationsolicitsfeedback,opinions,orassessmentsfromhumanevaluatorstogauge
thealignmentofAIsystemswithhumanvaluesandethicalstandards[147,189,284,339].Human-AICollaborative
EvaluationcollaborativelyevaluatesAIsystemswithbothhumanevaluatorsandlargelanguagemodels(LLMs)to
leveragethestrengthsofbothhumanjudgementandAIcapabilities[5,201].
AutomaticEvaluation.Thisdimensioninvolvesusingcomputationalmethodsoralgorithmstoassessthealignmentof
AIsystemswithhumanvalues,withoutdirecthumaninvolvement.HumanSimulatorsusesimulationmodelsorvirtual
agentstomimichumanbehaviorandassessAIperformanceinhuman-likescenarios.Typicalmethodsincludeagent-
basedsimulations,syntheticusermodels,andothers[97,167,405].EvaluationBenchmarksestablishesstandardized
benchmarksormetricsforevaluatingAIperformanceinrelationtohumanvaluesandethicalconsiderations[151,
189,214,314,315,339,346].DistributionDifferencecomparesthedifferencebetweentheoutputdistributionfromAI
generationsandhumandatatoevaluateAI[214,293].
4.2.4 EcosystemandPlatforms:howtobuildtheecosystemtofacilitatehuman-AIalignment? Theecosystem
andplatformsrefertothebroadercontextinwhichAIsystemsoperateandinteractwithotheragents,platforms,oren-
vironments.Thisincludestheinfrastructure,frameworks,andtechnologiesthatsupportthedevelopment,deployment,
andutilizationofAIsystems.LLM-basedAgentsarebasedonlargelanguagemodels(LLMs)suchasGPT(Generative
Pre-trainedTransformer)models,whichhavebeenpre-trainedonvastamountsoftextdata[88,435,443,483].RL-based
Agentsarebasedonreinforcementlearning(RL)algorithmstolearnandadapttheirbehaviorbasedonfeedback
16TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
B Align Humans to AI
Research Questions Sub-research Questions Dimensions Codes Example Papers
Human Cognitive Perceiving and Education and AI Literacy and Awareness (AI Literacy [250])
RQ3
Adjustment to AI Understanding of AI Training Human Training Courses (Intersectional AI [264])
(Sec 4.3) (Sec 4.3.1)
AI Sensemaking Perception and Sensemaking on AI (AngleKindling [300])
and Explanations Human-Centered Explanations (XAI with Interaction [376])
Critical Thinking Trust and Reliance Trustworthiness (Accuracy on Trust [461])
about AI on AI Decisions AI Reliability (Appropriate Reliance [329])
(Sec 4.3.2) Selective AI Adoption (GP-TSM [124])
Ethical Concerns Ethical Concerns and Mitigation (Algorithmic Fairness [142])
and AI Auditing Audit Deployed AI (Review of Algorithm Audits [19])
Calibrate Cognition Update Human Mental Model (Adjusting Expectations [198])
to Align AI Recalibrate Trust and Reliability (Trust Calibration [430])
RQ4 Human Adaptive Human Collaborating Assistants LLM Demand Specification (Specification Alignment [378])
Behavior to AI with Diverse AI Roles LLM Prompt Strategy (AI Chains [438])
(Sec 4.4) (Sec 4.4.1) LLM-Powered Prototypes (PATAT [112])
AI-Assisted Task and Decisions (AILA [59])
Simulated Agency (Generative Agents [291])
Partners
Reciprocal Learning (Collaborating Partners [465])
AI Delegation (AI Knowledge [303])
AI-Mediated Tasks (AI-MC [370])
Co-Design with AI (AI as Design Materials [460])
Tutors Tutoring Technical Skills (HypoCompass [256])
Tutoring Social/Behavioral Skills (Rehearsal [338])
AI Impacts on Humans Impact on Decision-making Process (XAI Usefulness [341])
and Society Individual Behavior Human Creativity (Human Ideas [10])
(Sec 4.4.2) Privacy (Privacy in LLM [225])
Learning Gain (Incidental Learning [105])
Societal Concerns Misinformation and Moderation (Social Media Misleading [15])
and AI Impacts
Impacts on Education (Self Learning with LLM [183])
Social Relationship and Norms (Anthropomorphism [56])
Workplace (Resist in Workspace [290])
Reaction to AI AI Regulatory and Policy (Regulating ChatGPT [130])
Advancements Shifts of AI Acceptance (Laypeople’s Expectation [233])
Surveillance and Intervention (HR Management [290])
Responsible AI Checklist (AI Fairness Checklist [260])
Evaluation in Human Evaluate Human-AI Human-AI Team Performance (RealHumanEval [272])
Studies Collaboration Cognitive Workload & Satisfaction (User-perceived tasks [81]
(Sec 4.4.3) Control and Trust (Perceived Control [82])
Interaction Behavioral Analytics (Collaborative Code [297]
Qualitative Survey and Interviews (Co-design Checklist [468])
Statistical Analysis (Regression Analysis [408])
Evaluate Societal Public Opinion Surveys (Whose Opinion [326])
Impact Behavioral Data Analytics (Chess Move Decisions [481])
Fig.7. Thefine-grainedtopologyof“AlignHumanto↦→AI”direction,whichstudieshumans’cognitiveandbehavioraladaptationto
theAIsystems,whichaimstohelphumansbettercritique,collaboratewith,andco-adapttoAI.
17AI Humans
Human Value and
RQ1
(Development) Representation Collaborate &
Data & Train (Integrate human values to train, Co-adapt
steer and customize AI)
A✦ Align AI to Humans
Interactive Alignment
Align Humans to AI B
(Help humans to better critique,
(Application) collaborate, and coadapt with AI) Perceive and
Model & Deploy Critique
Human Cognitive
RQ3
Adjustment to AI
Manuscript,submittedtoACM,2024 Shenetal.
fromtheenvironmentorhumanusers[464].AnnotationPlatformsreferstotheecosystemsthataredesignedto
crowdsourcehumandemonstrationsascollecteddataforreinforcementlearning[113]andsupervisedfinetuning
learningforalignment[294].
ADIRECTION-II: B ALIGNHUMANSto↦→AI
“Wheninteractingwithpeople,AIagentsdonotjustinfluencethestateoftheworld–theyalsoinfluencetheactionspeople
takeinresponsetotheagent,andeventheirunderlyingintentionsandstrategies”[143].Fromalong-termperspective,it
isessentialtoconsiderthedynamicchangesaroundhuman-AIalignment.Therefore,researchinthisdirectionaims
tohelphumansbetterunderstand,critique,collaboratewith,andadapttoAIadvancements.Thetwocoreresearch
questionsweidentifiedinthisdirectionare:RQ3.HumanCognitiveAdjustmenttoAI(Section4.3)andRQ4.
HumanAdaptiveBehaviortoAI(Section4.4).
4.3 A Rli Qg 1nHumRQa2nsto↦→AI:
RQ3
Hu Rm Q4an’sPerceptualAdaptationtoAI
RQ3.Howmighthumanslearntoperceive,explain,andcritiqueAI?HumansneedstounderstandAItobetter
specifytheirdemandsandcollaboratewithAI.Also,asAIsystemsproducearangeofrisks,itisimportanttoelicit
humans’criticalthinkingofAIinsteadofrelyingonAIblindly.Therefore,wecategorizeexistingliteraturetoanswer
thequestionsofhowhumanslearntoperceiveandunderstandAI (Section4.3.1),andhowtoengageincriticalthinking
onAI?(Section4.3.2).Wealsoanswerthetwo“Sub-ResearchQuestions”byintroducingtheanswer“Dimensions“
andproviding“Codes“associatedwith“ExamplePapers”.
4.3.1 PerceivingandUnderstandingAI:howdohumanslearntoperceiveandexplainAIsystems? Address-
ingtheproblemofhumanperceptionandunderstandingofAIincludesthefundamentaleducationandtrainingrequired
forlesstechnicalpeopletoimproveunderstandingofthebehindmechanismsandoutputsproducedbyAIsystems.It
alsoincludesvisualizationsandhuman-centeredexplanationsdesignedtohelpmorepeoplelearntounderstandAI
outputs.
EducatingandTrainingHumans.AIisincreasinglyincorporatedintothedailylivesofabroadspectrumofusers,
includingthosewithlittletonotechnicalknowledgeonhowAIoperates.Herewediscusshowtohelptheseless
technicalpeoplebecomemoreAIliterate,orbettertrainedtouseAI.AILiteracyandAwarenessisbroadlydefinedas
thecorecompetenciesrequiredforlesstechnicalpeopletobetteruseandcollaboratewithAI[250].Beyondthesecore
competencies,thereisalsomoreindepthandexplicitTrainingCoursestosupportindividualstobettercollaborateand
utilizeAI[289].
AISensemakingandExplanations.Toimprovepeople’sunderstandingofAIsystemsandgeneratedoutputs,various
techniquesandapproacheshavebeendevelopedtohelppeoplelearntomakesenseofandexplainthemodel’soutputs.
PerceptionandSensemakingonAIinvolvestheprocessthroughwhichhumanslearntomakebettersenseofAI
mechanismsanddecisionmakings[180,352].PeoplealsoneedtounderstandhowAIsystemsarriveatspecificgenerated
outputs.PriorstudiesinHuman-CenteredExplanationshaveexaminedvariousapproachesandinteractivetechniques
toincreasehumanunderstandingofAIgenerationsandoutputs[355,383].
4.3.2 CriticalThinkingaroundAI:howdohumansthinkcriticallyaboutAIsystems? Beyondsimplyperceiving
andunderstandingAI,individualsneedtocomparetheirmentalmodelofAIwiththeirownmentalmodeltojudge
whethertheAIisbehavingrationallyandethically.Broadly,thisinvolvesexploringthewaysinwhichhumansengage
incriticalthinkingandreflectontheirinteractionswithandevolvingunderstandingofAItechnologies.Herewediscuss
18
namuH
gnitargetnI
IA
otni seulaV 2QR RQ4
Behavior
to
AI
Human
AdaptiveTowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
studiesthathelphumansbecomemorecapabletoidentifybiasesanderrorsinAIoutput,andtheethicalimplications
thatarisefromusingAIalgorithmsindecision-makingprocesses.Also,wediscusshowhumansneedtocalibratetheir
mentalmodelstobemorealignedwithAI.
TrustandRelianceonAIDecisionsreferstotheextenttowhichpeoplementallytrusttheAIcompetencyand
practicallyrelyonAIforoutputgenerationanddecisionmaking.WeusethetermTrustworthinesstoindicatewhether
humansdecidetotrustthereliability,integrity,andcompetenceofanAIsystemindeliveringaccurateandtrustworthy
decisionsorrecommendationstotheusers[257,363].WedefineAIReliabilityastowhatextenthumansutilizeand
relyonAItoautomatedecisionmakinginpracticewithlowerrorratesandrobustnessperformance.[329,371,392].
SelectiveAIAdoptionreferstothecriteriaandconsiderationsthatguidetheadoptionorrejectionofAItechnologies
basedontheirperceivedbenefits,risks,andalignmentwithuserneedsandpreferences[124,392].
EthicalConsiderationsandAIAuditingreferstopotentialmoralandsocietalissuesthatarisefromthedevelopment,
deploymentanduseofAIsystems,aswellassystematicexaminationandevaluationofAIsystemsregardingthese
issues.EthicalConcernsandAIMitigationencourageshumanstocarefullyconsideriftheAIsystemspossessethical
concerns(e.g.,suchasbiasanddiscrimination,privacyviolationsandthepotentialforharmormisuse)andimplement
strategiesandpracticestoaddressandreducetheseethicalconcernsassociatedwithAI[142].AuditDeployedAIrefers
tothesystematicexaminationofAIsystemstoensurethattheyoperateasintended,complywithethicalandlegal
standards,anddonotcauseunintendedharm[19].
Re-CalibratingCognitiontoAlignwithAI.Thissub-categorydealswithinterventionsandtechniquestohelpusers
adjust(1)theirownmentalmodelofhowtheAIoperatesand(2)recalibratetheirperceptionoftheAI.UpdatingHuman
MentalModelofAImeansthatwhentheAIisnotalignedwithhumans,itisimportanttoadjusthumanperceptionsof
theconfidenceinAIsystemsbasedonthemodel’scapabilityandtrackrecord[137].RecalibratingTrustandReliability
indicatesthathumansadjusttheirperceptionsoftrustandreliabilityinAIsystemsbasedontheirperformanceand
reliability.ThisisalsoimportanttofosterappropriaterelianceandskepticismWischnewskietal.[430].
4 R. Q4
1
AliRgQn2Humansto↦→ RQA 3I:
RQ4
Human’sBehavioralAdaptationtoAI
RQ4.HowdohumansandsocietymakebehavioralchangesandreacttoAIadvancement?AsAIbecomes
increasinglyintegratedintodailylife,itisessentialtounderstanditsinfluenceonhumans,encompassingbothpositive
andnegativeaspects.Moreover,itiscrucialtodeterminehowindividualsandsocietycanbestandmostappropriately
respondtothisinfluence.Tothisend,wesummarizeliteraturetoanswerhowdohumanslearntocollaboratewithAIin
diverseAIroles?(Section4.4.1),howhumansandsocietyareimpactedbyAI (Section4.4.2)andhowmightweassessthese
impacts?(Section4.4.3)Wearticulatethethree“Sub-ResearchQuestions”byintroducingtheanswer“Dimensions“
andproviding“Codes“associatedwith“ExamplePapers”.
4.4.1 Human-AICollaborationMechanisms:whatarehumanstrategiestocollaboratewithAIthathave
differinglevelsofcapabilities? ThiscategorylooksatmanywaysthathumansandAIcancollaborate,suchas
teamwork,co-creation,andcoproduction.
AIAssistantforHumanscapturestheessenceofasymbioticrelationshipwhereAIsystemsaredesignedtobolster
humancapabilities,withhumanssteeringtheinteractions.LLM-basedDemandSpecificationemploysLLMstointerpret
andrespondtohumanrequests,poweringvirtualassistantsandchatbotsthatstreamlineinformationretrievaland
improvetaskaccuracy[378].ThisnaturallyextendstoLLM-basedPromptStrategy,whichhelpshumanstobetterwrite
promptsusingadditionalabstractionandscaffoldingmethods.Theexamplesystemcanenhancehumans’capabilityin
19Manuscript,submittedtoACM,2024 Shenetal.
generatingintelligentpromptsandsuggestions,suchasautocompleteandquestion-generationtoolsforLLM-based
systems[421,438],facilitatinghumans’smoothandintuitivedecision-makingprocesses.Inthecreativearena,LLM-
basedPrototypesutilizeAItotransformhumanideasintotangibleororganizedconcepts[112],enablingprofessionals
toexploreandrefineawidearrayofartisticpossibilitieswithAI-generatedoptions[157].Onabroadernote,researchers
havealsoexploredhowAI-AssistedTaskandDecisionsaimstoachievecomplementaryperformanceforhuman-AI
collaborativetasksbyempowerhumanstodiscernwhenandhowtoadoptAI-assistedrecommendationsorAI-generated
explanationsfordecision-making[410,414,479].
Human-AIPartnershipreferstoacollaborativerelationshipwherehumansandAIsystemsworktogetheraspartners,
combiningtheirrespectivestrengthstoachievesharedgoalsmoreeffectively.SimulatedAgencyenableshumansto
collaboratewithAIpartnerswithsimulatedagencyorautonomy(e.g.,autonomousagentsandcollaborativerobots[291])
tomakedecisionscollaboratively.ReciprocalLearningfocusesonhowhumanslearnfromandexchangeknowledgewith
AIsystems,enhancinghuman-AIcollectivecapabilitiesandperformancethroughknowledge-sharingplatformsand
collaborativefiltering[465].AIDelegationallowshumanstodelegateAIpartnerstohelpfinishtasksorresponsibilities,
facilitatedbytaskassignmentalgorithmsandworkflowmanagementsystems[303].Furthermore,AI-MediatedTasks
emphasizeshowtraditionalhumantasksorbehaviors(e.g.,communication)wouldbechangedbyincorporatingAI
partnersintheloop[27,370,445].Co-DesignwithAIexploresAIasadesignmaterialorapartnerinprototyping,which
enableshumanstoconversewithAIinsituationsthatcancollaborativelyimprovethedesignoutcomes.[421,460]
AITutoringforHumanLearninginvestigateshowhumansimprovetheirlearningandknowledgethroughinteractions
withAItutorsthatcanperformbetterthanhumansinsometasks.Withthetailoredinstructionsandcustomized
feedbackfromAItutors,humanscanenhancetheirthelearningoutcomesandfacilitatemasteryofnewskillsmore
effectivelythantraditionallearningmethods.AITutorforTechnicalSkillsreferstoempoweringhumanstolearn
technicalskillsfromAItutors.Fortechnicalsubjectslikecoding,AItutorscananalyzealearner’sprogressinrealtime,
adjustingthepace,content,andapproachtoensureasolidunderstandingofcomplexconceptsandpracticalskillssuch
asprogramming[256].Similarly,AITutorforSocialandBehavioralSkillsinvolvesenablinghumanstolearnsocialand
behavioralskillsfromAItutors.Humanscanleveragevirtualsimulations,createdbyAItutoringsystems,topractice
publicspeaking,interpersonalcommunication,andothersoftskills.Byanalyzingverbalandnon-verbalcues,humans
canreceiveconstructivefeedbackonareassuchasbodylanguage,tone,anddeliveryfromAI,ultimatelyenhancing
theirabilitytocommunicateeffectivelyacrossvarioussettings[295,338].
4.4.2 AIImpactonHumansandSociety:howarehumansinfluencedbyAIsystems? Thiscategoryexplores
the effects of AI advancement on human behaviors, attitudes, and societal dynamics. It involves examining the
behavioralchanges,adaptations,andreactionsthatindividuals,groupsandwidercommunitiesundergoinresponseto
theproliferationofAItechnologies.ThegoalistoelucidatethemultifacetedimpactsofAIonhumanbehaviorand
societyandtoinformpolicy-making,education,andinterventionefforts.
ImpactsonParticipatoryIndividualsandGroupscoverstheeffectsofAIadvancementonthebehaviors,attitudes,
andexperiencesofbothindividualsandgroups.ThisdimensionfocusesonexamininghowAItechnologiesinfluence
decision-making,creativity,privacy,andauthorship.DecisionMakingreferstoanalyzinghowAItechnologiesinfluence
humandecision-makingprocesses,includingbiases,preferences,andriskassessment,invariousdomainssuchas
healthcare, finance, and personal life [341]. Human Creativity explores the impact of AI technologies on human
creativity,innovation,andexpression,includingtheaugmentationorautomationofcreativetasksandtheemergenceof
newformsofartisticexpression[10].PrivacyrelatestoinvestigatingtheimplicationsofAItechnologiesforindividual
20TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
privacyrights,dataprotection,andsurveillance,includingconcernsaboutdatacollection,tracking,andalgorithmic
profiling[225].Authorshipcatalogsissuesrelatedtointellectualproperty,attribution,andownershipofAI-generated
content,includingquestionsoflegalresponsibility,copyrightinfringement,andplagiarismdetection.SalientisthatAI
canproduceincreasinglyrealistic,syntheticdataquicklyandatlowcost,whichbringsforthtensionsaroundtheuseof
suchdatatomakedecisions[132].
SocietalConcernsandAIImpactsinvolvesthebroadersocietalimplicationsandconsequencesofAIadvancementon
misinformation,education,socialrelationships,norms,jobdisplacement,andotheraspectsofhumansociety.Misinfor-
mationandModerationconcernsthechallengesofmisinformation,disinformation,andonlinecontentmoderationinthe
contextofAI-driveninformationecosystems,includingconcernsaboutalgorithmicbiasandfilterbubbles[15].Impacts
onEducationpertainstoassessingtheeffectsofAItechnologiesoneducationsystems,learningoutcomes,pedagogical
practices,andworkforcetraining,includingopportunitiesforpersonalizedlearningandskilldevelopment[182].Impacts
onSocialRelationshipandNormsexploreshowAItechnologiesshapeinterpersonalrelationships,socialinteractions,
andculturalnorms,includingchangesincommunicationpatterns,socialdynamics,andethicalconsiderations[56].
WorkplacereferstoexaminingtheeffectsofautomationandAItechnologiesonemploymentpatterns,jobmarkets,
andworkforcedynamics,includingconcernsaboutjobdisplacement,re-skilling,andeconomicinequality[290].
ReactiontoAIAdvancementinvolvessocietalresponses,regulatoryframeworks,andpolicyinitiativesaimedat
addressingthechallengesandopportunitiesposedbyAItechnologies.Thisdimensionencompasseseffortstoregulate
AIdeployment,re-calibratesocietalacceptance,andmanagepotentialbacklash.Forexample,reactiontobiasand
discrimination in algorithmic decision making can depend on how people perceive the machine and the context
ofuse,i.e.,ifthemachineisconsideredanactorembeddedinsocialstructuresthatcallforblamewhenharmful
decisionsaremade[232].AIRegulatoryandPolicyincludesregulatoryframeworks,legalframeworks,andpolicy
initiativesaimedatgoverningAIdevelopment,deployment,anduse,includingconcernsaboutethics,safety,and
accountability[130,254].ShiftsinAIAcceptancerelatestoinvestigatingsocietalattitudes,organizationalpractices,
andacceptanceofAItechnologiesovertimeinpractice,includingshiftsinpublicopinionandAIutilizationbyhumans
andinstitutesregardingAIdeploymentandimpact[233,308].SurveillanceandInterventionemphasizestheneedfor
transparency,monitoring,andhumanoversightinthealgorithmicdecision-makingprocess.Thisapproachenables
betterhumancontroloverAIsystemsandhelpsmitigatepotentialrisksassociatedwiththeiruse[290].ResponsibleAI
Checklistsinvolvesthecreationofethicalguidelines,suchasthosefocusingonfairnessandtransparency,toensurethe
responsibledevelopmentanddeploymentofAIsystems.Thesepublishedprinciplesserveasafoundationforguiding
ethicalAIpractices[260].
4.4.3 EvaluationinHumanStudies:howmightweevaluateandunderstandtheimpactofAIonhumans
andsociety? WesummarizecommonempiricalmethodsusedtorigorouslyunderstandandassesstheimpactofAIon
humans.Specifically,wefocusontwotypesofimpact.Onthemicro-level,wediscusshowtoevaluatetheeffectiveness
ofhuman-AIcollaboration;onthemacro-level,wediscusshowtoassesstheimpactofAIonalargegroupofpeople
overalongperiodoftime.
EvaluateHuman-AICollaborationreferstotheevaluationoftheeffectivenessofanAIsystemincollaborationwith
humans.Itiskeytonotonlyconsiderthefinaloutput,butalsotheinteractionexperience[210].Human-AITeam
Performancecompareshuman-AIteamperformancewiththeperformanceofhumansalonewithoutAIcollaboration
Themetricsformeasuringperformanceshouldincludebothtasksuccessmetrics(e.g.,accuracy)aswellasindicators
ofefficiency[81,272].CognitiveWorkloadandUserSatisfactioninvolvesunderstandingthedegreeofcognitiveload
21Manuscript,submittedtoACM,2024 Shenetal.
thattheuserexperienceswheninteractingwiththesystem,aswellasusersatisfactionwiththeinteractionandthe
finaloutcome.Suchaspectsareoftencapturedviasurveysorinterviews[81,210].ControlandTrustreferstohow
usercontrolcansupporttheavoidanceofcatastrophicAIfailures,especiallyinhigh-stakessettingswhereAImistakes
couldleadtoharm[82,362].InteractionBehavioralAnalyticsreferstomeasuringtaskperformancequantitatively.
Thisapproachincludesrecordinguserinteractiondataandanalyzingthepatterns[209,297,396].QualitativeSurvey
andInterviews referstoqualitativeapproachestounderstandinghuman-AIinteraction.Commonlyusedmethods
includequalitativesurveyquestions(i.e.,open-ended)anduserinterviewstoassessaspectsoftheuserexperience.[468].
StatisticalAnalysisutilizesmethodssuchasregressionanalysistoquantitativelyanalyzeandevaluatedatafromhuman
studies,allowingfortheverificationofhypotheses[408].
EvaluateSocietalImpactreferstothemacro-impactofagroupofpeopleastheycometouseAIbroadly.This
dimensionrequiressufficientscaleandtime.Theaimistounderstandhowthegroup’sbehaviorchangesaspeople
withinitfrequentlyinteractwithAI.PublicOpinionSurveysaimstoinvestigatetheimpactofAIonhumanmeasures
ofinterestthoughdeployingandanalyzinglargescalequestionnaires[326].BehavioralDataAnalyticscollectslarge-
scaleandpotentiallylongitudinalbehaviordata,withtheaimofunderstandinghowpatternevolveandshiftover
time[348,481].
5 PAPERCODINGANALYSESANDFINDINGS
Inthissection,ouraimistoconsolidatekeyfindingsderivedfromouranalysisoftheframeworkandthecurrentstate
ofliteraturewereviewed.Webeginbyanalyzingtheoveralltrendsandgapsintheliterature(Section5.1).Wethen
focusonthreeessentialaspects:therelationshipbetweenhumanvaluesandalignment(Section5.2),thepotential
interactionmodesusedtospecifyhumanvalues(Section5.3),andthegapsbetweenAImodelandhumanstudy
evaluation(Section5.4).
5.1 OverviewofTrendsandGapsintheLiterature
Basedonourcodingofallpapers,wecomputedthenumberofrelevantpapersforeachdimensionintheframework
(seeFigure8).Wenoticedthatcertaindimensionsareover-orunder-represented.Mostliteraturespecifiedhuman
valuesusingexplicithumanfeedback,whereasimplicitandsimulatedhumanfeedbackwerelargelyunder-explored.
Additionally,manystudiesonhumancognitiveadjustmenttoAIfocusonenablingAIsensemakingandexplanations
sothathumanscanbetterunderstand,trust,andrelyonAI.However,thesestudiesoftenfocusedonexplainingAI
decision-makingjustificationratherthaneducatingpeopletoacquiregeneralskillsandcompetenciesrequiredto
understand,use,critique,andinteracteffectivelywithAIsystems(i.e.,AIliteracy).AIliteracy[250]playsafundamental
roleinensuringpeopleunderstandsandusesAIcorrectly,butitstillneedstobeexploredcomparedtoothertopicslike
explanationandtrustworthiness.Also,weobservedawiderangeofstudies[112,256,291,438]developinginteractive
mechanismsandprototypestoempowerhumanstocollaboratewithAIindiverserolesofAI.However,mostexisting
studiesassumedthatAIplaysanassistantrole,beinglesscapablethanhumans.Thissituationmightchangeinthe
longterm.Moreover,theinfluenceofAIadvancementsonhumanbehavior,socialrelationships,andsocietalchangesis
essentialbutremainslargelyunexplored.
5.2 FindingsinHumanValuesforAlignment
Wepresentthekeyfindingsforfutureresearchwhichareidentifiedduringouradjustmentofthe“SchwartzTheoryof
BasicValues”andliteraturereview.
22TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
Interaction Modes to
Specify Values for AI
Customizing AI for
(Sec 4.1.2) Individuals/Groups
RQ1 D Ge ev ne elo rap l A VI a w lui et sh (Sec 4.2.2) AI Evaluation AI Impacts on
Humans and Society
(Sec 4.2.1) (Sec Perceive and
4.2.3) Understand AI Human (Sec 4.4.2) Assessment of
4( .S 3e .1c ) Criti ac ba ol uT th Ain Iking C Do il vla eb ro ser a Ati In Rg ow leit sh CI om llp abac ot r aa tn id on
(Sec 4.4.1) (Sec
(Sec 4.3.2) 4.4.3) RQ2
RQ4
RQ3
Dimensions in Bidirectional Human-AI Framework
Fig.8. Thenumberofpapersforeachdimensioninthebidirectionalhuman-AIalignmentframework.Outofpapersthatarerelevant
toeachresearchquestion(i.e.,graybars),weshowthenumberofpapersthatarerelevanttoeachdimension(i.e.,colorbars).This
figureillustratestheextenttowhicheachdimensionhasbeenexploredbyexistingresearch.WeprovidemoreanalysisinSection5.1.
5.2.1 TheRelativePriorityofValuesisasCrucialasTheirExistence. BasedonthedefinitionfromSchwartz
[333],wenotedthatahumanvaluesystemisnotanexclusivesubsetofvalues,butrather,anorderedsystem.Schwartz
[334]presentedthedefinitionforthisphenomenon:“avalueisorderedbyimportancerelativetoothervaluestoform
asystemofvalue priorities.Therelativeimportanceofmultiplevaluesguidesaction....Thetrade-offamongrelevant,
competingvaluesguidesattitudesandbehaviors.”Forinstance,thepursuitofachievementvaluescanpossiblyclashwith
benevolencevalues.Similarly,previousstudieshavehighlightedthetrade-offsbetweenAI’sstate-of-the-artcapabilities
andtheirethicalperformance,suchasinterpretabilityandfairness[343].Whilemostalignmentalgorithmsutilize
datasetsofhumanratingsandpreferencescollectedinthewild[282,312,359],AImodelsmayinadvertentlyalign
withthevalueprioritiesofthemajorityrepresentedinthesedatasets,potentiallyoverlookingorsacrificingthevalue
systemsofmarginalizedgroups[100].
5.2.2 Human-desiredAIValuesandCustomizationtoPersonalValues. WhilefurtherresearchinAIethicsis
crucialinthisnuancedarea,therearevaluesthat,ingeneral,humansexpectAItoprioritize(e.g.,capability,equity,
responsibility)andvaluesthathumansdonotwantAItointegrateinspecificscenarios(e.g.,seekingpowertoavoidor
harmpeople[276]).Ontheotherhand,AImodelsareexpectedtobetailoredtoaccommodatediversehumanvalue
systems[360],whichnecessitatesacomprehensiveunderstandingofalltypesofvalues.Therefore,futureresearch
23
srepaP
tnaveleR
fo
rebmuNManuscript,submittedtoACM,2024 Shenetal.
HCI Research Inference Stage [98] [302] [144] [340] [52] [65] [438] [175]
[251] [292] [162] [282] [463] [127] [17] [457] [158] Learning Stage NLP/ML
[237] [473] [114] Inference Stage Research
Discarded Language Social Rating Ranking Features Principles Text Inputs / Multi-Turn Multi-Modal Human Structural Contextual
Options Analysis Relationship Edits Dialogue Visualization Sketches Interaction Information
Numeric Interaction Natural Language Interaction Graphical Multi-Modal Interaction
Implicit Feedback Explicit Feedback
Human-AI Interaction Modes for Alignment
Fig.9. Theinteractiontechniquesforspecifyingvaluesinhuman-AIalignment.Wecomparethecommoninteractiontechniques
usedforthemodel“Learning”and“Inference”stagesinhuman-focused(e.g.,HCI)andAI-focused(e.g.,NLP/ML)researchstudies.
couldpotentiallyexplorethedirectionsof:(1)developingmethodstoidentifytheappropriatesetsofhumanvaluesto
alignwithspecificindividualsorgroups,and(2)understandingandcustomizingAItoalignwithusers’valueswhile
maintainingitsinherentethicalprinciples.
5.2.3 ExpectationsandEvaluationsofValuesMayDifferBetweenHumansandAISystems. Duetothefunda-
mentaldifferencesbetweenhumansandAImodels,theexpectationsforevaluatingcertainvaluescanvarybetweenthe
two.Forinstance,whilehumanhonestycanhardlybeassessedexceptobservableactions,forAImodelstheexpectations
mightbehigher.Itcouldinvolvereverse-engineeringthecomputationalmechanismsandrepresentationslearned
byneuralnetworksintoconceptsunderstandabletohumans.Thisapproach,knownasmechanisticinterpretability,
providesain-depthunderstandingofhowAImodelsoperate[26].FutureresearchisneededtoexploreevaluatingAI
valuesandcalibratinghumanexpectationsofthesevalues.
5.3 InteractionTechniquesforHumanValueSpecification
SelectingsuitableinteractiontechniquesforhumanstospecifyAIvaluesforalignmentiscrucial.Eachresearchdomain
offersdistinctstrengthsandinsightstoaddressthischallenge.Fromthebidirectionalperspective,weinvestigate
thestatusquoofexistinginteractiontechniquesforalignmentspecificationinbothhuman-centered(e.g.,HCI)and
AI-centered(e.g.,NLP/ML)studies.Additionally,weprovideadetailedanalysisofhowthesetechniqueshavebeen
utilizedinthelearningandinferencestages,asshowninFigure9.
5.3.1 InteractionTechniquesAcrossVariousDomains. AsshowninFigure9,thecoverageofinteractiontech-
niques in AI-centered (i.e.,NLP/MLResearch) and human-centered (i.e.,HCIResearch) studies often differ [36].
Particularly,weseethatNLP/MLstudiesprimarilyleveragenumeric-based,naturallanguage-basedinteractiontech-
niquesforhuman-AIinteractionandalignment.Inaddition,NLP/MLresearchersalsoleverageimplicitfeedbackto
improvethemodel.Forexample,somesystemstookinimplicitsignalssuchascontextualinformation,ordiscarded
optionstodevelopAIsystems.Incomparison,HCIstudiescovermorediversegraphicalmulti-modalinteractionsignals
(e.g.,sketches,locationinformation)beyondtextandimages,whichcanbelargelyattributedtotheproficientgraphical
userinterfacedevelopmentskillsfoundinHCIresearchersandpractitioners.Thispotentiallyindicatesgapsinthe
humanbehavioralinformationthatthetwofieldscanextractfromtheusersoftheAImodels.
5.3.2 DifferentInteractionTechniquesinSeparateStages. Anotherfindingwediscernedisthedifferentinterac-
tiontechniquesusedinseparatestages,especiallyintheNLP/MLfields.Specifically,thelearningstagereliesmostly
24TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
onratingandrankinginteractiontodealwiththegenerateddatasetsofthemodels.However,usersleveragetheAI
modelindifferentwaysduringinferencestage,asdemonstratedinHCIresearch.Thisindicatesthatusersmightelicit
differentneedsinpracticewheninteractingwithAIduringthemodeldeploymentstage.Therefore,futureNLP/MLand
HCIresearchersmightcollaboratetokeepthehuman-AIinteractiontechniquesinformed(orevenconsistent)byboth
domainsinordertofacilitateclosealignmentbetweenhumansandAI.
5.3.3 DissimilarUsageofInteractionDataBetweenDomains. Wenoticedthatthewaysinwhichthetwo
domainsutilizedatadiffer.Forexample,theinteractionoutputsofNLPresearcharecommonlythedatasettobe
trainedinthemodel,whereasHCIresearchersuseusagedatatoanalyzehumanbehaviorandfeedback.AsAIsystems
continuetoadvance,newmodesofinteractionarerequiredtocapturemorespaceofhumanexpression,withthegoal
ofdeeperandmeaningfulalignment.ThisisanimportantareaforNLP/MLresearcherstopartnerwithHCIresearchers
fordesigninginteractionparadigms,includingbutcertainlynotlimitedtoaffectivecomputing,accessibility,social
computing,computer-supportedcooperatedwork,andubiquitouscomputing.
5.4 GapsBetweenEvaluatingAISystemsandHumanStudyEvaluation
ImprovingbidirectionalalignmentbetweenhumansandAIcanpotentiallybefurtherenhancedbycollaborativeefforts
andcommitmentsfromboththeNLP/MLandAIdomains,ensuringconsistencyinevaluationmethodsandmetrics.
Nevertheless,weobservednotablegapsbycomparingtheliteratureanalysisregarding“evaluatingAIsystems”(i.e.,
Section4.2.3)and“evaluationinhumanstudies”(i.e.,Section4.4.3).
5.4.1 DifferentObjectivesandExpectationsofEvaluationsinHumansandAI. EvaluatingAIsystemsprimarily
focusesonwhatalgorithmicperformanceis,aimingtodeterminehowwellproposedmethodsperformcomparedwith
benchmarkorhuman-in-the-loopevaluation.Conversely,humanstudyevaluationsaremoreconcernedwithwhy–
understandingtheuserexperienceandinteractions,oftenprioritizingbothquantitativeandqualitativemeasurementsto
gainacomprehensiveunderstandingofuserexperienceandinteractionswithAIsystems.Giventhedistinctobjectives
inevaluation,futureresearchhasthepotentialtocollaborateinbridgingthesegaps.Forinstance,informedbythe
userexperienceanddemandsrevealedbyHCIstudies,NLP/MLresearcherscanincorporatetheinsightsanddesign
human-centeredevaluationbenchmarkstoassessAIsystems.
5.4.2 ContrastingWaysofUtilizingUserInformation. Giventhediverseobjectivesofassessmentdescribedabove,
NLP/MLresearchprimarilyfocusesonquantifiablemeasuressuchasaccuracy,precision,andrecall.Theinformation
receivedinevaluatingAIsystemsisoftenaccuratelymeasurable,e.g.,ratings,rankings,andmultiplechoicequestions.
Incomparison,byfocusingonunderstandingtheuserexperienceandinteractionwithAIsystems,HCIresearch
ofteninvolvesgatheringbothquantitativeandqualitativedata,suchasuserfeedback,perceptions,andbehaviors.The
collectedinformationfromHCIresearchmightcoverawiderspectrumofqualitativedatarelatedtohumanvalues,
experience,andneedsinpracticethanwhatcanbecapturedbyquantitativemetricsalone.However,incorporating
qualitativefindingsintoimprovingAIsystemscanbedifficult.Therefore,futureresearcherscaninvestigatemethodsto
convertqualitativehumanfeedbackintoquantitativedatathatAIsystemscaneffectivelyutilizeandalignwith.
5.4.3 EvaluationApproachesandScale. PriorstudiesinNLP/MLhavepredominantlyreliedonautomatedor
human-in-the-loopevaluationmethodstoassessAIsystemperformanceacrossextensivedatasets.Incomparison,HCI
studiestypicallyemployqualitativeand/orquantitativemeasurementstogaindeeperinsightsintouserexperiences
andinteractionswithindefinedhumangroups.Thesedivergentaspectshighlightdiversegapsbetweentheevaluation
25FUTURE CHALLENGES A✦ Align AI to Humans B Align Humans to AI
Sec6.1 Sec 6.1.1 Integrate fully specified human Sec 6.1.2 Elicit the nuanced and contextual
Specification Game values into aligning AI human values during diverse interaction
Sec6.2 Sec 6.2.1 Co-evolve AI with changes in Sec 6.2.2 Adapt humans and society to the latest
Dynamic Co-evolution of
humans and society AI advancements
Alignment
Sec6.3 Sec 6.3.1 Decompose superintelligent AI Sec 6.3.2 Enhance human capabilities to identify
Power Balancing behavior into interpretable and controllable power-seeking behavior and design corrigible
actions mechanisms
FUTURE CHALLENGES A✦ Align AI to Humans B Align Humans to AI
Sec6.1 Sec 6.1.1 Integrate fully specified human Sec 6.1.2 Elicit the nuanced and contextual
Specification Game values into aligning AI human values during diverse interaction
Sec6.2 Sec 6.2.1 Co-evolve AI with changes in Sec 6.2.2 Adapt humans and society to the latest
Dynamic Co-evolution of
humans and society AI advancements
Alignment
Sec6.3 Sec 6.3.1 Decompose AI final goals into Sec 6.3.2 Empower humans to identify and
Coadaptive Mutualism interpretable and controllable instrumental intervene in AI instrumental and final strategies
actions in collaboration
Manuscript,submittedtoACM,2024 Shenetal.
FUTURE CHALLENGES A✦ Align AI to Humans B Align Humans to AI
Sec6.1 Sec 6.1.1 Integrate fully specified human Sec 6.1.2 Elicit the nuanced and contextual
Specification Game values into aligning AI human values during diverse interaction
Sec6.2 Sec 6.2.1 Co-evolve AI with changes in Sec 6.2.2 Adapt humans and society to the latest
Dynamic Co-evolution of
humans and society AI advancements
Alignment
Sec6.3 Sec 6.3.1 Decompose AI final goals into Sec 6.3.2 Empower humans to identify and
Safeguarding Coadaptation interpretable and controllable instrumental intervene in AI instrumental and final strategies
actions in collaboration
AI Humans
Fig.10. Weenvisionfutureresearchdirectionstoachievelong-termhuman H-A umI aa nl i Vg an lum
e
ae nn
d
twithbotheffortsfromthe“AlignAIto↦→
Humans”and“AlignHumansto↦→AI”directions.(DWeeveelloapbmoreantte) thethrReQe1imRpeoprrteasennttaftuiotnurechallengCeosl,laibnocrluatdei n&g SpecificationGame
AI Humans
(Section6.1),DynamicCo-evolutionofAlignment(Section6.2),andSafeguardingCoadaptation(Section6.3).
Data & Train (Integrate human values to train, Co-adapt
RQ1 Human Value and steer and customize AI)
(Development) Representation Collaborate & A✦ Align AI to Humans
Data & Train (Integrate human values to tmraine, thodsaCno-dadsacpatlesutilizedinthetwodomains.Closingthisgapandadoptingconsistentevaluationstrategiescould
steer and customize AI) Interactive A✦ Align AI to Humlaenasdtoamoreholisticunderstandingandsynergyofhuman-AIinteraAcltigionnmeanntdalignmentacrossbothfields.
Overall,it’simportanttonotethatthedisparitiesbetweenHCIandNLP/MLstudiesextendbeyondtheaboveaspects,
Interactive Align Humans to AI B Alignment e.g.,researchmethodsandproblemformation.Ouranalysesaimtopavethewayforfutureinterdisciplinaryresearch
(Help humans to better critique,
collaboration,fosteringbidirectionalalignme(nAtpbpleictawtioene)n humcaolnlabsoaranted, anAd Icoaadcarpot swsithd AiIv)ersedPoemrceaiivne sa.nd
Align Humans to AI B Model & Deploy Critique
(Help humans to better critique, Human Cognitive RQ3
Adjustment to AI
(Application) collaborate, and coadapt with 6AI) FUTPUerRceEiveD aInRd ECTIONS
Model & Deploy Critique
Human Cognitive RQ3Thetwodirectionsofhuman-AIalignmentarenotindependent;instead,theyrepresentanongoing,mutualprocessto
Adjustment to AI
achieveadynamicalignmentgoaloverthelongterm.Futureresearchshouldapproachalignmentstudiesasabidirectional
processtofullyexplorethebreadthoftheresearchspaceandachievethisessentialgoal.Drawinguponinsightsgained
fromthedevelopmentofourframeworkandtheassociatedcodinganalysis,asshowninFigure10,weproposefuture
researchaimingtoachievethelong-termalignmentgoalbyidentifyingthreeimportantchallengesfromnear-termto
long-termobjectives,includingtheSpecificationGame(Section6.1),DynamicCo-evolutionofAlignment(Section6.2),
andSafeguardingCoadaptation(Section6.3).Particularly,wediscussresearchquestionsandmotivationsfollowed
byideasforsolutionexplorationfrombothdirectionsof“A AlignAIto↦→H Buman”(i.e.,domainsrelatedtoAI
algorithmandmethoddevelopment,includingMachineLearning,ArtificialIntelligence,DataScience,andothers)and
A “ B AlignHumanto↦→AI”(i.e.,domainsconductingstudiesrelatedtohumansandsociety,includingHuman-Computer
Interaction,SocialScience,CognitiveScienceandothers)foreachchallengebelow.
6.1 Challenge1:SpecificationGame
Animportantnear-termchallengeisresolvingthe“SpecificationGame”,whichinvolvespreciselydefiningandimple-
mentingAIgoalsandbehaviorstoalignwithhumanintentionsandvalues.Next,wewillintroducehowsynergistic
effortsfromtwodirectionscanpotentiallyaddressthischallenge.
6.1.1 AligningAIto↦→Humans:IntegratefullyspecifiedhumanvaluesintoaligningAI. Individualsoften
possessvaluesystemsthatencompassmultiplevalueswithvaryingpriorities,ratherthanasinglevalue,toguidetheir
behaviors[333,334].Forexample,peoplemayprioritizethevalueoffamilyandworkdifferently,leadingtovaried
choicesintimeallocation.Also,theseprioritiescanchangedynamicallythroughoutanindividual’slifestages.As
26
namuH
gnitargetnI
IA
otni seulaV 2QR
mreT-raeN
mreT-gnoL
mreT-raeN
mreT-gnoL
mreT-raeN
mreT-gnoL
RQ4
Behavior
to
AI
Human
Adaptive
namuH
gnitargetnI
IA
otni seulaV 2QR RQ4
Behavior
to
AI
Human
AdaptiveTowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
such,itisunlikelytothatwecanachieveauniversalvaluesystem,recognizedbyallhumans,togovernAIalignment.
Instead,itismorerealistictoselectvaluescompatiblewithspecificsocietiesorsituations,giventhefactthatwelive
inadiverseworld[104].Therefore,intheabsenceofauniversalvalueagreement,itiscrucialyetchallengingforAI
designerstoinvestigatehowtofullyspecifytheappropriatevaluesandtofurtherintegratethesevaluesintoAIalignment.
ExamplesofPotentialFutureSolutions.Futureworkcandrawfrompoliticaltheory,whichexaminesfair
methodsfordeterminingtheprinciplesthatstateinstitutesshouldfollow,asapotentialguideforselectinghuman
valuesforAIalignment.InspiredbySocialChoiceTheory[9],onefuturedirectioninvolvesaggregatingindividual
valuesintocollectivevalueagreementsorjudgmentsthroughdemocraticprocessessuchasvoting,discussion,and
civicengagement[104].Therefore,buildingonthesummaryofhumanvaluesinSection4.1and5.2,futureresearchers
canusedemocraticmethodstoidentifyawidespectrumofhumanvaluesubsetsforAIalignment.Additionally,an
importantfocusforfutureworkliesinthecurationofdatasetsthatcanrepresentthesewide-spectrumhumanvalues,
particularlyinrichformatsthatgobeyondsimpleratingsandrankings,whicharecommonlyusedincurrentalignment
algorithms(e.g.,RLHF[282],RLAIF[17]).Anotherkeyresearchareatoexploreisaroundalgorithmsormethods
(e.g.,Bradley–TerryModel[312]orEloRatingSystem[17]),potentiallydrawingfromeconomictheories,toconvert
heterogeneoushumanvaluedata(e.g.,principlesorcontextualinformation)intoAI-compatibleformats(e.g.,scalars)
fortrainingrewardmodelsandguidingreinforcementlearning.Also,futureresearchcanexploreAImodelsthatcan
actdirectlyonaligninghumans’unstructureddata,suchasfree-formdescriptionsofvalues,multimediaorsensor
recordingsdepictinghowpeopleactinvarioussituations,amongothers.
6.1.2 AligningHumansto↦→AI:Elicitnuancedandcontextualhumanvaluesduringdiverseinteractions.
Currentalignmentmethodsprimarilycapturehumanvaluesusinginstructions,ratingsandrankings,aimingtoinfer
humans’alignmentgoals(e.g.,humanvaluesandintentions)inadata-drivenmanner.However,theselimiteddata
formatsandinteractionmethodsfallwellshortoffullyspecifyingalloftherelevanthumanvaluesandconstraints.
Besides,whenhumansseektocollaboratewithorutilizeAI,theyoftenencounterchallengesinformulatingoptimal
prompts,whichrequirethemtoaccuratelyandefficientlyspecifytheirrequirementsorexpectations,inordertobeable
touseAIgeneratedoutputordecisionmakinginpractice.Additionally,peopleoftenstruggletoarticulatealloftheir
desiredvaluesaccuratelyandcomprehensively,especiallyasthesevaluescandynamicallychangebasedoncontextual
andtemporalsituations.Relatedly,practicesoftenoverlookimplicithumaninteractivesignalsthatcanalsoindicate
valuesrelevanttoAIalignment.
ExamplesofPotentialFutureSolutions.Onepromisingareaforfutureresearchisoptimizinginteractiveinterfaces
toelicithumanvaluesefficientlyandeffectively.Theseinterfacescanleveragediverseinteractionmodes(seeaninitial
summaryinFigure9)tofullycapturehumanvalueinformation.Forexample,toidentifyasetofimportantprinciples
forAIalignment,theinterfacecanusetheuser’sconversationalnaturallanguagespecificationsandgeneratealist
ofprincipleoptionsforuserstoselectfromand/orrevise.Recognizingthathumanscannotalwayscomprehensively
articulatetheirvalues,anotherkeyresearchareaistodevelopinterfacesthatproactivelyinteractwithusers.Thiscould
involveconversationaltechniquesorscaffoldingprocedurestoelicitnuanced,contextualized,andevolvinginformation
aboutanindividual’svalues.Additionally,tocaptureimplicithumaninteractionsignalsthatreflecthumanvalues
forAIalignment,anotherareaoffutureworkinvolvesdesigningsystemsthattrackinteractionstodevelopreal-time
hypothesesabouthumanvaluesontheseimplicitsignals,andthenproactivelyvalidatethemwithhumansasneeded.
27Manuscript,submittedtoACM,2024 Shenetal.
6.2 Challenge2:DynamicCo-evolutionofAlignment
Thechallengeaheadliesincomprehendingandeffectivelynavigatingthedynamicinterplayamonghumanvalues,
societalevolution,andtheprogressionofAItechnologies.Futurestudiesinthesedirectionsaimtobolsterasynergistic
co-evolutionbetweenAIandhumansocieties,adaptingbothtoeachother’schangesandadvancements.
6.2.1 AligningAIto↦→Humans:Co-evolveAIwithchangesinhumansandsociety. Existingliteratureoften
viewsAIalignmentasastaticprocess,neglectingthedynamicnatureofalignmentgoals.However,along-term
perspectiveofalignmentrequiresustotakeintoaccounttheco-evolutionofAI,humans,andsociety.Ononehand,as
AIsystemsscaleup,theyregularlyacquirenewandsometimesunexpected("emergent")capabilities,includinglearning
fromexamplesontheflyandadaptivelypursuinggoals.ThisleadstothechallengeofensuringthatthegoalsAImight
independentlyformulateremainconsistentlyalignedwithhumanvalues.Consequently,alignmentsolutionsmust
involvecontinuousoversightandupdatesinresponsetoAI’sevolutionduringdevelopmentanddeployment.Onthe
otherhand,AIadvancementsinfluencethestateoftheworld,affectinghumanactionsandeventheirunderlyingvalues
andstrategies[143].Thus,alignmentsolutionsthatcontinuallyadapttotheupdatedhumanandsocietalconsiderations
mayofferthemostrobustapproach[161].Consequently,itiscrucialtoensurethatAIco-evolveswithchangesinhuman
andsocietalvalues,cognition,andneedsdynamically.
ExamplesofPotentialFutureSolutions.UpdatingAItocontinuouslyadapttothedynamicchangesofhumans
andsocietyrequiresadjustmentsinalignmentdata,models,andevaluationprocessesspanningbothlearningand
deploymentstages.ReferringtothemethodologieslistedinSection4.2,currentstrategiesoftenrelyonfine-tuning
toupdateAIwithacuratedhumanvaluedatasetduringthelearningprocess.However,thisapproachmayleadto
AImodelsforgettingordiminishingpreviousalignmentgoals.Insituationswheresufficientdataforfine-tuningis
unavailable,thesemethodsbecomesmorechallenging.Therefore,acrucialareaforfutureresearchistodevelop
approachesforcontinuallyupdatingAIsystemsusinglimiteddatawithoutcompromisingexistingalignmentvaluesand
performance.Inreal-worldscenarios,itiscommonforAIsystemstoalreadybedeployedatscale,makingfine-tuning
achallengingorimpracticalpractice.Therefore,anotherimportantresearchdirectioninvolvesadaptingAI,during
thedeploymentstage,withoutrelyingonfine-tuning.Thischallengecouldpotentiallybeaddressedbyforecasting
thepotentialevolutiontrajectoriesofhumanvaluesorbehavioralpatterns,andpreparingAIwiththeflexibilityto
adaptinadvance,forexample,throughpromptingorinterventionstrategies.Insummary,theco-evolutionofAIwith
dynamichumanandsocietalchangesnecessitatesasynergeticcollaborationamongexpertsfromvariousdomains,
suchasmachinelearningandsocialsciences.
6.2.2 AligningHumansto↦→AI:AdapthumansandsocietytothelatestAIadvancements. AsAIprogresses,
humanswilllikelyneedtotransitionfrominteractingwithlesscapablesystemstoengagingadvancedAIsystems(e.g.,
AGI)[271].It’simperativetodevelopinteractivestrategieswhichenablehumanstoeffectivelyutilizeAIacrossvarying
levelsofmodelcapability.WhilecurrentAIsystemsstilllagbehindhumanperformanceinmanytasks,questions
persistabouthumanresiliencetoAImistakes.Efficientlyidentifyingthesemistakesanddevelopingappropriatefallback
actions,suchasinteractiveintervention,remainscrucialinvarioussituations;identifyingandhandlingerrors,including
knowingwhentoseekhumanintervention,willremainanimportantevenforhighlycapablefuturesystems.Looking
ahead,asAIadvancesfurther,itbecomesessentialtodevelopinteractivesystemswhichenablehumanstoutilizeAI
thathascapabilitiessurpassingtheirown.Researchisneededtounderstandhowindividualscaninterpretandvalidate
theoutputsofAIperformingtasksbeyondtheircurrentabilities,andalso,howhumanscouldleverageadvancedAIin
28TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
asustainableway,i.e.,benefitingtheirlifewithoutharmfulsideeffectssuchasjobdisplacementorlossofpurpose.In
addition,asAIbecomesincreasinglyintegratedintodailytasks,itsinfluenceonhumanvalues,behaviors,capabilities,
andsocietyremainsuncertain.Thus,it’svitaltocontinuouslyexaminetheimpactofAIadvancementsonindividuals,
socialrelationships,andbroadersocietalchanges.
ExamplesofPotentialFutureSolutions.WhilepriorAIassistantshaveprimarilyaimedtocomplementhuman
capabilities in task performance, future research on advanced AI systems should focus on developing validation
mechanismsthatenablehumanstointerpretandverifyAIoutputs.InspiredbyinitialexplorationsinSection4.4.1,
thiscouldinvolvedesigninginteractiveinterfacesthatallowhumanstorequeststep-by-stepjustificationsfromAI,or
integratingexternaltoolstoverifythetruthfulnessofAIoutputs.Thiscouldalsoincludedevelopinginterfacesthat
enablegroupsofhumanstoworktogethertovalidateAIoutputs,sincegroupsworkingjointlytypicallyhavebroader
anddeeper"intelligence"inpracticethananysingleactor).Further,thisapproachcanbeextendedtoscalablevalidation
tools,automatingtheverificationprocessforlarge-scaleapplicationssuchasineducationandtheworkplace.Another
importantresearchdirectionisdesigninginteractivestrategiestoenhancehumancapabilitiesbylearningfromadvanced
AI.Thisincludesgainingknowledgeandbuildingtechnicalandsocialskills.Furthermore,itiscrucialtoassesshow
humansandsocietyadapttoAIadvancementswhich,inturn,canguidethefutureevolutionofAI.Potentialresearch
areasincludeevaluatingchangesinindividualbehaviorandsocialrelationships(e.g.,howrelationshipswithadvanced
AImaysupplanthumanrelationships),andsocietalgovernance(e.g.,howlegalandeducationsystemsmaychangeas
AIisusedinplaceoftraditionalhumanskills).Examiningthesedynamicchangesisessentialforunderstandingthe
broaderimpactofAIadvancementsonhumanityandsociety.
6.3 Challenge3:SafeguardingCo-adaptation
AsAIgainsautonomyandcapability,therisksassociatedwithitsinstrumentalactions,asameanstowardaccomplishing
itsfinalgoals,increase.Theseactionscanbeundesirableforhumans,i.e.,power-seekingorevadinghumanintervention.
Therefore,safeguardingtheco-adaptationbetweenhumansandAIiscrucial.Thiscanbeachievedbyempowering
humanstounderstandandcontrolAI’sinstrumentalgoals,inordertoensurerationalandethicalbehaviors.Wenext
explorefutureresearchtoaddressthischallengefrombothdirections.
6.3.1 AligningAIto↦→Humans:SpecifythegoalsofanAIsystemintointerpretableandcontrollable
instrumentalactionsforhumans. AsadvancedAIsystemsbecomeincreasinglycomplex,theypresentgreater
challengesforhumaninterpretationandcontrol.Toaddressthis,itiscrucialtoempowerhumanstodetectandinterpret
AImisconductoninstrumentalactionstowardsaccomplishingitsfinalgoals.Additionally,mechanismsmustbedeveloped
to enable human intervention and prevent power-seeking AI misconduct, thus maintaining a safe co-adaptation
betweenAIandhumans.Furthermore,advancedAIsystems,evenwithsufficientinterpretationcapabilities,may
intentionallymisleadordisobeyhumans.ItispossibleforAItostandbyfalsehoods,generateemptyexplanations
fortheiranswers,andproduceoutrightfabricationsthatmayappearplausible[173].Therefore,developingreliable
interpretabilitymechanismstovalidatethefaithfulnessandhonestyofAIsystems’self-reportedbehaviorsisalsoessential.
ExamplesofPotentialFutureSolutions.Onepotentialresearchareaaimedatempoweringhumanstointerpret
andcontroladvancedAIbehavioristhedesignofcorrigiblemechanismsthatfacilitateeasyinterventionandcorrection.
ThisincludesdevelopingmodularAIarchitectureswherecomponentscanbeindependentlyadjustedorreplaced,and
creatingrobustoverrideprotocolsthatallowhumanoperatorstosafelyhaltorredirectAIactivities.Thesecomponents
shouldideallybehuman-interpretable,enablingsupervisorstoconductscenariotestingwhennecessary.Another
29Manuscript,submittedtoACM,2024 Shenetal.
criticalresearchdirectionliesinvalidatingthefaithfulnessandhonestyofAIinterpretability.Thiscouldinvolve
correlatingAIbehaviorswithinternalneuronactivitysignals,similartohowphysiologicalindicatorsaremeasuredin
humanpolygraphtests[14].Inspectinginternalneuronindicatorscouldsupporthumanassessmentofthetruthfulness
ofAIinterpretations,therebyallowingthemtoaccuratelyjudgeandpreventpotentialriskyinstrumentalactions.
6.3.2 AligningHumansto↦→AI:EmpowerhumanstoidentifyandinterveneinAIinstrumentalandfinal
strategiesincollaboration. PreventingfutureadvancedAIsystemsfromengaginginriskyinstrumentalactions
requires human capabilities to identify and mitigate such behaviors. Additionally, scalable solutions that can be
widelyimplementedareessentialforeffectivelysupervisingAIinstrumentalbehavioracrossvariousapplicationsand
environments.Futureresearchcouldpotentiallyexplorecomprehensivetrainingprogramsandthedevelopmentof
advanceddiagnostictoolstoachievethesegoals.
ExamplesofPotentialFutureSolutions.ToenhancehumancapabilityinsupervisingAIinstrumentalactions,
robusttrainingandsimulationenvironmentsareessential.Theseshouldofferscenario-basedtrainingwithtimely
feedbackloops,enablingsupervisorstoidentifyandmanagevariousinstrumentalactionseffectively.Additionally,
creatinginteractiveandintuitivedashboardsiscrucialforquicklyrecognizingandrespondingtopotentialrisky
instrumentalgoals.Thesedashboardsshouldincludeeffectivedataandmodelvisualization,interventiontechniquesto
highlightanomalies,andreal-timealertsforpromptintervention.Furthermore,asdeployingadvancedAIatscalemakes
real-timeoversightmorechallenging,developingadvancedandautonomousmonitoringtoolsisvital.Thesetools
shouldlearnthenormaloperatingparametersofAIsystems,flaggingdeviationsthatsuggestriskyinstrumentalactions
immediately.Byintegratingtrainingandsimulationenvironments,interactivedashboards,andscalablediagnostic
tools,humanscanbettermanageAIinstrumentalrisks,supportingbetteralignmentwithhumanvaluesandcontrol.
7 IMPLICATIONSANDLIMITATIONS
Inthissection,weprovideasummaryofthekeyimplicationsofourproposedframework,anddiscussthechallenges
andlimitationsweencounteredduringthesystematicliteraturereviewprocess.
7.1 FrameworkImplicationsandApplications
7.1.1 Cross-domaininspirations. Achievinglong-termhuman-AIalignmentrequiresholistic,interdisciplinary
efforts.Thispaperintroducesabidirectionalhuman-AIalignmentframeworktocreateasharedvocabularyamong
diversefields.Supportedbyover400multi-domainresearchpapers,thisframeworkenablesresearcherstointegrate
knowledgefromotherdomains,enhancingtheirworkandfosteringsynergeticcollaboration.Particularly,AI
researcherscanusethehumanvaluetaxonomygroundedinpsychologicaltheories(e.g.,Section5.2)todevelopdatasets
andalgorithmsthatincorporateabroaderspectrumofhumanvalues.Additionally,byexaminingstudiesonindividual
andsocietaladaptationstoAIalignment(e.g.,Section4.4.2),AIdeveloperscancreatemorepracticalandadaptiveAI
systemsthatevolvealongsidehumanandsocietalchanges.Conversely,HCIandsocialscienceresearcherscanleverage
customizableAIalignmentalgorithms(e.g.,Section4.2)todesigninteractivesystemsthatimprovehumaninteraction
withAI.Byusinginteractiontechniquestospecifyhumanvalues(Section4.1),theseresearcherscanoptimizeinterfaces
orconductsurveystoextracthumanvalues,informingAIalignmentdevelopment.
7.1.2 FoundationofDynamicAlignmentEvolution. Theproposedbidirectionalhuman-AIalignmentframework
alsoservesafoundationalroletosupportresearcherstoaddresstheoutlinedfuturechallengesandachieve
long-termalignment.AselaboratedinSection6,withineachdirection,researcherscanpotentiallyaddressfuture
30TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
challengesonthebasisofexistingalignmentstudiesorganizedbytheframework.Forinstance,totacklethespecification
game,futureAIresearcherscanusethecomprehensivehumanvaluetaxonomyoutlinedintheframework(Section6)
todevelopmethodsforselectingtheappropriatesubsetofthesehumanvaluestobeintegratedintoAIalignment.
Additionally,weemphasizetheimportanceofsynergizingbothdirectionstoachievelong-termbidirectionalhuman-
AIalignment.Tofacilitatedynamicco-evolution(Section6.2),weadvocateforcollaborationamongAI,HCI,and
socialscientiststomeasurehumanandsocietaladaptationsandincorporatethesechangesintothealignmentof
next-generationAIsystems.ThisholisticapproachcancontributetotheevolutionofAIinharmonywithhumanvalues
andsocietalneeds.
7.2 Limitations
Onelimitationofthisworkisthecoverageofthesampledandfilteredpapers.Theliteraturerevolvingaroundthetopic
ofhuman-AIalignmentisincreasingrapidly,scatteringindiversevenuesacrossmanydomains.Therefore,insteadof
strivingforanexhaustivecollectionofpapers,thisworkfocusedondevelopingaholisticloopofbidirectionalhuman-AI
alignmentframeworkbyusingessentialresearchquestions,dimensionsandcodes.Additionally,weareawarethatour
surveyedpapersandthepositionofourteammembersprimarilyfocusoncomputing-relateddomains,suchasML,NLP,
andHCI.Thereareadditionaldisciplinesinvolvedinalignmentresearch,suchascognitivescience,psychology,andSTS
(Science,Technology,andSociety).However,ourframeworkcannaturallyextendtothesedomainsbyincorporating
themintotheappropriatedirections.Despitetheselimitations,wearguethatthisbidirectionalhuman-AIalignment
frameworkservesasfoundationalreferenceforfutureresearchersexaminingexistingliteraturethatliesintheholistic
loopofthealignmentprocess,whilepreventingimplicitassumptionsoroverlookedconsiderations,therebyfacilitating
aholisticunderstandingofthedimensionsandfactorsthatdrivethedevelopingofAItechnologyandhumanimpacts.
Forfuturework,weplantocontinuetorefineourdimensionsandcodestoincorporatefutureliteraturerelevanttothe
bidirectionalhuman-AIalignmentprocess.
8 CONCLUSION
Inconclusion,thisstudyclarifiesthedefinitionsandscopeofcoreterminologiesofhuman-AIalignmentandconducts
asystematicreviewofover400relatedpapersspanningdiversedomainssuchasNLP,AI,HCI,andsocialscience.
Additionally,weintroduceanovelconceptualframeworkof“BidirectionalHuman-AIAlignment”,structuringthe
surveyedliteraturetaxonomiesinto“aligningAItohumans”and“aligninghumanstoAI”withdetailedcategoriesand
examplepapers.Furthermore,weidentifylimitationsandrisksinthisareaquantitativelyandqualitatively,analyzing
afine-grainedhumanvaluetaxonomy,interactionmodesforalignment,anddiscrepanciesbetweenAIandhuman
evaluation.Topavethewayforfuturestudies,wediscussfivestagestoachievethealignmentgoalsfromnear-termto
long-termperspectivesandidentifynewpossibilitiestohighlightfuturedirectionsandopportunitiesinresearch.
ACKNOWLEDGMENTS
WethankEricGilbertforhisconstructivefeedbackonhuman-centeredinsightsonalignment,thankEytanAdarforhis
valuableguidanceondesigningtheinteractiontechniquesforhuman-AIalignment,andthankElizabethF.Churchill
forherinsightfuldiscussiononthismanuscript.WealsothankMichaelSBernstein,DennyZhou,CliffLampe,and
NicoleEllisonfortheirencouragingfeedbackonthiswork.Wewelcomeresearchers’constructivediscussionsand
interdisciplinaryeffortstoachievelong-termanddynamichuman-AIalignmentcollaborativelyinthefuture.
31Manuscript,submittedtoACM,2024 Shenetal.
APPENDIX
A AUTHORCONTRIBUTIONS
Thisprojectwasateameffort,builtoncountlesscontributionsfromeveryoneinvolved.Toacknowledgeindividual
authors’contributionsandenablefutureinquiriestobedirectedappropriately,wefollowedtheACM’spolicyon
authorship[279]andlistedcontributorsforeachpartofthepaperbelow.
A.1 OverallAuthorListandContributions
ProjectLead
Theprojectleadinitializedandorganizedtheproject,coordinatedwithallauthors,participatedintheentiremanuscript.
• HuaShen(UniversityofMichigan,huashen@umich.edu):Initiatedandledtheoverallproject,prepared
weeklyprojectmeetings,filteredpapers,designeddimensionsandcodes(initial,revision),codedallpapers,
initiatedtheframeworkanddevelopedhumanvalueandinteractionmodesanalysisfigures,participatedin
draftingallsections,paperrevisionandpolishing.
TeamLeads
Theteamleadsorganizedallteamevents,coordinatedwithleadsandmembers,contributedtoaportionofmanuscript.
• TiffanyKnearem(Google,tknearem@google.com):LedtheHCIteam,preparedweeklyteammeetings,
filteredpapers,designeddimensionsandcodes(initial,revision),codedpartialpapers,ideatedtheframeworkand
analysisandfutureworkcontent,participatedinwriting(CriticalThinkingandAIImpactonHumansections),
paperrevisionandpolishing.
• ReshmiGhosh(Microsoft,reshmighosh@microsoft.com):LedtheNLP/AIteam,preparedweeklyteam
meetings,filteredpapers,codedpartialpapers,ideatedtheframeworkandanalysisandfutureworkcontent,
participatedinwriting(AIevaluationsection),paperrevisionandpolishing.
TeamMembers(Alphabetical)
Theteammemberscontributedtoaportionofpaperreview,regulardiscussions,anddraftedaportionofthemanuscript.
• KenanAlkiek(UniversityofMichigan,kalkiek@umich.edu):filteredpapers,codedpartialpapers,data
processingandanalysis,ideatedpaperanalysisandfuturework,paperrevisionandpolishing,mainlyinvolved
inNLPTeam
• KundanKrishna(CarnegieMellonUniversity,kundank@andrew.cmu.edu):filteredpapers,codedpartial
papers,ideatedtheframeworkandfuturework,participatedinwriting(CustomizingAIsection),designed
dimensionsandcodes(initial,revision),paperrevisionandpolishing,mainlyinvolvedinNLPTeam
• YachuanLiu(UniversityofMichigan,yachuan@umich.edu):filteredpapers,codedpartialpapers,par-
ticipatedinwriting(revisedIntegrateGeneralValueandCustomizationcontentsections),paperrevisionand
polishing,mainlyinvolvedinNLPTeam
• ZiqiaoMa(UniversityofMichigan,marstin@umich.edu):filteredpapers,codedpartialpapers,designed
dimensionsandcodes(initial,revision),developedHumanValuecategory,participatedinwriting(HumanValue
taxonomy,revisedrepresentation,andvaluegapanalysissections),paperrevisionandpolishing,mainlyinvolved
inNLPTeam
32TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
• SavvasPetridis(GooglePAIR,petridis@google.com):filteredpapers,codedpartialpapers,ideatedthe
interaction-relatedanalysisandfuturework,participatedinwriting(PerceiveandUnderstandAI),paperrevision
andpolishing,mainlyinvolvedinHCITeam
• Yi-HaoPeng(CarnegieMellonUniversity,yihaop@cs.cmu.edu):filteredpapers,codedpartialpapers,
participatedinwriting(Human-AICollaborationsection),paperrevisionandpolishing,mainlyinvolvedinHCI
Team
• Li Qiwei (University of Michigan, rrll@umich.edu): filtered papers, coded partial papers, ideated the
interaction-relatedtaxonomyandanalysis,participatedinwriting(InteractionModesection),mainlyinvolved
inHCITeam
• SushritaRakshit(UniversityofMichigan,sushrita@umich.edu):filteredpapers,codedpartialpapers,
participatedinwriting(IntegrateGeneralValuesection),paperrevisionandpolishing,mainlyinvolvedinNLP
andHCITeam
• ChengleiSi(StanfordUniversity,clsi@stanford.edu):filteredpapers,codedpartialpapers,designeddimen-
sionsandcodes(initial,revision),ideatedtheframeworkandfuturework,participatedinwriting(Assessmentof
CollaborationandImpactsection),paperrevisionandpolishing,mainlyinvolvedinHCITeam
• YutongXie(UniversityofMichigan,yutxie@umich.edu):filteredpapers,codedpartialpapers,designed
dimensionsandcodes(initial,revision),ideatedthevaluerepresentationtaxonomy,participatedinwriting
(HumanValueRepresentationsection),paperrevisionandpolishing,,mainlyinvolvedinNLPTeam
Advisors(Alphabetical)
Theadvisorsinvolvedinandmadeintellectualcontributionstoessentialcomponentsoftheprojectandmanuscript.
• JeffreyP.Bigham(CarnegieMellonUniversity,jbigham@cs.cmu.edu):contributedtotheframeworkon
aligninghumantoAIdirection,visiononthestatusquoofalignmentresearch,andfutureworkdiscussions,and
participatedinpaperrevisionandproofreading.
• FrankBentley(Google,fbentley@google.com):contributedtothehistoricalcontextandprojectobjectives,
improvedthedefinitionsanddesignofresearchmethodology,andparticipatedinpaperrevisionandproofreading.
• JoyceChai(UniversityofMichigan,chaijy@umich.edu):iterativelyinvolvedindevelopingandrevising
definitionsandtheframeworkonaligningAItohumandirection,advisedonanalysisandfuturework,and
participatedinpaperrevisionandproofreading.
• ZacharyLipton(CarnegieMellonUniversity,zlipton@cmu.edu):contributedinsightsfromMachine
Learning,NLP,andAIfieldstorevisethedefinitionsandframeworkonaligningAItohumandirection,and
participatedinpaperrevisionandproofreading.
• QiaozhuMei(UniversityofMichigan,qmei@umich.edu):contributedinsightsfromDataScience,Machine
Learning,andNLPfieldstoimprovedefinitionsandtheframeworkonaligningAItohumandirection,and
participatedinpaperrevisionandproofreading.
• RadaMihalcea(UniversityofMichigan,mihalcea@umich.edu):involvedinframingandrevisingthe
structureandtaxonomyofhumanvalues,andcontributedtoimprovingthemanuscript’stitle,introduction,and
othersections,andparticipatedinpaperrevisionandproofreading.
• MichaelTerry(GoogleResearch,michaelterry@google.com):contributedargumentsandvisiononthe
statusquoofalignmentresearch,framedprojectobjectivesandcontributions,improveddefinitionsanddata
analysis,andparticipatedinpaperrevisionandproofreading.
33Manuscript,submittedtoACM,2024 Shenetal.
• DiyiYang(StanfordUniversity,diyiy@stanford.edu):involvedinimprovingdefinitionsandtheframework,
contributedsocialinsightstothework,andparticipatedinpaperrevisionandproofreading.
ProjectLeadingAdvisors
Theprojectleadingadvisorsactivelyinvolvedintheentireprojectprocessandallmanuscriptsections.
• MeredithRingelMorris(GoogleDeepMind,merrie@google.com):iterativelyinvolvedindraftingall
sections,contributedtocoreargumentideation,frameworkanddefinitionimprovement,providedfuturework
insights,andparticipatedinpaperdrafting,revision,andproofreadingonallsections.
• PaulResnick(UniversityofMichigan,presnick@umich.edu):activelyinvolvedandadvisedontheentire
projectprocess,includinginitiatingtheprojectandresearchagenda,iterativelyimproveddefinitions,framework,
andanalysis,andparticipatedinpaperrevisionandproofreading.
• DavidJurgens(UniversityofMichigan,jurgens@umich.edu):providedadvicethroughouttheproject,
includingiterativediscussionsonprojectmilestonesandcontentideation,organizedseveralmeetingstoreceive
feedbackfromexternalaudiences,andparticipatedinpaperrevisionandproofreading.
B SYSTEMATICLITERATUREREVIEW
B.1 Venues
WeprimarilyfocusedonpapersfromthefieldsofHCI,NLP,andMLrangingfromyear2019to2024January.We
includedalltheirpaperstracks(e.g.,CSCWCompanionandFindings)withoutincludingworkshopsofconferences.
FromtheACLAnthology,OpenReviewandACMDigitalLibrary,weretrieved34,190papersintoaReferenceManager
Tool(i.e.,Paperpile).Particularly,thevenueswesurveyedarelistedbelow.
• HCI:CHI,CSCW,UIST,IUI;
• NLP:ACL,EMNLP,NAACL,Findings
• ML:ICLR,NeurIPS
• Others:ArXiv,FAccT,AIES,andotherrelatedwork
Additionally,wealsoconsolidatetheframeworkbyreviewingthepaperspublishedinFAccTandAIES(i.e.,important
venuesforAIEthicsresearch)between2019and2024andsupplementedthecodes,includingtheAIRegulatoryand
PolicycodeinSection4.4.2andtheexemplarypaperofRegulatingChatGPT[130]),whichwerenotcoveredbythe
originalcollections.Also,weincludeanumberofpapersinthe“Other”classarefoundbyrelatedworkthatarehighly
relevanttothistopic.
B.2 Keywords
Wedecidedonalistofkeywordsrelevanttobidirectionalhuman-AIalignment.Thedetailedkeywordsinclude:
• Human:Human,User,Agent,Cognition,Crowd
• AI:AI,Agent,MachineLearning,NeuralNetwork,Algorithm,Model,DeepLearning,NLP
• LLM:LargeLanguageModel,LLM,GPT,Generative,In-contextLearning
• Alignment:Align,Alignment
• Value:Value,Principle
• Trust:Trust,Trustworthy
• Interact:Interact,Interaction,Interactive,Collaboration,Conversational
34TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
• Visualize:Visualization,Visualize
• Explain:Interpretability,Explain,Understand,Transparent
• Evaluation:Evaluate,Evaluation,Audit
• Feedback:Feedback
• Ethics:Bias,Fairness
B.3 InclusionandExclusionCriteria
Tofurtherfilterthemostrelevantpapersamongthekeyword-filtered2136papers,weidentifiedthesixmostimportant
researchquestionsweareinterestedin.Weprimarilyselectedthepotentialpapersthatcanpotentiallyaddressthese
sixquestionsafterreviewingtheirtitleandabstracts.Thesixtopicsofresearchquestionsinourfilteringinclude:
RQ.1 [humanvaluecategory]WhatessentialhumanvalueshavebeenalignedbysomeAImodels?
RQ.2 [quantifyhumanvalue]HowdidweeffectivelyquantifyormodelhumanvaluestoguideAIdevelopment?
RQ.3 [integratehumanvalueintoAI]WhatstrategieshavebeenemployedtointegratehumanvaluesintotheAI
developmentprocess?
RQ.4 [assess/explainAIregardinghumanvalues]Howdidexistingstudiesimprovehumanunderstandingand
evaluationofAIalignment?
RQ.5 [human-AIinteractiontechniques]Whatarethepracticesfordesigninginterfacesandinteractionsthat
facilitatehuman-AIcollaboration?
RQ.6 [adaptAIfordiversehumanvalues]HowhasAIbeenadaptedtomeettheneedsofvarioushumanvalue
groups?
Particularly,weprovideelaboratedinclusionandexclusioncriteriaduringourpaperselectionaslistedbelow.We
areawarethatwehavelimitationsduringourpaperfilteringprocess.
InclusionCriteria:
• [Humanvalues] weincludepapersthatstudyhumanvaluedefinition,specificationandevaluationinAI
systems.
• [AIdevelopmenttechniques]WeincludetechniquesofdevelopingAIthataimtobemoreconsistentwith
humanvalueswithinteractionsalongallAIdevelopmentstages(e.g.,datacollection,modelconstruction,etc.)
• [AIevaluation,explanationandutilization]weincludepapersthatbuildhuman-AIinteractivesystemsor
conducthumanstudiestobetterevaluate,explain,andutilizeAIsystems.
• [buildingdatasetwithhumaninteraction]especiallyresponsibledataset.
ExclusionCriteria:
• [Alignmentnotbetweenhuman&AI]wedonotincludealignmentstudiesthatarenotbetweenhuman
andAI,suchasentityalignment,cross-lingualalignment,cross-domainalignment,multi-modalalignment,
token-environmentalignment,etc.
• [AImodelsbeyondLLMs-Modality]wedonotfocusonAImodelsotherthanLLMs(e.g.,3Dmodels,VR/AR,
voiceassistant,spokenassistant),ourprimarymodelmodalityistext.Specifically,wedonotconsideraudio/
videodata;wedonotconsiderpurecomputervisionmodality.
• [No human-AI interaction] we do not consider studies that do not involve the interaction between hu-
manandAI,suchas(multi-agent)reinforcementlearning.Specifically,wedonotconsiderinteractionsvia
35Manuscript,submittedtoACM,2024 Shenetal.
voices/speech,Donotconsidergameinteraction;DonotconsiderinteractionforAccessibility;Donotconsider
Mobileinteraction;Notconsiderautonomousvehicleinteractionwearabledevices,orPhysicalinteraction;
• [Tasks]artanddesign,emotion.
• [Nohumanincluded]
• [focusonEnglish]primarilyfocusonEnglishasthemainlanguage;
• [Application] notincludetheNLPpaperstailoredforaspecifictraditionaltask,suchastranslation,entity
recognition,sentimentanalysis,knowledgegraph,adversarialanddefense,topicmodeling,detectingAIgen-
erations,distillation,lowresource,physicalrobots,textclassification,games,image-basedtasks,hatespeech
detection,HumanTrafficking,etc.
• [VisualizingEmbeddings]Visualizing/interactingtransformerembeddings?
• [Embedding-based]explanation,evaluation,etc.
• [multi-agentreinforcementlearningwithself-playandpopulationplay]techniques,suchasself-play
(SP)orpopulationplay(PP),produceagentsthatoverfittotheirtrainingpartnersanddonotgeneralizewellto
humans.
B.4 CollectedMainPapers
• HCI:[4,11,12,19–21,23,25,30,34,37–42,47,52,53,57–59,63,65,66,68,69,73–75,79,81,90,98,102,105,109,112,
115,124,128,132,135–137,139,142,144,145,148,156,163–165,169,170,172,175,179,181,185,192,193,198,204–
206,211–213,215,217,226,228,229,231,232,234,241,244,250,253,257,260,262,264,267,269,270,274,290,
291,300,302–305,313,317–319,325,329,330,340,352,355–358,361,363,371,374,384,390–393,400–402,406–
408,413–415,422,423,425,430,431,433,436–438,445,445,451,452,461,465,468,471,472,474,475,479]
• NLP/AI
[2,5,8,18,22,28,29,31,35,43,44,46,48,49,51,54,55,60,64,67,71,72,77,80,82–88,91–97,99,100,107,
108, 110, 111, 113, 114, 117–119, 121, 125–127, 129, 134, 138, 143, 146, 147, 150, 152–154, 158, 159, 162, 166–
168, 171, 174, 176–178, 183, 186–191, 196, 197, 202, 203, 207, 214, 216, 218–224, 227, 230, 235–240, 242, 245–
247,249,251,252,255,258,259,261,263,266,268,273,275–278,280–284,286,292–294,296,299,306,309,310,
312,314–316,320,321,327,328,332,336,337,339,342,344–346,349–351,353,354,359,365,367–369,372,373,375–
377,379–382,385,386,394,395,397–399,403,404,409,411,412,416,418,419,426,427,434,439–441,443,444,446–
450,453,454,457–459,462–464,466,467,469,470,473,477,478,480,482–484]
• Others[3,10,13,15–17,50,56,106,130,155,180,182,194,201,225,233,256,272,297,298,301,326,331,338,
341,343,347,360,370,378,417,420,455,460,476,481,485]
36TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
REFERENCES
[1] 2023.Humansarebiased.GenerativeAIisevenworse. https://www.bloomberg.com/graphics/2023-generative-ai-bias/
[2] AfraFeyzaAkyürek,EkinAkyürek,AshwinKalyan,PeterClark,DerryTantiWijaya,andNiketTandon.2023.RL4F:GeneratingNaturalLanguage
FeedbackwithReinforcementLearningforRepairingModelOutputs.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputational
Linguistics(Volume1:LongPapers).7716–7733.
[3] BadrAlKhamissi,MuhammadElNokrashy,MaiAlKhamissi,andMonaDiab.2024.InvestigatingCulturalAlignmentofLargeLanguageModels.
arXivpreprintarXiv:2402.13231(2024).
[4] SaleemaAmershi,DanWeld,MihaelaVorvoreanu,AdamFourney,BesmiraNushi,PennyCollisson,JinaSuh,ShamsiIqbal,PaulNBennett,Kori
Inkpen,etal.2019.Guidelinesforhuman-AIinteraction.InProceedingsofthe2019chiconferenceonhumanfactorsincomputingsystems.1–13.
[5] PrithvirajAmmanabrolu,LiweiJiang,MaartenSap,HannanehHajishirzi,andYejinChoi.2022.AligningtoSocialNormsandValuesinInteractive
Narratives.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguage
Technologies.5994–6017.
[6] DarioAmodei,ChrisOlah,JacobSteinhardt,PaulChristiano,JohnSchulman,andDanMané.2016.ConcreteproblemsinAIsafety.arXivpreprint
arXiv:1606.06565(2016).
[7] UsmanAnwar,AbulhairSaparov,JavierRando,DanielPaleka,MilesTurpin,PeterHase,EkdeepSinghLubana,ErikJenner,StephenCasper,Oliver
Sourbut,etal.2024.FoundationalChallengesinAssuringAlignmentandSafetyofLargeLanguageModels.arXivpreprintarXiv:2404.09932(2024).
[8] AkshathaArodiandJackieChiKitCheung.2021. Textualtimetravel:Atemporallyinformedapproachtotheoryofmind.InFindingsofthe
AssociationforComputationalLinguistics:EMNLP2021.4162–4172.
[9] KennethJArrow.2012.Socialchoiceandindividualvalues.Vol.12.Yaleuniversitypress.
[10] JoshuaAshkinaze,JuliaMendelsohn,LiQiwei,CerenBudak,andEricGilbert.2024.HowAIIdeasAffecttheCreativity,Diversity,andEvolutionof
HumanIdeas:EvidenceFromaLarge,DynamicExperiment.arXivpreprintarXiv:2401.13481(2024).
[11] ZahraAshktorab,BenjaminHoover,MayankAgarwal,CaseyDugan,WernerGeyer,HaoBangYang,andMikhailYurochkin.2023. Fairness
EvaluationinTextClassification:MachineLearningPractitionerPerspectivesofIndividualandGroupFairness.InProceedingsofthe2023CHI
ConferenceonHumanFactorsinComputingSystems.1–20.
[12] ZahraAshktorab,QVeraLiao,CaseyDugan,JamesJohnson,QianPan,WeiZhang,SadhanaKumaravel,andMurrayCampbell.2020.Human-ai
collaborationinacooperativegamesetting:Measuringsocialperceptionandoutcomes.ProceedingsoftheACMonHuman-ComputerInteraction4,
CSCW2(2020),1–20.
[13] AmandaAskell,YuntaoBai,AnnaChen,DawnDrain,DeepGanguli,TomHenighan,AndyJones,NicholasJoseph,BenMann,NovaDasSarma,
etal.2021.Agenerallanguageassistantasalaboratoryforalignment.arXivpreprintarXiv:2112.00861(2021).
[14] AmericanPsychologicalAssociationetal.2004. Thetruthaboutliedetectors(akapolygraphtests). Recuperadode:https://www.apa.
org/topics/cognitive-neuroscience/polygraph(2004).
[15] ShubhamAtreja,LibbyHemphill,andPaulResnick.2023.Remove,Reduce,Inform:WhatActionsdoPeopleWantSocialMediaPlatformstoTake
onPotentiallyMisleadingContent?ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–33.
[16] YuntaoBai,AndyJones,KamalNdousse,AmandaAskell,AnnaChen,NovaDasSarma,DawnDrain,StanislavFort,DeepGanguli,TomHenighan,
etal.2022.Trainingahelpfulandharmlessassistantwithreinforcementlearningfromhumanfeedback.arXivpreprintarXiv:2204.05862(2022).
[17] YuntaoBai,SauravKadavath,SandipanKundu,AmandaAskell,JacksonKernion,AndyJones,AnnaChen,AnnaGoldie,AzaliaMirhoseini,
CameronMcKinnon,etal.2022.Constitutionalai:Harmlessnessfromaifeedback.arXivpreprintarXiv:2212.08073(2022).
[18] MichielBakker,MartinChadwick,HannahSheahan,MichaelTessler,LucyCampbell-Gillingham,JanBalaguer,NatMcAleese,AmeliaGlaese,John
Aslanides,MattBotvinick,etal.2022.Fine-tuninglanguagemodelstofindagreementamonghumanswithdiversepreferences.AdvancesinNeural
InformationProcessingSystems35,38176–38189.
[19] JackBandy.2021.Problematicmachinebehavior:Asystematicliteraturereviewofalgorithmaudits.Proceedingsoftheacmonhuman-computer
interaction5,CSCW1(2021),1–34.
[20] NikolaBanovic,ZhuoranYang,AdityaRamesh,andAliceLiu.2023.Beingtrustworthyisnotenough:Howuntrustworthyartificialintelligence
(ai)candeceivetheend-usersandgaintheirtrust.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),1–17.
[21] GaganBansal,TongshuangWu,JoyceZhou,RaymondFok,BesmiraNushi,EceKamar,MarcoTulioRibeiro,andDanielWeld.2021.Doesthe
wholeexceeditsparts?theeffectofaiexplanationsoncomplementaryteamperformance.InProceedingsofthe2021CHIconferenceonhuman
factorsincomputingsystems.1–16.
[22] HritikBansal,JohnDang,andAdityaGrover.2023.PeeringThroughPreferences:UnravelingFeedbackAcquisitionforAligningLargeLanguage
Models.(2023).
[23] LanthaoBenedikt,ChaitanyaJoshi,LouisaNolan,RubenHenstra-Hill,LukeShaw,andSharonHook.2020.Human-in-the-loopAIingovernment:
Acasestudy.InProceedingsofthe25thInternationalConferenceonIntelligentUserInterfaces.488–497.
[24] YoshuaBengio,GeoffreyHinton,AndrewYao,DawnSong,PieterAbbeel,TrevorDarrell,YuvalNoahHarari,Ya-QinZhang,LanXue,Shai
Shalev-Shwartz,etal.2024.ManagingextremeAIrisksamidrapidprogress.Science(2024),eadn0117.
[25] DanBennett,OussamaMetatla,AnneRoudaut,andElisaDMekler.2023.HowdoesHCIunderstandhumanagencyandautonomy?.InProceedings
ofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–18.
37Manuscript,submittedtoACM,2024 Shenetal.
[26] LeonardBereskaandEfstratiosGavves.2024.MechanisticInterpretabilityforAISafety–AReview.arXivpreprintarXiv:2404.14082(2024).
[27] MichaelSBernstein,GregLittle,RobertCMiller,BjörnHartmann,MarkSAckerman,DavidRKarger,DavidCrowell,andKatrinaPanovich.
2010.Soylent:awordprocessorwithacrowdinside.InProceedingsofthe23ndannualACMsymposiumonUserinterfacesoftwareandtechnology.
313–322.
[28] MarcelBinzandEricSchulz.2023.Turninglargelanguagemodelsintocognitivemodels.InTheTwelfthInternationalConferenceonLearning
Representations.
[29] BenediktBoecking,WillieNeiswanger,EricXing,andArturDubrawski.2020.InteractiveWeakSupervision:LearningUsefulHeuristicsforData
Labeling.InInternationalConferenceonLearningRepresentations.
[30] AngieBoggust,BenjaminHoover,ArvindSatyanarayan,andHendrikStrobelt.2022.Sharedinterest:Measuringhuman-aialignmenttoidentify
recurringpatternsinmodelbehavior.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–17.
[31] HelenaBonaldi,SaraDellantonio,SerraSinemTekiroğlu,andMarcoGuerini.2022.Human-MachineCollaborationApproachestoBuildaDialogue
DatasetforHateSpeechCountering.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.8031–8049.
[32] Jean-FrançoisBonnefon,AzimShariff,andIyadRahwan.2016.Thesocialdilemmaofautonomousvehicles.Science352,6293(2016),1573–1576.
[33] NickBostrom.2020.Ethicalissuesinadvancedartificialintelligence.MachineEthicsandRobotEthics(2020),69–75.
[34] KarenLBoyd.2021.DatasheetsfordatasetshelpMLengineersnoticeandunderstandethicalissuesintrainingdata.ProceedingsoftheACMon
Human-ComputerInteraction5,CSCW2(2021),1–27.
[35] HerbieBradley,AndrewDai,HannahTeufel,JennyZhang,KoenOostermeijer,MarcoBellagente,JeffClune,KennethStanley,GrégorySchott,and
JoelLehman.2024.Quality-diversitythroughAIfeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[36] RichardBrath.2021.SurveyingWonderlandformanymoreliteraturevisualizationtechniques.arXivpreprintarXiv:2110.08584(2021).
[37] ZanaBuçinca,MajaBarbaraMalaya,andKrzysztofZGajos.2021.Totrustortothink:cognitiveforcingfunctionscanreduceoverrelianceonAIin
AI-assisteddecision-making.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW1(2021),1–21.
[38] FedericoCabitza,AndreaCampagner,RiccardoAngius,ChiaraNatali,andCarloReverberi.2023.AIshallhavenodominion:onhowtomeasure
technologydominanceinAI-supportedhumandecision-making.InProceedingsofthe2023CHIconferenceonhumanfactorsincomputingsystems.
1–20.
[39] ÁngelAlexanderCabrera,AbrahamJDruck,JasonIHong,andAdamPerer.2021.Discoveringandvalidatingaierrorswithcrowdsourcedfailure
reports.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–22.
[40] ÁngelAlexanderCabrera,EricaFu,DonaldBertucci,KennethHolstein,AmeetTalwalkar,JasonIHong,andAdamPerer.2023.Zeno:Aninteractive
frameworkforbehavioralevaluationofmachinelearning.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–14.
[41] ÁngelAlexanderCabrera,AdamPerer,andJasonIHong.2023.Improvinghuman-AIcollaborationwithdescriptionsofAIbehavior.Proceedingsof
theACMonHuman-ComputerInteraction7,CSCW1(2023),1–21.
[42] CarrieJCai,SamanthaWinter,DavidSteiner,LaurenWilcox,andMichaelTerry.2019."HelloAI":uncoveringtheonboardingneedsofmedical
practitionersforhuman-AIcollaborativedecision-making.ProceedingsoftheACMonHuman-computerInteraction3,CSCW(2019),1–24.
[43] Xin-QiangCai,Yu-JieZhang,Chao-KaiChiang,andMasashiSugiyama.2023. ImitationLearningfromVagueFeedback. AdvancesinNeural
InformationProcessingSystems36.
[44] ChengzhiCao,YinghaoFu,ShengXu,RuimaoZhang,andShuangLi.2024.EnhancingHuman-AICollaborationThroughLogic-GuidedReasoning.
InTheTwelfthInternationalConferenceonLearningRepresentations.
[45] MicahCarroll,DavisFoote,AnandSiththaranjan,StuartRussell,andAncaDragan.2024.AIAlignmentwithChangingandInfluenceableReward
Functions.arXivpreprintarXiv:2405.17713(2024).
[46] MicahCarroll,RohinShah,MarkKHo,TomGriffiths,SanjitSeshia,PieterAbbeel,andAncaDragan.2019.Ontheutilityoflearningabouthumans
forhuman-aicoordination.Advancesinneuralinformationprocessingsystems32.
[47] FedericoMariaCau,HannaHauptmann,LucioDavideSpano,andNavaTintarev.2023.SupportingHigh-UncertaintyDecisionsthroughAIand
Logic-StyleExplanations.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.251–263.
[48] RobinChan,AfraAmini,andMennatallahEl-Assady.2023.WhichSpuriousCorrelationsImpactReasoninginNLIModels?AVisualInteractive
DiagnosisthroughData-ConstrainedCounterfactuals.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics
(Volume3:SystemDemonstrations).463–470.
[49] KushalChawla,IanWu,YuRong,GaleLucas,andJonathanGratch.2023.BeSelfish,ButWisely:InvestigatingtheImpactofAgentPersonalityin
Mixed-MotiveHuman-AgentInteractions.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.13078–13092.
[50] AngelicaChen,JérémyScheurer,JonAnderCampos,TomaszKorbak,JunShernChan,SamuelR.Bowman,KyunghyunCho,andEthanPerez.
2024.LearningfromNaturalLanguageFeedback.TransactionsonMachineLearningResearch(2024).
[51] JiaaoChen,MohanDodda,andDiyiYang.2023. Human-in-the-loopAbstractiveDialogueSummarization.InFindingsoftheAssociationfor
ComputationalLinguistics:ACL2023.9176–9190.
[52] QuanZeChen,TobiasSchnabel,BesmiraNushi,andSaleemaAmershi.2022.HINT:IntegrationTestingforAI-basedfeatureswithHumansinthe
Loop.In27thInternationalConferenceonIntelligentUserInterfaces.549–565.
[53] WeihaoChen,ChunYu,HuadongWang,ZhengWang,LichenYang,YukunWang,WeinanShi,andYuanchunShi.2023.FromGaptoSynergy:
EnhancingContextualUnderstandingthroughHuman-MachineCollaborationinPersonalizedSystems.InProceedingsofthe36thAnnualACM
SymposiumonUserInterfaceSoftwareandTechnology.1–15.
38TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[54] YuChen,YihanDu,PiheHu,SiweiWang,DeshengWu,andLongboHuang.2023.ProvablyEfficientIteratedCVaRReinforcementLearningwith
FunctionApproximationandHumanFeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[55] RuijiaCheng,AlisonSmith-Renner,KeZhang,JoelTetreault,andAlejandroJaimes-Larrarte.2022. MappingtheDesignSpaceofHuman-AI
InteractioninTextSummarization.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputational
Linguistics:HumanLanguageTechnologies.431–455.
[56] XusenCheng,XiaopingZhang,JasonCohen,andJianMou.2022.Humanvs.AI:Understandingtheimpactofanthropomorphismonconsumer
responsetochatbotsfromtheperspectiveoftrustandrelationshipnorms.InformationProcessing&Management59,3(2022),102940.
[57] Chun-WeiChiang,ZhuoranLu,ZhuoyanLi,andMingYin.2023.Aretwoheadsbetterthanoneinai-assisteddecisionmaking?comparingthe
behaviorandperformanceofgroupsandindividualsinhuman-aicollaborativerecidivismriskassessment.InProceedingsofthe2023CHIConference
onHumanFactorsinComputingSystems.1–18.
[58] Chun-WeiChiangandMingYin.2022.Exploringtheeffectsofmachinelearningliteracyinterventionsonlaypeople’srelianceonmachinelearning
models.In27thInternationalConferenceonIntelligentUserInterfaces.148–161.
[59] MinsukChoi,CheonbokPark,SoyoungYang,YonggyuKim,JaegulChoo,andSungsooRayHong.2019. Aila:Attentiveinteractivelabeling
assistantfordocumentclassificationthroughattention-baseddeepneuralnetworks.InProceedingsofthe2019CHIconferenceonhumanfactorsin
computingsystems.1–12.
[60] MinjeChoi,JiaxinPei,SagarKumar,ChangShu,andDavidJurgens.2023.DoLLMsUnderstandSocialKnowledge?EvaluatingtheSociabilityof
LargeLanguageModelswithSocKETBenchmark.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.
11370–11403.
[61] AakankshaChowdhery,SharanNarang,JacobDevlin,MaartenBosma,GauravMishra,AdamRoberts,PaulBarham,HyungWonChung,Charles
Sutton,SebastianGehrmann,etal.2023.Palm:Scalinglanguagemodelingwithpathways.JournalofMachineLearningResearch24,240(2023),
1–113.
[62] PaulFChristiano,JanLeike,TomBrown,MiljanMartic,ShaneLegg,andDarioAmodei.2017.Deepreinforcementlearningfromhumanpreferences.
Advancesinneuralinformationprocessingsystems30(2017).
[63] MichaelChromik,MalinEiband,FelicitasBuchner,AdrianKrüger,andAndreasButz.2021.Ithinkigetyourpoint,AI!theillusionofexplanatory
depthinexplainableAI.In26thinternationalconferenceonintelligentuserinterfaces.307–317.
[64] JohnChung,EceKamar,andSaleemaAmershi.2023.IncreasingDiversityWhileMaintainingAccuracy:TextDataGenerationwithLargeLanguage
ModelsandHumanInterventions.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).
575–593.
[65] JohnJoonYoungChung,WooseokKim,KangMinYoo,HwaranLee,EytanAdar,andMinsukChang.2022.TaleBrush:Sketchingstorieswith
generativepretrainedlanguagemodels.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–19.
[66] GabrieleCimolinoandTCNicholasGraham.2022.Twoheadsarebetterthanone:Adimensionspaceforunifyinghumanandartificialintelligence
insharedcontrol.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–21.
[67] NinaCorveloBenzandManuelRodriguez.2023.Human-alignedcalibrationforai-assisteddecisionmaking.AdvancesinNeuralInformation
ProcessingSystems36.
[68] ShanleyCorvite,KatRoemmich,TillieIlanaRosenberg,andNazaninAndalibi.2023.DataSubjects’PerspectivesonEmotionArtificialIntelligence
UseintheWorkplace:ARelationalEthicsLens.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),1–38.
[69] KathrynCunningham,BarbaraJEricson,RahulAgrawalBejarano,andMarkGuzdial.2021.AvoidingtheTuringtarpit:Learningconversational
programmingbystartingfromcode’spurpose.InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–15.
[70] AllanDafoeandStuartRussell.2016.Yes,weareworriedabouttheexistentialriskofartificialintelligence.MITTechnologyReview(2016).
[71] JosefDai,XuehaiPan,RuiyangSun,JiamingJi,XinboXu,MickelLiu,YizhouWang,andYaodongYang.2024.Saferlhf:Safereinforcementlearning
fromhumanfeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[72] BhavanaDalvi,OyvindTafjord,andPeterClark.2022.TowardsTeachableReasoningSystems:UsingaDynamicMemoryofUserFeedbackfor
ContinualSystemImprovement.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.9465–9480.
[73] HaiDang,KarimBenharrak,FlorianLehmann,andDanielBuschek.2022.Beyondtextgeneration:Supportingwriterswithcontinuousautomatic
textsummaries.InProceedingsofthe35thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–13.
[74] ValdemarDanry,PatPataranutaporn,YaoliMao,andPattieMaes.2023.Don’tjusttellme,askme:Aisystemsthatintelligentlyframeexplanations
asquestionsimprovehumanlogicaldiscernmentaccuracyovercausalaiexplanations.InProceedingsofthe2023CHIConferenceonHumanFactors
inComputingSystems.1–13.
[75] DevleenaDas,BeenKim,andSoniaChernova.2023.Subgoal-basedexplanationsforunreliableintelligentdecisionsupportsystems.InProceedings
ofthe28thInternationalConferenceonIntelligentUserInterfaces.240–250.
[76] KerstinDautenhahn,ChrystopherLNehaniv,andKDautenhahn.2000.LivingwithSociallyIntelligentAgents.HumanCognitionandSocialAgent
Technology,JohnBenjaminsPubl.Co(2000),415–426.
[77] NaihaoDeng,XinliangZhang,SiyangLiu,WinstonWu,LuWang,andRadaMihalcea.2023.YouAreWhatYouAnnotate:TowardsBetterModels
throughAnnotatorRepresentations.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.12475–12498.
[78] AdvaitDeshpandeandHelenSharp.2022.Responsibleaisystems:whoarethestakeholders?.InProceedingsofthe2022AAAI/ACMConferenceon
AI,Ethics,andSociety.227–236.
39Manuscript,submittedtoACM,2024 Shenetal.
[79] MichaelDesmond,MichaelMuller,ZahraAshktorab,CaseyDugan,EvelynDuesterwald,KristinaBrimijoin,CatherineFinegan-Dollak,Michelle
Brachman,AabhasSharma,NarendraNathJoshi,etal.2021.Increasingthespeedandaccuracyofdatalabelingthroughanaiassistedinterface.In
26thInternationalConferenceonIntelligentUserInterfaces.392–401.
[80] ShehzaadDhuliawala,VilémZouhar,MennatallahEl-Assady,andMrinmayaSachan.2023.ADiachronicPerspectiveonUserTrustinAIunder
Uncertainty.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.5567–5580.
[81] ZijianDing,AlisonSmith-Renner,WenjuanZhang,JoelTetreault,andAlejandroJaimes.2023.HarnessingthepowerofLLMs:Evaluatinghuman-AI
textco-creationthroughthelensofnewsheadlinegeneration.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.3321–3339.
[82] ZijianDing,AlisonSmith-Renner,WenjuanZhang,JoelTetreault,andAlejandroJaimes.2023.HarnessingthepowerofLLMs:Evaluatinghuman-AI
textco-creationthroughthelensofnewsheadlinegeneration.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.3321–3339.
[83] HanzeDong,WeiXiong,DeepanshuGoyal,YihanZhang,WinnieChow,RuiPan,ShizheDiao,JipengZhang,KashunShum,andTongZhang.
2023.Raft:Rewardrankedfinetuningforgenerativefoundationmodelalignment.arXivpreprintarXiv:2304.06767(2023).
[84] KefanDongandTengyuMa.2023. AsymptoticInstance-OptimalAlgorithmsforInteractiveDecisionMaking.InTheEleventhInternational
ConferenceonLearningRepresentations.
[85] YiDong,ZhilinWang,MakeshSreedhar,XianchaoWu,andOleksiiKuchaiev.2023.SteerLM:AttributeConditionedSFTasan(User-Steerable)
AlternativetoRLHF.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.11275–11288.
[86] ZibinDong,YifuYuan,JianyeHAO,FeiNi,YaoMu,YANZHENG,YujingHu,TangjieLv,ChangjieFan,andZhipengHu.2024.AlignDiff:Aligning
DiverseHumanPreferencesviaBehavior-CustomisableDiffusionModel.InTheTwelfthInternationalConferenceonLearningRepresentations.
[87] FlorianEDorner,MomchilPeychev,NikolaKonstantinov,NamanGoel,ElliottAsh,andMartinVechev.2023.Human-GuidedFairClassification
forNaturalLanguageProcessing.InTheEleventhInternationalConferenceonLearningRepresentations.
[88] YannDubois,ChenXuechenLi,RohanTaori,TianyiZhang,IshaanGulrajani,JimmyBa,CarlosGuestrin,PercySLiang,andTatsunoriBHashimoto.
2023.Alpacafarm:Asimulationframeworkformethodsthatlearnfromhumanfeedback.AdvancesinNeuralInformationProcessingSystems36.
[89] WKeithEdwardsandRebeccaEGrinter.2001.Athomewithubiquitouscomputing:Sevenchallenges.InUbicomp2001:UbiquitousComputing:
InternationalConferenceAtlantaGeorgia,USA,September30–October2,2001Proceedings3.Springer,256–272.
[90] MalinEiband,DanielBuschek,andHeinrichHussmann.2021. Howtosupportusersinunderstandingintelligentsystems?Structuringthe
discussion.In26thInternationalConferenceonIntelligentUserInterfaces.120–132.
[91] DavidEsiobu,XiaoqingTan,SagharHosseini,MeganUng,YuchenZhang,JudeFernandes,JaneDwivedi-Yu,EleonoraPresani,AdinaWilliams,
andEricMichaelSmith.2023.ROBBIE:RobustBiasEvaluationofLargeGenerativeLanguageModels.InThe2023ConferenceonEmpiricalMethods
inNaturalLanguageProcessing.
[92] KawinEthayarajhandDanJurafsky.2022.TheAuthenticityGapinHumanEvaluation.InProceedingsofthe2022ConferenceonEmpiricalMethods
inNaturalLanguageProcessing.6056–6070.
[93] XiangFan,YiweiLyu,PaulPuLiang,RuslanSalakhutdinov,andLouis-PhilippeMorency.2023.Nano:NestedHuman-in-the-LoopRewardLearning
forFew-shotLanguageModelControl.InFindingsoftheAssociationforComputationalLinguistics:ACL2023.11970–11992.
[94] ZahraFatemi,ChenXing,WenhaoLiu,andCaimmingXiong.2023. ImprovingGenderFairnessofPre-TrainedLanguageModelswithout
CatastrophicForgetting.InThe61stAnnualMeetingOfTheAssociationForComputationalLinguistics.
[95] AmirFeder,GuyHorowitz,YoavWald,RoiReichart,andNirRosenfeld.2022. Intheeyeofthebeholder:Robustpredictionwithcausaluser
modeling.AdvancesinNeuralInformationProcessingSystems35,14419–14433.
[96] YuFei,YifanHou,ZemingChen,andAntoineBosselut.2023.MitigatingLabelBiasesforIn-contextLearning.InProceedingsofthe61stAnnual
MeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).14014–14031.
[97] VirginiaFelkner,Ho-ChunHerbertChang,EugeneJang,andJonathanMay.2023. WinoQueer:ACommunity-in-the-LoopBenchmarkfor
Anti-LGBTQ+BiasinLargeLanguageModels.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:
LongPapers).9126–9140.
[98] ShiFengandJordanBoyd-Graber.2019.Whatcanaidoforme?evaluatingmachinelearninginterpretationsincooperativeplay.InProceedingsof
the24thInternationalConferenceonIntelligentUserInterfaces.229–239.
[99] ShangbinFeng,ChanYoungPark,YuhanLiu,andYuliaTsvetkov.2023.FromPretrainingDatatoLanguageModelstoDownstreamTasks:Tracking
theTrailsofPoliticalBiasesLeadingtoUnfairNLPModels.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics
(Volume1:LongPapers).11737–11762.
[100] EveFleisig,AubrieAmstutz,ChadAtalla,SuLinBlodgett,HalDauméIII,AlexandraOlteanu,EmilySheng,DanVann,andHannaWallach.2023.
FairPrism:evaluatingfairness-relatedharmsintextgeneration.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputational
Linguistics(Volume1:LongPapers).6231–6251.
[101] MaxwellForbes,JenaDHwang,VeredShwartz,MaartenSap,andYejinChoi.2020.Socialchemistry101:Learningtoreasonaboutsocialand
moralnorms.arXivpreprintarXiv:2011.00620(2020).
[102] JulesFrançoise,BaptisteCaramiaux,andTéoSanchez.2021.Marcelle:composinginteractivemachinelearningworkflowsandinterfaces.InThe
34thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.39–53.
[103] ViktorEFrankl.1966.Self-transcendenceasahumanphenomenon.JournalofHumanisticPsychology6,2(1966),97–106.
[104] IasonGabriel.2020.Artificialintelligence,values,andalignment.Mindsandmachines30,3(2020),411–437.
40TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[105] KrzysztofZGajosandLenaMamykina.2022. DopeopleengagecognitivelywithAI?ImpactofAIassistanceonincidentallearning.In27th
internationalconferenceonintelligentuserinterfaces.794–806.
[106] DeepGanguli,LianeLovitt,JacksonKernion,AmandaAskell,YuntaoBai,SauravKadavath,BenMann,EthanPerez,NicholasSchiefer,Kamal
Ndousse,etal.2022.Redteaminglanguagemodelstoreduceharms:Methods,scalingbehaviors,andlessonslearned.arXivpreprintarXiv:2209.07858
(2022).
[107] GeGao,Hung-TingChen,YoavArtzi,andEunsolChoi.2023.ContinuallyImprovingExtractiveQAviaHumanFeedback.InProceedingsofthe
2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.406–423.
[108] GeGao,EunsolChoi,andYoavArtzi.2022.SimulatingBanditLearningfromUserFeedbackforExtractiveQuestionAnswering.InProceedingsof
the60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).5167–5179.
[109] JieGao,YuchenGuo,TobyJia-JunLi,andSimonTangiPerrault.2023.CollabCoder:aGPT-poweredworkflowforcollaborativequalitativeanalysis.
InCompanionPublicationofthe2023ConferenceonComputerSupportedCooperativeWorkandSocialComputing.354–357.
[110] XiangGao,YizheZhang,MichelGalley,ChrisBrockett,andWilliamBDolan.2020.DialogueResponseRankingTrainingwithLarge-ScaleHuman
FeedbackData.InProceedingsofthe2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP).386–395.
[111] YimingGao,FeiyuLiu,LiangWang,DehuaZheng,ZhenjieLian,WeixuanWang,WenjinYang,SiqinLi,XianliangWang,WenhuiChen,etal.2024.
EnhancingHumanExperienceinHuman-AgentCollaboration:AHuman-CenteredModelingApproachBasedonPositiveHumanGain.(2024).
[112] SimretArayaGebreegziabher,ZhengZhang,XiaohangTang,YihaoMeng,ElenaLGlassman,andTobyJia-JunLi.2023. Patat:Human-ai
collaborativequalitativecodingwithexplainableinteractiverulesynthesis.InProceedingsofthe2023CHIConferenceonHumanFactorsin
ComputingSystems.1–19.
[113] MatthiasGerstgrasser,RakshitTrivedi,andDavidCParkes.2021.CrowdPlay:CrowdsourcingHumanDemonstrationsforOfflineLearning.In
InternationalConferenceonLearningRepresentations.
[114] MorGeva,AviCaciularu,GuyDar,PaulRoit,ShovalSadde,MicahShlain,BarTamir,andYoavGoldberg.2022.LM-Debugger:AnInteractiveTool
forInspectionandInterventioninTransformer-BasedLanguageModels.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNatural
LanguageProcessing:SystemDemonstrations.12–21.
[115] ZoharGilad,OfraAmir,andLiatLevontin.2021.Theeffectsofwarmthandcompetenceperceptionsonusers’choiceofanAIsystem.InProceedings
ofthe2021CHIconferenceonhumanfactorsincomputingsystems.1–13.
[116] EricGilbert.2024.HCCIsAllYouNeed:Alignment-TheSensibleKindAnyway-IsJustHuman-CenteredComputing.arXivpreprintarXiv:2405.03699
(2024).
[117] DongyoungGo,TomaszKorbak,GermánKruszewski,JosRozen,andMarcDymetman.2023.CompositionalPreferenceModelsforAligningLMs.
InTheTwelfthInternationalConferenceonLearningRepresentations.
[118] SeraphinaGoldfarb-Tarrant,HainingFeng,andNanyunPeng.2019. Plan,Write,andRevise:anInteractiveSystemforOpen-DomainStory
Generation.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics(Demonstrations).
89–97.
[119] SeraphinaGoldfarb-Tarrant,EddieUngless,EsmaBalkir,andSuLinBlodgett.2023.Thispromptismeasuring<mask>:evaluatingbiasevaluation
inlanguagemodels.InFindingsoftheAssociationforComputationalLinguistics:ACL2023.2209–2225.
[120] MitchellLGordon,MichelleSLam,JoonSungPark,KayurPatel,JeffHancock,TatsunoriHashimoto,andMichaelSBernstein.2022.Jurylearning:
Integratingdissentingvoicesintomachinelearningmodels.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.
1–19.
[121] ZhibinGou,ZhihongShao,YeyunGong,yelongshen,YujiuYang,NanDuan,andWeizhuChen.2024. CRITIC:LargeLanguageModelsCan
Self-CorrectwithTool-InteractiveCritiquing.InTheTwelfthInternationalConferenceonLearningRepresentations.
[122] NiteshGoyal,MinsukChang,andMichaelTerry.2024.DesigningforHuman-AgentAlignment:Understandingwhathumanswantfromtheir
agents.InExtendedAbstractsoftheCHIConferenceonHumanFactorsinComputingSystems.1–6.
[123] JesseGraham,JonathanHaidt,SenaKoleva,MattMotyl,RaviIyer,SeanPWojcik,andPeterHDitto.2013.Moralfoundationstheory:Thepragmatic
validityofmoralpluralism.InAdvancesinexperimentalsocialpsychology.Vol.47.Elsevier,55–130.
[124] ZiweiGu,IanArawjo,KennethLi,JonathanKKummerfeld,andElenaLGlassman.2024.AnAI-ResilientTextRenderingTechniqueforReading
andSkimmingDocuments.InProceedingsofthe2024CHIConferenceonHumanFactorsinComputingSystems.
[125] LinGuan,KarthikValmeekam,andSubbaraoKambhampati.2022. RelativeBehavioralAttributes:FillingtheGapbetweenSymbolicGoal
SpecificationandRewardLearningfromHumanPreferences.InTheEleventhInternationalConferenceonLearningRepresentations.
[126] LinGuan,MuditVerma,SunaSihangGuo,RuohanZhang,andSubbaraoKambhampati.2021.Wideningthepipelineinhuman-guidedreinforcement
learningwithexplanationandcontext-awaredataaugmentation.AdvancesinNeuralInformationProcessingSystems34,21885–21897.
[127] GeyangGuo,RanchiZhao,TianyiTang,WayneXinZhao,andJi-RongWen.2024.Beyondimitation:Leveragingfine-grainedqualitysignalsfor
alignment.InTheTwelfthInternationalConferenceonLearningRepresentations.
[128] LijieGuo,ElizabethMDaly,OznurAlkan,MassimilianoMattetti,OwenCornec,andBartKnijnenburg.2022.Buildingtrustininteractivemachine
learningviausercontributedinterpretablerules.In27thInternationalConferenceonIntelligentUserInterfaces.537–548.
[129] PrakharGupta,YangLiu,DiJin,BehnamHedayatnia,SpandanaGella,SijiaLiu,PatrickLLange,JuliaHirschberg,andDilekHakkani-Tur.2023.
DialGuide:AligningDialogueModelBehaviorwithDeveloperGuidelines.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.
14031–14047.
41Manuscript,submittedtoACM,2024 Shenetal.
[130] PhilippHacker,AndreasEngel,andMarcoMauer.2023.RegulatingChatGPTandotherlargegenerativeAImodels.InProceedingsofthe2023ACM
ConferenceonFairness,Accountability,andTransparency.1112–1123.
[131] SaraHajian,FrancescoBonchi,andCarlosCastillo.2016. Algorithmicbias:Fromdiscriminationdiscoverytofairness-awaredatamining.In
Proceedingsofthe22ndACMSIGKDDinternationalconferenceonknowledgediscoveryanddatamining.2125–2126.
[132] PerttuHämäläinen,MikkeTavast,andAntonKunnari.2023.Evaluatinglargelanguagemodelsingeneratingsynthetichciresearchdata:acase
study.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–19.
[133] AndyHamilton.2020.Conservatism.InTheStanfordEncyclopediaofPhilosophy(Spring2020ed.),EdwardN.Zalta(Ed.).MetaphysicsResearch
Lab,StanfordUniversity.
[134] PeterHaseandMohitBansal.2020.EvaluatingExplainableAI:WhichAlgorithmicExplanationsHelpUsersPredictModelBehavior?.InProceedings
ofthe58thAnnualMeetingoftheAssociationforComputationalLinguistics.5540–5552.
[135] GaoleHe,StefanBuijsman,andUjwalGadiraju.2023.HowStatedAccuracyofanAISystemandAnalogiestoExplainAccuracyAffectHuman
RelianceontheSystem.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–29.
[136] GaoleHe,LucieKuiper,andUjwalGadiraju.2023.Knowingaboutknowing:Anillusionofhumancompetencecanhinderappropriaterelianceon
AIsystems.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–18.
[137] ZiyaoHe,YunpengSong,ShuruiZhou,andZhongminCai.2023.InteractionofThoughts:TowardsMediatingTaskAssignmentinHuman-AI
CooperationwithaCapability-AwareSharedMentalModel.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.
1–18.
[138] PhilippHeinisch,MatthiasOrlikowski,JuliaRomberg,andPhilippCimiano.2023.ArchitecturalSweetSpotsforModelingHumanLabelVariation
bytheExampleofArgumentQuality:It’sBesttoRelatePerspectives!.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNatural
LanguageProcessing.11138–11154.
[139] PatrickHemmer,MonikaWestphal,MaxSchemmer,SebastianVetter,MichaelVössing,andGerhardSatzger.2023.Human-AICollaboration:The
EffectofAIDelegationonHumanTaskPerformanceandTaskSatisfaction.InProceedingsofthe28thInternationalConferenceonIntelligentUser
Interfaces.453–463.
[140] ThomasAHemphill.2020.HumanCompatible:ArtificialIntelligenceandtheProblemofControl.
[141] DanHendrycks,CollinBurns,StevenBasart,AndrewCritchCritch,JerryLiLi,DawnSong,andJacobSteinhardt.2021.AligningAIWithShared
HumanValues.InInternationalConferenceonLearningRepresentations.
[142] KennethHolstein,JenniferWortmanVaughan,HalDauméIII,MiroDudik,andHannaWallach.2019.Improvingfairnessinmachinelearning
systems:Whatdoindustrypractitionersneed?.InProceedingsofthe2019CHIconferenceonhumanfactorsincomputingsystems.1–16.
[143] JoeyHong,SergeyLevine,andAncaDragan.2023.Learningtoinfluencehumanbehaviorwithofflinereinforcementlearning.AdvancesinNeural
InformationProcessingSystems36.
[144] Matt-HeunHong,LaurenAMarsh,JessicaLFeuston,JanetRuppert,JedRBrubaker,andDanielleAlbersSzafir.2022. Scholastic:Graphical
human-AIcollaborationforinductiveandinterpretivetextanalysis.InProceedingsofthe35thAnnualACMSymposiumonUserInterfaceSoftware
andTechnology.1–12.
[145] MatthewKHong,AdamFourney,DerekDeBellis,andSaleemaAmershi.2021.Planningfornaturallanguagefailureswiththeaiplaybook.In
Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–11.
[146] WANGHongru,MindaHu,YangDeng,RuiWang,FeiMi,WeichaoWang,YashengWang,Wai-ChungKwan,IrwinKing,andKam-FaiWong.
2023.LargeLanguageModelsasSourcePlannerforPersonalizedKnowledge-groundedDialogues.InThe2023ConferenceonEmpiricalMethodsin
NaturalLanguageProcessing.
[147] TomHosking,PhilBlunsom,andMaxBartolo.2024.HumanFeedbackisnotGoldStandard.InTheTwelfthInternationalConferenceonLearning
Representations.
[148] YoyoTsung-YuHou,Wen-YingLee,andMalteJung.2023.“ShouldIFollowtheHuman,orFollowtheRobot?”—RobotsinPowerCanHaveMore
InfluenceThanHumansonDecision-Making.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–13.
[149] DirkHovyandDiyiYang.2021.Theimportanceofmodelingsocialfactorsoflanguage:Theoryandpractice.InProceedingsofthe2021Conference
oftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies.588–602.
[150] ShengranHuandJeffClune.2023.Thoughtcloning:Learningtothinkwhileactingbyimitatinghumanthinking.AdvancesinNeuralInformation
ProcessingSystems36.
[151] XumingHu,JunzheChen,XiaochuanLi,YufeiGuo,LijieWen,PhilipS.Yu,andZhijiangGuo.2024.DoLargeLanguageModelsKnowabout
Facts?.InTheTwelfthInternationalConferenceonLearningRepresentations. https://openreview.net/forum?id=9OevMUdods
[152] XiaoHu,JianxiongLi,XianyuanZhan,Qing-ShanJia,andYa-QinZhang.2024.Query-PolicyMisalignmentinPreference-BasedReinforcement
Learning.InTheTwelfthInternationalConferenceonLearningRepresentations.
[153] YebowenHu,KaiqiangSong,SangwooCho,XiaoyangWang,HassanForoosh,andFeiLiu.2023.Decipherpref:Analyzinginfluentialfactorsin
humanpreferencejudgmentsviagpt-4.InThe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.
[154] Jen-tseHuang,WenxuanWang,EricJohnLi,ManHoLAM,ShujieRen,YouliangYuan,WenxiangJiao,ZhaopengTu,andMichaelLyu.2023.
OntheHumanityofConversationalAI:EvaluatingthePsychologicalPortrayalofLLMs.InTheTwelfthInternationalConferenceonLearning
Representations.
42TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[155] XiaoweiHuang,WenjieRuan,WeiHuang,GaojieJin,YiDong,ChangshunWu,SaddekBensalem,RonghuiMu,YiQi,XingyuZhao,etal.2023.A
surveyofsafetyandtrustworthinessoflargelanguagemodelsthroughthelensofverificationandvalidation.arXivpreprintarXiv:2305.11391
(2023).
[156] ZihengHuang,SebastianGutierrez,HemanthKamana,andStephenMacNeil.2023. Memorysandbox:Transparentandinteractivememory
managementforconversationalagents.InAdjunctProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–3.
[157] MinaHuh,Yi-HaoPeng,andAmyPavel.2023.GenAssist:MakingImageGenerationAccessible.InProceedingsofthe36thAnnualACMSymposium
onUserInterfaceSoftwareandTechnology.1–17.
[158] EunJeongHwang,BodhisattwaMajumder,andNiketTandon.2023.AligningLanguageModelstoUserOpinions.InFindingsoftheAssociationfor
ComputationalLinguistics:EMNLP2023.5906–5919.
[159] MinyoungHwang,GunminLee,HogunKee,ChanWooKim,KyungjaeLee,andSonghwaiOh.2023.Sequentialpreferencerankingforefficient
reinforcementlearningfromhumanfeedback.AdvancesinNeuralInformationProcessingSystems36(2023).
[160] ASTMInternational.2012.FormandStyleofStandards,ASTMBlueBook.https://www.astm.org/media/pdf/bluebook_FormStyle.pdf.
[161] GeoffreyIrvingandAmandaAskell.2019.AIsafetyneedssocialscientists.Distill4,2(2019),e14.
[162] ArmanIsajanyan,ArturShatveryan,DavidKocharian,ZhangyangWang,andHumphreyShi.2024. SocialReward:EvaluatingandEnhanc-
ingGenerativeAIthroughMillion-UserFeedbackfromanOnlineCreativeCommunity.InTheTwelfthInternationalConferenceonLearning
Representations.
[163] AzraIsmailandNehaKumar.2021.AIinglobalhealth:theviewfromthefrontlines.InProceedingsofthe2021CHIConferenceonHumanFactorsin
ComputingSystems.1–21.
[164] MaiaJacobs,JeffreyHe,MelanieF.Pradier,BarbaraLam,AndrewCAhn,ThomasHMcCoy,RoyHPerlis,FinaleDoshi-Velez,andKrzysztofZ
Gajos.2021.DesigningAIfortrustandcollaborationintime-constrainedmedicaldecisions:asociotechnicallens.InProceedingsofthe2021chi
conferenceonhumanfactorsincomputingsystems.1–14.
[165] MauriceJakesch,AdvaitBhat,DanielBuschek,LiorZalmanson,andMorNaaman.2023.Co-writingwithopinionatedlanguagemodelsaffects
users’views.InProceedingsofthe2023CHIconferenceonhumanfactorsincomputingsystems.1–15.
[166] SullamJeoung,YubinGe,andJanaDiesner.2023.StereoMap:QuantifyingtheAwarenessofHuman-likeStereotypesinLargeLanguageModels.In
Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.12236–12256.
[167] XiaogangJia,DenisBlessing,XinkaiJiang,MoritzReuss,AtalayDonat,RudolfLioutikov,andGerhardNeumann.2024.TowardsDiverseBehaviors:
ABenchmarkforImitationLearningwithHumanDemonstrations.InTheTwelfthInternationalConferenceonLearningRepresentations.
[168] GuangyuanJiang,ManjieXu,Song-ChunZhu,WenjuanHan,ChiZhang,andYixinZhu.2023.Evaluatingandinducingpersonalityinpre-trained
languagemodels.AdvancesinNeuralInformationProcessingSystems36.
[169] JialunAaronJiang,KandreaWade,CaseyFiesler,andJedRBrubaker.2021.Supportingserendipity:OpportunitiesandchallengesforHuman-AI
Collaborationinqualitativeanalysis.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW1(2021),1–23.
[170] PeilingJiang,JudeRayan,StevenPDow,andHaijunXia.2023.Graphologue:Exploringlargelanguagemodelresponseswithinteractivediagrams.
InProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–20.
[171] ZhijingJin,SydneyLevine,FernandoGonzalezAdauto,OjasvKamal,MaartenSap,MrinmayaSachan,RadaMihalcea,JoshTenenbaum,and
BernhardSchölkopf.2022.Whentomakeexceptions:Exploringlanguagemodelsasaccountsofhumanmoraljudgment.Advancesinneural
informationprocessingsystems35,28458–28473.
[172] EunkyungJo,DanielAEpstein,HyunhoonJung,andYoung-HoKim.2023.Understandingthebenefitsandchallengesofdeployingconversational
AIleveraginglargelanguagemodelsforpublichealthintervention.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
Systems.1–16.
[173] StevenJohnsonandNikitaIziev.2022.AIismasteringlanguage.Shouldwetrustwhatitsays?TheNewYorkTimes4(2022),15.
[174] ErikJonesandJacobSteinhardt.2022.Capturingfailuresoflargelanguagemodelsviahumancognitivebiases.AdvancesinNeuralInformation
ProcessingSystems35,11785–11799.
[175] MatthewJörke,YasamanSSefidgar,TalieMassachi,JinaSuh,andGonzaloRamos.2023.Pearl:ATechnologyProbeforMachine-AssistedReflection
onPersonalData.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.902–918.
[176] BrihiJoshi,ZiyiLiu,SahanaRamnath,AaronChan,ZheweiTong,ShaoliangNie,QifanWang,YejinChoi,andXiangRen.2023.AreMachine
Rationales(Not)UsefultoHumans?MeasuringandImprovingHumanUtilityofFree-textRationales.InProceedingsofthe61stAnnualMeetingof
theAssociationforComputationalLinguistics(Volume1:LongPapers).7103–7128.
[177] BongGyunKang,HyunGiKim,DahuinJung,andSungrohYoon.2023.CLeAR:ContinualLearningonAlgorithmicReasoningforHuman-like
Intelligence.AdvancesinNeuralInformationProcessingSystems36.
[178] DongjunKang,JoonsukPark,YohanJo,andJinYeongBak.2023. FromValuestoOpinions:PredictingHumanBehaviorsandStancesUsing
Value-InjectedLargeLanguageModels.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.15539–15559.
[179] ShivaniKapania,AlexSTaylor,andDingWang.2023.Ahuntforthesnark:Annotatordiversityindatapractices.InProceedingsofthe2023CHI
ConferenceonHumanFactorsinComputingSystems.1–15.
[180] HarmanpreetKaur,EytanAdar,EricGilbert,andCliffLampe.2022.SensibleAI:Re-imagininginterpretabilityandexplainabilityusingsensemaking
theory.InProceedingsofthe2022ACMConferenceonFairness,Accountability,andTransparency.702–714.
43Manuscript,submittedtoACM,2024 Shenetal.
[181] AnnaKawakami,VenkateshSivaraman,Hao-FeiCheng,LoganStapleton,YanghuidiCheng,DianaQing,AdamPerer,ZhiweiStevenWu,Haiyi
Zhu,andKennethHolstein.2022.Improvinghuman-AIpartnershipsinchildwelfare:understandingworkerpractices,challenges,anddesiresfor
algorithmicdecisionsupport.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–18.
[182] MajeedKazemitabaar,XinyingHou,AustinHenley,BarbaraJaneEricson,DavidWeintrop,andToviGrossman.2023.HownovicesuseLLM-based
codegeneratorstosolveCS1codingtasksinaself-pacedlearningenvironment.InProceedingsofthe23rdKoliCallingInternationalConferenceon
ComputingEducationResearch.1–12.
[183] EoinMKenny,MycalTucker,andJulieShah.2022.Towardsinterpretabledeepreinforcementlearningwithhuman-friendlyprototypes.InThe
EleventhInternationalConferenceonLearningRepresentations.
[184] ZacharyKenton,TomEveritt,LauraWeidinger,IasonGabriel,VladimirMikulik,andGeoffreyIrving.2021.Alignmentoflanguageagents.arXiv
preprintarXiv:2103.14659(2021).
[185] PranavKhadpe,RanjayKrishna,LiFei-Fei,JeffreyTHancock,andMichaelSBernstein.2020. Conceptualmetaphorsimpactperceptionsof
human-AIcollaboration.ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW2(2020),1–26.
[186] FereshteKhaniandMarcoTulioRibeiro.2023.CollaborativeAlignmentofNLPmodels.AdvancesinNeuralInformationProcessingSystems36.
[187] DanielKhashabi,GabrielStanovsky,JonathanBragg,NicholasLourie,JungoKasai,YejinChoi,NoahASmith,andDanielSWeld.2022.GENIE:
TowardReproducibleandStandardizedHumanEvaluationforTextGeneration.(2022),11444–11458.
[188] TusharKhot,KyleRichardson,DanielKhashabi,andAshishSabharwal.2022.HeyAI,CanYouSolveComplexTasksbyTalkingtoAgents?.In
FindingsoftheAssociationforComputationalLinguistics:ACL2022.1808–1823.
[189] JohannesKiesel,MiladAlshomary,NicolasHandke,XiaoniCai,HenningWachsmuth,andBennoStein.2022.Identifyingthehumanvaluesbehind
arguments.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).4459–4471.
[190] HyunwooKim,MelanieSclar,XuhuiZhou,RonanBras,GunheeKim,YejinChoi,andMaartenSap.2023.FANToM:ABenchmarkforStress-testing
MachineTheoryofMindinInteractions.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.14397–14413.
[191] SungdongKim,SanghwanBae,JaminShin,SoyoungKang,DonghyunKwak,KangYoo,andMinjoonSeo.2023.AligningLargeLanguageModels
throughSyntheticFeedback.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.13677–13700.
[192] SunnieSYKim,ElizabethAnneWatkins,OlgaRussakovsky,RuthFong,andAndrésMonroy-Hernández.2023."HelpMeHelptheAI":Understanding
HowExplainabilityCanSupportHuman-AIInteraction.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–17.
[193] TaenyunKim,MariaDMolina,MinjinRheu,EmilySZhan,andWeiPeng.2023.OneAIdoesnotfitall:Aclusteranalysisofthelaypeople’s
perceptionofAIroles.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–20.
[194] TaeSooKim,YoonjooLee,JaminShin,Young-HoKim,andJuhoKim.2024.Evallm:Interactiveevaluationoflargelanguagemodelpromptson
user-definedcriteria.InProceedingsofthe2024CHIConferenceonHumanFactorsinComputingSystems.
[195] JanHKirchner,LoganSmith,JacquesThibodeau,KyleMcDonell,andLariaReynolds.2022.Researchingalignmentresearch:Unsupervisedanalysis.
arXivpreprintarXiv:2206.02841(2022).
[196] HannahKirk,AndrewBean,BertieVidgen,PaulRöttger,andScottHale.2023.ThePast,PresentandBetterFutureofFeedbackLearninginLarge
LanguageModelsforSubjectiveHumanPreferencesandValues.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguage
Processing.2409–2430.
[197] MartinKlissarov,PierlucaD’Oro,ShagunSodhani,RobertaRaileanu,Pierre-LucBacon,PascalVincent,AmyZhang,andMikaelHenaff.2024.
Motif:IntrinsicMotivationfromArtificialIntelligenceFeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[198] RafalKocielnik,SaleemaAmershi,andPaulNBennett.2019.Willyouacceptanimperfectai?exploringdesignsforadjustingend-userexpectations
ofaisystems.InProceedingsofthe2019CHIConferenceonHumanFactorsinComputingSystems.1–14.
[199] RyanKoo,MinhwaLee,VipulRaheja,JongInnPark,ZaeMyungKim,andDongyeopKang.2023.Benchmarkingcognitivebiasesinlargelanguage
modelsasevaluators.arXivpreprintarXiv:2309.17012(2023).
[200] VictoriaKrakovna,JonathanUesato,VladimirMikulik,MatthewRahtz,TomEveritt,RamanaKumar,ZacKenton,JanLeike,andShaneLegg.2020.
Specificationgaming:theflipsideofAIingenuity.DeepMindBlog3(2020).
[201] BumChulKwonandNandanaMihindukulasooriya.2023.Finspector:AHuman-CenteredVisualInspectionToolforExploringandComparing
BiasesamongFoundationModels.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume3:System
Demonstrations),DanushkaBollegala,RuihongHuang,andAlanRitter(Eds.).AssociationforComputationalLinguistics,Toronto,Canada,42–50.
https://doi.org/10.18653/v1/2023.acl-demo.4
[202] BumChulKwonandNandanaMihindukulasooriya.2023.Finspector:AHuman-CenteredVisualInspectionToolforExploringandComparing
BiasesamongFoundationModels.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume3:System
Demonstrations).42–50.
[203] PreethiLahoti,NicholasBlumm,XiaoMa,RaghavendraKotikalapudi,SahityaPotluri,QijunTan,HansaSrinivasan,BenPacker,AhmadBeirami,
AlexBeutel,etal.2023.ImprovingDiversityofDemographicRepresentationinLargeLanguageModelsviaCollective-CritiquesandSelf-Voting.In
Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.10383–10405.
[204] VivianLai,SamuelCarton,RajatBhatnagar,QVeraLiao,YunfengZhang,andChenhaoTan.2022. Human-aicollaborationviaconditional
delegation:Acasestudyofcontentmoderation.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–18.
[205] VivianLai,HanLiu,andChenhaoTan.2020."Whyis’Chicago’deceptive?"TowardsBuildingModel-DrivenTutorialsforHumans.InProceedings
ofthe2020CHIConferenceonHumanFactorsinComputingSystems.1–13.
44TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[206] VivianLai,YimingZhang,ChachaChen,QVeraLiao,andChenhaoTan.2023.Selectiveexplanations:Leveraginghumaninputtoalignexplainable
ai.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–35.
[207] Dong-HoLee,AkshenKadakia,BrihiJoshi,AaronChan,ZiyiLiu,KiranNarahari,TakashiShibuya,RyosukeMitani,ToshiyukiSekiya,JayPujara,
etal.2023. XMD:AnEnd-to-EndFrameworkforInteractiveExplanation-BasedDebuggingofNLPModels.InProceedingsofthe61stAnnual
MeetingoftheAssociationforComputationalLinguistics(Volume3:SystemDemonstrations).264–273.
[208] MinaLee,KatyIlonkaGero,JohnJoonYoungChung,SimonBuckinghamShum,VipulRaheja,HuaShen,SubhashiniVenugopalan,Thiemo
Wambsganss,DavidZhou,EmadAAlghamdi,etal.2024.ADesignSpaceforIntelligentandInteractiveWritingAssistants.InProceedingsofthe
2024CHIConferenceonHumanFactorsinComputingSystems.
[209] MinaLee,PercyLiang,andQianYang.2022. Coauthor:Designingahuman-aicollaborativewritingdatasetforexploringlanguagemodel
capabilities.InProceedingsofthe2022CHIconferenceonhumanfactorsincomputingsystems.1–19.
[210] MinaLee,MeghaSrivastava,AmeliaHardy,JohnThickstun,EsinDurmus,AshwinParanjape,InesGerard-Ursin,XiangLisaLi,FaisalLadhak,
FriedaRong,etal.2023.EvaluatingHuman-LanguageModelInteraction.TransactionsonMachineLearningResearch(2023).
[211] MinHunLeeandChongJunChew.2023.UnderstandingtheEffectofCounterfactualExplanationsonTrustandRelianceonAIforHuman-AI
CollaborativeClinicalDecisionMaking.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–22.
[212] MinKyungLeeandKatherineRich.2021.WhoisincludedinhumanperceptionsofAI?:TrustandperceivedfairnessaroundhealthcareAIand
culturalmistrust.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputingsystems.1–14.
[213] MichelleSengAhLeeandJatSingh.2021.Thelandscapeandgapsinopensourcefairnesstoolkits.InProceedingsofthe2021CHIconferenceon
humanfactorsincomputingsystems.1–13.
[214] NoahLee,NaMinAn,andJamesThorne.2023. CanLargeLanguageModelsCaptureDissentingHumanVoices?.InThe2023Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing.
[215] YoonjooLee,TaeSooKim,SungdongKim,YohanYun,andJuhoKim.2023. Dapie:Interactivestep-by-stepexplanatorydialoguestoanswer
children’swhyandhowquestions.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–22.
[216] PiyawatLertvittayakumjorn,LuciaSpecia,andFrancescaToni.2020.FIND:Human-in-the-LoopDebuggingDeepTextClassifiers.InProceedingsof
the2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP).332–348.
[217] KornelLewicki,MichelleSengAhLee,JenniferCobbe,andJatinderSingh.2023.OutofContext:InvestigatingtheBiasandFairnessConcernsof
“ArtificialIntelligenceasaService”.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–17.
[218] ChenliangLi,HeChen,MingYan,WeizhouShen,HaiyangXu,ZhikaiWu,ZhichengZhang,WenmengZhou,YingdaChen,ChenCheng,etal.2023.
ModelScope-Agent:BuildingYourCustomizableAgentSystemwithOpen-sourceLargeLanguageModels.InProceedingsofthe2023Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.566–578.
[219] GuohaoLi,HasanHammoud,HaniItani,DmitriiKhizbullin,andBernardGhanem.2023.Camel:Communicativeagentsfor"mind"explorationof
largelanguagemodelsociety.AdvancesinNeuralInformationProcessingSystems36.
[220] HuaoLi,YuChong,SimonStepputtis,JosephPCampbell,DanaHughes,CharlesLewis,andKatiaSycara.2023.TheoryofMindforMulti-Agent
CollaborationviaLargeLanguageModels.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.180–192.
[221] JunlongLi,ShichaoSun,WeizheYuan,Run-ZeFan,HaiZhao,andPengfeiLiu.2024.Generativejudgeforevaluatingalignment.InTheTwelfth
InternationalConferenceonLearningRepresentations.
[222] LeiLi,YekunChai,ShuohuanWang,YuSun,HaoTian,NingyuZhang,andHuaWu.2024.Tool-AugmentedRewardModeling.InTheTwelfth
InternationalConferenceonLearningRepresentations.
[223] MinzhiLi,TaiweiShi,CalebZiems,Min-YenKan,NancyChen,ZhengyuanLiu,andDiyiYang.2023.CoAnnotating:Uncertainty-GuidedWork
AllocationbetweenHumanandLargeLanguageModelsforDataAnnotation.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNatural
LanguageProcessing.1487–1505.
[224] ShuangLi,XavierPuig,ChrisPaxton,YilunDu,ClintonWang,LinxiFan,TaoChen,De-AnHuang,EkinAkyürek,AnimaAnandkumar,etal.2022.
Pre-trainedlanguagemodelsforinteractivedecision-making.AdvancesinNeuralInformationProcessingSystems35,31199–31212.
[225] TianshiLi,SauvikDas,Hao-PingLee,DakuoWang,BingshengYao,andZhipingZhang.2024.Human-CenteredPrivacyResearchintheAgeof
LargeLanguageModels.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.
[226] TobyJia-JunLi.2020.Multi-modalinteractivetasklearningfromdemonstrationsandnaturallanguageinstructions.InAdjunctProceedingsofthe
33rdAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.162–168.
[227] ZichaoLi,PrakharSharma,XingHanLu,JackieChiKitCheung,andSivaReddy.2022.UsingInteractiveFeedbacktoImprovetheAccuracyand
ExplainabilityofQuestionAnsweringSystemsPost-Deployment.InFindingsoftheAssociationforComputationalLinguistics:ACL2022.926–937.
[228] MengqiLiaoandSShyamSundar.2021.HowshouldAIsystemstalktouserswhencollectingtheirpersonalinformation?Effectsofroleframing
andself-referencingonhuman-AIinteraction.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputingsystems.1–14.
[229] QVeraLiao,DanielGruen,andSarahMiller.2020.QuestioningtheAI:informingdesignpracticesforexplainableAIuserexperiences.InProceedings
ofthe2020CHIConferenceonHumanFactorsinComputingSystems.1–15.
[230] JungwooLim,MyunghoonKang,JinsungKim,JeongwookKim,YunaHur,andHeui-SeokLim.2023.BeyondCandidates:AdaptiveDialogue
AgentUtilizingPersonaandKnowledge.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.7950–7963.
[231] GabrielLima,NinaGrgić-Hlača,andMeeyoungCha.2021.HumanperceptionsonmoralresponsibilityofAI:AcasestudyinAI-assistedbail
decision-making.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputingsystems.1–17.
45Manuscript,submittedtoACM,2024 Shenetal.
[232] GabrielLima,NinaGrgić-Hlača,andMeeyoungCha.2023.Blaminghumansandmachines:Whatshapespeople’sreactionstoalgorithmicharm.In
Proceedingsofthe2023CHIconferenceonhumanfactorsincomputingsystems.1–26.
[233] GabrielLima,NinaGrgic-Hlaca,JinKeunJeong,andMeeyoungCha.2023.WhoShouldPayWhenMachinesCauseHarm?Laypeople’sExpectations
ofLegalDamagesforMachine-CausedHarm.InProceedingsofthe2023ACMConferenceonFairness,Accountability,andTransparency(FAccT’23).
AssociationforComputingMachinery,NewYork,NY,USA,236–246. https://doi.org/10.1145/3593013.3593992
[234] GabrielLima,ChangyeonKim,SeunghoRyu,ChihyungJeon,andMeeyoungCha.2020.CollectingthepublicperceptionofAIandrobotrights.
ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW2(2020),1–24.
[235] BillYuchenLin,YichengFu,KarinaYang,FaezeBrahman,ShiyuHuang,ChandraBhagavatula,PrithvirajAmmanabrolu,YejinChoi,andXiang
Ren.2023.Swiftsage:Agenerativeagentwithfastandslowthinkingforcomplexinteractivetasks.AdvancesinNeuralInformationProcessing
Systems36.
[236] BillYuchenLin,AbhilashaRavichander,XimingLu,NouhaDziri,MelanieSclar,KhyathiChandu,ChandraBhagavatula,andYejinChoi.2023.Urial:
AligningUntunedLLMswithJustthe’Write’AmountofIn-ContextLearning.InTheTwelfthInternationalConferenceonLearningRepresentations.
[237] BillYuchenLin,AbhilashaRavichander,XimingLu,NouhaDziri,MelanieSclar,KhyathiChandu,ChandraBhagavatula,andYejinChoi.2024.The
UnlockingSpellonBaseLLMs:RethinkingAlignmentviaIn-ContextLearning.InTheTwelfthInternationalConferenceonLearningRepresentations.
[238] RuixiLinandHweeTouNg.2023.Mindthebiases:Quantifyingcognitivebiasesinlanguagemodelprompting.InFindingsoftheAssociationfor
ComputationalLinguistics:ACL2023.5269–5281.
[239] ZiLin,ZihanWang,YongqiTong,YangkunWang,YuxinGuo,YujiaWang,andJingboShang.2023.ToxicChat:UnveilingHiddenChallengesof
ToxicityDetectioninReal-WorldUser-AIConversation.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.4694–4702.
[240] AlisaLiu,SwabhaSwayamdipta,NoahASmith,andYejinChoi.2022. WANLI:WorkerandAICollaborationforNaturalLanguageInference
DatasetCreation.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2022.6826–6847.
[241] HanLiu,VivianLai,andChenhaoTan.2021.Understandingtheeffectofout-of-distributionexamplesandinteractiveexplanationsonhuman-ai
decisionmaking.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–45.
[242] HanLiu,YizhouTian,ChachaChen,ShiFeng,YuxinChen,andChenhaoTan.2023.LearningHuman-CompatibleRepresentationsforCase-Based
DecisionSupport.InTheEleventhInternationalConferenceonLearningRepresentations.
[243] JuneMLiu,DonghaoLi,HeCao,TianheRen,ZeyiLiao,andJiaminWu.2023.Chatcounselor:Alargelanguagemodelsformentalhealthsupport.
InTheFirstWorkshoponPersonalizedGenerativeAI@CIKM.
[244] MichaelXieyangLiu,AdvaitSarkar,CarinaNegreanu,BenjaminZorn,JackWilliams,NeilToronto,andAndrewDGordon.2023.“Whatitwants
metosay”:Bridgingtheabstractiongapbetweenend-userprogrammersandcode-generatinglargelanguagemodels.InProceedingsofthe2023
CHIConferenceonHumanFactorsinComputingSystems.1–31.
[245] RuiboLiu,GeZhang,XinyuFeng,andSoroushVosoughi.2022. Aligninggenerativelanguagemodelswithhumanvalues.InFindingsofthe
AssociationforComputationalLinguistics:NAACL2022.241–252.
[246] ShichengLiuandMinghuiZhu.2023. LearningMulti-agentBehaviorsfromDistributedandStreamingDemonstrations. AdvancesinNeural
InformationProcessingSystems36.
[247] WeiLiu,WeihaoZeng,KeqingHe,YongJiang,andJunxianHe.2024.WhatMakesGoodDataforAlignment?AComprehensiveStudyofAutomatic
DataSelectioninInstructionTuning.InTheTwelfthInternationalConferenceonLearningRepresentations.
[248] XinLiu,MuhammadKhalifa,andLuWang.2024.LightweightLanguageModelCalibrationforOpen-endedQuestionAnsweringwithVaried
AnswerLengths.InTheTwelfthInternationalConferenceonLearningRepresentations.
[249] TylerLoakman,AaronMaladry,andChenghuaLin.2023.TheIron(ic)MeltingPot:ReviewingHumanEvaluationinHumour,IronyandSarcasm
Generation.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.6676–6689.
[250] DuriLongandBrianMagerko.2020.WhatisAIliteracy?Competenciesanddesignconsiderations.InProceedingsofthe2020CHIconferenceon
humanfactorsincomputingsystems.1–16.
[251] HuaLu,SiqiBao,HuangHe,FanWang,HuaWu,andHaifengWang.2023.TowardsBoostingtheOpen-DomainChatbotwithHumanFeedback.
InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).4060–4078.
[252] JinghuiLu,LinyiYang,BrianNamee,andYueZhang.2022. ARationale-CentricFrameworkforHuman-in-the-loopMachineLearning.In
Proceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).6986–6996.
[253] XinyiLu,SiminFan,JessicaHoughton,LuWang,andXuWang.2023. Readingquizmaker:Ahuman-nlpcollaborativesystemthatsupports
instructorstodesignhigh-qualityreadingquizquestions.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–18.
[254] LauraLucaj,PatrickvanderSmagt,andDjalelBenbouzid.2023.Airegulationis(not)allyouneed.InProceedingsofthe2023ACMConferenceon
Fairness,Accountability,andTransparency.1267–1279.
[255] ChenyangLyu,LinyiYang,YueZhang,YvetteGraham,andJenniferFoster.2023.ExploitingRichTextualUser-ProductContextforImproving
PersonalizedSentimentAnalysis.InFindingsoftheAssociationforComputationalLinguistics:ACL2023.1419–1429.
[256] QianouMa,HuaShen,KennethKoedinger,andTongshuangWu.2024.HowtoTeachProgrammingintheAIEra?UsingLLMsasaTeachable
AgentforDebugging.25thInternationalConferenceonArtificialIntelligenceinEducation(AIED2024)(2024).
[257] ShuaiMa,YingLei,XinruWang,ChengboZheng,ChuhanShi,MingYin,andXiaojuanMa.2023.Whoshoulditrust:Aiormyself?leveraging
humanandaicorrectnesslikelihoodtopromoteappropriatetrustinai-assisteddecision-making.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems.1–19.
46TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[258] YechengJasonMa,WilliamLiang,GuanzhiWang,De-AnHuang,OsbertBastani,DineshJayaraman,YukeZhu,LinxiFan,andAnimaAnandkumar.
2023.Eureka:Human-LevelRewardDesignviaCodingLargeLanguageModels.InTheTwelfthInternationalConferenceonLearningRepresentations.
[259] ZiqiaoMa,JacobSansom,RunPeng,andJoyceChai.2023.TowardsAHolisticLandscapeofSituatedTheoryofMindinLargeLanguageModels.
InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.1011–1031.
[260] MichaelAMadaio,LukeStark,JenniferWortmanVaughan,andHannaWallach.2020. Co-designingcheckliststounderstandorganizational
challengesandopportunitiesaroundfairnessinAI.InProceedingsofthe2020CHIconferenceonhumanfactorsincomputingsystems.1–14.
[261] JessicaMaghakian,PaulMineiro,KishanPanaganti,MarkRucker,AkankshaSaran,andChengTan.2023.PersonalizedRewardLearningwith
Interaction-GroundedLearning(IGL).InTheEleventhInternationalConferenceonLearningRepresentations.
[262] AmamaMahmood,JeanieWFung,IsabelWon,andChien-MingHuang.2022.Owningmistakessincerely:StrategiesformitigatingAIerrors.In
Proceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–11.
[263] BodhisattwaMajumder,ZexueHe,andJulianMcAuley.2023.InterFair:DebiasingwithNaturalLanguageFeedbackforFairInterpretablePredictions.
InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.9466–9471.
[264] NoraMcDonaldandShimeiPan.2020. IntersectionalAI:Astudyofhowinformationsciencestudentsthinkaboutethicsandtheirimpact.
ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW2(2020),1–19.
[265] SamWhitmanMcGrath,JacobRussin,ElliePavlick,andRomanFeiman.2023.HowCanDeepNeuralNetworksInformTheoryinPsychological
Science?(2023).
[266] NickMckenna,TianyiLi,LiangCheng,MohammadHosseini,MarkJohnson,andMarkSteedman.2023. SourcesofHallucinationbyLarge
LanguageModelsonInferenceTasks.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.2758–2774.
[267] AndrewMMcNutt,ChenglongWang,RobertADeline,andStevenMDrucker.2023.Onthedesignofai-poweredcodeassistantsfornotebooks.In
Proceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–16.
[268] NiloofarMireshghallah,HyunwooKim,XuhuiZhou,YuliaTsvetkov,MaartenSap,RezaShokri,andYejinChoi.2024. CanLLMsKeepa
Secret?TestingPrivacyImplicationsofLanguageModelsviaContextualIntegrityTheory.InTheTwelfthInternationalConferenceonLearning
Representations.
[269] ElliotMitchell,NoemieElhadad,andLenaMamykina.2022.ExaminingAImethodsformicro-coachingdialogs.InProceedingsofthe2022CHI
ConferenceonHumanFactorsinComputingSystems.1–24.
[270] LillioMok,SashaNanda,andAshtonAnderson.2023.Peopleperceivealgorithmicassessmentsaslessfairandtrustworthythanidenticalhuman
assessments.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–26.
[271] MeredithRingelMorris,JaschaSohl-dickstein,NoahFiedel,TrisWarkentin,AllanDafoe,AleksandraFaust,ClementFarabet,andShaneLegg.
2024.LevelsofAGI:OperationalizingProgressonthePathtoAGI. arXiv:2311.02462[cs.AI]
[272] HusseinMozannar,ValerieChen,MohammedAlsobay,SubhroDas,SebastianZhao,DennisWei,ManishNagireddy,PrasannaSattigeri,Ameet
Talwalkar,andDavidSontag.2024.TheRealHumanEval:EvaluatingLargeLanguageModels’AbilitiestoSupportProgrammers.arXivpreprint
arXiv:2404.02806(2024).
[273] HusseinMozannar,JiminLee,DennisWei,PrasannaSattigeri,SubhroDas,andDavidSontag.2023.EffectiveHuman-AITeamsviaLearnedNatural
LanguageRulesandOnboarding.AdvancesinNeuralInformationProcessingSystems36.
[274] ImaniMunyaka,ZahraAshktorab,CaseyDugan,JamesJohnson,andQianPan.2023.DecisionMakingStrategiesandTeamEfficacyinHuman-AI
Teams.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),1–24.
[275] VinodMuthusamy,YaraRizk,KiranKate,PraveenVenkateswaran,VatcheIsahagian,AshuGulati,andParijatDube.2023.Towardslargelanguage
model-basedpersonalagentsintheenterprise:Currenttrendsandopenproblems.InThe2023ConferenceonEmpiricalMethodsinNaturalLanguage
Processing.
[276] RichardNgo,LawrenceChan,andSörenMindermann.2024.Thealignmentproblemfromadeeplearningperspective.InTheTwelfthInternational
ConferenceonLearningRepresentations.
[277] Duy-HungNguyen,NguyenVietDungNghiem,Bao-SinhNguyen,DungTienTienLe,ShahabSabahi,Minh-TienNguyen,andHungLe.2022.Make
TheMostofPriorData:ASolutionforInteractiveTextSummarizationwithPreferenceFeedback.InFindingsoftheAssociationforComputational
Linguistics:NAACL2022.1919–1930.
[278] AllenNie,YuhuiZhang,AtharvaShaileshAmdekar,ChrisPiech,TatsunoriBHashimoto,andTobiasGerstenberg.2023. MoCa:Measuring
Human-LanguageModelAlignmentonCausalandMoralJudgmentTasks.AdvancesinNeuralInformationProcessingSystems36(2023).
[279] TheACMDirectorofPublications.2024.ACMPolicyonAuthorship. https://www.acm.org/publications/policies/new-acm-policy-on-authorship
[280] MinsikOh,JoosungLee,JiweiLi,andGuoyinWang.2023.PK-ICR:Persona-KnowledgeInteractiveMulti-ContextRetrievalforGroundedDialogue.
InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.16383–16395.
[281] MatthiasOrlikowski,PaulRöttger,PhilippCimiano,andDirkHovy.2023.TheEcologicalFallacyinAnnotation:ModelingHumanLabelVariation
goesbeyondSociodemographics.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers).
1017–1029.
[282] LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,ChongZhang,SandhiniAgarwal,KatarinaSlama,Alex
Ray,etal.2022.Traininglanguagemodelstofollowinstructionswithhumanfeedback.Advancesinneuralinformationprocessingsystems35
(2022),27730–27744.
47Manuscript,submittedtoACM,2024 Shenetal.
[283] SiqiOuyangandLeiLi.2023.AutoPlan:AutomaticPlanningofInteractiveDecision-MakingTasksWithLargeLanguageModels.InFindingsofthe
AssociationforComputationalLinguistics:EMNLP2023.3114–3128.
[284] SiruOuyang,ShuohangWang,YangLiu,MingZhong,YizhuJiao,DanIter,ReidPryzant,ChenguangZhu,HengJi,andJiaweiHan.2023.The
ShiftedandTheOverlooked:ATask-orientedInvestigationofUser-GPTInteractions.InProceedingsofthe2023ConferenceonEmpiricalMethodsin
NaturalLanguageProcessing.2375–2393.
[285] MatthewJPage,JoanneEMcKenzie,PatrickMBossuyt,IsabelleBoutron,TammyCHoffmann,CynthiaDMulrow,LarissaShamseer,JenniferM
Tetzlaff,ElieAAkl,SueEBrennan,etal.2021.ThePRISMA2020statement:anupdatedguidelineforreportingsystematicreviews.Bmj372(2021).
[286] RohanPaleja,MuylengGhuy,NadunRanawakaArachchige,ReedJensen,andMatthewGombolay.2021.Theutilityofexplainableaiinadhoc
human-machineteaming.Advancesinneuralinformationprocessingsystems34,610–623.
[287] AlexanderPan,KushBhatia,andJacobSteinhardt.2022.TheEffectsofRewardMisspecification:MappingandMitigatingMisalignedModels.
(2022).
[288] AlexanderPan,JunShernChan,AndyZou,NathanielLi,StevenBasart,ThomasWoodside,HanlinZhang,ScottEmmons,andDanHendrycks.
2023.Dotherewardsjustifythemeans?measuringtrade-offsbetweenrewardsandethicalbehaviorinthemachiavellibenchmark.InInternational
ConferenceonMachineLearning.PMLR,26837–26867.
[289] KetanParanjape,MichielSchinkel,RishiNannanPanday,JosipCar,PrabathNanayakkara,etal.2019.Introducingartificialintelligencetrainingin
medicaleducation.JMIRmedicaleducation5,2(2019),e16048.
[290] HyangheePark,DaehwanAhn,KartikHosanagar,andJoonhwanLee.2021.Human-AIinteractioninhumanresourcemanagement:Understanding
whyemployeesresistalgorithmicevaluationatworkplacesandhowtomitigateburdens.InProceedingsofthe2021CHIconferenceonhuman
factorsincomputingsystems.1–15.
[291] JoonSungPark,JosephO’Brien,CarrieJunCai,MeredithRingelMorris,PercyLiang,andMichaelSBernstein.2023.Generativeagents:Interactive
simulacraofhumanbehavior.InProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–22.
[292] SunghyunPark,HanLi,AmeenPatel,SidharthMudgal,SungjinLee,Young-BumKim,SpyrosMatsoukas,andRuhiSarikaya.2021.AScalable
FrameworkforLearningFromImplicitUserFeedbacktoImproveNaturalLanguageUnderstandinginLarge-ScaleConversationalAISystems.In
Proceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.6054–6063.
[293] RomaPatelandElliePavlick.2021.“Wasit“stated”orwasit“claimed”?:Howlinguisticbiasaffectsgenerativelanguagemodels.InProceedingsof
the2021ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.10080–10095.
[294] JiaxinPei,AparnaAnanthasubramaniam,XingyaoWang,NaitianZhou,ApostolosDedeloudis,JacksonSargent,andDavidJurgens.2022.POTATO:
ThePortableTextAnnotationTool.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.
327–337.
[295] Yi-HaoPeng,JiWoongJang,JeffreyPBigham,andAmyPavel.2021.Sayitall:Feedbackforimprovingnon-visualpresentationaccessibility.In
Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–12.
[296] ZhenghaoMarkPeng,WenjieMo,ChendaDuan,QuanyiLi,andBoleiZhou.2023.Learningfromactivehumaninvolvementthroughproxyvalue
propagation.Advancesinneuralinformationprocessingsystems36(2023).
[297] NeilPerry,MeghaSrivastava,DeepakKumar,andDanBoneh.2023.DouserswritemoreinsecurecodewithAIassistants?(2023),2785–2799.
[298] MarkusPeschl,ArkadyZgonnikov,FransAOliehoek,andLucianoCSiebert.2022.MORAL:AligningAIwithHumanNormsthroughMulti-
ObjectiveReinforcedActiveLearning.InProceedingsofthe21stInternationalConferenceonAutonomousAgentsandMultiagentSystems.1038–1046.
[299] DominicPetrak,NafiseSadatMoosavi,YeTian,NikolaiRozanov,andIrynaGurevych.2024.LearningFromFree-TextHumanFeedback–Collect
NewDatasetsOrExtendExistingOnes?.InTheTwelfthInternationalConferenceonLearningRepresentations.
[300] SavvasPetridis,NicholasDiakopoulos,KevinCrowston,MarkHansen,KerenHenderson,StanJastrzebski,JeffreyVNickerson,andLydiaB
Chilton.2023.Anglekindling:Supportingjournalisticangleideationwithlargelanguagemodels.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems.1–16.
[301] SavvasPetridis,BenWedin,AnnYuan,JamesWexler,andNithumThain.2024.ConstitutionalExperts:TrainingaMixtureofPrinciple-based
Prompts.arXivpreprintarXiv:2403.04894(2024).
[302] SavvasPetridis,BenjaminDWedin,JamesWexler,MahimaPushkarna,AaronDonsbach,NiteshGoyal,CarrieJCai,andMichaelTerry.2024.
Constitutionmaker:Interactivelycritiquinglargelanguagemodelsbyconvertingfeedbackintoprinciples.InProceedingsofthe29thInternational
ConferenceonIntelligentUserInterfaces.853–868.
[303] MarcPinski,MartinAdam,andAlexanderBenlian.2023.AIknowledge:ImprovingAIdelegationthroughhumanenablement.InProceedingsofthe
2023CHIConferenceonHumanFactorsinComputingSystems.1–17.
[304] DavidPiorkowski,IngeVejsbjerg,OwenCornec,ElizabethMDaly,andÖznurAlkan.2023.AIMEE:AnExploratoryStudyofHowRulesSupport
AIDeveloperstoExplainandEditModels.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–25.
[305] SnehalPrabhudesai,LeyaoYang,SumitAsthana,XunHuan,QVeraLiao,andNikolaBanovic.2023.Understandinguncertainty:howlaydecision-
makersperceiveandinterpretuncertaintyinhuman-AIdecisionmaking.InProceedingsofthe28thInternationalConferenceonIntelligentUser
Interfaces.379–396.
[306] ShrimaiPrabhumoye,BrendonBoldt,RuslanSalakhutdinov,andAlanWBlack.2021.CaseStudy:DeontologicalEthicsinNLP.InProceedingsof
the2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies.3784–3798.
48TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[307] CarinaPrunklandJessWhittlestone.2020.Beyondnear-andlong-term:TowardsacleareraccountofresearchprioritiesinAIethicsandsociety.In
ProceedingsoftheAAAI/ACMConferenceonAI,Ethics,andSociety.138–143.
[308] DashaPruss.2023. GhostingtheMachine:JudicialResistancetoaRecidivismRiskAssessmentInstrument.InProceedingsofthe2023ACM
ConferenceonFairness,Accountability,andTransparency(FAccT’23).AssociationforComputingMachinery,NewYork,NY,USA,312–323.
https://doi.org/10.1145/3593013.3593999
[309] XiangyuQi,YiZeng,TinghaoXie,Pin-YuChen,RuoxiJia,PrateekMittal,andPeterHenderson.2023.Fine-tuningAlignedLanguageModels
CompromisesSafety,EvenWhenUsersDoNotIntendTo!.InTheTwelfthInternationalConferenceonLearningRepresentations.
[310] YushanQian,WeinanZhang,andTingLiu.2023.HarnessingthePowerofLargeLanguageModelsforEmpatheticResponseGeneration:Empirical
InvestigationsandImprovements.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.6516–6528.
[311] JackWRae,SebastianBorgeaud,TrevorCai,KatieMillican,JordanHoffmann,FrancisSong,JohnAslanides,SarahHenderson,RomanRing,
SusannahYoung,etal.2021.Scalinglanguagemodels:Methods,analysis&insightsfromtraininggopher.arXivpreprintarXiv:2112.11446(2021).
[312] RafaelRafailov,ArchitSharma,EricMitchell,ChristopherDManning,StefanoErmon,andChelseaFinn.2023.Directpreferenceoptimization:
Yourlanguagemodelissecretlyarewardmodel.AdvancesinNeuralInformationProcessingSystems36.
[313] BogdanaRakova,JingyingYang,HenrietteCramer,andRummanChowdhury.2021.WhereresponsibleAImeetsreality:Practitionerperspectives
onenablersforshiftingorganizationalpractices.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW1(2021),1–23.
[314] AidaRamezaniandYangXu.2023.Knowledgeofculturalmoralnormsinlargelanguagemodels.InProceedingsofthe61stAnnualMeetingofthe
AssociationforComputationalLinguistics(Volume1:LongPapers).428–446.
[315] AbhinavRao,AditiKhandelwal,KumarTanmay,UtkarshAgarwal,andMonojitChoudhury.2023.EthicalReasoningoverMoralAlignment:ACase
andFrameworkforIn-ContextEthicalPoliciesinLLMs.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.13370–13388.
[316] SiddharthReddy,SergeyLevine,andAncaDragan.2022. Firstcontact:Unsupervisedhuman-machineco-adaptationviamutualinformation
maximization.AdvancesinNeuralInformationProcessingSystems35,31542–31556.
[317] BriannaRichardson,JeanGarcia-Gathright,SamuelFWay,JenniferThom,andHenrietteCramer.2021.Towardsfairnessinpractice:Apractitioner-
orientedrubricforevaluatingFairMLToolkits.InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–13.
[318] TimRietzandAlexanderMaedche.2021.Cody:AnAI-basedsystemtosemi-automatecodingforqualitativeresearch.InProceedingsofthe2021
CHIConferenceonHumanFactorsinComputingSystems.1–14.
[319] JenRogersandAnamariaCrisan.2023.Tracingandvisualizinghuman-ML/AIcollaborativeprocessesthroughartifactsofdatawork.InProceedings
ofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–22.
[320] PaulRoit,JohanFerret,LiorShani,RoeeAharoni,GeoffreyCideron,RobertDadashi,MatthieuGeist,SertanGirgin,LeonardHussenot,Orgad
Keller,etal.2023.FactuallyConsistentSummarizationviaReinforcementLearningwithTextualEntailmentFeedback.InProceedingsofthe61st
AnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).6252–6272.
[321] YangjunRuan,HonghuaDong,AndrewWang,SilviuPitis,YongchaoZhou,JimmyBa,YannDubois,ChrisJMaddison,andTatsunoriHashimoto.
2023.IdentifyingtheRisksofLMAgentswithanLM-EmulatedSandbox.InTheTwelfthInternationalConferenceonLearningRepresentations.
[322] StuartRussell.2014.Whitepaper:Valuealignmentinautonomoussystems.November1(2014).
[323] StuartRussell.2022.ArtificialIntelligenceandtheProblemofControl.PerspectivesonDigitalHumanism19(2022).
[324] StuartJRussellandPeterNorvig.2016.Artificialintelligence:amodernapproach.Pearson.
[325] NithyaSambasivanandRajeshVeeraraghavan.2022. ThedeskillingofdomainexpertiseinAIdevelopment.InProceedingsofthe2022CHI
ConferenceonHumanFactorsinComputingSystems.1–14.
[326] ShibaniSanturkar,EsinDurmus,FaisalLadhak,CinooLee,PercyLiang,andTatsunoriHashimoto.2023.Whoseopinionsdolanguagemodels
reflect?.InInternationalConferenceonMachineLearning.PMLR,29971–30004.
[327] SebastinSanty,JennyLiang,RonanLeBras,KatharinaReinecke,andMaartenSap.2023.NLPositionality:CharacterizingDesignBiasesofDatasets
andModels.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).9080–9102.
[328] BidiptaSarkar,AndyShih,andDorsaSadigh.2023.DiverseConventionsforHuman-AICollaboration.AdvancesinNeuralInformationProcessing
Systems36.
[329] MaxSchemmer,NiklasKuehl,CarinaBenz,AndreaBartos,andGerhardSatzger.2023.AppropriaterelianceonAIadvice:Conceptualizationand
theeffectofexplanations.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.410–422.
[330] MorganKlausScheuerman,AlexHanna,andEmilyDenton.2021. Dodatasetshavepolitics?Disciplinaryvaluesincomputervisiondataset
development.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–37.
[331] JérémyScheurer,JonAnderCampos,TomaszKorbak,JunShernChan,AngelicaChen,KyunghyunCho,andEthanPerez.2023.Traininglanguage
modelswithlanguagefeedbackatscale.arXivpreprintarXiv:2303.16755(2023).
[332] TimoSchick,AYuJane,ZhengbaoJiang,FabioPetroni,PatrickLewis,GautierIzacard,QingfeiYou,ChristoforosNalmpantis,EdouardGrave,and
SebastianRiedel.2022.PEER:ACollaborativeLanguageModel.InTheEleventhInternationalConferenceonLearningRepresentations.
[333] ShalomHSchwartz.1994.Arethereuniversalaspectsinthestructureandcontentsofhumanvalues?Journalofsocialissues50,4(1994),19–45.
[334] ShalomHSchwartz.2012.AnoverviewoftheSchwartztheoryofbasicvalues.OnlinereadingsinPsychologyandCulture2,1(2012),11.
[335] ConstantineSedikidesandMichaelJStrube.1995.Themultiplymotivatedself.PersonalityandSocialPsychologyBulletin21,12(1995),1330–1335.
[336] NikilSelvam,SunipaDev,DanielKhashabi,TusharKhot,andKai-WeiChang.2023. TheTailWaggingtheDog:DatasetConstructionBiases
ofSocialBiasBenchmarks.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers).
49Manuscript,submittedtoACM,2024 Shenetal.
1373–1386.
[337] PrithvirajSen,YunyaoLi,EserKandogan,YiweiYang,andWalterLasecki.2019.HEIDL:Learninglinguisticexpressionswithdeeplearningand
human-in-the-loop.InProceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics:SystemDemonstrations.135–140.
[338] OmarShaikh,ValentinoChai,MicheleJGelfand,DiyiYang,andMichaelSBernstein.2024. Rehearsal:Simulatingconflicttoteachconflict
resolution.InACMConferenceonHumanFactorsinComputingSystems.
[339] AshishSharma,KevinRushton,InnaLin,DavidWadden,KhendraLucas,AdamMiner,TheresaNguyen,andTimAlthoff.2023. Cognitive
ReframingofNegativeThoughtsthroughHuman-LanguageModelInteraction.InProceedingsofthe61stAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1:LongPapers).9977–10000.
[340] HuaShen,Chieh-YangHuang,TongshuangWu,andTing-HaoKennethHuang.2023.ConvXAI:DeliveringheterogeneousAIexplanationsvia
conversationstosupporthuman-AIscientificwriting.InCompanionPublicationofthe2023ConferenceonComputerSupportedCooperativeWork
andSocialComputing.384–387.
[341] HuaShenandTing-HaoHuang.2020.Howusefularethemachine-generatedinterpretationstogeneralusers?ahumanevaluationonguessing
theincorrectlypredictedlabels.InProceedingsoftheAAAIConferenceonHumanComputationandCrowdsourcing,Vol.8.168–172.
[342] HuaShen,TongshuangWu,WenboGuo,andTing-HaoHuang.2022.AreShortestRationalestheBestExplanationsforHumanUnderstanding?.In
Proceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers).10–19.
[343] HuaShen,YuguangYang,GuoliSun,RyanLangman,EunjungHan,JashaDroppo,andAndreasStolcke.2022. Improvingfairnessinspeaker
verificationviagroup-adaptedfusionnetwork.InICASSP2022-2022IEEEInternationalConferenceonAcoustics,SpeechandSignalProcessing(ICASSP).
IEEE,7077–7081.
[344] HuaShen,VickyZayats,JohannRocholl,DanielWalker,andDirkPadfield.2023. MultiTurnCleanup:ABenchmarkforMulti-TurnSpoken
ConversationalTranscriptCleanup.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.9895–9903.
[345] WeiShen,RuiZheng,WenyuZhan,JunZhao,ShihanDou,TaoGui,QiZhang,andXuan-JingHuang.2023.Looselipssinkships:Mitigating
LengthBiasinReinforcementLearningfromHumanFeedback.,2859–2873pages.
[346] EmilySheng,Kai-WeiChang,PremNatarajan,andNanyunPeng.2021. SocietalBiasesinLanguageGeneration:ProgressandChallenges.In
Proceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJointConferenceonNatural
LanguageProcessing(Volume1:LongPapers).4275–4293.
[347] KatieShilton.2013.Valueslevers:Buildingethicsintodesign.Science,Technology,&HumanValues38,3(2013),374–397.
[348] MinkyuShin,JinKim,BasvanOpheusden,andThomasLGriffiths.2023.Superhumanartificialintelligencecanimprovehumandecision-making
byincreasingnovelty.ProceedingsoftheNationalAcademyofSciences120,12(2023),e2214840120.
[349] ChengleiSi,DanFriedman,NitishJoshi,ShiFeng,DanqiChen,andHeHe.2023. MeasuringInductiveBiasesofIn-ContextLearningwith
UnderspecifiedDemonstrations.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).
11289–11310.
[350] ChengleiSi,WeijiaShi,ChenZhao,LukeZettlemoyer,andJordanBoyd-Graber.2023.Gettingmoreoutofmixtureoflanguagemodelreasoning
experts.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.8234–8249.
[351] AnthonySiciliaandMaliheAlikhani.2023.LearningtoGenerateEquitableTextinDialoguefromBiasedTrainingData.InProceedingsofthe61st
AnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).2898–2917.
[352] VenkateshSivaraman,LeighABukowski,JoelLevin,JeremyMKahn,andAdamPerer.2023.Ignore,trust,ornegotiate:Understandingclinician
acceptanceofAI-basedtreatmentrecommendationsinhealthcare.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
Systems.1–18.
[353] CH-WangSky,ArkadiySaakyan,OliverLi,ZhouYu,andSmarandaMuresan.2023.Socioculturalnormsimilaritiesanddifferencesviasituational
alignmentandexplainabletextualentailment.InThe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.
[354] AvivSlobodkin,NivNachum,ShmuelAmar,OriShapira,andIdoDagan.2023.SummHelper:CollaborativeHuman-ComputerSummarization.In
Proceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.554–565.
[355] AlisonSmith-Renner,RonFan,MelissaBirchfield,TongshuangWu,JordanBoyd-Graber,DanielSWeld,andLeahFindlater.2020.Noexplainability
withoutaccountability:Anempiricalstudyofexplanationsandfeedbackininteractiveml.InProceedingsofthe2020chiconferenceonhuman
factorsincomputingsystems.1–13.
[356] AlisonSmith-Renner,VarunKumar,JordanBoyd-Graber,KevinSeppi,andLeahFindlater.2020.Diggingintousercontrol:perceptionsofadherence
andinstabilityintransparentmodels.InProceedingsofthe25thInternationalConferenceonIntelligentUserInterfaces.519–530.
[357] JaemarieSolyst,ShixianXie,ElliaYang,AngelaEBStewart,MotahhareEslami,JessicaHammer,andAmyOgan.2023.“IWouldLiketoDesign”:
BlackGirlsAnalyzingandIdeatingFairandAccountableAI.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.
1–14.
[358] JaemarieSolyst,ElliaYang,ShixianXie,AmyOgan,JessicaHammer,andMotahhareEslami.2023.ThePotentialofDiverseYouthasStakeholders
inIdentifyingandMitigatingAlgorithmicBiasforaFutureofFairerAI.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),
1–27.
[359] FeifanSong,BowenYu,MinghaoLi,HaiyangYu,FeiHuang,YongbinLi,andHoufengWang.2024.Preferencerankingoptimizationforhuman
alignment.InProceedingsoftheAAAIConferenceonArtificialIntelligence,Vol.38.18990–18998.
50TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[360] TaylorSorensen,JaredMoore,JillianFisher,MitchellGordon,NiloofarMireshghallah,ChristopherMichaelRytting,AndreYe,LiweiJiang,Ximing
Lu,NouhaDziri,etal.2024.ARoadmaptoPluralisticAlignment.arXivpreprintarXiv:2402.05070(2024).
[361] FrancescoSovranoandFabioVitali.2021.Fromphilosophytointerfaces:anexplanatorymethodandatoolinspiredbyachinstein’stheoryof
explanation.In26thInternationalConferenceonIntelligentUserInterfaces.81–91.
[362] NehaPundlikSrikanth,RupakSarkar,HeranY.Mane,ElizabethM.Aparicio,QuynhC.Nguyen,RachelRudinger,andJordanBoyd-Graber.2024.
LargeLanguageModelsHelpHumansVerifyTruthfulness—ExceptWhenTheyAreConvincinglyWrong.InNorthAmericanAssociationfor
ComputationalLinguistics.
[363] SumitSrivastava,MariëtTheune,andAlejandroCatala.2023.Theroleoflexicalalignmentinhumanunderstandingofexplanationsbyconversational
agents.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.423–435.
[364] EvropiStefanidi,MaritBentvelzen,PawełWWoźniak,ThomasKosch,MikołajPWoźniak,ThomasMildner,StefanSchneegass,HeikoMüller,and
JasminNiess.2023.LiteraturereviewsinHCI:Areviewofreviews.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
Systems.1–24.
[365] NisanStiennon,LongOuyang,JeffreyWu,DanielZiegler,RyanLowe,ChelseaVoss,AlecRadford,DarioAmodei,andPaulFChristiano.2020.
Learningtosummarizewithhumanfeedback.AdvancesinNeuralInformationProcessingSystems33,3008–3021.
[366] KeesStuurmanandHugoWijnands.2001.Softwarelaw:intelligentagents:acurseorablessing?Asurveyofthelegalaspectsoftheapplicationof
intelligentsoftwaresystems.ComputerLaw&SecurityReview17,2(2001),92–100.
[367] IliaSucholutskyandTomGriffiths.2023.Alignmentwithhumanrepresentationssupportsrobustfew-shotlearning.AdvancesinNeuralInformation
ProcessingSystems36.
[368] TianxiangSun,JunliangHe,XipengQiu,andXuan-JingHuang.2022.BERTScoreisUnfair:OnSocialBiasinLanguageModel-BasedMetricsfor
TextGeneration.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.3726–3739.
[369] ZhiqingSun,YikangShen,QinhongZhou,HongxinZhang,ZhenfangChen,DavidCox,YimingYang,andChuangGan.2023.Principle-driven
self-alignmentoflanguagemodelsfromscratchwithminimalhumansupervision.AdvancesinNeuralInformationProcessingSystems36.
[370] SShyamSundarandEun-JuLee.2022.Rethinkingcommunicationintheeraofartificialintelligence.HumanCommunicationResearch48,3(2022),
379–385.
[371] HariniSuresh,KathleenMLewis,JohnGuttag,andArvindSatyanarayan.2022.Intuitivelyassessingmlmodelreliabilitythroughexample-based
explanationsandeditingmodelinputs.In27thInternationalConferenceonIntelligentUserInterfaces.767–781.
[372] SiddharthSuresh,KushinMukherjee,XizhengYu,Wei-ChunHuang,LisaPadua,andTimothyRogers.2023.Conceptualstructurecoheresin
humancognitionbutnotinlargelanguagemodels.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.
722–738.
[373] PhillipSwazinna,SteffenUdluft,andThomasRunkler.2023. User-InteractiveOfflineReinforcementLearning.InTheEleventhInternational
ConferenceonLearningRepresentations.
[374] MaxwellSzymanski,MartijnMillecamp,andKatrienVerbert.2021.Visual,textualorhybrid:theeffectofuserexpertiseondifferentexplanations.
In26thinternationalconferenceonintelligentuserinterfaces.109–119.
[375] YiTay,DonovanOng,JieFu,AlvinChan,NancyChen,AnhTuanLuu,andChristopherPal.2020.Wouldyourather?anewbenchmarkforlearning
machinealignmentwithculturalvaluesandsocialpreferences.InProceedingsofthe58thAnnualMeetingoftheAssociationforComputational
Linguistics.5369–5373.
[376] IanTenney,JamesWexler,JasmijnBastings,TolgaBolukbasi,AndyCoenen,SebastianGehrmann,EllenJiang,MahimaPushkarna,CareyRadebaugh,
EmilyReif,etal.2020.TheLanguageInterpretabilityTool:Extensible,InteractiveVisualizationsandAnalysisforNLPModels.InProceedingsofthe
2020ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.107–118.
[377] MaartjeTerHoeve,JuliaKiseleva,andMaartenRijke.2022. WhatMakesaGoodandUsefulSummary?IncorporatingUsersinAutomatic
SummarizationResearch.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies.46–75.
[378] MichaelTerry,ChinmayKulkarni,MartinWattenberg,LucasDixon,andMeredithRingelMorris.2023.AIAlignmentintheDesignofInteractive
AI:SpecificationAlignment,ProcessAlignment,andEvaluationSupport.arXivpreprintarXiv:2311.00710(2023).
[379] KatherineTian,EricMitchell,HuaxiuYao,ChristopherDManning,andChelseaFinn.2024.Fine-tuninglanguagemodelsforfactuality.InThe
TwelfthInternationalConferenceonLearningRepresentations.
[380] KatherineTian,EricMitchell,AllanZhou,ArchitSharma,RafaelRafailov,HuaxiuYao,ChelseaFinn,andChristopherDManning.2023.JustAsk
forCalibration:StrategiesforElicitingCalibratedConfidenceScoresfromLanguageModelsFine-TunedwithHumanFeedback.InProceedingsof
the2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.5433–5442.
[381] YuandongTian,QuchengGong,andYuJiang.2020.Jointpolicysearchformulti-agentcollaborationwithimperfectinformation.Advancesin
NeuralInformationProcessingSystems33,19931–19942.
[382] YuanTian,ZhengZhang,ZhengNing,TobyLi,JonathanKKummerfeld,andTianyiZhang.2023.InteractiveText-to-SQLGenerationviaEditable
Step-by-StepExplanations.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.16149–16166.
[383] NavaTintarevandJudithMasthoff.2007.Asurveyofexplanationsinrecommendersystems.In2007IEEE23rdinternationalconferenceondata
engineeringworkshop.IEEE,801–810.
51Manuscript,submittedtoACM,2024 Shenetal.
[384] SuzanneTolmeijer,MarkusChristen,SerhiyKandul,MarkusKneer,andAbrahamBernstein.2022.Capablebutamoral?ComparingAIandhuman
expertcollaborationinethicaldecisionmaking.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–17.
[385] MarcelTorneVillasevil,BalsellsIPamies,ZihanWang,SamedhDesai,TaoChen,PulkitAgrawal,AbhishekGupta,etal.2023.Breadcrumbstothe
Goal:SupervisedGoalSelectionfromHuman-in-the-LoopFeedback.AdvancesinNeuralInformationProcessingSystems36.
[386] Bo-HsiangTseng,YinpeiDai,FlorianKreyssig,andBillByrne.2021.TransferableDialogueSystemsandUserSimulators.InProceedingsofthe59th
AnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJointConferenceonNaturalLanguageProcessing(Volume
1:LongPapers).152–166.
[387] CatherineTucker,AAgrawal,JGans,andAGoldfarb.2018.Privacy,algorithms,andartificialintelligence.Theeconomicsofartificialintelligence:
Anagenda(2018),423–437.
[388] AlexTurnerandPrasadTadepalli.2022.Parametricallyretargetabledecision-makerstendtoseekpower.AdvancesinNeuralInformationProcessing
Systems35(2022),31391–31401.
[389] AlexanderMattTurner,LoganRiggsSmith,RohinShah,AndrewCritch,andPrasadTadepalli.2021.OptimalPoliciesTendToSeekPower.(2021).
[390] NielsVanBerkel,JorgeGoncalves,DanielRusso,SimoHosio,andMikaelBSkov.2021.Effectofinformationpresentationonfairnessperceptions
ofmachinelearningpredictors.InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–13.
[391] RamaAdithyaVaranasiandNiteshGoyal.2023.“Itiscurrentlyhodgepodge”:ExaminingAI/MLPractitioners’ChallengesduringCo-productionof
ResponsibleAIValues.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems(CHI’23).AssociationforComputing
Machinery,NewYork,NY,USA,Article251,17pages. https://doi.org/10.1145/3544548.3580903
[392] HelenaVasconcelos,MatthewJörke,MadeleineGrunde-McLaughlin,TobiasGerstenberg,MichaelSBernstein,andRanjayKrishna.2023.Explana-
tionscanreduceoverrelianceonaisystemsduringdecision-making.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1(2023),
1–38.
[393] OleksandraVereschak,GillesBailly,andBaptisteCaramiaux.2021.HowtoevaluatetrustinAI-assisteddecisionmaking?Asurveyofempirical
methodologies.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–39.
[394] MuditVermaandKatherineMetcalf.2023.HindsightPRIORsforRewardLearningfromHumanPreferences.InTheTwelfthInternationalConference
onLearningRepresentations.
[395] JesseVig,WojciechKryściński,KaranGoel,andNazneenRajani.2021.SummVis:InteractiveVisualAnalysisofModels,Data,andEvaluationfor
TextSummarization.InProceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJoint
ConferenceonNaturalLanguageProcessing:SystemDemonstrations.150–158.
[396] AlejandroCuevasVillalba,EvaMBrown,JenniferVScurrell,JasonEntenmann,andMadeleineIGDaepp.2023. AutomatedIntervieweror
AugmentedSurvey?CollectingSocialDatawithLargeLanguageModels.arXivpreprintarXiv:2309.10187(2023).
[397] KailasVodrahalli,TobiasGerstenberg,andJamesYZou.2022.Uncalibratedmodelscanimprovehuman-aicollaboration.AdvancesinNeural
InformationProcessingSystems35,4004–4016.
[398] HenrikVoigt,ÖzgeAlaçam,MoniqueMeuschke,KaiLawonn,andSinaZarrieß.2022. Thewhyandthehow:Asurveyonnaturallanguage
interactioninvisualization.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies.348–374.
[399] EricWallace,JensTuyls,JunlinWang,SanjaySubramanian,MattGardner,andSameerSingh.2019. AllenNLPInterpret:AFrameworkfor
ExplainingPredictionsofNLPModels.InConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP):SystemDemonstrations.
[400] DakuoWang,JustinDWeisz,MichaelMuller,ParikshitRam,WernerGeyer,CaseyDugan,YlaTausczik,HorstSamulowitz,andAlexanderGray.
2019.Human-AIcollaborationindatascience:Exploringdatascientists’perceptionsofautomatedAI.ProceedingsoftheACMonhuman-computer
interaction3,CSCW(2019),1–24.
[401] DandingWang,QianYang,AshrafAbdul,andBrianYLim.2019.Designingtheory-drivenuser-centricexplainableAI.InProceedingsofthe2019
CHIconferenceonhumanfactorsincomputingsystems.1–15.
[402] FengjieWang,XuyeLiu,OujingLiu,AliNeshati,TengfeiMa,MinZhu,andJianZhao.2023.Slide4N:Creatingpresentationslidesfromcomputational
notebookswithhuman-aicollaboration.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–18.
[403] JiashuoWang,HaozhaoWang,ShichaoSun,andWenjieLi.2023.Aligninglanguagemodelswithhumanpreferencesviaabayesianapproach.
AdvancesinNeuralInformationProcessingSystems36.
[404] NanWang,QifanWang,Yi-ChiaWang,MaziarSanjabi,JingzhouLiu,HamedFirooz,HongningWang,andShaoliangNie.2023. COFFEE:
CounterfactualFairnessforPersonalizedTextGenerationinExplainableRecommendation.InProceedingsofthe2023ConferenceonEmpirical
MethodsinNaturalLanguageProcessing.13258–13275.
[405] PeiyiWang,LeiLi,LiangChen,DaweiZhu,BinghuaiLin,YunboCao,QiLiu,TianyuLiu,andZhifangSui.2023.Largelanguagemodelsarenot
fairevaluators.arXivpreprintarXiv:2305.17926(2023).
[406] QiaosiWang,MichaelMadaio,ShaunKane,ShivaniKapania,MichaelTerry,andLaurenWilcox.2023.Designingresponsibleai:Adaptationsofux
practicetomeetresponsibleaichallenges.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–16.
[407] QianwenWang,YaoMing,ZhihuaJin,QiaomuShen,DongyuLiu,MicahJSmith,KalyanVeeramachaneni,andHuaminQu.2019. Atmseer:
Increasingtransparencyandcontrollabilityinautomatedmachinelearning.InProceedingsofthe2019CHIconferenceonhumanfactorsincomputing
systems.1–12.
52TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[408] QiaosiWang,KoustuvSaha,EricGregori,DavidJoyner,andAshokGoel.2021.Towardsmutualtheoryofmindinhuman-aiinteraction:How
languagereflectswhatstudentsperceiveaboutavirtualteachingassistant.InProceedingsofthe2021CHIconferenceonhumanfactorsincomputing
systems.1–14.
[409] XingjinWang,LinjingLi,andDanielZeng.2023.LDM2:ALargeDecisionModelImitatingHumanCognitionwithDynamicMemoryEnhancement.
InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.4660–4681.
[410] XinruWang,ZhuoranLu,andMingYin.2022.WillYouAccepttheAIRecommendation?PredictingHumanBehaviorinAI-AssistedDecision
Making.InProceedingsoftheACMWebConference2022(,VirtualEvent,Lyon,France,)(WWW’22).AssociationforComputingMachinery,New
York,NY,USA,1697–1708. https://doi.org/10.1145/3485447.3512240
[411] XinpengWangandBarbaraPlank.2023.ACTOR:ActiveLearningwithAnnotator-specificClassificationHeadstoEmbraceHumanLabelVariation.
InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing.2046–2052.
[412] XiWang,HosseinRahmani,JiqunLiu,andEmineYilmaz.2023. ImprovingConversationalRecommendationSystemsviaBiasAnalysisand
Language-Model-EnhancedDataAugmentation.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.3609–3622.
[413] XinruWangandMingYin.2021.Areexplanationshelpful?acomparativestudyoftheeffectsofexplanationsinai-assisteddecision-making.In
26thinternationalconferenceonintelligentuserinterfaces.318–328.
[414] XinruWangandMingYin.2023.Watchoutforupdates:Understandingtheeffectsofmodelexplanationupdatesinai-assisteddecisionmaking.In
Proceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–19.
[415] YunlongWang,PriyadarshiniVenkatesh,andBrianYLim.2022.Interpretabledirecteddiversity:Leveragingmodelexplanationsforiterative
crowdideation.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputingSystems.1–28.
[416] YimingWang,ZhuoshengZhang,andRuiWang.2023.Element-awareSummarizationwithLargeLanguageModels:Expert-alignedEvaluation
andChain-of-ThoughtMethod.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).
8640–8665.
[417] YufeiWang,WanjunZhong,LiangyouLi,FeiMi,XingshanZeng,WenyongHuang,LifengShang,XinJiang,andQunLiu.2023.Aligninglarge
languagemodelswithhuman:Asurvey.arXivpreprintarXiv:2307.12966(2023).
[418] ZhilinWang,YuYingChiu,andYuCheungChiu.2023.HumanoidAgents:PlatformforSimulatingHuman-likeGenerativeAgents.InProceedings
ofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.167–176.
[419] ZhaoyangWang,ShaohanHuang,YuxuanLiu,JiahaiWang,MinghuiSong,ZihanZhang,HaizhenHuang,FuruWei,WeiweiDeng,FengSun,etal.
2023.DemocratizingReasoningAbility:TailoredLearningfromLargeLanguageModel.InProceedingsofthe2023ConferenceonEmpiricalMethods
inNaturalLanguageProcessing.1948–1966.
[420] ZekunWang,GeZhang,KexinYang,NingShi,WangchunshuZhou,ShaochunHao,GuangzhengXiong,YizhiLi,MongYuanSim,XiuyingChen,
etal.2023.Interactivenaturallanguageprocessing.arXivpreprintarXiv:2305.13246(2023).
[421] ZijieJWang,ChinmayKulkarni,LaurenWilcox,MichaelTerry,andMichaelMadaio.2024.Farsight:FosteringResponsibleAIAwarenessDuring
AIApplicationPrototyping.InProceedingsoftheCHIConferenceonHumanFactorsinComputingSystems.1–40.
[422] JingWei,SungdongKim,HyunhoonJung,andYoung-HoKim.2023.Leveraginglargelanguagemodelstopowerchatbotsforcollectinguser
self-reporteddata.arXivpreprintarXiv:2301.05843(2023).
[423] DanielKarlIWeidele,ShaziaAfzal,AbelNValente,ColeMakuch,OwenCornec,LongVu,DharmashankarSubramanian,WernerGeyer,Rahul
Nair,IngeVejsbjerg,etal.2023.AutoDOViz:Human-CenteredAutomationforDecisionOptimization.InProceedingsofthe28thInternational
ConferenceonIntelligentUserInterfaces.664–680.
[424] LauraWeidinger,MaribethRauh,NahemaMarchal,AriannaManzini,LisaAnneHendricks,JuanMateos-Garcia,StevieBergman,JackieKay,
ConorGriffin,BenBariach,etal.2023.Sociotechnicalsafetyevaluationofgenerativeaisystems.arXivpreprintarXiv:2310.11986(2023).
[425] JustinDWeisz,MichaelMuller,StephanieHoude,JohnRichards,StevenIRoss,FernandoMartinez,MayankAgarwal,andKartikTalamadupula.
2021.Perfectionnotrequired?Human-AIpartnershipsincodetranslation.In26thInternationalConferenceonIntelligentUserInterfaces.402–412.
[426] CharlesWelch,ChenxiGu,JonathanKKummerfeld,VerónicaPérez-Rosas,andRadaMihalcea.2022.Leveragingsimilarusersforpersonalized
languagemodelingwithlimiteddata.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:Long
Papers).1742–1752.
[427] SarahWiegreffe,JackHessel,SwabhaSwayamdipta,MarkRiedl,andYejinChoi.2022.ReframingHuman-AICollaborationforGeneratingFree-Text
Explanations.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguage
Technologies.632–658.
[428] NorbertWiener.1960.SomeMoralandTechnicalConsequencesofAutomation:Asmachineslearntheymaydevelopunforeseenstrategiesat
ratesthatbaffletheirprogrammers.Science131,3410(1960),1355–1358.
[429] Wikipedia.2024.AIalignment—Wikipedia,TheFreeEncyclopedia.http://en.wikipedia.org/w/index.php?title=AI%20alignment&oldid=1220304776.
[Online;accessed05-May-2024].
[430] MagdalenaWischnewski,NicoleKrämer,andEmmanuelMüller.2023.Measuringandunderstandingtrustcalibrationsforautomatedsystems:a
surveyofthestate-of-the-artandfuturedirections.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–16.
[431] RichmondYWong,MichaelAMadaio,andNickMerrill.2023.Seeinglikeatoolkit:HowtoolkitsenvisiontheworkofAIethics.Proceedingsofthe
ACMonHuman-ComputerInteraction7,CSCW1(2023),1–27.
[432] MichaelWooldridge.1999.Intelligentagents.Multiagentsystems:Amodernapproachtodistributedartificialintelligence1(1999),27–73.
53Manuscript,submittedtoACM,2024 Shenetal.
[433] AustinPWright,OmarShaikh,HaekyuPark,WillEpperson,MuhammedAhmed,StephanePinel,DuenHorngChau,andDiyiYang.2021.RECAST:
Enablinguserrecourseandinterpretabilityoftoxicitydetectionmodelswithinteractivevisualization.ProceedingsoftheACMonHuman-Computer
Interaction5,CSCW1(2021),1–26.
[434] JundaWu,RuiWang,TongYu,RuiyiZhang,HandongZhao,ShuaiLi,RicardoHenao,andAniNenkova.2022.Context-awareInformation-theoretic
CausalDe-biasingforInteractiveSequenceLabeling.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2022.3436–3448.
[435] QingyunWu,GaganBansal,JieyuZhang,YiranWu,ShaokunZhang,ErkangZhu,BeibinLi,LiJiang,XiaoyunZhang,andChiWang.2023.
Autogen:Enablingnext-genllmapplicationsviamulti-agentconversationframework.arXivpreprintarXiv:2308.08155(2023).
[436] SherryWu,HuaShen,DanielSWeld,JeffreyHeer,andMarcoTulioRibeiro.2023.Scattershot:Interactivein-contextexamplecurationfortext
transformation.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.353–367.
[437] SherryWu,HuaShen,DanielSWeld,JeffreyHeer,andMarcoTulioRibeiro.2023.Scattershot:Interactivein-contextexamplecurationfortext
transformation.InProceedingsofthe28thInternationalConferenceonIntelligentUserInterfaces.353–367.
[438] TongshuangWu,MichaelTerry,andCarrieJunCai.2022.Aichains:Transparentandcontrollablehuman-aiinteractionbychaininglargelanguage
modelprompts.InProceedingsofthe2022CHIconferenceonhumanfactorsincomputingsystems.1–22.
[439] WinstonWu,LuWang,andRadaMihalcea.2023.Cross-CulturalAnalysisofHumanValues,Morals,andBiasesinFolkTales.InThe2023Conference
onEmpiricalMethodsinNaturalLanguageProcessing.
[440] YufanWu,YinghuiHe,YilinJia,RadaMihalcea,YulongChen,andNaihaoDeng.2023.Hi-ToM:ABenchmarkforEvaluatingHigher-OrderTheory
ofMindReasoninginLargeLanguageModels.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.10691–10706.
[441] ZeqiuWu,YushiHu,WeijiaShi,NouhaDziri,AlaneSuhr,PrithvirajAmmanabrolu,NoahASmith,MariOstendorf,andHannanehHajishirzi.2023.
Fine-grainedhumanfeedbackgivesbetterrewardsforlanguagemodeltraining.AdvancesinNeuralInformationProcessingSystems36.
[442] ChengxingXie,CanyuChen,FeiranJia,ZiyuYe,KaiShu,AdelBibi,ZiniuHu,PhilipTorr,BernardGhanem,andGuohaoLi.2024.CanLarge
LanguageModelAgentsSimulateHumanTrustBehaviors?.InICLR2024Workshop:HowFarAreWeFromAGI.
[443] BinfengXu,XukunLiu,HuaShen,ZeyuHan,YuhanLi,MurongYue,ZhiyuanPeng,YuchenLiu,ZiyuYao,andDongkuanXu.2023.Gentopia.AI:
ACollaborativePlatformforTool-AugmentedLLMs.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:
SystemDemonstrations.237–245.
[444] JingXu,MeganUng,MojtabaKomeili,KushalArora,Y-LanBoureau,andJasonWeston.2023.LearningNewSkillsafterDeployment:Improving
open-domaininternet-drivendialoguewithhumanfeedback.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputational
Linguistics(Volume1:LongPapers).13557–13572.
[445] SonglinXuandXinyuZhang.2023.Augmentinghumancognitionwithanai-mediatedintelligentvisualfeedback.InProceedingsofthe2023CHI
ConferenceonHumanFactorsinComputingSystems.1–16.
[446] YihengXu,HongjinSu,ChenXing,BoyuMi,QianLiu,WeijiaShi,BinyuanHui,FanZhou,YitaoLiu,TianbaoXie,etal.2024.Lemur:Harmonizing
naturallanguageandcodeforlanguageagents.InTheTwelfthInternationalConferenceonLearningRepresentations.
[447] HaoYan,SaurabhSrivastava,YintaoTai,SidaIWang,Wen-tauYih,andZiyuYao.2023.LearningtoSimulateNaturalLanguageFeedbackfor
InteractiveSemanticParsing.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).
3149–3170.
[448] JunbingYan,ChengyuWang,TaolinZhang,XiaofengHe,JunHuang,andWeiZhang.2023.FromComplextoSimple:UnravelingtheCognitive
TreeforReasoningwithSmallLanguageModels.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023.12413–12425.
[449] XueYan,JiaxianGuo,XingzhouLou,JunWang,HaifengZhang,andYaliDu.2023.AnEfficientEnd-to-EndTrainingApproachforZero-Shot
Human-AICoordination.AdvancesinNeuralInformationProcessingSystems36.
[450] ChunxuYang,Chien-ShengWu,LidiyaMurakhovs’ka,PhilippeLaban,andXiangChen.2023. INTELMO:EnhancingModels’Adoptionof
InteractiveInterfaces.InProceedingsofthe2023ConferenceonEmpiricalMethodsinNaturalLanguageProcessing:SystemDemonstrations.161–166.
[451] QianYang,YuexingHao,KexinQuan,StephenYang,YiranZhao,VolodymyrKuleshov,andFeiWang.2023.Harnessingbiomedicalliteratureto
calibrateclinicians’trustinAIdecisionsupportsystems.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–14.
[452] QianYang,AaronSteinfeld,CarolynRosé,andJohnZimmerman.2020.Re-examiningwhether,why,andhowhuman-AIinteractionisuniquely
difficulttodesign.InProceedingsofthe2020chiconferenceonhumanfactorsincomputingsystems.1–13.
[453] BingshengYao,IshanJindal,LucianPopa,YannisKatsis,SayanGhosh,LihongHe,YuxuanLu,ShashankSrivastava,YunyaoLi,JamesHendler,
etal.2023.Beyondlabels:Empoweringhumanannotatorswithnaturallanguageexplanationsthroughanovelactive-learningarchitecture.In
FindingsoftheAssociationforComputationalLinguistics:EMNLP2023.11629–11643.
[454] BingshengYao,PrithvirajSen,LucianPopa,JamesHendler,andDakuoWang.2023.AreHumanExplanationsAlwaysHelpful?TowardsObjective
EvaluationofHumanNaturalLanguageExplanations.InProceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics
(Volume1:LongPapers).14698–14713.
[455] JingYao,XiaoyuanYi,XitingWang,JindongWang,andXingXie.2023.FromInstructionstoIntrinsicHumanValues–ASurveyofAlignment
GoalsforBigModels.arXivpreprintarXiv:2308.12014(2023).
[456] YifanYao,JinhaoDuan,KaidiXu,YuanfangCai,ZhiboSun,andYueZhang.2024.Asurveyonlargelanguagemodel(llm)securityandprivacy:
Thegood,thebad,andtheugly.High-ConfidenceComputing(2024),100211.
[457] ZonghaiYao,BenjaminSchloss,andSaiSelvaraj.2023.ImprovingSummarizationwithHumanEdits.InProceedingsofthe2023Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing.2604–2620.
54TowardsBidirectionalHuman-AIAlignment:ASystematicReview Manuscript,submittedtoACM,2024
[458] SeonghyeonYe,DoyoungKim,SungdongKim,HyeonbinHwang,SeungoneKim,YongraeJo,JamesThorne,JuhoKim,andMinjoonSeo.2024.
FLASK:Fine-grainedLanguageModelEvaluationbasedonAlignmentSkillSets.InTheTwelfthInternationalConferenceonLearningRepresentations.
[459] XiYeandGregDurrett.2022.CanExplanationsBeUsefulforCalibratingBlackBoxModels?.InProceedingsofthe60thAnnualMeetingofthe
AssociationforComputationalLinguistics(Volume1:LongPapers).6199–6212.
[460] NurYildirim,AlexKass,TeresaTung,ConnorUpton,DonnachaCostello,RobertGiusti,SinemLacin,SaraLovic,JamesMO’Neill,RudiO’Reilly
Meehan,etal.2022.HowexperienceddesignersofenterpriseapplicationsengageAIasadesignmaterial.InProceedingsofthe2022CHIConference
onHumanFactorsinComputingSystems.1–13.
[461] MingYin,JenniferWortmanVaughan,andHannaWallach.2019.Understandingtheeffectofaccuracyontrustinmachinelearningmodels.In
Proceedingsofthe2019chiconferenceonhumanfactorsincomputingsystems.1–12.
[462] ChaoYu,JiaxuanGao,WeilinLiu,BotianXu,HaoTang,JiaqiYang,YuWang,andYiWu.2023.LearningZero-ShotCooperationwithHumans,
AssumingHumansAreBiased.InTheEleventhInternationalConferenceonLearningRepresentations.
[463] HongyiYuan,ZhengYuan,ChuanqiTan,WeiWang,SongfangHuang,andFeiHuang.2023.RRHF:Rankresponsestoalignlanguagemodelswith
humanfeedback.AdvancesinNeuralInformationProcessingSystems36(2023).
[464] YifuYuan,JianyeHao,YiMa,ZibinDong,HebinLiang,JinyiLiu,ZhixinFeng,KaiZhao,andYanZheng.2024.Uni-RLHF:UniversalPlatformand
BenchmarkSuiteforReinforcementLearningwithDiverseHumanFeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[465] AlexeyZagalsky,DovTe’eni,InbalYahav,DavidGSchwartz,GahlSilverman,DanielCohen,YossiMann,andDafnaLewinsky.2021.Thedesignof
reciprocallearningbetweenhumanandartificialintelligence.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–36.
[466] YuhengZha,YichiYang,RuichenLi,andZhitingHu.2023.AlignScore:EvaluatingFactualConsistencywithAUnifiedAlignmentFunction.In
Proceedingsofthe61stAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).11328–11348.
[467] HongliZhan,DesmondOng,andJunyiJessyLi.2023.EvaluatingSubjectiveCognitiveAppraisalsofEmotionsfromLargeLanguageModels.
(2023),14418–14446.
[468] AngieZhang,OlympiaWalker,KaciNguyen,JiajunDai,AnqingChen,andMinKyungLee.2023.DeliberatingwithAI:ImprovingDecision-Making
fortheFuturethroughParticipatoryAIDesignandStakeholderDeliberation.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW1
(2023),1–32.
[469] HanZhang,YuLei,LinGui,MinYang,YulanHe,HuiWang,andRuifengXu.2024.CPPO:ContinualLearningforReinforcementLearningwith
HumanFeedback.InTheTwelfthInternationalConferenceonLearningRepresentations.
[470] JiaxinZhang,ZhuohangLi,KamalikaDas,andSricharanKumar.2023.InteractiveMulti-fidelityLearningforCost-effectiveAdaptationofLanguage
ModelwithSparseHumanSupervision.AdvancesinNeuralInformationProcessingSystems36.
[471] QiaoningZhang,MatthewLLee,andScottCarter.2022.Youcompleteme:Human-aiteamsandcomplementaryexpertise.InProceedingsofthe
2022CHIconferenceonhumanfactorsincomputingsystems.1–28.
[472] RuiZhang,NathanJMcNeese,GuoFreeman,andGeoffMusick.2021."Anidealhuman"expectationsofAIteammatesinhuman-AIteaming.
ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW3(2021),1–25.
[473] YangjunZhang,PengjieRen,andMaartendeRijke.2021.Ahuman-machinecollaborativeframeworkforevaluatingmalevolenceindialogues.
InProceedingsofthe59thAnnualMeetingoftheAssociationforComputationalLinguisticsandthe11thInternationalJointConferenceonNatural
LanguageProcessing(Volume1:LongPapers).5612–5623.
[474] ZhengZhang,JieGao,RanjodhSinghDhaliwal,andTobyJia-JunLi.2023. Visar:Ahuman-aiargumentativewritingassistantwithvisual
programmingandrapiddraftprototyping.InProceedingsofthe36thAnnualACMSymposiumonUserInterfaceSoftwareandTechnology.1–30.
[475] ZhengZhang,YingXu,YanhaoWang,BingshengYao,DanielRitchie,TongshuangWu,MoYu,DakuoWang,andTobyJia-JunLi.2022.Storybuddy:
Ahuman-aicollaborativechatbotforparent-childinteractivestorytellingwithflexibleparentalinvolvement.InProceedingsofthe2022CHI
ConferenceonHumanFactorsinComputingSystems.1–21.
[476] HaiyanZhao,HanjieChen,FanYang,NinghaoLiu,HuiqiDeng,HengyiCai,ShuaiqiangWang,DaweiYin,andMengnanDu.2024.Explainability
forlargelanguagemodels:Asurvey.ACMTransactionsonIntelligentSystemsandTechnology15,2(2024),1–38.
[477] LingjunZhao,KhanhNguyen,andHalDauméIII.2023. Define,Evaluate,andImproveTask-OrientedCognitiveCapabilitiesforInstruction
GenerationModels.InFindingsoftheAssociationforComputationalLinguistics:ACL2023.3688–3706.
[478] SiyanZhao,JohnDang,andAdityaGrover.2023.GroupPreferenceOptimization:Few-ShotAlignmentofLargeLanguageModels.InTheTwelfth
InternationalConferenceonLearningRepresentations.
[479] ChengboZheng,YuhengWu,ChuhanShi,ShuaiMa,JiehuiLuo,andXiaojuanMa.2023.CompetentbutRigid:IdentifyingtheGapinEmpowering
AItoParticipateEquallyinGroupDecision-Making.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems.1–19.
[480] RuiZheng,WeiShen,YuanHua,WenbinLai,ShihanDou,YuhaoZhou,ZhihengXi,XiaoWang,HaoranHuang,TaoGui,etal.2023.Improving
GeneralizationofAlignmentwithHumanPreferencesthroughGroupInvariantLearning.InTheTwelfthInternationalConferenceonLearning
Representations.
[481] EricZhouandDokyunLee.2024.Generativeartificialintelligence,humancreativity,andart.PNASnexus3,3(2024),pgae052.
[482] EnyuZhou,RuiZheng,ZhihengXi,SongyangGao,XiaoranFan,ZichuFei,JingtingYe,TaoGui,QiZhang,andXuan-JingHuang.2023.RealBehavior:
AFrameworkforFaithfullyCharacterizingFoundationModels’Human-likeBehaviorMechanisms.InFindingsoftheAssociationforComputational
Linguistics:EMNLP2023.10262–10274.
55Manuscript,submittedtoACM,2024 Shenetal.
[483] XuhuiZhou,HaoZhu,LeenaMathur,RuohongZhang,HaofeiYu,ZhengyangQi,Louis-PhilippeMorency,YonatanBisk,DanielFried,Graham
Neubig,etal.2023.SOTOPIA:InteractiveEvaluationforSocialIntelligenceinLanguageAgents.InTheTwelfthInternationalConferenceonLearning
Representations.
[484] ZhaoweiZhu,JialuWang,HaoCheng,andYangLiu.2023. UnmaskingandImprovingDataCredibility:AStudywithDatasetsforTraining
HarmlessLanguageModels.InTheTwelfthInternationalConferenceonLearningRepresentations.
[485] DanielMZiegler,NisanStiennon,JeffreyWu,TomBBrown,AlecRadford,DarioAmodei,PaulChristiano,andGeoffreyIrving.2019.Fine-tuning
languagemodelsfromhumanpreferences.arXivpreprintarXiv:1909.08593(2019).
56