A Promise Theory Perspective on
The Role of Intent in Group Dynamics
M. Burgess and R.I.M. Dunbar
February 2, 2024
Abstract
We present a simple argument using Promise Theory and dimensional analysis for the
Dunbar scaling hierarchy, supported by recent data from group formation in Wikipedia
editing. We show how the assumption of a common priority seeds group alignment until
thecostsassociatedwithattendingtothegroupoutweighthebenefitsinadetailedbalance
scenario. Subjecttopartialefficiencyofimplementingpromisedintentions,wecanreproduce
a series of compatible rates that balance growth with entropy.
Contents
1 Introduction 1
2 Statistical physics of human-machine agents 2
2.1 Intent and promises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
2.2 Promise patterns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
3 Cost accounting for ‘grooming’ work 6
3.1 Dimensional accounting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
3.2 Work afforded by a limited capacity . . . . . . . . . . . . . . . . . . . . . . . . . 8
3.3 Probability of group size n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
3.4 The scaling of group hierarchy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
4 Human attention and neural processes 11
5 Remarks 12
1 Introduction
Thedynamicsofsocialgroupsinhigheranimalsisdeeplyentwinedwithcognition. Forhumans,
social groups form around a hierarchy of scales with very specific values [1], resulting from the
way information flows between members of the groups [2,3]. In human groups, we one sees
how the frequency of individual contacts scales group sizes inversely with frequency [4,5] and
this repetition amounts to a sense of ‘trust’ through increasing familiarity [6,7]. A common
base number for human groups is about 5 individuals, which corresponds closely to the upper
limit of 4 on the number that can take part in a coherent conversation [8–12]. The limit on
conversational group size appears to be set directly by the capacity to manage the mental states
1
4202
beF
1
]IS.sc[
1v89500.2042:viXraor viewpoints of other individuals [10]. The proposal by Burgess to examine the role of trust as
adynamicalcurrencyinsocialinteractionsbetweenarbitraryagents[13]motivatedanempirical
study looking at group phenomena on a large scale in Wikipedia editing; there the familiar
group patterns for humans were observed in an unusually large sample of data, and could be
viewed through the new theoretical lens of Promise Theory [14] for calculating the sizes based
on emergent scales [15].
In this paper, we show how a theoretical model of contentious autonomous agents, combined
with straightforward physics of dimensional analysis and some elementary statistical mechanics,
togetherofferanexplanationforthemainfeaturesofgroupdynamics. Inparticular,wecalculate
the probability for reaching a certain group size, based on the work expended in attenting to
other agents. The latter is clearly supported by (and acts as a proxy for) cognitive capacity. We
also show how this may be distorted in a predictable way by the effects of non-human processes
like ‘bots’. The results are in good agreement with the data from over 200,000 individuals and
bots.
Our model shows how groups come together in response to an initial seed that attracts the
attention of agents. The group accretes new members until contention between them eventually
drives the group apart or the seed loses its interest value. The predictions fit well with the data
from the Wikipedia study [15], and give credence to a new formalization of ‘trust’ as a currency
forbehaviouralalignmentratherthanmoraljudgement. Linkstoneurosciencearealsoanatural
place to seek explanations, for the link between brain sizes and group sizes, and we point out a
possible connection to brain oscillation rates for different levels of attention.
2 Statistical physics of human-machine agents
Progressintheoreticalsocialsciencehasbeenslowcomparedtoothernaturalsciences. Recently,
attempts to model social phenomena, in terms of variables that can be exposed as population
characteristics, has led to the nascent field of Socio-Physics [16,17]. Socio-physics models argue
principallybyanalogytoknownphenomenainphysics(usuallyspinmodels). However,amissing
pieceinthesedescriptionsistheunderlyingreasoningforboththevariablesandtheirlikenessto
knownproblemsinfundamentalphysics. Oneimaginessomeuniversalityargumentsatplay,but
without a deeper causal link, the likenesses remain somewhat superficial in character. A second
missingpieceisthevastlygreaterscopeforsemanticstoplayaroleinbehaviouronahumanscale.
Discussionsofelementaryphenomenacanaffordtosuppresssemanticsandpromoteuniversality
because there are few degrees of freedom in play. Such isolation of information channels isn’t
generally plausible in human systems unless one can argue in terms of entropy.
Promise Theory, proposed by Burgess in the context of human-machine systems [18], was
introduced to deal with such criticisms in the context of technology. It takes issue with the
assumptions of logic as well as the suitability of Game Theory [19], Graph Theory [20], and
Network Science [21], but synthesizes all of these into a tool set with fundamental principles
basedoncompatibilitywithInformationTheory[22]. ItwasdevelopedbyBergstraandBurgess
overthesubsequentyears[14],andmorerecentlyhasbeenadoptedasamodelforsocio-economic
thinking.
The difficulty in formalizing human level concepts is that there is often a tendency to fall
backonmoralphilosophyorpsychologytoargueratherthanlookingforanunderlyingcausality
on an agent or group level [23,24]. Promise Theory is a bottom up theoretical framework,
embodyinggraphtheoreticnotionsaswellasrepresentationsofsemanticanddynamicvariability.
It embodies founding principles for the autonomy of agents. Taking a bottom up approach, it
develops both algebraic formulations and scaling principles. Using Promise Theory, Burgess has
2proposedtousethefamiliarconceptoftrustasaunifyinginstrumentinordertoconnectfamiliar
behavioural phenomena (and terminology) with more formal analytical structures familiar from
physics. Aswe’llsee,trustgivesusaconvenientdynamicalpotentialontowhichwecangraftthe
semantics of morality, through repeated processes like rituals and beliefs. Thus, in this picture,
weexpectrepetitiontobeageneralprinciplethroughwhichhumansrehearsegovernancethrough
social norms and graces. These ritualistic promises provide surrogate ‘shared purposes’ to rally
people into collective behaviour.
2.1 Intent and promises
As outside observers, we can’t always ask agents (people, animals, or machinery) what drives
them,orwhattheyarethinkingbutwecantrytomaptheirbehavioursontoamodelofintentions
that match our own thinking. The intentional behaviour of an agent is rarely singular: it could
be a rich admixture of goals with varying priorities. Each agent will prioritize based on its
own ‘algorithm’. Should a particular seed promise pass a threshold attention level for group
formation, then this can manifest as an implicit bias, potentially seeding an alignment with
otheragents. Inphysics, wecallthisspontaneoussymmetrybreaking; it’sassociatedwithphase
transitions.
In Promise Theory, intentionality can be represented by stylized ‘promises’, which can be
characterized by a ‘direction’ of intent, defined within a space of possible outcomes. We needn’t
expand on the specific understanding of resources or processes that underly the fulfillment of
promises here. The key point is that this approach to intent allows us to build an impartial
algebraic representation for each agent, without prejudicing the dynamics of changing intent.
An agent A can promise something described by some intention (usually denoted b, for the
1
body of the promise) in the form of an offer (denoted +b) to another agent A
2
+b
A −−→A . (1)
1 2
Assuming the agent A accepts some amount of what is offered b′ (denoted −b′)
2
−b′
A −−→A , (2)
2 1
then a unidirectional flow of strength b∩b′ of intended outcomes binds the agents in a relation-
ship. Thisrequirestheattentionofbothparties,withdonorandreceptorpromises,andinvolves
time as an implicit resource.
Energyconsiderationsalonearenotasufficientbasisfordeterminingsystemicbehaviour: one
alsohastoknowtherulesbywhichitgetsmovedandexchangedbetweenthedynamicalvariables
of a system. Thus, we need a story about the effective forces and representations for interaction
too. Our experiences in physics can help to shape the way we represent these however.
Promises are like the steady state solutions for motion in physical systems. In addition
to promises, there can be transient events, driven by changing boundary conditions or new
information, such as when an agent throws a ball to another to catch unannounced. These are
denoted by a special arrow resembling a fist:
+b
A A (3)
1 2
Impositions are transient (unplanned) interactions. They induce sudden demands or costs onto
the recipient, they may be interpreted as the basis of contention, tending to pull agents unpre-
dictably off course. In Promise Theory impositions play a significant role in reducing trust [25].
Thisdynamicalpictureisconsistentwitha‘work/energy’interpretationoftrustalludedtoin[13].
3Promise Theory predicts that impositions tend to be ineffective, because they are likely to be ill
aligned with receptor promises. It also predicts that impositions tend to reduce trustworthiness
assessments and increase the attentiveness of a receiver.
Whether leading or following, agents that are imposed upon by their episodic ‘neighbours’
withtransientdemandstendtoincreasemistrustortheattentionlevelofthegroup. Thisattracts
agentswiththesameconcernstoalign. Latertheymaydriftawayfromthegroupwhenthecost
of attentive work exceeds a fractional threshold of group mistrust. These are the elements we
need to complete the basic model of group formation.
2.2 Promise patterns
Simmel introduced the notion of triads in social systems [26]. Another triad theory of sentiment
relations in social balance theory was proposed in [27–29] as a rule of threes proposed for the
social sciences [30]. Triadic agent molecules have been proposed many times as basic control
units for social networks, and have been implicated in group formation. Promise Theory does
notrecognizethesespeculativetriadicnetworkstructuresassuch. Ratheritpredictsatriangular
co-dependence between agents arising from the fundamental autonomy of agents. This means
that agents fundamentally make decisions from within, possibly tempered by conditions from
without, according to the law of assisted promise keeping [14]. The pattern may be used to
express the promise a message from sender to receiver through a third party delivery agent, for
example.
Figure 1 shows two ways in which groups could form. The semantics of group formation are
Common goal / foe
Co−dependence
allignment?
Figure 1: Groups form either because agents come together independently attracted to contribute to a
commoncause(likefightingacommonenemyorworkingonacommonproduct),ortheyformemergent
clustersbypairwisepercolationofpromiserelationships. Inourmodel,weassumethelefthandpicture
of attraction in which ‘mistrust’ of the central ‘seed’ promise drives increased attention and potentially
proximity as a secondary effect.
significant to the costs associated with them. A group that follows a single leader or interacts
one at a time is different from a group that tries to maintain global coherence all at once and
all the time. The latter is very rigid and very expensive. For N agents, the cost is of the order
N2. In our discussion, we find the loose hierarchical association to be the cost that provides the
best agreement with data.
4+X(Y)
Agent1
−X(Y) Seed/Target
−X,Y +X,−Y +Y(X)
−Y(X)
Agent2
Figure2: Abasiccooperation/calibrationtriangleinPromiseTheoryallowstwoagentstoworktogether
on behalf of a third, or allows a third to act as a seed effectively bringing them into alignment X =
Y. From Promise Theory, one would expect opportunistic dyadic structures N = 2 for compositional
or symbiotic specialization, with more important coordinated structures built from equilibrated/cross-
checked triads N =3.
Consider the primitive pattern involving three agents shown in figure 2. The triangle of
promises is the maximum coordination for three agents. This is the configuration by which they
canmaintainconsistentinformationandclaimto‘agree’withoneanother. ItiscalledtheLawof
ConditionalAssistanceinPromiseTheory. Itrepresentsaconfigurationofvoluntarycooperation
respecting the autonomy of the agents. Agent promises an intended outcome X, based on the
1
other agent’s intent to supply Y’ in the most general sense. The intended outcome X could
involvewatchingoverthegroup,performingsomeworkonitsbehalf,etc. Essentially,itrequires
paying attention to the promise and allocating time resources. Agent also promise to make
1
use of the promise Y provided by Seed, which could simply be access to its personal space, or
the ability to perform some service for it. We can use the shorthand notation for the directed
promises:

+X|Y
π X : Agent 1 −−−−→Seed  ≡Agent −+ −−X −(Y −→) Seed. (4)
−Y 1
π : Agent −−→Seed 
Y 1
to represent the conditional promise of X given Y, together with the promise to accept Y if
offered. Inotherwords, ‘IwillkeepthepromiseofX withtheassistanceofanother,whointurn
helps me by supplying Y, written +X|Y, and I promise you that I am accepting such help −Y’.
Omitting the details [14], the full collaboration now takes the form:
+X(Y)
Agent −−−−−→ Seed
1
−Y,+X
Agent −−−−−→ Agent
1 2
+Y,−X
Agent −−−−−→ Agent
2 1
+Y(X)
Agent −−−−−→ Seed
2
−X(Y)
Seed −−−−−→ Agent
1
−Y(X)
Seed −−−−−→ Agent (5)
2
Noticethesymmetriesbetween±inthepromisecollaborationofequilibriumstate,andbetween
X,Y indicating the complementarity of the promises. The maximal cost of this configuration is
close to the square of the number of agents. Such a cost is unsustainable for large numbers.
5Forgroupcooperation,thislevelofcooperationistooexpensivetobesustainedmuchbeyond
n = 3, as the cost of predictable assurances rises like n2. The level of cooperation we find
represented in the scaling of group formation data rather suggests only the association of agents
1 and 2 through the proxy hub of the third. By extension, this is a classic hierarchical model
in which a single hub plays a coordination role in keeping a group together—such as a head of
department or group leader. In other words, the Promise Theory, predicts that interactions we
might call ‘grooming’ of the relationships are basically one to one with a leader (scaling to one
to n−1 in a group of size n), as reflected in section 3.2).
When a seed is eliminated, or becomes overwhelmed by new priorities arising from envi-
ronmental pressures, contention between the seed promise and impositions from the ambient
environmentrises,destabilizingitasapriority. Thus,intheabsenceofastrongseed,thereisno
effectivepromisetoattractagentstogetherandtheydriftapartinresponsetotheperturbations
from competing intentions.
3 Cost accounting for ‘grooming’ work
Ourinterpretationoftrustisapragmaticone. Ultimately,it’sasemanticabstractionofthe‘work
of attention’, or cognitive work, as we’ll show below. Apart from minor semantic distinctions,
such work ranges over a variety of phenomena and scales from idle curiosity to intense scrutiny
and mistrust that are covered by the same attention processes. We can call all of these forms of
‘kinetic mistrust’.
Thedifferencesarethusinthedegreesofscrutinyandtheindividualcharacterizationoftheir
importance of each agent. One agent’s causal interest might be another agent’s response to
untrustworthy behaviour. We believe that this is consistent with normal usage, but it allows us
to formalize trust as a form of work analogous to energy in two parts.
Since trust works as an attention accounting quantity, it’s driven by work done at different
times,pastandpresent. Asinphysics,potentialenergyisasummaryofhistoricallyaccumulated
work, expressed as a coarse snapshot of the slowly-varying history. Conversely, kinetic energy
is an immediate release of work, in response to the tendencies of directionality expressed by
the potential. Since potential is historically accumulated work, we need memory processes to
transmute learning into kinematics. Any memory process will do, but agents that have brain
matter are obviously highly optimized for this and adds the sophistication for dealing with
memory on many levels from dynamics to semantics.
3.1 Dimensional accounting
Dimensionalanalysisisthewayscalesofmeasurementaredefinedinnaturalscience. Classically,
allmeasurescanbereducedtocombinationsofpropertiesregardedas‘innate’tophysics,namely
mass, length, time, and a few others. The role of time is central to group formation, principally
because it is closely associated with work. The counting of any relationship with respect to
time has to follow a universal dimensional analysis. These relations were derived for continuum
processes for ballistic models.
In continuum language, a force F applied over a path length dx in some parameter space is
equivalent to a directional impulse dp. If one assumes a process velocity ⃗v = d⃗x/dt, where d⃗x
representsthedirectionofanintentioninthespaceofoutcomes,thissettlestheaccountingofthe
quantities with respect to time. The usual ‘Newtonian’ conventions follow from the observation
that a change in potential energy (defining a force) has the same dimensions as a change in
6kinetic energy:
→−
dV = ∇V ·d⃗x=F⃗ ·d⃗x = F⃗ ·⃗vdt
d⃗p
= ·⃗v dt
dt
= ⃗v·d⃗p
= m⃗v·d⃗v
1
= md(⃗v·⃗v)
2
(cid:18) (cid:19)
1
= d mv2
2
= dT. (6)
Thus,therelationshipbetweenthequantitieswecountasforceandenergyareconstrainedmainly
by dimension and rate, and energy accounting.
Inourdynamicsofpotentialalignmentsandkineticattentionprocesses,thekineticsaremore
like Shannon information sampling [22] than linear motion, but the dimensions have to be the
same. The rate of conversion of accumulated work from the keeping of promises is thus found
dimensionally by comparing
1
V ∼ mv2 (7)
2
up to dimensionless factors, where the attention rate or ‘velocity’ v whose dimensions are arbi-
traryexceptfortheroleoftime. Thepotentialamountstoareliabilityforpromisekeeping. One
mightevencallitakindof‘goodwill’V inhumanterms. Theworkofasingleagent, interacting
in a group of size n, would be expected to scale as
c +c (n−1)
W(agent)= 1 2 (8)
c n
0 β
where c , c , and c are constants. At low utilization, we can expect the availability or channel
0 1 2
capacitytobeapproximatelyproportionaltothenumberofagentsinteracting. Oncecontentions
sets in, this effective number slows down as agents begin to leave a group to an average—which
is the value at which contention is maximal.
When βE =0, the probability has to be 1, so for n=1 (self), all the share is in one agent’s
hands. So c = 0. Now we have a single scale C ≡ c /c representing the level of shared
1 2 0
of contention between agents. To determine this, we use the promise seed configuration again
below. Note that, at maximum entropy, this is evenly distributed without particular favour to
any agent. So, based on these dimensional arguments, we expect the limit of maximum entropy
for large N to take the form:
(cid:18) (cid:19)
C(n−1)
P(β)∼exp − , (9)
n
β
where n is some scale that characterizes the intra-group contention, Small C implies tolerance
β
of contention, or loose coupling and thus larger group sizes, while large C implies some kind of
territorial overlap that leads to altercation.
73.2 Work afforded by a limited capacity
We can make this more formal as follows. Suppose each agent has a cognitive processing work
capacity W for the process of group interactions that it shares with other tasks too. How
max
the capacity is sliced is a detail that we don’t need to address here. If we think in terms of the
‘poweroutput’orworkoftheagents,inkineticterms,relatingtothepromiseofsharingthegroup
resources. At max entropy (large N and large ensembles), the probable work fraction P(W) for
distribution would take the form of a Boltzmann distribution over the relative costs [31,32]:
P ∼ e−βE (10)
W(agent)
where βE (cid:55)→ , (11)
Total capacity
where the availability is the finite budget for shared resource channel capacity. Moreover, from
Shannon [22], we know that the channel capacity is a dimensionless representation of the power:
(cid:18) (cid:19)
W(agent)
C =Blog 1+ (12)
Cost of contention
where B is the maximum bandwidth for throughput.
Withthesepointsinmind,andassumingthatinteractionsbetweengroupmembersarenot‘all
atonce’, butinterleavedprincipallyoneatatime, theaccumulatedworkshouldbeproportional
to the group remainder size:
W
W ≤ max, (13)
n n
Thebulkofthisworkisassumedtobethehandlingofimpositionsbyunexpectedgroupmembers
toreverseeffortsandotherwiseinterferewiththeagentconcerned,preventingorsmoothingover
such incidents. The agent may have other things to deal with in addition to ‘grooming’ or
placatingcontentiousothers, sothisworkallocationmightnotbe100%efficient. Sowecantake
the cognitive capacity as a share for work:
1
(n−1)W = mv2, (14)
n 2
forsomeratev. Now, wearrangetomeasurethesequantitiesinunitssuchthatwecancompare
dimensionless ratios. In dimensionless form, we can write
W 1 m
(cid:18)
v
(cid:19)2
(n−1) n = , (15)
W 2m v
max min max
The effective mass of the interaction (which plays the role of the cost of agent “involvement”
with others) presumably has a minimum scale rather than a maximum, though this doesn’t
matter since we eliminate this by changing variables. None of these work rates are measurable
in this study, so we need to relate them to something with dimensions of n. We can make the
identification
W m β
n min ≡ , (16)
W m ⟨N⟩
max T
which has the form
Fractional work effort
×efficiency, (17)
Fractional cost of involvement
8whereweusetheconstantβ ≤1asanefficiency. Thisismotivatedbytheidentificationof⟨N⟩
T
as the scale for group size with maximal contention cost. From (16) we interpret the Dunbar
group size as being based on:
⟨N⟩ =cost as a fraction of work budget×efficiency. (18)
T
Inotherwords,⟨N⟩ maybecalledthegroupcontentioncost,measuredincognitiveworkunits.
T
The actual values for ⟨N⟩ can’t be derived without a specific implementation model, but we
T
expectthisisaninnateinternalcapacityofeachkindofagent,asoriginallyproposedbyDunbar.
In that case, this dimensional identification, based on the assumption of linearly shared work
together withthe assumptionof maximalentropy yieldsresults compatible withthe social brain
hypothesis. The fact that we rediscover this in the case of Wikipedia histories [15] is evidence
that the editing is a principally human to human interaction, albeit with cyborg influences. In
the Wikipedia results, β =1 gives the appropriate fit. In Dunbar’s human groups. β =0.75 is a
closer estimate of the promise efficiency.
Agents come together around a particular seed when their prioritization of the seed promise
becomes the dominant force in their behaviour. For example, the appearance of a predator
activates a behaviour for a herd; the appearance of a new Wiki page on a subject close to
one’s heart activates a desire to contribute. In the absence of an attraction, there are enough
alternative attractions to pull animals away, leading to an exponential decay of this heightened
priority.
3.3 Probability of group size n
We can now extend this dimensional argument to predict the dimensionless frequency (or prob-
ability) of finding a group of size n, which we denote by ψ(n). The graph in figure 3 fits very
closely a simple formula which we can motivate from the theory:
4 ν1 2 e−ν 2β(n−1)
ψ(ν)= √ , ν = , (n>1), (19)
π ⟨N⟩ ⟨N⟩
T T
where β corresponds to a dimensionless (probabilistic) rate of promise keeping for the seed
promise, i.e. β is the fraction of promises kept reliably, since reducing β has the same effect
as reducing the group contention size limit higher (less tolerance of contention). Another way
to think of β is therefore as an metaphorical ‘temperature’ complement for agent entropy. As
contentionincreases,themaximumoccursatsmallergroupsandthatisequivalenttolesseffective
promise keeping to interact with the seed agent. The result of this fit is shown in figure 3.
3.4 The scaling of group hierarchy
The precise fit of the formula 19 is subject to some tuning (see figure3 especially for small n).
The relationship between the maximum frequency and maximal contention scales is determined,
however, by the rate equation for detailed balance that leads to (19). The value of n, which
maximizes kinetic mistrust, is called ⟨N⟩ , while the value of n leading to the maximum value
T
of ψ(n), determined by dψ(N) =0 is:
dn
⟨N⟩
nmax =1+ T. (20)
i 4β
Notice how the expected group size is still always less than the maximal contention size. This is
interesting, as it suggests that (statistically) agents tend to prioritize working more intimately
90.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0 5 10 15 20 25 30 35 40
n
Figure3: Curvefitofdatausingtheformulainequation19. Thecrossesapproximateerroruncertainty.
The model fit is expected to be worst for small n due to integer effects.
with smaller groups. This could be a sign that there is an additional contention cost associated
with switching between on going relationships, as there is in computing called context switching.
Wecanexaminesomevaluesforthesemaximarelationshipstoillustratethefitwiththelayer
model in Dunbar [33] and the specific data for Wikipedia [15]. The column for β =1 reproduces
the results from the Wikipedia data in [15]. Removing all bot interactions arbitrarily alters
⟨N⟩ slightly to give an effective value of β =0.93. The column with lower efficiency β =0.875
T
generates the usual stylized Dunbar sequence quite accurately:
10
)N(ispMode Wiki No Bots Dunbar Approx
nmax ⟨N⟩ (β =1) ⟨N⟩ (β =0.93) ⟨N⟩ (β =0.875)
i T T T
3 8
5 14.9 14
8 28
14 45.5
14.9 52
28 108
45.5 156
52 188
108 428
156 542
188 697
428 1708
542 1892
Reading down each column, we see the mode frequency limited by the next scale up in the
two right hand columns. We note that the apparent self-similar scaling fraction of group sizes
depends on β for its precise value. It’s therefore unrelated to presence of triadic relationships in
thepromisegraphofagents, sincetherelevantpromisegraphispurelyhubcentric duringgroup
formation. Some of the curves for these values are plotted in figure 4.
4 Human attention and neural processes
We have shown that, if group size is moderated by contention, or grooming work to overcome it,
then achievable group size depends on the intrinsic timescales over which agents can deal with
the contention. This gets eliminated as a variable in probability distribution, but its remnants
are found in dimensionless β. When the rate of seed-related promise keeping falls and β falls
in value, the group can only either sustain itself over a longer timescale (through more invested
work) or with fewer numbers. If the work has a maximum capacity, then the available fraction
is spread more thinly and less contentiously over larger ⟨N⟩ .
T
We can add a brief speculation to this prediction. If the group hierarchy is associated with
cortical contention in humans (and indeed other machinery), we should probably ask what are
the dominant neural processes at each level of the hierarchy? One possibility could be that the
group sizes correspond to different level of brain activity. A proxy for these dynamics is perhaps
‘brainwave’ oscillation modes [34] for the transport of information between cortical regions.
Frequency is associated with power [35], so it’s interesting to compare the hierarchy of group
sizestothepowerassociatedwithlevelsofattentionorbrainconcentration. Buzs´akiwrites[36]:
“The power density of local electrical field potential is inversely proportional to frequency in
themammaliancortex. This1/fpowerrelationshipimpliesthatperturbationsoccurringatslow
frequencies can cause a cascade of energy dissipation at higher frequencies and that widespread
slow oscillations modulate faster local event.” Thus the idling work required for attentiveness in
a typical group size might be expected to follow the same kind of power requirement.
110.25
0.2
0.15
0.1
0.05
0
0 20 40 60 80 100
n
Figure 4: Thegroupequilibriumlawplottedfor⟨N⟩ =4,8,30,150illustratingtheflatteningofgroup
T
probability curves with increasing number. The amplitude gives an approximate magnitude for the
attention power rate required to maintain each level.
Once again, on dimensional grounds ⟨N⟩ can only appear in this relationship multiplied by
T
an effective time conversion scale ∆τ for the ‘latency’, and the product of this with frequency
f ×⟨N⟩ represents an average throughput of information up to some intrinsic timescale ∆τ. So
in relative units:
Attention Brain wave (Hz) f Dunbar ⟨N⟩ level f ×⟨N⟩
light attention α 5-15 (5) 150 750
middle attention β 12-30 (25) 30 750
concentrated γ-fast 32-200 (150) 5 750
Theproductofthecolumnsisapproximatelyofconstantorder,suggestingthattheaverageeffort
is indeed in inverse proportion to the group size. This is numerically interesting, if not exactly
proof of a connection.
5 Remarks
What began as a pragmatic model of trust as attention in Promise Theory has led us to a
plausible explanation for the hierarchy of social group sizes discovered by Dunbar. In this work,
we bring together these two narratives to offer a tantalizing perspective on each.
12
)N(ispThe model makes a bold assumption, supported by the scaling, namely that groups in a
socialbrainhierarchyformaroundaseedofintent,whichactstocapturetheattentionofagents
through associated kinetic process. There is a de facto attractive ‘force’ that promotes group
accretiononasmallscale,andlaterfadesawaytobecomeasymptoticallyfreeasgroupsdisband.
Our summary relationship is based on continuum process algebra (usual for large N), but
we know that social groups are about individuals (small N). This is where the separation of
scales in Promise Theory is helpful. It is not the scaling of network that predicts these results,
but the underpinning process of assessment of social ties that we call ‘attention’ (and effectively
‘trust’). Thus a predictability of group behaviour requires the smooth exchange of experiences
over a large enough timescale to distill stable patterns1. This separation of dynamical process
scales is implicitly the result of evolutionary biology. Today, researchers in Artificial Intelligence
dare to solve it with alternative models and computers.
What is the all important seed promise? By definition, it promises the role of a prioritized
behaviourthat’ssharedbytheindividualsinagroup. InthecaseofWikiediting,it’sclearlythe
promiseoftheplatformtoenablesatisfactorypublishingofinformation—thecreativecommons,
withitsattendantbenefits. Foranimalsinapackorherd, itmightbethepromiseofadefensive
posture when a predator is nearby, or the co-location of some tidbit, that drives them to attend
to one another’s relative positions and cluster. They would then drift apart again once the seed
weregone[37]. Forareligiousgrouporcompany,itcouldbeacharismaticleader[38],whichalso
aligns with work on the origin and semantics of authority [39]. Alternatively, it could be a more
abstracthealthbenefitacquiredasanevolutionaryadaptationoververylongtimes,suchaswhen
a change in the weather or other environmental conditions triggers group changes, as in slime
moulddissociationforinstance—ormerelytheopportunisticsharingofatransientresource[40].
The semantics of a seed of intent might change frequently to reflect changing group dynamics,
even as the underlying dynamics remains a universal function of physiology.
Agents offer their attention to group processes variably in order to invoke a simple optimiza-
tion for beneficial reasons. They have a finite budget for attention, which is governed by their
work capacity. In a future in which humans bond with artificial enhancements as ‘cyborgs’, Ar-
tificialIntelligence mayaltersomeaspectsofthis. Thiscould, inturn, pose adifferentspectrum
of threat to human character that needs exactly the kind of cognitive capacity predicted in the
Dunbar hierarchy to deal with effectively.
Acknowledgement: MBisgratefultoGy¨orgyBusz´akifordiscussionsabouttheneuroscience.
This work was supported by the NLnet Foundation.
References
[1] R.I.M.Dunbar. Structureandfunctioninhumanandprimatesocialnetworks: Implications
for diffusion, network stability and health. Proc. R. Soc. London, 476A:20200446, 2020.
[2] B.J. West, G.F. Massari, G. Culbreth, R. Failla, M. Bologna, R.I.M. Dunbar, and
P. Grigolini. Relating size and functionality in human social networks through complex-
ity. Proceedings of the National Academy of Sciences, 117(31):18355–18358, 2020.
1Atthetimeofwriting,thereisarevisitationofauthorIsaacAsimov’sfictionalFoundationTrilogyconcerning
the large scale prediction of human affairs, which he called ‘psychohistory’. Although one can wonder whether
Asimovwouldhavebeenequippedtounderstandthis,thiskindofpredictionovermassivedatasetsandaverages
istheonlylevelatwhichhumanbehaviourislikelytobepredictable. Individualactionsappeardisconnectedand
noisyonasmallscale. Hisstoriesaboutrobotsimaginedartificialbrainsthatwereruledbypotentials(Asimov
wasabiochemist)ratherthandigitallogic,morelikethecyberneticsofWienerandothers.
13[3] B.J. West, G. Culbreth, R.I.M. Dunbar, and P. Grigolini. Fractal structure of human and
primate social networks optimizes information flow, 2023.
[4] I. Tamarit, J.A. Cuesta, R.I.M. Dunbar, and A. S´anchez. Cognitive resource allocation
determines the organization of personal networks. Proceedings of the National Academy of
Sciences, 115(33):8316–8321, 2018.
[5] I. Tamarit, A. S´anchez, and J.A. Cuesta. Beyond dunbar circles: a continuous description
of social relationships and resource allocation. Scientific Reports, 12:1–11, 2022.
[6] A.J. Sutcliffe, R.I.M. Dunbar, J. Binder, and H. Arrow. Relationships and the social brain:
integrating psychological and evolutionary perspectives. Brit. J. Psychol., 103:149–168,
2012.
[7] J.A. Bergstra and M. Burgess. Local and global trust based on the concept of promises.
Technical report, arXiv.org/abs/0912.4637 [cs.MA], 2006.
[8] R.I.M. Dunbar, A. Marriott, and N. Duncan. Human conversational behavior. Human
nature (Hawthorne, N.Y.), 8:231–246, 09 1997.
[9] G. Dezecache and R.I.M. Dunbar. Sharing the joke: The size of natural laughter groups.
Evolution and Human Behavior, 33:775–779, 11 2012.
[10] J.A. Krems, R.I.M. Dunbar, and S.L. Neuberg. Something to talk about: are conversation
sizesconstrainedbymentalmodelingabilities? Evolution and Human Behavior, 37(6):423–
428, 2016.
[11] C. Robertson, B. Tarr, M. Kempnich, and R.I.M. Dunbar. Rapid partner switching may
facilitateincreasedbroadcastgroupsizeindancecomparedwithconversationgroups. Ethol-
ogy, 123:736–747, 2017.
[12] M.DahmardehandR.I.M.Dunbar. Whatshallwetalkaboutinfarsi?: Contentofeveryday
conversations in iran. Human Nature, 28(4):423–433, 2017.
[13] M. Burgess. Notes on trust as a causal basis for social science. SSRN Archive, available at
http://dx.doi.org/10.2139/ssrn.4252501 (DOI: 10.2139/ssrn.4252501), August 2022.
[14] J.A. Bergstra and M. Burgess. Promise Theory: Principles and Applications (second edi-
tion). χtAxis Press, 2014,2019.
[15] M.BurgessandR.I.M.Dunbar.Grouprelatedphenomenainwikipediaedits.Inpreparation,
2023.
[16] S. Galam. Sociophysics. Springer, 2012.
[17] M. Jusup, P. Holme, K. Kanazawa, M. Takayasu, I. Romi´c, Z. Wang, S. Geˇcek, T. Lipi´c,
B. Podobnik, L. Wang, W. Luo, T. Klanjˇsˇcek, J. Fan, S. Boccaletti, and M. Perc. Social
physics. Physics Reports, 948:1–148, feb 2022.
[18] Mark Burgess. An approach to understanding policy based on autonomy and voluntary
cooperation. In IFIP/IEEE 16th international workshop on distributed systems operations
and management (DSOM), in LNCS 3775, pages 97–108, 2005.
[19] R.B. Myerson. Game theory: Analysis of Conflict. (Harvard University Press, Cambridge,
MA), 1991.
14[20] C. Berge. The Theory of Graphs. (Dover, New York), 2001.
[21] R. Albert and A. Barab´asi. Statistical mechanics of complex networks. Reviews of Modern
Physics, 74:47, 2002.
[22] C.E. Shannon and W. Weaver. The Mathematical Theory of Communication. University of
Illinois Press, Urbana, 1949.
[23] D. Gambetta, editor. Trust Making and Breaking Cooperative Relations. Basil Blackwell
Ltd, 1988.
[24] R. Bachmann and A. Zaheer. Handbook of Trust Research, 4th Edition. Edward Elgar,
2006.
[25] J.A. Bergstra and M. Du¨well. Accusation theory. Transmathematica, Dec. 2021.
[26] G. Simmel. The Sociology of Georg Simmel. New York: Free Press., 1950.
[27] F. Heider. Attitudes and cognitive organization. Journal of Psychology, 21:107–112, 1946.
[28] F. Heider. The Psychology of Interpersonal Relation. J. Wiley & Sons, 1958.
[29] Deni Khanafiah and Hokky Situngkir. Social balance theory, 2004.
[30] P.I. Zhelyazkov. Interactions and interests: Collaboration outcomes, competitive concerns,
and the limits to triadic closure. Administrative Science Quarterly, 63(1):210–247, 2018.
[31] F. Reif. Fundamentals of statistical mechanics. McGraw-Hill, Singapore, 1965.
[32] M.Burgess. ATreatiseonSystems: Volume1: Analyticaldescriptionofhuman-information
networks. in progress, 2004-.
[33] R.Dunbar. Friends: Understanding the Power of our Most Important Relationships. Little,
Brown, 2022.
[34] G. Buzs´aki. Rhythms of the Brain. Oxford University Press, 2011.
[35] K. Motokawa. Energy of brain waves and energetics of the brain. The Tokyo Journal of
Experimental Medicine, 51(1,2):119–129, 1949.
[36] G. Buzs´aki and A. Draguhn. Neuronal oscillations in cortical networks. Science,
304(5679):1926–1929, 2004.
[37] M. Kings, J.J. Arbon, and G.E. McIvor et al. Wild jackdaws can selectively adjust their
socialassociationswhilepreservingvaluablelong-termrelationships. Nature, 14:5103, 2023.
[38] R. Dunbar. How Religion Evolved and Why It Endures. Oxford University Press, 2022.
[39] M. Burgess. Authority (i): A promise theoretic formalization. SSRN:
https://ssrn.com/abstract=3855352, http://dx.doi.org/10.2139/ssrn.3855352, 2021.
[40] E. Ostrom. Governing the Commons. Cambridge, 1990.
15