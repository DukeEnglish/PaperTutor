Group Related Phenomena in Wikipedia Edits
M. Burgess
ChiTek-i AS,
Oslo, Norway
and
R.I.M. Dunbar
Department of Experimental Psychology
University of Oxford
Radcliffe Quarter
Oxford OX2 6GG
UK
February 2, 2024
Abstract
Humancommunitieshaveself-organizingpropertiesthatgiverisetoveryspecificnatural
grouping patterns, reflected in the Dunbar Number and its layered structure (a Dunbar
Graph). Since work-groups are necessarily also social groups, we might expect the same
principles to apply here as well. One factor likely to be important in limiting the size of
groups is that conflicts typically escalate with the number of people involved. Here we
analyse Wikipedia editing histories across a wide range of topics to show that there is an
emergent coherence in the size of groups formed transiently to edit the content of subject
texts, with two peaks averaging at around N = 8 for the size corresponding to maximal
contention, and at around N = 4 as a regular team. These values are consistent with the
observed sizes of conversational groups, as well as the hierarchical structuring of Dunbar
graphs. We use the Promise Theory of trust to suggest a scaling law that may apply to all
group distributions based on seeded attraction. In addition to providing further evidence
that even natural communities of strangers are self-organising, the results have important
implicationsforthegovernanceoftheWikipediacommonsandforthesecurityofallonline
social platforms and associations.
1 Introduction
Human social groups have a natural hierarchical structure whose layers have very specific values
[1]. Theselayersrepresentaharmonicseriesofoptimawhereinformationflowroundthenetwork
is optimised [2,3]. The layers are an emergent property of the frequency with which individuals
contacteachother[4,5]andthewaythiscreatesasenseoftrustthroughincreasingfamiliarity,the
evaluationofcuesofcommunitymembership(otherwiseknownastheSevenPillarsofFriendship
[6]) and the exchange of tokens [7,8]. The base number to this series is a grouping of 5, which
corresponds closely to the upper limit of 4 on the number of individuals that can take part in a
1
4202
beF
1
]IS.sc[
1v59500.2042:viXracoherent conversation [9–13]. The limit on conversational group size appears to be set directly
by the capacity to manage the mental states, or viewpoints, of other individuals [11].
Wikipediaprovidesuswithanunusualopportunityforadirecttestoftheseclaims,sincethe
editing of its pages is, essentially, an online collaboration between large numbers of individuals.
Wikipedia provides a particularly suitable context for such a test because it is one of the few
onlineplatforms thatopenlyshares thehistories ofediting interactions onitspages. About20%
of these are editorial: performing administrative functions like labelling, fixing citations and
correcting spelling, etc.. Since editors are usually strangers, this allows us to test whether the
self-organising principles that structure genuine social groups such as personal social networks
also apply to groups of strangers and, by implication, to work-groups.
Wikipedia has a wealth of pages bearing content on a large number of topics, which means
that it samples contributions from a wide variety of individuals with different motivations. We
can assume that this diversity of topics says something about the high level of entropy of the
writing pool, which in turn allows us to study the universal aspects of group phenomena, i.e.
thosethatdependlittleoncontextoridentity. Byselectingtopicpagesandtheireditinghistories
at random we are able to examine basic statistical characteristics across the large reservoir of
intentional behaviours exhibited by online users.
The data show an emergent coherence in the sizes of transient groups formed to edit the
content of Wikipedia pages, averaging at around N = 8 and peaking in frequency at around
N =4, with a long tail. We obtain a simple formula for the probability distribution of transient
group sizes observed during editing and propose an explanation based on the Promise theory of
trust [8].
2 Methods
Analysis of timelines is somewhat time consuming, so sampling was performed in batches. After
someinitialteststodeterminethescaleforstatisticalstability,thenumberofsampleswaslimited
to around 800 topics involving around 200,000 separate online contributor identities. The data
werethencheckedforstabilitybyrecombiningthepagesintodifferentsubsetstotestforstability
under sampling. The results, while still noisy, exhibit a robust statistical stability for samples
overahundredtopics. Ourfinalresultsarebasedonthefullmergedsetofdataforcompleteness.
• We use the high level of entropy of the pages and contributors to paramaterize a Monte
Carloapproach,samplingrandomgroupsofpagesandaveragingtheresults. Sinceanalyz-
ing the pages is time consuming, even for a computer, we base our results on the mutual
consistency of results from independent random samples, to show invariance under sam-
pling; then we derive the final results from the maximal set of 827 topics and over 260,000
users for maximum significance.
• Users come to edit a topic that they care about more or less ad hoc. Once one author has
arrived, others will notice the changes and join in. These begin to form a group to either
challenge or improve on one another’s contributions, depending on the alignment of their
intentions.
• Editingtakesplaceinburstsofactivity,punctuatedbylongergaps. Wecanthusidentifya
seriesof“episodes”foreverypage,whichwetaketobecausallyindependent. Eachepisode
yields a group size and duration and a level of contention that one sees from the signals
embedded in the historical record.
2• For every topic page there is also a history page which we can read and analyze using
appropriatesoftware. Thepagesshowevidenceofuseridentities,whichmightbetransient
andevendeliberatelyanonymousbutwhichareassignedregularidentifiersbytheplatform.
We can see which edits were contested by others and the sizes, dates, and times of the
edits. This allows us to construct a process timeline and to identify contention between
individuals. Users can argue and even undo one another’s changes, and these events can
be counted.
• There is little evidence of coordination between the contributors across episodes. Coordi-
nation is essentially a stigmergic process via the medium of the editing produced. In part,
it is also a confrontational process, as we see from the history and discussion pages.
• Contention between users can be identified when one user undoes the contributions of
another, rather than adding to them. From even a cursory inspection of results, it’s clear
that contention between users is a significant issue in editing on all pages, so special focus
was attached to the level of overlap between edits and on cases where one user undid the
changes made by another.
• We also note that, in excess of 20% of all edits were made by automated “bots”, some of
which are designed to patrol changes for such activity (as well as trivial issues like spelling
corrections), so the intentional aspects of behaviour are to some degree invoked by proxy.
It’s trivial to collect basic quantitative measures like the length of text and the number of
different user identities from the platform. More interesting are the features which distinguish
selective engagement from users merely bumping into one another. One expects the subject
matter,language,andsemanticcontenttoplayastrongrolehereinattractinguserstoaspecific
page. We can show that—over the total sample—subject matter acts mainly as a seed for
attracting a particular sample of users. However, this selection eventually gets eliminated as a
variable, contributing mainly to noise, as the pool of editors is sufficiently statistically similar to
see no particular correlation with behaviour and subject matter. There is as much contention
for topics on cabbages or mathematics as for those on politics and celebrity. This is presumably
because the reasons for contention and criticism are somewhat similar across all subject areas,
just as typical errors of production are common to all forms of manufacturing.
Thetechniquefortransmutingsemanticsintocountableresultshasbeendescribedpreviously
in [14,15]. Briefly, the method selects fragments of language somewhat analogously to a bioin-
formatic analysis, by fragmenting symbols into n-grams. The relative frequency spectrum of
n-grams allows one to identify significant content independently of language. The approach has
been tested on European and Chinese texts with similar results, but the final sample of pages
was limited to mainly English language pages.
3 Natural groupings in Wikipedia editorial clusters
Figure 1 shows how the number of users involved per editing episode varies with the current
snapshot length of the main article. The article length may be taken as a proxy for the total
time invested by all editors of the page’s history. We see that rate of user comings and goings
decaysalmostimperceptiblywithlength, suggestingaslowstabilizationoftopics. However, this
issmallcomparedtothelevelofactivitymaintainedovertime. Inessence, weseelittleevidence
of pages ever being finished.
All pages appear to be subject to continuous contentious editing. The rate of stabilization
with length (time) is extremely slow, as can be seen using the length of the article as a proxy
31
4.5
"trust.dat" using 2:4
4
3.5
3
2.5
2
1.5
1
0.5
0
6 7 8 9 10 11 12 13
log L
Figure 1: Relationship between the average number of users contributing per episode as a function of
articlelength. ⟨N⟩(L)isalsonoisilyconstantordecaysinaweaklyexponentialmanner,suggestingthat
thereisamoreorlessconstantstreamofnewbattlestobefoughtorissuestobesolved. The(natural)
logplotsshowaweaktendencytoexponentialbehaviour,asexpectedfromaprobabilisticarrivalprocess.
However, the restricted number for N evident in all the graphs makes this almost insignificant.
to total time elapsed since creation. The bursty nature evident in the data suggests that causal
behaviour is limited to individual episodes, so we treat each episodic burst as a separate event.
In terms of longitudinal changes over time, notice that the editing of a document proceeds
in episodic bursts of somewhat similar duration. These were measured by computing average
durations and identifying the punctuated bursts by the gaps between them. The lifetime over
whichagroupeditsiscloselyboundedinduration,althoughtheboundsareverynoisy. Figure2
showstheexistenceofatleasttwodistinctclassesofepisodedurationevidentinwidelyseparated
clusters. This not an artefact of the analysis: the same feature recurs in different sample sets,
although most of the activity is in the lower band. In effect, the size of an active editorial group
remainssurprisinglyconstantdespiteconsiderableturnoverinmembershipovertime. Itremains
to be studied whether there is significant turnover in the groups with very long durations. This
would tend to make sense, given that the size of the group remains statistically constant over
even exponentially longer interactions.
From the episodic nature of edits, we infer that users are attracted to an editing episode
by the initiation of changes made by a user seed. The number of users in a typical episodic
event is noticeably clustered. We see this in a few measures, the most interesting of which is
the plot of contentious changes versus size of users in an episodic cluster. An average group size
associated with contention is around N = 8 (with a variation between 7.75-8.2, depending on
howwecalculateandsampletheaverage). Wetakethistobethegroupsizeatwhichcontention
reaches its maximum limit. Note, however, that upwards of 20% of all users on the platform
were approved bots working by proxy on behalf of both the platform and others. If we exclude
botactivity, thereisasmallreductioninaveragegroupsizethatbringsthedatafitclosertothe
numbers widely discussed in the literature.
Wherever users come together, they disagree. We can see signals of disagreement from both
4
N
golthe text semantics and the magnitude of the changes editors made. The most obvious signals,
however, are those where users undo one another’s changes. If we count such events, without
measuringtheirintensity,wefindafairlyconstantrateofcontentiousedits. Thecontentionitself
is also bounded, presumably by the size of the editorial group, into a region.
Figure 3 shows an enlargement of the non-empty region of the plot of contentions per event
as a function of users per episode. This shows that, although the rate of contention varies
somewhat between topics, the size of the group and the level of contention is confined to a
relatively predictable region. This tells us both that contention is intrinsic to users and that
users form groups of predictable size.
We emphasize here that group sizes cluster predominantly within the range N = [0,15],
centred on N =8. There are no other clusters evident. This suggests that there is single causal
explanation for this cluster size.
Themoststrikingevidenceofgroupsizecoherencemaybeseeninthefrequencyplot,however.
In figure 4), crosses show actual data and the dotted line a theoretical fit. This suggests an
underlying determinism, albeit on a statistical level. The spectrum of group sizes across all
episodes is remarkably free of the noisy artefacts from specific measurements, so we expect it to
be quite robust. Error bars are no larger than the crosses. It has a classic decaying exponential
tailtypicalofentropicprocesses. Moresignificantly,italsohasanon-exponentialgrowthfeature
for small N, which is where we expect the interesting dynamics to be.
Sinceweknowthatusersjoinepisodicgroupscoincidentallybyrandomlysearchingandonly
later following, the story suggested by this spectrum is that users accrete into groups gradually,
based on topic and activity, but on reaching a certain critical size they fizzle out. Initially the
probability of adding new users to a group begins to falter around a maximum of N = 4. By
thestageatwhichcontentionismaximal(N =8),theprobabilityofnewattachmentsisalready
significantlyreduced. Sinceweknow(fromthetimelinedata)thatthegroupepisodesterminate,
weconcludethattheentiregroupdisbands. Thus,thegroupsthemselvesdecayovertheirproper
time durations, probably as a result of general entropic diffusion. Such exponential decay is a
typical statistical feature of high entropy mixing.
4 A model of group formation
Wenowexplaintheresultsintermsofamodelthatcombinestherolesofuserintentandthework
effort involved in coming together. To do this, we measure the amount of semantic “novelty”
or “attention provoking content” in both the Wikipedia article texts and the supporting editing
histories. We define the amount of work done by users according to the length of their text
changes in alphabetic characters (for glyphs we can also count the numbers of strokes), since
short or easily written words are generally more common.
Theamountofworkislinkedtotheamountofattentionofferedbyeachagent,andthisplays
akeyroleinexplainingtheresults(seebelow). Thepresenceofcontentionwithactivitysuggests
that activity is stimulated by what we might call mistrust of the changes made by others. We
can assume that few if any of the agents know one another. There is little evidence of explicitly
cooperative behaviour.
Inadditiontothearticletext,whichisthereasonforuserstocometogether,wecangofurther
with the logs of change histories to see whether contributors altered each other’s contributions
deliberately in short succession. Over time, one expects all text might be altered in major and
minorways,butwhenthisoccursinthemannerofaduelbetweentwousers,itmarksasignificant
semantic interaction. In such a case, we characterize the behaviour as “contentious”.
The arrival and departure of users thus forms a kind of ‘detailed-balance’ model for the
5statistical stability of the group spectrum, i.e. the probability of finding a group of size N. Let
us assume that the set of agents affiliated with the Wikipedia platform is large and broad in its
characteristics. This can be expressed by saying it has maximum entropy. Now, suppose that
a new Wikipedia topic page is started at random by any agent. Eventually another agent will
find the changes and be attracted by the seed of a common interest. Indeed, a high proportion
of edits is carried out by automated processes that police the platform. Coincidence doesn’t
imply complete alignment between the agents, and they may contend with one another at a
rate proportional to the number of others in the group. This leads to kinetic work activity
proportional to N −1.
Let us assume that there is a reservoir of agents whose intentions are distributed with high
entropy. Wikipedia does not advertise nor incentivize editing in any way, so the arrival of a
singleagenttoeditapageiscompletelyadhoc. UsingPromiseTheory[16], wecanassumethat
a topic is represented by a direction in the space of promise outcomes and that there will be a
subset of the agents who are aligned with their understanding of this approximate topic.
To determine the rate of attention for the agents, we follow the guidance offered by the
dimensionsofwork/energyforworkdonebyapressureorforceandtheresultantkineticresponse.
Precisedetailsneedn’tbeknowntofindtherateoftemporalevolutionasavelocitychangefrom
thekineticwork(1/2mv2). Givensomelevelofattractivepotentialforcuriousagents,therateof
kinetic attachment would be expected to flatten like the square root of work. From information
theory,maximalentropyinaconservativereservoirofagentsgeneratesaBoltzmanndistribution
exp(−βE), where E is a work-energy parameter. We don’t actually require the number of
possibleagentstobeconserved,asthenumberisassumedtobeessentiallyinfinite. Aparameter
β represents the agents’ average intolerance for contention ‘back pressure’. Choosing the only
dimensionless combination of parameters ν ∼ β(N −1)/⟨N⟩ , where N −1 is the group size
T
exerting pressure on a newcomer and ⟨N⟩ is contention maximum groups scale, we obtain a
T
probability of
√
Pr(N)=Pr(attachment)ANDPr(dissipation)∼ ν×exp(−βν). (1)
From this, we can derive an expression for the probability of finding a group of size N:
4 ν1 2 e−ν 2β(N −1)
ψ(ν)= √ , ν = , (N >1). (2)
π ⟨N⟩ ⟨N⟩
T T
The broad narrative implied by this result is that new pages are random events (‘event one’ of
an episode). These events form a seed that attracts the attentions of others. In a group of total
size N, N −1 will be stimulated by the seeding to follow the rising square root rate of kinetic
attention. This corresponds to ‘grooming’ work in the language of [17]. As the back-pressure
arising from inevitable contention in the group rises, innate limitations on agents’ capacity for
this work drives them away. The entropy of the total mixture ensures this is exponential on a
large scale.
We need to be careful in interpreting statistical distribution laws as causative, because a
statistical law does not necessarily have reverse causal implications for individual instances. A
toleranceforgroupsizederivedstatisticallymayonlybeaweakindicatorofindividualbehaviour.
However, there is something intriguing about this result on a number of levels. There is an
‘invisiblehand’styleshapingofoutcomeswhichisnotquiteaforce,butwhichcouldbemodelled
as one in an effective theory. Indeed, theory suggests that there is a relationship between these
outcomes and innate properties.
The distribution relates the tendency for contention in a group to a tendency for neighbours
totolerateoneanother’spresence. Initially,thisworkseemstobetheveryessenceoftheprocess
6of discussing and contending over subject matter editing changes. Later, this progress seems to
be overpowered by the tendency for the costs of contention to overcome the perceived benefit.
This interpretation makes sense because the contention maximum always lies at larger size than
the most common maximum size. In other words, contention is still growing when the group
starts to falter.
5 Universality of the distribution
Before moving on, it is tantalizing to speculate on the wider behaviour of the curve in figure
4. Implicit in this functional form is a kind of stepping stone hierarchy of scales, determined
in detail by the contention cost β. Although we here only have data for ⟨N⟩ = 8, but we
T
can nonetheless compare the consequences of the model for other values with data from other
sources. If we examine the relationship between the maximum of contention and the maximum
equilibrium group size, we see an interesting hierarchy of sizes, reminiscent of the Dunbar hier-
archy (5,15,...150,500, etc.). The precise values depend on the choice of β, whose value lies close
to 1 for this work, but tolerates minor adjustment to smaller values. The value that generates
the usual Dunbar hierarchy of sizes lies between 0.875 and 0.95.
Implicit in the statistical law (2) is a prediction that there is a fission rate for groups with
contentiousinteractionsofapproximately2β forN ≫2β (forsmallerN theintegralnatureofN
precludes a precise analytical expression). The values in this study are consistent with the work
onconversationssummarizedin[18]. TheseshowconversationalgroupsofaroundN =8rapidly
partitioningintotwoseparatesemi-independentsubgroups. Theemergenceofacontentionlimit
orpeaklevelplaystheroleofan‘innate’characteristicforthebulkoftheagents. Weshouldnot
forget that 20% or more of agents are in fact software bots, with potentially infinite tolerance,
whose behaviour is largely triggered by human activity. The role of attractors is a key feature,
represented by the factors (N −1) in the spectrum.
In the case of the β = 0.875, we have a series close to 5,15,...150, etc. A group that could
loosely contend at n=550 would tend to break up into fragments of 150, and a group of around
15 might break up into smaller groups of order 5 under pressure, and so forth. This suggests
an interesting kinetic link between the dominant group scales. Again, we emphasize that these
are statistical tendencies not causal rules at the network level. The network causality implicit
in the formula is one based on the kinetic work done by the process supported by the local
network. The precise numbers are inevitably subject to a degree of statistical uncertainty, but
theessenceofthestoryiscompatiblewiththescalinghierarchyofDunbarnumbersknownfrom
wider sources. Removing all bot interactions from the data alters average N slightly to give an
effective value of β =0.93, which is closer to this idealized series.
The square root growth is a consequence of the work/energy invested in attending to the
ongoing process. The cognitive cost of increased familiarity is an increased processing time
cost [19]. In physics, energy is the complementary variable (and thus generator) of temporal
evolution in a system. This relationship is essentially information theoretic on a statistical level.
In this respect, information is a cybernetic concept in the sense that it can involve the exchange
ofactualinformationaboutsomeaspectoftheworldorsometokensuchasgroomingthatdefines
the quality of a relationship (see also West et al. [2,3]). The link between intentions, promises,
andtrustpointstothisintentionalityastheseedattractorintheexplanationofprocessnetwork
dynamics[20]. Theattractive‘force’duringgrowthisnotanetworkeffectbutakineticattention
effect over these networked bonds. Attraction does not therefore necessarily imply proximity in
physical spacetime, but rather in intention space (i.e. the alignment is in intention first and in
position only as a secondary consequence of attention [20]).
76 Discussion
The signature of an apparently universal group dynamics is evident within the data mined
from Wikipedia. We did not set out to look for it, yet it seems to dominate the behaviour
of contributors and offers a fortuitous opportunity to measure details normally not available
to onlookers. We emphasise that the data we analyse here only provides evidence for a single
grouping phenomenon with characteristic scales n ≃ 4 and ⟨N⟩ ≃ 8. Nonetheless, the
max T
present findings suggest that even online editorial cliques approximate, and are subject to, the
same rules and constraints as face-to-face conversations. Natural conversations have an upper
limit at four members [9–13], with this limit seemingly set by the mentalising capacities of the
average adult [11]. This suggests that the remote editing of documents works best if the editors
understand each other’s perspectives and likely intentional mindstates.
Thequestionweareleftwithiswhatistheseedingforceor”invisiblehand”shapingattraction
andrepulsioninthegroupprocesses. Isitthecharismaticleader,thethreatofpredation(animal
or human), the need for cooperation, etc. The formula derived from Promise Theory suggests
there will be one, eventually represented by the proxy of the group itself. For Wikipedia, it is
clearly the suspicion that someone is changing a subject others care enough about to defend. In
this sense, the process of ‘grooming’ or maintaining the relationship is with the subject matter
ratherthantheothersinthegroupdirectly, anditisclearlyakineticone: theactivityisthatof
a standalone agent, which is therefore limited by the characteristics of the agent, some of which
are innate and others a function of state.
One of the motivations for studying user behaviour in informatics is to understand the se-
curity of online platforms such as Wikipedia. Such platforms are increasingly prevalent features
of our lives. In Informatics, trust is usually handwaved away with very simple questions about
identityreliability(trustworthiness),leadingtomisleadingcallsfor‘zerotrust’behaviour. Trust-
worthiness is a trait that an agent or individual may have in some quantity (usually varying
probabilistically between 0 and 1) that characterises you as an individual [21]. Trustworthiness
(usually recognised by cues of various kinds) can act as a ‘first pass’ basis for action, but it is
at best a broad-brush cue based on generalities. Trust, on the other hand is not a trait but
a process that is built up over time through repeated interactions: I trust you because I have
interacted with you on a number of occasions and found you to be reliable (as an individual).
The challenge in using trust as a characteristic in the security of systems is that it represents
something taking shape over very large numbers of events. This may well make it useless as a
practical tool unless there are truly universal cues that transfer from one case to another.
There has been a tendency to look to ‘complexity science’ to explain phenomena that relate
to biological and social systems. We see little of that in the results here. At the scale of bulk
measurement, we find remarkable stability. This is an indication of a separation of timescales
between interior processes involved in relationship maintenance and the exterior ‘boundary con-
ditions’ of the social network. What is challenging for monitoring systems in general is that the
timescalesoverwhichsignificantchangesmayoccurmustbefasterthanthetimescaleoverwhich
statistical learning takes place. This is surely why attentiveness is so expensive and group sizes
areconstrainedinahierarchyoftradeoffs. Indeed,ifweseektocomparesingularinteractionsto
anaverageprofileofbulkbehaviour, wearefacedwithalearningchallengeifwearetoweedout
bad actors. This challenge is precisely the reason why brains evolved their phenomenal capabil-
ities in the context of ever larger social groups. Not surprisingly, it is currently under scrutiny
in connection with Machine Learning for Artificial Intelligence (AI).
Acknowledgement: MBisgratefultoGy¨orgyBusz´akifordiscussionsabouttheneuroscience.
This work was supported by the NLnet Foundation.
8References
[1] R.I.M.Dunbar. Structureandfunctioninhumanandprimatesocialnetworks: Implications
for diffusion, network stability and health. Proc. R. Soc. London, 476A:20200446, 2020.
[2] B.J. West, G.F. Massari, G. Culbreth, R. Failla, M. Bologna, R.I.M. Dunbar, and
P. Grigolini. Relating size and functionality in human social networks through complex-
ity. Proceedings of the National Academy of Sciences, 117(31):18355–18358, 2020.
[3] B.J. West, G. Culbreth, R.I.M. Dunbar, and P. Grigolini. Fractal structure of human and
primate social networks optimizes information flow, 2023.
[4] I. Tamarit, J.A. Cuesta, R.I.M. Dunbar, and A. S´anchez. Cognitive resource allocation
determines the organization of personal networks. Proceedings of the National Academy of
Sciences, 115(33):8316–8321, 2018.
[5] I. Tamarit, A. S´anchez, and J.A. Cuesta. Beyond dunbar circles: a continuous description
of social relationships and resource allocation. Scientific Reports, 12:1–11, 2022.
[6] R.I.M.Dunbar. Theanatomyoffriendship. TrendsinCognitiveSciences,22(1):32–51,2018.
[7] A.J. Sutcliffe, R.I.M. Dunbar, J. Binder, and H. Arrow. Relationships and the social brain:
integrating psychological and evolutionary perspectives. Brit. J. Psychol., 103:149–168,
2012.
[8] J.A. Bergstra and M. Burgess. Local and global trust based on the concept of promises.
Technical report, arXiv.org/abs/0912.4637 [cs.MA], 2006.
[9] R.I.M. Dunbar, A. Marriott, and N. Duncan. Human conversational behavior. Human
Nature, 8:231–246, 09 1997.
[10] G. Dezecache and R.I.M. Dunbar. Sharing the joke: The size of natural laughter groups.
Evolution and Human Behavior, 33:775–779, 11 2012.
[11] J.A. Krems, R.I.M. Dunbar, and S.L. Neuberg. Something to talk about: are conversation
sizesconstrainedbymentalmodelingabilities? Evolution and Human Behavior, 37(6):423–
428, 2016.
[12] C. Robertson, B. Tarr, M. Kempnich, and R.I.M. Dunbar. Rapid partner switching may
facilitateincreasedbroadcastgroupsizeindancecomparedwithconversationgroups. Ethol-
ogy, 123:736–747, 2017.
[13] M.DahmardehandR.I.M.Dunbar. Whatshallwetalkaboutinfarsi?: Contentofeveryday
conversations in iran. Human Nature, 28(4):423–433, 2017.
[14] M. Burgess. Testing the quantitative spacetime hypothesis using artificial narrative com-
prehension (i): Bootstrapping meaning from episodic narrative view as a feature landscape.
arXiv:2010.08126 [cs.AI], 2020.
[15] M. Burgess. Testing the quantitative spacetime hypothesis using artificial narrative com-
prehension (ii): Establishing the geometry of invariant concepts, themes, and namespaces
from narrative. arXiv:2010.08125 [cs.AI], 2020.
[16] J.A. Bergstra and M. Burgess. Promise Theory: Principles and Applications (second edi-
tion). χtAxis Press, 2014,2019.
9[17] R. Dunbar. Grooming, Gossip, and the Evolution of Language. Faber and Faber, London,
1996.
[18] R.Dunbar. Friends: Understanding the Power of our Most Important Relationships. Little,
Brown, 2022.
[19] T. D´avid-Barrett and R.I.M. Dunbar. Processing power limits social group size: compu-
tational evidence for the cognitive costs of sociality. Proceedings of the Royal Society B:
Biological Sciences, 280, 2013.
[20] M. Burgess. Notes on trust as a causal basis for social science. SSRN Archive, available at
http://dx.doi.org/10.2139/ssrn.4252501 (DOI: 10.2139/ssrn.4252501), August 2022.
[21] R.A. Barrio, T. Govezensky, R.I.M. Dunbar, G. In˜iguez, and K. Kaski. Dynamics
of deceptive interactions in social networks. Journal of The Royal Society Interface,
12(112):20150798, nov 2015.
1027
50000
"trust.dat" using 3:16
45000
40000
35000
30000
25000
20000
15000
10000
5000
0
0 10 20 30 40 50 60
N
29
12
"trust.dat" using 4:18
10
8
6
4
2
0
0 0.5 1 1.5 2 2.5 3 3.5 4 4.5
log N
Figure 2: Duration per episode versus N. This is the average fractional time spent by a single user
overanepisode. Thedurationismeasuredindays. Thegraphaxes(naturallogs)allshowclusteringin
a region, rather than a line relationship, suggesting that the tendency to continue interacting (fighting
or discussing) decays weakly and exponentially with the number of users, but is almost constant. The
number of users itself does not vary much in episodes, so the cluster is narrow.
11
resu
rep
noitarud
edosipe
lanoitcarf
resu
edosipe
rep
noitarud
gol3 zoom - Contention
120000
"trust.dat" using 3:7
100000
80000
60000
40000
20000
0
0 2 4 6 8 10 12 14
N
Figure3: AzoomedviewofthecontentionI(N)andmistrust,bothpeakaroundapproximatelyN =8.
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0 5 10 15 20 25 30 35 40
n
Figure 4: The normalized frequency spectrum of group sizes indicates the probability of finding an
episodicgroupofsizeN. WenotethatthepeaknearN =4iswellbelowthegroupsizethatmaximizes
contention at N = 8.2. The stippled line shows a theoretical fit for the curve derived from Promise
Theory and dimensional considerations (see text below). Crosses indicate estimated error uncertainty.
12
)N(I
)N(isp