DATA AUGMENTATION SCHEME FOR RAMAN SPECTRA WITH
HIGHLY CORRELATED ANNOTATIONS
APREPRINT
ChristophLange1,IsabelThiele2,LaraSantolin2,SebastianL.Riedel2,3,MaximBorisyak1,PeterNeubauer1,2,
andM.NicolasCruzBournazou1
1KIWIbiolab,TechnischeUniversitätBerlin,Ackerstr. 76,Berlin13355,Germany
2TechnischeUniversitätBerlin,InstituteofBiotechnology,ChairofBioprocessEngineering,Berlin,Germany
3BerlinerHochschulefürTechnik,DepartmentVIII–MechanicalEngineering,EventTechnologyandProcess
Engineering,LaboratoryofEnvironmentalandBioprocessEngineering,Berlin,Germany
ABSTRACT
InbiotechnologyRamanSpectroscopyisrapidlygainingpopularityasaprocessanalyticaltechnology
(PAT)thatmeasurescelldensities,substrate-andproductconcentrations. Asitrecordsvibrational
modesofmoleculesitprovidesthatinformationnon-invasivelyinasinglespectrum.Typically,partial
leastsquares(PLS)isthemodelofchoicetoinferinformationaboutvariablesofinterestfromthe
spectra. However,biologicalprocessesareknownfortheircomplexitywhereconvolutionalneural
networks(CNN)presentapowerfulalternative. Theycanhandlenon-Gaussiannoiseandaccount
forbeammisalignment,pixelmalfunctionsorthepresenceofadditionalsubstances. However,they
requirealotofdataduringmodeltraining,andtheypickupnon-lineardependenciesintheprocess
variables. Inthiswork,weexploittheadditivenatureofspectrainordertogenerateadditionaldata
pointsfromagivendatasetthathavestatisticallyindependentlabelssothatanetworktrainedonsuch
dataexhibitslowcorrelationsbetweenthemodelpredictions. WeshowthattrainingaCNNonthese
generateddatapointsimprovestheperformanceondatasetswheretheannotationsdonotbearthe
samecorrelationasthedatasetthatwasusedformodeltraining. Thisdataaugmentationtechnique
enablesustoreusespectraastrainingdatafornewcontextsthatexhibitdifferentcorrelations. The
additionaldataallowsforbuildingabetterandmorerobustmodel. Thisisofinterestinscenarios
wherelargeamountsofhistoricaldataareavailablebutarecurrentlynotusedformodeltraining. We
demonstratethecapabilitiesoftheproposedmethodusingsyntheticspectraofRalstoniaeutropha
batch cultivations to monitor substrate, biomass and polyhydroxyalkanoate (PHA) biopolymer
concentrationsduringoftheexperiments.
Keywords RamanSpectroscopy,ConvolutionalNeuralNetworkandDataAugmentation
1 Introduction
Ramanspectroscopygainedpopularityinbiotechnologyasitenablesmeasuringprocessparameteronlineinanon-
invasive manner. It tracks vibrational modes of molecules that reveal information about the cultivation all in one
spectrum. While partial least squares is the model of choice to predict concentrations from spectra, convolutional
neuralnetworksareusedmoreoften(Qietal.[2023]). CNNsareabletohandlenon-Gaussiannoiseandaccountfor
beammisalignment,pixelmalfunctionsorthepresenceofadditionalsubstances. Still,duetotheirimmensepredictive
power, CNNs require large amounts of training data. Hence, data augmentation is common training a CNN (Yun
etal.[2019]). Itpreventsthemodelfromoverfittingoncharacteristicsofsingleobservationsandpromoteslearning
underlyingpatterns. Thisadditionaldataimprovesthegeneralizationoftheneuralnetworkandhasaregularizingeffect
onthemodel.
Data obtained from a cultivation process typically has strong dependencies. For example, for a batch cultivation,
substrate is inversely related to biomass. Machine Learning models are able to learn these dependencies, which
allowsthemtoimprovebiomasspredictionsusingspectrallinesofsubstrate. Whilethisimprovementisdesirable
4202
beF
1
]GL.sc[
1v15800.2042:viXraDataAugmentationSchemeforRamanSpectrawithHighlyCorrelatedAnnotations APREPRINT
for making predictions for similar cultivations, quality quickly degrades when the model is applied to a different
process. Continuingtheexample,afed-batchcultivationwouldnothavesuchstrongdependenciesbetweenbiomass
andsubstrate,thus,applyingamodeltrainedonabatchcultivationtodatafromafed-batchcultivationwould,most
likely,resultinbiasedpredictions.
Inthispaper,weproposeamethodfor"erasing"thesedependenciesfromtrainingdata,thus,makingtheresultingmodel
suitableforamuchwiderrangeofprocesses. Weevaluateourapproachwithmultiplesyntheticdatasets,wherethe
schemeofthesynthesiswaslearnedfromrealRamanspectrarecordedduringcultivationsofRalstoniaeutropha,which
producedthebiodegradablepolyhydroxyalkanoate(PHA)copolymerpoly(hydroxybutyrate-co-hydroxyhexanoate)
[P(HB-co-HHx)],withchangingmonomercompositions,dependinge.g. onthesubstratesused(Santolinetal.[2023]).
AsAlcântaraetal.[2023]showedthisisachallengingtaskthatCNNscanprovideadditionalbenefitfor.
2 MaterialandMethods
Inthissetupm-dimensionalRamanspectraX ∈Rn×marerecordedduringfermentationexperimentsAlcântaraetal.
[2023]. TouseRamanspectroscopyasaPATtoolweusespectratopredicttheconcentrationsofprocessparameters
Y ∈Rn×k thatwillbecalledlabelsusingaCNN.
2.1 DataAugmentationScheme
Neuralnetworksarealmostexclusivelytrainedonminibatches. Thefollowingalgorithmisappliedtoeachbatch,hence
nisthebatchsize. WewanttoremovethecorrelationsfromourannotationsY ,sowejustsamplenewuncorrelated
annotationsU ∈Rn×k fromuniformdistributions,
u ∼U(0,max({Y ,1≤l≤n})) (1)
ij lj
intherangeofthecorrelatedannotationsY . NowwearelookingforcoefficientsΛ∈Rn×nthatyieldthesampled
annotations.
ΛY =U (2)
WeneedthesecoefficientsforcombiningthegivenspectraX tonewlygeneratedspectraΛX thatcorrespondtothe
uncorrelatedannotationsU. Forsolvingequation(2)weuseasingularvaluedecomposition(SVD)oftheoriginal
annotationmatrixY.
Y =UΣVT (3)
UsingarightinverseΣR ofΣweobtainthecoefficientsΛvia:
Λ=UVΣRUT (4)
Themixingprocedurechangesthemeasurementnoiseinanon-linearfashion. Assumingthatmeasurementnoiseis
homoscedasticandGaussianwithknownvarianceσ2,thevarianceofthenoiseforthei-thsyntheticsampleinthel-th
l
componentis:
   
N N N
(cid:88) (cid:88) (cid:88)
Var λ ijx jl= λ ijσ l2 = λ ijσ l2 (5)
j=1 j=1 j=1
Analogousexpressionscanbederivedfordifferentkindsofnoise. Tomatchthenoiseofthegeneratedsampleitothe
originalone,weaddartificialnoisewithvariance1−(cid:80)N
λ
.Unfortunately,thatisnotpossiblewhen(cid:80)N
λ >1.
j=1 ij j=1 ij
Inthiscase,wesimplyrejectthesample. Inthefollowingwerefertothisprocessasfiltering.
2.2 DataSynthesis
ForgeneratingsyntheticRamanspectrafromR.eutrophacultivations,wefirstuserealspectraX ∈Rn×mandoffline
measurementsY ∈Rn×k fromtwocultivationsanddecomposethemwithnon-negativematrixfactorization(NMF).
X ≈YH (6)
UsingleastsquaresyieldsthespectracomponentsH thatbelongtotherespectivesubstance,andwegeneratenew
spectraviacTH withconcentrationsc∈Rk.
Theconcentrationsareobtainedfromsyntheticcultivationsthataregeneratedwiththehelpofmechanisticmodelsfor
R.eutrophaproducingPHAbyKhannaandSrivastava[2006]. Weinferparametersθˆofthemodelbyleastsquaresfit
totheofflinemeasurementsfromourR.eutrophacultivations(figure1). Todiversifythesetofcultivationparameters
2DataAugmentationSchemeforRamanSpectrawithHighlyCorrelatedAnnotations APREPRINT
Figure1: ThefitofODEmodeltotheobservationsofonecultivation. Left: Substrates. Rightproducts. RCDW=
residualcelldryweight,HB=hydroxybutyratecontentofthecopolymer.
weperturbtheestimatedparametersθˆusingagammadistribution. Wesetα = β = 5toensureanexpectedvalue
E[w ]=1andpreservesimilarcultivationdynamicsasintheoriginalmodel.
i
θ =wTθˆ, w ∼Γ(α,β) (7)
i
Weusethesamemechanismtoperturbtheinitialconditionsy .
1
2.3 EvaluationSetup
WeusesyntheticspectraofR.eutrophabatchcultivationsthatproducethecopolymer[P(HB-co-HHx)]withvarying
monomercompositiondependingontheavailablesubstrates. CanolaoilisusedforHBandHHxsynthesis,whereas
fructose only leads to the incorporation of HB monomers into the copolymer (Santolin et al. [2023]). With such
a procedure we model realistic changes in statistical dependencies between various substances and measure the
performanceundernovelconditions.
2.3.1 Datasets
Weusethemechanisticmodeldescribedin2.2togeneratecultivationsoveraperiodof72h. Weuserealdatafromtwo
differentcultivationstoinfertheparametersofthemechanisticmodelfromtheofflinemeasurementsofcelldryweight
(CDW),residualcelldryweight(CDWwithoutPHA),fructose,urea,HBandHHxmonomercontent.
Forthetrainingandvalidationsetsweusetwodifferentcultivations. Generally,thetrainingsetandthevalidationsets
differintwoaspects. Ononehandtheunderlyingmechanisticmodelshavedifferentparametersandontheotherhand
forsomevalidationdatasetsthefractionofthetwocarbonsubstratesdiffersfromthetrainingsetratiosaccordingto
Table1whichleadstodifferentratiosofHBandHHx. Forcomparingouralgorithmagainstuncorrelateddata,weadd
thedatasetno_corr,whereallconcentrationsarerandomlysampledfromauniformdistributionwithoutanystructure
fromamechanisticmodel.
Table1: Anoverviewofthedatasetsusedforthemodelevaluation. Forthetrainingdataset,thepercentageiseither
thefirstnumberorthesecondwithinonecultivation. Thevalidationdatasetsarenamedaccordingtotheiroilcontent
and“no_corr”referstonocorrelationpresent. HB,HHx=hydroxybutyrate,hydroxyhexanoatecontentofthePHA
copolymerandall%refertowt.%.
Dataset Training val0 val2 val4 val6 val8 val10 no_corr
CanolaOil[%] 100/0 0 20 40 60 80 100 any
Fructose[%] 0/100 100 80 60 40 20 0 any
Samples 50,000 10,000 10,000 10,000 10,000 10,000 10,000 50,000
HB[%] 100/80 100 96 92 88 84 80 any
HHx[%] 0/20 0 4 8 12 16 20 any
OnecultivationandthemechanisticmodelaredepictedinFigure1. Allgeneratedcultivationscontainallfivelabels
every3hwiththecorrespondingspectra. Forthetrainingsetweuse2,000cultivationsandforthevalidationsets400
cultivationsrespectively. AscanolaoilisdifficulttomeasurewithbothRamanspectraandassays,weignorethemfor
parameterinferenceandthespectracomponents.
3DataAugmentationSchemeforRamanSpectrawithHighlyCorrelatedAnnotations APREPRINT
Figure 3: When filtering out sam-
pleswithcoefficientswhichnormis
greaterthan1,weobservethisdistri-
Figure2: Normalizedspectrageneratedfromthedecorre-
butionforbatchsize32.
lationalgorithminthetrainingsetandunchangedspectra
fromthevalidationset.
2.3.2 ModelArchitecture
Forallevaluationproceduresweusetheexactsameneuralnetworkstructure. ItisaReZeroarchitecturebyBachlechner
etal.[2021]andHeetal.[2016]withminoradaptationsforonespatialdimensionanddepthwiseseparableconvolutions
fromChollet[2017]toreducethenumberofparameters. Thenetworkconsistsof8residualblocksfollowedby3fully
connectedlayerswithdropoutof0.2tomakesurethemodelisproperlyregularized.
3 Results
3.1 CharacteristicsoftheDecorrelationAlgorithm
Comparingthespectrafromthetrainingsetobtainedbythealgorithmtotheoriginalspectrafromthevalidationsetin
figure2,weobservethatsomeofthespectralooksimilartotheonesfromthevalidationset.
Somespectra,however,lookdifferent,inparticular,asiftheywereinverted. Thisoccurswhensomeofthemixing
coefficientarenegative. Whilesuchspectraareunrealistic,theydonotharmtheoverallperformance,moreover,they
mightpotentiallyhavearegularizingeffectonthemodel.
Duetothephenomenonofnoiseamplificationaccordingtoequation(5)wefiltersamples. Lookingatfigure3we
observethatahighratioofrandomsamplesisfilteredoutforabatchsizeof32.
Weusesixdifferentvalidationdatasetsthatweregeneratedasdescribedin2.3.1. Wetrainfourmodelsindifferent
trainingsetting. Forillustrationpurposes,weincludetheidealscenario: oneofthemodelsistrainedonadatasetwitha
prioriuncorrelatedlabels(referredtoas"no’_corr"). Wetrainedtheothersoncorrelateddatafor100epochs.
AccordingtoTable2themodeltrainedontheuniformdatasetismostsuccessfulattransferringitspredictioncapabilities
to different experimental conditions. Among the models trained on the correlated experiments the decorrelation
algorithm with filtering performs best. We also highlight the consistency of the proposed method across different
validationsets. Notfilteringthespectrawithexcessivenoisecausesthemodeltoperformevenworsethanthemodel
onlytrainedoncorrelateddatadespitethedecorrelationalgorithmbeinginplace.
Table2: Theresultsoftheevaluationprocedure. Thefirstthreecolumnsdescribethetrainingsetupofthemodel. The
nextsixcolumnsdepictthemeansquarederroronthenormalizedlabelsofthevalidationsetsdescribedinTable1. The
lastcolumnshowsthemeanofallvalidationsets.
TrainingSet Decorrelate Filter val0 val2 val4 val6 val8 val10 mean
nocorrelation no no 0.27 0.18 0.11 0.1 0.05 0.09 0.13
cultivationlike no no 0.42 0.50 0.41 0.47 0.42 0.48 0.45
cultivationlike yes no 0.54 0.58 0.52 0.55 0.53 0.58 0.55
cultivationlike yes yes 0.23 0.25 0.20 0.23 0.20 0.23 0.22
4DataAugmentationSchemeforRamanSpectrawithHighlyCorrelatedAnnotations APREPRINT
4 Conclusions
WeproposeadataaugmentationprocedurethatallowstrainingrobustMachineLearningmodelsonRamanspectra. We
showthattheprocedure"erases"unwanteddependenciesintrainingdata,andremovesthecorrespondingbiasesfrom
themodels. Theprocedureensuresasimilarperformanceofthemodelsacrossawiderangeofcultivationconditions,
whichdramaticallysimplifiedfurtheranalysis.
Wedemonstratedperformanceofourapproachondatasetswithcorrelationsthatdifferfromthetrainingset. Weused
thealgorithmonRamanspectraofRalstoniaeutropha,however,thealgorithmexploitsonlytheadditivenatureof
spectraldata,and,thus,isagnostictothespectroscopymethodsorthenatureofthesubstances.
Inpracticewiththehelpofouralgorithmonecanreusedatafromoldcultivationastrainingdataforamodelthatinfers
informationfromthespectraofanewcultivationsetup. Thismakesmodelsmorerobustandreducesthenumberof
cultivationsneededfornewexperimentalsettings.
References
YapingQi,DanHu,YuchengJiang,ZhenpingWu,MingZheng,EstherXinyiChen,YongLiang,MohammadASadi,
KangZhang,andYongPChen. Recentprogressesinmachinelearningassistedramanspectroscopy. Advanced
OpticalMaterials,page2203104,2023.
SangdooYun,DongyoonHan,SeongJoonOh,SanghyukChun,JunsukChoe,andYoungjoonYoo. Cutmix: Regular-
izationstrategytotrainstrongclassifierswithlocalizablefeatures. InProceedingsoftheIEEE/CVFinternational
conferenceoncomputervision,pages6023–6032,2019.
Lara Santolin, Isabel Thiele, Peter Neubauer, and Sebastian L Riedel. Tailoring the hhx monomer content of p
(hb-co-hhx)byflexiblesubstratecompositions: scale-upfromdeep-well-platestolaboratorybioreactorcultivations.
FrontiersinBioengineeringandBiotechnology,11:1081072,2023.
JoãoMedeirosGarciaAlcântara,FrancescoIannacci,MassimoMorbidelli,andMattiaSponchioni. Softsensorbased
onramanspectroscopyforthein-linemonitoringofmetabolitesandpolymerqualityinthebiomanufacturingof
polyhydroxyalkanoates. JournalofBiotechnology,377:23–33,2023.
ShilpiKhannaandAKSrivastava. Computersimulatedfed-batchcultivationforoverproductionofphb: acomparison
ofsimultaneousandalternatefeedingofcarbonandnitrogen. Biochemicalengineeringjournal,27(3):197–203,
2006.
ThomasBachlechner,BodhisattwaPrasadMajumder,HenryMao,GaryCottrell,andJulianMcAuley. Rezeroisallyou
need: Fastconvergenceatlargedepth. InUncertaintyinArtificialIntelligence,pages1352–1361.PMLR,2021.
KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.Deepresiduallearningforimagerecognition.InProceedings
oftheIEEEconferenceoncomputervisionandpatternrecognition,pages770–778,2016.
François Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE
conferenceoncomputervisionandpatternrecognition,pages1251–1258,2017.
5