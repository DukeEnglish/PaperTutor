[
    {
        "title": "Corrective Machine Unlearning",
        "authors": "Shashwat GoelAmeya PrabhuPhilip TorrPonnurangam KumaraguruAmartya Sanyal",
        "links": "http://arxiv.org/abs/2402.14015v1",
        "entry_id": "http://arxiv.org/abs/2402.14015v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14015v1",
        "summary": "Machine Learning models increasingly face data integrity challenges due to\nthe use of large-scale training datasets drawn from the internet. We study what\nmodel developers can do if they detect that some data was manipulated or\nincorrect. Such manipulated data can cause adverse effects like vulnerability\nto backdoored samples, systematic biases, and in general, reduced accuracy on\ncertain input domains. Often, all manipulated training samples are not known,\nand only a small, representative subset of the affected data is flagged.\n  We formalize \"Corrective Machine Unlearning\" as the problem of mitigating the\nimpact of data affected by unknown manipulations on a trained model, possibly\nknowing only a subset of impacted samples. We demonstrate that the problem of\ncorrective unlearning has significantly different requirements from traditional\nprivacy-oriented unlearning. We find most existing unlearning methods,\nincluding the gold-standard retraining-from-scratch, require most of the\nmanipulated data to be identified for effective corrective unlearning. However,\none approach, SSD, achieves limited success in unlearning adverse effects with\njust a small portion of the manipulated samples, showing the tractability of\nthis setting. We hope our work spurs research towards developing better methods\nfor corrective unlearning and offers practitioners a new strategy to handle\ndata integrity challenges arising from web-scale training.",
        "updated": "2024-02-21 18:54:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14015v1"
    },
    {
        "title": "Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models",
        "authors": "Zhiwei HeBinglin ZhouHongkun HaoAiwei LiuXing WangZhaopeng TuZhuosheng ZhangRui Wang",
        "links": "http://arxiv.org/abs/2402.14007v1",
        "entry_id": "http://arxiv.org/abs/2402.14007v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14007v1",
        "summary": "Text watermarking technology aims to tag and identify content produced by\nlarge language models (LLMs) to prevent misuse. In this study, we introduce the\nconcept of ''cross-lingual consistency'' in text watermarking, which assesses\nthe ability of text watermarks to maintain their effectiveness after being\ntranslated into other languages. Preliminary empirical results from two LLMs\nand three watermarking methods reveal that current text watermarking\ntechnologies lack consistency when texts are translated into various languages.\nBased on this observation, we propose a Cross-lingual Watermark Removal Attack\n(CWRA) to bypass watermarking by first obtaining a response from an LLM in a\npivot language, which is then translated into the target language. CWRA can\neffectively remove watermarks by reducing the Area Under the Curve (AUC) from\n0.95 to 0.67 without performance loss. Furthermore, we analyze two key factors\nthat contribute to the cross-lingual consistency in text watermarking and\npropose a defense method that increases the AUC from 0.67 to 0.88 under CWRA.",
        "updated": "2024-02-21 18:48:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14007v1"
    },
    {
        "title": "The Importance of Architecture Choice in Deep Learning for Climate Applications",
        "authors": "Simon DrägerMaike Sonnewald",
        "links": "http://arxiv.org/abs/2402.13979v1",
        "entry_id": "http://arxiv.org/abs/2402.13979v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13979v1",
        "summary": "Machine Learning has become a pervasive tool in climate science applications.\nHowever, current models fail to address nonstationarity induced by\nanthropogenic alterations in greenhouse emissions and do not routinely quantify\nthe uncertainty of proposed projections. In this paper, we model the Atlantic\nMeridional Overturning Circulation (AMOC) which is of major importance to\nclimate in Europe and the US East Coast by transporting warm water to these\nregions, and has the potential for abrupt collapse. We can generate arbitrarily\nextreme climate scenarios through arbitrary time scales which we then predict\nusing neural networks. Our analysis shows that the AMOC is predictable using\nneural networks under a diverse set of climate scenarios. Further experiments\nreveal that MLPs and Deep Ensembles can learn the physics of the AMOC instead\nof imitating its progression through autocorrelation. With quantified\nuncertainty, an intriguing pattern of \"spikes\" before critical points of\ncollapse in the AMOC casts doubt on previous analyses that predicted an AMOC\ncollapse within this century. Our results show that Bayesian Neural Networks\nperform poorly compared to more dense architectures and care should be taken\nwhen applying neural networks to nonstationary scenarios such as climate\nprojections. Further, our results highlight that big NN models might have\ndifficulty in modeling global Earth System dynamics accurately and be\nsuccessfully applied in nonstationary climate scenarios due to the physics\nbeing challenging for neural networks to capture.",
        "updated": "2024-02-21 18:09:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13979v1"
    },
    {
        "title": "Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning",
        "authors": "Farhad Pourkamali-AnarakiJamal F. HusseiniScott E. Stapleton",
        "links": "http://arxiv.org/abs/2402.13945v1",
        "entry_id": "http://arxiv.org/abs/2402.13945v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13945v1",
        "summary": "This paper investigates the use of probabilistic neural networks (PNNs) to\nmodel aleatoric uncertainty, which refers to the inherent variability in the\ninput-output relationships of a system, often characterized by unequal variance\nor heteroscedasticity. Unlike traditional neural networks that produce\ndeterministic outputs, PNNs generate probability distributions for the target\nvariable, allowing the determination of both predicted means and intervals in\nregression scenarios. Contributions of this paper include the development of a\nprobabilistic distance metric to optimize PNN architecture, and the deployment\nof PNNs in controlled data sets as well as a practical material science case\ninvolving fiber-reinforced composites. The findings confirm that PNNs\neffectively model aleatoric uncertainty, proving to be more appropriate than\nthe commonly employed Gaussian process regression for this purpose.\nSpecifically, in a real-world scientific machine learning context, PNNs yield\nremarkably accurate output mean estimates with R-squared scores approaching\n0.97, and their predicted intervals exhibit a high correlation coefficient of\nnearly 0.80, closely matching observed data intervals. Hence, this research\ncontributes to the ongoing exploration of leveraging the sophisticated\nrepresentational capacity of neural networks to delineate complex input-output\nrelationships in scientific problems.",
        "updated": "2024-02-21 17:15:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13945v1"
    },
    {
        "title": "Do Efficient Transformers Really Save Computation?",
        "authors": "Kai YangJan AckermannZhenyu HeGuhao FengBohang ZhangYunzhen FengQiwei YeDi HeLiwei Wang",
        "links": "http://arxiv.org/abs/2402.13934v1",
        "entry_id": "http://arxiv.org/abs/2402.13934v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13934v1",
        "summary": "As transformer-based language models are trained on increasingly large\ndatasets and with vast numbers of parameters, finding more efficient\nalternatives to the standard Transformer has become very valuable. While many\nefficient Transformers and Transformer alternatives have been proposed, none\nprovide theoretical guarantees that they are a suitable replacement for the\nstandard Transformer. This makes it challenging to identify when to use a\nspecific model and what directions to prioritize for further investigation. In\nthis paper, we aim to understand the capabilities and limitations of efficient\nTransformers, specifically the Sparse Transformer and the Linear Transformer.\nWe focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)\nprompts and follow previous works to model them as Dynamic Programming (DP)\nproblems. Our results show that while these models are expressive enough to\nsolve general DP tasks, contrary to expectations, they require a model size\nthat scales with the problem size. Nonetheless, we identify a class of DP\nproblems for which these models can be more efficient than the standard\nTransformer. We confirm our theoretical results through experiments on\nrepresentative DP tasks, adding to the understanding of efficient Transformers'\npractical strengths and weaknesses.",
        "updated": "2024-02-21 17:00:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13934v1"
    }
]