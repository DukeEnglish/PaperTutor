[
    {
        "title": "Asymptotics of Learning with Deep Structured (Random) Features",
        "authors": "Dominik SchröderDaniil DmitrievHugo CuiBruno Loureiro",
        "links": "http://arxiv.org/abs/2402.13999v1",
        "entry_id": "http://arxiv.org/abs/2402.13999v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13999v1",
        "summary": "For a large class of feature maps we provide a tight asymptotic\ncharacterisation of the test error associated with learning the readout layer,\nin the high-dimensional limit where the input dimension, hidden layer widths,\nand number of training samples are proportionally large. This characterization\nis formulated in terms of the population covariance of the features. Our work\nis partially motivated by the problem of learning with Gaussian rainbow neural\nnetworks, namely deep non-linear fully-connected networks with random but\nstructured weights, whose row-wise covariances are further allowed to depend on\nthe weights of previous layers. For such networks we also derive a closed-form\nformula for the feature covariance in terms of the weight matrices. We further\nfind that in some cases our results can capture feature maps learned by deep,\nfinite-width neural networks trained under gradient descent.",
        "updated": "2024-02-21 18:35:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13999v1"
    },
    {
        "title": "Probabilistic Neural Networks (PNNs) for Modeling Aleatoric Uncertainty in Scientific Machine Learning",
        "authors": "Farhad Pourkamali-AnarakiJamal F. HusseiniScott E. Stapleton",
        "links": "http://arxiv.org/abs/2402.13945v1",
        "entry_id": "http://arxiv.org/abs/2402.13945v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13945v1",
        "summary": "This paper investigates the use of probabilistic neural networks (PNNs) to\nmodel aleatoric uncertainty, which refers to the inherent variability in the\ninput-output relationships of a system, often characterized by unequal variance\nor heteroscedasticity. Unlike traditional neural networks that produce\ndeterministic outputs, PNNs generate probability distributions for the target\nvariable, allowing the determination of both predicted means and intervals in\nregression scenarios. Contributions of this paper include the development of a\nprobabilistic distance metric to optimize PNN architecture, and the deployment\nof PNNs in controlled data sets as well as a practical material science case\ninvolving fiber-reinforced composites. The findings confirm that PNNs\neffectively model aleatoric uncertainty, proving to be more appropriate than\nthe commonly employed Gaussian process regression for this purpose.\nSpecifically, in a real-world scientific machine learning context, PNNs yield\nremarkably accurate output mean estimates with R-squared scores approaching\n0.97, and their predicted intervals exhibit a high correlation coefficient of\nnearly 0.80, closely matching observed data intervals. Hence, this research\ncontributes to the ongoing exploration of leveraging the sophisticated\nrepresentational capacity of neural networks to delineate complex input-output\nrelationships in scientific problems.",
        "updated": "2024-02-21 17:15:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13945v1"
    },
    {
        "title": "Do Efficient Transformers Really Save Computation?",
        "authors": "Kai YangJan AckermannZhenyu HeGuhao FengBohang ZhangYunzhen FengQiwei YeDi HeLiwei Wang",
        "links": "http://arxiv.org/abs/2402.13934v1",
        "entry_id": "http://arxiv.org/abs/2402.13934v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13934v1",
        "summary": "As transformer-based language models are trained on increasingly large\ndatasets and with vast numbers of parameters, finding more efficient\nalternatives to the standard Transformer has become very valuable. While many\nefficient Transformers and Transformer alternatives have been proposed, none\nprovide theoretical guarantees that they are a suitable replacement for the\nstandard Transformer. This makes it challenging to identify when to use a\nspecific model and what directions to prioritize for further investigation. In\nthis paper, we aim to understand the capabilities and limitations of efficient\nTransformers, specifically the Sparse Transformer and the Linear Transformer.\nWe focus on their reasoning capability as exhibited by Chain-of-Thought (CoT)\nprompts and follow previous works to model them as Dynamic Programming (DP)\nproblems. Our results show that while these models are expressive enough to\nsolve general DP tasks, contrary to expectations, they require a model size\nthat scales with the problem size. Nonetheless, we identify a class of DP\nproblems for which these models can be more efficient than the standard\nTransformer. We confirm our theoretical results through experiments on\nrepresentative DP tasks, adding to the understanding of efficient Transformers'\npractical strengths and weaknesses.",
        "updated": "2024-02-21 17:00:56 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13934v1"
    },
    {
        "title": "Dealing with unbounded gradients in stochastic saddle-point optimization",
        "authors": "Gergely NeuNneka Okolo",
        "links": "http://arxiv.org/abs/2402.13903v1",
        "entry_id": "http://arxiv.org/abs/2402.13903v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13903v1",
        "summary": "We study the performance of stochastic first-order methods for finding saddle\npoints of convex-concave functions. A notorious challenge faced by such methods\nis that the gradients can grow arbitrarily large during optimization, which may\nresult in instability and divergence. In this paper, we propose a simple and\neffective regularization technique that stabilizes the iterates and yields\nmeaningful performance guarantees even if the domain and the gradient noise\nscales linearly with the size of the iterates (and is thus potentially\nunbounded). Besides providing a set of general results, we also apply our\nalgorithm to a specific problem in reinforcement learning, where it leads to\nperformance guarantees for finding near-optimal policies in an average-reward\nMDP without prior knowledge of the bias span.",
        "updated": "2024-02-21 16:13:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13903v1"
    },
    {
        "title": "Non-asymptotic Convergence of Discrete-time Diffusion Models: New Approach and Improved Rate",
        "authors": "Yuchen LiangPeizhong JuYingbin LiangNess Shroff",
        "links": "http://arxiv.org/abs/2402.13901v1",
        "entry_id": "http://arxiv.org/abs/2402.13901v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13901v1",
        "summary": "The denoising diffusion model emerges recently as a powerful generative\ntechnique that converts noise into data. Theoretical convergence guarantee has\nbeen mainly studied for continuous-time diffusion models, and has been obtained\nfor discrete-time diffusion models only for distributions with bounded support\nin the literature. In this paper, we establish the convergence guarantee for\nsubstantially larger classes of distributions under discrete-time diffusion\nmodels and further improve the convergence rate for distributions with bounded\nsupport. In particular, we first establish the convergence rates for both\nsmooth and general (possibly non-smooth) distributions having finite second\nmoment. We then specialize our results to a number of interesting classes of\ndistributions with explicit parameter dependencies, including distributions\nwith Lipschitz scores, Gaussian mixture distributions, and distributions with\nbounded support. We further propose a novel accelerated sampler and show that\nit improves the convergence rates of the corresponding regular sampler by\norders of magnitude with respect to all system parameters. For distributions\nwith bounded support, our result improves the dimensional dependence of the\nprevious convergence rate by orders of magnitude. Our study features a novel\nanalysis technique that constructs tilting factor representation of the\nconvergence error and exploits Tweedie's formula for handling Taylor expansion\npower terms.",
        "updated": "2024-02-21 16:11:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13901v1"
    }
]