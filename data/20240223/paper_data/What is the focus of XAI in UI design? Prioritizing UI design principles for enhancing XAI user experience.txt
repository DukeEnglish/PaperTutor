What is the focus of XAI in UI design?
Prioritizing UI design principles for enhancing
XAI user experience
Dian Lei , Yao He, and Jianyou Zeng((cid:12))
China University of Geosciences, Wuhan, 430000, China
{thunder98, heyao, jianyou}@cug.edu.cn
Abstract. Withthewidespreadapplicationofartificialintelligence(AI),
the explainable AI (XAI) field has undergone a notable resurgence. In
this background, the importance of user experience in XAI has become
increasinglyprominent.Simultaneously,theuserinterface(UI)servesas
a crucial link between XAI and users. However, despite the existence
of UI design principles for XAI, there is a lack of prioritization based
on their significance. This will lead practitioners to have a vague un-
derstanding of different design principles, making it difficult to allocate
design space reasonably and emphasize design focal points. This paper
aims to prioritize four design principles, providing clear guidance for UI
design in XAI. Initially, we conducted a lightweight summary to derive
fiveuserexperiencestandardsfornon-expertusersinXAI.Subsequently,
wedevelopedfourcorrespondingwebpageprototypesforthefourdesign
principles. Nineteen participants then interacted with these prototypes,
providingratingsbasedonfiveuserexperiencestandards,andWecalcu-
latedtheweightsofthedesignprinciples.Ourfindingsindicatethat,for
non-expertusers,"sensitivity"istheoptimalUIdesignprinciple(weight
= 0.3296), followed by "flexibility" (weight = 0.3014). Finally, we en-
gage in further discussion and summarization of our research results,
and present future works and limitations.
Keywords: ExplainableAI·Explanationuserinterfaces·Userexperi-
ence · User interface design.
1 Introduction
AIhaspermeatedeveryfacetofourlivesandgraduallyintegratedintoourdaily
routines. The widespread popularity of large language models (LLMs) has fur-
ther intensified AI’s impact on our daily lives. However, the explanation of AI
output is not only a requirement for user experience but also a legal mandate
for the implementation of AI, such as the European Union’s GDPR [1]. Conse-
quently, the field of XAI has entered its third wave of research, with numerous
emergingXAItechnologies.IntheearlystagesofXAIresearch,therewasalack
of user involvement, relying primarily on the preferences of technical experts.
The opinions of the Human-Computer Interaction (HCI) community were often
4202
beF
12
]CH.sc[
1v93931.2042:viXra2 D. Lei et al.
overlooked or even rejected [2]. This has resulted in a significant focus on algo-
rithms and a disconnect from the actual usage environment of XAI. Later on,
many HCI researchers recognized the importance of a user-centric perspective
and attempted to shift the focus of XAI research from algorithms to the hu-
man [3,4,5,6].The UI design for XAI has also garnered more attention, with UI
being considered a crucial pathway for XAI output. Many researchers view UI
as the second step in the entire XAI application process, serving as the bridge
for presenting humanized outputs from specialized XAI data results. To reduce
unnecessary text, we will generalize the UI designed for XAI as XUI, defined
as "the sum of outputs of an XAI system that the user can directly interact
with." [7]
However,despitenumerousattemptstoenhanceuserexperienceinXAI,the
currentstateofaffairsstillreflectsadisconnectbetweenuserneedsandexisting
XAI systems [3,5]. Moreover, there is limited research on how humans perceive
XAI and their expectations of XAI systems [8]. Thus, improving the user expe-
rience with a human-centered approach remains a worthwhile direction in XAI.
There is existing research that has summarized XUI design principles [7], but
it has not prioritized weights to these principles. The design space for XUI is
limited, and excessive content may lead to cognitive overload and even psycho-
logicalconflicts[9].Therefore,thisvagueunderstandingofdesignprincipleswill
lead to a lack of focal points of design and an inability to reasonably allocate
design space. Lastly, evaluations of XAI often neglect user experience assess-
ments [11,10]. While some research exists on XAI user experience evaluations,
many standards are tailored for domain-specific professionals, creating a mis-
match for non-expert users. Details are further summarized in sect. 3.
To address these issues, we conducted a quantitative experiment aimed at
prioritizing the XUI design principles that enhance user experience. Initially,
we developed four webpage prototypes corresponding to four design principles.
Then,UsersratedtheseprototypesusingtheAnalyticHierarchyProcess(AHP)
to determine their weights [28], respectively. Additionally, we conducted quali-
tativeinterviewswithusersaftertheycompletedthequantitativeexperimentto
validate the conclusions and address potential shortcomings in the research.
Throughquantitativeanalysisofthedata,wefoundthatamongthefiveXAI
user experience standards, trust and understandability are the most important,
with weights of 0.2903 and 0.2398, respectively. Sensitivity and flexibility are
identified as the most critical XUI design principles, with weights of 0.3296 and
0.3014. We also obtained the weights of four XUI design principles under the
five XAI user experience standards. The contribution of this article is twofold:
1. We provided weighted priorities for design principles aimed at enhancing
XUI user experience, offering clear guidance for practitioners to allocate XUI
design space reasonably.
2.TakingaHuman-CenteredXAI(HCXAI)perspective,weofferedalightweight
summaryofuserexperiencestandardsfornon-expertusersinXAI.Thisprovides
subsequentresearcherswithareferenceframeworkforbetterunderstandingand
meeting the expectations of non-expert users in XAI.Prioritizing UI Design Principles in XAI for User Experience 3
2 Related Work
In this section, we first review the current status and shortcomings of user ex-
perience in the XAI field and then explore the research content related to XUI.
2.1 User Experience in XAI
Research on XAI has a long history, the first generation of XAI systems began
to appear in the late 1970s. However, contemporary XAI systems still face chal-
lenges from both the first and second generations, particularly in lacking user
experience [6].Inrecentyears,manyHCIresearchershaveendeavoredtoaddress
thisissue.Forexample,SpringerandWhittakerenhancedthetransparencyand
user experience of intelligent systems through progressive disclosure [12]. Fer-
reira and Monteiro, in their literature review, observed a general lack of focus
onuserexperienceinXAIresearchoutsidetheHCIcommunityandemphasized
the importance of user experience [13]. Ehsan and Riedl proposed an approach
that places humans at the center of XAI, known as HCXAI. Liao et al [4]. Liao
et al. developed an XAI question bank to meet user understanding needs [14].
However, related studies point out two major issues with the user experience in
XAI. First, as highlighted in the papers by Liao and miller [3,5], the existing
XAIsystemsstillsufferfromadisconnectwithuserrequirements,leadingtothe
"inmates running the asylum" problem. Second, evaluations of XAI primarily
focusoninterpretability(modelperformance),withuserevaluationsoftenbeing
overlooked [10,11].
2.2 UI Design for XAI
UI is crucial for XAI, serving as the bridge between users and XAI systems.
Program such as DARPA’s XAI and the study by Danilevsky et al. roughly
divide the XAI process into two stages: the generation of raw explanations by
interpretable models, followed by translation through UI into understandable
content for the general public[15,16]. Therefore, many researchers have made
efforts in UI design for XAI. For instance, Hohman et al. designed Gamut, an
interactive explainable interface targeting expert users [17]. Rjoob developed
a user interface for XAI generating Automated ECG (Electrocardiology) In-
terpretations [18]. Janet and Hani designed XAI interfaces tailored for finance
professionals[19].Hao-FeiChengandcollaboratorsdesignedvariousexplainable
interfaces, including interactive and white-box, for an AI system used in univer-
sity admissions [20]. Liao, adopting a scenario-based design approach, created a
UI design aiming for social transparency in AI systems [3]. It is noticeable that
existingXUIdesignshaverelativelylimitedfocusonnon-expertusers.Thismay
be attributed to XAI historically catering to expert users in various domains.
However,withthepopularityofLLMs,suchasChatGPT,XAIstakeholdersand
applicationscenariosarerapidgrowth[21].TheimportanceofXUIforordinary
non-expert users continues to increase.4 D. Lei et al.
3 XAI User Experience Standards for Non-Expert Users
AfteranalyzingmultipleliteratureonXAIuserexperiencestandards,thisstudy
provides a lightweight summary of the composition of user experience stan-
dards(see Table 1). We identified some shortcomings in existing XAI user ex-
perience standards. Firstly, there is currently no complete consensus on user
experience standards for XAI, andthereare too many standards related to XAI
user experience, causing difficulty in flexible application during the evaluation
process. Secondly, existing XAI user experience standards lack a clear defini-
tion of their target audience. Therefore, there are many standards that are not
applicable to non-expert users and that non-expert users do not care about in
practical use, such as Parsimony, Causality, Correct rate, etc.
Table 1. Summary of XAI user experience standards
No.Author(s) XAI user experience standards
Understandability;Satisfaction;Trust;Transparency;Expla-
01 Sajidetal.[11].
nation;Trust
Intelligibility, Comprehensibility, Interpretability; Trust;
02 Samulietal.[29]
Transparency;Controllability
03 Markusetal.[30] Understandable;Satisfaction;Explanation
04 Jasperetal.[10] Understandable;Persuasion;Correctrate;Accuracyrate
Adoption rate; Acceptance; Satisfaction; Engagement; Per-
05 JulianaJ&Mateus[13]
suasion;Continueduse
Usefulness; Naturalness; Trust; Transparency; Controllabil-
06 Suleetal.[31]
ity
Effectiveness; Understandability; Trust; Novelty; Satisfac-
07 Martijnetal.[32]
tion;Confidence
08 Markusetal.[33] Trust;Explanation;Satisfaction
Explanation; Satisfaction; Understandability; Curiosity;
09 Robertetal.[34]
Trust
Transparency; Scrutability; Trustworthiness; Effectiveness;
10 Nava[35]
Persuasiveness;Efficiency;Satisfaction
11 Tim[5] Coherence;Simplicity;Generality;Truth;Explanation
12 Aniek[36] Clarity;Parsimony;Completeness;Soundness
Satisfaction; Trust; Predictability; Understandable; Correct
13 David&David[16]
rate
Trust; Transferability; Causality; Informativeness; Account-
14 Nadia&Marco[37]
ability;Transparency
15 Shaneetal.[6] Explanation;Trust;Reliance;PredictabilityPrioritizing UI Design Principles in XAI for User Experience 5
To address these issues, this study adopts the HCXAI perspective to filter
out standards that do not meet the needs of non-expert users. In other words,
the focus is on standards that truly reflect the user experience for non-expert
users, excluding any standards irrelevant to their experience. Specifically, three
different levels are used to integrate XAI standards for non-expert user experi-
ence, resulting in five indicators that are truly applicable to non-expert users,
the details see Table 2. The specific summarized information is as follows:
3.1 Universal User Experience Level : Satisfaction
Universal user experience standards are prerequisites for any system aiming for
a good user experience, similar to constituting the "baseline" for a good user
experience.Thisstudyuses"satisfaction"toencompassuniversaluserexperience
indicators. Satisfaction can comprehensively reflect the system’s usability and
the user’s psychological pleasure, making it a metric for measuring the overall
experience of non-expert users.
3.2 Excellent Explanation Tool Level : Persuasiveness, Efficiency
ExplanationisacrucialcomponentofXAI,andtheeffectivenessofexplanations
directlyinfluencestheuserexperience.Therefore,anXAIsystemfornon-expert
users should meet the requirements of an excellent explanation tool. Some stan-
dards for excellent explanation tools overlap with unique XAI user experience
standards, which we will not repeat. In this study, we choose"persuasiveness"
and "efficiency" as the criteria for excellent explanation tools. Persuasiveness is
a key factor in the effectiveness of an XAI system, and good persuasiveness not
onlyenhancestheuserexperiencebutcanalsoinfluenceuserbehaviorforbetter
decision-making[22].Ontheotherhand,efficiencyiscrucialforuserexperience,
providinguserswithasenseoffluencyandconfidence[23].Fornon-expertusers
interacting with XAI systems, because the XAI systems they use lean towards
frequent application, a smooth user experience is highly essential.
3.3 Unique XAI User Experience Level : Understandability, Trust
XAI systems differ from ordinary products, and users have higher expectations
forattributessuchastransparency,trust,andreliability.Establishinguniqueex-
periencesforXAIuserscontributestoamorein-depthevaluationofXAIuserex-
perience.Thisstudyuses"understandability"and"trust"toreflecttheseunique
standards.UnderstandabilityhaslongbeenapersistentissueinXAI.Forexam-
ple, many XAI algorithms generate graphical results, such as LIME and SHAP,
which can be challenging for non-expert users to understand [24,25]. Addition-
ally, the degree of understanding of explanations is higher when they align with
theuser’smentalmodel[26].Therefore,understandabilitycanreflectthedegree
of matching between the XAI system and the user’s mental model. In systems
involving risks, the level of trust that users have in the system directly deter-
mines their experience [27]. Trust is one of the most important user experience6 D. Lei et al.
characteristicsforXAIaimedatordinarynon-expertusers.Existingstudiessug-
gest a high dependence between trust, transparency, and controllability [4,21].
And, Research suggests that trust in intelligent systems stems from control and
transparency[27].So,Trustasanindicatorcaneffectivelyreflectthenon-expert
user’s experience with the controllability and transparency of the XAI system.
Table 2. XAI User Experience Standards
Standard Description
This standard measures whether users gain satisfaction dur-
Satisfaction
ing use.
The standard of trust involves whether users increase their
Trust
trust in the AI system because of the explanation method.
The persuasiveness standard focuses on whether users feel
Persuasiveness
that XAI’s explanation is convincing.
Theefficiencystandardreferstowhetherusersfeelthatthey
Efficiency
have gained higher speed when understanding XAI.
The standard of understandability examines whether the
Understandability
content of XAI is easy for users to understand.
4 Method
InordertoexploretheweightofdesignprinciplesinXUI,weemployedamixed-
method approach for experimentation and data processing. Firstly, we created
four web prototypes based on four XUI design principles, and we used each of
thefourXUIdesignprinciplestoexplainthesameAImedicalconclusion,inthis
study,weassumethattheuserisdiagnosedwithcoronaryheartdiseaseandhas
corresponding symptoms and abnormal physiological indicators. Secondly, we
used the Analytic Hierarchy Process (AHP) method for quantitative analysis
of user experiences with the four web prototypes [28], obtaining specific weight
information. Finally, after the experiment, We conducted qualitative interviews
with participants to validate the conclusions drawn from our previous quantita-
tive analysis and to supplement areas that might have been overlooked during
the experimental process.Prioritizing UI Design Principles in XAI for User Experience 7
4.1 Design principles for Enhancing XUI User Experience
In the context of XUI design principles, we primarily adopted the principles
proposed by Chromik and Butz [7] in their SLR article. However, this paper
introducedsomemodificationstotheaspectofnaturalnesstoensureitsdistinc-
tivenessfromtheotherthreedesignprinciples.Forspecificdesignprinciplesand
explanations, see Table 3.
Table 3. Design principles for XUI
Design principle Description
This principle aims to enhance the logic and accuracy of ex-
planationsthroughnaturallanguage.Itachievesthisbyusing
A: Naturalness thesubstantialinformationcontentandrapidrationalization
characteristic of natural language to generate detailed and
logically sound explanations.
Theprincipleofresponsivenessaimstodynamicallyrespond
to the initial interpretation according to the user’s needs,
mainly through progressive disclosures of information to
B: Responsiveness
meet the user’s needs. This method not only helps reduce
thecognitiveloadofusersbutalsosatisfiesuserswithdiffer-
ent depths of understanding.
Theprincipleofflexibilityencouragestheuseofmultipledif-
ferentwaysofexplanationtoformatriangularandmutually
C: Flexibility
supportingexplanationmechanismandenhancethecompre-
hensiveness and credibility of explanations.
The principle of sensitivity emphasizes the continuous ad-
justment of explanation principles according to the user’s
D: Sensitivity
psychological state and usage scenarios to ensure the adapt-
ability and effectiveness of explanations.
4.2 Prototype Design
We constructed a fictitious online health assessment scenario. because, in the
contextofAIinferencesrelatedtohealthmatters,usershaveastrongerdemand
for explanations [38]. This helps capture the attention of our participants. Our
primary objective is provide an environment to experience various XUI design
principles and to gather feedback data in subsequent evaluations.
In the design practice. firstly, we used feature-based explanation style. Sec-
ondly, we designed the UI in the form of conversational agents. Finally, all our8 D. Lei et al.
explanatory content is in the form of post hoc local explanation. This is mainly
duetothefollowingreasons:1)Previousresearchindicatesthatthefeature-based
explanation style performs well in Online Symptom Checkers (OSCs), sharing
similarities with the experimental design of this study [39]. 2) The natural hu-
man demand for social explanations leads us to prefer conversational styles of
explanation,andconversationalmethodsareconsideredoneofthemostpromis-
ing approaches in intelligent system explanations [5]. And intelligent agents can
be easily embedded into various systems as tools for explanation [6]. Addition-
ally,popularLLMsprovideextensivetechnicalsupportforconversationalagents.
3) Research shows that users prefer Local Explanation in practical usage [40].
At the same time, XAI technologies for local explanations are also richer. The
specific details of XUI are as follows:
Natureness Althoughthismayseemlikeaverycommonexplanatoryapproach,
itsexplanationsarenotonlyrichininformationcontentbutalsoquiteaccurate.
Thisgivesitacertainadvantageinsystemsinvolvingrisks.Forexample,research
indicates that when users become aware of their health anomalies, they prefer
comprehensive and accurate explanations [39]. Additionally, different cultural
backgrounds and preferences may lead users to prefer textual explanations [42].
Furthermore, it also offers advantages in terms of faster generation speed and
rationalization speed [43]. See the specific design in Fig. 1.
Responsiveness WecreatedaninteractiveXUIthroughProgressiveDisclosure
to meet users’ responsiveness needs. Non-expert users dislike explanations that
requiremucheffort[44],andthisapproachcansignificantlyreducethelikelihood
ofuserinformationoverload.Byprogressivelyprovidinginformation,itbecomes
easier for users to obtain personalized depth of explanation. Specifically, we
initiallyprovideuserswithabriefnaturallanguageexplanationofwhytheyare
diagnosed with coronary heart disease. Next, users are free to choose additional
information they want to explore further, such as an introduction to coronary
heart disease or its symptoms. Finally, users can delve into how to treat the
disease. We limited the levels of Progressive Disclosure to two layers because
exceeding two layers can cause users to lose their way in the hierarchy [45]. See
the specific design in Fig. 2.
Flexibility Humansseekunderstandingthroughdiverseways[7].Similartoour
research, we frequently use triangulation to reduce errors. Diverse explanatory
approaches play a positive role when users are suspicious of the results. In the
flexible XUI design, we emphasize corroborating various forms of explanatory
materials and logical explanatory methods. In our XUI, we have set up two
different diagnostic explanations for coronary heart disease: 1) Inference logic:
a)inferringbasedonuserself-reportedsymptoms;b)inferringbasedonuserself-
reportedphysiologicalindicators.2)Multimediaexplanation:providingdetailedPrioritizing UI Design Principles in XAI for User Experience 9
Fig.1. The XUI of Natureness.
Fig.2. The XUI of Responsiveness.10 D. Lei et al.
explanationsofusers’symptomsandtheirself-describedcorrespondencethrough
videos and images12. See the specific design in Fig. 3.
Fig.3. The XUI of Flexibility.
Sensitivity This principle is primarily designed to address the diverse expla-
nationneedsofusers.Therefore,itrequiresXUItokeenlygraspchangesinuser
explanation needs and dynamically generate corresponding explanations based
on the user’s psychological model and state in real-time. To show the charac-
teristics of sensitivity, we introduce a new user context. We assume that the
user had previously suffered from coronary heart disease but has been healthy
foralongtime.However,theAIre-diagnosedthemwithcoronaryheartdisease.
XAIadjustsitsresponsesbasedonthisnewuserbackgroundtodemonstratethe
system’s adaptive adjustment to the user’s background and psychological state.
For instance, in this XUI, there are two instances: 1) When the AI recognizes
that the user has a basic understanding of medical knowledge and treatment
methods, the AI begins to attempt direct communication with the user using
medical terminology abbreviations. 2) Considering the user’s anxious mindset
1 https://www.youtube.com/watch?v=x6VrwrIonc0
2 https://www.myupchar.com/en/disease/coronary-artery-diseasePrioritizing UI Design Principles in XAI for User Experience 11
upon learning about the recurrence, the system provides emotional comfort and
suggests ways to alleviate the disease. See the specific design in Fig. 4.
Fig.4. The XUI of Sensitivity.
4.3 Participants
To finish the experiment, we recruited 19 adult participants, including both
teachers and students. The age range of the participants was 20 to 52 years
(M = 28.65, SD = 9.59), comprising 9 females and 10 males. We deliberately
selected individuals with diverse professional backgrounds to comprehensively
assess the effectiveness of the XAI system across different demographics. The
participants represented various age groups and genders to ensure the broad
applicability of the experimental results. All participants possessed an adequate
level of cultural literacy, the necessary knowledge, and the skills to comprehend
theinformationpresentedbytheXAIsystem.Moreover,allparticipantshadno
experienceinusingXAIsystems.Beforethestartoftheexperiment,weprovided
detailed explanations to the participants to ensure their understanding of the
XAIsystem’sfeatures,theexperiment’sobjectives,andthemeaningoftheAHP
scale. All participants volunteered to take part in the study, and each received
a gift of approximately $10 after completion.12 D. Lei et al.
4.4 Data Collection and Analysis
Participants provided evaluations for each principle according to the AHP scor-
ing table (see Table 4.4). Two rating tables were excluded due to the failure of
the consistency check.
Table 4. AHP assessment ratio scale and description
Scale Definition Explanation
1 As important as Meansifactorsareasimportantasjfactors
Slightly more impor- Meansifactorsareslightlymoreimportant
3
tant than j factors
Obviously more im- Meansifactorisobviouslymoreimportant
5
portant than j factor
Means i factor is more important than j
7 More important
factor
Meansifactorisextremelyimportantthan
9 Extremely important
j factor
Themedianvalueofthetwoadjacentjudg-
2, 4, 6, 8 Median
ments
Relative count back- When the j factor is compared with the i
Count backwards
wards factor, the judgment value is a = 1
ij aji
Subsequently, we proceeded with model construction. Initially, we used the
design principles of the four XUIs to form the decision layer of the AHP model.
Followingthat,weusedfiveXAIexperiencestandardstailoredforordinaryusers
to constitute the criteria layer, as depicted in Fig. 5.
The following illustrates the process of determining the weights of the 5
XAI user experience standards using the AHP method, using the example of a
participant (P1). Matrix processing mainly involves the following steps:
1. We constructed the corresponding judgment matrix A based on user rat-
ings, as shown in Formula 1 (Matrix diagram in Formula 2) :
 
1 1 3 1 1
5 3
 
5 1 4 3 3
 
 
A=1 1 1 1 1 (1)
3 4 3 3
 
1 1 3 1 1
 3 5
 
3 1 3 5 1
3Prioritizing UI Design Principles in XAI for User Experience 13
Fig.5. The AHP model
 
a a ··· a
11 12 1n
a 21 a 22 ··· a 2n
A m×n = 

. .
.
. .
.
... . .
.
  =[a ij] (2)
a a ···a
m1 m2 mn
2.We used the square root method to obtain its column vector, i.e., using
Formula 3. Then, we normalized it using Formula 4. Consequently, we obtained
specific information about the weights of the 5 XAI user experience standards
for P1, as shown in Table 5 :
(cid:118)
(cid:117) m
(cid:117)(cid:89)
ω¯ i = m(cid:116) a ij (3)
j=1
ω¯
ω = i (4)
i (cid:80)m
ω¯
j=1 j
3.Calculate the largest eigenvalue of the matrix using Formula 5, and the
calculated value is λmax = 5.4276:
n
λ
=(cid:88)(Aω)
i (5)
max nω
i
i=114 D. Lei et al.
Table 5. XAI User Experience Weight for P1
Satisfaction Trust Persuasiveness Efficiency Understandability
0.1083 0.4414 0.0623 0.1123 0.2757
4. The consistency of the matrix was examined through Formulas 6 and 7,
and the R.I. value is only related to the order of the judgment matrix, and it
is 1.12 in this case. The obtained C.R. value of 0.0955 < 0.1 confirms that it
passed the consistency test:
λ −n
C.I.= max (6)
n−1
C.I.
C.R.= (7)
R.I.
5. Repeat this process to explore users’ weights for each UI design principle
under each user experience criterion. Multiply the weights of the corresponding
design principle by the weights obtained for the respective experience criterion,
and then sum them up to obtain the total weight of the decision layer.
By repeating these steps for each participant, we obtained specific scores
for the four XUI design principles, their preferences for the 5 user experience
standards, and the scores of the 4 XUI design principles under different user
experience standards.
4.5 Interviews
To validate the rationale of our experiments, we decided to conduct interviews
with users after the conclusion of the experiments. Through this interview pro-
cess, we aim to ensure the credibility and effectiveness of the experiments, while
also gaining insights into users’ subjective experiences and feedback to better
comprehend the experimental data comprehensively. The interview questions
are as follows:
Q1: Please describe which specific XUI design principles had a significant
impactonyouruserexperienceduringtheinteractionwiththeXAIsystem,and
explain the specific ways in which it influenced your experience.
Q2: For each of the five XAI user experience criteria, please discuss which
XUI design principles achieved better results.
Q3: In your opinion, in which aspects of UI design further research or im-
provement is needed to achieve enhanced user interaction and interpretability?
5 Result
We obtained various data results through calculations. Specifically, we acquired
the weights of users for five XAI user experience standards, shown in Table 6.Prioritizing UI Design Principles in XAI for User Experience 15
Additionally, we obtained the weights for different design principles of XUI,
shown in Table 7. Furthermore, the weights of different design principles of XUI
under the five XAI user experience standards are shown in Table 8. Excluding
thedataresult,andcombiningthecontentfrominterviews,weprimarilyderived
the following results :
1. Trust is the most crucial aspect among the XAI user experience
standards, with a weight of 0.2903, followed by Understandability, the second
most important standard, with a weight of 0.2398. Responses to Q1 during the
interviews also confirmed this observation. Users often consider trust as the
foundation for a good XAI user experience. For example, P7 mentioned, "If
the system cannot provide enough trust, I find it challenging to have a positive
perception of the system. Even if other aspects are well-executed, I am likely to
maintain a skeptical outlook on other outputs." Similarly, Understandability is
frequentlymentionedbyusers,andtheyconsideritthekeytotheeffectivenessof
XAI. For instance, P2 mentioned, "Originally, I have doubts about the outputs
of AI, and I turn to XAI systems to seek answers. However, if it is still difficult
to understand, then one would have to seek XAI for XAI."
2. Sensitivity is the most important XUI design principle, with a
weight of 0.3296, but Flexibility also holds a weight of 0.3014. Sensitivity and
Flexibilityarecrucialforusers’trustandunderstandabilityattributes.Thisdata
is corroborated by responses to Q2 during the interviews. Users perceive Sensi-
tivity and Flexibility as sources of subjective and objective trust, respectively.
Users praise the user experience of Sensitivity because it increases the content
of relevant information and makes the system feel intelligent. For instance, P4
mentioned,"TheXUIdesignwithsensitivitymakesmefeelveryrelaxed.Idon’t
need to repeatedly self-report, and the information is mostly tailored to my
specific situation, reducing a lot of unnecessary information." Flexibility is well-
received because it eliminates ambiguity, P12 mentioned, "For illnesses, I have
both resistance and anxiety. Flexibility can meet my needs well and eliminate
many doubts I have about AI conclusions."
Table 6. the weights of users for five XAI user experience standard
Satisfaction Trust Persuasiveness Efficiency Understandability
0.1604 0.2903 0.1663 0.1433 0.2398
Table 7. the weights for different design principles of XUI
Design principle A Design principle B Design principle C Design principle D
0.1549 0.2140 0.3014 0.329616 D. Lei et al.
Table8.TheweightsofdesignprinciplesunderthefiveXAIuserexperiencestandards
DesignprincipleADesignprincipleBDesignprincipleCDesignprincipleD
Persuasiveness 0.0991 0.2816 0.3209 0.2984
Satisfaction 0.1528 0.1954 0.2722 0.3796
Trust 0.1073 0.1955 0.3397 0.3576
Efficiency 0.4135 0.2056 0.2763 0.1046
Understandability 0.0844 0.1603 0.3609 0.3944
6 Discussion
In this section, we will provide further insights and discussions based on the
experimental results, summarizing our experiences and offering valuable infor-
mation for XUI design. We will discuss on this in three subpoints :
1, Users demand "correct" information. Users are more concerned
about whether the information provided is "correct" (meeting their specific
needs) rather than just being comprehensive or persuasive. The weight of the
Sensitivityprinciple,whichprovidescontext-sensitiveresponses,is0.3796under
the satisfaction criterion, compared to the Flexibility principle, which provides
more detailed information with a weight of 0.2722. This trend is also observed
underthetrustcriterion.Userstendtopreferinformationthatalignswiththeir
specificneedsratherthananabundanceofinformation.Thisalignswithprevious
research findings that users dislike explanatory forms requiring more effort.
2, User experience is the core of XAI applications. Analysis of the
overall weights for the four XUI designs reveals that designs centered around
user-centric principles (such as Design principles C and D) often outperform
designs less focused on user experience (such as Design principle A, which is
more algorithm-centric). This further emphasizes the importance of HCXAI,
suggesting that XAI development should prioritize user needs. If detached from
user requirements, XAI may lose its practical value.
3, Diverse Demands. In our research, we discovered that differentiated
needs are a highly significant issue, primarily classified into two types:
Individual Differentiation: Almost every individual exhibits different prefer-
ences. XUI outputs should emphasize differentiation. For instance, Participants
P7 and P15 prefer the "Naturalness" design principle, unlike others. They be-
lieve that adding other forms is a waste of time when textual descriptions are
correct.
ScenarioDifferentiation: Thedataresultsindicatesignificantfluctuationsinthe
weights of the four principles under different XAI user experience criteria. For
example, "Naturalness" performs relatively poorly under other user experience
criteria but excels under the efficiency criterion. Therefore, flexible application
of different XUI design principles is recommended based on diverse scenarios
and requirements.Prioritizing UI Design Principles in XAI for User Experience 17
7 Limitation and Future Work
Inthefollowingsection,wewilldiscussthelimitationsofourstudyandpotential
directions for future research :
1. Lack of consideration for the combination of design principles.
The four principles discussed in this study are entirely combinable, yet our re-
search treats them as independent principles to explore their individual impor-
tance. While there are challenges related to the limited UI design space, future
research could investigate the impact of combining multiple XUI explanation
principles on users, for a more precise response to user needs.
2. Limited consideration of scalability. Due to constraints in the exper-
imentalenvironmentandcontrolledvariables,ourstudyhaslimitationsinterms
of scalability. Firstly, it only focuses on conversational AI interfaces, neglecting
exploration into other forms of AI interfaces such as XR interfaces or natural
interfaces. Secondly, the study does not account for changes over extended us-
age periods. In high-frequency usage scenarios, user demands may change, and
the weight of factors like "efficiency" could correspondingly increase. Lastly, the
study has a single-use scenario, real-life situations are more complex, with di-
verse user needs across different usage scenarios. Future research could explore
the scalability of various XUI design principles in more detail.
8 Conclusion
In this paper, we conducted a study on the weighting of XUI design princi-
ples and summarized lightweight XAI user experience standards for non-expert
users. Our contributions include providing weighted rankings for design princi-
plesaimedatenhancingtheXUIuserexperienceandofferingguidanceforprac-
titioners in allocating XUI design space reasonably. Additionally, we provided
a lightweight summary of XAI user experience standards for non-expert users
from the perspective of HCXAI, serving as a reference for future researchers.
As the widespread use of LLMs continues, the demand for XAI is expected to
grow, especially among non-expert users. Our study provides valuable insights
forspecificXUIdesignsandcontributestoimprovingtheuserexperienceofXAI
throughUIdesign.Inthefuture,wehopetheseresearchfindingswillguideXUI
design and encourage more researchers to engage in user experience studies in
the field of XAI.
9 Acknowledgments
This version of the contribution has been accepted for publication, after peer
review but is not the Version of Record and does not reflect post-acceptance
improvements,oranycorrections.UseofthisAcceptedVersionissubjecttothe
publisher’s Accepted Manuscript terms of use: https://www.springernature.
com/gp/open-research/policies/accepted-manuscript-terms.18 D. Lei et al.
References
1. P. Regulation, “Regulation (eu) 2016/679 of the european parliament and of the
council,” Regulation (eu), vol. 679, p. 2016, 2016.
2. Q.Yang,A.Scuito,J.Zimmerman,J.Forlizzi,andA.Steinfeld,“Investigatinghow
experienceduxdesignerseffectivelyworkwithmachinelearning,” inProceedingsof
the 2018 Designing Interactive Systems Conference, ser. DIS â€™18. New York,
NY, USA: Association for Computing Machinery, Jun. 2018, p. 585â€“596.
3. Q. V. Liao and K. R. Varshney, “Human-centered explainable ai (xai): From al-
gorithms to user experiences,” no. arXiv:2110.10790, Apr. 2022, arXiv:2110.10790
[cs].
4. U. Ehsan and M. O. Riedl, “Human-centered explainable ai: Towards a reflec-
tive sociotechnical approach,” in HCI International 2020 - Late Breaking Papers:
Multimodality and Intelligence, ser. è®¡ç®—æœºç§‘å¦ç³»å^—ä¹¦ç±è®²ä¹‰,
C. Stephanidis, M. Kurosu, H. Degen, and L. Reinerman-Jones, Eds. Cham:
Springer International Publishing, 2020, p. 449â€“466.
5. T. Miller, “Explanation in artificial intelligence: Insights from the social sciences,”
Artificial Intelligence, vol. 267, p. 1â€“38, Feb. 2019.
6. S. T. Mueller, R. R. Hoffman, W. Clancey, A. Emrey, and G. Klein, “Explanation
in human-ai systems: A literature meta-review, synopsis of key ideas and pub-
lications, and bibliography for explainable ai,” no. arXiv:1902.01876, Feb. 2019,
arXiv:1902.01876 [cs].
7. M.ChromikandA.Butz,“Human-xaiinteraction:Areviewanddesignprinciples
forexplanationuserinterfaces,” inHuman-ComputerInteractionâ€“ INTERACT
2021, ser. Lecture Notes in Computer Science, C. Ardito, R. Lanzilotti, A. Mal-
izia, H. Petrie, A. Piccinno, G. Desolda, and K. Inkpen, Eds. Cham: Springer
International Publishing, 2021, p. 619â€“640.
8. H. Vainio-Pekka, M. O.-O. Agbese, M. Jantunen, V. Vakkuri, T. Mikkonen,
R. Rousi, and P. Abrahamsson, “The role of explainable ai in the research field
of ai ethics,” ACM Transactions on Interactive Intelligent Systems, vol. 13, no. 4,
pp. 26:1–26:39, Dec. 2023.
9. C.-H.TsaiandP.Brusilovsky,“Evaluatingvisualexplanationsforsimilarity-based
recommendations: User perception and performance,” in Proceedings of the 27th
ACM Conference on User Modeling, Adaptation and Personalization. Larnaca
Cyprus: ACM, Jun. 2019, p. 22â€“30.
10. J. van der Waa, E. Nieuwburg, A. Cremers, and M. Neerincx, “Evaluating xai: A
comparisonofrule-basedandexample-basedexplanations,” Artificial Intelligence,
vol. 291, p. 103404, 2021.
11. S.Ali,T.Abuhmed,S.El-Sappagh,K.Muhammad,J.M.Alonso-Moral,R.Con-
falonieri,R.Guidotti,J.DelSer,N.Díaz-Rodríguez,andF.Herrera,“Explainable
artificial intelligence (xai): What we know and what is left to attain trustworthy
artificial intelligence,” Information fusion, vol. 99, p. 101805, 2023.
12. A.SpringerandS.Whittaker,“Progressivedisclosure:Designingforeffectivetrans-
parency,” no. arXiv:1811.02164, Nov. 2018, arXiv:1811.02164 [cs].
13. J. J. Ferreira and M. S. Monteiro, “What are people doing about xai user experi-
ence?asurveyonaiexplainabilityresearchandpractice,” inDesign, User Experi-
ence,andUsability.DesignforContemporaryInteractiveEnvironments. Springer,
Cham, 2020, p. 56â€“73.
14. Q.V.Liao,D.Gruen,andS.Miller,“Questioningtheai:Informingdesignpractices
forexplainableaiuserexperiences,” inProceedingsofthe2020CHIConferenceonPrioritizing UI Design Principles in XAI for User Experience 19
Human Factors in Computing Systems, ser. CHI â€™20. New York, NY, USA:
Association for Computing Machinery, Apr. 2020, p. 1â€“15.
15. M. Danilevsky, K. Qian, R. Aharonov, Y. Katsis, B. Kawas, and P. Sen, “A sur-
vey of the state of explainable ai for natural language processing,” arXiv preprint
arXiv:2010.00711, 2020.
16. D. Gunning and D. Aha, “Darpaâ€™s explainable artificial intelligence (xai) pro-
gram,” AI Magazine, vol. 40, no. 22, p. 44â€“58, Jun. 2019.
17. F.Hohman,A.Head,R.Caruana,R.DeLine,andS.M.Drucker,“Gamut:Adesign
probe to understand how data scientists understand machine learning models,” in
Proceedingsofthe2019CHIConferenceonHumanFactorsinComputingSystems.
Glasgow Scotland Uk: ACM, May 2019, p. 1â€“13.
18. K.Rjoob,R.Bond,D.Finlay,V.McGilligan,S.J.Leslie,A.Rababah,A.Iftikhar,
D.Guldenring,C.Knoery,A.McShaneetal.,“Towardsexplainableartificialintelli-
genceandexplanationuserinterfacestoopentheâ€~blackboxâ€™ofautomated
ecg interpretation,” in Advanced Visual Interfaces. Supporting Artificial Intelli-
gence and Big Data Applications: AVI 2020 Workshops, AVI-BDA and ITAVIS,
Ischia, Italy, June 9, 2020 and September 29, 2020, Revised Selected Papers.
Springer, 2021, pp. 96–108.
19. J. Adams and H. Hagras, “A type-2 fuzzy logic approach to explainable ai for
regulatory compliance, fair customer outcomes and market stability in the global
financialsector,”in2020IEEEInternationalConferenceonFuzzySystems(FUZZ-
IEEE). Glasgow, United Kingdom: IEEE, Jul. 2020, p. 1â€“8.
20. H.-F. Cheng, R. Wang, Z. Zhang, F. Oâ€™Connell, T. Gray, F. M. Harper, and
H.Zhu,“Explainingdecision-makingalgorithmsthroughui:Strategiestohelpnon-
expertstakeholders,”inProceedingsofthe2019CHIConferenceonHumanFactors
in Computing Systems. Glasgow Scotland Uk: ACM, May 2019, p. 1â€“12.
21. Q. V. Liao and J. W. Vaughan, “Ai transparency in the age of llms: A human-
centered research roadmap,” no. arXiv:2306.01941, Aug. 2023, arXiv:2306.01941
[cs].
22. M. Dragoni, I. Donadello, and C. Eccher, “Explainable ai meets persuasiveness:
Translatingreasoningresultsintobehavioralchangeadvice,” ArtificialIntelligence
in Medicine, vol. 105, p. 101840, May 2020.
23. R. Confalonieri, T. Weyde, T. R. Besold, and F. M. del Prado Martín, “Using
ontologies to enhance human understandability of global post-hoc explanations of
black-box models,” Artificial Intelligence, vol. 296, p. 103471, 2021.
24. H.Kaur,H.Nori,S.Jenkins,R.Caruana,H.Wallach,andJ.WortmanVaughan,
“Interpretinginterpretability:understandingdatascientists’useofinterpretability
tools for machine learning,” in Proceedings of the 2020 CHI conference on human
factors in computing systems, 2020, pp. 1–14.
25. W.Xu,M.J.Dainoff,L.Ge,andZ.Gao,“Transitioningtohumaninteractionwith
aisystems:Newchallengesandopportunitiesforhciprofessionalstoenablehuman-
centered ai,” International Journal of Humanâ€“Computer Interaction, vol. 39,
no. 3, p. 494â€“518, Feb. 2023.
26. Y. Xie, G. Gao, and X. â. Chen, “Outlining the design space of explain-
able intelligent systems for medical diagnosis,” no. arXiv:1902.06019, Feb. 2019,
arXiv:1902.06019 [cs].
27. B. Cahour and J.-F. Forzy, “Does projection into use improve trust and explo-
ration?anexamplewithacruisecontrolsystem,” Safety Science,vol.47,no.9,p.
1260â€“1270, Nov. 2009.
28. T. L. Saaty, What is the analytic hierarchy process? Springer, 1988.20 D. Lei et al.
29. S. Laato, M. Tiainen, A. Najmul Islam, and M. Mäntymäki, “How to explain ai
systemstoendusers:asystematicliteraturereviewandresearchagenda,” Internet
Research, vol. 32, no. 7, pp. 1–31, 2022.
30. M.Langer,D.Oster,T.Speith,H.Hermanns,L.Kästner,E.Schmidt,A.Sesing,
and K. Baum, “What do we want from explainable artificial intelligence (xai)?–a
stakeholder perspective on xai and a conceptual model guiding interdisciplinary
xai research,” Artificial Intelligence, vol. 296, p. 103473, 2021.
31. S. Anjomshoae, A. Najjar, D. Calvaresi, and K. FrÃ¤mling, “Explainable agents
androbotsâ€¯:Resultsfromasystematicliteraturereview.” InternationalFoun-
dation for Autonomous Agents and MultiAgent Systems, 2019, p. 1078â€“1088.
32. M. Millecamp, N. N. Htun, C. Conati, and K. Verbert, “To explain or not to
explain: the effects of personal characteristics when explaining music recommen-
dations,” in Proceedings of the 24th International Conference on Intelligent User
Interfaces. Marina del Ray California: ACM, Mar. 2019, p. 397â€“407.
33. S. Mohseni, N. Zarei, and E. D. Ragan, “A multidisciplinary survey and frame-
work for design and evaluation of explainable ai systems,” ACM Transactions on
Interactive Intelligent Systems, vol. 11, no. 3â€“4, pp. 24:1–24:45, Sep. 2021.
34. R. R. Hoffman, S. T. Mueller, G. Klein, and J. Litman, “Metrics for explainable
ai: Challenges and prospects,” no. arXiv:1812.04608, Feb. 2019, arXiv:1812.04608
[cs].
35. N.Tintarev,“Explanationsofrecommendations,” inProceedingsofthe2007ACM
conferenceonRecommendersystems. MinneapolisMNUSA:ACM,Oct.2007,p.
203â€“206.
36. A. F. Markus, J. A. Kors, and P. R. Rijnbeek, “The role of explainability in cre-
ating trustworthy artificial intelligence for health care: a comprehensive survey of
the terminology, design choices, and evaluation strategies,” Journal of biomedical
informatics, vol. 113, p. 103655, 2021.
37. N.BurkartandM.F.Huber,“Asurveyontheexplainabilityofsupervisedmachine
learning,” Journal of Artificial Intelligence Research, vol. 70, pp. 245–317, 2021.
38. A. Holzinger, C. Biemann, C. S. Pattichis, and D. B. Kell, “What do we need to
build explainable ai systems for the medical domain?” no. arXiv:1712.09923, Dec.
2017, arXiv:1712.09923 [cs, stat].
39. C.-H.Tsai,Y.You,X.Gui,Y.Kou,andJ.M.Carroll,“Exploringandpromoting
diagnostic transparency and explainability in online symptom checkers,” in Pro-
ceedings of the 2021 CHI Conference on Human Factors in Computing Systems.
Yokohama Japan: ACM, May 2021, p. 1â€“17.
40. M. Radensky, D. Downey, K. Lo, Z. Popovic, and D. S. Weld, “Exploring the role
of local and global explanations in recommender systems,” in CHI Conference on
HumanFactorsinComputingSystemsExtendedAbstracts. NewOrleansLAUSA:
ACM, Apr. 2022, p. 1â€“7.
41. Y. Zhou, M. T. Ribeiro, and J. Shah, “Exsum: From local explanations to model
understanding,” no. arXiv:2205.00130, Apr. 2022, arXiv:2205.00130 [cs].
42. G. Klein, L. Rasmussen, M.-H. Lin, R. R. Hoffman, and J. Case, “Influencing
preferences for different types of causal explanation of complex events,” Human
factors, vol. 56, no. 8, pp. 1380–1400, 2014.
43. U. Ehsan, P. Tambwekar, L. Chan, B. Harrison, and M. O. Riedl, “Automated
rationale generation: a technique for explainable ai and its effects on human per-
ceptions,” in Proceedings of the 24th International Conference on Intelligent User
Interfaces. Marina del Ray California: ACM, Mar. 2019, p. 263â€“274.
44. S. Gregor and I. Benbasat, “Explanations from intelligent systems: Theoretical
foundations and implications for practice,” MIS quarterly, pp. 497–530, 1999.Prioritizing UI Design Principles in XAI for User Experience 21
45. W. L. i. R.-B. U. Experience, “Progressive disclosure.”