Probabilistic Neural Networks (PNNs) for Modeling
Aleatoric Uncertainty in Scientific Machine Learning
Farhad Pourkamali-Anarakia, Jamal F. Husseinib, Scott E. Stapletonb
aMathematical and Statistical Sciences, 1201 Larimer St, Denver, 80204, CO, USA
bMechanical and Industrial Engineering, 1 University Ave, Lowell, 01854, MA, USA
Abstract
This paper investigates the use of probabilistic neural networks (PNNs) to
model aleatoric uncertainty, which refers to the inherent variability in the
input-output relationships of a system, often characterized by unequal vari-
ance or heteroscedasticity. Unlike traditional neural networks that produce
deterministic outputs, PNNs generate probability distributions for the target
variable, allowing the determination of both predicted means and intervals
in regression scenarios. Contributions of this paper include the development
of a probabilistic distance metric to optimize PNN architecture, and the
deployment of PNNs in controlled data sets as well as a practical material
science case involving fiber-reinforced composites. The findings confirm that
PNNs effectively model aleatoric uncertainty, proving to be more appropriate
than the commonly employed Gaussian process regression for this purpose.
Specifically, in a real-world scientific machine learning context, PNNs yield
remarkablyaccurateoutputmeanestimateswithR-squaredscoresapproach-
ing 0.97, and their predicted intervals exhibit a high correlation coefficient of
nearly 0.80, closely matching observed data intervals. Hence, this research
contributes to the ongoing exploration of leveraging the sophisticated rep-
resentational capacity of neural networks to delineate complex input-output
relationships in scientific problems.
Keywords: Probabilistic neural networks, Aleatoric uncertainty, Prediction
interval, Network architecture optimization
1. Introduction
Scientific data, ranging from observations and experiments to advanced
computer simulations, enable the creation of predictive models, acting as
Preprint submitted to Elsevier February 22, 2024
4202
beF
12
]LM.tats[
1v54931.2042:viXradigital twins of complex systems for the accurate prediction of behavior and
optimal design [1]. The utility of machine learning surrogate models becomes
particularly pronounced when it is challenging to derive a closed analytical
formula linking input parameters directly with the desired outputs. There-
fore, machine learning approaches have found application in diverse fields,
such as material science [2, 3, 4], structural engineering [5, 6, 7], environmen-
tal science [8, 9], and healthcare [10, 11, 12], to name a few.
In supervised machine learning, especially in regression tasks, training
data sets are composed of input-output pairs. Typically, these data sets
adhere to a deterministic model, meaning that a given input consistently
produces the same output each time. However, this deterministic perspective
ignores the inherent randomness or aleatoric uncertainty present in complex
real-world systems [13, 14, 15]. For example, in material science, properties
suchastensilestrengthandelectricalconductivityexhibitinherentvariability
duetovariableprocessingconditions,materialinconsistencies,andchangesin
environmental conditions. Even with advanced machinery, controlling every
aspect of the manufacturing process is unrealistic, contributing to variability
in these properties. Therefore, this randomness in scientific domains leads
to a scenario in which a fixed input can generate a range of outputs, posing
a challenge to the traditional deterministic approach of mapping inputs to
outputs.
Consequently, it is crucial to develop machine learning models for surro-
gate modeling that accurately reflect the inherent variability or uncertainty
of real-world systems. Nevertheless, most current machine learning methods
fallshortinprovidingreliableestimatesofaleatoricuncertainty. Forexample,
standard neural network regression models, such as multilayer perceptrons,
typically provide point predictions because they employ deterministic trans-
formations of the input data [16, 17, 18]. Additionally, from a statistical
viewpoint, the frequently employed mean squared error (MSE) loss function
is based on the restrictive assumption that the output variance is constant
and known for all inputs [19]. However, in reality, aleatoric uncertainty often
exhibits heteroscedasticity [20, 21], meaning that variability is dependent on
input. Therefore, practitioners and researchers involved in scientific machine
learning face challenges at multiple stages, ranging from the development to
the deployment of surrogate models.
To address these challenges, this paper examines the efficacy of proba-
bilistic neural networks (PNNs) to model and quantify aleatoric uncertainty
within scientific problems. PNNs, unlike standard neural networks, have
2the potential to go beyond point predictions by quantifying the inherent un-
certainty of the data. The basic idea is to transform the final or output
layer into a trainable probabilistic distribution, like a normal distribution
[22, 23]. This allows the mean and variance of this distribution to become
parametric functions of inputs, enabling continuous weight updates guided
by minimizing negative log likelihood. Consequently, PNNs adapt their pre-
dictive output distributions and uncertainty estimates, a crucial advantage
over standard deterministic models blind to heteroscedastic aleatoric uncer-
tainty. This enhanced versatility makes PNNs a powerful tool for surrogate
modeling in scientific machine learning [24, 25].
To effectively leverage PNNs for modeling aleatoric uncertainty, this pa-
per details four pivotal contributions:
1. Optimizing PNN architecture: A key aspect of PNN development is de-
termining the optimal architecture, which includes the depth (number
of hidden layers) and the width (number of units per layer). In this
paper, we introduce the use of Kullback-Leibler (KL) divergence [26]
to gauge the probabilistic distance between the actual and predicted
output distributions. The proposed approach replaces traditional de-
terministic scoring metrics, such as the R-squared, to optimize critical
hyperparametersofPNNs, offeringamorenuancedevaluationofmodel
performance.
2. Comparative analysis with other models: We conduct a comprehensive
comparison between PNNs and other machine learning models primar-
ily designed to capture model or epistemic uncertainty [14]. Our find-
ings demonstrate that popular models like Gaussian process regression
[27], although producing a normal distribution for the output variable,
fail to accurately estimate aleatoric uncertainty, even in synthetic and
controlled data settings. This underscores the significance of selecting
appropriate models to model aleatoric uncertainty.
3. Benchmarking with the Ishigami function: We apply PNNs to a well-
known benchmark in scientific machine learning and uncertainty quan-
tification: the Ishigami function [28]. This function, characterized by
its high nonlinearity and heteroscedastic noise, serves as an excellent
test case to illustrate the effectiveness of PNNs in complex scenarios.
4. Real-world Application in Material Science: We investigate a practical
scientific machine learning problem involving the development of sur-
rogate models for fiber-reinforced composite microstructure generators.
3Given the randomness in initial seeding and the amplification of vari-
ability through the ensuing discrete element simulations, it is crucial
to quantify the heteroscedastic aleatoric uncertainty for various input
conditions.
The remainder of this paper is organized as follows. In Section 2, we
dive into the foundations of deterministic neural network models, focusing
on data transformation methods and the MSE loss function, which originates
from the maximum likelihood estimation framework. Section 3 is dedicated
to explaining the core components of PNNs and the adaptation of the loss
function to incorporate heteroscedastic aleatoric uncertainty using the neg-
ative log likelihood principle. Additionally, we introduce a novel evaluation
metric tailored for neural architecture search that accounts for the proba-
bilistic nature of outputs. We evaluate the performance of PNNs using the
Ishigami function in Section 4, a standard benchmark for testing machine
learning surrogate models in complex nonlinear scenarios. Section 5 dis-
cusses the application of PNNs to a large-scale and real-world problem in
materials science, specifically the computational modeling of fiber-reinforced
composites. To conclude this paper, Section 6 offers a summary of our find-
ings, practical implications, and directions for future research, particularly in
the context of distinguishing various sources of uncertainty in neural network
regression models.
2. Overview of Deterministic Neural Networks
A key element in training machine learning models involves minimizing a
carefully chosen loss function. This minimization is essential to narrow the
gap between actual and predicted outputs. By conceptualizing training as
an estimation problem, we can employ a statistical model that links inputs
with their corresponding outputs. This approach transforms the training
process into the maximum likelihood estimation (MLE) problem. To clarify
this concept, we assume that the conditional probability of the output y ∈ R,
given the input vector x ∈ RD, adheres to a normal distribution:
(cid:0) (cid:1)
p(y|x;θ) = N f (x;θ),f (x;θ) , (1)
µ σ
where θ denotes all unknown parameters that we aim to infer during the
training process. Furthermore, f (x;θ) ∈ R and f (x;θ) ∈ R take the
µ σ +
place of the mean and variance of the normal distribution, respectively. For
4simplicity, it is common to assume that the variance is fixed. Thus, the
function f (x;θ) is replaced by a known scalar σ2, which is independent of
σ
the input vector x. As a result, we can rewrite the conditional distribution
in Eq. (1) as a deterministic function of the input plus a zero-mean fixed-
variance normal distribution, i.e., p(y|x;θ) = f (x;θ) + ε,ε ∼ N(0,σ2),
µ
thereby assuming that the aleatoric or data uncertainty is homoscedastic.
With this assumption in place, the objective of MLE is to determine
the model parameters that maximize the likelihood across all input-output
pairs in the training data set. This is typically achieved by maximizing
the logarithm of the likelihood function, or equivalently minimizing negative
log likelihood (NLL), for a given training data set in the form of D =
train
{(x ,y )}n :
i i i=1
n
(cid:88)
NLL(θ) = − logp(y |x ;θ)
i i
i=1
n
(cid:88) (cid:104)(cid:16) 1 (cid:17)1/2 (cid:16) 1 (cid:0) (cid:1)2(cid:17)(cid:105)
= − log exp − y −f (x ;θ)
2πσ2 2σ2 i µ i
i=1
n
=
n
log(2πσ2)+
1 (cid:88)(cid:0)
y −f (x
;θ)(cid:1)2
. (2)
2 2σ2 i µ i
i=1
Therefore,inthecasewherethevarianceσ2 isfixed,thefirstterm n log(2πσ2)
2
becomes a constant with respect to θ and is thus irrelevant for optimization.
As a result, if NLL in Eq. (2) is multiplied by 2σ2, it simplifies to the widely
n
used mean squared error (MSE) loss function.
In summary, this simplification process used to derive the MSE loss func-
tion results in a deterministic model in the form of x (cid:55)→ f (x;θ∗). In this
µ
representation, θ∗ signifies the parameters that minimize the NLL function
in Eq. (2). This deterministic model, particularly in the context of neural
networks, often involves a complex choice of parameterization. For example,
multilayer perceptrons (MLPs), also known as fully connected feed-forward
networks, are characterized by their layered architecture [29]. These layers
collectively form a composite function where the output of one layer serves
as the input to the next, leading to the following mapping:
input layer: x(0) = x,
(cid:0) (cid:1)
hidden layers: x(l) = g(l) W(l)x(l−1) +b(l) , l = 1,...,L,
(cid:0) (cid:1)
output layer: f (x;θ) = g(L+1) W(L+1)x(L) +b(L+1) . (3)
µ
5Therefore, thepredictionmodelf (x;θ)takesonacompositeornestedform,
µ
where θ = {W(1),...,W(L+1),b(1),...,b(L+1)} contains the weight matrix
and the bias vector for each layer. Therefore, the processing of the input
vector x in standard neural networks is deterministic, meaning that every
time the same input is provided, the network will produce the exact same
predicted output. However, this deterministic behavior limits the ability of
neural networks to naturally provide estimates of aleatoric uncertainty in
scientific applications. In Section 3, we will explain the building blocks of
probabilistic neural networks to provide uncertainty estimates.
Beyond the challenges of producing predictive uncertainties, inferring the
model parameters θ during training requires the selection of various hyper-
parameters in advance. For example, the number of hidden layers L and
the number of units or neurons in each hidden layer are pivotal hyperpa-
rameters that determine the depth and width of the network, respectively
[30]. To identify a neural network configuration that is sufficiently expressive
for the specific problem being addressed, it is often essential to experiment
with different combinations of network depth and width [31, 32]. Another
hyperparameter includes the selection of nonlinear activation functions, g(l),
such as the Rectified Linear Unit (ReLU), which sets negative values to zero,
and the Exponential Linear Unit (ELU) that allows a smoother treatment
of negative values [33]. For the purposes of this study, we adopt the ELU
activation function, which is defined as follows:
(cid:40)
z if z > 0
ELU(z) = . (4)
ez −1 if z ≤ 0
In the final part of this section, we explain the evaluation and scoring
techniques used to assess the accuracy of regression models. Typically, for a
given test set D = {(x(t),y(t))}nt , we take a set of predicted and actual
test i i i=1
outputs to compute a measure of the deviation between them. Although the
MSE loss function can be used for this purpose during the testing phase, the
R-squared score or the coefficient of determination emerges as a preferred al-
ternative in many problems. The R-squared score is defined by the following
equation [34]:
(cid:80)nt (cid:0) y(t) −yˆ(t)(cid:1)2
R2(y ,yˆ ) = 1− i=1 i i , (5)
test test (cid:80)nt (cid:0) y(t) −y¯(t)(cid:1)2
i=1 i
where yˆ(t) is the predicted value for the i-th testing sample and y(t) is the
i i
6corresponding true output, for each i ranging from 1 to n . Thus, n repre-
t t
sents the total number of testing samples and y¯(t) = 1 (cid:80)n y(t) denotes the
n i=1 i
mean of the actual outputs.
An R-squared score of 1 signifies that the model’s predictions perfectly
match the actual data, indicating excellent predictive accuracy. Conversely,
an R-squared score near 0 implies that the model’s predictions do not ade-
quately reflect the variance within the set D , essentially suggesting that
test
the model’s predictions are no better than simply guessing the mean value
y¯(t) for all predictions. Thus, the R-squared score, which can reach a max-
imum value of 1, provides a normalized measure of the regression model’s
predictive performance. However, it is important to note a significant limita-
tionoftheR-squaredscore: itisdesignedforevaluatingdeterministicmodels
and is not suitable for assessing models that make probabilistic predictions
to measure the confidence level. Therefore, in the next section, we will intro-
duce an enhanced evaluation metric designed to assess similarities between
actual and predicted probability distributions.
3. Building Blocks of Probabilistic Neural Networks (PNNs)
PNNs represent a class of artificial neural networks that integrate prob-
ability distributions within their multilayered transformations, discussed in
Eq. (3). These networks are particularly effective in capturing the intricate
relationships between inputs and outputs within a probabilistic framework,
especially in scenarios characterized by data or aleatoric uncertainty. This
section begins with developing a suitable loss function for scientific prob-
lems encompassing heteroscedastic aleatoric uncertainty, utilizing the MLE
framework without the fixed-variance assumption. Following this, we intro-
duce the concept of incorporating a probabilistic layer as the output layer
in a network. Additionally, we describe a method for evaluation purposes
that is cognizant of uncertainty, aiding in the determination of the optimal
network depth and width. We also present a controlled benchmark prob-
lem to facilitate the comparison of PNNs with Gaussian process regression
(GPR), a technique extensively employed in prior research for uncertainty
quantification.
3.1. Designing Loss Functions for Aleatoric Uncertainty Quantification
In this section, we revisit the statistical model for the output variable,
which takes the form of a conditional probability as shown in Eq. (1). The
7goal is to eliminate the restrictive assumption that the variance term, that is,
f (x;θ), must be fixed and known in advance. To this end, we compute the
σ
negative log likelihood or NLL function using both the mean and variance
functions:
n
(cid:88)
NLL(θ) = − logp(y |x ;θ)
i i
i=1
(cid:88)n (cid:104)(cid:16) 1 (cid:17)1/2 (cid:16) (cid:0) y
i
−f µ(x i;θ)(cid:1)2 (cid:17)(cid:105)
= − log exp −
2πf (x ;θ) 2f (x ;θ)
σ i σ i
i=1
1 (cid:88)n (cid:16) (cid:17) 1 (cid:88)n (cid:0) y
i
−f µ(x i;θ)(cid:1)2
= log 2πf (x ;θ) + . (6)
σ i
2 2 f (x ;θ)
σ i
i=1 i=1
The NLL function consists of two parts: the first term involves the logarithm
of the variance function f (x ;θ), which accounts for the uncertainty of the
σ i
prediction. Thesecondtermis ascaledsquareddifference between theactual
output value y and the predicted mean f (x ;θ), which penalizes deviations
i µ i
of the model’s predictions from the true outputs. The scaling factor is the
inverse of the predicted variance, emphasizing the model’s confidence in its
predictions. Tofurtherexplainthescalingfactor,notethatwhenthemodelis
certainf (x ;θ)issmall. Therefore,theinversescalingfactorbecomeslarger.
σ i
Now, the penalty for the difference between the predicted mean and the
actual value is increased. Hence, the model is confident about its prediction,
so if it makes an inaccurate prediction, it is penalized more heavily.
Minimizing the NLL function with respect to θ during the training stage
encourages the model to accurately predict the mean of the target variable
while also estimating the corresponding variance. The derivatives of the
NLL function with respect to the predicted mean f (x;θ) and the predicted
µ
variance f (x;θ) are pivotal for gradient-based optimization methods. These
σ
techniques are integral to deep learning frameworks, facilitating the step-
by-step refinement of the model parameters θ. To ensure a comprehensive
understanding, we list the derivatives of the NLL function with respect to
both the predicted mean and variance. This elucidates the mechanism of
parameter updating during model training. For the sake of simplicity and to
make the explanation more straightforward, we reduce the NLL loss function
8to a scenario involving only a single input-output pair (x,y) [35]:
∂NLL (y −f (x;θ))
µ
= − ,
∂f (x;θ) f (x;θ)
µ σ
∂NLL f (x;θ)−(y −f (x;θ))2
σ µ
= . (7)
∂f (x;θ) 2(f (x;θ))2
σ σ
Therefore, when the model’s predicted variance f (x;θ) is small, indicating
σ
high confidence, the gradients regarding both f (x;θ) and f (x;θ) lead to
µ σ
more substantial updates. This mechanism ensures that the model’s adjust-
mentsaremorepronouncedwhenitisconfidentinitspredictions, demanding
accuracy in such cases, while allowing for more cautious updates when the
model acknowledges greater uncertainty.
3.2. Trainable Distributions in Probabilistic Layers
Incorporating a probabilistic layer in neural networks marks a pivotal
shift, enabling these networks to produce more than mere point predictions;
they generate distributions representing a range of possible outcomes. This
innovative layer is adeptly engineered to yield two critical outputs for each
input vector x: the mean, denoted as f (x;θ), and the variance, represented
µ
by f (x;θ). Consequently, PNNs exhibit a dual-headed architecture, with
σ
one “head” focused on predicting the expected value of the target variable
and the other dedicated to quantifying the uncertainty associated with this
prediction. Figure 1 visually illustrates this unique architecture of PNNs
with the dual-headed structure.
Given that the variance in a normal distribution inherently signifies the
data’s spread or variability, it must always remain positive. To enforce this
property within PNNs, the Softplus function is often employed [36, 37]. This
function effectively maps any real number z to a positive domain using the
transformation log(1+exp(z)). The exponential component guarantees that
the output remains positive, and by adding 1, the expression 1 + exp(z) is
assured to be strictly greater than 1. The subsequent logarithmic operation
then smoothly scales the output, ensuring that it is positive and continu-
ously differentiable, a crucial aspect for maintaining the mathematical and
computational integrity of the model.
Therefore, incorporating trainable distributions into the final layer of
PNNs enables the identification of model parameters, denoted as θ, which
include layer weights and biases, maximizing the likelihood of generating the
9Figure 1: The inclusion of the probabilistic output layer transforms the neural network
frommakingdeterministicpredictionstoprovidinganormaldistributioncharacterizedby
its mean f (x;θ) and variance f (x;θ). By providing a distribution of possible outcomes
µ σ
rather than a single value, PNNs enable the quantification of heteroscedastic aleatoric
uncertainty.
observed input-output data pairs. This approach diverges from traditional
methods that focus solely on minimizing the discrepancy between actual out-
puts and point predictions, such as the MSE loss function. Instead, PNNs
employ a more rigorous strategy that accounts for data uncertainty or vari-
ability by optimizing both the predicted mean f (x;θ) and variance f (x;θ)
µ σ
of the output distribution. The training process is facilitated by minimizing
the NLL loss function in Eq. (6), which is dependent on the predicted mean
andvariance. Theclosed-formexpressionsforthederivativesoftheNLLwith
respect to these two variables, provided in Eq. (7), are critical for the ap-
plication of gradient-based optimization techniques. These gradients enable
the systematic adjustment of model parameters θ through backpropagation.
In this paper, our primary focus is on the Root Mean Square Propagation
(RMSProp) optimization algorithm [38, 39]. RMSProp dynamically adjusts
the learning rates for each parameter by computing a moving average of the
squared gradients. This approach effectively mitigates the issue of updates
becoming negligible due to small gradients (vanishing updates) and overly
large due to significant gradients (exploding updates). Formally, let g :=
∇ NLL represent the gradient of the NLL loss function with respect to the
θ
model parameters. The update mechanism for the model parameters is then
10described by the following equations:
s ← γ s+(1−γ) g2,
η
θ ← θ − √ g. (8)
s+ϵ
In this context, s refers to the updated moving average of squared gradients.
The decay rate, denoted by γ, is typically chosen as 0.9. The learning rate,
represented by η, is fixed at 0.001 in this study. Additionally, ϵ is a small
constant incorporated to enhance numerical stability.
Therefore, this update mechanism can be used to find the layer weights
and biases in PNNs, which we refer to them as θ∗. Upon the completion
of the training phase, PNNs leverage these optimized parameters to predict
the mean and variance of the output distribution for new input test points,
denoted by x(t). This prediction is facilitated through two distinct func-
tion evaluations: f (x(t);θ∗) for the mean and f (x(t);θ∗) for the variance,
µ σ
providing a comprehensive statistical analysis of the network’s output.
It is important to note that the primary focus of this paper is on mod-
eling aleatoric uncertainty, a crucial but often neglected aspect in scientific
machine learning. Consequently, our discussion is limited to the integration
of probabilistic layers at the network’s final stage; see Figure 1. While it
is feasible to introduce probability distributions to the weights and biases
across all network layers, leading to what is commonly known as Bayesian
neural networks (BNNs) [40, 41], such considerations fall outside the purview
of this paper.
3.3. Optimizing the Architecture of PNNs
Neural networks derive their remarkable expressive capabilities from the
incorporation of hidden layers and units [42, 43, 44]; see the intermediate
layers in Figure 1. As such, a pivotal aspect of neural network development
involves determining the optimal depth (number of hidden layers) and width
(number of units or neurons per layer). While grid search remains a preva-
lent method for fine-tuning neural network architectures, the success of this
optimization process lies in the selection of a suitable evaluation or scoring
metric. Such metrics are essential for effectively comparing the performance
of various models, ensuring that the chosen architecture not only fits the
data well but also generalizes effectively to new, unseen data. This balance
between model complexity and performance is crucial for the development of
robust and efficient neural networks.
11As highlighted in Section 2, prevalent evaluation metrics like the R-
squared score predominantly focus on the mean prediction f (x;θ) and often
µ
overlook variance-related information. This oversight is particularly critical
in the context of neural network regression models tailored for scientific ap-
plications, where aleatoric or inherent data uncertainty plays a significant
role. To address this gap, this work introduces an evaluation metric in the
context of PNNs that takes into account the entire distribution of actual and
predicted outputs, thereby offering a more comprehensive assessment that
aligns with the complexities of scientific data.
To explain our methodology, we start by identifying unique input vec-
tors within the test data set D . It is important to remember that due to
test
aleatoric uncertainty, a single input vector can lead to a variety of output val-
ues. Consequently, for each distinct input vector in the test set, represented
as x(t), we calculate the empirical mean and variance of the associated out-
puts. This process allows us to approximate the distribution of the actual
output variables. We model this distribution as a normal distribution, de-
noted by N(femp(x(t)),femp(x(t))), where femp(x(t)) and femp(x(t)) represent
µ σ µ σ
the mean and variance of the actual outputs for the input vector x(t). Note
that these two quantities do not depend on the optimized parameters of the
trained PNN, i.e., θ∗. This approach provides a statistical basis for evaluat-
ing the predictive performance of our models, taking into account both the
central tendency and the dispersion of the predicted values.
Next, weemploytheKullback-Leibler(KL)divergence[45,46]tomeasure
the probabilistic distance between the actual and predicted output distribu-
tions. Thatis, wecomputethepredictedmeanandvariancefortheinputtest
data point according to the trained PNN, i.e., f (x(t);θ∗) and f (x(t);θ∗),
µ σ
utilizing the model parameters θ∗ obtained from training. Given the two
normal distributions, the KL divergence can be calculated analytically due
to the well-defined properties of normal distributions:
(cid:16) (cid:17)
D N(cid:0) femp(x(t)),femp(x(t))(cid:1) || N(cid:0) f (x(t);θ∗),f (x(t);θ∗)(cid:1)
KL µ σ µ σ
1 (cid:16)f (x(t);θ∗)(cid:17)
femp(x(t))+(cid:0)
femp(x(t))−f
(x(t);θ∗)(cid:1)2
1
σ σ µ µ
= log + − . (9)
2 femp(x(t)) 2f (x(t);θ∗) 2
σ σ
Note that the KL divergence is zero when the actual and predicted distri-
butions are identical, reflecting perfect agreement. The KL divergence is
always non-negative, and it increases as the two distributions diverge further
12from each other, quantifying the amount of information lost when one dis-
tribution is used to approximate the other. Thus, in the context of PNNs,
the KL divergence not only provides a more systematic and principled ap-
proach for evaluation compared to traditional deterministic methods used
for grid searching various depth and width configurations, but it also offers a
cost-effective advantage due to its closed-form solution when measuring the
distance between two normal distributions.
3.4. Controlled Environment Case Study: Dissecting Aleatoric and Epis-
temic Uncertainty
In this section, we examine a 1D synthetic data set to showcase the capa-
bility of PNNs in modeling a certain type of heteroscedastic aleatoric noise.
This case study, set in a controlled environment, allows us to explore the
effectiveness of KL divergence for choosing the best model, as outlined in
Eq. (9). We particularly emphasize the significance of two critical hyperpa-
rameters in model selection: the number of hidden layers (which determines
the model’s depth) and the number of units in each hidden layer (which de-
fines the model’s width). For simplicity, we assume a uniform width across
all hidden layers. In this study, we employ TensorFlow/Keras for neural
network training, and all experiments were performed on a MacBook Pro
equipped with an Apple M2 Max chip and 32 GB of RAM.
The initial step in this case study involves considering a cubic function
that establishes the following relationship between scalar inputs x and scalar
outputs y:
y = x3 + 0.1(2+x)ε , (10)
(cid:124) (cid:123)(cid:122) (cid:125)
heteroscedasticnoise
where x lies in the interval [−1,1] and ε is drawn from the standard nor-
mal distribution N(0,1). To construct the training data set D , we use
train
uniform sampling to select 100 points from the interval [−1,1]. For each of
these points, we generate 10 instances of the random variable ε, leading to a
heteroscedastic noise model. Consequently, the training data set comprises
a total of 1,000 input-output pairs. Adopting a similar approach for the test
data set D , we select 50 points from the same interval [−1,1] and generate
test
10 realizations of ε for each, resulting in a total of 500 test input-output pairs
and 50 distinct input conditions for testing.
Figure 2(a) reports the results of a grid search carried out on PNNs that
vary in depth and width. For this study, the batch size was maintained at
1332, and each model underwent training over 100 epochs with the discussed
RMSProp optimizer. The analysis, guided by the observed Kullback-Leibler
(KL) divergences, reveals that a single hidden layer in PNNs fails to offer suf-
ficient expressiveness, regardless of the width setting. Conversely, increasing
the network’s depth appears to bring the model’s predicted output distribu-
tion more in alignment with the true distribution. It should be noted that
a PNN configuration with 4 hidden layers and 6 units in each layer achieved
the lowest KL divergence, marking it as the top-performing model. On the
contrary, a model configured with 3 hidden layers and a width of 2 units ex-
hibited the poorest performance, recording a KL divergence of 0.447, which
is nearly triple that of the best-performing model. Therefore, this case study
underscores the critical role of model selection in PNN applications, high-
lighting that mere increases in depth or width do not guarantee improved
predictive accuracy.
Figure 2: Demonstrating the critical role of hyperparameter tuning in PNNs through the
application of the proposed KL divergence metric. This controlled case study explores 4
varying depths for the number of hidden layers, ranging from 1 to 4, alongside 4 distinct
widths,representedbythenumberofhiddenunitswithintheset{2,4,6,8}. Theoutcomes
of the grid search are showcased in (a), while (b) and (c) respectively highlight the least
effective and optimal PNN models identified through this process. Note that in (a), lower
KL divergence values are favored as they indicate a closer match between the actual and
predicted output distributions.
To further underscore the importance of selecting appropriate PNN ar-
chitectures for modeling aleatoric uncertainty, we present visual comparisons
of the worst and best predictive models in Figures 2(b) and 2(c), respec-
tively. The dotted curve in these figures depicts the mean function f , akin
µ
to that in deterministic neural networks. Additionally, we highlight predic-
tion intervals through shaded green areas, representing the lower and upper
14bounds of a 90% confidence interval for a normal distribution, determined by
the mean function f and the variance function f . While the least accurate
µ σ
PNNmanagestofollowthegeneralinput-outputrelationship,itinadequately
represents aleatoric uncertainty, particularly evident in the overly broad pre-
diction intervals for smaller values of x. In contrast, the optimized PNN in
Figure 2(c) markedly improves in quantifying aleatoric uncertainty, offering
a more precise estimate. This comparison clearly demonstrates the potential
of well-optimized PNNs to deliver accurate and reliable aleatoric uncertainty
estimations.
Next, we evaluate the performance of the best performing PNN, char-
acterized by a depth of 4 and width of 6, by graphically comparing the
predicted mean with the actual or empirical mean, alongside the predicted
intervals against the actual intervals for each test point. The empirical inter-
vals are determined by computing the range, which is the difference between
the maximum and minimum of 10 outputs for each input vector x(t) from
the test set D . A key advantage of this assessment methodology is its
test
adaptability to more complex scenarios, making it applicable to regression
problems in higher dimensional input spaces.
Figure 3(a) demonstrates that the first “head” of the optimized PNN, il-
lustrated in Figure 1, provides very accurate estimates of the actual mean for
all 50 distinct test data points. Specifically, the R-squared score reaches 0.97,
nearing the ideal score of 1, and the proximity of the scatter plot to the 45-
degreelinefurtheratteststotheefficacyoftheoptimizedPNN.Furthermore,
Figure 3(b) illustrates the comparison between the predicted and empirical
intervals, where we use both the predicted mean and variance produced by
the two “heads” of the optimized PNN. The slight upward orientation of the
data points relative to the 45-degree line suggests a conservative tendency in
the PNN, tending to predict slightly broader intervals than observed empir-
ically. However, the Pearson correlation coefficient [47] between the actual
and predicted interval vectors shows a strong positive correlation, suggest-
ing that despite the slight overestimation, these intervals are still useful in
scientific settings for representing aleatoric uncertainty. Note that the corre-
lation coefficient ranges from −1 to 1, and values that are close to 1 signify
a strong positive correlation. For instance, as depicted in Figure 2(c), the
model predicts larger intervals for values of x near 1 compared to those near
-1, aligning with the expected behavior from the model specified in Eq. (10).
In the final segment of this section, we delineate a crucial distinction be-
tween PNNs with probabilistic output layers and Gaussian process regression
15Figure 3: Comparing the predicted mean with the actual or empirical mean in (a), along-
side the predicted intervals against the actual intervals in (b) using the optimized PNN
on the synthetic data set. The PNN delivers highly accurate predictions of the empirical
meanwhilegeneratingintervalsthataremarginallywiderthanthoseobservedempirically.
Note that for both metrics, the highest possible score is 1.
(GPR), a widely used technique for quantifying predictive uncertainties in
the field of scientific machine learning [48, 49, 50]. To clarify, we explore the
key aspects of GPR, including the model assumption, training methodology,
and prediction mechanism.
A Gaussian process is a collection of random variables, any finite number
of which follows a joint Gaussian or normal distribution. Hence, a Gaussian
process is fully defined by its mean function, m(x), and its covariance func-
tion, k(x,x′). The covariance function is typically chosen to be the squared
exponential kernel function in the form of k(x,x′) =
exp(cid:0)
−
∥x−x′∥2 2(cid:1)
, where
2l2
l > 0 is an important hyperparameter, known as the bandwidth or length
scale [51]. A notable benefit of using the scikit-learn package [52] for im-
plementing GPR is its ability to automatically adjust the kernel bandwidth
during the fitting process, given specified bounds for the length scale, an
approach that we employ in our research.
For a given training data set D = {(x ,y )}n , the GPR observation
train i i i=1
model is represented as:
y = f(x )+ε, (11)
i i
where ε in this case adheres to a zero-mean normal distribution with fixed
variance, i.e., N(0,σ2). Therefore, the joint distribution of the observed
16outputs in the vector format, that is y ∈ Rn, and the function value at a new
test point x(t) is given by:
(cid:20) (cid:21) (cid:20) (cid:21)
y (cid:16) K+σ2I k(t) (cid:17)
∼ N 0, , (12)
f(x(t)) (k(t))T k(x(t),x(t))
where I is the identity matrix, K ∈ Rn×n is the covariance matrix computed
from D , and k(t) ∈ Rn is a column vector of covariances between the
train
training samples and the test point x(t). A limitation of standard GPR is
its assumption of homoscedastic noise variance, represented by a constant
σ2. This assumption is less effective in heteroscedastic settings, where the
noiselevelvaries, sincethereisnoinherentmechanismtoadaptivelyestimate
different noise levels from the data [53]. In the scikit-learn implementation,
users have the flexibility to specify σ2 as a hyperparameter, allowing them to
add a constant value to the diagonal entries of the covariance matrix, thereby
adjusting for observation noise through fine-tuning and grid search.
Based on the above model, GPR predictions are made by computing the
mean and variance functions as follows [54]:
fGPR = (k(t))T(K+σ2I)−1y
µ
fGPR = k(x(t),x(t))−(k(t))T(K+σ2I)−1k(t). (13)
σ
Therefore, like PNNs, GPR offers insights into each test input through mean
and variance-related outputs. However, it is essential to note that the vari-
ance function in GPR mainly reflects the model’s epistemic uncertainty, or
the uncertainty due to the model’s lack of knowledge, rather than the in-
herent data uncertainty. This differentiation is particularly significant in
scientific fields where data or aleatoric uncertainty frequently exhibits het-
eroscedastic behavior, meaning it varies across different observations. Such
variability cannot be adequately represented using a constant noise variance
σ2, as implied in the standard GPR formulation in Eq. (11).
To demonstrate this point, we return to the synthetic data set featur-
ing heteroscedastic noise, as described in Eq. (10). In a manner similar to
our approach with PNNs, we begin by fine-tuning two critical hyperparam-
eters for GPR: the upper limit of the kernel’s length scale parameter l and
the noise variance σ2. Following this, we calculate the KL divergence to
assess the distance between the predicted normal distribution, defined by
the mean fGPR and variance fGPR produced by GPR, and the true normal
µ σ
17distribution of the test data set. Figure 4(a) illustrates that GPR’s effective-
ness is highly dependent on the selection of these two hyperparameters. For
instance, whereas the highest KL divergence score—indicating the least sim-
ilarity between true and predicted distributions—for PNNs stood at 0.447,
in the case of GPR, this score escalates dramatically to approximately 304.
This discrepancy highlights the increased complexity and resource demand
of GPR in identifying suitable hyperparameter settings. Nonetheless, the op-
timal GPR configuration, with a length scale limit of 0.1 and a noise level of
1, achieves a KL divergence score of 0.381. This performance is competitive
with that of the PNNs, demonstrating that, despite the challenges, GPR can
attain comparable accuracy with careful hyperparameter tuning.
Figure4: UsingGPRtomodeltheheteroscedasticaleatoricnoiseinthesyntheticdataset,
wedisplaytheKLdivergencescoresfordifferentsettingsofthetwohyperparametersin(a).
Additionally, we evaluate the top-performing GPR model’s accuracy in predicting mean
and variance, as shown in (b) and (c). The results clearly indicate that GPR struggles to
adequately represent the aleatoric uncertainty inherent in this controlled data setting.
Furthermore, wedelveintotheefficacyofthetop-performingGPRmodel.
Figures 4(b) and (c) showcase the comparison between the predicted means
18and empirical means, as well as the predicted intervals versus the actual
intervals, for the 50 distinct input vectors in the test data set. These findings
indicate that the finely tuned GPR model yields highly accurate estimates
of the empirical means, with an R-squared score of 0.976. This score slightly
exceeds the best performance achieved by PNNs, which was 0.97. However,
a significant limitation of the GPR model becomes apparent in Figure 4(c).
As discussed previously, standard GPR assumes constant observation noise
(homoscedasticity), rendering it incapable of adequately capturing aleatoric
noise, even within our synthetic data set. Notably, the correlation coefficient
is slightly below 0, implying a lack of meaningful correlation between the
predicted and actual intervals. This undermines the primary advantage of
employing GPR to quantify uncertainties in this scenario. Consequently, our
comparative study, coupled with the algorithmic review, demonstrates that
PNNs exhibit a superior capacity for modeling heteroscedastic aleatoric or
data uncertainty.
4. Benchmarking with the Ishigami Function
In this section, we employ the Ishigami function, as referenced in [55, 56,
28], to demonstrate the efficacy of PNNs to model the aleatoric uncertainty
for multidimensional inputs. The Ishigami function, a well-regarded bench-
mark in the field, is defined for a 3-dimensional input vector x = [x ,x ,x ]
1 2 3
as follows:
f(x) = sin(x )+asin2(x )+bx4sin(x ), (14)
1 2 3 1
where x ,x ,x are independent variables uniformly distributed over the
1 2 3
range [−π,π], and a and b are constants; we use a = 7 and b = 0.1 in
our study. The Ishigami function is particularly challenging and thus a ro-
bust benchmark for two main reasons: (1) it incorporates nonlinear elements
such as sine and polynomial terms, and (2) it is nonmonotonic with its vari-
ables, meaning that its output does not consistently increase or decrease with
changes in x ,x , or x . These characteristics introduce significant complex-
1 2 3
ity, making the Ishigami function an ideal testbed for assessing the model-
ing capabilities of PNNs. Additionally, to explore aleatoric uncertainty, we
examine the following relationship between input vectors x and their corre-
sponding outputs y:
y = f(x)+ε, ε ∼ N(0,0.2 |f(x)|). (15)
19Hence, this variance structure introduces heteroscedastic noise, making the
uncertainty in the output y dependent on the magnitude of f(x), which is
defined in Eq. (14). For the training phase, we create 10 instances of the
noise term ε for each of the 300 training inputs, yielding a total of 3,000
training pairs. In a similar vein, for the evaluation phase, we generate 10
noise realizations for each of the 100 test data points. All these data points
are selected uniformly at random from the entire input space [−π,π]3. Also,
consistent with the approach in the prior case study, we set the batch size at
32 and the total number of training epochs at 100.
Figure 5(a) presents the outcomes of a grid search exploring three dif-
ferent depths (number of hidden layers) {2,4,6} and five widths (number of
hidden units) {4,8,12,16,20}. This search was motivated by the nonlinear
nature of the input-output relationship in the case study. The findings re-
veal that PNNs with 2 hidden layers fail to capture the output distributions
accurately, even with a substantial width of 20 units. Conversely, enhancing
the network’s depth significantly improves prediction accuracy. Notably, a
depth of 6 layers with various widths, such as 16 and 20 hidden units, yields
considerably lower KL divergence values. Within the tested hyperparameter
range, the optimal configuration for the PNN was found to be a depth of 6
layers and a width of 16 units, which achieved the minimal KL divergence
score.
To delve deeper into the predictive capabilities of the optimized PNN, we
display a comparison of the predicted mean f (x(t);θ∗) against the empirical
µ
mean femp(x(t)) for each test vector x(t) in Figure 5(b). This comparison
µ
illustrates that the predicted means align closely with the actual values,
clustering tightly near the 45-degree line. Furthermore, the achieved R-
squared score is 0.924, which is close to the ideal score of 1. Although this
R-squared score is marginally lower than what was observed in the preceding
1D example in Figure 3(a), it is important to acknowledge the increased
complexity introduced by the Ishigami function’s greater nonlinearity.
We next turn our attention to the prediction intervals generated by the
optimized PNN, which incorporates both the predicted mean f (x(t);θ∗) and
µ
variance f (x(t);θ∗) to construct a 90% confidence interval. Figure 5(c) re-
σ
veals a mild upward trend in the distribution of the scatter plot points,
indicating that the optimized PNN tends to slightly overpredict the width of
the true prediction intervals, particularly for larger intervals. Despite this,
the strong positive correlation between the estimated and actual intervals,
as evidenced by a correlation coefficient of 0.826, underscores the model’s
20Figure 5: Utilizing PNNs to model the aleatoric uncertainty associated with the Ishigami
function, we report the KL divergence values between the actual and estimated output
distributions in (a). Additionally, we examine the predicted mean and interval accuracies
in (b) and (c). The results indicate that the optimized PNN is effective in generating an
accurate predictive distribution for the output.
reliability in capturing the relationship. This performance even surpasses
that observed in the 1D example shown in Figure 3(b). Consequently, we
deduce that PNNs are capable of delivering precise and reliable representa-
tions of aleatoric uncertainty within multidimensional and nonlinear systems
in scientific problems.
5. Real-world Application in Material Science: Composite Mi-
crostructure Generation
Fiber-reinforcedcompositesarehighlysoughtafterinengineeringapplica-
tions that demand high strength with minimal weight. For these composites
to be effectively used in structural parts, it is crucial to develop computer
models that can accurately predict their behavior under various loads. The
21challenge in modeling composites lies in the need for high fidelity to capture
microscale details, such as densely packed fiber clusters or resin-rich zones,
which can significantly increase computational demands. To address this,
multiscale modeling has proven effective, allowing for the detailed represen-
tation of microscale features within smaller, more manageable models.
In this work, we used a microstructure generator that employs several
input parameters to shape the fiber morphology, maintaining a balance be-
tween controlled outcomes and inherent randomness [57, 58]. The generator
was developed using in-house code with the Discrete Element Method as its
foundation. Fiber seeding parameters control the size of the microstructure
and the initial placement or seeding of the fibers prior to enforcing contact
between fibers. First, a number of fibers, n , were placed in a bounded
f
region divided into cells that were padded by a margin, m , based on a
cell
user-defined number of fibers per cell, n , until a global volume fraction,
f/cell
V , was reached. Increasing the margin decreased the area where fibers could
f
be placed, increasing the chance of initial overlapping and the potential en-
ergy of the system. Once seeded, the fibers were allowed to disperse, with
movement initiated by contact between the fibers.
The simulation phase of this generator continued until a prescribed ki-
netic energy cutoff, ϵ , criteria was met. Initially, a prescribed number of
KE
relaxation iterations was run without damping until a maximum number of
time steps, t , was reached and damping was enforced. Three different
nmax
types of damping were used to alter the kinetic energy dispersion: contact
damping, Cn, global damping, C , which increased with each time step, and
ij i
incremental damping, d , which was enforced at each time step. Once the
i
simulation ended, a minimum spacing between the fibers, d , was created
min
by reducing the radius of each fiber.
In this case study, a given set of inputs for the microstructure generator
does not ensure a consistent fiber morphology and the resulting descriptors,
due to the initial random placement of fibers, as shown in Figure 6. This
randomness originates from the initial setup, where fibers are positioned ran-
domly, potentially leading to overlaps. As the simulation begins, the move-
ments and interactions of the fibers are dictated by their initial placements,
leading them to disperse and collide until a stable state is achieved through
contact dynamics and viscous damping.
In summary, the stochastic nature of this process leads to diverse out-
comes in fiber configurations across simulations, reflected in a spectrum of
microstructural descriptor values for each set of input parameters. This
22Figure 6: Aleatoric uncertainty in generating microstructures: the observation model for
any given input vector x ∈ R7 incorporates a heteroscedastic noise term, which varies
with the input. Consequently, a data set comprising nearly 50 samples of the (unknown)
noise term for each input vector has been constructed, enabling the modeling of aleatoric
uncertainty through PNNs.
variability introduces a heteroscedastic noise element into the relationship
between the input vector x and the output variable y. To address this, we
performed around 50 repetitions for each set of inputs, generating 50 distinct
versions of the noise term. In this particular study, we have a total of 23,465
unique input vectors. We allocate 20% of these inputs to the test data set,
with the remaining 80% used for training purposes. Considering that the
training data set encompasses roughly one million input-output pairs, we
adjust the batch size to 2,048 and reduce the number of epochs to 10.
Figure 7 presents the outcomes of a grid search conducted on PNNs with
various configurations of depth and width. This study reveals that even a
single hidden layer can yield relatively low KL divergence scores, with the
scores dropping below 1 for configurations where the network width, or the
number of hidden units, is set to 8. Notably, a width of 8 consistently results
in KL divergence values under 1 across all tested depths, highlighting an
optimal width. Consequently, we will further explore the performance of
PNNs with a fixed width of 8 and depths ranging from 1 to 3. However,
it is important to highlight that the lowest KL divergence observed was
with a configuration of 3 hidden layers, each comprising 20 units. We will
23next elaborate on how these configurations influence the predicted output
distribution.
Figure 7: Presenting the KL divergence scores achieved by PNNs across different depths
and widths in the context of the microstructure generation problem. Our case study
highlights multiple architectures achieving KL divergence scores under 1.
Based on the results obtained from our grid search, we further explore the
predictive performance of PNNs with a consistent width of 8 across varying
depths, as illustrated in Figure 8. It is important to note that the KL diver-
gence scores showed a consistent decrease with increasing depth, indicating
a more accurate representation of the true or empirical output distribution.
This trend aligns with the observations in Figure 8, especially when com-
paring the predicted intervals with the empirical intervals. For instance, at
a depth of 1, the correlation coefficient stands at 0.613, but this value esca-
lates to 0.781 with the depth increased to 3. Moreover, with a depth of 3 and
width of 8, the data points demonstrate a closer alignment to the 45-degree
line compared to other configurations. From these observations, we draw two
primary conclusions: firstly, the performance of PNNs exhibits a robustness
to variations in network architecture, which is advantageous from a practical
perspective. Secondly, PNNs are capable of accurately estimating aleatoric
uncertainty within this materials science application.
In the final segment of this section, we delve into the performance of the
optimized PNN, which recorded the lowest KL divergence score during our
grid search. Figure 9 presents a comparison between predicted and empirical
means, alongside predicted and empirical intervals, for the refined PNN that
includes 3 hidden layers, each consisting of 20 units. The R-squared score de-
picted in Figure 9(a) indicates a modest improvement in the predicted mean,
especially when compared to the R-squared scores shown in Figure 8, where
24Figure 8: This figure displays the comparison of predicted versus empirical means in the
toprow,andthecomparisonofpredictedversusempiricalintervalsasfoundinourtestset
in the bottom row. Throughout these comparisons using the microstructure generation
problem, each PNN maintains a fixed width of 8, with the depth adjusted from 1 to 3.
the network width was fixed at 8. This reinforces the effectiveness of PNNs
in approximating the mean of the underlying normal distribution that gener-
atestheobserveddata. Moreover, thecorrelationcoefficientforthepredicted
intervals shows a slight enhancement, being approximately 0.02 higher than
the previously highest reported value. Consequently, this underscores the
utility of the KL divergence score as a valuable metric for identifying precise
PNN configurations in the context of real-world scientific machine learning
challenges.
6. Conclusion
In this paper, we explored various facets of developing probabilistic neu-
ral networks (PNNs) to model aleatoric uncertainty, focusing on aspects such
as model assumptions, loss functions, and employing Kullback-Leibler (KL)
divergence to assess the accuracy of predictions by comparing the predicted
and actual output distributions. Utilizing KL divergence to steer our grid
search yielded several notable findings. First, PNN performance appears rel-
atively robust to network architecture variations, such as depth and width.
25Figure 9: Assessing the effectiveness of the PNN model that achieved the minimal KL
divergence score in our grid search. The findings demonstrate the model’s capability to
deliverdependableestimationsofboththemeanoftheoutputdataandtheheteroscedastic
aleatoric noise within the context of a real-world scientific machine learning problem.
For instance, in a practical material science application, we found that dif-
ferent PNN configurations could all generate satisfactory predictive models.
Second, PNNs demonstrated the capability to accurately estimate the empir-
ical mean under a range of simulated or controlled aleatoric noise conditions,
as well as in a real-world scenario with an indeterminate noise analytical
form. Third, the prediction intervals provided by PNNs closely matched
the empirical prediction intervals, despite occasional slight overestimations.
However, the strong correlation coefficient underscores the utility of these
intervals for decision making, particularly in predicting the consistency of
real-world system outputs from repeated inputs, which is crucial for optimal
design strategies. Although this study primarily addresses aleatoric uncer-
tainty due to its pressing significance, future work will aim to enhance PNNs
for concurrent modeling of aleatoric and epistemic uncertainties, paving the
way for advanced active learning methodologies.
Acknowledgements
The present work was partially supported by a NASA Space Technol-
ogy Graduate Research Opportunity (80NSSC21K1285) and a NASA NRA
(80NSSC21N0102)throughtheNASATransformationalToolsandTechnolo-
gies (TTT) program, under the Aeronautic Research Mission Directorate
26(ARMD). This work was completed in part with resources provided by the
University of Massachusetts’ Green High Performance Computing Cluster
(GHPCC).
Conflicts of Interest
The authors declare that they have no known competing financial inter-
ests or personal relationships that could have appeared to influence the work
reported in this paper.
References
[1] V. Nemani, L. Biggio, X. Huan, Z. Hu, O. Fink, A. Tran, Y. Wang,
X. Zhang, C. Hu, Uncertainty quantification in machine learning for en-
gineering design and health prognostics: A tutorial, Mechanical Systems
and Signal Processing 205 (2023) 110796.
[2] N. Johnson, P. Vulimiri, A. To, X. Zhang, C. Brice, B. Kappes, A. Steb-
ner,Invitedreview: Machinelearningformaterialsdevelopmentsinmet-
als additive manufacturing, Additive Manufacturing 36 (2020) 101641.
[3] T. Nasrin, F. Pourkamali-Anaraki, A. Peterson, Application of machine
learning in polymer additive manufacturing: A review, Journal of Poly-
mer Science (2023).
[4] Y. Xie, K. Sattari, C. Zhang, J. Lin, Toward autonomous laborato-
ries: Convergence of artificial intelligence and experimental automation,
Progress in Materials Science 132 (2023) 101043.
[5] F. Pourkamali-Anaraki, M. Hariri-Ardebili, Neural networks and imbal-
anced learning for data-driven scientific computing with uncertainties,
IEEE Access 9 (2021) 15334–15350.
[6] A. Tapeh, M. Naser, Artificial intelligence, machine learning, and deep
learning in structural engineering: a scientometrics review of trends and
bestpractices,ArchivesofComputationalMethodsinEngineering30(1)
(2023) 115–159.
[7] H. Thai, Machine learning for structural engineering: A state-of-the-art
review, in: Structures, Vol. 38, 2022, pp. 448–491.
27[8] J. Weyn, D. Durran, R. Caruana, Improving data-driven global
weather prediction using deep convolutional neural networks on a cubed
sphere, Journal of Advances in Modeling Earth Systems 12 (9) (2020)
e2020MS002109.
[9] S. Salcedo-Sanz, P. Ghamisi, M. Piles, M. Werner, L. Cuadra,
A. Moreno-Mart´ınez, E. Izquierdo-Verdiguier, J. Mun˜oz-Mar´ı,
A. Mosavi, G. Camps-Valls, Machine learning information fusion
in earth observation: A comprehensive review of methods, applications
and data sources, Information Fusion 63 (2020) 256–272.
[10] X. Yang, Y. Wang, R. Byrne, G. Schneider, S. Yang, Concepts of artifi-
cial intelligence for computer-assisted drug discovery, Chemical reviews
119 (18) (2019) 10520–10594.
[11] P.Rajpurkar,E.Chen,O.Banerjee,E.Topol,AIinhealthandmedicine,
Nature medicine 28 (1) (2022) 31–38.
[12] M. Daidone, S. Ferrantelli, A. Tuttolomondo, Machine learning applica-
tions in stroke medicine: Advancements, challenges, and future prospec-
tives, Neural Regeneration Research 19 (4) (2024) 769–773.
[13] G. Bae, I. Budvytis, R. Cipolla, Estimating and exploiting the aleatoric
uncertainty in surface normal estimation, in: Proceedings of the
IEEE/CVF International Conference on Computer Vision, 2021, pp.
13137–13146.
[14] E. Hu¨llermeier, W. Waegeman, Aleatoric and epistemic uncertainty in
machine learning: An introduction to concepts and methods, Machine
Learning 110 (2021) 457–506.
[15] Y. Zhang, J. Lin, F. Li, Y. Adler, K. Rasul, A. Schneider, Y. Nevmy-
vaka, Risk bounds on aleatoric uncertainty recovery, in: International
Conference on Artificial Intelligence and Statistics, 2023, pp. 6015–6036.
[16] R. Barber, E. Cand`es, A. Ramdas, R. Tibshirani, Predictive inference
with the jackknife+, The Annals of Statistics 49 (1) (2021) 486 – 507.
[17] S. Deshpande, J. Lengiewicz, S. Bordas, Probabilistic deep learning for
real-time large deformation simulations, Computer Methods in Applied
Mechanics and Engineering 398 (2022) 115307.
28[18] A. Harakeh, J. Hu, N. Guan, S. Waslander, L. Paull, Estimating regres-
sionpredictivedistributionswithsamplenetworks,in: AAAIConference
on Artificial Intelligence, Vol. 37, 2023, pp. 7830–7838.
[19] K. Murphy, Probabilistic machine learning: an introduction, MIT press,
2022.
[20] C. Yang, Y. Li, Explainable uncertainty quantifications for deep
learning-basedmolecularpropertyprediction, JournalofCheminformat-
ics 15 (1) (2023) 13.
[21] A. Immer, E. Palumbo, A. Marx, J. Vogt, Effective Bayesian het-
eroscedastic regression with deep neural networks, in: Neural Informa-
tion Processing Systems, 2023.
[22] R. Maulik, K. Fukami, N. Ramachandra, K. Fukagata, K. Taira, Prob-
abilistic neural networks for fluid flow surrogate modeling and data re-
covery, Physical Review Fluids 5 (10) (2020) 104401.
[23] M. Seitzer, A. Tavakoli, D. Antic, G. Martius, On the pitfalls of het-
eroscedastic uncertainty estimation with probabilistic neural networks,
arXiv preprint arXiv:2203.09168 (2022).
[24] J. Thiyagalingam, M. Shankar, G. Fox, T. Hey, Scientific machine learn-
ing benchmarks, Nature Reviews Physics 4 (6) (2022) 413–420.
[25] A. Psaros, X. Meng, Z. Zou, L. Guo, G. Karniadakis, Uncertainty quan-
tification in scientific machine learning: Methods, metrics, and compar-
isons, Journal of Computational Physics 477 (2023) 111902.
[26] S. Ji, Z. Zhang, S. Ying, L. Wang, X. Zhao, Y. Gao, Kullback–Leibler
divergence metric learning, IEEE Transactions on Cybernetics 52 (4)
(2020) 2047–2058.
[27] T. Karvonen, C. Oates, Maximum likelihood estimation in Gaussian
process regression is ill-posed, Journal of Machine Learning Research
24 (120) (2023) 1–47.
[28] M. Hariri-Ardebili, F. Pourkamali-Anaraki, Structural uncertainty
quantification with partial information, Expert Systems with Applica-
tions 198 (2022) 116736.
29[29] W. Liu, Z. Wang, X. Liu, N. Zeng, Y. Liu, F. Alsaadi, A survey of deep
neural network architectures and their applications, Neurocomputing
234 (2017) 11–26.
[30] F. Pourkamali-Anaraki, T. Nasrin, R. Jensen, A. Peterson, C. Hansen,
Evaluation of classification models in limited data scenarios with appli-
cation to additive manufacturing, Engineering Applications of Artificial
Intelligence 126 (2023) 106983.
[31] K. Chitty-Venkata, M. Emani, V. Vishwanath, A. Somani, Neural archi-
tecture search benchmarks: Insights and survey, IEEE Access 11 (2023)
25217–25236.
[32] H. Jin, F. Chollet, Q. Song, X. Hu, Autokeras: An AutoML library for
deep learning, Journal of Machine Learning Research 24 (6) (2023) 1–6.
[33] A. Jagtap, G. Karniadakis, How important are activation functions in
regression and classification? a survey, performance comparison, and
future directions, Journal of Machine Learning for Modeling and Com-
puting 4 (1) (2023).
[34] O. Renaud, M. Victoria-Feser, A robust coefficient of determination for
regression, Journal of Statistical Planning and Inference 140 (7) (2010)
1852–1862.
[35] A. Stirn, H. Wessels, M. Schertzer, L. Pereira, N. Sanjana, D. Knowles,
Faithful heteroscedastic regression with neural networks, in: Interna-
tional Conference on Artificial Intelligence and Statistics, 2023, pp.
5593–5613.
[36] H. Zheng, Z. Yang, W. Liu, J. Liang, Y. Li, Improving deep neural
networks using softplus units, in: International Joint Conference on
Neural Networks, 2015, pp. 1–4.
[37] S. Nag, M. Bhattacharyya, A. Mukherjee, R. Kundu, SERF: Towards
better training of deep neural networks using log-softplus error acti-
vation function, in: IEEE/CVF Winter Conference on Applications of
Computer Vision, 2023, pp. 5324–5333.
30[38] M. Mukkamala, M. Hein, Variants of rmsprop and adagrad with loga-
rithmic regret bounds, in: International Conference on Machine Learn-
ing, 2017, pp. 2545–2553.
[39] R. Abdulkadirov, P. Lyakhov, N. Nagornov, Survey of optimization al-
gorithms in modern neural networks, Mathematics 11 (11) (2023) 2466.
[40] M. Magris, A. Iosifidis, Bayesian learning for neural networks: an algo-
rithmic survey, Artificial Intelligence Review (2023) 1–51.
[41] I. Oleksiienko, D. Tran, A. Iosifidis, Variational neural networks, Proce-
dia Computer Science 222 (2023) 104–113.
[42] M. Raghu, B. Poole, J. Kleinberg, S. Ganguli, J. Sohl-Dickstein, On the
expressive power of deep neural networks, in: International Conference
on Machine Learning, 2017, pp. 2847–2854.
[43] J. Lu, Z. Shen, H. Yang, S. Zhang, Deep network approximation for
smooth functions, SIAM Journal on Mathematical Analysis 53 (5)
(2021) 5465–5506.
[44] B. Adcock, N. Dexter, The gap between theory and practice in function
approximation with deep neural networks, SIAM Journal on Mathemat-
ics of Data Science 3 (2) (2021) 624–655.
[45] L. Feng, H. Wang, B. Jin, H. Li, M. Xue, L. Wang, Learning a dis-
tance metric by balancing kl-divergence for imbalanced datasets, IEEE
TransactionsonSystems,Man,andCybernetics: Systems49(12)(2018)
2384–2395.
[46] D. Guo, L. Tang, X. Zhang, Y. Liang, An off-policy multi-agent stochas-
tic policy gradient algorithm for cooperative continuous control, Neural
Networks 170 (2024) 610–621.
[47] H. Zhou, Z. Deng, Y. Xia, M. Fu, A new sampling method in parti-
cle filter based on pearson correlation coefficient, Neurocomputing 216
(2016) 208–215.
[48] E. Schulz, M. Speekenbrink, A. Krause, A tutorial on Gaussian process
regression: Modelling, exploring, and exploiting functions, Journal of
Mathematical Psychology 85 (2018) 1–16.
31[49] V. Deringer, A. Barto´k, N. Bernstein, D. Wilkins, M. Ceriotti,
G. Cs´anyi, Gaussian process regression for materials and molecules,
Chemical Reviews 121 (16) (2021) 10073–10141.
[50] W. Maddox, A. Potapcynski, A. Wilson, Low-precision arithmetic for
fast Gaussian processes, in: Uncertainty in Artificial Intelligence, 2022,
pp. 1306–1316.
[51] F. Pourkamali-Anaraki, S. Becker, Improved fixed-rank Nystro¨m ap-
proximation via QR decomposition: Practical and theoretical aspects,
Neurocomputing 363 (2019) 261–272.
[52] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, Scikit-
learn: Machine learning in Python, Journal of Machine Learning Re-
search 12 (2011) 2825–2830.
[53] Z. Li, X. Hong, K. Hao, L. Chen, B. Huang, Gaussian process regression
with heteroscedastic noises–a machine-learning predictive variance ap-
proach, Chemical Engineering Research and Design 157 (2020) 162–173.
[54] J. Wang, An intuitive tutorial to gaussian processes regression, Com-
puting in Science & Engineering (2023) 1–8.
[55] D. Allaire, K. Willcox, A variance-based sensitivity index function for
factorprioritization, ReliabilityEngineering&SystemSafety107(2012)
107–114.
[56] M. Opgenoord, D. Allaire, K. Willcox, Variance-based sensitivity anal-
ysis to support simulation-based design under uncertainty, Journal of
Mechanical Design 138 (11) (2016) 111410.
[57] J. Husseini, E. Pineda, S. Stapleton, Generation of artificial 2-D fiber re-
inforcedcompositemicrostructureswithstatisticallyequivalentfeatures,
Composites Part A: Applied Science and Manufacturing 164 (2023)
107260.
[58] J. Husseini, F. Pourkamali-Anaraki, P. Hajibabaee, S. Stapleton, Gener-
ation of 2-D fiber reinforced composite microstructures with statistically
equivalentfeaturesusingmachinelearningandadaptivedatageneration,
in: AIAA SCITECH 2023 Forum, 2023, p. 1267.
32