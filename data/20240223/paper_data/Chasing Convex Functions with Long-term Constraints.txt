Chasing Convex Functions with Long-term Constraints
AdamLechowicz∗ NicolasChristianson† BoSun‡ NomanBashir§
MohammadHajiesmaili¶ AdamWierman∥ PrashantShenoy∗∗
February22,2024
Abstract
We introduce and study a family of online metric problems with long-term constraints. In these
problems,anonlineplayermakesdecisionsx𝑡 inametricspace(𝑋,𝑑)tosimultaneouslyminimizetheir
hittingcost𝑓 𝑡(x𝑡)andswitchingcostasdeterminedbythemetric.Overthetimehorizon𝑇,theplayer
mustsatisfyalong-termdemandconstraint(cid:205) 𝑡𝑐(x𝑡) ≥ 1,where𝑐(x𝑡)denotesthefractionofdemand
satisfiedattime𝑡.Suchproblemscanfindawidearrayofapplicationstoonlineresourceallocationin
sustainable energy and computing systems. We devise optimal competitive and learning-augmented
algorithmsforspecificinstantiationsoftheseproblems,andfurthershowthatourproposedalgorithms
performwellinnumericalexperiments.
1 Introduction
This paper introduces and studies a novel class of online metric problems with long-term demand con-
straintsmotivatedbyemergingapplicationsinthedesignofsustainablesystems. Inconvexfunctionchas-
ingwithalong-termconstraint,anonlineplayeraimstosatisfyademandbymakingdecisionsinanormed
vector space, paying a hitting cost based on time-varying convex cost functions which are revealed on-
line,andswitchingcostdefinedbythenorm. Theplayerisconstrainedtoensurethattheentiredemand
is satisfied at or before the time horizon𝑇 ends, and their objective is to minimize their total cost. The
generality of this problem makes it applicable to a wide variety of online resource allocation problems;
in this paper, we consider one such special case, discussing its connections to other online settings and
suggestionstowardsbroadnewareasofinquiryinonlineoptimizationwithlong-termconstraints.
Our motivation to introduce these problems is rooted in an emerging class of carbon-aware control
problems for sustainable systems. A shared objective involves minimizing carbon emissions by shifting
flexible workloads temporally and/or spatially to better leverage low-carbon electricity generation (e.g.,
renewablessuchassolarandwind).Exampleswhichhaverecentlyseensignificantinterestincludecarbon-
aware electric vehicle (EV) charging [CBS+22] and carbon-aware compute shifting [WBS+21; BGH+21;
RKS+22;ALK+23;HLB+23].
∗UniversityofMassachusettsAmherst.Email:alechowicz@cs.umass.edu
†CaliforniaInstituteofTechnology.Email:nchristianson@caltech.edu
‡UniversityofWaterloo.Email:bo.sun@uwaterloo.ca
§MassachusettsInstituteofTechnology.Email:nbashir@mit.edu
¶UniversityofMassachusettsAmherst.Email:hajiesmaili@cs.umass.edu
∥CaliforniaInstituteofTechnology.Email:adamw@caltech.edu
∗∗UniversityofMassachusettsAmherst.Email:shenoy@cs.umass.edu
1
4202
beF
12
]SD.sc[
1v21041.2042:viXraTheproblemsweintroduceinthispaperbuildonalonglineofrelatedworkinonlinealgorithms.Most
existingworkcanberoughlyclassifiedintotwotypes:onlinemetricproblems,wheremanyworksconsider
multidimensional decision spaces and switching costs but do not consider long-term constraints [BLS92;
Kou09; CGW18; BKL+19; BCL+21; BC22; BCR23], and online search problems, which feature long-term
demand constraints but do not consider multidimensional decision spaces or switching costs [EFK+01;
LPS08;MAS14;SZL+21].
Webrieflyreviewthedirectprecursorsofourworkbelow. Intheonlinemetricliterature,theproblem
we study is an extension of convex function chasing (CFC) introduced by Friedman and Linial [FL93],
where an online player makes online decisions x𝑡 in a normed vector space (𝑋,∥·∥) over a sequence of
time-varyingcostfunctionsinordertominimizetheirtotalhittingandswitchingcost.Intheonlinesearch
literature, the problem we study is a generalization of one-way trading (OWT) introduced by El-Yaniv et
al. [EFK+01], in which an online player must sell an entire asset in fractional shares over a sequence of
time-varyingpriceswhilemaximizingtheirprofit.
Despite extensive existing work in the online metric and online search tracks, few works simultane-
ouslyconsiderlong-termdemandconstraints(asinOWT)andmovement/switchingcosts(asinCFC).The
existing prior works [LCZ+23; LCS+24] that consider both components are restricted to unidimensional
decision spaces, as is typical in the online search literature. However, generalizing from the unidimen-
sionalcaseishighlynon-trivial;e.g.,inconvexfunctionchasingwithalong-termconstraint,theproblem
cannotsimplybedecomposedoverdimensionsduetothesharedcapacityconstraintandmultidimensional
switchingcost. Thus,inthisworkwetacklethefollowingquestion:
Is it possible to design online algorithms for the studied problems that operate in multidimen-
sionaldecisionspaceswhilesimultaneouslyconsideringlong-termconstraints,hittingcosts,and
switchingcosts?
Although the aforementioned literature focuses on competitive algorithms in adversarial settings,
there has recently been significant interest in moving beyond worst-case analysis, which can result in
overlypessimisticalgorithms. Thefieldoflearning-augmentedalgorithms [LV18; PSK18]hasemergedas
aparadigmfordesigningandanalyzingalgorithmsthatincorporateuntrustedmachine-learnedadviceto
improveaverage-caseperformancewithoutsacrificingworst-caseperformancebounds. Suchalgorithms
areevaluatedthroughthemetricsofconsistencyandrobustness(seeDef.2.1).Recentstudieshaveproposed
learning-augmented algorithms for related problems, including convex function chasing [CHW22], one-
waytrading[SLH+21], metricaltasksystems[CSW23], andonlinesearch[LSH+24]. Whiletheliterature
ineachofthesetracksconsidersaspectrumofdifferentadvicemodels,theirresultspromptanaturalopen
question:
Canwedesignalgorithmsforonlinemetricproblemswithlong-termconstraintsthateffectively
utilizeuntrustedadvice(suchasmachine-learnedpredictions)toimproveperformancewhilepre-
servingworst-casecompetitiveguarantees?
Contributions. Despite extensive prior literature on adjacent problems, the problems we propose in
this paper are the first online settings to combine long-term demand constraints with multidimensional
decision spaces and switching costs. We introduce convex function chasing with a long-term constraint,
andaspecialcasecalledonlinemetricallocationwithalong-termconstraint. Thegeneralformsofbothare
independentlyinterestingforfurtherstudy.
We obtain positive results for both of the questions posed above under problem instantiations that
are especially relevant for motivating applications. We provide the first competitive results for online
problemsofthisforminSection3,andshowthatourproposedalgorithm(Algorithm1)achievesthebest
2possiblecompetitiveratio. InSection4,weproposealearning-augmentedalgorithm,CLIP(Algorithm2),
andshowitachievestheprovablyoptimaltrade-offbetweenconsistencyandrobustness.
Toachievetheseresults,theproposedalgorithmsmusttackletechnicalchallengesdistinctfromprior
work studying adjacent problems. We build on a generalization of the threshold-based designs used for
simpledecisionspacesintheonlinesearchliteraturecalledpseudo-costminimization.Weintroduceanovel
application of this framework to multidimensional decision spaces (see Section 3), and show that it sys-
tematicallyaddressesthecompetitivedrawbacksoftypicalalgorithmdesignsforonlinemetricproblems.
Weevaluateourproposedalgorithmsinnumericalexperimentsandshowthatouralgorithmsoutperform
asetofbaselineheuristicsonsyntheticinstancesofconvexfunctionchasingwithalong-termconstraint.
Our learning-augmented algorithm CLIP (see Section 4) introduces a novel projected consistency con-
straint which is designed to guarantee (1 +𝜖)-consistency against the provided advice ADV by continu-
ously comparing their solutions in terms of the cost incurred so far, the switching cost trajectories, and
the projected worst-case cost required to complete the long-term constraint. To solve both convex func-
tion chasing and online metric allocation with long-term constraints, we derive a transformation result
thatdirectlyrelatestheperformanceofanalgorithmontheformerproblemwithitsperformanceonthe
latter(seeSection2).
2 Problem Formulation and Preliminaries
Thissectionformalizesconvexfunctionchasingandonlinemetricallocationwithlong-termconstraints,
motivating them with a sustainability application. We also provide preliminaries used throughout the
paper,andgiveinitialresultstobuildalgorithmicconnectionsbetweenbothproblems.
Convex function chasing with a long-term constraint. A player chooses decisions x𝑡 ∈ 𝑋 ⊆ R𝑑
onlinefromanormedvectorspace (𝑋,∥·∥) inordertominimizetheirtotalcost(cid:205)𝑇 𝑡=1𝑓 𝑡(x𝑡) +(cid:205)𝑇 𝑡=+ 11 ∥x𝑡 −
x𝑡−1∥, where 𝑓 𝑡(·) : 𝑋 → R is a convex “hitting” cost that is revealed just before the player chooses x𝑡,
and ∥x𝑡 −x𝑡−1∥ isaswitchingcostassociatedwithchangingdecisionsbetweenrounds. Additionally,the
player must satisfy a long term constraint of the form (cid:205)𝑇 𝑡=1𝑐(x𝑡) = 1, where𝑐(x) : 𝑋 → [0,1] gives the
fractionoftheconstraintsatisfiedbyadecisionx. Wedenotetheutilizationattime𝑡 by𝑧(𝑡) = (cid:205) 𝜏𝑡 =1𝑐(x𝜏),
whichgivesthetotalfractionofthelong-termconstraintsatisfieduptoandincludingtime𝑡. Theoffline
versionofthisproblemcanbeformalizedasfollows:
min
∑︁𝑇
𝑓 𝑡(x𝑡)
+∑︁𝑇+1
∥x𝑡 −x𝑡−1∥ s.t.
∑︁𝑇
𝑐(x𝑡) ≥ 1, x𝑖
𝑡
∈ [0,1] ∀𝑖 ∈ [𝑑], ∀𝑡 ∈ [𝑇]. (1)
{x𝑡}𝑡∈[𝑇] (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)𝑡 (cid:32)(cid:32)(cid:32)=1 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)𝑡 (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)𝑡 (cid:32)(cid:32)=(cid:32)(cid:32)(cid:32)1 (cid:32)(cid:32)(cid:32)(cid:32) (cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)(cid:32)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Convexhittingcost Switchingcost Long-termconstraint
Assumptions. Here,wedescribetheprecisevariantofconvexfunctionchasingwithalong-termcon-
straintforwhichwedesignalgorithmsintheremainderofthepaper. Let ∥x−x′∥ (cid:66) ∥x−x′∥ ℓ 1(w),where
∥·∥ ℓ 1(w) denotestheweightedℓ 1 normwithweightvectorw ∈ R𝑑 .
Wedefinethelong-termconstraintsuchthat𝑐(x) (cid:66) ∥x∥ ℓ 1(c),i.e.,theweightedℓ 1normwithweightvector
c ∈ R𝑑 . Thenletthemetricspace𝑋 betheℓ 1 balldefinedby𝑋 (cid:66) {x ∈ R𝑑 :𝑐(x) ≤ 1}. Forallcostfunctions
𝑓 𝑡(·) : 𝑋 → R, weassumeboundedgradientssuchthat𝐿 ≤ [∇𝑓 𝑡]𝑖/ c𝑖 ≤ 𝑈 ∀𝑖 ∈ [𝑑],𝑡 ∈ [𝑇], where𝑖 denotes
the𝑖thdimensionofthecorrespondingvector,and𝐿,𝑈 areknownpositiveconstants.
Letting 0 denote the origin in R𝑑 (w.l.o.g), we have the property 𝑓 𝑡(0) = 0 for all 𝑡 ∈ [𝑇], i.e., that
“satisfying none of the long-term constraint costs nothing”, since𝑐(0) = 0. We assume the player starts and
endsattheorigin,i.e.,x0 = 0andx𝑇+1 = 0,toenforceswitching“on”and“off.”Theseassumptionsareintuitive
andreasonableinpractice,e.g.,inourexamplemotivatingapplicationbelow.
For analysis, it will be useful to establish a shorthand for the magnitude of the switching cost. Let
𝛽 (cid:66) max(cid:0) w𝑖/ c𝑖(cid:1) , which gives the greatest magnitude of the switching cost coefficient when normalized by
3theconstraintfunction. Weassumethat𝛽 isboundedontheinterval [0,𝑈−𝐿/2);if𝛽 is“large”(i.e., > 𝑈−𝐿/2),
1
wecanshowthattheplayershouldprioritizeminimizingtheswitchingcost.
Recall the player must fully satisfy the long-term constraint before the sequence ends. If the player has
satisfied𝑧(𝑡) fraction of the constraint at time𝑡, we assume a compulsory trade begins at time 𝑗 as soon as
(𝑇 −(𝑗 +1)) · c𝑖 < (cid:0)1−𝑧(𝑗)(cid:1) ∀𝑖 ∈ [𝑑] (i.e., when the time steps after 𝑗 are not sufficient to satisfy the
constraint). During this compulsory trade, a cost-agnostic algorithm takes over, making maximal decisions
to satisfy the constraint. To ensure that the problem remains technically interesting, we assume that the
2
compulsorytradeisasmallportionofthesequence.
Forbrevity,wehenceforthuseCFLtorefertothevariantofconvexfunctionchasingwithalong-term
constraintundertheassumptionsoutlinedabove.
Anexamplemotivatingapplication. CFLcanmodelavarietyofapplications,includingspecificap-
plications that motivate this study. Consider a carbon-aware temporal load shifting application with het-
erogeneous servers. Here, each of the𝑑 dimensions corresponds to one of𝑑 heterogeneous servers. An
algorithm makes decisions x𝑡 ∈ R𝑑, where x𝑖
𝑡
∈ [0,1] denotes the load of the𝑖th server at time 𝑡. The
long-term constraint (cid:205)𝑇 𝑡=1𝑐(x𝑡) ≥ 1 enforces that an entire workload should be finished before time𝑇,
andeachcoefficientc𝑖 representsthethroughputofthe𝑖thserver. Eachcostfunction𝑓 𝑡(x𝑡)representsthe
carbonemissionsduetotheelectricityusageoftheserversconfiguredaccordingtox𝑡,andtheswitching
cost ∥·∥ captures the carbon emissions overhead (e.g., extra latency) of pausing, resuming, scaling,
ℓ 1(w)
andmovingtheworkloadbetweenservers.
Online metric allocation with a long-term constraint. Bansal and Coester [BC22] introduced the
online metric allocation problem (MAP), which connects several online metric problems. MAP on a star
metricisequivalenttoCFCwhencostfunctionsareseparableoverdimensionsandsupportedontheunit
simplexΔ 𝑛.3 Furthermore,therandomizedmetricaltasksystemsproblem(MTS)isaspecialcaseofMAP
whencostfunctionsarelinearandincreasing.
We build on this formulation in our setting and introduce online metric allocation with a long-term
constraint,whichcapturesaparticularlyinterestingspecialcaseofCFL.Thegeneralversionoftheproblem
considersan𝑛-pointmetricspace (𝑋,𝑑),andaunitresourcewhichcanbeallocatedinarbitraryfractions
tothepointsof𝑋. Ateachtime𝑡 ∈ [𝑇],convexcostfunctions 𝑓𝑎(·) : [0,1] → Rarriveateachpoint𝑎 in
𝑡
themetricspace. Theonlineplayerchoosesanallocation𝑥𝑎 toeachpoint𝑎inthemetricspace,suchthat
𝑡
(cid:205)𝑛 𝑥𝑎 = 1forall𝑡 ∈ [𝑇]. Whenchangingthisallocationbetweentimesteps,theplayerpaysaswitching
𝑎=1 𝑡
costdefinedby𝑑(𝑎,𝑏) foranydistinctpoints𝑎,𝑏 ∈ 𝑋. AsinCFL, thelong-termconstraintenforcesthat
(cid:205)𝑇 𝑡=1𝑐(x𝑡) ≥ 1,where𝑐(x) isalinearandseparablefunctionoftheform𝑐(x) = (cid:205)𝑛 𝑎=1c𝑎𝑥𝑎. Aspreviously,
theplayer’sobjectiveistominimizethetotalcost(hittingplusswitchingcosts)incurredwhilesatisfying
thelong-termconstraint.
Assumptions. In the rest of the paper, we consider an instantiation of online metric allocation with
a long-term constraint on weighted star metrics that is particularly relevant to a wide class of resource
allocationproblems.
Toensurethelong-termconstraintisnon-trivial,wedenoteatleastonepoint𝑎′inthemetricspaceasthe“OFF
state”,wherec𝑎′ = 0and 𝑓𝑎′(𝑥) = 0 ∀𝑡 ∈ [𝑇],∀𝑥 ∈ [0,1]. Forallothercostfunctions,wecarryforwardthe
𝑡
assumptionsthat𝐿 ≤ 𝑑𝑓 𝑡𝑎/𝑑𝑥𝑎 ≤ 𝑈,𝑓 𝑡𝑎(0) = 0 ∀𝑡 ∈ [𝑇]. Wedefine 𝛽 (cid:66) max 𝑎′,𝑎𝑑(𝑎′,𝑎), i.e., themaximum
1Asbriefjustificationfortheboundson𝛽,considerthatafeasiblesolutionmayhaveobjectivevalue𝐿+2𝛽. If𝛽 > 𝑈−𝐿/2,
𝐿+2𝛽 >𝑈,andwearguethattheincurredswitchingcostismoreimportantthanthecostfunctionsaccepted.
2We assume the first time 𝑗′ where (𝑇 −(𝑗′+1))c𝑖 < 1 ∀𝑖 satisfies 𝑗′ ≫ 1, which implies that𝑇 and c are both sized
appropriatelyfortheconstraint. Thisisreasonableforanapplicationsuchascarbon-awareloadshifting,sinceshortdeadlines
(small𝑇)orlowthroughput(smallc𝑖 ∀𝑖)implythatevenofflinesolutionssufferalackofflexibilityinreducingtheoverallcost.
3Givenmetricspace𝑋,considerΔ(𝑋),whichrepresentsthesetofprobabilitymeasuresoverthepointsof𝑋.Since𝑋 isfinite,
wehavethat|𝑋|=𝑛andΔ(𝑋)isdenotedasΔ 𝑛.
4distancebetweentheOFFstateandanyotherstateintheweightedstar,inheritingthesameassumptionthat
𝛽 ∈ [0,𝑈−𝐿/2). Forbrevity,wehenceforthuseMALtorefertotheproblemonweightedstarmetricswith
theassumptionsdescribedabove.
Competitive analysis. Our goal is to design an algorithm that guarantees a small competitive ra-
tio [MMS88; BLS92], i.e., performs nearly as well as the offline optimal solution. Formally, let I ∈ Ω
denote a valid input sequence, where Ω is the set of all feasible inputs for the problem. Let OPT(I)
denote the cost of an optimal offline solution for instance I, and let ALG(I) denote the cost incurred
by running an online algorithm ALG over the same instance. The competitive ratio is then defined as
CR(ALG) (cid:66) max I∈ΩALG(I)/OPT(I) =𝜂,andALGissaidtobe𝜂-competitive. NotethatCR(ALG) isalways
≥ 1,andalower competitiveratioimpliesthattheonlinealgorithmisguaranteedtobecloser totheoffline
optimalsolution.
Learning-augmentedconsistencyandrobustness. Intheemergingliteratureonlearning-augmented
algorithms, competitive analysis is interpreted via the notions of consistency and robustness, introduced
by[LV18;PSK18].
Definition 2.1. Let LALG denote a learning-augmented online algorithm provided with advice denoted by
ADV. Then LALG is said to be𝑏-consistent if it is𝑏-competitive with respect to ADV. Conversely, LALG is𝑟-
robust if it is𝑟-competitive with respect to OPT when given any ADV (i.e., regardless of the performance of
ADV).
AconnectionbetweenCFLandMAL. BelowwestatetwousefulresultsconnectingtheCFLandMAL
settingsthatinfluenceouralgorithmdesignforeachproblem.
Lemma2.2. ForanyMALinstanceonaweightedstarmetric (𝑋,𝑑),thereisacorrespondingCFLinstance
on (R𝑛−1,∥·∥ ℓ 1(w′)) whichpreserves 𝑓 𝑡𝑎(·) ∀𝑡,𝑐(·) ∀𝑎 ∈𝑋,andupperbounds𝑑(𝑎,𝑏), ∀(𝑎,𝑏) ∈𝑋.
LeveragingLemma2.2,thefollowingresultexplicitlyconnectsthecompetitiveresultsoftheCFLand
MALsettings.
Proposition 2.3. Given an algorithm ALG for CFL, any competitive bound for ALG gives an identical com-
petitiveboundforMALwithparameterscorrespondingtotheCFLinstanceconstructedinLemma2.2.
The proofs of both are deferred to Appendix B.3. At a high-level, Proposition 2.3 shows that if ALG
is𝜂-competitiveagainstOPTwhichpaysnoswitchingcost,Lemma2.2impliesitisalso𝜂-competitiveon
MAL. Inthenextsection,ourproposedalgorithmswillbepresentedusingCFLnotation,buttheseresults
providethenecessaryconditionwhichallowsthemtosolveMALaswell.
3 Designing Competitive Algorithms
Inthissection,wepresentourrobustalgorithmdesign. Westartbydiscussingsomeinherentchallenges
in the problem, highlighting reasons why existing algorithms (e.g., for CFC) fail. Next, we introduce a
generalizationofexistingtechniquesfromonlinesearchcalledpseudo-costminimization,whichunderpins
our competitive algorithm, ALG1 (Algorithm 1). Finally, we state (and prove in Appendix B) two bounds,
whichjointlyimplythatALG1achievestheoptimalcompetitiveratioforCFLandMAL.
5Algorithm1Pseudo-costminimizationalgorithm(ALG1)
input: long-termconstraintfunction𝑐(·),distancemetric∥·∥ ℓ 1(w),pseudo-costthresholdfunction𝜙(𝑧)
initialize:𝑧(0) = 0;
whilecostfunction 𝑓 𝑡(·) isrevealedand𝑧(𝑡−1) < 1do
solvepseudo-costminimizationproblem:
∫ 𝑧(𝑡−1)+𝑐(x)
x𝑡 = argmin 𝑓 𝑡(x)+∥x−x𝑡−1∥ ℓ 1(w) − 𝜙(𝑢)𝑑𝑢 (2)
x∈𝑋:𝑐(x)≤1−𝑧(𝑡−1) 𝑧(𝑡−1)
updateutilization𝑧(𝑡) =𝑧(𝑡−1) +𝑐(x𝑡)
Challenges. Canonical algorithms for CFC [CGW18; Sel20; ZJL+21] make decisions that attempt to
minimize (or nearly minimize) the hitting cost of cost functions 𝑓 (·) and switching cost across all time
𝑡
steps.Asdiscussedintheintroduction,thestructureoftheproblemwithalong-termconstraintmeansthat
suchmyopiccost-minimizationalgorithmswillfailingeneral. Toillustratethis,considertheactionsofa
minimizer-drivenalgorithmonanarbitrarysequencewithlength𝑇.Foreach𝑡 <𝑇,thealgorithmchooses
apointatornear0,since0istheminimizerofeach 𝑓 𝑡. However,since𝑐(0) = 0,suchanalgorithmmust
subsequentlysatisfyalloralmostallofthelong-termconstraintduringthecompulsorytrade,incurringan
arbitrarilybadhittingcost.
This challenge motivates an algorithm design that balances between the two extremes of finishing
the long-term constraint “immediately” (i.e., at the first or early time steps), and finishing the long-term
constraint“whenforcedto”(i.e.,duringthecompulsorytrade). Bothextremesresultinapoorcompetitive
ratio. Many algorithms in the online search literature (e.g., online knapsack, OWT) leverage a threshold-
baseddesigntoaddresspreciselythisproblem,asin[ZCL08;SZL+21;LCS+24]. However,suchthreshold-
basedalgorithmsaretraditionallyderivedforsingle-dimensionaldecisionspaceswithnoswitchingcosts.
Inwhatfollows,wedescribeapseudo-costminimizationapproach,whichgeneralizesthethreshold-based
designtooperateinthesettingofCFL.
Algorithmdescription. Recallthat𝑧(𝑡) givesthefractionofthelong-termconstraintsatisfiedattime
𝑡. Building off of the intuition of threshold-based design, we define a function𝜙, which will be used to
computeapseudo-costminimizationproblemcentraltoourrobustalgorithm.
Definition3.1(Pseudo-costthresholdfunction𝜙 forCFL). Foranyutilization𝑧 ∈ [0,1],𝜙 isdefinedas:
𝜙(𝑧) =𝑈 −𝛽 +(𝑈/𝛼 −𝑈 +2𝛽)exp(𝑧/𝛼), (3)
where𝛼 isthecompetitiveratioandisdefinedin(4).
Then our algorithm (Algorithm 1, referred to as ALG1) solves the pseudo-cost minimization problem
definedin(2)toobtainadecisionx𝑡 ateachtimestep. Atahighlevel, theinclusionof𝜙 inthispseudo-
cost problem enforces that, upon arrival of a cost function, the algorithm satisfies “just enough” of the
long-termconstraint. Concretely,thestructureofthe𝜙 functionenforcesthat𝜙(𝑧(𝑡))−𝛽 correspondsto
the “best cost function seen so far”. Then, if a good cost function arrives, the pseudo-cost minimization
problemsolvesforthex𝑡 whichguaranteesacompetitiveratioof𝛼 againstthecurrentestimateofOPT.
Ataglance,itisnotobviousthattheminimizationproblemin(2)istractable;however,inAppendixB.1,
weshowthattheproblemisconvex,implyingthatitcanbesolvedefficiently. InTheorem3.2,westatethe
competitiveresultforALG1. Wediscussthesignificanceoftheresultbelow,andrelegatethefullproofto
AppendixB.2.
6Theorem3.2. ALG1is𝛼-competitiveforCFL,where𝛼 isthesolutionto 𝑈−𝐿−2𝛽 = exp(1/𝛼),givenby
𝑈−𝑈/𝛼−2𝛽
(cid:20) (cid:18)(cid:18)2𝛽 𝐿 (cid:19) (cid:19) 2𝛽 (cid:21)−1
𝛼 (cid:66) 𝑊 + −1 𝑒2 𝑈𝛽 −1 − +1 , (4)
𝑈 𝑈 𝑈
where𝑊 istheLambert𝑊 function[CGH+96].
Intuitively,parametersofCFL(𝐿,𝑈,and 𝛽)appearinthecompetitivebound. WhileresultsforOWT
and CFC are not directly comparable, we discuss connections and the relative order of 𝛼. When 𝛽 →
0, 𝛼 matches the optimal competitive ratio of (cid:2)𝑊 (cid:0) (𝐿/𝑈 −1)𝑒−1(cid:1) +1(cid:3)−1 for the minimization variant of
OWT[LPS08;SLH+21]. Intheintermediatecase(i.e.,when𝛽 ∈ (0,𝑈−𝐿/2)),CFLaddsanewlinear depen-
denceon𝛽 comparedtoOWT. Furthermore,when𝛽 →𝑈−𝐿/2,𝛼 approaches𝑈/𝐿,whichisthecompetitive
ratioachievablebye.g.,amyopiccostminimizationalgorithm. Since𝛼 doesnotfeatureadependenceon
the dimension𝑑 of the vector space, we note a connection with CFC: it is known that “dimension-free”
boundsareachievableinCFCwithstructuralassumptionsonthehittingcost[CGW18;AGG20]thatare
evocativeofourboundedgradientassumptionsinCFL.
ViaProposition2.3,weobtainanimmediatecorollarytoTheorem3.2whichgivesthefollowingcom-
petitive bound when ALG1 is used to solve MAL. The full proof of Corollary 3.3 can be found in Ap-
pendixB.3.
Corollary3.3. ALG1is𝛼-competitiveforMAL.
Onthetightnessofcompetitiveratios. ItisimportanttohighlightthattheboundsinTheorem3.2
and Corollary 3.3 are the first competitive bounds for any variant of convex function chasing or online
metricallocationimbuedwithlong-termconstraints. Anaturalfollow-upquestionconcernswhetherany
online algorithm for CFL (or MAL) can achieve a better competitive bound. In the following, we answer
this question in the negative, showing that ALG1’s competitive ratio is the best that any deterministic
online algorithm for CFL and/or MAL can achieve. We state the result here, and defer the full proof to
AppendixB.4.
Theorem3.4. ThereexistsafamilyofCFLinstancessuchthatanydeterministiconlinealgorithmforCFL
isatleast𝛼-competitive,where𝛼 isasdefinedin(4).
Since ALG1 is𝛼-competitive by Theorem 3.2, this implies that ALG1 achieves the optimal competitive
ratio for CFL. Furthermore, by leveraging Lemma 2.2, this result gives an immediate corollary result in
theMALsettingbyconstructingacorrespondingfamilyofMALinstances,whichforcesanyalgorithmto
achieveacompetitiveratioof𝛼. Westatetheresulthere,deferringthefullprooftoAppendixB.5.
Corollary3.5. TheCFLinstancesinTheorem3.4correspondtoinstancesofMALsuchthatanydeterministic
onlinealgorithmforMALisatleast𝛼-competitive.
As previously, since ALG1 is𝛼-competitive by Corollary 3.3, it achieves the optimal competitive ratio
for MAL. We note that beyond the settings of CFL and MAL considered in this paper, Theorem 3.4 and
Corollary 3.5 are the first lower bound results for convex function chasing and online metric allocation
with long-term constraints, and may thus give useful insight into the achievable competitive bounds for
differentormoregeneralsettingsoftheseproblems.
4 Learning-augmented Algorithms
In this section, we leverage techniques from the growing literature on learning-augmented algorithms to
considerhowuntrustedblack-boxadvice canhelpimprovetheaverage-caseperformanceofanalgorithm
7Algorithm2ConsistencyLimitedPseudo-costminimization(CLIP)
input:
consistencyparameter𝜖,long-termconstraintfunction𝑐(·),pseudo-costthreshold𝜙𝜖(·)
initialize:𝑧(0) = 0; 𝑝(0) = 0; 𝐴(0) = 0; CLIP0 = 0; ADV0 = 0
whilecostfunction 𝑓 𝑡(·) isrevealed,untrustedadvicea𝑡 isrevealed,and𝑧(𝑡−1) < 1do
updateadvicecostADV𝑡 = ADV𝑡−1+𝑓 𝑡(a𝑡)+∥a𝑡−a𝑡−1∥ ℓ 1(w) andadviceutilization𝐴(𝑡) =𝐴(𝑡−1)+𝑐(a𝑡)
solveconstrained pseudo-costminimizationproblem:
∫ 𝑝(𝑡−1)+𝑐(x)
x𝑡 = x∈𝑋:𝑐a (r xg )≤m 1i −n 𝑧(𝑡−1)𝑓𝑡(x)+∥x−x𝑡−1∥ℓ1(w) −
𝑝(𝑡−1)
𝜙𝜖(𝑢)𝑑𝑢 (5)
suchthat
CLIP𝑡−1+𝑓𝑡(x)+∥x−x𝑡−1∥ℓ1(w)+∥x−a𝑡∥ℓ1(w)+∥a𝑡∥ℓ1(w)+(1−𝑧(𝑡−1) −𝑐(x))𝐿+max((𝐴(𝑡) −𝑧(𝑡−1) −𝑐(x)), 0)(𝑈 −𝐿) (6)
≤ (1+𝜖)[ADV𝑡+∥a𝑡∥ℓ1(w)+(1−𝐴(𝑡))𝐿]
updatecostCLIP𝑡 = CLIP𝑡−1+𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥ ℓ 1(w) andutilization𝑧(𝑡) =𝑧(𝑡−1) +𝑐(x𝑡)
solveunconstrained pseudo-costminimizationproblem:
∫ 𝑝(𝑡−1)+𝑐(x)
x¯ 𝑡 = x∈𝑋:𝑐a (r xg )≤m 1i −n 𝑧(𝑡−1)𝑓𝑡(x)+∥x−x𝑡−1∥ℓ1(w) −
𝑝(𝑡−1)
𝜙𝜖(𝑢)𝑑𝑢 (7)
updatepseudo-utilization𝑝(𝑡) =𝑝(𝑡−1) +min(𝑐(x¯ 𝑡),𝑐(x𝑡))
for CFL and MAL while retaining worst-case guarantees. We first consider a sub-optimal “baseline” al-
gorithm that directly combines advice with a robust algorithm such as ALG1. We then propose a unified
algorithmcalledCLIP,whichintegratesadvicemoreefficientlyandachievestheoptimaltrade-offbetween
consistency androbustness(Definition2.1).
Advicemodel. ForaCFLorMALinstanceI ∈ Ω,letADVdenoteuntrustedblack-boxdecisionadvice,
i.e., ADV (cid:66) {a𝑡 ∈ 𝑋 : 𝑡 ∈ [𝑇]}. If the advice is correct, it achieves the optimal objective value (i.e.,
ADV(I) = OPT(I)).
A simple baseline. Lechowicz et al. [LCS+24] show that a straightforward “fixed-ratio” learning-
augmentedapproachworkswellinpracticeforunidimensionalonlinesearchwithswitchingcosts. Here
weshowthatasimilartechnique(playingaconvexcombinationofthesolutionschosenbytheadviceand
arobustalgorithm)achievesboundedbutsub-optimalconsistencyandrobustnessforCFL.
Let ROB (cid:66) {x˜ 𝑡 : 𝑡 ∈ [𝑇]} denote the actions of a robust algorithm for CFL (e.g., ALG1). For any
value𝜖 ∈ (0,𝛼 −1], thefixed-ratioalgorithm(denotedasBaselineforbrevity)setsafixedcombination
factor 𝜆 (cid:66) 𝛼 𝛼− −1− 1𝜖. Then at each time step, Baseline chooses a combination decision according to x𝑡 =
𝜆a𝑡+(1−𝜆)x˜ 𝑡. WepresentconsistencyandrobustnessresultsforBaselinebelow,deferringthefullproof
toAppendixC.1.
Lemma 4.1. Letting ROB denote the actions of ALG1 and setting a parameter 𝜖 ∈ (0,𝛼 − 1], Baseline is
(cid:16) (cid:17)
(1+𝜖)-consistentand (𝑈+2𝛽)/𝐿(𝛼−1−𝜖)+𝛼𝜖 -robustforCFL.
(𝛼−1)
Although this fixed-ratio algorithm verifies that an algorithm for CFL can utilize untrusted advice
to improve performance, it remains an open question of whether the trade-off between consistency and
robustness given in Lemma 4.1 is optimal. Thus, we study whether a learning-augmented algorithm for
CFLcanbedesignedwhichdoesachievetheprovablyoptimalconsistency-robustnesstrade-off.Inthenext
section, we start by considering a more sophisticated method of incorporating advice into an algorithm
design.
8An optimal learning-augmented algorithm. We present CLIP (Consistency-Limited Pseudo-cost
minimization,Algorithm2)whichachievestheoptimaltrade-offbetweenconsistencyandrobustnessfor
CFL. Tostart,forany𝜖 ∈ (0,𝛼−1],wedefineacorrespondingtargetrobustnessfactor𝛾𝜖,whichisdefined
astheuniquepositivesolutiontothefollowing:
𝑈 𝛾𝜖 (cid:18) 𝑈 −𝐿−2𝛽 (cid:19)
𝛾𝜖 =𝜖 + − (𝑈 −𝐿)ln . (8)
𝐿 𝐿 𝑈 −𝑈/𝛾𝜖 −2𝛽
Notethat𝛾𝛼−1 = 𝛼, and𝛾0 = 𝑈/𝐿. Weuse𝛾𝜖 todefineapseudo-costthresholdfunction𝜙𝜖 whichwillbe
usedinaminimizationproblemtochooseadecisionateachstepoftheCLIPalgorithm.
Definition4.2(Pseudo-costthresholdfunction𝜙𝜖). Given𝛾𝜖 from(8),𝜙𝜖(𝑝) for𝑝 ∈ [0,1] isdefinedas:
𝜙𝜖 (𝑝) =𝑈 −𝛽 +(𝑈/𝛾𝜖 −𝑈 +2𝛽)exp(𝑝/𝛾𝜖). (9)
For each time step 𝑡 ∈ [𝑇], we define a pseudo-utilization 𝑝(𝑡) ∈ [0,1], where 𝑝(𝑡) ≤ 𝑧(𝑡) ∀𝑡, and
𝑝(𝑡) describes the fraction of the long-term constraint which been satisfied “robustly” (as defined by the
pseudo-cost)attime𝑡.
ThenCLIP(seeAlgorithm2)solvesaconstrained pseudo-costminimizationproblem(definedin(5))to
obtainadecisionx𝑡 ateachtimestep. TheobjectiveofthisproblemismostlyinheritedfromALG1,butthe
inclusionofaconsistencyconstraint allowstheframeworktoaccommodateuntrustedadviceforbounded
consistencyandrobustness.
The high-level intuition behind this consistency constraint (defined in (6)) is to directly compare the
solutions of CLIP and ADV so far, while “hedging” against worst-case scenarios which may cause CLIP
to violate the desired (1+𝜖)-consistency. We introduce some notation to simplify the expression of the
constraint. WeletCLIP𝑡 denotethecostofCLIPuptotime𝑡,i.e.,CLIP𝑡 (cid:66) (cid:205) 𝜏𝑡 =1𝑓 𝜏(x𝜏)+∥x𝜏 −x𝜏−1∥
ℓ
1(w).
Similarly, weletADV𝑡 (cid:66) (cid:205) 𝜏𝑡 =1𝑓 𝜏(a𝜏) + ∥a𝜏 −a𝜏−1∥
ℓ 1(w)
denotethecostofADVuptotime𝑡. Additionally,
welet𝐴(𝑡) denotetheutilizationofADVattime𝑡,i.e.,𝐴(𝑡) (cid:66) (cid:205) 𝜏𝑡 =1𝑐(a𝜏)
The constraint defined in (6) considers the cost of both CLIP and ADV so far, and the current hitting
and switching cost 𝑓 𝑡(x) + ∥x − x𝑡−1∥
ℓ
1(w), ensuring that (1 + 𝜖)-consistency is preserved. Both sides
of the constraint also include terms which consider the cost of potential future situations. First, ∥x −
a𝑡∥
ℓ 1(w)
+ ∥a𝑡∥
ℓ 1(w)
ensuresthatifCLIPpaysaswitchingcosttofollowADVand/orpaysaswitchingcost
to“switchoff”(moveto0)ine.g.,thenexttimestep,thatcosthasbeenpaidfor“inadvance”. Asx𝑇+1 = 0,
the constraint also charges ADV in advance for the mandatory switching cost at the end of the sequence
(cid:0)
∥a𝑡∥
ℓ
1(w)(cid:1);thisensuresthatthereisalwaysafeasiblesettingofx𝑡.
In the term (cid:0)1−𝐴(𝑡)(cid:1)𝐿, the consistency constraint assumes that ADV can satisfy the rest of the long-
termconstraint atthebest marginalcost𝐿. Respectively, inthe term (1−𝑧(𝑡−1) −𝑐(x))𝐿 +max((𝐴(𝑡) −
𝑧(𝑡−1) −𝑐(x)), 0)(𝑈 −𝐿),theconstraintassumesCLIPcansatisfyupto (cid:0)1−𝐴(𝑡)(cid:1) oftheremaininglong-
term constraint at the best cost 𝐿, but any excess (i.e., (𝐴(𝑡) −𝑧(𝑡))) must be satisfied at the worst cost
𝑈 (e.g.,duringthecompulsorytrade). Thisworst-caseassumptionensuresthatwhenactualhittingcosts
replacetheaboveterms,thedesired (1+𝜖)-consistencyholds.
Ateachstep,CLIPalsosolvesanunconstrained pseudo-costminimizationproblemtoobtainx¯ 𝑡,which
updatesthepseudo-utilization𝑝(𝑡). ThisensuresthatwhenADVhasacceptedacostfunctionwhichwould
notbeacceptedbytheunconstrainedpseudo-costminimization,thethresholdfunction𝜙𝜖 can“startfrom
zero”insubsequenttimesteps.
At a high level, CLIP’s consistency constraint combined with the pseudo-cost minimization gener-
ates decisions which are as robust as possible while preserving consistency. In Theorem 4.3, we state the
consistencyandrobustnessofCLIP;werelegatethefullprooftoAppendixC.2.
9Theorem4.3. Forany𝜖 ∈ [0,𝛼 −1],CLIPis (1+𝜖)-consistentand𝛾𝜖 -robustforCFL(𝛾𝜖 asdefinedin(8)).
The previous result gives an immediate corollary when CLIP is used to solve MAL, which we state
below. ThefullproofofCorollary4.4canbefoundinAppendixC.3.
Corollary4.4. Forany𝜖 ∈ [0,𝛼 −1],CLIPis (1+𝜖)-consistentand𝛾𝜖 -robustforMAL.
Optimal trade-offs between robustness and consistency. Although the trade-off given by CLIP
implies that achieving 1-consistency requires a large robustness bound of 𝑈/𝐿 in the worst-case, in the
followingtheoremweshowthatthisisthebestwecanobtainfromanyconsistentandrobustalgorithm.
Westatetheresultanddiscussitssignificancehere,deferringthefullprooftoAppendixC.4.
Theorem 4.5. Given untrusted advice ADV and𝜖 ∈ (0,𝛼 −1], any (1+𝜖)-consistent learning-augmented
algorithmforCFLisatleast𝛾𝜖 -robust,where𝛾𝜖 isdefinedin(8).
This result implies that CLIP achieves the optimal trade-off between consistency and robustness for
CFL. Furthermore, via Lemma 2.2, this result immediately gives Corollary 4.6, which we state here and
proveinAppendixC.5.
Corollary4.6.
Any(1+𝜖)-consistentlearning-augmentedalgorithmforMALisatleast𝛾𝜖 -robust(𝛾𝜖
defined
by (8)).
As previously, this implies CLIP achieves the optimal consistency-robustness trade-off for MAL. Be-
yondthesettingsofCFLandMAL,thesePareto-optimalityresultsmaygiveusefulinsightintotheachiev-
ableconsistency-robustnesstrade-offsformoregeneralsettings.
5 Numerical Experiments
In this section, we conduct numerical experiments on synthetic CFL instances. We evaluate ALG1 and
CLIP against the offline optimal solution, three heuristics adapted from related work, and the learning-
augmentedBaseline.
Setup. Herewegiveanoverviewofourexperimentsetupandcomparisonalgorithms. Weconstructa
𝑑-dimensional decision space, where𝑑 is picked from the set {5,7,...,21}. The competitive ratio of our
proposed algorithms depends on both 𝑈/𝐿 and 𝛽 = max 𝑖wi, as the switching cost. Hence, we evalu-
ate their performance over the range of these parameters. We set different cost fluctuation ratios𝑈/𝐿 ∈
{50,150,...,1250} by setting 𝐿 and𝑈 accordingly, and 𝛽 is picked from the set 𝛽 ∈ {0,5,...,𝑈/2.5}. We
also set a parameter𝜎 ∈ {0,10,...,𝑈/2}, which controls the dimension-wise variability of generated cost
functions 𝑓 𝑡. Acrossallexperiments,𝑐(x) = ∥x∥1.
For a given setting of𝑑,𝑈/𝐿, and 𝛽, we generate 1,000 random instances as follows. First, each term
of the weight vector w for the weighted ℓ 1 norm is drawn randomly from the uniform distribution on
[0,𝛽]. Next, the time horizon𝑇 is generated randomly from a uniform distribution on [6,24]. For each
time 𝑡 ∈ [𝑇], a cost function is generated as follows: Let 𝑓 𝑡(x) = f 𝑡⊺ x, where f𝑡 is a𝑑-dimensional cost
vector. Togeneratef𝑡,wefirstdraw 𝜇
𝑡
fromtheuniformdistributionon [𝐿,𝑈],andthendraweachterm
of f𝑡 from a normal distribution centered at 𝜇 𝑡 with standard deviation𝜎 (i.e., f 𝑡𝑖 ∼ N(𝜇 𝑡,𝜎)). Any terms
whichareoutsidetheassumedinterval [𝐿,𝑈] (i.e. f𝑖 < 𝐿 orf𝑖 >𝑈)aretruncatedappropriately. Foreach
𝑡 𝑡
instance, we report the empirical competitive ratios as the evaluation metric, comparing the tested algo-
rithmsagainstanofflineoptimalbenchmark. Wegiveresultsfortheaverageempiricalcompetitiveratio
in the main body, with supplemental results for the 95th percentile (“worst-case”) empirical competitive
ratioinAppendixA.1.
10Inthesettingwithadvice,weconstructsimulatedadviceasfollows:Let𝜉 ∈ [0,1]denoteanadversarial
factor. When 𝜉 = 0, ADV gives the optimal solution, and when 𝜉 = 1, ADV is fully adversarial. Formally,
letting{x★
𝑡
:𝑡 ∈ [𝑇]}denotethedecisionsmadebyanoptimalsolution,andletting{x˘
𝑡
:𝑡 ∈ [𝑇]}represent
thedecisionsmadebyasolutionwhichmaximizestheobjective(ratherthanminimizingit),wehavethat
ADV = {(1−𝜉)x★ 𝑡 +𝜉x˘ 𝑡 :𝑡 ∈ [𝑇]}. Wenotethatalthough{x˘ 𝑡 :𝑡 ∈ [𝑇]}isadversarialfromtheperspective
oftheobjective,itisstillafeasiblesolutionfortheproblem(i.e.,itsatisfiesthelong-termconstraint).
Comparison algorithms. We use CVXPY [DB16] to compute the offline optimal solution for each
instanceusingaconvexoptimizationsolverwithaccesstoallcostfunctionsinadvance. Thisprovidesthe
empirical competitive ratio for each algorithm. We consider three online heuristic techniques based on
theliteratureforrelatedproblems. Thefirsttechniqueistermed“agnostic”,whichchoosestheminimum
dimension of the cost function in the first time step𝑡 = 1 (i.e.,𝑘 = argmin 𝑖∈[𝑑]c𝑖 1), sets x𝑘
1
= 1, and x𝑡 =
0∀𝑡 > 1. Thesecondtechniqueistermed“movetominimizer”,whichtakesinspirationfromalgorithms
for CFC [ZJL+21] and satisfies 1/𝑇 fraction of the long-term constraint at each time step by moving to
the minimum dimension of each cost function. Formally, at each time step𝑡, letting𝑘 𝑡 = argmin 𝑖∈[𝑑]c𝑖 𝑡,
“movetominimizer”setsx𝑘 𝑡 = 1/𝑇.Finally,thethirdtechniqueistermed“simplethreshold”,whichtakes
𝑡 √
inspiration from algorithms for online search [EFK+01]. This algorithm sets a fixed threshold𝜓 = 𝑈𝐿,
and completes the long-term constraint at the first time step and dimension where the hitting cost does
not exceed𝜓. Formally, at the first time step 𝜏 satisfying ∃ 𝑘 ∈ [𝑑] : f𝑘 ≤ 𝜓, “simple threshold” sets
𝜏
x𝑘 = 1. Importantly,noneoftheseheuristicsareaccompaniedbytraditionalcompetitiveguarantees,since
𝜏
ourworkisthefirsttoconsiderCFL. Inthesettingwithadvice,wecompareourproposedCLIPlearning-
augmented algorithm against the Baseline learning-augmented algorithm described in Section 4 (e.g.,
Lemma4.1).
Experimental results. Figure 1 summa-
rizes the main results for ALG1, the compari- 1.0 20 baseline[ =10]
sonalgorithms,andonesettingofCLIP(𝜖 = 2) 0.8 15 b ba as se el li in ne e[ [ = =5 2] ]
CLIP[ =10] in a CDF plot of the empirical competitive ra- 0.6 CLIP[ =5]
ALG1 10 ADV
tios across several experiments. Here we fix 0.4 agnostic
𝑈/𝐿 = 250, 𝜉 = 0, 𝜎 = 50, while varying 0.2 s mim ovp ele t oth mre is nh imol id zer 5
𝛽 and 𝑑. ALG1 outperforms in both average- 0.0 CLIP[ =2] 0
0 10 20 30 40 0.0 0.1 0.2 0.3 0.4 0.5
case and worst-case performance, improving empirical competitive ratio
on the closest “simple threshold” by an aver- Figure1: CDFsofempirical Figure2: Varyingadversar-
ageof18.2%,andoutperforming“agnostic”and competitive ratios for vari- ialfactor𝜉,with𝑈/𝐿=250,𝛽
“move to minimizer” by averages of 56.1% and ousalgorithms. =50,𝑑 =5,and𝜎 =50.
71.5%, respectively. With correct advice, CLIP
seessignificantperformancegainseverywhere.
In Figure 3-6, we investigate the impact of parameters on the average empirical competitive ratio
for each algorithm. In Appendix A.1, we give corresponding plots for the 95th percentile (“worst-case”)
results. Figure 3 plots competitive ratios for different values of𝑈/𝐿. We fix 𝛽 = 𝑈/5,𝑑 = 5,𝜉 = 0,𝜎 = 𝑈/5,
whilevarying𝑈/𝐿. Sincethereisadependenceon𝑈/𝐿inourcompetitiveresults,theperformanceofALG1
degrades as𝑈/𝐿 grows, albeit at a favorable pace compared to the heuristics. Figure 4 plots competitive
ratiosfordifferentvaluesof𝛽. Wefix𝑈/𝐿 = 250,𝑑 = 5,𝜉 = 0,𝜎 = 50. As𝛽 grows,the“agnostic”and“move
tominimizer”heuristicsimprovebecausetheswitchingcostpaidbyOPTgrows.
InFigure5,weplotcompetitiveratiosfordifferentvaluesof𝑑. Wefix𝑈/𝐿 = 250,𝛽 = 50,𝜉 = 0,𝜎 = 50,
whilevarying𝑑. As𝑑 grows,ALG1andCLIP’sperformancedegradesslowercomparedtotheheuristics,as
predictedbytheirdimension-freetheoreticalbounds. Finally,Figure6plotscompetitiveratiosfordifferent
11
ytisned
evitalumuc
laciripme
.gva
oitar
evititepmoc20 20 20 20
15 15 15 15
10 10 10 10
5 5 5 5
0 0 0 0
200 400 600 800 1000 0 20 40 60 80 100 5 10 15 20 0 20 40 60 80 100 120
Figure 3: VaU r/L ying 𝑈/𝐿, Figure4: Varying𝛽,with Figure 5: Varyding𝑑 with Figure6: Varying𝜎,with
with𝛽 =𝑈/5,𝑑 = 5,𝜉 = 0, 𝑈/𝐿 = 250,𝑑 = 5,𝜉 = 0, 𝛽 = 50,𝑈/𝐿 = 250,𝜎 = 50, 𝛽 = 50,𝑈/𝐿 = 250,𝑑 = 5,
and𝜎 =𝑈/5. and𝜎 = 50. and𝜉=0. and𝜉 =0.
values of 𝜎. We fix 𝑈/𝐿 = 250,𝛽 = 50,𝑑 = 5,𝜉 = 0, while varying 𝜎. As cost functions become more
variable, the performance of all algorithms degrades, with the exception of CLIP. There is a plateau as𝜎
grows,becausealarge𝜎 impliesthatmoretermsineachf𝑡 mustbetruncatedtotheinterval [𝐿,𝑈].
Figure2plotstheeffectofpredictionerroronthelearning-augmentedalgorithmsCLIPandBaseline.
Wetestseveralvaluesof𝜉 ∈ [0,1/2] (recallthat𝜉 = 0recoverscorrectadvice),whilefixing𝑈/𝐿 = 250,𝛽 =
50,𝑑 = 5, and𝜎 = 50. We also test Baseline and CLIP for several values of𝜖 ∈ {2,5,10} (note that ADV
correspondstoBaselineandCLIPwith𝜖 = 0). Notably,wefindthatCLIPsignificantlyoutperformsthe
Baseline algorithm as 𝜉 grows, showing an average improvement of 60.8% when 𝜉 > 0.1. This result
impliesthatCLIPismoreempiricallyrobusttopredictionerrorsthanthesimplefixedratiotechniqueof
Baseline.
6 Conclusion
Westudyonlinemetricproblemswithlong-termconstraints,motivatedbyemergingproblemsinsustain-
ability. These are the first such problems to concurrently incorporate multidimensional decision spaces,
switchingcosts,andlong-termdemandconstraints. OurmainresultsinstantiatetheCFLandMALprob-
lemstowardsamotivatingapplication. Wedesigncompetitiveandlearning-augmentedalgorithms,show
thattheirperformanceboundsaretight,andvalidatetheminnumericalexperiments. Severalinteresting
openquestionsarepromptedbyourwork. Specifically,(i)whatisachievableinnon-ℓ vectorspacese.g.,
1
theEuclideansetting,and(ii)canourresultsforMALinformalgorithmdesignsfore.g.,treemetrics,and
byextension,arbitrarymetricspaces?
References
[AGG20] C. J. Argue, Anupam Gupta, and Guru Guruganesh. “Dimension-Free Bounds for Chasing
ConvexFunctions”.In:ProceedingsofThirtyThirdConferenceonLearningTheory.PMLR,July
2020,pp.219–241.(Visitedon02/04/2022).
[ALK+23] Bilge Acun, Benjamin Lee, Fiodar Kazhamiaka, Kiwan Maeng, Udit Gupta, Manoj Chakkar-
avarthy,DavidBrooks,andCarole-JeanWu.“CarbonExplorer:AHolisticFrameworkforDe-
signingCarbonAwareDatacenters”.In:Proceedingsofthe28thACMInternationalConference
on Architectural Support for Programming Languages and Operating Systems, Volume 2. ASP-
LOS2023.Vancouver,BC,Canada:AssociationforComputingMachinery,2023,pp.118–132.
isbn: 9781450399166. doi: 10.1145/3575693.3575754. url: https://doi.org/10.1145/
3575693.3575754.
12
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc
laciripme
.gva
oitar
evititepmoc[BC22] Nikhil Bansal and Christian Coester. “Online Metric Allocation and Time-Varying Regular-
ization”.In:30thAnnualEuropeanSymposiumonAlgorithms(ESA2022).Ed.byShiriChechik,
GonzaloNavarro,EvaRotenberg,andGrzegorzHerman.Vol.244.LeibnizInternationalPro-
ceedingsinInformatics(LIPIcs).Dagstuhl,Germany:SchlossDagstuhl–Leibniz-Zentrumfür
Informatik, 2022, 13:1–13:13. isbn: 978-3-95977-247-1. doi: 10.4230/LIPIcs.ESA.2022.13.
url:https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ESA.2022.13.
[BCL+21] Sébastien Bubeck, Michael B. Cohen, James R. Lee, and Yin Tat Lee. “Metrical Task Systems
on Trees via Mirror Descent and Unfair Gluing”. In: SIAM Journal on Computing 50.3 (Jan.
2021),pp.909–923.issn:0097-5397,1095-7111.doi:10.1137/19M1237879.
[BCR23] Sébastien Bubeck, Christian Coester, and Yuval Rabani. “The Randomized $k$-Server Con-
jecture Is False!” In: Proceedings of the 55th Annual ACM Symposium on Theory of Comput-
ing(STOC2023).STOC2023.Orlando,FL,USA:AssociationforComputingMachinery,2023,
pp.581–594.isbn:9781450399135.doi:10.1145/3564246.3585132.url:https://doi.org/
10.1145/3564246.3585132.
[BGH+21] Noman Bashir, Tian Guo, Mohammad Hajiesmaili, David Irwin, Prashant Shenoy, Ramesh
Sitaraman,AbelSouza,andAdamWierman.“EnablingSustainableClouds:TheCaseforVir-
tualizing the Energy System”. In: Proceedings of the ACM Symposium on Cloud Computing.
SoCC’21.Seattle,WA,USA:AssociationforComputingMachinery,2021,pp.350–358.isbn:
9781450386388. doi: 10.1145/3472883.3487009. url: https://doi.org/10.1145/
3472883.3487009.
[BKL+19] Sébastien Bubeck, Bo’az Klartag, Yin Tat Lee, Yuanzhi Li, and Mark Sellke. “Chasing Nested
ConvexBodiesNearlyOptimally”.In:Proceedingsofthe2020ACM-SIAMSymposiumonDis-
crete Algorithms (SODA). Proceedings. Society for Industrial and Applied Mathematics, Dec.
2019,pp.1496–1508.doi:10.1137/1.9781611975994.91.
[BLS92] AllanBorodin,NathanLinial,andMichaelE.Saks.“AnOptimalOn-LineAlgorithmforMet-
rical Task System”. In: J. ACM 39.4 (Oct. 1992), pp. 745–763. issn: 0004-5411. doi: 10.1145/
146585.146588.url:https://doi.org/10.1145/146585.146588.
[CBS+22] Kai-WenCheng,YuexinBian,YuanyuanShi,andYizeChen.“Carbon-AwareEVCharging”.In:
2022 IEEE International Conference on Communications, Control, and Computing Technologies
for Smart Grids (SmartGridComm). 2022, pp. 186–192. doi: 10.1109/SmartGridComm52983.
2022.9960988.
[CGH+96] RobertMCorless,GastonHGonnet,DavidEGHare,DavidJJeffrey,andDonaldEKnuth.“On
theLambertWfunction”.In:AdvancesinComputationalmathematics5(1996),pp.329–359.
[CGW18] NiangJunChen,GautamGoel,andAdamWierman.“SmoothedOnlineConvexOptimization
in High Dimensions via Online Balanced Descent”. In: Proceedings of the 31st Conference On
LearningTheory.PMLR,July2018,pp.1574–1594.
[CHW22] Nicolas Christianson, Tinashe Handina, and Adam Wierman. “Chasing Convex Bodies and
FunctionswithBlack-BoxAdvice”.In:Proceedingsofthe35thConferenceonLearningTheory.
Vol.178.PMLR,July2022,pp.867–908.
[CSW23] Nicolas Christianson, Junxuan Shen, and Adam Wierman. “Optimal robustness-consistency
tradeoffsforlearning-augmentedmetricaltasksystems”.In:InternationalConferenceonArti-
ficialIntelligenceandStatistics.2023.
[DB16] Steven Diamond and Stephen Boyd. “CVXPY: A Python-embedded modeling language for
convexoptimization”.In:JournalofMachineLearningResearch17.83(2016),pp.1–5.
13[EFK+01] Ran El-Yaniv, Amos Fiat, Richard M. Karp, and G. Turpin. “Optimal Search and One-Way
Trading Online Algorithms”. In: Algorithmica 30.1 (May 2001), pp. 101–139. doi: 10.1007/
s00453-001-0003-0.url:https://doi.org/10.1007/s00453-001-0003-0.
[FL93] Joel Friedman and Nathan Linial. “On convex body chasing”. In: Discrete & Computational
Geometry 9.3(Mar.1993),pp.293–321.doi:10.1007/bf02189324.url:https://doi.org/
10.1007/bf02189324.
[HLB+23] WalidA.Hanafy,QianlinLiang,NomanBashir,DavidIrwin,andPrashantShenoy.“Carbon-
Scaler:LeveragingCloudWorkloadElasticityforOptimizingCarbon-Efficiency”.In:Proceed-
ings of the ACM on Measurement and Analysis of Computing Systems 7.3 (Dec. 2023). arXiv:
2302.08681[cs.DC].
[Kou09] EliasKoutsoupias.“Thek-serverproblem”.In:ComputerScienceReview3.2(May2009),pp.105–
118.doi:10.1016/j.cosrev.2009.04.002.url: https://doi.org/10.1016/j.cosrev.
2009.04.002.
[LCS+24] AdamLechowicz,NicolasChristianson,BoSun,NomanBashir,MohammadHajiesmaili,Adam
Wierman,andPrashantShenoy.“OnlineConversionwithSwitchingCosts:RobustandLearning-
augmented Algorithms”. In: Proceedings of the 2024 SIGMETRICS/Performance Joint Interna-
tional Conference on Measurement and Modeling of Computer Systems. Venice, Italy: Associa-
tionforComputingMachinery,June2024.arXiv:2310.20598[cs.DS].
[LCZ+23] AdamLechowicz,NicolasChristianson,JinhangZuo,NomanBashir,MohammadHajiesmaili,
AdamWierman,andPrashantShenoy.“TheOnlinePauseandResumeProblem:OptimalAl-
gorithmsandAnApplicationtoCarbon-AwareLoadShifting”.In:ProceedingsoftheACMon
MeasurementandAnalysisofComputingSystems7.3(Dec.2023).arXiv:2303.17551[cs.DS].
[LPS08] Julian Lorenz, Konstantinos Panagiotou, and Angelika Steger. “Optimal Algorithms for k-
Search with Application in Option Pricing”. In: Algorithmica 55.2 (Aug. 2008), pp. 311–328.
doi:10.1007/s00453-008-9217-8.
[LSH+24] Russell Lee, Bo Sun, Mohammad Hajiesmaili, and John C. S. Lui. “Online Search with Pre-
dictions: Pareto-optimal Algorithm and its Applications in Energy Markets”. In: Proceedings
of the 15th ACM International Conference on Future Energy Systems. e-Energy ’24. Singapore,
Singapore:AssociationforComputingMachinery,June2024.
[LV18] ThodorisLykourisandSergeiVassilvtiskii.“CompetitiveCachingwithMachineLearnedAd-
vice”.In:Proceedingsofthe35thInternationalConferenceonMachineLearning.Ed.byJennifer
DyandAndreasKrause.Vol.80.ProceedingsofMachineLearningResearch.PMLR,July2018,
pp.3296–3305.url:https://proceedings.mlr.press/v80/lykouris18a.html.
[MAS14] EstherMohr,IftikharAhmad,andGünterSchmidt.“Onlinealgorithmsforconversionprob-
lems:Asurvey”.In:SurveysinOperationsResearchandManagementScience 19.2(July2014),
pp. 87–104. doi: 10.1016/j.sorms.2014.08.001. url: https://doi.org/10.1016/j.
sorms.2014.08.001.
[MMS88] MarkManasse,LyleMcGeoch,andDanielSleator.“CompetitiveAlgorithmsforOn-LineProb-
lems”.In:ProceedingsoftheTwentiethAnnualACMSymposiumonTheoryofComputing.STOC
’88. Chicago, Illinois, USA: Association for Computing Machinery, 1988, pp. 322–333. isbn:
0897912640.doi:10.1145/62212.62243.
[MPF91] DragoslavS.Mitrinovic,JosipE.Pečarić,andA.M.Fink.InequalitiesInvolvingFunctionsand
TheirIntegralsandDerivatives.Vol.53.SpringerScience&BusinessMedia,1991.
14[PSK18] ManishPurohit,ZoyaSvitkina,andRaviKumar.“ImprovingOnlineAlgorithmsviaMLPre-
dictions”.In:AdvancesinNeuralInformationProcessingSystems.Ed.byS.Bengio,H.Wallach,
H.Larochelle,K.Grauman,N.Cesa-Bianchi,andR.Garnett.Vol.31.CurranAssociates,Inc.,
2018.
[RKS+22] AnaRadovanovic,RossKoningstein,IanSchneider,BokanChen,AlexandreDuarte,BinzRoy,
DiyueXiao,MayaHaridasan,PatrickHung,NickCare,etal.“Carbon-AwareComputingfor
Datacenters”.In:IEEETransactionsonPowerSystems(2022).
[Sel20] Mark Sellke. “Chasing Convex Bodies Optimally”. In: Proceedings of the Thirty-First Annual
ACM-SIAM Symposium on Discrete Algorithms. SODA ’20. USA: Society for Industrial and
AppliedMathematics,Jan.2020,pp.1509–1518.
[SLH+21] Bo Sun, Russell Lee, Mohammad Hajiesmaili, Adam Wierman, and Danny Tsang. “Pareto-
OptimalLearning-AugmentedAlgorithmsforOnlineConversionProblems”.In:Advancesin
Neural Information Processing Systems. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S.
Liang,andJ.WortmanVaughan.Vol.34.CurranAssociates,Inc.,2021,pp.10339–10350.
[SZL+21] Bo Sun, Ali Zeynali, Tongxin Li, Mohammad Hajiesmaili, Adam Wierman, and Danny H.K.
Tsang.“CompetitiveAlgorithmsfortheOnlineMultipleKnapsackProblemwithApplication
to Electric Vehicle Charging”. In: Proceedings of the ACM on Measurement and Analysis of
Computing Systems 4.3 (June 2021). doi: 10.1145/3428336. url: https://doi.org/10.
1145/3428336.
[WBS+21] Philipp Wiesner, Ilja Behnke, Dominik Scheinert, Kordian Gontarska, and Lauritz Thamsen.
“Let’sWaitAWhile:HowTemporalWorkloadShiftingCanReduceCarbonEmissionsinthe
Cloud”.In:Proceedingsofthe22ndInternationalMiddlewareConference.NewYork,NY,USA:
AssociationforComputingMachinery,2021,pp.260–272.doi:10.1145/3464298.3493399.
[ZCL08] YunhongZhou,DeeparnabChakrabarty,andRajanLukose.“BudgetConstrainedBiddingin
Keyword Auctions and Online Knapsack Problems”. In: Lecture Notes in Computer Science.
SpringerBerlinHeidelberg,2008,pp.566–576.
[ZJL+21] Lijun Zhang, Wei Jiang, Shiyin Lu, and Tianbao Yang. Revisiting Smoothed Online Learning.
2021.arXiv:2102.06933[cs.LG].url:https://arxiv.org/abs/2102.06933.
15Appendix
A Numerical Experiments (continued)
Inthissection,wegivesupplementalresultsexaminingthe95thpercentile(“worst-case”)empiricalcom-
petitiveratioresults,followingthesamegeneralstructureasinthemainbody.
100 100 100 100
75 75 75 75
50 50 50 50
25 25 25 25
0 200 400 600 800 1000 0 0 20 40 60 80 100 0 5.0 7.5 10.0 12 d.5 15.0 17.5 20.0 0 0 25 50 75 100 125
Figure 7: VarU/yLing 𝑈/𝐿, Figure8: Varying𝛽,with Figure 9: Varying𝑑 with Figure 10: Varying 𝜎,
with𝛽 =𝑈/5,𝑑 = 5,𝜉 = 0, 𝑈/𝐿 = 250,𝑑 = 5,𝜉 = 0, 𝛽 = 50,𝑈/𝐿 = 250,𝜎 = 50, with𝛽 =50,𝑈/𝐿=250,𝑑 =
and𝜎 =𝑈/5. and𝜎 = 50. and𝜉=0. 5,and𝜉 =0.
A.1 SupplementalResults
TocomplementtheresultsfortheaverageempiricalcompetitiveratioshowninSection5,inthissection
weplotthe95thpercentileempiricalcompetitiveratiosforeachtestedalgorithm, whichprimarilyserve
to show that the improved performance of our proposed algorithm holds in both average-case and tail
(“worst-case”)scenarios.
In Figure 7-10, we investigate the impact of different parameters on the performance of each algo-
rithm. In Figure 7, we plot 95th percentile empirical competitiveness for different values of𝑈/𝐿 – in this
experiment, we fix 𝛽 = 𝑈/5,𝑑 = 5,𝜉 = 0, and 𝜎 = 𝑈/5, while varying𝑈/𝐿 ∈ {50,...,1250}. As observed
in the average competitive ratio plot (Figure 3), the performance of ALG1 degrades as 𝑈/𝐿 grows, albeit
at a favorable pace compared to the comparison algorithms. Figure 8 plots the 95th percentile empirical
competitiveness for different values of 𝛽 – in this experiment, we fix𝑈/𝐿 = 250,𝑑 = 5,𝜉 = 0, and𝜎 = 50.
Aspreviouslyintheaveragecompetitiveresults(Figure4),“agnostic”and“movetominimizer”heuristics
performbetterwhen𝛽 grows,becausetheswitchingcostpaidbytheoptimalsolutiongrowsaswell.
InFigure9,weplotthe95thpercentileempiricalcompetitivenessfor
differentvaluesof𝑑 –inthisexperiment,wefix𝑈/𝐿 = 250,𝛽 = 50,𝜉 = 0,
and𝜎 = 50, while varying𝑑. Mirroring the previous results (Figure 5), 100 baseline[ =10]
ALG1 and CLIP’s competitive performance degrades slower as𝑑 grows baseline[ =5]
75 baseline[ =2]
comparedtothecomparisonheuristics,aspredictedbytheirdimension- CLIP[ =10]
CLIP[ =5]
free theoretical bounds. Finally, Figure 10 plots the 95th percentile em- 50 ADV
piricalcompetitivenessfordifferentvaluesof𝜎,whichisthedimension-
25
wisevariabilityofeachcostfunction. Herewefix𝑈/𝐿 = 250,𝛽 = 50,𝑑 =
5, and 𝜉 = 0, while varying 𝜎 ∈ {0,...,𝑈/2}. Intuitively, as cost func- 0 0.0 0.1 0.2 0.3 0.4 0.5
tions become more variable, the competitive ratios of all tested algo- Figure 11: Varying adversarial
rithmsdegrade,withtheexceptionofourlearning-augmentedalgorithm factor𝜉,with𝑈/𝐿=250,𝛽=50,𝑑
CLIP. This degradation plateaus as𝜎 grows, as a large standard devia- =5,𝜎 =50.
tion forces more of the terms of each cost vector c𝑡 to be truncated to
theinterval [𝐿,𝑈].
In Figure 11, we plot the 95th percentile empirical competitive ratio companion to Figure 2, which
measures the effect of prediction error on the learning-augmented algorithms CLIP and Baseline. We
16
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoc
laciripme
eli%
ht59
oitar
evititepmoctestseveralvaluesof𝜉 ∈ [0,1],theadversarialfactor(recallthat𝜉 = 0impliestheadviceiscorrect),while
fixing𝑈/𝐿 = 250,𝛽 = 50,𝑑 = 5,𝜎 = 50. WetestBaselineandCLIPforseveralvaluesof𝜖 ∈ {2,5,10}(note
that ADV corresponds to running either Baseline or CLIP with𝜖 = 0). Notably, in these 95th percentile
“worst-case”results,wefindthatCLIPcontinuestosignificantlyoutperformstheBaselinealgorithmas
𝜉 grows,furthervalidatingthatCLIPismoreempiricallyrobusttopredictionerrorsthanthesimplefixed
ratiotechniqueofBaseline.
B Proofs for Section 3 (Competitive Algorithms)
B.1 Convexityofthepseudo-costminimizationprobleminALG1
In this section, we show that the pseudo-cost minimization problem central to the design of ALG1 is a
convexminimizationproblem,implyingthatitcanbesolvedefficiently.
Defineℎ 𝑡(x) : 𝑡 ∈ [𝑇] to represent the pseudo-cost minimization problem for a single arbitrary time
step:
∫ 𝑧(𝑡−1)+𝑐(x)
ℎ 𝑡(·) = 𝑓 𝑡(x)+𝑑(x,x𝑡−1)− 𝜙(𝑢)𝑑𝑢. (10)
𝑧(𝑡−1)
TheoremB.1. UndertheassumptionsoftheCFLandMALproblemsettings,ℎ 𝑡(·) isalwaysconvex.
Proof. Weprovetheabovestatementbycontradiction.
Bydefinition,weknowthatthesumoftwoconvexfunctionsgivesaconvexfunction. Sincewehave
that𝑑(x,x′)isdefinedassomenorm,bydefinitionandbyobservingthatx′isfixed,𝑑(x,x′)isconvex. We
havealsoassumedaspartoftheproblemsettingthateach 𝑓 𝑡(x) isconvex. Thus, 𝑓 𝑡(x) +𝑑(x,x′) mustbe
convex.
We turn our attention to the term
−∫𝑧(𝑡−1)+𝑐(x)𝜙(𝑢)𝑑𝑢.
Let 𝑘(𝑐(x)) =
∫𝑧(𝑡−1)+𝑐(x)𝜙(𝑢)𝑑𝑢.
By the
𝑧(𝑡−1) 𝑧(𝑡−1)
fundamentaltheoremofcalculus,∇𝑘(𝑐(x)) =𝜙(𝑧(𝑡−1) +𝑐(x))∇𝑐(x)
Let𝑔(𝑐(x)) = 𝜙(𝑧(𝑡−1) +𝑐(x)). Then ∇2𝑘(𝑐(x)) = ∇2𝑐(x)𝑘(𝑐(x)) +∇𝑐(x)𝑔′(𝑐(x))∇𝑐(x)⊺. Since𝑐(x)
is piecewise linear (CFL and MAL both assume it is linear), we know that ∇2𝑐(x)𝑔(𝑐(x)) = 0. Since𝜙 is
monotonicallydecreasingontheinterval[0,1],weknowthat𝑔′(𝑐(x)) < 0,andthus∇𝑐(x)𝑔′(𝑐(x))∇𝑐(x)⊺
isnegativesemidefinite. Thisimpliesthat𝑘(𝑐(x)) isconcaveinx.
Sincethenegationofaconcavefunctionisconvex,thiscausesacontradiction,becausethesumoftwo
convexfunctionsgivesaconvexfunction.
Thus,ℎ 𝑡(·) = 𝑓 𝑡(x) +𝑑(x,x𝑡−1)
−∫ 𝑧𝑧 (𝑡( −𝑡− 1)1)+𝑐(x)𝜙(𝑢)𝑑𝑢
is always convex under the assumptions ofCFL
andMAL. □
By showing thatℎ 𝑡(·) is convex, it follows that the pseudo-cost minimization (2) in ALG1 is a convex
minimizationproblem(i.e.,itcanbesolvedefficientlyusingnumericalmethods).
B.2 ProofofTheorem3.2
Inthissection,weproveTheorem3.2,whichshowsthat𝛼 asgivenby(4)isanupperboundontheworst-
casecompetitiveratioofALG1(givenbyAlgorithm1)fortheCFLproblem.
ProofofTheorem3.2. Let𝑧(𝑗) = (cid:205) 𝑡∈[𝑇]𝑐(x𝑡) denote the fraction of the long-term constraint satisfied by
ALG1beforethecompulsorytradeonanarbitraryCFLinstanceI ∈ Ω. Alsonotethat𝑧(𝑡) = (cid:205) 𝑚∈[𝑡]𝑐(x𝑚)
isnon-decreasingover𝑛.
LemmaB.2. TheofflineoptimalsolutionOPT(I)foranyCFLinstanceI ∈ Ωislowerboundedby𝜙(𝑧(𝑗))−𝛽.
17Proof of Lemma B.2. We prove this lemma by contradiction. Note that the offline optimum will stay
at 0 whenever possible, and satisfy the long-term constraint using the cost functions with the minimum
gradient(i.e.,thebestmarginalcost). AssumethatOPT(I) <𝜙(𝑧(𝑗))−𝛽,andthat𝑧(𝑗) < 1(implyingthat
OPT(I) > 𝐿).
Recall that any cost function 𝑓 𝑡(·) : 𝑋 → R is minimized exactly at 0, since 𝑓 𝑡(0) = 0 ∀𝑡 ∈ [𝑇]. By
convexityofthecostfunctions,thisimpliesthatthegradientofsomecostfunction𝑓 issimilarlyminimized
𝑡
atthepoint0,andthusthebestmarginalcost for𝑓
𝑡
canbeobtainedbytakinganinfinitesimallysmallstep
awayfrom0inatleastonedirection,whichwedenote(withoutlossofgenerality)as𝑖 ∈ [𝑑]. Forbrevity,
wedenotethisbestmarginalcostin 𝑓 by [∇𝑓 ]𝑖.
𝑡 𝑡
TheassumptionthatOPT(I) <𝜙(𝑧(𝑗))−𝛽 impliesthatinstanceI mustcontainacostfunction 𝑓 𝑚(·)
atsomearbitrarytimestep𝑚 (𝑚 ∈ [𝑇])whichsatisfies [∇𝑓 ]𝑖 <𝜙(𝑧(𝑗))−𝛽 foranydimension𝑖 ∈ [𝑑].
𝑚
Priorwork[LPS08;SZL+21]hasshownthattheworst-caseforonlinesearchproblemswithlong-term
demandconstraintsoccurswhencostfunctionsarriveonlineindescendingorder,sowehenceforthadopt
thisassumption. Recallthatateachtimestep,ALG1solvesthepseudo-costminimizationproblemdefined
in(2). Withoutlossofgenerality,assumethat𝑧(𝑚−1) =𝑧(𝑗),i.e. thecostfunction 𝑓 𝑚(·) arriveswhenALG1
hasalreadyreacheditsfinalutilization(beforethecompulsorytrade).Thisimpliesthatx𝑚 = 0,andfurther
that𝑐(x𝑚) = 0. This implies that 𝑓 𝑚(x) + ∥x−x𝑚−1∥ ℓ 1(w) >
∫ 𝑧𝑧 (𝑚(𝑚 −− 1)1)+𝑐(x)𝜙(𝑢)𝑑𝑢,
since the pseudo-cost
minimizationproblemshouldbeminimizedwhenALG1setsx𝑚 = 0.
Thepseudo-costminimizationproblemattimestep𝑚 canbeexpressedasfollows:
∫ 𝑧(𝑚−1)+𝑐(x)
x𝑚 = argmin 𝑓 𝑚(x)+∥x−x𝑚−1∥ ℓ 1(w) − 𝜙(𝑢)𝑑𝑢.
x∈R𝑑:𝑐(x)≤1−𝑧(𝑚−1) 𝑧(𝑚−1)
Wenotethat∥x−x𝑚−1∥
ℓ 1(w)
isupperboundedby𝛽(𝑧(𝑚−1)+𝑐(x)),sinceintheworstcase,theprevious
online decision x𝑚−1 built up all of ALG1’s utilization (𝑧(𝑚−1)) so far, and in the next step it will have to
switchdimensionstorampuptox.
Since the function 𝜙 is monotonically decreasing on 𝑧 ∈ [0,1], the x𝑚 solving the true pseudo-
costminimizationproblemislower-boundedbythex˘
𝑚
solvingthefollowingminimizationproblem(i.e.,
𝑐(x˘ 𝑚) ≤𝑐(x𝑚)):
∫ 𝑧(𝑚−1)+𝑐(x)
x˘ 𝑚 = argmin 𝑓 𝑚(x)+𝛽(𝑧(𝑚−1) +𝑐(x))− 𝜙(𝑢)𝑑𝑢.
x∈R𝑑:𝑐(x)≤1−𝑧(𝑚−1) 𝑧(𝑚−1)
Thisfurthergivesthefollowing:
∫ 𝑧(𝑚−1)+𝑐(x)
𝑓 𝑚(x)+𝛽(𝑧(𝑡) +𝑐(x))− 𝜙(𝑢)𝑑𝑢
𝑧(𝑚−1)
∫ 𝑧(𝑚−1)+𝑐(x) (cid:20) (cid:18)𝑈 (cid:19) (cid:21)
𝑓 𝑚(x)+𝛽(𝑧(𝑡) +𝑐(x))− 𝑈 −𝛽 +
𝛼
−𝑈 +2𝛽 exp(𝑢/𝛼) 𝑑𝑢
𝑧(𝑚−1)
(cid:18) (cid:18)𝑧(𝑚−1) +𝑐(x)(cid:19) (cid:18)𝑧(𝑚−1)(cid:19)(cid:19)
𝑓 𝑚(x)−(𝑈 −𝛽)𝑐(x)+𝛽(𝑧(𝑡) +𝑐(x))− [𝑈 −𝑈𝛼 +2𝛽𝛼] exp
𝛼
−exp
𝛼
By assumption, since 𝑓 𝑚(·) is convex and satisfies [∇𝑓 𝑚]𝑖 < 𝜙(𝑧(𝑗)) −𝛽 at x = 0, there must exist a
dimension𝑖 in 𝑓
𝑚
whereanincrementalstepawayfrom0indirection𝑖 satisfiesthefollowinginequality:
𝑓 𝑚(x) ≲ [∇𝑓 𝑚]𝑖 ·𝑐(x) < [𝜙(𝑧(𝑗))−𝛽]𝑐(x) forsomexwhere𝑐(x) > 0. Thus,wehavethefollowinginthe
pseudo-costminimizationproblem:
(cid:18) (cid:18)𝑧(𝑚−1) +𝑐(x)(cid:19) (cid:18)𝑧(𝑚−1)(cid:19)(cid:19)
([∇𝑓 𝑚]𝑖 −𝑈 +𝛽)𝑐(x)+𝛽(𝑧(𝑡) +𝑐(x))− [𝑈 −𝑈𝛼 +2𝛽𝛼] exp
𝛼
−exp
𝛼
18Letting𝑐(𝑥) besome scalar𝑦 (whichis validsince weassume thereis atleastone dimensionin 𝑓 (·)
𝑡
wherethecostfunctiongrowthrateisatmost∇𝑓 ),thepseudo-costminimizationproblemfindsthevalue
𝑚
𝑦 whichminimizesthefollowingquantity:
(cid:18) (cid:18)𝑧(𝑚−1) +𝑦(cid:19) (cid:18)𝑧(𝑚−1)(cid:19)(cid:19)
([∇𝑓 ]𝑖 −𝑈 +𝛽)𝑦+𝛽(𝑧(𝑡) +𝑦)− [𝑈 −𝑈𝛼 +2𝛽𝛼] exp −exp
𝑚 𝛼 𝛼
Takingthederivativeoftheabovewithrespectto𝑦 yieldsthefollowing:
𝑑 (cid:20) (cid:18) (cid:18)𝑧(𝑚−1) +𝑦(cid:19) (cid:18)𝑧(𝑚−1)(cid:19)(cid:19)(cid:21)
𝑑𝑦
([∇𝑓 𝑚]𝑖 −𝑈 +𝛽)𝑦+𝛽(𝑧(𝑡) +𝑦)− [𝑈 −𝑈𝛼 +2𝛽𝛼] exp
𝛼
−exp
𝛼
=
(𝑈𝛼 −2𝛼𝛽
−𝑈)exp(cid:16)𝑧(𝑚−1)+𝑦(cid:17)
𝛼
= [∇𝑓 𝑚]𝑖 +2𝛽 −𝑈 +
𝛼
If𝑦 = 0,wehavethefollowingbyassumptionthat [∇𝑓 𝑚]𝑖 <𝜙(𝑧(𝑗))−𝛽 andthat𝑧(𝑗) =𝑧(𝑚−1):
(cid:18)𝑧(𝑚−1)(cid:19) (cid:18)𝑧(𝑚−1)(cid:19)
[∇𝑓 ]𝑖 +2𝛽 −𝑈 +(𝑈 −2𝛽 −𝑈/𝛼)exp <𝜙(𝑧(𝑗))+𝛽 −𝑈 +(𝑈 −2𝛽 −𝑈/𝛼)exp
𝑚 𝛼 𝛼
(cid:16) (cid:17)
<𝜙(𝑧(𝑗))− 𝜙(𝑧(𝑚−1)) = 0
Theabovederivationimpliesthatthederivativeofthecostminimizationproblemat𝑐(x) = 0(which
corresponds to the case where x = 0) is strictly less than 0. This further implies that x˘ 𝑚 must be non-
zero,sincetheminimizermustsatisfy𝑐(x˘ 𝑚) > 0. Since𝑐(x˘ 𝑚) lowerboundsthetrue𝑐(x𝑚),thiscausesa
contradiction,asitwasassumedthattheutilizationaftertimestep𝑚 wouldsatisfy𝑧(𝑚) =𝑧(𝑚−1) =𝑧(𝑗),
butif𝑐(x𝑚) > 0,𝑧(𝑚) mustsatisfy𝑧(𝑚) >𝑧(𝑚−1).
ItthenfollowsbycontradictionthatOPT(I) ≥𝜙(𝑧(𝑗))−𝛽.
LemmaB.3. ThecostofALG1onanyvalidCFLinstanceI ∈ Ω isupperboundedby
∫ 𝑧(𝑗)
ALG1(I) ≤ 𝜙(𝑢)𝑑𝑢 +𝛽𝑧(𝑗) +(1−𝑧(𝑗))𝑈. (11)
0
ProofofLemmaB.3. First,recallthat𝑧(𝑡) = (cid:205) 𝜏∈[𝑡]𝑐(x𝜏) isnon-decreasingover𝑡 ∈ [𝑇].
Observethatwhenever𝑐(x𝑡) > 0,weknowthat𝑓 𝑡(x𝑡)+∥x𝑡−x𝑡−1∥
ℓ1(w)
<
∫ 𝑧𝑧 (𝑡( −𝑡− 1)1)+𝑐(x𝑡)𝜙(𝑢)𝑑𝑢.
Then,
if𝑐(x𝑡) = 0,whichcorrespondstothecasewhenx𝑡 = 0,wehavethefollowing:
∫ 𝑧(𝑡−1)+𝑐(x𝑡)
𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥ ℓ1(w) − 𝜙(𝑢)𝑑𝑢 = 0+∥−x𝑡−1∥ ℓ1(w) −0 ≤ 𝛽𝑐(x𝑡−1)
𝑧(𝑡−1)
Thisgivesthatforanytimestepwhere𝑐(x𝑡) = 0,wehavethefollowinginequality:
𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥ ℓ1(w) ≤ 𝛽𝑐(x𝑡−1),∀𝑡 ∈ [𝑇] :𝑐(x𝑡) = 0. (12)
Andthus,sinceanytimestepwhere𝑐(x𝑡) > 0implies 𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ1(w)
<
∫ 𝑧𝑧 (𝑡( −𝑡− 1)1)+𝑐(x𝑡)𝜙(𝑢)𝑑𝑢,we
havethefollowinginequalityforalltimesteps(i.e.,anupperboundontheexcesscostnotaccountedforin
thepseudo-costthresholdfunctionorcompulsorytrade)
∫ 𝑧(𝑡−1)+𝑐(x𝑡)
𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ1(w)
− 𝜙(𝑢)𝑑𝑢 ≤ 𝛽𝑐(x𝑡−1),∀𝑡 ∈ [𝑇]. (13)
𝑧(𝑡−1)
19Thus,wehave
∑︁ ∑︁
(cid:34) ∫ 𝑧(𝑡−1)+𝑐(x𝑡) (cid:35)
𝛽𝑧(𝑗) = 𝛽𝑐(x𝑡−1) ≥ 𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥ ℓ1(w) − 𝜙(𝑢)𝑑𝑢 (14)
𝑡∈[𝑗] 𝑡∈[𝑗]
𝑧(𝑡−1)
∫ 𝑧(𝑗)
= ∑︁ (cid:2)𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥ ℓ1(w)(cid:3) − 𝜙(𝑢)𝑑𝑢 (15)
0
𝑡∈[𝑗]
∫ 𝑧(𝑗)
= ALG1−(1−𝑧(𝑗))𝑈 − 𝜙(𝑢)𝑑𝑢. (16)
0
CombiningLemmaB.2andLemmaB.3gives
ALG1(I)
∫𝑧(𝑗)
𝜙(𝑢)𝑑𝑢 +𝛽𝑧(𝑗) +(1−𝑧(𝑗))𝑈
≤ 0 ≤ 𝛼, (17)
OPT(I) 𝜙(𝑧(𝑗))−𝛽
wherethelastinequalityholdssinceforany𝑧 ∈ [0,1]
∫ 𝑧 ∫ 𝑧
𝜙(𝑢)𝑑𝑢 +𝛽𝑧+(1−𝑧)𝑈 = [𝑈 −𝛽 +(𝑈/𝛼 −𝑈 +2𝛽)exp(𝑧/𝛼)] +𝛽𝑧+(1−𝑧)𝑈 (18)
0 0
= (𝑈 −𝛽)𝑧+𝛼(𝑈/𝛼 −𝑈 +2𝛽)[exp(𝑧/𝛼)−1] +𝛽𝑧+(1−𝑧)𝑈 (19)
=𝛼(𝑈/𝛼 −𝑈 +2𝛽)[exp(𝑧/𝛼)−1] +𝑈 (20)
=𝛼 [𝑈 −2𝛽 +(𝑈/𝛼 −𝑈 +2𝛽)exp(𝑧/𝛼)] (21)
=𝛼[𝜙(𝑧)−𝛽]. (22)
Thus,weconcludethatALG1is𝛼-competitiveforCFL. □
B.3 ProofofCorollary3.3
Inthissection,weproveCorollary3.3,whichshowsthattheworst-casecompetitiveratioofALG1forMAL
isagainupperboundedby𝛼 asdefinedin(4).
ProofofCorollary3.3. Toshowthisresult,wefirstprovearesultstatedinthemainbody,namelyLemma
2.2, which states the following: For any MAL instance on a weighted star metric (𝑋,𝑑), there is a cor-
responding CFL instance on (R𝑛−1,∥·∥ ℓ 1(w′)) which preserves 𝑓 𝑡𝑎(·) ∀𝑡,𝑐(·) ∀𝑎 ∈ 𝑋, and upper bounds
𝑑(𝑎,𝑏) ∀(𝑎,𝑏) ∈𝑋.
Beforetheproof,wenotethatBansalandCoester[BC22]showedonlinemetricallocationonaweighted
star metric (𝑋,𝑑) is identical to convex function chasing (with separable cost functions) on the normed
vector space (Δ 𝑛,∥·∥ ℓ 1(w)), where Δ 𝑛 is the𝑛-point simplex in R𝑛 and ∥·∥ ℓ 1(w) is the weighted ℓ 1 norm,
withweightsgivenbythecorrespondingedgeweightintheunderlyingstarmetricasfollows:
∑︁
∥x∥ ℓ 1(w) = w𝑎 |x𝑎 |.
𝑎∈𝑋
ProofofLemma2.2. Recallthatbyassumption,theMALinstancecontainsatleastoneOFFpointdenoted
by 𝑎′ ∈ 𝑋 in the MAL instance, where c𝑎′ = 0. Without loss of generality, let the first dimension in Δ 𝑛
correspondtothisOFFpoint.
We define a linear map Φ : Δ → R𝑛−1, where Φ has𝑛 −1 rows and𝑛 columns, and is specified as
𝑛
follows:
(cid:40)
1ifj=i+1
Φ 𝑖,𝑗 =
0otherwise
20ItisstraightforwardtoseethatΦx ∈ R𝑛−1, ∀x ∈ Δ 𝑛.
RecallthataCFLdecisionspaceistheℓ 1balldefinedbythelong-termconstraintfunctioninR𝑛−1. For
anyMALinstancewithconstraintfunction𝑐(x) : Δ
𝑛
→ R,wecandefinealong-termconstraintfunction
𝑐′(x′) : R𝑛−1 → R as follows. The MAL constraint function 𝑐(x) is defined as ∥·∥ ℓ 1(c) for some vector
c ∈ R𝑛−1. Then
c′ = Φc
𝑐′(x′) = ∥x′∥ ℓ 1(c′) ∀x′ ∈ R𝑛−1
Furthermore,forany𝑧 ∈ [0,1],letx ∈ Δ
𝑛
:𝑐(x) < 1−𝑧. ThenitfollowsthatΦxisinR𝑛−1 :𝑐′(x′) < 1−𝑤.
RecallthatcostfunctionsintheMALinstanceareconvexandlinearlyseparableasfollows:
∑︁
𝑓 𝑡(x) = 𝑓 𝑡𝑎 (x𝑎 )
𝑎∈𝑋
Next,againlettingx ∈ Δ 𝑛,notethatthe𝑖thterminxisidenticaltothe (𝑖−1)thterminΦx(excludingthe
firstterminx). ThenwecanconstructcostfunctionsintheCFLinstanceasfollows:
𝑓′(x′) = ∑︁ 𝑓𝑖+1 (x𝑖 )
𝑡 𝑡
𝑖∈[𝑛−1]
UnderthemappingΦ,notethatitisstraightforwardtoshowthat 𝑓 𝑡(x) = 𝑓 𝑡′(Φx) foranyx ∈ Δ 𝑛.
Finally,considerthedistancesintheMALinstance’sweightedstarmetric,whichcanbeexpressedasa
weightedℓ 1normdefinedbyw,wherethetermsofwcorrespondtotheweightededgesofthestarmetric.
Recall that 𝛽 (cid:66) max 𝑎′,𝑎∥𝑎′ −𝑎∥ ℓ 1(w), i.e., the maximum distance between the OFF point and any other
pointintheweightedstar.
ThenwedefineacorrespondingdistancemetricintheCFLinstance,whichisanℓ
1
normweightedby
w′ ∈ R𝑛−1,whichisdefinedasfollows:
w′𝑖
=
w𝑖+1 +w0.
Notethatw0 istheedgeweightassociatedwiththeOFFpoint. Thenforany (x,y) ∈ Δ 𝑛,itisstraightfor-
wardtoshowthefollowing:
∥x−y∥
ℓ 1(w)
≤ ∥Φx−Φy∥
ℓ 1(w′)
This follows since for any (x,y) ∈ Δ 𝑛 where x0 = 0 and y0 = 0 (i.e., allocations which do not allocate
anythingtotheOFFpoint), ∥Φx−Φy∥ ℓ 1(w′) = ∥x−y∥ ℓ 1(w) +∥x−y∥ ℓ 1 ·w0.
Conversely, if either x or y have x0 > 0 or y0 > 0, we have ∥x − y∥ ℓ 1(w) ≤ ∥Φx − Φy∥ ℓ 1(w′) ≤
∥x−y∥ ℓ 1(w) +∥x−y∥ ℓ 1 ·w0. Finally,supposingthat(withoutlossofgenerality)xhasx0 = 1,wehavethat
∥x−y∥ ℓ 1(w) = ∥Φx−Φy∥ ℓ 1(w′).
Thus, ∥Φx−Φy∥
ℓ 1(w′)
upperbounds ∥x−y∥
ℓ
1(w). Furthermore,theconstructeddistancemetricpreserves
𝛽,i.e. given (𝑎′,𝑎) = argmax 𝑎′,𝑎∥𝑎′−𝑎∥ ℓ 1(w),wehavethat ∥Φ𝑎′−Φ𝑎∥ ℓ 1(w′) = 𝛽.
Next, we show that the transformation Φ is bijective. We define the affine map Φ−1 : R𝑛−1 → Δ as
𝑛
follows:Φ−1has𝑛rowsand𝑛−1columns,wherethefirstrowisall−1,andthebottom𝑛rowsarethe𝑛×𝑛
identitymatrix. Letb ∈ R𝑛−1 denotethevectorwithb0 = 1andallothertermsarezero,i.e.,b𝑖 = 0∀𝑖 ≥ 1.
Foranyx′ ∈ R𝑛−1 :𝑐′(x′) ≤ 1,itisstraightforwardtoshowthatΦ−1 x′+bisinΔ 𝑛,sincebydefinition
wehavethat(cid:205)
𝑖∈[𝑛+1]
(cid:0)Φ−1 x′+b(cid:1)
𝑖
= 1. Furthermore,bydefinitionof𝑐′(x′),wehavethat𝑐(Φ−1 x′ +b) =
𝑐′(x′), because the𝑖thterm (excludingthefirstterm) ofΦ−1 x′ +bisidentical tothe (𝑖 −1)thterm ofx′.
Similarly,bydefinitionof 𝑓 𝑡′,wehavethat 𝑓 𝑡(Φ−1 x′+b) = 𝑓 𝑡′(x′).
21Finally,consideringthedistancemetric,wehavethatforany (x′,y′) ∈ R𝑛−1 :𝑐′(x′) ≤ 1:
∥(Φ−1 x′+b)−(Φ−1 y′+b)∥
ℓ 1(w)
≤ ∥x′−y′∥
ℓ
1(w′).
Thisfollowsbyconsideringthatforanyx′,Φ−1 x′ +baddsadimension(correspondingtotheOFFpoint)
andsets (cid:0)Φ−1 x′+b(cid:1) = 1−∥x′∥1. Thenthedistancebetweenanytwopointswhichallocateanon-negative
fraction to the OFF point in Δ 𝑛 is ≤ the distance in R𝑛−1 by definition of the weight vector w′, and the
distancebetweene.g.,theallocationfullyintheOFFpoint(𝑎′)andanyotherallocationisexactlypreserved.
Furthermore,notethatifw0 = 0(i.e.,theweightoftheOFFstateintheweightedstarmetricis0),Φis
abijectiveisometrybetween (Δ ,∥·∥ ) and (R𝑛−1,∥·∥ ). □
𝑛 ℓ 1(w) ℓ 1(w′)
ThetransformationdefinedbyΦinLemma2.2allowsustoputdecisionsontheCFLinstance(R𝑛−1,∥·∥
ℓ
1(w′))
inone-to-onecorrespondencewithdecisionsin (Δ ,∥·∥ ).
𝑛 ℓ 1(w)
Below, we formalize this by proving a result stated in the main body (Proposition 2.3) which states
thefollowing: GivenanalgorithmALGforCFL,anyperformanceboundonALGwhichassumesOPTdoes
not pay any switching cost will translate to an identical performance bound for MAL whose parameters
dependonthecorrespondingCFLinstanceconstructedaccordingtoLemma2.2.
ProofofProposition2.3. The cost of ALG on the CFL instance is an upper bound on the cost of the ALG’s
decisions mapped into the MAL instance. This follows since the cost functions are preserved exactly
betweenthetwoinstances,thelong-termconstraintfunctionispreservedexactly,andtheCFLswitching
costisbydefinitionanupperboundontheMALswitchingcost.
If the CFL performance bound assumes that OPT does not pay any switching cost (e.g., as in Theo-
rem3.2),lowerboundingthecostofOPTontheCFLinstanceisequivalenttolowerboundingthecostof
OPTontheMALinstance,asthecostfunctionsandconstraintfunctionsarepreservedexactly.
Thus,wehavethatanysuchperformanceboundforALGontheCFLinstanceconstructedappropriately
(as in Lemma 2.2) immediately gives an identical performance bound for the MAL instance, yielding the
result. □
ByLemma2.2,wehavethatsinceALG1is𝛼-competitiveforCFL(Theorem3.2),ALG1is𝛼-competitive
foranyCFLinstanceconstructedbasedonaMALinstance. Furthermore,byProposition2.3,ALG1isalso
𝛼-competitiveontheunderlyingMALinstance,where𝛼 isgivenby(4). □
B.4 ProofofTheorem3.4
In this section, we prove Theorem 3.4, which shows that 𝛼 as given by (4) is the best competitive ratio
achievableforCFL.
To show this lower bound, we first define a family of special adversaries, and then show that the
competitiveratioforanydeterministicalgorithmislowerboundedundertheinstancesprovidedbythese
adversaries.
Priorworkhasshownthatdifficultinstancesforonlinesearchproblemswithaminimizationobjective
occurwheninputsarriveatthealgorithminandecreasingorderofcost[EFK+01;LPS08;SZL+21;LCZ+23].
ForCFL,weadditionallyconsiderhowanadaptiveadversarycanessentiallyforceanalgorithmtoincura
largeswitchingcostintheworst-case. Wenowformalizesuchafamilyofadversaries{A } ,where
𝑦 𝑦∈[𝐿,𝑈]
A
𝑦
iscalleda𝑦-adversary.
DefinitionB.4(𝑦-adversaryforCFL). Let𝑤,𝑚 ∈ Zbesufficientlylarge,and𝛿 := (𝑈−𝐿)/𝑤.
Without loss of generality, let 𝑘 = argmax 𝑖∈[𝑑]w𝑖, where w is the weight vector for ∥·∥ ℓ 1(w), and
let 𝛽 = max 𝑖∈[𝑑]w𝑖. For𝑦 ∈ [𝐿,𝑈], an adaptive adversary A 𝑦 sequentially presents two types of cost
functions 𝑓 𝑡(·) tobothALGandOPT.
22ThesetypesofcostfunctionsareUp(x) =𝑈1x⊺,andDown𝑖(x) = (cid:205)𝑑 𝑈x𝑗 +(𝑈 −𝑖𝛿)x𝑘.
𝑗≠𝑘
The adversary sequentially presents cost functions from these two types in an alternating, “continu-
ouslydecreasing”order. Specifically,theystartbypresentingcostfunctionUp(x),upto𝑚 times.
Then,theypresentDown1(x),whichhaslinearcostcoefficient𝑈 ineverydirectionexceptdirection
𝑘,whichhascostcoefficient (𝑈 −1·𝛿). Down1(x) ispresentedupto𝑚times. IfALGever“accepts”acost
function Down1(x) (i.e., if ALG makes a decision x where𝑐(x) > 0), the adaptive adversary immediately
presents Up(x) starting in the next time step until either ALG moves to the origin (i.e. online decision
x = 0)orALG’sutilization𝑧 = 1.
Theadversarycontinuesalternatinginthismanner,presentingDown2(x) upto𝑚times,followedby
Up(x) ifALGacceptsanything,followedbyDown3(x) upto𝑚 times,andsoon. Thiscontinuesuntilthe
adversarypresentsDown𝑤 𝑦(x),where𝑦 (cid:66) (𝑈 −𝑤 𝑦𝛿),upto𝑚 times. AfterpresentingDown𝑤 𝑦(x),A
𝑦
will present Up(x) until either ALG moves to the origin or has utilization 𝑧 = 1. Finally, the adversary
presentsexactly𝑚 costfunctionsoftheform(cid:205)𝑑 𝑈x𝑗 +(𝑦+𝜀)x𝑘,followedby𝑚 costfunctionsUp(x).
𝑗≠𝑘
Themechanismofthisadaptiveadversaryisdesignedtopresent“goodcostfunctions”(i.e.,Down𝑖(x))
inaworst-casedecreasingorder,interruptedbyblocksof“badcostfunctions”Up(x) whichforcealarge
switchingcostintheworstcase.
A issimplyastreamof𝑚 costfunctions𝑈,andthefinalcostfunctionsinany𝑦-adversaryinstance
𝑈
arealwaysUp(x).
ProofofTheorem3.4. Let 𝑔(𝑦) denote a conversion function [𝐿,𝑈] → [0,1], which fully describes the
progress towards the long-term constraint (before the compulsory trade) of a deterministic ALG playing
against adaptive adversary A . Note that for large𝑤, the adaptive adversary A is equivalent to first
𝑦 𝑦−𝛿
playingA (besidesthelasttwobatchesofcostfunctions),andthenprocessingbatcheswithcostfunctions
𝑦
Down𝑤 𝑦+1(x)andUp(x). SinceALGisdeterministicandtheconversionisunidirectional(irrevocable),we
musthavethat𝑔(𝑦−𝛿) ≥𝑔(𝑦),i.e.𝑔(𝑦) isnon-increasingin [𝐿,𝑈]. Intuitively,theentirecapacityshould
besatisfiediftheminimumpossiblepriceisobserved,i.e𝑔(𝐿) = 1.
Note that for 𝜀 → 0, the optimal solution for adversary A 𝑦 is OPT(A 𝑦) = 𝑦 + 2𝛽/𝑚, and for 𝑚
sufficientlylarge,OPT(A 𝑦) →𝑦.
Duetotheadaptivenatureofeach𝑦-adversary,anydeterministicALGincursaswitchingcostpropor-
tionalto𝑔(𝑦),whichgivestheamountofutilizationobtainedbyALGbeforetheendofA 𝑦’ssequence.
WheneverALGacceptssomecostfunctionwithcoefficient𝑈 −𝑖𝛿 indirection𝑘,theadversarypresents
Up(x) starting in the next time step. Any ALG which does not switch away immediately obtains a com-
petitiveratiostrictlyworsethananalgorithmwhichdoesswitchaway(ifanalgorithmaccepts𝑐 fraction
of a good price and switches away immediately, the switching cost it will pay is 2𝛽𝑐. An algorithm may
continue accepting𝑐 fraction of coefficient𝑈 in the subsequent time steps, but a sequence exists where
this decision will take up too much utilization to recover when better cost functions are presented later.
Intheextremecase, ifanalgorithmcontinuesaccepting𝑐 fractionofthese𝑈 coefficients, itmightfillits
utilizationandthenOPTcanacceptacostfunctionwhichisarbitrarilybetter).
Sinceacceptinganypricebyafactorof𝑐 incursaswitchingcostof2𝛽𝑐,theswitchingcostpaidbyALG
onadversaryA
𝑦
is2𝛽𝑔(𝑦). WeassumethatALGisnotifiedofthecompulsorytrade,anddoesnotincura
significantswitchingcostduringthefinalbatch.
Thenthetotalcostincurredbyan𝛼★-competitiveonlinealgorithmALGonadversaryA 𝑦isALG(A 𝑦) =
∫ 𝑦
𝑔(𝑈/𝛼★)𝑈/𝛼★− 𝑢𝑑𝑔(𝑢)+2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈,where𝑢𝑑𝑔(𝑢) isthecostofbuying𝑑𝑔(𝑢) utilizationat
𝑈/𝛼★
costcoefficient𝑢,thelasttermisfromthecompulsorytrade,andthesecondtolasttermistheswitching
costincurredbyALG. NotethatanydeterministicALGwhichmakesconversionswhenthepriceislarger
than𝑈/𝛼★canbestrictlyimprovedbyrestrictingconversionstoprices ≤𝑈/𝛼★.
23For any 𝛼★-competitive online algorithm, the corresponding conversion function 𝑔(·) must satisfy
ALG(A 𝑦) ≤ 𝛼★OPT(A 𝑦) = 𝛼★𝑦,∀𝑦 ∈ [𝐿,𝑈]. This gives a necessary condition which the conversion
functionmustsatisfyasfollows:
∫ 𝑦
ALG(A 𝑦) =𝑔(𝑈/𝛼★)𝑈/𝛼★− 𝑢𝑑𝑔(𝑢)+2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈 ≤ 𝛼★𝑦, ∀𝑦 ∈ [𝐿,𝑈].
𝑈/𝛼★
By integral by parts, the above implies that the conversion function must satisfy 𝑔(𝑦) ≥
𝑈−𝛼★𝑦 − 1 ∫ 𝑦 𝑔(𝑢)𝑑𝑢. ByGrönwall’sInequality[MPF91,Theorem1,p. 356],wehavethat
𝑈−𝑦−2𝛽 𝑈−𝑦−2𝛽 𝑈/𝛼★
𝑈 −𝛼★𝑦 1 ∫ 𝑦 𝑈 −𝛼★𝑢 (cid:18)∫ 𝑦 1 (cid:19)
𝑔(𝑦) ≥ − ·exp 𝑑𝑟 𝑑𝑢
𝑈 −𝑦−2𝛽 𝑈 −𝑦−2𝛽 𝑈 −𝑢 −2𝛽 𝑈 −𝑟 −2𝛽
𝑈/𝛼★ 𝑢
𝑈 −𝛼★𝑦 ∫ 𝑦 𝑈 −𝛼★𝑢
≥ − 𝑑𝑢
𝑈 −𝑦−2𝛽 (𝑈 −𝑢 −2𝛽)2
𝑈/𝛼★
𝑈 −𝛼★𝑦 (cid:20)𝑈𝛼★−𝑈 −2𝛽𝛼★ (cid:21)𝑦
≥ − −𝛼★ln(𝑢 +2𝛽 −𝑈)
𝑈 −𝑦−2𝛽 𝑢 +2𝛽 −𝑈
𝑈/𝛼★
≥ 𝛼★ln(𝑦+2𝛽 −𝑈)−𝛼★ln(𝑈/𝛼★+2𝛽 −𝑈), ∀𝑦 ∈ [𝐿,𝑈].
𝑔(𝐿) = 1 by the problem definition – we can combine this with the above constraint to give the fol-
lowingconditionforan𝛼★-competitiveonlinealgorithm:
𝛼★ln(𝐿+2𝛽 −𝑈)−𝛼★ln(𝑈/𝛼★+2𝛽 −𝑈) ≤𝑔(𝐿) = 1.
The optimal 𝛼★ is obtained when the above inequality is binding, so solving for the value of 𝛼★ which
solves 𝛼★ln(𝐿+2𝛽 −𝑈) −𝛼★ln(𝑈/𝛼★+2𝛽 −𝑈) = 1 yields that the best competitive ratio for any ALG
solvingCFLis𝛼★ ≥ (cid:104) 𝑊 (cid:16) 𝑒2𝛽/𝑈(𝐿/𝑈+2𝛽/𝑈−1)(cid:17) − 2𝛽 +1(cid:105)−1 . □
𝑒 𝑈
B.5 ProofofCorollary3.5
In this section, we prove Corollary 3.5, which shows that 𝛼 as given by (4) is the best competitive ratio
achievableforMAL.
Toshowthislowerbound,webuildoffofthefamilyofadversariesinDefinitionB.4,whicharedesigned
toforceanalgorithmtoincuralargeswitchingcostwhilesatisfyingthelong-termconstraint.InDefinition
B.5wedefinethisfamilyofadversarialinstancestailoredforMAL.
DefinitionB.5(𝑦-adversaryforMAL). Let𝑤,𝑚 ∈ Zbesufficientlylarge,and𝛿 := (𝑈−𝐿)/𝑤.
Recallthatwdenotesthevectorofedgeweightsforeachpointintheweightedstarmetric𝑋,andthe
OFF point is defined (without loss of generality) as the point𝑎′ ∈ 𝑋 where c𝑎′ = 0 and 𝑓𝑎′(x𝑎) = 0∀𝑡 ∈
𝑡
[𝑇],∀x𝑎 ∈ [0,1]. Wewillassumethatc𝑎 = 1∀𝑎 ∈𝑋 :𝑎 ≠𝑎′.
Thenwesetw𝑎′ = 0,i.e.,theOFFpointisconnectedtotheinteriorvertexoftheweightedstarwithan
edgeofweight0. Withoutlossofgenerality,welet𝑘 = argmax w𝑎 denotethelargestedgeweightof
𝑎∈[𝑛]
anyother(non-OFF)pointinthemetric. Bydefinition,recallthat𝛽 = w𝑘.
For𝑦 ∈ [𝐿,𝑈], an adaptive adversary A sequentially presents two different sets of cost functions
𝑦
𝑓𝑎(·) ateachpointinthemetricspace.
𝑡
These sets of cost functions are Up = {𝑓𝑎(𝑥) = 𝑈x𝑎 ∀𝑎 ∈ 𝑋 \ {𝑎′}}, and Down𝑖 = {𝑓𝑘(x𝑘) =
(𝑈 −𝑖𝛿)x𝑘}∩{𝑓𝑎(x𝑎) =𝑈x𝑎 ∀𝑎 ∈𝑋 \{𝑎′,𝑘}}. Notethattheadversaryonlyeverpresentscostfunctions
withacoefficient<𝑈 atthepoint𝑘 whichcorrespondstothelargestedgeweight.
Theadversarysequentiallypresentseitherofthesetwosetsofcostfunctionsinanalternating,“con-
tinuouslydecreasing”order. Specifically,theystartbypresentingUp,upto𝑚 times.
24Then,theypresentDown,whichhascostcoefficient𝑈 ineverypointexceptpoint𝑘,whichhascost
coefficient (𝑈 −1·𝛿). Down1 ispresentedupto𝑚 times. IfALGever“accepts”acostfunctioninDown1
(i.e.,ifALGmakesadecision𝑥 where𝑐(𝑥) > 0),theadaptiveadversaryimmediatelypresentsUpstarting
inthenexttimestepuntileitherALGmovesentirelytotheOFFpoint(i.e. onlinedecision𝑥𝑎′ = 1)orALG’s
utilization𝑧 = 1.
Theadversarycontinuesalternatinginthismanner,presentingDown2upto𝑚times,followedbyUp
ifALGacceptsanything,followedbyDown3 upto𝑚 times,andsoon. Thiscontinuesuntiltheadversary
presentsDown𝑤 𝑦,where𝑦 = (𝑈−𝑤 𝑦𝛿),upto𝑚times. AfterpresentingDown𝑤 𝑦,A 𝑦 willpresentUp(𝑥)
untileitherALGmovestotheOFFpointorhasutilization𝑧 = 1. Finally, theadversarypresentsthesetof
costfunctions{𝑓𝑘(x𝑘) = (𝑦+𝜀)x𝑘}∩{𝑓𝑎(x𝑎) =𝑈x𝑎 ∀𝑎 ∈𝑋 \{𝑎′,𝑘}}𝑚 times,followedbyUp𝑚 times.
The mechanism of this adaptive adversary is designed to present “good cost functions” (i.e., Down𝑖)
in a worst-case decreasing order, interrupted by blocks of “bad cost functions” Up which force a large
switchingcostintheworstcase.
AsinTheorem3.4, A
𝑈
issimplyastreamof𝑚 Upsetsofcostfunctions,andthefinalcostfunctions
inany𝑦-adversaryinstancearealwaysUp.
ProofofCorollary3.5. Aspreviously,welet𝑔(𝑦) denoteaconversionfunction [𝐿,𝑈] → [0,1],whichfully
describestheprogresstowardsthelong-termconstraint(beforethecompulsorytrade)ofadeterministic
ALGplayingagainstadaptiveadversaryA 𝑦. SinceALGisdeterministicandtheconversionisunidirectional
(irrevocable),𝑔(𝑦) isnon-increasingin [𝐿,𝑈]. Intuitively,theentirelong-termconstraintshouldbesatis-
fiediftheminimumpossiblepriceisobserved,i.e𝑔(𝐿) = 1. For𝜀 → 0,theoptimalsolutionforadversary
A
𝑦
isOPT(A 𝑦) =𝑦+2𝛽/𝑚,andfor𝑚 sufficientlylarge,OPT(A 𝑦) →𝑦.
As in Theorem 3.4, the adaptive nature of each𝑦-adversary forces any deterministic ALG to incur a
switchingcostof2𝛽𝑔(𝑦) onadversaryA 𝑦,andweassumethatALGdoesnotincurasignificantswitching
costduringthefinalbatch(i.e.,duringthecompulsorytrade).
Thenthetotalcostincurredbyan𝛼★-competitiveonlinealgorithmALGonadversaryA 𝑦isALG(A 𝑦) =
∫ 𝑦
𝑔(𝑈/𝛼★)𝑈/𝛼★− 𝑢𝑑𝑔(𝑢)+2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈,where𝑢𝑑𝑔(𝑢) isthecostofbuying𝑑𝑔(𝑢) utilizationat
𝑈/𝛼★
costcoefficient𝑢,thelasttermisfromthecompulsorytrade,andthesecondtolasttermistheswitching
costincurredbyALG. NotethatthisexpressionforthecostisexactlyasdefinedinTheorem3.4.
Thus by Theorem 3.4, for any 𝛼★-competitive online algorithm, the conversion function 𝑔(·) must
satisfy ALG(A 𝑦) ≤ 𝛼★OPT(A 𝑦) = 𝛼★𝑦,∀𝑦 ∈ [𝐿,𝑈]. Via integral by parts and Grönwall’s Inequality
[MPF91,Theorem1,p. 356],wehavethefollowingconditionon𝑔(𝑦):
𝑔(𝑦) ≥ 𝛼★ln(𝑦+2𝛽 −𝑈)−𝛼★ln(𝑈/𝛼★+2𝛽 −𝑈), ∀𝑦 ∈ [𝐿,𝑈].
𝑔(𝐿) = 1 by the problem definition – combining this with the previous condition gives the following
conditionforan𝛼★-competitiveonlinealgorithm:
𝛼★ln(𝐿+2𝛽 −𝑈)−𝛼★ln(𝑈/𝛼★+2𝛽 −𝑈) ≤𝑔(𝐿) = 1.
AsinTheorem3.4,theoptimal𝛼★isobtainedwhentheaboveinequalityisbinding,yieldingthatthebest
competitiveratioforanyALGsolvingMALis𝛼★ ≥ (cid:104) 𝑊 (cid:16) 𝑒2𝛽/𝑈(𝐿/𝑈+2𝛽/𝑈−1)(cid:17) − 2𝛽 +1(cid:105)−1 . □
𝑒 𝑈
C Proofs for Section 4 (Learning-Augmentation)
C.1 ProofofLemma4.1
In this section, we prove Lemma 4.1, which shows that the baseline fixed-ratio combination algorithm
(cid:16) (cid:17)
(Baseline)is(1+𝜖)-consistentand (𝑈+2𝛽)/𝐿(𝛼−1−𝜖)+𝛼𝜖 -robustforCFL,givenany𝜖 ∈ [0,𝛼−1]andwhere
(𝛼−1)
25𝛼 isasdefinedin(4).RecallthatLemma4.1specifiesALG1asthe“robustalgorithm”touseforthefollowing
analysis.
ProofofLemma4.1. UndertheassumptionthatADVsatisfiesthelong-termconstraint,(i.e.,that(cid:205)𝑇 𝑡=1𝑐(a𝑡) ≥
1),wefirstobservethattheonlinesolutionofBaselinemustalsosatisfythelong-termconstraint.
UndertheassumptionsofCFL,notethat𝑐(x) islinear(i.e.,aweightedℓ
1
normwithweightvectorc).
Bydefinition,denotingthedecisionsofALG1byx˜ 𝑡,weknowthat(cid:205)𝑇 𝑡=1𝑐(x˜ 𝑡) ≥ 1.
Thus,wehavethefollowing:
𝑇 𝑇 𝑇 𝑇
∑︁ ∑︁ ∑︁ ∑︁
𝑐(x𝑡) = 𝑐 (𝜆a𝑡 +(1−𝜆)x˜ 𝑡) =𝜆 𝑐(a𝑡)+(1−𝜆) 𝑐 (x˜ 𝑡) ≥ 𝜆+(1−𝜆) = 1.
𝑡=1 𝑡=1 𝑡=1 𝑡=1
Let I ∈ Ω be an arbitrary valid CFL sequence. We denote the hitting and switching costs of the robust
advicebyALG1hitting andALG1switch,respectively. Likewise,thehittingandswitchingcostoftheblack-box
adviceADVisdenotedbyADVhitting andADVswitch.
ThetotalcostofBaselineisupperboundedbythefollowing:
𝑇 𝑇+1
∑︁ ∑︁
Baseline(I) = 𝑓 𝑡(x𝑡)+ ∥x𝑡 −x𝑡−1∥ ℓ 1(w),
𝑡=1 𝑡=1
𝑇 𝑇+1
∑︁ ∑︁
= 𝑓 𝑡 (𝜆a𝑡 +(1−𝜆)x˜ 𝑡)+ ∥𝜆a𝑡 +(1−𝜆)x˜ 𝑡 −𝜆a𝑡−1−(1−𝜆)x˜ 𝑡−1∥ ℓ 1(w),
𝑡=1 𝑡=1
𝑇 𝑇 𝑇+1 𝑇+1
∑︁ ∑︁ ∑︁ ∑︁
≤ 𝜆 𝑓 𝑡(a𝑡)+(1−𝜆) 𝑓 𝑡(x˜ 𝑡)+ ∥𝜆a𝑡 −𝜆a𝑡−1∥
ℓ 1(w)
+ ∥(1−𝜆)x˜
𝑡
−(1−𝜆)x˜ 𝑡−1∥
ℓ
1(w),
𝑡=1 𝑡=1 𝑡=1 𝑡=1
𝑇+1 𝑇+1
∑︁ ∑︁
≤ 𝜆ADVhitting(I)+(1−𝜆)ALG1hitting(I)+𝜆 ∥a𝑡 −a𝑡−1∥
ℓ 1(w)
+(1−𝜆) ∥x˜
𝑡
−x˜ 𝑡−1∥
ℓ
1(w),
𝑡=1 𝑡=1
≤ 𝜆ADVhitting(I)+(1−𝜆)ALG1hitting(I)+𝜆ADVswitch(I)+(1−𝜆)ALG1switch(I),
≤ 𝜆ADV(I)+(1−𝜆)ALG1(I).
SinceALG1 ≤ 𝛼 ·OPT ≤ 𝛼 ·ADV,thisgivesthefollowing:
Baseline(I) ≤ 𝜆ADV(I)+(1−𝜆)𝛼ADV(I), (23)
Baseline(I) ≤ (𝜆+(1−𝜆)𝛼) ·ADV(I) (24)
Baseline(I) ≤ (1+𝜖) ·ADV(I). (25)
Furthermore,sinceADV ≤𝑈 +2𝛽 ≤ OPT ,wehave:
𝐿/(𝑈+2𝛽)
OPT(I)
Baseline(I) ≤ 𝜆 +(1−𝜆)𝛼OPT(I), (26)
𝐿/(𝑈+2𝛽)
(cid:20)𝜆(𝑈 +2𝛽) (cid:21)
Baseline(I) ≤ +(1−𝜆)𝛼 ·OPT(I), (27)
𝐿
(cid:18) (𝑈+2𝛽)/𝐿(𝛼 −1−𝜖)+𝛼𝜖(cid:19)
Baseline(I) ≤ ·OPT(I). (28)
(𝛼 −1)
Bycombining(25)and(28),weconcludethatBaselineis (1+𝜖)-consistentwithrespecttoblack-box
(cid:16) (cid:17)
adviceADV,and (𝑈+2𝛽)/𝐿(𝛼−1−𝜖)+𝛼𝜖 -robust. □
(𝛼−1)
26C.2 ProofofTheorem4.3
Inthissection,weproveTheorem4.3,whichshowsthatCLIPis (1+𝜖)-consistentand𝛾𝜖-robustforCFL,
where𝛾𝜖 isdefinedasthesolutiontothefollowing(asin(8)):
𝑈 𝛾𝜖 (cid:18) 𝑈 −𝐿−2𝛽 (cid:19)
𝛾𝜖 =𝜖 + − (𝑈 −𝐿)ln .
𝐿 𝐿 𝑈 −𝑈/𝛾𝜖 −2𝛽
ProofofTheorem4.3. We show the above result by separately considering consistency (the competitive
ratiowhenadviceiscorrect)androbustness(thecompetitiveratiowhenadviceisnotcorrect)inturn.
Recallthattheblack-boxadviceADVisdenotedbyadecisiona𝑡 ateachtime𝑡.Throughoutthefollowing
proof, we use shorthand notation CLIP𝑡 to denote the cost of CLIP up to time𝑡, and ADV𝑡 to denote the
costofADVuptotime𝑡. Westartwiththefollowinglemmatoproveconsistency.
LemmaC.1. CLIPis (1+𝜖)-consistent.
Proof. First, we note that the constrained optimization enforces that the possible cost so far plus a com-
pulsory term is always within (1+𝜖) of the advice. Formally, if time step 𝑗 ∈ [𝑇] denotes the time step
marking the start of the compulsory trade, we have that the constraint given by (6) holds for every time
step𝑡 ∈ [𝑗].
Thus,toshow(1+𝜖)consistency,wemustresolvethecostduringthecompulsorytradeandshowthat
thefinalcumulativecostofCLIPisupperboundedby (1+𝜖)ADV.
Let I ∈ Ω be an arbitrary valid CFL sequence. If the compulsory trade begins at time step 𝑗 < 𝑇,
bothCLIPandADVmustgreedilyfilltheirremainingutilizationduringthelast𝑚timesteps [𝑗,𝑇]. Thisis
assumedtobefeasible,andtheswitchingcostisassumedtobenegligibleaslongas𝑚issufficientlylarge.
Let (1−𝑧(𝑗−1)) denotetheremaininglong-termconstraintthatmustbesatisfiedbyCLIPatthefinal
timestep,andlet (1−𝐴(𝑗−1)) denotetheremaininglong-termconstrainttobesatisfiedbyADV.
Weconsiderthefollowingtwocases,whichcorrespondtothecaseswhereCLIPhasunder-andover-
provisionedwithrespecttoADV,respectively.
Case1: CLIP(I) has“underprovisioned”((1−𝑧(𝑗−1)) > (1−𝐴(𝑗−1))). Inthiscase,CLIPmustsatisfy
moreofthelong-termconstraintduringthecompulsorytradecomparedtoADV.
Fromtheprevioustimestep,weknowthatthefollowingconstraintholds:CLIP𝑗−1+∥x𝑗−1−a𝑗−1∥
ℓ
1(w)+
∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿+(𝐴(𝑗−1) −𝑧(𝑗−1))𝑈 ≤ (1+𝜖) (cid:2) ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿(cid:3).
Let{x𝑡}
𝑡∈[𝑗,𝑇]
and{a𝑡}
𝑡∈[𝑗,𝑇]
denotethedecisionsmadebyCLIPandADVduringthecompulsorytrade,
respectively. Bydefinition,wehavethat(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡) = (1−𝑧(𝑗−1)) and(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡) = (1−𝐴(𝑗−1)).
Considering {𝑓 𝑡(·)} 𝑡∈[𝑗,𝑇], we know that by definition (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡) ≥ 𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡), and by convex as-
sumptionsonthecostfunctions,(cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(x𝑡) ≤ (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡)+𝑈((cid:205)𝑇 𝑡=𝑗𝑐(x𝑡)−(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡)).
NotethattheworstcaseforCLIPoccurswhen(cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡) = 𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡),asADVisabletosatisfythe
restofthelong-termconstraintatthebestpossibleprice.
27Bytheconstraintintheprevioustimestep,wehavethefollowing:
CLIP𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿+(𝐴(𝑗−1) −𝑧(𝑗−1))𝑈
≤ (1+𝜖)[ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿],
𝑇 (cid:32) 𝑇 𝑇 (cid:33)
∑︁ ∑︁ ∑︁
CLIP𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+𝐿 𝑐(a𝑡)+𝑈 𝑐(x𝑡)− 𝑐(a𝑡)
𝑡=𝑗 𝑡=𝑗 𝑡=𝑗
(cid:34) 𝑇 (cid:35)
∑︁
≤ (1+𝜖) ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+𝐿 𝑐(a𝑡) ,
𝑡=𝑗
CLIP(I) ≤ (1+𝜖) [ADV(I)].
Case2: CLIP(I) has“overprovisioned”((1−𝑧(𝑗−1)) ≤ (1−𝐴(𝑗−1))). Inthiscase, CLIPmustsatisfy
lessofthelong-termconstraintduringthecompulsorytradecomparedtoADV.
Fromtheprevioustimestep,weknowthatthefollowingconstraintholds:CLIP𝑗−1+∥x𝑗−1−a𝑗−1∥
ℓ
1(w)+
∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿+(𝐴(𝑗−1) −𝑧(𝑗−1))𝑈 ≤ (1+𝜖) (cid:2) ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿(cid:3).
Let{x𝑡}
𝑡∈[𝑗,𝑇]
and{a𝑡}
𝑡∈[𝑗,𝑇]
denotethedecisionsmadebyCLIPandADVduringthecompulsorytrade,
respectively. Bydefinition,wehavethat(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡) = (1−𝑧(𝑗−1)) and(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡) = (1−𝐴(𝑗−1)).
Considering {𝑓 𝑡(·)} 𝑡∈[𝑗,𝑇], we know that by definition, (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(x𝑡) ≥ 𝐿(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡), and (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡) ≥
𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡). Byconvexity,because(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡) ≤ (cid:205)𝑇 𝑡=𝑗𝑐(a𝑡),(cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(x𝑡) ≤ (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡).
Bytheconstraintintheprevioustimestep,wehave:
CLIP𝑗−1+∥x𝑗−1−a𝑗−1∥
ℓ 1(w)
+∥a𝑗−1∥
ℓ 1(w)
+(1−𝑧(𝑗−1))𝐿
=
ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿
CLIP𝑗−1+∥x𝑗−1−a𝑗−1∥
ℓ 1(w)
+∥a𝑗−1∥
ℓ 1(w)
+𝐿(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡)
≤ (1+𝜖).
ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡)
Let𝑦 = (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(x𝑡) −𝐿(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡), and let𝑦′ = (cid:205)𝑇
𝑡=𝑗
𝑓 𝑡(a𝑡) −𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡). By definition,𝑦 ≥ 0 and
𝑦′ ≥ 0.
Note that CLIP𝑗−1 + ∥x𝑗−1 − a𝑗−1∥ ℓ 1(w) + ∥a𝑗−1∥ ℓ 1(w) + (1 −𝑧(𝑗−1))𝐿 +𝑦 ≥ CLIP(I) and ADV𝑗−1 +
∥a𝑗−1∥ ℓ 1(w) +𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡)+𝑦′ = ADV(I).
Furthermore,bydefinitionandconvexityofthecostfunctions 𝑓 (·),wehavethat𝑦 ≤𝑦′.
𝑡
Combinedwiththeconstraintfromtheprevioustimestep,wehavethefollowingbound:
CLIP(I)
≤
CLIP𝑗−1+∥x𝑗−1−a𝑗−1∥ ℓ 1(w) +∥a𝑗−1∥ ℓ 1(w) +(1−𝑧(𝑗−1))𝐿+𝑦
ADV(I) ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+(1−𝐴(𝑗−1))𝐿+𝑦′
≤
CLIP𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+𝐿(cid:205)𝑇 𝑡=𝑗𝑐(x𝑡)
≤ (1+𝜖).
ADV𝑗−1+∥a𝑗−1∥
ℓ 1(w)
+𝐿(cid:205)𝑇 𝑡=𝑗𝑐(a𝑡)
Thus, by combining the bounds in each of the above two cases, the result follows, and we conclude
thatCLIPis (1+𝜖)-consistentwithaccurateadvice. □
HavingprovedtheconsistencyofCLIP,weproceedtoshowrobustnessinthenextlemma.
LemmaC.2. CLIPis𝛾𝜖 -robust,where𝛾𝜖 isasdefinedin(8).
Proof. Let𝜖 ∈ (0,𝛼 −1] bethetargetconsistency(recallingthatCLIPis (1+𝜖) consistent),andletI ∈ Ω
denoteanarbitraryvalidCFLsequence.
ToprovetherobustnessofCLIP,weconsidertwo“badcases”fortheadviceADV(I),andshowthatin
theworst-case,CLIP’scompetitiveratioisboundedby𝛾𝜖.
28Case1: ADV(I) is“inactive”. ConsiderthecasewhereADVacceptsnothingduringthemainsequence
andinsteadsatisfiestheentirelong-termconstraintinthefinaltimestep. Intheworst-case,thisgivesthat
ADV(I) =𝑈 +2𝛽.
Basedontheconsistencyconstraint(andusingthefactthatCLIPwillalwaysbe“overprocuring”w.r.t.
ADVthroughoutthemainsequence),wecanderiveanupperboundontheamountthatCLIPisallowedto
acceptfromtherobustpseudo-costminimization. Recallthefollowingconstraint:
CLIP𝑡−1+𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ 1(w)
+∥x𝑡 −a𝑡∥
ℓ 1(w)
+∥a𝑡∥
ℓ 1(w)
+(1−𝑧(𝑡−1) −𝑐(x𝑡))𝐿
(cid:104) (cid:105)
≤ (1+𝜖) ADV𝑡 +∥a𝑡∥ ℓ 1(w) +(1−𝐴(𝑡))𝐿 .
Proposition C.3. 𝑧 is an upper bound on the amount that CLIP can accept from the pseudo-cost mini-
PCM
mizationwithoutviolating (1+𝜖) consistency,andisdefinedas:
(cid:20) 𝑈 −𝐿−2𝛽 (cid:21)
𝑧 =𝛾𝜖ln
PCM 𝑈 −𝑈/𝛾𝜖 −2𝛽
Proof. Consider an arbitrary time step 𝑡. When CLIP is not allowed to accept anything more from the
robust pseudo-cost minimization, we have that𝑐(x𝑡) is restricted to be 0 (recall that a𝑡 = 0 for any time
stepsbefore𝑇,becausetheadviceisassumedtobeinactive).
Bydefinition,sinceanycostfunctionsacceptedinCLIP𝑡−1canbeattributedtotherobustpseudo-cost
minimization,wehavethefollowingintheworst-case:
∫ 𝑧(𝑡−1)
CLIP𝑡−1 = 𝜙𝜖 (𝑢)𝑑𝑢 +𝛽𝑧(𝑡−1).
0
Combiningtheabovewiththeleft-handsideoftheconsistencyconstraint,wehavethefollowingby
observingthatx𝑡 = 0anda𝑡 = 0,andtheswitchingcostto“ramp-up”isabsorbedintothepseudo-cost𝜙:
∫ 𝑧(𝑡−1)
CLIP𝑡−1+(1−𝑧(𝑡−1))𝐿 = 𝜙𝜖 (𝑢)𝑑𝑢 +𝛽𝑧(𝑡−1) +(1−𝑧(𝑡−1))𝐿.
0
Asstated,let𝑧(𝑡−1) =𝑧 PCM. Thenbypropertiesofthepseudo-cost,
∫ 𝑧 PCM
CLIP𝑡−1+(1−𝑧 PCM)𝐿 = 𝜙(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 PCM)𝑈 +(1−𝑧 PCM)𝐿−(1−𝑧 PCM)𝑈,
0
=𝛾𝜖 [𝜙𝜖 (𝑧 PCM)−𝛽] +(1−𝑧 PCM)𝐿−(1−𝑧 PCM)𝑈,
(cid:18) (cid:20) 𝑈 −𝐿−2𝛽 (cid:21)(cid:19)
=𝛾𝜖𝐿+(𝐿−𝑈) 1−𝛾𝜖ln ,
𝑈 −𝑈/𝛾𝜖 −2𝛽
(cid:20) 𝑈 −𝐿−2𝛽 (cid:21)
=𝛾𝜖𝐿+𝐿−𝑈 −(𝐿−𝑈)𝛾𝜖ln .
𝑈 −𝑈/𝛾𝜖 −2𝛽
Substitutingforthedefinitionof𝛾𝜖,weobtain:
(cid:20) 𝑈 −𝐿−2𝛽 (cid:21)
CLIP𝑡−1+(1−𝑧 PCM)𝐿 =𝛾𝜖𝐿+𝐿−𝑈 −(𝐿−𝑈)𝛾𝜖ln
𝑈 −𝑈/𝛾𝜖 −2𝛽
,
(cid:20) (cid:20) 𝑈 −𝐿−2𝛽 (cid:21)(cid:21) (cid:20) 𝑈 −𝐿−2𝛽 (cid:21)
= 𝜖𝐿+𝑈 −𝛾𝜖 (𝑈 −𝐿)ln +𝐿−𝑈 +(𝑈 −𝐿)𝛾𝜖ln ,
𝑈 −𝑈/𝛾𝜖 −2𝛽 𝑈 −𝑈/𝛾𝜖 −2𝛽
=𝜖𝐿+𝐿 = (1+𝜖)𝐿.
Thiscompletestheproposition,since(1+𝜖)𝐿isexactlytheright-handsideoftheconsistencyconstraint
(notethat (1+𝜖) (cid:2) ADV𝑡 +∥a𝑡∥ ℓ 1(w) +(1−𝐴 𝑡)𝐿(cid:3) = (1+𝜖)𝐿). □
29If CLIP is constrained to use at most 𝑧 PCM of its utilization to be robust, the remaining (1 −𝑧 PCM)
utilization must be used for the compulsory trade and/or to follow ADV. Thus, we have the following
worst-casecompetitiveratioforCLIP,specificallyforCase2:
CLIP(I)
∫ 0𝑧 PCM𝜙𝜖(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 PCM)𝑈
≤
OPT(I) 𝐿
Bythedefinitionof𝜙𝜖(𝑝),wehavethefollowing:
CLIP(I)
∫ 0𝑧 PCM𝜙𝜖(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 PCM)𝑈
≤
OPT(I) 𝐿
≤
𝛾𝜖 [𝜙𝜖(𝑧 PCM)−𝛽]
≤
𝛾𝜖 [𝐿+𝛽 −𝛽]
≤
𝛾𝜖.
𝐿 𝐿
Case2: ADV(I) is“overactive”. WenowconsiderthecasewhereADVacceptsbadcostfunctionswhich
which it “should not” accept (i.e. ADV(I) ≫ OPT(I)). Let ADV(I) = 𝑣 ≫ OPT𝑇 (i.e. the final total hitting
andswitchingcostofADVis𝑣 forsome𝑣 ∈ [𝐿,𝑈 +2𝛽],andthisismuchgreaterthantheoptimalsolution).
This is without loss of generality, since we can assume that𝑣 is the “best cost function” accepted by
ADVandtheconsistencyratiochangesstrictlyinfavorofADV. Basedontheconsistencyconstraint,wecan
derivealowerboundontheamountthatCLIPmust acceptfromADVinordertostay (1+𝜖)-consistent.
Todothis,weconsiderthefollowingsub-cases:
•Sub-case2.1: Let𝑣 ≥ 𝑈+𝛽.
1+𝜖
Inthissub-case,CLIPcanfullyignoretheadvice,becausethefollowingconsistencyconstraintisnever
binding(notethatADV𝑡 ≥ 𝑈 1++ 𝜖𝛽𝐴(𝑡)):
CLIP𝑡−1+𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ 1(w)
+∥x𝑡 −a𝑡∥
ℓ 1(w)
+∥a𝑡∥
ℓ 1(w)
+(1−𝐴(𝑡))𝐿+(𝐴(𝑡) −𝑧(𝑡−1) −𝑐(x𝑡))𝑈
(cid:104) (cid:105)
≤ (1+𝜖) ADV𝑡 +∥a𝑡∥ ℓ 1(w) +(1−𝐴(𝑡))𝐿 ,
(cid:104) (cid:105)
(1−𝐴(𝑡))𝐿+(𝐴(𝑡))𝑈 +∥a𝑡∥ ℓ 1(w) ≤ (1+𝜖) ADV𝑡 +∥a𝑡∥ ℓ 1(w) +(1−𝐴(𝑡))𝐿 ,
(cid:20)𝑈 +𝛽 (cid:21)
(1−𝐴(𝑡))𝐿+𝑈𝐴(𝑡) +𝛽𝐴(𝑡) ≤ (1+𝜖) 𝐴(𝑡) +(1−𝐴(𝑡))𝐿
1+𝜖
•Sub-case2.2: Let𝑣 ∈ (𝐿, 𝑈+𝛽 ).
1+𝜖
Toremain (1+𝜖) consistent,CLIPmustacceptsomeofthese“badcostfunctions”denotedby𝑣 inthe
worst-case. We would like to derive a lower bound 𝑧 , such that 𝑧 describes the minimum amount
ADV ADV
thatCLIPmustacceptfromADVinordertoalwayssatisfythe (1+𝜖) consistencyconstraint.
Basedontheconsistencyconstraint,wehavethefollowing:
CLIP𝑡−1+𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ 1(w)
+∥x𝑡 −a𝑡∥
ℓ 1(w)
+∥a𝑡∥
ℓ 1(w)
+(1−𝐴(𝑡))𝐿+(𝐴(𝑡) −𝑧(𝑡−1) −𝑐(x𝑡))𝑈
(cid:104) (cid:105)
≤ (1+𝜖) ADV𝑡 +∥a𝑡∥ ℓ 1(w) +(1−𝐴(𝑡))𝐿 .
Welet 𝑓 𝑡(x𝑡)+∥x𝑡 −x𝑡−1∥
ℓ 1(w)
+∥x𝑡 −a𝑡∥
ℓ 1(w)
+∥a𝑡∥
ℓ 1(w)
≤ 𝑣𝑐(x𝑡) foranyx𝑡 :𝑐(x𝑡) <𝑐(a𝑡),which
holdsbyconvexityofthecostfunctions 𝑓 𝑡(·) andaprevailingassumptionthat𝑐(x𝑡) ≤ 𝑐(a𝑡) forthe“bad
costfunctions”acceptedbyADV. Notethat𝑣 −𝑈 isnegative(bytheconditionofSub-case1.2):
30(cid:104) (cid:105)
CLIP𝑡−1+𝑣𝑐(x𝑡)+𝐿−𝐿𝐴(𝑡) +𝑈𝐴(𝑡) −𝑈𝑧(𝑡−1) −𝑈x𝑡 ≤ (1+𝜖) 𝑣𝐴(𝑡−1) +𝑣𝑐(a𝑡)+𝐿−𝐿𝐴(𝑡) ,
(cid:104) (cid:105)
𝑣𝑐(x𝑡)−𝑈x𝑡 ≤ (1+𝜖) 𝑣𝐴(𝑡−1) +𝑣𝑐(a𝑡)+𝐿−𝐿𝐴(𝑡) −CLIP𝑡−1−𝐿+𝐿𝐴(𝑡) −𝑈𝐴(𝑡) +𝑈𝑧(𝑡−1),
(cid:104) (cid:105)
𝑣𝑐(x𝑡)−𝑈x𝑡 ≤ 𝑣𝐴(𝑡) −𝑈𝐴(𝑡) −CLIP𝑡−1+𝑈𝑧(𝑡−1) +𝜖 𝑣𝐴(𝑡−1) +𝑣𝑐(a𝑡)+𝐿−𝐿𝐴(𝑡) ,
𝑣𝐴(𝑡) −𝑈𝐴(𝑡) −CLIP𝑡−1+𝑈𝑧(𝑡−1) +𝜖 (cid:2)𝑣𝐴(𝑡) +𝐿−𝐿𝐴(𝑡)(cid:3)
x𝑡 ≥
𝑣 −𝑈
.
Intheeventthat𝐴(𝑡−1) = 0(i.e. nothinghasbeenacceptedsofarbyeitherADVorCLIP),wehavethe
following:
x𝑡 ≥
𝑣𝑐(a𝑡)−𝑈𝑐(a𝑡)+ 𝑣𝜖 −[𝑣 𝑈𝑐(a𝑡)+𝐿−𝐿𝑐(a𝑡)]
,
x𝑡 ≥ a𝑡 −
𝜖 [𝑣𝑐(a𝑡) 𝑈+ −𝐿 𝑣−𝐿𝑐(a𝑡)]
.
Througharecursivedefinition,wecanshowthatforany𝐴(𝑡),giventhatCLIPhasaccepted𝑧(𝑡−1) of
ADV’ssuggestedpricessofar,itmustsetx𝑡 suchthat:
𝑧(𝑡) ≥𝑧(𝑡−1) +a𝑡 −
𝜖 [𝑣𝑐(a𝑡) 𝑈+ −𝐿 𝑣−𝐿𝑐(a𝑡)]
.
Continuingtheassumptionthat𝑣isconstant,ifCLIPhasaccepted𝑧(𝑡−1) thusfar,wehavethefollowing
ifweassumethattheacceptanceuptothispointhappenedinasingleprevioustimestep𝑚:
𝑐(x𝑡) ≥ 𝐴(𝑡)
+𝑈𝑐(x𝑚)−CLIP𝑡−1 𝑣+ −𝜖 𝑈(cid:2)𝑣𝐴(𝑡) +𝐿−𝐿𝐴(𝑡)(cid:3)
,
𝑐(x𝑡)
≥𝑐(a𝑡)+𝑐(a𝑚)+𝑈𝑐(x𝑚)−𝑣𝑐(x𝑚)+𝜖 [𝑣(𝑐(a𝑡 𝑣)+ −𝑐 𝑈(a𝑚))+𝐿−𝐿(𝑐(a𝑡)+𝑐(a𝑚))]
,
𝑐(x𝑡) ≥𝑐(a𝑡)+𝑐(a𝑚)−x𝑚 +
𝜖 [𝑣(𝑐(a𝑡)+𝑐(a𝑚)) 𝑣+ −𝐿 𝑈−𝐿(𝑐(a𝑡)+𝑐(a𝑚))]
,
𝑐(x𝑡)+𝑐(x𝑚) ≥𝑐(a𝑡)+𝑐(a𝑚)+
𝜖 [𝑣(𝑐(a𝑡)+𝑐(a𝑚)) 𝑣+ −𝐿 𝑈−𝐿(𝑐(a𝑡)+𝑐(a𝑚))]
,
𝜖 (cid:2)𝑣𝐴(𝑡) +𝐿−𝐿𝐴(𝑡)(cid:3)
𝑧(𝑡) ≥ 𝐴(𝑡) + .
𝑣 −𝑈
Thisgivesintuitionintothedesired𝑧 bound. Theabovedescribesandmotivatesthattheaggregate
ADV
acceptancebyCLIPatanygiventimestep𝑡 mustsatisfyalowerbound. Considerthattheworstcasefor
Sub-case 1.2 occurs when all of the𝑣 prices accepted by ADV arrive first, before any prices which would
beconsideredbythepseudo-costminimization. Thenlet𝐴(𝑡) = 1forsomearbitrarytimestep𝑡, andwe
havethefollowinglowerboundon𝑧 :
ADV
𝑣𝜖
𝑧 ≥ 1− .
ADV 𝑈 −𝑣
If CLIP is forced to use𝑧 of its utilization to be (1+𝜖) consistent against ADV, that leaves at most
ADV
(1−𝑧 ) utilizationforrobustness.
ADV
Wedefine𝑧′ = min(1−𝑧 ADV,𝑧 PCM) andconsiderthefollowingtwocases.
31•Sub-case2.2.1: if𝑧′ =𝑧 PCM,theworst-casecompetitiveratioisboundedbythefollowing. Notethatif
𝑧′ =𝑧 PCM,theamountofutilizationthatCLIPcanuseto“berobust”isexactlythesameasinCase1:
CLIP(I)
≤
∫ 0𝑧 PCM𝜙(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 ADV−𝑧 PCM)𝑈 +𝑧 ADV𝑣
,
OPT(I) 𝐿
≤
∫ 0𝑧 PCM𝜙(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 PCM)𝑈
≤𝛾𝜖.
𝐿
• Sub-case 2.2.2: if 𝑧′ = 1 −𝑧 , the worst-case competitive ratio is bounded by the following. Note
ADV
that CLIP cannot use𝑧 PCM of its utilization for robustness, so the following bound assumes that the cost
functions accepted by CLIP are bounded by the worst (1 − 𝑧 ) fraction of the pseudo-cost threshold
ADV
function𝜙𝜖 (whichfollowssince𝜙𝜖 isnon-decreasingon𝑧 ∈ [0,1]):
CLIP(I)
≤
∫ 01−𝑧
ADV𝜙(𝑢)𝑑𝑢 +𝛽(1−𝑧 ADV)+𝑧 ADV𝑣
.
OPT(I) 𝐿
Notethatif𝑧′ = 1−𝑧 ADV,weknowthat1−𝑧
ADV
<𝑧 PCM,whichfurthergivesthefollowingbydefinition
of𝑧 :
ADV
𝑣𝜖
1−𝑧
PCM
< 1− ,
𝑈 −𝑣
𝑣𝜖 < (𝑈 −𝑣)𝑧 PCM,
𝑈
𝑣 < .
(1+ 𝜖 )
𝑧
PCM
(cid:18) (cid:19)
Since𝑧 𝑣 = (1−𝑧 PCM)𝑈 ,wehavethefollowing:
ADV 1+ 𝜖
𝑧PCM
(cid:18) (cid:19)
∫ 1−𝑧 ADV𝜙(𝑢)𝑑𝑢 +𝛽(1−𝑧 )+ (1−𝑧 PCM)𝑈
CLIP(I)
≤
0 ADV 1+ 𝑧P𝜖
CM ,
OPT(I) 𝐿
≤
∫ 0𝑧 PCM𝜙(𝑢)𝑑𝑢 +𝛽𝑧 PCM+(1−𝑧 PCM)𝑈
≤𝛾𝜖.
𝐿
Thus, by combining the bounds in each of the above two cases, the result follows, and we conclude
thatCLIPis𝛾𝜖-robustforanyadviceADV. □
Having proven Lemma C.1 (consistency) and Lemma C.2 (robustness), the statement of Theorem 4.3
follows–CLIPis (1+𝜖)-consistentand𝛾𝜖-robustgivenanyadviceforCFL. □
C.3 ProofofCorollary4.4
Inthissection,weproveCorollary4.4,whichshowsthatCLIPis(1+𝜖)-consistentand𝛾𝜖-robustforMAL,
where𝛾𝜖 isdefinedin(8).
ProofofCorollary4.4. We show the above result by separately considering consistency (the competitive
ratiowhenadviceiscorrect)androbustness(thecompetitiveratiowhenadviceisnotcorrect),relyingon
theproofofTheorem4.3.
Consistency. Bydefinition,MALonaweightedstarmetricisidenticaltoaninstanceofconvexfunction
chasingwithalong-termconstrainton (Δ ,∥·∥ ),whereΔ isthe𝑛-pointsimplexinR𝑛 and ∥·∥
𝑛 ℓ 1(w′) 𝑛 ℓ 1(w′)
32istheweightedℓ
1
norm,withweightsw′ givenbythecorrespondingedgeweightintheunderlyingstar
metric.
ObservethattheconsistencyproofgiveninLemmaC.1holdswhentheconsistencyconstraintateach
timestepisdefinedasfollows:
CLIP𝑡−1+𝑓𝑡(x)+∥x−x𝑡−1∥ℓ1(w′)+∥x−a𝑡∥ℓ1(w′)+∥a𝑡∥ℓ1(w′)+(1−𝑧(𝑡−1) −𝑐(x))𝐿+max((𝐴(𝑡) −𝑧(𝑡−1) −𝑐(x)), 0)(𝑈 −𝐿)
(29)
≤ (1+𝜖)[ADV𝑡+∥a𝑡∥ℓ1(w′)+(1−𝐴(𝑡))𝐿],
where x and a denote decisions by CLIP and ADV (respectively) supported on Δ 𝑛. Thus, since the consis-
tencyproofinLemmaC.1exactlyholdsundertheCFLvectorspacecorrespondingtoMAL,weconclude
thatCLIPis (1+𝜖)-consistentforMAL.
Robustness. First, we note that the robustness proof given in Lemma C.2 assumes OPT does not pay
any switching cost. This implies that the proof of Lemma C.2 meets the conditions of Proposition 2.3,
which states that any performance bound for an arbitrary ALG solving CFL which assumes OPT pays no
switchingcosttranslatestoanidenticalboundforMAL,wheretheproblem’sparameterscanberecovered
byconstructingacorrespondingCFLinstanceaccordingtoLemma2.2.
Thus,byProposition2.3,weconcludethatCLIPis𝛾𝜖-robustforMAL,where𝛾𝜖 isdefinedin(8).
Bycombiningthetworesults,thestatementofCorollary4.4follows–CLIPis (1+𝜖)-consistentand
𝛾𝜖-robustgivenanyadviceADVforMAL. □
C.4 ProofofTheorem4.5
In this section, we prove Theorem 4.5, which shows that any (1+𝜖)-consistent algorithm for CFL is at
least𝛾𝜖-robust,where𝛾𝜖 isasdefinedin(8).
ProofofTheorem4.5. To show this result, we leverage the same special family of𝑦-adversaries for CFL
definedinDefinitionB.4,where𝑦 ∈ [𝐿,𝑈]. Recallthat𝑘 = argmax 𝑖∈[𝑑]w𝑖,wherewistheweightvector
for ∥·∥ .
ℓ 1(w)
AsintheproofofTheorem3.4,wenotethatforadversaryA 𝑦,theoptimalofflinesolutionisOPT(A 𝑦) =
𝑦+2𝛽/𝑚,andthatas𝑚 growslarge,OPT(A 𝑦) →𝑦.
Againsttheseadversaries,weconsidertwotypesofadvice–thefirstisbad advice,whichsetsa𝑡 = 0
foralltimesteps𝑡 <𝑇 (i.e.,beforethecompulsorytrade),incurringafinalcostof𝑈 +2𝛽.
Ontheotherhand,goodadvicesetsa𝑡 = 0foralltimestepsuptothefirsttimestepwhen𝑦isrevealed,
atwhichpointitsetsa𝑘
𝑡
= 1/𝑚 toachievefinalcostADV(A 𝑦) = OPT(A 𝑦) =𝑦+2𝛽/𝑚.
We let 𝑔(𝑦) denote a robust conversion function [𝐿,𝑈] → [0,1], which fully quantifies the actions
of a learning-augmented algorithm LALG playing against adaptive adversary A 𝑦, where 𝑔(𝑦) gives the
progresstowardsthelong-termconstraintundertheinstanceA before(either)thecompulsorytradeor
𝑦
theblack-boxadvicesetsa𝑘
𝑡
> 0. Notethatforlarge𝑤,theadaptiveadversaryA
𝑦−𝛿
isequivalenttofirst
playingA (besidesthelasttwobatchesofcostfunctions),andthenprocessingbatcheswithcostfunctions
𝑦
Down𝑤 𝑦+1(x) and Up(x). Since LALG is deterministic and the conversion is unidirectional (irrevocable),
wemusthavethat𝑔(𝑦−𝛿) ≥𝑔(𝑦),i.e.𝑔(𝑦) isnon-increasingin [𝐿,𝑈].
AsintheproofofTheorem3.4,theadaptivenatureofeach𝑦-adversaryforcesanyalgorithmtoincur
aswitchingcostproportionalto𝑔(𝑦),specificallydenotedby2𝛽𝑔(𝑦).
Forany𝛾-robustonlinealgorithmLALGgivenanyarbitraryblack-boxadvice,thefollowingmusthold:
LALG(A 𝑦) ≤𝛾OPT(A 𝑦) =𝛾𝑦, ∀𝑦 ∈ [𝐿,𝑈].
∫ 𝑦
ThecostofLALGwithconversionfunction𝑔onaninstanceA 𝑦isLALG(A 𝑦) =𝑔(𝑈/𝛾)𝑈/𝛾− 𝑢𝑑𝑔(𝑢)+
𝑈/𝛾
2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈,where𝑢𝑑𝑔(𝑢) isthecostofbuying𝑑𝑔(𝑢) utilizationatprice𝑢,thelasttermisfrom
thecompulsorytrade,andthesecondtolasttermistheswitchingcostincurredbyLALG.
33Thisimpliesthat𝑔(𝑦) mustsatisfythefollowing:
∫ 𝑦
𝑔(𝑈/𝛾)𝑈/𝛾 − 𝑢𝑑𝑔(𝑢)+2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈 ≤𝛾𝑦, ∀𝑦 ∈ [𝐿,𝑈].
𝑈/𝛾
By integral by parts, the above implies that the conversion function must satisfy 𝑔(𝑦) ≥ 𝑈−𝛾𝑦 −
𝑈−𝑦−2𝛽
1 ∫ 𝑦 𝑔(𝑢)𝑑𝑢. ByGrönwall’sInequality[MPF91][Theorem1,p. 356],wehavethat
𝑈−𝑦−2𝛽 𝑈/𝛾
𝑈 −𝛾𝑦 1 ∫ 𝑦 𝑈 −𝛾𝑢 (cid:18)∫ 𝑦 1 (cid:19)
𝑔(𝑦) ≥ − ·exp 𝑑𝑟 𝑑𝑢 (30)
𝑈 −𝑦−2𝛽 𝑈 −𝑦−2𝛽 𝑈 −𝑢 −2𝛽 𝑈 −𝑟 −2𝛽
𝑈/𝛾 𝑢
𝑈 −𝛾𝑦 ∫ 𝑦 𝑈 −𝛾𝑢
≥ − 𝑑𝑢 (31)
𝑈 −𝑦−2𝛽 (𝑈 −𝑢 −2𝛽)2
𝑈/𝛾
𝑈 −𝛾𝑦 (cid:20)𝑈𝛾 −𝑈 −2𝛽𝛾 (cid:21)𝑦
≥ − −𝛾ln(𝑢 +2𝛽 −𝑈) (32)
𝑈 −𝑦−2𝛽 𝑢 +2𝛽 −𝑈
𝑈/𝛾
≥𝛾ln(𝑦+2𝛽 −𝑈)−𝛾ln(𝑈/𝛾 +2𝛽 −𝑈), ∀𝑦 ∈ [𝐿,𝑈]. (33)
Inaddition,tosimultaneouslybe𝜂-consistentwhentheadviceiscorrect,LALGmustsatisfyLALG(A 𝐿) ≤
𝜂OPT(A 𝐿) =𝜂𝐿.Iftheadviceiscorrect(and𝑚issufficientlylarge),weassumethatLALGpaysnoswitching
costtosatisfythelong-termconstraintatthebestcostfunctions𝐿. Itmuststillpayforswitchingincurred
bytherobustalgorithm(recallthatOPTpaysnoswitchingcost).
∫ 𝐿
𝑔(𝑢)𝑑𝑢 +2𝛽𝑔(𝐿) ≤𝜂𝐿−𝐿. (34)
𝑈/𝛾
By combining equations (33) and (34), the conversion function𝑔(𝑦) of any𝛾-robust and𝜂-consistent
onlinealgorithmmustsatisfythefollowing:
∫ 𝐿 (cid:18) 𝑢 +2𝛽 −𝑈 (cid:19) (cid:20) (cid:18) 𝑢 +2𝛽 −𝑈 (cid:19)(cid:21)
𝛾 ln 𝑑𝑢 +2𝛽 𝛾ln ≤𝜂𝐿−𝐿. (35)
𝑈/𝛾
𝑈/𝛾 +2𝛽 −𝑈 𝑈/𝛾 +2𝛽 −𝑈
Whenallinequalitiesarebinding,thisequivalentlygivesthat
𝑈 𝛾(𝑈 −𝐿) (cid:18) 𝑈 −𝐿−2𝛽 (cid:19)
𝜂 ≥𝛾 +1− + ln . (36)
𝐿 𝐿 𝑈 −𝑈/𝛾𝜖 −2𝛽
Wedefine𝜂 suchthat𝜂 (cid:66) (1+𝜖). Bysubstitutingfor𝜂 into(36),werecoverthedefinitionof𝛾𝜖 asgiven
by(8),whichsubsequentlycompletestheproof. Thus,weconcludethatany (1+𝜖)-consistentalgorithm
forCFLisatleast𝛾𝜖-robust. □
C.5 ProofofCorollary4.6
In this section, we prove Corollary 4.6, which shows that any (1+𝜖)-consistent algorithm for MAL is at
least𝛾𝜖-robust,where𝛾𝜖 isasdefinedin(8).
ProofofCorollary4.6. To show this result, we leverage the same special family of𝑦-adversaries for CFL
defined in Definition B.5, where𝑦 ∈ [𝐿,𝑈]. Recall that𝑘 = argmax w𝑎, deonotes the largest edge
𝑎∈[𝑛]
weightofany(non-OFF)pointinthemetricspace,and𝛽 = w𝑘.
AsintheproofofTheorem3.4,wenotethatforadversaryA 𝑦,theoptimalofflinesolutionisOPT(A 𝑦) =
𝑦+2𝛽/𝑚,andthatas𝑚 growslarge,OPT(A 𝑦) →𝑦.
34Againsttheseadversaries,weconsidertwotypesofadvice–thefirstisbad advice,whichsetsa𝑎′ = 1
𝑡
(i.e.,ADVstaysintheOFFpoint)foralltimesteps𝑡 <𝑇 (i.e.,beforethecompulsorytrade),incurringafinal
costof𝑈 +2𝛽.
Ontheotherhand,goodadvicesetsa𝑎′ = 1foralltimestepsuptothefirsttimestepwhen𝑦isrevealed,
𝑡
atwhichpointitsetsa𝑘
𝑡
= 1/𝑚 toachievefinalcostADV(A 𝑦) = OPT(A 𝑦) =𝑦+2𝛽/𝑚.
As previously, we let𝑔(𝑦) denote a robust conversion function [𝐿,𝑈] → [0,1], which fully quantifies
the actions of a learning augmented algorithm LALG playing against adaptive adversary A 𝑦. Since LALG
is deterministic and the conversion is unidirectional (irrevocable),𝑔(𝑦) is non-increasing in [𝐿,𝑈]. Intu-
itively, the entire long-term constraint should be satisfied if the minimum possible price is observed, i.e
𝑔(𝐿) = 1.
As in Theorem 4.5, the adaptive nature of each𝑦-adversary forces any deterministic ALG to incur a
switchingcostof2𝛽𝑔(𝑦) onadversaryA 𝑦,andweassumethatALGdoesnotincurasignificantswitching
costduringthefinalbatch(i.e.,duringthecompulsorytrade).
Forany𝛾-robustLALGgivenanyarbitraryblack-boxadvice,thefollowingmusthold:
LALG(A 𝑦) ≤𝛾OPT(A 𝑦) =𝛾𝑦, ∀𝑦 ∈ [𝐿,𝑈].
∫ 𝑦
ThecostofLALGwithconversionfunction𝑔onaninstanceA 𝑦isLALG(A 𝑦) =𝑔(𝑈/𝛾)𝑈/𝛾− 𝑢𝑑𝑔(𝑢)+
𝑈/𝛾
2𝛽𝑔(𝑦)+(1−𝑔(𝑦))𝑈,where𝑢𝑑𝑔(𝑢) isthecostofbuying𝑑𝑔(𝑢) utilizationatprice𝑢,thelasttermisfrom
the compulsory trade, and the second to last term is the switching cost incurred by LALG. Note that this
expressionforthecostisexactlyasdefinedinTheorem4.5.
ThusbyTheorem4.5,foranylearning-augmentedalgorithmLALGwhichissimultaneously𝜂-consistent
and𝛾-robust,theconversionfunction𝑔(·) mustsatisfythefollowinginequality(viaintegralbypartsand
Grönwall’sInequality[MPF91,Theorem1,p. 356]):
∫ 𝐿 (cid:18) 𝑢 +2𝛽 −𝑈 (cid:19) (cid:20) (cid:18) 𝑢 +2𝛽 −𝑈 (cid:19)(cid:21)
𝛾 ln 𝑑𝑢 +2𝛽 𝛾ln ≤𝜂𝐿−𝐿. (37)
𝑈/𝛾
𝑈/𝛾 +2𝛽 −𝑈 𝑈/𝛾 +2𝛽 −𝑈
Whenallinequalitiesarebinding,thisequivalentlygivesthattheoptimal𝜂 and𝛾 satisfy:
𝑈 𝛾(𝑈 −𝐿) (cid:18) 𝑈 −𝐿−2𝛽 (cid:19)
𝜂 ≥𝛾 +1− + ln . (38)
𝐿 𝐿 𝑈 −𝑈/𝛾𝜖 −2𝛽
Wedefine𝜂 suchthat𝜂 (cid:66) (1+𝜖). Bysubstitutingfor𝜂 into(36),werecoverthedefinitionof𝛾𝜖 asgiven
by(8),whichsubsequentlycompletestheproof. Thus,weconcludethatany (1+𝜖)-consistentalgorithm
forCFLisatleast𝛾𝜖-robust. □
35