LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation
and Planning with LM-Driven PDDL Planner
Xiaopan Zhang∗, Hao Qin∗, Fuquan Wang, Yue Dong, and Jiachen Li‡
Abstract—Languagemodels(LMs)possessastrongcapabil-
ity to comprehend natural language, making them effective in
translating human instructions into detailed plans for simple
r h a ao n dab n d do d rt eale slt l sa ol ts co hk an is tg s. io- ihN sn soe ur fv o eie z ,rr o wt n ch eoe t ol pae p rss e oks r p, s a, oi tt sie evsr epe am e h Lca ei aa ti nn ell r gs y o ua g ai en gs n ei eg s Mu on ubi ofi st dac ra s ek o ln -bt Di odc rth e ivn ta eetl nal ie fi mn Mcg a s u.e ti lTo tt ino o
-
Robot 1 s lA p tau hls pab es tc t oi dg a e ps e n t k se h os kd e n: tts up hA u reos nb w ls il gt ai og ea p hffrsn tt ke oo thsd pff: e , Robot 2
Agent PDDL Planner (LaMMA-P), a novel multi-agent task
planningframeworkthatachievesstate-of-the-artperformance
onlong-horizontasks.LaMMA-Pintegratesthestrengthsofthe
LMs’ reasoning capability and the traditional heuristic search
We need to separate the
planner to achieve a high success rate and efficiency while Put the powered-off laptop on subtasks and assign them
the desk, and turn off all lights. based on our skill sets.
demonstrating strong generalization across tasks. Additionally,
Robot 2 we create MAT-THOR, a comprehensive benchmark that fea- Robot 1 skills:
tures household tasks with two different levels of complexity skills: move,
move, switch
basedontheAI2-THORenvironment.Theexperimentalresults … pickup, on/off,
put down open/close demonstrate that LaMMA-P achieves a 105% higher success
rate and 36% higher efficiency than existing LM-based multi- Fig.1. Atypicalmulti-agentlong-horizoninahouseholdscenariowhere
agent planners. The experimental videos, code, and datasets of Robot1andRobot2collaboratetoexecutetasksbasedonhumancommands
this work as well as the detailed prompts used in each module giveninnaturallanguage.
are available at https://lamma-p.github.io.
Traditional multi-robot task planning approaches have
difficulty in managing such complex long-horizon tasks,
I. INTRODUCTION
especially in environments with diverse tasks and complex
Multi-robot systems have been widely applied to various
interdependencies between robots [8], [9]. They often rely
real-world tasks, such as search and rescue [1], [2], ware-
on fixed, pre-defined algorithms that are not flexible enough
house automation, and agricultural processes [3]–[5]. These
to handle the intricacies of tasks that extend over a long
systems enable multiple robots to collaborate autonomously,
duration [10]. Although recent approaches [11]–[14] that
whichoftenhavewell-definedobjectivesandrequireefficient
leverage language models (LMs) for multi-agent task plan-
coordination between robots. Recently, language models
ning have shown potential, they often struggle with long
(LMs) have been applied to complex, long-horizon house-
input sequences and complex task dependencies, especially
hold tasks, allowing robots to understand semantics and
in collaborative, multi-robot settings. They also fall short in
executenaturallanguagecommands[6],[7].Fig.1illustrates
generalization across tasks with varying levels of difficulty.
multi-robot cooperation in a household setting that exem-
To address these challenges, we propose LaMMA-P, a
plifies the complexity of long-horizon task planning, where LanguageModel-DrivenMulti-AgentPDDLPlanner,which
robots need to perform a sequence of interconnected tasks
integrates the structured problem-solving approach of the
that may require coordinated actions. Thus, different robots
PlanningDomainDefinitionLanguage(PDDL)[15]withthe
needtobeassignedspecifictasksbasedontheircapabilities.
strong reasoning ability of large language models (LLMs)
For instance, Robot 1 is responsible for moving a laptop,
to facilitate long-horizon task allocation and execution in
while Robot 2 is tasked with switching off the lights. Such
heterogeneous multi-robot systems. The LLM component
scenarios highlight the challenges of long-horizon planning
of LaMMA-P identifies and allocates sub-tasks based on
forheterogeneousrobotteams,includingtaskgeneralization,
eachrobot’sskills,generatesPDDLproblemdescriptionsfor
efficient sub-task allocation, and ensuring optimal coordi-
each robot’s domain, and improves its ability to generalize
nation. Managing these tasks over a long horizon requires
over human instructions, even when they are vague. These
both effectively leveraging each robot’s skills and accurately
problems are processed by the Fast Downward planner [16]
identifying parallelizable tasks to maximize performance.
to generate plans for each robot’s assigned sub-task. If the
initial plan fails, the LLM regenerates and adapts the plan
∗Equalcontribution ‡Correspondingauthor
until a viable solution is produced. The sub-plans are then
X. Zhang, F. Wang, Y. Dong, and J. Li are with the University
of California, Riverside, USA. {xzhan006, fuquanw, yued, combined and converted into executable commands for the
jiachen.li}@ucr.edu robots,allowingforseamlesstaskexecution.Bymergingthe
H.QiniswiththePennStateUniversity,USA.Thisworkwasdonewhen
PDDL’s heuristic search approach with flexible LLM rea-
H. Qin was a visiting student at the University of California, Riverside.
hxq5039@psu.edu soning, LaMMA-P enhances task execution in long-horizon
4202
peS
03
]OR.sc[
1v06502.9042:viXratasks, enabling effective planning in multi-robot systems. ment, such as preparing meals or rearranging objects. A hu-
The main contributions of this paper are as follows: manprovideshigh-levelnaturallanguageinstructions,which
• We introduce LaMMA-P, a novel framework that in- may lack detailed specifications of required actions. This
tegrates the reasoning ability of large language models requires task parsing and reasoning, long-horizon planning,
(LLMs)withtheheuristicplanningalgorithmsofPDDL andtaskallocationamongrobots,whichinvolvesidentifying
planners to address long-horizon task planning for het- necessary sub-tasks from the instructions and determining
erogeneous robot teams. To the best of our knowledge, whether certain sub-tasks can be executed in parallel.
LaMMA-P is the first approach that integrates PDDL We formalize this problem as a cooperative Multi-Agent
with LLMs to address multi-agent task planning prob- Planning (MAP) task [29] where multiple agents collab-
lems with a flexible number of agents. oratively generate a joint task plan to achieve a shared
• We develop a modular design that allows seamless goal. Formally, the MAP task is represented as a tuple
integration of LLMs, PDDL planning systems, and ⟨AG,D,{Ai}n i=1,P,I,G⟩, where AG is a set of n agents.
simulation environments, which enables flexible task Each agent i operates within a domain d i ∈D with its own
decomposition and the efficient allocation of sub-tasks set of actions Ai. P is the set of atoms representing the
based on the skills and capabilities of each robot. world state, I ⊆ P is the initial state, and G ⊆ P defines
• We create MAT-THOR, a benchmark of multi-agent the goal state. A solution plan is an ordered sequence of
complex long-horizon tasks based on the AI2-THOR actions Π g = {∆,≺}, where ∆ ⊆ A are actions and ≺
simulator, which evaluates the effectiveness and robust- defines their order. The generated plan starts from the initial
ness of multi-agent planning methods by providing a state I and leads to the goal state G.
standardized set of tasks and performance metrics for
long-horizontaskexecution.Ourmethodachievesstate-
IV. METHOD
of-the-art (SOTA) performance on this benchmark in Our framework, LaMMA-P, is designed to address long-
terms of success rate and efficiency. horizon tasks for heterogeneous multi-agent systems. Fig. 2
provides a detailed overview of the modular structure of
II. RELATEDWORK
our framework, which employs language models (LMs)
Long-horizon planning involves solving complex tasks and PDDL planners within six key modules: Precondition
that require a series of decisions over an extended period. Identifier(P),TaskAllocator,ProblemGenerator(G),PDDL
Traditional methods such as hierarchical task networks [17], Validator (V), Fast Downward/LLM Planner, and Sub-Plan
general-purpose planning systems based on PDDL [18], and Combiner. For detailed prompts for each module, refer to
MonteCarlotreesearch[19]havebeenemployedtoaddress
our project website or the supplemental video. Each module
long-horizon problems by decomposing tasks into subtasks
serves a specific role in the planning and execution of long-
or sampling possible future outcomes. However, these meth-
horizon tasks across multiple robots with different skill sets.
ods often struggle to scale to larger problem spaces, and
Wefocusondeterministic,fullyobservableplanningtasks.
they encounter difficulties in generalization and efficiency.
A PDDL domain consists of a name, types, predicates, and
Reinforcement learning [20] also faces similar challenges
operators. Each robot type has a pre-defined domain for its
when learning transferable and generalizable policies. availableactions.Thedomaindefinestwotypes:robotand
Recent studies integrateLLMs into long-horizon planning object.Onepredicateis(?o - object),where?oisa
to tackle these challenges [6], [7], [12]. LLMs can process
placeholder for an object. Operators in the domain represent
natural language tasks and translate them into structured
specific robot skills, and all the elements (types, predicates,
formats, which enables more adaptable and context-aware
operators, and objects) have human-readable names. For
planning. For example, recent LLM-enhanced planning ap-
example, the “pick up” operator is represented as:
proachesrelyontranslatingnaturallanguagetasksintoPlan-
ning Domain Definition Language (PDDL) patterns [21]– (:action PickupObject
:parameters (?robot - robot
[28], a framework used to represent and solve complex ?object - object
?location - object)
planning problems. Silver et al. [22] and Zhou et al. [24] :precondition (and
combineclassicPDDLvalidatorswithLLM-basedchain-of- (at-location ?object
?location)
thought planning to create an automatic loop that enables (at ?robot ?location)
(not(inaction ?robot)))
iterative correction of planning mistakes by LLMs. Singh et :effect (and
al. [13] propose a teacher-student pipeline where two agents (holding ?robot ?object)
(not(inaction ?robot)))
guide the planner. However, existing approaches are only )
restricted to single-agent or two-agent systems. In contrast,
A. Task Decomposition and Precondition Identifier
ourworkadvancesthefieldbyapplyingPDDLtoLM-driven
task planning with an arbitrary number of agents. The first step in our framework involves decomposing
the task into sub-tasks [11] and introducing a Precondition
III. PROBLEMFORMULATION
Identifierforeachone.Classicalplannercomputesaheuristic
We consider a scenario where multiple robots collabora- h(I,G)byignoringdeleteeffects[16],whereasLLMstackle
tively complete everyday activities in a household environ- tasks through probabilistic reasoning over action sequencesPrecondition List: Task Decomposition Analysis: PDDL Problem 1:
#### Initial Conditions #### General Task Decomposition (define (problem prepare-plate-with-egg)
1. Robot not at egg location. 1. **Prepare the Plate with Egg** (Skills (:domain robot2)
2. Robot not holding egg. Required: GoToObject, PickupObject, PutObject) (:objects
3. Robot not at tomato location. 2. **Prepare the Plate with Tomato** (Skills …
… Required: GoToObject, PickupObject, PutObject) (:init
3. **Microwave the Plate** (Skills Required: …
#### Actions GoToObject, OpenObject, PutObject, SwitchOn, (:goal
1. **GoToObject**: Robot goes to the egg. SwitchOff, CloseObject) …
- Parameters: `?robot, ?egg` )
- Preconditions: `(not (inaction ?robot))` #### Subtask 1: Prepare the Plate with Egg PDDL Problem 2:
- Effects: `(at ?robot ?egg), (not 1. Go to egg location. (define (problem prepare-plate-with-tomato)
(inaction ?robot))` 2. Pick up egg. (:domain robot3)
3. Go to plate location. (:objects
2. **PickupObject**: Robot picks up the egg. 4. Place egg on plate. …
- Parameters: `?robot, ?egg, ?location` (:init
(where egg is initially located) #### Subtask Skills Analysis: …
- Preconditions: `(at-location ?egg ? - **GoToObject**: Robot goes to the object (:goal
location), (at ?robot ?location), (not (egg/plate). …
(inaction ?robot))` - **PickupObject**: Robot picks up the object )
(
…
i n- a cE tf if oe nc t ?s r: o b` o( th )o )l `ding ?robot ?egg), (not ( - pe lg * ag * t/ P ep u .l ta Ot be j) e. ct**: Robot places objects on the P ( d D e (D f :L i dn
o
P e mr ao ( ib m nl i e c rm r
o
o b3 w o: a tv 1e )-plate)
6 (. a t* - - * ?C P P rl a r oo r e bs a c oe m o tO e n b t d ?j e i me r t ic s i ct : o r* n o* ` s w: ? : a r vR `o eo (b )b no `o ott t, c (?l imo nis ace crs to iwt oah nve e ?`m ri oc br oow ta )v )e ,. # - ` T# P h# R i e# o c r b k eS o u fu t p ob 3 O rt b ea h j ,s a e k s c a t sA s ` s,l k i l i gao l nnc l da s S t u` `i bG Po to un aT t: so O kO b #b j 1j e e c tc t ot `. `, R obot2. ( ( (: : :o … i … gb n oj i ae t lcts
- Effects: `(object-close ?robot ? #### Subtask 2: Prepare the Plate with Tomato …
microwave), (not (inaction ?robot))` … )
Fast
Task description: Precondition Task Problem PDDL Downward/
Microwaving an egg and Identifier (P) Allocator Generator (G) Validator (V) LLM Planner
a tomato on a plate FAST
GotoObject GotoObject PickupObject GotoObject PutObject Final Plan:
# Robot 2 and 3 to Plate, 1 to Microwave
Idle 0.000: (GotoObject robot1 microwave) Sub-Plan
0.000: (GotoObject robot2 egg) Combiner
0.000: (GotoObject robot3 tomato)
1.000: (OpenObject robot1 microwave)
1.000: (PickupObject robot2 egg)
GotoObject PickupObject PutObject GotoObject PutObject 1.000: (PickupObject robot3 tomato)
2.000: (GotoObject robot2 plate) 2.000: (GotoObject robot3 plate)
Idle 3.000: (PutObject robot2 egg plate) Plan-to-
3.000: (PutObject robot3 tomato plate) Code
4 #. 0 R0 o0 b: o t( sP 2i c tk ou p MO ib cj re oc wt a vr eo b to ht e2 Pp ll aa tt ee) Converter
5.000: (GotoObject robot2 microwave)
GotoObject OpenObject CClloosseeOObbjjeecctt SwitchonObject OpenObject 6.000: (PutObject robot2 plate microwave)
7.000: (CloseObject robot1 microwave)
Wait Robot 8.000: (Switchon robot1 microwave)
2&3 Task 9.000: (OpenObject robot1 microwave) Scenario
Completion Simulator
Time
Fig. 2. An overview of LaMMA-P’s modular architecture. Our framework leverages LMs within six key modules: Precondition Identifier (P), Task
Allocator, Problem Generator (G), Fast Downward/LLM Planner, PDDL Validator (V), and Sub-Plan Combiner, each serving a specific role in task
execution.ThePreconditionIdentifieranalyzestheinitialconditionsandrequirementsfortaskcompletion.TheTaskAllocatorassignssubtaskstoagents
basedontheirskillsetsandtaskcomplexity.TheFastDownward/LLMPlannerconvertstaskdescriptionsintoexecutableplansforeachagent.Finally,the
Sub-PlanCombinerintegratesindividualagentplansintoacohesiveexecutionstrategy,ensuringsynchronizedactionstoachievetheoveralltaskobjectives.
rather than explicit heuristics. The relaxed plan heuristic is actiona.P′ ⊆P andE′ ⊆E arethereducedsubsets.P′
a a a a a
(cid:32) (cid:33) and E a′ here are outcomes of the optimal probabilistic dis-
h(I,G)= min (cid:88) cost(a) , tribution. These variables also eliminate the need to classify
Π∈Π(I,G) the types of objects involved in the environment.
a∈Π
TheLLM’soutputcanbeviewedastheresultofapplying
where only add effects of the actions taken are considered
heuristics as shown in Fig. 2. It approximates the most
[16]. The heuristic h(I,G) estimates the cost of reaching
probablesequenceofactionstoachieveagivengoalG from
the goal state G from the initial state I, and the function
the initial state I. The expected the action sequence, given
cost(a) is the cost of performing action a. Π represents a
the probabilistic distribution over actions, is defined as
valid action sequence, and the minimization is taken over
(cid:34) (cid:35)
all valid action sequences Π(I,G). For LLMs, we define a
probabilistic distribution over action sequences: hˆ(I,G)=E (cid:88) cost(a)|p(a 1,...,a n |P a′,E a′,I,G) ,
a
n
(cid:89)
p(a 1,...,a n |I,G)= p(a i |a 1,...,a i−1,I,G), where hˆ(I,G) represents the result of applying heuristics,
i=1 and p(a ,...,a | P′,E′,I,G) refers to the probability
1 n a a
wherea ,...,a isthesequenceofactionstoachieveG.The distribution over all possible action sequences a ,...,a
1 n 1 n
Precondition Identifier, similar to relaxed plan, simplifies conditioned on simplified preconditions P′ and effects E′.
a a
the preconditions P and effects E by negating unessential In LaMMA-P, the LLM outputs the Precondition List
a a
effects. This reduction helps the LLM focus on generating which often identifies sub-goals or action sequences more
action sequences with fewer environment constraints. The optimally than relaxed planning. The generated initial state
modifiedprobabilitydistributionbecomesp(a|P′,E′,I,G) is often flawed and thereby significantly impacts the per-
a a
wheretheactionaisconditionedonsimplifiedpreconditions. formance of classic PDDL translators [21]. By simplifying
P is the preconditions, and E refers to the effects of each preconditions,theLLMcanmoreeffectivelygenerateanop-
a a
3
toboR
2 toboR
1
toboRtimalactionpath,minimizingunnecessarystepsandfocusing of the problem files by checking their format and structure
onthecoreelementsneededtoreachthegoal.Theidentified to ensure they are ready for the planning phase. A PDDL
preconditions P′ generated by P can serve as a grounded problem is characterized by a domain, a set of objects, an
a
sequence of action for generation and validation. initial state, and a goal. An object is identified by a name
Implementingthefew-shotfillingpromptbelow,theLLM and a type, e.g., Egg - object. A ground atom is a
generates a sequence of actions along with their associated predicate and a tuple of objects of the appropriate types,
P and E . These preconditions can serve as sub-goals that e.g., (cooked Egg). A state consists of a conjunction
a a
guide the planning process. The sequence generated by the of true ground atoms, assuming all other ground atoms are
LLMisthengroundedandvalidatedbyothermoduleswithin false. A goal is a conjunction of ground atoms that must be
thesystem.Forinstance,thislistofactionsandpreconditions true in any goal state. For example, in “Prepare plate with
assistsinthegenerationofthePDDLproblemfile,providing egg”, the goal is (at-location Egg Plate). The full
astructuredrepresentationofthetaskthatiscompatiblewith PDDL Problem 1, as illustrated in Fig. 2, is written as
the traditional PDDL-based Fast Downward planner [16].
(define (problem prepare-plate-with-egg)
(:domain robot2)
System Prompt: You are a task precondition identifier (:objects
planning for AG robots. Identify the sub-tasks and action Robot2 - robot
Egg Plate Location1 Location2 - object
preconditions that are similar to the examples below. )
User Prompt: Example 1: Independent subtasks: (:init
(at Robot2 InitLoaction)
Subtask 1: Put egg in the fridge. (skills required: (at-location Egg Location1)
GotoObject, PickupObject, PutObject, OpenObject) (at-location Plate Location2)
(not (inaction Robot2))
Subtask 2: Prepare apple slices. (skills required: ...) )
(:goal
...
(and(at-location Egg Plate)
Subtask 1: Put the egg in the Fridge (not (holding Robot2 Egg))
(not (holding Robot2 Plate)))
GoToObject: Robot goes to the egg.
)
- Parameters: ?robot, ?egg )
- Preconditions: (not (inaction ?robot))
D. Planning and Validation
- Effects: (at ?robot ?egg), (not (inaction ?robot))
PickupObject: Robot picks up the egg. Once the PDDL problems are generated, they are passed
... to the Fast Downward/LLM Planner module for plan gen-
Subtask 2: Prepapre apple slices eration. The Fast Downward planner [16], operating within
GotoObject: Robot goes to the apple. the types, constraints, and operators defined in the PDDL
... domain,producesasequenceofactionsthatachievethespec-
Example 2: ...
ified sub-task goals. A validator verifies the plan against the
robot domain’s constraints by analyzing the logs generated
B. Task Allocation
by the Fast Downward planner. If the plan is invalid, the
Once the task is decomposed into smaller, manageable
system falls back to the LLMs for potential re-planning or
sub-tasks for a single robot, the sub-tasks are then allocated
refinement, ensuring that a viable solution is available.
to heterogeneous multi-agent systems. The Task Allocator
E. Sub-Plan Combination and Task Execution
moduleparsesthetaskdescription,identifyingthenecessary
actionsandmatchingthemwiththeappropriaterobotsbased After individual sub-plans are generated and validated,
ontheirskillsandcapacities.Thisallocationprocessensures the Sub-Plan Combiner merges them into a final plan that
thatresourcesareusedefficiently,withtheoptiontoexecute addresses the entire high-level long-horizon task, as shown
tasks in parallel when feasible to reduce the time for task in Fig. 2. The combiner accounts for task parallelizability,
completion.Duetothelengthandinherentrandomnessofthe scheduling simultaneous execution where possible, while
previous result, LLM fails to generate in the correct format ensuring sequential execution for tasks with dependencies.
[30], [31]. Therefore, weddesign this module to conclude This synchronization ensures smooth transitions between
the identified preconditions and the task allocation into a sub-tasks and maintains inter-task dependencies, particularly
structured summary. The Task Decomposition Analysis, as inmulti-robotscenarios.Bybalancingparallelandsequential
showninFig.2,isgeneratedbytheLLMwithinthismodule. execution, the system maximizes efficiency throughout task
execution.Oncethefinalplaniscombined,thePlan-to-Code
C. PDDL Problem Generation and Validation
Converter transforms it into executable code, which runs in
With the sub-tasks allocated, the next phase involves thesimulatedenvironmentusingtheScenarioSimulator.The
generating PDDL problems. Each sub-task is translated into simulatorvisualizestherobotsperformingtheirassignedsub-
a PDDL problem, considering the current state of the envi- tasks, completing the task execution process.
ronment and the specific goals that need to be achieved.
V. EXPERIMENTS
The Problem Generator module constructs the PDDL
problems by specifying the relevant objects, actions, initial A. Benchmark Dataset
conditions, and goals. These problems are then passed to We present MAT-THOR, a multi-agent long-horizon task
the PDDL Validator module, which verifies the correctness dataset expanded from the SMART-LLM benchmark [11],Time: 0 1 3 Time: 6 3 Time: 10 3 Time: 18 Time: 27
2 2
1 1 1 1
2
3
2 2
3
R1: move to the light R1: turn off the light R2: put the phone
Initial position R2: pick up the phone R2: go to the bed R3: move to the desk R3: open the book
Time: 0 Time: 12 Time: 19 Time: 24 Time: 39
3 2
2
2 2 2
1 3 1 1 3 1
R1: pick up the watch R1: open the drawer R1: put the watch in,
R1: move to the desk1 move to the drawer 3 R2: wait for R1 to open, 3 close the drawer
R2: move to the drawer R2: pick up the keys then put the keys in R3: move to the table,
Initial position R3: move to the lamp R3: move to the lamp R3: turn off the lamp turn off the laptop
Fig. 3. The keyframes illustrate the execution of two tasks in different rooms within the AI2-THOR framework, showcasing the key phases of task
completion.Eachrowcorrespondstoadistincttask.Eachrowrepresentsadistincttask.Thethreerobotsareshowninyellowboxes,labeledwithdistinct
numbers.Eachobjecttobemanipulatedishighlightedinblueboxesintheprecedingframe.Thefirsttaskistoturnoffthelights,placethephoneonthe
bed,andleavethebookopen.Thesecondtaskinvolvesplacingthekeysandthewatchinthedrawer,aswellasturningoffthelampandthelaptop.
to evaluate LaMMA-P and baseline methods based on the the total action time steps and the ground truth time steps.
AI2-THORsimulator[32].TheMAT-THORdatasetincludes BothRU andEff areassessedonlyonsuccessfulexecutions.
70 tasks across five floor plans, with increasing complexity WeevaluateLaMMA-Pacrossdiversetaskswithdifferent
and vague commands for a more challenging evaluation. It languagemodels,includingGPT-4o[33],Llama-3.1-8B,and
supports testing on task allocation and execution efficiency Llama-2-13B[34].WeadoptSMART-LLM[11]asthestate-
with two to four robots of varying skills, and provides of-the-art baseline, with GPT-4 replaced by GPT-4o for a
detailedtaskinformation,includinginitialstates,robotskills, fair comparison. Also, we introduce a second baseline using
and final conditions for success. only Chain-of-Thought (CoT) prompting with GPT-4o. For
The tasks are categorized into three levels of complexity: the CoT baseline, we manually translate the generated plans
into code and evaluate performance metrics accordingly.
1) Compound Tasks: These tasks allow for flexible exe-
cution strategies (e.g., sequential, parallel, or hybrid). C. Results and Discussion
Eachrobotpossessesthenecessaryspecializedskillsto
We evaluate LaMMA-P and baseline methods on the
handle its assigned sub-tasks independently, with the
MAT-THOR dataset across three distinct task categories:
number of sub-tasks ranging from two to four.
Compound, Complex, and Vague Command. LaMMA-P
2) Complex Tasks: These tasks are specifically designed
consistently achieves superior performance compared to the
forheterogeneousrobotteams,whereindividualrobots
baseline methods across all task categories.
may not process all skills to complete their sub-tasks
Qualitative Analysis. Fig. 3 visualizes task executions
independently.Thenumberofsub-tasksissixormore.
in the AI2-THOR simulator (task descriptions are detailed
3) VagueCommandTasks:Thesetaskspresentadditional
in the caption). Each row presents key execution frames
challenges with ambiguous natural language instruc-
for a task. In the first Compound task, Robots 1 and 2
tions,whichrequiretherobotstoinfermissingdetails.
work simultaneously, while Robot 3 starts only after Robot
Our MAT-THOR dataset includes 30 compound tasks, 20 2 leaves the desk, optimizing parallelism. In the second
complextasks,and20vaguecommandtaskstoevaluatetask Complextask,onlyRobot1possessestheabilitytoopenand
decomposition, allocation, and execution efficiency. close objects, creating a dependency between the sub-tasks.
Robot2waitsbythedrawerforRobot1toarriveandopenit.
B. Evaluation Metrics and Baselines
Thesedemonstrateourmethod’sabilitytoeffectivelymanage
We adopt five evaluation metrics [11]: Success Rate (SR), complex dependencies while ensuring smooth coordination
Goal Condition Recall (GCR), Robot Utilization (RU), Ex- among the robots for efficient task completion.
ecutability (Exe), and Efficiency (Eff). For a certain task, Quantitative Analysis. Ours (GPT-4o) improves the av-
successful execution occurs when all task-specific goals are erage SR and Eff by 105% and 36%, respectively, compared
achieved. SR represents the ratio between successful execu- to the strongest baseline SMART-LLM (GPT-4o), which
tionsandthetotalnumberoftasks.GCRisthesetdifference indicates a substantial improvement in task completion,
between the ground truth final state and the achieved final efficiency and generalizability. These improvements result
state, normalized by the number of task-specific goals. RU from LaMMA-P’s integration of LMs’ advanced reasoning
calculates the ratio between the total transition count of all abilities with traditional heuristic search. By accurately de-
successful executions and the total ground truth, measuring composing tasks, efficiently assigning sub-tasks, and lever-
howeffectivelytheactionsequenceisplanned.Exemeasures aging heuristic search for planning, our method consistently
thefractionofactionsthatcanbeexecuted,regardlessoftask outperformsthebaselinesacrossallmetrics.Thequantitative
relevance.Eff capturessystemefficiencyastheratiobetween results of our experiments are summarized in Table I.TABLEI
EVALUATIONOFLAMMA-PANDBASELINESONDIFFERENTCATEGORIESOFTASKSINTHEMAT-THORDATASET
Compound Complex Vague
Methods
SR↑ Exe↑ GCR↑RU↑ Eff↑ SR↑ Exe↑ GCR↑RU↑ Eff↑ SR↑ Exe↑ GCR↑RU↑ Eff↑
CoT(GPT-4o) 0.32 0.67 0.40 0.72 0.59 0.00 0.55 0.12 0.47 0.38 0.00 0.24 0.00 0.00 0.00
SMART-LLM(GPT-4o)[11] 0.70 0.96 0.82 0.78 0.64 0.20 0.72 0.33 0.65 0.56 0.00 0.68 0.06 0.44 0.42
Ours(Llama2-13B) 0.36 0.88 0.45 0.84 0.54 0.05 0.78 0.08 0.51 0.43 0.00 0.66 0.00 0.00 0.00
Ours(Llama3.1-8B) 0.45 0.92 0.53 0.79 0.61 0.15 0.83 0.28 0.62 0.48 0.00 0.72 0.00 0.00 0.00
Ours(GPT-4o) 0.93 1.00 0.94 0.91 0.90 0.77 1.00 0.83 0.87 0.67 0.45 0.93 0.48 0.71 0.65
TABLEII
ABLATIONSTUDYONDIFFERENTVARIATIONSOFLAMMA-P
Compound Complex Vague
Methods
SR↑ Exe↑ GCR↑RU↑ Eff↑ SR↑ Exe↑ GCR↑RU↑ Eff↑ SR↑ Exe↑ GCR↑RU↑ Eff↑
Ours(w/oP&V &G&D) 0.50 0.93 0.50 0.77 0.79 0.10 0.93 0.10 0.91 0.72 0.10 0.85 0.25 0.91 1.00
Ours(w/oP&V &G) 0.71 0.87 0.73 0.78 0.85 0.52 0.92 0.70 0.72 0.62 0.20 0.93 0.32 0.61 0.85
Ours(w/oP&V) 0.67 0.84 0.72 0.76 0.89 0.58 0.87 0.60 0.77 0.61 0.15 0.87 0.22 0.86 0.77
Ours(w/oP) 0.79 0.91 0.85 0.87 0.86 0.68 0.82 0.74 0.76 0.63 0.25 0.91 0.32 0.75 0.74
Ours 0.93 1.00 0.94 0.91 0.90 0.77 1.00 0.83 0.87 0.67 0.45 0.93 0.48 0.71 0.65
In Compound tasks, Ours (GPT-4o) achieves higher SR and D. As a result, performance is significantly lower. The
and Eff than SMART-LLM (GPT-4o). This improvement absenceofpre-definedrobotdomainssignificantlydecreases
stems from Ours (GPT-4o)’s effective subtask identification the LLM’s ability to identify appropriate sub-tasks for each
and allocation, which also leads to higher Exe and GCR. robot, resulting in incorrect task allocation and sub-optimal
Similarly, Ours (GPT-4o) achieves a significantly higher performance. After adding D, the SR increases substantially
SR than SMART-LLM (GPT-4o), with Eff rising more in for all categories of tasks. This improvement highlights the
Complex tasks. This highlights LaMMA-P’s strength in importance of domain knowledge in guiding the LLM to
handlinglong-horizonplanning,withitsadvantagebecoming assign tasks more appropriately to robots. Next, the addition
more pronounced as task complexity increases, consistently ofGfurtherimprovesperformancebyprovidingastructured
surpassing other approaches under challenging conditions. approachtodescribesub-tasks,makingthemeasiertoassign.
The superior performance is further supported by improve- Eff for compound tasks and RU for complex and vague
ments in Exe, GCR, and RU, implying enhanced multi- command tasks show an increase, indicating more effective
robot coordination. For Vague Command tasks, although task decomposition and improved robot utilization. V brings
Ours (GPT-4o)’s SR drops, the baseline methods fail on notableimprovementsintaskperformance.Itensuresthatall
all test cases, demonstrating LaMMA-P’s stronger reasoning generated plans are executable before task execution, which
ability to transform natural language into sub-tasks even reduces task failures and optimizes the overall workflow.
withvagueinstructions.Moreover,itsgeneralizabilityacross When all components are included, Ours (GPT-4o) achieves
diverse task descriptions strengthens its advantage in com- the best performance. The addition of P simplifies complex
plex environments. Benefiting from the structured domains preconditions, enabling the LLM to generate action se-
of robot skills, Exe remains high, indicating that LaMMA-P quenceswithfewerconstraintstoguidefurthertaskplanning.
consistently assigns tasks to capable robots. Ours (Llama 2- VI. CONCLUSION
13B) and Ours (Llama 3.1-8B) consistently outperform CoT
We introduce LaMMA-P, a Language Model-Driven
(GPT-4o),demonstratingtheeffectivenessofourapproachin
Multi-AgentPDDLPlannerthataddresseslong-horizontask
handling complex reasoning tasks, even when compared to
allocation and planning for heterogeneous multi-robot sys-
larger, state-of-the-art models. Both underperform compared
tems. By unifying the strong reasoning ability of LLMs
to SMART-LLM (GPT-4o) on Compound tasks, likely due
with heuristic search planning based on PDDL, LaMMA-P
to the smaller model size of LLMs. However, as task
significantlyimprovestasksuccessratesandrobotutilization
complexity increases to Complex, Ours (Llama 3.1-8B)’s
efficiencyoverexistingmethods,whileexhibitinggeneraliza-
performancecloselyapproachesthatofSMART-LLM(GPT-
tion across a wide range of tasks. LaMMA-P outperforms
4o), demonstrating the robustness of our method when tack-
the strongest baseline SMART-LLM on the MAT-THOR
ling more challenging tasks despite the smaller model size.
benchmarkwitha105%highersuccessrateand36%higher
AblationStudy.Weconductanablationstudytoevaluate efficiency in long-horizon tasks. The integration of LLMs
theimpactofvariouscomponentsofLaMMA-Ponitsoverall enables flexible task translation and assignments, enhancing
performance.Theresults,showninTableII,indicatethatthe the system’s generalizability across various tasks. While
addition of key elements, such as the pre-defined domains LaMMA-Pshowspromisingresults,itassumesfullyobserv-
(D), Problem Generator (G), Precondition Identifier (P), able,staticenvironments,whichmaynotalwayssatisfyreal-
and PDDL Validator (V), leads to a significant increase in world conditions. Future work may focus on incorporating
task performance on both compound and complex tasks. vision-language models for improved perception and devel-
The first variation excludes all major components: P, V, G, oping adaptive re-planning for dynamic scenarios.REFERENCES [22] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. Kaelbling, and
M.Katz,“Generalizedplanninginpddldomainswithpretrainedlarge
languagemodels,”inProceedingsoftheAAAIConferenceonArtificial
[1] J.L.Baxter,E.Burke,J.M.Garibaldi,andM.Norman,“Multi-robot
Intelligence,vol.38,no.18,2024,pp.20256–20264.
search and rescue: A potential field based approach,” Autonomous
[23] S.Mahdavi,R.Aoki,K.Tang,andY.Cao,“Leveragingenvironment
robotsandagents,pp.9–16,2007.
interaction for automated pddl generation and planning with large
[2] J. P. Queralta, J. Taipalmaa, B. C. Pullinen, V. K. Sarker, T. N.
languagemodels,”arXivpreprintarXiv:2407.12979,2024.
Gia, H. Tenhunen, M. Gabbouj, J. Raitoharju, and T. Westerlund,
[24] Z. Zhou, J. Song, K. Yao, Z. Shu, and L. Ma, “Isr-llm: Iterative
“Collaborativemulti-robotsearchandrescue:Planning,coordination,
self-refined large language model for long-horizon sequential task
perception, and active vision,” Ieee Access, vol. 8, pp. 191617–
planning,” in 2024 IEEE International Conference on Robotics and
191643,2020.
[3] A.BoluandO¨.Korc¸ak,“Adaptivetaskplanningformulti-robotsmart Automation(ICRA). IEEE,2024,pp.2081–2088.
[25] G. Dagan, F. Keller, and A. Lascarides, “Dynamic planning with a
warehouse,”IEEEAccess,vol.9,pp.27346–27358,2021.
llm,”arXivpreprintarXiv:2308.06391,2023.
[4] L.F.Oliveira,A.P.Moreira,andM.F.Silva,“Advancesinagriculture
[26] L.Guan,K.Valmeekam,S.Sreedharan,andS.Kambhampati,“Lever-
robotics: A state-of-the-art review and challenges ahead,” Robotics,
aging pre-trained large language models to construct and utilize
vol.10,no.2,p.52,2021.
world models for model-based task planning,” Advances in Neural
[5] S. Chen, Y. Chen, R. Jain, X. Zhang, Q. Nguyen, and S. K. Gupta,
InformationProcessingSystems,vol.36,pp.79081–79094,2023.
“Accounting for travel time and arrival time coordination during
[27] K.Valmeekam,M.Marquez,A.Olmo,S.Sreedharan,andS.Kamb-
task allocations in legged-robot teams,” in 2024 IEEE International
hampati, “Planbench: An extensible benchmark for evaluating large
Conference on Robotics and Automation (ICRA). IEEE, 2024, pp.
languagemodelsonplanningandreasoningaboutchange,”Advances
16588–16594.
inNeuralInformationProcessingSystems,vol.36,2024.
[6] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, [28] Y. Xie, C. Yu, T. Zhu, J. Bai, Z. Gong, and H. Soh, “Translating
T.Shu,andC.Gan,“Buildingcooperativeembodiedagentsmodularly naturallanguagetoplanninggoalswithlarge-languagemodels,”arXiv
with large language models,” International Conference on Learning preprintarXiv:2302.05128,2023.
Representations(ICLR),2024. [29] A. Torreno, E. Onaindia, A. Komenda, and M. Sˇtolba, “Cooperative
[7] S. Nayak, A. M. Orozco, M. T. Have, V. Thirumalai, J. Zhang, multi-agent planning: A survey,” ACM Computing Surveys (CSUR),
D. Chen, A. Kapoor, E. Robinson, K. Gopalakrishnan, J. Harrison vol.50,no.6,pp.1–32,2017.
et al., “Long-horizon planning for multi-agent robots in partially [30] M. Levy, A. Jacoby, and Y. Goldberg, “Same task, more tokens:
observableenvironments,”arXivpreprintarXiv:2407.10031,2024. the impact of input length on the reasoning performance of large
[8] Y. Rizk, M. Awad, and E. W. Tunstel, “Cooperative heterogeneous languagemodels,”InProceedingsofthe62ndAnnualMeetingofthe
multi-robot systems: A survey,” ACM Computing Surveys (CSUR), Association for Computational Linguistics (Volume 1: Long Papers),
vol.52,no.2,pp.1–31,2019. 2024.
[9] Y.Wang,M.Damani,P.Wang,Y.Cao,andG.Sartoretti,“Distributed [31] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V.
reinforcement learning for robot teams: A review,” Current Robotics Le, D. Zhou et al., “Chain-of-thought prompting elicits reasoning in
Reports,vol.3,no.4,pp.239–257,2022. large language models,” Advances in neural information processing
[10] A.Khamis,A.Hussein,andA.Elmogy,“Multi-robottaskallocation: systems,vol.35,pp.24824–24837,2022.
A review of the state-of-the-art,” Cooperative robots and sensor [32] E.Kolve,R.Mottaghi,W.Han,E.VanderBilt,L.Weihs,A.Herrasti,
networks2015,pp.31–51,2015. M.Deitke,K.Ehsani,D.Gordon,Y.Zhuetal.,“Ai2-thor:Aninterac-
[11] S. S. Kannan, V. L. Venkatesh, and B.-C. Min, “Smart-llm: Smart tive 3d environment for visual ai,” arXiv preprint arXiv:1712.05474,
multi-agent robot task planning using large language models,” The 2017.
2024 IEEE/RSJ International Conference on Intelligent Robots and [33] J.Achiam,S.Adler,S.Agarwal,L.Ahmad,I.Akkaya,F.L.Aleman,
Systems(IROS),2024. D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4
[12] J. Wang, G. He, and Y. Kantaros, “Safe task planning for language- technicalreport,”arXivpreprintarXiv:2303.08774,2023.
instructed multi-robot systems using conformal prediction,” arXiv [34] A.Dubey,A.Jauhri,A.Pandey,A.Kadian,A.Al-Dahle,A.Letman,
preprintarXiv:2402.15368,2024. A.Mathur,A.Schelten,A.Yang,A.Fanetal.,“Thellama3herdof
[13] I. Singh, D. Traum, and J. Thomason, “Twostep: Multi-agent task models,”arXivpreprintarXiv:2407.21783,2024.
planning using classical planners and large language models,” arXiv
preprintarXiv:2403.17246,2024.
[14] Z. Mandi, S. Jain, and S. Song, “Roco: Dialectic multi-robot col-
laboration with large language models,” in 2024 IEEE International
Conference on Robotics and Automation (ICRA). IEEE, 2024, pp.
286–299.
[15] C.Aeronautiques,A.Howe,C.Knoblock,I.D.McDermott,A.Ram,
M. Veloso, D. Weld, D. W. Sri, A. Barrett, D. Christianson et al.,
“Pddl—theplanningdomaindefinitionlanguage,”TechnicalReport,
Tech.Rep.,1998.
[16] M.Helmert,“Thefastdownwardplanningsystem,”JournalofArtifi-
cialIntelligenceResearch,vol.26,pp.191–246,2006.
[17] I. Georgievski and M. Aiello, “An overview of hierarchical task
networkplanning,”arXivpreprintarXiv:1403.7426,2014.
[18] Y.-q.Jiang,S.-q.Zhang,P.Khandelwal,andP.Stone,“Taskplanning
in robotics: an empirical comparison of pddl-and asp-based sys-
tems,”FrontiersofInformationTechnology&ElectronicEngineering,
vol.20,pp.363–373,2019.
[19] C.B.Browne,E.Powley,D.Whitehouse,S.M.Lucas,P.I.Cowling,
P.Rohlfshagen,S.Tavener,D.Perez,S.Samothrakis,andS.Colton,
“Asurveyofmontecarlotreesearchmethods,”IEEETransactionson
ComputationalIntelligenceandAIingames,vol.4,no.1,pp.1–43,
2012.
[20] L. Kraemer and B.Banerjee, “Multi-agent reinforcement learning as
arehearsalfordecentralizedplanning,”Neurocomputing,vol.190,pp.
82–94,2016.
[21] B.Liu,Y.Jiang,X.Zhang,Q.Liu,S.Zhang,J.Biswas,andP.Stone,
“Llm+ p: Empowering large language models with optimal planning
proficiency,”arXivpreprintarXiv:2304.11477,2023.