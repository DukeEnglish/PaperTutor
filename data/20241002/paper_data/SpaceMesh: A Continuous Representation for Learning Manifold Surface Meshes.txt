SpaceMesh: A Continuous Representation for
Learning Manifold Surface Meshes
TIANCHANGSHEN,NVIDIA,UniversityofToronto,VectorInstitute,Canada
ZHAOSHUOLI,NVIDIA,USA
MARCLAW,NVIDIA,Canada
MATANATZMON,NVIDIA,Canada
SANJAFIDLER,NVIDIA,UniversityofToronto,VectorInstitute,Canada
JAMESLUCAS,NVIDIA,UK
JUNGAO,NVIDIA,UniversityofToronto,VectorInstitute,Canada
NICHOLASSHARP,NVIDIA,USA
Applications
isotropic
triangle meshes
mesh
repair
geometry
concise processing
n-gon meshes
manifoldness
thin structures
sharp features
Fig.1. Wepresentameshrepresentationthatenableslearningtodirectlygeneratepolygonalmeshesastheoutputofaneuralnetwork.Left:3Dmeshes
producedfromagenerativemodeltrainedonadatasetwithdesirablemeshconnectivity.Right:ourmodelcanbeappliedtochallengingtaskssuchasmesh
repair,andproducesmanifoldmeshessuitablefordownstreamprocessinglikecomputinggeodesicdistance.
Meshesareubiquitousinvisualcomputingandsimulation,yetmostexisting structurelearnedfromthedatasetpopulation,withconcisedetailsandhigh-
machinelearningtechniquesrepresentmeshesonlyindirectly,e.g.asthe qualitymeshelements.Inapplications,thisapproachnotonlyyieldshigh-
levelsetofascalarfieldordeformationofatemplate,orasadisordered qualityoutputsfromgenerativemodels,butalsoenablesdirectlylearning
trianglesouplackinglocalstructure.Thisworkpresentsaschemetodirectly challenginggeometryprocessingtaskssuchasmeshrepair.
generatemanifold,polygonalmeshesofcomplexconnectivityastheoutput
CCSConcepts:•Computingmethodologies→Shaperepresentations;
ofaneuralnetwork.Ourkeyinnovationistodefineacontinuouslatent
Reconstruction.
connectivityspaceateachmeshvertex,whichimpliesthediscretemesh.In
particular,ourvertexembeddingsgeneratecyclicneighborrelationshipsina AdditionalKeyWordsandPhrases:MeshGeneration,3DMachineLearning,
halfedgemeshrepresentation,whichgivesaguaranteeofedge-manifoldness GraphRepresentations
andtheabilitytorepresentgeneralpolygonalmeshes.Thisrepresentation
iswell-suitedtomachinelearningandstochasticoptimization,without
restrictiononconnectivityortopology.Wefirstexplorethebasicproperties
ofthisrepresentation,thenuseittofitdistributionsofmeshesfromlarge
datasets.Theresultingmodelsgeneratediversemesheswithtessellation
1
4202
peS
03
]VC.sc[
1v26502.9042:viXraShenetal.
1 INTRODUCTION showcaseourrepresentationinlearningdifferentsurfacediscretiza-
Polygonalmeshesplayanessentialroleincomputergraphics,fa- tionformeshing.Additionally,ourrepresentationenablesmesh
voredfortheirsimplicity,flexibility,andefficiency.Theycanrep- repairviadeeplearning,simultaneouslypredictingbothvertices
resentsurfacesofarbitrarytopologywithnon-uniformpolygons, andtopology.
andsupportawiderangeofdownstreamprocessingandsimulation.
2 RELATEDWORK
Additionally,meshesareidealforrasterizationandtexturemap-
ping,makingthemefficientforrendering.However,thebenefitsof Initial deep learning-based mesh generation techniques focused
meshesrelyheavilyontheirquality.Forexample,mesheswithnon- onvertexpredictionwhilemaintainingfixedconnectivity,which
manifoldconnectivityortoomanyelementsmaybreakoperations arechallengingtoadaptforcomplex3Dobjects[Chenetal.2019;
thatleveragelocalstructure,ormakeprocessingprohibitivelyex- Groueix et al. 2018; Hanocka et al. 2020; Litany et al. 2018; Liu
pensive.Consequently,developingautomaticalgorithmsandtools etal.2021;Ranjanetal.2018;Tanwaretal.2020;Wangetal.2018;
forgeneratinghigh-qualitymeshesisanongoingresearchfocus. Zhangetal.2020,2021].Althoughlocaltopologymodificationsare
Itisnosurprisethatrecentadvancementsindeeplearninghave possiblethroughsubdivision[Liuetal.2020a;Wangetal.2018]or
ledtogrowinginterestinlearning-basedmeshcreation.Generating remeshing[Palfinger2022],thesemethodsstillstruggletorepresent
meshesasoutput,however,isanotoriouslychallengingtaskforma- general,complex3Dobjects.Recentmethodsutilizeintermediary
chinelearningalgorithms,asmesheshaveacomplexcombination representationsthatareconvertedintomeshesusingtechniques
ofcontinuousanddiscretestructure.Notonlydomeshverticesand likePoissonreconstructiononpointclouds[Kazhdanetal.2006;
edgesformagraph,butmeshfacesaddadditionalinterconnected Pengetal.2021]orisosurfacingonimplicitfields[Chenetal.2022;
structure,andfurthermorethosefacesoughttobearrangedlocally Gaoetal.2022;Linetal.2023;Shenetal.2021,2023].However,these
formanifoldconnectivity.Existingapproachesrangefromimplicit conversionprocesseslackprecisecontrolovermeshconnectivity.
functionisosurfacing[Gaoetal.2022;Meschederetal.2019;Shen
etal.2021,2023],whichofferseasyoptimizationandaguaranteeof 2.1 GeneratingMeshes
validityattheexpenseofrestrictingtoalimitedfamilyofmeshes, Muchrecentworkhasspecificallystudiedapproachesforgenerating
todirectlygeneratingfacesasanarrayofvertextriplets[Alliegro surfacesmeshesinlearning-basedpipelines.
etal.2023;Nashetal.2020;Siddiquietal.2023],adiscrete-first
Volumetric3DReconstruction. SeePoint2Surf[Erleretal.2020],
perspectivewhichcannotbecertaintorespecttheconstraintsof
POCO[BoulchandMarlet2022],NKSR[Huangetal.2023]andBSP-
localstructure.Thisworkseeksasolutionthatoffersthebestofall
Net[Chenetal.2020],etc.Thesemethodsfocusonreconstructing
worlds:theeaseandutilitythatcomesfromworkinginacontinuous
thegeometricshape,ratherthanthemeshstructure;outputcon-
parameterization,aguaranteetoproducemesheswithmanifold
nectivityisalwaysamarching-cubesmesh(oraunion-of-planesin
structurebyconstruction,andthegeneralitytorepresentthefull
BSPNet).Ourapproachinsteadfocusesonfittingparticulardiscrete
rangeofpossiblemeshes.
meshconnectivitystructuresfromdata.Figure8and9includeafew
We present SpaceMesh, a representation for meshes built on
representativemethodsfromthisfamily,althoughtheygenerally
continuousembeddingswell-suitedforlearningandoptimization,
targetsignificantlydifferentgoals.Aparallelclassofmethodslever-
whichguaranteesmanifoldoutputandsupportscomplexpolygonal
agesVoronoi/Delaunay-basedformulations[Maruanietal.2023,
connectivity.Ourapproachderivesfromthehalfedgedatastruc-
2024]),butagainthesefocusonfittingasurface’sgeometricshape,
ture[Weiler1986],whichinherentlyrepresentsmanifold,oriented
ratherthantheparticularmeshconnectivity.
polygonalmeshes—theheartofourcontributionisacontinuous
parameterizationforhalfedgemeshconnectivity. DirectMeshLearning. SeeIER[Liuetal.2020b],PointTriNet[Sharp
The main idea is to represent mesh connectivity by first con- andOvsjanikov2020],DelaunaySurfaceElements(DSE)[Rakoto-
structingasetofedgesandhalfedges,andthenconstructingthe saona et al. 2021], DMesh [Son et al. 2024]. Like ours, these ap-
so-callednextrelationshipamongthosehalfedgestoimplicitlyde- proachesaimtodirectlylearnstructuredmeshconnectivity.How-
finethefacesofthemesh.Weintroduceaparameterizationofedge ever, our approach offers a guarantee of manifoldness, and can
adjacencyandnextrelationshipswithlow-dimensional,per-vertex encodegeneralpolygonalmeshes.Additionally,wedemonstratethe
embeddings.Theseembeddings,byconstruction,alwaysproducea abilitytoencodeconciseartist/CAD-liketessellationviacoupled
manifoldhalfedgemeshwithoutadditionalconstraints.Moreover, learningofvertexpositionsandconnectivity,ratherthangenerat-
theper-vertexembeddingisstraightforwardtopredictasaneural ingfacesamongaroughuniformly-sampledpointset.Conversely,
networkoutputanddemonstratesfastconvergenceduringopti- someofthesemethodsscaletohighresolutionoutputs,compared
mization.Thecontinuouspropertyofourrepresentationfacilitates to our small-medium meshes. Figure 2 includes comparisons to
newarchitecturesformeshgeneration,andenablesapplications DMesh[Sonetal.2024]asarepresentativemethodfromthisfamily,
likemeshrepairwithlearning. seealsoadditionalresultsfromDSEinFigure14inthesamesetting.
Wevalidateourrepresentationagainstalternativesforrepresent-
inggraphadjacencyandmeshes,anddemonstratesuperiorsignif- SequenceModeling. SeePolygen[Nashetal.2020],PolyDiff[Al-
icantlyfasterconvergence,whichisfundamentallyimportantfor liegro et al. 2023], MeshGPT [Siddiqui et al. 2023], and the con-
learningtasks.Combinedwithagenerativemodelforvertices,we currentMeshAnything[Chenetal.2024].Theseapproachesuse
large-scalearchitecturestoemitameshonefaceorvertexatatime.
Unlikeourmethod,theygenerallydonotofferanyguaranteesof
2SpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
connectivityorlocalstructure,andallbutPolygenproducetrian- Thetwinandnextoperatorscanbeinter-
glesoup,connectingfacestogetheronlybygeneratingverticesat pretedasapairofpermutationsoverthesetof
coarsely-discretizedcategoricalcoordinates.However,bybuilding next halfedges,thisgroup-theoreticperspectiveis
onprovenparadigmsfromlanguagemodeling,thesemodelshave studiedincombinatoricsasarotationsystem.
beensuccessfullytrainedatverylargescale.Additionally,many Apairofpermutationscanbeinterpretedasa
oftheseapproachessupportonlyunconditionalgeneration,and halfedgemeshaslongas(a)neitheroperator
somearenotpubliclyavailable.Weincludeagalleryofqualitative mapsanyhalfedgetoitself,and(b)twinoperatorisaninvolution,
comparisonsinFigure15. i.e.twin(twin(ℎ)) = ℎ.Thefacesofthemesharetheorbits tra-
versedbyrepeatedlyfollowingthenextoperator(seeinset);we
2.2 GraphLearning furtherrequirethattheseorbitsallhaveadegreeofatleastthree,to
Ourapproachdrawsinspirationfromgraphlearningrepresenta- disallowtwo-sidedfaces.Ourrepresentationwillconstructavalid
tions,whichhaveshownsuccessforgraphsincludinggeneexpres- setoftwinandnextoperatorsfromacontinuousembeddingto
sion[Marbachetal.2012],molecules[Kwonetal.2020],stochas- definemeshconnectivity.
ticprocesses[Backhoff-Veraguasetal.2020],andsocialnetworks
[Gehrkeetal.2003].BasedontheseminalworkofGromov[1987], 3.2 RepresentingEdges
Nickel and Kiela [2017] showed that hyperbolic embedding has Tobegin,considermodelingameshsimplyasagraphG=(V,E),
fundamentalpropertieswhichEuclideanembeddinglacks(arela- laterwewillextendthismodeltocapturemanifoldmeshstructure
tionshipwhichhasbeenwell-studiedinphysics[Bombellietal. viahalfedgeconnectivity(Section3.3).ThevertexsetV canbe
1987;KronheimerandPenrose1967;Meyer1993]),toexploitthege- viewedasaparticularkindofpointcloud,andpointcloudgen-
ometryofspacetimetorepresentgraphs.Inthispaper,weleverage erationisawell-studiedproblem([Nicholetal.2022;Zengetal.
spacetimeembeddings[LawandStam2020;LawandLucas2023] 2022]).Likewise,continuousrepresentationsforgeneratingundi-
toputthisperspectivetoworkforgeneratingmeshes. rectedgraphedgesisaclassictopicingraphrepresentationlearning
[LawandStam2020;NickelandKiela2017].Abasicapproachisto
3 REPRESENTATION associateanadjacencyembedding𝑥 𝑣 ∈R𝑘 witheachvertex,then
Weproposeacontinuousrepresentationforthespaceofmanifold defineanedgebetweentwovertices𝑖,𝑗iftheyaresufficientlyclose
polygonalmeshes,whichrequiresnoconstraintsandissuitablefor w.r.t.somedistancefunctiond:
optimizationandlearning.
E :=(cid:8) {𝑖,𝑗}suchthatd(𝑥 𝑖,𝑥 𝑗) <𝜏(cid:9) (1)
3.1 Background
forsomelearnedthreshold𝜏 ∈ R.Representingtheverticesand
ManifoldSurfaceMeshes. AsurfacemeshM =(V,E,F)consists edgesofameshthenamountstotwovectorsforeachvertex𝑣:a
ofverticesV,edgesE,andfacesF,whereeachvertex𝑣 ∈Vhasa 3Dposition𝑝 𝑣 ∈R3andanadjacencyembedding𝑥 𝑣 ∈R𝑘 .
position𝑝
𝑣
∈R3.Inageneralpolygonalmesh,eachfaceisacyclic
orderingof3ormorevertices.Eachedgeisanunorderedpairof SpacetimeDistance. Wefindthattakingtheadjacencyfeatures𝑥
verticeswhichappearconsecutivelyinoneormorefaces. asEuclideanvectorsunderpairwiseEuclideandistancedeu(𝑥 𝑖,𝑥 𝑗)=
Weareespeciallyconcernedwithgeneratingmesheswhichare ||𝑥 𝑖 −𝑥 𝑗|| 2 isineffective,withpoorconvergenceinoptimization
notjustasoupoffaces,butwhichhavecoherentandconsistent andlearning.Therearemanyotherpossiblechoicesofdistance
neighborhoodconnectivity.Assuch,weconsidermanifold,oriented function for this embedding, but we find the recently proposed
meshes.Manifoldconnectivityisatopologicalpropertywhichdoes spacetimedistance[LawandLucas2023]tobesimpleandhighly
notdependonthevertexpositions:edge-manifoldnessmeanseach effective.Thisdistancefunctionhasdeepinterpretationsinspecial
edgehasexactlytwoincidentfaces,whilevertex-manifoldnessmeans relativity,definingpseudo-Riemannianstructures.Inoursettingthe
thefacesincidentonthevertexformasingleedge-connectedcom-
spacetimedistancedstiscomputationallystraightforward,splitting
ponenthomeomorphictoadisk.Inanorientedmesh,allneighboring thecomponentsof𝑥intoasubvector𝑥s ∈R𝑘s ofspacecoordinates,
faceshaveaconsistentoutwardorientationasdefinedbyacounter- andasubvector𝑥t ∈R𝑘t oftimecoordinates:
clockwiseorderingoftheirvertices.
dst(𝑥 𝑖,𝑥 𝑗)=dst([𝑥 𝑖s,𝑥 𝑖t],[𝑥s 𝑗,𝑥t 𝑗]):=||𝑥 𝑖s−𝑥s 𝑗||2 2−||𝑥 𝑖t−𝑥t 𝑗||2 2, (2)
HalfedgeMeshes. Therearemanypossi-
bledatastructuresformeshconnectivity; where [·,·] denotes vector concatenation. Note that dst is not a
we will leverage halfedge meshes, which distancemetric,andmaybenegative;thisisofnoconcern,aswe
by-constructionencodemanifold,oriented
next simplyneedtothresholditbysome𝜏 ∈Rtorecoveredges,treating
mesheswithpossiblypolygonalfaces,all twin 𝜏 asanadditionaloptimizedparameter.InFigure4weshowthat
usingonlyapairofreferencesperelement. thissignificantlyacceleratesconvergence,seeSection4fordetails.
Asthenamesuggests,halfedgemeshesare halfedge
LossFunction. Attrainingtime,wefittheadjacencyembedding
definedintermsofdirectedface-sides,calledhalfedges(seeinset).
bysupervisingthedistancesunderacrossentropyloss:
Eachhalfedgestorestworeferences:atwinhalfedge,theoppositely-
orientedhalfedgealongthesameedgeinaneighboringface,anda ∑︁ log(cid:0)𝜎(d(𝑥 𝑖,𝑥 𝑗))−𝜏(cid:1)+𝜆 ∑︁ log(cid:0)𝜎(𝜏−d(𝑥 𝑖,𝑥 𝑗))(cid:1) (3)
nexthalfedge,thesubsequenthalfedgewithinthesameface.
𝑖,𝑗∈E
gt
𝑖,𝑗∉E
gt
3Shenetal.
where𝜎isthelogisticfunction(i.e.asigmoid),E gtdenotestheset optimization
ofedgesinthegroundtruthmesh,and𝜆 > 0isaregularization
parameterbalancingpositiveandnegativematches.
3.3 RepresentingFaces
iter. 100 500 1000 6900
To recover faces and manifold connectivity from a graph G =
(V,E), we further propose to parameterize halfedge connectiv-
target meshes
ityforthemesh(Section3.1).GivenV andE,weconstructthe (triangle)
halfedgesetbysplittingeachedge𝑒
𝑖𝑗
betweenvertices𝑖,𝑗intotwo
oppositely-directedhalfedgesℎ 𝑖𝑗,ℎ 𝑗𝑖.Thispairingtriviallyimplies
thetwinrelationshipsastwin(ℎ 𝑖𝑗) = ℎ 𝑗𝑖;wethenonlyneedto
target mesh
specifythenextrelationshipstocompletethehalfedgemeshand
(n-gon)
definethefaceset. iter. 10 30 50 70
Neighborhood Orderings. The
Fig.2. Fittingthegroundtruthconnectivityofasinglemeshtessellated
nextoperatordefinesacyclicper- withtrianglesandn-gons.
mutationwithasingleorbitonthe
halfedgesoutgoingfromeachver- next withoutviolatingthesingle-orbitconstraint.Theseneighborhood
tex.Thusthetaskofassigningthe matchingsthenimplyhalfedgeconnectivityas
nextoperator(andimplicitly,the local ordering
potentially-polygonalfacesofthe next(ℎ 𝑖𝑗):=ℎ 𝑘𝑖 for 𝑘 =matchΦ𝑖(𝑗). (6)
mesh)comesdowntolearningthispermutationforeachvertex.
RepresentingNeighborhoodOrderings. Foreachvertex,wedefine Thiscompletesthehalfedgemeshrepresentation.Faces,poten-
atripletofcontinuouspermutationfeatures:𝑦root,𝑦prev,𝑦next ∈R𝑘p . tiallyofanypolygonaldegree,canthenbeextractedasorbitsofthe
Theseareusedtodeterminethelocalcyclicorderingofincident nextoperator.
edges.Precisely,inthelocalneighborhoodofeachvertex𝑖 ∈Vwith
degree𝐷,foreachpairofedges𝑒 𝑖𝑗,𝑒 𝑖𝑘,wecombinethefeaturesof 4 VALIDATION
vertices𝑖,𝑗 and𝑘viaascalar-valuedfunction𝐹(𝑦 𝑖root,𝑦p 𝑗rev,𝑦 𝑘next)
Inthissection,weevaluatethebasicpropertiesofourmethod,by
(seeSection4.3).Gatheringthesepairwiseentriesyieldsanonnega-
directlyoptimizingtofitbothindividualmeshesandcollectionsof
tivematrixinthelocalneighborhoodofeachvertex:
meshes,aswellasablatingdesignchoices.
Φ𝑖 ∈R𝐷×𝐷, Φ𝑖 :=𝑒𝐹(𝑦 𝑖root,𝑦p 𝑗rev,𝑦 𝑘next),
(4)
𝑗𝑘
4.1 EncodingaGivenMesh
where each row corresponds to an incident edge. We then use
Themostbasictaskforameshrepresentationistodirectlyfitit
Sinkhornnormalization[Sinkhorn1964]torecoveradoubly-stochastic
toencodeaparticularmesh.Thoughstraightforwardinprinciple,
matrix,Φ¯𝑖
,representingasoftenedpermutationmatrix[Adamsand
thisoptimizationcouldfailifarepresentationisunabletorepresent
Zemel2011].
allpossiblemeshes,oriflocalminimaandslowconvergencemake
fittingineffectiveinpractice.Weconsiderthreedifferentchallenging
LossFunction. Attrainingoroptimizationtime,wesimplysu-
pervisethematricesΦ¯ directlywiththegroundtruthpermutation mesheswiththinparts,anisotropicfaces,andvaryinggeometric
details.Foreachsingleshape,weoptimizetoencodeitsconnectivity
matricesusingbinarycross-entropyloss:
∑︁ −log(Φ¯𝑖 𝑗𝑘), (5)
w fui nth cto iou nr spe fr r- ov mert Ee qx ue am tib oe ndd 3in ag ns d( 5𝑥 .𝑖, I𝑦 n𝑖ro Fo it g, u𝑦 r𝑖p ere 2v, w𝑦 𝑖n eex st h) ou wsin thg eth re eslo us ls
t
{𝑖,𝑗,𝑘}∈N ofthisoptimizationwithourapproach,aswellaswiththerecent
gt
DMesh[Sonetal.2024],whichproposesaDelaunay-basedmesh
whereN gtisthesetofallnextrelationshipsingroundtruthmesh
representation.Ourmethodnotonlyconvergesmuchfastertothe
suchthatnext(ℎ 𝑖𝑗) =ℎ 𝑗𝑘.Notethatwedonotneedtosupervise
correct connectivity,but also is applicableto polygonalmeshes,
theremainingentriesofΦ¯𝑖
,whichisalreadySinkhorn-normalized.
makingitmoresuitableforgeneralmeshgenerationtasks.Further
experimentaldetailsareprovidedintheSupplement.
ExtractingMeshes. Atinferencetimetoactuallyextractamesh,
foreachvertexneighborhoodweseekthelowest-costmatching
underthepairwisecostmatrix−Φ¯𝑖
,amongonlythosematchings
whichformasingleorbit.Tocomputethismatching,wefirstcom-
putetheoptimalunconstrainedlowest-costmatching[Jonkerand
Volgenant1988];oftenthismatchingalreadyformsasingleorbit,
butwhenitdoesnotwefallbackonagreedyalgorithmwhichstarts
atanarbitraryentryandrepeatedlytakesthenextlowest-costentry Fig.3. Meshesencodedbyourautodecoder.
4
hseMD
sruOSpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
1
showstheresults.Wefindelementwisemultiplicationfollowedby
Spacetimedistance
summationofallelementstobemosteffective.Precisely,weuse
0.5 Euclidean distance
0
Dotproduct 𝐹(𝑦 𝑖root,𝑦p 𝑗rev,𝑦 𝑘next):=trace(cid:0) diag(𝑦p 𝑗rev)diag(𝑦 𝑖root)diag(𝑦 𝑘next)(cid:1),
0 500 1000 1500 2000 (7)
number of iterations
wherediagdenotesconstructingadiagonalmatrixfromavector.
Fig.4. Comparisonofconvergencespeedwithdifferentdistancefunctions.
5 APPLICATION:LEARNINGTOMESH
1
Equippedwithacontinuousrepresentationformanifoldpolygonal
Element-wise product
Element-wise maximum meshes,wecanthenbeginlarge-scalelearningatoptherepresenta-
0.5
Addition tion.Inthissection,weintegrateSpaceMeshwitha3Dgenerative
Concatenation
modeltogeneratemeshesconditionedongeometryprovidedasa
0
0 5 10 15 20 25 30 pointcloud.Thisconditionedmodelcanthenbedirectlyappliedto
meshrepairwithoutfine-tuning(Section5.5).
Fig.5. Comparisonofconvergencespeedwithdifferentpermutationfeature
reductionfunctions.
5.1 ModelArchitecture
4.2 FittingMeshCollections
Ourmodelarchitecture(Figure6),consistsofthreemodules:apoint
Asanextbasictestoftheabilityofourmethodtoencodecollections cloudencodingnetworkforprocessinggeometryinformation,a
ofshapesinalearningsetting,wetrainasimpleauto-decoderarchi- vertexdiffusionmodeltogenerate3Dlocationsforvertices,anda
tectureonasubsetof200shapesfromtheThingi10kdataset,achal- connectivitypredictionnetworktopredictper-vertexembeddings.
lengingsetofreal-worldmodelsoriginallyfor3Dprinting[Zhou
andJacobson2016].Tobeclear,wedonotaimtodemonstratedown- PointCloudEncoder. WeencodethepointcloudusingPVCNN[Liu
streamlearningtaskswiththisexperiment,wesimplyvalidatethat etal.2019]togeneratethefeaturevolumesatmultiplespatialres-
ourrepresentationcansimultaneouslyrepresentavarietyofcom- olutions.Thesefeaturevolumes,asgeometrycontext,guidethe
plexshapes,evenwhentheembeddingsareparameterizedbya subsequentmeshgeneration.Notethatthisinputpointcloudis
neuralnetwork,seeSection5forlarge-scalelearningandapplica- not theresultingmeshvertexset,itisconditioninginformation
tions.Inparticular,hereweallocatealatentcodeforeachmesh,and indicatingthegeometrythatwearetryingtogenerateameshof.
optimizethoselatentcodesaswellastheparametersofasimple
VertexPositionGenerationNetwork. Were-purposePoint-E[Nichol
transformermodel[Vaswanietal.2017]thatdecodeseachlatent
etal.2022],adiffusiontransformernetworkthatwasoriginallyde-
codeintothemesh,intheformofper-vertexpositionsandcon-
signedforpointcloudgeneration,togeneratesparsemeshvertices
nectivityembeddingsofourrepresentation.SeetheSupplement
conditionedonthegeometrycontextfromtheencoder.Specifically,
forfurtherexperimentaldetails.AsshowninFigure3,ourmodel
wefirstinitializethevertexpositionbysamplingfromaGaussian
faithfullyoverfitstheshapecollection.Quantitatively,theencoded
distribution,anditerativelydenoisethevertexlocationthroughthe
meshesachieveameanL2lossof0.00062,anF1scoreof0.99for
diffusiontransformer.Ateachdenoisingstep,wefeedtheinput
adjacencyprediction,andanaccuracyof0.98forpermutationpre-
tothetransformerbyconcatenatingthevertices’positionswith
dictions.Thisispositiveevidencethattherepresentationisable
featuresthataretri-linearlyinterpolatedwiththemulti-resolution
tosimultaneouslyrepresentmanycomplexshapes,evenwithsig-
featurevolumesfromtheencodertocapturethegeometryinforma-
nificantgeometriccomplexityandthenonconvexityoftheneural
tion.Ifneeded,wehandlevaryingvertexcountsbypaddingtoa
parameterization.
predefinedmaximumsize,andadditionallydiffusingabinarymask
4.3 AblatingDesignChoices ateachvertextoindicatewhichverticesareartificialpadding.
SpacetimeDistance. Wefindspacetimedistancetobeadramati-
callymoreeffectiverepresentationthanEuclideanorothermetrics
todefineadjacencyembeddings(Section3.2),inthesensethatit PVCNN
canbeoptimizedmuchmoreeasily.Todemonstratethis,wefitthe
edgesofthebridgemeshappearingonthebottomrightofFigure4
using each of three formulations for d(𝑥 𝑖,𝑥 𝑗): (1) the spacetime
distanceintroducedinSection3.2,(2)thesquaredEuclideandis- Vertex Diffusion Model
tance∥𝑥 𝑖 −𝑥 𝑗∥2 2,and(3)thenegativedotproduct−𝑥 𝑖⊤𝑥 𝑗.Figure4
extract
shows the speed of convergence—spacetime distance converges
Transformer
muchfastercomparedtootherdistanceformulations,whichwe
observedconsistentlyacrossallexperiments. connectivity per-vertex
prediction embeddings
PermutationFeatureReduction. Wealsoinvestigateseveralchoices diffusion
forthepermutationfeaturereductionfunction𝐹 (Equation7),in-
cludingelementwisemaximum,addition,orconcatenation.Figure5 Fig.6. Networkarchitectureforlearningtogeneratemeshes.
5
erocs
1f
noitatumrep
ycaruccaShenetal.
minimal QEM quad Table1. Accuracyandqualitystatisticsformeshreconstruction.
isotropic
n-gon simplified dominant
Method CD(10−3)↓ F1↑ ECD(10−2)↓ EF1↑ #V #F IN↓
Ours PSR 46.35 0.44 56.81 0.03 2406 4736 63.31
PSR∗ 46.72 0.42 51.86 0.03 494 968 61.61
OccNet 11.31 0.47 33.08 0.08 7344 14688 48.53
Pixel2Mesh 6.37 0.48 29.52 0.09 2466 4928 52.03
Input Ours 1.39 0.66 3.21 0.42 512 1818 34.54
5.3 LearningMeshesfromtheABCDataset
Ground
Truth Toevaluatelearningatscaleonarealisticdataset,trainourmodelon
ABCdataset[Kochetal.2019a],whichconsistsofwatertighttriangle
meshes of CAD shapes with isotropic triangle distribution. The
meshesintheABCdatasetexhibitconsiderablediversity,featuring
Fig.7. Conditionedonthesamegeometry,ourmodelcangeneratedifferent
bothsharpandsmoothcurvedgeometricfeatures.Weemployeda
stylesofmeshesdependingtothedistributionitwastrainedon.Each
benchmark[Kochetal.2019b]subsetof10,000shapes,allwith512
rowdenotesastyleofmesh,forwhichweconstructadatasetofmeshed
vertices,randomlysplitinto80%fortrainingand20%fortesting.To
primitivesurfacesandfitourmodel.Becauseourmodelisgenerative,it
obtaintheinputconditioningpointcloud,weuniformlysampled
matchesthedistributionbutdoesnotexactlyreplicatevertexpositionsor
connectivity. 2048pointsfromthemeshsurface.
VertexConnectivityPredictionNetwork. Weleverageatransformer
Baselines. Wecompareourmodelagainstbothclassicandlearning-
architecture [Vaswani et al. 2017] to predict the per-vertex con-
based point cloud reconstruction methods. As a representative
nectivity embeddings given vertex positions. Similar to the ver-
classicapproach,wecomparetoPoissonSurfaceReconstruction
texpositiongenerationnetwork,weconcatenatevertexposition
(PSR)[Kazhdanetal.2006]asimplementedinOpen3D[Zhouetal.
withtheinterpolatedfeaturefromtheencoderforeachvertex,and
2018],withmeshesextractedviamarchingcubes[Lorensenand
predicttheadjacencyembeddings𝑥 andpermutationembeddings
Cline 1998]. We also consider isotropic remeshing [Hoppe et al.
𝑦root,𝑦prev,𝑦next.Weremovethepositionalembeddingfromthe
1993] on the output of Poisson reconstruction to obtain a more
originaltransformerandpredicttheembeddingsforallthevertices compactmeshtessellation,whichisdenotedPSR∗.Forrepresen-
simultaneouslybyusingtheself-attentionacrossthevertices.
tativelearning-basedapproaches,wechoosePixel2Mesh[Wang
etal.2018],whichdeformsatemplatespheretogenerateamesh,
TrainingDetails. Wetrainalltheneuralnetworkstogether.To andOccNet[Meschederetal.2019],whichpredictsanimplicitfield
trainthevertexpositiongenerationnetwork,weadoptthe𝜖-prediction andextractsthemeshusingMarchingCubes[LorensenandCline
fromthediffusionmodel[Hoetal.2020;Nicholetal.2022].Totrain 1998]afterwards.Forafaircomparisonamongdeeplearningbased
theconnectivitygenerationmodel,wecombinethelossesEqua- methods,weadoptthesamepointcloudencoderasourapproach.
tion3and5,supervisingonmeshesfromthedataset.Furtherdetails
areprovidedintheSupplement. Metrics. Ourprimarygoalistoevaluatetheabilitytocapture
thedesireddistributionofsurfacediscretization,asmeasuredby
intrinsicmeshstatisticssuchasedgelengthsandcorneranglesfor
5.2 BasicValidationonaSyntheticDataset eachpolygon.Furthermore,althoughourmethodisnotdirectly
Ourmodellearnstofitdistributionsofmeshes;thetessellationpat- designedtominimizereconstructionerror,weadditionallyevaluate
ternandelementshapesofgeneratedmesheswillmimicthetraining ourmethodagainstbaselinesonhowwellthegeneratedmeshes
population.Wefirstdemonstratethisbehaviorwithasimplesyn- alignwithgroundtruthgeometry.Tothisend,wefollowthemethod-
theticdataset,constructedbygeneratingshapesasaunionofran- ologyfromNDC[Chenetal.2022]andcomputeChamferDistance
domlyarrangedcubes,tetrahedra,andspheres.Foreachshape,we (CD), F-Score (F1), Edge Chamfer Distance (ECD), Edge F-Score
extracta3Diso-surfaceusingDualMarchingCubes[Nielson2003], (EF1),and thepercentageofInaccurate Normals(IN> 10◦)with
andmeshitaccordingtoseveralstrategies:(1)isotropicremesh- respecttothegroundtruthmesh.Adetaileddescriptionofthese
ing[Hoppeetal.1993]withMeshlab[Cignonietal.2008](2)planar metricsisprovidedintheSupplement.
decimationfromBlender[Community2018]tocreateN-gonmesh.
(3)QEMforsurfacesimplification[GarlandandHeckbert1997] Results. AsshowninFigure9andTable1,bothqualitativeand
fromMeshlab,and(4)InstantMesh[Jakobetal.2015]tocreatea quantitativeresultsdemonstratethatourmethodoutperformsbase-
quad-dominantmeshwiththeofficialimplementation linesunderthetargetmetrics,particularlyinrecoveringsharpfea-
InFigure7,weshowhowtrainingoneachofthesedatasetscauses tures.Theverticesandedgesalignaccuratelywithsharpfeatures,
ourmodeltogeneratedifferentstylesofmeshesasoutputs.Thefour highlightingtheadvantageofdirectlygeneratingmeshesasthe
models,wheneachgiventhesamepointcloudasinputspecifying outputrepresentation.AsshowninFigure8,thedistributionof
thedesiredgeometry,producerespectively(1)isotropictriangle elementshapesfromourgeneratedmeshesalignsmuchbetterwith
meshes,(2)minimalplanar-decimatedmeshes,(3)QEM-simplified thegroundtruththanthebaselines,demonstratingtheabilityofour
meshes,and(4)quad-dominantmeshes. modeltopredictconnectivitywhichalignswiththetargettraining
6SpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
Fig.8. Quantitativecomparisonoftheintrinsicqualityofreconstructedmeshes.Ourmethodproducesmesheswithdistributionsofedgelengthsandcorner
anglesmorecloselyalignedwiththegroundtruth.Thisisbecauseourmodellearnsthesurfacediscretizationfromthedata,unlikeothermethodsthat
primarilyfocusonreconstructinggeometry.Weadditionallyreportthepercentageoffaceswithself-intersectionsineachmesh.
Fig.10. Byleveragingadiffusionmodel,wecangeneratedifferentmeshes
fromthesameinputcondition.Noticehowthechairlegsaremodeledwith
differenttopologies,whichallconformtotheinputcondition.
DatasetDetails. Asinpriorwork[Nashetal.2020;Siddiquietal.
2023],wenotethattherawmeshesfromShapeNetconsistlargelyof
non-manifoldmesheswithduplicatedfacesandT-junctionsatinter-
sections,andthuswepreprocessallshapesbyremovingduplicated
facesandapplyingplanardecimationwithvaryingthresholdsto
simplifythemintominimalpolygonalmeshes.Afterthispreprocess-
ing,themajorityoftheshapearestillnon-manifold,makingthem
unsuitableforourgoalofgeneratingmanifoldmesheswithclean
connectivity.Wethusremoveallnon-manifoldshapes,resulting
inatotalof20,255shapes.Weadheretoan80-20train-testsplit
andrandomlysample2,048surfacepointsasgeometryconditioning
input.Additionally,weapplyrandomscalingaugmentationduring
training.Unlikepreviousautoregressivemethods,ourapproach
doesnotrequirequantizationofvertices.
Fig.9. GeneratedmeshesfortheABCDataset. Baselines. Many relevant baselines [Alliegro et al. 2023; Nash
etal.2020;Siddiquietal.2023]donothaveeithertrainingorinfer-
population.Notethatalthoughourrepresentationguaranteesman- encecodeavailable,andregardlesstherearemanydifferencesin
ifoldconnectivity,theremaystillbegeometricself-intersections experimentalprotocolsandtargettask.Assuch,weinsteadfocus
betweenfaces.Wereportthefractionoffacesineachmeshwith onqualitativecomparisonstogiveintuitionaboutthedifferences
self-intersectionsinFigure8,andprovidefurtherdiscussioninSec- betweenthesemethods,primarilyinregardtomeshquality.
tion6.
Results. Figure15showsavarietyofresultsgeneratedbyour
method,aswellasasamplingofpublishedresultsfrombaselines.
5.4 LearningMeshesfromtheShapeNetDataset
Ourmethodgeneratessharpandcompactpolygonalmeshesthat
Followingrecentworkonmeshgeneration[Alliegroetal.2023; matchwiththeinputconditionandareguaranteedtobemanifold.
Gaoetal.2022;Nashetal.2020;Siddiquietal.2023],wefurther Wealsonoteapromisingdiversityinouroutputsonthisdataset:
evaluateourmodelonShapeNetdataset[Changetal.2015]. becauseourmodelusesaprobabilisticdiffusionmodeltogenerate
7
tupnI
RSP
*RSP
teNccO
hseM2lexiP
sruO
hturT
dnuorGShenetal.
mark bad
regions regenerate
delete pretrained region
mesh model
sample points as
geometry conditioning
Fig.11. Ourtrainedconditionedmeshingmodelcanberepurposedfor
meshrepair.Forameshwithgoodgeometrybutpoortessellationincertain Fig.13. Failurecasesfromourlearningtomeshmodel.Althoughthey
regions(highlightedinred),theusercanmarkthoseregionsandpassthe stillhavemanifoldconnectivity,largeerroneousfacesandexcessiveself-
meshtoourmodeltore-predictbothverticesandconnectivity,effectively intersectionsyieldatangledmeshwithpoorgeometricaccuracy.
repairingthemesh(highlightedingreen).
ofthecompleteshapeasinput,withafocusonre-generatingsurface
discretizationwhilepreservinggeometry.MeshFixisdesignedonly
Input Ours SeMIGCN MeshFix forholefillingandcannotgeneratearepairedmeshconditioned
onthegeometry.Incontrast,SeMIGCNre-meshestheshapefor
runningGCN,resultinginanoverlydensemeshthatmightnot
bedesirable.Wecomparequantitativelywith100randomlysam-
pledexamplesfromtheABCdatasetvalidationshapes.SpaceMesh
achievedaChamferDistance(CD)of0.77(10−3)anda0.76F1score.
Thebaselines,SeMIGCNandMeshFix,achieveaCDof39.50(10−3)
and31.59(10−3),andanF1scoreof0.57and0.72,respectively.
Fig.12. Avisualcomparisonofmeshrepairmethods.Notethatourmethod
additionallytakessurfacepointssampledfromthewholemeshasinput, 6 DISCUSSION
unlikeothermethodswhichuseonlythepartialmesh.
ScalabilityandRuntime. Ourapproachrepresentsdiscreteconnec-
vertices,weareabletoproducedistinctmeshesconditionedonthe tivityviaafixed-sizecontinuousembeddingper-vertex.Concrete
samepointcloudinputbyrepeatedlysamplingthemodel(Figure10). resultsaboutthesizeofsuchanembeddingneededtorepresent
allpossiblediscretestructuresremainanopenproblemingraph
5.5 MeshRepair theory[Nickeletal.2014;NickelandKiela2017].Inpractice,we
findlow-dimensionalembeddings𝑘 < 10tobesufficienttorep-
Lastly,wedemonstratetheapplicationofourmodeltothedown-
resenteverymeshinourexperiments.Encodinga10,000-vertex
streamgeometryprocessingtaskofmeshrepair.Asillustratedin
meshviadirectoptimization,asshowninFigure2,convergesin
Figure11,weenvisionaworkflowwhereauseridentifiesaregion
600iterations(approximately2minutes)with𝑘𝑝
=6.
ofameshwithpoortessellationsuchasself-intersections,skinny
For learning, the bottleneck is memory usage in transformer
triangles,ornon-manifoldstructures,andwishestore-triangulate
blocks.Wedemonstrategenerationsupto2,000verticesintheauto-
thatregioninawaythatseamlesslyblendswiththesurrounding
decodersetting;thisismodestcomparedtohigh-resolutionmeshes,
mesh.Weshowthatwecanrepurposeourmodelforthistaskwith-
butitalreadycapturesmanyCADandartist-createdassets,and
outretraining,byviewingitasmeshinpainting,inthesamesense
exceedsotherrecentdirectmeshgenerationworks(e.g.,around
thatimagemodelsareusedtoinpaintundesiredregionsofimages
200 vertices in MeshGPT [Siddiqui et al. 2023]). Our generative
accordingtosomeconditioningwhilematchingthesurrounding
modeltakeslessthan2secondstogenerateasinglemesh,which
context.Weinpaintthemeshbysamplingapointcloudfromthe
isnotablyfasterthanrecentauto-regressivemodelslikeMeshGPT,
desiredgeometryandapplyingourgenerativemodel,projecting
whichrequire30-90seconds.Allinferenceandoptimizationtimes
duringdiffusiontoensurethefixedregionoftheinputmeshis
aremeasuredonanNVIDIAA6000GPU.
retained—seetheSupplementforanin-depthexplanation.Notethat
MeshGPT[Siddiquietal.2023]alsodemonstratedcompletionofa
Limitations. Althoughourrepresentationguaranteesmanifold
partialmesh;however,itwaslimitedtobottom-upcompletiondue
connectivity,itmaycontainothererrorssuchasself-intersections,
toauto-regressiveinferencewithsortedvertices.
spurioushigh-degreepolygons,orsignificantlynon-planarfaces.
Results. WevisualizetheresultsinFigure12.Ourapproachgen- Thefrequencyofsucherrorsdependsonhowtherepresentationis
erateshigh-qualitypatchestofilltheremovedregionsinthepartial generatedoroptimized:oftentheyhavelittleeffectontheapproxi-
mesheswhilepreservingthegeometryandconnectivityoftheinput. matedsurface(Figure9),butinothercasestheymaysignificantly
Forcomparison,wealsoincludethemostsimilarresultsofwhich degradethegeneratedgeometry,asshowninFigure13.Notethat
weareaware:aclassicmeshrepairframework,MeshFix[Attene suchartifactsarenotalwayserroneous—meshesdesignedbyartists
2010],andarecentlearning-basedmethod,SeMIGCN[Hattorietal. oftenintentionallyincludeself-intersections;ifdesired,wecould
2024].However,notethatthisisnotexactlyanapples-to-apples potentiallymitigateself-intersectionsbypenalizingthemwithreg-
comparison,ourmethodadditionallytakesthesurfacepointcloud ularizersduringtraining.
8SpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
Ourimplementationdoesnothandleopensurfaces,thiscould GET3D PolyGen MeshGPT
beaddressedbypredictingaflagforboundaryedgesmuchlikewe
predictamaskforpaddedvertices.Also,likeotherdiffusion-based
generativemodels,ourlarge-scalelearningexperimentsmaypro-
ducenonsensicaloutputsfordifficultorout-of-distributioninput.
FutureWork. Lookingforward,weseemanypossibilitiestobuild
uponourrepresentationfordirectlygeneratingmeshesinlearning
pipelines.Intheshortterm,thiscouldmeangeneratingconnectivity
embeddingsaswellasvertexpositionsfromadiffusionmodel,and
inthelongerterm,onemightevenfitSpaceMeshgeneratorsinan
unsupervisedfashionusingenergyfunctionstoremovethereliance
onmeshdatasetsforsupervisionentirely.
ACKNOWLEDGMENTS
TheauthorsaregratefultoYawarSiddiquiforprovidingtheresults
ofMeshGPTandPolygen,aswellastheanonymousreviewersfor
theirvaluablecommentsandfeedback.
Input Ours Ground Truth
DSE target meshes
(triangle)
Fig. 14. Fitting the ground truth connectivity of a single mesh with
DSE[Rakotosaonaetal.2021].TheexperimentsettingisdescribedinSec-
tion4.1.HereDSEisoverfittoencodeasingleshape,buteventhenits
representationstruggleswhenverticesaresparseandgeometryishighly
nonconvex.
Fig.15. Visualcomparisonofgeneratedmeshesfrommodelstrainedon
ShapeNet.Thetoppartshowcasesresultsfromthreeunconditionedmesh
generationmethods:GET3D,PolyGen,andMeshGPT.Thebottompart
showsmeshesgeneratedbyourmodel,whichtakespointcloudsasinput.
9Shenetal.
REFERENCES MichaelKazhdan,MatthewBolitho,andHuguesHoppe.2006. Poissonsurfacere-
RyanPrescottAdamsandRichardSZemel.2011.Rankingviasinkhornpropagation. construction.InProceedingsofthefourthEurographicssymposiumonGeometry
arXivpreprintarXiv:1106.1925(2011). processing,Vol.7.
AntonioAlliegro,YawarSiddiqui,TatianaTommasi,andMatthiasNießner.2023.Poly- DiederikPKingmaandJimmyBa.2014.Adam:Amethodforstochasticoptimization.
Diff:Generating3DPolygonalMesheswithDiffusionModels. arXivpreprint arXivpreprintarXiv:1412.6980(2014).
arXiv:2312.11417(2023). SebastianKoch,AlbertMatveev,ZhongshiJiang,FrancisWilliams,AlexeyArtemov,
MarcoAttene.2010.Alightweightapproachtorepairingdigitizedpolygonmeshes. EvgenyBurnaev,MarcAlexa,DenisZorin,andDanielePanozzo.2019a.ABC:A
Thevisualcomputer26(2010),1393–1406. BigCADModelDatasetForGeometricDeepLearning.InTheIEEEConferenceon
JulioBackhoff-Veraguas,DanielBartl,MathiasBeiglböck,andManuEder.2020.All ComputerVisionandPatternRecognition(CVPR).
adaptedtopologiesareequal. ProbabilityTheoryandRelatedFields178(2020), SebastianKoch,AlbertMatveev,ZhongshiJiang,FrancisWilliams,AlexeyArtemov,
1125–1172. EvgenyBurnaev,MarcAlexa,DenisZorin,andDanielePanozzo.2019b.Abcdataset
LucaBombelli,JoohanLee,DavidMeyer,andRafaelDSorkin.1987.Space-timeasa normalestimationbenchmark.(2019).
causalset.Physicalreviewletters59,5(1987),521. ErwinHKronheimerandRogerPenrose.1967.Onthestructureofcausalspaces.In
AlexandreBoulchandRenaudMarlet.2022. Poco:Pointconvolutionforsurface MathematicalProceedingsoftheCambridgePhilosophicalSociety,Vol.63.Cambridge
reconstruction.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand UniversityPress,481–501.
PatternRecognition.6302–6314. YoungchunKwon,DongseonLee,Youn-SukChoi,KyohamShin,andSeokhoKang.
AngelXChang,ThomasFunkhouser,LeonidasGuibas,PatHanrahan,QixingHuang, 2020.Compressedgraphrepresentationforscalablemoleculargraphgeneration.
ZimoLi,SilvioSavarese,ManolisSavva,ShuranSong,HaoSu,etal.2015.Shapenet: JournalofCheminformatics12,1(2020),1–8.
Aninformation-rich3dmodelrepository.arXivpreprintarXiv:1512.03012(2015). MarcLawandJosStam.2020.Ultrahyperbolicrepresentationlearning.Advancesin
WenzhengChen,HuanLing,JunGao,EdwardSmith,JaakkoLehtinen,AlecJacobson, neuralinformationprocessingsystems33(2020),1668–1678.
andSanjaFidler.2019.Learningtopredict3dobjectswithaninterpolation-based MarcT.LawandJamesLucas.2023.SpacetimeRepresentationLearning.InTheEleventh
differentiablerenderer.Advancesinneuralinformationprocessingsystems32(2019). InternationalConferenceonLearningRepresentations. https://openreview.net/forum?
YiwenChen,TongHe,DiHuang,WeicaiYe,SijinChen,JiaxiangTang,XinChen, id=qV_M_rhYajc
ZhongangCai,LeiYang,GangYu,etal.2024.MeshAnything:Artist-CreatedMesh Chen-HsuanLin,JunGao,LumingTang,TowakiTakikawa,XiaohuiZeng,XunHuang,
GenerationwithAutoregressiveTransformers. arXivpreprintarXiv:2406.10163 KarstenKreis,SanjaFidler,Ming-YuLiu,andTsung-YiLin.2023.Magic3D:High-
(2024). ResolutionText-to-3DContentCreation.InIEEEConferenceonComputerVision
ZhiqinChen,AndreaTagliasacchi,ThomasFunkhouser,andHaoZhang.2022.Neural andPatternRecognition(CVPR).
DualContouring.ACMTransactionsonGraphics(SpecialIssueofSIGGRAPH)41,4 OrLitany,AlexBronstein,MichaelBronstein,andAmeeshMakadia.2018.Deformable
(2022). ShapeCompletionwithGraphConvolutionalAutoencoders.CVPR(2018).
ZhiqinChen,AndreaTagliasacchi,andHaoZhang.2020.BSP-Net:GeneratingCompact Hsueh-TiDerekLiu,VladimirG.Kim,SiddharthaChaudhuri,NoamAigerman,and
MeshesviaBinarySpacePartitioning.ProceedingsofIEEEConferenceonComputer AlecJacobson.2020a.NeuralSubdivision.ACMTrans.Graph.39,4(2020).
VisionandPatternRecognition(CVPR)(2020). LingjieLiu,JiataoGu,KyawZawLin,Tat-SengChua,andChristianTheobalt.2021.
PaoloCignoni,MarcoCallieri,MassimilianoCorsini,MatteoDellepiane,FabioGanov- MeshGraphormer.InICCV.
elli,GuidoRanzuglia,etal.2008.Meshlab:anopen-sourcemeshprocessingtool..In MinghuaLiu,XiaoshuaiZhang,andHaoSu.2020b.Meshingpointcloudswithpredicted
EurographicsItalianchapterconference,Vol.2008.Salerno,Italy,129–136. intrinsic-extrinsicratioguidance.InComputerVision–ECCV2020:16thEuropean
BlenderOnlineCommunity.2018. Blender-a3Dmodellingandrenderingpackage. Conference,Glasgow,UK,August23–28,2020,Proceedings,PartVIII16.Springer,
BlenderFoundation,StichtingBlenderFoundation,Amsterdam.http://www.blender. 68–84.
org ZhijianLiu,HaotianTang,YujunLin,andSongHan.2019.Point-voxelcnnforefficient
PhilippErler,PaulGuerrero,StefanOhrhallinger,NiloyJMitra,andMichaelWim- 3ddeeplearning.Advancesinneuralinformationprocessingsystems32(2019).
mer.2020. Points2surflearningimplicitsurfacesfrompointclouds.InEuropean WilliamELorensenandHarveyECline.1998.Marchingcubes:Ahighresolution3D
ConferenceonComputerVision.Springer,108–124. surfaceconstructionalgorithm.InSeminalgraphics:pioneeringeffortsthatshaped
JunGao,TianchangShen,ZianWang,WenzhengChen,KangxueYin,DaiqingLi,Or thefield.347–353.
Litany,ZanGojcic,andSanjaFidler.2022. GET3D:AGenerativeModelofHigh DanielMarbach,JamesCCostello,RobertKüffner,NicoleMVega,RobertJPrill,DiogoM
Quality3DTexturedShapesLearnedfromImages.InAdvancesInNeuralInformation Camacho,KyleRAllison,ManolisKellis,JamesJCollins,andGustavoStolovitzky.
ProcessingSystems. 2012.Wisdomofcrowdsforrobustgenenetworkinference.Naturemethods9,8
MichaelGarlandandPaulSHeckbert.1997.Surfacesimplificationusingquadricerror (2012),796–804.
metrics.InProceedingsofthe24thannualconferenceonComputergraphicsand NissimMaruani,RomanKlokov,MaksOvsjanikov,PierreAlliez,andMathieuDesbrun.
interactivetechniques.209–216. 2023. Voromesh:Learningwatertightsurfacemesheswithvoronoidiagrams.In
JohannesGehrke,PaulGinsparg,andJonKleinberg.2003.Overviewofthe2003KDD ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.14565–
Cup.AcmSigkddExplorationsNewsletter5,2(2003),149–151. 14574.
MikhaelGromov.1987.Hyperbolicgroups.InEssaysingrouptheory.Springer,75–263. NissimMaruani,MaksOvsjanikov,PierreAlliez,andMathieuDesbrun.2024.PoNQ:a
ThibaultGroueix,MatthewFisher,VladimirG.Kim,BryanC.Russell,andMathieu NeuralQEM-basedMeshRepresentation.InProceedingsoftheIEEE/CVFConference
Aubry.2018.AtlasNet:APapier-MâchéApproachtoLearning3DSurfaceGeneration. onComputerVisionandPatternRecognition.3647–3657.
CVPR(2018). LarsMescheder,MichaelOechsle,MichaelNiemeyer,SebastianNowozin,andAndreas
RanaHanocka,GalMetzer,RajaGiryes,andDanielCohen-Or.2020.Point2Mesh:A Geiger.2019.OccupancyNetworks:Learning3DReconstructioninFunctionSpace.
Self-PriorforDeformableMeshes.ACMTransactionsonGraphics(TOG)39,4(2020), InProceedingsIEEEConf.onComputerVisionandPatternRecognition(CVPR).
1–12. DavidAMeyer.1993.SphericalcontainmentandtheMinkowskidimensionofpartial
ShotaHattori,TatsuyaYatagawa,YutakaOhtake,andHiromasaSuzuki.2024.Learning orders.Order10(1993),227–237.
Self-PriorforMeshInpaintingUsingSelf-SupervisedGraphConvolutionalNetworks. CharlieNash,YaroslavGanin,SMAliEslami,andPeterBattaglia.2020.Polygen:An
IEEETransactionsonVisualizationandComputerGraphics(2024). autoregressivegenerativemodelof3dmeshes.InInternationalconferenceonmachine
JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilistic learning.PMLR,7220–7229.
models.Advancesinneuralinformationprocessingsystems33(2020),6840–6851. AlexNichol,HeewooJun,PrafullaDhariwal,PamelaMishkin,andMarkChen.2022.
HuguesHoppe,TonyDeRose,TomDuchamp,JohnMcDonald,andWernerStuetzle. Point-e:Asystemforgenerating3dpointcloudsfromcomplexprompts. arXiv
1993.Meshoptimization.InProceedingsofthe20thannualconferenceonComputer preprintarXiv:2212.08751(2022).
graphicsandinteractivetechniques.19–26. MaximilianNickel,XueyanJiang,andVolkerTresp.2014.Reducingtherankinrela-
JiahuiHuang,ZanGojcic,MatanAtzmon,OrLitany,SanjaFidler,andFrancisWilliams. tionalfactorizationmodelsbyincludingobservablepatterns.AdvancesinNeural
2023.Neuralkernelsurfacereconstruction.InProceedingsoftheIEEE/CVFConference InformationProcessingSystems27(2014).
onComputerVisionandPatternRecognition.4369–4379. MaximillianNickelandDouweKiela.2017. Poincaréembeddingsforlearninghi-
WenzelJakob,MarcoTarini,DanielePanozzo,andOlgaSorkine-Hornung.2015.Instant erarchicalrepresentations. Advancesinneuralinformationprocessingsystems30
Field-AlignedMeshes. ACMTransactionsonGraphics(ProceedingsofSIGGRAPH (2017).
ASIA)34,6(Nov.2015). https://doi.org/10.1145/2816795.2818078 GregoryM.Nielson.2003.Onmarchingcubes.IEEETransactionsonvisualizationand
RoyJonkerandTonVolgenant.1988.Ashortestaugmentingpathalgorithmfordense computergraphics9,3(2003),283–297.
andsparselinearassignmentproblems.InDGOR/NSOR:Papersofthe16thAnnual WernerPalfinger.2022. Continuousremeshingforinverserendering. Computer
MeetingofDGORinCooperationwithNSOR/Vorträgeder16.JahrestagungderDGOR AnimationandVirtualWorlds33,5(2022),e2101.
zusammenmitderNSOR.Springer,622–622. SongyouPeng,Chiyu"Max"Jiang,YiyiLiao,MichaelNiemeyer,MarcPollefeys,and
AndreasGeiger.2021.ShapeAsPoints:ADifferentiablePoissonSolver.InAdvances
10SpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
inNeuralInformationProcessingSystems(NeurIPS).
Marie-JulieRakotosaona,PaulGuerrero,NoamAigerman,NiloyJMitra,andMaks
Ovsjanikov.2021.Learningdelaunaysurfaceelementsformeshreconstruction.In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
22–31.
AnuragRanjan,TimoBolkart,SoubhikSanyal,andMichaelJ.Black.2018.Generating
3DFacesusingConvolutionalMeshAutoencoders.InECCV.
NicholasSharpandMaksOvsjanikov.2020.Pointtrinet:Learnedtriangulationof3d
pointsets.InComputerVision–ECCV2020:16thEuropeanConference,Glasgow,UK,
August23–28,2020,Proceedings,PartXXIII16.Springer,762–778.
TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler.2021. Deep
MarchingTetrahedra:aHybridRepresentationforHigh-Resolution3DShapeSyn-
thesis.InAdvancesinNeuralInformationProcessingSystems(NeurIPS).
TianchangShen,JacobMunkberg,JonHasselgren,KangxueYin,ZianWang,Wenzheng
Chen,ZanGojcic,SanjaFidler,NicholasSharp,andJunGao.2023.FlexibleIsosurface
ExtractionforGradient-BasedMeshOptimization.ACMTrans.Graph.42,4,Article
37(jul2023),16pages. https://doi.org/10.1145/3592430
YawarSiddiqui,AntonioAlliegro,AlexeyArtemov,TatianaTommasi,DanieleSirigatti,
VladislavRosov,AngelaDai,andMatthiasNießner.2023. Meshgpt:Generating
trianglemesheswithdecoder-onlytransformers.arXivpreprintarXiv:2311.15475
(2023).
RichardSinkhorn.1964.Arelationshipbetweenarbitrarypositivematricesanddoubly
stochasticmatrices.Theannalsofmathematicalstatistics35,2(1964),876–879.
SanghyunSon,MatheusGadelha,YangZhou,ZexiangXu,MingCLin,andYiZhou.
2024.DMesh:ADifferentiableRepresentationforGeneralMeshes.arXivpreprint
arXiv:2404.13445(2024).
SiddharthTanwar,RajivRatnShah,andRogerZimmermann.2020.VariationalAutoen-
codersforDeformable3DMeshGeneration.InECCV.
AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN
Gomez,ŁukaszKaiser,andIlliaPolosukhin.2017.Attentionisallyouneed.Advances
inneuralinformationprocessingsystems30(2017).
NanyangWang,YindaZhang,ZhuwenLi,YanweiFu,WeiLiu,andYu-GangJiang.2018.
Pix2Mesh:3DMeshModelGenerationviaImageGuidedDeformation.InECCV.
KevinJWeiler.1986.Topologicalstructuresforgeometricmodeling(Boundaryrepresen-
tation,manifold,radialedgestructure).RensselaerPolytechnicInstitute.
XiaohuiZeng,ArashVahdat,FrancisWilliams,ZanGojcic,OrLitany,SanjaFidler,and
KarstenKreis.2022.LION:LatentPointDiffusionModelsfor3DShapeGeneration.
InAdvancesinNeuralInformationProcessingSystems.
YuxuanZhang,WenzhengChen,HuanLing,JunGao,YinanZhang,AntonioTorralba,
andSanjaFidler.2020.Imagegansmeetdifferentiablerenderingforinversegraphics
andinterpretable3dneuralrendering.arXivpreprintarXiv:2010.09125(2020).
YuxuanZhang,HuanLing,JunGao,KangxueYin,Jean-FrancoisLafleche,AdelaBar-
riuso,AntonioTorralba,andSanjaFidler.2021.Datasetgan:Efficientlabeleddata
factorywithminimalhumaneffort.InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition.10145–10155.
QingnanZhouandAlecJacobson.2016.Thingi10k:Adatasetof10,0003d-printing
models.arXivpreprintarXiv:1605.04797(2016).
Qian-YiZhou,JaesikPark,andVladlenKoltun.2018.Open3D:Amodernlibraryfor
3Ddataprocessing.arXivpreprintarXiv:1801.09847(2018).
11Shenetal.
Inthesupplement,weprovideadditionalexperimentaldetails mesh,theverticesaresortedinz-y-xorder,inaccordancewiththe
formeshfitting(SectionAandSectionB)andlearningexperiment methodologyofPolyGen[Nashetal.2020].
(SectionC).Wefurtherprovidemethodologydetailsforapplying
ourmethodtomeshrepairtasksinSectionD. C LEARNINGTOMESHTHESHAPE
C.1 TrainingDetails
A SINGLEMESHFITTING
Inthisexperiment,weuseadimensionof32foradjacencyembed-
TofitasinglemeshusingourSpaceMeshrepresentation,weop-
dingsandadimensionof12foreachpermutationembedding.The
timize the per-vertex embeddings (𝑥 𝑖,𝑦 𝑖root,𝑦 𝑖prev,𝑦 𝑖next). The ad-
totalnumberofchannelsfortheoutputofthevertexconnectivity
jacencyembeddings,𝑥 𝑖,aresettoadimensionof16,whileeach
predictionnetworkis68.
permutationembeddinghasadimensionof6.Thesamedimensions
Forthepointcloudencoder,weuseaPVCNN[Liuetal.2019]with
forspaceandtimecoordinatesareusedacrossallexperiments,with
4PVConvlayers,eachwithvoxelresolutionsof32,16,8,andchan-
𝑘𝑠 =𝑘𝑡 =𝑘/2.Duringtraining,thepermutationmatrixΦiscon-
nelsof64,128,and256,respectively.Thevertexpositiongeneration
structedusingthegroundtruthadjacencymatrix.Theregularization
networkfollowsthetransformer-baseddiffusionmodelasinthe
𝑁
parameter𝜆inEq.3ofthemainpaperissetto𝜆=4 edges ,where originalPoint-E[Nicholetal.2022],with10residualself-attention
𝑁 2
𝑁 edgesand𝑁 verticesrepresentthenumberofedgesanve drti vce es rticesin blocksofwidthequals256.Asmentionedinthemainpaper,ateach
eachshape,respectively. denoisingstep,weconcatenatethevertices’positionswithfeatures
TheAdamoptimizer[KingmaandBa2014]isemployedwith thataretri-linearlyinterpolatedwiththemulti-resolutionfeature
alearningrateof0.1.Theoverfittingprocesstypicallyconverges volumesfromtheencoder.Theconcatenatedfeaturesarefurther
within70iterations.ForcomparisonwithDMesh[Sonetal.2024], passedthrough4PVConvlayerswiththesamedimensionsasthe
weusedtheofficialreleasedcode1.ForcomparisonwithDSE[Rako- pointcloudencoder.Thetrainingfollowsthestandarddiffusion
tosaonaetal.2021],weusedtheofficialreleasedcode2andtrained modelschemewith1024diffusiontimesteps.
thenetworkstooverfitasinglemesheachtime. Forthevertexconnectivitypredictionmodel,wealsousePVConv
toprocesstheinterpolatedfeatures.Duringtraining,ourvertex
B FITTINGCOLLECTIONSOFMESHES generationmodel,whichisbasedonasettransformer,doesnot
Inthisexperimentwefollowatypicalautodecodersetup,optimiz- holdcorrespondencebetweendenoisedverticesandgroundtruth
ingone512-dimensionlatentcodeforeachmeshinthedatasetand vertices.Consequently,weusethegroundtruthverticesasinputfor
employingaTransformer[Vaswanietal.2017]todecodeeachlatent trainingtheconnectivitypredictionmodel,allowingsupervisionby
codeintothecorrespondingmesh.Specifically,foreachmesh,the thegroundtruthconnectivity.Weobservethatthevertexgeneration
latentcodeisrepeated𝑁 times(where𝑁 isthemaximumnumber model converges more quickly than the connectivity prediction
ofverticesinthedataset),andalearnablepositionalembedding network.Therefore,wetraintheconnectivitypredictionnetwork
(sharedacrossdifferentmeshes)isaddedtotherepeatedlatentcode. for10stepsforeverysingletrainingstepofthevertexgeneration
ThisresultingtensoristhenpassedtotheTransformertopredictthe model.
vertexpositionsandper-vertexembeddings.Toaccommodatevary- FortheABCdataset,sinceallmesheshavethesamenumber
ingnumbersofverticesacrossdifferentmeshes,allmeshvertices ofvertices,wedonotadditionallypredictavertexmask.Forthe
arepaddedwithzerosupto𝑁 =2000. ShapeNetdataset,wepredict512vertices,whichisthemaximum
Additionally,amaskchannelisappendedtothevertexpositions, numberofverticesinthefiltereddataset,andanadditionalmask
withgroundtruthvaluesof-1or1indicatingwhetherthevertex channel. We train our model using the Adam optimizer with a
ispaddedornot,respectively.Duringtraining,thelatentcodefor learningrateof0.0001for800kiterationsuntilconvergence.To
eachshape,thepositionalembedding,andtheTransformerweights combinethelossforvertexpredictionandconnectivityprediction,
are jointly optimized using a combination of the L2 loss on the wemultiplythelossfunctionfromEquation.3by200andadditto
predicted vertices and the losses described in Section 3. During thelossinEquation.5andthediffusionloss,bothwithascaleof1.
inference,verticeswithnegativepredictionsinthemaskchannel
EvaluationMetrics. Webrieflydescribethemetricsusedtoeval-
arepruned.
uatethereconstructionquality.Inallexperiments,thelongestdi-
Consistentwiththeoverfittingexperiment,theregularization
mensionofallmeshesisnormalizedto[-1,1].
𝑁
parameter𝜆inEq.3issetto𝜆 =4 edges ,andalearningrateof ChamferDistance(CD)measuresthedistancebetweentwopoint
𝑁 2
vertices
0.001isused. cloudsusingnearestneighborsearch,sampling10,000pointsfrom
thesurfaceofeachmesh.TheF1-scoreiscomputedforthesame
Dataset. WeconductourexperimentsontheThingi10K[Zhou
pointsetsusedforCD.Precisionisdeterminedbyclassifyingpoints
andJacobson2016]dataset,whichhasadiversecollectionofreal-
onthepredictedmeshastruepositivesiftheirdistancetothenearest
world3Dprintingmodelsexhibitingavarietyofshapecomplexities,
groundtruth(GT)pointcloudislessthan0.02;otherwise,theyare
topologies,anddiscretizations.Fromthisdataset,wefilterasubset
falsepositives.Recallusesthesame0.02threshold.EdgeChamfer
consistingofmanifoldmesheswithvertexcountsrangingbetween
Distance(ECD)andEdgeF-score(EF1)evaluatethereconstruction
1000and2000,andrandomlyselect200meshes.Foreachselected
ofsharpfeatures,followingpriorworks[Chenetal.2022].Each
1https://github.com/SonSang/dmesh pointinthesampledpointcloudischeckedbycomparingthedot
2https://github.com/mrakotosaon/dse-meshing productsbetweenitsnormalandthoseofitsneighbors;ifthemean
12SpaceMesh:AContinuousRepresentationforLearningManifoldSurfaceMeshes
step𝑇:V𝑇 ∼ N(0,I).Ateachdenoisingstep𝑡,wefirstalignV𝑡
withtheknownverticesVknowntoobtainamaskmwhichtakes
value1ifthevertexisinV𝑡 and0otherwise—seeparagraphbelow.
We feed V𝑡 into our point cloud diffusion model: V 𝑡u −n 1known ∼
N(𝜇 𝜃(V𝑡,𝑡),Σ 𝜃(V𝑡,𝑡)), where 𝜇 𝜃,Σ 𝜃 is the mean and variance
predictionfromourmodel,respectively.Thedenoisedverticeswill
be (cid:16)V √𝑡−1 =m⊙V 𝑡k −n 1own+ (cid:17)(1−m)⊙V 𝑡u −n 1known,whereV 𝑡k −n 1own ∼
N 𝛼¯𝑡Vknown,(1−𝛼¯𝑡)I .Aftersufficientlymanydenoisingsteps
wehavethefinalverticesV 0thatmatchtheoriginalmeshexcept
intheregionthathasbeenrepaired.
Thenewconnectivityispredictedusingourconnectivitygener-
Fig.16. ResultsontheABCdatasetgeneratedbyourlearningtomesh
model. ationmodel.Inthiscase,topreservetheexistingedgesandfaces
fromthepartialmesh,weonlyalteredtheconnectivitybetweenthe
predictedverticesandtheboundaryverticesfromVknown.
AligningVknownandV𝑡. Sinceitischallengingtoaligntwopoint
setswithdifferentnumbersofpointsforeachset,wefirstappend
surfacepointssampledfromthemaskedregions,denotedas𝑝masked,
totheknownverticesVknown,suchthat|V𝑡|=|Vknown|.Wethen
solvethecorrespondencebyfirstcomputingacostmatrixC,where
eachiteminthematrixC𝑖𝑗 = ∥V𝑡,𝑗 −V 𝑖known∥2 2.Todetermine
theone-to-onecorrespondence,weadoptthesamestrategythat
weusefordeterminingthelocalordering(Section3.3inthemain
Fig.17. ResultsontheThingi10kdatasetgeneratedbyourlearningtomesh paper).Inshort,weapplySinkhornnormalization[Sinkhorn1964]
modeltrainedonABCdataset. torecoveradoubly-stochasticmatrix,Cˆ,representingasoftened
permutationmatrix[AdamsandZemel2011].Thecorrespondence
dotproductisbelow0.2,thepointisclassifiedasanedgepoint.ECD
canberecoveredbycomputingtheoptimalunconstrainedlowest-
andEF1thenmeasuretheChamferDistanceandF1-scorebetween
costmatching[JonkerandVolgenant1988].
theseedgepoints.Forthepercentageofinaccuratenormals,we
usea10-degreethreshold.Thenormalofapointsampledfromthe
reconstructedmeshisconsideredasinaccurateiftheanglesbetween
itsnormalsandthatofthenearestgroundtruthpointexceed10
degrees.
C.2 AdditionalResults
Results on ABC Dataset. We present additional qualitative re-
sultsproducedbyourlearning-to-meshmodel,trainedontheABC
dataset,inFigure16.Tofurtherevaluateourmodel,weperform
stresstestsbymeshingnovelshapesfromtheThingi10kdataset[Zhou
andJacobson2016],withqualitativeresultsshowninFigure17.
Theresultsdemonstratethatourmodelaccuratelyreconstructs3D
manifoldmeshesfrominputpointclouds,showcasingitsabilityto
generalizetounseenshapesduringtraining.
D DOWNSTREAMTASK:MESHREPAIR
Weprovidedetailsonthealgorithmtorepairapartialmeshusing
ourmethod.Wefirstobtainthegeometrycontextbysamplingthe
pointcloudonthewholesurfaceandfeedingitintothepointcloud
encoder.Togeneratevertexpositionsonthetargetregion,while
maintainingtheoriginalverticesontheuntouchedregion,were-
designthevertexsamplingprocessinthevertexdiffusionmodel,
followingstandarddiffusionin-paintingapproaches.
Specifically,afterremovingtheregiontoberepairedfromthe
originalmesh,wedenotethepartialmeshthatwewanttocomplete
asMknown = (Vknown,Eknown,Fknown).Tobeginthedenoising
process,wesampleallverticesfromaGaussiandistributionfortime
13