[
    {
        "title": "Q-FOX Learning: Breaking Tradition in Reinforcement Learning",
        "authors": "Mahmood AlqaseerYossra H. AliTarik A. Rashid",
        "links": "http://arxiv.org/abs/2402.16562v1",
        "entry_id": "http://arxiv.org/abs/2402.16562v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16562v1",
        "summary": "Reinforcement learning (RL) is a subset of artificial intelligence (AI) where\nagents learn the best action by interacting with the environment, making it\nsuitable for tasks that do not require labeled data or direct supervision.\nHyperparameters (HP) tuning refers to choosing the best parameter that leads to\noptimal solutions in RL algorithms. Manual or random tuning of the HP may be a\ncrucial process because variations in this parameter lead to changes in the\noverall learning aspects and different rewards. In this paper, a novel and\nautomatic HP-tuning method called Q-FOX is proposed. This uses both the FOX\noptimizer, a new optimization method inspired by nature that mimics red foxes'\nhunting behavior, and the commonly used, easy-to-implement RL Q-learning\nalgorithm to solve the problem of HP tuning. Moreover, a new objective function\nis proposed which prioritizes the reward over the mean squared error (MSE) and\nlearning time (steps). Q-FOX has been evaluated on two OpenAI Gym environment\ncontrol tasks: Cart Pole and Frozen Lake. It exposed greater cumulative rewards\nthan HP tuning with other optimizers, such as PSO, GA, Bee, or randomly\nselected HP. The cumulative reward for the Cart Pole task was 32.08, and for\nthe Frozen Lake task was 0.95. Despite the robustness of Q-FOX, it has\nlimitations. It cannot be used directly in real-word problems before choosing\nthe HP in a simulation environment because its processes work iteratively,\nmaking it time-consuming. The results indicate that Q-FOX has played an\nessential role in HP tuning for RL algorithms to effectively solve different\ncontrol tasks.",
        "updated": "2024-02-26 13:39:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16562v1"
    },
    {
        "title": "Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects",
        "authors": "Han WangSijia YuChunyang ChenBurak TurhanXiaodong Zhu",
        "links": "http://dx.doi.org/10.1145/3638245",
        "entry_id": "http://arxiv.org/abs/2402.16546v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16546v1",
        "summary": "Deep Learning (DL) models have rapidly advanced, focusing on achieving high\nperformance through testing model accuracy and robustness. However, it is\nunclear whether DL projects, as software systems, are tested thoroughly or\nfunctionally correct when there is a need to treat and test them like other\nsoftware systems. Therefore, we empirically study the unit tests in open-source\nDL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit tested\nDL projects have positive correlation with the open-source project metrics and\nhave a higher acceptance rate of pull requests, 2) 68% of the sampled DL\nprojects are not unit tested at all, 3) the layer and utilities (utils) of DL\nmodels have the most unit tests. Based on these findings and previous research\noutcomes, we built a mapping taxonomy between unit tests and faults in DL\nprojects. We discuss the implications of our findings for developers and\nresearchers and highlight the need for unit testing in open-source DL projects\nto ensure their reliability and stability. The study contributes to this\ncommunity by raising awareness of the importance of unit testing in DL projects\nand encouraging further research in this area.",
        "updated": "2024-02-26 13:08:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16546v1"
    },
    {
        "title": "RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots",
        "authors": "Benjamin AltFlorian StöcklSilvan MüllerChristopher BraunJulian RaibleSaad AlhasanOliver RettigLukas RingleDarko KaticRainer JäkelMichael BeetzMarcus StrandMarco F. Huber",
        "links": "http://arxiv.org/abs/2402.16542v2",
        "entry_id": "http://arxiv.org/abs/2402.16542v2",
        "pdf_url": "http://arxiv.org/pdf/2402.16542v2",
        "summary": "Surface treatment tasks such as grinding, sanding or polishing are a vital\nstep of the value chain in many industries, but are notoriously challenging to\nautomate. We present RoboGrind, an integrated system for the intuitive,\ninteractive automation of surface treatment tasks with industrial robots. It\ncombines a sophisticated 3D perception pipeline for surface scanning and\nautomatic defect identification, an interactive voice-controlled wizard system\nfor the AI-assisted bootstrapping and parameterization of robot programs, and\nan automatic planning and execution pipeline for force-controlled robotic\nsurface treatment. RoboGrind is evaluated both under laboratory and real-world\nconditions in the context of refabricating fiberglass wind turbine blades.",
        "updated": "2024-02-27 08:57:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16542v2"
    },
    {
        "title": "Memory GAPS: Would LLM pass the Tulving Test?",
        "authors": "Jean-Marie Chauvet",
        "links": "http://arxiv.org/abs/2402.16505v1",
        "entry_id": "http://arxiv.org/abs/2402.16505v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16505v1",
        "summary": "The Tulving Test was designed to investigate memory performance in\nrecognition and recall tasks. Its results help assess the relevance of the\n\"Synergistic Ecphory Model\" of memory and similar RK paradigms in human\nperformance. This paper starts investigating whether the more than\nforty-year-old framework sheds some light on LLMs' acts of remembering.",
        "updated": "2024-02-26 11:40:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16505v1"
    },
    {
        "title": "Intelligent Known and Novel Aircraft Recognition -- A Shift from Classification to Similarity Learning for Combat Identification",
        "authors": "Ahmad SaeedHaasha Bin AtifUsman HabibMohsin Bilal",
        "links": "http://arxiv.org/abs/2402.16486v1",
        "entry_id": "http://arxiv.org/abs/2402.16486v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16486v1",
        "summary": "Precise aircraft recognition in low-resolution remote sensing imagery is a\nchallenging yet crucial task in aviation, especially combat identification.\nThis research addresses this problem with a novel, scalable, and AI-driven\nsolution. The primary hurdle in combat identification in remote sensing imagery\nis the accurate recognition of Novel/Unknown types of aircraft in addition to\nKnown types. Traditional methods, human expert-driven combat identification and\nimage classification, fall short in identifying Novel classes. Our methodology\nemploys similarity learning to discern features of a broad spectrum of military\nand civilian aircraft. It discerns both Known and Novel aircraft types,\nleveraging metric learning for the identification and supervised few-shot\nlearning for aircraft type classification. To counter the challenge of limited\nlow-resolution remote sensing data, we propose an end-to-end framework that\nadapts to the diverse and versatile process of military aircraft recognition by\ntraining a generalized embedder in fully supervised manner. Comparative\nanalysis with earlier aircraft image classification methods shows that our\napproach is effective for aircraft image classification (F1-score Aircraft Type\nof 0.861) and pioneering for quantifying the identification of Novel types\n(F1-score Bipartitioning of 0.936). The proposed methodology effectively\naddresses inherent challenges in remote sensing data, thereby setting new\nstandards in dataset quality. The research opens new avenues for domain experts\nand demonstrates unique capabilities in distinguishing various aircraft types,\ncontributing to a more robust, domain-adapted potential for real-time aircraft\nrecognition.",
        "updated": "2024-02-26 11:08:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16486v1"
    }
]