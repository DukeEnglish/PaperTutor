[
    {
        "title": "Distributed Finite-time Differentiator for Multi-agent Systems Under Directed Graph",
        "authors": "Weile ChenHaibo DuShihua Li",
        "links": "http://arxiv.org/abs/2402.16260v1",
        "entry_id": "http://arxiv.org/abs/2402.16260v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16260v1",
        "summary": "This paper proposes a new distributed finite-time differentiator (DFD) for\nmulti-agent systems (MAS) under directed graph, which extends the\ndifferentiator algorithm from the centralized case to the distributed case by\nonly using relative/absolute position information. By skillfully constructing a\nLyapunov function, the finite-time stability of the closed-loop system under\nDFD is proved. Inspired by the duality principle of control theory, a\ndistributed continuous finite-time output consensus algorithm extended from DFD\nfor a class of leader-follower MAS is provided, which not only completely\nsuppresses disturbance, but also avoids chattering. Finally, several simulation\nexamples are given to verify the effectiveness of the DFD.",
        "updated": "2024-02-26 02:45:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16260v1"
    },
    {
        "title": "Learning Translations: Emergent Communication Pretraining for Cooperative Language Acquisition",
        "authors": "Dylan CopePeter McBurney",
        "links": "http://arxiv.org/abs/2402.16247v1",
        "entry_id": "http://arxiv.org/abs/2402.16247v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16247v1",
        "summary": "In Emergent Communication (EC) agents learn to communicate with one another,\nbut the protocols that they develop are specialised to their training\ncommunity. This observation led to research into Zero-Shot Coordination (ZSC)\nfor learning communication strategies that are robust to agents not encountered\nduring training. However, ZSC typically assumes that no prior data is available\nabout the agents that will be encountered in the zero-shot setting. In many\ncases, this presents an unnecessarily hard problem and rules out communication\nvia preestablished conventions. We propose a novel AI challenge called a\nCooperative Language Acquisition Problem (CLAP) in which the ZSC assumptions\nare relaxed by allowing a 'joiner' agent to learn from a dataset of\ninteractions between agents in a target community. We propose and compare two\nmethods for solving CLAPs: Imitation Learning (IL), and Emergent Communication\npretraining and Translation Learning (ECTL), in which an agent is trained in\nself-play with EC and then learns from the data to translate between the\nemergent protocol and the target community's protocol.",
        "updated": "2024-02-26 02:13:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16247v1"
    },
    {
        "title": "Honeybee: Decentralized Peer Sampling with Verifiable Random Walks for Blockchain Data Sharding",
        "authors": "Yunqi ZhangShaileshh Bojja Venkatakrishnan",
        "links": "http://arxiv.org/abs/2402.16201v1",
        "entry_id": "http://arxiv.org/abs/2402.16201v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16201v1",
        "summary": "Data sharding - in which block data is sharded without sharding compute - is\nat the present the favored approach for scaling Ethereum. A key challenge\ntoward implementing data sharding is verifying whether the entirety of a\nblock's data is available in the network (across its shards). A central\ntechnique proposed to conduct this verification uses erasure coded blocks and\nis called data availability sampling (DAS). While the high-level protocol\ndetails of DAS has been well discussed in the community, discussions around how\nsuch a protocol will be implemented at the peer-to-peer layer are lacking. We\nidentify random sampling of nodes as a fundamental primitive necessary to carry\nout DAS and present Honeybee, a decentralized algorithm for sampling node that\nuses verifiable random walks. Honeybee is secure against attacks even in the\npresence of a large number of Byzantine nodes (e.g., 50% of the network). We\nevaluate Honeybee through experiments and show that the quality of sampling\nachieved by Honeybee is significantly better compared to the state-of-the-art.\nOur proposed algorithm has implications for DAS functions in both full nodes\nand light nodes.",
        "updated": "2024-02-25 21:29:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16201v1"
    },
    {
        "title": "Egalitarian Price of Fairness for Indivisible Goods",
        "authors": "Karen Frilya CelineMuhammad Ayaz DzulfikarIvan Adrian Koswara",
        "links": "http://dx.doi.org/10.1007/978-981-99-7019-3_3",
        "entry_id": "http://arxiv.org/abs/2402.16145v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16145v1",
        "summary": "In the context of fair division, the concept of price of fairness has been\nintroduced to quantify the loss of welfare when we have to satisfy some\nfairness condition. In other words, it is the price we have to pay to guarantee\nfairness. Various settings of fair division have been considered previously; we\nextend to the setting of indivisible goods by using egalitarian welfare as the\nwelfare measure, instead of the commonly used utilitarian welfare. We provide\nlower and upper bounds for various fairness and efficiency conditions such as\nenvy-freeness up to one good (EF1) and maximum Nash welfare (MNW).",
        "updated": "2024-02-25 16:54:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16145v1"
    },
    {
        "title": "Cooperation and Control in Delegation Games",
        "authors": "Oliver SourbutLewis HammondHarriet Wood",
        "links": "http://arxiv.org/abs/2402.15821v1",
        "entry_id": "http://arxiv.org/abs/2402.15821v1",
        "pdf_url": "http://arxiv.org/pdf/2402.15821v1",
        "summary": "Many settings of interest involving humans and machines -- from virtual\npersonal assistants to autonomous vehicles -- can naturally be modelled as\nprincipals (humans) delegating to agents (machines), which then interact with\neach other on their principals' behalf. We refer to these multi-principal,\nmulti-agent scenarios as delegation games. In such games, there are two\nimportant failure modes: problems of control (where an agent fails to act in\nline their principal's preferences) and problems of cooperation (where the\nagents fail to work well together). In this paper we formalise and analyse\nthese problems, further breaking them down into issues of alignment (do the\nplayers have similar preferences?) and capabilities (how competent are the\nplayers at satisfying those preferences?). We show -- theoretically and\nempirically -- how these measures determine the principals' welfare, how they\ncan be estimated using limited observations, and thus how they might be used to\nhelp us design more aligned and cooperative AI systems.",
        "updated": "2024-02-24 14:17:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.15821v1"
    }
]