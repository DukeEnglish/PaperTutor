[
    {
        "title": "A kernel-based analysis of Laplacian Eigenmaps",
        "authors": "Martin Wahl",
        "links": "http://arxiv.org/abs/2402.16481v1",
        "entry_id": "http://arxiv.org/abs/2402.16481v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16481v1",
        "summary": "Given i.i.d. observations uniformly distributed on a closed manifold\n$\\mathcal{M}\\subseteq \\mathbb{R}^p$, we study the spectral properties of the\nassociated empirical graph Laplacian based on a Gaussian kernel. Our main\nresults are non-asymptotic error bounds, showing that the eigenvalues and\neigenspaces of the empirical graph Laplacian are close to the eigenvalues and\neigenspaces of the Laplace-Beltrami operator of $\\mathcal{M}$. In our analysis,\nwe connect the empirical graph Laplacian to kernel principal component\nanalysis, and consider the heat kernel of $\\mathcal{M}$ as reproducing kernel\nfeature map. This leads to novel points of view and allows to leverage results\nfor empirical covariance operators in infinite dimensions.",
        "updated": "2024-02-26 11:00:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16481v1"
    },
    {
        "title": "Training Implicit Generative Models via an Invariant Statistical Loss",
        "authors": "José Manuel de FrutosPablo M. OlmosManuel A. VázquezJoaquín Míguez",
        "links": "http://arxiv.org/abs/2402.16435v1",
        "entry_id": "http://arxiv.org/abs/2402.16435v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16435v1",
        "summary": "Implicit generative models have the capability to learn arbitrary complex\ndata distributions. On the downside, training requires telling apart real data\nfrom artificially-generated ones using adversarial discriminators, leading to\nunstable training and mode-dropping issues. As reported by Zahee et al. (2017),\neven in the one-dimensional (1D) case, training a generative adversarial\nnetwork (GAN) is challenging and often suboptimal. In this work, we develop a\ndiscriminator-free method for training one-dimensional (1D) generative implicit\nmodels and subsequently expand this method to accommodate multivariate cases.\nOur loss function is a discrepancy measure between a suitably chosen\ntransformation of the model samples and a uniform distribution; hence, it is\ninvariant with respect to the true distribution of the data. We first formulate\nour method for 1D random variables, providing an effective solution for\napproximate reparameterization of arbitrary complex distributions. Then, we\nconsider the temporal setting (both univariate and multivariate), in which we\nmodel the conditional distribution of each sample given the history of the\nprocess. We demonstrate through numerical simulations that this new method\nyields promising results, successfully learning true distributions in a variety\nof scenarios and mitigating some of the well-known problems that\nstate-of-the-art implicit methods present.",
        "updated": "2024-02-26 09:32:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16435v1"
    },
    {
        "title": "Stable Training of Normalizing Flows for High-dimensional Variational Inference",
        "authors": "Daniel Andrade",
        "links": "http://arxiv.org/abs/2402.16408v1",
        "entry_id": "http://arxiv.org/abs/2402.16408v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16408v1",
        "summary": "Variational inference with normalizing flows (NFs) is an increasingly popular\nalternative to MCMC methods. In particular, NFs based on coupling layers (Real\nNVPs) are frequently used due to their good empirical performance. In theory,\nincreasing the depth of normalizing flows should lead to more accurate\nposterior approximations. However, in practice, training deep normalizing flows\nfor approximating high-dimensional posterior distributions is often infeasible\ndue to the high variance of the stochastic gradients. In this work, we show\nthat previous methods for stabilizing the variance of stochastic gradient\ndescent can be insufficient to achieve stable training of Real NVPs. As the\nsource of the problem, we identify that, during training, samples often exhibit\nunusual high values. As a remedy, we propose a combination of two methods: (1)\nsoft-thresholding of the scale in Real NVPs, and (2) a bijective soft log\ntransformation of the samples. We evaluate these and other previously proposed\nmodification on several challenging target distributions, including a\nhigh-dimensional horseshoe logistic regression model. Our experiments show that\nwith our modifications, stable training of Real NVPs for posteriors with\nseveral thousand dimensions is possible, allowing for more accurate marginal\nlikelihood estimation via importance sampling. Moreover, we evaluate several\ncommon training techniques and architecture choices and provide practical\nadvise for training NFs for high-dimensional variational inference.",
        "updated": "2024-02-26 09:04:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16408v1"
    },
    {
        "title": "Uncertainty Quantification in Anomaly Detection with Cross-Conformal $p$-Values",
        "authors": "Oliver HennhöferChristine Preisach",
        "links": "http://arxiv.org/abs/2402.16388v1",
        "entry_id": "http://arxiv.org/abs/2402.16388v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16388v1",
        "summary": "Given the growing significance of reliable, trustworthy, and explainable\nmachine learning, the requirement of uncertainty quantification for anomaly\ndetection systems has become increasingly important. In this context,\neffectively controlling Type I error rates ($\\alpha$) without compromising the\nstatistical power ($1-\\beta$) of these systems can build trust and reduce costs\nrelated to false discoveries, particularly when follow-up procedures are\nexpensive. Leveraging the principles of conformal prediction emerges as a\npromising approach for providing respective statistical guarantees by\ncalibrating a model's uncertainty. This work introduces a novel framework for\nanomaly detection, termed cross-conformal anomaly detection, building upon\nwell-known cross-conformal methods designed for prediction tasks. With that, it\naddresses a natural research gap by extending previous works in the context of\ninductive conformal anomaly detection, relying on the split-conformal approach\nfor model calibration. Drawing on insights from conformal prediction, we\ndemonstrate that the derived methods for calculating cross-conformal $p$-values\nstrike a practical compromise between statistical efficiency (full-conformal)\nand computational efficiency (split-conformal) for uncertainty-quantified\nanomaly detection on benchmark datasets.",
        "updated": "2024-02-26 08:22:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16388v1"
    },
    {
        "title": "Self Supervised Correlation-based Permutations for Multi-View Clustering",
        "authors": "Ran EisenbergJonathan SvirskyOfir Lindenbaum",
        "links": "http://arxiv.org/abs/2402.16383v1",
        "entry_id": "http://arxiv.org/abs/2402.16383v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16383v1",
        "summary": "Fusing information from different modalities can enhance data analysis tasks,\nincluding clustering. However, existing multi-view clustering (MVC) solutions\nare limited to specific domains or rely on a suboptimal and computationally\ndemanding two-stage procedure of representation and clustering. We propose an\nend-to-end deep learning-based MVC framework for general data (image, tabular,\netc.). Our approach involves learning meaningful fused data representations\nwith a novel permutation-based canonical correlation objective. Concurrently,\nwe learn cluster assignments by identifying consistent pseudo-labels across\nmultiple views. We demonstrate the effectiveness of our model using ten MVC\nbenchmark datasets. Theoretically, we show that our model approximates the\nsupervised linear discrimination analysis (LDA) representation. Additionally,\nwe provide an error bound induced by false-pseudo label annotations.",
        "updated": "2024-02-26 08:08:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16383v1"
    }
]