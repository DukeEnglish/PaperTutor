[
    {
        "title": "Integrating Large Language Models with Graphical Session-Based Recommendation",
        "authors": "Naicheng GuoHongwei ChengQianqiao LiangLinxun ChenBing Han",
        "links": "http://arxiv.org/abs/2402.16539v1",
        "entry_id": "http://arxiv.org/abs/2402.16539v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16539v1",
        "summary": "With the rapid development of Large Language Models (LLMs), various\nexplorations have arisen to utilize LLMs capability of context understanding on\nrecommender systems. While pioneering strategies have primarily transformed\ntraditional recommendation tasks into challenges of natural language\ngeneration, there has been a relative scarcity of exploration in the domain of\nsession-based recommendation (SBR) due to its specificity. SBR has been\nprimarily dominated by Graph Neural Networks, which have achieved many\nsuccessful outcomes due to their ability to capture both the implicit and\nexplicit relationships between adjacent behaviors. The structural nature of\ngraphs contrasts with the essence of natural language, posing a significant\nadaptation gap for LLMs. In this paper, we introduce large language models with\ngraphical Session-Based recommendation, named LLMGR, an effective framework\nthat bridges the aforementioned gap by harmoniously integrating LLMs with Graph\nNeural Networks (GNNs) for SBR tasks. This integration seeks to leverage the\ncomplementary strengths of LLMs in natural language understanding and GNNs in\nrelational data processing, leading to a more powerful session-based\nrecommender system that can understand and recommend items within a session.\nMoreover, to endow the LLM with the capability to empower SBR tasks, we design\na series of prompts for both auxiliary and major instruction tuning tasks.\nThese prompts are crafted to assist the LLM in understanding graph-structured\ndata and align textual information with nodes, effectively translating nuanced\nuser interactions into a format that can be understood and utilized by LLM\narchitectures. Extensive experiments on three real-world datasets demonstrate\nthat LLMGR outperforms several competitive baselines, indicating its\neffectiveness in enhancing SBR tasks and its potential as a research direction\nfor future exploration.",
        "updated": "2024-02-26 12:55:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16539v1"
    },
    {
        "title": "LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification",
        "authors": "Yiping SongJuhua ZhangZhiliang TianYuxin YangMinlie HuangDongsheng Li",
        "links": "http://arxiv.org/abs/2402.16515v1",
        "entry_id": "http://arxiv.org/abs/2402.16515v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16515v1",
        "summary": "As sufficient data are not always publically accessible for model training,\nresearchers exploit limited data with advanced learning algorithms or expand\nthe dataset via data augmentation (DA). Conducting DA in private domain\nrequires private protection approaches (i.e. anonymization and perturbation),\nbut those methods cannot provide protection guarantees. Differential privacy\n(DP) learning methods theoretically bound the protection but are not skilled at\ngenerating pseudo text samples with large models. In this paper, we transfer\nDP-based pseudo sample generation task to DP-based generated samples\ndiscrimination task, where we propose a DP-based DA method with a LLM and a\nDP-based discriminator for text classification on private domains. We construct\na knowledge distillation model as the DP-based discriminator: teacher models,\naccessing private data, teaches students how to select private samples with\ncalibrated noise to achieve DP. To constrain the distribution of DA's\ngeneration, we propose a DP-based tutor that models the noised private\ndistribution and controls samples' generation with a low privacy cost. We\ntheoretically analyze our model's privacy protection and empirically verify our\nmodel.",
        "updated": "2024-02-26 11:52:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16515v1"
    },
    {
        "title": "Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision",
        "authors": "Fan JiangTom DrummondTrevor Cohn",
        "links": "http://arxiv.org/abs/2402.16508v1",
        "entry_id": "http://arxiv.org/abs/2402.16508v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16508v1",
        "summary": "Cross-lingual question answering (CLQA) is a complex problem, comprising\ncross-lingual retrieval from a multilingual knowledge base, followed by answer\ngeneration either in English or the query language. Both steps are usually\ntackled by separate models, requiring substantial annotated datasets, and\ntypically auxiliary resources, like machine translation systems to bridge\nbetween languages. In this paper, we show that CLQA can be addressed using a\nsingle encoder-decoder model. To effectively train this model, we propose a\nself-supervised method based on exploiting the cross-lingual link structure\nwithin Wikipedia. We demonstrate how linked Wikipedia pages can be used to\nsynthesise supervisory signals for cross-lingual retrieval, through a form of\ncloze query, and generate more natural queries to supervise answer generation.\nTogether, we show our approach, \\texttt{CLASS}, outperforms comparable methods\non both supervised and zero-shot language adaptation settings, including those\nusing machine translation.",
        "updated": "2024-02-26 11:42:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16508v1"
    },
    {
        "title": "LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments",
        "authors": "Junzhe ChenXuming HuShuodi LiuShiyu HuangWei-Wei TuZhaofeng HeLijie Wen",
        "links": "http://arxiv.org/abs/2402.16499v1",
        "entry_id": "http://arxiv.org/abs/2402.16499v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16499v1",
        "summary": "Recent advancements in large language models (LLMs) have revealed their\npotential for achieving autonomous agents possessing human-level intelligence.\nHowever, existing benchmarks for evaluating LLM Agents either use static\ndatasets, potentially leading to data leakage or focus only on single-agent\nscenarios, overlooking the complexities of multi-agent interactions. There is a\nlack of a benchmark that evaluates the diverse capabilities of LLM agents in\nmulti-agent, dynamic environments. To this end, we introduce LLMArena, a novel\nand easily extensible framework for evaluating the diverse capabilities of LLM\nin multi-agent dynamic environments. LLMArena encompasses seven distinct gaming\nenvironments, employing Trueskill scoring to assess crucial abilities in LLM\nagents, including spatial reasoning, strategic planning, numerical reasoning,\nrisk assessment, communication, opponent modeling, and team collaboration. We\nconduct an extensive experiment and human evaluation among different sizes and\ntypes of LLMs, showing that LLMs still have a significant journey ahead in\ntheir development towards becoming fully autonomous agents, especially in\nopponent modeling and team collaboration. We hope LLMArena could guide future\nresearch towards enhancing these capabilities in LLMs, ultimately leading to\nmore sophisticated and practical applications in dynamic, multi-agent settings.\nThe code and data will be available.",
        "updated": "2024-02-26 11:31:48 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16499v1"
    },
    {
        "title": "On Languaging a Simulation Engine",
        "authors": "Han LiuLiantang Li",
        "links": "http://arxiv.org/abs/2402.16482v1",
        "entry_id": "http://arxiv.org/abs/2402.16482v1",
        "pdf_url": "http://arxiv.org/pdf/2402.16482v1",
        "summary": "Language model intelligence is revolutionizing the way we program materials\nsimulations. However, the diversity of simulation scenarios renders it\nchallenging to precisely transform human language into a tailored simulator.\nHere, using three functionalized types of language model, we propose a\nlanguage-to-simulation (Lang2Sim) framework that enables interactive navigation\non languaging a simulation engine, by taking a scenario instance of water\nsorption in porous matrices. Unlike line-by-line coding of a target simulator,\nthe language models interpret each simulator as an assembly of invariant tool\nfunction and its variant input-output pair. Lang2Sim enables the precise\ntransform of textual description by functionalizing and sequentializing the\nlanguage models of, respectively, rationalizing the tool categorization,\ncustomizing its input-output combinations, and distilling the simulator input\ninto executable format. Importantly, depending on its functionalized type, each\nlanguage model features a distinct processing of chat history to best balance\nits memory limit and information completeness, thus leveraging the model\nintelligence to unstructured nature of human request. Overall, this work\nestablishes language model as an intelligent platform to unlock the era of\nlanguaging a simulation engine.",
        "updated": "2024-02-26 11:01:54 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.16482v1"
    }
]