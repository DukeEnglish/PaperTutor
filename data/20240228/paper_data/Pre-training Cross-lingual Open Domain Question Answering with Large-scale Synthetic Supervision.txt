Pre-training Cross-lingual Open Domain Question Answering
with Large-scale Synthetic Supervision
FanJiang and TomDrummond and TrevorCohn*
SchoolofComputingandInformationSystems
TheUniversityofMelbourne,Victoria,Australia
fan.jiang1@student.unimelb.edu.au
{tom.drummond, trevor.cohn}@unimelb.edu.au
Abstract uments or the questions require knowledge from
diversecultures(Asaietal.,2021b).
Cross-lingual question answering (CLQA) is
Several attempts have been made to enhance
acomplexproblem,comprisingcross-lingual
the performance of multilingual open-domain
retrievalfromamultilingualknowledgebase,
QA(Asaietal.,2021b;Abulkhanovetal.,2023).
followed by answer generation either in En-
These approaches typically require passage la-
glish or the query language. Both steps are
usuallytackledbyseparatemodels,requiring belsforretrievertrainingthroughsupervisedcon-
substantial annotated datasets, and typically trastive learning. This requirement complicates
auxiliary resources, like machine translation cross-lingualretrievaltrainingsignificantlydueto
systemstobridgebetweenlanguages. Inthis thechallengeofconstructingalarge-scaledataset
paper,weshowthatCLQAcanbeaddressed
containing query-passage labels. This challenge
usingasingleencoder-decodermodel. Toef-
emergesfromtheunavailabilityofpriorknowledge
fectively train this model, we propose a self-
regardingwhichlanguagecontainstherelevantev-
supervised method based on exploiting the
idence. Furthermore, these efforts often involve
cross-linguallinkstructurewithinWikipedia.
WedemonstratehowlinkedWikipediapages separatetrainingoftheretrieverandreader,leading
canbeusedtosynthesisesupervisorysignals toerrorpropagationwithintheresultingpipeline.
for cross-lingual retrieval, through a form of EvidenceinthecontextofEnglishopen-domain
clozequery,andgeneratemorenaturalqueries
QA reveals that integrating retriever and reader
tosuperviseanswergeneration. Together,we
trainingtypicallyleadstoimprovedperformance
showourapproach,CLASS,outperformscompa-
on both components. This achievement is often
rablemethodsonbothsupervisedandzero-shot
realised by training both components (Guu et al.,
languageadaptationsettings, includingthose
usingmachinetranslation. 2020; Lewis et al., 2020) or a unified model that
performsbothtasks(Leeetal.,2022;Jiangetal.,
1 Introduction 2022)throughfullyend-to-endtraining. Nonethe-
less, such a joint training paradigm has not been
OpenDomainQuestionAnswering(QA)isthetask
extensivelyexploredinmultilingualopen-domain
ofgeneratingananswerforagivenquestionbased
QA,andhowtoadaptittosuitthecomplexitiesof
ontheevidencegatheredfromalargecollectionof
multilingualsettingsremainsanopenquestion.
documents. A widely adopted pipeline "retrieve-
In this paper, we introduce the first unified
then-read" is employed for this task (Chen et al.,
model capable of performing both cross-lingual
2017; Karpukhin et al., 2020), which begins by
retrievalandmultilingualopen-domainQAtasks.
retrieving a small set of passages using a dense
Toachievethis,weproposeCLASS(Cross-Lingual
retrieval model and subsequently processes re-
QAPre-trainingwithSyntheticSupervision),aself-
trievedpassagestogeneratetheanswerwithaded-
supervisedmethodtopre-trainthemodelwithmul-
icated reader. Unlike English open-domain QA,
tilingualtextsatscale. CLASScomprisestwocore
wherebothquestionsandknowledgesourcesshare
components: cross-lingualretrievalpre-training
thesamelanguage,multilingualopen-domainQA
thatequipsthemodelwithrobustcross-lingualre-
presentsnewchallenges,asitinvolvesretrievingev-
trievalability,andmultilingualQApre-training
idencefrommultilingualcorpora,consideringthat
that further enhances retrieval and QA abilities
manylanguageslackcomprehensivesupportdoc-
jointly. Concretely,asdepictedinFigure1,thepre-
*NowatGoogleDeepMind trainingdataiscreatedbyminingparallelqueries
1
4202
beF
62
]LC.sc[
1v80561.2042:viXraAEn: 2011 AL: 2011年
A: India
MMMuuullltttiiillliiinnnggguuuaaalll MMMooodddeeelll EEnngglliisshh MMooddeell MMMuuullltttiiillliiinnnggguuuaaalll MMMooodddeeelll & En
qL: 推定売上枚数は7.3万枚を記録し、水樹のシング
A: India ル全3作品が年間チャートTOP200入りを果たしたの
qEn : m O an nc ye d i in f f[ eM rea ns tk d] e, sh ti ip np ai te ios n w s.e ..nt to qL : インドでは、 目ヒ 的ッピ 地ー ...は多くの異なる は r se aa lい ec sh つ
o
t fh で 7e
3
tす ,o 0p 0か 02 ?0？ )0 ( o W f h the en ad nid n ua all l t ch hr ae re t so , f wM iti hz u ek si' ts i msin ag tl ee ds
Once in India, hippies went to インドでは、ヒッピーは多くの異な Query Transformation
many different destinations, on る目的地へいったが、トリヴァンド
the beaches of Goa and Kovalam ラム（ケーララ州）のゴアとコバラ
in Trivandrum (Kerala), or ムのビーチに大量に集まったり、 Type: Date
c spro es ns de d
m
oth ne
th
b
s
o inrd Ker
a
ti hn mto
a
nN de up .al to 国 ズで境 数を ヶ越 月え 過た ごネ しパ たー りル したの 。カトマン 推 20定 11売 年上 にリ枚 リ数 ーは ス7 さ.3 れ万 た枚 水を 樹記 の録 シし ン、 NER Tagging
グル全3作品が年間チャートTOP200 2011 (MMXI) was a common
入りを果たした。(Estimated sales year starting on Saturday of
were 73,000 copies, and all three of the Gregorian calendar...
Parallel Sentence Mining M eni tz eu rk ei d's ths ein g tole ps 2r 0e 0le a os fe d t hei n an2 n0 u1 a1 l Language Link
charts.)
2011年平年（2011 ねん）は、西
暦（グレゴリオ暦）による、土曜日
から始まる。平成23年。
(a). Stage 1: Cross-Lingual Retrieval Pre-training (b). Stage 2: Multilingual Question-Answering Pre-training
Figure1: Theoverviewofourtwo-stageunsupervisedpre-trainingmethodforcross-lingualopendomainquestion
answering. Notethattranslationsinstage2areemployedforillustrativepurposesonlyandarenotusedfortraining.
fromparallelWikipediapages,usingsaliententi- 1. Empirical results on the XOR-TYDI QA
tieswithinEnglishsentencesasanswers. Tofacil- benchmark demonstrate that CLASS outper-
itatecross-lingualretrievals,aknowledgedistilla- forms a wide range of prominent unsuper-
tionprocessisintroduced,requiringthemodelto vised, zero-shot, and supervised models on
match the distributions of a well-trained English bothtasks,whilesolelyrelyingonQApairs
teacherwhengivenqueriesinbothlanguages. The throughoutthewholetrainingprocesses.
follow-upisaself-supervisedlearningtaskforend- 2. On the MKQA dataset, CLASS exhibits re-
to-endpre-trainingbypropagatingtrainingsignals markable generalisation capabilities across
derivedfromtheendQAtask. Thisprocessentails linguisticallydiverselanguageswithoutusing
generatingpre-trainingdatausinganchortextsindi- human-annotateddata.
catedbyhyperlinksandaquestiontransformation 3. To the best of our knowledge, we are the pi-
techniquetoresembletheformatsofnaturalques- oneersinsystematicallyexploringtheadvan-
tions. Notably,ourapproachdoesnotnecessitate tagesofpre-trainingformultilingualretrieval
additionaltoolssuchasmachinetranslationandof- and open-domain QA tasks. This demon-
fersamoreconvenientapplicationtolow-resource stratesthefeasibilityofachievingmultilingual
languages,requiringonlycomparabledocuments open-domainQAwithinaunifiedmodel.
(i.e.,Wikipedialanguagelinks).
2 Preliminaries
Thislarge-scalepre-trainingframeworkempow-
ers the model to demonstrate promising unsuper- 2.1 TaskDefinition
vised performance, and it can even outperform GivenaquestionqL inlanguageL,Cross-lingual
manycompetitivesupervisedcounterparts. Byfine-
PassageRetrievalrequiresretrievingacollection
tuningitwithsupervisedEnglishandmultilingual of passages DEn from English Wikipedia CEn
QAdata, wecanattainfurtherimprovements, ul- thatpotentiallyprovideevidencetoanswerqL. An
timately establishing new state-of-the-art perfor- English answer aEn is then generated by a cross-
mance in both cross-lingual retrieval and multi-
lingualreaderwithretrievedinformation. Incon-
lingual open-domain QA tasks. In summary, our
trast,MultilingualOpen-DomainQuestionAn-
contributionsare:1
swering aims at answering qL in language L by
referringtoamultilingualWikipediaCMulti. In
1Sourcecodewillbereleasedathttps://github.com/
Fantabulous-J/CLASS thissetting,thepriorknowledgeofwhichlanguage
2
𝐸 𝑛 𝐸 𝑛 𝑃 𝑞𝑏𝑒
𝐸𝐸 𝑛𝑛𝜃𝜃
𝐸𝐸𝐸 𝑛𝑛𝑛𝓒𝓒𝓒
𝒟
ℒ K L
𝑃 𝑀 𝐿𝑏𝑒 𝑞 𝐸 𝑛
𝜃
ℒ
𝑀
align
𝐿
𝑃 𝑀 𝐿 𝑞𝑏𝑒
𝑀𝑀𝓒𝓒
𝐿 ℒ reader𝐸
𝑛 𝑃 𝑎 𝑞 an s ℒ align𝐿
𝑃 𝑎 𝑞 an s
ℒ reader
𝑢𝑢 𝑙𝑙𝑡𝑡𝑖𝑖
𝓒𝓒 𝐸𝐸 𝑛𝑛
𝑃an 𝑎s 𝐸 ℒ e2e𝑛 𝐿 𝑞
𝑀𝑀𝓒𝓒 𝑢𝑢
𝑀 𝐿𝜃
𝑙𝑙𝑡𝑡𝑖𝑖
𝑃an 𝑎s ℒ e2e𝐿 𝐿 𝑞
𝓒 𝑀 𝑢 𝑙𝑡𝑖 𝓒 𝐸 𝑛containstheevidenceisunavailable,andtherele- scoreservesasthepassagerelevancemeasurement:
vantpassagescanberetrievedfromanylanguage.
L = KL(P (·|q,D)||P (·|q,D)),
KL be ca
2.2 ModelArchitecture
exp(s(q,d ))
i
P (·|q,D) = |d ∈ D,
Weuseasingleencoder-decoderlanguagemodel be (cid:80) exp(s(q,d )) i
dj∈D j
toperformbothpassageretrievalandanswergen-
erationtask(Leeetal.,2022;Jiangetal.,2022).
(cid:88)H (cid:88)|di|
SG(CA(0,h,t))
P (·|q,D) = |d ∈ D,
ca i
H
Retriever Wedividetheencoderintotwoparts, h=0t=0
with the first B layers used as the dual-encoder,
whereP (·|q,D)andP (·|q,D)arethedistribu-
be ca
wherethequeryandpassageareencodedindepen-
tionsoverD fromtheretrieverandthedecoder’s
dently. Following Jiang et al. (2022), we use the
cross-attention scores, respectively. SG signifies
query Q and key vectors K in B +1-th layer as
the stop-gradient operation, and CA denotes the
queryandpassagerepresentations,respectively:
cross-attentionscoreatthelastdecoderlayer. The
term0referstothefirstoutputtoken,H isthenum-
E = {KB+1,h ∈ R|d|×e}H ,
d d h=1 berofcross-attentionheads,and|d |standsforthe
i
E q = {QB q+1,h ∈ R|q|×e}H h=1, lengthofpassaged i.
where|q|and|d|arequeryandpassagelength. H 3 Method
is the number of self-attention heads and e is the
dimensionofeachhead. Weproposeanunsupervisedtwo-stagepre-training
The self-attention matrix SAB+1,h from a spe- method for cross-lingual open-retrieval question
q,d
cific head is considered the source of retrieval answering,asdepictedinFigure1. Ourapproach
scores. Asumofmaxcomputations(Khattaband starts with cross-lingual retrieval pre-training,
Zaharia,2020)areperformedtoreduceittoyield where the multilingual model develops excellent
theretrievalscore: cross-lingualdenseretrievalcapabilities. Thispro-
ficiencyisacquiredthroughlearningfromawell-
s(q,d) = (cid:88) maxSAB+1,h, trainedEnglishmodel,employingcloze-styleparal-
i,j
j∈|d| lelqueriesandretrievedEnglishpassagesasinputs.
i∈|q|
The subsequent stage involves pre-training for
SAB+1,h = QB+1,h×KB+1,h⊤ ∈ R|q|×|d|.
q,d q d multilingual question-answering (QA), where
the model is further pre-trained on multilingual
Reader Aftertheretrieverlayer,bothqueryand
question-answerpairsthatareautomaticallygen-
passage are encoded jointly, wherein the remain-
erated. Thisprocessentailsselectingpotentialan-
ing encoder layers function as the cross-encoder.
swers from anchor texts and applying our novel
Then, the joint encodings of multiple passages
questiontransformationtechniquestoconvertcloze
{E }n areintegratedintothedecodertogen-
q,d i i=0 questions into natural questions by prompting a
eratetheanswerefficientlyfollowingtheFusion-
largelanguagemodel.
in-Decoderapproach(IzacardandGrave,2021).
3.1 Cross-LingualRetrievalPre-training
2.3 TrainingObjectives
Pre-trainingData Weconsiderclozequestions,
Themodelistrainedend-to-endbyemployingthe
whicharestatementswiththeanswermasked,as
trainingsignalsderivedfromtheanswergeneration
pseudoqueries. Theanswersaresalientspansse-
task: L = L +α·L .
e2e reader KL
lectedfromnamedentities. Weextractallnamed
ReaderLoss Thereaderistrainedwithlanguage entitiesforanEnglishsentenceusingaNERsys-
modelling loss via teacher forcing, by providing tem,generatingqueriesforeach. Formally,letsEn
thequeryqandacollectionofevidenceDasinput: beasentencesampledfromanEnglishWikipedia
page WEn, along with its associated named enti-
L
reader
=P ans(a|q,D)=−log(cid:81)T t=1P(a t|a <t,q,D) ties{a i}n i=1. Thisallowsustoderiveclozequeries
{qEn}n by masking each entity a . Then, for
i i=1 i
RetrieverLoss Theretrieveristrainedbylearn- each qEn, the objective is to identify its transla-
i
ingfromthedecoder,whereinthecross-attention tionqL inlanguageLbysearchingfromsentences
i
3{qL}n within a Wikipedia page WL, which is impedes the development of advanced question-
j j=0
connectedtoWEnvialanguagelinksinWikipedia. answeringskills. Moreover,theincapacitytopre-
Weuseamargin-basedminingmethod(Artetxe ciselylocateandmasktheanswerawithinqL for
andSchwenk,2019)toidentifyparallelsentences perfectly aligned queries makes the QA task no-
basedontheirsimilarityintheembeddingspace: tably simpler, as a implicitly appears in qL (e.g.,
"インド"inqL istheJapaneseanswerinFigure1).
cos(x,y) Meanwhile, since qEn and qL could be roughly
M(x,y) = ,
(cid:80) cos(x,z) +(cid:80) cos(y,z) aligned, the querying of a by qL is not assured,
z∈Nx 2k z∈Ny 2k
therebyintroducingnoiseintothepre-traineddata
where N x and N y are the top-k neighbours of (e.g.,"In1945,hisfathersenthimtoCollègedes
sentence x and y in the other language, respec- Frères" and "父はサブリーをヤッファのカ
tively. cos(x,y) denotes the cosine similarity be- トリック系フランス語学校に送った。" are
tween the embeddings of x and y. We follow aligned but the Japanese query does not mention
mSimCSE(Wangetal.,2022)topre-trainamultilin- the answer 1945). Thus, we design another pre-
gualmodelwithunsupervisedcontrastlearningand trainingtechniquetoaddressthelimitationsabove.
employitforembeddingextraction. Weapplythis
scoring function to qEn and each qL ∈ {qL}n . 3.2.1 Pre-trainingData
i j j j=0
Pairs whose scores surpass a pre-defined thresh-
Theconstructionofpre-trainingdatainthisstage
old T are selected as parallel queries, denoted as
involvestwosequentialsteps. Initialdataarefirst
{qEn,qL,a }.2
i j i acquiredfromamultilingualWikipediasourcein
theformatofclozequestions,followedbyaformat
Training A well-trained English model θEn is
transformationintonaturalquestions.
employedtoteachamultilingualmodelθML using
parallelqueries. Specifically,givenatrainingexam-
InitialData IncontrasttoEnglishtexts,where
ple{qEn,qL,a},weemployθEn toretrieveaset
robust NER systems facilitate the detection of
ofrelevantpassagesDEn fromEnglishWikipedia
namedentitieswithhighprecisionforanswergen-
CEnforqEn. Themultilingualmodelisthencom-
eration, such systems in other languages exhibit
pelledtoalignitsretrievaldistributionswiththose
inherentdeficiencies. Instead,weemployanchor
ofθEn overDEn throughKLdivergenceloss:
textswithhyperlinksasanswercandidates. Specif-
ically, for a given sentence sL in language L, we
L = KL(PML(·|qL,DEn)||PEn(·|qEn,DEn))
KL be be consider the anchor texts {aL}n within it as
+KL(PML(·|qEn,DEn)||PEn(·|qEn,DEn)). i i=0
be be potential answers and construct cloze questions
{qL}n accordingly.
Additionally, θML is trained to predict the an- i i=0
ForeachaL,wefetchtheWikipediapageWL
swerawitheitherqEn orqL asthequestion: i
towhichitlinksandaccessthecorrespondingEn-
L = P (a|qEn,DEn)+P (a|qL,DEn). glishWikipediapageWEn vialanguagelink. Sub-
reader ans ans
sequently,thetitleaEn ofWEn isassumedtobe
i
Moreover,toensurethatthemultilingualmodel thepseudotranslationofaL. Moreover,NERtag-
i
generatesconsistentpredictionsacrosslanguages, gingisperformedonthefirstparagraphofWEn to
weintroduceanalignmentregularisationterm: identifythetypet ofthetitleentityaEn,whichis
i i
thenassignedtoaL. Finally,atrainingexampleis
i
L align=KL(P bM eL(·|qL,DEn)||P bM eL(·|qEn,DEn)) derivedintheformof(q iL,aL
i
,aE
i
n,t i).3
+KL(P (a|qL,DEn)||P (a|qEn,DEn)).
ans ans
Query Transformation We employ large lan-
Overall,θML istrainedwiththeweightedcom- guagemodels(LLMs)forquerytransformationvia
binedloss: L = L +α·(L +L ). In-ContextLearning(ICL)(Brownetal.,2020).
stage1 reader KL align
WefirstpromptChatGPT(gpt-3.5-turbo)to
3.2 MultilingualQAPre-training
generate a few examples as meta-examples (Fan
Theclozequestionsaresubstantiallydifferentfrom et al., 2023) for ICL. Specifically, we randomly
theformatsofnaturalquestions,whichinherently
3Notably,aLischosenfortrainingwhenthedownstream
2Weidentifya iandmaskitinq jLthroughstringmatchif taskinvolvesmi ultilingualquestion-answering.Likewise,aE
i
n
LiswritteninLatinscriptandleaveqLunchangedotherwise. isemployedwhenEnglishanswergenerationisofinterest.
j
4sampleinstancesfromtheinitialdatasetandgener- B
CLASS-US
Stage 2
atetransformedquestionsbasedonthestructureof A D E
thepromptshowninPrompt3.1. Stage 1 NQ FT XOR FT
C
Stage 2
Prompt3.1: Meta-ExampleGeneration w/o QT CLASS-ZS CLASS
Figure2: Thetrainingpipelineofourmethod.
Rewritethissentence{qL}intoanaturalquestionwhose
i
questionwordis{wh_word}andansweris{aL}. Please
respond in the format: "The transformed
qi
uestion is:
7 languages of XOR-TYDI QA and a subset of
{qLT }" MKQAlanguagesasCMulti (Asaietal.,2021a).
i
WetakeR@2ktandR@5ktasevaluationmet-
wherewh_wordischosenaccordingtotheentity ricsforcross-lingualretrieval,whichmeasuresthe
typet i throughheuristics(Lewisetal.,2019). This fraction of queries for which the top-n retrieved
step yields a curated set of ICL examples: K = tokens contain the answer. The average R@2kt
{qL,wh_word,aL,qLT }k . Anexampleisshown andR@5ktscoresacrossalllanguagesareusedfor
i i i i=0
inFigure9intheAppendix. modelcomparison. F1andExactMatch(EM)are
We employ an open-sourced LLM, LLaMA-2- usedforevaluatingquestion-answeringtasks,with
7B(Touvronetal.,2023),fortheefficienttransfor- token-levelBLEUscoressupplementedonXOR-
mationofquestionsatlargescale. Specifically,the FullandMKQA.TheaverageF1scoreacrossall
promptisconstructedasfollows: (1)thefirstpart languagesisusedforperformancecomparisons.
includestheinstructionthatexpressestheintentof
the question transformation task; (2) n instances
4.2 ExperimentalSettings
are randomly sampled from K and organised in
a pre-defined structure; (3) the last part includes Pre-training Corpus In stage-1, for each
thetestinstancetobetransformed. Examplesare WEn ∈ CEn,wegatheritsparallelpagesacross
showninAppendixD. various languages. We consider 15 distinct lan-
guages,comprising7fromXOR-TYDI QA,and8
3.2.2 Training arehigh-resourceorcloselyrelatedtothe7evalu-
For each (qLT ,aL), we use the retrieval compo- atedlanguages. Parallelsentencesareminedfrom
nent of the current model θML to gather a set of eachpairofparallelpages. Astate-of-the-artNER
passagesDMulti fromCMulti,4 andoptimisethe taggerisappliedtoeachEnglishsentence,andwe
model using L as defined in §2.3. To ensure retainpairsfeaturingcontainednamedentities.
e2e
efficient training, passages are retrieved for each In stage-2, data generation is limited to 7 lan-
trainingquerybeforehand,withperiodicrefreshing guageson XOR-TYDI QA.WeemployLLaMA-
atspecificintervalsusingthemostrecentmodel. 2-7B to generate one transformed question per
trainingexamplewith3randomlysampledmeta-
4 Experiments
examplesinthesamelanguageastheprompt. We
generate multiple questions for each example in
4.1 Dataset
low-resource languages. More details are in Ap-
We evaluate our approach on the XOR-TYDI pendicesA.1.1andA.1.2.
QA dataset (Asai et al., 2021a), where the
XOR-Retrievetaskinvolvescross-lingualretrieval TrainingRecipe AnEnglishteacherθEn isfirst
and QA and XOR-Full centers on multilingual
trained on NQ (Kwiatkowski et al., 2019) as in
open-retrieval QA. For both tasks, we employ
Jiang et al. (2022). Undertaking stage-1 pre-
MKQA(Longpreetal.,2021),adatasetgenerated
trainingbyenforcingmt5-large(Xueetal.,2021)
by translating questions from Natural Questions tolearnfromθEnresultsinCLASS-US-Stage1,fol-
(NQ) (Kwiatkowski et al., 2019), to evaluate our
lowed by stage-2 pre-training to obtain the unsu-
model’szero-shotcross-lingualtransferabilityon
pervised model, CLASS-US. The zero-shot model
unseenlanguages. WeusetheFebruary2019En-
CLASS-ZSisacquiredbytrainingCLASS-USonEn-
glish Wikipedia dump as CEn and use the same
glish data (i.e., NQ), followed by fine-tuning on
Wikipediadumpsof13diverselanguagesfromall
labelled data from XOR-TYDI QA to obtain the
supervisedmodelCLASS.Anoverviewisshownin
4WereplaceaLwithaEnandCMultiwithCEnwhen
i
thedownstreamtaskofinterestisEnglishanswergeneration. Figure2andmoredetailsareinAppendixA.1.3.
5R@2kt R@5kt
Method Size
Ar Bn Fi Ja Ko Ru Te Avg Ar Bn Fi Ja Ko Ru Te Avg
UnsupervisedRetrievers
LAPCA¶§ 560M 51.1 50.2 48.6 35.1 57.3 32.2 64.4 48.4 61.0 58.4 52.6 40.5 66.7 40.8 70.1 55.7
CLASS-US 410M 66.0 75.7 63.4 57.7 63.5 68.8 70.6 66.5 71.2 81.6 69.4 66.8 70.5 75.1 77.3 73.1
Zero-shotRetrievers
DPR+MT† 220M 43.4 53.9 55.1 40.2 50.5 30.8 20.2 42.0 52.4 62.8 61.8 48.1 58.6 37.8 32.4 50.6
LAPCA¶§ 560M 46.2 50.3 56.6 41.4 48.7 52.3 54.6 50.0 53.0 60.5 66.2 49.7 56.1 60.7 63.8 58.6
ReAtt+MT 583M 63.1 67.7 20.7 55.9 60.3 55.3 58.4 54.5 67.3 71.0 29.3 61.8 67.0 61.2 66.4 60.6
CLASS-ZS 410M 65.1 79.3 67.8 60.6 61.1 69.2 74.4 68.2 72.5 83.2 73.9 70.5 69.1 75.1 81.9 75.2
(Semi-)SupervisedRetrievers
CORA 557M 32.0 42.8 39.5 24.9 33.3 31.2 30.7 33.5 42.7 52.0 49.0 32.8 43.5 39.2 41.6 43.0
mDPR† 557M 38.8 48.4 52.5 26.6 44.2 33.3 39.9 40.5 48.9 60.2 59.2 34.9 49.8 43.0 55.5 50.2
Sentri§ 560M 47.6 48.1 53.1 46.6 49.6 44.3 67.9 51.0 56.8 62.2 65.5 53.2 55.5 52.3 80.3 60.8
QuiCK 557M 52.8 70.1 62.2 54.8 62.8 57.8 70.6 61.3 63.8 78.0 65.3 63.5 69.8 67.1 74.8 68.9
DrDecr∗ 278M - - - - - - - 66.0 70.2 85.9 69.4 65.1 68.8 68.8 83.2 73.1
LAPCA¶§ 560M 61.1 76.9 72.6 60.9 69.1 69.1 75.6 69.3 70.2 83.8 79.6 69.7 73.6 75.5 83.1 76.5
CLASS 410M 67.3 80.9 67.2 64.7 71.6 69.6 79.8 71.6 74.8 84.5 72.3 73.9 79.3 77.2 85.3 78.2
F1 EM
Method Size
Ar Bn Fi Ja Ko Ru Te Avg Ar Bn Fi Ja Ko Ru Te Avg
mDPR† 835M 17.9 19.4 24.5 13.1 14.3 17.2 14.4 17.2 11.7 14.1 18.3 10.7 9.9 11.1 10.2 12.3
MT+DPR† - 28.0 25.6 29.3 19.2 19.4 18.4 3.8 20.5 23.4 20.3 22.1 13.8 14.2 13.6 2.7 15.7
ReAtt+MT 1.19B 26.0 36.6 3.5 18.4 29.3 29.3 27.0 24.3 17.1 30.1 1.7 14.5 22.7 22.8 21.0 18.6
GMT+GS† - 39.5 42.1 28.2 23.5 30.5 34.8 31.6 32.9 28.5 34.4 21.3 17.4 23.8 26.4 25.1 25.3
CLASS 1.23B 44.0 59.4 43.9 40.6 44.8 47.9 50.1 47.2 35.7 52.2 35.3 35.1 37.1 38.8 44.1 39.8
Table1: ResultsonthedevsetofXOR-Retrieve. ResultsreportedbyAsaietal.(2021a)andAbulkhanovetal.
(2023)aredenotedwith†and¶,respectively. ∗indicateshuman-translatedsupervisedparallelqueriesreleasedby
XOR-Retrieveareusedfortraining. §representsmethodsthatemployMTsystemsfortrainingdataaugmentation.
4.3 MainResults hindLAPCA.5 Themostpronouncedperformance
gaps are in Bengali and Korean, with the fewest
XOR-Retrieve Table1showstheresultsonthe
two training samples available within XOR-Full.
devsetofXOR-Retrieve. CLASS,whichexclusively
We believe it is the translated questions used by
employsquestion-answerpairsfortraining,demon-
Sentri and LAPCA that alleviate such discrepan-
stratesasubstantialperformanceadvantageoverall
cies. WeexpectCLASScanbefurtherimprovedby
baselinesthatrelyonpassagelabelsforcontrastive
introducing such augmented training data during
learning. Thisadvantageisparticularlypronounced
fine-tuning,whichweleaveasfuturework.
underunsupervisedandzero-shotsettings,where
both variants, CLASS-US and CLASS-ZS, achieve MKQA We assess the zero-shot performance
improvementsofmorethan10%comparedtostate- of CLASS in various unseen languages included
of-the-artmethods. IntheEnglishspanextraction in MKQA. Figure 3 shows that in cross-lingual
task,CLASSsurpassesallcompetitivebaselinesby retrieval tasks, all variants of our method exhibit
a significant margin (+15%), which is attributed promisingresults. Notably,CLASS-UScanoutper-
toitssuperiorretrievalabilitiesingatheringmore form the supervised model CORA significantly,
relevantdocuments. and further fine-tuning on English data leads to
substantialimprovements. Interestingly,CLASSun-
XOR-Full Table2reportstheresultsofCLASSon derperformsCLASS-ZS,despitebeingfurtherfine-
XOR-Full. CLASSachievessuperiorperformance tunedonmultilingualdata. Weattributethisphe-
whencomparedtoaseriesofbaselinemodelsand nomenon to two factors: the limited number of
thepriorstate-of-the-artCORAmodelinalltested queriesinXOR-Retrievemayresultinthemodel
languages, showcasing an average improvement overfitting to these specific languages; the query
of 7.8%. Compared to methods that rely on ma- topicsdiffer,asMKQAistheliteraltranslationof
chinetranslationtogenerateasubstantiallylarger
5AdirectcomparisonwithSentriandLAPCAisnotfeasi-
pool of multilingual training data from English
blesincetheWikipediapagestheyemployedasknowledge
datasets,CLASSiscomparabletoSentributfallsbe- sourcesaredifferentfromoursandAsaietal.(2021b).
6F1 MacroAverage
Method Size
Ar Bn Fi Ja Ko Ru Te F1 EM BLEU
BM25† - 31.1 21.9 21.4 12.4 12.1 17.7 – – – –
MT+DPR† - 7.2 4.3 17.0 7.9 7.1 13.6 0.5 8.2 3.8 6.8
ReAtt+MT 1.19B 15.0 10.5 1.8 13.1 14.9 15.4 8.2 11.3 5.5 9.5
GMT+GS† - 18.0 29.1 13.8 5.7 15.2 14.9 15.6 16.0 9.9 14.9
MT+Mono† - 15.8 9.6 20.5 12.2 11.4 16.0 0.5 17.3 7.5 10.7
CORA† 1.14B 42.9 26.9 41.4 36.8 30.4 33.8 30.9 34.7 25.8 23.3
CLASS 1.23B 49.5 32.0 49.6 44.7 37.5 41.4 42.0 42.4 32.7 29.2
IncomparableModels
Sentri§ 1.14B 52.5 31.2 45.5 44.9 43.1 41.2 30.7 41.3 34.9 30.7
LAPCA§ 1.14B 53.4 50.2 49.3 44.7 49.5 49.3 38.9 47.8 38.7 35.5
Table2: QuestionAnsweringresultsontheXOR-Fulldevset. ResultsreportedbyAsaietal.(2021b)aredenoted
with†. §indicatesmethodsthatusesyntheticandtranslatedqueriesfromEnglishdatasetsasaugmenteddata.
CORA Sentri CLASS-US CLASS CLASS - qL w/ 7 langs w/ MT
BM25+MT QuiCK CLASS-ZS 70 - qEn - align w/ CS
50
60
50
40
(a) Cross-lingual Retrieve
MT+Mono CLASS-US 40
25 ReAtt+MT CLASS-ZS R@2kt R@5kt
MT+DPR CLASS
CORA
70
20
60
15
(b) Multilingual QA 50
Figure3: Zero-shotcross-lingualretrievalresults(Avg.
R@2kt)onunseenlanguagesofMKQA. 40
ar bn fi ja ko ru te da* nl* no*
Figure4: Ablationsonstage-1pre-training,withresults
ontheXOR-Retrievedevsetreported. ∗ indicatesun-
NQwhileXOR-Retrieveiscreatedindependently.
seenlanguagesfromMKQA.
InthemultilingualQAtask,weobservesimilarpat-
ternswhereCLASS-ZSachievesthebestzero-shot
performanceacrossunseenlanguageswhilefurther
byensuringconsistentpredictions. iii)Pre-training
fine-tuningthismodelonXOR-Fulldataresultsin
solelyonthe7languagesof XOR-TYDI QA (w/
areductioninitsoverallgeneralizability.6 Detailed
7langs)doesnotsignificantlyimpactaverageper-
resultsineachlanguageareinAppendixB.
formance but affects specific low-resource lan-
guages. Inparticular,addingdatafromlanguages
4.4 Analysis
relatedtoTeluguandJapanese(e.g.,Tamil&Chi-
Wepresentdetailedablationstudiesinthissection.
nese) yields improvements. Moreover, including
MoreanalysesareinAppendixC.
a wider range of languages improves generalisa-
Ablations WecompareCLASSwithdifferentvari- tiontounseenlanguages. Forinstance,pre-training
ants to study the impact of different components in German enhances understanding of the West
instage-1pre-training. AsshowninFigure4,we Germaniclanguages(i.e.,Danish,Dutch,andNor-
foundthat: i)RemovingquerieseitherinEnglish wegian). iv) When comparing the approaches of
(-qEn) or in target languages (-qL) leads to per- gatheringparallelqueries,ourmethodoutperforms
formancedegradation. ii)Thecross-lingualalign- code-switching (w/ CS), which creates pseudo-
mentregularisation(-Lalign)enhancestheperfor- translationsthroughlexiconreplacementbasedon
mance of the model trained with parallel queries bilingualdictionaries,andmachinetranslations(w/
MT).Thisinferiorityisprimarilyattributedtothe
6Weleavetheexplorationofimprovedfine-tuningtech-
limitedcoverageofbilingualdictionariesandpoor
niquesthatstrikeabalancebetweenenhancingsupervisedand
zero-shotcross-lingualresultsasfuturework. translationqualityinlow-resourcelanguages.
7
tk2@R
1F
tk2@RXOR-Retrieve XOR-Full taband Zaharia,2020), anddistilling fromcross-
Method
R@2ktR@5kt F1 EM F1 EM BLEU encoderrerankers(Renetal.,2021). Withthead-
ventofmultilingualpre-trainedmodels,thesetech-
Unsupervised
CLASS-US(AB) 66.5 73.1 21.717.0 18.412.0 14.6 niqueswereadaptedtoimprovecross-lingualdense
-Stage-2(A) 59.1 67.4 6.0 4.1 5.7 3.9 4.0 retrievals (Asai et al., 2021b; Ren et al., 2022).
-QueryTF(AC) 66.1 73.1 7.4 5.5 7.2 4.8 4.9
However,allthesemethodsrelyonpassagelabels
Zero-shot
CLASS-ZS(ABD) 68.2 75.2 34.528.0 23.915.8 19.4 for contrastive learning, which is challenging to
-Stage-2(AD) 62.9 71.1 32.826.9 13.7 8.1 8.3 obtain in cross-lingual settings. In contrast, our
-Pre-train(D) 27.6 36.3 17.013.0 15.4 9.6 11.0
method explores a semi-supervised method and
Supervised
CLASS(ABDE) 71.6 78.2 47.239.8 42.432.7 29.2 showsthatacompetitivecross-lingualretrievercan
-Stage-2(ADE) 69.6 75.7 46.038.7 42.533.1 29.1 beachievedusingonlyquery-answerpairs.
-Pre-train(DE) 62.8 69.3 41.635.2 41.932.6 28.7
Multilingual Retrieval Pre-training Large-
Table3: Effectsoftwo-stagepre-training. Resultson scaleunsupervisedretrievalpre-traininghasbeen
thedevsetsarereported. Symbolswithinbracketsare shown to significantly enhance dense retriev-
describedinFigure2.
ers(GaoandCallan,2021;Izacardetal.,2022)in
processingEnglishtexts. Pre-traininghasalsobeen
Effects of Two-stage Pre-training We evalu- explored in cross-lingual and multilingual dense
atetheeffectivenessofourproposedpre-training retrieval,withaparticularemphasisonaugmenting
framework by excluding either the stage-2 or the the cross-lingual alignment capabilities of mod-
entirepre-trainingprocedures. Table3showcases els. LAPCA (Abulkhanov et al., 2023) is trained
theperformanceonbothXOR-RetrieveandXOR- through extensive cross-lingual contrastive learn-
Fullacrossunsupervised,zero-shot,andsupervised ing,employingtextsfromparallelWikipediapages
settings. The inclusion of stage-2 pre-training andparalleltextsgeneratedbymachinetranslation
dramatically boosts the performance in both un- systems. DrDecr(Lietal.,2022)learnsfromEn-
supervised and zero-shot scenarios. Removing glish models but operates on a smaller scale and
Query Transformation in stage-2 by solely em- reliesonsupervisedparallelqueries. Inthiswork,
ploying cloze-style questions has no discernible wedelveintothepotentialoflarge-scaleunsuper-
impact on retrieval performance but yields sub- visedpre-trainingforcross-lingualdenseretrieval
optimal QA results. This highlights the impor- and show that the resulting model exhibits high
tance of generating queries that resemble the for- efficacy,outperformingmanysupervisedones.
matsofnaturalquestionstodownstreamQAtasks.
Pre-trainingforRetrieval-AugmentedMultilin-
When discarding the entire pre-training process,
gualQA InthecontextofEnglish,jointlytrain-
wherein the model only uses the initial retrievals
ing a retriever and reader on supervised query-
from DPR (Karpukhin et al., 2020) for warm-up
answer pairs (Sachan et al., 2021; Lewis et al.,
training, we observe a notable decline in perfor-
2020) or large-scale unsupervised data derived
manceonbothdatasets. Insupervisedsettings,the
from masked salient span masking (Guu et al.,
advantagesconferredbyourproposedpre-training
2020;Leeetal.,2022)havebeenshowntoenhance
diminish in the presence of labelled data. These
theperformanceofbothretrievalandquestionan-
benefitsbecomeprogressivelyinconsequentialas
swering tasks. However, the application of such
thenumberofsuperviseddataincreases(i.e.,15K
a joint training paradigm, whether in supervised
inXOR-Retrievev.s. 61KinXOR-Full).
trainingorunsupervisedpre-training,hasnotbeen
exploredincross-lingualandmultilingualsettings.
5 RelatedWork
Ourstudyrepresentsthefirstinvestigationintothis
MultilingualDenseRetrieval Denseretrievers issue and proposes a curated pre-training frame-
adopt pre-trained language models and follow a work within a unified model to address both re-
dual-encoderarchitecture(Karpukhinetal.,2020) trievalandquestion-answeringtasks. Weintroduce
toencodequeriesandpassagesintodensevectors atwo-stagepre-trainingproceduretoinitiallyequip
andcalculatethesimilarityscores. Effectivetech- amultilingualmodelwithrobustcross-lingualre-
niques were proposed to advance English dense trieval abilities by learning from English experts
retrievals,includinghardnegativemining(Xiong andthengraduallyevolvingitthroughexposureto
et al., 2021), multi-vector representations (Khat- large-scalemultilingualQApairs. Thisapproach
8yieldsremarkableunsupervisedresultsandsignifi- aconcern. Nevertheless,itremainsimperativeto
cantperformanceimprovementsacrossunseenlan- exploremethodsforreducingtherelianceonpar-
guageswithoutannotatedtrainingdata. allel Wikipedia texts, as this is essential to scale
ourmethodtomorediverseanduniquelanguages,
6 Conclusion whichisworthexploringasafuturework.
Thisworkdoesnotexaminethebenefitsofpre-
Inthispaper,weexplorethepotentialofaunified
training in a broader range of languages and the
model for both cross-lingual retrieval and multi-
scaling effects of both model size and data size
lingualQAtasks. Byincorporatingourproposed
formultilingualQAtasks,whichisaninteresting
pre-trainingparadigm,CLASS,themodel’sperfor-
researchtopicthatshouldbeaddressedrigorously
mance can be significantly improved, achieving
inthefuture.
bothboostedretrievalandQAperformance,while
As this work uses large language models for
exhibiting impressive zero-shot transfer abilities
query transformation, it is possible that undesir-
tonumerousunseenlanguages. Detailedablations
ablebiases(e.g., genderandcultural)inherentin
andthoroughanalysesareconductedtoassessthe
theselanguagemodelsmaybepropagatedtodown-
efficacy of each component within our approach.
streamsystems. Furthermore,theextensivecorpus
OurfutureworkaimsatscalingCLASStoabroader
ofWikipediatexts,drawnfromamultitudeoflan-
rangeoflanguagestofurtherenhancethemodel’s
guages,couldpotentiallyintroduceadiversearray
cross-lingualtransferperformance.
of biases related to races and cultures to the pre-
trained model. Assessing the magnitude of bias
Limitations
withinthepre-trainingdataanditssubsequentim-
Theproposedpre-trainingframeworkincursaddi- pactonthemodelisaninherentlyintricateproblem,
tionaltrainingcostswhencomparedtostandardsu- whichremainsanopenquestionforfutureresearch.
pervisedtraining,suchasvariouspre-trainingdata Theoretically,ourmodelcanincorporateinforma-
generationpipelines. Theentiretrainingpipeline tionextractedfromanyexternalcorpustogenerate
requiresapproximatelytwoweekstocompletewith answerstoaskedquestions. Thiscapabilitycarries
amaximumof32A100GPUs. Thiscouldbeless the potential for significant information leakage
practicalforresearcherswhodonothaveaccessto or the exposure of potentially toxic content from
sufficient GPU resources. Nonetheless, common thecorpus,whichunderscorestheneedforexercis-
techniquessuchasgradientaccumulationcanbe ingcautionwhenapplyingourmethodinsensitive
appliedtoadaptourapproachfortraininginamore domains.
academic setting, although more training time is
requiredtoachievecomparableresults.
References
Bothstagesinourpre-trainingparadigmdepend
ontheavailabilityofparallelWikipediapages. This DmitryAbulkhanov,NikitaSorokin,SergeyNikolenko,
canposeachallengewhendealingwithlanguages and Valentin Malykh. 2023. Lapca: Language-
thathavelimitedresourcesevenintermsofmono- agnosticpretrainingwithcross-lingualalignment. In
Proceedings of the 46th International ACM SIGIR
lingual texts. Our approach may fail when no
ConferenceonResearchandDevelopmentinInfor-
language links exist between English and a spe-
mationRetrieval,SIGIR’23,page2098–2102,New
cific low-resource language. One may resort to York,NY,USA.AssociationforComputingMachin-
employingamulti-hopapproachtodiscoverparal- ery.
lelWikipediapages,byfirstsearchingforthelan-
Mikel Artetxe and Holger Schwenk. 2019. Margin-
guagelinkedtothelow-resourcelanguagewithin
basedparallelcorpusminingwithmultilingualsen-
Wikipedia and then repeating this process itera- tence embeddings. In Proceedings of the 57th An-
tively until reaching the corresponding English nualMeetingoftheAssociationforComputational
Linguistics,pages3197–3203,Florence,Italy.Asso-
page. Anotheroptioncouldberelyingonthegen-
ciationforComputationalLinguistics.
eralisationofthemultilingualmodelbytrainingit
inclosely-relatedlanguages. Ouranalysishasre- AkariAsai,JungoKasai,JonathanClark,KentonLee,
vealedthatincorporatingahigh-resourcelanguage EunsolChoi,andHannanehHajishirzi.2021a. XOR
QA:Cross-lingualopen-retrievalquestionanswering.
inthepre-trainingphaseconsistentlyresultsinim-
InProceedingsofthe2021ConferenceoftheNorth
provements for other languages within the same
AmericanChapteroftheAssociationforComputa-
language family, which makes this issue less of tionalLinguistics: HumanLanguageTechnologies,
9pages 547–564, Online. Association for Computa- pages 874–880, Online. Association for Computa-
tionalLinguistics. tionalLinguistics.
Akari Asai, Xinyan Yu, Jungo Kasai, and Hannaneh ZhengbaoJiang,LuyuGao,ZhiruoWang,JunAraki,
Hajishirzi. 2021b. One question answering model Haibo Ding, Jamie Callan, and Graham Neubig.
formanylanguageswithcross-lingualdensepassage 2022. Retrieval as attention: End-to-end learning
retrieval. In Advances in Neural Information Pro- ofretrievalandreadingwithinasingletransformer.
cessingSystems. In Proceedings of the 2022 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
Tom Brown, Benjamin Mann, Nick Ryder, Melanie 2336–2349,AbuDhabi,UnitedArabEmirates.As-
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind sociationforComputationalLinguistics.
Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
Gretchen Krueger, Tom Henighan, Rewon Child, Lewis,LedellWu,SergeyEdunov,DanqiChen,and
AdityaRamesh,DanielZiegler,JeffreyWu,Clemens Wen-tauYih.2020. Densepassageretrievalforopen-
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma- domainquestionanswering. InProceedingsofthe
teusz Litwin, Scott Gray, Benjamin Chess, Jack 2020ConferenceonEmpiricalMethodsinNatural
Clark, ChristopherBerner, SamMcCandlish, Alec LanguageProcessing(EMNLP),pages6769–6781,
Radford, Ilya Sutskever, and Dario Amodei. 2020. Online.AssociationforComputationalLinguistics.
Language models are few-shot learners. In Ad-
OmarKhattabandMateiZaharia.2020. Colbert: Effi-
vances in Neural Information Processing Systems,
cientandeffectivepassagesearchviacontextualized
volume 33, pages 1877–1901. Curran Associates,
lateinteractionoverbert. InProceedingsofthe43rd
Inc.
InternationalACMSIGIRConferenceonResearch
DanqiChen,AdamFisch,JasonWeston,andAntoine and Development in Information Retrieval, SIGIR
Bordes.2017. ReadingWikipediatoansweropen- ’20,page39–48,NewYork,NY,USA.Association
domainquestions. InProceedingsofthe55thAnnual forComputingMachinery.
Meeting of the Association for Computational Lin-
TomKwiatkowski, JennimariaPalomaki, OliviaRed-
guistics(Volume1: LongPapers),pages1870–1879,
field,MichaelCollins,AnkurParikh,ChrisAlberti,
Vancouver,Canada.AssociationforComputational
DanielleEpstein,IlliaPolosukhin,JacobDevlin,Ken-
Linguistics.
tonLee,KristinaToutanova,LlionJones,Matthew
Alexis CONNEAU and Guillaume Lample. 2019. Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob
Cross-lingual language model pretraining. In Ad- Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-
vances in Neural Information Processing Systems, ralquestions: Abenchmarkforquestionanswering
volume32.CurranAssociates,Inc. research. TransactionsoftheAssociationforCompu-
tationalLinguistics,7:452–466.
Lijie Fan, Dilip Krishnan, Phillip Isola, Dina Katabi,
andYonglongTian.2023. ImprovingCLIPtraining HaejunLee,AkhilKedia,JongwonLee,AshwinParan-
withlanguagerewrites. InThirty-seventhConference jape, Christopher Manning, and Kyoung-Gu Woo.
onNeuralInformationProcessingSystems. 2022. You only need one model for open-domain
questionanswering. InProceedingsofthe2022Con-
LuyuGaoandJamieCallan.2021. Condenser: apre- ferenceonEmpiricalMethodsinNaturalLanguage
trainingarchitecturefordenseretrieval. InProceed- Processing, pages 3047–3060, Abu Dhabi, United
ingsofthe2021ConferenceonEmpiricalMethods ArabEmirates.AssociationforComputationalLin-
in Natural Language Processing, pages 981–993, guistics.
OnlineandPuntaCana,DominicanRepublic.Asso-
ciationforComputationalLinguistics. PatrickLewis,LudovicDenoyer,andSebastianRiedel.
2019. Unsupervised question answering by cloze
KelvinGuu,KentonLee,ZoraTung,PanupongPasu- translation. InProceedingsofthe57thAnnualMeet-
pat,andMing-WeiChang.2020. Realm: retrieval- ingoftheAssociationforComputationalLinguistics,
augmentedlanguagemodelpre-training. InProceed- pages 4896–4910, Florence, Italy. Association for
ingsofthe37thInternationalConferenceonMachine ComputationalLinguistics.
Learning,ICML’20.JMLR.org.
PatrickLewis,EthanPerez,AleksandraPiktus,Fabio
GautierIzacard,MathildeCaron,LucasHosseini,Sebas- Petroni,VladimirKarpukhin,NamanGoyal,Hein-
tianRiedel,PiotrBojanowski,ArmandJoulin,and richKüttler, MikeLewis, Wen-tauYih, TimRock-
EdouardGrave.2022. Unsuperviseddenseinforma- täschel, Sebastian Riedel, and Douwe Kiela. 2020.
tionretrievalwithcontrastivelearning. Transactions Retrieval-augmented generation for knowledge-
onMachineLearningResearch. intensive nlp tasks. In Advances in Neural Infor-
mationProcessingSystems,volume33,pages9459–
GautierIzacardandEdouardGrave.2021. Leveraging 9474.CurranAssociates,Inc.
passageretrievalwithgenerativemodelsforopendo-
mainquestionanswering. InProceedingsofthe16th Yulong Li, Martin Franz, Md Arafat Sultan, Bhavani
ConferenceoftheEuropeanChapteroftheAssoci- Iyer,Young-SukLee,andAvirupSil.2022. Learn-
ationforComputationalLinguistics: MainVolume, ing cross-lingual IR from an English retriever. In
10Proceedings of the 2022 Conference of the North YaushianWang,AshleyWu,andGrahamNeubig.2022.
AmericanChapteroftheAssociationforComputa- Englishcontrastivelearningcanlearnuniversalcross-
tionalLinguistics: HumanLanguageTechnologies, lingual sentence embeddings. In Proceedings of
pages4428–4436,Seattle,UnitedStates.Association the2022ConferenceonEmpiricalMethodsinNat-
forComputationalLinguistics. uralLanguageProcessing,pages9122–9133,Abu
Dhabi,UnitedArabEmirates.AssociationforCom-
Shayne Longpre, Yi Lu, and Joachim Daiber. 2021.
putationalLinguistics.
MKQA:Alinguisticallydiversebenchmarkformul-
tilingualopendomainquestionanswering. Transac- LeeXiong,ChenyanXiong,YeLi,Kwok-FungTang,
tionsoftheAssociationforComputationalLinguis- Jialin Liu, Paul N. Bennett, Junaid Ahmed, and
tics,9:1389–1406. ArnoldOverwijk.2021. Approximatenearestneigh-
bor negative contrastive learning for dense text re-
PengQi,YuhaoZhang,YuhuiZhang,JasonBolton,and
trieval. In International Conference on Learning
Christopher D. Manning. 2020. Stanza: A python
Representations.
naturallanguageprocessingtoolkitformanyhuman
languages. InProceedingsofthe58thAnnualMeet-
LintingXue,NoahConstant,AdamRoberts,MihirKale,
ingoftheAssociationforComputationalLinguistics:
RamiAl-Rfou,AdityaSiddhant,AdityaBarua,and
SystemDemonstrations,pages101–108,Online.As-
ColinRaffel.2021. mT5: Amassivelymultilingual
sociationforComputationalLinguistics. pre-trainedtext-to-texttransformer. InProceedings
ofthe2021ConferenceoftheNorthAmericanChap-
Houxing Ren, Linjun Shou, Ning Wu, Ming Gong,
teroftheAssociationforComputationalLinguistics:
andDaxinJiang.2022. Empoweringdual-encoder
HumanLanguageTechnologies,pages483–498,On-
withquerygeneratorforcross-lingualdenseretrieval.
line.AssociationforComputationalLinguistics.
In Proceedings of the 2022 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
XinyuZhang,XueguangMa,PengShi,andJimmyLin.
3107–3121,AbuDhabi,UnitedArabEmirates.As-
2021. Mr. TyDi: A multi-lingual benchmark for
sociationforComputationalLinguistics.
denseretrieval. InProceedingsofthe1stWorkshop
RuiyangRen,YingqiQu,JingLiu,WayneXinZhao, onMultilingualRepresentationLearning,pages127–
QiaoQiaoShe,HuaWu,HaifengWang,andJi-Rong 137,PuntaCana,DominicanRepublic.Association
Wen.2021. RocketQAv2: Ajointtrainingmethod forComputationalLinguistics.
fordense passageretrievaland passagere-ranking.
In Proceedings of the 2021 Conference on Empiri-
calMethodsinNaturalLanguageProcessing,pages
2825–2835,OnlineandPuntaCana,DominicanRe-
public.AssociationforComputationalLinguistics.
DevendraSinghSachan,SivaReddy,WilliamL.Hamil-
ton,ChrisDyer,andDaniYogatama.2021. End-to-
endtrainingofmulti-documentreaderandretriever
foropen-domainquestionanswering. InAdvancesin
NeuralInformationProcessingSystems.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale,DanBikel,LukasBlecher,CristianCanton
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
CynthiaGao,VedanujGoswami,NamanGoyal,An-
thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
IsabelKloumann,ArtemKorenev,PunitSinghKoura,
Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez,RobertStojnic,SergeyEdunov,andThomas
Scialom.2023. Llama2: Openfoundationandfine-
tunedchatmodels.
11A ExperimentalSettings A.1.2 QueryTransformation
We use ChatGPT to generate 32 meta-examples.
A.1 ImplementationDetails
We then employ LLaMA-2-7B9 for query trans-
A.1.1 ParallelQueriesMining formationbyrandomlysampling3meta-examples
to construct prompts for each test instance, with
Ourimplementationencompasses15distinctlan-
theformatasshowninPromptsD.1,D.2,D.3,D.4,
guages,namelyArabic,Bengali,German,Span-
D.5,D.6,andD.7. WeuseBloomz-7B10forTelugu
ish, Finnish, French, Italian, Japanese, Korean,
aswefindLLaMA-2-7Bdoesnotworkwellinthis
Russian, Telugu, Tamil, Malayalam, Kannada,
language. TheQuestionwordwh_wordischosen
Chinese. Parallelqueriesarecollectedfromparal-
lelWikipediapagesforeachen-x. Usingunsuper- based on the entity type of the answer according
totheheuristicrulesinTable7. Ultimately,146K
visedcontrastivelearning,weadopttheapproach
examplesaregeneratedperlanguage,resultingin
in Wang et al. (2022) to first pre-train a multilin-
gualmodelXLM-R7 onEnglishWikipediatextsby atotalof1Mtraininginstances.
taking the dropout as a form of data augmenta-
A.1.3 TrainingDetails
tion. Theresultingmodelisproficientingenerat-
We use mt5-large11 to initialise the model. In
ing universal cross-lingual sentence embeddings
stage-1, we train the model for 64k steps on 32
without the need for parallel data, demonstrating
A100GPUs,whichtakesaboutoneweektocom-
robustzero-shotcross-lingualtransfercapabilities.
plete. The passages for all training queries are
Subsequently,wedeploythepre-trainedmodelfor
retrieved by the English teacher at once before
extractingmultilingualsentenceembeddingsand
training. In stage-2, we further train the model
miningparallelqueriesforeachen-xlanguagepair.
for 16k steps on 16 A100 GPUs with roughly 4
Empirically,wesetthemargin-scorethresholdto
days. Weperiodicallyupdatetheretrievedpassages
1.5formostlanguages;however,forJapaneseand
foreachtraininginstanceevery1kstepsusingthe
Chinese,weobserveimprovedperformancewith
mostrecentmodel. Forfine-tuning,wefirsttrain
alargerthresholdof1.65. Thisprocessyields5.4
the model on NQ with 8k steps and fine-tune the
million examples for the training, with the num-
modelonXOR-Retrievefor6kstepsand12ksteps
berofparallelqueriesforeachlanguagepairen-x
onXOR-Full,whichtakesabout19hoursand156
showninFigure5.
hourstocomplete,respectively. Likewise,wealso
We employ a balanced sampling strategy to
dopassagerefreshingperiodicallyevery1ksteps.
avoidthetrainingbiastowardshigh-resourcelan-
For all training stages, we use the same batch
guages. For N number of languages {D }N
i i=1 size of 64 queries with each paired with 100 re-
withprobabilities,{p }N ,wedefinethefollowing
i i=1 trieved passages and learning rate 5×10−5. We
multinomialdistributiontosamplefrom:
setαto8inalltraininglossfunctions. Wesetthe
fα n maximumqueryandpassagelengthsto50and200
p i = (cid:80)Ni fα,wheref i = (cid:80)N i
n
, forbothtrainingandevaluation.
j=1 j j=1 j
A.2 Datasets
where α is the sampling factor, which is set to
Weusedthefollowingdatasetsformodelevalua-
0.5byfollowingCONNEAUandLample(2019)
tioninourexperiments:
and n is the total number of parallel queries in
i • XOR-Retrieve. This dataset is under the
thei-thlanguage. Duringtraining,weusethisto
MIT License for non-commercial research
determinen′,thenumberofparallelqueriesineach
i purposes. Itcontains15250QApairsfortrain-
language;andtop-n′ queriesareusedfortraining
i ingandtakesthe20190201EnglishWikipedia
according to the margin-based scores. For every
dumpwhichcontains18Mpassagesasthere-
pairofminedquery,weemployastate-of-the-art
trievaldatabase.
NamedEntityTaggerfromStanza(Qietal.,2020)8
• XOR-Full. It is under the MIT License for
tofindsaliententitieswithintheEnglishqueryand
non-commercial research purposes. It con-
takeallidentifiedentitiesasanswercandidatesto
tains61360QApairsfortrainingandacollec-
constructcloze-stylequeries.
9https://huggingface.co/meta-llama/Llama-2-7b
7https://huggingface.co/xlm-roberta-large 10https://huggingface.co/bigscience/bloomz-7b1
8https://github.com/stanfordnlp/stanza 11https://huggingface.co/google/mt5-large
121e6
Original
1.4 Resample
1.2
1.0
0.8
0.6
0.4
0.2
0.0
ar bn de es fi fr it ja ko ru te ta ml kn zh
Languages
Figure5: Thenumberofminedparallelqueriesforeachlanguagepairen-x.
tionof43Mpassagesastheretrievaldatabase, 111,744,1254,829,720,421,995,670,646,
whichiscollectedfrom20190201Wikipedia and1190ineachlanguage,respectively. The
dumpsacross13languages,namelyEnglish, corpussizesforretrievalare2M,300K,33M,
Arabic, Finnish, Japanese, Korean, Russian, 1.9M, 1.5M, 7M, 1.5M, 9.6M, 137K, 548K,
Bengali, Telugu, Indonesian, Thai, Hebrew, and569Kineachlanguage,respectively.
Swedish,andSpanish.
• Natural Questions. It is under the Apache A.3 Baselines
Licenseandcontains79168QApairs. A.3.1 Cross-lingualPassageRetrieval
• MKQA. It is under the Apache License.
Wecompareourproposedmodelwitharangeof
This dataset covers 26 linguistically diverse
strongbaselines:
languages,namelyArabic,Danish,German,
• mDPR. This is the multilingual version of
English, Spanish, Finnish, French, Hebrew,
Dense Passage Retrieval (DPR) (Karpukhin
Hungarian,Italian,Japanese,Korean,Khmer,
etal.,2020)encoder,whichundergoesinitial
Malay,Dutch,Norwegian,Polish,Portuguese,
training on English NQ queries followed by
Russian,Swedish,Thai,Turkish,Vietnamese,
fine-tuningonXOR-Retrieve.
Chinese(Simplified),Chinese(HongKong),
• DPR+MT. This is a translate-test baseline
and Chinese (Traditional). For the cross-
that involves the translation of queries into
lingualretrievaltask,eachlanguagecontains
Englishduringtesttime,followedbymonolin-
6620questionsandtheretrievaldatabasecon-
gualpassageretrievalusingtheEnglishDPR
sistsof18MEnglishWikipediapassages. For
encoder.
themultilingualQAtask,eachlanguagecon-
• CORA. This method trains a multilingual
tains6758questionsanditusesthesamere-
DPR encoder iteratively, with positive and
trievaldatabaseasXOR-Full.
negativepassagesidentifiedbyamultilingual
• Mr.TyDi. It is under the Apache License.
QAmodel.
This dataset contains 11 languages, namely
• Sentri. Aniterativeself-trainingmethodthat
Arabic,Bengali,English,Finnish,Indonesian,
uses the latest retriever to identify positive
Japanese, Korean, Russian, Swahili, Telugu,
andnegativepassagesthroughanswerstring
and Thai. The queries for testing are 1081,
matchingforupdatingthetrainingdataset. It
13
seireuQ
lellaraP
fo
rebmuNalso employs data augmentation techniques • MT+Mono. This is a combination of the
bytranslatingEnglishdatasets. BM25 and MT+DPR baselines, which first
• QuiCK. A knowledge distillation method doesmonolingualQAforthetargetlanguage
thattrainsamultilingualbi-encoderretriever, using the BM25 method and resorts to the
learningfromaquerygeneratorastheteacher. MT+DPRbaselineifnoanswerisfound.
Thequerygeneratorisalsousedforgenerat- • Fusion-in-Decoder. Thisencompassesafam-
ingsyntheticmultilingualqueriestoenhance ily of multilingual retrieval-augmented gen-
theknowledgedistillationprocess. eration models, which take the passages re-
• DrDecr. AmultilingualColBERTmodelthat turned by a multilingual retriever as inputs
learnsfromanEnglishColBERTonparallel togeneratetheanswerinthetargetlanguage.
queries, sourced from both parallel corpora CORA,SentriandLAPCAareincludedin
and human-translated gold queries released thisfamilybyusingthepassagesreturnedby
byXOR-Retrieve. theirrespectiveretrievers.
• LAPCA. Apre-trainingmethodthattakesthe
first paragraphs of parallel Wikipedia pages B DetailedZero-shotEvaluation
as the parallel corpus for cross-lingual pre-
Cross-lingual Retrieval Table 4 presents the
training. Additionally,machinetranslationis
detailed result comparisons in each of the 20
employedfordataexpansion.
unseen languages covered by MKQA. Notably,
CLASS-ZSoutperformsotherbaselinessignificantly
A.3.2 MultilingualOpenDomainQuestion
onaverageandachievesthebestresultsinnearly
Answering
all languages except for Vietnamese. Compar-
• mDPR. Thismodelusesamultilingualreader
ing the three variants of our method, fine-tuning
toidentifytheanswerspanfromthepassages
onsupervisedEnglishdatasignificantlyenhances
retrievedbythemDPRretrieverasdescribed
cross-lingualtransferabilitiestoeveryunseenlan-
above.
guage (i.e., CLASS-US vs CLASS-ZS). However,
• MT+DPR. Thisrepresentsthetranslate-test
fine-tuningCLASS-ZSonalimitednumberofsuper-
baseline,inwhichqueriesaretranslatedinto
visedmultilingualdatawitharestrictedlanguage
Englishandtheanswersareidentifiedwithin
set does not lead to improved generalization per-
English passages retrieved by the DPR+MT
formance, as indicated by the result comparison
retriever. The English answer is then trans-
in every language between CLASS-ZS and CLASS.
latedbacktothetargetlanguageifnecessary.
Furthermore,adecreaseinperformanceisalsoob-
• ReAtt+MT. ThisistheEnglishteacherem-
served in both supervised and zero-shot settings
ployedinourstage-1pre-training. Weusea
wheneitherstage-2pre-trainingortheentirepre-
state-of-the-art machine translation model12
training procedures are omitted, highlighting the
to translate the queries into English at test
effectiveness of our pre-training approach in en-
time. It always retrieves passages from En-
hancingcross-lingualability.
glishWikipediaandgeneratesanswersinEn-
glish. Thegeneratedansweristranslatedback Multilingual QA Table 5 presents the detailed
tothetargetlanguageifnecessary. multilingualQAresultsforeachofthe20unseen
• GMT+GS. This pipeline follows the same languages covered by MKQA. We observe simi-
procedure as MT+DPR except that we em- larpatternswhereCLASS-USsurpassesarangeof
ploy Google Search for passage retrieval machine-translation-basedmethodsandCLASS-ZS
andGoogleMachineTranslationservicesfor outperformsthesupervisedCORAwithasignifi-
queryandanswertranslation. cant margin. Further fine-tuning CLASS-ZS on a
• Monolingual baseline (BM25). Instead of limited number of supervised multilingual data
usingamultilingualDPRoranEnglishDPR with a restricted language set hampers its gener-
model with query translation, this baseline alizability,withadeclineinperformanceacrossall
always retrieves the passage from the target examinedlanguages.
languageandextractstheanswerusingamul-
tilingualreader. MonolingualRetrieval Weevaluatethemodel
on the monolingual retrieval setting, with the re-
12https://huggingface.co/facebook/m2m100_418M sultsontheMr. TyDidataset(Zhangetal.,2021)
1460
42
50 40
38
40
w/ CS 36 CLASS
w/ MT
CORA
CLASS
30 34
0 20 40 60 80 100 5 15 25 50 100
Billion of Tokens Number of Passages
Figure6:Performanceevolutioninstage-1pre-training. Figure 8: Effects of employing different numbers of
retrievedpassagesforQAduringinferencetime.
70
morelabelleddatabecomesavailable. Notably,as
60 illustrated in Figure 7, the introduction of stage-
2 pre-training results in a 75% reduction in the
50
required amount of labelled data. Furthermore,
40 CLASS employing pre-training of both stages eliminates
CLASS w/o stage-2
CLASS w/o pre-train the need for any labelled data, in contrast to the
30
1% 5% 25% 50% 75% 100% approachthatsolelyreliesonsuperviseddatafor
Figure7:Scalingtrainingdataoncross-lingualretrieval. training(i.e.,CLASSw/opre-train).
EffectsofNumberofRetrievedPassages Fig-
reported in Table 6. We compare CLASS-ZS with
ure8reportstheperformanceconcerningthenum-
a series of zero-shot multilingual retrievers that
ber of retrieved passages for QA during infer-
havebeenfine-tunedonEnglishdatasets. Notably,
ence. Weobservetheperformanceimprovescon-
eventhoughCLASS-ZShavenotundergoneexplicit
sistently as the number of retrieved passages in-
training for monolingual retrieval, it consistently
creases. CLASS significantly outperforms CORA
outperformstheothermodelsineverylanguageex-
whenusingonlytop-5retrievedpassages,showcas-
amined,withtheperformancegainsbeingparticu-
ingsuperiorinferenceefficiency.
larlypronouncedinlanguageswritteninNon-Latin
scripts(e.g.,Japanese,Korean,andThai).
D QueryTransformationExamples
C MoreAnalysis Table9showcasesexamplesillustratingthegener-
ation of meta-examples through prompting Chat-
Performance Evolution during Pre-training
GPT. Prompts D.1, D.2, D.3, D.4, D.5, D.6, and
Figure 6 illustrates the trajectory of the perfor-
D.7 provide detailed illustrations of prompting a
manceontheXOR-Retrievecross-lingualretrieval
muchsmallerlargelanguagemodel,LLaMA-2-7B,
task. As shown in the Figure, the use of code-
toperformquerytransformationusingIn-Context
switchingconsistentlyyieldsinferiorresultscom-
Learning,whichincorporatesmeta-examplesinto
paredtoCLASSandthevariantusingmachinetrans-
the prompt to guide the model’s behaviour. The
lation. Aftertrainingonaround45billiontokens,
choice of the question word is determined based
CLASSconsistentlyoutperformsMT,matchingthe
on the detected entity type of the answer and the
performance of CS and MT with only 30% and
heuristicrulesoutlinedinTable7.
50%computationcosts. Thisdemonstratesgreater
trainingefficiency. Theperformancecontinuesto
improveoverthenext50%ofthetrainingtokens,
implying that the scalability of pre-training data
remainsbeneficialastrainingprogresses.
Few-ShotCross-lingualRetrieval Weconsider
afew-shotlearningtaskwithvaryingnumbersof
labelled training examples. Figure 7 shows that
CLASSisconsistentlybetterthantheothertwovari-
ants,althoughtheperformancegapdiminishesas
15
tk2@R
tk2@R
1FMethod Da De Es Fr He Hu It Km Ms Nl No Pl Pt Sv Th Tr Vi cn hk tw Avg
Unsupervised
CLASS-US 50.5 53.4 53.8 53.9 44.1 49.1 52.6 39.8 55.3 53.3 49.5 52.6 50.4 52.5 54.9 50.9 48.0 48.0 46.3 46.4 50.3
Zero-shot
BM25+MT 44.1 43.3 44.9 42.5 36.9 39.3 40.1 31.3 42.5 46.5 43.3 46.5 45.7 49.7 46.5 42.5 43.5 37.5 37.5 36.1 42.0
CLASS-ZS 59.3 58.9 59.4 59.2 50.1 54.0 58.7 46.2 59.6 60.4 58.5 57.5 58.0 59.4 58.0 55.1 54.1 52.1 51.5 51.4 56.1
-Stage-2 58.0 57.6 57.7 58.0 47.3 51.8 57.2 44.4 58.0 59.3 57.1 56.1 56.2 57.7 56.4 53.6 52.3 50.6 49.8 49.1 54.4
-Pre-train 50.9 50.5 49.9 50.0 32.5 41.9 49.6 32.9 49.9 52.3 50.2 46.6 49.3 51.5 44.2 44.7 41.3 37.8 37.7 37.1 45.0
Supervised
CORA 44.5 44.6 45.3 44.8 27.3 39.1 44.2 22.2 44.3 47.3 48.3 44.8 40.8 43.6 45.0 34.8 33.9 33.5 41.5 41.0 41.1
Sentri 57.6 56.5 55.9 55.1 47.9 51.8 54.3 43.9 56.0 56.3 56.5 55.8 54.8 56.9 55.3 53.0 54.4 50.2 50.7 49.4 53.3
QuiCK 58.3 56.4 55.2 55.5 44.7 52.4 52.3 42.0 56.9 57.5 57.0 54.9 54.7 58.0 55.7 53.9 54.9 50.4 49.3 48.9 53.4
CLASS 57.4 57.5 58.0 57.8 48.5 52.5 57.1 43.4 58.2 58.4 56.7 56.0 56.4 57.6 57.2 54.2 52.5 51.3 49.9 50.2 54.6
-Stage-2 56.9 57.3 57.2 57.0 47.3 51.8 56.2 42.9 57.6 58.7 56.0 55.3 55.5 56.8 56.1 53.3 51.5 51.4 49.9 49.4 53.9
-Pre-train 56.5 55.3 55.9 55.1 44.8 50.8 55.0 41.3 56.4 57.4 55.8 53.3 54.8 56.5 53.7 51.9 49.6 47.3 46.4 45.8 52.2
Table4:Zero-shotcross-lingualretrievalresults(R@2kt)ontheMKQAdataset."cn":"Zh-cn"(Chinese,simplified).
"hk": "Zh-hk"(Chinese,HongKong). "tw": "Zh-tw"(Chinese,traditional).
Method Da De Es Fr He Hu It Km Ms Nl No Pl Pt Sv Th Tr Vi cn hk tw Avg
Unsupervised
CLASS-US 24.9 27.4 29.1 27.1 12.9 21.7 25.2 9.3 26.3 27.0 25.0 23.7 22.4 26.0 13.2 22.8 17.5 7.3 8.9 6.3 20.2
Zero-shot
ReAtt+MT 22.4 23.9 21.6 23.5 24.2 6.3 13.7 3.2 12.7 22.1 21.5 11.2 18.6 17.3 7.2 6.3 24.0 10.8 4.7 4.0 15.0
MT+DPR 26.2 25.9 28.4 21.9 8.9 15.7 25.1 1.2 12.6 28.3 18.3 24.6 24.7 19.7 6.9 18.2 15.1 3.3 3.8 3.8 16.5
CLASS-ZS 37.6 38.5 40.2 37.6 17.0 29.1 36.2 16.2 36.9 38.6 37.4 34.4 33.6 38.6 18.9 30.9 29.6 8.7 13.8 8.5 29.1
Supervised
MT+Mono 19.3 21.6 21.3 21.9 8.9 16.5 20.9 1.2 12.6 21.5 17.4 24.6 19.9 20.0 8.3 16.6 15.1 4.9 3.8 5.1 14.8
CORA 30.4 30.2 32.0 30.8 15.8 18.4 29.0 5.8 27.8 32.1 29.2 25.6 28.4 30.9 8.5 22.2 20.9 5.2 6.7 5.4 21.8
CLASS 33.4 35.4 37.5 35.7 12.3 27.7 35.3 10.2 34.6 36.1 34.3 31.9 32.8 33.3 17.6 29.3 25.1 8.6 10.2 7.4 26.4
Table5: Zero-shotmultilingualquestionansweringresults(F1)ontheMKQAdataset. "cn": "Zh-cn"(Chinese,
simplified). "hk": "Zh-hk"(Chinese,HongKong). "tw": "Zh-tw"(Chinese,traditional).
Method Ar Bn Fi Id Ja Ko Ru Sw Te Th Avg
mDPR 62.0 67.1 37.5 46.6 53.5 49.0 49.8 26.4 35.2 45.5 47.3
LAPCA 89.4 95.0 83.6 90.6 78.1 76.0 80.2 74.4 93.0 92.8 85.3
mContriever 88.7 91.4 88.1 89.8 81.7 78.2 83.8 91.4 96.6 90.5 88.0
CLASS-ZS 93.8 96.4 92.6 94.8 91.3 86.8 92.5 93.1 98.8 97.1 93.7
Table6: Zero-shotmonolingualretrievalwithresults(R@100)onthetestsetofMr. TyDidataset.
HighLevelAnswerCategory NamedEntityTypes Mostappropriatewh_word
PERSON/NORP/ORG PERSON,NORP,ORG Who
PLACE GPE,LOC,FAC Where
THING PRODUCT,EVENT,WORKOFART,LAW,LANGUAGE What
TEMPORAL TIME,DATE When
NUMERIC PERCENT,MONEY,QUANTITY,ORDINAL,CARDINAL Howmuch/Howmany
Table7: Theheuristicsrulesforchoosingthemostappropriatequestionwordbasedonnamedentitytypes(taken
fromLewisetal.(2019)).
16FinnishPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"StrappingYoungLad(lyh.SYL)oliDevinTownsendinvuonna1994perustamakanadalainenmetal-
liyhtye."intoanaturalquestionwhosequestionwordis"Milloin"andansweris"1994".Pleaserespondintheformat:"The
transformedquestionis: MilloinDevinTownsendperustikanadalaisenmetalliyhtyeenStrappingYoungLad(lyh.SYL)?"
RussianPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence" В215годуЦаоЦаоатаковалЧжанЛуиразгромилеговбитвевпроходеЯнпингуань.
"intoanaturalquestionwhosequestionwordis" Кто"andansweris" ЧжанЛу".Pleaserespondintheformat:"Thetrans-
formedquestionis: Кто был атакован Цао Цао и разгромлен в битве в проходе Янпингуань в 215 году? "
JapanesePrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"熊野那智神社（くまのなちじんじゃ）は、宮城県名取市にある神社である。"intoanatural
questionwhosequestionwordis"どこ"andansweris"宮城県".Pleaserespondintheformat:"Thetransformedquestionis:
熊野那智神社はどこにある神社ですか？"
KoreanPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"19세기후반에아일랜드에는독립과토지개혁을요구하는운동이크게확산되었다."intoa
naturalquestionwhosequestionwordis"어디"andansweris"아일랜드".Pleaserespondintheformat:"Thetransformed
questionis: 19세기후반에독립과토지개혁을요구하는운동이ᅳᄏ게확산된나라는어디입니까?"
ArabicPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence" ⁄(cid:152)k(cid:159) (cid:143)¤ (cid:155)(cid:20)A(cid:154) (cid:0)(cid:152)t‘ly(cid:156) (cid:0)(cid:152)‘A(cid:152)¤ (cid:11)ftqr (cid:0)(cid:152)mslmy(cid:159), ⁄(cid:158)\r(cid:0) –(cid:143)r(cid:0) (cid:1)Fr¡(cid:156) ⁄(cid:1)(cid:146)AC(cid:7)h(cid:156) (cid:1)(cid:27)@¡A (cid:136)(cid:159)
⁄ZA¶(cid:144)(cid:143)¤ ⁄(cid:154)(cid:0)(cid:152)(cid:28)ly(cid:21)⁄(cid:19)nw(cid:10)Jr(cid:148)(cid:5)FyA)(cid:1)FAFA⁄Fn(cid:140)A(cid:143)wC›,⁄(cid:1)(cid:152)mA(cid:158)yA(cid:155)A(cid:152)yz§A⁄(cid:7)r⁄(cid:158)A'(cid:143)¤(cid:19)nw(cid:10)(cid:5)FyA((cid:158)fshA(cid:143)¤
F(cid:159)(cid:155)bkr›."intoanaturalquestionwhosequestionwordis" (cid:1)§(cid:159)"andansweris" (cid:19)nw(cid:10)Jr(cid:148)(cid:5)FyA".Pleaserespondin
theformat:"Thetransformedquestionis:
(cid:1)§(cid:159)§(cid:2)(cid:27)@(cid:1)(cid:143)r(cid:0) (cid:1)Fr(cid:0)(cid:152)mslmy(cid:159)⁄(cid:1)(cid:146)AC(cid:7)h(cid:156)⁄ZA¶(cid:144)(cid:139)A(cid:152)bA(cid:190)A,(cid:155)mA§¥ '(cid:3)(cid:152)Y(cid:143)qd(cid:0)(cid:160)(cid:0)fl¡tmA(cid:157)(cid:7)A(cid:152)t‘ly(cid:156)(cid:0)(cid:152)‘A(cid:152)¤? "
BengaliPrompt
YouareanAImodelthatrewritessentencesintoquestions,usingagivenquestionwordandanswer.
Rewritethissentence"varte Hajar Hajar manuP AnaHaer mara JaJ, ik(cid:218)u zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n."intoanatural
questionwhosequestionwordis"ekaQaJ"andansweris"vart".Pleaserespondintheformat:"Thetransformedquestionis:
ekaQaJ Hajar Hajar manuP AnaHaer mara JaJ EbK zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n Qaek?"
TeluguPrompt
You are an AI model that rewrites sentences into questions, using a given question word and answer.
Rewrite this sentence "
!ట#ల%ప(’ ి*,+-ెం*+న123ాస6కన89ాపర;<శ>?@*ే6ఆలయంఆంధ’ప*’ ేE?ాషGంH ల%పIJమLM*Nవ?PQలSRల%
." into a natural question whose question word is " " and answer is " ". Please
TUనుLWండఅZ[పటGణంల%ఉం*+ ఎవర_ TUనుLWండ
respond in the format: "The transformed question is:
ఆంధ’ప*’ ేE?ాషGంH పIJమLM*Nవ?PQలSRల%‘ప(’ ి*,+-ెం*+న123ాస6కన89ా
? "
పర;<శ>?@*ే6ఆలయంఉనaపటGణంఎవర_
Figure9: Meta-examplesobtainedbypromptingChatGPTareshownforeachlanguagecoverdbyXOR-TYDIQA.
Lightbluetexts indicatethetransformedquestions.
17PromptD.1: FinnishExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: ToisaaltahänolitaiteidensuosijajahänenvaltakaudellaanPreussisaihaltuunsasuurenosanPuola-Liettuasta
Puolanjaoissavuosina1793ja1795.
Questionword:Missä
Answer:Preussi
TransformedQuestion: MissämaassataiteidensuosijahallitsijamissävaltakunnassasaatiinhaltuunsasuuriosaPuola-
LiettuastaPuolanjaoissavuosina1793ja1795?
Sentence:HänpelasiurallaanmyösRuotsissajaSlovakiassa.
Questionword:Missä
Answer:Slovakia
TransformedQuestion:MissämaassahänpelasiurallaanRuotsinlisäksi?
Sentence:BarokinjälkeenconcertogrossojaovatsäveltäneetmuunmuassaHeitorVilla-Lobos,BohuslavMartinu˚,Alfred
SchnittkejaPhilipGlass.
Questionword:Kuka
Answer:BohuslavMartinu˚
TransformedQuestion: KukasäveltäjistäHeitorVilla-Lobosin,AlfredSchnittkenjaPhilipGlassinohellaonsäveltänyt
concertogrossojabarokinjälkeen?
Sentence:Hänenajatteluunsavaikuttivatmuunmuassabuddhalaisetjataolaisetideat,joihinhäntutustuiAasianmatkoillaan,
MahatmaGandhinväkivallattomuusliike,sekähänenkatolinenuskontonsa.
Questionword:Kuka
Answer:MahatmaGandhi
TransformedQuestion: Kukavaikuttihänenajatteluunsa,mahtimaailmaanjakatoliseenuskontonsa?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: On the other hand, he/she was a fan of the arts and during his/her reign, Prussia took over a large part of
Poland-LithuaniainthepartitionsofPolandin1793and1795.
Questionword:Where
Answer:Prussia
TransformedQuestion: InwhichcountrydidtheloveroftheartsruleandinwhichkingdomwasalargepartofPoland-
LithuaniatakenoverduringthepartitionsofPolandin1793and1795?
Sentence:He/ShealsoplayedinSwedenandSlovakiaduringhercareer.
Questionword:Where
Answer:Slovakia
TransformedQuestion:Inwhichcountrydidhe/sheplayinhis/hercareerbesidesSweden?
Sentence:AftertheBaroque,concertogrossoshavebeencomposedby,amongothers,HeitorVilla-Lobos,BohuslavMartinu˚,
AlfredSchnittkeandPhilipGlass.
Questionword:Kuka
Answer:BohuslavMartinu˚
TransformedQuestion:BesidesHeitorVilla-Lobos,AlfredSchnittkeandPhilipGlass,whichofthecomposershascomposed
concertogrossosaftertheBaroque?
Sentence: His/Herthinkingwasinfluenced,amongotherthings,byBuddhistandTaoistideas,whichhe/shegottoknow
duringhis/hertravelsinAsia,MahatmaGandhi’snon-violencemovement,andhis/herCatholicreligion.
Questionword:Who
Answer:MahatmaGandhi
TransformedQuestion: Whoinfluencedhis/herthinking,theworldofpowerandhis/herCatholicreligion?
18PromptD.2: RussianExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: Корабли проекта выполняли контроль за учениями ВМС стран НАТО в Норвежском и Сре-
диземном морях, следили за корабельными и авианосными группами флотов США и Великобритании.
Questionword: Кто
Answer: НАТО
TransformedQuestion: Кто выполнял контроль за учениями ВМС в Норвежском и Средиземном морях и
следил за корабельными и авианосными группами флотов США и Великобритании?
Sentence: 1апреля1768годаДовернюназначаютпенсиюКоролевскойакадемиимузыкивразмере1000
ливров как автору музыки.
Questionword: Кто
Answer: Королевской академии музыки
TransformedQuestion: Кто1апреля1768годаназначилпенсиювразмере1000ливровДовернюкакавтору
музыки?
Sentence: Софи´я Шарло´тта Авгу´ста (22 февраля 1847, Мюнхен — 4 мая 1897, Париж) — принцесса
Баварская, герцогиня Баварская, позднее герцогиня Алансонская и Орлеанская.
Questionword: Где
Answer: Мюнхен
TransformedQuestion: Где родилась София Шарлотта Августа, принцесса Баварская?
Sentence: В первой половине XIX века паровозы в Россию, в основном, ввозились из-за рубежа.
Questionword: Когда
Answer: XIX век
TransformedQuestion: Когда паровозы в Россию, в основном, ввозились из-за рубежа?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Theproject’sshipsmonitoredNATOnavalexercisesintheNorwegianandMediterraneanSeasandmonitoredship
andaircraftcarriergroupsoftheUSandBritishnavies.
Questionword:Who
Answer:NATO
TransformedQuestion:WhomonitorednavalexercisesintheNorwegianandMediterraneanseasandmonitoredshipand
aircraftcarriergroupsoftheUSandBritishfleets?
Sentence:OnApril1,1768,DauvergnewasawardedapensionfromtheRoyalAcademyofMusicintheamountof1000
livresastheauthorofmusic.
Questionword:Who
Answer:RoyalAcademyofMusic
TransformedQuestion:Who,onApril1,1768,awardedapensionof1000livrestoDovergneastheauthorofmusic?
Sentence: SophiaCharlotteAuguste(22February1847,Munich-4May1897,Paris)-PrincessofBavaria,Duchessof
Bavaria,laterDuchessofAlençonandOrléans.
Questionword:Where
Answer:Munich
TransformedQuestion:WherewasSophiaCharlotteAugusta,PrincessofBavariaborn?
Sentence:Inthefirsthalfofthe19thcentury,steamlocomotivesweremainlyimportedtoRussiafromabroad.
Questionword:When
Answer:19thcentury
TransformedQuestion: WhenweresteamlocomotivesmainlyimportedintoRussiafromabroad?
19PromptD.3: JapaneseExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: 2月、竇憲は左校尉の耿夔を遣わし、金微山において北匈奴の単于を包囲しこれを大いに破り、単于
の母の閼氏を捕虜とした。
Questionword:誰
Answer:匈奴
TransformedQuestion:2月に金微山で竇憲の遣わした左校尉の耿夔が包囲し大いに破ったのは誰の単于ですか？
Sentence:この町を法人化する法はリチャード・キャズウェルが提出し、キャズウェルはここを本拠地とし、後
の1776年から1780年までノースカロライナ州の初代知事となった。
Questionword:どこ
Answer:ノースカロライナ州
TransformedQuestion:リチャード・キャズウェルが初代知事となったのはどこですか？
Sentence:これより以前、司空張華は司馬倫に疎まれて誅殺されていた。
Questionword:誰
Answer:張華
TransformedQuestion:誰がこれより以前に司馬倫に疎まれて誅殺されていたのですか？
Sentence:魯迅はこの無支祁が孫悟空の先祖・源流ではないかと推測した。
Questionword:誰
Answer:魯迅
TransformedQuestion: 誰はこの無支祁が孫悟空の先祖・源流ではないかと推測したのでしょうか？
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: InFebruary,DouXiansentZuo’slieutenant,GengKui,tobesiegeanddefeattheNorthernXiongnuDanyuat
Jinweishan,andtookDanyu’smother,theYanfamily,prisoner.
Questionword:Who
Answer:Xiongnu
TransformedQuestion:InFebruary,inJinweishan,whichwasthelandofDanyuthatwasbesiegedandseverelydefeatedby
GengKu,thecommanderoftheleftschoolsentbyDouXian?
Sentence:TheacttoincorporatethetownwasintroducedbyRichardCaswell,whomadeithishomeandlaterbecameNorth
Carolina’sfirstgovernorfrom1776to1780.
Questionword:Where
Answer:NorthCarolina
TransformedQuestion:WheredidRichardCaswellbecomethefirstgovernor?
Sentence:Beforethis,ZhangHuawasshunnedbySimaLunandkilled.
Questionword:Who
Answer:ZhangHua
TransformedQuestion:WhohadbeenshunnedandkilledbySimaLunbeforethis?
Sentence:LuXunsurmisedthatthisMujiqiwastheancestorandoriginofSunWukong.
Questionword:Who
Answer:LuXun
TransformedQuestion: WhocouldhaveguessedthatMujiqiwastheancestor/originofSonGoku?
20PromptD.4: KoreanExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:전투에서승리한뒤,오버워치는10년간계속해서평화를지켰으나내분으로인해해산되었다.
Questionword:누구
Answer:오버워치
TransformedQuestion:누구가전투에서승리한뒤10년동안평화를지키다가내분으로인해ᅢᄒ산되었나요?
Sentence:그가구단을떠난지10년이ᅬᄃ는2013년4월,스포르팅리스본은호날두를100,000번째회원으로등ᆨ로해
경의를표했다.
Questionword:누구
Answer:스포르팅리스본
TransformedQuestion:누가2013년4월그가구단을떠난지10년이되는해에호날두를100,000번째회원으로등ᆨ로
해경의를표했나요?
Sentence:19세기후반에아일랜드에는독립과토지개혁을요구하는운동이크게확산되었다.
Questionword:어디
Answer:아일랜드
TransformedQuestion:19세기후반에독립과토지개혁을요구하는ᅮᆫᄋ동이ᅳᄏ게확산된나라는어디입니까?
Sentence:산ᅡᆫᄐ젤로다리()또는하드리아누스의다리는로마에있는다리가운데ᅡᄒ나이다.
Questionword:어디
Answer:로마
TransformedQuestion: 산ᅡᆫᄐ젤로다리가있는곳은어디인가?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Afterwinningthebattle,Overwatchcontinuedtomaintainpeacefor10years,butwasdisbandedduetointernal
strife.
Questionword:Who
Answer:Overwatch
TransformedQuestion:Whowonthebattle,keptthepeacefortenyears,andthendisbandedduetoinfighting?
Sentence:InApril2013,10yearsafterhelefttheclub,SportingLisbonpaidtributetoRonaldobyregisteringhimastheir
100,000thmember.
Questionword:Who
Answer:SportingLisbon
TransformedQuestion:WhopaidtributetoRonaldobyregisteringhimastheir100,000thmemberinApril2013,marking10
yearssincehelefttheclub?
Sentence:Inthelate19thcentury,movementscallingforindependenceandlandreformspreadwidelyinIreland.
Questionword:Where
Answer:Ireland
TransformedQuestion:Inwhichcountrydidthemovementcallingforindependenceandlandreformspreadsignificantlyin
thelate19thcentury?
Sentence:PonteSant’Angelo()orHadrian’sBridgeisoneofthebridgesinRome.
Questionword:Where
Answer:Rome
TransformedQuestion: WhereisthePonteSant’Angelo?
21PromptD.5: ArabicExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence: ⁄(cid:152)d(cid:149)fi'(cid:143)¤(cid:155)qAV‘T¡A(cid:158)w(cid:143)r(cid:7)wfl§T(cid:143)r(cid:19)ynyA(cid:143)¤(cid:136)A(cid:157)1777,⁄(cid:152)kn¢(cid:0)(cid:158)tq(cid:153)(cid:3)(cid:152)Y(cid:152)yksyn(cid:140)tw(cid:160),(cid:149)ntA(cid:149)¤(cid:143)¤
(cid:136)A(cid:157)1797.
Questionword: (cid:1)§(cid:159)
Answer: (cid:149)ntA(cid:149)¤
TransformedQuestion: (cid:1)§(cid:159)(cid:0)(cid:158)tq(cid:153)⁄(cid:152)d(cid:149)fi'(cid:7)‘d(cid:155)yfi £(cid:143)¤(cid:155)qAV‘T¡A(cid:158)w(cid:143)r,⁄fl§T(cid:143)r(cid:19)ynyA(cid:143)¤(cid:136)A(cid:157)1797?
Sentence: ⁄(cid:149)A(cid:160)(cid:158)\A(cid:157)Jr(cid:149)TF¤(cid:7)¤(cid:3)x¡w(cid:0)–(cid:149)(cid:16)r(cid:11)qd(cid:155)A⁄(cid:143)AE(cid:7)A(cid:152)mnA(cid:143)sT(cid:143)¤(cid:149)(cid:153)(cid:155)r›.
Questionword: (cid:155)(cid:159)
Answer: Jr(cid:149)TF¤(cid:7)¤(cid:3)x
TransformedQuestion: (cid:155)(cid:159)(cid:149)A(cid:160)(cid:152)d§¢(cid:0)(cid:152)n\A(cid:157)(cid:0)–(cid:149)(cid:16)r(cid:11)qd(cid:155)A⁄(cid:143)AE(cid:7)A(cid:152)mnA(cid:143)sT(cid:143)¤(cid:149)(cid:153)(cid:155)r›?
Sentence: (cid:149)mA(cid:0)(cid:152)(cid:28)Ww“(cid:0)(cid:152)(cid:20)w§T(cid:0)(cid:152)br§WA(cid:158)yT(cid:11)K(cid:140)(cid:153)(cid:1)§SA}A(cid:152)T(cid:158)A '(cid:0)(cid:152)tnfy@'(cid:7)y(cid:159)(cid:0)(cid:152)bw(cid:0)(cid:7)A(cid:14)21⁄23.
Questionword: (cid:155)(cid:159)
Answer: (cid:0)(cid:152)(cid:28)Ww“(cid:0)(cid:152)(cid:20)w§T(cid:0)(cid:152)br§WA(cid:158)yT
TransformedQuestion: (cid:155)(cid:159)§K(cid:140)(cid:153)}A(cid:152)T(cid:158)A '(cid:0)(cid:152)tnfy@'(cid:7)y(cid:159)(cid:0)(cid:152)bw(cid:0)(cid:7)A(cid:14)21⁄23?
Sentence: ⁄(cid:146)d (cid:0)(cid:143)tt(cid:25) (cid:23)d§(cid:16)A(cid:190) (cid:143)¤ (cid:146)Or (cid:0)(cid:152)‘\(cid:156) (cid:146)A(cid:136)ty(cid:159) (cid:11)SmA(cid:160) (cid:7)A(cid:158)wC(cid:0)(cid:155)A (cid:152)(cid:24)r(cid:10) (cid:11)Kr§(cid:159) (cid:152)t(cid:24)r§r§T (cid:136)A(cid:157) 1973, ⁄(cid:7)A(cid:158)wC(cid:0)(cid:155)A
(cid:152)(cid:24)r(cid:10)(cid:11)mwE2006.
Questionword: (cid:1)§(cid:159)
Answer: (cid:146)Or(cid:0)(cid:152)‘\(cid:156)
TransformedQuestion: (cid:1)§(cid:159)(cid:7)A(cid:158)wC(cid:0)(cid:155)A(cid:152)(cid:24)r(cid:10)(cid:11)Kr§(cid:159)(cid:152)t(cid:24)r§r§T(cid:136)A(cid:157)1973?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:ClaywasborninHanoverCounty,Virginiain1777,butmovedtoLexington,Kentuckyin1797.
Questionword:Where
Answer:Kentucky
TransformedQuestion:WheredidClaymoveafterhisbirthinHanoverCounty,Virginiain1797?
Sentence:TheCPSsystemwasthemostadvancedandwonthecompetition.
Questionword:Who
Answer:CPSsystem
TransformedQuestion:Whohadthemostadvancedsystemandwonthecompetition?
Sentence:BritishAirwaysalsooperatestheTeenClubloungebetweengatesB21andB23.
Questionword:Who
Answer:BritishAirways
TransformedQuestion:WhooperatestheExecutiveClubloungebetweengatesB21andB23?
Sentence:TwohallswererecentlyopenedinAl-AzmPalacecontainingapanoramaoftheOctoberLiberationWarof1973,
andapanoramaoftheJulyWarof2006.
Questionword:Where
Answer:Al-AzmPalace
TransformedQuestion: WhereisthepanoramaoftheOctoberLiberationWarof1973?
22PromptD.6: BengaliExample&Translation
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Ja(cid:213)apeQ sbar Aaeg e(cid:22)(cid:150)pd(cid:140) (cid:23)aN Haran.
Questionword:ek
Answer:e(cid:22)(cid:150)pd(cid:140)
TransformedQuestion:Ja(cid:213)apeQ sbar Aaeg ek (cid:23)aN Haran?
Sentence:Apridek katarer rajzan(cid:140) edaHaet raiSJar EkiT ‡QaJ(cid:140) d(cid:142)tabas rJeeq.
Questionword:ekaQaJ
Answer:katar
TransformedQuestion:raiSJar ‡QaJ(cid:140) d(cid:142)tabasiT ekaQaJ Abi‡Qt?
Sentence:varte Hajar Hajar manuP AnaHaer mara JaJ, ik(cid:218)u zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n.
Questionword:ekaQaJ
Answer:vart
TransformedQuestion:ekaQaJ Hajar Hajar manuP AnaHaer mara JaJ EbK zflm(cid:23)carkra taedr (cid:23)it Udas(cid:140)n Qaek?
Sentence:EiT OJaiSKTn -Er isJaTl-E Abi‡Qt exala jaJgaJ EkiT maeqr bajar.
Questionword:ekaQaJ
Answer:isJaTl
TransformedQuestion: EiT OJaiSKTn ekaQaJ exala jaJgaJ EkiT maeqr bajar?
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Draupadiwasthefirsttodieonthejourney.
Questionword:Who
Answer:Draupadi
TransformedQuestion:Whodiedfirstonthejourney?
Sentence:Inaddition,RussiahasapermanentembassyinDoha,thecapitalofQatar.
Questionword:Where
Answer:Qatar
TransformedQuestion:WhereisthepermanentembassyofRussialocated?
Sentence:ThousandsofpeopledieofstarvationinIndia,butmissionariesareindifferenttothem.
Questionword:Where
Answer:India
TransformedQuestion:Wherearethousandsofpeopledyingofstarvationandthemissionariesareindifferenttothem?
Sentence:Itisanopen-airfishmarketlocatedinSeattle,Washington.
Questionword:Where
Answer:Seattle
TransformedQuestion: WhereisanopenairfishmarketinWashington?
23PromptD.7: TeluguExample&Translation
Rewrite sentences into short and precise questions, using given question words and answers:
Sentence: , , , , .
ఈ"$ామమ&ల(వ*+ ,ెరక0 మ1234 56ర7శనగ క;ర"ాయల0=దలగ&న?పBA Cనపంటల0
Question word:
ఎవర7
Answer:
మ1234
Transformed Question: ?
ఈ"$ామమ&ల(పBA Cనపంటలల(ఎవర7ఒకటI
Sentence: .
ఈసమయంల(పపA ంచంల(LఉNOC*ాలగణQయRSTనUVర7గ&దలక0,ైXCYారణRSTంNZ
Question word:
ఎక[డ
Answer:
,ైXC
Transformed Question: ?
ఈసమయంల(పపA ంచంల(ఉNOC*ాలగణQయRSTనUVర7గ&దలక0ఎక[డYారణRSTంNZ
Sentence:
]టIల(ప^A ిN‘Z,ెంNZనa$5ాస?కనbYాపరRcశd*eNే?ఆలయంఆంధAపNA ేi*ాషkంl ల(పmnమ"oNCవ*+pలq1ల(UVను"sండఅX6
.
పటkణంల(ఉంNZ
Question word:
ఎవర7
Answer:
UVను"sండ
Transformed Question:
ఆంధAపNA ేi*ాషkంl పmnమ"oNCవ*+pలq1ల(Lప^A ిN‘Z,ెంNZనa$5ాస?కనbYాపరRcశd*eNే?ఆలయంఉనu
?
పటkణంఎవర7
Sentence: .
vాతbYxLకృతవరzఅడ|{Y}నడంచూ^ినNోAణ&డ{ధరz*ా(cid:128)5(cid:129)ౖప(cid:130)5(cid:129)(cid:131)(cid:132)(cid:133)డ{
Question word:
ఎవర7
Answer:
ధరz*ా(cid:128)
Transformed Question: ?
vాతbYxLకృతవరzఅడ|{Y}నడంచూ^ినNోAణ&డ{ఎవర75(cid:129)ౖప(cid:130)5(cid:129)(cid:131)(cid:132)(cid:133)డ{
Rewritesentencesintoshortandprecisequestions,usinggivenquestionwordsandanswers:
Sentence:Themaincropsinthisvillagearerice,sugarcane,mango,groundnut,vegetablesetc.
Questionword:Who
Answer:mango
TransformedQuestion:Whichisoneofthemaincropsinthisvillage?
Sentence:Chinaaccountedforasignificantincreaseinworldemissionsduringthisperiod.
Questionword:Where
Answer:China
TransformedQuestion:Whereintheworldhascausedthesignificantincreaseinemissionsduringthistime?
Sentence:Amongthese,thefamousSriVasaviKanyakaParameshwariDeviTempleislocatedinthetownofPenugondain
theWestGodavaridistrictofthestateofAndhraPradesh.
Questionword:Who
Answer:Penugonda
TransformedQuestion:WhichtowninWestGodavaridistrictofAndhraPradeshstatehasthefamousSriVasaviKanyaka
ParameshwariDevitemple?
Sentence:SeeingSatyakibeingstoppedbyKritavarma,DronawenttowardsDharmaraja.
Questionword:Who
Answer:Dharmaraja
TransformedQuestion: TowhomdidDronagowhenhesawKritavarmastoppingSatyaki?
24