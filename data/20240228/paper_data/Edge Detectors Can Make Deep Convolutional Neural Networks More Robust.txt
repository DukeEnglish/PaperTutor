Edge Detectors Can Make Deep Convolutional Neural
Networks More Robust
Jin Dinga,b,∗, Jie-Chao Zhaoa, Yong-Zhi Suna, Ping Tana,∗, Jia-Wei Wanga,
Ji-En Mab,c, You-Tong Fangb,c
aSchool of Automation and Electrical Engineering & Key Institute of Robotics of Zhejiang
Province, Zhejiang University of Science and Technology, Hangzhou, 310023, China
bState Key Laboratory of Fluid Power and Mechatronic Systems, Zhejiang University,
Hangzhou 310027, China
cSchool of Electrical Engineering, Zhejiang University, Hangzhou, 310027, China
Abstract
Deep convolutional neural networks (DCNN for short) are vulnerable to ex-
amples with small perturbations. Improving DCNN’s robustness is of great
significance to the safety-critical applications, such as autonomous driving
and industry automation. Inspired by the principal way that human eyes
recognize objects, i.e., largely relying on the shape features, this paper first
employs the edge detectors as layer kernels and designs a binary edge feature
branch (BEFB for short) to learn the binary edge features, which can be eas-
ily integrated into any popular backbone. The four edge detectors can learn
the horizontal, vertical, positive diagonal, and negative diagonal edge fea-
tures, respectively, and the branch is stacked by multiple Sobel layers (using
edge detectors as kernels) and one threshold layer. The binary edge fea-
tures learned by the branch, concatenated with the texture features learned
by the backbone, are fed into the fully connected layers for classification.
We integrate the proposed branch into VGG16 and ResNet34, respectively,
and conduct experiments on multiple datasets. Experimental results demon-
strate the BEFB is lightweight and has no side effects on training. And the
accuracy of the BEFB integrated models is better than the original ones on
∗Corresponding author
Email addresses: jding@zust.edu.cn (Jin Ding), zjiechao@126.com (Jie-Chao
Zhao), sunyongzhi@hotmail.com (Yong-Zhi Sun), 115011@zust.edu.cn (Ping Tan),
13175040964@163.com (Jia-Wei Wang), majien@zju.edu.cn (Ji-En Ma),
youtong@zju.edu.cn (You-Tong Fang)
Preprint submitted to Neural Networks February 27, 2024
4202
beF
62
]VC.sc[
1v97461.2042:viXraall datasets when facing FGSM, PGD, and C&W attacks. Besides, BEFB
integrated models equipped with the robustness enhancing techniques can
achieve better classification accuracy compared to the original models. The
work in this paper for the first time shows it is feasible to enhance the ro-
bustness of DCNNs through combining both shape-like features and texture
features.
Keywords: learnable edge detectors, binary edge feature branch, Sobel
layer, threshold layer, adversarial robustness, deep convolutional neural
networks
1. Introduction
It is well known that deep convolutional neural networks (DCNN for
short)canbefooledbyexampleswithsmallperturbations[1–5], whichbrings
the potential hazards when applying DCNNs to the safety-critical applica-
tions, e.g., autonomous driving, airport security, and industry automation.
Therefore, it is of great significance to improve the robustness of DCNNs.
Fig. 1 shows several clean examples and their adversarial counterparts. Ad-
versarial examples (AE for short) in Fig. 1(b) are with small noises which
can induce DCNNs to make wrong decisions. However, these noises can be
filtered by human eyes easily. Researches show that the principal way human
beings recognize the objects is largely relying on the shape features [6, 7],
and that’s why human beings are not susceptible to the noise imposed in
Fig. 1(b). Inspired by this, it is natural to ask, is it possible to make the
DCNNs more robust by learning the shape-like features?
(a) Clean examples (b) Adversarial examples
Figure 1: Clean examples and adversarial examples.
2Fig.2showsthethresholdededgeimagesofFig.1. Fromthefigure, itcan
be observed that the thresholded edge images for Fig. 1(a) and Fig. 1(b) are
almost the same. It prompts us that, enhancing the robustness of DCNNs
can be achieved by using the binary edge features which can be seen as a
kind of shape features. To this end, in this paper, four learnable edge detec-
tors are designed and taken as layer kernels, which can be used to extract
horizontal, vertical, positive diagonal, and negative diagonal edge features,
respectively [8–10]. And based on the edge detectors, a binary edge feature
branch (BEFB for short) is proposed, which is staked by multiple Sobel lay-
ers and one threshold layer. The Sobel layers employ the edge detectors as
kernels, and the threshold layer turns the output of the last Sobel layer to the
binary features. The binary features concatenated with the texture features
learnt by any popular backbone are then fed into fully connected layers for
classification. To deal with the zero gradient of threshold layer, which makes
the weights in BEFB unable to update using the chain rule, STE technique
[11–13] is employed. In addition, to take obfuscated gradient effect raised by
[14–16] into consideration, zero gradient or one center-translated sigmoid ac-
tivation function are also used for generating AEs. In the experiments, we in-
tegrate BEFB into VGG16 [17] and ResNet34 [18, 19], respectively, and con-
duct experiments on multiple datasets. The results demonstrate BEFB has
no side effects on model training, and BEFB integrated models can achieve
better accuracy under FGSM [1], PGD [20], and C&W [21] attacks com-
pared to the original ones. Furthermore, we combine the BEFB integrated
models with two popular robustness enhancing techniques--AT(abbreviation
for adversarial training) [22] and PCL(abbreviation for prototype conformity
loss) [23], respectively, and find BEFB integrated models can achieve better
accuracy than the original models as well.
The contributions of this paper can be summarized as follows:
1. Inspired by the principal way that the human beings recognize objects,
we design four learnable edge detectors and propose BEFB to make
DCNNs more robust.
2. BEFB can be easily integrated into any popular backbone, and has
no side effects on model training. Extensive experiments on multiple
datasets show BEFB integrated models can achieve better accuracy
under FGSM, PGD, and C&W attacks when compared to the original
models.
3. For the first time, we show it is feasible to make DCNNs more robust
3(a) Thresholded edge im- (b) Thresholded edge im-
ages for clean examples ages for adversarial exam-
ples
Figure 2: Thresholded edge images of Fig. 1.
by combining the shape-like features and texture features.
The organization of the paper is as follows. Section 2 briefly reviews the
related works, and Section 3 describes the details of BEFB. In Section 4 and
5, the experiments on multiple datasets are conducted, and the discussions
are made. Finally, in Section 6, the concluding remarks are given.
2. Related Work
Robustness Enhancing with AT. AT improves the robustness of the
DCNNs by generating AEs as training samples during optimization. Tsipras
et al. [24] found there exists a tradeoff between robustness and standard ac-
curacy of the models generated by AT, due to the robust classifiers learning
a different feature representation compared to the clean classifiers. Madry et
al. [22] proposed an approximated solution framework to the optimization
problems of AT, and found PGD-based AT can produce models defending
themselves against the first-order adversaries. Kannan et al. [25] investi-
gated the effectiveness of AT at the scale of ImageNet [26], and proposed a
logit pairing AT training method to tackle the tradeoff between robust ac-
curacy and clean accuracy. Wong et al. [27] accelerated the training process
using FGSM attack with random initialization instead of PGD attack [20],
and reached significantly lower cost. Xu et al. [28] proposed a novel attack
method which can make a stronger perturbation to the input images, result-
ing in the robustness of models by AT using this attack method is improved.
4Li et al. [29] revealed a link between fast growing gradient of examples and
catastrophic overfitting during robust training, and proposed a subspace AT
method to mitigate the overfitting and increase the robustness. Dabouei
et al. [30] found the gradient norm in AT is higher than natural training,
which hinders the training convergence of outer optimization of AT. And
they proposed a gradient regularization method to improve the performance
of AT.
Robustness Enhancing without AT. Non-AT robustness enhancing
techniques can be categorized into part-based models [31, 32], feature vector
clustering[23,33],adversarialmarginmaximization[34,35],etc. Liet al. [31]
argued one reason that DCNNs are prone to be attacked is they are trained
only on category labels, not on the part-based knowledge as humans do.
They proposed an object recognition model, which first segments the parts
of objects, scores the segmentations based on human knowledge, and final
outputs the classification results based on the scores. This part-based model
shows better robustness than classic recognition models across various attack
settings. Sitawarin et al. [32] also thought richer annotation information can
help learn more robust features. They proposed a part segmentation model
with a head classifier trained end-to-end. The model first segments objects
into parts, and then makes predictions based on the parts. Mustafa et al.
[23] stated that making feature vectors in the same class closer and centroids
of different classes more separable can enhance the robustness of DCNNs.
They added PCL to the conventional loss function, and designed an auxiliary
function to reduce the dimensions of convolutional feature maps. Seo et
al. [33] proposed a training methodology that enhance the robustness of
DCNNsthroughaconstraintthatappliesaclass-specificdifferentiationtothe
feature space. The training methodology results in feature representations
with a small intra-class variance and large inter-class variances, and can
improve the adversarial robustness notably. Yan et al. [34] proposed an
adversarial margin maximization method to improve DCNNs’ generalization
ability. They employed the deepfool attack method [36] to compute the
distance between an image sample and its decision boundary. This learning-
based regularization can enhance the robustness of DCNNs as well.
Note that, BEFB integrated models proposed in this paper can be easily
combined with above-mentioned robustness enhancing techniques, such as
AT [22] and PCL [23], and can achieve better classification accuracy than
the original models.
53. Proposed Approach
In this section, we first introduce four learnable edge detectors, and then
illustrate a binary edge feature branch (BEFB for short).
3.1. Edge Detectors
Inspired by the fact that shape features is the main factor relied on by
human beings to recognize objects, here, we design four learnable edge de-
tectors which can extract horizontal edge features, vertical edge features,
positive diagonal edge features, and negative diagonal edge features, respec-
tively. These four learnable edge detectors can be taken as layer kernels and
are shown in Fig. 3.
(a) Horizontal edge detec- (b) Vertical edge detector
tor
(c) Positive diagonal edge (d) Negativediagonaledge
detector detector
Figure 3: Four types of edge detectors.
For horizontal edge detector in Fig. 3(a), we have

∈ [0, 1] if i = 1, j = 1, 2, 3,


w = 0 if i = 2, j = 1, 2, 3, (1)
ij

 ∈ [-1, 0] if i = 3, j = 1, 2, 3,
6For vertical edge detector in Fig. 3(b), we have

∈ [0, 1] if j = 1, i = 1, 2, 3,


w = 0 if j = 2, i = 1, 2, 3, (2)
ij

 ∈ [-1, 0] if j = 3, i = 1, 2, 3,
For positive diagonal edge detector in Fig. 3(c), we have

∈ [0, 1] if (i, j) ∈ {(1, 1), (1, 2), (2, 1) },


w = 0 if (i, j) ∈ {(1, 3), (2, 2), (3, 1) }, (3)
ij

 ∈ [-1, 0] if (i, j) ∈ {(2, 3), (3, 2), (3, 3) },
For negative diagonal edge detector in Fig. 3(d), we have

∈ [0, 1] if (i, j) ∈ {(1, 2), (1, 3), (2, 3) },


w = 0 if (i, j) ∈ {(1, 1), (2, 2), (3, 3) }, (4)
ij

 ∈ [-1, 0] if (i, j) ∈ {(2, 1), (3, 1), (3, 2) },
3.2. Binary Edge Feature Branch
Based on the four learnable edge detectors, BEFB is proposed to extract
the binary edge features of the images. BEFB is stacked by multiple So-
bel layers and one threshold layer, and can be integrated into any popular
backbone. The architecture of a BEFB integrated DCNN model is shown in
Fig. 4.
Sobel Layer. A Sobel layer is one single convolutional layer or multiple
parallel convolutional layers using addition for fusion. In our experiments,
for Sobel layer with one single convolutional layer, horizontal edge detector is
used as its kernel. For Sobel layer with multiple parallel convolutional layers,
we set the number of convolutional layers to four, and take horizontal, verti-
cal, positive diagonal, and negative diagonal edge detectors as their kernels,
respectively. Fig. 4 shows a BEFB integrated model in which Sobel layer is
with four parallel convolutional layers.
Threshold Layer. The threshold layer in its nature is an activation
layer. The activation function can be written as follows.
(cid:40)
1 if xin ≥ t * max(xin),
xout = ikj i (5)
ikj 0 if xin < t * max(xin),
ikj i
7Figure 4: The architecture of a BEFB integrated DCNN model.
InEq.(5),xin isanelementofthetensorxin ∈RN×P×Q,whichrepresents
ikj
the feature map obtained by the last Sobel layer. xout is an element of the
ikj
tensor xout ∈ RN×P×Q, which represents the binary feature map output by
the threshold layer. N is the number of channels of the feature map, and
P and Q are the width and height of a channel. i = 1, 2, ..., N, k = 1, 2,
..., P, and j = 1, 2, ..., Q. t is a proportional coefficient and belongs to [0,
1]. max(xin) represents the maximum value of channel i. It is obvious to see
i
that, the higher t, the less binary features obtained; the smaller t, the more
binary features obtained.
The threshold layer turns the output of the last Sobel layer to the binary
edge features, which concatenated with the texture features learnt by the
backbone are fed into fully connected layers for classification. Note that, the
gradient of activation function of Eq. (5) is zero. To update the weights in
8BEFB, STE technique [11–13] is employed.
4. Experiments
Inthissection,weintegrateBEFBintoVGG16[17]andResNet34[18,19],
respectively, and conduct the experiments on CIFAR-10 [37], MNIST [38],
SVHN [39], and TinyImageNet (TinyIN for short) [40] datasets. We examine
theeffectsofBEFBonmodeltraining,analyseobfuscatedgradienteffect[14–
16] by using different activation functions of the threshold layer to generate
AEs, and compare the accuracy of BEFB integrated models when facing
FGSM[1], PGD[20], andC&W[21]attackswithoriginalones. Furthermore,
we combine the BEFB integrated models with two robustness enhancing
techniques--AT [22] and PCL [23] to evaluate the classification accuracy. All
experiments are coded in Tensorflow with one TITAN XP GPU.
4.1. Experimental Settings
In the experiments, we adopt two types of BEFB integrated models. One
is Sobel layer with a single convolutional layer, denoted as BEFB-single.
The other is Sobel layer with four parallel convolutional layers, denoted as
BEFB-multiple. ThesettingsofthenumberofSobellayerslandproportional
coefficient t of threshold layer are shown in table 1. The settings of the ϵ,
steps, and stepsize of FGSM and PGD are shown in table 2. Each model is
run for five times, and the best value is recorded.
CIFAR-10 MNIST SVHN TinyIN
l t l t l t l t
VGG16-BEFB 2 0.8 2 0.8 2 0.8 3 0.6
ResNet34-BEFB 2 0.6 2 0.6 2 0.6 3 0.6
Table1: ThesettingsofthenumberofSobellayersandproportionalcoefficientofThresh-
old layer.
4.2. Effects of BEFB on model training
We examine the effects of BEFB on model training by comparing three
metrics between the BEFB-multiple models and the original ones, i.e., train-
ing accuracy, test accuracy, and training time per epoch. The loss function,
optimizer, batch size, and number of epochs are set to be the same. Table 3
9CIFAR-10 MNIST SVHN TinyIN
ϵ 8 80 8 8
steps 8 8 8 8
stepsize 2 20 2 2
Table 2: Parameters of FGSM and PGD.
shows the comparison of training performance between BEFB-multiple mod-
els and the original ones. From the table, it is clear to see the BEFB-multiple
modelsareonaparwiththeoriginalmodelsonthreemetrics,whichindicates
BEFB is lightweight and has no side effects on model training. Fig. 5 and
Fig. 6 depict the training profiles of VGG16-BEFB-multiple and ResNet34-
BEFB-multiple on CIFAR-10 dataset, respectively. From the figures, we can
see BEFB-multiple models demonstrate the similar training dynamics with
the original ones.
CIFAR-10 MNIST SVHN TinyIN
Tr.Acc. Te.Acc. Ti.PE Tr.Acc. Te.Acc. Ti.PE Tr.Acc. Te.Acc. Ti.PE Tr.Acc. Te.Acc. Ti.PE
VGG16 99.17% 83.70% 18s 99.72% 99.40% 16s 99.68% 94.36% 18s 94.32% 33.84% 80s
VGG16-BEFB-multiple 99.53% 82.95% 18s 99.56% 99.46% 17s 99.35% 94.64% 18s 92.03% 30.01% 95s
ResNet34 99.32% 79.19% 48s 99.63% 99.40% 40s 99.76% 93.22% 50s 97.53% 30.80% 238s
ResNet34-BEFB-multiple 99.48% 74.58% 48s 99.38% 99.28% 42s 99.78% 93.41% 52s 97.98% 26.31% 250s
Tr.Acc. standsfortrainingaccuracy. Te.Acc. standsfortestaccuracy. Ti.PEstandsfortrainingtimeperepoch.
Table 3: Comparison of training performance between BEFB-multiple models and the
original ones.
4.3. Analysis of obfuscated gradient effect
The activation function of the threshold layer is expressed by Eq. (5),
whose gradient is zero. In order to update the weights in BEFB, STE tech-
nique [11–13] is adopted. But with respect to generating AEs, STE may
bring obfuscated gradient effect [14–16], which means the yielded AEs are
not powerful enough to deceive the models. Here, in addition to STE, zero
gradient and gradient of a center-translated sigmoid activation function for
threshold layer are also tested. Table 4 compares the classification accuracy
of AEs generated by these three gradient computing strategies under FGSM
attacks. Eq. (6) defines the center-translated sigmoid function. x in general,
0
is the threshold value for channels, illustrated in Eq. (5).
10(a) VGG16 (b) VGG16-BEFB-multiple
Figure5: ComparisonoftrainingprofilesbetweenVGG16-BEFB-mutiplemodel
and the original one on CIFAR-10 dataset.
(a) ResNet34 (b) ResNet34-BEFB-multiple
Figure 6: Comparison of training profiles between ResNet34-BEFB-mutiple
model and the original one on CIFAR-10 dataset.
1
f(x) = (6)
1+ex−x0
From the table 4, it is clear to see the classification accuracy under STE
is much higher than zero gradient and gradient of center-translated sigmoid
function. It indeed brings the obfuscated gradient effect using STE. In our
experiments, we employ zero gradient of threshold layer to generate AEs.
4.4. Performance comparison between BEFB integrated models and original
models under attacks
Table 5 compares the classification accuracy of BEFB integrated models
and the original models under FGSM, PGD, and C&W attacks.
11CIFAR-10 MNIST SVHN TinyIN
STE 64.24% 81.65% 71.02% 43.21%
VGG16-BEFB-multiple Sigmoid 44.93% 68.25% 59.75% 33.06%
Zero Gradient 44.40% 67.42% 59.28% 31.97%
STE 23.35% 17.55% 14.36% 35.87%
ResNet34-BEFB-multiple Sigmoid 14.87% 13.84% 12.71% 5.82%
Zero Gradient 14.88% 14.53% 12.17% 5.39%
Table 4: Comparison of classification accuracy of AEs generated by three gradient com-
puting strategies under FGSM attacks.
CIFAR-10 MNIST SVHN TinyIN
FGSM PGD C&W FGSM PGD C&W FGSM PGD C&W FGSM PGD C&W
VGG16 28.59% 1.93% 0.06 56.54% 3.63% 6.78 57.77% 16.84% 0.08 27.39% 4.03% 0.05
VGG16-BEFB-single 42.77% 8.01% 0.05 59.05% 5.83% 6.53 58.15% 17.98% 0.08 31.15% 8.74% 0.07
VGG16-BEFB-multiple 45.60% 8.05% 0.07 67.42% 15.53% 7.03 59.28% 19.48% 0.10 31.93% 9.18% 0.07
ResNet34 7.82% 0.47% 0.05 12.66% 0.76% 1.22 24.14% 2.49% 0.02 5.80% 0.00% 0.10
ResNet34-BEFB-single 10.31% 0.78% 0.06 13.33% 2.33% 1.50 23.95% 2.41% 0.02 5.99% 0.36% 0.11
ResNet34-BEFB-multiple 14.88% 1.01% 0.10 14.53% 2.95% 1.39 25.17% 2.98% 0.03 5.95% 0.95% 0.14
Table 5: Comparison of classification accuracy between BEFB integrated models and
original ones under attacks.
From the table, it is clear to see that BEFB-single and BEFB-multiple
models are more robust than the original models under FGSM, PGD and
C&Wattacks,andclassificationaccuracyofBEFB-multiplemodelsareslightly
better than BEFB-single models. On CIFAR-10 dataset, VGG16-BEFB-
multiple model can achieve 17% and 6% higher accuracy than the original
model under FGSM and PGD attacks, respectively. On MNIST dataset,
VGG16-BEFB-multiple model can achieve 11% and 12% higher accuracy
than the original model under FGSM and PGD attacks, respectively.
Fig7andFig8examinetheextractedfeaturesofbothcleanexamplesand
the AEs by the original VGG16 model and VGG16-BEFB-multiple model
on TinyIN dataset, respectively. On Fig. 7, the certain images from TinyIN
dataset under FGSM of ϵ=16 attack are predicted wrong by the original
VGG16 model, and it is clear to see there is significant difference between
the extracted texture features of the clean examples and the AEs. On Fig. 8,
the same images from TinyIN dataset under FGSM of ϵ=16 attack are clas-
sified correctly by the VGG16-BEFF-multiple model, and the difference of
the extracted texture features between the clean examples and the AEs is
12lower than that in the original model. More notably, the extracted binary
edge features of clean examples and AEs are almost the same, e.g., in ”la-
dybug” image and ”sock” image, the number of different pixels are both
zero. It indicates these extracted binary edge features play an important
role in improving the classification accuracy on AEs. Furthermore, we add
more perturbations to the images and observe the extracted features and
prediction results of the VGG16-BEFB-multiple models. On Fig. 9, four
more perturbations are added on the images under FGSM attack. The dif-
ference of texture features between the clean examples and AEs is slightly
higher than that under ϵ=16 attack, e.g., RMSE (root mean square error)
of ”jellyfish” image is 0.15 under ϵ=16 and 0.18 under ϵ=20, and RMSE of
”mushroom” image is 0.48 under ϵ=16 and 0.52 under ϵ=20. The difference
of binary edge features between the clean examples and AEs is nearly un-
changed under ϵ=16 attack and ϵ=20 attack, e.g., the number of different
pixels for ”jellyfish” image is 1 under both ϵ=16 attack and ϵ=20 attack, and
the number of different pixels for ”mushroom” image is also 1 under both
ϵ=16 attack and ϵ=20 attack. And the prediction results under FGSM of
ϵ=20 attack are correct. On Fig. 10, another four perturbations are added.
Anditcanbeseenthatthedifferenceoftexturefeaturesunderϵ=24attackis
slightly higher than that under ϵ=20 attack, e.g., RMSE of ”jellyfish” image
is 0.18 under ϵ=20 and 0.19 under ϵ=24, and RMSE of ”mushroom” image is
0.52 under ϵ=20 attack and 0.57 under ϵ=24 attack. The number of different
pixels in binary edge features of clean examples and AEs keeps very close
under ϵ=20 attack and ϵ=24 attack, e.g. the number for ”mushroom” image
keeps unchanged and the number for ”jellyfish” image increases one. Both
Fig. 9 and Fig. 10 demonstrate the binary edge features are not susceptible
to small perturbations, and to further improve the classification accuracy on
AEs, exploring the novel combination forms for both texture features and
binary edge features may be a key issue.
Similarly, from Fig. 11 to Fig. 14, we examine the extracted features
and prediction results for both clean examples and AEs by the original
ResNet34 model and ResNet34-BEFB-multiple model on CIFAR-10 dataset.
On Fig. 11 and Fig. 12, it can be seen that, the original ResNet34 model
makes the wrong predictions for the certain images from CIFAR-10 dataset
underFGSMofϵ=8attack, whileResNet34-BEFB-multiplemodelgetsthem
correct because of the extracted binary edge features almost the same be-
tween the clean examples and the AEs. For example, on ”dog”, ”airplane”,
”automobile”, ”ship” and ”frog” images, the number of different pixels is
13Figure 7: Texture features extracted by the original VGG16 model and its
predictions under FGSM of ϵ=16 attack.
Figure 8: Binary edge features and the texture features extracted by the
VGG16-BEFB-multiple model and its predictions under FGSM of ϵ=16 at-
tack.
zero. On Fig. 13 and Fig. 14, four more and eight more perturbations are
added, respectively. It can be seen that the prediction results are correct
under FGSM of ϵ=12 attack and wrong under FGSM of ϵ=16 attack. When
focusing on the binary edge features under these two attacks, it is found the
changes on binary edge features in most of cases are zeros, e.g., in ”dog”,
”truck”, and ”ship” images.
14Figure 9: Binary edge features and the texture features extracted by the
VGG16-BEFB-multiple model and its predictions under FGSM of ϵ=20 at-
tack.
Figure 10: Binary edge features and the texture features extracted by the
VGG16-BEFB-multiple model and its predictions under FGSM of ϵ=24 at-
tack.
15Figure 11: Texture features extracted by the original ResNet34 model and its
predictions under FGSM of ϵ=8 attack.
Figure 12: Binary edge features and the texture features extracted by the
ResNet34-BEFB-multiple model and its predictions under FGSM of ϵ=8 at-
tack.
We also compare the classification performance of both original models
and BEFB integrated models on the images perturbed by gaussian noise.
Fig. 15 illustrates the gaussian noise perturbed images of CIFAR-10 dataset
and MNIST dataset. In table 6, it is clear to see the classification accuracy
of BEFB integrated models are better than the original models on both
16Figure 13: Binary edge features and the texture features extracted by the
ResNet34-BEFB-multiple model and its predictions under FGSM of ϵ=12 at-
tack.
Figure 14: Binary edge features and the texture features extracted by the
ResNet34-BEFB-multiple model and its predictions under FGSM of ϵ=16 at-
tack.
17datasets, e.g. the ResNet34-BEFB-multiple model can achieve 15% and 10%
higher accuracy than the original model on CIFAR-10 dataset and MNIST
dataset, respectively.
(a) Gaussian noise with zero mean (b) Gaussian noise with zero mean
and 0.08 standard deviation on and 0.35 standard deviation on
CIFAR-10 dataset MNIST dataset
Figure 15: Gaussian noise perturbed images.
CIFAR-10 MNIST
VGG16 61.35% 85.17%
VGG16-BEFB-multiple 64.17% 88.75%
ResNet34 75.63% 76.01%
ResNet34-BEFB-multiple 91.62% 86.11%
Table 6: Comparison of classification accuracy between the original models and BEFB
integrated models on gaussian noise perturbed CIFAR-10 and MNIST datasets.
4.5. Combining BEFB integrated models with AT and PCL
We combine BEFB-multiple models with two popular robustness enhanc-
ing techniques--AT and PCL, and compare them to the original models
with AT and PCL. We denote VGG16-BEFB-multiple models with AT as
VGG16-BEFB-multiple-AT, and VGG16-BEFB-multiple models with PCL
as VGG16-BEFB-multiple-PCL. The same notations for ResNet34-BEFB-
multiple models and the original models. Fig 16 compares the classification
18accuracy of BEFB-multiple-AT models with AT enhanced original models
under PGD attack. Fig. 17 compares the classification accuracy of BEFB-
multiple-PCL models with PCL enhanced original models under FGSM and
PGD attacks.
Figure16: ComparingATenhancedBEFB-multiplemodelswithoriginalmodels
under PGD attack.
(a) under FGSM attack (b) under PGD attack
Figure17: ComparingPCLenhancedBEFB-multiplemodelswithoriginalmod-
els under FGSM and PGD attacks.
From the figures, we can see AT and PCL enhanced BEFB-multiple mod-
els have better classification accuracy than AT and PCL enhanced original
models.
194.6. Ablation study
BEFB integrated models have two main components, i.e., Sobel layers
and threshold layer. We remove them respectively in BEFB-multiple models
to observe the accuracy change. We denote threshold layer removed models
as BEFB-multiple-tlre, and Sobel layers removed models as BEFB-multiple-
slre. Table 7 shows the comparison of classification accuracy between the
original BEFB-multiple models and BEFB-multiple models with threshold
layer and Sobel layers removed, respectively. From the table, it is clear to see
when removing threshold layer and Sobel layers, respectively, the robustness
ofBEFB-multiple-tlreandBEFB-multiple-slremodelsisweakened. Thiscan
be also illustrated by Fig. 18. Fig. 18(b) shows, without thresholding, the
small noise in AEs is amplified after performing edge detection.
CIFAR-10 SVHN
FGSM PGD FGSM PGD
VGG16-BEFB-multiple-tlre 40.55% 6.73% 48.70% 10.46%
VGG16-BEFB-multiple-slre 33.73% 2.90% 55.22% 15.89%
VGG16-BEFB-multiple 45.60% 8.05% 59.28% 19.48%
ResNet34-BEFB-multiple-tlre 13.58% 0.09% 24.22% 2.44%
ResNet34-BEFB-multiple-slre 9.11% 0.86% 16.42% 2.18%
ResNet34-BEFB-multiple 14.88% 1.01% 25.17% 2.98%
Table 7: Comparison of removing threshold layer and Sobel layers respectively.
(a) Edge images for clean (b) Edge images for adver-
examples sarial examples
Figure 18: Edge images of clean examples and adversarial examples.
205. Discussions
The experimental results from Section 4 shows BEFB has no side effects
on model training, and BEFB integrated models are more robust than orig-
inal models under attacks. And when combining BEFB integrated models
with AT and PCL, it can achieve better classification accuracy than origi-
nal models. It also can be seen that, using BEFB to enhance robustness is
effective but not that significant. It may be because under BEFB, the bi-
nary edge features are combined with texture features by concatenation. We
believe it is worthwhile to explore other combination forms of binary edge
features and texture features which can potentially improve the robustness
of DCNNs notably.
6. Conclusions
Enhancing the robustness of DCNNs is of great significance for the safety-
critical applications in the real world. Inspired by the principal way that hu-
man eyes recognize objects, in this paper, we design four edge detectors and
propose a binary edge feature branch (BEFB for short), which can be eas-
ily integrated into any popular backbone. Experiments on multiple datasets
showBEFBhasnosideeffectsonmodeltraining, andBEFBintegratedmod-
els are more robust than the original models. The work in this paper for the
first time shows it is feasible to combine shape-like features and texture fea-
tures to make DCNNs more robust. In future’s work, we endeavor to explore
other effective and efficient combination forms of binary edge features and
texture features, and design an optimization framework for the parameter
searching to yield models with good performance under attacks.
Acknowledgment
This work was supported by the National Natural Science Foundation of
China (No.51977193).
References
[1] I. J. Goodfellow, J. Shlens, C. Szegedy, Explaining and harnessing ad-
versarial examples, in: International Conference on Learning Represen-
tations (ICLR), 2015.
21[2] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Good-
fellow, R. Fergus, Intriguing properties of neural networks, in: Interna-
tional Conference on Learning Representations (ICLR), 2014.
[3] T. Bai, J. Luo, J. Zhao, B. Wen, Q. Wang, Recent advances in adversar-
ial training for adversarial robustness, in: Z.-H. Zhou (Ed.), Proceedings
of the Thirtieth International Joint Conference on Artificial Intelligence,
IJCAI-21, International Joint Conferences on Artificial Intelligence Or-
ganization, 2021, pp. 4312–4321.
[4] J. Zhang, C. Li, Adversarial examples: Opportunities and challenges,
IEEEtransactionsonneuralnetworksandlearningsystems31(7)(2019)
2578–2593.
[5] A. Serban, E. Poll, J. Visser, Adversarial examples on object recogni-
tion: A comprehensive survey, ACM Computing Surveys (CSUR) 53 (3)
(2020) 1–38.
[6] L. I. Davitt, F. Cristino, A. C.-N. Wong, E. C. Leek, Shape informa-
tion mediating basic-and subordinate-level object recognition revealed
by analyses of eye movements., Journal of Experimental Psychology:
Human Perception and Performance 40 (2) (2014) 451.
[7] H. M. Sigurdardottir, S. M. Michalak, D. L. Sheinberg, Shape beyond
recognition: form-derived directionality and its effects on visual atten-
tion and motion perception., Journal of Experimental Psychology: Gen-
eral 143 (1) (2014) 434.
[8] J. Kittler, On the accuracy of the sobel edge detector, Image and Vision
Computing 1 (1) (1983) 37–42.
[9] H. Xiao, S. Xiao, G. Ma, C. Li, Image sobel edge extraction algorithm
accelerated by opencl, JOURNAL OF SUPERCOMPUTING 78 (14)
(2022) 16236–16265. doi:10.1007/s11227-022-04404-8.
[10] M. Yasir, M. S. Hossain, S. Nazir, S. Khan, R. Thapa, Object identifica-
tion using manipulated edge detection techniques, Science 3 (1) (2022)
1–6.
22[11] Y. Bengio, N. L´eonard, A. Courville, Estimating or propagating gra-
dients through stochastic neurons for conditional computation, arXiv
preprint arXiv:1308.3432 (2013).
[12] Z. Yang, J. Lee, C. Park, Injecting logical constraints into neural net-
works via straight-through estimators, in: International Conference on
Machine Learning, PMLR, 2022, pp. 25096–25122.
[13] A. Vanderschueren, C. De Vleeschouwer, Are straight-through gradients
and soft-thresholding all you need for sparse training?, in: Proceedings
of the IEEE/CVF Winter Conference on Applications of Computer Vi-
sion, 2023, pp. 3808–3817.
[14] A. Athalye, N. Carlini, D. Wagner, Obfuscated gradients give a false
sense of security: Circumventing defenses to adversarial examples, in:
Proceedings of the 35th International Conference on Machine Learning,
ICML 2018, 2018.
[15] K. Yue, R. Jin, C.-W. Wong, D. Baron, H. Dai, Gradient obfuscation
gives a false sense of security in federated learning, in: 32nd USENIX
Security Symposium (USENIX Security 23), 2023, pp. 6381–6398.
[16] Y. Huang, Y. Yu, H. Zhang, Y. Ma, Y. Yao, Adversarial robustness of
stabilized neural ode might be from obfuscated gradients, in: Mathe-
matical and Scientific Machine Learning, PMLR, 2022, pp. 497–515.
[17] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-
scale image recognition, in: International Conference on Learning Rep-
resentations (ICLR), 2015.
[18] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image
recognition, in: Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770–778.
[19] F. He, T. Liu, D. Tao, Why resnet works? residuals generalize, IEEE
transactions on neural networks and learning systems 31 (12) (2020)
5349–5362.
[20] A. Kurakin, I. Goodfellow, S. Bengio, Adversarial machine learning at
scale, in: InternationalConferenceonLearningRepresentations(ICLR),
2017.
23[21] N. Carlini, D. Wagner, Towards evaluating the robustness of neural
networks, in: 2017 IEEE Symposium on Security and Privacy (SP),
2017, pp. 39–57. doi:10.1109/SP.2017.49.
[22] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, A. Vladu, Towards
deep learning models resistant to adversarial attacks, in: International
Conference on Learning Representations (ICLR), 2018.
[23] A. Mustafa, S. H. Khan, M. Hayat, R. Goecke, J. Shen, L. Shao, Deeply
supervised discriminative learning for adversarial defense, IEEE Trans-
actionsonPatternAnalysisandMachineIntelligence43(9)(2021)3154–
3166.
[24] D.Tsipras, S.Santurkar, L.Engstrom, A.Turner, A.Madry,Robustness
may be at odds with accuracy, in: International Conference on Learning
Representations (ICLR), 2019.
[25] H. Kannan, A. Kurakin, I. Goodfellow, Adversarial logit pairing, in:
Proceedings of the 32th International Conference on Neural Information
Processing Systems, 2018.
[26] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A
large-scale hierarchical image database, in: IEEE conference on com-
puter vision and pattern recognition, Ieee, 2009, pp. 248–255.
[27] E. Wong, L. Rice, J. Z. Kolter, Fast is better than free: Revisiting
adversarial training, in: International Conference on Learning Repre-
sentations (ICLR), 2020.
[28] Z. Xu, G. Zhu, C. Meng, S. Cui, Z. Ying, W. Wang, M. Gu, Y. Huang,
A2: Efficient automated attacker for boosting adversarial training, in:
Proceedings of the 36th International Conference on Neural Information
Processing Systems, 2022.
[29] T. Li, Y. Wu, S. Chen, K. Fang, X. Huang, Subspace adversarial train-
ing, in: Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, 2022, pp. 13409–13418.
[30] A. Dabouei, F. Taherkhani, S. Soleymani, N. M. Nasrabadi, Revisiting
outer optimization in adversarial training, in: Computer Vision–ECCV
242022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022,
Proceedings, Part V, Springer, 2022, pp. 244–261.
[31] X. Li, Z. Wang, B. Zhang, F. Sun, X. Hu, Recognizing object by com-
ponents with human prior knowledge enhances adversarial robustness
of deep neural networks, IEEE Transactions on Pattern Analysis and
Machine Intelligence (2023).
[32] C. Sitawarin, K. Pongmala, Y. Chen, N. Carlini, D. Wagner, Part-based
models improve adversarial robustness, in: International Conference on
Learning Representations (ICLR), 2023.
[33] S. Seo, Y. Lee, P. Kang, Cost-free adversarial defense: Distance-based
optimization for model robustness without adversarial training, Com-
puter Vision and Image Understanding 227 (2023) 103599.
[34] Z. Yan, Y. Guo, C. Zhang, Adversarial margin maximization networks,
IEEE transactions on pattern analysis and machine intelligence 43 (4)
(2019) 1129–1139.
[35] Y. Guo, C. Zhang, Recent advances in large margin learning, IEEE
Transactions on Pattern Analysis and Machine Intelligence 44 (10)
(2022) 7167–7174. doi:10.1109/TPAMI.2021.3091717.
[36] S.-M. Moosavi-Dezfooli, A. Fawzi, P. Frossard, Deepfool: a simple and
accurate method to fool deep neural networks, in: Proceedings of the
IEEE conference on computer vision and pattern recognition, 2016, pp.
2574–2582.
[37] A. Krizhevsky, G. Hinton, et al., Learning multiple layers of features
from tiny images (2009).
[38] L. Deng, The mnist database of handwritten digit images for machine
learning research, IEEE Signal Processing Magazine 29 (6) (2012) 141–
142.
[39] N. Yuval, Reading digits in natural images with unsupervised feature
learning, in: Proceedings of the NIPS Workshop on Deep Learning and
Unsupervised Feature Learning, 2011.
[40] Y. Le, X. Yang, Tiny imagenet visual recognition challenge, CS 231N
7 (7) (2015) 3.
25