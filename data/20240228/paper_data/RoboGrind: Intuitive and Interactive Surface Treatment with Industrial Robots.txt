RoboGrind: Intuitive and Interactive Surface Treatment with Industrial
Robots
Benjamin Alt1,2,∗, Florian Sto¨ckl3, Silvan Mu¨ller3, Christopher Braun4,5, Julian Raible4,5,
Saad Alhasan3, Oliver Rettig3, Lukas Ringle1, Darko Katic1, Rainer Ja¨kel1,
Michael Beetz2, Marcus Strand3, and Marco F. Huber4,5
Abstract—Surfacetreatmenttaskssuchasgrinding,sanding
or polishing are a vital step of the value chain in many
industries, but are notoriously challenging to automate. We
present RoboGrind, an integrated system for the intuitive,
interactive automation of surface treatment tasks with indus-
trialrobots.Itcombinesasophisticated3Dperceptionpipeline
for surface scanning and automatic defect identification, an
interactive voice-controlled wizard system for the AI-assisted
bootstrappingandparameterizationofrobotprograms,andan
automatic planning and execution pipeline for force-controlled
robotic surface treatment. RoboGrind is evaluated both under
laboratory and real-world conditions in the context of refabri-
cating fiberglass wind turbine blades.
I. INTRODUCTION
Fig. 1: RoboGrind is an intuitive, interactive system for
Inawiderangeofindustriessuchasaerospace,consumer
robotic surface treatment comprising perception, program
goodsmanufacturing,ortheenergysector,surfacetreatment
generation, planning and control.
tasks are integral components of the value chain. With the
rise of remanufacturing as a core component of the circular
economy, the need for robust, cost-efficient (re-)finishing of
We also propose that the human is an integral source of
surfaces has become even more pressing. One example is
knowledge, guidance, and oversight, and ought to remain
the refabrication of wind turbine rotor blades, which require
involvedinthesurfacefinishingprocess,thoughinadifferent
considerablesurfacetreatmentafterseveralyearsofuse.Due
capacity and to a lesser degree.
to ashortage ofqualified laborand highcosts, economically
In this paper, we present RoboGrind, a software sys-
feasible remanufacturing requires novel, robust solutions for
tem for iteractive, artificial intelligence (AI)-assisted surface
automating surface finishing tasks with robots.
Roboticsurfacetreatmentischallengingduetothephysics treatment with industrial robots. It combines four distinct
of contact and abrasion, which are hard to simulate and technical contributions:
require robust force control. Moreover, in the context of 1) Advanced 3D vision and automatic defect detection,
remanufacturing, workpieces have been subject to different enabling the automatic treatment of different surface
degrees of wear, requiring sophisticated perception and al- geometries and defect locations;
gorithms for automatically identifying defects. At the same 2) Automatic planning of tool paths based on a 3D scan
time,manystepsinthesurfacetreatmentworkflow,fromthe of the workpiece, depending on the tool and material;
proper parameterization of robot programs to the choice of 3) AI-assisted bootstrapping of robot programs, with
tool, require considerable human expertise. We hypothesize a deep-learning-based natural language processing
that a software system that combines sophisticated percep- (NLP) frontend for user interaction;
tion,planning,reasoning,andcontrolcapabilitiescangreatly 4) Automatic simulation and force-controlled execution
reduce the cost of automation for surface finishing tasks. of the generated robot programs.
1ArtiMindsRobotics,76131Karlsruhe,Germany RoboGrind integrates these components into a unified archi-
2Institute for Artificial Intelligence, University of Bremen, 28359 Bre- tecture to achieve a very high degree of automation. The
men,Germany perception, planning, and control systems are individually
3Baden-Wu¨rttemberg Cooperative State University, 76133 Karlsruhe,
evaluated under laboratory conditions. The overall system is
Germany
4Institute of Industrial Manufacturing and Management IFF, University evaluated under real-world conditions for the refabrication
ofStuttgart,70569Stuttgart,Germany of fiberglass wind turbine blades. This paper conducts one
5Fraunhofer Institute for Manufacturing Engineering and Automation
of the first investigations into force-controlled disk sanding
IPA,70569Stuttgart,Germany
∗ Correspondingauthor:benjamin.alt@uni-bremen.de of fiberglass with lightweight collaborative robot arms.
©2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media,
includingreprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributiontoservers
orlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.
4202
beF
72
]OR.sc[
2v24561.2042:viXraII. RELATEDWORK generates a Cartesian tool path depending on the surface
A. Robotic Surface Treatment geometry.
3) Force-Controlled Surface Treatment: The generated
Li et al. implemented a pipeline for automated rail grind-
robot program is simulated and displayed to the user for
ing [1], which removes excess material from welds. They
validation. It is then automatically compiled into executable
designed a system with seven main modules, including
robotcodeandexecutedontherobot.Thistypicallyinvolves
modules for measurement, motion control, and information
force-controlled, abrasive motions in contact with the sur-
feedback. The main difference to our system is their spe-
face, as well as collision-free approach and depart motions.
cialization on weld seams and lack of guided adaption of
As most surface treatment tasks are iterative processes, the
sandingparametersbasedonaknowledgebase.Oyekanetal.
processisiterateduntilthedesiredsurfacequalityisreached.
researched methods to automate fan-blade reconditioning of
Thethreestepsoftheworkflowaredetailedinthefollow-
aerospace maintenance [2], using a simulation environment
ing sections.
based on a digital twin. Our work ties back to the point
they make in their conclusion: The main bottleneck for IV. 3DSURFACESCANNING
automatedgrindingremains“embeddingtheknowledgeofa
RoboGrind performs program generation and path plan-
skill worker into an automated cell” [2].
ning based on a 3D point cloud representation of the sur-
B. AI-Assisted Robot Programming face. We use a Gocator 24901 laser line scanner with a
field of view of up to 2m and a resolution of 6µm. The
Awidevarietyofmethodsfacilitatingthecreationofrobot
starting point of a scan is defined manually according to
programs have been proposed. Task and Motion Planning
the measurement range. Segmentation, outlier detection, and
(TAMP)approachesviewrobotprogrammingasajointtask-
downsamplingareperformed.Basedonaninitialcalibration
and motion-level planning problem and combine search-
step, the point cloud is transformed into the robot’s base
based planning in task space with collision-free motion
frame. We propose an automatic defect detection pipeline
planning [3], [4]. CRAM [5] proposes a knowledge-based
that combines two outlier detection algorithms: First, curve
approach to robot programming by combining a symbolic
fitting by linear regression is performed separately for the
program and knowledge representation with the KnowRob
pointsofeachscannedlineand,basedonseveralthresholds,
knowledge representation and reasoning (KR&R) engine
outliers and defects are marked and excluded. Second, a
[6] and a realistic simulation environment. This paradigm
StatisticalOutlierRemovalfilterfromthePointCloudLibrary
has been shown to support several forms of AI-assisted
(PCL)basedonk-NearestNeighbors(k-NN)isusedtodetect
robot programming [7], or synthesis of robot programs from
points with few neighbors. This allows detecting scanning
humanvirtualreality(VR)demonstrations[8].Severalrecent
artefacts that cause holes in point clouds, and eliminates
approachesproposetoleveragenaturallanguageasasuitable
outliers that do not belong to a scanned part. It also helps
abstraction for program synthesis. Code as Policies [9] and
reducing the number of false positives detected, as these
ProgPrompt [10] use a large language model (LLM) to
have no high point density and have too few neighbors. The
generatePythoncodethatusesanAPIofrobotprimitivesto
combined algorithms can detect all defects that deviate from
solvemanipulationtasks.TidyBot[11]usesnaturallanguage
anidealsurfaceshape,includingdents,bumps,scratches,and
as an intuitive representation for user input. We propose to
roughsurfaceareas.Unlikeneuralnetworks,theyrequireno
combine the advantages of natural language-based systems
training. The code can be found in our GitLab repository2.
withstructuredKR&Randplanningtoachieveintuitiveuser
interaction and precise, industrially robust execution. V. AI-ASSISTEDROBOTPROGRAMMING
III. OVERVIEW A core objective of RoboGrind is to solve robot-based
surface treatment tasks with a high degree of automation.
RoboGrind is an interactive system for rapidly and in-
RoboGrind builds upon a KR&R engine to automate large
tuitively automating surface finishing tasks with robots.
parts of the surface treatment workflow. At the same time,
It achieves this by combining advanced perception and
the complexity of the task as well as safety considerations
planning algorithms with KR&R capabilities and natural
necessitate the continued involvement of human experts in
language understanding. RoboGrind realizes a three-step
the process. Recognizing this, RoboGrind realizes a robot
workflow (see Fig. 2):
1) 3D Surface Scanning: The workpiece is scanned with programmingparadigmthatisfundamentallyinteractive,and
a laser scanner. Scanning and scan data processing is nearly integrates a natural language interface to facilitate intuitive
completely automated and defects on the workpiece are interaction with the user.
automatically detected.
A. Meta-Wizard Architecture
2) AI-AssistedRobotProgramming: Vianatural-language
The cognitive subsystem for interactive robot program-
interaction, the user is guided through the process of gen-
ming, which we call meta-wizard, comprises a knowledge
erating a parameterized robot program for the given task
base and a novel reasoner for surface treatment tasks. Both
(e.g., sanding, polishing, or deburring). A digital twin of the
robot and the required robot skills to perform the task are 1LMITechnologiesGmbH,Teltow,Germany
automaticallyinstantiatedandparameterized.Apathplanner 2https://gitlab.com/rahm-lab/robogrind-surfacetreatmentFig.2:RoboGrindintegratesperception(1),AI-assistedprogramming(2),planningandforcecontrol(3)intoacomprehensive
assistance system for robotic surface treatment.
are integrated into the KnowRob KR&R engine [6], which environment. Moreover, it permits human experts to add
provides a framework for robot cognition and metaprogram- procedural knowledge to the wizard without changing its
ming. code.
2) Domain-Specific Reasoner: To realize the cognitive
1) Knowledge Base: The knowledge base contains com- functions required for interactive program synthesis, we
monsense,robot-specificanddomain-specificknowledgeand contribute a novel reasoning system consisting of a Python
forms the basis for reasoning. In the KnowRob framework, executable (the control module) and a KnowRob plugin
knowledge is stored as Resource Description Format (RDF) (the reasoner). The control module controls the program
triples in a MongoDB database. KnowRob provides utilities generation process, using the Prolog-based reasoners in
for the automatic conversion of Web Ontology Language KnowRob and the natural language interface (see Sec. V-B)
(OWL)ontologiesintoRDFtriples,whichinturnallowsrea- to gather information about the workflow, tools, workpieces,
soners to jointly reason over symbolic (ontological) knowl- etc., and to make decisions about what actions to take.
edgeandsubsymbolic,unstructureddatasuchasforce-torque The reasoner is implemented as a set of Prolog predicates
data from a robot [6]. Commonsense and robot-specific over classes, individuals, and relations in the knowledge
knowledge is provided via the SOMA upper-level ontology base. Using these predicates, the control module can not
[12], while additional domain-specific knowledge is repre- only access explicit knowledge, but also derive new facts
sentedinanovelRoboGrindontology.Thisontologyextends about existing knowledge. One example is the predicate
SOMA by surface treatment-specific concepts such as task has tool(Task, Tool), which is true for all tool
types (e.g., Sanding), tools (e.g., OrbitalSander), or types that can be used for a given task.
materials (e.g., Fiberglass) as well as their subsymbolic
B. Natural Language Interface
properties (e.g., rotational speeds). The knowledge base can
be extended to new domains, materials, or tools by adding At runtime, some information required for program syn-
new classes and individuals to the ontology. thesis, such as the exact material of the workpiece, cannot
One important feature of the meta-wizard subsystem be inferred from the knowledge base and must be obtained
is that the surface treatment workflow itself is repre- by interacting with the user. For this purpose, we leverage
sented as classes and individuals of the ontology. Us- an NLP pipeline combining the Google Speech Recognition
ing soma:Workflow and related classes, surface treat- API[13],basedondeepneuralnetworks,andthespaCy[14]
ment processes can be represented by modeling their re- NLP library:
spective steps (e.g., SurfaceScanning, Simulation, 1) Conversion of the user’s speech to text using the
Execution, QualityControl) and chaining them via Google Speech Recognition API.
succeedence relations. This representation of workflows as 2) Grammar-based chunking of the text into semantic
ontological knowledge permits reasoners to reason about units using spaCy.
the workflow itself, and enables the meta-wizard to change 3) Semantic matching of chunks to the concept(s) to
its behavior depending on its belief state—its ontologi- be grounded (e.g., “mm” to Unit, or “fiberglass” to
cal knowledge and current understanding of the task and Material), based on spaCy’s word vector distance.Fig. 3: Illustration of the meta-wizard’s interactive symbol grounding mechanism. The meta-wizard’s main control module
retrieves symbolic knowledge about tasks, workpieces, etc., via Prolog queries to a domain-specific reasoner connected to
the KnowRob KR&R engine. Missing information about the concrete task, workpiece, etc., is obtained via dialog with the
user.
When the information provided by the user is insufficient,
e.g. due to misunderstood voice input, this information is
discarded and the current step is repeated.
VI. FORCE-CONTROLLEDSURFACETREATMENT
A. Path Planning
According to the position and orientation of the scanned
Fig. 4: Path planning on pointFig. 5: Test setup under surface, a set of intersection planes is adaptively defined.
cloud data. real-world conditions. By slicing the point cloud uniformly with multiple parallel
intersection planes, a set of cross-section contours is deter-
mined. This requires identifying all points whose distance
from a plane does not exceed a certain threshold. These
Voice output (text-to-speech) is realized with the Windows
points are then projected onto the corresponding plane and
voice APIs.
subsequently sorted, filtered, and interpolated to form the
C. Interactive Programming Workflow corresponding contours. As a continuous path is desired, a
curvedeterminationprocessenablesgeneratingsetsofpoints
Fig. 3 shows part of the interactive robot programming
that allow connecting the adjacent contours to form one
workflow. The complete process takes the following steps:
meanderingpath(seeFig.4).Thepathplannerisdesignedto
1) Meta-task grounding: The user is prompted for the operateonverticallyprojectivelyplanarsurfaces.Wereferto
top-leveltask(e.g.,Sanding).Suitabletools,possible [15]formoretechnicaldetailsanddiscussionoftheplanner.
workpieces and task parameters (such as the amount
of material to be removed) are retrieved from the
B. Simulation and Code Generation
knowledge base. Missing knowledge is grounded by
asking the user. The generated robot program and tool path are simulated
2) Task selection: To take steps towards achieving the and visualized in a 3D environment. The 3D digital twin
meta-task,thenext(sub-)taskisidentifiedbyquerying of the robot is updated by the meta-wizard during program
theknowledgebaseforthenextsuccessorinthemeta- generation to reflect, e.g., the surface finishing tool. Simu-
tasks workflow definition, depending on the meta- lation both permits to validate the kinematic feasibility of
wizard’s current belief state. In some cases, this re- the planned path and the collision-freeness of approach and
quiresinputfromtheuser,e.g.,whendecidingwhether depart motions, but also permits the user to ensure safe
to perform an additional pass over the surface. execution of the program. The program is then compiled to
3) Task execution: The selected task (e.g., executable robot code and executed on the robot. For sim-
Simulation)isexecutedbycallingacorresponding ulation, compilation, and execution, the robot programming
handler function in the control module. software ArtiMinds RPS3 is used.
4) Iteration: Iteration of steps 2) and 3) until a terminal
step in the workflow is reached. 3ArtiMindsRoboticsGmbH,Karlsruhe,GermanyTABLEI:Evaluationofthepathplanningalgorithmw.r.t.to
C. Hybrid Force-Position Control
itsabilityofapproximatingthesurfacetobesanded.Metrics
Atruntime,theplannedpathisexecutedbyahybridforce-
are computed for each of the 12 point clouds independently.
position controller. The control law is a PID controller
Averages and standard deviations are reported.
(cid:90) t de(t)
u wrench(t)=K pe(t)+K i e(τ)dτ +K d dt , RMSE/mm MAE/mm MAX/mm
0
0.372(σ=0.030) 0.348(0.034) 1.046(0,330)
u(t)=u (t)+u (t) .
pose wrench
The control signal u(t) is a 6-dimensional vector denoting
a spatial offset (Cartesian position and orientation), which Error(RMSE),MeanAbsoluteError(MAE),andMaximum
is the sum of separate wrench and pose components. The AbsoluteError(MAX).Itisworthmentioningthatthescores
6Dwrenchcomponentu wrench(t)iscomputedbyastandard computed are directly correlated with the resolution of the
PIDlaw,wherethewrencherrore(t)isthedistancebetween surface point cloud, i.e., higher resolution leads to lower
the currently measured end-effector wrench to the allowed scores in general and vice versa, requiring normalization
wrench region (a 6D hypercube spanned by the wrenches for ideal comparability. We report the raw scores without
allowed for the application). For sanding of fiberglass, this normalization as all point clouds have nearly the same
region collapses to a point, where the force F z is applied amount of total points (µ = 83,501.75, σ = 2,288.78),
along the z-dimension, and zero along all other dimensions. which introduces a small but defensible bias in favor of
The pose component u pose(t) is the deviation of the current reporting values with an associated dimension (mm).
end-effector pose from the point on the planned path at 3) Control: Foreachofthe36scans,thesurfaceissanded
time t. at least once using the proposed simulation, planning, and
controlsubsystems.Robotend-effectortrajectories,compris-
VII. EXPERIMENTS
ing end-effector forces, are measured and analyzed. Each
The following comprehensive experimental evaluation of surfacesegmentissandedwithdifferentparameters,varying
RoboGrind assesses its capabilities regarding robot-assisted the contact pressure F , angle of attack α (in ◦) and number
z
surface treatment for remanufacturing, exemplified by wind ofpasses.Thecontactpressuresusedinthez directionwere
turbineblades.Theperception,planning,andcontrolsubsys- 5N and 10N, the angles of attack between the disc and the
tems are individually assessed under laboratory conditions. workpiece were 2° and 5°, and the process was repeated
Moreover, the overall system is evaluated holistically under for 5 or 10 passes. A total of 120 executions have been
realconditions.Inallexperiments,weutilizeaUR10erobot4
performed. To quantify the precision of the force controller,
with a disk sander5 for safe human-robot collaboration. we compute the MAE and MAX error of the measured end-
As robots by ABB, KUKA, FANUC or MOTOMAN are effector forces along the z-axis with respect to the contact
commonly used for polishing tasks [16], we additionally force setpoint F . In addition, we compute the rise time of
z
provide an assessment of the suitability of UR robots with the controller, defined as the time it takes for the measured
respect to surface treatment. end-effector force to reach 90% of F .
z
A. Laboratory Experiments
B. Real-World Experiments
1) Perception: Three identical 500mm x 750mm pieces
To evaluate RoboGrind under realistic conditions, we
of the same uncoated fiberglass rotor blade with the same
deploy it on-site at a company specialized in robot-based
curvature are partitioned into four segments, resulting in surfacetreatment6.Incontrasttothelaboratoryexperiments,
a total of twelve concave segments with various surface
the experiments are conducted on the complete blade and
defects (indentations and rough areas). The segments are
not on a cut-out section. First, a scan of the surface and two
scanned, followed by filling of the defects with fiberglass
sandingpassesareperformed(roughandfinesanding).Then
putty,scannedagain,andfinallyallthesegmentsarescanned
fiberglass putty is applied, the surface is scanned again and
a third time after sanding. The result is 36 point clouds,
two additional passes are performed. The main aim of the
12 without defects and 24 with 96 detectable defects. The
experiment is to determine to what extent RoboGrind can
detected, undetected and falsely detected defects are marked
provide user assistance for robotic surface treatment. The
on the 24 point clouds with detectable defects.
experiment setup is shown in Fig. 5.
2) Planning: Precise path planning is characterized by
howwellthepathalignswiththesurfaceitapproximates.To VIII. RESULTS
measurethisalignment,wedeterminethedistancefromeach
A. Laboratory Experiments
pointonthepathtotheclosestpointwithinthesurfacepoint
cloud obtained after being primed for subsequent sanding. 1) Perception: Evaluation of laboratory experiments re-
Using these distances, we estimate the accuracy of the garding the perception and damage detection demonstrated
approximation by computing the metrics Root Mean Square that perception is robust in over 71% of the 24 samples and
96 included damages. 69 defects were correctly detected,
4UniversalRobotsA/S,Odense,Denmark
5OnRobotGmbH,Soest,Germany 6SHLAG,Bo¨ttingen,GermanyTABLE II: Measured force control metrics for the three TABLE III: Evaluation of the surface quality in laboratory
tested contact force threshold values F . MAX is computed experiments.Measuredsurfaceroughnessforfourparameter
z
after F has first been reached. sets.
z
Parameters Metrics Parameters Metrics
Fz /N MAE/N MAX/N Risetime Trials Fz /N α/◦ Passes Ra1 /µm Ra2 /µm
5 1.47 9.74 0.96 40 10 5 5 199.57 122.44
10 1.84 7.17 1.75 26 10 2 10 169.45 104.25
20 2.10 5.52 1.35 17 5 5 5 123.46 162.02
5 2 10 225.01 119.82
to roughness after sanding R , which is close to the initial
a2
value.
B. Real-World Experiments
In the field experiment, we found that all components
of RoboGrind performed as well in an industrial setting
as in the laboratory. The 3D scanning and path planning
algorithms performed robustly under realistic, uncontrolled
light conditions, both before and after putty has been ap-
Fig. 6: Four randomly selected, exemplary executions for plied. For the path planner, we report errors close to the
each of the three tested contact forces. One execution per values observed in the laboratory (0.378mm, 0.357mm and
group has been highlighted. Smaller force setpoints lead to 0.994mm for RMSE, MAE and MAX). After putty has
better controller behavior. been applied, small regions with strong noise regarding the
scanned surface led to noisy point normals and therefore a
slight, but sudden change in the orientation of the sander.
27 were missed and 7 marked spots were false positives. This can be avoided by applying a global low-pass filter on
Remaining problems are holes in point clouds caused by the point cloud before path planning. The interactive meta-
failed measurements and false positive defect detections. wizard understood user inputs well despite loud background
Failed measurements result from darker colored or dirty noise. The control behavior is influenced by the much
surfaces that are not detectable by the laser scanner. False larger dimensions of the workpiece (see Fig. 5) and the
positives occur in sections where the depth of the defects is resulting strongly differing natural frequencies. A sufficient
low because of the dynamic thresholds of the algorithms. surface quality for the application was achieved. We leave
the optimization of controller parameters for future work.
2) Planning: The planner performs robustly on all 12
Overall, the UR10e robot proved suitable for sanding tasks.
point clouds (see Table I and Fig. 4). Scores ranging
from 0.331mm to 0.425mm for RMSE and 0.307mm to IX. CONCLUSIONS
0.420mm for MAE indicate a consistent performance, al-
In this work, we introduced RoboGrind, an AI-assisted
though some point clouds do contain void areas, leading to
robotic system for automating surface treatment tasks.
higher MAX scores.
We contribute the first quantitative evaluation of robotic
3) Control: Out of the 120 sanding attempts, 69% were
sanding of fiberglass with a collaborative robot. Moreover,
successful. The remainder failed due to exceeding force-
we provide a qualitative evaluation on a real-world use case.
torque limits of the UR10e, which occurred because of the
Our findings indicate that RoboGrind is able to largely
natural vibration of the workpiece. For the 83 successful
automate the process from perception to program execution
executions, the computed metrics are shown in Table II.
forsurfacetreatment.Thesystemcomponentsachievealevel
The MAE increases with the force setpoint, but is limited
of reliability and competence suitable for real-world use.
to 2.1N, indicating sufficiently precise control for fiberglass
However, some limitations remain. The meta-wizard is
sanding.Therisetimeremainedbelow1secondforF =5.
z currently limited to tasks within its existing knowledge
Overall, we found that a low force setpoint of 5N achieves
base—future work will explore methods for learning new
thebestquantitativecontrollerbehaviorandresultingsurface
tasks from demonstration or observation. Applications be-
quality. Exemplary force trajectories for each force setpoint
yond surface treatment, such as peg-in-hole assembly, also
are plotted in Fig. 6.
remain open directions for future work.
In the laboratory experiments, we found that the sanding
parameters shown in Table III deliver the best results. Ad- ACKNOWLEDGMENT
ditionally to these parameters the rotational speed and the This work was supported by the state of Baden-
traversespeedweresetto6,000rpmand20m/s,respectively. Wu¨rttemberg in the project RoboGrind under grant
The surface roughness of the rotor blade before the process BW1 0079/01, the DFG CRC EASE (CRC #1320) and the
is about 90µm. We compare the roughness after filling R EU project euROBIN (grant 101070596).
a1REFERENCES
[1] J. Li, T. Yuan, W. Wu, H. Zhu, C. Zhang, and J. Xie, “Automatic
programmingsystemforgrindingrobotofchsrrail,”Proceedingsof
the2018IEEEInternationalConferenceonRoboticsandBiomimetics,
2018.
[2] J. Oyekan, M. Farnsworth, W. Hutabarat, D. Miller, and A. Tiwari,
“Applying a 6 DoF robotic arm and digital twin to automate
fan-blade reconditioning for aerospace maintenance, repair, and
overhaul,” Sensors, vol. 20, no. 16, p. 4637, 2020. [Online].
Available:https://www.mdpi.com/1424-8220/20/16/4637
[3] C. R. Garrett, R. Chitnis, R. Holladay, B. Kim, T. Silver, L. P.
Kaelbling, and T. Lozano-Pe´rez, “Integrated Task and Motion
Planning,” arXiv:2010.01083 [cs], Oct. 2020, arXiv: 2010.01083.
[Online].Available:http://arxiv.org/abs/2010.01083
[4] L. P. Kaelbling and T. Lozano-Perez, “Hierarchical task and motion
planninginthenow,”inICRA,May2011,pp.1470–1477.[Online].
Available:http://ieeexplore.ieee.org/document/5980391/
[5] M.Beetz,L.Mo¨senlechner,andM.Tenorth,“CRAM—ACognitive
Robot Abstract Machine for everyday manipulation in human envi-
ronments,”in2010IEEE/RSJInternationalConferenceonIntelligent
RobotsandSystems,Oct.2010,pp.1012–1017,iSSN:2153-0866.
[6] M. Beetz, D. Bessler, A. Haidu, M. Pomarlan, A. K. Bozcuoglu,
and G. Bartels, “Know Rob 2.0 — A 2nd Generation Knowledge
Processing Framework for Cognition-Enabled Robotic Agents,”
in ICRA, May 2018, pp. 512–519. [Online]. Available: https:
//ieeexplore.ieee.org/document/8460964/
[7] S. Koralewski, G. Kazhoyan, and M. Beetz, “Self-Specialization of
General Robot Plans Based on Experience,” IEEE Robotics and
AutomationLetters,2019.
[8] B. Alt, F. K. Kenfack, A. Haidu, D. Katic, R. Ja¨kel, and M. Beetz,
“Knowledge-Driven Robot Program Synthesis from Human VR
Demonstrations,”Rhodes,Greece,Sep.2023,arXiv:2306.02739[cs].
[Online].Available:http://arxiv.org/abs/2306.02739
[9] J.Liang,W.Huang,F.Xia,P.Xu,K.Hausman,B.Ichter,P.Florence,
andA.Zeng,“CodeasPolicies:LanguageModelProgramsforEm-
bodiedControl,”in2023IEEEInternationalConferenceonRobotics
andAutomation(ICRA),May2023,pp.9493–9500.
[10] I. Singh, V. Blukis, A. Mousavian, A. Goyal, D. Xu, J. Tremblay,
D. Fox, J. Thomason, and A. Garg, “ProgPrompt: Generating
Situated Robot Task Plans using Large Language Models,” Sep.
2022,arXiv:2209.11302[cs].[Online].Available:http://arxiv.org/abs/
2209.11302
[11] J. Wu, R. Antonova, A. Kan, M. Lepert, A. Zeng, S. Song,
J.Bohg,S.Rusinkiewicz,andT.Funkhouser,“TidyBot:Personalized
Robot Assistance with Large Language Models,” May 2023,
arXiv:2305.05658 [cs]. [Online]. Available: http://arxiv.org/abs/2305.
05658
[12] D. Beßler, R. Porzel, M. Pomarlan, A. Vyas, S. Ho¨ffner, M. Beetz,
R. Malaka, and J. Bateman, “Foundations of the Socio-physical
Model of Activities (SOMA) for Autonomous Robotic Agents,”
arXiv:2011.11972 [cs], Nov. 2020, arXiv: 2011.11972. [Online].
Available:http://arxiv.org/abs/2011.11972
[13] “Speech-to-Text:AutomaticSpeechRecognition.”[Online].Available:
https://cloud.google.com/speech-to-text
[14] M. Honnibal and I. Montani, “spaCy: Industrial-strength Natural
Language Processing (NLP) in Python.” [Online]. Available:
https://github.com/explosion/spaCy
[15] J. Raible, C. Braun, and M. Huber, “Automatic Path Planning for
RoboticGrindingandPolishingTasksbasedonPointCloudSlicing,”
inISREurope2023;56thInternationalSymposiumonRobotics,2023,
pp.382–389.
[16] X. Zeng, G. Zhu, Z. Gao, R. Ji, J. Ansari, and C. Lu, “Surface
polishingbyindustrialrobots:areview,”TheInternationalJournalof
Advanced Manufacturing Technology, vol. 125, no. 9-10, pp. 3981–
4012,2023.