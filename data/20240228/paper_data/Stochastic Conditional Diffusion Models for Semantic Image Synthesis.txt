Stochastic Conditional Diffusion Models for Robust Semantic Image Synthesis
JuyeonKo*1 InhoKong*1 DogyunPark1 HyunwooJ.Kim1
Abstract models(Yangetal.,2019;Tangetal.,2020a;Ntavelisetal.,
2020;Tanetal.,2021a)suchasconditionalGANs(Goodfel-
Semanticimagesynthesis(SIS)isatasktogen-
lowetal.,2014;Mirza&Osindero,2014).Givenasemantic
eraterealisticimagescorrespondingtosemantic labelmapy,theseworkssampleanewimagexˆ fromthe
maps (labels). It can be applied to diverse real-
learnedconditionaldistributionp (X Y =y).Asdiffusion
worldpracticessuchasphotoeditingorcontent θ |
models(Sohl-Dicksteinetal.,2015;Hoetal.,2020;Song
creation.However,inreal-worldapplications,SIS
et al., 2021) have gained significant attention on various
often encounters noisy user inputs. To address
generationtasks(Rameshetal.,2021;Dhariwal&Nichol,
this,weproposeStochasticConditionalDiffusion
2021;Couaironetal.,2023),diffusionmodelsforSIShave
Model (SCDM), which is a robust conditional
beenrecentlystudiedbyafewworks(Wangetal.,2022a;
diffusionmodelthatfeaturesnovelforwardand
Xueetal.,2023). Specifically,SDM(Wangetal.,2022b)
generationprocessestailoredforSISwithnoisy
embedstheinputconditionssimilarlytoSPADE(Parketal.,
labels. Itenhancesrobustnessbystochastically
2019)andintegratesdiffusionmodelsinto thecontextof
perturbingthesemanticlabelmapsthroughLabel
SIS.LDM(Rombachetal.,2022)learnsadiffusionmodel
Diffusion,whichdiffusesthelabelswithdiscrete
onlatentvectorswithconditionencoders.
diffusion. Through the diffusion of labels, the
noisy and clean semantic maps become similar SIS has a wide range of real-world applications such as
as the timestep increases, eventually becoming photo editing or content creation (Chen & Koltun, 2017;
identical at t = T. This facilitates the genera- Park et al., 2019; Zhu et al., 2020a; Tang et al., 2020b).
tionofanimageclosetoacleanimage,enabling In practice, SIS often involves noisy input y˜ from users.
robust generation. Furthermore, we propose a Forinstance,usersmarkspecificareasastheclassesthey
class-wisenoisescheduletodifferentiallydiffuse wishtosynthesize,andthemarkscomewitherrorssuchas
thelabelsdependingontheclass.Wedemonstrate jaggededgesandincompletelymarkedareas.Evenlabelsby
thattheproposedmethodgenerateshigh-quality professionalannotatorsinbenchmarkdatasetsoccasionally
samplesthroughextensiveexperimentsandanal- containmistakesandshowinconsistencybetweenannota-
yses on benchmark datasets, including a novel tors,andtheinputfromenduserswouldinevitablyentail
experimentalsetupsimulatinghumanerrorsdur- noise. This posesthe gap between thelabel distributions
ingreal-worldapplications. fortrainingandinference. Usually,modelsaretrainedwith
cleanlabelsyinbenchmarkdatasets,whereasgeneration
isperformedwithnoisylabelsy˜. Inthecaseofdiffusion
1.Introduction models, the model is exposed to the erroneous guidance
throughoutT timesteps,i.e.,t=T tot=1,generatingthe
Semantic image synthesis (SIS) is a type of image trans- correspondingnoisyimage.
lation that converts a given semantic map (label) into a
Tominimizethegap,wegeneratesampleswithstochasti-
photo-realisticimage,whichistheinverseofsemanticseg-
callyperturbedlabelsforbothtrainingandinference.Specif-
mentation. Itisalsooneoftheconditionalimagegeneration
ically,weproposetodiffusethesemanticlabelmapy to
taskswithsemanticlabelmapsservingastheinputcondi- 0
y ,...,y andusethemthroughoutthegenerationprocess.
tions. Theproblemisformulatedasapproximatingthecon- 1 T
Assumethereexistsacleansemanticmapycorresponding
ditionaldistributionq(X Y)whereXandY aretherandom
| tothenoisyoney˜. Then,utilizingdiscretediffusionwith
variablesdenotingtheimageandthesemanticmap,respec-
anabsorbingstateallowsustomaketheintermediatenoisy
tively. SISisaddressedbyadoptingconditionalgenerative
mapy˜ andcleanmapy graduallybecomesimilar,asthey
t t
*Equalcontribution 1DepartmentofComputerScience,Korea aremaskedandeventuallybecomeidenticalatt=T. Since
University,RepublicofKorea. Correspondenceto: HyunwooJ. thetrajectoriesy andy˜ providedtothemodelduring
1:T 1:T
Kim<hyunwoojkim@korea.ac.kr>.
thegenerationprocessaresimilar,i.e.,y andy˜ getcloser
t t
than y and y˜, the generated image is close to the clean
Preprint.Underreview.
1
4202
beF
72
]VC.sc[
2v60561.2042:viXraStochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
y<latexit sha1_base64="Z36/E6rTRdnPOqgKUWDBzyu+nPY=">AAACz3icjVHLTsJAFD3UF+ILdemmkZi4IsUQdUl04xISeSRASFsGmNBXplMNIRi3/oBb/SvjH+hfeGcsiUqMTtP2zLn3nJl7rxN5PJaW9ZoxlpZXVtey67mNza3tnfzuXiMOE+Gyuht6oWg5dsw8HrC65NJjrUgw23c81nTGlyrevGEi5mFwLScR6/r2MOAD7tqSqE7Ht+XIGUwns57VyxesoqWXuQhKKSggXdUw/4IO+gjhIoEPhgCSsAcbMT1tlGAhIq6LKXGCENdxhhlypE0oi1GGTeyYvkPatVM2oL3yjLXapVM8egUpTRyRJqQ8QVidZup4op0V+5v3VHuqu03o76RePrESI2L/0s0z/6tTtUgMcK5r4FRTpBlVnZu6JLor6ubml6okOUTEKdynuCDsauW8z6bWxLp21Vtbx990pmLV3k1zE7yrW9KASz/HuQgaJ8XSabFcKxcqF+moszjAIY5pnmeo4ApV1Mk7wiOe8GzUjFvjzrj/TDUyqWYf35bx8AF1vZRK</latexit> 0: Cleansemantic map(e.g., ) , x<latexit sha1_base64="+3RFoRz8mRTwZf8G7JcbA92DYU0=">AAAC13icjVHLSsNAFD2Nr/qOdekmWARXJZWiLotuXFawD2lLmaTTNjQvkom0lOJO3PoDbvWPxD/Qv/DOmIJaRCckOXPuPWfm3muFrhML03zNaAuLS8sr2dW19Y3NrW19J1eLgySyedUO3CBqWCzmruPzqnCEyxthxJlnubxuDc9lvH7Do9gJ/CsxDnnbY33f6Tk2E0R19FxrwMSk5TExsHqT0XTaMTt63iyYahnzoJiCPNJVCfQXtNBFABsJPHD4EIRdMMT0NFGEiZC4NibERYQcFeeYYo20CWVxymDEDunbp10zZX3aS89YqW06xaU3IqWBA9IElBcRlqcZKp4oZ8n+5j1RnvJuY/pbqZdHrMCA2L90s8z/6mQtAj2cqhocqilUjKzOTl0S1RV5c+NLVYIcQuIk7lI8Imwr5azPhtLEqnbZW6bibypTsnJvp7kJ3uUtacDFn+OcB7WjQvG4ULos5ctn6aiz2MM+DmmeJyjjAhVUyXuERzzhWbvWbrU77f4zVcukml18W9rDByYkl0c=</latexit>ˆ 0 : Generated image y<latexit sha1_base64="T/zFpkM62YvHcFeXBaL99a71j2k=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCq5JKUZdFNy4r2Ae0pSTptB3Mi2Qi1NCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtPm5hcWl/LLhZXVtfUNfXOrEQdJ5LC6E7hB1LKtmLncZ3XBhctaYcQsz3ZZ0746k/HmNYtiHviXYhyyrmcNfT7gjiWI6uk7HcHdPks7niVG9iAdTyY9s6cXzZKpljELyhkoIlu1QH9BB30EcJDAA4MPQdiFhZieNsowERLXRUpcRIirOMMEBdImlMUowyL2ir5D2rUz1qe99IyV2qFTXHojUhrYJ01AeRFheZqh4olyluxv3qnylHcb09/OvDxiBUbE/qWbZv5XJ2sRGOBE1cCpplAxsjonc0lUV+TNjS9VCXIIiZO4T/GIsKOU0z4bShOr2mVvLRV/U5mSlXsny03wLm9JAy7/HOcsaByWykelykWlWD3NRp3HLvZwQPM8RhXnqKFO3jd4xBOetbZ2q91p95+pWi7TbOPb0h4+AH3+mDE=</latexit>˜0: Noisysemantic map (e.g., ) , <latexit sha1_base64="3G73uGbdEOBwa0pxM3zQf5gnmkg=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCuCipFHVZdOOygn1AW8sknbaheZFMxFq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjoRhvKa0mdm5+YX0YmZpeWV1Lbu+UY38OLR4xfIdP6ybLOKO7fGKsIXD60HImWs6vGYOTmW8dsXDyPa9CzEMeMtlPc/u2hYTRLWzW80+E6Omy0Tf7I6ux+O2cbnfzuaMvKGWPg0KCcghWWU/+4ImOvBhIYYLDg+CsAOGiJ4GCjAQENfCiLiQkK3iHGNkSBtTFqcMRuyAvj3aNRLWo730jJTaolMcekNS6tgljU95IWF5mq7isXKW7G/eI+Up7zakv5l4ucQK9In9SzfJ/K9O1iLQxbGqwaaaAsXI6qzEJVZdkTfXv1QlyCEgTuIOxUPCllJO+qwrTaRql71lKv6mMiUr91aSG+Nd3pIGXPg5zmlQPcgXDvPF82KudJKMOo1t7GCP5nmEEs5QRoW8b/CIJzxrDe1Wu9PuP1O1VKLZxLelPXwAxFGX4w==</latexit>xˆ ⇤0 : Generated image
t<latexit sha1_base64="hU9n5qlOd59SFLqixAlrNBGjpoM=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6kYouumyon1ALZJMp3VomoRkopQi+ANu9dPEP9C/8M44BbWITkhy5tx7zsy9148DkUrHec1Zc/MLi0v55cLK6tr6RnFzq5lGWcJ4g0VBlLR9L+WBCHlDChnwdpxwb+QHvOUPz1S8dcuTVEThpRzHvDvyBqHoC+ZJoi7kiXNdLDllRy97FrgGlGBWPSq+4Ao9RGDIMAJHCEk4gIeUng5cOIiJ62JCXEJI6DjHPQqkzSiLU4ZH7JC+A9p1DBvSXnmmWs3olIDehJQ29kgTUV5CWJ1m63imnRX7m/dEe6q7jenvG68RsRI3xP6lm2b+V6dqkejjWNcgqKZYM6o6Zlwy3RV1c/tLVZIcYuIU7lE8Icy0ctpnW2tSXbvqrafjbzpTsWrPTG6Gd3VLGrD7c5yzoHlQdg/LlfNKqXpqRp3HDnaxT/M8QhU11NEg7wEe8YRnq2aFVmbdfaZaOaPZxrdlPXwAtCCQAw==</latexit> =0 <latexit sha1_base64="R21JLS5gmCXG8vQfIqmd22QVJ84=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMU3XRZsS+oRZJ0WoemSZhMlFIEf8Ctfpr4B/oX3hmnoBbRCUnOnHvPmbn3+knIU+k4rzlrbn5hcSm/XFhZXVvfKG5uNdM4EwFrBHEYi7bvpSzkEWtILkPWTgTzRn7IWv7wXMVbt0ykPI7qcpyw7sgbRLzPA08SdSlP69fFklN29LJngWtACWbV4uILrtBDjAAZRmCIIAmH8JDS04ELBwlxXUyIE4S4jjPco0DajLIYZXjEDuk7oF3HsBHtlWeq1QGdEtIrSGljjzQx5QnC6jRbxzPtrNjfvCfaU91tTH/feI2Ilbgh9i/dNPO/OlWLRB8nugZONSWaUdUFxiXTXVE3t79UJckhIU7hHsUF4UArp322tSbVtaveejr+pjMVq/aByc3wrm5JA3Z/jnMWNA/K7lH58OKwVDkzo85jB7vYp3keo4IqamiQ9wCPeMKzVbUiK7PuPlOtnNFs49uyHj4ACa+QJw==</latexit>t=T t<latexit sha1_base64="hU9n5qlOd59SFLqixAlrNBGjpoM=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6kYouumyon1ALZJMp3VomoRkopQi+ANu9dPEP9C/8M44BbWITkhy5tx7zsy9148DkUrHec1Zc/MLi0v55cLK6tr6RnFzq5lGWcJ4g0VBlLR9L+WBCHlDChnwdpxwb+QHvOUPz1S8dcuTVEThpRzHvDvyBqHoC+ZJoi7kiXNdLDllRy97FrgGlGBWPSq+4Ao9RGDIMAJHCEk4gIeUng5cOIiJ62JCXEJI6DjHPQqkzSiLU4ZH7JC+A9p1DBvSXnmmWs3olIDehJQ29kgTUV5CWJ1m63imnRX7m/dEe6q7jenvG68RsRI3xP6lm2b+V6dqkejjWNcgqKZYM6o6Zlwy3RV1c/tLVZIcYuIU7lE8Icy0ctpnW2tSXbvqrafjbzpTsWrPTG6Gd3VLGrD7c5yzoHlQdg/LlfNKqXpqRp3HDnaxT/M8QhU11NEg7wEe8YRnq2aFVmbdfaZaOaPZxrdlPXwAtCCQAw==</latexit> =0 <latexit sha1_base64="R21JLS5gmCXG8vQfIqmd22QVJ84=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMU3XRZsS+oRZJ0WoemSZhMlFIEf8Ctfpr4B/oX3hmnoBbRCUnOnHvPmbn3+knIU+k4rzlrbn5hcSm/XFhZXVvfKG5uNdM4EwFrBHEYi7bvpSzkEWtILkPWTgTzRn7IWv7wXMVbt0ykPI7qcpyw7sgbRLzPA08SdSlP69fFklN29LJngWtACWbV4uILrtBDjAAZRmCIIAmH8JDS04ELBwlxXUyIE4S4jjPco0DajLIYZXjEDuk7oF3HsBHtlWeq1QGdEtIrSGljjzQx5QnC6jRbxzPtrNjfvCfaU91tTH/feI2Ilbgh9i/dNPO/OlWLRB8nugZONSWaUdUFxiXTXVE3t79UJckhIU7hHsUF4UArp322tSbVtaveejr+pjMVq/aByc3wrm5JA3Z/jnMWNA/K7lH58OKwVDkzo85jB7vYp3keo4IqamiQ9wCPeMKzVbUiK7PuPlOtnNFs49uyHj4ACa+QJw==</latexit>t=T
y<latexit sha1_base64="jiUeE4BMYOZOUkUHOKhnWXl+PS0=">AAAC0HicjVHLSsNAFD2Nr/quunQTLIKrkkpRl0U3LqvYB7SlJOm0Dc3LyUQspYhbf8CtfpX4B/oX3hmnoBbRCUnOnHvPmbn3OrHvJcKyXjPG3PzC4lJ2eWV1bX1jM7e1XUuilLus6kZ+xBuOnTDfC1lVeMJnjZgzO3B8VneGZzJev2E88aLwSoxi1g7sfuj1PNcWRLVbgS0GTs8cjyYd0cnlrYKlljkLihrkoVclyr2ghS4iuEgRgCGEIOzDRkJPE0VYiIlrY0wcJ+SpOMMEK6RNKYtRhk3skL592jU1G9JeeiZK7dIpPr2clCb2SRNRHicsTzNVPFXOkv3Ne6w85d1G9He0V0CswIDYv3TTzP/qZC0CPZyoGjyqKVaMrM7VLqnqiry5+aUqQQ4xcRJ3Kc4Ju0o57bOpNImqXfbWVvE3lSlZuXd1bop3eUsacPHnOGdB7bBQPCqULkr58qkedRa72MMBzfMYZZyjgip5X+MRT3g2Lo1b4864/0w1Mlqzg2/LePgAjJCUuA==</latexit> t y<latexit sha1_base64="jiUeE4BMYOZOUkUHOKhnWXl+PS0=">AAAC0HicjVHLSsNAFD2Nr/quunQTLIKrkkpRl0U3LqvYB7SlJOm0Dc3LyUQspYhbf8CtfpX4B/oX3hmnoBbRCUnOnHvPmbn3OrHvJcKyXjPG3PzC4lJ2eWV1bX1jM7e1XUuilLus6kZ+xBuOnTDfC1lVeMJnjZgzO3B8VneGZzJev2E88aLwSoxi1g7sfuj1PNcWRLVbgS0GTs8cjyYd0cnlrYKlljkLihrkoVclyr2ghS4iuEgRgCGEIOzDRkJPE0VYiIlrY0wcJ+SpOMMEK6RNKYtRhk3skL592jU1G9JeeiZK7dIpPr2clCb2SRNRHicsTzNVPFXOkv3Ne6w85d1G9He0V0CswIDYv3TTzP/qZC0CPZyoGjyqKVaMrM7VLqnqiry5+aUqQQ4xcRJ3Kc4Ju0o57bOpNImqXfbWVvE3lSlZuXd1bop3eUsacPHnOGdB7bBQPCqULkr58qkedRa72MMBzfMYZZyjgip5X+MRT3g2Lo1b4864/0w1Mlqzg2/LePgAjJCUuA==</latexit> t
Y<latexit sha1_base64="Kt50sZ5wZAq0KimNEHqkUy/UmrE=">AAACxHicjVHLSsNAFD2Nr/quunQTLIKrkkhRl0VBXLZgH1KLJOm0hk4eZCZCKfoDbvXbxD/Qv/DOOAW1iE5Icubce87MvddPeSik47wWrLn5hcWl4vLK6tr6xmZpa7slkjwLWDNIeJJ1fE8wHsasKUPJWSfNmBf5nLX90ZmKt+9YJsIkvpTjlPUibxiHgzDwJFGNq5tS2ak4etmzwDWgDLPqSekF1+gjQYAcERhiSMIcHgQ9XbhwkBLXw4S4jFCo4wz3WCFtTlmMMjxiR/Qd0q5r2Jj2ylNodUCncHozUtrYJ01CeRlhdZqt47l2Vuxv3hPtqe42pr9vvCJiJW6J/Us3zfyvTtUiMcCJriGkmlLNqOoC45Lrrqib21+qkuSQEqdwn+IZ4UArp322tUbo2lVvPR1/05mKVfvA5OZ4V7ekAbs/xzkLWocV96hSbVTLtVMz6iJ2sYcDmucxarhAHU3t/YgnPFvnFreElX+mWgWj2cG3ZT18ACRqj2c=</latexit> Y<latexit sha1_base64="Kt50sZ5wZAq0KimNEHqkUy/UmrE=">AAACxHicjVHLSsNAFD2Nr/quunQTLIKrkkhRl0VBXLZgH1KLJOm0hk4eZCZCKfoDbvXbxD/Qv/DOOAW1iE5Icubce87MvddPeSik47wWrLn5hcWl4vLK6tr6xmZpa7slkjwLWDNIeJJ1fE8wHsasKUPJWSfNmBf5nLX90ZmKt+9YJsIkvpTjlPUibxiHgzDwJFGNq5tS2ak4etmzwDWgDLPqSekF1+gjQYAcERhiSMIcHgQ9XbhwkBLXw4S4jFCo4wz3WCFtTlmMMjxiR/Qd0q5r2Jj2ylNodUCncHozUtrYJ01CeRlhdZqt47l2Vuxv3hPtqe42pr9vvCJiJW6J/Us3zfyvTtUiMcCJriGkmlLNqOoC45Lrrqib21+qkuSQEqdwn+IZ4UArp322tUbo2lVvPR1/05mKVfvA5OZ4V7ekAbs/xzkLWocV96hSbVTLtVMz6iJ2sYcDmucxarhAHU3t/YgnPFvnFreElX+mWgWj2cG3ZT18ACRqj2c=</latexit>
(1) (1)
y<latexit sha1_base64="T/zFpkM62YvHcFeXBaL99a71j2k=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCq5JKUZdFNy4r2Ae0pSTptB3Mi2Qi1NCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtPm5hcWl/LLhZXVtfUNfXOrEQdJ5LC6E7hB1LKtmLncZ3XBhctaYcQsz3ZZ0746k/HmNYtiHviXYhyyrmcNfT7gjiWI6uk7HcHdPks7niVG9iAdTyY9s6cXzZKpljELyhkoIlu1QH9BB30EcJDAA4MPQdiFhZieNsowERLXRUpcRIirOMMEBdImlMUowyL2ir5D2rUz1qe99IyV2qFTXHojUhrYJ01AeRFheZqh4olyluxv3qnylHcb09/OvDxiBUbE/qWbZv5XJ2sRGOBE1cCpplAxsjonc0lUV+TNjS9VCXIIiZO4T/GIsKOU0z4bShOr2mVvLRV/U5mSlXsny03wLm9JAy7/HOcsaByWykelykWlWD3NRp3HLvZwQPM8RhXnqKFO3jd4xBOetbZ2q91p95+pWi7TbOPb0h4+AH3+mDE=</latexit>˜0 y<latexit sha1_base64="AJTcb3rx+9hHr9top0f0Is1vNTM=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCq5JKUZdFNy4r9AVtKUk6bYfmRTIRaujCnbj1B9zqD4l/oH/hnTEFtYhOSHLm3HvOzL3XChweCcN4zWgLi0vLK9nV3Nr6xuZWfnunEflxaLO67Tt+2LLMiDncY3XBhcNaQchM13JY0xpfyHjzmoUR972amASs65pDjw+4bQqievm9juBOnyUd1xQja5BMptNerZcvGEVDLX0elFJQQLqqfv4FHfThw0YMFwweBGEHJiJ62ijBQEBcFwlxISGu4gxT5EgbUxajDJPYMX2HtGunrEd76RkptU2nOPSGpNRxSBqf8kLC8jRdxWPlLNnfvBPlKe82ob+VernECoyI/Us3y/yvTtYiMMCZqoFTTYFiZHV26hKrrsib61+qEuQQECdxn+IhYVspZ33WlSZStcvemir+pjIlK/d2mhvjXd6SBlz6Oc550Dgulk6K5atyoXKejjqLfRzgiOZ5igouUUWdvG/wiCc8a23tVrvT7j9TtUyq2cW3pT18ANN+mFU=</latexit>˜T y<latexit sha1_base64="T/zFpkM62YvHcFeXBaL99a71j2k=">AAAC2XicjVHLSsNAFD2Nr1pf8bFzEyyCq5JKUZdFNy4r2Ae0pSTptB3Mi2Qi1NCFO3HrD7jVHxL/QP/CO2MKahGdkOTMufecmXuvHbo8Fqb5mtPm5hcWl/LLhZXVtfUNfXOrEQdJ5LC6E7hB1LKtmLncZ3XBhctaYcQsz3ZZ0746k/HmNYtiHviXYhyyrmcNfT7gjiWI6uk7HcHdPks7niVG9iAdTyY9s6cXzZKpljELyhkoIlu1QH9BB30EcJDAA4MPQdiFhZieNsowERLXRUpcRIirOMMEBdImlMUowyL2ir5D2rUz1qe99IyV2qFTXHojUhrYJ01AeRFheZqh4olyluxv3qnylHcb09/OvDxiBUbE/qWbZv5XJ2sRGOBE1cCpplAxsjonc0lUV+TNjS9VCXIIiZO4T/GIsKOU0z4bShOr2mVvLRV/U5mSlXsny03wLm9JAy7/HOcsaByWykelykWlWD3NRp3HLvZwQPM8RhXnqKFO3jd4xBOetbZ2q91p95+pWi7TbOPb0h4+AH3+mDE=</latexit>˜0 y<latexit sha1_base64="xJ6nUQpkxIjedqfUJiu7vm0ckMk=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047JCX9CWkqTTdmheJJNCKcWtP+BWP0v8A/0L74xTUIvohCRnzj3nztx73djnqbCs15yxsrq2vpHfLGxt7+zuFfcPGmmUJR6re5EfJS3XSZnPQ1YXXPisFSfMCVyfNd3xjYw3JyxJeRTWxDRm3cAZhnzAPUcQ1e4Ejhi5A3Paq/WKJatsqWUuA1uDEvSqRsUXdNBHBA8ZAjCEEIR9OEjpacOGhZi4LmbEJYS4ijPMUSBvRipGCofYMX2HtGtrNqS9zJkqt0en+PQm5DRxQp6IdAlheZqp4pnKLNnfcs9UTnm3Kf1dnSsgVmBE7F++hfK/PlmLwABXqgZONcWKkdV5OkumuiJvbn6pSlCGmDiJ+xRPCHvKueizqTypql321lHxN6WUrNx7WpvhXd6SBmz/HOcyaJyV7Yvy+d15qXKtR53HEY5xSvO8RAW3qKKuOv6IJzwbVWNizI37T6mR055DfFvGwweefpOM</latexit> T
y<latexit sha1_base64="Z36/E6rTRdnPOqgKUWDBzyu+nPY=">AAACz3icjVHLTsJAFD3UF+ILdemmkZi4IsUQdUl04xISeSRASFsGmNBXplMNIRi3/oBb/SvjH+hfeGcsiUqMTtP2zLn3nJl7rxN5PJaW9ZoxlpZXVtey67mNza3tnfzuXiMOE+Gyuht6oWg5dsw8HrC65NJjrUgw23c81nTGlyrevGEi5mFwLScR6/r2MOAD7tqSqE7Ht+XIGUwns57VyxesoqWXuQhKKSggXdUw/4IO+gjhIoEPhgCSsAcbMT1tlGAhIq6LKXGCENdxhhlypE0oi1GGTeyYvkPatVM2oL3yjLXapVM8egUpTRyRJqQ8QVidZup4op0V+5v3VHuqu03o76RePrESI2L/0s0z/6tTtUgMcK5r4FRTpBlVnZu6JLor6ubml6okOUTEKdynuCDsauW8z6bWxLp21Vtbx990pmLV3k1zE7yrW9KASz/HuQgaJ8XSabFcKxcqF+moszjAIY5pnmeo4ApV1Mk7wiOe8GzUjFvjzrj/TDUyqWYf35bx8AF1vZRK</latexit> 0 y<latexit sha1_base64="Ew3+acQ7L8vDTc+Fj5zyIazppXQ=">AAAC0XicjVHLSsNAFD2Nr1pfVZdugkVwVVIRdVl047JiX9DWkqTTNjQvJhMhhIK49Qfc6k+Jf6B/4Z0xBbWITkhy5tx7zsy91wpdJxKG8ZrTFhaXllfyq4W19Y3NreL2TjMKYm6zhh24AW9bZsRcx2cN4QiXtUPOTM9yWcuaXMh465bxyAn8ukhC1vPMke8MHdsURN2kXc8UY2uYJtNpv94vloyyoZY+DyoZKCFbtaD4gi4GCGAjhgcGH4KwCxMRPR1UYCAkroeUOE7IUXGGKQqkjSmLUYZJ7IS+I9p1MtanvfSMlNqmU1x6OSl1HJAmoDxOWJ6mq3isnCX7m3eqPOXdEvpbmZdHrMCY2L90s8z/6mQtAkOcqRocqilUjKzOzlxi1RV5c/1LVYIcQuIkHlCcE7aVctZnXWkiVbvsranibypTsnJvZ7kx3uUtacCVn+OcB82jcuWkfHx1XKqeZ6POYw/7OKR5nqKKS9TQIG+ORzzhWbvWEu1Ou/9M1XKZZhfflvbwAW+QlXo=</latexit> T y<latexit sha1_base64="Z36/E6rTRdnPOqgKUWDBzyu+nPY=">AAACz3icjVHLTsJAFD3UF+ILdemmkZi4IsUQdUl04xISeSRASFsGmNBXplMNIRi3/oBb/SvjH+hfeGcsiUqMTtP2zLn3nJl7rxN5PJaW9ZoxlpZXVtey67mNza3tnfzuXiMOE+Gyuht6oWg5dsw8HrC65NJjrUgw23c81nTGlyrevGEi5mFwLScR6/r2MOAD7tqSqE7Ht+XIGUwns57VyxesoqWXuQhKKSggXdUw/4IO+gjhIoEPhgCSsAcbMT1tlGAhIq6LKXGCENdxhhlypE0oi1GGTeyYvkPatVM2oL3yjLXapVM8egUpTRyRJqQ8QVidZup4op0V+5v3VHuqu03o76RePrESI2L/0s0z/6tTtUgMcK5r4FRTpBlVnZu6JLor6ubml6okOUTEKdynuCDsauW8z6bWxLp21Vtbx990pmLV3k1zE7yrW9KASz/HuQgaJ8XSabFcKxcqF+moszjAIY5pnmeo4ApV1Mk7wiOe8GzUjFvjzrj/TDUyqWYf35bx8AF1vZRK</latexit> 0
X<latexit sha1_base64="OCgb2gGq5wWr4vsjQR6f5IHjtCs=">AAACxHicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6rIoiMsW7ANqkWQ6raGTB5mJUIr+gFv9NvEP9C+8M6agFtEJSc6ce8+Zuff6iQikcpzXgrWwuLS8Ulwtra1vbG6Vt3faMs5SxlssFnHa9T3JRRDxlgqU4N0k5V7oC97xx+c63rnjqQzi6EpNEt4PvVEUDAPmKaKa3Ztyxak6ZtnzwM1BBflqxOUXXGOAGAwZQnBEUIQFPEh6enDhICGujylxKaHAxDnuUSJtRlmcMjxix/Qd0a6XsxHttac0akanCHpTUto4IE1MeSlhfZpt4plx1uxv3lPjqe82ob+fe4XEKtwS+5dulvlfna5FYYhTU0NANSWG0dWx3CUzXdE3t79UpcghIU7jAcVTwswoZ322jUaa2nVvPRN/M5ma1XuW52Z417ekAbs/xzkP2kdV97haa9Yq9bN81EXsYR+HNM8T1HGJBlrG+xFPeLYuLGFJK/tMtQq5ZhfflvXwASIKj2Y=</latexit> (1) Fixed y<latexit sha1_base64="QFs8FQGSVT9HScjzqkDuhC2dkm4=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6rLoxmUF+4C2lCSdtkPzIpkUSilu/QG3+lniH+hfeGecglpEJyQ5c+45d+be68Y+T4VlveaMldW19Y38ZmFre2d3r7h/0EijLPFY3Yv8KGm5Tsp8HrK64MJnrThhTuD6rOmOr2W8OWFJyqPwTkxj1g2cYcgH3HMEUe1O4IiROzCnPatXLFllSy1zGdgalKBXLSq+oIM+InjIEIAhhCDsw0FKTxs2LMTEdTEjLiHEVZxhjgJ5M1IxUjjEjuk7pF1bsyHtZc5UuT06xac3IaeJE/JEpEsIy9NMFc9UZsn+lnumcsq7Tenv6lwBsQIjYv/yLZT/9claBAa4VDVwqilWjKzO01ky1RV5c/NLVYIyxMRJ3Kd4QthTzkWfTeVJVe2yt46KvymlZOXe09oM7/KWNGD75ziXQeOsbJ+XK7eVUvVKjzqPIxzjlOZ5gSpuUENddfwRT3g2asbEmBv3n1Ijpz2H+LaMhw9I/pNo</latexit> 0 X<latexit sha1_base64="OCgb2gGq5wWr4vsjQR6f5IHjtCs=">AAACxHicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6rIoiMsW7ANqkWQ6raGTB5mJUIr+gFv9NvEP9C+8M6agFtEJSc6ce8+Zuff6iQikcpzXgrWwuLS8Ulwtra1vbG6Vt3faMs5SxlssFnHa9T3JRRDxlgqU4N0k5V7oC97xx+c63rnjqQzi6EpNEt4PvVEUDAPmKaKa3Ztyxak6ZtnzwM1BBflqxOUXXGOAGAwZQnBEUIQFPEh6enDhICGujylxKaHAxDnuUSJtRlmcMjxix/Qd0a6XsxHttac0akanCHpTUto4IE1MeSlhfZpt4plx1uxv3lPjqe82ob+fe4XEKtwS+5dulvlfna5FYYhTU0NANSWG0dWx3CUzXdE3t79UpcghIU7jAcVTwswoZ322jUaa2nVvPRN/M5ma1XuW52Z417ekAbs/xzkP2kdV97haa9Yq9bN81EXsYR+HNM8T1HGJBlrG+xFPeLYuLGFJK/tMtQq5ZhfflvXwASIKj2Y=</latexit> (1) Diffused y<latexit sha1_base64="jiUeE4BMYOZOUkUHOKhnWXl+PS0=">AAAC0HicjVHLSsNAFD2Nr/quunQTLIKrkkpRl0U3LqvYB7SlJOm0Dc3LyUQspYhbf8CtfpX4B/oX3hmnoBbRCUnOnHvPmbn3OrHvJcKyXjPG3PzC4lJ2eWV1bX1jM7e1XUuilLus6kZ+xBuOnTDfC1lVeMJnjZgzO3B8VneGZzJev2E88aLwSoxi1g7sfuj1PNcWRLVbgS0GTs8cjyYd0cnlrYKlljkLihrkoVclyr2ghS4iuEgRgCGEIOzDRkJPE0VYiIlrY0wcJ+SpOMMEK6RNKYtRhk3skL592jU1G9JeeiZK7dIpPr2clCb2SRNRHicsTzNVPFXOkv3Ne6w85d1G9He0V0CswIDYv3TTzP/qZC0CPZyoGjyqKVaMrM7VLqnqiry5+aUqQQ4xcRJ3Kc4Ju0o57bOpNImqXfbWVvE3lSlZuXd1bop3eUsacPHnOGdB7bBQPCqULkr58qkedRa72MMBzfMYZZyjgip5X+MRT3g2Lo1b4864/0w1Mlqzg2/LePgAjJCUuA==</latexit> t
t<latexit sha1_base64="hU9n5qlOd59SFLqixAlrNBGjpoM=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6kYouumyon1ALZJMp3VomoRkopQi+ANu9dPEP9C/8M44BbWITkhy5tx7zsy9148DkUrHec1Zc/MLi0v55cLK6tr6RnFzq5lGWcJ4g0VBlLR9L+WBCHlDChnwdpxwb+QHvOUPz1S8dcuTVEThpRzHvDvyBqHoC+ZJoi7kiXNdLDllRy97FrgGlGBWPSq+4Ao9RGDIMAJHCEk4gIeUng5cOIiJ62JCXEJI6DjHPQqkzSiLU4ZH7JC+A9p1DBvSXnmmWs3olIDehJQ29kgTUV5CWJ1m63imnRX7m/dEe6q7jenvG68RsRI3xP6lm2b+V6dqkejjWNcgqKZYM6o6Zlwy3RV1c/tLVZIcYuIU7lE8Icy0ctpnW2tSXbvqrafjbzpTsWrPTG6Gd3VLGrD7c5yzoHlQdg/LlfNKqXpqRp3HDnaxT/M8QhU11NEg7wEe8YRnq2aFVmbdfaZaOaPZxrdlPXwAtCCQAw==</latexit> =0 t<latexit sha1_base64="hU9n5qlOd59SFLqixAlrNBGjpoM=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIp6kYouumyon1ALZJMp3VomoRkopQi+ANu9dPEP9C/8M44BbWITkhy5tx7zsy9148DkUrHec1Zc/MLi0v55cLK6tr6RnFzq5lGWcJ4g0VBlLR9L+WBCHlDChnwdpxwb+QHvOUPz1S8dcuTVEThpRzHvDvyBqHoC+ZJoi7kiXNdLDllRy97FrgGlGBWPSq+4Ao9RGDIMAJHCEk4gIeUng5cOIiJ62JCXEJI6DjHPQqkzSiLU4ZH7JC+A9p1DBvSXnmmWs3olIDehJQ29kgTUV5CWJ1m63imnRX7m/dEe6q7jenvG68RsRI3xP6lm2b+V6dqkejjWNcgqKZYM6o6Zlwy3RV1c/tLVZIcYuIU7lE8Icy0ctpnW2tSXbvqrafjbzpTsWrPTG6Gd3VLGrD7c5yzoHlQdg/LlfNKqXpqRp3HDnaxT/M8QhU11NEg7wEe8YRnq2aFVmbdfaZaOaPZxrdlPXwAtCCQAw==</latexit> =0
(2)
<latexit sha1_base64="3G73uGbdEOBwa0pxM3zQf5gnmkg=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCuCipFHVZdOOygn1AW8sknbaheZFMxFq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjoRhvKa0mdm5+YX0YmZpeWV1Lbu+UY38OLR4xfIdP6ybLOKO7fGKsIXD60HImWs6vGYOTmW8dsXDyPa9CzEMeMtlPc/u2hYTRLWzW80+E6Omy0Tf7I6ux+O2cbnfzuaMvKGWPg0KCcghWWU/+4ImOvBhIYYLDg+CsAOGiJ4GCjAQENfCiLiQkK3iHGNkSBtTFqcMRuyAvj3aNRLWo730jJTaolMcekNS6tgljU95IWF5mq7isXKW7G/eI+Up7zakv5l4ucQK9In9SzfJ/K9O1iLQxbGqwaaaAsXI6qzEJVZdkTfXv1QlyCEgTuIOxUPCllJO+qwrTaRql71lKv6mMiUr91aSG+Nd3pIGXPg5zmlQPcgXDvPF82KudJKMOo1t7GCP5nmEEs5QRoW8b/CIJzxrDe1Wu9PuP1O1VKLZxLelPXwAxFGX4w==</latexit>xˆ⇤0
x<latexit sha1_base64="JDPwiIyHxM9uQplk4S7nnaA20zM=">AAACznicjVHLTsJAFD3UF+ILdemmkZi4IsUQdUl04xITXgkQ0g4DTOgr7ZRICHHrD7jVzzL+gf6Fd8aSqMToNG3PnHvOnbn3OqErYmlZrxljZXVtfSO7mdva3tndy+8fNOIgiRivs8ANopZjx9wVPq9LIV3eCiNue47Lm874WsWbEx7FIvBrchryrmcPfTEQzJZEtTueLUfOwLzr1Xr5glW09DKXQSkFBaSrGuRf0EEfARgSeODwIQm7sBHT00YJFkLiupgRFxESOs4xR468Cak4KWxix/Qd0q6dsj7tVc5Yuxmd4tIbkdPECXkC0kWE1Wmmjic6s2J/yz3TOdXdpvR30lwesRIjYv/yLZT/9alaJAa41DUIqinUjKqOpVkS3RV1c/NLVZIyhMQp3Kd4RJhp56LPpvbEunbVW1vH37RSsWrPUm2Cd3VLGnDp5ziXQeOsWDovlm/LhcpVOuosjnCMU5rnBSq4QRV13fFHPOHZqBoTY27cf0qNTOo5xLdlPHwAnByTiw==</latexit> T (2)
y<latexit sha1_base64="xJ6nUQpkxIjedqfUJiu7vm0ckMk=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047JCX9CWkqTTdmheJJNCKcWtP+BWP0v8A/0L74xTUIvohCRnzj3nztx73djnqbCs15yxsrq2vpHfLGxt7+zuFfcPGmmUJR6re5EfJS3XSZnPQ1YXXPisFSfMCVyfNd3xjYw3JyxJeRTWxDRm3cAZhnzAPUcQ1e4Ejhi5A3Paq/WKJatsqWUuA1uDEvSqRsUXdNBHBA8ZAjCEEIR9OEjpacOGhZi4LmbEJYS4ijPMUSBvRipGCofYMX2HtGtrNqS9zJkqt0en+PQm5DRxQp6IdAlheZqp4pnKLNnfcs9UTnm3Kf1dnSsgVmBE7F++hfK/PlmLwABXqgZONcWKkdV5OkumuiJvbn6pSlCGmDiJ+xRPCHvKueizqTypql321lHxN6WUrNx7WpvhXd6SBmz/HOcyaJyV7Yvy+d15qXKtR53HEY5xSvO8RAW3qKKuOv6IJzwbVWNizI37T6mR055DfFvGwweefpOM</latexit> T
<latexit sha1_base64="3G73uGbdEOBwa0pxM3zQf5gnmkg=">AAAC2XicjVHLSsNAFD2Nr1pf9bFzEyyCuCipFHVZdOOygn1AW8sknbaheZFMxFq6cCdu/QG3+kPiH+hfeGdMQS2iE5KcOfeeM3PvNQPHjoRhvKa0mdm5+YX0YmZpeWV1Lbu+UY38OLR4xfIdP6ybLOKO7fGKsIXD60HImWs6vGYOTmW8dsXDyPa9CzEMeMtlPc/u2hYTRLWzW80+E6Omy0Tf7I6ux+O2cbnfzuaMvKGWPg0KCcghWWU/+4ImOvBhIYYLDg+CsAOGiJ4GCjAQENfCiLiQkK3iHGNkSBtTFqcMRuyAvj3aNRLWo730jJTaolMcekNS6tgljU95IWF5mq7isXKW7G/eI+Up7zakv5l4ucQK9In9SzfJ/K9O1iLQxbGqwaaaAsXI6qzEJVZdkTfXv1QlyCEgTuIOxUPCllJO+qwrTaRql71lKv6mMiUr91aSG+Nd3pIGXPg5zmlQPcgXDvPF82KudJKMOo1t7GCP5nmEEs5QRoW8b/CIJzxrDe1Wu9PuP1O1VKLZxLelPXwAxFGX4w==</latexit>xˆ⇤0 x<latexit sha1_base64="JDPwiIyHxM9uQplk4S7nnaA20zM=">AAACznicjVHLTsJAFD3UF+ILdemmkZi4IsUQdUl04xITXgkQ0g4DTOgr7ZRICHHrD7jVzzL+gf6Fd8aSqMToNG3PnHvOnbn3OqErYmlZrxljZXVtfSO7mdva3tndy+8fNOIgiRivs8ANopZjx9wVPq9LIV3eCiNue47Lm874WsWbEx7FIvBrchryrmcPfTEQzJZEtTueLUfOwLzr1Xr5glW09DKXQSkFBaSrGuRf0EEfARgSeODwIQm7sBHT00YJFkLiupgRFxESOs4xR468Cak4KWxix/Qd0q6dsj7tVc5Yuxmd4tIbkdPECXkC0kWE1Wmmjic6s2J/yz3TOdXdpvR30lwesRIjYv/yLZT/9alaJAa41DUIqinUjKqOpVkS3RV1c/NLVZIyhMQp3Kd4RJhp56LPpvbEunbVW1vH37RSsWrPUm2Cd3VLGnDp5ziXQeOsWDovlm/LhcpVOuosjnCMU5rnBSq4QRV13fFHPOHZqBoTY27cf0qNTOo5xLdlPHwAnByTiw==</latexit> T
x<latexit sha1_base64="KJ//Ig+RJT+BjkUS3QpUzg2Eyhs=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047KCfUBbSjKdtqF5kUyKpRS3/oBb/SzxD/QvvDNOQS2iE5KcOfecO3PvdWPfS4VlveaMpeWV1bX8emFjc2t7p7i7V0+jLGG8xiI/Spquk3LfC3lNeMLnzTjhTuD6vOGOrmS8MeZJ6kXhrZjEvBM4g9Dre8wRRLXagSOGbt+864pusWSVLbXMRWBrUIJe1aj4gjZ6iMCQIQBHCEHYh4OUnhZsWIiJ62BKXELIU3GOGQrkzUjFSeEQO6LvgHYtzYa0lzlT5WZ0ik9vQk4TR+SJSJcQlqeZKp6pzJL9LfdU5ZR3m9Df1bkCYgWGxP7lmyv/65O1CPRxoWrwqKZYMbI6prNkqivy5uaXqgRliImTuEfxhDBTznmfTeVJVe2yt46KvymlZOWeaW2Gd3lLGrD9c5yLoH5Sts/KpzenpcqlHnUeBzjEMc3zHBVco4qa6vgjnvBsVI2xMTPuP6VGTnv28W0ZDx/oHJOr</latexit> t x<latexit sha1_base64="+3RFoRz8mRTwZf8G7JcbA92DYU0=">AAAC13icjVHLSsNAFD2Nr/qOdekmWARXJZWiLotuXFawD2lLmaTTNjQvkom0lOJO3PoDbvWPxD/Qv/DOmIJaRCckOXPuPWfm3muFrhML03zNaAuLS8sr2dW19Y3NrW19J1eLgySyedUO3CBqWCzmruPzqnCEyxthxJlnubxuDc9lvH7Do9gJ/CsxDnnbY33f6Tk2E0R19FxrwMSk5TExsHqT0XTaMTt63iyYahnzoJiCPNJVCfQXtNBFABsJPHD4EIRdMMT0NFGEiZC4NibERYQcFeeYYo20CWVxymDEDunbp10zZX3aS89YqW06xaU3IqWBA9IElBcRlqcZKp4oZ8n+5j1RnvJuY/pbqZdHrMCA2L90s8z/6mQtAj2cqhocqilUjKzOTl0S1RV5c+NLVYIcQuIk7lI8Imwr5azPhtLEqnbZW6bibypTsnJvp7kJ3uUtacDFn+OcB7WjQvG4ULos5ctn6aiz2MM+DmmeJyjjAhVUyXuERzzhWbvWbrU77f4zVcukml18W9rDByYkl0c=</latexit>ˆ0 x<latexit sha1_base64="KJ//Ig+RJT+BjkUS3QpUzg2Eyhs=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047KCfUBbSjKdtqF5kUyKpRS3/oBb/SzxD/QvvDNOQS2iE5KcOfecO3PvdWPfS4VlveaMpeWV1bX8emFjc2t7p7i7V0+jLGG8xiI/Spquk3LfC3lNeMLnzTjhTuD6vOGOrmS8MeZJ6kXhrZjEvBM4g9Dre8wRRLXagSOGbt+864pusWSVLbXMRWBrUIJe1aj4gjZ6iMCQIQBHCEHYh4OUnhZsWIiJ62BKXELIU3GOGQrkzUjFSeEQO6LvgHYtzYa0lzlT5WZ0ik9vQk4TR+SJSJcQlqeZKp6pzJL9LfdU5ZR3m9Df1bkCYgWGxP7lmyv/65O1CPRxoWrwqKZYMbI6prNkqivy5uaXqgRliImTuEfxhDBTznmfTeVJVe2yt46KvymlZOWeaW2Gd3lLGrD9c5yLoH5Sts/KpzenpcqlHnUeBzjEMc3zHBVco4qa6vgjnvBsVI2xMTPuP6VGTnv28W0ZDx/oHJOr</latexit> t x<latexit sha1_base64="+3RFoRz8mRTwZf8G7JcbA92DYU0=">AAAC13icjVHLSsNAFD2Nr/qOdekmWARXJZWiLotuXFawD2lLmaTTNjQvkom0lOJO3PoDbvWPxD/Qv/DOmIJaRCckOXPuPWfm3muFrhML03zNaAuLS8sr2dW19Y3NrW19J1eLgySyedUO3CBqWCzmruPzqnCEyxthxJlnubxuDc9lvH7Do9gJ/CsxDnnbY33f6Tk2E0R19FxrwMSk5TExsHqT0XTaMTt63iyYahnzoJiCPNJVCfQXtNBFABsJPHD4EIRdMMT0NFGEiZC4NibERYQcFeeYYo20CWVxymDEDunbp10zZX3aS89YqW06xaU3IqWBA9IElBcRlqcZKp4oZ8n+5j1RnvJuY/pbqZdHrMCA2L90s8z/6mQtAj2cqhocqilUjKzOTl0S1RV5c+NLVYIcQuIk7lI8Imwr5azPhtLEqnbZW6bibypTsnJvp7kJ3uUtacDFn+OcB7WjQvG4ULos5ctn6aiz2MM+DmmeJyjjAhVUyXuERzzhWbvWbrU77f4zVcukml18W9rDByYkl0c=</latexit>ˆ0
<latexit sha1_base64="R21JLS5gmCXG8vQfIqmd22QVJ84=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMU3XRZsS+oRZJ0WoemSZhMlFIEf8Ctfpr4B/oX3hmnoBbRCUnOnHvPmbn3+knIU+k4rzlrbn5hcSm/XFhZXVvfKG5uNdM4EwFrBHEYi7bvpSzkEWtILkPWTgTzRn7IWv7wXMVbt0ykPI7qcpyw7sgbRLzPA08SdSlP69fFklN29LJngWtACWbV4uILrtBDjAAZRmCIIAmH8JDS04ELBwlxXUyIE4S4jjPco0DajLIYZXjEDuk7oF3HsBHtlWeq1QGdEtIrSGljjzQx5QnC6jRbxzPtrNjfvCfaU91tTH/feI2Ilbgh9i/dNPO/OlWLRB8nugZONSWaUdUFxiXTXVE3t79UJckhIU7hHsUF4UArp322tSbVtaveejr+pjMVq/aByc3wrm5JA3Z/jnMWNA/K7lH58OKwVDkzo85jB7vYp3keo4IqamiQ9wCPeMKzVbUiK7PuPlOtnNFs49uyHj4ACa+QJw==</latexit>t=T (2) x<latexit sha1_base64="KJ//Ig+RJT+BjkUS3QpUzg2Eyhs=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047KCfUBbSjKdtqF5kUyKpRS3/oBb/SzxD/QvvDNOQS2iE5KcOfecO3PvdWPfS4VlveaMpeWV1bX8emFjc2t7p7i7V0+jLGG8xiI/Spquk3LfC3lNeMLnzTjhTuD6vOGOrmS8MeZJ6kXhrZjEvBM4g9Dre8wRRLXagSOGbt+864pusWSVLbXMRWBrUIJe1aj4gjZ6iMCQIQBHCEHYh4OUnhZsWIiJ62BKXELIU3GOGQrkzUjFSeEQO6LvgHYtzYa0lzlT5WZ0ik9vQk4TR+SJSJcQlqeZKp6pzJL9LfdU5ZR3m9Df1bkCYgWGxP7lmyv/65O1CPRxoWrwqKZYMbI6prNkqivy5uaXqgRliImTuEfxhDBTznmfTeVJVe2yt46KvymlZOWeaW2Gd3lLGrD9c5yLoH5Sts/KpzenpcqlHnUeBzjEMc3zHBVco4qa6vgjnvBsVI2xMTPuP6VGTnv28W0ZDx/oHJOr</latexit> t <latexit sha1_base64="R21JLS5gmCXG8vQfIqmd22QVJ84=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMU3XRZsS+oRZJ0WoemSZhMlFIEf8Ctfpr4B/oX3hmnoBbRCUnOnHvPmbn3+knIU+k4rzlrbn5hcSm/XFhZXVvfKG5uNdM4EwFrBHEYi7bvpSzkEWtILkPWTgTzRn7IWv7wXMVbt0ykPI7qcpyw7sgbRLzPA08SdSlP69fFklN29LJngWtACWbV4uILrtBDjAAZRmCIIAmH8JDS04ELBwlxXUyIE4S4jjPco0DajLIYZXjEDuk7oF3HsBHtlWeq1QGdEtIrSGljjzQx5QnC6jRbxzPtrNjfvCfaU91tTH/feI2Ilbgh9i/dNPO/OlWLRB8nugZONSWaUdUFxiXTXVE3t79UJckhIU7hHsUF4UArp322tSbVtaveejr+pjMVq/aByc3wrm5JA3Z/jnMWNA/K7lH58OKwVDkzo85jB7vYp3keo4IqamiQ9wCPeMKzVbUiK7PuPlOtnNFs49uyHj4ACa+QJw==</latexit>t=T (2) x<latexit sha1_base64="KJ//Ig+RJT+BjkUS3QpUzg2Eyhs=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdVl047KCfUBbSjKdtqF5kUyKpRS3/oBb/SzxD/QvvDNOQS2iE5KcOfecO3PvdWPfS4VlveaMpeWV1bX8emFjc2t7p7i7V0+jLGG8xiI/Spquk3LfC3lNeMLnzTjhTuD6vOGOrmS8MeZJ6kXhrZjEvBM4g9Dre8wRRLXagSOGbt+864pusWSVLbXMRWBrUIJe1aj4gjZ6iMCQIQBHCEHYh4OUnhZsWIiJ62BKXELIU3GOGQrkzUjFSeEQO6LvgHYtzYa0lzlT5WZ0ik9vQk4TR+SJSJcQlqeZKp6pzJL9LfdU5ZR3m9Df1bkCYgWGxP7lmyv/65O1CPRxoWrwqKZYMbI6prNkqivy5uaXqgRliImTuEfxhDBTznmfTeVJVe2yt46KvymlZOWeaW2Gd3lLGrD9c5yLoH5Sts/KpzenpcqlHnUeBzjEMc3zHBVco4qa6vgjnvBsVI2xMTPuP6VGTnv28W0ZDx/oHJOr</latexit> t
(a) Existing Conditional Diffusion Models (b) Stochastic Conditional Diffusion Models
Figure1.Visualizationofconditionalgeneration. Eachcoloredtrajectoryrepresentsasamplingtrajectoryconditionedonanoisy
semanticmapy˜ (Red)andthecorrespondingcleansemanticmapy (Blue).Theyareprojectedontothe(1)semanticmapspaceandthe
0 0
(2)imagespace,sharingthesamex .(a)Existingconditionaldiffusionmodels(baseline)useafixedconditiony overthegeneration
T 0
process,andthegapbetweeny˜ andy yieldserroneousconditionalscoreestimationateachtimestept. (b)Incontrast,ourmethod
t t
stochasticallyperturbstheconditionwithmasking,resultinginatrajectoryy followingaprobabilitydistributionq(y |y ),as
1:T 1:T 0
depictedwithblueshadedareasaroundthey trajectory.Thismakestheintermediatetrajectories,i.e.,y |y andy˜ |y˜ ,closeto
t 1:T 0 1:T 0
eachother,enhancingtherobustnessagainstthenoisylabels.
image,asillustratedinFigure1. • WeintroduceanewSISbenchmarkdesignedtoassess
generationperformanceundernoisyconditions,simu-
Inthispaper,weintroduceStochasticConditionalDiffu-
latinghumanerrorsthatcanoccurduringreal-world
sionModel(SCDM),anovelconditionaldiffusionmodel
applications.
specificallydesignedtoenhancerobustnessonnoisylabels.
OurSCDMstochasticallyperturbsthesemanticmapswith • We conduct extensive experiments and analyses on
Label Diffusion and conditions image generation on the benchmarkdatasetsandachievecompetitiveresults.
diffusedlabels. Wealsoincorporatelabelstatisticsandde-
velopanewclass-wisenoisescheduleforlabelstoenhance 2.RelatedWorks
thegenerationqualityofsmallandrareclasses. Moreover,
thegenerationprocessofSCDMentailstwoheterogeneous SemanticImageSynthesis. SincePix2pix(Isolaetal.,
diffusionprocesses: adiscreteforwardprocessforlabels 2017)haveestablishedageneralframeworkforSIS,condi-
and a continuous reverse process for images. We empir- tionalGenerativeAdversarialNetworks(GANs)arewidely
ically demonstrate that SCDM can approximate q(X Y) usedinSIS(Yangetal.,2019;Zhuetal.,2017;Ntavelis
andpresenttheoreticalanalysis. Additionally,weintrodu| ce et al., 2020; Tang et al., 2020b; Tan et al., 2021a;b; Shi
a new noisy SIS benchmark and prove the robustness of etal.,2022). SPADE(Parketal.,2019)proposesspatially-
SCDMundernoisyconditions. adaptivenormalizationandsuccessfullypreservessemantic
information. RESAIL(Shietal.,2022)proposesretrieval-
Tosummarize,ourcontributionsareasfollows:
basedspatiallyadaptivenormalization,andOASIS(Sushko
et al., 2020) designs the discriminator as a semantic seg-
• WeproposeStochasticConditionalDiffusionModel,a mentationnetwork. SAFM(Lvetal.,2022)proposesshape-
novelandrobustconditionaldiffusionmodelforSIS aware position descriptors to modulate the features. Re-
withadiscreteforwardprocessoflabelsandacontinu- cently, diffusion models (DMs) also have been proposed
ousreverseprocessofimages. forSIS.SDM(Wangetal.,2022b)encodesthesemantic
labelmapwithSPADE.LDM(Rombachetal.,2022)lever-
• WedesignLabelDiffusion,adiscretediffusionprocess agesalatentspacefortheconditionsincludingthesemantic
forlabels,whichenablesdifferentialconditioningon maps. PITI (Wang et al., 2022a) pre-trains the semantic
thesemanticlabels. latentspaceandfinetunesitwiththeRGB-preprocessedse-
manticmaskimages,ratherthanusingthemapswithclass
• We provide theoretical analyses of our class-wise indexeslikemoststudiesincludingours. FLIS(Xueetal.,
scheduleandtherelationshipbetweentheclassguid- 2023)incorporatesnotonlysemanticlabelmapsbutalso
ances(implicitclassifiergradients)inducedbyfixed additionaltextinputs. Mostoftheseworkshaverecognized
labelsandlabeldiffusion. theapplicabilityofSISinreal-worldscenarios. However,to
2StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
thebestofourknowledge,ourmethodisthefirstDM-based The conditional DM can be trained with the hybrid loss
modeltoaddresstheissueofnoisyuserinputsinSIS. from(Nichol&Dhariwal,2021)as:
ConditionalDiffusionModels. BymodifyingtheU-Net
= +λ , (4)
hybrid simple vlb
(Ronnebergeretal.,2015)architecturetoincorporatethe L L L
=E ϵ ϵ (√α x +√1 α ϵ,y ,t) 2 ,
conditions into the network, conditional diffusion mod- Lsimple t,x0,y0,ϵ || − θ t 0 − t 0 ||2
els are prevalently leveraged for conditional generations. vlb =D KL(p θ(x (cid:2)t 1 x t,y 0) q(x t 1 x t,x 0)), (cid:3)
L − | || − |
ADM(Dhariwal&Nichol,2021),forexample,encodesthe
whereλisabalancinghyperparamerandϵ isanoisepre-
classembeddingintothenetworkwithAdaGNandutilizes θ
dictionmodel.
classifierguidance. LDM(Rombachetal.,2022)extracts
featuresfromthevariousconditionsandencodestheminto DiscreteStateSpaceDiffusionProcess. Foradiscrete
thenetworkthroughconcatenationorcross-attention.Mean- categorical random variable z 1,...,C with C cate-
∈ { }
while,SDM(Wangetal.,2022b)replacesGroupNormof gories, DMs for discrete state spaces (Hoogeboom et al.,
U-NetdecoderwithSPADEtoembedthelabelsintothenet- 2021;Austinetal.,2021)aredefinedwithtransitionmatri-
workinaspatiallyadaptivemanner. UNIT-DDPM(Sasaki ceswhere[Q ] = q(z = iz = j)andQ RC C.
etal.,2021)usestwodifferentdiffusionmodelsandado-
Theforwardpt roij cessistt hend| efit −ne1 dasfollows:t ∈ ×
maintranslationfunctionforthetrainingandsamplingof
q(z z ):=Cat(z ;p=Q z ), (5)
animage-to-imagetranslationmodel. Ourmethoddiffuses t | t −1 t t t −1
labelswithacarefullydesigneddiscretediffusionprocess
wherezistheone-hotcolumnvector(e )andCat(z;p)isa
and generates images conditioned on the diffused labels, z
categoricaldistributionparameterizedbyp. Wecansample
formulatinganovelconditionaldiffusionmodel.
z at an arbitrary timestep t from the following marginal
t
startingfromz inclosedform,duetotheMarkovproperty:
0
3.Preliminaries
q(z z ):=Cat(z ;p=Q z ),
Inthiswork,weconsiderconditionaldiffusionmodel(DM) t | 0 t t 0 (6)
whereQ =Q Q ...Q .
p (x y )forSIStask. WebrieflyintroduceexistingDM- t t t 1 1
θ 0 0 −
|
basedmodelsthatlearntheconditionaldistributionq(x y )
0 0
| AsthedesignchoiceofthetransitionmatrixQ determines
byestimatingareverseprocessgivenafixedlabely 0 that t
thediffusionprocess,onehastochoosethematrixcarefully.
approximatesanunconditionalforwardprocessq(x x ).
1:T 0
| Forinstance,D3PM(Austinetal.,2021)controlledthedata
Then, as our method perturbs labels y using a discrete
0
corruptionbydesigningthematrixwithdomainknowledge
diffusion,wesummarizebasicconceptsofadiscretestate
orstructuresuchastexttokenembeddingdistance.
spacediffusionprocess.
SemanticImageSynthesiswithDiffusionModels. In
4.StochasticConditionalDiffusionModel
previousmethods,theforwardprocessisdefinedasanun-
conditionaldiffusionmodelthataddsGaussiannoisetothe
We propose Stochastic Conditional Diffusion Model
imageasfollows:
(SCDM),arobustandnovelconditionaldiffusionmodelfor
α α
t t semanticimagesynthesis. Inthissection,weintroduceour
q(x x ):= x ; x , 1 I ,
t t 1 t t 1
| − N (cid:18) (cid:114)α t −1 − (cid:18) − α t −1(cid:19) (cid:19)
(1)
forwardandgenerationprocessesofSCDM(Section4.1),
discretelabeldiffusionprocess(Section4.2),andthetrain-
wherethedecreasingsequenceα
1:T
definesthenoiselevel
ingandsamplingschemesofourmethod(Section4.3).
withstrictlypositiveα . Fortheforwardprocess,wehave
t
aclosed-formsamplingstepofx atanarbitrarytimestep
t 4.1.Definitions
t,q(x x )= (x ;√α x ,(1 α )I),asitisdefinedas
t 0 t t 0 t
| N −
aMarkovchain. Thereverseprocessp (x y )isalso StochasticConditionalDiffusionModel(SCDM)isaclass
θ 0:T 0
|
definedasaMarkovchainwithlearnedtransitionsstarting ofconditional diffusionmodelsapproximating thecondi-
fromp(x T)= N(x T;0,I)givenas: tionaldistributionq(x 0 |y 0).Itconditionsondiffusedlabels,
T
i.e.,y 1:T,giveny 0.
p (x y ):=p(x ) p (x x ,y ). (2)
θ 0:T | 0 T θ t −1 | t 0 OurSCDMisdefinedasfollows:
t=1
(cid:89)
Itisusuallylearnedbyadeepneuralnetworkparameterized p θ(x 0 |y 0):= p θ(x 0:T,y 1:T |y 0)dx 1:Tdy 1:T, (7)
byθthatrepresentsGaussiantransitionsgivenas: (cid:90) (cid:90)
wherex andy arelatentswiththesamedimensional-
1:T 1:T
p (x x ,y ):= (x ;µ (x ,y ,t),Σ (x ,y ,t)). ityasx andy respectively,and(x ,y ) q(x ,y ).
θ t −1 | t 0 N t −1 θ t 0 θ t 0
(3)
0 0 0 0 ∼ 0 0
3StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Stochastic Conditional Diffusion Model (SCDM)
Generation process <latexit sha1_base64="BWyeS3hEBm5D0DuxhWBsX6Kzsp4=">AAAC0XicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMUBXFZsS/wUZJ01GCaCZOJUEpF3PoD7kR/yYX4B/UjBO9MI6hFdEKSM+fec2buvW4U+LG0rNeMMTI6Nj6RncxNTc/MzuXnF2oxT4THqh4PuGi4TswCP2RV6cuANSLBnLYbsLp7uavi9SsmYp+HFdmJ2EnbOQ/9M99zJFGnx5HgrdNKsyu37Z7ZzBesoqWXOQzsFBRKe/33h2d+Xeb5FxyjBQ4PCdpgCCEJB3AQ03MEGxYi4k7QJU4Q8nWcoYccaRPKYpThEHtJ33PaHaVsSHvlGWu1R6cE9ApSmlghDac8QVidZup4op0V+5t3V3uqu3Xo76ZebWIlLoj9S/eZ+V+dqkXiDFu6Bp9qijSjqvNSl0R3Rd3c/FKVJIeIOIVbFBeEPa387LOpNbGuXfXW0fG+zlSs2ntpboI3dUsasP1znMOgtla0N4rrBzTpHQxWFktYxirNcxMl7KOMKnkL3OMRT8ah0TFujNtBqpFJNYv4toy7DxF5mXI=</latexit> T
<latexit sha1_base64="OXFIYDYPMnLfO9xO7QcRHNvwLjE=">AAADDHicjVHLSsNAFD3GV31XXboJitCilFRERRCKLnSp0GrBSpjEqQ3mRTIRS+0vuPI33LkTt/6ACxF0r3/hnWkKVRGdkOTMufecmXuvFbpOLAzjpU/rHxgcGs6MjI6NT0xOZadnDuMgiWxesQM3iKoWi7nr+LwiHOHyahhx5lkuP7LOd2T86IJHsRP4ZdEM+YnHznyn7thMEGVmd0OzJhpcsFzNY6Jh1VuXbbNlbJbby12imRJXPYSR3wq7Cv3SLOfN7IJRMNTSf4JiChZK87Wlm5dScz/IPqOGUwSwkcADhw9B2AVDTM8xijAQEneCFnERIUfFOdoYJW1CWZwyGLHn9D2j3XHK+rSXnrFS23SKS29ESh2LpAkoLyIsT9NVPFHOkv3Nu6U85d2a9LdSL49YgQaxf+m6mf/VyVoE6thQNThUU6gYWZ2duiSqK/Lmek9VghxC4iQ+pXhE2FbKbp91pYlV7bK3TMXfVaZk5d5OcxN8yFvSgIvfx/kTHK4UimuF1QOa9DY6K4M5zCNH81xHCXvYR4W8b/GEV7xp19qddq89dFK1vlQziy9Le/wEZ/evzA==</latexit>p (x ,y y )=p(x )
✓ 0:T 0:T 0 T
… |
t=1
Y
(Noisy) y<latexit sha1_base64="kVT9nMRFhqTb49nX2lx80WJvBpA=">AAACznicjVHLSsNAFD2Nr1pfVZeKBIvgqiQi6rLoxmULfUFbSpJO29C8SCaFUoorwR9wq7/RPxH/QPEnvDNNQS2iE5KcOfecO3PvNQPHjrimvaaUpeWV1bX0emZjc2t7J7u7V438OLRYxfIdP6ybRsQc22MVbnOH1YOQGa7psJo5uBHx2pCFke17ZT4KWMs1ep7dtS2DE9Vougbvm1111C63szktr8mlLgI9AbnC4bT0cX80LfrZFzTRgQ8LMVwweOCEHRiI6GlAh4aAuBbGxIWEbBlnmCBD3phUjBQGsQP69mjXSFiP9iJnJN0WneLQG5JTxQl5fNKFhMVpqozHMrNgf8s9ljnF3Ub0N5NcLrEcfWL/8s2V//WJWji6uJI12FRTIBlRnZVkiWVXxM3VL1VxyhAQJ3CH4iFhSzrnfValJ5K1i94aMv4mlYIVeyvRxngXt6QB6z/HuQiqZ3n9In9eoklfY7bSOMAxTmmelyjgFkVUZMcf8YRnpagMlYlyN5MqqcSzj29LefgEsp6XMw==</latexit> T y<latexit sha1_base64="zosaMPjlUk0LnR+EdgKOT6hQRZQ=">AAACznicjVHLSsNAFD2Nr1pfVZdugkVwVRIt6rLoxmUF+4C2lEk6bQfzIpkUSilu/QG3+lniH+hfeGdMQS2iE5KcOfecO3PvdSJPJNKyXnPG0vLK6lp+vbCxubW9U9zdayRhGru87oZeGLcclnBPBLwuhfR4K4o58x2PN527KxVvjnmciDC4lZOId302DMRAuEwS1e74TI6cgTnpnfaKJats6WUuAjsDJWSrFhZf0EEfIVyk8MERQBL2wJDQ04YNCxFxXUyJiwkJHeeYoUDelFScFIzYO/oOadfO2ID2Kmei3S6d4tEbk9PEEXlC0sWE1Wmmjqc6s2J/yz3VOdXdJvR3slw+sRIjYv/yzZX/9alaJAa40DUIqinSjKrOzbKkuivq5uaXqiRliIhTuE/xmLCrnfM+m9qT6NpVb5mOv2mlYtXezbQp3tUtacD2z3EugsZJ2T4rV24qpeplNuo8DnCIY5rnOaq4Rg113fFHPOHZqBljY2bcf0qNXObZx7dlPHwAUB6Taw==</latexit> 3 y<latexit sha1_base64="xnBvshull8q/2xzb/7tbTohbMOY=">AAACznicjVHLSsNAFD2Nr1pfVZeKBIvgqiRF1GXRjcsW7APaUpJ02obmRTIplFJcCf6AW/2N/on4B4o/4Z1pCmoRnZDkzLnn3Jl7rxk4dsQ17TWlLC2vrK6l1zMbm1vbO9ndvWrkx6HFKpbv+GHdNCLm2B6rcJs7rB6EzHBNh9XMwbWI14YsjGzfu+WjgLVco+fZXdsyOFGNpmvwvtlVR+1CO5vT8ppc6iLQE5ArHk7LH/dH05KffUETHfiwEMMFgwdO2IGBiJ4GdGgIiGthTFxIyJZxhgky5I1JxUhhEDugb492jYT1aC9yRtJt0SkOvSE5VZyQxyddSFicpsp4LDML9rfcY5lT3G1EfzPJ5RLL0Sf2L99c+V+fqIWji0tZg001BZIR1VlJllh2Rdxc/VIVpwwBcQJ3KB4StqRz3mdVeiJZu+itIeNvUilYsbcSbYx3cUsasP5znIugWsjr5/mzMk36CrOVxgGOcUrzvEARNyihIjv+iCc8KyVlqEyUu5lUSSWefXxbysMnYd6XEQ==</latexit> 2 y<latexit sha1_base64="ineCUMG8iR9z/MWCpc7X8WP0m5U=">AAACznicjVHLSsNAFD2Nr1pfVZeKBEVwVRIRdVl047IF+4C2SJJO22BeTCaFUoorwR9wq7/RPxH/QPEnvDNNQS2iE5KcOfecO3PvtSPPjYVhvGa0ufmFxaXscm5ldW19I7+5VY3DhDus4oReyOu2FTPPDVhFuMJj9Ygzy7c9VrNvL2W81mc8dsPgWgwi1vKtbuB2XMcSRDWaviV6dkcf3Jg3+QOjYKilzwIzBQfF3XH5435vXArzL2iijRAOEvhgCCAIe7AQ09OACQMRcS0MieOEXBVnGCFH3oRUjBQWsbf07dKukbIB7WXOWLkdOsWjl5NTxyF5QtJxwvI0XcUTlVmyv+UeqpzybgP622kun1iBHrF/+abK//pkLQIdnKsaXKopUoyszkmzJKor8ub6l6oEZYiIk7hNcU7YUc5pn3XliVXtsreWir8ppWTl3km1Cd7lLWnA5s9xzoLqccE8LZyUadIXmKwsdrCPI5rnGYq4QgkV1fFHPOFZK2l9baTdTaRaJvVs49vSHj4BX36XEA==</latexit> 1
Label y<latexit sha1_base64="RTxlPnTlisxUqQAdIjoa46cj+6g=">AAACznicjVHLSsNAFD2Nr1pfVZeKBIvgqqQi6rLoxmUL9gFtKUk6bYN5MZkUSimuBH/Arf5G/0T8A8Wf8M40BbWITkhy5txz7sy91wpdJxKG8ZrSFhaXllfSq5m19Y3Nrez2TjUKYm6zih24Aa9bZsRcx2cV4QiX1UPOTM9yWc26vZLx2oDxyAn8GzEMWcsze77TdWxTENVoeqboW1192Dba2ZyRN9TS50EhAbni/qT8cX8wKQXZFzTRQQAbMTww+BCEXZiI6GmgAAMhcS2MiOOEHBVnGCND3phUjBQmsbf07dGukbA+7WXOSLltOsWll5NTxxF5AtJxwvI0XcVjlVmyv+UeqZzybkP6W0kuj1iBPrF/+WbK//pkLQJdXKgaHKopVIyszk6yxKor8ub6l6oEZQiJk7hDcU7YVs5Zn3XliVTtsremir8ppWTl3k60Md7lLWnAhZ/jnAfVk3zhLH9apklfYrrS2MMhjmme5yjiGiVUVMcf8YRnraQNtLF2N5VqqcSzi29Le/gEXR6XDw==</latexit> 0 Stochastic conditioningvia Label Diffusion forward discrete Label Diffusion
…
reverse continuous
<latexit sha1_base64="qH6p4PXEqgfghRLrgF8v47FsunE=">AAAC8nicjVHLSsNAFD3G9zvq0k1QhIpaEhEV3BTd6EYUbCvYUibjVIN5kUzEIn6FrtyJW3/ArX6E+Af6F94ZU/GB6IQk5557z5m5c93Y91Jp288dRmdXd09vX//A4NDwyKg5Nl5JoyzhoswjP0r2XZYK3wtFWXrSF/txIljg+qLqnmyofPVUJKkXhXuyFYt6wI5Cr+lxJolqmAu1gMljznxru6Ch27TOGntrVjuw5z/g1mzDnLaLtl7WT+DkYLo0VZu7ei61diLzCTUcIgJHhgACISRhHwwpPQdwYCMmro5z4hJCns4LXGCAtBlVCapgxJ7Q94iig5wNKVaeqVZz2sWnNyGlhRnSRFSXEFa7WTqfaWfF/uZ9rj3V2Vr0d3OvgFiJY2L/0rUr/6tTvUg0sap78KinWDOqO567ZPpW1MmtT11JcoiJU/iQ8glhrpXte7a0JtW9q7tlOv+iKxWrYp7XZnhVp6QBO9/H+RNUFovOcnFplya9jvfVh0lMoUDzXEEJm9hBmbwvcY8HPBrSuDZujNv3UqMj10zgyzLu3gA6+qMM</latexit> N(xT;0,I) x<latexit sha1_base64="56RV3KSWmRIDOQ1SLdSaYIZxQ34=">AAAC4nicjVHLSsNAFD3GV62vqEsRQosgCCUVUZdFNy4rWFtopUzSqQ3mRTIRS+3KnTvRpT/gVj9G+gf6F96ZpqAW0QlJzj33njNz51qh68TCNAcT2uTU9MxsZi47v7C4tKyvrJ7FQRLZvGIHbhDVLBZz1/F5RTjC5bUw4syzXF61Lo9kvnrFo9gJ/FPRDfm5xy58p+3YTBDV1DcaHSZ6DY+JjtU2rvtN82YUdJtmU8+bBVMtYxwUU5Av5Rrbj4NStxzob2ighQA2Enjg8CEIu2CI6amjCBMhcefoERcRclSeo48saROq4lTBiL2k7wVF9ZT1KZaesVLbtItLb0RKA5ukCaguIix3M1Q+Uc6S/c27pzzl2br0t1Ivj1iBDrF/6UaV/9XJXgTaOFA9ONRTqBjZnZ26JOpW5MmNL10JcgiJk7hF+YiwrZSjezaUJla9y7tlKv+uKiUrYzutTfAhT0kDLv4c5zg42ykU9wq7JzTpQwxXBuvIYYvmuY8SjlFGhbxv8YwXvGot7U671x6GpdpEqlnDt6U9fQJy1Z5a</latexit>ˆ 0|y
0
Figure2. GenerationprocessofSCDM.TheStochasticConditionalDiffusionModel(SCDM)isarobustconditionaldiffusionmodel
forsemanticimagesynthesis.SCDMconsistsofadiscreteforwardprocessforlabelsandacontinuousreverseprocessforimages.It
improvestherobustnesstonoisysemanticlabelsaswellasgenerationperformanceoncleansemanticlabels.z denotesthei-thpixelof
0
thesemanticmap,i.e.,z =yi wherey ={y1,...,yH×W}.
0 0 0 0 0
Forward process. SCDM consists of two diffusion pro- 4.2.1.TRANSITIONMATRIXFORLABELMASKING
cesses: acontinuousdiffusionprocessq(x x )forim-
agesasinEq.(1)andadiscretediffusionproct e| sst − q(1
y y )
Tograduallyerasetheinformationofthesemanticmapand
forcategoricalsemanticlabelsasinEq.(5).
Wenat m| et −th1
e
increasesimilarityamongdifferentmapsast=0 →t=T,
wedesignedourLabelDiffusionprocessbyprogressively
discretediffusionprocessLabelDiffusion. Then, thefor-
maskinglabels. Inotherwords,theoriginalsemanticlabels
wardprocessofSCDMisdefinedasfollows:
areconvertedintotheabsorbingstate‘masked’withsome
probability at each timestep. Consequently, all semantic
T
mapseventuallybecomeidenticalatt=T,eachfilledwith
q(x ,y x ,y ):= q(x ,y x ,y ), (8)
1:T 1:T 0 0 t t t 1 t 1
| | − − ‘masked’ateverypixel.
t=1
(cid:89)
q(x ,y x ,y ):=q(x x )q(y y ). (9) GivenC semanticclassesandonemaskedstate,wedefine
t t t 1 t 1 t t 1 t t 1
| − − | − | − thetransitionmatrixQ R(C+1) (C+1)atatimesteptas
t ∈ ×
Notethatalthoughwediffuseimagesandlabelsindepen-
dently,x tandy tarestillcorrelatedasx 0andy 0aredepen- 1 −β t,c if i=j =c,
dent(i.e.,y isdeterministicallydecidedgivenx ). β if i=C+1,j =c,
0 0 [Q ] = t,c (12)
Generation process. We define the joint distribution for
t ij 1 if i=j =C+1,
ourgenerationprocessas: 0 otherwise,
wheretheabsorbingstateisaddedas(C+1)-thclassand
T
β is the probability of a label of class c to be masked.
p (x ,y y ):=p(x )q(y y ) p (x x ,y ), t,c
θ 0:T 1:T 0 T 1:T 0 θ t 1 t t
| | − | Notethatclass-wisedefinedprobabilityβ enablesclass-
t=1 t,c
(cid:89) (10) wisenoisescheduling,whichwillbefurtherdiscussedin
thefollowingsection. WeassumethatQ isappliedtoeach
p (x x ,y ):= (x ;µ (x ,y ,t),Σ (x ,y ,t)), t
θ t −1 | t t N t −1 θ t t θ t t
(11)
pixelofthesemanticmapindependently.Sincethe‘masked’
stateistheabsorbingstate,oncethestateisinC+1then
thenextstateisalwaysC+1.
whereq(y y )isthediscreteLabelDiffusionforward
1:T 0
|
p cero ssc .es As san ydp iθ s( gx it v−e1 n|x int, Sy It S) ,is wt ehe onco lynt hin au vo eu ts or se av mer ps le ep tr ho e- wIn ha icd hdi it sio on n, e-th he otp vr eo cb ta ob ri wlit iy thq 1(z att | cz -0 th) ea nt tt ryst aa srt ii nng Eqfr .o (m 6),z i0 s:,
0
imagexˆ andwedonotneedareverseprocessforthela-
0
q(z z )=Cat z ;p=Q z =(1 γ )z +γ e ,
bel. Therefore,wedefineourgenerationprocesswiththe t | 0 t t 0 − t,c 0 t,c C+1
(13)
forwardprocessq(y 1:T |y 0)andtheintermediatey 1:T are whereγ = 1(cid:0) t (1 β )denotestheprobability(cid:1)
obtainedfromy 0withoutanyneuralnetworkevaluations. t,c − i=1 − i,c
thatasemanticlabelchasbeenassignedtotheabsorbing
(cid:81)
stateuntiltimesteptande istheone-hotcolumnvector
4.2.LabelDiffusion C+1
where(C+1)-thentryis1.Utilizingγ notonlysimplifies
t,c
WeintroduceourLabelDiffusion,anewdiscretediffusion theimplementationofthetransitionkernelbutalsoreduces
withlabelmaskingandclass-wisenoisescheduling. memory consumption in the generation process. The en-
4
)T,Ty,Tx(✓✏>tixetal/<xBKrMNQ/+Knxh7JaQPrq/V/8Le+ZOffn/MQ8fnQ/pzwALi3+PcGnbJQ8PvQdZo7/zC7uhrH6v01wDerupMPwytlm+XTu38hZwOtN/EPstm+ubpiaXfm3y1qjkw7Y+wA5UoTaVtW3Nz8Vtlac4qrpyIspxGUr+K4YFlanflnnud5elEzqlsixj6/MuZuny678vF2st+6GcN9mScVmJnqNuUZJ+KxUMXXWZN+eMida7k7z+tQ2EMDJzWTtKQMfL1IlJuSkcNVuF8BABlT8QBiTmMoICFJqELXGCDzvbjsONfwVv5JBSghXuD439ob9ed/1Ccv9uDhX47O3yBPeMGPzs7BM9Tc0nGqUNymWV2zIEWiSLSye7FXq0wCVNx08KqZeK8MQZXuSLnCd+ZyNLK6jiEFpSRJX5NRpqxRmRJDVIN+yJzz4Og1yvqywTn8+Gpv2qHf5oVfupFHcwnXw79vvSrKJU92eZy595y8+l5Y1FpdkBnZw/BwfQ8S4sNg8Yf4Yw+TxRVxxw+LVmN5uaoimVSLlLyiNKsMJc3llVJVpRZhNLBwjl2At10DFANtbLHVjci37CAAA>"=krZAUvGViiUyFsz9e0DQTzkFuev"=46esab_1ahs
tixetal<
)3,3y,3x(✓✏>tixetal/<=4AoK813Lz5s8Xlm0wi6T+Pfmnf1zP65PYMuXVQ/pzQXPi3WfcGnr3QYeZh6zYn1OL8HFeOo8ej9N4N6n+cAJ72ax1ay4ufNGmZs/uhCevZtyaar2135qgt4LZ8Eg7cQDZalV5v7uJ2uttUjFXdMWWRNK2AbMMhGtwk6/bee62H7UaMrU+qGPifz7qpeCv/y9aoz2ybbz5EbJ51ZmYKvdpyS8RypYqusza89ZAL13Jnn8fmsIYWSmtmaFxI+XuRKScFI4escK4DAEOn4gCEnNZARFOSUIS+EEK2f3uZta6grfzDCkATz9Ggv6ff7X7LuZA7YwJ49Hb3430Nxn5ob7j703PhReWoS+EraURvjQUpKsE522PuUohFqam5pVgj8V4pnZXuSL7Cc+ZyOnRkHENKSliCsyfiSUnjMiSGqRe4lSmnxcE7leV1+XWZ7LfRpznd80VPp8rnPe8AOt839aXFRK247zNjn3nznsFb0C0OSqbmevA+D1H1flC7DLX3V119D6Toax0+VhnRCbqBKiAUEqskpBLRymYyyq0qEou4GyqsEWS5r42DFAttTLHVjci37CAAA>"=8P8R/dWQUBqvxt+0Flpj0G+TtXa"=46esab_1ahs
tixetal<
)2,2y,2x(✓✏>tixetal/<=sAoXfVA/+KnzyfdaSDzqPZ/5a85X48V443Oh77M7PN6HaR827xz4YbJgzWBqPTQ+bvwvX46gybdcgRfR7knDIJ3LHfrJj7+1YYm0+fjF+WTan9UWtrPTXJbxVy45A/ZgE60Kp6/3dTMdZbpGLu6YusCaWsB2uHCGv4U6E78009P7bSMrWyKGPq/T4m5earvy/RYz26rbw10bKxVZmcq24Sll4rETxcdZl147xI2ttDuv43SZTwMkMbN1Khw8tUjUm4KTy1M5WwHAUUOxDFIOZygiIUkoSsc5AMMufLm1ppNu+NPIQCMd3dA+uXdpv93c1w2ZjdQ71+qh1enEfii6NPsjf/IH5RhIVTsqhF9OARlqwSgra9wShGWpqRmXUBLyThn9yu8lWGk/9RiNKP6jjMlpRRpU4JRpr1+mQFTVKBJyL/T40vlysuyoKu/6Ztu2mnXaxFWftZndyjnx95vfnWVSoyN9ysz7xt59JrxUtQtjkamo/r2PIeB+vNdP0esOsuufUPCVHH7vIsMTYDNQREg1oySmieihZiDLrCqkMiV2sULh0U542DFAttTLHVjci37CAAA>"=wyeI3meCyixgM5OqHn7SZLUkzLV"=46esab_1ahs
tixetal<
)1,1y,1x(✓✏>tixetal/<=gAokCFAv/TOoBvVoV9Mq23xnfnzvxpz2x/aFi/rvfEosfGxYvLPlj1tDi38UbWrN3uhufhjCO/WYTz+imJPHUSuta8tmMO7WrhZGzPbronbWrsm1mN9cu6YJ+SGPOYOF4gmVF09zNXFbrGXu5SqMCbqsC1ahFLDoV7Mr+fmmk+fZHRjZliX18x8bcHN1X69UufDd2GeabOnYLJvO30R4pLVWifSPFT1ldWjuPTYw6e49k/TkBBzSys1UvgCizFbkmEXSGeHIjC+CEyzKGoAxRTGSQRjGNSkO6zg67tTWjm27yH8gA5wWTnB6n+2pevv46Rs2ibQ71+qBtfwEfsgxBfQL2dDUoXF/oWxpOy1YLEVoKr+foVDJFqYoqGZcS1oIzlevMryVaJX/zXT360jcnoRRqUUBRuTVeqslRUyRJyDvQy8Lm9Yuwrq3bpl3+lFve5iCnv/uZHbz3zMU++/9VKVIhavv3dV7d9VsZrkBCWkjXXQuBA3i2SysF4csJK77GC3CFzG29R4pdopa3oBkEAlCmlNIYZGYuJLKSCSjuyGyAsMSIUAMwCFAxtTLFVjci37CAAA>"=gRIRDRgzXTOW25ANw07b+igakqj"=46esab_1ahs
tixetal<StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
tiretrajectoryy y canbeefficientlyrepresentedwitha =E ϵ ϵ (√α x +√1 α ϵ,y ,t) 2 ,
singleRH W m1 a:T tr| ix0 . Formoredetails,seeAppendixC.4. Lsimple t,x0,yt,ϵ || − θ t 0 − t t (1|| 82 )
×
(cid:2) (cid:3)
=D (p (x x ,y ) q(x x ,x )), (19)
vlb KL θ t 1 t t t 1 t 0
4.2.2.NOISESCHEDULING L − | || − |
where α determines the noise level for input image x at
t
Weobservethatthesemanticinformationofsmallobjects timestep t, ϵ (0,I) is a Gaussian noise, and λ is a
∼ N
inanimageispronetobelostatarelativelyearlystageof balancing hyperparameter. This is similar to the hybrid
diffusioncomparedtolargerobjects. Moreover,forarare loss(Nichol&Dhariwal,2021),withaslightadaptationof
classofobjectsinthedataset,itwouldbehardtolearntheir usingy t. SeeAppendixA.1foradetailedderivationofthe
semanticsiftheirlabelsaremaskedquickly. Thus,wepro- objectivefunction.
poseaclass-wisenoisescheduletodifferentiallytransform
To generate a sample, by the definition of the generation
semanticlabelsdependingontheclass. Wedesignedγ to
t,c process,wefirstsampley fromthesemanticmapy and
1:T 0
ensurethatlabelsoccupyingsmallerareasandrarelyappear-
feeditsequentiallytotheprocess. Inaddition,weformulate
inginthedatasetaretransitionedintotheabsorbingstate
theclassifier-freeguidance(Ho&Salimans,2021)inour
moreslowlyandatalatertime. Theclass-wiseschedule
model:
improvesgenerationqualityforsmallandrareobjects. For
moredetails,seeSection6.2andAppendixF.4. ϵ˜ (x y )=ϵ (x y )+s(ϵ (x y ) ϵ (x )), (20)
θ t t θ t t θ t t θ t
| | | − |∅
Foragivenclassc,weintroduceψ casdefinedinEq.(15) wheresistheguidancescale. Thisissimilartoalineof
andϕ cinEq.(16). Thesetermstakeintoaccountthearea works (Nichol et al., 2022; Rombach et al., 2022; Wang
( object size) andfrequency ofthe class c, respectively, et al., 2022b) adopting the guidance, but we use the per-
≈
fornoisescheduling. Weestimatedψ andϕwithtraining turbedlabelsy byourdiscreteforwardprocessinsteadof
t
data. Usingψandϕ,wedefineγ t,cfortheclass-wisenoise thecleanandfixedlabely 0forallsteps.
scheduleas:
γ :=
(ψ cϕ c)η Tt −1
, (14) Extrapolation. Inspired by (Lu et al., 2022), we give
t,c (ψ cϕ c)η −1 additional guidance in x
0
space, as opposed to directly
ψ c =E x ∈Xc Pr(y ij =c |x) −1 , (15) Tsa hm isp vl ain lug ex ist −th1 e. nW exe trfi ar ps ot lac to em dp fru ot me x th( 0 et) pt rh er co eu dg inh gϵ˜ tθ im(x et -| sy tet p).
(cid:104) (cid:105)
ϕ
c
=log Pr(x ∈Xc) −1 , (16) prediction,x˜( 0t+1),usingtheformula:
(cid:16) (cid:17)
where cisthesetofimagescontainingclassc,y ij isthe x˜(t) =x(t)+w x(t) x˜(t+1) , (21)
classlaX belofthesemanticmapyat(i,j),andηisahyper- 0 0 0 − 0
(cid:16) (cid:17)
parameter. Thisproperlyslowsdownthelabeldiffusionof wheretheconstantextrapolationscaleisdenotedbyw. Fol-
smallandrareobjects. Weprovideavisualaidforγ t,cwith lowingextrapolation,weapplydynamicthresholding(Sa-
differentψ cϕ cvaluesinAppendixD. hariaetal.,2022)andsubsequentlyrandomlysamplex
t 1
Proposition1. Forγ t,cinEq.(14)withψ cϕ c >1forallc utilizingx t andx˜( 0t). Thecompletetrainingandsamplin− g
andt<T, algorithmisinAppendixB.
t
limγ = and lim γ =0.
η 0 t,c T η t,c 4.4.Discussion
→ →∞
Interestingly,ourclass-wiseschedulegeneralizesthelinear Weheretheoreticallyanalyzethegenerativeprocessesof
anduniformschedule,andnoLabelDiffusion. Asη 0, SCDMtodiscussaninterestingrelationshipwiththefixed
theclass-wisescheduledefinedin(14)convergestoali→ near conditional diffusion model (baseline). SCDM approxi-
anduniformnoiseschedule,i.e., t.Labelsacrossallclasses matesthefollowingconditionalscore:
T
havethesameprobabilitytobemasked,andthemarginal
logq(x y )= logq(x )+ logq(y x ),
probability (13) linearly increases. This schedule is the ∇xt t | t ∇xt t ∇xt t | t
(22)
sameastheoneleveragedinabsorbing-stateD3PM(Austin
whilethebaselineapproximatesthefollowing:
et al., 2021). Also, as η , the masking probability
→ ∞
approacheszero. Formally,thispropertyissummarizedin logq(x y )= logq(x )+ logq(y x ).
∇xt t
|
0 ∇xt t ∇xt 0
|
t
Proposition1,anditsproofisprovidedinAppendixA.2. (23)
As the unconditional score logq(x ) is identical for
∇xt t
4.3.TrainingandSampling both models, we analyze the relationship between class
guidance(gradientsofimplicitclassifiers(Ho&Salimans,
Wetrainournetworkwiththefollowinglossfunction:
2021;Dhariwal&Nichol,2021)),i.e., logq(y x )and
∇xt t
|
t
= +λ , (17) logq(y x )inthefollowingproposition.
L
Lsimple Lvlb ∇xt 0
|
t
5StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Proposition2. Supposethereexistsadifferentiablefunc-
Table1. SISwithnoisylabels.FisFIDandlowerisbetter.Mis
tion f such that q(yi x ) = Cat(yi;p = f (x ))
and yi 01 |x t,...,y 0H ×W |x0 t| at re independe0 nt, wherei i t
∈
m anI doU thean od thh ei rg sh ae rr eis Gb Ae Ntte -r b. aT seh de mbo et tt ho om dsth .r Te he ero bw ess ta rr ee suD ltM sa-b ma ose nd g,
1,...,H W denotes the index of a pixel in semantic
thediffusion-basedapproachesareboldfaced,andthebestresults
{
map
and×
y 0i
∈}RC+1
is a one-hot vector. With q(y ti |y 0i) overallareunderlined.
fromEq.(13)andγ = γ foranyc,wehavethefollow-
t,c t
ingrelationship; DS Edge Random
Category Methods
F( ) M( ) F( ) M( ) F( ) M( )
E [ logq(y x )]=(1 γ ) logq(y x ). ↓ ↑ ↓ ↑ ↓ ↑
q(yt|y0) ∇xt t | t − t ∇xt 0 | t SPADE 36.6 41.0 40.2 39.7 92.7 18.5
CC-FPSE 42.0 40.4 38.7 41.7 141.3 16.2
TheproofisavailableinAppendixF.5. Proposition2im- DAGAN 37.6 41.3 42.2 39.0 109.1 16.4
pliesthattheexpectationofimplicitclassifiergradientsin GroupDNet 45.9 28.9 49.9 28.0 76.0 21.2
GAN
OASIS 34.5 48.1 37.6 47.4 54.2 42.1
ourmethodoverallpossibley giveny isequivalentto
t 0
CLADE 37.4 41.8 41.9 40.1 71.8 29.9
logq(y x ) after time-dependent scaling. First, the
∇xt 0 | t INADE 36.1 38.3 40.3 35.6 61.3 30.2
scaling factor (1 γ ) starts from 0 when t = T and is
t SCGAN 38.1 44.0 63.9 43.3 40.9 38.6
−
setto1whent = 0. Inotherwords,ourmethodactslike SAFM* 36.7 50.1 40.0 44.9 80.6 34.1
anunconditionalgenerationatthebeginningofthereverse
SDM 35.5 43.8 39.4 39.4 141.9 11.8
processandgetsstrongerguidanceastgoesto0. Second,
DM LDM 38.9 28.1 39.5 26.0 36.3 27.1
theexpectationoftheclassifiergradientinourmethodis Ours 32.4 44.7 31.2 40.1 28.1 45.2
thesamedirectionastheoneinthebaselinewithfixedclass
labels. Notethatthisdoesnotmeanthatourmethodhasthe
sameguidanceasthebaselinewithfixedlabelsandtime-
(e.g., CelebAMask-HQ (Lee et al., 2020) and COCO-
dependentscaling. Formorediscussion,seeAppendixF.5.
Stuff(Caesaretal.,2018))areinAppendixF.
5.Experiments
5.1.NoisySISbenchmark 5.2.ExperimentalSetup
We evaluate our method on ADE20K (Zhou et al., 2017) WeadoptFre´chetInceptionDistance(FID)(Heuseletal.,
dataset. ADE20K contains 20K images for training and 2017)toevaluategenerationqualityandmeanIntersection-
2K images for test annotated with 151 classes including over-Union(mIoU)toassessthealignmentofthesynthesis
the‘unlabeled’class. Additionally,weintroducethreenew resultswithgroundtruthsemanticmaps. Wecompareour
experimentalsetupstoassessgenerationperformanceunder modelwithGAN-basedmethodsandDM-basedmethods.
noisyconditionsusingtheADE20Kdatasetasfollows: Allthebaselinesandoursaretrainedwithcleanbenchmark
datasets,andtestedonthenoisySISbenchmark.Wepresent
[DS]Thissetupemploysdownsampledsemanticmapsthat
our results on noisy labels sampled over 25 steps in Sec-
are resized by nearest-neighbor interpolation. This setup
tion5.3.Moreinformationonbaselinesandimplementation
simulateshumanerrorssuchasjaggededgesandcoarse/low-
detailsareprovidedinAppendixC.2andC.3,respectively.
resolutionuserinputs. Wedownsamplethesemanticmaps
to 64 64 and then upsample them to 256 256. Conse-
× × 5.3.SISwithNoisyLabels
quently,thelabelmapscontainjaggededges.
Table1showstheperformancesofourmethodandbaselines
[Edge] This setup masks the edges of instances with an
underthethreesettings. SCDMdemonstratesitssuperior
unlabeledclass. Thissetupimitatesincompleteannotations
robustnesstoallthreetypesofnoiseingenerationquality
aroundedges,especiallybetweeninstances. Weobserved
measured by FID, compared to other baselines. Notably,
thathumanannotatorsoccasionallyleavethepixelsonthe
inthethreesetups,theperformancegapsbetweenthebest
boundariesofinstancesas‘unlabeled’duetotheirinherent
baseline scores and our method are +2.1, +6.4, and +8.2,
ambiguity,seeAppendixEforexamples. Assumingapixel
respectively. Wealsoevaluatethesemanticcorrespondence
withadifferentclasscomparedtoitsneighboristheedge
betweenthecleanground-truthlabelmapsandthegenera-
oftheinstance,wedetectedgesusingthelabelmap. Then,
tionresultsandreportmIoUscores. Ourmethodachieved
wefillthesemanticmappixelswithadistanceof2orless
the best mIoU performance among DM-based models in
fromtheedgeswiththeunlabeledclass.
all three settings. Compared to strong GAN-based base-
[Random]Thissetuprandomlyaddsanunlabeledclassto lines,includingSAFM(Lvetal.,2022)thatleveragesextra
thesemanticmaps(10%). Thissetupmimicsunintended ground truth instance maps during sampling, our results
usererrorsandextremerandomnoise. showcomparableresultsincorrespondence.
Moreexperimentalresultswithotherbenchmarkdatasets WepresentthequalitativecomparisonsinFigure3. While
6StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label Baseline Ours
(a)
Label OASIS SAFM SDM LDM Ours
(a) Maskswithjaggededges(DS)
(b)
(c)
Label OASIS SAFM SDM LDM Ours
(b) Incompletemasks(Edge),limegreenareasdenote‘unlabeled’.
(d)
Figure4.GenerationresultswithandwithoutLabelDiffusion.
Label OASIS SAFM SDM LDM Ours
Theresultsaresampledwiththefixedrandomseedsandsame
(c) Corruptedmasks(Random) x T,andgeneratedwith(a)cleanlabels,(b)DS,(c)Edge,and(d)
Randomsetupnoisylabels,respectively.
Figure3. Generationresultsonnoisylabels.
6.1.1.DOESSCDMSUCCESSFULLYESTIMATEq(X Y)?
thebaselinessynthesizedthejaggedorunnaturalcribim- |
agesgiventhelow-resolutionsemanticlabel,oursproduced TheeffectoftwocomponentsofSCDM(LabelDiffusion
clean edges and generated a realistic image, as shown in andextrapolation)isanalyzedbyanablationstudyinTa-
Figure3(a). InFigure3(b),ourapproachnaturallyfillsin ble2. Inthisanalysis,weadoptLPIPS(Zhangetal.,2018)
theunlabelededgeareas,whereasthebaselinesfailtogen- toadditionallycomparethegenerationdiversityandmea-
eraterealisticimages,especiallyonthe‘unlabeled’edges. sure the average distance between multi-modal synthesis
AsshowninFigure3(c),ourssuccessfullygenerateswhen results. Wecomparethefollowing;(a)Basegeneratesim-
conditionedonrandomlycorruptedmasks,whileothersfail ages conditioned on original fixed semantic maps y 0, (b)
andsynthesizeartifacts. +LabelDiffusiongeneratesimagesconditionedonperturbed
labelsbyourLabelDiffusion,and(c)+Extrapolationuses
6.Analysis Eq. (21) instead of direct sampling of x on top of (b).
t 1
Theresultsarereportedforthefew-step(−25,50,100,and
In this section, we analyze our method to understand (1) 250steps)andthefull-step(1000steps)settings.
theefficacyofLabeldiffusionandextrapolationand(2)the
Byeliminatingallofourcomponents, (c) (a), theper-
effectoftheclass-wisenoiseschedule.
→
formanceofallthreemetricssignificantlydeclinedforall
sampling steps. This empirically shows that our SCDM
6.1.AblationStudy
successfullyestimatestheconditionaldistributionq(X Y).
|
To further demonstrate SCDM’s enhanced robustness The degradation became more substantial when omitting
againstnoisylabels,wefirstshowtheeffectofourcompo- extrapolation, (b) (a), in fewer steps, highlighting its
→
nentsintheoriginal(clean)benchmark. Subsequently,we significanceinthefew-stepgeneration. Surprisingly,full
showthatoursamplesgeneratedwithnoisylabelsclosely SCDM(c)withonly25steps(FIDof27.7)outperformsthe
resembletheresultsobtainedwithcleanlabels,supporting baseline(a)with1000steps(FIDof28.1). Thissupports
ourmotivationinFigure1. theeffectivenessoftheproposedmethod.
7StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Table2. AblationstudyonADE20K.ForFID(F),lowerisbetter.ForLPIPS(L)andmIoU(M),higherisbetter.
25steps 50steps 100steps 250steps 1000steps
Method
F( ) L( ) M( ) F( ) L( ) M( ) F( ) L( ) M( ) F( ) L( ) M( ) F( ) L( ) M( )
↓ ↑ ↑ ↓ ↑ ↑ ↓ ↑ ↑ ↓ ↑ ↑ ↓ ↑ ↑
(a) Base 44.6 0.471 33.8 35.8 0.489 47.1 31.9 0.500 48.2 29.3 0.506 48.6 28.1 0.508 48.6
(b) +LabelDiffusion 39.5 0.492 45.5 33.6 0.513 47.3 29.8 0.522 48.6 27.7 0.528 48.7 26.9 0.530 48.8
(c) +Extrapolation 27.7 0.518 48.7 27.0 0.525 48.7 26.7 0.522 49.8 26.7 0.530 49.6 26.8 0.531 49.9
Table3.AblationstudyonnoisySIS.Generationresultswithand Table4.mIoU per each group on ADE20K. The classes are
withoutLabelDiffusionarecompared,wheresamplesgenerated groupedbasedontheirψ ϕ scores.
c c
fromeachnoisydatasetarecomparedwiththosefromtheclean
NoiseSchedule All Frequent Common Rare
dataset.ForLPIPSandFID,lowerisbetter.ForSSIMandPSNR,
higherisbetter. Linear&uniform 43.0 56.1 40.8 32.2
Class-wise 49.4(+6.4) 60.3(+4.2) 47.7(+6.9) 38.4(+8.1)
Metric
Dataset Method
LPIPS( ) SSIM( ) PSNR( ) FID( )
↓ ↑ ↑ ↓
Baseline 0.221 0.823 30.4 24.2
DS LabelDiffusionisemployed(OursinFigure4).
Ours 0.180 0.865 31.3 19.0
Baseline 0.248 0.771 29.7 32.7 6.2.EffectofClass-wiseNoiseSchedule
Edge
Ours 0.223 0.825 30.2 20.0
In this section, we elucidate the effect of our class-wise
Baseline 0.560 0.427 28.1 145.6
Random noiseschedulebycomparingthegenerationresultsoftwo
Ours 0.076 0.944 32.9 10.0
differentmodelsusingtheclass-wisescheduleandlinear
and uniform schedule, i.e., η 0. We observe that the
→
6.1.2.DOESLABELDIFFUSIONCONTRIBUTETO class-wisescheduleclearlyimprovestheimagequality,es-
ROBUSTNESS? pecially in terms of semantic correspondence (mIoU ( )
↑
of49.4(class-wise)>43.0(uniform)onADE20K).The
Furthermore,weexaminetheeffectofLabelDiffusionin
quantitativeandqualitativeresultsarepresentedintheAp-
thenoisySISsettingtoverifytherobustnessofourmethod,
pendixF.4. Furthermore,theclass-wisescheduleexhibits
asdepictedinFigure1.Specifically,wedemonstratethatthe
superiorityinsmallandrareclasssynthesis. Byorganizing
generationresultsgivencleanandnoisylabelsaresimilar.
theclassesintothreegroups-frequent,common,andrare
Torigorouslyanalyzetheeffects,wefixtherandomseeds
-basedontheirψ ϕ scores, wecomparemIoUpereach
and use the same x . Then we compare the generation c c
T grouponADE20KandreporttheperformanceinTable4.
resultsofourmethodandthebaseline,conditionedonclean
Notably,ourclass-wisescheduleexhibitedmIoUgaininall
(originaldataset)semanticmapswithresultsofnoisy(DS,
thegroups,withthehighestperformanceimprovementof
Edge, and Random) semantic maps, respectively. For a
+8.1intheraregroup.
quantitative comparison, we adopt the following metrics:
LPIPS(perceptualsimilarity),SSIM(structuralsimilarity),
7.Conclusion
PSNR(peaksignal-to-noiseratio),andFID,anddetailsare
inAppendixC.1. LPIPS,SSIM,andPSNRarecalculated
Inthispaper,weintroduceanovelandrobustconditional
sample-wise,comparingeachpairofgeneratedsamplesof
diffusionmodel,SCDM,forsemanticimagesynthesis. The
thecleanandnoisysemanticmaps,whileFIDcomparesthe
discrete diffusion for labels, which we name Label Dif-
distributionofthegeneratedsetofimages.
fusion, is designed with label masking. Label Diffusion
ResultsinTable3indicatethatLabelDiffusionsignificantly ensures that the intermediate labels along the generation
contributestorobustgeneration,withoursamplesexhibit- processbecomesimilarandeventuallyidenticalatt = T.
ingbettersimilarityinallfourmetrics. Particularly, ours Additionally, the class-wise noise schedule improves the
resultedin+0.041,+0.025,and+0.484ofLPIPSgainover generationqualityforsmallandrareobjects. Wedefinethe
baseline in DS, Edge, and Random settings, respectively. generationprocesswithadiscreteforwardprocessoflabels
Figure4presentsaqualitativecomparisonsupportingour andacontinuousreverseprocessofimages,asthelabelsare
intuition behind SCDM. Without Label Diffusion (Base- giveninSIS.SCDMdemonstratesitsrobustnessinnoisy
lineinFigure4),thegeneratedresultsshowinconsistency, SISsetupswhichwedesignedtosimulatehumanerrorsin
whereassamplesconformtotheresultofcleanlabelswhen real-worldapplications.
8StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
BroaderImpact Isola,P.,Zhu,J.-Y.,Zhou,T.,andEfros,A.A. Image-to-
imagetranslationwithconditionaladversarialnetworks.
Thispaperfocusesonrobustgenerationagainstnoisyuser
InCVPR,2017.
input,whichisacrucialaspecttoregardinreal-worldap-
plications. Asthecleanlabelsandthebenchmarkdataset Lee,C.-H.,Liu,Z.,Wu,L.,andLuo,P. Maskgan: Towards
intrinsicallycontainbiases,ourmodelmightreinforcethebi- diverse and interactive facial image manipulation. In
aseswhenthesamplesfromourmodelareusedprevalently CVPR,2020.
throughouttheInternet. Nevertheless,ourresearchopens
Liu, X., Yin, G., Shao, J., Wang, X., et al. Learning to
upnewavenuesforfutureworksinimagegenerationfor
predictlayout-to-imageconditionalconvolutionsforse-
real-worldproblems,potentiallyexpandingtheapplication
manticimagesynthesis. InNeurIPS,2019.
ofdiffusionmodelsinpracticalscenarios.
Loshchilov,I.andHutter,F. Decoupledweightdecayregu-
References larization. InICLR,2019.
Austin,J.,Johnson,D.D.,Ho,J.,Tarlow,D.,andvanden Lu,C.,Zhou,Y.,Bao,F.,Chen,J.,Li,C.,andZhu,J. Dpm-
Berg,R.Structureddenoisingdiffusionmodelsindiscrete solver++: Fastsolverforguidedsamplingofdiffusion
state-spaces. InNeurIPS,2021. probabilisticmodels. arXivpreprintarXiv:2211.01095,
2022.
Caesar,H.,Uijlings,J.,andFerrari,V. Coco-stuff: Thing
andstuffclassesincontext. InCVPR,2018. Lv,Z.,Li,X.,Niu,Z.,Cao,B.,andZuo,W.Semantic-shape
adaptivefeaturemodulationforsemanticimagesynthesis.
Chen,L.-C.,Papandreou,G.,Kokkinos,I.,Murphy,K.,and InCVPR,2022.
Yuille, A. L. Semantic image segmentation with deep
Mirza,M.andOsindero,S. Conditionalgenerativeadver-
convolutional nets and fully connected crfs. In ICLR,
sarialnets. arXivpreprintarXiv:1411.1784,2014.
2015.
Nichol,A.,Dhariwal,P.,Ramesh,A.,Shyam,P.,Mishkin,
Chen,Q.andKoltun,V. Photographicimagesynthesiswith
P.,McGrew,B.,Sutskever,I.,andChen,M. Glide: To-
cascadedrefinementnetworks. InICCV,2017.
wardsphotorealisticimagegenerationandeditingwith
Chen,Z.,Duan,Y.,Wang,W.,He,J.,Lu,T.,Dai,J.,and text-guideddiffusionmodels. InICML,2022.
Qiao,Y. Visiontransformeradapterfordensepredictions.
Nichol,A.Q.andDhariwal,P.Improveddenoisingdiffusion
arXivpreprintarXiv:2205.08534,2022.
probabilisticmodels. InICML,2021.
Couairon, G., Verbeek, J., Schwenk, H., and Cord, M.
Ntavelis, E., Romero, A., Kastanis, I., Gool, L. V., and
Diffedit: Diffusion-based semantic image editing with
Timofte, R. SESAME: semantic editing of scenes by
maskguidance. InICLR,2023.
adding,manipulatingorerasingobjects. InECCV,2020.
Dhariwal,P.andNichol,A. Diffusionmodelsbeatganson Park,T.,Liu,M.-Y.,Wang,T.-C.,andZhu,J.-Y. Semantic
imagesynthesis. NeurIPS,2021. imagesynthesiswithspatially-adaptivenormalization. In
CVPR,2019.
Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B.,
Warde-Farley,D.,Ozair,S.,Courville,A.C.,andBengio, Ramesh,A.,Pavlov,M.,Goh,G.,Gray,S.,Voss,C.,Rad-
Y. Generativeadversarialnets. InNeurIPS,2014. ford,A.,Chen,M.,andSutskever,I. Zero-shottext-to-
imagegeneration. InICML,2021.
Heusel,M.,Ramsauer,H.,Unterthiner,T.,Nessler,B.,and
Hochreiter,S. Ganstrainedbyatwotime-scaleupdate Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and
ruleconverge toalocalnashequilibrium. In NeurIPS, Ommer,B. High-resolutionimagesynthesiswithlatent
2017. diffusionmodels. InCVPR,2022.
Ho,J.andSalimans,T. Classifier-freediffusionguidance. Ronneberger,O.,Fischer,P.,andBrox,T. U-net: Convolu-
InNeurIPSW,2021. tionalnetworksforbiomedicalimagesegmentation. In
MICCAI,2015.
Ho,J.,Jain,A.,andAbbeel,P. Denoisingdiffusionproba-
Saharia,C.,Chan,W.,Saxena,S.,Li,L.,Whang,J.,Denton,
bilisticmodels. NeurIPS,2020.
E.L.,Ghasemipour,K.,GontijoLopes,R.,KaragolAyan,
Hoogeboom,E.,Nielsen,D.,Jaini,P.,Forre´,P.,andWelling, B.,Salimans,T.,etal. Photorealistictext-to-imagedif-
M. Argmaxflowsandmultinomialdiffusion: Learning fusion models with deep language understanding. In
categoricaldistributions. InNeurIPS,2021. NeurIPS,2022.
9StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Sasaki,H.,Willcocks,C.G.,andBreckon,T.P. Unit-ddpm: Wang,Y.,Qi,L.,Chen,Y.-C.,Zhang,X.,andJia,J. Image
Unpairedimagetranslationwithdenoisingdiffusionprob- synthesisviasemanticcomposition. InICCV,2021.
abilisticmodels. arXivpreprintarXiv:2104.05358,2021.
Wang, Z., Bovik, A. C., Sheikh, H. R., and Simoncelli,
Shi, Y., Liu, X., Wei, Y., Wu, Z., and Zuo, W. Retrieval- E.P. Imagequalityassessment: fromerrorvisibilityto
basedspatiallyadaptivenormalizationforsemanticimage structuralsimilarity. IEEETrans.ImageProcess.,2004.
synthesis. InCVPR,2022.
Xiao,T.,Liu,Y.,Zhou,B.,Jiang,Y.,andSun,J. Unified
perceptual parsing for scene understanding. In ECCV,
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and
2018.
Ganguli,S. Deepunsupervisedlearningusingnonequi-
libriumthermodynamics. InICML,2015.
Xue, H., Huang, Z., Sun, Q., Song, L., and Zhang, W.
Freestylelayout-to-imagesynthesis. InCVPR,2023.
Song,Y.,Sohl-Dickstein,J.,Kingma,D.P.,Kumar,A.,Er-
mon,S.,andPoole,B. Score-basedgenerativemodeling
Yang,D.,Hong,S.,Jang,Y.,Zhao,T.,andLee,H.Diversity-
throughstochasticdifferentialequations. InICLR,2021.
sensitiveconditionalgenerativeadversarialnetworks. In
ICLR,2019.
Sushko,V.,Scho¨nfeld,E.,Zhang,D.,Gall,J.,Schiele,B.,
andKhoreva,A. Youonlyneedadversarialsupervision Zhang,R.,Isola,P.,Efros,A.A.,Shechtman,E.,andWang,
forsemanticimagesynthesis. InICLR,2020. O. Theunreasonableeffectivenessofdeepfeaturesasa
perceptualmetric. InCVPR,2018.
Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A.
Inception-v4,inception-resnetandtheimpactofresidual Zhou,B.,Zhao,H.,Puig,X.,Fidler,S.,Barriuso,A.,and
connectionsonlearning. InAAAI,2017. Torralba,A. Sceneparsingthroughade20kdataset. In
CVPR,2017.
Tan,Z.,Chai,M.,Chen,D.,Liao,J.,Chu,Q.,Liu,B.,Hua,
G., and Yu, N. Diverse semantic image synthesis via Zhu,J.-Y.,Zhang,R.,Pathak,D.,Darrell,T.,Efros,A.A.,
probabilitydistributionmodeling. InCVPR,2021a. Wang,O.,andShechtman,E. Towardmultimodalimage-
to-imagetranslation. InNeurIPS,2017.
Tan,Z.,Chen,D.,Chu,Q.,Chai,M.,Liao,J.,He,M.,Yuan,
L.,Hua,G.,andYu,N.Efficientsemanticimagesynthesis Zhu, P., Abdal, R., Qin, Y., and Wonka, P. Sean: Image
viaclass-adaptivenormalization. TPAMI,2021b. synthesis with semantic region-adaptive normalization.
InCVPR,2020a.
Tang, H., Bai, S., and Sebe, N. Dual attention gans for
Zhu,Z.,Xu,Z.,You,A.,andBai,X. Semanticallymulti-
semanticimagesynthesis. InACMMM,2020a.
modalimagesynthesis. InCVPR,2020b.
Tang,H.,Xu,D.,Yan,Y.,Torr,P.H.,andSebe,N. Local
class-specificandglobalimage-levelgenerativeadversar-
ial networks for semantic-guided scene generation. In
CVPR,2020b.
Tang, H., Qi, X., Xu, D., Torr, P. H., and Sebe, N. Edge
guidedganswithsemanticpreservingforsemanticimage
synthesis. InICLR,2023.
Wang,T.,Zhang,T.,Zhang,B.,Ouyang,H.,Chen,D.,Chen,
Q., and Wen, F. Pretraining is all you need for image-
to-imagetranslation. arXivpreprintarXiv:2205.12952,
2022a.
Wang, T.-C., Liu, M.-Y., Zhu, J.-Y., Tao, A., Kautz, J.,
andCatanzaro,B. High-resolutionimagesynthesisand
semanticmanipulationwithconditionalgans. InCVPR,
2018.
Wang, W., Bao, J., Zhou, W., Chen, D., Chen, D., Yuan,
L., and Li, H. Semantic image synthesis via diffusion
models. arXivpreprintarXiv:2207.00050,2022b.
10StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Theappendixisorganizedintothefollowingsections.
• AppendixA:Derivations
– A.1VariationalLowerBoundforStochasticConditionalDiffusionModel
– A.2ProofofProposition1
– A.3ProofofProposition2
• AppendixB:Algorithms
• AppendixC:ExperimentalSetup
– C.1Metrics
– C.2Baselines
– C.3ImplementationDetails
– C.4EfficientTrajectoryRepresentation
• AppendixD:DetailedExplanationsonψ andϕ
c c
• AppendixE:ADE20KDatasetAnnotationExamples
• AppendixF:AdditionalExperimentalResults
– F.1StandardSISSetting
– F.2ExtrapolationHyperparameterSearch
– F.3VisualizationofLabelDiffusion
– F.4EffectofClass-wiseNoiseSchedule
– F.5FurtherDiscussionandAnalysisonClassGuidance
– F.6ValidationofSCDMGenerationProcess
– F.7MoreQualitativeResults-MultimodalGeneration
– F.8MoreQualitativeResults-SISwithNoisyLabels
– F.9MoreQualitativeResults-StandardSISSetting
A.Derivations
A.1.VariationalLowerBoundforStochasticConditionalDiffusionModel
Inthissection,weprovideadetailedderivationoftheobjectivefunction(Eq. (17))discussedinSection4.3ofthemain
paper. WestartbydefiningourStochasticConditionalDiffusionModelas:
p (x y ):= p (x ,y y )dx dy , (24)
θ 0 | 0 θ 0:T 1:T | 0 1:T 1:T
(cid:90) (cid:90)
wherethegenerationprocessisdefinedasfollows:
T
p (x ,y y ):=p(x )q(y y ) p (x x ,y ), (25)
θ 0:T 1:T 0 T 1:T 0 θ t 1 t t
| | − |
t=1
(cid:89)
p (x x ,y ):= (x ;µ (x ,y ,t),Σ (x ,y ,t)). (26)
θ t 1 t t t 1 θ t t θ t t
− | N −
ThediffusionforwardprocessinwhichSCDMapproximatesis:
T
q(x ,y x ,y ):= q(x ,y x ,y ), (27)
1:T 1:T 0 0 t t t 1 t 1
| | − −
t=1
(cid:89)
q(x ,y x ,y ):=q(x x )q(y y ). (28)
t t t 1 t 1 t t 1 t t 1
| − − | − | −
Variationalboundonnegativelog-likelihoodofSCDMcanbederivedasfollows:
11StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
E [ logp (x y )] (29)
q(x1:T,y1:T|x0,y0)
−
θ 0
|
0
p (x ,y y )
=E log θ 0:T 1:T | 0 (30)
q
− p (x ,y y )
(cid:20) θ 1:T 1:T | 0 (cid:21)
p (x ,y y )q(x ,y x ,y )
=E log θ 0:T 1:T | 0 1:T 1:T | 0 0 (31)
q
− p (x ,y y )q(x ,y x ,y )
(cid:20) θ 1:T 1:T | 0 1:T 1:T | 0 0 (cid:21)
p (x ,y y ) q(x ,y x ,y )
=E log θ 0:T 1:T | 0 1:T 1:T | 0 0 (32)
q
− q(x ,y x ,y ) p (x ,y y )
(cid:20) 1:T 1:T | 0 0 θ 1:T 1:T | 0 (cid:21)
p (x ,y y ) q(x ,y x ,y )
=E log θ 0:T 1:T | 0 +E log 1:T 1:T | 0 0 (33)
q q
− q(x ,y x ,y ) − p (x ,y y )
(cid:20) 1:T 1:T | 0 0 (cid:21) (cid:20) θ 1:T 1:T | 0 (cid:21)
p (x ,y y )
=E log θ 0:T 1:T | 0 D (q(x ,y x ,y ) p (x ,y y )) (34)
q KL 1:T 1:T 0 0 θ 1:T 1:T 0
− q(x ,y x ,y ) − | || |
(cid:20) 1:T 1:T | 0 0 (cid:21)
DKL≥0
p (x ,y y )
E log θ 0:T 1:T | 0 , (cid:124) (cid:123)(cid:122) (cid:125) (35)
q
≤ − q(x ,y x ,y )
(cid:20) 1:T 1:T | 0 0 (cid:21)
p (x ,y y )
E log θ 0:T 1:T | 0 (36)
q
− q(x ,y x ,y )
(cid:20) 1:T 1:T | 0 0 (cid:21)
p(x )q(y y ) T p (x x ,y )
=E q (cid:34)−log T T t=1: 1T q| (x0 t, (cid:81)y tt |= x1 t −1θ ,yt t− −1 1| ) t t (cid:35) (37)
=E q
(cid:34)−logp(x T)q(cid:81)(
T
ty
=1 1:T
q(|y
x0 t
|)
x (cid:81)t
−T
t 1= )1
qp (yθ( tx
|yt − t −1
1|x )t,y t)
(cid:35) (38)
=E q
(cid:34)−logp(x
T T
t) =(cid:81)q 1(y
q(1 x:T t|
|y
x0
t
−) 1(cid:81))T
t=1 T
t=p
1θ
q(x
(yt −
t
|1
y|x
t
−t, 1y )t)
(cid:35)
(39)
=E q (cid:34)−logp(x(cid:81)T) (cid:81)T t=T t= 11 qp (xθ( tx |xt −
t
−1(cid:81) 1|x )t,y t)
(cid:35)
(40)
T
(cid:81) p (x x ,y )
=E
q
logp(x T) log θ t −1 | t t =:L (41)
(cid:34)− − q(x t x t 1) (cid:35)
(cid:88)t=1 | −
Also,wecanderivethereducedvariancevariationalboundforSCDMasfollows:
T
p (x x ,y )
L=E
q
logp(x T) log θ t −1 | t t (42)
(cid:34)− − q(x t x t 1) (cid:35)
(cid:88)t=1 | −
T
p (x x ,y ) p (x x ,y )
=E
q
logp(x T) log θ t −1 | t t log θ 0 | 1 1 (43)
(cid:34)− − q(x t x t 1) − q(x 1 x 0) (cid:35)
(cid:88)t=2 | − |
T
p (x x ,y )q(x x ) p (x x ,y )
=E
q
logp(x T) log θ t −1 | t t t −1 | 0 log θ 0 | 1 1 (44)
(cid:34)− − q(x t 1 x t,x 0) q(x t x 0) − q(x 1 x 0) (cid:35)
(cid:88)t=2 − | | |
T
p(x ) p (x x ,y )
=E
q
log T log θ t −1 | t t logp θ(x
0
x 1,y 1) (45)
(cid:34)− q(x T x 0) − q(x t 1 x t,x 0) − | (cid:35)
| (cid:88)t=2 − |
T
=E D (q(x x ) p(x ))+ D (q(x x ,x ) p (x x ,y )) logp (x x ,y ) . (46)
q KL T 0 T KL t 1 t 0 θ t 1 t t θ 0 1 1
(cid:34) | || − | || − | − | (cid:35)
t=2
(cid:88)
12StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
The only difference between the typical bound of a conditional DM and our bound is the substitution of y for y in
0 t
p (x x ,y ). Therefore, we can use the DDPM simple loss ( ) (Ho et al., 2020) or the hybrid loss ( +
θ t 1 t t simple simple
λ
)−(N| ichol&Dhariwal,2021)fortrainingourStochasticCondiL
tionalDiffusionModel.
L
vlb
L
A.2.ProofofProposition1
WeprovidetheproofofProposition1,whichshowsthatourclass-wisenoiseschedulegeneralizesthelinearanduniform
scheduleandnoLabelDiffusion,i.e.,atypicalconditionalDMdescribedinSection3. Proposition1andthefollowing
proofholdundertwoassumptionsofψ ϕ >1forallcandt<T.
c c
Proposition1. Forγ inEq.(14)withψ ϕ >1forallcandt<T,
t,c c c
t
limγ = and lim γ =0.
t,c t,c
η 0 T η
→ →∞
Proof. First,whenηconvergesto0,thelinearanduniformnoiseschedulecanbederivedasfollows:
limγ = lim
(ψ cϕ c)η Tt −1
(47)
η →0 t,c η →0 (ψ cϕ c)η −1
= lim
(ψ cϕ c)η Tt −(ψ cϕ c)0 Tt
(48)
η →0 (ψ cϕ c)η −(ψ cϕ c)0
(ψcϕc)ηTt −(ψcϕc)0Tt
= lim η (49)
η →0 (ψcϕc)η − η(ψcϕc)0
= lim
ln(ψ cϕ c) Tt(ψ cϕ c)η Tt
(50)
η →0 ln(ψ cϕ c)(ψ cϕ c)η
t
= lim (ψ cϕ c)η( Tt −1) (51)
η 0T
→
t
= . (52)
T
Whenηexplodesto+ ,thenoiseschedulewithoutLabelDiffusioncanbederivedasfollows:
∞
lim γ = lim
(ψ cϕ c)η Tt −1
(53)
η →+
∞
t,c η →+
∞
(ψ cϕ c)η −1
= lim
(ψ cϕ c)η( Tt −1) −(ψ cϕ c) −η
(54)
η →+
∞
1 −(ψ cϕ c) −η
t
=0. ∵ 1<0 (55)
T −
Thesetwoderivationsshowthatourclass-wisenoiseschedulegeneralizespreviousworks. Althoughwesetη =1forour
experiments,differentηcanbesearchedandemployedforcontrollingthenoiseschedules,whichweleaveasfuturework.
A.3.ProofofProposition2
WeprovidetheproofofProposition2.
Proposition 2. Suppose there exists a differentiable function f such that q(yi x ) = Cat(yi;p = f (x )) and
y y01 i|x t R,. C.., +y 10H is× aW
o|
nx et -ha or te vi en cd toep r.e Wnd ite hnt q, (yw ih yer ie )i
fro∈ m{
E1 q, .. (. 1., 3H
)a×
ndW γ}i d =en γot fe os rt ah ne yi cn ,d0 w| ex et ho af va etp hi exe fl oli ln o0 wse inm ga rn et li aci tim ot na sp hia pn ;d
0 ∈ t| 0 t,c t
E [ logq(y x )]=(1 γ ) logq(y x ).
q(yt|y0) ∇xt t
|
t
−
t ∇xt 0
|
t
13StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Proof.
q(y
0
|x t)=q(y 01,y 02,...,y 0H ×W |x t) (56)
H W
×
= q(yi x ), (57)
0| t
i=1
(cid:89)
H W
×
logq(y x )= log q(yi x ) (58)
∇xt 0 | t ∇xt 0| t
i=1
(cid:89)
H W
×
= logq(yi x ). (59)
∇xt 0| t
i=1
(cid:88)
Sinceyi x areindependentandourLabelDiffusionforwardprocessisappliedtoeachpixelofy independently,yi x are
0| t 0 t| t
independent. Therefore,
q(y
t
|x t)=q(y t1,y t2,...,y tH ×W |x t) (60)
H W
×
= q(yi x ), (61)
t| t
i=1
(cid:89)
H W
×
logq(y x )= log q(yi x ) (62)
∇xt t | t ∇xt t| t
i=1
(cid:89)
H W
×
= logq(yi x ), (63)
∇xt t| t
i=1
(cid:88)
H W
E [ logq(y x )]= × E [ logq(yi x )] (64)
q(yt|y0) ∇xt t | t q(yt|y0) ∇xt t| t
i=1
(cid:88)
H W
= × E [ logq(yi x )] (65)
q(y ti |y0) ∇xt t| t
i=1
(cid:88)
H W
= × E [ logq(yi x )]. (66)
q(y ti |y 0i) ∇xt t| t
i=1
(cid:88)
Thus,ourproofcanbesubstitutedforprovingthefollowingstatement:
E [ logq(yi x )]=(1 γ ) logq(yi x ). (67)
q(y ti |y 0i) ∇xt t| t − t ∇xt 0| t
Withaslightabuseofnotation,weusey todenoteyi,y todenoteyi,andf(x )todenotef (x )fortherestoftheproof.
0 0 t t t i t
Then, logq(y x )canbederivedasfollows:
∇xt 0
|
t
q(y x )=yTf(x ), (68)
0 | t 0 t
1 ∂f(x )
logq(y x )= t y (69)
∇xt 0
|
t
q(y x ) ∂x
0
0 t t
|
1 ∂f(x )
= t y . (70)
yTf(x ) ∂x 0
0 t t
14StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Also, logq(y x )canbederivedasfollows:
∇xt t
|
t
q(y x )= q(y ,y x )= q(y y ,x )q(y x ) (71)
t t t 0 t t 0 t 0 t
| | | |
(cid:88)y0 (cid:88)y0
C+1
= q(y y )q(y x )= yTQ e eTf(x ) (72)
t | 0 0 | t t t c c t
(cid:88)y0 (cid:88)c=1
C+1
=yTQ ( e eT)f(x ) (73)
t t c c t
c=1
(cid:88)
=yTQ f(x ), (74)
t t t
logq(y x )=
1 ∂f(x t) QT
y (75)
∇xt t | t q(y x ) ∂x t t
t t t
|
=
1 ∂f(x t) QT
y . (76)
y tTQ tf(x t) ∂x t t t
Therefore,E [ logq(y x )]canbederivedasfollows:
q(yt|y0) ∇xt t
|
t
E [ logq(y x )]= q(y y ) 1 ∂f(x t) QT y (77)
q(yt|y0) ∇xt t | t (cid:88)yt t | 0 y tTQ tf(x t) ∂x t t t
=
∂f(x t)
q(y y )
1 QT
y (78)
∂x t (cid:88)yt t | 0 y tTQ tf(x t) t t
= ∂f(x t) yTQ y 1 QT y (79)
∂x t (cid:88)yt t t 0 y tTQ tf(x t) t t
= ∂f(x t) QT 1 y yTQ y (80)
∂x t (cid:88)yt t y tTQ tf(x t) t t t 0
= ∂f(x t) QT 1 y yT Q y (81)
∂x t t (cid:32) (cid:88)yt y tTQ tf(x t) t t (cid:33) t 0
C+1
= ∂f(x t) QT 1 e eT Q y (82)
∂x t t (cid:32)
c=1
eT cQ tf(x t) c c (cid:33) t 0
(cid:88)
=
∂f(x t) QT
DQ y , (83)
∂x t t 0
t
where D is a diagonal matrix. Since the class corresponding to the absorbing state, i.e., class C+1 does not exist in
the original dataset, we have q(y = e ) = 0 [f(x )] = 0. Therefore, [D] = ((1 γ )[f(x )] ) 1 when
0 C+1 t C+1 cc t t c −
c ̸=C+1,otherwise,γ t−1. Asy 0isaone-hotvecto⇔ r, −
∂f(x ) 1 1 γ
E [ logq(y x )]= t (1 γ ) y +γ (1+ − t e ) (84)
q(yt|y0) ∇xt t | t ∂x
t (cid:18)
− t y 0Tf(x t) 0 t γ
t
C+1
(cid:19)
1 ∂f(x ) ∂f(x ) 1 γ
=(1 γ ) t y +γ t (1+ − t e ) (85)
− t yTf(x ) ∂x 0 t ∂x γ C+1
0 t t t t
1 γ
=(1 γ ) logq(y x )+γ (1+ − t e )Tf(x ) (86)
−
t ∇xt 0
|
t t ∇xt
γ
C+1 t
t
=(1 γ ) logq(y x )+γ 1 (87)
−
t ∇xt 0
|
t t ∇xt
=(1 γ ) logq(y x ). (88)
−
t ∇xt 0
|
t
15StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
B.Algorithms
Algorithm1and2summarizethegeneraltrainingandsamplingprocessofourSCD,respectively. Whilemhastobe
e RC+1, we implemented the absorbing vector with a zero vector 0 RC to minimize the modification of the
C+1
∈ ∈
pretrainedSISmodel.
Algorithm1Training
Require: imagex RH W 3,labely RH W C,noisescheduleα ,γ ,absorbingvectorm RC
0 × × 0 × × 1:T 1:T
∈ ∈ ∈
1: whilenotconvergeddo
2: ϵ x (0,I) //ϵ x RH ×W ×3
3: i,j∼ [ϵ yN ] ij Uniform(0,1) { //ϵ∈ y RH ×W}
∀ ∼ { ∈ }
4: t Uniform( 1,...,T )
∼ { }
5: x t √α tx 0+√1 α tϵ x
← −
6: i,j[y t]
ij
[y 0]
ij
if[ϵ y]
ij
γ telsem
∀ ← ≥
7: Takeagradientdescentstepon hybrid(ϵ x,ϵ θ(x t,y t,t),Σ θ(x t,y t,t))
L
8: endwhile
Algorithm2Sampling
Require: labely RH W C, noisescheduleα ,γ ,
0 × × 1:T 1:T
guidancescale∈ s,absorbingvectorm RC,
∈
extrapolationscalew
1: x (0,I)
T
∼N
2: fort T,...,1do
3: i,j← [ϵ y] ij Uniform(0,1) //ϵ y RH ×W
∀ ∼ { ∈ }
4: i,j[y t]
ij
[y 0]
ij
if[ϵ y]
ij
γ telsem
5: ϵ∀ x (0← ,I)ift=1else0≥ //ϵ x RH ×W ×3
∼N ̸ { ∈ }
6: ϵ˜ ϵ (x ,y ,t)+s(ϵ (x ,y ,t) ϵ (x ,0,t)) //Classifier-freeguidance
θ θ t t θ t t θ t
← − { }
7: x( 0t)
←
xt−√ √1 α− tαtϵ˜θ {//Reparameterizeϵ-predmodeltopredictx 0
}
8: x(t) dynamic thresholding(x(t)) //Dynamicthresholding
0 ← 0 { }
9: x˜(t) x(t)+w x(t) x˜(t+1) ift=T elsex(t) //Extrapolation
0 ← 0 0 − 0 ̸ 0 { }
(cid:16) (cid:17)
1 10 1:
:
µ xt
t
=
1
√1 −1 µα tt
+(cid:16)
Σ√ θα (xt − t1 ,( y1 t,− t)α 21α t z−t 1)x˜( 0t) + (cid:113)αα t−t 1(1 −α t −1)x //t
S(cid:19)
amplex
t 1
12:
endf−or← { − }
13: Returnx
0
C.ExperimentalSetup
C.1.Metrics
C.1.1.EXPERIMENTSINSECTION6.1.1
FID(fidelity). Toquantitativelymeasuregenerationquality,weadoptFre´chetInceptionDistance(FID)(Heuseletal.,
2017)asourevaluationmetrics. FIDcapturestheimage’svisualqualitybycomparingthedistributionbetweenrealand
generatedimagesontheinceptionnetwork’s(Szegedyetal.,2017)featurespace.
mIoU(semanticcorrespondence). Additionally,followingpreviousworks,weassessthealignmentofthesynthesisresults
withgroundtruthsemanticmapsbyusingoff-the-shelfpretrainedsegmentationnetworksandreportmeanIntersection-over-
Union(mIoU).Wefeedthesampledimagestothepre-trained,off-the-shelfsemanticsegmentationnetworks: U-Net(Lee
etal.,2020;Ronnebergeretal.,2015)forCelebAMask-HQ,ViT-Adapter-S(Chenetal.,2022)withUperNet(Xiaoetal.,
2018)forADE20K,andDeepLabV2(Chenetal.,2015)forCOCO-Stuff. Forafaircomparison,wetriedtomeasureand
16StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
reproducethemIoUofallbaselinesamples. ForthestandardSISsetting,whensamplesorcheckpointswerenotpublicly
available,wereporttheresultsfrom(Tangetal.,2023)anddenotethemwith‘*’inthetable.
C.1.2.EXPERIMENTSINSECTIONF.1
LPIPS(diversity). InadditiontoFIDandmIoU,weadoptLearnedPerceptualImagePatchSimilarity(LPIPS)(Zhang
etal.,2018)asourgenerationdiversitymetricsinSectionF.1andcomparetheaveragedistancebetweenmulti-modal
synthesisresults. Specifically,following(Tanetal.,2021a),wesample10differentimagesforeachsemanticmap,compute
thepairwiseLPIPSdistance,andaverageoverthelabelmaps.
C.1.3.EXPERIMENTSINSECTION6.1.2
LPIPS. InSection6.1.2, weadoptLPIPStocomparesimilarity, asLPIPSessentiallymeasuresthesimilarityoftwo
differentimages. Therefore,lowerLPIPSisbetterinourexperimentalsetting. WecalculateLPIPSbycomparingimages
generatedwithcleanandnoisylabels,andaveragingtheresults.
PSNR. PeakSignal-to-NoiseRatio(PSNR)isametricthatevaluatesthereconstructionquality,i.e.,higherPSNRisbetter.
WecalculatePSNRbycomparingimagesgeneratedwithcleanandnoisylabels,andaveragingtheresults.
SSIM. StructuralSimilarityIndexMeasure(SSIM)(Wangetal.,2004)isametrictoevaluatethesimilarityofapairof
images,i.e.,higherSSIMisbetter. WecalculateSSIMbycomparingimagesgeneratedwithcleanandnoisylabels,and
averagingtheresults.
FID. InSection6.1.2,weuseFIDtocomparethedistributionbetweenthesetofgeneratedimagesconditionedonclean
labelsandthesetofgeneratedimagesconditionedonnoisylabels. Inourexperimentalsetting,lowerFIDindicatesthatthe
twodistributionsarecloser,whichisbetter.
C.2.Baselines
We compare our model with GAN-based methods such as pix2pixHD (Wang et al., 2018), SPADE (Park et al., 2019),
DAGAN (Tang et al., 2020a), SCGAN (Wang et al., 2021), CLADE (Tan et al., 2021b), CC-FPSE (Liu et al., 2019),
GroupDNet (Zhu et al., 2020b), INADE (Tan et al., 2021a), OASIS (Sushko et al., 2020), RESAIL (Shi et al., 2022),
SAFM(Lvetal.,2022),andECGAN(Tangetal.,2023). Wealsoevaluateourmethodwithdiffusion-basedapproaches,
SDM(Wangetal.,2022b),LDM(Rombachetal.,2022),andPITI(Wangetal.,2022a). AlthoughFLIS(Xueetal.,2023)
doestackleSISwithdiffusionmodels,theyutilizeextratextinputs(captions)withthesemanticmaps. Forafaircomparison,
wedidnotincludeFLISasabaseline.
As the pretrained weights of pix2pixHD and PITI on ADE20K are not publicly available, we excluded them from our
noisySISexperimentsonADE20K.Additionally,thepretrainedweightsandthefullcodeofRESAILandECGANarenot
availableinpublic,thereforewedidnotincludetheminournoisySISexperimentsbaselinesaswell.
ForthestandardSISsetting,wereportalltheresultsevaluatedwiththeuploadedsamplesorcheckpointsexceptwhen
theyareunavailable. ForPITI,astheCOCO-Stuffpretrainedweightswereonlyavailable,wesampledimageswiththe
weightsandreportedtheLPIPSandmIoUscores. ForCelebAMask-HQresultsofSDM,wereportthereproducedresults.
AlthoughLDMdidnotincludeSISexperimentsonbenchmarkdatasetsintheirofficialpaper,wetrainedtheirmodelwith
theirSIStrainingconfigurationsandreportedtheresultsinbothnoisyandstandardSISexperiments,formorecomparison
withDM-basedapproaches.
C.3.ImplementationDetails
We followed the overall architecture of SDM (Wang et al., 2022b), a diffusion model for semantic image synthesis.
Specifically,weembedtheconditionintotheU-NetdecoderwithSPADE(Parketal.,2019)andconstructedasimilar
U-Netstructure,wherethearchitecturedetailsarepubliclyavailableintheirGitHubrepository. SDMtrainedtheirmodel
withtwostages: (1)pre-trainedtheirconditionaldiffusionmodeland(2)fine-tunedthepre-trainedmodelbyrandomly
droppingoutthesemanticlabelmapsinordertouseclassifier-freeguidanceinsampling. WetrainedourSCDMstarting
fromtheirpre-trainedweightstoreducethetrainingtime. Wetrainedourmodelwith4NVIDIARTXA6000GPUsfor1-2
17StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
days. Imagesamplingandevaluationsareconductedonaserverwith8NVIDIARTX3090GPUs.
Forthehyperparameters,weusedλ=0.001forourhybridloss(Nichol&Dhariwal,2021),classifier-freeguidance(Ho&
Salimans,2021)scales=0.5,20%ofdropratefortheSISexperimentsonthreedatasets,noiseschedulehyperparameter
η =1,dynamicthresholding(Sahariaetal.,2022)percentileof0.95,andtheextrapolationscaleofw =0.8. Exceptfor
theablationstudy(inTable2),wedidn’tuseextrapolationforexperimentswith1000samplingsteps,asextrapolationis
designedtoenhancesmall-stepgeneration. Wealsoutilizedexponentialmovingaverage(EMA)with0.9999decay,and
AdamW(Loshchilov&Hutter,2019)optimizer. WeemployedinstancelabelsofCelebAMask-HQandCOCO-Stuffto
produceinstanceedgemapsandusedthemasadditionalinputfollowingSDM.
Furthermore,fortheclass-wisenoiseschedule,weclampedϕ tobeatleast1,todownthediffusionofrareclasseswithout
c
speedingupthetransitionoffrequentclasses. Wesettheclass-wisenoiseschedulesofthe‘unlabeled’classofADE20Kand
COCO-Stufftobetheuniformschedule,i.e.,γ =t/T forc=‘unlabeled’. Inaddition,weimplementedthecalculationof
t,c
γ usingt 1insteadoftinthecodetoensurethattheassumptionofLemma1issatisfied.
t,c
−
ForourexperimentsonADE20K,wemodifiedthecalculationofψ ϕ valuesoftheclass-wisenoiseschedulewithan
c c
empiricallychosenscalefactor. ThisisbecauseADE20Khasnumerousclassesandhighdiversityinthedatasetcompared
tothenumberoftrainingdata,whileCelebAMask-HQhasrelativelylowdiversityandCOCO-Stuffhasalargenumberof
trainingdata. Specifically,wemodifiedψ ϕ as:
c c
ψ ϕ :=λPr(y =c) 1log Pr(x ) 1 , (89)
c c ij − c −
∈X
(cid:0) (cid:1)
whereλisthescalefactor( 0.278)makingthesmallestvalueofψ ϕ convergeto1,i.e.,γ =t/T.
c c t,c
≈
C.4.EfficientTrajectoryRepresentation
ThegenerationprocessofSCDMutilizesy ,...,y ateachtimestept=T,...,1.Aswehavenotdefinedthereverseprocess
T 1
ofthelabels,weusethelabelforwardprocessq(y y ),whichsequentiallyconstructsy ,...,y fromy . Consequently,
1:T 0 1 T 0
|
y needstobecachedduringsamplinginordertobeaccessedfromt=T tot=1. However,thisresultsinasignificant
1:T
memoryconsumption,posingachallengetooursamplingprocess. Toaddressthisissue,weleverageγ fromEq(13).
t,c
Specifically,werepresenttheentiretrajectoryy withasinglematrixU RH W,whereU denotesthe‘timestep’
1:T × ij
∈
that(i,j)-thpixelismasked. Supposethat(i,j)-thpixelcorrespondstoclassc. Sinceγ canbeexpressedasastrictly
t,c
monotonicfunctionγ (t),wecaneasilysampleU usingtheinverseCDFmethodonγ 1(u),whereu Uniform(0,1).
c ij c−
∼
D.DetailedExplanationsonψ andϕ
c c
Inthissection,weelaborateonψ andϕ asintroducedinSection4.2andprovidesomevisualaidforγ . ψ accounts
c c t,c c
forthearea( objectsize)ofclassc. Eq.(15)definesψ ,whichweestimatedwithtrainingdata. ψ ensuresthatclasses
c c
≈
withsmalleraverageareastransitiontothemaskedstatelater. Specifically,thetermisdefinedastheinverseoftheratioof
averagetotalimagepixelstotheaverageclasspixels. Astheaverageareaofclasscdecreases,theψ valuediminishes. On
c
theotherhand,ϕ ensuresaslowdiffusion(tothemaskedstate)ofclassesthatrarelyappearinthedataset. Itisdefinedin
c
Eq.(16),anditcanberegardedastheinversefrequencyoftheclassintrainingimages. Alargerϕ valuecorrespondstoa
c
classthatrarelyappearsinthedataset. InFigure5,wevisualizeγ withdifferentnoiseschedules. Theclass-wiseschedule
t,c
ofclass‘clock’ensuresthattheclassisdiffusedatarelativelylatertime,asitsψ ϕ valueislarge.
c c
E.ADE20KDatasetAnnotationExamples
Inthissection,weprovideexamplesoferroneous/inconsistentannotations.
Jaggededges(DS). WeobservethatsomeimageshavejaggededgesaslabelmapsgiveninFigure12. Thiscouldbethe
resultoferroneousannotationsbutalsocouldoccurduetothecoarseandlowresolutionoftheimages. ADE20Kdataset
containsimagesofvarioussizes. Similarly,thesizeofuserinputscanbediverseinreal-worldapplications.
Incompletemasks(Edge). Figure13showssomeexamplesofincompletemasks,wherethepixelsontheboundariesof
instanceswereleftas‘unlabeled’. Thisusuallyoccursduetotheirinherentambiguity.
18StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Figure5.Visualizationofγ throughoutdiffusioninthebaseline,linearanduniform,andclass-wisenoiseschedule.γ indicates
t,c t,c
theprobabilityofalabelchastransitionedtotheabsorbingstateuntiltimestept.Inourclass-wiseschedule,smallandrareobjectstend
tobeintactrelativelylongerinthediffusionprocess,e.g.,clock.
Inconsistentannotation (e.g., umbrella). Similarto Figure9, Figure11 shows trainingimages (firstrow)and their
annotations(secondrow). Someumbrellasarecorrectlyannotatedwiththeshafts(Figure11(a)),whileothersareannotated
withouttheshaftsandhandles(Figure11(b)). Trainedwiththeseinconsistentlabels,baselinesdidnotsynthesizetheshaft
fortheparasol(class‘umbrella’)inFigure9,whereasourSCDMsuccessfullygeneratedtheshaftsleveragingourLabel
Diffusion.
F.AdditionalExperimentalResults
F.1.StandardSISSetting
F.1.1.GENERATIONQUALITYCOMPARISON.
We also evaluate our method in a standard SIS setting with clean labels. Table 5 shows that SCDM achieves the best
performanceinallthreemetrics(e.g.,FID,LPIPS,mIoU)comparedtorecentDM-basedbaselinesinalldatasets. Also,
includingGAN-basedmodels,theproposedmethodshowsthebestoverallperformance. Specifically,ourmethodsurpasses
allbaselinesonCelebAMask-HQinallthreemetricswithasignificantgainof+1.4(FID)comparedtothestate-of-the-art
method.
Figure6presentsthequalitativecomparisonwithotherSISmodelsandourmethodonCelebAMask-HQ.Remarkably,our
methodgeneratesrealisticimagesevenforanintricatesemanticmapwithflutteringhairovertheface,whileothersstruggle
withgeneratingtheoccludedeyenaturally.
AsFigure7illustratesthequalitativeresultsonADE20K,ourmethoddemonstratesitsadvantageoverpreviousmethodsin
generatingdetails,andconvincingimageswithinthegivensemantics. Especially,ourSCDMgeneratesamorerealisticand
clearimageofthewaterfallthanthebaselines. Inaddition,ourapproachmorenaturallydepictstherocksvisiblethroughthe
water,comparedtothebaselines. ForADE20K,weusedslightlymodifiedψ ϕ withsomescalefactors,andthedetailsare
c c
inAppendixC.3.
Lastly,onCOCO-Stuffourmethodoutperformsthestate-of-the-artmethodsinFIDandLPIPS.Thequalitativecomparison
withothersandoursisgiveninFigure8.Ourssynthesizedamorerealisticandclearerimageofaclocktower,bysuccessfully
generatingthenumbersandhandsoftheclock. Furthermore,oursgeneratedamorenaturalimageofthetreebranchesover
theclocktower.
19StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Table5.Quantitativeperformancecomparisonongenerationquality.ThebaselinemethodsarecategorizedintoGenerativeAdversarial
Networks(GAN)andDiffusionModels(DM).ForFID,lowerisbetter.ForLPIPSandmIoU,higherisbetter.Thebestresultsamongthe
diffusion-basedapproachesareboldfaced,andthebestresultsoverallareunderlined. ‘-’indicatesthatthemethoddidnotreportthe
metricordidnottrainthedataset,orthecheckpointorsamplesarenotpubliclyavailable. ‘Seg’denotesthatthemethodleveragesa
pre-trainedsegmentationnetworkduringtraining.
CelebAMask-HQ ADE20K COCO-Stuff
Methods Seg
FID( ) LPIPS( ) mIoU( ) FID( ) LPIPS( ) mIoU( ) FID( ) LPIPS( ) mIoU( )
↓ ↑ ↑ ↓ ↑ ↑ ↓ ↑ ↑
RESAIL(Shietal.,2022) ✓ - - - 30.2 - 49.3* 18.3 - 44.7
SAFM(Lvetal.,2022) ✓ - - - 32.8 - 52.6 24.6 - 43.3
ECGAN(Tangetal.,2023) ✓ - - - 25.8 0.52 50.6* 15.7 - 46.3
pix2pixHD(Wangetal.,2018) ✗ 38.5 0 76.1 81.8 0 20.3* 111.5 0 14.6
SPADE(Parketal.,2019) ✗ 29.2 0 75.2 33.9 0 44.5 33.9 0 36.9
GAN CC-FPSE(Liuetal.,2019) ✗ - - - 31.7 0.078 47.3 19.2 0.098 40.8
DAGAN(Tangetal.,2020a) ✗ 29.1 0 76.6 31.9 0 45.5 - - -
GroupDNet(Zhuetal.,2020b) ✗ 25.9 0.365 76.1 41.7 0.230 33.7 - - -
OASIS(Sushkoetal.,2020) ✗ - - - 28.3 0.286 50.9 17.0 0.328 44.2
INADE(Tanetal.,2021a) ✗ 21.5 0.415 74.1 35.2 0.459 41.4 - - -
SCGAN(Wangetal.,2021) ✗ 20.8 0 75.5 29.3 0 50.0 18.1 0 41.7
CLADE(Tanetal.,2021b) ✗ 30.6 0 75.4 35.4 0 44.7 29.2 0 36.9
SDM(Wangetal.,2022b) ✗ 18.8 0.404 77.0 27.5 0.524 48.7 15.9 0.518 34.9
LDM(Rombachetal.,2022) ✗ 21.5 0.315 74.6 36.5 0.417 23.2 - - -
DM
PITI(Wangetal.,2022a) ✗ - - - 27.3 - - 15.8 0.489 32.2
Ours ✗ 17.4 0.418 77.2 26.9 0.530 49.4 15.3 0.519 37.9
Label Original DAGAN SCGAN INADE SDM LDM Ours
Figure6. QualitativeresultsonCelebAMask-HQ.Ourssuccessfullycatchesthefine-graineddetailsandgeneratesrealisticimages
conditioningonchallengingsemanticlabelswithhighlyoccludedobjects(e.g.,eyecoveredbyhairs).
Label SCGAN OASIS SAFM SDM LDM Ours
Figure7. QualitativeresultsonADE20K.Oursiscapableofsynthesizingrealisticandclearimages,asourgeneratedimagesshow
moredepthandclearerresultsofthewaterfall.
20StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label SCGAN CC-FPSE OASIS SDM PITI Ours
Figure8. QualitativeresultsonCOCO.OurSCDclearlycapturesthedetails(e.g.,thehandsontheclock)andnaturallydepictsthe
branchesovertheclocktower.
Label Original OASIS SDM Ours
Figure9. Robustnesstoinconsistentsemanticlabels. OurSCDexhibitsrobustnesstoinconsistentsemanticlabels. Althoughthe
parasol (class ‘umbrella’) in the original image has a shaft, it is not accurately annotated in the semantic map. Interestingly, ours
synthesizedanaturalimagewiththemissingshaftwhereasallbaselinesfailedtogenerateit.
F.1.2.ANALYSISONSEMANTICCORRESPONDENCE.
Furthermore,weevaluatethesemanticcorrespondenceusingpre-trainedsegmentationnetworksandcompareourmethod
withbaselinesonmIoU.SCDMshowsbetterperformancethanthestate-of-the-artonCelebAMask-HQ,whileforthe
othertwodatasets,diffusion-basedapproachesincludingoursshowcomparativelyweakerperformancethanadversarial
methodssuchasSAFMorECGAN.Webelievethatoneofthereasonsforthiscouldbetheerroneousannotationofimages.
Forexample,‘umbrella’isoftenannotatedwithoutashaftandahandle(examplesaregiveninAppendixE).InFigure9,
baselinestrainedwiththeseimagesdidnotsynthesizetheshaftforthegivensemanticmapofaparasol(class‘umbrella’)
withoutashaft, whileoursdid. Althoughoursismorerealistic, thiscanresultinlowermIoUscores. Wealsosuspect
thattheperformancesoftheoff-the-shelfsegmentationmodelsusedformIoUevaluationarenotveryrobust. Weranthe
segmentationmodelonground-truth(i.e.,realandclean)imagesanditshowsapoormIoUwithsemanticlabels(43.1on
ADE20Kand34.7onCOCO).Additionally,itisnoteworthythatbaselineswithhighmIoUscoressuchasRESAIL,SAFM,
andECGANleverage‘pretrained’segmentationmodelsintheirsemanticalignmentlosses(denotedby‘Seg’inTable5). In
contrast,oursdoesnotrelyonsuchexplicitguidanceforcorrespondence.
F.2.ExtrapolationHyperparameterSearch
Fortheextrapolationhyperparameterw,wesearchedforvaluesin[0.4,0.5,0.6,0.7,0.8,0.9],followingasimilarprotocol
of(Ho&Salimans,2021). ThesearchresultsareinTable6,andwechosethevaluew =0.8intermsofthegeneration
quality(FID).
21StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Table6. ExtrapolationhyperparametersearchonADE20K.Thesamplesaregeneratedwith25samplingsteps.
w FID( )
↓
0.4 33.0
0.5 31.6
0.6 30.3
0.7 29.2
0.8 27.7
0.9 30.9
Table7.Quantitativenoiseschedulecomparisononsemanticcorrespondence(mIoU(↑)).Theresultsaresampledover1000sampling
steps.
NoiseSchedule CelebAMask-HQ ADE20K COCO-Stuff
Linear&Uniform 76.8 43.0 36.8
Class-wise 77.2 49.4 37.9
F.3.VisualizationofLabelDiffusion
WeshowtheintermediatestepsofourLabelDiffusionasavisualaidforunderstandingthetwodifferentnoiseschedules.
Figure15(a)and15(b)illustratetheintermediateresultsofthediffusedlabelsintheLabelDiffusionprocessusingthelinear
anduniformnoisescheduleandtheclass-wiseschedule,respectively. Thefirstrowofeachsubfigureshowsthediffused
semanticmapgiventothemodelduringthediscretediffusionprocess,whilethesecondrowmagnifiesanddisplaysthe
labelofaclockonacabinetfromthefirstrow. Theψ ϕ valuesofthe‘clock’and‘cabinet’classesare651.3and17.3,
c c
respectively. Astheclass‘clock’occupiesrelativelysmallareasinthedataset,theclass-wiseschedulemakestheclock
diffusedslowly,anddenoisedfastlyduringthegenerationprocess. Meanwhile,intheuniformnoiseschedule,the‘clock’
classisperturbedfasterthanintheclass-wiseschedule(Figure15(b)),becausetheuniformscheduleevenlydiffusesall
classlabelsinthelabelmap.
F.4.EffectofClass-wiseNoiseSchedule
In this section, we show the quantitative comparison of the class-wise schedule and the linear and uniform schedule,
continuingthediscussionfromSection6.2ofthemainpaper. TheresultsaregiveninTable7,onthree(original)benchmark
datasets. Theresultsaresampledwith1000samplingsteps,withoutextrapolation. AsdemonstratedbythemIoUgains,the
class-wisenoisescheduleincreasesthesemanticcorrespondenceofthegeneratedimages. Additionally,weprovidethe
qualitativecomparisononCOCO-StuffinFigure14.
F.5.FurtherDiscussionandAnalysisonClassGuidance
InSection4.4,weanalyzedLabelDiffusionregardingtheconditionalscorethatourmethodapproximates. Althoughour
methoddoesnothavethesameguidanceasthebaselinewithfixedlabelsandtime-dependentscaling,wefurtherassessthe
effectofscalingandcompareitwithourmethod. Specifically,wemodifythefixedclassifier-freeguidancescalethrough
scheduling,i.e.,stos(1 γ )inEq.(20),resultingincomparablefidelitywiththebaselineusingfixedguidance(FID( )
t
− ↓
of28.6(CFGscalescheduling)and28.1(baseline)). Nevertheless,itstillyieldssuboptimalresultscomparedtoours(FID
of26.9). WhatfurtherdistinguishesourmethodfromCFGscaleschedulingisthatourabsorbingstateexplicitlyinformsthe
modelthatthepixelisunconditional,facilitatingthenaturalgenerationoftheambiguouspartsinanimage. Someconcrete
examplesoftheambiguouspartsaregiveninFigure6and8,wheretheeyeisoccludedbyhairsandthetreebranchesare
overtheclocktower.
22StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Table8.SamplingresultswithdifferentnoiseschedulesforgenerationprocessonADE20K.Theresultsaresampledfrom(a)SCDM
trainedwithaclass-wisenoiseschedule(η=1),and(b)baseline(trainedwithoutLabelDiffusion,i.e.,η=+∞).
Model Samplingnoiseschedule η FID mIoU
NoLabelDiffusion + 30.6 47.8
∞
(a)Ours Linearanduniform 0 34.5 28.9
Class-wise 1 27.7 48.7
NoLabelDiffusion + 28.1 48.6
∞
(b)Base Linearanduniform 0 76.2 15.7
Class-wise 1 44.0 43.1
(a) CelebAMask-HQ. (b) ADE20K. (c) COCO-Stuff.
Figure10. Multimodalgenerationresults.
F.6.ValidationofSCDMGenerationProcess
Inthissection,wevalidatetheSCDMgenerationprocessbyshowingtheeffectofourLabelDiffusionduringsampling.
Althoughourforwardprocessdiffusesimagesandlabelsindependently(Eq.(9)ofthemainpaper),ourmodelsuccessfully
learnsthejointdistributionoftheimagesandlabels,andthereforegeneratestheimagesdependentonthegivenperturbed
labels.
Toshowthisempirically,wefirsttrainedourmodelwiththeclass-wisenoiseschedule(i.e.,η = 1). Thenwesampled
imageswiththreedifferentLabelDiffusionnoiseschedulesbycontrollingη: (1)η = + ,i.e.,noLabelDiffusionand
∞
usingfixedy fortheentiregenerationprocess,(2)η =0,i.e.,thelinearanduniformnoiseschedule,and(3)η =1,i.e.,the
0
class-wisenoiseschedulethatwasleveragedduringtraining. TheresultsarereportedinTable8(a)andweused25sampling
steps. AstheFIDscoresshowthatthequalityofthesamplesnotgeneratedwiththetrainednoisescheduleisworsethanthe
imagessampledwithη =1,wecanobservethatLabelDiffusionaffectsthegenerationprocess.
Additionally, we sampled images using the baseline model with the same noise schedules, i.e., η = + , η = 0, and
∞
η =1. TheresultsarereportedinTable8(b)andweused1000samplingsteps(withoutextrapolation). Theperformance
deteriorateswhenLabelDiffusionisappliedtothebaseline(i.e.,trainedwithoutLabelDiffusion). Thisalsoindicatesthat
LabelDiffusioncontributestothegenerationprocess,validatingtheSCDMgenerationprocess.
F.7.MoreQualitativeResults-MultimodalGeneration
Weprovideadditionalgenerationresultsofourmethod,showingSCDM’scapabilityofgeneratingdiversesamples.Figure10
showsmultimodalgenerationresultsonCelebAMask-HQ,ADE20K,andCOCO-Stuff(standardSISsetting).
23StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
(a) Trainingdataexampleswithshaftannotated. (b) Trainingdataexampleswithshaftnotannotated.
Figure11. Examplesofinconsistentsemanticlabels(class‘umbrella’)inthetrainingset.
Figure12. ExamplesofjaggededgesintheADE20Kdataset.
F.8.MoreQualitativeResults-SISwithNoisyLabels
WeprovideadditionalgenerationresultsofourmethodandbaselinesonSISwithnoisylabels. Theresultsof[DS],[Edge],
and[Random]areillustratedinFigure16,17,and18,respectively,andtheexperimentsareontheADE20Kdataset.
F.9.MoreQualitativeResults-StandardSISSetting
WepresentadditionalgenerationresultsofourSCDMandotherbaselinesonthestandardSISsetting. Figure19showsthe
resultsofourmethodandqualitativecomparisonsonCelebAMask-HQ.Figure20and21showtheresultsandqualitative
comparisonsonADE20KandCOCO-Stuff,respectively.
24StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
‘unlabeled’ class
Figure13. ExamplesofincompletemasksintheADE20Kdataset.
Label Uniform Class-wise
Figure14. QualitativenoiseschedulecomparisononCOCO-Stuff.
25StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
t<latexit sha1_base64="9mxw3qKmSObraXWBfIgayq/hfDc=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSOIbrqsaB9QiyTTaR2aF5OJUorgD7jVTxP/QP/CO2MKahGdkOTMufecmXuvnwQiVY7zWrBmZufmF4qLpaXlldW18vpGM40zyXiDxUEs276X8kBEvKGECng7kdwL/YC3/OGZjrduuUxFHF2qUcK7oTeIRF8wTxF1oY6d63LFqTpm2dPAzUEF+arH5RdcoYcYDBlCcERQhAN4SOnpwIWDhLguxsRJQsLEOe5RIm1GWZwyPGKH9B3QrpOzEe21Z2rUjE4J6JWktLFDmpjyJGF9mm3imXHW7G/eY+Op7zaiv597hcQq3BD7l26S+V+drkWhjyNTg6CaEsPo6ljukpmu6JvbX6pS5JAQp3GP4pIwM8pJn22jSU3tureeib+ZTM3qPctzM7zrW9KA3Z/jnAbNvap7UHXP9ysnp/moi9jCNnZpnoc4QQ11NMh7gEc84dmqWZGVWXefqVYh12zi27IePgCzKpAA</latexit> = 0 <latexit sha1_base64="MgDRrxbRzNke7iUtFjNtASkLlag=">AAACxnicjVHLSsNAFD2Nr1pfVZdugkVwVRIRdSMU3XRZsS+oRZLptA5NkzCZKKUI/oBb/TTxD/QvvDOmoBbRCUnOnHvPmbn3+nEgEuU4rzlrbn5hcSm/XFhZXVvfKG5uNZMolYw3WBREsu17CQ9EyBtKqIC3Y8m9kR/wlj881/HWLZeJiMK6Gse8O/IGoegL5imiLtVp/bpYcsqOWfYscDNQQrZqUfEFV+ghAkOKEThCKMIBPCT0dODCQUxcFxPiJCFh4hz3KJA2pSxOGR6xQ/oOaNfJ2JD22jMxakanBPRKUtrYI01EeZKwPs028dQ4a/Y374nx1Hcb09/PvEbEKtwQ+5dumvlfna5FoY8TU4OgmmLD6OpY5pKaruib21+qUuQQE6dxj+KSMDPKaZ9to0lM7bq3nom/mUzN6j3LclO861vSgN2f45wFzYOye1R2Lw5LlbNs1HnsYBf7NM9jVFBFDQ3yHuART3i2qlZopdbdZ6qVyzTb+Lashw8IuZAk</latexit>t = T
(a) Uniformandlinearnoiseschedule.
(b) Class-wisenoiseschedule.
Figure15. VisualizationofLabelDiffusionintermediatesteps.
Label SCGAN OASIS SAFM SDM LDM Ours
Figure16. MorequalitativecomparisonsonSISwithnoisylabels(DS).Thegenerationresultsareconditionedwithsemanticmasks
withjaggededges.
26StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label SCGAN OASIS SAFM SDM LDM Ours
Figure17. MorequalitativecomparisonsonSISwithnoisylabels(Edge).Thegenerationresultsareconditionedwithincomplete
masksontheedgesofinstances.
Label SCGAN OASIS SAFM SDM LDM Ours
Figure18. MorequalitativecomparisonsonSISwithnoisylabels(Random).Thegenerationresultsareconditionedwithcorrupted
masks.
27StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label Ours DAGAN SCGAN INADE SDM LDM
Figure19. MorequalitativeresultsandcomparisonsonCelebAMask-HQ.Thefirsttworowsaretheresultofourmodel,whilethe
otherrowsdepictqualitativecomparisonsintermsofgenerationquality.
28StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label Ours SCGAN OASIS SAFM SDM LDM
Figure20. MorequalitativeresultsandcomparisonsonADE20K.Thefirsttworowshowstheresultofourmodel,whiletheother
rowsdepictqualitativecomparisonsintermsofgenerationquality.
29StochasticConditionalDiffusionModelsforRobustSemanticImageSynthesis
Label Ours CC-FPSE OASIS SCGAN SDM PITI
Figure21. MorequalitativeresultsandcomparisonsonCOCO-Stuff.Thefirsttworowshowstheresultofourmodel,whiletheother
rowsdepictqualitativecomparisonsintermsofgenerationquality.
30