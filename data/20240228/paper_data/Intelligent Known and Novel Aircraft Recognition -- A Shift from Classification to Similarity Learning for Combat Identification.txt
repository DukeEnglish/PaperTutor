1
Intelligent Known and Novel Aircraft Recognition -
A Shift from Classification to Similarity Learning
for Combat Identification
Ahmad Saeeda, Haasha Bin Atifa, Usman Habiba, Mohsin Bilala,b
aDepartment of Artificial Intelligence & Data Science
National University of Computer and Emerging Sciences, Islamabad, Pakistan
bCollege of Computer Engineering and Sciences
Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia
{I212281, haasha.atif, usman.habib, mohsin.bilal}@nu.edu.pk
Abstract—Preciseaircraftrecognitioninlow-resolutionremote
sensingimageryisachallengingyetcrucialtaskinaviation,espe-
ciallycombatidentification.Thisresearchaddressesthisproblem
with a novel, scalable, and AI-driven solution. The primary
hurdle in combat identification in remote sensing imagery is
the accurate recognition of Novel/Unknown types of aircraft in
addition to Known types. Traditional methods, human expert-
driven combat identification and image classification, fall short
inidentifyingNovelclasses.Ourmethodologyemployssimilarity
learning todiscern featuresof a broadspectrum ofmilitary and
civilianaircraft.ItdiscernsbothKnownandNovelaircrafttypes,
leveraging metric learning for the identification and supervised
few-shot learning for aircraft type classification.To counter the
challenge of limited low-resolution remote sensing data, we
proposeanend-to-endframeworkthatadaptstothediverseand
versatile process of military aircraft recognition by training a
generalized embedder in fully supervised manner.Comparative
analysis with earlier aircraft image classification methods shows
that our approach is effective for aircraft image classification
(F1-scoreAircraftTypeof0.861)andpioneeringforquantifying
the identification of Novel types (F1-score Bipartitioning of
0.936).Theproposedmethodologyeffectivelyaddressesinherent
challengesinremotesensingdata,therebysettingnewstandards
in dataset quality. The research opens new avenues for domain
experts and demonstrates unique capabilities in distinguishing
various aircraft types, contributing to a more robust, domain-
adapted potential for real-time aircraft recognition.
Index Terms—Aircraft, Bipartitioning, Combat Identifica-
tion(CID), Embedder, Few shot learning, Novel class, Remote
Sensing (RS), Recognition, Youden Index
Fig. 1. Flow Diagram from left to Right showing a)Traditional CID , b)
Imageclassification&c)IntelligentKnownandNovelAircraftRecognition
I. INTRODUCTION (INNAR)tofindKnownandNovelclass
Aircraft recognition in remote sensing imagery presents a
far-reaching challenge due to its wide-ranging applications, Novel classes (unfamiliar/disjoint types). The former repre-
encompassing border security surveillance, emergency re- sents established types encountered during training, while the
sponse,disastermanagement,airtrafficcontrol,environmental latterposeschallengesduetothemodel’slackofexplicittrain-
monitoring, maritime surveillance, counter-terrorism efforts ing. Traditional methods, such as human expert-driven CID
and critical asset security. The principal challenge of combat (Figure1-a,andimageclassification-basedaircraftrecognition
identification (CID) [2], [27] stems from the need to identify (Figure 1-b, fall short in identifying Novel classes. This paper
and label potential targets as friend, foe, or neutral aircraft, a presentsapioneeringmethodologytermed’IntelligentkNown
task of considerable practical importance. The primary hurdle andNovelAircraftRecognition(INNAR)’illustratedinFigure
in CID is the accurate recognition of Novel/Unknown classes 1-c. This innovative approach signifies a paradigm shift from
of aircraft in addition to Known aircraft types (or classes). traditional image classification to similarity learning, with the
Recognition hinges on distinguishing Known classes from objective of automating CID. It facilitates the recognition
4202
beF
62
]VC.sc[
1v68461.2042:viXra2
of both Known and Novel aircraft, thereby setting a new and testing sets showcasing diversity in capturing angles and
benchmark in CID. simulating scenarios. MTARSI is the only dataset for aircraft
Incorporating deep learning into CID processes enhances recognition, but contains several errors and issues related to
patternanalysisandimagerecognition[8],improvingaccuracy class labeling and cross-contamination. We have performed
and speed in large, diverse datasets. Recognizing various a thorough evaluation and cleaning of the MTARSI dataset
aircraft, especially Novel classes, extends beyond standard [33]byinvolvinginputfromfieldexperts(pilots)andsatellite
image classification tasks. The primary challenge lies in the imagery analysis. This process aimed to conclusively address
continuous introduction of new, unknown aircraft into fleets. class labeling and cross-contamination issues, as highlighted
Limited training data, diverse designs, dynamic appearance in Figure 2. Our refined techniques not only reduce errors
changes,andintra-classvariabilityincreaseremotesensingim- but also facilitate a precise, unambiguous interpretation of the
agery complexity. These challenges necessitate advance deep dataset, thereby establishing a new benchmark for technical
learning(DL)modelstoadapttoevolvingaircrafttechnology, precision in data processing. Section IV describes the dataset
sparse and noisy data, and the absence of comprehensive evaluation and cleaning procedure in detail.
contextual information. Our INNAR approach is a novel method that effectively
To this end, we are proposing INNAR, a transformative integrates a thresholding technique in the recognition process
approach that redefines the solution to the CID problem. that effectively determines image alignment with the embed-
This approach integrates a generalized aircraft embedder ding space distribution, enabling informed decision-making
and similarity learning within an end-to-end deep learning during testing. Simultaneously, it incorporates advanced deep
framework, enabling efficient aircraft recognition with min- nets within the existing framework, eliminating the need for
imal training data. Current state-of-the-art multi-classification a completely new architecture, showcasing its efficiency and
algorithms [19], [22], [37], [14] can predict classes based adaptability in addressing key challenges in aircraft recog-
on learned patterns from training data, but fall short as a nition. Unlike image classification that makes false promise
comprehensivesolutiontotheCIDproblem.SectionIIfurther of very high accuracy (up to 99% [12]) on original noisy
discusses the literature available on aircraft classification. As MTARSI dataset [32], the proposed INNAR methodology
depicted in Figure 1, traditional CID approaches are limited utilizescutting-edgeconvnetsandleveragessimilaritylearning
to predicting classes within the domain of input training to construct robust and generalizable feature representation
embedding, whether derived from live or offline streams. with image triplets.
In contrast, an automated CID solution necessitates a data- This paper makes significant contributions to the aircraft
efficient,generalizable,androbustapproachthatcanrecognize recognition and combat identification, which are listed below:
brand-new(few-shotsamplesandNovelclasses)aircrafttypes, 1) We introduced a novel method to achieve CID in an
evenwhentheyareabsentinthetrainingdatabutpresentinthe automated manner.
target fleet. This approach eliminates the need for re-training 2) We introduced a new and better version of the dataset
or fine-tuning of the image embedder, thereby advancing the - MTARSI-INNAR that advances automated CID de-
state-of-the-art in CID. velopment and evaluation after identifying errors in
MTARSI dataset and performing a rigorous data clean-
(cid:32) (cid:88)n (cid:33) p1 ing process that involves domain experts. 1
d(x,y)= |x −y |p (1)
i i 3) We proposed INNAR, an innovative methodology that
i=1 distinguishes between Known (Friend) and Novel (Foe)
Equation 1 assesses vector proximity (x and y) in a classes with high accuracy to enhance adaptability in
specified vector space. Parameter p denotes the norm type, CID. It utilizes cutting-edge convnets and leverages
defining distance metrics like Manhattan (L1) and Euclidean similarity learning to construct robust and generalizable
(L2). These feature vectors undergo processing through fully feature representation with image triplets.
connected layers, utilizing similarity metrics crucial for se- 4) We validated that image classification makes false
curity applications. The focus lies in discerning aircraft fea- promises of very high accuracy on original noisy
tures, especially in few-shot learning. Our proposed method MTARSI dataset [32] and propose a shift to similarity
excels in identifying novel classes and integrates state-of- andfewshotlearningforaircraftrecognitionandcombat
the-art techniques to create an embedding space, effectively identification.
distinguishing between Known and Novel classes. Section III
explains INNAR and its empirical evaluation.
II. RELATEDWORK
Moreover, remote sensing imagery poses unique challenges
The evolution of aircraft recognition in remote sensing,
and characteristics when compared to optical [13], [16] [20]
with its multifaceted components of classification, detection,
and medical images [1], [4], [5]. These distinctions arise
and segmentation, has shown a paradigm shift in recent
from inherent complexities, including diverse environmental
years towards end-to-end network development. This shift
settings, limitations imposed by satellite sensors, fluctuating
underscorestheincreasingsignificanceofseamlessintegration
weather conditions, and noisy datasets as highlighted in these
studies[9],[38].Inthisstudy,weworkedwiththeMulti-Type
1”Tocontributeinopenscienceandreproducibility,wewillsharethecode
Aircraft Remote Sensing Images (MTARSI) dataset [21], Fig-
repository for research purposes and the dataset is available at Zenodo.org
ure2&3showafewsamplesofallaircrafttypesfromtraining [21]”3
Fig. 2. MTARSI-INNAR [23] Embedder Training Set Showcasing Remote Sensing Military & Civil Aircraft highlighting Remote Sensing challenges as
illuminationconditions,orientation,background,noiseandcapturingangles.
acrossdiverseapplications.Direshiftinfromconvolution[29], ing interpretability with unbalanced datasets, and managing
[15] to Transformers [10] and now again convNext [25] Deep CNN mapping complexity. However, limitations include in-
Learning networks has advanced formidably, particularly in sufficient evaluation details, concerns about generalization,
object classification in the form of feature representation/ ex- and a lack of real-world examples and datasets.In the same
traction capabilities. The contemporary approach treats object relam, TransEffiDet [30],innovates aircraft detection with Ef-
detection as a classification challenge for regions of interest, ficientDet and Transformer, excelling in aerial imagery with
harnessingdeeparchitecturestoautonomouslyextractintricate BiFPN. Achieving enhanced military accuracy, challenges
image features. include detecting specific aircraft types due to less distinct
shapes and lacking real-time detection, critical for timely
In order to address aircraft shadows and robust feature
responses. An important factor in above-mentioned methods
extraction combination of methods are introduced like [31]
and established remote sensing datasets like UCMerced Lan-
direction estimation through a reconstruction-based similarity
dUse[35],NWPU-RESISC45[36],PatternNet[39],AID[34]
measure and a jigsaw matching pursuit algorithm. Evaluation
[7], [31] and FAIR1M [26] present challenges by treating
with Quickbird imagery validates the method’s effectiveness,
aircraft as a single class, creating a skewed distribution that
while a Principal Component Analysis (PCA)-based CNN
hinders accurate classification due to intricate complexities.
approach [18] showcases enhanced segmentation with a novel
This limitation makes these datasets unsuitable for Known
low downsampling ratio, though it encounters difficulties in
and Novel class recognition techniques, revealing a critical
addressing large aircraft in salient regions and managing
research gap in addressing the challenges of CID and Novel
unbalanced datasets.An impressive work in this domain Mul-
class recognition in aircraft datasets. Aircraft recognition in
tiple Class Activation Mapping (MultiCAM) approach [11]
eXplainable Artificial Intelligence (XAI) framework by [28]
demonstrates improved class activation maps by precisely
makesanotablecontributionbycombiningtheHybridGlobal
localizing object parts and addressing background interfer-
Attribution Mapping (HGAM) algorithm, Path Aggregation
ence, yet faces challenges in covering large aircraft, ensur-4
Fig.4. Misslabelling&crosscontaminationissuesinMTARSIdatasets.a)
B-777,B-747andAirbusbeingdisplayedasBoeing.b)B-777,B-747andT-
1AbeingmisclassifiedwithC-40.c)C-130,DC-4EandP3Cbeingdisplayed
asDC-4.
likeAlexNetandEfficiNet.However,limitationsincludenoise
and imbalance in dataset, neglecting multi-resolution impact
on aerial images for generalization to diverse scenarios in
remotely sensed images. The MTARSI dataset open new
horizon for the researcher community on military aircraft
recognition,where[3]introducesanovelapproachintegrating
handcrafted and DCNN features, achieving successful identi-
fication. However, limitations include lack of impact of the
multi-resolution RS images specifically negating noise and
imbalance in dataset, thus more emphasis on accuracy rather
than correct identification. In the realm of advance network
techniques, like Swin Transformer [12] in combination of
state-of-the-art super resolution method for image upsam-
pling which improves validation accuracy and emphasizes the
importance of the training procedure over model selection,
suggesting a nuanced understanding of the dataset and the
learning process. It also critically examines the limitations
of the MTARSI dataset, such as mislabeling, class scopes,
Fig.3. MTARSI-INNAR[23]NovelTestingSethighlightinguniqueclasses andcross-contamination,andrecommendstrainingonmultiple
coveringroleandfeaturesasFighter,ISR,Transport,SurveillanceandMulti-
datasets to achieve generalizable models. Another paper [22]
MissionPlatforms.
appliesadvanceddeeplearningmethods,suchasVisionTrans-
formers, ResNet50v2, EfficientNetB0, and InceptionNetV3,
Network (PANet) module for feature learning, and Class- to the MTARSI dataset and achieves higher classification
specific Confidence Scores Mappings (CCSM) metrics to accuracythanthebenchmark.Itfocusesonthedesignandfine-
enhance deep neural network interpretability in synthetic tuning of the architectures to capture the features and patterns
aperture radar-based aircraft detection. Despite introducing ofcomplexmilitaryplatforms.Incurrentera,theintroduction
novel XAI techniques to a domain with known challenges of few shot learning by [17] introduces S2I-DAFSL, a novel
in comprehensibility, the method exhibits limitations such as domain adaptive few-shot learning method for aircraft recog-
insufficient evaluation details, concerns about generalization, nition, utilizing an attention transferred importance-weighting
and a lack of real-world examples and datasets. network (ATIN) for enhanced transferability from satellites
In 2020, [33] addressed the lack of standardized bench- to inverse synthetic aperture radar (ISAR). This approach
marksinaircrafttyperecognitionbyintroducingtheMTARSI strength lies in cross-domain few-shot ISAR aircraft recogni-
dataset, consisting of 9,385 images of 20 aircraft types and tion tasks, however,it lacks in task-specific model adaptability
over 12,000 samples in version -1 & II [32] [21] with diverse tonewsamplesalongwithdomainadaptiverobustness,assum-
backgrounds and resolutions. The dataset proved crucial for ing labeled data availability in the source domain.
fair comparisons, demonstrating a 26% improvement in aver- Model training procedure and role of loss, is essential
age accuracy through transfer learning using shallow networ for effective image recognition and classification in handling5
imbalanced, noisy, and heterogeneous data [6]. The batch are then updated through backpropagation, optimizing the
hard triplet approach, which offers stability and faster con- embeddingspace for the given task.This methodologyproves
vergence, outperforms conventional methods for image recog- especially effective in scenarios where pairwise information
nition. However, it candidly admits the approach’s limited about similarity or dissimilarity between samples is available,
success in achieving high accuracy on Unknown classes, making it valuable for tasks ranging from image verification
acknowledging the persistent challenge posed by fine-grained to recommendation systems.
classes with high intra-class variance. FaceNet significantly Foracomprehensiveevaluation,weconductedextensivetri-
contributes [24] by introducing a unified system for facial als using a diverse range of architectures, exploring variations
recognition, optimizing training to generate discriminative in both structure and nature to ensure a thorough examination
embeddings capable of recognizing and verifying faces un- ofthemodel’sperformance.Thisinvolvedtestingwithseveral
der various conditions. Its innovative use of a triplet-based deep learning architectures like ResNet, EfficientNet, Swin
loss function efficiently minimizes distances between similar Transformer, and ConvNext, each serving as embedders to
faces and maximizes distances between different individuals, generate distinct embedding vectors for our evaluation pur-
marking a substantial leap in facial analysis and verification poses.
systems. After completing the initial step, we acquired an embedder
with the ability to generate vector representations for any
III. PROPOSEDINNARMETHODOLOGY input aircraft image. To overcome data scarcity and ensure
scalability for newly incorporated aircraft without retraining,
This research focuses on designing an end-to-end pipeline
we embraced few-shot learning. We considered a limited set
for aircraft recognition, particularly in identifying Known
of images for each aircraft, fed them into the embedder,
classesvsNovelaircraft.Firstly,wetrainamodeltorecognize
andobtainedcorrespondingembeddingvectors.Thesevectors,
aircraft via similarity learning, elaborated in Section III-A.
along with their labels, were stored to create an embedding
This forms the basis for the next steps and is essential for
space addressing both data scarcity and scalability issues.
the model to distinguish effectively between various aircraft
This space allows us to calculate distances with test-time
categories.Secondly,weusethemodeltrainedinthefirststep
embedding vectors using Euclidean Distance.
to construct an embedding space through few-shot learning.
Thirdly, we introduce a model adaptive thresholding mech-
anism discussed in Section III-B to determine if an image
B. Bipartitioning for out-of distribution images
belongs to a Known or Novel distribution for the recogni-
In this crucial step, we introduce a thresholding technique
tion pipeline. If the image belongs to a Known category, it
to discern whether an image aligns with the distribution of
undergoes further classification using a few-shot classifier,
our generated embedding space. If the image falls outside
refiningthemodel’sdiscernmentformoregranulardistinctions
our generated embedding space, it indicates that the pro-
within established aircraft categories. To understand the pro-
vided image does not pertain to any of the aircraft classes
cess better, the details of each step and the intricate workings
encompassed by our space. To achieve this, we transformed
contributing to the model’s prowess in aircraft recognition in
the aircraft labels into a binary format, where 0 represents
subsequent sections and as illustrated in Figure 5.
the classes used for our known aircraft representation, and
1 signifies classes set aside that are not part of this space.
A. Embedding Architecture Training
With the transformed labels, we selected an image from the
Thesiamesenetworklearnsembeddingsdesignedtocapture development set and computed its distance within our embed-
the similarity between input triplets. During the training pro- ding space. These distances for all development images were
cess,weconstructtripletsofsamples,comprisingananchor,a recorded and used to plot their distributions as highlighted
positive,andanegativesample.Theanchorsignifiestheinput in Figure 7 and compute Receiver Operating Curve (ROC)
for which we seek to learn a meaningful embedding, with the enabling the identification of the True Novel Rate (or True
positive being a sample similar to the anchor and the negative Positive Rate) and False Novel Rate (or False Positive Rate)
being a dissimilar sample. The objective actively involves respectively. By scrutinizing this, we can make an informed
minimizing the distance between the anchor and the positive decision on selecting a threshold that aligns with our model
while simultaneously maximizing the distance between the and other preferences—whether prioritizing a higher TPR, a
anchor and the negative, as highlighted in Equation 2. This higher FPR, or a balanced point. This chosen threshold is
approach effectively creates a margin that encourages the then applied during testing to distinguish images belonging
model to map similar instances close together and dissimilar to our distribution from those in out-of-distribution classes.
instances far apart in the embedding space, as illustrated in For this study, we opted for Youden Index for the selection of
the Embedder Training section within Figure 5. optimal threshold which tries to capture maximum potential
effectiveness for a distribution. After determining whether
an image falls within our embedding space. The next step
L(a,p,n)=max{d(a ,p )−d(a ,n )+margin,0} (2)
i i i i involves classification for those images that do belong to
The loss function associated with the triplet loss typically the space. Employing the K-Nearest Neighbor method, we
takes the form of the hinge loss, penalizing the model when leverage the Known embedding space and their corresponding
the margin constraints are violated. The network’s parameters labels for this classification. Once an embedding vector is6
Fig.5. ProposedINNARMethodologyofAutomatedCIDtoidentifyNovelClass;wheretheinputimagegetstransformedintofeaturevectorwhichisthen
usedtoidentifyasaKnownorNovelfollowedbyclassification.a)EmbedderArchitecturetrainingb)Fewshotlearningforembeddingspacec)Bipartitioning
forout-ofdistributionimagesd)Few-ShotClassification
generated for a test image, its distances are computed with explanationofthefinalphase,ensuringthatthestepstakenare
all vectors in the embedding space. The labels of the closest straightforwardandeasytograspwithintheoverallalgorithm.
K vectors are extracted, and a consensus is reached among
these labels, assigning the most recurrent label to the image
IV. DATASETQUALITYMANAGEMENT
inquestion.Togaugetheoverallperformanceofourpipeline,
we evaluate it using weighted F1-Score. In 2020, the introduction of the MTARSI dataset [32],
This algorithm goes into detail about how the final step [21], which constitutes three versions (V1,V2 & V3) offers a
is carried out. It explains the specific actions and methods valuableresourceforadvancingresearchinremotesensingand
involved in this step, aiming to make the process more deeplearningbyestablishingbenchmarkstocomparedifferent
understandable. The goal is to provide a clear and accessible models. However, the datasets constitutes severe challenges7
Algorithm 1 Automated CID Embedding-based Algorithm
Input: Images
Output: Aircraft recognition into Known classes or Novel
Class
1: Initialization: Embedder,Threshold,K
Set = {x ,x ,...,x } (Set of Known Classes)
A A1 A2 AN
Set = {x ,x ,...,x } (Set of Novel Classes)
B B1 B2 BN
Set =Set ∪Set (Set of All Classes)
C A B
2: Few Shot Phase:
3: for each class c in the Set A do
4: Sample N images {xc,xc,...,xc } from class c
1 2 N
5: Generate embedding vectors {vc,vc,...,vc } using
1 2 N
Embedder
6: Store vectors (vc,c) for i=1 to N in the database
i
7: Store labels (lc,c) for i=1 to N in the database
i
8: end for Fig.6. MTARSI-INNAR[23]sampleswiththenumberofClassesrectified
forduplicity&crosscontaminationincomparisontoMTARSIdatasetswith
9: Testing Phase: correspondinglabels
10: for each class c in the C do
11: for each sample s in the c do
12: v test ←Embedder(s) providesaversatileresearchopportunitytoanalyseboth
13: distances←Compute p-norm distance between v test domains at the same time. In Figure 2 (training image
and v for i=1 to N samples) and Figure 3 (testing image samples), codes
i
14: topKsamples ← Select the top K samples with F, B, C, and T represent fighters, bomber, transport and
minimum distance trainer categories, respectively.
15: meanDistance ← Calculate the mean of the 2) Several aircraft (up to 10 different) types erroneously
topKsamples labelled as airliner class, which require careful re-
16: if meanDistance≥Threshold then categorization to overcome the contamination. The con-
17: Output: Classify as Novel fusionmatrixinFigure6reportsthenumberofsamples
18: else mislabelled because of this contamination and Figure 4
19: Pass v test through our Few-Shot classifier (a) show a few of those samples.
20: Output: Final Classification Result 3) B-29 Superfortress and P-3 Orion types contain highly
21: end if identicalimagesampleswhichwehavemergedtogether
22: end for as a single class as listed in Figure 6.
23: end for 4) AsillustratedinFigure4(b),theconfusionbetweenthe
C-40 and aircraft types B-777, B-747, and T-1A arises
from their shared characteristics as passenger planes.
like contamination, miss-classification, duplicity, labeling in- 5) Figure 4 (c) emphasizes the confusion between DC-
accuracies and integration inconsistencies. Certainly, Cross- 4 with C-130, DC-4E, and P3C aircraft, highlighting
contamination in image classification labels involves uninten- the inherent visual similarities that affect representation
tional mixing or mislabeling of images from different classes learning and classification.
during machine learning model training or testing, leading 6) Inthetrainingset,mislabelingoccursduetosimilarities
to reduced accuracy and performance as the model may between F-4, F-18, and F-22 with F-15, leading to
struggle to distinguish between classes due to contaminated potential convergence issues.
label information. We have taken following steps to clean MTARSI dataset
To review and clean the MTARSI [32], [21] dataset, we from above-mentioned issues and duplicate samples:-
adopt a comprehensive step by step approach, whose broader 1) A dedicated team of 12 specialists, as acknowledged
contours are highlighted as follows:- in Section VI, cleaned the dataset. This team comprises
1) Acarefulstudyofthedatasethighlightsidentificationof professionalswithdiverseexpertise,includingpilotsand
fourdataissuesintheshapeofinterferencebyobjectsin experts in satellite imagery considering the role and
the vicinity, image dimensions not compatible with the feature types of various aircraft image samples.
size(biggeraircraftwithsqueezedshapes),aircraftback- 2) Duplicate samples, where the same sample is present
groundnoises,imagemergingwiththesamesurface(e.g in multiple aircraft types, are identified automatically
black)andproblemssuchasexposure&weatherissues, through a Python code snippet for duplicates.
underscores the challenges within the dataset, empha- 3) We perform an iterative approach to refine the dataset,
sizing the need for careful consideration in subsequent actively reviewing and updating it based on feedback
analyses. The image samples in Figure 2 and Figure 3 from specialists and any newly acquired knowledge
highlight these issues. Moreover, the dataset [21], [32] about the aircraft types.
constitutesbothmilitaryandcivilimagesamples,which 4) Finally, the above-mentioned steps ensured unified scal-8
ing to enhance quality and accuracy. Following this, the trade-off between correctly classifying Known entities and
samples are normalized to 224 pixels × 224 pixels to accurately identifying unknown entities is a critical consid-
ensurecompatibilitywithspecificmodelsoralgorithms, eration. The specific application’s requirements and priorities
ensuring efficient processing and analysis. play a significant role in determining the threshold values.
Addressing the challenging task of identifying Known
V. EXPERIMENTALRESULTSANDDISCUSSION classeswhichisacrucialpartofreal-worldproblemofaircraft
recognition and combat identification, our approach involved
A. Experimental Setup
a distinctive strategy: training an embedder. This embedder,
We used Weights & Biases, extending beyond experiment
initialized with ImageNet weights, underwent further refine-
managementtoencompasslogging,plotting,andversioncon-
mentthroughtheapplicationoftheTripletLossFunctionover
trol. We executed the experiments on a single Nvidia Tesla
severalepochs.InFigure7,weilluminatekeyinsightsintothe
P100 GPU with 16GB memory. For dataset partitioning, 80%
distributionsonboththedevelopmentandtestsets,emphasiz-
was allocated for training and 20% for testing on a class-wise
ing that each architecture embeds vectors within a uniquely
basis as highlighted in where classes in bold correspond to
rangedspace.ItisevidentthatEfficientNetandSwinV2which
Novel Class. To maintain consistency, input dimensions were
are smaller architectures create the most confined embedding
standardized, resizing images to 224x224 with a batch size
space (Their distributions are much compact). On the other
of 32, and employing the ADAM optimizer with a learning
hand,ResNetandConvNextseemstohaveawiderdistribution
rate of 1e-4. We utilized various architectures, including
and they also have very less overlapping region between the
Resnet,EfficientNet,Swin,andConvNext,asembedders.The
Known and Novel classes which is highlighted by Blue and
embedder incorporated the Triplet Margin Loss, configured
Orange color respectively.
with a margin of 1 and a threshold derived from the median
Weintroducedadeliberate22-5splittothedevelopmentset
value of the ROC Curve in Figure 9. For classification, we
ashighlightedinDevelopmentSet(27Classes),designating22
rely on K-nearest neighbors (KNN) with a constant K value
classesasKnownand5asNovel.Theimplementationoffew-
of 5 across all experiments.
shot learning entailed selecting K=5 representative images for
each of the 22 Known classes, generating their embedding
B. Results & Discussion
vectors, and subsequently validating them against other im-
In our exploration of the [32] and [21] datasets, our initial ages from the same classes. Notably, utilizing the few shot
classification efforts yielded impressive results, achieving a technique on training set, we identified an optimal threshold
flawless1.0F1-Scorefor[32]andan0.84F1-Scorefor[21]as using Youden Index to discern the separation between Known
highlighted in Figure 8 above. However, this success brought andNovelclasses,crucialforevaluatingtheperformanceofthe
to light a notable challenge: the models’ outstanding perfor- embedderonthetestingset.Fortestingset,Wetookthisastep
mance on [32] revealed a significant limitation, specifically in further by introducing 16 completely new classes, all unseen
terms of cross-contamination. This issue arose when identical duringtheembedder’straining.Outofthese,weutilized13as
images were present in both the training and testing sets Knownand3asNovelasmentionedinTestingSet(16Classes).
of same class as well as in different class. Consequently, Given that threshold selection is based on the development
this prompted a critical reassessment of improved dataset to set, certain architectures exhibit excellent performance on
address and mitigate this unexpected phenomenon. development data but struggle on the test set. A closer exami-
In the [32] dataset, the challenge of overfitting is primarily nationofSwinV2’sdistributionsrevealsaconsiderablesepara-
driven by a complex interplay of multiple factors. These tionbetweenKnownandNovelclassesinthedevelopmentset,
include labeling errors, inconsistent class definitions and the with minimal overlap. However, this architecture undergoes a
absence of a canonical data split. Labeling inaccuracies have significant transformation in range and representation on the
proven to be a significant hurdle, causing our experimental testset.TheF1-ScoreofbiparitioningontheIndependentTest
deep learning models to memorize specific, often erroneous Set stands at 0.83.
features within the training data. As a result, the models EfficientNet, on the other hand, manifests a broader devel-
fixate on these unique details, failing to grasp the general opment distribution but contracts significantly on the test set
characteristics crucial for accurate classification. Furthermore, however the data separation remain roughly intact. It achieves
the absence of a well-defined data split complicates the an F1-Score Bipartitioning of 0.827 on the Independent Test
evaluationofamodel’sabilitytogeneralize.Thiscomplicates Set. Even though this score seems great however it is still
matters by potentially leading to overfitting on the validation the worst performer amongst other architectures. The largest
set, where models might perform remarkably well due to model in our study, ConvNext, achieves the highest F1-Score
getting overly familiar to specific validation set features. The Bipartitioning on the test set standing at 0.936.
issues extend to classes like B-2, achieving perfect scores ResNet showed the second best performance on biparti-
despite being indistinguishable from others. The inconsistent tioning. The distributions generated by it are much wider
class definitions, as seen in the ’Boeing’ class, further worsen compared to any other architecture and it retains it’s perfor-
overfitting concerns. Additionally, the F-16 class contained mance on both development and test set. It achieves an F1-
images unrelated to the actual F-16 aircraft, underlining the Scorebipartitioningof0.892ontheindependenttestsetbeing
necessity of accurate data labeling and maintaining consistent roughly 3% less than ConvNext.
class definitions for effective model training. Balancing the Each architecture exhibits unique properties on the devel-9
Fig.7. HistogramshowingKnownvsNovelclassdistributionsforStateofArtdeeplearningarchitectureswhereX-axisrepresentDistance&Y-axisrepresent
theFrequencyonMTARSI-INNAR[23]DevelopmentandIndependentTestSets.
Fig. 9. ROC Curve on Test Set between Known and Novel where Novel
correspondstoPositiveclass
exhibitssuperiorperformancecomparedtootherarchitectures,
Fig.8. ComparativeAnalysisofMTARSI[32]&[21].F1Scorehighlights striking a balance between sparseness (evidenced by a higher
cleardeclineinperformanceofvariousdeeplearningarchitecturesonNoisy
F1-score) and generalizability across datasets. With consistent
(left)&lessNoisy(Right)datasets
distributions and minimal overlap between Known and Novel
classes in both training and test sets, ConvNext achieves F1-
opment and test set. The confusion matrix highlights their Scores of 0.8879 on the development set and 0.8612 on the
intricacies on the Independent Test set in Figure 10 a). testing sets revealing a modest 2% decline. This decline is
Apart from bipartitioning performance, it is also important the smallest among other models in classification, indicating
to evaluate each architecture’s performance on the classifi- the model’s robustness. ConvNext’s balanced and consistent
cation of aircraft within the Known Class. For this, we’ve performance underscores its efficacy in handling both Known
computed weighted F1-Score Aircraft Types. SwinV2 per- and Novel classes as well as classification.
forms the worst here on both the development and test set. The radar plot in Figure 10 b) shows F1-scores obtained
It achieves an F1-Score of 0.847 on the development set by each method on the test set. ResNet exhibits diverg-
putting which then drops down to 0.7053 on the test set. ing performance pattern. It demonstrates an intense focus
In contrast, EfficientNet is able to achieve an F1-Score of on specific classes, attaining remarkably high F1-Scores for
0.7224 which is 2% better than that of SwinV2 however the them but exhibits sub-optimal performance for other classes,
difference is not very significant. Both of these architectures particularly struggling with T-1A and Light AC, where it
fail to produce sparse embedding representations in our case. recordsF1-Scoresof0.39and0.3,respectively.Ofsignificance
The distributions of both of these architectures are the most is ResNet’s noteworthy competence in recognizing Novel
compact as visible in Figure 7. classes, positioning itself as the second-best performer in this
ResNet even though being a relatively outdated model than regard. It is worth noting that across all architectures, there
SwinV2 and EfficientNet is able to achieve an F1-Score of is a unanimous struggle in accurately classifying the ARJ-21
0.8358 on the development set and 0.7668 on the test set. class, owing to its significant similarity to the ATR-72 — a
ResNet also exhibits the decline in performance which could distinction discussed in previous sections.
beduetothedifferenceofclassesinembeddertrainingsetand The challenges persist across various aircraft classes, such
testset.Incontrast,ourtop-performingarchitectureConvNext asLightAC,RC-135,andT-1A,whereallarchitecturesexhibit10
Fig.10. Evaluationontestsetofvariousarchitectures.a)Biparitioningperformancevisualizationusingconfusionmatrixandclass-wisef1-scorebetween
ActualandPredictedlabelsofKnownvsNovelonTestSet.b)RadarplotshowingtheperformanceonMTARSI-INNAR[23]Testsetfor13Knownclasses
&Novelclass.Stateofartdeeplearningmodels’F-1ScoreonbestperformingATR-72,B-57,DC-4EaircraftbutshowperformancedeclineonARJ-21and
LightAC.
subpar performance. Nevertheless, a compelling revelation appropriate threshold becomes impossible. Similarly, INNAR
emerges in the performance of ConvNext, which maintains distinguishes all unseen aircraft types as Novel but it do not
an F1-Score of approximately 0.72 on Novel classes. This further classify each sub-type within the Novel Category.
achievement stands out prominently within the context of our
anticipatedresults,showcasingConvNext’srobustadaptability
VI. CONCLUSIONANDFUTUREWORK
and effectiveness in handling previously unseen classes.
The INNAR being potentially extendable presents a well- This paper presents an innovative methodology for the
structured and comprehensive approach to tackling image recognition of military aircraft from remote sensing imagery,
classificationchallengesanddistinguishingbetweenNoveland utilizingembeddingandsimilaritymetricsforprecisefew-shot
Known classes in the context of aircraft recognition. While learning across both Known and Novel aircraft classes. Our
the INNAR effectively addresses and adept challenges in experimental evaluation, encompassing a variety of architec-
aircraft recognition, its current pipeline has a limitation of tures of different scales and complexities, reveals a significant
considering image-based embedding space only and not ac- trend:largermodelsdemonstrateenhancedperformanceinour
commodatingdiversesensor(multi-modal)inputsfordecision- scenario, highlighting their ability to generate sparse vector
making, like radar and infrared data that will further enhance representations and capture nuanced insights effectively.
the accuracy and impact of automated combat identification. In addition to evaluating the performance of different ar-
For an effective identification of new aircraft types, INNAR chitectures, we have addressed challenges in dataset quality,
needs an intermediate dataset (Development Set) with unseen effectively mitigating issues of cross-contamination and erro-
aircraft types as a Novel class; without it, determining the neous annotations. With a focus on robustness, our approach11
Fig.11. PerformancecomparisonofF1-ScoreClassificationagainstF1-ScoreBipartitioning.Thesizeofeachpointhighlightstheparametersofarchitecture
offers a promising solution for the aviation industry and re- [6] Mohsin Bilal, Yee Wah Tsang, Mahmoud Ali, Simon Graham, Emily
searchers striving for efficient recognition within the complex Hero, Noorul Wahab, Katherine Dodd, Harvir Sahota, Shaobin Wu,
Wenqi Lu, et al. Development and validation of artificial intelligence-
domain of military aircraft from satellite imagery. As we look
basedprescreeningoflarge-bowelbiopsiestakenintheukandportugal:
to the future, we emphasize the need for diverse datasets that a retrospective cohort study. The Lancet Digital Health, 5(11):e786–
cover a wide range of aircraft types. These datasets not only e797,2023.
[7] Gong Cheng, Junwei Han, and Xiaoqiang Lu. Remote sensing image
enable more comprehensive research but also promote the
sceneclassification:Benchmarkandstateoftheart. Proceedingsofthe
developmentofadvancedalgorithmsessentialforaccurateand IEEE,105(10):1865–1883,2017.
nuanced aircraft type recognition. The practical implications [8] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-
Fei.Imagenet:Alarge-scalehierarchicalimagedatabase.In2009IEEE
of fine-grained classification span various domains, including
conferenceoncomputervisionandpatternrecognition,pages248–255.
aviation, defense, and other sectors where precise aircraft Ieee,2009.
identification is of utmost importance. [9] JianDing,NanXue,Gui-SongXia,XiangBai,WenYang,MichaelYing
Yang, Serge Belongie, Jiebo Luo, Mihai Datcu, Marcello Pelillo, and
Liangpei Zhang. Object detection in aerial images: A large-scale
ACKNOWLEDGMENTS benchmarkandchallenges. IEEETransactionsonPatternAnalysisand
MachineIntelligence,44(11):7778–7796,2022.
We are grateful to the pilots and remote sensing special- [10] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weis-
ists (Murad Ali, Saleem Raza, Shahbaz Ahmad, and Usman senborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani,
Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is
Qamar) and their assistants for their expertise and dedication
worth16x16words:Transformersforimagerecognitionatscale. arXiv
in refining the MTARSI [32] dataset. Their careful analysis preprintarXiv:2010.11929,2020.
ofremotesensingimageryimprovedthedataset’squality[23] [11] Kun Fu, Wei Dai, Yue Zhang, Zhirui Wang, Menglong Yan, and
Xian Sun. Multicam: Multiple class activation mapping for aircraft
and reliability, contributing to the progress of remote sensing.
recognitioninremotesensingimages.Remotesensing,11(5):544,2019.
[12] KyleGao,HongjieHe,DeningLu,LinlinXu,LingfeiMa,andJonathan
REFERENCES Li. Optimizing and evaluating swin transformer for aircraft classifica-
tion:Analysisandgeneralizabilityofthemtarsidataset. IEEEAccess,
[1] SalmanAhmed,HaashabinAtif,MuhammadBilalShabbir,andHam- 10:134427–134439,2022.
madNaveed.Prnet:Progressiveresolutionbasednetworkforradiograph [13] Zhang.J.Gu.Y.,Zhang.Y. Integrationofspatial–spectralinformation
based disease classification. In 2021 Ethics and Explainability for for resolution enhancement in hyperspectral images. IEEE Trans.
ResponsibleDataScience(EE-RDS),pages1–5.IEEE,2021. Geosci.RemoteSensing,2008.
[2] D.H. Andrews, L.C.R.P. Herz, M.B. Wolf, P.D. Harris, E. Salas, and [14] Yonghui Guo, Yuntao Li, and Yu Zhang. Research on mimo-isar
P.N.A.Stanton.HumanFactorsIssuesinCombatIdentification.Human high resolution imaging technology. In 2021 IEEE 4th Advanced
FactorsinDefence.AshgatePublishingLimited,2012. Information Management, Communicates, Electronic and Automation
[3] FaisalAzam,AkashRizvi,WazirZadaKhan,MohammedYAalsalem, ControlConference(IMCEC),volume4,pages169–174.IEEE,2021.
HeejungYu,andYousafBinZikria.Aircraftclassificationbasedonpca [15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
and feature fusion techniques in convolutional neural network. IEEE residual learning for image recognition. In Proceedings of the IEEE
Access,9:161683–161694,2021. conferenceoncomputervisionandpatternrecognition,pages770–778,
[4] MohsinBilal,RobertJewsbury,RuoyuWang,HammamMAlGhamdi, 2016.
Amina Asif, Mark Eastwood, and Nasir Rajpoot. An aggregation [16] G. Krizhevsky, A.; Hinton. Learning multiple layers of features from
of aggregation methods in computational pathology. Medical Image tinyimages. UniversityofToronto:Toronto,ON,Canada,2009.
Analysis,page102885,2023. [17] Binquan Li, Yuan Yao, and Qiao Wang. Domain adaptive few-shot
[5] Mohsin Bilal, Mohammed Nimir, David Snead, GrahamS Taylor, and learning for isar aircraft recognition with transferred attention and
NasirRajpoot. Roleofaianddigitalpathologyforcolorectalimmuno- weightingimportance. Electronics,12(13):2909,2023.
oncology. BritishJournalofCancer,128(1):3–11,2023. [18] GeLiu,XianSun,KunFu,andHongqiWang. Aircraftrecognitionin12
high-resolution satellite images using coarse-to-fine shape prior. IEEE [30] YanfengWang,TaoWang,XinZhou,WeiweiCai,RunminLiu,Meigen
GeoscienceandRemoteSensingLetters,10(3):573–577,2012. Huang,TianJing,MuLin,HuaHe,WeipingWang,etal. Transeffidet:
[19] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, aircraftdetectionandclassificationinaerialimagesbasedonefficientdet
Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision and transformer. Computational Intelligence and Neuroscience, 2022,
transformer using shifted windows. In Proceedings of the IEEE/CVF 2022.
internationalconferenceoncomputervision,pages10012–10022,2021. [31] Qichang Wu, Hao Sun, Xian Sun, Daobing Zhang, Kun Fu, and
[20] Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Hongqi Wang. Aircraft recognition in high-resolution optical satellite
Andrea Vedaldi. Fine-grained visual classification of aircraft. arXiv remotesensingimages. IEEEGeoscienceandRemoteSensingLetters,
preprintarXiv:1306.5151,2013. 12(1):112–116,2014.
[21] RRudd-OrthnerandLMihaylova.Multi-typeaircraftofremotesensing
[32] Z Wu. Multi-type aircraft of remote sensing images: Mtarsi. Zenodo.
images:Mtarsi2. Zenodo,2021.
org,10,2019.
[22] Ahmad Saeed, Haasha Bin Atif, Usman Habib, and Mohsin Bilal.
[33] Zhi-ZeWu,Shou-HongWan,Xiao-FengWang,MingTan,LeZou,Xin-
Remotesensingaircraftclassificationharnessingdeeplearningadvance-
ments.In202318thInternationalConferenceonEmergingTechnologies LuLi,andYanChen.Abenchmarkdatasetforaircrafttyperecognition
(ICET),pages50–55,2023.
fromremotesensingimages.AppliedSoftComputing,89:106132,2020.
[23] Ahmad Saeed, Haasha Bin Atif, Mohsin Bilal, and Usman Habib. [34] Gui-SongXia,JingwenHu,FanHu,BaoguangShi,XiangBai,Yanfei
Mtarsi-innar. Zenodo.org,January2024. Zhong, Liangpei Zhang, and Xiaoqiang Lu. Aid: A benchmark data
[24] Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A set for performance evaluation of aerial scene classification. IEEE
unifiedembeddingforfacerecognitionandclustering.InProceedingsof Transactions on Geoscience and Remote Sensing, 55(7):3965–3981,
theIEEEconferenceoncomputervisionandpatternrecognition,pages 2017.
815–823,2015. [35] Yi Yang and Shawn Newsam. Bag-of-visual-words and spatial exten-
[25] Tao.Lei Song.F, Peng.Z. Raih-det: An end-to-end rotated aircraft and sions for land-use classification. In Proceedings of the 18th SIGSPA-
aircraftheaddetectorbasedonconvnextandcyclicalfocallossinoptical TIAL international conference on advances in geographic information
remotesensingimages. IEEETrans.Geosci.RemoteSensing,2023. systems,pages270–279,2010.
[26] XianSun,PeijinWang,ZhiyuanYan,FengXu,RuipingWang,Wenhui [36] YuhangZhang,HaoSun,JiaweiZuo,HongqiWang,GuangluanXu,and
Diao, Jin Chen, Jihao Li, Yingchao Feng, Tao Xu, et al. Fair1m: A Xian Sun. Aircraft type recognition in remote sensing images based
benchmarkdatasetforfine-grainedobjectrecognitioninhigh-resolution on feature learning with conditional generative adversarial networks.
remotesensingimagery.ISPRSJournalofPhotogrammetryandRemote RemoteSensing,10(7):1123,2018.
Sensing,184:116–130,2022.
[37] BaojunZhao,WeiTang,YuPan,YuqiHan,andWenzhengWang. Air-
[27] Bin Tan, Qiuni Li, Tingliang Zhang, and Hui Zhao. The research of
crafttyperecognitioninremotesensingimages:Bilineardiscriminative
air combat intention identification method based on bilstm+ attention.
extremelearningmachineframework. Electronics,10(17):2046,2021.
Electronics,12(12):2633,2023.
[28] Wei Tang, Chenwei Deng, Yuqi Han, Yun Huang, and Baojun Zhao. [38] Qi Zhao, Shuchang Lyu, Yuewen Li, Yujing Ma, and Lijiang Chen.
Srarnet:Aunifiedframeworkforjointsuperresolutionandaircraftrecog- Mgml:Multigranularitymultilevelfeatureensemblenetworkforremote
nition. IEEEJournalofSelectedTopicsinAppliedEarthObservations sensingsceneclassification.IEEETransactionsonNeuralNetworksand
andRemoteSensing,14:327–336,2020. LearningSystems,2021.
[29] Ferhat Ucar, Besir Dandil, and Fikret Ata. Aircraft detection system [39] Weixun Zhou, Shawn Newsam, Congmin Li, and Zhenfeng Shao.
basedonregionswithconvolutionalneuralnetworks.InternationalJour- Patternnet:Abenchmarkdatasetforperformanceevaluationofremote
nal of Intelligent Systems and Applications in Engineering, 8(3):147– sensingimageretrieval. ISPRSjournalofphotogrammetryandremote
153,2020. sensing,145:197–209,2018.