SubmittedtoEUROVIS2024 PREPRINT
... Volume000(2024),Number0
... STAR–StateofTheArtReport
Open Your Ears to Take a Look:
A State-of-the-Art Report on the Integration of Sonification and
Visualization
K.Enge1,2 ,E.Elmquist4 ,V.Caiola3 ,N.Rönnberg4 ,A.Rind1 ,M.Iber1 ,
S.Lenzi5 ,F.Lan6 ,R.Höldrich2 ,andW.Aigner1
1St.PöltenUniversityofAppliedSciences,St.Pölten,Austria
2UniversityofMusicandPerformingArtsGraz,Graz,Austria
3CityUniversityofHongKong,Kowloon,HongKong
4LinköpingUniversity,Linköping,Sweden
5UniversidaddeDeusto,Bilbao,Spain
6UniversityofUtah,SaltLakeCity,USA
Abstract
Theresearchcommunitiesstudyingvisualizationandsonificationfordatadisplayandanalysisshareexceptionallysimilar
goals,essentiallymakingdataofanykindinterpretabletohumans.Onecommunitydoessobyusingvisualrepresentationsof
data,theothercommunitydoessobyemployingauditory(non-speech)representationsofdata.Whilethetwocommunities
havealotincommon,theydevelopedmostlyinparalleloverthecourseofthelastfewdecades.WiththisSTAR,wediscuss
acollectionofworkthatbridgesthebordersofthetwocommunities,henceacollectionofworkthataimstointegratethe
twotechniquestooneformofaudiovisualdisplay,whichwearguetobe“morethanthesumofthetwo.”Weintroduceand
motivateaclassificationsystemapplicabletosuchaudiovisualdisplaysandcategorizeacorpusof57academicpublications
thatappearedbetween2011and2023incategoriessuchasreadinglevel,datasettype,orevaluationsystem,tomentionafew.
Thecorpusalsoenablesameta-analysisofthefield,includingregularlyoccurringdesignpatternssuchastypeofvisualization
andsonificationtechniques,ortheuseofvisualandauditorychannels,andtheanalysisofaco-authornetworkofthefieldwhich
showsindividualteamswithoutmuchinterconnection.ThebodyofworkcoveredinthisSTARalsorelatestothreeadjacent
topics:audiovisualmonitoring,accessibility,andaudiovisualdataart.Thesethreetopicsarediscussedindividuallyinaddition
tothesystematicallyconductedpartofthisresearch.Thefindingsofthisreportmaybeusedbyresearchersfrombothfieldsto
understandthepotentialsandchallengesofsuchintegrateddesigns,whileinspiringthemforfuturecollaborationwithexperts
fromtherespectiveotherfield.
1. Introduction bythedefinitionofthevisualidiombyMunzner[Mun15],wethink
ofanaudiovisualdisplayidiomas“adistinctapproachtocreating
Overthecourseofthelastfewdecades,tworesearchcommunities andmanipulatingaudiovisualrepresentationsofdata.”
have developed largely in parallel: one studying data visualiza-
tion and one studying sonification. While the visualization com- Inourdailylives,weperceiveoursurroundingsinaninherently
munityisprimarilyinterestedin“theuseofcomputer-supported, multimodalway.Weseeandwehear,wereadbooksandwelisten
interactive,visualrepresentationsofabstractdatatoamplifycog- tomusic.Weuseoursensestounderstandandexploretheworld
nition”[CMS99],thesonificationcommunitystudies“theuseof aroundus.Althoughwearemultisensorialbeings,thepredominant
non-speechaudiotoconveyinformation”[KWB∗99].Tothisday, data analysis idioms are uni-modal. Sight and hearing are inher-
thecommunitiesseemtobelargelydisjunct,despitetheirshared entlydifferent,withdifferentstrengthsandchallenges,andaremost
goalspromisingfruitfulcollaboration.Boththetheoreticalcross- probablysuitablefordifferentapproachesindatarepresentation.
pollination[ERI∗23,CLR22],andthepracticalintegrationandcom- Thevisualperceptioncanlookuponavisualrepresentationina
binationofsonificationandvisualizationofferpotentialforinterest- non-linearfashion,andtheuseofdifferenttypesofgraphs,charts,
ingresearchoutcomes.Therefore,withthisstate-of-the-artreport andothervisualformats,canrevealpatterns,correlations,andtrends
(STAR),wewanttoshedlightonaudiovisualdisplayidiomsthatsys- indatathatareoftennotasnoticeableinnumericalform.Visual
tematicallyintegratedatavisualizationandsonification.Informed representationsofdatacanalsobeexperiencedasmoreengaging
©2024TheAuthors.
ThisisanopenaccessarticleunderthetermsoftheCreativeCommonsAttributionLicense,which
permitsuse,distributionandreproductioninanymedium,providedtheoriginalworkisproperly
cited.
4202
beF
62
]CH.sc[
1v85561.2042:viXra2of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
andmemorabletoausercomparedtotableswithnumbers[FPS∗21]. themeaningoftheearconbeforeitcanbebeneficiallyused.Audi-
Sonification,ontheotherhand,exploitstheexcellentabilityofthe toryiconsarealsoshortdistinctivesoundsbutaresoundsnippetsof
humanauditorysystemtorecognizetemporalchangesandpatterns. realsoundthatarepresentineverydaylife.Thismeansthatthere
Itis,therefore,usefulwhendisplayingcomplexpatterns,suchas isanassociationbetweentheauditoryiconandtheeventtheyare
changesintime,andwarningsforimmediateaction.Inreal-time usedtorepresent.
environments,sonificationallowsacontrollertoperceiveinforma-
A brief history of sonification: While the discipline of visual-
tionwithouttheconstantmonitoringofvisualdisplays.Sonification
izationhasarelativelylonghistory[Fri08],theresearchfieldof
alsoenablesthecommunicationofdataandinformationforvisually
sonification is younger [Fry05], essentially starting with its first
impairedindividuals[WM10].
InternationalConferenceonAuditoryDisplayin1992.Thepro-
Thevisualperceptionhassomechallengesthatcanbesupported ceedingsofthisfirstconferencewerepublishedin1994inthebook
bysonification,andsimilarlytheauditorysystemhasotherchal- AuditoryDisplay[Kra94].Whenitwaspublished,thebookwas
lenges that in turn can be supported by visualization. Therefore, alsoareflectiononthepotentialsofthenewbornfieldofresearch
webelievethatawell-designedaudiovisualrepresentationcanbe andthenewbornInternationalCommunityForAuditoryDisplay
morethanthemeresumofavisualandanauditoryrepresentation. (ICAD).Earlyon,Barrass[Bar97]presentedatasktaxonomyfor
Toputthisintopractice,wewanttorefertoatypicalreal-world auditorydisplays,calledTaDa!,whichstandsforTasksandData.
situationwherethecombinationofvisualandauditoryinputsaid TheTaDa!taxonomyisespeciallyrelevantinthecontextofthis
usinreachingamoreinformedconclusion:imaginerainfalling STAR, as it is well-aligned with taxonomies from the visualiza-
outsideofawindow.Itoftenishardtocorrectlyestimatethedensity tionliterature[Ber83,BM13,SNHS13,Shn96,YKSJ07],anditalso
oftherainbyjustlookingoutsideofaclosedwindow.Itisalso functionsasinspirationfortheclassificationappliedlaterinthis
noteasytoestimatetheamountofrainwhenonlylisteningtoit STAR.
withyoureyesclosed.Itistheholisticaudiovisualperspective,that
The book Ecological Psychoacoustics, edited by Neuhoff in
perceptuallyintegratesbothofoursenses,thatallowsustobest
2004[Neu04],challengedmanypsychoacousticalstudies(being
determinewhetherweshoulduseanumbrellaorevenstayindoors.
thepartofpsychophysicsthatinvolvesthescientificstudyofsound
Inspiredbythecapabilitiesofthehumanvisualandauditorysys- perception,traditionallyconductedincontrolledlaboratoryenviron-
tems,andthepossibilitytointegratevisualizationandsonification, ments).Neuhoffpromotedanecologicalsoundapproachtosoni-
thisSTARcoversacademiccontributionsfromboththevisualization ficationfromaholisticperspective,whichechoestheaimsofthe
andthesonificationcommunitiesthatblendsonificationandvisual- BELIVworkshopseriesestablishedin2006attheAdvancedVisual
izationwithinthecontextofdataexplorationanddatapresentation. Interfacesconference[BPS06].Neuhoff’sinterventionunderscores
WehopethisSTARwillhelpbothvisualizationandsonification theneedtoconsiderreal-worldcontextsfortransformingdesign
researchersrealizethepotentialofsuchcombinationsandfoster principlesandmethodologiesforauditorydisplaysfromtheoryto
futurecollaborationsbetweentwooftendisjunctcommunities. practice.Thisperspectiveemphasizedintegratingecologicalfactors
insonificationtoincreaseeffectivenessanddeepentheconnection
betweenauditorystimuliandreal-worldexperiences.
1.1. SonificationBackground
ThisSTARbeingpublishedatavisualizationvenuecallsforabrief Thesonificationdesignspacemapwasintroducedin2007by
introductiontothesonificationtechniquesthatarepartofourdata deCampo[dC07],guidingadesigner’sdecision-makingprocessof
(foramorecomprehensivedescriptionofthedifferenttechniquessee selectinganappropriatesonificationtechniquefortheirtask.The
theSonificationHandbook[HHN11]).Audificationisatechnique mapcovesatwo-dimensionalspacebetweenthenumberofdata
forrepresentingsequencesofdatavaluesthataretransformedinto properties a designer intends to sonify, and the number of data
sound.Thissoundisatranslationofthedatavaluesintotheaudible points that is necessary for the different sonification techniques
domain,intermsoffrequencyandloudness.Audificationtypically tobeemployedinanadequatemanner.Retrospectively,another
representsasequenceofdataasanaudiowaveform,thatthencan milestonewithinthesonificationcommunitywastheintroduction
beprocessedwithvarioussignalprocessingtechniquestofurther ofthenowwidelyaccepteddefinitionofsonificationasascientific
assessdatafeatures.Parametermappingsonificationinvolvesthe techniqueforrepresentingdata,presentedbyHermann[Her08]in
associationofdatavalueswithauditoryparameterssuchaspitch 2008.Beforetheintroductionofthisdefinition,itwaslessclear
orloudness.Thesoundisdependentonthemappingfunctionbe- wheretodrawtheborderbetweenartisticandscientificmappings
tween the data and the auditory parameter and the nature of the fromdatatosound(whichbringstomindthediscussionthatdata
mapping,forexamplebeinglineartolinearorlineartoexponential. visualizationismorethanjustprettypictures).Asitreflectsour
Model-basedsonificationisageneraltermforvarioussonification understandingofthetermsonification,wewanttorefertothefull
techniquesthatmakeuseofdynamicmodelsofchangesinasystem definitionbelow:
overtime.Thesoundisdependentonasonificationmodelbased
“Atechniquethatusesdataasinput,andgeneratessoundsig-
onthedynamicsofasystemthatgeneratesandchangesthesound
nals (eventually in response to optional additional excitation or
inrelationtoexcitationscausedbyuserinteraction.Earconsare
triggering)maybecalledsonification,ifandonlyif
shortdistinctivesoundsthatareusedtorepresentspecificeventsor
conveyinformation.Thesesoundsareoftensynthesizedtonesor Thesoundreflectsobjectivepropertiesorrelationsintheinput
•
soundpatternsandcanbedescribedasdesignedorcomposedsound data.
symbols.Thispresupposesanunderstandingandagreementabout Thetransformationissystematic.Thismeansthatthereisapre-
•
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 3of27
cisedefinitionprovidedofhowthedata(andoptionalinterac- sonificationmappingsthathavebeenusedinscientificallyevaluated
tions)causethesoundtochange. designs.Unfortunately,thewebsiteisnolongeravailable.Another
Thesonificationisreproducible:giventhesamedataandidentical moretimelyandexhaustiveexplorationofsonificationliterature
•
interactions(ortriggers)theresultingsoundhastobestructurally emergesinAndreopoulouandGoudarzi’s2021publication[AG21].
identical. Theauthorsreviewed456papersfromtheInternationalConference
Thesystemcanintentionallybeusedwithdifferentdata,andalso onAuditoryDisplayproceedings.Thisincisiveanalysisexposes
•
beusedinrepetitionwiththesamedata.” compellingtrends,rangingfromthesonificationdomainstothedi-
versepublicationvenues.Thereportrevealslinguistictrendsandex-
TheSonificationHandbook[HHN11],publishedin2011,pro-
ploresthebalancebetweenresearchandartisticcontributions.Inad-
videdthefirstgeneralandoverarchingperspectiveonthefieldof
dition,itilluminatesthelandscapeoftools,methodologies,andeval-
sonification,discussingboththeoryandpracticeofsonification.The
uationpracticesthathaveledtosonification’smultifacetedevolution.
Handbookisstillthemostcomprehensivecollectionofsonifica-
Markingthebeginningasocioculturalreflectionwithinthesonifica-
tionwork,andthereforeitspublicationyearin2011alsomarksthe
tioncommunity,in2017,AndreopoulouandGoudarzi[AG17]also
beginningofthetimeperiodconsideredinourSTAR.
studiedthe“representationoffemaleresearchersandartistsinthe
Throughtheyears,variousdesignframeworksforsonification conferencesoftheInternationalCommunityforAuditoryDisplay
have been proposed. The design framework proposed by Bar- (ICAD)”.Theirfindingsshowedthatonlyabout18%ofICADpa-
rass[Bar12],emphasizingthefusionofaestheticsandfunctionality perswereco-authoredbywomen,withstagnantnumbersbetween
toenhancetheaccessibilityandmeaningfulnessofsonificationsfor theyears1994and2016.
abroaderaudience.TheworkdonebyWorrallin2019[Wor19b]
Withrespecttocombinationsofvisualizationandsonification,
formalizedsonificationtechniquesintoaframeworkthatalsohigh-
Caiolaetal.[CLR22]recentlypresentedananalysisofvisualand
lightedchallengesandadvantagesofthesesonificationtechniquesas
auditorychannelscommonlyusedinaudiovisualdisplayidioms.
wellastheimportanceofunderstandingtheprocessandthechoices
Theirsurveyincludescombinedidiomsthatmapdataattributesre-
thatinfluencesoundrepresentation.Thesonificationdesigncanvas,
dundantlytobothavisualchannel(suchasposition)andanauditory
introducedbyLenziin2021[Len21],isacontributiontoconstruct-
channel(suchaspitch).AnalyzedworksstemfromtheSonifica-
ingamorecomprehensivedesignframework,aimingtointegrateall
tionArchive(describedbelow)andaGooglekeywordsearchusing
aspectsintoacohesivedesigntool.Despitetheseefforts,developing
sonification-relatedtermsexclusively.(SonificationArchive),widely
acomprehensiveprotocolthatsystematicallyconsidersend-usersat
knowninthesonificationcommunity,isacuratedcollectionofsoni-
eachstageofthedesignprocesshasyettobeachieved.
ficationdesigns,oftenrelatedtoothermodesofrepresentation,such
Morethan30yearsafterthebeginningofsystematicsonification as visualization. The sonification archive holds both artistic and
research,wesawaconsiderablenumberoftheoreticalcontributions academiccontributions,aswellasdesignsfromdatajournalism.
tothefield[Kra94,KWB∗99,VH06,dC07,NW08,HHN11,GH12,
Searchingthroughthevisualizationliterature,wewerenotable
Sup12,Nee19,Neu19,Wor19b,Len21],nevertheless,explicitwork
tofindanySTARorsurveyfocusedontheintegrationofsonifica-
integratingsonificationandvisualizationtheoryisrare.Inanat-
tionandvisualization.Weexploredthesurveyofsurveys[ML17]
tempttofindacommonlanguageandthereforebuildatheoretical
butcouldnotidentifyanyrelatedcontributions.Therefore,tothe
bridgebetweenthevisualizationandthesonificationcommunities,
bestofourknowledge,thisisthefirstsystematicSTARdedicated
Engeetal.[ERI∗23]introducedthreetheoreticalconstructsmeant
to academic contributions in the intersection of sonification and
toformallydescribeaudiovisualdisplayidioms.Theydefinedthe
visualizationfordataexplorationandpresentation.
“auditorymark”inspiredbythevisualmark,the“auditorychannel”
inspiredbythevisualchannel,andthe“substrateofsonification”
inspiredthespatialsubstratethatisemployedinvisualizationthe- 1.3. HowtoUseThisSurvey
ory[Ber83,CMS99].Thedefinitionoftimeasthesubstrateofsoni-
With this STAR we intend to provide an overview of an emerg-
ficationallowsadescriptionofsonificationdesignswithauditory
ingresearchfield,aswellasconnecttwomostlydisjointresearch
marksbeingplacedintime,withdataencodedintotheirauditory
communities.Wehopetoreachresearchersfrombothcommunities,
appearanceusingauditorychannelssuchaspitchofloudness.These
inspiringthemforintertwiningsonificationandvisualizationintheir
definitionsallowtheahighleveldiscussionandcategorizationof
futureresearch.WeseeseveralwaysofusingthisSTAR:
boththevisualandtheauditorypartofanaudiovisualdisplayidiom.
Thetheoreticalconstructsprovedusefulsothatweadoptedtheterm using it as an overview, intended for researchers who seek a
•
ofauditorychannelsforourclassificationinthisSTARaswell. summaryofthefield.
usingittofindresearchopportunitiesandexistinggapsinthe
•
field.
1.2. RelatedWorkandSurveys usingoursupplementalmaterialtostudytheexistingmeta-data
•
inmoredetail,suchasidentifyingauthorsfromtherespective
Ingeneral,systematicstate-of-the-artreportsarelessestablished
otherfieldforpotentialcollaboration.Furthermore,weprovidea
inthesonificationcommunity.Arareexceptionisthe“systematic
publicZoterolibrary,holdingallrelevantpublicationmetadata,
reviewofmappingstrategiesforthesonificationofphysicalquan-
ourtags,andallopenaccessPDFs.
tities”byDubusandBresin[DB13],which,however,justcovers
sonification-onlycontributions.Muchearlier,in2001,Walkerand This STAR will be structured as follows: section 2 describes
Lane[WL01]providedawebsiteenablingresearcherstosearchfor themethodologyusedtosearchandfiltertheliteratureidentified
©2024TheAuthors.4of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
aspotentiallyrelevant.Insection3wedescribeourclassification discussingalistofrepresentativeworks,thatservesasastarting
systemanduseittodiscussthesurveyliterature.Insection4we pointforfutureresearchinterests.
applyametaperspectiveonthesurveydata,describingcorrelations
betweenindividualtags,aswellastheco-authornetworkofthefield.
2.2. SearchStrategyandFiltering
Insection5weintroducethethreeadjacenttopicsofaccessibility,
monitoring,andarts,whicharerelatedtoourSTAR,butwerenot Webaseourcorpusofliteratureonpublicationsthattheauthorshave
systematicallystudied.Finally,insection6,weofferaconcluding alreadybeenawareoffromtheirpreviousworkinthisfieldandbyan
discussionfocusingonfuturework. extensiveonlineliteraturesearch.Theonlinesearchwasakeyword-
basedsearchinthedigitallibrariesofIEEEXplore,ACMDigital
Library,andSpringerLink,whichincludeworkpublishedatIEEE
2. Method VIS,CHI,andotherVGTC-andSIGCHI-sponsoredvenues.Fur-
Inthissection,wediscussourinclusionandexclusioncriteriaand thermore,wesearchedthedigitallibrariesofEurographics,ICAD,
themethodsweusedtosearchfortherelevantliterature.Weuseda ISon,OrganisedSound,andtheSoundandMusicComputingCom-
five-stagepipelinetoconstructacorpusofresearchworksthatareat munity.Figure1providesanoverviewofthedifferentstageswe
theintersectionofvisualizationandsonificationfordataexploration usedtosystematicallyfilterourdatabaseforrelevantpublications.
andpresentation. Tokeeptrackoftheprogressofidentifyingrelevantpapers,weused
aGooglesheetdocument.Thefinaldatabase,includingallpapers
andalltagsbytheauthors,isprovidedinthesupplementalmaterial
2.1. ScopeoftheSurveyedLiterature asaCSVfile.
Sonificationandvisualizationsharetheaimofmakingdatainter- Stage1–Thesearchqueryweusedinstage1wasthefollowing:
pretabletotheirusersandobservers.Withthissharedgoal,combina- ("Visualization"OR"Visualisation"OR"VisualAnalytics")AND
tionsofthetwocanbedesignedfornumerouspossibleapplications ("Sonification"OR"AuditoryDisplay")ANDNOT(centrifug*OR
andcontexts.OurresearchinterestinthisSTARisthecombina- lys*ORhomogeniz*)ItconsistsofanANDcombinationofavisu-
tionofsonificationandvisualizationinthecontextofdataanalysis, alizationtermandasonificationtermcombinedwiththeexclusion
coveringbothdataexplorationandpresentation.Aworkrelevant ofspecificword-beginnings.Thereasontoexcludepapersthathold
forourSTARmustincludeboth,visualizationandsonificationof wordsstartingwithcentrifug*,lys*,andhomogeniz*isthefactthat
data.Therefore,asonificationwithavisualinterfacethatdoesnot sonification,alsocalledsonication,isatermusedalsoinbiology
representdataisnotenoughtobeconsideredrelevant,neitheris todescribeaprocesswheresoundisusedtoagitateparticlesina
avisualizationswithsoundsthatdonotrepresentdata.Thework sample.Aspapersusingsonificationinthiscontextarenotrelevant
mustbeanacademicpaper,publishedbetweentheyears2011and tothisSTAR,weidentifiedterms,includingthethreementioned
2023andmustbepeerreviewedtobeconsideredinourSTAR. above,thatareoftenassociatedwiththismeaningofsonification.
ThesearchintheSpringerLinkdatabaseespecially,wassensibleto
Thinkingmorebroadlyaboutthecombinationofsonificationand
theexclusionoftheseterms.Astherecouldbefalsenegativesusing
visualization,threeadditionalareasofapplicationcometomind:(1)
theexclusionofthethreeterms,weconductedamanualreviewof
accessibility,(2)real-timemonitoring,and(3)arts.Allthreeareas
thepapertitlesthatwereexcludedduetothisstrategyandrestored
arevast,andadetailedclassificationofthemisbeyondthescope
fivepapersthatwerepotentiallyrelevant.Thisonlinesearch,com-
of our STAR. However, we find them relevant and inspirational
binedwithpaperswewerealreadyawareoffromourpreviouswork
for our field. Thus, we provide a brief introduction to the fields
inthefield,resultedinadatabaseholding1498papers.Todownload
ofaccessibility,monitoring,andartisticcontributionsinsection5.
therespectivepapersandtomakethemavailabletoallco-authors
Inthecontextofaccessibility,sonificationcanbeusedtosupport
weusedtheliteraturemanagementsoftwareZotero.
thecollaborationbetweensightedandnon-sightedindividualsby
mappingdatatobothavisualandanauditorydisplay.Inthesame Stage2–Inthesecondphaseofourliteraturesearch,eachpaper
manner,suchadesigncouldsupportthecollaborationbetweendeaf titlewasreadbytwooftheauthorsandclassifiedintopotentially
individualsandindividualswithouthearingloss.Nevertheless,our relevantorirrelevant.Weagreedtouseaninclusivemindsetfor
researchinterestisthecombinationofsonificationandvisualization thisstage,i.e.,wetaggedvaguetitlesmostlyaspotentiallyrelevant
for the integrated analysis of data. Therefore, in our STAR, we tonotoverlooktoomanypapersatthisearlystage.Forpapersthat
consider only designs intended to be used with both the visual weretaggeddifferentlybytwopeople,thetwopeoplecametoan
andtheauditorysensesfullyavailabletoauser.Theapplication agreementorthepaperwastakentothenextstage.Stage2resulted
ofreal-timemonitoringsuchasmedicalmonitoring,monitoring inadatabaseholding500papers.
of critical infrastructure, alarms, or real-time feedback of body
Stage3–Inthethirdphaseofourliteraturesearch,eachabstract
movement,isvastanddistinctfromthepurposeofdataexploration.
wasreadbytwooftheauthorsandclassifiedintopotentiallyrele-
Especiallywithrespecttosonificationandauditorydisplay,thefield
is well researched (e.g., [KIK19,SJMT19,VRGM20,WMY∗17, vantorirrelevant.Again,weusedaninclusivemindsetandtagged
vagueabstractaspotentiallyrelevant.Forpapersthatweretagged
HRM15]),andwewillnotcoversuchdesignsinthisSTAR.Artistic
differentlybytwopeople,thetwopeoplecametoanagreementor
contributionshavethepotentialtobehighlyinspirationalforour
thepaperwastakentothenextstage.Stage3resultedinadatabase
field,butrequireadifferentsearchmethodandmostlikelyadifferent
holding163papers.
systemofclassification.Again,wedecidedtonotsystematically
coverartisticcontributionsinthisSTAR,buttoprovideasubsection, Stage4–Inthefourthphaseofourliteraturesearch,eachpaperwas
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 5of27
Stage 1 Stage 2 Stage 3 Stage 4 Stage 5 be designed for (subsection 3.2), followed by an analysis of id-
iom design possibilities (subsection 3.3). We will study several
Search ok nn lo iw nn e w so er ak r c& h r te ia td li en sg abr se ta rd ai cn tg s fulr le a pd ai pn eg rs snowballing technicalperspectivesthatweretaggedindividuallyforthesoni-
fication and the visualization aspects of each paper: the reading
R esults po rt e pe l an e pt v ei a ra n sl tl y po rt e pe l an e pt v ei a ra n sl tl y po rt e pe l an e pt v ei a ra n sl tl y re pl ae pv ea rn st rea pld aed pvi ean rng st levels(subsection3.4)suggestedbyBertin[Ber83],thesearchlev-
els (subsection 3.5) suggested by Munzner [Mun15], as well as
thedatasettypes[Mun15]includingthelevelsofmeasurementof
# Papers 1498 500 163 47 b fa oc rk ww aa rr dd :: 55 thedisplayeddata(subsection3.6).Wewillthenreviewdifferent
evaluationmethods(subsection3.8),differenttargetplatforms,and
variouspossibilitiesofinteractingwithaudiovisualdisplayidioms
classification & analysis
of 57 papers (subsection3.9).Finally,westudythediverseusergroupsandthe
possiblegoalsofdesigners(subsection3.10).
Figure1:Theliteraturesearchwasconductedinfivestagesranging
Alltheabovecategoriesandsubcategoriesareconciselypresented
fromanonlinekeywordsearchtousingthesnowballingtechnique
intwotables.Table1showsanoverviewofallpapersandasubset
ontheasrelevantidentifiedpapers.
oftheirmostrelevanttags.Table2providesadetaileddescription
foreachcategoryandtheirrespectivesubcategories.Wealsoreport
onthetotalnumberofpaperswithineachsubcategory.Thefour
technicalcategoriesmentionedabovehavedistinctvisualizationand
readbyoneoftheauthorsandclassifiedasrelevantorirrelevant.As
sonificationtagswhicharerepresentedintheleftandrightboxesin
theauthorshadasolidcommonunderstandingoftheinclusionand
the“Num.”column,respectively.Thecolorsaturationoftheboxes
exclusioncriteriabythisstage,andasapersonhadthefullpaper
encodesthetotalnumberofpapersineachsubcategory.
informationavailabletotakeadecision,onepersondecidedonthe
relevanceatthisstage.Thepapersidentifiedasrelevantinstage4
wereclassifiedusingthetagsexplainedindetailinTable2.Each 3.1. ThematicCorpusOverview
paperwasfirstclassifiedbyoneoftheco-authorsandtheirtags
Scanningourdatabase,weidentifiedsevenastronomyrelatedpa-
werelaterverifiedbyasecondco-author.Whenevertwoco-authors
pers. Riber [Rib18] presented a prototypical virtual and interac-
initiallydisagreedonaspecifictag,theycametoanagreementorthe
tive audio synthesizer called Planethesizer that enables users to
firstauthortookadecision.Stage4resultedinadatabaseholding
designsonifications,especiallyfocusedonplanetarydata.Sonifigra-
47papers.
pher[Rib19]isavirtualsynthesizerthatletsuserssonifythelight
Stage5–Furthermore,weextendedthecorpusofrelevantpapersby curvesdatafromNASA’sexoplanetarchive.Alsotherecentlypre-
snowballing[Woh14],checkingallincomingoutgoingreferences sentedSonifiedHertzsprung-RusselDiagram[HPDW23]sonifies
of the articles matching our inclusion criteria. Snowballing was thelightcurves,withthediagramactingasboththevisualization
donebyoneoftheco-authorswithanexclusivemindsettowards andtheinterfacetochooseastartobesonified.Withthisdesign,
thepapertitles,meaningthatavaguetitlewasnotconsideredas hearingaconstantpitchwillinformauserabouttherotationofa
relevant.Stage5resultedinourdatabaseholding57papersoverall, star.Therotation,temperature,andotherparametersofplanetsin
adding 10 papers to the prior stage. During the final two stages, oursolarsystemwerealsosonifiedbyElmquistetal.[EEBR21]in
wheneverweidentifiedanaudiovisualidiomthatwaspublishedin OpenSpaceSonification.Theirdesigncanbeusedbothwithcon-
morethanonepaper,weretainedthemostextensiveversioninour ventionalcomputerdesktopenvironmentsaswellasinplanetarium
STAR.Weidentifiedtwosuchcaseswhereadesignwaspreviously settings, tailored towards public outreach and science communi-
publishedinashortpaperbutlaterexpanded[YH18,MAFP19b]. cation. Public outreach is also the core of the publication Audio
UniversebyHarrisonetal.[HTHB22].Thepublicationdescribes
the design of a 35-minute audiovisual show about the the solar
3. CategorizationandResults systemintegratingvisualizationandsonification,aswellasanau-
diovisualanimationdisplayingthestarsintheordertheirappear
Inthissection,wewilldiscusstherelevantliteratureindetailfrom
tooureyesduringdusk.Similarly,RussoandSantaguida[RS22]
theperspectivesofourclassification.Thesystematicintegrationof
collaboratedwithNASA,celebratingthediscoveryofthe5000th
sonificationandvisualizationisawideanddiverseresearchfield
exoplanet.Theirdesigndisplaystheexoplanetsastheywerediscov-
thatisdifficulttoclassifyusingonlyahandfulofcategories.There-
eredovertheyears.Recently,Traverpresentedanotheraudiovisual
fore,wedecidedtoapplyanextensivelistoftagstotheliterature
installationwhereuserscancontroltheauditoryrepresentationof
tobeabletopresentdiverseperspectivesonthefield,mostlycon-
theplanetsusingaMidicontroller[TB23].
cerningbasicresearch,i.e.,thebasicprinciplesthatdistinguishes
thedesigns/idiomsfromeachother. We identified six medicine and health related topics in our
database, out of which three are related to brain scans [GR11,
Togivereadersaninitialthematicoverviewofthefield,wewill
RFM13,GRK∗16],twoareaudiovisuallydisplayingblowflowand
startbybrieflydescribingeachofthe57selectedpapersinsubsec-
aneurysmmodels[MNW∗18,TMN∗21],andoneisconcernedwith
tion3.1.Wewilldosobyclusteringtheliteraturetothefollowing
Covid-19data[LSB∗23].
topics:astronomy,medicineandhealth,molecularscience,earth
science,domainagnosticdatadisplays,andothertopics.Wewill Ourdatabaseholdsfouridiomsthatwerelatetomolecularsci-
thencontinuewithadiscussiononthepurposethatanidiomcan ence. In an idiom presented by Rau et al. [RFK∗15], scientific
©2024TheAuthors.6of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
Purpose Redundancy Soni.Technique Goal
Paper Theme DemoLink VisualizationIdiom
[EEBR21] Astronomy [<—>] volumerendering
• • • •
[Rib19] Astronomy [<—>] linechart,scatterplot
• • • •
[HTHB22] Astronomy [<—>] pointcloud
• • • •
[HPDW23] Astronomy [<—>] scatterplot
• • • • •
[Rib18] Astronomy [<—>] volumerendering
• • • •
[RS22] Astronomy [<—>] 3Dmap
• • • •
[TB23] Astronomy 3Dscatterplot
• • • •
[BTB23] DomainAgnosticDisplay linechart,parallelcoordinates
• • • •
[CWM21] DomainAgnosticDisplay [<—>] linechart
• • • • • •
[DLVDCG22] DomainAgnosticDisplay [<—>] linechart
[DCM∗18] DomainAgnosticDisplay • • convexhull,other,barchart • •
[ERI∗22a] DomainAgnosticDisplay [<—>] • • scatterplot • • •
• • • • • •
[FBC12] DomainAgnosticDisplay linechart
• • • •
[GKW21] DomainAgnosticDisplay [<—>] network
• • • • •
[KLTW17] DomainAgnosticDisplay [<—>] linechart
• • • •
[LF21] DomainAgnosticDisplay [<—>] linechart
• • • • • •
[MAFP19b] DomainAgnosticDisplay [<—>]* heatmap
• • • •
[PCB23] DomainAgnosticDisplay [<—>] linechart
• • • •
[PC19] DomainAgnosticDisplay linechart
• • • •
[RJ16] DomainAgnosticDisplay [<—>] scatterplot,parallelcoordinates
• • • •
[YH18] DomainAgnosticDisplay [<—>] scatterplot
• • • •
[Bal15] EarthScience heatmap
• • • •
[Bea11] EarthScience [<—>] map
• • • •
[BF12] EarthScience [<—>] map
[GDAS∗18] EarthScience • • map • •
• • • •
[HK22] EarthScience geographicscatterplot
• • • •
[HCTP14] EarthScience heatmap
• • • •
[MMU16] EarthScience map
[NRL∗12] EarthScience [<—>] • • map • • •
[PFH∗22] EarthScience [<—>] • • dotmap • •
• • • •
[SAR22] EarthScience [<—>] fluid-likesimulation
• • • •
[WW15] EarthScience [<—>] linechart
[GRK∗16] MedicineandHealth • • slicing,volumerendering • •
• • • •
[GR11] MedicineandHealth slicing
[LSB∗23] MedicineandHealth [<—>] • • map • •
[MNW∗18] MedicineandHealth [<—>] • • volumerendering • •
• • • •
[RFM13] MedicineandHealth slicing
[TMN∗21] MedicineandHealth [<—>] • • volumerendering • •
[AJB∗18] MolecularScience [<—>] • • 3Dmoleculerendering • •
• • • •
[BBV16] MolecularScience 3Dmoleculerendering
• • • • •
[BM20] MolecularScience volumerendering
[RFK∗15] MolecularScience • • volumerendering • •
• • • • •
[FN18] Others linechart
• • • •
[LLW21] Others [<—>] 3Dnetwork
• • • •
[NSC16] Others [<—>] ganttchart
• • • • •
[CB17] Others barchart
• • • •
[MMM18] Others [<—>] individualcirculardesign
[ASH∗12] Others [<—>] • • volumerendering • •
• • • •
[Her20] Others [<—>] network
• • • •
[PBM15] Others 3Dnetwork
• • • • •
[PBV14] Others network
• • • •
[HAR16] Others dottedchartvisualization
• • • • •
[JMP13] Others 3Dscatterplot
• • • •
[KAV21] Others [<—>] 3Dpointcloud
• • • •
[Rön21] Others [<—>] barchart
• • • •
[AK11] Others map
• • • •
[BB19] Others pointgrid
• • • •
Table1:Atableshowingall57entriesinourdatabase,sortedbytheirthematiccluster.Inthecolumnsfortheusedsonificationtechnique,
“PMS”standsforparametermappingsonification,and“MBS”standsformodel-basedsonification.Whereavailable,thedemolinkspointto
thesupplementalmaterialofthepapers(lastaccessedon22nd ofDecember2023).*Therearetwoadditionaldemovideosassociatedwith
thispaper:[<—>]and[<—>];allthreedemosrequirethepassword:icad2019.
©2024TheAuthors.
noitarolpxE noitatneserP htoB tnadnudeR dexiM yratnemelpmoC SMP SBM noitacfiiduA snocIyrotiduA snocraE noitacudE sisylanAataD hcraeseR
tnemegagnEcilbuPK.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 7of27
visualizationofamolecularsimulationisenhancedusingparame- proposeahybridversioncontrolsystemthatemploysaudiovisual
termappingsonificationandauditoryicons.Amongotherthings, feedbacktorepresentsoftwaredevelopmentdatasuchastimelines
theirdesignguidestheattentionofausertowardsvisuallyoccluded andconflicts.Alonsoetal.[ASH∗12]developaninterfaceforprod-
phenomenausingsonification.Ballwegetal.[BBV16]usesoni- uctdesignthatintroducesamultisensoryapproachforcommunicat-
fication with the intention of supporting chemists and structural ingvirtualobjects’geometricaldata,i.e.,curvatureandshape.While
biologists with drug design. For their sonification plug-in, they AdhityaandKuuskankare[AK11]proposeaprototypethatoffersa
focusedontasksthatwerenotwellsupportedvisuallyinasoft- sonification-basedapproachtourbandesignplanning,severalpubli-
warefortheinteractivevisualizationofmolecularstructurescalled cationsfocusonaudiovisualdatarepresentationinVR.Chabotand
“UCSFChimera.”Inthecontextofbiomoleculessimulation,Arbon Braasch[CB17]presentamultimodalapproachtoacomplexstock
etal.[AJB∗18]developedasonificationdisplayingcharacteristics marketdataset,performedinanimmersivevirtualrealitysettingand
ofthe“freeenergylandscape,”amapusedtostudytheproperties utilizingdynamicspatializationtechniquesforacollaborativeexpe-
ofbiomolecularsystems.Theirtechniqueallowsausertovisually rience.Papachristodoulouetal.[PBM15]integratesonificationinto
inspectthephysicalconfigurationofabiomoleculewhilelistening exploringacomplexneurosciencedatasetusinganimmersiveVR
totheircorrespondingfreeenergylandscape.Exploringthepossibil- application,revealingthepotentialforimproveduserperformance
itiesof3Dsound,BoucharaandMones[BM20]suggestedawork in brain region identification across different spatial resolutions.
inprogressimmersivesonificationmodeltostudyproteinsurfaces. BergerandBill[BB19]presentanimmersive,multisensory,and
audiovisualVRapplicationtosupportdecision-makersandcitizens
The earth science cluster in our survey data holds eleven
abouturbantrafficnoiseissues,safety,andqualityoflife.Anexcit-
publications covering topics that range from oceanographic
ingapproachtoneurosciencethroughacomplexdatasetinimmer-
data [SAR22], wildfires [HK22], hurricanes [Bal15], and cli-
siveandinteractive3DvisualizationisgivenbyPapachristodoulou
mate change [Bea11], to sonophenology [NRL∗12], seismol-
etal.[PBV14],demonstratingthatsonificationenhancessubjects’
ogy[HCTP14,WW15,MMU16,PFH∗22],andgeospatialdatadis-
structuralunderstandingofthedataset,providinganadditionallayer
plays[BF12,GDAS∗18].
ofcomprehensionforhiddenpatternsinlargedatasets.WhileJo-
liatetal.[JMP13]combinesspatializedsonificationwith3Ddata
Thecategoryofdomainagnosticdatadisplayidiomsinoursur-
visualizationforsensordatacommunication,enablingdataexplo-
veydataholds14papers.Theseidiomsarenotdesignedtosupport
ration with privacy protection and time-compression algorithms.
usersfromaspecificdomain,butareimplementationstacklingprob-
TwopublicationsfocusonExplainableArtificialIntelligence(XAI).
lemsacrossmultipledomains.Sixofthepapersdescribesoftware
Lyuetal.[LLW21]presentaninteractive,audiovisualVRrepre-
frameworksthatareintendedtohelppeopledesignsonifications
sentationofNeuralNetworks,whileHerrmann[Her20]designsa
alongwithvisualrepresentationsoftheirdata[PC19,PCB23,LF21,
systemthatvisualizesandsonifiestheinnerworkingsofamusic-
DLVDCG22,CWM21,KLTW17].Theirunifyingcoregoalisthe
trained neural network, employing contrastive predictive coding.
democratization of sonification as a technique to represent data,
Itenablestherenderingofhowmusicsoundstotheartificialear
hencemakingitaccessibletomorepeople,bothprofessionalsas
anddynamicvisualizationofneuronactivationsusingaforcegraph
wellasdomainexperts.Otherpublicationsfocusonbasicresearch
layouttechnique.
combiningdifferentsonificationtechniquessuchasparametermap-
pingsonificationormodel-basedsonificationwithbasicinformation
visualizationssuchasscatterplots[ERI∗22a,RJ16,YH17],parallel Aswehavenowbrieflytouchedonall57papersthatarepart
ofourdatabase,wecanfocusonthemetalevelclassificationin
coordinatesplots[BTB23,RJ16],orlinecharts[FBC12]tostudythe
thefollowingsubsections.Withthesemorehighleveldescriptors,
potentialsofaudiovisualdisplayidioms.Groppeetal. [GKW21]
we intend to provide a number of versatile perspectives on the
studiednetworkvisualizationandsonificationthroughtheirdesign,
literature.Theywillhelpusidentifyresearchgapsandopportunities
whileMalikovaetal.[MAFP19b]showthepotentialofsonifica-
forthesystematicintegrationofsonificationandvisualizationfor
tiontohelpusersidentifysmallestsymmetrydifferencesinscalar
thefutureworkofbothresearchcommunitiesinsection6.Along
fieldsvisualizations.Whilemoststudiesfocusonmetricssuchas
thediscussionoftheseperspectives,wewillpresentaselectionof
precision,errorrates,ortaskcompletiontimes,thestudybyDuet
al.[DCM∗18]explicitlyinvestigatesthesonification’sinfluenceon papersthatarerepresentativeexamplesfortherespectivecategory.
By doing so, we intend to provide the reader with (1) a broad
userengagement.
explorationofthefieldoverall,and(2)insightsintothecontentof
Finally,wewanttoprovideanoverviewoftheremainingother theactualpapersthemselves.
15publicationsnotpartoftheabovethematicclusters.Thetopics
relatedtothepublicationstaggedas"other"arediverse,ranging
fromamultimodalsystemforanalyzingbusinessprocessexecution
data[HAR16]toanaudiovisualrepresentationofthePortuguese 3.2. Purpose
consumptionpatterns[MMM18]toamultimodalimplementation
of“GameofLife”usinganidiomthatsonifiesthree-dimensional Inthissection,wewilldiscusstwodifferentpurposesanaudiovi-
cellularautomata,enhancingperceivedquality,patterns,andim- sualidiomcanbedesignedfor,inspiredbythetaxonomydescribed
mersiveness[KAV21].Amusicalsonificationaimedatconveying in[Mun15]:explorationandpresentation.Thepurposeshouldbe
informationaboutrunningdataandemotion[Rön21],aninvestiga- readasgeneraldesigngoalofatoolwithbroadperspective.There-
tionintotheuseoftimbreinsonificationrevealitsimpactontrend fore,thetermexplorationalsocoverswhatiswidelyreferredtoas
identificationinsonifiedlinecharts[FN18].Northetal.[NSC16] dataanalysis.
©2024TheAuthors.8of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
Category Num. Subcategory Explanation
29 Exploration designsusedfordataexploration
Purpose 17 Presentation designsusedfordatapresentation
11 Both designsusedforbothpurposesabove
Idiom thevisualizationidiom,suchasscatterplotorlinechart
Identitychannels nameofthevisualchannelsuchascolorhueorshape,thatisusedtocommunicatethe
Visualization
identityofanitem(i.e.,"What"somethingis)
Design
Magnitudechannels nameofthevisualchannelsuchaspositionorlengththatisusedtocommunicatethe
magnitudeofanattribute(i.e.,"Howmuch"somethingis)
Technique thesonificationtechniquesuchasparametermappingorearcons
Identitychannels theauditorychannelsuchastimbrethatisusedtocommunicatetheidentityofanitem
Sonification
(i.e.,"What"somethingis)
Design
Magnitudechannel theauditorychannelsuchaspitchordurationthatisusedtocommunicatethemagnitude
ofanattribute(i.e.,"Howmuch"somethingis)
50 29 Whole designsthatdisplayalldatapoints
ReadingLevel 13 29 Group designsthatdisplayagroupofdatapoints
4 17 Single designsthatdisplaysingledatapoints
2 2 Lookup theuserknowsthelocationandthetargetofthesearch
9 6 Browse theuserknowsthelocationbutnotthetargetofthesearch
SearchLevel
7 7 Locate theuserdoesn’tknowthelocationbutthetargetofthesearch
40 42 Explore theuserdoesn’tknowthelocationorthetargetofthesearch
11 8 None noneoftheabove
29 40 Table dataconstructedfromitemsandattributes(spreadsheets)
5 3 Network dataconstructedfromitems(nodes),linksandpotentiallyattributes
DatasetType
9 7 Field dataconstructedfromgrids(positions)andattributes
20 9 Geometry dataconstructedfromitemsandpositions
22 13 Nominal datathatbuildscategories(suchasdifferentfruits)
Levelof 8 8 Ordinal datathatbuildsorderedcategories(suchast-shirtsizes)
Measurement 27 31 Interval datathathasequalintervals,suchasthetimeontheclock
27 34 Ratio datathathasequalintervalsandameaningfulzeropoint,suchaslengthorweight
17 Redundant adesignmappingalldisplayedinformationtobothsensesredundantly
Levelof 14 Complementary adesignmappingpartoftheinformationexclusivelytothevisualizationandanother
Redundancy partoftheinformationexclusivelytothesonification
28 Mixed adesignmappingsomeinformationredundantly,someinformationcomplementary
12 UserPerformance evaluationscollectingmetricssuchaserrorratesortaskcompletiontimes
11 UserExperience evaluationscollectinguserfeedback,typicallydoneinausabilitytest
Evaluation
2 AlgorithmicPerformance evaluationsdoingmeasurementswithoutuserssuchasrenderingspeed
System
17 QualitativeResultInspection evaluationsprovidingsubjectiveargumentsonthequalityoftheresult
20 None noevaluationdoneinthepaper
43 DesktopComputerDisplay conventionalscreenondesktopcomputer
Target 4 XR extendedrealitysettingssuchasvirtualoraugmentedrealityglasses
Platform 10 PhysicalEnvironments environmentsthatfostercollaborationsuchasaCAVE
5 TouchDisplay interactivescreenthatuserscaninteractwithviatouch
User 37 Yes designsthatrequireuserinteractionotherthanpressingplay
Interaction 20 No designsthatrequirenouserinteraction
25 DomainExperts domainexpertsthatarenotvisualizationorsonificationresearchers
Users 7 Researchers visualizationorsonificationresearchers
31 GeneralPublic theinterestedgeneralpublic
8 Education idiomsdesignedforeducation
35 DataAnalysis idiomsdesignedfordataanalysis(incl.dataexploration)
Goals
3 Research idiomsdesignedforvisualizationandsonificationresearch
17 PublicEngagement idiomsdesignedforpublicengagement
29 Yes thepaperlinkstoademosuchasaninteractivewebsite,avideo,oranaudiorecording
Demo
23 No thepaperdoesn’tlinktoademo
5 Yes,butnotonline thepaperprovidesalinkthatisnotonlineanymore
Table2:Descriptionsanddistributionsofallusedclassificationtags.Forthecategorieswithtwoseparatetagsunderthe”Num."column,the
leftandrightboxesrepresentthevisualizationandsonificationdistributions,respectively.Fortherowsregardingidiomdesign,wereportthe
numberofdifferententriesinthedatabase.
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 9of27
3.2.1. Exploration exoplanetcharacteristics.NASA’sstrategicdisseminationonsocial
media platforms garnered substantial engagement, with positive
Awiderangeofaudiovisualidiomsinourdatabasesupportusers
feedbackindicatingthepresentation’sbroadappeal.
withtheexplorationofdata,seeTable2.Werefertothepurposeof
explorationincaseswhereauserintendstoacquirenewknowledge The presentation objective appears linked to eliciting emo-
fromtheirdatabyusinganaudiovisualdisplayidiom. tional engagement from end users, as evident in Rönnberg’s re-
search [Rön21]. This representation involves assessing running
ExploratoryDataAnalysisisthecoreaimofmodel-basedsoni-
statistics,weatherdata,andassociatedemotions.Presentedasan
fication[Her02].TheModeExplorerisaninteractiveaudiovisual
animatedvisualizationsynchronizedwithsonification,itdepicts
display idiom, combining a scatterplot visualization and model-
weeklyrunsemphasizingevokingemotionalresponsesratherthan
based sonification to explore high-dimensional data [YH18]. To
precise data interpretation—a practice denoted by the author as
explorethedataausercan“scratch”ascatterplotofdimensionality-
“musification”(seefurtherdiscussionaboutsonificationandmusic
reduceddatawithaninteractivepen.Thescratchingintroducesa
inVickers,2016[Vic16]),leveragingsound’sdualcapacitytoillus-
virtualparticletothehigh-dimensionalspacewhichwillfollowa
tratedataandengenderamusicalexperience.Thestudyassessesthe
gradientdescenttowardsthenearestmodeinthedata.The“kinetic
representation’sefficacythroughauserstudy,whereinparticipants
energy”ofthisvirtualparticleiswhatauserwillbeabletohear.
watchedavideo.Resultsindicatethatthesonificationeffectively
Whiletheparticletravelscloserandclosertoitsfinalmode,the
conveysintendedemotionsbutattheexpenseofalessaccuratedata
soundgraduallyturnsmoreandmoreharmonic,finallyresultingin
representation.
aclearpitchwhenamodeisreached.
Recentworksdelveintoenvironmentalconcernsandthepromo-
AIivecombinesvisualizationandsonificationinavirtualreality
tionofawareness.Onesuchnoteworthycontributionispresented
environment[LLW21].Theidiomsupportsusersinunderstanding
in[HK22].Thispublicationcentersaroundamultimodalmuseum
thebasicconceptsofneuralnetworks.Userscanmanipulatethe
installationdesignedtofosterpublicengagementwithwildfirefore-
weightsofthenodesofavirtuallydisplayed3Dneuralnetwork
casts in specifically chosen California and South Korea regions.
bydraggingthenodesin3Dspace.Inreal-time,thesonification
Theprojectincorporatesinteractivedatavisualization,sonification,
displaysthelossandaccuracyoftheneuralnetwork,thereforeen-
and3D-printedsculptures.Combiningtheseelementsconveyswild-
ablingausertoexploredifferentconstellationsofnodeweights.
firedata,creatingacomprehensiveandimmersiveexperience.The
Usersarealsoabletoaddordeletenodes,henceexperimentingwith
installationallowsaudiencestoexploretherepresentationfreely
thecomplexityoftheneuralnetwork.Whiletheauthorsdonotpro-
throughcontactlessinteraction.Withoutuserengagement,thewild-
videauserstudyintheirpaper,itismostplausibletheexploratory
firedatarepresentationseamlesslyloopsacrossthescreen.Notably
character of the design can support people in understanding the
showcasedattheARKOArtCenterinSeoul,thisprojectsuccess-
basicsofneuralnetworks.
fullycaptivatedtheattentionof20users.Theoutcomesrevealeda
Inarecentpublication,Lemmonetal.presentedanaudiovisual heightenedlevelofinterestandcomprehensionregardingtheimpact
mapidiomthatseekstotacklesomeofthesociotechnicalchallenges ofwildfiresthroughtheeffectiveutilizationofmultimodalinterac-
associatedwithepidemiologicalmapping[LSB∗23].Usingtheir
tion.Theprojectemphasizesobservationsandpromptsaudience
idiom,userscaninteractivelyexploreSuffolkCounty’sexperience reflection without demanding immediate action, leveraging new
withCovid-19.Todoso,theblackpopulationandassociatedcase mediatoenhancepublicclimatechangecomprehension.
numbersaredisplayedontheleftaudiochannel,whilethewhite
populationandassociatedcasenumbersaredisplayedontheright
3.2.3. ExplorationandPresentation
channel via the pitch of sine and triangle waves. A correlation
betweenethnicityandCovid-19casenumbersandtheirdependency Someofthedesignsweidentifiedweredesignedbothtoexplore
ondifferentregionsbecomesclearlyapparentwhenlisteningtothe andtopresentdata.Inclusioninthiscategoryrequiresthedesigner
sonificationwhilebrushingthemapusingthecomputermouse. to put similar weight on the exploration and presentation of the
data.Topresentafewexamples,Patéetal.[PFH∗22]demonstrate
3.2.2. Presentation theiraudiovisualdisplayidiomwiththreeseismicdatasets,where
thesonificationmethodsareadaptedtothespecificpropertiesof
Werefertothepurposeofpresentationwhenauserintendstopresent
eachdataset.Amulti-scaleaudificationmethodispresentedwhere
priorknowledgetoothers,orincaseswhereauserispresentedwith
differentspeedfactorsareuseddependingonthesizeofeachdataset,
informationthatisnewtothembutnottothedesigner.
anddifferentsounddesignsareusedtohighlightspecificproperties
Onepotentialapplicationofapresentation-onlyapproachisin ofthedataset.Thisclassificationcanalsoindicatethattheuser
citizenscience,exemplifiedbythecommunicationofsignificant canexploreseveralpresentationsthathavebeencreatedfromthe
discoveries, such as NASA’s announcement of the 5000th exo- samedatasetandmakecomparisonsbetweenthem.Huppenkothen
planet [RS22]. This representation is explicitly crafted for com- etal.[HPDW23]createdanaudiovisualversionoftheHertzsprung-
municationwiththegeneralpublic,primarilythroughsocialme- RussellDiagramwheretheusercanlistenandcompareauditory
diachannels.Translatingdataintovarioussensorymodalitiesis representationsofeachtypeofstarthatisincludedinthediagram
straightforward,whilesignificantattentionisdevotedtoachievinga (seeFigure7(c)).Itisalsopossibletofilterthediagramaccording
pleasingandharmoniousaesthetic.Thesonification,complemented tocertaincriteria,whichinturnfilterswhichsonificationsareable
bytwoanimatedvideos,enhancesvisualcomprehension,vividly tobelistenedto.Elmquistetal.[EEBR21]createdcomplementing
portraying celestial spheres with dynamic elements representing sonificationsoftheplanetsinthesolarsystemwhichwereintegrated
©2024TheAuthors.EUROVIS2022/T.Höllt,W.Aigner,andM.Agus ShortPaper
Towards Multimodal Exploratory Data Analysis:
SoniScope as a Prototypical Implementation
K.Enge1,2 ,A.Rind1 ,M.Iber1 ,R.Höldrich2 andW.Aigner1
1St.PöltenUniversityofAppliedSciences,Austria
2UniversityofMusicandPerformingArtsGraz,Austria
10of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
fordata,providinganauditorylensto“listeninto”one’sdata.The
A B C exploratorycharacteroftheidiomismostapparentwhenthesoni-
ficationdisplaysnon-visualdatadimensions.Tointeractwiththe
idiom,ausercanbrushthedatausingavisuallens.Clickinginto
the scatterplot will then trigger the sonification of a non-visual
attribute of the selected data items. Regarding the used magni-
tudechannels,weseeacommoncombinationofvisualposition
and the pitch of the sounds, also employed in publications such
1 2 3 4 5
as[BF12,DLVDCG22,FBC12,FN18,KLTW17].
Sonification Time Bearman[Bea11]studiedthepossibilitiestodisplaytheuncer-
taintyinfutureclimateprojectionsfortheUK.Todoso,thepro-
Figure1:UsingtheSoniScopeapproachtoexplorea“bike-sharing”dataset.SectionA:Usersdefinevisualandauditorymappings,thpeosedaudiovisualidiomshowsamapoftheUKwithaheatmap
“Size”and“Shape”ofthevisuallens,aFsiwgeullraesth2e:“STchaneDSuroantiioSn”c.oSpecetioanuBd:iUosverissuspaeclifdyiasnpalraeayinidthieosmcatt[eErpRloIt∗ th2at2wail]l.besonifieodverlaydisplayingtheprojectedtemperaturevalues.Thisvisual-
(SectionC).AmouseclicktriggerstheUsosuenrdsgecnaenratiinonte.Wrahcilteivtweolyofstheelesceltecaterdeagttiroibnuteinsaaresrcepartetseenrtpeldovtistuoallsyoinnitfhyesacnatterplotvia
izationiscombinedwiththesonificationtechniqueofinteractive
abscissaandordinate,athirddatadimension(selectedthroughthe“Pitch”drop-downoption)ismappedtothepitchofthesoundevents.
additionaldataattributefortherespectiveitems.
Theorderoftheseeventsisdeterminedbythe“Sort”drop-downoption.Thisexampleisalsoillustratedinthedemovideo. parametermapping.Peopleinauserstudywereaskedtohoverover
the heatmap with amouse, triggering thesonification of there-
Abstract
spectiveregion.Ahigherpitchofatrumpetsoundcommunicateda
Themetaphorofauscultatingwithastethoscopecanbeaninspirationtocombinevisualizationandsonificationforex-
ploratorydataanalysis.ThispaperpresentsSoniScope,amultimodalapproachanditsprototypicalimplementationbased higheruncertaintyforthatregion.Hence,fortheirdesign,Bearman
onthismetaphor.Itcombinesawsciatthteraplvotiswuitahlainzainttieornac,tiwvehpearraemaetuersmerapcpainngesoxnpifilcoarteionth,teheprerboypceorntvieeysingofadtdhiteional
usedthespatialpositionasavisualidentitychannelandcoloras
informationaboutitemsthatwerpelsaelnecettesdwainthdamvisaukalelecnos.mSopniaSrciospoenexsplboeretswseeveernaltdheesimgn.oTpthioensufosretrheisshaapbeloefittoslens
andthesortingoftheselecteditemsforsubsequentsonification.Furthermore,theopen-sourceprototypeservesasablueprint visualmagnitudechannel.Thissonificationdidnotuseanidentity
listentoallofthesonificationsforeachplanetatthesametime,or
frameworkforhowtocombineD3.jsvisualizationandSuperCollidersonificationintheJupyternotebookenvironment. channel(onlyonesoundcouldbeheard)butusedpitchasmagnitude
enablespecificsonificationsforeachplanetstocomparespecific
CCSConcepts channel.
•Human-centeredcomputing prVoipsuearltiizeasti.onDsuysteetmasla.n[dDtoColMs;A∗ u1d8it]orcyofneeddubacctke;dSoausntdu-bdayseidnivnepustti/goauttpinutg;the
!
enhancedvisualizationofbasketballplayermovementdataduring Severalpapersinourdatabasedescribeframeworksthatareex-
agame.Thevisualizationisdesignedtoconveytheoffensiveand plicitly developed for the design of sonifications (see examples
1. Introduction defensivedynamicsofthaendteshaampe.chTahnneelisn,atesrcfaattecreploptrmimatraixr,ilpyaraellnelacboloerdsinates,orian Figure 3), always in combination with a visualization [PC19,
userstospecifyaparticulatarbtleimlenesr[aTnS2g0e].oSfominetaeprpersota,chpersorveliydoinngintaeramctoivrietyoranimaP-CB23,LF21,DLVDCG22,Rib19,CWM21].Asarepresentative
In exploratory settings, a human analyst generally searches for tiontoexploreattributespairwiseaftereachother[TS20],display
structuresorpatternswithindata[Tuk77c ]o .Fm orp er xe ah me pn les ,i sv cae ttev ri pe low tsofin ofo ver rm viea wtio ann dw dei tath ilein ddt ah taat inti mm ue ltf ipr la em vie ew. sN [o Rt oa bb 07ly ],, oranalytai-ndflexibleexamplewewanttodiscusstheHighchartsSonification
areoftenusedforpattern-findingintwosoqunainfitictaatitvieoanttriisbuitnest.eFgorratedecaxlclyluresdiuvceeldyimdeunrsiionngalitthye[SeMxTp1l3o]r.aHtoiwonevepr,heaasceh.oftheseapS-tudio[CWM21],acollaborationbetweenthecompanyHighcharts
exploringpatternsinmultivariatedata,numerousvisualizationap- proachestothevisualizationofmultivariatedatahasitslimitationas,ndtheGeorgiaTechSonificationLab.Regardingthedesignofthe
proacheshavebeenproposed,suchasabubbleplotwithcolor,size,
visualization,theenvironmentoffersline-andareacharts,aswell
3.3. AudiovisualIdiomDesign
©2022TheAuthor(s) asscatterplots,barcharts,andpiecharts,allwiththeirrespective
EurographicsProceedings©2022TheEurographicsAssociation.
Designersofaudiovisualidiomshaveasheerendlessnumberof standardvisualchannelssuchasposition,length,angle,orcolorhue.
possibilitiestocombinetheirvisualizationsandsonifications.They Thesonificationisdoneusingparametermappingwithseveralop-
canchoosefromavastnumberofestablishedvisualizationidioms tionsforauditorymagnitudechannelssuchaspitch,spatialposition
andsonificationtechniques.Havingchosentwodesignstointegrate inthestereofield,loudness,orharmonicrange.Differentattributes
with each other, they are free to choose the visual and auditory inthedatacanbedistinguishedusingdifferentmusicalinstruments,
channelstheywanttomaptheirdatato.Duringtheclassification hencetheemployedauditoryidentitychannelisthetimbreofthe
ofthesurveyedliterature,weusedsixdifferentcategoriestocap- differentsounds.ThedefaultoptionoftheHighchartssonification
turethestate-of-the-artofaudiovisualidiomdesign.Thecategories studioissettocombinealinechartwithanauditorygraph,which
arethevisualizationidiom,thesonificationtechnique,thevisual traditionallyplaysbackthelinefromlefttorightusingpitchover
identity-andmagnitudechannels,aswellastheauditoryidentity- time.
andmagnitudechannels.Theconstructsofidentity-andmagnitude
Intheirpaper,Wintersetal.[WW15]describethedesignofthe
channelsareusedtodistinguishbetweenencodingsthatcommu-
visualizationandthesonificationofthe2011Tohokuearthquakein
nicate“what”somethingisand“howmuchof”somethingthere
is[Mun15,ERI∗23].Typicalvisualidentitychannelsaretheshape Japan.Thedesigncombinesfourlinechartsoffourseismographic
recordingstationsinJapanwithanaudificationofthesamedata
ofavisualmarkoritscolorhue.Typicalvisualmagnitudechannels
streams.Theessenceoftheaudificationisthatthelowfrequency
arethepositionorthelengthofavisualmark.Atypicalauditory
recordings of the earthquake are played back in a faster tempo,
identity channel is the timbre of a sound, often generated using
makingthemaudibletothehumanear.Thisverydirectmapping
differentmusicalinstruments.Typicalauditorymagnitudechannels
betweenthephysical(non-audible)phenomenonandtheaudifica-
arepitchandloudness[DB13,CLR22].Inthefollowing,wewill
tiontotheaudiblerangeresultsinarichauditoryimpressionthat
makeuseofthesedescriptionstoshedlightonsomeofthedesigns
becomesinformativeinanecologicallyvalidmanner.Thepaper
inourdatabase.
mostlydiscussesthepopularityofthissonificationonYouTube,cur-
SoniScope [ERI∗22a] is an interactive audiovisual display id- rentlywitharound90kviews,explicitlymentioningtherelevance
iom that combines a scatterplot visualizationwith an interactive ofcombiningthesonificationwithvisualizationforitssuccessin
parametermappingsonification(compareFigure2).Inspiredby publicoutreach.Thevisualizationusespositionasbothitsidentity
thetechniqueofauscultation,theSoniScopeactsasastethoscope and its magnitude channel. The sonification employs the spatial
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 11of27
(a) (b) (c)
Figure3:Examplesofframeworksforsonificationincombinationwithvisualization.(a)TheSonificationWorkstationbyPhillipsand
Cabrera[PC19]designedforgeneralsonificationtasks.(b)TheWebAudioXMLSonificationToolkit(WAST)userinterfacebyLindetorpand
Falkenberg[LF21]alsoaimedforgeneralsonificationtasks.(c)TheSonifigraphervirtualsynthesizerinterfacebyRiber[Rib19]forsonifying
lightcurves.AllscreenshotsCCBY4.0.
stereopositionofthefourchannelstodistinguishbetweenthem, Visualization
Sonification
henceastheiridentitychannel.Themagnitudechannelsareamix whole group single
ofpitchandtimbre,resultingfromthedirectmappingbetweenthe
whole 27 3 1
physicalphenomenonandthesound.
group 24 12 1
Disscussion:Fromthedata,weseethatparametermappingisby single 14 4 3
farthemostusedsonificationtechniqueforthedesignofaudio-
Table3:ThenumberofentriesforBertin’sdifferentreadinglev-
visualidioms–53outof57papersinthedatabaseemploysome
els[Ber83]andtheirdistributiontothetwodisplaytypes.
sortofparametermappingsonification.Onlyasevenofthemcom-
bine parameter mapping sonification with other techniques such
asaudification[MMU16,HPDW23],earcons[HAR16,NSC16],or
auditoryicons[BBV16,RFK∗15,PBM15].Thetechniqueofau-
dificationispartofthedatabasethreetimesonitsown[PFH∗22, 3.4. ReadingLevels
HCTP14,WW15],andincombinationwithearconsonceinasecond Theclassificationofdesignswithrespecttoreadinglevelsisin-
designofapaper[PFH∗22].YangandHermannaretheonlyau- spiredbythetaxonomybyBertininhisseminalbookSemiologyof
thorsemployingmodel-basedsonificationwiththeirModeExplorer Graphics[Ber83].Thethreereadinglevelsdescribetheamountof
design[YH17].Themostprominentauditoryidentitychannelin dataauserstudiesusingaspecifictool.The“Whole”leveldescribes
ourliteraturecorpusistimbre(used21times)andthemostused toolsthatenabletheusertoaskquestionsabout“all”ofthedata
auditorymagnitudechannelispitch(47times),alsousedincom- underconsideration.The“Group”leveldescribestoolsthatenable
binationwithotherchannels.Thesefindingsarejustinlinewith theusertoaskquestionsabouta“subgroup”ofthedataundercon-
othermetaanalysesofthefieldofsonification[CLR22,DB13].The sideration,andthe“Single”leveldescribestoolsthatenabletheuser
visualizationsinourcorpusemployidiomssuchaslinecharts(10 tostudy“single”items.Forthiscategory,wedecidedtoassigntwo
times),scatterplots(8times),maps(7times),aswellasnetworks, tagsperentryinourdatabase:Oneforthevisualizationpartand
barcharts,slicing,heatmaps,andseveralotheridioms.Thesepubli- oneforthesonificationpartoftheidiom.Theclassificationusing
cationsusetheidentitychannelscolorhue(27times),position(11 readinglevelsaimstowardspotentialdifferencesinthedistribution
times),aswellasshape(11times).Theemployedvisualmagnitude oftasksbetweensonificationandvisualization,suchasoverview
channelsareposition(33times),colorhue(15times),size(9times), anddetailphenomena.
andotherchannelssuchasopacity,tilt,oranimation. Rau et al. [RFK∗15] presented an audiovisual idiom that lets
Taggingthesurveyedliteraturemadeusrealizethatwithtech- usersinteractivelyexploremolecularstructuresbyusinga“virtual
niquessuchasaudificationormodel-basedsonificationusingthe microphone”thatcanbeplacedinsidea3Dmolecularvisualization.
conceptofthe“channel”isnottrivial.Withthesetechniques,thede- Thevisualdesignprovidesanoverviewusingthe“Whole”level
signerofasonification,tosomeextent,losescontroloverthesonic whiledisplayingdetailsatgrouplevelviathesonification.Atthe
outcomeofasonification.Thiscontradictsthedefinitionofavisual sametime,thedesignprovidesauserwithinformationaboutpo-
channelas“awaytocontroltheappearanceofmarks”[Mun15]. tentiallyvisuallyoccludeddata.Hence,itmakestheuserawareof
Instead,thinkingofthe“channel”as“thequalityofamarkthattrans- theexistenceofaphenomenon,thattheycould,ifrelevant,study
portsinformation,”alsoallowsforthedescriptionofaudifications in detail at a later point. The metaphor of the microphone to be
and model-based sonifications. While these techniques typically usedto“listenintothedata”issimilartotheoneofthestethoscope
resultinhighlycomplexsoundsequences,itwilloftenbequalities in[ERI∗22b],wherethevisualizationprovidesanoverviewwhile
suchaspitchortimbrethatareinformativetothelistener.Ingeneral, userscaninteractivelychooseasubsetofdatatodisplayacoustically.
weseeaquitediversefieldofdifferentaudiovisualidiomdesignsin Anexampleofanidiomworkingatthesonification“whole”level
ourcorpus. andthevisualization“group’level,istheModeExplorer[YH17].
©2024TheAuthors.Why?
Actions Targets
Analyze All Data
Consume Trends Outliers Features
Discover Present Enjoy
Attributes
Produce
One Many
Annotate Record Derive
Distribution Dependency Correlation Similarity
tag
2.4.DatasetTypes Extremes 25
1S2eofa2r7ch K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
Dataset Types
Tables Networks Fields (Continuous) Geometry (Spatial)
Target known Target unknown
Attributes (columns) Grid of positions
Location Lookup Browse I (t re om wss ) Network DataLink Node Cell Position
known Cell containing value (item) Attributes (columns)
Location MultidimensTionoal Tpabloe logTreyes Value in cell
Locate Explore
unknown Figure5:FourdatasettypessuggestedbyMunzner:tables,net-
works,fields,andgeometries.(Figurefrom“VisualizationAnalysis
andDesign”Valu[e iMn cellun15]byTamaraMunzner,withillustrationsby
Figure4:ThefoursearchlevelssuggestedbyMunzner:lookup,
Query EamonnMaguire,CCBY4.0.)
browse,locateandexplore.(Figurefrom“VisualizationAnalysis Paths
Figure2.4.Thedetailedstructureofthefourbasicdatasettypes.
andDesign”[Mun15]byTamaraMunzner,withillustrationsby
Identify Compare Summarize
EamonnMaguire,CCBY4.0.)
2.4.1 Tables Sonification Visualization What?
table network field geometry
Manydatasetscomeintheformoftablesthataremadeupof
rowsandcolumns,atfaabmleiliarformt2o3anybodyw1hohasus4eda 12
Visualization spreadsheet.SInpthiascthiaaptler ,DIfoacutsaontheconceptofatableas
Sonification
explore browse locate lookup
simplyatypeofdatanseetttwhaotriksindepend0entofanyp2articularv0isual 0
Why?
representation;laterchfiaepltdersaddress0thequestio0nofwhatv7isual !Ch1apter7covershowto
explore 37 4 5 5 representationsarSe gah ep opa mropp er ti rae yteforthe 1differentty 0pesofdata 0sets. arran 9getablesspatially.
browse 3 2 2 2 Forasimpleflattable,thetermsusedinthisbookarethateach
rowrepresentsanitemofdata,andeachcolumnisanattributeof
locate 4 3 5 5 thedTaatabselte. E5ac:hcTehlleintnheumtabbleerisfuolflysepnectirfiieedsbyftohrecotmh-e different dataset How?
lookup 1 0 1 2 b coin na tatti yio npn seo asf va [aMlr uo ew ufna orn 1d t5ha ]atc ao pl nau idm r.n t— Fhia geun irri ete c2m o.5ma sn bhd oiwnan sata ait notr neib xsu at mbe— peleta wn od feen the two display
thefitrescthfenwiqdouzeens.iteNmostianbalyta,btleheofvoridseursa,lwizhaerteiothneoatftrgibeuotemsetriesisoftencom-
Table4:ThenumberofentriesforMunzner’sdifferentsearchlev- areorderID,orderdate,orderpriority,productcontainer,product
els[Mun15]andtheirdistributiontothetwodisplaytypes. basebminaregdin,waintdhsthhipedsaoten.ificationoftabledata. ! Keys and values are
Figure 3.1. Why people are usAinmgultidvimisensiinonaltetabrlemhassaomforaeccomtipolexnsstrucatunredfortian-rgdeisctusss.ed further in Sec-
dexingintoacell,withmultiplekeys. tion2.6.1.
Thedesignsonifiesahigh-dimensionaldataspacewhilevisualizing Malikovaetal.[MAFP19b],forexample,presentedanidiomthat
atwo-dimensionalprojectionofthatspacewithascatterplot. helpsusersexplorescalarfieldsusingboththeirearsandtheireyes.
Todoso,theregionalmagnitudeofsmallareasofascalarfieldis
Discussion:Outofallpossiblecombinationsofreadinglevelsand
sonifiedusingpitch.Fromthesearchlevelperspective,auserof
display type, the majority of cases (27) use the “Whole” level
thisidiomdoesnotgenerallyknowwhattolookorlistenforatthe
for both the sonification and the visualization (some of them
beginningoftheanalysis,thereforebothmodalitiesareusedfor
are[EEBR21,MMM18,RS22,SAR22,WW15]).Thenextbiggest
exploringthepresenteddata.Thesystemcould,forexample,reveal
groupinourdatabaseholds24papersthatcandisplaydataatthe
theexistenceofsmallsymmetrydifferencesinscalarfields.What
“Whole”levelusingtheirvisualizationandatthe“group”levelus-
visuallyseemstobeaperfectlysymmetricalfield,couldbecome
ingtheirsonification,suchas[BF12,BTB23,FBC12,GDAS∗18,
apparentasnotquitesymmetricwhentwosimilarpitchesresultin
RFK∗15].Generallyspeaking,wecanobservethatthevisualiza-
anacousticphenomenoncalled“frequencybeating.”Theclearly
tionpartsaremostlycoveringthesameorahigherlevelofreading
audiblephenomenonmakesalistenerawareofthenon-symmetry
thanthesonificationpartofadesign(comparetableTable3).This
ofthefield,potentiallyresultinginthemtakingacloserlookattheir
phenomenoncanbedirectlyrelatedtothedistributionoftaskson
data.
thetwodisplaytypes,withvisualizationmoreoftenprovidingan
overviewandthesonificationratherdisplayingdetails.Insection6, Discussion:Generallyspeaking,manyidiomscanbeusedformore
wewillargueforbreakingsuchpatternsinthefutureworkofthe than one search level and it seems to be dependent on the prior
community. knowledge of a user (both about the data and about the idiom)
whatsearchleveltheyuseitfor.Nevertheless,themajorityofpa-
persinthesurveyedliteratureofferthesearchlevelof“explore”
3.5. SearchLevel and, in general, most papers use the same search level for both
their visualization and their sonification parts (see Table 2 and
Inspired by the taxonomy suggested by Munzner [Mun15], we
Table4).Someexamplesofdesignsemployingthesamesearch
taggedfourdifferentsearchlevels,againassignedindividuallyfor
levelare[CB17,DCM∗18,ERI∗22a,FBC12,Rib19,GR11,HK22],
thesonificationandthevisualizationpartsoftheidiom.Thetype
while fewer combine different search levels for the two modali-
ofsearchauserappliesdependsontheirpriorknowledge.Users
ties[HAR16,RFK∗15,RJ16,AK11,Bal15,CWM21].
whoknowwhattheyarelookingforandwheretheycanfinditwill
doalookup.Searchingforanunknownpatternataknownlocation
iscalledbrowsingwhilelocatingisasearchwithoutknowingthe
3.6. DatasetTypeandLevelofMeasurement
locationbutthepatternoneislookingfor.Asearchuninformedboth
withregardstothelocationandthetypeofpatternoneislooking Two more categories we tagged individually for the sonification
for is called exploration. Designs that combine sonification and partsandthevisualizationpartsarethedatasettype(seeFigure5
visualizationcouldserveeachofthedescribedsearchlevelsaswell andTable2)andthelevelofmeasurement(seeTable2).Wedistin-
asacombinationofthem. guishbetweenthefourdatasettypesoftables,networks,fields,and
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 13of27
Visualization theycanmapsomepartsofthedataredundantlyandsomecom-
Sonification
ratio interval ordinal nominal plementary(mixedmappings).Whilethiscontinuumseemstobe
ratio 21 11 0 10 anintuitivedescriptionofaudiovisualdisplayidioms,weshould
interval 7 22 2 12 distinguishbetween“technicalredundancy”and“communicative
ordinal 0 2 8 7 redundancy.”
nominal 4 2 5 12
Technicalredundancy describesthetechnicalmappingfrom
Table6:Thenumberofentriesforthedifferentlevelofmeasurement thedatatoavisualandauditoryrepresentation.Ifallthedisplayed
andtheircombinationsbetweenthetwodisplaytechniques.Most informationismappedtochannelsofbothmodalities,thentheau-
idiomsuseidenticallevelofmeasurement.Notably,42casesusea diovisualdisplayidiomemploysatechnicallyredundantmapping.
higherlevelofmeasurementwiththeirsonificationthanwiththeir Anexampleistheauditorylinegraph:Weseeandhearidenticalin-
visualization(numbersabovethemaindiagonal).20casesusethe formationviaspatialposition(visualization)andpitch(sonification).
levelsofmeasurementtheotherwayaround(numbersunderthe Insomecases,itisnotenoughtouseapurelytechnicaldescription
maindiagonal). of redundancy, without incorporating our way of perceiving the
differentdisplaysashumans.Therefore,weintroducethetermof
"communicativeredundancy."
Redundant Mixed Complementary
Communicativeredundancydescribesthefactthattechnically
redundantdesignsmightencodethesameinformationwithdifferent
Son & Vis Son & Vis Son Vis perceptualqualities.Hence,wecouldidentifydifferentpatternsin
databylisteningtothem,andthenbylookingatthem.Commu-
nicativeredundancywillusuallybestronglyrelatedtotechnical
Figure6:Thethreelevelsofmapping-redundancy:Redundantmap- redundancy,butthereareexceptionssuchasthecombinationofa
pingsdisplaythesameinformationviavisualizationandsonification. WAVformvisualization(linechart)andanaudification,suchasin
Complementarymappingsdisplaydifferentinformationtothetwo theSonificationoftheTohokuEarthquakeinJapanin2011,also
sensesandmixedmappingsmapsomeinformationredundantlyand describedin[WW15].Technically,thosetwoarefullyredundant
otherinacomplementaryway. (thesamedataattributesaredisplayedbothvisuallyandauditorily),
butcommunicativelytheycomplementeachother.
Inthefollowing,whenwespeakofredundancy,weusethedefi-
nitionoftechnicalredundancy.Communicativeredundancyismost
geometries[Mun15]andbetweenthefourlevelsofmeasurementof
likelyalsodependentontheindividualreceiver,whichiswhywe
nominal,ordinal,interval,andratioscale.
wouldnotbeabletoconsistentlyassignatagtoeachcase.Neverthe-
It is reasonable that most idioms display data from identical less,whenimplementinganaudiovisualdisplayidiom,adesigner
dataset types with both their visualization and their sonification. shouldconsideritscommunicativeredundancyjustaswell.
The most prominent dataset type is the table, used in designs
suchas[BTB23,DLVDCG22,DCM∗18,ERI∗22a,FBC12,HAR16, RönnbergandJohannson[RJ16]presentatechnicallyredundant
mappingofthedensityofascatterplotoraparallelcoordinatesplot
MMM18,RJ16].Table5revealsanotableexceptionfromthedomi-
toauditorychannels.Userswouldbeabletohoverovertheplotand
nanceofidenticaldatasettypes:thecombinationofvisualizedge-
listentoanauditoryrepresentationofthedensityinthedata.Itis
ometryincombinationwithasonifiedtables,oftenrelatedtomaps
andsupplementedregionalinformation[BF12,LSB∗23,MMU16, technicallyredundantaswearegenerallyabletoseethedensityof
NRL∗12,RS22]. theplotbylookingatit.Inacommunicativesense,thedesignisnot
redundant,whichiswhytheirevaluationshowsthattheadditional
Concerning the levels of measurement of the displayed data, sonificationhelpsusersidentifyespeciallydenseareas.Theeyes’
we observe, again, that most idioms display data from the abilitytoassessthevisualdensityissupportedbythesoundoftheir
same level (see Table 5). We list a selection of cases for ratio design.
data [ASH∗12,DCM∗18,GRK∗16,PFH∗22,Rön21], for inter-
Dedicated environments that offer the design of audiovisual
valdata[BB19,DLVDCG22,Rib19,Her20,MMU16],forordinal
display idioms often employ redundant mappings [PC19,Rib18,
data[AK11,LF21,PCB23],andfornominaldata[GKW21,HAR16,
CWM21,DLVDCG22,KLTW17,Rib19].OneofthemistheSonifig-
NSC16],andnowwillcontinuewithadiscussionofthreemethods
rapher(seeFigure3(c)),presentedbyGarcía[Rib19],thatcombines
tomapthedatatothesenses,thelevelsofredundancy.
alinechartandaparametermappingsonificationofthelightcurves
fromNASA’sexoplanetarchive.Theverticalpositionofalineis
3.7. LevelofRedundancy mappedtothepitchofamusicalsound,essentially“playingback”
thelinefromlefttoright(compareFigure7).
Whencombiningsonificationandvisualization,designershavethree
options–displayedinFigure6–todistributetheinformationthey TheworkpresentedbyRauetal.[RFK∗15]complementarilyen-
wanttotransporttothesenses.Theycanhavethesameinformation hancesthevisualizationofmolecularsimulationsbyusingauditory
representedinboththesonificationandthevisualization(redundant iconsandparametermappingsonification.Ausercanpositiona
mappings),theycandisplayonepartofthedataexclusivelyvisually “virtualmicrophone”insideofa3Drenderedvisualrepresentation
andanotherexclusivelyauditorily(complementarymappings),or ofamoleculeandlistentoprocessesthatarevisuallyoccluded.
©2024TheAuthors.14of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
Temoretal.[TMN∗21]presentedamixedmappingapproachfor thecombinationofvisualizationandsonificationincreasedaccuracy
theaudiovisualanalysisofcomputationalfluiddynamics,intheir incomparisonwithvisualizationonlybutalsothatresponsetimes
specificcasetailoredtowardsthepredictionofcerebralaneurysm werelongerwhensonificationwasused.
ruptures,henceinthemedicalcontext.Theirsonificationdesignis
psychoacousticallymotivatedinawaythatamplifiesthedifferences TheclassofUEincludesevaluationsthatfocusonsubjective
betweendifferentsimulationsoftheirspatiotemporallydynamic feedbackandexperiencesonavisualizationorsonification[IIC∗13].
data.Theauthorsexplicitlymentiontheirchoicetoapplyamixed Theuseofinterviewsand/orvariousquestionnairesarecommon
mappingintheirdesign.Theymotivatetheirdecisionbytheobser- evaluation methods. In the corpus of papers this was a common
vationthatthe”spatiotemporalfluctuationsarehighlightedinaway approachforevaluatingtheaudiovisualrepresentations,andoften
thatseemstobesuperiortothepresentationofdifferentinformation usedincombinationwithotherevaluationapproaches.Thepaper
todifferentsensorymodalities,whichisinlinewithhowwemake byBallweg,etal.,[BBV16]presentsastudywhereusersanswered
senseofspatiotemporally-dynamicstimuliineverydayscenarios”. aquestionnaireabouttheirexperienceofanaudiovisualsystemfor
Weconsiderthisobservationashighlyplausibleandinspirational drugdesignona5-pointLikertscale.Bycomparingresponsesgiven
forpotentialfutureresearchandwillreflectuponitintheconcluding beforeandafterthestudyitcouldbedeterminedhowthesystem
discussionofthisSTAR. couldbeintegratedintotheusers’workflow,ifsonificationcould
haveapositiveeffectonthetask,andinwhatwaythesystemcould
Maças&MartinsandMachadopresentanaudiovisualdisplay
beimproved.
idiomthatdisplaysconsumptionpatternscollectedfromPortuguese
supermarkets over the course of two years. The authors, just in
linewithTemoretal.[TMN∗21],alsoarguefortheemployment FewpapersinthesystematicliteraturereviewusedAPasaneval-
ofamixeddesign,theirteamshavingmadepriorexperiencewith uationapproach.Evaluationapproachesinthisclassshouldcontain
complementarydesignsthatseemtohavebeenlesseffective. aquantitativestudyoftheperformanceorqualityofvisualization
and/orsonificationalgorithms[IIC∗13].However,inthecorpusof
Discussion:Regardingthelevelofmapping-redundancy,ahigh-
papersusedintheclassification,thisapproachwasonlyfoundin
levelobservationisthefollowing:Whendesigninganaudiovisual
a few cases and was employed to determine that an audiovisual
displayidiom,themixedmappingseemstoshowaspecialpotential.
algorithmcouldproducesufficientqualityratherthandetermining
Themappingoverlapbetweenthesonificationandthevisualization
acertainlevelofqualityorcomparingdifferentalgorithms.Asan
seemstohelptheuserwithperceivinganidiomasintegrated,rather
example,inthepaperbyKariyadoetal.,[KAV21]itisstatedthat
thanastwodisplaysexistingnexttoeachother.Therearediffer-
theobjectiveevaluationshowedthatthesystempresentedinthe
entoptionstodesignamixedmapping,outofwhichapromising
paperallowedforadefaultamountof255audiosourceswithany
oneseemstobetosynchronizeavisualanimationwithasonifica-
audiodrop-outs.Theassessmentofthealgorithmcorrespondingto
tion[TMN∗21,MNW∗18].Insimilarmannersynchronizingthe
alevelof255wasdeterminedbythegameengineUnity’sability
spatialpositionofthevisualdisplaywiththedirectionauserper-
toproduce255validaudiosourcesandnotbecauseofasystematic
ceivedthesoundfromcanbehelpfultoperceptuallyintegratethe
reviewofthenumberofaudiosources.
twostimuli[CB17].
EvaluationsintheclassQRIaimtodrawconclusionsbasedon
3.8. EvaluationApproaches qualitative discussions and assessments of audiovisual represen-
tations[IIC∗13].IncontrasttoUE,thesetypesofevaluationsdo
Theevaluationofdesignsisapressingissueinboththesonification
notinvolveendusersbutinstead,asktheuserofavisualization
andthevisualizationfields.Justaswell,audiovisualdisplayidioms
orsonificationtoassesstherepresentationforthemselves.Inthe
needtobeevaluated.RönnbergandForsellevenargueforafuture
workofBru,etal.,[BTB23],anapproachtoacombinedaudiovisual
standardizationofquestionnairesthatassesstheusabilityofaudio-
representationbasedonparallelcoordinatesordenselinechartsis
visualrepresentationsthatcouldbeusedincombinationwithother
presented.Inthepaperseveraldifferentattributesandcharacteristics
measurements[RF22].Tostudythecurrentpracticeofevaluation
intherepresentationsarediscussedbasedontheresearchers’own
ofaudiovisualdesigns,weappliedfouroftheclassesofevaluation
reflectionsbutwithnoformaluserevaluationperformed.
techniquessuggestedbyIsenbergetal.[IIC∗13].Thefourclasses
areuserperformance(UP),userexperience(UE),algorithmicper-
Discussion:Aswehavenowdemonstratedtherearevariousap-
formance(AP),andqualitativeresultinspection(QRI).
proachesforevaluatingaudiovisualrepresentations,andtheaimof
Whenevaluationsobjectivelymeasurehowspecificfeaturesin theworkandtheresearchquestionsaskedtodeterminetheclass
avisualizationorsonificationaffectuserperformancewithasys- ofevaluationchosen.Insomecases,inthecorpusofpapers,two
tem,theseapproachesbelongtotheevaluationclassUP[IIC∗13]. oftheseevaluationapproacheshavebeencombinedtoprovidea
Controlledexperimentsusingvarioustimemeasurementsandac- betterandmoredetailedanalysisoftheoutcomeofthestudyfind-
curacy are typical example methods in this class. Rönnberg and ings[BBV16,GRK∗16,PFH∗22].Yetaboutathirdofthestudies
Johansson[RJ16]exploredthecombinationofvisualizationand includedinthesystematicreviewdidnotincludeanevaluationatall.
sonification,wheretheusersweretaskedwithidentifyingthevi- Theabsenceofevaluationmightleadtoasituationwherepromising
sualareawiththehighestdensityinvisualrepresentationswithand audiovisualdesignideasmightberejectedasclearandconvincing
without support of sonification. The user performance was mea- evidenceoftheirusability,benefits,andfunctionisnotpresentedin
suredinaccuracyandresponsetime,andtheresultsshowedthat apaper,orthatlessusefulideasareoverratedandpromoted.
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 15of27
3.9. TargetPlatformsandInteractivity theotherhand,therealsoexistmorecomplexformsofinteractions
suchasnavigatinga3Denvironment[BB19,JMP13,MNW∗18].
Audiovisual display idioms can be displayed on different target
Papachristodoulouetal.[PBM15]createdadesignfornavigating
platformsandindifferentenvironments(seeexamplesinFigure7).
complex datasets of brain networks, where the sonification con-
Atypicaldisplayforthecombinationofsonificationandvisualiza-
veyedinformationofdifferentbrainregionsofthedataset.Within
tionisthecomputerdesktopenvironment,asthisisalsothemost
thesonificationcommunity,itwastheintroductionofmodel-based
commonlyusedenvironmentforvisualization-onlydesigns.About
sonification[Her02],thatmadeuserinteractionanintegralpartof
two-thirds of the designs included in this survey are developed
thedataanalysisprocess.Anexampleofamodel-basedsonifica-
exclusivelyforadesktopenvironment.
tionistheModeExplorerbyYangandHermann[YH18],where
The second largest category of target platforms was physical scratching-interactionswithapencilonascatterplotenablesthe
and/ormulti-userenvironments.Thisincludesdometheatersand usertoinvestigatedifferentmodesandtheirpropertiesthroughthe
planetariums, which are commonly used for audiovisual display sonification.
idiomstowardtopicsofastronomy(aspreviouslymentionedinsub-
section3.1)[HTHB22,RS22,EEBR21].Anothertypeofphysical Discussion: When displaying an audiovisual display idiom on
a target platform other than a desktop environment, it often cre-
environmentarededicatedimmersiveenvironmentsforcollaborative
atesopportunitiesforinteractingwiththesysteminanovelman-
dataanalysis,whereseveraluserscantakepartinthedataexplo-
ner[EEBR21,HK22,NRL∗12,PBM15].Inthecontextofdataanal-
ration.OneexampleofsuchanenvironmentistheCRAIVE-Lab
ysis,interactionisalsoaparticularlyrelevantpartoftheuserexperi-
(Collaborative-Research Augmented Immersive Virtual Environ-
ence[BBV16,Bea11,EEBR21,HK22].
mentLaboratory),whereadesignvisualizedandsonifiedmarket
dataof128corporationsbyusingthelargepanoramicdisplayand
the128-channelloudspeakerarrayoftheenvironment[CB17](see 3.10. UsersandGoals
Figure7(b)).
Justaswithvisualization-onlydesigns,audiovisualdisplayidioms
Alow-costalternativeforphysicalenvironmentsarevirtualenvi-
areoftendevelopedtowardspecificusersandendgoals.Themost
ronments,whicharemostcommonlyenabledthroughhead-mounted
commonlyoccurringgoalforthepapersinthedatabasewasdata
displays. An approach for an audiovisual display idiom in this
analysis.Thiscouldeitherbetopresentadatasettotheuserorletting
type of environment is to let the user navigate the dataset in a
theuserexploreoneorseveraldatasetswiththeidiom,asdescribed
first-personperspectiveandusespatializedsonificationwhichdy-
insubsection3.2.Thebenefitofusingvisualizationandsonification
namicallychangesdependingonwheretheuserispositionedin
in this regard is that the user can gain different perspectives of
thedataset.AnexampleisthedesignofBerger&Bill(seeFig-
thedatathroughthetwosensorymodalities.Forexample,Alonso-
ure7(a)),whichfacilitatesanimmersiveexplorationofurbannoise Arevaloetal.[ASH∗12]createdamultimodalinterfaceforcurve
standards[BB19]bycreatingavirtualenvironmentofacitywhere
shapesandcurvature,wheretheusercanevaluatethequalityof
thesonificationallowstheusertolistentothecollectednoiselevels
athree-dimensionalshapebyusingboththevisualandauditory,
bynavigatingtheenvironment.
andinthiscaseeventheirhapticperception.Thecurveshapewas
Theuseoftouchdisplaysandothertangibleinterfacesforan mappedtothefundamentalfrequencyofdifferentcarriersoundsto
audiovisualdisplayidiomcanallowforaunifiedintegrationofthe offerdifferentsounddesignstoconveytheinformation.
sonificationandthevisualization.Arecurringapproachistouse
Themostrecurringpairofusersandgoalsinthedatabasewas
the visualization as a graphical user interface which enables the
data analysis for domain experts, which most commonly would
sonificationuponinteraction.Throughatouchdisplay,thedesign
involveanaudiovisualdisplayidiomtoconveydatainaspecific
byFergusonetal.[FBC12]enablestheusertofilteralinegraph applicationdomaininthenaturalsciences.Temoretal.[TMN∗21]
withmulti-touchgesturestoselectwhatdatashouldbesonified. andMacDonaldetal.[MNW∗18]createdanauditorycomplement
Asamoreanalogapproach,thesystemSonophenologybyNess
toascientificvisualizationofcomputationalfluiddynamics,where
etal.[NRL∗12]letstheuserselectareasonaprintedcolor-coded
thesonificationaidedinunderstandingthetemporalchangesinthe
paper map through fiducial markers, which in turn selects what visualanimation.Gionfridaatal.[GRK∗16]suggesttocombinethe
informationshouldbeconveyedbythesonification.
visualizationofbrainscans(inthecontextofAlzheimer’sdementia
About two thirds of the papers in the database include some research)withaparametermappingsonificationthattheycallTriple-
form of interaction. One of the most recurring objectives of the ToneSonification.Thedesignmakesuseofthefactthatthehuman
interactionwastomakeaselectionofthedatasetthatwouldbesoni- earwillperceivethesoundoftwoormoreverysimilarfrequen-
fied[FBC12].Thiscanincludeselectinggeographicregionswhich ciesas"frequencybeating,"whichisalsoemployedin[MAFP19a].
thedatasetisattributedto[NRL∗12].Forexample,theaudiovisual Forthepurposeofprocessexecutiondataanalysis,Hildebrandtet
displayidiomofMatsubaraetal.[MMU16]createsaninteractive al.[HAR16]demonstratedhowincorporatingsoundcouldenhance
sonificationsystemforexplorationofseismicdatathroughahori- theprocessofidentifyinganomaliesorconductingrootcauseanal-
zontalandverticalrangeslidertospecifyageographicregion.Other ysisforirregularitiesanderrors.Adesignforamoregeneraluser
formsofinteractionincludesimplertaskssuchasbrowsingsonifica- casewascreatedbyNorthetal.[NSC16],whichcreatedaanidiom
tionsofindividualorgroupsofdataobjects[Rib19,LSB∗23].Hup- toconveyGitversioncontroldata.Thetemporalnatureofthedata
penkothenetal.[HPDW23]createdaninteractivemultimediaver- lentitselfwelltobesonifiedbysequentiallygoingthroughthedata,
sionoftheHertzsprung-RussellDiagram,whereausercanselectin- whereanearconisplayedwhenacommitoccurs,anddrumsounds
dividualdataentriesofthediagramtolistentotheirsonification.On areplayedwheneveraconflictoccursinthedata.
©2024TheAuthors.16of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
(a) (b) (c)
Figure7:Examplesofdifferenttargetplatformsandenvironments.(a)ThecombinationofVRvisualizationandsonificationforimmersive
explorationofnoiseinurbanenvironmentsbyBergerandBill[BB19].(b)Animmersivevirtualenvironmentforaudiovisualspatializeddata
sonificationpresentedbyChabotandBraasch[CB17].(c)AscreenshotshowingtheinteractiveinterfaceforsonifiedHertzsprung-Russel
diagrambyHuppenkothenetal.[HPDW23].AllscreenshotsCCBY4.0.
Thesecondmostcommonlyoccurringpairofusersandgoals whichhasbeenusedinonlytwopapers).Therefore,weonlydis-
waspublicengagementforthegeneralpublic,wheretheuseofan cusscorrelationsthatareplausibleandmostrelevanttothebigger
audiovisualdisplayidiomhasthepotentialtoenablehigherengage- picture.
mentbyconveyinginformationthroughboththevisualandaudi-
Close to the main diagonal of the correlation matrix we high-
torymodality.Thiswouldcommonlybetargetedtowardspopular
lighted four smaller matrices (1), showing an interesting phe-
sciencetopicssuchasclimatechange[HK22,Bal15]andastron-
nomenon:Wheneverthetaggingofthepaperswasdoneindividually
omy[HTHB22,TB23].Aspreviouslymentionedinsubsection3.2,
forthevisualizationandthesonificationparts,thetwoweremostly
theworkbyRussoetal.[RS22]isanexampleofasonification
taggedwiththesamelabel.Hence,thevisualizationsandthesonifi-
targetedtowardsthegeneralpublicforpublicengagement,where
cation,inmanycases,usethesamereadinglevels[Ber83],thesame
theresponseoftheresultingvideosonsocialmediawereinpart
searchlevels[Mun15],thesamedatasettypes,andthesamelevels
usedasametricforthepublicengagementofthedesign.
ofmeasurement.Thisfindingcanmotivatefutureresearchregarding
Discussion:Regardingthesuccessfuldesignofaudiovisualidioms, thereadinglevelsandthesearchlevels.Studiescouldinvestigatethe
actually supporting their users in analyzing data, it is most rel- potentialsofotherdistributionsofthereadinglevelontothesenses.
evant to include them in the design process. Both the visualiza-
Marked with (2), we highlighted four phenomena concerning
tioncommunityandthesonificationcommunityhaveindividually
thepurposeofanaudiovisualidiom.Idiomsdesignedtopresent
studiedtherelevanceofincludingdomainexpertsintheirdesign
rather than explore data are likely to also use the reading level
process[SMM12,Gou17],andthesamewillbenecessaryforthe
“whole”fortheirsonification(r=0.41).Ontheotherhand,idioms
integrationofsonificationandvisualization.Theco-authornetwork
thataredesignedforexploration,likelyusethegroupreadinglevel
showninFigure9displaysquitemanydomainexpertsbeingcol-
(r=0.3).Weseeacorrelationbetweenthepurposeofanidiom
laboratorsinthesurveyedliterature,whichcanberegardedasa
anditsinteractivity,withidiomsforexplorationmorelikelytobe
promisingsigningeneral.
interactive(r=0.23),andidiomsforpresentationmorelikelynotto
beinteractive(r= 0.48).Also,domainexpertsusemoreidioms
−
4. SurveyDataAnalyses forexploration(r=0.44),whilethegeneralpublicismorelikely
tobe‘just’presentedwithdata(r=0.50),goinghandinhandwith
So far, we have focused on the discussion of the audiovisual id- theirgeneralgoalsofdataanalysis(r=0.52)orpublicengagement
iomdesignsthemselves.Inthissection,wewanttotakeaneven (r=0.50).
broaderperspectiveonthecollecteddata.Wewillstudyexisting
relationshipsbetweendifferenttagsalongacorrelationmatrixin Twomorerelationshipswiththeinteractiontagemergeformthe
subsection4.1,aswellasthenetworkofco-authorsanditsimplica- correlationmatrix(3).Asonificationthatusesthereadinglevelsof
tionforthefieldinsubsection4.2. “group”or“single,”islikelytoofferuserinteraction(rgroup=0.45
andr =0.24),whileasonificationwiththereadinglevelof
single
“whole”usuallydoesnotofferuserinteraction(r = 0.28).
whole
−
4.1. CorrelationMatrixAnalysis Furthermore,designsthatmapdatatothesensesinacomplementary
wayaremorelikelytoofferinteractiontotheirusers(r=0.32).
Tounderstandpotentialrelationshipsbetweendifferenttagswithin
ourclassification,wecomputedacorrelationmatrix,showninFig-
ure8.Wewanttohighlightsomeofthefoundcorrelationsinthe
4.2. Co-AuthorNetworkandDevelopmentOverTime
data.Notethatoverallmostofthecorrelationsareclosetozeroand
aremostlikelynotsignificant.Also,someofthehighercorrelation As part of our meta analyses, we studied the co-author network
valuesthatcanbefoundinthematrixareverylikelynotsignificant, withinourdatabase.Eachnodeintheco-authornetworkrepresents
duetothelowamountofdataforthesetags(e.g.,theAPevaluation, anauthorwithatotalof165nodes(in48teams),andalinkconnects
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 17of27
1
1
1
1
3
2
Figure8:Thecorrelationmatrixofaselectionofclassificationtags.Adivergingcolorpaletteisusedwithwhiteinthecenterrepresentingno
correlation,teal(up)increasinglypositivecorrelations,andbrown(down)increasinglynegativecorrelations.(1)revealssimilartagsfor
visualizationandsonificationparts;(2)showscorrelationsbetweenpurpose,readinglevel,interactivity,andintendedaudience;(3)uncovers
relationshipswiththeinteractiontag.Ahigh-resolutionversionofthisfigureispartofthesupplementalmaterial.
twonodesifthecorrespondingauthorshavecollaborativelycon-
tributedtoapublication.Thethicknessofthelinksisproportional
tothenumberofpublicationssharedbetweentherespectiveauthors.
Weassignacolortoeachnodeusingtheprimarydisciplineofthe
author.Weclassifyeachauthor,tothebestofourabilities,intoone
offourdisciplines:sonification,visualization,domain,andunclas-
Sonification sified.Foreachauthor,weconsidertheirmainpublicationfocus
Visualization
Domain Expert particularlyaroundthetimeoftheircontributiontotheworksin
Unclassified
ourdatabase,alongwiththeirbackground,education,andtheirrole
andinputtotherelevantpapers.Authorsclassifiedunder“domain”
arerecognizedasdomainexpertsandthecategory“unclassified”
encompassesscenarioswheretheauthor’sprimarydisciplinedoes
notfallintoanyoftheotherthreecategories,theauthorisinthe
earlystagesoftheircareerwithoutadefinedresearchfocus,orthat
theinformationabouttheauthorisnotavailable.
Figure9:Theco-authornetwork,displaying165authorsofthe57 Thenetworkoffersseveralinsightsintothestructureofthefield.
papersinthedatabase.Thelinksrepresentpaperswrittenasateam Themajorityofco-authorteamsareindividualteamswithoutin-
ofco-authors,andthecolorsdisplaytheirprimarydisciplines.An terconnections.Onlyinfourcaseshaveauthorscollaboratedwith
interactiveversionofthenetworkcanbeexploredusingtheOrange different(groupsof)co-authors,usuallybecauseonepersonworked
workflowthatispartofthesupplementalmaterial. withdifferentcollaborators.Thisphenomenondiffersfromnetworks
inotherfields,suchastheonedescribedinarecentSTARontheuse
ofembeddingsinVisualAnalytics[HWKK23],showinganetwork
withclustersuptothesizeof75authors(notethattheSTARon
embeddingshas122entries).Weinterpretthedominanceofmany
disjointgroupsasasignfortheratheryoungfieldandhope,withthis
STAR,tocontributetothefuturedevelopmentofthefieldgrowing
©2024TheAuthors.18of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
8 aretheauditoryequivalenttovisualrepresentations,suchasplots,
graphs,andcharts[HHN11],butinsteadofmappingdataproperties
6 tolinepositionsorthesizeofanarea,theyaremappedtovarious
auditoryparameterssuchaspitchorloudness.Auditorygraphsare
4
suggestedtobeusefulassensorysubstitutionandasameansof
2 presentinginformationwhenlineofsightisnotpossible[SNH05],
andusingsoundtorepresentdatamightmakedataanalysismore
0
2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 accessible[WM10].Togivethereaderabriefintroductiontothis
category,hereareafewrecentstudiesthathaveexploredsonification
Figure10:Thebarchartshowsthenumberofpaperspublished
foraccessibilityinvisualization.
betweentheyears2011to2023.Generally,weseearisingtrendin
publicationsoverthecourseofthelast12years. Onestudyexploredtheaccessibilityofdatavisualizationspre-
senting data to blind and visually impaired users [FFSR∗23]. It
was found that sonification might make discerning trends in the
data more accessible, but also that the lack of experience in us-
closertogether.Weidentified14teamsorindividualauthorscon-
ingsonificationcouldleadtomisinterpretationsofthepresented
tributingtothefieldthathaveonlysonificationexpertsontheirteam.
data.Thestudywasconductedusingscreenreaders,andtheusers
Twooftheteamsconsistexclusivelyofvisualizationresearchers
oftenusedalt-textinformationtosupportandvalidatewhatwas
and21oftheteamsarecollaborationsbetweenthecommunities,
heardthroughthesonification.Anotherstudyexploredtheuseof
alsoincludingdomainexpertsmanytimes.Theinclusionofdomain
naturalsoundsmappedtodatavisualizations,barcharts,andline
expertsandthequitelargenumberofdiversegroupsalsoincluding
charts[HEUHEB23].Thereasonforusingnaturalsoundswasto
domainexpertscanbeconsideredapromisingsignforthefuture
supportuserswithoutmusicaltraininginunderstandingthesonifica-
developmentofthefield.
tionandauditorygraph,anditwasfoundthatthesenaturalsounds
Duringtheyears2011and2023,overall,57paperswerepub- couldsupporttheunderstandingofcategoricaldataandweremost
lished.Figure10displaysthemajorityofpapersbeingpublished usefulforuserswithoutmusicaltraining.Infographics,thecom-
inthesecondhalfofthistimespan,pointingtowardsagenerally binationofvisualizationandtextinformation,hasbeenexplored
increasingtrend.Thedropinpublicationsintheyear2020islikely withanauditory-onlyapproach[HGI∗22].Aninteractiveapproach,
aphenomenonrelatedtotheCOVID-19pandemic,beingdominant infosonic,wasexploredtofacilitateaccessibilityofdatatoblind
worldwideespeciallyduringtheyear2020. and low-vision users, using spoken introduction and annotation,
andnon-speechsonification.Thestudyshowsthatthesonification
approachsupportedunderstandingandformingamentalimageof
5. AdjacentTopics
thedata.Evenifonlyafewstudieshavebeenintroducedinthis
Asmentionedearlier,threedistincttopicsareadjacenttothescope texttherearemorestudiesonsonificationandaccessibility,andthis
ofourSTAR:audiovisualidiomsinthecontextofaccessibility,real- isimportantforindividualswhoareblindoroflowvisiontohave
timemonitoring,andarts.Althoughthethreeareasarerelated,they equitableaccesstodata,news,andinformation.
mightbebetterservedbyadifferentclassificationsystemthanthe
Oftenaccessibilitystudiestendtoblendsonification,i.e.,non-
oneweused.Still,theyarerelevantandcanbeinspirationalforour
speechsounds,withgeneratedspeechorscreenreaders.Thismakes
field.Thefollowingthreesectionspresentworkfromthoseadjacent
theinterpretationoftheresultsfromthesestudiessomewhatchal-
fieldsthathavebeencuratedbyourteamofco-authors.Thesections
lenging.Thefindings,i.e.,theexperiencesandtheunderstandingof
donotclaimcompletenessortheusageofasystematicapproach
thesonification,mightbeduetothesonificationitself,ordepending
butareindentedasageneralintroductionfortheinterestedreader.
onotherauditorystimuliused.Also,thevisualrepresentation,the
userinteraction,anduser-interfacearelikewiseofimportancefor
5.1. Accessibility thestudyoutcome.Invisualdataanalysisinteractionisessentialfor
exploringthedata[CGM19],andsimilarly,forsonificationtobea
Even though visualization is one of the most common ways of
usefultooldynamichumaninteractionisnecessary[HH04].Never-
communicatingdata,manyvisualizationsareinaccessibletoreaders
theless,sonificationforaccessibilityofvisualizationforthevisually
withvisualimpairments.Somestudieshavesuggestedtheuseof
impairedisaninterestingapproach.Someofthesefindingsmight
sonificationtosupportreaderswithvisualimpairments.Duringthe
suggestinterestingapproachesalsoforreaderswithnormalorcor-
filteringandclassificationoftheassembledliterature,acategory
rectedtonormalvisualacuityinsupportingvisualperceptionwith
emerged exploring sonification for accessibility of visualization.
sonification[Rön19a,Rön19b],orreducingcognitiveload[ZPR16]
The literature that was sorted into this category focused on the
onthevisualmodalitybysonification(seeforexample[MLS95]).
designandevaluationofsonificationtoimproveaccessibilityof
visualizationsforvisuallyimpairedpeople.Astheliteratureinthis
categorywasnotexploringintegratedaudiovisualrepresentations
fordataanalysisingeneral,butratherusingsonificationasasupport 5.2. Monitoring
tool,thesearenotincludedinthesystematicpartofourSTAR.
Acomprehensiveovervieworasystematicliteraturereviewofau-
Sonificationforaccessibilityinthiswayoftensuggestssonifi- diovisualprocessmonitoringisfarbeyondthescopeofthisreport.
cationdesignsleaningtowardsauditorygraphs.Auditorygraphs Therefore,thissectionisintendedtoprovidesomeinsightsintothis
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 19of27
researchfieldandtodistinguishthevariousscientificcommunities asecondarydomainwhilesimultaneouslyperformingaprimary
involved. task[LWP∗13,HHRM16,TML∗15,NGJW14].
Thecombinationofvisualandauditorydisplaysforprocessmon- (Non-)systematicliteraturereviewshavebeenpublishedinsev-
itoringpurposeshasbeenwell-establishedinreal-worldapplica- eralofthementionedareas[WMY∗17,KIK19,SMS21,HRM15].
tionsandinterfaces.TheaudiovisualrepresentationofMorsecode To the best knowledge of the authors, no comprehensive STAR
for an exchange of information serves as an early example of a coveringtheentirespectrumofaudiovisualorrelatedmulti-modal
multi-modalmonitoringdisplayandinterface.Insupervisingand monitoringapplicationsandapproacheshasbeenconductedthus
controllingthestatesofvariousdevicesandprocesses,audiovisual far.However,therearesomefundamentalpublicationstreatingthe
interfacescombinetheadvantagesofbothmodes:volatilealerting specificattributesandcriteriaforresearchanddevelopmentinthe
soundsignalsenhancesituationawareness,whilevisualcuespro- field,suchas[Ibe20,Joh04,WS07].
videadditionalinformationaboutthesituation,enablingusersto
takeaction.Implementationsofaudiovisualinterfacesareubiqui-
tousinbothprofessionalandday-lifeenvironments.Forinstance,
5.3. Arts
considerthewarningbeep,whichcanbeheard,whenthetempera-
tureoutsideyourcardropsbelow4°C,alertingyoutothepossibility Duringtheclassificationofthecorpus,an“art”categoryemerged,
ofslipperyroadconditions.Aquickglanceatthevisualdisplay definingprojectscombiningvisualizationandsonificationforartis-
willprovideyouwiththeexacttemperatureandtheopportunityto tic purposes. We understand the emergence of art practices that
decidewhethertotakeactionornot. intertwinesonificationandvisualizationnotonlyasinspiringfor
designersandaudiencesalike,butalsorelevanttothebroaderdis-
Besidestheapproachestoaudiovisualdataanalysisdescribed
coursearounddatarepresentationtowardsabetter,moreefficient,
in the previous sections of this report, audiovisual monitor-
andengaginghuman-datarelationship.
ing interfaces play an integral role in various domains, in-
cluding air traffic control [EBL∗23], control rooms [SFLD22, Workingwiththeliterature,weunderstoodartisticendeavorscall
HHG∗12],anesthesia[AQH∗21,RMS∗22],neurology[LCS∗28],
foradifferentkindofclassificationthanidiomsintendedforaudio-
dermoscopy [WRK∗19], surgery [Zie23], network monitor- visualdataanalysis.Wedecidedtonotincludesuchcontributionsin
ing[Wor19a,AHvR∗21],automotive[JDS15,XWX∗22],tonamea
thesystematicpartofthisSTARevenwhentheycompliedwiththe
few. requirementofbeingpublishedinanacademicjournalanddealing
withthesimultaneouscombinationofvisualizationandsonifica-
DuringliteraturesearchforthisSTAR,severalpublicationswere
tion.Weexcludedpaperswhereauthorsmadetheirintentionsofan
labeledwiththetag“monitoring”.Aftercloserinvestigation,which
artisticcontributionexplicitinthepaper.
involvedexcludingmultiplepublicationswrittenbyidenticalauthors
onverysimilartopics,aswellaspublicationsaddressingtopicsof Nevertheless,togivethereaderabriefintroductiontothefield,we
accessibilityandartisticmediainstallations,onlyarelativelysmall presentrepresentativecasesofanemergingartcategorythatcould
representativesubsetof14findingsqualifiesforaudiovisualprocess formthebasisoffutureresearchontheintegrationofsonification
monitoringwithinthesearchcriteriaofthisSTAR. andvisualization.Inadditiontotheartisticcasesthatemergedfrom
Thereasonsforthisratherlimitednumberofretrievedarticles ourliteraturesearch,weusefourmoresourcestocurateacollection
inthiscategoryaremanifold.Firstly,mostresearchonmonitoring ofrepresentativecasesforartisticendeavors:TheDataSonification
applicationsusedforauditoryfeedbackofhumanbehaviorinthe Archive(DSA),theComputerMusicJournal,theLeonardoMusic
fields of sports, therapy, or rehabilitation focuses on the design, Journal, and the Ars Electronica Festival. The Data Sonification
impact,andevaluationofinterfacesthatutilizethenon-intrusive Archiveisanonlinecrowd-sourcedcollectionofdatasonification
attributesofauditorydisplays,enablinguserstoperceiveinforma- projects.Outof455casescurrentlyhostedintheDSA,threeofthe
tionwithoutanyinterferingactions,suchasadjustingtheirheador co-authorsofthisreportrecentlycategorized139casesas“art”,i.e.,
bodypositiontoviewavisualdisplay[SJMT19,VRGM20,MNS16]. ashavingtheirprimarypurposeincreatinganddeliveringanartistic
Whilesomeoftheseinterfacesincludevisualizationsatalowscale experiencetoanaudience[LLC23].Apreliminarysearchonsome
level,theyhardlyqualifyasaudiovisualmonitoringdevicesinterms ofthemajorvenuesforacademicartisticpublications–Computer
ofprovidingabalancedcontributionfrombothmodalities. MusicJournalandLeonardoMusicJournal–accountsfor182and
118casesrespectively,inlinewiththevolumeofart-relatedcases
Inindustrialandsurveillancecontexts,whichisanotherreason
in the Data Sonification Archive. A search of the archive of the
for the limited number of results in our search, factors such as
renownedArsElectronicaFestivalonprojectsthattranslatedata
cognitiveworkload,perceptionorganization,situationalawareness,
intoanaudiovisualidiomreturns32cases,again,inlinewiththe23
alarm fatigue, and deafness play crucial roles in the successful
projectscurrentlyhostedontheDSA.
implementation of infrastructures. However, these attributes are
discussedinotherscientificcommunities,includingHumanFac- Typically,data-drivenartworksthatuseanaudiovisualdesign
torsandAppliedErgonomics,aswellasseveralareasofmedicine addressanon-expertaudienceandcantakedifferentformssuch
and health, particularly in anesthesia, rehabilitation, sports, and asliveperformances,multimediainstallations,videoproductions,
cognitivepsychology.Inadditiontoperformancecomparisonsbe- orwebexperienceswherethesonificationandvisualizationofthe
tweenauditory,visual,andaudiovisualmodalities[AG19],partic- samedatasetarecombined.TheDSAclassificationhighlightsre-
ularinterestisgiventothedual-taskparadigm,whichevaluates, curringtopicssuchasclimatechangeand/ortherepresentationof
for instance, the ability to identify an event requiring action in environmentaldata;individualandcollectiveinteractionintheurban
©2024TheAuthors.20of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
space;internetandsocialmedia.Thepredominanceofsociallyrele- 6. ConcludingDiscussionandFutureWork
vanttopicsshowsthattheemergingartcategorypresentsborderline
InthisSTAR,wehaveprovidedanoverviewofthefieldofaudiovi-
characteristicswiththeadjacentcategory(intheDSAclassification
sualidiomdesigntailoredtowardsdataexplorationandpresentation.
system,see[LLC23])of“publicengagement”.Thislattercategory
Wehaveusedavarietyofperspectivestoclassifytheexistinglit-
identifiesprojectsthat,althoughbeingoftenpresentedintheform
erature.Foreachofthesecategorizations,wealsoprovideabrief
ofanartisticexperience,haveexplicitlyandprimarilythegoalof
discussionorreflection.Insection5,weofferedinsightsintothree
increasingawareness–evenfosteringactivism–amongthegeneral
topicsthatareadjacenttoourreportandcanbehighlyinspirational
public,onaspecificphenomenon.
forfuturedevelopments.Inthefollowingsection,wetakeastep
back,adoptaglobalviewpoint,anddiscussthebroaderinsights,
Thisisthecaseforprojectsthatpresentdatarelatedtoclimate challenges,andexcitingfutureresearchopportunities.
changesuchasKlima|Anlage—Performingclimatedata[GHJ∗19],
Thecultureofprovidingsupplementalmaterial:Athrivingfu-
oneofthecasesidentifiedasartisticinourliteraturesearch.Inthis
tureforthefieldofaudiovisualidiomdesignalsodependsonthe
work,climatedatafrom1950to2100canbechosenbythelistener
communities’culturewhenprovidingdemosfortheirdesignsas
fortwelveselectedregionsoftheworldandinteractivelysonified
supplementalmaterial.Outof57articlesinoursurveyedliterature,
andvisualizedinanimmersiveinstallationenvironmentwiththe
only29providedademothatisstillavailabletoday.Fiveprovided
goalofcontributingto“theurgentneedtoinformthegeneralpublic
ademothatisnolongeravailable,and23providednodemoatall.
aboutclimatechange”.
OnlinerepositoriessuchasZenodo,hostedbyCERN,orlong-term
archivessuchasPhaidra,hostedbytheUniversityofVienna,allow
InTooBlue[Foo15],hostedontheDSA,theauthorcreatedan
theuploadofvideosandeventheassignmentofDOIs.Whilemak-
audiovisualexperience(intheformofavideo)wheremusicgener-
ingsoundavailableinapaperusedtobeanexplicitchallengetothe
atedbytrackingthelandlossincoastalLouisianaover78yearsdue
sonificationfield,itisnotthecaseanymore.Anadditionalvisual
toman-madelevees,drillinganddredgingforoilandgas,andcli-
representationofthesoundcanalsobeincludedinthepaper,using
matechangeiscombinedwithanaerialcolor-codedvisualmapthat
aspectrogramofthesounditselforaniconicrepresentationofit.
showstheincreaseinthe“blues”coloredareas,correspondingto
thesea,inthecoastallandofLouisiana.InHeatandtheHeartbeat Evaluatingaudiovisualidioms:Itisoftenchallengingtoconduct
oftheCity[Pol06],theurgencytocommunicateclimatechangeto systematic,well-informed,andaboveall,properlyperformedand
thebroaderaudiencecombineswithareflectionontheurbanspace reportedevaluationsofaudiovisualidioms.Especially,whenthe
throughthesimultaneoussonificationandvisualizationofactual goalistocomparedifferentstudies.Asmentionedearlier,Rönnberg
andprojecteddataonincreasedtemperatureinNewYorkCity.In andForsellsuggestedthestandardizationofquestionnairestailored
aqua_forensic[SŠ18]dataoninvisiblepollutantsintheDanube tothefieldinordertoincreasethecomparabilitybetweendiffer-
river’swater,andtheeffectonitsecosystem,arecollected,sonified, entstudies[RF22].Establishingthiscomparabilityisparticularly
andvisualized‘topresenttheresultsofthisscientificresearchtothe difficultbecausethetwosensesareusedsimultaneouslyinanau-
wideaudienceinapoeticandartisticway’.Otherprominentsocial diovisualdisplay,andtheevaluationmethodsmustadapttothis
issuessuchaspersonaldatacollectionandprivacyintheageofso- characteristicofthedesign.Specifically,theexistingmethodsfo-
cialmediaareatthecenterofmulti-awardedartprojectssuchasDig- cus on several aspects. One is user performance, which studies
italViolence[FE21]wheresonificationisexplicitlyusedtoincrease quantitativemetricssuchastaskcompletiontimesandprecisionof
theaudience’sengagementwiththevisualizeddatasetontheissue responses.Anotherisuserexperience,whichfocusesmoreonquali-
ofillegalgovernmentsurveillancepractices.Fromthecollectiveto tativemetricssuchasuserengagement,andmemorability.Fromthe
theindividualexperience,projectssuchasOrbuculum[Ylm23]and datawecollectedinourSTAR,wecandrawhigh-levelconclusions
DeepSync[KOR23]invitethepublictointeractivelyengagewith regardingthetypeofevaluationsthathavebeenusedwithinthe
personalpsychologicalandphysiologicaldimensionstocreatean corpusofliterature.
immersiveauditoryandvisualexperience.Inamore-than-human
Mostofthepapersinthesystematicliteraturereviewusedsonifi-
perspective,workssuchasSpiderWebSonification[SQS∗20]and
cationtosupporttheperceptionofthedatavisualization,somealso
BiotaBeats[KGS∗20]shiftthefocusfromhumanstootherspecies
aimedtoprovideadditionalinformationviatheauditorychannel
inanefforttosupportthepublicengagementwithscience.
complementingthevisualization,andanadditionalfewaimedfor
publicengagementorfacilitatingmulti-useranalysisofthedata.
Data art can stimulate an “artistic affectivization” that can Amongthepapersthatincludedauserevaluation,mostreporteda
contribute to building shared perspectives within a commu- subjectivelystatedbenefitofsonificationinperceivingandinterpret-
nity [BMLA22]. The engagement of the audience with the phe- ingthevisualization.Somesubjectiveratingsalsosuggestedthatthe
nomenonbehindthedata,however,alsoimpliesaninformationand useofsonificationwasengaging,couldprovideemotionalcontent,
knowledgetransfer[MVC∗10]i.e.thepublichasnotonlytoconnect andwasexperiencedasinterestingorpleasant.Otherpapersalsore-
emotionallywiththedata,butalsounderstandtheirmeaning.The portedobjectivemeasurementsofincreaseduserperformancewhen
emergenceofacategoryofartisticprojectsthatcombinesonification sonificationandvisualizationwereusedincombinationcomparedto
andvisualizationwiththeexplicitintenttoactivatetheaudienceon visualizationalone.Thiswasshownintermsofhigherscoresorin-
asociallyrelevantissueshowsthatmultimodalapproacheshavethe creasedaccuracywhensonificationwasused.However,thisincrease
potentialtogenerateimpact,notonlyforeducationandawareness inaccuracywasreportedtoberelatedtoincreasedtaskcompletion
butalsoforstimulatingaction. times. Similar effects have also been shown in other studies not
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 21of27
includedinthissystematicreview[MBKSM16,Rön19a,Rön19b]. window,tonotonlyseebutalsohearthesoundoftheraingives
Theseresultsindicatethatthereis,ingeneral,abenefitofcombin- usabetterestimationoftheamountandintensityoftherainfall.
ingvisualizationandsonificationfordataexplorationandanalysis, Abstractly,insuchasituationweperceiveaspatio-temporalphe-
regardlessofthespecificvisualizationand/orsonificationdesign. nomenon.Itismostplausiblethataddingsoundtoatimeseriesof
Thisbenefitcanbemanifestedinhigheruserengagement,increased scientificvisualizationcanincreaseitsholisticinterpretabilityin
user performance with higher scores or accuracy, or with more anecologicallyvalidmanner[Neu04].Thisphenomenonisshown
information conveyed to the user via both modalities. However, intwopublicationsinthedatabase,intheworkbyMacDonaldet
improvementsinaccuracymightcomewiththecostofincreased al.[MNW∗18],andtheworkbyTemoretal.[TMN∗21].Similarly,
taskcompletiontimes.Thecasemightbethattheuseoftheaddi- theseideasalsoapplytoanimationsininformationvisualization
tionalinformationprovidedbysonificationthatmakestheincreased wheretemporalaspectsofthedatamightbevisualizedandsonified.
accuracypossibletakeslongertimetoprocessandassess.While
Designframeworks:Whenitcomestothepossibilitiestodesign
traditionallyincreasedtaskcompletiontimesareconsideredadis-
audiovisualdisplayidioms,mostresearchers,aswellasmostdo-
advantage,insomecontextsthiscanbeseenaspositive.Slowing
mainexperts,willnotbeabletosuccessfullydeveloptheirown
downtheuserresultinginthemspendingmoretimewiththeirdata,
designs.Interdisciplinaryknowledgebridgingvisualization,soni-
studyingitfrommoreandfromdifferentperspectives(including
fication,interactivedesign,andhumanperceptionisnecessaryto
theauditoryperspective),mightrevealstructuresorpatternsina
designeffective,engaging,andre-usableaudiovisualdisplayidioms.
dataset,thatwouldhavestayedsilentandunseenifanalyzedwitha
Therefore,wecannotexpectadomainexperttobeabletoquickly
conventionaluni-modaldisplay[HAS11].
draftaprototypethesamewaytheymaybeabletodousingestab-
Thepotentialofunconventionaltaskdistribution:Thedatafrom lishedvisualization-onlyframeworkssuchasmatplotlib[Hun07].
ourSTARshowsthatreadinglevels[Ber83]arenotequallydis-
Inourdatabase,weidentifiedseveraldesignframeworkstack-
tributedtothetwosenses:Thevastmajority–50outof57papers
lingthischallenge[PC19,PCB23,LF21,DLVDCG22,KLTW17,
usedthereadinglevel“whole”fortheirvisualization(seeTable2),
CWM21].Theirprimaryfocusisthedesignofthesonificationpart
whileonlyabouthalfofthepapersusethesamereadinglevelfor
oftheidiom,whichiswhywecannotspeakoftrulybalancedcon-
theirsonificationparts.Thisobservationmightbedirectlyrelatedto
tributionstobothsenses.Apromisingendeavortoenabletrulybal-
thewayaudiovisualidiomsdistributethetasksofoverviewandde-
anceddesigns,withboththevisualizationandthesonificationbeing
tailtothetwosenses.Thecurrentlymorepopulardistributionseems
equallywell-informed,mightbetonotdesignthemusingone,but
tobetousevisualizationtodisplayanoverviewofthedatawhile
twoseparateframeworks,eachspecializedforitspurpose.Inthisre-
sonificationisemployedtoprovidedetails.Whilethisdistribution
gard,therecentworkbyReinschandHermann[HR21,RH22,RH23]
seemslikeanintuitivechoice,futureresearchshouldstudythepo-
ispromising,asitprovidesasonificationdesignframeworkembed-
tentialofswitchingtherolesbetweensonificationandvisualization.
ded in the Python environment and is conceptually inspired by
Itisourdailylivesandthewayweexperiencetheworldaround
visualizationdesigntoolssuchasmatplotlib.Withboththesonifi-
us,thatsuggeststosonifyanoverviewandtovisualizedetails.Our
cationdesignandthevisualizationdesignhappeninginthesame
auditorysenseconstantlyscreensour360°environmentwhileour
environment,inthiscase,forexample,aJupyterNotebook,both
visualsenseactivelyfocusesondetailsinourenvironment.Thefield
canbedevelopedwiththerequiredqualitytomeettheirindividual
ofauditoryprocessmonitoringmakesuseofexactlythissituation
standards.Regardingtheintroductionofuserstoanewdesignenvi-
whenalertingusofastatus,regardlessofourcurrentvisualfocus.
ronment,beitforvisualization,sonification,ortheircombination,
Nevertheless,weidentifiedonlythreecaseswherethereadinglevel
effective“onboarding”isapressingissue.Inthevisualizationcom-
forthesonificationwas“whole”andtheoneforthevisualization munity,thetopichasbeenstudiedinrecentyears[SPA23,SWG∗23],
was“group”[DLVDCG22,FBC12,YH18].
andthesamewillbenecessaryforsonification,andaudiovisualdis-
playidioms.Again,whenitcomestosonificationasatechniqueto
Asecondphenomenonweobserveinthedataisthatmanyaudio-
displaydata,thepriorexperienceofdomainexpertsorthegeneral
visualdisplayidiomsemploythesamesearchlevel[Mun15](see
publicislow.Thislackofexperiencecan,intheshortterm,onlybe
Figure8)andmostofthememploythesearchlevelof“explore”
metwithcarefullydesignedonboardingprocesses.
(seeTable2).Again,itseemslikeafruitfulfutureendeavortostudy
theopportunitiesofdesignsthatexplicitlybreaksuchapattern. Adjacenttopicsasinspirationtothefield:Ourbrieflookinto
the adjacent fields ofmonitoring, accessibility, andarts shows a
Thepotentialofintegratingsonificationandscientificvisualiza-
specialpotentialforinspirationforourcommunities’futurework.
tion:Mostarticlesinourdatabasecanberegardedasrelatedto
Thefieldofmonitoringoffersestablishedevaluationmethods,that
thefieldofinformationvisualization,ratherthanscientificvisual-
couldpotentiallybeadoptedtosupporttheevaluationofaudiovi-
ization.Scientificvisualizationtypicallydisplaysinherentlyspatial
sualidiomstailoredtowardsexploratorydataanalysis.Duringour
phenomenaandisoftenusedtorepresentdatathatvariesovertime.
unstructuredinvestigationintothefield,wealsoidentifiedthepo-
Theinherentlyspatio-temporalqualityofsuchdisplaysconstitutes
tentialofasystematicSTARasafuturecontributiontothefieldof
theirpotentialtobeintegratedwithsonification,assonificationisa
displaytechniquetailoredtowardtemporaldatastructures[ERI∗23]. monitoring.
Werelatethisargumentbacktothereal-worldexamplefromour Also,theadjacentfieldofaccessibilitycaninspirefutureresearch,
introductionwherethecombinationofourvisualandourauditory whereunderstandingtheanalysispatternsofvisuallyimpairedin-
sensesofferabetterunderstandingofaphenomenonthanbyeach dividualscaninformdesigndecisionsforidiomstailoredtowards
sensealone:Rainfallingoutsideofaclosedwindow.Openingthe sightedpeople[WM10].Whilethefieldofaccessibilitycanbein-
©2024TheAuthors.22of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
formativetothefieldofaudiovisualaudiovisualdisplayidioms,the References
sameholdstruetheotherwayaround.Especiallythedesignsfrom
[AG17] ANDREOPOULOUA.,GOUDARZIV.:Reflectionsontherepresen-
ourSTARthatusearedundantmappingtoboththevisualandthe tationofwomenintheInternationalConferencesonAuditoryDisplays
auditorysense,whichcaninspiredesignsforvisuallyimpairedusers. (ICAD).InProceedingsofthe23rdInternationalConferenceonAuditory
Furthermore,suchdesignshavethepotentialtofostersuccessful Display(ICAD2017)(PennsylvaniaStateUniversity,June2017),Georgia
InstituteofTechnology,pp.43–48.doi:10.21785/icad2017.031.
collaborativedataanalysisinvolvingbothsightedandblindusers.
3
Theidentifiedartisticcontributionsshowgreatpotentialtobe [AG19] AUDRYE.,GARCIAJ.: Congruentaudio-visualalarmsforsu-
inspirationaltothefieldofaudiovisualidiomdesignaswell.Inthe pervisiontasks.InProceedingsofthe25thInternationalConferenceon
AuditoryDisplay(ICAD2019)(NewcastleuponTyne,June2019),De-
future,effortshouldbemadebytheresearchcommunitytodevelop
partmentofComputerandInformationSciences,NorthumbriaUniversity,
aspecificframeworkfortheevaluationandanalysisofaudiovisual pp.7–11.doi:10.21785/icad2019.022.19
idiomsatthecrossingofartandpublicengagementtoexplorehow
[AG21] ANDREOPOULOUA.,GOUDARZIV.:Sonificationfirst:Therole
specific design strategies (e.g., interactivity and embodiment, as oficadintheadvancementofsonification-relatedresearch.InProceedings
usedinmanyofthecasespresentedinsubsection5.3)canbecom- ofthe26thInternationalConferenceonAuditoryDisplay(June2021),
binedtosupportbothaffectandsense-making.Again,asystematic GeorgiaInstituteofTechnology,pp.65–73.URL:http://hdl.handle.net/
1853/66335.3
STARdedicatedtotheartisticperspectivewouldbeahighlytimely
contributiontothecommunity. [AHvR∗21] AXONL.,HAPPAJ.,VANRENSBURGA.J.,GOLDSMITH
M.,CREESES.: Sonificationtosupportthemonitoringtasksofsecu-
Anaudiovisualanalyticscommunity:Withthisstate-of-the-artre- rityoperationscentres. IEEETransactionsonDependableandSecure
Computing18,3(2021),1227–1244. doi:10.1109/TDSC.2019.
port,wehopetocontributetothefutureestablishmentofsystematic
2931557.19
researchonaudiovisualdisplayidiomdesign.Thecurrentdevelop-
[AJB∗18] ARBONR.E.,JONESA.J.,BRATHOLML.A.,MITCHELLT.,
mentconcerningthestudiedco-authornetworkandthetemporal
GLOWACKID.R.:Sonifyingstochasticwalksonbiomolecularenergy
developmentofpublicationnumbersinthefieldispromising.We landscapes.InProc.24thInternationalConferenceonAuditoryDisplay
hopetoreachresearchersfromboththe–todayoftendisjunct–vi- (ICAD2018)(MichiganTechnologicalUniversity,June2018),Georgia
sualizationandsonificationcommunities,inspiringthemforfuture InstituteofTechnology,pp.232–239. doi:10.21785/icad2018.
032.6,7
interdisciplinary collaborations, and to open their ears to take a
look. [AK11] ADHITYAS.,KUUSKANKAREM.:Thesonifiedurbanmasterplan
(sum)tool:Sonificationforurbanplanninganddesign. InProc.17th
InternationalConferenceonAuditoryDisplay(ICAD-2011)(Budapest,
Hungary,June2011).http://hdl.handle.net/1853/51918.6,7,12,13
SupplementalMaterial [AQH∗21] ANDRADEE.,QUINLANL.,HARTER.,BYRNED.,FALLON
E.,KELLYM.,CASEYS.,KIRRANEF.,O’CONNORP.,O’HORAD.,
AssupplementalmaterialtothisSTAR,weprovide:
SCULLY M., LAFFEY J., PLADYS P., BEUCHÉE A., ÓLAIGHIN G.:
Augmentingcriticalcarepatientmonitoringusingwearabletechnology:
•
corpus.bibandcorpus.rdf:publicationmetadataofthesurveyed
Reviewofusabilityandhumanfactors.JMIRHumanFactors8,2(2021),
literatureinBibTeXandZoteroRDFformat. e16491.doi:10.2196/16491.19
•
corpus-tagging.csv:atableholdingthesurveyedliteratureandall [ASH∗12] ALONSO-AREVALOM.A.,SHELLEYS.,HERMESD.,HOL-
oftheusedtags.Interestedreadersmayusethetabletoidentify LOWOODJ.,PETTITTM.,SHARPLESS.,KOHLRAUSCHA.: Curve
articlesthatfallintospecificcombinationsofclasses. shapeandcurvatureperceptionthroughinteractivesonification. ACM
Trans. Appl. Percept. 9, 4 (Oct. 2012). doi:10.1145/2355598.
authors.csv:atableholdingthenamesoftheauthorsinourSTAR
• 2355600.6,7,13,15
corpusandtheirprimarydiscipline.Interestedreadersmayuseit
toidentifypotentialfuturecollaborators.
[Bal15] BALLORA M.: Two examples of sonification for viewer en-
gagement:Hurricanesandsquirrelhibernationcycles. InProc.21st
•
corrmat.pdf:ahigh-resolutionversionofFigure8.
InternationalConferenceonAuditoryDisplay(ICAD-2015)(Graz,Aus-
authornet.ows:theOrangeDataMiningworkflowfile,usedto tria,July2015),GeorgiaInstituteofTechnology,pp.300–301. http:
•
generatetheco-authornetworkinFigure9(incl.theusedcolor //hdl.handle.net/1853/54172.6,7,12,16
schemefileauthornet_colorscheme.colors). [Bar97] BARRASSS.: AuditoryInformationDesign. PhDthesis,Aus-
tralianNationalUniversity,Canberra,1997.2
In addition, the corpus of relevant papers with tags, pub-
[Bar12] BARRASSS.:Theaestheticturninsonificationtowardsasocial
lication metadata and fulltext of open accesss work is avail- andculturalmedium. AI&Society27,2(May2012),177–181. doi:
able as a Zotero library at https://www.zotero.org/groups/ 10.1007/s00146-011-0335-5.3
integrationsonificationvisualization/items. [BB19] BERGER M., BILL R.: Combiningvrvisualizationandsoni-
fication for immersive exploration of urban noise standards. Mul-
timodal Technologies and Interaction 3, 2 (May 2019), 34:1–34:15.
doi:10.3390/MTI3020034.6,7,13,15,16
Acknowledgments
[BBV16] BALLWEGH.,BRONOWSKAA.K.,VICKERSP.:Interactive
WewouldliketothankPerMagnusLindborg,SchoolofCreative sonificationforstructuralbiologyandstructure-baseddrugdesign. In
ProceedingsofISon2016,5thInteractiveSonificationWorkshop,CITEC,
Media, City University of Hong Kong, for valuable feedback.
BielefeldUniversity(Bielefeld,Germany,2016).6,7,11,14,15
This research was funded in part by the Austrian Science Fund
[Bea11] BEARMANN.: Usingsoundtorepresentuncertaintyinfuture
(FWF):P33531-NandtheGesellschaftfürForschungsförderung
climateprojectionsfortheunitedkingdom.InProc.17thInternational
Niederösterreich(GFF)SC20-006,aswellasbytheKnutandAlice ConferenceonAuditoryDisplay(ICAD-2011)(Budapest,Hungary,June
WallenbergFoundation(grantKAW2019.0024). 2011).http://hdl.handle.net/1853/51922.6,7,10,15
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 23of27
[Ber83] BERTINJ.: SemiologyofGraphics:DiagramsNetworksMaps. [EBL∗23] ELMQUIST E., BOCK A., LUNDBERG J., YNNERMAN A.,
UniversityofWisconsin,Madison,1983.Originallypublishedin1967in RÖNNBERGN.: SonAir:thedesignofasonificationofradardatafor
French.2,3,5,11,16,21 airtrafficcontrol.JournalonMultimodalUserInterfaces17,3(2023),
137–149.doi:10.1007/s12193-023-00404-x.19
[BF12] BEARMANN.,FISHERP.F.: Usingsoundtorepresentspatial
datainarcgis. Computers&Geosciences46 (Sept.2012),157–163. [EEBR21] ELMQUIST E., EJDBO M., BOCK A., RÖNNBERG N.:
doi:10.1016/j.cageo.2011.12.001.6,7,10,12,13 Openspacesonification:Complementingvisualizationofthesolarsystem
[BM13] BREHMERM.,MUNZNERT.:Amulti-leveltypologyofabstract withsound.InProc.26thInternationalConferenceonAuditoryDisplay
visualizationtasks. IEEETrans.VisualizationandComputerGraphics (ICAD2021)(VirtualConference,June2021),InternationalCommunity
19,12(2013),2376–2385.doi:10.1109/TVCG.2013.124.2 forAuditoryDisplay,pp.135–142.doi:10.21785/icad2021.018.
5,6,9,12,15
[BM20] BOUCHARAT.,MONTÈSM.:Immersivesonificationofprotein
surface. In 2020 IEEE Conference on Virtual Reality and 3D User [ERI∗22a] ENGEK.,RINDA.,IBERM.,HÖLDRICHR.,AIGNERW.:
InterfacesAbstractsandWorkshops(VRW)(Mar.2020),pp.380–383. Towardsmultimodalexploratorydataanalysis:Soniscopeasaprototypi-
doi:10.1109/VRW50115.2020.00082.6,7 calimplementation. InProc.24thEurographicsConferenceonVisual-
ization(EuroVis2022)-ShortPapers(Rome,2022),TheEurographics
[BMLA22] BUENINGR.,MAEDAT.,LIEWK.,ARAMAKIE.:Between Association,pp.67–71. doi:10.2312/evs.20221095. 6,7,10,
factandfabrication:Howvisualartmightnurtureenvironmentalcon-
12,13
sciousness.FrontiersinPsychology13(2022).doi:10.3389/fpsyg.
2022.925843.20 [ERI∗22b] ENGEK.,RINDA.,IBERM.,HÖLDRICHR.,AIGNERW.:
TowardsMultimodalExploratoryDataAnalysis:SoniScopeasaProto-
[BPS06] BERTINIE.,PLAISANTC.,SANTUCCIG.(Eds.):Proceedings
typicalImplementation.InEuroVis2022-ShortPapers(2022),AgusM.,
ofthe2006AVIworkshoponBEyondtimeanderrors:novelevaluation
AignerW.,HoelltT.,(Eds.),TheEurographicsAssociation,pp.67–71.
methodsforinformationvisualization. ACM,2006. doi:10.1145/ doi:10.2312/evs.20221095.11
1168149.2
[ERI∗23] ENGEK.,RINDA.,IBERM.,HÖLDRICHR.,AIGNERW.:
[BTB23] BRUE.,TRAUTNERT.,BRUCKNERS.:LineHarp:Importance-
Towardsaunifiedterminologyforsonificationandvisualization.Journal
drivensonificationfordenselinecharts.InProceedingsofIEEEVisualiza-
onPersonalandUbiquitousComputing27(2023),1949–1963. doi:
tionandVisualAnalytics(VIS)2023–ShortPapers(2023),pp.186–190.
10.1007/s00779-023-01720-5.1,3,10,21
arXiv:2307.16589,doi:10.1109/VIS54172.2023.00046.
6,7,12,13,14 [FBC12] FERGUSON S., BEILHARZ K., CALÒ C. A.: Navigationof
interactivesonificationsandvisualisationsoftime-seriesdatausingmulti-
[CB17] CHABOTS.,BRAASCHJ.:Animmersivevirtualenvironmentfor
touchcomputing. JournalonMultimodalUserInterfaces5,3(May
congruentaudio-visualspatializeddatasonifications. InProc.23rdIn-
2012),97–109.doi:10.1007/s12193-011-0075-3.6,7,10,12,
ternationalConferenceonAuditoryDisplay(ICAD–2017)(Pennsylvania
13,15,21
StateUniversity,June2017),GeorgiaInstituteofTechnology,pp.203–
210.doi:10.21785/icad2017.072.6,7,12,14,15,16 [FE21] FORENSIC ARCHITECTURE, ENO B.: Digitalviolence,2021.
Webpage: https://sonification.design/#DigitalViolence. Last accessed:
[CGM19] CENEDAD.,GSCHWANDTNERT.,MIKSCHS.:Areviewof
Dec21st2023.20
guidanceapproachesinvisualdataanalysis:Amultifocalperspective.
ComputerGraphicsForum38,3(2019),861–879. doi:10.1111/ [FFSR∗23] FAND.,FAYSIUA.,RAOH.,KIMG.S.-H.,VAZQUEZ
cgf.13730.18 X., GRECO L., O’MODHRAIN S., FOLLMER S.: The accessibility
[CLR22] CAIOLAV.,LENZIS.,RICCÒD.: Audiovisualsonifications: ofdatavisualizationsonthewebforscreenreaderusers:Practicesand
Adesignmapformultisensoryintegrationindatarepresentation. In experiencesduringcovid-19.ACMTransactionsonAccessibleComputing
DRS2022:Bilbao(2022).doi:10.21606/drs.2022.380.1,3,10, 16,1(2023),1–29.18
11 [FN18] FITZPATRICKJ.,NEFFF.:Streamsegregation:Utilizingharmonic
[CMS99] CARDS.K.,MACKINLAYJ.D.,SHNEIDERMANB.(Eds.): varianceinauditorygraphs.InProc.15thSoundandMusicComputing
ReadingsinInformationVisualization:UsingVisiontoThink. Morgan Conference(SMC2018)(Limassol,Cyprus,2018),Zenodo,pp.52–59.
Kaufmann,SanFrancisco,1999.1,3
doi:10.5281/zenodo.1422501.6,7,10
[CWM21] CANTRELLS.J.,WALKERB.N.,MOSENGØ.:Highcharts [Foo15] FOOB.:TooBlue,2015.Webpage:https://sonification.design/
sonificationstudio:Anonline,open-source,extensible,andaccessible #TooBlue.Lastaccessed:Dec21st2023.20
datasonificationtool.InProc.26thInternationalConferenceonAuditory [FPS∗21] FRANCONERIS.L.,PADILLAL.M.,SHAHP.,ZACKSJ.M.,
Display(ICAD2021)(VirtualConference,June2021),GeorgiaInstitute HULLMANJ.:Thescienceofvisualdatacommunication:Whatworks.
ofTechnology,pp.210–216.doi:10.21785/icad2021.005.6,7,
PsychologicalScienceinthepublicinterest22,3(2021),110–161.2
10,12,13,21
[Fri08] FRIENDLYM.:ABriefHistoryofDataVisualization.InHand-
[DB13] DUBUSG.,BRESINR.:ASystematicReviewofMappingStrate-
bookofDataVisualization,ChenC.-h.,HärdleW.,UnwinA.,(Eds.),
giesfortheSonificationofPhysicalQuantities.PLoSONE8,12(2013),
SpringerHandbooksComp.Statistics.Springer,Berlin,Heidelberg,2008,
e82491.doi:10.1371/journal.pone.0082491.3,10,11
pp.15–56.doi:10.1007/978-3-540-33037-0_2.2
[dC07] DECAMPOA.:Towardadatasonificationdesignspacemap.In
[Fry05] FRYSINGERS.P.:Abriefhistoryofauditorydatarepresentation
Proceedingsofthe13thInternationalConferenceonAuditoryDisplay
tothe1980s.InProceedingsoftheInternationalConferenceonAuditory
(2007),pp.342–347.URL:http://hdl.handle.net/1853/50042.2,3
Display(2005).URL:http://hdl.handle.net/1853/50089.2
[DCM∗18] DUM.,CHOUJ.-K.,MAC.,CHANDRASEGARANS.,MA [GDAS∗18] GUNEA.,DEAMICISR.,SIMÕESB.,SANCHEZC.A.,
K.-L.: Exploring the role of sound in augmenting visualization to
DEMIREL H. O.: Graphically hearing: Enhancing understanding of
enhance user engagement. In 2018 IEEE Pacific Visualization Sym-
geospatial data through an integrated auditory and visual experience.
posium (PacificVis) (Kobe, Apr. 2018), IEEE, pp. 225–229. doi:
IEEEComputerGraphicsandApplications38,4(July2018),18–26.
10.1109/PacificVis.2018.00036.6,7,10,12,13
doi:10.1109/MCG.2018.042731655.6,7,12
[DLVDCG22] DELAVEGAG.,DOMINGUEZL.M.E.,CASADOJ.,
GARCÍAB.:Sonounoweb:Aninnovativeusercentredwebinterface.In
[GH12] GROND F., HERMANN T.: Singing function: Exploring au-
ditory graphs with a vowel based sonification. Journal on Multi-
HCIInternational2022–LateBreakingPosters(Cham,2022),Stephani-
modal User Interfaces 5, 3-4 (May 2012), 87–95. doi:10.1007/
disC.,AntonaM.,NtoaS.,SalvendyG.,(Eds.),CommunicationsinCom-
s12193-011-0068-2.3
puterandInformationScience,SpringerNatureSwitzerland,pp.628–633.
doi:10.1007/978-3-031-19679-9_79.6,7,10,13,21 [GHJ∗19] GROSS-VOGT K., HERMANN T., JURY M. W., STEINER
©2024TheAuthors.24of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
A.K.,KARTADINATAS.:Klima|Anlage—performingclimatedata.In [HHRM16] HILDEBRANDTT.,HERMANNT.,RINDERLE-MAS.:Con-
AddressingtheChallengesinCommunicatingClimateChangeAcrossVar- tinuoussonificationenhancesadequacyofinteractionsinperipheralpro-
iousAudiences,LealFilhoW.,LacknerB.,McGhieH.,(Eds.).Springer, cessmonitoring.InternationalJournalofHuman-ComputerStudies95
Cham,2019,pp.339–355.doi:10.1007/978-3-319-98294-6_ (2016),54–65.doi:10.1016/j.ijhcs.2016.06.002.19
21.20
[HK22] HANY.C.,KHANDUJAA.:Thefutureisred:Visualizingwild-
[GKW21] GROPPE S., KLINCKENBERG R., WARNKE B.: Soundof firepredictionsusingcontactlessinteraction.InExtendedAbstractsofthe
databases:Sonificationofasemanticwebdatabaseengine.Proc.VLDB 2022CHIConferenceonHumanFactorsinComputingSystems(New
Endow.14,12(July2021),2695–2698. doi:10.14778/3476311. York,NY,USA,2022),CHIEA’22,AssociationforComputingMachin-
3476322.6,7,13 ery.doi:10.1145/3491101.3519903.6,7,9,12,15,16
[Gou17] GOUDARZIV.:SystematicProceduretoDevelopSonifications. [HPDW23] HUPPENKOTHEN D., PAMPIN J., DAVENPORT J. R. A.,
PhDthesis,UniversityofMusicandPerformingArtsGraz,2017.16 WENLOCKJ.:Thesonifiedhertzsprung-russelldiagram.InProc.28th
[GR11] GOMEZ I., RAMIREZ R.: A data sonification approach to InternationalConferenceonAuditoryDisplay(ICAD2023)(Norrköping,
cognitivestateidentification. InProc.17thInternationalConference Sweden, June 2023), Georgia Institute of Technology, pp. 272–279.
on Auditory Display (ICAD-2011) (Budapest, Hungary, June 2011). doi:10.21785/icad2023.6263.5,6,9,11,15,16
http://hdl.handle.net/1853/51569.5,6,12
[HR21] HERMANNT.,REINSCHD.: Sc3nb:APython-SuperCollider
[GRK∗16] GIONFRIDAL.,ROGINSKAA.,KEARYJ.,MOHANRAJH., InterfaceforAuditoryDataScience. InProceedingsofthe16thInter-
FRIEDMANK.P.: Thetripletonesonificationmethodtoenhancethe nationalAudioMostlyConference(NewYork,NY,USA,Oct.2021),
diagnosisofalzheimer’sdementia.InProc.22ndInternationalConfer- AM’21,AssociationforComputingMachinery,pp.208–215. doi:
enceonAuditoryDisplay(ICAD–2016)(Canberra,Australia,July2016). 10.1145/3478384.3478401.21
doi:10.21785/icad2016.023.5,6,13,14,15
[HRM15] HILDEBRANDT T., RINDERLE-MA S.: Serversoundsand
[HAR16] HILDEBRANDTT.,AMERBAUERF.,RINDERLE-MAS.:Com- networknoises.InCognitiveInfocommunications(CogInfoCom),2015
biningsonificationandvisualizationfortheanalysisofprocessexecution 6thIEEEInternationalConferenceon(2015),IEEE,pp.45–50.4,19
data.In2016IEEE18thConferenceonBusinessInformatics(CBI)(Aug.
2016),vol.02,pp.32–37. doi:10.1109/CBI.2016.47. 6,7,11, [HTHB22] HARRISONC.,TRAYFORDJ.,HARRISONL.,BONNEN.:
12,13,15
Audiouniverse:Tourofthesolarsystem.Astronomy&Geophysics63,2
(Apr.2022),2.38–2.40.doi:10.1093/astrogeo/atac027.5,6,
[HAS11] HULLMANJ.,ADARE.,SHAHP.: BenefittingInfoViswith 15,16
visualdifficulties. IEEETransactionsonVisualizationandComputer
Graphics 17, 12 (Dec. 2011), 2213–2222. doi:10.1109/TVCG. [Hun07] HUNTERJ.D.: Matplotlib:A2dgraphicsenvironment. Com-
2011.175.21 putinginScience&Engineering9,3(2007),90–95.doi:10.1109/
MCSE.2007.55.21
[HCTP14] HOLTZMANB.,CANDLERJ.,TURKM.,PETERD.: Seis-
micsoundlab:Sights,soundsandperceptionoftheearthasanacous- [HWKK23] HUANG Z., WITSCHARD D., KUCHER K., KERREN A.:
ticspace. InSound,Music,andMotion(Cham,2014),AramakiM., VA+EmbeddingsSTAR:AState-of-the-ArtReportontheUseofEm-
Derrien O., Kronland-Martinet R., Ystad S., (Eds.), Lecture Notes beddingsinVisualAnalytics. ComputerGraphicsForum42,3(2023),
inComputerScience,SpringerInternationalPublishing,pp.161–174. 539–571.doi:10.1111/cgf.14859.17
doi:10.1007/978-3-319-12976-1_10.6,7,11
[Ibe20] IBERM.:Auditorydisplayinworkspaceenvironments.InFoun-
[Her02] HERMANNT.:SonificationforExploratoryDataAnalysis.PhD dationsinSoundDesignforEmbeddedMedia:AMultidisciplinaryAp-
thesis,BielefeldUniversity,Bielefeld,Germany,022002.9,15 proach,FilimowiczM.,(Ed.).Routledge,2020,pp.131–154.19
[Her08] HERMANNT.: Taxonomyanddefinitionsforsonificationand [IIC∗13] ISENBERG T., ISENBERG P., CHEN J., SEDLMAIR M.,
auditorydisplay.InProceedingsofthe14thInternationalConferenceon MÖLLER T.: Asystematicreviewonthepracticeofevaluatingvisu-
AuditoryDisplay(2008).URL:http://hdl.handle.net/1853/49960.2 alization. IEEETrans.VisualizationandComputerGraphics19,12
[Her20] HERRMANNV.:Visualizingandsonifyinghowanartificialear (2013),2818–2827.doi:10.1109/TVCG.2013.126.14
hears music. In Proceedings of the NeurIPS 2019 Competition and [JDS15] JAKUS G., DICKE C., SODNIK J.: Auserstudyofauditory,
DemonstrationTrack(Dec.2020),EscalanteH.J.,HadsellR.,(Eds.), head-upandmulti-modaldisplaysinvehicles. AppliedErgonomics46
vol.123ofProceedingsofMachineLearningResearch,PMLR,pp.192– (2015),184–192.doi:10.1016/j.apergo.2014.08.008.19
202.https://proceedings.mlr.press/v123/herrmann20a.html.6,7,13
[JMP13] JOLIATN.,MAYTONB.,PARADISOJ.A.:Spatializedanony-
[HEUHEB23] HOQUEM.N.,EHTESHAM-UL-HAQUEM.,ELMQVIST
mousaudioforbrowsingsensornetworksviavirtualworlds. InProc.
N.,BILLAHS.M.: Accessibledatarepresentationwithnaturalsound.
19thInternationalConferenceonAuditoryDisplay(ICAD2013)(Lodz,
InProceedingsofthe2023CHIConferenceonHumanFactorsinCom-
Poland,July2013),GeorgiaInstituteofTechnology,pp.67–75. http:
putingSystems(2023),pp.826:1–826:19.doi:10.1145/3544548.
//hdl.handle.net/1853/51643.6,7,15
3581087.18
[HGI∗22] HOLLOWAYL.M.,GONCUC.,ILSARA.,BUTLERM.,MAR- [Joh04] JOHANNSEN G.: Auditory displays in human-machine inter-
faces.ProceedingsoftheIEEE92,4(2004),742–758.doi:10.1109/
RIOTTK.:Infosonics:Accessibleinfographicsforpeoplewhoareblind
JPROC.2004.825905.19
usingsonificationandvoice. InProceedingsofthe2022CHIConfer-
enceonHumanFactorsinComputingSystems(2022),pp.480:1–480:13. [KAV21] KARIYADO Y., AREVALO C., VILLEGAS J.: Auralization
doi:10.1145/3491102.3517465.18 of three-dimensional cellular automata. In Artificial Intelligence in
[HH04] HUNTA.,HERMANNT.:Theimportanceofinteractioninsonifi- Music, Sound, Art and Design (Cham, 2021), Romero J., Martins
cation.InProc.ofthe10thMeetingoftheInternationalConferenceon T., Rodríguez-Fernández N., (Eds.), Lecture Notes in Computer Sci-
AuditoryDisplay(ICAD2004)(Sydney,Australia,2004),pp.1–8.18
ence,SpringerInternationalPublishing,pp.161–170.doi:10.1007/
978-3-030-72914-1_11.6,7,14
[HHG∗12] HÖFERLIN B., HÖFERLIN M., GOLOUBETS B., HEIDE-
MANNG.,WEISKOPFD.:Auditorysupportforsituationawarenessin [KGS∗20] KIM C., GUO A., SALHOTRA G., SPRINKHUIZEN S.,
videosurveillance.InProceedingsofthe18thInternationalConference SHETTY K., KONG D. S.: Sonifying data from the human micro-
onAuditoryDisplay,(Atlanta,GA,USA„June2012),GeorgiaInstitute biota:Biotabeats. ComputerMusicJournal44,1(Mar.2020),51–70.
ofTechnology,pp.156–163.URL:http://hdl.handle.net/1853/44426.19 doi:10.1162/comj_a_00552.20
[HHN11] HERMANNT.,HUNTA.,NEUHOFFJ.G.(Eds.):TheSonifica- [KIK19] KANEVI.K.,ILIEVI.T.,KRASTEVAV.T.:Sonification–an
tionHandbook.Logos,Bielefeld,2011.2,3,18 alternativepresentationoftheelectrocardiogram:Asystematicliterature
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 25of27
review.In2019IEEEXXVIIIInternationalScientificConferenceElectron- non-visualpointestimationtasks.PeerJComputerScience2(2016),e51.
ics(ET)(2019),IEEE,pp.1–4.doi:10.1109/ET.2019.8878650. 21
4,19
[ML17] MCNABBL.,LARAMEER.S.:SurveyofSurveys(SoS)-Map-
[KLTW17] KONDAKZ.,LIANGT.A.,TOMLINSONB.,WALKERB.N.: pingTheLandscapeofSurveyPapersinInformationVisualization.Com-
Websonificationsandbox-aneasy-to-usewebapplicationforsonifying puterGraphicsForum36,3(2017),589–617. doi:10.1111/cgf.
dataandequations. InProc.WebAudioConferenceWAC-2017(Lon- 13212.3
don,UK,Aug.2017).https://qmro.qmul.ac.uk/xmlui/handle/123456789/
[MLS95] MOUSAVIS.Y.,LOWR.,SWELLERJ.: Reducingcognitive
26083.6,7,10,13,21
loadbymixingauditoryandvisualpresentationmodes.Journalofeduca-
[KOR23] KIESENHOFERS.,OELSCHA.,RAMMERD.:Deepsync,2023. tionalpsychology87,2(1995),319.18
Webpage: https://ars.electronica.art/futurelab/en/projects-deep-sync/. [MMM18] MAÇÃSC.,MARTINSP.,MACHADOP.:Consumptionasa
Lastaccessed:Dec28st2023.20 rhythm:Amultimodalexperimentontherepresentationoftime-series.In
[Kra94] KRAMERG.(Ed.):AuditoryDisplay:Sonification,Audification 201822ndInternationalConferenceInformationVisualisation(IV)(July
andAuditoryInterfaces.ProceedingsoftheFirstInternationalConfer- 2018),pp.504–509.doi:10.1109/iV.2018.00093.6,7,12,13
enceonAuditoryDisplay(ICAD)1992.Addison-Wesley,Reading,Mass, [MMU16] MATSUBARAM.,MORIMOTOY.,UCHIDET.:Collaborative
1994.2,3 studyofinteractiveseismicarraysonificationfordataexplorationand
[KWB∗99] KRAMER G., WALKER B., BONEBRIGHT T., COOK P., publicoutreachactivities.InProceedingsofISon2016,5thInteractive
FLOWERS J. H., MINER N., NEUHOFF J., ET AL.: Sonification SonificationWorkshop,CITEC,BielefeldUniversity(Bielefeld,Germany,
Report: Status of the Field and Research Agenda. Report for the 2016).6,7,11,13,15
NSF, International Community for Auditory Display, 1999. URL: [MNS16] MACULEWICZ J., NILSSON N. C., SERAFIN S.: Aninves-
http://www.icad.org/websiteV2.0/References/nsf.html.1,3 tigation of the effect of immersive visual and auditory feedback on
[LCS∗28] LINJ.-W.,CHENW.,SHENC.-P.,CHIUM.-J.,KAOY.-H., rhythmicwalkinginteraction.InProceedingsoftheAudioMostly2016
LAIF.,ZHAOQ.,CICHOCKIA.:Visualizationandsonificationoflong- (2016),AM’16,AssociationforComputingMachinery,pp.194–201.
termepilepsyelectroencephalogrammonitoring. JournalofMedical doi:10.1145/2986416.2986429.19
andBiologicalEngineering38,6(2028),943–952. doi:10.1007/ [MNW∗18] MACDONALDD.E.,NATARAJANT.,WINDEYERR.C.,
s40846-017-0358-6.19
COPPINP.,STEINMAND.A.:Data-drivensonificationofcfdaneurysm
[Len21] LENZIS.: TheDesignofDataSonification.DesignProcesses, models. InProc.24thInternationalConferenceonAuditoryDisplay
ProtocolsandToolsGroundedinAnomalyDetection. PhDthesis,Po- (ICAD2018)(Houghton,Michigan,June2018),TheInternationalCom-
litecnicodiMilano,2021.https://www.politesi.polimi.it/handle/10589/ munityforAuditoryDisplay,pp.28–33.doi:10.21785/icad2018.
177079.3 010.5,6,14,15,21
[LF21] LINDETORP H., FALKENBERG K.: Sonificationforeveryone [Mun15] MUNZNERT.:VisualizationAnalysisandDesign.CRCPress,
everywhere:Evaluatingthewebaudioxmlsonificationtoolkitforbrowsers. BocaRaton,Jan.2015.1,5,7,10,11,12,13,16,21
InProc.26thInternationalConferenceonAuditoryDisplay(ICAD2021) [MVC∗10] MASUD L., VALSECCHI F., CIUCCARELLI P., RICCI D.,
(VirtualConference,June2021),GeorgiaInstituteofTechnology,pp.15– CAVIGLIAG.:Fromdatatoknowledge–visualizationsastransformation
21.http://hdl.handle.net/1853/66351.6,7,10,11,13,21 processeswithinthedata-information-knowledgecontinuum. In2010
[LLC23] LINDBORGP.,LENZIS.,CHENM.:Climatedatasonification 14th International Conference Information Visualisation (July 2010),
andvisualization:Ananalysisoftopics,aesthetics,andcharacteristicsin
pp.445–449.doi:10.1109/IV.2010.68.20
32recentprojects.FrontiersinPsychology13(2023).doi:10.3389/ [Nee19] NEESM.A.:Eightcomponentsofadesigntheoryofsonification.
fpsyg.2022.1020102.19,20 InProceedingsofthe25thInternationalConferenceonAuditoryDisplay
[LLW21] LYU Z., LI J., WANG B.: Aiive: Interactive visualization
(ICAD2019)(2019),pp.176–183.doi:10.21785/icad2019.048.
and sonification ofneural networks in virtual reality. In 2021 IEEE 3
International Conference on Artificial Intelligence and Virtual Real- [Neu04] NEUHOFFJ. G.(Ed.): EcologicalPsychoacoustics. Elsevier
ity(AIVR)(Nov.2021),pp.251–255. doi:10.1109/AIVR52153. AcademicPress,SanDiego,2004.2,21
2021.00057.6,7,9
[Neu19] NEUHOFFJ.G.:Issonificationdoomedtofail.InProceedings
[LSB∗23] LEMMONE.,SCHEDELM.,BILKHUI.,ZHUH.,ESCOBAR ofthe25thInternationalConferenceonAuditoryDisplay(ICAD2019)
L.,AUMOITHEG.:Mappingintheemergency:Designingahyperlocal (2019),pp.327–330.3
andsociallyconscioussonifiedmapofcovid-19insuffolkcounty,new
[NGJW14] NEES M. A., GABLE T. M., JEON M., WALKER B. N.:
york.InProceedingsofISon2022,7thInteractiveSonificationWorkshop,
Prototype auditory displays for a fuel efficiency driver interface. In
BSCC,UniversityofBremen(Jan.2023),Zenodo. doi:10.5281/
Proceedingsofthe20thInternationalConferenceonAuditoryDisplay
ZENODO.7552257.5,6,9,13,15
(NewYork,USA,June2014),GeorgiaInstituteofTechnology.Publisher:
[LWP∗13] LUS.A.,WICKENSC.D.,PRINETJ.C.,HUTCHINSS.D., GeorgiaInstituteofTechnology.URL:http://hdl.handle.net/1853/52089.
SARTERN.,SEBOKA.:Supportinginterruptionmanagementandmul- 19
timodalinterfacedesign:Threemeta-analysesoftaskperformanceas [NRL∗12] NESS S., REIMER P., LOVE J., SCHLOSS W. A., TZANE-
afunctionofinterruptingtaskmodality. HumanFactors55,4(2013),
697–724.doi:10.1177/0018720813476298.19
TAKISG.:Sonophenology.JournalonMultimodalUserInterfaces5,3
(May2012),123–129.doi:10.1007/s12193-011-0066-4.6,7,
[MAFP19a] MALIKOVAE.,ADZHIEVV.,FRYAZINOVO.,PASKOA.: 13,15
Visual-auditoryrepresentationandanalysisofmolecularscalarfields.In
Proc.EUROGRAPHICS2019(2019),pp.25–26.doi:10.2312/egp.
[NSC16] NORTHK.J.,SARMAA.,COHENM.B.: Understandinggit
history:Amulti-senseview. InProceedingsofthe8thInternational
20191051.15
WorkshoponSocialSoftwareEngineering(NewYork,NY,USA,2016),
[MAFP19b] MALIKOVAE.,ADZHIEVV.,FRYAZINOVO.,PASKOA.: SSE2016,AssociationforComputingMachinery,pp.1–7. doi:10.
Visual-auditoryvolumerenderingofscalarfields. InProc.25thInter- 1145/2993283.2993285.6,7,11,13,15
nationalConferenceonAuditoryDisplay(ICAD2019)(Northumbria
[NW08] NEESM.A.,WALKERB.N.:Encodingandrepresentationof
University,June2019),vol.147–154,GeorgiaInstituteofTechnology.
informationinauditorygraphs:Descriptivereportsoflistenerstrategies
http://hdl.handle.net/1853/61517.5,6,7,12
forunderstandingdata.InProceedingsoftheInternationalConference
[MBKSM16] METATLAO.,BRYAN-KINNSN.,STOCKMANT.,MAR- onAuditoryDisplay(Paris,FR,June2008).URL:http://hdl.handle.net/
TINF.:Sonificationofreferencemarkersforauditorygraphs:Effectson 1853/49907.3
©2024TheAuthors.26of27 K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization
[PBM15] PAPACHRISTODOULOUP.,BETELLAA.,MANZOLLIJ.:Aug- BMC Anesthesiology 22, 1 (2022), 167:1–167:10. doi:10.1186/
mentingthenavigationofcomplexdatasetsusingsonification:Acase s12871-022-01705-6.19
studywithbrainx3. In2015IEEE2ndVRWorkshoponSonicInter-
[Rön19a] RÖNNBERGN.:Musicalsonificationsupportsvisualdiscrimina-
actionsforVirtualEnvironments(SIVE)(Mar.2015),pp.1–6. doi:
tionofcolorintensity.Behaviour&InformationTechnology38,10(2019),
10.1109/SIVE.2015.7361284.6,7,11,15
1028–1037.doi:10.1080/0144929X.2019.1657952.18,21
[PBV14] PAPACHRISTODOULOUP.,BETELLAA.,VERSCHUREP.:Soni-
[Rön19b] RÖNNBERGN.:Sonificationsupportsperceptionofbrightness
ficationoflargedatasetsina3dimmersiveenvironment:Aneuroscience
contrast.JournalonMultimodalUserInterfaces13,4(2019),373–381.
casestudy. InProc.ACHI2014:TheSeventhInternationalConfer- doi:10.1007/s12193-019-00311-0.18,21
enceonAdvancesinComputer-HumanInteractions(Jan.2014),IARIA,
pp.35–40.6,7 [Rön21] RÖNNBERGN.: Sonificationforconveyingdataandemotion.
InProceedingsofthe16thInternationalAudioMostlyConference(New
[PC19] PHILLIPSS.,CABRERAA.: Sonificationworkstation. In25th York,NY,USA,2021),AM’21,AssociationforComputingMachinery,
InternationalConferenceonAuditoryDisplay(ICAD2019)(Northumbria pp.56–63.doi:10.1145/3478384.3478387.6,7,9,13
University,June2019),GeorgiaInstituteofTechnology,pp.184–190.
http://hdl.handle.net/1853/61529.6,7,10,11,13,21 [RS22] RUSSO M., SANTAGUIDA A.: 5000exoplanets:Listentothe
soundsofdiscovery.InProc.27thInternationalConferenceonAuditory
[PCB23] PENGT.,CHOIH.,BERGERJ.:Siren:Creativeandextensible Display(ICAD2022)(VirtualConference,June2022),GeorgiaInstitute
sonification on the web. In Proc. 28th International Conference on ofTechnology,pp.64–68.http://hdl.handle.net/1853/67384.5,6,9,12,
AuditoryDisplay(ICAD2023)(Norrköping,Sweden,June2023),Georgia 13,15,16
InstituteofTechnology,pp.78–84.https://hdl.handle.net/1853/72879.6,
7,10,13,21
[SAR22] SVORONOS-KANAVASI.,AGIOMYRGIANAKISV.,RÖNNBERG
N.:Anexploratoryuseofaudiovisualdisplaysonoceanographicdata.In
[PFH∗22] PATÉ A., FARGE G., HOLTZMAN B. K., BARTH A. C., Proc.AVI2022WorkshoponAudio-VisualAnalytics(WAVA22)(Frascati,
POLI P., BOSCHI L., KARLSTROM L.: Combiningaudioandvisual Italy,2022),Zenodo.doi:10.5281/zenodo.6555839.6,7,12
displays to highlight temporal and spatial seismic patterns. Journal
on Multimodal User Interfaces 16, 1 (Mar. 2022), 125–142. doi: [SFLD22] SIRKKA A., FAGERLÖNN J., LINDBERG S., DELSING K.:
10.1007/s12193-021-00378-8.6,7,9,11,13,14 Thedesignofanauditoryalarmconceptforapapermillcontrolroom.
InAdvancesinErgonomicsInDesign,Usability&SpecialPopulations:
[Pol06] POLLIA.: HeatandtheHeartbeatoftheCity:SonifyingData PartIII(2022),vol.20,AHFEOpenAcces.ISSN:27710718Issue:20.
DescribingClimateChange. LeonardoMusicJournal16(Dec.2006), doi:10.54941/ahfe1001301.19
44–45.doi:10.1162/lmj.2006.16.44.20
[Shn96] SHNEIDERMANB.:Theeyeshaveit:Ataskbydatatypetaxon-
[RF22] RÖNNBERGN.,FORSELLC.:Questionnairesassessingusability omyforinformationvisualizations.InProceedingsoftheIEEESympo-
ofaudio-visualrepresentations.InProc.AVI2022WorkshoponAudio- siumonVisualLanguages,VL(1996),pp.336–343. doi:10.1109/
VisualAnalytics(Rome,2022). doi:10.5281/zenodo.6555676. VL.1996.545307.2
14,20
[SJMT19] SCHAFFERTN.,JANZENT.B.,MATTESK.,THAUTM.H.:
[RFK∗15] RAUB.,FRIESSF.,KRONEM.,MULLERC.,ERTLT.:En- Areviewontherelationshipbetweensoundandmovementinsports
hancingvisualizationofmolecularsimulationsusingsonification. In andrehabilitation.FrontiersinPsychology10(2019).doi:10.3389/
2015IEEE1stInternationalWorkshoponVirtualandAugmentedReal- fpsyg.2019.00244.4,19
ityforMolecularScience(VARMS@IEEEVR)(Mar.2015),pp.25–30.
[SMM12] SEDLMAIR M., MEYER M., MUNZNER T.: Designstudy
doi:10.1109/VARMS.2015.7151725.5,6,11,12,13
methodology:Reflectionsfromthetrenchesandthestacks.IEEETrans.
[RFM13] ROGIN´SKA A., FRIEDMAN K., MOHANRAJ H.: Exploring VisualizationandComputerGraphics18,12(2012),2431–2440.doi:
sonificationforaugmentingbrainscandata.InProc.19thInternational 10.1109/TVCG.2012.213.16
ConferenceonAuditoryDisplay(ICAD2013)(Lodz,Poland,July2013),
[SMS21] SCHLOSSERP.D.,MATTHEWSB.,SANDERSONP.M.:Head-
GeorgiaInstituteofTechnology,pp.95–101.http://hdl.handle.net/1853/
worndisplaysforhealthcareandindustryworkers:Areviewofapplica-
51653.5,6
tionsanddesign.InternationalJournalofHuman-ComputerStudies154
[RH22] REINSCHD.,HERMANNT.:Interactingwithsonifications:The (2021),102628.doi:10.1016/j.ijhcs.2021.102628.19
mesonicframeworkforinteractiveauditorydatascience. InProceed- [SNH05] STOCKMANT.,NICKERSONL.V.,HINDG.:Auditorygraphs:
ingsofthe7thInteractiveSonificationWorkshop(ISon)(2022),CITEC, Asummaryofcurrentexperienceandtowardsaresearchagenda. In
BielefeldUniversity,p.65.21 InternationalConferenceonAuditoryDisplay(ICAD2005),Limerick,
[RH23] REINSCHD.,HERMANNT.:Sonecules:APythonsonification Ireland(2005).18
architecture. InProceedingsofthe28thInternationalConferenceon [SNHS13] SCHULZH.-J.,NOCKET.,HEITZLERM.,SCHUMANNH.:
AuditoryDisplay(Norrköping,Sweden,June2023),GeorgiaInstituteof Adesignspaceofvisualizationtasks. IEEETrans.Visualizationand
Technology,pp.62–69.doi:10.21785/icad2023.5580.21 ComputerGraphics19,12(Dec.2013),2366–2375. doi:10.1109/
[Rib18] RIBERA.G.:Planethesizer:Approachingexoplanetsonification.
TVCG.2013.120.2
InProc.24thInternationalConferenceonAuditoryDisplay(ICAD2018) [SPA23] STOIBERC.,POHLM.,AIGNERW.: Designactionsforthe
(MichiganTechnologicalUniversity,June2018),GeorgiaInstituteof designofvisualizationonboardingmethods.InEduVisWorkshop,IEEE
Technology,pp.219–226.http://hdl.handle.net/1853/60073.5,6,13 VIS(Melbourne,Australia,2023).doi:10.31219/osf.io/wjp5x.
[Rib19] RIBERA.G.:Sonifigrapher:Sonifiedlightcurvesynthesizer.In 21
Proc.25thInternationalConferenceonAuditoryDisplay(ICAD2019) [SQS∗20] SUI.,QINZ.,SARACENOT.,BISSHOPA.,MÜHLETHALER
(NorthumbriaUniversity,June2019),GeorgiaInstituteofTechnology, R.,ZIPORYNE.,BUEHLERM.J.:Sonificationofa3-Dspiderweband
pp.62–66.http://hdl.handle.net/1853/61497.5,6,10,11,12,13,15 reconstitutionformusicalcompositionusinggranularsynthesis. Com-
puterMusicJournal44,4(Dec.2020),43–59.doi:10.1162/comj_
[RJ16] RÖNNBERGN.,JOHANSSONJ.:Interactivesonificationforvisual
a_00580.20
densedatadisplays.InProc.5thInteractiveSonificationWorkshop,ISon
(2016),CITEC,BielefeldUniversity,pp.63–67.6,7,12,13,14 [SŠ18] SEBJANICˇ R.,ŠUTIC´ G.:Aqua_forensic,2018.Webpage:https:
[RMS∗22] ROCHE T. R., MAAS E. J. C., SAID S., BRAUN J., //ars.electronica.art/aeblog/en/2018/11/07/aquaforensic/.Lastaccessed:
Dec21st2023.20
MACHADOC.,SPAHND.R.,NOETHIGERC.B.,TSCHOLLD.W.:
Anesthesia personnel’s visual attention regarding patient monitoring [Sup12] SUPPER A.: Lobbying for the Ear : The Public Fascination
insimulatednon-criticalandcriticalsituations,aneye-trackingstudy. with and Academic Legitimacy of the Sonification of Scientific Data.
©2024TheAuthors.K.Engeetal./AState-of-the-ArtReportontheIntegrationofSonificationandVisualization 27of27
Doctoralthesis,MaastrichtUniversity,2012. doi:10.26481/dis. [WS07] WATSON M., SANDERSON P.: Designing for attention
20120606as.3 with sound: Challenges and extensions to ecological interface de-
[SWG∗23] STOIBER C., WAGNER M., GRASSINGER F., POHL M., s 0i 0gn 1. 872H 0u 0m 7a Xn 31F 2a 5ct 3o 1rs .14 99, 2 (2007), 331–346. doi:10.1518/
STITZ H., STREIT M., POTZMANN B., AIGNER W.: Visualization
onboardinggroundedineducationaltheories.InVisualizationPsychol- [WW15] WINTERSR.M.,WEINBERGG.: Sonificationofthetohoku
ogy.SpringerNature,2023.doi:10.1007/978-3-031-34738-2. earthquake:Music,popularization&theauditorysublime.InProc.The
21 21thInternationalConferenceonAuditoryDisplay(ICAD–2015(July
2015),GeorgiaInstituteofTechnology,pp.273–280.http://hdl.handle.
[TB23] TRAVERP.,BERGHE.:Harmonicessolaris-sonificationofthe
net/1853/54149.6,7,10,11,12,13
planets. InProc.28thInternationalConferenceonAuditoryDisplay
(ICAD 2023) (Norrköping, Sweden, June 2023), Georgia Institute of [XWX∗22] XINX.,WANGY.,XIANGG.,YANGW.,LIUW.: Effec-
Technology,pp.242–248.doi:10.21785/icad2023.204.5,6,16 tivenessofmultimodaldisplayinnavigationsituation. InTheNinth
[TML∗15] TARDIEUJ.,MISDARIISN.,LANGLOISS.,GAILLARDP., AIn st se orn cia at ti io on nal foS rym Cop mos piu um tino gf MCh acin he inse erC y,H pI p( .2 50 02 –2 6) 2, .Ch di one is :e 1C 0H .1I 12 402 51 /,
LEMERCIERC.:Sonificationofin-vehicleinterfacereducesgazemove-
3490355.3490361.19
mentsunderdual-taskcondition.AppliedErgonomics50(2015),41–49.
doi:10.1016/j.apergo.2015.02.004.19 [YH17] YANGJ.,HERMANNT.:Modeexplorer:Usingmodel-basedsoni-
ficationtoinvestigatebasinsofattraction.InProceedingsofthe12thInter-
[TMN∗21] TEMOR L., MACDONALD D. E., NATARAJAN T., COP-
nationalAudioMostlyConferenceonAugmentedandParticipatorySound
PINP.W.,STEINMAND.A.: Perceptually-motivatedsonificationof
andMusicExperiences(NewYork,NY,USA,2017),AM’17,Associa-
spatiotemporally-dynamicCFDdata.InProc.26thInternationalConfer- tionforComputingMachinery.doi:10.1145/3123514.3123525.
enceonAuditoryDisplay(ICAD2021)(VirtualConference,June2021),
7,11
GeorgiaInstituteofTechnology,pp.202–209.http://hdl.handle.net/1853/
66343.5,6,14,15,21 [YH18] YANGJ.,HERMANNT.:Interactivemodeexplorersonification
enhancesexploratoryclusteranalysis.JournaloftheAudioEngineering
[VH06] VICKERSP.,HOGGB.:Sonificationabstraite/sonificationcon- Society66,9(Sept.2018),703–711. doi:10.17743/jaes.2018.
crète:An’æstheticpersepctivespace’forclassifyingauditorydisplaysin 0042.5,6,9,15,21
thearsmusicadomain.InProceedingsofthe12thInternationalConfer-
enceonAuditoryDisplay(London,UK,June2006),GeorgiaInstituteof [YKSJ07] YIJ.S.,KANGY.A.,STASKOJ.T.,JACKOJ.A.: Toward
Technology,pp.210–216.URL:http://hdl.handle.net/1853/50641.3 adeeperunderstandingoftheroleofinteractionininformationvisual-
ization.IEEETrans.VisualizationandComputerGraphics13,6(2007),
[Vic16] VICKERSP.:Sonificationandmusic,musicandsonification.In 1224–1231.doi:10.1109/TVCG.2007.70515.2
TheRoutledgeCompaniontoSoundingArt,CobussenM.,MeelbergV.,
TruaxB.,(Eds.).Routledge,2016,pp.135–144.9 [Ylm23] YLMAZS.: Orbuculum,2023. ArsElectronicaFestival2023.
Webpage:https://ars.electronica.art/who-owns-the-truth/de/orbuculum/.
[VRGM20] VANRHEDENV.,GRAHT.,MESCHTSCHERJAKOVA.:Soni- Lastaccessed:Dec28th2023.20
ficationapproachesinsportsinthepastdecade:aliteraturereview. In
Proceedingsofthe15thInternationalAudioMostlyConference(2020), [Zie23] ZIEMER T.: Three-dimensionalsonificationforimage-guided
ACM,pp.199–205.doi:10.1145/3411109.3411126.4,19 surgery. InProceedingsofthe28thInternationalConferenceonAu-
ditoryDisplay(Norrköping,Sweden,June2023),GeorgiaInstituteof
[WL01] WALKERB.N.,LANED.M.:Sonificationmappingsdatabase Technology,pp.8–14.doi:10.21785/icad2023.2324.19
ontheweb. InProceedingsofthe2001InternationalConferenceon
AuditoryDisplay(Espoo,Finland,2001),GeorgiaInstituteofTechnology, [ZPR16] ZAGERMANNJ.,PFEILU.,REITERERH.:Measuringcognitive
p.281.3 loadusingeyetrackingtechnologyinvisualcomputing.InProceedings
ofthesixthworkshoponbeyondtimeanderrorsonnovelevaluation
[WM10] WALKERB.N.,MAUNEYL.M.:Universaldesignofauditory methodsforvisualization(2016),ACM,pp.78–85. doi:10.1145/
graphs:Acomparisonofsonificationmappingsforvisuallyimpairedand 2993901.2993908.18
sightedlisteners.ACMTransactionsonAccessibleComputing(TACCESS)
2,3(2010),1–16.2,18,21
[WMY∗17] WANGQ.,MARKOPOULOSP.,YUB.,CHENW.,TIMMER-
MANSA.:Interactivewearablesystemsforupperbodyrehabilitation:a
systematicreview.JournalofNeuroEngineeringandRehabilitation14,1
(2017),20.doi:10.1186/s12984-017-0229-y.4,19
[Woh14] WOHLINC.:Guidelinesforsnowballinginsystematicliterature
studiesandareplicationinsoftwareengineering.InProceedingsofthe
18thInternationalConferenceonEvaluationandAssessmentinSoftware
Engineering(LondonEnglandUnitedKingdom,May2014),ACM,pp.1–
10.doi:10.1145/2601248.2601268.5
[Wor19a] WORRALL D.: Polymedia design for network metadata
monitoring. In Sonification Design: From Data to Intelligible
Soundfields, Worrall D., (Ed.), Human–Computer Interaction Series.
SpringerInternationalPublishing,2019,pp.253–273.doi:10.1007/
978-3-030-01497-1_9.19
[Wor19b] WORRALLD.:SonificationDesign:FromDatatoIntelligible
Soundfields.Human–ComputerInteractionSeries.Springer,Cham,2019.
doi:10.1007/978-3-030-01497-1.3
[WRK∗19] WALKERB.N.,REHGJ.M.,KALRAA.,WINTERSR.M.,
DREWSP.,DASCALUJ.,DAVIDE.O.,DASCALUA.: Dermoscopy
diagnosisofcancerouslesionsutilizingdualdeeplearningalgorithms
viavisualandaudio(sonification)outputs:Laboratoryandprospective
observationalstudies. EBioMedicine40(2019),176–183. doi:10.
1016/j.ebiom.2019.01.028.19
©2024TheAuthors.