Beyond Accuracy: An Empirical Study on Unit Testing in
Open-source Deep Learning Projects
HANWANG,
FacultyofInformationTechnology,MonashUniversity,Australia
SIJIAYU,
JilinUniversity,Changchun,China
CHUNYANGCHEN,
FacultyofInformationTechnology,MonashUniversity,Australia
BURAKTURHAN∗,
M3SResearchUnit,FacultyofITEE,UniversityofOulu,Finland
XIAODONGZHU,
JilinUniversity,Changchun,China
DeepLearning(DL)modelshaverapidlyadvanced,focusingonachievinghighperformancethroughtesting
modelaccuracyandrobustness.However,itisunclearwhetherDLprojects,assoftwaresystems,aretested
thoroughlyorfunctionallycorrectwhenthereisaneedtotreatandtestthemlikeothersoftwaresystems.
Therefore,weempiricallystudytheunittestsinopen-sourceDLprojects,analyzing9,129projectsfrom
GitHub.Wefindthat:1)unittestedDLprojectshavepositivecorrelationwiththeopen-sourceprojectmetrics
andhaveahigheracceptancerateofpullrequests,2)68%ofthesampledDLprojectsarenotunittestedatall,
3)thelayerandutilities(utils)ofDLmodelshavethemostunittests.Basedonthesefindingsandprevious
researchoutcomes,webuiltamappingtaxonomybetweenunittestsandfaultsinDLprojects.Wediscuss
theimplicationsofourfindingsfordevelopersandresearchersandhighlighttheneedforunittestingin
open-sourceDLprojectstoensuretheirreliabilityandstability.Thestudycontributestothiscommunityby
raisingawarenessoftheimportanceofunittestinginDLprojectsandencouragingfurtherresearchinthis
area.
CCSConcepts:•Softwareanditsengineering→Softwaretestinganddebugging.
AdditionalKeyWordsandPhrases:DeepLearning,UnitTesting
1 INTRODUCTION
Inrecentyears,DeepLearning(DL)[44],akeybranchofMachineLearning(ML),hasdemonstrated
significantperformanceindifferentArtificialIntelligence(AI)taskssuchasautonomousdriving[35],
medicalimagediagnosis[31],andspeechrecognition[54].Theopen-sourceversionsofsuccessful
DLprojectsbecamereadilyavailableoncode-sharingwebsites,andpeopleadoptedthemforusein
theirresearchandapplications[62].Asopen-sourceprojectsarefreelyaccessible,theyhavethe
potentialtobeusedandincorporatedintovariousdownstreamsystems,leadingtowidespread
adoption and usage. However, without proper testing, any issues within the projects may be
propagateddownstream,potentiallycausingproblemsfromincorrectlyinterpretingavoicetotext
toaseverecarcrashinautonomousdriving.
Therehavebeenmanystudiesonmodelevaluation,i.e.,evaluationoftheperformance(e.g.,
accuracy, precision, etc.) on a validation or test dataset [46, 60]. To ensure consistent model
performanceinvariousenvironments,manyapproacheshavebeenproposedtodefendagainst
potentialadversarialattacks[46,55,67,73].However,open-sourceDLmodelscanbeemployedas
integralcomponentsinsoftwaresystemsdevelopedbyothersorincorporatedintovariousresearch
projects.Assuch,itisessentialtoconductunittestingontheseindividualcomponentstoidentify
∗BurakTurhanisthecorrespondingauthor.
Authors’addresses:HanWang,han.wang@monash.edu,FacultyofInformationTechnology,MonashUniversity,Australia;
SijiaYu,yusj19@mails.jlu.edu.cn,JilinUniversity,Changchun,China;ChunyangChen,chunyang.chen@monash.edu,
FacultyofInformationTechnology,MonashUniversity,Australia;BurakTurhan,burak.turhan@oulu.fi,M3SResearchUnit,
FacultyofITEE,UniversityofOulu,Finland;XiaodongZhu,zhuxd@jlu.edu.cn,JilinUniversity,Changchun,China.
2024.XXXX-XXXX/2024/2-ART$15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn
,Vol.1,No.1,Article.Publicationdate:February2024.
4202
beF
62
]ES.sc[
1v64561.2042:viXra2 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
andmitigatepotentialfaultswithinthem,therebyensuringthatthemodelfunctionsaccordingto
expectationswhenintegratedintoalargersystem.
PreviousresearchhassummarizeddifferenttypesoffaultsfromexistingDLprojects[37,39].
FaultsinaDLmodelmaybeduetothemisconfigurationoflearningparameters(seeninStack-
Overflow(SO)#49226447),receivingdatainthewrongformatforthetensorinput(SO#41563720),
etc.SometimesevensimplymakingAPIcallsfromTensorflowcancausebugs(SO#49742061).In
addition,specificbugsinDLmodelsaredeeplyembeddedinthecode,e.g.,theprojectwillnot
generateanyerrormessagesorcrashesifthenetworkisnotstacked,butwillcausethemodelto
underperform,resultinginextraefforttodebug[3].
Unittestsarewidelyusedinconventionalsoftwaresystemstoensuresoftwarequality.They
canbeautomated,serveasasourceofdocumentation,andcandetectproblemsatearlystages
before deployment [29, 66, 69]. Nevertheless, unlike conventional software development with
relativelyclearlogic,DLsystemsarefuzzier,withinherentrandomness,massivedatasets,and
limitedinterpretability.Moreover,duringourpreliminaryobservationsontheunittestsinDL
projects,wenoticedthatthewayDLprojectsareunittesteddiffersfromconventionalunittesting,
e.g., new assertion statements for DL projects only, asserting the range or shape instead of an
absolutevalue.EvenwithinthesameDLproject,wefoundunitteststobeappliedindifferent
partsofaDLsystemhaveotherpreferencesintestingproperties,forexample,pre-processing(e.g.,
checkingtheshapeandscaleofdata),modelarchitecture(e.g.,matchingtheshapeofthelayer
output),training(e.g.,checkingweightchangesduringtraining),andevaluation(e.g.,checking
theloggedoutputsareasexpected).Whilepriorresearch[42,52]hasdelvedintounittestingof
DLlibraries,providingvaluableperspectivessuchastheuseoforacleapproximationassertions
tovalidateoutputranges[52],thereremainsagapinthecomprehensiveunderstandingofthe
motivationsandmethodologiesofunittestinginDLprojects.
Tofilltheknowledgegap,weconductalarge-scaleempiricalstudyonunittestinginopen-source
DLprojects.Weraisethefollowingthreeresearchquestionswithmotivations:
RQ1: How can unit tests help open-source DL projects? In conventional projects, unit
testingisessentialinindicatingcodequalityandhelpstodebug,especiallywhenmakingnew
changestothecodebase[32].However,DLmodelsarecomplexandhighlydynamic,anditis
unclearhowunittestscanbeappliedtotheseprojectsorwhethertheyarenecessary.InthisRQ,
weexaminevariousopen-sourceprojectmetricsandwhethertheyhaveunitteststogaininsights
intotheassociationofunittestswiththepopularityofopen-sourceDLprojectsandtodetermine
theimportanceofunittestsinthisrapidlygrowingfield.
RQ2:TowhatextentarecurrentDLprojectsunittested?
Asstated,thetrendofusingopen-sourceDLmodelsisrising.However,withthousandsofmodels
introducedeachyear,aredeveloperswritingunittestcasesforthenewlyintroducedmodels;if
so,whichtestingframeworksaretheyusing?Thefindingsansweringthisresearchquestionshall
provideageneralpictureofunittestingintheopen-sourceDLfield.
RQ3:WhichunitsandpropertiesaretestedinDLprojects?
ForDLmodelsthatalreadyhaveunittestcases,weaimtounderstandwhatpartsofaDLmodel
and which property of the unit the developers are most concerned with. Results shall help us
uncovertestinggaps,identifypotentialproblemareas,andimprovefuturedevelopmenteffortsin
unittestingforopen-sourceDLprojects.
RQ1seekstoestablishthefoundationalunderstandingofthesignificanceofunittestsinDL
projects.Buildinguponthisunderstanding,RQ2narrowsdowntotheactualadoptionrates.It
quantifiestheprevalenceofunittestsintheDLdomain,providingaquantitativeperspectiveon
howextensivelythecommunityhasembracedtestingandadoptedthetestingframeworks.Lastly,
RQ3divesdeeperintothespecificsofhowdeveloperswriteunittestsforopen-sourceDLprojects.
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 3
ToanswertheRQs,weconductedanin-depthstudyofunittestinginopen-sourceDLprojects.
BasedontheIEEEStandard[40]andKerasdocumentation[7],wecategorizedunittypesinDL
modelsintosevencategories:Layer,LossFunction,Optimizer,ActivationFunction,Metric,Util,and
Others.Wethenanalyzed9,129open-sourceDLprojectsfromGithubtoevaluatethefrequencyof
unittests.OurfindingssuggestthatprojectswithunittestshavehigherGithubpopularitymetrics,
unittestsleadtobetterprojectmanagement,andprojectownerspreferthepullrequestswith
unittests.Inaddition,wealsoprovideguidanceonthoroughlytestingDLprojectcomponentsto
identifycommonflaws.
Wesummarizethekeycontributionsofthispaperasfollows:
• Tothebestofourknowledge,thisisthefirststudytoanalyzetheroleofunittestsinopen-
sourceDLprojects,includingthebenefitsunittestscouldbringtoopen-sourceDLprojects
andaninvestigationofDLprojectsthathaveadoptedunittests.Thestudyhighlightsthe
importanceofunittestsinensuringthereliabilityandstabilityofopen-sourceDLprojects.
• WebuiltupataxonomyofunittestsinDLprojectswhichcontainsunittypes,testedproperties,
andassertionsentences.Inaddition,weintegrateourtaxonomywithanexistingone,linking
commonDLfaultswithdifferentunittypesinDLprojects.Theproposedandintegrated
taxonomiesaimtoguidetheDLmodeldevelopersinwritingtestcases.
• Wesystematicallycollectedadatasetforunittestinginopen-sourceDLprojects.Thedataset
mayinspireotherrelatedresearch,suchasautomatedtestcasegeneration,bugrepair,and
furtherempiricalstudies.
2 BACKGROUND
UnitsinDeepLearningProjects:TheIEEEInternationalStandardforSystemsandSoftware
Engineeringspecifiesthataunitrepresentsthesmallestcomponentthatcannotbefurthersubdi-
videdandcanundergotestingindependently[40].Inthecontextofobject-orientedprogramming,
this typically corresponds to the class level [23]. In the field of DL, some components possess
uniquerolesandrequirefurtherclassificationbasedontheirfunctions.DrawinguponKeras[7],a
widely-recognizedDLlibrary,wecategorizeDLmodelunitsintosevendistincttypes.Weillustrate
howeachpartofaunitinaDLprojectworksinFig.1.First,thetrainingandtestingdataare
producedbypre-processingutilitiesbasedontheinputdataset.Second,theLayersintheDLModel
calculateandproducethepredictiondata,whereactivationfunctionsusuallyproducetheoutput
valuesofLayers.Third,theLossfunctioncalculatesthelossvaluebycomparingthetrainingdata
labelsandpredictedvalue,whiletheOptimizerupdatesthemodelparametersforoptimization.
TheMetricunitcalculatesthemetricvalueofthemodeltoevaluateitsperformance.Finally,there
maybesomepost-processingworktobedone.
BugsinDeepLearningProjects:FaultsorbugsinsideDLprojectshavebeenwellstudied
by researchers and may occur in different units of a DL project [37, 39, 81]. Some bugs in DL
projectsmaycausecrashesinthemodelandcanbeidentifiedeasilybasedontheframework’serror
message.Nevertheless,Islametal.[39]foundthat31outof50randomlyselectedcrashedbugs
inDLprojectseitherhadnomessagesorthefixeswereunrelatedtothereturnedmessages.The
faultsmayhideinsidethemodelandwon’ttriggeranyerrorsorcrashes,whichmakesthemhard
todebug.Forexample,theusertriedtobuildaclassifiertopredictthematchresults[4],butthe
modelalwaysoutputs0%Lossand100%Accuracywithnoerrormessages.Inthesourcecode,he
definedtf.nn.softmax_cross_entropy_with_logitsasthelossfunction.Duetothenatureofsoftmax,
thesingleoutputfromthelogitwillalwaysbe1.Hence,afterthecrossentropy,theoutputfromthe
lossfunctionwillbe0.Suchinappropriateusageoflossfunctionbugscanbeidentifiedbyhavinga
,Vol.1,No.1,Article.Publicationdate:February2024.4 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
Fig.1. Anexamplecodeforalossfunctionwithitsunittestcodeandaflowchartshowingtheunitsand
theirinteractionsinDLprojects.
unittestontheoutputofthelossfunctionvaluetoensureitwillneverbe0[3].Wewilldiscuss
mappingsbetweenbugs/faultsandunittestinginDLprojectslaterinthepaper.
UnitTestsinDeepLearningProjects:Aunittestisasmallandexecutablepieceofcodethat
exercisesthefunctionalityofaunitundertest[19].It’spartofsoftwaretestingandcandetect
bugsearly.BasedontheIEEEstandard[40],weconcludeunittestsinDLprojectsaretestingof
individualmoduleswithinorrelatedtotheDLmodelbythedevelopertoensurenoerrorsorbugsin
thewholemodel.Forexample,inFig.1,losses.pyisthelossfunctionfilewithinanopen-sourceDL
project,andlosses_test.pyisitsunittest.Insidetheunittestfile,mockedparameterslikey_clf_true
areinitializedandpassedintothetestedfunctionfocal_loss().Then,theassertionstatementchecks
whethertheactualoutputlossiswithintheexpectedandacceptabletolerance;ifnot,theunittest
fails,andanexplanatoryerrormessageisreturned.
TosupportdevelopersandresearcherswritingunittestsforDLmodels,popularMLframeworks
haveintroducedbuilt-inunittestfunctionsliketf.testinTensorFlow[49].Bydefault,theunittest
frameworkembeddedinPythononlyprovides33assertionsentences,whereasthetf.testoffers
87 different assertion sentences to fit the unique requirements of DL developers. For example,
theassertAllClose isusedtoassertthattwostructuresoflists,NumPyarraysorTensors,have
nearvalueswithinthetolerance.IthasbeenseeninmanyoftheunittestsinML/DLprojectsbut
isnotavailableinthedefaulttestframework.OtherassertionsentenceslikeassertBetweenand
assertArrayEqualarealsocommonlyseeninDLprojectsbutnotusedbystandardPythonprojects.
3 METHODOLOGY
Thissectionexplainshowwecollectandanalyzethedatausedinourstudy.Also,wediscussthe
motivationandapproachforeachresearchquestion.
3.1 DataCollection
InFig.2,wepresentourdatacollectionprocess.First,wecollectedopen-sourceprojectsfrom
PapersWithCode[6]thatwereimplementedusingtheTensorFlowframework(whichisknown
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 5
asthemostpopularframework[80])andreleasedafter2017toensurethatouranalysiswasup
todate.Then,wematchedtheseprojectstotheirrespectivecoderepositoriesanddownloaded
9,129open-sourceDLprojectsfromGitHub(forRQ1).Third,wefiltered2,878ofthemcontaining
unittestscriptsbasedonwhethertheycontainedPythonfileswiththestring“test"inthefile
nameorfilepath[69,70](forRQ1andRQ2).Finally,werandomlysampled400DLprojectswith
unittests.Afterremovingtheduplicatesandarchivedprojects,weachievedadatasetcontaining
363open-sourceDLprojects(minimalcriteriasizewithaconfidencelevelof95%andconfidence
Intervalas0.05[77])withunittests(forRQ2andRQ3).Theprojectscomefromvarioussources,
includingready-to-useframeworks,academicresearchworks,andindustryprojectsfromlarge
techcompanies(e.g.,Google,IBM,LinkedIn,andUber).
Fig.2. Datacollectionpipelinesfortheresearchquestions.
Name Category Definition
LossFunction[7] Thepurposeoflossfunctionsistocomputethequantitythatamodelshouldseektominimizeduringtraining.
Optimizationalgorithmsaretypicallydefinedbytheirupdaterule,whichiscontrolledbyhyperparameters
Optimizer[7,27]
thatdetermineitsbehavior(e.g.thelearningrate).
Activationfunctionsarefunctionsusedinneuralnetworkstocomputetheweightedsumofinputandbiases,
ActivationFunction[7,53]
andtransformthemtotheoutputofaneuroninalayer.
DLunits Layer[7] Alayerconsistsofatensor-intensor-outcomputationfunctionandsomestate,heldinvariables.
Metric[7] Ametricisafunctionthatisusedtojudgetheperformanceofthemodel.
UtilitiesusedinDLprojects,suchasmodelplottingutilities,dataloadingutilities,serializationutilities,
Util[7]
NumPyutilities,backendutilities.
Others OtherunitsinDLprojects,suchasuser-definedlabelclasses,sampling,functions.
Theinput/output(I/O)testcontainstestsforvaluerange,shape,type,etc.Itcandetectwhethertheinputdatameetsthe
Input/Output[16,38]
modelinputrequirements,andalsoreflectswhetherthefunctionsimplementedintheunitmeettheexpectations.
Theerror-raisingtestreferstowhetherthecodecancorrectlythrowanexception,andisoftenusedtocheck
Error-raising[16,38]
whetherthemagnituderangeofthevaluesgeneratedduringthecalculationmeetsthedesignrequirements.
Unit
Themetrictestconsistsofatestofthemetriccalculationfunctionandtheoutputmetricvaluesafterthemodel
properties Metric
istrained.Itisoftenusedtocheckwhetherthemetriccalculationprocessiscorrectorthemodeldesignisvalid.
tobetested
Config[38] Theconfigtestcontainstestsforconfigurationstocheckwhethertheunithasbeeninitializedcorrectly.
Variabletestingincludestherangeofvalues,shape,gradientofvariables,etc.Itcanreflectwhetherthe
Variable
modelstructureisdesignedasexpectedandwhetherthemodelparameterscanbeupdated.
Others Othertests,forexample,testwhetherfilesaregenerated,whetherwebrequestsaresuccessful,etc.
Table1. Typesofdeeplearningunitsandpropertiestobetestedthatarediscussedinourstudy.
3.2 StudyDesign
RQ1:Howcanunittestshelpopen-sourceDLprojects?Tounderstandhowhavingunittests
willhelpopen-sourceDLprojects,weperformedquantitativeanalysisoverallofthe9,129GitHub
DLprojects.WiththesupportofGitHubAPI[13],wemanagedtocrawlthebasicmetricsofanopen-
sourceprojectonGitHub,whichincludesissues,pullrequests,contributors,stars,andforks.Wealso
calculatedtheprojectsizebyKLOCwiththecloctool[17].WeusedtheMann–WhitneyUtest[48]
andCliff’sDeltaeffectsize[28],tocalculatethesampledifferences.Toexaminethecorrelation,we
appliedPearson’scorrelation[64].FollowingthenormalizingGithubmetricsprocedureintroduced
,Vol.1,No.1,Article.Publicationdate:February2024.6 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
byJarczyketal.[41],weappliedlogarithmictransformation𝑥′ =𝑙𝑜𝑔 (𝑥+10)tothemetricsbefore
10
calculatingthecorrelation.
Furthermore,weexploredtheissuesandpullrequestsoftheprojectsformoredetails.Foreach
issueinaDLproject,weextractedtheassociatedlabels.Initially,weorganizedthesebasedonthe
9standardlabelsprovidedbyGitHub[12],resultingin4principalcategories.Subsequently,the
firsttwoauthorsundertookmanuallabellingforlabelsrecurringover100times,leadingtoatotal
of6distinctcategories:Bug,Dependency,Question,Document&Enhancement,Status,andOther.
ForthepullrequestsinaDLproject,wefirstdetermineiftheycontainunittestsbycheckingthe
changedfilelist.Then,wereadthestatusofapullrequestandrecordeditsdetaileddescription
contentwithcomments.FortheDLprojectswithunittests,wecomparedthePRacceptancerate
ofthePRswithunittestsandthePRswithoutunittests.Theacceptancerateisderivedbydividing
thenumberofacceptedunit-testedPRsbythetotalnumberofunit-testedPRs,andviceversa.In
addition,wealsocalculatetheoddratio.TheoddsratioiscomputedbydividingtheoddsofPRs
withunittestsbeingacceptedbytheoddsofPRswithoutunittestsbeingaccepted.Avaluegreater
than1suggeststhathavingunittestsisassociatedwithahigherlikelihoodofPRacceptance.
InSection4.1,weanalyzedtheresultsofDLprojectsthatutilizedunittestsandthosethatdid
not,usingthedatawecollected.AlthoughthefindingsfromRQ1mayseemtrivial,itisimportant
topresentempiricalevidenceforthebenefitsofincorporatingunittestinginDLprojects,asthere
iscurrentlyalackofresearchonthesubject.
RQ2:TowhatextentareDLprojectsunittested?
ToinvestigatetheprevailingstateofunittestsintheDLdomain,weexamined9,129projectsto
determinetheuseofunittestsforDLprograms.Foradeeperunderstanding,wespecificallyutilized
the363DLprojectsthatemployunitteststoexploretheassociatedfiles,testingframeworksand
theassertstatementsutilizedbydevelopers.
For the presence of unit tests in open-source DL projects, we refer to recommendations on
writingunittestsfromtheofficialTensorFlow[9]andPython[16]websites.Moreover,Trautschet
al.[69,70]andYuetal.[76]discussedfilteringrulestocheckunittestsinJavaandPythonprojects.
Basedontheseworks,weidentifyunittestsinDLprojectsbyascertainingwhether“test”existsin
thefilenamesorfilepathsofDLprojects.Forexample,givenasourcecodefilefoo.py,developers
alwaysnameitsunittestasfoo_test.py,orputallthetestscriptfilesinaseparatetestfolderwith
thenamefoo_test.
For the unit-tested projects, we further investigated the files associated with tests, testing
frameworkfrequency,andtheassertionsbeingused.Giventhecomplexitiesofconfiguringand
runningunittestsforthevastnumberofprojects,wetookastaticanalysisapproachforthe363
unit-testedprojects.Specifically,weanalyzedtheimportstatementswithintheunittestfilesto
estimatethenumberofsourcecodefilesthey’reassociatedwith.Bydividingthisnumberbythe
totalfilecount,wederivedanapproximationofthetestcoverageintermsoffiles.Tolearnthe
frequentlyusedtestingframeworks,weusedregularexpressionstoextracttheimportstatements
andassertionsentencesfromthetestscriptfilesineachproject(fromRQ1)andsortedthemby
thenumberofoccurrences.Thefirsttwoauthorsthenmanuallyidentifiedthetestframeworks
and checked the framework documentation and the API usage instructions to ensure that the
frameworkprovidestestingandassertionfunctionalities.
RQ3:WhichunitsandpropertiesaretestedinDLprojects?
Weanalyzedthe363open-sourceDLprojectswithunitteststounderstandwhichunitsofthe
DLmodelsaretestedfrequentlyandwhichunitsneedmoreattention.Inaddition,welookedinto
whatpropertiesaretested,i.e.,whatcontentsaretestedineachunittest,inordertogainsome
insightintounittestsinDLprojects.Duetothelargenumberoftestfiles(over6k)inourdataset,
weadoptedautomatedclassifierstocategorizetheunittestingcasesinDLprojects.
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 7
In our effort to classify unit types within DL projects, we initially consulted the Keras API
documentation [7], given Keras’s widespread adoption and its representation of high-level DL
projectabstractions[37,51].TheAPIcategoriesinKeras,rangingfromModelstoUtilities,served
asafoundationalreference.Postsomerefinementswhichinvolvedomittingoverlyhigh-levelAPIs
andmergingcloselyrelatedones,weestablishedsevendistinctunittypesforDLprojects.These
unittypesareoutlinedinTable1.Inadditiontothese,weidentifiedsixcommonlytestedproperties
within each unit,drawing insights from a notable study byIslam et al. on Deep LearningBug
Characteristics[38]andfromrecommendationsintheofficialPythondocumentation[16]
ToclassifyunittypesandunitpropertieswithinDLprojects,weinitiallyconsultedtheKeras
APIdocumentation[7],givenKeras’swidespreadadoptionanditsrepresentationofhigh-levelDL
projectabstractions[38,51].Aftersomerefinementswhichinvolvedomittingoverlyhigh-level
APIsandmergingcloselyrelatedones,weestablishedsevendistinctunittypesforDLprojects.
TheseunittypesareoutlinedinTable1.Inadditiontothese,weidentifiedsixcommonlytested
propertieswithineachunit,drawinginsightsfromanotablestudybyIslametal.onDeepLearning
BugCharacteristics[38]andfromrecommendationsintheofficialPythondocumentation[16].
Basedonthedefinitionandtheidentifiedtypes,thefirsttwoauthorsmanuallylookedthrough
thetestcasesandnoticedthattheunittypebeingtestedcanbereflectedbythetestclassname
or test file name. For example, the file test_loss.py in Mxnet [10] tests the loss functions, and
test_lstm_layer.pyinDeText[11]teststhelayerwithinthemodel.Similarly,weextractedtheunit
propertiesfromthemethodnamesandtestparameternames.
WebuiltupavaluedictionaryforeachcategorydefinedinTable1.Givenonecategory,we
referredtothemethodnamescollectedinPaperWithCodedataset[18].Forexample,wechecked
theactivationfunctionnameslistedonthewebsiteandincludedthemintheactivationfunction
category,e.g.,relu,tanh.WedevelopedtwoclassifierstocategorizeDLunitsandpropertiesbased
onagivenDLtestfile.TheseclassifiersutilizetheAbstractSyntaxTree(AST)toobtainastructured
representation of the source code [22]. By traversing through each node of the tree with the
𝑁𝑜𝑑𝑒𝑉𝑖𝑠𝑖𝑡𝑜𝑟 providedbytheASTlibraryinPython,theclassifierscanextracttheclass,function,
andmethodcalls.Weoverridethe𝑛𝑜𝑑𝑒𝑉𝑖𝑠𝑖𝑡𝑜𝑟 functioninASTtorecordthemethodcalls.For
example,toextractproperties,ouroverrideofthe𝑣𝑖𝑠𝑖𝑡_𝐶𝑎𝑙𝑙 function.Withinthisfunction,we
checkforthepresenceofthestring“assert"inthecallname.Iffound,weextractthenameof
thetestedparameterfromtheassertionstatementusingthe𝑎𝑟𝑔𝑠 attribute.Afterextraction,the
classifiersmatchthesenamesagainstourpredefineddictionary,whichinturn,determinesthe
appropriatecategoriesforeachfile.
Toevaluatetheaccuracyofourclassifiers,werandomlyselected30filesfromeachcategory.
Then,thefirsttwoauthorsofthispapermanuallycheckedifthepredictedresultswerecorrect
individually. Finally, they got together and worked out any differences until they reached an
agreement.
Weevaluatedtheunittypeclassifierandtheunitpropertyclassifierseparately.Theunittype
classificationisamulti-classproblem(oneobjectcanonlybeassignedtoonenon-binarycategory).
Basedonourcalculation,theaverageaccuracyofourclassifieris0.89,precisionis0.89,recallis1,
andF1scoreis0.94.Notethatforeachcategory,werandomlyselectedtheonesthatarepredicted
astrueinthatcategory,therefore,theprecisionvalueisthesameastheaccuracyandtherecall
valueisalways1.
The classification of unit properties to be tested is a multi-label problem (one object can be
assignedtomultiplelabels).Weevaluatetheresultsinbothlabel-basedandexample-basedways[79].
Label-basedevaluationissimilartohowweevaluatethepreviousclassifierforunittypes(randomly
selected30filesfromeachcategory).Theaverageaccuracyis0.89,precisionis0.89,recallis1,and
F1scoreis0.94.Tocalculatetheexample-basedmetrics,werandomlyselectasubsetof30files
,Vol.1,No.1,Article.Publicationdate:February2024.8 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
800 Tested 30 Tested 150 Tested
600 Untested Untested Untested 20 100
400
10 50
200
0 0 0
2 4 6 8 10 2 4 6 8 10 2 4 6 8 10
KLOC KLOC KLOC
(a) Average Star Count Grouped by(b) AverageIssueCountunderAllStates(c) Average Fork Count Grouped by
KLOC GroupedbyKLOC KLOC
100 40
Tested Tested
80 Untested 30 Untested
60
20
40
20 10
0 0
2 4 6 8 10 5 10
KLOC KLOC
(d) Average PR Count Grouped by(e) Average Individual Contributors
KLOC CountGroupedbyKLOC
Fig.3. AcomparisonofGithubMetricsbetweentheunit-testedopensourceDLprojectsandtheuntested
projects.
fromalltestfilesandcalculatethe𝑆𝑢𝑏𝑠𝑒𝑡𝐴𝑐𝑐𝑢𝑟𝑎𝑐𝑦and𝐻𝑎𝑚𝑚𝑖𝑛𝑔𝐿𝑜𝑠𝑠 metrics.Theresultsareas
follows:SubsetAccuracyis0.77,HammingLossis0.056,Accuracy𝑒𝑥𝑎𝑚 is0.86,Precision𝑒𝑥𝑎𝑚 is
0.95,Recall𝑒𝑥𝑎𝑚 is0.88,andF1𝑒𝑥𝑎𝑚 is0.91.Detailsoftheevaluationdataarereleasedonline[15].
Withthetwoautomaticclassifiers,wecouldidentifytheunittypesandwhatpropertieswere
testedinthegiventestcases.Therefore,webuiltupataxonomyofunittestsinDLprojectsbased
on the results from the classifiers. First, we categorized the test cases into different unit types
bytheunittypeclassifier.Second,weappliedtheunitpropertyclassifiertothetestcasesunder
eachoftheunittypesseparately.Third,wecounttheoccurrenceoftheassertsentencesunder
eachcategorywithAST.Withsuchdata,weconstructthetaxonomyofunittestsinDLprojects,
includingunittypes,testedproperties,andfrequentlyusedassertions.Notethatduetothespace
limit,weonlypickthetop3testedpropertiesandsomeuniqueassertionsentencesundereach
unittypeinDLprojects.WewilldiscussthetaxonomyindetailinSection4.3.
4 RESULTS
4.1 RQ1:Howcanunittestshelpopen-sourceDLprojects?
Finding1:Unittestsinopen-sourceDLprojectscorrelatewiththenumberofstars,forks,
andcontributors.
Inthisstudy,weevaluatethepopularityofanopen-sourceprojectbyfivedifferentcharacteristics,
whicharestars,forks,issues,pullrequests,andcontributors,inspiredbypreviousworks[24,71].
Table2presentsthegroupdifferenceandcorrelationresults.Asaresult,unit-testedprojectshave
statisticallysignificantlyhighercharacteristics(𝑝 < 0.01)forallfivecategorieswith(small)effect
sizesrangingfrom0.15to0.33.Thepresenceofunittestsdemonstratesapositivecorrelationwith
allfivemetrics,thoughnotallcorrelationsarestrong.Specifically,forthenumberofpullrequests
(𝑝 =0.41),weobservearobustcorrelation,suggestingthatunit-testedprojectsaremoreclosely
associatedwithincreasedpullrequestactivity.
,Vol.1,No.1,Article.Publicationdate:February2024.
)gva(
srats
fo
rebmuN
)gva(
sRP
fo
rebmuN
)gva(
seussI
fo
rebmuN
)gva(
srotubirtnoc
fo
rebmuN
)gva(
skrof
fo
rebmuNBeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 9
Metrics Mann-WhitneyU𝑝 EffectSize Pearson𝑝
Star <0.01 0.18 0.10
Issue <0.01 0.22 0.14
Fork <0.01 0.15 0.10
PR <0.01 0.33 0.41
Contributor <0.01 0.19 0.19
Table2. Thesampledifferencesandcorrelationofpopularitymetricswiththepresenceofunittests
50
41.8 Tested
40 Untested
30.8
30
20 15.717.1
12.6
16.7
14.0 11.412.2 12.8
10 6.7 8.2
0
bug dep de on cd uen mc ey nt&enhancemen It
ssue
Lqu aes bti eo ln
s
status other
Fig.4. AcomparisonofGithubissuelabelcategoriesofunittestedanduntestedDLprojects(inpercentage).
Toaccountforvariationsarisingfromprojectsizes,wenormalizedthenumberofthosepopularity
metricsusingtheKLOC(thousandsoflinesofcode)ofeachproject.Fig.3(a)-(e)comparesthefive
characteristicsbetweenallDLprojectswithunittestsandthosewithoutunittests.Specifically,
Fig.3(d-e)consistentlydisplaysunit-testedprojectssurpassingtheuntestedones,suggestinggreater
engagementfromdevelopersincontributingorreproducingtotheproject.WhileFig.3(a-c)shows
someoverlapsbetweenthetwogroups,unit-testedprojectsgenerallyhavehigheraveragevalues
forstars,issues,andforks.
Finding2:Pullrequestswithunittestshaveahigheracceptancerate.
Wealsocrawledthepullrequests(PR)detailsfromDLprojectsthatcontainunittests.Intotal,
wecollected76,105PRsfromDLprojectswithunittests,where25%ofthePRsincludeupdatesin
theunittestfiles.SimilartothefindingsbyTsayetal.[71]inconventionalopen-sourceprojects,we
alsofindthattheinclusionofunittestsinfluencesthePRacceptancerateinDLprojects.Specifically,
82.8%ofthePRswith unittestsaremergedintothesourcecode,whereasonly74.4%ofthose
withoutunittests.Theoddsratiois1.113,whichishigherthantheresult(oddratio=1.059)fromthe
previousstudythatwasconductedacrossmoregeneralconventionalprojects[71].Thissuggests
thatwhileunittestsareassociatedwithahigherlikelihoodofPRacceptanceingeneralopen-source
projects,theirsignificanceisevenmorepronouncedinopen-sourceDLprojects.Asidefromthe
acceptancerate,PRswithunittestsalsohaveashorterwaitingtimebeforethemerge.Wefind
that,onaverage,thePRswithunittests(6.25days)is4hoursfastertobeacceptedthanthose
withoutunittests(6.43days).ItcouldbeduetothePRwithunitteststhatcanhelpthedeveloper
automaticallyidentifythepotentialbugsinthesubmittedcode.Sometimes,theprojectownermay
askthecontributortoaddaunittestforthePRoraskthemtodouble-checkifthecurrentunit
testsarepassedbeforethemerge.
,Vol.1,No.1,Article.Publicationdate:February2024.
tnecreP10 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
Finding3:Issuesfromunit-testedprojectsareresolvedquickerandhavemoreproject
managementlabels.
Inadditiontofinding1and2,weinvestigatedissuemanagementbycomparingtheclosingrate
andthetimetakentocloseissuesandcategorizingdifferentissuetypesbetweenunit-testedand
untestedDLprojects.Ourdatasetcomprised10,858issuesfromprojectswithoutunittestsand
105,430issuesfromunit-testedprojects.Wefindthatissuesfromunit-testedprojectsexhibita
higherclosurerate(83.9%)incontrasttoprojectswithoutunittests(61.8%).Similartotheapproach
usedinFinding2,onaverage,issuesinunit-testedprojectsareclosedin42.7days,whichis4.8
hoursfastercomparedtothoseinprojectswithoutunittests,wheretheaverageclosuretimeis42.9
days.Thisshortertimeframeforissueresolutionandthehighissuecloseratecanindicatethat
unit-testedprojectsareabletoidentifyandaddressissuesmoreswiftly.Thisagilitycontributesto
enhancingtheproject’soveralldependabilityandmakesitmorereliable[21].
Fig.4presentstheissuelabeltypedistributioninagroupedbarchart.Dependencyhasthemost
labelsintheuntestedDLprojectissues(41.8%).Thedependencylabelsaremainlyautomatically
generated when one of the libraries used by the project is updated. On the contrary, the issue
labelsfromDLprojectswithunittestsaretypicallygeneratedandmanagedbydevelopersand
aremorerelatedtostatus(e.g.,approve,duplicated,done)anddocument&enhancement(e.g.,
feedback,upgrade,suggest).Mostotherissuelabels(forDLprojectswithunittests)arerelatedto
thecontributorlicenseagreement(CLA),whichbenefitstheprojectmanagementandencourages
developerstocontribute.Besides,wenoticemoreabbreviatedlabelsusedinthetestedDLprojects,
e.g.,lgtm,wip,tbd.Overall,wefindthatDLprojectswithunittestsareunderbettermanagement,
oneoftheadvantagesthatunittestingbringstoasoftwareproject.
Summary:Ouranalysisrevealedunit-testedDLprojectshaveapositivecorrelationwith
open-sourceprojectmetrics,suchasthenumberofstars,forks,pullrequests,andahigher
acceptancerateofpullrequests.Moreover,unit-testedprojectsdemonstratedfasterand
moreefficientissueresolution.Additionally,theywerealsofoundtohavemoreproject
managementlabels.Thesefindingssuggestthatunittestsplayanessentialroleinensuring
thereliabilityandstabilityofopen-sourceDLprojectsandhighlighttheneedforrigorous
testingtomaintaintheirqualityandpreventissuesfrompropagatingdownstream.
4.2 RQ2:TowhatextentareDLprojectsunittested?
Finding4:68%oftheDLprojectsdonothaveunittestsandtheunittestfilecoverageis
low.
WepresenttheresultsfromRQ2inthissectiontoprovideageneralpictureofhowunittests
aredeployedintheopen-sourceDLprojects.31.52%oftheopen-sourceDLprojectsinourdataset
containunittests,whereastherestoftheprojects(68.48%)donothaveunittests.Itcanbedueto
thatsomeoftheprojectsarefromresearcherswhoprefertofocusontheresultscomparedtothe
codetesting[75].ThelackoftestinginsuchDLprojectsmaymakeithardertoensurethecodeis
workingasintendedandproducingaccurateresults,presentbarriersforotherdeveloperswhowant
toreplicateandimprovetheoriginalmodel,andalsohinderthegrowthofopen-sourceprojects.
Additionally,wealsonoticesomeoftheuntestedprojectsaresimplytheTensorflowversionofa
modelthatwasoriginallydevelopedbyotherframeworks.Third,therearealsodeveloperswho
choosetouse.ipynbtypeoffilefortheirmodel,whichneedsextraefforttotestthefiles[2].Fig.5
demonstratesthedistributionofopen-sourceDLprojectsbasedontheirfileassociatedwiththe
testsrate.56%oftheprojectshavelessthan30%oftheirfilesassociatedwithtestfiles.Andonly
5%oftheprojectshaveacoverageover90%.ThissuggeststhatwhilemanyDLprojectsemployed
unittests,asubstantialnumberoffileshavenotbeencoveredbythetests.
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 11
30
20
10
0
0 20 40 60 80 100
File Associated with Tests Rate (%)
Fig.5. Thedistributionofopen-sourceDLprojectsbasedontheirfileassociatedwithtestsrate.
Framework Numpy Tensorflow unittest PyTest absl GoogleTest nose Others
Num.ofProjects 2,232(77.6%) 1,862(64.7%) 440(15.3%) 284(9.9%) 98(3.4%) 23(0.8%) 19(0.7%) 269(9.3%)
Table3. PythonunittestframeworksusedinsampledDLprojects(notethatoneprojectmayincludemore
thanoneframework).
Finding5:NumpyandTensorflowarethemostcommonlyusedtestingframeworks.
InTable3,wepresenttheusageoftestingframeworksinDLprojects.TheNumPy[14]and
TensorFlowframeworksareusedthemostforwritingunittests,accountingfor77.6%and64.7%,
respectively. Some DL projects use both frameworks. In some simple test scenarios, the basic
assertionmethodsprovidedbyNumPyaremorestraightforwardandeasiertouse,ordevelopers
needothermethodsthanNumPyprovidestoinitiateparametervalues,e.g.,np.int32,np.random,
andnp.zeros.Ifmorecomplextestsareneeded,orifthetestenvironmentreliesontheTensorFlow
run-timeenvironment,moredeveloperswillchoosethetoolsprovidedbyTensorFlowfortesting[8].
Inaddition,somedeveloperswriteunittestscriptsusingframeworkssuchasunittest[16](theone
providedbydefaultinPython)andpytest[1],whichprovidesimilartestingmethods.
Ontheotherhand,9.3%oftheDLprojectsusedifferentframeworkswhenwritingunittests.
Specifically,somedevelopersusedlessfrequentframeworks,customtestingtools,orprintfunctions
towriteunittests.Forexample,thedriver-check.py inmsc-graphstudy[5]combinesif-elseand
try-except statements using print and raise to output the results of the process and the final
promptmessagetodeterminewhetherthetestpasses.Insomeexceptionalcases,commontesting
frameworks may not be utilized for various reasons, such as limited testing knowledge of the
developersorunsuitabilityforthespecifictask(e.g.,whentestingwhetheralibraryisimported
correctlyorconfiguringthemodelenvironment).
Finding6:21%oftheassertionsentencesarenotidentifiedwithinthedataset.
WealsocounttheusageofassertionsentencesfromTensorFlow.Asatestframework,tf.Test [8]
provides87assertsentences.79%oftheassertsentencesareusedinourdataset.Thefivemost
frequentlyusedsentencesareassertEqual,assertTrue,assertAllEqual,assertAllClose,andAssertRaises.
NotethatassertAllEqualandassertAllClosearenotprovidedbytheunittestframeworkembedded
inPython.TheyweredesignedtoasserttheNumPyndarraiesorTensorscommonlyusedinDL
projects. Besides, some assertions are not found in the dataset. Some of them are the negative
form of other assertion sentences used in the dataset, e.g., assertNotStartWith, assertNotRegex,
assertNotAlmostEquals.Insteadofcallingthosenegativeforms,developersusepositiveforms,such
asassertRegex andassertAlmostEquals.Otherassertionsnotfoundinthedatasetmayneedmore
attentiontobeused.Forexample,theassertWarnsandassertWarnsRegexarenotusedprobablydueto
developerscaremoreabouterrorsthanwarnings.Assertions(e.g.,assertContainsExactSubsequence,
assertContainsInOrder,andassertContainsSubsequence)thatcheckthesubsetofastringorlistmay
,Vol.1,No.1,Article.Publicationdate:February2024.
)%(
stcejorP
fo
egatnecreP12 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
Fig.6. Ataxonomyofunittestsinopen-sourceDLprojectsincludestesttypes,propertiestobetested,and
frequentlyusedassertions.
Framework Input/Output ErrorRaising Metric Config Variable Others
Num.ofTestFiles 3,467(50.3%) 1,223(17.8%) 1,005(14.6%) 538(7.8%) 345(5%) 907(13.2%)
Table4. PropertiesofunitstestedinDLprojectsintermsoftestfilesfromthedataset.
becreatedforuncommonDLtasksorintroduceddirectlyfromassertionsinJavathathavesimilar
functionalities.
Summary:68%oftheopen-sourceDLprojectsinourdatasetdonothaveunittests.And56%
ofthetestedprojectshavelessthan30%ofthefilesassociatedwithtests.Themostcommon
frameworksinthetestedDLprojectsareNumPyandTensorFlow.Specialscenariosmay
havecustomtestingtoolstowriteunittests.Someofthelesscommonassertionsentences
couldrequiresomeattention.
4.3 RQ3:WhichunitsandpropertiesaretestedinDLprojects?
Afterhavingageneralpictureofunittestinginopen-sourceDLprojects,welookedintothecontent
oftheunittestscripts.Wedevelopedclassifierstotellwhichunitsaretestedandwhatproperties
ofunitsaretestedinDLprojects.
Finding7:AtaxonomythatlinkstheunittypesandtestedpropertiesinDLprojects.
AdetailedtaxonomyofunittypesandtestedpropertiesisshowninFig.6whichhasbeenderived
byfollowingtheprocessmentionedinSection3.2.Itpresentsseventypesofunitsinopen-source
DLprojects.Foreachunit,thenumbernexttoitsnamerepresentstheoccurrenceofitamong
all test files in percentage. It also links with the frequently tested properties and the assertion
sentencesoftenusedtotestthespecificunit.Table4presentstheoveralldistributionofproperties
tobetestedinallunits.WediscusseachoftheunitsinFig.6.
Layer. TheLayerunithasthemostunittestsamongallotherunittypes,asitisthecoreunitof
aDLmodel.AlayerintheDLmodelisalsoknownasablockorasinglenet.Layersofneurons
formaDLnetwork.Fig.7showsanexampleofatestcasefora2Dconvolutionlayer.Itgetsthe
output (testingI/O)ofthetestedlayerandcomparesitsshapewithanexpectedoutputshape.The
testsvaryfromtestingthesingle-layeroutputstotestingtheresultsoftheentirenetworkwithin
anexpectedrange.Duringthestudy,wenoticedthatsomedevelopersalsotendtomisconfigure
thelayeronpurposeandcatchtheraisederrorswithassertRaises orassertRaisesRegex (testing
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 13
import tensorflow as tf
def test_conv2d(self):
...
output = cl.conv2d(inputs, 'test_conv2d',
filter_size, in_channels, out_channels, strides)
output_shape = [2, 5, 5, 4]
self.assertAllEqual(tf.shape(output), output_shape)
Fig.7. Examplecodetotesttheshapeoftheoutputvalueinonelayer.
def test_net_construct(self, net):
with self.assertRaisesRegex(ValueError,
"output_channels must not be empty"):
net(output_channels=[],
kernel_shapes=self.kernel_shapes,
strides=self.strides,
paddings=self.paddings)
Fig.8. ExamplecodetotestthelayervariablewithassertRaisesRegex.
ErrorRaising),whichpreventsdevelopersfromusingtry/catch,asshowninFig.8.Therefore,fewer
ExceptionHandling,knownasoneofthebadpracticesintestcodes(testsmells),occurinPython
comparedtoJava[72].TotesttheConfigorVariableofalayer,developerscancallget_configor
get_variablesandassertthevalue,respectively.
Util. TestingtheUtilunitincludesdataprocessing,testinitiation,databaseutilities,andother
utilityfunctions.BecausetheUtilunithasthehighestnumberoffunctionsinaDLproject,there
naturallyexistsahighernumberofunittestsforit.Sincetheutilityfunctionshavestraightforward
functionalities,writingunittestsforthemiseasierthanotherunitsinDLprojects.Forexample,
whentestingmatrixreshapesfunctionssuchasmatrixtransposition,developerscanquicklycreate
some input matrix and the expected outputs. The AssertDTypeEqual can be used to check the
ndarraydatatype.
Metric. TestingtheMetricofaDLprojectaimstoensurethevalidationworks.Wenoticedthat
AssertBetweenorAssertNear isusedtomeasurethemetricresultwithinexpectation.Aidefrom
that,AssertIsInstanceisalsousedtoensurethereturnedmetricisinthecorrectformatforreading
andcomputing,asseeninFig.9.
Optimizer. Intestingtheoptimizer,developerstendtotraintheDLmodeltocomputethe
actual gradients of the loss value. Besides, we also saw some unit tests testing the optimizer’s
configurationtoensurethefunctionwassetupcorrectly,asseeninFig.10.
LossFunction&ActivationFunction. LossFunctionandActivationFunctionunitsarenot
testedmuch,likelyduetothedevelopersonlytestingsuchfunctionswhentheyneedtocreatea
newapproach.Inmostcases,developerscallloss/activationAPIfromwell-establishedDLlibraries
forwhichtheydonotneedtowritetestcases.Anexampleoftestingthelossfunctionoutputvalue
isshowninFig.1.
Others. TheOthersunitincludestestingofself-definedfunctions,samplingfunctions,math
calculations,whetheranHTTPrequestissuccessful,etc.Theunittestsforthisunitaresimilarto
unittestsinconventionalsoftwareprojects.
,Vol.1,No.1,Article.Publicationdate:February2024.14 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
def test_classification_metrics(self):
...
expected_return = {'precision': np.array[],
'recall': ...}
metrics = classification_metrics(ground_truth,
retrieved)
self.assertIsInstance(metrics, dict)
for k, v in metrics.items():
self.assertIsInstance(v, np.ndarray)
...
Fig.9. Examplecodetotesttheclassificationmetrics.
def test_adam_tf(self):
"""Test creating an Adam optimizer."""
opt = optimizers.Adam(learning_rate=0.01)
global_step = tf.Variable(0)
tfopt = opt._create_tf_optimizer(global_step)
self.assertIsInstance(tfpot, tf.keras.optimizers
.Adam)
Fig.10. Examplecodetotesttheoptimizer.
Summary: More than 70% of the unit tests test the Layer and Util unit in DL projects.
ActivationFunction,Optimizer,andLossFunctionaretheleasttested.Morethanhalfof
thetestcasesaretestingtheI/O.ErrorRaisingisalsocommonlyseenintestcases.Config
andVariablesoftheunitsarenotthefocuswhentesting,whichmayneedmoreattention
inthefuture.Wesummarizedataxonomy(Fig.6)thataimstohelpdeveloperstowritetest
casesfordifferentunitsinanopen-sourceDLproject.
5 DISCUSSIONANDIMPLICATIONS
Based on the preceding findings, our study reveals the emergence of the need for unit testing
inopen-sourceDLprojects;despitetheadvantagesthatunittestingcouldprovideforprojects,
notenoughhaveunittests.Wenextdiscusssomeactionableimplicationsforpractitionersand
researchers.
5.1 Implicationforpractitioners
Basedonthefindingsintheresearchquestions,wesummarisetheimplicationsforDLpractitioners.
DetectingandmitigatingDeepLearningfaultsbecomessimplerwithadeveloper’sguide
inwritingDLunittests.InRQ3,webuildataxonomyforunittestsinopen-sourceDLprojects
toassistdevelopersinwritingtestcases.Sinceunittestingisknownforidentifyingfaults/bugs
inside the code [61], we discuss the mapping between DL faults and unit tests in this section.
Previously,Humbatovaetal.[37]haveidentifiedfaultsinDLsystemsandbuiltataxonomyasone
oftheresearchoutcomes.Integratedwiththeiroutcomes,wemanagedtobuildataxonomythat
mapsthedeeplearningfaults[37]andunittests(RQ3),whichmayhelpthepractitionersprevent
thecorrespondingfaults.Thefirsttwoauthorsconductedopencodingtobuildthetaxonomyto
achievethis.First,theywentthrougheachsubsectionofthefaultsinopen-sourceDLProjectsand
triedtofindcorrespondingsamplesinthecodebase.Second,eachofthemconductedthemapping
individually.Someofthemappingsareintuitive.Forexample,mapthefaultsintheoptimizerwith
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 15
Fig.11. Integrationwithexistingliterature[37],themappingofourtaxonomy(unittestsinopen-sourceDL
projects)withthetaxonomyoffaultsinDLprojects.
theunittestsintheoptimizer.Finally,theymetupandsolvedthedisagreementsuntiltheyreached
aconsensus.wecalculatedtheKrippendorff’salphascore[36]andthevalue(𝛼 =0.87)indicatesa
goodagreement.
InFig.11,wepresentthetaxonomyofunittypesofDLprojectsmappedwiththefaultsthat
unittestscouldidentify.Weputthedetailedfaultsintobulletpointsunderthesecondlevelofthe
taxonomy.Wehidesomefaultswithdotsduetothespacelimit.Afullversionofthetaxonomy
ispresentedonline[15].Notethatsomefaultscanbetestedbymulti-unitsofDLprojects,e.g.,
Wronginput,API,andGPUUsage.
Withsuchconnections,weaimtogivedevelopersaguideintohoweachtypeofunittestcan
navigateorpreventcertaintypesofbugsfromhappening.Givenaparticularbug,developersshall
locatethebuggedunitfromthistaxonomysothattheycanrefertoFig.6toconstructatestcase
toavoidfutureissueswithintheunit.Specifically,totestamissinglayerfault,developerscan
firstidentifywhetherthebugisrelatedtothelayerunit.Then,theycouldcheckthecommonly
usedassertionsintheLayerunitinFig.6,andassertthelengthoflayersisunderexpected(e.g.,
𝑎𝑠𝑠𝑒𝑟𝑡𝐿𝑒𝑛(𝑚𝑜𝑑𝑒𝑙.𝑙𝑎𝑦𝑒𝑟𝑠,𝑛𝑢𝑚_𝑙𝑎𝑦𝑒𝑟)).Duringthetrainingphase,whichhasthemajoritynumber
offaults,wepresentasample(Fig.1)onhowtotestaself-definedlossfunctiontoensuretheoutput
isunderexpectationbyusingthe𝐴𝑠𝑠𝑒𝑟𝑡𝐴𝑙𝑙𝐶𝑙𝑜𝑠𝑒 toavoidthewronglosscalculationerror.The
Validating/TestingfaultscanbedetectedbywritingunittestsfortheMetric,e.g.,checkingifthe
metricvalueiswithinexpectationwith𝐴𝑠𝑠𝑒𝑟𝑡𝐵𝑒𝑡𝑤𝑒𝑒𝑛.TheUtilitytestscanaddressfaultsinthe
TrainingDataQuality.Beforereadingthedataasinput,developerscouldwriteunitteststocheck
ifthedataislabelledwell,whichincludesassertingthevalueisequaltotheexpectedonesorifthe
labelleddatasizeiscorrect.ForthefaultsinGPUUsage,TensorflowhasprovidedseveralAPIsto
checkthenumberofavailableGPUsandtheirnames.Wefoundthatsomeunittestswillcheck
thenumberofGPUs(𝑡𝑓.𝑐𝑜𝑛𝑓𝑖𝑔.𝑒𝑥𝑝𝑒𝑟𝑖𝑚𝑒𝑛𝑡𝑎𝑙.𝑙𝑖𝑠𝑡_𝑝ℎ𝑦𝑠𝑖𝑐𝑎𝑙_𝑑𝑒𝑣𝑖𝑐𝑒𝑠(′𝐺𝑃𝑈′))beforethetraining
tocheckwhetheritisenoughforthetrainingorsimplycheckiftheGPUisavailable.
Despitethediscussedfaultsthatcanbeidentifiedbyunittesting,wefoundsomefaultsthathave
notbeenwell-testedinDLprojects.Forexample,mostunittestsinactivationfunctiononlyfocus
ontestingifthefunctionisworkingasexpected,e.g.,thecorrectoutputvalue.Fewoftheunit
teststestwhethertheselectedactivationfunctioniscorrect.Itmaybetrivialfortheseniors,but
fornovicedeveloperswhotriedtoreproduceothermodels,anassertontheactivationfunction
nameortheoutputsfromdifferentfunctionscansavethemtimetodebugsincethewrongtypeof
activationfunctionisthemainfaultinthisfield[37].Besides,intheTrainingprocess,wedidnot
,Vol.1,No.1,Article.Publicationdate:February2024.16 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
seemanytestsonthesuboptimalnumberofepochsandbatchsize.InthefaultsintheModel,a
commonfault,namelysuboptimalnetworkstructure(usingtoofewortoomanylayers),isalso
notseenintheunittestcases.Thiscouldbebecausethedevelopersarefamiliarwiththeirmodel
andwillnotmakesuchmistakes.However,fortheoneswhowanttoreusethemodelorconduct
someresearchonit,asuboptimalfaultcouldcausefailures.Therefore,developersshouldconsider
potentialcontributorswhentheywriteunittestcasesfortheirDLprojects.
Writeunittestswhensubmittingapullrequest.InRQ1,weobservethatwhensubmitting
aPR,thetestinclusionleadstoahigheracceptancerateandashorterwaitingperiod.Therefore,
whendeveloperstendtosubmitaPR,wesuggesttheycommentthatallexistingtestshavebeen
passedandnewtestshavebeenaddedfornewfeatures.Someexamplesfromtheopen-source
projectsarelike“Listofchanges:...Addunittestsforthemetricsmodule."and“So,wefinishedwith
lastupdatesofcodetopassalltests.Thelastthingisfailingandalsofixed.".Alternatively,theproject
ownermayrequestyoutodoso,e.g.,‘ThisisanexcellentPR.Canyouaddtestsforit?‘".Inaddition,
wealsoencouragepractitionerstosubmitPRsthatarepurelyrelatedtounittests(allchangedfiles
aretestfiles),especiallytoprojectswithoutunittests.Therequestsmayberelatedtofixingtest
smellsinthecurrentunittestsoraddingnewtestsfortheexistingmethods.
5.2 Implicationforresearchers
QualitativestudieswithpractitionersWhileourcurrentstudyisgroundedinastaticquantita-
tiveanalysisofminedrepositories,thereexistsanavenueforfurtherresearchthatcanprovidea
qualitativestudyinthisfield.Toaugmentourfindings,researcherscouldconductonqualitative
studiesinvolvingdirectengagementwithDLpractitioners.Conductinginterviews,surveys,or
focusgroupswithdeveloperscouldprovidedeeperinsightsintotheirunittestingpracticesand
morechallenges.Byvalidatingandrefiningthetaxonomiesderivedfromourquantitativestudy
throughtheseinteractions,researchersmaybeabletounearthmoreaspectsofunittestingpractices
inthecontextofopen-sourceDLprojectsandaddmoretothetaxonomies.Thisapproachwould
enhanceunderstandingoftheinteractionbetweenunittestingandtheopen-sourceDLproject
development.
SupportunittestscompletionforDLprojectsThoughpreviousworks[33,47,55,57,67,73]
havebeenconductedonbettertestingDLprojects,agapremainsintherealmofunittestingfor
suchprojects.Theobservedlowadoptionandfilecoverageratesforunittests,ashighlightedin
RQ2,underscoreaneedforresearcherstodelvedeeper.It’simportanttounderstandtheunderlying
reasonswhydevelopersarenotwritingunittestsandtounearththechallengesdevelopersface.
Pinpointing these challenges can pave the way for solutions that facilitate more effective unit
testwriting,forinstance,unittestcompletionforDLprojects.Consideringthecomplexityoftest
case generation in Python [45], an initial step could be assisting developers in completing the
assertstatementsforDLprojects.OurfindingsfromRQ3,detailingfrequentlytestedproperties
acrossvariousunittypesandpreferredassertions(somepotentiallyDL-specific),offerafoundation.
Leveragingthis,futureresearchcanemploytoolslikeLargeLanguageModelstofurtherassist
developersinrefiningandcompletingtheirtestcases.
EnhancedunittestqualityinopensourceDLprojectsWithourdeepunderstandingof
DLunittypesandtheirassociatedbugs,thereemergesanopportunitytoinnovatemethodsthat
enhancethequalityofunittestsinDLprojects,ensuringtheyarecomprehensiveandaddress
potentialvulnerabilities.SimilartoJiaetal.[43]didtotheDLlibraries,researcherscouldinjecta
knowntypeofbugsinDLprojectsandcheckiftheunittestcandetectthecertainbugandhow
theunittestcanbeimproved.Forexample,givenaunittestonthelayerofamodel,onenew
approachcouldbetointentionallyinjectabug(e.g.,omittheflattenlayerinthesourcecode).The
testshouldideallyflagthisomission.Ifthetestdoesn’tcatchthisbug,there’sanopportunityfor
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 17
researcherstorefinethetest’ssensitivity.Beyondjustdetection,thechallengethenextendsto
providingmeaningfulerrormessagesordrawingfromthetaxonomytosuggestspecificupdates
forbug-specifictestcases.Suchrefinedtestingmethodscouldboostthereliabilityandrobustness
oftestsinopen-sourceDLprojects.
Research DL projects also need unit tests As mentioned in our study, only 31.5% of the
projectswecollectedhaveunittests(RQ2).Thereasonswhyopen-sourceDLprojectsdonothave
unittestsmaybebecause,forAIresearchers,themodelmaycallsomethird-partyAPIsanddo
notthinkunittestsareneeded.WhilesomeDLmodelscouldonlybecomposedofafewAPIcalls
fromDLframeworks,theremightstillbeundetectedfaultsinthosecalls(seeninFig.11and[37]).
Havingunittestsaheadcanreducethedebuggingtime.Asidefromthat,wefindthatunit-tested
open-sourceDLprojectspositivelycorrelatewithopen-sourceprojectmetrics(RQ1),soresearchers
shouldconsideraddingunittestsfortheirprojectstoincreasethetrustworthinessandreliability
ofthecodeandmakeitmoreusefulforotherresearchersandpractitionerswhomayalsowantto
reproduceyourworkinotherareas.
6 THREATSTOVALIDITY
InternalvalidityApotentialthreattothevalidityofthisstudyisthedetectionofunittestsin
aproject.Althoughthereareofficialdocuments[9,16]thatguidehowtowriteunittests,some
developersmaynotfollowtheseguidelineswhenwritingunittests.Thiscouldleadtothepotential
misclassificationofprojects.Tomitigatethisconcern,wenotonlyreliedonofficialdocuments
butalsoreviewedotherresearch[70]onunittestingtodeterminehowtoidentifyunittestsina
project.Additionally,wetriedtobeasthoroughaspossibleindetectingunittestsinaproject,but
theremaybesomecaseswhereunittestsarenotdetected.
Another internal threat is how we defined unit types in DL projects and the properties. To
mitigatethepotentialbias,werefertotheIEEEdefinitionofunittest,Kerasdocumentation,and
somerelatedresearchinDLprojects[7,16,38,40].Tomitigatethethreatduringtheevaluation
of our scripts (the classifiers for which units and properties are tested), we have two authors
independentlylabeltheoutputfromthescripts,andtheaccuracyisfair.Duringtheprocedureof
buildingthetaxonomy(Fig.11),manualeffortsarerequiredfortheintegration.Tomitigatethis,
wehavetwoauthors(withDLexperience)toconductthemappingandresolvetheconflictsforthe
finalresults.Inaddition,themetrictomeasuretheinneragreementishigh,demonstratingthe
result’sreliability.
ExternalvalidityThethreatstoexternalvalidityinourstudyarerelatedtothedataselection
andgeneralization.ThisstudycollecteddatafromPaperswithCode,whichcontainsvariousopen-
sourceDLprojectsfromdifferentpublications.Still,itmaynotberepresentativeofallopen-source
DLprojectsthatexist.Ourinvestigationofthedownloadedopen-sourceDLprojectsrevealedthat
thedatasetincludedprojectsdevelopedbyacademiciansandnotableprojectsfromtechcompanies
suchastheBERTmodel[30]orDeText[34].Recentresearch[74],usingdatafromPaperswithCode,
alsoconfirmsbothsectors’presence,highlightingclosecollaborationastheindustryusesacademic
frameworksandacademicsemployindustryDLlibraries.However,weacknowledgethatitmaynot
includeprojectsthatdonothavepublications.Thislimitationshouldbetakenintoconsideration
wheninterpretingtheresultsofthestudy.Furthermore,werecognizethatresearchersmaynot
alwayswriteunittestsforresearchprojects,whichcouldinfluencetheFinding4 ofthisstudy.
Nevertheless,unittestingisstillconsideredacrucialstepinthesoftwaredevelopmentprocess,
andthisstudyaimstoprovidevaluableinsightsintobestpracticesforDLmodeltesting.
ConstructvalidityInRQ1ofthisstudy,wemeasuredthepopularityoftheopen-sourceprojects
usingthenumberofstars,forks,andcontributorsasproxies,whichalignswiththemethodsused
inpreviousstudiesthathaveusedsimilarmetricstoassesspopularity[24].Furthermore,previous
,Vol.1,No.1,Article.Publicationdate:February2024.18 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
studieshavealsoconfirmedthatthenumberofcontributorsisakeyfactorinthesuccessofopen-
sourceprojects[24,50].However,it’simportanttonotethatusingmetricssuchasstars,forks,
andcontributorstomeasurepopularitymaynotbeentirelyaccurate,asdevelopersmaystara
projectforotherreasons,suchasusingitasabookmarkorsimplywantingtofollowtheupdate.
Additionally,it’sdifficulttodetermineacausalrelationshipbetweenunittestingandpopularity,as
otherfactorsmaycontributetoaproject’ssuccess.
7 RELATEDWORK
StudiesonUnitTestingRecentworksinunittestingdoubtwhetherexistingstandarddefinitions
ofunittestingarestillvalidinmodernsoftwaredevelopmentenvironments[68–70].Trautsch
etal.[70]classified38,782testcasesasunitandintegrationtestsandusedmutationtestingto
evaluatetheirdefectdetectionability.Theysuggestedreconsideringthedefinitionsofunitand
integrationtesting.Trautschetal.[68]studied27JavaandPythonprojectswithmorethan49,000
testcases.Theyconfirmedthatunittestswerebetteratpinpointingthesourceofthedefect.Our
studydefinedtheunittypesinDLprojectsbasedontheIEEEdefinitionandourobservationsof
theKeraslibrarytoensuretheresultisgeneralizedandobjective.
TestinginDLProjectsInpreviousstudies,researchersstudiedthechallenges[20,58,59]in
ML-basedsoftwaresystems.Theypointedoutfromahigh-levelperspectivewhichpartsofmachine
learning-basedsoftwaresystemsneedtobetestedinpractice[25],suchasfunctionsanddata,
modeldevelopment,infrastructure,andmonitoringtests.Later,softwareengineeringresearchers
conductedmoredetailedresearchondatatestingandmodeltestingofDLapplications.Brecket
al.[26]proposedadataverificationsystemtospecificallydetectanomaliesinthedatasenttothe
machinelearningpipeline.Regardingmodeltesting,arelatedtopicisastudyofgeneratinginput
datatoincreasethecoverageofneuralnetworkmodels.Researchersalsohaveproposedsome
newneuralnetworkcoveragemetrics[46,55,60,65],black-boxtesting[73]andwhite-boxtesting
methods [33, 57, 67]. Specifically, the DeepXplore [55] first proposed neuron coverage criteria
to drive test generation. Ma et al. [47] proposed DeepGauge, a set of multi-granularity testing
standardsforDLsystemsdesignedtoportraytestplatformsinmanyways.AndYanetal.[73]
designedtheARTDLalgorithmbasedontheblackboxtestingmethodRT(randomtesting)to
generatetestcasesmorelikelytocausefailure.Guoetal.[33]proposedDLFuzz,whichmaximizes
theneuroncoverageandthepredictiondifferencebetweentheoriginalinputandthemutated
inputbykeepingasmallinputmutation.Mostoftheresearchmentionedabovehasbeenfocused
onexploringnewapproachestoincreasethecoverageoftestcases,testedneurons,andplatforms.
OurstudyinvestigatestheunittestincurrentDLsystems,thefirstworkintheareatoourbest
knowledge.
ThisstudyisoneofthefewthatexaminesunittestinginDLprojects.Zhangetal.[78]have
highlightedthechallengesindividingDLsystemsintotestableunits.Theycitedtwoolderworks
thatmaybeusefulforwritingunittestsforMLprograms.However,theseworksarenotsuitable
forrecentDLmodels.Riccioetal.[56],andSongetal.[63]alsostudiedthecurrenttestingpractices
andemphasizedtheneedformoreresearchonunittestinginlearningsystemstoidentifybugs.
Our research aims to contribute to the ongoing efforts to improve unit testing practices in DL
projectsandgiveguidanceonwritingunittestsbystudyingexistingtestcasesinDLprojects.
8 CONCLUSION
Deep learning models have become widely used and essential for various applications. Thus,
ensuringopen-sourceDLprojectmethodsperformcorrectlyviaunittestingiscriticaltotheir
reliability,efficiency,androbustness.Inthisresearch,weexaminedunittestinginopen-source
DLprojects.OurfindingsindicateunittestedDLprojectshavehigherprojectmetrics,suchas
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 19
thenumberofcontributors,stars,andforks,shorterwaitingtimes,andhigheracceptancerates
forpullrequests.However,68%oftheprojectsinthedatasetdonotcurrentlyuseunittests.We
examinedtheprojectsthatuseunittestsbyanalyzingtheASTtreesandfoundthatmostunittests
testedtheLayerunit,focusingontestingI/O.Wediscusstheimplicationsofthesefindingsand
thestudy’spotentiallimitations.Wesuggestthatdevelopersusethetaxonomiesoutlinedinthe
paperasaguideforcreatingunitteststoimprovethereliabilityandreproducibilityofopen-source
DLprojects.Forresearchers,theycouldexploreautomaticunittestsgenerationforDLprojectsor
improvetheexistingcodequality.
ACKNOWLEDGEMENTS
ThisresearchispartiallyfundedbytheAustralianResearchCouncilundergrantDP210100041.
REFERENCES
[1] 2015.pytest:helpsyouwritebetterprograms.https://docs.pytest.org/en/7.1.x/. Accessed:2022-08-21.
[2] 2016.UnittestsforfunctionsinaJupyternotebook?https://stackoverflow.com/questions/40172281/unit-tests-for-
functions-in-a-jupyter-notebook. Accessed:2022-08-16.
[3] 2017.HowToUnitTestMachineLearningCode.https://www.kdnuggets.com/2017/11/unit-test-machine-learning-
code.html. Accessed:2022-03-09.
[4] 2017.Tensorflowresponseismakingnosense.https://www.reddit.com/r/MachineLearning/comments/6qyvvg/p_
tensorflow_response_is_making_no_sense/. Accessed:2022-08-09.
[5] 2021.driver-check.py.https://github.com/5gon12eder/msc-graphstudy/blob/master/test/driver-check.py. Accessed:
2022-01-09.
[6] 2021.Github-paperswithcode/paperswithcode-data:thefulldatasetbehindpaperswithcode.com.https://github.com/
paperswithcode/paperswithcode-data. Accessed:2022-01-09.
[7] 2021.KerasAPIreference.https://keras.io/api/. Accessed:2022-01-09.
[8] 2021. Module:tf.test|TensorFlowCorev2.5.0. https://tensorflow.google.cn/versions/r2.5/api_docs/python/tf/test.
Accessed:2022-01-09.
[9] 2021.TensorFlowtestingbestpractices.https://tensorflow.google.cn/community/contribute/tests. Accessed:2022-01-
09.
[10] 2021.test_loss.py.https://github.com/apache/incubator-mxnet/blob/master/tests/python/unittest/test_loss.py. Ac-
cessed:2022-01-09.
[11] 2021.test_lstm_layer.py.https://github.com/linkedin/detext/blob/master/test/detext/layers/test_lstm_layer.py. Ac-
cessed:2022-01-09.
[12] 2022. GitHub Managing labels. https://docs.github.com/en/issues/using-labels-and-milestones-to-track-work/
managing-labels. Accessed:2022-08-09.
[13] 2022.GitHubRESTAPI.https://docs.github.com/en/rest. Accessed:2022-08-09.
[14] 2022.TestSupport(numpy.testing).https://numpy.org/doc/stable/reference/routines.testing.html. Accessed:2022-08-
21.
[15] 2022.UnitTestinOpen-sourceDLProjects.https://github.com/freddiewanah/UnitTest-DL. Accessed:2023-07-09.
[16] 2022.unittest-Unittestingframework-python3.10.2documentation.https://docs.python.org/3/library/unittest.html.
Accessed:2022-08-09.
[17] 2023.AlDanial/cloc:cloccountsblanklines,commentlines,andphysicallinesofsourcecodeinmanyprogramming
languages.https://github.com/AlDanial/cloc. Accessed:2023-08-09.
[18] 2023.GeneralMethods,PapersWithCode.https://paperswithcode.com/methods/area/general. Accessed:2023-08-19.
[19] MMoeinAlmasi,HadiHemmati,GordonFraser,AndreaArcuri,andJanisBenefelds.2017.Anindustrialevaluationof
unittestgeneration:Findingrealfaultsinafinancialapplication.In2017IEEE/ACM39thInternationalConferenceon
SoftwareEngineering:SoftwareEngineeringinPracticeTrack(ICSE-SEIP).IEEE,263–272.
[20] AndersArpteg,BjörnBrinne,LukaCrnkovic-Friis,andJanBosch.2018. Softwareengineeringchallengesofdeep
learning.In201844thEuromicroConferenceonSoftwareEngineeringandAdvancedApplications(SEAA).IEEE,50–59.
[21] LerinaAversanoandMariaTortorella.2015.Analysingthereliabilityofopensourcesoftwareprojects.In201510th
InternationalJointConferenceonSoftwareTechnologies(ICSOFT),Vol.1.IEEE,1–10.
[22] IraDBaxter,AndrewYahin,LeonardoMoura,MarceloSant’Anna,andLorraineBier.1998. Clonedetectionusing
abstractsyntaxtrees.InProceedings.InternationalConferenceonSoftwareMaintenance(Cat.No.98CB36272).IEEE,
368–377.
[23] RobertVBinder.1999.TestingObject-OrientedSystems:Objects,Patterns,andTools.
,Vol.1,No.1,Article.Publicationdate:February2024.20 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
[24] HudsonBorges,AndreHora,andMarcoTulioValente.2016.Understandingthefactorsthatimpactthepopularity
ofGitHubrepositories.In2016IEEEinternationalconferenceonsoftwaremaintenanceandevolution(ICSME).IEEE,
334–344.
[25] EricBreck,ShanqingCai,EricNielsen,MichaelSalib,andDSculley.2017.TheMLtestscore:ArubricforMLproduction
readinessandtechnicaldebtreduction.In2017IEEEInternationalConferenceonBigData(BigData).IEEE,1123–1132.
[26] EricBreck,NeoklisPolyzotis,SudipRoy,StevenWhang,andMartinZinkevich.2019.DataValidationforMachine
Learning..InMLSys.
[27] DamiChoi,ChristopherJShallue,ZacharyNado,JaehoonLee,ChrisJMaddison,andGeorgeEDahl.2019. On
empiricalcomparisonsofoptimizersfordeeplearning.arXivpreprintarXiv:1910.05446(2019).
[28] NormanCliff.1993.Dominancestatistics:Ordinalanalysestoanswerordinalquestions.Psychologicalbulletin114,3
(1993),494.
[29] ErmiraDakaandGordonFraser.2014.Asurveyonunittestingpracticesandproblems.In2014IEEE25thInternational
SymposiumonSoftwareReliabilityEngineering.IEEE,201–211.
[30] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018.BERT:Pre-trainingofDeepBidirectional
TransformersforLanguageUnderstanding.arXivpreprintarXiv:1810.04805(2018).
[31] SindhuDevunooru,AbeerAlsadoon,PWCChandana,andAzamBeg.2021.Deeplearningneuralnetworksformedical
imagesegmentationofbraintumoursfordiagnosis:arecentreviewandtaxonomy.JournalofAmbientIntelligenceand
HumanizedComputing12,1(2021),455–483.
[32] GiovanniGrano,CristianDeIaco,FabioPalomba,andHaraldCGall.2020.Pizzaversuspinsa:Ontheperceptionand
measurabilityofunittestcodequality.In2020IEEEInternationalConferenceonSoftwareMaintenanceandEvolution
(ICSME).IEEE,336–347.
[33] JianminGuo,YuJiang,YueZhao,QuanChen,andJiaguangSun.2018. Dlfuzz:Differentialfuzzingtestingofdeep
learningsystems.InProceedingsofthe201826thACMJointMeetingonEuropeanSoftwareEngineeringConferenceand
SymposiumontheFoundationsofSoftwareEngineering.739–743.
[34] WeiweiGuo,XiaoweiLiu,SidaWang,HuijiGao,andBoLong.2020.DeText:ADeepNLPFrameworkforIntelligentText
Understanding. https://engineering.linkedin.com/blog/2020/open-sourcing-detext
[35] AbhishekGupta,AlaganAnpalagan,LingGuan,andAhmedShaharyarKhwaja.2021. Deeplearningforobject
detectionandsceneperceptioninself-drivingcars:Survey,challenges,andopenissues.Array10(2021),100057.
[36] AndrewFHayesandKlausKrippendorff.2007.Answeringthecallforastandardreliabilitymeasureforcodingdata.
Communicationmethodsandmeasures1,1(2007),77–89.
[37] NargizHumbatova,GunelJahangirova,GabrieleBavota,VincenzoRiccio,AndreaStocco,andPaoloTonella.2020.
Taxonomyofrealfaultsindeeplearningsystems.InProceedingsoftheACM/IEEE42ndInternationalConferenceon
SoftwareEngineering.1110–1121.
[38] MdJohirulIslam,GiangNguyen,RangeetPan,andHrideshRajan.2019.Acomprehensivestudyondeeplearningbug
characteristics.InProceedingsofthe201927thACMJointMeetingonEuropeanSoftwareEngineeringConferenceand
SymposiumontheFoundationsofSoftwareEngineering.510–520.
[39] MdJohirulIslam,RangeetPan,GiangNguyen,andHrideshRajan.2020.Repairingdeepneuralnetworks:Fixpatterns
andchallenges.In2020IEEE/ACM42ndInternationalConferenceonSoftwareEngineering(ICSE).IEEE,1135–1146.
[40] ISOIso.2017.iec/ieeeinternationalstandard-systemsandsoftwareengineering–vocabulary.ISO/IEC/IEEE24765:2017
(E)(2017).
[41] OskarJarczyk,BłażejGruszka,SzymonJaroszewicz,LeszekBukowski,andAdamWierzbicki.2014.Githubprojects.
qualityanalysisofopen-sourcesoftware.InSocialInformatics:6thInternationalConference,SocInfo2014,Barcelona,
Spain,November11-13,2014.Proceedings6.Springer,80–94.
[42] LiJia,HaoZhong,andLinpengHuang.2021.Theunittestqualityofdeeplearninglibraries:Amutationanalysis.In
2021IEEEInternationalConferenceonSoftwareMaintenanceandEvolution(ICSME).IEEE,47–57.
[43] LiJia,HaoZhong,XiaoyinWang,LinpengHuang,andZexuanLi.2022.HowDoInjectedBugsAffectDeepLearning?.
In2022IEEEInternationalConferenceonSoftwareAnalysis,EvolutionandReengineering(SANER).IEEE,793–804.
[44] YannLeCun,YoshuaBengio,andGeoffreyHinton.2015.Deeplearning.nature521,7553(2015),436–444.
[45] StephanLukasczyk,FlorianKroiß,andGordonFraser.2020.Automatedunittestgenerationforpython.InInternational
SymposiumonSearchBasedSoftwareEngineering.Springer,9–24.
[46] LeiMa,FelixJuefei-Xu,MinhuiXue,BoLi,LiLi,YangLiu,andJianjunZhao.2019.Deepct:Tomographiccombinatorial
testingfordeeplearningsystems.In2019IEEE26thInternationalConferenceonSoftwareAnalysis,Evolutionand
Reengineering(SANER).IEEE,614–618.
[47] LeiMa,FelixJuefei-Xu,FuyuanZhang,JiyuanSun,MinhuiXue,BoLi,ChunyangChen,TingSu,LiLi,YangLiu,etal.
2018.Deepgauge:Multi-granularitytestingcriteriafordeeplearningsystems.InProceedingsofthe33rdACM/IEEE
InternationalConferenceonAutomatedSoftwareEngineering.120–131.
,Vol.1,No.1,Article.Publicationdate:February2024.BeyondAccuracy:AnEmpiricalStudyonUnitTestinginOpen-sourceDeepLearningProjects 21
[48] HenryBMannandDonaldRWhitney.1947.Onatestofwhetheroneoftworandomvariablesisstochasticallylarger
thantheother.Theannalsofmathematicalstatistics(1947),50–60.
[49] NickMcClure.2017.TensorFlowmachinelearningcookbook.PACKTpublishingLtd.
[50] AudrisMockus,RoyTFielding,andJamesDHerbsleb.2002.Twocasestudiesofopensourcesoftwaredevelopment:
ApacheandMozilla.ACMTransactionsonSoftwareEngineeringandMethodology(TOSEM)11,3(2002),309–346.
[51] JojoMoolayil,JojoMoolayil,andSureshJohn.2019.LearnKerasfordeepneuralnetworks.Springer.
[52] MahdiNejadgholiandJinqiuYang.2019.Astudyoforacleapproximationsintestingdeeplearninglibraries.In2019
34thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering(ASE).IEEE,785–796.
[53] ChigozieNwankpa,WinifredIjomah,AnthonyGachagan,andStephenMarshall.2018.Activationfunctions:Compari-
sonoftrendsinpracticeandresearchfordeeplearning.arXivpreprintarXiv:1811.03378(2018).
[54] DanielSPark,WilliamChan,YuZhang,Chung-ChengChiu,BarretZoph,EkinDCubuk,andQuocVLe.2019.
Specaugment:Asimpledataaugmentationmethodforautomaticspeechrecognition.arXivpreprintarXiv:1904.08779
(2019).
[55] KexinPei,YinzhiCao,JunfengYang,andSumanJana.2017.Deepxplore:Automatedwhiteboxtestingofdeeplearning
systems.Inproceedingsofthe26thSymposiumonOperatingSystemsPrinciples.1–18.
[56] VincenzoRiccio,GunelJahangirova,AndreaStocco,NargizHumbatova,MichaelWeiss,andPaoloTonella.2020.
Testingmachinelearningbasedsystems:asystematicmapping.EmpiricalSoftwareEngineering25,6(2020),5193–5254.
[57] VincenzoRiccioandPaoloTonella.2020.Model-basedexplorationofthefrontierofbehavioursfordeeplearningsystem
testing.InProceedingsofthe28thACMJointMeetingonEuropeanSoftwareEngineeringConferenceandSymposiumon
theFoundationsofSoftwareEngineering.876–888.
[58] DavidSculley,GaryHolt,DanielGolovin,EugeneDavydov,ToddPhillips,DietmarEbner,VinayChaudhary,and
MichaelYoung.2014.Machinelearning:Thehighinterestcreditcardoftechnicaldebt.(2014).
[59] DavidSculley,GaryHolt,DanielGolovin,EugeneDavydov,ToddPhillips,DietmarEbner,VinayChaudhary,Michael
Young,Jean-FrancoisCrespo,andDanDennison.2015.Hiddentechnicaldebtinmachinelearningsystems.Advances
inneuralinformationprocessingsystems28(2015),2503–2511.
[60] JasmineSekhonandCodyFleming.2019. Towardsimprovedtestingfordeeplearning.In2019IEEE/ACM41st
InternationalConferenceonSoftwareEngineering:NewIdeasandEmergingResults(ICSE-NIER).IEEE,85–88.
[61] SinaShamshiri,RenéJust,JoséMiguelRojas,GordonFraser,PhilMcMinn,andAndreaArcuri.2015.Doautomatically
generatedunittestsfindrealfaults?anempiricalstudyofeffectivenessandchallenges(t).In201530thIEEE/ACM
InternationalConferenceonAutomatedSoftwareEngineering(ASE).IEEE,201–211.
[62] AliShatnawi,GhadeerAl-Bdour,RaffiAl-Qurran,andMahmoudAl-Ayyoub.2018. Acomparativestudyofopen
sourcedeeplearningframeworks.In20189thinternationalconferenceoninformationandcommunicationsystems(icics).
IEEE,72–77.
[63] QunyingSong,MarkusBorg,EmelieEngström,HåkanArdö,andSergioRico.2022.ExploringMLtestinginpractice–
LessonslearnedfromaninteractiverapidreviewwithAxisCommunications.arXivpreprintarXiv:2203.16225(2022).
[64] StephenMStigler.1989.FrancisGalton’saccountoftheinventionofcorrelation.Statist.Sci.(1989),73–79.
[65] YouchengSun,XiaoweiHuang,DanielKroening,JamesSharp,MatthewHill,andRobAshmore.2018.Testingdeep
neuralnetworks.arXivpreprintarXiv:1803.04792(2018).
[66] SureshThummalapenta,MadhuriRMarri,TaoXie,NikolaiTillmann,andJonathandeHalleux.2011.Retrofittingunit
testsforparameterizedunittesting.InInternationalConferenceonFundamentalApproachestoSoftwareEngineering.
Springer,294–309.
[67] YuchiTian,KexinPei,SumanJana,andBaishakhiRay.2018.Deeptest:Automatedtestingofdeep-neural-network-
drivenautonomouscars.InProceedingsofthe40thinternationalconferenceonsoftwareengineering.303–314.
[68] FabianTrautsch.2019.AnAnalysisoftheDifferencesbetweenUnitandIntegrationTests.Ph.D.Dissertation.Nieder-
sächsischeStaats-undUniversitätsbibliothekGöttingen.
[69] FabianTrautschandJensGrabowski.2017.Arethereanyunittests?anempiricalstudyonunittestinginopensource
pythonprojects.In2017IEEEInternationalConferenceonSoftwareTesting,VerificationandValidation(ICST).IEEE,
207–218.
[70] FabianTrautsch,SteffenHerbold,andJensGrabowski.2020.Areunitandintegrationtestdefinitionsstillvalidfor
modernJavaprojects?Anempiricalstudyonopen-sourceprojects.JournalofSystemsandSoftware159(2020),110421.
[71] JasonTsay,LauraDabbish,andJamesHerbsleb.2014.Influenceofsocialandtechnicalfactorsforevaluatingcontribution
inGitHub.InProceedingsofthe36thinternationalconferenceonSoftwareengineering.356–366.
[72] TongjieWang,YaroslavGolubev,OlegSmirnov,JiaweiLi,TimofeyBryksin,andIftekharAhmed.2021.PyNose:A
TestSmellDetectorForPython.In202136thIEEE/ACMInternationalConferenceonAutomatedSoftwareEngineering
(ASE).IEEE,593–605.
[73] MinYan,LiWang,andAiguoFei.2019.ARTDL:Adaptiverandomtestingfordeeplearningsystems.IEEEAccess8
(2019),3055–3064.
,Vol.1,No.1,Article.Publicationdate:February2024.22 HanWang,SijiaYu,ChunyangChen,BurakTurhan,andXiaodongZhu
[74] ZhouYang,ChenyuWang,JiekeShi,ThongHoang,PavneetKochhar,QinghuaLu,ZhenchangXing,andDavidLo.
2023. WhatDoUsersAskinOpen-SourceAIRepositories?AnEmpiricalStudyofGitHubIssues. arXivpreprint
arXiv:2303.09795(2023).
[75] ZhuoYao,DaliWang,JinyuanSun,andDongZhong.2017.AUnitTestingFrameworkforScientificLegacyCode.In
2017InternationalConferenceonComputationalScienceandComputationalIntelligence(CSCI).IEEE,940–944.
[76] HaoYu,YilingLou,KeSun,DezhiRan,TaoXie,DanHao,YingLi,GeLi,andQianxiangWang.2022. Automated
AssertionGenerationviaInformationRetrievalandItsIntegrationwithDeepLearning.ICSE.
[77] JerroldHZar.1999.Biostatisticalanalysis.PearsonEducationIndia.
[78] JieMZhang,MarkHarman,LeiMa,andYangLiu.2020.Machinelearningtesting:Survey,landscapesandhorizons.
IEEETransactionsonSoftwareEngineering(2020).
[79] Min-LingZhangandZhi-HuaZhou.2013.Areviewonmulti-labellearningalgorithms.IEEEtransactionsonknowledge
anddataengineering26,8(2013),1819–1837.
[80] XufanZhang,YilinYang,YangFeng,andZhenyuChen.2019.Softwareengineeringpracticeinthedevelopmentof
deeplearningapplications.arXivpreprintarXiv:1910.03156(2019).
[81] YuhaoZhang,YifanChen,Shing-ChiCheung,YingfeiXiong,andLuZhang.2018.AnempiricalstudyonTensorFlow
programbugs.InProceedingsofthe27thACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis.
129–140.
,Vol.1,No.1,Article.Publicationdate:February2024.