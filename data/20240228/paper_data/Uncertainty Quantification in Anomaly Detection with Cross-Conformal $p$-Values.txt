Uncertainty Quantification in Anomaly Detection
with Cross-Conformal p-Values
OliverHennho¨fer1 ChristinePreisach2
Abstract andwiderindustry,withcriticalapplicationsinfrauddetec-
tion(Hilaletal.,2022),cybersecurity(Evangelou&Adams,
Giventhegrowingsignificanceofreliable,trust-
2020),predictivemaintenance(Carrascoetal.,2021)and
worthy, and explainable machine learning, the
healthcare(Fernandoetal.,2021),amongothers. Despite
requirement of uncertainty quantification for
thegeneralinterestandimportanceformanyindustryap-
anomalydetectionsystemshasbecomeincreas-
plications,thenecessityofuncertaintyquantificationinthis
inglyimportant. Inthiscontext,effectivelycon-
contexthasonlyrecentlybeenrecognized,withtheemer-
trollingTypeIerrorrates(α)withoutcompromis-
genceofreliable(Smuha,2019),trustworthy(Chenetal.,
ingthestatisticalpower(1−β)ofthesesystems
2022),andexplainablemachinelearning(Belle&Papanto-
can build trust and reduce costs related to false
nis,2021).
discoveries, particularly when follow-up proce-
dures are expensive. Leveraging the principles In this work, we primarily focus on the unsupervised ap-
ofconformalpredictionemergesasapromising proachofone-class-classification(Petsche&Gluck,1994;
approachforprovidingrespectivestatisticalguar- Japkowiczetal.,1999;Tax,2001)foranomalydetection
anteesbycalibratingamodel’suncertainty. —inthe sensethatonlynon-anomalous observationsare
This work introduces a novel framework for usedtotrainananomalydetectionmodel. Thisapproach
anomaly detection, termed cross-conformal isparticularlysuitablewhenarepresentativesetofanoma-
anomaly detection, building upon well-known lousobservationsisnotavailable,astobeexpectedinmost
cross-conformal methods designed for predic- anomalydetectionsettings.
tion tasks. With that, it addresses a natu-
Oneproblemmostalgorithmscommonlyusedforone-class-
ral research gap by extending previous works
classificationshare,isthattheydonotcomewithstatistical
in the context of inductive conformal anomaly
guaranteesregardingtheiranomalyestimates. Withthat,an
detection, relying on the split-conformal ap-
estimator’suncertaintyandresultingerrorprobabilitiescan
proach for model calibration. Drawing on in-
notbequantified,underminingitstrustworthiness.
sightsfromconformalprediction,wedemonstrate
Conformalanomalydetectioncanaddressthisproblemby
that the derived methods for calculating cross-
leveragingthenon-parametricandmodel-agnosticframe-
conformalp-valuesstrikeapracticalcompromise
workprovidedbyconformalprediction(Papadopoulosetal.,
between statistical efficiency (full-conformal)
2002;Vovketal.,2005;Lei&Wasserman,2013),which
and computational efficiency (split-conformal)
hasrecentlygainedrenewedattentionasareliableapproach
foruncertainty-quantifiedanomalydetectionon
touncertaintyquantification. Asshowninprecedingworks,
benchmarkdatasets.
correspondingconformalizedmethodsforpredictiontasks
caninprinciplebeadaptedfortheapplicationinanomaly
detectionwithoutcompromisingthestatisticalvalidityof
1.Introduction
theunderlyingconcept(Laxhammar&Falkman,2010;Lax-
hammar,2014).
Thefieldofanomalydetection,alsoreferredtoasnovelty
detection,hasbeensteadilygaininginterestinboththesci- Conformalpredictionwasoriginallyproposedtoallowfor
entificcommunity(Pimenteletal.,2014;Pangetal.,2021) distribution-free uncertainty quantification for regression
tasks (using prediction intervals) and classification tasks
1Institute of Applied Research (IAF), Karlsruhe University
(usingpredictionsets)thatguaranteesa1−αcoverageof
ofAppliedSciences,Karlsruhe,Germany2FacultyofComputer
ScienceandBusinessInformationSystems(IWI),KarlsruheUni- thetruevalueorclassgivenasignificancelevelα. Guaran-
versityofAppliedSciences,Karlsruhe,Germany.Correspondence teesbyconformalmethodsholdwhentrainingandtestdata
to:OliverHennho¨fer<oliver.hennhoefer@h-ka.de>. aresaidtobeexchangeable. Exchangeabilityisastatistical
term,closelyrelatedbutweakerthantheassumptionofin-
1
4202
beF
62
]LM.tats[
1v88361.2042:viXraUncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
dependentandidenticallydistributedvariables(i.i.d.). anomalydetectionandotherareasarisesfromthelackof
Inoneofthemostbasicapproachesofconformalpredic- non-parametric models, often subject to a priori assump-
tion, the so-called (non-)conformity scores (e.g. residual tions,andtheabundanceofparameter-ladenalgorithms—
values,classprobabilityscores,...) obtainedbyascoring bothpronetoeithermisspecificationoroverfitting(Keogh
function(anestimator)arecalibratedonahold-outset,sep- et al., 2007). Beyond that, critical (hyper-)parameters
aratedfromthetrainingdata,providingameanstoassess likeanomalythresholdsandresultingfalsediscoveryrates
themodel’sconfidenceinitspredictionsobjectively. This (FDR)oftendecidewhethertheanomalydetectionsystem
approachissaidtobesplit-conformal,otherwiseknownas athandisdeemedpracticalornot.
inductiveconformalprediction.
Contributions. Withinthegivencontext,themaincontri-
Inthisworkwefocusoncross-conformalmethods,which butionsofthisworkmaybesummarizedasfollows:
representa“hybridofthemethodsofinductiveconformal
predictionandcross-validation”(Vovk,2013a). Withthat, • Proposal of a novel cross-conformal framework for
cross-conformalmethodsaddressnotoriousproblemslike
anomalydetection,basedoncross-conformalpredic-
overfitting and estimator instability (Andrews, 1986) due tion,offeringreliable(marginal)FDR-controlwhile
to data variability. Respective methods also make more
yielding more powerful anomaly detectors than the
efficientuseofavailabletrainingdata,sincethededicated
inductiveconformalapproachofrelatedworks.
holdoutsetoftheinductiveapproachbecomesdispensable.
Cross-conformalmethodsmayparticularlybeinteresting • Derivation of five cross-conformal anomaly detec-
whenworkingwithsmallertrainingdatasets(n≪10.000). tion methods in analogy to their existing counter-
parts for conformal prediction, namely Jackknife
AD
and Jackknife+ , CV and CV+ and the
AD AD AD
Jackknife+-after-Bootstrap .
AD
• Empiricalevaluationtestifyingoverallsuperiorstatis-
ticalpower(sensitivity)ofcross-conformaldetectors,
withoutbreakingthe(marginal)FDR-controlatgiven
nominallevelsbytheBenjamini-Hochbergprocedure.
2.RelatedWork
Beyondtheseminalworksregardingconformalinference
(Gammermanetal.,1998;Papadopoulosetal.,2002;Vovk
etal.,2005;Lei&Wasserman,2013)thetermconformal
anomalydetectionwasfirstintroducedin(Laxhammar&
Falkman,2010)andlaterrevisitedandextendedin(Bates
etal.,2023),amongothers.
In(Laxhammar&Falkman,2010;Laxhammar,2014)con-
formalanomalydetectionwasinitiallyappliedfordetecting
anomaloustrajectoriesinmaritimesurveillanceapplications.
Bothworksformalizedanddiscussedtheprinciplesofcon-
Figure1.Non-exhaustivetaxonomyofconformalinferencewith
conformalpredictionandthederivedconformalanomalydetection formalpredictionappliedtoananomalydetectiontask. As
includingthecurrentresearchgapofcross-conformalanomaly partof(Laxhammar,2014),conformalanomalydetection1
detectionbasedoncross-conformalprediction. andinductiveconformalanomalydetectionwereproposed
without further assessing strategies beyond the inductive
procedure.
Themajorityof(cross-)conformalpredictionmethodscan Other works relying on the application of conformal
beadaptedfortheapplicationwithinthefieldofanomalyde-
1In(Laxhammar,2014)thetermconformalanomalydetection
tectionwhilemaintainingstatisticalvalidity,aswedemon-
directlyreferstotheanalogoustermoftransductiveconformal
strate in this work. The lack of respective mathematical
prediction(Vovk,2013b),otherwiseknownasfull-conformalpre-
formulationsandpracticaldemonstrations,particularlyfor diction(compareFigure1). Fullconformityisanimportantthe-
cross-conformalanomalydetectors,representsanaturalre- oreticalconceptinthefieldofconformalinferenceandthemost
searchgap(seeFigure1). statisticallyefficientofallapproaches.Itdoesnotrequireadedi-
catedcalibrationsetbutthefittingofmanymodelsatruntimefor
The general necessity of conformalized methods for inference,makingitimpracticalformostreal-worldapplications.
2UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
anomaly detection or related (conformal) concepts are n−m≥1000isdeemedtobesufficientformostapplica-
(Smithetal.,2015;Guan&Tibshirani,2022;Haroushetal., tions(Angelopoulos&Bates,2021).
2022)complementedby(Fedorovaetal.,2012;Ishimtsev Forinference,thecalibratedscoringfunctionthenassigns
etal.,2017;Cai&Koutsoukos,2020;Vovk,2020;2021; ascoresˆ(x),asascalarestimateforanomalousness,toan
Vovketal.,2021),specificallydedicatedtoonlinesettings. unseenx∈D . Inthiswork,smallerscoressˆ(x)indicate
test
Noneoftheseworksexplicitlyreferredtoorassessedvari- thatxmightbeananomaly2. Theobtainedscoresˆ(x)is
antsofcross-conformalanomalydetection. thencomparedtothecalibrationset.
Withthat,the(split-)conformalp-valuesofanynewobser-
Cross-conformalmethods,tobeadaptedfortheapplication
vationxiscomputedby
in anomaly detection, are namely Jackknife (Steinberger
&Leeb,2016;2023),Jackknife+,CV,CV+(Vovk,2013a;
|{i∈D : sˆ(X )≤sˆ(x)}|+1
Barberetal.,2021)andJackknife+-after-Bootstrap(Kim p(x)= cal i (1)
|D |+1
et al., 2020). All of these methods were derived in the cal
contextofcross-conformalprediction.
Theoverarchingframework,andthederivedmethods,are withappliedadditivelysmoothingadjustmentfunction
model-agnostic,soitisgenerallypossibletoconformalize
anygivenanomalydetectorthatoutputssuitableanomaly nx+1
p(x)= (2)
scores (see Section 3). Most well-known methods for n+1
anomalydetection(Aggarwal,2013;Agrawal&Agrawal,
2015)adheretothisrequirement.
toensurethesuperuniformnatureofcomputedp-values,as
3.Background discussedinthefollowing(seeMarginallySuperuniform
Conformalp-Values).
First, we briefly examine the widely applied and already
The provided equation computes the conformal p-value
well-describedsplit-conformalapproachforcomputingcon-
as the probability of observing a test score sˆ(x) as ex-
formalp-valuesinthecontextofanomalydetection—syn-
treme as or more extreme than the entire calibration set
onymouswithinductiveconformalanomalydetection(Lax-
of sˆ(X ) for all X ∈ D . Given a defined level of
hammar&Falkman,2010;Laxhammar,2014).Establishing i i cal
significance α = 0.05, a score outside the quantile range
thefundamentalswillserveasastartingpointforderiving
Q assˆ(x)≤Q [sˆ(X )]wouldbeconsideredstatistically
thecross-conformalmethodsinSection4. α α i
significantandlabeledasananomaly.
Weconsiderananomalydetectiontaskgivenasetofobser- Consequently, for anomaly scores that would increase
vationsD ={x 1,x 2,...,x n}={X i}n i=1usedfortraining, with the estimated anomalousness (i.e. reconstruc-
comprisingnobservationsX i ∈Rdinad-dimensionalfea- tion errors, Mahalanobis distances, ...), the test scores
turespace,sampledfromanunknowncontinuous,discrete, sˆ(x)≥Q [sˆ(X )]wouldbeconsideredstatisticallysig-
1−α i
ormixeddistributionP X consideredtobenon-anomalous. nificantandlabeledasananomaly,respectively.
Weaimtotestanunseen(non-empty)setofobservations
D = {x ,x ,...,x } = {X }ntest assumedto For comparison, a non-conformal (na¨ıve) alternative ap-
test n+1 n+2 ntest n+i i=1 proach might be to solely rely on scores as observed on
besampledfromP forpotentialanomalies.
X
thetrainingdataitself. Thisprocedurewouldmostlikely
Inthiscontext,anomaliesmaybecharacterizedaseitherun-
underestimatethescoresobtainedonnewlyobserved(non-
usual(seenoveltydetection)orout-of-distribution,arising
anomalous)dataandresultinanincreasedFDR.
fromadistinctunderlyingdata-generatingprocess.
MarginallySuperuniformConformalp-Values.Theinduc-
Inductive Conformal Anomaly Detection. Initially, an
anomaly scoring function sˆ : Rd → R is fitted on tiveconformalinferenceprocedure,asdescribedpreviously,
calculatesmarginallysuper-uniform(conservative)p-values
D ⊂DandsubsequentlycalibratedonD ⊂Dwhich
train cal
p (x). The same applies in principle to p-values ob-
is disjoint from D with D ∩D = ∅. Depending (marg)
train cal train
tainedbythelaterdescribedcross-conformalmethods.With
onthenumberofobservationsmassignedtothetraining
that,thep-valuesaresuper-uniformlydistributedwhenthere
set D with m < n, the scoring function sˆis fitted on
train
is no true effect (H is true), which is a desired property
D ={x ,x ,...,x }={X }m byasuitableanomaly 0
train 1 2 m i i=1
detectionalgorithmAassˆ=A(X i)forallX i ∈D train. 2Insklearn,IsolationForestcomputeslowerscoreswhena
Subsequently, sˆ is calibrated on the remaining observa- pointiseasiertoisolate,indicatingananomaly. Forthedensity-
tions in the hold-out set D = {x ,x ,...,x } = based Local Outlier Factor, lower densities indicate a point’s
cal m+1 m+2 n
{X }n by computing the calibration set as sˆ(X ) isolation,resultinginalowerscore.One-ClassSVMreportscores
m+i i=1 i based on a point’s distance to the decision boundary. A lower
for all X ∈ D . In practice, a calibration set of size
i cal (negative)scoreindicatesapotentialanomaly.
3UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
for being able to control the false positive rate reliably3. Benjamini-Hochberg procedure, known to be robust to
Consequently,computedconformalp-valuessatisfy PRDS, effectively controls the (marginal) FDR. This is
importanttonote,sincethemutualdependenceofobtained
p-valuesonD mayinvalidatecertainmultiplicityadjust-
P [p (x)≤t]≤t (3) cal
H0 (marg) ments(Batesetal.,2023).
Multipletestingapproachesanderrorcontrolcanbesensible
whenthenumberofconductedtestsforpotentialanomalies
foranynon-anomalousxdrawnfromP(X),witht∈[0,1], islargeandcontrollingtheFDRisrequired. Thiscanbethe
as implied by (1). This applies as p (marg)(X) becomes casewhenactionstakenuponthepresumeddiscoveryofa
uniformon{ 1 , 2 ,...,1}(compareEquation2)when significantobservationarecostlyorotherwisecritical.
n+1 n+1
sˆ(X)followsacontinuousdistribution.
Calibration-Conformalp-Values
However, sincethisdoesnotnecessarilyholdinpractice,
resultingp-valuesareconsideredtobemarginallyvalidbe- Forhighlycriticalapplications,suchasclinicaltrials,the
causeoftheirdependenceonobservationsinD cal,withD cal marginal guarantees provided by marginal conformal p-
andxbeingrandom. WithD =D train∪D test,thiscondition valuesandresultingmarginalFDR-controlmightnotsuffice.
canleadtop (marg)(x)becominganti-conservative(smaller Althoughtheevaluationofcalibration-conformalp-values
thantheyshouldbe)becauseofrandomfluctuationsinthe is out of the scope of this paper, we want to mention the
scoresofD cal duetounluckysplits. Thisresultsinthep- possibilityofcomputingthiskindofp-values,asdescribed
values only being valid on average when observations in in(Batesetal.,2023). Respectivep-valuesprovidestronger
D calareconsideredtoberandom. Type I error guarantees by controlling the stricter family-
wiseerrorrate(FWER)asdefinedbytheprobabilityofany
Itshouldbenotedthat,forhighlycriticalapplications,the
TypeIerrorsatall(Tukey,1953).
resultingguaranteesregardingthecontroloffalsepositives
Giventheevaluationresults,aspresentedinthispaper,valid
maybetooweakandareadirectconsequenceofrelying
(and more powerful) calibration-conformal p-values may
on D . Beyond this constraint, the conformal inference
cal
alsobeobtainedbyourproposedcross-conformalmethods,
procedurecomeswiththelimitationthatobtainedp-values
can never be < 1 . This circumstance prevents highly althoughthishastobeempiricallydemonstratedaspartof
n+1 futureworks.
confidentestimatesforsmallsetsofdata.
Multiple Testing and Benjamini-Hochberg Procedure.
4.Cross-ConformalAnomalyDetection
Controllingthenumberoffalsediscoveries(falsepositives),
whenworkingwithp-values,necessarilyrequirestheadop- Cross-conformalanomalydetectorsarebasedontheideaof
tion of a multiple testing perspective (Tukey, 1953). The cross-conformalpredictors(Vovk,2013a)thatinturnextend
problem of multiple testing applies when p-values fail to thesplit-conformalapproachofinductiveconformalpredic-
provideaninformativequantificationinthecontextoflarge tionbycross-validation(CV)andleave-one-out-validation
numbersoftestsperformedsimultaneously. Inthesecases, (LOOV)schemes.Withoutadedicatedcalibrationset,cross-
the probability of obtaining false positives inevitably in- conformalapproachesmakemoreefficientuseofavailable
creaseswithoutadditionalposthocadjustments. Thefalse trainingdata,whichmaybedifficultorexpensivetoobtain
discoveryrate(FDR)helpstocontrolTypeIerrorsbymea- in certain contexts. Beyond that, resulting anomaly esti-
suringtheproportionof(significant)discoveries(rejecting matorsarelesspronetounstableestimatesduetounlucky
H 0)thatareactually(non-significant)falsepositives. splitsregardingtrainingandcalibrationsetthatmaylead
Several methods exist that seek to control the FDR, with totheviolationofunderlyingassumptionsinpractice(see
theBenjamini-Hochbergprocedure(Benjamini&Hochberg, Section 3). With that, they have the potential to mitigate
1995)beingoneofthemoreadvancedandpopularmethods4.
implicationsbythedependenceonD .
cal
As demonstrated in (Bates et al., 2023), marginally con-
In the following, five well-known cross-conformal meth-
formalp-valuesdonotinvalidatetheBenjamini-Hochberg
ods for prediction are reformulated for the application in
procedureoninliers(H beingtrue),astheyareassumed
0
anomaly detection as so-called cross-conformal anomaly
to be positive regression dependent on a subset (PRDS)
detectors.
(Benjamini&Yekutieli,2001). PRDStranslatestoarather
restrictivepositivedependenceassumptionimplyingaposi-
tivecorrelationstructurewithinasubsetofvariables5. The 4.1.Jackknife AD
3Theconceptofsuper-uniformityisintroducedinAppendixB. ThetermJackknife(Quenouille,1949;1956;Tukey,1958)
4TheconceptofmultipletestingandtheBenjamini-Hochberg primarilydenotesastatisticalprocedureencompassinggen-
procedureisintroducedinAppendixC. eralresamplingtechniquesforestimatingbiasandvariance
5TheconceptofPRDSisintroducedinAppendixD.
4UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
ofa(statistical)estimator(Shao&Tu,1995). Incontrast, thecasewhenremovingasingleobservationX ∈ Dcan
i
thewell-knownleave-one-out-validation(LOOV)canbe significantlyinfluencethepredictedvaluesˆ(x).
viewedasaspecificimplementationoftheJackknifemethod
BothJ andJ+ becomecomputationallyprohibitivefor
formodelevaluationinmachinelearning. AD AD
largedatasets.
The Jackknife (J ), analogously described in (Barber
AD AD
etal.,2021;Steinberger&Leeb,2016;2023)forpredictive
4.3.CV
tasks,gathersasetofncalibrationscoresbynleave-one- AD
outscoringfunctionssˆ −iforallobservationsX i ∈Das TheJ ADmethodcanbeseenasaspecialcaseoftheCV AD
method that relies on k-fold cross-validation, instead of
sˆ :=A(x ,...,x ,x ,...,x ). leave-one-out-validation,tocomputeacalibrationset.
−i 1 i−1 i+1 n
ForCV ,theobservationsX ∈Daresplitintokdisjoint
AD i
subsets S 1,S 2,...S k, each of size l = n/k. With that, k
scoringfunctions
Scores for unseen observations sˆ(x) are calculated by a
single classifier sˆ eventually trained on all X ∈ D as
i
sˆ=A(x 1,...,x n)=A(D) and compared to the set of n sˆ −Sk :=sˆ(x h : h∈{1,2,...,n}\S k)
leave-one-outcalibrationscoressˆ (X )as
−i i
p(x)=
|{sˆ −i(X i)≤sˆ(x)}|+1
. (4)
arefittedonX i ∈ D withobservationsofthekth foldS k
removed. LikeforJ ,everyxiseventuallyscoredbyan
n+1 AD
estimatorsˆ,fittedonallX ∈D,as
i
|{sˆ (S )≤sˆ(x)}|+1
Likethesplit-conformalapproach(seeSection3)andthe p(x)= −Sk k . (6)
n+1
cross-conformalmethodsintroducedinthefollowing,the
J computes(cross-)conformalp-valuesastheprobability
AD
ofobservingatestscoresˆ(x)asextremeasormoreextreme
4.4.CV+
thantheentirecalibrationsetofsˆ (X )forallX ∈D. AD
−i i i
AswithJackknifeandJackknife+,theCV+(Barberetal.,
4.2.Jackknife+ 2021)extendstheideaofCVbyadditionallyretainingeach
AD
fitted(in-fold)estimatorforeventualinferenceonx.
In contrast to the standard Jackknife, that calculates sˆ(x)
Analogous to the procedure for CV , the p-value for
AD
with sˆfitted on all X ∈ D observations, the Jackknife+
i an unseen observation is calculated as the median value
(Barberetal.,2021)retainseachfittedleave-one-outscoring
Median({sˆ (x)})oftheestimatesforxobtainedfrom
function sˆ for eventual inference on x. By taking the
−Sk
−i eachfittedandretained(in-fold)estimatorsˆ thatgets
medianestimateMedian({sˆ (x)})as
−Sk
−i comparedtotheout-of-foldcalibrationvaluesinthecalibra-
tionsetsˆ (S )as
−Sk k
Median(sˆ (x),sˆ (x),...,sˆ (x))
−1 −2 −n
|{sˆ (S )≤Median({sˆ (x)})}|+1
p(x)= −Sk k −Sk . (7)
n+1
ofthesetofleave-one-outestimates,thep-valueiscalcu-
latedbytheJackknife+ (J+ )as
AD AD
4.5.Jackknife+-after-Bootstrap
AD
|{sˆ (X )≤Median({sˆ (x)})}|+1
p(x)= −i i −i . (5) The Jackknife+-after-Bootstrap (Kim et al., 2020) is
n+1
based on the idea of Jackknife-after-bootstrap (Efron,
1992) following a bootstrapping approach. The derived
Jackknife+-after-Bootstrap (J+aB )providesforresam-
AD AD
The J+ AD is an extension of J AD and gives a more stable plingwithreplacementofX i ∈Dtoobtainbnon-disjoint
estimatebyaccountingforthevariabilityofthefittedsˆ −i, bootstrapsB 1,B 2,...,B
b
ofequalsize,leavingacomple-
dependingonD. mentingsetofout-of-bagobservations−B ,−B ,...,−B ,
1 2 b
In case all fitted sˆ −i would resemble sˆ, the obtained esti- respectively. Withthat,bscoringfunctions
mateswillbesimilartotheonesofJ .However,insettings
AD
wheretheestimatorishighlysensitivetocertainsubsetsof sˆ :=sˆ(x : g ∈{1,2,...,n}\−B ) (8)
Dtheresultingoutputcanvaryconsiderably. Thismaybe
Bb g b
5UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
arefittedonX ∈DwithobservationsofbthbootstrapB . IsolationForest,datasetswithatleastacertainnumberof
i b
globaloutliersweretypicallyconsideredforevaluation.
Forcalibration,thescoresarecomputedontheout-of-bag
sets−B thatcomplementthebootstrapsusedfortrain-
b(g)
5.2.Setup
ing. Thein-bagestimatessˆ (x)areaggregatedandcom-
Bb
paredtotheout-of-bagcalibrationsetsˆ Bb(−B b)as Following the general setup as described in (Bates et al.,
2023),wecreatedJ distinctdatasetsD ,...,D withj ∈J,
1 j
comprisingexclusivelyobservationsofinliers. Eachdataset
|{sˆ (−B )≤Agg.({sˆ (x)})}|+1
p(x)= Bb b Bb . (9) D j representsanindependentsetofdatafortrainingand
b×|−B |+1
b calibration. EachD comeswithLtestsetsDtest,...,Dtest
j j,1 j,l
withl ∈L. WhileD isfixedregardingitsrespectivetest
j
sets,thetestsetsthemselvesaredrawnrandomlyandarenot
AsforJ+ andCV+ ,thebfittedandretainedestimators necessarilydisjointfromeachother. Withthat,eachDtest
AD AD j,l
sˆ areusedforinferencewiththeirestimatesbeingaggre- representsthetestsetforatrainingsetD underscenariol.
Bb j
gatedintoasinglescore. Followingtheoriginalpaper,any Fortheevaluation,weareinterestedintheFDRconditional
aggregationfunction(Agg.)maybeused—typicallythe onD definedastheexpectationvalue
j
mean,median,ortrimmedmean(Kimetal.,2020).
Naturally, the J+aB AD may be parameterized more freely cFDR(D j):=E(cid:2) FDP(cid:0) Dtest;D j(cid:1) |D j(cid:3) , (10)
regarding the size of the resulting calibration set by the
numberofcreatedbootstraps(b)andtheirsize(|B |).
b
with FDP(Dtest;D ) as the false discovery proportion of
j
5.Evaluation inliersinthetestsetthatwasincorrectlyreportedasoutliers.
The results for any given j ∈ J will be evaluated by the
In this section, we compare the derived cross-conformal
FDR
methodswiththesplit-conformalapproachtoassesstheir
effectivenessinprovidingvaliduncertaintyquantification L
andoverallsensitivityacrossarangeofbenchmarkdatasets. cFD(cid:92) R(D ):= 1 (cid:88) FDP(cid:0) Dtest;D (cid:1) (11)
j L j,l j
InourevaluationweexemplarilyappliedIsolationForest l=1
(Liuetal.,2008)withitsdefaultparametersasimplemented
bythePythonpackagesklearn(Pedregosaetal.,2011).
andthestatisticalpower
WeomittedJ+aB forthefinalevaluationsincethemethod
AD
hasmoredegreesoffreedomregardingitsparameters,as L
previously mentioned. With that, it’s difficult to strike a cPo(cid:92) wer(D j):= L1 (cid:88) Power(cid:0) D jte ,s lt;D j(cid:1) (12)
fairbalancewiththeothermethodsthatbydefinitionyield l=1
calibrationsetsizesofn(|D|)each. Nonetheless,thecore
principleofallcross-conformalmethodsremainsthesame
sothatprovidedinsightsingeneralalsoapplytoJ+aB . wherePower(Dtest;D )isdefinedastheproportionoftotal
AD j,l j
outliersinDtestcorrectlyidentifiedasoutliers. Ourexperi-
j,l
5.1.Data mentsdemonstratethatthemarginalFDRasmF(cid:92) DR(D )=
j
Derivedmethods,andthesplit-conformalapproachforref- J1 (cid:80)J j=1c(cid:92) FDR(D j)iscontrolled.
erence,wereappliedtotenbenchmarkdatasetsasfoundin
Withthiscombinationofevaluationmeasures,wecoverthe
ADBench(Hanetal.,2022)—acollectionofbenchmark
two errors that may typically occur during the classifica-
datasetsforanomalydetection. Theutilizeddatasetsaimed
tionofanobservationinthecontextofanomalydetection.
toencompassadiverserangeofdataintermsof(i)size,(ii)
Anormalobservation(inlier)caneitherincorrectlybela-
dimensionality,and(iii)classimbalance. Additionally,the
beled as an anomaly (a false alarm) or an anomaly goes
overall suitability of the data for the application of Isola-
unrecognized(amisseddetection).
tionForest,asmeasuredbystatisticalpower,wastakeninto
account. Thiswasdonesincethegeneraleffectivenessof
5.3.ImplementationDetails
conformalmethods(foranomalydetectionandprediction)
stronglydependsontheoverallappropriatenessoftheesti- Fortrainingandcalibration,n /2observationswereused
Inlier
matorandthechoiceofthenon-conformitymeasure. With withn trainandn
cal
=min{2000,ntrain/2},followingthesplit
that,datasetsthatresultedinobservedstatisticalpowersof configurationin(Batesetal.,2023). Foreachoftheresult-
< 0.05 were categorically excluded. Given the nature of ingJ =100subsetsfortrainingandcalibration,L=100
6UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
Table1.Performanceofsplit-andcross-conformalanomalydetectionmethodsregardingtheirFDRatthenominallevelα=0.2ongiven
benchmarkdatasets. Split-andcross-conformalmethodsarereliablycontrolledbytheBenjamini-Hochbergprocedureinamarginal
sense.Beyondthemarginalcaseatthe90-thquantile(P ;lowerthanSplit-Conformal isbetter)oftheempiricalFDRdistribution,
90 AD
thecross-conformalmethodstendtogivelowervalueswithincreasingdatasetsizewhileshowingoveralllowervariability(σ).
FalseDiscoveryRate
Split-Conformal CV CV+ Jackknife Jackknife+
AD AD AD AD AD
x¯ P σ x¯ P σ x¯ P σ x¯ P σ x¯ P σ
90 90 90 90 90
WBC .128 .279 .146 .134 .295 .137 .127 .282 .135 .133 .284 .133 .133 .289 .132
Ionosph. .044 .087 .120 .093 .284 .139 .068 .204 .119 .103 .290 .133 .095 .269 .126
Breast .178 .312 .112 .181 .326 .102 .176 .322 .096 .178 .324 .096 .176 .318 .094
Cardio .160 .298 .098 .159 .290 .094 .154 .287 .088 .159 .293 .089 .140 .274 .087
Musk .116 .205 .117 .145 .288 .152 .050 .109 .065 .114 .200 .160 — — —
Thyroid .130 .230 .099 .143 .265 .112 .115 .199 .091 .134 .241 .115 — — —
Gamma .172 .243 .062 .163 .231 .061 .158 .226 .043 — — — — — —
Shuttle .175 .208 .025 .177 .210 .029 .174 .206 .010 — — — — — —
Mammo. .163 .248 .076 .169 .257 .072 .134 .218 .058 — — — — — —
Fraud .180 .223 .033 .179 .220 .016 .175 .216 .006 — — — — — —
test sets D jte ,s lt of size n
test
= min{2000,ntrain/3} were sam- beyondthemarginalcase—atleastforlargerdatasets.
pled,eachwith90%inliersand10%outliersthatmayover- While the FDR is reliably controlled marginally (x¯) for
lapbetweenthetestsetsduetothefinite(test)data. The everyevaluatedmethod,theabilitytocontroltheFDRof
FDRwascontrolledatthenominal(marginal)levelα=0.2 conformalmethodshastobenecessarilyseeninthecontext
bytheBenjamini-Hochbergprocedure. oftheobservedstatisticalpowersincelowFDRandhigh
statisticalpoweroftenrepresentatrade-offinpractice.
Forthefinalevaluation,thedatasetsweregroupedintosmall
(CV , CV+ and J , J+ ), medium (CV , CV+ Beyond the ability to reliably quantify the uncertainty of
AD AD AD AD AD AD
andJ )andlarge(CV andCV+ )datasetssinceJ obtainedanomalyestimates,theresultsinTable2indicate
AD AD AD AD
andJ+ becamecomputationallyprohibitivewithincreas- thatcross-conformaldetectorstendtooveralloutperform
AD
ingsizeofdata,givenavailablecomputingcapacities. split-conformaldetectorsregardingtheirstatisticalpower.
For the small (n ≤ 2,000) and medium datasets Theyseemtoparticularlyoutperformonsmallerdatasets,
(n≤10,000),thesizeofkforCV andCV+ wascho- astobeexpectedduetotheproportionallylargercalibration
AD AD
sen to create folds of the size of the calibration sets as setwithrespecttoavailabletrainingdata(seeSubsection
createdbythesplit-conformalreferenceprocedure. Forthe 5.3). Respectiveresultsforthelargerdatasetswithk =20,
largedatasets,CV andCV+ followedthevariantwith resultinginweakermodelstrainedwithfewerdata(butcali-
AD AD
k =20. bratedonmoredata)thanthesplit-conformalmethod,while
thesplit-conformalmethodispotentiallymoresensitiveto
Theexperimentsandrespectiveresultsmayexactlybere-
theperformedsplits. Thisisalsothereasonwhytheresults
producedbythecodeprovided(seeSoftwareandData).
forcross-conformalmethodsaremorestablemakingthem
moremanageableandreliableforcriticalapplications. It
6.Results isinterestingtonotethatJ andJ+ donotconsistently
AD AD
outperformCV andCV+ forsmalldatasets,although
The results presented in Table 1 confirm the findings de- AD AD
thereisacleartrendfavoringtheLOOapproaches.
scribedin(Batesetal.,2023), concerningtheefficacyof
FDRcontrolinsplit-conformalmethods,whichmayalso Withtheoverallevaluationsetupregardingparameteriza-
betransferredtoourderivedcross-conformalmethods. As tion (see Subsection 5.3) we tried to seek a compromise
all evaluated methods are reliably controlled marginally betweencomparabilityandpracticabilitybydistinguishing
(x¯ < 0.2), the results obtained by the cross-conformal betweensmall,medium,andlargedatasets. Anaturallimi-
methodsaregenerallymorestable,asindicatedbyalower tationofourevaluationistheinherentdifferencesbetween
standard deviation (σ), compared to those obtained by thecross-conformalmethodsandthesplit-conformalproce-
the split-conformal method. Within the group of cross- dure. Theincreasedcalibrationsetsizesofcross-conformal
conformalmethods,CV+ andJ+ exhibitsmallerFDR, methodsaffectobservedp-valuesthatinturnaffectthead-
AD AD
andsmaller(uncontrolled)FDRatthe90th-percentile(P ), justedp-valuesbytheBenjamini-Hochbergprocedure.With
90
7UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
Table2.Performanceofsplit-andcross-conformalanomalydetectionmethodsregardingtheirstatisticalpower(x¯andP ; higher
90
isbetter), andrespectivevariability(σ; lowerisbetter)asgivenbythestandarddeviation, ongivenbenchmarkdatasets. Overall,
cross-conformalmethodsoutperformwhenappliedtosmalldatasets,withthetendencytooutperformwhenappliedtomediumandlarge
datasets.Both,CV andCV+ aretrainedwithk=20onlargedatasets.Highervaluesfork(tendingtowardsJ andJ+ )may
AD AD AD AD
increaseperformancebutrepresentatrade-offbetweenstatisticalefficiencyandcomputationalefficiency.
StatisticalPower
Split-Conformal CV CV+ Jackknife Jackknife+
AD AD AD AD AD
x¯ P σ x¯ P σ x¯ P σ x¯ P σ x¯ P σ
90 90 90 90 90
WBC .315 .627 .315 .666 .913 .273 .641 .877 .295 .756 .970 .202 .760 .963 .203
Ionosph. .046 .105 .105 .089 .288 .093 .074 .237 .091 .152 .468 .130 .150 .518 .127
Breast .787 .960 .232 .852 .982 .176 .866 .994 .119 .878 .997 .101 .881 .999 .094
Cardio .285 .449 .141 .298 .450 .142 .297 .460 .114 .298 .455 .125 .273 .446 .093
Musk .259 .319 .344 .249 .320 .336 .195 .259 .300 .185 .227 .304 — — —
Thyroid .121 .179 .112 .130 .189 .125 .115 .176 .095 .114 .173 .108 — — —
Gamma .180 .231 .036 .180 .231 .022 .181 .229 .012 — — — — — —
Shuttle .981 .992 .002 .981 .992 .003 .982 .993 .001 — — — — — —
Mammo. .150 .187 .103 .135 .175 .078 .111 .149 .049 — — — — — —
Fraud .666 .721 .103 .677 .728 .062 .684 .733 .013 — — — — — —
that,cross-conformalmethodsallowforthecomputationof field of conformal anomaly detection. Cross-conformal
smallerp-values,potentiallyindicatinggreatercertaintyfor methodsareparticularlyhelpfulforanomalydetectiontasks
significantinstances(seeSection3). thatrequirethequantificationofanestimator’suncertainty
Furthermore, CV and CV+ are sensitive to their pa- in critical application contexts by an additional layer of
AD AD
rameterizationregardingk. Ingeneral,thesmallerthepro- safetyintheformofmodelcalibration. Respectivemeth-
portionofthefoldsize(s)tothetotaltrainingsize(i.e. the odsoveralloutperformthesplit-conformalapproachesthat
larger k), the better cross-conformal approaches perform. related works relied on in the past. By framing (batch-
Withthat,especiallyJ andJ+ havelimitedusecases wise) inference, in the context of anomaly detection, as
AD AD
thatareprimarilyrestrictedtoworkingwithsmalldatasets. a multiple testing problem, the marginal FDR of cross-
Nonetheless, computation time is an important factor to conformalanomalydetectorscanreliablybecontrolledby
be considered, although it is mostly a one-off cost at the theBenjamini-Hochbergprocedure,whiletypicallyexhibit-
modeltrainingstage. Amoreflexibleapproachmightbe inghigherstatisticalpowerandestimatorstability.
offeredbyJ+aBalthoughdifferentparameterizationsshould Duetotheinherentmodelagnosticismof(cross-)conformal
bethoroughlyevaluatedinfutureworks. methods, they may be easily integrated into existing
anomalydetectionsystemsofferinghighpracticability.Con-
In general, the effectiveness of all mentioned conformal
straints are mainly the increased need for computational
methods for anomaly detection (and beyond) highly de-
capacities,atleastatthemodeltrainingstage,andtheex-
pendsontheabilityoftheunderlyingestimator(s)andthe
changabilityassumption. Furthermore,sinceFDRcontrol
suitabilityofthechosenanomalymeasuretocapablysepa-
isinherentlytiedtotheadoptionofamultiple-testingper-
ratenormalfromanomalousinstances.
spective,thegeneralapproachdoesnotdirectlyapplytoan
Despite the findings, the inductive approach still offers a
onlineanomalydetectionsetting.
goodratioofcosttobenefit,demonstratingthesufficiency
Beyond that, conformal anomaly detection methods inte-
ofarathersmallamountofdatausedforcalibration,partic-
grateelegantlywithalgorithmslikeIsolationForest,among
ularlywhenavailabletrainingdatasetsarelarge. Thisgener-
others,thatrequirethedefinitionofathresholdvalue.
allyunderlinestheeffectivenessoftheunderlyingprinciples
ofconformalinference—atleastwhentheassumptionof Overall,theresultsprovidedinthisworkaffirmtheeffective-
exchangeabilityisnotviolatedinpractice. nessoftheoverarchingprinciplesofconformalinference
inawiderrangeofapplicationsbeyondconformalpredic-
tion. Insummary,thepresentedworkformallydefinedthe
7.Conclusion
fieldofcross-conformalanomalydetectioninanalogytothe
Asdemonstratedinthiswork,thederivedcross-conformal existingfieldofcross-conformalpredictionandrespective
methods represent a natural and effective addition to the cross-conformalmethods,closinganaturalresearchgap.
8UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
References November 2009. ISSN 1471-2962. doi: 10.1098/rsta.
2009.0127. URLhttp://dx.doi.org/10.1098/
Aggarwal,C.C. OutlierAnalysis. Springer,2013. ISBN
rsta.2009.0127. pp.4257–4259.
978-1-4614-6396-2.URLhttp://dx.doi.org/10.
1007/978-1-4614-6396-2. Blanchard, G. and Roquain, E. Two simple sufficient
Conditions for FDR Control. Electronic Journal of
Agrawal, S. and Agrawal, J. Survey on Anomaly De-
Statistics, 2, January 2008. ISSN 1935-7524. doi:
tectionusingDataMiningTechniques. ProcediaCom-
10.1214/08-ejs180. URLhttp://dx.doi.org/10.
puterScience,60:708–713,2015. ISSN1877-0509. doi:
1214/08-EJS180.
10.1016/j.procs.2015.08.220. URLhttp://dx.doi.
org/10.1016/j.procs.2015.08.220. Cai,F.andKoutsoukos,X. Real-timeOut-of-distribution
DetectioninLearning-enabledCyber-physicalSystems.
Andrews, D. W. K. Stability Comparison of Estima-
In 2020 ACM/IEEE 11th International Conference on
tors. Econometrica, 54(5):1207–1235, 1986. ISSN
Cyber-Physical Systems (ICCPS), pp. 174–183, 2020.
00129682, 14680262. URL http://www.jstor.
doi: 10.1109/ICCPS48487.2020.00024.
org/stable/1912329. p.1.
Carrasco, J., Lo´pez, D., Aguilera-Martos, I., Garc´ıa-
Angelopoulos, A. N. and Bates, S. A Gentle Introduc-
Gil, D., Markova, I., Garc´ıa-Barzana, M., Arias-Rodil,
tiontoConformalPredictionandDistribution-freeUncer-
M., Luengo, J., and Herrera, F. Anomaly Detection
taintyQuantification.CoRR,abs/2107.07511,2021.URL
in Predictive Maintenance: A new Evaluation Frame-
https://arxiv.org/abs/2107.07511.pp.14–
work for Temporal Unsupervised Anomaly Detection
15.
Algorithms. Neurocomputing, 462:440–452, October
Barber,R.F.,Cande`s,E.J.,Ramdas,A.,andTibshirani,R.J. 2021. ISSN 0925-2312. doi: 10.1016/j.neucom.2021.
PredictiveInferencewiththeJackknife+. TheAnnalsof 07.095. URL http://dx.doi.org/10.1016/j.
Statistics,49(1),February2021. ISSN0090-5364. doi: neucom.2021.07.095.
10.1214/20-aos1965. URL http://dx.doi.org/
Chen,C.,Murphy,N.,Parisa,K.,Sculley,D.,andUnder-
10.1214/20-AOS1965.
wood, T. Reliable Machine Learning: Applying SRE
Bates, S., Cande`s, E., Lei, L., Romano, Y., andSesia, M. PrinciplestoMLinProduction. O’ReillyMedia,Incor-
TestingforOutlierswithConformalp-Values. TheAn- porated,2022. ISBN9781098106225. URLhttps://
nalsofStatistics,51(1):149–178,2023. doi: 10.1214/ books.google.de/books?id=1rvHzgEACAAJ.
22-AOS2244. URLhttps://doi.org/10.1214/
Efron,B. Jackknife-After-BootstrapStandardErrorsand
22-AOS2244.
Influence Functions. Journal of the Royal Statistical
Belle,V.andPapantonis,I. PrinciplesandPracticeofEx- Society.SeriesB(Methodological),54(1):83–127,1992.
plainable Machine Learning. Frontiers in Big Data, 4, ISSN 00359246. URL http://www.jstor.org/
July2021. ISSN2624-909X. doi: 10.3389/fdata.2021. stable/2345949.
688969. URL http://dx.doi.org/10.3389/
Evangelou,M.andAdams,N.M. AnAnomalyDetection
fdata.2021.688969.
Framework for Cyber-Security Data. Computers
Benjamini, Y. and Hochberg, Y. Controlling the False & Security, 97:101941, 2020. ISSN 0167-4048.
DiscoveryRate: APracticalandPowerfulApproachto doi: https://doi.org/10.1016/j.cose.2020.101941.
Multiple Testing. Journal of the Royal Statistical So- URL https://www.sciencedirect.com/
ciety.SeriesB(Methodological),57(1):289–300,1995. science/article/pii/S0167404820302170.
ISSN 00359246. doi: 10.2307/2346101. URL http:
Fedorova,V.,Gammerman,A.,Nouretdinov,I.,andVovk,V.
//dx.doi.org/10.2307/2346101.
Plug-inmartingalesfortestingexchangeabilityon-line.In
Benjamini,Y.andYekutieli,D. TheControloftheFalse Proceedingsofthe29thInternationalCoferenceonInter-
DiscoveryRateinMultipleTestingunderDependency. nationalConferenceonMachineLearning,ICML’12,pp.
TheAnnalsofStatistics,29(4),August2001. ISSN0090- 923–930,Madison,WI,USA,2012.Omnipress. ISBN
5364.doi:10.1214/aos/1013699998.URLhttp://dx. 9781450312851.
doi.org/10.1214/aos/1013699998. p.1168.
Fernando, T., Gammulle, H., Denman, S., Sridharan, S.,
Benjamini, Y., Heller, R., and Yekutieli, D. Selective and Fookes, C. Deep Learning for Medical Anomaly
Inference in Complex Research. Philosophical Trans- Detection – A Survey. ACM Comput. Surv., 54(7), jul
actions of the Royal Society A: Mathematical, Physi- 2021. ISSN 0360-0300. doi: 10.1145/3464423. URL
cal and Engineering Sciences, 367(1906):4255–4271, https://doi.org/10.1145/3464423.
9UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
Gammerman, A., Vovk, V., and Vapnik, V. Learning by Laxhammar, R. Conformal Anomaly Detection: De-
Transduction. InProceedingsoftheFourteenthConfer- tectingAbnormalTrajectoriesinSurveillanceApplica-
ence on Uncertainty in Artificial Intelligence, UAI’98, tions. PhDthesis,UniversityofSko¨vde,Sweden,2014.
pp. 148–155, San Francisco, CA, USA, 1998. Morgan URL https://urn.kb.se/resolve?urn=urn:
KaufmannPublishersInc. ISBN155860555X. nbn:se:his:diva-8762. pp.45–58.
Guan,L.andTibshirani,R. PredictionandOutlierDetec- Laxhammar, R. and Falkman, G. Conformal Predic-
tion in Classification Problems. Journal of the Royal tion for Distribution-independent Anomaly Detection
StatisticalSocietySeriesB:StatisticalMethodology,84 in Streaming Vessel Data. In Proceedings of the First
(2):524–546, February 2022. ISSN 1467-9868. doi: International Workshop on Novel Data Stream Pat-
10.1111/rssb.12443.URLhttp://dx.doi.org/10.
tern Mining Techniques, StreamKDD ’10, pp. 47–55,
1111/rssb.12443.
New York, NY, USA, 2010. Association for Comput-
ing Machinery. ISBN 9781450302265. doi: 10.
Han, S., Hu, X., Huang, H., Jiang, M., and Zhao, Y.
1145/1833280.1833287. URL https://doi.org/
ADBench: AnomalyDetectionBenchmark. Advances
10.1145/1833280.1833287.
in Neural Information Processing Systems, 35:32142–
32159,2022.
Lei, J. and Wasserman, L. Distribution-free Prediction
Haroush, M., Frostig, T., Heller, R., and Soudry, D. A Bands for Non-parametric Regression. Journal of the
statisticalframeworkforefficientoutofdistributionde- Royal Statistical Society Series B: Statistical Method-
tectionindeepneuralnetworks. InInternationalConfer- ology, 76(1):71–96, 07 2013. ISSN 1369-7412. doi:
enceonLearningRepresentations,2022. URLhttps: 10.1111/rssb.12021. URL https://doi.org/10.
//openreview.net/forum?id=Oy9WeuZD51. 1111/rssb.12021.
Hilal, W., Gadsden, S. A., and Yawney, J. Financial Liu, F.T., Ting, K.M., andZhou, Z.-H. IsolationForest.
Fraud: A Review of Anomaly Detection Techniques In2008EighthIEEEInternationalConferenceonData
and Recent Advances. Expert Systems with Ap- Mining.IEEE,December2008. doi: 10.1109/icdm.2008.
plications, 193:116429, 2022. ISSN 0957-4174. 17. URL http://dx.doi.org/10.1109/ICDM.
doi: https://doi.org/10.1016/j.eswa.2021.116429. 2008.17.
URL https://www.sciencedirect.com/
science/article/pii/S0957417421017164. Mitroff, I. and Silvers, A. Dirty Rotten Strategies. Stan-
ford University Press, Redwood City, 2009. ISBN
Ishimtsev, V., Bernstein, A., Burnaev, E., and Nazarov, I.
9781503627260.doi:doi:10.1515/9781503627260.URL
Conformal k-NN anomaly detector for univariate data
https://doi.org/10.1515/9781503627260.
streams. InGammerman,A.,Vovk,V.,Luo,Z.,andPa-
padopoulos,H.(eds.),ProceedingsoftheSixthWorkshop
Pang,G.,Shen,C.,Cao,L.,andHengel,A. DeepLearning
on Conformal and Probabilistic Prediction and Appli- for Anomaly Detection: A Review. ACM Computing
cations, volume 60 of Proceedings of Machine Learn- Surveys,54:1–38,032021. doi: 10.1145/3439950.
ing Research, pp. 213–227. PMLR, 13–16 Jun 2017.
URLhttps://proceedings.mlr.press/v60/ Papadopoulos, H., Proedrou, K., Vovk, V., and Gam-
ishimtsev17a.html. merman, A. Inductive Confidence Machines for
Regression, pp. 345–356. Springer Berlin Heidel-
Japkowicz, N., Myers, C., and Gluck, M. A novelty de-
berg, 2002. ISBN 9783540367550. doi: 10.1007/
tection approach to classification. Proceedings of the
3-540-36755-1 29. URLhttp://dx.doi.org/10.
FourteenthJointConferenceonArtificialIntelligence,10
1007/3-540-36755-1 29.
1999.
Keogh, S., Lonardi, E. A., Ratanamahatana, C., Wei, L., Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V.,
Lee, S.-H., and Handley, J. Compression-based Data Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P.,
MiningofSequentialData. DataMiningandKnowledge Weiss,R.,Dubourg,V.,Vanderplas,J.,Passos,A.,Cour-
Discovery,14(1):99–129,2007. pp.1–3. napeau,D.,Brucher,M.,Perrot,M.,andDuchesnay,E.
Scikit-learn: Machine Learning in Python. Journal of
Kim,B.,Xu,C.,andBarber,R.F. PredictiveInferenceis MachineLearningResearch,12:2825–2830,2011.
FreewiththeJackknife+-after-Bootstrap. InProceedings
ofthe34thInternationalConferenceonNeuralInforma- Petsche, T. and Gluck, M. Workshop on Novelty De-
tionProcessingSystems,NIPS’20,RedHook,NY,USA, tection and Adaptive System Monitoring. In NIPS,
2020.CurranAssociatesInc. ISBN9781713829546. p. 1994.URLhttps://www.cs.cmu.edu/Groups/
3. NIPS/1994/94workshops-schedule.html.
10UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
Pimentel, M. A., Clifton, D. A., Clifton, L., and 10.1214/22-aos2250. URL http://dx.doi.org/
Tarassenko, L. A Review of Novelty Detection. 10.1214/22-AOS2250.
Signal Processing, 99:215–249, 2014. ISSN 0165-
Tax,D. One-classClassification. PhDthesis,DelftUniver-
1684. doi: https://doi.org/10.1016/j.sigpro.2013.12.
sityofTechnology,June2001.
026. URLhttps://www.sciencedirect.com/
science/article/pii/S016516841300515X.
Tukey,J. BiasandConfidenceinnotquitelargeSamples.
AnnalsofMathematicalStatistics,29:614,1958.
Quenouille, M. H. Approximate Tests of Correla-
tion in Time-series. Mathematical Proceedings of
Tukey,J.W.TheProblemofMultipleComparisons.Unpub-
the Cambridge Philosophical Society, 45(3):483–484,
lishedmanuscript.SeeBraun(1994),pp.1-300.,1953.
July 1949. ISSN 1469-8064. doi: 10.1017/
s0305004100025123. URL http://dx.doi.org/ Vovk, V. Cross-conformal Predictors. Annals of
10.1017/s0305004100025123. Mathematics and Artificial Intelligence, 74(1–2):9–28,
July 2013a. ISSN 1573-7470. doi: 10.1007/
Quenouille,M.H. NotesonBiasinEstimation. Biometrika, s10472-013-9368-4. URL http://dx.doi.org/
43(3/4):353, December 1956. ISSN 0006-3444. doi: 10.1007/s10472-013-9368-4. p.1.
10.2307/2332914. URL http://dx.doi.org/10.
2307/2332914. Vovk,V. TransductiveConformalPredictors. In9thArti-
ficialIntelligenceApplicationsandInnovations(AIAI),
Quirk,J.P.andSaposnik,R. AdmissibilityandMeasurable pp. 348–360, Paphos, Greece, September 2013b. doi:
UtilityFunctions. TheReviewofEconomicStudies,29 10.1007/978-3-642-41142-7 36. URLhttps://hal.
(2):140,February1962. ISSN0034-6527. doi: 10.2307/ archives-ouvertes.fr/hal-01459630.
2295819. URL http://dx.doi.org/10.2307/
2295819. Vovk, V. Testing for Concept Shift Online.
ArXiv, abs/2012.14246, 2020. URL https:
Schmit, S. The useful useless p-value, May 17 //api.semanticscholar.org/CorpusID:
2023. URL https://www.geteppo.com/blog/ 229678222.
the-useful-useless-p-value. Accessed on
27.01.2024. Vovk,V. TestingRandomnessOnline. StatisticalScience,
36(4):595–611, 2021. doi: 10.1214/20-STS817. URL
Shao,J.andTu,D. TheJackknifeandBootstrap. Springer https://doi.org/10.1214/20-STS817.
NewYork,1995. ISBN9781461207955. doi: 10.1007/
978-1-4612-0795-5. URL http://dx.doi.org/ Vovk, V., Gammerman, A., and Shafer, G. Algorithmic
10.1007/978-1-4612-0795-5. p.414. LearninginaRandomWorld. Springer-Verlag,Berlin,
Heidelberg,2005. ISBN0387001522.
Smith, J., Nouretdinov, I., Craddock, R., Offer, C. R.,
andGammerman,A. Conformalanomalydetectionof Vovk, V., Petej, I., Nouretdinov, I., Ahlberg, E., Carls-
trajectories with a multi-class hierarchy. In Gammer- son, L., and Gammerman, A. Retrain or not retrain:
man,A.,Vovk,V.,andPapadopoulos,H.(eds.),Statis- Conformal Test Martingales for Change-point Detec-
ticalLearningandDataSciences,pp.281–290,Cham, tion. In Carlsson, L., Luo, Z., Cherubin, G., and
2015. Springer International Publishing. ISBN 978-3- An Nguyen, K. (eds.), Proceedings of the Tenth Sym-
posiumonConformalandProbabilisticPredictionand
319-17091-6.
Applications, volume 152 of Proceedings of Machine
Smuha, N. A. The EU Approach to Ethics Guidelines Learning Research, pp. 191–210. PMLR, 08–10 Sep
forTrustworthyArtificialIntelligence. ComputerLaw 2021.URLhttps://proceedings.mlr.press/
Review International, 20(4):97–106, 2019. doi: doi: v152/vovk21b.html.
10.9785/cri-2019-200402. URLhttps://doi.org/
10.9785/cri-2019-200402. Zhao, Q., Small, D. S., and Su, W. Multiple Test-
ing when many p-Values are Uniformly Conservative,
Steinberger,L.andLeeb,H. Leave-one-outPredictionIn- with Application to Testing Qualitative Interaction in
tervalsinLinearRegressionModelswithmanyVariables. Educational Interventions. Journal of the American
arXiv: Statistics Theory, 2016. URL https://api. Statistical Association, 114(527):1291–1304, October
semanticscholar.org/CorpusID:88514378. 2018. ISSN1537-274X. doi: 10.1080/01621459.2018.
1497499. URL http://dx.doi.org/10.1080/
Steinberger, L. and Leeb, H. Conditional Predictive In- 01621459.2018.1497499.
ference for Stable Algorithms. The Annals of Statis-
tics, 51(1), February 2023. ISSN 0090-5364. doi:
11UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
A.BenchmarkDatasets
Thebenchmarkdatasets,asusedforevaluation(seeSection5),arepartofacollectionofdatasets,namelyADBench(Han
etal.,2022),forbenchmarkinganomalydetectionalgorithms. Respectivedatamayvaryincertaininstancesfromdata
foundinothersources,despitebeinglabeledwiththesamename.
Table3. KeyfiguresofbenchmarkdatasetsasfoundinADBenchandusedforevaluationofproposedmethods.
Dataset(Abbrev.) n n
feature
n
inlier
n
outlier
noutlier/n SubjectArea Source
WhiteBloodCells 223 9 213 10 .045 Health/Medicine (Hanetal.,2022)
Ionosphere 351 32 225 126 .359 Physics/Chemistry —”—
BreastCancer(W.) 683 9 444 239 .350 Health/Medicine —”—
Cardio 1,831 21 1,655 176 .096 Health/Medicine —”—
Musk 3,062 166 2,965 97 .032 Physics/Chemistry —”—
Thyroid 7,200 6 6,666 534 .074 Health/Medicine —”—
Mammography 11,183 6 10,923 260 .023 Health/Medicine —”—
MAGICGammaTel. 19,020 10 12,332 6,688 .352 Physics/Chemistry —”—
Statlog(Shuttle) 49,097 9 45,586 3,511 .072 Physics/Chemistry —”—
CreditCardFraud 284,807 29 284,315 492 .002 Finance/Economics —”—
12UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
B.Super-UniformityinHypothesisTesting
Super-uniformitydescribesapropertyofp-valuesin(frequentist)hypothesistesting,thatmayalsobedefinedasconservative
(Zhaoetal.,2018), stochasticallylargerthanuniform(Quirk&Saposnik,1962)orstochasticallylowerboundedbya
uniform(Blanchard&Roquain,2008)incorrespondingliterature.
Startingwiththefundamentaldefinition,ap-valuecanbedefinedasfollows:
DefinitionB.1. ArandomvalueX canbeconsideredasbeingap-valueif,underH ,theprobabilityP (X ≤t)≤tfor
0 H0
allt∈[0,1]. Withthat,X issaidtobesuper-uniformlydistributed[0,1].
Bythegivendefinition,ap-valuecanbeconsideredasrandomvariablesincetheunderlyingdataisarandomvariableitself.
Thisappliesprovidedthepopulationparametersarefixed(e.g. thepopulationmean).
To build intuition, a constant c = 1 (representing a p-value) is super-uniform since it is greater than any draw from a
uniformly distributed [0,1] random variable — although uninformative in the particular case6. This is sometimes also
referredtoasgenerallybeingstochasticallylargerorstochasticallydominatingasinstochasticallydominatesastandard
uniformrandomvariable—seeabovestochasticallylargerthanuniform(Quirk&Saposnik,1962). Inthecontextof
distributions,super-uniformdistributionsstochasticallydominateuniformdistributions.
NotethatthegivendescriptionsareunderH beingtrue,asp-valuesunderH beingtruecanassumeanyvalueinprinciple.
0 1
Withthat,super-uniformitymakesitpossibletocontroltheFDR,makingitadesiredpropertyofp-values.
Thefollowingdistinctionscanbemadebasedontheprovidedexplanations:
DefinitionB.2. ArandomvalueX within[0,1]issaidtobesuper-uniformif[itscumulativedistributionfunction(CDF)is
givenby]P (X ≤t)≤tforallt∈[0,1]. ThisimpliesthatX issuper-uniformlydistributed[0,1].
H0
DefinitionB.3. ArandomvalueX within[0,1]issaidtobestandard-uniformifP (X ≤t)=tforallt∈[0,1]. This
H0
impliesthatX isstandard-uniformlydistributed[0,1].
DefinitionB.4. ArandomvalueX within[0,1]issaidtobesub-uniformifP (X ≤t)≥tforallt∈[0,1]. Thisimplies
H0
thatX issub-uniformlydistributed[0,1].
6Givenexampleisbasedontheoneasdescribedin(Schmit,2023).
13UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
C.MultipleTestingandtheBenjamini-HochbergProcedure
Inhypothesestesting,therearegenerallythreetypesoferrorthatmayoccur:
• TypeIerrorsrefertofalsepositives. TheH isactuallytrue,butwerejectit,basedonourtestresult. Inourgivencase,
0
weflaganormalinstance,asbeinganomalous.
• TypeIIerrorsrefertofalsenegatives. TheH isactuallyfalse,butwerejectit,basedonourtestresult. Inourgiven
0
case,wefailtodetectananomalousinstance,falselyflaggingitasbeingnormal.
• TypeIII(andIV)errorsrefertomoresystematicerrorslikecorrectlyrejectingH butforthewrongreason,among
0
otherexamples(Mitroff&Silvers,2009). Thismayoccurduetopoororincompletedataorconfirmationbiasand
shallonlybementionedforthesakeofcompleteness.
In the context of hypothesis testing, the problem of multiple testing (Tukey, 1953) occurs when carrying out multiple
(simultaneous)statisticaltests(adozentothousands),andeachofthemhasthepotentialtoproduceadiscovery. Theactual
problemarisessinceeachtestincreasesthechanceofobservingaseeminglysignificantresultjustbymerechance—aType
Ierror. Concerningobtainedp-valuesandparticularlyrespectivethresholds(e.g. α = 0.05),usedtodeterminewhether
aresultisdeemedasstatisticallysignificantornot,thechancesforaTypeIerrorareproportionaltothenumberoftests
carriedout. For1,000testswithα=0.05,theexpectednumberoffalsepositivesisnaturally50(or5%inrelativeterms).
A popular approach to address this kind of problem, without compromising statistical power (or sensitivity) by also
minimizingTypeIIerrors,istocontrolthefalsediscoveryrate(FDR)(Benjamini&Hochberg,1995). TheFDRcanbe
thoughtofasaqualitycriterionformultipletesting(adjustments)thataimstostrikeabalancebetweenminimizingTypeI
errorsandTypeIIerrors.
Specifically,theFDRisdefinedastheexpectedproportionoffalsediscoveries(Q)asdefinedbytheproportionoftotal
discoveries(R)toerroneousdiscoveries(V),givenR>0(elseE(Q)=0)with
(cid:20)(cid:18) (cid:19) (cid:21)
V
FDR=E(Q)=E |R>0 ,
R
orputpractically,incontextofdiscussedanomalydetectionsystems,as
(cid:18) (cid:19)
effortswastedonfalsealarms
FDR=E ,
totalefforts
bothfollowingthedefinitionsasprovidedin(Benjaminietal.,2009).
Apopularmethodforadjustingobtainedp-valuestocontroltheFDRistheBenjamini-Hochbergprocedure(Benjamini
&Hochberg,1995). Thegeneralideabehindmostadjustmentmethods(includingBenjamini-Hochberg),istofirstsort
obtained p-values since the smallest usually provide the strongest evidence to reject the H . With that, the methods
0
determinetheadjustedthresholdvalue(orrankk)todistinctbetweensignificanceandnon-significance.
The Benjamini-Hochberg procedure computes adjusted p-values pBH for m tested hypotheses
(i)
{H ,H ,...,H }={H }m andcorrespondingp-values{p ,p ,...,p }={p }m bysortingrespectivep-valuesas
01 02 0i 0i i=1 1 2 i i i=1
p
(1)
≤p
(2)
≤...≤p (m). Nowletp
k
bethelargestvalue, sothatp
k
≤ kα/m. Incasenorespectivek exists, noactual
discoveryisamongtheobtainedresults. Otherwise,incasearespectivekexists,rejectthekhypothesesH thatbelongto
0i
p ,...,p ,formallydefinedas
(1) (k)
(cid:18)(cid:18) (cid:19) (cid:19)
pB (iH
)
=Minimum Minimummp(j)/j ,1 .
j≥i
Withthat,pBH ≤αonlyifrespectiveH wasamongthediscoveriespriortotheadjustment.
(i) i
14UncertaintyQuantificationinAnomalyDetectionwithCross-Conformalp-Values
D.TheAssumptionofthePositiveRegressionDependenceon(eachonefrom)aSubset
Toprovidecontext,weassumetestingN hypothesesH ,eachofthembeingtrue(nodiscoveries). Giventhedefinitionsin
0
AppendixB,allN obtainedp-valuesarerandomvariables. Withthat,repeatingtheexperiments,thatunderliethetested
hypotheses,wouldresultindifferentp-values,formingadistributionofp-values.
In (frequentist) hypothesis testing, p-values under the H must be at least (standard-)uniformly distributed [0,1]. This
0
includesthedefinitionforsuper-uniformity(compareDefinitionB.2andDefinitionB.3)inthecontextofthereliablecontrol
oftheFDR.Inthecontextofmultipletesting(seeAppendixC),therespectiveN observedmarginaldistributionsalso
followauniformdistribution.
Inthecaseofthedataandthehypothesestestsbeingindependent,thejointN-dimensionaldistributionofallobtained
p-valueswillnaturallybealsouniformlydistributed[0,1]. Originally,Benjamini-Hochbergmethodwasdevelopedunder
the assumption of described independencies, so controlling the FDR with Benjamini-Hochberg method, under given
circumstances,wouldbevalid(Benjamini&Hochberg,1995). However,inpractice,moreoftenthannot,teststatisticsand
respective(pairsof)p-valuesmaybepositivelyornegativelycorrelatedinsomeway. Therefore,theBenjamini-Hochberg
methodwasprovedtobealsorobustagainst(i)“positivelycorrelatednormallydistributed”,and(ii)“positivelydependent
teststatistics”whileitmaybe“easilymodified”tocontroltheFDRforothercasesofdependency—althoughconservatively
(Benjamini&Yekutieli,2001).
Here,positivelydependentteststatisticsmayalsobedescribedasthepropertyofpositiveregressiondependencyoneach
onefromasubset(PRDS),withsubsetI ,asarelaxedformoftherelatedpositiveregressiondependency(PDS)thatinturn
0
impliesPRDS(Benjamini&Yekutieli,2001).
RemarkD.1. AsetDissaidtobeincreasingifx∈Dwithy ≥xwiththeimplicationofy ∈D.
RemarkD.2. ForanyincreasingsetD,andforeachi∈I , P(X ∈D|X =x)isnon-decreasinginx.
0 i
Insimpleterms,PRDSdescribesthepositivedependencybetweentherank(seeAppendixC)andthefailuretorejectH .
0
Thelowertherankofateststatistics,themorelikelyitistobesignificant. Withthat,PRDSisrelatedtothemodusoperandi
ofe.g. theBenjamini-Hochbergproceduretosortthep-values. Here,thesubsetsrefertotestingtheseriesofsubsetsofk
andbelow(seeAppendixC).ThepositivedependenceresultsfromtheacceptanceofH foronep-value,forthattheH for
0 0
allother(higher)p-valueswithhigherrankkisaccepted—withadependenceonthekthresult. Viceversa,whentheH
1
ofaparticulartestresultisaccepted,itonlyaffectshigherp-valuesbytheriseofthe(significance)threshold,tobemore
lenient—asanexpressionofthepositivedependence,makingitmore(notless)likelytorejecttheH forotherp-values.
0
TheoremD.3. Ifthejointdistributionofthep-values(orteststatistics)isPRDSonthesubsetofp-values(orteststatistics)
correspondingtotrueH ,theBenjaminiHochbergprocedurecontrolstheFDRatlevels≤ |H0|α.
0 |H|
15