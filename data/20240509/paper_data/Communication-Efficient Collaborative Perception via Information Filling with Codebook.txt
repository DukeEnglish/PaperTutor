Communication-Efficient Collaborative Perception via
Information Filling with Codebook
YueHu1,4 JuntongPeng1,4 SifeiLiu1,4 JunhaoGe1,4 SiLiu3 SihengChen1,2,4
1CooperativeMedianetInnovationCenter,ShanghaiJiaoTongUniversity 2ShanghaiAILaboratory
3BeihangUniversity 4Multi-AgentGovernance&IntelligenceCrew(MAGIC)
1 3
{18671129361,juntong.peng,hiraeth416,cancaries,sihengc}@sjtu.edu.cn {liusi}@buaa.edu.cn
Abstract
Collaborative perception empowers each agent to im-
prove its perceptual ability through the exchange of per-
ceptual messages with other agents. It inherently re-
sults in a fundamental trade-off between perception abil-
ity and communication cost. To address this bottleneck
issue, our core idea is to optimize the collaborative mes-
sages from two key aspects: representation and selec-
tion. The proposed codebook-based message representa-
tion enables the transmission of integer codes, rather than
high-dimensionalfeaturemaps. Theproposedinformation- Figure 1. CodeFilling avoids redundant messages and
filling-drivenmessageselectionoptimizeslocalmessagesto achieves more complete detections by transmitting more critical
collectively fill each agent’s information demand, prevent- perceptualinformationwiththecompactcodeindexmessage.
ing information overflow among multiple agents. By in- cations,particularlyvehicle-to-everything-communication-
tegrating these two designs, we propose CodeFilling, aidedautonomousdriving[2,3,18,26,28–30,33,38,39].
a novel communication-efficient collaborative percep- In this emerging field, a central challenge lies in opti-
tion system, which significantly advances the perception- mizing the trade-off between perception performance and
communication trade-off and is inclusive to both homo- communication cost inherent in agents sharing perceptual
geneous and heterogeneous collaboration settings. We data[10,12,16,19,20,30,41,42].Giveninevitablepracti-
evaluate CodeFilling in both a real-world dataset, calconstraintsofcommunicationsystems,efficientutiliza-
DAIR-V2X, and a new simulation dataset, OPV2VH+. tionofcommunicationresourcesistheprerequisiteforcol-
Results show that CodeFilling outperforms previ- laborative perception. To minimize communication over-
ous SOTA Where2comm on DAIR-V2X/OPV2VH+ with head,astraightforwardsolutionislatecollaboration,where
1,333/1,206× lower communication volume. Our code agentsdirectlyexchangetheperceptionoutputs. However,
is available at https://github.com/PhyllisH/ numerous previous works indicate that late collaboration
CodeFilling. yields marginal perception improvements and is vulnera-
bletovariousnoises[10,21]. Tooptimizetheperception-
communicationtrade-off, moststudiesconsiderintermedi-
1.Introduction atecollaboration,wherethecollaborativemessagesareper-
ceptual features [10, 12, 16, 19, 20, 29, 35, 37, 40]. For
Collaborative perception aims to enhance the perceptual example,When2com[19]proposedthehandshakestrategy
abilityofeachindividualagentbyfacilitatingtheexchange tolimitthenumberofcollaborators;andWhere2comm[10]
of complementary perceptual information among multiple proposedapragmaticstrategythatonlytransmitsmessages
agents [1, 10, 12, 15, 16, 19, 22, 24, 30, 31, 43]. It aboutconstrainedspatialareas. Whilethesemethodsmiti-
fundamentallyovercomestheocclusionandlong-rangeis- gatecertaincommunicationcosts, theystillnecessitatethe
sues in single-agent perception [4, 11, 13, 45]. As the transmission of high-dimensional feature maps, which in-
forefront of autonomous systems, collaborative perception curssubstantialcommunicationexpenses.
shows significant potential in enormous real-world appli- To overcome the limitations of intermediate collabora-
4202
yaM
8
]TI.sc[
1v66940.5042:viXration,ourcoreideaistooptimizethecollaborativemessages icantly improves the perception- communication trade-off
from two key perspectives: representation and selection. and is inclusive to both homogeneous and heterogeneous
For message representation, we introduce a codebook to collaborationsettings;
standardize the communication among agents, where each •Weproposetwonovelmethodstooptimizecollabora-
codeisanalogoustoawordinthehumanlanguagedictio- tivemessages:codebook-basedmessagerepresentationand
nary. Basedonthissharedcodebookamongallagents,we information-filling-drivenmessageselection;
canusethecodestoapproximateperceptualfeatures; con- • We conduct comprehensive experiments to vali-
sequently,onlyintegercodeindicesneedtobeexchanged, date that CodeFilling achieves SOTA perception-
eliminatingtheneedfortransmittinghigh-dimensionalfea- communication trade-off across varying communication
tures comprised of floating-point numbers. For message bandwidths, on both real-world and simulation datasets in
selection, we propose an information filling strategy, akin bothhomogeneousandheterogeneoussettings.
to piecing together a jigsaw puzzle. In this approach, as-
2.Relatedworks
suming an agent’s information demand is upper bounded,
Collaborative Perception. Collaborative perception [10,
each of its collaborators performs a local optimization to
12, 16, 17, 19–21, 30, 32, 35, 36, 43] is an emerging
select non-redundant messages to fill its information gap.
application of multi-agent communication systems to per-
Thisstrategypreventsinformationoverflowamongmultiple
ception tasks, which promote the crucial perception mod-
agents,furthersignificantlyreducingcommunicationcost.
ule through communication-enabled complementary per-
Followingtheabovespirit,weproposeCodeFilling,
ceptual information sharing. Several high-quality datasets
anovelcommunication-efficientcollaborative3Ddetection
have emerged [10, 12, 17, 35, 43, 44] to aid in the algo-
system; see Figure 2. The proposed CodeFilling in-
rithmdevelopment. Collaborativeperceptionsystemshave
cludesfourkeymodules: i)asingle-agentdetector,provid-
maderemarkableprogressinimprovingperceptionperfor-
ing basic detection capabilities; ii) an novel information-
mance [36, 37] and robustness on practical issues, such as
filling-driven message selection, which solves local opti-
communication bandwidth constraints, pose error [21, 27]
mizationsforchoosingpertinentmessagestooptimallyfill
andlatency[14,31].Here,consideringthatcommunication
other agents’ information demands without causing infor-
efficiencyisthebottleneckissueforthescale-upofcollab-
mation flow; iii) an novel codebook-based message rep-
orative perception, we aim to optimize the performance-
resentation, which leverages a task-driven codebook to
communication trade-off instead of solely promoting the
achievepragmaticapproximationoffeaturemaps,enabling
perceptionperformanceregardlessofbandwidthcosts.
thetransmissionofintegercodeindices;andiv)amessage
Communication efficiency in collaborative perception.
decodingandfusionmodule,whichintegratesthemessages
To address this bottleneck issue, prior methods have made
toachieveenhancedcollaborativedetections.
effortsintwokeyaspects: messageselectionandmessage
CodeFilling offers two distinct advantages: i)
representation. Formessageselection,When2com[19]and
it delivers a substantial advancement in the perception-
Who2comm [20] employ a handshake mechanism, to se-
communication trade-off through the transmission of non-
lect information from all the relevant collaborators. Fur-
redundantcodeindices;andii)itisinclusivetobothsettings
thermore,Where2comm[10]andCoCa3D[12]expandthe
ofhomogeneousandheterogeneousagentsbyleveraginga
selection process to incorporate spatial dimensions. For
standardized code representation; that is, feature maps ob-
message representation, intermediate feature representa-
tainedfromvariousperceptionmodelsanddiversesensors
tion [10, 12, 16, 17, 30, 36, 37] has demonstrated a more
canbealignedtotheunifiedfeaturespaceprovidedbythe
balanced performance-communication trade-off. Source
proposedcodebook.
coding [30] and channel compression [16] techniques are
To evaluate CodeFilling, we conduct extensive ex- used to further enhance feature representation efficiency.
perimentsonreal-worlddatasetDAIR-V2X,andanewsim- However, previous methods accumulate redundant infor-
ulation dataset OPV2VH+ under two homogeneous (Li- mation from various collaborators and still transmit high-
DAR, camera) and one heterogeneous setting. The re- dimensionalfeaturevectors,incurringhighcommunication
sultsshowthati)CodeFillingachievessuperiorperfor-
costs. Here, we facilitate essential supportive information
manceperformancesthanWhere2comm,thecurrentSOTA, exchangeamongagentswithcompactcodebook-basedrep-
with 1333/1206 × less communication cost on DAIR- resentation,efficientlyenhancingdetectionperformance.
V2X/OPV2VH+; and ii) CodeFilling maintains supe- Codebook compression. Codebook compression, a loss-
riortrade-offinbothhomogeneousandheterogeneousset- lesscompressiontechnique,effectivelycapturestheessence
tings,establishinganinclusivecollaborationsystem. of high-dimensional vectors through the combination of
Tosumup,ourmaincontributionsarethree-fold: these codes [7]. It has diverse applications, ranging from
•WeproposeCodeFilling,anovelcommunication- digitalimagecompression[8]totheneuralnetworkparam-
efficient collaborative 3D detection system, which signif- eters compression [9]. Recently, task-adaptive codebooksFigure2. CodeFillingisanovelcommunication-efficientcollaborative3Ddetectionsystem. Theproposedinformation-filling-driven
messageselectionandcodebook-basedmessagerepresentationcontributetooptimizingcollaborativemessages.
haveemerged. Ratherthanpursuinglosslesscompression, P ,whichshouldbebothinformativeandcompact.
j→i
it drops task-irrelevant information and focuses on essen-
4.CodeFilling: Collaborative3DDetection
tial information for specific downstream tasks, further im-
provingrepresentationefficiency[5,25].However,existing To optimize the trade-off between perception ability and
task-adaptive codebooks have largely concentrated on 2D communication cost, we present CodeFilling, a novel
classificationtasks[25]. Here, weexplorethenovelrealm communication-efficientcollaborative3Ddetectionsystem;
ofcollaborative3Dobjectdetection,introducingfreshchal- see Fig. 2. It has two parts: i) single-agent 3D detection,
lenges for codebook compression. This entails preserving whichallowsanagentto equipbasicdetectionability, im-
an extensive feature set for precise 3D interpretation and plementingΦ in(1),andii)multi-agentcollaboration,en-
θ
adapting to fluctuating communication bandwidths, neces- hancing an agent’s detection ability through the exchange
sitatingversatilecodebookconfigurations. ofefficientperceptualmessagesP in(1).
3.ProblemFormulation 4.1.Single-agent3Ddetection
An agent learns to detect 3D objects based on its sen-
Consider N homogeneous or heterogeneous agents in the
sor inputs. It involves an observation encoder and a de-
scene, each has its individual perceptual task and unique
tection decoder. CodeFilling allows agents to accept
sensorsetup.Toenhancetheperceptionabilities,theagents
multi-modalityinputs,includingRGBimagesand3Dpoint
exchange complementary perceptual information, forming
clouds. Each agents with its distinct modality projects its
a decentralized mutually beneficial collaboration network.
perceptualinformationtotheunifiedglobalbird’seyeview
Each agent concurrently acts as both a supporter and a re-
(BEV)coordinatesystem,bettersupportinginter-agentcol-
ceiver.Intheirroleassupporters,theycontributeperceptual
laboration and more compatible with both homogeneous
information to assist their counterparts. Conversely, as re-
andheterogeneoussettings.
ceivers, they gain from the messages provided by others.
Observationencoder. Theobservationencoderextracts
Such collaborative perception leads to a holistic enhance-
featuremapsfromthesensordata. Fortheithagent,given
mentofperceptualcapabilities.Herewefocuson3Dobject
its input X , the BEV feature map is F = Φ (X ) ∈
detection. Let X be the input collected by the ith agent’s i i enc i
sensor (LiDAR oi r camera), and O0 be the corresponding RH×W×C, where Φ enc(·) is the encoder and H,W,C are
i itsheight,weightandchannel. Forimageinputs,Φ (·)is
ground-truth detection. The objective is to maximize the enc
followedbyanadditionalwarpingfunctionthattransforms
detectionperformancesofallagentsgivencertaincommu-
theextractedfront-viewfeaturetoBEV.TheBEVfeatureis
nicationbudgetB;thatis,
outputtothedecoder,andalsomessageselectionandfusion
max (cid:88) g(cid:16) Φ (cid:16) X ,{P }N (cid:17) ,O0(cid:17) ,s.t. (cid:88) b(P )≤B, moduleswhencollaborationisestablished.
θ i j→i j=1 i j→i
θ,P Detectiondecoder. Thedetectiondecoderdecodesfea-
i i,j,j̸=i
(1) tures into objects, including class and regression output.
whereg(·,·)isthedetectionevaluationmetric,Φ(·)isade- Given the feature map F , the detection decoder Φ (·)
i dec
tectionmodelwithtrainableparameterθ,P isthemes- generate the detections of ith agent by O = Φ (F ) ∈
j→i i dec i
sage transmitted from the ith agent to the jth agent, and RH×W×7, where each location of O represents a rotated
i
b(·) measures the communication cost of the collaborative box with class (c,x,y,h,w,cosα,sinα), denoting class
messages. Thekeychallengeistodeterminethemessages confidence,position,sizeandangle.4.2.Multi-agentcollaboration
In the proposed multi-agent collaboration, each agent acts
in the dual role of supporter and receiver. As a sup-
porter, each agent employs two novel modules, including
information-filling-drivenmessageselectionandcodebook-
Figure3.Theinformation-filling-drivenmessageselectionfulfills
based message representation, to determine compact, yet
theinformationdemandwithnon-redundantinformation.
supportive collaboration messages to help others. These
only requires the necessary information at certain spatial
two proposed modules enhance communication efficiency
areas for precise detection, as extra information no longer
inbothspatialandchanneldimensionsofafeaturemap,re-
provides significant benefits. This requires each supporter
spectively.Asareceiver,eachagentemploysamessagede-
to prioritize non-redundant and informative spatial regions
codingandfusionmoduletointegratesupportivemessages
with higher scores to assist others and halts the selection
fromotheragents,improvingitsperceptualperformance.
oncethereceiver’sinformationdemandsarefulfilled.
Specifically, the optimization is formulated as a proxy-
4.2.1 Information-filling-drivenmessageselection
constrained problem and obtains a binary selection matrix
To efficiently select compact collaborative messages for each agent to support each receiver. Let M ∈
i→j
that support other agents, each agent employs a novel {0,1}H×W bethebinaryselectionmatrixsupportedonthe
information-filling-driven message selection method. The BEV map. Each element in the matrix indicates whether
key idea is to enable each agent to restrainedly select per- Agent i should send the information to Agent j at a spe-
tinent messages to share with other agents; then collec- cific spatial location (1 for sending information, and 0 for
tively, these pieces of non-redundant messages mutually not sending). To solve for the binary selection matrix, the
fulfill each other’s information demands. For example, proxy-constrainedproblemisformulatedasfollows,
 
in occlusion scenarios, extra information from supporters N N
helps an agent detect missed objects. However, overfilled {M∗ i→j} i,j = argmax(cid:88) f minC j+ (cid:88) M i→j⊙C i,u,
M
information from multiple supporters wastes communica- j=1 i=1,i̸=j
N (3a)
tionresources. Thus,collectivecoordinationisessentialto where (cid:88) M ≤b,M ∈{0,1}H×W. (3b)
i→j i→j
avoid redundancy and enable more beneficial information.
i,j=1,j̸=i
To achieve this, the proposed selection has two key steps: Here⊙denoteselement-wisemultiplication,andthescalar
informationdisclosure,whereinagentsmutuallysharetheir u is a hyper-parameter to reflect the upper bound of in-
awareness of available information within specific spatial formation demand. The function f (·,·) computes the
min
areas, and filling-driven optimization, wherein each agent element-wiseminimumbetweenamatrixandascalar.
locallyoptimizesthesupportivemessagesforothers. In(3a),C +(cid:80)N M ⊙C indicatesthateach
j i=1,i̸=j i→j i
Informationdisclosure.Ininformationdisclosure,each receiverj accumulatestheinformationtransmittedfromall
agent: i) employs an information score generator to create supporters,combinedwithitsowninformation,ateachlo-
itsinformationscoremapfromitsfeaturemap,reflectingits cation, f (C + (cid:80)N M ⊙ C ,u) denotes the
min j i=1,i̸=j i→j i
availableinformationateachspatialarea,andii)broadcasts utility for each receiver, linearly increasing with the accu-
thismaptoallotheragents,promotingamutuallythorough mulated information scores until reaching the information
awarenessofalltheavailablesupport. demandu. Notethat: i)(3a)issolvedatthesupporterside
Theinformationscoremapisimplementedwiththede- forpreparingmessagestoareceiver;ii)thesum-basedutil-
tectionconfidencemap. Intuitively,theareascontainingan ity motivates supporters to collectively meet the receiver’s
objectarelikelytooffermoreusefulinformationforreveal- demand and focus on higher-scoring regions, and iii) the
ing missed detections and, therefore, should be assigned cutoffpointleadstohaltingselectiontopreventredundancy.
higher information scores. Specifically, given a BEV fea- Equation (3a) transforms the feature-based collabora-
turemapF i,itsspatialinformationscoremapis tion utility in (1) as the sum of the information scores.
C i =Φ generator(F i)∈[0,1]H×W, (2) This is based on the assumption that the accumulation of
where Φ (·) is implemented by detection decoder. information scores mirrors the benefits of feature aggre-
generator
When information score map is generated, each agent gation. Equation (3b) addresses the bandwidth limitation
broadcasts it to other agents. This initial communication in (1) by quantifying the total number of selected regions.
isefficientbecauseoflightweightinformationscoremaps. This approach simplifies the objective in (1) into a proxy-
Filling-drivenoptimization. Intheroleofasupporter, constrainedproblemin(3a)and (3b). Theoptimizedselec-
eachagentgatherstheotheragents’informationscoremaps tionsolutionderivedfrom(1)isexpectedtoyieldasuperior
anddetermineswhoneedsperceptualinformationatwhich outcomeinthefinalfeature-basedcollaboration.
spatialareasbylocallysolvingafilling-drivenoptimization. Thisoptimizationproblemhasananalyticalsolution;see
Here, filling the information demands means that an agent thetheoreticalderivationintheappendix. Thesolvingpro-cess incurs a computational cost of O(log(m)), where m
denotesthenumberofspatialregioncandidates. Byfocus-
ingontheextremelysparseforegroundareas,weeffectively
reducethecosttoanegligiblelevel,enablingeachagentto
providemoretargetedsupportforotherswithminimalcost.
Based on the optimized selection matrix {M∗ }N , Figure4.Thecodebook-basedmessagerepresentationdepictsthe
i→j j=1
eachagentsupportseachcollaboratorwithasparseyetin- originalfeaturevectorwiththemostrelevantcodes.
formative feature map Z = M∗ ⊙ F , promising task and the second term reflects the reconstruction error
i→j i→j i
superior perception improvements given the limited com- between the original feature vector and the code. This ap-
municationbudget. Theseselectedsparsefeaturemapsare proximation is lossy for reconstruction while lossless for
thenoutputtothemessagerepresentationmodule. the perceptual task, enabling the reduction of communica-
Theproposedmessageselectionofferstwokeybenefits: tioncostwithoutsacrificingperceptualcapacity.
i) it avoids redundancy from multiple supporters via col- Codeindexrepresentation. Basedonthesharedcode-
lectiveselection,andii)itadaptstovaryingcommunication book D, each agent can substitute the selected sparse fea-
conditionsbyadjustinginformationdemand,lowerdemand turemapZ byaseriesofcodeindicesI . Foreach
i→j i→j
forefficiencyinlimitedbudgets,andhigherdemandforsu- BEVlocation(h,w),thecodeindexisobtainedas,
periorperformanceinamplebudgets.Comparedtoexisting
(cid:13) (cid:13)2
selectionmethods[10,12,19,20],whicharebasedonindi- (I i→j) [h,w] =argm ℓin(cid:13) (cid:13)(Z i→j) [h,w]−D [ℓ](cid:13) (cid:13) 2. (5)
vidualsupporter-receiverpairs, ourcollectiveoptimization
The codebook offers versatility in its configuration by ad-
furtherreducesredundancyacrossvarioussupporters.
justingboththecodebooksizen andthequantityofcodes
L
4.2.2 Codebook-basedmessagerepresentation n R used for representing the input vector. Equation (5)
demonstratesaspecificinstancewheren = 1,chosenfor
ToefficientlytransmittheselectedfeaturemapZ ,each R
i→j simplicityinnotation.Whenn islarger,therepresentation
agent leverages a novel codebook-based message repre- R
involvesacombinationofmultiplecodes.
sentation, reducing communication cost along the chan-
Overall,thefinalmessagesentfromtheithagenttothe
nel dimension. The core idea is to approximate a high-
jth agent is P = I , conveying the required com-
dimensionalfeaturevectorbythemostrelevantcodefroma i→j i→j
plementaryinformationwithcompactcodeindices. Agents
task-drivencodebook;asaresult,onlyintegercodeindices
exchangethesepackedmessageswitheachother.
needtobetransmitted,ratherthanthecompletefeaturevec-
This codebook-based representation offers three advan-
torscomposedoffloating-pointnumbers.
tages: i) efficiency for transmitting lightweight code in-
Codebook learning. Analogous to a language dictio-
dices; ii) adaptability to various communication resources
nary used by humans, our task-driven codebook is shared
via adjusting code configurations (smaller for efficiency,
among all agents to standardize their communication for
larger for superior performance), and iii) extensibility by
achievingthedetectiontask.Thiscodebookconsistsofaset
providing a shared standardized representation. New het-
of codes, which are learned to pragmatically approximate
erogeneous agents can easily join the collaboration by
possibleperceptualfeaturespresentinthetrainingdataset.
addingitseffectiveperceptualfeaturebasistothecodebook.
Herethepragmaticapproximationreferstoeachcodeserv-
ing as a lossy approximation of a feature vector, while re- 4.2.3 Messagedecodingandfusion
tainingessentialinformationnecessaryforthedownstream
Message decoding reconstructs the supportive features
detection task within that vector. Specifically, let 𭟋 =
basedonthereceivedcodeindicesandthesharedcodebook.
{F(i,s)}N,S be the collective set of BEV feature maps
i=1,s=1 GiventhereceivedmessageP =I ,thedecodedfea-
extractedbytheobservationencodersofallN agentsacross j→i j→i
all S training scenes. Let D =
(cid:2)
d ,d ,··· ,d
(cid:3)
∈
turemap’sZ(cid:98)j→i ∈ RH×W×C elementlocatedat(h,w)is
1 2 nL
RC×nL be the codebook, where D [ℓ] = d ℓ ∈ RC is the (Z(cid:98)j→i) [h,w] = D [Ij→i[h,w]]. Subsequently,messagefusion
ℓthcodeandn isthenumberofcodes. aggregates these decoded feature maps to augment indi-
L
Thetask-drivencodebookislearnedthroughfeatureap- vidualfeatures,implementingbythenon-parametricpoint-
proximationateachspatiallocation;thatis, wise maximum fusion. For the ith agent, given the recon-
D∗ =argm Din F(cid:88) ∈𭟋(cid:88) h,wm ℓin(cid:16) Ψ(D [ℓ])+(cid:13) (cid:13)F [h,w]−D [ℓ](cid:13) (cid:13)2 2(cid:17) , (4)
s tatr iu nc et ded asfe Ha itu =re jmZ(cid:98)
∈j a N→ x i(i
F. iT ,Zh (cid:98)e j→en i)ha ∈nc Red H×B WEV ×Cfe wat hu er re ei Ns o ib is-
i-thagent’sconnectedcollaboratorsandmax(·)maximizes
where Ψ(·) denotes the resulting detection performance thecorrespondingfeaturesfrommultipleagentsateachin-
achieved by substituting D for F . The first term dividual spatial location. The enhanced feature H is de-
[ℓ] [h,w] i
pertains to the requirements of the downstream detection codedtogeneratetheupgradeddetectionO(cid:98)i.Figure5.InDAIR-V2X,CodeFillingachievesthebestperception-communicationtrade-offinhomogeneous&heterogeneoussettings.
Figure6.InOPV2VH+,CodeFillingachievesthebestperception-communicationtrade-offinhomogeneous&heterogeneoussettings.
4.3.Lossfunctions laborative perception dataset OPV2V+ [12] with a larger
array of collaborative agents (a total of 10) and addi-
Totraintheoverallsystem,wesupervisethreetasks: infor-
tionalLiDARsensors,co-simulatedbyOpenCDA[34]and
mation score map generation, object detection, and code-
CARLA [6]. Each agent has a LiDAR, 4 cameras, and 4
booklearning. Theinformationscoremapgeneratorreuses
depthsensors. Thedetectionrangeis281.6m×80m.
theparametersofthedetectiondecoder. Theoveralllossis
definedas,L=(cid:80)N
i
L
det(cid:16)
O(cid:98)i,O
i0(cid:17) +(cid:13)
(cid:13)F i−F
i(cid:13) (cid:13)2
2,where
I Cm aDpl Dem Ne [n 2t 3a ]ti fo on r.
the
LW iDe ARad ao np dt caP mo ein ratP dil el ta er cto[ r1 ,3 r] espa en cd
-
L det(·) denotes the detection loss [45], O i0 and O(cid:98)i repre- tively. Regarding the heterogeneous setup, agents are ran-
sentstheground-truthandpredictedobjects,andF iandF i domlyassignedeitherLiDARorcamera,resultinginabal-
denotethei-thagent’soriginalfeaturemapandtheoneap- anced1:1ratioofagentsacrossthedifferentmodalities.
proximatedbycodes. Duringtheoptimization,thenetwork Communication volume. Specifically, for feature repre-
parametersandthecodebookareupdatedsimultaneously. sentation,givenaselectionmatrixM,thebandwidthiscal-
culatedaslog (H×W×|M|×C×32/8).Here,32repre-
5.ExperimentalResults 2
sentsthefloat32datatypeand8convertsbitstobytes. For
Our experiments cover two datasets, both real-world and code index representation, given codebook D ∈ RC×nL,
simulation scenarios, two types of sensors (LiDAR and comprised of n codes and each vector constructed using
L
cameras), and both homogeneous and heterogeneous set- n codes, the bandwidth given the selection matrix M is
R
tings. Specifically, we conduct 3D object detection in the calculated as log (H × W × |M| × log (n ) × n /8).
2 2 L R
setting of V2X-communication-aided autonomous driving Here,log (n )signifiesthedataamountrequiredtorepre-
2 L
on DAIR-V2X dataset [43] and the extended large-scale senteachcodeindexinteger,decidedbythecodebooksize.
OPV2VH+ dataset. The detection results are evaluated by
5.2.Quantitativeevaluation
Average Precision (AP) at Intersection-over-Union (IoU)
Benchmark comparison. Fig. 6 and 5 compare the pro-
thresholds of 0.30 and 0.50. The communication volume
posed CodeFilling with previous methods in terms
followsthestandardsettingas [10,12,33,35]thatcounts
of the trade-off between detection performance and com-
themessagesizebybyteinlogscalewithbase2.
munication bandwidth for DAIR-V2X and OPV2VH+
5.1.Datasetsandexperimentalsettings
datasets under homogeneous and heterogeneous settings,
DAIR-V2X [43] is a widely-used real-world collabora- respectively. Detailed values can also be found in
tive perception dataset. Each scene contains two agents: the appendix. Baselines include no collaboration (O ),
i
a vehicle and a road-side-unit. Each agent is equipped Where2comm [10], HMViT [33], V2VNet [30], Dis-
with a LiDAR and a camera. The perception range is coNet [16], V2X-ViT [37], AttFuse [35] and late fusion,
204.8m×102.4m. OPV2VH+ is an extended large-scale whereagentsexchangethedetected3Dboxesdirectly.Note
version of the original vehicle-to-vehicle camera-only col- thatHMViTisspecificallydesignedforheterogeneousset-Figure7.CodeFillingisrobusttoposeerrorissue. Figure8.CodeFillingisrobusttocommunicationlatencyissue.
(a)Twocomponents. (b)Selectionutilitydesign. (c)Informationdemand. (d)Codebooksize. (e)Codequantity.
Figure9.Boththeproposedinformation-filling-drivenmessageselectionandcodebook-basedrepresentationareeffective.
tings by using domain adaption, while CodeFilling is tently surpasses No Collaboration, whereas baselines fail
naturally compatible with heterogeneous settings without whenposeerrorexceeds0.6mandlatencysurpasses100ms.
additional cost. We see that CodeFilling: i) achieves
5.3.Ablationstudies
a far-more superior perception-communication trade-off
Effectiveness of our message selection and representa-
across all the communication bandwidth choices and var-
tion. Fig. 9a compares CodeFilling, the one without
ious collaborative perception settings, including camera-
messageselection,andtheonewithoutcodebookandmes-
only, lidar-only, and heterogeneous 3D detection; ii) sig-
sage selection. We see that: i) applying code index rep-
nificantly improves the detection performance, especially
resentation reduces the communication cost by 208 times
under extremely limited communication bandwidth, im-
whilemaintainingthesamedetectionperformance,asitby-
proves the SOTA performance by 11.093/5.271/38.357%,
passes the high channel dimension typical of feature vec-
14.75/28.516/28.372% for LiDAR/camera/heterogeneous
tors, and an integer index requires less data than the orig-
on DAIR-V2X and OPV2VH+ even when the bandwidth
inal floating-point numbers, and ii) applying information-
isconstrainedbyafactorof100K;andiii)outperformspre-
filling-driven message selection achieves 4.8% higher de-
vious communication-efficient SOTA, Where2comm, with
tectionperformancewiththesamecommunicationcost,as
significantly reduced communication cost: 1333/115/863,
it reallocates the bandwidth wasted in redundant informa-
1206/1078/252timeslessonDAIR-V2XandOPV2VH+.
tiontomorebeneficialinformation.
Furthermore, for inference speed, CodeFilling Ablationofinformation-filling-drivenmessageselection.
(36/99ms) is comparable to Where2comm (34/94ms), and Fig. 9b compares different utility designs in information-
significantly faster than HMViT (90/1266ms) on DAIR- filling optimization: sum, max, and scenarios without se-
V2X/OPV2VH+. This communication efficiency ensures lection. The max utility design favors selecting collabora-
thatagentsareabletoactivelycollaboratewitheachother. tors with the highest score, leading to no selection if the
Robustness to pose error and communication latency. egoagenthasthehighestscore. Weseethatthesum-based
We validate the robustness against pose error and commu- utility outperforms both the max and no selection in the
nication latency on both OPV2VH+ and DAIR-V2X. The perception-communicationtrade-offacrossallcommunica-
pose error setting follows CoAlign [21] using Gaussian tionbandwidthconditions.Thissuperiorityisduetotheop-
noise with a mean of 0m and standard deviations ranging timizedcombinationofinformationfromdifferentcollabo-
from0mto1.0m.ThelatencysettingfollowsSyncNet[14], rators, which has proved to be more effective than relying
varyingfrom0msto500ms. Figs.7and8showthedetec- solely on the best-performing single agent. This approach
tion performances as a function of pose error and latency, encourages agents to participate in collaboration; even the
respectively. Wesee: i)whileperceptionperformancegen- top-performingagentscanbenefitfromcollaboration.
erally declines with increasing levels of pose error and la- Fig.9bevaluatesthreedifferentinformationdemandsu
tency, CodeFilling consistently outperforms baselines (0.5, 1.0, 1.5). Weseethat: i)lowerudemonstratesbetter
under all imperfect conditions; ii) CodeFilling consis- efficiencyunderlimitedcommunicationbudgets;ii)higher(a)Egodetections (b)Egofeature (c)Egoinformationscore (d)Collaboratorscore1 (e)Collaboratorscore2
(f)Selectionmatrix1 (g)Selectionmatrix2 (h)Filledconfidence (i)Codebook-basedmessage (j)Collaborativedetections
Figure10.VisualizationofcollaborationinCodeFilling.Greenandreddenotegroundtruthanddetection,respectively.
(a)NoCollaboration (b)V2X-ViT (c)HMViT (d)Where2comm (e)CodeFilling
Figure 11. CodeFilling achieves more accurate detections with 1256 times less communication cost. Green and red boxes denote
ground-truthanddetection,respectively.
udemonstratessuperiorperformanceunderamplecommu- ing that the information demands have been met, which is
nication budgets. By adjusting u, CodeFilling con- indicativeofimprovedperceptionperformance. Fig.10(f)
sistently maintains superior performance-communication presentsthecodebook-representedmessage,revealingthat:
trade-offacrossallcommunicationconditions. i)itisspatiallysparse,andii)theselectedinformationfrom
Ablation of codebook-based message representation. heterogeneouscollaboratorsisunifiedinacommonformat,
Fig. 9d and Fig. 9e explore different codebook configu- facilitatingextensibility.
rations: codebook size and code quantity. We see that: Visualization of detection results. Fig. 11 com-
i) all the codebook configurations demonstrate a supe- pares CodeFilling with previous SOTAs. We see
riorperception-communicationtrade-offunderhighlycon- that CodeFilling qualitatively outperforms previous
strained communication conditions, showing the effective- SOTAswith1256timeslesscommunicationcost. Therea-
ness and robustness of the codebook-based representation; son is that CodeFilling avoids redundant information
and ii) larger codebook sizes and quantities yield bet- fromdifferentcollaboratorsandemploysefficientcodein-
ter performance, while smaller sizes and quantities offer dex representation, thereby transmitting more critical per-
greatercommunicationefficiency. Byadaptingtheconfig- ceptualinformationevenwithlesscommunicationcost.
uration, CodeFillingmaintainssuperiorperformance-
6.Conclusions
communicationtrade-offacrossallcommunicationbudgets.
We propose CodeFilling, a novel communication-
5.4.Qualitativeevaluation
efficient collaborative 3D detection system with two
Visualization of message selection and representa- noveldesigns: codebook-basedmessagerepresentationand
tion. Fig. 10 showcases the efficient collaboration in information-filling-drivenmessageselection. Extensiveex-
CodeFilling. Thescenefeaturesoneegoagentandtwo periments covering both real-world and simulation scenar-
collaborators - one with LiDAR and the other with a cam- ios show that CodeFilling not only achieves state-of-
era, with all visualizations presented from the ego’s per- the-art perception-communication trade-off under various
spective. Fig. 10 (a) and (j) compare the detection results modalities, including LiDAR, camera, and heterogeneous
before and after collaboration. We see that through col- settingsbutalsoisrobusttoposeerrorandlatencyissues.
laboration, the ego agent successfully uncovers detections Limitationandfuturework. Weplantoexplorethetem-
missedinitsindividualview. Fig.10(d-g)displaysthecol- poraldimensionanddeterminecriticaltimestamps.
laborators’informationscoremapsandtheircorresponding Acknowledgments. This research is supported by the
selection matrices. We see that the redundant information National Key R&D Program of China under Grant
intheoverlappedregionsisavoided, promotingcommuni- 2021ZD0112801, NSFC under Grant 62171276 and the
cationefficiency. Fig.10(c)and(h)illustratetheevolution ScienceandTechnologyCommissionofShanghaiMunici-
oftheinformationscorebeforeandafterfilling, highlight- palunderGrant21511100900and22DZ2229005.References [14] ZixingLei,ShunliRen,YueHu,WenjunZhang,andSiheng
Chen.Latency-awarecollaborativeperception.ECCV,2022.
[1] Ebtehal Turki Alotaibi, Shahad Saleh Alqefari, and Anis
2,7
Koubaa. Lsar: Multi-uav collaboration for search and res-
[15] JinlongLi,RunshengXu,XinyiLiu,BaoluLi,QinZou,Ji-
cuemissions. IEEEAccess,7:55817–55832,2019. 1
aqi Ma, and Hongkai Yu. S2r-vit for multi-agent coopera-
[2] QiChen.F-cooper:featurebasedcooperativeperceptionfor tiveperception: Bridgingthegapfromsimulationtoreality.
autonomousvehicleedgecomputingsystemusing3dpoint ArXiv,abs/2307.07935,2023. 1
clouds. Proceedings of the 4th ACM/IEEE Symposium on
[16] YimingLi,ShunliRen,PengxiangWu,SihengChen,Chen
EdgeComputing,2019. 1
Feng, and Wenjun Zhang. Learning distilled collaboration
[3] RunjianChen,YaoMu,RunsenXu,WenqiShao,Chenhan graphformulti-agentperception. AdvancesinNeuralInfor-
Jiang,HangXu,YuQiao,ZhenguoLi,andPingLuo. CO3: mationProcessingSystems,34:29541–29552,2021. 1,2,6
Cooperativeunsupervised3drepresentationlearningforau- [17] Yiming Li, Ziyan An, Zixun Wang, Yiqi Zhong, Siheng
tonomousdriving.InTheEleventhInternationalConference Chen, and Chen Feng. V2X-Sim: A virtual collaborative
onLearningRepresentations,2023. 1 perceptiondatasetforautonomousdriving. IEEERobotics
[4] Siheng Chen, Baoan Liu, Chen Feng, Carlos Vallespi- andAutomationLetters,7,2022. 2
Gonzalez,andCarlK.Wellington.3dpointcloudprocessing [18] YimingLi,QiFang,JiamuBai,SihengChen,FelixJuefei-
and learning for autonomous driving: Impacting map cre- Xu,andChenFeng.Amongus:Adversariallyrobustcollab-
ation,localization,andperception. IEEESignalProcessing orativeperceptionbyconsensus. ICCV,2023. 1
Magazine,38:68–86,2021. 1 [19] Yen-Cheng Liu, Junjiao Tian, Nathaniel Glaser, and Zsolt
[5] TianshiChen,ZidongDu,NinghuiSun,JiaWang,Chengy- Kira. When2com: Multi-agentperceptionviacommunica-
ong Wu, Yunji Chen, and Olivier Temam. Diannao: a tiongraphgrouping. InProceedingsoftheIEEE/CVFCon-
small-footprint high-throughput accelerator for ubiquitous ference on computer vision and pattern recognition, pages
machine-learning. Proceedings of the 19th international 4106–4115,2020. 1,2,5
conference on Architectural support for programming lan- [20] Yen-ChengLiu,JunjiaoTian,Chih-YaoMa,NathanGlaser,
guagesandoperatingsystems,2014. 3 Chia-Wen Kuo, and Zsolt Kira. Who2com: Collaborative
[6] Alexey Dosovitskiy, Germa´n Ros, Felipe Codevilla, Anto- perceptionvialearnablehandshakecommunication.In2020
nioM. Lo´pez, andVladlenKoltun. Carla: An openurban IEEEInternationalConferenceonRoboticsandAutomation
drivingsimulator. InConferenceonRobotLearning,2017. (ICRA),pages6876–6883.IEEE,2020. 1,2,5
6 [21] Yifan Lu, Quanhao Li, Baoan Liu, Mehrdad Dianat, Chen
Feng, SihengChen, andYanfengWang. Robustcollabora-
[7] AllenGershoandRobertM.Gray. Vectorquantizationand
signal compression. In The Kluwer International Series in tive3dobjectdetectioninpresenceofposeerrors. IEEEIn-
EngineeringandComputerScience,1991. 2
ternationalConferenceonRoboticsandAutomation(ICRA),
2023. 1,2,7
[8] AllenGershoandBhaskarRamamurthi.Imagecodingusing
[22] YifanLu,YueHu,YiqiZhong,DequanWang,SihengChen,
vector quantization. In IEEE International Conference on
andYanfengWang. Anextensibleframeworkforopenhet-
Acoustics,Speech,andSignalProcessing,1982. 2
erogeneouscollaborativeperception.InTheTwelfthInterna-
[9] Song Han, Huizi Mao, and William J. Dally. Deep com-
tionalConferenceonLearningRepresentations,2024. 1
pression: Compressing deep neural network with pruning,
[23] Cody Reading, Ali Harakeh, Julia Chae, and Steven L.
trainedquantizationandhuffmancoding. ComputerVision
Waslander. Categorical depth distribution network for
andPatternRecognition,2015. 2
monocular3dobjectdetection. 2021IEEE/CVFConference
[10] Yue Hu, Shaoheng Fang, Zixing Lei, Yiqi Zhong, and Si-
onComputerVisionandPatternRecognition(CVPR),pages
hengChen.Where2comm:Communication-efficientcollab-
8551–8560,2021. 6
orative perception via spatial confidence maps. Advances
[24] Ju¨rgen Scherer, Saeed Yahyanejad, Samira Hayat, Evsen
in neural information processing systems, 35:4874–4886,
Yanmaz,TorstenAndre,AsifKhan,VladimirVukadinovic,
2022. 1,2,5,6
Christian Bettstetter, Hermann Hellwagner, and Bernhard
[11] Yue Hu, Shaoheng Fang, Weidi Xie, and Siheng Chen. Rinner.Anautonomousmulti-uavsystemforsearchandres-
Aerial monocular 3d object detection. IEEE Robotics and cue. InProceedingsoftheFirstWorkshoponMicroAerial
AutomationLetters,8:1959–1966,2022. 1 Vehicle Networks, Systems, and Applications for Civilian
[12] YueHu,YifanLu,RunshengXu,WeidiXie,SihengChen, Use,pages33–38,2015. 1
andYanfengWang. Collaborationhelpscameraovertakeli- [25] Saurabh Singh, Sami Abu-El-Haija, Nick Johnston, Jo-
dar in 3d detection. 2023 IEEE/CVF Conference on Com- hannes Balle´, Abhinav Shrivastava, and George Toderici.
puterVisionandPatternRecognition(CVPR),2023. 1,2,5, End-to-endlearningofcompressiblefeatures. In2020IEEE
6 InternationalConferenceonImageProcessing(ICIP),pages
[13] AlexH.Lang,SourabhVora,HolgerCaesar,LubingZhou, 3349–3353.IEEE,2020. 3
JiongYang,andOscarBeijbom. Pointpillars: Fastencoders [26] Sanbao Su, Yiming Li, Sihong He, Songyang Han, Chen
for object detection from point clouds. 2019 IEEE/CVF Feng,CaiwenDing,andFeiMiao. Uncertaintyquantifica-
Conference on Computer Vision and Pattern Recognition tionofcollaborativedetectionforself-driving. ICRA,2023.
(CVPR),pages12689–12697,2018. 1,6 1[27] NicholasVadivelu,MengyeRen,JamesTu,JingkangWang, Communication-efficientandcollaboration-pragmaticmulti-
andRaquelUrtasun. Learningtocommunicateandcorrect agentperception. AdvancesinNeuralInformationProcess-
poseerrors. InConferenceonRobotLearning,2020. 2 ingSystems,2023. 1
[28] Binglu Wang, Lei Zhang, Zhaozhong Wang, Yongqiang [41] Kun Yang, Dingkang Yang, Jingyu Zhang, Mingcheng Li,
Zhao, andTianfeiZhou. Core: Cooperativereconstruction Y. Liu, Jing Liu, Hanqi Wang, Peng Sun, and Liang Song.
formulti-agentperception. ICCV,2023. 1 Spatio-temporaldomainawarenessformulti-agentcollabo-
[29] Tianhang Wang, Guang Chen, Kai Chen, Zhengfa Liu, Bo rativeperception.Proceedingsofthe31stACMInternational
Zhang, Alois Knoll, and Changjun Jiang. Umc: A uni- ConferenceonMultimedia,2023. 1
fied bandwidth-efficient and multi-resolution based collab- [42] Kun Yang, Dingkang Yang, Jingyu Zhang, Hanqi Wang,
orativeperceptionframework. 2023IEEE/CVFConference Peng Sun, and Liang Song. What2comm: Towards
onComputerVisionandPatternRecognition(CVPR),2023. communication-efficientcollaborativeperceptionviafeature
1 decoupling.Proceedingsofthe31stACMInternationalCon-
[30] Tsun-Hsuan Wang, Sivabalan Manivasagam, Ming Liang, ferenceonMultimedia,2023. 1
Bin Yang, Wenyuan Zeng, and Raquel Urtasun. V2vnet: [43] HaibaoYu,YizhenLuo,MaoShu,YiyiHuo,ZebangYang,
Vehicle-to-vehicle communication for joint perception and Yifeng Shi, Zhenglong Guo, Hanyu Li, Xing Hu, Jirui
prediction. In European Conference on Computer Vision, Yuan, etal. DAIR-V2X:Alarge-scaledatasetforvehicle-
pages605–621.Springer,2020. 1,2,6 infrastructurecooperative 3dobjectdetection. InProceed-
[31] Sizhe Wei, Yuxi Wei, Yue Hu, Yifan Lu, Yiqi Zhong, Si- ings of the IEEE/CVF Conference on computer vision and
hengChen,andYaZhang. Asynchrony-robustcollaborative patternrecognition(CVPR),2022. 1,2,6
perceptionviabird’seyeviewflow. InAdvancesinNeural [44] Haibao Yu, Wenxian Yang, Hongzhi Ruan, Zhenwei Yang,
InformationProcessingSystems,2023. 1,2 YingjuanTang,XuGao,XinHao,YifengShi,YifengPan,
[32] HaoXiang,RunshengXu,XinXia,ZhaoliangZheng,Bolei Ning Sun, Juan Song, Jirui Yuan, Ping Luo, and Zaiqing
Zhou, and Jiaqi Ma. V2xp-asg: Generating adversarial Nie. V2x-seq: Alarge-scalesequentialdatasetforvehicle-
scenesforvehicle-to-everythingperception. 2023IEEEIn- infrastructure cooperative perception and forecasting. In
ternationalConferenceonRoboticsandAutomation(ICRA), ProceedingsoftheIEEE/CVFConferenceonComputerVi-
pages3584–3591,2022. 2 sionandPatternRecognition,2023. 2
[33] HaoXiang, RunshengXu, andJiaqiMa. Hm-vit: Hetero- [45] XingyiZhou,DequanWang,andPhilippKra¨henbu¨hl. Ob-
modalvehicle-to-vehiclecooperativeperceptionwithvision jectsaspoints.InarXivpreprintarXiv:1904.07850,2019.1,
transformer. ICCV,2023. 1,6 6
[34] Runsheng Xu, Yi Guo, Xu Han, Xin Xia, Hao Xiang, and
Jiaqi Ma. Opencda: An open cooperative driving automa-
tion framework integrated with co-simulation. 2021 IEEE
InternationalIntelligentTransportationSystemsConference
(ITSC),pages1155–1162,2021. 6
[35] Runsheng Xu, Hao Xiang, Xin Xia, Xu Han, Jinlong Liu,
andJiaqiMa. Opv2v: Anopenbenchmarkdatasetandfu-
sionpipelineforperceptionwithvehicle-to-vehiclecommu-
nication. 2022 International Conference on Robotics and
Automation(ICRA),pages2583–2589,2021. 1,2,6
[36] RunshengXu,ZhengzhongTu,HaoXiang,WeiShao,Bolei
Zhou,andJiaqiMa. CoBEVT:Cooperativebird’seyeview
semantic segmentation with sparse transformers. CoRL,
2022. 2
[37] RunshengXu,HaoXiang,ZhengzhongTu,XinXia,Ming-
HsuanYang,andJiaqiMa.V2X-ViT:Vehicle-to-everything
cooperative perception with vision transformer. ECCV,
2022. 1,2,6
[38] RunshengXu,JinlongLi,XiaoyuDong,HongkaiYu,andJi-
aqiMa.Bridgingthedomaingapformulti-agentperception.
ICRA,2023. 1
[39] RunshengXu,XinXia,JinlongLi,HanzhaoLi,ShuoZhang,
ZhengzhongTu, ZonglinMeng, HaoXiang, XiaoyuDong,
RuiSong,HongkaiYu,BoleiZhou,andJiaqiMa.V2v4real:
Areal-worldlarge-scaledatasetforvehicle-to-vehiclecoop-
erativeperception. InTheIEEE/CVFComputerVisionand
PatternRecognitionConference(CVPR),2023. 1
[40] Dingkang Yang, Kun Yang, Yuzheng Wang, Jing Liu, Zhi
Xu,RongbinYin,PengZhai,andLihuaZhang.How2comm: