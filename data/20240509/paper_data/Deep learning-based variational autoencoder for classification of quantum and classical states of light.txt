Deep learning-based variational autoencoder for classification of quantum
and classical states of light
Mahesh Bhupati†,1 Abhishek Mall†,2,3 Anshuman Kumar,1,4 and Pankaj K. Jha∗5
1Laboratory of Optics of Quantum Materials (LOQM), Department of Physics,
Indian Institute of Technology Bombay, Powai, Mumbai 400076, India
2Max Planck Institute for the Structure and Dynamics of Matter, 22761 Hamburg, Germany
3Center for Free Electron Laser Science, 22761 Hamburg, Germany
4Centre of Excellence in Quantum Information,
Computation, Science and Technology,
Indian Institute of Technology Bombay, Powai, Mumbai 400076, India
5Quantum Technology Laboratory ⟨Q|T|L⟩,
Department of Electrical Engineering and Computer Science,
Syracuse University, Syracuse, NY, USA
Abstract
Advancementsinopticalquantumtechnologieshavebeenenabledbythegeneration, manipulation, and
characterizationoflight,withidentificationbasedonitsphotonstatistics. However,characterizinglightand
its sources through single photon measurements often requires efficient detectors and longer measurement
times to obtain high-quality photon statistics. Here we introduce a deep learning-based variational au-
toencoder(VAE)methodforclassifyingsinglephotonaddedcoherentstate(SPACS),singlephotonadded
thermal state (SPACS), mixed states between coherent/SPACS and thermal/SPATS of light. Our semi-
supervisedlearning-basedVAEefficientlymapsthephotonstatisticsfeaturesoflighttoalowerdimension,
enabling quasi-instantaneous classification with low average photon counts. The proposed VAE method
is robust and maintains classification accuracy in the presence of losses inherent in an experiment, such
as finite collection efficiency, non-unity quantum efficiency, finite number of detectors, etc. Additionally,
leveraging the transfer learning capabilities of VAE enables successful classification of data of any qual-
ity using a single trained model. We envision that such a deep learning methodology will enable better
classificationofquantumlightandlightsourceseveninthepresenceofpoordetectionquality.
∗CorrespondenceandrequestsformaterialsshouldbeaddressedtoP.K.J(pkjha@syr.edu)
1
4202
yaM
8
]hp-tnauq[
1v34250.5042:viXraI. INTRODUCTION
Thedevelopmentofnoveltechnologiesthatallowforthegeneration,manipulation,andcharacter-
ization of quantum states of light has led to a substantial advancement in the field of quantum op-
tics in recent years [1–7] with applications spanning quantum communication, cryptography, and
sensing [8–10]. Different quantum states of light have distinctive properties that make them more
suitable for particular applications [11–14]. For instance, photon-added coherent states [15, 16]
denotedby|α,m⟩,wheremphotonsareaddedtothesamemodeasacoherentstate|α⟩viastimu-
lated emission, have applications ranging from quantum sensing [17, 18] and quantum key distri-
bution [19, 20] to understanding fundamentals of quantum physics [21–23]. Quasi-instantaneous
identification and characterization of quantum states of light at the single photon level is one of
thechallengesofworkingwiththem.
Recent research has demonstrated the potential of deep learning algorithms in nanophoton-
ics[24–29],quantumoptics[30]andquantumcomputing[31]. Thedeeplearningmethods,dense
neural networks (NNs), can be used to classify different quantum states of light accurately [32–
36]. These algorithms are trained on simulated or experimental data of varying average photon
statistics and sample sizes allowing them to learn the features that distinguish one quantum light
state from another. In scenarios where the photon count is low or the photon counting detector
is inefficient, the classification of distinct quantum light sources can pose a challenge for deep
learningalgorithmsduetoalackofinformation-richstatistics. Toovercomethislimitation,artifi-
cialneuralnetworkshavebeenutilizedtoidentifyquantumlightsources,asdemonstratedinprior
work [32, 36]. As the average photon count and measurement binsize change, the information
encodingalsochanges,makingitnecessarytotrainmultiplemodelsfordifferentphotonstatistics
scenarios. A successful distinction of quantum light sources requires exploring the statistical in-
formation change with varying average photon counts and binsize. To achieve this, a latent space
representation that encapsulates information over multiple datasets could provide better informa-
tionfeaturesfortheclassificationofquantumlightsources.
In this paper, we propose and implement a deep learning-based variational autoencoder (VAE)
method to classify non-classical states of light generated by single photon addition to an initial
coherent and thermal via stimulated emission. These non-classical states of light are also known
assinglephoton-addedcoherentstates(SPACS)andsinglephoton-addedthermalstates(SPATS),
respectively. Suchsourcesareusefulforhigh-bit-ratecommunicationandquantumstateengineer-
2ing[21,37–41]. Ourproposedmethodemploysasemi-supervisedlearningapproachtoefficiently
classify SPATS and SPACS. In this work, for simplicity, we focused on states of a single quan-
tizedfieldmodeofcoherentandthermallight. Usingavariationalautoencoder(VAE),thephoton
statistics features of the quantum states of light are mapped to a lower dimensional latent space,
enablingclassificationwithlowphotoncountsandshortermeasurementtimes. TheVAEistrained
over multiple datasets, each with different average photon counts, resulting in a well-behaved la-
tent space that can be used for classification using another neural network (a classifier). This
approach is robust and maintains classification accuracy despite experimental losses, such as fi-
nite collection efficiency and non-unity quantum efficiency, and finite number of the detectors.
Moreover, the transfer learning capabilities of VAE allow the successful classification of data of
any quality witha singletrained model. Our method has the potentialto significantly enhance the
classification of quantum light and light sources, even under conditions of poor detection qual-
ity. The importance of efficient state classification in quantum technology is increasing, and the
methodology introduced, exemplified by SPACs, SPATs, Coherent, Thermal, and mixed states,
could pave the way for efficient classification of light sources. Studies [42, 43] highlight the role
of quantum state discrimination in quantum optics experiments and the practical implications of
quantumstateclassificationinenhancingmeasurementprecision.
II. METHOD
Figure 1 shows the simple schematic of photodetection using four click-counting detectors.
Heretheincominglowfluxlight(SPACS/SPATS/thermal/coherent/mixed)isredistributedequally
amongthedetectorsusing50/50beamsplitters.
A. Datasetgeneration.
We will begin by considering light in pure SPACS and SPATS. The probability of finding n
photonsinSPACSandSPATSisgivenbyEquations(1,2),respectively[20].
e−|α|2 (cid:20) |α|2(n−1) |α|2(n−2)(cid:21)
P(1+)(n) = +|α|2 (1)
|α⟩ 1+|α|2 (n−1)! (n−2)!
 
n¯n−1 n
P(1+)(n) =  (n ≥ 1) (2)
th (1+n¯)n+1
1
3where (1+) denotes single photon addition to the input coherent and thermal states with initial
mean photon number n¯. Equation (1) shows a combination of two shifted and scaled Poissonian
distributions,wherethefirstandsecondtermscorrespondtoshiftsbyoneandtwophotons,respec-
tively,totheinitialcoherentstatewithn¯ = |α|2. Ontheotherhand,Equation(2)correspondstoa
negativebinomialdistributionforthephotonnumberinSPATS,whereforn < 1theprobabilityis
0. Inexperiments,wecanalsogeneratemixedstatebetweencoherent/SPACSandthermal/SPATS.
Employing the density operator approach to denote a mixed state, for instance, a mixed state be-
tween coherent (|α⟩) and SPACS (|α,1⟩) with the probability r and (1−r) respectively is given
bytherelation[44]:
ρˆ = r|α⟩⟨α|+(1−r)|α,1⟩⟨1,α| (3)
(|α⟩;|α,1⟩)
Now,theprobabilityoffindingnphotonsinthefieldisgivenby
p(n) = ⟨nˆ|ρˆ |nˆ⟩ (4)
(|α⟩;|α,1⟩)
where nˆ is the number operator. Similar expression can be written for the mixed state between
thermal and SPATS. Using Eqs.(1-4), a substantial dataset containing 108 data points was gener-
ated, with each bin having a size of τ . The dataset included bins with statistical photon counts
b
ranging from 0 to 6 for each bin. We chose to limit the upper bound of photon numbers to 6
based on the observation that higher photon probabilities have a minimal effect on classification,
especially for small n¯. To achieve accuracy, probabilities were computed up to P(6) during the
simulation,however,probabilitiesuptoP(4)weresufficient.
B. LossesinDataset.
The overall detection efficiency of the system is determined by the combined effect of linear
propagationlossesandthe photodetectorquantumefficiency. This canberepresentedmathemati-
cally using Equation (5), where P (n) is the probability of detecting n photons due to losses, and
r
P (m) is the probability of finding m photons [45] in the ideal lossless scenario. The parame-
i
ter η represents the detection efficiency, and the summation accounts for all possible numbers of
photonsthatcanbedetected.
∞ (cid:18) (cid:19)
(cid:88) m
P (n) = ηn(1−η)m−nP (m) (5)
r i
n
m=n
4However,inreality,thereexistsadeadtime(τ ≃100ns)fortypicalSi-basedsingle-photondetec-
D
tors,whichmeansthateachdetectionchannelcannotdetectmorethanonephotonwithinthistime
interval. As a result, a non-linear relationship exists between the detected photon statistics and
thesourcephotonstatistics,andthenumberofdetectedphotonsinonebinsizecannotexceedthe
number of detectors. To address this issue, a low photodetection rate was considered (R ≪ τ−1)
D
to reduce the impact of the detector deadtime. By doing so, one can obtain more accurate and
reliabledatafromthedetectors.
C. SimulatingN detectors.
We employed a multinomial expansion approach to account for losses in a system with N
detectors and m photons [45]. In this approach, each sensor d was modeled as having a certain
i
numberofphotonsk hittingit,wherek representsthenumberofphotonsreceivedbyithdetector.
i i
Equation(6)describesthemultinomialexpansionasfollows:
(cid:18) (cid:19) N
(cid:88) N (cid:89)
(d +d +...+d )m = dki (6)
1 2 N k ,k ,...,k i
(cid:80)ki=m&ki≥0 1 2 N i=1
Todeterminetheprobabilityofexactlynphotonsbeingdetected,thesumofthecoefficientsofall
termsinthemultinomialexpansioniscalculatedwithexactlynnon-zerok anddividedbythesum
ofallcoefficients. Togeneratesimulateddata,wecomputedthetheoreticalprobabilitydistribution
that accounted for both types of losses. We calculated the theoretical probability of having n
photons P (n) for 0 ≤ n ≤ 20, and ignored P (n) for n > 20 as it’s below a certain threshold
i i
that can be ignored for the simulation. This is done by ensuring that the (cid:80) P (n) ≤ 10−6. We
i
n>20
thenincorporatedthequantumefficiencyusingEquation(5)andthedeadtimelossusingEquation
(6). The probability of detecting n photons using N sensors was calculated using the following
equations:
S = {K : k > 0} (7)
i
(cid:80) (cid:0) N (cid:1)
C(n,j) =
len(S)=n&(cid:80)ki=j
k1,k2,...,kN
(8)
Nj
(cid:88)
P (n) = C(n,j)∗P (j) (9)
o i
j≥n
In the above equations, S represents the set of all combinations of detectors that detect photons.
C(n,j) represents the sum of the coefficients of all terms in the multinomial expansion with ex-
actly n non-zero k and with a sum of j. In other words, C(n,j) represents if the emitter emitted
5j photons then the probability of it being received at n detectors (a detector can receive multiple
photons,butitcannotstatehowmany. Therefore,wecounteachdetectionasasinglephoton,even
ifitmayhavebeenmultiplephotonsthatwerereceived). Finally,P (n)representstheprobability
o
of detecting n photons. After calculating the final probability incorporating losses, we generated
108 datapoints based on the probability distribution. We then binned the dataset and calculated
P (0),P (1),...,P (6), and n¯ , which represent the probabilities of detecting 0 to 6 photons and
o o o o
themeannumberofphotonsobserved,respectively. Thesevalues,alongwiththebindataforeach
bin,wereusedastrainingdata. Atotalof2000trainingdatapointsforeachbinsize.
D. NetworkandTraining.
The VAE is an unsupervised deep learning technique used for generating new data from an
existing dataset by extracting a compact and organized representation of the input data [46]. The
VAE model has two main components: encoder and decoder. The encoder takes input data and
generates a latent representation that represents the input data in a condensed and structured for-
mat. On the other hand, the decoder takes the latent representation as input and reconstructs the
original input, aiming to produce an accurate reconstruction of the input data. The VAE model
employed in this study, as shown in Figure 2 (a), is composed of three primary components: the
encoder,thedecoder,andaclassifier. Tobegin,theencoderreceivesthephotonnumberprobabil-
ities represented by P(X) at the input nodes, where X=(0,1,...,4). The input data is then processed
through a series of dense layers with a scaled exponential linear unit (SELU) activation function,
batchnormalization,anddropout,collectivelyformingtheencodernetwork. Thefinaldenselayer
outputcomprisesofthemeanµandσ valuesofthelatentrepresentation. Thesevaluesareutilized
to sample from a normal distribution, which is subsequently used as the latent representation (Z),
alsoknownasthebottleneckoftheVAE.
The latent representation (Z), which is obtained from the bottleneck layer, is fed into the de-
coder to reconstruct the input data. The decoder is made up of dense layers with SELU activation
function,batchnormalization,anwriteddropout,similartotheencoder. Thefinaldenselayerpro-
duces the reconstructed input data. During training, both the encoder and decoder networks are
trained to minimize the reconstruction loss. After obtaining the latent representation, the classi-
fier takes it as input and predicts the class label. In this study, the classifier is trained to classify
SPATS or SPACS by minimizing the classification loss. It uses the latent representation Z to pro-
6duce a scalar output that indicates whether the input data belongs to a certain class or not. The
classifiercomprisesdenselayerswithleakyrectifiedlinearunit(LeakyReLU)activationfunction,
batch normalization, and dropout. The VAE model used in this study employs a loss function
that combines two terms: reconstruction loss and Kullback-Leibler (KL) divergence loss. The
reconstructionlossassessesthedissimilaritybetweentheoriginalinputdataandthereconstructed
output from the decoder. On the other hand, the KL divergence loss measures the variation be-
tweenthedistributionofthelatentrepresentationgeneratedbytheencoderandastandardnormal
distribution. By using this loss function, the VAE model is trained to produce diverse and realis-
tic data by encouraging the encoder to produce latent representations that are close to a standard
normal distribution. Additionally, the sharing of the bottleneck layer between the VAE and the
classification model (classifier) allows the VAE to learn a latent representation that is appropriate
for both reconstruction and classification tasks. This is particularly useful for complex data that
have high dimensions or structures. During the training process, both the VAE and the classifica-
tion model losses are simultaneously minimized by summing the VAE loss and the classification
loss.
L = L +L +L (10)
total recon KL BCE
where L is the reconstruction loss, L is the KL divergence loss, and L is the binary
recon KL BCE
crossentropylossfortheclassificationtask.
Here,reconstructionloss[46]:
N d
1 1 (cid:88)(cid:88)
L = − (x −xˆ )2, (11)
recon ij ij
N d
i=1 j=1
where N is the number of samples, d is the dimensionality of the data, x is the j-th component
ij
ofthei-thinputsample,andxˆ isthecorrespondingreconstructedvalue.
ij
KLdivergenceloss[46]:
N d
1 (cid:88)(cid:88) (cid:0) (cid:1)
L = − [1+log σ2 −µ2 −σ2], (12)
KL 2N j j j
i=1 j=1
where µ and σ2 are the mean and variance of the j-th component of the latent representation,
j j
respectively.
Binarycrossentropyloss[47]:
1
(cid:88)NL
L = − [y log(yˆ)+(1−y )log(1−yˆ)], (13)
BCE i i i i
N
L
i=1
7where N is the number of labeled samples, y is the true class label of the i-th labeled sample
L i
(either0or1),andyˆ isthepredictedprobabilityofthei-thsamplebelongingtoclass1.
i
In this VAE model, various hyperparameters were utilized to achieve the desired performance.
Thesehyperparametersincludethenumberofnodesinthedenselayers,thedropoutrate,thetype
ofactivationfunctions,andthelearningrate. Theencoderconsistsofdenselayerswith16,32,64,
32, and 16 nodes, respectively, while the decoder has 8, 16, 32, 16, and input nodes. A dropout
rateof0.2wasimplementedintheencoder,decoder,andclassifier. Theencoderanddecoderwere
both set to use the SELU activation function, while the classifier used the LeakyReLU activation
function. During training, a batch size of 512 was used with a learning rate of 0.001 for the VAE
model. Moreover, by employing a fixed seed for the random initialization of the VAE, we ensure
consistent initial conditions for each run, thus aiding in replicable results and mitigating the risk
ofconvergencetolocalminima(seeSupplementaryInformation).
III. SIMULATIONEXPERIMENTS
A. LosslessData
Transfer learning is a deep learning training methodology where features learned from one
datasetaretransferredandappliedtoanotherrelateddataset. Heretransferlearningwasemployed
to improve the accuracy and generalization of the VAE model trained on the lossless dataset,
particularlywhendealingwithdifferentbinsizes. InitialtrainingofVAEmodelisdoneonalarger
binsizeof100observationsperbin. Thischoicewasmadetocapturemoreinformationaboutthe
data distribution. During this training phase, the encoder, decoder, and classifier networks were
optimizedtoreconstructtheinputdataaccuratelyandclassifyitbetweenSPATSandSPACS.After
the initial training on the larger bin-sized data, the model was fine-tuned using smaller bin-sized
data. This process involved taking the pre-trained weights of the model obtained from the initial
training and continuing the training process using the smaller bin-sized data. By fine-tuning the
model on smaller bin sizes, it allows the model to adapt and improve its performance specifically
ondatawithsmallerbinsizes. Thefine-tuningprocessenablesthemodeltotransfertheknowledge
itlearnedfromtheinitialtrainingonlargerbinsizestothesmallerbin-sizeddata. Thepre-trained
weights of the model serve as a starting point for the fine-tuning process. As the model continues
8trainingonthesmallerbin-sizeddata,itadjustsitsparameterstobettersuitthecharacteristicsand
distributions of the smaller bin sizes. This knowledge transfer helps improve the accuracy and
performance of the model on smaller bin-sized data. Finally, validation is done on test dataset
to evaluate the model’s ability to generalize across different bin sizes. This test dataset likely
contained smaller bin sizes than the training data. The model’s performance on this test dataset
wasassessedtodetermineitsgeneralizationcapability. Themodelperformswellonthetestdataset
with smaller bin sizes, indicating the effectiveness of the transfer learning approach in improving
the model’s accuracy and robustness across different bin sizes. By combining the initial training
onlargerbinsizes,fine-tuningwithsmallerbin-sizeddata,andvalidatingthemodel’sperformance
on a test dataset, this transfer learning approach helped enhance the accuracy and generalization
oftheVAEmodel. Thepseudo-codeimplementationismentionedinAlgorithm1.
Algorithm1:Losslessdata,Idealcase
TrainingPhase:
Input: ProbabilitydistributionX :[P(0),P(1),P(2),P(3),P(4)]
Output: ClassY andreconstructionofX asXˆ
1. PredictsclassandreconstructstheX asXˆ
2. ComputeBCElossbetweenpredictedclassandgroundtruthclass(SPACS/SPATS)
3. Computereconstructionloss(MSE)andKLDivergenceloss[46]
4. Optimizethemodelusingallthreelossesuntilconvergence.
TestingPhase:
Input: ProbabilitydistributionX :[P(0),P(1),P(2),P(3),P(4)]
Output: ClassY andEmbeddingofX frombottlenecklayerasZ
B. Datawithlosses
The training scheme for the VAE model, which takes into account losses, begins with a data
processing step that involves carefully selecting training data. This step is crucial to ensure the
applicability of the model to various bin sizes and efficiencies. To improve the generalization
capabilitiesofthemodel,wehavechosenalargerbinsizeof200observations. Thisdecisionpro-
vides the model with a wider range for classifying data, eliminating the need for multiple models
9tohandledifferentusecasesorminorchangesinlosses. Toenhancethemodel’sflexibilityinhan-
dling diverse data, we have introduced an additional input parameter called the observed average
photon number (n¯ ), which is incorporated alongside the probability distribution. By including
obs
n¯ as an input, the model becomes capable of handling a wide range of observable average pho-
obs
ton number values, regardless of the corresponding theoretical n¯ and quantum efficiency. This
the
accounts for the effect of quantum loss in the system, as the correlation between n¯ and n¯
obs the
captures this relationship. In order to generate the training dataset, we determine the range of the
target observable average photon number (n¯ ). From this range, we select corresponding theo-
obs
retical n¯ values and quantum efficiencies. By plotting observable n¯ against theoretical n¯ ,
the obs the
we can choose the desired theoretical n¯ and quantum efficiency pairs. This approach allows
the
the model to effectively generalize across different observable n¯ values and account for varia-
obs
tions in theoretical n¯ and quantum efficiency. Subsequently, we train the VAE model using this
the
dataset, incorporating the observed n¯ and the probability distribution. The encoder, decoder,
obs
and classifier networks of the model are optimized to minimize the reconstruction loss and clas-
sification loss. This training process equips the model with the ability to accurately reconstruct
input data while effectively classifying between SPATS and SPACS. For detailed information on
theimplementationofthistrainingscheme,pleaserefertoAlgorithm2.
Algorithm2:Incorporationofobservedaveragephotonnumber,n¯
obs
TrainingPhase:
Input: Probabilitydistributionandn ,X : [P(0),P(1),P(2),P(3),P(4),n ]
obs obs
Output: ClassY andreconstructionofX asXˆ
1. PredictsclassandreconstructstheX asXˆ
2. ComputeBinaryCross-entropylossbetweenpredictedclassandgroundtruthclass
(SPACS/SPATS)
3. Computereconstructionloss(MSE)andKLDivergenceloss[46]
4. Optimizethemodelusingallthreelossesuntilconvergence.
TestingPhase:
Input: Probabilitydistributionandn ,X : [P(0),P(1),P(2),P(3),P(4),n ]
obs obs
Output: ClassY andEmbeddingofX frombottlenecklayerasZ
10IV. RESULTSANDDISCUSSION
Figure2presentsacomparisonbetweentwomethodsforanalyzingtheprobabilitydistributionof
photonstatisticsofSPATSandSPACS.Initially,weemployedthet-DistributedStochasticNeigh-
borEmbedding(t-SNE)algorithm,apopularmultidimensionalscalingtechnique[48],tovisually
represent our high-dimensional data. The purpose of t-SNE is to reduce dimensions while pre-
serving the similarity structure within the data, with the expectation that it would allow us to
differentiatebetweenthetwoclassesofphotonstatistics. Afterrunningt-SNEfor1000iterations,
weobtaineda3-dimensionalrepresentationthatrevealedasignificantoverlapbetweentheSPATS
and SPACS classes. t-SNE has inherent limitations related to the possibility of different global
structures within the data. This variation in global structures could result in the convergence of
datapointsfromdifferentclasses,leadingtooverlappingclusters. Furthermore,t-SNEissensitive
to its hyperparameters, and the selection of these parameters can greatly affect the resulting visu-
alization. Theoverlapobservedinouranalysismay,inpart,beattributedtosuboptimalparameter
settings. Adjusting these parameters, such as the perplexity value or the learning rate, yields such
best-observed separability between the two classes. Moreover, the nature of our dataset, which
encompasses different average photon numbers and measurement bin sizes, poses a challenge for
t-SNE. The changing photon statistics information across these variations makes it difficult for
t-SNE to effectively capture such features. As a consequence, t-SNE proves to be inefficient in
representing the diverse range of photon statistics present in the data. The 2D t-SNE visualiza-
tion of full photon statistics data, distinguished by different photon counts and bin sizes higlights
substantial overlap between SPATS and SPACS classes, complicating effective classification (see
Supplementary). Incontrast,theimplementationoftheVAEmethodoffersamoredistinctiverep-
resentationofthedatasetwithinthelatentspace. TheVAEmodelwastrainedonmultipledatasets,
encompassingvariousaveragephotonnumbersandmeasurementbinsizes. Thistrainingapproach
enables the VAE to capture a broader range of photon statistics, resulting in a latent space with
distinguishablefeaturesanddiscernibleboundaries. Consequently,theVAEmethoddemonstrates
superiorityinhandlingsuchcomplexdataforclassificationpurposes.
In Figure 3(b), we explore the relationship between classification accuracy and bin size using
lossless data, with an average photon number (n¯) = 1.3. As the bin size increases, so does the ac-
curacy, indicative of an intrinsic relationship between these two variables. However, the accuracy
plateausbeyondacertainbinsize. Thissaturationeffectcanbeattributedtotheinherentnatureof
11photon statistics; larger bins, corresponding to longer observation times, allow for a more precise
representation of the photon distribution. Yet, beyond a certain point, the additional information
gained does not improve the ability of the model to classify the sources. Despite this, it is worth
highlighting that our classification algorithm performs robustly even with smaller bins. This is
demonstrated by the maintaining of over 65% accuracy using a bin size = 50 with a single model
trainedacrossmultipledatasetsofaveragephotonnumberandbinsizeandthentestedonn¯ =1.3.
This promising result suggests the algorithm’s potential efficiency even when dealing with sparse
datapoints,whichmightbeespeciallyrelevantinreal-worldapplicationswherehigh-volumedata
collectionisnotalwaysfeasible.
Figure 4(a) provides insights into the relationship between the theoretical mean photon number
n¯ and the corresponding observed n¯ values for four sensors, each characterized by a specific
the obs
quantum efficiency. Notably, at higher n¯ values, saturation occurs, likely due to the fixed number
of sensors utilized in the simulation. This saturation phenomenon emphasizes the significance of
carefully selecting the number of sensors in the experimental setup to mitigate the sensor “dead
time” effect and maximize the extraction of information from the light source. In Figure 4(b), we
investigatetheaccuracyofthemodelasafunctionofquantumefficiency,usingfoursensorsanda
fixedbinsizeof200. Remarkably,themodeldemonstratesconsistentperformanceacrossarange
ofquantumefficiencies. However,anotabledegradationinperformanceoccurswhenthequantum
efficiency falls significantly below 0.2, which is a consequence of using a single photon source.
This deterioration suggests the presence of a critical threshold below which the signal-to-noise
ratio may decline to a level where distinguishing between the probability distributions for SPACS
andSPATSbecomeschallenging,leadingtoerroneousclassification.
Next, we present a performance analysis shows performance analysis of the classifier network
within the VAE framework, demonstrating its accuracy across different bin sizes (Figure 5) and
observedmeanphotonnumbers,n¯ (Figure6). TheVAEmodelwastrainedusingsimulateddata
obs
generatedforatheoreticalmeanphotonnumberofn¯ =1.9andafixedbinsizeof200. Notably,
the
duringthedatagenerationstep,weincorporatedlosseffectsbyconsideringvaryingquantumeffi-
cienciesof0.9,0.8,and0.6. Byincorporatingthesedifferentquantumefficiencies,weconstructed
a diverse training dataset that encompassed a broad range of observed mean photon number val-
ues,rangingfrom1.45to1.16. Thisdeliberatevariationaimedtoenhancetheabilityofthemodel
togeneralizewellacrossdifferentscenarios. Remarkably,ourtrainedmodelexhibitedexceptional
generalization capabilities, consistently achieving high classification performance across varying
12bin sizes and observed mean photon numbers. This robust performance was particularly notewor-
thy given the relatively limited size of our training dataset. The ability of model to maintain its
classificationperformancedespitechangesinbinsizeandobservedmeanphotonnumbersimplies
itsadaptabilityviatransferlearningwhichisacrucialfeatureforpracticalimplementation,asreal-
world conditions often exhibit inherent variations. In Figure 7, we demonstrate the architecture’s
adaptability to new tasks. Here, we analyze four different types of photon sources: mix-SPAC
(a mixture of coherent and SPAC sources, where the Y-axis represents its mix ratio), mix-SPAT
(a mixture of thermal and SPAT sources, where the X-axis represents its mix ratio), Coherent,
and Thermal. As the mix ratio approaches 1, mix-SPAC becomes predominantly Coherent, and
mix-SPAT becomes predominantly Thermal, as indicated by Eqs. (3,4). This results in low clas-
sification accuracy, as expected. However, the architecture achieves over 90% for mix ratios less
than0.8,demonstratingitsrobustnessintheclassificationtask.
V. CONCLUSIONS
The development of deep learning-based algorithms has demonstrated great potential in the field
of quantum optics. Here, a deep learning-based method was proposed and implemented for the
efficient classification of non-classical states of light, specifically SPACS and SPATS, which are
valuable for various applications such as high-bit-rate communication, and quantum state engi-
neering. The proposed method employed a semi-supervised learning approach using a VAE to
map photon statistics features to a lower-dimensional latent space. The VAE was trained over
multiple datasets with different average photon counts, resulting in a well-behaved latent space
that was robust and maintained classification accuracy even under conditions of poor detection
quality. ThesimulationexperimentalresultsshowedthattheVAEwassuccessfulindistinctlyrep-
resentingthedatasetinthelatentspace,andtheclassificationalgorithmperformedwellevenwith
very few observations through transfer learning approach. The proposed method has the potential
tosignificantlyenhancetheclassificationofquantumlightsources[49–51],especiallyundercon-
ditions of poor detection quality, which is an important step toward the development of practical
quantumcommunication,sensing,andcomputingtechnologies.
13acknowledgements
A.K. acknowledges funding support from the Department of Science and Technology via the
grants: CRG/2022/001170, ECR/2018/001485, and DST/NM/NS-2018/49. P. K. Jha acknowl-
edges the unrestricted gift from Google and the Syracuse University Start-up Funds, which par-
tiallysupportedthisproject.
AuthorInformation
∗Towhomallcorrespondenceshouldbeaddressed. pkjha@syr.edu
†M.BhupatiandA.Mallcontributedequallytothiswork
14[1] ChristopherMonroeandJungsangKim,“Scalingtheiontrapquantumprocessor,”Science339,1164–
1169(2013).
[2] HJeffKimble,“Thequantuminternet,”Nature453,1023–1030(2008).
[3] Hyukjoon Kwon, Kok Chuan Tan, Tyler Volkoff, and Hyunseok Jeong, “Nonclassicality as a quan-
tifiableresourceforquantummetrology,”Physicalreviewletters122,040503(2019).
[4] PVanLoock,TDLadd,KSanaka,FYamaguchi,KaeNemoto,WJMunro, andYYamamoto,“Hybrid
quantumrepeaterusingbrightcoherentlight,”Physicalreviewletters96,240501(2006).
[5] FulvioFlamini,NicoloSpagnolo, andFabioSciarrino,“Photonicquantuminformationprocessing: a
review,”ReportsonProgressinPhysics82,016001(2018).
[6] Paul-AntoineMoreau, ErmesToninelli, ThomasGregory, andMilesJPadgett,“Imagingwithquan-
tumstatesoflight,”NatureReviewsPhysics1,367–380(2019).
[7] DietrichLeibfried,MurrayDBarrett,TSchaetz,JosephBritton,JChiaverini,WayneMItano,JohnD
Jost,ChristopherLanger, andDavidJWineland,“Towardheisenberg-limitedspectroscopywithmul-
tiparticleentangledstates,”Science304,1476–1478(2004).
[8] JonathanPDowling,“Quantumopticalmetrology–thelowdownonhigh-n00nstates,”Contemporary
physics49,125–143(2008).
[9] Christian L Degen, Friedemann Reinhard, and Paola Cappellaro, “Quantum sensing,” Reviews of
modernphysics89,035002(2017).
[10] IlanKremer,Quantumcommunication(Citeseer,1995).
[11] MichaelANielsenandIsaacChuang,“Quantumcomputationandquantuminformation,” (2002).
[12] NicolasGisinandRobThew,“Quantumcommunication,”Naturephotonics1,165–171(2007).
[13] TakafumiOno,RyoOkamoto, andShigekiTakeuchi,“Anentanglement-enhancedmicroscope,”Na-
turecommunications4,2426(2013).
[14] Gabriela Barreto Lemos, Victoria Borish, Garrett D Cole, Sven Ramelow, Radek Lapkiewicz, and
AntonZeilinger,“Quantumimagingwithundetectedphotons,”Nature512,409–412(2014).
[15] GSAgarwalandKTara,“Nonclassicalpropertiesofstatesgeneratedbytheexcitationsonacoherent
state,”PhysicalReviewA43,492(1991).
[16] GSAgarwalandKTara,“Nonclassicalcharacterofstatesexhibitingnosqueezingorsub-poissonian
statistics,”PhysicalReviewA46,485(1992).
15[17] Roman Schnabel, “Squeezed states of light and their applications in laser interferometers,” Physics
Reports684,1–51(2017).
[18] Daniel Braun, Pu Jian, Olivier Pinel, and Nicolas Treps, “Precision measurements with photon-
subtractedorphoton-addedgaussianstates,”PhysicalReviewA90,013821(2014).
[19] Gilles Van Assche, Quantum cryptography and secret-key distillation (Cambridge University Press,
2006).
[20] Stephen M Barnett, Gergely Ferenczi, Claire R Gilson, and Fiona C Speirits, “Statistics of photon-
subtractedandphoton-addedstates,”PhysicalReviewA98,013809(2018).
[21] Valentina Parigi, Alessandro Zavatta, Myungshik Kim, and Marco Bellini, “Probing quantum com-
mutation rules by addition and subtraction of single photons to/from a light field,” Science 317,
1890–1893(2007).
[22] Kosmas L Tsakmakidis, Pankaj K Jha, Yuan Wang, and Xiang Zhang, “Quantum coherence–driven
self-organizedcriticalityandnonequilibriumlightlocalization,”Scienceadvances4,eaaq0465(2018).
[23] KavehNajafian, ZivMeir, MuditSinhal, andStefanWillitsch,“Identificationofmolecularquantum
statesusingphase-sensitiveforces,”Naturecommunications11,4470(2020).
[24] Abhishek Mall, Abhijeet Patil, Dipesh Tamboli, Amit Sethi, and Anshuman Kumar, “Fast design of
plasmonicmetasurfacesenabledbydeeplearning,”JournalofPhysicsD:AppliedPhysics53,49LT01
(2020).
[25] Abhishek Mall, Abhijeet Patil, Amit Sethi, and Anshuman Kumar, “A cyclical deep learning based
framework for simultaneous inverse and forward design of nanophotonic metasurfaces,” Scientific
reports10,1–12(2020).
[26] Peter R Wiecha, Arnaud Arbouet, Christian Girard, and Otto L Muskens, “Deep learning in nano-
photonics: inversedesignandbeyond,”PhotonicsResearch9,B182–B200(2021).
[27] DavidePiccinotti,KevinFMacDonald,SimonAGregory,IanYoungs, andNikolayIZheludev,“Ar-
tificialintelligenceforphotonicsandphotonicmaterials,”ReportsonProgressinPhysics84,012401
(2020).
[28] KaiQu,KeChen,QiHu,JunmingZhao,TianJiang, andYijunFeng,“Deep-learning-assistedinverse
designofdual-spin/frequencymetasurfaceforquad-channeloff-axisvorticesmultiplexing,”Advanced
PhotonicsNexus2,016010(2023).
[29] Mohammadreza Zandehshahvar, Yashar Kiarashinejad, Muliang Zhu, Hossein Maleki, Tyler Brown,
andAliAdibi,“Manifoldlearningforknowledgediscoveryandintelligentinversedesignofphotonic
16nanostructures: breakingthegeometriccomplexity,”ACSPhotonics9,714–721(2022).
[30] VojteˇchHavl´ıcˇek,AntonioDCo´rcoles,KristanTemme,AramWHarrow,AbhinavKandala,JerryM
Chow, and Jay M Gambetta, “Supervised learning with quantum-enhanced feature spaces,” Nature
567,209–212(2019).
[31] Siddhant Garg and Goutham Ramakrishnan, “Advances in quantum deep learning: An overview,”
arXivpreprintarXiv:2005.04316 (2020).
[32] Chenglong You, Mario A Quiroz-Jua´rez, Aidan Lambert, Narayan Bhusal, Chao Dong, Armando
Perez-Leija,AmirJavaid,RobertodeJLeo´n-Montiel, andOmarSMagan˜a-Loaiza,“Identificationof
lightsourcesusingmachinelearning,”AppliedPhysicsReviews7,021404(2020).
[33] Shahnawaz Ahmed, Carlos Sa´nchez Mun˜oz, Franco Nori, and Anton Frisk Kockum, “Classification
and reconstruction of optical quantum states with deep neural networks,” Physical Review Research
3,033278(2021).
[34] Zhaxylyk A Kudyshev, Simeon I Bogdanov, Theodor Isacsson, Alexander V Kildishev, Alexandra
Boltasseva, and Vladimir M Shalaev, “Rapid classification of quantum sources enabled by machine
learning,”AdvancedQuantumTechnologies3,2000067(2020).
[35] ValentinGebhart,MartinBohmann,KarstenWeiher,NicolaBiagi,AlessandroZavatta,MarcoBellini,
and Elizabeth Agudelo, “Identifying nonclassicality from experimental data using artificial neural
networks,”PhysicalReviewResearch3,023229(2021).
[36] Valentin Gebhart and Martin Bohmann, “Neural-network approach for identifying nonclassicality
fromclick-countingdata,”PhysicalReviewResearch2,023150(2020).
[37] Su-Yong Lee and Hyunchul Nha, “Quantum state engineering by a coherent superposition of photon
subtractionandaddition,”PhysicalReviewA82,053812(2010).
[38] ShuaiWang,Hong-yiFan, andLi-yunHu,“Photon-numberdistributionsofnon-gaussianstatesgen-
eratedbyphotonsubtractionandaddition,”JOSAB29,1020–1028(2012).
[39] JieLi,SimonGro¨blacher,Shi-YaoZhu, andGSAgarwal,“Generationanddetectionofnon-gaussian
phonon-addedcoherentstatesinoptomechanicalsystems,”PhysicalReviewA98,011801(2018).
[40] ET Burch, C Henelsmith, W Larson, and M Beck, “Quantum-state tomography of single-photon
entangledstates,”PhysicalReviewA92,032328(2015).
[41] Marco Bellini, Hyukjoon Kwon, Nicola Biagi, Saverio Francesconi, Alessandro Zavatta, and
MS Kim, “Demonstrating quantum microscopic reversibility using coherent states of light,” Physi-
calReviewLetters129,170604(2022).
17[42] Serge Haroche and J-M Raimond, Exploring the quantum: atoms, cavities, and photons (Oxford
universitypress,2006).
[43] VittorioGiovannetti,SethLloyd, andLorenzoMaccone,“Quantum-enhancedmeasurements: beating
thestandardquantumlimit,”Science306,1330–1336(2004).
[44] GirishS.Agarwal,QuantumOptics(CambridgeUniversityPress,2012).
[45] RomainAlle´aume,FrancoisTreussart,Jean-MichelCourty, andJean-FrancoisRoch,“Photonstatis-
ticscharacterizationofasingle-photonsource,”NewJournalofphysics6,85(2004).
[46] Diederik P Kingma and Max Welling, “Auto-encoding variational bayes,” arXiv preprint arXiv
1312.6114 (2013).
[47] IanGoodfellow,YoshuaBengio, andAaronCourville,Deeplearning(MITpress,2016).
[48] Laurens Van der Maaten and Geoffrey Hinton, “Visualizing data using t-sne.” Journal of machine
learningresearch9(2008).
[49] Hamidreza Akbari, Wei-Hsiang Lin, Benjamin Vest, Pankaj K Jha, and Harry A Atwater,
“Temperature-dependentspectralemissionofhexagonalboronnitridequantumemittersonconductive
anddielectricsubstrates,”PhysicalReviewApplied15,014036(2021).
[50] Pankaj K Jha, Hamidreza Akbari, Yonghwi Kim, Souvik Biswas, and Harry A Atwater, “Nanoscale
axialpositionandorientationmeasurementofhexagonalboronnitridequantumemittersusingatun-
ablenanophotonicenvironment,”Nanotechnology33,015001(2021).
[51] Hamidreza Akbari, Souvik Biswas, Pankaj Kumar Jha, Joeson Wong, Benjamin Vest, and Harry A
Atwater,“Lifetime-limitedandtunablequantumlightemissioninh-bnviaelectricfieldmodulation,”
NanoLetters22,7798–7803(2022).
18Low flux light
BS BS
1 2
D
1
BS
3 D
3
D
2
Photon distribution in each bin
BS: Beam Splitter
D: Click Detectors
D
4
Figure1: Experimentalsetupillustratingthedivisionofasingleincominglightbeamintofourequalpaths
usingthreebeamsplitters. Eachpathdirectslighttowardadedicatedclickdetector,registeringthenumber
of photons detected for a single instance. This process is repeated for n trials, where n represents the bin
size,yieldingadatasetofclickcounts. Analysisofthisdataproducesaprobabilitydistributionshowcasing
thelikelihoodofdetectingaspecificnumberofphotonsacrossallnsamples.
19(a)
t-SNE
(b)
VAE
Figure2: Distinctrepresentationofquantumstatesoflightinlow-dimensionalembeddingspace. Thelow-
dimensional embedding spaces for photon statistics data, showcase distinct representations of for SPATS
& SPACS across multiple average photon numbers. (a) The t-SNE model’s 3-component representation
illustrates a dense overlapping of data points clusters. (b) The 3D-latent space of the VAE model reveals
twodistinctdataclusterswithgoodseparation.
20(a) X<latexit sha1_base64="sQl4tVW2kZ45+CpC4nFgU5j+HMY=">AAAB73icbVDLSgNBEJz1GeMr6tHLYBA8hV3xdQx68RjBPCBZwuykNxkyO7vO9IphyU948aCIV3/Hm3/jJNmDJhY0FFXddHcFiRQGXffbWVpeWV1bL2wUN7e2d3ZLe/sNE6eaQ53HMtatgBmQQkEdBUpoJRpYFEhoBsObid98BG1ErO5xlIAfsb4SoeAMrdTqIDxh1hp3S2W34k5BF4mXkzLJUeuWvjq9mKcRKOSSGdP23AT9jGkUXMK42EkNJIwPWR/alioWgfGz6b1jemyVHg1jbUshnaq/JzIWGTOKAtsZMRyYeW8i/ue1Uwyv/EyoJEVQfLYoTCXFmE6epz2hgaMcWcK4FvZWygdMM442oqINwZt/eZE0TiveReX87qxcvc7jKJBDckROiEcuSZXckhqpE04keSav5M15cF6cd+dj1rrk5DMH5A+czx95XJBF</latexit> X<latexit sha1_base64="ABBeJZKCvn3i0ZgHGYxlNYMyMGw=">AAAB9XicbVBNS8NAEN3Ur1q/qh69BIvgqSTi17HoxWMF+wFtLJvtpF262YTdiVpC/ocXD4p49b9489+4bXPQ1gcDj/dmmJnnx4JrdJxvq7C0vLK6VlwvbWxube+Ud/eaOkoUgwaLRKTaPtUguIQGchTQjhXQ0BfQ8kfXE7/1AErzSN7hOAYvpAPJA84oGum+O6SYdhGeMG1nWa9ccarOFPYicXNSITnqvfJXtx+xJASJTFCtO64To5dShZwJyErdRENM2YgOoGOopCFoL51endlHRunbQaRMSbSn6u+JlIZaj0PfdIYUh3rem4j/eZ0Eg0sv5TJOECSbLQoSYWNkTyKw+1wBQzE2hDLFza02G1JFGZqgSiYEd/7lRdI8qbrn1bPb00rtKo+jSA7IITkmLrkgNXJD6qRBGFHkmbySN+vRerHerY9Za8HKZ/bJH1ifP1U4kxI=</latexit>ˆ
bottleneck
sX
encoder sampler Z decoder
µX
<latexit sha1_base64="zNu172r9KWQOWUdbSgpavov/AZI=">AAAB73icbVDLTgJBEOzFF+IL9ehlIjHxRHaNryPRi0dM5GFgQ2aHASbMzq4zvUay4Se8eNAYr/6ON//GAfagYCWdVKq6090VxFIYdN1vJ7e0vLK6ll8vbGxube8Ud/fqJko04zUWyUg3A2q4FIrXUKDkzVhzGgaSN4Lh9cRvPHJtRKTucBRzP6R9JXqCUbRSs438CdP7cadYcsvuFGSReBkpQYZqp/jV7kYsCblCJqkxLc+N0U+pRsEkHxfaieExZUPa5y1LFQ258dPpvWNyZJUu6UXalkIyVX9PpDQ0ZhQGtjOkODDz3kT8z2sl2Lv0U6HiBLlis0W9RBKMyOR50hWaM5QjSyjTwt5K2IBqytBGVLAhePMvL5L6Sdk7L5/dnpYqV1kceTiAQzgGDy6gAjdQhRowkPAMr/DmPDgvzrvzMWvNOdnMPvyB8/kDeuGQRg==</latexit>Y
classifier
(b)
0.9
0.8
0.7
0.6
0.5
0 50 100 150 200
Binsize
Figure3: ArchitectureandaccuracyofintroducedVAE.(a)SchematicrepresentationoftheVAEcombined
with a classifier network. The VAE consists of three main components: an encoder, a decoder, and a
classifier. The encoder takes the input data, denoted as X which comprises probabilities P of having
n
n photons in observation. Here, X is defined as [P ,P ,P ,...,P ], where n represents the number of
0 1 2 n
sensors, and generates a latent representation. The decoder takes this latent representation as input and
reconstructs the original data, resulting in Xˆ. The classifier utilizes the latent representation Z obtained
from thebottleneck layerand predictsthe classlabel forSPATS&SPACS. (b)Investigation ofthe impact
ofbinsizeontheclassificationaccuracyoftheclassifier intheVAEmodel. Theclassificationaccuracyis
assessed for varying numbers of binsizes, considering a simulated dataset with an average photon number
(n¯)=1.3,withoutanylosseffects.
21
ycaruccA
tupnI
tupni
detcurtsnoceR
ssalC(a)
2.0
[0.2]
[0.6]
[0.9]
1.5
1.0
0.5
0
1.0 1.5 2.0 2.5 3.0
Theoretical average photon, n
the
(b)
1.0
0.9
0.8
0.7
0.6
0.5
0 0.2 0.4 0.6 0.8 1.0
Quantum efficiency
Figure 4: Quantum loss and dead time effects on classification accuracy. (a) Illustrates the relationship
between the observed average photon number (n¯ ) and the theoretical average photon number (n¯ ) for
obs the
a fixed quantum efficiency of four sensors. In the simulations, an incoming beam was split into two equal
beamsusingabeamsplitter,eachhavinganequalprobabilityofcontainingaphoton. Subsequently,another
layerofbeamsplittersdividedthesetwobeamsintofourbeams,eachwithanequalprobabilityofcontaining
a photon. (b) Depicts the accuracy of the classifier in the VAE model as a function of quantum efficiency
for a n¯ = 1.9. As the observed average photon number increases with higher quantum efficiency, the
obs
classifierachievesimprovedaccuracy.
22
n
,notohp
egareva
devresbO
ycaruccA
sbo0.9
[0.9,1.45]
[0.8,1.31]
0.8 [0.7,1.16]
0.7
0.6
0.5
0 50 100 150 200
Binsize
Figure 5: Generalization of VAE performance across bin sizes and average observed photon number. The
plot shows the relationship between the accuracy of the classifier in the VAE model and the number of
binsizes in the simulated experiment. The curves depict the performance at an average theoretical photon
number(n¯ )of1.9,wheredifferentquantumefficienciesyieldvaryingobservedaveragephotonnumbers
the
(n¯ ). Each curve’s color represents the accuracy for different combinations of quantum efficiency and
obs
n¯ .
obs
23
ycaruccA0.9
0.8
0.7
0.6
0.5
0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6
Observed average photon, n<latexit sha1_base64="zyTSJnWXZnjkEyYBVgY82KGDL4c=">AAAB9HicbVBNSwMxEJ2tX7V+VT16CRbBU9kVqR6LXjxWsB/QLiWbZtvQbLJNsoWy7O/w4kERr/4Yb/4b03YP2vpg4PHeDDPzgpgzbVz32ylsbG5t7xR3S3v7B4dH5eOTlpaJIrRJJJeqE2BNORO0aZjhtBMriqOA03Ywvp/77SlVmknxZGYx9SM8FCxkBBsr+b0Aq1Rk/VQGOuuXK27VXQCtEy8nFcjR6Je/egNJkogKQzjWuuu5sfFTrAwjnGalXqJpjMkYD2nXUoEjqv10cXSGLqwyQKFUtoRBC/X3RIojrWdRYDsjbEZ61ZuL/3ndxIS3fspEnBgqyHJRmHBkJJongAZMUWL4zBJMFLO3IjLCChNjcyrZELzVl9dJ66rq1aq1x+tK/S6PowhncA6X4MEN1OEBGtAEAhN4hld4c6bOi/PufCxbC04+cwp/4Hz+AIFikpk=</latexit>¯
obs
Figure6: Theaccuracyisdirectlydependentonn¯ ,aswearedealingwithasinglephoton-addedsource.
obs
When n¯ < 1, it becomes very difficult to distinguish, as it is mostly noise and the loss is too significant
toidentifythesource. Asn¯ increases,theclassificationaccuracysaturatesaround90%. (binsize=200,
obs
n¯ > 1(singlephotonaddedsource),differentquantumefficienciesfordifferentn¯ )
the obs
24
ycaruccAProbability, r
1
Figure 7: The plot of classification accuracy among all four classes: mixSPAC, mixSPAT, Coherent, and
Thermalforgivenvaluesofr andr . Herethex-axisrepresentsmixSPAT(amixtureofThermalandSPAT
1 2
with the probability of r ), and the y-axis represents mixSPAC (a mixture of Coherent and SPAC with the
1
probability of r ). The strength of the proposed architecture lies in its adaptability to new data. For this
2
experiment, the observed mean photon number (n¯) was fixed at 1.3, and the bin size was set to 200. We
observethatthemodelcanadapttonewclasseswhilemaintainingsimilarperformanceforSPATandSPAC
withn¯ = 1.3asshowninFigure6.
obs
25
r
,ytilibaborP
2