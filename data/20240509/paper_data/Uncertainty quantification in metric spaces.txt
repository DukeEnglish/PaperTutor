Uncertainty quantification in metric spaces
GáborLugosi1,2,3 andMarcosMatabuena*4,5
1DepartmentofEconomicsandBusiness,PompeuFabraUniversity,Barcelona,Spain
2ICREA,Pg. LluísCompanys23,08010Barcelona,Spain
3BarcelonaGraduateSchoolofEconomics
4DepartmentofBiostatistics,HarvardUniversity,Boston,MA02115,USA
5UniversidaddeSantiagodeCompostela
May9,2024
Abstract
Thispaperintroducesanoveluncertaintyquantificationframeworkforregressionmodelswhere
the response takes values in a separable metric space, and the predictors are in a Euclidean space.
Theproposedalgorithmscanefficientlyhandlelargedatasetsandareagnostictothepredictivebase
model used. Furthermore, the algorithmspossess asymptotic consistency guaranteesand, in some
specialhomoscedasticcases,weprovidenon-asymptoticguarantees. Toillustratetheeffectiveness
oftheproposeduncertaintyquantificationframework, weusealinearregressionmodelformetric
responses(knownastheglobalFréchetmodel)invariousclinicalapplicationsrelatedtoprecisionand
digitalmedicine.Thedifferentclinicaloutcomesanalyzedarerepresentedascomplexstatisticalobjects,
includingmultivariateEuclideandata,Laplaciangraphs,andprobabilitydistributions.
Keywords: UncertainityQuantification;MetricSpaces;ConformalPrediction;FréchetMean;Precision
medicineapplications.
1 Introduction
1.1 Motivationandgoal
The increasing use of statistical and machine learning algorithms as predictive tools is transforming
[Banerjietal.,2023,Hammourietal.,2023,Matabuena,2022],anddigitalmarkets.Hence,ithasbecome
morecriticalthanevertoconductanuncertaintyanalysistocreatetrustworthypredictivemodelsand
validate their usefulness [Romanoetal.,2019]. Data analysts tend to focus on pointwise estimation
throughtheconditionalmeanbetweenaresponseandasetofpredictors,neglectingothercrucialaspects
oftheconditionaldistributionbetweentheinvolvedrandomvariables[Kneibetal.,2021]. Inorderto
quantifytheuncertaintyofthepointestimates,weneedtoestimateothercharacteristicsoftheconditional
distributionbeyondtheconditionalmean.
Aninnovativeapproachtotackleuncertaintyquantificationproblemsinvolvesemployingtheconformalin-
ferenceframework,firstintroducedbyGammerman,Vovk,andVapnikin1998[Gammermanetal.,1998].
Buildinguponthisfoundation,Vovk,Gammerman,andShaferhavemadesignificantcontributionstothe
*mmatabuena@hsph.harvard.edu
1
4202
yaM
8
]TS.htam[
1v01150.5042:viXrafield[Vovketal.,2005]. Conformalinferenceallowsonetoconstructpredictionsetswithnon-asymptotic
guarantees,settingitapartfromothermethodsthatonlyofferasymptoticguarantees.
However,despiteitsattractivepropertiesandadvantages,conformalinferencedoeshavesomelimitations
indifferentsettingsthatinclude:
1. ComputationalComplexity: Theimplementationofconformalinferencemethodscanbecom-
putationallyexpensive,especiallyifdata-splittingstrategiestoestimatetheunderlyingregression
model and prediction region (referred to as conformal-split in the literature) are not considered
[Vovketal.,2018,SolariandDjordjilovic´,2022].
2. Conservative Intervals: The method tends to produce conservative intervals if the regression
functionusedisnotwell-calibratedwithrespecttotheunderlyingmodel,oriftheconformalinfer-
encemethodismis-specified[Lu,2023](e.g.,usingahomoscedasticmodelwhentheunderlying
conditionaldistributionfunctionbetweentherandomresponsevariableY andtherandompredictor
X isgovernedbyheteroscedasticrandomerrors).
3. LimitedApplicability:Conformalinferencemayhavelimitedapplicability,particularlyinscenarios
withmultivariateresponsesorwhentheobserveddataisextractedfromcomplexsurveydesigns
wheretheexchangeabilityhypothesiscanbeviolated(see[Barberetal.,2023],whoquantifythe
impactofthisfactintermsofthetotalvariationdistancebetweendistributions).
4. Asymptotic Guarantees: In some special cases, other methods may provide stronger asymp-
toticguaranteescomparedtothealgorithmsderivedfortheconformalinferenceframework(see
[GyörfiandWalk,2019]foradiscussion).
Inthecontextofprecisionanddigitalmedicine,clinicaloutcomescantakeoncomplexstatisticalforms
suchasprobabilitydistributionsorgraphs[Matabuena,2022],andthereisnogeneralmethodologyavail-
abletoperformuncertaintyanalysisinsuchsettings. Forinstance,inthecaseofaglucosetimeseries,
a modern approach to summarizing the glucose profiles involves using a distributional representation
of the time series, such as their quantile functions. As prior research has shown, these new represen-
tations[GhosalandMatabuena,2023]cancaptureinformationaboutglucosehomeostasismetabolism
that traditional diabetes biomarkers cannot measure [Matabuenaetal.,2021a, Matabuenaetal.,2022a,
Ghosaletal.,2021a].
Thispaperproposesageneralmethodtoquantifyuncertaintyinregressionmodelingforresponsestaking
valuesinseparablemetricspaces[Fréchet,1948,PetersenandMüller,2019,Schötz,2021]andEuclidean
predictors. Thenewalgorithmscanhandlelargedatasetsefficiently,workindependentlyofthepredictive
base model fitted, and offer asymptotic consistency guarantees. We demonstrate the usefulness and
applicabilityofthenoveluncertaintyquantificationframeworkinpracticethroughseveralexamplesin
digitalandprecisionmedicine.
Below,weintroducethenotationandmathematicalconceptstodefinethenewuncertaintyquantification
framework.
1.2 Notationandproblemdefinition
Let(X,Y)∈X ×Y beapairofrandomvariablesthatplaytheroleofthepredictorandresponsevariable
in a regression model. We assume that X =Rp and Y is a separable metric space equipped with a
distanced . Weassumethatthereexistsy∈Y suchthatE(d2(Y,y))<∞. Theregressionfunctionmis
1 1
definedas
m(x)=argminE(d2(Y,y)|X =x), (1)
1
y∈Y
2where x∈Rp. In other words, m is the conditional Fréchet mean [PetersenandMüller,2019]. For
simplicity, we assume that the minimum in (1) is achieved for each x and moreover, the conditional
FréchetmeanofY givenX =x,isunique. WenoteherethatonemayalsoconsidertheconditionalFréchet
medianobtainedbyargmin y√∈Y E(d 1(Y,y)|X =x).However,thisisaspecialcaseofoursetupobtainedby
replacingthemetricd ,by d (whichisalsoametric).
1 1
SupposethatY isalsoequippedwithanotherdistanced . Wemayhaved =d ,butinsomecasesitis
2 2 1
convenienttoworkwithtwodistances.
Fory∈Y andr≥0,denotebyB(y,r):={z∈Y; d (y,z)≤r},theclosedballofcentery∈Y,and
2
radiusr.
Definition1. Wesaythatthedistributionof(X,Y)ishomoscedasticwithrespecttotheregressionfunction
mifthereexistsafunctionφ :[0,∞)→[0,1]suchthatforallx∈Rpandr≥0,
P(Y ∈B(m(x),r)|X =x)=φ(r).
Tomotivatebetterourdefinitionofhomoscedasticity,letusconsiderthefollowingexamples. Thefirst
exampleisthemostnaturalandcommonlyencounteredinthestatisticalliterature. Inthiscase,thenotion
ofhomoscedasticityalignswiththetraditionaldefinition.
However,thesecondexampleisnon-trivialandservestoillustratethateveninaspaceswithoutavector-
space structure, it is still possible to have statistical models that fall under the homoscedastic regime
accordingtoourdefinition.
Example1. SupposethatX =Rp, Y =Rm,d (·,·)=d (·,·)=∥·−·∥(arbitrarynorminRm), and
1 2
considertheregressionmodel
Y =m(X)+ε, (2)
where,therandomvectorε,takingvaluesinRm,isindependentofX.
Obviously,P(d (Y,m(x))≤r|X =x)=P(∥ε∥≤r|X =x)=φ(r),duetotheindependenceofε andX.
2
Example2. ConsiderX =Rp andY =W (R), whereW (R)denotesthe2-Wassersteinspace(see
2 2
[Major,1978,PanaretosandZemel,2020]). Morespecifically,wedefineW (R)={F ∈Π(R)},where
2
Π(R)isthesetofdistributionfunctionsoverRwithafinitenumberofdiscontinuities.
AnaturalmetricforW (R)isd2 (F,G),isdefinedas
2 W
2
(cid:90) 1
d2 (F,G)= (Q (t)−Q (t))2dt. (3)
W F G
2 0
Here,Q andQ denotethequantilefunctionsofthedistributionfunctionsF andG,respectively.
F G
Definethediscrete-timestochasticprocessZ(·)as
Z(j)=g(X)+ε(j), j=1,...,n,
where X is a random vector taking values in Rp, g:Rp →R is a continuous function, and for each
t=1,...,n,ε(t)∼N (0,σ2),withε(j)⊥ε(j′)for j̸= j′,where⊥denotesthestatisticalindependence
ε
betweentworandomvariables,andε(1),...,ε(n)areindependentofX.
Then,wedefinetheelementF ∈W (R)as
n 2
1 n
F (t)= ∑I{Z(j)≤t}. (4)
n
n
j=1
3Similarly, we can define the ρ-th quantile related to F as Q (ρ)=inf{t :F (t)≥ρ}, which has an
n n n
explicitexpressionasQ n(ρ)=g(X)+∑ j:[j/n]≤ρε (j),whereε
(j)
isthe j-thorderedrandomerrorvalue
from{ε(j)}n . Theexpectationofthequantilefunctioncanbeeasilyderivedas:
j=1
E(Q (ρ)|X)=g(X)+σ h (ρ), (5)
n ε n
whereh (·)isafunctionthatdependsonthesamplesizen.Tosimplifythenotation,wedenoteQ =[F ]−1.
n n n
Bythedefinitionofthemetricd2 (·,·),[m(X)]−1(ρ)=E[Q (ρ)|X]. Toseethis,wenotethat
W n
2
(cid:18)(cid:90) 1 (cid:19)
m(x)=argminE(d2 (F ,y)|X=x)=argminE (cid:0) Q (t)−y−1(t))2dt(cid:1) |X =x =E[Q |X =x]−1,
W n n n
y∈W 2(R) 2 y∈W 2(R) 0
(6)
where,inthefinalstep,weleveragethepropertythatthemeanoperatorminimizestheaforementioned
optimizationprobleminanyEuclideanspace.
Then,thesquaredWassersteindistancebetweenthedistributionfunctionF withrespecttoitsconditional
n
Fréchetmeanm(X)iscalculatedas:
(cid:32) (cid:33)2
(cid:90) 1
d W2 (F n,m(X))= g(X)+ ∑ ε (j)−g(X)−σ εh n(ρ) dρ,
2 0 j:[j/n]≤ρ
whichdoesnotdependonthevalueofX.
Wesaythatthedistributionof(X,Y)isheterocedasticwithrespecttotheregressionfunctionmwhen
P(Y ∈B(m(x),r)|X =x)
maydependonx.
GivenarandomobservationX,andconfidencelevelα ∈[0,1],ourgoalistoestimateapredictionregion
Cα(X)⊂Y oftheresponsevariableY thatcontainstheresponsevariablewithprobabilityatleast1−α.
Weintroducethepopulationversionofthepredictionregion.
Definition2. Wedefinetheoracle-predictionregionas
Cα(x):=B(m(x),r(x)), (7)
wherer(x)isthesmallestnumberrsuchthatP(Y ∈B(m(x),r)|X =x)≥1−α.
InordertoestimateCα(x),supposethatweobservearandomsampleD ={(X,Y)∈X ×Y :i∈[n]:=
n i i
{1,2,...,n}}containingindependent,identicallydistributed(i.i.d.) pairsdrawnfromthesamedistribution
as(X,Y). Intherestofthispaper, wesplitD intwodisjointsubsets, D =D ∪D , inorderto
n n train test
estimatethecenterandradiusoftheballwithtwoindependentrandomsamples. Wedenotethesetof
indexes[S ]:={i∈[n]:(X,Y)∈D },[S ]:={i∈[n]:(X,Y)∈D },andwedenote|D |=n
1 i i train 2 i i test train 1
and|D |=n =n−n .
test 2 1
Weproposeestimatorsoftheoracle-predictionregionCα(x)oftheformC(cid:101)α(x)=B(m (cid:101)(x), (cid:101)r α(x)),where
m(x) and r (x) are estimators of m(x) and r (x). For simplicity, we assume that the outcomes of the
(cid:101) (cid:101)α α
estimatorm(·;D )remainunaffectedbytheorderinwhichtherandomelementsofD areconsidered
(cid:101) train train
duringtheestimationprocess(i.e.,theestimatorispermutation-invariant). Thistechnicalrequirementis
commonlyintroducedinthecontextofconformalinferencealgorithms.
4Definition3. ConsiderameasurablemappingC:X →2Y. WedefinetheerrorofCwithrespecttothe
oracle-predictionregionas
ε(C,x)=P(Y ∈C(X)△Cα(X)|X =x),
where△denotesthesymmetricdiference.
IfC=C(cid:101),isconstructedfromD n,then
ε(C(cid:101),x)=P(Y ∈C(cid:101)(X)△Cα(X)|X =x,D n).
Weareinterestedintheintegratederror
E(ε(C(cid:101),X)|D n).
WesaythatC(cid:101)isconsistentif
limE(ε(C(cid:101),X)|D n)→0inprobability. (8)
n→∞
1.3 Contributions
Now,wesummarizethemaincontributionsofthispaper:
1. Weproposetwouncertaintyquantificationalgorithms,oneforthehomoscedasticcaseandanother
oneforthegeneralcase.
(a) Homoscedasticcase: Weproposeanaturalgeneralizationofsplitconformalinferencetech-
niques [Vovketal.,2018, SolariandDjordjilovic´,2022] in the context of metric space re-
sponses. We obtain non-asymptotic guarantees of marginal coverage of the type P(Y ∈
C(cid:101)α(X))≥1−α. In this setting, we also show that C(cid:101) is consistent, under mild assump-
tions, which only require the consistency of the conditional Fréchet mean estimator, i.e.,
E(d (m(X),m(X))|D )→0inprobabilityas|D |→∞.
2 (cid:101) train train
(b) Heteroscedasticcase: Wepresentanovellocalalgorithmbasedontheconceptofk-nearest
neighbors,initiallyproposedbyFixandHodges[FixandHodges,1951]andlaterextendedby
Cover[Cover,1968](foracontemporaryreferenceonthetopic,see[BiauandDevroye,2015]).
Whilewedonotprovidenon-asymptoticguaranteesregardingthemarginalcoverageofthe
predictionregion,weproveitsconsistency.
(c) Thepredictionsregionsarethegeneralizationoftheconceptofconditionedquantilesformetric
space responses. The prediction regions are defined by a center function m and a specific
radiusrcorrespondingtoachosenprobabilitylevel,α ∈[0,1]. Thisextensionbuildsupon
recentadvancesinthetheoryofunconditionalquantilesformetricspaces[Liuetal.,2022]
andprovidesanaturalgeneralizationoftheexistingconcepts.
Importantly, from a computational perspective, after estimating the regression function m, the
uncertaintyquantificationalgorithmsarecapableofhandlingproblemsinvolvingmillionsofdata
pointsinjustafewseconds.
2. We introduce an approach to discern between homoscedastic and heteroscedastic uncertainty
quantification models using a global hypothesis testing criterion. Unlike classical approaches
[GoldfeldandQuandt,1965],ourmethodstakeageneralandnon-parametricperspective,allowing
forwiderapplicability. Wedrawupontheconceptdistancecorrelation,basedontheenergydis-
tanceinitiallyintroduced[Székelyetal.,2007a,SzékelyandRizzo,2017]. Ourcriterionprovidesa
powerfultooltoassessthehomoscedasticityorheteroscedasticityoftheunderlyingdistribution.
53. The proposed uncertainty quantification framework has the potential to develop new models
for complex statistical objects for different modeling tasks. In this paper, we focus on a local
[BoehmVocketal.,2015]andgeneralvariableselectionmethoddesignedspecificallyforresponses
inanarbitraryseparablemetricspace. Otherexistingvariableselectionmethodsarelimitedtolinear
modelsandadoptaglobalperspective[Tuckeretal.,2021].
4. We illustrate the potential of the proposed framework in real-world scenarios and demonstrate
itsperformanceinapplicationsinthedomainofdigitalandprecisionmedicine[Tuetal.,2020].
Thedifferentapplicationsinvolveprobabilitydistributionswiththe2-Wassersteinmetric, fMRI
data with Laplacian graphs, and multivariate Euclidean data. As application of our framework,
wediscussanapplicationthatprovidesnormativereferencevalues[Wangetal.,2018]forglucose
time series in healthy individuals using the recently proposed distributional glucose time series
representations[Matabuenaetal.,2021a]. Thisnewanalysishasthepotentialtoestablishclearer
characterizations as the glucose values evolve in the healthy population conditioned on patient
characteristics,providingaformalbasisforestablishingpersonalizeddefinitionofdiseases. For
example,thederivationofreferencevaluesacrosshealthypopulationshasgainedincreasinginterest
among digital medical researchers, as demonstrated by the study [Shapiroetal.,2023]. In their
research,theydefinednormativevaluesforadigitalbiomarker,namely,the"PulseOximetryvalue."
1.4 Literatureoverview
1.4.1 Uncertainityquantification
Inrecentyears,uncertaintyquantificationbecameanactiveresearcharea[Geisser,2017,Politis,2015].
Theimpactofuncertaintyquantificationondata-drivensystemshasledtoaremarkablesurgeofinterestin
bothappliedandtheoreticaldomains. Theseworksdelveintotheprofoundimplicationsofuncertainty
quantificationinstatisticalscienceandbeyondsuchasinthebiomedicalfield[Hammourietal.,2023,
Banerjietal.,2023].
Geisser’spioneeringbookdevelopsamathematicaltheoryofpredictioninference[Geisser,2017]. Build-
ing upon Geisser’s foundations, Politis presented a comprehensive methodology that effectively har-
nessesresamplingtechniques[Politis,2015]. Additionally,thebookofVovk,Gammmerman,andShafer
[Vovketal.,2005] (see recent reviews [AngelopoulosandBates,2023, Fontanaetal.,2023] here) has
beeninfluential.
Oneofthemostwidelyusedandrobustframeworksforquantifyinguncertaintyinstatisticalandmachine
learningmodelsisconformalinference[ShaferandVovk,2008]. Thecentralideaofconformalinference
isrootedintheconceptofexchangeability[Kuchibhotla,2020].Forsimplicity,weassumethattherandom
elementsobserved, D , areindependentandidenticallydistributed(i.i.d.). Now, wepresentageneral
n
overview of conformal inference methods for regresion models with scalar responses. Consider the
sequenceD ={(X,Y)}n ofi.i.d. randomvariables. Givenanewi.i.d. randompair(X,Y)withrespect
n i i i=1
to D , conformal prediction, as introduced by [Vovketal.,2005], provides a family of algorithms for
n
constructingpredictionintervalsindependentlyoftheregressionalgorithmused.
Fixanyregressionalgorithm
A : ∪ (X ×R)n → {measurablefunctionsm:X →R},
n≥0 (cid:101)
which maps a data set containing any number of pairs (X,Y), to a fitted regression function m. The
i i (cid:101)
algorithmA isrequiredtotreatdatapointssymmetrically,i.e.,
A(cid:0)
(x ,y ),...,(x ,y
)(cid:1) =A(cid:0)
(x ,y ),...,(x ,y
)(cid:1)
(9)
π(1) π(1) π(n) π(n) 1 1 n n
6foralln≥1,allpermutationsπ on[n]={1,...,n},andall{(x,y)}n . Next,foreachy∈R,let
i i i=1
my=A(cid:0)
(X ,Y ),...,(X ,Y
),(X,y)(cid:1)
(cid:101) 1 1 n n
denotethetrainedmodel,fittedtothetrainingdatatogetherwithahypothesizedtestpoint(X,y),andlet
(cid:40)
|Y −my(X)|, i=1,...,n,
Ry= i (cid:101) i
(10)
i |y−my(X)|, i=n+1.
(cid:101)
ThepredictionintervalforX isthendefinedas
(cid:40) (cid:32) (cid:33)(cid:41)
n+1
C(cid:101)α(X;D n)= y∈R : Ry n+1≤Q 1−α ∑ n+1 1·δ Ry
i
, (11)
i=1
(cid:16) (cid:17)
whereQ 1−α ∑n i=+ 11 n+1 1·δ Ry
i
denotesthequantileoforder1−α oftheempiricaldistribution∑ in =+ 11 n+1 1·
δ Ry.
i
Thefullconformalmethodisknowntoguaranteedistribution-freepredictivecoverageatthetargetlevel
1−α:
Theorem1(Fullconformalprediction[Vovketal.,2005]). Ifthedatapoints(X ,Y ),...,(X ,Y ),(X,Y)
1 1 n n
arei.i.d.(ormoregenerally,exchangeable),andthealgorithmA treatstheinputdatapointssymmetrically
asin(9),thenthefullconformalpredictionsetdefinedin(11)satisfies
P(Y ∈C(cid:101)α(X;D n))≥1−α.
Thesameresultholdsforsplitconformalmethods,whichinvolveestimatingtheregressionfunctionon
D andthequantileonD .
train test
Conformal inference (both split and full) was initially proposed in terms of “nonconformity scores”
S(cid:98)(X i,Y i), where S(cid:98)is a fitted function that measure the extent to which a data point (X i,Y i) is unusual
relativetoatrainingdatasetD . Forsimplicity,sofarwehaveonlypresentedthemostcommonlyused
train
nonconformityscore,whichistheresidualfromthefittedmodel
S(cid:98)(X i,Y i):=|Y i−m (cid:101)(X i)|, (12)
where m is estimator of the regression function, estimated using random elements from the first split,
(cid:101)
D .
train
Thenon-asymptoticguaranteesprovidedbyTheorem1canbeachievedundermoregeneralconditions.
Forinstance,Vovk[Vovk,2012]establishednon-asymptoticguaranteeswithrespecttotheconditional
coverageprobabilityD ,employingthesamehypothesesusedinTheorem1. Heprovesinequalitiesofthe
n
form
P(Y ∈C(cid:101)α(X;D n)|D n)≥1−α, (13)
whileBarberetal. [FoygelBarberetal.,2021]investigatedthecaseofconditionalcoverageprobability
withrespecttoaspecificpointx∈X,meaning
P(Y ∈C(cid:101)α(X;D n)|X =x)≥1−α. (14)
However, onlyinsomespecialcases, suchasthoseinvolvingafinitepredictorspace, isitpossibleto
generalizetheresultsofTheorem1.
Inthegenerali.i.d. context,andbeyondtheconformalinferenceframework,withintheasymptoticregime,
GyörfiandWalk[GyörfiandWalk,2019]presentedakNN-baseduncertaintyquantificationalgorithm
7conditionedonboth: i)arandomsampleD ,andii)covariatecharacteristics. Thisalgorithmpossessesthe
n
propertythat
limP(Y ∈C(cid:101)α(X;D n)|D n,X =x)=1−α inprobability.
n→∞
Theworkof[GyörfiandWalk,2019]isparticularlyrelevantasitprovidesoptimalnon-parametricrates
forkNN-baseduncertaintyquantification.
Severalauthorsestablishednon-asymptoticguaranteesforthecoverageoutlinedinequation(14).However,
in general, this is impossible without incorporating strong assumptions about the joint distribution of
(X,Y)orpossessingexactknowledgeofthedistribution[FoygelBarberetal.,2021,Gibbsetal.,2023].
[LeiandWasserman,2014] introduced conditions under which the condition in (14) can lead to the
Lebesgue measure of the estimated prediction regionC(cid:101)α(X;D n) becoming unbounded under general
hypotheses. Morespecifically,theyprovethat,
limE[Leb(C(cid:101)α(X;D n))]=∞,
n→∞
whereLebdenotestheLebesguemeasure.
Conformalinferencetechniqueshavebeenappliedtovariousregressionsettings,includingtheestimationof
theconditionalmeanregressionfunction[Leietal.,2018],conditionalquantiles[SesiaandCandès,2020],
anddifferentquantitiesthatarisefromconditionaldistributionfunctions[Singhetal.,2023,Chernozhukovetal.,2021a].
Inrecentyears,multipleextensionsofconformaltechniqueshaveemergedtohandlecounterfactualinfer-
enceproblems[Chernozhukovetal.,2021b,Candèsetal.,2023,Yinetal.,2022,Jinetal.,2023],hetero-
geneouspolicyeffect[ChengandYang,2022],reinforcementlearning[DietterichandHostetler,],feder-
atedlearning[Luetal.,2023],outlierdetection[Batesetal.,2023],hyphotesistesting[HuandLei,2023],
robustoptimization[JohnstoneandCox,2021],multilevelstructures[FongandHolmes,2021,Dunnetal.,2022],
missingdata[Matabuenaetal.,2022a,Zaffranetal.,2023],andsurvivalanalysisproblems[Candèsetal.,2023,
Tengetal.,2021], as well as problems involving dependent data such as time series and spatial data
[Chernozhukovetal.,2021b,XuandXie,2021,Sun,2022,XuandXie,2023].
Despitethesignificantprogressinconformalinferencemethods,therehasbeenrelativelylittleworkonhan-
dlingmultivariate[JohnstoneandNdiaye,2022,Messoudietal.,2022]andfunctionaldata[Leietal.,2013,
Diquigiovannietal.,2022,Matabuenaetal.,2021b,DietterichandHostetler,2022,GhosalandMatabuena,2023].
Inthecaseofclassificationproblems,thefirstcontributionstohandlemultivariateresponseshavealso
beenrecentlyproposed(see,forexample,[Cauchoisetal.,2021]).
[ZhangandPolitis,2022,WuandPolitis,2023,Dasetal.,2022],provideasymptoticmarginalguarantees
and,incertaincases,asymptoticresultsfortheconditionalcoverage.Thekeyideabehindtheseapproaches
istheapplicationofresamplingtechniques,originallyproposedbyPolitisetal.[PolitisandRomano,1994],
toresidualsorotherscoremeasures. Notably,thesemethodologiesareapplicableregardlessofthepredic-
tivealgorithmbeingused,asemphasizedby[Politis,2015].
Bayesianmethodsarealsoanimportantframeworktoquantifyuncertainty(see[ChhikaraandGuttman,1982]),
whichcanalsobeintegratedwithconformalinferencemethods[AngelopoulosandBates,2023,FongandHolmes,2021,
Pateletal.,2023]. Gaussianresponsetheory,includinglinearGaussianandmultivariateresponseregres-
sionmodels[ThombsandSchucany,1990,Lietal.,2022],asaparticularcase,isaclassicalandpopular
approach. However, the latter techniques generally introduce stronger parametric assumptions in sta-
tisticalmodelingorincludethelimitationordifficultyinselectingtheappropriatepriordistributionin
Bayesianmodeling[Gawlikowskietal.,2023]. Thetheoryoftoleranceregionsgivesanotherconnection
withtheproblemstudiedhere[FraserandGuttman,1956,Hamadaetal.,2004],whichwasgeneralized
forthemultivariatecasewiththenotionofdepthbands(see[LiandLiu,2008]). However,afewcon-
ditional depth measures are available in the literature [García-MeixideandMatabuena,2023]. Depth
band measures for statistical objects that take values in metric spaces have recently been proposed
[Geenensetal.,2023,Dubeyetal.,2022,Liuetal.,2022,Virta,2023]butonlyintheunconditionalcase.
81.4.2 Statisticalmodelinginmetricspaces
Oneofthemostprominentapplicationsofstatisticalmodelinginmetricspacesisinbiomedicalprob-
lems[Matabuena,2022]. Inpersonalizedanddigitalmedicineapplications,itisincreasinglycommonto
measurepatients’healthconditionswithcomplexstatisticalobjects,suchascurvesandgraphs,which
allow recording patients’ physiological functions and measuring the topological connectivity patterns
of the brain at a high resolution level. For example, in recent work, the concept of "glucodensity"
[Matabuenaetal.,2021a]hasbeencoined,whichisadistributionalrepresentationofapatient’sglucose
profilethatimprovesexistingmethodologyindiabetesresearch[Matabuenaetal.,2022a]. Thisrepresen-
tationisalsohelpfulinobtainingbetterresultswithaccelerometerdata[MatabuenaandPetersen,2023,
Ghosaletal.,2021b,Matabuenaetal.,2022b,GhosalandMatabuena,2023].
Fromamethodologicalpointofview,statisticalregressionanalysisofresponsedatainmetricspacesisa
novelresearchdirection[FanandMüller,2021,Chenetal.,2021b,Petersenetal.,2021,ZhouandMüller,2022,
DubeyandMüller,2022, Jeonetal.,2022, Jeonetal.,2022, KurisuandOtsu,, ChenandMüller,2023].
Thefirstpapersonhypothesistesting[Lyons,2021,DubeyandMüller,2019,Petersenetal.,2021,FoutandFosdick,2023],
variableselection[Tuckeretal.,2021],missingdata[Matabuenaetal.,2024a],multilevelmodels[MatabuenaandCrainiceanu,2024,
BhattacharjeeandMüller,2023],dimension-reduction[Zhangetal.,2022],semi-parametricregression
models[BhattacharjeeandMüller,2021,Ghosaletal.,2023],semi-supervisedalgorithms[Qiuetal.,2024]
andnon-parametricregressionmodels[Schötz,2021,Hanneke,2022,BultéandSørensen,2023,Bhattacharjeeetal.,2023]
haverecentlyappeared.
2 Mathematical models
Inthissection,wepresentaframeworkforuncertaintyquantification,buildinguponthepreviousdefinition
oftheoraclepredictionregion(seeSection1.2):
Cα(x):=B(m(x),r(x)). (15)
Recallthatr(x)isthesmallestnumberrsuchthatP(Y ∈B(m(x),r)|X =x)≥1−α.
The initial phase of our uncertainty quantification methodology entails the estimation of the Fréchet
regression function m:X →Y. This estimation process leverages the geometry introduced by the
distancefunctiond .
1
Inthesecondstep,wedeterminetheradiusthatgovernsthenumberofpointsencompassedwithinthe
predictionregions. Thisselectionismadetoensurethatthesetincludesatleast(1−α)proportionof
pointsfromthedataset.
Weemphasizethatourmethodestablishesfordifferentconfidencelevelsα ∈[0,1],differentlevelsets
forthepredictionregionsproblem. Thisapproachallowsustoassociatethepredictionregionswiththe
notionofconditionalquantilesformetricspaceresponses,generalizingtheexistingmarginalapproaches
[Liuetal.,2022].
2.1 Homoscedasticcase
Algorithm1outlinesthecorestepsofouruncertaintyquantificationmethodforthehomoscedasticcase.
Thekeyideabehindourapproachistoestimatethefunctionmandtheradiusrbydividingthedatainto
twoindependentdatasets.
Inthehomoscedasticcase,thedistributionofd (Y,m(x))remainsinvariantregardlessofthepointx∈X.
2
Asaresult,itisnaturaltowhichestimatetheradiususingtheempiricaldistributionfromtherandom
sampleD ={d (Y,m(X))} . Then,wecanformulateaconformalizedversionofthisalgorithmto
test 2 i (cid:101) i i∈[S2]
attainnon-asymptoticguaranteesoftheformP(Y ∈C(cid:101)α(X;D n))≥1−α.
9Thecoreideaofestimatingdifferentquantitiesofthemodelindifferentsplitsisnotnewintheliterature
ofconformalinference. Thisapproachenhancesthecomputationalfeasibilityofthemethods,providing
non-asymptotic guarantees and facilitating theoretical asymptotic analysis. However, there may be
some loss in statistical efficiency due to estimating model quantities in subsamples. These methods,
knownassplitconformalmethods,havebeenextensivelystudied(see,forexample,[Vovketal.,2018,
SolariandDjordjilovic´,2022]).
Algorithm1Uncertaintyquantificationalgorithmhomoscedasticset-up
1. Estimatethefunctionm(·),bym(·)usingtherandomsampleD .
(cid:101) train
2. Foralli∈[S ],evaluatem(X)anddefiner =d (Y,m(X)).
2 (cid:101) i (cid:101)i 2 i (cid:101) i
3. EstimatetheempiricaldistributionG(cid:101)∗(t)= n1 2∑ i∈[S2]I{ (cid:101)r i≤t}anddenotebyq (cid:101)1−α theempirical
quantileoflevel1−α oftheempiricaldistributionfunctionG(cid:101)∗(t).
4. ReturnC(cid:101)α(x;D n)=B(m (cid:101)(x),q (cid:101)1−α).
Observethatwehavethemarginalfinitesampleguarantee.
Proposition2. Foranyregressionfunctionmandestimatorm,assumingtherandomelements{(X,Y)}n
(cid:101) i i i=1
arei.i.d. withrespecttoapair(X,Y),Algorithm1satisfies:
P(Y ∈C(cid:101)α(X;D n))≥1−α.
Proof. Thisfollowsbyobservingthat
P(Y ∈C(cid:101)α(X;D n))=P(Y ∈B(m (cid:101)(X),q (cid:101)1−α))
=E[I{d (Y,m(X))≤q }]≥1−α.
2 (cid:101) (cid:101)1−α
Remark1. Proposition2holdsinboththehomoscedasticcaseandtheheteroscedasticcase. However,
whenweapplyAlgorithm1toaheteroscedasticmodel,theresultingconditionalcoveragecansubstantially
deviatefromthetruevalue. Undersuchcircumstances,thealgorithmmaynotbeconsistency.
Remark2. InAlgorithm1,whenhandlingdiscretespaces,itbecomescrucialtoincorporaterandom-
izationstrategiesintheradiusestimation. Thisensuresthattherandomvariabled (Y,m(X))remains
2
continuous, andguaranteesthatforanytwodistinctr andr , theprobabilityofthembeingequalis
(cid:101)j (cid:101)j′
preciselyzero(withprobabilityone).
Thisgeneralstrategyhasbeenextensivelyexplored,including[Kuchibhotla,2020](seeDefinition1),and
[Cauchoisetal.,2021],whichspecificallyfocusesondiscretestructures.Theintegrationofrandomization
techniquesinsuchscenariosensuresthecontinuityoftherandomvariableandleadsto:
1
1−α+ ≥P(Y ∈C(cid:101)α(X;D n))≥1−α.
n +1
2
2.1.1 Statisticalconsistencytheory
NextweintroducethetechnicalassumptionsthatensuretheasymptoticconsistencyoftheAlgorithm1.
Assumption1. Supposethatthefollowinghold:
101. n →∞.
2
2. misaconsistentestimatorinthesensethatlim E(d (m(X),m(X))|D )→0,inprobability.
(cid:101) n1→∞ 2 (cid:101) train
3. Thepopulationquantileq =inf{t ∈R:G(t)=P(d (Y,m(X))≤t)=1−α}existsuniquely
1−α 2
andisacontinuitypointofthefunctionG(·).
Theorem3. UnderAssumption1,theestimatedpredictionregionC(cid:101)α(x;D n)obtainedusingAlgorithm1
satisfies
limE(ε(C(cid:101)α(X;D n))→0inprobability. (16)
n→∞
Proof. SeeAppendix.
Assumption2. Supposethatforallt∈R,thedistributionfunctionofdistancesG(t,x)=P(d (Y,m(x))≤
2
t|X =x)isuniformlyLipschitzwithconstantLinthesensethatforallt,t′∈Randforallx∈X,we
have|G(t,x)−G(t′,x)|≤L|t−t′|.
Example 3. Suppose that X =Rp, Y =Rm, d (·,·)=d (·,·)=∥·−·∥ (L2 norm), and consider the
1 2
regressionmodel
Y =m(X)+ε, (17)
whereε isarandomvectortakingvaluesinRm,andindependentfromX. Let f bethedensityfunctionof
therandomvariableε. Ifthedensityfunction f isbounded,then,GisuniformlyLipschitz.
Remark3. SupposethattheassumptionsofExample3aresatisfied. Consideranyestimatormofm,and
(cid:101)
definethedistributionofthedistances:
G∗(t,x)=P(d (Y,m(X))≤t|X =x).
2 (cid:101)
Wecanexpressthisprobabilityintermsoftheperturbationintroducedbytheestimator:
G∗(t,x)=P(∥ε+(m(X)−m(X))∥≤t|X =x).
(cid:101)
Thenforallx,thefunctionG∗(t,x)isLipschitzcontinuouswithaconstantL.
Proposition4. UnderAssumptions1and2,andassumingthatG∗(t,x)=P(d (Y,m(X))≤t|X =x),is
2 (cid:101)
uniformlyLipschitz,wecanboundtheconditionalexpectederrorofC(cid:101)givenD nasthesumoftwoterms:
afunctionoftheexpecteddistancebetweenm(X)andm(X),conditionalonthetrainingsetD ,and
(cid:101) train
afunctionofthedifferencebetweentheestimatedandtrueα-quantilesofthedistributionofradiusr,
denotedbyq andq ,respectively. Specifically,wecanwrite:
(cid:101)1−α 1−α
E(ε(C(cid:101),X)|D n)≤C(E(d 2(m (cid:101)(X),m(X))|D train)+4(|q (cid:101)1−α−q 1−α|)),
whereCisapositiveconstantdependingontheLipschitzconstantsofthefunctionsGandG∗.
Proof. SeeAppendix.
Example4. SupposethatX =Rp,Y =Rm,andd (·,·)=d (·,·)=∥·−·∥(theL2 norm). Consider
1 2
theregressionmodel
Y =m(X)+ε, (18)
whereε isarandomvectortakingvaluesinRmandisindependentofX. Let f denotethedensityfunction
ofε. Inthemultivariatescale-localizationregressionmodelsdefinedin(18),wecanobtaintheratesof
Proposition4
E(ε(C(cid:101),X)|D n)≤C(E(d 2(m (cid:101)(X),m(X))|D train)+4(|q (cid:101)1−α−q 1−α|)).
11Remark 4. In the absence of covariates and with the Fréchet mean m known, the rate of our es-
timation uniquely depends on the speed at which we estimate the quantiles of pseudoresiduals r =
d(Y,m(X)). Inthisparticularhomoscedasticcase,ourboundsextendtheoptimalityresultsestablishedin
(cid:112)
[GyörfiandWalk,2019]fortheunivariatecaseandempiricaldistribution,yieldingarateofO( lnn/n).
InthecasewheretheFréchetmeanisnotknown,butwecanestimate,itforexampleattheparametric
√
rateO(1/ n),ouralgorithmcanexhibitfastrates.
Remark5. Morespecificnon-asymptoticresultscanbederivedforhomoscedasticcasesandunivariate
responses, as demonstrated in Corollary 1 of [FoygelBarberetal.,2021], using the conformal model
introducedin[Leietal.,2018]. Intheirwork,theauthorsimposemorestringentassumptionstoboundthe
Lebesguemeasure,includingrequirementssuchastheexistenceofadensityfunctionfortherandomerror
andsymmetricalconditions,alongsidestabilitycriteriafortheunderlyingmeanregressionfunctions.
Incontrast,wedonotaimtoestablishconvergenceundersymmetricalconditionsorassumetheexistence
ofadensityfunctionfortherandomerror. Whilesymmetricalconditionscouldberelevantinpractical
applicationsforobtaininginterpretableandvaluableregions,theyarenotimperativefromatheoretical
perspectivewithinourframework. Moreover,assumingtheexistenceofadensityfunctionfortherandom
errorisaverystrongrequirementinmanyreal-worldapplications.
Remark6. Inthisresearch,weprimarilyfocusonutilizingourmethodologyinthesettingwhereX =Rp
isafinite-dimensionalEuclideanspace. However,itisworthnotingthatourmethodologyhasthepotential
tobeappliedwhenX =H,whereHisanarbitraryseparablemetricspacewithfinitediameterunder
minimaltheoreticalconditionsoraHilbertspaceasthecaseofpredictorsthatlieinaReproducingKernel
HilbertSpaces(seeforexamplethisrepresentativeregressionalgorithm[Bhattacharjeeetal.,2023]). For
moredetailsaboutthestatisticalmodelsthataccommodatesuchpredictorssee[Hanneke,2022]
2.2 Heterocedasticcase
Algorithm2Uncertaintyquantificationalgorithmforheteroscedasticsetup
1. Estimatethefunctionm(·)usingtherandomsampleD .
(cid:101) train
2. Foragivennewpointx∈X,letX (x),X (x),...,X (x)denotethek-nearestneighbors
(n2,1) (n2,2) (n2,k)
ofxinincreasingorderbasedonthedistanced . ForeachdatapointX inthetestdatasetD ,
2 i test
computethepredictedvaluem(X). Then,definethepseudo-residualr asthedistancebetweenthe
(cid:101) i (cid:101)i
trueresponsevalueY andthepredictedvaluem(X),i.e.,r =d (Y,m(X)). Denotethepseudo-
i (cid:101) i (cid:101)i 2 i (cid:101) i
residualsassociatedwiththei-thorderedobservationasr (x)=d (Y ,m(x)).
(cid:101)(n2,i) 2 (n2,i) (cid:101)
3. Estimatetheempiricalconditionaldistributionoforder1−α byG(cid:101)∗ k(x,t)= 1 k∑k i=1I{ (cid:101)r (n2,i)(x)≤t}
anddenotebyq (cid:101)1−α(x)theempiricalquantileoftheempiricaldistributionG(cid:101)∗ k(x,t).
4. ReturntheestimatedpredictionregionasC(cid:101)α(x):=C(cid:101)α,k(x)=B(m (cid:101)(x),q (cid:101)1−α(x))
Thehomoscedasticassumptioncanbetoorestrictiveinmetricspacesthatlackalinearstructure,making
a local approach more appropriate. In this paper, we adopt the k-nearest neighbors (kNN) regression
algorithm[FixandHodges,1951,BiauandDevroye,2015]forthispurpose,asitisbothcomputationally
efficientandeasytoimplement.
Inheteroscedasticmethods,givenapointx,werepeatthesamestepsasinthehomoscedasticalgorithm,
buttheradiusestimationonlyconsidersdatapointsinaneighborhoodofx,denotedasN (x)={i∈[S ]:
k 2
12d (X,x)≤d (x)}. Here,d (x)representsthedistancebetweenxanditsk-thnearestneighborin
2 i 2(n2,k) 2(n2,k)
increasingorderinthetestdatasetD usingthedistanced . Algorithm2providesadetailedoutlineof
test 2
thisprocedure.
Remark7. AlthoughAlgorithm2canbeconsistent,itlacksfinitesampleguarantees. Toaddressthis
limitation and propose a heteroscedastic algorithm with non-asymptotic performance guarantees, we
suggestextendingtheconformalquantilemethodologyintroducedby[Romanoetal.,2019]toourcontext.
Specifically, we aim to achieve the marginal property P(Y ∈C(cid:101)α(X;D n))≥1−α. The core steps are
outlinedbelow:
1. Estimationofm(·): UtilizethedatasetD toestimatetheregressionfunctionm(·).
train
2. Estimation of r(·): Employ the random sample D and the pairs (X,d (Y,m(X))) for each
test i 2 i (cid:101) i
i∈[S ]toestimatetheradiusfunctionr(·).
2
3. Calibrationofr(x): Inanadditionaldata-splitD ,wecalibratetheradiusr(x)toobtainthe
(cid:101) test2 (cid:101)
non-asymptoticguaranteesusingthescoresS =d (Y,m(X))−r(X). Theempiricalquantileat
i 2 i (cid:101) i (cid:101) i
levelα,denotedbyw ,isthenusedtodefinethefinalradiusfunctionasr(x)=r(x)+w .
(cid:101)α (cid:98) (cid:101) (cid:101)α
2.2.1 StatisticalTheory
ThefollowingtechnicalassumptionsareintroducedtoguaranteethattheproposedheteroscedastickNN-
algorithmisasymptoticallyconsistent.
Assumption3. 1. n →∞.
2
2. misaconsistentestimatorinthesensethatE(d (m(X),m(X))|D )→0inprobabilityasn →∞.
(cid:101) 2 (cid:101) train 1
3. Asn →∞,k→∞,and k →0.
2 n2
4. Except in a set of probability zero, for all x∈X, the pointwise population quantile q (x)=
1−α
inf{t∈R:G(t,x)=P(d (Y,m(x))≤t|X =x)=1−α}existsuniquelyandisacontinuitypoint
2
ofthefunctionG(·,x).
5. Exceptinasetofprobabilityzero,forallx∈X,E(d (Y,m(x))|X =x)<∞.
2
Theorem5. UnderAssumption3,theuncertaintyquantificationestimatorC(cid:101)α,k(·)obtainedusingAlgo-
rithm2satisfies:
limE(ε(C(cid:101),X)|D n)→0.
n→∞
Proof. TheproofisgivenintheAppendix.
Remark8. WecangeneralizeProposition4usingAssumption3forthekNNalgorithm(andintroducingan-
othermodifiedLipchitzconditionfortheradiusestimationr=d (Y,m(X)),see[GyörfiandWalk,2019]):
2
E(ε(C(cid:101),X)|D n)≤C(E(d 2(m (cid:101)(X),m(X))|D train)+4(E(|q (cid:101)1−α(X)−q 1−α(X)|))).
Intheheterocedasticcase,wemustconsiderexplicitlytheimpactoftheconditionalquantileq (x)for
1−α
eachx∈X intherate. Inasimilarcontext,Györfietal. [GyörfiandWalk,2019]proposetheoptimal
rateforpredictionintervals,whichcoincideswhentheconditionalregressionfunctionmisknownandis
(cid:18) (cid:19)
givenbyO lnn for p≥1,where pdenotesthedimensionofthepredictorX. Itisimportanttonote
1
np+2
thatthisratescaleswiththedimensionofthecovariatespacep,unlikethehomoscedasticornon-covariate
settings.
132.3 GlobalFréchetregressionmodel
Inthissection,weintroducesomebackgroundonregressionmodelinginmetricspaces,whichisessential
for implementing our uncertainty quantification algorithms in practice. After motivating the need for
modelsthathandlerandomresponsesinmetricspaces,particularlyinclinicalapplications,theprimary
objectiveofthissectionistointroducetheglobalFréchetregressionmodel. Thisregressionmodelin
metricspaceswillbeemployedacrossvariousanalyticaltasks.
Thegoalistomodeltheregressionfunction
m(x)=argminE(d2(Y,y)|X =x)
1
y∈Y
sothatitsestimationbecomesfeasible.
Inthissection,wefocusonaspecificregressionmodeldesignedformetric-spacevaluedoutcomes,known
astheglobalFréchetregressionmodel[PetersenandMüller,2019].
TheglobalFréchetregressionmodelprovidesanaturalextensionofthestandardlinearregressionmodel
fromEuclideanspacestometricspaces.
Ourinterestinthismodelstemsfromitspotentialapplicationsinthefieldofmedicaldataanalysis. As
medicaltechnologycontinuestoadvance,weexpecttohaveaccesstoincreasingamountsofcomplexdata
aboutpatients’healthconditions.
To illustrate the significance of uncertainty quantification in this context, we turn our attention to the
continuousglucosemonitoringtechnology. Considertwonon-diabeticindividualswhoshareidentical
clinicalcharacteristics,exceptfortheirbodymassindex. Ourprimaryfocusistopredicttheirglucose
quantilefunctions. AsdepictedinFigure1,bothindividualsexhibitthesameconditionalmeanfunction
(indicatedbytheblackline). However,itisimportanttonotethattheuncertaintyinthepredictioncurves
increaseswithhigherbodymass.
Inpracticalterms,ifweweretousetheconditionalmeanresultstomodifythedietbasedonchangesinthe
glucoseprofilesofoverweightpatients,wewouldencountertechnicaldifficulties. Thepatientresponses
inthissubgroupturnouttobeheterogeneousandindividualizedresponses,asevidencedbythevarying
levels of uncertainty in the predictions. As a consequence, relying solely on prescriptive data-driven
algorithmsbasedonconditionalmeanregressionfunctionwouldproveinadequateforoptimizingdiet
selectionamongthesepatients.
To effectively utilize uncertainty quantification algorithms, we consider the global Fréchet model, a
generalizationoflinearregressiontometric-spacevaluedresponses.
Inparticular,[PetersenandMüller,2019]proposetomodeltheregressionfunctionintheform
m(x)=argminE(cid:2) ω(x,X)d(Y,y)2(cid:3)
,
y∈R
wheretheweightfunctionω isdefinedby
ω(x,z)=1+(z−µ)⊤Σ−1(x−µ)
withµ =E(X)andΣ=Cov(X). As[PetersenandMüller,2019]show,inthecaseofY =R,thismodel
reducestostandardlinearregression.
WhileinourapplicationsweprimarilyfocusondevelopingestimatorsintheglobalFréchetregression
model,itisimportanttoemphasizethatouruncertaintyquantificationalgorithmcanbeappliedtoany
regressiontechnique,includingrandomforestsinmetricspaces. Itshouldbenoted,however,thatifthe
globalFréchetmodelsdonotalignwiththeconditionalFréchetmeanm,theresultingestimatorswillbe
inconsistent.
Toestimatetheconditionalmeanfunctionm(x)undertheglobalFréchetmodelfromarandomsample
D ={(X,Y)}n ,wemaysolvethecounterpartempiricalproblem
n i i i=1
14Figure 1: Uncertainty quantification from the quantile glucose representations for two non-diabetic
patientswiththesameclinicalcharacteristics,withtheexceptionofbodymassindex(BMI).Inpatient(i),
BMI=20kg/m2,andinpatient(ii),BMI=30kg/m2(moreuncertainty).
1 n
m(x)=argmin ∑[ω (x)d2(y,Y)], (19)
(cid:101) y∈Y n i=1 in 1 i
(cid:104) (cid:105)
whereω in(x)= 1+(X i−X)Σ(cid:101)−1(x−X) ,withX = 1 n∑n i=1X i,andΣ(cid:101)= n−1 1∑n i=1(X i−X)(X i−X)⊤
2.4 Testing Homoscedastic and Heteroscedastic Nature of the Uncertainity Quan-
tificationModel
Inthissection,weintroducerigorouscriteriafortestingwhetherthedistribution(X,Y)ishomoscedastic.
15Fromapracticalstandpoint,modelusersarefacedwithachoicebetweenemployingthehomoscedasticor
heteroscedasticalgorithm. Intheformercase,finitesampleguaranteesareavailable,whereasinthelatter
case,onlyconsistencyguaranteesexist. Iftheunderlyingdistributionalmodelisnothomoscedasticand
weusesuchanalgorithm,theestimatedconditionalpredictionsregionswouldbeinconsistent. Froma
mathematicalstatisticalperspective,theappropriatecriterionfordecidingwhichmodeltochooseistotest
thenullhypothesisthat,forallx∈X,andr≥0:
P(Y ∈B(m(x),r)|X =x) (20)
isindependentofx.
Alternatively, we can define the problem as to test that the random variable of the pseudo-residuals
r=d (Y,m(X))isindependentofX,i.e.,H :r⊥X versusH :r⊥̸ X.
2 0 a
To achieve this, we first estimate the regression function m using the random elements of D , ob-
train
taining an estimator m. Subsequently, we construct a hypothesis test with the random sample D =
(cid:101) test
{X,d (Y,m(X))} . Due to the structural hypothesis, as m is a consistent estimator, meaning that
i 2 i (cid:101) i i∈[S2] (cid:101)
E(d (m(X),m(X))|D )→0inprobabilityas|D |→∞, itisexpected, thathypothesistestingfor
2 (cid:101) train train
homoscedasticityisconsistent.
Inthisarticle,weproposeemployinganexistingmultivariateindependencetestingmethodology—distance
covarianceordistancecorrelation(thestandardizedversion)[Székelyetal.,2007b,Zhongetal.,2023]—
asaformalcriterionfortestingthehomocedasticityof(X,Y)withrespecttotheregressionfunctionm.This
buildsupontheoriginalhypothesistestingframeworkofhomoscedasticityfrom[GoldfeldandQuandt,1965]
forunivariateresponses. Ourapproachismethodologicallyvalidfortestingthehomocedasticnatureof
thepair(X,Y)whenthepredictorX takesvaluesinseparableHilbertspaces[Lyons,2013].
LetusstartwiththedefinitionofthesampledistancecovariancefortheEuclideandistance∥·−·∥.
Foralli∈[S ],considerthebivariaterandomelement(X,d (Y,m(X))).
2 i 2 i (cid:101) i
Definition4. Thesquaredsampledistancecovariance(ascalar)isthearithmeticaverageoftheproducts
A ·B :
j,k j,k
(cid:93)2 1
dCov (X,r)= ∑ ∑ A ·B ,
n2 j,k j,k
2 j∈[S2]k∈[S2]
where
A =a −a −a +a j,k∈[S ],
j,k j,k j· ·k ·· 2
B =b −b −b +b , j,k∈[S ]
j,k j,k j· ·k ·· 2
with
a =∥X −X ∥, j,k∈[S ],
j,k j k 2
b =∥d (Y ,m(X ))−d (Y ,m(X ))∥, j,k∈[S ],
j,k 2 j (cid:101) j 2 k (cid:101) k 2
anda isthe j-throwmean,a isthek-thcolumnmean,anda isthegrandmeanofthedistancematrix
j· ·k ··
oftheX sample. Thenotationissimilarforthebvalues. ∥·∥denotestheEuclideannorm.
Thefollowingconsistencyresultenablesustodevelopaconsistenthypothesistesttodeterminewhether
therandompair(X,Y)exhibitshomoscedasticitywithrespecttothefunctionm.
Proposition6. SupposethatE(∥X∥)<∞,E(r)<∞,andE(d (m(X),m(X))|D )→0inprobability
2 (cid:101) train
as|D |→∞. Then
train
16lim lim d(cid:93) Cov2 (X,r)=dCov2(X,r), (21)
n1→∞n2→∞
wheredCov(X,r)isthepopulationdefinitionofthedistancecovarianceintroducedin[Székelyetal.,2007b].
Proof. Theorem 2 from [Székelyetal.,2007b] using the hypothesis E(d (m(X),m(X))|D )→0 in
2 (cid:101) train
probabilityas|D |→∞.
train
(cid:93)2
Then, the test statistic T =n dCov (X,r) determines a statistical tests asymptotically valid to any
n2 2
deviation(alternative)fromthenullhyphotesis. Foranimplementation,seethedcov.testfunctionin
theenergypackageforR.
Fromapracticalperspective,weprovideseveralalternativestocalibratetheteststatisticsunderthenullhy-
photesisandderive p-values,includingpermutationmethods,resamplingmethodsbasedonEfron’sNaive
bootstrap,ortheWildbootstrap[Székelyetal.,2007b,Matabuenaetal.,2022a,Matabuenaetal.,2023b].
Eachofthesecalibrationoptionsoffersvaluablemeanstofinetunethestatisticaltests,fordiverseanalysis
requirements.
2.5 Newmodelconstructions: variableselectionmethodsforregressionmodelsin
metricspaces
Variable Importance
Variable 1 Variable 2
30000
20000
4000
10000
0 0
-10000
-4000
-20000
1.00 1.25 1.50 1.75 2.00 20 40 60 80
x1 x2
Variable 3 Variable 4
20000
10000
10000
0 0
-10000 -10000
-20000
100 200 300 400 0.0e+00 5.0e+06 1.0e+07 1.5e+07 2.0e+07 2.5e+07
x3 x4
Variable 5 Variable 6
10000 5000
5000
0
0
-5000
-5000
-10000
25 50 75 100 100 200 300 400
x5 x6
Figure2: Anexampleofthenewlocalvariablemodel,includingsixpredictors. Thefirstpredictorisa
binaryvariablerepresentingtheindividual’ssex,andtheremainingvariablesarecontinuousbiomarkers.
Basedontheresultsobtained,allvariablesexceptforvariables3and5werefoundtobeimportantglobally
inthisexample.
17
1y
3y
5y
2y
4y
6yInthissection,wepresentavariableselectionmodelthatcanbeappliedtoanyarbitraryregressionmodels
operating within metric spaces. Before we begin, it is important to clarify that we utilize uncertainty
quantificationalgorithmsappliedoveratransformedrandomvariableW ontherealline,thenwecanapply
overtraditionalconformalinferencetechniques. Thecriticalmodelingstepistocombinethediferentsteps
ofouruncertaintyalgorithmstocreateavariableselectionalgorithmusingscalarmethods.
Forsimplicity,weconsiderthattheunderlyingregressionfunctionmisdefinedthroughtheglobalFréchet
Regressionmodel
m(x)=argminE(cid:2) ω(x,X)d2(Y,y)(cid:3)
, (22)
1
y∈Y
whereΣisthecovariancematrixofX,µ
=E(X),ω(x,X)=(cid:2) 1+(X−µ)Σ−1(x−µ)(cid:3)
.
Letm(·)denotetheregressionfunctionwiththe p-covariatesandm (·)denotetheregressionfunction
−j
obtainedbyexcludingthe jthvariablefromthemodel. Toevaluatetherelevanceofthe jthpredictor,we
introducetherandomvariableW(X,Y)=d2(Y,m (X))−d2(Y,m(X))suchthatE(W(X,Y))≤0. From
1 −j 1
atheoreticalpointofview,underthenullhypothesis,H : j∈{1,...,p}isanirrelevantpredictor,the
0
randomvariableW(X,Y)isequaltozerowithprobabilityone. Inordertotestthisnullhypothesis,we
constructaunivariatepredictionintervalfollowingthemethodologyestablishedinSections2.1and2.2
respectively(forY =R),denotedasC(cid:101)α(X),whereP(W(X,Y)∈C(cid:101)α(X))≥1−α,andwecheckifthis
intervalcontainsonlypositivevalues. Thishypothesiscanbetestedlocallyandgloballyforapre-specified
confidencelevelα ∈[0,1].
The new variable selection method offers several significant advantages over existing variable selec-
tion methods in metric spaces [Tuckeretal.,2021]. Firstly, it provides a local measure of the impor-
tance of the jth variable, as demonstrated in Figure 2. Unlike its competitors, our method can be
applied in more general settings beyond linear models, including additive or semiparametric models
[Linetal.,2023],anditeffectivelyhandlescategoricalpredictors(withtwoormorelevelsasgroup-Lasso
models[WangandLeng,2008]). Notably, theexistingvariable selectionmethodsfor metricspacere-
sponses[Tuckeretal.,2021]informabouttheglobalimportanceofthe jthpredictor,whileourapproach
islocal,beingmoreflexibleandinformativeaboutthecontributionofapredictorinaspecificregionofthe
predictionspace.
Secondly,ourmethoddoesnotnecessitatevariablestandardization,makingitmorepracticalandstraight-
forwardtouse. Additionally,itprovidesa p-valuethatreflectsthestrengthofeachvariable,enablingan
assessmentoftheirsignificance.
To obtain a global p-value indicating the significance of each variable, we introduce an additional
notation. We define the functions W(cid:101)j(x,y)=d 12(y,m (cid:101)−j(x))−d 12(y,m (cid:101)(x)) and consider the median or
integratedmediancomputedfromtherandomelementsofthesampleD . Forinstance,wecalculate
test
w (cid:101)j = |D1 test|∑ i∈D testW(cid:101)j(X i,Y i) and employ a t-test to evaluate the null hypothesis H 0 :w j ≤0 against
H :w >0. Alternatively,aWilcoxontestcanbeused,whichtendstobemorerobustinthepresenceof
a j
outliers. Inthispaper,weemployaWilcoxontesttoassessthesignificanceofeachvariableandapply
aBonferronicorrectiontoadjusttheconfidencelevelformultiplecomparisons. Alongthispaper,we
implementthisvariableselectionprocedurewiththehomoscedasticalgorithmdefinedinSection2.1.
3 Simulation study
Weconductedacomprehensivesimulationstudytorigorouslyevaluatetheempiricalperformanceofthe
proposeduncertaintyquantificationframeworkwithfinitesamples. Thestudyencompassedawiderange
ofscenariosanddiversedatastructures.
183.1 MultidimensionalEuclideandata
3.1.1 Homoscedasticcase
Toevaluatethemethodsperformanceunderhomoscedasticconditionsandcontrolledsettings,wecon-
ductedasimulationstudybasedontheclassicalmultivariateGaussianlinearregressionmodel.Specifically,
weconsidera p-dimensionalGaussianpredictorvariableX =(X ,...,X )⊤∼N ((0,...,0)⊤,Σ),where
1 p
(Σ) =ρ∈[0,1]foralli̸= jand(Σ) =1foralli=1,...,p. Additionally,weconsiderans-dimensional
ij ii
randomresponsevariableY =(Y ,...,Y)⊤∈Rs,modeledbythefunctionalrelationship:
1 s
Y =m(X)+ε =X⊤β+ε, (23)
whereβ isa p×smatrixofcoefficientswithallentriesequalto1. Therandomerrorε =(ε ,...,ε )⊤∼
1 s
N (0,diag(1,...,1))isassumedtobeindependentfromX andsatisfiesE(ε|X)=0.
To assess the performance of our methods under various scenarios, we conducted a comprehensive
simulationstudywithmultiplecases. Weexploreddifferentconfigurationsforthevaluesofsand p,as
wellasvarioussamplesizes,confidencelevels,andcorrelationstructuresforthecovariancematrixΣ,
governedbytheparameterr∈[0,1]. Specifically,weconsidereds∈{1,2,5}and p∈{1,2,5,10},while
thesamplesizenvariedbetween500and5000datapoints. Theconfidencelevelsα rangedfrom0.05to
0.5,andwesetcorrelationparametersrequalto0,0.2,0.4,and0.6. Here,weonlyshowtheresultsinan
intermediaterangewiths=2, p=0.5,r=0.2,andn∈{500,1000,5000}.
Toensuretherobustnessofourfindings,weemployedatrainingsetofsize|D |=n/2andatestset
train
ofsize|D |=n−|D |. Eachscenariowasrepeated500times,andweevaluatedthefinitemarginal
test train
coverageinanadditionaltestset|D |=5000drawnfromthesameprobabilitylaw.
test2
Forestimationpurposes,weobtainedestimatesoftheregressionfunctionmusingamultivariateresponse
linearregressionmodelwiththestandardmeansquarecriteria[SeberandLee,2003]. Subsequently,we
appliedAlgorithm1,asdefinedinSection2.1,togeneratepredictionregions. Theresultsforvarious
confidencelevelsandsamplesizesareillustratedinFigure3. Itisevidentthatthealgorithmconsistently
maintainsthedesiredmarginalcoverage,andasthesamplesizeincreases,thevariabilitydecreases. This
observationindicatesthegoodperformanceofouralgorithmacrossdiversescenarios,inaccordancewith
itsnon-asymptoticguaranteesandtheoreticalconsistencyproperties.
3.1.2 Heterocedasticcase
Toaccountforheteroscedasticityinthesimulationscenarios,wemodifytheprevioussimulationscheme
and incorporate an additional term σ :Rp →R that represents the heteroscedastic term in the model.
Specifically,wesettherandomerrortermtobeσ(X)ε,whereσ(x)=∥x∥ isafunctionthatmapseach
2
featurevectortoascalarvaluecorrespondingtotheirnorm. Theoverallgenerativemodelweconsideris:
⊺
Y =m(X)+σ(X)ε =X β+∥X∥ ε, (24)
2
Toestimatetheregressionfunction,weuselinearregressionwithoutincorporatingtheheteroscedastic
covariance structure in the model estimation. Although this estimator is not the most efficient in the
senseoftheGauss-Markovtheorem[Harville,1976],whichdealswithunbiasedandminimumvariance
characters,theestimatorremainsconsistent.
In this case, we use the algorithm presented in Section 2.2, denoted as Algorithm ??, and utilize the
k-nearestneighbor(kNN)algorithmwithvaryingvaluesofk: k=10,20,50,and100. Weevaluatethe
marginalcoverageoftheresultingpredictionstoassesstheaccuracyofthemodel. Theresultsofour
analysisarepresentedinFigure4,followingaformatsimilartothepreviousexample. Thisfigureoffers
insightsintoourmethodsperformanceacrossvariousvaluesofkandassistsindeterminingtheoptimal
choiceofk. Theselectionofthisoptimalvalueisguidedbyspecificuncertaintyquantificationresults,
195% Confidence Level 10% Confidence Level
0.975
0.92
0.950
0.88
0.925
0.900 0.84
500 1000 5000 500 1000 5000
Sample Size Sample Size
30% Confidence Level 50% Confidence Level
0.80
0.55
0.75
0.50
0.70
0.45
0.65
500 1000 5000 500 1000 5000
Sample Size Sample Size
Figure3: ThefigureshowsthedistributionofthemarginalcoverageP(Y ∈C(cid:101)α(X))inthehomoscedastic
caseacrossdifferentsamplesizesandconfidencelevels. Theresultsofouranalysisprovideinsightsinto
howthemarginalcoveragevariesasafunctionofsamplesizeandconfidencelevel.
whicharetailoredtothecharacteristicsofthedatasetandthecoverageachievedduringtheanalysisofthe
results.
The analysis of empirical results highlights the sensitivity of the method’s performance to the choice
oftheparameterk,especiallywhendealingwithsmallconfidencelevelsandsituationswheremultiple
neighbors are required to approximate extreme quantiles. Across various dimensions of the response
variableandpredictors,weseethatthemethodmaintainsstableperformanceasthesamplesizeincreases.
However, it is important to acknowledge that in the heteroscedastic case, tuning the k parameter on a
case-by-casebasismaybenecessary. Wearewellaware,bothfromempiricalevidenceregardingtheuse
ofk-nearestneighbors(kNN)forestimatingconditionalmeansandtheoreticalresults,thatthechoiceof
thesmoothingparameterkisofutmostimportanceinachievingestimatorswithgoodempiricalproperties
(see[Zhangetal.,2018]).
Lastly,wemustnotethatatamedianlevelcorrespondingtoα parameterof0.5,themarginalcoverageis
consistentacrossdifferentsituationsexamined,demonstratingtherobustnessofthemethodindetecting
predictionregionsthatcontainhalfofthesample.
20
egarevoC
egarevoC
egarevoC
egarevoC5% confidence level 10% confidence level
group 500 1000 5000 group 500 1000 5000
500 1000 5000 500 1000 5000
0.9 0.9 0.9
0.9 0.9 0.9
0.8 0.8 0.8
0.8 0.8 0.8
0.7 0.7 0.7
0.7 0.7 0.7
0.6 0.6 0.6 0.6 0.6 0.6
0.5 0.5 0.5 0.5 0.5 0.5
10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50
k k
30% confidence level 50% confidence level
group 500 1000 5000 group 500 1000 5000
500 1000 5000 500 1000 5000
0.9 0.9 0.9
0.8 0.8 0.8
0.8 0.8 0.8
0.7 0.7 0.7
0.6 0.6
0.6
0.6 0.6 0.6
0.4 0.4
0.5 0.5 0.5 0.4
10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50 10 100 30 50
k k
Figure 4: The figure illustrates how the distribution of the marginal coverage P(Y ∈C(cid:101)α(X) in the
heterocedasticcasevariesacrossdifferentsamplesizesandconfidencelevelsasthenumberofneighbors
changes. Ourresultsprovideinsightsintothebehaviorofthemarginalcoverageandtheimpactofthe
numberofneighborsontheperformanceofourmethod.
21
egarevoC
egarevoC
egarevoC
egarevoC3.2 Examplesofprobabilitydistribution
3.2.1 Uncertaintyquantification
LetusrevisitExample2fromtheintroduction,,wherewedevelopamodeltorepresentobservations
drawnfromalatentcontinuousprocessbyutilizingtheirdistributionfunction. Formally,wedefinethe
spacesX =Rp andY =W (R). Here,W (R)representsthe2-Wassersteinspace,equippedwiththe
2 2
2-Wassersteinmetricd2 (F,G)=(cid:82)1(Q (t)−Q (t))2dt. Q andQ denotethequantilefunctionsofthe
W 2 0 F G F G
distributionfunctionsF andG,respectively.
Forourspecificsimulationpurposes,wesupposethattheunderlyinggenerativemodelisdefined:
p
Z(j)=100+5·∑X +ε(j), j=1,...,n.
l
l=1
Let
1 n
F(cid:101)(ρ)= ∑I{Z(j)≤ρ}. (25)
n
j=1
Wesetn=300. Theremainingparametersareestablishedasintheprevioussimulationsrelatedtothe
multivariateEuclideandata,with p=5andn rangingfrom500to5000. Weuseatrainingsetofsize
i
|D |=n/2andatestsetofsize|D |=n−|D |,andrepeateachscenario500times,evaluatingthe
train test train
finitemarginalcoverageatadditionaltestpoints|D |=5000usingthesameprobabilitylawasthepair
test2
(X,Z).
Forestimationpurposes,weutilizetheGlobal-Fréchetmodelequippedwiththe2-Wassersteindistance
topredictthequantileresponsevariable. WeconsidertheEuclideandistance,denotedasd ,between
2
the predicted quantiles and the observed estimated quantile function. The confidence level α is fixed
with values varying from 0.05 to 0.5. It is important to note that in our example, we use estimated
quantilefunctionsfromatimeseriesastheresponsevariable,introducingadditionalsourcesofuncertainty
andmakingitchallengingtoobtainexactmarginalcontrol. Despitethis,theunderlyingmodelfollows
a homoscedastic definition introduced in Section 1.2. The results, presented in figure 5, confirm this
hypothesisandindicatethattheobtainedcoverageisanti-conservative(belowthenominalvalue)butvery
closetotherealnominalvalues. Again, wenotethatatamedianlevelcorrespondingtoα =0.5, the
marginalcoverageisconsistentacrossdifferentsituationsexamined,demonstratingtherobustnessofthe
methodindetectingpredictionregionsthatcontainhalfofthesample.
225% Confidence Level 10% Confidence Level
0.96
0.90
group group
0.93 500 500
1000 1000
5000 5000
0.85
0.90
0.87
500 1000 5000 500 1000 5000
Sample Size Sample Size
30% Confidence Level 50% Confidence Level
0.76
0.55
0.72
group group
500 0.50 500
0.68 1000 1000
5000 5000
0.64 0.45
500 1000 5000 500 1000 5000
Sample Size Sample Size
Figure5: Thefigurepresentsthedistributionofthemarginalcoverageacrossdifferentconfidencelevels
and sample sizes in the distributional data analysis example. The analysis utilized estimated quantile
functionsfromatimeseriesastheresponsevariable,introducingadditionalsourcesofvariabilityand
makingitchallengingtoobtainexactmarginalcontrol,despitetheunderlyingregressionmodelbeing
homoscedastic. Nonetheless,theresultsindicatethatthemethodiseffectiveinobtainingconservative
coveragelevelsthatareveryclosetothetruevalues.
3.2.2 Variableselection
Continuingwiththepreviousexample,wenowconsiderthecasewherethenumberofvariablesthatappear
inthegenerativemodelisequalto p =1(thefirstcovariateforsimplicity)acrossallscenarios. For
true
each j=1,...,n,thespecificgenerativemodelisgivenby
Z(j)=100+5·X +ε(j).
1
Toidentifythemostrelevantvariableforthemodel,weemploythevariableselectionstrategiesoutlinedin
Section2.5,withaconfidencelevelofα=0.05. Forthispurpose,weutilizetheGlobal-Fréchetregression
modelasabaseregressionmodeltopredicttheempiricalquantilefunction.
Animportantpointinthevariableselectionmodelingstrategy,highlightedinSection2.5,isthatweare
testingsimultaneously p-hypotheses,andwemustaddressthestatisticalproblemsofmultiplecomparisons.
Inthispaper,weimplementtheBonferronimethodformultiplecomparisons. Table1displaystheresults
acrossdifferentsamplesizes,demonstratingthestatisticalconsistencyofthevariableselectionapproach
asthesamplesizeincreasesinthisexample.
23
egarevoC
egarevoC
egarevoC
egarevoCOneVariable TwoorMoreVariables
DetectTrueVariables(%)
FalsePositive(%) FalsePositive(%)
n=500 100 68 26
n=1000 100 29 4
n=5000 100 3 1
Table1: ResultsofSimulationsforVariableSelectionApproach
4 Data analysis examples
Inthissection,wedemonstratethewide-rangingutilityandadaptabilityofouralgorithmacrossdifferent
datastructuresandstatisticalmodelingscenariosthroughaseriesofreal-worldexamples. Ouremphasisis
onshowcasingthealgorithm’sapplicabilityinmodernmedicalcontexts.
The initial example explores situations lacking predictors, utilizing insights from shape analysis to
characterizeParkinson’sdiseaseusingdigitalbiomarkers. Thiscontrastswiththenextfourexamples,
whichexaminepairs(X,Y)∈X ×Y,offeringabroaderperspectiveonthealgorithm’sperformancein
regressionanalyses.
4.1 ShapeAnalysis
4.1.1 Motivation
Shapeanalysisisaresearchareathatrequiresnovelstatisticalmethodsinmetricspaces[DrydenandMardia,2016,
Steyeretal.,2023]andhasbroadapplicationsinthebiomedicalsciences. Thisapproachisparticularly
usefulwhenanalyzingrandom objectsbasedontheirgeometricalproperties. Here, wearemotivated
to analyze the shapes of handwritten samples from patients with a neurological disorder versus those
from a control group of healthy individuals. The scientific problem we aim to address in this section
is to define uncertainty prediction regions for healthy individuals at some confidence level α ∈(0,1),
usinghandwritingtrajectories. Assumingthatindividualswiththeneurologicaldisorderexhibitbehaviors
thatdeviatesignificantlyfromthoseexpectedofthecontrolgroupintheirwritingshapes. Weusethese
prediction regions to identify patients who differ markedly from the control group and to detect and
characterizateoutlierbehavior.
4.1.2 DataDescription
This study employs data from [Isenkuletal.,2014], comprising n =15 control subjects and n =30
1 2
individualsdiagnosedwithParkinson’sdisease,toanalyzehandwritingshapescapturedthroughdigital
tests. Ourobjectiveistoestablishexpectedpredictionsregionsatdifferentconfidencelevelsα basedon
thecontrolgroup’sdata. Forthispurpose,firstweestimatetheempiricalFréchetmeanusingEuclidean
distance d2(·,·)=∥·−·∥2. Subsequently, we adopt d (·,·)=∥·−·∥ to graphically represent the
1 2 ∞
toleranceregionsforvariousindividualsacrossconfidencelevels,utilizingtheconvexhullofextreme
pointsforvisualizationpurposes.
4.1.3 Results
Figure6illustratesthehandwritingtrajectoriesalongsidetoleranceregionsforconfidencelevelsα =0.5
andα =0.7,includingthosefromindividualswithParkinson’sdisease(yellowcolor). Forindividuals
affectedbyParkinson’s,employingtoleranceregionsatα =0.5enablesdistinguishingover75%ofthe
24patientsbyexaminingwhethertheirhandwritingshapefallswithinoroutsidethesepredefinedregions.
Thesefindingsareencouraging,showcasingthepotentialofouruncertaintyquantificationapproachin
validatingnoveldigitalbiomarkersforcontemporarymedicalapplications,suchasanalyzinghandwriting
patternsinthedatafromtheclinicalstudyexamined.
α=0.7 α=0.5
600 600
400 400
Group Group
Control Control
200 200
Parkinson Parkinson
0 0
-200 0 200 400 600 -200 0 200 400 600
Axis X Axis X
Figure6: Toleranceregionsinexpectationsforvariousconfidencelevelsinthewrittentestusingcontrol
individualsasareference. TheplotsdepicttherawtrajectoriesofbothcontrolandParkinson’spatients.
WedonotintroducecovariatesinthederivationofpredictionregionsfortheFréchetmean.
4.2 MultidimensionalEuclideandata
4.2.1 Motivation
MultivariateEuclideandata,denotedasY =Rm(m>1),isincreasinglyprevalentinclinicaloutcome
analysis,particularlyintheintegrationofmultiplebiomarkerstoenhancediagnosticaccuracyforvarious
diseases. This approach is exemplified in diabetes research, where at least two biomarkers – Fasting
Plasma Glucose (FPG) and Glycosylated Hemoglobin (A1C) – are considered in the diagnosis of the
disease. Inthissimple2−dimensionalexample,providingnaiveuncertaintyquantificationmeasuresisfar
fromtrivialduetothelackofanaturalorderinR2. Moreover,bivariatequantileestimationmethodscan
dependonaspecificnotionofordertailoredtoeachproblem,asdiscussedin[KleinandKneib,2020].
Thissectionaimstoillustrateouruncertaintyquantificationframework, whichcanaccommodateany
distance d to define the prediction regionCα(·), and overcome technical difficulties associated with
2
definingamultivariatequantile. Toemphasizethemathematicalintuitionbehindourmethodsfordefining
predictionregionsusingballs,weconsiderthestandardEuclideandistanced 22(x,y)=∑m i=1(x i−y i)2for
allx,y∈Rm. Continuingwiththediscussionondiabetes,wefocusonascientificapplicationinthisfield.
Todemonstratetheapplicationofourmethodology,weconsiderthementionedbiomarkers: FPGand
A1Casaresponseoftheregressionmodelsthatinthiscasewillbeamultivariate–responselinearmodel.
25
Y
sixA
Y
sixAThe goal is to create a predictive models to estimate the continuous outcomed used to diagnostic and
monitoringtheprogressionofdiabetesmellitusdisease.
Uncertaintyanalysisiscrucialinclinicalpredictionmodels,asithelpsunderstandtheadvantagesand
disadvantagesofthesemodels. Incaseswherethereissignificantuncertaintyintheregressionmodelm,it
maybenecessarytoconstructamorecomplexmodelincorporatingnewpatientcharacteristicattributes.
Alternatively,consideringmoresophisticatedregressionmodels,suchasneuralnetworks,mightenhance
thepredictivecapacityofthemodels.
4.2.2 DataDescription
WeconductedanextensivestudyusingacomprehensivedatasetfromtheNationalHealthandNutrition
ExaminationSurvey(NHANES)cohort(seemoredetails[Matabuenaetal.,2023a]),comprisingasub-
stantialnumberofindividuals(n=58,972). Forouranalysis,weutilizedpredictorandresponsevariables
describedinTable2,andappliedalinearmultivariateregressionmodeltoestimatethefunctionm. We
consideredk=200asthenumberofneighborsinthekNNmethod.
Ourstudyaimedtoaddresstwoprimaryobjectives: firstly,todemonstratetheremarkablecomputational
efficiency of our algorithm, and secondly, to underscore the importance of quantifying uncertainty in
standarddiseaseriskscores. Inanidealclinicalcontext,theprimaryclinicalgoalwouldbetoestablish
asimpleandcost-effectiveriskscorethatcouldaccuratelycapturepatients’glucoseconditionswithout
relyingontraditionaldiabetesdiagnosticvariables,andstratifytheriskofdiabetestopromotenewpublic
healthinterventions[Matabuenaetal.,2024b]. Withuncertaintyquantification,wecanevaluatewhether
ourregressionmodelmcanbeusefulforsuchclinicalpurposes.
4.2.3 Results
TheimplementationofouralgorithmintheNHANESdatasetintheRsoftwareexhibitedremarkable
efficiency,withexecutiontimesofjustafewseconds.
Figure7presentstheresultstoapplytheuncertainityquantificationregioninthreepatients. Weobserve
individualuncertainitydifferenceswhenwepredicttheA1CandFPGbiomarkersbasedonindividual
clinicalcharacteristics. Patient(C),characterizedasyoungandhealthy(seeTable2),ispredictedtobe
inthenon-diabetesrangewithlowuncertainty. Incontrast,patient(A),whoisolder,hasahighwaist
circumference,andelevatedsystolicpressure,ispredictedtofallwithinthediabetesandprediabetesrange,
despiteexhibitingglucoseprofilescharacteristicofanon-diabetichealthyindividual. Theseoutcomes
underscoretheneedformoresophisticatedvariablestoaccuratelypredictthetrueglycemicpatientstatus,
asalsoevidencedbythemarginalR2foreachvariablethattakesvaluesequalto0.12and0.08,respectively
fortheA1CandFPG.
Inseparateresearch[Matabuenaetal.,2024b],weprovideevidencethatweneedtheincorporateatleast
one diabetes biomarker that directly measures the glucose of the individuals, such as FPG or A1C, is
indispensableforbuildingreliablepredictivemodels. Essentially,thishighlightsthatpredictingDiabetes
Mellitusisimpossiblewithoutconsideringspecificglucosemeasurementsorproxyvariablesforthem.
ID Age Waist SystolicPressure DiastolicPressure Triglycerides Glucose GlycosylatedHemoglobin
45424(A) 76 114.30 144 66 64 91.00 5.10
31858(B) 55 107.70 128 70 72 98.00 7.60
28159(C) 23 84.60 124 64 147 81.00 5.40
Table2: Characteristicsofthreepatientsinareal-lifeexamplewheretheresponsevariableismultivariate
(bivariate)Euclideandata.
26A
B
C
80 100 120 140 160 180 200
Glucose mg/dL
Figure 7: Prediction regions for three patients based on the geometry of the Euclidean distance. The
black lines in the plot indicate the transition between prediabetes and diabetes status. Patient (C) is
normoglycemic, while the other two patients, (A) and (B), exhibit oscillations between two glycemic
statuses. Patient(B)ischaracterizedasnormoglycemicanddiabetic,whilepatientAshowsdiabetesand
prediabetes. Theplothighlightsthevaryingglycemicpatternsaccordingtopatientcharacteristics.
4.3 DistributionalRepresentationofBiosensorTimeSeries
4.3.1 Motivation
The field of distributional data analysis has seen significant growth within data–science communities
[Klein,2023,Matabuenaetal.,2022a,Meunieretal.,2022],largelyduetoitscriticalroleinunderstand-
ing the marginal distributional characteristics of biological time series in regression modeling. We
investigate the probability distributions within continuous glucose monitor (CGM) time series data
[Matabuenaetal.,2021a], vital for discerning distributional patterns like hypoglycemia, and hyper-
glycemia in diabetes research. Figure 8 illustrates such mathematical transformation in the case of
aonenon-diabeticanddiabeticindividual
27
%
nibolgomeh
detalysocylG
5.7
0.7
5.6
0.6
5.5
0.5
5.4
0.4Figure8: ThefigurepresentstheprocessoftransformationCGMtimeseriesoftwoindividualsintheir
marginaldensityfunctionsandmarginalquantilefunctions.
We focus on analyzing biological outcomes defined in the space Y =W (T), comprising univariate
2
continuousprobabilitydistributionsonthecompactsupportT =[40,400]⊂R. Thisworkemphasizes
"distributionalrepresentation"throughquantilefunctions,aimingtoenrichourunderstandingofglucose
profiles’ impacts from various factors beyond CGM simple summary as CGM mean and – standard
deviationvaluesestimatedwiththerawglucosetimeseries.
Givenarandomsampleofhealthyindividuals,thegoalofouranalysisistoprovidethereferencequantile
glucosevalueswithouruncertaintyquantificationalgorithmacrossdifferentagegroups.Thedetermination
ofthisreferenceprofilecanhavevariousapplications,suchasdetectingindividualsathighriskofdiabetes
mellitus, as well as determining threshold criteria considering the latest advancements about glucose
homeostasisprovidedbyaCGMmonitor. Wenotethattheglucosevaluesatleast,inaverageglucose
levels increase with the age, and according to this biological behaviour, we must move to a medicine
basedonpersonalizedcriteria. TheuseofCGMonedistributionalrepresentationsallowstoexaminethis
biologicalphenomenoninall,low,middleandhigh-glucoseconcentrations.
4.3.2 DataDescription
Datafrom[Shahetal.,2019],whichcollectedglucosevaluesat5-minuteintervalsoverseveraldaysfrom
non-diabeticindividualsineverydaysettings,wasconsideredinouranalysis. Thisdatawasoriginally
collected to establish normative glucose ranges with simple summaries as CGM mean values by age.
Extendingthisfoundation,weadoptthedistributionalperspectiveofCGMdataasourregressionmodel’s
response,utilizingthe2-Wassersteindistance(equivalently,quantilerepresentation)inGlobalFréchet
regression. Foranalysisandvisualization,weapplythesupremedistanced (·,·)=∥·−·∥ ,settingthe
2 ∞
confidencelevelatα =0.2andthekNNsmoothingparametertok=30.
4.3.3 Results
Theapplicationofouruncertaintyquantificationalgorithmshowsavariationinuncertaintylevelsacross
differentagegroups,asoutlinedinFigure9. However,theanalysisrevealsaconsistentconditionalmean
28ofglucoseacrossagesbutamarkedincreaseintheuncertaintyofquantileglucosevalueswiththeincrease
oftheageofpatients. Theseclinicalfindingsenhanceourcapabilitytoclassifyandmonitorhealthin
non-diabeticsthroughCGM.Thisapproachtodefiningdiseasestatesoffersapathwaytowardsperson-
alizedmedicine,asevidencedbyitsapplicationinourresearchonpersonalizedsarcopeniadefinitions
[Matabuenaetal.,2023a],wheretheresponsevariablewasfinite-dimensionaloutcome(Y =R2).
20 50
160 160
120 120
80 80
30 60
160 colour 160 colour
120 L Po rew de ir c tB ioo nund 120 L Po rew de ir c tB ioo nund
Upper Bound Upper Bound
80 80
40 70
160 160
120 120
80 80
0.00 0.25 Pr0o.5b0, p 0.75 1.00 0.00 0.25 Pr0o.5b0, p 0.75 1.00
(a)Middle-ageindividuals (b)Elderlyindividuals
Figure9: Thefigurepresentsthenormativecontinuousglucosemonitoring(CGM)distributionalvalues
across different age groups, with a confidence level α =0.2. Our analysis indicates that while the
conditionalmeanvaluesremainsimilaracrossdifferentagegroups,thereisanincreaseinuncertaintyas
ageincreases.
4.4 NeuroimageApplications: LaplacianGraphs
4.4.1 Motivation
Neuroimaging represents important field that is motivated by the development of functional and met-
ric space statistical methods in order to improve or udnerstanding the behaviour of the human brain
[DubeyandMüller,2020,Daietal.,2021,BhattacharjeeandMüller,2022,Chenetal.,2021a]. Predom-
inantly, functional magnetic resonance imaging (fMRI) serves as the benchmark for analyzing brain
structures[Wangetal.,2021,Chenetal.,2021a,Pervaizetal.,2020].
SummarizingfMRIdata’suniquebrainstructuresignaturesinvolvesgeneratingindividualprofiles. These
profiles estimate intra- and inter-regional cerebral connections through both continuous (correlation
matrices)anddiscrete(graphstructures)datarepresentations[Wangetal.,2021].
Thereisagrowinginterestinapplyinguncertaintyquantificationtechniqueswithinneuroimaging. Yet,
thesemethodspredominantlyemployunivariateapproaches,highlightinganeedformorecomprehensive
models[Ernstingetal.,2023].
Thegoalofthisanalysisistohighlighttheversatilityofouralgorithmtoquantifytheuncertaintyover
graphs. For each patient, a graph is avalaible that measures the connectivity between different brain
regions.
4.4.2 fMRIrepresentionwithLaplaciangraphs
We begin by examining the continuous domain of Pearson correlation matrices Y with dimension r,
(cid:113)
utilizingtheFrobeniusmetricd FRO(A,B)= ∑r i,j=1(A ij−B ij)2. Thisapproachextendstothenetwork
space,characterizedbyrnodesandemployingthesamemetricforLaplacianmatrices. Toaligngraph
spaceswiththeirLaplacianrepresentations,certaintechnicalprerequisitesarenecessary.
29
)p(Q )p(QConsideranetworkG =(V,E)withnodesV ={v ,...,v }andedgeweightsE={w :w ≥0;i,j=
m 1 r ij ij
1,...,r}. WeassumethatG isasimplegraph,devoidofself-loopsormultipleedgesandedgeweights
m
bounded0≤w ≤w.
ij
WedefinethegraphLaplacianasthematrixL=(l ),where
ij
(cid:40)
−w , ifi̸= j
ij
l =
ij
∑ k̸=iw ik, ifi= j
forallindicesi,j=1,...,r. Thisdefinitionleadstothecharacterizationofthespaceofnetworksthrough
theassociatedspaceofgraphLaplacians,definedas:
L =(cid:8) L=(l ):L=LT,L1 =0 ,−W ≤l ≤0fori̸= j(cid:9) ,
r ij r r ij
where1 and0 denotether-vectorsofonesandzeroes,respectively.
r r
4.4.3 DataDescription
Our study leverages an uncertainty quantification framework to analyze neuroimaging data, focusing
on fMRI datasets from schizophrenia patients (n=60) and a control group (n=45) obtained from
[Reliónetal.,2019].
WeutilizedLaplaciangraphsconstructedfromthedata,followingthepreprocessingstepsfrom[Reliónetal.,2019].
Inouranalysis,weconsiderauniquepredictorX ∈{0,1},whereX =1indicatestheschizophreniaofthe
individual.
4.4.4 Results
UtilizingGlobalFréchetregressioninthespaceofLaplaciannetworksY =(L ,d ),whichisequipped
r FRO
withtheFrobeniusdistanceappliedtographLaplacians,weestimatedtheregressionfunctionm. Subse-
quently,weappliedtheheteroscedasticuncertaintyquantificationalgorithmwithafixedconfidencelevel
ofα =0.2andasmoothingparameterk=20. Figure10illustratestheseconditionalmeanestimations
alongwiththeiruncertaintyintervals. Theanalysisrevealssignificantuncertainty,suggestingthepotential
utilityofincorporatingadditionalpredictorstoreducedthelargeuncertainityobservedintheregression
model.
4.5 Variableselectioninphysicalactivityexample
Physicalexerciseiswidelyrecognizedasaneffectivenon-pharmacologicalinterventionforabroadrange
ofdiseases,aswellasameansofmitigatingphysiologicaldeclinewithageandimprovingoverallhealth
[HarridgeandLazarus,2017]. Therefore,understandingthepatientattributesthatcontributetovariations
inphysicalactivitylevelsisofgreatscientificinterestandcaninformthedevelopmentofpublichealth
policiesaimedatreducingdisparitiesinphysicalactivityacrossdifferentsubpopulations. Inthisstudy,we
illustrateourvariableselectionmethodsforidentifyingrelevantvariablesthatareassociatedwithphysical
activitylevelsofanindividual.
4.5.1 DataDescription
Thisstudyuseddatafromthecombined2011-2014NHANEScohort,whichinvolvedacomprehensive
array of standardized health examinations and medical tests. These evaluations covered biochemical,
dietary,physicalactivity,andanthropometricassessments. Tomeasurephysicalactivitylevelsathigh
resolution,thestudyutilizedtheActiGraphGT3X+accelerometer(Actigraph,Pensacola,FL)wornonthe
30Figure10: Left: Conditionalmeanfunction. Center: Leftendoftheuncertaintyset. Right: Rightendof
theuncertaintyset. Uncertaintyanalysisfromapatientwithschizophreniausingasaconfidencelevel20
percent.
non-dominantwristforsevenfullandtwopartialdaysamongasubsampleofparticipants. Furtherdetails
regardingthespecificprotocolsforcollectingNHANESvariablescanbeaccessedontheofficialwebsite
athttps://www.cdc.gov/nchs/nhanes/index.htm.
In our investigation, we adopt a functional perspective to summarize physical activity profiles using
distributionalquantilerepresentations. Theserepresentationsareequippedwiththe2Wassersteindistance
(Y =W ([a,b])), as originally proposed in [MatabuenaandPetersen,2023]. Our predictor variables
2
includegender,age,waistcircumference,glucoselevels,andascalarsummaryofenergeticexpenditure,
totalactivitycount,anddiethealthscore. Wepositedthatthebiochemicalvariableglucosewouldexhibita
weakassociationwithphysicalactivitylevels,whilethesummaryphysicalactivityvariablesanddietwould
displayastrongerrelationship. Moreover,weanticipatedthattheremainingvariableswoulddemonstrate
moderateconnectionswithdailyphysicalactivityandenergyexpenditure.
4.5.2 Results
Theglobalimportanceofrelevantandnon-relevantvariablesforpredictingdistributionalphysicalactivity
representationsissummarizedinTable3. Initially,basedonourhypothesis,weexpectedglucosetobe
non-relevant,whilewaistcircunferencewouldexhibitastatisticalassociationwiththeresponse. However,
theresultsofthenewvariableselectionmethodsurprisedus,indicatingthatwaistcircunferenceisnota
significantvariable. Thisunexpectedoutcomecanbeattributedtothefactthattheeffectofwaistisalready
captureddirectlybythetotalactivitycount(TAC),asbothvariablesarecorrelated.
Tovisuallyillustratethelocalimportanceoftheanalyzedvariables,wepresentFigure2. Thefiguredepicts
theintensityofimportanceforeachvalueofthepredictoronthey-axis. Notably,inourapplication,the
31importanceofthevariablesincreaseswithhighervalues. Thistrendisparticularlypronouncedforthe
TACvariable,wherelargerTACvaluescorrespondtohighervariableimportance.
BothTable3andFigure2offervaluableinsightsintotherelevanceandimportanceofthevariablesin
predictingdistributionalphysicalactivityrepresentations. Thesefindingscontributetounderstandingthe
individualcharacteristicsthatimpactphysicalactivityprofiles.
VariableNo. VariableName Selected Rawp-value
1 Gender TRUE 0.003
2 Age TRUE <0.001
3 Waist FALSE <0.26
4 TAC TRUE <0.001
5 HealthyEatingIndex TRUE <0.001
6 GlucoseValues FALSE <0.04
Table 3: Summary of results from applying a new variable selection method to predict distributional
physicalactivityrepresentationsusingdatafromtheNHANES2011-2014dataset. VariableNo. indicates
thevariablenumberintheFigure2.
5 Discussion
This paper introduces a novel data analysis framework designed to quantify uncertainty in regression
modelswithrandomresponsestakingvaluesinmetricspaces. Ourapproachdemonstratesversatility,
applicabletoawiderangeofregressionalgorithms,andoperatesunderminimaltheoreticalconditions.Our
methodprovidesnon-asymptoticguaranteesinhomoscedasticcases. Furthermore,thisnoveluncertainty
quantificationframeworkextendsthenotionofconditionalquantilefunctionformetricspaceresponses
[Liuetal.,2022].
Inthecontextofhomoscedasticity,ourapproachrepresentsanaturalgeneralizationofsplitconformal
methodsbyincorporatingthedistancefunctiond . asaconformityscore. Fortheheteroscedasticcase,we
2
drawuponrecentworkbyGyörfiandWalkonunivariateresponses[GyörfiandWalk,2019],extending
theirmethodologytometricspaces. Throughextensivesimulationsandtheoreticalanalysis,wevalidate
theeffectivenessofourmethodandhighlightitspropertiesinvarioussettings.
Weacknowledgethatintheheteroscedasticcase,theselectionofmodelhyperparameters,specificallyd ,
2
andk,smoothingparameter,cansignificantlyimpactthequalityoffinalestimatorresults. Toaddressthis
issueeffectively,weproposeexploringstabilityselectiontechniques[MeinshausenandBuhlmann,2010]
andotherresamplingtechniquesbasedonbootstrapforthekNNmethod,asproposedintheliterature
[Halletal.,2008,Samworth,2012]. Investigatingtheseapproachesinfutureresearchisanticipatedto
offervaluablesolutionstothetuningparameterproblem.
The effectiveness of our approach is demonstrated through different relevant medical examples. For
example,wepresentanovelapplicationindiabetes,proposingnormativedistributionalglucosevalues
acrossdifferentagegroupsusingthenotionofglucodensity[Matabuenaetal.,2021a]. Currently,theuse
ofCGMdevicesindiabetesresearchisofincreasinginterest[Keshetetal.,2023],andourapplications
havecontributedtothisdirectioninhumanhealthresearch.
Moreover,wehavedevelopedavariableselectionmethodformetricspaceresponses. Thismethodiscom-
putationallyefficienct. Importantly,ourapproachintegratesintoothersemiparametricmodels,suchasthe
partialsingleindexFréchetmodel[Ghosaletal.,2023],distinguishingitfromexistingvariableselection
methodsinmetricspacesthatarelimitedtotheglobalFréchetregressionmodel[Tuckeretal.,2021].
Futureresearchdirectionsforourmethodaregearedtowardsexpandingitsapplicabilityandadvancingits
capabilitiesinhandlingdiversedatascenariosandstructures.Onecrucialaspectisextendingtheuncertainty
32quantificationframeworktoeffectivelyhandletemporallyandspatiallycorrelateddata,enablingusto
tacklemorecomplexreal-worldsituations. Additionalrelevantdirectioncouldincludetheaccommodation
ofnon-Euclideanpredictors[CohenandKontorovich,2022].
Acknowledgments
ThisresearchwaspartiallysupportedbyUSHorizon2020researchandinnovationprogramundergrant
agreementNo. 952215(TAILORConnectivityFund). GáborLugosiacknowledgesthesupportofAyudas
FundaciónBBVAaProyectosdeInvestigaciónCientífica2021andtheSpanishMinistryofEconomyand
Competitiveness,GrantPGC2018-101643-B-I00andFEDER,EU.
References
[AngelopoulosandBates,2023] Angelopoulos, A. N. and Bates, S. (2023). Conformal prediction: A
gentleintroduction. FoundationsandTrends®inMachineLearning,16(4):494–591.
[Banerjietal.,2023] Banerji,C.R.S.,Chakraborti,T.,Harbron,C.,andMacArthur,B.D.(2023).Clinical
aitoolsmustconveypredictiveuncertaintyforeachindividualpatient. NatureMedicine.
[Barberetal.,2023] Barber,R.F.,Candès,E.J.,Ramdas,A.,andTibshirani,R.J.(2023). Conformal
predictionbeyondexchangeability. TheAnnalsofStatistics,51(2):816–845.
[Batesetal.,2023] Bates,S.,Candès,E.,Lei,L.,Romano,Y.,andSesia,M.(2023). Testingforoutliers
withconformalp-values. TheAnnalsofStatistics,51(1):149–178.
[Bhattacharjeeetal.,2023] Bhattacharjee, S., Li, B., and Xue, L. (2023). Nonlinear global fr\’echet
regressionforrandomobjectsviaweakconditionalexpectation. arXivpreprintarXiv:2310.07817.
[BhattacharjeeandMüller,2021] Bhattacharjee,S.andMüller,H.-G.(2021). Singleindexfréchetregres-
sion. arXivpreprintarXiv:2108.05437.
[BhattacharjeeandMüller,2022] Bhattacharjee,S.andMüller,H.-G.(2022). Concurrentobjectregres-
sion. ElectronicJournalofStatistics,16(2):4031–4089.
[BhattacharjeeandMüller,2023] Bhattacharjee, S.andMüller, H.-G.(2023). Geodesicmixedeffects
modelsforrepeatedlyobserved/longitudinalrandomobjects. arXivpreprintarXiv:2307.05726.
[BiauandDevroye,2015] Biau,G.andDevroye,L.(2015). Lecturesonthenearestneighbormethod,
volume246. Springer.
[BoehmVocketal.,2015] BoehmVock,L.F.,Reich,B.J.,Fuentes,M.,andDominici,F.(2015). Spatial
variableselectionmethodsforinvestigatingacutehealtheffectsoffineparticulatemattercomponents.
Biometrics,71(1):167–177.
[BultéandSørensen,2023] Bulté,M.andSørensen,H.(2023). Medoidsplitsforefficientrandomforests
inmetricspaces. arXivpreprintarXiv:2306.17031.
[Candèsetal.,2023] Candès,E.,Lei,L.,andRen,Z.(2023). Conformalizedsurvivalanalysis. Journal
oftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,85(1):24–45.
[Cauchoisetal.,2021] Cauchois,M.,Gupta,S.,andDuchi,J.C.(2021). Knowingwhatyouknow: valid
andvalidatedconfidencesetsinmulticlassandmultilabelprediction. JournalofMachineLearning
Research,22(81):1–42.
33[ChenandMüller,2023] Chen,H.andMüller,H.-G.(2023).Slicedwassersteinregression.arXivpreprint
arXiv:2306.10601.
[Chenetal.,2021a] Chen, Y., Dubey, P., Müller, H.-G., Bruchhage, M., Wang, J.-L., and Deoni, S.
(2021a). Modelingsparselongitudinaldatainearlyneurodevelopment. NeuroImage,237:118079.
[Chenetal.,2021b] Chen,Y.,Lin,Z.,andMüller,H.-G.(2021b). Wassersteinregression. Journalofthe
AmericanStatisticalAssociation,116(535):1–14.
[ChengandYang,2022] Cheng,J.andYang,P.(2022). Conformalinferenceforheterogeneouspolicy
effect.
[Chernozhukovetal.,2021a] Chernozhukov, V., Wüthrich, K., and Zhu, Y. (2021a). Distributional
conformalprediction. ProceedingsoftheNationalAcademyofSciences,118(48):e2107794118.
[Chernozhukovetal.,2021b] Chernozhukov, V., Wüthrich, K., and Zhu, Y. (2021b). An exact and
robustconformalinferencemethodforcounterfactualandsyntheticcontrols. JournaloftheAmerican
StatisticalAssociation,116(536):1849–1864.
[ChhikaraandGuttman,1982] Chhikara,R.S.andGuttman,I.(1982). Predictionlimitsfortheinverse
gaussiandistribution. Technometrics,24(4):319–324.
[CohenandKontorovich,2022] Cohen, D. T. and Kontorovich, A. (2022). Metric-valued regression.
ArXivPreprint.
[Cover,1968] Cover,T.(1968). Estimationbythenearestneighborrule. IEEETransactionsonInforma-
tionTheory,14(1):50–55.
[Daietal.,2021] Dai, X., Lin, Z., and Müller, H.-G. (2021). Modeling sparse longitudinal data on
Riemannianmanifolds. Biometrics,77(4):1328–1341.
[Dasetal.,2022] Das, S., Zhang, Y., and Politis, D. N. (2022). Model-based and model-free point
predictionalgorithmsforlocallystationaryrandomfields. arXivpreprintarXiv:2212.03079.
[Devroye,1981] Devroye,L.(1981). OntheAlmostEverywhereConvergenceofNonparametricRegres-
sionFunctionEstimates. TheAnnalsofStatistics,9(6):1310–1319.
[DietterichandHostetler,] Dietterich,T.andHostetler,J. Reinforcementlearningpredictionintervals
withguaranteedfidelity.
[DietterichandHostetler,2022] Dietterich,T.G.andHostetler,J.(2022). Conformalpredictionintervals
formarkovdecisionprocesstrajectories. arXivpreprintarXiv:2206.04860.
[Diquigiovannietal.,2022] Diquigiovanni,J.,Fontana,M.,andVantini,S.(2022). Conformalprediction
bandsformultivariatefunctionaldata. JournalofMultivariateAnalysis,189:104879.
[DrydenandMardia,2016] Dryden, I. L. and Mardia, K. V. (2016). Statistical shape analysis: with
applicationsinR,volume995. JohnWiley&Sons.
[Dubeyetal.,2022] Dubey, P., Chen, Y., andMüller, H.-G.(2022). Depthprofilesandthegeometric
explorationofrandomobjectsthroughoptimaltransport. arXivpreprintarXiv:2202.06117.
[DubeyandMüller,2019] Dubey,P.andMüller,H.-G.(2019). Fréchetanalysisofvarianceforrandom
objects. Biometrika,106(4):803–821.
34[DubeyandMüller,2020] Dubey, P. and Müller, H.-G. (2020). Functional models for time-varying
randomobjects. JournaloftheRoyalStatisticalSociety: SeriesB(StatisticalMethodology),82(2):275–
327.
[DubeyandMüller,2022] Dubey,P.andMüller,H.-G.(2022). Modelingtime-varyingrandomobjects
anddynamicnetworks. JournaloftheAmericanStatisticalAssociation,117(540):2252–2267.
[Dunnetal.,2022] Dunn,R.,Wasserman,L.,andRamdas,A.(2022). Distribution-freepredictionsets
fortwo-layerhierarchicalmodels. JournaloftheAmericanStatisticalAssociation,pages1–12.
[Ernstingetal.,2023] Ernsting,J.,Winter,N.R.,Leenings,R.,Sarink,K.,Barkhau,C.B.C.,Fisch,L.,
Emden,D.,Holstein,V.,Repple,J.,Grotegerd,D.,Meinert,S.,Investigators,N.,Berger,K.,Risse,B.,
Dannlowski,U.,andHahn,T.(2023). Fromgroup-differencestosingle-subjectprobability: Conformal
prediction-baseduncertaintyestimationforbrain-agemodeling.
[FanandMüller,2021] Fan, J. and Müller, H.-G. (2021). Conditional Wasserstein barycenters and
interpolation/extrapolationofdistributions. arXivpreprintarXiv:2107.09218.
[FixandHodges,1951] Fix,E.andHodges,J.(1951). Discriminatoryanalysis,nonparametricdiscrimi-
nationusaschoolofmedicine. Texas: RendolphField,1952.
[FongandHolmes,2021] Fong,E.andHolmes,C.C.(2021).Conformalbayesiancomputation.Advances
inNeuralInformationProcessingSystems,34:18268–18279.
[Fontanaetal.,2023] Fontana, M., Zeni, G., and Vantini, S. (2023). Conformal prediction: a unified
reviewoftheoryandnewchallenges. Bernoulli,29(1):1–23.
[FoutandFosdick,2023] Fout,A.andFosdick,B.K.(2023). Fréchetcovarianceandmanovatestsfor
randomobjectsinmultiplemetricspaces. arXivpreprintarXiv:2306.12066.
[FoygelBarberetal.,2021] FoygelBarber,R.,Candès,E.J.,Ramdas,A.,andTibshirani,R.J.(2021).
Thelimitsofdistribution-freeconditionalpredictiveinference. InformationandInference: AJournalof
theIMA,10(2):455–482.
[FraserandGuttman,1956] Fraser, D. A. and Guttman, I. (1956). Tolerance regions. The Annals of
MathematicalStatistics,27(1):162–179.
[Fréchet,1948] Fréchet, M. R. (1948). Les éléments aléatoires de nature quelconque dans un espace
distancié. Annalesdel’institutHenriPoincaré,10(4):215–310.
[Gammermanetal.,1998] Gammerman,A.,Vladimir,V.,andVapnik,V.(1998). Learningbytransduc-
tion. InProceedingsofthe1stAnnualConferenceonUncertaintyinArtificialIntelligence(UAI-85),
pages148–155.
[García-MeixideandMatabuena,2023] García-Meixide, C. and Matabuena, M. (2023). Causal sur-
vival embeddings: non-parametric counterfactual inference under censoring. arXiv preprint
arXiv:2306.11704.
[Gawlikowskietal.,2023] Gawlikowski,J.,Tassi,C.R.N.,Ali,M.,Lee,J.,Humt,M.,Feng,J.,Kruspe,
A.,Triebel,R.,Jung,P.,Roscher,R.,etal.(2023). Asurveyofuncertaintyindeepneuralnetworks.
ArtificialIntelligenceReview,pages1–77.
[Geenensetal.,2023] Geenens,G.,Nieto-Reyes,A.,andFrancisci,G.(2023).Statisticaldepthinabstract
metricspaces. StatisticsandComputing,33(2):46.
35[Geisser,2017] Geisser,S.(2017). Predictiveinference. ChapmanandHall/CRC.
[Ghosaletal.,2023] Ghosal, A., Matabuena, M., Meiring, W., and Petersen, A. (2023). Predicting
distributionalprofilesofphysicalactivityinthenhanesdatabaseusingapartiallylinearsingle-index
fréchetregressionmodel. arXivpreprintarXiv:2302.07692.
[GhosalandMatabuena,2023] Ghosal,R.andMatabuena,M.(2023). Multivariatescalaronmultidimen-
sionaldistributionregression.
[Ghosaletal.,2021a] Ghosal, R., Varma, V. R., Volfson, D., Hillel, I., Urbanek, J., Hausdorff, J. M.,
Watts, A., and Zipunnikov, V. (2021a). Distributional data analysis via quantile functions and its
applicationtomodellingdigitalbiomarkersofgaitinAlzheimer’sdisease. Biostatistics. kxab041.
[Ghosaletal.,2021b] Ghosal,R.,Varma,V.R.,Volfson,D.,Urbanek,J.,Hausdorff,J.M.,Watts,A.,and
Zipunnikov,V.(2021b). Scalarontime-by-distributionregressionanditsapplicationformodelling
associationsbetweendaily-livingphysicalactivityandcognitivefunctionsinalzheimer’sdisease. arXiv
preprintarXiv:2106.03979.
[Gibbsetal.,2023] Gibbs, I., Cherian, J. J., and Candès, E. J. (2023). Conformal prediction with
conditionalguarantees. arXivpreprintarXiv:2305.12616.
[GoldfeldandQuandt,1965] Goldfeld,S.M.andQuandt,R.E.(1965). Sometestsforhomoscedasticity.
JournaloftheAmericanstatisticalAssociation,60(310):539–547.
[GyörfiandWalk,2019] Györfi,L.andWalk,H.(2019). Nearestneighborbasedconformalprediction.
InAnnalesdel’ISUP,volume63,pages173–190.
[Halletal.,2008] Hall,P.,Park,B.U.,andSamworth,R.J.(2008). Choiceofneighbororderinnearest-
neighborclassification.
[Hamadaetal.,2004] Hamada,M.,Johnson,V.,Moore,L.M.,andWendelberger,J.(2004). Bayesian
predictionintervalsandtheirrelationshiptotoleranceintervals. Technometrics,46(4):452–459.
[Hammourietal.,2023] Hammouri,Z.A.A.,Mier,P.R.,Félix,P.,Mansournia,M.A.,Huelin,F.,Casals,
M., andMatabuena, M.(2023). Uncertaintyquantificationinmedicinescience: Thenextbigstep.
ArchivosdeBronconeumología.
[Hanneke,2022] Hanneke,S.(2022). Universallyconsistentonlinelearningwitharbitrarilydependent
responses. InInternationalConferenceonAlgorithmicLearningTheory,pages488–497.PMLR.
[HarridgeandLazarus,2017] Harridge,S.D.andLazarus,N.R.(2017). Physicalactivity,aging,and
physiologicalfunction. Physiology,32(2):152–161.
[Harville,1976] Harville,D.(1976). Extensionofthegauss-markovtheoremtoincludetheestimationof
randomeffects. TheAnnalsofStatistics,4(2):384–395.
[HuandLei,2023] Hu,X.andLei,J.(2023). Atwo-sampleconditionaldistributiontestusingconformal
predictionandweightedranksum. JournaloftheAmericanStatisticalAssociation,pages1–19.
[Isenkuletal.,2014] Isenkul,M.,Sakar,B.,Kursun,O.,etal.(2014). Improvedspiraltestusingdigitized
graphicstabletformonitoringparkinson’sdisease. InThe2ndinternationalconferenceone-healthand
telemedicine(ICEHTM-2014),volume5,pages171–175.
[Jeonetal.,2022] Jeon, J.M., Lee, Y.K., Mammen, E., andPark, B.U.(2022). Locallypolynomial
Hilbertianadditiveregression. Bernoulli,28(3):2034–2066.
36[Jinetal.,2023] Jin,Y.,Ren,Z.,andCandès,E.J.(2023). Sensitivityanalysisofindividualtreatment
effects: Arobustconformalinferenceapproach. ProceedingsoftheNationalAcademyofSciences,
120(6):e2214889120.
[JohnstoneandCox,2021] Johnstone, C. and Cox, B. (2021). Conformal uncertainty sets for robust
optimization. InConformalandProbabilisticPredictionandApplications,pages72–90.PMLR.
[JohnstoneandNdiaye,2022] Johnstone,C.andNdiaye,E.(2022). Exactandapproximateconformal
inferenceinmultipledimensions. arXivpreprintarXiv:2210.17405.
[Keshetetal.,2023] Keshet, A., Shilo, S., Godneva, A., Talmor-Barkan, Y., Aviv, Y., Segal, E., and
Rossman,H.(2023). Cgmap: Characterizingcontinuousglucosemonitordatainthousandsofnon-
diabeticindividuals. CellMetabolism,35(5):758–769.e3.
[Klein,2023] Klein, N. (2023). Distributional regression for data analysis. arXiv preprint
arXiv:2307.10651.
[KleinandKneib,2020] Klein,N.andKneib,T.(2020).Directionalbivariatequantiles:arobustapproach
basedonthecumulativedistributionfunction. AStAAdvancesinStatisticalAnalysis,104(2):225–260.
[Kneibetal.,2021] Kneib,T.,Silbersdorff,A.,andSäfken,B.(2021). Rageagainstthemean–areview
ofdistributionalregressionapproaches. EconometricsandStatistics.
[Kuchibhotla,2020] Kuchibhotla,A.K.(2020). Exchangeability,conformalprediction,andranktests.
arXivpreprintarXiv:2005.06095.
[KurisuandOtsu,] Kurisu,D.andOtsu,T. Modelaveragingforglobalfréchetregression.
[Leietal.,2018] Lei,J.,G’Sell,M.,Rinaldo,A.,Tibshirani,R.J.,andWasserman,L.(2018).Distribution-
freepredictiveinferenceforregression.JournaloftheAmericanStatisticalAssociation,113(523):1094–
1111.
[Leietal.,2013] Lei,J.,Robins,J.,andWasserman,L.(2013). Distribution-freepredictionsets. Journal
oftheAmericanStatisticalAssociation,108(501):278–287.
[LeiandWasserman,2014] Lei, J. and Wasserman, L. (2014). Distribution-free prediction bands for
non-parametricregression. JournaloftheRoyalStatisticalSociety: SeriesB:StatisticalMethodology,
pages71–96.
[LiandLiu,2008] Li,J.andLiu,R.Y.(2008). Multivariatespacingsbasedondatadepth: I.construction
ofnonparametricmultivariatetoleranceregions. TheAnnalsofStatistics,36(3):1299–1323.
[Lietal.,2022] Li,X.,Ghosh,J.,andVillarini,G.(2022). Acomparisonofbayesianmultivariateversus
univariatenormalregressionmodelsforprediction. TheAmericanStatistician,0(0):1–9.
[Linetal.,2023] Lin,Z.,Müller,H.-G.,andPark,B.(2023). Additivemodelsforsymmetricpositive-
definitematricesandliegroups. Biometrika,110(2):361–379.
[Liuetal.,2022] Liu, H., Wang, X., and Zhu, J. (2022). Quantiles, ranks and signs in metric spaces.
arXivpreprintarXiv:2209.04090.
[Luetal.,2023] Lu, C., Yu, Y., Karimireddy, S. P., Jordan, M., and Raskar, R. (2023). Federated
conformalpredictorsfordistributeduncertaintyquantification. InInternationalConferenceonMachine
Learning,pages22942–22964.PMLR.
37[Lu,2023] Lu,H.(2023). DataAugmentationandConformalPrediction. PhDthesis,Massachusetts
InstituteofTechnology.
[Lyons,2013] Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability,
41(5):3284–3305.
[Lyons,2021] Lyons,R.(2021). Seconderratatodistancecovarianceinmetricspacess. TheAnnalsof
Probability,49(5):2668–2670.
[Major,1978] Major,P.(1978).Ontheinvarianceprincipleforsumsofindependentidenticallydistributed
randomvariables. JournalofMultivariateAnalysis,8(4):487–517.
[Matabuena,2022] Matabuena,M.(2022). Contributionsonmetricspaceswithapplicationsinpersonal-
izedmedicine. PhDthesis,UniversidadedeSantiagodeCompostela.
[Matabuenaetal.,2023a] Matabuena, M., Abdalla, P. P., Machado, D. R. L., Bohn, L., and Mota, J.
(2023a). Handgripstrengthconditionaltoleranceregionssuggesttheneedforpersonalizedsarcopenia
definition: ananalysisoftheamericannhanesdatabase. AgingClinicalandExperimentalResearch,
35(6):1369–1373.
[MatabuenaandCrainiceanu,2024] Matabuena,M.andCrainiceanu,C.M.(2024). Multilevelfunctional
distributionalmodelswithapplicationtocontinuousglucosemonitoringindiabetesclinicaltrials. arXiv
preprintarXiv:2403.10514.
[Matabuenaetal.,2024a] Matabuena, M., Díaz-Louzao, C., Ghosal, R., and Gude, F. (2024a). Per-
sonalizedimputationinmetricspacesviaconformalprediction: Applicationsinpredictingdiabetes
developmentwithcontinuousglucosemonitoringinformation.
[Matabuenaetal.,2023b] Matabuena,M.,Félix,P.,Ditzhaus,M.,Vidal,J.,andGude,F.(2023b). Hy-
pothesistestingformatchedpairswithmissingdatabymaximummeandiscrepancy: Anapplicationto
continuousglucosemonitoring. TheAmericanStatistician,0(0):1–13.
[Matabuenaetal.,2022a] Matabuena,M.,Félix,P.,García-Meixide,C.,andGude,F.(2022a). Kernel
machinelearningmethodstohandlemissingresponseswithcomplexpredictors.applicationinmod-
ellingfive-yearglucosechangesusingdistributionalrepresentations. ComputerMethodsandPrograms
inBiomedicine,page106905.
[Matabuenaetal.,2022b] Matabuena,M.,Félix,P.,Hammouri,Z.A.A.,Mota,J.,anddelPozoCruz,B.
(2022b). Physicalactivityphenotypesandmortalityinolderadults: anoveldistributionaldataanalysis
ofaccelerometryinthenhanes. AgingClinicalandExperimentalResearch,pages1–8.
[MatabuenaandPetersen,2023] Matabuena,M.andPetersen,A.(2023). Distributionaldataanalysisof
accelerometerdatafromtheNHANESdatabaseusingnonparametricsurveyregressionmodels. Journal
oftheRoyalStatisticalSocietySeriesC:AppliedStatistics,72(2):294–313.
[Matabuenaetal.,2021a] Matabuena,M.,Petersen,A.,Vidal,J.C.,andGude,F.(2021a).Glucodensities:
A new representation of glucose profiles using distributional data analysis. Statistical Methods in
MedicalResearch,30(6):1445–1464. PMID:33760665.
[Matabuenaetal.,2021b] Matabuena, M., Rodríguez-Mier, P., García-Meixide, C., and Leborán, V.
(2021b). Covid-19: Estimationofthetransmissiondynamicsinspainusingastochasticsimulatorand
black-boxoptimizationtechniques. Computermethodsandprogramsinbiomedicine,211:106399.
38[Matabuenaetal.,2024b] Matabuena, M., Vidal, J. C., Ghosal, R., and Onnela, J.-P. (2024b). Deep
learningframeworkwithuncertaintyquantificationforsurveydata: Assessingandpredictingdiabetes
mellitusriskintheamericanpopulation.
[MeinshausenandBuhlmann,2010] Meinshausen, N. and Buhlmann, P. (2010). Stability selection.
JournaloftheRoyalStatisticalSociety: SeriesB(StatisticalMethodology),72(4):417–473.
[Messoudietal.,2022] Messoudi, S., Destercke, S., and Rousseau, S. (2022). Ellipsoidal conformal
inferenceformulti-targetregression. InConformalandProbabilisticPredictionwithApplications,
pages294–306.PMLR.
[Meunieretal.,2022] Meunier, D., Pontil, M., and Ciliberto, C. (2022). Distribution regression with
slicedWassersteinkernels. InChaudhuri,K.,Jegelka,S.,Song,L.,Szepesvari,C.,Niu,G.,andSabato,
S.,editors,Proceedingsofthe39thInternationalConferenceonMachineLearning,volume162of
ProceedingsofMachineLearningResearch,pages15501–15523.PMLR.
[PanaretosandZemel,2020] Panaretos,V.M.andZemel,Y.(2020). AninvitationtostatisticsinWasser-
steinspace. SpringerNature.
[Pateletal.,2023] Patel, Y., McNamara, D., Loper, J., Regier, J., and Tewari, A. (2023). Variational
inferencewithcoverageguarantees. arXivpreprintarXiv:2305.14275.
[Pervaizetal.,2020] Pervaiz,U.,Vidaurre,D.,Woolrich,M.W.,andSmith,S.M.(2020). Optimising
networkmodellingmethodsforfMRI. Neuroimage,211:116604.
[Petersenetal.,2021] Petersen,A.,Liu,X.,andDivani,A.A.(2021). WassersteinF-testsandconfidence
bandsfortheFréchetregressionofdensityresponsecurves. TheAnnalsofStatistics,49(1):590–611.
[PetersenandMüller,2019] Petersen,A.andMüller,H.-G.(2019). Fréchetregressionforrandomobjects
witheuclideanpredictors. TheAnnalsofStatistics,47(2):691–719.
[Politis,2015] Politis,D.N.(2015). Model-freepredictioninregression. InModel-FreePredictionand
Regression,pages57–80.Springer.
[PolitisandRomano,1994] Politis,D.N.andRomano,J.P.(1994). Largesampleconfidenceregions
basedonsubsamplesunderminimalassumptions. TheAnnalsofStatistics,pages2031–2050.
[Qiuetal.,2024] Qiu,R.,Yu,Z.,andLin,Z.(2024). Semi-supervisedfréchetregression.
[Reliónetal.,2019] Relión,J.D.A.,Kessler,D.,Levina,E.,andTaylor,S.F.(2019). Networkclassifica-
tionwithapplicationstobrainconnectomics. TheAnnalsofAppliedStatistics,13(3):1648–1667.
[Romanoetal.,2019] Romano,Y.,Patterson,E.,andCandès,E.(2019). Conformalizedquantileregres-
sion. AdvancesinNeuralInformationProcessingSystems,32:3543–3553.
[Samworth,2012] Samworth,R.J.(2012). Optimalweightednearestneighbourclassifiers.
[Schötz,2021] Schötz,C.(2021). TheFréchetMeanandStatisticsinNon-EuclideanSpaces. PhDthesis.
[SeberandLee,2003] Seber,G.A.andLee,A.J.(2003). Linearregressionanalysis,volume330. John
Wiley&Sons.
[SesiaandCandès,2020] Sesia,M.andCandès,E.J.(2020). Acomparisonofsomeconformalquantile
regressionmethods. Stat,9(1):e261. e261sta4.261.
39[ShaferandVovk,2008] Shafer,G.andVovk,V.(2008). Atutorialonconformalprediction. Journalof
MachineLearningResearch,9(3).
[Shahetal.,2019] Shah,V.N.,DuBose,S.N.,Li,Z.,Beck,R.W.,Peters,A.L.,Weinstock,R.S.,Kruger,
D.,Tansey,M.,Sparling,D.,Woerner,S.,etal.(2019). Continuousglucosemonitoringprofilesin
healthynondiabeticparticipants:amulticenterprospectivestudy.TheJournalofClinicalEndocrinology
&Metabolism,104(10):4356–4364.
[Shapiroetal.,2023] Shapiro,I.,Stein,J.,MacRae,C.,andO’Reilly,M.(2023). Pulseoximetryvalues
from33,080participantsintheappleheart&movementstudy. npjDigitalMedicine,6(1):134.
[Singhetal.,2023] Singh,S.,Sarna,N.,Re,M.,Li,Y.,Lin,Y.,Orfanoudaki,A.,andBerger,M.(2023).
Distribution-free risk assessment of regression-based machine learning algorithms. arXiv preprint
arXiv:2310.03545.
[SolariandDjordjilovic´,2022] Solari,A.andDjordjilovic´,V.(2022). Multisplitconformalprediction.
Statistics&ProbabilityLetters,184:109395.
[Steyeretal.,2023] Steyer, L., Stöcker, A., and Greven, S. (2023). Elastic analysis of irregularly or
sparselysampledcurves. Biometrics,79(3):2103–2115.
[Sun,2022] Sun,S.(2022). Conformalmethodsforquantifyinguncertaintyinspatiotemporaldata: A
survey. arXivpreprintarXiv:2209.03580.
[SzékelyandRizzo,2017] Székely,G.J.andRizzo,M.L.(2017). Theenergyofdata. AnnualReviewof
StatisticsandItsApplication,4:447–479.
[Székelyetal.,2007a] Székely,G.J.,Rizzo,M.L.,andBakirov,N.K.(2007a). Measuringandtesting
dependencebycorrelationofdistances. TheAnnalsofStatistics,35(6):2769–2794.
[Székelyetal.,2007b] Székely,G.J.,Rizzo,M.L.,andBakirov,N.K.(2007b). Measuringandtesting
dependencebycorrelationofdistances. TheAnnalsofStatistics,35(6):2769–2794.
[Tengetal.,2021] Teng, J., Tan, Z., and Yuan, Y. (2021). T-sci: A two-stage conformal inference
algorithmwithguaranteedcoverageforcox-mlp. InInternationalConferenceonMachineLearning,
pages10203–10213.PMLR.
[ThombsandSchucany,1990] Thombs,L.A.andSchucany,W.R.(1990). Bootstrappredictionintervals
forautoregression. JournaloftheAmericanStatisticalAssociation,85(410):486–492.
[Tuetal.,2020] Tu,J.,Torrente-Rodríguez,R.M.,Wang,M.,andGao,W.(2020). Theeraofdigital
health: A review of portable and wearable affinity biosensors. Advanced Functional Materials,
30(29):1906713.
[Tuckeretal.,2021] Tucker, D. C., Wu, Y., and Mülller, H.-G. (2021). Variable selection for global
fréchetregression. JournaloftheAmericanStatisticalAssociation,0(0):1–15.
[Virta,2023] Virta,J.(2023). Spatialdepthfordatainmetricspaces. arXivpreprintarXiv:2306.09740.
[Vovk,2012] Vovk,V.(2012).Conditionalvalidityofinductiveconformalpredictors.InAsianconference
onmachinelearning,pages475–490.PMLR.
[Vovketal.,2005] Vovk,V.,Gammerman,A.,andShafer,G.(2005). Algorithmiclearninginarandom
world,volume29. Springer.
40[Vovketal.,2018] Vovk,V.,Nouretdinov,I.,Manokhin,V.,andGammerman,A.(2018).Cross-conformal
predictivedistributions. InConformalandProbabilisticPredictionandApplications,pages37–51.
PMLR.
[WangandLeng,2008] Wang,H.andLeng,C.(2008). Anoteonadaptivegrouplasso. Computational
statistics&dataanalysis,52(12):5277–5286.
[Wangetal.,2018] Wang,Y.-C.,Bohannon,R.W.,Li,X.,Sindhu,B.,andKapellusch,J.(2018). Hand-
gripstrength: normativereferencevaluesandequationsforindividuals18to85yearsofageresidingin
theunitedstates. JournalofOrthopaedic&SportsPhysicalTherapy,48(9):685–693.
[Wangetal.,2021] Wang,Z.,Sair,H.I.,Crainiceanu,C.,Lindquist,M.,Landman,B.A.,Resnick,S.,
etal.(2021).Onstatisticaltestsoffunctionalconnectomefingerprinting.CanadianJournalofStatistics,
49(1):63–88.
[WuandPolitis,2023] Wu,K.andPolitis,D.N.(2023). Bootstrappredictioninferenceofnon-linear
autoregressivemodels. arXivpreprintarXiv:2306.04126.
[XuandXie,2021] Xu,C.andXie,Y.(2021). Conformalpredictionintervalfordynamictime-series. In
InternationalConferenceonMachineLearning,pages11559–11569.PMLR.
[XuandXie,2023] Xu,C.andXie,Y.(2023). Conformalpredictionfortimeseries. IEEETransactions
onPatternAnalysisandMachineIntelligence.
[Yinetal.,2022] Yin,M.,Shi,C.,Wang,Y.,andBlei,D.M.(2022). Conformalsensitivityanalysisfor
individualtreatmenteffects. JournaloftheAmericanStatisticalAssociation,pages1–14.
[Zaffranetal.,2023] Zaffran,M.,Dieuleveut,A.,Josse,J.,andRomano,Y.(2023). Conformalprediction
withmissingvalues. arXivpreprintarXiv:2306.02732.
[Zhangetal.,2022] Zhang,Q.,Li,B.,andXue,L.(2022). Nonlinearsufficientdimensionreductionfor
distribution-on-distributionregression. arXivpreprintarXiv:2207.04613.
[Zhangetal.,2018] Zhang, S., Cheng, D., Deng, Z., Zong, M., and Deng, X. (2018). A novel knn
algorithmwithdata-drivenkparametercomputation. PatternRecognitionLetters,109:44–54.
[ZhangandPolitis,2022] Zhang,Y.andPolitis,D.N.(2022). Bootstrappredictionintervalswithasymp-
toticconditionalvalidityandunconditionalguarantees. InformationandInference: AJournalofthe
IMA,12(1):157–209.
[Zhongetal.,2023] Zhong,W.,Li,Z.,Guo,W.,andCui,H.(2023). Semi-distancecorrelationandits
applications. JournaloftheAmericanStatisticalAssociation,0(ja):1–23.
[ZhouandMüller,2022] Zhou,Y.andMüller,H.-G.(2022). Networkregressionwithgraphlaplacians.
JournalofMachineLearningResearch,23(320):1–41.
41A Theory
A.1 Homoscedasticcase
A.1.1 Statisticalconsistency
Proposition7. AssumethatAssumption1issatisfied. Then
1
∑ |d (Y,m(X))−d (Y,m(X))|=o (1). (26)
n 2 i i 2 i (cid:101) i p
2i∈[S2]
Furthermore,foranycontinuitypointv∈RofGwhereG(v)=P(d (Y,m(X))≤v),wehave:
2
|G(cid:101)∗(v)−G(v)|=o p(1), (27)
whereG(cid:101)∗(v)= n1 2∑ i∈[S2]I{d 2(Y i,m (cid:101)(X i))≤v}.
Proof. Forthefirstresult,observethat
1 1
∑ |d (Y,m(X))−d (Y,m(X))|≤ ∑ |d (m(X),m(X))|.
n 2 i i 2 i (cid:101) i n 2 i (cid:101) i
2i∈[S2] 2i∈[S2]
ByAssumption1andthelawoflargenumbers,wehave
1
∑ |d (Y,m(X))−d (Y,m(X))|=o (1).
n 2 i i 2 i (cid:101) i p
2i∈[S2]
Forthesecondpart,fixv∈Rasacontinuitypoint. DefineG(cid:101)∗ m(v)= n1 2∑ i∈[S2]I{d 2(Y i,m(X i))≤v}and
therandomquantityR T(v)=|G(cid:101)∗ m(v)−G(v)|,satisfying,bythelawoflargenumbers,R T(v)=o p(1).
Foranyfixedγ >0,definethesetA ={i∈[S ]:|d (Y,m(X))−d (Y,m(X))|≥γ}. Then,
γ 2 2 i (cid:101) i 2 i i
(cid:104) (cid:105)
n
2
G(cid:101)∗ m(v)−G(cid:101)∗(v)
≤(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)i∈∑ Aγ(I{d 2(Y i,m (cid:101)(X i))≤v}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)+(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)i∈∑
Ac
γ(I{d 2(Y i,m (cid:101)(X i)≤v))}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
≤|A γ|+(cid:12) (cid:12)∑(I{d 2(Y i,m (cid:101)(X i))≤v}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12).
(cid:12) (cid:12)
(cid:12)i∈Ac γ (cid:12)
Fori∈Ac,d (Y,m(X))−γ ≤d (Y,m(X))≤d (Y,m(X))+γ. Therefore,
γ 2 i i 2 i (cid:101) i 2 i i
∑ I{d (Y,m(X))≤v−γ}≤ ∑ I{d (Y,m(X))≤v}≤ ∑ I{d (Y,m(X))≤v+γ}.
2 i i 2 i (cid:101) i 2 i i
i∈Ac
γ
i∈Ac
γ
i∈Ac
γ
Foranycontinuitypointv∈R+andanyε >0,thereexistsδ >0suchthatforanyz∈(v−δ ,v+δ ),
v v v v
|G(z)−G(v)|<ε . Then,
v
(cid:12) (cid:12)
n 2(cid:12) (cid:12)G(cid:101)∗(v)−G(cid:101)∗ m(v)(cid:12)
(cid:12)
42(cid:12) (cid:12)
(cid:12) (cid:12)
≤|A γ|+(cid:12) (cid:12)∑ I{d 2(Y i,m (cid:101)(X i))≤v}− ∑ I{d 2(Y i,m(X i))≤v}(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12)i∈Ac γ i∈Ac γ (cid:12)
(cid:12) (cid:32) (cid:33)(cid:12)
(cid:12) (cid:104) (cid:105) (cid:12)
≤|A γ|+(cid:12) (cid:12)n
2
G(cid:101)∗ m(v+γ)−G(cid:101)∗ m(v−γ) − ∑ I{d 2(Y i,m(X i))≤v+γ}− ∑ I{d 2(Y i,m(X i))≤v−γ} (cid:12)
(cid:12)
(cid:12) i∈Aγ i∈A
δ
(cid:12)
≤|A |+n ((G(v+γ))−G(v−γ)+R (v+γ)+R (v−γ))+|A | (triangleinequality)
γ 2 T T γ
≤n (2ε +R (v+γ)+R (v−γ))+2|A |.
2 v T T γ
Firstlettingn →∞andthenγ →0,weobtain
2
|G(cid:101)∗(v)−G(v)|≤|G(cid:101)∗(v)−G(cid:101)m(v)|+R T(v)≤o p(1).
Corollary8. AssumethatAssumption1issatisfied. Forafixedα ∈(0,1),letq :=inf{t∈R:G(t)≥
1−α
1−α},andsupposethatq existsuniquelyandisacontinuitypointofG(·). Foranyε >0,asn →∞,
1−α 1
and,n →∞,wehave
2
lim P(cid:0)(cid:12) (cid:12)q (cid:101)m 1−α−q 1−α(cid:12) (cid:12)≥ε(cid:1) =1,
n2→∞
and
lim P(|q −q |≥ε)=1,
(cid:101)1−α 1−α
n2→∞
whereqm istheempiricalquantilefromtheempiricaldistribution
(cid:101)1−α
1
G(cid:101)m(t)= ∑ I{d 2(Y i,m(X i))≤t},
n
2i∈[S2]
andq istheempiricalquantilefromtheempiricaldistribution
(cid:101)1−α
1
G(cid:101)∗(t)=
n
∑ I{d 2(Y i,m (cid:101)(X i))≤t}.
2i∈[S2]
Proof. Bothresultsareconsequencesofthelawoflargenumbers,sinceG(cid:101)∗(q 1−α)=G(q 1−α)+o p(1)
andG(cid:101)∗ m(q 1−α)=G(q 1−α)+o p(1).
A.2 ProofofTheorem3
Thegoalofthissectionistoshow:
(cid:90)
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1),
X
whereCα(x)andC(cid:101)α(x)aredefinedinSection2.1.
Proof. Forafixedα∈(0,1),letq denotethecorrespondingquantileofd (Y,m(X)),andsupposethat
1−α 2
q
1−α
isacontinuitypointforthefunctionG(·). DefinethesetsC(cid:101)mα(x)=B(m(x),q (cid:101)1−α)andC(cid:101)qα(x)=
B(m(x),q ),consideringafixedx∈X.DefinealsothefunctionG∗(t,x)=P(d (Y,m(X))≤t|X=x).
(cid:101) 1−α 2 (cid:101)
Giventhepropertiesofthemetricinducedbythesymmetricdifferenceoftwosets,itholdsthat
43P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)
≤P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)+P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
+P(Y ∈C(cid:101)α(x)△C(cid:101)qα(x)|X =x,D n)+P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n).
Wewillanalyzethefourtermsseparately.
Case1:
P(Y ∈Cα(x)△C(cid:101)mα(X)|X =x,D n)
= P({Y :d (Y,m(X))>q ,d (Y,m(X))≤q }|X =x,D )
2 1−α 2 (cid:101)1−α n
+P({Y :d (Y,m(X))≤q ,d (Y,m(X))>q }|X =x,D )
2 1−α 2 (cid:101)1−α n
= 2|G(q )−G(q )|.
(cid:101)1−α 1−α
Integrating,wehave
(cid:90)
P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)P X(dx)
X
(cid:90)
=2|G(q )−G(q )| P (dx)=o (1),
(cid:101)1−α 1−α X p
X
andincombinationwithCorollary8.
Case2:
P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
=P({Y :d(Y,m(X))>q ,d (Y,m(X))≤q }|X =x,D )
(cid:101)1−α 2 (cid:101) (cid:101)1−α n
+P({Y :d (Y,m(X))≤q ,d (Y,m(X))>q }|X =x,D )
2 (cid:101)1−α 2 (cid:101) (cid:101)1−α n
≤P({Y :d (Y,m(X))≤q <d (m(X),m(X))+d (y,m(X))}|X =x,D )
2 (cid:101) (cid:101)1−α 2 (cid:101) 2 (cid:101) n
+P({Y :d (Y,m(X))≤q <d (m(X),m(X))+d (Y,m(X))}|X =x,D )
2 (cid:101)1−α 2 (cid:101) 2 n
≤G∗(q +d (m(x),m(x)),x)−G∗(q ,x)+G(q +d (m(x),m(x))−G(q ).
(cid:101)1−α 2 (cid:101) (cid:101)1−α (cid:101)1−α 2 (cid:101) (cid:101)1−α
Now,usingthecontinuityhypothesisforq ,∀ε >0,asn →∞,and,n →∞,wehave
1−α 1 2
lim P(|q −q |≥ε)=1,
(cid:101)1−α 1−α
n2→∞
andthatE(d (m(X),m(X))|D )→0as|D |→∞,weinferthat(cid:82) G∗(q +d (m(x),m(x)),x)−
2 (cid:101) train train X (cid:101)1−α 2 (cid:101)
G∗(q ,x)P (dx)=o (1). Repeatingfortheotherterm,wehave
(cid:101)1−α X p
(cid:90)
P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)
X
(cid:90)
= [G∗(q +d (m(x),m(x)),x)−G∗(q ,x)+G(q +d (m(x),m(x))−G(q )]P (dx)=o (1).
(cid:101)1−α 2 (cid:101) (cid:101)1−α (cid:101)1−α 2 (cid:101) (cid:101)1−α X p
X
Case3:
44P(Y ∈C(cid:101)α(x)△C(cid:101)qα(x)|X =x,D n)
=P({Y :d (Y,m(X))>q ,d (Y,m(X))≤q }|X =x,D )
2 1−α 2 (cid:101) 1−α n
+ P({Y :d (Y,m(X))≤q ,d(Y,m(X))>q }|X =x,D )
2 1−α (cid:101) 1−α n
ThisissimilartoCase2,exceptthatweexchangetheroleofq withq . Therefore,wehave
(cid:101)1−α 1−α
P(Y ∈Cα(x)△C(cid:101)qα(x)|X =x,D n)
≤G∗(q +d (m(x),m(x),x)−G∗(q ,x)+G(q +d (m(x),m(x)),x)−G(q )
1−α 2 (cid:101) 1−α 1−α 2 (cid:101) 1−α
Asaconsequence,
(cid:90)
[G∗(q +d (m(x),m(x),x)−G∗(q ,x)+G(q +d (m(x),m(x))−G(q ))]P (dx)=o (1).
1−α 2 (cid:101) 1−α 1−α 2 (cid:101) 1−α X p
X
Case4:
FollowingtheargumentsofCase1,wehavethat
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)
=P({d (Y,m(x))>q ,d (Y,m(x))≤q }|X =x,D )
2 (cid:101) 1−α 2 (cid:101) (cid:101)1−α n
+ P({Y :d (Y,m(X))≤q ,d (Y,m(X))>q }|X =x,D ),
2 (cid:101) 1−α 2 (cid:101) (cid:101)1−α n
and,
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)≤2|G∗(q (cid:101)1−α,x)−G∗(q 1−α,x)|=o p(1),
andasaconsequence
(cid:90)
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1).
X
Finally,combiningthepriorfourresults,weinferthat
(cid:90)
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1).
X
A.3 ProofofPropositon4
Proof. We begin by observing that, for the proof Proposition 4, we can decompose the probability of
interestasfollows:
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)
≤P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)+P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
+P(Y ∈C(cid:101)α(x)△C(cid:101)qα(x)|X =x,D n)+P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n).
Now,forafixedx∈X,wedecomposethefourtermsexplicitly:
451. P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)=2|G(q (cid:101)m 1−α)−G(q 1−α)|
2. P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
≤G∗(q +d (m(x),m(x)),x)−G∗(q ,x)+G(q +d (m(x),m(x)))−G(q )
(cid:101)1−α 2 (cid:101) (cid:101)1−α (cid:101)1−α 2 (cid:101) (cid:101)1−α
3. P(Y ∈Cα(x)△C(cid:101)qα(x)|X =x,D n)
≤G∗(q +d (m(x),m(x)),x)−G∗(q ,x)+G(q +d (m(x),m(x)))−G(q )
1−α 2 (cid:101) 1−α 1−α 2 (cid:101) 1−α
4. P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)=2|G∗(q (cid:101)1−α,x)−G∗(q 1−α,x)|
First of all, we note that for the second and third terms, we use the fact that G and G∗ are Lipschitz
functions,andthatweobtainanupperboundoftheformCd (m(x),m(x)).
2 (cid:101)
For the first and fourth terms, we can provide an upper bound in terms of the distance between the
populationquantileandtheempiricalquantile. Morespecifically,wehave
P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)+P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)≤4C|q (cid:101)1−α−q 1−α|.
Now,integrating(cid:82)
X
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)P X(dx),weobtainthedesiredresults.
A.4 Heteroscedasticcase
To extend consisting results to the heteroscedastic scenario, we employ analogous arguments as in
the homoscedastic case. The primary challenge arises from our use of a kNN algorithm to locally
estimatetheconditionaldistributionofdistances,G(v,x)=P(Y ∈d (Y,m(X))≤v|X =x),asappliedin
2
[GyörfiandWalk,2019]. Foragivenx∈Rpandv∈Rasacontinuitypoint,establishingconvergencein
probabilitycruciallyreliesontheexpression:
R T(v,x)=|G(cid:101)∗ m(v,x)−G(v,x)|=o p(1), (28)
whereG(cid:101)∗ m(v,x)= 1 k∑ i∈Nk(x)I{d 2(Y i,m(X i))≤v}.
Toaddressthesechallenges,wefirstestablishsomepreliminaryresults.
Theorem9(StrongconsistencyofkNN[Devroye,1981]). Let(X,Y),(X ,Y ),...,(X ,Y )beindependent
1 1 n n
identicallydistributedRp×R-valuedrandomvectorswithE(|Y|)<∞. Theregressionfunctionm(x)=
E(Y|X =x),forx∈Rp,isestimatedby
1
m(x)= ∑ Y, k∈N. (29)
(cid:101) k i
i∈Nk(x)
Assumealsothat
|Y|≤γ <∞
andk=k isasequenceofintegerssuchthat k →0andk→∞asn→∞.
n n
Then, for the nearest neighbor estimate, E{|m (x)−m(x)|}→0 as n→∞ for almost all x∈X, and
(cid:101)n
E{|m (X)−m(X)|}→0asn→∞. If,inaddition, k →∞ask,n→∞,then
(cid:101)n logn
E{|m (X)−m(X)||X ,Y ,...,X ,Y }→0a.s.
(cid:101)n 1 1 n n
46Lemma1. Supposethatk→∞and k →∞asn→∞andhypothesisofTheorem5aresatisfied. Then
logn
foralmosteveryx∈Rp,
|G(cid:101)∗ m(v,x)−G(v,x)|=o p(1)asn→∞,
and
E{|G(cid:101)∗ m(v,x)−G(v,x)|X 1,Y 1,...,X n,Y n}=o p(1)asn→∞,
whereG(cid:101)∗ m(v,x)= 1 k∑ i∈Nk(x)I{d 2(Y i,m(X i))≤v}.
Proof. ForafixedpositivevcontinuitypointofG(v,x)=P(d (Y,m(X))≤v|X =x),definethefunction
2
f :Rp×R→[0,1]as f(x,y)=I{d (y,m(x))≤v}. Consider
2
1 k
m (cid:101)(x)=
k
∑ f(X (i)(x),Y (i)(x))=G(cid:101)∗ m(v,x).
i=1
Notethat
(cid:12) (cid:12)
(cid:12)1 k (cid:12)
|G(cid:101)∗ m(v,x)−G(v,x)|=(cid:12)
(cid:12)k
∑ f(X (i)(x),Y (i)(x))−E[f(X,Y)|X =x](cid:12) (cid:12). (30)
(cid:12) i=1 (cid:12)
Now,definetherandomvariableY′= f(X,Y),andthepair(X,Y′)∈Rp×Rsatisfiestheconditionsof
Theorem9,whereweobtain:
|G(cid:101)∗ m(v,x)−G(v,x)|=o p(1)asn→∞, (31)
and
E{|G(cid:101)∗ m(v,x)−G(v,x)|X 1,Y 1,...,X n,Y n}→0a.sasn→∞.
A.4.1 Statisticalconsistency
Proposition10. AssumethatAssumption3holds. Foreveryfixedx∈X,andv∈Risacontinuitypoint
ofG(v,x)=P(d (Y,m(X))≤v|X =x),andk∈NsatisfyingtheregularityconditionsfromTheorem5,
2
then
|G(cid:101)∗(v,x)−G(v,x)|=o p(1), (32)
whereG˜∗(v,x)= 1 k∑ i∈Nk(x)I{d 2(Y i,m (cid:101)(X i))≤v}.
Proof. Fixv∈Rasacontinuitypoint. DefineG(cid:101)∗ m(v,x)= 1 k∑ i∈Nk(x)I{d 2(Y i,m(X i))≤v}andR T(v,x)=
|G(cid:101)∗ m(v,x)−G(v,x)|. ByLemma1R T(v,x)=o p(1),foralmosteveryx∈Rp.
Foranyfixedγ >0,definethesetA ={i∈N (x):|d (Y,m(X))−d (Y,m(X))|≥γ}. Then,
γ k 2 i (cid:101) i 2 i i
(cid:104) (cid:105)
k G(cid:101)∗ m(v,x)−G(cid:101)∗(v,x)
≤(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)i∈∑ ∈Aγ(I{d 2(Y i,m (cid:101)(X i))≤v}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)+(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12)i∈∑
Ac
γ(I{d 2(Y i,m (cid:101)(X i)≤v))}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
≤|A γ|+(cid:12) (cid:12)∑(I{d 2(Y i,m (cid:101)(X i))≤v}−I{d 2(Y i,m(X i))≤v})(cid:12) (cid:12).
(cid:12) (cid:12)
(cid:12)i∈Ac γ (cid:12)
Fori∈Ac,d (Y,m(X))−γ ≤d (Y,m(X))≤d (Y,m(X))+γ. Therefore,
γ 2 i i 2 i (cid:101) i 2 i i
∑ I{d (Y,m(X))≤v−γ}≤ ∑ I{d (Y,m(X))≤v}≤ ∑ I{d (Y,m(X))≤v+γ}.
2 i i 2 i (cid:101) i 2 i i
i∈Ac
γ
i∈Ac
γ
i∈Ac
γ
47Forafixedx∈Rp,andanycontinuitypointv∈R+andanyε >0,thereexistsδ >0suchthatforany
v v
z∈(v−δ ,v+δ ),|G(z,x)−G(v,x)|<ε . Then,
v v v
(cid:12) (cid:12)
k(cid:12) (cid:12)G(cid:101)∗(v,x)−G(cid:101)m(v,x)(cid:12)
(cid:12)
(cid:12) (cid:12)
(cid:12) (cid:12)
≤|A γ|+(cid:12) (cid:12)∑ I{d 2(Y i,m (cid:101)(X i))≤v}− ∑ I{d 2(Y i,m(X i))≤v}(cid:12) (cid:12)
(cid:12) (cid:12)
(cid:12)i∈Ac γ i∈Ac γ (cid:12)
(cid:12) (cid:32) (cid:33)(cid:12)
(cid:12) (cid:104) (cid:105) (cid:12)
≤|A γ|+(cid:12) (cid:12)k G(cid:101)∗ m(v+γ,x)−G(cid:101)m(v−γ,x) − ∑ I{d 2(Y i,m(X i))≤v+γ}− ∑ I{d 2(Y i,m(X i))≤v−γ} (cid:12)
(cid:12)
(cid:12) i∈Aγ i∈A
δ
(cid:12)
≤|A |+k((G(v+γ,x))−G(v−γ,x)+R (v+γ,x)+R (v−γ,x))+|A | (triangleinequality)
γ T T γ
≤k(2ε +R (v+γ,x)+R (v−γ,x))+2|A |.
v T T γ
Firstlettingn →∞,k→∞andγ →0,weobtain
2
|G(cid:101)∗(v,x)−G(v,x)|≤|G(cid:101)∗(v,x)−G(cid:101)m(v,x)|+R T(v,x)≤o p(1).
Corollary11. AssumethatAssumption3issatisfied. Forafixedx∈X,andα ∈(0,1),letq (x):=
1−α
inf{t∈R:G(t,x)≥1−α},andsupposethatq (x)existsuniquelyandisacontinuitypointofG(·,x).
1−α
∀ε >0,asn →∞,n →∞,k→∞wehave
1 2
lim lim P(cid:0)(cid:12) (cid:12)q (cid:101)m 1−α(x)−q 1−α(x)(cid:12) (cid:12)≥ε(cid:1) =1,
k→∞n2→∞
and
lim lim P(|q (x)−q (x)|≥ε)=1.
(cid:101)1−α 1−α
k→∞n2→∞
A.5 ProofofTheorem5
Thegoalofthisproofistoshow:
(cid:90)
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1),
X
whereCα(x)andC(cid:101)α(x)aredefinedasbefore.
Proof. Forafixedx∈Rp,andα ∈(0,1),letq (x)denotethecorrespondingquantileofd (Y,m(X))|
1−α 2
X =x,andsupposethatq 1−α(x)isacontinuitypointforthefunctionG(·,x). DefinethesetsC(cid:101)mα(x)=
B(m(x),q (cid:101)1−α(x))andC(cid:101)qα(x)=B(m (cid:101)(x),q 1−α(x)),consideringafixedx∈X. Definealsothefunction
G∗(t,x)=P(d (Y,m(X))≤t |X =x). Given the properties of the metric induced by the symmetric
2 (cid:101)
differenceoftwosets,itholdsthat
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)
≤P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)+P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
48+P(Y ∈Cα(x)△C(cid:101)qα(x)|X =x,D n)+P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n).
Wewillanalyzethefourtermsseparately.
Case1:
P(Y ∈Cα(x)△C(cid:101)mα(X)|X =x,D n)
= P({Y :d (Y,m(X))>q (x),d (Y,m(X))≤q (x)}|X =x,D )
2 1−α 2 (cid:101)1−α n
+P({Y :d (Y,m(X))≤q (x),d (Y,m(X))>q (x)}|X =x,D )
2 1−α 2 (cid:101)1−α n
= 2|G(q (x),x)−G(q (x),x)|.
(cid:101)1−α 1−α
Integrating,wehave
(cid:90)
P(Y ∈Cα(x)△C(cid:101)mα(x)|X =x,D n)P X(dx)
X
(cid:90)
=2|G(q (x),x)−G(q (x),x)| P (dx)=o (1),
(cid:101)1−α 1−α X p
X
andincombinationwithCorollary11.
Case2:
P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)
=P({Y :d(Y,m(X))>q (x),d (Y,m(X))≤q (x)}|X =x,D )+
(cid:101)1−α 2 (cid:101) (cid:101)1−α n
P({Y :d (Y,m(X))≤q (x),d (Y,m(X))>q (x)}|X =x,D )
2 (cid:101)1−α 2 (cid:101) (cid:101)1−α n
≤P({Y :d (Y,m(X))≤q (x)<d (m(X),m(X))+d (y,m(X))}|X =x,D )+
2 (cid:101) (cid:101)1−α 2 (cid:101) 2 (cid:101) n
P({Y :d (Y,m(X))≤q (x)<d (m(X),m(X))+d (Y,m(X))}|X =x,D )
2 (cid:101)1−α 2 (cid:101) 2 n
≤G∗(q (x)+d (m(x),m(x)),x)−G∗(q (x),x)+G(q (x)+d (m(x),m(x)),x)−G(q (x),x).
(cid:101)1−α 2 (cid:101) (cid:101)1−α (cid:101)1−α 2 (cid:101) (cid:101)1−α
Now,usingthecontinuityhypothesisforq (x),∀ε >0,asn →∞,n →∞,andk→∞wehave
1−α 1 2
lim lim P(cid:0)(cid:12) (cid:12)q (cid:101)m 1−α(x)−q 1−α(x)(cid:12) (cid:12)≥ε(cid:1) =1,
k→∞n2→∞
and
lim P(|q (x)−q (x)|≥ε)=1,
(cid:101)1−α 1−α
n2→∞
andthatE(d (m(X),m(X))|D )→0as|D |→∞,weinferthat(cid:82) G∗(q (x)+d (m(x),m(x)),x)−
2 (cid:101) train train X (cid:101)1−α 2 (cid:101)
G∗(q (x),x)P (dx)=o (1). Repeatfortheotherterm,wehave
(cid:101)1−α X p
(cid:90)
P(Y ∈C(cid:101)mα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)
X
(cid:90)
= [G∗(q (x)+d (m(x),m(x)),x)−G∗(q (x),x)
(cid:101)1−α 2 (cid:101) (cid:101)1−α
X
+G(q (x)+d (m(x),m(x),x)−G(q (x),x)]P (dx)=o (1).
(cid:101)1−α 2 (cid:101) (cid:101)1−α X p
Case3:
49P(Y ∈Cα(x)△C(cid:101)qα(x)|X =x,D n)
=P({Y :d (Y,m(X))>q (x),d (Y,m(X))≤q (x)}|X =x,D )
2 1−α 2 (cid:101) 1−α n
+P({Y :d (Y,m(X))≤q (x),d(Y,m(X))>q (x)}|X =x,D ).
2 1−α (cid:101) 1−α n
ThisissimilartoCase2,exceptthatweexchangetheroleofq (x)withq (x). Therefore,wehave
(cid:101)1−α 1−α
P(Y ∈Cα(x)△C(cid:101)qα(x)|X =x,D n)
≤G∗(q (x)+d (m(x),m(x),x)−G∗(q (x),x)+G(q (x)+d (m(x),m(x),x)−G(q (x),x).
1−α 2 (cid:101) 1−α 1−α 2 (cid:101) 1−α
Asaconsequence,
(cid:90)
[G∗(q (x)+d (m(x),m(x),x)−G∗(q (x)+G(q (x)+d (m(x),m(x),x)−G(q (x),x)]P (dx)=o (1).
1−α 2 (cid:101) 1−α 1−α 2 (cid:101) 1−α X p
X
Case4:
FollowingtheargumentsofCase1,wehavethat
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)
=P({d (Y,m(X))>q (x),d (Y,m(X))≤q (x)}|X =x,D )
2 (cid:101) 1−α 2 (cid:101) (cid:101)1−α n
+P({Y :d (Y,m(X))≤q (x),d (Y,m(X))>q (x)}|X =x,D ),
2 (cid:101) 1−α 2 (cid:101) (cid:101)1−α n
and,
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)≤2|G∗(q (cid:101)1−α(x),x)−G∗(q 1−α(x),x)|=o p(1),
andasaconsequence
(cid:90)
P(Y ∈C(cid:101)qα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1).
X
Finally,combiningthepriorfourresults,weinferthat
(cid:90)
P(Y ∈Cα(x)△C(cid:101)α(x)|X =x,D n)P X(dx)=o p(1).
X
50