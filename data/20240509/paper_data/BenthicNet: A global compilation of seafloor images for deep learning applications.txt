BenthicNet: A global compilation of seafloor images
for deep learning applications
Scott C. Lowe1,2,†,*, Benjamin Misiuk3,4,†,*, Isaac Xu1,†,*, Shakhboz Abdulazizov1,
Amit R. Baroi5,6, Alex C. Bastos7, Merlin Best8, Vicki Ferrini9, Ariell Friedman10,11,
Deborah Hart12, Ove Hoegh-Guldberg13, Daniel Ierodiaconou14,
Julia Mackin-McLaughlin15, Kathryn Markey13, Pedro S. Menandro7, Jacquomo Monk16,
Shreya Nemani17, John O’Brien18, Elizabeth Oh16, Luba Y. Reshitnyk19, Katleen Robert17,
Chris M. Roelfsema13, Jessica A. Sameoto18, Alexandre C. G. Schimel20,
Jordan A. Thomson21, Brittany R. Wilson18, Melisa C. Wong18, Craig J. Brown22,‡, and
Thomas Trappenberg1,‡
1FacultyofComputerScience,DalhousieUniversity,Halifax,NovaScotia,Canada
2VectorInstitute,Toronto,Ontario,Canada
3DepartmentofGeography,MemorialUniversityofNewfoundland,St. John’s,Newfoundland,Canada
4DepartmentofEarthSciences,MemorialUniversityofNewfoundland,St. John’s,Newfoundland,Canada
5SchoolforResourceandEnvironmentalStudies,DalhousieUniversity,Halifax,NovaScotia,Canada
6DeepSense,DalhousieUniversity,Halifax,NovaScotia,Canada
7UniversidadeFederaldoEsp´ıritoSanto,DepartamentodeOceanografiaeEcologiaVito´ria,Brazil
8FisheriesandOceansCanada,MarineSpatialEcologyandAnalysisSection,InstituteofOceanSciences,Sidney,
BritishColumbia,Canada
9ColumbiaUniversity,Lamont-DohertyEarthObservatory,Palisades,NewYork,USA
10AustralianCentreforFieldRobotics,UniversityofSydney,Sydney,NewSouthWales,Australia
11GreybitsEngineering,Sydney,NewSouthWales,Australia
12NationalOceanicandAtmosphericAdministrationNortheastFisheriesScienceCenter,WoodsHole,
Massachusetts,USA
13UniversityofQueensland,SchooloftheEnvironment,Brisbane,Queensland,Australia
14DeakinUniversity,SchoolofLifeandEnvironmentalSciences,Warrnambool,Victoria,Australia
15OxyOccidentalCollege,VantunaResearchGroup,LosAngeles,California,USA
16UniversityofTasmania,InstituteforMarineandAntarcticStudies,Hobart,Tasmania,Australia
17FisheriesandMarineInstituteofMemorialUniversityofNewfoundland,SchoolofOceanTechnology,St. John’s,
Newfoundland,Canada
18FisheriesandOceansCanada,BedfordInstituteofOceanography,Dartmouth,NovaScotia,Canada
19HakaiInstitute,HeriotBay,BritishColumbia,Canada
20GeologicalSurveyofNorway(NGU),Trondheim,Norway
21EcologyActionCentre,Halifax,NovaScotia,Canada
22DepartmentofOceanography,DalhousieUniversity,Halifax,NovaScotia,Canada
*correspondingauthor(s): ScottC.Lowe(scottclowe@gmail.com),BenjaminMisiuk(bmisiuk@mun.ca),IsaacXu
(isaac.xu@dal.ca)
†Theseauthorscontributedequallytothiswork
‡Theseauthorscontributedequallytothiswork
ABSTRACT
1
4202
yaM
8
]VC.sc[
1v14250.5042:viXraAdvancesinunderwaterimagingenablethecollectionofextensiveseafloorimagedatasetsthatarenecessaryformonitoring
important benthic ecosystems. The ability to collect seafloor imagery has outpaced our capacity to analyze it, hindering
expedientmobilizationofthiscrucialenvironmentalinformation. Recentmachinelearningapproachesprovideopportunities
toincreasetheefficiencywithwhichseafloorimagedatasetsareanalyzed,yetlargeandconsistentdatasetsnecessaryto
supportdevelopmentofsuchapproachesarescarce. HerewepresentBenthicNet: aglobalcompilationofseafloorimagery
designedtosupportthetrainingandevaluationoflarge-scaleimagerecognitionmodels. Aninitialsetofover11.4million
imageswascollectedandcuratedtorepresentadiversityofseafloorenvironmentsusingarepresentativesubsetof1.3million
images. Theseareaccompaniedby2.6millionannotationstranslatedtotheCATAMIscheme,whichspan190,000ofthe
images. Alargedeeplearningmodelwastrainedonthiscompilationandpreliminaryresultssuggestithasutilityforautomating
largeandsmall-scaleimageanalysistasks. Thecompilationandmodelaremadeopenlyavailableforusebythescientific
communityathttps://doi.org/10.20383/103.0614.
Background & Summary
Spatialdataproductsconveyinformationthatisnecessarytoachievemarinemanagementgoals1,includingmonitoringspecies
or habitats of interest, informing policy decisions, and guiding sustainable ocean resource use2. The creation of seafloor
spatialdataproductsisbroadlyreferredtoas“benthichabitatmapping”3,4,whichdescribesbothbioticandabioticmapping
elements. Highqualityspatialdataunderpinsaccuratebenthichabitatmaps,andadvancesinmarinesamplingtechnologiesand
techniqueshaveincreasedcapacitytocollectandanalyzebenthicdataeffectively.
Underwaterimagery,includingbothstillphotographsandvideo,isamongthemostcommonformsofdatausedtoinform
benthichabitatmapping. Seabedimageryhasgreatutilityforcharacterizingbenthicenvironmentsforseveralreasons: itis
non-invasiveandminimallydestructive,itmaybecollectedremotely,itmaybeanalyzedformultiplepurposes(e.g. biology,
geology),anditismoreefficienttocollectandstorethanphysicalsamples(e.g. grabs,cores,preservedspecimen). Inaddition
tomanualinsitu(e.g. snorkeling,SCUBA)orsurface(e.g. dropcamera)deployment,imageryisincreasinglycollectedusing
automatedandremoteunderwatervehicles(AUVs,ROVs). Eachofthesedeploymentmethods,butparticularlyAUVsand
ROVs,havethepotentialtogeneratelargevolumesofimagerydata5,6. Inadditiontolargedatavolumes,imagedatasetsalso
oftenhavecharacteristicsofspatial,andthereforeenvironmental,redundancy7—forexample,whereproximalimageframes
extractedfromvideodatadepictsimilarbiologicalorgeologicalattributesduetopositivespatialautocorrelation8,9.
Benthicimagedataistraditionallyanalyzedbyatrainedoperator,yetthisisofteninefficientgiventhevolumeandspatial
redundancythattypifybenthicimagedatasets. Dependingonthedetailofanalysis(e.g. leveloftaxonomicidentification),there
isnowcapacitytocollectimagedatafasterthanitcanbeanalyzed10—particularlyinthecaseofautomatedplatformssuch
asAUVs. Themanualclassification,annotation,andlabellingofseabedimagerythereforeactsasabottleneckinthehabitat
mappingworkflow11,anditiscommontoanalyzeonlysmallportionsoflargeimagedatasetstoexpeditetheproductionof
spatialdataproducts. Theseinefficienciesofferopportunitiesforautomation.
Machinelearningisanascenttechnologythatcanfacilitatetheautomationofmanualandsubjectivetasks. Amachine
learningmodeliscreatedbycollectingmanysamplesofexampledataforagiventask,thentrainingamodelthataccurately
mapsinputsamplestothedesiredtargetoutputs. Inparticular,deeplearningallowsustobuildthecomplexmodelsnecessary
tosolvechallengingtasksthatwouldbelaboriousforahumantoperform12–14. Deeplearningmodelshaverevolutionized
computervisionoverthelast10years15–17,andhavebeensuccessfullyappliedtoavarietyofimageprocessingtaskssuch
as classification15,16,18–21, semantic and instance segmentation22–24, and image generation25–28. Some models have even
attainedhuman-levelorsuperhumanperformanceatnarrowtasks16,29–31. Thedominantnetworkarchitecturesusedinthe
fieldofcomputervisionarecurrentlyconvolutionalneuralnetworks32,yetotherattention-basedarchitecturessuchasvision
transformersareincreasinglyapplied21.
Successfullytraininglarge-scaledeeplearningmodelsfromscratchrequireslargevolumesofdata. However,adeepneural
networkthathaspreviouslybeentrainedononetaskcanberepurposedforanewtask,providedthenewtaskusessimilar
inputstimulitothatusedwhentrainingtheoriginalnetwork. Thisprocess,knownastransferlearning,cansaveconsiderable
resources,sinceretrainingor“fine-tuning”amodelrequiresmuchfewercomputationalresourcesthantrainingawholenew
model. Thiscanenablethelearningofnoveltasksfromsmalllabelleddatasets,whichwouldotherwisebetoosmalltosupport
trainingadeepnetworkfromscratch. Transferlearningispossiblebecausetheearlylayersofadeepneuralnetworkneedto
learntoseeimagestimulifirstinordertocomprehendandprocessthem. Thesubtaskofseeingandunderstandingtheimage
stimuliconstitutesmostofthecomplexityofanyimageprocessingtask,andthissubtaskiscommontoalltasksinvolving
imageryfromthatdomain. Fornaturalimagedata,transferlearningistypicallyperformedbyreusingmodelspretrainedon
thewidelyavailableILSVRC-2012(ImageNet-1k)dataset30,consistingof1.28Mphotographsofrealworldobjectsscraped
fromimagehostingwebsites. However,thisdatasetcomprisesterrestrialandanthropocentricobjectsandscenes,anddoesnot
representsubaqueousenvironments. Thedifferenceinthedomainoftheinputdatamaylimitthecapacityfortransferlearning.Developmentoflarge-scalemodelsusingcompilationsofbenthicimagerythataresuitablefortransferlearningpurposes
would be ideal, yet this is made difficult by a lack of universal labels for seabed features. One of the primary difficulties
associatedwithdevelopingdeeplearningmodelsinthiscontextisthat,unliketerrestrialandanthropocentricimages,there
isnoobjectivelabelformanyseabedhabitats,biologicalcommunities,substratetypes,ororganisms. Indeed,anumberof
differentclassificationschemesareusedtolabelbenthicfeatures33–35. Becausenosinglevocabularyisuniversallyappliedto
describethesefeatures,wecurrentlylacklargesetsofconsistentlylabelledimagesthatarenecessaryfortrainingdeeplearning
modelsforbenthicenvironments. Wenoteanoutstandingneedtodevelopstandardizedprotocolsforthetranslationofcommon
marineimagelabellingschemes.
Self-supervisedlearning(SSL)isarecenttechniqueinwhichmodelscanlearntounderstandtheirstimuliwithouttheuse
ofmanuallyannotateddata36–44. Insteadofusinglabelleddata,self-supervisedmodelslearntosolveapretexttaskthatcanbe
automaticallyconstructedfromtheinputdataitself. SSLenablesthetrainingoflarge-scalemodelsonunlabelledimagery,
whichcanbecollectedatscalemoreeasilythanannotatedimagery. ModelstrainedwithSSLhavealreadylearnttoseeand
understandthestimuliofinterest,andcansubsequentlybeusedfortransferlearningontospecifictasks,evenifthereisonlya
limitedamountofannotateddataavailableforthenewtask.
SSLmayenablethetrainingofdeeplearningmodelsonlarge-scalebenthicimagedatasetsforthepurposesoftransfer
learningonsmallernoveltasks(e.g. site-specifichabitatlabelling),despitethelackoflargeconsistentlylabelledimagedatasets.
Cumulatively,adequatevolumesofbenthicimagedatacurrentlyexisttosupportthedevelopmentofSSLmodels,butthey
arespreadgloballyamongvariousresearchgroups,governmentdataportals,andopendatarepositories. Thereisaneedto
compileandcuratedatasetsforthedevelopmentoflarge-scaleimagerecognitionmodels. Suchcompilationsmustinclude
imagesfromarangeofbiomes,depths,andphysicaloceanographicconditionsinordertoadequatelyrepresenttheglobal
heterogeneityofbenthicenvironments. Additionally,datashouldbeincludedfromanarrayofacquisitionplatformsandcamera
configurationstorepresentthevariabilityinimagecharacteristics(e.g. lighting,resolution,quality,perspective)thatarisefrom
non-standardizedimagedatacollectionmethods.
Theintendedapplicationsandscopeforabenthichabitatmachinelearningimagedatasetdictatequalitiesthatimages
should possess to be useful for automating tasks in this context. Unlike imagery that is focused solely on specific biota,
benthichabitatimagesoftendepictabroaderarea(e.g. ontheorderofm2),whichnecessarilyincludestheseafloor. Thegoal
ofanalyzingsuchdataisoftentobroadlycategorizethebenthicenvironment,potentiallyincludingbothbioticandabiotic
elements45. Bioticcharacterizationmayincludedescriptionsofindividualorganisms46orcommunitycomposition47,while
abioticcomponentsincludedescriptionofsubstrate,sedimentbedforms,heterogeneity,rugosity,andrelief48–50. Forthese
reasons,benthichabitatinformationisoftensummarizedatthewhole-imagelevel—forexample,byassigningoneorseveral
“habitat”labelstoanentireimageusingapre-definedscheme34,35,51,orbyaggregatingindividuallabelsindicatingpresence
orabsence,abundance,orpercentagecoverofindividualhabitatcomponents,whichmaybelabelledusingamoredetailed
vocabulary33. Itisthereforeusefulforbenthichabitatimagestodepictabroadenoughareasothatbothabioticandbiotic
habitatcomponentsmayberecognized. Thismaydifferfromotherformsofmarineimagelabellingthatfocusonlocating
specificobjects,semanticlabelling,boundingboxes,andmasking. Theseformsoflabellingarewellsuitedtoapplicationsthat
focusonsingletaxa,pelagicbiota,andobjectdetectionortracking. Progressonestablishingextensiveimagedatasetsforthose
fieldsisalsoprogressing11,52–61,andseveraldataportalsandsoftwarepackagessupportthelabellingandcentralizationofthis
data(e.g. CoralNet11,FathomNet53,SQUIDLE+62,BIIGLE63,VIAME).
Here we describe BenthicNet: a global compilation of seafloor images that is designed to support development of
automatedimageprocessingmodelsforbenthichabitatdata. Withthiscompilation,westrivetoobtainthematicdiversityby(i)
compilingbenthichabitatimagesfromlocationsaroundtheworld,and(ii)representinghabitatsfromabroadrangeofmarine
environments. Thecompileddatasetisassessedforthesequalities. Additionally,weaimtoachievediversityofnon-thematic
imagecharacteristics(e.g. imagequality,lighting,perspective)byobtainingdatafromarangeofacquisitionplatformsand
cameraconfigurations. Thedatasetispresentedinthreeparts: adiversecollectionofover11millionseafloorimagesfrom
aroundtheworld,providedwithoutlabels(BenthicNet-11M);ararefiedsubsetof1.3millionimages,selectedtomaintain
diversityintheimagerywhilereducingredundancyandvolume(BenthicNet-1M);andacollectionof188688labelledimages
bearing2.6millionannotations(BenthicNet-Labelled). WeprovidealargeSSLmodelpretrainedontheBenthicNet-1M,and
demonstrateitsapplicationusingexamplesfromtheBenthicNet-Labelled. ThecompilationandSSLmodelaremadeopenly
availabletofosterfurtherdevelopmentandassessmentofbenthicimageautomationtools.
Methods
Inordertoachieveadiversecollectionofbenthichabitatimagesfortrainingdeeplearningmodels,dataspanningarangeof
environmentsandgeographieswereobtainedfromavarietyofsources. Theseinitiallyincludedprojectpartnersandresearch
contacts,whichwereleveragedtoestablishadditionaldatapartnershipswithindividuals,academicandnot-for-profitresearch
groups,andgovernmentorganizations. Thelargestdatavolumeswereeventuallyobtainedfromseveralacademic,government,
3/30andthird-partypublicdatarepositories. Theacquisitionoflabelleddatawasprioritizedinallcases,butextensivehighquality
unlabelleddatacollectionswerealsoincludedwherefeasible. Thedesiredformatforeachdatasetwasasinglefoldercontaining
uniqueimages,accompaniedbyasinglecommaseparatedvalue(CSV)fileindicating,ataminimum,thedataset,filename,
latitude,longitude,dateandtimeofacquisition,URL(ifhostedonline)andlabel(s)(ifprovided)foreachimage.
Datacompilationandqualitycontrol
Labelledbenthicimagedatawasinitiallyobtainedfromprojectcollaborators,datapartners,andopportunisticsourcessuchas
academicjournalsupplementarymaterials. Theformatsandvarietiesofdatawerediverse,includingcollectionsofimages
withspreadsheetmetadata,imageswithmetadatacontainedinfilenames,GISfilescontainingimagesfromwhichmetadata
wasextracted,listsofURLimagelinks,andrawvideowithtextfileannotations. Datasetsthatwerenotformattedasasingle
folderofimagesorlistofURLlinkswithCSVmetadatawerere-formatteduponreceipt. Metadatacontainedinimagefile
nameswasparsedandusedtoconstructametadataCSVfilewherenecessary. ImagedatacontainedwithinGISfileswas
extractedusingArcGISProandtheArcPyPythonpackage,alongwithgeographicinformationandothermetadatacontained
withinthefiles. AllgeographiccoordinateswereconvertedtodecimaldegreesusingtheWGS84datum. Dataobtainedas
videofilesweresubsampledbyextractingstillframesaccordingtotheirmetadatausingFFmpeg. Afterformatting,alldatasets
weresubjectedtoqualitycontrolchecksformissingentries,duplicates,labelconsistency,imagequality,andmatchesbetween
imagesandmetadata. DatacolumnswererenamedtomatchastandardizedformatfortheBenthicNetdataset. Allquality
controlandformattingwascompletedusingRandPython. ThedatasetsourcesaresummarizedinTable1. Additionaldetailon
theindividualdatasetsisprovidedinAppendixB.
Individualcontributions
Anumberofdatasetswerecontributedbyindividualprojectpartners;severalofthesewerefromeasternCanada. TheSeascape
EcologyandMapping(SEAM)LabatDalhousieUniversityprovidedthreedatasetsfortheBenthicNetcompilationfrom
thisregion. Stillimageswereprovided(n=2281)thatwereextractedfrompassivedropdownvideodriftsconductedinthe
BayofFundyat281sitesbetween2017–2019usinga4kcamerasystem64. Whole-imagelabelsweresuppliedaccordingto
site-specific“benthoscapes”interpretedbytheimageanalyst,whicharerecognizablecombinationsofdominantsubstratetype
andbiologicalcharacteristics3,4. Allmegafaunawereadditionallyidentifiedtothehighestpossibletaxonomicresolutionfor
eachimage. Adatasetofhighdefinitionbenthicphotographs(n=4064)wasalsoprovidedfromsurveysconductedbetween
2009–2014attheStAnnsBankmarineprotectedarea65,whichincludedwhole-imagebenthoscapelabelsdefinedforthesite.
Finally,theSEAMlabcontributedphotographsoftheseabed(n=62)usedforthe2017R2SonicMultispectralChallenge
intheBedfordBasin,NovaScotia66,whichincludedbroadwhole-imagesubstratedescriptionsand,occasionally,biological
observations. The4DOceanslabattheFisheriesandMarineInstituteofMemorialUniversityofNewfoundlandprovided
stillimages(n=3000)extractedfromunderwatervideo,aspartoftheproject“CoastalHabitatMappingofPlacentiaBay”
conductedoffthecoastofNewfoundland,whichincludedwhole-imagesubstrate-derivedbottomclasslabels67,68. TheEcology
ActionCentre(EAC)provided1220imagescollectedbycitizenscientistsviaGoPro-mountedkayakbetween2019–2021at
shalloweelgrasssitesinNovaScotia. Theseincludedwhole-imagelabelsforthepresenceorabsenceofeelgrass(Zostera
marina).
SeveraldatasetscollectedbyresearchersatMemorialUniversityofNewfoundland(MUN)werealsocontributedfrom
northernCanada. Theseincluded895imagescollectedforabenthicmappingprojectinFrobisherBay,Nunavut,between
2015–201669;1059imagesfromWagerBay,Nunavut,collectedincollaborationwithParksCanadaaspartoftheUkkusiksalik
NationalParkMarineBaselineDataCollectionProject;541imagesfromChesterfieldInlet,Nunavut,collectedforalocal
benthichabitatmappingprojectconductedincoordinationwiththeGovernmentofNunavut,andUniversityofManitoba;and
8443imagesfromtheareaaroundQikiqtarjuaq,Nunavut,whichwereobtainedaspartofamappingcampaigntomonitor
alocallyharvestedsoft-shellclampopulation9. Thesedatasetswereeachaccompaniedbysite-specificwhole-imagelabels
describingthedominantsubstratetypesvisibleineachimage.
SeveralimagedatasetswereprovidedbytheHakaiInstitutefromwesternCanada. Atotalof8787imageswereobtained
fromnearshorebenthicsurveysconductedbetween2017–2020fromsitesonthecentralcoastofBritishColumbiaandsites
withinPacificRimNationalParkReserve(PRNPR).ThisdatawascomprisedofstillimagesfromROVdeploymentsand
GIS-annotateddropcameravideoscollectedprimarilyforthepurposesofmappingeelgrassmeadows(Zosteramarina). Still
imageswereextractedfromvideosusingthemethodsdescribedabove(i.e. usingFFmpeg). Whole-imagelabelswereprovided
correspondingtothedominantvisiblesubstrateandvegetationtypepresentineachimage.
IndividualdatasetswerealsoacquiredfromoutsideCanada. TheMarineGeosciencesLab(LaboGeo)atUniversidade
FederaldoEspiritoSanto(UFES)providedquadratsampleimagesacquiredbydropcameraduringrhodolithsurveysoffthe
eastcoastofBrazilbetween2015–202070,71. Thesewerecroppedtoremovethequadratframe,and360imageswereincluded
intheBenthicNetcompilation. Whole-imagelabelswereprovidedthatidentifythepresenceofrhodolithsandselectbiogenic
substratetypes. Adatasetof505imageswasprovidedbytheHierarchicalAnticipatoryLearning(HAL)labatDalhousie
4/30University,whichwascollectedfromOchoRios,Jamaica,inshallowwaterbysnorkelerin2022. Imageswereunlabelled,and
comprisedcoralreefandarangeofsubstratetypes.
DFO
FisheriesandOceansCanada(DFO)isafederalinstitutionresponsibleformanagingmanyofCanada’smarineresources. DFO
providedthreeseparatecontributionstotheBenthicNetcompilation. ThePopulationEcologyDivisionattheBedfordInstitute
ofOceanography(BIO)contributed645annotatedimagesfromGeorge’sBank,whichseparatestheGulfofMainefromthe
NorthwestAtlantic. TheseimageswerecollectedbytheGeologicalSurveyofCanada(GSC)Atlanticforprogramsunder
NaturalResourcesCanada(NRCan)usingtheCampoddigitialcamerasystemdeployedfromtheCCGSHudsonin200072and
200273. Annotationsincludedwhole-imagebenthoscapelabelsdescribingtheprimarysubstrateandpresenceofcharacteristic
biota. BenthicimageswerealsocontributedfromaGSCsurveyonGermanBankoffthesouthwestcoastofNovaScotiain
200374 usingCampod(n=641),andfromDFOEcosystemsandOceanScienceSectorsurveysin200675 (n=2044),and
201076(n=3181)usingtheTowcamunderwaterimagingplatform. Theseimagesincludedwhole-imagelabelsdescribingthe
dominantvisiblesubstratetype,someofwhichadditionallyincludeddetailedcommentsdescribingtheproportionofcover
formultiplesubstratetypes. AseparatecontributionfromtheHabitatEcologySectionatBIOcomprised1262imagesfrom
coastaleelgrassandmacroalgaesurveysalongtheEasternShoreofNovaScotiabetween2019and202077. Theseimageswere
extractedfromvideofootagecapturedbyaGoProHERO7(1080por2.7kresolution)deployedfromadrop-downplatform
forpassivedriftsat269sites. Substratelabelswereprovidedatthewhole-imagelevelaccordingtotheCoastalandMarine
EcologicalClassificationStandard(CMECS)35,aswerelabelsforparticularbiota,includingmacroalgaeandseagrasses.Finally,
theDFODeep-seaEcologyProgramattheInstituteofOceanSciences(IOS),BritishColumbia,contributeddatacollected
duringthe2018NortheastPacificSeamountExpeditionusingtheROVHercules. NortheastPacificSeamountExpedition
PartnersandOceanExplorationTrustcollectedimageryatSGaanKinghlas-Bowie,Explorer,andDellwoodSeamountsoff
the west coast of Canada in 2018. Video frames were extracted every 10 seconds for analysis, and 16247 were included
here. Labelswereprovidedforsomeimagesdescribingtheprimarysubstratetypeandalsothe“biotope”observed,which
broadlydescribesthebenthiccommunityand/orhabitatcontext(e.g. coralgarden,verticalwall,spongeground). Someimages
overlappedandwerethusnotoriginallylabelledmultipletimes;here,neighbouringimagelabelswereinterpolatedwherenot
initiallyassignedbecauseofoverlapwithotherimages.
NRCan
NaturalResourcesCanada(NRCan)isafederalorganizationresponsibleformanagingandresearchingarangeofnatural
resourcesatthenationalscale. NRCanmakesdatafreelyavailableviatheCanadaOpenGovernmentPortal. TheNRCan/GSC
SeabedPhotoCollectionwasacquiredforthisproject,whichincludes20260imagesrecordedfrom1804camerastations
across78expeditionsdistributedthroughoutthewaterssurroundingCanada. Thesephotographswerecollectedbetween1965
and2015usingarangeofequipment;photographstakenbefore1978wereingreyscale,andafter1978incolour. Photographs
before2000werecollectedusingfilmandafter2004weredigital,withbothusedintheinterim. 3767ofthephotographswere
annotatedwithverbosedescriptionsofeithergeologicalfeatures,biologicalcontents,orboth. Thesedescriptionswereparsed
inordertoapplywhole-imagesubstrateandbiotalabels(seeDatamanagementsectionbelow). Thefulllistofexpeditions
associated with this dataset was obtained along with URLs of corresponding metadata CSV files in GeoDataBase format
fromtheNRCanFTPserver. TheGeoDataBasefilewasprocessedwithgeopandas,andCSVfilesweredownloadedforeach
expeditionlocation(URLsweremanuallycorrectedforexpedition82FOGO-ISLE,forwhichtheCSVfileswereavailable
atURLscontainingthestring82FOGO_ISLEinstead). TheseCSVfiles,containingURLsforindividualimagesfromthe
expeditions,weremergedtogether. Theyearofacquisitionwasinferredfromtheexpeditionname,andcolumnswererenamed
tomatchthestandardizeddatasetformat. Sampleimageswereinspectedfromeachexpeditiontoverifytheirappropriateness.
Allimagesfromexpedition71014consistedofcollagesformedof2–6individualphotographs,andwereexcluded.
NGU
The Geological Survey of Norway (NGU) is responsible for national geological mapping and research, including marine
applications. NGU contributed 50290 images to this project, which were extracted from 581 underwater video transects
acquiredduringsixcruises. Thesewerecarriedoutbetween2010and2017incoastalareasandfjordsofNorway(Astafjorden,
Frohavet,SøreSunmøre, SognogFjordane,Ofoten, Tysfjorden, andTjeldsundet),aspartofseveral“MarineBaseMaps”
projects. Thevideoswereacquiredusingacamerarigtowedneartheseafloor(0mto200mdepth)fromtheNGUresearch
vesselSeisma. The2010cruises(codes1002and1007)useda720x480digitalvideocamera,whilealltheothercruises(codes
1408,1508,1511,and1706)usedahigher-resolutionGoProHERO3+. Theimageswereobtainedbyextractingonevideo
frameevery10secondsofvideofootage.
5/30MGDS
TheMarineGeoscienceDataSystem(MGDS)isadatarepositorythatofferspublicaccesstoacuratedcollectionofmarine
geophysicaldataproductsandcomplementarydatarelatedtounderstandingtheformationandevolutionoftheseafloorand
sub-seafloor. MGDSprovidestoolsandservicesforthediscoveryanddownloadofdatacollectedthroughouttheglobaloceans
producedprimarilybyresearchersfundedbytheU.S.NationalScienceFoundation. SixdatasetswereobtainedfromMGDS,in
collaborationwiththeLamont-DohertyEarthObservatoryatColumbiaUniversity. FourofthesewerecollectedfromtheLong
IslandSoundEstuaryin2012and2013usingtheUnitedStatesGeologicalSurvey(USGS)SeabedObservationandSampling
System(SEABOSS),IntegratedSeafloorImagerySystemcamerasled,andtheKraken2ROV78.Onedatasetwasobtainedfrom
theEastPacificRiseSpreadingCenterduringthe2011Atlantisexpedition,usinganInsiteScorpioDigitalCameramountedon
theROVJasonII.ThefinaldatasetwasacquiredbytheSchmidtOceanInstitute(SOI)duringthe2020R/VFalkorexpedition
FK200429offthenortheastcoastofAustralia. Here,theROVSuBastianwasmobilizedandimageswereobtainedusinga
SubseaSystemsandInc. Z70DigitalCamera. AlldatasetsfromMGDSweremanuallyreviewedandfilteredtoremovesurface
images(e.g. ontheresearchvessel),andduplicates. AdditionaldetailsareprovidedinAppendixB.
NOAA
TheU.S.NationalOceanicandAtmosphericAdministration(NOAA)isafederalscienceinstitutionthatconductsextensive
marineresearch. NOAAhostsdiversecollectionsofenvironmentaldatathataremadeavailabletothepublic. Benthicimages
weresourcedfromtheNOAAdatarepositoryforadditiontotheBenthicNetdataset. Candidatedatawereidentifiedusing
theNOAAOneStopportal, usingthesearchstrings“benthic”, “habitat”, “image”, “camera”, and“photograph”. Datasets
returnednotcontainingimagefileswererejected. Theremainderwerereviewedmanually,anddatasetswereadditionally
rejectedthatdidnotmeetqualityorcontentstandards. Reasonsforrejectionincludedsubstantialproportionsofnon-benthic
images(e.g. above-water,pelagic,individualanimals,airphotos),partialorfullsceneobstructionbynon-benthicobjects(e.g.
equipment,ROV/AUVparts),highlyinconsistentimagecontentorquality,andincoherentdatasetormetadataformatting(e.g.
unorganizedcollectionsofvarioustypesofdata,metadatanotreadableviascript). Datasetswerealsoexcludedthatdidnot
meetthemetadatarequirementsofthisproject—namely,thoselackingmetadataentirely,orlackinggeographiclocationsfor
images. Wherethelatteroccurred,effortsweremadetoestimateimagelocationsusingavailableinformation;forexample,by
assigninggeneralstudysitecoordinatestoimages,orbyassigningthemeangeographiccentreofotherimagesatthestudysite.
Datasetsthatwereotherwisesuitableforinclusionweregenerallynotrejectedduetopoorimagequalityorlowresolutionalone.
AlldatasetsweresubjectedtothequalitycontrolcheckslistedpreviouslybeforedownloadingforinclusionintheBenthicNet
collection,andcolumnswererenamedtomatchthestandardizeddatasetformat. Severaldatasetsincludedlabelsassociated
withtheNationalCoralReefMonitoringProgram(NCRMP)describingthebenthiccover,whichprimarilycomprisedcoral
taxaandsubstratelabelsappliedtobothwhole-imagesandpoints. Theselabelswereretained. Theindividualdatasetsretrieved
fromtheNOAArepositoryarelistedinAppendixB.
AdditionaldatawascontributedbytheNOAANortheastFisheriesScienceCenter(NEFSC).Theseincludedbenthicimages
fromGeorgesBank,theMid-AtlanticBight,andoffthecoastofCapeCod(n=2240). Imagesurveyswereconductedin2015
usingtheNOAAHabCambenthicimagingplatform. Whole-imagelabelswereprovidedindicatingtheprimaryandsecondary
substratetypes,andalsothepresenceofcertaintaxa(mussels,Didemnumtunicates,bryozoans).
USGS
TheUnitedStatesGeologicalSurvey(USGS)isafederalorganizationthatconductsearthscienceresearchandprovidespublic
geoscienceinformationanddata. AseriesofunlabelledbenthicimagedatasetswereretrievedfromtheUSGSScienceData
Catalogue(seeAppendixB). Severalofthesewereinitiallydiscoveredfromreviewofthescientificliterature79,80,andthe
remainderwerediscoveredbyqueryingtherepositoryusingthesearchstrings“benthic”,“habitat”,“image”,“camera”,and
“photograph”. Candidatedatasetswerescreenedusingthesamemethodologyasoutlinedabovefordataretrievedfromthe
NOAArepository. Datasetswererejectedthatdidnotcontainimages,containednon-benthicimages,werelargelyobstructed
bynon-benthicobjects,orwereformattedincoherently. Wherepreciseimagelocationswerenotprovided,estimateswere
obtainedusingthemeancentreofthestudysiteboundingboxcoordinates. Allcandidatedatasetsweresubjectedtothequality
controlcheckslistedpreviouslyandcolumnswererenamedtomatchthestandardizeddatasetformat.
USAP-DC
TheU.S.AntarcticProgramDataCenter(USAP-DC)isfundedbytheU.S.NationalScienceFoundationandisadomain
repository for U.S. Antarctic Research data from all disciplines. Five unlabelled datasets were obtained from USAP-DC.
ThesewerediscoveredfromtheUSAP-DCwebsiteusingthesearchstrings“benthic”, “habitat”, “image”, “camera”, and
“photograph”. DatasetswerescreenedusingthemethodologydescribedfortheNOAAandUSGSrepositories. Additionally,
someimagesthatdidnotdepicttheseabed(e.g. picturesontheboatdeck)weremanuallyomitted. Themeancentreofthe
studysiteboundingboxeswereusedtoestimateimagelocationswhereprecisepositioningwasnotprovided. Theindividual
6/30datasetsarelistedinAppendixB. Thesewerecheckedforqualityusingthemethodologydescribedpreviouslyandcolumns
wererenamedtomatchthestandardizeddatasetformat.
AADC
TheAustralianAntarcticDataCentre(AADC)isalong-termrepositoryforAustralia’sAntarcticdata. Thisdataisfreely
andopenlyavailableforscientificuse. TwodatasetswereobtainedforthisprojectfromtheAADCdataportal(AppendixB).
Seafloorimages(n=203)fromtheSabrinaslope,EastAntarctica,werecollectedin2017overfourtransectsduringsurvey
“IN2017_V01”usingtheAustralianCSIROMarineNationalFacility’sDeepTowCamera81,andweredownloadedalongwith
associatedmetadatafromAADC.Theseincludedwhole-imagelabelsindicatingthesubstratetypecoverageandthepresence
ofbiota;theformerwereretainedhere. Additionally,GeoscienceAustraliaandtheAustralianAntarcticDivisioncollected
underwaterphotographsin2011at97sitesintheMertzGlacierregionofAntarctica82,and1853imageswereacquiredfor
thisproject. Imagesandmetadatafrombothdatasetswerecheckedforqualityandformattedforstandardizationwiththe
BenthicNetcompilation.
SQUIDLE+
SQUIDLE+isanonlinetoolformanaging,exploring,andannotatingimagesandvideooftheseafloor. Italsoservesasa
globalrepository,containingstandardizedrecordsforimagescollectedbydifferentgroupsaroundtheworld. SQUIDLE+isa
livingproductthatisupdatedcontinuouslywithnewimagesandlabels. AsnapshotoftheimagesavailableonSQUIDLE+
wasacquiredonApril13,2023. TheSQUIDLE+webAPIwasusedtodownloadtherecordsforeveryimageonSQUIDLE+,
totalling9166472atthattime. ThepaginateddownloadwasjoinedtogetherandmergedintoasingleCSVfile,andcolumns
wererenamedtomatchourstandardizedformatforthecompilation. ThefulllistofSQUIDLE+datasetsobtainedisprovided
inAppendixB.
Several of the large individual SQUIDLE+ datasets in this collection additionally included publicly accessible image
annotations. TheseincludedAustralia’sIntegratedMarineObservingSystem(IMOS),whichdistributesoceanographicdata
fromaconsortiumofAustralianinstitutionsthatisfreelyandopenlyavailabletothescientificcommunity. Thisdataincludeda
largenumberofimagescollectedbytheIMOSAUVFacility,notably,usingSiriusandNimbusAUVs. IMOSimagesavailable
fromSQUIDLE+werecross-referencedwithdataentriesfromtheAustralianOceanDataNetwork(AODN)portalforthis
project. LabelledimageswerealsoprovidedbytheReefLifeSurvey(RLS)83,84,whichisaglobalcitizenscienceprogram
thattrainsSCUBAdiverstoconductunderwatervisualsurveysofshallowreefbiodiversityintemperateandtropicalreef
habitats,typicallybetween2m–20mdepth. Diverscaptureapproximately20imagespersurveyusinganunderwatercamera
positionedapproximately50cmfromthesubstrate,andimagesvaryinresolutionandqualityduetocameraconfiguration
andenvironmentalconditions. TheSchmidtOceanInstitute(SOI)isanon-profitfoundationestablishedtoadvanceglobal
oceanographicresearchthathostsalargelabelledimagecollectiononSQUIDLE+. DeployedfromtheSOIR/VFalkor,the
ROVSuBastianhascollectedhighresolutionimagesfromwatersaroundtheworld,includingthedeepocean.Alloceanographic
datacollectedbytheSOIaremadeopenlyavailableforresearchpurposes. TheNationalEnvironmentalScienceProgram
(NESP)MarineBiodiversityHub85hasalsoprovidedalargelabelledimagedataset. Thisprojectaimstoprovidefoundational
scienceforconservationinAustralianandprovidesdataopenlyinsupportofmarineresearch. Eachoftheabovedatasets
includedsub-imagepointlabelsidentifyingunderlyingphysicalorbiologicalelementsaccordingtotheCATAMIscheme33.
Finally,theimagedatasetpresentedbyYamadaetal.86 collectedviaAUVfromtheSouthernHydrateRidgewasdownloaded
fromaseparateSQUIDLEdomain,SOISQUIDLE+,alongwithpointannotationsdescribingsubstrateorbioticelements
accordingtoasite-specificscheme.
FathomNet
FathomNet53isanopen-sourceunderwaterimagedatabasewithglobalscopeoperatedbytheMontereyBayAquariumResearch
Institute (MBARI). FathomNet is soliciting contributions from around the world to develop a large open-source database
ofimagesthatmaybeusedtodevelopartificialintelligencealgorithms, withafocusonidentifyingmarinespecies. Like
SQUIDLE+,FathomNetisalivingproductthatisupdatedcontinuously. WeusedtheFathomNetPythonAPItodownloada
snapshotoftheimagesavailableonFathomNetasofApril6,2023. ThecodeforthisAPIcallisprovidedinAppendixC. Atthe
timeofdownloading,theseimageswereprimarilyacquiredfromPacificWatersaroundCalifornia,WesternUSA.Recordswere
partitionedinto“sites”basedonthedirectorystructureintheURL.Wherenotavailableintherecorditself,timestampswere
extractedfromimagenames,wherepossible. Columnswererenamedtomatchourstandardizedformat. Manyoftheimages
wereannotatedwithboundingboxesaroundanimalsandotherconceptsappearingintheimages. Howevertheannotations
wereonlyavailableunderaNoDerivativeslicense(CCBY-ND4.0),whichprohibitedusfromconvertingthelabelstothe
sameformataslabelsfromothersources,hencewediscardedallFathomNetannotations.
PANGAEA
PANGAEAisanopenaccessrepositoryaimedatarchiving,publishinganddistributinggeoreferenceddatafromearthsystem
7/30research,hosting678projectsand408811datasetsfromvariousfieldsatthetimeofwriting. Wesearchedandretrievedbenthic
imagedatasetsfromPANGAEAwithacombinationofAPIcallsandweb-scraping,thenprunedtheresultingdatasetsand
reformattedthem. ThepangaeapyPythonpackage87wasusedtointerfacewiththePANGAEAlibrary. UsingthePanQuery
API,PANGAEAwassearchedfor20querieswithvariouscombinationsofbenthicenvironmentrelatedkeywordstofind
photographsoftheseafloor(seeAppendixAforcompletelist). ThePanDataSetAPIwasusedtoretrievethemetadatafor
thedatasetIDsidentifiedinthesesearches. SomeIDscorrespondedtodatasetseries,whichlistmultiplechilddatasets. Inthese
cases,allchilddatasetswereretrieved. Somedatasetswereavailableintabularformat,andweredownloadeddirectly. Other
datasetswerepaginated,withimageshostedonwebpagesonPANGAEA;thesecouldnotbedownloadedwiththeAPIand
werescrapedwithacustomwebscraperusingtheBeautifulSoup4andrequestlibraries.
AlldatasetsreturnedbythissearchasofJanuary1,2024weredownloadedandresultswerefilteredasfollows. (1)Datasets
thatdidnotpossessacolumncontainingtheword“url”or“image”thatwaspopulatedbyhyperlinkstofilesinanimageformat
(TIFF,JPEG,PNG,BMP,CR2)wereremovedtoenableautomationofthedataacquisitionprocess. Itwasnotpossibleto
verifyanyZIPfilewouldcontainimageswithoutdownloadingit,andwasimpracticaltoautomaticallyassociatemetadatawith
theimageswithinaZIPfileofunknownstructure. DatasetswithimagesonlyavailabletodownloadasaZIPfilewerethus
discarded. (2)Falsepositivesfromthesearch(datasetscomprisingimagerynotoftheseafloor)werefilteredoutbyremoving
datasetswithtitlescontainingundesiredkeywordsappearinginamanuallycuratedblacklist(e.g. “aquarium”,“meteorological
observations”,“seaiceconditions”,“donotuse”). (3)URLsforimagesconsistingofmaps,otherdatasetsummaryfigures,
andinappropriatephotosubjectswerefilteredoutbyremovingdatahostedonPANGAEAsubdomainsdedicatedtosubjects
suchasmaps,projects,publications,seaice,andsatelliteimagery. (4)ImageswereremovedwheretheURLcontainedtext
indicatingthesubjectmatterwasotherwiseinappropriate(e.g. “dredgephotos”,“grabsample”,“core”,“aquarium”,“divemap”).
Finally,thecolumnsintheCSVfileswererenamedtoourstandardizedformat. Detailsforindividualdatasetsareprovidedin
AppendixB.
SeveralofthedatasetsobtainedfromPANGAEAincludedthematiclabelscorrespondingtobenthicimages. Manyof
thesewerelabelsofspecificbiotaidentifiedtothehighestpossibletaxonomicresolution,someofwhichincludedestimatesof
percentagecoverofeachorganismintheimage. Severalofthelatterdatasetscomprisedexperimentalgrowthplatesharbouring
thelabelledbiota. Somedatasetsadditionallyincludedlabelsfortrashandanthropogenicdebris. Alllabelsweredropped
wheredatasetsindicatedusageofmachine-assistedannotationinsteadofmanualannotation. Finally,additionalpointlabels
wereobtainedfordatasetsfromtheGreatBarrierReefMarinePark,easternAustralia,collectedforhabitatmappingpurposes
bytheUniversityofQueenslandRemoteSensingResearchCentre. Thesedatasetscomprisedquadratimagescollectedvia
snorkelanddivingfromover100reefsthroughouttheGreatBarrierReefMarinePark88–90. Pointswerelabelledaccordingtoa
customschemeusedfortheseprojectsattheGreatBarrierReefthatdescribebioticandabioticelementsfoundwithinthereef.
Additionallabelswerealsoprovidedindicatingthebioticfunctionalgroup,andasimplifiedclassificationschemeapplicableto
aglobalcontext.
XLCatlinSeaviewSurvey
TheXLCatlinSeaviewSurveywasalarge-scaleprojectundertakenbetween2012–2018todocumentandstudythestatusof
coralreefsgloballyusingunderwaterimagery. Surveysfocusedonshallowreefstypicallyaround10mdepthandcomprised
linear transects ranging between 1.6km to 2km in length. Downward-facing seabed images of approximately 1m2 were
acquiredusingCanon5DMIIcamerasmountedonaself-propelleddiver-operatedplatformcalledthe“SVII”6,91.Datafromthe
projectismadeopenlyavailableforfurtherscientificresearch. Forthisproject,1082452imagesfrom860surveysorganized
into22regionaldatasetsweredownloadedfromtheUniversityofQueenslanddatarepository. Tabulardataprovidingimage
metadatawasalsoacquiredinCSVformat,includingimagepointlabelsidentifyingbioticandabioticelementsusingtheglobal
schemeappliedabovefortheGreatBarrierReefmappingprojects. Themetadatawererenamedandformattedtomatchthe
standardizedBenthicNetcompilation.
Datamanagement
In total, 11408887 images were collected from the sources described above (see Data compilation and quality control).
Thegreatestdiscrepancywithinthiscollectionwasthepresenceofimagelabels. Ofalltheimagesacquired,only188688
includedlabelscorrespondingtovisiblebenthicelements. Thepresenceandcompositionoflabelsinmanywaysdetermines
theutilityofthedataset; labelsenabletrainingandvalidationforsupervisedmodellingtasks,suchaslocalizedspeciesor
substrateidentifications92,93,orbottomtypeclassification94. Thereareseveralways,though,thatunlabelleddatamaystillbe
utilizedusingunsupervised86,semi-supervised95–98,andself-supervised36–38,40,44,99,100approaches. Tofacilitatearangeof
potentialapplications,weconsiderthedatasetintwowayshereafter: thefullsetofimageswithouttheirlabels(unlabelled;
BenthicNet-11M)andthesetoflabelledimages(BenthicNet-Labelled).
8/30Table1. SummaryofBenthicNetdatasourcesincludingthenumberofimagesinBenthicNet-11M(Fullcollection),
BenthicNet-1M(Subsampled),andBethicNet-L(Labelled). Furtherdetailsontheindividualdatasetsareprovidedin
AppendixB.
№Samples
Source Region №Datasets №Sites Fullcollection Subsampled Labelled
OnlineRepository/Collection
AADC Antarctic 2 86 2056 2024 203
CatlinSeaview Global 22 861 1082452 283674 11346
FathomNet W.USA 8 3381 68908 58196 0
MGDS Global 6 32 15023 6154 0
NOAA(viaOneStop) USA 18 526 73019 40714 4543
NRCan Canada 78 1804 23855 18851 3595
PANGAEA Global 1191 1196 764924 236968 40204
SQUIDLE+ Global 691 14187 9166472 608576 85387
USAP-DC Antarctic 5 27 4144 2886 0
USGS USA 5 38 104155 7035 0
IndividualContributions
4DOceans E.Canada 2 274 3008 2715 3000
DFO(BIO) E.Canada 6 381 7773 5981 7762
DFO(IOS) W.Canada 7 9 16247 1993 10106
EAC E.Canada 1 7 1220 1015 886
HakaiInstitute W.Canada 2 45 4735 3609 1697
HAL Jamaica 1 1 505 505 0
LaboGeo/UFES E.Brazil 1 359 359 287 359
MUN Arctic 4 135 10691 6403 10687
NGU Norway 4 580 50290 50275 0
NOAA(NEFSC) N.E.USA 1 2 2240 2065 2240
SEAM E.Canada 3 284 6811 5170 6673
Total Global 2058 24215 11408887 1345096 188688
Labelleddata
Inordertoincreasetheutilityofthecompileddata,andtofacilitatevalidationofmodelstrainedonit,imagelabelsfromall
datasetsweretranslatedtotheCATAMIclassificationscheme33(version1.4),whichspansbothsubstrateandbiotacategories.
BiotalabelswereadditionallymappedtotheWorldRegistryofMarineSpecies(WoRMS)taxonomy101.
Imageswereoriginallylabelledaccordingtoarangeofdifferentestablishedandbespokeschemes,yetalargenumberof
these(forexample,thelabelleddataacquiredfromSQUIDLE+)werereadilyavailableasCATAMIlabels. Additionally,the
qualitiesofCATAMIprovideaflexibleframeworkthatmayaccommodatetranslationandintegrationofabroadrangeofother
labelleddata. First,CATAMIsupportslabelsformultipleclassesofbenthicfeatures,including“branches”forbothbiotaand
physicalelementssuchassubstrate,bedforms,andrelief. Thisenablesthetranslationofarangeoflabelleddatasetsthatwere
initiallycollectedforavarietyofdifferentpurposes. Second,thelabelswithinthesebranchesarehierarchical. Thismeansthat
objectsmaybelabelledatdifferentorevenmultiplelevelsofdetaildependingonthequalityofthedata,theconfidenceofthe
analyst,ortherequirementsofaparticularapplication. Thischaracteristiciscriticalforthetranslationofthemulti-source
datacompiledhere,whichwereinitiallyanalyzedatarangeofthematic(e.g. taxonomic)resolutionsfordifferentpurposes.
Finally,CATAMIimplementslabelsthataredesignedtobevisuallyrecognizablefromimagedata. Atacoarselevel,these
maydistinguishbroadgroupsorphylaofbiota,butatfinerlevels,whereidentifyingindividualgeneraorspeciesmaybecome
difficultusingimagedataalone,morphologicallabelsmaybeapplied. Thesedescribethesize,shape,colour,andgrowth
formofanorganism,whichmayberecognizablewherethetaxonomyisambiguous. Detailedtaxonomiclabelsoftenrequire
specializedknowledgeorbiologicalexpertise,whereasmorphologicallabelsenablecollaborativeclassificationandtranslation
ofimagerybynon-experts.
TranslationofallimagelabelstotheCATAMIschemewasperformedbyateamofBenthicNetcollaborators(e.g. Table2).
Alluniquelabelswereextractedforeachlabelledimagedatasetinturn, whichincludedcasesofasinglelabelindicating
onebenthicfeature(e.g. sedimenttypeorbiota),asinglelabelindicatingmultiplefeatures(e.g. sedimenttypeandbiota),
9/30Table2. ExamplesoforiginalimagelabelstranslatedtohierarchicallabelsaccordingtoCATAMIv1.4andWoRMS.Some
originallabelsindicatedbothsubstrateandbiota,othersonlyoneofthese. Forbiota,someoriginallabelsprovidedmore
morphologicaldetailandothersmoretaxonomic;asmuchdetailwasretainedaspossibleinboththeCATAMIBiotaand
WoRMStaxonomictranslations,respectively.
CATAMI WoRMS
Original Substrate Biota AphiaID Taxonomy
Substrate
Cobble ↰Consolidated(hard) – – –
↰Cobbles
Substrate
Worms
↰Unconsolidated(soft) Annelida
Mudandtubeworms ↰Polychaetes 883
↰Sand/mud(<1mm) ↰Polychaeta
↰Tubeworms
↰Mud/silt(<64um)
Cnidaria
HardCoral: ↰Corals Cnidaria
Nonhermatypic: – ↰Stonycorals 1363 ↰Hexacorallia
Freeliving(Fungiaetc) ↰Solitary ↰Scleractinia
↰Freeliving
Cnidaria
Cnidaria ↰Hexacorallia
Pocilloporasp. – ↰Corals 206938 ↰Scleractinia
↰Stonycorals ↰Pocilloporidae
↰Pocillopora
ormultiplelabelsfordifferentfeatures(e.g. oneforsedimenttype,oneforbiota). Eachuniquelabelforeachdatasetwas
translatedtoitsclosestCATAMIequivalent(s),maintainingthehierarchicalleveloftheoriginaldataascloselyaspossible.
Insomecases,additionalinformationwithinthemetadatasuchascommentsorauxiliarylabelswereusedtocompletethe
translation.SomeannotationswereprovidedinschemesthatextendversionsofCATAMI,suchastheAustralianMorphospecies
Catalogue,which,forexample,providesmoreprecisemorphologicaldetailfortheshapeofsponges. Wherethiswasdone
systematicallyandwithmorethan10samples,weextendedourschemebyaddingchildnodestocorrespondtothisincreased
levelofmorphologicaldetail. Someannotationsincludedman-madeobjects,suchastrashorcables,whichfelloutsidethe
scopeoftheCATAMIscheme,butwhichmayhavevaluetowardmonitoringtheanthropogenicimpactonbenthichabitats.
ThuswealsoaddedanadditionalAnthropogenicbranchtothehierarchytocatertotheseannotations. Alltold,thisprocess
producedatotalof2618016hierarchicalCATAMIlabelsfortheBenthicNetcompilation. Weadditionallyincludefieldsfor
CATAMImodifiersthatindicateadditionalinformationaboutimagelabels,suchaswhetherorganismsarebleachedordead,or
theircolours,whereavailable.
Somedatasetsprovidedtaxonomiclabelsofbiotaatahighlevelofdetail(genusorspecieslevel). Toretainthisinformation,
taxonomicbiotalabelswereadditionallyassignedanAphiaIDfromtheWorldRegistryofMarineSpecies(WoRMS).The
remainingbiotaannotations(e.g. morphologicaldescriptionsfromCATAMI)werealsomappedontotheWoRMStaxonomyat
thehighestlevelofspecificitypossible(typicallyphylum,class,ororder). Intotal,thereare887517taxonomiclabelsforthe
BenthicNetcompilation.
Intotal,therewere188688labelledimages,and2618016individuallabels. Thecountsforeachindividuallabelarepro-
videdwiththedatasethostedontheCanadianFederatedResearchDataRepository(FRDR;doi:https://doi.org/10.20383/103.0614).
ToenableconsistentvalidationandbenchmarkingbetweenmodelsusingtheBenthicNetdatasetcompilation,wepropose
trainandtestpartitionsofthelabelleddata. Testdatawereselectedaccordingtoapartiallyspatialandstratifiedprocedure
inordertoensurerepresentationofabroadrangeoflabels,andtoreducethedegreeofsimilaritybetweentestandtraining
partitionscausedbyspatialautocorrelation.
The challenge in partitioning the dataset stems from the multi-label nature and imbalanced proportions of labels in
BenthicNet. Firstly,theimbalancenecessitatescarefulassignmentofrarerlabelsinthedataset. Additionally,asingleimage
mayhaveanycombinationoflabelsacrossmultiplebranchesoftheCATAMIhierarchy. Ifanimageisassignedtotestor
trainingpartitionsduetoaparticularlabel,wemustconsiderhowtheassignmentaffectsotherlabelsonthesameimage,some
10/30ofwhichwillberarer.
Ourpartitioningprocesswasasfollows. Weselectedthetargetnumberofannotationsperlabeltoplaceinthetestsetas
thesmallerof15%ofthenumberofsamplesforthemostfrequentlyoccurringlabeland35%ofthesamplesforthemedian
label. Weincrementallyaddedimagestotrainortestpartitionsoneatatime. Weconsideredtheavailableimagelabelsineach
iteration,andselectedthenextlabeltoaddtoapartitionbasedonthefollowingfactors,inorderofpriority:
1. Ensureatleasttwosamplesforeachlabelcanbeplacedinthetrainpartition;
2. Ensureatleast50%ofthesamplesforeachlabelcanbeplacedinthetrainpartitionwithoutusingsampleswithin50m
ofatestsample;
3. Ensureatleast15%ofthesamplesforeachlabelcanbeplacedinthetestpartitionwithoutusingsampleswithin50mof
atrainsample;
4. Ensurenomorethan35%ofthesamplesforeachlabelwouldbeplacedinthetestpartition;
5. PrioritizetheCATAMIlabelwiththefewestremainingimageswhichcanbeallocatedtothetrain/testpartition.
Afterdeterminingthenextlabelforwhichasamplewillbeaddedtoapartition,andthepartitiontowhichitshouldbe
added,weselectedanimagebearingthatannotationtoaddtothepartitionasfollows:
1. Oftheimagesbearingthedesiredlabel,ifanyimagesarewithin50mofanimagealreadyinthetargetpartition,randomly
selectanimagefromtheclosest10%ofthoseimages.
2. Otherwise,randomlyselectanimagebearingthedesiredlabelthatisnotwithin50mofanimagealreadyallocatedto
theotherpartition. Imagesviolatingthe50mexclusionzonewereusedifneededtosatisfytheminimumpopulationsfor
eachpartitiondescribedabove(50%intrain,15%intest).
Inpractice,thismeansthatpartitionsgrowspatiallyoutwardsfrominitialseedlocations,withnewlocationsbeingseeded
atrandomwhenneededinordertorepresentnewlabelclasses. Anyremainingsamplesthathavenotbeenassignedthrough
thisprocesswereallocatedtothetestpartitionifwithin50mofanimagealreadyinthetestpartition,andtothetrainpartition
otherwise.
Effectively,testdatawasselectedtoprioritizerepresentationofCATAMIlabels,andthentominimizespatialoverlapwith
thetrainingdata,tothemaximumextentpossible. BecausethecomputationofthisalgorithmscalesO(n2)withdatasize,itwas
runinparallelon37subsetsofthedata,eachcorrespondingtoadifferentEcologicalMarineUnit102(EMU;seeUnlabelled
dataexploratoryanalysissection). 142767images(75.66%)wereassignedtothetrainingpartitionand45921(24.34%)totest.
ThecodeforobtainingtrainingandtestpartitionsofthelabelleddataisprovidedattheBenthicNetcoderepository(seeCode
availabilitysectionbelow).
Unlabelleddata
AllimagescollatedinBenthicNetmaybeusedforunlabelledapplications,includingthoseimagesthathavelabels,thusforthe
“unlabelled”sliceofthedataweconsideredall11408887images. WerefertothefullcollectionasBenthicNet-11M.These
imageswerenotdistributeduniformlyinspace;somedatasetswerecharacterizedbyalowsamplingintensity,withonlya
fewimagesperrecordingsitetakenmanuallybydivers,whileothersweredenselysampled—forexample,whereimages
wereextractedfromAUVvideo. Inordertoreducetheredundancyofthedenselysampleddata(therebyalsoreducingdata
volumeandimbalance)theunlabelleddatawassubsampledspatially,asdescribedbelow. Werefertothesubsampleddatasetas
BenthicNet-1M.
Theaimofthesubsamplingprocedurewastoobtainamanageableunlabelleddatavolumewithoutreducingthebreadth
ofbenthicenvironmentsrepresented. Manydatasetsindicatedwhichimageswerecollectedatthesamerecordingstation,or
thesamecameradeployment/transect. Wecollectivelyrefertothislocationannotationasa“site”. Tomaximizespatialand
thematicdiversityofimages,subsamplingwasperformedseparatelyforeachuniquesiteintheunlabelleddatatset.
Inordertosubsamplethedataspatially,wefirstdeterminedadesirablenumberofimagesthatshouldbedrawnfroma
givensitebasedonthedatadensity. Thebasetargetnumberofimagessoughtateachsitewassetto250,meaningthatthe
subsamplingprocedurewouldnotreducethenumberofimagesbelowthisnumber. Notallcomponentdatasetsindicated
whetherimageswerecollectedatthesamesite,despitecontainingimagesfrommultipledistinctlocationsthatwouldmeet
our“site”criteria. Toaddressthis,weautomaticallydetectedthenumberof“pseudo-sites”withinanannotatedsite,orwithin
adatasetoriginallylackinganysitelabels. Pseudo-sitesweredeterminedasclustersofsamplesatleast1000mfromeach
other. Thetargetnumberofsampleswasscaledupbythenumberofpseudo-siteswithinalabelledsite. Somepseudo-sites
11/30additionallyhadgapsbetweenthemofseveralhundredmetres,whichwerefertoas“subsites”. Thetargetnumberofsamples
forasitewasincreasedby50foreachsubsitewithinitseparatedbyatleast100m.
Afterdeterminingthetargetnumberofimagestodrawfromeachsiteintheunlabelleddataset,thedatawassubsampled
spatially. Siteswithfewerthan40samplesperpseudo-sitewerenotsubsampled. Atsiteswithmorethan40images,images
weresubsampledwithatargetseparationdistanceof∆=1.25maccordingtothefollowingprocedure:
1. Addthefirstimageinthedataset.
2. Continuethroughthelistofimagesinthedataset(sortedincollectionorder;i.e. chronologically)untilfindingthefirst
imageatleast∆=1.25mfromthelastimageaddedtothedataset.
3. Addeitherthisimageorthepreviousimageinthelist,whicheverisclosesttobeingadistance∆=1.25mfromthelast
imageaddedtothedataset.
4. Fromthelistofremainingimagestoconsider,removeallimagescollectedwithin∆/2=0.625mofthisimage.
5. ReturntoStep2;repeatuntilreachingtheendofthedataset.
6. Addthelastimageinthedatasetifitwasatleast∆/2=0.625mfromallotherimages.
Sites lacking precise coordinate information for each image could not be subsampled spatially. In these cases, sites were
subsampledbykeepingeveryn-thimage(orderedchronologically)atthesitetoachievethedesirednumber.
Manysitesstillhadmoreimagesthantheirtargetnumberofsamplesafterthisinitialspatialsubsampling,sothisprocesswas
repeatedwithlargerseparationdistancesuntilthetargetsubsamplesizewasachievedateachsite,oramaximumdownsampling
separationdistanceof20mwasreached. Separationdistanceswerescaledupbyfactorsof2,3,4,6,8,10,12,14,or16
comparedtothebasesubsamplingof1.25mtargetseparationtoachievethedesiredsubsamplesize(i.e. ∆=2.5m,3.75m,
...,20m). Thesubsamplingdistanceselected(andhencesubsampledsetofimagesatthatsite)wasthelargestdistancewhich
didnotreducethetotalnumberofimagesbelowthetargetforthesite(250+),determinedasdescribedabove. Thesubsampling
procedureselected1345096images(11.8%ofthetotal)tobeincludedinthesubsampledBenthicNetdataset(Figure1),which
werefertoasBenthicNet-1M.
12/30Figure1. DistributionofimagesafterspatialsubsamplingprojectedtoEqualEarth. (Top)imagesaccordingtodatasource
and(bottom)aggregatedbytheirdensityandscaledlogarithmically.
Downloading
WedownloadedimagesavailableonlinebyusingthePythonrequestspackage. URLswereretriedatleastfivetimesiftheserver
wasbusy. ImagesthatcouldnotbefoundattheirURL,thatweretruncated,orwhichcouldnotbeopenedafterdownloading,
wereremovedfromthefinaldataset. Intotal,thedownloadprocesstookapproximatelysixmonths.
Compression
Imagesweredownsampledsuchthattheirshortestsidewas512pixelsinlength,withaspectratiopreserved,andthenconverted
toJPEGformat.
Data Records
Dataformats
Allunlabelledimagemetadatawerestandardizedtoacommonformat(Table3). Thedatetimefieldwascompletedtothe
highestlevelofprecisionpossible. TimeswereconvertedtoUTCwheretimezoneswereindicated,andassumedtobeUTC
otherwise; itisnotpossibletoguaranteealltimesareinUTC.Missingdatetimeandcoordinateinformationwasimputed
everywherewherereasonablypossible—forexample, byassigningthegeographicmeancentreoftheimageacquisition
sitewherecoordinatesweremissingforsomeimagesatagivensite. Labelledimageswereadditionallyassignedmetadata
describingtheoriginalandtranslatedCATAMIlabels(Table4). Theunlabelleddatasetincludesalllabelledimages.
All BenthicNet data, metadata, and models described here are available from the Canadian Federated Research Data
Repository(FRDR;doi:https://doi.org/10.20383/103.0614). Theseinclude(i)asingleCSVfilewithanentryforeachimage
13/30Table3. FormatforcompiledBenthicNet-1Munlabelledimagemetadata.
Column Contents Data-type Units Coverage
url URLaddressforthisimage String 71.86%
source Dataprovider/repository String 100.00%
dataset Nameofdataset String 100.00%
site Imagelocationname String 100.00%
image Imagefilename String 100.00%
latitude Latitude(WGS84) Float Decimaldegree 99.63%
longitude Longitude(WGS84) Float Decimaldegree 99.63%
datetime Acquisitiondateandtime(UTC) String YYYY-MM-DDHH:mm:ss 99.85%
Table4. FormatforcompiledBenthicNet-Labelledimagemetadata. Coverageisthefractionofimageswhichhaveatleast
onesuchannotation.
Column Contents Data-type Units Coverage
url URLaddressforthisimage String 76.34%
source Dataprovider/repository String 100.00%
dataset Nameofdataset String 100.00%
site Imagelocationname String 100.00%
image Imagefilename String 100.00%
latitude Latitude(WGS84) Float Decimaldegree 100.00%
longitude Longitude(WGS84) Float Decimaldegree 100.00%
datetime Acquisitiondateandtime(UTC) String YYYY-MM-DDHH:mm:ss 100.00%
partition Train/testsplitallocation String 100.00%
annotation_column Relativexlocationoflabelledpixel Float Fractionofimagewidth 44.69%
annotation_row Relativeylocationoflabelledpixel Float Fractionofimageheight 44.69%
original_label Originalimagelabel String 82.10%
catami_biota CATAMIbiotalabel String 75.59%
catami_substrate CATAMIsubstratelabel String 70.30%
catami_bedforms CATAMIbedformlabel String 6.81%
catami_relief CATAMIrelieflabel String 2.46%
catami_qualifiers CATAMIlabelqualifier String 10.82%
colour_qualifier Labelcolourqualifier String 6.54%
aphia_id WoRMStaxonAphiaIDlabel Integer 60.15%
inthesubsampledcompilation(“BenthicNet-1M”)conformingtotheconventionpresentedinTable3;(ii)asingleCSVfile
withanentryforeachlabelofeachimageofthelabelledcompilation(“BenthicNet-Labelled”),conformingtotheformat
presentedinTable4;(iii)atarreddirectorycontainingeachimageinBenthicNet-1MandBenthicNet-Labelled(asdescribed
in the CSV files above), resized and compressed to JPEG format; (iv) a version of the entire image compilation tarred at
the individual “dataset” level; and (v) the ResNet-50 model weights resulting from self-supervised training on the entire
unlabelleddatasetasdescribedinthefollowingTechnicalValidationsection. WeadditionallyincludeaCSVfilelistingthe
countsofeachindividualCATAMIlabelpresentinthelabelledcompilation. The“image”directoryhostedonFRDRisdivided
into“labelled”and“unlabelled”components,whichcontainthefulltarred(full_labelled_512px.tar)andindividual
datasettars(individual_datasets_tars)versionsoftheimages. Bothdirectoriesareorganizedby“dataset”,which
containsub-directoriescorrespondingtothe“site”. Thus,itispossibletoquerytheimagecompilationusingthecorresponding
CSVmetadatafields“dataset”>“site”>“image”. Themetadataandmodelsareavailableforusewithoutrestrictionunder
the Creative Commons Attribution 4.0 License (CC-BY-4.0). Most images are available for use without restriction under
CC-BY-4.0,exceptwheretheoriginallicensesofindividualdatasetsindicatelimitationstoderivativeorcommercialuses(see
AppendixBfordetails).
14/30Technical Validation
Unlabelleddataexploratoryanalysis
ThesubsampledBenthicNetdatasetcontainsimagesfromlocationsaroundtheworldFigure1. Severalregionsaredensely
sampled—notably,theentireAustraliancoast,theIberianPeninsula,theNorwegianandGreenlandSeas,theEasternCanadian
andNortheasternU.S.continentalshelves,theWesternCanadianandWesternU.S.continentalshelves,andalsosomeofthe
Antarcticcoast,includingpartsoftheAntarcticPeninsulaandWeddellSea. Imagescollectedintheopenoceansaremore
dispersedthanthoseatthecontinentalshelves.
Environmentalheterogeneity
Giventhespatialheterogeneityinbenthicimagesamplingintensity,itisimportantandinformativetoassesstheenvironmental
andgeographicdiversityoftheseimages. Imagesinthecompileddatasetswereacquiredbetween1965–2021fromdepths
ranging from < 1m to over 5500m (Figure 2). Sayre et al.102 introduced a three-dimensional partitioning of the global
oceansintostatisticalclustersbasedona57-yearclimatologyofphysiochemicaloceanographicmeasurements103–106. These
37“EcologicalMarineUnits”(EMUs)representaconciseandobjectivesummaryofglobalmarineenvironmentsat0.25◦
horizontalresolution,andarefreelyavailablefordownload. Thebottom-layerEMUswereextractedtoassessthedistribution
ofBenthicNetimagesamplesacrossglobalbenthicenvironmentalregions. Eachimagewasassignedthenearestbottom-layer
(i.e. seafloor)EMUinspacetocomparethesampledfrequencyofeachenvironmenttotheproportionofareacoveredbyeach
EMU(Figure3). Asimilaranalysiswasconductedtoassesstherepresentativenessofimagesamplesacrossthebroaderglobal
oceansbycomparingthesampledfrequencytotheareaofeachoceanbasin,accordingthetheEMUattributes(Figure4).
Generally,imagesweredistributedmoreevenlyacrossthebottom-layerEMUsthanwouldbeexpectedfromarandom
sample,whilethedistributionacrossthemajoroceanbasinsmorecloselymatchedexpectation. Themajorityoftheglobal
seafloor(82.4%)isclassifiedintoEMUs14(deep,verycold,normalsalinity,moderateoxygen,highnitrate,lowphosphate,high
silicate),13(deep,verycold,normalsalinity,lowoxygen,highnitrate,mediumphosphate,highsilicate),and36(deep,very
cold,normalsalinity,moderateoxygen,mediumnitrate,lowphosphate,lowsilicate)102,comprisingmostofthePacific,Indian,
andpolaroceans. Theseenvironmentsarenotover-representedintheBenthicNetdataset,withnosingleEMUaccounting
for> 20.6%. ThethreemostcommonEMUssampled(47.6%)were24(shallow,warm,normalsalinity,moderateoxygen,
lownitrate,lowphosphate,lowsilicate),11(shallow,cool,normalsalinity,moderateoxygen,lownitrate,lowphosphate,low
silicate),and13(deep,verycold,normalsalinity,lowoxygen,highnitrate,mediumphosphate,highsilicate),representing
continentalshelvesintheequatorialregions,theshallowsub-tropics,andthedeepPacificandIndianoceans. Thedistributionof
imagesacrossoceanbasinswasgenerallyproportionatetotheexpectationgiventheareaofeachocean,butnotableexceptions
includeanapparentunder-representationoftheSouthAtlantic,andover-representationoftheSouthPacific.
Figure2. DistributionofBenthicNet-1Mimagesaccordingto(a)(logscale)depthdataretrievedfromtheGEBCO2022
grid107and(b)yearofacquisition.
15/30Figure3. DistributionofBenthicNet-1MimagesaccordingtobottomlayerEcologicalMarineUnits(EMUs). (a)Proportion
andareaofglobaloceansclassifiedintoeachEMU.(b)ProportionofBenthicNetimagesamplesfromeachEMU.SeeSayeret
al.102 forafulldescriptionoftheEMUclasses.
16/30Figure4. DistributionofBenthicNet-1Mimagesaccordingtoglobaloceanbasins102. (a)Proportionandareaofoceanbasins.
(b)ProportionofBenthicNetimagesamplesfromeachoceanbasin.
Self-supervisedlearning
Asaminorityoftheimagerywaslabelled,wesoughttoutilizetheunlabelleddatabyusingself-supervisedlearning(SSL)to
trainanencoderbeforeadaptingittothedownstreamtaskonthelabelleddata. Asaseriesofbenchmarks,weexaminedfour
recentSSLmethodsusingaResNet-50modelarchitecture,trainedontheBenthicNet-1Mdata. Thesefourmethodsarefroma
familyoftechniquesknownasinstancelearningandconsistofSimSiam41,BootstrapYourOwnLatent(BYOL)40,Momentum
Contrast(MoCo-v2)108,andBarlowTwins(BT)100.Wefoundthatoverall,themethodsperformedsimilarly,withBTperforming
consistentlywellatthedownstreamclassificationtasks. Allsubsequentanalysesfollowinginitialexperimentationandreporting
usesBarlowTwinsastherepresentativemethodforSSL.
As an instance learning method, BT’s pretext task for learning a useful embedding space works with the encoded
representations of a batch of images. Each image in the batch, X, is distorted twice using transformations independently
randomlyselectedfromapredefinedtransformation-generator,producingtwoinputviews,X andX . Thetransformation-
A B
generatorisconstructedsuchthatitdoesnotaltertheapparentidentityofthecontentsoftheimage,butdoesalterotheraspects
oftheimagesuchasthecolourbalance,contrast,andzoom. Eachbatchoftransformedimagesispassedthroughthemodelto
yieldembeddingsZ andZ . Byusingthecosinesimilaritydistancemetric,acorrelationmatrixCisconstructedbetweeneach
A B
embeddingvectorinZ andeachinZ . Anidealencoderwouldberobustagainsttherandomly-selectedtransforms,producing
A B
17/30thesameembeddingvectornomatterwhichtransformisselected,hencewewouldlikethediagonalofCtobe1. Furthermore,
imageswhichhavedifferentcontentsshouldbeencodeddifferentlysowecantellthemapartfromtheirembeddings;hencewe
wouldliketheoff-diagonalelementsofCtobezero. Thisobjectiveatahighlevelcanbedescribedasrenderingthemodel
embeddingspaceinvarianttothetransformationsapplied,whilealsointroducinganorthogonalitytothismodel’sembedding
space100.
UsingtheBTSSLparadigm,wetrainedaResNet-50modelontheBenthicNet-1Mdatasetforthreedifferentdurations
(100,200,and400epochs)withtheAdamWoptimizer109,110. ThehyperparameterswerethesameasusedbyZbontaretal.100,
exceptthelearningrateasourinitialexperimentsshowedasmallerlearningrateof2×10−3yieldedbetterperformancethan
thedefaultof0.2. Thelearningratewasannealedusingaone-cyclecosineschedulewithawarm-upperiodof10epochs111.
ThemodelsweretrainedusingfourNvidiaA100GPUs,withatotalbatchsizeof512.
Labelleddataexploratoryanalysis
TheBenthicNet-LabelleddataspansaglobalextentsimilartothatoftheBenthicNet-1Mdata(Figure5,comparedagainst
Figure1). TwooftheEMUsthatwereabundantlysampledwithunlabelledimagerywerealsoprominentlyrepresentedin
thelabelleddataset;EMUs11(shallow,cool,normalsalinity,moderateoxygen,lownitrate,lowphosphate,lowsilicate)and
24(shallow, warm, normalsalinity, moderateoxygen, lownitrate, lowphosphate, lowsilicate)comprisedanear-majority
(49.82%)ofofthelabelleddataset(Figure6). Thesetwoenvironmentsarebroadlydistributedinspace102,andhereprimarily
representdatasetsfromAustralia,Tasmania,andCentralAmerica. ThefulldistributionoflabelsacrosstheCATAMIhierarchy
isprovidedassupplementarymaterial.
Figure5. DistributionoflabelledBenthicNetimagesprojectedtoEqualEarth. (Top)EcologicalMarineUnits(EMUs)of
labelledimagesand(Bottom)labelledimagesampledensityscaledlogarithmically.
18/30Figure6. DistributionofBenthicNetimagesaccordingtobottomlayerEcologicalMarineUnits(EMUs)for(a)unlabelled
and(b)labelleddatasets. SeeSayeretal.102 forafulldescriptionoftheEMUclasses.
Supervisedtransferlearning
HereweprovidetwoexamplesofutilizingalargemodelpretrainedwithSSLontheunlabelledBenthicNet-1Mdatasetfor
automatingbenthicimagelabellingtasks.
First,wetrainedamodeltoclassifythesubstratevisibleinbenthicimageryatthegranularityofthesecondlevelinthe
CATAMIsubstratehierarchy,comprisedofthe5classes“Sand/mud”,“Pebble/gravel”,“Cobbles”,“Boulders”,and“Rock”.
ThismodelwastrainedthesubsetofBenthicNet-Labelledcontainingwhole-imagesingly-annotatedCATAMISubstratelabels
toatleastthislevelofgranularity. Werefertothissubsetasthe“SubstrateDepth-2dataset”,comprisedof75537images—
58418ofwhichwereusedfortraining,and17119fortesting(partitionedasdescribedaboveinLabelleddata). Usingthe
pretrainedResNet-50backbone,weaddedalinearclassifierheadwithsoftmaxactivationtopredicttheclassoftheimage. The
targetswereone-hotencoded. ToevaluatetheutilityofSSLpretrainingontheBenthicNet-1Mdataset,wealsocompareagainst
transferlearningfromapubliclyavailableResNet-50modelpretrainedwithcross-entropyonImageNet-1k(600epochs),
providedbytorchvision112,andagainsttrainingfromscratchonSubstrate-2withoutanypretraining.
Oursupervisedclassificationpipelineconsistsoftwostages: alinearprobeandfine-tuning. Duringthelinearprobe,the
pretrainedencoderweightsarefrozenwhilstthenewlinearclassifierheadistrained. Wetrainedtheclassifierheadfor100
epochswithaone-cyclecosineannealingschedulerforthelearningrate. AswiththeSSLtraining,thelearningratestarted
19/30at3×10−6,andincreasedtoamaximumof3×10−5 over10warm-upepochs,thenwascosineannealedbackdowntothe
originalrate. Forthefine-tuningstage,webeginwiththepretrainedencoderandtheclassifierheadfromthelinearprobe. We
unfreezetheencoder,andtrainthewholenetworkend-to-endwithonetenththelearningrateusedforthelinearprobefor300
epochs(atotaltrainingperiodof400epochsacrossbothstages).
Thetransfer-learningmodelswerecomparedtomodelstrainedfromscratch. Thesewererandomlyinitialized,andthe
entiremodel(encoderandclassifier)trainedend-to-endfor100or400epochs,usingtheone-cycleschedulewithpeaklearning
rate3×10−5.
Table5. Micro-accuracyandmacroF1-score(%)onSubstrateDepth-2datasetwhentrainingfromscratch(Nopretraining),
withlinearprobeofapretrainedencoder(Frozen)orfinetuning(notfrozen). Mean(±std. err.) overn=3randomseeds
(samepretrainedbackbonesoverseeds). Bold: bestperforminglinearprobeandfine-tunedmodels.
Pretraining
Dataset Loss Frozen Epochs Accuracy↑ F1-score↑
ImageNet-1k Cross-entropy ✓ 100 51.2±0.5 66.6±0.4
BenthicNet-1M BarlowTwins ✓ 100 51.4±0.4 64.0±0.1
Nopretraining ✗ 100 53.3±0.7 57.9±0.8
Nopretraining ✗ 400 76.4±0.4 78.7±0.3
ImageNet-1k Cross-entropy ✗ 100+300 75.5±0.3 84.0±0.2
BenthicNet-1M BarlowTwins ✗ 100+300 76.8±0.2 82.8±0.1
                         
 H U V
 G
 X O
 R
 %                            
 H V
 E O
 E
 R
 &
                       
 R F N
 5
                         
 H O
 D Y
 J U
 H   
                     
 H E E O
 P
 P 
 3  
 
 6 D Q G    P X G    % R X O G H U V  & R E E O H V  5 R  E F  E N  O H    J U D Y  P H  X O  G     P  P   % R X O G H U V  & R E E O H V  5 R  E F  E N  O H    J U D Y  P H  X O  G     P  P 
 3 H  G     3 H  G   
 Q  Q
 D  D
 6  6
 3 U H G L F W H G  3 U H G L F W H G
Figure7. Confusionmatrix(%ofgroundtruth)forCATAMISubstratepredictionsonSubstrate-2data. (Left)Model
pretrainedwithcross-entropyonImageNet-1k,fine-tunedonSubstrate-2. (Right)ModelpretrainedwithBarlowTwinson
BenthicNet-1M,fine-tunedonSubstrate-2.
AsshowninTable5,theperformanceoftheImageNet-1kandBenthicNet-1Mpretrainedmodelswascomparable,withthe
ImageNet-1kpretrainedmodelyieldinghigheraccuracyandtheBenthicNet-1MpretrainedyieldinghigherF1-score,forboth
thelinearprobeandfinetuningevaluations. Bothmodelsoutperformedthemodeltrainedfromscratch. Theconfusionmatrices
(Figure7)showsthemodelshavesimilarbiases,confusingthesameclassesaseachother(Boulders↔Cobbles;Cobbles→
Pebble/gravel;everything→Sand/mud).
Asasecondtask, weconsideredtheGermanBank2010datasetprovidedbyDFO(Table1), whichhadwhole-image
“benthoscape”labelsdescribedbyBrownetal.76. Intheoriginallabellingscheme,fivebenthoscapelabelswereassignedthat
describerecognizablecombinationsofsubstrate,bedforms,andbiologyvisiblein3181images,collectedoffthesouthwest
coastofNovaScotia,Canada. Thebenthoscapelabelswere(1)“reef”inwhichbouldersorbedrockwithfrequentepifauna
comprisemorethan50%ofimages;(2)“glacialtill”consistingofmixedsediments(cobble,gravel,sand);(3)“silt/mud”with
frequentevidenceofinfaunalbioturbation;(4)“siltwithbedforms”;and(5)“sandwithbedforms”,whichcommonlyincluded
20/30
 K W X U 7  G Q X R U *sanddollars(Echinarachniusparma). Again,thepretrainedResNet-50modelswereutilizedbyaddinganewclassifierhead
whoseoutputscorrespondtoeachofthebenthoscapeclasses. UsingtheBenthicNet-Lpartitions(describedinLabelleddata),
2681imageswereusedtotrainthemodeland500wereusedfortesting. Themodeltraininghyperparameterswereidenticalto
thoseusedfortheSubstrateDepth-2experiments.
Table6. Micro-accuracyandmacroF1-score(%)onGermanBank2010datasetwhentrainingfromscratch(Nopretraining),
withlinearprobeofapretrainedencoder(Frozen)orfinetuning(notfrozen). Mean(±std. err.) overn=3randomseeds
(samepretrainedbackbonesoverseeds). Bold: bestperforminglinearprobeandfine-tunedmodels.
Pretraining
Dataset Loss Frozen Epochs Accuracy↑ F1-score↑
ImageNet-1k Cross-entropy ✓ 100 37.6±5.2 30.0±2.9
BenthicNet-1M BarlowTwins ✓ 100 55.9±2.4 43.2±6.0
Nopretraining ✗ 100 53.4±2.4 43.0±3.8
Nopretraining ✗ 400 54.1±3.2 46.7±3.2
ImageNet-1k Cross-entropy ✗ 100+300 65.9±4.0 59.2±4.2
BenthicNet-1M BarlowTwins ✗ 100+300 77.0±0.7 72.3±0.8
                     
 G
 X
 P
 V L O W 
                       
 P V
 R U
 G I
 Z L W K  E H
 U H H I
                         
 V L O W 
                       
 D O  W L O O
 D F L
 J O                         
 P V
 R U
 G I
 V D Q G  Z L W K  E H  V L O W   Z L P  W X  K  G  E H G I R U P V  U H H I  J O D F L D  Z O  L   W W L  K O   O  E H G I R U P V  V L O W   Z L P  W X  K  G  E H G I R U P V  U H H I  J O D F L D  Z O  L   W W L  K O   O  E H G I R U P V
 V L O W   D Q G   V L O W   D Q G 
 V  V
 3 U H G L F W H G  3 U H G L F W H G
Figure8. Confusionmatrix(%ofgroundtruth)fortheGermanBank2010dataset. (Left)Modelpretrainedwith
cross-entropyonImageNet-1k,fine-tunedonGermanBank2010. (Right)ModelpretrainedwithBarlowTwinson
BenthicNet-1M,fine-tunedonGermanBank2010.
AsshowninTable6,weobservedthatthemodelpretrainedonBenthicNet-1Mstronglyoutperformedboththemodel
pretrainedonImageNet-1k,andthemodeltrainedfromscratch. Thefine-tunedBenthicNet-1Mmodelwasabletocorrectly
identify“silt/mud”and“siltwithbedforms”classesin87%and88%ofcases(seeFigure8). Bothfine-tunedmodelsconfused
certainclasspairs(reef→glacialtill;sandwithbedforms→reef;siltwithbedforms→silt/mud),buttheBenthicNet-1MSSL
pretrainedmodelwasabletogreatlyincreasetherecallofboth“silt/mud”and“siltwithbedforms”,andgreatlyreducethehigh
confusiontheImageNet-1kmodelexhibitedforotherpairs(glacialtill↔sandwithbedforms).
Animportantobservationisthatforbothsupervisedclassificationtasks,andbothtransfermodels,thebest-predictedclasses
tendedtobethosethataremostdistinct,whiletheintermediateclassestendtobeconfused. Forexample,“cobble”wasthe
mostdifficultlabeltopredictintheSubstrate-2dataset,andindeed,itcanbedifficultevenforahumantodifferentiatecobbles
frompebblesorbouldersinunderwaterimagery. Thesesubstrateclassboundariesaredefinedarbitrarilyataparticularlength
scale(2mmand64mm)thatmayonlybedeterminedthroughaccuratemeasurementorimagescaling;thereissubstantial
possibilityofincorrectorsubjectivehumanlabelsforsuchdata. Additionally,theimbalancedpriorsfortheclassesmayalso
playaroleinpredictivesuccess. Sandandmudlabelsdominatebothdatasubsets—itisnotsurprisingthatthemodelshavea
tendencytopredictsandforotherclasses,andtoperformstronglyonsand.
21/30
 K W X U 7  G Q X R U *Whileperformancebetweenthetransfermodels(ImageNet-1kandBenthicNet-1M)weresimilarfortheSubstrate-2task,
differencesinperformanceonGermanBank2010werefarmorepronounced. Notably,ourself-supervisedmodelwasthe
strongestperformingacrossallaspectsoftheevaluation—outperformingallothersusingbothlinearprobesandfinetuning
Table6. Thefine-tunedresultsforBenthicNet-1Malsodemonstratelessvariancecomparedtotheothermodels. Weconjecture
that,whiletransferlearningmayperformwellforbothpretrainedmodelsifthelabelleddatasetislargeenough(i.e. tensof
thousandsoflabelledimagesfortheSubstrate-2task),theBenthicNet-1MSSLpretrainedmodelisbetterabletotransferto
smaller,morefine-graineddatasets,wherefewertrainingexamplesperclassareavailable. Previousexposuretooveramillion
relevantimagesduringtheSSLphasemayhaveenhanceditsabilitytoseparateimageswhichinitiallylooklikebroadlysimilar
seafloorimages. WenotethatthesizeoftheGermanBank2010datasetissimilartowhatmightbecommonlyencounteredfor
asite-specifichabitatmappingapplication(e.g. thousandsoflabelledimages). Anumberofexperimentsexploringtheseand
relatedresearchquestionsarecurrentlyunderway—forexample,onthehierarchicalandmulti-labelCATAMIclassificationof
BenthicNetimages113. OurResNet-50model,pretrainedonBenthicNet-1MwithBT,isaccessiblefromtheFRDRrepository
(doi:https://doi.org/10.20383/103.0614).
Usage Notes
WenotethatdatalabelstranslatedtotheCATAMIschemeweresourcedfromawidevarietyofscientificstudieswiththe
expressintentofsupportingthetrainingandvalidationoflargeimagerecognitionmodels. Jointly, theselabelsshouldbe
analyzed with care, particularly if utilized for other purposes. Some datasets included whole image labels indicating the
presenceofasinglebenthicfeature(e.g. organism,substrate),whileotherssuppliedsinglelabelsindicatingmultiplefeatures,
ormultiplelabelsfordifferentfeatureswithinanimage. Oneresultofsuchdiversityisvariationamongthecompleteness
oflabelsfromdifferentdatasets—some,forexample,focusonathepresenceofsinglespecies,oronlyfocusonthemost
conspicuousorabundantsubstratetypes. Forsomedatasets,itisthusreasonabletoexpectalargerproportionoffalsenegative
labelsifthedataistreatedinapresence/absencemanner. Inotherwords,manybenthicfeaturesarelikelyvisibleintheimages,
whichhavenotbeenlabelled. Weoperateundertheassumption,though,thatlabelswithinadatasetwereassignedconsistently.
Ifperforminganalysesatthedatasetlevelusingthecompilationpresentedhere,itisimportanttoinvestigatethespecificsofthe
dataset(s)inquestion.
Similarly,thediversityoflabellingmethodologieshasresultedinanumberofdifferentschemabywhichoriginallabels
weretranslatedtotheirCATAMIequivalents. Forexample,somelabelsindicatingthepercentcoveroforganismsorsubstrate
typesinanimagewereconvertedtobinarypresence/absenceinformationforthepurposesofassigninglabels. Additionally,
auxiliaryinformationprovidedwithlabelssuchasannotatornoteswereusedinsomecasestoobtainaCATAMIlabel,orto
enhanceitsaccuracy. Effortsweremadetoindicatetheoriginaldatalabelascloselyaspossibleinthelabelledmetadatafile,
butitwasnotalwayspossibletoincludeallinformationthatwasusedtotranslateanoriginallabeltotheCATAMIscheme.
Therefore,originallabelsprovidedinourmetadatamaynotcontainallavailablelabelledinformationforeachimage,andthe
originaldatasetsshouldbereferencedastheauthoritativesourceinallcases.
Theexamplesprovidedherefocusonthephysicalenvironment,butthereareabundantopportunitiestoexploreuseof
thebiologicallabels. ThroughuseoftheSSLpretrainedencoder,webelievethatthetraininganddeploymentofhierarchical
morphologicalandtaxonomicidentificationmodelsispossible. Theseapplicationswillbeexploredincomingwork.
Code availability
Codeusedtoquery,download,convert,process,subsample,andpartitionthefulldatacompilationmaybeaccessedwithout
restrictionfromhttps://github.com/DalhousieAI/BenthicNet. Codeusedtoqueryanddownloaddatafrom
SQUIDLE+usingtheAPIisavailableathttps://github.com/DalhousieAI/squidle-downloader.Codeused
toqueryanddownloaddatafromPANGAEAisavailableathttps://github.com/DalhousieAI/pangaea-downloader.
Codeusedtotraintheself-supervisedmodelisavailableathttps://github.com/DalhousieAI/ssl-bentho.
Codeusedtoperformone-hotmulti-classtransferlearning,aspresentedinthesectionSupervisedtransferlearning,isavailable
athttps://github.com/DalhousieAI/benthicnet_probes.
References
1. Harris,P.T.&Baker,E.K. Whymapbenthichabitats? InHarris,P.T.&Baker,E.K.(eds.)SeafloorGeomorphologyas
BenthicHabitat,3–15,doi:10.1016/B978-0-12-814960-7.00001-4(Elsevier,2020),2ndedn.
2. Baker,E.K.&Harris,P.T. Habitatmappingandmarinemanagement. InHarris,P.T.&Baker,E.K.(eds.)Seafloor
GeomorphologyasBenthicHabitat,17–33,doi:10.1016/B978-0-12-814960-7.00002-6(Elsevier,2020),2ndedn.
22/303. Brown,C.J.,Smith,S.J.,Lawton,P.&Anderson,J.T. Benthichabitatmapping: Areviewofprogresstowardsimproved
understandingofthespatialecologyoftheseafloorusingacoustictechniques. Estuarine,Coast.ShelfSci.92,502–520,
doi:10.1016/j.ecss.2011.02.007(2011).
4. Misiuk,B.&Brown,C.J. Benthichabitatmapping: Areviewofthreedecadesofmappingbiologicalpatternsonthe
seafloor. EarthArXivdoi:10.31223/X5DD4S(2023).
5. Williams,S.B.,Pizarro,O.,Jakuba,M.&Barrett,N. AUVbenthichabitatmappinginsoutheasternTasmania. InField
andServiceRobotics,275–284,doi:10.1007/978-3-642-13408-1_25(Springer,2010).
6. González-Rivero,M.etal. TheCatlinSeaviewSurvey–kilometre-scaleseascapeassessment,andmonitoringofcoralreef
ecosystems. AquaticConserv.Mar.Freshw.Ecosyst.24,184–198,doi:https://doi.org/10.1002/aqc.2505(2014).
7. Foster, S.D., Hosack, G.R., Hill, N.A., Barrett, N.S.&Lucieer, V.L. Choosingbetweenstrategiesfordesigning
surveys: autonomousunderwatervehicles. MethodsEcol.Evol.5,287–297,doi:10.1111/2041-210X.12156(2014).
8. Kendall,M.S.etal. Benthicmappingusingsonar,videotransects,andaninnovativeapproachtoaccuracyassessment:
acharacterizationofbottomfeaturesintheGeorgiaBight. J.Coast.Res.2005,1154–1165,doi:10.2112/03-0101R.1
(2005).
9. Misiuk,B.,Bell,T.,Aitken,A.,Brown,C.J.&Edinger,E.N. MappingArcticclamabundanceusingmultipledatasets,
models, andaspatiallyexplicitaccuracyassessment. ICESJ.Mar.Sci.76, 2349–2361, doi:10.1093/icesjms/fsz099
(2019).
10. Schoening,T.,Osterloff,J.&Nattkemper,T.W. RecoMIA—Recommendationsformarineimageannotation: Lessons
learnedandfuturedirections. Front.Mar.Sci.3,59,doi:10.3389/fmars.2016.00059(2016).
11. Beijbom,O.etal. Towardsautomatedannotationofbenthicsurveyimages: Variabilityofhumanexpertsandoperational
modesofautomation. PLOSONE10,1–22,doi:10.1371/journal.pone.0130312(2015).
12. LeCun,Y.,Bengio,Y.&Hinton,G. Deeplearning. Nature521,436–444,doi:10.1038/nature14539(2015).
13. Schmidhuber,J. DeepLearning. Scholarpedia10,32832,doi:10.4249/scholarpedia.32832(2015). Revision#184887.
14. Goodfellow,I.,Bengio,Y.&Courville,A. DeepLearning(MITPress,2016). http://www.deeplearningbook.org.
15. Krizhevsky,A.,Sutskever,I.&Hinton,G.E. ImageNetclassificationwithdeepconvolutionalneuralnetworks. InPereira,
F.,Burges,C.,Bottou,L.&Weinberger,K.(eds.)AdvancesinNeuralInformationProcessingSystems,vol.25(Curran
Associates,Inc.,2012). https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.
16. He,K.,Zhang,X.,Ren,S.&Sun,J.Deepresiduallearningforimagerecognition.InProceedingsoftheIEEEConference
onComputerVisionandPatternRecognition(CVPR),770–778,doi:10.1109/CVPR.2016.90(2016).
17. Bengio,Y.,Lecun,Y.&Hinton,G. DeeplearningforAI. Commun.ACM64,58–65,doi:10.1145/3448250(2021).
18. Simonyan,K.&Zisserman,A. Verydeepconvolutionalnetworksforlarge-scaleimagerecognition. InBengio,Y.&
LeCun,Y.(eds.)3rdInternationalConferenceonLearningRepresentations,ICLR,SanDiego,CA,USA,May7-9,2015,
ConferenceTrackProceedings,doi:10.48550/arXiv.1409.1556(2015).
19. Szegedy,C.,Vanhoucke,V.,Ioffe,S.,Shlens,J.&Wojna,Z. RethinkingtheInceptionarchitectureforcomputervision. In
2016IEEEConferenceonComputerVisionandPatternRecognition(CVPR),2818–2826,doi:10.1109/CVPR.2016.308
(2016).
20. Tan, M. & Le, Q. EfficientNet: Rethinking model scaling for convolutional neural networks. In Chaudhuri, K. &
Salakhutdinov, R. (eds.) Proceedings of the 36th International Conference on Machine Learning (ICML), vol. 97
of Proceedings of Machine Learning Research, 6105–6114, doi:10.48550/arxiv.1905.11946 (PMLR, 2019). http:
//proceedings.mlr.press/v97/tan19a.html.
21. Dosovitskiy,A.etal. Animageisworth16x16words: Transformersforimagerecognitionatscale. In9thInternational
ConferenceonLearningRepresentations,ICLR,doi:10.48550/arxiv.2010.11929(2021).
22. Ronneberger,O.,Fischer,P.&Brox,T. U-Net: Convolutionalnetworksforbiomedicalimagesegmentation. InNavab,
N.,Hornegger,J.,Wells,W.M.&Frangi,A.F.(eds.)MedicalImageComputingandComputer-AssistedIntervention–
MICCAI2015,234–241,doi:10.1007/978-3-319-24574-4_28(SpringerInternationalPublishing,Cham,2015).
23. Redmon,J.,Divvala,S.,Girshick,R.&Farhadi,A.Youonlylookonce:Unified,real-timeobjectdetection.InProceedings
oftheIEEEConferenceonComputerVisionandPatternRecognition(CVPR),779–788,doi:10.1109/CVPR.2016.91
(2016).
23/3024. Minaee,S.etal. Imagesegmentationusingdeeplearning: Asurvey. IEEETransactionsonPatternAnalysisMach.Intell.
44,3523–3542,doi:10.1109/TPAMI.2021.3059968(2022).
25. Goodfellow, I. et al. Generative adversarial nets. In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N. &
Weinberger, K. (eds.) Advances in Neural Information Processing Systems, vol. 27 (Curran Associates, Inc., 2014).
https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf.
26. Nichol,A.Q.etal. GLIDE:Towardsphotorealisticimagegenerationandeditingwithtext-guideddiffusionmodels. In
Chaudhuri,K.etal.(eds.)Proceedingsofthe39thInternationalConferenceonMachineLearning,vol.162ofProceedings
ofMachineLearningResearch,16784–16804(PMLR,2022). https://proceedings.mlr.press/v162/nichol22a.html.
27. Ramesh,A.,Dhariwal,P.,Nichol,A.,Chu,C.&Chen,M. Hierarchicaltext-conditionalimagegenerationwithclip
latents. arXivpreprintarXiv:2204.06125,doi:10.48550/arxiv.2204.06125(2022).
28. Rombach, R., Blattmann, A., Lorenz, D., Esser, P. & Ommer, B. High-resolution image synthesis with latent diffu-
sion models. In 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 10674–10685,
doi:10.1109/CVPR52688.2022.01042(2022).
29. Karpathy, A. What I learned from competing against a ConvNet on ImageNet. Andrej Karpathy blog (2014). http:
//karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/,Accessed:2022-05-01.
30. Russakovsky, O. et al. ImageNet large scale visual recognition challenge. Int. J. Comput. Vis. 115, 211–252,
doi:10.1007/s11263-015-0816-y(2015).
31. Santoro,A.,Bartunov,S.,Botvinick,M.,Wierstra,D.&Lillicrap,T. Meta-learningwithmemory-augmentedneural
networks. InBalcan,M.F.&Weinberger,K.Q.(eds.)ProceedingsofThe33rdInternationalConferenceonMachine
Learning(ICML),vol.48ofProceedingsofMachineLearningResearch,1842–1850(PMLR,NewYork,NewYork,
USA,2016). https://proceedings.mlr.press/v48/santoro16.html.
32. LeCun, Y. et al. Backpropagation applied to handwritten zip code recognition. Neural Comput. 1, 541–551,
doi:10.1162/neco.1989.1.4.541(1989).
33. Althaus,F.etal. Astandardisedvocabularyforidentifyingbenthicbiotaandsubstratafromunderwaterimagery: The
CATAMIclassificationscheme. PLOSONE10,1–18,doi:10.1371/journal.pone.0141039(2015).
34. Mount,R.,Bricher,P.&Newton,J. NationalIntertidal/SubtidalBenthic(NISB)habitatclassificationscheme. Tech.
Rep.,AustralianGreenhouseOffice,NationalLand&WaterResourcesAudit,SchoolofGeographyandEnvironmental
Studies,UniversityofTasmania(2007). https://ozcoasts.org.au/wp-content/uploads/2018/05/pn21267.pdf.
35. MarineandCoastalSpatialDataSubcommittee. Coastalandmarineecologicalclassificationstandard(CMECS). Tech.
Rep.FGDC-STD-018-2012,UnitedStatesFederalGeographicDataCommittee(2012). https://repository.library.noaa.
gov/view/noaa/27552.
36. Balestriero, R. et al. A cookbook of self-supervised learning. arXiv preprint arXiv:2304.12210,
doi:10.48550/arxiv.2304.12210(2023).
37. Chen,T.,Kornblith,S.,Norouzi,M.&Hinton,G. Asimpleframeworkforcontrastivelearningofvisualrepresentations.
InIII,H.D.&Singh,A.(eds.)Proceedingsofthe37thInternationalConferenceonMachineLearning(ICML),vol.119of
ProceedingsofMachineLearningResearch,1597–1607(PMLR,2020). https://proceedings.mlr.press/v119/chen20j.html.
38. He, K., Fan, H., Wu, Y., Xie, S. & Girshick, R. Momentum contrast for unsupervised visual representation
learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
doi:10.1109/CVPR42600.2020.00975(2020).
39. Chen,T.,Kornblith,S.,Swersky,K.,Norouzi,M.&Hinton,G.E. Bigself-supervisedmodelsarestrongsemi-supervised
learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. & Lin, H. (eds.) Advances in Neural Information
ProcessingSystems,vol.33,22243–22255(CurranAssociates,Inc.,2020). https://proceedings.neurips.cc/paper_files/
paper/2020/file/fcbc95ccdd551da181207c0c1400c655-Paper.pdf.
40. Grill,J.-B.etal. Bootstrapyourownlatent-anewapproachtoself-supervisedlearning. InLarochelle,H.,Ranzato,M.,
Hadsell,R.,Balcan,M.&Lin,H.(eds.)AdvancesinNeuralInformationProcessingSystems,vol.33,21271–21284
(CurranAssociates,Inc.,2020). https://papers.nips.cc/paper/2020/file/f3ada80d5c4ee70142b17b8192b2958e-Paper.pdf.
41. Chen,X.&He,K. Exploringsimplesiameserepresentationlearning. InProceedingsoftheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition(CVPR),15750–15758,doi:10.1109/CVPR46437.2021.01549(2021).
24/3042. Chen,X.,Xie,S.&He,K. Anempiricalstudyoftrainingself-supervisedvisiontransformers. InProceedingsofthe
IEEE/CVFInternationalConferenceonComputerVision(ICCV),9640–9649, doi:10.1109/ICCV48922.2021.00950
(2021).
43. Caron,M.etal. Emergingpropertiesinself-supervisedvisiontransformers. In2021IEEE/CVFInternationalConference
onComputerVision(ICCV),9630–9640,doi:10.1109/ICCV48922.2021.00951(2021).
44. He,K.etal. Maskedautoencodersarescalablevisionlearners. In2022IEEE/CVFConferenceonComputerVisionand
PatternRecognition(CVPR),15979–15988,doi:10.1109/CVPR52688.2022.01553(2022).
45. Ierodiaconou,D.etal. Combiningpixelandobjectbasedimageanalysisofultra-highresolutionmultibeambathymetry
andbackscatterforhabitatmappinginshallowmarinewaters. Mar.Geophys.Res.39,271–288,doi:10.1007/s11001-017-
9338-z(2018).
46. Baumstark, R., Duffey, R. & Pu, R. Mapping seagrass and colonized hard bottom in Springs Coast, Florida using
WorldView-2satelliteimagery. Estuarine,Coast.ShelfSci.181,83–92,doi:10.1016/j.ecss.2016.08.019(2016).
47. Buhl-Mortensen,P.etal. ClassificationandmappingofbenthicbiotopesinArcticandSub-ArcticNorwegianwaters.
Front.Mar.Sci.271,doi:10.3389/fmars.2020.00271(2020).
48. Espinosa,F.etal. AssessmentofconservationvalueofCapdesTroisFourches(Morocco)asapotentialMPAinsouthern
Mediterranean. J.Coast.Conserv.19,553–559,doi:10.1007/s11852-015-0406-8(2015).
49. Neves, B. M., Du Preez, C. & Edinger, E. Mapping coral and sponge habitats on a shelf-depth environment using
multibeamsonarandROVvideoobservations: LearmonthBank,northernBritishColumbia,Canada. Deep.SeaRes.
PartII:Top.Stud.Oceanogr.99,169–183,doi:10.1016/j.dsr2.2013.05.026(2014).
50. Wienberg,C.,Wintersteller,P.,Beuck,L.&Hebbeln,D. CoralPatchseamount(NEAtlantic)–asedimentologicaland
megafaunalreconnaissancebasedonvideoandhydroacousticsurveys. Biogeosciences10,3421–3443,doi:10.5194/bg-
10-3421-2013(2013).
51. Galparsoro,I.etal. UsingEUNIShabitatclassificationforbenthicmappinginEuropeanseas: Presentconcernsand
futureneeds. Mar.Pollut.Bull.64,2630–2638,doi:10.1016/j.marpolbul.2012.10.010(2012).
52. Boulais,O.etal. FathomNet: Anunderwaterimagetrainingdatabaseforoceanexplorationanddiscovery. arXivpreprint
arXiv:2007.00114,doi:10.48550/arxiv.2007.00114(2020).
53. Katija,K.etal. FathomNet: Aglobalimagedatabaseforenablingartificialintelligenceintheocean. Sci.Reports12,
15914,doi:10.1038/s41598-022-19939-2(2022).
54. Chen, Q., Beijbom, O., Chan, S., Bouwmeester, J. & Kriegman, D. A new deep learning engine for
CoralNet. In 2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW), 3686–3695,
doi:10.1109/ICCVW54120.2021.00412(2021).
55. Orenstein,E.C.,Beijbom,O.,Peacock,E.E.&Sosik,H.M.WHOI-Plankton-Alargescalefinegrainedvisualrecognition
benchmarkdatasetforplanktonclassification. arXivpreprintarXiv:1510.00745,doi:10.48550/arxiv.1510.00745(2015).
56. Hong,J.,Fulton,M.&Sattar,J. TrashCan: Asemantically-segmenteddatasettowardsvisualdetectionofmarinedebris.
arXivpreprintarXiv:2007.08097,doi:10.48550/arxiv.2007.08097(2020).
57. Zhuang,P.,Wang,Y.&Qiao,Y. Wildfish: Alargebenchmarkforfishrecognitioninthewild. InProceedingsofthe26th
ACMInternationalConferenceonMultimedia,MM’18,1301–1309,doi:10.1145/3240508.3240616(Associationfor
ComputingMachinery,NewYork,NY,USA,2018).
58. Jian, M.etal. TheOUC-vision large-scaleunderwater imagedatabase. In 2017IEEEInternational Conference on
MultimediaandExpo(ICME),1297–1302,doi:10.1109/ICME.2017.8019324(2017).
59. Raphael,A.,Dubinsky,Z.,Iluz,D.,Benichou,J.I.&Netanyahu,N.S. Deepneuralnetworkrecognitionofshallowwater
coralsintheGulfofEilat(Aqaba). Sci.reports10,1–11,doi:10.1038/s41598-020-69201-w(2020).
60. Pedersen, M., BruslundHaurum, J., Gade, R.&Moeslund, T.B. Detectionofmarineanimalsinanewunderwater
datasetwithvaryingvisibility. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
Workshops,18–26(2019).
61. Beijbom,O.,Edmunds,P.J.,Kline,D.I.,Mitchell,B.G.&Kriegman,D. Automatedannotationofcoralreefsurveyim-
ages.In2012IEEEconferenceoncomputervisionandpatternrecognition,1170–1177,doi:10.1109/CVPR.2012.6247798
(IEEE,2012).
25/3062. Friedman,A. SQUIDLE+,Atoolformanaging,exploring&annotatingimages,video&large-scalemosaics. https:
//squidle.org/(2020). Accessed: 2023-04-03.
63. Langenkämper,D.,Zurowietz,M.,Schoening,T.&Nattkemper,T.W. BIIGLE2.0-Browsingandannotatinglarge
marineimagecollections. Front.Mar.Sci.4,doi:10.3389/fmars.2017.00083(2017).
64. Wilson,B.R.etal. MappingseafloorhabitatsintheBayofFundytoassessmegafaunalassemblagesassociatedwith
Modiolusmodiolusbeds. Estuarine,Coast.ShelfSci.252,107294,doi:10.1016/j.ecss.2021.107294(2021).
65. Lacharité, M., Brown, C. J. & Gazzola, V. Multisource multibeam backscatter data: Developing a strategy for the
production of benthic habitat maps using semi-automated seafloor classification methods. Mar. Geophys. Res. 39,
307–322,doi:10.1007/s11001-017-9331-6(2018).
66. Brown,C.J.,Beaudoin,J.,Brissette,M.&Gazzola,V. Multispectralmultibeamechosounderbackscatterasatoolfor
improvedseafloorcharacterization. Geosciences9,126,doi:10.3390/geosciences9030126(2019).
67. Mackin-McLaughlin,J.etal. Spatialdistributionofbenthicfloraandfaunaofcoastalplacentiabay,anecologically
and biologically significant area of the island of Newfoundland, Atlantic Canada. Front. Environ. Sci. 10, 999483,
doi:10.3389/fenvs.2022.999483(2022).
68. Nemani,S.etal. Amulti-scalefeatureselectionapproachforpredictingbenthicassemblages. Estuarine,Coast.ShelfSci.
108053,doi:10.1016/j.ecss.2022.108053(2022).
69. Misiuk,B.etal. Aspatiallyexplicitcomparisonofquantitativeandcategoricalmodellingapproachesformappingseabed
sedimentsusingrandomforest. Geosciences9,254,doi:10.3390/geosciences9060254(2019).
70. Menandro,P.S.etal.Theroleofbenthichabitatmappingforscienceandmanagers:Amulti-designapproachintheSouth-
eastBrazilianShelfafteramajorman-induceddisaster. Front.Mar.Sci.9,1004083,doi:10.3389/fmars.2022.1004083
(2022).
71. Menandro,P.S.,Misiuk,B.,Brown,C.J.&Bastos,A.C. Multispectralmultibeambackscatterresponseofheterogeneous
rhodolithbeds. Sci.Reports13,20220,doi:10.1038/s41598-023-46240-7(2023).
72. Todd, B. et al. Expedition report 2000-047: CCGS Hudson, southern Scotian Shelf. Tech. Rep. Open File 3911,
GeologicalSurveyofCanada(2001). doi:10.4095/212966.
73. Todd,B.etal. ExpeditionreportCCGSHudson2002-026: GulfofMaine. Tech.Rep.OpenFile1468,GeologicalSurvey
ofCanada(2003). doi:10.4095/214143.
74. Todd,B.etal. ExpeditionreportCCGSHudson2003-054: GermanBank,GulfofMaine. Tech.Rep.OpenFile4728,
GeologicalSurveyofCanada(2005). doi:10.4095/216676.
75. Tremblay, M. J., Smith, S. J., Todd, B. J., Clement, P. M. & McKeown, D. L. Associations of lobsters (Homarus
americanus)offsouthwesternNovaScotiawithbottomtypefromimagesandgeophysicalmaps. ICESJ.Mar.Sci.66,
2060–2067,doi:10.1093/icesjms/fsp178(2009).
76. Brown, C.J., Sameoto, J.A.&Smith, S.J. Multiplemethods, maps, andmanagementapplications: Purposemade
seafloormapsinsupportofoceanmanagement. J.SeaRes.72,1–13,doi:10.1016/j.seares.2012.04.009(2012).
77. O’Brien,J.,Wong,M.&Roethlisberger,B. BenthicimageryfromnearshoredropcamerasurveysalongEasternShore
(NovaScotia,Canada)tocharacterizeshallowsubtidalhabitats. MendeleyData,doi:10.17632/xfby2gf6kp.1(2022).
Availableathttps://data.mendeley.com/datasets/xfby2gf6kp/1.
78. Zajac,R.N.etal. Chapter10-Anintegratedseafloorhabitatmaptoinformmarinespatialplanningandmanagement: a
casestudyfromLongIslandSound(NorthwestAtlantic). InHarris,P.T.&Baker,E.(eds.)SeafloorGeomorphologyas
BenthicHabitat,199–217,doi:10.1016/B978-0-12-814960-7.00010-5(Elsevier,2020),2ndedn.
79. Lidz,B.H.&Zawada,D.G. PossiblereturnofAcroporacervicornisatPulaskiShoal,DryTortugasNationalPark,
Florida. J.Coast.Res.29,256–271,doi:10.2112/JCOASTRES-D-12-00078.1(2013).
80. Zawada,D.G.,Ruzicka,R.&Colella,M.A. Acomparisonbetweenboat-basedanddiver-basedmethodsforquantifying
coralbleaching. J.Exp.Mar.Biol.Ecol.467,39–44,doi:10.1016/j.jembe.2015.02.017(2015).
81. Post,A.,O’Brien,P.E.,Armand,L.K.&Carroll,A. SeafloorimageannotationsfromtheSabrinaupperslope,East
Antarctica,Ver.1. AustralianAntarcticDataCentreDataset,doi:10.26179/5caed60a7b076(2020).
82. Smith,J. HighresolutionstillphotographsoftheseaflooracrosstheMertzGlacierRegion,Ver.1. AustralianAntarctic
DataCentreDataset,doi:10.4225/15/59acda196ccfb(2017).
26/3083. Edgar, G. J. & Stuart-Smith, R. D. Systematic global assessment of reef fish communities by the Reef Life Survey
program. Sci.Data1,140007,doi:10.1038/sdata.2014.7(2014).
84. Edgar,G.J.etal. EstablishingtheecologicalbasisforconservationofshallowmarinelifeusingReefLifeSurvey. Biol.
Conserv.252,108855,doi:10.1016/j.biocon.2020.108855(2020).
85. Jordan,A.&Hedge,P. Marinebiodiversityhubimpactreport.synopsisofresearchimpacts2007–2020. Tech.Rep.,
DepartmentofAgriculture,WaterandtheEnvironment.Canberra,Australia(2020). https://www.nespmarine.edu.au/
system/files/Marine_Biodiversity_Hub_Impact_Report_FINAL_DEC2020.pdf.
86. Yamada,T.,Prügel-Bennett,A.&Thornton,B. Learningfeaturesfromgeoreferencedseafloorimagerywithlocation
guidedautoencoders. J.FieldRobotics38,52–67,doi:10.1002/rob.21961(2021).
87. Huber, R., Gordeev, E., Stocker, M., Balamurugan, A.&Schindler, U. pangaeapy-aPythonmoduletoaccessand
analysePANGAEAdata,doi:10.5281/zenodo.4013941(2020).
88. Roelfsema,C.M.,Kovacs,E.M.&Phinn,S.R. Georeferencedphotographsofbenthicphotoquadratsacquiredalong
160transectsdistributedover23reefsintheCairnstoCooktownregionoftheGreatBarrierReef,JanuaryandApril/May,
2017,doi:10.1594/PANGAEA.877578(2017).
89. Roelfsema,C.M.etal. HabitatmapstoenhancemonitoringandmanagementoftheGreatBarrierReef. CoralReefs39,
1039–1054,doi:10.1007/s00338-020-01929-3(2020).
90. Roelfsema,C.M.,Kovacs,E.M.,Stetner,D.&Phinn,S.R. Georeferencedbenthicphotoquadratscapturedannually
from2002-2017,distributedoverHeronReefflatandslopeareas,doi:10.1594/PANGAEA.894801(2018).
91. González-Rivero,M.etal. Scalingupecologicalmeasurementsofcoralreefsusingsemi-automatedfieldimagecollection
andanalysis. Remote.Sens.8,30,doi:10.3390/rs8010030(2016).
92. Jackett, C. et al. A benthic substrate classification method for seabed images using deep learning: Application to
managementofdeep-seacoralreefs. J.Appl.Ecol.60,1254–1273,doi:10.1111/1365-2664.14408(2023).
93. Piechaud,N.,Hunt,C.,Culverhouse,P.,Foster,N.&Howell,K. Automatedidentificationofbenthicepifaunawith
computervision. Mar.Ecol.Prog.Ser.615,15–30,doi:10.3354/meps12925(2019).
94. Diegues,A.,Pinto,J.,Ribeiro,P.,Frias,R.&Alegre,d.C. AutomaticHabitatMappingusingConvolutionalNeural
Networks. In2018IEEE/OESAutonomousUnderwaterVehicleWorkshop(AUV),1–6,doi:10.1109/AUV.2018.8729787
(IEEE,Porto,Portugal,2018).
95. Arosio,R.etal. Fullyconvolutionalneuralnetworksappliedtolarge-scalemarinemorphologymapping. Front.Mar.Sci.
10,1228867,doi:10.3389/fmars.2023.1228867(2023).
96. Ouali,Y.,Hudelot,C.&Tami,M. Anoverviewofdeepsemi-supervisedlearning. arXivpreprintarXiv:2006.05278,
doi:10.48550/arxiv.2006.05278(2020).
97. vanEngelen,J.E.&Hoos,H.H. Asurveyonsemi-supervisedlearning. Mach.Learn.109,373–440,doi:10.1007/s10994-
019-05855-6(2020).
98. Yang,X.,Song,Z.,King,I.&Xu,Z. Asurveyondeepsemi-supervisedlearning. IEEETransactionsonKnowl.Data
Eng.35,8934–8954,doi:10.1109/TKDE.2022.3220219(2023).
99. Huang,M.,Wang,Y.,Zou,W.&Cao,Y. Fastadaptiveself-supervisedunderwaterimageenhancement. In2022IEEE
InternationalConferenceonImageProcessing(ICIP),3371–3375,doi:10.1109/ICIP46576.2022.9897298(2022).
100. Zbontar,J.,Jing,L.,Misra,I.,LeCun,Y.&Deny,S. Barlowtwins: Self-supervisedlearningviaredundancyreduction.
InMeila,M.&Zhang,T.(eds.)Proceedingsofthe38thInternationalConferenceonMachineLearning(ICML),vol.
139ofProceedingsofMachineLearningResearch,12310–12320(PMLR,2021). https://proceedings.mlr.press/v139/
zbontar21a.html.
101. WoRMSEditorialBoard. Worldregisterofmarinespecies(WoRMS). https://www.marinespecies.org,doi:10.14284/170
(2024). Accessed: 2023-04-03.
102. Sayre, R. G. et al. A three-dimensional mapping of the ocean based on environmental data. Oceanography 30,
doi:10.5670/oceanog.2017.116(2017).
103. Locarnini, R.etal. WorldOceanAtlas2013, Volume1: Temperature. InLevitus, S.(ed.)NOAAAtlasNESDIS73
(UnitedStatesDepartmentofCommerce,2013). Mishonov,A.technicaled.
104. Zweng,M.etal. WorldOceanAtlas2013,Volume2: Salinity. InLevitus,S.(ed.)NOAAAtlasNESDIS74(UnitedStates
DepartmentofCommerce,2013). Mishonov,A.technicaled.
27/30105. Garcia, H. et al. World Ocean Atlas 2013, Volume 3: Dissolved oxygen, apparent oxygen utilization, and oxygen
saturation. InLevitus,S.(ed.)NOAAAtlasNESDIS75(UnitedStatesDepartmentofCommerce,2014). Mishonov,A.
technicaled.
106. Garcia,H.etal. WorldOceanAtlas2013,Volume4: Dissolvedinorganicnutrients(phosphate,nitrate,silicate). In
Levitus,S.(ed.)NOAAAtlasNESDIS76(UnitedStatesDepartmentofCommerce,2014). Mishonov,A.technicaled.
107. GEBCOCompilationGroup. GEBCO_2022Grid,doi:10.5285/e0f0bb80-ab44-2739-e053-6c86abc0289c(2022).
108. Chen,X.,Fan,H.,Girshick,R.B.&He,K. Improvedbaselineswithmomentumcontrastivelearning. arxivpreprint
arXiv:2003.04297,doi:10.48550/arXiv.2003.04297(2020).
109. Kingma,D.P.&Ba,J. Adam: Amethodforstochasticoptimization. InBengio,Y.&LeCun,Y.(eds.)3rdInternational
ConferenceonLearningRepresentations,ICLR,doi:10.48550/arxiv.1412.6980(2015).
110. Loshchilov, I. & Hutter, F. Fixing weight decay regularization in Adam. arXiv preprint arxiv:1711.05101,
doi:10.48550/arxiv.1711.05101(2017).
111. Smith,L.N. Adisciplinedapproachtoneuralnetworkhyper-parameters: Part1-learningrate,batchsize,momentum,
andweightdecay. arXivpreprintarXiv:1803.09820,doi:10.48550/arxiv.1803.09820(2018).
112. Paszke, A. et al. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neu-
ral Information Processing Systems 32, 8024–8035 (Curran Associates, Inc., 2019). http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf.
113. Xu,I.etal. Hierarchicalmulti-labelclassificationwithmissinginformationforbenthichabitatimagery. InInternational
JointConferenceonNeuralNetworks(IJCNN)(2024).
Acknowledgements
ThisresearchispartoftheOceanFrontierInstitute(OFI)BenthicEcosystemMappingandEngagement(BEcoME)Project.
DatawassourcedfromAustralia’sIntegratedMarineObservingSystem(IMOS)—IMOSisenabledbytheNational
CollaborativeResearchInfrastructureStrategy(NCRIS).Itisoperatedbyaconsortiumofinstitutionsasanunincorporated
jointventure,withtheUniversityofTasmaniaasLeadAgent.
We would would like to acknowledge the Australian National Research Program and the Australian Centre for Field
Robotics(ACFR)forgatheringimagedatathatwasusedaspartofthisproject.
WearegratefultothemanyReefLifeSurvey(RLS)diversaroundtheworldwhocontributedtodatathatwassourcedfor
thisproject.
NGUdatacollectionwasfundedpartlybyNGUandpartlybylocal/regionalcommunitiesinvariousMarineBaseMaps
projectsbetween2010and2017.
AlargenumberofimagessourcedfromSQUIDLE+werecollectedaspartoftheReefBuilderprogram2021–2023,ledby
TheNatureConservancyAustraliaandsupportedbytheAustralianGovernment.
ForthedatafromwesternCanada,wethankHakaiInstitutestaffNickVinerforcollectingandpreparingROVfootageand
KeithHolmes,DerekVanMaanan,CarolynKnapper,BenMillard-MartinandOndinePontierforsupportwithtowedvideo
collectionandanalysis. WealsothankcolleaguesatthePacificRimNationalParkReserve—JenniferYakimishyn,Caron
Olive,MikeCollyer,AngelaRehhorn,andSilvanaBotros—fortheirsupportinthecollectionandanalysisoftowedvideofor
seagrassmapping. ThedatacontributedbytheHakaiInstitutewascollectedwithinthetraditionalterritoriesoftheHaíëzaqv
(Heiltsuk)andWuikinuxkvFirstNationsontheCentralCoastofBritishColumbiaandtheTseshahtandnuucˇaan´uuëPath. nism´a
(Nuu-chah-nulth)NationsonthewestcoastofVancouverIsland.
ThankstoYanLiangTanandMollyWellsforcontributionstoCATAMIlabeltranslation.
ThisresearchwasenabledinpartbysupportprovidedbyACENETandtheDigitalResearchAllianceofCanada(alliance-
can.ca).
This research was enabled in part by support provided by the DeepSense computing platform. DeepSense is funded
by the Atlantic Canada Opportunities Agency (ACOA), the Province of Nova Scotia, the Centre for Ocean Ventures and
Entrepreneurship(COVE),IBMCanadaLtd.,andtheOceanFrontierInstitute(OFI).
Author contributions statement
S.C.L.andB.M.conceivedofanddesignedtheproject. S.C.L.,B.M.,andA.B.acquiredpubliclyavailabledatafromonline
repositories. S.C.L.,B.M.,andI.X.wrotetheinitialmanuscriptdraft. S.C.L.andB.M.designedthedatapartitioningscheme.
S.C.L. and I.X. designed and executed the data sub-sampling routine. S.C.L., B.M., I.X., S.A., and K.M. contributed to
28/30CATAMIlabeltranslation. I.X.conductedthemodelling. C.J.B.andT.T.supervisedtheproject;andK.R.,C.J.B.,andT.T.
acquiredfundingtosupportit. S.C.L.,B.M.,A.C.B.,M.B.,V.F.,A.F.,D.H.,D.I.,J.M.-M.,K.M.,P.S.M.,J.M.,S.N.,J.O.,
E.O.,L.Y.R.,K.R.,C.M.R.,J.A.S.,A.C.G.S.,J.A.T.,B.R.W.,M.C.W.,C.J.B.contributeddatathatwasusedtoestablishthe
BenthicNetdatacompilationandmodels. S.C.L.,B.M.,I.X.,A.C.B.,M.B.,V.F.,A.F.,D.H.,D.I.,J.M.-M.,K.M.,P.S.M.,
J.M.,S.N.,J.O.,E.O.,L.Y.R.,K.R.,C.M.R.,J.A.S.,A.C.G.S.,J.A.T.,B.R.W.,M.C.W.,C.J.B.,T.T.contributedtoeditingand
revisionoftheinitialdraft. Allauthorsreviewedthemanuscript.
Competing interests
Theauthorsdeclarenocompetinginterests.
A PANGAEA Search
TothoroughlysearchPANGAEAforseafloorimagery,weused20searchtermswitharangeofsynonymsforthecontentof
interest. ThePANGAEAsearchAPIiscomprehensiveandallowstermsbecombinedwithANDorORoperators,andnegative
searchtermstobeused. However,wecouldnotmergealloursynonymstogetherintoasingle,largequerybecausethenumber
ofresultswhichcanbereturnedbyonequeryislimitedto500records.
Thesearchtermsusedwereasfollows:
(seabed OR "sea bed" OR "sea-bed") (image OR imagery OR photo OR photograph
OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif
OR tiff)
(seafloor OR "sea floor" OR "sea-floor") (image OR imagery OR photo OR photograph
OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif
OR tiff)
("ocean floor" OR "ocean-floor") (image OR imagery OR photo OR photograph
OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif
OR tiff)
underwater (habitat* OR substrate OR sediment) (image OR imagery OR photo
OR photograph OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg
OR png OR tif OR tiff)
benthic (image OR imagery OR photo OR photograph OR "photo-transect" OR photoquad*
OR photo-quad* OR jpg OR jpeg OR png OR tif OR tiff)
(benthos or benthoz) (image OR imagery OR photo OR photograph OR "photo-transect"
OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif OR tiff)
(coral OR reef OR seagrass OR "sea grass") (image OR imagery OR photo OR photograph
OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif
OR tiff)
(auv OR rov OR uuv OR "underwater vehicle") (image OR imagery OR photo OR photograph
OR "photo-transect" OR photoquad* OR photo-quad* OR jpg OR jpeg OR png OR tif
OR tiff)
benthoscape habitat* image
benthoscape habitat* imagery
benthoscape habitat* photo
benthoscape habitat* photograph
benthoscape habitat* ("photo-transect" OR photoquad* OR photo-quad*)
benthoscape habitat* (jpg OR jpeg OR png OR tif OR tiff)
benthoscape image
benthoscape imagery
benthoscape photo
benthoscape photograph
benthoscape ("photo-transect" OR photoquad* OR photo-quad*)
benthoscape (jpg OR jpeg OR png OR tif OR tiff)
Eachsearchtermwasprefixedwithasetofnegativesearchtermstoremovefalsepositives,givenasfollows
-microscop? -"Meteorological observations" -topsoil -soil -sky
-"wind vector" -"wind stress" -"vertical profile" -"vertical distribution"
29/30ThecodeforourPANGAEAsearchispubliclyavailableathttps://github.com/DalhousieAI/pangaea-downloader.
B Repository Dataset Details
SeeAppendixBdocument.
C FathomNet Python API Code
import fathomnet.api.images
import pandas as pd
keys = ["url", "uuid", "timestamp", "latitude", "longitude",
"oxygenMlL", "pressureDbar", "salinity", "temperatureCelsius"]
records = []
for submitter in fathomnet.api.images.find_distinct_submitter():
for image in fathomnet.api.images.find_by_contributors_email(submitter):
records.append({k: getattr(image, k) for k in keys})
df = pd.DataFrame.from_records(records)
df.drop_duplicates(subset="url", inplace=True)
30/30