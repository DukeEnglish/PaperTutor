Title: CARE-SD: Classifier-basedanalysis for recognizingand eliminatingstigmatizingand
doubt markerlabels inelectronic healthrecords:model developmentandvalidation
Corresponding Author:
Drew Walker
Decatur GA
andrew.walker@emory.edu
Authors:
Drew Walker,(1 and2), Annie Thorne(3), Sudeshna Das(4), JenniferLove(5),HannahLF
Cooper,(1), MelvinLivingston III (1), AbeedSarker (4and6)
Affiliations:
1.Department of Behavioral, Social,Health Education Sciences,Rollins SchoolofPublic
Health, Emory University, AtlantaGA,USA
2.Department of Pediatrics,College ofMedicine, Universityof Florida, Gainesville, FL,USA
3.Department of Infectious Disease,Children’sHealthcareof Atlanta,AtlantaGA,USA
4.Department of Biomedical Informatics,SchoolofMedicine, EmoryUniversity, AtlantaGA,
USA
5. Department of EmergencyMedicine, MountSinai, New York, NY,USA
6.Department of Biomedical Engineering,Georgia InstituteofTechnology andEmory
University,Atlanta,GA,USA
KeyWords: stigma,electronic healthrecord,text classification,natural languageprocessing
Dr.Walker’swork wassupported byNIDA T32Grant (T32DA0505552)and DrsDasand
Sarker’sworkwas supported byNIDAR01 Grant Funding (R01DA057599)Abstract
Objective: Todetectand classify featuresof stigmatizingandbiasedlanguageinintensive care
electronic healthrecords(EHRs)using naturallanguageprocessing techniques. Materialsand
Methods:Wefirst createdalexiconand regularexpression listsfrom literature-drivenstem
wordsfor linguistic features ofstigmatizingpatient labels,doubtmarkers,andscare quotes
within EHRs. Thelexicon wasfurther extendedusing Word2VecandGPT3.5,and refined
through humanevaluation. Theselexicons wereused tosearch for matchesacross 18million
sentences fromthede-identifiedMedical InformationMart for IntensiveCare-III (MIMIC-III)
dataset.For eachlinguisticbias feature,1000sentence matcheswere sampled,labeledbyexpert
clinical andpublic healthannotators, andusedto supervisedlearning classifiers.Results:
Lexicondevelopmentfromexpanded literature stem-word listsresulted inadoubtmarker
lexiconcontaining 58expressions,and astigmatizinglabelslexiconcontaining 127expressions.
Classifiersfor doubt markers andstigmatizinglabels hadthehighestperformance, withmacro
F -scores of .84and.79,positive-label recall andprecision valuesrangingfrom.71to.86,and
1
accuraciesaligningclosely withhuman annotatoragreement(.87). Discussion:Thisstudy
demonstrated thefeasibilityof supervised classifiersinautomatically identifyingstigmatizing
labels anddoubt markersinmedical text,and identifiedtrendsinstigmatizinglanguageuse inan
EHRsetting. Additionallabeled datamay helpimprove lowerscare quotemodel performance.
Conclusions: Classifiersdevelopedin thisstudy showedhighmodel performance andcan be
appliedto identify patterns andtargetinterventionsto reducestigmatizinglabelsand doubt
markersin healthcaresystems.
BACKGROUND ANDSIGNIFICANCE
Provider biasesand stigmatization ofpatientsdrive healthcareinequities
Provider stigmasandbiasesarewidely believedtocontribute todiscrimination andhealth
inequities amongpatients.1,2Patientsregularlyexperiencestigmaandbiases byprovidersas a
resultof their race,gender,sexualorientation,disease status,druguse, andsocioeconomicstatus,
or otherlabeled characteristics identifiedbyproviderteams.3Currentapproaches toreducing
provider stigmatization oftenstruggle withlimited effectover time,withdifficulties in
establishingongoing accountability toensurelong-term behavioral change.3Theabilityto
identify potentialinstances ofpatient stigmatizationwithin theelectronic healthrecord(EHR)
couldhelpto inform andtargetfuture interventionsandfacilitate real-time auditsofhealthcare
teamcommunication.
Stigmadefined
Stigmahasbeendefinedbysocialpsychologists Link andPhelan asa socialprocessthat
ischaracterized bytheinterplayof labeling,stereotypingandseparation,whichleadsto status
loss anddiscrimination, andimportantly, occurswithin acontextofpower,such asthat of the
patient-provider relationship.4Borrowing fromLink andPhelan, linguisticbias has beendefined
as“asystematic asymmetryin wordchoiceasa functionofthe socialcategory towhichthe
target belongs”.5Althoughtherearea varietyof waysinwhichlinguistic bias canmanifest,6they
all facilitatethetransmission of“essentialistbeliefs aboutsocial categories”,resulting inthe
separationand stigmatizationof others.Linguistic manifestations ofstigmatization
Beukeboom andBurgersrecently developedaframeworkto understandhow
stigmatization canmanifestand beformedthrough language,via theSocial Categoriesand
StereotypeCommunication Framework.7Thisframeworkpositsthat stereotypesare
communicatedthrough systematicdifferences inhow othergroups are1)labeled,and 2)how
their behaviorsandcharacteristicsaredescribed. Recentresearch investigatinglinguisticbias in
theEHRhasidentifiedsalient featuresofbias within thelanguageof providernotes, namely
focused ontheusageof stigmatizinglabels, negativedescriptors,as wellas theexpression of
doubt inpatient testimonythrough linguistic doubtmarkersand“scare quotes”.8–10
Stigmatizing labels
Stigmatizing labelstodescribe groups areoftenusedto perpetuatestereotypes,andwhen
usedbyproviders, canlead tofeelings ofstigmatization andreducedtrust amongtheirpatients.
Arecent NIDAstudypublished alistofwords toavoid usingaround patientswith substanceuse
disorders,including"addict","abuser","user",or "junkie", whichhavebeen foundto be
associatedwith perceivedstigmatization bypatients.11Similar studieshavebeen appliedtoother
chronic illnesspopulations,identifying termslike “sickler”or “frequentflier”whichmay be
usedto further stigmatizepatients withchronicillnesseswho areoftenadmittedinto thehospital.
9,12Whilesomeproviders mayargue that thesetermsmay beusefulin flaggingunwantedpatient
behaviorsor mental states, arecent studyhas shownthatpatients exposed tolanguagewritten
aboutthem byproviderswhichincludedstigmatizing labelsresulted inpatientsfeeling unfairly
judged,labeled, anddisrespected.13Recentresearchled byMichaelSun andcolleagues onover
40,000clinical noteshasfound disparitiesinpresence of “NegativeDescriptor”words, which
includedcommonlyusedtermsinthe EHRsuchas “(non-)adherent,aggressive,agitated, angry,
challenging,combative,(non-)compliant, confront, (non-)cooperative,defensive, exaggerate,
hysterical, (un-)pleasant,refuse,andresist”.Research intostereotypeexpression inlanguagehas
found that evenseeminglyinnocuous category labelsmayprompt others toperceive target
individual actionsand characteristics as“static”aspects oftheir identity,andexaggerate
differences acrossgroupsandsimilarities withinthem.5
DoubtMarkers
Linguistic features suchas evidentials,definedas“the linguistic codingof
epistemology”,14arewords thatarefrequentlyused inchartlanguageto questiontheveracity of
patients.Amongthemany wordsused asevidentials,words andexpressionsusedto conferdoubt
or uncertaintysuchas: allegedly,apparently,orverbslike claimed,areoftenusedtowhen
describing patienttestimonies,for example: “patientclaimed theirpain was10/10”.15Providers
mayusewordswhendescribingpatient testimonyincombination withstigmatizinglabels or
negative descriptorsof patients totransmittheirstance, orexpression ofattitudes, feelings, and
judgmentaboutpatientstootherproviders whichmay impactfuture treatmentandcare
decisions.16Inequitieshavebeen foundamong usageof thesetermsacross raceandgender,
where patientswhowere womenandpatients who wereBlack werefound tohave significantly
higherfrequenciesof evidentialsintheir providernotes thanpatients who weremen orWhite.15
ScareQuotes
Another linguistic markerof uncertaintythat hasbeen previouslyidentifiedinpatient
chartsare“scare quotes”,which involvethe utilizationofquotationmarks tomock,castdoubt,challengepatient credibility, orinsinuate lowhealthliteracywhendescribing thetestimony of
another individual.15While quotationsincharts canbeuseful todescribe patientsymptomsusing
their exactlanguageanddocument patientwishes orconcerns, recentlinguistic researchhas
identifieda troublingprevalence ofproviders utilizingquotations inwaystomock, manipulate,
and regulatethevoicesof patients. Forexample,consider theambiguityadded tothe sentence:
“Patient reports10/10 pain related tosicklecellcrisis.”,whenyouadd“Patient reports‘10/10’
painrelated to‘sickle cellcrisis’. Becauseof thequotationmarks, both10/10andsickle cell
crisis couldbeinferred asbeing untrueoruncertain. Similar toevidentialsandnegativepatient
descriptors,scarequotes havebeen foundto bemoreprevalent amongpatients whowere Black
and amongpatientswhowere women.8,15
Natural Language Processing toidentifystigma andbias in EHRData
Whilelinguistic studieshave actedtoguideresearchers intoidentifying manifestationsof
stigma andbias intext, due tothenature ofqualitative,in-depthassessments, thesemethodscan
havesignificant limitationsinbeing able tobedeployed torapidlyidentify stigmaandbias in
medicalnotes ina wayinwhichwecan intervene onit.Recent advancesincomputational
linguisticsareallowing researcherstoharness human-annotatedinsightsonlinguistic bias and
stigma andscale upcategorization tolargeramountsof unlabeleddata.
This paperaimsto applyadvancedmethodsinnatural languageprocessing todetectand
assessthepresence of stigmatizing andbiasedlanguageinthe EHRfor patientswithin theICU.
This studyextendsqualitative andNLPmethodsto detectproviderstigma biasin EHRinan
effort toincreasetheaccountability, evaluation,andinterventionof negativebias that threatensto
deteriorate qualityof care for patientsamong avarietyof uniquely stigmatizedgroups. Building
from otherresearchin linguistic stigmaandbias inmedical charts,this studyrepresents the
developmentof themost comprehensive, automatedclassificationsystem for doubtmarkersand
stigmatizing labels,applied onthelargest corpusofde-identified EHRstodate.17Doubtmarker
and stigmatizinglabellexicons, aswell asclassification models,areavailablefor others toutilize
this pipelineto identify stigmatizinglanguageinEHR.18
METHODS
Our methodsfor identifyingsentences withinthe MIMIC-III EHRdatasetcontaining
doubt markers,stigmatizing labels,andscare quoteswithin providernotes consisted ofthree
steps:
1) Lexicondevelopment andsamplepreparation
2) Sentence-levelannotation,and
3) Supervised classificationusing bag-of-wordsandtransformer-basedmodels
MIMIC-IIIDataset
TheMedicalInformation Martfor Intensive Care, or“MIMIC-III”, isafreely-availabledatabase
of comprehensive, de-identified EHR,free-textnotes, andevent documentation for over 40,000
patientsadmittedto theICU atBethIsraelDeaconessMedical Center inBoston,MAfrom2001
to 2012.19 Thisdatasetcontainsover 1.2millionclinical provider notes,across nearly50,000
admissions. Becausethis dataset containsfreely-available,EHRfromICU providers froma
diverserangeof conditionsand ageranges,it isa valuableresourcefor developingbias and
stigma detectionalgorithms inprovider language,particularlyfor patients living withchronic
illnesseswho maybemore likelytobeadmitted tocriticalcareunits.20Lexicondevelopment and samplepreparation
Thelexicondevelopment processfor doubtmarkersand stigmatizingpatientlabelsbegan
with astem-word listdescribingwords previouslyidentifiedas demarcatingdoubtor
perpetuatingstigmatizing patient labelswithinmedical charts.We expanded expandedthese
word liststo includemisspellingsor wordswithhigh semanticsimilarity andrelevanceinthe
domain byusingtwosubsequent techniques:1) BioWordVec,awordembeddings modeltrained
onmedicaltext, whichgeneratedthe top10most semanticallysimilar words for each stem
word,21,22and 2) GPT3.5,whichsuggested anadditional25words andspellingdeviations for
each lexicon,following chain-of-thought promptingrelated toeach linguisticbias feature.23
Following thefirstround of expansion,wemanuallyvalidatedthe listofgenerated words for
task relevance,andassessed humanannotation interraterreliabilityonwhethereach wordwas
relevant toeach specificbias feature.Afterthesecond round ofGPT3.5expansions, weassessed
10-20 sample matchesfrom thehighesttop-frequency terms’toremoveanyextremely
high-frequencyword matchesfrom thelexiconwhichwere notrelated totransmission of
stigmatizing labelsor doubtmarkersand couldhave significantimpactonthe annotationsample.
This iterativeprocess,reliant onexpert-driven inquiry,and complementedbyunsupervised,
supervised, andtransferlearningmethods,reflects thestrategies championedby computational
grounded theoryframework, andensures ourresults areinformed andvalidatedbyhuman
domain experts.24Ouranalyticpipelineis outlinedinFigure 1,withintermediary results
described inAppendix 1.
Figure1: Natural language processing analytic pipelinefor lexicon development,regular
expression matching, annotation,and classifiermodel training for stigmatizinglinguistic
featuresin MIMIC-III.Stigmatizing labels
Stigmatizing label lexicondevelopmentwas guidedbyliterature onstigmatizing
languagein medicalcare,specifically fromthe NIDA“Words Matter”publication,Sun’s
“Negative Patient Descriptors: DocumentingRacial Biasinthe ElectronicHealth Record”, as
wellasZestcott’s “Health CareProviders’ NegativeImplicit Attitudes andStereotypes of
AmericanIndians”.11,25,26The initialstemwordlistconsisted of18words:
"abuser","junkie","alcoholic", "drunk","drug-seeking","nonadherent", "agitated","angry",
"combative","noncompliant","confront", "noncooperative","defensive","hysterical",
"unpleasant","refuse","frequent-flyer","reluctant".
Doubtmarkers
Doubtmarker lexicon developmentwas guidedbyliterature onuseof “doubtmarkers” in
medicalcare, specificallyledbyBeachand colleagues,which identifiedwordssuch as“claims”,
“insists”,and “adamant”or “apparently”,whichhave beenfound tobeused todiscreditor
invalidate patienttestimony.The6words includedontheinitial stemlistwere:"adamant",
"claimed","insists","allegedly","disbelieves","dubious".
Scarequotes
Scarequotesample preparationwascreated bysearching theMIMIC-III notes using
regular expression((?=.*\".*\")(?=.*\b(pt|patient|pateint|he|she|they)\b)) whichcaught matching
closedquotes, andreferencestopatients by“patient” derivationsandpronouns, inordertomore
accurately capturequoteswith patientattributions.Finally, several wordswere addedto filter
rows,where matcheswithquoted wordswere commonlyreferring toanswersfor “alert and
oriented” examinations-- i.e.“Patient Name”,“Hospital”, “Year”,etc.
Matching withsentences in MIMIC-III, creatingcoding samples
Expanded lexicons orregular expression for eachlinguistic bias featurewere usedto
filter through patientfree-text clinical notes,which hadbeentokenized atthe sentencelevelto
allowfor easier readability andclassificationfeasibility.All duplicatesentences were removed
from thedataset,andchartslabeledas EEGor Radiologywere removedinorderto restrictto
chartsmorelikelyto havesubjective narrativeand patienthistorytext data, suchas progress
notes, historyand prognosis notes,and dischargesummaries.Each linguisticfeaturedataset was
randomly sampledin non-replacement groups of100(for double-coderreliabilityscores),400
(codedbyAT, aPhysician’s Assistant),and500(codedbyDW,abehavioral data scientist).
Annotation process
Coding ontologiesfor each ofthe 3linguistic biasfeatures weredevelopedoriginally by
DW,theniteratedonduringthe first roundof reliabilitycoding. Theoriginalontologieswere
inspiredbyresearch ledbyBeach, Park,andGoddu onthe roleofstigmatizinglanguagein
patient charts.9,15,27Qualitative annotatorsmet once todiscusseach ofthe threecoding ontologies
and guiding theories,aswell asco-code5sentence examplesfrom eachlinguistic bias dataset.
Following thefirstmeeting, each codercompletedthe samesetof 100sentences for eachof the
linguistic biasfeaturedatasets.After inter-raterreliabilitywas assessed,the codersmet todiscuss
disagreements andsentences markedas “closecalls”,or difficult labelingdecisions, and“exemplary” sentences,whichwere particularly obviousexamples toreview. Afterall
disagreements wereadjudicatedbythe coders,they solo-coded400(AT) and500(DW)
sentences tocompletethe1000samples for eachlinguistic bias feature.
Sentence Classification
Theannotation datawasused totrainsupervised modelsfor the binaryclassificationtask
of identifying sentenceswhichdo,or donotcontaineach ofthe linguistic biasfeatures. This
supervised learningtaskwascarriedout usingfour models:Naive Bayes,LogisticRegression,
RandomForest,aswellas thestate-of-the-art transformer-basedRoBERTa model.28Sentences
from clinicalnotes weretokenized into1-2 wordunigrams andbigrams
A gridsearchapproachwas usedfor hyperparameteroptimizationfor thesemodels,using
thetraining data set,which wassplitat 80/20%.For NaiveBayes,Logistic Regression, and
RandomForest,weutilized astratified k-fold,with5splits,in ordertocreate trainingand test
setswhich preservedthepercentage ofsamples for each class.
Following modeltraining, eachmodel wasevaluated onaheld-out20% ofthe data, in
which weprioritized theperformancemetricsof 1)positive-classprecision, 2)positive-class
recall, and3) macro F -score toselect thehighest-performing model ofeach model type.
1
Hyperparametervaluesfor each ofthe best-performingmodelsfor each linguistic featureare
available inAppendix 2-4. Positive-class precision,or theproportion oftruepositives divided
bythetotalnumberof positivepredictions,was prioritizedtoreduce falsepositives anddevelop
modelshighly likelyto identifyactual stigmatizinglanguage.Recall, orthe proportionof alltrue
positiveslabeled correctly, wasprioritized toensureour classifiercanidentify asmany truecases
of stigmatization aspossible.F scores, orthe harmonicmeansof recall andprecision, providea
1
measure of balancebetweenthe twoperformance metricsfor eachmodel across bothpositive
and negativeclass labels.We appliedbootstrappingto modelevaluation byassessing prediction
and ground-truth labelsof 1000samples, generatedwithout replacement.Theperformance
metricsof F ,precision,accuracy,recall were aggregatedto calculatetheconfidence intervalsof
1
all modelmetrics.
Finally,weassessedbest-performing model textfeatureimportanceand featurelogistic
regression coefficientsin order toevaluatethe degreetowhich certainmatched termsand
phrasescontribute tothelinguistic bias labelpredictionsofthe models.Featureimportancewas
assessed usingGiniimportance meanimpurity reductionmethod for decisiontrees inthe random
forest classifiers,and regression coefficientswere calculatedfromthe logisticregression
classifiers.29–31Codefor allanalyses for this studyareavailable onGitHub:
https://github.com/drew-walkerr/Diss_Detecting_Provider_Bias.
RESULTS
LexiconDevelopment
For thestigmatizinglabelslexiconexpansionand annotatorpruning, theinitial listof18
was expandedto 180,which wasthenassessed byannotators DWandSD, removing83terms
(Annotator agreement= 75%).Final decisionswere adjudicated byDW.Thefinalexpanded and
pruned listof stigmatizing labelsusedto searchthe MIMIC-III datasettotaled127words, andis
providedin Appendix1.Following assessmentsof most frequentterm matches,weremovedthe
following termsdue tohighproportion ofnoise referring toillness characteristicsorclinical
situations, ratherthanpatients orpatienttestimonies: 'difficult','suspicious','aggressive','unstable',
'dramatic','unreliable','entitled','invalid','violent', 'dangerous'.For thedoubtmarkerslexiconexpansionandannotator pruning, theinitial listof6terms
was expandedto 60,which wasthenpruned byannotators toremove2terms (Annotator
agreement= 80%). Thefinalexpanded listofdoubt markersusedtosearch theMIMIC-III
datasettotaled 58words,and isprovidedinAppendix 1.Followingregular expressionsearching
and assessmentsof mostfrequent termmatches, weremovedthefollowing terms duetohigh
proportion of noise referring touncertaintyinillness orclinical presentations,rather than patient
testimonies:'suspicion', 'suspicious','questionable', 'questioning','uncertain', 'hesitancy',
'hesitant','unsure'.
Figure1: Network Diagram showingdoubt markerstem words(green,also includesGPT
3.5) to show expansionsof initialstemwordsto expandedlexicon words(purple)Regular ExpressionSearchresults
Results describing thetext data ofthe preprocessedMIMIC-III full sample,as wellas of
searchresults for eachof thestigmatizinglabels, doubtmarkers,andscare quotesregular
expression (regex)matcheddata framesaresummarizedinTable 1.
Table 1: Summarystatisticsof MIMIC-IIIDataset,comparedwith linguisticbiascorpa
MIMIC-III Stigmatizing DoubtMarker ScareQuotes
Sample LabelCorpus Corpus Corpus
Number of 814,548notes 8,950notes 3,682notes 4,806notes
uniquenotes
Avg notelength 654words 623words 937words 763words
Number of total 18,288,213 10,278sentences 3,856sentences 5,156sentences
sentences sentences
Average 12words 48words 35words 55words
sentencelength
Number of 11,633patients 3,483patients 2,368patients 2,830patients
patients
Number of 1,879providers 1,056providers 800providers 677providers
providers
Themost frequent matchingtermsfrom ourlexicon,along withthemost commonly
occurring trigramswithin quotedtext, areprovidedfor each ofthe 3biasfeatures inFigure 2.
For stigmatizinglabels, versionsof ‘refusing’ and‘refuses’were byfarthemost frequently
matched terms.In thedoubtmarker labellexicon,‘believes’was themost frequently matched
term, followedbyinsisted andinsisting. Scarequotequoted textfrequent words, bigrams,and
trigrams werelessledbyany particularphrases orwords, butwere mostlyuseddescribing
patient chiefcomplaints, descriptions ofsymptomsor condition.Figure2: Top 20Matched TermsStigmatizing Labels,Doubt Markers,and ScareQuotesAnnotation
Annotation codingontologies, detailingthe labelinginstructionsfor each ofthe three
linguistic biasfeatures, were informedlargely throughthe literature-basedstemword
operationalizationsof each set oflinguistic bias features.Appendices1-3detail thecoding
ontologies for eachcorpus.Table 2providesthe interrateragreementandkappascore for thefirst
100samplesof each linguistic feature,andpositiveclassfrequency inthe final1000sentence
sample.
Table 2: Annotationsample reliability,linguistic biasfeaturespositive classfrequencies,
and notable examples
BiasFeature Agreement Interrater Frequency in final
reliability (Kappa) sample
(N=1000)
Stigmatizing
Labels 87% .74 43.9%
Doubt Markers
87% .73 31.0%
ScareQuotes
87% .73 20.7%Table 3providesnotablepositiveclass examplesfor each ofthe 3linguistic features.
Table 3: Notable annotationexamples forstigmatizing labels, doubtmarkers, andscare
quotes
BiasFeature Notable Sentence Examples
(Flaggedascontaining biased feature,matchingor quotedtext underlined)
Stigmatizing Pt very uncooperative,willbarely allowanynursingcare.
Labels
Neuro: Isvery needy,needs tobeincouraged todomorefor herself.
Refusesblood draws,callingout, askingfor dilaudiddespite mednotbeing
due, requiringmuchemotionalsupport.
Doubt “Paincontrol (acutepain,chronicpain)Assessment:Pt has chronicabdpain
Markers constantlyclaimingpainscale 10.”
“Hislastdrink of alcoholwassupposedlythreeweeks ago.”
Insisting onmakingphone callsbecomesvery irritated ifdon't jumpto his
requests.
Scare Easily frustrated,especially whenaskedquestions toassessorientation...pt
Quotes states"youhavealreadyaskedme this 100times".
NOnausea/vomiting although ptstateshe doesnotwant toeat becausehe
"fears"beingnauseated.
At10:06, ptput oncalllight torequest"pain pill" andthenput onthecall
light 5moretimesover thenext 8minutestomake samedemand, atone
point saying tothenurserespondingto thecalllight, "What thehell isgoing
on."
Linguistic BiasClassifier ModelEvaluation Results
Table 4displaysthe resultsof thebest performingmodelsacross types andlinguistic bias
features. Acompletelistof the bestperforming modelhyperparameters canbe foundin
Appendix 5.Wewereableto achievethehighestperformance ondoubtmarkersand stigmatizing
labels, withscarequotemodels underperforming otherlinguisticbias modelsacross nearlyevery
evaluationmetric.
Thebest performingmodel typefor doubt markersandscarequotes wasRoBERTa, with
LogisticRegression achieving thebest performance inclassifyingstigmatizinglabelsentences.Runduration wasmuchhigher for RoBERTamodels,as comparedwith RandomForest,Logistic
Regression, andNaiveBayesclassifiers.
Table 4: LinguisticBiasClassifierModel Performance(best modelof eachfeaturein bold)
BiasFeature Model Accuracy Precision Recall F1(Positive) Macro Macro MacroF1 Run
(Positive) (Positive) Precision Recall Duration
Stigmatizing RoBERTa .69(.63,.76) .63(.54,.72) .75(.67,.84) .69(.62,.76) .70(.64,.76) .70(.64,.76) .69(.63,.75) 484.1s
Labels
Random .79(.73,.84) .77(.68,.86) .73(.63,.82) .75(.67,.82) .77(.68,.86) .73(.63,.82) .75(.67,.82) 148.4s
Forest
Logistic .81(.75,.86) .75(.66,.85) .84(.75,.91) .79(.72,.86) .75(,66,.84) .84(.75,.91) .79(.72,.86) 3.2s
Regression
Naive .71(.64,.77) .62(.53,.70) .86(.79,.93) .72(.64,.78) .62(.53,.70) .86(.79,.93) .72(.64,.78) 0.1s
Bayes
Doubt RoBERTa .86(.81,.91) .86(.75,.96) .71(.59,.81) .77(.69,.85) .86(.80,.91) .82(.76,.88) .84(.78,.88) 790.72s
Markers
Random .85(.80,.89) .76(.64,.86) .76(.65,.85) .76(.67,.84) .76(.64,.86) .76(.65,.85) .76(.67,.84) 18.0s
Forest
Logistic .85(.80,.90) .71(.61,.81) .89(.80,.96) .78(.69,.85) .70(.60,.80) .88(.80,.96) .78(.69,.85) 2.4s
Regression
Naive .85(.80,.89) .70(.60,.80) .89(.80,.96) .78(.69,.85) .70(.60,.80) .89(.80,.96) .78(.69,.85) 0.1s
Bayes
ScareQuotes RoBERTa .75(.69,.81) .40(.24,.58) .30(.17,.45) .35(.20,.48) .61(.52,.70) .59(.52,.67) .62(.52,.70) 810.0s
Random .79(.74,.85) 0.00(0,0) 0.00(0,0) 0.00(0,0) 0.00(0,0) 0.00(0,0) 0.00(0,0) 148.9s
Forest
Logistic .77(.71,.82) .30(.07,.56) .10(.02,.20) .14(.04,.28) .30(.07,.56) .10(.02,.20) .14(.04,.28) 1.7s
Regression
Naive .78(.72,.83) .43(.22,.63) .24(.12,.38) .31(.16,.45) .43(.22,.63) .24(.12,.38) .31(.16,.45) 0.1s
Bayes
After modelevaluation,we alsoran featureimportanceandcontribution plots usingthe models
of thebest performingrandomforest andlogistic regressionmodels.Figure 3highlightstermsor
phrasesthat areparticularlyinformative torandomforest modelsduringcategorization (left-hand
side), andtheright-hand side displaystheterms withthe highestregressioncoefficients (negative
and positive),which aremorelikelyto belabeledas negative(blue,unbiased),or positive(red,
biased/stigmatizing).
Figure3: Top 30Stigmatizing Label Tokensby Importanceand FeatureContributionsDISCUSSION
This studydemonstratedthe viabilityof scalinguppreviousresearchonstigma in
languageto developtools that canbeappliedto identifyingstigmatizing textin theEHR.Our
suiteof tools, comprisinglexiconsand refinedsupervised classificationmodels,titled
“CARE-SD 1.0:Classifier-basedAnalysisfor Recognizing andEliminating Stigmatizing and
DoubtMarker Labelsin Electronic HealthRecords”areavailable onGitHubfor other
researchers inthis spaceseekingto reproduceor adapt ourstudy process.
For thetaskof lexicondevelopment, ourexpanded wordlistssuccessfully produced
termsthat frequently matched withsentences whichwere eventuallylabeledas stigmatizingor
doubt-marking bycoders.These lexiconsarevaluabletools for researchersseekingto focuson
EHRsentences witha higherfrequency of stigmatizingordoubt markingsignals.Thisprocess
canbe adaptedtoexpandsearches for wordsrelated toavariety ofconcepts withinstigmaand
othersociolinguisticphenomena.Supervised learning classifiersfor stigmatizinglabels anddoubtmarkersdemonstrated
near-humanagreementperformance. Webelievethat thesetools, trainedonICU data amonga
largecohortof patients,will beapplicable tootherEHRsettingsor datasets sincethelinguistic
markersarelikelyto besemanticallysimilar.
Several patternsinstigmatizing labelanddoubtmarker usearose thatmay helpinform
clinical practice.Amongstigmatizinglabels,the useof “needy”waspredictiveof positive
stigmatizing labels.“Needy”was oftenusedtodescribe aninherent trait,which ishighly
problematic for anyoneseeking careinthe ICU. Otherproviders may wrongfullyassumethe
patient is“needy”inothercontexts,includingpain management, dailyactivity assistance,or any
othergenuine healthcomplaint.“Noncompliant”,aword identifiedintheexpanded stigmatizing
labels lexicon,waslabeled asstigmatizing chieflywhenit wasusedto definethepatient directly
assuchand notwhendescribinga specificbehaviororwhenproviding morecontext(i.e.due to
lack of funds).Labeling patients as“noncompliant”has beenhotly debated,thoughrecent
EHR-related NLPwork isincreasingly operationalizingits use asonethat has negative
connotations,and pointsblame atthe patient,rather thanstructural factorswhichmayhave
stronger impactsandconstraints onpatienthealth.17,25
Weencountered many usagesof“refusing” amongstigmatizinglabelcharts. Weaimed
to negatively label(unbiased) whenproviders werespecificabout thebehavior andcontextin
which thepatientwas refusingaspecifictreatment, orwhenthe contextwassurrounding
end-of-life or donot resuscitate (patientrefusing further life-saving measures),andaimedto
positivelylabel(biased)when thelanguagearound whatpatients wererefusing wasvague, or
paintedthepatient asrefusinganycare inawaythat couldportray thepatient asinherently
stubborn.Wealso positively labeledsentences whichdescribed patients“refusingto try”or
“refusingto perform [activityof daily living]”.Ourcoding ontologypositsthat depictinga
patient asrefusingto try/assert effortcan beinterpreted aslabelinga patientaslazy or unwillful,
whentheymaybe unabletocomplete tasksduetodiscomfort ordecreasedhealthstatus.
Information gatheredfromdoubt markersfeatureimportanceandcontribution plots,as
wellasfrom annotatornotes andfeedbackalso showpatterns that reflectdoubtmarker usage
acrossa varietyof contexts.Useof “insisted”and“insisting”were consistentlylabeledas
positive for doubtmarkers. Whilethesewordsmay behelpfulinexpressing the strong
conviction behindpatientneeds, itis frequentlyalso ladenwith negative,stubborn, ordifficult
connotations.Theword “claimed”, particularly whendescribingpain orseverity of illness
symptoms or pain,washighly likelytobe labeledasa doubtmarker.“Alcohol”also hada high
featurecontribution towards positivedoubtmarker labels.Both annotators described thatdoubt
marker wordswerefrequentlyemployedtoreport patientalcoholanddrug usehistory,as
exemplified inTable 2.
Limitations
Low performance onscare quotes maybeindicative of theneed for additionaldata to
train future models.Duetothe highvarietyof quoteusage inlanguage,it isimportant to
considerdifferent approaches andlinguistic structuralfeatureswithin scarequotes. Additionally,
our datasetconsistsonly ofnotes fromICU admissions fromonesite.Many stigmatizedpatients,
particularly thosewith mentalhealthor substanceuse problems,may notbeadmitted duetoa
varietyof structuralbarriers,interactions withhealthcareproviders, orconcomitant illness. 32–34
Another limitation toconsider isthe positionalityoflabelersinthis study.Annotations
were completedbytworesearchers, who,although trained inreadingmedical textsandinterpreting linguistic bias,have limitedscope tothe varietyof experiencesofstigmatization and
bias whichmanypatientsmay endure.
Finally,it isimportantto conveythat aslanguageand medicinehave changedfrom
2001-2012 in MIMIC-III notes, theremaybe wordsthat were acceptableatonetimeand are
only realizedtobe derogatory overtime.Theprocess ofidentifying stigmaand biasmust bea
continuouseffort tokeeppacewith howstigma andbiasesevolve over timetoevade scrutinyor
drawin-group membersclosertogether.35,36
Conclusions
TheCARE-SD1.0 modelsandlexiconsproducedinthis study holdhighutilityfor
identifying patternsof stigmatizinglabels anddoubtmarkersinhealthcare systems,particularly
for targetingand designing interventions.Ourgoal insharingthesetools is toaccelerate research
efforts in thestudyof linguistic stigmaandbias inhealthcare.With additionalvalidation, these
modelscanbe usedtoauditand evaluatehealthcaresystems for units, providers,or patients
whomexperiencehigherrates ofstigmatizinglabels anddoubtmarkers,andallow real-time
feedbackfor anti-stigmatization interventionefforts inawaythat hasnot beenpossiblewith
traditional implicitbias trainingapproaches.3
REFERENCES
1. HatzenbuehlerML,Phelan JC,Link BG. Stigmaas aFundamentalCause ofPopulation
Health Inequalities.Am JPublic Health.2013;103(5):813-821.
doi:10.2105/AJPH.2012.301069
2. MainaIW,BeltonTD, GinzbergS, Singh A, JohnsonTJ.A decadeof studyingimplicit
racial/ethnicbias inhealthcareproviders using theimplicit associationtest.SocSci Med.
2018;199:219-229. doi:10.1016/j.socscimed.2017.05.009
3. FitzGeraldC,Hurst S. Implicit biasin healthcareprofessionals:asystematicreview. BMC
Med Ethics.2017;18(1):19. doi:10.1186/s12910-017-0179-8
4. Link BG, PhelanJC.ConceptualizingStigma. Annu RevSociol.2001;27(1):363-385.
doi:10.1146/annurev.soc.27.1.363
5. Beukeboom CJ,Burgers C.Linguistic Bias.In: OxfordResearchEncyclopediaof
Communication.Oxford UniversityPress; 2017.
doi:10.1093/acrefore/9780190228613.013.439
6. Beukeboom CJ.Mechanismsof linguisticbias:How wordsreflect andmaintainstereotypic
expectancies. In:Social CognitionandCommunication.Sydneysymposiumof social
psychology.PsychologyPress;2014:313-330.
7. Beukeboom CJ,Burgers C,Reviews Rof CROAHQL.How Stereotypes AreShared
Through Language- AReviewandIntroduction of theSocial Categories andStereotypes
Communication (SCSC) Framework.RevCommunRes.Publishedonline January1,2019.
Accessed February26, 2024.
https://www.academia.edu/38218166/Beukeboom_and_Burgers_2019_How_Stereotypes_Ar
e_Shared_Through_Language_A_Review_and_Introduction_of_the_Social_Categories_and
_Stereotypes_Communication_SCSC_Framework
8. Beach MC,Saha S.QuotingPatients inClinicalNotes: First, DoNo Harm. Ann InternMed.
2021;174(10):1454-1455. doi:10.7326/M21-2449
9. P GodduA, O’ConorKJ, LanzkronS, et al.Do WordsMatter?Stigmatizing Languageand
theTransmissionof Biasin theMedical Record.JGenIntern Med.2018;33(5):685-691.
doi:10.1007/s11606-017-4289-210. ZhangH, LuAX,Abdalla M,McDermott M,GhassemiM. Hurtfulwords: quantifying
biases inclinical contextual wordembeddings.In: Proceedingsof theACM Conferenceon
Health,Inference,and Learning.CHIL ’20.Association for ComputingMachinery;
2020:110-120. doi:10.1145/3368555.3384448
11. Abuse NIonD. WordsMatter - TermstoUseand Avoid WhenTalking About Addiction.
NationalInstituteonDrugAbuse. PublishedNovember29,2021.Accessed January22,
2022.
https://www.drugabuse.gov/nidamed-medical-health-professionals/health-professions-educat
ion/words-matter-terms-to-use-avoid-when-talking-about-addiction
12. GlassbergJ,Tanabe P,RichardsonL, DeBaun M.Amongemergency physicians,use ofthe
term “Sickler”isassociated withnegativeattitudes toward peoplewith sicklecelldisease.
Am J Hematol.2013;88(6):532-533. doi:10.1002/ajh.23441
13. Fernández L,FossaA,Dong Z, etal. WordsMatter:What DoPatients Find Judgmentalor
Offensivein OutpatientNotes? JGenInternMed.2021;36(9):2571-2578.
doi:10.1007/s11606-020-06432-7
14. ChafeWL,Nichols J. Evidentiality:TheLinguisticCoding ofEpistemology.Ablex; 1986.
15. Beach MC,Saha S,Park J,etal. TestimonialInjustice:LinguisticBias intheMedical
Records of BlackPatients andWomen. JGenInternMed.2021;36(6):1708-1714.
doi:10.1007/s11606-021-06682-z
16. Benamara F,Taboada M,MathieuY. EvaluativeLanguage Beyond BagsofWords:
Linguistic InsightsandComputationalApplications. ComputLinguist.2017;43(1):201-264.
doi:10.1162/COLI_a_00278
17. HimmelsteinG, BatesD, Zhou L. ExaminationofStigmatizing Language intheElectronic
Health Record.JAMA NetwOpen.2022;5(1):e2144967.
doi:10.1001/jamanetworkopen.2021.44967
18. WalkerD. drew-walkerr/CARE-SD-Stigma-and-Doubt-EHR-Detection.Published online
February 22,2024.Accessed May6,2024.
https://github.com/drew-walkerr/CARE-SD-Stigma-and-Doubt-EHR-Detection
19. JohnsonAEW,PollardTJ,ShenL, et al.MIMIC-III, afreely accessiblecritical care
database.SciData.2016;3(1):160035. doi:10.1038/sdata.2016.35
20. CarsonSS, BachPB. Theepidemiology andcostsof chroniccriticalillness. CritCareClin.
2002;18(3):461-476. doi:10.1016/S0749-0704(02)00015-5
21. ZhangY, ChenQ, YangZ, Lin H, LuZ. BioWordVec, improvingbiomedical word
embeddings withsubwordinformationand MeSH.SciData.2019;6(1):52.
doi:10.1038/s41597-019-0055-0
22. BioWordVec& BioSentVec:pre-trained embeddingsfor biomedical wordsand sentences.
Published onlineOctober 27,2022.AccessedNovember1,2022.
https://github.com/ncbi-nlp/BioSentVec
23. OpenAI Platform.AccessedDecember 27,2023.https://platform.openai.com
24. NelsonLK. ComputationalGrounded Theory: AMethodologicalFramework. Sociol
Methods Res.2020;49(1):3-42. doi:10.1177/0049124117729703
25. Sun M,Oliwa T,PeekME,Tung EL. NegativePatientDescriptors:DocumentingRacial
Bias In TheElectronic HealthRecord. HealthAff (Millwood).2022;41(2):203-211.
doi:10.1377/hlthaff.2021.01423
26. Zestcott CA,SpeceL, McDermott D,Stone J.Health CareProviders’ NegativeImplicit
Attitudes andStereotypesof AmericanIndians. JRacialEthn Health Disparities.2021;8(1):230-236. doi:10.1007/s40615-020-00776-w
27. Park J, SahaS, CheeB,TaylorJ, BeachMC. PhysicianUseofStigmatizing Language in
PatientMedicalRecords.JAMA NetwOpen.2021;4(7):e2117052-e2117052.
doi:10.1001/jamanetworkopen.2021.17052
28. Liu Y, OttM, GoyalN,et al.RoBERTa:A RobustlyOptimized BERTPretraining Approach.
ArXiv190711692Cs.Published online July26,2019.AccessedFebruary 7,2022.
http://arxiv.org/abs/1907.11692
29. Nembrini S,KönigIR,Wright MN.Therevivalof theGini importance?Bioinformatics.
2018;34(21):3711-3718. doi:10.1093/bioinformatics/bty373
30. sklearn.linear_model.LinearRegression.scikit-learn.AccessedJanuary 9,2024.
https://scikit-learn/stable/modules/generated/sklearn.linear_model.LinearRegression.html
31. Feature importanceswith aforest oftrees. scikit-learn.AccessedJanuary9,2024.
https://scikit-learn/stable/auto_examples/ensemble/plot_forest_importances.html
32. Chen LY,Crum RM,Martins SS,KaufmannCN, Strain EC,MojtabaiR. ServiceUseand
Barriersto MentalHealthCare AmongAdultsWith MajorDepressionand Comorbid
SubstanceDependence.PsychiatrServ.2013;64(9):863-870. doi:10.1176/appi.ps.201200289
33. RossLE, Vigod S,Wishart J,et al.Barriersandfacilitators toprimary carefor people with
mental healthand/orsubstance useissues: aqualitativestudy.BMC Fam Pract.
2015;16(1):135. doi:10.1186/s12875-015-0353-3
34. Bremer W,PlaisanceK, WalkerD, et al.Barrierstoopioid usedisorder treatment: A
comparison of self-reported informationfromsocial mediawithbarriersfound inliterature.
Front Public Health.2023;11:1141093. doi:10.3389/fpubh.2023.1141093
35. Smith RA. Languageof theLost: An ExplicationofStigma Communication.Commun
Theory.2007;17(4):462-485. doi:10.1111/j.1468-2885.2007.00307.x
36. Link BG, PhelanJC.Stigmaand itspublic healthimplications.TheLancet.
2006;367(9509):528-529. doi:10.1016/S0140-6736(06)68184-1
APPENDIX 1: LEXICONSFOR DOUBT MARKERSANDSTIGMATIZINGLABELS
Lexicon StemWord Expanded GPT-3.5added High-noise FinalLexicon Final
List Words words terms Lexicon
(Prunedto) removed Length
Doubt "adamant", 60total, ['"skeptical', 'suspicion', ['"doubtful',"'dubious", 58
"claimed", reducedby 'dubiousness', 'suspicious', '.insists','accused',
Markers
"insists", 2. 'questionable', 'questionable' 'adamant',
"allegedly","d Agreement 'doubting', , 'adamant/belligerant',
isbelieves","d =80% 'uncertain', 'questioning', 'adamantly','addamant',
ubious" 'skepticalness', 'uncertain', 'alledgedly','alleged',
'incredulous', 'hesitancy', 'allegedly',
'hesitating', 'hesitant','uns 'allegedly-unnecessary',
'suspicious', ure' 'asserted','believes',
'mistrustful', 'claimed','claimedthat',
'distrustful', 'claimes','claiming',
'unconvinced', 'confessionally',
'unsure', 'culpably','disbelief',
'hesitant', 'disbelieve',
'wary', 'disbelieved',
'dubious', 'disbeliever',
'disbelieving', 'disbelievers',
'skepticalism', 'disbelieves','hesitancy', 'disbelieving',
'skepticism', 'disclaimed','doggedly',
'mistrust', 'doubious','doubtful',
'uncertainness', 'dubious',
'disbelief', 'dubious/equivocal',
'suspicion', 'dubiously','insisist',
'mistrustfulness', 'insisisted','insist',
'incredulity', 'insisted','insisting',
'incredulously', 'insists','misbelieve',
'wavering', 'misbelieved',
'ambivalent', 'misbelieves',
'waveringly', 'mistrustful',
'questionableness', 'mistrusting',
'mistrustingly', 'non-dubious',
'doubter', 'proclaimed',
'questioning', 'purportedly','reinsists',
'doubtingly', 'skeptical','speculative',
'mistrusting', 'supposedly',
'doubtful', 'them-insists',
'skeptic', 'unconvinced',
'unconvincedly', 'undisguisedly',
'mistrustingly', 'unreliable','unsure"',
'mistrustfully', 'wavering']
'doubtingness',
'skepticism',
'questioningness',
'unbelieving',
'unsureness',
'skepticness',
'questioningness',
'doubtingly',
'unbelievingly',
'skeptically',
'mistrustingly',
'mistrustfully',
'skeptically',
'questioningly',
'doubtingly',
'skeptically',
'mistrustingly',
'mistrustfully"']
Stigmatizing "abuser","jun 180, ['"hysterical',' 'difficult', ['"hysterical', 127
Labels kie","alcoholi reducedby aggressive','drug 'suspicious','a "''drug-seeking",
c","drunk", 83. addict',' ggressive','un "''hysterical",
"drug-seeking Annotator non-compliant',' stable', "'drug-seeking",
","nonadhere agreement= lazy',' 'dramatic', "'junkie",'.reluctant',
nt", .75. attention-seeking',' 'unreliable','e 'abuse/abuser',
"agitated", manipulative',' ntitled','inval 'abused-abuser','abuser',
"angry", hypochondriac',' id','violent', "abuser's",'abusers',
"combative", difficult','mentally 'dangerous' 'addictive-drug-seeking',
"noncomplian unstable',' 'alcoholic','angry',
t","confront", troublemaker',' 'angry-disgusted',
"noncooperati irresponsible',' 'angry/disgusted',
ve", unpredictable',' 'attention-seeker',
"defensive", irrational','needy',' 'attention-seeking',
"hysterical", demanding',' 'challenging',
"unpleasant", disruptive',' 'combative',
"refuse","freq uncooperative',' 'combatively',
uent-flyer", unreliable','high 'compliant/noncomplian
"reluctant" maintenance',' t','counterdefensive',
attention-seeker',' 'deceptive','defensive',
dramatic',' 'defensive/offensive',
attention-seeking',' 'delusional',
lazy','invalid',' 'demanding',
faker','irrational',' 'disruptive','drug
hostile','aggressive',' addict','drugseeker',
challenging',' 'drug-craving/drug-seekiuncooperative',' ng','drug-seeking',
deceptive',' 'drug-seeking/-taking',
demanding',' 'drug-seeking/drug-takin
unreliable',' g','drug-seeking/taking',
high-strung',' 'drug-seeking/use',
self-destructive',' 'drunk','drunken',
unstable',' 'drunkenly','drunker',
manipulative',' 'drunkest','drunks',
entitled',' 'ex-abuser',
attention-seeking',' 'ex-alcoholic','faker',
violent','drugseeker', 'frequent-flier',
'malingerer','faker',' 'frequent-flyer',
mentallyill',' 'frequent-flyers',
dangerous',' 'frequent-fvl',
delusional','needy',' 'frequent-hitter',
overlysensitive',' 'frequent-hitters','high
unstable',' maintenance',
irrational"'] 'high-strung',
'histrionic-hysterical',
'hostile',
'hypochondriac',
'hypochondriac-hysteric
al','hysteric',
'hysterical',
'hysterical-obsessive',
'hysterical/anaclitic',
'hystericals','hysterics',
'incompliant',
'irrational','irrational"',
'irresponsible',
'iv-abuser','ivdabuser',
'junkie',"junkie's",
'junkies','lazy',
'ma-abuser',
'malingerer',
'manipulative','mentally
ill','mentallyunstable',
'morereluctant','needy',
'non-adherent',
'non-alcoholic/alcoholic'
,'non-compliant',
'non-cooperating',
'non-cooperation',
'non-cooperative',
'non-cooperatively',
'nonadhered',
'nonadherent',
'nonadherently',
'nonadherents',
'noncompliant',
'noncompliant/complian
t',
'noncompliant\\medicall
y','noncompliants',
'noncooperating',
'noncooperation',
'noncooperative',
'noncooperatively',
'novelty/drug-seeking',
'ny-nonadherent',
'onadherent',
'overdefensive','overly
sensitive','prealcoholic',
'pt.noncompliant',
'refuse','refuses',
'refusing','reluctanly',
'reluctant','reluctantly',
'reluctants',
'schizo-hysterical','self-destructive',
'troublemaker',
'un-adherent',
'unadherent',
'uncooperative',
'unpleasant',
'unpleasant/annoying',
'unpleasantly',
'unpleasantries',
'unpredictable',
'unwilling',
'unwillingly']
Scare ((?=.*\".*\")(?=.*\ - - ['yes','no','itchy','h
b(pt|patient|pateint ospital','DoNot
Quotes |he|she|they)\b)) Resuscitate','Yes
orNo',
'wet','yes/no','dry',
'DONOT
RESUSCITATE','
comfortmeasures
only','Known',
'Name',
'firstname',
'lastname','[**Do
ctorLastName
**]','[**Last
Name(un)**]',
'[**Known
firstname**]
[**Known
lastname
**]','[**Doctor
FirstName**]',
'[**Hospital1
**]','[**Hospital3
**]','[**Known
lastname**],
[**Known
firstname**]']
APPENDIX 2: STIGMATIZINGLABELS ONTOLOGY
Coding Process
DWand ATmet for 1hourbefore thefirst round ofcoding began.During thistimethey
discussedrationaleand literature backgroundsfor each ofthe threelinguistic biasfeatures, then
proceededto co-code5examples notincludedinthe subsequentdatasets. Then,eachannotator
codedthesamerandomsampleof 100.DWandAT met todiscusseach ofthe disagreements in
this sample,and usedthese examplesto further informontology developmentfor the final
sample. Coderswereableto reachagreementonall ofthe linguisticbias featuresafter discussing
disagreements.
After calculatingagreementand meetingtoadjudicate disagreements, ATcoded an
additional400sentences, and DWcoded500sentences for each linguisticbias term.Table 2
displays theresultsof thereliability dataset, includingfrequenciesof classlabels,as wellas final
results fromthe1000sentencedataset, withnotablesentencenotes, chosen outof aselection
marked bycodersfor potentialmanuscriptexamples.
Link andPhelan Stigma Definition
Stigmahasbeendefinedbysocialpsychologists Link andPhelan asa socialprocessthat
ischaracterized bytheinterplayof1. Labeling:Identifying individuals asbelonging toaparticular group.Status loss
and discriminationinvolvesanegative evaluationof agroups’attributesand its
members relative toanothergroup. Commonlyused withnouns(staticlabel) or
directadjectives topatient(patient isinsistent onreceiving watervspatientwas
repeatedlyasking for water).Nouns/direct adjectivesworkto labelpatientsas
staticqualitiesrather than specific,isolatedbehaviors.
2. Stereotyping:ascribing aproclivity towardsaspecificbehavior orcharacteristic
to membersof alabeledgroup.
3. Separation:involvesdistancingfrom thegroup, anddrawing linesof“us versus
them”.
4. Status loss anddiscrimination:involve anegative evaluationof agroups’
attributes and itsmembers relativetoanother group.(Comparingthis patientwith
others, or patientvsprovider)
5. Occurswithinacontext ofpower,such asthat ofthe patient-provider
relationship.
(Link & Phelan,2001)
Stigmatizing labelsandnegativedescriptorsin charts
Stigmatizing labelstodescribe groups areoftenusedto perpetuatestereotypes,andwhen
usedbyproviders, canlead tofeelings ofstigmatization andreducedtrust amongtheirpatients.
Muchof therecentwork onidentifying andreducing stigmatizinglabelshas comefrom
providers seekingtoimprovecare for patientswithsubstance usedisorders.A recent NIDA
studypublisheda listof words toavoid usingaround patientswith substanceuse disorders,
including"addict","abuser","user",or "junkie", whichhavebeen foundto beassociatedwith
perceived stigmatizationby patients.(Abuse, 2021a) Similarstudieshave beenappliedto other
chronic illnesspopulations,identifying termslike “sickler”, “frequentflier”or “drug-seeking”,
which maybeusedto further stigmatizepatients withchronicillnesseswho areoftenadmitted
into thehospital. (Abuse,2021b;Glassberg etal., 2013;Goddu etal., 2018)Whilesome
providers mayarguethat these termsmay beusefulin flaggingunwantedpatient behaviorsor
mental states,arecentstudyhas shownthatpatients exposed tolanguagewrittenabout themby
providers whichincludedstigmatizinglabels resultedin patientsfeeling unfairlyjudged, labeled,
and disrespected.(Fernández etal., 2021)
Recentresearch ledbyMichael Sun andcolleagues onover40,000clinical notes has
found disparitiesin presenceof “NegativeDescriptor”words, evaluatedbythe HealthEquity
Commissionof theSociety ofGeneral InternalMedicine,whichincludedcommonlyused terms
in the EHRsuchas“(non-)adherent,aggressive,agitated, angry,challenging, combative,
(non-)compliant, confront, (non-)cooperative,defensive, exaggerate,hysterical,(un-)pleasant,
refuse, andresist”.This study foundthat compared toWhitepatients,Black patientshad2.54
times theoddsof havingat leastonenegativedescriptor writtenintheirhistory andphysical
notes. (Sunetal.,2022) Researchinto stereotypeexpression in language hasfound that even
seeminglyinnocuous category labelsmay promptothersto perceivetargetindividual
actionsand characteristics as“static” aspectsof theiridentity,andexaggerate differences
acrossgroupsand similaritieswithin them. (Beukeboom& Burgers,2017) Theselabels can
be usedtojustify clinical decision-making, withholding ofresources,or toconfer doubtuponpatient testimonies.(Beukeboom,2014) Whilecurrent recommendationsencourage useof
person-centered, neutrallanguage inmedical charts,it isimportant toevaluate thepresence of
known stigmatizinglabelswithin providernotes tomitigate the transmissionof biasin theEHR.
Guiding Question: Does this sentenceinvolve languageaboutthe patientwhichcould resultin
thestigmatization or negativelabelingof apatient,which couldlead tofurther status
loss/discrimination inthecontext ofthe patient-providerrelationship?
Coding Rules
● Code =1: Yes,sentenceinvolveslanguagethat could resultinthe stigmatization ofthis
patient-- i.e.it involveslabeling, stereotyping,separation,whichcouldlead tostatus
loss/discrimination inthe contextofthe patient-providerrelationship.
○ Yes,clearexample:
■ Hewasdemandingdilaudidonadmission
■ Patientvery needythis shift
○ Patientrefusing care.(Broadly)
○ Refusing:difficult todiscern,
■ can beusedin stigmatizingwayrelated todaily activitiesoreffort put
forthbypatient
● If the quotewaspatient “refusing”anormaldaily activity,wecode
=1.
○ Example:“Patientrefusing toput onsocks”,whichcould
paint them inanegative,or “stubborn”light. We should
insteadsay “patientnot ableto putsocks on”or“patient
does notwantsocks on”.
○ Thisis bcweareplacingdirect blameonpatientsdueto
lack ofeffort, without consideringotherfactorslike
inability
■ If the quotewasdescribing how thepatient wasrefusing, relatedto effort
onbehalfof thepatient, code=1.
● Examples:“Patient refusingto attempt”,“patient refusing totry”,
“patient refusingto cooperate”.Thesemay bemore related to
patientsuffering and notgettingcarethey need,andsaying the are
refusing toputforth effortcan bestigmatizing.
● Code =0: No, thesentence doesnot involvestigmatizing/negative patientdescriptors.
Stigmatizing word/negative descriptorisnot referringto thepatient’s staticcharacteristics
or wouldnot likely resultin statusloss/discrimination amongthe medicalteam.
○ Thesearetypicallywhenwords areusedtodescribe apatients’specificbehavior
vs paintinga pictureabout theircharacterin broadstrokes.
■ I.e. if they’rerefusing, bespecificabout whatthey’re refusing
○ Examples:
■ “Wakingfor some feedsbutnot demandingyet.”
■ “O2satswere unreliableandcould notbemonitored”
■ “Non-adherentbandage”● Instead ofcallinga patientnon-adherenttotreatmentor
noncompliant, whichwouldfallunder stigmatizinglabels/negative
ptdescriptors
○ Describing patientacutepsychosisor “delusion”
○ “Refusing”
■ Refusing aspecificmedical treatment,withoutotherstigmatizing
languageor adjectives,wouldbea0.
● Example:“pt refusingto gotoCTscan”
■ Refusing DNRstatus--well withinpatientright to refuse,and itis
important toclearly understand.These wouldbelabeled0.
● “Refusingfurther care” ==0whendiscussed inthecontextof
being donotresuscitate/donotintubate
APPENDIX 3: DOUBTMARKERS ONTOLOGY
Coding Process
DWand ATmet for 1hourbefore thefirst round ofcoding began.During thistimethey
discussedrationaleand literature backgroundsfor each ofthe threelinguistic biasfeatures, then
proceededto co-code5examples notincludedinthe subsequentdatasets. Then,eachannotator
codedthesamerandomsampleof 100.DWandAT met todiscusseach ofthe disagreements in
this sample,and usedthese examplesto further informontology developmentfor the final
sample. Coderswereableto reachagreementonall ofthe linguisticbias featuresafter discussing
disagreements.
After calculatingagreementand meetingtoadjudicate disagreements, ATcoded an
additional400sentences, and DWcoded500sentences for each linguisticbias term.Table 2
displays theresultsof thereliability dataset, includingfrequenciesof classlabels,as wellas final
results fromthe1000sentencedataset, withnotablesentencenotes, chosen outof aselection
marked bycodersfor potentialmanuscriptexamples.
Doubt markersoverview
Linguistic features suchas evidentials,definedas“the linguistic codingof
epistemology”,1arefrequently usedalong withotherwordsreferred toas “doubtmarkers”, to
questiontheveracity of patienttestimonies,particularly related totheirsymptoms andadherence
to treatment.(Park etal.,2021)
Amongthemanywords usedas doubtmarkers,wordsand expressionsusedtoconfer
uncertaintysuchas: allegedly,apparently,or verbslikeclaimed,areoftenused whendescribing
patient testimonies,for example:“patient claimedtheir painwas10/10”.3These wordsareoften
usedto discusstheveracityof patientsymptomsand adherenceto treatment.
Disparities havebeenfound amongusage of thesetermsacross raceandgender, where
patientswho werewomenand patientswho were Blackwere foundtohave significantlyhigher
frequenciesof doubt markersin theirprovidernotes than patientswho were menor White.3The
extentto whichproviders use doubtmarkersis positedtobereflective ofthe amount ofdoubt
and uncertaintyaprovider has onpatienttestimony,andis thushypothesized toimpacttrust
within thepatient-providerrelationship, andrelated outcomeslike leavingagainstmedicaladvice
or in painmanagementstrategies.2,3Providers mayuse wordswhendescribing patienttestimony incombinationwith
stigmatizing labelsor negativedescriptors ofpatients totransmittheirstance, orexpression of
attitudes, feelings,and judgment aboutpatients tootherproviders whichmay impactfuture
treatment andcare decisions.4
Guiding Question:
Could thissentencebe interpreted byaprovider inawaythat confers doubttowardsthepatient’s
testimony,behavior,or condition?
Coding Rules
doubt_testimony =1: Yes,it couldbeinterpreted tocastdoubtonpatient testimony,behavior,
or condition.
a. Examples:
i. “apparentlyhewas sittingathome onthefloor feelingfinewhensuddenly
he felt fatiguedall over hisbody,”
ii. “the patientinsists shegets sick fromvaccines.”
doubt_testimony =0: No, this sentencewouldlikelynotbe interpretedtodoubt thepatients’
testimony,behavior,or condition.
b. Thesemayjust reflectuncertaintyinmedical results/plan
i. Example:“Diagnosisremains unclear atthis time”
c. Theycould alsobe instanceswhenthe chartis discussingsecondhandinformation
abouta patient,like “family believespatientis depressed”.Because testimonyis
secondhand,this isactually appropriate.
d. Other times,the wordmaybe usedtoaccurately portrayapatient’s own doubtor
subjectivityaround asituation.
i. Example:“patient believesthey havenooptions left”
References
1. ChafeWL,NicholsJ. Evidentiality:TheLinguisticCoding ofEpistemology.Ablex;
1986.
2. Park J, SahaS, Chee B,TaylorJ, BeachMC. PhysicianUseofStigmatizing Language in
PatientMedicalRecords.JAMA NetwOpen.2021;4(7):e2117052-e2117052.
doi:10.1001/jamanetworkopen.2021.17052
3. Beach MC,Saha S,Park J,etal. TestimonialInjustice:LinguisticBias intheMedical
Records of BlackPatients andWomen. JGenInternMed.Published online March22,2021.
doi:10.1007/s11606-021-06682-z
4. Benamara F,Taboada M,MathieuY. EvaluativeLanguage Beyond BagsofWords:
Linguistic InsightsandComputationalApplications. ComputLinguist.2017;43(1):201-264.
doi:10.1162/COLI_a_00278APPENDIX 4: SCAREQUOTESONTOLOGY
Coding Process
DWand ATmet for 1hourbefore thefirst round ofcoding began.During thistimethey
discussedrationaleand literature backgroundsfor each ofthe threelinguistic biasfeatures, then
proceededto co-code5examples notincludedinthe subsequentdatasets. Then,eachannotator
codedthesamerandomsampleof 100.DWandAT met todiscusseach ofthe disagreements in
this sample,and usedthese examplesto further informontology developmentfor the final
sample. Coderswereableto reachagreementonall ofthe linguisticbias featuresafter discussing
disagreements.
After calculatingagreementand meetingtoadjudicate disagreements, ATcoded an
additional400sentences, and DWcoded500sentences for each linguisticbias term.Table 2
displays theresultsof thereliability dataset, includingfrequenciesof classlabels,as wellas final
results fromthe1000sentencedataset, withnotablesentencenotes, chosen outof aselection
marked bycodersfor potentialmanuscriptexamples.
Scare QuotesOverview
Another linguisticmarkerof uncertaintythat hasbeen previouslyidentifiedinpatient chartsare
“scare quotes”,whichinvolve theutilizationof quotationmarkstomock, castdoubt,challenge
patient credibility,or insinuatelowhealthliteracywhendescribing the testimonyof another
individual.(Beachetal.,2021) Whileuseof scarequotes hasbeen documentedsincethe 1950s,
some arguethat thelinguistic phenomenonhas beenincreasingincreasingin recentyears,both
from theriseof “air quoting” gestureinthe 80sand90s, andwascommonlyemployedbyTrump
prior toand throughout hispresidency.(Garber,2016;Saner, 2017)
Whilequotations in chartscan beusefultodescribe patientsymptoms usingtheirexact
languageand documentpatient wishesor concerns,recent linguistic researchhasidentifieda
troubling prevalenceof providers utilizingquotationsin waystomock, manipulate,and regulate
thevoicesof patients.For example,consider theambiguityadded tothe sentence:“Patient
reports 10/10painrelatedto sicklecellcrisis.”,whenyouadd“Patientreports ‘10/10’pain
related to‘sickle cellcrisis’.Because ofthe quotationmarks,both10/10 andsicklecellcrisis
couldbe inferredasbeinguntrueor uncertain.Similar toevidentialsandnegative patient
descriptors,scarequotes havebeen foundto bemoreprevalent amongpatients whowere Black
and amongpatientswhowere women.(Beach etal., 2021)Early researchonscare quotingin
patient chartshasrecommendedthat providers utilizequotes onlywhenabsolutely necessaryto
reflect apatient’s exactexperience,wishes, or concerns,andthat even whenmadein earnest,
unnecessaryquotationopens patienttestimonyupto alevelofuncertaintyor inferencetoother
providers whomayquestionthe veracityof patientconditionsor experiences.(Beach &Saha,
2021)
Thegoal of thisannotation taskis todetermine whetherthesesentences identifiedas
matching closed quotationstrings andincluding reference topatient could beinterpretedby otherprovidersas “scarequotes”. Wewill useabinarysystem 1/0todeterminewhetheror
not thesentenceincludeda scarequote ornot.
Wearetrying to understandif the useof thesequotescould beinterpreted tomock,castdoubt,
challengepatient credibility, insinuatelowhealthliteracyor assignothernegativelabelsto
patients.In reading eachchart,it’simportant toask: didthis need tobequoted? Orcould ithave
beenwritten differently,or moredefinitively?
Coding Rules
scare_quote= “1”,Couldbeinterpreted asScareQuote.
● Yes: Castdoubt on patientasproviding reliabletestimony.
○ Examples:
■ Stated “migraine”wasdue to“stress”.Vs-- Patientstatedmigraine was
brought onbystress.
● Yes:Convey ridicule, contempt,stigmatization, or frustration byhighlighting
unsophisticated languageor limited knowledge
○ Examples:
■ Patientrepeatedlyasked to“get meout ofthis fuckingplace”
■ Doesnot believehehas prostatecancer because“his bowelsareworking
fine”
Scare_quote= “0”:Nota ScareQuote.
● Clinical Info,Effect on Life,Valuesor Preferences.Descriptive ofissue
○ Examples:
■ Chestpain that “feelslike anelephant isonmychest”
■ Reported that “thisisthe worstheadache I’vehadinmy life”
■ When discussingtreatmentgoals, she said“ifI cannot breathewithout a
tube, Idon’t wanttolive. Idonot wanttosuffer. Iwantto makesurethat
myfamily arewithme atthe end.”
● Weird randomquotes bookendingthe entirenarrative
○ Thesewill behuge. You’llknow whenyousee them
● Describing AcutePsychosis
○ This isadifficult/tricky line,but intheinstances where thequotes areused to
describe anaspectof apatients’psychosis,webelieve thisis medically necessary
to communicate,and notascare quote,despitethat it isused tocommunicatethat
thepatients’ viewisunreliable.
○ Examples:
■ [Pt] then transientlysitsupsaying clearing"what's goingonhere"
■ Pt able tosleepintermit overnight,however, ptreported havingseveral
baddreams andawokevery disoriented(calling thenursethe "president's
dgtr").APPENDIX 5: BESTPERFORMINGMODEL HYPERPARAMETERS
Stigma Modelhyperparameters:
● RF: {'max_depth':None,'min_samples_split': 2,'n_estimators':200}
● NB:{'alpha': 1.0}
● Log Reg:{'C':1.0}
● RoBERTA: {‘Max_len’:128,‘Batch_size’: 4,‘epochs’ :10,‘learning_rate’: 1e-5}
Doubt MarkersHyperparameters:
● RF: {'max_depth':None,'min_samples_split': 2,'n_estimators':100}
● NB:{'alpha': 1.0}
● Log Reg:{'C':1.0}
● RoBERTA: {‘Max_len’:512,‘Batch_size’: 4,‘epochs’ :10,‘learning_rate’: 1e-5}
Scare QuoteModelHyperparameters:
● RF: {'max_depth':None,'min_samples_split': 5,'n_estimators':100}
● NB:{'alpha': 1.0}
● Log Reg:{'C':0.01}
● RoBERTA: {‘Max_len’:512,‘Batch_size’: 8,‘epochs’ :10,‘learning_rate’: 1e-5}