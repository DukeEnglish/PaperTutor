ConcernsonBiasinLargeLanguageModelswhenCreatingSyntheticPersonae
HELENAA.HAXVIG,DipartimentoDiIngegneriaEScienzaDell’Informazione,UniversitàDiTrento,Italia
Thispositionpaperexploresthebenefits,drawbacks,andethicalconsiderationsofincorporatingsyntheticpersonaeinHCIresearch,
particularlyfocusingonthecustomizationchallengesbeyondthelimitationsofcurrentLargeLanguageModels(LLMs).Theseper-
spectivesarederivedfromtheinitialresultsofasub-studyemployingvignettestoshowcasetheexistenceofbiaswithinblack-box
LLMsandexploremethodsformanipulatingthem.Thestudyaimstoestablishafoundationforunderstandingthechallengesasso-
ciatedwiththesemodels,emphasizingthenecessityofthoroughtestingbeforeutilizingthemtocreatesyntheticpersonaeforHCI
research.
CCSConcepts:•Human-centeredcomputing→Naturallanguageinterfaces;HCItheory,conceptsandmodels;HCIdesignand
evaluationmethods;Participatorydesign;Contextualdesign.
AdditionalKeyWordsandPhrases:LLM,BiasDetection,SyntheticPersonae,ParticipatoryDesign,Ethics
ACMReferenceFormat:
HelenaA.Haxvig.2024.ConcernsonBiasinLargeLanguageModelswhenCreatingSyntheticPersonae.InProceedingsofLLM-BASED
SYNTHETICPERSONAEANDDATAINHCI-Workshop(CHI2024).ACM,NewYork,NY,USA,4pages.https://doi.org/10.1145/nnnnnnn.nnnnnnn
1 INTRODUCTION
IncorporatingLargeLanguageModels(LLMs)assyntheticpersonaeintheevolvinglandscapeofHuman-Computer
Interaction (HCI) research presents bothinteresting opportunities, daunting challenges and concerns that warrant
carefulconsiderationaboutcriticalconcernsofbiasandotherflawsinLLMs[10,15,20].Oneimmenseconcernrelates
totheexistenceofbiasinthemodels,andcreatingsyntheticpersonaehasthepotentialtoaidtheinvestigationofhow
differentformsofbiasmanifestinLLMs,byintroducinganewmethodoftesting.However,theblack-boxnatureofa
majorityofthesemodels,andtheirinabilitytoexpress’opinions’contrarytooverallLLMrulesorfail-safes,introduces
complexitiesinhowtopromptthemodelstoactoutspecificsyntheticpersonaeinvariousscenarios.
Thispositionpaperintroducesanexplorationofafewfundamentalquestions:Whatarethebenefitsanddrawbacks
ofusingsyntheticpersonaeinHCIresearch,andhowcanwecustomizethembeyondthelimitationsofcurrentLLMs?
Theperspectivespresentedinthispaperhavesprungfromthesub-studyofaPhDprojectonArtificialIntelligence
and ParticipatoryDesign [18]. Thesub-study,currently a workin progress, aims at developing a novel method of
adversarialtesting[6,13,21]throughtheuseofcontextualized"real-life"vignettes[2,16]promptedtotheinterfaces
ofmultipleLLMstoidentifypotentialbias,tryingtoopenupthe"blackbox"fromamorequalitativehuman-computer
interactionperspective[10].
2 BIASDETECTIONINLLMINTERFACES
Researchinvarioussub-fieldshasshownthathumanengagementinAIdesign,development,andevaluation,particu-
larlyinaqualitativemanner,canensureafocusonthesocio-technicalembeddednessofAI[3].Thiscanhelpinclude
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforcomponents
ofthisworkownedbyothersthantheauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,toposton
serversortoredistributetolists,requirespriorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ManuscriptsubmittedtoACM
1
4202
yaM
8
]CH.sc[
1v08050.5042:viXraCHI2024,Honolulu,Hawai’i,
HelenaA.Haxvig
socio-behavioralattributestoimprovecontextualunderstandingandinteroperability,oridentifypotentialtrapsdevel-
opersmightfallintobyproactivelydetectingissuesandethicalrisksduringthedevelopmentprocess[14].
Inalignment withthis,thepresent sub-studyfocusesonconductingapilotstudyemployingvignettes asanew
methodtoshowcasetheexistenceofbiaswithinblack-boxLanguageModelModels(LLMs)andexploringmethods
tostressthemodelsthroughenactmentofpersonae.Emphasizingthenecessityofthoroughtestingbeforeutilizing
theseLLMstocreatesyntheticpersonae,thestudyaimstoestablishafoundationforunderstandingthechallenges
associatedwiththesemodels.Furthermore,theresearchisparticularlyattentivetoFeministandQueerHCI[1,7,17,19]
considerations,acknowledgingtheimportanceofacriticalstanceinunderstandingandpossiblymitigatingbiasesin
LLMsfortheresponsiblecreationofsyntheticpersonae.
Thesub-studybeganwithpilotteststodeterminewhichLLMinterfacesaremostsuitedforthestudy,culminating
in the development of a systematic strategy for the vignette tests. The pilot tests explored various approaches to
promptengineeringandadversarialtestingmethodstoexplorethemalleability,susceptibilitytospecificprompts,and
limitationsofLLMs.
2.1 PilotTestingwithAdversarialAttacks
Thepilotstudyinitially aimedtoassess someofthelargest and mostprominent LLMsexisting today,considering
factorssuchasavailability,commercializedonlineinterfaces,andprototypeaccessibility.Thestudyincludedinterfaces
suchasChatGPT3.5turbo,GoogleBARD(usingPaLM2untilGemini1.0’slaunchinFebruary2024),Gemini,PI.ai
(Inflection-1),andCoral(Coheremodel).Additionally,prototypetestingwasconductedonFalcon180B,LlaMa270B,
Guanaco33B,andVicuna33B.
ExistingresearchonbiasinAItrainingdata[5,8]andrecentinvestigationsintobiasinLargeLanguageModels
(LLMs)highlightthepotentialrisksofbiasmanifestationinLLMs[15,20].Theinitialphase,thus,involved’interview-
ing’themodelsonbiasinLLMsandawarenessofpotentialflawslikehallucinations.Whendirectlyquestionedabout
bias,mostmodelsacknowledgethepossibility,citingconcernsrelatedtogender,ethnicity,culture,religion,politics,
ability,andage.Whilemanymodelsasserttheirattemptstomaintainimpartiality,some,likeChatGPT3.5,Gemini,and
Cohere,elaborateontheoriginsofbias,attributingittotrainingdata,samplingbias,algorithmicbias,confirmation
bias,andleadingquestions..Thisinitialtesting,comprisedofleadingquestionstoassessthegeneralembeddedruleson
inappropriatebehavior,revealednosignificantdifferencesbetweenthemodels.Furthertesting,involvingadversarial
attacksinspiredbyexamplesfromDAIR.AI[6],assessedlogicalreasoning,resistancetopromptinjection,andresis-
tancetojailbreakingtechniques,includingcreativepromptslikeplayingagameorenactingtheDAN(DoAnything
Now)characterforillegalactivitiesamongothers.Thisprovidedsomenoteworthyinsights,particularlyinexploring
themodels’abilitiestoassumedifferentpersonae.SomemodelsresistedDANmanipulationforillegalinstructionsbut
exhibitedpotentialforexpressingbiases,suchasracialandgenderbias,wheninstructedtoembodyspecificpersonae.
Notallmodelssuccumbed,butthosethatdidshowpromiseinadoptingpositivecharacters.Onlytwomodels,PIand
Vicuna,werewillingtoadoptoffensivebehaviorwithabasicjailbreakingprompt.
Thispresentsachallengein creatingsynthetic personaeasthemodelsresponddifferently tothesame prompts,
eveniftheyshareasimilarcautious"personality".Assuch,itisnecessarytodeterminewhetherarelativelyuniversal
approachtosyntheticpersonaeisfeasibleorifuniquepromptsarerequiredforeachmodel.Additionally,addressing
modelsresistanttomanipulationposesachallengeincreatingheterogeneoussyntheticpersonae.And,whenstressing
themodelswithdifferentapproacheswefurtherriskcreatingsituationswherethemodelisescapingcontrol,which
wouldbecriticaline.g.aworkshopwithhumanparticipants.
2CHI2024,Honolulu,Hawai’i,
ConcernsonBiasinLargeLanguageModelswhenCreatingSyntheticPersonae
Someofthesechallengeswillbeexploredandaddressedinthesubsequentstepsofthesub-study,wheretheideais
tocombinethevignettetechniquewithideasfromadversarialattacks.Scenariosandpersonaewillbebuiltonthebasis
ofempiricalinterviewdataandexistingliterature,andthesewillbepromptedtotheLLMs’interfaces.Thisallowsthe
LLMstooperatebasedonthesepersonae’sperspectivesand respondtopresentedscenarios. Whilethesepersonae
arecraftedthroughresearch,instructingthemodelstoembodythemcouldresultinasyntheticpersonashapedby
themodels’inherentbiases.Thiscanproducevaluableinsightsintohowbiasmanifestsinthesemodelsandexplore
strategiesforhowwecanmovebeyondthelimitationsofLLMswhenpromptingsyntheticpersonae.
3 ONTOLOGICALANDETHICALCONCERNS
Technologicaldevelopment doesnothappeninavacuumand technologiesarenotsimplypassive tools,butsocial
interventionsthatrequireengagementinmoraldiscourse[9].Withtheinclusionofafewpointsthatwarrantfurther
discussion,thissectionunderscorestheneedforathoughtfulandethicalapproachtoincorporatingLLMsinvarious
contexts,emphasizingtheimportanceofresponsibledesignpractices.
Inatimewherethewordsweapplytoidentifyourselveshavebecomemoreopentointerpretation,languageserves
asanimperfectreflectionofshiftingsocialrealities[11],whichbegsustoquestionwhetherreducingthehumanex-
periencetoclassificationsinLMMsproducesadequateimitationsofsaidrealities.Thelackofadeepunderstanding
ofreal-world contexts, culturalnuances, and human emotions in LLMs raises concerns abouttheir ability to accu-
ratelyrepresentpersonae,nottomentiondiverseuserexperiences,inHuman-ComputerInteraction(HCI).Thisisa
particularconcernwhencreatingsynthetic personaefrompotentiallyflawedandbiased"blackbox"systems.Inar-
easlikeParticipatoryDesign[18],whereamplifyingmarginalizedvoicesisparamount,syntheticpersonaemustbe
instrumentsforempowermentratherthanbiasedobstacles.
Lastly,conductingexperimentswithLLM-generatedsyntheticpersonae,especiallyindynamicreal-worldscenarios
involvinghumans,posesrisksandrequiresrigorousvettingforpotentialharmandunpredictabilitybeforedeployment.
AswenavigatethelandscapeofLLMsandHCI,itisimperativetoapproachthetopicwithethicalresponsibilityand
criticalscrutiny,exploringhowtotestamodel’ssuitabilitybeforeusingittocreatesyntheticpersonae.
4 FUTUREWORK
Atthecurrentpointintime,thepilottestshavebeencarriedoutandprovidedinsightsrelevantforthestrategyof
the next steps. Now, the focuswill move to creating the mentioned vignettes and "interviewing" the LLMs to test
theirarticulationofbias,particularlyonfeminist andqueerrightsissues.Inadditiontodevelopingthisinnovative
interviewmethodforexploringLLMs’portrayalsofsensitivetopics(i.e.inherentbias),thisstudyalsoaimstoestablish
aworkshopmethodwithLLMsasnon-humanparticipants(i.e.syntheticpersonae)asanovelnon-anthropocentric
approachforsemi-structuredadversarialtestingofbiasarticulationinLLMinterfaces,inalignmentwithprinciples
ofmore-than-humandesignapproaches[4,12].Thecurrentsub-studyisexpectedtobefollowedwithaspeculative
designapproach,envisioningtrainingLLMsonspecificallyselecteddata,e.g.withcontrastingworldviewstoprovoke
criticaldiscussionsaboutembeddedvaluesintechnology.Thisprovotypingcouldchallengeprevailingrepresentations
andpromptustoconsiderhowcreatingspecificsyntheticpersonaecanguideHCIresearchintoLLMbehaviourand
human-LLMinteraction.
3CHI2024,Honolulu,Hawai’i,
HelenaA.Haxvig
REFERENCES
[1] ShaowenBardzell.2010.FeministHCI:takingstockandoutlininganagendafordesign.InProceedingsoftheSIGCHIConferenceonHumanFactors
inComputingSystems(CHI’10).AssociationforComputingMachinery,NewYork,NY,USA,1301–1310. https://doi.org/10.1145/1753326.1753521
[2] Christine Barter and Emma Renold. 1999. The Use of Vignettes in Qualitative Research. Social Research Update 25 25 (1999).
https://sru.soc.surrey.ac.uk/SRU25.html
[3] Marianne Cherrington, David Airehrour, Joan Lu, Qiang Xu, David Cameron-Brown, and Ihaka Dunn. 2020. Features of Human-
Centred Algorithm Design. In 2020 30th International Telecommunication Networks and Applications Conference (ITNAC). 1–6.
https://doi.org/10.1109/ITNAC50341.2020.9315169 Journal Abbreviation: 2020 30th International Telecommunication Networks and Appli-
cationsConference(ITNAC).
[4] PaulCoultonandJosephLindley.2019. More-ThanHumanCentredDesign:ConsideringOtherThings. TheDesignJournal22(May2019),1–19.
https://doi.org/10.1080/14606925.2019.1614320
[5] KateCrawford.2021. AtlasofAI:power,politics,andtheplanetarycostsofartificialintelligence. YaleUniversityPress,NewHaven. OCLC:
on1111967630.
[6] DAIR.AI.2023.AdversarialPrompting. https://www.promptingguide.ai/risks/adversarial
[7] MichaelAnnDeVito,CaitlinLustig,EllenSimpson,KimberleyAllison,TeeChuanromanee,KattaSpiel,AmyKo,JenniferRode,BriannaDym,
MichaelMuller,MorganKlausScheuerman,AshleyMarieWalker,JedBrubaker,andAlexAhmed.2021.QueerinHCI:StrengtheningtheCommu-
nityofLGBTQIA+ResearchersandResearch.InExtendedAbstractsofthe2021CHIConferenceonHumanFactorsinComputingSystems(CHIEA
’21).AssociationforComputingMachinery,NewYork,NY,USA,1–3. https://doi.org/10.1145/3411763.3450403
[8] VirginiaEubanks.2019.Automatinginequality:howhigh-techtoolsprofile,police,andpunishthepoor(firstpicadoreditioned.).PicadorSt.Martin’s
Press,NewYork.
[9] Christopher Frauenberger and Peter Purgathofer. 2019. Ways of thinking in informatics. Commun. ACM 62, 7 (June 2019), 58–64.
https://doi.org/10.1145/3329674
[10] HelenaAHaxvig.2023.ExploringLargeLanguageModelInterfacesThroughCriticalandParticipatoryDesign.InCHItaly2023Proceedingsofthe
DoctoralConsortiumofthe15thBiannualConferenceoftheItalianSIGCHIChapter(CHItaly2023).Italy. https://ceur-ws.org/Vol-3481/paper4.pdf
[11] FrederikeKaltheuner.2021.FakeAI.MeatspacePress. OCLC:1292530708.
[12] DariaLoi,ChristineT.Wolf,JeanetteL.Blomberg,RaphaelArar,andMargotBrereton.2019.Co-designingAIFutures:IntegratingAIEthics,Social
Computing,andDesign.InCompanionPublicationofthe2019onDesigningInteractiveSystemsConference2019Companion(DIS’19Companion).
AssociationforComputingMachinery,NewYork,NY,USA,381–384. https://doi.org/10.1145/3301019.3320000
[13] JakobMökander,JonasSchuett,HannahRoseKirk,andLucianoFloridi.2023.Auditinglargelanguagemodels:athree-layeredapproach.AIand
Ethics(May2023). https://doi.org/10.1007/s43681-023-00289-2
[14] OrestisPapakyriakopoulos,ElizabethAnneWatkins,AmyWinecoff,KlaudiaJaźwińska,andTithiChattopadhyay.2021.QualitativeAnalysisfor
HumanCenteredAI.arXivpreprintarXiv:2112.03784(2021).
[15] DavidRozado.2023. ThePoliticalBiasesofChatGPT.SocialSciences12,3(March2023),148. https://doi.org/10.3390/socsci12030148Number:3
Publisher:MultidisciplinaryDigitalPublishingInstitute.
[16] HelenSampsonandIdarAlfredJohannessen.2020.Turningonthetap:thebenefitsofusing‘real-life’vignettesinqualitativeresearchinterviews.
QualitativeResearch20,1(Feb.2020),56–72. https://doi.org/10.1177/1468794118816618Publisher:SAGEPublications.
[17] MorganKlaus Scheuerman, Jacob M. Paul, and Jed R. Brubaker.2019. How Computers See Gender: An Evaluation of Gender Classifica-
tion inCommercialFacialAnalysis Services. Proceedings ofthe ACMon Human-Computer Interaction3, CSCW(Nov.2019), 144:1–144:33.
https://doi.org/10.1145/3359246
[18] JesperSimonsenandToniRobertson(Eds.).2013.Routledgeinternationalhandbookofparticipatorydesign.Routledge,London. OCLC:818827037.
[19] YolandeStrengers,LizhenQu,QiongkaiXu,andJarrodKnibbe.2020.Adhering,Steering,andQueering:TreatmentofGenderinNaturalLanguage
Generation.InProceedingsofthe2020CHIConferenceonHumanFactorsinComputingSystems(CHI’20).AssociationforComputingMachinery,
NewYork,NY,USA,1–14. https://doi.org/10.1145/3313831.3376315
[20] YixinWan,GeorgePu,JiaoSun,AparnaGarimella,Kai-WeiChang,andNanyunPeng.2023. “KellyisaWarmPerson,JosephisaRoleModel”:
GenderBiasesinLLM-GeneratedReferenceLetters.InFindingsoftheAssociationforComputationalLinguistics:EMNLP2023,HoudaBouamor,Juan
Pino,andKalikaBali(Eds.).AssociationforComputationalLinguistics,Singapore,3730–3748.https://doi.org/10.18653/v1/2023.findings-emnlp.243
[21] XilieXu,KeyiKong,NingLiu,LizhenCui,DiWang,JingfengZhang,andMohanKankanhalli.2023. AnLLMcanFoolItself:APrompt-Based
AdversarialAttack. https://doi.org/10.48550/arXiv.2310.13345arXiv:2310.13345[cs].
Received22/02/2024;accepted05/03/2024
4This figure "acm-jdslogo.png" is available in "png"(cid:10) format from:
http://arxiv.org/ps/2405.05080v1