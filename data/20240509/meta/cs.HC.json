[
    {
        "title": "\"Community Guidelines Make this the Best Party on the Internet\": An In-Depth Study of Online Platforms' Content Moderation Policies",
        "authors": "Brennan SchaffnerArjun Nitin BhagojiSiyuan ChengJacqueline MeiJay L. ShenGrace WangMarshini ChettyNick FeamsterGenevieve LakierChenhao Tan",
        "links": "http://dx.doi.org/10.1145/3613904.3642333",
        "entry_id": "http://arxiv.org/abs/2405.05225v1",
        "pdf_url": "http://arxiv.org/pdf/2405.05225v1",
        "summary": "Moderating user-generated content on online platforms is crucial for\nbalancing user safety and freedom of speech. Particularly in the United States,\nplatforms are not subject to legal constraints prescribing permissible content.\nEach platform has thus developed bespoke content moderation policies, but there\nis little work towards a comparative understanding of these policies across\nplatforms and topics. This paper presents the first systematic study of these\npolicies from the 43 largest online platforms hosting user-generated content,\nfocusing on policies around copyright infringement, harmful speech, and\nmisleading content. We build a custom web-scraper to obtain policy text and\ndevelop a unified annotation scheme to analyze the text for the presence of\ncritical components. We find significant structural and compositional variation\nin policies across topics and platforms, with some variation attributable to\ndisparate legal groundings. We lay the groundwork for future studies of\never-evolving content moderation policies and their impact on users.",
        "updated": "2024-05-08 17:18:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.05225v1"
    },
    {
        "title": "The Potential and Implications of Generative AI on HCI Education",
        "authors": "Ahmed KharrufaIan G Johnson",
        "links": "http://dx.doi.org/10.1145/3658619.3658627",
        "entry_id": "http://arxiv.org/abs/2405.05154v1",
        "pdf_url": "http://arxiv.org/pdf/2405.05154v1",
        "summary": "Generative AI (GAI) is impacting teaching and learning directly or indirectly\nacross a range of subjects and disciplines. As educators, we need to understand\nthe potential and limitations of AI in HCI education and ensure our graduating\nHCI students are aware of the potential and limitations of AI in HCI. In this\npaper, we report on the main pedagogical insights gained from the inclusion of\ngenerative AI into a 10 week undergraduate module. We designed the module to\nencourage student experimentation with GAI models as part of the design brief\nrequirement and planned practical sessions and discussions. Our insights are\nbased on replies to a survey sent out to the students after completing the\nmodule. Our key findings, for HCI educators, report on the use of AI as a\npersona for developing project ideas and creating resources for design, and AI\nas a mirror for reflecting students' understanding of key concepts and ideas\nand highlighting knowledge gaps. We also discuss potential pitfalls that should\nbe considered and the need to assess students' literacies and assumptions of\nGAIs as pedagogical tools. Finally, we put forward the case for educators to\ntake the opportunities GAI presents as an educational tool and be experimental,\ncreative, and courageous in their practice. We end with a discussion of our\nfindings in relation to the TPACK framework in HCI.",
        "updated": "2024-05-08 15:46:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.05154v1"
    },
    {
        "title": "Concerns on Bias in Large Language Models when Creating Synthetic Personae",
        "authors": "Helena A. Haxvig",
        "links": "http://arxiv.org/abs/2405.05080v1",
        "entry_id": "http://arxiv.org/abs/2405.05080v1",
        "pdf_url": "http://arxiv.org/pdf/2405.05080v1",
        "summary": "This position paper explores the benefits, drawbacks, and ethical\nconsiderations of incorporating synthetic personae in HCI research,\nparticularly focusing on the customization challenges beyond the limitations of\ncurrent Large Language Models (LLMs). These perspectives are derived from the\ninitial results of a sub-study employing vignettes to showcase the existence of\nbias within black-box LLMs and explore methods for manipulating them. The study\naims to establish a foundation for understanding the challenges associated with\nthese models, emphasizing the necessity of thorough testing before utilizing\nthem to create synthetic personae for HCI research.",
        "updated": "2024-05-08 14:24:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.05080v1"
    },
    {
        "title": "Impact of Tone-Aware Explanations in Recommender Systems",
        "authors": "Ayano OkosoKeisuke OtakiSatoshi KoideYukino Baba",
        "links": "http://arxiv.org/abs/2405.05061v1",
        "entry_id": "http://arxiv.org/abs/2405.05061v1",
        "pdf_url": "http://arxiv.org/pdf/2405.05061v1",
        "summary": "In recommender systems, the presentation of explanations plays a crucial role\nin supporting users' decision-making processes. Although numerous existing\nstudies have focused on the effects (transparency or persuasiveness) of\nexplanation content, explanation expression is largely overlooked. Tone, such\nas formal and humorous, is directly linked to expressiveness and is an\nimportant element in human communication. However, studies on the impact of\ntone on explanations within the context of recommender systems are\ninsufficient. Therefore, this study investigates the effect of explanation\ntones through an online user study from three aspects: perceived effects,\ndomain differences, and user attributes. We create a dataset using a large\nlanguage model to generate fictional items and explanations with various tones\nin the domain of movies, hotels, and home products. Collected data analysis\nreveals different perceived effects of tones depending on the domains.\nMoreover, user attributes such as age and personality traits are found to\ninfluence the impact of tone. This research underscores the critical role of\ntones in explanations within recommender systems, suggesting that attention to\ntone can enhance user experience.",
        "updated": "2024-05-08 13:55:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.05061v1"
    },
    {
        "title": "Overcoming Anchoring Bias: The Potential of AI and XAI-based Decision Support",
        "authors": "Felix HaagCarlo StinglKatrin ZerfassKonstantin HopfThorsten Staake",
        "links": "http://arxiv.org/abs/2405.04972v1",
        "entry_id": "http://arxiv.org/abs/2405.04972v1",
        "pdf_url": "http://arxiv.org/pdf/2405.04972v1",
        "summary": "Information systems (IS) are frequently designed to leverage the negative\neffect of anchoring bias to influence individuals' decision-making (e.g., by\nmanipulating purchase decisions). Recent advances in Artificial Intelligence\n(AI) and the explanations of its decisions through explainable AI (XAI) have\nopened new opportunities for mitigating biased decisions. So far, the potential\nof these technological advances to overcome anchoring bias remains widely\nunclear. To this end, we conducted two online experiments with a total of N=390\nparticipants in the context of purchase decisions to examine the impact of AI\nand XAI-based decision support on anchoring bias. Our results show that AI\nalone and its combination with XAI help to mitigate the negative effect of\nanchoring bias. Ultimately, our findings have implications for the design of AI\nand XAI-based decision support and IS to overcome cognitive biases.",
        "updated": "2024-05-08 11:25:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.04972v1"
    }
]