HoloHisto: End-to-end Gigapixel WSI Segmentation
with 4K Resolution Sequential Tokenization
YuchengTang1∗,YufanHe1,VishweshNath1,PengfeigGuo1,RuiningDeng2,
TianyuanYao2,QuanLiu2,CanCui2,MengmengYin3,ZiyueXu1,HolgerRoth1,
DaguangXu1,HaichunYang3,andYuankaiHuo2,3
1 Nvidia
2 VanderbiltUniversity
3 VanderbiltUniversityMedicalCenter
Abstract. In digital pathology, the traditional method for deep learning-based
imagesegmentationtypicallyinvolvesatwo-stageprocess:initiallysegmenting
high-resolutionwholeslideimages(WSI)intosmallerpatches(e.g.,256×256,
512×512,1024×1024)andsubsequentlyreconstructingthemtotheiroriginal
scale.Thismethodoftenstrugglestocapturethecomplexdetailsandvastscope
ofWSIs.Inthispaper,weproposetheholistichistopathology(HoloHisto)seg-
mentationmethodtoachieveend-to-endsegmentationongigapixelWSIs,whose
maximumresolutionisabove80,000×70,000pixels.HoloHistofundamentally
shiftstheparadigmofWSIsegmentationtoanend-to-endlearningfashionwith
1) a large (4K) resolution base patch for elevated visual information inclusion
and efficient processing, and 2) a novel sequential tokenization mechanism to
properlymodelthecontextualrelationshipsandefficientlymodeltherichinfor-
mationfromthe4Kinput.Toourbestknowledge,HoloHistopresentsthefirst
holistic approach for gigapixel resolution WSI segmentation, supporting direct
I/OofcompleteWSIandtheircorrespondinggigapixelmasks.UndertheHolo-
Histoplatform,weunveilarandom4Ksamplerthattranscendsultra-highreso-
lution,delivering31and10timesmorepixelsthanstandard2Dand3Dpatches,
respectively,foradvancingcomputationalcapabilities.Tofacilitateefficient4K
resolutiondenseprediction,weleveragesequentialtokenization,utilizingapre-
trained image tokenizer to group image features into a discrete token grid. To
assesstheperformance,ourteamcuratedanewkidneypathologyimagesegmen-
tation(KPIs)datasetwithWSI-levelglomerulisegmentationfromwholemouse
kidneys.Fromtheresults,HoloHisto-4Kdeliversremarkableperformancegains
overpreviousstate-of-the-artmodels.
Keywords: wholeslideimage·sequencemodeling·segmentation.
1 Introduction
Digitalpathology,arapidlyevolvingfieldofmedicalvisionresearch,hasseenatrans-
formativeadvancementwithlargevisionmodels(LVMs)[1,26,33].Thissignificantad-
ventcreatednewdemandsforhigh-qualityperception,whichiscrucialformicroscopic
4202
luJ
3
]VI.ssee[
1v70330.7042:viXra2 AuthorsSuppressedDuetoExcessiveLength
5x 10x 20x 40x 4K (3840x2160) 2K (2048x1080) 1080P (1920x1080) 720P (1280x720) 480P (720x480)512x512256x256
Fig.1.Thefieldofviewprovidedbydifferentresolutions,suchastheconventional512×512
patch(indicatedbyaredbox)and256×256,revealsonlyalimitedrangeofdetailswithinthe
targettissuestructures.Incontrast,ultra-highresolution(4K)imagesofferamorecomprehensive
viewofinterrelationsandcanserveasafoundationalvisualconstituteforWSIanalysis.
(e.g., whole slide) image computing. However, current models are limited to the ca-
pabilityofdissectingandinterpretingsmallpre-definedpatcheswithinimages[8,10].
Typically, pre-processed tiles are confined to dimensions of 512 × 512 pixels or re-
sampled to smaller dimensions of 224×224 defined by some predominating frame-
works [5,12,28], which restrict the scopes of tissue details that can be captured. The
absence of rich information hinders the model’s performance, particularly impacting
tasksofdetectingsmallobjectsanddenseprediction[10,14].Forinstance,thedetection
andsegmentationofcompletemedullasunderkidneyWSIwilldegradebymorethan
10%inDSCbyusingaheightandwidthof512orcompletelyfailwithoutpatchingpre-
definedROI[11].Thisscalability,especiallywhendealingwithgigapixelwholeslide
image (WSI), remains a bottleneck in comprehensive and efficient computing analy-
sis. To date, there are no established gold standard datasets for segmenting gigapixel
WSIs,resultinginalackofcomprehensiveend-to-endmethodsinthishistopathology
research.
To include more information, a higher resolution is necessary as shown in Fig. 1.
Nevertheless, modeling ultra-high definition (UHD) images (e.g. beyond 4K resolu-
tion) is extremely challenging [9,13,30]. High-resolution dense prediction requires a
balanceofstrongcontextinformationextractionandmodelefficiency[4].Thecompu-
tationalcostofconvolutionalandtransformermodels,despitetheirsignificantbenefits,
hasquadraticincreasesinthedemandforcomputationalresources[31].Thispresents
acriticalscalingchallengeforprocessingwholeslideimages.Therefore,high-quality
imagedensepredictionrequiresmodelscapableofunderstandingbothglobalcompo-
sitionandlocalityofinteractionsatacompressionrate.
Inthiswork,weproposetheHoloHistoframework,debutingtheholisticapproach
toredesignhistopathologyimagesegmentationwiththreekeyfeatures:
The Holistic Approach: We developed an end-to-end workflow for training and in-
ferencing gigascale WSI, introducing a novel learning paradigm to the field of WSI
analysis..HoloHistoisdesignedtohandleinputsandoutputsofanysize,regardlessofTitleSuppressedDuetoExcessiveLength 3
whether theyare (WSIs) or smaller patches. By leveragingcuCIM, our dataloaderfa-
cilitatesreal-timereadingofWSIsatvariousmagnificationlevelsandsupportsrandom
foreground patching, tiling, or augmentation, enhancing the flexibility and efficiency
ofourapproach.Ourapproachiscapableofdynamicallycreatingdatasetsonlinefrom
one or multiple WSIs, potentially comprising an unlimited number of images during
training.Thisapproachdoesnotdependonpre-definedcroppingstrategies,offeringa
more flexible and scalable solution for training models on large-scale datasets. In the
inferencestage,itcangeneratethecorrespondinggigapixeloutput.
Architecture: WedesignanefficientbackbonetailoredforsegmentingUHDimages.
First,weemploythesequentialtokenizerforlearningdiscretevisualtokensfromper-
ceptually rich constituents, streamlining towards 4K resolution dense prediction. Sec-
ond, to model the long discrete tokens from these UHD images, we propose to use a
two-stageViTarchitecturethatincorporatesmulti-scaleattention[4],whichusesReLU
linearattentioninsteadoftheinefficientSoftmaxattention.
Data:AsasignificantefforttoimprovegigapixelWSIcomputing,ourpathologistsad-
dressedthecriticalgapintheavailabilityofimagingdata.WepresentKidneyPathology
ImageSegmentation(KPIS),thedatasetthatfacilitatesthediagnosisandtreatmentof
chronickidneydisease(CKD).AnnotationsareperformedattheWSIlevel,servingas
afoundationbenchmarkfordevelopingcutting-edgeimagesegmentationtechnologies.
Insummary,thispaperexploresanewlearningparadigmofWSIsegmentation:1)
HoloHistoframeworkthatiscapableofparallelingtileprocessingwithdirectWSII/O,
2) scalable segmentation backbone with sequential tokenizer for ultra-high resolution
images,and3)gigapixelWSIannotationdatasetasafoundationalbenchmark.
2 RelatedWorks
Pathology Segmentation. Recent advances in deep learning with CNN and trans-
formers [15,18] achieve significant improvement in the field of pathology segmen-
tation. Several works were proposed to address the challenges of microscopic imag-
ingdata,includingH&Estainedpathologyimages,fluorescedata,orothercellimag-
ing modalities [3,22]. Numerous datasets for cell and tissue segmentation, including
MoNuSeg[25]andNEPTUNE[2],areavailableforidentifyingavarietyofglomerular
structures. In addition, instance segmentation is developed in the general cell imag-
ing domain [27]. However, most current approaches focus on analyzing local tiles at
a uniform magnification level, including nuclei, glomeruli, or tubules. This results in
a notable gap in the segmentation of disease-related regions across entire whole slide
images.Despitelimitedexplorationorestablishedefficacyinthefield,weintroducea
segmentationdatasetandmethodologydesignedforcomprehensiveWSIsegmentation.
Foundation Vision Models. Inspired by the achievement of large language models
(LLMs) [13,32], many endeavors [1,17] have been made to develop foundation vi-
sionmodels.Withthedevelopmentoftransformerorstatespacemodels[16],sequence
modelingbecamethedefactowayformodelingvisualsentences[1],whichenabledthe
uniformmodelingofvariousvisiontasks.Inthiswork,weexplorelargevisionmodels
(LVM) for digital pathology with two key features: (1) a pre-trained vector quantized
generative adversarial networks (VQGAN) [13] that enables scalable tokenization for4 AuthorsSuppressedDuetoExcessiveLength
WSI Loader Pretrained VQGAN Discrete Multi-Scale ViT Blocks Mask
4K Sampler Encoder Tokens for Ultra High Resolution Image Prediction
FFN
C
ReLU ReLU
Linear Att Linear Att
ReLU Level 1 Level 2
Linear Att Token AGG Token AGG
Codebook
Fig.2. HoloHisto-4K backbone. To enable scalable encoding of ultra-high-resolution images
(4K),ourapproachusesapre-trainedconvolutionalVQGANtolearnthefromvisualpartsinto
discretetokens,thisdesignfollowsautoregressiveLVMthatenablescompressionwhileretaining
highperceptionquality.Weemployedmulti-scalelinearattentionasanefficientwaytocapture
longdiscretevisualtokensforhigh-resolutiondenseprediction.
theultra-high-resolutionimageatacompressionrate;(2)anefficientmulti-scaleatten-
tionmoduleforlongsequencerepresentationlearning.
3 Approach
Inthiswork,weproposeaholisticframeworkforsegmentinggigapixelWSI.Inaddi-
tion, to model ultra-high resolution representation for dense prediction, we propose a
modelarchitectureforhigh-qualityperceptionlearning:1)usethesequencetokeniza-
tion forlearning 4Kvisual partsat compressionscale; 2)train ViTblocks withlinear
multi-scaleattention.WesummarizeourapproachinFig2.
3.1 SequenceTokenization
To enable scalable modeling of ultra-high-resolution images while circumventing the
quadraticincreaseincomplexityassociatedwiththescan-lineorderofpatches,adis-
creteapproachisessential.Thismethodshouldefficientlyencodevisualelementsand
enablethesamplingofhigh-qualityperceptualrepresentationsfromaprobabilisticdis-
tribution.Inspiredbyneuraldiscreterepresentationlearning[32]andVectorQuantised
(VQGAN)[13],weemployanimagetokenizer.Thistokenizermapsinputimagestoa
semantic,discretetokencodebookthroughaquantizationlayer.Thistechniquecaptures
therichconstituentsofimages,effectivelyreducingtheexpressionlengthoforiginal4K
resolutionimages.Consequently,itenablesefficientmodelingofglobalinterrelations.
Let the given UHD input be denoted by x, which exists in the space RH′×W′×3.
Thisimagecanbedecomposedintoagridofcodebookvectorsz ,withinthedomain
enc
Rh′×w′×dz.Here,d
z
representsthenumberofdimensionsforeachcode.Weapproxi-
mateagivenimagexbyxˆ=G(z ).
q
Decoder OutputTitleSuppressedDuetoExcessiveLength 5
Real-time tiling I/O Async read of individual Per-tile kernel
4K tiles into GPU buffers
(a) Training G (4i 4g 8a 4p 6ix , e 4l 0 i 1n 0p 3u )t (b) Inference G (4i 4g 8a 4p 6ix , e 4l 0 m 10a 3sk )
Fig.3.TheholisticapproachforgigapixelWSIsegmentation.HoloHistotakestheentirekidney
slideimageasinput,itsupportsreal-timereadingofmulti-magnificationlevelsandtilesampling.
Intheinferencestage,HoloHistopresentsaglobalgigapixelsegmentationmaskasoutput.
To obtain z , we start with the encoding zˆ = E(x), which resides in the space
q
Rh′×w′×dz.Followingthis,weapplyanelement-wisequantizationq(·)toeachspatial
codezˆ
ij
withinRnz,aligningitwithitsnearestentryz k.Theprocessisformulatedas:
z =q(zˆ):=argmin∥zˆ −z ∥ (1)
q ij k
zk∈Z
wherez
q
∈Rh′×w′×dz
3.2 LinearMulti-ScaleAttention
High-resolution dense prediction models require strong representation learning capa-
bilitywithgoodefficiency.InsteadofwidelyusedSoftmaxattention[12],ReLUatten-
tion[23]provideslinearcomplexity,whichofferstheflexibilityofmulti-scalemodules
for high-resolution dense prediction. Following the efficientViT [4] design, we make
transformer blocks consisting of 2-stage multi-scale ReLU attention and FNN layers.
The3hierarchicalmulti-scaleReLUattentioncanbeexpressedas:
(cid:16) (cid:17)
ReLU(Q ) (cid:80)N ReLU(K )TV
i j=1 i j
A = (2)
i (cid:16) (cid:17)
ReLU(Q ) (cid:80)N ReLU(K )T
i j=1 j
(cid:16) (cid:17) (cid:16) (cid:17)
Thecalculationsfortheterms (cid:80)N max(0,K )TV and (cid:80)N max(0,K )T
j=1 j j j=1 j
needtobeperformedonlyonce.
3.3 HoloHisto:End-to-endframework
ThecompletepipelineoftrainingandinferenceisdemonstratedinFig3.
Training Paradigm. In prior studies [7,10], pathology image training has been per-
formedusingpre-croppedpatchesofafixedsizeoverselectedregionsofinterest(ROIs).
Thisofflinepreprocessing,usedbeforethetrainingandinferencephasesforgigapixel
images,resultsinthemodelrepeatedlylearningfromthesamepatchesineachepoch.In
thiswork,weintroducearandomsamplingparadigmfordigitalpathologyimageloader
Backbone
HoloHisto-4k6 AuthorsSuppressedDuetoExcessiveLength
based on the cuCIM4 multidimensional processing unit. During the training phase, a
foregroundmaskiscreatedusingathresholdingtechnique.Subsequently,werandomly
extract ROIs at a 4K resolution from the identified foreground areas. The dataloader
thencompilesadatasetfromoneorseveralwholeslideimages(WSIs).Asthenumber
oftrainingepochsincreases,theframeworkiscapableofsamplingavirtually”unlim-
ited”numberofpatchesfromtheWSIs.
Inference with WSI. During the inference stage, HoloHisto is capable of processing
the entire WSI. The dataloader seamlessly reads the designated magnification level
andisolatestheforegroundregionsthroughthresholding.Subsequently,HoloHistoper-
formstheforegroundtilingwithorwithoutoverlap,andloadsindividualtilesintoone-
dimensional GPU buffers, then positions them correctly within a pre-allocated GPU
array until predictions have been made for all tiles. Finally, the predicted masks for
each4KtilecanbeallocatedbackontotheWSIspace.
4 ExperimentsandResults
4.1 Datasets
KidneyPathologyImageSegmentation(KPIs).TheKPIschallengecohortincludes
60 high-resolution WSIs of whole mouse kidneys derived from 20 rodents, including
three CKD disease models in addition to normal kidneys. Tissues were stained with
PeriodicAcid-Schiff(PAS)andcapturedat40×magnificationusingtheLeicaSCN400
Slide Scanner. This diverse cohort allows for comprehensive analysis across different
CKD models and normal conditions, providing a rich dataset for advancing research
in renal pathology image segmentation. These WSIs are derived from four different
groupsofmousemodels,eachrepresentingadifferentconditionorstageofCKD.More
informationaboutKPISstudiesandannotationsisinthesupplementarymaterial.
NEPTUNE [2]. The public dataset consists of 1751 Region of Interest (ROI) images
that are extracted from 459 Whole Slide Images (WSIs) from 125 patients diagnosed
with Minimal Change Disease. These images underwent manual segmentation for six
structurallynormalpathologicalfeatures.Eachimageisat3000×3000resolution.
4.2 Experiments
WeconductacomparativestudyoftheproposedHoloHistointwodatasets:KPISand
the publicly available tissue segmentation NEPTUNE [2]. For the evaluation of KPIS
dataset, we present comparisons among conventional tile-based segmentation frame-
works and calculated metrics in each 4K patch. In addition, to show the effectiveness
of the WSI-level segmentation, we compute the Dice score on the entire WSI fore-
ground.Were-trainedbaselinemodelsincludingU-Nets[29],UNETR[19],swinunetr-
V2 [20],SegFormer [34], and SAM variants [24]. We choose these methods based on
groupsofCNN,transformerandfoundationalbackbones.
4https://developer.nvidia.com/cucim-for-image-io-processingTitleSuppressedDuetoExcessiveLength 7
Table1.SegmentationresultsoftheKPISdatasetontestingcases.ExceptHoloHisto,evaluations
ofWSIonbaselinemodelsareperformedusingpredictionsfromnon-overlappingtiles,which
aremappedbacktotheWSIspace.Dicesimilaritycoefficientscores(%)arereported.Thedif-
ferencebetweenthereference(Ref.)methodandbenchmarksforWSIisstatisticallyevaluated
byWilcoxonsigned-ranktest.
All
Method 56Nx DN NEP25 Normal
4KPatch-wise WSI Statistic.
U-Nets[21] 88.29 87.14 84.91 90.12 87.62 62.19 p<0.01
UNETR[19] 88.96 87.47 85.81 88.46 87.68 64.25 p<0.01
SegFormer[34] 88.58 89.86 89.97 90.33 89.69 65.01 p<0.01
DeepLabV3[6] 88.41 89.84 89.90 89.91 89.52 68.22 p<0.01
SwinUNETR-V2[20] 89.04 91.02 89.05 90.08 89.80 71.58 p<0.01
SAM-ViT-B[24] 89.98 90.19 90.13 90.23 90.13 75.19 p<0.01
SAM-ViT-H[24] 90.93 91.04 90.18 90.05 90.55 77.24 p<0.01
HoloHisto-4K 93.77 92.45 94.81 94.12 93.79 84.54 Ref.
Table 2. NEPTUNE segmentation performance. HoloHisto experiments are conducted under
3000×3000 according to the dataset’s original resolution. Dice similarity coefficient scores
(%)arereported.
Metrics DT PT CAP TUFT VES PTC Average
SAMViT-BBinary[24] 79.82 85.58 93.58 93.09 83.29 74.90 86.09
UNetmulti-scale[29] 81.11 89.85 96.70 96.66 85.03 77.19 87.76
DeepLabV3[6] 81.05 89.90 96.77 96.69 85.35 78.04 87.97
SwinUNETR-V2[20] 81.10 89.02 96.74 85.29 85.33 78.68 86.03
SAMViT-Bmulti-scale[24] 81.38 89.01 96.90 96.79 85.25 78.58 87.99
SAMViT-Hmulti-scale[24] 81.40 90.58 97.00 96.95 85.91 79.05 88.48
HoloHisto-4K 82.14 90.88 97.06 96.99 86.11 79.93 88.85
4.3 Ultra-highResolutionAnalysis
KPIS. Table1showsthequantitativeresultforthebinarysegmentationtaskofhigh-
resolution images in the KPIS dataset. We compared HoloHisto to various baselines
includingCNN,andTransformer-basedmethods.Weevaluatedthemetricsintwofor-
mats:1)calculateDicescoresunderthe4Kresolutionpatch,HoloHistoistrainedand
inferenced in 4K patch, baseline methods are performed in 1024 × 1024, which is
thebestscaleforSAMandothers.HoloHistoconsistentlyoutperformsstate-of-the-art
pathologysegmentationbackbone.Alongwiththeablationstudyonresolution,weob-
servethehigherresolutionpatchdimensions,thelargermarginisobtainedfromHolo-
Histo,indicatingtheeffectivenessofthehigh-qualityperceptionmodelingbroughtby
the tokenizer and efficientViT. In Table 3, we show the ablative experiments result of
componentsdesignofsequencetokenizerandReLUlinearattentioncomparedtolinear
projectionandmulti-headself-attention(MHSA)invanillaViT.
NEPTUNE. We conducted additional experiments on the existing public dataset NE-
TUNE.Among6differentscalesoftissues,HoloHistosurpassesbaselinemodelscon-
sistently.HoloHistoexperimentsareperformedin3000×3000atitslargestresolution
fromthedatasource,baselinesused1024×1024slidingwindowinferencefromtheir
besttrainingstrategy.TheDicescoresarereportedinTable2.8 AuthorsSuppressedDuetoExcessiveLength
Input Ground Truth U-Net SAM-ViT-B HoloHisto-4K HoloHisto WSI Seg
Fig.4. Kidney pathology segmentation qualitative results. We show the comparisons of three
differentapproachesfromCNN,ViT-basedSAMandourHoloHisto.Therightcolumnshows
HoloHisto’scapabilityofoutputtingtheentireWSIsegmentation.
Table3.AblationStudyofapproachmodules.Dicescoreof4ktilesandWSIsarereportedfor
ultra-highresolutionencoderandWSIhandlingconfigurations,respectively.
Ultra-highResolutionEncoder WSIHandling
Tokenizer ReLUAtt Sampler Resolution
LinearProj+MHSA 90.45 LinearProj+ReLUAtt 91.85 tilesampler 80.87 2K 79.41
Tokenizer+MHSA 92.94 Tokenizer+ReLUAtt 93.79 randsampler 84.54 4K 84.54
4.4 End-to-endPrediction
Comparison with pre-tiling In Table 3, the WSI handling section shows the results
of using a 4K random sampler with cuCIM and MONAI dataloader versus the tiling
strategy,weobservealargermarginofimprovementusingtheend-to-endframework.
ThevisualizationofcompleteWSIisshowninFig.4rightpanel.
5 DiscussionandConclusion
This work tackles the fundamental task of segmenting histopathology images, a task
that formerly relied on complex pipelines and was restricted to the analysis of small
patches.WeproposeaholisticapproachtosegmentgigapixelimageswithdirectWSI
I/O.Tomodeltheultra-highresolutionimageswithinloadedWSI,weproposetouse
asequentialtokenizer,whichencodesimagesasacompositionofperceptionpartsand
therebyavoidsthequadraticallyincreasedcomplexity.Inaddition,weevaluatethelin-
ear ReLU multi-scale attention instead of the Softmax attention for 4K UHD image
tokens. In experiments, we exhibit the first WSI-level segmentation via a 4K image
patch sampler and show the effectiveness and capability of HoloHisto-4K by outper-
formingstate-of-the-artapproaches.Towardsthedevelopmentofcutting-edgecompu-
tationalresearch,wealsoprovidethegold-standardpathologistannotateddatasetasa
WSIsegmentationbenchmark.
Limitation.Itisimportanttonotethatweemployedthenaturalimagepre-trained
sequencetokenizer,wherethelearnedcodebookisnotforhistopathologyimages.ItisTitleSuppressedDuetoExcessiveLength 9
stillratherchallengingtoachievepathologyLVM,limitingthemodelperformanceand
applicationtoWSIanalysis.Therefore,wewillcontinuetoexploregeneralistmodels
forpathologyvisiontasks.
References
1. Bai, Y., Geng, X., Mangalam, K., Bar, A., Yuille, A., Darrell, T., Malik, J., Efros, A.A.:
Sequential modeling enables scalable learning for large vision models. arXiv preprint
arXiv:2312.00785(2023)
2. Barisoni,L.,Nast,C.C.,Jennette,J.C.,Hodgin,J.B.,Herzenberg,A.M.,Lemley,K.V.,Con-
way,C.M.,Kopp,J.B.,Kretzler,M.,Lienczewski,C.,etal.:Digitalpathologyevaluationin
themulticenternephroticsyndromestudynetwork(neptune).ClinicaljournaloftheAmeri-
canSocietyofNephrology:CJASN8(8), 1449(2013)
3. Bueno,G.,Fernandez-Carrobles,M.M.,Gonzalez-Lopez,L.,Deniz,O.:Glomerulosclerosis
identification in whole slide images using semantic segmentation. Computer methods and
programsinbiomedicine184,105273(2020)
4. Cai,H.,Li,J.,Hu,M.,Gan,C.,Han,S.:Efficientvit:Lightweightmulti-scaleattentionfor
high-resolutiondenseprediction.In:ProceedingsoftheIEEE/CVFInternationalConference
onComputerVision.pp.17302–17313(2023)
5. Caron,M.,Touvron,H.,Misra,I.,Je´gou,H.,Mairal,J.,Bojanowski,P.,Joulin,A.:Emerging
propertiesinself-supervisedvisiontransformers.In:ProceedingsoftheIEEE/CVFinterna-
tionalconferenceoncomputervision.pp.9650–9660(2021)
6. Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous
separableconvolutionforsemanticimagesegmentation.arXiv:1802.02611(2018)
7. Chen,R.J.,Chen,C.,Li,Y.,Chen,T.Y.,Trister,A.D.,Krishnan,R.G.,Mahmood,F.:Scaling
vision transformers to gigapixel images via hierarchical self-supervised learning. In: Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
16144–16155(2022)
8. Chen, R.J., Krishnan, R.G.: Self-supervised vision transformers learn visual concepts in
histopathology.arXivpreprintarXiv:2203.00585(2022)
9. Chen,R.J.,Lu,M.Y.,Weng,W.H.,Chen,T.Y.,Williamson,D.F.,Manz,T.,Shady,M.,Mah-
mood, F.: Multimodal co-attention transformer for survival prediction in gigapixel whole
slideimages.In:ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVi-
sion.pp.4015–4025(2021)
10. Deng,R.,Liu,Q.,Cui,C.,Yao,T.,Long,J.,Asad,Z.,Womick,R.M.,Zhu,Z.,Fogo,A.B.,
Zhao, S., et al.: Omni-seg: A scale-aware dynamic network for renal pathological image
segmentation.IEEETransactionsonBiomedicalEngineering(2023)
11. Deng,R.,Liu,Q.,Cui,C.,Yao,T.,Yue,J.,Xiong,J.,Yu,L.,Wu,Y.,Yin,M.,Wang,Y.,
etal.:Prpseg:Universalpropositionlearningforpanoramicrenalpathologysegmentation.
arXivpreprintarXiv:2402.19286(2024)
12. Dosovitskiy,A.,Beyer,L.,Kolesnikov,A.,Weissenborn,D.,Zhai,X.,Unterthiner,T.,De-
hghani, M., Minderer, M., Heigold, G., Gelly, S., et al.: An image is worth 16x16 words:
Transformersforimagerecognitionatscale.In:InternationalConferenceonLearningRep-
resentations(2020)
13. Esser,P.,Rombach,R.,Ommer,B.:Tamingtransformersforhigh-resolutionimagesynthe-
sis.In:ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
pp.12873–12883(2021)
14. Feng, C., Liu, F.: Artificial intelligence in renal pathology: Current status and future.
BiomoleculesandBiomedicine23(2), 225(2023)10 AuthorsSuppressedDuetoExcessiveLength
15. Gadermayr,M.,Dombrowski,A.K.,Klinkhammer,B.M.,Boor,P.,Merhof,D.:Cnncascades
forsegmentingwholeslideimagesofthekidney.arXivpreprintarXiv:1708.00251(2017)
16. Gu,A.,Dao,T.:Mamba:Linear-timesequencemodelingwithselectivestatespaces.arXiv
preprintarXiv:2312.00752(2023)
17. Guo,J.,Hao,Z.,Wang,C.,Tang,Y.,Wu,H.,Hu,H.,Han,K.,Xu,C.:Data-efficientlarge
visionmodelsthroughsequentialautoregression.arXivpreprintarXiv:2402.04841(2024)
18. Hara,S.,Haneda,E.,Kawakami,M.,Morita,K.,Nishioka,R.,Zoshima,T.,Kometani,M.,
Yoneda, T., Kawano, M., Karashima, S., et al.: Evaluating tubulointerstitial compartments
inrenalbiopsyspecimensusingadeeplearning-basedapproachforclassifyingnormaland
abnormaltubules.PloSone17(7),e0271161(2022)
19. Hatamizadeh, A., Tang, Y., Nath, V., Yang, D., Myronenko, A., Landman, B., Roth,
H., Xu, D.: Unetr: Transformers for 3d medical image segmentation. arXiv preprint
arXiv:2103.10504(2021)
20. He,Y.,Nath,V.,Yang,D.,Tang,Y.,Myronenko,A.,Xu,D.:Swinunetr-v2:Strongerswin
transformerswithstagewiseconvolutions for3dmedicalimagesegmentation. In:Interna-
tional Conference on Medical Image Computing and Computer-Assisted Intervention. pp.
416–426.Springer(2023)
21. Isensee, F., Jaeger, P.F., Kohl, S.A., Petersen, J., Maier-Hein, K.H.: nnu-net: a self-
configuringmethodfordeeplearning-basedbiomedicalimagesegmentation.NatureMeth-
ods18(2),203–211(2021)
22. Israel,U.,Marks,M.,Dilip,R.,Li,Q.,Schwartz,M.S.,Pradhan,E.,Pao,E.,Li,S.,Pearson-
Goulart,A.,Perona,P.,etal.:Afoundationmodelforcellsegmentation.bioRxiv(2023)
23. Katharopoulos,A.,Vyas,A.,Pappas,N.,Fleuret,F.:Transformersarernns:Fastautoregres-
sivetransformerswithlinearattention.In:Internationalconferenceonmachinelearning.pp.
5156–5165.PMLR(2020)
24. Kirillov,A.,Mintun,E.,Ravi,N.,Mao,H.,Rolland,C.,Gustafson,L.,Xiao,T.,Whitehead,
S.,Berg,A.C.,Lo,W.Y.,etal.:Segmentanything.arXivpreprintarXiv:2304.02643(2023)
25. Kumar, N., Verma, R., Anand, D., Zhou, Y., Onder, O.F., Tsougenis, E., Chen, H., Heng,
P.A.,Li,J.,Hu,Z.,etal.:Amulti-organnucleussegmentationchallenge.IEEEtransactions
onmedicalimaging39(5),1380–1391(2019)
26. Ma, J., He, Y., Li, F., Han, L., You, C., Wang, B.: Segment anything in medical images.
NatureCommunications15(1), 654(2024)
27. Ma,J.,Xie,R.,Ayyadhury,S.,Ge,C.,Gupta,A.,Gupta,R.,Gu,S.,Zhang,Y.,Lee,G.,Kim,
J.,etal.:Themulti-modalitycellsegmentationchallenge:Towardsuniversalsolutions.arXiv
preprintarXiv:2308.05864(2023)
28. Oquab,M.,Darcet,T.,Moutakanni,T.,Vo,H.,Szafraniec,M.,Khalidov,V.,Fernandez,P.,
Haziza,D.,Massa,F.,El-Nouby,A.,etal.:Dinov2:Learningrobustvisualfeatureswithout
supervision.arXivpreprintarXiv:2304.07193(2023)
29. Ronneberger,O.,Fischer,P.,Brox,T.:U-Net:ConvolutionalNetworksforBiomedicalImage
Segmentation.In:MICCAI(2015)
30. Shen,T.,Zhang,Y.,Qi,L.,Kuen,J.,Xie,X.,Wu,J.,Lin,Z.,Jia,J.:Highqualitysegmen-
tation for ultra high-resolution images. In: Proceedings of the IEEE/CVF Conference on
ComputerVisionandPatternRecognition.pp.1310–1319(2022)
31. Tang, Y., Yang, D., Li, W., Roth, H.R., Landman, B., Xu, D., Nath, V., Hatamizadeh, A.:
Self-supervised pre-training of swin transformers for 3d medical image analysis. In: Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp.
20730–20740(2022)
32. VanDenOord,A.,Vinyals,O.,etal.:Neuraldiscreterepresentationlearning.Advancesin
neuralinformationprocessingsystems30(2017)TitleSuppressedDuetoExcessiveLength 11
33. Wang,J.,Liu,Z.,Zhao,L.,Wu,Z.,Ma,C.,Yu,S.,Dai,H.,Yang,Q.,Liu,Y.,Zhang,S.,
et al.: Review of large vision models and visual prompt engineering. Meta-Radiology p.
100047(2023)
34. Xie,E.,Wang,W.,Yu,Z.,Anandkumar,A.,Alvarez,J.M.,Luo,P.:Segformer:Simpleand
efficientdesignforsemanticsegmentationwithtransformers.AdvancesinNeuralInforma-
tionProcessingSystems34,12077–12090(2021)