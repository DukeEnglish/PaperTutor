Smart City Surveillance Unveiling Indian Person
Attributes in Real Time
Shubham Kale Shashank Sharma Abhilash Khuntia
M.Tech CSE M.Tech CSE M.Tech CSE
Dept. of CSE Dept. of CSE Dept. of CSE
IIIT Delhi IIIT Delhi IIIT Delhi
shubham23094@iiitd.ac.in shashank23088@iiitd.ac.in abhilash23007@iiitd.ac.in
Abstract—Thisprojectfocusesoncreatingasmartsurveillance public infrastructure usage, thereby facilitating more efficient
system for Indian cities that can identify and analyze people’s city operations [31] [17].
attributesinrealtime.Usingadvancedtechnologieslikeartificial
Ultimately, ”Smart City Surveillance Unveiling Indian Per-
intelligence and machine learning, the system can recognize
son Attributes in Real Time” endeavors to set a benchmark
attributes such as upper body color what the person is wearing,
accessories that he or she is wearing, headgear check, etc., for smart city initiatives, demonstrating how AI-driven tech-
and analyze behavior through cameras installed around the nologies can contribute to creating safer, more resilient, and
city. We have provided all our code for our experiments at inclusive urban environments in India [28] [29].
https://github.com/abhilashk23/vehant-scs-parWewillbecontin-
uously updating the above GitHub repo to keep up-to-date with
the most cutting-edge work on person attribute recognition. II. DATASET
The dataset provided for the VEHANT RESEARCH LAB
I. INTRODUCTION
challenge on ’Smart City Surveillance: Unveiling Indian Per-
Intoday’srapidlydevelopingworld,ensuringthesafetyand son Attributes in Real Time consists of around 600 images
security of citizens has become a concern for city administra- categorized under various attributes [19]. These attributes
tors. The project ”Smart City Surveillance Unveiling Indian encompass a variety of visual features, including colors and
Person Attributes in Real Time” addresses this challenge types of upper and lower body clothing, length of sleeves, ac-
by harnessing the power of artificial intelligence (AI) and cessoriescarried,typesoffootwear,poses,andviews[30][8].
machine learning (ML) to create a cutting-edge surveillance Data augmentation is crucial for computer vision tasks where
system. This system is tailored specifically for Indian cities, the dataset for a particular task is very low, so in this case,
where diverse populations and bustling urban environments we can perform various data augmentation techniques which
necessitate innovative solutions [27] [3] [13]. can help to upsample the dataset, thus building a more robust
Theprimaryobjectiveofthisprojectistodeployanetwork model[18][22][32].Forthepersonattributerecognitiontask,
of intelligent cameras with computer vision models capable we have used different augmentation techniques, which will
of not only monitoring, but also comprehensively analyzing helpinup-samplingthedataset[40][25]..Thetechniquesused
individual attributes in real time. These attributes include were:
but are not limited to upper body colors, clothing styles,
accessories,andvarioustypesofheadgearwornbyindividuals Parameter Value
RotationRange ±25degrees
[30] [8]. By leveraging AI algorithms, the system can detect
WidthShiftRange ±15%ofthetotalwidth
anomalies, identify suspicious behavior patterns, and provide HeightShiftRange ±15%ofthetotalheight
timely alerts to law enforcement agencies [24] [1]. ShearRange 0.5intensity
ZoomRange ±50%
Moreover, the project emphasizes the importance of pri-
HorizontalFlip Randomhorizontalflip
vacy and ethical considerations in the deployment of surveil- FillMode ’nearest’
lance technologies [16]. Robust measures are implemented
TABLEI
to ensure data protection, adherence to legal regulations, and
DATAAUGMENTATIONPARAMETERS
transparency in operations [5] [21]. Public engagement and
feedback mechanisms are also integral, fostering community
trust and collaboration in enhancing urban safety [26] [12].
III. METHODOLOGY
By integrating advanced data analytics and predictive mod-
eling, the system aims to not only mitigate security risks but Inourexperiment,weuseddataaugmentationtechniquesto
also optimize urban planning and resource management [35] expand our dataset. Initially, we had 600 images. Each image
[33]. Insights derived from real-time surveillance data can in- was augmented 12 times, considerably increasing the number
formcityplannersaboutcrowddynamics,trafficpatterns,and of samples for training our model [32] [25].
4202
luJ
3
]VC.sc[
1v50330.7042:viXraData augmentation is a crucial strategy that is used to Eachofthe15epochsusedfortrainingincludedseparatesteps
increase the diversity of our training data set without collect- forvalidationandtraining.Afterinputtingtheimagesintothe
ing new data. By applying transformations such as rotation, GPU for training, predictions were generated, and the loss
scaling,andflipping,wecreatednewimagesfromtheoriginal was computed using BCEWithLogitsLoss [7]. Subsequently,
set, thus enhancing the robustness of our model [38] [37]. the model parameters were fine-tuned using the Adam op-
timizer [14]. The training and validation processes involved
monitoring two key performance indicators (KPIs): accuracy
and loss [4].
C. Challenges with Initial Approaches
1) Overfitting: Thefirsttwoapproachestopersonattribute
recognition faced significant overfitting issues. Overfitting
occurs when a model performs well on the training data but
poorly on unseen validation or test data [10]. This typically
happens when the model learns to memorize the training data
rather than generalizing from it. Overfitting can be mitigated
by using techniques such as data augmentation, regularization
(e.g., dropout), and cross-validation [34].
2) ComputationallyIntensive: Theinitialmodelswerealso
Fig.1. ModelArchitectureandflowoftheproject
computationally intensive, which means they required a sig-
To ensure our model was evaluated effectively, we split the nificant amount of computational resources (GPU) and time
augmenteddatasetintotrainingandvalidationsets.Weapplied to train [4]. This can be due to various factors, such as:
an80-20split,where20%ofthedatawasusedforvalidation. • Large model size with many parameters [7].
Thismeansthatoutofthetotalnumberofaugmentedimages, • Inefficient data loading and preprocessing [23].
80%wasusedtotrainthemodel,and20%wasusedtovalidate
Toaddresstheseissues,wewentthroughthirdapproachbelow
it [7].
[9].
A. First Approach : D. Third Approach :
For person attribute recognition, we used the BEiT (Bidi- Intheinitialapproach,wefacedissueswithclassimbalance
rectional Encoder representation from Image Transformers) and overfitting. To overcome these, we include the Scaled-
modeloptimizedforpersonattributerecognition[2].Thetrain- BCELoss and FeatClassifier in this approach. The ”Scaled-
ing pipeline included data preparation, model initialization, BCELoss” fixes class imbalance by adjusting the weights
training, and validation. Augmented images and their labels of different attribute classes. This makes sure that learning
were loaded using PyTorch DataLoader for efficient batch from both common and rare attributes works well, which
processing [23]. The BEiT model and image processor were leads to better generalization and performance on data that
initialized with the HuggingFace transformers library has not been seen before [39]. The FeatClassifier combines
[36].TrainingwasconductedforfifteenepochswiththeAdam a pre-trained ResNet50 backbone with a custom classifier
optimizer at a learning rate of 1×10−5, using Binary Cross head,leveragingrobustfeatureextractionandtailoredattribute
Entropy with Logits Loss [14]. A custom callback calculated mapping. This enhances model accuracy and efficiency, and
label-based mean accuracy (mA) at each epoch’s end. The dropoutregularizationpreventsoverfitting,resultinginamore
model’s performance was evaluated on the validation set, and reliable performance on person attribute recognition model
the model with the lowest validation loss was retained for [11] [34].
further testing. figure 1 shows the flow of the project.
1. ScaledBCELoss
B. Second Approach :
The ScaledBCELoss class implements a custom binary
In our second approach, we leveraged cutting-edge deep cross-entropy loss function that scales the logits based on the
learning algorithms to classify images using the Swin Trans- frequency of each class in the dataset. This helps in balancing
former architecture [20]. We used the same augmentation the contribution of frequent and infrequent person attributes
techniques as in our previous strategy, and we used PyTorch’s to the loss, which is particularly useful in cases of class
DatasetandDataLoaderutilitiestomanagedataloadingwitha imbalance [39].
customImageDatasetclass[23].TheSwinTransformer,which
2. FeatClassifier
iswell-knownforitsstate-of-the-artperformance,waschosen
andcustomisedforourgoalusingthepre-trainedSwinForIm- TheFeatClassifierclasscombinesafeatureextractorback-
ageClassification model from the transformers library, which bone(inthiscase,aResNet50modelpre-trainedonImageNet)
was trained on ImageNet [6] [15]. The model’s compatibility with a custom classifier head. The backbone extracts high-
was ensured by using AutoImageProcessor for preprocessing. level features from the input images, and the classifier head(a fully connected layer) maps these features to the output includes capturing various scenarios, lighting condi-
classes (person attributes) [11]. tions,anddifferenttypesoffootwearandcarrieditems.
A diverse dataset will help the model generalize better
3. Training and Evaluation and improve accuracy across various attributes.
The train and evaluate function orchestrates the entire • Synthetic Data Generation: Using techniques such
training and evaluation process. It includes: as data augmentation and synthetic data generation
can help simulate different scenarios and augment the
• DataloadingandtransformationusingDataLoader[23].
existing dataset. This approach can provide the model
• Model initialization with a pre-trained ResNet50 back-
withmoreexamplestolearnfromwithouttheneedfor
bone [11].
extensive manual data collection.
• Loading pre-trained weights for fine-tuning [7].
• Defining the optimizer and learning rate scheduler [14]. 2) Advanced Machine Learning Techniques:
• Trainingloopwithmodelevaluationonthevalidationset • Transfer Learning: Implementing transfer learning
[10]. can enhance the model’s performance by leveraging
• Saving the best model based on validation accuracy [4]. pre-trained models on large, diverse datasets. This can
help the model learn more effectively from the limited
IV. CHALLENGES data available and improve its ability to recognize
IntheSmartCitySurveillanceproject,designedtounveilIn- specific attributes.
dianpersonattributesinrealtime,wefacedseveralsignificant • Fine-Tuning:Continuouslyfine-tuningthemodelwith
challenges that affected the model’s performance. A primary new data and incorporating feedback from real-time
issue was the scarcity of training images, which constrained deployments can help adapt the model to changing
the model’s ability to learn and generalize effectively across conditions and improve its accuracy over time.
various attributes. This limitation was particularly evident in 3) Model Architecture and Optimization:
themodel’sdifficultyinrecognizingspecificattributessuchas • Improved Architecture: Experimenting with
shoesanditemscarriedbyindividuals.Theinadequatedataset different model architectures and incorporating
for these attributes meant the model struggled to identify and state-of-the-art techniques can enhance the model’s
categorize them accurately. robustness and accuracy. Techniques like attention
Moreover, there was a noticeable performance discrep- mechanisms and convolutional neural networks
ancy between the static model and its real-time counterpart. (CNNs) can be explored to better capture and
While the static model performed admirably under controlled recognize fine-grained details.
conditions, its accuracy and reliability significantly dropped • Optimization for Real-Time Performance:
when deployed in real-time scenarios. This gap highlighted Optimizing the model for real-time performance
the model’s struggle to adapt to the dynamic nature of real- involves reducing latency and improving
timesurveillance,whichinvolvesconstantlychanginglighting computational efficiency. Techniques such as model
conditions,occlusionswherepartsofapersonmaybeblocked pruning, quantization, and using efficient neural
from view, and rapid movements. These real-world complex- network architectures can help achieve faster and
ities presented substantial challenges that the model was not more reliable real-time processing.
fully equipped to handle. 4) Real-Time Adaptability and Robustness:
The deployment phase also revealed that the model robust-
• Handling Variability: Developing algorithms that
ness needed improvement to achieve consistent performance
can handle variability in real-time conditions, such as
in real-time applications. This includes refining the model
changes in lighting, occlusions, and rapid movements,
architecture, enhancing its ability to process and analyze
is essential. This may involve incorporating adaptive
live video feeds, and implementing strategies to handle the
algorithms that can dynamically adjust to changing
variability and unpredictability of real-world environments.
environments.
Insummary,whiletheprojecthasmadesignificantprogress
• Continuous Learning: Implementing continuous
in developing a surveillance system capable of identifying
learning frameworks where the model can learn from
person attributes in real time, it faces ongoing challenges that
new data and experiences in real-time can help
require further research and development. Addressing these
improve its adaptability and robustness. This includes
challenges through data augmentation, advanced techniques,
using techniques like online learning and
andmodelrefinementwillbekeytoachievingamoreaccurate
reinforcement learning.
and reliable real-time surveillance system.
5) IntegrationwithAdditionalSensorsandDataSources:
V. SCOPEOFIMPROVEMENT • Multi-Modal Data Integration: Integrating data
from additional sensors, such as depth cameras,
1) Dataset Expansion and Diversification:
thermal cameras, and audio sensors, can provide
• Increase Quantity and Diversity: Acquiring a larger complementary information that enhances the model’s
andmorediversesetoftrainingimagesiscrucial.Thisability to recognize and understand person attributes.
• Contextual Information: Incorporating contextual
information, such as location data, time of day, and
historical patterns, can help improve the model’s
accuracy and provide more meaningful insights.
6) User Interface and Experience:
• Enhanced GUI: Improving the graphical user
interface (GUI) to be more intuitive and user-friendly
can facilitate easier interaction with the system.
Features like real-time alerts, detailed analytics, and
customization options can enhance the user
experience.
• Feedback Mechanisms: Implementing feedback
Fig.3. Train&ValidationLossVsEpochmodel2
mechanisms where users can provide input on the
model’s performance and flag inaccuracies can help
continuously refine and improve the model.
VI. EXPERIMENTALRESULTS
Sr.No Model mAVal Train Loss Val Loss Epoch
1 Model1 0.91 0.008 0.32 15
2 Model2 0.91 0.003 0.38 15
3 Model3 0.86 0.14 0.17 15
TABLEII
COMPARISONOFDIFFERENTMODELS
VII. RESOURCEUTILIZATION
Fig.4. Train&ValidationLossVsEpochmodel3
Model ComputationTime(seconds) DeviceType
Model1 52214.74 GPUP100 IX. FUTUREWORK
Model2 52327.79 GPUP100
Model3 1020.65 GPUP100 In the landscape of urban development, smart city surveil-
lance stands poised at the forefront of innovation, promising
TABLEIII
RESOURCEUTILIZATIONBYDIFFERENTMODELS transformative advancements in safety, efficiency, and com-
munity participation. As cities embrace interconnected tech-
nologies and data-driven solutions, the future of work within
smart city surveillance unfolds with distinct implications and
opportunities.
VIII. VISUALIZATION
• Public Health Monitoring:
– Epidemic Surveillance: In public areas, surveillance
devices can keep an eye on things like body tem-
perature, movement patterns, and crowd density. This
data can be analyzed to detect early signs of disease
outbreaks,allowingforpromptpublichealthresponses
and containment measures.
– Behavioral Analysis: Authorities can act swiftly and
efficientlybyrecognisingoddbehavioursortrendsthat
maypointtoemergenciesorhealththreatsbyanalysing
data from monitoring systems.
• Community Engagement:
– Transparency:Inordertointeractwiththepublic,cities
should be transparent about the data that is gathered,
Fig.2. Train&ValidationLossVsEpochmodel1 howitisused,andhowsurveillancetechnologieswork.
Policies that are transparent foster confidence andreassure the public about the appropriate application
of surveillance technologies.
– Education and Participation: Community support and
cooperationarefosteredbyinformingthepublicabout
the advantages of smart city surveillance, such as
increased safety and better urban services, and by
offering channels for public feedback and involvement
in decision-making processes.
• Crisis Response and Management:
– Social Media Integration: By combining social media Fig.7. Oursetupforliveprediction
analytics with surveillance data, authorities can better
assess public opinion during emergencies and respond
images and receive predictions from our model in figure
to community needs.
8. Here is the demo link.
– Drone Surveillance: Deploying drones with surveil-
lancecapabilitiestoquicklyanalyzethesituationfrom
the air during crises like fires, natural catastrophes, or
search and rescue missions.
X. MODELDEPLOYMENT
We have created a GUI using the model in our third
approach -
1) Live camera prediction: Created a GUI using Tkinter
which uses the device cam to give live predictions for
the labels Figure 5 & 6. The demo is shown below. The
image shown in figure 7 depicts our setup Live demo
link..
Fig.5. LivePrediction1
Fig.6. LivePrediction2
2) Static Prediction: We deployed our model on Hugging Fig.8. StaticPrediction1
Face and developed a GUI that enables users to uploadXI. CONCLUSION [17] AKumarandDPatel. Trafficpatternsincities. TrafficJournal,pages
45–55,2019.
In this study, we developed a comprehensive pipeline
[18] RKumarandPMehta. Imagedataaugmentationapproaches. Journal
for person attribute recognition, evaluating three distinct ap- ofComputerVision,pages78–89,2023.
proaches: BEiT, SWIN, and FeatClassifier. Our initial ex- [19] VehantResearchLab. Vehantresearchlabchallengedataset. Research
LabData,pages10–20,2021.
periments with the BEiT model incorporated advanced data
[20] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang,
augmentationtechniquesandanovelScaledBCELossfunction Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision
toaddressclassimbalance.WethenexploredtheSWINmodel, transformer using shifted windows. Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV), pages 10012–
a state-of-the-art architecture renowned for its performance
10022,2021.
in various vision tasks. However, the FeatClassifier, which [21] K Mehta and P Shah. Transparency in ai systems. Tech Ethics, pages
integrates a pre-trained ResNet50 backbone with a custom 30–42,2021.
[22] S Mir. Data augmentation techniques for computer vision. Journal of
classifier head, emerged as the most effective model. Its
AIResearch,pages123–134,2022.
superior performance can be attributed to dropout regulariza- [23] APaszke,SGross,FMassa,ALerer,JBradbury,GChanan,TKilleen,
tion that successfully mitigates overfitting and its pre-training Z Lin, N Gimelshein, L Antiga, et al. Pytorch: An imperative style,
high-performancedeeplearninglibrary.AdvancesinNeuralInformation
on the RAPv2 dataset, which is specifically comprised of
ProcessingSystems,pages1–12,2019.
pedestrian images. In contrast, the BEiT and SWIN models [24] V Patil and P Deshmukh. Surveillance in smart cities. Surveillance
were pre-trained on the ImageNet dataset, which contains a Review,pages78–88,2021.
[25] L Perez and J Wang. The effectiveness of data augmentation in
diverse range of images.
imageclassificationusingdeeplearning. JournalofMachineLearning
Our experimental results validate the FeatClassifier ap- Research,pages1–20,2017.
proach, demonstrating its strong potential for real-world ap- [26] R Ramesh and A Verma. Public engagement in smart cities. Urban
Affairs,pages78–89,2020.
plicationsinpersonattributerecognition.Movingforward,we
[27] A Rao and M Srivastava. Ai in smart cities. Journal of Urban
are excited about further enhancing our pipeline. Future work Technology,pages35–45,2018.
will involve implementing more sophisticated augmentation [28] BReddy. Aiinurbandevelopment. UrbanAI,pages33–44,2021.
[29] M Shah and K Desai. Smart city technologies. Smart City Journal,
strategies, experimenting with various backbone architectures,
pages15–25,2022.
and extending our model to recognize a wider array of [30] ASharmaandRGupta.Fashiontrendsinurbanindia.FashionJournal,
attributes.Additionally,weplantotestourapproachonlarger pages50–60,2020.
[31] N Sharma. Crowd dynamics in urban areas. Crowd Science, pages
and more diverse datasets to further confirm its robustness
20–30,2018.
and scalability. We are committed to advancing this project [32] CShortenandTMKhoshgoftaar.Asurveyonimagedataaugmentation
and look forward to achieving even greater milestones in the fordeeplearning. JournalofBigData,pages1–48,2019.
[33] P Singh. Urban resource management. Resource Management, pages
field of person attribute recognition.
55–65,2020.
[34] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever,
REFERENCES
and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural
[1] SAgarwal. Anomalydetectioninsurveillance. SecurityJournal,pages networksfromoverfitting.JournalofMachineLearningResearch,pages
98–108,2020. 1929–1958,2014.
[2] HBao,LDong,andFWei. Beit:Bertpre-trainingofimagetransform- [35] R Venkat. Data analytics in urban planning. Analytics Journal, pages
ers. arXivpreprintarXiv:2106.08254,pages1–13,2021. 89–99,2022.
[3] RBhargavaandSJain.Mltechniquesinurbanplanning.UrbanScience, [36] TWolf,LDebut,VSanh,JChaumond,CDelangue,AMoi,PCistac,
pages112–121,2019. T Rault, R Louf, M Funtowicz, et al. Transformers: State-of-the-art
[4] JBrownlee.Accuracyandperformanceindeeplearning.DeepLearning natural language processing. Proceedings of the 2020 Conference on
Journal,pages15–25,2019. Empirical Methods in Natural Language Processing: System Demon-
[5] S Das and V Rao. Legal regulations in ai surveillance. Law Journal, strations,pages38–45,2020.
pages40–50,2021. [37] S Yun, D Han, S Oh, S Chun, J Choe, and Y Yoo. Cutmix: Regu-
[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei- larization strategy to train strong classifiers with localizable features.
Fei. Imagenet: A large-scale hierarchical image database. 2009 IEEE InternationalConferenceonComputerVision,pages1–10,2019.
Conference on Computer Vision and Pattern Recognition, pages 248– [38] H Zhang, M Cisse, Y Dauphin, and D Lopez-Paz. Mixup: Beyond
255,2009. empirical risk minimization. International Conference on Learning
[7] IGoodfellow,YBengio,andACourville. Deeplearning. MITPress, Representations,pages1–13,2018.
pages1–775,2016. [39] Z Zhang. Imbalanced classification of images. Journal of Machine
[8] N Gupta and A Patel. Use of accessories in urban areas. Accessory LearningResearch,pages45–60,2018.
Review,pages23–34,2019. [40] Y Zhu and L Wang. Data augmentation for object detection. IEEE
[9] Song Han, Jeff Pool, John Tran, and William Dally. Deep learning.
TransactionsonImageProcessing,pages10–20,2020.
arXivpreprintarXiv:1506.02626,pages1–10,2015.
[10] T Hastie, R Tibshirani, and J Friedman. The elements of statistical
learning. Springer,pages1–745,2009.
[11] K He, X Zhang, S Ren, and J Sun. Deep residual learning for image
recognition. Proceedings of the IEEE Conference on Computer Vision
andPatternRecognition,pages770–778,2016.
[12] AJain.Communitytrustinai.CommunityJournal,pages34–45,2019.
[13] MKhan.Diversityinindiancities.CulturalStudies,pages15–26,2021.
[14] DP Kingma and J Ba. Adam: A method for stochastic optimization.
arXivpreprintarXiv:1412.6980,pages1–15,2014.
[15] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet
classification with deep convolutional neural networks. Advances in
neuralinformationprocessingsystems,25:1097–1105,2012.
[16] PKulkarni. Privacyconcernsinai. AIEthics,pages12–23,2022.