GMM-RESNEXT:COMBININGGENERATIVEANDDISCRIMINATIVEMODELSFOR
SPEAKERVERIFICATION
HuiYan,ZhenchunLei*,ChanghongLiu,YongZhou
SchoolofComputerandInformationEngineering,JiangxiNormalUniversity,Nanchang,China
ABSTRACT remarkable performance. For CNN-based ASV systems, Zeinali
et al. [5] firstly used Residual Networks (ResNet) [6] in image
Withthedevelopmentofdeeplearning,manydifferentnetworkar-
recognitionasspeakerembeddingextractorinVoxSRC2019. Liu
chitectures have been explored in speaker verification. However,
etal. [7]proposedResNetbasedonsequentialandparallelfeature
mostnetworkarchitecturesrelyonasingledeeplearningarchitec-
attention fusion mechanism, which uses attention mechanism to
ture, and hybrid networks combining different architectures have
learnfusionweightsbasedonfeaturecontent,therebydynamically
beenlittlestudiedinASVtasks.Inthispaper,weproposetheGMM-
integratingidentitymappingfeaturesandresiduallearningfeatures.
ResNext model for speaker verification. Conventional GMM does Chenetal.[8]proposedanenhancedRes2Net,whichusesattention
not consider the score distribution of each frame feature over all
fusion module to fuse features in a residual block to extract local
Gaussian components and ignores the relationship between neigh-
signals, and fuse features of different scales to aggregate global
boring speech frames. So, we extract the log Gaussian probabil-
signals.ForTDNN-basedASVsystems,x-vectorproposedbySny-
ity features based on the raw acoustic features and use ResNext-
der et al. [9] employed TDNN to map variable-length speech to
based network as the backbone to extract the speaker embedding.
fixed-length speaker embedding for the first time, and used PLDA
GMM-ResNextcombinesGenerativeandDiscriminativeModelsto
back-endmodeltocomparesimilarityofapairofspeakerembed-
improve the generalization ability of deep learning models and al-
dings. Desplanques et al. [10] proposed ECAPA-TDNN based
lows one to more easily specify meaningful priors on model pa-
on Squeeze-Excitation (SE) [11] module and Res2Net[12], which
rameters. Atwo-pathGMM-ResNextmodelbasedontwogender-
achievestheequalerrorratesoflessthan1%inVoxCeleb-Otestset.
related GMMs has also been proposed. The Experimental results
Thienpondtetal. [13]proposedECAPACNN-TDNN,whichintro-
show that the proposed GMM-ResNext achieves relative improve-
ducesa2-DconvolutionintoECAPA-TDNNtotransfersomestrong
ments of 48.1% and 11.3% in EER compared with ResNet34 and
characteristics of ResNet to this hybrid CNN-TDNN architecture,
ECAPA-TDNNonVoxCeleb1-Otestset.
andachievesbetterresultsonVoxCeleb-Otestset. Zhaoetal. [14]
Index Terms— speaker verification, ResNext, GMM, genera- proposedtosegmenttheinputspectralmapintoseveralfrequency
tivemodel,discriminativemodel bandsanduseprogressivechannelfusionstrategytograduallyfuse
thesebandstoimprovetheECAPA-TDNN.
Althoughtheembeddingextractorsmentionedaboveshowex-
1. INTRODUCTION
cellent performance in ASV task, they only rely on a single deep
learning architecture. In the filed of ASV, Alam et al. [15] pro-
The task of Automatic Speaker Verification (ASV) [1] is to verify
posedahybridneuralnetwork(HNN)architecturewithCross-and
theidentityofspeakersbyusingspeakerspeechasfeature. Fortwo
Self-moduleAttentionpoolingmechanismsforspeakerverification.
givenutterances,atypicalASVsystemcanextractspeakerembed-
Wang et al. [16] proposed MACCIF-TDNN, which is a series of
dingsofthemandautomaticallydeterminewhethertheybelongto
residual networks and transformers. Wang et al. [17] proposed a
thesamespeakerornot. TheprocedureofamodernASVsystem
Parallel-coupledTDNN/TransformerNetwork(p-vectors)toreplace
generallyconsistsofacousticfeatureextraction,speakerembedding
the serial hybrid networks. In the field of speech deepfake detec-
extractionandsimilarityscoring.Thepurposeofacousticfeatureex-
tion, Lei et al. [18] proposed GMM-Transformer, which is a fu-
tractionistotransformawaveformofspeechintoacousticfeatures,
sionofGaussianMixtureModel(GMM)anddeepneuralnetwork,
suchasFilter-Banks,MelFrequencyCepstralCoefficients(MFCCs)
andachievesexcellentdetectioneffectinthespeechdeepfakedetec-
andspectrograms.Speakerembeddingextractionistoextractfixed-
tionlogicalaccesstask. Wenetal. [19]alsoproposedmulti-branch
length speaker embeddings from variable-length utterances. Simi-
GMM-MobileNetmodelbasedondifferentdataaugmentationand
larity scoring aims to calculate the similarity between test speaker
attack methods. However, hybrid networks that combine conven-
embeddingandenrollmentspeakerembedding.
tionalmachinelearningmethodswithpopulardeeplearningmeth-
The conventional generative models such as Gaussian mixture
odshavebeenrarelystudiedinASVtasks.
model-UniversalBackgroundModel(GMM-UBM)[2]andi-vector
[3] with Probabilistic Linear Discriminant Analysis (PLDA) [4] The Gaussian Mixture Model accumulates the scores on all
were main method in the field of ASV. With the development of framesindependently,anddoesnotseparatelyconsiderthescoresof
deep learning techniques, these models have been gradually re- featureframesoneachGaussiancomponent. Inaddition,theGMM
placed by Deep Neural networks (DNNS). Now, more and more ignores the relationship between adjacent speech frames along the
DNN-basedmodelswereappliedtoASVtasks. Especiallyr-vector timedimension. Inthispaper,weproposetheGMM-ResNextthat
structuresbasedonconvolutionneuralnetwork(CNN)andx-vector appliestheGaussianprobabilityfeaturesasinputforspeakerverifi-
architecturesbasedonTimeDelayNeuralNetwork(TDNN)shown cation. ThenourproposedGMM-ResNextconcatenatestheoutput
feature maps from last layer in each stage to aggregate the multi-
*Correspondingauthor layer representations before final pooling. On the other hand, the
4202
luJ
3
]DS.sc[
1v53130.7042:viXraFig.1.TheoverallarchitectureofGMM-ResNext
specificityofmalespeechfeaturesandfemalespeechesfeaturesis traction ability. However, with the increase of the number of lay-
usefulformodelingthefeaturedistributionofspeech.Thereforewe ers in the network, the problem of gradient explosion or gradient
propose the dual-path GMM-ResNext(dGMM-ResNext) based on disappearanceorevennetworkdegradationwillappearinthetrain-
thedifferentgenders. ing process. In order to solve the above problems, the ResNet [6]
employs shortcut connections to fusion the identity mapping fea-
tures and the residual learning features to improve the stability of
2. LOGGAUSSIANPROBABILITYFEATURE
the model. In ResNet, the number of parameters in the model is
The GMM is a conventional speaker recognition classifier. For a mainlyadjustedbydepthandwidth.Inpractice,weusuallyfindthat
speech feature vector, the GMM sums the probability density val- directly increasing the depth or width of the model is ineffective,
uesofNGaussiancomponents,butdoesnotconsiderthescoredis- andeasilycauseoverfittingproblemsduetothelargenumberofpa-
tributionofeachGaussiancomponentseparately. Therelationship rameters.TheResNext[20]thatincludesthegroupedconvolutional
betweenadjacentspeechframesisignored.Fortheinformationdis- layercalledasplit-transform-mergestrategyinblocksisdesignedto
tributions of speeches of different speakers are different in feature easythisproblemandimprovetherepresentationabilityofResNet
space,theirscoredistributionsonallGaussiancomponentsarealso model. TheResNexthasachievedreliableperformanceinSV[21],
different.Therefore,thisscoredistributioninformationishelpfulfor soweproposedtheGMM-ResNextmodelthatfusestheGMMand
speakerverification.TheGMMtakestherawacousticfeatureasin- ResNextforspeakerverification. Theoverallarchitectureisshown
putandoutputstheLogGaussianProbability(LGP)feature.ForaD inFigure1.
dimensionalinputfeaturex(MFCCinourexperiments),theelement TheproposedGMM-ResNextmodelconsistsofaGMMmod-
y oftheLGPfeatureyisdefinedas: ule, a ResNext backbone with four residual stages, An attention
i
statisticspooling(ASP)layerwithMulti-layerFeatureAggregation
y i =logp i(x) (MFA),andafullyconnectedlayer. Encouragedby[22]proposed
1 1 design principles, we adjusted the number of blocks in each stage
=log exp{− (x−µ )′Σ−1(x−µ )}
(2π)D/2|Σ |1/2 2 i i i from (3, 4, 6, 3) to (3, 3, 9, 3), which is different from the origi-
i
nal stage ratio in the residual network. BN stands for Batch Nor-
1
=− 2x′Σ− i 1x+x′Σ− i 1µ i+C (1) malizationandtheRectifiedLinearUnits(ReLU)isthenon-linear
activationfunction.
wherep i(x)istheprobabilitydensityfunctionofthei-thGaussian Tofurtherreducethenumberofparametersinthemodel,weuse
component,whichisparameterizedbyaD×1meanvector,µ iand depthwiseconvolutioninsteadofgroupedconvolutioninResNext,
aD×Dcovariancematrix,Σ i. which is a special case of grouped convolution where the number
Inordertoreducecomputation,theconstanttermC canbere- ofgroupsequalsthenumberofchannels. ThestructureoftheDW-
moved. Afterthat,themeanmean yi andstandarddeviationstd yi ResBlockmoduleisshowninFigure2.Themoduleconsistsoftwo
offeaturesintrainingdataarecomputed,whichareusedformean convolutionallayerswithfiltersizeof1,1Ddepthwiseconvolutional
andvariancenormalization. layer with filter size of 3, SE block, and BN and ReLu after the
y −mean convolutionallayer.IntheSEBlock,thedimensionofthebottleneck
y′ = i yi (2)
i std issetto1/4ofthenumberofinputchannel.
yi
Previousstudies[23]haveshownthattheshallowfeaturemaps
indeepneuralnetworksalsofacilitatetheextractionofmorerobust
3. PROPOSEDMETHOD
speakerembeddings. In[10], theECAPA-TDNNconcatenatesthe
Inthissection,wedescribedetailsoftheproposedGMM-ResNext outputfeaturesofallSE-Res2Netblocks,andthenusesadenselayer
modelanddual-PathGMM-ResNext. toprocesstheconnectedfeatureinformationtogeneratetheinputof
thepoollayer. Zhangetal. [24]proposedMFA-Conformermodel
thatconcatenatestheoutputfeaturesofeachConformerblock,and
3.1. GMM-ResNext
then feed them into a LayerNorm layer. This aggregation method
TheCNN-basedmodeliswidelyusedasthebackbonenetworkof resultsinaobviousperformanceimprovement. Influencedbythese
various machine learning tasks because of its stronger feature ex- studies,wealsoconcatenatestheoutputfeaturemapsofallstagestoFig.3. Thearchitectureofdual-pathGMM-ResNextbasedonmale
GMMandfemaleGMM.
loss function. The training method is the same as that of the one-
pathmodel.Inthesecondstep,weremovetheirclassifiersandcon-
catenatethespeakerembeddingsofthetwobranchesintoonefully
connectedlayertogeneratethefinalspeakerembedding. Thenwe
freezetheparametersofalllayersofthedual-dualResNextexcept
theclassifiertotrainthefullyconnectedlayerandtheclassifier.
4. EXPERIMENTALSETUP
Fig.2.ThearchitectureofDWResBlock.Thenumbersinparenthe-
sesrefertokernelsize,stride,andnumberofchannel.
4.1. Dataset
TheexperimentsareconductedonVoxCeleb1[26]andVoxCeleb2
generatemulti-levelinputfeaturesofthepooledlayerbeforeaBN
[27] dataset. They include a development set and a test set. Vox-
layer.
Celeb2 development set is used for training, which consists of
H =BatchNorm(Concat(h ,h ,...,h )) (3) 109,200,9 utterances from 599,4 speakers. The whole VoxCeleb1
1 2 L
dataset is used as the testing data, which contains over 100,000
Whereh ∈RC×T representstheoutputfeatureoflastlayerineach utterances from 125,1 speakers. The performance of all models
i
stageandH ∈ RC×T. Concatisaconcatenationoperation. Lis are evaluated on three different test trials, namely VoxCeleb1-O,
thenumberofstagesandD=C×T. VoxCeleb1-EandVoxCeleb1-H.Inaddition, toincreasethediver-
After aggregating the output features of the different residual sity of the original training data, we employed data augmentation
blocks,weusetheASPtocapturetheweightcoefficientsthatrepre- duringtraining,addingnoiseusingtheMUSANdataset[28],simu-
sentstheimportanceofeachframe. Theoutputofthepoolinglayer latingreverberationusingtheRIRdataset[29].
isgivenbyconcatenatingtheweightedmeanvectorandtheweighted
standarddeviationcalculatedbytheweightcoefficient. Finally,We
usethefullconnectionlayertoprojectthepooledvectorintoalow-
4.2. Implementationdetails
dimensionalspeakerembedding.
Forfaircomparison,were-implementedr-vectorin[5]andECAPA-
3.2. Dual-pathGMM-ResNext
TDNNin[10]asthebaselines.Ther-vectorincludesResNet18and
Improvingthegeneralizationabilityofspeakerverificationisagreat ResNet34withchannelsofresidualblockssetas{32,64,128,256}.
challenge.Thespeechfromspeakersofdifferentgendershasdiffer- ECAPA-TDNNconsistsofabasicmodelwith512channelsanda
entfeaturedistribution. TheconventionalGMMdescribesthecom- large model with 1024 channels. The PyTorch framework is used
moninformationdistribution. ButtheGMMdoesnotpayattention toimplementthebaselineandtheproposedmodels. Afixedlength
tothedifferencebetweenmaleandfemalespeeches,whichisuse- 2-secondsegmentsareextractedrandomlyfromeachutterance. We
fultomodelinformationdistributionofspeechfromdifferentgen- use80-dimensionalMFCCswithawindowlengthof25msanda
ders.Soweproposeadual-patharchitecturewithResNext(dGMM- frameshiftof10ms. MeannormalizationisappliedtotheMFCCs
ResNext)forspeakerverification,whichisconstructedaccordingto features before input network. The GMM implemented by MSR
twoGMMstrainedbymalespeechesandfemalespeeches. IdentityToolbox[30]wastrainedfor30iterations. Adamoptimizer
Figure 3 shows the dual-path GMM-ResNext which contains withaninitiallearningrateof0.001isusedduringthetrainingpro-
two networks with same architecture. The LGP features are ex- cess. Thelearningrateisreducedby3%everyoneepoch. Weuse
tractedontwoGMMs,whicharetrainedonmalespeechesandfe- additivemarginsoftmax(AAM-softmax)[31]losswithamarginof
malespeechesfromtrainingset. Theembeddingvectorsfromtwo 0.2 and a scale factor of 30 to train all models. In order to avoid
pathsareconcatenatedandinputtedtothefullyconnectedlayer.Fi- overfitting,theweightdecayissetto2e-5. IntheASP,thedimen-
nally,thespeakerembeddingareoutputfromthelastfullyconnected sionofthebottleneckissetto128. Thebatchsizeis200andthe
layer. sizeofspeakerembeddingsis256. Allmodelsaretrainedfor100
Multi-steptrainingscheme[25]isusuallyusedtosolvetheprob- epochs.
lem of model overfitting. Considering the large number of model In the evaluation phase, we use the cosine similarity between
parameters,atwo-steptrainingmethodisadoptedtoimprovethero- embeddings for scoring. the Equal Error Rate (EER) and mini-
bustnessofmodel.Inthefirststep,thetwobranchesofthedual-path mumDetectionCostFunction(minDCF)withp = 0.01and
target
ResNextmodelaretrainedindependentlyusingtheAAM-softmax C =C =0.01willbereportedforperformanceevalution.
FA MissTable1.EERandMinDCFresultsofallmodelsonthestandardVoxCeleb1testset.
VoxCeleb1-O VoxCeleb1-E VoxCeleb1-H
Model
EER(%) MinDCF EER(%) MinDCF EER(%) MinDCF
ResNet18[5] 1.97 0.2502 2.15 0.2445 3.94 0.3659
ResNet34[5] 1.81 0.2108 1.92 0.2183 3.46 0.3379
ECAPA-TDNN(512)[10] 1.22 0.1455 1.41 0.1609 2.59 0.2555
ECAPA-TDNN(1024)[10] 1.06 0.1310 1.32 0.1495 2.49 0.2532
CA-HNN[15] 1.38 - 1.62 - 2.86 -
CSA-HNN[15] 1.32 - 1.53 - 2.79 -
MACCIF-TDNN[16] 1.19 0.148 1.47 0.158 2.48 0.235
P-vector[17] 0.85 0.1199 1.11 0.1201 2.11 0.2081
GMM-ResNext(256) 1.35 0.1430 1.54 0.1741 2.84 0.2697
GMM-ResNext(512) 0.96 0.1168 1.20 0.1424 2.31 0.2247
dGMM-ResNext(256) 1.18 0.1478 1.33 0.1537 2.48 0.2387
dGMM-ResNext(512) 0.94 0.1100 1.13 0.1298 2.18 0.2207
5. RESULTSANDANALYSIS strategy. It can be observed from the experiment results that both
GMMlayerandmulti-layerfeatureaggregationmoduleplayakey
5.1. ResultsonVoxCelebtestset roleinimprovingtheperformance. TheGMMlayerreducesEER
andminDCFby21.3%and19.3%relatively. Andaggregatingthe
Table1showstheEERandtheMinDCfofthebaselinesandthepro-
outputofallblocksbrings16.5%and21.2%relativeimprovement
posed models on the VoxCeleb1-O, VoxCeleb1-E and VoxCeleb1-
inEERandminDCF.Atthesametime,thetwosteptrainingstrategy
H datasets. Compared with GMM-ResNext(256), the GMM-
furtherimprovesthegeneralizationabilityofthedGMM-ResNext.
ResNext(512)obtainstherelativeimprovementsinEERby28.8%,
22.1%, 18.7% and in MinDCF by 18.3%, 18.2%, 16.7%. The
dGMM-ResNext(512) also obtains similar performance improve-
Table2. AblationexperimentsonVoxCeleb1-O.2S:Thetwostep
ments compared with dGMM-ResNext(256). It can be observed
trainingstrategy.
thatwhenthenumberofGaussiancomponentsincrease,theGMM-
Vox1Celeb-O
ResNext can achieve better performance. This may be due to the Model
factthatGaussianprobabilityfeaturescontainmoredistinguishing EER(%) MinDCF
speakerinformation.
ResNext(512) 0.96 0.1168
ComparedwithGMM-ResNext(256),thedGMM-ResNext(256)
w/oGMM) 1.22 0.1447
obtainstherelativeimprovementsinEERby12.6%,13.6%,12.7%
w/oMFA) 1.15 0.1483
on the VoxCeleb1 test set. The dGMM-ResNext(512) further im-
proves improvement compared with GMM-ResNext(512). The dGMM-ResNext(512) 0.94 0.1100
dGMM-ResNext(512) obtains the best results, which relatively re- w/o2S 1.04 0.1172
ducestheEERby48.1%,41.1%,37.0%andtheMinDCFby47.8%,
40.5%,34.7%comparedwiththeResNet34,andrelativelyreduces
the EER by 11.3%, 14.4%, 12.4% and the MinDCF by 16.0%,
13.2%,12.8%comparedwiththeECAPA-TDNN(1024). 6. CONCLUSION
Compared with other HNN systems, such as CA-HNN, CSA-
Inthispaper,weproposedtheGMM-ResNextmodelthatcombines
HNNandMACCIF-TDNN,thedGMM-ResNext(512)alsoachieves
conventionalmachinelearningmethodswithdeeplearningmethods
competitiveresults.ButtheperformanceofthedGMM-ResNext(512)
for speaker verification. First, the proposed model uses Gaussian
isworsethanP-vector. ThereasonmaybethatP-vectorleverages
probabilityfeaturesastheinputoftheresidualnetwork. Then,the
theconvolutionaloperationsandtheattentionmechanismtointeract
outputfeaturemapsofthefourstagesareaggregatedtointegratethe
andaggregatethelocalandglobalinformation.
multi-levelfeatures,soastoobtainmoredistinguishablespeakerin-
formation. We also proposed the dual-path GMM-ResNext model
5.2. Ablationexperiments
based on different genders to improve the generalization ability of
To evaluate the role of key modules, we conduct ablation experi- themodel. ExperimentsontheVoxCelebdatasetshowthatthepro-
ments to study the effect of each modules contributing to perfor- posed dGMM-ResNext model is significantly superior to the cur-
manceimprovements. Table2showstheresultsoftheablationex- rentlypopularResNetandECAPA-TDNNmodels. Infuturework,
periments on VoxCeleb1-O test set. The first line is the results of wewillexplorenewnetworkarchitecturesfusedwithGaussianmix-
theGMM-ResNext(512). Inthesecondline,weremovetheGMM turemodel.
layerandusetheMFCCfeatureinsteadofthelog-Gaussianprob-
abilistic feature as the input of the network. In the third line, the 7. ACKNOWLEDGEMENTS
MFA layer isremoved and only the output feature mapof the last
residualblockisused.TheresultsinthefourthlinearethedGMM- ThisworkissupportedbyNationalNaturalScienceFoundationof
ResNext(512).Inthelastline,wedoesnotusethetwosteptraining China(62067004).8. REFERENCES [16] FangyuanWang,ZhigangSong,HongchenJiang,andBoXu,
“Maccif-tdnn:Multiaspectaggregationofchannelandcontext
[1] ZhongxinBaiandXiaoLeiZhang,“Speakerrecognitionbased interdependence features in tdnn-based speaker verification,”
ondeeplearning:Anoverview,” NeuralNetworks,pp.65–99, in2021IEEEAutomaticSpeechRecognitionandUnderstand-
2021. ingWorkshop(ASRU),2021,pp.214–219.
[2] Douglas A. Reynolds, Thomas F. Quatieri, and Robert B. [17] Xiyuan Wang, Fangyuan Wang, Bo Xu, Liang Xu, and Jing
Dunn, “Speaker verification using adapted gaussian mixture Xiao, “P-vectors: A parallel-coupled tdnn/transformer net-
models,” DigitalSignalProcessing,pp.19–41,2000. workforspeakerverification,” inProc.INTERSPEECH2023,
[3] Kenny P. J. Dehak R. Dumouchel P. Ouellet P Dehak, N., 2023,pp.3182–3186.
“Front-end factor analysis for speaker verification,” Audio, [18] ZhenchunLei,HuiYu,YingenYang,andMingleiMa,“Atten-
Speech,andLanguageProcessing,IEEETransactionson,pp. tionnetworkwithgmmbasedfeatureforasvspoofingdetec-
p.788–798,2011. tion,” BiometriRecognition,Cham,pp.458–465,2021.
[4] Sergey Ioffe, “Probabilistic linear discriminant analysis,” in
[19] Yan Wen, Zhenchun Lei, Yingen Yang, Changhong Liu, and
EuropeanConferenceonComputerVision,2006,pp.531–542.
MingleiMa, “Multi-PathGMM-MobileNetBasedonAttack
[5] Hossein Zeinali, Shuai Wang, Anna Silnova, Pavel Mateˇjka, Algorithms and Codecs for Synthetic Speech and Deepfake
and Oldich Plchot, “But system description to voxceleb Detection,” inProc.Interspeech2022,2022,pp.4795–4799.
speakerrecognitionchallenge2019,” 2019.
[20] Saining Xie, Ross Girshick, Piotr Dollar, Zhuowen Tu, and
[6] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Kaiming He, “Aggregated residual transformations for deep
“Deep residual learning for image recognition,” in 2016 neural networks,” in Computer Vision and Pattern Recogni-
IEEEConferenceonComputerVisionandPatternRecognition tion,2017.
(CVPR),2016,pp.770–778.
[21] TianyanZhou,YongZhao,andJianWu, “Resnextandres2net
[7] BeiLiu,ZhengyangChen,andYanminQian, “AttentiveFea- structureforspeakerverification,” 2020.
ture Fusion for Robust Speaker Verification,” in Proc. Inter-
[22] Zhuang Liu, Hanzi Mao, Chao Yuan Wu, Christoph Feicht-
speech2022,2022,pp.286–290.
enhofer, TrevorDarrell, andSainingXie, “Aconvnetforthe
[8] Yafeng Chen, Siqi Zheng, Hui Wang, Luyao Cheng, Qian 2020s,” arXive-prints,2022.
Chen, and Jiajun Qi, “An enhanced res2net with local and
[23] Zhifu Gao, Yan Song, Ian McLoughlin, Pengcheng Li, Yi-
global feature fusion for speaker verification,” in Proc. IN-
heng Jiang, and Li-Rong Dai, “Improving Aggregation and
TERSPEECH2023,2023,pp.2228–2232.
LossFunctionforBetterEmbeddingLearninginEnd-to-End
[9] David Snyder, Daniel Garcia-Romero, Gregory Sell, Daniel SpeakerVerificationSystem,”inProc.Interspeech2019,2019,
Povey,andSanjeevKhudanpur, “X-vectors: Robustdnnem- pp.361–365.
beddings for speaker recognition,” in 2018 IEEE Interna-
[24] Yang Zhang, Zhiqiang Lv, Haibin Wu, Shanshan Zhang,
tionalConferenceonAcoustics,SpeechandSignalProcessing
Pengfei Hu, Zhiyong Wu, Hung yi Lee, and Helen Meng,
(ICASSP),2018,pp.5329–5333.
“MFA-Conformer: Multi-scale Feature Aggregation Con-
[10] BrechtDesplanques,JentheThienpondt,andKrisDemuynck, former for Automatic Speaker Verification,” in Proc. Inter-
“ECAPA-TDNN:EmphasizedChannelAttention,Propagation speech2022,2022,pp.306–310.
and Aggregation in TDNN Based Speaker Verification,” in
[25] JeeweonJung,HeesooHeo,ILhoYang,HyejinShim,and
Proc.Interspeech2020,2020,pp.3830–3834.
HajinYu,“AvoidingSpeakerOverfittinginEnd-to-EndDNNs
[11] JieHu,LiShen,andGangSun, “Squeeze-and-excitationnet-
UsingRawWaveformforText-IndependentSpeakerVerifica-
works,” in 2018 IEEE/CVF Conference on Computer Vision
tion,” inProc.Interspeech2018,2018,pp.3583–3587.
andPatternRecognition,2018,pp.7132–7141.
[26] Arsha Nagrani, Joon Son Chung, and Andrew Zisserman,
[12] ShanghuaGao,MingMingCheng,KaiZhao,XinYuZhang,
“Voxceleb:alarge-scalespeakeridentificationdataset,” 2017.
andPhilipH.S.Torr, “Res2net: Anewmulti-scalebackbone
architecture,” IEEETransactionsonPatternAnalysisandMa- [27] Joon Son Chung, Arsha Nagrani, and Andrew Zisserman,
chineIntelligence,pp.652–662,2019. “Voxceleb2:Deepspeakerrecognition,” 2018.
[13] JentheThienpondt,BrechtDesplanques,andKrisDemuynck, [28] DavidSnyder, GuoguoChen, andDanielPovey, “Musan: A
“Integrating frequency translational invariance in tdnns and music,speech,andnoisecorpus,” ComputerScience,2015.
frequency positional information in 2d resnets to enhance [29] Tom Ko, Vijayaditya Peddinti, Daniel Povey, Michael L.
speakerverification,” 2021. Seltzer, and Sanjeev Khudanpur, “A study on data augmen-
[14] Zhenduo Zhao, Zhuo Li, Wenchao Wang, and Pengyuan tationofreverberantspeechforrobustspeechrecognition,” in
Zhang, “Pcf: Ecapa-tdnnwithprogressivechannelfusionfor IEEEInternationalConferenceonAcoustics,2017.
speakerverification,” inICASSP2023-2023IEEEInterna- [30] SeyedOmidSadjadi,MalcolmSlaney,Heck,andLarry, “Msr
tionalConferenceonAcoustics,SpeechandSignalProcessing
identitytoolboxv1.0: Amatlabtoolboxforspeakerrecogni-
(ICASSP),2023. tionresearch,” MicrosoftResearchTechnicalReport,2013.
[15] Jahangir Alam, Woo Hyun Kang, and Abderrahim Fathan,
[31] JiankangDeng,JiaGuo,NiannanXue,andStefanosZafeiriou,
“Hybrid neural network with cross- and self-module atten-
“Arcface: Additiveangularmarginlossfordeepfacerecogni-
tion pooling for text-independent speaker verification,” in
tion,” inProceedingsoftheIEEE/CVFConferenceonCom-
ICASSP2023-2023IEEEInternationalConferenceonAcous-
puterVisionandPatternRecognition(CVPR),June2019.
tics,SpeechandSignalProcessing(ICASSP),2023.