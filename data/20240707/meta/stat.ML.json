[
    {
        "title": "Accelerated Inference for Partially Observed Markov Processes using Automatic Differentiation",
        "authors": "Kevin TanGiles HookerEdward L. Ionides",
        "links": "http://arxiv.org/abs/2407.03085v1",
        "entry_id": "http://arxiv.org/abs/2407.03085v1",
        "pdf_url": "http://arxiv.org/pdf/2407.03085v1",
        "summary": "Automatic differentiation (AD) has driven recent advances in machine\nlearning, including deep neural networks and Hamiltonian Markov Chain Monte\nCarlo methods. Partially observed nonlinear stochastic dynamical systems have\nproved resistant to AD techniques because widely used particle filter\nalgorithms yield an estimated likelihood function that is discontinuous as a\nfunction of the model parameters. We show how to embed two existing AD particle\nfilter methods in a theoretical framework that provides an extension to a new\nclass of algorithms. This new class permits a bias/variance tradeoff and hence\na mean squared error substantially lower than the existing algorithms. We\ndevelop likelihood maximization algorithms suited to the Monte Carlo properties\nof the AD gradient estimate. Our algorithms require only a differentiable\nsimulator for the latent dynamic system; by contrast, most previous approaches\nto AD likelihood maximization for particle filters require access to the\nsystem's transition probabilities. Numerical results indicate that a hybrid\nalgorithm that uses AD to refine a coarse solution from an iterated filtering\nalgorithm show substantial improvement on current state-of-the-art methods for\na challenging scientific benchmark problem.",
        "updated": "2024-07-03 13:06:46 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.03085v1"
    },
    {
        "title": "Stable Heterogeneous Treatment Effect Estimation across Out-of-Distribution Populations",
        "authors": "Yuling ZhangAnpeng WuKun KuangLiang DuZixun SunZhi Wang",
        "links": "http://arxiv.org/abs/2407.03082v1",
        "entry_id": "http://arxiv.org/abs/2407.03082v1",
        "pdf_url": "http://arxiv.org/pdf/2407.03082v1",
        "summary": "Heterogeneous treatment effect (HTE) estimation is vital for understanding\nthe change of treatment effect across individuals or subgroups. Most existing\nHTE estimation methods focus on addressing selection bias induced by imbalanced\ndistributions of confounders between treated and control units, but ignore\ndistribution shifts across populations. Thereby, their applicability has been\nlimited to the in-distribution (ID) population, which shares a similar\ndistribution with the training dataset. In real-world applications, where\npopulation distributions are subject to continuous changes, there is an urgent\nneed for stable HTE estimation across out-of-distribution (OOD) populations,\nwhich, however, remains an open problem. As pioneers in resolving this problem,\nwe propose a novel Stable Balanced Representation Learning with\nHierarchical-Attention Paradigm (SBRL-HAP) framework, which consists of 1)\nBalancing Regularizer for eliminating selection bias, 2) Independence\nRegularizer for addressing the distribution shift issue, 3)\nHierarchical-Attention Paradigm for coordination between balance and\nindependence. In this way, SBRL-HAP regresses counterfactual outcomes using ID\ndata, while ensuring the resulting HTE estimation can be successfully\ngeneralized to out-of-distribution scenarios, thereby enhancing the model's\napplicability in real-world settings. Extensive experiments conducted on\nsynthetic and real-world datasets demonstrate the effectiveness of our SBRL-HAP\nin achieving stable HTE estimation across OOD populations, with an average 10%\nreduction in the error metric PEHE and 11% decrease in the ATE bias, compared\nto the SOTA methods.",
        "updated": "2024-07-03 13:03:51 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.03082v1"
    },
    {
        "title": "Warm-up Free Policy Optimization: Improved Regret in Linear Markov Decision Processes",
        "authors": "Asaf CasselAviv Rosenberg",
        "links": "http://arxiv.org/abs/2407.03065v1",
        "entry_id": "http://arxiv.org/abs/2407.03065v1",
        "pdf_url": "http://arxiv.org/pdf/2407.03065v1",
        "summary": "Policy Optimization (PO) methods are among the most popular Reinforcement\nLearning (RL) algorithms in practice. Recently, Sherman et al. [2023a] proposed\na PO-based algorithm with rate-optimal regret guarantees under the linear\nMarkov Decision Process (MDP) model. However, their algorithm relies on a\ncostly pure exploration warm-up phase that is hard to implement in practice.\nThis paper eliminates this undesired warm-up phase, replacing it with a simple\nand efficient contraction mechanism. Our PO algorithm achieves rate-optimal\nregret with improved dependence on the other parameters of the problem (horizon\nand function approximation dimension) in two fundamental settings: adversarial\nlosses with full-information feedback and stochastic losses with bandit\nfeedback.",
        "updated": "2024-07-03 12:36:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.03065v1"
    },
    {
        "title": "FairJob: A Real-World Dataset for Fairness in Online Systems",
        "authors": "Mariia VladimirovaFederico PavoneEustache Diemert",
        "links": "http://arxiv.org/abs/2407.03059v1",
        "entry_id": "http://arxiv.org/abs/2407.03059v1",
        "pdf_url": "http://arxiv.org/pdf/2407.03059v1",
        "summary": "We introduce a fairness-aware dataset for job recommendation in advertising,\ndesigned to foster research in algorithmic fairness within real-world\nscenarios. It was collected and prepared to comply with privacy standards and\nbusiness confidentiality. An additional challenge is the lack of access to\nprotected user attributes such as gender, for which we propose a solution to\nobtain a proxy estimate. Despite being anonymized and including a proxy for a\nsensitive attribute, our dataset preserves predictive power and maintains a\nrealistic and challenging benchmark. This dataset addresses a significant gap\nin the availability of fairness-focused resources for high-impact domains like\nadvertising -- the actual impact being having access or not to precious\nemployment opportunities, where balancing fairness and utility is a common\nindustrial challenge. We also explore various stages in the advertising process\nwhere unfairness can occur and introduce a method to compute a fair utility\nmetric for the job recommendations in online systems case from a biased\ndataset. Experimental evaluations of bias mitigation techniques on the released\ndataset demonstrate potential improvements in fairness and the associated\ntrade-offs with utility.",
        "updated": "2024-07-03 12:30:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.03059v1"
    },
    {
        "title": "Implementation and Analysis of GPU Algorithms for Vecchia Approximation",
        "authors": "Zachary JamesJoseph Guinness",
        "links": "http://arxiv.org/abs/2407.02740v1",
        "entry_id": "http://arxiv.org/abs/2407.02740v1",
        "pdf_url": "http://arxiv.org/pdf/2407.02740v1",
        "summary": "Gaussian Processes have become an indispensable part of the spatial\nstatistician's toolbox but are unsuitable for analyzing large dataset because\nof the significant time and memory needed to fit the associated model exactly.\nVecchia Approximation is widely used to reduce the computational complexity and\ncan be calculated with embarrassingly parallel algorithms. While multi-core\nsoftware has been developed for Vecchia Approximation, such as the GpGp R\npackage, software designed to run on graphics processing units (GPU) is\nlacking, despite the tremendous success GPUs have had in statistics and machine\nlearning. We compare three different ways to implement Vecchia Approximation on\na GPU: two of which are similar to methods used for other Gaussian Process\napproximations and one that is new. The impact of memory type on performance is\ninvestigated and the final method is optimized accordingly. We show that our\nnew method outperforms the other two and then present it in the GpGpU R\npackage. We compare GpGpU to existing multi-core and GPU-accelerated software\nby fitting Gaussian Process models on various datasets, including a large\nspatial-temporal dataset of $n>10^6$ points collected from an earth-observing\nsatellite. Our results show that GpGpU achieves faster runtimes and better\npredictive accuracy.",
        "updated": "2024-07-03 01:24:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.02740v1"
    }
]