Cartan moving frames and the data manifolds
Eliot Tron1*, Rita Fioresi3, Nicolas Couellan1,2,
St´ephane Puechmorel1,2
1Ecole Nationale de l’Aviation Civile, 7 Avenue Edouard Belin, Toulouse,
31400, France.
2Institut de Math´ematiques de Toulouse, UMR 5219, Universit´e de
Toulouse, CNRS, UPS, 118 route de Narbonne, Toulouse, F-31062 Cedex
9, France.
3FaBiT, Universit`a di Bologna, via S. Donato 15, I-40126 Bologna, Italy.
*Corresponding author(s). E-mail(s): eliot.tron@enac.fr;
Contributing authors: nicolas.couellan@recherche.enac.fr;
stephane.puechmorel@enac.fr; rita.fioresi@UniBo.it;
Abstract
ThepurposeofthispaperistoemploythelanguageofCartanmovingframesto
studythegeometryofthedatamanifoldsanditsRiemannianstructure,viathe
data information metric and its curvature at data points. Using this framework
and through experiments, explanations on the response of a neural network are
given by pointing out the output classes that are easily reachable from a given
input.Thisemphasizeshowtheproposedmathematicalrelationshipbetweenthe
output of the network and the geometry of its inputs can be exploited as an
explainable artificial intelligence tool.
Keywords:NeuralNetworks,DataManifolds,MovingFrames,Curvature,
ExplainableAI
1 Introduction
In machine learning, the idea of data manifold is based on the assumption that the
dataspace,containingthedatapointsonwhichweperformclassificationtasks,hasa
natural Riemannian manifold structure. It is a quite old concept (see [1], [2] and refs
therein)anditislinkedtothekeyquestionofdimensionalityreduction[3],whichisthe
1
4202
peS
81
]LM.tats[
1v75021.9042:viXrakey to efficient data processing for classification tasks, and more. Several geometrical
tools, such as geodesics, connections, Ricci curvature, become readily available for
machinelearningproblemsunderthemanifoldhypothesis,andareespeciallyeffective
whenemployedinexaminingadversarialattacks[4–7]orknowledgetransferquestions,
see [8, 9] and refs. therein.
More specifically, the rapidly evolving discipline of information geometry [10–13]
is now offering methods for discussing the above questions, once we cast them appro-
priatelybyrelating thestatisticalmanifold, i.e.the manifoldof probability measures,
studied in information geometry with data manifolds (see [10, 14]).
We are interested in a naturally emerging foliation structure on the data space
comingthroughthedatainformationmatrix(DIM),whichistheanalogoftheFisher
information matrix and in concrete experiments can be obtained by looking at a
partially trained deep learning neural network for classification tasks. As it turns
out, the leaves of such foliation are related with the dataset the network was trained
with [14, 15]. Further work in [15] linked such study to the possible applications to
knowledge transfer.
The purpose of the present paper is to study and understand the data manifolds,
withCartanmovingframesmethod.Followingthephilosophyin[10],wewanttoequip
the manifolds coming as leaves of the above mentioned foliation, via a natural metric
coming through the data information matrix. As it turns out, the partial derivatives
oftheprobabilitiesallowustonaturallydefinetheCartanmovingframeateachpoint
and are linked with the curvature of such manifold in an explicit way.
Fromabroaderperspective,theworkproposedhereemphasizesthemathematical
relationshipbetweenthechangesintheoutputsofaneuralnetworkandthecurvature
of the data manifolds. Furthermore, we show how this relationship can be exploited
to provide explanations for the responses of a given neural network. In critical sys-
tems, providing explanations to AI model decisions can sometimes be required or
mandatory by certification processes (see for example [16]). More generally, the field
of eXplainable Artificial Intelligence (AI) is a fast growing research topic that devel-
ops tools for understanding and interpreting predictions given by AI models [17]. In
Section6ofthisarticle,throughsimpleexperiments,weshowhowtheDIMrestricted
to the moving frame given by the neural network output probability partial deriva-
tives can be used to understand the local geometry of trained data. Specifically, in
the case of the MNIST handwritten digits dataset [18] and CIFAR10 animals / vehi-
cles dataset [19] by displaying the restricted DIM in the form of images, we are able
to understand, starting from a given data point, which classes are easily reachable by
the neural networks or not.
The organization of the paper is as follows.
In Section 2, we briefly recap some notions on information geometry and some
key known results that we shall need in the sequel. Our main reference source will be
[12, 13].
InSection3,wetakeadvantageofthemachinerydevelopedbyCartan(see[20,21])
and define moving frames on the data manifolds via the partial derivatives of the
probabilities.
2In Section 4 and 5, we relate the probabilities with the curvature of the leaves, by
deriving the calculations of the curvature forms in a numerically stable way.
Finally in Section 6, we consider some experiments on MNIST and CIFAR10
elucidatinghownearadatapoint,somepartialderivativesoftheprobabilitiesbecome
more important and the metric exhibits some possible singularities.
Acknowledgements. We thank Emanuele Latini, Sylvain Lavau for helpful dis-
cussions. This research was supported by Gnsaga-Indam, by COST Action CaLISTA
CA21109, HORIZON-MSCA-2022-SE-01-01 CaLIGOLA, MSCA-DN CaLiForNIA -
101119552, PNRR MNESYS, PNRR National Center for HPC, Big Data and Quan-
tum Computing, INFN Sezione Bologna. ET is grateful to the FaBiT Department of
the University of Bologna for the hospitality.
2 Preliminaries
The neural networks we consider are classification functions
( )
X
N :X ×Θ−→ p∈RC ; p =1, p >0 ,
k k
k
from the spaces of data X and weights (or parameters) Θ, to the space of parame-
terized probability densities p(y |x,θ) over the set of labels Y, where x ∈ X is the
input,y ∈Y isthetargetlabelandθ ∈Θistheparameterofthemodel.Forinstance
θ are the weights and biases in a perceptron model predicting C classes, for a given
input datum x.
We may assume both the dataspace X and the parameter space Θ to be (open)
subsetsofeuclideanspaces,X ⊂Rd,Θ⊂Rn,thoughitisclearthatinmostpractical
situations only a tiny portion of such open sets will be effectively occupied by data
points or parameters of an actual model.
In the following, we make only two assumptions on N:
N =softmax◦s (H1)
∀i,j,k, ∂ ∂ s (x)=0 a.e. (H2)
xi xj k
where s is called a score function, and softmax is the function (a i)
i
7→(eai/P keak) i.
Wedetailwhytheseassumptionsareimportantinthefollowingsections.Anexample
ofneuralnetworksatisfyingtheseconditionsisthefeed-forwardmulti-layerperceptron
with ReLU activation functions. Other popular neural network architectures verify
theses assumptions.
A most important notion in information geometry is the Fisher-Rao matrix F,
providing in some important applications, a metric on the space Θ:
F =(f
):=(cid:0)E (cid:2)
∂ lnp(y |x,θ)∂ lnp(y
|x,θ)(cid:3)(cid:1)
, 1≤i,j ≤n.
ij y|x,θ θi θj
3Wenowgive inanalogyto F the datainformation matrixD (DIMfor short), defined
in a similar way.
Definition 2.1. Wedefinedata information matrix D =(D )forapointx∈X and
ij
a fixed model θ ∈Θ to be the following symmetric matrix:
D (x)=E (cid:2) ∂ lnp(y |x,θ)∂ lnp(y |x,θ)(cid:3) , 1≤i,j ≤d.
ij y|x,θ xi xj
Hence, D is a d×d matrix, d the dimension of the dataspace.
Observation 2.2. In what follows, we will use the notation p (x) := p(y |x,θ) in
k k
thecaseofclassificationintoafinitesetY ={y ,...,y }.Wethenconcatenatethese
1 C
values in the vector p(x)=(p (x)) . In practice, p(x)=N(x).
k k=1,...,C
Weomitthedependenceinθ astheparametersremainunchangedduringtherest
of the paper. We shall omit the dependence in x too in long computations for easier
reading.
As one can readily check, we have that:
X 1
D (x)= ∂ p (x)∂ p (x). (1)
ij p (x) xi k xj k
k
k
In the following, we will use ∂ , the canonical basis of TX associated to the
i
coordinates xi, and the Einstein summation notation.
Remark 2.3. Notice the appearance of the probability p at the denominator in
i
the expression of D. Since p(y | x,θ) is an empirical probability, on data points it
may happen that some of the p (x) are close to zero, giving numerical instability in
k
practicalsituations.Weshallcommentonthisproblemandhowwemaysolveit,later
on.
We have the following result [14], we briefly recap its proof, for completeness.
Theorem 2.4. The data information matrix D(x) is positive semidefinite, moreover
( )!⊥
X
kerD(x)= span ∂ lnp (x)∂
k=1,...,C i k i
i
with ⊥ taken w.r.t. the Euclidean scalar product on TX. Hence, the rank of D is
bounded by C−1, with C the number of classes.
Proof. To check semipositive definiteness, let u∈T X. Then,
x
X
uTD(x)u= u u E [∂ lnp(y |x,θ)∂ lnp(y |x,θ)]
i j y|x,θ i j
i,j
 
X X
=E y|x,θ u i∂ ilnp(y |x,θ) u j∂ jlnp(y |x,θ)
i j
h i
=E ⟨∂ lnp(y |x,θ)∂ ,u⟩2 .
y|x,θ i i e
4For the statement regarding kernel and rank of D(x), we notice that uTD(x)u =
(cid:0) P (cid:1)⊥
0, whenever u ∈ span { ∂ lnp (x)∂ } , where ⟨·,·⟩ and ⊥ refer to the
k=1,...,C i i k i e
P P
Euclideanmetric.Besides, p =1 =⇒ ∂ p =0,hencetherankboundedby
k k ik i k
C−1 and not C.
This result prompts us to define the distribution:
( )
X
x7→D :=span ∂ p (x)∂ , k =1,...,C−1 . (2)
x i k i
i
For popular neural networks (satisfying H1 and H2), the distribution D turns to
be integrable in an open set of Rd, hence it defines a foliation. This matter has been
discussed in [15].
Theorem 2.5. Let θ be the weights of a neural network classifier N satisfying H1
and H2, associated with the vector p given by softmax. Assume D has constant rank.
Then, at each smooth point x of N there exists a local submanifold L of X, such that
its tangent space at x, T L=D.
x
Inparticular,givenadataset(e.g.MNIST),wecalldataleafaleafofsuchfoliation
containing at least one point of the dataset. In [15] the significance of such leaves is
fully explored from a geometrical and experimental point of view. More specifically,
Thm. 3.6 in [15] shows that the open set in Thm 2.5 is dense in the dataspace X.
In the next sections we shall focus on the geometry of this foliation in the data
space.
3 Cartan moving frames
In this section we first review some basic notions of Cartan’s approach to differen-
tiable manifolds via the moving frames point of view and then we see some concrete
application to our setting.
Definition 3.1. Let E → L be a C∞ vector bundle over a smooth manifold L. A
connection on E is a bilinear map:
∇:X(L)×Γ(E)→Γ(E)
such that
∇ (fs)=df(v)s+f∇ s, v ∈X(L), f ∈C∞(L), s∈Γ(E)
v v
where X(L) are the vector fields on L and Γ(E) the sections of the vector bundle E.
We shall be especially interested to the case, E = TL the tangent bundle to
a leaf L of a suitable foliation (Thm. 2.5). Our framework is naturally set up to
take advantange of Cartan’s language of moving frames [20]. Before we give this key
definition, let us assume our distribution D as in (2) to be smooth, constant rank
and integrable. This assumption is reasonable, since it has been shown in [15] that,
5for neural networks with ReLU non linearity, D satisfies these hypotheses in a dense
open subset of the dataspace.
Definition 3.2. We define the data foliation F , the foliation in the data space X
D
definedbythedistributionD asinEquation2anddata leaf aleafL ofF containing
x
at least one data point i.e. a point of the data set the network was trained with.
If ⟨·,·⟩ denotes the symmetric bilinear form defined by the data information
D
matrix D as in Def. 2.1 in the dataspace, by the very definitions, when we restrict
ourselves to the tangent space to a leaf L of F, we have that ⟨·,·⟩ := ⟨·,·⟩ | is
L D L
a non degenerate inner product (Prop. 2.4 and Thm. 2.5). Hence it defines a metric
denoted gD.
Definition 3.3. Let the notation be as above and let L be a fixed leaf in F . At
D
P
each point x ∈ L, we define (e := ∂ p (x)∂ ) to be a frame for T L.
k i i k i (k=1,...C−1) x
The symmetric bilinear form gD defines a Riemannian metric on L, that we call data
metric.
Let ∇ be the Levi-Civita connection with respect to the data information metric.
Definition 3.4. The Levi-Civita connection
X
∇ e = ωi(X)e
X j j i
i
defines ωi, which are called the connection forms and ω the connection matrix
j
relative to the frame (e ).
i
The Levi-Civita connection is explicitly given by (see [20] pg 46):
2gD(∇ e ,e )=e (cid:0) gD(e ,e )(cid:1) +e (cid:0) gD(e ,e )(cid:1) −e (cid:0) gD(e ,e )(cid:1)
ea b c a b c b c a c a b
−gD(e ,[e ,e ])+gD(e ,[e ,e ])+gD(e ,[e ,e ]). (3)
a b c b c a c a b
To explicitly compute the connection forms ωi(e ) we need to define
j k
C :=gD(∇ e ,e ) (4)
a,b,c ea b c
then we have by definition that
X
C = ωi(e )gD(e ,e ).
a,b,c b a i c
i
Define the matrix Dˆ = (cid:0) gD(e ,e )(cid:1) . This is the matrix of the metric
i j i,j=1,...,C−1
gD(·,·)restrictedtoaleafLforthebasisgivenbyaframe.Weshallseeaninteresting
significance for the matrix Dˆ in the experiments in Section 6. Hence:
X Dˆ ωi(e )=C .
l,i j k k,j,l
i
6This gives, in matrix notation:
(cid:16) (cid:17)
ωi(e )= Dˆ−1C . (5)
j k k,j,·
i
The curvature tensor R is given by:
X
R(X,Y)e = Ωi(X,Y)e
j j i
i
where Ωi is a 2-form on TX, alternating and D-bilinear called the curvature form
j
(matrix) of the connection ∇ relative to the frame (e ) on TX.
i
TocomputeRweshallmakeuseofthefollowingresultfoundin[20]Theorem11.1.
Proposition 3.5. The curvature form Ω is given by:
Ωi (X,Y)=(cid:0) dωi(cid:1) (X,Y)+X ωi ∧ωk(X,Y).
j j k j
k
By using all the previous propositions and definitions, we will see in the following
sections how we can numerically compute the curvature for a neural network with a
softmax function on the output.
It is useful to recall some formulae. If α and β are C∞ 1-forms and X,Y are C∞
vector fields on a manifold, then
(α∧β)(X,Y)=α(X)β(Y)−α(Y)β(X) (6)
and
(dα)(X,Y)=Xα(Y)−Yα(X)−α([X,Y]). (7)
4 The Curvature of the Data Leaves
Computing in practice the curvature of a manifold with many dimensions is often
intractable though essential for many tasks. This is why we are interested in com-
puting the curvature just for the data leaves. Notice that, since in our frame
(e :=P ∂ p (x)∂ ), we have P ∂ lnp (x)∂ = 1 P ∂ p (x)∂ = 1 e , we
k i i k i i i k i pk(x) i i k i pk(x) k
mayforgetthelogarithminthecomputationsasitcontributesonlybyascalarfactor.
P
Let U = ( ∂ p ∂ p ) be the matrix of the dot products of the partial
k k i k j i,j
derivatives of the probabilities.
With this notation, if P =diag{p , k =1,...,C}, then
k
Dˆ =(cid:0) UP−1U(cid:1) .
a,b a,b
(cid:16) (cid:17)
Besides, if J(p) = ∂pa is the Jacobian matrix of first order derivatives,
∂xi a=1,...,C
i=1,...,d
then U =J(p)J(p)T.
7NoticethatP mightnotbenumericallyinvertible,wheneversomeclassesarevery
unlikely and thus with a probability close to zero. The goal of this section, and the
followingone,isthustoderivethecomputationsofthecurvatureformsinawaythatis
numericallystable.Thiswillallowustoimplementthecurvatureformscomputations
on a computer.
Proposition 4.1. Let the notation be as above. We have:
[e ,e ]=H(p )e −H(p )e (8)
a b b a a b
with H(f)=(∂ ∂ f) the matrix of second order partial derivatives.
i j i,j=1,...,d
Proof. First,recallthat(cid:2) uk∂ ,vl∂ (cid:3) =(cid:16) uk∂vl −vk∂ul(cid:17) ∂ .Thus,withuk = ∂pa and
k l ∂xk ∂xk l ∂xk
vl = ∂pb we get:
∂xl
!
[e ,e ]= X ∂p a ∂2p b −X ∂p b ∂2p a ∂
a b ∂xk ∂xk∂xl ∂xk ∂xk∂xl l
k k
=H(p )e −H(p )e .
b a a b
Proposition 4.2. Ifsrepresentthescorevector,i.e.theoutputoftheneuralnetwork
before going through the softmax function then, for all j =1,...,C,
X X
∂ p = p (δ −p )∂ s and ∂ lnp = (δ −p )∂ s . (9)
j i i ik k j k j i ik k j k
k k
In term of Jacobian matrices, this rewrites as
J(p)=(cid:0)
P
−ppT(cid:1)
J(s).
Proof. This is simply due to the fact that p=softmax(s) and that the derivative of
the softmax function is ∂softmax(x)i =softmax(x) (δ −softmax(x) ).
∂xk i i,k k
We now give other formulae for the second order partial derivatives of the
probabilities.
Proposition 4.3. Let the notation be as above. We have:
C
H(p ) = ∂ ip a∂ jp a −p X ∂ p ∂ s . (10)
a ij p a i k j k
a
k=1
Proof.
!
X
H(p ) =∂ (∂ p )=∂ p (δ −p )∂ s
a ij i j a i a ik k j k
k
8X X
=∂ p (δ −p )∂ s +p ∂ ((δ −p )∂ s )
i a ak k j k a i ak k j k
k k
| {z }
= p1 a∂jpa
1 X X
= ∂ p ∂ p +p (δ −p )H(s )−p ∂ p ∂ s .
p i a j a a ak k k a i k j k
a
k k
But H(s )=0 almost everywhere by H2.
k
However,withthisform,theprobabilityatthedenominatorwillcausesomeinsta-
bilityproblems,wheneverthenetworkissufficientlytrained.Thus,weexpressH(p )
a
in another form below.
Proposition 4.4. Let the notation be as above. We have:
X
H(p ) = [(δ −p )∂ p −p ∂ p ]∂ s
a ij ak k i a a i k j k
k
" #
X X
=p (δ −p ) (δ −p )∂ s −∂ p ∂ s .
a ak k al l i l i k j k
k l
Proof. The proof is a straightforward combination of Equation 9 and Equation 10.
We simply need to replace ∂ p twice in the expression 10 by 9.
i a
Lemma 4.5.
e (D)(x)=J(s)TA J(s) (11)
a a
with
X
(A ) = ∂ p ((δ −p )∂ p −p ∂ p )
a kl i a kl l i k k i l
i
Proof.
X
e (D)(x)= ∂ p ∂ D(x)
a i a i
i
=X ∂ p ∂ (cid:0) J(s)T (cid:0) P −ppT(cid:1) J(s)(cid:1)
i a i
i
=X ∂ p J(s)T∂ (cid:0) P −ppT(cid:1) J(s) because H(s )=0.
i a i k
i
Indeed,H(s )=0forallkalmosteverywherebyH2.Thenattheindexesk,l,weget:
k
∂
(cid:0)
P
−ppT(cid:1)
=∂ (p δ −p p )
i kl i k kl k l
=δ ∂ p −p ∂ p −p ∂ p .
kl i k l i k k i l
Thus,bymultiplyingwith∂ p andsummingoveri,itgivestheexpressionofA .
i a a
9Proposition 4.6. Recall that the neural network satisfies H2, then
e (cid:0) gD(e ,e )(cid:1) =M +M +(J(s)e )T A J(s)e
a b c a,c,b a,b,c b a c
with
M =(H(p )e )T J(s)T (cid:0) P −ppT(cid:1) J(s)e .
a,b,c b a c
Proof. The proof is straightforward.
e (cid:0) gD(e ,e )(cid:1) =X ∂ p ∂ (cid:0) eTD(x)e (cid:1)
a b c i a i b c
i
=X ∂ p ∂ (cid:0) eT(cid:1) D(x)e +X ∂ p eT∂ (D(x))e
i a i b c i a b i c
i i
X
+ ∂ p eTD(x)∂ e
i a b i c
i
=eTH(p )T D(x)e +eTe (D(x))e +eTD(x)H(p )e
a b c b a c b c a
(cid:16) (cid:17)T
=M +eTJ(s)TA J(s)e + eTH(p )T D(x)e
a,b,c b a c a c b
=M +eTJ(s)TA J(s)e +(M )T .
a,b,c b a c a,c,b
And M is a scalar, thus MT =M , hence the result.
a,c,b a,c,b a,c,b
Then, we use the following proposition to remove the second order derivative in
M. An alternative formula for this expression is given in A.1. This facilitates the
computations with automatic differentiation methods.
Proposition 4.7.
 
X X
H(p a)e
b
= (δ ak−p k)(∂ is k∂ ip b)e a− p a(∂ is k∂ ip b)e k. (12)
k,i k,i
Proof.
!
X X
H(p )e = ((δ −p )∂ p −p ∂ p )∂ s ∂ p
a b ak k j a a j k i k i b
i k
! !
X X X X
= (δ −p )∂ p ∂ s ∂ p −p ∂ p ∂ s ∂ p
ak k j a i k i b a j k i k i b
i k i k
 
X X
= (δ ak−p k)∂ is k∂ ip b∂ jp a−p
a
(∂ is k∂ ip b)∂ jp k.
k,i k,i
10Proposition 4.8.
X
gD(e ,[e ,e ])= ∂ p D(x) (∂ ∂ p ∂ p −∂ ∂ p ∂ p ). (13)
a b c i a ij j k c k b j k b k c
i,j,k
Proof. Straightforward from the previous propositions and lemmas.
Withallthesepropositions,theconnectionformscanbecomputeddirectlywithout
numerical instabilities.
5 Computation of the curvature forms
In this section we conclude our calculation of the curvature forms. In Prop. 3.5 we
wrote the explicit expression for the curvature form as:
Ω(X,Y)=(dω)(X,Y)+ω∧ω(X,Y). (14)
where ω denotes the (Levi-Civita) connection form. To ease the reading we go back
to notation of Section 3 and we set:
X
e := ∂ p (x)∂ , for k =1,...,C−1.
k i k i
i
We then can express explicitly the connection form as:
X
∇ e = ωi(X)e .
X j j i
The wedge product of the connection forms in (14) can thus be easily computed with
the propositions of the previous section, because of formula (6) report here:
(ω∧ω)(X,Y)=ω(X)ω(Y)−ω(Y)ω(X). (15)
The exterior derivative of ω remains to be computed and it is more complicated.
We recall the formula (7):
(dω)(X,Y)=Xω(Y)−Yω(X)−ω([X,Y]). (16)
The last term is computed via the following proposition.
Proposition 5.1. Let the notation be as above. Then:
 
X
ω ji([e a,e b])= (δ bk−p k)(∂ ls k∂ lp a)ω ji(e b)
k,l
 
X
− (δ ak−p k)(∂ ls k∂ lp b)ω ji(e a)
k,l
11X
− (∂ s (p ∂ p −p ∂ p ))ωi(e ).
l k b l a a l b j k
k,l
Proof.
ωi([e ,e ])=ωi(H(p )e )−ωi(H(p )e ).
j a b j b a j a b
Besides,
  
X X
ω ji(H(p a)e b)=ω ji  (δ ak−p k)(∂ ls k∂ lp b)e a− p a(∂ ls k∂ lp b)e k
k,l k,l
 
X X
= (δ ak−p k)(∂ ls k∂ lp b)ω ji(e a)− p a(∂ ls k∂ lp b)ω ji(e k).
k,l k,l
Thus,
 
X
ω ji([e a,e b])= (δ bk−p k)(∂ ls k∂ lp a)ω ji(e b)
k,l
 
X
− (δ ak−p k)(∂ ls k∂ lp b)ω ji(e a)
k,l
X
− (∂ s (p ∂ p −p ∂ p ))ωi(e ).
l k b l a a l b j k
k,l
We now tackle the question of determining the first two terms in (7).
Observation 5.2. We notice that to compute e (cid:0) ωi(e )(cid:1) , we can use the fact that:
a j b
!
e (cid:0) gD(∇ e ,e )(cid:1) =e X ωi(e )gD(e ,e )
a eb c d a c b i d
i
=X e (cid:0) ωi(e )(cid:1) gD(e ,e )+X ωi(e )e (cid:0) gD(e ,e )(cid:1)
a c b i d c b a i d
i i
⇐⇒ X Dˆ e (cid:0) ωi(e )(cid:1) =e (cid:0) gD(∇ e ,e )(cid:1) −X ωi(e )e (cid:0) gD(e ,e )(cid:1)
d,i a c b a eb c d c b a i d
i i
| {z }
Na,b,c,d
⇐⇒ e (ω· (e ))=Dˆ−1N .
a c b a,b,c,·
Hence we need to compute: e gD(∇ e ,e ).
a eb c d
12Theorem 5.3. The expression of the curvature is given by:
(cid:16) (cid:17) (cid:16) (cid:17)
Ωi (e ,e )= Dˆ−1N − Dˆ−1N −ωi([e ,e ])
j a b a,b,j,· b,a,j,· j a b
i i
+X(cid:2) ωi (e )ωk(e )−ωi (e )ωk(e )(cid:3) (17)
k a j b k b j a
k
where N = (N ) is the vector defined in Observation 5.2 by
a,b,c,· a,b,c,d d=1,...,C−1
e (cid:0) gD(∇ e ,e )(cid:1) −P ωi(e )e (cid:0) gD(e ,e )(cid:1) for d = 1,...,C −1, and where Dˆ =
(cid:0) ga D(e ,ee )b(cid:1)c d ii s tc heb maa trix of pi aird wise metric products of the frame.
i j i,j=1,...,C−1
We report the lemmas needed to compute the tensor N in Appendix B.
a,b,c,d
6 Experiments
P
To understand why the frame e = ∂ p ∂ and the DIM were chosen to compute
a i i a i
the connection and curvature forms, we shall focus on experiments on the MNIST
and the CIFAR10 datasets. As we will see, this frame and the DIM can provide some
explanations to the response of the neural network.1
The MNIST dataset is composed of 60k train images of shape 28 × 28 pixels
depicting handwritten digits between 0 and 9, and the CIFAR10 dataset is composed
of60kRGBtrainimagesofshape32×32classifiedin10differentclasses(seeTable1).
Table 1: Correspondence index - class of the CIFAR10 dataset.
No. 0 1 2 3 4 5 6 7 8 9
Class airplane automobile bird cat deer dog frog horse ship truck
On Figure 1 are represented various input points x from the MNIST training set
and the corresponding matrix2 Dˆ = (g (e ,e )) . The neural network used
x x a b a,b=1,...,C
inthisexperimentisdefinedasstatedinTable2.Thisnetworkhasbeentrainedonthe
test set of MNIST with stochastic gradient descent until convergence (98% accuracy
on the test set).
OnFigure1,itcanbeseenthatthematricesDˆ haveonlyafewmaincomponents
x
indicating which probabilitiesare the easiestto change. A large(positive) component
on the diagonal at index i suggests that one can increase or decrease easily p (x) by
i
moving in the directions ±e . A negative (resp. positive) component at position (i,j)
i
indicates that, starting from the image x, classes i and j are in opposite (resp. the
same) directions: increasing p (x) will most likely decrease (resp. increase) p (x).
i j
For instance, the first image on the top left is correctly classified as a 2 by the
network, but since the coefficient (3,3) of matrix Dˆ is positive too, it indicates that
1Thecodeusedtoproducetheseresultsisavailableathttps://github.com/eliot-tron/curvcomputenn/.
2WeplotherethematrixDˆ witha,bgoinguptoC,andnotC−1,torepresentalltheclassesandhave
aneasierinterpretation.
13class 3 should be easily reachable. This makes sense, as the picture can also be inter-
preted as a part of the 3 digit. Negative coefficients at (3,2) and (2,3) thus indicates
that going in the direction of a 3 will decrease the probability of predicting a 2. On
the secondpicture, the same phenomenon arises but with classes2 and 8. Indeed, the
buckle in the bottom part of the picture brings it closer to an 8.
Remark 6.1. Be careful as teal colored coefficients on Figure 1 and Figure 2 are not
exactly zero but rather very low compared to the few main ones that are yellow and
purple.
Table 2:ArchitectureoftheneuralnetworktrainedonMNIST.
No. Layers(sequential)
(0): Conv2d(1, 32, kernel size=(3, 3), stride=(1, 1))
(1): ReLU()
(2): Conv2d(32, 64, kernel size=(3, 3), stride=(1, 1))
(3): ReLU()
(4): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1)
(5): Flatten()
(6): Linear(in features=9216, out features=128, bias=True)
(7): ReLU()
(8): Linear(in features=128, out features=10, bias=True)
(9): Softmax()
OnFigure2arerepresentedvariousinputpointsxfromtheCIFAR10trainingset
andthecorrespondingmatrixDˆ =(g (e ,e )) .Theneuralnetworkusedin
x x a b a,b=1,...,C
this experiment is defined as stated in Table 3. This network has been trained on the
testsetofCIFAR10withstochasticgradientdescentuntilconvergence(84%accuracy
on the test set).
OnFigure2,itcanbeseenthatthematricesDˆ haveonlyafewmaincomponents
x
indicating which probabilities are the easiest to change, i.e. with a similar behavior
as seen above for MNIST. The interpretation of matrix Dˆ then is identical.
For instance, the first image on the top left is correctly classified as a dog (class
No. 5) by the network, but since the coefficient (3,3) of matrix Dˆ is positive too, it
indicatesthatclassNo.3“cat”shouldbeeasilyreachable.Thismakessensesincedogs
and cats form a subclass of similar little animals. Negative coefficients at (3,2) and
(2,3)thusindicatesthatgoinginthedirectionofthecatwilldecreasetheprobability
of predicting a dog. There are also positive coefficients at (3,7) and (7,3) indicating
that going in the direction of the cat should also slightly increase the probability of
seeing a horse. Again, this makes sense as they all belong in the animal subclass.
On the second picture, the dog can be transformed into a cat or a frog, probably
because of the green cloth around its neck.
7 Conclusion
In this study, we have shown that analyzing the geometry of the data manifold of
a neural network using Cartan moving frames is natural and practical. Indeed, from
14Predicted: 2 Predicted: 2 Predicted: 9
with proba 0.985 with proba 0.955 with proba 0.999
0 2 4 6 8 0 2 4 6 8 0 2 4 6 8
1e 7
0 0 0
0.002
2 2 0.05 2 5
4 4 4
0.000 0.00 0
6 6 6
0.05 5
8 0.002 8 8
Predicted: 8 Predicted: 1 Predicted: 6
with proba 1.000 with proba 0.993 with proba 1.000
0 2 4 6 8 0 2 4 6 8 0 2 4 6 8
1e 15 1e 15
0 1 0 0
2 2 0.0001 2 2
4 4 4
0 0.0000 0
6 6 6
8 8 8
0.0001 2
Fig. 1: Couples of input point x (above) and the corresponding matrix Dˆ(x) =
(cid:0) gD(e ,e )(cid:1) (below) on MNIST.
x a b a,b=1,...,C
the Fisher Information Matrix, we define a corresponding Data Information Matrix
that generates a foliation structure in the data space. The partial derivatives of the
probabilities learned by the neural network define a Cartan moving frame on the
leaves of the data manifold. We detail how the moving frame can be used as a tool to
providesomeexplanationsontheclassificationchangesthatcaneasilyhappenornot
around a given data point. Experiments on the MNIST and CIFAR datasets confirm
the relevance of the explanations provided by the Cartan moving frames and the
correspondingDateInformationMatrix.Forverylargeneuralnetwork,thetheorystill
holds. However, the method might be limited by the computational requirements of
the partial derivatives calculation for each class (usually obtained through automatic
differentiation).Webelievethatcombiningthemovingframe,theconnectionandthe
15Table 3: Architecture of the neural network trained on CIFAR10.
No. Layers(sequential)
(0): Conv2d(3, 64, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): BatchNorm2d(64, eps=1e-05, momentum=0.1)
(2): ReLU()
(3): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1)
(4): Conv2d(64, 128, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(5): BatchNorm2d(128, eps=1e-05, momentum=0.1)
(6): ReLU()
(7): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1)
(8): Conv2d(128, 256, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(9): BatchNorm2d(256, eps=1e-05, momentum=0.1)
(10): ReLU()
(11): Conv2d(256, 256, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(12): BatchNorm2d(256, eps=1e-05, momentum=0.1)
(13): ReLU()
(14): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1, ceil mode=False)
(15): Conv2d(256, 512, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(16): BatchNorm2d(512, eps=1e-05, momentum=0.1)
(17): ReLU()
(18): Conv2d(512, 512, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(19): BatchNorm2d(512, eps=1e-05, momentum=0.1)
(20): ReLU()
(21): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1, ceil mode=False)
(22): Conv2d(512, 512, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(23): BatchNorm2d(512, eps=1e-05, momentum=0.1)
(24): ReLU()
(25): Conv2d(512, 512, kernel size=(3, 3), stride=(1, 1), padding=(1, 1))
(26): BatchNorm2d(512, eps=1e-05, momentum=0.1)
(27): ReLU()
(28): MaxPool2d(kernel size=2, stride=2, padding=0, dilation=1, ceil mode=False)
(29): AvgPool2d(kernel size=1, stride=1, padding=0)
(30): Linear(in features=512, out features=10, bias=True)
(31): Softmax(dim=1)
curvature forms should provide new insights to build more advanced explainable AI
tools. This is work in progress.
16Predicted: dog Predicted: dog Predicted: deer
with proba 1.000 with proba 0.987 with proba 1.000
0 2 4 6 8 0 2 4 6 8 0 2 4 6 8
1e 7 1e 18
0 1 0 1.0 0 5
2 2 2
0.5
4 4 4
0
0
6 6 0.0 6
8 8 8
5
0.5
Predicted: ship Predicted: truck Predicted: ship
with proba 1.000 with proba 1.000 with proba 1.000
0 2 4 6 8 0 2 4 6 8 0 2 4 6 8
1e 22 1e 22 1e 23
0 2 0 0
2 1 2 5 2 1
4 4 4
0 0 0
6 6 6
5
1
8 8 8 1
Fig. 2: Couples of input point x (above) and the corresponding matrix Dˆ(x) =
(cid:0) gD(e ,e )(cid:1) (below) on CIFAR10.
x a b a,b=1,...,C
References
[1] Fefferman, C., Mitter, S., Narayanan, H.: Testing the manifold hypothesis. J.
Amer. Math. Soc. 29, 983–1049 (2016)
[2] Roweis, S.T., Saul, L.K.: Nonlinear dimensionality reduction by locally linear
embedding. Science 290 5500, 2323–6 (2000)
[3] Maaten, L., Hinton, G.E.: Visualizing data using t-sne. Journal of Machine
Learning Research 9, 2579–2605 (2008)
[4] Shen, C., Peng, Y., Zhang, G., Fan, J.: Defending Against Adversarial Attacks
by Suppressing the Largest Eigenvalue of Fisher Information Matrix (2019)
17arXiv:1909.06137 [cs, stat]. Accessed 2021-09-15
[5] Martin, J., Elster, C.: Inspecting adversarial examples using the Fisher informa-
tion (2019) arXiv:1909.05527 [cs, stat]. Accessed 2021-09-15
[6] Carlini,N.,Wagner,D.:AdversarialExamplesAreNotEasilyDetected:Bypass-
ing Ten Detection Methods arXiv:1705.07263 [cs]. Accessed 2021-09-15
[7] Tron, E., Couellan, N.P., Puechmorel, S.: Adversarial attacks on neural net-
works through canonical riemannian foliations. To appear in Machine Learning.
Preprint available at: ArXiv abs/2203.00922 (2022)
[8] Weiss, K.R., Khoshgoftaar, T.M., Wang, D.: A survey of transfer learning.
Journal of Big Data 3 (2016)
[9] Pan, S.J., Yang, Q.: A survey on transfer learning. IEEE Transactions on
Knowledge and Data Engineering 22, 1345–1359 (2010)
[10] Sun, K., Marchand-Maillet, S.: An information geometry of statistical man-
ifold learning. In: International Conference on Machine Learning (2014).
https://api.semanticscholar.org/CorpusID:7149130
[11] Amari,S.-I.,Barndorff-Nielsen,O.E.,Kass,R.E.,Lauritzen,S.L.,Rao,C.R.:Dif-
ferentialGeometryinStatisticalInference10,1–1719219597161163165217219240
4355557
[12] Amari,S.-i.:InformationGeometryandItsApplicationsvol.194.Springer,Tokyo
(2016). https://doi.org/10.1007/978-4-431-55978-8
[13] Nielsen, F.: An elementary introduction to information geometry. Entropy
22(10), 1100 (2020) https://doi.org/10.3390/e22101100
[14] Grementieri, L., Fioresi, R.: Model-centric data manifold: The data through the
eyes of the model. SIAM Journal on Imaging Sciences 15(3), 1140–1156 (2022)
https://doi.org/10.1137/21M1437056
[15] Tron, E., Fioresi, R.: Manifold Learning via Foliations and Knowledge Transfer
(2024). https://arxiv.org/abs/2409.07412
[16] Artificial Intelligence in Aeronautical Systems: Statement of Concerns, SAE
AIR6988 (2021). https://www.sae.org/standards/content/air6988/
[17] Samek,W.,Montavon,G.,Vedaldi,A.,Hansen,L.K.,Muller,K.-R.:Explainable
AI: Interpreting, Explaining and Visualizing Deep Learning vol. 11700, 1st edn.
Springer, Switzerland (2019)
[18] LeCun, Y.: The mnist database of handwritten digits.
http://yann.lecun.com/exdb/mnist/ (1998)
18[19] Krizhevsky,A.,Nair,V.,Hinton,G.:CIFAR-10(CanadianInstituteforAdvanced
Research). University of Toronto, ON, Canada (2009)
[20] Tu, L.W.: Differential Geometry: Connections, Curvature, and Characteristic
Classes vol. 275. Springer, Switzerland (2017)
[21] Jost, J.: Riemannian geometry and geometric analysis, 5th edition. (2008).
https://api.semanticscholar.org/CorpusID:206736101
A An auxiliary lemma
Wereporthere,forconvenience,analternativeformulafortheexpressionusedin4.6.
(cid:0) (cid:1)
Proposition A.1. Recall that U =(u )= ⟨e ,e ⟩ . Then
i,j i j e i,j
e (cid:0) gD(e ,e )(cid:1) = X u u u 1
a b c aj bj cjp2
j j
(cid:18) (cid:19)
+ u ab + u ac X 1 u u
p p p bj cj
b c j
j
X 1 X
− (u p +u p ) (∂ p ∂ s )u
cj b bj c p i a i k jk
j
j k,i
X
− (∂ p ∂ s )(u u +u u ).
i a i k cj bk bj ck
i
Notice that on the second line, we recognise the expression of gD(e ,e ) for the sum.
b c
Proof.
e (cid:0) gD(e ,e )(cid:1) =X ∂ p ∂ (cid:0) gD(e ,e )(cid:1)
a b c i a i b c
i
 
X X 1
= ∂ ip a∂ i
p
u bju cj
j
i j
(cid:18)(cid:18) (cid:19) (cid:19)
X 1 1 1
= ∂ p ∂ u u + (∂ u )u + u (∂ u ) .
i a ip cj bj p i bj cj p bj i cj
j j j
i,j
Now we compute ∂ u :
i bj
!
X
∂ u =∂ ∂ p ∂ p
i bj i l b l j
l
X X
= (∂ ∂ p )∂ p + ∂ p (∂ ∂ p )
i l b l j l b i l j
| {z }
l l
=H(pb)
i,l
19!
=X ∂ ip b∂ lp b −p X ∂ s ∂ p ∂ p
p b i k l k l j
b
l k
!
+X ∂ p ∂ ip j∂ lp j −p X ∂ s ∂ p
l b p j i k l k
j
l k
(cid:18) (cid:19)
=X ∂ ip b + ∂ ip j u −X (p ∂ p +p ∂ p )X ∂ s ∂ p .
p p aj a l j j l a i k l k
b j
l l k
Thus
e (cid:0) gD(e ,e )(cid:1) = X u u u −1
a b c bj cj aj p2
j j
(cid:18) (cid:19)
+X u ab + u aj 1 u u
p p p bj cj
b j j
j
 
X 1 X X
− p u cjp b (∂ lp a∂ ls k)u jk+p j (∂ lp a∂ ls k)u bk
j
j k,l k,l
(cid:18) (cid:19)
+X u ac + u aj 1 u u
p p p bj cj
c j j
j
 
X 1 X X
−
p
u bjp
c
(∂ lp a∂ ls k)u jk+p
j
(∂ lp a∂ ls k)u ck.
j
j k,l k,l
To get a numerically stable expression for e gD(e ,e ), we can develop u with
a b c
Equation 9 and the probability at the denominator will cancel out with the one in
factor of Equation 9.
B Further computations of the curvature forms
In this section we report, for convenience, some lemmas necessary for the full
derivation of the curvature forms calculations.
Lemma B.1.
e (cid:0) e (cid:0) gD(e ,e )(cid:1)(cid:1) =e (M )+e (M )+e (cid:0) eTJ(s)TA J(s)e (cid:1) . (18)
a b c d a b,d,c a b,c,d a c b d
Proof.
e (cid:0) e (cid:0) gD(e ,e )(cid:1)(cid:1) =e (cid:0) M +M +eTJ(s)TA J(s)e (cid:1)
a b c d a b,d,c b,c,d c b d
=e (M )+e (M )+e (cid:0) eTJ(s)TA J(s)e (cid:1) .
a b,d,c a b,c,d a c b d
20Lemma B.2.
e (M )= e (H(p )e )T D(x)e
a b,c,d a c b d
+(H(p )e )T J(s)TA J(s)e
c b a d
+(H(p )e )T D(x)(H(p )e ). (19)
c b d a
Proof.
(cid:16) (cid:17)
e (M )= e eTH(p )T D(x)e
a b,c,d a b c d
= e (H(p )e )T D(x)e
a c b d
+(H(p )e )T e (D(x))e
c b a d
+(H(p )e )T D(x)e (e )
c b a d
= e (H(p )e )T D(x)e
a c b d
+(H(p )e )T J(s)TA J(s)e
c b a d
+(H(p )e )T D(x)(H(p )e ).
c b d a
Lemma B.3.
!
Xh X
e (H(p )e )= −(u ) ∂ s ∂ p e
a c b ak i k i b c
k i
 
X
+(δ ck−p k) ∂ is k∂ i∂ jp b∂ jp ae
c
i,j
!
X i
+(δ −p ) ∂ s ∂ p H(p )e
ck k i k i b c a
i
!
Xh X
− (u ) ∂ s ∂ p e
ac i k i b k
k i
 
X
+p c ∂ is k∂ i∂ jp b∂ jp ae k
i,j
!
X i
+p ∂ s ∂ p H(p )e .
c i k i b k a
i
21Proof. The proof is straightforward by developing the following:
!! ! !
X X X X
e (H(p )e )= e (δ −p ) ∂ s ∂ p e − p ∂ s ∂ p e .
a c b a ck k i k i b c c i k i b k
k i k i
Lemma B.4.
e (cid:0) eTJ(s)TA J(s)e (cid:1) = eTH(p )T J(s)TA J(s)e
a c b d a c b d
+eTJ(s)Te (A )J(s)e
c a b d
+eTJ(s)TA J(s)H(p )e .
c b d a
Lemma B.5.
e (A ) = eTH(p )((δ −p )e −p e )
a b kl a b kl l k k l
+(cid:0) eTe (cid:1)(cid:0) eTe (cid:1) −p eTe
a l b k k b l
+eT ((δ −p )H(p )e −p e )
b kl l k a k l
+(δ −p )(cid:0) eTe (cid:1) −(cid:0) eTe (cid:1)(cid:0) eTe (cid:1) .
kl l b k a k b l
Proof. The proof is straightforward by developing the following:
e (A ) = X ∂ p ∂ (cid:0) eT ((δ −p )e −p e )(cid:1) .
a b kl i a i b kl l k k l
i
Lemma B.6.
e (cid:0) gD(e ,[e ,e ])(cid:1) = eTH(p )D(x)(H(p )e −H(p )e )
a b c d a b d c c d
+eTJ(s)TA J(s)(H(p )e −H(p )e ) (20)
b a d c c d
+eTD(x)(B −B ).
b a,d,c a,c,d
with
!
Xh X
B = −(u ) ∂ s ∂ p e
a,c,d ak i k i d c
k i
 
X
+(δ ck−p k) ∂ is k∂ i∂ jp d∂ jp ae
c
i,j
!
X
+(δ −p ) ∂ s ∂ p H(p )e
ck k i k i d c a
i
22!
X
−(u ) ∂ s ∂ p e
ac i k i d k
i
 
X
−p c ∂ is k∂ i∂ jp d∂ jp ae k
i,j
!
X i
−p ∂ s ∂ p H(p )e
c i k i d k a
i
Proof of the lemma.
e (cid:0) gD(e ,[e ,e ])(cid:1) = e (cid:0) eTD(x)(H(p )e −H(p )e )(cid:1)
a b c d a b d c c d
= eTH(p )D(x)(H(p )e −H(p )e )
a b d c c d
+eTJ(s)TA J(s)(H(p )e −H(p )e )
b a d c c d
+eTD(x)e (H(p )e −H(p )e ).
b a d c c d
Besides, e (H(p )e ) has already been computed previously.
a d c
23