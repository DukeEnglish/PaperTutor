[
    {
        "title": "Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra",
        "authors": "Darioush KevianUsman SyedXingang GuoAaron HavensGeir DullerudPeter SeilerLianhui QinBin Hu",
        "links": "http://arxiv.org/abs/2404.03647v1",
        "entry_id": "http://arxiv.org/abs/2404.03647v1",
        "pdf_url": "http://arxiv.org/pdf/2404.03647v1",
        "summary": "In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra in solving\nundergraduate-level control problems. Controls provides an interesting case\nstudy for LLM reasoning due to its combination of mathematical theory and\nengineering design. We introduce ControlBench, a benchmark dataset tailored to\nreflect the breadth, depth, and complexity of classical control design. We use\nthis dataset to study and evaluate the problem-solving abilities of these LLMs\nin the context of control engineering. We present evaluations conducted by a\npanel of human experts, providing insights into the accuracy, reasoning, and\nexplanatory prowess of LLMs in control engineering. Our analysis reveals the\nstrengths and limitations of each LLM in the context of classical control, and\nour results imply that Claude 3 Opus has become the state-of-the-art LLM for\nsolving undergraduate control problems. Our study serves as an initial step\ntowards the broader goal of employing artificial general intelligence in\ncontrol engineering.",
        "updated": "2024-04-04 17:58:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.03647v1"
    },
    {
        "title": "WorDepth: Variational Language Prior for Monocular Depth Estimation",
        "authors": "Ziyao ZengDaniel WangFengyu YangHyoungseob ParkYangchao WuStefano SoattoByung-Woo HongDong LaoAlex Wong",
        "links": "http://arxiv.org/abs/2404.03635v1",
        "entry_id": "http://arxiv.org/abs/2404.03635v1",
        "pdf_url": "http://arxiv.org/pdf/2404.03635v1",
        "summary": "Three-dimensional (3D) reconstruction from a single image is an ill-posed\nproblem with inherent ambiguities, i.e. scale. Predicting a 3D scene from text\ndescription(s) is similarly ill-posed, i.e. spatial arrangements of objects\ndescribed. We investigate the question of whether two inherently ambiguous\nmodalities can be used in conjunction to produce metric-scaled reconstructions.\nTo test this, we focus on monocular depth estimation, the problem of predicting\na dense depth map from a single image, but with an additional text caption\ndescribing the scene. To this end, we begin by encoding the text caption as a\nmean and standard deviation; using a variational framework, we learn the\ndistribution of the plausible metric reconstructions of 3D scenes corresponding\nto the text captions as a prior. To \"select\" a specific reconstruction or depth\nmap, we encode the given image through a conditional sampler that samples from\nthe latent space of the variational text encoder, which is then decoded to the\noutput depth map. Our approach is trained alternatingly between the text and\nimage branches: in one optimization step, we predict the mean and standard\ndeviation from the text description and sample from a standard Gaussian, and in\nthe other, we sample using a (image) conditional sampler. Once trained, we\ndirectly predict depth from the encoded text using the conditional sampler. We\ndemonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where\nwe show that language can consistently improve performance in both.",
        "updated": "2024-04-04 17:54:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.03635v1"
    },
    {
        "title": "Training LLMs over Neurally Compressed Text",
        "authors": "Brian LesterJaehoon LeeAlex AlemiJeffrey PenningtonAdam RobertsJascha Sohl-DicksteinNoah Constant",
        "links": "http://arxiv.org/abs/2404.03626v1",
        "entry_id": "http://arxiv.org/abs/2404.03626v1",
        "pdf_url": "http://arxiv.org/pdf/2404.03626v1",
        "summary": "In this paper, we explore the idea of training large language models (LLMs)\nover highly compressed text. While standard subword tokenizers compress text by\na small factor, neural text compressors can achieve much higher rates of\ncompression. If it were possible to train LLMs directly over neurally\ncompressed text, this would confer advantages in training and serving\nefficiency, as well as easier handling of long text spans. The main obstacle to\nthis goal is that strong compression tends to produce opaque outputs that are\nnot well-suited for learning. In particular, we find that text na\\\"ively\ncompressed via Arithmetic Coding is not readily learnable by LLMs. To overcome\nthis, we propose Equal-Info Windows, a novel compression technique whereby text\nis segmented into blocks that each compress to the same bit length. Using this\nmethod, we demonstrate effective learning over neurally compressed text that\nimproves with scale, and outperforms byte-level baselines by a wide margin on\nperplexity and inference speed benchmarks. While our method delivers worse\nperplexity than subword tokenizers for models trained with the same parameter\ncount, it has the benefit of shorter sequence lengths. Shorter sequence lengths\nrequire fewer autoregressive generation steps, and reduce latency. Finally, we\nprovide extensive analysis of the properties that contribute to learnability,\nand offer concrete suggestions for how to further improve the performance of\nhigh-compression tokenizers.",
        "updated": "2024-04-04 17:48:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.03626v1"
    },
    {
        "title": "On the Efficiency of Convolutional Neural Networks",
        "authors": "Andrew Lavin",
        "links": "http://arxiv.org/abs/2404.03617v1",
        "entry_id": "http://arxiv.org/abs/2404.03617v1",
        "pdf_url": "http://arxiv.org/pdf/2404.03617v1",
        "summary": "Since the breakthrough performance of AlexNet in 2012, convolutional neural\nnetworks (convnets) have grown into extremely powerful vision models. Deep\nlearning researchers have used convnets to produce accurate results that were\nunachievable a decade ago. Yet computer scientists make computational\nefficiency their primary objective. Accuracy with exorbitant cost is not\nacceptable; an algorithm must also minimize its computational requirements.\nConfronted with the daunting computation that convnets use, deep learning\nresearchers also became interested in efficiency. Researchers applied\ntremendous effort to find the convnet architectures that have the greatest\nefficiency. However, skepticism grew among researchers and engineers alike\nabout the relevance of arithmetic complexity. Contrary to the prevailing view\nthat latency and arithmetic complexity are irreconcilable, a simple formula\nrelates both through computational efficiency. This insight enabled us to\nco-optimize the separate factors that determine latency. We observed that the\ndegenerate conv2d layers that produce the best accuracy-complexity trade-off\nalso have low operational intensity. Therefore, kernels that implement these\nlayers use significant memory resources. We solved this optimization problem\nwith block-fusion kernels that implement all layers of a residual block,\nthereby creating temporal locality, avoiding communication, and reducing\nworkspace size. Our ConvFirst model with block-fusion kernels ran approximately\nfour times as fast as the ConvNeXt baseline with PyTorch Inductor, at equal\naccuracy on the ImageNet-1K classification task. Our unified approach to\nconvnet efficiency envisions a new era of models and kernels that achieve\ngreater accuracy at lower cost.",
        "updated": "2024-04-04 17:39:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.03617v1"
    },
    {
        "title": "Mitigating the Impact of Outlier Channels for Language Model Quantization with Activation Regularization",
        "authors": "Aniruddha NrusimhaMayank MishraNaigang WangDan AlistarhRameswar PandaYoon Kim",
        "links": "http://arxiv.org/abs/2404.03605v1",
        "entry_id": "http://arxiv.org/abs/2404.03605v1",
        "pdf_url": "http://arxiv.org/pdf/2404.03605v1",
        "summary": "We consider the problem of accurate quantization for language models, where\nboth the weights and activations are uniformly quantized to 4 bits per\nparameter, the lowest bitwidth format natively supported by GPU hardware. In\nthis context, the key challenge is activation quantization: it is known that\nlanguage models contain outlier channels whose values on average are orders of\nmagnitude higher than than other channels, which prevents accurate low-bitwidth\nquantization with known techniques. We systematically study this phenomena and\nfind that these outlier channels emerge early in training, and that they occur\nmore frequently in layers with residual streams. We then propose a simple\nstrategy which regularizes a layer's inputs via quantization-aware training\n(QAT) and its outputs via activation kurtosis regularization. We show that\nregularizing both the inputs and outputs is crucial for preventing a model's\n\"migrating\" the difficulty in input quantization to the weights, which makes\npost-training quantization (PTQ) of weights more difficult. When combined with\nweight PTQ, we show that our approach can obtain a W4A4 model that performs\ncompetitively to the standard-precision W16A16 baseline.",
        "updated": "2024-04-04 17:25:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.03605v1"
    }
]