Capabilities of Large Language Models in Control Engineering:
A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra
DarioushKevian1,UsmanSyed1,XingangGuo1,AaronHavens1,
GeirDullerud1,PeterSeiler2,LianhuiQin34,andBinHu∗1
1UniversityofIllinoisUrbana-Champaign
2UniversityofMichigan
3AllenInstituteforAI
4UniversityofCaliforniaSanDiego
∗ Correspondingauthor. E-Mail: binhu7@illinois.edu
Abstract
Inthispaper,weexplorethecapabilitiesofstate-of-the-artlargelanguagemodels(LLMs)suchas
GPT-4,Claude3Opus,andGemini1.0Ultrainsolvingundergraduate-levelcontrolproblems. Controls
providesaninterestingcasestudyforLLMreasoningduetoitscombinationofmathematicaltheoryand
engineeringdesign.WeintroduceControlBench,abenchmarkdatasettailoredtoreflectthebreadth,depth,
andcomplexityofclassicalcontroldesign. Weusethisdatasettostudyandevaluatetheproblem-solving
abilitiesoftheseLLMsinthecontextofcontrolengineering. Wepresentevaluationsconductedbyapanel
ofhumanexperts,providinginsightsintotheaccuracy,reasoning,andexplanatoryprowessofLLMs
incontrolengineering. OuranalysisrevealsthestrengthsandlimitationsofeachLLMinthecontext
ofclassicalcontrol,andourresultsimplythatClaude3Opushasbecomethestate-of-the-artLLMfor
solvingundergraduatecontrolproblems. Ourstudyservesasaninitialsteptowardsthebroadergoalof
employingartificialgeneralintelligenceincontrolengineering.
1 Introduction
Recently,thelandscapeoflargelanguagemodels(LLMs)haswitnessedrapidadvancements,withmodels
such as GPT-4 [1], Claude 3 [2], and Gemini 1.0 Ultra [46] pushing the boundaries of what artificial
intelligence(AI)canachieveincomplexproblem-solvingscenarios. Thesedevelopmentshavesparkeda
growinginterestintheapplicationofLLMsacrossvariousdomains,includingcoding[38,37,52,13,35],
reasoning [51, 28, 57, 45, 25], mathematics [30, 7, 19, 55, 26], science [49, 10, 41, 54, 11], and planning
[47,48,56,44,14]. RecentdiscussionsandstudieshavehighlightedtheimpressivecapabilitiesofLLMsin
manyofthesetasks. Followingthistrajectory,ourpaperaimstoexplorethecapabilitiesofstate-of-the-art
LLMsinsolvingundergraduate-levelcontrolsystemproblems,acornerstoneofengineeringeducationand
research.
Automaticcontrolisafundamentalpillarofmodernengineeringknownforitscomplexfeedbacksystem
designsandtheoreticaldepth[40,18,39,6]. ThepotentialofLLMstotacklecontrolengineeringproblems
presentsanintriguingavenueforresearch,giventhediscipline’srelianceonbothmathematicalrigorand
engineeringdesign. Controlengineeringencompassesavarietyofchallengingconceptsincludingsystem
dynamics, andPID/loopshapingdesign, andstability/robustnessanalysisoffeedbackmechanisms. The
abilityofLLMstounderstandandsolveundergraduate-levelcontrolproblemscouldsignifyasubstantial
1
4202
rpA
4
]CO.htam[
1v74630.4042:viXraleap by integrating artificial intelligence into modern control engineering pipelines. More generally, the
explorationofLLMsinsolvingcontrolproblemsmarksasignificantinquiryintothepotentialofthesemodels
tocontributetoareastraditionallyreservedforspecializeddomain-specifichumanexpertise.
Inthispaper,wedelveintothisemergingresearchareabyevaluatingthecapabilitiesofthreestate-of-
the-artLLMs,namelyGPT-4,Claude3Opus,andGemini1.0Ultra,onourproposedcollege-levelControl
systemproblem-solvingBenchmark,referredtoasControlBench. OurproposedControlBenchintroducesa
carefullycrafteddatasetdesignedtoreflectthebreadth,depth,andcomplexityofclassicalcontroldesign.
Ourproblemsetcapturestheessenceoffeedbacksystemdesignandtheanalyticalskillsrequiredinthisfield.
Throughacomprehensiveevaluationconductedbyapanelofhumanexperts,weassesstheperformanceof
leadingLLMs,includingGPT-4,Claude3Opus,andGemini1.0Ultra,intermsoftheiraccuracy,reasoning
capabilities,andabilitytoprovidecoherentandinformativeexplanations. Ouranalysisshedslightonthe
distinctstrengthsandlimitationsofeachmodel,offeringvaluableinsightsintothepotentialroleofLLMsin
controlengineering. Thisinvestigationnotonlycontributestoourunderstandingofthecurrentcapabilitiesof
LLMsbutalsopavesthewayforfutureresearchaimedatharnessingartificialgeneralintelligenceinthe
advancementofcontrolengineeringsolutions. Ourmaincontributionscanbesummarizedasfollows.
• Weintroduceanewnatural-languagedataset,calledControlBench,totestthecapabilitiesofLLMsin
solvingundergraduatecontrolsystemproblems.
• WepresentevaluationsofGPT-4,Claude3Opus,andGemini1.0UltraonControlBench,conducted
byapanelofhumanexperts. Builtuponouraccuracyandfailuremodeanalysis,wefurtherdiscussthe
strengthsandlimitationsoftheseLLMs. WepresentvariousexamplesofLLM-basedControlBench
responses to support our discussion. Our results imply that Claude 3 Opus has become the state-
of-the-art LLM in solving undergraduate control problems, outperforming the others in this study.
Basedonourobservation,onemainlimitationforallthreeLLMsisthattheyalsosufferonproblems
involvingvisualelementssuchasBodeplotsandNyquistplots. Ourstudyalsoshedslightontherole
ofself-correction,andissuessuchassensitivitytotheproblemstatements.
• WealsointroduceasimplifiedversionofControlBench,termedasControlBench-C,whichonlyconsists
ofsingle-answermultiple-choiceproblems. ControlBench-CenablesfastautomaticevaluationofLLMs
fromresearcherswithoutcontrolbackground. WealsohighlightthelimitationsofControlBench-C.
Specifically,ControlBench-CismuchsimplerthanControlBench,andcannotprovideacomprehensive
evaluationforthereasoningcapabilitiesofLLMsincontrolengineering.
By examining the performance of LLMs in this specialized domain, we take an important step towards
realizingthebroadergoalofintegratingmachineintelligenceintothefabricofengineeringeducationand
research.
RelatedWork: TherehavebeensomeearlyeffortsonusingLLMstogeneratecodes,costfunctions,
and/orvaluemapsforroboticcontroltasks[36,29]. Ourpapertakesacomplementaryangle,focusingon
benchmarkingthecapabilitiesofvariousLLMsinsolvingundergraduatecontrolproblems.
2 Motivating Example: A Showcase for LLM Capabilities in Control Design
Beforeproceedingtoamorecomprehensivebenchmarkstudy,wewillstartwithanillustrativeexampleto
showcasetoshowcasethepotentialofLLMsforsolvingcontroldesignproblems. Inthissection,wefocus
onasimplemotivatingexamplethatconsidersthedesignofaproportional-integral(PI)controllerforacruise
2control system. We will ask GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra to solve this simple PI design
problem,andmakeafewobservations. Theexactproblemstatementisgivenasfollows.1
PIDesignExample
ProblemStatement: ConsideracarwhoselongitudinalmotionismodeledbythefollowingODE:
2085v˙(t)+23.2v(t)=40u(t)+108.4−F (t)
grav
Theinputisthethrottleuandtheoutputisthevelocityv. ThegravitationalforceF isadisturbance.
grav
Lete(t)=v −v(t)denotethetrackingerrorbetweenthedesiredvelocityv =29m/sandactual
des des
velocityv(t). ConsideraPIcontrollerofthefollowingform:
t
u(t)=u¯+K e(t)+K ∫ e(τ)dτ
p i
0
whereu¯=14.11istheopen-loopinputtomaintainv whenonatroadθ=0○ . ChoosethePIgains
des
sothatthecruisecontrolsystemisstableandrejectsdisturbancesduetochangingroadslopeswithin
≈10sec. Theclosed-loopshouldalsobeoverorcriticallydampedasoscillationsareuncomfortable
forthedriver.
Thisparticularproblemisofinterestasitisoneofthefirstdesignproblemsencounteredbyundergraduates
incontrolengineering. Moreover,itrequiresreasoningabouttheimpactofthecontrolgainsontheclosed-
looppolesandtheconnectiontotransientresponseproperties. Thereismorethanonedesignthatsatisfies
the given objectives. One approach is to note that the closed-loop characteristic equation is 2085s2 +
(23.2+40K )s+40K = 0. We can place the closed-loop poles in the left half plane (LHP) to have any
p i
desireddampingratioζ andnaturalfrequencyω bychoosingthecontrollergainstosatisfyω2 = 40Ki and
n n 2085
2ζω = 23.2+40Kp. Selectingζ =1givestwocriticallydampedclosed-looppolesplacedats=−ω . Thetime
n 2085 n
constantforthesepolesisτ = 1 secand,forcriticallydampedpoles,the5%settlingtimeisapproximately
ωn
4.75τ = 4.75. Thuswecanselectω = 4.75 =0.475toobtainasettlingtimenear10sec. Finally,usingζ =1
andω =ω 0n .475tosolveforthePIn gain1 s0 leadstoK = 48.94andK = 11.76. Thecorrespondingtransfer
n p i
functionfromF tov is
grav
−s
T (s)= (2.1)
Fgrav→v 2085s2+1981s+470.4
Thishascriticallydampedpolesats=−0.475asexpected. Astepchangeincreaseingravitationalforce(due
toastepincreaseintheroadslope)willcausethevelocitytoinitiallydropfromthedesiredvalue. However,
thePIcontrollerrejectsthedisturbancein≈10secwiththevelocityconvergingtothedesiredvaluewitha
niceoverdampedresponse.
InitialAnswersfromLLMs: WetestedGPT-4,Claude3Opus,andGemini1.0ontheaboveproblem.
GPT-4givesashortanswerdescribingtheprocesswithaself-evaluated40%confidenceinitsanswer(we
askLLMstoprovideconfidencescoresfortheirownanswers). ThekeypartoftheGPT-4answermakesthe
followingstatementwithoutgivingfeasiblevaluesforthePIgains.
1ThisexampleisactuallyProblem5.17fromControlBench,whichwillbeintroducecinthenextsection.
3GPT-4: Steps for PI Controller Design include Linearization, Transfer Function derivation, and PI
ControllerDesigntoensureStability,DisturbanceRejection,andDampingcriteriaaremet.
We marked the answer from GPT-4 as "Incorrect". Gemini 1.0 Ultra gave a slightly more detailed set of
designstepsbutalsofailedtoprovidevaluesforthePIgains. ThesolutionfromGemini1.0Ultraisalso
markedas"Incorrect."
Interestingly,inourinitialtesting,Claude3Opusfollowedalmosttheexactprocedureasourbaseline
solutiongivenabovewithaself-evaluated90%confidence. Itusedaslightlydifferentapproximationforthe
settlingtimeandchoseclosed-looppolesats=−0.1and−0.2rad/sec. ItthensolvedforthegainsK =48.1
p
andK =10.4. Itmadeacalculationerrorasthesegainsactuallyplacetheclosed-looppolesats=−0.60
i
and−0.33. However,thiscalculationerrorisminorandthereasoningusedbyClaude3Opusinthedesignis
correct. OneotherminorpointisthatClaude3basesitsdesignontheclosed-looptransferfunctionfrom
referencetooutput,i.e. onthecomplementarysensitivity.
40K s+40K
T(s)= p i (2.2)
2085s2+(23.2+40K )s+40K
p i
Notethatthistransferfunctionisdistinctfromthedisturbancetooutputtransferfunction(2.1)asitincludes
azeroduetothePIcontroller. ThegainsgivenbyClaude3Opusplacethiszeroatat−Ki =−0.21. This
Kp
zeroisclosetotheimaginaryaxisand,asaresult,causesasignificantovershootduetostepchangesinthe
referencespeed. Thismightbeuncomfortabletothedriver. Toinvestigatethisissuefurther,werewordedthe
designproblemtoincludethefollowingprompt.
RewordedProblem: TodesignaPIcontrollerforthegivencarlongitudinalmotionmodel,weneed
to choose the gains K and K such that the closed-loop system is stable, rejects disturbances within
p i
approximately10seconds,andhasanovershootlessthan1%inthestepresponse.
ThisvariationofthequestionismorechallengingthantheoriginalwordingasitrequirestheLLMto
reasonabouttheeffectoftheclosed-loopzeroonthestepresponsecharacteristics. Inotherwords,itisnot
sufficienttosimplyplaceoverdampedclosed-looppolesasthezerocancausesovershootasinthedesign
solutionsabove. Claude3Opusrepeatsitsdesignwithaconfidenceof90%andthefollowingreasoning:
Claude3Opus: Forastablesystemwithanovershootlessthan1%,thedampingratioshouldbeζ ≥0.826.
√
Wecanchoosethepolestobes =−ζω ±jω 1−ζ2,withζ =0.9andω =0.4toachieveasettling
1,2 n n n
timeofapproximately10seconds(settlingtime≈ 4 ).
ζωn
Claude3OpusthencomputesgainsofK =71.6andK =33.4. Thesegainsyieldclosed-looppoleswith
p i
ζ = 0.865 and ω = 0.8rad/sec so there again appears to be a minor calculation error. More importantly,
n
Claude3Opusfailedtoaccountfortheeffectofthezeroontheovershootinitsreasoning. Finally,wegive
theprompt: ‘‘thinkabouttheimpactsofclosed-loopzeros."ThispromptwassufficientasClaude3Opus
thenre-workeditsdesigntoaccountforthezeroandreturnedPIgainsK =200andK =5thatdid,indeed,
p i
giveastepreferenceresponsewithovershootlessthan1%.
Obviously,thereissomerandomnessintheanswergenerationfromLLMs. Fortheabovequestion,even
withthelastpromptonzeros,LLMs(includingClaude3Opus)donotalwaysgivecorrectanswersdueto
potentialcalculationmistakes. However,webelievethattheaboveexampledemonstratesthepotentialof
LLMsincontrolengineering,astheyalreadyhavemasteredtheknowledgeofbasiccontroldesigntosome
extent. Next,wewillintroduceControlBenchforexaminingthecapabilitiesofLLMsincontrolengineering.
4Table1: Summaryofthecontrolproblemdataset. Wereportthenumberofproblemsundereachtopic,and
thenumberofproblemswithvisualelements.
Topic #ofProblems #Visual
Background 28 0
Stability 19 0
Timeresponse 21 3
Blockdiagrams 5 5
ControlSystemDesign 24 0
BodeAnalysis 15 13
Root-LocusDesign 7 1
NyquistDesign 5 4
Gain/PhaseMargins 9 0
SystemSensitivityMeasures 3 0
Loop-shaping 4 0
AdvancedTopics 7 0
Total 147 26
3 The ControlBench Dataset
ToassessthecapabilitiesofLLMsinsolvingcontrolproblems,wefirstcreateacollectionof147undergrad-
uatecontrolproblems. Thiscollectioncomprisesproblemssourcedfromexercisesin[16], andproblems
gatheredfromundergraduatecontrolclassesatUniversityofMichigan(EECS460)andUniversityofIllinois,
Urbana-Champaign(ECE486).
Ourproblemsetspansabroadspectrumoftopicstypicallyencounteredinundergraduatecontrolcourses,
blendingbothtextualandvisualelementstomirrorthemultifacetednatureofreal-worldapplications. Such
integrationiscrucialascontrolsystemdesigninherentlynecessitatesvarioustypesofplotstoanalyzeand
understandsystembehaviors. Forinstance,inthecontextoffrequency-domaincontroldesign,Bodeplots
andNyquistplotsareoftenusedasfundamentaltoolsforanalysis. Ourdatasetcoversthesetopics,serving
as a valuable tool for assessing the efficacy of LLMs in utilizing graphical information to tackle control
problems. Wesummarizethestatisticsofourcontrolproblemdatasetforeachsub-topicinTable1,wherewe
alsoreportthenumberofproblemswithvisualelementsundereachtopic.
WecollecteachproblemfromoriginaldocumentsinPDFfilesandpresentationslides. Wemanually
transfer these problems into LaTeX format. All the problems are carefully verified by human annotators
toensurethatLaTeXdocumentscanbecompiledwithoutanysyntaxerrors. Inaddition,wealsoprovide
a detailed step-by-step solution for each problem in LaTeX. Our ControlBench dataset and the related
Latex/PDFfilesareavailableathttps://agi4engineering.github.io/LLM4Control/.
4 Evaluations of Leading LLMs on ControlBench
Inthissection,wepresenttheevaluationresultsforGPT-4,Claude3Opus,andGemini1.0Ultra,focusing
ontheirperformanceinsolvingcontrolproblemscompliedwithinourdatasetControlBench.
54.1 StatisticalAccuracyAnalysis
First,weexaminetheaccuracyofGPT-4,Claude3Opus,andGemini1.0Ultrainsolvingtheproblemsfrom
ControlBench. TofacilitateafoundationalunderstandingofhowLLMsapproachcontrolproblems,westart
withazero-shotpromptingstrategy(i.e.,directlyinputtingthequestion)andexaminetheresponsesthrough
humanannotation. Thissettingcanillustratedasfollows:
Zero-ShotSetting
HumanInput: Considerthecontrolproblem...
GPT-4: Forthisproblem,weneedtoconsiderseveralaspects,includingthedynamicsoftheplant,
thecharacteristicsofthePIcontroller,and...
Claude 3 Opus: For this problem, we need to consider the closed-loop system dynamics. Let’s
approachthisstepbystep...
Gemini1.0Ultra: Absolutely,let’sanalyze...
OncewegettheLLMresponses,wecheckthecorrectnessoftheLLManswersviahumanannotation.
The input to LLMs is typically just copied from the LaTex description of the problems in ControlBench.
Thissimplezero-shotsettingservesastartingpointforouranalysis. Tounderstandhowself-checkingcan
improve the performance [27, 32, 50], we also study a setting where a subsequent self-checking prompt
suchas"carefullycheckyouransweragain"isusedtoaidLLMsinidentifyingandrectifyingtheirprevious
mistakes. Thissettingisillustratedasfollows.
Self-Checking(orSelf-Correction)
HumanInput: Considerthecontrolproblem...
Claude3Opus: Wecanperformthefollowingcalculationsstepbystep...
HumanInput: Checkyoursolutionscarefullyandfixalltheerrors.
Claude3Opus: Iapologizefortheconfusion. Letmecorrecttheerrorsandprovideamoreaccurate
solution...
Once we get the revised LLM answers, the correctness is again examined by human experts. In this
section,wetestbothsettingsforGPT-4,Claude3Opus,andGemini1.0Ultra.
Evaluation Metric: Our main evaluation metric is Accuracy (ACC), defined as the proportion of
instances where the LLMs correctly solve the given problems. In the LLM literature, it is known that
sometimesasimpleself-checkingprompt,suchas"carefullycheckyouransweragain",enablesLLMsto
identityandfixerrorsintheirpreviousanswers[27]. Toquantifythisself-correctionability,wedeploya
subsequentself-checkingpromptforinitiallyincorrectresponses,aidingLLMsinidentifyingandamending
6Table2: Accuracy(ACC)andSelf-CheckedAccuracy(ACC-s)ofGPT-4,Claude3Opus,andGemini1.0
Ultrainsolvingcontrolproblemsacrossvarioustopics. TheACC-smetricrepresentsthemodels’ability
tocorrecttheirinitialerrorsuponaself-review, offeringinsightintotheadaptabilityanderror-correction
capabilitiesofeachmodelwhentacklingcontrolproblems. Thebestresultsforeachmetricarehighlighted
inbold.
GPT-4 Claude3Opus Gemini1.0Ultra
Topics ACC↑ ACC-s↑ ACC ACC-s ACC ACC-s
Background 60.7%(17/28) 64.3%(18/28) 75%(21/28) 89.3%(25/28) 53.6%(15/28) 57.1%(16/28)
Stability 57.9%(11/19) 57.9%(11/19) 76.2%(15/19) 89.5%(17/19) 31.6%(6/19) 31.6%(6/19)
Timeresponse 57.1%(12/21) 66.6%(14/21) 76.2%(16/21) 76.2%(16/21) 52.4%(11/21) 57.1%(12/21)
Blockdiagrams 40.0%(2/5) 40.0%(2/5) 40.0%(2/5) 60.0%(3/5) 0.0%(0/5) 0.0%(0/5)
ControlSystemDesign 29.2%(7/24) 29.2%(7/24) 33.3%(8/24) 62.5%(15/24) 25.0%(6/24) 37.5%(9/24)
BodeAnalysis 6.66%(1/15) 6.66%(1/15) 13.3%(2/15) 13.3%(2/15) 6.66%(1/15) 6.66%(1/15)
Root-LocusDesign 28.6%(2/7) 28.6%(2/7) 42.9%(3/7) 42.9%(3/7) 28.6%(2/7) 28.6%(2/7)
NyquistDesign 0.0%(0/5) 0.0%(0/5) 40.0%(2/5) 40.0%(2/5) 0.0%(0/5) 0.0%(0/5)
Gain/PhaseMargins 66.7%(6/9) 66.7%(6/9) 66.7%(6/9) 66.7%(6/9) 33.3%(3/9) 33.3%(3/9)
SystemSensitivityMeasures 100.0%(3/3) 100.0%(3/3) 100.0%(3/3) 100.0%(3/3) 66.7%(2/3) 100.0%(3/3)
Loop-shaping 25.0%(1/4) 25.0%(1/4) 50.0%(2/4) 75.0%(3/4) 25.0%(1/4) 25.0%(1/4)
AdvancedTopics 71.4%(5/7) 71.4%(5/7) 85.7%(6/7) 85.7%(6/7) 42.9%(3/7) 57.1%(4/7)
Total 45.6%(67/147) 47.6%(70/147) 58.5%(86/147) 68.7%(101/147) 34.0%(50/147) 38.8%(57/147)
mistakes. This leads to the Self-Checked Accuracy (ACC-s) as a secondary metric, which quantifies the
instancesinwhichLLMssuccessfullyamendtheiranswersafteraself-reviewprocess.
Table2providestheAccuracy(ACC)andSelf-CheckedAccuracy(ACC-s)ofGPT-4,Claude3Opus,
and Gemini 1.0 Ultra across a variety of control problem topics in our dataset ControlBench. Claude 3
Opusemergesasthestandoutmodel,demonstratingsuperiorperformanceinbothACCandACC-s. This
indicates that Claude 3 Opus not only has a higher baseline understanding of control problems but also
exhibitssuperiorself-correctioncapabilities2. GPT-4displayscompetitiveaccuracyinspecificareas,suchas
BlockDiagrams,Root-LocusDesign,andSystemSensitivityMeasures,butdoesnotmatchClaude3Opusin
overallperformance. Gemini1.0Ultra,meanwhile,ranksloweringeneraleffectiveness. Notably,Claude3
Opusalsoshowsenhancedproficiencyinhandlingproblemswithvisualcomponents,particularlyintopics
likeNyquistDesign, Root-LocusDesign, andLoop-shaping. Itisimportanttoclarifythattheaccuracies
detailed in Table 2 are not intended for direct comparison with human expertise. Instead, these results
establishaninitialbenchmarkfortheperformanceofLLMsinaddressingcollege-levelcontrolproblems.
WealsowanttoemphasizethatthereissomerandomnessintheanswergenerationsofallthreeLLMs.
Evenforthesamequestion,allthreeLLMscangeneratedrasticallydifferentanswers. Therefore,ourresults
shouldbeinterpretedinamorequalitativemanner,i.e. theygiveaninitialcomparisonofthecapabilitiesof
GPT-4,Claude3Opus,andGemini1.0Ultrainsolvingcontrolproblems. Morestudyisdefinitelyneededin
thefuture. Next,weshowcasethepotentialofLLMsinsolvingcontroldesignproblemsviaanillustrative
example,andthendiscusstheirfailuremodesandself-correctioncapabilitiesobservedinourexperiments.
4.2 StrengthsofLLMsandSuccessfulExamples
FromTable2,wecanseethatLLMs(especiallyClaude3OpusandGPT-4)doreasonablywellinsolving
problemsrelatedtobackgroundmathematics,stability,andtimeresponse. Inaddition,Claude3Opushas
2Thisalignswiththefindingsin[2]mentioningthesuperiorperformanceofClaude3Opusonmanytaskscomparedtoother
LLMsincludingGPT-4andGemini1.0Ultra.
7achieved33.3%ACCand70.8%ACC-sinbasiccontroldesignproblems,demonstratingitspotentialinthe
domainofcontrolsystemdesign. Inthissection,wewillpresentseveralsuccessfulexamplestoshowcasethe
currentcapabilitiesofLLMsincontrolengineering. Wewillstartwiththefollowingsimplestabilityproblem
whichhasbeensuccesfullysolvedbyallthreeLLMs.
Routh-HurwitzStabilityCriteria(Problem2.6fromControlBench)
HumanInput: Asystemhasacharacteristicequationgivenby
s3+Ks2+(K+1)s+6=0. (4.1)
DeterminetherangeofK forastablesystem. YoucanuseRouth-HurwitzStabilityCriteria.
GPT-4: TodeterminetherangeofK forastablesystemusingtheRouth-HurwitzStabilityCriteria,
westartwiththegivencharacteristicequation:
s3+Ks2+(K+1)s+6=0.
WeconstructtheRoutharrayasfollows...Solvingthesecondinequality,wefindthesolutiontobe
K < −3 or K > 2. However, since K > 0 is required for stability, we ignore the solution K < −3.
Hence,forthesystemtobestable,therangeofK isK >2.
Claude3Opus: TodeterminetherangeofKforastablesystemusingtheRouth-Hurwitzstability
criteria,weneedtoanalyzethecoefficientsofthecharacteristicequation. Given: Thecharacteristic
equationiss3+Ks2+(K +1)s+6=0. Step1: Writethecharacteristicequationinthestandard
form. a s3+a s2+a s+a = 0, where: a = 1, a = K, a = K +1, a = 6. Step 2: Apply the
0 1 2 3 0 1 2 3
Routh-Hurwitzstabilitycriteriaforathird-ordersystem. Forastablesystem,allthecoefficientsofthe
characteristicequationmustbepositive,andthefollowingconditionmustbesatisfied: a a >a a .
1 2 0 3
Step3: Checkthepositivityofthecoefficients. a =1>0(alwayspositive)a =K >0a =K+1>0
0 1 2
a = 6 > 0 (always positive) From a > 0 and a > 0, we get: K > 0 and K > −1. Step 4: Check
3 1 2
theconditiona a >a a . a a >a a K(K +1)>1×6K2+K −6>0. Solvingthequadratic
1 2 0 3 1 2 0 3
inequality: (K+3)(K−2)>0K <−3orK >2. Step5: CombinetheconditionsforK.Fromsteps
3and4,wehave: K >0andK >2. Therefore,therangeofKforastablesystemisK >2.
Gemini1.0Ultra: Routh-HurwitzStabilityCriterion: TheRoutharrayis:
s3 1 K+1
s2 K 6
s1 K2+K−6 0
K
s0 6 0
ConditionsforStability: K >0,K2+K−6>0 (cid:212)⇒ (K−2)(K+3)>0,6>0(alwaystrue)
RangeofKforstability: K >2
For the above stability problem, all three LLMs follow roughly the same reasoning path and reach to the
correct answer eventually. There are many other stability problems (from ControlBench) which actually
causedifficultyforGemini1.0UltraorevenGPT-4. Overall,wecanseefromTable2thatClaude3Opus
8hasoutperformedGPT-4andGemini1.0UltrainansweringControlBenchquestionsrelatedtobackground
mathematics,stability,andtimeresponse.
Next,wegiveoneexampleshowcasingthebasiccontroldesignknowledgeofGPT-4andClaude3Opus.
PolePlacement(Problem5.2fromControlBench)
HumanInput: Aplantwithnominalmodel
1
G (s)= (4.2)
o (s+1)2
is in a feedback loop under control with a PI controller having transfer function C(s) = Kps+Ki.
s
Determinewhetherthiscontrollerconfigurationcanbeusedtoachievefullpoleplacement.
GPT-4: Incontroltheory,poleplacementisastrategyforthedesignoffeedbackcontrollerstoforce
theclosed-loopcontrolsystemtohavedesiredeigenvaluesorpoles...Thischaracteristicequationis
acubicpolynomialins,whichmeansitwillhavethreerootsorpoles. However,theabilitytofreely
placethesepolesislimitedbythestructureofthepolynomial. Ingeneral,fullpoleplacementrequires
asmanyadjustableparametersastherearepoles. Inthiscase,wehaveonlytwoparameters(K and
p
K )toadjustthreepoles. Thus,whilethePIcontrollerconfigurationcaninfluencethelocationofthe
i
polestosomeextent,itcannotachievearbitrarypoleplacementforallthreepolesduetothelimited
numberoftuningparameters. Additionalcontrolterms,suchasaderivativeterm(makingitaPID
controller),mayberequiredtoachievefullpoleplacementcapabilityinthisscenario.
Claude3Opus: TodetermineifthegivenPIcontrollerconfigurationcanachievefullpoleplacement,
weneedtoanalyzetheclosed-looptransferfunctionofthesystem...Forfullpoleplacement,the
controllershouldhaveatleastasmanyparametersastheorderoftheplant. Inthiscase,theplantis
ofsecondorder,andthePIcontrollerhastwoparameters(K andK ). However,theclosed-loop
p i
characteristic equation is of third order. Therefore, the given PI controller configuration cannot
achievefullpoleplacementforthisplant. Toachievefullpoleplacement,wewouldneedacontroller
withatleastthreeparameters,suchasaPIDcontrollerorahigher-ordercontroller.
Gemini 1.0 Ultra: Here’s a breakdown of how to determine if full pole placement is achievable
...Becausethenumberofadjustableparametersfromthecontrollermatchesthenumberofpolesin
theplant,youcanlikelyachievefullpoleplacementwiththegivenPIcontrollerconfiguration. Note
thatthisassumesthesystemiscontrollable;you’dstillneedtoverifyitscontrollability.
Fortheaboveproblem,bothGPT-4andClaude3Opusreachthecorrectconclusion,andthesampledanswer
fromGemini1.0Ultraiswrong. Ifwekeeponsamplinganswersforthisquestion,sometimesGemini1.0
Ultrawillalsogivethecorrectanswer(andClaude3Opuscanoccasionallygiveawrongansweratfirstand
thenfixesthemistakeafterself-checking). Thisexamplegivesusaroughideaontheknowledgelevelof
LLMsonbasiccontroldesign. BasedonTable2,itisfairtostatethatClaude3Opushasshownstronger
potentialinaddressingclassiccontroldesigntasks,i.e. ithasachievedmuchhigherACCandACC-sforthis
topic. NowwegiveanotherexampletoshowcasethesuperiordesigncapabilitiesofClaude3Opus.
9PIDControl(Problem5.11fromControlBench)
HumanInput: Considertheplantwiththefollowingtransferfunction:
505
G(s)=
s3+21s2+121s+101
Thepolesofthissystemareats=−1,−10±j,andtheDCgainis5.
(a) WhatisthedominantpoleapproximationG (s)forthisplant?
a
(b) WouldyourecommendusingaPI,PD,orPIDcontroller?
(c) Choosethecontrollergainssothattheclosed-loopwithG (s)haspolesrepeatedats=−1
a
GPT-4: To address your questions, let’s break down each part systematically ...Therefore, the
dominantpoleapproximationG (s)isG (s)= 5 ...Giventhesystemhasasingledominantpole
a a s+1
andassumingwewantbothgoodsteady-stateperformanceandresponsivedynamics,aPIDcontroller
wouldbeabalancedchoice,providingacompromisebetweenresponsivenessandsteady-stateerror
correction...GiventhecomplexityofG(s)andthenonlinearityintroducedbythePIDcontroller,
thisprocesscanbequiteinvolvedandmayrequirenumericalmethodsorrootlocustechniquesto
solveaccurately. Ifamoredetailedsolutionisneeded,Icouldassistfurtherwiththatprocess.
Claude3Opus: Alright,let’stacklethisproblemstepbystep:
(a)ThedominantpoleapproximationG (s)isfoundbyconsideringthepoleclosesttotheorigin
a
(thedominantpole)andneglectingtheotherpoles. Inthiscase,thedominantpoleisats=−1. The
transferfunctionofthedominantpoleapproximationis: G (s)= K ,whereK istheDCgainof
a s+1
theoriginalsystem. GiventhattheDCgainis5,wehave: G (s)= 5 .
a s+1
(b)Sincethedominantpoleisrealandthesystemisstable,aPIcontrollerwouldbeagoodchoiceto
eliminatesteady-stateerrorandimprovethesystem’sresponse.
(c)Toplacetheclosed-looppolesofG (s)withaPIcontrollerats=−1,thecharacteristicequation
a
should be: (s+1)2 = 0. The closed-loop transfer function with a PI controller is: Ga(s)C(s) ,
1+Ga(s)C(s)
whereC(s)=K + Ki. Thecharacteristicequationis: 1+G (s)C(s)=0,1+ 5 (K + Ki)=0,
p s a s+1 p s
1+ 5Kps+5Ki = 0, s(s+1)+5K s+5K = 0, s2 +(5K +1)s+5K = 0. To place the poles at
s(s+1) p i p i
s=−1,thecharacteristicequationshouldbe: (s+1)2 =s2+2s+1=0. Comparingthecoefficients,
weget: 5K +1=2and5K =1. Solvingforthecontrollergains: K = 1 andK = 1 Therefore,
p i p 5 i 5
thePIcontrollertransferfunctionis: C(s)= 1 + 1 .
5 5s
Gemini1.0Ultra: Absolutely,let’sanalyzethiscontrolsystemproblem...Wecanapproximatethe
transfer function as: G (s) ≈ 505 ...We need to substitute the plant and controller transfer
a s2+20s+100
functionsintothecharacteristicequationandequatecoefficients. Thisisasomewhatinvolvedprocess
thatwouldtypicallymakeuseofsymboliccomputationsoftware...
Forthisproblem,theabovesampledanswerfromClaude3Opusiscorrect3. Interestingly,forPart(b),Claude
3Again,thereissomerandomnessinvolved.Basedonourobservationonthisproblem,moreoftenthannot,Claude3givesthe
10Figure1: Proportions(%)ofsevenerrortypes(#errors/#totalcases)forGPT-4andClaude3Opus,including
portionofcorrectanswersforquickcomparison
3OpusoftenprefersaPIcontroller,whileGPT-4andGemini1.0UltratendtochooseaPIDcontroller(we
havetriedgeneratingmanysampledanswersfromGPT-4,andweobservedthatveryoccasionally,GPT-4
mayalsochooseaPIcontroller). Claude3Opusgivesthefollowingreason: “aPIcontrollercaneffectively
eliminatesteady-stateerrorandachievethedesiredclosed-loopperformancewithouttheaddedcomplexity
ofthederivativeaction."Thiscapturestheessenceofthisquestion: derivativecontrolisnotrequiredasthe
dominantpoleapproximationfortheplantisfirstorder. ItisinterestingthatClaude3Opusisabletocorrectly
reasonabouttheimpactofthisdominantpoleapproximationonthechoiceofthecontrolarchitecture. This
exampleagainshowcasesthepotentialofClaude3Opus,althoughtheconsistencyisstillanopenissue.
4.3 AnalysisandInsightsforFailureModes
Despitetheirgreatpotential,LLMscanfailinmanydifferentways. Inthissection,wediscussvariousfailure
modesobservedinourexperiments,subsequentlybuildingtowardsmoreintricatefailuremodeanalysis.
Wehaveobservedquitediversefailuremodesinourexperiments. Tomakethediscussionmoreformal,
wecategorizetheLLMfailuresintoseveraltypes, andhighlighttheproportions(%)ofsevenerrortypes
forGPT-4andClaude3OpusinFigure1(forsimplicity,ourdiscussioninthissectionmainlyfocuseson
comparingGPT-4andClaude3Opus,bothofwhichoutperformGemini1.0Ultra). Ourerroranalysisis
performedforACC-s. FromFigure1,wecanseethatthebiggestbottleneckpreventingGPT-4toachieve
better accuracy on ControlBench is its limited reasoning capabilities. In contrast, Claude 3 Opus has
significantly fewer reasoning errors. This observation is consistent with the fact that Claude 3 Opus has
surpassedGPT-4formanyreasoningtasksingeneral. Currently,thebiggestbottleneckforClaude3Opusis
itscalculationabilities. However,issuesrelatedtocalculationerrorscanbetypicallymitigatedbycalling
externalcalculationtoolsoradoptingtheprogram-of-thoughtapproach[12]. Forexample,asdemonstrated
in[41],theprogram-of-thoughtapproachcansignificantlyreducetheLLMcalculationerrorsinchemistry
rightanswer.
11problemsviatranslatingtheLLMsolutionintoPythoncodes. Althoughpursuingsuchextensionsisbeyond
thescopeofourpaper,weexpectthattheperformanceofClaude3OpusonControlBenchcanbesignificantly
improvedinthenearfutureviaimprovingthecalculationprecision. Incomparisontothecalculationerrors,
thereasoningissueismorefundamental. Inthemachinelearningfield,thereareon-goingresearchefforts
aimingtoimprovethereasoningcapabilitiesofLLMs[53,8,23]. Wewillinvestigatehowtointegratesuch
effortswithControlBenchinthefuture.
WealsonoticethatallthreeLLMssufferfrommisreadinggraphicaldataincludingBode,Nyquist,and
root-locusplots. Toillustratethisissue,weconsiderasimpleBodeplotproblemtakenfromEECS460at
UniversityofMichigan. Theproblemstatementisgivenasfollows(thisisProblem6.3ofControlBench).
Figure2: BodePlotExample
BodePlotExample(Problem6.3fromControlBench)
Human Input: A linear time-invariant system G(s) with input u and output y has the Bode plot
shownabove:
(a) Whatis∣G(10j)∣indB andactualunits?
(b) Whatis∠G(10j)indegsandradians?
GPT-4: For(a),∣G(10j)∣indBisapproximately-6dB.Inactualunits,∣G(10j)∣=10− 206 ≈0.5012.
For(b),∠G(10j)isapproximately-45degrees,orinradians, −45×π ≈−0.7854radians.
180
Claude3Opus: For(a),fromthemagnitudeplot,∣G(10j)∣≈−45dB.Convertingtoactualunits:
∣G(10j)∣ = 10−45/20 ≈ 0.00562. For (b), from the phase plot, ∠G(10j) ≈ −90○. Converting to
radians: ∠G(10j)≈−π rad.
2
Ashumans,wecaneasilyseethat∣G(j10)∣=0dB =1and∠G(j10)=−90deg=−πrad. However,forsuch
2
asimpletask,GPT-4andClaude3Opusbothgivewronganswers. BothLLMsmisreadthemagnitudeplot
inFigure2,andmademistakesinansweringthefirstpartoftheabovequestion. Forthisexample,Claude3
12Opussomehowreadsthephaseplotcorrectly. However,ingeneral,bothGPT-4andClaude3Opusperform
badly on problems that require extracting data from plots. This highlights the need of developing more
advancedvisuallanguagemodelsforsolvingsuchproblems. Besidestheabovemainobservations,several
otherfindingsarealsoworthdiscussing. Nextwepresentthesefindings.
Commonvs. IsolatedMistakes: WehaveobservedthatGPT-4,Claude3Opus,andGemini1.0Ultra
sometimesmakethesamemistakes. However,itismoreoftentoseethatthesemodelsexhibitdiverseisolated
failurecasesthatareduetoeithertherandomnessintheLLManswergenerationorsomespecifictraining
dataidiosyncrasies. Weillustratethisviathefollowingsimpleexample(Problem3.5fromControlBench).
Problem3.5fromControlBench
HumanInput: Whatistheunitstepresponseofacontinuoussystemwhosetransferfunctionhasa
zeroat−1,apoleat−2,andagainfactorof2?
GPT-4: Givenasystemwithatransferfunctioncharacterizedbyazeroats=−1,apoleats=−2,
and a gain factor of 2, the transfer function H(s) is expressed as H(s) = 2s+1. The unit step
s+2
responseofthesystemcanbefoundbydeterminingtheoutputY(s)whentheinputisaunitstep
function u(t), whose Laplace transform is 1. Thus, the Laplace transform of the output is given
s
by Y(s) = H(s)× 1 == 2 s+1 . This expression can be decomposed into partial fractions to
s s(s+2)
facilitate the inverse Laplace transform Y(s) = 2(A + B ). Solving for coefficients A and B by
s s+2
setting s = 0 and s = −2, respectively, and then equating coefficients, we find Y(s) = 1 + 1.
s+2 s
TakingtheinverseLaplacetransformofY(s)givestheunitstepresponsey(t)inthetimedomain:
y(t) = L−1{ 1 + 1} = e−2tu(t)+u(t), where u(t) is the unit step function. Therefore, the unit
s+2 s
stepresponseofthegivensystemis: y(t)=e−2t+1 for t≥0.
Claude3Opus: Tofindtheunitstepresponseofthegivensystem,weneedtofollowthesesteps:
Writethetransferfunctionofthesystem. Performpartialfractionexpansiononthetransferfunction.
FindtheinverseLaplacetransformoftheresultingexpression.
Step1: TransferfunctionThetransferfunctionisgivenby: G(s)=2⋅ s+1.
s+2
Step2: Partialfractionexpansion 2(s+1) =2− 2
s+2 s+2
Step3: InverseLaplacetransformTheinverseLaplacetransformofaconstantistheconstantitself
multipliedbytheunitstepfunction,andtheinverseLaplacetransformof 1 ise−atu(t),whereu(t)
s+a
istheunitstepfunction. Therefore,theinverseLaplacetransformof2− 2 is:
s+2
2
L−1[2− ]=2u(t)−2e−2tu(t)
s+2
The unit step response of the system is: y(t) = 2u(t) − 2e−2tu(t). This can be simplified to:
y(t)=2(1−e−2t)u(t). Therefore,theunitstepresponseofthecontinuoussystemwithazeroat−1,
apoleat−2,andagainfactorof2isy(t)=2(1−e−2t)u(t).
Fortheaboveproblem,GPT-4iscorrect,whileClaude3Opusmakesamistake. Infact,nomatterhowwe
askClaude3Opustodoself-checkingonthisproblem,italmostalwaysgivesthesamewronganswerhere
(interestingly,differentwrongreasoningpathsshowuptoleadtothesamewrongfinalanswer). Therefore,it
seemsthatClaude3Opushasaspecialisolatedfailuremodeforthisproblem,whichisnotsharedbyGPT-4
13orGemini1.0Ultra. HereisasampledanswerfromClaude3Opusafterself-checking.
Claude3OpuswithSelf-CorrectionforProblem3.5fromControlBench
HumanInput: Youranswerisincorrect. Fixit.
Claude3Opus: Iapologizefortheconfusioninmypreviousresponse. Letmecorrecttheanswer
foryou. Givenzeroats=−1,poleats=−2,gainfactorof2,thecorrecttransferfunctionis:
s+1
G(s)=2⋅
s+2
Tofindtheunitstepresponse,wecanusethefollowingpropertyoftheLaplacetransform: Lu(t)= 1.
s
Multiplyingthetransferfunctionby 1:
s
Y(s) s+1 1
=G(s)=2⋅ ⋅
U(s) s+2 s
Simplifying:
s+1
Y(s)=2⋅
s(s+2)
Usingpartialfractionexpansion:
1 1
Y(s)=2⋅( − )
s s+2
TakingtheinverseLaplacetransform:
y(t)=2⋅(1−e−2t)u(t)
Therefore,thecorrectunitstepresponseofthecontinuoussystemwithazeroat−1,apoleat−2,and
againfactorof2isy(t)=2⋅(1−e−2t)u(t).
ItisinterestingtoseehowClaude3Opusgetsstuckwiththesamemistakeforthisproblem. Ifweprompt
Claude 3 Opus to carefully check the partial fraction expansion of Y(s), then it will generate the correct
answer and give a very detailed reasoning process for getting the correct inverse Laplace transform of
Y(s) = 2⋅ s+1 . This example demonstrates that each LLM may have its own internal bias which may
s(s+2)
affectthefinalsolutionandleadtouniqueisolatedmistakes.
CorrelationsofFailuresandConfidence: WecanaskLLMstoprovideaconfidencescore(%)fortheir
ownanswers. WeobservethatitismorelikelythatLLMswillgivecorrectanswerswhentheirconfidence
level is high. However, we also observe that LLMs can give wrong answers even if the self-evaluated
confidencelevelishigh. Forinstance,fortheaboveproblem(3.5fromControlBench),Claude3Opusis95%
confidentinitssolutiony(t)=2−2e−2t,whichturnsouttobewrong. Thisisquitecommonforallthree
LLMs. Therefore,highconfidenceprovidedbyLLMsdoesnotmeanhighaccuracy.
Failures from Mathematical Derivations: Another observation is that LLMs can give unexpected
mathematicalderivationerrors,whichwebelievethatcouldbefixedusingexternalsymbolictoolssuchas
Mathematica. Weillustratethisonthefollowingsimpleexampleproblem.
14Problem1.3fromControlBench
HumanInput: ConsiderasystemwithatransferfunctionH(s)= 2 + α ,whereαisarealnumber.
s+1 s+2
Istherearangeofrealvaluesforαsuchthatthesystem’sunitstepresponseexhibitsundershoot?
Forthisproblem,itissufficientcombinethetermsofH(s)andderivethatithasaNon-MinimumPhase
(NMP)zero,i.e. RHPzero,when−4<α<−2. WithpromptsrelatedtoNMPzerosandself-checking,both
GPT-4andClaude3Opusgivethecondition−4+α >0. However,neitherisabletoconvertthisconditionto
2+α
obtainthefinalcorrectanswer−4<α<−2. ThisexamplemayrevealthatLLMshavedifficultiesdealing
withmultiplesymbolicinequalities. ThereareactuallymanymoreexamplesshowingthatLLMscanmake
unexpectederrorsinsymbolicmanipulations(seeourprojectwebsiteformoreexamples). Thismaymotivate
thefuturestudyonintegratingLLMswithsymbolictoolboxesforimprovingperformancesonControlBench.
4.4 DiscussionsonSelf-CorrectionCapabilities
Inthissection,wewanttohighlighttheself-correctioncapabilitiesofLLMs[27,21]. ItseemsthatClaude3
Opussignificantlyimprovedtheaccuracyafterwepromptittocheckitspreviouswrongsolutions. GPT-4and
Gemini1.0Ultrahavealsoshownsomeimprovementswiththeself-correctionstep,buttheimprovements
arelesssignificant. Forillustrations,considerthefollowingsimplestabilityproblem.
Problem2.1fromControlBench
HumanInput: Inafeedbackcontrolloop,theopen-looptransferfunctionG(s)andthecontroller
C(s)aregivenby
s−2 s+1
G(s)= , C(s)=K
(s−1)(s+4) s
DetermineK ∈R,ifexists,suchthatthecontrolloopisstable.
Claude3Opus: TodeterminetherangeofvaluesforthegainK thatmakestheclosed-loopsystem
stable,weneedtoanalyzethecharacteristicequationofthesystemusingtheRouth-Hurwitzstability
criterion ...Combining the conditions, we find that for the system to be stable, K must satisfy:
−3<K <2. Therefore,therangeofvaluesforK thatmakestheclosed-loopsystemstableis(−3,2).
HumanInput: Carefullycheckyoursolution.
Claude3Opus: Thankyouforthesuggestiontodouble-checkthesolution. Uponreviewingthe
work,Ifoundanerrorinthesimplificationofthecharacteristicequation. Letmecorrectthemistake
andsolvetheproblemagain...WefindthatthereisnovalueofK thatsatisfiesallthreeconditions
simultaneously. Therefore,theclosed-loopsystemcannotbemadestableforanyrealvalueofK. I
apologizefortheearliermistakeandthankyouforpromptingmetoreviewthesolutioncarefully.
ThecorrectanswerfortheaboveproblemisthatthereisnosuchrealvalueforK tomakethesystem
stable. Atthebeginning,Claude3Opusmadeamistakeinthecalculations. Similarly,GPT-4andGemini1.0
15Ultraalsodonotgivethecorrectanswer. Surprisingly,afteraskingClaude3Opustodoself-checking,it
doesstatethatnosuchvaluesofK exists4. Asamatteroffact,theself-correctionabilityofClaude3Opusis
quitenoticeable,i.e. itimprovestheaccuracyonControlBenchby13.6%afterself-correction. Weprovide
anotherinterestingexampletoillustratethis.
Claude3OpuswithSelf-CorrectiononPIDDesign(Problem5.13fromControlBench)
HumanInput: Considertheplantwiththefollowingtransferfunction: G(s)= 20 .
s2−6s+10
(a) What is the closed-loop ODE from reference r to output y if we use the following PID
controller? u(t)=K e(t)+K ∫ e(t)+K e˙(t),wheree(t)=r(t)−y(t)
p i d
(b) Choose the controller gains so that the closed-loop has poles repeated at s = −3. Hint:
(s+3)3 =s3+9s2+27s+27
(c) WhatistheimpactoftheimplementingthederivativetermK e˙(t)asversustheratefeedback
d
from−K y˙(t)?
d
Claude3Opus: Let’stacklethisproblemstepbystep:
(a) The closed-loop ODE from reference r to output y using the PID controller can be derived as
follows...TakingtheinverseLaplacetransform,wegettheclosed-loopODE:
...
y+(20K −6)y¨+(20K +10)y˙+20K y =20(K r¨+K r˙+K r)
d p i d p i
(b)Tochoosethecontrollergainssothattheclosed-loophaspolesrepeatedats=−3,wecompare
thedenominatoroftheclosed-looptransferfunctionwith(s+3)3:
s3+(20K −6)s2+(20K +10)s+20K =s3+9s2+27s+27
d p i
Equatingcoefficients:
20K −6=9⇒K = 15 =0.7520K +10=27⇒K = 17 =0.8520K =27⇒K = 27 =1.35
d d 20 p p 20 i i 20
(c)TheimpactofimplementingthederivativetermasK e˙(t)versus−K y˙(t):...Insummary,using
d d
−K y˙(t)insteadofK e˙(t)canprovideamorepracticalimplementationofthederivativetermin
d d
thePIDcontroller,butitmayrequireadditionalfilteringtomitigatehigh-frequencynoise.
HumanInput: CarefullycheckyoursolutionforPart(c).
Claude3Opus: Iapologizeformyoversight. LetmetakeanothercarefullookatPart(c)...K e˙(t)
d
introduceszeros,whichcanleadtoafasterresponsebutmaycauseovershootorundershoot. −K y˙(t)
d
affects only the poles, which can improve stability and dampen the response but may result in a
slowerresponse. Thechoicebetweenthetwoimplementationsdependsonthespecificrequirements
andconstraintsofthecontrolsystem,suchasthedesiredresponsecharacteristics,robustnesstonoise,
andthepresenceofhigh-frequencycomponentsinthereferencesignalormeasurements. Iapologize
formypreviousoversightsandthankyouforencouragingmetorevisitthisproblemmorecarefully.
Fortheaboveproblem,bothGPT-4andGemini1.0UltracannotgiveanymeaningfulvaluesforthePID
controlgains(Part(b)). Incontrast,Claude3Opuscansolve(a)and(b)inazero-shotsetting. Afterself-
4Weobservedthatduetotherandomnessintheanswergeneration,Claude3Opussometimescorrectsitsmistakeforthisproblem,
andobtainedtherightfinalanswerusingonlyapartiallycorrectreasoningpath.
16checking,Claude3OpuscanalsogiveamorepreciseanswerforPart(c). Thisexampleagaindemonstrates
theself-correctioncapabilitiesofClaude3Opus. TherearecaseswhereGPT-4andGemini1.0Ultraalso
benefitfromself-correction,althoughtheresultantimprovementsarelesssignificantforthesetwoLLMs.
Obviously,self-correctiondoesnotfixallthemistakesmadebyLLMs. Forinstance,wehaveobserved
thatself-correctiondoesnotworkwellforproblemsinvolvingvisualelementssuchasBodeplotsandNyquist
plots. More study on how to combine the self-correction capabilities of LLMs with advanced reasoning
searchisneededinthefuture.
4.5 SensitivitytotheProblemStatements
ItisknownthatLLMresponsescanbesensitivetothesmallchangesinthehumaninput[43,42,60,22].
NowwediscusssomesimilarphenomenonofLLMsonControlBench. Specifically,weobservedthatfor
some ControlBench problems, very small changes in the problem statements can completely change the
LLMresponses. Wewillpresenttwoexamplestodemonstratethisphenomenon. First,werevisitthesecond
exampleinSection4.2(Problem5.2fromControlBench),andshowthatanalmostnegligiblechangeinthe
problemstatementcancauseGemini1.0Ultratocompletelychangethesolution,asdemonstratedbelow.
ARevisitofProblem5.2fromControlBench
HumanInput(Original): Aplantwithnominalmodel
1
G (s)= (4.3)
o (s+1)2
is in a feedback loop under control with a PI controller having transfer function C(s) = Kps+Ki.
s
Determinewhetherthiscontrollerconfigurationcanbeusedtoachievefullpoleplacement.
Gemini 1.0 Ultra: Here’s a breakdown of how to determine if full pole placement is achievable
...Becausethenumberofadjustableparametersfromthecontrollermatchesthenumberofpolesin
theplant,youcanlikelyachievefullpoleplacementwiththegivenPIcontrollerconfiguration. Note
thatthisassumesthesystemiscontrollable;you’dstillneedtoverifyitscontrollability.
Human Input (Modified): A plant with nominal model G (s) = 1 is in a feedback loop
o (s+1)2
undercontrolwithaPIcontrollerhavingtransferfunctionC(s)= Kps+Ki. Determinewhetherthis
s
controllerconfigurationcanbeusedtoachievefullpoleplacement.
Gemini1.0Ultra: Here’showtodetermineiffullpoleplacementcanbeachievedwiththegiven
controllerconfiguration...ThegivenPIcontrollerconfigurationcannotbeusedtoachievefullpole
placementfortheplantwiththegivennominalmodel...
Intheaboveexample,theonlychangemadeintheproblemstatementisthatweabsorbEquation(4.3)(which
originally takes one row) into the text. This is a very minor formatting change. However, the response
fromGemini1.0Ultraiscompletelychanged. Forthemodifiedproblem,Gemini1.0Ultragivesthecorrect
conclusion. For this specific problem, GPT-4 and Claude 3 Opus are more robust against the changes in
theproblemstatement. Next,werevisitPart(a)ofProblem5.11fromControlBench(thethirdexamplein
17Section4.2),anddemonstratethatourleadingLLMClaude3Opussometimesfacesasimilarissue.
RevisitingPart(a)ofProblem5.11fromControlBench
HumanInput(Original): Considertheplantwiththefollowingtransferfunction:
505
G(s)=
s3+21s2+121s+101
Thepolesofthissystemareats=−1,−10±j,andtheDCgainis5.
(a) WhatisthedominantpoleapproximationG (s)forthisplant?
a
Claude3Opus: (a)ThedominantpoleapproximationG (s)isfoundbyconsideringthepoleclosest
a
totheorigin(thedominantpole)andneglectingtheotherpoles. Inthiscase,thedominantpoleisat
s=−1. Thetransferfunctionofthedominantpoleapproximationis: G (s)= K ,whereK isthe
a s+1
DCgainoftheoriginalsystem. GiventhattheDCgainis5,wehave: G (s)= 5 .
a s+1
HumanInput(Modification1): Considertheplantwiththefollowingtransferfunction:
505
G(s)=
s3+21s2+121s+101
Thepolesofthissystemareats=−1,−10±j.
(a) WhatisthedominantpoleapproximationG (s)forthisplant?
a
Claude3Opus: (a)Tofindthedominantpoleapproximation,weneedtoidentifythepoleclosest
to the origin (i.e., the dominant pole) and factor it out from the transfer function ...Now, we can
approximatethetransferfunctionbyconsideringonlythedominantpoleG (s)= K ...Wecanuse
a s+1
theresidueformula: lim 505 = 505 = 505 ≈6.159. Therefore,thedominant
s→−1 s2+20s+101 (−1)2+20(−1)+101 82
poleapproximationisG (s)= 6.159.
a s+1
HumanInput(Modification2): Considertheplantwiththefollowingtransferfunction:
505
G(s)=
s3+21s2+121s+101
(a) UsetheDCgaintocomputethedominantpoleapproximationG (s)forthisplant.
a
Claude 3 Opus: (a) To find the dominant pole approximation, we first need to find the DC gain
and the dominant pole of the system ...Now, we can write the dominant pole approximation as:
G (s)= K = 5 ,whereK istheDCgainandpisthedominantpole.
a s−p s+1
Wetriedtwomodificationsforthisproblem. First,weremovetheinformationoftheDCgainbeing5from
theproblemstatement. Thenallofasudden,Claude3OpusfailsinrecognizingthattheDCgainisneeded
18forthedominantpoleapproximationandmakesaweirdmistakeingivingthewronganswerG (s)= 6.159.
a s+1
ThenonemaywonderwhetherwehavetogivetheexactDCgaininformationtoClaude3Opustoensure
thatacorrectsolutioncanbefound. Inoursecondmodifiedproblemstatement,weremoveboththepoleand
DCgaininformation,andspecificallypromptClaude3OpustousetheDCgainforitscalculationofthe
dominantpoleapproximation. Interestingly,Claude3OpusisabletocalculatetheDCgainandthedominant
polebyitself,reachingtotherightfinalanswerunderthisspecialprompton“usingtheDCgain."However,
weemphasizethataddingtheprompt“DCgain"doesnotguaranteeClaude3Opustosolvedominantpole
approximation problems.5 Overall, the above discussion highlights the need of future research efforts in
addressingtheconsistencyandrobustnessofLLMresponsesforansweringcontrol-relatedquestions.
5 ControlBench-C: Facilitating Evaluations by Non-Control Experts
TheevaluationsofLLMsonControlBenchareconductedbyapanelofhumanexperts. Sofarwedonot
have a fast automated way to evaluate LLM responses on ControlBench. To partially address this issue,
weconvert100problemsfromControlBenchintosingle-answermultiple-choicequestions,leadingtothe
ControlBench-Cdataset. ThereasonControlBench-ChasfewerproblemsthanControlBenchisthatsome
oftheproblemsfromControlBenchinvolvecomplicatedreasoningandrigorousmathematicalproofs,and
it is quite difficult to convert those problems into a multiple-choice format. ControlBench-C is designed
tosupportevaluationsbyresearchersfromdiversebackgrounds,includingthosenotspecializedincontrol
theory,andhasbeenpostedonourprojectwebsite. Currently,theproblemsinControlBench-Careprovided
byLaTexdescriptions,thatcanbeeasilyconvertedintotheJsonformatforautomatedevaluationsusing
APIcalls. Forillustrativepurposes,considerthefollowingexamplefromControlBench-C.
ModifyingProblem3.5fromControlBenchasaMulti-ChoiceProblem
HumanInput: Whatistheunitstepresponseofacontinuoussystemwhosetransferfunctionhasa
zeroat−1,apoleat−2,andagainfactorof2? Selectthecorrectoptionfromthefollowingchoices:
(a) y(t)=1+e−t, t≥0
(b) y(t)=2+e−2t, t≥0
(c) y(t)=1+e2t, t≥0
(d) y(t)=1+e−2t, t≥0
Pleaseoutputyourchoicebyjustchoosing*ONLYONE*optionfrom(a),(b),(c),or(d),andprovide
ashortexplanationbelowinJSONformatbyfillingintheplaceholdersin[]. Youranswershouldnot
includeanyfurtherexplanation,andremembertouseparentheses;forexample,"(a)"iscorrect,not
"a":
"Choice": "[ONLYONEchoicefrom(a),(b),(c),(d)]",
"Reason": "[Yourexplanation]"
Theaboveproblemismuchsimplerthantheoriginalproblemwhichasksonetocomputey(t). Fortheabove
5Forinstance,Claude3OpuscanfailonProblem1.21(anotherproblemondominatepoleapproximation)fromControlBench,
withorwithouttheprompt“DCgain."
19Table3: Accuracy(ACC)andSelf-CheckedAccuracy(ACC-s)ofGPT-4,Claude3Opus,andGemini1.0
UltraonControlBench-C.BothACCandACC-sareverifiedbyexaminingthechoice,withoutconsidering
whetherthereasoningiscorrectornot. Thebestresultsforeachmetricarehighlightedinbold.
GPT-4 Claude3Opus Gemini1.0Ultra
Topics ACC↑ ACC-s↑ ACC ACC-s ACC ACC-s
Background 73.3%(11/15) 100%(15/15) 66.7%(10/15) 80.0%(12/15) 73.3%(11/15) 80.0%(12/15)
Stability 83.3%(10/12) 91.7%(11/12) 50.0%(6/12) 91.7%(11/12) 83.3%(10/12) 91.7%(11/12)
Timeresponse 76.4%(13/17) 76.4%(13/17) 82.3%(14/17) 94.1%(16/17) 64.7%(11/17) 94.1%(16/17)
Blockdiagrams 50.0%(1/2) 50.0%(1/2) 50.0%(1/2) 50.0%(1/2) 0.0%(0/2) 50.0%(1/2)
ControlSystemDesign 43.7%(7/16) 50.0%(8/16) 37.5%(6/16) 56.2%(9/16) 43.7%(7/16) 56.2%(9/16)
BodeAnalysis 36.3%(4/11) 90.9%(10/11) 54.5%(6/11) 90.9%(10/11) 36.3%(4/11) 63.6%(7/11)
Root-LocusDesign 40.0%(2/5) 40.0%(2/5) 80.0%(4/5) 100%(5/5) 60.0%(3/5) 60.0%(3/5)
NyquistDesign 25.0%(1/4) 50.0%(2/4) 50.0%(2/4) 75.0%(3/4) 0.0%(0/4) 50.0%(2/4)
Gain/PhaseMargins 71.4%(5/7) 85.7%(6/7) 57.1%(4/7) 85.7%(6/7) 57.1%(4/7) 85.7%(6/7)
SystemSensitivityMeasures 100.0%(3/3) 100.0%(3/3) 100.0%(3/3) 100.0%(3/3) 66.7%(2/3) 100.0%(3/3)
Loop-shaping 0.0%(0/1) 0.0%(0/1) 0.0%(0/1) 100%(1/1) 100%(1/1) 100%(1/1)
AdvancedTopics 100%(7/7) 100%(7/7) 42.9%(3/7) 85.7%(6/7) 42.9%(3/7) 57.1%(4/7)
Total 64.0%(64/100) 78.0%(78/100) 59.0%(59/100) 83.0%(83/100) 56.0%(56/100) 75.0%(75/100)
problem,allthreeLLMschoosethecorrectanswer(d). Gemini1.0Ultraprovidesthereasonthatthesystem
isstable(poleintheleft-halfplane),andthefinalvaluematchestheDCgainofthetransferfunction,while
Claude3OpususesthereasonthattheinverseLaplacetransformofthepartialfractionexpansiongivesthe
unitstepresponseasy(t)=1+e−2t fort≥0. Interestingly,asdiscussedinSection4.3,Claude3Opususes
asimilarreasoningpathfortheoriginalproblem(Problem3.5fromControlBench)butmakesamistakein
thecalculations. Wecanseethatsomehowsuchamistakeisavoidedwhentheproblemisformulatedasa
single-answermulti-choiceproblem.
Forcompleteness,wealsoevaluatetheACCandACC-sofGPT-4,Claude3Opus,andGemini1.0Ultra
onControlBench-C.Forfastautomatedevaluations,bothACCandACC-sarecalculatedviaexaminingthe
choicesfromtheLLMs,withoutconsideringwhetherthereasoningiscorrectornot. Suchevaluationscanbe
easilydonebynon-controlexperts. However,thedownsideisthatsometimesLLMscanpicktherightchoice
basedonwrongreasoning,causingconcernsaboutwhethersuchtestingreflectsthetruecapabilitiesofLLMs
in solving control problems. For ControlBench-C, GPT-4 and Claude 3 Opus have similar performances.
GPT-4achievesthehighestACC,whileClaude3OpusachievesthehighestACC-s. WeviewControlBench-C
as a complement to ControlBench. Specifically, ControlBench-C enables automated evaluations even by
non-controlexperts. However,theresultsfromControlBench-Cdonotprovidethesamelevelofinsightas
ourpreviousanalysisonControlBench. Animportantfuturetaskistodevelopautomatedevaluationmethods
forControlBench.
6 Conclusion and Future Work
Inthispaper,westudythecapabilitiesoflargelanguagemodels(LLMs)includingGPT-4,Claude3Opus,
and Gemini 1.0 Ultra in solving undergraduate control engineering problems. To support the study, we
introduce a benchmark dataset, ControlBench. We offer comprehensive insights from control experts to
uncoverthecurrentpotentialandlimitationsofLLMs. Webelievethatourworkisjustastartingpointfor
furtherstudiesofLLM-basedmethodsforcontrolengineering. Weconcludeourpaperwithabriefdiscussion
onfutureresearchdirections.
20Expansionoftheproblemset. IncreasingthediversityoftheproblemsetintheControlBenchdataset
couldprovideamorecomprehensiveevaluationofLLMs. Byintroducingmorecomplexandchallenging
control design tasks, the dataset can push the capabilities of LLMs further. It will also be interesting to
include more problems on advanced topics such as nonlinear control [31], stochastic control [5], robust
control[58],adaptivecontrol[4],andquantumcontrol[17].
Control-oriented prompting. It is well known that LLMs can often be steered to generate prescribed
responsesaslongasonefindstherightprompts[9,3,20]. Inmanysituations,shortprompts,referredtoas
“magicwords"[9],aresufficientforthepurposeofsteeringLLMs. Itwillbeinterestingtoinvestigatewhether
one can combine domain knowledge and automatic prompt search methods to develop control-oriented
promptsandinstructionsforimprovingthecapabilitiesofLLMsincontrolengineering.
Improvingreasoningcapabilitiesandtooluseabilitiesforconsistencyandaccuracy. Inthefuture,we
alsoplantoadoptadvancedplanningstrategiessuchastrees-of-thoughtprompting[53]orMonteCarloTree
Search(MCTS)[23]andintegrateexternalresourceslikeprogrammingcodeorMatlabcontroltoolboxes
[26,24]. Thosestrategiesaimatenhancingthemodelaccuracyandconsistencyinreasoningandcalculations
for the control design task. One main issue observed in our paper is that LLMs can sometimes generate
inconsistent answers even for the same problem. Improving the reasoning and calculation capabilities of
LLMscanpotentiallyleadtosolutionsforthisissue.
Efficientevaluation. EfficientevaluationmethodsarecrucialforscalingtheapplicationofLLMsincontrol
engineering. Automatingtheevaluationprocess,whileensuringitcomplementsexperthumanassessments,
couldstreamlinethevalidationofLLMoutputsandfacilitatemorerapidadvancementsinthefield. Thereis
aneedtodevelopnewmethodsandmetricsforfastautomatedevaluationofLLMsoncontrolbenchmarks.
Vision-languagemodelsforhandlingvariousplots. Asobservedinourpaper,GPT-4,Claude3Opus,
andGemini1.0UltraallhavedifficultiesinsolvingproblemsinvolvingBodeplots,Nyquistplots,androot
locusplots. Therefore,itisimportanttodevelopnewmethodsforincorporatingcontrol-domainknowledge
intostate-of-the-artvision-languagemodels[15,33,34,59].
Acknowledgement
U.Syed,X.Guo,A.Havens,andB.HuaregenerouslysupportedbytheNSFawardCAREER-2048168.
Potential Social Impact
TheaspectofAIsafetyinthecontextofintegratinglargelanguagemodels(LLMs)intocontrolengineering
is paramount, especially given the potential for these models to be applied in critical infrastructure and
systems. AswelooktowardsafuturewhereLLMsmayplayasignificantroleindesigning,optimizing,and
maintainingcontrolsystems,wemustprioritizethedevelopmentofsafetyprotocolsandstandardstogovern
theirdeployment. TheintegrationofLLMsincontrolengineeringalsoraisesimportantethicalconsiderations.
Asthesemodelsbegintoinfluencedecision-makingincontrolsystems,questionsregardingaccountability,
transparency,andthepotentialforunintendedconsequencesmustbeaddressed. Developingframeworksthat
clearlydelineatetheresponsibilitiesofhumanoperatorsandLLMswillbecrucial. Additionally,ensuring
21thatLLMsaredesignedwithfairnessandbiasmitigationinmindwillhelppreventthepropagationofexisting
prejudices into control engineering solutions. To address these challenges and opportunities, fostering a
collaborativeenvironmentbetweencontrolengineers,AIresearchers,ethicists,andpolicymakersisessential.
Such collaborations can lead to the development of interdisciplinary solutions that not only enhance the
technicalcapabilitiesofLLMsincontrolengineeringbutalsoensurethattheirdeploymentissafe,ethical,
andsociallybeneficial. Bycombiningdomain-specificknowledgewithadvancementsinAI,wecancreate
robustframeworksfortheresponsibleuseofLLMsincontrolengineering. Inaddition,thedevelopmentof
comprehensiveregulatoryframeworksandstandardsspecifictotheuseofLLMsincontrolengineeringwill
becrucial. TheseframeworksshouldaddressaspectssuchasthevalidationofLLMoutputs,theethicaluse
ofAIinengineeringapplications,andthesafetyofAI-drivencontrolsystems. Establishingclearguidelines
and standards will not only promote the safe and responsible use of LLMs but also foster public trust in
AI-enhancedcontrolengineeringsolutions.
Theintegrationoflargelanguagemodels(LLMs)intocontrolengineering,andtheirbroaderapplication
across various disciplines, also prompts a critical examination of their potential negative social impacts,
particularlyintherealmofeducation. TheaccessibilityandefficiencyofLLMsinsolvingcomplexproblems
mightinadvertentlyleadtoarelianceonthesetoolsamongstudents,potentiallyunderminingthedevelopment
of foundational problem-solving skills and critical thinking. This scenario could lead to a superficial
understanding of complex subjects, diminishing the educational process’s depth and rigor. To mitigate
thesepotentialnegativeimpactsoneducation,itiscrucialtoadoptabalancedapproachthatleveragesthe
benefitsofLLMswhilefosteringdeeplearningandskilldevelopment. Oneeffectivestrategycouldinvolve
integratingLLMsintothecurriculumassupplementarytoolsratherthanprimaryproblemsolvers. Educators
can design assignments and projects that require students to critically evaluate LLM-generated solutions,
encouragingdeeperengagementwiththematerialandpromotingcriticalthinking. Moreover,developing
educationalframeworksthatemphasizetheunderstandingofunderlyingprinciplesratherthansolelyfocusing
onobtainingsolutionscanhelpmaintaintheeducationalquality. Incorporatingproject-basedlearning,where
students must apply concepts to real-world scenarios, can ensure that they develop practical skills and a
comprehensiveunderstandingofthesubjectmatter. Finally,ethicaltrainingregardingtheuseofLLMsand
otherAItoolsinacademicsettingsmaybeintegratedintocurriculatoinstillasenseofresponsibilityand
integrityamongstudents.
References
[1] JoshAchiam,StevenAdler,SandhiniAgarwal,LamaAhmad,IlgeAkkaya,FlorenciaLeoniAleman,
Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report.
arXivpreprintarXiv:2303.08774,2023.
[2] Anthropic. Claude3haiku: ourfastestmodelyet. 2024. Availableat: https://www.anthropic.
com/news/claude-3-haiku.
[3] SimranArora,AvanikaNarayan,MayeeFChen,LaurelOrr,NeelGuha,KushBhatia,InesChami,and
ChristopherRe. Askmeanything: Asimplestrategyforpromptinglanguagemodels. InTheEleventh
InternationalConferenceonLearningRepresentations,2022.
[4] K.ÅströmandB.Wittenmark. Adaptivecontrol. CourierCorporation,2013.
[5] KarlJÅström. Introductiontostochasticcontroltheory. CourierCorporation,2012.
22[6] KarlJohanÅströmandRichardMurray. Feedbacksystems: anintroductionforscientistsandengineers.
Princetonuniversitypress,2021.
[7] ZhangirAzerbayev,HaileySchoelkopf,KeiranPaster,MarcoDosSantos,StephenMcAleer,AlbertQ
Jiang,JiaDeng,StellaBiderman,andSeanWelleck.Llemma: Anopenlanguagemodelformathematics.
arXivpreprintarXiv:2310.10631,2023.
[8] Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda,
TomaszLehmann,MichalPodstawski,HubertNiewiadomski,PiotrNyczyk,etal. Graphofthoughts:
Solvingelaborateproblemswithlargelanguagemodels. arXiv:2308.09687,2023.
[9] AmanBhargava,CameronWitkowski,ManavShah,andMattThomson. What’sthemagicword? a
controltheoryofllmprompting. arXivpreprintarXiv:2310.04444,2023.
[10] Abeba Birhane, Atoosa Kasirzadeh, David Leslie, and Sandra Wachter. Science in the age of large
languagemodels. NatureReviewsPhysics,5(5):277–280,2023.
[11] QiyuanChenandChengDeng. Bioinfo-bench: Asimplebenchmarkframeworkforllmbioinformatics
skillsevaluation. bioRxiv,pages2023–10,2023.
[12] Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting:
Disentanglingcomputationfromreasoningfornumericalreasoningtasks. arXiv:2211.12588,2022.
[13] RobertChew,JohnBollenbacher,MichaelWenger,JessicaSpeer,andAnniceKim.Llm-assistedcontent
analysis: Usinglargelanguagemodelstosupportdeductivecoding. arXivpreprintarXiv:2306.14924,
2023.
[14] Gautier Dagan, Frank Keller, and Alex Lascarides. Dynamic planning with a llm. arXiv preprint
arXiv:2308.06391,2023.
[15] WenliangDai,JunnanLi,DongxuLi,AnthonyMengHuatTiong,JunqiZhao,WeishengWang,Boyang
Li,PascaleNFung,andStevenHoi. Instructblip: Towardsgeneral-purposevision-languagemodels
withinstructiontuning. AdvancesinNeuralInformationProcessingSystems,36,2024.
[16] JosephJDiStefano,AllenJStubberud,andIvanJWilliams. Schaum’soutlineoffeedbackandcontrol
systems. McGraw-HillProfessional,1997.
[17] Domenico d’Alessandro. Introduction to quantum control and dynamics. Chapman and hall/CRC,
2021.
[18] Gene F Franklin, J David Powell, and Abbas Emami-Naeini. Feedback control of dynamic systems,
volume3. Addison-WesleyReading,MA,1994.
[19] SimonFrieder,LucaPinchetti,Ryan-RhysGriffiths,TommasoSalvatori,ThomasLukasiewicz,Philipp
Petersen,andJuliusBerner. MathematicalcapabilitiesofChatGPT. AdvancesinNeuralInformation
ProcessingSystems,36,2024.
[20] JonasGeiping,AlexStein,ManliShu,KhalidSaifullah,YuxinWen,andTomGoldstein. Coercingllms
todoandreveal(almost)anything. arXivpreprintarXiv:2402.14020,2024.
23[21] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen.
Critic: Largelanguagemodelscanself-correctwithtool-interactivecritiquing. arXiv:2305.11738,2023.
[22] XingangGuo,FangxuYu,HuanZhang,LianhuiQin,andBinHu. Cold-attack: Jailbreakingllmswith
stealthinessandcontrollability. arXivpreprintarXiv:2402.08679,2024.
[23] Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhiting Hu.
Reasoningwithlanguagemodelisplanningwithworldmodel. arXiv:2305.14992,2023.
[24] Shibo Hao, Tianyang Liu, Zhen Wang, and Zhiting Hu. Toolkengpt: Augmenting frozen language
modelswithmassivetoolsviatoolembeddings. Advancesinneuralinformationprocessingsystems,
36,2024.
[25] AlexHavrilla,SharathRaparthy,ChristoforusNalmpantis,JaneDwivedi-Yu,MaksymZhuravinskyi,
EricHambro,andRobertaRailneau. Glore: When,where,andhowtoimprovellmreasoningviaglobal
andlocalrefinements. arXivpreprintarXiv:2402.10963,2024.
[26] JoyHe-Yueya,GabrielPoesia,RoseEWang,andNoahDGoodman. Solvingmathwordproblemsby
combininglanguagemodelswithsymbolicsolvers. arXivpreprintarXiv:2304.09102,2023.
[27] JiaxinHuang,ShixiangShaneGu,LeHou,YuexinWu,XuezhiWang,HongkunYu,andJiaweiHan.
Largelanguagemodelscanself-improve. arXiv:2210.11610,2022.
[28] Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey.
arXivpreprintarXiv:2212.10403,2022.
[29] Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, and Li Fei-Fei. Voxposer:
Composable3dvaluemapsforroboticmanipulationwithlanguagemodels. InConferenceonRobot
Learning,pages540–562,2023.
[30] ShimaImani,LiangDu,andHarshShrivastava. Mathprompter: Mathematicalreasoningusinglarge
languagemodels. arXivpreprintarXiv:2303.05398,2023.
[31] H.K.Khalil. NonlinearSystems. PrenticeHall,thirdedition,2001.
[32] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large
language models are zero-shot reasoners. Advances in neural information processing systems, 35:
22199–22213,2022.
[33] JunnanLi,DongxuLi,SilvioSavarese,andStevenHoi. Blip-2: Bootstrappinglanguage-imagepre-
trainingwithfrozenimageencodersandlargelanguagemodels. InInternationalconferenceonmachine
learning,pages19730–19742.PMLR,2023.
[34] HaotianLiu,ChunyuanLi,QingyangWu,andYongJaeLee. Visualinstructiontuning. Advancesin
neuralinformationprocessingsystems,36,2024.
[35] StephenMacNeil,AndrewTran,DanMogil,SethBernstein,ErinRoss,andZihengHuang. Generating
diverse code explanations using the gpt-3 large language model. In Proceedings of the 2022 ACM
ConferenceonInternationalComputingEducationResearch-Volume2,pages37–39,2022.
24[36] ChristopherEMower,HongzhanYu,AntoineGrosnit,JanPeters,JunWang,andHaithamBou-Ammar.
Optimalcontrolsynthesisfromnaturallanguage: Opportunitiesandchallenges. 2024.
[37] Daye Nam, Andrew Macvean, Vincent Hellendoorn, Bogdan Vasilescu, and Brad Myers. Using an
llmtohelpwithcodeunderstanding. In2024IEEE/ACM46thInternationalConferenceonSoftware
Engineering(ICSE),pages881–881.IEEEComputerSociety,2024.
[38] ErikNijkamp, BoPang, HiroakiHayashi, LifuTu, Huan Wang, YingboZhou, SilvioSavarese, and
CaimingXiong. Codegen: Anopenlargelanguagemodelforcodewithmulti-turnprogramsynthesis.
arXivpreprintarXiv:2203.13474,2022.
[39] NormanSNise. Controlsystemsengineering. JohnWiley&Sons,2020.
[40] KatsuhikoOgataandYanjuanYang. Moderncontrolengineering,volume5. Pearson,2009.
[41] Siru Ouyang, Zhuosheng Zhang, Bing Yan, Xuan Liu, Jiawei Han, and Lianhui Qin. Structured
chemistryreasoningwithlargelanguagemodels. arXivpreprintarXiv:2311.09656,2023.
[42] Abel Salinas and Fred Morstatter. The butterfly effect of altering prompts: How small changes and
jailbreaksaffectlargelanguagemodelperformance. arXivpreprintarXiv:2401.03729,2024.
[43] MelanieSclar,YejinChoi,YuliaTsvetkov,andAlaneSuhr. Quantifyinglanguagemodels’sensitivityto
spuriousfeaturesinpromptdesignor: Howilearnedtostartworryingaboutpromptformatting. arXiv
preprintarXiv:2310.11324,2023.
[44] ChanHeeSong,JiamanWu,ClaytonWashington,BrianMSadler,Wei-LunChao,andYuSu. Llm-
planner: Few-shotgroundedplanningforembodiedagentswithlargelanguagemodels. InProceedings
oftheIEEE/CVFInternationalConferenceonComputerVision,pages2998–3009,2023.
[45] Jiankai Sun, Chuanyang Zheng, Enze Xie, Zhengying Liu, Ruihang Chu, Jianing Qiu, Jiaqi Xu,
Mingyu Ding, Hongyang Li, Mengzhe Geng, et al. A survey of reasoning with foundation models.
arXiv:2312.11562,2023.
[46] GeminiTeam,RohanAnil,SebastianBorgeaud,YonghuiWu,Jean-BaptisteAlayrac,JiahuiYu,Radu
Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highly capable
multimodalmodels. arXivpreprintarXiv:2312.11805,2023.
[47] KarthikValmeekam,AlbertoOlmo,SarathSreedharan,andSubbaraoKambhampati. Largelanguage
modelsstillcan’tplan(abenchmarkforllmsonplanningandreasoningaboutchange). arXivpreprint
arXiv:2206.10498,2022.
[48] Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati. On the
planningabilitiesoflargelanguagemodels-acriticalinvestigation. AdvancesinNeuralInformation
ProcessingSystems,36,2024.
[49] XiaoxuanWang,ZiniuHu,PanLu,YanqiaoZhu,JieyuZhang,SatyenSubramaniam,ArjunRLoomba,
ShichangZhang,YizhouSun,andWeiWang. Scibench: Evaluatingcollege-levelscientificproblem-
solvingabilitiesoflargelanguagemodels. arXiv:2307.10635,2023.
25[50] XuezhiWang,JasonWei,DaleSchuurmans,QuocLe,EdChi,SharanNarang,AakankshaChowdhery,
andDennyZhou. Self-consistencyimproveschainofthoughtreasoninginlanguagemodels. arXiv
preprintarXiv:2203.11171,2022.
[51] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny
Zhou,etal. Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels. Advancesinneural
informationprocessingsystems,35:24824–24837,2022.
[52] FrankFXu,UriAlon,GrahamNeubig,andVincentJosuaHellendoorn. Asystematicevaluationof
largelanguagemodelsofcode. InProceedingsofthe6thACMSIGPLANInternationalSymposiumon
MachineProgramming,pages1–10,2022.
[53] ShunyuYao,DianYu,JeffreyZhao,IzhakShafran,TomGriffiths,YuanCao,andKarthikNarasimhan.
Tree of thoughts: Deliberate problem solving with large language models. Advances in Neural
InformationProcessingSystems,36,2024.
[54] WillYeadonandTomHardy. Theimpactofaiinphysicseducation: acomprehensivereviewfromgcse
touniversitylevels. PhysicsEducation,59(2):025010,2024.
[55] RenruiZhang,DongzhiJiang,YichiZhang,HaokunLin,ZiyuGuo,PengshuoQiu,AojunZhou,Pan
Lu,Kai-WeiChang,PengGao,etal. Mathverse: Doesyourmulti-modalllmtrulyseethediagramsin
visualmathproblems? arXivpreprintarXiv:2403.14624,2024.
[56] Zirui Zhao, Wee Sun Lee, and David Hsu. Large language models as commonsense knowledge for
large-scaletaskplanning. AdvancesinNeuralInformationProcessingSystems,36,2024.
[57] DennyZhou,NathanaelSchärli,LeHou,JasonWei,NathanScales,XuezhiWang,DaleSchuurmans,
ClaireCui,OlivierBousquet,QuocLe,etal. Least-to-mostpromptingenablescomplexreasoningin
largelanguagemodels. arXivpreprintarXiv:2205.10625,2022.
[58] Kemin Zhou, John Comstock Doyle, and Keith Glover. Robust and Optimal Control, volume 40.
PrenticeHallNewJersey,1996.
[59] Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: Enhancing
vision-languageunderstandingwithadvancedlargelanguagemodels. arXivpreprintarXiv:2304.10592,
2023.
[60] Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. Universal and transferable adversarial
attacksonalignedlanguagemodels. arXivpreprintarXiv:2307.15043,2023.
26