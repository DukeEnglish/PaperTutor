Understanding Iterative Combinatorial Auction Designs via
Multi-Agent Reinforcement Learning
GREGD‚ÄôEON,UniversityofBritishColumbia,Canada
NEILNEWMAN,UniversityofBritishColumbia,Canada
KEVINLEYTON-BROWN,UniversityofBritishColumbia,Canada
Iterativecombinatorialauctionsarewidelyusedinhighstakessettingssuchasspectrumauctions.Such
auctionscanbehardtounderstandanalytically,makingitdifficultforbidderstodeterminehowtobehave
andfordesignerstooptimizeauctionrulestoensuredesirableoutcomessuchashighrevenueorwelfare.
Inthispaper,weinvestigatewhethermulti-agentreinforcementlearning(MARL)algorithmscanbeused
tounderstanditerativecombinatorialauctions,giventhatthesealgorithmshaverecentlyshownempirical
successinseveralotherdomains.WefindthatMARLcanindeedbenefitauctionanalysis,butthatdeploying
iteffectivelyisnontrivial.Webeginbydescribingmodellingdecisionsthatkeeptheresultinggametractable
withoutsacrificingimportantfeaturessuchasimperfectinformationorasymmetrybetweenbidders.We
alsodiscusshowtonavigatepitfallsofvariousMARLalgorithms,howtoovercomechallengesinverifying
convergence,andhowtogenerateandinterpretmultipleequilibria.Weillustratethepromiseofourresulting
approachbyusingittoevaluateaspecificrulechangetoaclockauction,findingsubstantiallydifferentauction
outcomesduetocomplexchangesinbidders‚Äôbehavior.
Contents
Abstract 0
Contents 0
1 Introduction 1
2 Methodology:UnderstandingIterativeCombinatorialAuctionsviaMARL 3
3 CaseStudy:BidProcessinginClockAuctions 8
4 ExperimentalResults 12
5 ConclusionsandDiscussion 17
References 19
A ComputationalEnvironment 21
B ClockAuctions 22
C ValueSamplingDetails 22
D PPOHyperparameters 23
E AdditionalResults 25
Manuscriptsubmittedforreviewtothe25thACMConferenceonEconomics&Computation(EC'24).
4202
beF
92
]TG.sc[
1v02491.2042:viXraGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 1
1 INTRODUCTION
Iterativecombinatorialauctionsareahigh-stakes,sociallyimportantclassofmechanisms.These
auctionshavebecomethedominantmechanismforradiospectrumprivatization[Teytelboymetal.,
2021],adomainwewilluseasarunningexamplethroughoutthispaper.Spectrumauctionsrevenues
frequentlyreachbillionsofdollarsandoutcomeshavenationalimpact.Iterativecombinatorial
auctionsarealsodeployedinawiderangeofothersettings[see,e.g.,Palacios-Huertaetal.,2021].
Itisimportantforbidderstomakegoodstrategicchoicesinanauctionwhoseoutcomecan
materiallyaffecttheircompany‚Äôsvalue.Itisalsoimportantfordesignerstoestablishauctionrules
thatachievegoodoutcomesintermsofrevenue,welfare,andothermetrics.However,neither
task is easy, because iterative combinatorial auctions are profoundly complex. Combinatorial
designsexplodebidders‚Äôactionspaces,butareessentialwhenbiddershavestrongneedstoexpress
complementaritiesand/orsubstitutabilitiesacrossindividualgoods.Iterativedesignsyieldasecond
exponentialincreaseinstrategiccomplexity,butarecriticalwhenbiddersneedtoperform‚Äúprice
discovery‚Äùbyupdatingtheirstatedpreferencesinresponsetoinformationaboutothers‚Äôdemand.
Considerthecaseofspectrumauctions.Theiterativecombinatorialauctionsusedtosellradio
spectrumcanhave50+pagemanualsexplaininghowtheyevolveovertimeandwhichbidsarelegal
tosubmit[FCC,2015].Theyareheldtooinfrequentlytolearnaboutfromhistoricaldata,occurring
onlyonceeverfewyearsnationally.What‚Äôsmore,whilethereareafewpopularauctionformats,
suchasSimultaneousMultipleRoundAuctions(SMRA)[Milgrom,2000],CombinatorialClock
Auctions(CCA)[Ausubeletal.,2006],andClockAuctions1[Ausubel,2004],evenwithinasingle
format,rulestendtodifferfromoneauctiontothenext.Forexample,betweenthe(consecutive)
Canadian700MHz[ISED,2012]and600MHz[ISED,2018]auctions,theactivityrulewasaltered;
later,betweentheCanadian3500MHz[ISED,2021]and3800MHz[ISED,2022]auctions,aspectrum
capwasaddedlimitingthemaximumabiddercouldwinineachregion.Giventhatrulesarein
constantflux,andthatitisdifficulttopredicthowisolatedrulechangeswillimpactanauction‚Äôs
equilibrium,itisimportanttodevelopmethodsforreasoningabouttheeffectsofcounterfactual
policychangesintheseauctions.
Ideally,wewouldanalyzesuchproblemsbycomputingtheBayes‚ÄìNashequilibriaofthegame
inducedbyeachsetofauctionrules,evaluatinghowoutcomeschangeinequilibrium.Thisisthe
dominantapproachtakenbytheoreticalworkineconomics,andhasalsobeenadoptedbyvarious
computationalapproaches[e.g.Rabinovichetal.,2013,Thompsonetal.,2017,ThompsonandLeyton-
Brown,2017].However,thereislittlehopeofidentifyingBayes‚ÄìNashequilibriaofrealisticiterative
combinatorialauctions,astheyaretoocomplextoadmitpen-and-paperanalysisusingknown
techniques.Thus,themostinfluentialexistingworkstudieshighlysimplifiedsettings.Forinstance,
foroneauctionformat,RiedelandWolfstetter[2006]provedthatitisanequilibriumforbiddersto
endtheauctioninthefirstround,buttheirproofappliesonlytoauctionswithasingleproduct,
infinitesimalpriceincreases,andcompleteinformationaboutbidders‚Äôvalues.Combinatorialaction
spacesandmulti-roundstructuresimplyenormousextensive-formrepresentations,puttingthem
outofreachoftraditionalequilibriumsolversaswell.
Analternativeistosimulatetheauctionundertheassumptionthatbiddersplaysomegiven,
fixedstrategy[e.g.,Caryetal.,2007,Newmanetal.,2024].Onecanthenobserveboththeeffectof
arulechangeanditssensitivitytochangesinbidders‚Äôvaluationsandtorandomnessintheauction
mechanism.However,combinatorialauctionsarenottypicallystrategyproof[seee.g.,Bosshardand
Seuken,2021,LevinandSkrzypacz,2016].Thereisthustypicallynotasingularreasonablestrategy
tosimulate,letaloneonewithconsistentincentivepropertiesacrosstherulesbeingstudied.
1ClockAuctionsarecombinatorialauctions,butareadistinctauctionformatfromCombinatorialClockAuctions.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 2
Multi-agentreinforcementlearning(MARL)offersamiddleground:agentswhoexhibitmuch
richerstrategicreasoningthaninstaticsimulationsbutmuchmorecomputationaltractabilitythan
classicalBayes‚ÄìNashequilibriumcomputation.Overthepastdecade,MARLalgorithmshavemade
greatstrides.Earlyeffortsfocusedonachievingsuperhumanperformanceintwo-playerzero-sum
games,suchasGo[Silveretal.,2016],Shogi[Silveretal.,2017],andStratego[P√©rolatetal.,2022].
Thesegamessharethespecialpropertythatplayersdonotneedtosolvetheequilibriumselection
problem[HarsanyiandSelten,1988]:ifaplayerplaystheirpartofanequilibriumstrategy,itwill
doatleastaswellagainstanyotherstrategyanopponentmightplay.Ofcourse,thispropertydoes
notholdinauctions,nordoesitholdinzero-sumgameshavingmorethantwoplayers.Itisthus
strikingthatrecentworkhasshownsuperhumanperformanceinmultiplayerzero-sumgamessuch
aspoker[BrownandSandholm,2019b].Ofparticularrelevancetowhatfollows,Counterfactual
RegretMinimization(CFR)[Zinkevichetal.,2007]isapopular,modernMARLalgorithmthatwas
recentlyusedtosolveTexasHold‚Äôempoker[Bowlingetal.,2015,BrownandSandholm,2018].
Anotherimpressiverecentachievementwasthedemonstrationofhuman-levelplayintheboard
gameDiplomacy[Anthonyetal.,2022,Bakhtinetal.,2022].Indeed,thisgamesharesotherkey
similaritieswithourdomain:acombinatorialactionspaceanditerative,simultaneousmoves.
Weforeseenonear-terminterestfrommarketparticipantsindeploying‚Äúsuperhuman‚Äùbotsto
bidautonomouslyincomplexandhigh-stakesauctionswithouthumanoversight‚Äînobodyisgoing
tobetaFortune500company‚ÄôsfutureonanRLalgorithmrunningagainstunknownopponent
strategiesinanoveleconomicenvironment.However,eveninsuchdomains,MARLtoolsoffer
promiseforevaluatingcompetingauctiondesignsandgainingeconomicunderstanding.Inthisvein,
MARLhasbeenusedtoidentifyandevaluatecomplexpolicydecisionsregardingtaxation[Zheng
etal.,2022]andregulationsoneconomicplatforms[Wangetal.,2023].MARLhasalsobeenapplied
tobargaining,wherepriorworkhasstudiedhowdifferentlearningalgorithmsleadtomoreor
lesssociallydesirableoutcomes[Abramowicz,2020,Lietal.,2023].Weareawareoffewerpapers
thatuseRLtostudyauctionsspecifically.BanchioandSkrzypacz[2022]studythebehaviourof
ùëÑ-learnersinfirst-andsecond-priceauctions,arguingthatinfast-pacedonlineadvertisingauctions
suchalgorithmsreallydointeractwitheachotherandhenceitismoreimportanttounderstand
theirjointdynamicsthantoconsiderequilibriumbehavior.DeepMARLhasalsobeenusedto
computeequilibriaofsingle-roundcombinatorialauctions[Bichleretal.,2021,2023].Closesttothe
domainwestudy,Pacaudetal.[2023]combineheuristicstrategieswithMonte-Carlotreesearchto
findeffectivebiddingstrategiesinclockauctions;however,theyfocusonfindingstrategiesthat
performwellagainstexistingheuristicsinauctionswithcompleteinformation.
ThispaperaimstouseMARLtogaineconomicinsightin(incomplete-information)iterative
combinatorialauctions.Suchinsightscouldhelpahumanbidderassembleastrategic‚Äúplaybook‚Äù
by providing examples of strong bidding both by an agent with their own preferences and by
their counterparties; to date, such playbooks are typically derived via pen-and-paper analysis
ofdramaticallysimplifiedsubproblemsandviaobservationsofexperthumanplayinahandful
of‚Äúmockauctions‚Äù.InsightsgleanedfromMARLanalysiscouldalsohelpanauctiondesignerto
tradeoffthecostsandbenefitsofcandidaterulechanges,evaluatingeconomicvariablessuchas
revenue,welfare,lengthoftheauction,varianceinoutcomes,etc.Unfortunately,actuallyrunning
MARLtounderstandaniterativecombinatorialauctionisnotnearlyassimpleasimplementingan
auctionsimulatorandthenunleashingmultiplecopiesofsomeoff-the-shelfalgorithm.Modeling
aspectrumauctionverbatimfromitsrulebookproducesgamesthatarevastlytoolargetosolve.
Oneisthenimmediatelyfacedwithimportantmodelingchoices,findingwaystoreducethegame
toafeasiblesizewithoutabstractingawaythemoststrategicallyimportantelements.
Ourworkmakestwomaincontributions.First,inSection2,wepresentageneralmethodology
forstudyingcomplex,iterativeauctionsusingMARL.Notably,weadvocateforsimplifyingtheGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 3
auctionmodelbyabstractingtheactionspace,controllingthenumberofbidders,andlimiting
the auction‚Äôs length, without giving up on qualitatively important features such as imperfect
informationorasymmetrybetweenbidders.WedescribethelandscapeofMARLalgorithmsand
importantproblemsthatcanarise,suchasarbitrarybehaviorwhenmultipleactionsleadtothe
sameoutcome,andconvergencetobrittleequilibriathatinvolveunrealisticlevelsofcoordination.
Wealsodiscusskeychallengesinverifyinganalgorithm‚Äôsconvergence,andinterpretingtrained
policiesinthefaceofmultipleequilibria.
Second,wepresentacasestudyshowingthat,despitethechallengesjustdescribed,MARLcan
beusedtoconductnovel,economicallymeaningfulanalysis.Weconsideraprominentfamilyof
iterativecombinatorialauctionscalledclockauctionsand,leveragingtwomodernMARLalgorithms,
investigateakeydesignchoice:howtoprocessbidswhenmultiplebidderswanttodropthesame
product to a level below supply. Section 3 describes the problem, how we model it as a game,
how we solved it using MARL, and how we assessed performance. Section 4 then goes on to
demonstratethatthisrulechangedoesindeedgivebiddersincentivetochangetheirbehavior,
yieldingsubstantialdifferencesinbothrevenueandauctionlength.Furthermore,weshowthat
modelingbiddersasfollowingastraightforward,myopicbiddingheuristicgivesmisleadingresults
inthesamesetting,andindeedwouldleadadesignertoconcludethattherulechangehasthe
oppositeeffect.
Beyondthesefindings,wecontributeahighlyconfigurableclockauctionenvironment.Inthe
hopesthatitwillserveasatestbedforfutureresearchonMARLforauctions,weexposemany
parametersrepresentingpossibleauctionrulechanges.Wealsoprovidesoftwarethatgenerates
clock-auctiongameinstancesandassociatedbiddervalues,leveragingarealisticvaluemodelfrom
theliterature[Weissetal.,2017].Allofourcodeisavailableathttps://github.com/newmanne/
open_spiel.ThepaperconcludesinSection5,wherewediscussvariousdesignchoicesripefor
futureinvestigationandspeculateonmethodologicaladvancements.
2 METHODOLOGY:UNDERSTANDINGITERATIVECOMBINATORIALAUCTIONSVIA
MULTI-AGENTREINFORCEMENTLEARNING
WebeginbylayingoutourmethodologyforapplyingMARLtounderstanditerative,combinatorial
auctions.First,wediscusshowwemodeltheauction,tradingoffmodelfidelitywithsizeofthe
resultinggametree.Wethenturnto‚Äúsolving‚ÄùthegameusingMARL,discussingthestrengths
andweaknessesofdifferentMARLalgorithmfamilies,howtoaddresstheproblemofmultiple
equilibria,andconsideringequilibriumrefinements(preferringpureequilibria;avoidingbrittle
equilibria).Thesectionconcludesbyconsideringhowtovalidateandinterpretpolicies:assessing
theextenttowhichpolicieshaveconvergedtoaBayes‚ÄìNashequilibriumandreasoningacross
multipleequilibria.
2.1 ModellinganAuction
Itistemptingtosimplymodelanauctionwholesale,mappingitsentirerulesmanualintoaMARL
environment,andthenunleashingaMARLalgorithm.Unfortunately,thisapproachisveryunlikely
tosucceedforiterativecombinatorialauctionproblemsbecausethenumberofbundleswillbelarge,
thenumberofbidderswillbelarge,andtheauctionwilllastmanyrounds,yieldinganenormous
gametreethatissimplyinfeasibletosolve.Muchlikepen-and-paperanalysis,onemustabstract
awaycertainelementstobuytheabilitytoaccuratelymodelothers.
Certainkindsofrulecomplexitythatwouldposesignificantbarrierstopen-and-paperanalysis
areunproblematicforMARL,suchaswinnerdeterminationalgorithmsthatfallbackondefault
behaviors when solvers time out, ideosyncratic tie-breaking rules, and complex activity rules
determiningconditionsunderwhichcertainactionsareavailabletocertainbidders.Inothercases,Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 4
auctionelementscandramaticallyincreasethenumberofactionsavailabletoaplayerineach
informationset,suchasopportunitiesforintra-roundbidding,theoptiontosidestepactivityrules
asmallnumberoftimes,ortheabilitytoplacejumpbids.
Werecommendgainingasolidfoundationbystartingwithsimple,easy-to-solvegamesand
scalinguplaterratherthanstartingwithcomplexonesthatmightprovetobeintractable.Wehave
beensurprisedcountlesstimesbyhowevenauctionswithmoderatenumbersofbidders,goods,
androundscanleadtoanenormous,unwieldygametree,leavinglittlehopeofobtainingreliable
resultsfromMARLalgorithms.However,aswedemonstrateinourexperimentsinSection3,there
isasweetspotofgamesizesoutofreachofpen-and-paperanalyses,butverymuchtractablefor
MARL.Webeginbydescribingseveralhigh-leveldecisionsthatadesignercanmaketocontrolthe
sizeofthegametree.Thekeymetricofimportanceisusuallythenumberofdistinctinformation
statesinthegame‚Äîthenumberofgamestatesthatanagentcandistinguish.
2.1.1 Numberofactions. Combinatorialauctionstypicallyhaveenormousactionspaces,often
correspondingtothesetofalllegalbundles.Theactionspacedeterminesthebranchingfactor
ofthegametree,soreiningitinhasadramaticeffectongamesize.Onehelpfulwaytolimitthe
sizeofanactionspaceistoexperimentwithauctionsthathavefewgoodsorunitsforeachgood
available,limitingthenumberofpossiblebids.However,wecautionagainstreducingtheauction
downtoasingleproduct(e.g.,severalunitsofagenericlicense),asauctionswithonlyoneproduct
maynottoengagewithmanyoftheauction‚Äôsrules,leavinginterestingbehaviorunstudied.We
recommendbeginningwithauctionsofferingtwoorthreeproducts.
Itisalsopossibletostudyauctionswithmoreavailablegoodsbyrestrictingbiddersmoreheavily,
onlyallowingthemtochoosefromasmallnumberofheuristicstrategiesateachstate.Forexample,
theseheuristicscouldincludebiddingmyopically,maintainingthelastround‚Äôsbid,raisingprices
onanopponent‚Äôsholdings,orattemptingtodropoutoftheauction;ofcourse,manyotheroptions
arepossible.Careisrequiredheretoensurethatthisrestrictiondoesnotsignificantlyhamper
players‚Äô ability to best respond to others‚Äô strategies. As a concrete example, one might reduce
theactionspacebylimitingbidderstoonlybiddingonpackagestheygenuinelyvalue.However,
itiswell-knownthatthereareauctioninstanceswheresuchsimplebidding isneveroptimalin
Bayes‚ÄìNashequilibrium[BosshardandSeuken,2021].Ahelpfulintermediateoptionistoallow
playerstodeviatefromagivensetofheuristicsuptoùëò timesperauction;thiscanbeusefulwhenit
isonlystrategicallyimportanttodeviatefromknownheuristicsoccasionally,andalsocanbeused
todiagnosetheeffectivenessofthegivensetofheuristics.Thisapproachhasthebeneficialside
effectofproducingstrategiesthatareeasierforananalysttointerpret,whichcanbeparticularly
helpfulfordevelopingaplaybook.Restrictingactionstoasmallersetisalsolikelytomakethe
resultingstrategiesmoreusefulasmeta-strategiesforuseinEmpiricalGameTheoryAnalysis
[Wellman,2006].
Insomeauctions,anaiveimplementationwouldproduceacontinuousactionspace.Forinstance,
bothintra-roundbiddinginclockauctionsandthesupplementaryroundsofCCAsgivebiddersthe
abilitytoreportreal-valuedprices.WhilethereissomeworkonRLwithcontinuousactions,we
recommendagainsttakingthisroute:thesemethodstypicallymakestrongassumptionsthatare
notsuitableinauctionsettings(e.g.,assumingthatbidsaredrawnfromaGaussiandistribution).
Thesimplestmethod,whichweadoptinthiswork,istosimplyavoidmodellingthepartofthe
auctionthatadmitsacontinuousactionspace.Whenthisisnotpossible,agoodalternativeisto
restrictpossiblebidstoafixedgrid:forinstance,allowingbidderstoonlybidin$1increments.
Wesuggestexperimentingwithmultiplediscretizationsthatvaryingranularitytoensurethat
thechosendiscretizationdoesnothaveasubstantialeffectontheresults.Finally,onecanagainGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 5
employafinitesetofheuristics(eachofwhichmapstoanunrestrictedrealvalue),recoveringa
discreteactionspacewithoutdiscretizingbidsthemselves.
2.1.2 Auctionlength. Real-worldspectrumauctionscanlasttenstohundredsofrounds.Thisis
problematicforMARLanalysis,asthesizeofagametreetypicallygrowsexponentiallywithits
maximumlength:withùëü roundsandùêµpossiblebidseachround,agametreewouldhaveùêµùëü states!
However,thereisoftenlittlevalueinanalyzingsuchlongauctions.Inpractice,itiscommonto
seethesamebidsrepeatedatslightlyincreasingpricesformanyrounds,withmuchoftheaction
compressedintoafewkeyrounds.Werecommendsettingopeningpricesandpriceincrements
suchthatauctionslastnolongerthantenrounds;thistendstoavoidenormousgametreeswithout
sacrificingmuchofthestrategiccomplexityoftheauction.Insomecases,eventwoorthreerounds
canbeenoughtoyieldeconomicallymeaningfulconclusions.
Arelatedtechnicalissueisthat,intheory,auctionscanbearbitrarilylong:aslongasbidders
continuetooverdemandproducts,theauctionwillcontinue.Thesearbitrarilylargegametrees
donottypicallyposeaproblemtotheorists,whocanhandlethemwithinductiveproofs,norto
reasonablebiddersinpractice,whowouldneverexposethemselvestoindefinitelyrisingprices.
However,theydoposeaproblemtomostRLalgorithms,whichcannotlearntoavoideachofthese
unreasonablebidtrajectorieswithoutfirstgainingexperiencebymakingthem.Werecommend
constrainingagents‚Äôbidstoruleoutsucharbitrary-lengthbiddingsequencesaltogether.Anatural
solutionistodisallowbiddersfrommakingbidsthatarestrictlydominatedbydroppingoutofthe
auction,ensuringthattheywouldeventuallybeforcedtodropoutwhenpricesbecomesufficiently
high. Another is modelling bidders as budget-constrained, disallowing bids that would exceed
abidder‚Äôsbudgetifprocessed.Budgetsareamoretenuousmodellingchoice:whilereal-world
biddersdotrulyhavefiniteresources,itmaybeunrealistictoprohibitabidderfrombuyinga
licensethattheyvaluemorethanitscost.Afurtherconcernisthatmakinganover-budgetbiddoes
notmeanthatthebidderwillnecessarilyenduppayingmorethantheirbudget;preventingsuch
movesmayunwittinglyrestrictthesetofequilibria.Wealsoexperimentedwithimplementinga
fixedlimitonauctionlength,givingallplayersarbitrary,negativeutilitiesuponhittingthislimit;
werecommendagainstthisasitcanhaveadramaticeffectontheequilibriaofthegame.2
2.1.3 Numberofbidders. Inpractice,spectrumauctionscaninvolvedozensofbidders.However,
manybiddersinrealauctionsrepresentsmall,locally-operatingtelecomsthathavelimitedabilityto
makelarge-scalebids,andrelativelyfewbiddersmakestrategicchoicesatanationalscale.Ifsmaller
biddersneedtobemodeled,considerwhethertheyneedtheflexibilityofstrategicadaptation,
whethertheiractionspacescanberestrictedtotheirbundlesofinterest,orwhetheradeterministic
heuristicstrategywouldsuffice.
2.1.4 Perfectorimperfectinformation. Inaperfect-informationgame,eachbidderknowstheir
opponents‚Äôexactvaluations.Perfect-informationmodelsofauctionsoftenhaveequilibriainwhich
bidderscoordinatestronglyandunrealistically.Forexample,intheperfect-informationmodelofa
sealed-bid,first-priceauction,thebidderwiththehighestvaluebidsthesecond-highestbidder‚Äôs
value and all other bidders bid arbitrarily; missing much of the strategic reasoning that takes
placeinsuchanauction.Analogously,whenweexperimentedwithperfect-informationmodelsof
iterativecombinatorialauctions,weoftenfoundthattheyterminatedinasingleround.
Realauctions,wherebidderslikelyhavepriorsovertheiropponents‚Äôstrategicgoalsandvalua-
tions,arebestmodelledasBayesiangames.WhileBayesianmodelingisabigstepmathematically,
inanRLenvironmentitamountssimplytoaddingachancenodeattherootofthegametree.Such
2Specifically,wefoundthatweakbiddersthatwouldotherwisebeallocatednothingcouldmakenon-crediblethreatstobid
uptothelimit,forcingstrongerbidderstoconcedeanitem.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 6
anodecreatesacopyofthegametreeforeachtypecombination,whichleadstoamuchlarger
gametreebut,sincebiddersdonotknoweachothers‚Äôtypes,hasasmallereffectonthenumber
ofinformationstates.Wethusrecommendexperimentingwithbiddersthathaveasmallnumber
oftypes.Forexample,whenweadaptedtheexperimentsjustdescribedtoimperfect-information
settings in which each bidder can have one of multiple possible valuations, we have typically
observedmoreinteresting,multi-roundbehavior,includingpoolingequilibriainwhichweaker
typesactliketheirstrongercounterpartstodrivebetternegotiationsthanthey‚Äúdeserve‚Äù.
2.1.5 Asymmetrybetweenbidders. Itiscommoninauctionanalysistomodelbiddersassymmetric.
Thisoffersseveraltechnicaladvantages.Whenallbiddersaresymmetric,theequilibriumselection
problemcanmitigatedbysearchingforsymmetricequilibria.Furthermore,ifallagentsbehave
symmetrically,onlyasinglepolicyneedstobetrained.However,inreality,biddersinspectrum
auctions are not usually well-approximated as symmetric, as they often have vastly different
resources, business interests, and priorities. Thankfully, such asymmetry is a straightforward
additiontoaMARLenvironment,asRLalgorithmshavelittletroubledealingwithasymmetric
bidders.Weadvocateforexperimentingwithvaryingbidders‚Äôrelativestrengths.
2.2 FindingEquilibria
WenowturntotheproblemofusingMARLtofindnear-equilibriumstrategyprofiles.
2.2.1 Choosinganalgorithm. Atahighlevel,MARLalgorithmsvaryalongtwokeydimensions.
The first is whether they use a lookup table or function approximation to represent players‚Äô
policies.Intabularmethods,eachinformationstateinthegameisrepresentedseparately;bidders
facedwithanewinformationstatedonotreasonaboutitssimilaritytootherstateswithwhich
theyhavepreviousexperience,butinsteadstartlearningafresh.Thisisadouble-edgedsword:
it does not constrain players‚Äô behavior in any particular way, allowing them to learn flexible
strategies,butcauseserraticbehavior(typicallyclosetouniformrandom)inveryrarelyencountered
states.Withfunctionapproximation(i.e.,deepreinforcementlearning),eachinformationstate
isrepresentedbyafeaturevectorandtheagent‚Äôsbehaviorisregularizedtobesimilarinstates
havingsimilarfeaturevectors.Thisallowsagentstogeneralizefromonepartofthegametreeto
another,butcanbemoredifficulttotrainreliably.Sometabularmethods,suchasCounterfactual
RegretMinimization[Zinkevichetal.,2007],alsoassumeperfectrecall‚Äîthatanagentneverforgets
anythingthattheypreviouslyobserved‚Äîwhilefunctionapproximationmethodsgenerallydonot.
Considerwhetheritseemsstrategicallyimportantthatagentsneverblendobservationstogether.
ThesecondkeydimensiondistinguishingMARLalgorithmsiswhichpartsofthegametreeare
exploredineachtrainingiteration.Manyalgorithmsfromsingle-agentreinforcementlearning,
suchasQ-learning[WatkinsandDayan,1992]orpolicy-gradientmethods[Suttonetal.,1999],
only sample a single path through the game tree at each iteration. While it is possible to use
thesealgorithmsinmulti-agentsettingsbyrunningthemindependentlyforeachplayer,theycan
struggleduetofocusingmostoftheirtrainingeffortonasmallfractionofthegametree.Atthe
otherextreme,algorithmssuchasCounterfactualRegretMinimization(CFR)[Zinkevichetal.,
2007]enumerateeveryinformationstateineachiteration,gettinggoodcoverageovertheentire
gametree,buttheirruntimequicklybecomesinfeasibleforlargergames.Lastly,somealgorithms
fitbetweenthesetwoextremes,enumeratingoneplayer‚Äôsactionsbutsamplingopponentactions
andchanceoutcomes;onesuchexampleisexternal-samplingMonte-CarloCFR(MCCFR)[Lanctot
etal.,2009].
If it is feasible to enumerate the entire game tree, we see little reason not to use a tabular
methodthatexploresmuchofthegametree,suchasCFRorrelatedvariants;attheveryleast,we
recommendsuchalgorithmsasabaselineforcomparingtootherapproaches.Forverylargegames,Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 7
whereitbecomesinfeasibletorunevenasingleiterationofaCFRvariant,functionapproximation
methodsarelikelythewayforward.
2.2.2 Multipleequilibria. Complexauctionstypicallyadmitmultipleequilibria.Whenusingnon-
deterministicMARLalgorithms,asimplewaytofindmultipleequilibriaistorunthealgorithm
withmultiplerandomseeds,whichinfluencebothitsrandominitializationandanyrandomevents
withintheRLenvironment,causingittotakeadifferentlearningtrajectoryoneachrun.Wethus
recommendnon-deterministicalgorithms,e.g.,preferringMonte-CarlosamplingvariantsofCFR
overtheoriginalalgorithm.WehavelessexperiencewithdeterministicMARLalgorithms;we
speculateaboutpotentialapproachestoidentifyingmultipleequilibriawithsuchalgorithmsin
Section5.2.1.
Whentwoormoreactionsproducethesameterminalreward,RLalgorithmshavenoreasonto
preferoneactionoveranother,andequilibriamultiply.Thiscanbedetrimentaltobothconvergence
andauctionoutcomes.Forexample,considerabidderfacinganincrediblystrongopponentthat
willpricethemoutoftheauctionnomatterhowtheybehaveinearlyrounds.Sincetheycannot
impacttheir ownutility, theycanplay anystrategyin equilibrium,rangingfromimmediately
droppingoutoftheauctiontoraisingtheiropponent‚Äôspricesuptotheirownvalue;theirarbitrary
choicewillimpactmanyauctionoutcomesofinterest(e.g.,auctionlength,revenue).Wetherefore
advocateforaddingsmall,‚Äúsecondary‚ÄùrewardstotheRLenvironment,biasingagentstoward
certainstrategies(e.g.,preferringtodropoutthantostayin)whenallelseisequal.
2.2.3 Pureormixedequilibria. Ananalystmustdecidewhethertofocussolelyonpureequilibria
oralsotoconsidermixedequilibria.Thereareseveraladvantagestostudyingpureequilibria.First,
workingwithpureequilibriaiscomputationallybeneficial:restrictingtopurestrategiesgreatly
reducesthestrategyspace,tendingtomakeiteasiertotrain,validate,andevaluatepolicies.Second,
someMARLalgorithmsmaynotbeabletoconvergetomixedequilibriaatall.Forabroadclassof
MARLalgorithms,theonlystablepointsofthelearningdynamicsarepureequilibria[Flokasetal.,
2020];webelievethatasimilarresultislikelytoholdformanyalgorithms,suchasCFR.While
thereisnoguaranteethateverygamewillhaveanypureequilibria,inourownexperiments,we
havefoundthatMARLalgorithmscanfindapureequilibriuminthevastmajorityofourgames.
Werecommendconsideringwhetheritissufficienttostudypureequilibria.Ifthereisreason
tosuspectthatsomeinterestingbidderbehaviorcanonlyberepresentedwithmixedequilibria
(e.g., randomized bluffing), it is necessary to be cautious about the choice of MARL algorithm.
Otherwise,werecommendenforcingthatpoliciesplaypurestrategiesbyroundingthemtothe
nearestpurestrategy,deterministicallyplayingtheactionwiththehighestprobabilityinthepolicy;
werefertosuchroundedpoliciesasmodal.Thisroundingstepisnecessaryforfindingpurestrategy
equilibriawithMARLalgorithmsthatplayactionswithprobabilitiesthatapproachzero,butdo
soexceedinglyslowly,potentiallyneverreachingzero.OnesuchexampleisPPO,whichrewards
entropyinitslossfunction.
2.2.4 Avoidingbrittleequilibria. PriorworkinMARLhasfoundthattrainedpoliciescanfailcata-
strophicallywhenfacingnewopponents.Forexample,inthecooperativecardgameHanabi[Bard
etal.,2020],policiestrainedthroughself-playcanachievenear-perfectscores,butfailtogeteven
asinglepointwhenplayingwithpoliciesfromothertrainingruns.Onewaythiscanhappenis
whenMARLalgorithmsidentifybrittleequilibria,inwhichplayersrelyonperfectcoordination
witheachother,whichtheyachievethroughtheirtraininghistory.Suchequilibriamayhaveno
robustness to even minor misspecifications. Furthermore, in the domain of spectrum auctions,
achievingsuchcoordinationwouldlikelyrequireillegalcollusionbetweenthebidders.Tocombat
thisproblem,duringtrainingwerecommendhavingpoliciestrembleduringtraining,deviatingGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 8
fromthepolicyandplayinganactionuniformlyatrandomwithasmallprobability(e.g.,1%).Such
tremblingpushesagentsawayfromequilibriathatdemandperfectcoordination.Additionally,it
servesasawayoffurtherbreakingdownindifferences:eveniftwoactionsgivethesamerewards
on-path,theymaygivedifferentrewardsoff-path.
2.3 ValidatingandInterpretingPolicies
Lastly,wediscusshowtoproceedaftertrainingasetofpolicieswithaMARLalgorithm.
2.3.1 Assessingconvergence. ItisimportanttofirstunderstandwhetheraMARLalgorithmhas
convergedtoanequilibrium:ifnot,itisdifficulttoknowwhethertrendsinbidders‚Äôstrategies
aresimplycausedbypoorconvergence.TheidealmeasureofconvergenceistheNashConv of
thepolicy,whichisdefinedasthesumofeachagent‚Äôsregret‚Äîtheutilitygaintheywouldachieve
byplayingabest-response,holdingtheiropponents‚Äôstrategiesfixed.ANashConvofzerothus
correspondstoaNashEquilibrium,andapositiveNashConvcorrespondstoanùúñ-Nashequilibrium,
whereùúñ isnogreaterthantheNashConv.Unfortunately,NashConvisnontrivialtocompute,asit
requiresrequiresfindingtheoptimalsolutiontoasingle-agentRLproblemforeachplayer,atask
thatrequiresanexhaustivesearch.Thus,whileitwouldbeidealtocheckpointthetrainedpolicy
periodicallyandtoanalyzeonlythecheckpointwiththesmallestNashConv(whichneednotbe
thelatestcheckpoint),thisisinfeasibleonallbutthesmallestofgames.
WhenitisnotpossibletocomputeNashConvexactly,itcanstillbevaluabletoapproximateit
bycomputingapproximatebestresponses.Onewayistorestricttheactionspaceofthegametoa
smallersetofheuristics(suchasinSection2.1.1)andcomputethebestresponseonthisrestricted
game.Anotheristorunatraditionalsingle-agentRLalgorithm,whichhasnoguaranteeoffinding
theoptimalpolicy,butmaynonethelessfindagoodpolicy.Theseapproximatebestresponsesgive
alowerboundonaplayer‚Äôsregret:ifonestrategywouldhaveincreasedtheirutility,thentheirbest
responsemusttoo.Whilethisapproachcannotguaranteethatastrategyprofileisanequilibrium,
itcanstillbeusefultohavesomeevidencethateachplayer‚Äôsstrategyisnoteasytoimproveupon.
Note that it is dramatically easier to compute NashConv of a pure strategy profile, as this
exponentiallyreducesthenumberofsubtreesthatmustbeexamined.Werecommendattempting
tocomputeNashConvexactlyifanalyzingpurestrategies.WhenoneexpectsapurestrategyNash
equilibrium,itcanalsobeusefultotracktheentropyofplayers‚Äôpolicies,whichmustdecayto0.
2.3.2 Interpretingmultipleequilibria. Wehavealreadystatedsomerefinementsabovethatrule
outcertainequilibria.Then,ifasingleequilibriumremains,onecansimplyproceedtostudyits
strategyprofileorcheckhowitsoutcomesareaffectedbychangestotheauction.However,alikely
outcomeistowindupwithasetofequilibria,makingtheanalysismurkier:shouldananalysttreat
oneequilibriumasmoreimportantorplausiblethananother?
Withoutanyotherdesiderata,webelieveitisdifficulttorankequilibriabytheirplausibilityor
frequency,astheexactchoiceofMARLalgorithmbiaseswhichequilibriaarelikelytobefound
in ways that are difficult to predict. When faced with multiple equilibria, we advocate that no
equilibriumisinherentlymoreplausiblethanothers.Thus,werecommendlookingattherangeof
possiblestrategiesoroutcomesrepresentedbythesetofequilibria,ratherthanlookingate.g.,the
meanoutcomeacrossallsamples,oronlystudyingasinglesample.
3 CASESTUDY:BIDPROCESSINGINCLOCKAUCTIONS
Wenowdemonstrateourmethodologyonclockauctions,amoderniterativecombinatorialauction
format.Asacasestudy,wefocusonaspecificquestionaboutthedesignofthisauction:inwhich
ordershouldtheauctioneerprocesssimultaneousbids?Wediscusshowtoinstantiateeachpartof
ourmethodologytotacklethisquestion.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 9
3.1 ClockAuctions
Clockauctionsareaniterativecombinatorialauctionformatthathasbeenusedtoallocatespectrum,
e.g.,intheFCC‚ÄôsAuction102[FCC,2019]andtheCanadian3500MHzauction[ISED,2021].Here,
wedescribeasimplifiedauctionformatthatdrawsheavilyupontheserealspectrumauctions;we
provideaformaldescriptionoftheauctioninAppendixB.
In a clock auction for allocating spectrum, an auctioneer sells indivisible radio licenses to a
numberofbidders,witheachbidderrepresentingatelecomcompany.Thelicensesaredivided
into products, with each product corresponding to an equivalence class of geographic region
andspectrumquality;therearetypicallyseveralunitsofsupplyavailableforeachproduct.The
auctioneersetsanopeningpriceforeachproduct.Then,theauctionproceedsoveraseriesof
rounds.Ineachround,bidderssubmitavector-valuedbidrepresentingthenumberofunitsofeach
producttheywanttobuyatthecurrentprices.Ifanyproductisoverdemanded‚Äîthatis,hasmore
aggregatedemandthansupply‚Äîthentheauctioneerincreasesthepriceoneachoverdemanded
product,informsallbiddersofeveryproduct‚Äôsaggregatedemandandnewprice,andproceedsto
thenextroundoftheauction.Otherwise,theauctionends,witheachbidderwinningtheunits
theybidfor,payingtheirfinalprices.
Wehighlighttwoadditionalrulesthataddconsiderablecomplexitytoclockauctionanalysis.
First,todiscouragestrategicbidding,bidderscannotbidforarbitrarybundlesineachround.Future
bidsareconstrainedbypastbidsthroughanactivityrule.Weconsiderasimpleimplementation
whichassignseachbundleanumberof‚Äúeligibilitypoints‚Äùandrequiresbidstobeweaklydecreasing
ineligibilitypoints.Second,toavoidleavinglicensesunsold,theauctioneerrejectsbidsthatwould
lowerthedemandforaproductbelowitssupply.Combinedwiththeactivityrule,thiscreates
apotentialexposureproblem,asbidsmayonlybepartiallyprocessedifpointsfromadropped
productareneededtopickupanewproduct.
We now use our methodology to evaluate a potential design choice: when multiple bidders
simultaneouslyrequesttodroplicenses,howshouldtheauctioneerdeterminewhichbidstoprocess
first? Processingeverybidder‚Äôsdroprequestcouldchangeaproductfrombeingover-tounder-
demanded,whichtheauctionrulesdisallow.Toavoidleavinglicensesunsold,theauctioneermust
insteadprocessthedroprequestssequentially.Inpractice(e.g.,intheCanadian3500MHzauction),
thesetiesarehandledbyrandomlyorderingthequeueofrequestsandprocessingentiredrop
requests in this order, letting bidders drop as many licenses as they requested, until no excess
demandremains.This‚Äúdrop-by-bidder‚Äùmechanismcanhavehighvariance,processingeitherall
ornoneofeachbidder‚Äôssubmittedbid.Wecomparethismechanismtoanalternativewherea
requesttodropseverallicensesofaproductisrepresentedinthequeueasmultiplerequeststodrop
anindividuallicense.Thisalternative‚Äúdrop-by-license‚Äùmechanismreducesvariance,makingit
mostlikelythateachbidderwillhavesomeoftheirdroprequestsprocessed.Thesebidprocessing
mechanisms are well-suited for our computational methodology because they require a large
amountofcase-basedreasoningtostudy,makingthemoverwhelmingtoanalyzewithtraditional
methodsbutidealforreinforcementlearning.
3.2 DefiningtheEnvironment
Intheremainderofthissection,wedescribehowweinstantiatedthemethodologytocompare
thesetwoauctiondesigns.WeimplementedourclockauctiongameintheframeworkofOpenSpiel
[Lanctotetal.,2019].Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 10
3.2.1 Auctionsetup. Weconsiderauctionswithtwobiddersandasinglegeographicregionwith
twoproducts:anunencumbered3productwithonelicenseofsupply,andanencumberedproduct
withfourlicenses,eachofwhichonlygives60%ofthebandwidthofanunencumberedlicense.Each
licensehaseligibilitypointsandanopeningpriceproportionaltotheamountofbandwidthavailable.
Wefocusonaspecificstatemidwaythroughtheauction4:weassumethateachbidderhaspreviously
bidforthreeoftheencumberedlicensesforseveralrounds,makingitmoreexpensiveperMHzof
spectrumthantheunencumberedlicense.Thebiddershaveastrategicchoicetomake:continue
biddingonthemoreexpensiveproduct,orattempttoswitchtothecheaperone(e.g.,dropping
twoencumberedlicensestopickuponeunencumberedlicense).Thebidprocessingmechanismis
usedifbothbiddersattempttoswitch.Inthedrop-by-biddermechanism,theauctioneerchooses
arandomorderoverthebiddersandprocessesallofonebidders‚Äôdropsinorder,allowingone
randombiddertoswitchwhiletheother‚Äôsbidisunprocessed.Inthedrop-by-licensemechanism,
theyinsteadprocesstheindividualrequesteddropsinarandomorder,mostoftenendingwith
bothbiddersdroppingoneencumberedlicense;inthiscase,theactivityrulepreventsbothbidders
frompickinguptheunencumberedlicense.5
Wesettheopeningstart-of-roundpricesto$12millionontheunencumberedproductand$7
millionontheencumberedproduct.Wesettheclockspeed‚Äîthepriceincreaseaftereachround‚Äîto
5%ofthecurrentprice.Thus,aftertworoundsofbiddingfortheencumberedproduct,itsprice
increasedbytwoclockincrementsto$7.72million.
3.2.2 Bidderutilities. Weassumethateachbidderhasafinitenumberoftypes,witheachtype
beingequallylikely.Eachtypehasaquasilinearutilityfunction,meaningthattheyhaveavalue
foreachbundle,andtheirutilityforwinningabundleisitsvalueminusitspricepaid.Wechoose
thesevaluesbydrawingthemfromtheSpectrumAuctionTestSuite(SATS)valuemodel[Weiss
et al., 2017], informed by the 2014 Canadian spectrum auction. Within a region, SATS models
biddersashavingacriticalamountofspectrumwhichtheyneedinordertoprovideahighquality
ofservice,andlowmarginalvaluewhentheyhavemuchmoreorlessthanthiscriticalamount.
Biddersarethusdescribedbytwoparameters:theirvaluepersubscriber,theamountofvaluethey
wouldgainfromwinningallofthespectrum,andtheirmarketshare,thefractionofspectrum
whichtheyneedtoobtainhalfofthismaximumvalue.Theirvaluesarethensigmoidalwithrespect
tothefractionofspectrumtheywin,withhighmarginalvalueswithin¬±15%oftheirmarketshare,
andlowmarginalvaluesoutsideofthisrange.6Foreachtype,wedrawtheirvaluepersubscriber
uniformlyatrandombetween$20millionand$30million,andtheirmarketshareuniformlyat
randombetween35%and50%.Notethatthesenon-linearvaluefunctionscanmake‚Äúswitch‚Äùbids
risky,asbidderscanlosealargeamountofvalueifaswitchbidisonlypartiallyprocessed.
Inpreliminaryexperiments,wefoundthatsomesamplesfromthisvaluemodelledtogames
thatwereeitherstrategicallyuninteresting(e.g.,hadabiddertooweaktohaveachanceofwinning
asinglelicense)orhadgametreestoolargetobefeasible(e.g.,couldlast20roundsormore).To
guardagainsttheseproblems,weranrejectionsampling,resamplingvaluesthatwouldexhibitone
oftheseproblems.Wegeneratedvaluesforbiddershaving1,2,3,5,and7types,generating5value
3Inspectrumauctions,certainlicensesareencumbered,onlycoveringafractionoftheMHz-Popthatafull,unencumbered
licensewould.Encumberedlicensesareusuallypricedatadiscounttoreflecttheirpoorercoverage.
4Wedonotassumethisparticularmidwaypointispartofanyequilibriumofthegamestartingfromthefirstround.Weare
interestedinequilibriumbehaviorstartingfromthispoint.
5Realauctionsoftenincludeagraceperiodrule,givingbiddersachancetoregainlostactivityinthefollowinground.Our
modeldoesnotincludeagraceperiod.However,noticethatinthisstrategicsetting,ifbothplayersloseactivity,theauction
isguaranteedtoend,andagraceperiodrulewouldhavenoeffectinthesecases.
6Wenoteasimilarsigmoidalmodelingchoicein[Bichleretal.,2022],whichstudiestheFCC‚ÄôsC-band.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 11
profilesforeachnumberoftypes.Weprovidetheprecisedetailsoftherejectionsamplingprocess
andanexampleofbidders‚ÄôvaluefunctionsinAppendixC.
3.2.3 Secondaryrewards. Withnofurtherchanges,theseauctionscanadmitmanydifferentactions
thatleadtothesameterminalrewards:forexample,attemptingtodropfromademandof3toa
demandof0oftenhasthesameeffectasdroppingtoademandof1.Weaddressthisproblemby
addingsecondaryrewards(asdescribedinSection2.2.2).Specifically,eachround,wesubtracta
penaltybetweenzeroandonefromeachplayer‚Äôsutility.Apenaltyofzerocorrespondstochoosing
the most profitable bundle at the current prices, and a penalty of one to the least profitable;
otherbundles‚Äôpenaltiesinterpolatebetweenthesetwoextremes.Thesesecondaryrewardscanbe
understoodasgivingbiddersanincentivetopreferstraightforwardbidsandshorterauctionsin
theabsenceofanyotherdifferences,breakingequalitiesbetweenactions‚Äôterminalrewards.These
penaltiesareremovedaftertraining,andallofourreportedNashConvvaluesarewithrespectto
theunmodifiedgame.
3.3 FindingEquilibria
WerantwoMARLalgorithms:aMonteCarlosamplingvariantofCounterfactualRegretMinimiza-
tion,andProximalPolicyOptimization,anon-policydeepreinforcementlearningmethod.
3.3.1 MonteCarloCounterfactualRegretMinimization. MonteCarloCounterfactualRegretMini-
mization(MCCFR)isatabularMARLalgorithm.Itiseffectivelyageneralizationofregretmatching
toimperfectinformationextensiveformgames:ateachinformationstate,ittracksaregretforeach
action,playingactionswithprobabilitiesproportionaltotheirregret.Specifically,weuseavariant
knownasExternalSamplingMCCFR[Lanctotetal.,2009],whichavoidstraversingtheentiregame
treebyrandomlysamplingchanceoutcomesandopponentactions.Initialexperimentationrevealed
thattwocommonperformancetrickswerehelpful:weusetheregretmatchingplus[Tammelin,
2014]algorithminsteadofregretmatching,andweuselinearCFR[BrownandSandholm,2019a],
whichdiscountsregretsovertimesothatlateriterationshavelargerimpacts.Lastly,asiscommon
forCFR,weanalyzetheaveragestrategyacrossalliterations,ratherthanthelastiterate.
Wemakeonemodificationtothisstandardalgorithm.TohelpsteerMCCFRawayfrombrittle
equilibria,wetrainagainsttremblingopponents.Specifically,whenwesampleanopponent‚Äôsaction,
weassumethattheytremble1%ofthetime,pickinganactionuniformlyatrandomratherthan
usingtheirtrainedpolicy.7Thistremblingonlyoccursduringtraining;thereisnotremblinginour
finalpolicies.
3.3.2 ProximalPolicyOptimization. Oursecondalgorithmisadeepreinforcementlearningalgo-
rithm,ProximalPolicyOptimization(PPO)[Schulmanetal.,2017].PPOisanon-policyalgorithm
inspiredbyclassicpolicygradientmethods.Itrepresentsitspolicywithaneuralnetwork;roughly,
totrainthispolicy,itcollectsasampleofinformationstates,actions,andtheireventualrewards,
thenupdatesitspolicytoincreasetheprobabilityitplacesonactionsleadingtohighrewards.PPO
differsfromastandardpolicygradientmethodinthatitsobjectivefunctionpenalizeslargechanges
inactionprobability,causingittochangeitspolicymoreslowlyduringtraining.
InordertousePPO,wemustchooseaneuralnetworkarchitecture.Weexperimentwithtwo.
Thefirstisafeed-forwardneuralnetwork,acceptingaflatvectordescribingallvariablesknown
intheinformationstateasinput.Whilethisisasimplearchitecture,itisunlikelytobeeffective:
suchanetworkwouldhavetolearnhowtoprocessfactsabouteverysinglebundleoflicenses
independently.Toaddressthisissue,wealsotestanequivariantarchitecture[Hartfordetal.,2018],
7Wedonotmakethetrainingplayertremble,asexternalsamplingMCCFRalreadyevaluateseveryoneoftheirownactions
ratherthansamplingjustone.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 12
Fig.1. TheAuctionNetneuralnetworkarchitecture.
whichisshowninFigure1.Inthisarchitecture,eachbundlehasanassociatedsetoffeatures,and
the network must perform the same computation on every bundle. Comparisons can be made
acrossbundlesusingmax-pooling.Thisenforcesthatthenetworkmustapplythesamefunctionto
eachbundle,givingitastronginductivebiastowardlearningasingle,simplefunctionandapplying
itglobally.
ForbothMCCFRandPPO,weconvertalltrainedpoliciestopurestrategies,placingprobability1
onthemodalaction.Thisconversioniscomputationallyimportant,makingitpossibletocompute
NashConvbypruningallactionswithprobability0.
3.4 ValidatingandInterpretingPolicies
Wecomputeseveralmetricsabouteachofourtrainedpolicies.Foreachsimulation,werecordthe
auctionrevenue,welfare,length(inrounds),thenumberofunsoldlicenses,andnumberoflotteries
inbidprocessing.Thelatterisrelevanttothedesigndecisionbeingstudiedasitshineslighton
whetheragentsareengaginginstrategiesthattriggerlotteriesorcarefullyavoidingthem.We
validatetheconvergenceofourmodalpoliciesbycomputingNashConvwithastandarddepth-first
searchalgorithm.
Wealsocompareourresultstosimulationsofstraightforwardbidders.Concretely,wedefinea
straightforwardbidder asabidderwho,ineachround,bidsforthebundleoflicensesthatwould
givethehighestutilityatthecurrentprices.8Thisisanaturaldefinitionofstraightforwardbidding
behaviorasitismyopic,withnoregardtopriceincreasesoractivityconstraintsinfuturerounds.
Itisalsoanalogoustoexistingdefinitionsofstraightforwardbiddinginsimultaneousmulti-round
auctions[e.g.,Milgrom,2004],arelatedauctionformat.
4 EXPERIMENTALRESULTS
Wenowdiscussthreesetsofexperimentsandtheirresults.First,wetunedourtwoMARLalgorithms.
Wefoundconfigurationsthatcouldidentifypolicieswithlow(oftenzero!)NashConvinourgames.
Second,weranourtunedalgorithmsongameswithtwodifferentbidprocessingalgorithms.We
observedthatthemodificationtobidprocessingyieldssubstantiallydifferentauctionoutcomes
duetonon-trivialchangesinbidderbehavior.Third,wetestedhowwellthesealgorithmsscaledto
largergames.Wefoundthattheyoftenstillconvergedtoapproximateequilibria.
OurcomputationalenvironmentisdescribedinAppendixA.Exceptwherenotedotherwise,we
ranourMARLalgorithmsforonehourofwalltime.
8Whilewerefertothisstrategyasstraightforward,wenotethatitisfarfromstraightforwardtodefinestraightforward
biddinginthisauction.Anybidthatinvolvesdroppinglicensesmightberejected.Thisisespeciallyimportantwhen
part‚Äîbutnotenough‚Äîofadropbidgoesthroughandabidderdoesnothaveenoughactivitytopickupwhattheyintended.
Abiddermaythereforenotwanttoplacebidsthatcouldleavethemexposed.Reasoningaboutbidsinthismannerrequires
amorecomplexdemandforecastingmodel.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 13
Fig.2. NashConvofMCCFRablations,varyingsecondaryrewardsandtremblingopponents.
4.1 AblationsandHyperparameterTuning
First,weexperimentwithvarioushyperparametersettingsforeachofourMARLalgorithms.
4.1.1 MCCFR:TremblingOpponentsandSecondaryRewards. MCCFRhasfewhyperparameters
thatneedtobetuned.Here,weevaluateourrecommendationsfromSections2.2.2and2.2.4,where
weadvocatedforbreakingtiesbetweenrewardsforactions,andforhavingopponentstrembleto
avoidbrittlestrategies.Totestthesetechniques,wecomparedfourvariantsofMCCFR,varying
whetheropponentstrembledduringtrainingandwhetherthegameincludedsecondaryrewards.
Weraneachvariantwith10randomseedson10differentfive-typegames(comprisingof5valuation
samplesand2bidprocessingrules),makingforatotalof100runsforeachvariant.Foreachrun,
wecomputedNashConvatsixcheckpoints,after100,200,500,1000,2000,and3000iterations,
respectively.Runstookbetween10and60minutes.
The results are shown in Figure 2. All four variants consistently converged to approximate
equilibria.However,therewereconsistentdifferencesbetweensomeofthevariants:trainingwith
secondaryrewardsledtolowerNashConvearlyintraining,andmorefrequentlyconvergedtoexact
Nashequilibria.Trainingagainsttremblingopponentshadamorevariedimpactonconvergence,
increasingNashConvearlyintrainingbuthavingnoeffectatlatercheckpoints.Intheremainder
ofourexperiments,weoptedtorunMCCFRwithbothofthesefeatures,reasoningthattheywere
likelytosteerMCCFRawayfrombrittleequilibriaandleadtofasterconvergence.
4.1.2 PPO: Architecture and Hyperparameter Optimization. Compared to CFR, PPO has many
hyperparametersanditsperformanceishighlysensitivetothesehyperparametersettings.These
hyperparameterscontrol,amongotherelements,itsneuralnetworkarchitecture,lossfunction,
andoptimizers.Wetunedthesehyperparametersusingrandomsearch.Specifically,wesampled60
randomconfigurationsofthesehyperparametersandraneachwith3randomseedson6different
five-typegames(comprisingof3valuationsamplesand2bidprocessingrules),makingforatotal
of18runsforeachconfiguration.Foreach,weranPPOfor30minutes,computingNashConvonce
attheend.Weprovidedetailsaboutthehyperparametersandourrandomsamplingdistributions
inAppendixD.
TheresultsareshowninFigure3.Thehyperparameterconfigurationsvariedsubstantiallyin
theirabilitytofindapproximateequilibria,withmanyfrequentlyproducingpolicieswithveryhigh
NashConv.However,afewconfigurationsconsistentlyconvergedtoapproximateequilibria;the
bestconfigurationalwaysreturnedpolicieswithaNashConvbelow0.1.Notably,thisconfiguration
selectedtheAuctionNetarchitecture(asdo8ofthebest10configurations).Weusedthissingle
bestPPOconfigurationintheremainderofourexperiments.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 14
Fig.3. NashConvofPPOhyperparametertuningruns,showingall60configurations(left)andadetailed
viewofthe20bestconfigurations(right).Configurationsaresortedby95thpercentileofNashConv.Whiskers
denote5thand95thpercentiles.
4.2 EffectsofBidProcessingAlgorithms
Wenowturntoourmaineconomicquestion:howdoestheauction‚Äôsbidprocessingalgorithmaffect
bidders‚Äôstrategiesandoutcomesoftheauction? Toanswerthisquestion,weexperimentedwith
biddervaluationswith1,2,3,5,and7types,generating5samplesofeachforatotalof25value
profiles.9Foreachvalueprofile,wecreatedtwogames:onewitheachbidprocessingalgorithm.
Thesegamesvariedinsize,withthe1-typegameshaving10‚Äì100informationstates,andthe7-type
gameshaving500-700informationstates.WeranMCCFRandPPOoneachgamewith10random
seeds,foratotalof1000MARLalgorithmruns.Wediscarded24runsthathadaNashConvgreater
than0.1,leaving976runs;904ofthesehadaNashConvof0,meaningthattheyconvergedtoNash
equilibria.
OurresultsareshowninFigure4.Thisplotshowsfourmetrics:thelengthoftheauction,number
oflotteries(i.e.,thenumberofroundswherethebidprocessingalgorithmcanproducetwoor
moredifferentoutcomes),revenue,andwelfare.Thesemetricswereaveragedovertenthousand
episodestoaccountforrandomnessinbidders‚Äôassignedtypesandbidprocessingoutcomes.Each
pointrepresentsan(approximate)equilibriumfoundbyoneofthetwoMARLalgorithms.We
providesupplementaryplotsseparatingtheequilibriafoundbyeachofthetwoMARLalgorithms
inAppendixE.
Ourmainfindingisthatthetwobidprocessingrulesleadtoqualitativelydifferentoutcomes:
whenbiddershave3ormoretypes,equilibriaunderthedrop-by-licenserulecanproducelongerauc-
tionswithhigherrevenueandlowerwelfarethanunderthedrop-by-playerrule.Thesedifferences
inauctionoutcomesarecausedbydifferencesinbidderbehavior.Underdrop-by-player,whenboth
biddersattempttoswitchtheirdemandfromtheencumberedproducttotheunencumberedone,the
bidprocessingalgorithmcanresultinalottery;whenthishappens,theauctionimmediatelyends.
Underdrop-by-license,however,theselotteriesarelessdesirabletobidders,astheyriskdropping
asingleencumberedlicensewhichwillnotcreateenoughactivitytobuyanunencumberedlicense.
Biddersadjusttheirstrategiesaccordingly,takingcaretoavoidsimultaneouslyswitchingtheir
demand,causingeverysingleequilibriumunderthisruletohavenolotteries.Inmanygames,this
adjustmentcanleadtolongerauctions,creatingadditionalrevenueasthepricesincrease.
Notably,thedifferencesbetweenthetwobidprocessingalgorithmsvanishwhenbiddersonly
haveasingletype.Inthesegames,biddershavecompleteinformationabouttheiropponent‚Äôsvalues
(and,inequilibrium,theiropponent‚Äôsstrategy).Theyarethenabletoavoidlotteriesregardless
9Bidders‚Äôvaluationsweresampledindependentlyforeachofthesegames.Thismeansthat,forexample,bidders‚Äôvaluesin
the1-typegameswerenotnecessarilyequaltoanyvaluesingameswithmorethan1type.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 15
Fig.4. AuctionoutcomesusingMCCFRandPPOon2-playergameswith1to7types.
ofthebidprocessingalgorithminmostgames,leadingtoidenticalauctionlengthsandrevenues
underthetworules.Theresultsarealsoambiguouswith2typesperbidder,wherenoequilibrium
leadstoabidprocessinglotteryin3ofour5games.Thesefindingshighlighttheimportanceof
modellingtheenvironmentasaBayesiangamewithmultipletypesforeachplayer,asdoingso
canleadtoqualitativelydifferentfindings.Lastly,thesefindingsalsohighlighttheimportanceof
searchingformultipleequilibria;ifwehadonlysampledasingleequilibriumfromeachgame,we
wouldhavedrawnverydifferentconclusions.
Wealsosimulatedtheauctionsunderstraightforwardbidding.Straightforwardsimulationresults
for7-typegamesareshowninFigure5,withadditionalplotsfortheothergamesinAppendixE.
Figure5showsthatignoringbidders‚Äôincentiveswouldleadtoentirelydifferentconclusions.Here,
bothrulesleadtoauctionsofthesamelength,asbiddersactthesamewayregardlessofthebid
processingalgorithm.Furthermore,itisnowthedrop-by-playerrulethatleadstomorerevenue:
underthedrop-by-licenserule,itiscommonforalicensetobeleftunsold,losingrevenue.TheGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 16
Fig.5. Auctionoutcomesunderstraightforwardbiddingon2-playergameswith7types.
(a) (b)
Fig.6. (a)NashConvruntimedistribution;(b)auctionoutcomesusingMCCFRon3-playergames.
drop-by-playerrulealsoproduceshigherwelfareforasimilarreason,asitisinefficienttoleave
licensesunsold.Wenotethatstraightforwardbiddingisindeednotanequilibriumintheseauctions:
onthe7-typegames,NashConvrangesfrom0.18to3.10.
4.3 ScalingtoLargerGames
Encouragedbyhowwellouralgorithmsperformedonthegamesabove,wecreatedasetoflarger
gamestotesthowwellourMARLalgorithmswouldscale.Todoso,weaddedathirdbidderanda
fifthencumberedlicense.Tokeepthegamestractable,wealsoincreasedtheclockincrementfrom
5%to20%.Weinitializedtheauctioninasimilarstateasbefore,havingeachbidderbidforthree
encumberedlicensesfortworounds.Wegenerated5valueprofileswith3typesperbidder,yielding
atotalof10gamesacrossthetwobidprocessingalgorithms.Thesegamesaresubstantiallylarger
thanthe2-playergames:thesmallesthavearound8,000informationstates,whilethelargesthave
over40,000.WeranMCCFRfor8hoursoneachgame.
Validatingtrainedpoliciesontheselargergameswassubstantiallymoredifficult.Attheendof
eachrun,weattemptedtocomputeNashConvforupto1hour.Withinthistimelimit,wewere
onlyabletocomputeNashConvfor46ofthe100runs;thedistributionofruntimes,plottedin
Figure6a,showsthatNashConvtookatleast30minutesonmostruns.Nonetheless,whenwe
wereabletocomputeNashConv,itwaslow.Theworstrun‚ÄôsNashConvwas0.03and36runshad
NashConvsof0.Thus,itispossibleforMCCFRtofindequilibriaoftheselargergames.
Forcompleteness,Figure6bshowstheauctionmetricsforall100runs,includingthoseforwhich
wecouldnotcomputeNashConv.Itisinterestingthatthedifferencesbetweentherulesinthis
settingarequiteunlikethoseinthe2-playergames,withthedrop-by-playerruleleadingtolongerGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 17
auctions,higherrevenue,andhigherwelfare.Onepotentialexplanationisthatunderthedrop-
by-playerrule,allthreeplayerscansafelyattempttoswitchtheirdemandfromtheencumbered
producttotheunencumberedproduct,allowingforfurthercompetitioninthefollowinground.
5 CONCLUSIONSANDDISCUSSION
Multiagentreinforcementlearningalgorithmsarerapidlymaturing,havingrecentlyreachedseveral
significantmilestones.Thispaperarguesthat‚Äîifgamesaremodelledappropriatelyandtheright
algorithmicchoicesaremade‚ÄîMARLcanbeusedtoanalyzeiterativecombinatorialauctionsthat
resistbothpen-and-paperandcomputationalBayes‚ÄìNashanalysis.Welaidoutamethodologyfor
modellinganauctionforusewithMARLanalysis,findingnear-equilibriausingMARLalgorithms,
andbothvalidatingandinterpretingtheresults.Wethenofferedacasestudyonbidprocessingin
clockauctions,showingthatMARLanalysiscouldreachaneconomicallymeaningfulconclusion
inasettingthatwouldnothaveadmittedequilibriumanalysis,andforwhichasimulation-based
analysiswouldhaveyieldedthewrongconclusion,andfindingevidencethatMARLanalysishas
thepotentialtoscaletoevenlargersettings.
WehopethatwehavepersuadedthereaderthatMARLhassomethingtoofferauctionanalysis;
however,ourownworkhasclearlyonlyscratchedthesurface.Wethusconcludewithanin-depth
discussionofusefulnextsteps:futureclockauctiondesignchoicesthatwouldbefruitfultoanalyze;
promisingavenuesforimprovingourmethodology;andopentheoreticalquestions.
5.1 PromisingAuctionDesignQuestions
AswedescribedinSection3.1,anauctiondesignerfacesmanypotentialchoicesabouthowto
instantiateeachaspectofanauction,eachofwhichcouldinfluencebiddingbehaviorandultimately
outcomes. Here, we describe three such design choices that we believe would be amenable to
MARLanalysis,demonstratingtherelevanceofeachwithcitationseithertotheacademicliterature
ortobidderconsultationswithpolicymakers.Foreach,wediscussthedesignchoice‚Äôsstrategic
implicationsandhowitmightimpactrevenue,welfare,and/orlengthofauctions.
Clockspeed. Adesignerchoosestheexponentialincrementbywhichpricesofoverdemanded
productsincrease.Largerincrementsallowforquickerauctions,butreduceopportunitiesforprice
discoveryasthereislessfeedbackforbidders.Biddersreacttotheseincrements;inaconsultation
forthe3800MHzCanadianauction,Telus‚Äúarguedthatincrements[of10%-20%]wouldcreatean
acceleratedcadenceatthestartoftheauctionthatmayprovecontrarytothedesiredintention
ofpromotingpricediscovery‚Äù[ISED,2022].Anauctioneermayevenconsiderdynamicschemes,
suchasmodifyingtheclockspeedpartwaythroughtheauction,orusingaseparateclockspeed
foreachproduct,withsteeperpriceincreasesformoreoverdemandedproducts.
Informationdisclosure. Attheendofeachround,theauctioneerdisclosesinformationaboutthe
currentstateoftheauction.Commonly,thisincludesthepricesandunitsofaggregatedemand
for each product. An auctioneer could vary this policy‚Äîfor example, only disclosing whether
each product was over- or under-demanded‚Äîhoping to improve outcomes by disincentivizing
strategicbidding.Anoppositeextremeistodeanonymizeallbids.Suchasuggestionwasmadeina
consultationforthe3500MHzCanadianauction:‚ÄúEastlinkopposedtheuseofanonymousbidding,
statingthatitgenerallyfavoursthelargenationalincumbentbiddersastheyinherentlyhavemore
informationavailabletothemduringthepricediscoveryrounds‚Äù[ISED,2021].
Activityrules. Thereisabodyofworkonhowtoselectactivityrules,mostlycenteredaround
whichonetopickfromtheperspectivesofdiscouragingstrategicmanipulationsandminimizing
complexityforthebidder.Forexample,Harshaetal.[2010]definestrongactivityrulesasthoseGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 18
whichadmitstraightforwardbiddingstrategiesandexcludestrategiesthatnotconsistentwith
straightforwardbiddingundersomeutilityfunction.AusubelandBaranov[2020]proposethat
anactivityruleshould(1)ensuredemandandpricemoveinoppositedirections,(2)alwaysallow
straightforwardbidding,and(3)alwaysallowrepeatingthepreviousbid;theauthorsprovethatan
activityrulebasedontheGeneralizedAxiomofRevealedPreference(GARP)uniquelysatisfiesthe
threeaxiomsundernon-linearprices.Ofcourse,neitherofthesepapersisbackedbyequilibrium
analysis,asthiswouldbeintractable;itwouldthusbevaluabletouseMARLanalysistoestimate
theextenttowhichtheseactivityrulesallowstrategicmanipulation.
Itwouldalsobevaluabletostudybidderbehaviorunderavarietyofvaluemodels‚Äîforexample,
modellingrisk-aversebidders,orspitefulbidderswhogainutilityfromcompetitorspayinghigh
prices‚Äîtounderstandtheextenttowhichanyfindingsarerobusttothechoiceofbiddermodel.
5.2 MethodologicalImprovements
5.2.1 Enumeratingmanyequilibria. Ourmethodologyrecommendedidentifyingmultipleequilibria
byrunningMARLalgorithmswithdifferentrandomseeds.Thisapproachissimpletoimplement,
butmaynotbeabletofindallequilibriaofagame;furthermore,inductivebiasesinthealgorithm
almostcertainlymakeitmorelikelytofindsomeequilibriathanothers.Whilethismaybeseenasa
goodthingifonebelievesthatequilibriathatlearningdynamicsstrugglestofindarelessplausible,
itmayalsobeseenasablindspot.Analternateapproachthatcouldbeworthinvestigatingis
termedqualitydiversityinsingle-agentRL[e.g.,Pughetal.,2016];itfocusesonfindingmultiple
distinct,goodpolicies.Futureworkshoulddevelopandevaluatealgorithmstoincreasethediversity
ofequilibria,expandingourabilitytofullyunderstandtheequilibriaofanauction.
5.2.2 Interpretingbiddingbehavior. Ouranalysisinourcasestudyfocusedmostlyonoutcomes.
Particularlyforbidder-focused‚Äúplaybook‚Äùapplications,itcanbeimportanttoderiveinsightsabout
whatconstitutesagoodstrategy.Thisrequiresthatlearnedpoliciesnotonlybemeasurablebutbe
interpretable.BertsimasandPaskov[2022]useCFRtotrainpokeragentsandthenfitdecisiontrees
totheCFRstrategiesthroughsupervisedlearningtoproduceinterpretablepokerstrategies.Future
workcouldsimilarlyfocusondistillingbiddingbehavior.Asetofcomposablebiddingstrategy
buildingblockscouldbevaluablebothforunderstandingauctionsandasheuristicsforscale.
5.3 TheoreticalQuestions
5.3.1 Convergence to Nash equilibrium. In two-player zero-sum games, CFR is guaranteed to
convergetoanapproximateNashequilibrium.However,auctionsarenotzero-sum,andexisting
guarantees for general-sum games are far weaker. Morrill et al. [2021] show that CFR is only
guaranteedtoconvergetoacounterfactualcoarsecorrelatedequilibrum,amuchweakersolution
concept. Despite this lack of theoretical justification, on our auctions, we found that MCCFR
consistentlyconvergedtopureBayes‚ÄìNash(near-)equilibrium.Isthereaclassofgames(larger
than two-player zero-sum) in which existing MARL algorithms converge to Nash equilibria?
UnderstandingthespaceofsuchgameswouldhelpwithselectinganappropriateMARLalgorithm.
5.3.2 Alternativesolutionconcepts. Whilewehavefocusedonfinding(Bayes‚Äì)Nashequilibria,
thissolutionconceptcanadmitunrealisticbehavior.Oneconcreteproblemisthatitispossiblefor
ourlearnedpoliciestomakenon-crediblethreatsinoff-pathstates.Forexample,abiddercould
adoptatriggerstrategy,biddingroundafterroundtoincreasepricestounprofitableheightsiftheir
opponentdoesnotcoordinatewiththeminearlierrounds.Thesestrategiesareunrealistic,asno
reasonablebidderwouldgobankrupttopunishanopponent.Variousequilibriumrefinementsseek
toeliminatethisbehavior,suchassequentialequilibrium[KrepsandWilson,1982];developing
MARLalgorithmsthatconvergetotheserefinementswouldbeavaluabledirectionforfuturework.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 19
ACKNOWLEDGEMENTS
ThankstoMarcLanctotandBettySheafortheirtechnicalcontributionsonearlyiterationsof
thiswork,andtoCostaHuang,PaulMilgrom,JulienPerolat,SamuelSokota,andAlbertZuofor
helpfuldiscussions.ThisworkwassupportedinpartbyanNSERCCGS-Dscholarship,andthrough
computationalresourcesandservicesprovidedbyAdvancedResearchComputingattheUniversity
ofBritishColumbia.ThisworkwasdoneinpartwhileseveralauthorswerevisitingtheSimons
InstitutefortheTheoryofComputing.
REFERENCES
MichaelAbramowicz.2020.ModelingSettlementBargainingwithAlgorithmicGameTheory.ResearchPaper2020-80.GWU
LegalStudies.
ThomasAnthony,TomEccles,AndreaTacchetti,J√°nosKram√°r,IanGemp,ThomasC.Hudson,NicolasPorcel,Marc
Lanctot,JulienP√©rolat,RichardEverett,RomanWerpachowski,SatinderSingh,ThoreGraepel,andYoramBachrach.
2022.LearningtoPlayNo-PressDiplomacywithBestResponsePolicyIteration. arXiv:2006.04635[cs.LG]
LawrenceM.Ausubel.2004. AnEfficientAscending-BidAuctionforMultipleObjects. AmericanEconomicReview94,5
(December2004),1452‚Äì1475.
LawrenceM.AusubelandOlegBaranov.2020.Revealedpreferenceandactivityrulesindynamicauctions.International
EconomicReview61,2(2020),471‚Äì502.
LawrenceMAusubel,PeterCramton,andPaulMilgrom.2006.Theclock-proxyauction:Apracticalcombinatorialauction
design.InHandbookofspectrumauctiondesign.MIT,120‚Äì140.
AntonBakhtin,NoamBrown,EmilyDinan,GabrieleFarina,ColinFlaherty,DanielFried,AndrewGoff,JonathanGray,
HengyuanHu,AthulPaulJacob,MojtabaKomeili,KarthikKonath,MinaeKwon,AdamLerer,MikeLewis,AlexanderH.
Miller,SandraMitts,AdithyaRenduchintala,StephenRoller,DirkRowe,WeiyanShi,JoeSpisak,AlexanderWei,DavidJ.
Wu,HughZhang,andMarkusZijlstra.2022.Human-levelplayinthegameofDiplomacybycombininglanguagemodels
withstrategicreasoning.Science378(2022),1067‚Äì1074.
MartinoBanchioandAndrzejSkrzypacz.2022.ArtificialIntelligenceandAuctionDesign.InProceedingsofthe23rdACM
ConferenceonEconomicsandComputation(EC‚Äô22).AssociationforComputingMachinery,NewYork,NY,USA,30‚Äì31.
https://doi.org/10.1145/3490486.3538244
NolanBard,JakobN.Foerster,SarathChandar,NeilBurch,MarcLanctot,H.FrancisSong,EmilioParisotto,Vincent
Dumoulin,SubhodeepMoitra,EdwardHughes,IainDunning,ShiblMourad,HugoLarochelle,MarcG.Bellemare,and
MichaelBowling.2020.TheHanabichallenge:AnewfrontierforAIresearch.ArtificialIntelligence280(2020),103216.
https://doi.org/10.1016/j.artint.2019.103216
DimitrisBertsimasandAlexPaskov.2022. World-classinterpretablepoker. MachineLearning111,8(2022),3063‚Äì3083.
https://doi.org/10.1007/s10994-022-06179-8
MartinBichler,MaximilianFichtl,StefanHeidekr√ºger,NilsKohring,andPaulSutterer.2021. Learningequilibriain
symmetricauctiongamesusingartificialneuralnetworks. NatureMachineIntelligence3,8(2021),687‚Äì695. https:
//doi.org/10.1038/s42256-021-00365-4
MartinBichler,MaxFichtl,andMatthiasOberlechner.2023. ComputingBayes‚ÄìNashEquilibriumStrategiesinAuction
GamesviaSimultaneousOnlineDualAveraging.OperationsResearch(2023).
MartinBichler,PaulR.Milgrom,andGregorSchwarz.2022.TamingtheCommunicationandComputationComplexityof
CombinatorialAuctions:TheFUELBidLanguage.Manag.Sci.69(2022),2217‚Äì2238.
VitorBosshardandSvenSeuken.2021. TheCostofSimpleBiddinginCombinatorialAuctions.InProceedingsofthe
22ndACMConferenceonEconomicsandComputation.AssociationforComputingMachinery,NewYork,NY,USA,157.
https://doi.org/10.1145/3465456.3467609
MichaelBowling,NeilBurch,MichaelJohanson,andOskariTammelin.2015. Heads-uplimithold‚Äôempokerissolved.
Science347,6218(2015),145‚Äì149. https://www.science.org/doi/abs/10.1126/science.1259433
NoamBrownandTuomasSandholm.2018.SuperhumanAIforheads-upno-limitpoker:Libratusbeatstopprofessionals.
Science359,6374(2018),418‚Äì424. https://www.science.org/doi/abs/10.1126/science.aao1733
NoamBrownandTuomasSandholm.2019a. Solvingimperfect-informationgamesviadiscountedregretminimiza-
tion.InProceedingsoftheThirty-ThirdAAAIConferenceonArtificialIntelligenceandThirty-FirstInnovativeAppli-
cationsofArtificialIntelligenceConferenceandNinthAAAISymposiumonEducationalAdvancesinArtificialIntelligence
(AAAI‚Äô19/IAAI‚Äô19/EAAI‚Äô19).AAAIPress,Article225,8pages. https://doi.org/10.1609/aaai.v33i01.33011829
NoamBrownandTuomasSandholm.2019b. SuperhumanAIformultiplayerpoker. Science365,6456(2019),885‚Äì890.
https://doi.org/10.1126/science.aay2400Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 20
MatthewCary,AparnaDas,BenEdelman,IoannisGiotis,KurtisHeimerl,AnnaRKarlin,ClaireMathieu,andMichael
Schwarz.2007.Greedybiddingstrategiesforkeywordauctions.InProceedingsofthe8thACMConferenceonElectronic
Commerce.262‚Äì271.
FCC.2015.ApplicationProceduresforBroadcastIncentiveAuctionScheduledtoBeginonMarch29,2016.https://www.fcc.
gov/document/application-procedures-broadcast-incentive-auction.FCCPublicNoticeDA15-1183(2015).
FCC.2019.Auction102ClockPhaseTechnicalGuide.https://www.fcc.gov/file/14284/download.(2019).
LamprosFlokas,EmmanouilV.Vlatakis-Gkaragkounis,ThanasisLianeas,PanayotisMertikopoulos,andGeorgiosPiliouras.
2020.No-RegretLearningandMixedNashEquilibria:TheyDoNotMix.InProceedingsofthe34thInternationalConference
onNeuralInformationProcessingSystems(NIPS‚Äô20).Article117,12pages.
JohnC.HarsanyiandReinhardSelten.1988.AGeneralTheoryofEquilibriumSelectioninGames.MITPress.
PavithraHarsha,CynthiaBarnhart,DavidParkes,andHaoqiZhang.2010.StrongActivityRulesforIterativeCombinatorial
Auctions.Computers&OperationsResearch37(072010),1271‚Äì1284.
JasonHartford,DevonGraham,KevinLeyton-Brown,andSiamakRavanbakhsh.2018.DeepModelsofInteractionsAcross
Sets.InProceedingsofthe35thInternationalConferenceonMachineLearning(ProceedingsofMachineLearningResearch,
Vol.80),JenniferDyandAndreasKrause(Eds.).PMLR,1909‚Äì1918.
ISED. 2012. Consultation on a Licensing Framework for Mobile Broadband Services (MBS) ‚Äî 700 MHz
Band.https://ised-isde.canada.ca/site/spectrum-management-telecommunications/en/spectrum-allocation/auctions/700-
mhz-2014/consultation-licensing-framework-mobile-broadband-services-mbs-700-mhz-band.(2012). Accessed2024-
02-12.
ISED. 2018. Technical, Policy and Licensing Framework for Spectrum in the 600 MHz Band. https://ised-
isde.canada.ca/site/spectrum-management-telecommunications/sites/default/files/attachments/2022/SLPB-002-
18-600MHz-decision-e.pdf.SpectrumManagementandTelecommunicationsSLPB-002-18(2018). Accessed2024-02-12.
ISED.2021.PolicyandLicensingFrameworkforSpectruminthe3500MHzBand.https://ised-isde.canada.ca/site/spectrum-
management-telecommunications/en/spectrum-allocation/policy-and-licensing-framework-spectrum-3500-mhz-
band.SpectrumManagementandTelecommunicationsSLPB-001-20(2642021). Accessed2024-02-12.
ISED.2022.PolicyandLicensingFrameworkforSpectruminthe3800MHzBand.https://ised-isde.canada.ca/site/spectrum-
management-telecommunications/en/spectrum-allocation/policy-and-licensing-framework-spectrum-3800-mhz-
band.SpectrumManagementandTelecommunicationsSPB-002-22(062022). Accessed2024-02-12.
DavidM.KrepsandRobertWilson.1982.SequentialEquilibria.Econometrica50,4(1982),863‚Äì894. http://www.jstor.org/
stable/1912767
MarcLanctot,EdwardLockhart,Jean-BaptisteLespiau,ViniciusZambaldi,SatyakiUpadhyay,JulienP√©rolat,Sriram
Srinivasan,FinbarrTimbers,KarlTuyls,ShayeganOmidshafiei,DanielHennes,DustinMorrill,PaulMuller,Timo
Ewalds,RyanFaulkner,J√°nosKram√°r,BartDeVylder,BrennanSaeta,JamesBradbury,DavidDing,SebastianBorgeaud,
MatthewLai,JulianSchrittwieser,ThomasAnthony,EdwardHughes,IvoDanihelka,andJonahRyan-Davis.2019.
OpenSpiel:AFrameworkforReinforcementLearninginGames.CoRRabs/1908.09453(2019).arXiv:1908.09453[cs.LG]
http://arxiv.org/abs/1908.09453
MarcLanctot,KevinWaugh,MartinZinkevich,andMichaelBowling.2009.MonteCarlosamplingforregretminimization
inextensivegames.Advancesinneuralinformationprocessingsystems22(2009).
JonathanD.LevinandAndrzejSkrzypacz.2016.PropertiesoftheCombinatorialClockAuction.TheAmericanEconomic
Review106(2016),2528‚Äì2551. https://doi.org/doi:10.1257/aer.20141212
ZunLi,MarcLanctot,KevinR.McKee,LukeMarris,IanM.Gemp,DanielHennes,PaulMuller,K.Larson,YoramBachrach,
andMichaelP.Wellman.2023.CombiningTree-Search,GenerativeModels,andNashBargainingConceptsinGame-
TheoreticReinforcementLearning.ArXivabs/2302.00797(2023).
PaulMilgrom.2000.PuttingAuctionTheorytoWork:TheSimultaneousAscendingAuction.JournalofPoliticalEconomy
108(122000). https://doi.org/10.1086/262118
PaulMilgrom.2004.PuttingAuctionTheorytoWork.CambridgeUniversityPress.
DustinMorrill,RyanD‚ÄôOrazio,RecaSarfati,MarcLanctot,JamesRWright,AmyRGreenwald,andMichaelBowling.2021.
Hindsightandsequentialrationalityofcorrelatedplay.InProceedingsoftheAAAIConferenceonArtificialIntelligence,
Vol.35.5584‚Äì5594.
NeilNewman,KevinLeyton-Brown,PaulMilgrom,andIlyaSegal.2024.IncentiveAuctionDesignAlternatives:ASimulation
Study.ManagementScience. forthcoming.
AlexandrePacaud,AurelienBechler,andMarceauCoupechoux.2023.BiddingefficientlyinSimultaneousAscendingAuctions
withbudgetandeligibilityconstraintsusingSimultaneousMoveMonteCarloTreeSearch. arXiv:2307.11428[cs.GT]
IgnacioPalacios-Huerta,DavidC.Parkes,andRichardSteinberg.2021.CombinatorialAuctionsinPractice.SSRNElectronic
Journal(2021). https://doi.org/10.2139/ssrn.3844338
JulienP√©rolat,BartDeVylder,DanielHennes,EugeneTarassov,FlorianStrub,VincentdeBoer,PaulMuller,JeromeT.
Connor,NeilBurch,ThomasW.Anthony,StephenMcAleer,Romuald√âlie,SarahH.Cen,ZheWang,AudrunasGruslys,Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 21
AleksandraMalysheva,MinaKhan,SherjilOzair,FinbarrTimbers,TobiasPohlen,TomEccles,MarkRowland,Marc
Lanctot,Jean-BaptisteLespiau,BilalPiot,ShayeganOmidshafiei,EdwardLockhart,L.Sifre,NathalieBeauguerlange,
R√©miMunos,DavidSilver,SatinderSingh,DemisHassabis,andKarlTuyls.2022.MasteringthegameofStrategowith
model-freemultiagentreinforcementlearning.Science378(2022),990‚Äì996.
JustinK.Pugh,LisaB.Soros,andKennethO.Stanley.2016.Qualitydiversity:Anewfrontierforevolutionarycomputation.
FrontiersinRoboticsandAI3(2016),40.
ZinoviRabinovich,VictorNaroditskiy,EnricoH.Gerding,andNicholasR.Jennings.2013. ComputingpureBayesian-
Nashequilibriaingameswithfiniteactionsandcontinuoustypes. ArtificialIntelligence195(2013),106‚Äì139. https:
//doi.org/10.1016/j.artint.2012.09.007
FrankRiedelandElmarWolfstetter.2006.Immediatedemandreductioninsimultaneousascending-bidauctions:auniqueness
result.EconomicTheory29,3(2006),721‚Äì726.
JohnSchulman,FilipWolski,PrafullaDhariwal,AlecRadford,andOlegKlimov.2017. ProximalPolicyOptimization
Algorithms.CoRRabs/1707.06347(2017).arXiv:1707.06347 http://arxiv.org/abs/1707.06347
DavidSilver,AjaHuang,ChrisJ.Maddison,ArthurGuez,L.Sifre,GeorgevandenDriessche,JulianSchrittwieser,Ioannis
Antonoglou,VedavyasPanneershelvam,MarcLanctot,SanderDieleman,DominikGrewe,JohnNham,NalKalchbrenner,
IlyaSutskever,TimothyP.Lillicrap,MadeleineLeach,KorayKavukcuoglu,ThoreGraepel,andDemisHassabis.2016.
MasteringthegameofGowithdeepneuralnetworksandtreesearch.Nature529(2016),484‚Äì489.
DavidSilver,ThomasHubert,JulianSchrittwieser,IoannisAntonoglou,MatthewLai,ArthurGuez,MarcLanctot,L.Sifre,
DharshanKumaran,ThoreGraepel,TimothyP.Lillicrap,KarenSimonyan,andDemisHassabis.2017.MasteringChess
andShogibySelf-PlaywithaGeneralReinforcementLearningAlgorithm.ArXivabs/1712.01815(2017).
RichardS.Sutton,DavidMcAllester,SatinderSingh,andYishayMansour.1999.PolicyGradientMethodsforReinforcement
LearningwithFunctionApproximation.InAdvancesinNeuralInformationProcessingSystems,S.Solla,T.Leen,and
K.M√ºller(Eds.),Vol.12.MITPress.
OskariTammelin.2014.SolvingLargeImperfectInformationGamesUsingCFR+. arXiv:1407.5042[cs.GT]
AlexanderTeytelboym,ShengwuLi,ScottDukeKominers,MohammadAkbarpour,andPiotrDworczak.2021.Discovering
Auctions:ContributionsofPaulMilgromandRobertWilson. TheScandinavianJournalofEconomics123,3(2021),
709‚Äì750. https://doi.org/10.1111/sjoe.12441
DavidThompson,NeilNewman,andKevinLeyton-Brown.2017. ThePositronicEconomist:AComputationalSystem
forAnalyzingEconomicMechanisms. ProceedingsoftheAAAIConferenceonArtificialIntelligence31,1(Feb.2017).
https://doi.org/10.1609/aaai.v31i1.10592
DavidR.M.ThompsonandKevinLeyton-Brown.2017.ComputationalAnalysisofPerfect-InformationPositionAuctions.
GamesandEconomicBehavior102(2017),583‚Äì623.
XintongWang,GaryQiuruiMa,AlonEden,ClaraLi,AlexanderTrott,StephanZheng,andDavidParkes.2023.Platform
BehaviorunderMarketShocks:ASimulationFrameworkandReinforcement-LearningBasedStudy.InProceedingsofthe
ACMWebConference2023(Austin,TX,USA)(WWW‚Äô23).AssociationforComputingMachinery,NewYork,NY,USA,
3592‚Äì3602. https://doi.org/10.1145/3543507.3583523
ChristopherJ.C.H.WatkinsandPeterDayan.1992.Q-learning.MachineLearning8,3(1992),279‚Äì292. https://doi.org/10.
1007/BF00992698
MichaelWeiss,BenjaminLubin,andSvenSeuken.2017.SATS:AUniversalSpectrumAuctionTestSuite.InProceedingsof
the16thConferenceonAutonomousAgentsandMultiAgentSystems.S√£oPaulo,Brazil,51‚Äì59.
MichaelP.Wellman.2006.Methodsforempiricalgame-theoreticanalysis.InAAAI,Vol.980.1552‚Äì1556.
StephanZheng,AlexanderTrott,SunilSrinivasa,DavidCParkes,andRichardSocher.2022.TheAIEconomist:Taxation
policydesignviatwo-leveldeepmultiagentreinforcementlearning.Scienceadvances8,18(2022),eabk2607.
MartinZinkevich,MichaelJohanson,MichaelBowling,andCarmeloPiccione.2007.RegretMinimizationinGameswith
IncompleteInformation.InAdvancesinNeuralInformationProcessingSystems,J.Platt,D.Koller,Y.Singer,andS.Roweis
(Eds.),Vol.20.CurranAssociates,Inc.
A COMPUTATIONALENVIRONMENT
Ourexperimentswereperformedontwodifferentcomputeclusters.Ourfirstclusterconsisted
ofnodesequippedwith322.10GHzIntelXeonE5-2683v4CPUswith40960KBcacheand96GB
RAM.Oursecondclusterconsistedof16-coremachineswithIntelSilver4216CascadeLake2.1GHz
processorsand96GBRAM.Jobswerescheduledsuchthateachrunhadaccessto4CPUsand20
GBofRAM.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 22
B CLOCKAUCTIONS
Inthisappendix,wegiveamoreformaldescriptionoftheclockauctiongamesthatweimplemented.
LetùëÅ bethenumberofbiddersandùëÄbethenumberofserviceareas.Eachserviceareaùëócontains
ùëû identicallicensesforsale.10Theclockauctionproceedsoveraseriesofroundsùë°,beginningwith
ùëó
ùë° =1.Ineachroundùë°,allbiddersobserveastart-of-roundpriceùëÉ
ùëó,ùë°
andaclockpriceùëÉ
ùëó,ùë°
¬∑ùëéforeach
productùëó,whereùëéistheclockincrement(e.g.,5‚Äì20%).(Thesepricesareanonymous‚Äîi.e.,allbidders
facethesameprice.)Then,eachbidderùëñsimultaneouslysubmitsabidùêµ ùëñ,ùë°,ùëó ‚àà {0,1,...,ùëû ùëó}foreach
product ùëó,representingtheirdemandforeachproduct.Afterthebidsaremade,eachproducthas
anaggregatedemandùëç
ùëó,ùë°
=(cid:205) ùëñùêµ ùëñ,ùëó,ùë°.Ifnoproductisoverdemanded(i.e.,ùëç
ùëó,ùë°
‚â§ùëû
ùëó
forallproducts
ùëó),thentheauctionends,witheachbidderùëñ winningùêµ licensesofproduct ùëó,payingùëÉ for
ùëñ,ùë°,ùëó ùë°,ùëó
eachone.Otherwise,thepriceofeachoverdemandedproductincreases,withthestart-of-round
pricebeingsettothepreviousclockprice,andtheauctioncontinuesontothenextround.
Typically,auctionsincludeanactivity rule.Therulerestrictsthesetoflegalbidsbasedona
bidder‚Äôsbidhistorywiththeaimofdiscouragingstrategicbidding.Whiletherearemanyvariants,
asimpleandcommonruleistoassigneachproduct ùëó anumberofeligibilitypointsùëí ;then,each
ùëó
bidder‚Äôstotalactivity(cid:205) ùëóùêµ
ùëñ,ùë°,ùëó
¬∑ùëí
ùëó
mustbenon-increasing.Thisruledisallowsbiddersfrombidding
forfewitemsearlyintheauctionandrapidlyexpandingtheirbidlater.
Auctionscanallowforintra-roundbidding.Suchaprovisionallowsbidderstoexpresschangesin
theirdemandbetweenclockincrements(e.g.,ifthestart-of-roundpriceis$100andtheclockprice
is$120andabidderholdstwolicensesinaregion,theymaybidtodroptoonelicenseat$110.If
thisdropcausessupplytoequaldemand,thenewstart-of-roundpricewouldbe$110.).Intra-round
biddingallowsanauctioneertosetlargerclockincrements.Perhapsourmostsignificantmodeling
simplificationisthatwedonotmodelintra-roundbidding.Instead,weassumethatagentscanonly
bidattheclockprice.Thisrestrictionrequirestheclockincrementsinourmodeledgamestobe
keptrelativelysmall.
The clock auction includes a rule that prohibits demand from dropping ever dropping from
abovesupplytobelowsupply.Thisguaranteesthatonceaproducthaseverhadaroundwhere
demandwasatleastsupply,itwillbesold.Inpractice,thisrequirestheauctioneertorejectsome
bids.Thebidprocessingalgorithmworksbyplacingtuplesofrequestsoftheform(bidder,product,
changeindemand)intoaqueue.Theserequestsarethenprocessedinqueueordertothedegree
possible(arequestmayonlybepartiallyfulfilledifeitherthereisnotenoughdemandtoallow
furtherdropbids,orthebidderdoesnothavesufficientactivitytoallowapickupbid).Ifarequest
isonlypartiallyfulfilled,itisreinsertedintothequeue.Thealgorithmcontinuesapplyingthese
requestsuntilitisnotabletoapplyanyadditionalrequestsinthequeue.
C VALUESAMPLINGDETAILS
Removing uninteresting games. Our game sampler rejects games that we deem strategically
uninteresting.Werequirethatnobidder,inalltyperealizations,isallocatednothingunderthe
utility-maximizingallocationatopeningprices.Wesolvefortheutility-maximizingallocation
usingaMIP.Suchabidderishopelesslyweak,tendingtoslowdownsimulationsfornoadded
benefit.
Infeasiblegames. Somecriteriaensuredthatwegeneratedgamesthatwewerecapableofsolving.
First,asaproxymeasureforthelengthoftheauction,wecomputedthenumberofroundsitwould
takefortheauctiontoconcludeinasimulationinwhicheachbidderbidsforitsprofit-maximizing
bundleatstart-of-roundpricesineveryround.Werejectedauctionslongerthan20suchrounds.
10Arealisticauction,e.g.Canada‚Äôs600MHzauctionhadùëÅ = 10andùëÄ= 15.Canada‚Äôs3500MHzauctionhadùëÄmuch
higher,inthehundreds).Typicalvaluesforùëûùëó rangefrom1to10.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 23
Fig.7. Anexamplevalueprofileforagamewithtwobiddersandfourtypes.Fractionalnumbersoflicenses
onthex-axiscorrespondtobundleswithencumberedlicenses.
Secondly,wererantheabovesimulation,thistimeincrementingthepriceonasingle,randomly
chosenproductamongthosethatwereoverdemandedineachround.Thisisacrudemodelof
theworst-caseauction(fromalengthperspective),inwhicheachroundpricesonlyincrement
onasingleproduct.Werejectedsimulationsthattookonaveragelongerthan25suchroundsto
conclude.Lastlyfor2-playergames,werequiredMCCFRtobeabletorunatleast25iterationsper
second.Thesecheckswereallbasedonthedrop-by-playerrules.
Changesfor3-playergames. Wemadeseveralsmallchangestothevaluemodelforthe3-player
gamesinSection4.3.ForSATSparameters,biddershadmarketsharessampleduniformlyfrom20%
to30%andvaluespersubscribersampleduniformlyfrom$35millionto$45million.Thekeypoints
ontheirsigmoidalvaluefunctionwereplacedat¬±10%fromtheirmarketshare.Wealsoadjusted
therejectionsamplerrequirementthatMCCFRbeabletorun25iterationspersecond,loosening
thisthresholdto1iterationpersecond.
Examplevaluefunction. WeshowansamplevaluefunctioninFigure7.
D PPOHYPERPARAMETERS
Ourconfigurationsweresampledasfollows:
def sample_config ():
config = dict()
config[ 'steps_per_batch '] = int(np.random.choice([64, 128]))
config[ 'num_minibatches '] = int(np.random.choice([4, 8]))
config[ 'update_epochs '] = int(np.random.choice([4, 8, 16]))
config[ 'learning_rate '] = float(np.random.choice([3e‚àí5, 6e‚àí6, 9e‚àí5, 1e‚àí4, 3e‚àí4]))
config[ 'gae'] = bool(np.random.choice([True, False]))
config[ 'anneal_lr '] = bool(np.random.choice([True, False]))
config[ 'gae_lambda '] = float(np.random.uniform(0.94, 1.))
config[ 'clip_coef '] = float(loguniform.rvs(0.0003, .3, size=1)[0])
config[ 'clip_vloss '] = bool(np.random.choice([True, False]))
config[ 'entropy_coef '] = float(np.random.choice([1e‚àí4, 1e‚àí5, 1e‚àí6, 0, 3e‚àí5, 3e‚àí6]))Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 24
config[ 'value_coef '] = float(loguniform.rvs(0.1 , 1.3, size=1)[0])
config[ 'num_envs'] = int(np.random.choice([4, 8, 16]))
config[ 'normalize_advantages '] = bool(np.random.choice([True, False]))
config[ 'optimizer '] = random.choice([ 'adam' , 'rmsprop' , 'sgd'])
optimizer_kwargs = dict()
if config[ 'optimizer '] == 'adam':
beta1 = float(np.random.uniform(0.8 , .9))
beta2 = float(np.random.uniform(0.8 , .999))
optimizer_kwargs[ 'betas '] = [beta1 , beta2]
config[ 'optimizer_kwargs '] = optimizer_kwargs
config[ 'max_grad_norm'] = float(np.random.uniform(0.1 , 1))
agent_kwargs = dict()
agent_fn = base_config[ 'agent_fn '].lower()
if agent_fn == 'auctionnet ':
agent_kwargs[ 'activation '] = str(np.random.choice([ 'relu ' , 'tanh ']))
agent_kwargs[ 'hidden_sizes '] = random.choice([
[32, 32, 32], [64, 64, 64], [128, 128, 128],
])
agent_kwargs[ 'add_skip_connections '] = bool(np.random.choice([True, False]))
agent_kwargs[ 'use_torso '] = bool(np.random.choice([True, False]))
elif agent_fn == 'ppoagent ': # MLP
hidden_sizes = random.choice([
[64, 64], [128, 128], [256, 256],
[64, 64, 64], [128, 128, 128], [256, 256, 256],
])
activation = str(np.random.choice([ 'relu ' , 'tanh ']))
agent_kwargs[ 'actor_hidden_sizes '] = hidden_sizes
agent_kwargs[ 'critic_hidden_sizes '] = hidden_sizes
agent_kwargs[ 'actor_activation '] = activation
agent_kwargs[ 'critic_activation '] = activation
config[ 'agent_fn_kwargs '] = agent_kwargs
return config
OurfinalPPOconfigurationisasfollows:Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 25
Variable Value
0 Activation relu
1 AddSkipConnections True
2 AnnealLR True
3 Architecture AuctionNet
4 ClipCoef 0.018894
5 ClipVloss False
6 EntropyCoef 0.000030
7 Gae False
8 GaeLambda 0.985872
9 Gamma 1.000000
10 HiddenSizes [32,32,32]
11 LearningRate 0.000090
12 MaxGradNorm 0.526474
13 NormalizeAdvantages False
14 NumAnnealingUpdates ‚Äî
15 NumEnvs 16
16 NumMinibatches 8
17 Optimizer adam
18 OptimizerBetas [0.8032349345217956,0.8653019218632017]
19 StepsPerBatch 64
20 TargetKL ‚Äî
21 TrackStats True
22 UpdateEpochs 8
23 UseTorso True
24 ValueCoef 0.609288
E ADDITIONALRESULTSGregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 26
Fig.8. AuctionoutcomesusingMCCFRon2-playergameswith1to7types.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 27
Fig.9. AuctionoutcomesusingPPOon2-playergameswith1to7types.Gregd‚ÄôEon,NeilNewman,andKevinLeyton-Brown 28
Fig.10. Auctionoutcomesunderstraightforwardbiddingon2-playergameswith1to7types.