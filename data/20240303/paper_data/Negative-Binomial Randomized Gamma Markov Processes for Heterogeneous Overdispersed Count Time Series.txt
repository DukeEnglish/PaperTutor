Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous
Overdispersed Count Time Series
RuiHuang1, SikunYang1, HeinzKoeppl2
1SchoolofComputingandInformationTechnology,GreatBayUniversity
2DepartmentofElectricalEngineeringandInformationTechnology,TechnischeUniversita¨tDarmstadt
Abstract linkthecountobservationstolatentcontinuousdynamicsto
modelcounttimesequences. Nonetheless,theextendedrank
Modeling count-valued time series has been re-
likelihoodfunctionscannotfaithfullycaptureburstydynam-
ceiving increasing attention since count time se-
ics underlying real-world count sequences. Meanwhile, the
riesnaturallyariseinphysicalandsocialdomains.
extended rank likelihood functions often require an approx-
Poisson gamma dynamical systems (PGDSs) are
imate inference scheme, and thus scale poorly with high-
newly-developed methods, which can well cap-
dimensional count sequences, such as single-cell RNA se-
ture the expressive latent transition structure and quencing data [Chandra et al., 2023]. Notably, some re-
bursty dynamics behind count sequences. In
cent works [Acharya et al., 2015; Schein et al., 2016a;
particular, PGDSs demonstrate superior perfor-
Schein et al., 2016b; Schein et al., 2019] model sequen-
mance in terms of data imputation and predic-
tial count observations using gamma Poisson family distri-
tion, compared with canonical linear dynamical
butions. More specifically, [Acharya et al., 2015] devel-
system (LDS) based methods. Despite these ad-
ops a gamma Markov process to capture continuous dy-
vantages, PGDScannotcapturetheheterogeneous
namics underlying count-valued sequences. In particular,
overdispersed behaviours of the underlying dy-
the number of latent factors behind high-dimensional count
namic processes. To mitigate this defect, we
data, can be appropriately determined by the gamma pro-
propose a negative-binomial-randomized gamma
cess prior, in a Bayesian non-parametric manner. Following
Markov process, which not only significantly im-
the success of [Acharya et al., 2015], Schein et al. [2016a]
provesthepredictiveperformanceoftheproposed
study a Poisson gamma dynamical system, in which a tran-
dynamicalsystem,butalsofacilitatesthefastcon-
sition kernel is designed to capture how the latent dimen-
vergenceoftheinferencealgorithm. Moreover,we
sions interact with each other to model complicated ob-
developmethodstoestimatebothfactor-structured
served dynamics. Another appealing aspect of the Poisson
and graph-structured transition dynamics, which
gamma dynamic model is that the posterior simulation can
enableustoinfermoreexplainablelatentstructure,
be performed using a tractable-yet-efficient Gibbs sampling
compared with PGDSs. Finally, we demonstrate
algorithm via Poisson-Logarithm data augmentation strat-
theexplainablelatentstructurelearnedbythepro-
egy [Zhou and Carin, 2012; Zhou and Carin, 2015]. Hence,
posed method, and show its superior performance
the Poisson gamma dynamic models [Acharya et al., 2015;
inimputingmissingdataandforecastingfutureob-
Schein et al., 2016a; Schein et al., 2019] are in particular
servations,comparedwiththerelatedmodels.
well-fittedtoimputemissingentries,topredictfutureunseen
observationsandtoestimateuncertainties.
1 Introduction
Despite these advantages, these models still cannot well
Counttimesequences,naturallyariseinmanydomainssuch capture the heterogeneous overdispersion effects of the la-
as text mining [Blei and Lafferty, 2006; Wang et al., 2008; tent dynamic processes behind count observations. For in-
Rudolph and Blei, 2018; Acharya et al., 2018; Dieng et al., stance, international event data, usually consists of multiple
2019], cell genomic analysis [Levitin et al., 2019; Tong et latent dynamic processes, which often change rapidly with
al., 2020; Jones et al., 2023], population movement fore- the different magnitudes [King, 2001; Stewart, 2014]. To
casting [Sheldon et al., 2013; Stuart and Wolfram, 2020; capturesuchheterogeneousoverdispersedbehaviours,wede-
Roy and Dunson, 2020], and etc. Modeling count se- velopanegative-binomial-randomizedgammaMarkovchain
quences has been drawing increasing research attention be- structure, which not only greatly enhances the model flexi-
cause these real-world count data usually exhibit bursty and bility, butalsofacilitatesthefastconvergenceofthederived
overdispersedbehaviours,whichcannotbewell-capturedby Gibbssamplingalgorithms. Moreover,thetransitiondynam-
canonicallineardynamicalsystems(LDSs)[Ghahramaniand ics behind real-world high-dimensional count data, are of-
Roweis, 1998]. In addition, some previous works use ex- ten sparse, and exhibit a certain amount of graph structure.
tended rank likelihood functions [Han et al., 2014] which Hence, we propose to learn the graph-structured transition
4202
beF
92
]GL.sc[
1v59981.2042:viXradynamicsusingrelationalgammaprocesses[Zhou,2015].To whereRG1istherandomizedgammadistributionofthefirst
thebestofourknowledge,thisisthefirstattempttolearnthe type. ThemarginalexpectationandvarianceofthePRGMC
latentgraph-structuredtransitiondynamicsunderthePoisson isE[θ(t) |θ(t−1),Π]=Πθ(t−1)+ϵ(θ)τ−1and
0
gammadynamicalsystem. Var[θ(t) | θ(t−1),Π] = 2Πθ(t−1)τ−1 + ϵ(θ)τ−2, respec-
Themaincontributionsofthepaperinclude:1)Anegative- 0
tively.
binomial-randomizedgammaMarkovprocess(NBRGMP)is
proposed to estimate the heterogeneous overdispersion ef-
fects of the latent dimensions underlying sequential count 3 TheProposedModel
observations; 2)Relationalgammaprocessesarethoroughly
Inthissectionwewillintroducethenovelnegative-binomial-
studied to learn both factor-structured and graph-structured
randomized gamma Markov chain structure to capture the
transition dynamics, which renders the estimated latent
heterogeneous overdispersion effects of the latent dimen-
structure more explainable, compared with transition struc-
sions behind count data. Then we shall describe how
ture inferred using non-informative priors; 3) Although the
to learn explainable latent transition structure with rela-
proposed NBRGMP and its factor-structured and graph-
tional gamma processes. The proposed negative-binomial-
structured extensions are intractable, simple-yet-efficient
randomizedgammadynamicalsystemisdefinedby
Gibbs sampling algorithms are developed via Negative-
binomial data augmentation strategies to perform inference;
4)Extensive experiments are conducted to illustrate the ex- n(t) ∼Pois(δ(t)(cid:88)K λ ϕ θ(t)), (3)
v k=1 k vk k
plainabletransitionstructurelearnedbytheproposedmodel.
We demonstrate the superior performance of the proposed where δ(t) is a nonnegative multiplicative term capturing
methodinmissingdataimputationandfuturesnapshotfore- time-dependent bursty dynamics. We place a gamma prior
casting,withseveralrelatedworks. on δ(t) as δ(t) ∼ Gam(ϵ ,ϵ ), and let δ(t) = δ if the
0 0
generative process (Eq. 3) is stationary over time. Here
2 Preliminary
ϕ = (ϕ ,ϕ ,...,ϕ )T denotes the loading coefficient
k 1k 2k Vk
Suppose we have a sequentially-observed count data over ofk-thlatentcomponent, andλ denotestheweightofk-th
k
timeinterval[0,T]specifiedbyN=(n ,...,n )TofVdi- latentcomponent. Toensuremodelidentifiability,werequire
1 V
(cid:80)
mensions,wheren v = (n( v1),...,n( vT))T withn( vt) denoting vϕ vk = 1 and thus have a Dirichlet prior over ϕ k given
thev-thobservationattimet.ThePoissongammadynamical byϕ k ∼Dir(ϵ 0,...,ϵ 0). Morespecifically,wedrawλ k from
system[Scheinetal.,2016a]modelsthecountn( vt)as a hierarchical prior as λ
k
∼ Gam(ϵ K0(λ) + g k,β), in which
n(t) ∼Pois(δ(t)(cid:88)K ϕ θ(t)), (1) g k ∼ Pois( Kγ). We specify gamma priors over γ and β as
v k=1 vk k γ ∼ Gam(ϵ 0,ϵ 0),β ∼ Gam(ϵ 0,ϵ 0). NotethatasK → ∞,
whereθ(t)capturesthestrengthoflatentcomponentkattime the summation of the weight expectation remains finite and
t,andϕk
vk
representstheinvolvementdegreeofdimensionv fixed,i.e.,(cid:80)∞ k=1E[λ k]=β−1(ϵ( 0λ)+γ). Hence,thishierar-
in latent component k. To model the underlying dynamics, chicalpriorenablesustoeffectivelyestimateafinitenumber
the PGDS assumes that the latent components evolve over oflatentfactorsthatarerepresentativetocapturethetemporal
timeaccordingtoagammaMarkovchainstructureas dynamics.
θ k(t) ∼Gam(τ 0(cid:88)K k2=1π kk2θ k(t 2−1),τ 0), (2) 3.1 MNe ag ra kt oiv ve P-B ri on co em ssi ea sl .RandomizedGamma
wherethelatentcomponentsθ(t−1) = (θ(t−1),...,θ(t−1))T
1 K
evolveovertimethroughthetransitionmatrixΠ. Theθ(t−1) To capture the heterogeneous overdispersed behaviors of
k the latent dimensions behind count sequences, we intro-
captureshowstronglythek-thlatentcomponentactivatesat
duce a negative-binomial randomized gamma Markov pro-
timet−1,andπ modelshowstronglythek -thcomponent
kk2 2
cess(NBRGMP)specifiedby
θ(t−1) attimet−1affectthek-thcomponentθ(t) attimet.
k2 k
Eq.2naturallydefinesagammaMarkovchainstructure. The θ(t) ∼Gam(ϵ(θ)+h(t),τ),
expectationandvarianceofthegammaMarkovchaincanbe k 0 k
calculatedrespectivelyasE[θ(t) |θ(t−1),Π]=Πθ(t−1)and h(t) ∼NB(τ(cid:88)K π θ(t−1), ψ ), (4)
Var[θ(t) | θ(t),Π] = (Πθ(t−1))τ 0−1, where τ
0
controls the k k2=1 kk2 k2 1+ψ
varianceofθ(t).
Scheinetal.[2019]furtherdevelopaPoisson-randomized wherewesetθ k(0) = λ k, andθ k(t) isgammadistributedwith
gammaMarkovchain(PRGMC)structurespecifiedby shapeparameterϵ(θ)+h(t) whereϵ(θ) ≥ 0,andtheratepa-
0 k 0
θ(t) ∼Gam(ϵ(θ)+h(t),τ), h(t) ∼Pois(τ(cid:88) π θ(t−1)). rameterτ. Here,insteadofspecifyingaPoissonpriorasdid
k 0 k k kk2 k2 in [Scheinetal.,2019],wedrawtheintermediatelatentstate
k2 h(t)fromanegative-binomialdistributiontoenhancetheflex-
BymarginalizingoutthePoissonlatentstatesh( kt),wehave ibk
ilityofθ(t),whichenableustoestimatetheheterogeneous
acontinuous-valueddynamicalsystemgivenby k
overdispersedbehavioursofthelatentdynamicprocesses.
θ k(t) ∼RG1(ϵ( 0θ),τ(cid:88) k2π kk2θ k(t 2−1),τ), Morespecifically,themarginalexpectationandvarianceofFigure 2: The hierarchical structure of the NBRGMP. The red ar-
rowsindicateintractabledependenciesthatrequiredataaugmenta-
tionschemesforposteriorinference.
Fig. 2 shows the graphical representation of the devel-
Figure 1: The realizations of the negative-binomial-randomized
g sea tm tom 0a aM na drk 1o ,v rep spro ec ce tis vs ee ls y.d Tefi hn ee id nii tn ialE vq a.4 lu. esH oe fre thϵ e( 0θ N) Ba Rnd GMτ Pw se ir ne o ispe ad ppN roB xR imG aM telP y. cW hah re an cteτ r(cid:80) izek d2 bπ ykk P2θ ok( it s2− (1 τ) (cid:80)→ π∞, t θh (e t−h 1)( kt ))
.
(a)and(b),weresetto1,(c)and(d)weresetto1000,andthechains Hence,bymarginalizingthePoissondistψ ributk e2 dlak tk e2 ntk2 states
weresimulateduntilt=50.Eachsubplotcontainstenindependent
h(t)fromEq.4,thenegative-binomialrandomizedgammady-
realizations. k
namical system can be equivalently represented by random-
izedgammadistributionofthefirsttypeas
theNBRGMPcanbecalculatedbyiterationas
θ(t) ∼RG1(ϵ(θ), τ (cid:88) π θ(t−1),τ).
E[θ(t) |θ(t−1)]=ϵ(θ)τ−1+ Πθ(t−1) , k 0 ψ k2 kk2 k2
0 ψ
(1+2ψ)Πθ(t−1)
Var[θ(t) |θ(t−1)]=ϵ(θ)τ−2+ , 3.2 Factor-structuredTransitionDynamics
0 ψ2τ
We first propose to learn the latent factor structure behind
respectively. We note that both the concentration parame- transition dynamics. To that end, we specify a hierarchical
ter τ and hyperparameter ϵ(θ) appear in the additive term of Dirichlet prior over π as π ∼ Dir(a ,...,a ),where
0 k k 1k Kk
theexpectationandvariance,whichcanbeconcealedbylet- a =(a ,...,a )Tisthehyper-parameter. Ourgoalhere
k 1k Kk
ting ϵ(θ) = 0. The hyperparameter ψ plays a crucial role in is to capture the correlation structure between the latent di-
0
controllingthevarianceoftheNBRGMP.Morespecifically, mensionsofthetransitionkernel. Thus,wemodelthehyper-
whenψ ∈(0,1)thevaluesofθ(t)willfluctuatedramatically parameterA=[a k1k2]K k1,k2 usingaPoissonfactormodelas
becauseofitslargeexpectationandvariance. Whenψ = 1,
(cid:88)C
the expectation of the NBRGMP will be the same with the a ∼Pois( m r m ),
PRGMC (as discussed in Sec.2), while the variance of the
k1k2
c=1
k1c c k2c
NBRGMPwillbethreetimesofthevarianceofthePRGMC, where r is the weight of c-th latent factor, and m cap-
c kc
whichthusallowstheproposeddynamicalsystemtocapture tures how strongly k-th component associate with c-th fac-
reasonable h √eterogeneous overdispersed behaviors. When tor. Naturally, k 1-th component interact with k 2-th compo-
ψ ∈ (1,1+ 2),theexpectationoftheNBRGMPwilltend
nent through the weight
(cid:80)C
m r m . To ensure the
tobesmallercomparedwiththeexpectationofthePRGMC, c=1 k1c c k2c
latent factor to be nonnegative, we draw the factor r , and
c
whichwillbemoresuitabletocapturesparsecounts. Mean-
factorloadingm fromthepriorsspecifiedby
kc
while,thevarianceoftheNBRGMPstillallowsustocapture
√
r
alimitedrangeofoverdispersioneffects.Ifψ ≥1+ 2,both m ∼Gam(aˆ ,ˆb ), r ∼Gam( 0,c ),
expectationandvarianceconvergetozerosasψgoestoinfin- kc k k c C 0
ity. Fig.1plotstherealizationsoftheNBRGMPbyvarying
respectively. Here, C isthemaximumnumberoflatentfac-
theparameterψ. Notethatthenegative-binomialdistributed
tors. As C → ∞, the weights of the latent factors {r }C
l Pa ote isn st os nta mte ixh tu( k rt) eac san be equivalently drawn from a gamma- a Gnd =the (cid:80)fa ∞ctor rlo δading fro{ mm c a}C c gac man mabe pc roo cn es sid ser Ged aPa (s Ga d ,c crawc
),
c=1 c mc 0 0
h(t) ∼Pois(hˆ(t)), hˆ(t) ∼Gam(τ(cid:88) π θ(t−1),ψ). whereG 0 denotesthebasemeasureoverthemetricspaceΩ,
k k k k2 kk2 k2 andc 0theconcentrationparameter[Ferguson,1973].3.3 Graph-StructuredTransitionDynamics
Forhigh-dimensionalcountsequences,theunderlyingtransi-
tion dynamics are often sparse and exhibit a certain amount
ofgraphstructure. Hence,wefurtherstudytolearnthelatent
graph-structured transition kernel behind count time series,
usingrelationalgammaprocessprior. Inparticular,wesam-
ple the transition parameter π from a hierarchical Dirich-
k
letprior,asπ ∼ Dir(a ,...,a ). Tointroduceasparse
k 1k Kk
graph-structuredtransitionkernel,wemodelthematrixofthe
hyper-parameter A = [a ]K as A = D ⊙ Z,where
k1k2 k1,k2
D = [d ]K denotes the matrix of the nonnegative
k1k2 k1,k2
hyper-parameters, and Z = [z ]K is a binary mask.
k1k2 k1,k2
More specifically, we consider the dimensions of the transi-
tionkernelasvertices,andthenon-zerotransitionbehaviours
asgraphedges.Naturally,wecancapturethesparsestructure
ofthetransitionkernelΠusingagraph. AsshowninFig.3,
foreachpairoftwoverticesiandj, b = 1meansthatthe
ij
transitionprobabilityfromi-thcomponenttoj-thcomponent
isnon-zero,andviceversa.Inparticular,wemodelthebinary
maskZusingrelationalgammaprocessesas
Figure3:Thegraphstructureofthelatentdimensionsofthetransi-
(cid:88)C tionkernelbehindsequentialcountobservations.
z ∼Ber[1−exp( m r m )],
k1k2
c=1
k1c c k2c
wherer canbeconsideredastheweightoflatentcommunity processwhichcancaptureacertainamountofburstydynam-
c
c, and m measures how strongly k-th vertex (the dimen- ics, and thus demonstrates advantages over gamma Markov
kc
sionofthetransitionkernel)relatetoc-thlatentcommunity, processes. [Virtanen and Girolami, 2020] studies a second
as illustrated in Fig. 3. Note that the binary mask Z can be type of gamma Markov chain structure via the scale pa-
equivalentlydrawnviatheBernoulli-Poissonlinkfunctionas rameter of the latent gamma states, which demonstrate bet-
ter stationary property over the gamma Markov chain pro-
(cid:88)C
z ∼δ(w ≥1), w ∼Pois( m r m ). posed by [Acharya et al., 2015]. [Filstroff et al., 2021] re-
k1k2 k1k2 k1k2
c=1
k1c c k2c
centlyprovidesathoroughsurveyonthestudiesofthedevel-
To ensure the model explainability, we restrict r c and m kc oped gamma Markov processes, and evaluates these models
to be nonnegative, and thus place Gamma priors over these through standard tasks including data smoothing and fore-
twoparametersasm kc ∼ Gam(aˆ k,ˆb k),r c ∼ Gam(r C0,c 0), casting. [Han et al., 2014] first tries to capture sequential
respectively. As we discussed in Sec 3.2, this hierarchical count observations using linear dynamical systems, via the
gammapriorcanbeconsideredasadrawG =
(cid:80)∞
c=1r cδ mc extend rank likelihood function. [Linderman et al., 2017]
from a gamma process GaP(G 0,c 0). In particular, we call proposes to learn switching behaviors of sequential data us-
thisBayesiannon-parametricpriortherelationalgammapro- ingrecurrentlineardynamicalsystems(rLDS).[Nassaretal.,
cess,asagraph-structurecanbenaturallyinduced. Thenon- 2018] further develops a tree-structured extension of rLDS,
negativehyper-parametersD = [d k1k2]K
k1,k2
aredrawnfrom with multi scale resolution. [Chen et al., 2020] extends the
agammadistributionasd ∼Gam(ϵ ,ϵ ). Poisson gamma dynamical systems to learn non-stationary
k1k2 0 0
Theproposedgammadynamicalsystemsarenotfullycon- transition dynamics behind count time series. Some efforts
jugate. Nonetheless, tractable-yet-efficient Gibbs sampling are also dedicated to developing Bayesian deep models to
algorithms are developed to perform posterior simulation capturecountsequences.[Ganetal.,2015]developsatempo-
via negative-binomial data augmentation strategies [Zhou, ralsigmoidbeliefnetworkforcounttimeseries.[Guoetal.,
2016a]. Thefullderivationoftheinferenceprocedureispre- 2018] proposes deep Poisson-dynamical systems to capture
sentedinthesupplementarymaterial. long-rangetemporaldependencies.
4 RelatedWork 5 Experiments
Modeling sequentially observed count sequences has been We evaluate the proposed relational gamma process dynam-
receiving growing interests in recent years. Here we dis- ical systems, and compare it with closely-related methods,
cuss several types of methods closely related to our stud- usingbothsyntheticandreal-worldcountdata.
ies. [Acharya et al., 2015] first studies the gamma Markov Real-world data. We conducted the experiments with the
processonsequentiallycountsequences, inwhichthelatent following real-world datasets: (1) Integrated Crisis Early
statesevolveindependentlyovertime. [Scheinetal.,2016a] WarningSystem(ICEWS)datasetcontainsthecountnum-
tries to capture the excitations among the latent gamma berof6,000pairwiseinteractionsbetween233countriesover
Markov processes using a transition structure. [Schein et 365 days. By screening out 4,800 dimensions where the
al.,2019]investigatesaPoisson-randomizedgammaMarkov sample sparsity exceeds 99%, we used a subset of ICEWFigure 4: Negative-binomial-randomized gamma dynamical systems (NBRGDSs) demonstrate strong ability in capturing heterogeneous
overdispersioneffects,andthusachievesfasterconvergence(a),lowestmeanabsoluteerror(b)andmeanrelativeerror(c),comparedwith
theotherrelatedbaselines. Thestationaryandnon-stationarygenerativeprocessi.e. δ(t) =δandδ(t),denotedassolidlineanddottedline,
respectively.
data which contains V = 1,200 dimensions, and T = 365 thosedimensionswithlargervariation/expectationratio. We
timesteps; (2)Last.fmcontainsthelisteninginformationof present the result for the setting L = 300. We treated the
7,071musicartistsover51months,wherewehaveT = 51 80 percent of the data as the training set, and the remaining
timesteps,andV =7,071dimensions;(3)EarthquakeRe- 20percentasthetestset. Then,wetrainedallthecompared
portsDatabase(EQDB):recordsmorethan120,000earth- modelswiththetrainingset,andevaluatedthemodelperfor-
quake reports over 15,000 earthquakes whose epicenters in mance using the test set. In the experiments, we used mean
the United States and nearby U.S. territories from 1928 to absoluteerror(MAE)andmeanrelativeerror(MRE)toeval-
1985. We created a count matrix where each column repre- uatethemodelperformanceinfittingcountsequences:
sents a month and each row represents a state. The EQDB
V T
used in the experiments, contains T = 696 time steps, and 1 (cid:88)(cid:88)
MAE= |n(t)−nˆ(t)|,
V =64dimensions. (4)COVID-19containsthedailydeath VT v v
tollinthefiftystatesandWashingtonDCoftheUnitedStates, v=1t=1
from March 2020 to March 2021. We have T = 365 time 1 (cid:88)V (cid:88)T |n( vt)−nˆ( vt)|
MRE= ,
steps,andV =51dimensions. VT 1+n(t)
v=1t=1 v
Baselines. In the experiments we compared the predictive
of the proposed models with (1) the gamma process dy- where n(t) and nˆ(t) denotes the ground true value and es-
v v
namic Poisson factor analysis (GaP-DPFA) [Acharya et al., timated value of dimension v at time t, respectively. They
2015], in which the gamma Markov chain evolves indepen- differ because MRE considers the relative magnitude of the
dently over time; (2) the Poisson-gamma dynamical system errorsinrelationtotheactualvalues,takingintoaccountthe
(PGDS) [Schein et al., 2016a], in which a transition ker- scale of the data, while MAE simply measures the absolute
nel is used to capture the excitations among latent gamma magnitude of the errors without considering the data scale.
Markovchains;(3)thePoisson-randomizedgammadynami- Fig. 4 shows the results of the compared models averaged
calsystem(PRGDS)[Scheinetal.,2019]wherethePoisson- overtenrandomtraining-testingrepeats.
randomizedgammaMarkovchainstructurecancaptureacer- AsshowninFig.4(a),NBRGDShasstartedtoconvergeto
tainamountofburstydynamics. itssteadystatesafteralmost102iterations,whilebothPGDS
We denote the proposed negative-binomial-randomized and PRGDS start to converge until 103 iterations. Fig.4 (b)
gamma dynamical system as NBRGDS. The proposed and (c) compares the mean absolute errors and mean rela-
NBRGDSwithfactor-structuredpriorimposedoverthetran- tive errors of the compared models, respectively. Overall,
sition kernel, is denoted as FS-NBRGDS. The proposed NBRGDSachievesthelowestMAEandMRE.PRGDSper-
NBRGDS with graph-structured prior placed over the tran- forms better than PGDS as PRGDS can capture a certain
sitionstructure,isdenotedbyGS-NBRGDS. amountofoverdispersioneffectsviaitsPoisson-randomized
chain structure. We also note that NBRGDS with a time-
To evaluate the performance of the compared models in
varing scaling factor δ(t), performs better than stationary
capturing heterogeneous overdispersed behaviours of latent
dynamicprocessesbehindcountsequences,weconsidereda NBRGDS because this scaling factor δ(t) can also capture
subsetofICEWSdatathatconsistsofheterogeneousoverdis- burstydynamics. Nonetheless,stationaryNBRGDSstillout-
persed counts. More specifically, we sorted the oberserved performs both the PRGDS and PGDS with time-varing δ(t).
dimensionsaccordingtotheirvariance/expectationratio,and We conjecture that this improved prediction accuracy is be-
selected the first L dimensions in descending order, i.e., cause the time-varying scaling factor δ(t) fail to capture theGaP-DPFA PGDS PRGDS NBRGDS FS-NBRGDS GS-NBRGPDS
ICEWS MAE S 1.29±0.01 1.04±0.02 1.06±0.01 1.04±0.00 1.04±0.01 1.04±0.01
F 0.94±0.01 0.95±0.03 0.98±0.04 1.12±0.02 0.91±0.02 0.90±0.01
MRE S 0.61±0.00 0.41±0.01 0.42±0.00 0.43±0.01 0.42±0.00 0.41±0.02
F 0.53±0.01 0.51±0.04 0.59±0.03 0.58±0.02 0.54±0.01 0.51±0.01
Last.fm MAE S 1.71±0.03 1.38±0.01 1.39±0.01 1.37±0.01 1.36±0.02 1.38±0.02
F 8.04±0.07 1.41±0.02 5.47±0.22 1.41±0.02 1.12±0.01 1.13±0.02
MRE S 0.52±0.01 0.34±0.01 0.34±0.00 0.34±0.01 0.33±0.00 0.34±0.00
F 4.02±0.04 0.86±0.02 2.59±0.09 0.85±0.03 0.53±0.04 0.53±0.01
EQDB MAE S 3.37±0.09 3.37±0.20 3.41±0.33 3.26±0.12 3.26±0.20 3.34±0.27
F 10.17±2.21 10.89±0.94 7.08±0.90 5.65±0.63 3.55±0.04 3.33±0.06
MRE S 0.89±0.17 0.89±0.05 0.84±0.08 0.83±0.09 0.83±0.07 0.82±0.05
F 8.12±2.14 6.54±0.93 2.45±0.46 1.49±0.11 1.52±0.15 1.40±0.10
COVID-19 MAE S 12.09±0.26 11.42±0.62 11.08±0.25 10.99±0.43 11.57±0.07 11.37±0.62
F 23.35±1.07 27.67±0.18 21.95±0.59 20.87±0.29 23.55±0.08 23.30±0.05
MRE S 1.47±0.19 1.54±0.11 1.23±0.11 1.19±0.13 1.41±0.22 1.32±0.11
F 6.30±0.58 7.87±0.32 6.32±0.32 1.94±0.15 1.36±0.03 1.40±0.03
Table1:Resultsforthedatasmoothing(“S”)andfuturedataforecasting(“F”)tasks.Forbothmeanabsoluteerror(MAE)andmeanrelative
error(MRE),lowervaluesarebetter.
and overdispersion magnitude of the dimensions by tuning
the values of p and p, respectively1. More specifically, we
0
generatedfivegroupsofsyntheticdata,inwhicheachgroup
containsV = 10dimensionsandT = 365timesteps,using
thefollowingconfigurations: (1)p = 0.9, r = 5, p = 0.9,
0
V/E = 1.6; (2) p = 0.9, r = 5, p = 0.8, V/E = 2.3;
0
(3) p = 0.9, r = 5, p = 0.7, V/E = 3.3; (4) p = 0.9,
0 0
r = 5, p = 0.6, V/E = 4.7; (5)p = 0.9, r = 5, p = 0.5,
0
V/E = 6.5,whereVandErepresentsvarianceandexpecta-
tionofeachgroupdata, respectively. ThenV/Edenotesthe
ratio of variance to expectation, and thus measures overdis-
persion effects. Fig.5 plots the model performance of the
compared methods by varying the ratio of variance to ex-
Figure5:TheproposedNBRGDSconsistentlyachieveslowermean
pectation. NBRGDS models including its factor-structured
absoluteandrelativeerrors, whenwevarytheoverdispersedmag-
and graph-structured versions, consistently outperforms the
nitude(theratioofvariancetoexpection)ofthesyntheticcountse-
quences,comparedwiththeotherclosely-relatedmodels. othermethods. Inparticular,NBRGDSachievesasignificant
improvementcomparedwithPRGDS,althoughPRGDSstill
cancaptureacertainamountofoverdispersioneffects. Addi-
underlying overdispersed behaviours, although it still can tionalexperimentsonsyntheticdataunderdifferentconfigu-
model a certain amount of bursty dynamics in observed di- rationsareavailableinthesupplementarymaterial.
mensions. This observation further demonstrates the strong Data Smoothing and Forecasting To quantatively evaluate
abilityoftheNBRGDSincapturinghetergeneousoverdisper- thepredictiveperformanceofthecomparedmethods,wecon-
sioneffectsofthelatentdimensionsbehindcountsequences. sidered two standard tasks: data smoothing and future data
Synthetic data. To further evaluate the performance of forecasting. The data smoothing is to predict y(t) given the
v
the compared models in capturing overdispersion effects,
remaining observations y(1:T) \ y(t), while the future data
we also considered generating synthetic data with heteroge- v v
prediction is to predict future observations at next S time
neousoverdisperseddynamics. Tothatend,weconsideredto
simulatesyntheticdatausingzero-inflatednegative-binomial steps y v(T+1):(T+S) given the history up to T, y v(1:T). Here
(ZINB)modelsgivenby we considered to predict next two time steps (S = 2). We
used the default settings of GaP-DPFA, and PRGDS as pro-
f ZINB(n|p 0,r,p)=p 0I 0(n)+(1−p 0)f NB(n|r,p), vided in the corresponding releases [Acharya et al., 2015;
Schein et al., 2019]. For NBRGDS, FS-NBRGDS and GS-
where f and f represents the probability mass func-
ZINB NB NBRGDS, we choose K = 100 when V ≥ 1000, while
tion(PMF)ofthezero-inflatednegative-binomialdistribution
andnegative-binomialdistribution,respectively. Here,I (n)
0 1Assume an random variable x ∼ ZINB(p ,r,p). The ex-
is an indicator function that takes 1 when n = 0, otherwise 0
pectation and variance of x are E[x] = r(1−p )(1−p)/p, and
0
0. Theparameterp 0 ∈[0,1]controlstheratioofzerocounts, Var[x] = (1 − p 0)r(1 − p)/p2 + p 0(1 − p 0)r2(1 − p)2/p2,
whilerandparethetwoparametersofthenegative-binomial respectively. Thus, the ratio of variance to expectation of x is
distribution. Hence, we can effectively control the sparsity (1+rp (1−p))/p.
0Figure6:ThelatentgraphstructureinferredbytheproposedmethodonICEWSdata
thedimensionsofEQDBandCOVID-19datasetsaresmaller mostestimatedlatentdynamicprocessesarealmostindepen-
than 100, thus we choos K = 25. We set C = K for FS- denttotheotherdynamicprocesses,butonlyinteractwitha
NBRGDS and GS-NBRGDS. We ran 5000 iterations of the fewotherdimensions. Weprovidethelatentgraphsinferred
Gibbssampler,whichhavestartedtoconvergeafter1000it- fortheotherreal-worlddatainthesupplement.
erations. We discarded the first 3000 samples which were
treated as burn-in time and collected a posterior sample ev-
6 Conclusion
ery tenth sample thereafter. Tab. 1 shows the results of the
compared methods in these two tasks. Overall, NBRGDS Novelnegative-binomial-randomizedgammadynamicalsys-
outperforms the GaP-DPFA, PGDS and PRGDS on almost tems, have been proposed to capture the heterogeneous
all the datasets. In particular, we found that FS-NBRGDS overdispersedbehaviorsoflatentdynamicsbehindcounttime
andGS-NBRGDSshowsuperiorperformanceinfuturedata sequences. Thenewframeworkdemonstratesmoreexplain-
forecasting.Weconjecturethisimprovedpredictionaccuracy able latent structure, by learning the factor structure and
isduetothatFS-NBRGDSandGS-NBRGDScaneffectively sparse graph structure of the transition kernels, compared
leveragethestructureinformationunderlyingdynamiccount with transition kernel by non-informative priors. Although
data, and thus yields better predictive accuracy. We provide thepriorspecificationoftheproposedframeworklackscon-
morecomparativeresultsondatasmoothingandforecasting jugacy,tractable-yet-efficientsamplingalgorithmsaredevel-
overdifferentmodelsinappendixSec.D. oped to perform posterior inference. In the future, we plan
Graph-StructuredTransitionDynamics. Fig. 6showsthe to capture time-varying graph-structured transition dynam-
latent graph structure underlying the transition kernel, esti- ics, which will enable to better understand non-stationary
matedby theproposed model. Althoughthemodel wasini- count sequences. We are also considering to enhance the
tialized with C = 50 latent communities, the latent graph modeling capacities of gamma belief networks [Zhou et al.,
only consists of approximately ten communities with non- 2015; Zhou et al., 2016; Zhou, 2018] and convex poly-
zeroweights,asshowninFig.6(a).Fig.6(d-k)plotstheeight tope methods [Zhou, 2016b; Armandpour et al., 2021] us-
evidentlatentcommunitiesinwhichtheverticesaredensely ing the negative-binomial-randomized gamma Markov pro-
connected as the corresponding dimensions are more likely cesses. Moreover, the future interesting research directions
to interact with each other. Fig. 6(c) demonstrates that the includemodelingburstydynamicsoftenobservedinonlineormobilesocialnetworks[YangandKoeppl,2018b;Yangand [Guoetal.,2018] Dandan Guo, Bo Chen, Hao Zhang, and
Koeppl,2018a;YangandKoeppl,2020;YangandZha,2023; Mingyuan Zhou. Deep poisson gamma dynamical sys-
YangandZha,2024]inthefutureresearch. tems. InAdvancesinNeuralInformationProcessingSys-
tems,2018.
References [Hanetal.,2014] Shaobo Han, Lin Du, Esther Salazar, and
[Acharyaetal.,2015] Ayan Acharya, Joydeep Ghosh, and Lawrence Carin. Dynamic rank factor model for text
streams. AdvancesinNeuralInformationProcessingSys-
MingyuanZhou. Nonparametricbayesianfactoranalysis
tems,27:2663–2671,2014.
fordynamiccountmatrices. InArtificialIntelligenceand
Statistics,pages1–9.PMLR,2015. [Jonesetal.,2023] Andrew Jones, F. William Townes, Di-
[Acharyaetal.,2018] Ayan Acharya, Joydeep Ghosh, and dong Li, and Barbara E. Engelhardt. Alignment of spa-
tialgenomicsdatausingdeepGaussianprocesses. Nature
Mingyuan Zhou. A dual markov chain topic model for
Methods,20(9):1379–1387,2023.
dynamic environments. In Proceedings of the 24th ACM
SIGKDDInternationalConferenceonKnowledgeDiscov- [King,2001] Gary King. Proper nouns and methodological
ery&DataMining,page1099–1108,2018. propriety:Poolingdyadsininternationalrelationsdata.In-
[Armandpouretal.,2021] Mohammadreza Armandpour, ternationalOrganization,55(2):497–507,2001.
Ali Sadeghian, and Mingyuan Zhou. Convex polytope [Levitinetal.,2019] Hanna Mendes Levitin, Jinzhou Yuan,
trees and its application to VAE. In Advances in Neural Yim Ling Cheng, Francisco JR Ruiz, Erin C Bush, Jef-
InformationProcessingSystems,pages5038–5051,2021. frey N Bruce, Peter Canoll, Antonio Iavarone, Anna La-
[BleiandLafferty,2006] DavidMBleiandJohnDLafferty. sorella,DavidMBlei,etal.Denovogenesignatureidenti-
Dynamictopicmodels. InProceedingsofthe23rdinter- ficationfromsingle-cellrna-seqwithhierarchicalpoisson
nationalconferenceonMachinelearning,pages113–120, factorization. Molecular systems biology, 15(2):e8557,
2006. 2019.
[Chandraetal.,2023] Noirrit Kiran Chandra, Antonio [Lindermanetal.,2017] Scott Linderman, Matthew John-
Canale, and David B. Dunson. Escaping the curse of di- son, Andrew Miller, Ryan Adams, David Blei, and Liam
mensionalityinbayesianmodel-basedclustering. Journal Paninski. Bayesian Learning and Inference in Recurrent
ofMachineLearningResearch,24(144):1–42,2023. Switching Linear Dynamical Systems. In Proceedings
of the 20th International Conference on Artificial Intelli-
[Chenetal.,2020] Wenchao Chen, Bo Chen, Yicheng Liu,
genceandStatistics,pages914–922,2017.
Qianru Zhao, and Mingyuan Zhou. Switching poisson
gammadynamicalsystems. InChristianBessiere, editor, [Nassaretal.,2018] JosueNassar,ScottLinderman,Monica
ProceedingsoftheTwenty-NinthInternationalJointCon- Bugallo,andIlMemmingPark. Tree-structuredrecurrent
ference on Artificial Intelligence, IJCAI-20, pages 2029– switching linear dynamical systems for multi-scale mod-
2036.InternationalJointConferencesonArtificialIntelli- eling. 2018.
genceOrganization,72020. Maintrack. [RoyandDunson,2020] Arkaprava Roy and David B Dun-
[Diengetal.,2019] AdjiB.Dieng,FranciscoJ.R.Ruiz,and son. Nonparametric graphical model for counts. The
David M. Blei. The dynamic embedded topic model. JournalofMachineLearningResearch,21(1):9353–9373,
ArXiv,2019. 2020.
[Ferguson,1973] ThomasS.Ferguson.ABayesianAnalysis [RudolphandBlei,2018] Maja Rudolph and David Blei.
of Some Nonparametric Problems. The Annals of Statis- Dynamic embeddings for language evolution. In Pro-
tics,1(2):209–230,1973. ceedings of the 2018 World Wide Web Conference, pages
1003—-1011,2018.
[Filstroffetal.,2021] Louis Filstroff, Olivier Gouvert,
Cedric Fevotte, and Olivier Cappe. A comparative study [Scheinetal.,2016a] Aaron Schein, Hanna Wallach, and
of gamma markov chains for temporal non-negative Mingyuan Zhou. Poisson-gamma dynamical systems.
matrix factorization. IEEE Transactions on Signal Advances in Neural Information Processing Systems,
Processing,69:1614–1626,2021. 29:5012–5020,2016.
[Ganetal.,2015] Zhe Gan, Chunyuan Li, Ricardo Henao, [Scheinetal.,2016b] AaronSchein,MingyuanZhou,David
David Carlson, and Lawrence Carin. Deep temporal sig- Blei, and Hanna Wallach. Bayesian poisson tucker de-
moidbeliefnetworksforsequencemodeling. InProceed- composition for learning the structure of international re-
ings of the 28th International Conference on Neural In- lations. InProceedingsofThe33rdInternationalConfer-
formationProcessingSystems-Volume2,NIPS’15,page enceonMachineLearning,pages2810–2819,2016.
2467–2475,Cambridge,MA,USA,2015.MITPress.
[Scheinetal.,2019] Aaron Schein, Scott Linderman,
[GhahramaniandRoweis,1998] Zoubin Ghahramani and Mingyuan Zhou, David Blei, and Hanna Wallach.
SamRoweis.Learningnonlineardynamicalsystemsusing Poisson-randomized gamma dynamical systems. Ad-
anemalgorithm. Advancesinneuralinformationprocess- vances in Neural Information Processing Systems,
ingsystems,11:431–437,1998. 32:782–793,2019.[Sheldonetal.,2013] DanielSheldon,TaoSun,AkshatKu- modeling. IEEE Trans. Pattern Anal. Mach. Intell.,
mar, and Tom Dietterich. Approximate inference in col- 37(2):307–320,2015.
lectivegraphicalmodels. InProceedingsofthe30thInter-
[Zhouetal.,2015] Mingyuan Zhou, Yulai Cong, and
national Conference on Machine Learning, pages 1004–
BoChen. Thepoissongammabeliefnetwork. Advances
1012,2013.
inNeuralInformationProcessingSystems,28:3043–3051,
[Stewart,2014] Brandon M Stewart. Latent factor regres- 2015.
sions for the social sciences. Technical report, Harvard
[Zhouetal.,2016] Mingyuan Zhou, Yulai Cong, and
University,2014.
BoChen. Augmentablegammabeliefnetworks. Journal
[StuartandWolfram,2020] Andrew M. Stuart and Marie- ofMachineLearningResearch,17(163):1–44,2016.
ThereseWolfram. Inverseoptimaltransport. SIAMJour-
[Zhou,2015] MingyuanZhou. InfiniteEdgePartitionMod-
nalonAppliedMathematics,80(1):599–619,2020.
els for Overlapping Community Detection and Link Pre-
[Tongetal.,2020] Alexander Tong, Jessie Huang, Guy diction. In Proceedings of the Eighteenth International
Wolf,DavidVanDijk,andSmitaKrishnaswamy. Trajec- ConferenceonArtificialIntelligenceandStatistics,pages
torynet: Adynamicoptimaltransportnetworkformodel- 1135–1143,2015.
ingcellulardynamics. InProceedingsofthe37thInterna-
[Zhou,2016a] Mingyuan Zhou. Nonparametric bayesian
tionalConferenceonMachineLearning,2020.
negative binomial factor analysis. Bayesian Analysis,
[VirtanenandGirolami,2020] Seppo Virtanen and Mark 13(4):1065–1093,2016.
Girolami.Dynamiccontentbasedranking.InProceedings
[Zhou,2016b] Mingyuan Zhou. Softplus regressions and
oftheTwentyThirdInternationalConferenceonArtificial
convexpolytopes,2016.
IntelligenceandStatistics,pages2315–2324,2020.
[Zhou,2018] MingyuanZhou. Parsimoniousbayesiandeep
[Wangetal.,2008] Chong Wang, David M. Blei, and
networks. InAdvancesinNeuralInformationProcessing
David E. Heckerman. Continuous time dynamic topic
Systems,2018.
models. InConferenceonUncertaintyinArtificialIntelli-
gence,2008.
[YangandKoeppl,2018a] Sikun Yang and Heinz Koeppl.
Dependent relational gamma process models for longitu-
dinalnetworks. InProceedingsoftheInternationalCon-
ference on Machine Learning (ICML), pages 5551–5560,
2018.
[YangandKoeppl,2018b] SikunYangandHeinzKoeppl.A
Poissongammaprobabilisticmodelforlatentnode-group
membershipsindynamicnetworks. InProceedingsofthe
AAAI Conference on Artificial Intelligence (AAAI), pages
4366–4373,2018.
[YangandKoeppl,2020] Sikun Yang and Heinz Koeppl.
The Hawkes edge partition model for continuous-time
event-basedtemporalnetworks.InProceedingsofthe36th
ConferenceonUncertaintyinArtificialIntelligence(UAI),
pages460–469,2020.
[YangandZha,2023] Sikun Yang and Hongyuan Zha. Es-
timatinglatentpopulationflowsfromaggregateddatavia
inversing multi-marginal optimal transport. In Proceed-
ings of the 2023 SIAM International Conference on Data
Mining(SDM),pages181–189,2023.
[YangandZha,2024] Sikun Yang and Hongyuan Zha. A
variational autoencoder for neural temporal point pro-
cesseswithdynamiclatentgraphs. InProceedingsofthe
AAAIConferenceonArtificialIntelligence(AAAI),2024.
[ZhouandCarin,2012] Mingyuan Zhou and Lawrence
Carin. Augment-and-conquer negative binomial pro-
cesses. In Advances in Neural Information Processing
Systems,volume25,pages2546–2554.CurranAssociates,
Inc.,2012.
[ZhouandCarin,2015] Mingyuan Zhou and Lawrence
Carin. Negative binomial process count and mixture