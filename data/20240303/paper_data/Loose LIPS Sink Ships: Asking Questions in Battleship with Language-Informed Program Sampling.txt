Loose LIPS Sink Ships:
Asking Questions in Battleship with Language-Informed Program Sampling
GabrielGrand1,2 ValerioPepe2,3 JacobAndreas1 JoshuaB.Tenenbaum1,2
1MITCSAIL 2MITBCS 3HarvardSEAS
Abstract In this paper, our goal is to model how people efficiently
generate informative questions in a grounded environment,
Questionscombineourmasteryoflanguagewithourremark-
subject to resource constraints. We explore several models
ablefacilityforreasoningaboutuncertainty. Howdopeople
navigatevasthypothesisspacestoposeinformativequestions in the context of the Battleship Game (Rothe et al., 2017,
given limited cognitive resources? We study these tradeoffs 2018, 2019): an adaptation of the classic board game to an
inaclassicgroundedquestion-askingtaskbasedontheboard
open-endedquestion-askingtask. Rotheetal. castquestion-
game Battleship. Our language-informed program sampling
(LIPS) model uses large language models (LLMs) to gener- asking as program synthesis, where questions are expressed
ate natural language questions, translate them into symbolic assymbolicprogramsinadomain-specificlanguage(DSL).
programs, and evaluate their expected information gain. We
Theyshowthatsamplingprogramsandscoringthemaccord-
findthatwithasurprisinglymodestresourcebudget,thissim-
pleMonteCarlooptimizationstrategyyieldsinformativeques- ing to features learned from many human questions can ap-
tionsthatmirrorhumanperformanceacrossvariedBattleship proximatethedistributionofquestionspeopleask.
boardscenarios. Incontrast, LLM-onlybaselinesstruggleto
groundquestionsintheboardstate;notably,GPT-4Vprovides Weaimtoextendthisapproachinseveralways. Humans
noimprovementovernon-visualbaselines. Ourresultsillus- express questions via language—not code—and we would
tratehowBayesianmodelsofquestion-askingcanleveragethe
likemodelscapableofthesame. Nevertheless,symbolicpro-
statisticsoflanguagetocapturehumanpriors,whilehighlight-
ingsomeshortcomingsofpureLLMsasgroundedreasoners. gramsareausefulformatforexpressingandevaluatingques-
tions;here,webridgethisgapbymodelingmeaning-making
Introduction as the process of translating from natural language to a lan-
Humanbeingsarequestion-generatingmachines. Fromearly guageofthought(LoT).Finally,questionscanbecuedbythe
childhood,wearedriventoaskwhat,where,when,howand situation(theboardstate)inabottom-upway;whileprevious
why. Butoutofallthe(infinitelymany)grammatically-valid modelsusedtheboardstrictlyfortop-downutilitycomputa-
questionswecouldposeinagivensituation,howdowede- tion,here,theboardalsoinformsquestiongeneration.
cidewhichonestoask? Andhowdowefindgoodquestions We build on new approaches for modeling language-
efficiently,givensuchalargesearchspace? informed thinking (L. Wong et al., 2023) that integrate
Questions can serve many functions, but a core goal is to two powerful computational tools: large language models
gain information: reducing the speaker’s uncertainty about (LLMs)andprobabilisticprograms. LLMsallowourmodels
the state of the world (Graesser et al., 1993; Hawkins et al., to pose questions in free-form everyday language and trans-
2015; D. Markant & Gureckis, 2012). Informational value latethosequestionsintosymbolicrepresentation. Probabilis-
must be grounded in a shared speaker-listener environment ticprogramsformalizethequestion-asker’sworldmodelsand
and is highly context-dependent. For instance, “Are you the support coherent reasoning about the expected informativity
guyintheredhat?”isanaturalquestionforAlicetotextBob of questions. Our work thus contributes to both Bayesian
inacrowdedairport—butlesssoinaface-to-faceinteraction, models of cognition and LLM accounts: We highlight how
or on a day when the local firefighter convention is in town. Bayesian models of active learning and information search
Asking informative questions therefore requires integrating can be applied to natural language inputs and outputs, and
linguisticcompetencewiththeabilitytorepresentandreason how LLMs—which have been increasingly tuned to answer
aboutpossibleworlds. queries(e.g.,Ouyangetal.,2022)—canalsobeusedtosup-
In addition to grounding and context, question-asking is portcoherent,groundedquestion-asking.
shaped by cognitive resource constraints (Anderson, 1990;
Ourmodel(Fig.1)isformulatedasasimpleMonteCarlo
Chater&Oaksford,1999;Lieder&Griffiths,2019). Forin- (sampling-based) search that draws k candidate questions
stance, we know that both children and adults are “greedy”
stochastically from a language prior and estimates their in-
information-seekersinactivelearningandmayconsideronly
formativityviasimulationinaninternalworldmodel. LLMs
very few hypotheses at a time (Klayman & Ha, 1989; D. B.
playtwodistinctroles: (1)asapriordistributionoverques-
Markantetal.,2016;Mederetal.,2019;Ruggerietal.,2016;
tions, and (2) as a conditional distribution that maps ques-
Vuletal.,2014). Facedwithacognitivelydemandingsearch
tions from language into LoT programs. (Hence we name
task,peoplealsopreferqueriesthatyieldsimpleanswersthat
ourframework“Langugage-informedprogramsampling”;or
areeasytointerpret(Cheyetteetal.,2023).
LIPS.) The translation step allows us to symbolically com-
putetheExpectedInformationGain(EIG)ofcandidateques-
tionsandchoosethehighest-valueone. Byvaryingk,wecan
Correspondencetogg@mit.edu. Codeforthispaperisavail-
ableat:github.com/gabegrand/battleship. control how much mental computation the model performs
4202
beF
92
]LC.sc[
1v17491.2042:viXraPreprint: Undersubmission.
Hypothesis space
Sample k questions Translate into LoT Info gain
“Is any part of the
Is the blue ship ver.cal? (== (orient Blue) V) 0.74 purple ship in
row 6?”
(any (map (lambda y0
Is any part of the purple ship
(== (rowL y0) 6)) 0.99
in row 6? !
(coloredTiles Purple)))
Battleship board
(partiallyrevealed)
Is the red ship longer than 2 .les? (> (size Red) 2) 0.00
(A) Language prior (B) Program likelihood (C) Simulation
Figure 1: How do people formulate information-seeking questions in a grounded task such as the game Battleship? Given a
partially-revealedboard,ourLIPSmodel(A)sampleskquestionsfromalanguagemodelpriorand(B)translatestheseintoLoT
programs. (C)Theutilityofaquestioniscomputedbysimulatingtheprogramagainstahypothesisspaceofboardscompatible
withtheobservation. Here, thebestquestionachievesExpectedInformationGain(EIG)of0.99, meaningtheanswerwould
rule out nearly half the boards in the hypothesis space. Our model is well-suited to filtering out samples from a noisy prior
(e.g.,“Istheredshiplongerthan2tiles?”) thatareredundantorinconsistentduetolackofgrounding.
beforeproducingaquestion. zontal or vertical), and placement. While later variants ex-
In our experiments, we compare question priors based on tended the paradigm to study multi-turn interactions (Rothe
twodifferentLLMs(CodeLlama-7bandGPT-4)aswellasa et al., 2019), here we consider the original, single-turn task
probabilisticcontext-freegrammar(PCFG)hand-engineered formulation.
for the Battleship domain. We find LLM priors yield infor-
Models
mative questions that are well-calibrated to human data for
surprisinglysmallvaluesofk. Incomparison, thePCFGre- Following prior work, we begin by considering an ideal ob-
quires slightly more samples to match mean human perfor- servermodelofaplayerthatstartswithauniformprior p(s)
manceandyieldsahigherproportionofunnaturallycomplex overpossibleboardsconsistentwiththeobservedinitialstate.
questions. WealsoexploreusingLLMsasperceptualpattern After asking a question x and receiving an answer y, the
learners to propose good questions in a bottom-up fashion. playerperformsaBayesianupdatetotheirbeliefdistribution
Whileatextualencodingoftheworldstatedoesofferamod-
p(y|s;x)p(s)
erate improvement in efficiency of question-asking, we find p(s|y;x)= (1)
that a state-of-the-art multimodal LLM, GPT-4V, provides
∑ s′∈Sp(y|s′;x)p(s′)
no improvementover non-visualbaselines. Thus, theLLM- where the likelihood p(y|s;x) is 1 if y is consistent with s
based models are also far from complete: they still struggle and0otherwise.Themarginallikelihoodcanbecomputedby
withgrounding,producingmanyredundantoruninformative enumerationorapproximatedbysamplingoverahypothesis
questions. Inshort,ourresultsillustratehowcognitivemod- spaceofboardsS.
elsofinformativequestion-askingcanleverageLLMstocap- Theplayer’suncertaintyaboutthehiddenstateofthegame
turehuman-likepriors,whilehighlightingsomeoftheshort- boardcanbemeasuredbytheShannonentropyH(s)(Shan-
comingsofthesemodelsasgroundedreasoners. non,1948),andthevalueofaquestionxcanbedefinedasits
ExpectedInformationGain(EIG):
TheBattleshipGame
WeadopttheBattleshiptaskdevelopedbyRotheetal.(2017, EIG(x;s)= E [H(s)−H(s|y;x)] (2)
y∼p(y|x;s)
2018), a grid-based environment that evaluates participants’
ability to ask goal-directed questions. In this task, partici- Intuitively,EIGprovidesalog-spacemeasureofthenumber
pants are presented a partially-revealed board (Fig. 1) and ofcandidateboardsthattheplayercanruleoutwithquestion
askedtocomeupwithaquestionthatwouldhelptorevealthe x. For instance, if there are 100 possible boards consistent
location of the hidden ships. The task consists of 18 unique with s, then an ideal yes/no question that rules out 50% the
6x6 board contexts, each containing three ships (red, blue, boards would achieve EIG(x;s)=1. (Throughout, we use
and purple) of varying length (2-4 tiles), orientation (hori- log ,soEIGismeasuredinbits.)
2Preprint: Undersubmission.
In Battleship, questions that admit various possible an-
swerscanachieveEIG≫1(e.g.,“Whattilecontainsthetop-
Answer→Bool|Num.|Color|Orient.|Loc.
leftcorneroftheRedship?”). However,theplayerdoesnot
Bool→‘T’|‘F’|(andBB)|(touchShipShip)...
know the answer a priori; this uncertainty over possible an-
Num.→0|1|...|9|(+NN)|...
swers gives rise to the expectation in Eq. 2. In prior work,
EIG was considered as one among several heuristic features Num.→(sizeShip)|(rowL)|(colL)...
(complexity,answertype,etc.) inaBoltzmannenergymodel Color→Ship|
thatwasfittomaximizethelikeihoodofthecollectedhuman Ship→‘Blue’|‘Red’|‘Purple’
questions(Rotheetal.,2017). Orient.→‘Horizontal’|‘Vertical’|(orientShip)
Herewetakeacomplementaryapproach: insteadoffitting
Loc.→1A|1B|...|6F|(topleftSet)...
our model to human data collected from Battleship, we in-
Set→(tilesColor)|(∩SetSet)|‘AllColors’...
steadaimtosampledirectlyfromadistributionofmaximally-
informativequestions—withoutpositingthespaceoffeatures As a computational instantiation of a cognitive theory, the
thesequestionsmighthave. Wehypothesizethathuman-like PCFGproposaldistributionfollowsinthe(probabilistic)lan-
questionswillfalloutnaturallyfromaBayesianmodelwith guage of thought tradition (Fodor, 1975; Goodman & Las-
averygenericpriorthatissubjecttocognitiveresourcecon- siter, 2015; Goodman et al., 2014). One advantage of this
straints. formalizationisthatitcomeswithclear-cutdenotationalse-
We formulate our model as a probabilistic sample-based mantics: questionsareprogramsthatcanbeexecutedagainst
search with a parameter k that controls the amount of inter- the board state to yield an answer. Additionally, the PCFG
nalcomputationthemodelperforms. (Weareinpartinspired imparts an inductivebias towards shorter programsthat nat-
by the bounded space model of Ullman et al. 2016 for cre- urally implements Bayesian Occam’s Razor (Gelman et al.,
ativelanguagegeneration.) Givensomeproposaldistribution 1995; Henderson et al., 2010). However, the PCFG also
overquestions,wesamplekquestionsandchoosetheonethat yields a combinatorially-large number of trivial statements
maximizesEIG. (e.g., mathematical propositions that do not make reference
totheboard). Theseissuescouldbeaddressedbymakingthe
{x 1,...,x k}∼p(x|s) (3) PCFG board-conditional—e.g., by training a neural “recog-
x∗=argmaxEIG(x;s) (4) nition network” (Ellis et al., 2021) to map board inputs to
i
xi
weights. Nevertheless, achieving a good fit with this model
A central challenge of this approach is choosing a suitable wouldrequirealabeleddatasetcontainingmanythousandsof
proposal distribution p(x|s) that admits efficient sampling. (s,x) pairs, which we do not currently have. In the absence
Moreover, as the notation implies, this distribution should ofsuchdata, wefollowthepriorworkintreatingthePCFG
ideallybeboard-conditionalsoastogeneratetargetedques- as an unconditional prior with uniform probability over the
tions about the particular board at hand. To facilitate com- productionrules.
putation of EIG, it is also desirable to have a proposal dis-
Languagemodelproposaldistribution
tribution that is capable of expressing questions as LoT-like
Arecentlineofworkinprobabilisticprogrammingexplores
programs that can be deterministically executed against the
using Large Language Models (LLMs) as instantiations of
board following some denotational semantics; i.e., y= x .
s
Weconsidertwokindsofquestion-proposaldistribution(cid:74)th(cid:75)at humanlikepriorsinBayesianmodels(Dohanetal.,2022;El-
lis, 2023; Lew et al., 2020, 2023). For the purpose of con-
allowustoinstantiateourLIPSmodel.
structingacognitivemodelofhumanquestion-asking,LLMs
Grammarproposaldistribution represent an attractive proposal distribution for several rea-
sons. First, since they are trained on vast corpora of natural
We begin by considering a probabilistic context-free gram-
text, LLMs directly encode a prior over plausible questions.
mar(Johnson,1998)asaproposaldistributionoverquestions.
We adopt the grammar of Rothe et al. (2017)1 whose rules Moreover,LLMsarestrongin-contextlearners(Brownetal.,
2020) and are increasingly amenable to instruction from the
andterminalscorrespondtokeyconceptsinBattleship:ships
experimenter (Ouyang et al., 2022; Rafailov et al., 2023).
vary in color, size, orientation, location, etc. The grammar
Consequently,byconstructinganappropriateprompt,wecan
alsoencodesnumericandset-theoreticoperationstosupport
transform a generic LLM into a proposal distribution over
comparisons; e.g., “Howmanyoftheblueship’stilesarein
questionsintheBattleshipdomain. Thisapproachfacestwo
columnB?”
mainchallenges,whichwedetailbelow.
Grounding generation in the state of the world Ide-
ally, we would like our model to be “stimulus computable”
(Yamins & DiCarlo, 2016), accepting the same images and
task instructions as a human participant. While multimodal
1SeeTableSI-1inRotheetal.(2017)forthefullgrammar.Note
LLMsaregrowinginpopularityandavailability(Driessetal.,
thatinsampling,weomitλ-abstractionsandexpressionsofdepth1,
whichalmostneveryieldwell-formedquestions. 2023;OpenAI,2023b),itremainsuncleartowhatextenttheyPreprint: Undersubmission.
A B C D E F LLMs We queried GPT-4 (OpenAI, 2023a, 2023b) via
1 H P W H W H 1-B is a purple ship tile. API, using gpt-4-0613 for the textual and grid board for-
2 H H H R B H 1 1- -C E i is s a a w wa at te er r t ti il le e. . mats, and gpt-4-vision-preview for the visual format.
3 H W H H H H 2-D is a red ship tile. To compare against a reproducible, open-source LLM, we
4 W H W H H W 2-E is a blue ship tile.
5 H H W W H H ... used CodeLlama (Roziere et al., 2023), a member of the
6 H W H H H H 6-B is a water tile. Llama 2 family of models that was finetuned for code gen-
Grid Textual Visual eration. We obtained the model weights from Hugging-
Face(CodeLlama-7b-hf)andusedthesmallestvariantofthe
Figure 2: We experiment with 3 different board representa- model, which contains 7B parameters. We performed local
tions:anASCII-stylegrid,atextualserialization,andavisual inferenceonasingleGPU,takingadvantageofthehfpplli-
promptencodedasanimage. brary(Lewetal.,2023)tospeedupinferenceviacaching.
Prompting We fed both LLMs identical sets of
arecapableofextractingstructuredvisualinformation—such algorithmically-constructedprompts(seethe“Prompts”sec-
asaBattleshipboard—intoanappropriatecomputationalrep- tionintheAppendix). Forquestiongeneration p(l|s),each
resentation. We experiment with three different types of prompt consisted of instructions describing the task setup
board representation (Fig. 2) in order to evaluate the degree (“YouareplayingtheboardgameBattleship. Therearethree
towhichourLLMproposaldistributionsareabletoleverage shipsontheboard...”).Inthezero-shotcondition,theprompt
board-conditionalinformation. concludedwithatargetgameboard(Fig.2)andtexttoelicita
TranslatingfromnaturallanguagetotheLoT OurLIPS question. Inthefew-shotcondition,thepromptadditionally
modelpositsthatthequestion-askermentallydrawsandeval- included3exampleboards,eachwith10questionsfromthe
uatesk samplesandchoosesthemostinformativeone. This human data. The example boards and questions were sam-
is straightforward in the case of the PCFG, which directly pledwithoutreplacementinaleave-one-outmannersoasto
generates programs, but not for the case of LLMs, which excludehumandatacollectedforthetargetboard. Fortrans-
output natural language. To address this, we follow the ap- lation p(x|l),thepromptconsistedofasimilartaskinstruc-
proachoftheRationalMeaningConstructionframework(L. tion, followed by 12 (l,x) pairs randomly sampled from the
Wongetal.,2023),whichusesLLMstoimplementa“mean- humandatainthesamemanner.
ing function” that translates from natural language into the Sampling ForeachLLMcondition,wesampled100ques-
LoT.Concretely,wedecomposetheLLMproposalintosep- tions/board × 18 boards. To explore the effects of prompt
arate linguistic question generation p(l |s) and language- andboardformats,werepeatedthisprocessforeachcombi-
to-programtranslation p(x|l)distributions, whichweap- nation of {zero-shot, few-shot} × {textual, grid, visual, no
proximateviasampling. board} using GPT-4(V). For the PCFG, which is not board-
conditional, we sampled a single set of 100K questions and
p(x|s)=∑p(x|l)p(l|s) (5)
computed their EIG values for each board. Following Ull-
l manetal.(2016),toavoidexpensivere-collectionofdata,the
This formalization admits many possible denotational bootstrapped sampler was constructed post-hoc by grouping
semantics— · couldbeimplementedbyaLISPinterpreter, samplesintobucketsofsizek. Sincetheunderlyingsamples
s
aPythonpro(cid:74)g(cid:75)ram,orevenaLLM.Forconvenience,weuse arei.i.d.,thisprovidesanunbiasedestimateofthetruesam-
thesameBattleshipDSLfromRotheetal.(2017),whichal- pler,withthecaveatthattheeffectivesamplesizediminishes
lowsustotakeadvantageofthefastC++implementationof with increasing k. Throughout, null hypothesis testing was
theEIGfunctiondevelopedforthatwork.2 conductedbetweenconditionsusingWelch’st-test.
ResultsandDiscussion
Experiment
Informativity How informative are the questions collected
Participants,materials,andmethods
fromhumans? Andtowhatextentdoourmodelscapturethe
Humandata WeusethehumandatasetcollectedbyRothe
information-seeking quality of human questions? We com-
etal.2017,whichconsistsof26-39questionsforeachboard
puted EIG values for all human and model-generated ques-
composedbyasinglepoolofN=40participants,foratotalof
tions (Table 1). Across the 18 boards, the average human
605 question-board pairs. Participants were not “prompted”
question scored EIG=1.27, while the best human question
with any example questions; they were only given the con-
achievedconsiderablyhigherEIG=3.61. Despitethislarge
straint that the question should admit a single-word answer.
range, virtually all (97%) of the human questions were in-
Astheprogramannotationsinthisdatasetusedanearlierver-
formative (EIG>0), revealing that participants were highly
sion of the DSL, we manually re-annotated a representative
sensitivetotheboardstate.
subsetofthequestionsandusedaLLMtranslator(described
In contrast, the underlying proposal distributions (k =
below)toannotatetheremainingprograms.
1) were substantially noisier than people: questions from
CodeLlama and GPT-4 averaged EIG = 0.65-0.66, respec-
2https://github.com/anselmrothe/EIG tively, while questions from the grammar averaged EIG =Preprint: Undersubmission.
3.0
Prompting Board Format
3.5 Human max CodeLlama-7b
zero-shot textual visual
GPT-4 2.5 few-shot grid no board
3.0
Grammar
2.5 2.0
2.0
1.5
1.5 Human mean
1.0
1.0
0.5
0.5
0.0 0.0
1 5 10 20 50 0 10 20 30 40 50
Samples (k) Samples (k)
model = CodeLlama-7b model = GPT-4 model = Grammar
100
k=50
k=20 k=50 k=50
80 k=20
k=10 k=10
k=20
60 k=5
man k=5 man k=10 man
Hu Hu Hu
40
k=5
20 k=1
0 k=1 k=1
0 20 40 60 80 100 0 20 40 60 80 100 0 20 40 60 80 100
Percentile of Model Percentile of Model Percentile of Model
Figure 3: Comparing the informativity of model-generated questions against human data. (Top left) LIPS with two LLMs
andahand-engineeredgrammarasproposaldistributionsoverquestions. Askincreases,allthreemodelsreachmean-human
performance,thoughtheyfallshortofthebesthuman-generatedquestions. (Topright)EvaluatingGPT-4’sperformancewith
different prompt formats and board representations. Including few-shot examples universally boosts EIG. However, perfor-
mance varies depending on the board format. Notably, GPT-4(V) was unable to utilize the board’s structure in text (grid) or
images (visual), implying a failure of grounding. (Bottom) Q-Q plots comparing model vs. human EIG values at varying
sample sizes. At k=5, all three models are generally well-calibrated to humans, though they fall short of the top 10-20%
of human questions. Throughout, error bars and shaded regions indicate 95% bootstrapped confidence intervals. GPT-4 and
CodeLlama-7brefertothefew-shot,textualconditionunlessotherwisenoted.
Model EIG %Valid %Informative ProgramDepth ProgramSize QuestionWords
µ σM µ σM µ σM µ σM µ σM µ σM
Human 1.27 0.04 1.00 0.00 0.97 0.01 3.22 0.07 4.51 0.14 7.12 0.08
Grammar 0.36 0.00 1.00 0.00 0.38 0.00 3.01 0.00 5.13 0.01 – –
CodeLlama-7b 0.65 0.02 0.75 0.01 0.45 0.01 2.64 0.02 3.24 0.04 6.66 0.04
GPT-4(few-shot) 0.77 0.02 0.88 0.01 0.59 0.01 2.61 0.02 3.22 0.04 6.23 0.03
GPT-4(zero-shot) 0.66 0.01 0.40 0.01 0.35 0.01 3.73 0.04 5.04 0.09 5.19 0.02
GPT-4(noboard) 0.60 0.02 0.68 0.01 0.43 0.01 3.08 0.03 4.12 0.07 6.28 0.03
Table1:Summarystatisticsoftheunderlyingsamples(k=1)acrossallboardcontexts.Questionsthattranslatedtoaparseable
programareconsideredValid,andthosethatachievedEIG>0areconsideredInformative.ProgramDepthandSizerefertothe
depthandnumberofnodesoftheprogramabstractsyntaxtree. QuestionWordsmeasuresthenumberofwordsinthenatural
languagequestion. µandσ denotesamplemeanandstandarderror,respectively.
M
namuH
fo
elitnecreP
)GIE(
niaG
noitamrofnI
detcepxE
GIEPreprint: Undersubmission.
0.36. However,asFig.3(topleft)reveals,bootstrappingal-
Human Grammar
lowsforinasignificantboostinperformance:withjustk=5 Question Type
samples, bothLLMsapproachedhumanmeanperformance; Boolean
andatk=10,bothmodelssignificantlyoutperformedthehu- 54.0% 33.2% Color
20.1% Location
manmean,with p<0.001forCodeLlama,and p=0.01for
Number
GPT-4 (textual, few-shot). This trend continues for sample 4. 70 .% 8% 2.4% 20.6% Orientation
34.2% 23.7%
sizesk=20andk=50, thoughallmodelsstillfallshortof Set
thebesthuman-generatedquestions.
Sampleefficiency Whatrepresentsacognitively-plausible CodeLlama-7b GPT-4 (zero-shot) GPT-4 (few-shot)
amount of mental sampling? Fig. 3 (bottom) compares the
fulldistributionofmodelvs. humanEIGvaluesforvarying
39.2% 43.3%
values of k. At k =5, both LLMs were closely calibrated
4.2%
tothehumandistribution, performingonparwiththegram- 19.7% 0.7% 97.4% 20..24%% 1.9% 00..13%%
mar,whichwashand-engineeredtocapturethisdistribution. 7.1%
33.3% 50.2%
Inotherwords, theNthpercentileofhumanquestion-askers
wrotequestionsthatwereofcomparableinformativitytothe
Nthpercentileofsamplesfromthemodel. However,thetop
Figure4: Proportionoftop-levelquestiontypesgeneratedby
human questions (approx. 85-90th percentile) outperformed
eachproposaldistributionatk=1.
thetopmodel-generatedquestions.
Translation fidelity One restriction of our evaluation is
promptedLLMsapproximatethehumandistribution,though
that, in order for a question to be considered informative, it
CodeLlamamirrorsitmorecloselythanGPT-4. Withoutac-
needstobeexpressableintheBattleshipDSL.Buthoweffec-
cesstoexamples,GPT-4(zero-shot)defaultstobooleanques-
tive is the model at translating questions into programs? As
tions that echo traditional Battleship moves; e.g., “Is there
Table1(%Valid)shows,ahighpercentageofsamplesfrom
a ship at 2-C?” Thus, the different choices of prior encode
CodeLlama(75%)andGPT-4(88%)weresuccessfullytrans-
different inductive biases—and LLMs provide an especially
lated. OnlyintheGPT-4(zero-shot)casedidthetranslation
flexiblewayofencodingbothhumangeneralknowledgeand
modelachievelowfidelity(40%). Sincethemodeldoesnot
domain-specificpriorsintocognitivemodels.
receive any examples in the zero-shot case, it is not surpris-
ingthatmanyofthequestionsfromthisdistributionwerenot
Conclusion
translatable.
As more and more people interact with language models on
Groundedness To what extent did the LLM-generated
a daily basis, understanding how humans seek information
questionstaketheboardstateintoaccount? Ofthevalidpro-
through language is a truly important scientific question. In
gramssampledfromeachmodel,40%(CodeLlama)and33%
(GPT-4)wereuninformative(EIG=0). Thisoccurswhena thiswork, weintroducedanewapproachtomodelinginfor-
mative question-asking by sampling questions from a noisy
questionisredundantwithrespecttoinformationalreadyre-
LLMpriorandtranslatingintoprogramsinaLoT.Butwhere
vealedintheboard. (Forinstance,“Istheredshipvertical?”
doesthisLoTcomefrominthefirstplace? Here,weusedan
isuninformativefor3/18boardsinthestimulusset.)Thehigh
existingDSLasinitialstep,butourapproachcouldbecom-
proportion of uninformative programs highlights a potential
bined with Bayesian program induction techniques to learn
failure of grounding. Our evaluation of different board for-
a new DSL from data (Ellis et al., 2021; Grand et al., 2023;
mats, shown in Fig. 3 (top right), provides further evidence
Piantadosi et al., 2024; C. Wong et al., 2021). Relaxing our
of this issue. Of the four board formats (Fig. 2), the “tex-
assumptionsevenfurther,wemighteschewaDSLinfavorof
tual” representation was the only one that significantly out-
performedthe“noboard”condition(p<0.05fork=1-20). a domain-general programming language like Python (Ellis,
Notably,acrossk,the“visual”boardformatperformedeither 2023;Wangetal.,2023).
significantlyworse(p<0.05fork=1,5)orwasnotsignif- While Monte Carlo sampling is attractive for its simplic-
icantlydifferentthanthe“noboard”condition(p>0.05for ity, more sophisticated inference techniques have recently
k=10-50). TheseresultsshowthatthatGPT-4Vwasunable beenproposedforelicitinguserpreferences(Lietal., 2023;
toutilizetheboard’sstructuretoformulateinformativeques- Piriyakulkijetal.,2023)andclarifyingambiguity(Zhang&
tionsrelativetoaboard-agnosticbaseline. Choi, 2023) in a dialogue context. Applying these to study
people’sbehavioracrosslongerinteractions—suchasmulti-
Questiontype Whatkindsofinformationdohumansask
turnBattleship—presentsanaturaldirectionforfuturework.
about, and do the models reflect this distribution? As illus-
tratedinFig.4,humansaskadiverserangeofquestiontypes,
Acknowledgments
with a preference for boolean and numeric answers. Owing
toitsstructure,thegrammargeneratesanapproximatelyuni- We thank Brenden Lake, Maddy Bowers, and Lionel Wong
formdistributionovertypes.Meanwhile,bothofthefew-shot forhelpfuldiscussionsandfeedback.Preprint: Undersubmission.
TheauthorsgratefullyacknowledgesupportfromtheMIT Goodman, N. D., Tenenbaum, J. B., & Gerstenberg, T.
QuestforIntelligence,theMIT-IBMWatsonAILab,theIntel (2014).Conceptsinaprobabilisticlanguageofthought.In
Corporation, AFOSR, DARPA, and ONR. GG is supported E. Margolis & S. Laurence (Eds.), Concepts: New Direc-
by the National Science Foundation (NSF) under Grant No. tions.MITPress.
2141064. JA is supported by NSF Grant IIS-2144855. JBT Graesser, A. C., Langston, M. C., & Baggett, W. B. (1993).
received support from AFOSR Grant #FA9550-19-1-0269, Exploringinformationaboutconceptsbyaskingquestions.
the MIT-IBM Watson AI Lab, ONR Science of AI and the In Psychology of learning and motivation (pp. 411–436,
DARPA Machine Common Sense program. Any opinions, Vol.29).Elsevier.
findings, and conclusions or recommendations expressed in Grand, G.,Wong, L., Bowers, M.,Olausson, T. X.,Liu, M.,
thismaterialarethoseoftheauthor(s)anddonotnecessarily Tenenbaum, J. B., & Andreas, J. (2023). Lilo: Learning
reflecttheviewsofsponsors. interpretable libraries by compressing and documenting
code.arXivpreprintarXiv:2310.19791.
References
Hawkins, R. X., Stuhlmu¨ller, A., Degen, J., & Goodman,
Anderson, J. R. (1990). The adaptive character of thought. N. D. (2015). Why do you ask? good questions provoke
PsychologyPress. informativeanswers.CogSci.
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, Henderson,L.,Goodman,N.D.,Tenenbaum,J.B.,&Wood-
J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., ward,J.F.(2010).Thestructureanddynamicsofscientific
Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., theories: A hierarchical bayesian perspective. Philosophy
Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., ofScience,77(2),172–200.
Wu, J., Winter, C., ... Amodei, D. (2020). Language Johnson,M.(1998).PCFGmodelsoflinguistictreerepresen-
Models are Few-Shot Learners [arXiv: 2005.14165]. tations.ComputationalLinguistics,24(4),613–632.
arXiv:2005.14165[cs]. Klayman, J., & Ha, Y.-w. (1989). Hypothesis testing in rule
Chater,N.,&Oaksford,M.(1999).Tenyearsoftherational discovery: Strategy, structure, and content. Journal of Ex-
analysis of cognition. Trends in cognitive sciences, 3(2), perimentalPsychology:Learning,Memory,andCognition,
57–65. 15(4),596.
Cheyette,S.J.,Callaway,F.,Bramley,N.R.,Nelson,J.D.,& Lew, A. K., Tessler, M. H., Mansinghka, V. K., & Tenen-
Tenenbaum,J.(2023).Peopleseekeasilyinterpretablein- baum, J. B. (2020). Leveraging unstructured statistical
formation.ProceedingsoftheAnnualMeetingoftheCog- knowledgeinaprobabilisticlanguageofthought.Proceed-
nitiveScienceSociety,45(45). ingsoftheAnnualConferenceoftheCognitiveScienceSo-
Dohan, D., Xu, W., Lewkowycz, A., Austin, J., Bieber, D., ciety.
Lopes, R. G., Wu, Y., Michalewski, H., Saurous, R. A., Lew, A. K., Zhi-Xuan, T., Grand, G., & Mansinghka, V. K.
Sohl-Dickstein,J.,etal.(2022).Languagemodelcascades. (2023). Sequential monte carlo steering of large lan-
arXivpreprintarXiv:2207.10342. guagemodelsusingprobabilisticprograms.arXivpreprint
Driess,D.,Xia,F.,Sajjadi,M.S.,Lynch,C.,Chowdhery,A., arXiv:2306.03081.
Ichter,B.,Wahid,A.,Tompson,J.,Vuong,Q.,Yu,T.,etal. Li, B. Z., Tamkin, A., Goodman, N., & Andreas, J. (2023).
(2023).Palm-e:Anembodiedmultimodallanguagemodel. Eliciting human preferences with language models. arXiv
arXivpreprintarXiv:2303.03378. preprintarXiv:2310.11589.
Ellis, K. (2023). Human-like few-shot learning via bayesian Lieder,F.,&Griffiths,T.L.(2019).Resource-rationalanaly-
reasoning over natural language. Thirty-seventh Confer- sis: Understanding human cognition as the optimal use of
enceonNeuralInformationProcessingSystems. limitedcomputationalresources.BehavioralandBrainSci-
Ellis, K., Wong, C., Nye, M., Sable´-Meyer, M., Morales, ences,43.
L.,Hewitt,L.,Cary,L.,Solar-Lezama,A.,&Tenenbaum, Markant, D., & Gureckis, T. (2012). Does the utility of in-
J. B. (2021). Dreamcoder: Bootstrapping inductive pro- formationinfluencesamplingbehavior?Proceedingsofthe
gramsynthesiswithwake-sleeplibrarylearning.Proceed- annualmeetingofthecognitivesciencesociety,34(34).
ingsofthe42ndACMSIGPLANInternationalConference Markant, D. B., Settles, B., & Gureckis, T. M. (2016). Self-
on Programming Language Design and Implementation, directed learning favors local, rather than global, uncer-
835–850. tainty.Cognitivescience,40(1),100–120.
Fodor, J. A. (1975). The language of thought. Harvard Uni- Meder, B., Nelson, J. D., Jones, M., & Ruggeri, A. (2019).
versityPress. Stepwise versus globally optimal search in children and
Gelman,A.,Carlin,J.B.,Stern,H.S.,&Rubin,D.B.(1995). adults.Cognition,191,103965.
Bayesiandataanalysis.Chapman;Hall/CRC. OpenAI.(2023a).Gpt-4technicalreport.
Goodman,N.D.,&Lassiter,D.(2015).Probabilisticseman- OpenAI. (2023b, September). GPT-4V(ision) System Card
tics and pragmatics: Uncertainty in language and thought. [Accessed:2024-01-30].
The handbook of contemporary semantic theory, 2nd edi- Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.,
tion.Wiley-Blackwell. Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,Preprint: Undersubmission.
et al. (2022). Training language models to follow instruc- Yamins, D. L., & DiCarlo, J. J. (2016). Using goal-driven
tions with human feedback. Advances in Neural Informa- deeplearningmodelstounderstandsensorycortex.Nature
tionProcessingSystems,35,27730–27744. neuroscience,19(3),356–365.
Piantadosi, S. T., Rule, J. S., & Tenenbaum, J. B. (2024). Zhang, M. J., & Choi, E. (2023). Clarify when necessary:
Learning as Bayesian inference over programs. In T. L. Resolving ambiguity through interaction with lms. arXiv
Griffiths, N. Chater, & J. B. Tenenbaum (Eds.), Bayesian preprintarXiv:2311.09469.
models of cognition: Reverse-engineering the mind. MIT
Press.
Piriyakulkij,T.,Kuleshov,V.,&Ellis,K.(2023).Activepref-
erence inference using language models and probabilistic
reasoning.arXivpreprintarXiv:2312.12009.
Rafailov,R.,Sharma,A.,Mitchell,E.,Ermon,S.,Manning,
C. D., & Finn, C. (2023). Direct preference optimization:
Your language model is secretly a reward model. arXiv
preprintarXiv:2305.18290.
Rothe,A.,Lake,B.M.,&Gureckis,T.(2017).Questionask-
ingasprogramgeneration.Advancesinneuralinformation
processingsystems,30.
Rothe,A.,Lake,B.M.,&Gureckis,T.M.(2018).Dopeople
ask good questions? Computational Brain & Behavior, 1,
69–89.
Rothe, A., Lake, B. M., & Gureckis, T. M. (2019). Ask-
ing goal-oriented questions and learning from answers.
CogSci,981–986.
Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I.,
Tan, X. E., Adi, Y., Liu, J., Remez, T., Rapin, J., et al.
(2023). Code llama: Open foundation models for code.
arXivpreprintarXiv:2308.12950.
Ruggeri,A.,Lombrozo,T.,Griffiths,T.L.,&Xu,F.(2016).
Sourcesofdevelopmentalchangeintheefficiencyofinfor-
mationsearch.Developmentalpsychology,52(12),2159.
Shannon,C.E.(1948).Amathematicaltheoryofcommuni-
cation.TheBellsystemtechnicaljournal,27(3),379–423.
Ullman,T.D.,Siegel,M.H.,Tenenbaum,J.,&Gershman,S.
(2016).Coalescingthevaporsofhumanexperienceintoa
viableandmeaningfulcomprehension.CogSci.
Vul, E., Goodman, N., Griffiths, T. L., & Tenenbaum, J. B.
(2014). One and done? optimal decisions from very few
samples.Cognitivescience,38(4),599–637.
Wang, R., Zelikman, E., Poesia, G., Pu, Y., Haber, N.,
& Goodman, N. D. (2023). Hypothesis search: Induc-
tive reasoning with language models. arXiv preprint
arXiv:2309.05660.
Wong,C.,Ellis,K.,Tenenbaum,J.B.,&Andreas,J.(2021).
Leveraging language to learn program abstractions and
searchheuristics.InM.Meila&T.Zhang(Eds.),Proceed-
ingsofthe38thinternationalconferenceonmachinelearn-
ing,ICML2021,18-24july2021,virtualevent(pp.11193–
11204,Vol.139).PMLR.
Wong, L., Grand, G., Lew, A. K., Goodman, N. D., Mans-
inghka, V. K., Andreas, J., & Tenenbaum, J. B. (2023).
Fromwordmodelstoworldmodels:Translatingfromnatu-
rallanguagetotheprobabilisticlanguageofthought.arXiv
preprintarXiv:2306.12672.Preprint: Undersubmission.
Appendix
Table2: Examplesquestionsandprogramsforeachboardcontext. Foreachmodel, wesampledonebest⋆andonerandom
question. For humans, the random sample was drawn from the full pool of participant data for each trial; for models, the
randomsamplewasselectedfromtheLIPSoutputswithk=10,whichprovidesaclosematchtomeanhumanperformance. In
caseswherethebestEIGvaluewasattainedbymultipleprograms,tiebreakingwasrandom. NotethattheGrammargenerates
programsdirectly—manyofwhicharenotreadilytranslatabletonaturallanguage—so“Question”isomittedforthismodel.
Board Model Question Program EIG
Trial1 ⋆ At what location is the top left part (topleft (coloredTiles Red)) 4.67
Human
oftheredship?
Isthereapurpletileat1A? (== (color 1A) Purple) 0.39
⋆ At what location is the top left part (topleft (coloredTiles 4.67
CodeLlama
oftheblueship? Blue))
Howmanytilesistheblueship? (size Blue) 1.36
⋆ Whatisthelocationofonebluetile? (topleft (coloredTiles 4.67
GPT-4
Blue))
Howmanytilesistheblueship? (size Blue) 1.36
⋆ — (topleft (coloredTiles Red)) 4.67
Grammar
— (color 6B) 1.40
Trial2 ⋆ Whatisthelocationofoneredtile? (topleft (coloredTiles Red)) 4.58
Human
Howmanytilesisthepurpleship? (size Purple) 1.58
⋆ Whatisthelocationofoneredtile? (topleft (coloredTiles Red)) 4.58
CodeLlama
Howmanytilesistheredship? (size Red) 1.41
⋆ Whereisonebluetilelocated? (topleft (coloredTiles 4.58
GPT-4
Blue))
Howmanytilesisthepurpleship? (size Purple) 1.58
⋆ — (bottomright (union 4.65
Grammar
(intersection (set AllTiles)
(coloredTiles Red))
(intersection (unique
(set...
— (color 3F) 1.43
Trial3 ⋆ At what location is the top left part (topleft (coloredTiles 4.62
Human
ofthepurpleship? Purple))
Howmanytilesistheredship? (size Red) 1.44
⋆ Howmanytilesisthepurpleship? (size Purple) 1.44
CodeLlama
Istheredshiphorizontal? (== (orient Red) H) 0.99
⋆ Howmanytilesistheredship? (size Red) 1.44
GPT-4
Istheredshiphorizontal? (== (orient Red) H) 0.99
⋆ — (bottomright (unique 4.73
Grammar
(intersection (set AllTiles)
(coloredTiles Purple))))
— (orient Purple) 0.99
Trial4 ⋆ At what location is the top left part (topleft (coloredTiles 4.62
Human
ofthepurpleship? Purple))
At what location is the top left part (topleft (coloredTiles 4.62
ofthepurpleship? Purple))
⋆ Howmanytilesistheredship? (size Red) 1.57
CodeLlama
Howmanytilesistheredship? (size Red) 1.57
⋆ Howmanytilesistheredship? (size Red) 1.57
GPT-4
Howmanytilesistheredship? (size Red) 1.57Preprint: Undersubmission.
Board Model Question Program EIG
⋆ — (bottomright (intersection 4.64
Grammar
(set AllTiles) (intersection
(coloredTiles Purple) (set
AllTiles))))
— (== (orient Blue) H) 0.91
Trial5 ⋆ At what location is the top left part (topleft (coloredTiles Red)) 4.66
Human
oftheredship?
Howmanytilesisthepurpleship? (size Purple) 1.57
⋆ Atwhatlocationisthebottomright (bottomright (coloredTiles 1.90
CodeLlama
partofthepurpleship? Purple))
Howmanytilesisthepurpleship? (size Purple) 1.57
⋆ Howmanytilesisthepurpleship? (size Purple) 1.57
GPT-4
Howmanytilesisthepurpleship? (size Purple) 1.57
⋆ — (topleft (unique 4.66
Grammar
(coloredTiles Red)))
— (size Purple) 1.57
Trial6 ⋆ At what location is the top left part (topleft (coloredTiles Red)) 4.73
Human
oftheredship?
Does the red ship touch both other (and (touch Red Blue) (touch 0.60
ships? Red Purple))
⋆ At what location is the top left part (topleft (coloredTiles Red)) 4.73
CodeLlama
oftheredship?
Istheredship2tileslong? (== (size Red) 2) 1.00
⋆ Whereisatileoftheredship? (topleft (coloredTiles Red)) 4.73
GPT-4
Howmanytilesistheredship? (size Red) 1.50
⋆ — (topleft (intersection (set 4.73
Grammar
AllTiles) (coloredTiles
Red)))
— (+ (== (color 4A) Red) TRUE) 0.52
Trial7 ⋆ How many tiles are occupied by (++ (map (lambda x0 (size 2.48
Human
ships? x0)) (set AllColors)))
Isthereabluetileat5E? (== (color 5E) Blue) 0.87
⋆ Whatisthelocationofoneredtile? (topleft (coloredTiles Red)) 1.79
CodeLlama
Howmanytilesistheredship? (size Red) 1.58
⋆ Howmanytilesistheredship? (size Red) 1.58
GPT-4
Howmanytilesistheredship? (size Red) 1.58
⋆ — (- (setSize (union 3.28
Grammar
(coloredTiles Red)
(setDifference (union
(unique (union
(intersection...
— (== (color 6D) Blue) 0.98
Trial8 ⋆ Atwhatlocationisthebottomright (bottomright (coloredTiles 2.41
Human
partoftheredship? Red))
Istheredshiphorizontal? (== (orient Red) H) 0.85
⋆ Whatisthelocationofonebluetile? (topleft (coloredTiles 2.58
CodeLlama
Blue))
Atwhatlocationisthebottomright (bottomright (coloredTiles 2.41
partoftheredship? Red))
⋆ Howmanytilesistheblueship? (size Blue) 1.58
GPT-4Preprint: Undersubmission.
Board Model Question Program EIG
Howmanytilesistheredship? (size Red) 1.57
⋆ — (- (setSize (coloredTiles 3.16
Grammar
Blue)) (setSize
(setDifference (intersection
(coloredTiles (color 3A))...
— (orient Red) 0.85
Trial9 ⋆ How many tiles in row 4 are occu- (++ (map (lambda x0 (++ (map 1.73
Human
piedbyships? (lambda y0 (== (rowL y0) 4))
(coloredTiles x0)))) (set
AllColors)))
Istheblueship3tileslong? (== (size Blue) 3) 0.89
⋆ Whereisthebottomrighttileofthe (bottomright (coloredTiles 2.25
CodeLlama
blueship? Blue))
Howmanytilesistheredship? (size Red) 1.54
⋆ Howmanytilesistheblueship? (size Blue) 1.58
GPT-4
Howmanytilesistheredship? (size Red) 1.54
⋆ — (- (setSize (coloredTiles 3.21
Grammar
Blue)) (setSize
(setDifference (intersection
(coloredTiles (color 3A))...
— (== (color 5B) Water) 0.99
Trial10 ⋆ Whatisthelocationofonebluetile? (topleft (coloredTiles 3.64
Human
Blue))
Howmanytilesistheblueship? (size Blue) 1.12
⋆ Whereisthebottomrightpartofthe (bottomright (coloredTiles 3.80
CodeLlama
purpleship? Purple))
What is the top left tile of the blue (topleft (coloredTiles 3.64
ship? Blue))
⋆ Whereisthepurpleshiplocated? (topleft (coloredTiles 3.64
GPT-4
Purple))
Howmanytilesistheredship? (size Red) 1.12
⋆ — (bottomright (setDifference 3.93
Grammar
(coloredTiles Blue)
(coloredTiles (color 6E))))
— (color 1C) 1.95
Trial11 ⋆ What is the location of one purple (topleft (coloredTiles 3.88
Human
tile? Purple))
Howmanytilesistheblueship? (size Blue) 0.97
⋆ What is the location of one purple (topleft (coloredTiles 3.88
CodeLlama
tile? Purple))
Isthereashipat2E? (color 2E) 1.07
⋆ Whatisthepositionofonetileofthe (topleft (coloredTiles Red)) 3.88
GPT-4
redship?
Howmanytilesistheblueship? (size Blue) 0.97
⋆ — (topleft (coloredTiles 3.88
Grammar
Purple))
— (+ (size Red) (rowL 3F)) 1.02Preprint: Undersubmission.
Board Model Question Program EIG
Trial12 ⋆ At what location is the top left part (topleft (coloredTiles 4.16
Human
oftheblueship? Blue))
Is there any part of the blue ship in (any (map (lambda y0 (== 0.97
row1? (rowL y0) 1)) (coloredTiles
Blue)))
⋆ At what location is the top left part (topleft (coloredTiles 4.16
CodeLlama
oftheblueship? Blue))
Howmanytilesistheblueship? (size Blue) 1.47
⋆ Howmanytilesistheblueship? (size Blue) 1.47
GPT-4
Howmanytilesistheblueship? (size Blue) 1.47
⋆ — (topleft (unique 4.16
Grammar
(coloredTiles Red)))
— (color 6D) 1.13
Trial13 ⋆ At what location is the top left part (topleft (coloredTiles 3.99
Human
ofthepurpleship? Purple))
Howmanytilesistheblueship? (size Blue) 1.57
⋆ At what location is the top left part (topleft (coloredTiles 3.99
CodeLlama
ofthepurpleship? Purple))
Howmanytilesistheblueship? (size Blue) 1.57
⋆ Howmanytilesistheblueship? (size Blue) 1.57
GPT-4
Howmanytilesistheblueship? (size Blue) 1.57
⋆ — (topleft (coloredTiles 3.99
Grammar
Purple))
— (setSize (setDifference 2.03
(coloredTiles (color 1E))
(unique (coloredTiles
Blue))))
Trial14 ⋆ Whatisthelocationofoneredtile? (topleft (coloredTiles Red)) 4.00
Human
Is there any part of the red ship in (any (map (lambda y0 (== 0.95
columnA? (colL y0) 1)) (coloredTiles
Red)))
⋆ At what location is the top left part (topleft (coloredTiles 1.58
CodeLlama
oftheblueship? Blue))
Howmanytilesistheredship? (size Red) 1.39
⋆ Howmanytilesistheredship? (size Red) 1.39
GPT-4
Istheblueshipvertical? (== (orient Blue) V) 0.93
⋆ — (topleft (coloredTiles Red)) 4.00
Grammar
— (topleft (setDifference 2.71
(unique (union (coloredTiles
Water) (set AllTiles)))
(unique (union...
Trial15 ⋆ At what location is the top left part (topleft (coloredTiles Red)) 4.18
Human
oftheredship?
Istheredship3tileslong? (== (size Red) 3) 0.83
⋆ Howmanytilesistheredship? (size Red) 1.27
CodeLlama
Howmanytilesistheredship? (size Red) 1.27
⋆ Howmanytilesistheredship? (size Red) 1.27
GPT-4
Howmanytilesistheblueship? (size Blue) 0.00
⋆ — (topleft (coloredTiles Red)) 4.18
Grammar
— (- (setSize (coloredTiles 1.27
Water)) (colL 2B))Preprint: Undersubmission.
Board Model Question Program EIG
Trial16 ⋆ How many tiles in row 2 are occu- (++ (map (lambda x0 (++ (map 1.93
Human
piedbyships? (lambda y0 (== (rowL y0) 2))
(coloredTiles x0)))) (set
AllColors)))
Istheredshiphorizontal? (== (orient Red) H) 0.86
⋆ Whatisthelocationofoneredtile? (topleft (coloredTiles Red)) 1.99
CodeLlama
Howmanytilesistheredship? (size Red) 1.53
⋆ Howmanytilesistheredship? (size Red) 1.53
GPT-4
Howmanytilesistheredship? (size Red) 1.53
⋆ — (- (setSize (coloredTiles 3.13
Grammar
Blue)) (setSize
(setDifference (intersection
(coloredTiles (color 3A))...
— (setSize (coloredTiles 2.14
(color 3B)))
Trial17 ⋆ How many tiles in row 1 are occu- (++ (map (lambda x0 (++ (map 2.21
Human
piedbyships? (lambda y0 (== (rowL y0) 1))
(coloredTiles x0)))) (set
AllColors)))
Howmanytilesisthepurpleship? (size Purple) 0.92
⋆ Where is the top left part of the red (topleft (coloredTiles Red)) 1.92
CodeLlama
ship?
Howmanytilesistheredship? (size Red) 1.52
⋆ Howmanytilesistheredship? (size Red) 1.52
GPT-4
Howmanytilesistheredship? (size Red) 1.52
⋆ — (setSize (union 2.98
Grammar
(coloredTiles (color
6A)) (union (intersection
(set AllTiles) (unique
(coloredTiles...
— (color 1C) 0.97
Trial18 ⋆ Atwhatlocationisthebottomright (bottomright (coloredTiles 2.50
Human
partofthepurpleship? Purple))
Howmanytilesisthepurpleship? (size Purple) 1.56
⋆ Howmanytilesisthepurpleship? (size Purple) 1.56
CodeLlama
Howmanytilesistheredship? (size Red) 0.00
⋆ Howmanytilesisthepurpleship? (size Purple) 1.56
GPT-4
Howmanytilesisthepurpleship? (size Purple) 1.56
⋆ — (setSize (coloredTiles 2.50
Grammar
(color 2B)))
— (size Purple) 1.56Preprint: Undersubmission.
Fullresults
EIG %Valid %Informative ProgramDepth ProgramSize QuestionWords
Model k µ σM µ σM µ σM µ σM µ σM µ σM
Human 1 1.27 0.04 1.00 0.00 0.97 0.01 3.22 0.07 4.51 0.14 7.12 0.08
Grammar 1 0.36 0.00 1.00 0.00 0.38 0.00 3.01 0.00 5.13 0.01 – –
5 0.98 0.00 1.00 0.00 0.89 0.00 2.74 0.00 4.07 0.01 – –
10 1.25 0.00 1.00 0.00 0.98 0.00 2.82 0.00 4.12 0.01 – –
20 1.49 0.00 1.00 0.00 1.00 0.00 3.08 0.01 4.62 0.02 – –
50 1.86 0.00 1.00 0.00 1.00 0.00 3.65 0.01 5.71 0.04 – –
CodeLlama-7b 1 0.65 0.02 0.75 0.01 0.45 0.01 2.64 0.02 3.24 0.04 6.66 0.04
5 1.24 0.04 0.99 0.01 0.90 0.02 2.49 0.04 2.89 0.08 6.77 0.09
10 1.55 0.06 0.99 0.01 0.97 0.01 2.36 0.05 2.58 0.09 7.10 0.13
20 1.83 0.10 1.00 0.00 1.00 0.00 2.34 0.06 2.46 0.11 7.61 0.21
50 2.31 0.20 1.00 0.00 1.00 0.00 2.58 0.13 2.69 0.22 8.56 0.37
GPT-4(textual,few-shot) 1 0.77 0.02 0.88 0.01 0.59 0.01 2.61 0.02 3.22 0.04 6.23 0.03
5 1.16 0.04 0.98 0.01 0.86 0.02 2.47 0.05 2.92 0.09 6.48 0.05
10 1.43 0.05 1.00 0.00 0.97 0.01 2.33 0.06 2.62 0.12 6.71 0.07
20 1.65 0.09 1.00 0.00 1.00 0.00 2.17 0.04 2.26 0.06 6.90 0.11
50 2.04 0.19 1.00 0.00 1.00 0.00 2.19 0.07 2.19 0.07 7.22 0.14
GPT-4(textual,zero-shot) 1 0.66 0.01 0.40 0.01 0.35 0.01 3.73 0.04 5.04 0.09 5.19 0.02
5 0.74 0.02 0.60 0.03 0.54 0.03 3.53 0.08 4.82 0.17 5.34 0.04
10 0.79 0.02 0.77 0.03 0.73 0.03 3.60 0.10 4.89 0.21 5.37 0.06
20 0.82 0.03 0.92 0.03 0.88 0.03 3.66 0.15 5.05 0.32 5.39 0.07
50 0.92 0.03 1.00 0.00 1.00 0.00 3.42 0.11 4.33 0.14 5.36 0.11
GPT-4(grid,few-shot) 1 0.62 0.02 0.85 0.01 0.49 0.01 2.72 0.02 3.42 0.04 6.06 0.03
5 1.00 0.03 0.96 0.01 0.77 0.02 2.56 0.05 3.10 0.10 6.31 0.06
10 1.18 0.05 0.99 0.01 0.87 0.03 2.41 0.06 2.80 0.13 6.58 0.08
20 1.38 0.07 1.00 0.00 0.92 0.03 2.27 0.08 2.50 0.16 6.84 0.12
50 1.64 0.14 1.00 0.00 1.00 0.00 2.25 0.07 2.39 0.12 7.22 0.24
GPT-4(grid,zero-shot) 1 0.56 0.01 0.55 0.01 0.39 0.01 3.30 0.03 4.49 0.06 5.85 0.04
5 0.79 0.02 0.88 0.02 0.80 0.02 3.24 0.05 4.42 0.10 5.71 0.07
10 0.89 0.02 0.96 0.01 0.93 0.02 3.20 0.06 4.33 0.12 5.82 0.09
20 0.94 0.01 1.00 0.00 1.00 0.00 3.16 0.08 4.26 0.16 5.86 0.11
50 0.99 0.02 1.00 0.00 1.00 0.00 3.19 0.15 4.36 0.30 5.83 0.21
GPT-4(visual,few-shot) 1 0.54 0.01 0.80 0.01 0.46 0.01 3.02 0.02 4.01 0.04 5.69 0.03
5 0.89 0.03 0.91 0.01 0.75 0.02 2.97 0.06 3.92 0.12 5.92 0.07
10 1.08 0.04 0.99 0.01 0.92 0.02 2.81 0.07 3.60 0.16 6.16 0.10
20 1.29 0.06 1.00 0.00 0.98 0.02 2.56 0.09 3.07 0.19 6.56 0.15
50 1.56 0.12 1.00 0.00 1.00 0.00 2.42 0.13 2.72 0.25 7.03 0.24
GPT-4(visual,zero-shot) 1 0.34 0.01 0.58 0.01 0.25 0.01 2.18 0.02 2.28 0.03 1.11 0.01
5 0.73 0.03 0.70 0.02 0.56 0.03 2.18 0.04 2.30 0.07 1.03 0.01
10 0.88 0.04 0.80 0.03 0.71 0.03 2.07 0.03 2.10 0.04 1.00 0.00
20 0.99 0.05 1.00 0.00 0.92 0.03 2.07 0.04 2.09 0.05 1.00 0.00
50 1.19 0.07 1.00 0.00 1.00 0.00 2.22 0.11 2.31 0.15 1.00 0.00
GPT-4(noboard,few-shot) 1 0.60 0.02 0.68 0.01 0.43 0.01 3.08 0.03 4.12 0.07 6.28 0.03
5 0.98 0.03 0.98 0.01 0.89 0.02 3.01 0.07 3.97 0.13 6.24 0.08
10 1.19 0.05 1.00 0.00 0.97 0.01 2.82 0.07 3.59 0.15 6.31 0.12
20 1.38 0.08 1.00 0.00 0.98 0.02 2.73 0.11 3.42 0.24 6.80 0.19
50 1.75 0.18 1.00 0.00 1.00 0.00 2.72 0.19 3.28 0.40 7.64 0.36
GPT-4(noboard,zero-shot) 1 0.65 0.01 0.69 0.01 0.50 0.01 3.37 0.03 4.67 0.05 6.55 0.02
5 0.81 0.02 0.94 0.01 0.81 0.02 3.32 0.05 4.59 0.10 6.27 0.04
10 0.88 0.02 1.00 0.00 0.92 0.02 3.33 0.07 4.61 0.14 6.26 0.06
20 0.93 0.03 1.00 0.00 0.94 0.02 3.47 0.12 4.89 0.24 6.39 0.10
50 1.01 0.02 1.00 0.00 1.00 0.00 3.89 0.24 5.72 0.49 6.83 0.19
Table 3: Full statistics for all models and values of k. µ and σ denote sample mean and standard error, respectively, and
M
arecomputedacrossallboardcontexts. QuestionsthattranslatedtoaparseableprogramareconsideredValid,andthosethat
achievedEIG>0areconsideredInformative. ProgramDepthandSizerefertothedepthandnumberofnodesoftheprogram
abstractsyntaxtree. QuestionWordsmeasuresthenumberofwordsinthenaturallanguagequestion.Preprint: Undersubmission.
Prompts
Our model procedurally constructs few-shot LLM prompts to elicit task-relevant questions and translations. There are two
prompt formats: one for question-generation and one for translation. Each prompt is structured as a series of messages con-
veyinginstructions,few-shotexamples,orinformationaboutthetargettask. Insomecases,theformatofthemessagevaries
dependingonthemodalityoftheboardrepresentation(textual,grid,orvisual).
FollowingemergingconventionsaroundAPIsforconversationalAImodels,eachcomponentislabeledwitharole. System
providesgeneralhigh-levelinstructions;Userindicatesinputsfromauser;andAssistantindicatesresponsesgeneratedfrom
themodel. Theserolelabelsareeitherpassedasmetadata(forGPT-4)orprependedtothetextofeachmessage(CodeLlama).
Notethatthepurposeoftheserolelabelsistomockillustrateadesiredinteractionpattern;theLLMonlygeneratestextatthe
endoftheconversation.
Questiongenerationprompt
Instructions ThepromptbeginswithasystemmessageexplainingtheroleoftheLLM(“Youareagame-playingagent...”).
ThisisfollowedbyasetofgeneralinstructionsdescribingtheBattleshiptask. Finally,oneofthreemodality-specificmessages
isgiventodescribetheformatoftheboardrepresentation.
Few-shotexamples Next,toillustratethedesiredbehavior,weprovideseveralfew-shotexamplesofboardsandquestions.
Concretely, we randomly choose 3 boards that are not the target board, and randomly choose 10 questions for each board
from the human data. (All sampling is done without replacement.) In the “no board” condition, the board representation is
omitted,buttheexamplequestionsarestillpresent. Inthezero-shotcondition,theentireblockbeginningwith“Herearesome
examples...” isomitted.
Targetboard Finally,thepromptconcludeswiththetargetboardinordertoelicitanewquestionfromtheLLM.Inthe“no
board” condition, the transition message (“Now, it’s your turn...”) and the target board are both omitted, so that the prompt
effectivelyreducestoalistofexamplequestionsthattheLLMextendswithoutanyknowledgeoftheboard.
System You are a game-playing agent. Read the game instructions and examples carefully. Respond
with a single question that can be answered with one word. Do not include any other explanation or
prose.
User You are playing the board game Battleship. There are three ships on the board: Red, Blue, and
Purple. Ships are oriented either horizontally or vertically and can be 2, 3, or 4 tiles in length.
The board is a 6x6 grid, with numbered rows 1, 2, 3, 4, 5, 6 and lettered columns A, B, C, D,
E, F. Coordinates are specified as a row, column pair. For example, 2-C is the tile in row 2, column C.
You will be given a partially-revealed game board. Your task is to ask a single question that will
help you gain information about the position of the remaining hidden ships on the board. You can
ask any question, but it must be answerable with a single word answer.
User (textual) The board is User (grid) The board is User (visual) The board is
represented as a textual represented as a grid with represented as an image, with
description. the following symbols: light gray indicating hidden
tiles, dark gray indicating
H: Hidden water tiles, and red, blue
W: Water and purple indicating ship
R: Red ship tiles.
B: Blue ship
P: Purple ship
User Here are some examples of questions from other agents about different boards.Preprint: Undersubmission.
User (textual) User (grid) User (visual)
2-C is a water tile. A B C D E F
2-E is a water tile. 1 H H H H H H
3-C is a purple ship tile. 2 H H W H W H
4-D is a water tile. 3 H H P H H H
5-B is a water tile. 4 H H H W H H
6-E is a water tile. 5 H W H H H H
6 H H H H W H
3x
Assistant At what location is the top left part of the red ship?
N=10
Assistant Is the red ship horizontal?
Assistant Is there any ship in column F?
User Now, it’s your turn. Here is your board:
User (textual) User (grid) User (visual)
1-B is a purple ship tile. A B C D E F
1-C is a water tile. 1 H P W H W H
1-E is a water tile. 2 H H H R B H
2-D is a red ship tile. 3 H W H H H H
2-E is a blue ship tile. 4 W H W H H W
3-B is a water tile. 5 H H W W H H
... 6 H W H H H H
Assistant ...Preprint: Undersubmission.
Translationprompt
Instructions ThepromptalsobeginswithasystemmessagecontainingageneralinstructionsdescribingtheBattleshiptask
andexplainingtheassistant’sroleasastranslator.TheBattleshiptaskinstructionsareidenticaltotheonesgiveninthequestion-
generationprompt.
Few-shotexamples Thebodyofthepromptconsistsof12pairsof(language,code)examplesillustratingthedesiredtrans-
lationbehavior. Theseexamplesarerandomlysampledwithoutreplacementfromthehumandata. Weexcludeanyexamples
pertainingtothesameboardastheonetargetedduringquestion-generation.
Targetlanguage Finally,thepromptconcludeswithatargetquestioninlanguage,whichtheLLMtranslatesintocode.
System You are playing the board game Battleship. There are three ships on the board: Red, Blue,
and Purple. Ships are oriented either horizontally or vertically and can be 2, 3, or 4 tiles in
length. The board is a 6x6 grid, with numbered rows 1, 2, 3, 4, 5, 6 and lettered columns A, B, C, D,
E, F. Coordinates are specified as a row, column pair. For example, 2-C is the tile in row 2, column C.
Your task is to translate each of the user’s questions into a query program.
User How many tiles is the red ship?
Assistant (size Red)
User Do the red ship and the purple ship touch?
Assistant (touch Red Purple)
User Is there a ship at 1F?
N=12
Assistant (not (== (color 1F) Water))
User Is the blue ship horizontal?
Assistant (== (orient Blue) H)
User How many ships are horizontal?
Assistant (++ (map (lambda x0 (== (orient x0) H)) (set AllColors)))
User Are there more horizontal ships than vertical ships?
Assistant ...