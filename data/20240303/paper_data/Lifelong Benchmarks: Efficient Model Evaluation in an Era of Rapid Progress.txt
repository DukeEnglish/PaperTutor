Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress
AmeyaPrabhu∗12 VishaalUdandarao∗23 PhilipTorr1 MatthiasBethge†2 AdelBibi†1 SamuelAlbanie†3
§ github.com/bethgelab/sort-and-search ı github.com/bethgelab/lifelong-benchmarks
Abstract
Traditional Approach: Static Benchmarking
Models to
evaluate
Standardized benchmarksdrive progress inma-
Model
chinelearning. However, withrepeatedtesting, 1 Model
theriskofoverfittinggrowsasalgorithmsover- Mo 3del 2 Static Dataset 1 Static Dataset 2 Static Dataset 3
exploit benchmark idiosyncrasies. In our work, Model Score Model Score Model Score
1 0.94 1 0.86 1 0.71
we seek to mitigate this challenge by compil- Model 2 0.87 2 0.75 2 0.95
N
ingever-expandinglarge-scalebenchmarkscalled 3 0.58 3 0.89 3 0.83
Lifelong Benchmarks. As exemplars of our ap- Models to Proposed Approach: Lifelong Benchmarking
proach,wecreateLifelong-CIFAR10andLifelong- evaluate
Model Score
ImageNet,containing(fornow)1.69Mand1.98M 1 0.63
testsamples,respectively. Whilereducingover-
Mo 1del sample ranking 2 0.49
fitting,lifelongbenchmarksintroduceakeychal-
Mo 2del model evaluation …3 0 ….82
Lifelong Pool N 0.76
lenge: thehighcostofevaluatingagrowingnum- Model
3 update pool
berofmodelsacrossanever-expandingsample
New incoming
set. To address this challenge, we also intro- Mo Ndel samples
duceanefficientevaluationframework: Sort&
Search(S&S),whichreusespreviouslyevaluated time time
modelsbyleveragingdynamicprogrammingal-
Figure1.StaticvsLifelongBenchmarking.(Top)Staticbench-
gorithms to selectively rank and sub-select test marksincentivisemachinelearningpractitionerstooverfitmodels
samples,enablingcost-effectivelifelongbench- tospecificdatasets,weakeningtheirabilitytoassessgeneralisa-
marking. Extensiveempiricalevaluationsacross tion.(Bottom)WeintroduceLifelongBenchmarksasanalternative
∼31,000modelsdemonstratethatS&Sachieves paradigm—ever-expandingpoolsoftestsamplesthatresistoverfit-
highly-efficient approximate accuracy measure- tingwhileretainingcomputationaltractability.
ment,reducingcomputecostfrom180GPUdays
to5GPUhours(∼1000xreduction)onasingle
models. However,overtime,thesestaticbenchmarkshave
A100 GPU, with low approximation error. As
beenexposedtomanyevaluations,eachleakingcuesabout
such,lifelongbenchmarksofferarobust,practical
theirtestdataandweakeningtheirstatisticalpowerastools
solutiontothe“benchmarkexhaustion”problem.
ofgeneralisationmeasurement (Ottetal.,2022;Mazumder
et al., 2023; Kiela et al., 2021). Fresh approaches must
compete with a body of methods that have been highly
1.Introduction tunedtosuchbenchmarks,incentivisingfurtheroverfitting
if they are to compete (Bender et al., 2021; Beyer et al.,
Weareinthemidstofabenchmarkrevolution.Datasetslike
2021). Thisraisesacriticalquestion: Whatfunctionshould
ImageNet(Dengetal.,2009),MS-COCO(Linetal.,2014),
suchbenchmarksserve?
GLUE(Wangetal.,2018)andBigBench(Srivastavaetal.,
2022)havebeeninstrumentalinadvancingmachinelearning TowardsLifelongBenchmarks.Theprimarygoalofthevi-
researchbyprovidingstandardisedscenariosforcomparing sionbenchmarksconsideredinthisworkistoassessmodel
performance on some task using data that is representa-
1University of Oxford 2Tu¨bingen AI Center, University of tive of the visual world (Torralba and Efros, 2011). For
Tu¨bingen3UniversityofCambridge.
instance,theCIFAR10(Krizhevskyetal.,2009)benchmark
Correspondenceto:{ameya@prabhu.be tested whether classifiers can distinguish between 10 cat-
vishaal.udandarao@bethgelab.org} egories, such as dogs and cats. Subsequent versions like
∗equalcontribution†equaladvising CIFAR10.1(Luetal.,2020),CIFAR10.2(Luetal.,2020),
1
4202
beF
92
]GL.sc[
1v27491.2042:viXra
…
…LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
CINIC10(Darlowetal.,2018),andCIFAR10-W(Sunetal., cientlybyleveragingdatafromprevioustests. Itthenuses
2023) introduced more challenging and diverse samples theseupdatedrankingstoevaluatenewmodels,streamlining
toevaluatethesameobjectiveofclassifying10categories. thebenchmarkingprocess. Thisstrategyenablesefficient
Overtime,however,thankstorepeatedevaluationexposure lifelongbenchmarking,reducingthecostdramaticallyfrom
fromcompetingapproaches,eachindividualbenchmarkdi- acollectiveof180GPUdaysto5GPUhoursonasingle
minishesinrepresentativenessasoverfittingoccursatboth A100GPU.Thiscorrespondstoa1000×reductionininfer-
theindividualmethodandresearchcommunitylevel(Fang encecostscomparedtostaticevaluationonallsamples. To
etal.,2023;Vishniakovetal.,2023). Inthiswork,weaim summarizeourkeycontributionsinthiswork:
totacklethischallengebyintroducingtwoLifelongBench-
marks: Lifelong-CIFAR10andLifelong-ImageNet. These 1. Weintroduceandformaliselifelongbenchmarkingasa
areever-expandingpoolsoftestsamplesthataimtorestore novelframeworkforrobust,efficientmodelevaluation.
the representativeness of benchmarks to the visual world
2. Wecuratetwolifelongbenchmarks:Lifelong-CIFAR10
(seeFig.1)bypreventingmodelsfromoverfittingspecifi-
and Lifelong-ImageNet, consisting of 1.69M and
callytothebiasesofanysubsetbenchmark.
1.98Msamplesrespectively
Evaluation Cost. Our Lifelong-CIFAR10 and Lifelong-
ImageNetbenchmarkscontain1.69millionand1.98million 3. We propose a novel framework, Sort & Search for
test samples, respectively. A challenge we face with this efficient model evaluation, reducing over 99.9% of
expandingdatasetistheincreasingcostofevaluation—it computationcostsonourlifelongbenchmarkswhile
takes roughly 140 and 40 GPU days to evaluate our cur- accuratelypredictingsample-wiseperformance.
rentmodelset(containing31,000and167modelsrespec-
tively,seeSection5.1),onLifelong-CIFAR10andLifelong- 2.LifelongBenchmarks: Curation
ImageNetrespectively. Similarissuesoccurinlarge-scale
foundationmodel(Bommasanietal.,2021)evaluation. For Considerations. Weaimtoestablishlifelongbenchmark-
instance,evaluatingasinglelargelanguagemodel(LLM) ing as a standard evaluation protocol in computer vision.
ontheMMLUbenchmark(Hendrycksetal.,2021b)(stan- To demonstrate this, we considered two popular datasets
dardbenchmarkforevaluatingLLMs)takes24hoursona as our basis: CIFAR10 (Krizhevsky et al., 2009) and Im-
consumer-gradeGPU(IlyasMoutawwakil,2023). Asmod- ageNet (Deng et al., 2009). We chose them due to (1)
elsgrowincomplexity,lifelongtestingwillinevitablylead their widespread adoption in prior art, (2) the diverse set
toasurgeinevaluationcostswhenbenchmarkingalargeset ofmodelstrainedonthem,and(3)thepresenceofnumer-
ofincreasinglyexpensivemodelsagainstanever-growing ous dataset variants with the same set of labels, encom-
collectionoftestsamples(SardanaandFrankle,2023;De- passing distribution shifts (Barbu et al., 2019), temporal
hghani et al., 2021). Can we reduce this evaluation cost variations(ShiraliandHardt,2023),andadversarialsam-
whileminimisingthepredictionerror? ples(Hendrycksetal.,2021c).
EfficientModelEvaluation. Wedevelopalgorithmsfor Notethatwhileourcurrentlifelongbenchmarksarebased
efficientevaluationinlifelongbenchmarksbydrawingin- on two datasets, our framework can generally be applied
spiration from the field of computerized adaptive testing toanybroaderrangeofdatasets. Wedescribetheprecise
(CAT)(VanderLindenandGlas,2000),whichcangenerate construction of our datasets below. See Table 1 for key
examsliketheGREandSATfromanever-expandingpool statisticsandadetailedbreakdown.
of questions. Unlike traditional tests where all questions
Lifelong-CIFAR10. Wecombine22domainsofdifferent
mustbeanswered,CATadaptivelysub-samplesquestions
CIFAR10-like datasets comprising samples applied with
based on examinee responses. This approach efficiently
varioussyntheticdistributionshifts,syntheticsamplesgen-
gaugesproficiencywithfarfewerquestions,whilemaintain-
eratedbydiffusionmodels,andsamplesqueriedfromdif-
ingassessmentaccuracy. Atthesametime,astesttakers
ferent search engines using different colors and domains.
continuetakingthetests,thequestionpoolgetsmoreaccu-
Wededuplicateourdatasettoensureuniquenessanddown-
ratelycalibrated,reinforcingthis“lifelongtestingpool”.
sampleallimagestothestandardCIFAR10resolutionof
Similarly,inourlifelongbenchmarkingframework,weaim 32×32. Ourfinaldatasetconsistsof1.69millionsamples.
toevaluatetheclassificationabilityofnewmodelswithout
Lifelong-ImageNet. WesourceourtestsamplesfromIma-
testing them on all samples, instead selecting a subset of
geNetanditscorrespondingvariants. SimilartoLifelong-
samplestoevaluatemodels. Weproposeamethodnamed
CIFAR10,ourbenchmarkisdesignedforincreasedsample
Sort&Search(S&S),whichreusespastmodelevaluations
diversity(43uniquedomains)whileoperatingonthesame
onasamplesetthroughdynamicprogrammingtoenable
ImageNetclassset. Weincludesamplessourcedfromdif-
efficientevaluationofnew,incomingmodels. S&Soperates
ferentweb-enginesandgeneratedusingdiffusionmodels.
by first ranking test samples by their difficulty, done effi-
OurfinalLifelong-ImageNetcontains1.98millionsamples.
2LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Table1.OverviewofourLifelongBenchmarks.Welisttheconstituentsourcedatasets(deduplicated)andtheirstatisticsforconstructing
ourlifelongbenchmarkshere.Ourbenchmarksencompassawide-rangeofnaturalandsyntheticdomains,sourcesanddistributionshifts,
makingforacomprehensivelifelongtestbed.
Dataset #TestSamples #Domains #UniqueSources Synthetic/Natural Corrupted/Clean
Lifelong-CIFAR10 1,697,682 22 9 Both Both
CIFAR10.1(Rechtetal.,2018) 2,000 1 1 Natural Clean
CIFAR10(Krizhevskyetal.,2009) 10,000 1 1 Natural Clean
CIFAR10.2(Luetal.,2020) 12,000 1 1 Natural Clean
CINIC10(Darlowetal.,2018) 210,000 1 1 Natural Clean
CIFAR10-W(Sunetal.,2023) 513,682 3 8 Both Clean
CIFAR10-C(Hendrycksetal.,2021b) 950,000 19 1 Natural Corrupted
Lifelong-ImageNet 1,986,310 43 9 Both Both
ImageNet-A(Hendrycksetal.,2021c) 7,500 1 3 Natural Clean
ObjectNet(Barbuetal.,2019) 18,514 1 1 Natural Clean
OpenImagesNet(Kuznetsovaetal.,2020) 23,104 1 1 Natural Clean
ImageNet-V2(Rechtetal.,2019) 30,000 1 1 Natural Clean
ImageNet-R(Hendrycksetal.,2021a) 30,000 13 1 Natural Clean
ImageNet(Dengetal.,2009) 50,000 1 1 Natural Clean
Greyscale-ImageNet(Taorietal.,2020) 50,000 1 1 Natural Clean
StylizedImageNet(Geirhosetal.,2018) 50,000 1 1 Synthetic Corrupted
ImageNet-Sketch(Wangetal.,2019b) 50,889 1 1 Natural Clean
SDNet(BansalandGrover,2023) 98,706 19 1 Synthetic Clean
LaionNet(ShiraliandHardt,2023) 677,597 1 1 Natural Clean
ImageNet-C(HendrycksandDietterich,2019) 900,000 19 1 Natural Corrupted
3.LifelongBenchmarks: Formulation, a lifelong benchmark B, how can we efficiently compute
ChallengesandApproach metrics()eachtimeweinsertnewmodelsintoM( 2 )
ornewlabelledsamplesintoD( 1 )?
Inthissection,weformalisetheobjectiveoflifelongbench-
markinganddescribethekeychallengesitraises. Approach. Ourapproachisunderpinnedbytwokeyideas.
First, we augment B with an instance-level prediction
Formulation. Let D=((x ,y ),...,(x ,y )) denote an
1 1 n n cache to amortise inference costs across evaluations, ef-
orderedcollectionoflabelledexamples,sampledfromthe
fectivelyexchanging(costly)computationfor(moreafford-
underlying task distribution of interest P(X×Y). Here, able)storage(Prabhuetal.,2023)1. Second, wepropose
x ∈X denotestheithdatasampleandy ∈Ydenotesthecor-
i i strategies to efficiently populate the cache with new pre-
respondinglabel. LetM=(f ,...,f )denoteanordered
1 m dictions through judicious sampling and inference. The
collection of models where each model, f:X→Y, maps cacheisinstantiatedasamatrixA∈{0,1}|M|×|D|where
data samples to predicted labels. A lifelong benchmark, A(i,j)≜I[f (x )=y ]. Givensuchacache,metrics()
i j j
B=(D,M,insert ,insert ,metrics),augments
D M canbecomputedtriviallybyrow-wiseaveragingA. Our
DandMwiththreeoperations:
methodologyisillustratedinFig.2.
1 insert ((x′,y′)) inserts a new labelled example
D
(x′,y′)intoD. Inserting∆mmodels( 2 insert M). Supposethat∆m
2 insert (f′)insertsanewmodelf′intoM. newmodelshavebeendevelopedaftertheinitialcreationof
M
thebenchmark. WewishtoinsertthesenewmodelsintoM
3 metrics()returnsa|M|-dimensionalvectorestimat-
andupdatethecacheaccordingly. Anaiveapproachwould
ingeachmodel’sperformanceonthetaskofinterest.
betodosobyevaluatingthe∆mmodelsonall|D|samples.
Key challenges. To resist overfitting and provide util- Giventhehighcostofthisapproachwhen|D|growslarge,
ity to the research community, we want both the model we instead propose to select a small subset of n′ ≪ |D|
collection, M, and sample collection, D, to expand over samplesforevaluation. Thesearechosenwiththegoalof
time. To enable this, we can instantiate a “naive” imple- enablingaccuratepredictionoftheremainingcacheentries.
mentationofthemetrics()operation( 3 )bysimplyre-
Inserting∆nsamples( 1 insert ). Oursecondchal-
evaluatingeverymodeloneverysampleaftereachcallto D
lengeariseswhenweobtainnew∆nlabelleddataexamples.
insert ( 2 )orinsert ( 1 ). However,suchastrat-
M D
egyexhibitsO(|D||M|)runtimecomplexityforeachcall 1Notethatthebenefitsofourstrategydependontaskandmodel
tometrics(),renderingbenchmarkevaluationinfeasible characteristics:theratioofcomputationtopredictionvectorsize
asDandBgrow,hencepreventingthepracticaladoptionof andtherelativecostsofcomputeandstorage. Ourapproachis
thelifelongbenchmarkingparadigm. Thecentralquestion well-suitedtomoderndeeplearningmodelsthatemploysignificant
computationforeachpredictionandproducecompactinference
consideredbythisworkisthereforethefollowing: Given
artefacts.
3LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Samples New Model Sample Pool
x x x 1 0 . . . 0
1 2 n
select subset 0 0 . . . 0
. . .
of size n' . . .
f m+1 {x 1 , x 2 ,…, x n} 1 1 . . . 1
f 1 0 . . . 0
1 eval on subset
Efficient Model Evaluation Predictions?
f 0 0 . . . 0
2
New Sample Existing Models 1 0 . . . 0
. . . 0 0 . . . 0
select subset
f 1 1 . . . 1 . . . m of size m'
m ✕ n x {f , f ,…, f } 1 1 . . . 1
n+1 1 2 m
Initial Accuracy Predictions eval on subset
Efficient Insertion
Figure2.ProposedLifelongBenchmarkingsetup.Assumeaccesstoaninitialpoolofnsamplesandmmodelsthathavebeenevaluated
onthesesamples(left).Ourgoalistoefficientlyevaluateanewmodel( 2 insert )atsub-linearcost(righttop)andefficientlyinsert
M
anewsampleintothelifelongbenchmark( 1 insert )bydeterminingsampledifficultyatsub-linearcost(rightbottom).
D
WeseektoinsertthesesamplesintoDandupdatethecache sets(seeSection5forempiricalresults).
accordingly. Anaiveapproachentailsevaluatingall|M|
modelsonthe∆nnewexamples. Asabove,tosubstantially
4.EfficientBenchmarkingwithSort&Search
reducecost,weselectasmallsubsetofm′ ≪|M|models
with the objective of accurately predicting the remaining Inspiredbythecomputerizedadaptivetesting(VanderLin-
cacheentriescorrespondingtothenew∆nsamples. denandGlas,2000)paradigm,inthissection,weproposean
efficientevaluationframeworkforlifelong-benchmarking:
RelatedWork. Whilethelifelongbenchmarkingsetupin-
Sort&Search(S&S),consistingoftwokeycomponents:(1)
troducedhasreceivedlimitedattention,thesub-challenge
Rankingtestsamplesfromtheentiredatasetpoolaccording
of efficiently evaluating models has received more focus.
totheirdifficulty2,i.e.,Sortand(2)Samplingasubsetfrom
Concretely, this maps to the problem of insert ( 2 )
M the pool to predict performance on, i.e., Search. We aim
withinourframework. Wecomprehensivelydrawconnec-
tosolvethetwokeyoperationsthatwenotedinSection3
tionsacrossdifferentresearchdirectionsintheAppendix
( 1 insert and 2 insert )withourframework. We
and briefly present the most similar works here. Model D D
nowdescribetheobjectiveandalgorithmsusedinS&S.
Spider(Zhangetal.,2023)efficientlyranksmodelsfrom
apre-trainedmodelzoo. LOVM(Zoharetal.,2023)and
4.1.RankingbySort
Flash-HELM (Perlitz et al., 2023) similarly rank founda-
tionmodelsefficientlyonunseendatasets. However,these Setup. We recall that our lifelong benchmark pool con-
approachespredictdataset-levelmetricsratherthaninstance- sists of evaluations of |M| models on |D| samples. For
level metrics, and thereby cannot be used in our setup to easeofreference,say|M|=mand|D|=n. Forourmethod,
growthepredictioncacheefficiently. given each model f , i ∈ {1,..,m}, we use the binary
i
accuracy prediction per sample, across all n samples ob-
Concurrent to our work, Anchor Point Sampling (Vivek
taininga =[p ,p ...,p ]. Here,p ∈{0,1}represents
etal.,2023)andIRT-Clustering(Poloetal.,2024)bothpro- i i1 i2 in ij
whether the model f classified the sample x correctly.
poseefficientinstance-levelevaluationsbycreatingsmaller i j
Thus,formmodelsandnevaluationsamples,weconstruct
core-setsfromtestdata. Theyintroduceprincipledmethods
abinarymatrixA ∈ {0,1}m×n byrow-wisestackingall
basedonclusteringanditemresponsetheory(Baker,2001)
theaccuracypredictionsa (seeFig.2left).
toobtainsample-wiseaccuracypredictions. However,their i
methodsrequirememoryandtimecomplexityofO(|D|2)
Goal. GivenadatamatrixA,wewanttoobtainaranked
withthenumberofdatasamples,preventingcomparisons order (from easy to hard) for the columns of A, which
on datasets bigger than a few thousand samples. This is represent the samples. This sorted order (Sort) can later
infeasible,requiringwellover10TBofRAM,forourlife- be used for efficient prediction on new incoming models
longbenchmarkshavingover1.5milliontestsampleseach. (Search).Here,thegoalistofindthebestglobalpermutation
In contrast, our novel Sort & Search approach, requires
memory and time complexity of O(|D|log|D|) with the 2“Difficult”isdefinedasifasamplex iiseasierthanasample
x thenatleastequalnumberofmodelspredictx correctlyasthe
numberofsamples, andcan scaleuptobillion-sizedtest j i
numberofmodelspredictingx correctly(Baldocketal.,2021).
j
4
sledoM
. . . . . . . . . . . .
. . .
. . .
. . .
. . .
. . .
. . .
Predictions?LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
def sort_by_sum(A): def uniform_sampling(query, num_p):
sum_ranking = A.sum(axis=0) # idx -> num_p uniformly sampled points
order = np.flip(np.argsort(sum_ranking)) idx = np.arange(0, len(query),
return order len(query)//num_p)[1:]
return idx
def two_stage_sort_by_sum(A, idx):
#Step 1: Sum def dp_search(query):
order = sort_by_sum(A) # query is 1 x k (from a row of PA)
#Step 1: Search # (k can be assigned := n, n', m, m')
thresh = dp_search(A[:, order]) query[query==0] = -1
cumsum = np.cumsum(query)
#Iterate over bins idx = np.argmax(cumsum)
bins_ordered = sum_bins[order] return idx/len(query)
uniq_bins = np.unique(bins_ordered) # threshold as % of length, transfers n' -> n size
for u_bin in uniq_bins: Listing2: AlgorithmsforOptimizingYgivenP
idx = np.nonzero(bins_ordered==u_bin)[0]
bin_thresh = np.nonzero(np.all([[bins_ordered
(cid:44)→ >= idx.min()], [bins_ordered <=
(cid:44)→ idx.max()]], axis=0))[1]
At = A[thresh][:, order[idx]] 4.1.1.OPTIMIZINGPGIVENY
#Step 2: Sum
new_order = sort_by_sum(At)
# Replace current ordering within new in bin WeseefromEq.(1)thatPisbinary. Thismakesfinding
order[idx] = order[idx[new_order]] theoptimalP∗ anNP-Hardproblem(YuanandGhanem,
return order
2016). Hence,wediscusshowtosimplifythesub-problem.
Listing1: AlgorithmsforOptimizingPgivenY We first present an algorithm to solve the case where we
canordersamplesinastrictlydecreasingorderofdifficulty,
measuredbyhowmanymodelsclassifieditcorrectly( 1 ).
However,samplescanneverbearrangedasstrictlydecreas-
matrix P ∈ {0,1}n×n, a binary matrix, such that AP
ing in practice. Subsequently, we present one alternative
permutes the columns of A so that we can rank samples
whichcomputessoftconfidences,whichallowsthestrictly
fromeasy(all1sacrossmodels)tohard (all0sacrossall
decreasingconstrainttohold( 2 ). Athirdalternativeal-
models). We say this has a minimum distance from the
gorithmweexploreremovestheintroducedconstraintofa
optimalrankedaccuracypredictionmatrixY ∈{0,1}m×n,
strictlydecreasingorder( 3 ).
formallydefinedas:
P∗,Y∗ =argmin ∥AP−Y∥, 1 SortingbySum. Wediscusshowtoordersamplesif
P,Y
theyfollowastrictlydecreasingorderofdifficulty.Formally,
s.t. P∈{0,1}n×n,P1 =1 ,1⊤P=1 ,
n n n n (1) considering elements column-wise, the difficulty of each
if Y ij =1,thenY ij′ =1 ∀j′ ≤j, sample(acolumn)isinverselyproportionaltothenumber
if Y =0,thenY =0 ∀j′ ≥j. of1sinthatcolumni.e.,more1sinacolumnindicatesmore
ij ij′
modelsclassifythissamplecorrectly. Wecanordersam-
The constraints P1 = 1 ,1⊤P = 1 are sufficient to
n n n n plesindecreasingorderofdifficultybyasimplealgorithm
enforcethatPisapermutationmatrix.Therankedaccuracy
detailedinListing1(sort by sum)—intuitively,thisal-
predictionmatrixY iscreatedbyarow-wiseapplication
gorithmsortssamplesfromeasy(more1s)tohard(less1s)
of a thresholding operator for every row in Y separately.
bysortingthesumvectoracrossrowspercolumn. Wecall
Intuitively,ifthethresholdfortheith rowisk,thentheith
thismethodSortingbySum,whichreturnsanorderingover
row is of the form [1⊤,0⊤ ] where 1 is a vector of all
k n−k k samples(whichcantriviallybeconvertedtothepermutation
onesofsizekand0 isazerovectorofsizen−k. In
n−k matrixP∗). However,theassumptionofstrictlydecreasing
everyrow,allsamplesbeforetherow-wisethresholdkare
orderofdifficultyisunrealisticasthenumberofsamplesis
predicted to be correctly classified (easy) and those after
usuallyfarlargerthanthenumberofmodels. Hence,itis
areincorrectlyclassified(hard)forthemodelcorresponding
guaranteedthatmanysampleswillhavethesamelevelof
to the row. The informal explanation of the optimization
difficultybythepigeonholeprinciple(Ajtai,1994).
probleminEquation1istofindanorderingofsamplessuch
thaterrorintroducedbythresholdingisminimized. 2 Sorting by Confidence Sum. One method to have a
strictly decreasing order is to relax the constraint on the
Giventhisoptimizationproblem, wenextdiscusshowto
samples of a = [p ,p ...,p ] from p ∈ {0,1} to
i i1 i2 in ij
solve it. While the goal of this optimization problem is
p ∈ [0,1], anduseconfidenceofthegroundtruthclass.
findingtheoptimalpermutationP∗,westillneedtojointly ij
Thismodificationallowsallexamplestobeunique,allowing
solveforP,Yhere. Wewillfindasolutionbyalternating
SortingbySum( 1 )tobethebestsolution,andpotentially
betweenoptimizingPkeepingYconstantandoptimizing
enablemoresampleefficientranking.
Y keeping P constant, with the goal of finding the best
solution P∗, in an EM-style algorithm. We now present 3 Recursive Sorting by Sum. Another alternative is
algorithmsforoptimizingthetwosubproblemsindetail. relaxingtheequaldifficultyassumptioninAlgorithm 1 .
5LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Anaturalquestionis: Howdoesoneordersampleswhich raciesforeachnewmodelf oneachofthensamples.
m+1
haveequalnumberofmodelspredictingthemcorrectly,i.e., Wewilllatershowthatthesamepipelineandalgorithms
twocolumnsofAwithequalnumberof1s? workwellfortheproblemofnewincomingsamples∆n.
Weproposeaniterativesolution:ateachstep,ordersamples Goal. Given the permutation matrix P∗ and ∆m new
of equal difficulty by alternatively optimizing P keeping models,wewanttopredicttheaccuracyacrossallnsam-
Y constant by applying Algorithm 1 and optimizing Y ples per model, i.e., predict the accuracy matrix Y ∈
∆m
keeping P constant by DP-Search algorithm (described {0,1}∆m×n. Theprimarychallengeistodothisbyonly
next). Therecursiveaspectisdividingthevectorintosub- evaluatingonasfewsamplesn′ ≪nselectedpermodel.
sets, where each subset consists of samples which have
WefirstrestatethattheconstraintsonY inEq.(1)imply
the same sum. Within each subset, we reorder points by
athresholdingoperatorofindexfrom{1,...,n}forevery
onlyconsideringthethresholdsobtainedwhenoptimizing
rowinY ,i.e.,everymodelin∆mindependently. Since
Y given P which fall within this region and recursively ∆m
theproblemisseparableperrow,weconsidertheproblem
applyingthealternatingminimization. Weprovidetheal-
of optimizing the first new model y ∈ {0,1}1×n in-
gorithm for two iterations for an illustration in Listing 1 m+1
dependentlyhere. Similarly,wedenotethecorresponding
(two stage sort by sum). Note that this strictly im-
groundtruthvectorbya ,createdbyevaluatingthenew
provesthesolutionateachrecursiondepth. Weadditionally m+1
modelonallnsamples,whichwillbeusedforevaluating
note that ties are broken by preferring the model which
predictionsy .
minimizeserrorthemost. m+1
Inthissection,weanswerthetwoquestions. (i)Howtofind
4.1.2.OPTIMIZINGY GIVENAP thebest-rankedaccuracypredictionvectory m+1? (ii)How
goodistherankedaccuracypredictionvectory ?
Here, we discuss how to optimize the prediction matrix m+1
Y. Were-iteratethatwewanttofindarow-wisethreshold (i)Howtogettheoptimaly ? Ourgoalhereistogen-
m+1
k minimizing the error with the matrix AP for a given eratethesample-wisepredictionvectory ∈{0,1}1×n.
m+1
permutation P. To optimize Y given a P, we propose Wedivideitintotwosubtasks: selectionandoptimization.
analgorithmbasedondynamicprogramming,calledDP- The selection task is to select the best n′ observations to
Search,whichoperatesrow-wiseoneachrowy ,detailed sample. Theoptimizationtaskis,giventhen′observations
i
inListing2(dp search). Givenarow, itcomputesthe a′ ∈ {0,1}1×n′ howtogeneratethepredictionvector
m+1
differencebetweennumberof1sandnumberof0sforeach y ∈{0,1}1×n.
m+1
indexbasedonaprefixsumstructure. Duetotheprefixsum
Subtask1: HowtoSelectSamples? Theselectiontaskin-
structure,foraninputofsizen,thedynamicprogramming
volvesfindingthebestn′observationsforminga′. Wenote
approachreducesthetimecomplexityfromquadraticO(n2)
thatanyrankedsolutionweobtainusingthisarrayneeds
tolinearO(n). Theoptimalthresholdk isthemaximum
tobeinterpolatedfromn′ pointstonpoints,andusethis
value in this vector. The vector y is simply [1⊤,0⊤ ]
i k n−k intuitiontosamplen′points. Asimplesolutionistosample
where1 isavectorofallonesofsizekand0 isazero
k n−k pointssuchthatanythresholdfoundminimizesthediffer-
vectorofsizen−k. DP-Searchisguaranteedtoreturnthe
encebetweentheactualthresholdandathresholdpredicted
globallyoptimalsolution,definedas:
byoursetofn′,i.e.,samplen′pointsuniformly,providing
Theorem 4.1. Optimality of Y given P. For any given the algorithm in Listing 2 (uniform sampling). We
a i ∈{0,1}1×nandP,theDP-Searchalgorithmreturnsan alsocompareempiricallywithapurerandomsamplingap-
orderedpredictionvectory i ∈{0,1}1×nwhichisaglobal proachinSection5.
minimumof∥a P−y ∥ .
i i 1
Subtask2: Optimizingy . Here,wediscussthatgiven
m+1
TheDP-Searchalgorithmwhenappliedrow-wiseindepen- then′observationsa′ m+1 ∈{0,1}1×n′ howtogeneratethe
dently returns the optimal Y given P. Now, having opti- prediction vector y m+1 ∈ {0,1}1×n. We use the thresh-
mizedtherankingproblem,wehaveapermuationP∗ from oldgivenbytheDP-Search(seeListing2)andobtainthe
thedatamatrixindicatingtheorderofthesamplesbased threshold,givenintermsoffractionofsamplesin|a′ m+1|.
ondifficulty. InthenextsectionweuseP∗towardseither Weextrapolatethisthresholdfromn′tonpoints,toobtain
evaluatingnewmodelsoraddingnewsamplesefficiently. thethresholdforthepredictionvectory m+1. Thepredicted
vectory issimply[1⊤,0⊤ ]where1 isavectorof
m+1 k n−k k
allonesofsizekand0 isazerovectorofsizen−k.
4.2.EfficientSelectionbySearch n−k
GiventhatwehavefoundthebestP∗inthesortingphase, Having studied how to generate the predictions, we next
describehowtoevaluatethem.
weassumethisorderingofdifficultyofsamplesgeneralizes
tonewincomingmodels∆m. Sincetheproblemissepara- (ii) How good are my predictions? Given a prediction
bleineachmodel,itsufficestopredictsample-wiseaccu-
6LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Compute Saved Compute Saved
106 105 104 103 102 101 106 105 104 103 102 101
0.21 0.72
0.62 0.17
0.60 Normalized Agreement 00 .. 12 90 00 .. 67 80 Normalized Agreement 0.16 E agP g o =w 1e 5r .- 9l a *w (n f 'i )t -0: .18 E agP go =w 1e 5r .- 6l a *w (n f 'i )t -: 0.23
0.58 Mean Absolute Error 0.18 0.66 Mean Absolute Error 0.15
0.14
0.56 0.17
0.64
0.54 0.16 0.13
101 102 103 104 101 102 103 104
Sampling Budget n' Sampling Budget n'
(a) Lifelong-CIFAR10 (b) Lifelong-ImageNet (c) Lifelong-CIFAR10 (d) Lifelong-ImageNet
Figure3.MainResults. Figure(a,b)Weachieveupto99%cost-savingsfordoingmodelevaluationonbothLifelong-ImageNetand
Lifelong-CIFAR10showcasingtheefficiencyofourSort&Searchmethod.InFigure(c,d)Power-lawfitsontheobservedabsolute-accuracy
differenceerrors(E )andsamplingbudget(n′)relationshipreveallargeexponentssuggestingveryquickconvergence.
agg
vector y , we can compute the Mean-Absolute Error othersamplesinthebenchmark. Toefficientlydetermine
m+1
(MAE), given by E(a ,y ). It is computed using difficulty by only evaluating m′ ≪ m models, a ranking
m+1 m+1
theHammingdistancetothegroundtruthvectora ∈ overmodelsisrequiredtoenableoptimallysub-sampling
m+1
{0,1}1×n,formallydefinedas: a subset of m′ models. This problem is quite similar in
E(a ,y )=∥a P∗−y ∥ (2) structuretothepreviouslydiscussedadditionofnewmodels,
m+1 m+1 m+1 m+1 1
wherewehadtoevaluateusingasubsetofn′ ≪nsamples.
However,inthissection,wewanttonormalizebytheagree-
Howdoweconnectthetwoproblems?
ment between predictions and ground truth explained by
chance alone (refer to Geirhos et al. (2020) for analysis We recast the same optimization objectives as described
in-depth). Weillustratethiswithanexamplewheremod- inEq.(1),butreplaceAwithA⊤andYwithY⊤. Inthis
elshave90%accuracyonabinarytaskwithequalnumber case,Eq.(1)wouldhaveA⊤P,whichwouldsortmodels,
ofsamplesperclass. Inthatcase, giventworandompre- insteadofsamples,basedontheiraggregatesumoversam-
dictions,82%3 ofthesampleswillagreebychancealone. ples(i.e.,accuracy)optimizedusingAlgorithm 1 toobtain
Thegeneralmetricforagreementbetweenanygroundtruth P∗,orderingthemodelsfromclassifyingleastsamplescor-
vectora andapredictionvectory bychanceisgivenby: rectly to most samples correctly. Here, Algorithm 1 is
i i
E (a ,y )= ∥a i∥ 1∥y i∥ 1 sufficient,withoutneedingtosolvethejointoptimization
rand i i n n ( 3 )becauseaccuracies(sumacrossrows)areuniqueasthe
(cid:18) (cid:19)(cid:18) (cid:19) (3)
∥a ∥ ∥y ∥ numberofsamplesistypicallymuchlargerthanthenumber
+ 1− i 1 1− i 1 .
n n ofmodels.
ThenormalizedagreementisdefinedbytheCohen’sKappa
Incaseofnewincomingsamples∆n,wesimilarlywould
(Cohen,1960)givenas:
treat every sample independently and optimize the pre-
(1−E(a ,y ))−E (a ,y )
κ(a ,y )= i i rand i i . (4) dictedarrayy⊤ usingEfficientSelectionbySearch(Sec-
i i 1−E (a ,y ) n+1
rand i i tion4.2).
where0≤κ(a ,y )≤1.
i i
The intuition for this normalization is described in detail 5.Experiments
inGeirhosetal.(2020). Wemeasurebothmean-absolute
error(giveninEq.(2))andourdefinednormalizedagree- Todemonstrateourframeworkempirically, weshowcase
ment(giveninEq.(4))assample-wisemetricsinthiswork. experiments on our two tasks: 1 efficient estimation of
Notethatsmallermean-averageerrorE isbetterbuthigher new sample difficulties (insert ) and 2 efficient per-
D
normalizedagreementκisbetter. formanceevaluationofnewmodels(insert ). Wethen
M
provideacomprehensiveanalysisofvariousdesignchoices
Sofar, wehaveonlydiscussedtheefficientevaluationof
withinourSort&Searchframework.
∆mnewmodels( 2 insert ).Howdoweapproachthe
M
problemwhenwewanttoefficientlyextendthebenchmark,
adding∆nnewsamples( 1 insert )? 5.1.ExperimentalDetails
D
Model Space. For Lifelong-CIFAR10, we use 31,250
4.3.EfficientInsertionofNewSamples(insert D) CIFAR-10 pre-trained models from the NATS-Bench-
Topology-searchspace(Dongetal.,2021). ForLifelong-
Toaddnewsamplesintoourlifelongbenchmarkefficiently,
ImageNet, we use 167 ImageNet-1K and ImageNet-21K
we have to estimate their “difficulty” with respect to the
pre-trainedmodels,sourcedprimarilyfromtimm(Wight-
30.82=0.9×0.9+0.1×0.1 man,2019)andimagenet-testbed(Taorietal.,2020).
7
tnemeergA
dezilamroN
tnemroererErg
.Asb
dAe znialaemMroN
rorrE .sbA
naeMLifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Lifelong-CIFAR10
Lifelong-ImageNet
Figure4.Estimatedv/sGround-Truthaccuracies.Fordifferentsamplingbudgets(n′=64−1024),ourestimatedaccuraciesfor117
models(Lifelong-ImageNet)and25,250models(Lifelong-CIFAR10)aresurprisinglyclosetoground-truthaccuracies(ρ=0.86−0.97).
SampleAdditionSplit( 1 insert ). Tostudyefficient varyingnumberofsamplingbudgetsn′i.e.,werunourS&S
D
estimationofnewsampledifficultiesonLifelong-CIFAR10, frameworkover13differentsamplingbudgets: {8,16,32,
we hold-out CIFAR-10W (Sun et al., 2023) samples for 64,128,256,512,1024,2048,4096,8192,16384,32768}
evaluation(∼500,000samples)andusetherest∼1.2mil- onbothLifelong-ImageNetandLifelong-CIFAR10.
lionsamplesforsorting. Wedonotperformexperiments
Unlessotherwisespecified,ourmainresultsinSections5.2
onthisproblemforLifelong-Imagenet—sincethenumber
and5.3usethesimpleSortingbySumalgorithm( 1 ,List-
ofmodelsisquitesmall(167intotal),directlyevaluating
ing1)forobtainingP∗anduniformsamplingforthesample
all models is relatively efficient, as opposed to the more
budgetn′. Weanalyzeandablatetheotherdesignchoices
challengingLifelong-CIFAR10scenariowhereevaluation
inSection5.4. Wenowpresentourmainresults.
on31,250modelsisexpensiveanditispracticallypossible
toreducethenumberofmodelsevaluatedpernewsample. KeyResult1: ExtremeCost-Efficiency. FromFigs.3(a)
and3(b),weobservethatourapproachconvergestoavery
Model Evaluation Split ( 2 insert ). To study ef-
M high normalized agreement and low mean-absolute error
ficient evaluation of new models, we split the model set
with1/1000thenumberofevaluationsamples,leadingtoex-
fortheLifelong-CIFAR10benchmarkintoarandomlyse-
tremecostsavingsatinferencetime(from180GPUdaysto
lectedsubsetof6,000modelsfororderingthesamples(i.e.,
5GPUhoursonasingleA100-80GBGPU)4.Thisconsis-
Sort)andevaluatemetricsontheremaining25,250models
tentlyholdsacrossbothdatasetsonallthreemetrics: Nor-
(i.e.,Search). ForLifelong-Imagenet,weuse50randomly
malizedAgreement,MeanAbsoluteError,andAbsolute-
selected models for ordering the samples (i.e., Sort) and
accuracydifference.
evaluateon117models(i.e.,Search).
KeyResult2: PredictionErrorScalesasaPower-Law.
Metrics( 3 metrics()). Wemeasureerrorsbetweenes-
WefurtheranalysetheobservedE againstthesampling
timatedpredictionsforeachnewmodely andground- agg
m+1 budget(n′)relationshipbyfittingpower-lawsinFigs.3(c)
truthpredictionsa independentlyusingbothinstance-
m+1 and3(d). Thepower-lawstaketheformE =cn′p,where
level metrics and dataset-level metrics. For instance- agg
cisthescalingwidthandpistheexponentialcoefficient.We
level predictions, we measure the mean-average error
findthatthepower-lawshavelargeexponentialcoefficients,
E(a ,y )usingEq.(2)alongwiththenormalized
m+1 m+1 p=−0.18forLifelong-CIFAR10andp=−0.23forLifelong-
agreement κ using Eq. (4). For dataset-level metrics, we
ImageNet. Thisfurtherdemonstratesthesurprisinglyhigh
measure the absolute difference between estimated and
sample-efficiencyobtainedbySort&Search(S&S).
groundtruthaccuracies, E
agg
= |(|ym+1|−|am+1|)|/n. This
givesusaglobalmetricthatdoesnottakeintoaccountin- KeyResult3: HighlyAccuratePerformanceEstimation.
dividualsample-levelcorrespondencesbetweeny and WenotefromFig.4thatS&Sisabletoveryaccuratelypre-
m+1
a ,butrathersimplythedifferencebetweentheaggre- dicttheground-truthaccuraciesofmodels. Atasampling
m+1
gatesumofcorrectpredictions.
4The “compute saved” axis in the plots is computed as
n. Effective compute savings are: In Lifelong-CIFAR10,
5.2.ModelPerformanceEstimation(insert M) wn′ e do 25,250×1,697,682 evaluations in the full evaluation
v/s 25,250×2,048 in our evaluation. Similarly, for Lifelong-
Inthissetofexperiments,weevaluatethepredictivepower
ImageNet, we perform 117×1,986,310 v/s 117×2,048 evalu-
ofS&Sforevaluatingnewmodels( 2 )whensubjectedtoa ations.
8LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Compute Saved
106 105 104 103 102 101
Sum
0.275 Confidence-Sum 0.70 0.725 0.70 0.250 0.700
0.225 0.65 0.675 0.65
0.650 0.200 m=10 0.60 m=20 0.625 Sum 0.60
0.175 m=50 Recursive Sum Uniform
m=100 0.600 Confidence Sum Random
0.150 0.55 0.575 0.55
101 102 103 101 102 103 104 101 102 103 104 101 102 103 104
Sampling Budget m' Sampling Budget n' Sampling Budget n' Sampling Budget n'
(a) SampleDifficultyEstimation (b) Analysis:#Rankingmodels (c) Analysis:Rankingmethods (d) Analysis:Samplingmethods
Figure5.AdditionalAnalyses. Figure(a)WeachieveaccuratesampledifficultyestimatesonLifelong-CIFAR10(<0.15MAE)ata
fractionofthetotalnumberofmodelstobeevaluated,therebyenablinganefficientinsertionofnewsamplesintotheorderedsetof
samplesinthebenchmark.InFigures(b,c,d),weanalysethreedesignchoiceaxesforabetterunderstandingoftheS&Smethodusingthe
Lifelong-Imagenetdataset.
Lifelong-CIFAR10 Lifelong-ImageNet
- - - - Total Error (E) - - - - Total Error (E)
—— Epistemic Error (Eepistemic) —— Epistemic Error (Eepistemic)
Aleatoric Error Aleatoric Error
Figure6.ErrorDecompositionAnalysisonLifelong-CIFAR10(left)andLifelong-ImageNet(right).Weobservethatepistemicerror
(solidline)dropsto0withinonly100to1000samplesacrossbothdatasets,indicatingthiserrorcannotbereducedfurtherbybetter
samplingmethods.ThetotalerrorEisalmostentirelyirreducible(Aleatoric),inducedbecausenewmodelsdonotperfectlyalignwith
therankingorderP∗.Thissuggestsgeneralizingbeyondasinglerankordering,notbettersamplingstrategies,shouldbethefocusof
subsequentresearchefforts.
budget(n′)ofjust512or1,024samples,ourpredictedaccu- ber of models we use to evaluate our samples over):
raciesalmostexactlymatchthetrueaccuracies,asmeasured {8,16,32,64,128,256,512,1024,2048}. From Fig. 5(a),
bythepearsoncorrelations(0.96forLifelong-CIFAR10and weobservethatbothmethodsconvergequickly—Sorting
0.97forLifelong-ImageNetatasamplingbudgetof1,024). bySum( 1 )reachesamean-absoluteerroroflessthan0.15
Notethatthisperformancepredictionabilityisespecially byonlyevaluatingonm′=64modelsoutof31,250(104×
surprising given these results are aggregated over 25,250 computationsavings). Thisdemonstratesourmethod’sabil-
modelsforLifelong-CIFAR10and117modelsforLifelong- itytoefficientlydeterminesampledifficulty,enablingeffi-
ImageNet,spanningawiderangeofarchitectures,model cientinsertionbackintothelifelong-benchmarkpool.
sizes,andaccuracies. Additionalplotsacrossamorefiner
variationofn′areprovidedintheAppendix. 5.4.BreakingdownSort&Search
WenextnalysethedifferentdesignchoicesusedinourS&S
5.3.SampleDifficultyEstimation(insert )
D
framework,andcomparetheirinducedefficiencygains.
We next showcase results with the complementary task
Varying the Number of Models Used for Ranking.
( 1 ) where for new samples, the goal is to sub-sample
InFig.5(b),weanalysetheeffectofthenumberofmodels
the number of models to evaluate on the new samples,
usedforcomputingtheinitialranking(i.e.,m)onthefinal
for accurately determining sample difficulty. We present
performancepredictiononLifelong-ImageNet. Havingac-
results on this task on the Lifelong-CIFAR10 benchmark
cesstomoremodelsseemstobeakeyfactorinimproving
with two different methods for ranking models5, Sort-
prediction accuracy since using a lower number of mod-
ing by Sum ( 1 ) and Sorting by Confidence Sum ( 2 ).
elsforranking(m=10)convergestoasmallernormalised
We evaluate over different model budgets m′ (the num-
agreement(4%performancedifferenceatconvergencewhen
5Recursivesum( 3 )isnotapplicablehereasallsumvalues usingm=100(blueline)comparedtom=10(redline)). In-
areunique,seeSection4.3. terestingly,thenumberofmodelsmusedforrankingdoes
nothaveanyeffectonthespeedofconvergenceitself(all
9
rorrE
.sbA
naeM
tnemeergA
dezilamroN
tnemeergA
dezilamroN
tnemeergA
dezilamroNLifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
methods roughly converge at the same sampling budget
(n′=2,048)),butratheronlyonthepredictionaccuracy. E (y∗ ,y )=∥y∗ −y ∥. (6)
epistemic m+1 m+1 m+1 m+1
DifferentSortingMethods.Wecomparethethreedifferent
Note that in a similar way, we can also decompose
algorithmsonLifelong-Imagenet: 1 SortingbySum, 2
the normalized agreement metric κ simply by com-
SortingbyConfidenceSum,and 3 SortingbyRecursive puting κ (a ,y ) = κ(a ,y∗ ) and
aleatoric m+1 m+1 m+1 m+1
Sum.FromFig.5(c),wenotenosubstantialbenefitstousing κ (y∗ ,y )=κ(y∗ ,y ).
epistemic m+1 m+1 m+1 m+1
thecontinualrelaxationoftheaccuracypredictionvalues
Results. WeanalysetheeffectivenessofsamplinginLife-
as confidence values, in fact, this degrades the predictive
longCIFAR-10andLifelong-ImageNetbystudyingtheEpis-
accuracy of our method. However, using the multi-step
temic Sampling Error (E ) and Aleatoric Sampling
recursivecorrectionofrankings( 3 )providessignificant epistemic
boosts(2%boostinnormalizedagreementatalln′>1,024) Error(E aleatoric)inFigure6. First,weseethattheepistemic
errorisverylowandquicklyconvergesto0,i.e.,wecon-
duetoitsabilitytolocallycorrectrankingerrorsthatthe
vergetothebestachievableperformancewithinsampling
globalsummethod( 1 )isunabletoaccountfor.
just100to1000samplesonbothdatasets. Theremaining
DifferentSamplingMethods.InFig.5(d),wecomparethe errorafterthatisirreducible,andisprimarilycausedbygen-
methodusedforsub-selectingthedata-samplestoevaluate— eralizationgapsinthepermutationmatrixP∗. Further,we
wecomparebetweenuniformandrandomsampling. Both notethattheRecursiveSumalgorithm( 3 )doesnothelp
methods converge very quickly and at similar budgets to reducethegapasshowninFig.5(c).Thisgapisattributable
their optimal values and start plateauing. Worth noting to new models inherently not following a single ranking
however is that uniform sampling provides large boosts orderacrossallsamples.
overrandomsamplingwhenthesamplingbudgetissmall
(10%betterinabsolutenormalizedagreementatn′=8)—
7.OpenProblems
thiscanbeattributedtoits“diversity-seeking”behaviour
which helps cover samples from all difficulty ranges and
Althoughshowcasingverypromisingresultsinenhancing
hencebetterrepresenttheentirebenchmarkevaluationsam-
theefficiencyofevaluatingLifelongBenchmarks,ourinves-
ples than an unrepresentative random set that is sampled tigationwithS&Sleadstosomeinterestingopenproblems:
fromtherandomsamplingapproach.
(1)One-StepProcess: Currently,ourapproachisrestricted
toone-stepsamplerankingandmodelevaluation,whereas
6.DecomposingtheErrorsofS&S
ideallifelongevaluationwouldneedsimultaneousoptimiza-
Inthissection,weshowcasethattheerrorsofSort&Search tion of these steps. How do we extend our framework to
multi-stepcontinualrankingandevaluation?
can be intuitively decomposed. The total mean absolute
errorE(a m+1,y m+1)canbedecomposedintoacomponent (2)RankingImprecision: Ourerrordecompositionanalysis
irreduciblebyfurthersampling,referredtoastheAleatoric providesconvincingevidence(Section6)thattheordering
SamplingError(E aleatoric),andacomponentwhichcanbe ofsamplesP∗whileevaluatingnewmodelsbottleneckspre-
improvedbyqueryinglargerfractionofsamplesn′,referred
dictionperformance. Generalizingfromimposingasingle
toastheEpistemicSamplingError(E epistemic). sampleorderingP∗tosampleorderingstructures,suchas
AleatoricSamplingError. Lety∗ =y′whenn′ =n, differentclustersofmodelseachwiththeirownorderings
m+1
i.e., itisthebestpredictionobtainableacrossallsubsam- orrejectionframeworksformodelsifitdoesnotalignwith
pledthresholds,aswehaveaccesstothefulla vector. theorderingcoulddramaticallyimprovetheframework.
m+1
However, some error remains between y∗ and a m+1 due (3)IdentifyingDifficultSamples: Findingandlabelingchal-
totheorderingoperation(i.e.,Sort). Thiserror,causedby lenging examples is an essential task for lifelong bench-
errorsinthegeneralizationofthepermutationmatrixP∗
marks,whichisnotthefocusofourwork. Studyinghard
cannotbereducedbyincreasingthesamplebudgetn′.More
or adversarial sample selection approaches with lifelong
formally,wedefinethiserroras: benchmarkingisapromisingdirection. Weprovideanex-
tensivesurveyofrelatedapproachesinthisdirectioninthe
E (a ,y )= min ∥a P∗−y ∥ Appendix.
aleatoric m+1 m+1 m+1 m+1
ym+1 (5)
=∥a P∗−y∗ ∥.
m+1 m+1 8.Conclusion
EpistemicSamplingError. Onthecontrary,thereisagap
between the optimal ranking prediction y∗ and y Inthiswork,weintroducedLifelong-Benchmarks: aframe-
m+1 m+1
with the current sample size n′. This gap, referred to as workfordynamicallyexpandingapooloftestsamples,de-
signedtoenhancetherobustnessofcurrentbenchmarksby
EpistemicSamplingErrorisformallydefinedas:
mitigatingtheissueofoverfittingtospecificdatasetbiases.
10LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
As two instances of this paradigm, we curated Lifelong- AndreiBarbu,DavidMayo,JulianAlverio,WilliamLuo,Christo-
CIFAR-10andLifelong-ImageNetcontainingoveramillion pherWang,DanGutfreund,JoshTenenbaum,andBorisKatz.
Objectnet: A large-scale bias-controlled dataset for pushing
evaluation samples each. To counter the challenge of in-
thelimitsofobjectrecognitionmodels. ConferenceonNeural
creasingevaluationcostsonsuchlarge-scalebenchmarks,
InformationProcessingSystems(NeurIPS),2019.
weproposedanefficientframeworkcalledSort&Search
that leverages previous model predictions to rank and se- EmilyMBender,TimnitGebru,AngelinaMcMillan-Major,and
lectivelyevaluatetestsamples. Ourextensiveexperiments, ShmargaretShmitchell. Onthedangersofstochasticparrots:
Canlanguagemodelsbetoobig? InConferenceonFairness,
involvingover30,000models,demonstratethatourmethod
Accountability,andTransparency(FAccT),2021.
reduces over 99% of evaluation costs. We hope our Life-
longBenchmarkingstrategyspursmorerobustandefficient LucasBeyer,OlivierJHe´naff,AlexanderKolesnikov,Xiaohua
evaluations. Zhai, and Aa¨ron van den Oord. Are we done with ima-
genet? InConferenceonNeuralInformationProcessingSys-
tems(NeurIPS),2021.
Acknowledgements
HaoyangBi,HaipingMa,ZhenyaHuang,YuYin,QiLiu,Enhong
The authors would like to thank (in alphabetic order): Chen, Yu Su, and Shijin Wang. Quality meets diversity: A
Bruno Andreis, C¸ag˘atay Yıldız, Fabio Pizzati, Federico model-agnosticframeworkforcomputerizedadaptivetesting.
D’Agostino, Ori Press, Shashwat Goel, and Shyamgopal InInternationalConferenceonDataMining(ICDM),2020.
Karthik for helpful feedback. AP is funded by Meta AI
YonatanBitton,HritikBansal,JackHessel,RulinShao,Wanrong
Grant No. DFR05540. VUthanks theInternational Max
Zhu,AnasAwadalla,JoshGardner,RohanTaori,andLudwig
PlanckResearchSchoolforIntelligentSystems(IMPRS-IS) Schimdt. Visit-bench: Abenchmarkforvision-languagein-
andtheEuropeanLaboratoryforLearningandIntelligent structionfollowinginspiredbyreal-worlduse. Conferenceon
Systems(ELLIS)PhDprogramforsupport. PTthanksthe NeuralInformationProcessingSystems(NeurIPS),2023.
RoyalAcademyofEngineeringfortheirsupport. ABac-
Nitzan Bitton-Guetta, Yonatan Bitton, Jack Hessel, Ludwig
knowledgestheAmazonResearchAward. SAissupported
Schmidt,YuvalElovici,GabrielStanovsky,andRoySchwartz.
by a Newton Trust Grant. This work was supported by Breaking common sense: Whoops! a vision-and-language
theGermanResearchFoundation(DFG):SFB1233, Ro- benchmarkofsyntheticandcompositionalimages. InProceed-
ingsoftheIEEE/CVFInternationalConferenceonComputer
bustVision: InferencePrinciplesandNeuralMechanisms,
Vision,pages2616–2627,2023.
TP4,projectnumber: 276693517andtheUKRIgrant: Tur-
ing AI Fellowship EP/W002981/1. MB is a member of AvrimBlumandMoritzHardt. Theladder:Areliableleaderboard
theMachineLearningClusterofExcellence,fundedbythe formachinelearningcompetitions. InInternationalConference
DeutscheForschungsgemeinschaft(DFG,GermanResearch onMachineLearning(ICML),2015.
Foundation)underGermany’sExcellenceStrategy–EXC
RishiBommasani,DrewAHudson,EhsanAdeli,RussAltman,
number2064/1–Projectnumber390727645.
Simran Arora, Sydney von Arx, Michael S Bernstein, Jean-
netteBohg,AntoineBosselut,EmmaBrunskill,etal. Onthe
References opportunitiesandrisksoffoundationmodels. arXivpreprint
arXiv:2108.07258,2021.
ChiragAgarwal,DanielD’souza,andSaraHooker. Estimating
exampledifficultyusingvarianceofgradients. InConference FlorianBordes,ShashankShekhar,MarkIbrahim,DianeBoucha-
onComputerVisionandPatternRecognition(CVPR),2022. court,PascalVincent,andAriSMorcos. Pug: Photorealistic
andsemanticallycontrollablesyntheticdataforrepresentation
Miklo´sAjtai. Thecomplexityofthepigeonholeprinciple. Combi- learning. arXivpreprintarXiv:2308.03977,2023.
natorica,14:417–433,1994.
SamuelRBowmanandGeorgeEDahl. Whatwillittaketofix
FrankBBaker. Thebasicsofitemresponsetheory. ERIC,2001. benchmarkinginnaturallanguageunderstanding? InNorth
AmericanChapteroftheAssociationforComputationalLin-
EslamMohamedBakr,PengzhanSun,XiaogianShen,FaizanFa- guistics(NAACL),2021.
rooqKhan,LiErranLi,andMohamedElhoseiny. Hrs-bench:
Holistic,reliableandscalablebenchmarkfortext-to-imagemod- Se´bastienBubeck,VarunChandrasekaran,RonenEldan,Johannes
els. InInternationalConferenceonComputerVision(ICCV), Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee,
2023. Yuanzhi Li, Scott Lundberg, et al. Sparks of artificial gen-
eralintelligence:Earlyexperimentswithgpt-4. arXivpreprint
RobertBaldock,HartmutMaennel,andBehnamNeyshabur. Deep arXiv:2303.12712,2023.
learningthroughthelensofexampledifficulty. Conferenceon
NeuralInformationProcessingSystems(NeurIPS),2021. MuxiChen,YuLi,andQiangXu. Hibug:Onhuman-interpretable
modeldebug. InConferenceonNeuralInformationProcessing
Hritik Bansal and Aditya Grover. Leaving reality to imagina- Systems(NeurIPS),2023.
tion:Robustclassificationviagenerateddatasets. International
ConferenceonLearningRepresentationsWorkshop(ICLR-W), JacobCohen. Acoefficientofagreementfornominalscales. Edu-
2023. cationalandpsychologicalmeasurement,1960.
11LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
CiprianACorneanu,SergioEscalera,andAleixMMartinez.Com- QuentinGarrido,RandallBalestriero,LaurentNajman,andYann
putingthetestingerrorwithoutatestingset. InConferenceon Lecun. Rankme: Assessingthedownstreamperformanceof
ComputerVisionandPatternRecognition(CVPR),2020. pretrained self-supervised representations by their rank. In
InternationalConferenceonMachineLearning(ICML),2023.
LukeNDarlow,ElliotJCrowley,AntreasAntoniou,andAmosJ
Storkey. Cinic-10isnotimagenetorcifar-10. arXivpreprint
RobertGeirhos, PatriciaRubisch, ClaudioMichaelis, Matthias
arXiv:1810.03505,2018.
Bethge,FelixAWichmann,andWielandBrendel. Imagenet-
trainedcnnsarebiasedtowardstexture;increasingshapebias
MostafaDehghani,AnuragArnab,LucasBeyer,AshishVaswani,
improvesaccuracyandrobustness. InInternationalConference
and Yi Tay. The efficiency misnomer. arXiv preprint
onLearningRepresentations(ICLR),2018.
arXiv:2110.12894,2021.
JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLi RobertGeirhos,KristofMeding,andFelixAWichmann. Beyond
Fei-Fei. Imagenet:Alarge-scalehierarchicalimagedatabase. accuracy: quantifyingtrial-by-trialbehaviourofcnnsandhu-
In Conference on Computer Vision and Pattern Recognition mansbymeasuringerrorconsistency. ConferenceonNeural
(CVPR),2009. InformationProcessingSystems(NeurIPS),2020.
Gregd’Eon, Jasond’Eon, JamesRWright, andKevinLeyton- AritraGhoshandAndrewLan.Bobcat:Bileveloptimization-based
Brown.Thespotlight:Ageneralmethodfordiscoveringsystem- computerizedadaptivetesting. InternationalJointConference
aticerrorsindeeplearningmodels. InConferenceonFairness, onArtificialIntelligence(IJCAI),2021.
Accountability,andTransparency(FAccT),2022.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural
Xuanyi Dong, Lu Liu, Katarzyna Musial, and Bogdan Gabrys.
networkrobustnesstocommoncorruptionsandperturbations.
Nats-bench: Benchmarking nas algorithms for architecture
InternationalConferenceonLearningRepresentations(ICLR),
topologyandsize. TransactionsonPatternAnalysisandMa-
2019.
chineIntelligence(TPAMI),2021.
KawinEthayarajh,YejinChoi,andSwabhaSwayamdipta. Un- DanHendrycks, StevenBasart, NormanMu, SauravKadavath,
derstanding dataset difficulty with v-usable information. In FrankWang,EvanDorundo,RahulDesai,TylerZhu,Samyak
InternationalConferenceonMachineLearning(ICML),2022. Parajuli, MikeGuo, etal. Themanyfacesofrobustness: A
criticalanalysisofout-of-distributiongeneralization. InInter-
Sabri Eyuboglu, Maya Varma, Khaled Saab, Jean-Benoit Del- nationalConferenceonComputerVision(ICCV),2021a.
brouck,ChristopherLee-Messer,JaredDunnmon,JamesZou,
andChristopherRe´. Domino: Discoveringsystematicerrors DanHendrycks,CollinBurns,StevenBasart,AndyZou,Mantas
withcross-modalembeddings. InternationalConferenceon Mazeika,DawnSong,andJacobSteinhardt.Measuringmassive
LearningRepresentations(ICLR),2022. multitasklanguageunderstanding. InternationalConferenceon
LearningRepresentations(ICLR),2021b.
AlexFang,SimonKornblith,andLudwigSchmidt. Doesprogress
onimagenettransfertoreal-worlddatasets? InConferenceon
DanHendrycks,KevinZhao,StevenBasart,JacobSteinhardt,and
NeuralInformationProcessingSystems(NeurIPS),2023.
DawnSong. Naturaladversarialexamples. InConferenceon
ComputerVisionandPatternRecognition(CVPR),2021c.
WanyongFeng,AritraGhosh,StephenSireci,andAndrewSLan.
Balancingtestaccuracyandsecurityincomputerizedadaptive
testing. InternationalConferenceonArtificialIntelligencein Cheng-YuHsieh,JieyuZhang,ZixianMa,AniruddhaKembhavi,
Education(AIED),2023. and Ranjay Krishna. Sugarcrepe: Fixing hackable bench-
marks for vision-language compositionality. arXiv preprint
Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan arXiv:2306.14610,2023.
Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten,
MitchellWortsman,DhrubaGhosh,JieyuZhang,etal. Data- ZhenyaHuang,QiLiu,ChengxiangZhai,YuYin,EnhongChen,
comp:Insearchofthenextgenerationofmultimodaldatasets. WeiboGao,andGuopingHu. Exploringmulti-objectiveexer-
In Conference on Neural Information Processing Systems ciserecommendationsinonlineeducationsystems. InInterna-
(NeurIPS),2023. tionalConferenceonInformationandKnowledgeManagement
(CIKM),2019.
DeepGanguli, LianeLovitt, JacksonKernion, AmandaAskell,
YuntaoBai,SauravKadavath,BenMann,EthanPerez,Nicholas
BenHutchinson, NegarRostamzadeh, ChristinaGreer, Kather-
Schiefer,KamalNdousse,etal. Redteaminglanguagemod-
ineHeller,andVinodkumarPrabhakaran. Evaluationgapsin
elstoreduceharms: Methods,scalingbehaviors,andlessons
machinelearningpractice. InConferenceonFairness,Account-
learned. arXivpreprintarXiv:2209.07858,2022.
ability,andTransparency(FAccT),2022.
Irena Gao, Gabriel Ilharco, Scott Lundberg, and Marco Tulio
Ribeiro. Adaptivetestingofcomputervisionmodels. InInter- Re´gis Pierrard Ilyas Moutawwakil. Llm-perf leaderboard.
https://huggingface.co/spaces/optimum/
nationalConferenceonComputerVision(ICCV),2023.
llm-perf-leaderboard,2023.
Matt Gardner, Yoav Artzi, Victoria Basmova, Jonathan Berant,
BenBogin,SihaoChen,PradeepDasigi,DheeruDua,Yanai NeelJain,KhalidSaifullah,YuxinWen,JohnKirchenbauer,Manli
Elazar,AnanthGottumukkala,etal. Evaluatingmodels’local Shu,AniruddhaSaha,MicahGoldblum,JonasGeiping,and
decisionboundariesviacontrastsets. InConferenceonEm- TomGoldstein.Bringyourowndata!self-supervisedevaluation
pirical Methods in Natural Language Processing (EMNLP), forlargelanguagemodels. arXivpreprintarXiv:2306.13651,
2020. 2023.
12LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Disi Ji, Robert L Logan, Padhraic Smyth, and Mark Steyvers. InbalMagarandRoySchwartz. Datacontamination:Frommem-
Activebayesianassessmentofblack-boxclassifiers.InProceed- orization to exploitation. arXiv preprint arXiv:2203.08242,
ingsoftheAAAIConferenceonArtificialIntelligence,pages 2022.
7935–7944,2021.
Horia Mania, John Miller, Ludwig Schmidt, Moritz Hardt,
AmitaKamath,JackHessel,andKai-WeiChang.Textencodersare and Benjamin Recht. Model similarity mitigates test set
performancebottlenecksincontrastivevision-languagemodels. overuse.ConferenceonNeuralInformationProcessingSystems
arXivpreprintarXiv:2305.14897,2023. (NeurIPS),32,2019.
GalKaplun,NikhilGhosh,SaurabhGarg,BoazBarak,andPree- Mark Mazumder, Colby Banbury, Xiaozhe Yao, Bojan Karlasˇ,
tumNakkiran.Deconstructingdistributions:Apointwiseframe- WilliamGaviriaRojas,SudnyaDiamos,GregDiamos,Lynn
workoflearning. InternationalConferenceonLearningRepre- He,AliciaParrish,HannahRoseKirk,etal. Dataperf:Bench-
sentations(ICLR),2023. marksfordata-centricaidevelopment. ConferenceonNeural
InformationProcessingSystems(NeurIPS),2023.
FaisalKhan,BilgeMutlu,andJerryZhu. Howdohumansteach:
Oncurriculumlearningandteachingdimension. Advancesin DenaFMujtabaandNiharRMahapatra. Multi-objectiveopti-
neuralinformationprocessingsystems,24,2011. mization of item selection in computerized adaptive testing.
InProceedingsoftheGeneticandEvolutionaryComputation
DouweKiela,MaxBartolo,YixinNie,DivyanshKaushik,Atticus Conference,pages1018–1026,2021.
Geiger,ZhengxuanWu,BertieVidgen,GrushaPrasad,Aman-
YixinNie, AdinaWilliams, EmilyDinan, MohitBansal, Jason
preetSingh, PratikRingshia, etal. Dynabench: Rethinking
benchmarkinginnlp. NorthAmericanChapteroftheAssocia- Weston,andDouweKiela. Adversarialnli:Anewbenchmark
tionforComputationalLinguistics(NAACL),2021. for natural language understanding. Annual Meeting of the
AssociationforComputationalLinguistics(ACL),2020.
Jannik Kossen, Sebastian Farquhar, Yarin Gal, and Tom Rain-
SimonOtt,AdrianoBarbosa-Silva,KathrinBlagec,JanBrauner,
forth. Activetesting: Sample-efficientmodelevaluation. In
andMatthiasSamwald. Mappingglobaldynamicsofbench-
InternationalConferenceonMachineLearning(ICML),2021.
markcreationandsaturationinartificialintelligence. Nature
JannikKossen,SebastianFarquhar,YarinGal,andThomasRain- Communications,13(1):6793,2022.
forth. Activesurrogateestimators:Anactivelearningapproach
LetitiaParcalabescu,MicheleCafagna,LilittaMuradjan,Anette
tolabel-efficientmodelevaluation. ConferenceonNeuralInfor-
Frank,IacerCalixto,andAlbertGatt.Valse:Atask-independent
mationProcessingSystems(NeurIPS),2022.
benchmarkforvisionandlanguagemodelscenteredonlinguis-
AlexKrizhevsky,GeoffreyHinton,etal. Learningmultiplelayers ticphenomena. arXivpreprintarXiv:2112.07566,2021.
offeaturesfromtinyimages. 2009.
EthanPerez,SaffronHuang,FrancisSong,TrevorCai,Roman
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ring,JohnAslanides,AmeliaGlaese,NatMcAleese,andGe-
IvanKrasin,JordiPont-Tuset,ShahabKamali,StefanPopov, offrey Irving. Red teaming language models with language
MatteoMalloci,AlexanderKolesnikov,etal. Theopenimages models. Conference on Empirical Methods in Natural Lan-
datasetv4:Unifiedimageclassification,objectdetection,and
guageProcessing(EMNLP),2022.
visualrelationshipdetectionatscale. InternationalJournalof
Yotam Perlitz, Elron Bandel, Ariel Gera, Ofir Arviv, Liat Ein-
ComputerVision(IJCV),128(7):1956–1981,2020.
Dor, EyalShnarch, NoamSlonim, MichalShmueli-Scheuer,
andLeshemChoshen. Efficientbenchmarking(oflanguage
Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai,
models). arXivpreprintarXiv:2308.11696,2023.
Joon Sung Park, Agrim Gupta, Yunzhi Zhang, Deepak
Narayanan, Hannah Benita Teufel, Marco Bellagente, et al. MomchilPeychev,MarkNiklasMu¨ller,MarcFischer,andMar-
Holistic evaluation of text-to-image models. Conference on
tinVechev. Automatedclassificationofmodelerrorsonima-
NeuralInformationProcessingSystems(NeurIPS),2023.
genet. ConferenceonNeuralInformationProcessingSystems
(NeurIPS),2023.
PercyLiang,RishiBommasani,TonyLee,DimitrisTsipras,Dilara
Soylu,MichihiroYasunaga,YianZhang,DeepakNarayanan, FelipeMaiaPolo,LucasWeber,LeshemChoshen,YuekaiSun,
YuhuaiWu,AnanyaKumar,etal. Holisticevaluationoflan- GongjunXu,andMikhailYurochkin. tinybenchmarks:evaluat-
guagemodels. arXivpreprintarXiv:2211.09110,2022. ingllmswithfewerexamples.arXivpreprintarXiv:2402.14992,
2024.
ThomasLiao,RohanTaori,InioluwaDeborahRaji,andLudwig
Schmidt. Arewelearningyet? ametareviewofevaluation ChristopherPotts, ZhengxuanWu, AtticusGeiger, andDouwe
failures across machine learning. In Conference on Neural Kiela. Dynasent:Adynamicbenchmarkforsentimentanalysis.
InformationProcessingSystems(NeurIPS),2021. Dynasent:Adynamicbenchmarkforsentimentanalysis,2021.
Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,Pietro AmeyaPrabhu,ZhipengCai,PuneetDokania,PhilipTorr,Vladlen
Perona,DevaRamanan,PiotrDolla´r,andCLawrenceZitnick. Koltun,andOzanSener. Onlinecontinuallearningwithoutthe
Microsoft coco: Common objects in context. In European storageconstraint. arXivpreprintarXiv:2305.09253,2023.
ConferenceonComputerVision(ECCV),2014.
AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,
ShangyunLu, Bradley Nott, AaronOlson, AlbertoTodeschini, GabrielGoh,SandhiniAgarwal,GirishSastry,AmandaAskell,
HosseinVahabi,YairCarmon,andLudwigSchmidt. Harder PamelaMishkin,JackClark,etal. Learningtransferablevisual
or different? a closer look at distribution shift in dataset re- models from natural language supervision. In International
production. InInternationalConferenceonMachineLearning conference on machine learning, pages 8748–8763. PMLR,
Workshops(ICML-W),2020. 2021.
13LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
InioluwaDeborahRaji,EmilyMBender,AmandalynnePaullada, YonglongTian,LijieFan,KaifengChen,DinaKatabi,DilipKr-
EmilyDenton,andAlexHanna. Aiandtheeverythinginthe ishnan,andPhillipIsola. Learningvisionfrommodelsrivals
wholewideworldbenchmark. ConferenceonNeuralInforma- learningvisionfromdata. arXivpreprintarXiv:2312.17742,
tionProcessingSystems(NeurIPS),2021. 2023.
BenjaminRecht,RebeccaRoelofs,LudwigSchmidt,andVaishaal AntonioTorralbaandAlexeiAEfros.Unbiasedlookatdatasetbias.
Shankar. Docifar-10classifiersgeneralizetocifar-10? arXiv In Conference on Computer Vision and Pattern Recognition
preprintarXiv:1806.00451,2018. (CVPR),2011.
BenjaminRecht,RebeccaRoelofs,LudwigSchmidt,andVaishaal VishaalUdandarao,MaxFBurg,SamuelAlbanie,andMatthias
Shankar. Doimagenetclassifiersgeneralizetoimagenet? In Bethge. Visual data-type understanding does not emerge
InternationalConferenceonMachineLearning(ICML),2019. from scaling vision-language models. arXiv preprint
arXiv:2310.08577,2023.
PedroRodriguez,JoeBarrow,AlexanderMiserlisHoyle,JohnP
WimJVanderLindenandCeesAWGlas.Computerizedadaptive
Lalor,RobinJia,andJordanBoyd-Graber. Evaluationexam-
testing:Theoryandpractice. Springer,2000.
plesarenotequallyinformative:Howshouldthatchangenlp
leaderboards? InAnnualMeetingoftheAssociationforCom-
KirillVishniakov,ZhiqiangShen,andZhuangLiu. Convnetvs
putationalLinguistics(ACL),2021.
transformer, supervised vs clip: Beyond imagenet accuracy.
2023.
Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara
Fridovich-Keil,MoritzHardt,JohnMiller,andLudwigSchmidt. RajanVivek,KawinEthayarajh,DiyiYang,andDouweKiela.An-
Ameta-analysisofoverfittinginmachinelearning. Conference chorpoints:Benchmarkingmodelswithmuchfewerexamples.
onNeuralInformationProcessingSystems(NeurIPS),2019. arXivpreprintarXiv:2309.08638,2023.
Mark Rofin, Vladislav Mikhailov, Mikhail Florinskiy, Andrey EricWallace,AdinaWilliams,RobinJia,andDouweKiela. Ana-
Kravchenko, Elena Tutubalina, Tatiana Shavrina, Daniel lyzingdynamicadversarialtrainingdatainthelimit. InAnnual
Karabekyan,andEkaterinaArtemova. Vote’n’rank:Revision MeetingoftheAssociationforComputationalLinguistics(ACL),
ofbenchmarkingwithsocialchoicetheory. AnnualMeetingof pages202–217,2022.
theAssociationforComputationalLinguistics(EACL),2022.
AlexWang,AmanpreetSingh,JulianMichael,FelixHill,Omer
NikhilSardanaandJonathanFrankle. Beyondchinchilla-optimal: Levy,andSamuelRBowman. Glue:Amulti-taskbenchmark
Accountingforinferenceinlanguagemodelscalinglaws.arXiv andanalysisplatformfornaturallanguageunderstanding.arXiv
preprintarXiv:2401.00448,2023. preprintarXiv:1804.07461,2018.
ZhelunShi,ZhipinWang,HongxingFan,ZhenfeiYin,LuSheng, AlexWang,YadaPruksachatkun,NikitaNangia,AmanpreetSingh,
YuQiao,andJingShao. Chef: Acomprehensiveevaluation JulianMichael,FelixHill,OmerLevy,andSamuelBowman.
framework for standardized assessment of multimodal large Superglue:Astickierbenchmarkforgeneral-purposelanguage
languagemodels. arXivpreprintarXiv:2311.02692,2023. understanding systems. Conference on Neural Information
ProcessingSystems(NeurIPS),2019a.
AliShiraliandMoritzHardt. Whatmakesimagenetlookunlike
laion. arXivpreprintarXiv:2306.15769,2023. Haohan Wang, Songwei Ge, Zachary Lipton, and Eric P Xing.
Learningrobustglobalrepresentationsbypenalizinglocalpre-
AliShirali,RedietAbebe,andMoritzHardt. Atheoryofdynamic dictivepower. ConferenceonNeuralInformationProcessing
benchmarks. arXivpreprintarXiv:2210.03165,2022. Systems(NeurIPS),2019b.
HangyuWang,TingLong,LiangYin,WeinanZhang,WeiXia,
AarohiSrivastava,AbhinavRastogi,AbhishekRao,AbuAwalMd
QichenHong,DingyinXia,RuimingTang,andYongYu. Gmo-
Shoeb,AbubakarAbid,AdamFisch,AdamRBrown,Adam
cat:Agraph-enhancedmulti-objectivemethodforcomputerized
Santoro,AdityaGupta,Adria`Garriga-Alonso,etal.Beyondthe
adaptivetesting. InConferenceonKnowledgeDiscoveryand
imitationgame:Quantifyingandextrapolatingthecapabilities
DataMining(KDD),2023.
oflanguagemodels. arXivpreprintarXiv:2206.04615,2022.
Zan Wang, Hanmo You, Junjie Chen, Yingyi Zhang, Xuyuan
XiaoxiaoSun,XingjianLeng,ZijianWang,YangYang,ZiHuang,
Dong, and Wenbin Zhang. Prioritizing test inputs for deep
andLiangZheng. Cifar-10-warehouse: Broadandmorereal-
neural networks via mutation analysis. In 2021 IEEE/ACM
istictestbedsinmodelgeneralizationanalysis. arXivpreprint
43rdInternationalConferenceonSoftwareEngineering(ICSE),
arXiv:2310.04414,2023.
pages397–409.IEEE,2021.
Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini,
RossWightman. Pytorchimagemodels. https://github.
BenjaminRecht,andLudwigSchmidt. Measuringrobustness
com/rwightman/pytorch-image-models,2019.
tonaturaldistributionshiftsinimageclassification. Conference
onNeuralInformationProcessingSystems(NeurIPS),2020. OliviaWiles,IsabelaAlbuquerque,andSvenGowal. Discovering
bugsinvisionmodelsusingoff-the-shelfimagegenerationand
TristanThrush,RyanJiang,MaxBartolo,AmanpreetSingh,Ad- captioning. arXivpreprintarXiv:2208.08831,2022.
inaWilliams,DouweKiela,andCandaceRoss. Winoground:
Probingvisionandlanguagemodelsforvisio-linguisticcom- JingweiYu,MuZhenyu,JiayiLei,Li’AngYin,WeiXia,YongYu,
positionality. InProceedingsoftheIEEE/CVFConferenceon andTingLong. Sacat:Student-adaptivecomputerizedadaptive
ComputerVisionandPatternRecognition,pages5238–5248, testing. InTheFifthInternationalConferenceonDistributed
2022. ArtificialIntelligence,2023.
14LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Ganzhao Yuan and Bernard Ghanem. Binary optimization via
mathematicalprogrammingwithequilibriumconstraints. arXiv
preprintarXiv:1608.04425,2016.
XiangYue,YuanshengNi,KaiZhang,TianyuZheng,RuoqiLiu,
GeZhang,SamuelStevens,DongfuJiang,WeimingRen,Yux-
uanSun,etal. Mmmu:Amassivemulti-disciplinemultimodal
understandingandreasoningbenchmarkforexpertagi. arXiv
preprintarXiv:2311.16502,2023.
MertYuksekgonul,FedericoBianchi,PratyushaKalluri,DanJu-
rafsky,andJamesZou. Whenandwhyvision-languagemodels
behavelikebags-of-words,andwhattodoaboutit? InThe
EleventhInternationalConferenceonLearningRepresentations,
2022.
Xiaohua Zhai, Joan Puigcerver, Alexander Kolesnikov, Pierre
Ruyssen,CarlosRiquelme,MarioLucic,JosipDjolonga,An-
dreSusanoPinto,MaximNeumann,AlexeyDosovitskiy,etal.
Thevisualtaskadaptationbenchmark. 2019.
Yi-KaiZhang,Ting-JiHuang,Yao-XiangDing,De-ChuanZhan,
andHan-JiaYe. Modelspider: Learningtorankpre-trained
modelsefficiently. arXivpreprintarXiv:2306.03900,2023.
LianminZheng, Wei-LinChiang, YingSheng, SiyuanZhuang,
ZhanghaoWu,YonghaoZhuang,ZiLin,ZhuohanLi,Dacheng
Li,Eric.PXing,HaoZhang,JosephE.Gonzalez,andIonStoica.
Judgingllm-as-a-judgewithmt-benchandchatbotarena,2023.
WangchunshuZhou,YanZeng,ShizheDiao,andXinsongZhang.
Vlue:Amulti-taskmulti-dimensionbenchmarkforevaluating
vision-languagepre-training. InInternationalConferenceon
MachineLearning(ICML),2022.
YanZhuang,QiLiu,ZhenyaHuang,ZhiLi,ShuanghongShen,
andHaipingMa. Fullyadaptiveframework: Neuralcomput-
erizedadaptivetestingforonlineeducation. InConferenceon
ArtificialIntelligence(AAAI),2022.
OrrZohar, Shih-ChengHuang, Kuan-ChiehWang, andSerena
Yeung. Lovm: Language-onlyvisionmodelselection. arXiv
preprintarXiv:2306.08893,2023.
15LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
9.Correlationplotsbetweenestimatedandground-truthaccuracies
Inthissection,weexpandSection4.2fromthemainpaperwithmoredatapoints.
Lifelong-ImageNet: Estimated vs GT-accuracies for different sampling budgets
100
n'=32 n'=64 n'=128 n'=256
50 y=x
Corr: 0.87 Corr: 0.91 Corr: 0.93 Corr: 0.95
0
100
n'=512 n'=1024 n'=2048 n'=4096
50
Corr: 0.96 Corr: 0.97 Corr: 0.98 Corr: 0.99
0
0 50 100 0 50 100 0 50 100 0 50 100
GT-Accuracies GT-Accuracies GT-Accuracies GT-Accuracies
Figure7.Estimatedv/sGround-TruthaccuraciesonLifelong-ImageNet. Fordifferentsamplingbudgets(n′ = 32−4096),our
estimatedaccuraciesfor117modelsaresurprisinglyclosetothetrueground-truthaccuracies(ρ=0.94−1.0).
1
seicaruccA-tsE
seicaruccA-tsELifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
Figure8.Estimatedv/sGround-TruthaccuraciesonLifelong-CIFAR10. Fordifferentsamplingbudgets(n′ = 32−4096),our
estimatedaccuraciesfor25,250modelsaresurprisinglyclosetothetrueground-truthaccuracies(ρ=0.81−0.98).
10.ExtendedRelatedWork
Inthissection,weexpandonthebriefliteraturereviewfromSection3foramoreexpansivecoverageofrelatedtopics.
Comprehensive Benchmarks. Benchmarking has become ubiquitous in the machine learning world in the last few
years(Rajietal.,2021). IthasgainedfurthertractionintherecentpastwiththereleaseoffoundationmodelslikeGPT-
4(Bubecketal.,2023)andCLIP(Radfordetal.,2021). ApopulardirectiontakenbyeffortslikeGLUE(Wangetal.,
2018),BigBench(Srivastavaetal.,2022),HELM(Liangetal.,2022)etc.,istohaveabenchmarkofbenchmarks,reporting
theaverageaccuracyovertheconstituentdatasets. Thisapproachnowspansacrossseveraldomainsincludingfact-based
question-answering(Hendrycksetal.,2021b),languageunderstanding(Wangetal.,2019a),zero-shotclassificationof
vision-languagemodels(Gadreetal.,2023),large-scalevisionmodelevaluation(Zhaietal.,2019),multi-modalmodel
evaluation(Yueetal.,2023;Zhouetal.,2022),andtext-to-imagegeneration(Bakretal.,2023;Leeetal.,2023). Despite
thesebenchmarkshavingvastcoverageoftestingconcepts,theobviousdownsidesaretwo-fold: (1)theyarestaticinnature
andhencecanalwaysbesusceptibletotest-setcontamination(MagarandSchwartz,2022),and(2)theirlargesizesrenders
themveryexpensivetorunfullmodelevaluationson.
AdversarialDynamicBenchmarks. Onenecessaryaspectessentialforlifelongbenchmarksiscollectinghardersamples,
whichhasbeenpursuedbytwostrandsofworks. Adversarialmethodstoaugmentbenchmarks(Wallaceetal.,2022;Nie
etal.,2020;Kielaetal.,2021;Pottsetal.,2021;Shiralietal.,2022)aimtoautomaticallycuratesamplesthatalltested
modelsreliablyfailon. Thesemethodsusuallyinvolveaniterativeoptimisationproceduretofindsuchadversarialsamples.
Thesecondstrandofworkincuratingadversarialsamplesareeffortsrevolvingaroundred-teaming(Gangulietal.,2022;
Perezetal.,2022)thataimtoexplicitlyelicitcertainsetsofbehavioursfromfoundationmodels;primarilytheseapproaches
look at the problem of adversarial benchmarking from a safety perspective. Further, a host of benchmarks that aim to
stress-testmodelsaremakingtheirwayonthehorizon—theirprimarygoalistocreatetestsetsformanuallydiscovered
failuremodes(Yuksekgonuletal.,2022;Parcalabescuetal.,2021;Thrushetal.,2022;Udandaraoetal.,2023;Hsiehetal.,
2023;Kamathetal.,2023;Bitton-Guettaetal.,2023;Bordesetal.,2023). However,whiletheyaresampleefficient,they
arecriticizedasunfair. Tomitigatethis,astrandofautomaticerrordiscovery(Chenetal.,2023;Eyubogluetal.,2022;
Wilesetal.,2022;Peychevetal.,2023)ortheirhuman-in-the-loopvariants(Wangetal.,2021;d’Eonetal.,2022;Gao
etal.,2023)havebeendeveloped. Thisiscomplementarytoourwork,asweprimarilyexploremodeltesting.
ActiveTesting. Effortssuchas(Jietal.,2021;Kossenetal.,2021;2022)aimtoidentify“high-quality”,representativetest
instancesfromalargeamountofunlabeleddata,whichcanrevealmoremodelfailureswithlesslabelingeffort. Thekey
assumptionunderlyingtheseworksisthattheyassumeaccesstoahostofunlabeleddataatarelativelycheapcost. However,
theyassumethatthecostoflabelacquisitionisabottleneck. However,theseassumptionscanbreakdownwhendoing
multipleforwardpassesonasinglebatchofdatawithalarge-scalefoundationmodelisnecessitated. Albeitsimilarinspirit
2LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
tothetaskofactivelyacquiringasubsetofsamplesfortestingmodels,animportantdistinctionofourmethodisthatwe
wanttominimisethenumberofforward-passesthroughamodel—webelievethatthecostofrunningamodelonseveral
testsamplesissubstantial,andhenceneedstobereducedforefficientevaluationintermsoftime,resourcesandcapital.
IdeasforReplacingBenchmarks.Recently,therehavebeenasurgeofmethodsintroducingcreativewaysofbenchmarking
models(Liaoetal.,2021;Roelofsetal.,2019;Kaplunetal.,2023;Gardneretal.,2020;Rodriguezetal.,2021;Rofinetal.,
2022;Maniaetal.,2019;Hutchinsonetal.,2022;BowmanandDahl,2021;Tianetal.,2023;Ottetal.,2022;Garridoetal.,
2023;Roelofsetal.,2019;Rodriguezetal.,2021)includinghostedcompetitions(BlumandHardt,2015),self-supervised
evaluation(Jainetal.,2023)andnewermetrics(Geirhosetal.,2020). Further, recentlyELOstylemethodshavebeen
gainingalotofattention(Bittonetal.,2023;Zhengetal.,2023)duetotheirscalabilityofdeploymenttomillionsofusers
inapeer-to-peermanner. TheELOalgorithmisusedtocomputeranksfordifferentmodelsbasedonhuman-in-the-loop
preferences. However,despiteitsutilityELOisheavilydependentonthechoiceofuserinputsandcanbeaverybiased
estimatorofmodelrankings(Shietal.,2023). Anotherinterestingideaproposedby(Corneanuetal.,2020)istoassume
access to the pre-training data of models and compute topological maps to give predictions of test error; this however
requiresrunningexpensiveforwardpassesoverthetrainingdataormodifyingthetrainingprotocol,whichmightbenotbe
scalabletopre-trainedmodels.
ComputerizedAdaptiveTesting. ComputerizedAdaptiveTesting(CAT)isaframeworkthatallowsforefficienttesting
ofhumanexaminees. Theideaistolowertheburdenofstudentstakingtestsbyonlyaskingthemasubsetofquestions
fromtheentirepool. Therehavebeenfewmaindirectionsofsolutions: model-agnosticstrategiesforselection(Bietal.,
2020),bi-leveloptimization(GhoshandLan,2021;Zhuangetal.,2022;Fengetal.,2023),multi-objectiveoptimization
(MujtabaandMahapatra,2021;Huangetal.,2019;Wangetal.,2023),retrieval-augmentedadaptivesearch(Yuetal.,2023).
OnekeychallengeinCATisthelackofastableground-truth. SincethegoalinCATistoestimatetheproficiencyofan
examinee,andtheexaminee’strueground-truthproficiencyisnotprovided,howwouldoneevaluatethetrueproficiencyof
anexaminee? Thereby,existingCATmethodscannotexplicitlyoptimiseforpredictingabilitydirectlyi.e. theycannotdo
exactabilityestimation. Hence,CATmethodsarenotusuallyguaranteedtoconvergetothetrueexamineeabilitiesunder
certainconditions. ThebiggestdistinctionofourworkfromCATistheaccesstotheground-truthtargetsforthetaskswe
consider. InbothLifelong-ImageNetandLifelong-CIFAR10,wehaveaccesstotheground-truthandhencecancompute
groundedmetricsthatcanbeoptimisedtowards,unlikeinCAT,whereeverymethodhastoinherentlybelabel-free.
CurriculumLearning. Thisreferstotheproblemoffindingacurriculumofinputsamplessuchthattheoptimisation
objective of an algorithm becomes easier. The most intuitive explanation from curriculum learning comes from how
humans learn (Khan et al., 2011). In the context of machine learning, the idea behind curriculum learning is to find
the “difficulty” of samples, where difficulty is usually defined in terms of the ease of classifying that sample correctly.
Somerecentworksinthisdirectionutiliseestimatingvarianceofgradients(Agarwaletal.,2022)andotherinformation
theoreticproperties(Ethayarajhetal.,2022)toestimatesampledifficulty. TheseapproachesarecomplementarytoourSum
componentinS&Ssincethesecanbeeasilyintegratedintoourframeworkdirectly.
11.ProofofTheorem4.2
Proof. First,usingthesamedecompositionasEquation6,wereducethetheoremproblemtothefollowing:
y′∗ =argmin ∥a′P∗−y′|| (7)
y′
Notethaty′ essentiallyconstructsavectorofallonesuptosomeindexwiththerestwherexisnonzerowiththerest
beingzero. Therefore,y′ isavectorofallonesuptoindexiwiththerestbeingzero. Letb=a′P∗bethesortedvector
i
accordingtothepermutationmatrix. Thus,theobjectivefunctionhasthefollowingerror:
(cid:32) i (cid:33) n
(cid:88) (cid:88)
e(y′ )= i− b + b . (8)
i k k
k=1 k=i+1
Observethatthefirsttermisthenumberofzerostotheleftofindexi(inclusive)inb,whilethesecondtermisthenumber
of1sinbtotherightofindexi.
Proposition11.1. Ify′ isaminimizertoTheorem4.2,then,thefollowingholds:
i
n n
(cid:88) (cid:88)
b ≤(n−i)− b .
k j
k=i+1 k=i+1
Proof. Letj <iandthaty′ andy′ arefeasiblesolutionsforTheorem4.2. However,letthaty′ besuchthattheinequality
i j i
3LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
inProposition11.1whileitisnotthecasefory′ . Then,wecomparethedifferencesintheobjectivefunctionse(y′ )and
j i
e(y′ ). Wehavethat:
j
(cid:32) j (cid:33) n  (cid:34)(cid:32) i (cid:33) n (cid:35)
(cid:88) (cid:88) (cid:88) (cid:88)
e(y′ j)−e(y′ i)= j− b
j
+ b k− i− b
k
+ b
k
k=1 k=j+1 k=1 k=i+1
i
(cid:88)
=2 b −(i−j).
k
k=j+1
However, we know from the assumptions that
2(cid:80)n
b ≤ n−i and that
2(cid:80)n
b ≥ n−j. Subtracting the two
i+1 k j+1 k
inequalitieswehave2(cid:80)n b ≥i−j whichimpliesthaty′(s )≥e(y′ )whichimpliesthaty′ isabettersolutionto
k=j+1 k j i i
anyothery′ notsatisfyingtheinequalityinProposition11.1.
j
Theinequalityconditioninproposition11.1,impliesthatforthechoiceofindexi,thenumberofzerosinatotherightof
indexiismorethanthenumberof1stotherightofofindexi. Sinceanysolution,i.e. y′ oringeneralthresholdingindexi,
i
eitherstatisfiespropertyinproposition11.1ornot,andsincepropositiondemonstratedthatthesetofindicesthatsatisfythis
propertyarebetter,inobjectivevalue(lower),thanallthosethatdonotsatisfyit,thenthisconditionachievesoptimality.
12.167ModelsusedforLifelong-ImageNetexperiments
Weusethefollowingmodels(asnamedinthetimm(Wightman,2019)andimagenet-testbed(Taorietal.,2020)
repositories):
1. BiT-M-R101x3-ILSVRC2012 25. dpn131 49. efficientnet-b6-autoaug
2. BiT-M-R50x1-ILSVRC2012 26. dpn68 50. efficientnet-b7-advprop-autoaug
51. efficientnet-b7-autoaug
3. BiT-M-R50x3-ILSVRC2012 27. dpn68b
52. efficientnet-b7-randaug
4. FixPNASNet 28. dpn92
53. efficientnet-b8-advprop-autoaug
5. FixResNet50 29. dpn98
54. fbresnet152
6. FixResNet50CutMix 30. efficientnet-b0
55. inceptionresnetv2
7. FixResNet50CutMixv2 31. efficientnet-b0-autoaug 56. inceptionv3
8. FixResNet50noadaptation 32. efficientnet-b1 57. inceptionv4
9. FixResNet50v2 33. efficientnet-b1-advprop-autoaug 58. instagram-resnext10132x16d
10. alexnet 34. efficientnet-b1-autoaug 59. instagram-resnext10132x32d
60. instagram-resnext10132x8d
11. alexnetlpf2 35. efficientnet-b2
61. mnasnet05
12. alexnetlpf3 36. efficientnet-b2-advprop-autoaug
62. mnasnet10
13. alexnetlpf5 37. efficientnet-b2-autoaug
63. mobilenetv2
14. bninception 38. efficientnet-b3
64. mobilenetv2lpf3
15. bninception-imagenet21k 39. efficientnet-b3-advprop-autoaug 65. mobilenetv2lpf5
16. cafferesnet101 40. efficientnet-b3-autoaug 66. nasnetalarge
17. densenet121 41. efficientnet-b4 67. nasnetamobile
18. densenet121lpf2 42. efficientnet-b4-advprop-autoaug 68. polynet
69. resnet101
19. densenet121lpf3 43. efficientnet-b4-autoaug
70. resnet101cutmix
20. densenet121lpf5 44. efficientnet-b5
71. resnet101lpf2
21. densenet161 45. efficientnet-b5-advprop-autoaug
72. resnet101lpf3
22. densenet169 46. efficientnet-b5-autoaug
73. resnet101lpf5
23. densenet201 47. efficientnet-b5-randaug 74. resnet152
24. dpn107 48. efficientnet-b6-advprop-autoaug 75. resnet18
4LifelongBenchmarks:EfficientModelEvaluationinanEraofRapidProgress
76. resnet18-rotation-nocrop40 107. resnet50ssl 138. seresnext10132x4d
77. resnet18-rotation-random30 108. resnet50swsl 139. seresnext5032x4d
78. resnet18-rotation-random40 109. resnet50trainedonSIN 140. senet154
79. resnet18-rotation-standard40 110. resnet50trainedonSINandIN 141. shufflenetv2x05
80. resnet18-rotation-worst1030 111. resnet50withbrightnessaws 142. shufflenetv2x10
81. resnet18-rotation-worst1040 112. resnet50withcontrastaws 143. squeezenet10
82. resnet18lpf2 113. resnet50withdefocusbluraws 144. squeezenet11
83. resnet18lpf3 114. resnet50withfogaws
145. vgg11
84. resnet18lpf5 115. resnet50withfrostaws
146. vgg11bn
85. resnet18ssl 116. resnet50withgaussiannoiseaws
147. vgg13
86. resnet18swsl 117. resnet50withgreyscaleaws
148. vgg13bn
87. resnet34 118. resnet50withjpegcompressionaws
149. vgg16
88. resnet34lpf2 119. resnet50withmotionbluraws
150. vgg16bn
89. resnet34lpf3 120. resnet50withpixelateaws
151. vgg16bnlpf2
90. resnet34lpf5 121. resnet50withsaturateaws
152. vgg16bnlpf3
91. resnet50 122. resnet50withspatteraws
153. vgg16bnlpf5
92. resnet50adv-train-free 123. resnet50withzoombluraws
154. vgg16lpf2
93. resnet50augmix 124. resnext10132x16dssl
155. vgg16lpf3
94. resnet50awsbaseline 125. resnext10132x4d
156. vgg16lpf5
95. resnet50cutmix 126. resnext10132x4dssl
157. vgg19
96. resnet50cutout 127. resnext10132x4dswsl
158. vgg19bn
97. resnet50deepaugment 128. resnext10132x8d
159. wideresnet1012
98. resnet50deepaugmentaugmix 129. resnext10132x8dssl
160. xception
99. resnet50featurecutmix 130. resnext10132x8dswsl
100. resnet50l2eps3robust 131. resnext10164x4d 161. resnet50trainedonSINandINthenfinetunedonIN
101. resnet50linfeps4robust 132. resnext5032x4d 162. resnet50imagenetsubsample1of16batch64originalimages
102. resnet50linfeps8robust 133. resnext5032x4dssl 163. resnet50imagenetsubsample1of2batch64originalimages
103. resnet50lpf2 134. resnext5032x4dswsl 164. resnet50imagenetsubsample1of32batch64originalimages
104. resnet50lpf3 135. seresnet101 165. resnet50imagenetsubsample1of8batch64originalimages
105. resnet50lpf5 136. seresnet152 166. resnet50withgaussiannoisecontrastmotionblurjpegcompressionaws
106. resnet50mixup 137. seresnet50 167. resnet50imagenet100percentbatch64originalimages
5