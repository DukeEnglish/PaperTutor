ALISON: Fast and Effective Stylometric Authorship Obfuscation
EricXing1,SaranyaVenkatraman2,ThaiLe3,DongwonLee2
1McKelveySchoolofEngineering,WashingtonUniversityinSt.Louis,MO,USA
2CollegeofInformationSciencesandTechnology,ThePennsylvaniaStateUniversity,PA,USA
3SchoolofEngineering,UniversityofMississippi,MS,USA
e.xing@wustl.edu,saranyav@psu.edu,thaile@olemiss.edu,dongwon@psu.edu
Abstract
VBD RB
Authorship Attribution (AA) and Authorship Obfuscation I got back my first memo today
Author A
(AO) are two competing tasks of increasing importance in
10x faster ALISON 15 % Authorship
privacy research. Modern AA leverages an author’s consis-
success Attributor
tent writing style to match a text to its author using an AA
classifier.AOisthecorrespondingadversarialtask,aimingto I just received my first memo today
modifyatextinsuchawaythatitssemanticsarepreserved, RB VBD Author B
yet an AA model cannot correctly infer its authorship. To
address privacy concerns raised by state-of-the-art (SOTA)
Figure1:ALISONsuccessfullyobfuscatingatextbychang-
AA methods, new AO methods have been proposed but re-
mainlargelyimpracticaltouseduetotheirprohibitivelyslow ingitsstylewhilepreservingsemantics.
training and obfuscation speed, often taking hours. To this
challenge,weproposeapracticalAOmethod,ALISON,that
(1) dramatically reduces training/obfuscation time, demon-
(e.g., semantics of words and phrases in the text) are engi-
strating more than 10x faster obfuscation than SOTA AO
neered to allow a machine learning model to match a text
methods,(2)achievesbetterobfuscationsuccessthroughat-
tackingthreetransformer-basedAAmethodsontwobench- to an authorship label. These engineered features, such as
markdatasets,typicallyperforming15%betterthancompet- Writeprints(AbbasiandChen2008),oftenincludenotone
ingmethods,(3)doesnotrequiredirectsignalsfromatarget but several interpretable signals such as word and charac-
AAclassifierduringobfuscation,and(4)utilizesuniquesty- ter bigrams, word length distributions, or special character
lometricfeatures,allowingsoundmodelinterpretationforex- frequenciestoimprovetheclassificationaccuracy.
plainableobfuscation.WealsodemonstratethatALISONcan
However, recent AA techniques (Fabien et al. 2020;
effectivelypreventfourSOTAAAmethodsfromaccurately
Devlin et al. 2019) utilize complex transformer models–
determining the authorship of ChatGPT-generated texts, all
e.g., BERT (Jin et al. 2020), RoBERTa (Liu et al. 2019),
whileminimallychangingtheoriginaltextsemantics.Toen-
surethereproducibilityofourfindings,ourcodeanddataare BertAA (Fabien et al. 2020), to automatically learn useful
availableat:https://github.com/EricX003/ALISON. featuresforAAfromrawtext.Thisremovestheneedtorely
on explicitly engineered stylometric features. While these
modelsaremorecomputationallyexpensivetotrainandno-
Introduction
torious for their lack of interpretability, they significantly
Writing styles are often consistent among texts written by outperformtraditionalAAclassifiers (Fabienetal.2020).
thesameauthor.However,thewritingstylesofdifferentau-
As AA techniques become more accurate and efficient,
thorscanbeverydissimilar.Therefore,theauthorshipiden-
they are more likely to be exploited by malicious actors to
tity of an anonymous piece of writing can still be revealed
detect authorship identities behind anonymous texts. This
by analyzing its writing style and matching it to a pool of
is severely detrimental to a number of groups, especially
known authorship markers, a task known as Authorship
NGO activists, whistleblowers, and journalists. As current
Attribution (AA). In a machine learning context, author-
SOTA transformer-based AA models are sufficiently pow-
shipmarkersarepredictivesignalsthatcandistinguishone
erful,itbecomesimportanttodevelopmethodsthatreduce
author’s writing style from the others. Such signals are of-
the risk of an anonymous text’s true authorship being ex-
tencalledstylometricfeatures.Multipletypesofstylometric
posed.Therefore,inthiswork,westudytheoppositetaskof
features, including lexical features (e.g., structure of words
AA,knownasAuthorshipObfuscation(AO),whichaims
and frequency of different character sequences), syntactic
tothwartauthorshipattributionclassifiersbymakingafew
features (e.g., part-of-speech distributions and occurrences
changes to the input text in a systematic way. Successful
of functional words and punctuation), and content features
AOwillfoolthetargetmodelintomakinganincorrectattri-
Copyright©2024,AssociationfortheAdvancementofArtificial bution outof apool ofcandidates. BecauseAA techniques
Intelligence(www.aaai.org).Allrightsreserved. generallydegradeinperformanceasthenumberofauthors
4202
beF
1
]LC.sc[
1v53800.2042:viXrabecomeslarge(i.e.> 100),andanadversarycangenerally Other popular greedy-based black-box methods in the
narrowthepoolofauthorsdowntoasmall,finiteset,wedo NLP adversarial literature, such as TextFooler (Jin et al.
not consider authorship obfuscation in the open-world set- 2020) and BERT-Attack (Li et al. 2020), often have a high
ting.Figure1showsanexampleofasuccessfulauthorship degree of dependence on the accessibility to the target AA
obfuscation against a BERT-based (Devlin et al. 2019) au- classifier they attack. These methods make queries to the
thorshipattributor. victimmodelpertokeninordertoobtainalogit-basedrank-
There are three important properties that we desire in a ing of word importance. Then, top tokens may be replaced
“practical”AOapproach:(1)abilitytooperatewithoutsig- withcloseneighborsinprecomputedembeddingspaces(Jin
nificant knowledge of the adversary, (2) fast running time et al. 2020) or by leveraging token representations of large
for long-form texts (< 1 second, not minutes or hours), language models (Li et al. 2020). However, these meth-
and (3) intuitive interpretability for a trustworthy obfusca- odsoftendemonstrateasharpdeclineinperformanceonce
tionprocess.Unfortunately,SOTAAOmethods,donotsat- the attacks are transferred to different target classifiers (Jin
isfythesepropertiesatall,oftenrequiringlongrunningtime et al. 2020). Additionally, such methods generally lack in-
to obfuscate text in a black-box fashion while making nu- terpretability,asmodelexplanationsarebasedsolelyonthe
merous calls to the attacked model. Such methods are im- black-boxmodelthatisbeingattackedinsteadofrevealing
practical because a black-box understanding of the model identifyinglinguisticpatterns.
tobeattackedisoftenimpossibletoobtain,prohibitiverun- Lastly, large generative language models, such as Chat-
ning times diminish the productivity of an author seeking GPT (Ouyang et al. 2022), have demonstrated impressive
anonymity,andalackofinterpretabilityduringobfuscation paraphrasingcapabilitywhichmaybesuitableforAOappli-
preventscurrentmethodsfrombeingtrustworthy. cations.Ausermayobtainastylometricallydifferentbutse-
ToaddresstheaforementionedlimitationsofcurrentAO manticallyconsistenttextbyprependingafixedparaphras-
methods,weproposeanovelstylometry-groundednovelob- ingprompttoqueryalanguagemodel.
fuscation method, ALISON: (Fast Stylometric Authorship
Obfuscation),whichovercomesthesechallengesasfollows:
ProblemFormulation
• ALISON significantly reduces the obfuscation runtime
GivenatextcorpusX,wedefineanAAclassifierf trained
byover10xwhilealsoachievingbettersemanticpreser-
onX,suchthatforarbitrarytextx∈X,f(x)attributesthe
vationduringobfuscation.
authorship of x. Given T is a set of texts to obfuscate, our
• ALISON consistently outperforms competing ap- objective is to thwart f for any text t ∈ T by transform-
proachesbyaround15%inobfuscationsuccessrate. ingtintot′ suchthatf(t)̸=f(t′).WeassumethatX andT
• ALISON is also able to provide explanations for its ob- sharethesamepoolofpotentialauthorsandareinasimilar
fuscationresultswithinterpretablestylometricfeatures. domain–e.g., news articles, blog posts– but do not contain
anyidenticaltexts.
Moreover, we also assume no access to X by the ad-
Background
versary. However, they do have access to another non-
We narrow the scope of our work to the blind AO setting overlapping corpus X∗ with a similar size containing the
where a textual adversarial attack against AA classifier has samepoolofauthorsanddomainwithX.Suchassumption
twomainconstraints:(1)theattackercannotquerytheAA isreasonableinpractice,especiallywhenonlinesocialnet-
classifier, and (2) the attacker also does not have access to works have made it very convenient for anyone to access
its architecture, training data, etc. These constraints make textcontentgeneratedbymillionsofpeopleworldwide.To
the AO task more challenging but also more practical than evaluateourapproachinthissetting,wespliteachpublicly
existingthreatmodelsoftenusedinexistingliteraturewhere availabletextclassificationcorpusintothreedisjointsets,X,
apublicAPItothetargetAAclassifierisassumedtobeac- X∗,andT stratifiedbyuniqueauthorshiplabels.
cessible.Thefollowingsectiondescribesexistingworkper-
tinenttothisAOsetting.
ProposedMethod
Mutant-X(Mahmoodetal.2019)isanautomatedobfus-
cation method that utilizes genetic algorithms to iteratively Figure2illustratesALISON’soverallobfuscationpipeline.
makesingle-wordsubstitutionsbyexaminingtheconfidence ALISON is designed to reduce computational complexity
degradationgleanedfromablack-boxunderstandingofthe while advancing obfuscation success and semantic preser-
attackedmodel.Whilethisisablack-boxattackmethod,we vationduringobfuscation.Todothis,weemploythreeover-
repurposeditasablindattackasdescribedintransferability archingstrategies.First,wetrainaninternal,lightweightAA
studies associated with its original paper (Mahmood et al. classifieroncethatusesintuitivelinguisticpropertiesofpart-
2019).AvengersEnsemble(Haroonetal.2021)attemptsto of-speech(POS)sequencestoguidetheobfuscationprocess.
improveuponMutant-Xanddecreaserelianceonblack-box Second,weaimtoobfuscateaphraseofmultiplewordsata
knowledgeofthetargetclassifierbyutilizinganensemble- time instead of perturbing token by token. Third, we lever-
basedinternalclassifiertoimprovethetransferabilityofthe ageanadvancedpre-trainedlanguagemodel(PLM)togen-
method to a variety of adversaries, which boosts its per- erate the replacement token sequence that best fits the sen-
formance in the blind attack setting. We will refer to this tence context and semantics without making queries to an
methodasAvengersfortherestofthepaper. embeddingspace.ALISON
Tokens POS N-gram Feature Importance POS Sequence Masking Masked Token Obfuscated Text
Generation Ranking Replacement
Help me pick a <VB> <PRP> <VB> <DT> <VB> <DT> <NN> Help me <MASK> <MASK> Help me search for Help me
place to work <NN> <TO> <VB> ... <MASK> to work offices to work search for offices to work
Repeat L times <VB> <PRP> <VB> <IN>
<NNS> <TO> <VB>
Figure2:ALISON:Ourproposedobfuscationpipeline.
One-TimeStylisticInternalAAClassifierTraining tance,for∀t∈T usingIntegratedGradients (Sundararajan,
Because blind attacks on AA models often rely on an in- Taly,andYan2017),amodelinterpretabilityalgorithmthat
ternalapproximationofanarbitraryadversarialclassifierto assignsanimportancescoretoeachinputfeaturebyapprox-
choosecandidatewordsorphrasestobereplaced,tuningthe imatingtheintegralofthegradientswithrespecttotheinput.
internalclassifierformaximaltransferabilitytoothertarget We also multiply each extracted importance by the term
classifiersisintegraltoproducinghighobfuscationsuccess clength(feature) for each feature’s attribution, where c is a
rate(Haroonetal.2021).Therefore,weaugmentthetradi- constant.Duringexperimentation,weempiricallyobserved
tional internal classifier feature space of character n-grams thatshorterPOSn-gramsweremoreabundantatthebegin-
with POS n-grams, features we believe to be more heavily ning of the attribution-ranked n-gram lists. We believe that
rootedintruestyle.Wehypothesizethatwhilewritingstyle this behavior is because of the necessarily lesser frequency
encompasses word and character frequencies, more gener- ofanarbitrarilylongerPOSn-gramintypicaltexts,aseach
ally,writingstylealsoencompassesfrequenciesofindivid- longern-gramoccurrencenecessarilyisanoccurrenceofall
ualPOStagsandtheircollocations.Intuitively,POSandse- contiguous substrings of the n-gram, i.e., shorter n-grams.
quences of several POS tags capture writing style because Therefore,weintroducedthisscalingconstanttoartificially
they do not describe the content of the text but rather how inflatetheimportanceoflongerPOSn-gramstocompensate
the ideas in the text are synthesized. Generally, an author’s forthisbehavior.
textsshouldcontainsimilarPOSsequencepatterns,asthey
representcommontextualstructuresusedtosynthesizedif- ReplacementPhraseGenerationviaMaskedPLM
ferentideas.
To perform obfuscation, we must be able to generate re-
Feature Extraction. We first extract the POS tags of all placementphrasesusingexistingphrasesasprompts.Todo
textsinthecorpusX∗.Next,weextractcharacterandPOS this, we leverage the masked language modeling approach
tag n-grams of various lengths as features for training the usedby Devlinetal.(2019).Morespecifically,givenasen-
internal classifier. Figure 3 demonstrates the procedure of tenceandthedesiredwordtokenstobereplaced,wemask
extractingPOSn-gramsfromasamplesentencewithn←3. thetokenstobereplacedandusethismodifiedtextasinput
for a BERT model under a masked token prediction task.
The top prediction for each masked token is used as the
Help me pick a place to work
Verb (VB)Pronoun (PRP)Verb (VB) Determiner (DT)Noun (NN)Particle (PRT)Verb (VB) word’sreplacement.ByusingaSOTAlanguagemodel,we
POS
trigrams VBPRPVB PRPVB DT VB DT NN DT NNPRT NNPRTVB aim to minimize the degree of information loss, as the lan-
guagemodelwillbeabletoinfermuchofthecontentsofthe
Figure3:AnexampleofextractingPOStrigrams. phrase through context but may scramble POS sequences,
which hides authorship. This token-sequence masking pro-
Ann-gramisacontiguoussequenceofnlinguisticunits cedure lies at the core of ALISON’s speed-up, allowing a
(e.g.,characters,words,POStags)withinatext.Givenaset singlePLMforwardpasstoperturbmultipletokens.
of sequence lengths V, for each length l ∈ V, we extract
allcharacterandPOSlevell-gramsovertheentiretraining TextObfuscationProcess:OneN-GramataTime
corpus and collect the L most frequent character and POS
To obfuscate each t ∈ T, we first extract the POS tags
l-grams. The normalized frequencies of these L most fre-
and n-gram features for t, which are used to compute im-
quentcharacterandPOSl-gramsforeachlengthl ∈ V are
portance values as described previously. Then, we iterate
concatenatedtoformthestylisticrepresentationsofthetext.
through the ranked feature list in descending order of im-
Internal Classifier Training. The resulting vector repre- portance, omitting character n-gram features (only consid-
sentationsarethenusedtotrainafullyconnectedneuralnet- eringPOSn-gramfeatures)andpickthetopLfeatures.We
work(NN)modelontheauthorshipattributiontask.Weopt omitcharactern-gramsbecauseimportantcharactern-grams
forasimpleNNduetoitscomputationalefficiencywithout aregenerallyfunctionalwordsorinvolvepunctuation,which
much compromise on generalization. To utilize this model wouldnegativelyimpactfluencyuponperturbation.
forprioritizingwhichphasesorwordsinasentencetoper- Next, we attempt to match each of the top L POS n-
turbfirst,wethenextractalistoffeatures,rankedbyimpor- gramstothePOSn-gramprofileoft.Foreachn-grammatchfound, we update t through the phrase generation proce- toprovideafaircomparisonandillustratetheeffectiveness
dureasdescribedpreviously.Lastly,wemarkthisphraseas of our stylometry-grounded approach. BERT-Attack was
changedsothatitcannotbechangedinsubsequentstepsas trainedusingstandardBERT(Devlinetal.2019).ChatGPT-
topreventanyspecificsectionoftextfromdeviatingsignif- basedobfuscationwasperformedbypretendingafixedpara-
icantly from the original. Obfuscation is complete once all phrasingprompttoeachtextandobtainingthereturnedma-
matchesforthetopLPOSn-gramsareprocessed. chineresponse.
OneuniquepropertyofALISONisthatitwillmodifythe
EvaluationMetrics
text even if the internal classifier believes it will be classi-
fiedincorrectly.ThispropertyisdesirablebecauseALISON • Obfuscation Success. The most intuitive measure of ob-
will uniformly obfuscate all texts, likely decreasing adver- fuscationsuccessismeasuringthetargetAAmodel’saccu-
sarial classifier confidence even if a complete obfuscation racy. Because there is a potential for the label distribution
is unsuccessful. This differs from logit query-based meth- tobecomeskewedduringtheremovalofmisclassifiedsam-
ods because they do not attempt to perform any obfusca- ples, we also measure F1-Score, a more robust metric in
tion if their internal classifier’s prediction does not match suchasetting.Toanalyzetheobfuscationsuccess,wealso
thegroundtruth,leadingtoalargeproportionoft ∈ T be- monitorthereductionintargetmodelaccuracybetweenthe
ingcompletelyuneditedandthereforevulnerable. originalandobfuscatedtexts.Becauseweonlyretaincor-
rectly classified samples for obfuscation, the baseline ac-
ExperimentalSetup curacy and F1-Score are 1.00. A smaller post-obfuscation
accuracyandF1-Scoreindicatesamoresuccessfulattack,
Datasets. We use TuringBench (Uchendu et al. 2021) to
andthereforegreaterobfuscationsuccess.
evaluateALISONonmachine-generatedtexts.TuringBench • RunningTime.First,werecordedtherunningtimeofeach
isacollectionof160Khumanandmachine-generatedtexts
algorithm, as an obfuscation method that requires a pro-
across 20 authors, 19 of which are neural text generation
hibitiveamountofresourcesorcomputationtimemaynot
models, and one of whom is human. We also use the Blog
be scalable to real world AO scenarios. We split this time
AuthorshipCorpus(Schleretal.2006)toevaluateALISON
measurementintotwophases,thetimeassociatedwithone-
on human-written texts. The dataset consists of the aggre-
timetrainingofinternalclassifiers,andthetimeassociated
gated blog posts of 19,320 bloggers gathered from blog-
withtheaverageinferencetimeoftheretainedsamples.
ger.com,ofwhichweselectonlytheblogsfromthetop-10 • Semantic Preservation. We also measure metrics of se-
mostfrequentauthors.Bothdatasetsarepubliclyavailable.
mantic preservation or semantic similarity between the
WereportallAOresultsonthetestset.
original and obfuscated texts. Metrics indicating higher
Target Classifiers. We use three SOTA transformer-based semantic preservation are favorable, as they indicate that
modelsastargetAAclassifierstoattack:BERT(Devlinetal. therewasalimiteddegreeofinformationlossandthatthe
2019), DistilBERT (Sanh et al. 2019), and RoBERTa (Liu perturbations to the text would not significantly impair a
et al. 2019). These adversarial classifiers were trained on reader’s understanding of the original text. These metrics
the1stdisjointhalf ofthetrainingandvalidationsets.They include (1) METEOR Score: METEOR score is a stan-
achieved around 80% testing accuracy on on TuringBench, dard for measuring the similarity between two texts in a
while demonstrating varying performance on the Blog Au- natural language setting. It is grounded in the measure of
thorship Corpus, ranging from approximately 85% (Distil- alignmentsofwordunigramsamongtexts;(2)USECosine
BERT)to95%(RoBERTa)testingaccuracy. Similarity: The Universal Sentence Encoder (USE) (Cer
et al. 2018) is a text embedding model that is frequently
Obfuscation Baselines and Internal Classifier Training.
adoptedtoaccuratelycapturethesemanticsofasentence.
We utilize TextFooler, Mutant-X, Avengers, BERT-Attack,
We utilize cosine-similarity to determine the degree of
andChatGPTasbaselinestocompareagainstourproposed
similaritybetweengeneratedembeddings;(3)BERTScore:
AOframeworkALISON.ExceptforChatGPT,thesemeth-
BERTScore (Zhang et al. 2020) is another metric of se-
ods all maintain an internal classifier for reference during
manticsimilaritythatutilizesBERT’spretrainedcontextual
obfuscation.Whilemanyoftheseareblack-boxattackmeth-
embeddings.BERTScoreiscalculatedbymaximizingpair-
ods, we repurposed them for the blind attack setting us-
wise embedding similarities for the tokens of an original
ingtheinternalclassifierspecificationsgivenintransferabil-
and its obfuscated text. All scores lie in [0,1], and higher
ity studies instead of giving them access to our SOTA tar-
scoresdenotegreatersemanticsimilarity.
get models. Our neural-network-based n-gram classifier is
• Fluency. Lastly, we measure the perplexity of obfuscated
trainedonthedisjoint2ndhalfofthetrainingandvalidation
textstoensurethattheobfuscationprocessdoesnotdimin-
data that was not used to train our SOTA target models us-
ishthehumanreadabilityofobfuscatedtexts.Theperplex-
ing V = {1,2,3,4}. Internal classifiers for Mutant-X and
ityiscalculatedasthenegativelog-likelihoodofLLaMA2-
Avengers were trained as outlined by their papers (Haroon
7B(Touvronetal.2023)overobfuscatedtexts.
et al. 2021; Mahmood et al. 2019) on the same data as our
internal classifier. TextFooler was trained with both word-
Results
basedCNN(wordCNN)(Kim2014)andword-basedLSTM
(wordLSTM) internal classifiers as specified in their pub- Obfuscation Success. The experimental results on both
licimplementation.WeadditionallytestedTextFoolerusing datasetsfromourmainobfuscationexperimentaresumma-
our n-gram-based NN model (denoted as TextFooler-POS) rizedbyTable1.Inthetable,wedenotethemetricindicat-ObfuscationSuccess(LowerisBetter) SemanticPreservation(HigherisBetter)
Method Accuracy↓ F1-Score↓ METEOR↑ USECosineSimilarity↑ BERTScore↑
TuringBench
BERT
Mutant-X 0.8987 0.8798 0.8381 0.9159 0.9366
Avengers 0.8354 0.8334 0.8333 0.9030 0.9320
TextFooler-wordCNN 0.7089 0.6797 0.8667 0.9614 0.9386
TextFooler-wordLSTM 0.7342 0.6935 0.8813 0.9671 0.9430
TextFooler-POS 0.7595 0.7011 0.8650 0.9635 0.9382
BERT-Attack 0.9114 0.9179 0.8388 0.8701 0.9526
ChatGPT 0.7089 0.6566 0.8373 0.9113 0.9490
ALISON 0.6962(-1.79%) 0.6065(-7.63%) 0.8505(-3.49%) 0.9682(0.11%) 0.9583(0.60%)
DistilBERT
Mutant-X 0.9494 0.9464 0.8450 0.9192 0.9406
Avengers 0.9113 0.8515 0.8341 0.9048 0.9320
TextFooler-wordCNN 0.7848 0.7556 0.8641 0.9609 0.9413
TextFooler-wordLSTM 0.7722 0.7705 0.8819 0.9677 0.9447
TextFooler-POS 0.7972 0.7955 0.8675 0.9657 0.9391
BERT-Attack 0.8228 0.8172 0.8434 0.8737 0.9538
ChatGPT 0.7456 0.6474 0.8428 0.9142 0.9494
ALISON 0.5823(-21.90%) 0.4925(-23.93%) 0.8538(-3.19%) 0.9685(0.08%) 0.9588(0.52%)
RoBERTa
Mutant-X 0.9014 0.8527 0.8182 0.9062 0.9306
Avengers 0.8028 0.7393 0.8157 0.8967 0.9248
TextFooler-wordCNN 0.6901 0.6074 0.8621 0.9618 0.9386
TextFooler-wordLSTM 0.7606 0.6682 0.8814 0.9686 0.9446
TextFooler-POS 0.7606 0.6760 0.8623 0.9624 0.9402
BERT-Attack 0.8451 0.8412 0.8279 0.8603 0.9484
ChatGPT 0.7924 0.6569 0.8268 0.9057 0.9436
ALISON 0.6620(-4.07%) 0.5624(-7.41%) 0.8554(-2.95%) 0.9701(0.15%) 0.9595(1.17%)
BlogAuthorshipCorpus
BERT
Mutant-X 0.9130 0.9180 0.8325 0.8514 0.9237
Avengers 0.9565 0.9528 0.8894 0.9028 0.9316
TextFooler-wordCNN 0.9348 0.9305 0.8854 0.9472 0.9356
TextFooler-wordLSTM 0.9565 0.9531 0.8811 0.9439 0.9382
TextFooler-POS 0.9348 0.9476 0.8838 0.9453 0.9321
BERT-Attack 0.9130 0.8914 0.9007 0.9221 0.9202
ChatGPT 0.9022 0.8908 0.6720 0.8827 0.9368
ALISON 0.8804(-2.42%) 0.7860(-11.76%) 0.8296(-7.89%) 0.9551(0.83%) 0.9386(0.04%)
DistilBERT
Mutant-X 0.9048 0.9128 0.8209 0.8497 0.9135
Avengers 0.9405 0.9435 0.8826 0.9044 0.9305
TextFooler-wordCNN 0.8810 0.8570 0.8839 0.9465 0.9356
TextFooler-wordLSTM 0.8810 0.8425 0.8786 0.9427 0.9382
TextFooler-POS 0.8810 0.8591 0.8832 0.9442 0.9349
BERT-Attack 0.9048 0.8784 0.9026 0.9245 0.9205
ChatGPT 0.9762 0.9712 0.6524 0.8820 0.9347
ALISON 0.7738(-12.17%) 0.7189(-14.67%) 0.8431(-6.59%) 0.9595(1.37%) 0.9387(0.05%)
RoBERTa
Mutant-X 0.9895 0.9886 0.8285 0.8514 0.9232
Avengers 1.00 1.00 0.8886 0.9033 0.9331
TextFooler-wordCNN 0.3579 0.3397 0.8872 0.9496 0.9370
TextFooler-wordLSTM 0.3684 0.3394 0.8832 0.9464 0.9382
TextFooler-POS 0.3369 0.3295 0.8654 0.9417 0.9339
BERT-Attack 0.9053 0.8737 0.9018 0.9239 0.9205
ChatGPT 0.5684 0.5939 0.6682 0.8844 0.9368
ALISON 0.3053(-9.38%) 0.2912(-11.62%) 0.8288(-8.09%) 0.9544(0.51%) 0.9452(0.75%)
Table 1: Results from main obfuscation trials, 15 < L < 25. Best performance is shown in boldface. The percentage (%)
indicates the performance gain of ALISON compared to the 2nd best competition if positive (or drop if negative) per each
metric.Method One-TimeTrainingInference Semantic Preservation. Across both datasets, ALISON
TuringBench consistently outperforms in semantic preservation when
Mutant-X 4hrs 3min evaluated with USE cosine similarity, the most robust
Avengers 6hrs 5min measure of semantic preservation we measured, and
TextFooler-wordCNN 2hrs 8sec BERTScore. However, we observe that ALISON consis-
TextFooler-wordLSTM 2hrs 7sec tently performs the worst in terms of METEOR score on
BERT-Attack 6hrs 8sec
bothdatasets;however,webelievethatthisresultcanlargely
ALISON 12min 0.8sec
beattributedtotheinherentflawsoftheMETEORscore,as
BlogAuthorshipCorpus
it is generally less correlated with human judgments when
Mutant-X 8min 10min
comparedtoUSEcosinesimilarity,whichisastrongerstan-
Avengers 24min 14min
TextFooler-wordCNN 2hrs 11sec dardforsemanticsimilarityanalysis.Wedemonstratethese
TextFooler-wordLSTM 2hrs 9sec limitationsintheAppendix.
BERT-Attack 6hrs 9sec Fluency.Table 3demonstratesthatALISONdemonstrates
ALISON 6min 1.0sec thebestperplexityacrossbothdatasets,indicatingthehigh-
estreadabilityacrossallAOmethods.
Table 2: Statistics of the one-time training runtime and the
averageinferencetimeperonesampleforallmethods. Method TuringBench Blog
Mutant-X 65.12 29.55
Avengers 64.51 23.12
ing the most favorable attack in bold (the metric with the
TextFooler-wordCNN 57.69 17.96
lowest magnitude for obfuscation success metrics, and the
TextFooler-wordLSTM 52.89 19.28
metric with the highest magnitude for semantic preserva-
TextFooler-POS 56.23 18.34
tion metrics) across each adversarial trial. Additionally, for
ALISON 20.82 12.11
the rows containing results for ALISON, we show the per-
centagechangeofeachmetricfromthemethodthatwasthe
Table3:Perplexityofpost-obfuscationtextsmeasuredusing
highest performing, excluding ALISON. Therefore a lower
LLaMA2-7B(lowerisbetter).
percentage(higherdegradationofadversarialaccuracy/F1-
Score) is more desirable for obfuscation success metrics,
whileahigherpercentage(lesssemanticdegradation)isfa-
vorableforsemanticpreservationmetrics. Discussion
OnTuringBench,weseethatALISONisconsistentlythe AuthorLabelBias.First,weanalyzethedistributionofau-
bestperformerintermsofattacksuccess.ALISONconsis- thorfrequenciesbeforeandafterobfuscationtoidentifypo-
tentlydegradesadversarialaccuracymorethanothermeth- tential obfuscation bias towards an author or set of authors
ods, demonstrating improvement as high as 21.90%. Addi- onbothdatasets.Todothis,wecalculatethenormalizeden-
tionally,F1-Scoreevenmorepronounceddegradation,with tropyofauthorlabelsoverobfuscatedsamples.
improvementashighas23.93%. Becauseofthevariedattacksuccessesofdifferentmeth-
OntheBlogAuthorshipCorpus,resultsshowninTable1 ods,wedonotconsidertherawentropyvaluesbutinstead,
indicate that ALISON is consistently the best performer in considertheproportionofthetotallabelentropyeachauthor
termsofF1-Scoreandaccuracy. contributes. The distribution of these label entropy propor-
AblationofInterpretability-BasedReplacement.Weob- tions should be as uniform as possible so that each author
serve that ALISON outperforms TextFooler-POS in all tri- label transforms in an unpredictable way. A non-uniform
als. This demonstrates the value of ALISON’s sequence entropydistributionacrossauthorsindicatesthattheobfus-
replacement schema and interpretability-centric approach cation of a small pool of authors’ texts contributes signif-
when compared to traditional token-by-token perturbation icantly to the overall attack success. This indicates a bias
methods. during obfuscation in regard to the transformation of au-
ComputationalComplexity.Runningtimeresultsaresum- thor labels, a bias that can potentially be exploited by the
marized by Table 2. The One-Time Training stage encom- attackedmodel.Ifthepost-obfuscationpredictionlabelwere
passesalloperationsassociatedwithdatafeatureextraction predictable based on the pre-obfuscation prediction label,
and one-time training, while Inference corresponds to per- an adversary would be able to gain significant information
textrunningtime. abouttheauthorshipofatextbasedonthepredictedauthor
The results indicate that ALISON outperforms all base- post-obfuscation.Thisbiasisfurthernotdesirablesincethe
linesbothintermsofone-timetrainingandobfuscationrun- authorshippoolmayvaryfromvariousobfuscationsettings.
time. ALISON’s total time for both one-time training and We present the individual author entropy contributions
obfuscationof100samplesindicatesatleasta10xspeed-up over all authors for all methods in Figure 4. It is visually
on TuringBench and at least an 18x speed-up on the Blog apparent that the distribution of author entropy contribu-
Authorship Corpus. ALISON is additionally at least 10x tionsissignificantlymoreuniformforALISONwhencom-
faster on TuringBench and 20x faster on the Blog Author- paredtoothermethods.Thisindicatessignificantlylesspre-
ship Corpus with respect to one-time training and at least dictabilityandlabelbiasduringobfuscationwhencompared
10xfasterduringobfuscationonbothdatasets. to other methods. There are very few labels with a smallObfuscationSuccess SemanticPreservation
Method
Accuracy↓F1-Score↓METEOR↑USECosineSimilarity↑BERTScore↑
GPTOutputDetector-Base 0.5000 0.3670 0.6966 0.8754 0.8941
GPTOutputDetector-Large 0.5682 0.3623 0.6948 0.8734 0.9017
GPTZero 0.6170 0.5323 0.6897 0.8717 0.8936
DetectGPT 0.5729 0.4984 0.7478 0.9030 0.9134
Table4:ALISON’sattacksuccessandsemanticpreservationagainstfourmachinetextdetectionmodels.
Methodology.WeusednewsarticleheadlinesfromTuring-
BenchtoquerytheOpenAICompletionsAPI.Asinglere-
quest was made for each unique headline, which consisted
ofafixedgenerationpromptprependedtotheheadline.The
correspondinghuman-writtentextsintheTuringBenchcor-
pusprovidednegativeexamplestointroduceintothecorpus,
generating a set of evenly distributed negative and positive
examples.Theexperimentalsetupdescribedpreviouslywas
thenrepeated.
Main Obfuscation Trial Result. Table 4 shows metrics of
Figure 4: Distribution of author-wise contributions to label
ObfuscationSuccessandSemanticPreservationagainstad-
entropypost-obfuscation.
versarial classifiers. ALISON demonstrates degradation of
adversarial accuracy to at most 0.617 and adversarial F1-
Scoretoatmost 0.5323.Inaddition,ALISONconsistently
ornonexistentcontributiontooverallentropy,whicharela- maintainsahighdegreeofsemanticsimilaritybetweenorig-
belsthatcouldbetriviallyreverse-engineeredbythetargeted inalandobfuscationtexts,maintainingatleast0.8717USE
model,unliketheentropydistributionsofothermethods. CosineSimilarityand0.8936BERTScore.ChatGPTtextde-
Interpretability. Because ALISON relies on explicitly de- tectorsbecomenegligiblyusefulatsuchadversarialperfor-
terminedcriteriaforobfuscation,itcanexplainobfuscation mance,astheadversarialaccuracyisclosetothetrivialac-
decisionsusingquantifiedtokenimportances.Interpretabil- curacyof0.50inthebinaryclassificationsetting.
ity is generated by extracting the POS n-grams in a text
EntropyResult.Weobserveanentropyof0.56associated
andusingIntegratedGradientstogeneratetheimportanceof
withthehumanclassandanentropyof0.44associatedwith
each POS n-gram, which is scaled as described previously.
the ChatGPT class. Because the distribution of authorship
Top POS n-gram features may then be mapped to specific
label entropy is not significantly skewed toward any class,
tokensequencesintheoriginaltext.
ALISON does not demonstrate a significant degree of bias
during the obfuscation process in transferring attributions
AUseCase:ObfuscatingChatGPTTexts
fromanyspecificclass.
The impressive performance of ChatGPT (OpenAI 2023),
a conversational language model, has led to its ubiquitous
use in the workplace and classroom. Though ChatGPT can
Conclusion
assisthumanswitheverydaytasks,itspotentiallydishonest
applications (e.g. construing ChatGPT’s output as human-
writtentextinacademicsettings)maketheidentificationof
Wehavepresentedanewauthorshipobfuscationtechnique,
ChatGPT-writtentextsanimportantproblemwithextensive
ALISON,basedonthereplacementofrevealingstylisticse-
commercialandacademicstudy (Tian2022;Mitchelletal.
quences. ALISON greedily replaces text sequences match-
2023;Solaimanetal.2019;Wang,Le,andLee2023).The
ing POS n-grams identified to be important by interpret-
commercial value of ChatGPT detection further motivates
ingalightweightneuralnetworktrainedtoperformauthor-
anAOtechniquethatiscomputationallyefficient.
ship attribution using mixed n-grams. We use ALISON to
ProblemFormulation.Thereal-worldtaskofdiscriminat- attack three SOTA transformer-based attribution classifiers
ingbetweenChatGPTandhuman-writtentextsisanincreas- anddemonstrateanimprovementinobfuscationsuccessand
ingly relevant AA task that motivates the study of the cor- semanticpreservationwhencomparedtosevendiversebase-
responding AO task. We select four well-known machine- lines. We demonstrate that ALISON’s intuitive and simple
text generators, each demonstrating > 95% discrimination but effective nature demonstrates a drastic improvement in
accuracy,tostudyunderadversarialperturbation:GPTZero computational complexity compared to baseline methods.
(Tian 2022), DetectGPT (Mitchell et al. 2023), and both Parameteranalysis,qualitativeanalysisofALISON’sobfus-
theBaseandLargeGPTOutputdetectors (Solaimanetal. catedtexts,limitationsofMETEORscore,etc.arepresented
2019)releasedbyOpenAI. intheAppendix.EthicalStatement Mitchell, E.; Lee, Y.; Khazatsky, A.; Manning, C. D.;
and Finn, C. 2023. DetectGPT: Zero-Shot Machine-
Whileauthorshipobfuscationenablesfreedomofspeechfor
Generated Text Detection using Probability Curvature.
various previously described individuals including whistle-
arXiv:2301.11305.
blowersandjournalists,italsopotentiallypermitsmalicious
groups to stay hidden. We acknowledge such ethical con- OpenAI.2023.GPT-4TechnicalReport.arXiv:2303.08774.
cerns but stress the need to study and design systems that Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright,
can protect and enhance the freedom of speech of the pub- C.L.;Mishkin,P.;Zhang,C.;Agarwal,S.;Slama,K.;Ray,
lic. A.; Schulman, J.; Hilton, J.; Kelton, F.; Miller, L.; Simens,
M.; Askell, A.; Welinder, P.; Christiano, P.; Leike, J.; and
Acknowledgements Lowe,R.2022. Traininglanguagemodelstofollowinstruc-
ThisworkwassupportedinpartbyNSFawards#1820609, tionswithhumanfeedback. arXiv:2203.02155.
#1950491,and#2131144. Sanh,V.;Debut,L.;Chaumond,J.;andWolf,T.2019. Dis-
tilBERT,adistilledversionofBERT:smaller,faster,cheaper
References andlighter. arXivpreprintarXiv:1910.01108.
Abbasi,A.;andChen,H.-c.2008. Writeprints:AStylomet- Schler,J.;Koppel,M.;Argamon,S.;andPennebaker,J.W.
ric Approach to Identity-level Identification and Similarity 2006. Effects of age and gender on blogging. In AAAI
Detection in Cyberspace. ACM Transactions on Informa- springsymposium:Computationalapproachestoanalyzing
tionSystems,26:1–29. weblogs,volume6,199–205.
Cer, D.; Yang, Y.; Kong, S.-y.; Hua, N.; Limtiaco, N.; Solaiman, I.; Brundage, M.; Clark, J.; Askell, A.; Herbert-
St. John, R.; Constant, N.; Guajardo-Cespedes, M.; Yuan, Voss, A.; Wu, J.; Radford, A.; Krueger, G.; Kim, J. W.;
S.; Tar, C.; Strope, B.; and Kurzweil, R. 2018. Universal Kreps, S.; McCain, M.; Newhouse, A.; Blazakis, J.;
SentenceEncoderforEnglish. InConferenceonEmpirical McGuffie, K.; and Wang, J. 2019. Release Strategies and
MethodsinNaturalLanguageProcessing. theSocialImpactsofLanguageModels. arXiv:1908.09203.
Devlin,J.;Chang,M.-W.;Lee,K.;andToutanova,K.2019. Sundararajan, M.; Taly, A.; and Yan, Q. 2017. Axiomatic
BERT:Pre-trainingofDeepBidirectionalTransformersfor AttributionforDeepNetworks. InProceedingsofthe34th
LanguageUnderstanding. InConferenceoftheNorthAmer- InternationalConferenceonMachineLearning.
icanChapteroftheAssociationforComputationalLinguis- Tian, E. 2022. GPTZero. https://gptzero.me/. Accessed:
tics(NAACL),4171–4186. 2023.
Fabien,M.;Villatoro-Tello,E.;Motlicek,P.;andParida,S. Touvron,H.;Martin,L.;Stone,K.;Albert,P.;Almahairi,A.;
2020. BertAA : BERT fine-tuning for Authorship Attribu- Babaei,Y.;Bashlykov,N.;Batra,S.;Bhargava,P.;Bhosale,
tion.InProceedingsofthe17thInternationalConferenceon S.; Bikel, D.; Blecher, L.; Ferrer, C. C.; Chen, M.; Cucu-
NaturalLanguageProcessing(ICON),127–137.IndianIn- rull,G.;Esiobu,D.;Fernandes,J.;Fu,J.;Fu,W.;Fuller,B.;
stituteofTechnologyPatna,Patna,India:NLPAssociation Gao, C.; Goswami, V.; Goyal, N.; Hartshorn, A.; Hosseini,
ofIndia(NLPAI). S.; Hou, R.; Inan, H.; Kardas, M.; Kerkez, V.; Khabsa, M.;
Haroon, M.; Zaffar, M. F.; Srinivasan, P.; and Shafiq, Z. Kloumann, I.; Korenev, A.; Koura, P. S.; Lachaux, M.-A.;
2021. Avengers Ensemble! Improving Transferability of Lavril,T.;Lee,J.;Liskovich,D.;Lu,Y.;Mao,Y.;Martinet,
AuthorshipObfuscation. ArXiv,abs/2109.07028. X.; Mihaylov, T.; Mishra, P.; Molybog, I.; Nie, Y.; Poul-
ton,A.;Reizenstein,J.;Rungta,R.;Saladi,K.;Schelten,A.;
Jin,D.;Jin,Z.;Zhou,J.T.;andSzolovits,P.2020. IsBERT
Silva,R.;Smith,E.M.;Subramanian,R.;Tan,X.E.;Tang,
ReallyRobust?AStrongBaselineforNaturalLanguageAt-
B.; Taylor, R.; Williams, A.; Kuan, J. X.; Xu, P.; Yan, Z.;
tack on Text Classification and Entailment. In The Thirty-
Zarov,I.;Zhang,Y.;Fan,A.;Kambadur,M.;Narang,S.;Ro-
FourthAAAIConferenceonArtificialIntelligence(AAAI).
driguez, A.; Stojnic, R.; Edunov, S.; and Scialom, T. 2023.
Kim, Y. 2014. Convolutional neural networks for sentence
Llama 2: Open Foundation and Fine-Tuned Chat Models.
classification. arXivpreprintarXiv:1408.5882.
arXiv:2307.09288.
Li,L.;Ma,R.;Guo,Q.;Xue,X.;andQiu,X.2020. BERT-
Uchendu, A.; Ma, Z.; Le, T.; Zhang, R.; and Lee, D. 2021.
ATTACK:AdversarialAttackAgainstBERTUsingBERT.
TuringBench:ABenchmarkEnvironmentforTuringTestin
In Webber, B.; Cohn, T.; He, Y.; and Liu, Y., eds., Conf.
the Age of Neural Text Generation. In Conf. on Empirical
on Empirical Methods in Natural Language Processing
MethodsinNaturalLanguageProcessing(EMNLP).
(EMNLP),6193–6202.
Wang,Z.;Le,T.;andLee,D.2023.UPTON:PreventingAu-
Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M.; Chen, D.;
thorshipLeakagefromPublicTextReleaseviaDataPoison-
Levy, O.; Lewis, M.; Zettlemoyer, L.; and Stoyanov, V. ing. InFindingsofConf.onEmpiricalMethodsinNatural
2019. RoBERTa:ARobustlyOptimizedBERTPretraining LanguageProcessing(EMNLP-Findings).
Approach. ArXiv,abs/1907.11692.
Zhang,T.;Kishore,V.;Wu,F.;Weinberger,K.Q.;andArtzi,
Mahmood, A.; Ahmad, F.; Shafiq, Z.; Srinivasan, P.; and
Y. 2020. BERTScore: Evaluating Text Generation with
Zaffar,F.2019. AGirlHasNoName:AutomatedAuthor- BERT. InInt’lConf.onLearningRepresentations(ICRL).
shipObfuscationusingMutant-X. ProceedingsonPrivacy
EnhancingTechnologies,2019:54–71.HyperparameterAnalysis not significantly change across values of c. However, met-
rics of obfuscation success decrease, then increase across
Inthefollowing,weexploretheeffectsofvaryingtwokey
c ∈ [1.0,1.6], where the optimal value of c is between 1.3
parameters on metrics of obfuscation on TuringBench. We
and1.5.Thissupportstheideathatartificiallyscalingimpor-
firstexploretheeffectsofvaryingthevalueofL.Werecord
tancebasedonlengthallowsALISONtochoosesequences
the previously described metrics for values of L ranging
ofoptimallengthtomask.
from 1 to 250. The results of this experiment are summa-
rizedbyFig. 5.
LimitationsofMETEORScore
While ALISON generally outperforms other baselines, we
demonstrate consistent underperformance when measuring
semantic preservation in terms of METEOR score. We be-
lievethatthisbehaviorisduetotheinherentbiasoftheME-
TEOR scoreagainst ALISON’s styleof perturbation. First,
weobservethattheMETEORscorehighlydependsonex-
act spacing. During the process of encoding and decoding
associatedwithobtainingmasked-phrasesubstitutions,erro-
neousspacesareintroducedintothetext.Whilethesespaces
donotimpactinformationlosssignificantly,theydosignifi-
cantlyimpacttheMETEORscore.Withoutanyphrasesub-
stitutions, the spacing changes made by PLM and the re-
construction process degrade the METEOR score to 0.93
on TuringBench and 0.90 on the Blog Authorship Corpus.
Figure 5: Effect of varying L on obfuscation success and However, the USE Cosine Similarity and BERTScore are
semanticpreservation minimally affected, maintaining values of around 0.99. An
exampleofatextexhibitingnear-perfectsemanticpreserva-
ThisfigureindicatesthatincreasingthevalueofLincreases tion (as measured qualitatively, by USE Cosine Similarity,
thechangerateanddecreasesallothermetrics(bothmetrics and by BERTScore) but with a low METEOR score is the
ofobfuscationsuccessandsemanticpreservation).Thisre- following:
sult is intuitive, as increasing the number of sequences to
• Original: That is what it is. Cold and dreary. A Soda
change will, of course, increase the change rate and will
withoutfizz.Boogers.
thereforebemoresuccessfulinfoolingtheadversarialclas-
• Obfuscated:iknowwhatitis.Coldanddreary.ASoda
sifier, and will also cause a greater difference between the
withoutfizz.Boogers.
originalandobfuscatedtexts,decreasingsemanticpreserva-
tion. WhiletheUSECosineSimilarityis0.9409andBERTScore
is 0.9616, the METEOR score is 0.5152. The patterns ex-
Wealsoexploretheeffectofvaryingthevalueofcfrom
hibited in this example, leading to a low METEOR score,
1.0to1.6.Theresultsofthisexperimentaresummarizedin
are repeated throughout many examples in our obfuscation
Fig.6.
method.
However, other baselines do not exhibit these patterns,
withsemanticpreservationscoresgenerallyagreeingmore.
This is because single-word substitutions often leave spac-
ingpatternsandtherelativeorderingofwordsgenerallyun-
changed. The following, a sample taken from Avengers, il-
lustratesthis:
• Original: Went to an information session for people
who might be interested in helping to teach the First
Year Lawyering program next year... it’s an organiza-
tion called the Board of Student Advisors. The meeting
wasn’tfunnyenoughtogivemeanythingfunnytowrite.
• Obfuscated: Went to an info meeting for children who
might become interested in helping to teach the First
Figure6:Effectofvaryingconobfuscationsuccessandse- YearLawyeringinitiativenextmonth...it’sAnwatchdog
manticpreservation called the Board of Student Advisors. The press wasn’t
funnyenoughtogetmenothinghumoroustopublish.
From this, we observe that the value of c does not signifi- This sample demonstrates a METEOR score of 0.7673, a
cantlyimpactmetricsofsemanticpreservation,astheadver- USE Cosine Similarity of 0.8117, and a BERTScore of
sarialMETEOR,USECosineSimilarity,andBERTScoredo 0.9452.QualitativeAnalysis
Weanalyzethetypesofchangesmadebysamplingsomeof
thesentencespre-andpost-obfuscationonTuringBenchand
theBlogAuthorshipCorpus.Thechangesgenerallyfollow
afewdistinctpatterns:
• SynonymSubstitutions:Often,awordintheoriginaltext
isreplacedbyasynonymintheobfuscatedtexts.Forex-
ample,memo⇐⇒novel,perfectly⇐⇒well,smile⇐⇒
laugh, etc. These most likely result from a short POS-
tagsequencebeingidentifiedasimportant,leadingtothe
PLM being able to relatively accurately determine the
meaning of the masked words from context, leading to
littleinformationloss.
• Contextually Acceptable Substitutions: These substitu-
tions involve the substitution of a word or phrase with
asemanticallyunequivalentphrasethatseemsplausibly
correct in context. For example, white ⇐⇒ black, shirt
⇐⇒ dress, shorted ⇐⇒ given, etc. These most likely
arise from a phrase being masked that cannot be reli-
ablydeterminedfromthesurroundingcontext.Thisleads
tothePLMmakinganincorrectinferenceregardingthe
semantic meaning of the masked phrase. While this in-
creasesthedegreeofinformationlossbetweentheorig-
inalandobfuscatedtexts,itdoesnotsignificantlyaffect
thereadabilityoftheobfuscatedtext.
• Deletions: Sometimes, nonessential words and phrases
arecompletelydeletedafterreconstructionwithaPLM.
These deletions often occur in introductory phrases that
contributelittlesemanticmeaning.Althoughrarelyhap-
pen, these deletions may slightly contribute to informa-
tionlossordecreasereadability.
• Equivalent Substitutions Resulting in Solecism: Some-
times,wordsorshortphraseswillbereplacedbynearly
identical substitutes semantically and functionally that
result in a solecism. This results in no information loss,
however, thesolecism may resultin decreased readabil-
ity.Thesesubstitutionsmayindicateinherentlimitations
of BERT for Masked Language Modeling, or inherent
grammaticalerrorsinthedataBERTwastrainedon.Ad-
ditionally,theuncapitalized”i”isalsocommon.