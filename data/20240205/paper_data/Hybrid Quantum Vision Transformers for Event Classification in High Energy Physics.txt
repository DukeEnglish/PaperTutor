Hybrid Quantum Vision Transformers for Event
Classification in High Energy Physics
EyupB.Unlu MarçalComajoanCara
IFT,PhysicsDepartment, DepartmentofSignalTheoryandCommunications
UniversityofFlorida PolytechnicUniversityofCatalonia
Gainesville,FL32611 Barcelona,Barcelona08034,Spain
eyup.unlu@ufl.edu marcal.comajoan@estudiantat.upc.edu
GopalRameshDahale ZhongtianDong RoyT.Forestano
IndianInst. ofTechnologyBhilai Dep.Physics&Astronomy IFT,DepartmentofPhysics
Kutelabhata,Khapri, UniversityofKansas UniversityofFlorida
Chhattisgarh–491001,India Lawrence,KS66045 Gainesville,FL32611
gopald@iitbhilai.ac.in cosmos@ku.edu roy.forestano@ufl.edu
SergeiGleyzer DanielJustice KyoungchulKong
Dep.Physics&Astronomy SoftwareEngineeringInstitute Dep.Physics&Astronomy
UniversityofAlabama CarnegieMellonUniversity UniversityofKansas
Tuscaloosa,AL35487 Pittsburgh,PA15213 Lawrence,KS66045
sgleyzer@ua.edu dljustice@sei.cmu.edu, kckong@ku.edu
TomMagorsch KonstantinT.Matchev KatiaMatcheva
Physik-Department IFT,PhysicsDepartment, IFT,PhysicsDepartment,
TechnischeUniv. München UniversityofFlorida UniversityofFlorida
85748Garching,Germany Gainesville,FL32611 Gainesville,FL32611
tom.magorsch@tum.de matchev@ufl.edu matcheva@ufl.edu
Abstract
Modelsbasedonvisiontransformerarchitecturesareconsideredstate-of-the-art
when it comes to image classification tasks. However, they require extensive
computational resources both for training and deployment. The problem is ex-
acerbated as the amount and complexity of the data increases. Quantum-based
visiontransformermodelscouldpotentiallyalleviatethisissuebyreducingthe
trainingandoperatingtimewhilemaintainingthesamepredictivepower. Although
currentquantumcomputersarenotyetabletoperformhigh-dimensionaltasksyet,
theydoofferoneofthemostefficientsolutionsforthefuture. Inthiswork,we
constructseveralvariationsofaquantumhybridvisiontransformerforaclassifica-
tionprobleminhighenergyphysics(distinguishingphotonsandelectronsinthe
electromagneticcalorimeter). Wetestthemagainstclassicalvisiontransformer
architectures. Ourfindingsindicatethatthehybridmodelscanachievecomparable
performancetotheirclassicalanalogueswithasimilarnumberofparameters.
1 Introduction
Thefirsttransformerarchitecturewasintroducedin2017byVaswanietal. inafamouspaper"Atten-
tionIsAllYouNeed"[24]. Thenewmodelwasshowntooutperformtheexistingstate-of-the-art
modelsbyasignificantmarginfortheEnglish-to-GermanandEnglish-to-Frenchnewstest2014
4202
beF
1
]hp-tnauq[
1v67700.2042:viXratests. Since then, the transformer architecture has been implemented in numerous fields and be-
camethego-tomodelformanydifferentapplicationssuchassentimentanalysis[20]andquestion
answering[13].
The vision transformer architecture can be considered as the implementation of the transformer
architectureforimageclassification. Itutilizestheencoderpartofthetransformerarchitectureand
attachesamulti-layerperceptron(MLP)layertoclassifyimages.Thisarchitecturewasfirstintroduced
by Dosovitskiy et al. in the paper "An Image is Worth 16x16 Words: Transformers for Image
RecognitionatScale"[7]. Itwasshownthatinamultitudeofdatasets,avisiontransformermodelis
capableofoutperformingthestate-of-the-artmodelResNet152x4whileusinglesscomputationtime
topre-train. Similartotheirlanguagecounterparts,visiontransformersbecamethestate-of-the-art
modelsforamultitudeofcomputervisionproblemssuchasimageclassification[26]andsemantic
segmentation[9].
However,theseadvantagescomewithacost. Transformerarchitecturesareknowntobecomputa-
tionallyexpensivetotrainandoperate[23]. Specifically,theirdemandsonthecomputationpower
andmemoryincreasequadraticallywiththeinputlength. Anumberofstudieshaveattemptedto
approximateself-attentioninordertodecreasetheassociatedquadraticcomplexityinmemoryand
computationpower[11,25,6,19]. Therearealsoproposedmodificationsofthearchitecturewhich
aimtoalleviatethequadraticcomplexity[15,27,5]. Arecentreviewonthedifferentmethodsfor
reducingthecomplexityoftransformerscanbefoundin[10]. Astheamountofdatagrows,these
problemsareexacerbated. Inthefuture,itwillbenecessarytofindasubstitutearchitecturethathas
similarperformancebutdemandsfewerresources.
Aquantummachinelearningmodeljustmightbeoneofthosesubstitutes. Althoughthehardware
forquantumcomputationisstillinitsinfancy,thereisahighvolumeofresearchthatisfocusedon
thealgorithmsthatcanbeusedonthishardware. Themainappealofquantumalgorithmsisthat
theyarealreadyknowntohavecomputationaladvantagesovertheclassicalalgorithmsforavariety
ofproblems. Forinstance,Shor’salgorithmcanfactorizenumberssignificantlyfasterthanthebest
classicalmethods[22]. Furthermore,therearestudiessuggestingthatquantummachinelearningcan
leadtocomputationalspeedups[21,8].
Inthiswork,wedevelopaquantum-classicalhybridvisiontransformerarchitecture. Wedemonstrate
ourarchitectureonaproblemfromexperimentalhighenergyphysics,whichisanidealtestingground
becauseexperimentalcolliderphysicsdataisknowntohaveasignificantamountofcomplexity,and
computationalresourcesrepresentamajorbottleneck[1,2,12]. Specifically,weuseourmodelto
classifytheparentparticleinanelectromagneticshowereventinsidetheCMSdetector. Inaddition,
wewilltesttheperformanceofourhybridarchitecturebybenchmarkingitagainstaclassicalvision
transformerofequivalentarchitecture.
Thepaperisstructuredasfollows. Insection2, wepresentanddescribethedataset. Themodel
architecturesforboththeclassicalandhybridmodelsarediscussedinsection3.Themodelparameters
andthetrainingarespecifiedinsection4and5,respectively. Finally,insection6weshowourresults
anddiscusstheminsection7. WediscussfuturedirectionsforstudyinSection8.
2 DatasetandPreprocessingDescription
The Compact Muon Solenoid (CMS) is one of the four largest experiments at the Large Hadron
Collider (LHC) at CERN. The CMS detector records the products from proton-proton collisions
at 13.6 TeV center-of-mass energy. Among the basic types of objects reconstructed from those
collisionsarephotonsandelectrons,whichleaverathersimilarsignaturesintheCMSelectromagnetic
calorimeter(ECAL).Acommontaskinhighenergyphysicsistoclassifytheresultingelectromagnetic
showerintheECALasaphoton(γ)orelectron(e−). Inpractice,onealsousesinformationfromthe
tracker,butforthepurposesofourstudy,weshalllimitourselvestotheECALonly.
Thedatasetusedinourstudycontainsthereconstructedhitsof498000simulatedelectromagnetic
showereventsintheECALsub-detectoroftheCMSexperiment[3]. Halfoftheeventsoriginate
fromphotons,whiletheremaininghalfareinitiatedbyelectrons. Ineachcase,aneventisgenerated
withexactlyoneparticle(γ ore−)whichisfiredfromtheinteractionpointwithfixedtransverse(i.e.,
orthogonaltothebeamline)momentumcomponentofp =50GeV.Thedirectionofthemomentum
T
issampleduniformlyinpseudorapidity−1.4≤η ≤1.4andinazimuthalangle−π ≤φ≤π.
2Foreachevent,thedatasetincludestwoimagegrids,representingenergyandtiminginformation,
respectively. Thefirstgridgivesthepeakenergydetectedbythecrystalsofthedetectorina32x32
gridcenteredaroundthecrystalwiththemaximumenergydeposit. Thesecondimagegridgivesthe
arrivaltimewhenpeakenergywasmeasuredintheassociatedcrystal. (Inourwork,weshallonly
usethefirstimagegridwiththeenergyinformation.) Eachpixelinanimagegridcorrespondsto
exactlyoneECALcrystal,thoughnotnecessarilythesamecrystalfromoneeventtoanother. The
imageswerethenscaledsothatthemaximumentryforeacheventwassetto1. Severalrepresentative
examplesofourimagedataareshowninFig.1.
Figure1: Fourrepresentativeimagegridexamplesfromthedataset,inthe(φ,η)plane. Thefirstrow
showstheimagegridsfortheenergy(normalizedanddisplayedinlog scale),whilethesecondrow
10
displaysthetiminginformation(notusedinourstudy). Thetitleslistthetruelabels(realelectronor
realphoton),aswellasthecorrespondinglabelspredictedbyoneofthebenchmarkclassicalmodels.
AscanbegleanedfromFig.1withthenakedeye,electron-photondiscriminationisachallenging
task. Tofirstapproximation,thee− andγ showerprofilesareidentical,andmostlyconcentrated
ina3x3gridofcrystalsaroundthemaindeposit. However,interactionswiththemagneticfieldof
theCMSsolenoid(B =3.8T)causeelectronstoemitbremsstrahlungradiation,preferentiallyinφ.
Thisintroducesahigher-orderperturbationontheshowershape,causingthee−showerprofilestobe
morespreadoutandslightlyasymmetricinφ.
3 ModelArchitectures
Thefollowingdefinitionswillbeusedfortherestofthepaperandarelistedhereforconvenience.
• n : Numberoftokens/patches
t
• d : Flattenedpatchlength
i
• d : Tokenlength
t
• n : Numberofheads
h
• d
h
≡ nd ht: Datalengthperhead
• d : Thedimensionofthefeed-forwardnetwork
ff
3.1 GeneralModelStructure
Boththebenchmarkandhybridmodelsutilizethesamearchitecturesexceptforthetypeofencoder
layers. ThesearchitecturesareshowninFig. 2. Ascanbeseeninthefigure,therewillbetwomain
variantsofthearchitecture: (a)column-poolingvariantand(b)classtokenvariant.
Astheencoderlayeristhemaincomponentofboththeclassicalandthehybridmodels,theywill
bediscussedinmoredetailinsubsections3.2and3.3,respectively. Therestofthearchitectureis
discussedhere.
3(a)
Positional
Embedding
Column-wisePooling
Linear Encoder
+ MLP
Embedding Layer
(32,LReLU,1)
x
N Sigmoid
Probabilities
(b)
Positional
Embedding
ExtractClassToken
Linear Encoder
Embedding Concat + Layer MLP
(32,LReLU,1)
x
N Sigmoid
ClassToken Probabilities
Figure2: Thearchitectureforthe(a)column-wisepoolingand(b)theclass-tokenmodels. Forclarity,
weuseaMNISTimage[16]todemonstratetheprocess. Thehybridandtheclassicalmodeldifferby
thearchitectureoftheirencoderlayers(seeFigures3and4).
First,westartbydividingourinputpictureinton patchesofequalarea,whicharethenflattened
t
toobtainn vectorswithlengthd . Theresultingvectorsareafterwardsconcatenatedtoobtaina
t i
n ×d matrixforeachimagesample. Thismatrixispassedthroughalinearlayerwithabias(called
t i
"LinearEmbedding"inthefigure)tochangethenumberofcolumnsfromd toadesirablenumber
i
(tokendimension,referredtoasd ).
t
Ifthemodelisaclasstokenvariant,atrainablevectoroflengthd isconcatenatedasthefirstrow
t
ofthematrixathand(module"Concat"inFig.2b). Afterthat,anon-trainablevectorisaddedto
eachrow(calledthepositionalembeddingvector). Thentheresultisfedtoaseriesofencoderlayers
whereeachsubsequentencoderlayerusesitspredecessor’soutputasitsinput.
Ifthemodelisaclasstokenvariant,thefirstrowoftheoutputmatrixofthefinalencoderlayeris
fedintotheclassifyinglayertoobtaintheclassificationprobabilities("ExtractClassToken"layerin
Fig.2b). Otherwise,acolumn-poolingmethod(takethemeanofalltherowsortakethemaximum
valueforeachcolumn)isusedtoreducetheoutputmatrixintoavector,thenthisvectorisfedintothe
classifyinglayertoobtaintheclassificationprobabilities("Column-wisePooling"layerinFig.2a).
3.2 Theclassicalencoderlayer
ThestructureoftheclassicalencoderlayercanbeseeninFig. 3a. First,westartbystandardizing
theinputdatatohavezeromeanandstandarddeviationofone. Afterwards,thenormalizeddatais
fedtothemulti-headattention(discussedinthenextparagraph)andtheoutputissummedwiththe
unnormalizeddata. Then,themodifiedoutputisagainnormalizedtohavezeromeanandstandard
deviationofone. Thisnormalizedmodifieddataisthenfedintoamultilayerperceptronoftwolayers
withhiddenlayersized andtheresultissummedupwiththemodifieddatatoobtainthefinal
ff
result.
Themulti-headattentionworksbyseparatingourinputmatrixinton manyn ×d matricesby
h t h
splittingthemthroughtheircolumns. Afterwards,thesplitmatricesarefedtotheattentionheads
describedinEqs.(1-2). Finally,theoutputsoftheattentionheadsareconcatenatedtoobtainan ×d
t t
matrix,whichhasthesamesizeasourinputmatrix. Eachattentionheadisdefinedas
(cid:32) (x W(i))(x W(i))T(cid:33)
AttentionHead(x ;W(i),W(i),W(i))=SoftMax i K√ i Q (x W(i))
i K Q V d i V
h
W K(i) ∈R(dh×dh),W Q(i) ∈R(dh×dh),W V(i) ∈R(dh×dh)d
h
≡d t/n h; (1)
4Classical Encoder Layer
(a)
Multi-Head MLP
Data Layernorm + LayerNorm +
Attention (d ff,GELU,d t)
Attention
Head1
(b)
...
Multi-Head
Attention: Data Split ... Concatenate
...
Attention
Headd
h
Figure3: Theclassicalencoderlayerarchitectureforthebenchmarkmodels.
where
X =[x
1
x
2
... x nh]∈R(nt×dt), x
i
∈R(nt×dh) (2)
istheinputmatrix.
3.3 HybridEncoderLayer
Hybrid Encoder Layer
(a)
Hybrid
MLP
Data Layernorm Multi-Head +
(d ,GELU,d )
Attention ff t
Hybrid
Attention
Head1
(b)
...
Multi-Head
Attention: Data Split ... Concatenate
...
Hybrid
Attention
Headd
h
Figure4: Thehybridencoderlayerarchitectureforthebenchmarkmodels.
ThestructureofthehybridencoderlayercanbeseeninFig.4a. Firstly,westartbystandardizingthe
inputdatatohavezeromeanandstandarddeviationofone. Afterward,thenormalizeddataisfedto
thehybridmulti-headattentionlayer(discussedinthenextparagraph). Then,theoutputisfedintoa
multilayerperceptronoftwolayerswithhiddenlayersized ,andtheresultissummedupwiththe
ff
unnormalizeddatatoobtainthefinalresult.
5Figure5: KeyandQuerycircuitforthed =8case. Thefirsttworowsofcircuitsloadthedatato
h
thecircuit(Uˆ(x )operator),whiletherestarethepartsofthetrainableansatz. Thereforethetotal
i
numberofparametersforeachcircuitisequalto3d +1.
h
Thehybridmulti-headattentionworksbyseparatingourinputmatrixinton manyn ×d matrices
h t h
bysplittingthemthroughtheircolumns. Afterwards,thesplitmatricesarefedtothehybridattention
heads(whicharedescribedinthebulletedprocedurebelow). Finally,theoutputsoftheattention
headsareconcatenatedtoobtainann ×d matrix,whichhasthesamesizeasourinputmatrix.
t t
The hybrid attention heads we used are almost identical to the architecture implemented in [17],
"QuantumSelf-AttentionNeuralNetworksforTextClassification"byLietal. Inordertoreplacethe
self-attentionmechanismofaclassicalvisiontransformerinEq.(1),weusethefollowingprocedure:
• Definex astheithrowoftheinputmatrixX.
i
• DefinethedataloaderoperatorUˆ(x )as
i
|x i⟩≡Uˆ(x
i)|0>(dh)=(cid:79)dh
Rˆ x(x ij)Hˆ |0⟩, (3)
j=1
whereHˆ istheHadamardgateandRˆ istheparameterisedrotationaroundthexaxis.
x
• Applythekeycircuit(dataloader+keyoperatorKˆ(θ ))foreachx andobtainthecolumn
K i
vectorK(seefig. 5).
K =⟨x |Kˆ†(θ )Zˆ Kˆ(θ )|x ⟩, 1≤i≤d , (4)
i i K 0 K i t
whereZˆ isspinmeasurementoftheithqubitonthezdirection.
i
• Applythequerycircuit(dataloaderUˆ(x )+queryoperatorQˆ(θ ))foreachx andobtain
i Q i
thecolumnvectorQ(seeFig.5).
Q =⟨x |Qˆ†(θ )Zˆ Qˆ(θ )|x ⟩, 1≤i≤d . (5)
i i Q 0 Q i t
• Obtainthesocalledattentionmatrixusingthekeyandthequeryvectorsusingthefollowing
expression
A =−(Q −K )2; 1≤i≤d ,1≤j ≤d . (6)
ij i j t t
• Applythevaluecircuit(dataloader+valueoperatorVˆ(θ ))toeachrowoftheimageand
V
measureeachqubitseparatelytoobtainthevaluematrix. (SeeFig.6)
V =⟨x |Vˆ†(θ )Zˆ Vˆ(θ )|x ⟩,|x ⟩=Uˆ(x )|0 >; 1≤i≤d ,1≤j ≤d . (7)
ij i V j V i i i n t h
• Definetheselfattentionoperationas,
(cid:18) (cid:19)
A
HybridAttentionHead: SoftMax √ V. (8)
d
h
6Figure6: Thevaluecircuitusedforthed =8case. Thefirsttworowsofcircuitsloadthedatato
h
thecircuit(Uˆ(x )operator),whiletherestarethepartsofthetrainableansatz. Therefore,thetotal
i
numberoftrainableparametersforeachcircuitisequalto3d .
h
4 Hyper-Parameters
Thenumberofparametersisafunctionofthehyper-parametersforboththeclassicalandthehybrid
models. However,thesefunctionsaredifferent. Bothmodelssharethesamelinearembeddingand
classifyinglayer.Thelinearembeddinglayercontains(d +1)d manyparametersandtheclassifying
i t
layercontains32d +65parameters.
t
Foreachclassicalencoderlayer,wehaven manyattentionheadswhichallcontain3d2 parameters
h h
from Q, K, V layers respectively. In addition, the MLP layer inside each encoder layer contains
2d d +d +d parameters.Overall,eachclassicalvisiontransformerhasd (33+d )+n (2d d +
ff t ff t t i l ff t
d +d +3n d2)parametersexcepttheclasstokenvariationwhichhasextrad parameters.
ff t h h t
Foreachhybridencoderlayer,wehaven manyattentionheadswhichallcontain9d +2parameters
h h
from Q, K, V layers respectively. In addition, MLP layer inside each encoder layer contains
2d d +d +d parameters.Overall,eachhybridvisiontransformerhasd (33+d )+n (2d d +
ff t ff t t i l ff t
d +d +n (9d +2))parametersexcepttheclasstokenvariationwhichhasextrad parameters.
ff t h h t
Therefore,assumingtheyhavethesamehyper-parameters,thedifferencebetweenthenumberof
parametersfortheclassicalandhybridmodelisn (d (3d −9)−2n ).
l t h h
Ourpurposewastoinvestigatewhetherourarchitecturemightperformsimilarlytoaclassicalvision
transformerwherethenumberofparametersareclosetoeachother. Inordertouseasimilarnumber
ofparameters,wepickedaregionofhyperparameterssuchthatthisdifferenceisratherminimal. For
allmodels,thefollowingparameterswereused:
• n =5
l
• d =16
t
• n =16
t
• n =4
h
• d h = dd hi =4
• d =16.
ff
7(a)
(b)
Figure7: BCElossonthevalidationandtrainingsetduringtrainingforthe(a)quantumand(b)
classicalmodels. Fromlefttoright, eachcolumncorrespondstoadifferentmodelvariant: class
token(leftcolumn),columnmax(middlecolumn)andcolumnmeanvariant(rightcolumn). For
eachplot,theblue(orange)linecorrespondstothevalidation(training)setlossforthemodelwith
positionalencoding,whereasthedashedgreen(red)linecorrespondstothevalidation(training)set
lossforthemodelwithoutpositionalencodinglayer.
Therefore,forourexperimentthenumberofparametersfortheclassicalmodels(4785to4801)is
slightlymorethanthequantummodels(4585to4601).
5 TrainingProcess
All the classical parts of the models were implemented in PyTorch [18]. The quantum circuit
simulationsweredoneusingTensorCircuitwiththeJAXbackend[4,28]. Eachmodelwastrainedfor
40epochs. Thecriteriafortheselectionofthebestmodeliterationwastheaccuracyonthevalidation
data. TheoptimizerusedwastheADAMoptimizerwithlearningrateλ=5∗10−3[14]. Allmodels
weretrainedonGPUs. Thebatchsizewas512forallmodelsaswell. Thelossfunctionutilizedwas
thebinarycrossentropy. Thecodeusedtocreateandtrainthemodelscanbefoundatthefollowing
githubrepository: EyupBunlu/QViT_HEP_ML4Sci.
6 Results
ThetraininglossandtheaccuracyonthevalidationandtrainingdataareplottedinFigures7and8,
respectively. Inaddition,themodelswerecomparedonseveralmetricssuchastheaccuracy,binary
crossentropylossandAUC(areaundertheROCcurve)onthetestdata. Thiscomparisonisshown
inTable1.
8(a)
(b)
Figure8: ThesameasFigure7,butfortheaccuracyonthevalidationandtrainingsetduringtraining
forthe(a)quantumand(b)classicalmodels.
Model Positional Accuracy BCELoss AUCScore Trainable
Encoding (Cls/Hybrid) (Cls/Hybrid) (Cls/Hybrid) Paraneters
(Cls/Hybrid)
WithClassToken Yes .717/.502 .564/.6931 .780/.501 4801/4601
WithClassToken No .720/.502 .561/.6931 .783/.500 4801/4601
ColumnMax(CMX) Yes .718/.718 .562/.565 .783/.779 4785/4585
ColumnMax(CMX) No .722/.718 .557/.565 .786/.779 4785/4585
ColumnMean(CMN) Yes .720/.696 .559/.592 .784/.751 4785/4585
ColumnMean(CMN) No .720/.692 .560/.595 .783/.748 4545/4785
Table1: Comparisontableforthemodels. Theaccuracy, theBCElossandtheAUCscorewere
calculated on the test data. For each entry, the first number corresponds to the classical model,
whereasthesecondonecorrespondstothehybridmodel.
7 Discussion
AsseeninTable1,thepositionalencodinghasnosignificanteffectontheperformancemetrics. We
notethattheCMXvariant(eitherwithorwithoutpositionalencoding)performssimilarlytothe
correspondingclassicalmodel. Thissuggeststhataquantumadvantagecouldbeachievedwhen
extrapolatingtohigher-dimensionalproblemsanddatasets,sincethequantummodelsscalebetter
withdimensionality.
On the other hand, Table 1 shows that hybrid CMN variants are inferior to their hybrid CMX
counterpartsforallmetrics. Thismightbeduetothefactthattakingthemeanforceseachelement
oftheoutputmatrixofthefinalencoderlayertoberelevant, unliketheCMXvariant, wherethe
maximumvaluesarechosen. Thiscouldexplainthelargernumberofepochsrequiredtoconverge
inthecaseofthehybridCMN(seeFig.7and8). Itisalsopossiblethatthehybridmodellacksthe
expressivenessrequiredtoencodeenoughmeaningfulinformationtothecolumnmeans.
Somewhatsurprisingly,thetrainingplotsofthehybridclasstokenvariants(upperleftpanelsinFigs.7
and8)showthatthehybridclasstokenvariantsdidnotconvergeduringournumericalexperiments.
Thereasonbehindthisbehavioriscurrentlyunknownandisbeinginvestigated.
98 Outlook
Quantummachinelearningisarelativelynewfield. Inthiswork,weexploredafewofthemany
possible ways that it could be used to perform different computational tasks as an alternative to
classicalmachinelearningtechniques. Asthecurrenthardwareforquantumcomputersimproves
further,itisimportanttoexploremorewaysinwhichthishardwarecouldbeutilized.
Ourstudyraisesseveralquestionswhichwarrantfutureinvestigations. First,weobservethatthe
hybridCMXmodelsperformsimilarlytotheclassicalvisiontransformermodelswhichweused
forbenchmarking. Itisfairtoaskifthissimilarityisduetothecomparablenumberoftrainable
parameters or the result of identical choice of hyper-parameter values. If it is the latter, we can
extrapolateandconcludethatasthesizeofthedatagrows,hybridmodelswillstillperformaswellas
theclassicalmodelswhilehavingsignificantlyfewernumberofparameters.
Itisfairtosaythatboththeclassicalandhybridmodelsperformsimilarlyatthisscale. However,
thehybridmodeldiscussedinthisworkismostlyclassical,exceptfortheattentionheads. Thenext
stepinourresearchistoinvestigatetheeffectofincreasingthefractionofquantumelementsofthe
model. Forinstance,theconversionoffeed-forwardlayersintoquantumcircuitssuchasthevalue
circuitmightleadtoanevenbiggeradvantageinthenumberoftrainableparametersbetweenthe
classicalandhybridmodels.
Althoughtheobservedlimitationsintheclasstokenandcolumnmeanvariantsmightappeardisap-
pointingatfirstglance,theyarealsoimportantfindingsofthiswork. Itisworthinvestigatingwhether
thisisduetothenatureofthedatasetorasignofafundamentallimitationinthemethod.
9 SoftwareandCode
Thedatasetusedinthisanalysisisdescribedin[3]andisavailableatElectronsandPhotons. The
codeusedtocreateandtrainthemodelscanbefoundatEyupBunlu/QViT_HEP_ML4Sci.
Acknowledgements
ThisresearchusedresourcesoftheNationalEnergyResearchScientificComputingCenter,aDOE
OfficeofScienceUserFacilitysupportedbytheOfficeofScienceoftheU.S.DepartmentofEnergy
underContractNo. DE-AC02-05CH11231usingNERSCawardNERSCDDR-ERCAP0025759. SG
issupportedinpartbytheU.S.DepartmentofEnergy(DOE)underAwardNo. DE-SC0012447. KM
issupportedinpartbytheU.S.DOEawardnumberDE-SC0022148. KKissupportedinpartbyUS
DOEDE-SC0024407. CDissupportedinpartbyCollegeofLiberalArtsandSciencesResearch
FundattheUniversityofKansas. CD,RF,EU,MCCandTMwereparticipantsinthe2023Google
SummerofCode.
References
[1] J.Albrechtetal. ARoadmapforHEPSoftwareandComputingR&Dforthe2020s. Comput.
Softw.BigSci.,3(1):7,2019. doi: 10.1007/s41781-018-0018-8.
[2] S.Amorosoetal. ChallengesinMonteCarloEventGeneratorSoftwareforHigh-Luminosity
LHC. Comput.Softw.BigSci.,5(1):12,2021. doi: 10.1007/s41781-021-00055-1.
[3] M.Andrews,M.Paulini,S.Gleyzer,andB.Poczos. End-to-EndEventClassificationofHigh-
EnergyPhysicsData. J.Phys.Conf.Ser., 1085(4):042022, 2018. doi: 10.1088/1742-6596/
1085/4/042022.
[4] J.Bradbury,R.Frostig,P.Hawkins,M.J.Johnson,C.Leary,D.Maclaurin,G.Necula,A.Paszke,
J. VanderPlas, S. Wanderman-Milne, and Q. Zhang. JAX: composable transformations of
Python+NumPyprograms,2018. URLhttp://github.com/google/jax.
[5] K.Choromanski,V.Likhosherstov,D.Dohan,X.Song,A.Gane,T.Sarlos,P.Hawkins,J.Davis,
A.Mohiuddin,L.Kaiser,D.Belanger,L.Colwell,andA.Weller. Rethinkingattentionwith
performers,2022.
10[6] T.Dao,D.Y.Fu,S.Ermon,A.Rudra,andC.Ré. Flashattention: Fastandmemory-efficient
exactattentionwithio-awareness,2022.
[7] A.Dosovitskiy,L.Beyer,A.Kolesnikov,D.Weissenborn,X.Zhai,T.Unterthiner,M.Dehghani,
M.Minderer,G.Heigold,S.Gelly,J.Uszkoreit,andN.Houlsby. Animageisworth16x16
words: Transformersforimagerecognitionatscale. InInternationalConferenceonLearning
Representations,2021. URLhttps://openreview.net/forum?id=YicbFdNTTy.
[8] V.DunjkoandH.J.Briegel.Machinelearning&artificialintelligenceinthequantumdomain:a
reviewofrecentprogress. ReportsonProgressinPhysics,81(7):074001,jun2018. ISSN1361-
6633. doi: 10.1088/1361-6633/aab406. URLhttp://dx.doi.org/10.1088/1361-6633/
aab406.
[9] Y.Fang,W.Wang,B.Xie,Q.Sun,L.Wu,X.Wang,T.Huang,X.Wang,andY.Cao. Eva:
Exploring the limits of masked visual representation learning at scale. In 2023 IEEE/CVF
ConferenceonComputerVisionandPatternRecognition(CVPR).IEEE,jun2023.doi:10.1109/
cvpr52729.2023.01855. URLhttp://dx.doi.org/10.1109/CVPR52729.2023.01855.
[10] Q.Fournier,G.M.Caron,andD.Aloise. Apracticalsurveyonfasterandlightertransformers.
ACM Comput. Surv., 55(14s), jul 2023. ISSN 0360-0300. doi: 10.1145/3586074. URL
https://doi.org/10.1145/3586074.
[11] A.GuptaandJ.Berant. Value-awareapproximateattention,2021.
[12] T.S.Humble,G.N.Perdue,andM.J.Savage. SnowmassComputationalFrontier: Topical
GroupReportonQuantumComputing,92022.
[13] C.Jun,H.Jang,M.Sim,H.Kim,J.Choi,K.Min,andK.Bae. ANNA:Enhancedlanguage
representationforquestionanswering. InProceedingsofthe7thWorkshoponRepresentation
LearningforNLP,pages121–132,Dublin,Ireland,may2022.AssociationforComputational
Linguistics.doi:10.18653/v1/2022.repl4nlp-1.13.URLhttps://aclanthology.org/2022.
repl4nlp-1.13.
[14] D.P.KingmaandJ.Ba. Adam: Amethodforstochasticoptimization,2017.
[15] N.Kitaev,ŁukaszKaiser,andA.Levskaya. Reformer: Theefficienttransformer,2020.
[16] Y.LeCunandC.Cortes. MNISThandwrittendigitdatabase. http://yann.lecun.com/exdb/mnist/,
2010. URLhttp://yann.lecun.com/exdb/mnist/.
[17] G.Li,X.Zhao,andX.Wang. Quantumself-attentionneuralnetworksfortextclassification,
2022.
[18] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,
N.Gimelshein,L.Antiga,A.Desmaison,A.Kopf,E.Yang,Z.DeVito,M.Raison,A.Tejani,
S.Chilamkurthy,B.Steiner,L.Fang,J.Bai,andS.Chintala. Pytorch:Animperativestyle,high-
performancedeeplearninglibrary. InAdvancesinNeuralInformationProcessingSystems32,
pages8024–8035.CurranAssociates,Inc.,2019.URLhttp://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
[19] H. Peng, N. Pappas, D. Yogatama, R. Schwartz, N. Smith, and L. Kong. Random feature
attention. In International Conference on Learning Representations, 2021. URL https:
//openreview.net/forum?id=QtTKTdVrFBB.
[20] C.Raffel,N.Shazeer,A.Roberts,K.Lee,S.Narang,M.Matena,Y.Zhou,W.Li,andP.J.Liu.
Exploringthelimitsoftransferlearningwithaunifiedtext-to-texttransformer. J.Mach.Learn.
Res.,21(1),jan2020. ISSN1532-4435.
[21] R. A. Servedio and S. J. Gortler. Equivalences and separations between quantum and clas-
sical learnability. SIAM Journal on Computing, 33(5):1067–1092, 2004. doi: 10.1137/
S0097539704412910.
11[22] P. W. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms on
aquantumcomputer. SIAMJournalonComputing, 26(5):1484–1509, 1997. doi: 10.1137/
S0097539795293172. URLhttps://doi.org/10.1137/S0097539795293172.
[23] S.Tuli, B.Dedhia, S.Tuli, andN.K.Jha. Flexibert: Arecurrenttransformerarchitectures
toohomogeneousandrigid? JournalofArtificialIntelligenceResearch,77:39–70,2023. doi:
10.1613/jair.1.13942.
[24] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and
I.Polosukhin. Attentionisallyouneed. InProceedingsofthe31stInternationalConference
onNeuralInformationProcessingSystems,NIPS’17,page6000–6010,RedHook,NY,USA,
2017.CurranAssociatesInc. ISBN9781510860964.
[25] Y.Xiong,Z.Zeng,R.Chakraborty,M.Tan,G.Fung,Y.Li,andV.Singh. Nyströmformer: A
nyström-basedalgorithmforapproximatingself-attention,2021.
[26] X.Yu,Y.Xue,L.Zhang,L.Wang,T.Liu,andD.Zhu. NoisyNN:ExploringtheInfluenceof
InformationEntropyChangeinLearningSystems. arXive-prints,art.arXiv:2309.10625,sep
2023. doi: 10.48550/arXiv.2309.10625.
[27] M.Zaheer,G.Guruganesh,A.Dubey,J.Ainslie,C.Alberti,S.Ontanon,P.Pham,A.Ravula,
Q.Wang,L.Yang,andA.Ahmed. Bigbird: transformersforlongersequences. InProceedings
ofthe34thInternationalConferenceonNeuralInformationProcessingSystems,NIPS’20,Red
Hook,NY,USA,2020.CurranAssociatesInc. ISBN9781713829546.
[28] S.-X.Zhang, J.Allcock, Z.-Q.Wan, S.Liu, J.Sun, H.Yu, X.-H.Yang, J.Qiu, Z.Ye, Y.-Q.
Chen,C.-K.Lee,Y.-C.Zheng,S.-K.Jian,H.Yao,C.-Y.Hsieh,andS.Zhang. Tensorcircuit: a
quantumsoftwareframeworkforthenisqera.Quantum,7:912,feb2023.ISSN2521-327X.doi:
10.22331/q-2023-02-02-912. URLhttp://dx.doi.org/10.22331/q-2023-02-02-912.
12