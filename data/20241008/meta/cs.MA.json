[
    {
        "title": "Distributed Networked Multi-task Learning",
        "authors": "Lingzhou HongAlfredo Garcia",
        "links": "http://arxiv.org/abs/2410.03403v1",
        "entry_id": "http://arxiv.org/abs/2410.03403v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03403v1",
        "summary": "We consider a distributed multi-task learning scheme that accounts for\nmultiple linear model estimation tasks with heterogeneous and/or correlated\ndata streams. We assume that nodes can be partitioned into groups corresponding\nto different learning tasks and communicate according to a directed network\ntopology. Each node estimates a linear model asynchronously and is subject to\nlocal (within-group) regularization and global (across groups) regularization\nterms targeting noise reduction and generalization performance improvement\nrespectively. We provide a finite-time characterization of convergence of the\nestimators and task relation and illustrate the scheme's general applicability\nin two examples: random field temperature estimation and modeling student\nperformance from different academic districts.",
        "updated": "2024-10-04 13:10:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03403v1"
    },
    {
        "title": "Multi-Robot Motion Planning with Diffusion Models",
        "authors": "Yorai ShaoulItamar MishaniShivam VatsJiaoyang LiMaxim Likhachev",
        "links": "http://arxiv.org/abs/2410.03072v1",
        "entry_id": "http://arxiv.org/abs/2410.03072v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03072v1",
        "summary": "Diffusion models have recently been successfully applied to a wide range of\nrobotics applications for learning complex multi-modal behaviors from data.\nHowever, prior works have mostly been confined to single-robot and small-scale\nenvironments due to the high sample complexity of learning multi-robot\ndiffusion models. In this paper, we propose a method for generating\ncollision-free multi-robot trajectories that conform to underlying data\ndistributions while using only single-robot data. Our algorithm, Multi-robot\nMulti-model planning Diffusion (MMD), does so by combining learned diffusion\nmodels with classical search-based techniques -- generating data-driven motions\nunder collision constraints. Scaling further, we show how to compose multiple\ndiffusion models to plan in large environments where a single diffusion model\nfails to generalize well. We demonstrate the effectiveness of our approach in\nplanning for dozens of robots in a variety of simulated scenarios motivated by\nlogistics environments. View video demonstrations in our supplementary\nmaterial, and our code at: https://github.com/yoraish/mmd.",
        "updated": "2024-10-04 01:31:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03072v1"
    },
    {
        "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
        "authors": "Patara TriratWonyong JeongSung Ju Hwang",
        "links": "http://arxiv.org/abs/2410.02958v1",
        "entry_id": "http://arxiv.org/abs/2410.02958v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02958v1",
        "summary": "Automated machine learning (AutoML) accelerates AI development by automating\ntasks in the development pipeline, such as optimal model search and\nhyperparameter tuning. Existing AutoML systems often require technical\nexpertise to set up complex tools, which is in general time-consuming and\nrequires a large amount of human effort. Therefore, recent works have started\nexploiting large language models (LLM) to lessen such burden and increase the\nusability of AutoML frameworks via a natural language interface, allowing\nnon-expert users to build their data-driven solutions. These methods, however,\nare usually designed only for a particular process in the AI development\npipeline and do not efficiently use the inherent capacity of the LLMs. This\npaper proposes AutoML-Agent, a novel multi-agent framework tailored for\nfull-pipeline AutoML, i.e., from data retrieval to model deployment.\nAutoML-Agent takes user's task descriptions, facilitates collaboration between\nspecialized LLM agents, and delivers deployment-ready models. Unlike existing\nwork, instead of devising a single plan, we introduce a retrieval-augmented\nplanning strategy to enhance exploration to search for more optimal plans. We\nalso decompose each plan into sub-tasks (e.g., data preprocessing and neural\nnetwork design) each of which is solved by a specialized agent we build via\nprompting executing in parallel, making the search process more efficient.\nMoreover, we propose a multi-stage verification to verify executed results and\nguide the code generation LLM in implementing successful solutions. Extensive\nexperiments on seven downstream tasks using fourteen datasets show that\nAutoML-Agent achieves a higher success rate in automating the full AutoML\nprocess, yielding systems with good performance throughout the diverse domains.",
        "updated": "2024-10-03 20:01:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02958v1"
    },
    {
        "title": "Grounded Answers for Multi-agent Decision-making Problem through Generative World Model",
        "authors": "Zeyang LiuXinrui YangShiguang SunLong QianLipeng WanXingyu ChenXuguang Lan",
        "links": "http://arxiv.org/abs/2410.02664v1",
        "entry_id": "http://arxiv.org/abs/2410.02664v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02664v1",
        "summary": "Recent progress in generative models has stimulated significant innovations\nin many fields, such as image generation and chatbots. Despite their success,\nthese models often produce sketchy and misleading solutions for complex\nmulti-agent decision-making problems because they miss the trial-and-error\nexperience and reasoning as humans. To address this limitation, we explore a\nparadigm that integrates a language-guided simulator into the multi-agent\nreinforcement learning pipeline to enhance the generated answer. The simulator\nis a world model that separately learns dynamics and reward, where the dynamics\nmodel comprises an image tokenizer as well as a causal transformer to generate\ninteraction transitions autoregressively, and the reward model is a\nbidirectional transformer learned by maximizing the likelihood of trajectories\nin the expert demonstrations under language guidance. Given an image of the\ncurrent state and the task description, we use the world model to train the\njoint policy and produce the image sequence as the answer by running the\nconverged policy on the dynamics model. The empirical results demonstrate that\nthis framework can improve the answers for multi-agent decision-making problems\nby showing superior performance on the training and unseen tasks of the\nStarCraft Multi-Agent Challenge benchmark. In particular, it can generate\nconsistent interaction sequences and explainable reward functions at\ninteraction states, opening the path for training generative models of the\nfuture.",
        "updated": "2024-10-03 16:49:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02664v1"
    },
    {
        "title": "Agents' Room: Narrative Generation through Multi-step Collaboration",
        "authors": "Fantine HuotReinald Kim AmplayoJennimaria PalomakiAlice Shoshana JakobovitsElizabeth ClarkMirella Lapata",
        "links": "http://arxiv.org/abs/2410.02603v1",
        "entry_id": "http://arxiv.org/abs/2410.02603v1",
        "pdf_url": "http://arxiv.org/pdf/2410.02603v1",
        "summary": "Writing compelling fiction is a multifaceted process combining elements such\nas crafting a plot, developing interesting characters, and using evocative\nlanguage. While large language models (LLMs) show promise for story writing,\nthey currently rely heavily on intricate prompting, which limits their use. We\npropose Agents' Room, a generation framework inspired by narrative theory, that\ndecomposes narrative writing into subtasks tackled by specialized agents. To\nillustrate our method, we introduce Tell Me A Story, a high-quality dataset of\ncomplex writing prompts and human-written stories, and a novel evaluation\nframework designed specifically for assessing long narratives. We show that\nAgents' Room generates stories that are preferred by expert evaluators over\nthose produced by baseline systems by leveraging collaboration and\nspecialization to decompose the complex story writing task into tractable\ncomponents. We provide extensive analysis with automated and human-based\nmetrics of the generated output.",
        "updated": "2024-10-03 15:44:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.02603v1"
    }
]