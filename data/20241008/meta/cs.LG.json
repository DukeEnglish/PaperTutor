[
    {
        "title": "System 2 reasoning capabilities are nigh",
        "authors": "Scott C. Lowe",
        "links": "http://arxiv.org/abs/2410.03662v1",
        "entry_id": "http://arxiv.org/abs/2410.03662v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03662v1",
        "summary": "In recent years, machine learning models have made strides towards human-like\nreasoning capabilities from several directions. In this work, we review the\ncurrent state of the literature and describe the remaining steps to achieve a\nneural model which can perform System 2 reasoning analogous to a human. We\nargue that if current models are insufficient to be classed as performing\nreasoning, there remains very little additional progress needed to attain that\ngoal.",
        "updated": "2024-10-04 17:59:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03662v1"
    },
    {
        "title": "RAFT: Realistic Attacks to Fool Text Detectors",
        "authors": "James WangRan LiJunfeng YangChengzhi Mao",
        "links": "http://arxiv.org/abs/2410.03658v1",
        "entry_id": "http://arxiv.org/abs/2410.03658v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03658v1",
        "summary": "Large language models (LLMs) have exhibited remarkable fluency across various\ntasks. However, their unethical applications, such as disseminating\ndisinformation, have become a growing concern. Although recent works have\nproposed a number of LLM detection methods, their robustness and reliability\nremain unclear. In this paper, we present RAFT: a grammar error-free black-box\nattack against existing LLM detectors. In contrast to previous attacks for\nlanguage models, our method exploits the transferability of LLM embeddings at\nthe word-level while preserving the original text quality. We leverage an\nauxiliary embedding to greedily select candidate words to perturb against the\ntarget detector. Experiments reveal that our attack effectively compromises all\ndetectors in the study across various domains by up to 99%, and are\ntransferable across source models. Manual human evaluation studies show our\nattacks are realistic and indistinguishable from original human-written text.\nWe also show that examples generated by RAFT can be used to train adversarially\nrobust detectors. Our work shows that current LLM detectors are not\nadversarially robust, underscoring the urgent need for more resilient detection\nmechanisms.",
        "updated": "2024-10-04 17:59:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03658v1"
    },
    {
        "title": "Geometric Representation Condition Improves Equivariant Molecule Generation",
        "authors": "Zian LiCai ZhouXiyuan WangXingang PengMuhan Zhang",
        "links": "http://arxiv.org/abs/2410.03655v1",
        "entry_id": "http://arxiv.org/abs/2410.03655v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03655v1",
        "summary": "Recent advancements in molecular generative models have demonstrated\nsubstantial potential in accelerating scientific discovery, particularly in\ndrug design. However, these models often face challenges in generating\nhigh-quality molecules, especially in conditional scenarios where specific\nmolecular properties must be satisfied. In this work, we introduce GeoRCG, a\ngeneral framework to enhance the performance of molecular generative models by\nintegrating geometric representation conditions. We decompose the molecule\ngeneration process into two stages: first, generating an informative geometric\nrepresentation; second, generating a molecule conditioned on the\nrepresentation. Compared to directly generating a molecule, the relatively\neasy-to-generate representation in the first-stage guides the second-stage\ngeneration to reach a high-quality molecule in a more goal-oriented and much\nfaster way. Leveraging EDM as the base generator, we observe significant\nquality improvements in unconditional molecule generation on the widely-used\nQM9 and GEOM-DRUG datasets. More notably, in the challenging conditional\nmolecular generation task, our framework achieves an average 31\\% performance\nimprovement over state-of-the-art approaches, highlighting the superiority of\nconditioning on semantically rich geometric representations over conditioning\non individual property values as in previous approaches. Furthermore, we show\nthat, with such representation guidance, the number of diffusion steps can be\nreduced to as small as 100 while maintaining superior generation quality than\nthat achieved with 1,000 steps, thereby significantly accelerating the\ngeneration process.",
        "updated": "2024-10-04 17:57:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03655v1"
    },
    {
        "title": "Learning Humanoid Locomotion over Challenging Terrain",
        "authors": "Ilija RadosavovicSarthak KamatTrevor DarrellJitendra Malik",
        "links": "http://arxiv.org/abs/2410.03654v1",
        "entry_id": "http://arxiv.org/abs/2410.03654v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03654v1",
        "summary": "Humanoid robots can, in principle, use their legs to go almost anywhere.\nDeveloping controllers capable of traversing diverse terrains, however, remains\na considerable challenge. Classical controllers are hard to generalize broadly\nwhile the learning-based methods have primarily focused on gentle terrains.\nHere, we present a learning-based approach for blind humanoid locomotion\ncapable of traversing challenging natural and man-made terrain. Our method uses\na transformer model to predict the next action based on the history of\nproprioceptive observations and actions. The model is first pre-trained on a\ndataset of flat-ground trajectories with sequence modeling, and then fine-tuned\non uneven terrain using reinforcement learning. We evaluate our model on a real\nhumanoid robot across a variety of terrains, including rough, deformable, and\nsloped surfaces. The model demonstrates robust performance, in-context\nadaptation, and emergent terrain representations. In real-world case studies,\nour humanoid robot successfully traversed over 4 miles of hiking trails in\nBerkeley and climbed some of the steepest streets in San Francisco.",
        "updated": "2024-10-04 17:57:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03654v1"
    },
    {
        "title": "Minimax-optimal trust-aware multi-armed bandits",
        "authors": "Changxiao CaiJiacheng Zhang",
        "links": "http://arxiv.org/abs/2410.03651v1",
        "entry_id": "http://arxiv.org/abs/2410.03651v1",
        "pdf_url": "http://arxiv.org/pdf/2410.03651v1",
        "summary": "Multi-armed bandit (MAB) algorithms have achieved significant success in\nsequential decision-making applications, under the premise that humans\nperfectly implement the recommended policy. However, existing methods often\noverlook the crucial factor of human trust in learning algorithms. When trust\nis lacking, humans may deviate from the recommended policy, leading to\nundesired learning performance. Motivated by this gap, we study the trust-aware\nMAB problem by integrating a dynamic trust model into the standard MAB\nframework. Specifically, it assumes that the recommended and actually\nimplemented policy differs depending on human trust, which in turn evolves with\nthe quality of the recommended policy. We establish the minimax regret in the\npresence of the trust issue and demonstrate the suboptimality of vanilla MAB\nalgorithms such as the upper confidence bound (UCB) algorithm. To overcome this\nlimitation, we introduce a novel two-stage trust-aware procedure that provably\nattains near-optimal statistical guarantees. A simulation study is conducted to\nillustrate the benefits of our proposed algorithm when dealing with the trust\nissue.",
        "updated": "2024-10-04 17:55:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.03651v1"
    }
]