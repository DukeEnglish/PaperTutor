HyperCMR: Enhanced Multi-Contrast CMR
Reconstruction with Eagle Loss
Ruru Xu1, Caner Özer1,2,3, and Ilkay Oksuz1
1 ComputerEngineeringDepartment,IstanbulTechnicalUniversity,Istanbul,Turkey
2 Department of Artificial Intelligence and Data Engineering, Istanbul Technical
University, Turkey
3 Department of Applied Mathematics, University of Twente, Enschede, 7522 NB,
The Netherlands
xu21@itu.edu.tr
https://github.com/Ruru-Xu/HyperCMR
Abstract. Accelerating image acquisition for cardiac magnetic reso-
nance imaging (CMRI) is a critical task. CMRxRecon2024 challenge
aims to set the state of the art for multi-contrast CMR reconstruction.
This paper presents HyperCMR, a novel framework designed to accel-
erate the reconstruction of multi-contrast cardiac magnetic resonance
(CMR)images.HyperCMRenhancestheexistingPromptMRmodelby
incorporatingadvancedlossfunctions,notablytheinnovativeEagleLoss,
whichisspecificallydesignedtorecovermissinghigh-frequencyinforma-
tion in undersampled k-space. Extensive experiments conducted on the
CMRxRecon2024 challenge dataset demonstrate that HyperCMR con-
sistently outperforms the baseline across multiple evaluation metrics,
achieving superior SSIM and PSNR scores.
Keywords: CardiacMRI·Multi-Modality·Reconstruction·DeepLearn-
ing.
1 Introduction
Multi-contrast cardiac magnetic resonance (CMR) imaging is a crucial tool
for comprehensive cardiac assessment, providing detailed insights into cardiac
structure and function across various contrast levels. Each contrast-weighted
image—such as Cine, Aorta, Mapping, and Tagging—emphasizes different as-
pects of cardiac physiology, making them indispensable for accurate diagno-
sis. However, acquiring these images typically requires extended scan times, in-
creasing patient discomfort and leading to more motion artifacts, complicating
the reconstruction process [2]. Reconstructing multi-contrast CMR images from
undersampled k-space data is particularly challenging because it requires the
preservation of intricate details specific to each contrast, despite their distinct
characteristics. For example, Cine imaging captures the dynamic motion of the
heart, Aorta imaging focuses on the vascular wall, and Mapping requires a pre-
cise depiction of myocardial tissue properties. These varying demands make it
4202
tcO
4
]VI.ssee[
1v42630.0142:viXra2 Ruru Xu et al.
difficult to design a universal reconstruction model that performs well across
multiple modalities. Traditional methods often compromise on essential details
required for certain contrasts or struggle to generalize across different contrast
types [1].
To address these limitations, we introduce HyperCMR, a novel framework
specifically designed to handle the complexities of multi-contrast CMR recon-
struction. HyperCMR builds upon existing deep learning techniques, incorpo-
ratingsubstantialinnovationstotacklethechallengesinherentinmulti-contrast
imaging. A key enhancement is the integration of a specialized loss function,
Eagle Loss [7], engineered to recover the high-frequency information in under-
sampled k-space.
Recent advances in deep learning have demonstrated the feasibility of recon-
structing CMR images from undersampled k-space data [4][3][10][11]. However,
thesemethodsoftenstruggletobalanceglobalstructuralcoherencewithpreserv-
inglocaldetailsacrossdifferentcontrastmodalities.Incontrast,HyperCMRnot
only achieves this delicate balance but also delivers superior reconstruction per-
formance across multiple modalities, providing a robust and effective solution
for multi-contrast CMR reconstruction.
2 Datasets
2.1 Data and Task Description
TheCMRxRecon2024challenge[8]providesthemulti-contrastk-spacedatauti-
lizedinthispaper.Thedatasetisdividedintotraining,validation,andtestsets,
each containing different anatomical views and contrast settings.
The training set includes various CMR modalities, such as Cine (196 sub-
jects),Aorta(154subjects),Mapping(193subjects),andTagging(143subjects),
eachwithdistinctimagingcharacteristicsthathighlightdifferentaspectsofcar-
diac anatomy and function. Additionally, the validation and test sets introduce
two previously unseen contrast modalities: Flow2d and BlackBlood, further in-
creasing the complexity of the reconstruction task. Each modality in the valida-
tion and test sets contains data from 60 subjects.
Theprimaryobjectiveofthischallengeistodevelopacontrast-generalmodel
capable of delivering high-quality image reconstruction from highly accelerated,
uniformly undersampled k-space data. HyperCMR is specifically designed to
address this challenge by improving the reconstruction quality across these dif-
ferent modalities. The inclusion of unseen contrasts in the validation and test
sets underscores the importance of generalization in model performance, which
is a central focus of the HyperCMR framework.
2.2 Datasets processing and Training idea
Based on different modalities (aorta_sag, aorta_tra, cine_lax, cine_sax, cine_
lvot, T1map, T2map, tagging) and different sizes (cine_lax includes two sizes:Efficient CMR Reconstruction 3
Fig.1. Overview of the HyperCMR framework. Our pipeline includes generation of
sensitivity maps and repaired k-space generation with promptUnet.
[:, :, :, 204, 448] and [:, :, :, 168, 448]. cine_sax includes three sizes: [:, :, :, 246,
512], [:, :, :, 162, 512] and [:, :, :, 204, 512]), we divide the dataset into 11 groups
to facilitate us to set different batch sizes for training. The training process is
shown in Algorithm 1.
Algorithm 1 Training process across modality groups
Require: 11 modality groups, max_epochs, model, optimizer
for epoch in range(max_epochs) do
total_train_loss = 0
total_val_loss = 0
for modality_group in [group_1, group_2, ..., group_11] do
modality_train_loss = train_epoch(modality_group, model, optimizer, ...)
modality_val_loss = validate_epoch(modality_group, model, ...)
total_train_loss += modality_train_loss
total_val_loss += modality_val_loss
end for
Compute total_train_loss and total_val_loss for this epoch
end for
3 Methods
3.1 Enhancing PromptMR: The Development of HyperCMR
The HyperCMR framework builds upon the established PromptMR [9] model.
PromptMR is particularly effective in restoring missing information in the low-
frequency regions of undersampled k-space, which contributes significantly to
the overall structural integrity of the reconstructed images. However, it strug-
gles with the recovery of high-frequency details, which are crucial for preserving4 Ruru Xu et al.
the finer structures and textures in CMR images. High-frequency components
typically encode critical information such as sharp edges and intricate patterns,
which are vital for accurate and detailed cardiac assessment. To address this
limitation, HyperCMR introduces several key enhancements, utilizing a combi-
nation of loss functions specifically designed to recover high-frequency informa-
tion from undersampled k-space. By optimizing the model’s ability to focus on
bothlow-andhigh-frequencyregions,HyperCMRachievesamorebalancedand
comprehensive reconstruction performance.
AsillustratedinFigure1,theHyperCMRframeworkleveragesthetemporal
similarity of information by connecting slices from two adjacent time frames.
With the inclusion of 10 coils, the input data format expands to 50 channels,
ultimately producing a single-channel reconstructed image. The process begins
by fixing 16 lines of k-space data, which are subsequently used to estimate sen-
sitivity maps through SensNet. An initial reconstruction is performed using the
inverse Fast Fourier Transform (iFFT), and the resulting image, combined with
the sensitivity maps, undergoes Root Sum of Squares (RSS) calculation to yield
aninitialimagereconstruction.ThisimageisthenrefinedusingthePromptUnet
model, which is central to both the HyperCMR and PromptMR pipelines.
3.2 Loss Functions
Our approach incorporates a set of advanced loss functions, each meticulously
selected and weighted to balance the diverse aspects of CMR image reconstruc-
tion:
- Data Fidelity Loss (k-space domain, α = 1.0): This loss ensures
1
that the repaired k-space data closely matches the fully-sampled ground truth,
focusing on the accurate recovery of k-space information.
L =∥k −k ∥2
fidelity pred fully 2
-SSIM Loss (image domain, α =1.0):Thiscomponentpromotesstruc-
2
turalsimilaritybetweenthereconstructedimageandthegroundtruth,ensuring
perceptual quality and structural integrity.
L =1−SSIM(img ,img )
recons_ssim recons fully
-Eagle Loss (image domain, α =0.05):Specificallydesignedtoenhance
3
high-frequency detail recovery, Eagle Loss plays a crucial role in edge preserva-
tion and the accurate reconstruction of fine structures in CMR images [7].
L =FFT-based high-pass filter loss on variance maps
eagle
- VGG Perceptual Loss (image domain, α = 0.1): This loss guides
4
the network to capture higher-level perceptual features, ensuring that the re-
constructed image maintains visual fidelity in comparison to the ground truth
[5].Efficient CMR Reconstruction 5
(cid:88)
L = ∥VGG (img )−VGG (img )∥2
vgg l recons l fully 2
l
- Regularization Loss (k-space domain, α =0.01): This loss promotes
5
sparsity and smoothness in the repaired k-space data, helping to prevent over-
fitting while preserving essential details [6].
L =∥k ∥ +β∥k ∥
reg recons 1 recons 2
The overall loss function is a weighted combination of these components:
L =α ·L +α ·L +α ·L +α ·L +α ·L
total 1 fidelity 2 recons_ssim 3 eagle 4 vgg 5 reg
The specific weights for each loss component were determined through ex-
tensive empirical validation. We set α = 1.0 and α = 1.0 to prioritize data
1 2
fidelity and structural similarity, ensuring that the reconstructed image closely
resembles the ground truth in both the k-space and image domains. The weight
forEagleLoss,α =0.05,wascarefullychosentofocusonhigh-frequencydetail
3
recoverywithoutovershadowingthecontributionsofotherlosscomponents.The
VGG Perceptual Loss, weighted at α = 0.1, is crucial for maintaining visual
4
fidelity, particularly in capturing finer image details. Finally, the Regularization
Loss, set at α =0.01, helps prevent overfitting while preserving key structural
5
details, contributing to a robust and generalizable reconstruction model.
3.3 Optimized Eagle Loss
Inourmethod,weimprovedupontheoriginalEagleLosstechniquedescribedin
[7]byreplacingtheGaussianhigh-passfilterwithaButterworthhigh-passfilter,
which preserves high-frequency information crucial for multi-contrast CMR im-
agereconstruction.Additionally,weintroducedpaddingandotheroptimizations
to further enhance the performance of the loss function.
AsshowninFig.2,theeffectofvaryingpatchsizesandcutofffrequencieson
the high-pass filter weights and the resulting magnitude maps within the Eagle
Loss framework are as follows:
– Patch Size: This parameter determines the scale of features emphasized by
the high-pass filter. Smaller patch sizes (e.g., 3) focus on finer details and
higher frequencies, enhancing intricate structures but potentially amplify-
ing noise. In contrast, larger patch sizes (e.g., 5) offer a broader context,
capturing mid-level frequencies while preserving essential high-frequency in-
formation, thereby maintaining structural integrity with minimal noise am-
plification.
– CutoffFrequency:ThecutofffrequencyintheButterworthfiltercontrolsthe
threshold for emphasizing higher frequencies. A lower cutoff frequency (e.g.,
0.3) allows more high-frequency components to pass through, highlighting
sharp edges and fine details, but at the cost of increased noise sensitivity.6 Ruru Xu et al.
Fig.2.Visualizationoftheimpactofdifferentpatchsizesandcutofffrequenciesonthe
high-pass filter and resulting magnitude maps. The selected patch size of 5 and cutoff
of 0.35 provide balanced performance in capturing mid-level frequencies and spatial
details in the HyperCMR framework.
Conversely, a higher cutoff frequency (e.g., 0.4 or 0.5) suppresses very high
frequencies, focusing on preserving mid-level details and reducing noise.
– Selected Parameters: We selected a patch size of 5 and a cutoff frequency of
0.35 for their balanced performance. This combination effectively captures
both mid-level and high-frequency details, yielding magnitude maps that
closely resemble the ground truth. This balance ensures optimal structural
preservationwithminimalnoise,whichiscrucialforhigh-fidelityreconstruc-
tion in the HyperCMR framework.
The Eagle Loss process (Fig. 3), is designed to capture the structural differ-
encesbetweenpredictedandtargetimagesbyfocusingontheirgradientinforma-
tioninboththexandydirections.Theprocessbeginswithgradientcalculation,
where the predicted and target images are convolved with predefined gradient
filters (Scharr kernel) to compute the horizontal (gradient_x) and vertical (gra-
dient_y) gradients. These gradients highlight edge-like structures, which are
critical for accurate image reconstruction.
Next, for each direction (x and y), the gradient maps are divided into non-
overlapping patches, and the variance of each patch is calculated. This vari-
ance map reflects the distribution of gradient magnitudes in different regions
of the image. These variance maps are then passed through a 2D Fast Fourier
Transform (FFT) to obtain their frequency representations. To emphasize the
high-frequency components—representing fine details—the Eagle Loss applies a
Butterworth high-pass filter to the FFT magnitudes.
The filtered FFT magnitudes of the predicted and target images are then
compared using the L1 loss function in the frequency domain, capturing the
differences in their high-frequency details. The overall Eagle Loss is the sum
of the losses computed for both the x and y-direction gradients, ensuring that
the model learns to preserve structural details across multiple directions. ThisEfficient CMR Reconstruction 7
Fig.3.ThefigureillustratesthedetailedworkflowoftheEagleLossimplementationfor
calculatinggradientsinthex-direction.Theprocessbeginsbycomputingthegradients
for both the predicted and target images, followed by calculating variance across non-
overlapping patches. These variance maps are then transformed using a 2D FFT, and
their magnitudes are filtered with a Butterworth high-pass filter. Finally, the L1 loss
iscalculatedbycomparingthefilteredmagnitudesinthefrequencydomain.Thesame
processisappliedtothey-directiongradients.ThetotalEagleLossiscomputedasthe
sum of the loss for both x and y-direction gradients.
approach helps the model focus on recovering fine structures and details that
are often lost during undersampling in MRI reconstruction.
4 Experiments and Results
4.1 Experiments
The model was implemented in PyTorch, utilizing the AdamW optimizer with
aninitiallearningrateof0.00009,aweightdecayof1e-4,andaStepLRlearning
rate scheduler with a step size of 2 and gamma of 0.95. To manage the large
computational demands, gradient accumulation was employed with 8 steps.
We trained the 4x acc, 8x acc, and 10x acc models on three servers respec-
tively. The details are as follows:
– 4x acc: GPU: RTX 3090 24G, one epoch: 15.96 hours. The batch_size of
all 11 groups is set to 1.
– 8x acc: GPU: RTX 6000 24G, one epoch: 26.13 hours. The batch_size of
all 11 groups is set to 1.
– 10x acc: GPU: GV100 32G, one epoch: 20.42 hours. The batch_size of the
11 groups (aorta_sag, aorta_tra, cine_lax204, cine_lax168, cine_sax246,
cine_sax162, cine_sax204, cine_lvot, T1map, T2map, tagging) is set to 2,
2, 2, 2, 2, 1, 1, 2, 2, 4, 2 respectively.8 Ruru Xu et al.
Table 1. Performance across CMR modalities and acceleration factors (4x, 8x, 10x)
in terms of SSIM, PSNR, and NMSE.
Modality 4x 8x 10x
SSIM PSNR NMSE SSIM PSNR NMSE SSIM PSNR NMSE
Tagging 0.9621 38.57 0.0118 0.9162 33.98 0.0321 0.9112 33.20 0.0380
Mapping 0.9508 37.33 0.0077 0.8880 31.87 0.0220 0.8791 30.91 0.0268
Cine 0.9391 36.54 0.0102 0.8512 30.83 0.0312 0.8121 29.13 0.0437
Aorta 0.9393 36.70 0.0137 0.8475 31.12 0.0452 0.8078 29.61 0.0609
BlackBlood 0.9426 36.14 0.0104 0.8404 30.22 0.0375 0.7842 28.30 0.0570
Flow2d 0.9770 40.98 0.0028 0.9212 33.38 0.0153 0.9121 32.38 0.0188
Overall 0.9518 37.71 0.0094 0.8774 31.90 0.0306 0.8511 30.59 0.0409
4.2 Results Analysis
To further evaluate the robustness of our model, we analyzed its performance
acrossspecificaccelerationfactors,including4x,8x,and10x.Table1providesa
detailed breakdown of our model’s performance across various CMR modalities
under these acceleration settings. Notably, our model demonstrates consistent
performance across different modalities and acceleration factors, achieving an
excellent balance between maintaining structural similarity and reducing noise.
Table 2 provides a detailed analysis of the impact of different loss functions
ontheperformanceofourmodelatan8xaccelerationfactoracrossvariousCMR
modalities. Three configurations were evaluated: the results from using the pre-
trained PromptMR model with SSIM loss only, our model without Eagle Loss,
and our model with Eagle Loss.
– Performance of Pre-trained PromptMR with SSIM Loss: The pre-trained
PromptMRmodel,trainedexclusivelywithSSIMloss,servesasthebaseline.
This model demonstrates the weakest performance across all metrics. These
results indicate that while the pre-trained PromptMR model can achieve a
basic level of reconstruction, it struggles with accuracy, which is crucial for
precise CMR imaging.
– Effect of Removing Eagle Loss: Excluding Eagle Loss from our model still
leads to a significant performance improvement over the baseline. This sug-
gests that even without Eagle Loss, a combination of multiple loss functions
contributes to more accurate reconstructions. However, the slightly higher
NMSEvaluessuggestthatthemodelstillencounterschallengesinfullycap-
turing high-frequency details.
– ImpactofIncludingEagleLoss:IncludingEagleLossinourmodelyieldsthe
best performance across all metrics and modalities. Eagle Loss effectively
boosts the model’s ability to recover high-frequency details and improves
overall reconstruction quality.
The ablation study demonstrates that while our model offers substantial im-
provements over the pre-trained PromptMR, the integration of Eagle Loss isEfficient CMR Reconstruction 9
Table 2.Resultof8xacceleration.ComparisonofSSIM,PSNR,andNMSEscoresfor
different loss functions. "PromptMR with SSIM Loss" represents the results obtained
using the pre-trained PromptMR model, which was trained solely with SSIM loss.
"OurswithoutEagleLoss"referstoourmodeltrainedwithacombinationofmultiple
lossfunctions,excludingEagleLoss."OurswithEagleLoss"indicatestheresultsofour
model trained with the same combination of multiple loss functions, including Eagle
Loss.
PromptMR with Ours without Ours with
Modality SSIM Loss Eagle Loss Eagle Loss
SSIM PSNR NMSE SSIM PSNR NMSE SSIM PSNR NMSE
Tagging 0.7423 28.60 0.1254 0.9155 33.92 0.0326 0.9166 34.03 0.0320
Mapping 0.8878 31.86 0.0223 0.8890 31.93 0.0218 0.8941 32.18 0.0210
Cine 0.8387 30.29 0.0347 0.8497 30.69 0.0316 0.8512 30.83 0.0312
Aorta 0.8311 30.57 0.0510 0.8457 31.05 0.0458 0.8487 31.12 0.0448
BlackBlood 0.8394 30.19 0.0377 0.8422 30.27 0.0369 0.8426 30.40 0.0361
Flow2d 0.9078 32.37 0.0189 0.9205 33.20 0.0154 0.9212 33.38 0.0153
Overall 0.8412 30.65 0.0483 0.8771 31.84 0.0307 0.8791 31.99 0.0300
essentialforachievingstate-of-the-artperformance.Itsignificantlyenhancesthe
recoveryofhigh-frequencyinformationinundersampledk-space,makingourHy-
perCMRframeworksuperiorinproducinghigh-quality,detailedreconstructions
across various CMR modalities.
In addition to quantitative evaluations, we conducted a qualitative analy-
sis by visually comparing the reconstructions from our proposed HyperCMR
method against the baseline PromptMR model. Fig. 4 illustrates the recon-
struction quality for three different CMR modalities: aorta_tra, cine_lvot, and
cine_sax, under a 10x acceleration factor. This figure demonstrates how our
methodeffectivelyrestoreshigh-frequencyinformationwhichiscrucialformain-
tainingimagefidelityinundersampledk-spacescenarios.Intheaorta_tramodal-
ity,thehighlightedregionrevealsthatourmethodpreservesstructuralintegrity
more effectively than the PromptMR baseline. For the cine_lvot modality, our
method demonstrates superior preservation of k-space textures, as indicated by
the yellow arrow. Additionally, in the cine_sax modality, the superior recov-
ery of high-frequency components further validates the efficacy of our two-stage
framework in improving image fidelity and detail preservation.
5 Conclusion
In this paper, we introduce HyperCMR, a novel framework designed to enhance
the reconstruction of highly accelerated multi-contrast cardiac magnetic reso-
nance (CMR) images. Our approach builds on the PromptMR model and in-
corporates advanced loss functions, including a newly optimized Eagle Loss,
specifically designed to recover the missing high-frequency information in the10 Ruru Xu et al.
Fig.4. Visual comparisonof reconstructed imagesfor three different CMR modalities
(aorta_tra,cine_lvot,cine_sax)at10xacceleration.TheSSIMvaluesandzoomed-in
regions highlight the superior performance of our model (HyperCMR) compared to
the PromptMR baseline. This figure provides a clear example of the improvements
achievedbyourmethodinpreservingfinedetailsandenhancingoverallimagequality,
particularly in the high-frequency regions of the undersampled k-space.
undersampled k-space. The success of HyperCMR can be attributed to several
key innovations: the introduction of an advanced loss function framework, and
thecarefulselectionofpatchsizeandcutofffrequency.Thesecontributionshave
resulted in a powerful and generalizable model capable of effectively addressing
the various challenges posed by multi-contrast CMR imaging.
Extensive experiments on the CMRxRecon2024 dataset demonstrate that
ourmethodachievesbalancedperformanceacrossdifferentCMRmodalitiesand
acceleration factors, significantly improving SSIM, PSNR, and NMSE scores.
The experimental results confirm that our model is capable of preserving high-
frequency information in the undersampled k-space, contributing to superior
image reconstruction quality.
Acknowledgments. Thispaperhasbeenbenefittedfromthe2232InternationalFel-
lowship for Outstanding Researchers Program of TUBITAK (Project No: 118C353).
However, the entire responsibility of the thesis belongs to the owner. The financial
support received from TUBITAK does not mean that the content of the thesis is ap-
provedinascientificsensebyTUBITAK.Computingresourcesusedinthisworkwere
providedbytheNationalCenterforHighPerformanceComputingofTurkey(UHeM)
undergrantnumber4020052024.ThepaperalsobenefitedfromIstanbulTechnicalUni-
versityScientificResearchProjects(ITUBAP)funds,grantnumbersFHD-2024-45302
and PMA-2024-44970.Efficient CMR Reconstruction 11
References
1. Hammernik, K., Klatzer, T., Kobler, E., Recht, M., Sodickson, D., Pock, T. &
Knoll,F.LearningavariationalnetworkforreconstructionofacceleratedMRIdata.
Magnetic Resonance In Medicine. 79, 3055-3071 (2018)
2. Knoll, F., Hammernik, K., Zhang, C., Moeller, S., Pock, T., Sodickson, D. & Ak-
cakaya, M. Deep-learning methods for parallel magnetic resonance imaging recon-
struction:Asurveyofthecurrentapproaches,trends,andissues.IEEE Signal Pro-
cessing Magazine. 37, 128-140 (2020)
3. Lustig, M., Donoho, D., Santos, J. & Pauly, J. Compressed sensing MRI. IEEE
Signal Processing Magazine. 25, 72-82 (2008)
4. Schlemper,J.,Caballero,J.,Hajnal,J.,Price,A.&Rueckert,D.Adeepcascadeof
convolutionalneuralnetworksfordynamicMRimagereconstruction.IEEE Trans-
actions On Medical Imaging. 37, 491-503 (2017)
5. Simonyan, K. & Zisserman, A. Very deep convolutional networks for large-scale
image recognition. ArXiv Preprint ArXiv:1409.1556. (2014)
6. Sun, J., Li, H., Xu, Z. & Others Deep ADMM-Net for compressive sensing MRI.
Advances In Neural Information Processing Systems. 29 (2016)
7. Sun, Y., Huang, Y., Schneider, L., Thies, M., Gu, M., Mei, S., Bayer, S. & Maier,
A. EAGLE: An Edge-Aware Gradient Localization Enhanced Loss for CT Image
Reconstruction. ArXiv Preprint ArXiv:2403.10695. (2024)
8. Wang, Z., Wang, F., Qin, C., Lyu, J., Cheng, O., Wang, S., Li, Y., Yu, M., Zhang,
H., Guo, K. & Others CMRxRecon2024: A Multi-Modality, Multi-View K-Space
DatasetBoostingUniversalMachineLearningforAcceleratedCardiacMRI.ArXiv
Preprint ArXiv:2406.19043. (2024)
9. Xin, B., Ye, M., Axel, L. & Metaxas, D. Fill the k-space and refine the image:
Promptingfordynamicandmulti-contrastMRIreconstruction.InternationalWork-
shop On Statistical Atlases And Computational Models Of The Heart. pp. 261-273
(2023)
10. Xu, R. & Oksuz, I. Segmentation-aware MRI subsampling for efficient cardiac
MRIreconstructionwithreinforcementlearning.ImageAndVisionComputing.pp.
105200 (2024)
11. Yang,Z.,Shen,D.,Chan,K.&Huang,J.Attention-BasedMultiOffsetDeepLearn-
ingReconstructionofChemicalExchangeSaturationTransfer(AMO-CEST)MRI.
IEEE Journal Of Biomedical And Health Informatics. (2024)12 Ruru Xu et al.
Supplementary Material
In the A, we will introduce the experimental details of the Random sampling
CMR reconstruction task.
A TASK 2: Random sampling CMR reconstruction
A.1 Experimental details
We performed distributed training on 4*A100 80G servers, randomly selecting
half of datasets for training in each epoch. The batch_size of the 11 groups
(aorta_sag, aorta_tra, cine_lax204, cine_lax168, cine_sax246, cine_sax162,
cine_sax204, cine_lvot, T1map, T2map, tagging) is set to 6, 6, 4, 6, 4, 4, 2, 6,
6, 10, 4 respectively. One epoch: 23.65 hours
A.2 Results
Fig.5. Task2 result. Some examples