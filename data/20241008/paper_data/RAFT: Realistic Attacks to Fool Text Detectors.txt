RAFT: Realistic Attacks to Fool Text Detectors
JamesWang1*,RanLi1*,JunfengYang1,ChengzhiMao2
ColumbiaUniversity1,RutgersUniversity2
{jlw2247, rl3424, jy2324}@columbia.edu, cm1838@rutgers.edu
Abstract To defend against these malicious use cases,
variousmethodshavebeendevelopedtosuccess-
Large language models (LLMs) have exhib-
fully detect machine-generated text such as Ope-
ited remarkable fluency across various tasks.
nAI’sGPT-2superviseddetector(Solaimanetal.,
However,theirunethicalapplications,suchas
2019),watermarking(Kirchenbaueretal.,2023),
disseminatingdisinformation,havebecomea
growingconcern. Althoughrecentworkshave and likelihood-based zero-shot detectors such as
proposed a number of LLM detection meth- DetectGPT(Mitchelletal.,2023). Inresponse,red-
ods,theirrobustnessandreliabilityremainun- teamingmethodsforattackingmachine-generated
clear. Inthispaper,wepresentRAFT:agram-
textdetectorswerecreatedtoidentifyvulnerabili-
marerror-freeblack-boxattackagainstexisting
ties. Red-teamingmethodsareprimarilybasedon
LLMdetectors. Incontrasttopreviousattacks
paraphrasing or word substitution. Paraphrasing-
forlanguagemodels,ourmethodexploitsthe
based attacks such as DIPPER fine-tune a gener-
transferabilityofLLMembeddingsattheword-
levelwhilepreservingtheoriginaltextquality. ative language model on a large set of manually
Weleverageanauxiliaryembeddingtogreed- collected paraphrase pairs (Krishna et al., 2023;
ily select candidate words to perturb against Sadasivan et al., 2023). Word substitution-based
the target detector. Experiments reveal that attackshaveleveragedmaskedlanguagemodelsor
our attack effectively compromises all detec- auxiliaryLLMstogeneratereplacementcandidates
torsinthestudyacrossvariousdomainsbyup
(Krishnaetal.,2023;Shietal.,2024). Despitetheir
to99%,andaretransferableacrosssourcemod-
effectivenessinsubvertingvariousdetectors,word
els.Manualhumanevaluationstudiesshowour
substitution-basedattacksoftencontainnumerous
attacksarerealisticandindistinguishablefrom
originalhuman-writtentext. Wealsoshowthat grammatical errors and semantic inconsistencies
examples generated by RAFT can be used to thatarereadilydiscernibleuponhumanevaluation.
trainadversariallyrobustdetectors. Ourwork In this work, we explore whether machine-
showsthatcurrentLLMdetectorsarenotad-
generatedtextcansubvertdetectionwithrealistic
versariallyrobust,underscoringtheurgentneed
perturbationsthatremaininconspicuoustohuman
formoreresilientdetectionmechanisms.
readers. Aperturbationisconsideredrealisticifit
1 Introduction maintainspart-of-speech(POS)consistency,mini-
mallyincreasesperplexity,andisindistinguishable
Largelanguagemodels(LLMs)suchasChatGPT
fromhuman-writtentextinmanualevaluations.
(Ouyang et al., 2022), LLaMA (Touvron et al.,
WepresentRAFT,azero-shotblack-boxattack
2023),andGPT-4(OpenAI,2023)haveexhibited
frameworktosubvertmachine-generatedtextdetec-
transformativeabilitiestogenerateremarkablyflu-
tors. RAFT leveragesanauxiliaryLLMembedding
entandcogentlong-formtextinresponsetouser
to optimally select words in machine-generated
queries. However,LLMshavebeenmisusedtodis-
textforsubstitutionbyperformingaproxytask. It
seminatedisinformation,commitacademicdishon-
thenemploysablack-boxLLMtogeneratereplace-
esty,andlaunchtargetedspearphishingcampaigns
ment candidates, greedily selecting the one that
againstvulnerablepopulations(Hazell,2023). To
mosteffectivelysubvertsthetargetdetector. RAFT
mitigate harm from malicious use, the capability
onlyrequiresaccesstoanLLM’sembeddinglayer,
todistinguishmachine-generatedtextandhuman-
makingiteasilydeployableandadaptablewiththe
writtentextisparamount.
numerous powerful open-source LLMs available
*Theseauthorscontributedequallytothework (HuggingFaceInc.,2022).
4202
tcO
4
]LC.sc[
1v85630.0142:viXraOriginal GPT3.5 Red-Teaming (Shi et al.) Ours
Maj Richard Scott, 40, is accused of driving at Maj Richard Scott, Two score, is accused of Maj Richard Scott, 40, is reproached of steering at
speeds of up to 95mph (153km/h) in bad weather driving at quickens of up to lightning tempo (swift speeds of up to 95mph (153km/h) under bad
before the fatal crash that claimed the lives of two pace) in bad Sunny before the fatal crash that weather before the fatal crash that claimed the
young children. The incident occurred on the A34 claimed the lives of two young children. The deaths of two young minors. The mishap occurred
motorway near Newbury, Berkshire, last Saturday. circumstance betided on the path motorway near near the A34 motorway near Newbury, UK,
Newbury, Berkshire, last Saturday. previous Saturday.
DetectGPT LLM Likelihood: 0.7100 DetectGPT LLM Likelihood: 0.0500 DetectGPT LLM Likelihood: 0.0400
Perplexity: 12.14 Perplexity: 137.72 Perplexity: 43.14
Figure 1: RAFT can attack a sample text generated by GPT-3.5-turbo more effectively to subvert detection by
DetectGPTthanrecentredteamingattackefforts(Shietal.,2024)whilepreservinglanguagefluencyandsemantic
consistency. ByenforcinggrammaticalconsistencyinthesubstitutedwordsthroughPOScorrection,RAFT achieves
significantly lower perplexity than attacks that do not enforce grammar. Qualitative evaluation also highlight
RAFT’slanguagefluencyandsemanticconsistencywiththeoriginaltext. Redtextrepresentssubstitutedwords
withgrammaticalerrorsorsemanticinconsistencies. Bluetextrepresenterror-freesubstitutions.
Our results show RAFT can reduce detection supervised classifiers (Solaiman et al., 2019;
performance by up to 99% while preserving the Hovy, 2016; Zellers et al., 2019), watermark
part-of-speechandsemanticconsistencyofthere- detectors(Kirchenbaueretal.,2023;Grinbaumand
placed words. Additionally, we show that the re- Adomaitis,2022;AbdelnabiandFritz,2021),and
placementwordsselectedtogreedilysubvertone zero-shotstatistical-basedmethods(Mitchelletal.,
targetdetectorcanbeeffectivelytransferredtoat- 2023;Tian,2023;Lavergneetal.,2008;Solaiman
tackotherdetectors,outperformingbenchmarked et al., 2019; Gehrmann et al., 2019; Ippolito
attack methods. Furthermore, we demonstrate etal.,2020). Asnewdetectionmethodscontinue
thatRAFT’soutputscanbeleveragedtoenhance to be developed, parallel efforts in red-teaming
a detector’s robustness through adversarial train- thesedetectorshavealsogainedmomentum. The
ing. Our findings suggest that current detectors primarytechniquesforattackingthemincludetext
arevulnerabletoadversarialattacksandhighlight paraphrasingandwordreplacement. Krishnaetal.
the urgency to develop more resilient detection (2023) presentDIPPER, a paraphrasegeneration
mechanisms. Our code and data is available at modelthatcanbeconditionedonsurroundingcon-
https://www.github.com/jameslwang/raft. texttoeffectivelyattackstate-of-the-artdetectors
whilecontrollingoutputdiversityandmaintaining
2 RelatedWork
semantic consistency. Sadasivan et al. (2023)
Substitution-basedAttacksagainstNLPtargets: iterate on this method and present a recursive
Whileexistinggradient-basedadversarialattacks paraphrasingattackthatbreakswatermarkingand
are effective in the vision and speech domains retrieval-baseddetectorswithslightdegradationin
(Carlini and Wagner, 2017), attacks in the text textqualitybyusingalightweightT5-basedpara-
domain present unique challenges due to its phrasermodel. Theseattackframeworksaremore
discrete nature. Attacks in the natural language vulnerable to attack since they are reliant on one
domainarealsoconstrainedbylanguagefluency, large fine-tuned LLM model and utilize smaller
semantic consistency, and human prediction paraphrasing models that are relatively weaker
consistency. Jinetal.(2020)introduceablack-box than the source LLM. Shi et al. (2024) introduce
wordsubstitution-basedattackthatfulfillsallthese awordreplacementmethodthatutilizesanLLM
criteria by utilizing semantic similarity and POS to randomly generate substitution candidates for
matchingtogreedilyreplacewordswithsynonyms multiplewords,selectingtheoptimalreplacement
until a successful attack. In this work, we use an candidates using an iterative evolutionary search
LLM instead to generate semantically consistent algorithm to minimize detection score. We
word replacement candidates and greedily select improve upon this framework by introducing a
the POS-consistent word that most effectively replaceable proxy scoring model that uses an
attacksthetargetdetector. auxiliary LLM embedding to rank which words
inthemachine-generatedtextshouldbereplaced
LLM Detector Attack Frameworks: Ex- andgreedilyselectLLM-generatedcandidatesthat
istingalgorithmsfordetectingmachine-generated effectivelysubvertthetargetdetector.
text can be categorized into three categories:Figure2: Histogramsshowthedistributionsofdifferentdetectionscoresforhuman-writtentext,GPT-3.5-Turbo
generatedtext,andRAFT-attackedGPT-3.5-Turbotext. Thehorizontalaxisrepresentstherawoutputfromthe
detector. Thediagramsillustratethatourattackeffectivelyshiftsthedistributionofgenerateddatatowardsthe
negativeregion,foolingthedetectors.
3 Method 3.2 OurAttack
FindingImportantWordsforSubstitutionusing
3.1 Preliminaries
aProxyTaskEmbeddingObjective: Wecapital-
Setup: Given a text passage X consisting of
izeonFreestoneandSantu(2024)’sobservations
N words [x ,...,x ], we consider a black-box
1 N
thatLLMssharesimilarlatentsemanticspacesand
detector D(X) ∈ [0,1] that predicts whether the
performsimilarlyonsemantictasks. Toeffectively
inputXismachine-generatedorhuman-written. A
minimizeD(X′),weuseawhite-boxLLMM to
higher D(X) score indicates a greater likelihood
performaword-leveltaskFthatgeneratesascore
thatXismachine-generated. Wedenoteτ asthe
f foreachwordthatactsasaproxysignalforse-
i
detection threshold, such that X is classified as
lectingwordstoreplace,whereM doesnotneces-
machine-generatedifD(X) ≥ τ.
sarilyneedtobethesamesourceLLMmodelused
togenerateX. WechooseLLMembeddingtasks
Adversarial Attack for LLM Detector: The
correlatedwithidentifyingwordsthatwouldalter
goal of the attack is to perturb the input passage
thestatisticalpropertiesofthemachine-generated
X into X′ such that D(X′) incorrectly classifies
text,suchasnext-tokengenerationandsupervised
X′ as human written, while ensuring that X′
LLMtextdetection. FromF,wechoose
remainsindistinguishablefromhuman-writtentext
when manually reviewed. To preserve semantic X = argmax F(M,X) (2)
similarity between X and X′, the number of k kN
wordstobesubstitutedisconstrainedtok%ofX. where X is the subset of k% words in X to
k
Additionally,tomaintaingrammaticalcorrectness perturbfrom.
and fluency, x and x′ must have consistent
i i
part-of-speech (Brill, 1995). We formulate the Constraints for Realistic Generation: To
attack on the LLM Detector D as a constrained perturb words in X while ensuring that X
k
minimization problem, with the objective to remainsindistinguishabletoahumanevaluatoras
modifyXsuchthatD(X′) ≤ τ: machine-generated,weconstrainthereplacement
wordssuchthattheymustnotinducegrammatical
X′ = argminD(X′) s.t. pos(x′) = pos(x ),
i i errors and are semantically consistent with the
X′
x′ ∈ {x } ∪ s(x ,X,t), original text. We use GPT-3.5-Turbo (OpenAI,
i i i
2024b)asourwordsubstitutioncandidategenera-
N
(cid:88) torbypromptingitwiththewordtoreplaceandits
1(x′ ̸= x ) ≤ kN
i i
surroundingcontextusingthefollowingprompt:
i
(1) Q: Given some input paragraph ,
we have highlighted a word
wherepos(x )returnsthepart-of-speechlabelof
i using brackets . List top {t}
any word x and s(·) is a word substitution gen-
i alternative words for it that
erator that outputs t candidates for x using the
i ensure grammar correctness
surroundingcontextinX.and semantic fluency . Output Metrics: We use the Area Under the Re-
words only .\n{paragraph} ceiver Operating Characteristic Curve (AUROC)
A: The alternative words are 1. to summarize detection accuracy for our attack
2. ... framework under various thresholds. We also
measure the True Positive Rate at a 5% False
UsinganLLMforwordsubstitutionallowsusto
PositiveRate(TPRat5%FPR),asitisimperative
convenientlyobtaincontext-compatiblecandidates
in this context for human-written text to not
in one step, instead of needing to compute can-
be misclassified as machine-generated text. To
didates using word embeddings followed by an
measure text quality, we measure the perplexity
additional model to check context compatibility
oftheattackedtextagainstGPT-NEO-2.7B(Gao
(Alzantotetal.,2018). Afterretrievingtreplace-
etal.,2021).
mentcandidatesfromGPT-3.5-Turbo,wefilterout
words that have inconsistent part-of-speech with
4.2 EmbeddingsforProxyScoringModels
theoriginalwordbyusingtheNLTKlibrary(Bird
We use the language modeling heads of GPT-2
etal.,2009)andthenselectthecandidatethatmin-
(Radford et al., 2019), OPT-2.7B (Zhang et al.,
imizesD.
2022),GPT-NEO-2.7B(Gaoetal.,2021),andGPT-
3.3 ImplementationDetails J-6B(WangandKomatsuzaki,2021)fornext-token
generation,andtheRoBERTa-baseandRoBERTa-
We set k to 10% across all experiments to evalu-
largesupervisedGPT-2detectormodels(Solaiman
ate the effectiveness of our attack with a limited
et al., 2019) for LLM detection as proxy tasks
numberofchanges. Weevaluatetheeffectiveness
to rank which words from the original text to
ofusinglanguagemodelingheadsfornext-token
substitute. We present results for OPT-2.7B and
generationandsupervisedLLMdetectiontasksas
RoBERTa-large proxy scoring models in Table 1
proxyscoringmodelstooptimallyselectwordsto
andtherestinTableA.1.
substituteinX. Fornext-tokengeneration,weuse
the probability of the next token being X from
i 4.3 Detectors
the language modeling head as the proxy objec-
We evaluate our attack against a variety of target
tive. Intuitively,replacingtokenswiththehighest
detectionmethods:
likelihoodfromtheLLMallowsustoalterthesta-
LogLikelihood(Gehrmannetal.,2019)isaclas-
tistical properties of the machine-generated text
sicalthreshold-basedzero-shotmethodwherepas-
mosteffectively. ForLLMdetection,weiteratively
sageswithhigherlogprobabilityscoresaremore
computetheimportanceofeachwordbasedonthe
likelytohavebeengeneratedbythetargetLLM.
decreaseindetectionscoreD(X)byassigning0to
Log Rank (Solaiman et al., 2019) is a classical
itscorrespondingtokensinthedetector’sattention
threshold-basedzero-shotmethodwherepassages
mask,andrankingthescorechangesindescending
with above average rank are more likely to have
order,wherethewordthatyieldsahigherabsolute
beengeneratedbythetargetLLM.
changeindetectorscoreisconsideredtobemore
DetectGPT(Mitchelletal.,2023)isastate-of-the-
importantfordetection.
artzero-shotdetectorthatleveragesthelikelihood
ofgeneratedtextstoperformthresholdingforde-
4 Experiments
tectingmachine-generatedtext.
4.1 DatasetsandMetrics Fast-DetectGPT (Bao et al., 2024) is a state-of-
Datasets: Weusethreedatasetstocoveravariety the-artdetectorthatimprovesuponDetectGPTby
of domains and use cases. We use 200 pairs introducingconditionalprobabilitycurvaturetoun-
of human-written and LLM-generated samples derscore discrepancies in word choices between
from each of the XSum (Narayan et al., 2018) LLMs and humans to improve detection perfor-
and SQuAD (Rajpurkar et al., 2016) datasets manceandcomputationalspeed.
generatedbyBaoetal.(2024)usingGPT-3.5-turbo. Ghostbusters (Verma et al., 2024) is a state-of-
Additionally, we use the ArXiV Paper Abstract the-artdetectorthatusesprobabilisticoutputsfrom
dataset (Mao et al., 2024) which contains 350 LLMstoconstructfeaturestotrainanoptimalde-
abstracts generated using GPT-3.5-turbo from tectionclassifier.
ICLRconferencepapers. Raidar(Maoetal.,2024)isastate-of-the-artde-
tector that uses prompt rewriting and an output’sOriginal GPT3.5 Red-Teaming (Shi et al.) Ours
The incident occurred on March 30, 1981, when John The incident occured on March tridsat' (Russian), 1981, The event occurred on March 30, 1981, when John
Hinckley Jr. attempted to assassinate President Ronald when John attempted killer Jr. attempted to assassinate Hinckley Jr. endeavored to assassinate President Ronald
Reagan. The shooting took place outside the Hilton Hotel chief magistrate Ronald Reagan. The shooting took Reagan. The shooting took place outside a Hilton Hotel in
in Washington, just moments after President Reagan had place outside the accommodations Hotel in Washington, Washington, merely moments after President Reagan had
delivered a speech. just bat of an eye after President Reagan had delivered delivered a dialogue.
a speech.
Log Rank LLM Likelihood: 0.7900 Log Rank LLM Likelihood: 0.1200 Log Rank LLM Likelihood: 0.0800
Perplexity: 7.60 Perplexity: 253.66 Perplexity: 17.14
The ban specifically targets clothing and symbols The inhibit specifically targets habit and symbols joined The interdiction specifically targets clothing and symbols
associated with Islam, such as the hijab and the crescent with Islam, such as the hijab and the crescent earth's associated with Islam, such as the hijab and the crescent
moon and star. This decision follows similar measures natural satellite and star. This decision follows similar moon and insignia. This decision follows similar steps
implemented in other parts of the country. measures implemented in other parts of the country. implemented among other parts of the country.
Ghostbuster LLM Likelihood: 0.9627 Ghostbuster LLM Likelihood: 0.0352 Ghostbuster LLM Likelihood: 0.0262
Perplexity: 16.23 Perplexity: 161.73 Perplexity: 39.29
The impact caused both cars to veer off the road and The impact caused both coaches to veer off the road The impact caused both motorcars to veer off the pathway
crash into a nearby tree. Tragically, the two children, and crash into a nearby tree. Tragically, the binary and crash into a nearby timber. Tragically, the two
aged 3 and 5, who were passengers in the other vehicle, children, past one's prime 3 and quinquevalent, who juveniles, aged 3 and 5, who were passengers in the
were pronounced dead at the scene. The driver of that were journeyers in the other vehicle, were pronounced other vehicle, were pronounced dead at the vicinity. The
car, a 32-year-old woman, sustained serious injuries and dead at the scene. The driver of that wheels, a driver of that car, a 32-year-old woman, endured serious
is currently in critical condition at a local hospital. 32-year-time-honored woman, sustained serious lesions wound and is currently in critical condition in a local
and is currently in critical condition at a local hospital. hospital.
Fast-DetectGPT LLM Likelihood: 0.9800 Fast-DetectGPT LLM Likelihood: 0.0001 Fast-DetectGPT LLM Likelihood: 0.0001
Perplexity: 6.31 Perplexity: 46.43 Perplexity: 17.25
Figure 3: Generated texts from LLMs and their respective attacks using Shi et al. (2024)’s query-based word
substitutionattackandRAFT (ours)usingtheRoBERTa-largeproxyscoringmodel,evaluatedagainstLogRank,
Ghostbuster,andFast-DetectGPTdetectors. RAFT demonstratesthegreatestreductionindetectionlikelihoodwhile
maintaininggrammaticalcorrectnessandsemanticconsistencywiththeoriginaltext. Redtextrepresentssubstituted
wordswithgrammaticalerrorsorsemanticinconsistencies. Bluetextrepresenterror-freesubstitutions.
edit distance to gain additional context about the attackedtext,whichwepresentinTableA.2. For
input. moreinsight,wepresenttheROCcurveforourex-
perimentsinFigure6. BetweenShietal.(2024)’s
4.4 Baselines
query-based attack and our method, RAFT con-
WecompareourattackmethodwithDIPPER(Kr- sistentlyyieldslowerperplexityscoresacrossall
ishnaetal.,2023),aparaphrasegenerationmodel scenarios. Raidarstandsoutasthemostrobustde-
usingsettingsof20lexicaldiversityand60order tectoragainstattacks,likelyduetotheuniqueedit
diversity. This corresponds to about 20% lexical distanceofrewritingusedintheapproach. Qualita-
modification–theminimummodificationwecan tiveresultsshowninFigures1and3highlightour
setonthismethod. WealsocomparewithShietal. method’s semantic consistency and language flu-
(2024)’squery-basedwordsubstitutionattackand ency. Additionally,cosinesimilaritycalculations
limitthenumberofsubstitutedwordstobeatmost betweentheoriginalandperturbedtextsshownin
10%tomatchoursubstitutionfrequency. Table 3 using state-of-the-art LLMs Mistral-7B-
v0.3 (Jianget al.,2023) and Llama-3-8B(Dubey
4.5 Results
et al., 2024) highlight their strong semantic sim-
Tables 1 and 2 demonstrate that our attack effec- ilarity. We also show in Figure 2 that our attack
tivelycompromisesalltesteddetectorswhilecaus- effectivelyaltersthedistributionofdetectionlike-
ing only a modest change in perplexity from the lihood scores, diverging from the distribution as-
originalmachine-generatedtext. Usingnext-token sociatedwiththemachine-generatedtext,thereby
generationwithOPT-2.7BandLLMdetectionwith subvertingdetection.
RoBERTa-largeasproxyscoringmodelsforRAFT
achievedlowerAUROCacrossalldatasetsandtar- 4.6 HumanEvaluation
get detectors when compared to the original text, To validate that RAFT preserves text quality, we
and in most cases, lower than both DIPPER and conductedacrowd-sourcedhumanevaluationus-
Shietal.(2024)’squery-basedwordsubstitution. ing Amazon Mechanical Turk (MTurk). We se-
AlthoughDIPPERpreservesthetextqualitybetter lectedthefirst100pairsofhuman-writtenandGPT-
intermsofperplexity,itsAUROCissignificantly 3.5-Turbo-generatedtextsfromtheXSum,SQuAD,
higher than RAFT and Shi et al. (2024)’s attack. andAbstractdatasets. AfterapplyingRAFT tothe
The TPR at 5% FPR was 0 for almost all RAFT LLM-generatedtext,threeMTurkworkersevalu-Table1: RAFT attackresults. WeevaluateRAFT performanceagainst6targetdetectorsusingGPT-3.5-Turbo
generatedtextfrom3datasets,measuringthedetector’sperformancebeforeandafterattackusingtheAUROC
metric. BoldedAUROCresultsindicatebestattackperformance. Theseresultsshowthesuperiorityofourattack
comparedtobenchmarkedmethods.
Metric LogProbability LogRank Ghostbuster DetectGPT Fast-DetectGPT Raidar Average
XSum/Unattacked 0.9577 0.9584 0.6637 0.7853 0.9903 0.7667 0.8537
Dipper 0.7981 0.8080 0.7196 0.4693 0.9610 0.4667 0.7038
Query-basedSubstitution 0.0481 0.0739 0.0980 0.0384 0.2308 0.6000 0.1815
OPT-2.7B(Ours) 0.0035 0.0069 0.0826 0.1273 0.0006 0.7000 0.1535
RoBERTa-large(Ours) 0.0346 0.0568 0.0004 0.0704 0.0371 0.6000 0.1324
SQuAD/Unattacked 0.9027 0.9075 0.7659 0.7916 0.9800 0.7833 0.8552
Dipper 0.7929 0.8067 0.7959 0.5916 0.9492 0.5333 0.7449
Query-basedSubstitution 0.1542 0.1852 0.2032 0.1408 0.3624 0.8333 0.3132
OPT-2.7B(Ours) 0.0496 0.0659 0.0851 0.1539 0.0131 0.8333 0.2002
RoBERTa-large(Ours) 0.0942 0.1199 0.0166 0.1262 0.1039 0.7167 0.1963
Abstract/Unattacked 0.6329 0.6502 0.8455 0.1538 0.9148 0.7667 0.6607
Dipper 0.5029 0.5370 0.8826 0.1049 0.9441 0.6833 0.6091
Query-basedSubstitution 0.0234 0.0364 0.3142 0.0046 0.2976 0.7167 0.2322
OPT-2.7B(Ours) 0.0945 0.1249 0.0841 0.3131 0.0399 0.7667 0.2372
RoBERTa-large(Ours) 0.0162 0.0336 0.0374 0.0044 0.1481 0.6500 0.1666
Table2: PerplexityoftextafterdifferentattacksmeasuredbyGPT-NEO-2.7B.RAFT attackedtextswereoptimized
againstFast-DetectGPTdetector. Lowerperplexityindicatesbettertextquality. Theresultsshowthatourattackis
abletomaintaintextqualitywhilesubvertingdetection.
Dataset Unattacked Dipper Query-basedSubstitution OPT-2.7B(Ours) RoBERTa-large(Ours)
XSum 8.4804 11.3649 28.0979 17.6181 22.4542
SQUAD 9.7947 11.9064 30.0879 19.6190 25.1480
Abstract 12.9136 15.2685 36.6523 26.8810 31.6123
Table 3: Cosine similarity, evaluated across multiple α < 0.05,supportingthenullhypothesisthatthe
LLMembeddingsbetweentheoriginaltextsandthose
twotextsareindistinguishable. TheFleiss’kappa
perturbedbyRAFT usingRoBERTa-baseastheproxy
was0.774,indicatingstrongagreementamongan-
scoringmodelandFast-DetectGPTasthetargetdetector,
notators.
indicatesthatthetextsmaintainsemanticsimilarity.
5 Discussion
EmbeddingModel XSum SQuAD Abstract
RoBERTa-large 0.9999 0.9999 0.9999 5.1 EffectofScoringModel
Llama-3-8B 0.9747 0.9759 0.9841
Weperformablationstudiestoevaluatetheisolated
Mistral-7B-v0.3 0.9761 0.9735 0.9847
effectiveness of the proxy scoring model (rank-
ing) and the greedy selection of generated POS-
atedeachpairoforiginalhuman-writtenandRAFT-
consistentreplacementwordsaimedatsubverting
modifiedtexts,indicatingtheirpreferenceforone
detection (optimization). For brevity, we refer to
of them or expressing no preference. RAFT’s
thesetwomethodsas"ranking"and"optimization",
perturbationsweredeemedindistinguishablefrom
respectively. AsshowninTable5,thestudyiscon-
human-writtentextiftwoormoreannotatorseither
ductedunderfoursettings: neitherrankingnoropti-
preferredtheperturbedtextorwereindifferent. To
mization,rankingonly,optimizationonly,andboth
ensureEnglishproficiency,weincludedascreen-
rankingandoptimization. Theresultsindicatethat
ingquestionusingatextcomparisontasksourced
rankingisaboutaseffectiveasoptimization,signif-
from the ETS TOEFL website. Out of valid 396
icantlyreducingAUROCwhenapplied,supporting
responses,185preferredthehuman-writtentexts,
the idea that LLM embeddings are transferable.
182 were indifferent, and 29 responses were ex-
However,theeffectsofrankingandoptimization
cludedforratingbothtextsaslowquality. Atwo-
arenotnecessarilyadditive.
tailed binomial test yielded a p-value of 0.917 atTable4: AUROCofRAFT-attackedtext,usingWord2VecembeddingmodeltrainedontheGoogleNewscorpusfor
wordreplacementcandidategenerationinsteadofGPT-3.5-turboontheXSumandAbstractdatasets,suggeststhat
usingaclassicwordembeddinginplaceofanLLMalsoyieldseffectiveresults.
SeStetitntigng NNeiethitehrer OOptpimtimiziaztaiotinonOOnlnyly RaRnakniknigngOOnlnyly RaRnakniknigng++OOptpimtimiziaztaiotinon
ProxyModel/Detector LogProbability LogRank Ghostbuster Fast-DetectGPT
GGhohXsot Sbsutubmsut /esUtrenrattacke0 d.03.3343141 0.90 5. 701 7.0100101 0.95840.00.90891801.6637 0. 001 ..0 910 900 0030
FaFsat O-sDtP-DTet -ee 2tc .e7tcG BtGP (T OPTurs)0.07.5715010 0.00 0. 500 2.0020626 0.01440.00.00300300.0408 0.000..00000063046
RoBERTa-large(Ours) 0.0016 0.0064 0.0000 0.0698
TaTbalbele3:3:EfEffefcetcotfosfcsocroinrigngmmodoedlesl.s.ToToshsohwowthteheefeffefcetcivtievneensesssofofthtehewworodrdrarnakniknigngprporcoecdeudruer,ew, weeatatattcakckagaagianisntst
GGhohsotsbtubsutsetreranadndFAaFbssatts-raDt-cDet/tUeetnceatcGtttaGPcTkPeTddedteetcetcotrosr0sw.6wi3thi2t9hOOPTP-T2-.27.0B7.B6o5n0o2nXXSuSmum0d.8ad4taa5ts5aesteutnudnedrer40.49d1id4ffi8fefreernetnstestetitntignsg,sw, whehreere
OPT-2.7B(Ours) 0.1041 0.1577 0.0873 0.0711
rarnakniknigngrerfeefresrstotothtehewworodrdrarnakniknigngwwithiththtehescsocroinrigngmmodoedle,la,nadndopotpimtimiziaztaiotinonmmeaenasnsgrgereedeydyupudpadtaeteagaagianisntstthtehe
RoBERTa-large(Ours) 0.0021 0.0040 0.0075 0.0346
dedteetcetcotrowrwhehnensesleelcetcintigngwworodrdalateltrenrantaivtiev.eT.hTehererseuslutsltsshsohwowssthtahtabtobtohthrarnakniknignganadndopotpimtimiziaztaiotinonaraereefeffefcetcivtieveatatattcakck
tetcehcnhinqiuqeuse,sb,ubtutthtehererseuslutlitsinsontontenceecsessasrailryilyadaddidtiivtievewwhehnenbobtohtharaerecocmombibniende.d.
Table5: Effectofscoringmodels. Toshowtheisolatedeffectivenessoftheproxyscoringmodel,weattackthe
GhostbusterandFast-DetectGPTdetectorsusingOPT-2.7Bnext-tokengenerationontheXSumdatasetacross
fourdifferentconfigurations. Here,"rankingN"NoroePfOPeOSrsSCtooCrotrherrceetcipotrinoonxyscoPriOnPgOSSmCoCorodrererclet,ciaotinnodn"optimization"referstothe
AUAUROROCC PePreprlpelxeixtyity AUAUROROCC PePreprlpelxeixtyity
greedyselectionofgeneratedPOS-consistentwordsagainstthetargetdetector. Theresultsindicatebothtechniques
are effective, but their coOmOPbTPi-Tn2-e.27d.B7eBffect is n0o.00t.00n00e00c0essar2il8y2.83a.23d2ditive0..00B.000o06l0d6ed A1U71R.75O.35C3 results denote best attack
performance. RoRBoEBRETRaT-ala-lragrege 0.00.0060262 313.13.636 0.00.4074171 252.50.808
TaTbalbele4:4E:fEffefcetcotSfeotaftipanpgplpyliynigngouorugrNrgaermaitmhmemraracrOocnpotsnitmsratirzianaittni.otnW. WOeneulysueseOROPaTnPk-T2i-n.2g7.B7OBnalnyadndRRRoaBonBkEiREngTR+aT-aOl-aplratgirmegieazsaatssiocsnocroirnigngmmodoedleslstoto
atatattcakckagaagianisntsFtaFsats-Dt-DeteetceGcGPTPTdedteetcetcotroornonXXSuSmumdadtaatsaestewtwithithanadndwwithitohuotutthtehePaPrat-rot-fo-fS-pSepeecehch(P(OPOS)Sc)ocnosntsratrianitnftofror
Ghostbuster 0.3341 0.1001 0.0981 0.1000
ouotuptuptuttetxetxst.sT.hTehererseuslutsltssusguggegsetsmtmaragrignianladledcerceraesaeseininatatattcakckpeprefrofromrmanacnecebubtustisginginfiicfiacnatnitmimprporvoevmemenetnitninpepreprlpelxeixtyity
Fast-DetectGPT 0.7510 0.0026 0.0030 0.0006
wwhehnenPOPOSScocnosntRsratariiadniatnsrtasraereenefnofrocrec0de..7d6.67 0.6333 0.6667 0.6000
(a)LogRank (b)Fast-DetectGPT
(a()aL)oLgogRaRnaknk (b()bF)aFsat-sDt-DeteetcetcGtGPTPT
Figure 4: Study on the impact of different mask percentages. We use OPT-2.7B and RoBERTa-large as proxy
FiFgiugruere4:4S:tSutduydyononthteheimimpapcatcotfodfidffifefreernetnmtmasakskpeprecrecnetnatgaegse.sW. WeeusueseOOPTP-T2-.27.B7BanadndRRoBoBEERRTaT-al-alragregeasasscsocroirnigng
scoringmodelstoattackLogRankandFast-DetectGPTdetectorsontheXSumdatasetat1%,5%,10%,15%,and
mmodoedleslstotoatatattcakckLoLgogRRanaknkanadndFaFsats-Dt-DeteetcetcGtGPTPTdedteetcetcotrosrsononXXSuSmumdadtaatsaesteattat1%1%, 5,%5%, 1,01%0%, 1,51%5%, ,anadnd202%0%
20%maskingrateswhilemeasuringdetectionperformanceandtextqualityintermsofAUROCandperplexity. The
mmasaks,kw,whihleilemmeaesausruinrigngdedteetcetciotinonpeprefrofromrmanacneceanadndtetxetxqtuqaulaitlyityinintetremrmssofoAfAUURROOCCanadndpepreprlpelxeixtyit.yT. TheheAAUURROOCC
AUROCapproaches0ataround10%withamoderateincreaseinperplexity. Maskingpercentagesbeyond15%
apapprporaocahcehse0s0ataatraoruonudnd101%0%wwithithmmodoedreartaetepepreprlpelxeixtyit.y.
degradetextqualityacrossbothdetectors.
5.2 ImpactofWordReplacementGeneration 5.3 ImpactofMaskingPercentage
414414 2021091)9,)R,RoBoBEERRTaT-al-alragrege(S(oSloaliamimananeteatla.,l.2,021091)9,)a,nadnd plpelsesinicnrceraesaesse,ss,usguggegsetsintigngthtahtatthtrhoruoguhghadavdevresrasrairailal 424727
Method
414515 FaFsats-tD-DeteetcetcGtGPTPT(B(Baoaoeteatla.,l.2,022032)3)dedteetcetcotrosr.s. rWer-eet-rtaerivanaiinlnuigna,tgeo,utohrueratpateattrcafkcokrimsiscaancpcaeapbaalbneldeoftoefmxmtaqkauiknaignligteyxeioxsfits-t- 424828
We evaluate the effectiveness of replacing GPT- iRniAgngFdTedteaetccertcootsrossrsvmamroirooeuresrormboaubssukts.itn.WgWpeeeprcrpeersneetsanegtnettsh.tihFsiisagsausraenan
424929
414616 5.543..45-TTTuhrehbeoUUwsesifteuhfluanlentrseassdsoitfoioOfnOualruWrGoGerndeen2rVearetacetdeemdAbAtettdatdcaikcnskgs i4mimsphoporowtrastnattnhdtaidtriterhceetciAotinoUnfRofOroCrfufstuuttaruberielriezrseeessaearacrrohcu.hn.d0when
434030
414717 modfeoflro(rMAAdikvdoevlroesvraseratiraailla.T,l2Tr0ar1ian3iinan)i.gnSgpecifically,weuse themaskingpercentagereaches10%,accompanied
414818
WWteheeprpWerseoesrnedtn2etVveeivcdiemdneocndeceetlhttarhataiotnueodruraotnatatGtcakocokngonletootNnoelnwylyssucsocur-c-- 5b.5y5.5aTmTroardnaesnrfsaeftreerrairnbaciblriietlaiytsyeofoinfOOupruerrTpTelexextxittAyA.tttatMcakcasksksing 434131
414919
cecpseussfssu,flwulylhlyiecvehavcdaoednsetsdaiednteestce1tcobtroislrlisboubntuwctaocnradnaslas(lMosomikmaoklaoekvethettehmaelm., IpnIenArcApepnpetpanegdneidsxixeTxaTcbaelbeedle7in,7gw,w1e5es%tsutduayrdeythutenhnetretacrnaessnfsseafrreayrbaaiblniidltiyty
434232
424020
mmo2r0oe1rer3obrbo)u,bsutotsttlhotrhcorauolgulyhghraedatvrdieverevsreasrat ira= ilatlr1 ta0 rianPiinnOignS.g-A.coAsnssshsioshtwoewnntn olfeoaofduortuoartaatatstcaigkcnkaicfiarccorasonsstsddidefifgferfraeedrneatntidtoednteeitcnetcotterosxr,tst,qrtaurnaaslnifsteyfre.rrirnigng
434333
424121 inisnTy anTboalnbeylem 5,5s,aa fas tfetw rerto hrtedheRreRap ial daiadc raemrdeedtneettcec tcoatrnodrisiidsaa date vds ev. resrW asra-er- thteheouotuptuptuttetxetxwt weegegtebtybyopotpitmimiziiznigngagaagianisntstLLogog 434434
showinTable4thatusingawordembeddingmodel
424222 iailalyllyrer-et-rtarianiendedonontetxetxstswwithithwworodrdswswapappipnign,g,itit RRanaknkanadndDDeteetcetcGtGPTPTtotosesveevrearlalotohtehrerdedteetcetcotrosr.s. 434535
insteadofanLLMalsoproduceseffectiveresults.
424323 alawlwayasysexehxihbiibtsitsaammucuhchgrgeraetaetrerinicnrceraesaeseinindedteetce-c- TTheheAAUURROOCConolnylydedcerceraesaessesmmaragrignianlalyll,ys,usguggegsetsintigng 434636
424424 tiotinonpeprefrofromrmanacneceunudnedreratatattcakckthtahnanthtehededcerceraesaese thtahtaotuoruratatattcakckisishihgihglhylytrtarnasnfsefrearbalbel.e. 434737
424525 ininpeprefrofromrmanacnecewwithitohuotutatatattcakc.k.FoFrorthteheAAbsbtsrtarcatct
424626 dadtaatsaeste,tt,hteheAAUURROOCCfofrobrobtohthclcelaenananadndatatattcakcksasmam--
77Table6: Effectofapplyingourgrammarconstraint. WeuseOPT-2.7BandRoBERTa-largeasscoringmodelsto
attacktheFast-DetecGPTdetectorontheXSumdataset,comparingperformancewithandwithoutthepart-of-speech
constraintonthegeneratedreplacementwords. Theresultsshowamarginaldecreaseinattackperformancebuta
significantimprovementinperplexitywhenPOSconstraintsareenforced.
NoPOSCorrection POSCorrection
AUROC Perplexity AUROC Perplexity
OPT-2.7B 0.0000 28.32 0.0006 17.53
RoBERTa-large 0.0062 31.36 0.0471 25.08
Original GPT3.5 Ours + No POS Correction Ours + POS Correction
The ban was backed by local authorities in The ban injunction backed by local authorities The ban was backed by local authorities within
Urumqi, state media reported. The move is the preserved Urumqi, state publication indicated. Urumqi, state media announced. The move
latest in a campaign against Islamic clothing and The move is the latest in a campaign against represents the latest in a campaign against
symbols, as the authorities strive to promote Islamic clothing and symbols, as the authorities Islamic clothing and symbols, since the authorities
secularism and maintain social stability in the strive laboring promote secularism sustain strive to promote secularism and maintain social
region. maintain social stability in the region. stability inside the region.
DetectGPT LLM Likelihood: 0.69 DetectGPT LLM Likelihood: 0.10 DetectGPT LLM Likelihood: 0.03
Perplexity: 17.03 Perplexity: 157.65 Perplexity: 36.70
Figure5: ComparisonontheeffectsofPOStagging. OntheleftisunmodifiedtextgeneratedbyGPT3.5-turbo;
inthemiddleisRAFT attackedtextbutwithoutPOSconsistencyconstraints;andontherightisRAFT attacked
text with POS consistency. This example illustrates that POS tagging significantly enhances text quality both
qualitativelyandquantitativelyasmeasuredbyperplexity,withoutcompromisingdetectionperformance.
5.4 ImpactoftheSourceGenerationModel 5.6 RAFT forAdversarialTraining
WestudytheeffectivenessofRAFT underdifferent We present evidence that our attack not only ef-
source generation models. We evaluate its effec- fectively subverts detectors but can also enhance
tiveness on text generated using GPT-3.5-Turbo, their robustness through adversarial training. As
Llama-3-70B(Touvronetal.,2023),andMixtral- showninTable7,aftertheRaidardetectorunder-
8x7B-Instruct(Jiangetal.,2024),whichrepresent goesadversarialtrainingonRAFT-attackedtext,it
a set of LLMs of varying size, architecture, and consistentlydemonstratesasignificantincreasein
trained corpora. We utilize the same generation detection performance under attack compared to
parametersasthoseemployedby(Baoetal.,2024) theperformancedecreaseobservedbeforeretrain-
forproducingtheGPT-3.5-turbogeneratedXSum ing. FortheAbstractdataset,theAUROCforboth
andSQuADdatasetsforLlama-3-70BandMixtral- attackedandnon-attackedtextsamplesincreases,
8x7B-Instruct. WeshowinFigure7thatRAFT re- indicatingthatRAFT canenhancetherobustness
mainshighlyeffectivewhennext-tokengeneration of existingdetectors throughadversarialtraining.
isusedasaproxytaskwithOPT-2.7B,GPT-NEO- Wepresentthisasanimportantdirectionforfuture
2.7B,GPT-J-6Bembeddingsmodelforsubverting research.
detectionagainstLogRank,RoBERTa-large,and
6 Conclusion
Fast-DetectGPTdetectors.
We introduce RAFT, an adversarial attack frame-
5.5 TransferrabilityofRAFT onother workforsubvertingmachine-generatedtextdetec-
Detectors torsbyleveragingauxiliaryLLMembeddings. Our
We study the transferability of RAFT-attacked methodeffectivelyidentifiesoptimalwordstoper-
text across various detectors. We evaluate the turbusingaproxyLLMembeddingandperturbs
attacked text generated by using OPT-2.7B next- them such that the original text remains semanti-
token generation and RoBERTa-large LLM de- callyconsistent,grammarerror-free,andreadsflu-
tectionproxyscoringtasksoptimizedagainstLo- ently. Experimentalresultsandmanualannotation
gRank and DetectGPT detectors on GhostBuster exercisesshowthatourmethodsuccessfullycom-
andFast-DetectGPT.Theresults,presentedinTa- promises various LLM detection methods while
ble A.3, show that the AUROC only decreases maintainingtextqualityandsemanticconsistency,
slightly,suggestingthatourattackishighlytrans- highlightingtheneedforrobustLLMcontentde-
ferable. tectors. Wealsodemonstratethattheoutputsfrom
RAFT canbeusedtoenhancetheresilienceofex-
istingdetectorsthroughadversarialtraining.ROC Plots on RAFT with RoBERTa-large LLM Detection Proxy Scoring Model
XSum Dataset SQuAD Dataset Abstract Dataset
1.0 1.0 1.0
0.8 0.8 0.8 L Lo og g P Pr ro ob ba ab bi il li it ty y ( (O RAri Fg Tin )al)
Log Rank (Original)
Log Rank (RAFT)
0.6 0.6 0.6 Ghostbuster (Original)
Ghostbuster (RAFT)
DetectGPT (Original)
DetectGPT (RAFT)
0.4 0.4 0.4 Fast-DetectGPT (original)
Fast-DetectGPT (RAFT)
0.2 0.2 0.2
0.0 0.0 0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate (FPR)
Figure6: ROCcurvesformachine-generatedXSumdatasetunderRAFT attack,usingRoBERTa-largeastheproxy
scoringmodel,comparedacrossmultipledetectors. TheROCcurvesforbothattackedandunattackedtextprovide
amorecomprehensiveevaluationofRAFT’srobustnessinsubvertingtextdetectorsthansinglemetrics.
XSum Dataset
GPT-3.5-Turbo Llama-3-70B Mixtral-8x7B-Instruct
Proxy Model Proxy Model Proxy Model
OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B
0.30
LogRank 0.2793 0.2023 0.2187 LogRank 0.2421 0.1802 0.1787 LogRank 0.2597 0.2092 0.2179 0.25
0.20
RoBERTa-Large 0.2408 0.1202 0.1222 RoBERTa-Large 0.1316 0.0680 0.0712 RoBERTa-Large 0.1144 0.0638 0.0634 0.15
0.10
Fast-DetectGPT 0.0010 0.0017 0.0023 Fast-DetectGPT 0.0042 0.0056 0.0047 Fast-DetectGPT 0.0378 0.0392 0.0383 0.05
0.00
SQuAD Dataset
GPT-3.5-Turbo Llama-3-70B Mixtral-8x7B-Instruct
Proxy Model Proxy Model Proxy Model
OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B OPT-2.7B
GPT-NEO-2.7B
GPT-J-6B
0.30
LogRank 0.3100 0.2544 0.2421 LogRank 0.2957 0.2273 0.2299 LogRank 0.2854 0.2230 0.2192 0.25
0.20
RoBERTa-Large 0.2013 0.1460 0.1357 RoBERTa-Large 0.0459 0.0289 0.0336 RoBERTa-Large 0.0610 0.0412 0.0374 0.15
0.10
Fast-DetectGPT 0.0155 0.0287 0.0313 Fast-DetectGPT 0.0031 0.0095 0.0064 Fast-DetectGPT 0.0069 0.0124 0.0102 0.05
0.00
Figure7: AUROCofusingRAFT undervarioussourcegenerationmodelsandproxyscoringmodelsagainstLog
Rank,RoBERTa-large,andFast-DetectGPTdetectorsontheXSumandSQuADdataset. Theresultsdemonstrate
RAFT remainsrobustundervarioussourcegenerationmodelsandproxyscoringmodelpairs.
Table7: Adversarialtrainingresults. WetraintheRaidardetectorontextswithandwithoutwordswapping,denoted
asTrainingMethod,andevaluateditsperformanceonsampleswith(Attack)andwithout(Clean)wordswapping.
Theresultshowsthedetectorbecomesmorerobustunderadversarialtraining. BoldedAUROCresultsdenote
highest-performingdetector.
Dataset XSum SQuAD Abstract
TrainingMethod Normal Adversarial Normal Adversarial Normal Adversarial
CleanAUROC 0.8000 0.7500 0.6833 0.6667 0.6500 0.6833
AttackAUROC 0.6000 0.7333 0.7167 0.8000 0.6500 0.7167
)RPT(
etaR
evitisoP
eurT
rotceteD
rotceteD
rotceteD
rotceteD
rotceteD
rotceteD7 Limitations one’s work and efficiency. By scrutinizing LLM
detectors through red-teaming, we highlight cur-
While we demonstrate RAFT’s effectiveness in
rentvulnerabilitiesinthesesystemsandurgently
compromising various LLM detectors, there are
advocate for the development of more resilient
severallimitationstonote:
mechanisms. While we introduce how examples
generatedbyRAFT canbeutilizedforadversarial
Scalability of Human Evaluations: While
training,futureworkshouldemphasizethedevel-
ourmanualhumanevaluationstudydemonstrated
opmentofrobustdefensemechanisms.
thatRAFT’sperturbationsarerealisticandarenot
necessarily less preferred from the original text, 9 Acknowledgements
larger-scale human evaluations are necessary to
This work was supported in part by mul-
validate the quality and realism of the perturbed
tiple Google Cyber NYC awards, Columbia
texts robustly. Furthermore, we did not exten-
SEAS/EVPR Stimulus award, and Columbia
sively explore the demographic and linguistic
SEAS-KFAIGenerativeAIandPublicDiscourse
backgroundsofthehumanevaluators,whichmay
Researchaward.
inducebiasinourstudy.
Computational & Cost Overhead: The
References
runtime performance of RAFT is shown in Table
A.5. Generating substitution candidates using SaharAbdelnabiandMarioFritz.2021. Adversarialwa-
termarkingtransformer: Towardstracingtextprove-
GPT-3.5-Turbo or using a word embedding for
nancewithdatahiding. In42ndIEEESymposiumon
each selected candidate replacement word intro- SecurityandPrivacy,SP2021,SanFrancisco,CA,
duces significant computation and cost overhead. USA,24-27May2021,pages121–140.IEEE.
This may limit the practicality of this attack in
MoustafaAlzantot,YashSharma,AhmedElgohary,Bo-
real-time or in budget-constrained environments.
JhangHo,ManiB.Srivastava,andKai-WeiChang.
Developing more efficient prompting strategies 2018. Generating natural language adversarial ex-
for effective word-level substitutions would be amples. InProceedingsofthe2018Conferenceon
EmpiricalMethodsinNaturalLanguageProcessing,
essentialforpracticaluse.
Brussels,Belgium,October31-November4,2018,
pages 2890–2896. Association for Computational
Fixed Perturbation Rate: We fixed the Linguistics.
perturbation rate at 10% across all experiments,
GuangshengBao, YanbinZhao, ZhiyangTeng, Linyi
which is less than the rate set in Shi et al. (2024)
Yang, and Yue Zhang. 2024. Fast-detectgpt: Effi-
and Krishna et al. (2023). While this provides
cientzero-shotdetectionofmachine-generatedtext
a consistent and strong benchmark, it does not viaconditionalprobabilitycurvature. InTheTwelfth
accountforscenarioswhereasmallerperturbation International Conference on Learning Representa-
tions,ICLR2024,Vienna,Austria,May7-11,2024.
rate may be more effective. Exploring adaptive
OpenReview.net.
perturbation strategies based on text complexity
anddetectionsensitivitymayyieldamoreefficient StevenBird,EwanKlein,andEdwardLoper.2009. Nat-
uralLanguageProcessingwithPython. O’Reilly.
andeffectiveattack.
Eric Brill. 1995. Transformation-based error-driven
Limited Detector Evaluation: RAFT was learning and natural language processing: A case
tested against various types of LLM detectors. studyinpart-of-speechtagging. Comput.Linguistics,
21(4):543–565.
However, as new detection methods emerge, we
mustcontinuouslyevaluateourattack’srobustness NicholasCarliniandDavidA.Wagner.2017. Towards
onnovelapproaches. evaluatingtherobustnessofneuralnetworks. In2017
IEEESymposiumonSecurityandPrivacy,SP2017,
8 EthicsStatement SanJose,CA,USA,May22-26,2017,pages39–57.
IEEEComputerSociety.
Whileourpaperpresentsamethodtosubvertdetec-
tionofmachine-generatedtextbyLLMdetectors, AbhimanyuDubey,AbhinavJauhri,AbhinavPandey,
AbhishekKadian,AhmadAl-Dahle,AieshaLetman,
itisimperativetoacknowledgethatLLMsarepre-
Akhil Mathur, Alan Schelten, Amy Yang, Angela
dominantlyutilizedingoodfaithandhaveawide
Fan, and et al. 2024. The llama 3 herd of models.
variety of benefits to society, such as improving CoRR,abs/2407.21783.MatthewFreestoneandShubhraKantiKarmakerSantu. Albert Q. Jiang, Alexandre Sablayrolles, Antoine
2024. Word embeddings revisited: Do llms offer Roux,ArthurMensch,BlancheSavary,ChrisBam-
somethingnew? CoRR,abs/2402.11094. ford,DevendraSinghChaplot,DiegodeLasCasas,
Emma Bou Hanna, Florian Bressand, Gianna
LeoGao,StellaBiderman,SidBlack,LaurenceGold- Lengyel, Guillaume Bour, Guillaume Lample,
ing, Travis Hoppe, Charles Foster, Jason Phang, Lélio Renard Lavaud, Lucile Saulnier, Marie-
Horace He, Anish Thite, Noa Nabeshima, Shawn AnneLachaux,PierreStock,SandeepSubramanian,
Presser, and Connor Leahy. 2021. The pile: An Sophia Yang, Szymon Antoniak, Teven Le Scao,
800gbdatasetofdiversetextforlanguagemodeling. Théophile Gervet, Thibaut Lavril, Thomas Wang,
CoRR,abs/2101.00027. TimothéeLacroix,andWilliamElSayed.2024. Mix-
tralofexperts. CoRR,abs/2401.04088.
Sebastian Gehrmann, Hendrik Strobelt, and Alexan-
derM.Rush.2019. GLTR:statisticaldetectionand Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter
visualization of generated text. In Proceedings of Szolovits. 2020. Is BERT really robust? A strong
the57thConferenceoftheAssociationforCompu- baselinefornaturallanguageattackontextclassifi-
tationalLinguistics,ACL2019,Florence,Italy,July cation and entailment. In The Thirty-Fourth AAAI
28-August2,2019,Volume3: SystemDemonstra- ConferenceonArtificialIntelligence,AAAI2020,The
tions,pages111–116.AssociationforComputational Thirty-Second Innovative Applications of Artificial
Linguistics. IntelligenceConference,IAAI2020,TheTenthAAAI
SymposiumonEducationalAdvancesinArtificialIn-
AlexeiGrinbaumandLaurynasAdomaitis.2022. The
telligence,EAAI2020,NewYork,NY,USA,February
ethical need for watermarks in machine-generated
7-12,2020,pages8018–8025.AAAIPress.
language. CoRR,abs/2209.03118.
John Kirchenbauer, Jonas Geiping, Yuxin Wen,
JulianHazell.2023. Largelanguagemodelscanbeused JonathanKatz,IanMiers,andTomGoldstein.2023.
toeffectivelyscalespearphishingcampaigns. CoRR, Awatermarkforlargelanguagemodels. InInterna-
abs/2305.06972. tionalConferenceonMachineLearning,ICML2023,
23-29 July 2023, Honolulu, Hawaii, USA, volume
Dan Hendrycks, Collin Burns, Steven Basart, Andy
202ofProceedingsofMachineLearningResearch,
Zou,MantasMazeika,DawnSong,andJacobStein-
pages17061–17084.PMLR.
hardt.2021. Measuringmassivemultitasklanguage
understanding. In9thInternationalConferenceon Kalpesh Krishna, Yixiao Song, Marzena Karpinska,
LearningRepresentations,ICLR2021,VirtualEvent, John Wieting, and Mohit Iyyer. 2023. Paraphras-
Austria,May3-7,2021.OpenReview.net. ingevadesdetectorsofai-generatedtext,butretrieval
is an effective defense. In Advances in Neural In-
DirkHovy.2016. Theenemyinyourowncamp: How
formation Processing Systems 36: Annual Confer-
well can we detect statistically-generated fake re-
enceonNeuralInformationProcessingSystems2023,
views-anadversarialstudy. InProceedingsofthe
NeurIPS2023,NewOrleans,LA,USA,December10
54thAnnualMeetingoftheAssociationforCompu-
-16,2023.
tationalLinguistics,ACL2016,August7-12,2016,
Berlin,Germany,Volume2: ShortPapers.TheAsso- ThomasLavergne,TanguyUrvoy,andFranccoisYvon.
ciationforComputerLinguistics. 2008. Detectingfakecontentwithrelativeentropy
scoring. InProceedingsoftheECAI’08Workshop
Hugging Face Inc. 2022. Transformers: State-of- on Uncovering Plagiarism, Authorship and Social
the-art natural language processing. https:// SoftwareMisuse,Patras,Greece,July22,2008,vol-
huggingface.co.
ume377ofCEURWorkshopProceedings.CEUR-
WS.org.
Daphne Ippolito, Daniel Duckworth, Chris Callison-
Burch,andDouglasEck.2020. Automaticdetection ChengzhiMao,CarlVondrick,HaoWang,andJunfeng
ofgeneratedtextiseasiestwhenhumansarefooled. Yang. 2024. Raidar: generative AI detection via
InProceedingsofthe58thAnnualMeetingoftheAs- rewriting. InTheTwelfthInternationalConference
sociationforComputationalLinguistics,ACL2020, on Learning Representations, ICLR 2024, Vienna,
Online,July5-10,2020,pages1808–1822.Associa- Austria,May7-11,2024.OpenReview.net.
tionforComputationalLinguistics.
TomásMikolov,KaiChen,GregCorrado,andJeffrey
MojanJavaheripiandSébastienBubeck.2023. Phi-2: Dean.2013a. Efficientestimationofwordrepresenta-
Thesurprisingpowerofsmalllanguagemodels. tionsinvectorspace. In1stInternationalConference
onLearningRepresentations,ICLR2013,Scottsdale,
AlbertQ.Jiang,AlexandreSablayrolles,ArthurMen- Arizona,USA,May2-4,2013,WorkshopTrackPro-
sch,ChrisBamford,DevendraSinghChaplot,Diego ceedings.
de Las Casas, Florian Bressand, Gianna Lengyel,
Guillaume Lample, Lucile Saulnier, Lélio Re- TomásMikolov,IlyaSutskever,KaiChen,GregoryS.
nard Lavaud, Marie-Anne Lachaux, Pierre Stock, Corrado,andJeffreyDean.2013b. Distributedrepre-
TevenLeScao,ThibautLavril,ThomasWang,Timo- sentationsofwordsandphrasesandtheircomposi-
théeLacroix,andWilliamElSayed.2023. Mistral tionality. InAdvancesinNeuralInformationProcess-
7b. CoRR,abs/2310.06825. ingSystems26: 27thAnnualConferenceonNeuralInformationProcessingSystems2013.Proceedings IreneSolaiman,MilesBrundage,JackClark,Amanda
ofameetingheldDecember5-8,2013,LakeTahoe, Askell,ArielHerbert-Voss,JeffWu,AlecRadford,
Nevada,UnitedStates,pages3111–3119. and Jasmine Wang. 2019. Release strategies and
the social impacts of language models. CoRR,
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, abs/1908.09203.
Christopher D. Manning, and Chelsea Finn. 2023.
Detectgpt: Zero-shotmachine-generatedtextdetec- E.Tian.2023. Gptzero: Anaitextdetector.
tion using probability curvature. In International
ConferenceonMachineLearning,ICML2023,23- HugoTouvron,ThibautLavril,GautierIzacard,Xavier
29July2023,Honolulu,Hawaii,USA,volume202 Martinet,Marie-AnneLachaux,TimothéeLacroix,
ofProceedingsofMachineLearningResearch,pages BaptisteRozière,NamanGoyal,EricHambro,Faisal
24950–24962.PMLR. Azhar,AurélienRodriguez,ArmandJoulin,Edouard
Grave,andGuillaumeLample.2023. Llama: Open
Shashi Narayan, Shay B. Cohen, and Mirella Lapata. and efficient foundation language models. CoRR,
2018. Don’tgivemethedetails,justthesummary! abs/2302.13971.
topic-aware convolutional neural networks for ex-
treme summarization. In Proceedings of the 2018 VivekVerma,EveFleisig,NicholasTomlin,andDan
Conference on Empirical Methods in Natural Lan- Klein.2024. Ghostbuster: Detectingtextghostwrit-
guageProcessing,Brussels,Belgium,October31- ten by large language models. In Proceedings of
November 4, 2018, pages 1797–1807. Association the2024ConferenceoftheNorthAmericanChap-
forComputationalLinguistics. teroftheAssociationforComputationalLinguistics:
Human Language Technologies (Volume 1: Long
OpenAI. 2023. GPT-4 technical report. CoRR, Papers),pages1702–1717,MexicoCity,Mexico.As-
abs/2303.08774. sociationforComputationalLinguistics.
OpenAI.2024a. Hello,gpt-4o. Accessed: 2024-09-30. Ben Wang and Aran Komatsuzaki. 2021. GPT-J-
6B: A 6 Billion Parameter Autoregressive Lan-
OpenAI.2024b. Models. https://platform.openai. guageModel. https://github.com/kingoflolz/
com/docs/models/gpt-3-5-turbo. mesh-transformer-jax.
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida, Rowan Zellers, Ari Holtzman, Hannah Rashkin,
Carroll L. Wainwright, Pamela Mishkin, Chong YonatanBisk,AliFarhadi,FranziskaRoesner,and
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay, Yejin Choi. 2019. Defending against neural fake
JohnSchulman,JacobHilton,FraserKelton,Luke news. InAdvancesinNeuralInformationProcessing
Miller,MaddieSimens,AmandaAskell,PeterWelin- Systems32: AnnualConferenceonNeuralInforma-
der,PaulF.Christiano,JanLeike,andRyanLowe. tion Processing Systems 2019, NeurIPS 2019, De-
2022. Training languagemodelsto followinstruc- cember8-14,2019,Vancouver,BC,Canada,pages
tionswithhumanfeedback. InAdvancesinNeural 9051–9062.
InformationProcessingSystems35: AnnualConfer-
enceonNeuralInformationProcessingSystems2022, Susan Zhang, Stephen Roller, Naman Goyal, Mikel
NeurIPS2022,NewOrleans,LA,USA,November28 Artetxe, Moya Chen, Shuohui Chen, Christopher
-December9,2022. Dewan, Mona T. Diab, Xian Li, Xi Victoria Lin,
TodorMihaylov,MyleOtt,SamShleifer,KurtShus-
AlecRadford,JeffreyWu,RewonChild,DavidLuan, ter, Daniel Simig, Punit Singh Koura, Anjali Srid-
DarioAmodei,IlyaSutskever,etal.2019. Language har, Tianlu Wang, and Luke Zettlemoyer. 2022.
modelsareunsupervisedmultitasklearners. OpenAI OPT: open pre-trained transformer language mod-
blog,1(8):9. els. CoRR,abs/2205.01068.
PranavRajpurkar,JianZhang,KonstantinLopyrev,and
PercyLiang.2016. SQuAD:100,000+questionsfor
machinecomprehensionoftext. InProceedingsof
the2016ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages2383–2392,Austin,
Texas.AssociationforComputationalLinguistics.
VinuSankarSadasivan,AounonKumar,SriramBala-
subramanian,WenxiaoWang,andSoheilFeizi.2023.
Canai-generatedtextbereliablydetected? CoRR,
abs/2303.11156.
ZhouxingShi,YihanWang,FanYin,XiangningChen,
Kai-WeiChang,andCho-JuiHsieh.2024. Redteam-
inglanguagemodeldetectorswithlanguagemodels.
Trans.Assoc.Comput.Linguistics,12:174–189.A Appendix
A.1 Tables
TableA.1: OurattackresultsusingadditionalproxyscoremodelsdemonstrateRAFT iseffectiveagainstvarious
targetdetectors,scoringsimilarlytoresultsshowninTable1. GPT-2,GPT-NEO-2.7B,andGPT-6Busenexttoken
generationandRoBERTa-baseusesLLMdetectionasproxyscoringmodeltasks. MetricreportedisAUROC.
Dataset/Method LogProbability LogRank Ghostbuster DetectGPT Fast-DetectGPT Average
XSum/Unattacked 0.9577 0.9584 0.6637 0.9903 0.8925 0.8925
GPT-2 0.0046 0.0196 0.0453 0.0211 0.0182 0.0217
GPT-NEO-2.7B 0.0052 0.0144 0.0408 0.0120 0.0160 0.0177
GPT-6B 0.0034 0.0156 0.0426 0.0202 0.0160 0.0196
RoBERTa-base 0.0372 0.0584 0.0003 0.0621 0.0390 0.0394
SQuAD/Unattacked 0.9027 0.9075 0.7659 0.9800 0.8890 0.8890
GPT-2 0.0595 0.0959 0.0862 0.0574 0.0695 0.0737
GPT-NEO-2.7B 0.0532 0.0839 0.0831 0.0518 0.0617 0.0667
GPT-J-6B 0.0524 0.0883 0.0667 0.0508 0.0600 0.0636
RoBERTa-base 0.0999 0.1262 0.0175 0.1433 0.1068 0.0988
Abstract/Unattacked 0.6329 0.6502 0.8455 0.9148 0.7609 0.7609
GPT-2 0.1466 0.1960 0.0912 0.1885 0.1353 0.1515
GPT-NEO-2.7B 0.1041 0.1577 0.0873 0.1491 0.1050 0.1206
GPT-J-6B 0.1066 0.1624 0.0794 0.1515 0.1075 0.1215
RoBERTa-base 0.0296 0.0426 0.0388 0.0079 0.1994 0.0637
TableA.2: PerformanceofRAFT attackmeasuredbyTPRat5%FPR.OurresultsshowthatRAFT significantly
lowerstheTPRat5%FPRtonearly0acrossalldetectorsanddatasets,highlightingtherobustnessofourapproach.
Metric LogProbability LogRank Ghostbuster DetectGPT Fast-DetectGPT
XSum/Unattacked 0.7800 0.8067 0.2200 0.1667 0.9400
OPT-2.7B(Ours) 0.0000 0.0000 0.0000 0.0000 0.0000
RoBERTa-base(Ours) 0.0000 0.0000 0.0000 0.0000 0.0000
RoBERTa-large(Ours) 0.0000 0.0000 0.0000 0.0000 0.0000
SQuAD/Unattacked 0.5750 0.6050 0.1650 0.1533 0.9150
OPT-2.7B(Ours) 0.0000 0.0000 0.0000 0.0000 0.0150
RoBERTa-base(Ours) 0.0000 0.0000 0.0000 0.0000 0.0000
RoBERTa-large(Ours) 0.0000 0.0000 0.0000 0.0000 0.0000
Abstract/Unattacked 0.2086 0.2257 0.2314 0.0000 0.6600
OPT-2.7B(Ours) 0.0000 0.0000 0.0200 0.0000 0.0229
RoBERTa-base(Ours) 0.0000 0.0000 0.0171 0.0000 0.0000
RoBERTa-large(Ours) 0.0000 0.0000 0.0143 0.0000 0.0000TableA.3: TransferabilityofRAFT attackedtext. WeevaluateRAFT perturbedtext,usingOPT-2.7BandRoBERTa-
largeproxyscoringmodelsagainstLogRankandDetectGPTdetectors,onLogRank,GhostBuster,DetectGPT,and
Fast-DetectGPTdetectors. AUROCmetricsshowonlyaslightdecrease,suggestingourattackishighlytransferable.
RAFT-optimizedDetector LogRank DetectGPT
RAFTProxyScoreModel/TransferDetector GhostBuster DetectGPT Fast-DetectGPT LogRank GhostBuster Fast-DetectGPT
OPT-2.7B 0.1082 0.1411 0.0022 0.0235 0.1264 0.0059
RoBERTa-large 0.0578 0.0498 0.1541 0.2247 0.1116 0.2927
TableA.4: EvaluationofRAFT byusinghigher-performingLLMs,basedonMMLUbenchmarkscore(Hendrycks
etal.,2021),fornext-tokengenerationasproxyscoringmodelontheXSumdataset. GPT-4o(OpenAI,2024a)
isusedforwordreplacementcandidategenerationinsteadofGPT-3.5-Turbo. TheresultsillustratethatRAFT is
highlyeffectiveonmorerecentmodels.
ProxyScoringModel AUROC TPRat5%FPR
XSum/Unattacked 0.9903 0.9400
Llama-3-8B 0.0485 0.0000
Mistral-7B-v0.3 0.2071 0.0000
Phi-2-2.7B(JavaheripiandBubeck,2023) 0.1873 0.0000
A.2 HumanEvaluationTaskDetails
Theworkerswerepaid$0.05USDforeachexample. Theannotationtimeforeachexamplevaries,but
theestimatedwagerateis$9/hour,whichishigherthantheUSminimumwage($7.25/hour).
MTurkTaskPrompt:
Text 1: ${Text 1}
Text 2: ${Text 2}
Options :
• Text 1 is better
• Text 2 is better
• No Preference
• Both texts are equally bad
Note that ${Text 1} and ${Text 2} are shuffled between the original human-written text and RAFT
perturbedtexttoavoidselectionbias.
A.3 RAFT RuntimePerformance
TableA.5: WeexecuteRAFT onaLinuxcomputeclusterequippedwith188GBofRAMandanNVIDIAA100
GPUwith40GBofmemory. UsingRoBERTa-baseastheproxyscoringmodelandFast-DetectGPTasthetarget
detector,bothloadedontheGPU,werunRAFT ontheXSumdataset. Wordreplacementcandidatesaregenerated
usingGPT-3.5-Turbo.
No.Sam- Masking Rate Avg. No. Words/ Avg. No. WordsRe- Avg.Runtime(s)/ Avg. Runtime(s)/
ples (k%) Sample placed/Sample Sample WordReplaced
150 10% 181 18 21.64 1.20