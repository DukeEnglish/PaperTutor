MINT: A wrapper to make multi-modal and multi-image AI models interactive
Jan Freyberg1∗, Abhijit Guha Roy1∗, Terry Spitz1∗, Beverly Freeman1, Mike Schaekermann1, Patricia Strachan1,
Eva Schnider1, Renee Wong1, Dale R Webster1, Alan Karthikesalingam1, Yun Liu1, Krishnamurthy Dvijotham2∗∗,
Umesh Telang1∗∗
1Google Research, Health AI, 2Google DeepMind
Abstract
Duringthediagnosticprocess, doctorsincorporatemultimodalinformationincludingimagingandthemedicalhistory
- and similarly medical AI development has increasingly become multimodal. In this paper we tackle a more subtle
challenge: doctors take a targeted medical history to obtain only the most pertinent pieces of information; how do
we enable AI to do the same? We develop a wrapper method named MINT (Make your model INTeractive) that
automatically determines what pieces of information are most valuable at each step, and ask for only the most useful
information. WedemonstratetheefficacyofMINTwrappingaskindiseasepredictionmodel,wheremultipleimagesand
a set of optional answers to 25 standard metadata questions (i.e., structured medical history) are used by a multi-modal
deep network to provide a differential diagnosis. We show that MINT can identify whether metadata inputs are needed
and if so, which question to ask next. We also demonstrate that when collecting multiple images, MINT can identify if
an additional image would be beneficial, and if so, which type of image to capture. We showed that MINT reduces the
numberofmetadataandimageinputsneededby82%and36.2%respectively,whilemaintainingpredictiveperformance.
Using real-world AI dermatology system data, we show that needing fewer inputs can retain users that may otherwise
fail to complete the system submission and drop off without a diagnosis. Qualitative examples show MINT can closely
mimic the step-by-step decision making process of a clinical workflow and how this is different for straight forward cases
versusmoredifficult, ambiguouscases. FinallywedemonstratehowMINTisrobusttodifferentunderlyingmulti-model
classifiers and can be easily adapted to user requirements without significant model re-training.
Keywords: Deep learning, dermatology, interactive AI, multi-modal networks.
1. Introduction step they assimilate all information gathered so far to de-
termine the top candidate diagnoses. They then ask spe-
cific questions or gather specific data points to rule in or
Deep learning for medical applications increasingly in-
rule out diagnoses. This process can be characterised by
volves structured, tabular data to augment unstructured
threeattributes: (i)Asequentialdecisionmakingpro-
input data such as images and signals. This reflects the
cesstogatheradditionalinformation,(ii)Apersonalised
nature of medical care, in which doctors tend to make de-
flow–whichquestionstoaskinwhatorder–whichvaries
cisionsbasedonmulti-modalinformationinsteadofpurely
across patient journeys, based on data acquired, and (iii)
based on imaging or physiological data. For example,
Identifying when to stop the acquisition process when
alongside capturing images or scans, patient information
a reliable diagnosis has been obtained. In this way, the
such as demographics, patient history, non-visual symp-
diagnostic data collection process is targeted and enables
toms, signs, and test results can be critical in the decision
both faster diagnosis and avoids superfluous testing.
making process. Often, even the unstructured data comes
In this paper, we focus on medical AI and the human-
inmultipleviews, suchasfrontalandlateralchestX-rays,
AI interaction during data acquisition and consider how
or photographs of skin lesions from multiple perspectives
active feature acquisition (AFA, also known as dynamic
or in multiple locations. Acquisition of the complete bat-
feature selection) can improve interactions with patients
tery of information involves collection of extraneous infor-
when multiple views and multiple modalities are required
mation and its associated costs.
for prediction.
By contrast, clinicians in practice approach data col-
lection during diagnosis as an iterative process. At every
1.1. Related work
We consider the field of AFA as most relevant to the
∗J.Freyberg,A.GuhaRoyandT.Spitzarejointfirstauthors.
∗∗U.TelangandK.Dvijothamarejointlastauthors. work presented here. The goal of AFA is to acquire a
Correspondenceto: {janfreyberg,agroy,terryspitz}@google.com subset of features, in a cost sensitive manner, in order to
Preprint submitted to Medical Image Analysis January 23, 2024
4202
naJ
22
]CH.sc[
1v23021.1042:viXraa) gain for each selected feature one interaction at a time.
For example, (Ma et al., 2018) and (Zannone et al., 2019)
model the information gain by predicting missing features
Additional image
Diagnostic usingvariationalautoencoders(VAEs),andusingthepre-
model Y Y1 Additional question: “...” dicted features to calculate information gain. We recently
Y2
3 proposedaparticularformulationformodelsrelyingonin-
No additional questions termediate concepts in which we use confidence and value
1 2 3. . . MINT of the concepts to determine their importance (Chauhan
4.
… et al., 2022). Recently, Covert et al. (Covert et al., 2023)
aimtousetheadvantagesofgreedyselectionintraininga
b)
reinforcement learning algorithm. They train a policy to
MINT
greedily select the next best feature, improving the stabil-
“Wide view” “Q3” “Q1” “None” ity of the resulting policy and succeeding in applying it to
Next info? Next info? Next info? Next info?
a broad range of datasets.
User The majority of existing work covers tabular data for
Workflow 1. 1. 1. 1. Y
2 3 4 …. . . 2 3 4 …. . . 2 3 4 …. . . 2 3 4 …. . . Y Y1 2
3
historicandpracticalreasons. AFAwasdevelopedforweb
data in the e-commerce space (see e.g. Zheng and Pad-
manabhan, 2002), and before deep learning made high-
Figure1: a)TheMINTframeworkwrapsamulti-modaldiagnostic dimensional data modelling more commonplace. Prac-
modelforinteractiveuse,takingapartialsetofimagesandmetadata
tically, many metrics and objectives optimised by many
asinputsandreturningthenextimagetype,questionorearlystop-
ping token. b) The workflow consists ofinteractive data gathering; AFA algorithms are tractable only for low-dimensional
in each round all data collected so far is passed to MINT. If MINT data, such as mutual information between features and
requestsadditionaldata,thenextimageoransweriscollectedfrom outcome (see e.g. Chen et al., 2015). Recent work in
theuser,otherwisetheworkflowstopsandreturnsafinalresultfrom
medical domains has involved multi-modal classification
thediagnosticmodel.
(Akrout et al., 2018, 2019), but only tabular data was ac-
quired interactively.
maximisetesttimeperformance. Mostworkestimatesthe Work that involves actively acquiring image data of-
information value of a feature at each step. This tends to ten focuses on single-image, pixel-wise data acquisition
be approached using either Reinforcement Learning (RL) (e.g. Li et al., 2021; Ghosh and Lan, 2023; Li and Oliva,
or greedy approaches. 2020). This is an approximation of active perception (Ba-
RL approaches have the benefit that agents can the- jcsy et al., 2018), a problem of real-world perception by
oretically be trained to maximise the performance of the robot agents that may not be able to perceive a whole
fullsequentialfeatureselection,ratherthanjustthatofthe scene all at once, but is has limited relevance in many
next feature. Previous work treats the diagnostic model medical domain tasks.
as a black box reward evaluator (Bernardino et al., 2022), MostrelevanttoourworkisrecentworkbyAkroutand
or by sharing representations and training the diagnostic colleagues(2018;2019). Theauthorsfocusondermatology
and acquisition model jointly (Shim et al., 2018). How- classification using images. Using single-image diagnostic
ever, despite the promise of RL to optimise the sequential data, the authors train a classification model that esti-
acquisitiontaskasawhole,recentworkshowsthatgreedy mates the probabilities of each disease. They then use an
approaches(Chauhanetal.,2022;Covertetal.,2023)and independent dataset for identifying structured questions
evenstaticapproaches(Erionetal.,2022;Chauhanetal., related to the diseases they are diagnosing, which they
2022) can outperform RL-based methods. Whether RL term the knowledge graph. The authors update the prob-
is competitive varies significantly across tasks, indicating abilities produced by the image model using the knowl-
that the methods are sensitive to the dimensionality and edge graph by multiplying the conditional probability of
cardinality of the dataset. a disease given a structured piece of information with the
One particularly relevant paper is (Kossen et al., 2022). probability estimated by the image model. This means
The authors focus on multi-modal data, specifically tem- they do not require the image model and the structured
poral datasets, where data are acquired over time. This updating to be trained on the same dataset.
is relevant for medical scenarios, where over the course The authors then test two approaches towards actively
of a patient’s treatment, different data may become im- acquiring these structured questions. First, as they up-
portant at different points. Multi-modal data are han- dateprobabilities, theycancalculatetheinformationgain
dled using the PerceiverIO architecture, and the authors foreachstructuredquestiondirectly(Akroutetal.,2018).
demonstrate that their approach can structurally handle Second, in order to estimate the benefit of questions in
sequentialdatawithmissingfeatures. However,theacqui- a non-greedy fashion, they use RL to identify the next
sition agent produces static behaviour rather than ”per- question to ask (Akrout et al., 2019). The authors see re-
sonalised” behaviour for each example. markable success, with the RL model improving over the
Greedy approaches instead maximise information greedy model by 22%. In contrast to this work, we fo-
2
segamI
atadateMcusonamulti-modalmodelinwhichstructuredquestions twochangestothemodelinputpipeline. First,eachinput
are used as input to the deep learning classifier directly. from X is acquired one at a time in a step-by-step or-
Dependingonthespecificdatasetused, thisallowsthedi- der with MINT iteratively establishing its sequence. This
agnostic model to compare image features and structured change introduces a personalised input flow for each pa-
information when making diagnostic predictions and en- tient similar to clinical setups. Second, at every input ac-
ables better fusion of structured information. quisition step MINT estimates the value of incorporating
additional inputs and can terminate the acquisition pro-
1.2. Our contributions cessearlyifnoadditionalperformancegainsareexpected.
This change can potentially reduce the number of inputs
In this article, we propose MINT: Make your model
required significantly.
Interactive,aninteractiveAIframeworkwhichcanmimic
MINT involves learning a value estimator f (·) and
theiterativeinformationacquisitionprocessusedinaclin- MINT
a value threshold T. At any step of the input acquisi-
ical scenario. We focus on the application of dermatology
tion process, we use f (·) to estimate the value for all
conditionclassification(asdescribedinLiuetal.,2020and MINT
possible inputs yet to acquire. We then acquire the input
Roy et al., 2022). We use multiple smartphone captured
withhighestestimatedvalue(i.e. themostinformativein-
photographs and structured medical history metadata as
put) at each step. If the highest estimated value is below
inputswiththeaimofprovidingpotentialdifferentialdiag-
threshold T, we stop the acquisition process.
nosisconditionsasoutput. MINTactsasawrapperwhich
Wefindparametersforthevalueestimatorf (·)and
can operate on top of any multi-modal/ multi-view ML MINT
the threshold T by optimising for two competing objec-
model and make it interactive. This makes our solution
tives. The first objective O in Eq. 1 indicates the differ-
easy to use in a scalable manner, without retraining the 1
ence in average cardinality of the total possible inputs to
underlying model. This enables ML models to iteratively
theinputsactuallyacquiredbyMINT.Thiscanbewritten
acquire the most relevant information from the user, and
as:
thus reduces inference time data acquisition cost caused
by querying for irrelevant or redundant data.
In this article, we: maximuminputsize
• Extend active feature acquisition to the multi-view, O 1 :E i[|X i|]−E i[|Xˆ i|] (1)
multi-modalsettingencounteredinmanymedicalap-
acquiredinputsize
plications.
ThesecondobjectiveO inEq.2indicatestheexpected
• Produce a simple but effective approach to actively 2
changeinmodelperformanceusingallpossibleinputsver-
acquiring photographs of complex skin problems that
sususingonlyinputsacquiredbyMINT.Thiscanbewrit-
can require views from different perspectives.
ten as:
• Develop an algorithm for active tabular data acquisi- performancewith performancewith
tion conditioned on high-dimensional image data. maxinput acquiredinput
• Evaluate our approach using a real-world dermatol- O :E [∥L(f ,X ,y ) − L(f ,Xˆ,y )∥] (2)
2 i θ i i θ i i
ogydatasetandshowthatourapproachincreasesthe
where L(·) indicates the function to compute the perfor-
absolute number of users supplied with a correct di-
mance metric.
agnosisbyreducingtheuserdrop-offratewhilemain-
MINTcanbecalibratedbasedontwouse-cases. Task1
taining a high accuracy.
showninEq.3considersthesituationwheretheuserpro-
vides a tolerance ϵ on the permissible drop in model per-
2
2. Method formance(O ). Theacquiredinputsizeisthenmaximally
2
reduced (O ) while keeping the performance drop below
1
2.1. Problem Formulation
ϵ . Task 2 shown in Eq. 4 considers a situation where
2
Let us consider a multi-modal and multi-view dataset the user specifies a required average reduction in acquired
D = {(X ,y ),...,(X ,y )} with N samples, where the inputs ϵ . MINT then minimises the reduction in model
1 1 N N 1
input X = {I ,...,I ,m ,...,m }i represents a set of performance O .
i 1 j 1 k 2
multi-modalinputsconsistingofj imagesI ={I ,...,I }
i 1 j
and k tabular metadata M = {m ,...,m }, and y in-
i 1 k
dicates the class label. Let f (·) be a multi-modal ML permissibleperformancedrop
θ
model, withweightsθ whichlearnstopredictclassy from
Task 1: max(O ) with O ≤ ϵ (3)
an input set X, i.e. f :X →y. 1 2 2
θ
Inthisarticle,weproposetheMINTframework. MINT Task 2: min(O ) with O ≥ ϵ (4)
2 1 1
wraps around a trained model f (·) and makes it interac-
θ
tive in nature. The wrapping process involves introducing desirednumberof
whithheldinputs
32.2. Multi-modal classification model data, and to decide whether to actually acquire that piece
In this article, we focus on the application of classi- ofinformationbasedonitsvalueestimateandathreshold
fication of dermatological conditions. We use a multi- (see Algorithm 2).
view, multi-modal model for the task, conceptualised as
f : X → y. Such multi-modal models are commonly Algorithm 1 MINT Interactive input process
θ
decomposed into an image embedding model (g(·)), and 1: X ← Permissible set of inputs ▷ user specified
a metadata embedding, fusion and classification model 2: Xˆ ←∅ ▷ input acquired by MINT
(h(·)), such that f θ(X i)=h(g(I i),M i). While this is the 3: f θ(·)← classifier model
most common type of model in use by medical AI prac- 4: d←0 ▷ value of next action
titioners, this architecture is not a requirement for MINT 5: Xˆ ←Xˆ∪I 1 ▷ start interaction; (random) first image
to work. More details about the model training process 6: while d≥0and|Xˆ|<|X| do
can be found in Appendix Appendix B.1. Details of the 7: d←[0] 1×|X\Xˆ| ▷ value vector
model are provided below.
8: for x in X\Xˆ do ▷ loop over remaining inputs
Multi-image embedding: We use a wide ResNet-
BiT 101 × 3 pre-trained on ImageNet-21k (Kolesnikov
9: d[x]← EstimateValue(Xˆ, x, f θ(·))
10: end for
et al., 2020), as the feature extractor g(·). For all images
for a case {I ,...,I }, we estimate an image embedding
11: x next,d← argmax(d), max(d)
{v ,...,v } 1 where ej ach v ∈ R6044. We average-pool the 12: Xˆ ←Xˆ∪Answer(x next) ▷ next input acquired
1 j j 13: end while
availableimageembeddingsforeachcasetogetacase-level
image embedding: vˆ = E[{v ,...,v }], where vˆ ∈ R6044. 14: return f θ(Xˆ) ▷ final prediction
1 j
This average-pooling ensures the model is agnostic to the
number of input images. In brief, we assign the predictive distribution change
Structured metadata embedding: In medical classi- with a particular input information as its value, and try
fier models metadata is often collected as an input vector to estimate it. Depending on the type of input (image or
alongside images. These data consist of either scalar in- metadata),weproposetwodifferentstrategiestoestimate
puts(patientage)representedasR1, orcategoricalinputs the value of acquiring additional input. For details, see
in a multidimensional binary representation as Bc, where Sections 2.3.1 and 2.3.2.
c is the number of possible answers for a given multi- MINT’salgorithm2hasseveralhyperparameters,which
categorical input, including an option of unknown. For we tune using a validation set. First, the metric D used
example,aquestionsuchas‘Doyouhavefever?’,withan- to calculate the distance between p current and p new. We
swers Yes/ No/ Unknown is a B3 vector, while a question compare (i) Kullback-Leibler (KL) divergence, (ii) Jensen
aboutFitzpatrickskintypeisaB7vector(scaleof1-6with Shannon(JS)distance,and(iii)Absolutedifferenceinpre-
an unknown option). For patient age, we use the median dictiveentropy. Secondarethethresholdsforselectingad-
age in our training data as a place-holder for Unknown. ditionalimagesormetadata,T {I,M},whichwesetbyfirst
In this article, answers to the 25 metadata questions selecting appropriate reductions in performance η {1,2} in
(including age) in M are encoded in this way and con- Equations3and4andfindingthresholdvaluesthatsatisfy
catenated, resulting in a vector m∈R1 + B100. the objectives. Lastly, a statistical model f ζ(·) is required
Multi-modalfusionandClassificationhead: Inthis to estimate the value of different images. We describe the
part,wefirstcombinethecase-levelembeddingsofimages development of this model in the next section.
vˆ andmetadatamusingafusionstrategy,thenpassthem
to a classifier head. We compare two fusion methods as 2.3.1. Interactive image acquisition
choices for combining multi-modal information: feature- The vast majority of information for predicting derma-
wise linear modulation (FiLM, see Perez et al., 2018) and tological conditions lies in the image(s) (Liu et al., 2020).
concatenation with case-level embedding. Our proposed Thus, we start the interactive acquisition process using
framework is agnostic to the choice of fusion strategy. MINT with images. Note that this is not a requirement.
The classifier head is a two-layer MLP with hidden size We pose the interactive image acquisition process as a 3-
1024 and output size 288 (number of classes), which after way decision making task: (i) input a near-shot (NS) im-
softmax yields the class probabilities. age, (ii) input a far-shot (FS) image, and (iii) no more
images required. We repeatedly decide to either ask the
2.3. Interactive input process using MINT user for additional images (NS/ FS), or stop and continue
MINT (Make your model INTeractive) is a light-weight to the next stage of the workflow. NS/ FS serve as in-
scalablewrapperaroundanypre-trainedmulti-modalclas- structions to the user when taking the images, such as
sifier to make its input acquisition process interactive. In whether a skin photograph should be taken from close-up
Algorithm 1, we show the interactive input process for or further away respectively. We train a supervised sta-
MINT. tistical model f (·) to accomplish this task. We pose the
ζ
Across both domains of input, we apply a simple strat- learning task as a regression task predicting the value of
egy: to estimate the prospective value of a new piece of an additional image, given all past image acquired. For
4Algorithm 2 EstimateValue function f (·)
MINT
1: I ←Permissible image types 13: else if x∈M cat∪M real then ▷ metadata
2: M cat ← Permissible categorical metadata 14: v←[·] ▷ value vector
3: M real ← Permissible real-valued metadata 15: if x∈M cat then
4: D ← Distance metric to estimate value. 16: for possible values x n of x do
5: T I ← threshold for image value 17: p new ←f θ(Xˆ∪x n)
6: T M ← threshold for metadata value 18: Append D(p current,p new) to v
7: f θ(·)← classifier model 19: end for
8: f ζ(·)← estimator for value of image types 20: else if x∈M real then
9: procedure EstimateValue( 21: for percentiles P 10%,P 50%,P 90% of x do
Xˆ: current inputs, 22: p new ←f θ(Xˆ∪P of x)
x: prospective input, 23: Append D(p current,p new) to v
f θ(·): diagnostic model) 24: end for
10: p current ←f θ(Xˆ) ▷ current predictions 25: end if
11: if x∈I then ▷ images 26: return E(v)−T M
12: return f ζ(Xˆ,p current,x)−T I 27: end if
28: end procedure
a given case, let us assume the model has already pro- preference (Task 1 or Task 2) as discussed in Sec. 2.1.
vided N images {I ,...,I }. At the (N +1)th interac- During evaluation, at each stage of interaction, we make
i N
tion f ({I ,...,I },NS/ FS) will provide the value of ac- two decisions. Firstly, the model decides whether an ad-
ζ i N
quiring the corresponding image. Based on the predicted ditional image will improve model prediction. Secondly, if
value, the next recommended action is asked of the user, anadditionalimageisneeded, themodelneedstoprovide
includingnotaskingforfurtherimagesifthevalueisbelow instructions to the user on whether a near-shot (NS) or a
threshold T . far-shot (FS) image is needed. For this we estimate the
I
Model Training: We train f (·) using the valida- value of both a NS and a FS next image at every stage of
ζ
tion split (on which the base multi-modal model was not the interaction as
trained). We split this in two sets to 75% train and 25%
tune sets. For each case X , every image I is a associ-
ated with a view-label Ij i ∈ B2, indicatingj if it’s near- Valuej N→ Sj+1 =f ζ(zj→j+1(I vj i+ ew1 =NS)) (7)
view
shot or far-shot. For each case, every subset with size Valuej→j+1 =f (zj→j+1(Ij+1 =FS)) (8)
FS ζ view
greaterthanonefromthesetofavailableimagescanserve
Using these values, we average them to estimate the
as a data-point for model training. Each subset of size
(j +1) can serve as a data-point for jth interaction, i.e. value of any additional image
{I 1,...,I j} → I j+1. We use the classifier model to esti- Valuej→j+1 =E[{Valuej→j+1,Valuej→j+1}]. (9)
mate the predictions p and p before and after the NS FS
1:j 1:j+1
interaction. Using the ground-truth label y, we define the Following this, we decide if another image is needed:
valueofthejth interactionasthechangeinpredictivedis-
tance from the label before and after the interaction, i.e.
Valuej→j+1 ≤T →Early stopping, (10)
I
Valuej→j+1 =D(p ,y)−D(p ,y). (5)
1:j 1:j+1 Valuej→j+1 >T →Take another image. (11)
I
As an input for this jth interaction zj can be set as,
Ifanotherimageisneeded,wedecideonitsinstruction/
zj→j+1 =concat[vˆ ;p ;Ij ;Ij+1]. (6) view label as
1:j 1:j view view
Foreachcase,wecangeneratemultipledata-pointscor- Valuej→j+1 ≥Valuej→j+1 →Take NS image, (12)
NS FS
responding to different types of transitions. We construct Valuej→j+1 <Valuej→j+1 →Take FS image. (13)
NS FS
a dataset for a regression task by creating data-points for
different cases in the validation set, which is used to train Note that the start of the interactive process is by pro-
f (·). As a choice of model, we use a Random Forest re- viding a random image.
ζ
gressor (Breiman, 2001) for our task. Note that this is a We compare our model based approach to a model
design choice and may vary for different applications. confidence based interactive baseline. As a measure of
Model tuning and evaluation: We can tune the model confidence we use max of softmax (MSP) as a sig-
value threshold T on the tune sub-set based on input nal (Hendrycks and Gimpel, 2016). We use the MSP of
I
5thecurrentpredictionMSP(p )asthevaluefornextim- the whole validation set, i.e. the best possible se-
1:j
age Valuej→j+1. We set T on the tune set. We compare quence of questions for the whole validation set on
I
MINT against this confidence based approach in Sec. 4.1. average.
Note that, for each case in our dataset, we have dif-
ferent numbers of available images and varying NS and 2.4. Real-world cost of acquiring information
FS images. For our simulation experiments we set some
One of the key aims of MINT is to reduce user bur-
boundary conditions. For a case with available j images,
den. User burden isacomplexconcept. Inmedicalcarein
if MINT asked for another image at the jth interaction,
particular, burdencanstemfromtheuser’sfeelingsabout
early stopping was triggered due to unavailability. Also,
theircaremoregenerally, theneedtoseekcareinthefirst
at any stage of the interaction, if MINT asks for a FS/
place, and the implications of a diagnosis. In this paper,
NS image and no unused image with that view label is
we focus on the burden of asking unnecessary and possi-
available,werandomlyprovideMINTwithanyremaining
bly invasive questions during the process of developing a
unused image.
differential diagnosis.
Specifically, we focus the proportion of users who drop
2.3.2. Interactive tabular metadata acquisition off the submission flow of a non-diagnostic dermatology
InAlgorithm1, weshowhowourMINTframeworkcan AI system (LLC, 2022), i.e. do not complete a submis-
interactively figure out the best metadata question to ac- sion. While a user may drop off the submission flow for a
quire and update the model predictions in a step-by-step variety of reasons, we are motivated to mitigate drop-off
process. by reducing the number of irrelevant questions.
At any stage of the metadata interactive process, we The system requires users to submit 3 images, and asks
sweepoverallunansweredmetadataquestions(X\Xˆ)and userstocompleteallmetadataquestionsmodelledin2.3.2.
estimate the expected value each of them would provide The user is free to skip any of these. The 25 metadata
to the underlying model. We select the metadata that questions modelled are grouped into 6 separate screens.
provides the highest value (x ). We then ask the user Metrics from this system report how many users reach
next
to provide the answer, and update the model predictions. which screen, including the final Results screen. We esti-
We describe the process of value estimation in Algo- mate the user burden of requesting an image, or asking a
rithm 2. As metadata input is structured, all possible particularquestion,astheproportionofuserswhodropoff
answers for a given question x can be enumerated (i.e. thesubmissionflowatthescreenonwhichtheinformation
n
{x1,...xd}). We can modify the metadata embedding by is requested.
n n
considering all possible answers and estimating predictive Inordertoestimatethereductionindrop-offratesusing
probabilities {p1 ,...,pd }, where p1 =f (Xˆ∪x1). MINT, we simulate cases in our evaluation set as passing
xn xn xn θ n
We define the value of a metadata t with an answer t1 throughthesubmissionflow. Ifanimageorpieceofmeta-
i i
asD(p ,p1). Wethevalueforthemetadatax asthe data x is requested by MINT, we randomly drop cases
current i n
expected value for all possible answers, i.e. fromtheflowwithprobabilitypdrop,i.e. theproportionof
x
cases that drop off on the screen this question appears on,
as estimated using the system’s metrics. Note that as we
Value =E[{D(p ,p1 ),...,D(p ,pd )}] (14) only have these metrics at a screen level, if multiple ques-
ti current xn current xn
tions that appear on the same screen are asked, we apply
At the end of an interactive step, the output can be pdrop only once. We do this simulation 1000 times, and
x
either the next most informative question to ask to the compare the proportion of cases estimated to be dropped
user or to inform the user that no more input is needed using MINT with the proportion of cases estimated to be
and show the final prediction (see Algorithm 1). We refer dropped if all information is requested.
to this feature as early stopping. Early stopping is trig- This is an imperfect estimate of the true reduction in
gered when the value of the next best question is below user drop-off, as it makes several assumptions: (1) that
the threshold T M. We set the value of T using the tune pdrop is independent, (2) that the sequencing of metadata
X
subset of the validation set, by optimising Equations 3 or questionshasnoimpact,and(3)thatthepdrop forimages
4. isequallydistributedacrossthethreeimagesrequestedby
We compare our proposed interactive approach against the system, which only reports metrics for image submis-
two baselines: sion as a whole.
• Random baseline: In this baseline for each case we
acquire the metadata answer in a random sequence 3. Data description and experimental setup
andreporttheaverageperformancemetricscomputed
over multiple trials. In this article, we use the de-identified dataset used
in (Liu et al., 2020) for model development. Cases in this
• Global sequence: We estimate a static sequence of datasetwerecollectedfrom17differentsitesacrossCalifor-
metadata questions which optimises performance for nia and Hawaii. The dataset consists of 17454 cases, with
6the ground truth generated by aggregating the diagnoses
1000
frommultipleboardcertifieddermatologists. Thedetailed Method
annotation process is presented in (Liu et al., 2020). Note MINT (Image)
800
thatforsimplicity,weremovedthecasesthathadmultiple MINT (Image w/ Instruction)
conditions or that had multiple primary diagnoses in the MSP
600
groundtruth. Theunderlyingmodelwastrainedon12335
cases. Weuse3020casesasvalidationsetandreportper-
formance on a test set with 2099 cases. We maintain a 400
patient-level separation between the training, validation
andtestsets. Eachcaseinthedatasetconsistsofmultiple 200
RGB images. The images were captured by either medi-
cal assistants or nurse practitioners using consumer-grade 0
1.0 2.0 3.0 4.0 5.0 6.0 8.0+
digital cameras. The number of images captured and the
Num Images used
type of images (near-shot/ far-shot etc) per case were de-
cided by the clinician. The images exhibit a large amount Figure2: HistogramofimagesusedbyMINT.
of variation in terms of affected anatomic location, back-
ground objects, resolution, perspective and lighting. All
images had adequate image quality to be deemed usable
global baseline. We report the results on the test set and
by healthcare professionals.
methodswerecalibrated(ifrequired)onthevalidationset.
Alongside images the dataset contains 25 pre-defined
pieces of metadata information about the cases which in-
clude patient demographics, symptoms, and medical his-
tory. During the labelling process the dermatologists had 4.2.1. Effect of divergence metric for value estimation
access to all the captured images alongside all the meta-
In this section we present the results for interactive
data information.
metadata in Fig. 3. We show MINT with three differ-
ent divergence metrics for value estimation, i.e. (i) KL
4. Experimental Results divergence, (ii) JS divergence and (iii) absolute difference
in predictive entropy as mentioned in Sec. 2.3.
For model performance we report Top-3 accuracy. For
InFig.3(left),weshowtheresultswhenweusethedif-
demonstrating the efficacy of MINT, we show the reduc-
ferentdivergencemetricstore-orderthesequenceinwhich
tion of inputs required to maintain certain performance
metadata inputs are acquired from one case to another.
metrics. This is reported in 2 ways for both images and
Random baseline simulates the situation where metadata
metadata questions: (1) average number of inputs versus
inputsareacquiredfromdifferentcasesinarandomorder.
performance achieved and (2) Histogram of input counts
Global baseline estimates a static sequence of metadata
over all cases.
inputs which provides the highest boost on the validation
set, and metadata input for all the test cases are acquired
4.1. Interactive image acquisition
in that static order.
We first report MINT performance on the multi-view
Firstly, we observe that the tabular metadata informa-
interactive image acquisition process.
tion provides a 7 points boost in Top-3 accuracy to the
The trained model, predicting whether to request an
model. For all the methods, we observe a steady increase
additional image or to stop collecting images, achieves a
inperformancewithmoreinteractions/metadatainforma-
reduction of 27.9% of images requested, at a difference of
tion. Forthefirst10interactionsalltheacquisitionmeth-
−0.9pp in top-3 accuracy. When additionally predicting
ods provide a similar boost in performance. Beyond that,
the near/far instruction for the next image it achieves re-
we observe that KL divergence and JS divergence provide
duction of 36.2% of images requested, at a difference of
a significantly greater boost in Top-3 accuracy compared
−1.1pp in top-3 accuracy (see Table 1).
to the random and global baselines. MINT with absolute
The histogram in Figure 2 shows the number of images
differenceinentropyasthemetricisbetterthanthebase-
requested for cases in the test set.
lines but worse than the other metrics. It must be noted
thatthechoiceofmetricfunctionisahyper-parameterfor
4.2. Interactive tabular metadata acquisition
MINTandshouldbechosenseparatelyfordifferentappli-
In this section, we demonstrate the results of using cations. Also,re-orderingthesequenceofmetadatainputs
MINT for interactive acquisition of tabular metadata in- using MINT is an unsupervised approach and doesn’t re-
puts. For these experiments, we use a model which com- quire a validation set for calibration. Among all the ap-
bines the image and metadata using a FiLM layer (Perez proaches reported, only global baseline leverages the val-
et al., 2018). We show MINT results using three different idation set to estimate the optimal sequence of metadata
methods of value estimation along with a random and a inputs.
7
sesac
muNTable1: ResultsofbaselinesandourMINTmodelusingtheJSdivergencedistancemetric.
Experiment Top 3 accuracy Avg. images used Median num.
(%) (% reduction) metadata used
All image 56.1 4.37(−) 0
All image + metadata 63.1 4.37(−) 25
MSP based ES 55.1±0.2 3.4(21.89) 0
MINT (Image) 55.2±0.2 3.15(27.86) 0
MINT (Image w/ instruction) 55.0±0.3 2.79(36.16) 0
MINT (Image + metadata) 61.2±0.2 3.15(27.86) 8
MINT (Image w/ instruction + metadata) 59.5±0.3 2.79(36.16) 4
600
KL Div
JS Div
500
0.62 Entropy Diff 0.62
Random Baseline
400
Global Baseline
0.60 0.60
300
0.58 0.58 KL Div + ES1 200
KL Div + ES2
JS Div + ES1 100
0.56 JS Div + ES2
0.56
0
0 5 10 15 20 25 0 5 10 15 20 25 0 5 10 15 20 25
Median interactions with early stopping
Number of interactions
Figure 3: MINT for structured metadata. Left: Top-3 accuracy vs. number of interactions for different divergence metrics and baselines.
Middle: Performanceandaveragenumberofrequestedpiecesofinformationfortwovariantsofearlystopping,usingthetwobest-performing
divergencemetrics. Weincludethelinesfromtheleftfigureforillustrationpurposes. Right: HistogramofnumberofinteractionsusingJS
divergence+ES1.
4.2.2. Effect of Early stopping tempting to match Top-3 accuracy early stopping leads
to significantly fewer interactions required from the user.
In this section, we investigate the effectiveness of early-
This holds for MINT with both KL and JS divergences.
stoppingwedescribedinSec.2.3.2. Wepresenttheresults
Comparing Tasks 1 and 2, we observe that MINT using
in Fig. 3 (middle). We limit the results to only the best
JS attains slightly better performance than KL as shown
performing methods: MINT with KL (in red) and JS (in
in Fig. 3 (middle).
blue) divergences. For both the methods, we show two
In Fig. 3 (right), we show the histogram of number of
different strategies for operating point selection for early
metadata inputs collected over the test set, corresponding
stopping, satisfying equations 3 and 4 respectively:
to MINT with JS Divergence, calibrated with ES1. We
Task 1: Denoted by a ⋆ in the plot. In this setup, we se-
observe a significant number of cases using only 2-3 in-
lectthevalueofanearlystoppingthresholdT,bydefining
teractions with MINT in contrast to all 25, reflecting its
a tolerance on reduction of Top-3 accuracy. Within a per-
efficacy in reducing the burden in input acquisition.
missible reduction, we choose T to provide the minimum
number of median interactions in validation set.
4.2.3. Understanding MINT behavior
Task 2: Denoted by a + in the plot. In this setup, we To further understand when and how MINT can save
select an operating point (value of threshold T) based on interaction steps, we look at the relationship between the
a user-defined budget on number of interactions. On the characteristics of a particular case and the number of in-
validationset,foragivenvalueofmedianinteraction(here teractions required when using MINT.
3), we select a threshold which provides the best Top-3 First, we look at the score (summed votes from the
accuracy. dermatologist panel) of the ground truth diagnosis after
Firstly, compared to choosing a single fixed number of multi-rater aggregation (for details on this aggregation,
interactions for every user, early stopping is more flexi- see Liu et al., 2020). More difficult cases should result in
ble, leading to increased performance at the same average higher clinician disagreement and therefore a lower score
number of interactions across users. Secondly, when at- of the diagnosis. We find a small correlation between case
8
ycarucca
3-poT
sesac
fo
rebmuNWe also estimate the proportion of users who would be
0.55
shown a correct result, defined as cases in which the true
diagnosis is in the model’s top 3 predictions, and which
0.50
didnotdropoffthesimulatedsubmissionflow. Thisanal-
ysis, shown in Figure 5b, reveals that even though perfor-
0.45 mance on the validation set reduces slightly with MINT,
useroutcomesmayinfactimprovebyenablingmoreusers
tocompletethesubmissionflowandreachtheresultspage.
0.40
Wefurtheranalysetheburdenplacedonusersbyassign-
ing each piece of information an empirical cost: its con-
0.35 tribution to user drop-off. We compare the cost incurred
by MINT and the cost incurred if all data was acquired in
Figure 5c. The graph highlights that the cost placed on
0.30
users is bimodal under MINT, echoing the results shown
0 5 10 15 20 25
in Figures 2 and 3.
Number of interactions used
Figure 4: The relationship between the number of interactions re- 5. Discussion
quested by MINT, and the difficulty of the case as defined by dis-
agreementbetweendermatologists. Showninblackisalinearregres- 5.1. Dynamic feature selection at inference time with
sion(Spearman’sρ=0.11,p=7.4×10−54).
equivalent performance
Weproposeandevaluateamethodforactivefeatureac-
quisitioninthemulti-view,multi-modalsettingcommonly
difficulty (1−diagnosis score) and the number of interac-
observed in medicine. We demonstrate reduced user bur-
tions (Spearman’s ρ = 0.11, p = 7.4×10−54). For cases
denwithapproximatelyequivalentperformancebyperson-
for which there is more disagreement between clinicians,
alising the inputs to each user. We also show that trading
MINT asks for more information.
off user burden with performance can and should be con-
We also look at MINT’s behaviour broken down by
sidered by practitioners. While this is often done before
ground truth class. Since the number of classes is large,
training AI systems, we recommend to instead do so at
we focus on a grouping of classes into risk severity lev-
inference time using MINT.
els: Low, Medium and High (for a full definition, see Roy
Weshowthatinacasetypicalofmedicalmachinelearn-
et al., 2022). We find that MINT requests more informa-
ing, we can reduce the number of inputs required from a
tion for Medium, and even more for High cases (using a
user by over a third, while maintaining predictive accu-
3x1 ANOVA; F =89.8, p=1.5×10−39).
racy within a few percentage points. Compared to setting
We also strive to understand whether MINT asks more
a fixed number of inputs for every user, personalising the
relevantquestionsbasedonthecategoryofskincondition,
inputs each user allows the system to ask for drastically
suchasInfectiouseruption,Benignneoplasm,orMetabolic
less information in most cases (see Figures 3 and 2).
eruption. We compare the frequencies of each metadata
question for a given category of skin diseases with the fre-
5.2. Simplicity of MINT as a wrapper model
quencyofthequestionforthepopulationasawholeusing
OneimportantaspectofMINTisitssimplicityandgen-
aχ2 test. WefindthatafterBonferronicorrection, 17out
eralisability. It is agnostic to the underlying diagnostic
of the 26 categories are asked significantly distinct ques-
model, and has few parameters. This means that MINT
tions at an alpha level of 0.001.
can be tuned post-hoc, on a dataset independent of the
diagnostic model’s training set, and using limited data.
4.3. Real-world burden of acquiring information Wedeliberatelychooseasmallmodelforimagevaluepre-
diction, and use no parameters other than thresholds for
UsingMINT,wedeterminehowmanyimagesandwhich metadata value prediction.
questions are acquired for each case in our evaluation set. This simplicity makes MINT suitable for many other
We simulate whether these cases would have successfully medical applications, and enables practitioners in medical
completedarealdermatologyAIapplication(LLC,2022), AI to tune MINT parameters separately for a new setting
using metrics from real users submitting their case to the theywouldliketodeployitin. ItalsomeansthatMINTis
system. more interpretable than comparable approaches that use
This provides an estimate of the real-world impact reinforcementlearning(RL).Bydirectlyestimatingapiece
of MINT. Of the cases in our evaluation dataset, 4.6% of information’s impact on the predictive distribution, the
(3.9–4.4%) would likely drop off when all information is usercanbegiventhepurposeofanewpieceofinformation
required. When MINT is used to interactively acquire the requested by the system. For example, the user could be
information, 3.1% (2.9– 3.3%) would likely drop off (see told that their age is being asked because it may narrow
Figure 5a. down the differential diagnosis from 5 to 3 diseases.
9
ytluciffiD
esaC25
0
0.06 MINT MINT
No MINT 0.06 No MINT 0.25
0.04 0.20
0.04
0.15
0.02 0.02 0.10
0.05
0.00 0.00
3.0 3.5 4.0 4.5 56.5 57.0 57.5 0.00
User dropout rate (%) Rate of positive outcomes (%) 0.00 0.05 co0 s.1 t 0 use0 d.1 b5 y M0 I. N20 T 0.25 0 Den1 s0 ity
(a) (b) (c)
Figure 5: Simulated user outcomes. (a) The estimated proportion in users who do not complete the submission flow, with and without
MINT.WithMINT,weestimatethedrop-offratetobesignificantlylower. (b)Theestimatedproportionofuserswhoseeacorrectresult,
i.e. whocompletethesubmissionflowandforwhichthediagnosisisinthetop3predictions. WithMINT,significantlymoreusersseecorrect
predictions. (c)CostanalysisusingMINT.Contour-linesanddensityplotswerederivedusingkerneldensityestimates.
5.3. Easy and difficult cases in MINT Case3showsadifficultcasewherethemodelmakesthe
WebelievethatonekeyadvantageofMINTisthatitis incorrectpredictionbothwithandwithoutMINT(721out
able to stop early when the model does not benefit from of 2091 cases in test set). The patient has ‘Hemangioma’
furtherinformation,i.e. whenacaseisclearlydiagnosable asitsprimarydiagnosis. HerealsoMINTusessignificantly
using the information available already. One measure of lessinputs(1outof6images,3outof25metadata). Note
the ease of diagnosis is clinician agreement. As our data from the images that this is indeed a very difficult case as
was labelled by multiple clinicians (Liu et al., 2020), we therearefrecklespresentnearthemoleinnear-shotimages
can use agreement between clinicians as a metric of how and the mole is small and hard to see in far-shot images.
unambiguous a case is. Cases for which there was less Case 4 demonstrates a failure case where the model
agreementsawsignificantlylessinformationrequested. So, makes the correct prediction without MINT but an incor-
whenacaseisclearer,MINTdiagnosesfaster(usingfewer rect one when using MINT (138 out of 2091 cases in the
interactions). test set). The case has ‘Stasis Dermatitis’ as the primary
We also see MINT asking more questions for high-risk diagnosis. HerealsoMINTusessignificantlylessinputs(1
compared to low-risk conditions. While this seems desir- out of 6 images, 1 out of 25 metadata) while being unsuc-
able, it is also surprising, since we did not optimise for cessful. This may be because the condition is less evident
harm reduction. It may be explained by two factors: that in the image used by MINT.
there are more cases of low-risk conditions in the training
data (see A.3), or that clinician agreement (see above) is 5.5. Thetrade-offbetweenperformanceandpatientburden
lower for high-risk conditions. While MINT is flexible and in theory is able to request
the upper limit of inputs for a difficult case, there are fail-
5.4. Qualitative analysis of MINT ure cases. These cases - cases which the diagnostic model
We present some qualitative results using MINT in predicts correctly with all inputs but where MINT fails to
Fig.6. WecontrasttheMINTresultsagainstourbaseline ask all questions - lead to a drop in performance. This
ofusingallinputsandselect4randomcasesfordiscussion. means that for practitioners, there is a trade-off between
Case 1 shows a case where the model makes the cor- reducing user burden and diagnostic accuracy. Since tun-
rect prediction with and without MINT (1190 out of 2091 ingthistrade-offwithMINTisrelativelysimple(choosing
cases in the test set). The case has ‘Melanoma’, a high- a threshold value using a validation set), it is suitable for
risk condition as the diagnosis. MINT uses significantly individualised tuning by practitioners based on use case
less inputs (1 of 3 images and only 6 out of 25 metadata) requirements.
information for making the correct prediction. We believe that a key determining factor in this trade
Case2showsaninterestingcasewherethemodelmakes off is the rate of users with a completion of the full user
the correct prediction with MINT but an incorrect one flowandseeingcorrectresults. Whileduringdevelopment,
without MINT (50 out of 2091 cases in the test set). The models may appear to be performing slightly worse with
case has ‘Folliculitis’ as its primary diagnosis. MINT uses fewer inputs, a lower rate of user dropout due to fewer
significantly less inputs (1 of 6 images and only 5 out of questions means more users will successfully complete the
25 metadata) information for making the correct predic- submission flow and receive accurate results. When simu-
tion. Using too many inputs caused the model to make latingpatientoutcomesusingreal-worlddrop-offrates,we
the wrong prediction. We believe this is due to noise in actuallyseeanincreaseinpositiveuseroutcomes(seeFig-
certain inputs which MINT can ignore. ure5b). Thisisdespiteasmallreductionintop3accuracy
10
noitalumis
ni
noitroporP
stupni
elbaliava
lla fo
tsoc
ytisneDCase 1. Ground truth: Melanoma Case 2. Ground truth: Folliculitis
MINT Without MINT MINT Without MINT
Images used - 1 out of 3 Images used - 3 out of 3 Images used - 1 out of 6 Images used - 6 out of 6
6/25 Metadata Q acquired 25 / 25 Metadata Q acquired. 3/25 Metadata Q acquired 25 / 25 Metadata Q acquired.
Age Gender History of Skin problem
Bleeding Burning psoriasis resemblance
Shortness Painful Age
of breath
Top-3 Agreement: Yes ✅ Top-3 Agreement: Yes ✅ Top-3 Agreement: Yes ✅ Top-3 Agreement: No ❌
Case 3. Ground truth: Hemangioma Case 4. Ground truth: Stasis Dermatitis
MINT Without MINT MINT Without MINT
Images used - 1 out of 6 Images used - 6 out of 6 Images used - 1 out of 6 Images used - 6 out of 6
5/25 Metadata Q acquired 25 / 25 Metadata Q acquired. 1/25 Metadata Q acquired 25/25 Metadata Q acquired.
Age Chills Age
Joint pain Concerning
Shortness appearance
of breath
Top-3 Agreement: No ❌ Top-3 Agreement: No ❌ Top-3 Agreement: No ❌ Top-3 Agreement: Yes ✅
Figure6: QualitativeAnalysisofresults. FourexamplesofcasesinwhichprocessingwithandwithoutMINTleadtothesamecorrectresult
(left), MINTperformingbetter(second), MINTandthemodelwithallinputsbothfail(third), andMINTfailingwhilethemodelwithall
inputsucceeds.
withMINT,andisdrivenbytheincreasedcompletionrate 5.7. Limitations and future work
of users.
One of the key limitations of MINT is that it is limited
by the underlying diagnostic model. This manifests itself
5.6. User trust and the relevance of questions
in the prediction of relevant questions. If the underlying
One important issue in medical AI systems is the ques- diagnosticmodeldoesnotadequatelyintegratestructured
tion of trust. Trust in an application is a multifaceted questions in its predictions, then predicting which ques-
concept, and can include trust that only relevant data are tions are valuable will also be noisy.
collected, or trust that the system performs as advertised. The underlying diagnostic model also limits MINT in
Both of these trust domains are affected by the number the types of interactions it can choose. Diagnostic image
and types of questions an AI system asks. and metadata models are still widespread in medical AI
By asking fewer questions and ensuring those asked are practice, but may be replaced by large foundation models
personalised based on the skin condition, we believe that in the future. In particular, by leveraging natural lan-
weareabletoimprovetrustinbothdomains. Fewerques- guage,largelanguagemodelsaremoreflexiblebothinthe
tionsandimages,alongsidemoretargetedquestionsreduce types of questions they can ask, and in the breadth of an-
the likelihood that a question is seen as intrusive or irrel- swersthatcanbeprovided. Whilethismaymakeformore
evant. For example, users looking for information about a efficient and flexible information exchanges, it could also
small rash may consider a question about cancer history introduce new risks such as asking questions that can be
to be of questionable relevance. seen as intrusive, as well as providing answers outside of
MINTenablestheAItopersonalisequestionstobespe- the intended scope. Future work will be needed to under-
cific to the condition a user is seeking information about, stand how best to use MINT on such flexible models.
which may engender more trust in the system in the real MINT also lacks long-term temporal modelling over
world. multiple turns of interactions, something which all greedy
11active feature acquisition methods lack. With larger and Aritra Ghosh and Andrew Lan. Difa: Differentiable feature acqui-
more diverse training sets, using reinforcement learning sition. Proceedings of the AAAI Conference on Artificial Intelli-
gence,37(6):7705–7713,Jun.2023.doi: 10.1609/aaai.v37i6.25934.
may prove better. These performance benfits of temporal
DanHendrycksandKevinGimpel. Abaselinefordetectingmisclas-
modelling will need to be balanced against the simplicity
sifiedandout-of-distributionexamplesinneuralnetworks. arXiv
and robustness of MINT. preprint arXiv:1610.02136,2016.
AlexanderKolesnikov,LucasBeyer,XiaohuaZhai,JoanPuigcerver,
JessicaYung,SylvainGelly,andNeilHoulsby. Bigtransfer(bit):
General visual representation learning. In Computer Vision–
6. Conclusion
ECCV 2020: 16th European Conference, Glasgow, UK, August
23–28, 2020, Proceedings, Part V 16, pages 491–507. Springer,
We present MINT, a powerful, practical approach to 2020.
makingmedicaldiagnosticmodelsinteractive. Wedemon- Jannik Kossen, Ca˘t˘alina Cangea, Eszter V´ertes, Andrew Jaegle,
VioricaPatraucean,IraKtena,NenadTomasev,andDanielleBel-
strateitsabilitytodrasticallysimplifythesubmissionflow
grave. Active acquisition for multimodal temporal data: A chal-
for a dermatology system, including the first demonstra-
lenging decision-making task. arXiv preprint arXiv:2211.05039,
tion of interactive acquisition of multi-image multi-modal 2022.
data. YangLiandJunierBOliva. Dynamicfeatureacquisitionwitharbi-
traryconditionalflows. arXiv preprint arXiv:2006.07701,2020.
Wedemonstratetheefficacyofthisapproachusingreal-
YangLi,SiyuanShan,QinLiu,andJunierBOliva. Towardsrobust
world user burden. By simulating user drop off from a activefeatureacquisition.arXivpreprintarXiv:2107.04163,2021.
dermatology AI system, we estimate that more patients Yuan Liu, Ayush Jain, Clara Eng, David H Way, Kang Lee, Peggy
receive a correct diagnosis with less acquired information. Bui, Kimberly Kanada, Guilherme de Oliveira Marinho, Jessica
Gallegos, Sara Gabriele, et al. A deep learning system for differ-
This is accomplished with minimal impact on model per-
entialdiagnosisofskindiseases. Naturemedicine,26(6):900–908,
formance, and highlights the importance of considering 2020.
user burden in AI system design. Google LLC. Identify skin conditions with dermassist, 2022. URL
https://health.google/consumers/dermassist/.
We show that MINT is simple to tune and can be con-
Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jos´e Miguel
figured to satisfy diverse use cases, allowing practitioners
Hern´andez-Lobato, SebastianNowozin, andChengZhang. Eddi:
to trade off user burden and model accuracy. Efficientdynamicdiscoveryofhigh-valueinformationwithpartial
vae. arXiv preprint arXiv:1809.11142,2018.
EthanPerez,FlorianStrub,HarmDeVries,VincentDumoulin,and
AaronCourville.Film: Visualreasoningwithageneralcondition-
References
ing layer. In Proceedings of the AAAI Conference on Artificial
Intelligence,volume32,2018.
Mohamed Akrout, Amir-massoud Farahmand, and Tory Jarmain. Abhijit Guha Roy, Jie Ren, Shekoofeh Azizi, Aaron Loh, Vivek
Improvingskinconditionclassificationwithaquestionanswering Natarajan, Basil Mustafa, Nick Pawlowski, Jan Freyberg, Yuan
model. arXiv preprint arXiv:1811.06165,2018. Liu, Zach Beaver, et al. Does your dermatology classifier know
Mohamed Akrout, Amir-massoud Farahmand, Tory Jarmain, and what it doesn’t know? detecting the long-tail of unseen condi-
Latif Abid. Improving skin condition classification with a visual tions. Medical Image Analysis,75:102274,2022.
symptomcheckertrainedusingreinforcementlearning.InMedical HajinShim,SungJuHwang,andEunhoYang. Jointactivefeature
ImageComputingandComputerAssistedIntervention–MICCAI acquisition and classification with variable-size set encoding. In
2019: 22nd International Conference, Shenzhen, China, October NeurIPS,pages1375–1385,2018.
13–17, 2019, Proceedings, Part IV 22, pages 549–557. Springer, Sara Zannone, Jos´e Miguel Hern´andez-Lobato, Cheng Zhang, and
2019. Konstantina Palla. Odin: Optimal discovery of high-value infor-
RuzenaBajcsy,YiannisAloimonos,andJohnKTsotsos. Revisiting mationusingmodel-baseddeepreinforcementlearning. InICML
activeperception. Autonomous Robots,42:177–196,2018. Real-world Sequential Decision Making Workshop,2019.
Gabriel Bernardino, Anders Jonsson, Filip Loncaric, Pablo-Miki Zhiqiang Zheng and Balaji Padmanabhan. On active learning for
Mart´ı Castellote, Marta Sitges, Patrick Clarysse, and Nicolas dataacquisition.In2002IEEEInternationalConferenceonData
Duchateau. Reinforcement learning for active modality selection Mining, 2002. Proceedings.,pages562–569.IEEE,2002.
during diagnosis. In International Conference on Medical Image
Computing and Computer-Assisted Intervention, pages 592–601.
Springer,2022.
LeoBreiman. Randomforests. Machine learning,45:5–32,2001.
Kushal Chauhan, Rishabh Tiwari, Jan Freyberg, Pradeep Shenoy,
and Krishnamurthy Dvijotham. Interactive concept bottleneck
models. arXiv preprint arXiv:2212.07430,2022.
YuxinChen,S.HamedHassani,AminKarbasi,andAndreasKrause.
Sequential information maximization: When is greedy near-
optimal? In Peter Gru¨nwald, Elad Hazan, and Satyen Kale, ed-
itors, Proceedings of The 28th Conference on Learning Theory,
volume 40 of Proceedings of Machine Learning Research, pages
338–363,Paris,France,03–06Jul2015.PMLR.
IanConnickCovert,WeiQiu,MingyuLu,NaYoonKim,NathanJ
White,andSu-InLee. Learningtomaximizemutualinformation
for dynamic feature selection. In International Conference on
Machine Learning,pages6424–6447.PMLR,2023.
Gabriel Erion, Joseph D Janizek, Carly Hudelson, Richard B Utar-
nachitt, Andrew M McCoy, Michael R Sayre, Nathan J White,
and Su-In Lee. Coai: Cost-aware artificial intelligence for health
care. Nature biomedical engineering,6(12):1384,2022.
12Appendix A. Dataset
Appendix A.1. Full list of Metadata Questions
Question Options
Age scalar value
Gender F / M / Unspecified / Prefer not to say / Other
Skin type Fitzpatrick skin type 1-7
Is the appearance concerning? Yes / No / Unknown
Is it bleeding? Yes / No / Unknown
Is it burning? Yes / No / Unknown
Are you experiencing chills? Yes / No / Unknown
Are you experiencing fatigue? Yes / No / Unknown
Are you experiencing fever? Yes / No / Unknown
Are you experiencing joint pain? Yes / No / Unknown
Are you experiencing joint pain? Yes / No / Unknown
Are you experiencing mouth sores? Yes / No / Unknown
Are you experiencing shortness of breath? Yes / No / Unknown
No symptoms other than what can be seen? Yes / No / Unknown
Is it itchy? Yes / No / Unknown
Is it getting darker? Yes / No / Unknown
Is it getting larger? Yes / No / Unknown
Is it painful? Yes / No / Unknown
Do you have a history of eczema? Yes / No / Unknown
Do you have a history of psoriasis? Yes / No / Unknown
Do you have a history of melanoma? Yes / No / Unknown
Do you have a history of skin cancer? Yes / No / Unknown
Which body part is the skin problem on? Select any of 12 body parts
What best describes your skin issue? Acne; Growth or mole; Hair loss;
Other hair issue; nail issue; Pigment issue
Duration of problem Unknown; Since childhood; One day; Less than one week;
One to four weeks; One to three months; Three to twelve months;
Over one year; Over five years; Other
Table A.2: The full list of metadata questions and the values each can take. For all questions except for age, we represent them as binary
vectorswithasizeequaltothenumberofoptions.
Appendix A.2. Class distribution
Forthefulldistributionofclassesinourdataset, seeFigureA.7. Wealsodivideconditionsintothreeseveritybuckets
(low, medium and high), the proportions for which are shown in Table A.3
Appendix B. Training process
Appendix B.1. Base Model training
We resized each image to 448×448 pixels for our training. We use data augmentation for training. This includes:
random horizontal and vertical flips, random variations of brightness (max intensity = 0.1), contrast (intensity =
[0.8−1.2]),saturation(intensity=[0.8−1.2])andhue(maxintensity=0.02),randomGaussianblurringusingstandard
deviation between 0.01 and 7.0 and random rotations between −150◦ and 150◦.
In order to ensure the model is robust to variable numbers of input, image embeddings are averaged, producing a
single average embedding for each case. Additionally, we train the model with random metadata masking.
13Acne
Eczema
Psoriasis Impetigo
Allergic Contact Der.. Infected eczema
Melanocytic Nevus Livedo reticularis
Folliculitis Canker sore
Seborrheic Dermatiti.. Poikiloderma
Alopecia Areata Pityriasis lichenoid..
Hidradenitis Pityriasis rubra pil..
SK/ISK Ecthyma
Androgenetic Alopeci.. Arterial ulcer
Cyst Candida
Scar Condition Syphilis
Tinea Versicolor Post-Inflammatory hy..
Actinic Keratosis Erythema multiforme
Onychomycosis Cellulitis
Verruca vulgaris SJS/TEN
Acne keloidalis Lipodermatosclerosis
Insect Bite Chilblain
Hemangioma Onycholysis
Drug Rash Erythema ab igne
Abscess Pityriasis alba
Lichen planus/lichen.. Dermatofibrosarcoma ..
Rosacea Diabetic ulcer
Dermatofibroma Longitudinal melanon..
Basal Cell Carcinoma Purpura
Erythrasma
Post-Inflammatory hy.. Acquired digital fib..
Melasma Hematoma of skin
Lentigo Dermatitis herpetifo..
Keratosis pilaris Granuloma faciale
Skin Tag Porokeratosis
Vitiligo Cutaneous metastasis
Tinea Hypersensitivity
Granuloma annulare Angiokeratoma of ski..
Lichen Simplex Chron.. Pemphigus vulgaris
Pigmented purpuric e.. Hyperhidrosis
Condyloma acuminatum Skin and soft tissue..
Inflicted skin lesio.. Burn of skin
Pyogenic granuloma Pearly penile papule..
Stasis Dermatitis Acute generalised ex..
Perioral Dermatitis Dermatomyositis
Pityriasis rosea Pemphigoid gestation..
SCC/SCCIS Knuckle pads
Prurigo nodularis Perleche
Urticaria Comedone
Melanoma Cutaneous sarcoidosi..
Photodermatitis Giant cell tumor
Lipoma Inflammatory linear ..
Scabies Miliaria
Irritant Contact Der.. Epidermal nevus
Bullous Pemphigoid Angiosarcoma of skin
Herpes Zoster Kaposi's sarcoma of ..
Acanthosis nigricans Apocrine cystadenoma
Amyloidosis of skin Mucocele
Cutaneous lupus Leprosy
Atypical Nevus Deep fungal infectio..
Intertrigo Nevus spilus
Molluscum Contagiosu.. Pilonidal cyst
Herpes Simplex Other
Confluent and reticu.. Necrobiosis lipoidic..
Telogen effluvium Calciphylaxis cutis
Idiopathic guttate h.. Accessory nipple
Leukocytoclastic Vas.. Hirsutism
Pyoderma Gangrenosum Cutaneous neurofibro..
Keratoderma Porphyria cutanea ta..
Erythema nodosum Glomus tumour of ski..
Healthy Beau's lines
Adnexal neoplasm Hemosiderin pigmenta..
Milia Chicken pox exanthem
Dissecting celluliti.. Traumatic bulla
Telangiectasia disor..
Traction alopecia Livedoid vasculopath..
Lichen sclerosus Onychomadesis
Cutaneous T Cell Lym.. Ecthyma gangrenosum
Morphea/Scleroderma Breast cancer
Skin striae Pruritic urticarial ..
Paronychia Calcinosis cutis
Folliculitis decalva.. Sweet syndrome
Fordyce spots Perforating dermatos..
O/E - ecchymoses pre.. Zoon's balanitis
Nevus sebaceous Nail dystrophy due t..
Central centrifugal .. Bullosis diabeticoru..
Sebaceous hyperplasi.. B-Cell Cutaneous Lym..
Clavus Grover's disease
Venous Stasis Ulcer Cutaneous lymphadeno..
Angiofibroma Erythema gyratum rep..
Erythema dyschromicu.. Erythema annulare ce..
Lichen planopilaris Alopecia mucinosa
Xerosis Viral Exanthem
0.1% 0.3% 1% 3% 10% 0.1% 0.3% 1% 3% 10%
Percentage of dataset Percentage of dataset
FigureA.7: Percentageofconditionsinthedataset
14
noitidnoC
noitidnoCTableA.3: Proportionofseverityconditionsinthedataset.
Severity Percentage
Low 56%
Medium 36%
High 8%
WeuseaStochasticGradientDescentoptimiserwithmomentumandexponentiallydecayinglearningratefortraining.
Each model is trained for 10000 steps. Convergence of all the models were ensured on the validation set. We use a
batch-size of 16 cases for training. We use the validation set to set the hyper-parameters ( initial learning rate, decay
factor, momentum) and to select the best checkpoints for all the models. Checkpoint selection was based on Top-3
accuracy.
15