Collaborative Reinforcement Learning Based
Unmanned Aerial Vehicle (UAV) Trajectory Design
for 3D UAV Tracking
Yujiao Zhu, Student Member, IEEE, Mingzhe Chen, Member, IEEE,
Sihua Wang, Student Member, IEEE, Ye Hu, Member, IEEE,
Yuchen Liu, Member, IEEE, and Changchuan Yin, Senior Member, IEEE
Abstract—In this paper, the problem of using one active since it supports a wide range of applications in military,
unmannedaerialvehicle(UAV)andfourpassiveUAVstolocalize assistanceandindustrialscenarios[2]–[5].Forexample,when
a 3D target UAV in real time is investigated. In the considered
UAVs perform attack missions in the military field, it is
model, each passive UAV receives reflection signals from the
necessary to locate and track unauthorized UAVs in real
targetUAV,whichareinitiallytransmittedbytheactiveUAV.The
receivedreflectionsignalsalloweachpassiveUAVtoestimatethe time [6], [7]. However, achieving accurate UAV positioning
signal transmission distance which will be transmitted to a base faces several challenges. First, UAVs are moving at a high
station (BS) for the estimation of the position of the target UAV. speed, and thus estimating the real-time positions of UAVs is
DuetothemovementofthetargetUAV,eachactive/passiveUAV
challenging. Second, since the coordinates of UAVs are three-
must optimize its trajectory to continuously localize the target
dimensional(3D),estimating3DcoordinatesofUAVsrequires
UAV. Meanwhile, since the accuracy of the distance estimation
depends on the signal-to-noise ratio of the transmission signals, more sensors (at least four sensors) and complex positioning
the active UAV must optimize its transmit power. This problem algorithms. Third, dynamic wireless environments such as
isformulatedasanoptimizationproblemwhosegoalistojointly electromagnetic interference, transmit power allocation, and
optimize the transmit power of the active UAV and trajectories
availablecommunicationresourceswillaffectthetransmission
of both active and passive UAVs so as to maximize the target
of pilot signals used for UAV localization thus affecting UAV
UAV positioning accuracy. To solve this problem, a Z function
decomposition based reinforcement learning (ZD-RL) method localization accuracy [8]–[10].
is proposed. Compared to value function decomposition based
RL (VD-RL), the proposed method can find the probability A. Related Works
distribution of the sum of future rewards to accurately estimate
Recently, several existing works such as [11]–[17] have
the expected value of the sum of future rewards thus finding
focusedonUAVlocalization.Theauthorsin[11]and[12]con-
bettertransmitpoweroftheactiveUAVandtrajectoriesforboth
active and passive UAVs and improving target UAV positioning sideredtheuseofasinglecamerasensortotrackmovementof
accuracy. Simulation results show that the proposed ZD-RL UAVs. However, the positioning algorithms used in [11] and
method can reduce the positioning errors by up to 39.4% and [12]mustbeimplementedbasedonuniquehardwareandhigh
64.6%,comparedtoVD-RLandindependentdeepRLmethods,
computational resource. The authors in [13]–[17] used radio-
respectively.
frequency (RF) signals to estimate the positions of UAVs. In
Index Terms—Unmanned aerial vehicles, localization, tra-
jectory design, Z function decomposition based reinforcement particular,in[13],[14],theauthorsobtainedthearrivaltimeof
learning. transmittedsignalsfromseveralsensorsanddeterminedthe3D
positionsofUAVs.Theauthorsin[15]jointlyusedthearrival
I. INTRODUCTION angleanddepartureangleoftransmittedsignalstoestimatethe
positions of UAVs thus reducing the number of sensors used
Unmanned aerial vehicle (UAV) localization has gained
for UAV localization. The authors in [16] studied the UAV
significant attention from academic and commercial fields
trajectory optimization problem and estimate the position of
Y.Zhu,S.Wang,andC.YinarewiththeBeijingLaboratoryofAdvanced the UAV based on angle information of arrival signals. The
Information Network, Beijing University of Posts and Telecommunications, authors in [17] used the received signals strength to measure
Beijing,100876,China(E-mail:yjzhu@bupt.edu.cn;sihuawang@bupt.edu.cn;
distance information and analyzed the impact of different dis-
ccyin@bupt.edu.cn).
M. Chen is with the Department of Electrical and Computer Engineering tance measurement errors on UAV localization performance.
and Institute for Data Science and Computing, University of Miami, Coral However, the authors in [11]–[17] did not consider how the
Gables,FL,33146,USA(Email:mingzhe.chen@miami.edu).
positions of sensors affect the UAV localization accuracy and
Y.HuiswiththeDepartmentofIndustrialandSystemEngineering,Uni-
versityofMiami,CoralGables,FL,33146,USA(Email:yehu@miami.edu). they also did not consider the optimization of the deployment
Y.LiuiswiththeDepartmentofComputerScience,NorthCarolinaState of sensors. In fact, the positions of sensors will significantly
University,Raleigh,NC,27695,USA(Email:yuchen.liu@ncsu.edu).
affect the UAV positioning accuracy [18]. Meanwhile, most
Apreliminaryversionofthiswork[1]isacceptedintheProceedingsofthe
2023IEEEInternationalGlobalCommunicationsConference(GLOBECOM). oftheseworks[11]–[17]assumedthatthevaluesofsignal-to-
4202
naJ
22
]AM.sc[
1v97021.1042:viXranoiseratio(SNR)oftransmittedsignalsareconstant,whichis trajectory to accurately localize the target UAV. Mean-
impractical in actual wireless networks. In addition, most of while,theaccuracyofthedistanceinformationestimated
theseworks[11]–[17]assumedthatacentralcontrollerknows by passive UAVs depends on the SNR of the signals
thepositionsofallsensorsandchannelstateinformation(CSI) transmitted from the active UAV and hence the active
inadvancesuchthatthecentralcontrollerwilldirectlyusethis UAV must optimize its transmit power according to the
informationforUAVpositioning.Therefore,theseworks[11]– movements of the target UAV and passive UAVs. This
[17] cannot be used for scenarios where the central controller problem is formulated as an optimization problem that
cannot obtain the positions of sensors or CSI. aims to maximize the localization accuracy of the target
Recently,anumberofexistingworks[19]–[23]havestudied UAVviaoptimizingthetransmitpoweroftheactiveUAV
the use of reinforcement learning (RL) [24] for UAV local- and the trajectories of the active and passive UAVs.
ization in the networks where the central controller cannot • Tosolvethisproblem,weproposeaZfunctiondecompo-
obtain all the information needed for UAV localization. In sitionbasedreinforcementlearning(ZD-RL)methodthat
particular,theauthorsin[19]selecteddifferentgroundsensors enables each controlled UAV to determine its trajectory
to optimize the UAV localization performance using a dou- and the active UAV to determine its transmit power via
ble deep Q-network based RL method. The authors in [20] its individual observation. Compared to value function
developed a domain randomization based RL algorithm and decomposition methods [25], the Z function decompo-
estimated the real-time position of a UAV using a monocular sition can find the probability distribution of the sum
camerawhileconsideringenvironmentalimpactssuchaswind of future rewards such that each controlled UAV can
gusts.Theauthorsin[21]usedtimedifferenceofsignalarrival accurately estimate the expected value of the sum of
information measured by ground sensors to estimate 3D coor- futurerewardstoupdatetheparametersofitsdeepneural
dinatesofUAVsandapplieddeepdeterministicpolicygradient networks (DNNs). Hence, the proposed ZD-RL method
(DDPG)andsoftactor-criticmethodstooptimizeTaylorseries canimprovetheefficiencyandstabilityofoptimizingthe
linearized localization approach. The authors in [22] analyzed transmit power of the active UAV and the trajectories of
the effects of measurement uncertainty on the performance controlled UAVs to minimize the positioning error of the
of UAV localization based on a proximal policy optimization target UAV.
(PPO) algorithm in an environment with dynamic noise. In • To further minimize the positioning error of the target
[23], the authors mapped UAVs’ initial sensory measurements UAV, we analyze how the positions of the controlled
intocontrolsignalsforlocalizationandnavigationbyanactor- UAVs affect the positioning error of the target UAV.
critic based deep reinforcement learning (DRL) algorithm. Ouranalyticalresultsshowthattheminimumpositioning
However, the central controller in these works [19]–[23] must errorofthetargetUAVcanbeachievedwhenthedistance
collect sensing data from all sensors to determine the UAV between each controlled UAV and the target UAV is
movement, which will increase the communication overhead minimized.
and the time used for UAV localization. Meanwhile, most of
Simulation results show that the proposed ZD-RL method
theseworks[20]–[23]consideredtheuseofstaticallyinstalled
can achieve up to 39.4% and 64.6% reduction in the posi-
sensors for UAV localization, which may not be used for
tioning error of the positions of the target UAV compared
localizing a UAV with a high movement speed.
to traditional value function decomposition based RL (VD-
RL) and independent DRL methods, respectively. To the best
B. Contributions of our knowledge, this is the first work that presents a UAV
localization framework that utilizes one active UAV and four
The main contribution of this work is to design a novel
passive UAVs for 3D UAV positioning.
framework that can real-time monitor the position of a target
UAV by controlled UAVs including four passive UAVs and The rest of this paper is organized as follows. The system
one active UAV. The main contributions include: model and problem formulation are described in Section II.
TheZfunctiondecompositionbasedpowerallocationandtra-
• We propose a UAV-based localization system to estimate
jectorydesignmethodisdiscussedinSectionIII.Theoptimal
the positions of the target UAV in which the active UAV
deployment of controlled UAVs for target UAV localization
transmits signals to the target UAV, while four passive
areanalyzedinSectionIV.InSectionV,numericalsimulation
UAVs collect the arrival time of signals transmitted from
results are presented and analyzed. Finally, conclusions are
theactiveUAVtothetargetUAV,andthenfromthetarget
drawn in Section VI.
UAVtopassiveUAVs.Next,eachpassiveUAVestimates
the distance from the active UAV to the target UAV, and
then to the passive UAV. Such distance information is II. SYSTEMMODELANDPROBLEMFORMULATION
transmitted to the BS, which calculates the position of
the target UAV. Consider a UAV-assisted positioning network in which a
• In the considered UAV localization system, since the ground BS and a set M of five controlled UAVs jointly
target UAV will change its position according to its monitor the position of the target UAV in real time, as
performed task, each controlled UAV must optimize its shown in Fig. 10. The controlled UAVs consist of an active(cid:6)(cid:16)(cid:13)(cid:1)(cid:9)(cid:11)(cid:25)(cid:17)(cid:27)(cid:13)(cid:1)(cid:7)(cid:2)(cid:8)(cid:1)
(cid:25)(cid:23)(cid:9)(cid:20)(cid:24)(cid:19)(cid:17)(cid:25)(cid:24)(cid:24)(cid:17)(cid:15)(cid:20)(cid:9)(cid:18)(cid:24)
(cid:5)(cid:17)(cid:15)(cid:20)(cid:9)(cid:18)(cid:24)(cid:1)(cid:9)(cid:23)(cid:13)(cid:1)(cid:23)(cid:13)(cid:14)(cid:18)(cid:13)(cid:11)(cid:25)(cid:13)(cid:12)(cid:1)
(cid:10)(cid:28)(cid:1)(cid:25)(cid:16)(cid:13)(cid:1)(cid:25)(cid:9)(cid:23)(cid:15)(cid:13)(cid:25)(cid:1)(cid:7)(cid:2)(cid:8)
(cid:4)(cid:9)(cid:24)(cid:24)(cid:17)(cid:27)(cid:13)(cid:1)(cid:7)(cid:2)(cid:8)(cid:24)(cid:1)
(cid:1) (cid:23)(cid:13)(cid:11)(cid:13)(cid:17)(cid:27)(cid:13)(cid:1)(cid:25)(cid:16)(cid:13)(cid:1)(cid:23)(cid:13)(cid:14)(cid:18)(cid:13)(cid:11)(cid:25)(cid:13)(cid:12)(cid:1)(cid:24)(cid:17)(cid:15)(cid:20)(cid:9)(cid:18)(cid:24)
(cid:1) (cid:11)(cid:9)(cid:18)(cid:11)(cid:26)(cid:18)(cid:9)(cid:25)(cid:13)(cid:1)(cid:24)(cid:17)(cid:15)(cid:20)(cid:9)(cid:18)(cid:1)(cid:25)(cid:23)(cid:9)(cid:20)(cid:24)(cid:19)(cid:17)(cid:24)(cid:24)(cid:17)(cid:21)(cid:20)(cid:1)(cid:12)(cid:17)(cid:24)(cid:25)(cid:9)(cid:20)(cid:11)(cid:13)(cid:1)(cid:10)(cid:9)(cid:24)(cid:13)(cid:12)(cid:1)
(cid:21)(cid:20)(cid:1)(cid:23)(cid:13)(cid:11)(cid:13)(cid:17)(cid:27)(cid:13)(cid:12)(cid:1)(cid:24)(cid:17)(cid:15)(cid:20)(cid:9)(cid:18)(cid:24)
(cid:1) (cid:25)(cid:23)(cid:9)(cid:20)(cid:24)(cid:19)(cid:17)(cid:25)(cid:1)(cid:12)(cid:17)(cid:24)(cid:25)(cid:9)(cid:20)(cid:11)(cid:13)(cid:1)(cid:17)(cid:20)(cid:14)(cid:21)(cid:23)(cid:19)(cid:9)(cid:25)(cid:17)(cid:21)(cid:20)(cid:1)(cid:25)(cid:21)(cid:1)(cid:25)(cid:16)(cid:13)(cid:1)(cid:3)(cid:5)
(cid:3)(cid:9)(cid:24)(cid:12)(cid:5)(cid:25)(cid:9)(cid:25)(cid:16)(cid:21)(cid:20) (cid:2)(cid:10)(cid:25)(cid:16)(cid:26)(cid:12)(cid:7)(cid:2)(cid:8) (cid:6)(cid:9)(cid:23)(cid:14)(cid:12)(cid:25)(cid:1)(cid:7)(cid:2)(cid:8) (cid:4)(cid:9)(cid:24)(cid:24)(cid:16)(cid:26)(cid:12)(cid:7)(cid:2)(cid:8) (cid:6)(cid:16)(cid:13)(cid:1)(cid:3)(cid:5)(cid:1)(cid:13)(cid:24)(cid:25)(cid:17)(cid:19)(cid:9)(cid:25)(cid:13)(cid:24)(cid:1)(cid:25)(cid:16)(cid:13)(cid:1)
(cid:5)(cid:16)(cid:14)(cid:20)(cid:9)(cid:18)(cid:24)(cid:1)(cid:23)(cid:12)(cid:13)(cid:18)(cid:12)(cid:10)(cid:25)(cid:12)(cid:11)(cid:1)(cid:13)(cid:23)(cid:21)(cid:19)(cid:1)(cid:25)(cid:15)(cid:12)(cid:1)(cid:25)(cid:9)(cid:23)(cid:14)(cid:12)(cid:25)(cid:1)(cid:7)(cid:2)(cid:8) (cid:22)(cid:21)(cid:24)(cid:17)(cid:25)(cid:17)(cid:21)(cid:20)(cid:1)(cid:21)(cid:14)(cid:1)(cid:25)(cid:16)(cid:13)(cid:1)(cid:25)(cid:9)(cid:23)(cid:15)(cid:13)(cid:25)(cid:1)(cid:7)(cid:2)(cid:8)
(cid:6)(cid:23)(cid:9)(cid:17)(cid:12)(cid:10)(cid:25)(cid:21)(cid:23)(cid:27)(cid:21)(cid:13)(cid:25)(cid:15)(cid:12)(cid:1)(cid:25)(cid:9)(cid:23)(cid:14)(cid:12)(cid:25)(cid:1)(cid:7)(cid:2)(cid:8)
(cid:5)(cid:16)(cid:14)(cid:20)(cid:9)(cid:18)(cid:24)(cid:1)(cid:25)(cid:23)(cid:9)(cid:20)(cid:24)(cid:19)(cid:16)(cid:25)(cid:25)(cid:12)(cid:11)(cid:1)(cid:13)(cid:23)(cid:21)(cid:19)(cid:1)(cid:25)(cid:15)(cid:12)(cid:1)(cid:9)(cid:10)(cid:25)(cid:16)(cid:26)(cid:12)(cid:1)(cid:7)(cid:2)(cid:8)
(cid:6)(cid:23)(cid:9)(cid:17)(cid:12)(cid:10)(cid:25)(cid:21)(cid:23)(cid:27)(cid:21)(cid:13)(cid:25)(cid:15)(cid:12)(cid:1)(cid:10)(cid:21)(cid:20)(cid:25)(cid:23)(cid:21)(cid:18)(cid:18)(cid:12)(cid:11)(cid:1)(cid:7)(cid:2)(cid:8)
(cid:5)(cid:16)(cid:14)(cid:20)(cid:9)(cid:18)(cid:24)(cid:1)(cid:25)(cid:23)(cid:9)(cid:20)(cid:24)(cid:19)(cid:16)(cid:25)(cid:25)(cid:12)(cid:11)(cid:1)(cid:13)(cid:23)(cid:21)(cid:19)(cid:1)(cid:25)(cid:15)(cid:12)(cid:1)(cid:22)(cid:9)(cid:24)(cid:24)(cid:16)(cid:26)(cid:12)(cid:1)(cid:7)(cid:2)(cid:8)(cid:24) Fig.2. TheflowchartoftheconsideredUAVpositioningprocess.
TABLEI
Fig.1. IllustrationoftheconsideredUAVlocalizationnetwork.
LISTOFNOTATIONS
UAV and four passive UAVs1. Here, the target UAV cannot
Notation Description
directly transmit its position to the BS since the target UAV M NumberofcontrolledUAVs
may not know its current position, or the target UAV may um,t PositionofcontrolledUAVm
be an adversarial UAV and it will not share its position to
vm,t FlightspeedofcontrolledUAVm
∆t Timedurationofatimeslot
the BS and passive UAVs. In our model, the active UAV
φm,t YawangleofcontrolledUAVm
first transmits signals to the target UAV which will reflect ϕm,t PitchangleofcontrolledUAVm
the signals to passive UAVs. Then, passive UAVs estimate τm,t Transmittimeofsignals
c Speedoflight
the signal transmission distance from the active UAV to the
st PositionofthetargetUAV
target UAV, and then to passive UAVs. The estimated signal dm,t DistancefromthetargetUAVtocontrolledUAVm
transmissiondistancewillbetransmittedtotheBStocalculate pm,t TransmitpowerofcontrolledUAVm
the position of the target UAV. We assume that the real-time ωm,t RandomGaussiannoise
3D coordinates of the controlled UAVs are known to the
at Transmittingsignal
ym,t ReceivedsignalsatpassiveUAVm
BS. The flow chart of estimating the target UAV’s position xm,t ScatteringcoefficientofthetargetUAV
is shown in Fig. 2. Next, we first introduce the movement hm,t PathlossbetweenUAVs
model of the active and passive UAVs. Then, the transmission
β0 LoSpathlossatareferencedistance
γA SNRofsignalsreceivedbypassiveUAVm
links among the active UAV, target UAV, passive UAVs, and m,t
σ2 Varianceofmeasurementerror
the BS are introduced. Finally, the positioning model and the Em,t EnergyconsumptionoftheactiveUAV
optimization problem is formulated. km,t DistancebetweentheBSandpassiveUAVm
Letu =[x ,y ,z ]T bethe3DcoordinateofUAV sB PositionoftheBS
m,t m,t m,t m,t χm,t ElevationangleofpassiveUAVm
m at time slot t. Hereinafter, we use a sequence number 0 to L FS Free-spacepathloss
represent the active UAV and a sequence number from 1 to 4 lLoS LoSpathlossfromUAVmtotheBS
m,t
(cid:16) (cid:17)
to represent a passive UAV. For example, u 0,t represents the Pr l mLo ,S t ProbabilityofLoS
coordinateoftheactiveUAVandu m,t with1⩽m⩽4isthe l mNL ,o tS NLoSpathlossfromUAVmtotheBS
coordinate of a passive UAV. Then, the coordinate of UAV m D Datasizeofthedistanceinformation
is γ mB ,t SNRofsignalsreceivedattheBS
W Bandwidth
  ϵ2 VarianceofGaussiannoise
cosφ cosϕ
m,t m,t TA TransmissiondelaybetweenUAVs
m,t
u m,t+1(ϕ m,t,φ m,t)=u m,t+v m,t∆ tsinφ m,tcosϕ m,t, rˆt Distancemeasurementinformation
sinϕ
m,t
rt Actualdistance
(1) nm,t Measurementinformationerror
where φ is the yaw angle, ϕ is the pitch angle, v is
T mB
,t
TransmissiondelayfrompassiveUAVmtotheBS
m,t m,t m,t
V Numberoftimeslots
the flight speed, and ∆ is the time duration of a time slot.
t sˆt EstimatedpositionofthetargetUAV
A. Transmission Model
1Sinceweusethetraditionaltimedifferenceofarrival(TDOA)methodto
calculatethethree-dimensional(3D)coordinateofthetargetUAV[26],four
Here, we introduce the models for transmission links a)
passiveUAVsarerequiredtoestimatethefoursignaltransmissiondistances
andcalculatethe3DpositionofthetargetUAV. from the active UAV to the target UAV and then reflectedto passive UAVs, b) from passive UAVs to the ground BS. 2) Passive UAV-BS Links: Passive UAVs require to use
1) Active UAV-Target UAV-Passive UAV Links: In our their received signals to calculate the distance rˆ from the
m,t
model,theactiveUAVtransmitsasignala t tothetargetUAV. active UAV to the target UAV and then from the target UAV
We assume that there is no occlusion in the path from the to the passive UAV. Then, each passive UAV will transmit
active UAV to the target UAV, and paths from the target UAV its calculated distance rˆ to the BS. Since the ground
m,t
to passive UAVs. Let τ m,t denote the time of transmitting communicationsmayinterferethetransmissionbetweenUAVs
signal a t from the active UAV to passive UAV m via the and the BS, we use probabilistic LoS and non-line-of sight
target UAV. Then, τ m,t can be given by (NLoS) links to model the links between passive UAVs and
r (u ,s ,u ) the BS. The LoS and NLoS path loss of passive UAV m
τ m,t = m,t 0,t c t m,t , (2) transmitting signals to the BS located at s B at time slot t
is given by
where c is the speed of light and r (u ,s ,u ) =
m,t 0,t t m,t
d 0,t(u 0,t,s t)+d m,t(s t,u m,t) is the distance from the active lLoS(u )
m,t m,t
UAV to the target UAV and then from the target UAV to
=L (k )+10µ log(k (u ,s ))+λ ,
passive UAV m with d (u ,s ) = ∥u −s ∥ being the FS 0 LoS m,t m,t B σLoS
0,t 0,t t 0,t t (7)
distance between the active UAV and the target UAV located
at s =[x ,y ,z ]T and d (s ,u )=∥s −u ∥ being
t t t t m,t t m,t t m,t lNLoS(u )=
the distance between the target UAV and passive UAV m. m,t m,t
L (k )+10µ log(k (u ,s ))+λ ,
Since less obstacles exist in the sky, we use a line-of-sight FS 0 NLoS m,t m,t B σNLoS
(LoS)transmissionmodelforthelinksbetweentheactiveUAV (8)
and passive UAVs [27], [28]. Then, the signals transmitted
where L (k ) =
20log(cid:0)
k
fB4π/c(cid:1)
is the free-space path
fromtheactiveUAV,reflectedbythetargetUAV,andreceived FS 0 0 0
loss with k being the free-space reference distance and fB
by passive UAV m at time slot t is given by 0 0
being the carrier frequency. k (u ,s ) is the distance
√ m,t m,t B
y m,t = p 0,th m,tx m,th 0,ta t−τm,t +w m,t, (3) between passive UAV m and the BS at time slot t. λ σLoS and
λ are the shadowing random variables, which are Gaus-
w sloh ter te
,
xp 0 m,t ,tis ret ph re est er na tn ssm thi et sp co aw tte er rino gf t ch oe efa fic ct ii ev ne tU oA fV theat tat ri gm ee
t
siσ aN nLo vS ariables in dB with zero mean and (cid:0) σ LB oS(cid:1)2 , (σ NLoS)2
UAV [29], and w is Gaussian noise with zero mean and dB variances. The probability of LoS is given by
m,t √
ϵ2 variance. h 0,t = β 0d− 0,1 t (u 0,t,s t) represents the path Pr(cid:0) lLoS(u )(cid:1) =(1+Xexp(−Y [χ −X]))−1, (9)
loss from the active UAV to the target UAV, and h = m,t m,t m,t
√ m,t
β 0d− m1 ,t(u m,t,s t) represents √the path loss from the target whereX andY areconstantswhicharerelatedtotheenviron-
UAV to passive UAV m with β 0 being the LoS path loss ment factors, and χ m,t is the elevation angle of passive UAV
at a reference distance [30]. We use LoS links to model the m at time slot t, which satisfies sin(χ ) = zm,t .
linkbetweentheactiveUAVandthetargetUAVandthelinks Therefore, the path loss from passive Um A,t V m k tom,t th(u em B,t, SsB a) t
between the target UAV and passive UAVs. time slot t is given by
At passive UAV m, the signal-to-noise ratio (SNR) of the
signaltransmittedbytheactiveUAVandreflectedbythetarget ¯l m,t(u m,t)=Pr(cid:0) l mLo ,S
t
(u m,t)(cid:1) ×l mLo ,S
t
(u m,t)
UAV is given by [31] +(cid:0) 1−Pr(cid:0) lLoS(u )(cid:1)(cid:1) ×lNLoS(u ).
m,t m,t m,t m,t
p |h x h |2 (10)
γA (u ,u ,p )= 0,t m,t m,t 0,t . (4)
m,t 0,t m,t 0,t ϵ2
We assume that passive UAVs use an orthogonal frequency
From(4),weseethattheSNRofeachpassiveUAVdepends
division multiple access (OFDMA) technique [24]. The SNR
on the transmit power of the active UAV and the distance
of the signal transmitted from passive UAV m to the BS at
between the active UAV and the passive UAV via the target
time slot t is given by
UAV.ThetransmissiondelayfromtheactiveUAVtothetarget
UAV and from the target UAV to passive UAV m is given by γB (u )= p m,t10−¯lm,t(um,t)/10, (11)
m,t m,t ϵ2
D
TA (u ,u ,p )= A , (5)
m,t 0,t m,t 0,t W log 2(cid:0) 1+γ mA ,t(u m,t)(cid:1) where p m,t is the transmit power of passive UAV m at time
slot t. Hence, the SNR of the BS changes as the transmit
where D is the size of the transmitting signals and W is
A powers of passive UAVs and the positions of passive UAVs
the bandwidth. The energy consumption of the active UAV is
vary. The transmission delay from passive UAV m to the BS
given by
at time slot t is given by
E (u ,u ,p )=p TA (u ,u ,p ). (6)
m,t 0,t m,t 0,t 0,t m,t 0,t m,t 0,t D
Due to the limited energy of the active UAV, the transmit T mB ,t(u m,t)=
W log
(cid:0) 1+γB
B (u
)(cid:1), (12)
power of the active UAV must be optimized to minimize the 2 m,t m,t
positioningerrorofthetargetUAVwhilesatisfyingtheenergy where D is the data size of the distance information trans-
B
consumption requirements of the active UAV. mitted from passive UAVs to the BS.B. Model for Positioning betweenacontrolledUAVandthetargetUAV,and(13f)isthe
Let rˆ = [rˆ ,··· ,rˆ ]T be the distance measurement constraint of the distance between any two controlled UAVs.
t 1,t 4,t
The problem (13) is challenging to solve by conventional
information received by the BS from passive UAVs. Then,
optimization algorithms due to the following reasons. First,
the BS uses rˆ to estimate the position of the target UAV.
t
since the Hessian matrix of objective function in (13) is not a
A two-stage weighted least-squares (TSWLS) method [32] is
positive semi-definite matrix, the problem (13) is non-convex.
exploited to determine the position of the target UAV. Hence,
Second, the BS must know the coordinates of the target
we assume that the distance measurements rˆ from the active
t
UAV to optimize the transmit power of the active UAV and
UAV to passive UAV m via the target UAV involves an error,
trajectories of controlled UAVs using optimization methods.
andcanbeexpressedbyrˆ =r +n (p ,u ,u ),
m,t m,t m,t 0,t 0,t m,t
However, the target UAV is moving and hence the BS may
where n (p ,u ,u ) represents the error between the
m,t 0,t 0,t m,t
not be able to obtain the real-time position of the target UAV.
measured distance rˆ and the truth distance r and is the
m,t m,t
To solve the optimization problem (13), we use a distributed
independent Gaussian measurement error with zero mean and
variance σ2 (u ,u ,p ) [33]. Based on the distance RL algorithm which finds the probability distribution of the
m,t 0,t m,t 0,t
sum of future rewards to estimate the expected value of
measurement information rˆ , 3D position of the controlled
t
UAVs U = [u ,··· ,u ]T and the transmit power p the sum of future rewards accurately. The proposed method
t 0,t 4,t 0,t
enables the active UAV to determine its transmit power and
of the active UAV at time slot t, the estimated position of
each controlled UAV to determine its trajectory using its
the target UAV sˆ (U ,p ) can be obtained via the TSWLS
t t 0,t
individual observation. Hence, using distributed RL, the BS
method in [32].
and controlled UAVs can minimize the positioning error of
C. Problem Formulation the target UAV.
Given the defined system model, our goal is to minimize
(cid:113) III. PROPOSEDZFUNCTIONDECOMPOSITIONBASEDRL
the positioning error (cid:80)V (sˆ (U ,p )−s )2 between
t=1 t t 0,t t In this section, we introduce a ZD-RL method to solve
the estimated position sˆ (U ,p ) and the actual position
t t 0,t the optimization problem in (13). Compared to standard RL
s of the target UAV over a time period T that consists of
t algorithms [25] such as deep Q-network (DQN) that uses
V time slots under the delay and movement constraints of
a neural network to directly estimate the expected value of
UAVs,where(sˆ (U ,p )−s )2 representsthesquareofthe
t t 0,t t the sum of future rewards, the ZD-RL method aims to find
positioningerrorbetweentheestimatedpositionandtheactual
the probability distribution of the sum of future rewards and
position of the target UAV at time slot t. This minimization
capture richer distribution information, thus improving the
problem includes optimizing the transmit power of the active
efficiency of optimizing the transmit power of the active
UAV and the trajectories of passive and active UAVs. The
UAV and trajectories of controlled UAVs. Hence, the ZD-
optimization problem is given by
RL method can improve the efficiency of optimizing the
V (cid:113) transmitpoweroftheactiveUAVandtrajectoriesofcontrolled
min (cid:88) (sˆ t(U t,p 0,t)−s t)2, UAVs. Next, we first introduce the components of the ZD-RL
p0,t,φ t,ϕ
tt=1 method. Then, the process of using the ZD-RL method to
(13)
findtheglobaloptimaltransmitpowerfortheactiveUAVand
s.t. E ⩽E , (13a) trajectories for controlled UAVs is explained.
m,t max
T mB ,t(u m,t)⩽ξ, ∀m∈M, (13b) A. Components of the ZD-RL method
φmin ⩽φ m,t ⩽φmax, ∀m∈M, (13c) The ZD-RL method consists of six components: a) agents,
ϕmin ⩽ϕ ⩽ϕmax, ∀m∈M, (13d) b) actions, c) states, d) rewards, e) individual Z function, f)
m,t
L ⩽∥u −s ∥⩽L , ∀m∈M, (13e) global Z function, which are specified as follows:
min m,t+1 t+1 max
L ⩽∥u −u ∥⩽L , ∀m,m′ ∈M, • Agents: The agents that perform the ZD-RL method are
min m,t+1 m′,t+1 max the controlled UAVs. Each passive UAV must decide its
(13f)
yaw angle and pitch angle and the active UAV must
where p is the transmit power of the active UAV, φ = decide its transmit power, yaw angle, and pitch angle at
0,t t
[φ ,...,φ ]T and ϕ = [ϕ ,...,ϕ ]T are the yaw each time slot.
0,t 4,t t 0,t 4,t
angle vector and the pitch angle vector for the active UAV • State space: A state of each agent is used to describe the
and passive UAVs, respectively. (13a) is a maximum energy localenvironmentofeachcontrolledUAV.Inparticular,a
consumption constraint for the active UAV, (13b) is the delay state of each passive UAV consists of its 3D coordinates
needed to transmit distance information from each passive and the distance measurements from the active UAV to
UAV to the BS, E is the maximal energy of the active the target UAV, and then from the target UAV to the
max
UAV, and L is the maximal distance between any two passive UAV. Hence, a state of a passive UAV m at time
max
UAVs to ensure the accurate UAV positioning. (13c) and slot t is o = [x ,y ,z ,rˆ ]. Since the active
m,t m,t m,t m,t m,t
(13d) are the yaw angle and the pitch angle constraints for UAV cannot obtain the distance measurement, and the
the controlled UAVs. (13e) is the constraint of the distance BS does not need the distance measurement of the activeUAV to estimate the position of the target UAV, the state From (16), we can see that Z function is to
of the active UAV is o =[x ,y ,z ]. The states of find a value of Zˆ (o ,a ,ς ) such that
0,t 0,t 0,t 0,t
(cid:16)
ωm m,t m,t i
(cid:17)
all agents at time slot t can be represented by a vector P Z(o ,a )⩽Zˆ (o ,a ,ς ) = ς . Given
m,t m,t ωm m,t m,t i i
o =[o ,...,o ].
t 0,t 4,t the relationship between ς and Zˆ (o ,a ,ς ),
• Actions:TheactionofeachpassiveUAVistheyawangle i ωm m,t m,t i
the next step is to determine the value of ς such
and the pitch angle and the action of the active UAV is i
that we can use less DNN outputs to estimate the
the transmit power, the yaw angle and the pitch angle.
entire probability distribution of Z(o ,a ). To this
Hence, an action of passive UAV m at time slot t can m,t m,t
end, we use a quantile vector ς = [ς ,··· ,ς ] with
be expressed as a = [φ ,ϕ ], and an action of 1 N
m,t m,t m,t ς = i ,i=1,··· ,N.
the active UAV at time slot t is a = [p ,φ ,ϕ ]. i N
The actions of all controlled
UAVs0 a,t
t
time0 s, lt
ot
t0, it
s
a0,t
=
• Global Z function: The global Z function Z T(o t,a t)
t is used to estimate the probability distribution of all
[a ,··· ,a ].
0,t 4,t controlledUAVs’achievablefuturerewardsateachglobal
• Reward:TherewardofeachcontrolledUAVcapturesthe
stateo andactiona .SimilarlytoindividualZfunctions,
positioning accuracy of the target UAV resulting from a t t
the probability distribution of the global Z function is
selectedaction.Giventheglobalstateo andtheselected
t approximated by a set of global Z function values with a
action a , the reward of each controlled UAV at time
t (cid:113) quantilevectorς,andtheapproximatedglobalZfunction
slot t is R t(o t,a t) = − (sˆ t(U t,p 0,t)−s t)2. Note is represented by Zˆ (o ,a ,ς). Based on the distribu-
T t t
that, R t(o t,a t) increasesas thepositioningerrorin (13) tional individual-global-max principle [36], the relation-
decreases, which implies that maximizing the reward of ship between Zˆ (o ,a ,ς) and Zˆ (o ,a ,ς) is
each controlled UAV can minimize the positioning error. given by
T t t ωm m,t m,t
• Individual Z function: Z function is defined as the sum 4
of future reward under a given state o , a selection Zˆ (o ,a ,ς)= (cid:88) M(o ,a ,ς)
m,t T t t m,t m,t
action a m,t, and a policy π, which can be expressed as m=0
Z dis( co om u, nt t, ea dm f, at) cto= r.(cid:80) Gi∞ t v= e0 nγ tt hR e(o dem fi, nt, ita iom n, ,t) o, uw rh pe ure rpγ oseis ia s + (cid:88)4 (cid:16) Zˆ ωm(o m,t,a m,t,ς)−M(o m,t,a m,t,ς)(cid:17) ,
to estimate the probability distribution of Z(o ,a ). m=0
m,t m,t (17)
This is different from DQN [25] that uses a neural
where M(o ,a ,ς) is the approximated expected
network to estimate the sum of expected future reward. m,t m,t
value of Zˆ (o ,a ,ς) and can be written as
Inparticular,therelationshipbetweenQfunctionandour
M(o ,a
ωm ,ς)m =,t
1
(cid:80)m, Nt
Zˆ (o ,a ,ς ).
defined Z function is expressed as m,t m,t N i=1 ωm m,t m,t i
Q(o ,a )=E [Z(o ,a )] B. Training of the ZD-RL Method
m,t m,t π m,t m,t
(cid:34) (cid:88)∞ (cid:35) (14) Here, we describe the entire training process of the ZD-
=E γtR(o ,a ) . RL method for optimizing the transmit power of the active
π m,t m,t
UAV and trajectories of all controlled UAVs. In particular, we
t=0
The advantage of estimating Z function instead of Q will first introduce the loss function of the ZD-RL method.
function is that Q function values estimated using the Then, we introduce the training procedures. The total loss of
probability distribution of Z function are more accurate the ZD-RL method is defined as the sum of the pair-wise loss
compared to Q function values directly estimated by for two values ς i,ς j based on quantile Huber loss [37], where
DQN [34]. Hence, the ZD-RL method ensures the sta- ς i,ς j ∈ ς. Compared to mean-square-error (MSE) loss and
bilityandeffectivenessofmodelconvergence[35].Next, meanabsoluteerror(MAE)usedintraditionalRL,thequantile
weintroducetheprocessofestimatingtheprobabilitydis- Huberlosscanreducethesensitivitytoabnormalsamplesthat
tributionofZfunction.First,weintroducethecumulative deviate from the normal range. The total loss is
distribution function (CDF) of Z(o m,t,a m,t), which is L T(ω 0,··· ,ω 4)
given by
V N N
F (z)=P(Z(o m,t,a m,t)⩽z), (15) =
N1 (cid:88)(cid:88)(cid:88)
|ς i−1
{u(ot,at,ςi,ςj)<0}|G(u(o t, ηa t,ς i,ς j))
,
t=1 i=1j=1
whereF (z)representstheprobabilitythatZ(o ,a )
m,t m,t (18)
is smaller than a value z. To estimate the probability
where 1 = 1 when x<0 and 1 = 0, other-
distribution of Z(o ,a ), we use a DNN. The input {x} {x}
m,t m,t wise. u(o ,a ,ς ,ς ) = R (o ,a )+γZˆ (o ,a ,ς )−
oftheDNNistheindividualstateo ,individualaction t t i j t t t T t+1 t+1 j
m,t Zˆ (o ,a ,ς ) with a = argmax M(o ,a′ ,ς)
a m,t and a probability value ς i, and the output is a value T t t i m,t+1 a′ m m,t+1 m
of Z function, such as Zˆ (o ,a ,ς ), where ω [38]. G(u(o t,a t,ς i,ς j)) is given by
ωm m,t m,t i m
is the parameters of the DNN. The relationship between G(u(o ,a ,ς ,ς ))
t t i j
the input of DNN and its output can be expressed as (cid:40) 1(u(o ,a ,ς ,ς ))2, if |u(o ,a ,ς ,ς )|⩽η,
(cid:16) (cid:17) = 2 t t i j t t i j
ς i =P Z(o m,t,a m,t)⩽Zˆ ωm(o m,t,a m,t,ς i) . (16) η(cid:0) |u(o t,a t,ς i,ς j)|− 1 2η(cid:1) , otherwise,Algorithm 1 ZD-RL Method for Solving Problem (13) the ZD-RL method is summarized in Algorithm 1.
1: Initialize the DNN parameters ω of each controlled UAV,
m
a quantile vector ς. C. Convergence, Implementation, and Complexity Analysis
2: for each iteration do
Next, we analyze the convergence, implementation and
3. for each controlled UAV m do
4. for each time slot t do complexity of training the proposed ZD-RL method.
5. Observe the observation o m,t. 1)ConvergenceAnalysis:Here,weanalyzetheconvergence
6: Select an action according to a ϵ-greedy scheme. oftheproposedZD-RLalgorithm.Wefirstanalyzethegapbe-
7: Calculate individual Z function values
tween the optimal expected value of the individual Z function
Zˆ (o ,a ,ς) and Zˆ (o ,a ,ς).
ωm m,t m,t ωm m,t+1 m,t+1 of controlled UAV m and the expected value of individual Z
8: end for
9: Controlled UAVs transmit o , Zˆ (o ,a ,ς), function of controlled UAV m obtained by the proposed ZD-
and Zˆ (o ,a ,m ς),t to tω hem BSm . ,t m,t RLmethod.Then,weshowthatthisgapwillconvergetozero.
10: end
forωm m,t+1 m,t+1
In particular, the gap between the optimal expected value of
11: The BS calculates the reward and global Z function, individual Z function of controlled UAV m and the expected
and transmits to controlled UAVs. value of individual Z function of controlled UAV m obtained
12: for each controlled UAV m do
by the proposed ZD-RL method is
13: Update ω using R(o ,a ), Zˆ (o ,a ,ς) and
m t t T t t
Zˆ T(o t+1,a t+1,ς) based on (19). e(o m,t,a m,t)=M(o m,t,a m,t)−M∗(o m,t,a m,t), (20)
14: end for
15: end for where M∗(o ,a ) = E[Z∗(o ,a )] is the ex-
m,t m,t m,t m,t
pected value of the optimal individual Z function of con-
where η is a hyper-parameter that determines the empha- trolled UAV m with respect to future Z functions (i.e.,
sis of Huber loss on MSE or MAE. Here, using function Z∗(o m,t+1,a m,t+1), Z∗(o m,t+2,a m,t+2),···). From (20),
G(u(o t,a t,ς i,ς j)) can balance the sensitivity of MSE to we can see that if the gap e(o m,t,a m,t) converges to zero,
large errors and the robustness of MAE to outliers and thus the proposed ZD-RL method converges [39]. To prove that
incorporating the strengths of both MSE and MAE. This is the gap e(o m,t,a m,t) will finally converge to zero, we need
because the MSE loss function 1(u(o ,a ,ς ,ς ))2 is highly to analyze how the gap changes as the number of training
2 t t i j
sensitive to outliers since it squares the errors, which can iterations increases. In particular, we define a distributional
destabilizelearninginthepresenceofnoiseoranomalies.The Bellmanoperatortofindarelationshipbetweentheindividual
MAElossfunction|u(o ,a ,ς ,ς )|islesssensitivetooutliers Z function of controlled UAV m at two continuous time
t t i j
when dealing with smaller errors. slots. In particular, the distributional Bellman operator of the
individual Z function is defined as
The training process consists of the following three steps:
• Step 1 (training at controlled UAVs): Given a quantile T (Z(o ,a )):D =R(o ,a )+γZ(o ,a ),
m,t m,t m,t m,t m,t+1 m,t+1
vector ς = [ς ,··· ,ς ], each controlled UAV observes
1 N (21)
itslocalstateo m,t,takesanactiona m,t accordingtoaϵ- where a = argmax M(o ,a′ ). Based on the
greedyalgorithm,andcalculatesitsindividualZfunction m,t+1 a′ m m,t+1 m
above definition, the convergence of the proposed ZD-RL
values Zˆ (o ,a ,ς), Zˆ (o ,a ,ς).
ωm m,t m,t ωm m,t+1 m,t+1 algorithm is shown in the following lemma.
Then, each UAV transmits its state o , indi-
m,t Lemma 1. The proposed ZD-RL method is guaranteed to
vidual Z function values Zˆ (o ,a ,ς) and
ωm m,t m,t convergetozero,ifthefollowingconditionsaresatisfied[40]:
Zˆ (o ,a ,ς) to the BS.
ωm m,t+1 m,t+1
1) The gap e(o ,a ) satisfies
• Step 2 (training at the BS): After collecting individual m,t m,t
stateandindividual Zfunctionvaluesfromallcontrolled
e (o ,a )
k+1 m,t m,t
UAVs, the BS calculates the reward R (o ,a )
and the global Z function values Zˆ (ot ,at ,ςt ), =(1−α m)e k(o m,t,a m,t)+α mF (o m,t,a m,t),
Zˆ (o ,a ,ς) based on (17), andT trt anst mits (22)
T t+1 t+1
R t(o t,a t), Zˆ T(o t,a t,ς), and Zˆ T(o t+1,a t+1,ς) to where F (o m,t,a m,t) = R(o m,t,a m,t) +
controlled UAVs. Here, the BS does not need to γM(o ,a )−M∗(o ,a ).
m,t+1 m,t+1 m,t m,t
implement and update any neural networks. 2) ||E[F (o ,a )]|| ⩽ γ||e(o ,a )|| ,∀γ ∈
m,t m,t ∞ m,t m,t ∞
• Step3(updatingatcontrolledUAVs):EachUAVupdates (0,1), where ||·|| represents the infinite norm taking
∞
DNN parameters to approximate the probability distribu- themaximumvalueoftheabsolutevalueoftheelements,
tionofitsindividualZfunctionusingitscollectedglobal E[F (o ,a )]istheexpectedvalueofF (o ,a )
m,t m,t m,t m,t
reward and global Z function values. The update of each withrespecttothestatetransitionprobabilitydistribution.
controlled UAV m is 3) Var(E[F (o ,a )]) ⩽ C (cid:0) 1+||e(o ,a )||2 (cid:1) ,
m,t m,t F m,t m,t ∞
where Var(E[F (o ,a )]) is the variance of
ω =ω +α ▽ L (ω ,··· ,ω ), (19) m,t m,t
m m m ωm T 0 4 E[F (o ,a )], and C is a constant with C ⩾0.
m,t m,t F F
where α is the step size. The entire training process of Proof: See Appendix A. □
mwith N , N , and N being the number of elements in their
(cid:3)(cid:19)(cid:17)(cid:24)(cid:29)(cid:2)(cid:1)(cid:13)(cid:15)(cid:29)(cid:21)(cid:31)(cid:17)(cid:1)(cid:13)(cid:24)(cid:16)(cid:1)(cid:26)(cid:13)(cid:28)(cid:28)(cid:21)(cid:31)(cid:17)(cid:1)(cid:10)(cid:3)(cid:11)(cid:28)(cid:29)(cid:27)(cid:13)(cid:24)(cid:28)(cid:23)(cid:21)(cid:29)(cid:21)(cid:24)(cid:18)(cid:25)(cid:27)(cid:23)(cid:13)(cid:29)(cid:21)(cid:25)(cid:24)(cid:29)(cid:25)(cid:29)(cid:20)(cid:17)(cid:4)(cid:8)(cid:1) P 1 2
corresponding sets. Since we only consider optimizing the
transmit power of the active UAV and the transmit power
(cid:7)(cid:25)(cid:28)(cid:21)(cid:29)(cid:21)(cid:25)(cid:24)(cid:28)(cid:25)(cid:18)(cid:1)
(cid:5)(cid:21)(cid:28)(cid:29)(cid:13)(cid:24)(cid:15)(cid:17)(cid:23)(cid:17)(cid:13)(cid:28)(cid:30)(cid:27)(cid:17)(cid:23)(cid:17)(cid:24)(cid:29) (cid:15)(cid:25)(cid:24)(cid:29)(cid:27)(cid:25)(cid:22)(cid:22)(cid:17)(cid:16)(cid:10)(cid:3)(cid:11)(cid:28) (cid:6)(cid:24)(cid:16)(cid:21)(cid:31)(cid:21)(cid:16)(cid:30)(cid:13)(cid:22)(cid:12)(cid:18)(cid:30)(cid:24)(cid:15)(cid:29)(cid:21)(cid:25)(cid:24)(cid:1) of passive UAVs are constant, we have N P = 1, when
(cid:21)(cid:24)(cid:18)(cid:25)(cid:27)(cid:23)(cid:13)(cid:29)(cid:21)(cid:25)(cid:24)(cid:18)(cid:27)(cid:25)(cid:23)
(cid:9)(cid:27)(cid:13)(cid:24)(cid:28)(cid:23)(cid:21)(cid:29)(cid:26)(cid:25)(cid:32)(cid:17)(cid:27)(cid:25)(cid:18) (cid:31)(cid:13)(cid:22)(cid:30)(cid:17)(cid:28)(cid:25)(cid:18)(cid:17)(cid:13)(cid:15)(cid:20)(cid:13)(cid:19)(cid:17)(cid:24)(cid:29) m = 1,··· ,4. The interval of two yaw angles ∆φ is
(cid:26)(cid:13)(cid:28)(cid:28)(cid:21)(cid:31)(cid:17)(cid:10)(cid:3)(cid:11)(cid:28) m
(cid:29)(cid:20)(cid:17)(cid:13)(cid:15)(cid:29)(cid:21)(cid:31)(cid:17)(cid:10)(cid:3)(cid:11) defined as ∆φ = φi+1 − φi ,i = 1,··· ,N − 1 and
m m,t m,t 1
the interval of two pitch angles ∆ϕ is defined as ∆ϕ =
m m
ϕi+1 − ϕi ,i = 1,··· ,N − 1. Hence, the relationship
(cid:9)(cid:20)(cid:17)(cid:1)(cid:4)(cid:8)(cid:1)(cid:15)(cid:13)(cid:22)(cid:15)(cid:30)(cid:22)(cid:13)(cid:29)(cid:17)(cid:28)(cid:29)(cid:20)(cid:17) (cid:9)(cid:20)(cid:17)(cid:1)(cid:4)(cid:8)(cid:1)(cid:15)(cid:13)(cid:22)(cid:15)(cid:30)(cid:22)(cid:13)(cid:29)(cid:17)(cid:28)(cid:29)(cid:20)(cid:17)(cid:31)(cid:13)(cid:22)(cid:30)(cid:17)(cid:28)(cid:1) m,t m,t 2
between N , N and the interval of angles ∆φ and ∆ϕ
(cid:26)(cid:25)(cid:28)(cid:21)(cid:29)(cid:21)(cid:25)(cid:24)(cid:21)(cid:24)(cid:19)(cid:17)(cid:27)(cid:27)(cid:25)(cid:27)(cid:13)(cid:24)(cid:16)(cid:27)(cid:17)(cid:32)(cid:13)(cid:27)(cid:16) (cid:25)(cid:18)(cid:1)(cid:1)(cid:29)(cid:20)(cid:17)(cid:1)(cid:19)(cid:22)(cid:25)(cid:14)(cid:13)(cid:22)(cid:1)(cid:12)(cid:1)(cid:18)(cid:30)(cid:24)(cid:15)(cid:29)(cid:21)(cid:25)(cid:24) 1 2 m m
φN1−φ1 ϕN2−ϕ1
is N = m,t m,t +1, and N = m,t m,t +1. Then, the
1 ∆φm 2 ∆ϕm
(cid:1)(cid:5)(cid:3)(cid:2)(cid:6)(cid:4) complexity of training the designed ZD-RL method is shown
(cid:9)(cid:20)(cid:17)(cid:4)(cid:8)(cid:29)(cid:27)(cid:13)(cid:24)(cid:28)(cid:23)(cid:21)(cid:29)(cid:28)(cid:29)(cid:20)(cid:17)(cid:28)(cid:17)(cid:21)(cid:24)(cid:18)(cid:25)(cid:27)(cid:23)(cid:13)(cid:29)(cid:21)(cid:25)(cid:24)(cid:29)(cid:25)(cid:13)(cid:19)(cid:17)(cid:24)(cid:29)(cid:28)
in the following proposition.
Fig.3. Theflowchartofimplementation. Proposition 1. The time complexity of training the proposed
ZD-RL method is
2) Implementation Analysis: Next, we explain the imple-
mentation of the proposed ZD-RL method for UAV local-
(cid:32)L−1
(cid:88)
O l l +|o |l +Nl
ization. The proposed ZD-RL method includes an offline i i+1 m,t 1 L
training stage and an online decision-making stage. In the l=1
(cid:32) (cid:32) (cid:33)(cid:32) (cid:33)(cid:33)(cid:33)
offline training phase, as shown in Fig. 3, each controlled φN1 −φ1 ϕN2 −ϕ1
+l N m,t m,t +1 m,t m,t +1 ,
UAV requires 1) the positioning error between the estimated L P ∆φ ∆ϕ
m m
position and the actual position of the target UAV and 2) the
(23)
global Z function value to update its DNN parameters based
on (18) and (19). To calculate the positioning error, the BS where |o m,t| is the size of state space, l i is the number of
needs to collect the distance measurement information rˆ , neurons in hidden layer i, L is the number of hidden layers,
m,t
the transmit power of the active UAV, and the positions of N is the number of elements in the quantile vector.
controlledUAVs.Thedistanceinformationisestimatedbythe Proof: Based on [41], at each iteration, the
signals transmitted from the active UAV to the passive UAV time-complexity of training ZD-RL method is
(cid:16) (cid:17)
and reflected by the target UAV. The transmit power of the O
(cid:80)L−1l
l +|o |l +Nl +|a |l , where
l=1 i i+1 m,t 1 L m,t L
active UAV is notified by the active UAV, and the positions |a | is the size of action space. Since |a | depends on
m,t m,t
of controlled UAVs are transmitted by controlled UAVs. To the interval ∆φ of two adjacent yaw angles and the interval
m
calculate the global Z functions, the BS needs to collect ∆ϕ of two adjacent pitch angles, |a | can be given by
m m,t
individual Z functions as shown in (17) in our training stage.
(cid:32) (cid:33) (cid:32) (cid:33)
Intheonlinedecision-makingstage,thewelltrainedDNNcan |a |=N × φN m1 ,t−φ1 m,t +1 × ϕN m2 ,t−ϕ1 m,t +1 ,
be directly used to determine the transmit power, yaw angle, m,t P ∆φ ∆ϕ
m m
andpitchangleofcontrolledUAVs.Fromtheimplementation (24)
process, we see that the ZD-RL method enables each agent to where N = 1 when m = 1,··· ,4. This is because we only
P
train their deep neural networks parallelly and distributively. consider optimizing the transmit power of the active UAV
Hence, the designed ZD-RL method can be directly used in and the transmit power of passive UAVs are constant. Based
the scenario with more passive or active UAVs. In particular, on (24), the time-complexity of training the proposed ZD-RL
when the number of agents increases, after all agents select method is
and take actions, the BS will collect values of all individual Z (cid:32)L−1
functionsfromagentstocalculatetheglobalZfunctionvalues O (cid:88) l l +|o |l +Nl
i i+1 m,t 1 L
and collect positions and distance measurement information
l=1
of all agents to calculate the positioning error of the target (cid:32) (cid:32) φN1 −φ1 (cid:33)(cid:32) ϕN2 −ϕ1 (cid:33)(cid:33)(cid:33)
UAV. Thus, the ZD-RL method can adapt to the increase in +l N m,t m,t +1 m,t m,t +1 .
L P ∆φ ∆ϕ
the number of agents and enables the system to maintain its m m
localization performance. (25)
3) Complexity Analysis: The complexity of the proposed This completes the proof. □
algorithm lies in training the DNN of each controlled UAV. From proposition 1, we see that as the interval ∆φ and
m
To analyze the complexity of training the designed ZD-RL ∆ϕ of two adjacent angles decreases, the time-complexity
m
method, we first assume that the value of the transmit power of training the proposed ZD-RL method at each iteration
p m,t of controlled UAV m at time slot t is selected from a increases and hence the number of iterations that the ZD-RL
(cid:110) (cid:111)
set of p1 ,··· ,pNP , the yaw angle φ of controlled method required to converge increases. However, when the
m,t m,t m,t
(cid:110) (cid:111) intervals ∆φ and ∆ϕ increases, the controlled UAVs may
UAV m is selected from a set φ1 ,··· ,φN1 , and the m m
m,t m,t find better yaw angles and pitch angles for the target UAV
(cid:110) (cid:111)
pitch angle ϕ is selected from a set ϕ1 ,··· ,ϕN1 localization thus improving localization performance.
m,t m,t m,tIV. CONTROLLEDUAVDEPLOYMENTFORTARGETUAV TABLEII
LOCALIZATION PARAMETERS
In this section, we aim to find the positions of contrlled Parameters Values Parameters Values
UAVs that can minimum the positioning error of the target c 3e8 m/s pm,t 5W
ϵ2 -95dBm W 1MHz
UAV.Ateachtimeslot,therelationshipbetweenthepositions
(cid:0) σB (cid:1)2 8.41 (cid:0) σB (cid:1)2 33.78
ofcontrolledUAVsandthedistancer fromtheactiveUAV LoS NLoS
m,t Emax 100kJ ξ 1s
to the target UAV and then from the target UAV to passive L min 100m Lmax 10km
UAV m is given by ϕ min −15o ϕmax 15o
φ
min
−15o φmax 15o
r
m,t
=d m,t(u m,t,s t)+d 0,t(u 0,t,s t), (26) DB 5bit V 30
µB 2 µB 2.4
LoS NLoS
Taking differentiation at both sides of (26), we have Y 0.13 X 11.9
(cid:18) (cid:19)
dr = x t−x m,t + x t−x 0,t dx TABLEIII
m,t d d t HYPERPARAMETERS
m,t 0,t
(cid:18) (cid:19)
y −y y −y Hyperparameters Values
+ t m,t + t 0,t dy
d d t Discountedfactorγ 0.9
m,t 0,t Thenumberofhiddenlayersofeachagent 2
(cid:18) (cid:19)
+ z t−z m,t + z t−z 0,t dz , m=1,2,3,4. Thenumberofneuronsofeachhiddenlayer 64
d d t Learningrate 0.0005
m,t 0,t
Thesizeofabatch 512
(27)
Thenumberofepisodesofthetargetnetworkperupdate 200
Thesizeofthereplaybuffer 2000
Then, we can rewrite (27) as
d = d = d = d = L ), the positioning error can
dr =Mds (28) 1,t 2,t 3,t 4,t min
t t
be minimized.
where dr = [dr ,dr ,dr ,dr ]T, ds = BasedonTheorem2,next,wecanalsoderivetheminimum
t 1,t 2,t 3,t 4,t t
[dx ,dy ,dz ]T, and positioning error of the target UAV when the position of
t t t
the active UAV is given, which is shown in the following
M =
proposition.
xt−x1,t + xt−x0,t yt−y1,t + yt−y0,t zt−z1,t + zt−z0,t Lemma 2. Given the positions of the target UAV s and the
d1,t d0,t d1,t d0,t d1,t d0,t t
 

x xt td− −2x x,t2 3, ,t
t
+
+
x xt td− −0x x,t0 0, ,t
t
y yt td− −2y y,t2 3, ,t
t
+
+
y yt td− −0y y,t0 0, ,t
t
z zt td− −2z z,t2 3, ,t
t
+
+
z zt td− −0z z,t0 0, ,t t 
 .
ta ac rt giv ee
t
UU AA VV su a0 ti, st, fyif dt 1h ,te =dis dta 2n ,tce =s f dr 3o ,m
t
=pa dss 4i ,v t,e thU eAV ms int io muth me
 d3,t d0,t d3,t d0,t d3,t d0,t  positioning error of the target UAV is
xt−x4,t + xt−x0,t yt−y4,t + yt−y0,t zt−z4,t + zt−z0,t
d4,t d0,t d4,t d0,t d4,t d0,t 3 √
(29) e = (L +d ) k, (31)
t 2 min 0,t
Based on (28), the positioning error between the esti- where k is a coefficient [33].
mated position sˆ t and the actual position s t of the target Proof: See Appendix C. □
UAV in (13) at time slot t can be expressed as e t = FromLemma2,weseethatwhenthepositionsoftheactive
(cid:113)
(dx )2+(dy )2+(dz )2 [42]. Hence, we have e = UAV and the target UAV are given, the minimum positioning
t t t t
(cid:113) tr(cid:0)E(cid:2) ds dsT(cid:3)(cid:1) ,wheretr(·)isthetraceofthematrix.Then, error only depends on the distance L min between each passive
t t UAV and the target UAV.
the minimum value of the positioning error e of the target
t
UAV is shown in the following proposition. V. SIMULATIONRESULTSANDANALYSIS
Theorem 2. If the distances between passive UAVs and the
For our simulations, five controlled UAVs and a BS jointly
target UAV satisfy d = d = d = d , the minimum
1,t 2,t 3,4 4,t localize a target UAV. The moving speed of each controlled
positioning error of the target UAV e is
t UAV is v = 10 m/s and the time duration of a time
m,t
(cid:115) (cid:18)(cid:16) (cid:17)−1(cid:19) slot is ∆ t = 1 s. We use the TSWLS method to estimate
e = 4k(L )2tr MTM . (30) the position of the target UAV at each time slot [32]. Other
t min
system parameters are listed in Table II and the training
Proof: See Appendix B. □ hyperparameters are listed in Table III. For comparison, we
consider five baselines: a) independent DRL method in which
From Theorem 2, we can see that the minimum positioning
error of the target UAV depends on the safety distance L each controlled UAV uses a DQN to optimize its trajectory
min
without considering other controlled UAVs’ movements and
between any two UAVs in constraint (13e), and the value of
(cid:18)(cid:16) (cid:17)−1(cid:19) b) VD-RL method in which controlled UAVs collaboratively
tr MTM which relies on the positions of controlled
determine their trajectories to minimize positioning errors by
UAVs. Theorem 2 also shows that as the distance between summing individual Q function values to approximate the
each controlled UAV and the target UAV is minimum (i.e., global Q function value [25].(a) (b) (c)
(d) (e) (f)
(g) (h) (i)
(j) (k) (l)
Fig.4. TheactualtrajectoriesofthetargetUAVandtheestimatedtrajectoriesobtainedbydifferentmethods.
Fig. 4 shows the actual and the estimated trajectories of the 4(a), 4(b), and 4(c), the target UAV moves in a straight line
target UAV obtained by the considered algorithms. In Figs. fromthestatingposition(500m,500m,100m)to(789m,500TABLEIV
TRAININGCOMPLEXITY 25
Proposed ZD-RL
VD-RL
Methods Timeperiteration(s) Iterations
ZD-RL 0.0090 180800 20 Independent DRL
Theoretical minimum value
VD-RL 0.0083 216200
Qtran 0.0079 218200
15
IndependentDRL 0.0081 224200
Mappo 0.0147 301800
10
50
Proposed ZD-RL
45 VD-RL
5
Independent DRL
40
35 0
100 200 300 400 500 600 700 800 900 1000
30 Distance between each passive UAV and the target UAV (m)
Fig.6. Valueofthepositioningerrorasthedistancebetweeneachcontrolled
25
UAVandthetargetUAVvaries.
20
target UAV increases, the positioning errors of the considered
15 algorithms increase. This is due to the fact that as the speed
10 of the target UAV increases, controlled UAVs cannot follow
the target UAV and the distances between the target UAV and
5
8 10 12 14 16 18 20 22 controlledUAVsincrease.Fig.5alsoshowsthattheproposed
Speed of the target UAV (m/s) ZD-RL method can achieve up to 28.9% and 39.6% gains
Fig.5. ValueofthepositioningerrorasthespeedofthetargetUAVvaries. in terms of the positioning accuracy compared to the VD-
RLmethodandindependentDRLmethod,respectively,inthe
m, 116 m) and five controlled UAVs are randomly distributed case that the target UAV moving at the speed of 22 m/s. The
in a sphere of radius 1000 m centered on the target UAV. In 28.9%gainstemsfromthefactthattheVD-RLmethodobtains
Figs.4(d),4(e),and4(f),thetargetUAVmovesinthecurveof the global value function by linearly calculating the sum of
“C”. In Figs. 4(g), 4(h), and 4(i), the target UAV follows the the expected value of future rewards at each controlled UAV.
curve of “S”. In Figs. 4(j), 4(k), and 4(l), the real trajectory However,theproposedZD-RLmethodcalculatestheglobalZ
of the target UAV is generated by its movement from the functionusingasetofglobalZfunctions,whichcontainsmore
startingposition(0m,0m,333m)andthetargetUAVselects interaction information with the environment thus being able
the pitch angle and yaw angle randomly at each time slot. to select pitch angle and yaw angle for controlled UAVs and
From Fig. 4, we can also see that the gaps between the real optimize the transmit power for the target UAV to localize
trajectoriesandestimatedtrajectoriesobtainedbytheproposed the target UAV accurately. The 39.6% gain is because the
ZD-RL increase as the trajectories of the target UAV become proposed ZD-RL uses the global observation information and
more complex. This is because as the trajectories of the target global reward generated by the BS to train DNN parameters
UAV becomes more complex, it becomes more difficult for ofeachcontrolledUAVandenablescontrolledUAVstoselect
the proposed ZD-RL method to control the trajectories of accurate actions by learning the movements from each other
controlled UAVs to keep small distances with the target UAV thus improving the localization accuracy cooperatively.
in real time. From Fig. 4, we can also see that the proposed Fig. 6 shows how the average positioning errors change as
method can estimate the target UAV position more accurately thedistancebetweeneachcontrolledUAVandthetargetUAV
compared to the VD-RL, and independent DRL method. As varies. In this simulation, the target UAV moves in the curve
the target UAV moves from the initial position to the end of “S” and the distances between each controlled UAV and
position,thegapbetweentheactualpositionsandthepositions the target UAV satisfy d = d = d = d . The yellow
1,t 2,t 3,t 4,t
estimated by the proposed ZD-RL method is small while the line in Fig. 6 represents the theoretically analytical result of
gap resulting from each baseline increases. This is due to the minimum positioning error obtained by Lemma 2. In Fig.
the fact that, the proposed ZD-RL method enables controlled 6, we can see that the minimum positioning error obtained by
UAVs to cooperatively select the pitch angle and yaw angle the proposed ZD-RL method is 1.61 m while the theoretical
based on the global Z function, which is generated by the BS positioning error is 1.18 m when d = 100 m. Hence, there
m,t
usingasetofindividualZfunctionsthustheproposedZD-RL is a gap between the theoretical and the simulation results.
method can accurately optimize the trajectories of controlled This is because the measurement information estimated by
UAVsintimetotrackthetargetUAVasthetargetUAVmoves passive UAVs may have errors and the controlled UAVs may
in different trajectories. not be able to keep the minimum safety distance with the
Fig.5showshowthepositioningerrorchangesasthespeed target UAV in real time. From Fig. 6, we can also see that
of the target UAV varies when the target UAV moves in the the positioning errors of considered algorithms increase as
curve of “S” . In Fig. 5, we can see that as the speed of the the distance between each controlled UAV and the target
)m(
rorrE
gninoitisoP
)m(
rorre
gninoitisoP30 1.4
Proposed ZD-RL Proposed ZD-RL
VD-RL VD-RL
25 Independent DRL 1.2 Independent DRL
1
20
0.8
15
0.6
10
0.4
5
0.2
0
0 2 4 6 8 10 30 40 50 60 70
SNR (dB) Number of time slots at one tracking process
Fig.7. ValueofthepositioningerrorastheSNRofsignalstransmittedfrom Fig.8. Averagepositioningerrorasthenumberoftimeslotsatonetracking
thetargetUAVtopassiveUAVsvaries.(d1,t =d2,t =d3,t =d4,t =900 processvaries.
m)
18
UAV increases. This stems from the fact that the SNR of
Trajectory "S"
signals transmitted from the active UAV to each passive Trajectory "C"
UAV via the target UAV decreases as the distance between 16
each controlled UAV and the target UAV increase. Fig. 6
also shows that the proposed ZD-RL method can reduce the 14
positioning error by up to 33.6% and 46.7% compared to the
VD-RLandindependentDRLmethodswhend =1000m.
m,t 12
This is because the proposed ZD-RL algorithm enables each
controlled UAV to update its DNN parameters based on the
approximated probability distribution of individual Z function 10
and adjust its trajectory to minimize the positioning error of
the target UAV cooperatively. 8
2 4 6 8 10
Fig. 7 shows how the positioning errors change as the SNR
Number of elements in the quantile vector
of signals transmitted from the active UAV to each passive
Fig. 9. Value of the positioning error as the number of elements N in the
UAVvaries.FromFig.7,wecanseethatasSNRincreases,the
quantile vector varies when the target UAV moves in the curve of “S” and
positioningerrorsobtainedbyconsideredalgorithmsdecrease. “C”.
This stems from the fact that the variance of measurement
error of the ZD-RL increases slower compared to VD-RL
errorsofeachpassiveUAVincreasesasSNRdecreases.Fig.7
and independent DRL methods. This is because the ZD-RL
alsoshowsthattheproposedalgorithmcanreducepositioning
method can approximate the probability distribution of the
errorsbyupto24.3%and37.1%comparedtoVD-RLmethod
sum of future rewards and capture richer information of the
and independent DRL method, respectively, when the SNR is
environment, thus estimating the expected value of the sum
0 dB. This is because the proposed ZD-RL can approximate
of rewards under selected actions more accurately compared
the expected value of the sum of future rewards using a non-
to the VD-RL and independent DRL methods and optimally
linear weight function thus improve approximation accuracy.
adjusting UAV trajectories to reduce the average positioning
FromFig.7,wecanseethatastheSNRofeachpassiveUAV
error.
increases, the positioning error of the target UAV decreases
Fig. 9 shows how the positioning errors obtained by the
slowly. This is because the positioning accuracy of the target
proposed ZD-RL method change as the number of elements
UAV is not only affected by SNRs of passive UAVs, but also
N in the quantile vector varies. From Fig. 9, we can see that
the deployment of controlled UAVs. When SNR is small, the
as the value of N increases, the positioning errors obtained
increase of SNR can significantly decrease the positioning
by the proposed ZD-RL method decrease. This stems from
errors. However, as SNR continues to increases, the impact
the fact that when the number of elements in the quantile
of SNR on positioning errors decreases and the deployment
vectorincreases,eachagentcanobtainmorevaluesofthesum
of controlled UAVs becomes the key factor that introduces of
of future rewards with different quantiles thus approximating
the positioning errors.
the probability distribution of individual Z functions more
Fig. 8 shows how the average positioning error e¯ =
t accurately. Fig. 9 also shows that the positioning error first
(cid:113)
1 (cid:80)V (s −sˆ)2 of the target UAV changes as the num- drops rapidly when the number of quantiles is small and then
V t=1 t t
ber of time slots V at one tracking process varies. From Fig. decreases more slowly as the number of quantiles increases
8, we see that when V increases, the average positioning sufficiently.Thisisbecauseasthenumberofquantilesisquite
)m(
rorre
gninoitisoP
)m(
rorre
gninoitisop
egarevA
)m(
rorre
gninoitisoPSuburban Urban DenseUrban
0 0 0
−20 −20 −20
−40 −40 −40
−60 −60 −60
−80 ZD-RL −80 ZD-RL −80 ZD-RL
VD-RL VD-RL VD-RL
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0
Numberofiterations(×105) Numberofiterations(×105) Numberofiterations(×105)
(a) (b) (c)
Fig.10. Thesumofrewardsasthenumberofiterationsvariesindifferentscenarios.
TABLEV E mF ,t(ϕ m,t) of controlled UAV m at time slot t as [45]
CHANNELCONDITIONS
C ∆
Scenarios Suburban Urban DenseUrban EF (ϕ )= 1 t
(λσLoS,λσNLoS) (0.1,21) (1.0,20) (1.6,23) m,t m,t (cid:114) (cid:0)
vL
(cid:1)2 +(cid:113) (cid:0)
vL
(cid:1)4 +4(cid:0)
vH
(cid:1)4
(32)
m,t m,t m,t
35 +Mgv sinϕ +C (cid:0) vL (cid:1)3 ,
m,t m,t 2 m,t
Proposed ZD-RL
VD-RL
30 Independent DRL where C 1 and C 2 are coefficients [45], v mL ,t = v m,tcosϕ m,t
is the horizontal flight speed, M is the weight of each
25 controlled UAV, g is the acceleration of gravity, and v mH ,t is
the power needed for hovering. Then, under the flight energy
consumption constraint EF ⩽ 500 J, Fig. 11 shows how
20 m,t
the positioning error of the target UAV changes as the speed
of controlled UAVs varies under the maximal flight energy
15
consumption constraint when the target UAV moves in the
curve ‘C’. From Fig. 11, we see that the positioning errors
10
obtained by the considered methods increase as the speed of
8 10 12 14 16 controlled UAVs increases. This stems from the fact that the
Speed of controlled UAVs (m/s) UAV flight energy consumption is proportional to the speed
Fig.11. PositioningerrorasthespeedofcontrolledUAVsvariesunderUAV of controlled UAVs. Thus, the increase of the UAV’s speed
flightenergyconsumptionconstraint.
limits the UAV movement and increases the positioning error
ofthetargetUAV.Fig.11alsoshowsthattheproposedZD-RL
small, the localization performance is mainly limited by the
can reduce the positioning error of the target UAV by up to
factthattheproposedalgorithmcannotaccuratelyapproximate
15.8% and 34.7% compared to VD-RL and independent DRL
theprobabilitydistributionofindividualZfunctions.WhenN
methods when the speed of controlled UAVs is 10 m/s. This
graduallyincreases,themainlimitationshiftsfromthenumber
is because the ZD-RL can estimate the sum of future rewards
of quantiles to the trajectory of the target UAV.
more accurately and thus can optimally adjust the trajectories
Fig.10showshowthesumofrewardsobtainedbytheZD- ofcontrolledUAVstolocalizethetargetUAVundertheenergy
RL and VD-RL methods change as the number of iterations consumption constraint.
varies under different environments (Suburban, Urban, and
Fig. 12 shows how the positioning accuracy changes as
Dense Urban [43]), in which the channel conditions are listed
the number of iterations varies. In this figure, we compare
in Table V. Figs. 10(a), 10(b), and 10(c) show the sum
the proposed method with three other methods: 1) Qmix
of rewards obtained by the ZD-RL and VD-RL methods
method in which the BS uses a mixing network to combine
under these scenarios. From Fig. 10, we see that the ZD-RL
individual Q function values of each controlled UAV into a
can obtain better localization performance than the VD-RL
global Q function value [46], 2) Qtran method that optimizes
method in different environments. This is because the ZD-RL
UAV trajectories by transforming actions of controlled UAVs
calculates the positioning error more accurately compared to
into variables related to individual Q functions [47], and
the VD-RL method in different environments and optimally
3) Mappo method in which each controlled UAV optimizes
adjusts the trajectories of controlled UAVs.
its trajectory and controlled UAVs share agents’ experiences
Since limited UAV flight energy affects the UAV trajectory [48]–[50]. From Fig. 12, we see that the proposed ZD-RL
optimization [44], we analyze the localization performance of method can improve the sum of rewards by up to 39.4%,
theZD-RLmethodunderlimitedUAVflightenergyconsump- 54.6%, 64.6%, and 72.9% compared to the VD-RL, Qtran,
tion constraint. We first model the flight energy consumption independent DRL, and Mappo methods, respectively. This
sdrawerfomuS
)m(
rorre
gninoitisoP
sdrawerfomuS sdrawerfomuSTo further reduce the positioning error of the target UAV,
we have derived the relationship between the positions of
0
controlled UAVs and the positioning error of the target UAV.
−20 Based on the derived expression of the positioning error,
we can obtain the minimum positioning error of the target
−40
UAV.Simulationresultshaveshownthattheproposedmethod
−60 yielded significant improvements in terms of the positioning
−80 accuracy compared to baselines.
−100 P Vr Do -p Ro LsedZD-RL APPENDIX
−120 Qmix
Qtran A. Proof of Lemma 1
IndependentDRL
−140
Mappo
We first explain why the proposed ZD-RL method satisfies
1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 condition 1). From (18), the update rule of individual Z
Numberofiterations(×105)
function of controlled UAV m can be given by
Fig.12. Valueofthesumofrewardsasthetotalnumberofiterationsvaries.
stems from the fact that the ZD-RL method can approximate Z (o ,a )=Z (o ,a )+α (R(o ,a )
k+1 m,t m,t k m,t m,t m m,t m,t
the probability distribution of the sum of discounted future +Z(o ,a )−Z(o ,a )).
m,t+1 m,t+1 m,t m,t
rewards to calculate the expected value of the sum of future (33)
rewards more accurately compared to other baseline methods
that estimate the expected value of the sum of future rewards Taking the expectation of individual Z function with respect
directly. Fig. 12 also shows that the proposed ZD-RL method to transition probability distribution P(o′ m|o m,t,a m,t) and
canreducethenumberofiterationsrequiredtoconvergebyup subtracting M∗(o m,t,a m,t) at both sides, we have
to9.0%,12.7%,19.35%,and30.8%comparedtotheVD-RL,
E[Z (o ,a )]−M∗(o ,a )=
Qtran, independent DRL, and Mappo methods. The reason is k+1 m,t m,t m,t m,t
that the proposed method cooperatively train the trajectories (1−α m)(E[Z(o m,t,a m,t)]−M∗(o m,t,a m,t))
(34)
of controlled UAVs and the transmit power of the active UAV +α (R(o ,a )+γE[Z(o ,a )]
m m,t m,t m,t+1 m,t+1
usingtheprobabilitydistributionofthesumoffuturerewards.
−M∗(o ,a )).
m,t m,t
Compared to other baselines that estimate the expected value
of the sum of future rewards, the proposed ZD-RL method Sincee(o ,a )=M(o ,a )−M∗(o ,a )and
m,t m,t m,t m,t m,t m,t
are more stable and accurate thus reducing the number of F (o ,a ) = R(o ,a ) + γM(o ,a ) −
m,t m,t m,t m,t m,t+1 m,t+1
iterations required to convergence. In particular, the number M∗(o ,a ), we have
m,t m,t
of iterations of the considered methods to converge is shown
in Fig. 12 and the tested implementation time per iteration e k+1(o m,t,a m,t)
(35)
of each method is listed in Table IV. The total training times =(1−α )e (o ,a )+α F (o ,a ).
m k m,t m,t m m,t m,t
of the ZD-RL, VD-RL, Qtran, independent DRL, and Mappo
methodstoreachconvergenceare1627.2s,1794.5s,1723.8s, Hence, the proposed ZD-RL method satisfies condition 1).
1816.0 s, and 4436.4 s. Consequently, the ZD-RL can reduce Next, we explain why the proposed ZD-RL method satisfies
the training complexity by up to 9.3%, 5.6%, 10.4%, and condition 2). To prove condition 2), we first find the expected
63.3% compared to VD-RL, Qtran, independent DRL, and value of F (o m,t,a m,t), which is given by
Mappo methods.
E[F (o ,a )]
m,t m,t
VI. CONCLUSION =E[R(o ,a )+γM(o ,a )
m,t m,t m,t+1 m,t+1
In this paper, a novel localization framework that uses −M∗(o ,a )]
m,t m,t
several controlled UAVs to localize a target UAV has been =E[R(o ,a )+γE[Z(o ,a )]]
m,t m,t m,t+1 m,t+1 (36)
proposed. We have modeled this localization problem as an
−E[Z∗(o ,a )]
optimization problem that aims to optimize the positioning m,t m,t
accuracybyjointlyoptimizingthetransmitpoweroftheactive ( =a)E[T (Z(o ,a ))]−E[T (Z∗(o ,a ))]
m,t m,t m,t m,t
UAV and trajectories of all controlled UAVs. To solve this
( =b) T (E[Z(o ,a )])−T (E[Z∗(o ,a )]),
problem, we have proposed a ZD-RL method, which uses m,t m,t m,t m,t
the probability distribution of the sum of future rewards to
whereequation(a)andequation(b)followfromtheresultsin
estimate the expected values of the sum of future rewards
[39, Lemma 4]. According to the results in [39, Lemma 3],
insteadofdirectlyestimatingtheexpectedvaluesofthesumof
we have
futurerewardsasdoneinDeepQ.Hence,theproposedmethod
enableseachcontrolledUAVtofinditsoptimaltransmitpower ||T (E[Z(o ,a )])−T (E[Z∗(o ,a )])||
m,t m,t m,t m,t ∞
(37)
and trajectory to minimize the positioning errors efficiently. ⩽γ||E[Z(o ,a )]−E[Z∗(o ,a )]|| .
m,t m,t m,t m,t ∞
sdrawerfomuSBased on (37), (36) can be written as Based on (40) and (41), we have
||E[F (o m,t,a m,t)]||
∞
Var(E[F (o m,t,a m,t)])⩽C F(cid:0) 1+||e(o m,t,a m,t)||2 ∞(cid:1) ,
=||T (E[Z(o ,a )])−T (E[Z∗(o ,a )])|| (42)
m,t m,t m,t m,t ∞ where C is the maximal value of 2γ2||M∗(o a )|| +
⩽γ||E[Z(o m,t,a m,t)]−E[Z∗(o m,t,a m,t)]|| ∞ γ2||M∗(F o ,a )||2 and γ2(1+2||M∗(om,t ,am,t )|∞ | ).
m,t m,t ∞ m,t m,t ∞
=γ||M(o m,t,a m,t)−M∗(o m,t,a m,t)|| ∞ Hence, condition 3) is satisfied. This completes the proof.
=γ||e(o m,t,a m,t)|| ∞. B. Proof of Theorem 2
(38) (cid:113)
Since e =
tr(cid:0)E(cid:2)
ds
dsT(cid:3)(cid:1)
, we first calculate the value
t t t
Hence, condition 2) is satisfied. For condition 3), using (36), of E(cid:2) ds dsT(cid:3) . From (28), we have
Var(E[F (o ,a )]) can be rewritten as t t
m,t m,t (cid:16) (cid:17)−1
ds = MTM MTdr , (43)
Var(E[F (o ,a )]) t t
m,t m,t
(cid:104) (cid:105) and the positioning error e of the target UAV at time slot t
=E (F (o ,a )−E[F (o ,a )])2 t
m,t m,t m,t m,t can be rewritten as
=E[F (o m,t,a m,t) E(cid:2) ds tdsT
t
(cid:3)
−(T (M(o ,a ))−T (M∗(o ,a )))2(cid:105) (cid:34) (cid:16) (cid:17)−1 (cid:18)(cid:16) (cid:17)−1 (cid:19)T(cid:35)
m,t m,t m,t m,t =E MTM MTdr MTM MTdr
t t
=E[R(o ,a )+γM(o ,a )
m,t m,t m,t+1 m,t+1
−(R(o m,t,a m,t)+γE[M(o m,t,a m,t)])2(cid:105) =E(cid:34) (cid:16) MTM(cid:17)−1 MTdr drT (cid:18)(cid:16) MTM(cid:17)−1 MT(cid:19)T(cid:35)
t t
(cid:104) (cid:105)
=γ2E (M(o ,a )−E[M(o ,a )])2
=γ2Var(E[Mm (, ot+ m1 ,t+m 1,, at+ m1 ,t+1)]) m,t m,t =(cid:16) MTM(cid:17)−1 MTE(cid:2) dr tdrT t (cid:3)(cid:18)(cid:16) MTM(cid:17)−1 MT(cid:19)T ,
(cid:104) (cid:105)
⩽γ2E M(o ,a )2 (44)
m,t+1 m,t+1
(cid:16) (cid:17)−1
⩽γ2max,max(M(o m,t,a m,t))2 where MT is a transpose matrix of M, MTM
⩽γ2||o em (, ot am ,, at )+M∗(o ,a )||2 is an inverse matrix of MTM, E(cid:2) dr tdrT t (cid:3) =
m,t m,t m,t m,t ∞ diag(cid:0) σ2 ,σ2 ,σ2 ,σ2 (cid:1) with σ2 = k(d +d )2
=γ2||e(o ,a )||2 +γ2||M∗(o ,a )||2 1,t 2,t 3,t 4,t m,t m,t 0,t
m,t m,t ∞ m,t m,t ∞ being the variance of the independent Gaussian measurement
+2γ2||e(o m,t,a m,t)|| ∞||M∗(o m,t,a m,t)|| ∞. errorofpassiveUAVmattimeslottandkbeingacoefficient
(39) [33]. Since d = d = d = d , E(cid:2) dr drT(cid:3) can be
1,t 2,t 3,t 4,t t t
rewritten as
Since the value of Var(E[F (o ,a )]) depends on
m,t m,t
||e(o ,a )|| , next, we calculate the maximum E(cid:2) dr drT(cid:3) =k(d +d )2I, (45)
m,t m,t ∞ t t m,t 0,t
value of Var(E[F (o ,a )]) according to the
m,t m,t where I = diag(1,1,1,1). Substituting (45) into (44), we
value of ||e(o ,a )|| ⩽ 1. In particular, when
m,t m,t have
||e(o m,t,a m,t)|| ∞ ⩽1, (39) can be written as E(cid:2) ds dsT(cid:3)
t t
γ2||e(o m,t,a m,t)||2 ∞+γ2||M∗(o m,t,a m,t)||2 ∞ =k(d +d )2(cid:16) MTM(cid:17)−1 MT (cid:18)(cid:16) MTM(cid:17)−1 MT(cid:19)T
+2γ2||e(o ,a )|| ||M∗(o ,a )|| m,t 0,t
m,t m,t ∞ m,t m,t ∞
⩽γ2||e(o m,t,a m,t)||2 ∞+2γ2||M∗(o m,t,a m,t)||
∞ (40) =k(d m,t+d
0,t)2(cid:16) MTM(cid:17)−1 MTM(cid:16) MTM(cid:17)−1
+γ2||M∗(o ,a )||2
m,t m,t ∞ (cid:16) (cid:17)−1
⩽γ2(cid:0) ||M∗(o ,a )||2 +2||M∗(o ,a )|| (cid:1) =k MTM .
m,t m,t ∞ m,t m,t ∞
×(cid:0) 1+||e(o ,a )||2 (cid:1) . (46)
m,t m,t ∞
Based on (46), the positioning error e of the target UAV
If ||e(o ,a )|| ⩾ 1, we have ||e(o ,a )|| ⩽ t
m,t m,t ∞ m,t m,t ∞ can be given by
||e(o ,a )||2 and (39) can be rewritten as
m,t m,t ∞ (cid:115)
(cid:18) (cid:16) (cid:17)−1(cid:19)
γ2||e(o m,t,a m,t)||2 ∞+γ2||M∗(o m,t,a m,t)||2 ∞ e t = tr k(d m,t+d 0,t)2 MTM
+2γ2||e(o m,t,a m,t)|| ∞||M∗(o m,t,a m,t)|| ∞ (cid:115) (cid:18)(cid:16) (cid:17)−1(cid:19)
⩽γ2(1+2||M∗(o m,t,a m,t)|| ∞)||e(o m,t,a m,t)||2
∞
= k(d m,t+d 0,t)2tr MTM (47)
+γ2||M∗(o ,a )||2
m,t m,t ∞ (cid:115)
⩽γ2(1+2||M∗(o m,t,a m,t)|| ∞)(cid:0) 1+||e(o m,t,a m,t)||2 ∞(cid:1) . ( ⩾a)
4kL2
tr(cid:18)(cid:16) MTM(cid:17)−1(cid:19)
,
(41) minwhere equation (a) stems from the fact that the distance d where equation (a) stems from the fact that d = d =
m,t 1,t 2,t
between each controlled UAV and the target UAV satisfy d =d . Substituting (51) into (50), we have
3,t 4,t
d ⩾ L ,m = 0,··· ,4, according to constraint (13e). (cid:115)
m,t min (cid:18) (cid:19)
3
TT hh ie sre cf oo mre p, lee tq eu sa tt hio en p( ra o) ofi .s hold when d m,t = d 0,t = L min. e t = k(d m,t+d 0,t)23 4
(cid:114)
C. Proof of Lemma 2 9 (52)
= k(d +d )2
Given the positions s and u , the distance d between 4 m,t 0,t
t 0,t 0,t
the target UAV and the active UAV is a constant and (27) can (a) 3 √
⩾ (L +d ) k,
be rewritten as 2 min 0,t
dr
m,t
= x t d−x m,t dx t+ y t d−y m,t dy t+ z t d−z m,t dz t. sw hh oe wre ne inqu (a 1t 3io en ).( Ta h) isst ce om ms pf lr eo tm
es
t th he
e
pfa rc ot oft .hat d m,t ⩾ L min as
m,t m,t m,t
(48)
REFERENCES
Then, the value of M in Theorem 2 can be rewritten as
[1] Y.Zhu,M.Chen,S.Wang,Y.Liu,andC.Yin,“Trajectorydesignfor3D
 
x −x y −y z −z UAVlocalizationinUAVbasednetworks,”inProc.IEEEInternational
t 1,t t 1,t t 1,t
M = 1  x t−x 2,t y t−y 2,t z t−z 2,t . (49) G Ml ao lb aa yl siaC ,o Dm em c.un 2i 0c 2a 3ti .ons Conference (GLOBECOM), Kuala Lumpur,
d m,t x t−x 3,t y t−y 3,t z t−z 3,t [2] I. Guvenc, F. Koohifar, S. Singh, M. L. Sichitiu, and D. Matolak,
x −x y −y z −z “Detection,tracking,andinterdictionforamateurdrones,”IEEECom-
t 4,t t 4,t t 4,t
municationsMagazine,vol.56,no.4,pp.75–81,Apr.2018.
From (47), the positioning error e can be written
t [3] M. Mozaffari, W. Saad, M. Bennis, Y.-H. Nam, and M. Debbah, “A
(cid:115)
as e =
k(cid:0)
d +d2
(cid:1)
tr(cid:18)(cid:16) MTM(cid:17)−1(cid:19)
. Since
t ou pt eo nria pl roo bn leU mA sV ,”s IEfo Er Ew Cire ol mes ms un ne ictw ato iork ns s: SA up rp veli yc sat &ion Ts u, tc oh ra iall le sn ,g ve os l, .a 2n 1d
,
t m,t 0,t
no.3,pp.2334–2360,Thirdquarter.2019.
(cid:18)(cid:16) (cid:17)−1(cid:19) [4] Z. Yang, C. Pan, M. Shikh-Bahaei, W. Xu, M. Chen, M. Elkashlan,
tr MTM = (cid:80)3 i=1 ϱ1
i
with ϱ i being the eigenvalue a on pd timA i. zN ata ioll nan fa ot rh Uan A, V“ -J eo nin at bla el dtit cu od me, mb ue nam icaw tii od nth s, ,”lo Ic Ea Eti Eon C, oa mnd mb ua nn icd aw tii od nth
s
of MTM [51], e can be rewritten as Letters,vol.22,no.8,pp.1716–1719,June2018.
t
(cid:118) [5] O. Y. Kolawole and M. Hunukumbure, “UAV based 5G indoor lo-
e
=(cid:117) (cid:117)
(cid:116)k(d +d
)2(cid:88)3 1 c Ina tl eiz ra nt aio tin onf ao lr Ae Cm Merg Men oc by ics oe mrvi Wce os r,” kshin opPr oo nc. DP rr oo nc eee Ad sin sig ss tedof Wth ire el5 esth
s
t m,t 0,t ϱ i Communicationsfor5GandBeyond,pp.43–48,NewYork,NY,USA,
i=1
Oct.2022.
(cid:118)
( ⩾a)(cid:117) (cid:117) (cid:117)
(cid:116)k(d m,t+d
0,t)23(cid:32) (cid:89)3 ϱ1 i(cid:33)1 3
(50)
[ [6 7]
]
d oQ F.e n. s HWiW g oinu
r
,e, f Rlo eY .sr.
s
GmZ
C
ee u
o
rn l amtg i l- d, mU ea
u
sAn
n
,Vd
i
AcaR e .tn i. GoaZ nb osh l ne ,a ad vn lvog w el,
.
si“ ,r 1eJ
7
Blo ,ei .sn nst
o
R.n it gr 3ea a,tj w ue
p
lc o
p
tt ,r .o k
2
Br sy 1, .” 0a S9In p–Ed o2E r1c E
t2
io c1m T h,r ,m Ma Dnu asn .yai Kc c 2a t
0
uit oi
1
bo n
8
on s
.
,
i=1
M.Cavazza,andH.Prendinger,“Decentralizedmulti-agentpathfinding
(cid:118)
(cid:117)   forUAVtrafficmanagement,”IEEETransactionsonIntelligentTrans-
( =b)(cid:117) (cid:117) (cid:116)k(d m,t+d 0,t)23 (cid:16) 3 (cid:17), [8] p Zo .r Yta at nio gn , S Cy .st Pem ans ,, Kvo .l. W2 a3 n, gn ,o. an2 d,p Mp. .9 S9 h7 i– k1 h0 -0 B8 a, hF aee ib ,. “2 E0 n2 e2 r. gy efficient
tr MTM resourceallocationinUAV-enabledmobileedgecomputingnetworks,”
IEEE Transactions on Wireless Communications, vol. 18, no. 9, pp.
where equation (a) is achieved by the triangle-inequality and 4576–4589,Sept.2019.
[9] M. Chen, D. Gu¨ndu¨z, K. Huang, W. Saad, M. Bennis, A. V. Feljan,
equation (a) is hold when ϱ = ϱ = ϱ , equation (b)
1 2 3(cid:16) (cid:17) and H. V. Poor, “Distributed learning in wireless networks: Recent
stems from the fact that ϱ + ϱ + ϱ = tr MTM and progress and future challenges,” IEEE Journal on Selected Areas in
1 2 3
(cid:16) (cid:17) Communications,vol.39,no.12,pp.3579–3605,Dec.2021.
ϱ = 1tr MTM when ϱ = ϱ = ϱ . Based on (49), [10] J.Gui,T.Yu,B.Deng,X.Zhu,andW.Yao,“Decentralizedmulti-UAV
i 3 1 2 3
(cid:16) (cid:17) cooperative exploration using dynamic centroid-based area partition,”
tr MTM is given by DRONES,vol.7,no.6,Jun.2023.
[11] H. Sier, X. Yu, I. Catalano, J. P. Queralta, Z. Zou, and T. Westerlund,
(cid:16) (cid:17)
tr MTM “UAV tracking with Lidar as a camera sensors in GNSS-denied envi-
ronments,”https://arxiv.org/abs/2303.00277,Mar.2023.
(cid:32) 4 4 [12] Z.Xu,X.Zhan,Y.Xiu,C.Suzuki,andK.Shimada,“Onboarddynamic-
= 1 (cid:88) (x −x )2+ (cid:88) (y −y )2 object detection and tracking for autonomous robot navigation with
d2 t m,t t m,t RGB-Dcamera,”https://arxiv.org/abs/2303.00132,Feb.2023.
m,t m=1 m=1 [13] P.SinhaandI.Guvenc,“ImpactofantennapatternonTOAbased3D
4 (cid:33) UAVlocalizationusingaterrestrialsensornetwork,”IEEETransactions
+ (cid:88) (z −z )2 onVehicularTechnology,vol.71,no.7,pp.7703–7718,Apr.2022.
t m,t [14] U.Bhattacherjee,E.Ozturk,O.Ozdemir,I.Guvenc,M.L.Sichitiu,and
m=1 H.Dai,“ExperimentalstudyofoutdoorUAVlocalizationandtracking
=
1 (cid:88)4 (cid:16)
(x −x )2+(y −y )2+(z −z
)2(cid:17)
[15]
u F.si Wng enp ,as Js .i Sve hiR ,F G.se Gn usi in ,g H,” .Ght atp cs a: n/ i/ na ,rx ai nv. dor Og ./a Abs ./ D21 o0 b8 re.0 ,7 “8 35 -7 D,S poep sit t. io2 n0 i2 n2 g.
d2
m,t m=1
t m,t t m,t t m,t
methodforanonymousUAVbasedonbistaticpolarizedMIMOradar,”
(cid:32) 4 (cid:33) IEEEInternetofThingsJournal,vol.10,no.1,pp.815–827,Sept.2023.
= d21 (cid:88) d2 m,t ( =a) 4, [16] oS f. mX uu l, tiK pl. eD Uo Ag Van sa fy o, ra And OAH. taH rgm etam lo, ca“ lD izi as tt ir oi nbu ,”te id n p Pa rt oh c.o 2p 0ti 1m 6iz Ia Eti Eo En
m,t m=1 International Conference on Acoustics, Speech and Signal Processing
(51) (ICASSP),pp.3141–3145,Shanghai,China,May2016.[17] M.SilicandK.Mohseni,“Anexperimentalevaluationofradiomodels [37] W.Dabney,M.Rowland,M.Bellemare,andR.Munos,“Distributional
forlocalizingfixed-wingUAVsinruralenvironments,”IEEETransac- reinforcementlearningwithquantileregression,”inProc.theAAAICon-
tionsonVehicularTechnology,vol.72,no.5,pp.5576–5586,May2023. ference on Artificial Intelligence, 32(1), pp. 2892–2901, New Orleans,
[18] M. Sadeghi, F. Behnia, and R. Amiri, “Optimal geometry analysis USA,Oct.2018.
for TDOA-based localization under communication constraints,” IEEE [38] J.Zhao,Y.Zhu,X.Mu,K.Cai,Y.Liu,andL.Hanzo,“Simultaneously
TransactionsonAerospaceandElectronicSystems,pp.3096–3106,Oct. transmittingandreflectingreconfigurableintelligentsurface(STAR-RIS)
2021. assisted UAV communications,” IEEE Journal on Selected Areas in
[19] A. Gendia, O. Muta, S. Hashima, and K. Hatano, “UAV positioning Communications,vol.40,no.10,pp.3041–3056,Oct.2022.
with joint NOMA power allocation and receiver node activation,” in [39] M.G.Bellemare,W.Dabney,andR.Munos,“Adistributionalperspec-
Proc. IEEE Annual International Symposium on Personal, Indoor and tive on reinforcement learning,” https://arxiv.org/abs/1707.06887, Jul.
Mobile Radio Communications (PIMRC), pp. 240–245, Kyoto, Japan, 2017.
Dec.2022. [40] T. Jaakkola, M. I. Jordan, and S. P. Singh, “On the convergence of
[20] V. Saj, B. Lee, D. Kalathil, and M. Benedict, “Robust reinforce- stochasticiterativedynamicprogrammingalgorithms,”NeuralCompu-
ment learning algorithm for vision-based ship landing of UAVs,” tation,vol.6,no.6,pp.1185–1201,Nov.1994.
https://arxiv.org/abs/2209.08381,Sept.2022. [41] S.Wang,M.Chen,Z.Yang,C.Yin,W.Saad,S.Cui,andH.V.Poor,
[21] V. Tilwari and S. Pack, “Autonomous 3D UAV localization using “Distributedreinforcementlearningforageofinformationminimization
taylor series linearized TDOA-based approach with machine learning in real-time IoT systems,” IEEE Journal of Selected Topics in Signal
algorithms,” in Proc. International Conference on Information and Processing,vol.16,no.3,pp.501–515,Jan.2022.
Communication Technology Convergence (ICTC), pp. 783–785, Jeju [42] H. Godrich, A. M. Haimovich, and R. S. Blum, “Target localization
Island,Korea,Nov.2022. accuracy gain in MIMO radar-based systems,” IEEE Transactions on
[22] B. Joshi, D. Kapur, and H. Kandath, “Sim-to-real deep reinforcement InformationTheory,vol.56,no.6,pp.2783–2803,May2010.
learningbasedobstacleavoidanceforUAVsundermeasurementuncer- [43] A. Al-Hourani, S. Kandeepan, and S. Lardner, “Optimal LAP altitude
tainty,”https://arxiv.org/abs/2303.07243,Mar.2023. formaximumcoverage,”IEEEWirelessCommunicationsLetters,vol.3,
[23] C. Wang, J. Wang, Y. Shen, and X. Zhang, “Autonomous navigation no.6,pp.569–572,Dec.2014.
of UAVs in large-scale complex environments: A deep reinforcement [44] N.Lin,Y.Fan,L.Zhao,X.Li,andM.Guizani,“Green:Aglobalenergy
learningapproach,”IEEETransactionsonVehicularTechnology,vol.68, efficiencymaximizationstrategyformulti-UAVenabledcommunication
no.3,pp.2124–2136,Shanghai,China,Mar.2019. systems,”IEEETransactionsonMobileComputing,vol.22,no.12,pp.
[24] Y.Hu,M.Chen,W.Saad,H.V.Poor,andS.Cui,“Distributedmulti- 7104–7120,Dec.2023.
agent meta learning for trajectory design in wireless drone networks,” [45] Y. Sun, D. Xu, D. W. K. Ng, L. Dai, and R. Schober, “Optimal 3D-
IEEE Journal on Selected Areas in Communications, vol. 39, no. 10, trajectory design and resource allocation for solar-powered UAV com-
pp.3177–3192,Oct.2021. munication systems,” IEEE Transactions on Communications, vol. 67,
[25] P. Sunehag, G. Lever, A. Gruslys, W. M. Czarnecki, V. Zambaldi, no.6,pp.4281–4298,June2019.
M. Jaderberg, M. Lanctot, N. Sonnerat, J. Z. Leibo, and K. Tuyls, [46] T. Rashid, M. Samvelyan, C. S. de Witt, G. Farquhar, J. Foerster, and
“Value-decomposition networks for cooperative multi-agent learning,” S. Whiteson, “QMIX: Monotonic value function factorisation for deep
https://arxiv.org/abs/1706.05296,June2017. multi-agent reinforcement learning,” https://arxiv.org/abs/1803.11485,
[26] Y. Chan and K. Ho, “A simple and efficient estimator for hyperbolic June2018.
location,” IEEE Transactions on Signal Processing, vol. 42, no. 8, pp. [47] K. Son, D. Kim, W. J. Kang, D. E. Hostallero, and Y. Yi, “QTRAN:
1905–1915,Aug.1994. Learning to factorize with transformation for cooperative multi-agent
[27] W.Huang,H.Guo,andJ.Liu,“TaskoffloadinginUAVswarm-based reinforcementlearning,”https://arxiv.org/abs/1905.05408,May2019.
edge computing: Grouping and role division,” in Proc. 2021 IEEE [48] C. Yu, A. Velu, E. Vinitsky, J. Gao, Y. Wang, A. Bayen, and Y. Wu,
Global Communications Conference (GLOBECOM), pp. 1–6, Madrid, “ThesurprisingeffectivenessofPPOincooperative,multi-agentgames,”
SpainDec.2021. https://arxiv.org/abs/2103.01955,Nov2022.
[28] J.Sabzehali,V.K.Shah,Q.Fan,B.Choudhury,L.Liu,andJ.H.Reed, [49] J.G.Kuba,R.Chen,M.Wen,Y.Wen,F.Sun,J.Wang,andY.Yang,
“Optimizing number, placement, and backhaul connectivity of multi- “Trustregionpolicyoptimisationinmulti-agentreinforcementlearning,”
UAV networks,” IEEE Internet of Things Journal, vol. 9, no. 21, pp. https://arxiv.org/abs/2109.11251,Apr.2022.
21548–21560,Nov.2022. [50] C. Yu, A. Velu, E. Vinitsky, J. Gao, Y. Wang, A. Bayen, and Y. Wu,
[29] A.Albanese,P.Mursia,V.Sciancalepore,andX.Costa-Perez,“PAPIR: “ThesurprisingeffectivenessofPPOincooperative,multi-agentgames,”
PracticalRIS-aidedlocalizationviastatisticaluserinformation,”inProc. https://arxiv.org/abs/2103.01955,Nov.2022.
International Workshop on Signal Processing Advances in Wireless [51] M. Zhang and J. Zhang, “A fast satellite selection algorithm: Beyond
Communications(SPAWC),pp.531–535,Lucca,Italy,Nov.2021. four satellites,” IEEE Journal of Selected Topics in Signal Processing,
[30] Y.ZengandR.Zhang,“Energy-efficientUAVcommunicationwithtra- vol.3,no.5,pp.740–747,Oct.2009.
jectoryoptimization,”IEEETransactionsonWirelessCommunications,
vol.16,no.6,pp.3747–3760,Mar.2017.
[31] X. Tong, Z. Zhang, Y. Zhang, Z. Yang, C. Huang, K.-K. Wong, and
M. Debbah, “Environment sensing considering the occlusion effect: A
multi-viewapproach,”IEEETransactionsonSignalProcessing,vol.70,
pp.3598–3615,June2022.
[32] Y. Chan and K. Ho, “A simple and efficient estimator for hyperbolic
location,” IEEE Transactions on Signal Processing, vol. 42, no. 8, pp.
1905–1915,Aug.1994.
[33] A.Quazi,“Anoverviewonthetimedelayestimateinactiveandpassive
systemsfortargetlocalization,”IEEETransactionsonAcoustics,Speech,
andSignalProcessing,vol.29,no.3,pp.527–533,June1981.
[34] Y. Su, H. Zhou, Y. Deng, and M. Dohler, “Energy-
efficient cellular-connected UAV swarm control optimization,”
https://arxiv.org/abs/2303.10398,Mar.2023.
[35] W. Dabney, G. Ostrovski, D. Silver, and R. Munos, “Implicit quantile
networks for distributional reinforcement learning,” in Proc. Inter-
national Conference on Machine Learning (ICML), pp. 2640–3498,
Stockholm,Sweden,Jun.2018.
[36] W.-F. Sun, C.-K. Lee, and C.-Y. Lee, “DFAC framework: Factorizing
the value function via quantile mixture for multi-agent distributional
Q-learning,” in Proc. International Conference on Machine Learning
(ICML),pp.9945–9954,Vienna,Austria,Dec.2021.