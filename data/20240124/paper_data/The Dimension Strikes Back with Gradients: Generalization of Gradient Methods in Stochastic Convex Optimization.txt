The Dimension Strikes Back with Gradients: Generalization of
Gradient Methods in Stochastic Convex Optimization
Matan Schliserman Uri Sherman Tomer Koren
January 23, 2024
Abstract
We study the generalization performance of gradient methods in the fundamental stochas-
tic convex optimization setting, focusing on its dimension dependence. First, for full-batch
2
gradient descent (GD) we give a construction of a learning problem in dimension d = O(n ),
wherethecanonicalversionofGD(tunedforoptimalperformanceoftheempiricalrisk)trained
with n training examples converges, with constant probability, to an approximate empirical
risk minimizer with Ω(1) population excess risk. Our bound translates to a lower bound of
Ω(√d) on the number of training examples required for standard GD to reach a non-trivial
test error, answering an open question raised by Feldman (2016) and Amir, Koren, and Livni
(2021b) and showing that a non-trivial dimension dependence is unavoidable. Furthermore,
for standard one-pass stochastic gradient descent (SGD), we show that an application of the
same construction technique provides a similar Ω(√d) lower bound for the sample complexity
of SGD to reacha non-trivialempirical error,despite achieving optimal test performance. This
againprovidesanexponentialimprovementin the dimensiondependence comparedto previous
work (Koren, Livni, Mansour, and Sherman, 2022), resolvingan open question left therein.
1 Introduction
The study of generalization properties of stochastic optimization algorithms has been at the heart
of contemporary machine learning research. While in the more classical frameworks studies largely
focused on the learning problem (e.g., Alon et al., 1997; Blumer et al., 1989), in the past decade it
has become clear that in modern scenarios the particular algorithm used to learn the model plays
a vital role in its generalization performance. As a prominent example, heavily over-parameterized
deep neuralnetworks trained by firstordermethods outputmodels that generalize well, despite the
fact thatan arbitrarily chosen EmpiricalRisk Minimizer (ERM)may performpoorly (Zhang et al.,
2017; Neyshabur et al., 2014, 2017). The present paper aims at understanding the generalization
behavior of gradient methods, specifically in connection with the problem dimension, in the funda-
mentalStochasticConvexOptimization(SCO)learningsetup;awellstudied,theoreticalframework
widely used to study stochastic optimization algorithms.
The seminal work of Shalev-Shwartz et al. (2010) was the first to show that uniform con-
vergence, the canonical condition for generalization in statistical learning (e.g., Vapnik, 1971;
Bartlett and Mendelson, 2002) may not hold in high-dimensional SCO: they demonstrated learn-
ing problems where there exist certain ERMs that overfit the training data (i.e., exhibit large
population risk), while models producedby e.g., Stochastic Gradient Descent (SGD) or regularized
empirical risk minimization generalize well. The construction presented by Shalev-Shwartz et al.
(2010), however, featured a learning problem with dimension exponential in the number of training
1
4202
naJ
22
]GL.sc[
1v85021.1042:viXraexamples, which only served to prove an Ω(logd) lower bound on the sample complexity for reach-
ing non-trivial population risk performance, where d is the problem dimension. In a followup work,
Feldman (2016) showed how to dramatically improve the dimension dependenceand established an
Ω(d) sample complexity lower bound, matching (in terms of d) the well-known upper bound ob-
tained from standard covering number arguments (see e.g., Shalev-Shwartz and Ben-David, 2014).
Despite settling the dimension dependence of uniform convergence in SCO, it remained unclear
from Shalev-Shwartz et al. (2010); Feldman (2016) whether the sample complexity lower bounds
for uniform convergence actually transfer to natural learning algorithms in this framework, and in
particular, to common gradient-based optimization methods. Indeed, it is well-known that in SCO
there exist simple algorithms, such as SGD, that the models they produce actually generalize well
with high probability (see e.g., Shalev-Shwartz and Ben-David, 2014), despite these lower bounds.
More technically, the construction of Feldman (2016) relied heavily on the existence of a “peculiar”
ERM which does not seem reachable by gradient steps from a data-independent initialization, and
it was not at all clear (and in fact, stated as an open problem in Feldman, 2016) how to adapt the
construction so as to pertain to ERMs that could be found by gradient methods.
In an attempt to address this issue, Amir et al. (2021b) recently studied the population per-
formance of batch Gradient Descent (GD) in SCO, and demonstrated problem instances where it
leads (with constant probability) to an approximate ERM that generalizes poorly, unless the num-
ber of training examples is dimension-dependent.1 Subsequently, Amir et al. (2021a) generalized
this result to the more general class of batch first-order algorithms. However, due to technical
complications, the constructions in these papers were based in part on the earlier arguments of
Shalev-Shwartz et al. (2010) rather than the developments by Feldman (2016), and therefore fell
short of establishing their results in dimension polynomial in the number of training examples. As
a consequence, their results are unable to rule out a sample complexity upper bound for GD that
depends only (poly-)logarithmically on problem dimension.
In this work, we resolve the open questions posed in both Feldman (2016) and Amir et al.
(2021b): Our first main result demonstrates a convex learning problem where GD, unless trained
with at least Ω(√d) trainingexamples, outputs a badERM with constant probability. Thisbridges
thegap between theresults ofFeldman (2016)andactual, concrete learningalgorithms (albeitwith
a slightly weaker rate of Ω(√d), compared to the Ω(d) of the latter paper) and greatly improves on
the previous Ω(logd) lower bound of Amir et al. (2021b), establishing that the sample complexity
of batch GD in SCO has a significant, polynomial dependence on the problem dimension.
Furthermore, in our second main result we show how an application of the same construction
technique provides a similar improvement in the dimension dependence of the empirical risk lower
boundpresented intherecent workof Koren et al. (2022), thusalsoresolvingtheopenquestionleft
intheirwork. ThisworkdemonstratedthatinSCO,well-tunedSGDmayunderfit thetrainingdata
despiteachieving optimal populationrisk performance. At adeeperlevel, theoverfitting of GD and
underfitting of SGD both stem from a combination of two conditions: lack of algorithmic stability,
andfailureofuniformconvergence; asitturnsout, thiscombination allows fortheoutputmodelsto
exhibit a large generalization gap, defined as the difference in absolute value between the empirical
and population risks. Our work presents a construction technique for such generalization gap
lower bounds that achieves small polynomial dimension dependence, providing for an exponential
improvement over previous works.
1Herewe refer to GD as performing T =n iterations with stepsize η=Θ(1/√n),where n denotesthesize of the
training set, butour results hold more generally; see below for a more detailed discussion of thevarious regimes.
21.1 Our contributions
In some more detail, our main contributions are as follows:
(i) We present a construction of a learning problem in dimension d = O(nT +n2+η2T2) where
runningGD for T iterations with step η over a trainingset of n i.i.d.-sampled examples leads,
with constant probability, to asolution withpopulation errorΩ(η√T+1/ηT).2 Inparticular,
forthecanonicalconfigurationofT = nandη = Θ(1/√n),thelowerboundbecomesΩ(1)and
demonstrates that GD suffers from catastrophic overfitting already in dimension d = O(n2).
Put differently, this translates to an Ω(√d) lower bound the number of training examples
required for GD to reach nontrivial test error. See Theorem 1 below for a formal statement
and further implications of this result.e
(ii) Furthermore, wegive aconstruction of dimensiond= O(n2)wheretheempiricalerrorof one-
pass SGD trained over T = n training examples is Ω(η√n+1/ηn). Assuming the standard
setting of η = Θ(1/√n), chosen for optimal test peerformance, the empirical error lower
bound becomes Ω(1), showing that the “benign underfitting” phenomena of one-pass SGD
is exhibited already in dimension polynomial in the number of training samples. Rephrasing
this lower bound in terms of the number of training examples required to reach nontrivial
empirical risk, we again obtain an Ω(√d) sample complexity lower bound. See Theorem 2 for
the formal statement and further implications.
e
Both of the results above are tight (up to logarithmic factors) in view of existing matching
upper bounds of Bassily et al. (2020). We remark that the constructions leading to the results
feature differentiable Lipschitz and convex loss functions, whereas the lower bounds in previous
works concerned with gradient methods (Amir et al., 2021b,a; Koren et al., 2022) crucially applied
only to the class of non-differentiable loss functions. From the perspective of general non-smooth
convex optimization, this feature of the results imply that ourlower boundsremain valid underany
choice of a subgradient oracle of the loss function (as opposed to only claiming that there exists a
subgradient oracle under which they apply, like prior results do).
1.2 Main ideas and techniques
Our work builds primarily on two basic ideas. The first is due to Feldman (2016), whereby an
exponential number (in n) of approximately orthogonal directions, that represent the potential
candidates for a “bad ERM,” are embedded in a Θ(n)-dimensional space. The second idea, under-
lyingBassily et al.(2020);Amir et al.(2021b,a);Koren et al.(2022)istoaugmentthelossfunction
with a highly non-smooth component, that is capable of generating large (sub-)gradients around
initialization directed at all candidate directions, that could steer GD towards a bad ERM that
overfits the training set.
The major challenge is in making these two components play in tandem: since the candidate
directions of Feldman (2016) are only nearly orthogonal, the progress of GD towards one specific
direction gets hampered by its movement in other, irrelevant directions. And indeed, previous
work in this context fell short of resolving this incompatibility and instead, opted for a simpler
construction with a perfectly-orthogonal set of candidate directions, that was used in the earlier
work of Shalev-Shwartz et al. (2010). Unfortunately though, this latter construction requires the
ambient dimensionality to be exponential in the number of samples n, which is precisely what we
aim to avoid.
2Bypopulationerror(ortesterror)wemeanthepopulationexcessrisk,namelythegapinpopulationriskbetween
thereturned solution and theoptimal solution.
3Our solution for overcoming this obstacle, which we describe in length in Section 3, is based
on several novel ideas. Firstly, we employ multiple copies of the original construction of Feldman
(2016) in orthogonal subspaces, in a way that it suffices for GD to make a single step within
each copy so as to reach, across all copies, a bad ERM solution; this serves to circumvent the
“collisions” between consecutive GD steps alluded to above. Secondly, we carefully design a convex
loss term that, when augmented to the loss function, forces successive gradient steps to be taken
in a round-robin fashion between the different copies, so that each subspace indeed sees a single
update step through the GD execution. Lastly, we introduce a novel technique that memorizes the
full training set by “encoding” it into the iterates in a convex and differentiable manner, so that
the GD iterate itself (to which the subgradient oracle has access) contains the information required
to “decode” the right movement direction towards a bad ERM. We further show how all of these
added loss components can be made differentiable, so as to allow for a differentiable construction
overall. A detailed overview of these construction techniques and a virtually complete description
of our construction are provided in Section 3.
1.3 Additional related work
Learnability and generalization in the SCO model. Ourworkbelongs tothebodyoflitera-
tureonstabilityandgeneralizationinmodernstatisticallearningtheory,pioneeredbyShalev-Shwartz et al.
(2010) and the earlier foundational work of Bousquet and Elisseeff (2002). In this line of research,
Hardt et al. (2016); Bassily et al. (2020) study algorithmic stability of SGD and GD in the smooth
and non-smooth (convex) cases, respectively. In the general non-smooth case which we study here,
Bassily et al. (2020) gave an iteration complexity upper bound of O(η√T + 1/ηT + ηT/n) test
error for T iterations with step size η over a training set of size n. The more recent work of
Amir et al. (2021b) showed this to be tight up to log-factors in the dimension independent regime,
and Amir et al. (2021a) further extends this result to any optimization algorithm making use of
only batch gradients (i.e., gradients of the empirical risk). Even more recently, Kale et al. (2021)
considers (multi-pass) SGD and GD in a more general SCO model where individual losses may
be non-convex (but still convex on average), and prove a sample complexity lower bound for GD
showing it learns in a suboptimal rate with any step size and any number of iterations.
Sample complexity of ERMs. With relation to the sample complexity of an (arbitrary) ERM
in SCO, Feldman (2016) showed that reaching ǫ-test error requires Ω(d/ǫ+1/ǫ2) training samples,
but did not establish optimality of this bound. In a recent work, Carmon et al. (2023) show this
to be nearly tight and presents a O(d/ǫ +1/ǫ2) upper bound for any ERM, improving over the
O(d/ε2) upper bound that can be derived from standard covering number arguments. Another
recent work related to ours is that oef Magen and Shamir (2023), whoprovided another example for
a setting in which learnability can be achieved without uniform convergence, showing that uniform
convergence may not hold in the class of vector-valued linear (multi-class) predictors. However, the
dimension of their problem instance was exponential in the number of training examples.
Implicit regularization and benign overfitting. Another relevant body of research focuses
on understanding the effective generalization of over-parameterized models trained to achieve zero
training error through gradient methods (see e.g., Bartlett et al., 2020, 2021; Belkin, 2021). This
phenomenonappearstochallengeconventionalstatisticalwisdom,whichemphasizestheimportance
of balancing data fit and model complexity, and motivated the study of implicit regularization (or
bias) as a notion for explaining generalization in the over-parameterized regimes. Our findings in
this paper could be viewed as an indication that, at least in SCO, generalization does not stem
4from some form of an implicit bias or regularization; see Amir et al. (2021b); Koren et al. (2022)
for a more detailed discussion.
2 Problem setup and main results
We consider the standard setting of Stochastic Convex Optimization (SCO). The problem is char-
acterized by a population distribution over an instance set Z, and loss function f : W Z R
D × →
defined over convex domain W Rd in d-dimensional Euclidean space. We assume that, for any
⊆
fixed instance z Z, the function f(w,z) is both convex and L-Lipschitz with respect to its first
∈
argument w. In this setting, the learner is interested in minimizing the population loss (or risk)
which corresponds to the expected value of the loss function over , defined as
D
F(w) =E [f(w,z)], (population risk/loss)
z
∼D
namely, finding a model w W that achieves an ε-optimal population loss, namely such that
∈
F(w) F(w )+ε, where w argmin F(w) is a population minimizer.
w W
≤ ∗ ∗ ∈ ∈
To find such a model w, the learner uses a set of n training examples S = z ,...,z , drawn
1 n
{ }
i.i.d. from the unknown distribution . Given the sample S, the corresponding empirical loss (or
D
risk), denoted F(w), is defined as the average loss over samples in S:
n
b 1
F(w) = f(w,z ). (empirical risk/loss)
i
n
i=1
X
b
We let w argmin F(w) denote a minimizer of the empirical risk, refered to as an empirical
w W
∗ ∈ ∈
risk minimizer (ERM). Moreover, for every w W, we define the generalization gap at w as the
∈
absolutebvalue of the diffebrence between the population loss and the empirical loss, i.e., F(w)
| −
F(w).
|
b
Optimization algorithms. We consider several canonical first-order optimization algorithms
in the context of SCO. First-order algorithms make use of a (deterministic) subgradient oracle
that takes as input a pair (w,z) and returns a subgradient g(w,z) ∂ f(w,z) of the convex loss
w
∈
function f(w,z) with respect to w. If ∂ f(w,z) = 1, the loss f(,z) is differentiable at w and the
w
| | ·
subgradient oracle simply returns the gradient at w; otherwise, the subgradient oracle is allowed
to emit any subgradient in the subdifferential set ∂ f(w,z).
w
First, we consider standard gradient descent (GD) with a fixed step size η > 0 applied to the
empirical risk F. We allow for a potentially projected, m-suffix averaged version of the algorithm
that takes the following form:
b
initialize at w W;
1
∈
n
η
update w = Π w g(w ,z ) , 1 t < T;
t+1 W t t i
" − n # ∀ ≤ (1)
i=1
X
m
1
return w := w .
T,m T i+1
m −
i=1
X
Here Π : Rd W denotes the Euclidean projection onto the set W; when W is the entire space
W
→
Rd, thisbecomessimplyunprojectedGD.Thealgorithm returnseither thefinaliterate, theaverage
of the iterates, or more generally, any m-suffix average (1 m T) of iterates.
≤ ≤
5The second method that we analyze is Stochastic Gradient Descent (SGD), which is again
potentially projected and/or suffix averaged. This method uses a fixed stepsize η > 0 and takes
the following form:
initialize at w W;
1
∈
update w = Π w ηg(w ,z ) , 1 t < T;
t+1 W t t t
− ∀ ≤ (2)
m
1 (cid:2) (cid:3)
return w := w .
T,m T i+1
m −
i=1
X
Main results. Our main contributions in the context of SCO are tight lower bounds for the
populationlossofGDandfortheempiricallossofSGD,wheretheproblemdimensionispolynomial
in the number of samples n and steps T. First, for the population risk performance of GD, we
prove the following:
Theorem 1. Fix n > 0, T > 32002 and 0 η 1 and let d= 178nT +2n2+max 1,25η2T2 .
≤ ≤ 5√T { }
There exists a distribution over instance set Z and a convex, differentiable and 1-Lipschitz loss
D
function f :Rd Z R such that for GD (either projected or unprojected; cf. Eq. (1) with W = Bd
× →
or W = Rd respectively) initialized at w = 0 with step size η, for all m = 1,...,T, the m-suffix
1
averaged iterate has, with probability at least 1 over the choice of the training sample,
6
F(w ) F(w ) = Ω min η√T +1/ηT,1 . (3)
T,m
− ∗
(cid:16) n o(cid:17)
For SGD, we prove the following theorem concerning its convergence on the empirical risk:
Theorem 2. Fix n > 2048 and 0 η 1 and let d = 712nlogn + 2n2 + max 1,25η2n2 .
≤ ≤ 5√n { }
There exists a distribution over instance set Z and a convex, 1-Lipschitz and differentiable loss
D
function f : Rd Z R such that for one-pass SGD (either projected or unprojected; cf. Eq. (2)
× →
with W = Bd or W = Rd respectively) over T = n steps initialized at w = 0 with step size η, for
1
all m = 1,...,T, the m-suffix averaged iterate has, with probability at least 1 over the choice of the
2
training sample,
F(w ) F(w ) = Ω min η√T +1/ηT,1 . (4)
T,m
− ∗
(cid:16) n o(cid:17)
Discussion. As noted inb the introdb ucbtion, both of the bounds above are tight up to logarithmic
factors in view of matching upper bounds due to Bassily et al. (2020). For GD tuned for optimal
convergence on the empirical risk, where T = n and η = Θ(1/√n), Theorem 1 gives an Ω(1)
lower bound for the population error, which precludes any sample complexity upper bound for
this algorithm of the form O(dp/ǫq) unless p 1. In particular, this implies an Ω(√d) lower
≥ 2
bound the number of training examples required for GD to reach a nontrivial population risk. In
contrast, lower bounds in previous work (Amir et al., 2021b) only implies an exponentially weaker
Ω(logd) dimension dependence in the sample complexity. We note however that there is still a
small polynomial gap between our sample complexity lower bounds to the known (nearly tight)
bounds for generic ERMs (Feldman, 2016; Carmon et al., 2023); we leave narrowing this gap as an
open problem for future investigation.
More generally, with GD fixed to perform T = nα,α > 0 steps, and setting η so as to optimize
the lower bound, the right-hand side in Eq. (3) becomes Θ(n α/4), which rules out any sample
−
6complexity upper bound of the form O(dp/ǫq) unless it satisfies max 2,α + 1 p + 1αq 1.3
{ } 4 ≥
Specifically, we see that any dimension-free upper bound with T = n must have at least an 1/ǫ4
dependence on ǫ; and that for matching the statistically optimal sample complexity rate of 1/ǫ2,
one must either run GD for T = n2 steps or suffer a polynomial dimension dependence in the rate
(e.g., for T = n this dependence is at least d1/4).
Similar lower bounds (up to a logarithmic factor) are obtained for SGD through Theorem 2,
but for the empirical risk of the algorithm when tuned for optimal performance on the population
risk with T = n. In this case, the bounds provide an exponential improvement in the dimension
dependence over the recent results of Koren et al. (2022), showing that the “benign underfitting”
phenomena they revealed for one-pass SGD is exhibited already in dimension polynomial in the
number of training samples.
Finally, weremarkthatourrestriction onη is onlymeantforplacingfocusonthemorecommon
and interesting range of stepsizes in the context of stochastic optimization. It is not hard to extend
the result of Theorems 1 and 2 to larger values of η (in this case the lower bounds are Ω(1), the
same rate the theorems give for η = Θ(1/√T)), in the same way this is done in previous work
(e.g., Amir et al., 2021b; Koren et al., 2022).
3 Overview of constructions and proof ideas
In this section we outline the main ideas leading to our main results and give an overview of the
lower bound constructions. As discussed above, the main technical contribution of this paper is in
establishingthefirstΩ(η√T)terminEqs.(3)and(4)usingalossfunctionindimensionpolynomial
in n and T, and this is also the focus of our presentation in this section. In Sections 3.1 to 3.4 we
focus on GD and describe the main ideas and technical steps towards proving our first main result;
in Section 3.6 we survey the additional steps and adjustments needed to obtain our second main
result concerning SGD.
Starting with GD and Theorem 1, recall that our goal is to establish a learning scenario where
GDislikelytoconvergetoa“badERM”,namelyaminimizeroftheempiricalriskwhosepopulation
loss is large. We will do that in four steps: we will first establish that such a “bad ERM” actually
exists; then, we will show how to make such a solution reachable by gradient steps from the origin;
we next describe how the information required to identify this solution can be “memorized” by GD
into its iterates; and finally, we show how to combine these components and actually drive GD
towards a bad ERM.
3.1 A preliminary: existence of bad ERMs
Our starting point is the work of Feldman (2016) that demonstrated that in SCO, an empirical risk
minimizer might fail to generalize, already in dimension linear in the number of training samples.
More concretely, they showed that for any sample size n, there exists a distribution over convex
D
loss functions in dimension d = Θ(n) such that, with constant probability, there exists a “bad
ERM”: one that overfits the training sample and admits a large generalization gap.
Theirapproachwasbasedonaconstructionofasetofunitvectors ofsize2Ω(n),denotedU,that
are “nearly orthogonal”: the dot product between any two distinct u,v U satisfies u,v 1.4
∈ |h i| ≤ 8
3Toseethis,letr=max 2,α+1 andnotethatforourconstructiond=O(nT+n2)=O(nr)andǫ=Ω(n−α/4);
{ }
thesamplecomplexityupperboundO(dp/ǫq)canbethereforerewrittenintermsofnasO(nrp+αq/4),andsincethis
should asymptotically upperbound thenumberof samples n, one must have that rp+ 1αq 1.
4The original construction by Feldman (2016) satisfied slightly different conditions, w4 hich≥ we adjust here for our
analysis.
7Then, they take the power set Z = P(U) of U as the sample space (namely, identifying samples
with subsets of U), the distribution to be uniform over Z, and the (convex, Lipschitz) loss
D
h : RΘ(n) Z R to be defined as follows:
F16
× →
h (w,V) = max 1,max u,w . (5)
F16 2 u V h i
n ∈ o
For this problem instance, they show that with constant probability over the choice of a sample
S = V ,...,V iid n of size n = O(d), at least one of the vectors in U, say u U, will not be
1 n 0
{ }∼D ∈
observed in any of the sets V ,...,V , namely u U n V . Finally, they prove that such a
1 n 0 ∈ \ i=1 i
vector u is in fact an Ω(1)-bad ERM (for which the generalization gap is Ω(1)).
0 S
To see why this is the case, note that, since every vector u U is in every training example
∈
V with probability 1, the set U (whose size is exponential in n) is large enough to guarantee the
i 2
existence of a vector u / n V with constant probability. Consequently, the empirical loss of
0 ∈ i=1 i
such u equals 1 (since u ,v 1 for any v V and therefore h (u ,V ) = 1 for all i). However,
0 2 h 0 Si ≤ 8 ∈ i F16 0 i 2
for a fresh example V , with probability 1 it holds that u V, and therefore h (u ,V)= 1,
∼ D 2 0 ∈ F16 0
in which case the population risk of u is at least = 1 1 + 1 1 = 3 and the generalization gap is
0 2 · 2 2 · 2 4
therefore at least 1.
4
3.2 Ensuring that bad ERMs are reachable by GD
AsFeldman(2016)explainsintheirwork,although thereexistsanERMwithalargegeneralization
gap, it is not guaranteed that such a minimizer is at all reachable by gradient methods, within a
reasonable (say, polynomial in n) number of steps. This is because in their construction, the loss
function h remains flat (and equals 1, see Eq. (5)) inside a ball of radius Ω(1) around the origin,
F16 2
where GD is initialized; within this ball, all models are essentially “good ERMs” that admit zero
generalization gap. It remains unclear how to steer GD, with stepsize of order η = O(1/√T) over
T steps, away from this flat region of the loss towards a bad ERM, such as the u identified above.
0
To address this challenge, we modify the construction of Feldman (2016) in a fundamental
way. The key idea is increase dimensionality and replicate Feldman’s construction in T orthogonal
subspaces; this would allow us to decrease, in each of the subspaces, the distance to a bad ERM to
only O(η), rather than Θ(1) as before. Then, while each of these subspace ERMs is only Ω(η)-bad,
when taken together, they constitute an Ω(1)-bad ERM in the lifted space whose distance from the
origin is roughly η√T = Θ(1), yet is still reachable by T steps of GD.
Moreconcretely, weintroducealossfunctionh :Rd′ P(U) R(ford = Θ(n))thatresembles
′
× →
Feldman’s function from Eq. (5) up to a minor adjustment:
h(w ,V)= max 3 η,max u,w . (6)
′ 32 ′
u V
n ∈ (cid:10) (cid:11)o
As in the original construction by Feldman, V here ranges over subsets of a set U
Rd′
of
size
2Ω(d′),
the elements of which are nearly-orthogonal unit vectors. Then, we
constru⊆
ct a loss
function in dimension d = Td by applying h in T orthogonal subspaces of dimension d, denoted
′ ′
W(1),...,W(T), as follows:5
T
2
ℓ (w,V) = h(w(k),V) . (7)
1 v
u uk X=2(cid:16) (cid:17)
t
Here and throughout, w(k) refers to the k’th orthogonal component of the vector w, that resides
in the subspace W(k). Finally, the distribution is again taken to be uniform over Z = P(U),
D
5The summation starts at k=2 dueto technical reasons that will become apparent later in this proof sketch.
8and a training set is formed by sampling S = V ,...,V n. As before, we know that with
1 n
{ } ∼ D
probability at least 1, there exists a vector u such that u U n V .
2 0 0 ∈ \ i=1 i
With this setup, it can be shown that ℓ is indeed convex and O(1)-Lipschitz, and further,
1 S
that any vector w satisfying w(k) = cηu for a sufficiently large constant c > 0 and Ω(T)-many
0
components k, is an Ω(1)-bad ERM with respect to ℓ . The important point is that, unlike in
1
Feldman’s original construction, such bad ERMs are potentially reachable by GD: it is sufficient
to guide the algorithm to make a single, small step (with stepsize η) towards u in each subspace
0
W(k).
3.3 Memorizing the dataset in the iterate
There is one notable obstacle to the plan we just described: the vector u is determined in a rather
0
complex way by the full description of the training set and it is unclear how to reproduce such a
vector through subgradients of the loss function. Indeed, recall that the only access GD has to
the training set is through subgradients of individual functions g(w,V ),...,g(w,V ) (and linear
1 n
combinations thereof), and none of these has direct access to the full training set that could allow
for determining a vector u U n V .
0 ∈ \ i=1 i
To circumvent this difficulty, another key aspect of our construction involves a mechanism that
S
effectively memorizes the full training set in the iterate w itself, using the first few steps of GD. For
this memorization, wecan, forexample, furtherincreasethedimensionof thedomainW andcreate
an “encoding subspace,” denoted as W(0) (and the corresponding component of a vector w W is
∈
indicated by w(0)), which is orthogonal to W(1),...,W(T). In this subspace, each step taken with
respect to (a linear combination of) individual gradients g(w ,V ) encodes the information on the
t i
sets V ,...,V into the iterate w . Then, since the subgradient oracle receives w as input, it can
1 n t t
reconstruct the training set encoded in w (0) and recover u , in every subsequent step.
t 0
On its own, the task of memorizing the training set is not particularly challenging and can
be addressed in a rather straightforward manner.6 What turns out to be more challenging is to
design the encoding in such a way that u is realized as the unique subgradient (i.e., the gradient)
0
of the loss function. This would be crucial for establishing that our lower bound is valid for any
subgradientoracle, andnotonlyforanadversariallychosenone(aswellformakingtheconstruction
differentiable; we discuss this later on, in Section 3.5).
Let us describe an encoding mechanism where u acts as the unique subgradient at w = 0.
0 1
We will employ an encoding subspace W(0) of dimension Θ(n2), and augment samples with a
number j [n2], drawn uniformly at random; namely, each sample in the training set is now a pair
∈
(V ,j ) P(U) [n2], for i= 1,...,n. We then create an encodingfunction φ: P(U) [n2] W(0)
i i
∈ × × →
such that φ(V,j) maps the set V into the j’th (2-dimensional) subspaceof the encoding space. The
role of j is to ensure that, with constant probability, sets in the training sample are mapped to
distinctsubspacesoftheencodingspaceW(0),andthuscanbeuniquelyinferredgiventheencoding.
To implement the encoding within the optimization process, we introduce the following term into
the loss:
ℓ (w,(V,j)) := φ(V,j),w(0) . (8)
2
h− i
Following a single step of GD, the iterate becomes w (0) = η n φ(V ,j ), and by the properties
2 n i=1 i i
of the encoding φ it is then possible, with constant probability, to fully recover the sets V ,...,V
P 1 n
in the training set, given the iterate w .
2
6Onesimple approach is toutilize aone-dimensional encoding space toencode everyindividual training example
V P(U) in the least significant bits of w (0), in a way that guarantees there are no collisions between different
t
∈
possible values of such sets. This allows the subgradient oracle to calculate the specific u from the training set
0
encoded in theleast significant bits of w (0) and return it as a subgradient.
t
9Next, we introduce an additional term into the loss function, whose role is to “decode” the
training set V ,...,V from w and produce a vector u U n V as a subgradient. For this,
we represent
1
every
pn
otential
tt
raining set using a
vect0 or∈
ψ
\ Ψi=1 Bi 2n2
, and define a mapping
α :
R2n2
U that, for every ψ Ψ, provides a vector
α(ψ)∈ S
U
⊆
that does not appear in any of
→ ∈ ∈
the sets V in the training sample associated with ψ (if such a vector exists). Finally, we add the
i
following term to the loss function,
ℓ (w) := max δ ,max ψ,w(0) β α(ψ),w(1) , (9)
3 1
ψ Ψ h i− h i
(cid:26) ∈ n o(cid:27)
where β,δ > 0 are small predefined constants. We can show, assuming that in the first step, the
1
training set was encoded to the iterate (w (0) = η n φ(V ,j )), that for a suitable choice of the
2 n i=1 i i
encoder (φ) and decoder (ψ and α), in the following iteration, the vector ψ Ψ that represents
P ∗ ∈
theactualtrainingsetV ,...,V isrealized as auniquemaximizer inEq.(9), which inturntriggers
1 n
a gradient step along u := α(ψ) in the subspace W(1).
0
3.4 Making GD converge to a bad ERM
Our final task is to finally make GD converge to a “bad ERM,” namely to a model w such that
w(k) = cηu for a sufficiently large constant c > 0 and Ω(T)-many values of k, assuming it was
0
successfully initialized at w with w(1) = c u (and w(k) = 0 for k > 1) as we just detailed. We
1 0
will accomplish this by forcing GD into making a single step towards u in Ω(T) of the subspaces
0
W(1),...,W(T).
To this end, we employ a variation of a technique used in previous lower bound construc-
tions (Bassily et al., 2020; Amir et al., 2021b; Koren et al., 2022) to induce gradient instability
aroundtheorigin. Inthesepriorinstances,however, thepotentialdirectionsofprogress—analogous
to vectors in our set U—were perfectly orthogonal (and thus, the dimension of space was required
to be exponential in n). In contrast, in our scenario the vectors in U are only approximately or-
thogonal, and directly applying this approach could lead to situations where gradient steps from
consecutive iterations may interfere with progress made in correlated directions in previous itera-
tions.
To address this, we introduce a careful variation on this technique, based on augmenting the
loss function with the following convex term:
ℓ (w) = max δ , max 3 u,w(k) 1 u,w(k+1) , (10)
4 2 u U,k<T 8h i− 2h i
(cid:26) ∈ n o(cid:27)
where δ > 0 is a small constant (that will be set later). The key idea here is that following the
2
initialization stage, theinnermaximization aboveis always attained atthesamevector u= u , and
0
for values of k that increase by 1 in every iteration of GD. Consequently, subgradient steps with
respect to this term will result in making a step towards u in each of the components w(1),w(2),...
0
one by one, avoiding interference between consecutive steps. At the end of this process, there are
Ω(T) values of k such that w(k) = 1ηu , which is what we set to achieve.
8 0
In some more detail, assuming GD is successfully initialized at a vector w with w(1) = c u and
1 0
w(k) = 0 for k > 1 (c > 0 is a small constant), note that the maximum in Eq. (10) is uniquely
1
attained at k = 1 and u = u . Consequently, the subgradient of ℓ at initialization is a vector g
0 4
such that g(1) = 3u , g(2) = 1u (and g(k) = 0 for k = 1,2), and taking a subgradient step with
8 0 −2 0 6
stepsize η results in w(1) = (ηβ 3η)u and w(2) = ηu (for k = 1,2, w(k) remains as is). In each
− 8 0 2 0 6
subsequent iteration, the maximization in Eq. (10) is attained at an index k for which w(k) = ηu
2 0
10and at u = u .7 Subsequently, every gradient step adds 3ηu to w(k) and ηu to w(k+1) and
0 − 8 0 2 0
results in w(2) = w(3) = ... = w(k) = ηu and w(k+1) = ηu (whereas for all s > k+1, w(s) remains
8 0 2 0
zero).
Finally, we note that the GD dynamics we described ensurethat the iterates w ,...,w remain
1 T
strictly within the unit ball Bd, even when the algorithm does not employ any projections. As
a consequence, the construction we described applies equally to a projected version of GD, with
projections to the unit ball, and the resulting lower bound will apply to both versions of the
algorithm.
3.5 Putting things together
We can now integrate the ideas described in Sections 3.1 to 3.4 into a construction of a learning
problem where GD overfits the training data (with constant probability), that would serve to prove
our lower bound for gradient decent. To summarize this construction:
• The examples in the learning problem are parameterized by pairs (V,j) Z := P(U) [n2],
∈ ×
whereU isthesetofnearly-orthogonal vectors describedinSection 3.1, andP(U)isits power
set;
• The population distribution is uniform over pairs (V,j) Z, namely such that V
D ∈ ∼
Unif(P(U)) (i.e., V is formed by including every element u U independently with proba-
∈
bility 1) and j Unif([n2]);
2 ∼
• The loss function in this construction, f : W (P(U) [n2]) R, is then given by:
× × →
(V,j) Z, f(w,(V,j)) := ℓ (w,V)+ℓ (w,(V,j))+ℓ (w)+ℓ (w), (11)
1 2 3 4
∀ ∈
with the terms ℓ ,ℓ ,ℓ ,ℓ as defined in Eqs. (7) to (10) respectively.
1 2 3 4
With a suitable choice of parameters, this construction serves to proving Theorem 1. We remark
that, while f in this construction is convex and O(1)-Lipschitz, it is evidently non-differentiable.
For obtaining a construction with a differentiable objective that maintains the same lower bound
and establish the full claim of Theorem 1, we add one final step of randomized smoothing of the
objective. Thisargumenthingesonthefactthatthesubgradientsoff areuniquealong any possible
trajectory of GD, so that smoothing in a sufficiently small neighborhood would preserve gradients
along any such trajectory (and thus does not affect the the dynamics of GD), while making the
objective differentiable everywhere. The full proof of Theorem 1 is deferred to Appendix A.
3.6 Additional adjustments for SGD
Moving on to discuss our second main result for SGD, we provide here a brief overview of the
necessary modifications upon the construction for GD to establish the lower bound for SGD in
Theorem 2; further details can be found in Section 5. In the case of SGD, our goal is to establish
underfitting: namely, to show that the algorithm may converge to a solution with an excessively
large empirical risk despite successfully converging on the population risk.
Themain ideas leading toour construction for SGDaresimilar towhatwediscussedabove, but
there are several necessary modifications that arise from the fact that, whereas in GD the entire
7For this value of k, it holds that max u∈U 3 8hu,w(k)
i−
21 hu,w(k+1)
i
= 13 6η (attained at u = u 0), whereas for
othervaluesofk thisquantityisat most 1 3η+1 1 2 η< 1η duetothenear-orthogonality ofvectorsinU. It
≈ 8·(cid:8)8 8· 2 8 (cid:9)
follows that thesubgradient is a vectorg such that g(k)= 3u , g(k+1)= 1u (and zeros elsewhere).
(cid:0) (cid:1)8 0 −2 0
11training set is revealed already in the first iteration, in SGD it is revealed sequentially, one training
sample at a time. In particular, unlike in the case of GD where it is possible to identify a bad
ERM u at the few first steps of the algorithm and steer the algorithm in this direction in every
0
subspace W(1),W(2),..., for SGD the required progress direction in W(t), represented as a “bad
solution” u , can be only determined in the t’th step based on the encoded training set up to that
t
point, V ,...,V . As a result, it is crucial to modify the loss function such that the process of
1 t 1
−
decoding such u from V ,...,V occurs in every iteration t.
t 1 t 1
−
Another essential adjustment involves identifying a solution with a large generalization gap
(namely large empirical risk, low population risk) and guiding the SGD iterates to converge to
such a solution. Considering the function ℓ defined in Eq. (7), such a solution is represented by
1
a vector u U that appears in all of the sets V ,...,V in the training sample. However, since u
1 n t
∈
cannot depend on future examples, our goal within every subspace W(t) is to take a single gradient
step towards a vector u present only in sets up to that point, namely in t 1V (note that such
t i=−1 i
u maximizes the corresponding loss functions ℓ (w,V )...ℓ (w,V )). Additionally, to ensure
t 1 1 1 t 1 T
−
that gradients for future loss functions remain zero and do not affect the algorithm’s dynamics,
it is necessary to to guarantee that u n V ; in other words, we are looking for a solution
t ∈ i=t i
u t 1V n V . For ensuring that such a vector actually exists (with constant probability),
t ∈ i=−1 i ∩ i=t i T
we lift the dimension of the set U and the subspaces W(k) n to d = Θ(nlogn) (instead of Θ(n)
T T { }k=1
as before) and modify the distribution so as to have that V is sampled such that every element
D
u U is included in V independently with probability 1/4n2.
∈
Withtheseadaptationsinplace,wecanobtainTheorem2; formoredetailswerefertoSection5.
4 Overfitting of GD: Proof of Theorem 1
In this section, we provide a formal proof of our main result for GD. We establish a lower bound of
Ω(η√T) for the population loss of GD, where the hard loss function is defined in a d-dimensional
Euclidean space, wherethedimensiondis polynomialin thenumberof examplesn. InAppendixA
wecompletetheproofofTheorem1, byshowingalower boundofmin 1/ηT,1 , andaconstruction
{ }
of a differentiable objective that holds the lower bound stated in Theorem 1.
Full construction. For the first step, for a dimension d that will be set later, we use a set of
′
approximately orthogonalvectors
inRd′
withsize(atleast) exponentialind,theexistenceofwhich
′
is given by the following lemma, adapted from Feldman (2016).
Lemma 1. For any d ′ 256, there exists a set U d′
Rd′
, with U d′
2d′/178,
such that for all
≥ ⊆ | | ≥
u,v
∈
U d′,u 6= v, it holds that |hu,v
i|≤
81.
Now, let n be the number of examples in the training set. We define the set U := U d′ to be a
set as specified by Lemma 1 for d = 178n. Then, as outlined in Section 3, we define the sample
′
space Z := (V,j) : V U,j [n2] and the hard distribution as the uniform distribution.
{ ⊆ ∈ } D
Moreover, we consider the loss function f : Rd R (defined in Eq. (11) for d := Td +2n2 =
′
→
178nT +2n2. This loss function is convex and 5-Lipschitz over Rd, as established in the following
lemma:
Lemma 2. For every (V,j) Z, the loss function f(w,(V,j)) is convex and 5-Lipschitz over Rd
∈
with respect to its first argument.
For this construction of distribution and loss function, we obtain the following theorem.
12Theorem 3. Assume that n > 0, T > 32002 and η 1 . Consider the distribution and the
≤ √T D
loss function f that defined in Section 3.5 for d = 178nT +2n2, ε = 1 (1 cos( 2π )), β = ǫ ,
n2 − P(U) 4T2
δ = η and δ = 3ηβ. Then, for Unprojected GD (cf. Eq. (1) with W = Rd) on| F,| initialized at
1 2n 2 16
w = 0 with step size η, we have, with probability at least 1 over the choice of the training sample:
1 6
b
(i) The iterates of GD remain within the unit ball, namely w Bd for all t = 1,...,T;
t
∈
(ii) For all m = 1,...,T, the m-suffix averaged iterate has:
F(w ) F(w ) = Ω η√T .
T,m
− ∗
(cid:0) (cid:1)
Algorithm’s dynamics. We next give a key lemma that characterizes the trajectory of GD
when applied to the empirical risk F formed by the loss function f and the training sample S =
(V ,j ) n . The characterization holds under a certain “good event”, given as follows:
{ i i }i=1
b
n
:= V = U j = j , k = l . (12)
i k l
E i=1 6 ∩ 6 ∀ 6
(cid:8)[ (cid:9) (cid:8) (cid:9)
In words, under the event there exists at least one “bad direction” (which is a vector in the set
E
U n V ) and there is no collision between the indices j ,...,j . In the following lemma we
\ i=1 i 1 n
show that holds with a constant probability. The proof is deferred to Appendix B.2.
S E
Lemma 3. For the event defined in Eq. (12), it holds that Pr( ) 1.
E E ≥ 6
Under this event, the dynamics of GD are characterized as follows.
Lemma 4. Assume the conditions of Theorem 3, and consider the iterates of unprojected GD on
F, with step size η 1/√T initialized at w = 0. Under the event , we have for all t 5 that
1
≤ E ≥
b η n φ(V ,j ) k = 0;
n i=1 i i
 −P3 8 + t −42 Tǫ 2 ηu 0 k = 1;
w t(k) = (cid:0) 11 8η ηu
u0 (cid:1)
2
k≤
=k
t
≤
2t ;−3; (13)
2 0 −
where u is a vector such that u
0
U n V .
t −1
≤
k
≤
T,
0 0 ∈ \ i=1 i
To prove Lemma 4, we break down tSo the different components of the loss and analyze how the
terms ℓ ,ℓ and ℓ affects the dynamics of GD under the event . For each of these components,
1 3 4
E
which involve maximum over linear functions, we show which term achieves the maximum value
for each w and derive the expressions for the gradients at those points by the maximizing terms.
t
First, we show that under this event, the gradients of ℓ do not affect the dynamics since in any
1
iteration t the gradient of ℓ is zero, as stated in the following lemma. The proof is deferred to
1
Appendix B.
Lemma 5. Assume the conditions of Theorem 3 and the event . Let w Rd be such that for
E ∈
every 2 k T, w(k) = cηu for c 1 and u U n V . Then, for every i, it holds that
≤ ≤ 0 ≤ 2 0 ∈ \ i=1 i
(i) for every k 2, it holds max w(k),u η ;S
≥ u ∈Vih 0 i≤ 16
(ii) ℓ is differentiable at w and for all i [n], we have ℓ (w,V ) = 0.
1 1 i
∈ ∇
13Next, for the term ℓ , as outlined in Section 3.3, it is used for identifying the actual training
3
set S = (V ,j ) n given an encoding ψ = 1 n φ(V ,j ) in the iterate w (0) and ensuring a
{ i i }i=1 ∗ n i=1 i i t
performanceofgradientstepinW(1) towardsacorrespondingvectoru U n V inthefollowing
P 0 ∈ \ i=1 i
iteration. Itisdonebygetting ψ asamaximumoflinearfunctions(withpositiveconstant margin)
∗ S
over the set Ψ which contains all possibleencoded datasets. This idea is formalized in the following
lemma.
Lemma 6. Assume the conditions of Theorem 3 and the event . Let ψ = 1 n φ(V ,j ) and
E ∗ n i=1 i i
w Rd be such w(0) = ηψ , and let w(1) = cηu for c 1 and u U n V . Then
∈ ∗ 0 | | ≤ 0 ∈ \ i=1 iP
(i) For every ψ Ψ, ψ = ψ : S
∗
∈ 6
w(0),ψ ǫ α(ψ ),w(1) > w(0),ψ ǫ α(ψ),w(1) + ηǫ;
h ∗ i− 4T2h ∗ i h i− 4T2h i 4
(ii) For ψ = ψ , it holds that
∗
w(0),ψ ǫ α(ψ ),w(1) > δ + η ;
h ∗ i− 4T2h ∗ i 1 16n
(iii) ℓ is differentiable at w and the gradient is given as follows:
3
ψ k = 0;
∗
( ∇ℓ 3(w))(k) =  0−4Tǫ 2u
0
k oth= er1 w;
ise.

Finally, for ℓ , as detailed in Section 3.4, the role of this term is to make the last iterate w
4 T
hold w (k) = ηηu for Ω(T) many sub-spaces W(k). In the following lemma, we show that in every
T 8 0
iteration t, every gradient step increases the amount of such ks by 1, namely, in every iteration t,
the maximum of ℓ is attained at u = u and index k = argmax k : w (k) = 0 , which increases
4 0 t t
{ 6 }
by 1 in every iteration, making the w (kt) = ηηu .
t+1 8 0
Lemma 7. Assume the conditions of Theorem 3 and the event . Let w Rd, u U n V
E ∈ 0 ∈ \ i=1 i
and 3 m < T be such that w(1) = cηu for 3 c 0, w(k) = ηu for every 2 k m 1,
≤ 0 −8 ≤ ≤ 8 0 ≤ ≤S −
w(k) = ηu and w(k) = 0 for every k m. Then, it holds that,
2 0 ≥
(i) For every pair u U and k < T such that k = m or u= u ,
0
∈ 6 6
3 u ,w(m) 1 u ,w(m+1) > 3 u,w(k) 1 u,w(k+1) + η
8h 0 i− 2h 0 i 8h i− 2h i 64
(ii)
3 u ,w(m) 1 u ,w(m+1) > δ + η .
8h 0 i− 2h 0 i 2 64
(iii) ℓ is differentiable at w and the gradient is given as follows:
4
3u k = m;
8 0
(cid:0)∇ℓ 4(w) (cid:1)(k) = 
−
0
1 2u
0
k ot= herm wi+ se1 .;

14Proof of Lemma 4. We prove the lemma by induction on t; the base case, for t = 5, is proved in
Lemma 21 in Appendix B and here we focus on the induction step. For this, fix any t 5 and
≥
assume the that the lemma holds for w ; we will prove the claim for w .
t t+1
First, for ℓ , note that, by the hypothesis of the induction, for every 2 k T, w (k) = cηu
1 t 0
≤ ≤
for c 1, thus, by Lemma 5, for every i, ℓ (w ,V ) = 0.
≤ 2 ∇ 1 t i
For ℓ , we know that, for every i,
2
φ(V ,j ) k = 0;
(k) i i
ℓ (w ,(V ,j )) = −
2 t i i
∇ (0 otherwise.
(cid:0) (cid:1)
For ℓ , using the hypothesis of the induction, which implies that w (1) = cηu for c 1 and
3 t 0
| | ≤
w (0) = η n φ(V ,j ), by Lemma 6, we get that,
t n i=1 i i
P
1 n φ(V ,j ) k = 0;
n i=1 i i
(cid:0)∇ℓ 3(w t) (cid:1)(k) =  0−P4Tǫ 2u
0
k ot= her1 w;
ise.
For ℓ 4, by the hypothesis of the
induction
we know that w t(1) = −3 8 + (t − 42) Tǫ 2 ηu 0, thus, w t(1) =
cηu for 3c 0. Then the conditions of Lemma 7 hold for m = t 2, thus, it holds that,
0 −8 ≤ (cid:0) − (cid:1)
3u k = t 2;
8 0 −
(cid:0)∇ℓ 4(w t) (cid:1)(k) = 
−
0
1 2u
0
k ot= hert
w−
is1 e;
.
Combining all together, we get that,

ǫ u k = 1;
−4T2 0
∇F(w t)
(k) = −83u
1
20
u
0
kk == tt
−−
12 ;;
(cid:0) (cid:1)
b 0 otherwise,
where u U n V , and the lemma
follows.
(cid:3)
0 ∈ \ i=1 i
S
Proof of Lower Bound. Now we can turn to prove Theorem 3. Here we prove the lower bound
for the case of suffix averaging with m = 1, namely, when the output solution is the final iterate
w of GD; the full proof for the more general case can be found in Appendix B.3.
T
Proof of Theorem 3 (m =1 case). We prove the theorem under the condition that occurs. First,
E
in Lemma 22 in appendix Appendix B we know that for every t, we have that w 1.
t
k k≤
Next, w is as in Eq. (13). Now, we notice that if a vector v U is in a set V U, it holds
T
∈ ⊆
that max u,v = 1. However, if v / V, it holds that max u,v = 1. As a result, by the fact
that everyu ∈ vV eh ctori for a fresh pair (V,j)∈ D, u U is in V wu i∈ tV hh probi abil8 ity 1, the following holds:
∼ 0 ∈ 2
E
T
max
3η
,max u,w (k)
2
E
T −3
max
3η
,max u,w (k)
2
Vv
u uk X=2 (cid:26)32 u ∈V h
T
i (cid:27) ≥
Vv
u uk X=2 (cid:26)32 u ∈V h
T
i (cid:27)
t t
3η η 2
= E (T 4)max ,max u, u
V 0
s − 32 u V h 8 i
(cid:26) ∈ (cid:27)
15η√T 4 3
= − E max ,max u,u
V 0
8 4 u V h i
(cid:26) ∈ (cid:27)
η√T 4 3
− Pr(u / V)+Pr(u V)
0 0
≥ 8 4 ∈ ∈
(cid:18) (cid:19)
7η
= √T 4.
64 −
Moreover, we notice that for every t, V U and j [n2], ℓ (w ,(V,j)) w (0) η,
2 t t
⊆ ∈ ≥ −k k ≥ −
ℓ (w ) δ and ℓ (w ) δ , thus, it holds that
3 t 1 4 t 2
≥ ≥
7η 7
F(w ) √T +δ +δ η η √T 1 ;
T 1 2
≥ 64 − ≥ 64 −
(cid:18) (cid:19)
3η
F(w ) F(0) √T +η.
∗ ≤ ≤ 32
Then, since T is assumed large enough so that 2 1 √T, we conclude
≤ 128
1 η
F(w ) F(w ) η √T 2 √T. (cid:3)
T
− ∗ ≥ 64 − ≥ 128
(cid:18) (cid:19)
5 Underfitting of SGD: Proof of Theorem 2
In this section we show a formal proof of our main result for SGD. As in GD, we construct a hard
loss function, which is defined in a d-dimensional Euclidean space such that d is polynomial in the
number of examples n. Using this construction, we establish a lower bound of Ω(η√T) for the
empirical loss of SGD with T = n iterations. We complete the proof of Theorem 2 in Appendix A.
Full construction. For the firststep of the construction, we use Lemma 1 (see Section 4), which
shows for every dimension d an existence of a set of approximately orthogonal vectors in U
Rd′
′
∈
with size exponential in d ′. We define the set U to be U := U d′ for d ′ = 712nlogn and the sample
space to be ZSGD := V : V U . Moreover, we define the hard distribution SGD to be such
{ ⊆ } D
that every u U is included in V U independently with probability δ = 1 .
∈ ⊆ 4n2
For the hard loss function, we continue referring to every vector w Rd as a concatenation of
vectors, w = (w(0),w(1),w(2),...,w(n)), where for 1 k n, w(k) R∈ 712nlogn and w(0) R2n2 .
≤ ≤ ∈ ∈
In this construction, w(0) is also a concatenation of n vectors w(0,1),...,w(0,n) such that each for
every r [n], w(0,r) R2n
∈ ∈
Our approach is, as in GD, in every iteration t, to encode the set V , sampled from SGD into
t
D
the iterate w(0) . For this, we construct an encoder, φ :P(U) [n] R2n, a decoder α :R2n U,
t+1 × → →
a real number ǫ > 0 and n sets denoted as Ψ ,...,Ψ . Here, the idea behind the construction is
1 n
such set ψ represents all of the possible training sets with k examples, V ...,V , and in every
k 1 k
{ }
iteration t, it is possible to get the vector ψ Ψ that is recognized with the actual sets
V ,...,V that are sampled before this
iteratt∗ i−o1 n,∈
as
at − m1
aximizer of a linear function with margin
1 t 1
ǫ. Then, a− s outlined in Section 3.6, we aim to output a vector u n V . Theexact construction
t ∈ i=t i
of such ǫ,φ,α,Ψ ,...,Ψ is detailed in Lemma 23 in Appendix C.
1 n T
Then, for ǫ,φ,α,Ψ ,...,Ψ and d:= nd +2n2 = 712n2logn+2n2 we define the loss function
1 n ′
in our construction. The loss function fSGD is composed of three terms: ℓSGD, ℓSGD, ℓSGD, and is
1 2 3
16defined as follows,
T 3η 2
fSGD(w,V) := max ,max u,w(k) (14)
v u uk X=2 (cid:18)32 u ∈V h i (cid:19)
t
ℓSGD(w,V):=
1
| {z3 1} 1
+max δ , max u,w(k) α(ψ),w(k+1) + w(0,k), ψ
1
(cid:18)
k ∈[n −1],u ∈U,ψ ∈Ψk(cid:18)8h i− 2h i h 4n i
1 1
w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
−h 4n i h −4n2 i
(cid:19)(cid:19)
1 1
+ w(0,1), φ(V,1) u ,w(1) ,
h −4n2 i−hn3 1 i
ℓSGD(w,V):=
3
| {z }
where the second term is denoted ℓSGD(w,V) and u is an arbitrary vector in U. In the following
2 1
lemma, weestablish that theabove loss functionin indeedconvex andLipschitzover Rd. Theproof
appears in Appendix C.
Lemma 8. For every V Z, the loss function fSGD (w,V) is convex and 4-Lipschitz over Rd with
∈
respect to its first argument.
For this construction of distribution and loss function, we show the following theorem,
Theorem 4. Assume that n > 2048 and η 1 . Consider the distribution SGD and the loss
≤ √T D
function fSGD with d = 712n2logn + 2n2, ε = 1 (1 cos( 2π )) and δ = η . Then, for
n2 − P(U) 1 8n3
Unprojected SGD (cf. Eq. (2) with W = Rd) with T = n iterati| ons,| initialized at w = 0 with step
1
size η, we have, with probability at least 1 over the choice of the training sample,
2
(i) The iterates of SGD remain within the unit ball, namely w Bd for all t = 1,...,T;
t
∈
(ii) For all m = 1,...,T, the m-suffix averaged iterate has:
FSGD (w ) FSGD (w ) = Ω η√T .
T,m
− ∗
(cid:0) (cid:1)
Algorithm’s dynamics. As inb GD, we providb e a keby lemma that characterizes the trajectory
of SGD under a certain ”good event”. For this good event, given a random training set sample
S = V n , we denote P = t 1V and S = t=nV . Moreover, if P = , we denote r =
{ i }i=1 t i=−1 i t i=t i t 6 ∅ t
argmin r : V P and J = v U. The good event is given as follows,
{ t ∈ t } t rTt ∈ T
= t T P = and J S (15)
′ t t t
E {∀ ≤ 6 ∅ ∈ }
In the following lemma we show that occurs with a constant probability. The proof appears in
′
E
Appendix C.
Lemma 9. For T = n and the event defined in Eq. (15), it holds that Pr( ) 1.
E′ E′ ≥ 2
Under this event, the dynamics of SGD is characterized as follows,
17Lemma 10. Assume the conditions of Theorem 4, and consider the iterates of unprojected SGD,
with step size η 1 initialized at w = 0. Under the event , we have for t 4 and s = 0,
≤ √T 1 E′ ≥ 6
3ηu +(t 1) η u k = 1
−8 1 − n3 1
1ηu 2 k t 2
w t(k) = 18 2ηuk
t −1
k≤
= t
−≤
1
−
0 t k n,
and for s = 0,
 ≤ ≤
η t 1φ(V ,1) k = 1
4n2 i=−2 i
w t(0,k) =  04nη
2
Pt i=−11φ(V i,i) kk =
/
t
1−
,t1
1 .
P
∈ { − }
where u U and every another
vect
or u holds u k 1V n V .
1 ∈ k k ∈ i=−1 i ∩ i=k i
For proving this key lemma, we analyze how the teTrms ℓSGD,TℓSGD affects the dynamics of SGD
1 2
underthe event . First, we show that the gradients of ℓSGD does notaffect the dynamics of SGD,
E′ 1
as the gradient of this term in any iterate w is zero. Theidea is formalized in the following lemma.
t
The proof is deferred to Appendix C.
Lemma 11. Assume the conditions of Theorem 4 and the event . Let w Rd and t be such that
′
E ∈
for every 2 k t 1, w(k) = cηu for c 1 and every such u holds u k 1V n V , and
≤ ≤ − k ≤ 2 k k ∈ i=−1 i ∩ i=k i
for every t k T, w(k) = 0. Then, for every t, it holds that, ℓSGD is differentiable at (w,V) and
≤ ≤ SGD 1 T T
for all i [n], we have ℓ (w,V )= 0.
∈ ∇ 1 t
Now, we analyze the gradient of ℓSGD. The role of this component is to decode the next ”bad
2
solution” α 1 t 1φ(V ,i) from the sets V ,...,V , and make a progress in this direction in
n i=−1 i 1 t 1
−
some subspa(cid:16)cePW(t −1). In th(cid:17)e following lemma, we show that the gradient of ℓS 2GD, serves this goal.
Lemma 12. Assume the conditions of Theorem 4 and the event . For every k, let ψ =
E′ k∗
1 k φ(V ,t). Moreover, let m 3 and w Rd such that w(1) = cηu for 3 c 0 and
n t=1 t ≥ ∈ 1 −8 ≤ ≤
u U, for every 2 k m 1, w(k) = 1ηu such that every u holds u k 1V n V ,
1P∈ ≤ ≤ − 8 k k k ∈ t=−1 t ∩ t=k t
w(m) = 1ηu where u holds u m 1V n V and for every m+1 k T, w(k) = 0.
2 m m m ∈ t=−1 t ∩ i=m t ≤T ≤ T
Moreover, assume that w holds w(0,m) = η ψ , w(0,1) η and for every k / m,1 , w(0,k) = 0.
SGD T 4n m∗ Tk k ≤ ∈ { }
Then, for every V U, ℓ is differentiable at (w,V) and, we have for k = 0,
⊆ 2 6
3u k = m
8 m
ℓSGD (w,V)(k) =  1α(ψ ) k = m+1
∇ 2 0−2 m∗
k / m,m+1
∈ { }
and,

1 m φ(V ,i) k = m
4n2 t=1 t
ℓSGD (w,V)(0,k) =  1 m φ(V ,i) 1 φ(V,i) k = m+1
∇ 2 −
0
4nP2 t=1 t − 4n2
k / m,m+1 .
P
∈ { }

18Now we can prove Lemma 10.
Proof of Lemma 10. We assume that holds and prove the lemma by induction on t. We begin
′
E
from the basis of the induction, t = 4, which is proved in Lemma 26 in Appendix C. Now, we
assume the hypothesis of the induction, that the lemma holds for iteration t and turn to show the
required for iteration t+1.
First, we notice that for every 2 k t 1, w (k) = cηu for c 1 and every such u holds
≤ ≤ − t k ≤ 2 k
u k 1V n V , and for every t k T, w (k) = 0. Then, by Lemma 11, we have that
k ∈ i=−1 i ∩ i=k i ≤ ≤ t
ℓSGD(w ,V ) = 0.
∇ 1 T t t T
Second, ℓSGD is a linear function, thus,
3
1 u s =1
−n3 1
∇ℓS 3GD(w t,V t)(s) = 
−
0
4n1 2φ(V t,1) s ot= he0 rw,1
ise.
Third, For ℓSGD(w ,V ), we notice for m = t
1
3 it holds that w (1) = cηu for 3 c 0 and
2 t t − ≥ t 1 −8 ≤ ≤
u U, for every 2 k m 1, w (k) = 1ηu such that every u holds u k 1V n V ,
1 ∈ ≤ ≤ − t 8 k k k ∈ t=−1 t ∩ t=k t
w (m) = 1ηu where u holds u m 1V n V , and for every m+1 k T, w(k) = 0.
t 2 m m m ∈ t=−1 t ∩ i=m t ≤T ≤ T
Moreover, w holds w(0,m) = η ψ , w (0,1) η and for every k / m,1 , w (0,k) = 0. Then, by
t 4n m∗ kTt k ≤ T ∈ { } t
Lemma 12, we get that, we have for k = 0,
6
3u k = t 1
∇ℓS 2GD(w t,V t)(k) =
−
08 1 2t α− (1 ψ
t∗
−1) k
k
=
/
t t−
1,t
∈ { − }
and,

1 t 1φ(V ,i) k = m
4n2 i=−1 i
∇ℓS 2GD(w t,V t)(0,k) = 
−
0
4n1
P2
t i=1φ(V i,i) kk =
/
m m+ ,m1
+1 .
P
∈ { }
Now, by Lemma 23, for j = argmin i{i:v
i
∈
t i=−11V
i
}, we get that
T t 1
−
α(ψ )= v V .
t∗ −1 j ∈ i
i=1
\
We notice that t 1V = P and thus α(ψ ) = J . Then, by , α(ψ ) also holds α(ψ ) S .
Combining the
abi=− ov1
e
i togetht
er, we get,
fort∗ −u1
=
α(t
ψ ) P
E S′
,
t∗ −1 t∗ −1 ∈ t
T t t∗ −1 ∈ t ∩ t
1 u k = 1
−n3 1
3u k = t 1
∇f(w t,V t)(k) = −8 21t u− t1
k =
t−
0 k / 1,t 1,t ,
and,
 ∈ { − }
1 φ(V ,1) k = 1
−4n2 3
 1 t 1φ(V ,i) k = t 1
∇f(w t,V t)(0,k) = −4n 42
n1
P2
i=−
t
i1 =1φ(i
V i,i) k =
t−
0 k / 1,t 1,t ,
P
 ∈ { − }
19and the lemma follows. (cid:3)
The proof of Theorem 4 is similar to Theorem 3, using Lemma 10 instead of Lemma 4, and is
deferred to Appendix C.
Acknowledgments
This project has received fundingfrom the European Research Council (ERC) under the European
Union’s Horizon 2020 research and innovation program (grant agreements No. 101078075; 882396).
Views and opinions expressed are however those of the author(s) only and donot necessarily reflect
those of the European Union or the European Research Council. Neither the European Union nor
the granting authority can be held responsible for them. This work received additional support
from the Israel Science Foundation (ISF, grant number 2549/19), from the Len Blavatnik and the
Blavatnik Family foundation, and from the Adelis Foundation.
References
N. Alon, S. Ben-David, N. Cesa-Bianchi, and D. Haussler. Scale-sensitive dimensions, uniform
convergence, and learnability. Journal of the ACM (JACM), 44(4):615–631, 1997.
I.Amir,Y.Carmon,T.Koren,andR.Livni.Nevergofullbatch(instochasticconvexoptimization).
Advances in Neural Information Processing Systems, 34:25033–25043, 2021a.
I. Amir, T. Koren, and R. Livni. SGD generalizes better than gd (and regularization doesn’t help).
In Conference on Learning Theory, pages 63–92. PMLR, 2021b.
P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and struc-
tural results. Journal of Machine Learning Research, 3(Nov):463–482, 2002.
P. L. Bartlett, P. M. Long, G. Lugosi, and A. Tsigler. Benign overfitting in linear regression.
Proceedings of the National Academy of Sciences, 117(48):30063–30070, 2020.
P.L.Bartlett, A.Montanari,andA.Rakhlin. Deeplearning: astatisticalviewpoint. Actanumerica,
30:87–201, 2021.
R. Bassily, V. Feldman, C. Guzm´an, and K. Talwar. Stability of stochastic gradient descent on
nonsmooth convex losses. Advances in Neural Information Processing Systems, 33, 2020.
M. Belkin. Fit without fear: remarkable mathematical phenomena of deep learning through the
prism of interpolation. Acta Numerica, 30:203–248, 2021.
A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. Learnability and the vapnik-
chervonenkis dimension. Journal of the ACM (JACM), 36(4):929–965, 1989.
O. Bousquet and A. Elisseeff. Stability and generalization. The Journal of Machine Learning
Research, 2:499–526, 2002.
D. Carmon, R. Livni, and A. Yehudayoff. The sample complexity of ERMs in stochastic convex
optimization. arXiv preprint arXiv:2311.05398, 2023.
V.Feldman. Generalization ofERMinstochastic convex optimization: Thedimensionstrikes back.
In Advances in Neural Information Processing Systems, volume 29, 2016.
20A. D. Flaxman, A. T. Kalai, and H. B. McMahan. Online convex optimization in the bandit
setting: gradient descent without a gradient. In Proceedings of the sixteenth annual ACM-SIAM
symposium on Discrete algorithms, pages 385–394, 2005.
M. Hardt, B. Recht, and Y. Singer. Train faster, generalize better: Stability of stochastic gradient
descent. In International Conference on Machine Learning, pages 1225–1234. PMLR, 2016.
S. Kale, A. Sekhari, and K. Sridharan. SGD: The role of implicit regularization, batch-size and
multiple-epochs. arXiv preprint arXiv:2107.05074, 2021.
T. Koren, R. Livni, Y. Mansour, and U. Sherman. Benign underfitting of stochastic gradient
descent. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors,
Advances in Neural Information Processing Systems, volume 35, pages 19605–19617. Curran
Associates, Inc., 2022.
R. Magen and O. Shamir. Initialization-dependent sample complexity of linear predictors and
neural networks. arXiv preprint arXiv:2305.16475, 2023.
M. E. Muller. A note on a method for generating points uniformly on n-dimensional spheres.
Communications of the ACM, 2(4):19–20, 1959.
B. Neyshabur, R. Tomioka, and N. Srebro. In search of the real inductive bias: On the role of
implicit regularization in deep learning. arXiv preprint arXiv:1412.6614, 2014.
B. Neyshabur, S. Bhojanapalli, D. McAllester, and N. Srebro. Exploring generalization in deep
learning. Advances in neural information processing systems, 30, 2017.
S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algo-
rithms. Understanding Machine Learning: From Theory to Algorithms. Cambridge University
Press, 2014. ISBN 9781107057135.
S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan. Learnability, stability and uniform
convergence. The Journal of Machine Learning Research, 11:2635–2670, 2010.
V. Vapnik. On the uniform convergence of relative frequencies of events to their probabilities.
Theory of Probability and its Applications, 16(2):264–281, 1971.
C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals. Understanding deep learning requires
rethinking generalization. In 5th International Conference on Learning Representations, ICLR
2017, 2017.
A Differentiability and Proofs of Theorems 1 and 2
In this section, we complete theproof of Theorems 1 and 2, by showing a construction of a differen-
tiable objective that maintains the same lower bounds given in Theorems 3 and 4 and Lemma 33.
Our general approach is to use a randomized smoothing of the original objectives. Then, we use
the fact that the subgradients are unique along any possible trajectory of GD, to show that when
smoothing is applied within a sufficiently small neighborhood, gradients along any such trajectory
are preserved. Consequently, this approach does not impact the dynamics of the optimization
algorithm, while simultaneously ensuring the objectives become differentiable everywhere.
21A.1 Proof of Theorem 1
Full construction. The hard distribution is defined to be as in Section 4. The hard loss
D
function is a smoothing of f (Eq. (11)), and is defined as
f˜(w,(V,j)) := E [f(w+δv,(V,j))], (16)
v B
∈
for a sufficiently small δ > 0 and the d-dimensional unit ball B. Analogously, we denote the empir-
ical loss and the population loss with respect to the loss function f˜as F˜(w) = 1 n f˜(w,(V ,j ))
n i=1 i i
and F˜(w) = E f˜(w,(V,j)), respectively. The loss function f˜ is differentiable, 5-Lipschitz
with respect to( iV t, sj) fi∼ rD st argument and convex over Rd, as stated in theb followingP lemma.
Lemma 13. For every (V,j) Z, the loss function f˜is differentiable, convex and 5-Lipschitz with
∈
respect to its first argument and over Rd.
We first prove the following theorem,
Theorem 5. Assume that n > 0, T > 32002 and η 1 . Consider the distribution and the loss
≤ √T D
function f˜for d = 178nT +2n2, ε = 1 (1 cos( 2π )), β = ǫ , δ = ηβ, δ = η and δ = 3ηβ.
n2 − P(U) 4T2 32 1 2n 2 16
Then, for Unprojected GD (cf. Eq. (1) with W
=|Rd)|
on F, initialized at w = 0 with step size η,
1
we have, with probability at least 1 over the choice of the training sample:
6
b
(i) The iterates of GD remain within the unit ball, namely w Bd for all t = 1,...,T;
t
∈
(ii) For all m = 1,...,T, the m-suffix averaged iterate has:
F˜(w ) F˜(w ) = Ω η√T .
T,m
− ∗
(cid:0) (cid:1)
Algorithm dynamics. Now we show that the dynamics of GD when is applied on F˜ is identical
to dynamics of the algorithm on F, as stated in the following lemma.
b
Lemma 14. Under the conditionbs of Theorems 3 and 5, let w t,w˜
t
be the iterates of Unprojected
GD with step size η 1 and w = 0, on F and F˜ respectively. Then, if occurs, then for every
≤ √T 1 E
t [T], it holds that w = w˜ .
t t
∈ b b
Proof of Theorem 5. Next, we set out to establish the proof for Theorem 5.
Proof of Theorem 5. Let w be the m-suffix average of GD when is applied on F. Let w =
T,m
argmin F(w). By Lemma 14, we know that, with probability of at least 1, occurs and w ∗ =
w 6 E T,m
w . Then, by Theorem 3 and Lemma 32, b
T,m
η
√T F(w ) F(w )
T,m
3200 ≤ − ∗
= F(w ) F(w )
T,m
− ∗
F˜(w )+5δ F˜(w )+5δ
T,m
≤ − ∗
F˜(w )+5δ F˜(w )+5δ,
T,m
≤ − ∗
and,
η 10ηǫ
F˜(w ) F˜(w ) √T
T,m − ∗ ≥ 3200 − 128T2
22η η
√T
≥ 3200 − 10T2
η
√T. (T 30)
≥ 6400 ≥
(cid:3)
Now we can finally prove Theorem 1. The proof is an immediate corollary from Theorem 5
and the lower bound of Ω min 1 ,1 given in Lemma 35 in Appendix E. It’s important to
ηT
highlight that we offer arigo(cid:16)rous(cid:16)proof f(cid:17)o(cid:17)r a modified version of Theorem 1, wheretheloss function
f possesses a Lipschitz constant of only 5. By scaling down this loss function by a factor of 1 and
5
simultaneously adjusting the step size η by a factor of 5, we can employ the same proof to establish
the validity of Theorem 1.
Proof of Theorem 1. We know that η 1 . First, by Theorem 5, we know that for Unprojected
≤ 5√T
GD and d = 178nT +2n2, there exist a distribution over a probability space Z, a constant C
1 1
and a loss function f˜:Rd1 Z R such that, with pD robability of at least 1,
× → 6
F˜(w ) F˜(w ) C η√T.
T,m 1
− ∗ ≥
Second, by Lemma 35, we know that for Unprojected GD and d = max(25η2T2,1), there exist a
2
constant C and a deterministic loss function f˜OPT : Rd2 R such that
2
→
1
f˜OPT(w ) f˜OPT(w ) C min 1,
T,m 2
− ∗ ≥ ηT
(cid:18) (cid:19)
Now, let C = 21 min(C 1,C 2). If η
≥
T −3 4, then, η√T
≥
min(1, η1 T), and we get,
1 1
F˜(w ) F˜(w ) C η√T +min 1, C min 1,η√T + .
T,m
− ∗ ≥ ηT ≥ ηT
(cid:18) (cid:18) (cid:19)(cid:19) (cid:18) (cid:18) (cid:19)(cid:19)
Otherwise, we get that,
1 1
f˜OPT(w ) f˜OPT(w ) C η√T +min 1, C min 1,η√T + .
T,m
− ∗ ≥ ηT ≥ ηT
(cid:18) (cid:18) (cid:19)(cid:19) (cid:18) (cid:18) (cid:19)(cid:19)
Since in both cases, by Lemma 35 and Theorem 5, w Bd for every t [T], the theorem is
t
∈ ∈
applicable also for Projected GD. (cid:3)
A.2 Proof of Theorem 2
Full construction. The hard distribution SGD is defined to be as in Section 5. The hard loss
D
function is a smoothing of fSGD (Eq. (14)), and is defined as
f˜SGD(w,V):= E fSGD(w+δv,V) , (17)
v B
∈
h i
for a sufficiently small δ > 0 and the d-dimensional unit ball B. Analogously, we denote the
SGD
empirical loss and the population loss with respect to the loss function f˜SGD as F˜ (w) =
1 n f˜SGD(w,V ) and F˜SGD(w) = E f˜SGD(w,V), respectively. The loss function f˜SGD is
dn iffei r= e1 ntiable, 4-Li ipschitz with respect tV o∼ iD ts first argument and convex over Rd, as stb ated in the
P
following lemma.
23Lemma 15. For every V Z, the loss function
f˜SGD
is differentiable, convex and 4-Lipschitz with
∈
respect to its first argument and over Rd.
We first prove the following theorem,
Theorem 6. Assume that n > 2048 and η 1 . Consider the distribution SGD and the loss
≤ √n D
function f˜SGD with d = 712n2logn+2n2, ε = 1 (1 cos( 2π )), δ = ηε and δ = η . Then,
n2 − P(U) 32n3 1 8n3
for Unprojected SGD (cf. Eq. (2) with W = Rd) with T =| n ite| rations, initialized at w = 0 with
1
step size η, we have, with probability at least 1 over the choice of the training sample,
2
(i) The iterates of SGD remain within the unit ball, namely w Bd for all t = 1,...,n;
t
∈
(ii) For all m = 1,...,n, the m-suffix averaged iterate has:
SGD SGD
F˜ (w ) F˜ (w )= Ω η√n .
n,m
− ∗
b b (cid:0) (cid:1)
Algorithm’s dynamics. Now, As in GD, the main sbtep in proving Theorem 6 is to show that
taking expectation of fSGD for every point w in a ball with small enough radius does not change
the dynamics of SGD.
Lemma 16. Under the conditions of Theorems 4 and 6, let w ,w˜ be the iterates of Unprojected
t t
SGD
SGD with step size η 1 and w = 0, on FSGD and F˜ respectively. Then, if occurs, then
≤ √T 1 E′
for every t [T], it holds that w = w˜ .
t t
∈ b b
Proof of Theorem 6. Next, we set out to establish the proof for Theorem 6.
Proof of Theorem 6. Let w be the m- suffix average of SGD when is applied on fSGD and let
n,m
w = argmin FSGD(w). By Lemma 16, we know that, with a probability 1 ,w = wSGD. Then,
w 2 n,m n,m
∗
by Theorem 4 and Lemma 32,
b b
η
√n FSGD(w ) FSGD(w )
n,m
64000 ≤ − ∗
= FbSGD(w n,m) −FbSGD(w
b
∗)
SGD SGD
Fb˜ (w n,m)+4bδ F˜
b
(w )+4δ
≤ − ∗
SGD SGD
Fb˜ (w )+4δ Fb˜ (w )+4δ,
n,m b
≤ − ∗
and, b b b
SGD SGD η ηǫ
F˜ (w ) F˜ (w ) √n
n,m − ∗ ≥ 64000 − 4n3
η η
b b √n
b ≥ 64000 − 4n3
η
√n. (n 40)
≥ 128000 ≥
(cid:3)
Now we can finally prove Theorem 2.
24Proof proof of Theorem 2. We know that T = n and η 1 . First, by Theorem 6, we know that
≤ 5√T
forUnprojectedSGD andd = 712n2logn+2n2, thereexistadistribution SGD over aprobability
1
space Z, a constant C and a loss function f˜SGD : Rd1 Z R such thatD , with probability of at
1
× →
least 1,
2
SGD SGD
F˜ (w ) F˜ (w ) C η√T.
T,m 1
− ∗ ≥
Second, by Lemma 35, we knowb that for Unprbojected SGD and d
2
= max(25η2T2,1), there exist
a constant C and a deterministic loss function
f˜OPTb
: Rd2 R such that
2
→
1
f˜OPT(w ) f˜OPT(w ) C min 1,
T,m 2
− ∗ ≥ ηT
(cid:18) (cid:19)
Now, let C = 21 min(C 1,C 2). If η
≥
T −3 4, then, ηb √T
≥
min(1, η1 T), and we get,
SGD SGD 1 1
F˜ (w ) F˜ (w ) C η√T +min 1, C min 1,η√T + .
T,m
− ∗ ≥ ηT ≥ ηT
(cid:18) (cid:18) (cid:19)(cid:19) (cid:18) (cid:18) (cid:19)(cid:19)
b b
Otherwise, we get that, b
1 1
f˜OPT(w ) f˜OPT(w ) C η√T +min 1, C min 1,η√T + .
T,m
− ∗ ≥ ηT ≥ ηT
(cid:18) (cid:18) (cid:19)(cid:19) (cid:18) (cid:18) (cid:19)(cid:19)
Since in both cases, by Lembma 35 and Theorem 6, w Bd for every t [T], the theorem is
t
∈ ∈
applicable also for Projected SGD. (cid:3)
B Proofs of Section 4
B.1 Proofs for the full construction
−d′
Proof of Lemma 1. Let r = 2178. For every 1 i r and 1 j d
′
we define the random variable
uj bea random variable to be 1 with probab≤ ilit≤ y 1 and ≤ 1 w≤ ith probability 1. Then, for every
i √d′ 2 −√d′ 2
j
1 i r, we define the vector u which its jth entry is u and look at the set U = u ,u ,...u .
≤ ≤ i i { 1 2 r }
This set will hold the required property with positive probability. First, for every i= k, u ,u are
i k
6 h i
sums of d random variables that taking values in [ 1, 1] with E u ,u = 0. Then by Hoeffding’s
−d′ d′
h
i k
i
inequality,
−2(1)2
Pr( u i,u k
1
) 2e
d′· d8 4
′2 = 2e
−1d 2′
8
|h i| ≥ 8 ≤
Then, by union bound on the r pairs of vectors in U,
2
(cid:0) (cid:1)
1 ′ r ′ 1
Pr( i,k u i,u k ) 2e −1d 28 < 2e −1d 28 r2 1.
∃ |h i| ≥ 8 ≤ · 2! · 2 ≤
(cid:3)
Lemma 17. Let n,d 1 and a set U Bd. Let P(U) be the power set of U. Then, there exist a
set Ψ R2n2 , a numbe≥ r 0 < ǫ < 1 and⊆ two mappings φ : P(U) [n2] R2n2 , α : R2n2 U such
⊆ n × → →
that,
(i) For every j [n2] and V U, it holds φ(V,j) 1;
∈ ⊆ k k≤
25(ii) For every ψ Ψ, it holds ψ 1;
∈ k k ≤
(iii) Let V ,...,V be arbitrary subsets of U. If j ,...,j hold that j = j for i = k, ψ =
1 n 1 n i k ∗
6 6
1 n φ(V ,j ) is that,
n i=1 i i
P•
n
1 7
ψ , φ(V ,j ) > ;
∗ i i
n 8n
D Xi=1 E
• For every ψ Ψ, ψ = ψ :
∗
∈ 6
n n
1 1
ψ , φ(V ,j ) ψ, φ(V ,j ) +ǫ;
∗ i i i i
n ≥ n
D Xi=1 E D Xi=1 E
• If n i=1V i 6= U,thenitholdsthatα(ψ ∗) = v i∗
∈
U
\
n i=1V i fori ∗ = min {i :v i
∈
U
\
n i=1V i }.
Proof. First, Swe consider an arbitrary enumeration of P(US) = V1,...V P(U) and defineSg :
| |
{ }
P(U) R2, g(Vi) = sin 2πi ,cos 2πi . Now, we refer to a vector a R2n2 as a
→ P(U) P(U) ∈
| | | |
concatenation of n2 vect(cid:16)ors (cid:16)in R2, (cid:17)a(1),..(cid:16).,a(n2).(cid:17)(cid:17)Then, we define δ = 1 cos 2π , ǫ = δ
− P(U) n2
| |
and (cid:16) (cid:17)
g(V) i= j
φ(V,j)(i) =
0 otherwise
(
As a result, for every Vi,j it holds that
2πi 2 2πi 2
φ(Vi,j) = g(Vi) = sin +cos = 1
k k k k s P(U) P(U)
(cid:18)| |(cid:19) (cid:18)| |(cid:19)
Moreover, if j = j ,
1 2
6
φ(Vi,j ),φ(Vi,j ) = 0,
1 2
h i
and if i > k,
φ(Vi,j),φ(Vk,j) = g(Vi),g(Vk)
h i h i
2πi 2πk 2πi 2πk
= sin sin +cos cos
P(U) P(U) P(U) P(U)
(cid:18)| |(cid:19) (cid:18)| |(cid:19) (cid:18)| |(cid:19) (cid:18)| |(cid:19)
2π(i k)
= cos −
P(U)
(cid:18) | | (cid:19)
2π
cos (cos is monotonic decreasing in [0,π/2])
≤ P(U)
(cid:18)| |(cid:19)
= 1 δ
−
We notice that 0 < δ < 1. Now, we consider an arbitrary enumeration of U = v ,...v , and
1 U
define the following set Ψ
R2n2
and the following two mappings σ
:R2n2 P(U{
),α :
R2| n|2}
U,
⊆ → →
n
1
Ψ = φ(V ,j ) : i V U, j [n2] and i = l = j = j
i i i i i ℓ
{n ∀ ⊆ ∈ 6 ⇒ 6 }
i=1
X
26Note that, for every ψ Ψ,
∈
n n
1 1
ψ = φ(V ,j ) φ(V ,j ) = 1.
i i i i
k k kn k ≤ n k k
i=1 i=1
X X
Then, for every a R2n2 and j [n2], we denote the index q(a,j) [P(U)] as
∈ ∈ ∈ | |
q(a,j) = argmax g(V ),a(j) ,
r
r h i
and define the following mapping σ
:R2n2
P(U),
→
n2
σ(a) = V .
q(a,j)
j=1,[a(j)=0
6
Moreover, for every a
R2n2
, we denote the index p(a) [U ] as
∈ ∈ | |
p(a) = argmin i : v U σ(a) ,
i
{ ∈ \ }
i
and define the following mapping α:
R2n2
U,
→
v σ(a) = U
α(a) = U .
| |
v σ(a) = U
( p(a)
6
Now, Let V ,...,V U and j ,...j that are sampled uniformly from [n2], We prove the last
1 n 1 n
⊆
part of the lemma under the condition that j = j for i = k. ψ = 1 n φ(V ,j ) holds
i 6 k 6 ∗ n i=1 i i
n n n P
1 1 1
ψ , φ(V ,j ) = φ(V ,j ), φ(V ,j )
∗ i i i i i i
h n i hn n i
i=1 i=1 i=1
X X X
n
1
= φ(V ,j ),φ(V ,j )
n2 h i i i i i
i=1
X
1
=
n
7
>
8n
Forψ = 1 n φ(V ,j )suchthatψ = ψ ,thereareatmostnpairsi,lsuchthat φ(V ,j ),φ(V ,j ) =
n l=1 l′ l′ 6 ∗ h i′ i′ l′ l′ i 6
0. thus,thereexistsapair(V ,j )that(V ,j ) / (V ,j ) :i [n] . andforeveryi, φ(V ,j ),φ(V ,j )
P r′ r′ r′ r′ ∈ { i i ∈ } h i i l′ l′ i ≤
1 δ. As a result,
−
n n n
1 1 1
ψ, φ(V ,j ) = φ(V ,j ), φ(V ,j )
h n
i i
i hn
l′ l′
n
i i
i
l=1 i=1 i=1
X X X
n n
1
= φ(V ,j ),φ(V ,j )
n2 h i i l′ l′ i
i=1l=1
XX
n
1
1 δ+ 1
≤ n2  − 
i=1,i=r
X6
1  
(1 δ+n 1)
≤ n2 − −
271 δ
=
n − n2
n
1
= ψ , φ(V ,j ) ǫ
∗ i i
h n i−
i=1
X
Furthermore, since if all j are distinct, for every i it holds that, 1 n φ = (V ,i)(ji) = 1g(V ),
i n i=1 i n i
thus,
P
1
n
1
n (ji)
q φ(V ,j ),j = argmax g(V ), φ(V ,j )
i i i r i i
n ! r h n i
i=1 i=1
X X
1
= argmax g(V ), g(V )
r i
r h n i
= i,
and we get,
n
1
σ(ψ ) = σ φ(V ,j )
∗ i i
n !
i=1
X
n2
= V q( n1 n i=1φ(Vi,ji),j)
j=1, n1 n i=[ 1φ(Vl,ji)(j) 6=0
P
n
P
= V q( n1 n i=1φ(Vi,ji),ji) (The indices that are non-zero are {j i }n i=1})
i=1
[
n P
= V
i
i=1
[
Finally, assuming that n V = U,
i=1 i 6
S n
α(ψ ) = v U V .
∗ p(a) i
∈ \
i=1
[
(cid:3)
Proof of Lemma 2. We prove that ℓ ,ℓ and ℓ are convex and 1-Lipschitz and ℓ is convex and
1 2 4 3
12-Lipschitz.
First, by Lemmas 1 and 17 for every u U and V P(U), j [n2], it holds that u = 1,
∈ ∈ ∈ k k
φ(V,j) = 1. Then,ℓ is a1-Lipschitz linearfunction, andℓ isamaximum over 1-Lipschitz linear
2 4
k k
functions, thus, both functions are convex and 1-Lipschitz. Moreover, for every possible ψ Ψ
∈
n n
1 1
ψ = φ(V ) φ(V ) = 1.
l l
k k kn k ≤ n k k
l=1 l=1
X X
thus, ℓ is a maximum over 2-Lipschitz linear functions, thus, it is convex and 2-Lipschitz. Now,
3
for ℓ , for every set V U, let α (w) RT 1 to be the vector which its k’th coordinate is
1 V −
⊆ ∈
α (w)(k) = max 3η,max uw(k+1) and prove convexity and 1-Lipshitzness. For establishing
V 32 u ∈V h i
convexity, observ(cid:16)e (cid:17)
T 3η 2
max ,max u,(λx+(1 λ)y)(k)
v u uk X=2 (cid:18)32 u ∈V h − i (cid:19)
t
28T 3η 2
= max ,max λ u,x(k) +(1 λ) u,y(k)
v u uk X=2 (cid:18)32 u ∈V
(cid:0)
h i − h i (cid:1)(cid:19)
t
T 3η 2
max ,max λ u,x(k) +max (1 λ) u,y(k)
≤ v u uk X=2 (cid:18)32 u ∈V
(cid:0)
h i
(cid:1)
u ∈V
(cid:0)
− h i (cid:1)(cid:19)
t (convexity of max & monotonicity of square root)
T 3η 3η 2
λmax ,max u,x(k) +(1 λ)max ,max u,y(k)
≤ v u uk X=2(cid:18) (cid:18)32 u ∈V (cid:0)h i (cid:1)(cid:19) − (cid:18)32 u ∈V h i (cid:19)(cid:19)
t
= λα (x)+(1 λ)α (y)
V V 2
k − k
λ α (x) +(1 λ)α (y) (convexity of ℓ norm)
V 2 V 2 2
≤ k k − k
T 3η 2 T 3η 2
= λ max ,max ux(k) +(1 λ) max ,max uy(k) .
v u uk X=2 (cid:18)32 u ∈V h i (cid:19) − v u uk X=2 (cid:18)32 u ∈V h i (cid:19)
t t
For 1-Lipschitzness, for every w Rd and sub-gradient g(w,V) ∂ℓ (w,V), there exists a sub
1
∈ ∈
2
gradient h(w,V) ∂ T max 3η,max uw(k) such that
∈ k=2 32 u ∈V h i
(cid:18) (cid:16) (cid:17) (cid:19)
P
h(w,V) h(w,V)
g(w,V) = k k = k k .
k k 2
r
T k=2max 3 3η 2,max
u ∈V
huw(k)
i
2 2
q
T k=2α V(w)(k)2
P (cid:16) (cid:17) P
Moreover, for every k and sub gradient b (w) ∂ α (w)(k) we denote r (w) Rd the
k,V V k,V
∈ ∈
vector with r (w)(k) = b (w) and for j = k, r ((cid:16)w)(j) = 0(cid:17). Then, for every sub gradient
k,V k,V k,V
6
2
h(w,V) ∂ T max 3η,max uw(k) , there exists T 1 such vectors r (w) Rd
∈ k=2 32 u ∈V h i − k,V ∈
(2 k T) s(cid:18) uPch that, (cid:16) (cid:17) (cid:19)
≤ ≤
T
h(w,V) = 2 r (w)α (w)(k)
k,V V
k=2
X
As a result, by the fact that every sub gradient of b (w) ∂ α (w)(k) is either 0 or λ u +
k,V V 1 1
∈
λ u +... +λ u for λ 1, such that for all every j,k, u (cid:16) U and(cid:17)α (w)(k) = u ,w() k ,
2 2 p p i i ≤ j ∈ V h j i
combining by the facts Pthat for distinct k,k ′, r k,V,r k′,V are orthogonal, it holds, for u2 j,...uT j ∈ U
such that for every k, α (w)(k) = uk,w(k) ,
V h j i
T
h(w,V) = 2 r (w)α (w)(k)
k,V V
k k k ik
k=2
X
T
= 2 r (w)α (w)(k)
k,V V
k ik
k= X2,bk,V
T
= 2 r uk,w(k) .
k k,V h j ik
k=2
X
29Now, we denote ck(w) Rd the vector with ck(w)(k) = uk and for j = k, ck(w)(j) = 0, and,
j ∈ j j 6 j
T
h(w,V) = 2 r ck,w
k k k k,V h j ik
k=2
X
T T
2 r ck,w , r cl,w
≤ vh k,V h j i l,V h j ii
u k=2 l=2
u X X
t
T
= 2 r 2 ck,w 2
v k k,V k h j i
uk=2
uX
t
T
2 uk,w(k) 2
≤ v h j i
uk=2
uX
t
T
= 2 α
(w)(k)2
.
v V
uk=2
uX
t
The lemma follows. (cid:3)
B.2 Proof of algorithm’s dynamics
In this section we describe the dynamics of GD when applied on F for training set S that is
sampled from a distribution . We begin with showing that the good event (Eq. (12)) occurs
D E
with a constant probability. b
Proof of Lemma 3. By the fact that every V and j are independent, it is enough to show that
i i
n
1
Pr V i = U d′ ,
6 ! ≥ 2
i=1
[
and,
1
Pr(for every k = l, j = j ) .
k l
6 6 ≥ 3
For the former, for every u U d′, since V i are sampled independently and every vector u U d′ is
∈ ∈
in every V with probability 1,
i 2
n n
Pr u V = 1 Pr u / V = 1 2 n,
i i −
∈ ! − ∈ ! −
i=1 i=1
[ [
thus, since by Lemma 1, |U d′
|≥
1d 7′
8
= n , it holds that,
n n
Pr V i = U d′ = Pr u U d′ u V i
! ∀ ∈ ∈ !
i=1 i=1
[ [
= 1 2 −n |U d′ |
−
′
(cid:0)
1 2
n(cid:1)21d
78
−
≤ −
= (cid:0)1 2
n(cid:1)2n
−
−
1
(cid:0) (cid:1)
≤ e
301
< .
2
We conclude,
n
1
Pr V i = U d′ .
6 ! ≥ 2
i=1
[
For the latter, since all j s are sampled independently, for a single pair k = l, it holds that
i
6
1
Pr(j = j ) = 1
k 6 l − n2
As a result,
n(n−1) n2
Pr(for every k = l, j = j ) = 1 1 2 1 1 2 1 1 . (cid:3)
6 k 6 l − n2 ≥ − n2 ≥ √2e ≥ e
(cid:18) (cid:19) (cid:18) (cid:19)
From now on, we analyze the dynamics of the GD conditioned on (Eq. (12)). We begin with
E
several lemmas.
Proof of Lemma 5. For the first part, we know that, for every 2 k T, w(k) = cηu for c 1. In
≤ ≤ 0 ≤ 2
addition, by the facts that u U n V and that for every u= v U, it holds that u,v 1,
0 ∈ \ i=1 i 6 ∈ h i ≤ 8
we get for every i, max u ,u 1, thus, for every i and k 2,
u ∈Vih 0 i ≤S8 ≥
1 η
maxuw(k) = max u,cηu cη .
0
u ∈Vi u ∈Vih i≤ 8 · ≤ 16
For the second part, for every sub-gradient g(w,V ) ∂ℓ (w,V ), there exists a sub gradient
i 1 i
∈
2
h(w,V ) ∂ T max 3η,max uw(k) such that
i ∈ k=2 32 u ∈V h i
(cid:18) (cid:16) (cid:17) (cid:19)
P
h(w,V )
i
g(w,V )= .
i
2
2 T max 3η,max uw(k)
r
k=2 32 u ∈Vih i
(cid:16) (cid:17)
P
Then, since for every k, it holds that max w(k),u η , every such sub-gradient h(w,V ) is
zero, ℓ (w,V ) = 0.
u ∈U h 0 i ≤ 16 i
(cid:3)
1 i
∇
Proof of Lemma 6. First, for the first part, by Lemma 17, the fact that for every ψ, α(ψ) 1,
k k ≤
and by w(1) η, for every ψ Ψ, ψ = 1 n φ(V ,j ) holds,
k k ≤ ∈ ∗ n i=1 i i
P n
1 ǫ η ηǫ
w(0),ψ α(ψ ),w(1) φ(V ,j ),ψ
h ∗ i− 4T2h ∗ i ≥ hn i i ∗ i− 4
i=1
X
n
1 ηǫ
η φ(V ,j ),ψ
i i ∗
≥ hn i− 4
i=1
X
n
1 ηǫ
η φ(V ,j ),ψ +ηǫ (Lemma 17)
i i
≥ hn i − 4
i=1
X
n
1 ηǫ ηǫ
= η φ(V ,j ),ψ + +
i i
hn i 2 4
i=1
X
1 ǫ ηǫ
> w(0),ψ α(ψ),w(1) + ,
h i− 4T2h i 4
31thus,
n
1 ǫ 1
argmax w(0),ψ α(ψ),w(1) = ψ = φ(V ,j ).
ψ Ψ h i− 4T2h i ∗ n i i
∈ (cid:18) (cid:19) Xi=1
For the second part, by the fact that ǫ < 1 and Lemma 17,
n
1 ǫ 7η η η η η
w(0),ψ α(ψ ),w(1) > + = δ + .
h ∗ i− 4T2h ∗ i≥ 8n − 4n 2n 16n 1 16n
Now, by , for u = α(ψ ), which is the u with the minimal index in U n V ,
E 0 ∗ \ i=1 i
n S
α(ψ ) = u U V .
∗ 0 i
∈ \
i=1
[
As a result, by the fact that the maximum is attained uniquely at ψ , we derive that,
∗
1 n φ(V ,j ) k = 0
n i=1 i i
∇ℓ 3(w)(k) =  0−P41 Tǫ 2u
0
k ot= her1
wise.
 (cid:3)
Proof of Lemma 7. We show that the maximum is attained uniquely at k = m and u = u . For
0
k = 1 and every u U,
∈
3 1 3 1 η 9η η 13η
u,w (1) u,w (2) = u,cηu u, u + = .
t t 0 0
8h i− 2h i 8h i− 2h 8 i≤ 512 128 512
Moreover, for every 2 k m 2 and every u U,
≤ ≤ − ∈
3 1 3 η 1 η 3η η 7η
u,w(k) u,w(k+1) = u, u u, u + = .
0 0
8h i− 2h i 8h 8 i− 2h 8 i≤ 64 128 128
For k = m 1 and every u U,
− ∈
3 1 3 η 1 η 3η η 5η
u,w(m 1) u,w(m) = u, u u, u + = .
− 0 0
8h i− 2h i 8h 8 i− 2h 2 i≤ 64 32 64
For k = m and u = u ,
0
3 1 3 η 1 3η
u,w(m) u,w(m+1) = u , u u ,0 = .
0 0 0
8h i− 2h i 8h 2 i− 2h i 16
For k = m and u = u ,
0
6
3 1 3 η 1 3η
u,w(m) u,w(m+1) = u, u u,0 .
′ 0 ′
8h i− 2h i 8h 2 i− 2h i ≤ 128
For every m+1 k < T 1 and every u U,
≤ − ∈
3 1
u,w(k) u,w(k+1) = 0.
′
8h i− 2h i
Moreover, since T 4,η < 1,ǫ < 1, δ 3η , and
≥ 1 ≤ 1024
3 1 3η η
u,w(m) u,w(m+1) = > δ + .
2
8h i− 2h i 16 64
32We derive that,
3u k = m
8 0
∇ℓ 4(w)(k) = 
−
0
1 2u
0
othk e= rwm ise+
.
1

(cid:3)
Lemma 18. Under the conditions of Theorem 3, if occurs and w is the iterate of Unprojected
t
E
GD on F, with step size η 1 and w = 0, then, for t = 2 it holds that,
≤ √T 1
b η n φ(V ,j ) k = 0
w (k) = n i=1 i i
2
(0
P
otherwise.
Proof. For t = 1, w = 0. By Lemma 5 we know that for every i, ℓ (w ,V ) = 0. Moreover, by
1 1 1 i
∇
the fact that δ ,δ > 0 the maximum in ℓ and ℓ is attained in δ and δ , respectively, thus we
1 2 3 4 1 2
get that
ℓ (w ) = ℓ (w) = 0
3 1 4
∇ ∇
As a result,
F(w )(k) = 1 n ℓ (w ,(V ,j ))(k) = −n1 n i=1(V i,j i) k = 0
1 2 1 i i
∇ n i=1∇ (0
P
otherwise,
X
b
and,
η n φ(V ,j ) k = 0
w (k) = n i=1 i i
2
(0
P
otherwise.
(cid:3)
Lemma 19. Under the conditions of Theorem 3, if occurs and w is the iterate Unprojected GD
t
E
on F, with step size η 1 and w = 0, then, for t = 3 it holds that,
≤ √T 1
b η ǫ u k = 1
4T2 0
w 3(k) = 0 2 k T
η
n φ(V ,j )
k≤
=
0,≤
n i=1 i i
where u U n V .  P
0 ∈ \ i=1 i
Proof. ByLemmSa18,w (1),...w (T) = 0,thus,byLemma5,weknowthatforeveryi, ℓ (w ,V )=
2 2 1 1 i
∇
0. Moreover, by the fact that δ > 0, we get that ℓ (w ) = 0. For ℓ (w ), by Lemma 6, using the
2 4 2 3 2
∇
fact that w (1) = 0 and w (0) = η n φ(V ,j ), we get that
2 2 n i=1 i i
P
1 n φ(V ,j ) k = 0
n i=1 i i
∇ℓ 3(w 2)(k) = 
−
0
P1 4Tǫ 2u
0
k ot= her1
wise.

33For ℓ (w ), for every i, the gradient is
2 2
φ(V ,j ) k = 0
ℓ (w ,(V ,j ))(k) = − i i
2 2 i i
∇ (0 otherwise.
Combining all together, we conclude that, for u U n V , it holds that,
0 ∈ \ i=1 i
1 ǫ u kS = 1
(k)
−4T2 0
F(w 2) = 0 2 k T
∇ 0 k≤
=
0,≤
b
and

η ǫ u k = 1
4T2 0
w 3(k) = 0 2 k T
η
n φ(V ,j )
k≤
=
0.≤
n i=1 i i
 P (cid:3)
Lemma 20. Under the conditions of Theorem 3, if occurs and w is the iterate Unprojected GD
t
E
on F, with step size η 1 and w = 0, then, for t = 4 it holds that,
≤ √T 1
b 3ηu + η ǫ u k = 1
− 8 0 2T2 0
ηu k = 2
w 4(k) =02 0
3
≤
k
≤
T
η n φ(V ,j ) k = 0,
n i=1 i i
where u U n V .

P
0 ∈ \ i=1 i
Proof. We startSwith ℓ ,ℓ ,ℓ . For ℓ , by Lemma 19, for every 2 k T, w (k) = 0, thus, by
1 2 3 1 3
≤ ≤
Lemma 5, we know that for every i, ℓ (w ,V ) = 0. For ℓ , we know that, for every i,
1 1 i 2
∇
φ(V ,j ) k = 0
ℓ (w ,(V ,j ))(k) = − i i
2 3 i i
∇ (0 otherwise.
For ℓ , by Lemma 6, using the fact that w (1) = cηu for c 1 and w (0) = η n φ(V ,j ), we
3 3 0 | | ≤ 3 n i=1 i i
get that,
P
1 n φ(V ,j ) k = 0
n i=1 i i
∇ℓ 3(w 3)(k) = 
−
0
P1 4Tǫ 2u
0
k ot= her1
wise.
Now, for ℓ , we show that the
maximum
is attained uniquely in k = 1 and u = u : For k = 1,
4 0
6
for every u U
∈ 3 1
u,w (k) u,w (k+1) =0.
3 3
8h i− 2h i
For k = 1 and u= u ,
0
6
3 1 3 1
u,w (k) u,w (k+1) = u,w (1) u,w (2)
3 3 3 3
8h i− 2h i 8h i− 2h i
343 η ǫ
= u, u
8h 4T2 0 i
3η ǫ
≤ 256T2
For k = 1 and u= u ,
0
3 1 3 1
u,w (k) u,w (k+1) = u ,w (1) u ,w (2)
3 3 0 3 0 3
8h i− 2h i 8h i− 2h i
3 η ǫ
= u , u
8h 0 4T2 0 i
3η ǫ
=
32T2
>δ
2
We derive that,
3u k = 1
8 0
 1u k = 2
∇ℓ 4(w 3)(k) = −
0
2 0
3
≤
k
≤
T
0 k = 0.
Combining all together, we get that,

3u 1 ǫ u k = 1
8 0 − 4T2 0
∇F(w
3)(k)
=

−
0
1 2u 0 k
3
≤= k2
≤
T
b 0 k = 0,
and

3ηu + η ǫ u k = 1
− 8 0 2T2 0
ηu k = 2
w 4(k) = 02 0
3 ≤s
≤
T
η n φ(V ,j ) k = 0,
n i=1 i i
where u U n V .

P (cid:3)
0 ∈ \ i=1 i
Lemma 21. UnSder the conditions of Theorem 3, if occurs and w is the iterate Unprojected GD
t
E
on F, with step size η 1 and w = 0, then, for t = 5 it holds that,
≤ √T 1
b 3ηu + 3η ǫ u k = 1
−8 0 4 T2 0
 81ηu 0 k = 2
w 5(k) = 01 2ηu
0
k
4
= s3
T
≤ ≤
where u U n V .
n1 Pn i=1φ(V i,j i) k = 0,
0 ∈ \ i=1 i
S
35Proof. We begin with ℓ ,ℓ ,ℓ . Note that, by Lemma 20, for every 2 k T, w (k) = cηu for
1 2 3 4 0
≤ ≤
c 1, thus, by Lemma 5, for every i, ℓ (w ,V ) = 0. For ℓ , we know that, for every i,
≤ 2 ∇ 1 4 i 2
φ(V ,j ) k = 0
ℓ (w ,(V ,j ))(k) = − i i
2 4 i i
∇ (0 otherwise.
For ℓ , by Lemma 6, using Lemma 20, where we showed that w (1) = cηu for c 1 and
3 4 0
| | ≤
w (0) = η n φ(V ,j ), we get that,
4 n i=1 i i
P
1 n φ(V ,j ) k = 0
n i=1 i i
∇ℓ 3(w 4)(k) = 
−
0
P1 4Tǫ 2u
0
k ot= her1
wise.
It is left to calculate ℓ (w ). We
show
that the maximum is attained uniquely at k = 2 and
4 4
∇
u= u . First,
0
3 η ǫ 3η ǫ 3η
u, u = u,u ,
8h 2T2 0 i 16T2h 0 i ≤ 16T2
thus, since T 4,
≥
3 1 3 3η η ǫ 1 η 9η η 9η 43η 3η
u,w (1) u,w (2) = u, u + u u, u + + = < .
8h 4 i− 2h 4 i 8h − 8 0 2T2 0 i− 2h 2 0 i ≤ 512 32 256 512 16
For k = 2 and u= u ,
0
3 1 3 η 1 3η
u,w (2) u,w (3) = u , u u ,0 = (> δ ).
4 4 0 0 0 2
8h i− 2h i 8h 2 i− 2h i 16
For k = 2 and u= u ,
t 2
6 −
3 1 3 η 1 3η
u,w (2) u,w (3) = u, u u,0 .
4 ′ 3 0
8h i− 2h i 8h 2 i− 2h i ≤ 128
For every 3 k T 1,
≤ ≤ −
3 1
u,w (k) u,w (k+1) = 0.
4 ′ 4
8h i− 2h i
We derive that,
3u k = 2
8 0
 1u k = 3
∇ℓ 4(w 4)(k) = −
0
2 0
3
≤
k
≤
T
0 k = 0.
Combining all together, we get that,

1 ǫ u k = 1
−4T2 0
 83u 0 k = 2
∇F(w
4)(k)
=
−
0
1 2u
0
k
4
= k3
T
b ≤ ≤
0 k = 0
36and
3ηu + 3η ǫ u k = 1
−8 0 4 T2 0
1 8ηu
0
k = 2
w 5(k) = 021ηu
0
k
4
= s3
T
≤ ≤
where u U n V .
n1 Pn i=1φ(V i,j i) k = 0,
0 ∈ \ i=1 i
(cid:3)
S
Lemma 22. Assume the conditions of Theorem 3, and consider the iterates of unprojected GD on
F, with step size η 1/√T initialized at w = 0. Under the event , we have for all t [T] that
1
≤ E ∈
w 1.
b t
k k ≤
Proof. If holds,byLemmas 4and18to20, weknowthatforeveryt 2, w (1) η, w (t 1)
E ≥ k t k≤ 2 k t − k≤
η and for every k 2,...,t 2 , w (t 1) η. As a result,
2 ∈{ − } k t − k≤ 8
d
w 2 w [i]2
t t
k k ≤
i=1
X
T
w (k) 2
t
≤ k k
k=0
X
η 2 η 2 η n 2
< 2 +(T 3) + φ(V ,j )
i i
· 2 − 8 n
(cid:18) (cid:19) (cid:18) (cid:19) (cid:13) Xi=1 (cid:13)
η2 η2(T 3) (cid:13) (cid:13) (cid:13) (cid:13)
+ − +η2
≤ 2 64
1 3
+ (η 1 )
≤ 64 2T ≤ √T
1 (T 2)
≤ ≥
(cid:3)
B.3 Proof of Theorem 3
Proof of Theorem 3. By Lemma 3, with probability of at least 1, occurs and by Lemma 4, it
6 E
holds for every 2 k T 3 that,
≤ ≤ −
1 m ηu k T m 2
w (k) = w (k) = 8 0 ≤ − − (18)
T,m m Xi=1 T −i+1 ( m1 η 2 + η 8(T −k −2) u 0 k ≥ T −m −1
ηu(cid:0) k T (cid:1)m 2
= 8 0 ≤ − −
η(T k+2)
( 8− m u 0 k ≥ T −m −1
Then, we denote α RT 4 the vector which its kth entry is max 3η,max u,w (k+1) . By
V ∈ − 32 u ∈V h T,m i
the fact that every vector u U is in V with probability 1, the fo(cid:16)llowing holds, (cid:17)
∈ 2
E
T
max
3η
,max u,w (k)
2
E
T −3
max
3η
,max u,w (k)
2
Vv
u uk X=2 (cid:18)32 u ∈V h
T,m
i (cid:19) ≥
Vv
u uk X=2 (cid:18)32 u ∈V h
T,m
i (cid:19)
t t
37= E
T −4
max
3η
,max u,w (k+1)
2
Vv
u uk X=1 (cid:18)32 u ∈V h
T,m
i (cid:19)
= E t α
V V
k k
E α
V V
≥ k k
=
T −3
E max
3η
,max u,w (k)
2
v u uk X=2(cid:18) V (cid:18)32 u ∈V h T,m i (cid:19)(cid:19)
t
Then, by Eq. (18),
T 3η 2
E max ,max u,w (k)
Vv
u uk X=2 (cid:18)32 u ∈V h
T,m
i (cid:19)
t
T −m −2
E max
3η
,max u,w (k)
2
+
T −3
E max
3η
,max u,w (k)
2
≥ v V 32 u V h T,m i V 32 u V h T,m i
u k=2 (cid:18) (cid:18) ∈ (cid:19)(cid:19) k=T m 1(cid:18) (cid:18) ∈ (cid:19)(cid:19)
u X X− −
t
T −m −2
E max
3η
,max u,
η
u
2
+
T −3
E max
3η
,max u,
η(T −k+2)
u
2
≥ v u k=2 (cid:18) V (cid:18)32 u ∈V h 8 0 i (cid:19)(cid:19) k=T m 1(cid:18) V (cid:18)32 u ∈V h 8m 0 i (cid:19)(cid:19)
u X X− −
t
=
η T −m −2
E max
3
,max u,u
2
+
T −3
E max
3
,
T −k+2
max u,u
2
8v V 4 u V h 0 i V 4 m u V h 0 i
u k=2 (cid:18) (cid:18) ∈ (cid:19)(cid:19) k=T m 1(cid:18) (cid:18) ∈ (cid:19)(cid:19)
u X X− −
t
η T −m −2
E max
3
,max u,u
2
+
T −3
E max
3
,
T −k+2
max u,u
2
≥ 8v u
u
k X=2 (cid:18) V (cid:18)4 u ∈V h 0 i (cid:19)(cid:19) k=T X−m −1(cid:18) V (cid:18)4 T u ∈V h 0 i (cid:19)(cid:19)
t
=
η T −m −2
E max
3
,max u,u
2 +m −1
E max
3 ,k+4
max u,u
2
8v u
u
k X=2 (cid:18) V (cid:18)4 u ∈V h 0 i (cid:19)(cid:19) k X=1 (cid:18) V (cid:18)4 T u ∈V h 0 i (cid:19)(cid:19)
t
Now, treating each of the term separately, with probability 1 on V, max u,u 1 (otherwise
2 u ∈V h 0 i ≤ 8
it is 1), thus,
3 1 3 1 7
E max ,max u,u = + 1=
V 0
4 u V h i 2 · 4 2 · 8
(cid:18) ∈ (cid:19)
Moreover, if k 3T 4
≤ 4 −
3 k+4 3
E max , max u,u = ,
V 0
4 T u V h i 4
(cid:18) ∈ (cid:19)
otherwise,
3 k+4 1 3 k+4 1 3
E max , max u,u max , +
V 0
4 T u V h i ≥ 2 4 T 2 · 4
(cid:18) ∈ (cid:19) (cid:18) (cid:19)
3 k+4
+
≥ 8 2T
Then, we get, if m T 3, (note that it implies l 1 3T 4),
≥ − − ≥ 4 −
T 3η 2
E max ,max u,w (k)
Vv
u uk X=2 (cid:18)32 u ∈V h
T,m
i (cid:19)
t
38η m −1
E max
3 ,k+4
max u,u
2
≥ 8v uk=1 (cid:18) V (cid:18)4 T u ∈V h 0 i (cid:19)(cid:19)
uX
t
η 9 3 k+4 2
+ +
≥ 8v 16 8 2T
u u uk:1 ≤kX ≤3 4T −4 k:3 4T −4X<k ≤m −1(cid:18) (cid:19)
t
η 9 3 k 2
+ +
≥ 8v 16 8 2T
u u uk:1 ≤kX ≤3 4T −4 k:3 4T X<k ≤T(cid:18) (cid:19)
t
η 27T 144 9 3k
− + +
≥ 8 64 64 8T
v u
u
k:3 4T X<k ≤T(cid:18) (cid:19)
t
η 27T 144 9T 3
v − + + k
≥ 8u 64  256 8T 
u u
u 
k:3 4T X<k ≤T

t  
η 27T −144 + 9T + 3T2 3(3 4T +1)2 (i2 n i2 (i+1)2 )
≥ 8v u 64 256 16T − 16T ! 2 ≤ i=1 ≤ 2
u P
t
η 27T 144 9T 3T 27T 3 9
= − + +
8s 64 256 16 − 256 − 16T − 32
(cid:18) (cid:19)
η 148T 45 3
=
8s 256 − 32 − 16T
η 147T
(T 512 = 45 + 3 T )
≥ 8s 256 ≥ ⇒ 32 16T ≤ 256
3η 101√T
.
≥ 32 · 100
Otherwise, if m < T 4, by similar arguments,
−
T 3η 2
E max ,max u,w (k)
Vv
u uk X=2 (cid:18)32 u ∈V h
T,m
i (cid:19)
t
η T −m −2
E max
3
,max u,u
2
+
T −3
E max
3 ,T −k+2
max u,u
2
≥ 8v V 4 u V h 0 i V 4 T u V h 0 i
u k=2 (cid:18) (cid:18) ∈ (cid:19)(cid:19) k=T m 1(cid:18) (cid:18) ∈ (cid:19)(cid:19)
u X X− −
t
η T −m −2 7 2 9 3 k 2
+ + +
≥ 8v 8 16 8 2T
u u k X=2 (cid:18) (cid:19) k:1 kX3T 4 k:T<Xk m+3(cid:18) (cid:19)
u ≤ ≤ 4 − 2 ≤
t
η T 7 2 9 3 k 2
= + + +
8v 8 16 8 2T
u uk= Xm+4(cid:18) (cid:19) k:1 kX3T 4 k:T<Xk m+3(cid:18) (cid:19)
u ≤ ≤ 4 − 2 ≤
t
η 9 3 k 2
+ + (3 + k 7)
≥ 8v 16 8 2T 8 2T ≤ 8
u u uk:1 ≤kX ≤3 4T −4 k:3 4T X<k ≤T(cid:18) (cid:19)
t
393η 101√T
.
≥ 32 · 100
Moreover, we notice that for every t, ℓ (w ) w (0) η, ℓ (w ) δ and ℓ (w ) δ , thus,
2 t t 3 t 1 4 t 2
≥ −k k ≥ − ≥ ≥
it holds that,
303η 303
F(w ) √T +δ +δ η η √T 1
T,l 1 2
≥ 3200 − ≥ 3200 −
(cid:18) (cid:19)
and
3η
F(w ) √T +η
∗ ≤ 32
Then, with probability of at least 1,
6
303 3
F(w ) F(w ) η( √T 2 √T)
T,l
− ∗ ≥ 3200 − − 32
303 302
η( √T √T) (T 32002 = 2 2 √T)
≥ 3200 − 3200 ≥ ⇒ ≤ 3200
η
= √T.
3200
(cid:3)
C Proofs of Section 5
C.1 Proofs for the full construction
Lemma 23. Let n, a set U Rd. Let P(U) be the power set of U. Then, there exist sets
∈
Ψ ,...Ψ R2n, a number 0 < ǫ < 1 and two mappings φ : P(U) [n] R2n, α : R2n U
{ 1 n } ⊆ n × → →
such that,
1. For every j [n] and V U, φ(V,j) 1.
∈ ⊆ k k ≤
2. For every k, ψ Ψ , α(ψ) 1, ψ 1.
k
∈ k k ≤ k k ≤
3. Let V ,...,V U. Then, for every k, ψ = 1 k φ(V ,i) holds,
1 k ⊆ k∗ n i=1 i
• For every ψ Ψ , ψ =ψ : P
∈
k
6
k∗
k k
1 1
ψ , φ(V ,i) ψ, φ(V ,i) +ǫ;
h
k∗
n
i
i ≥ h n
i
i
i=1 i=1
X X
• If k V = and m = argmin i :v k V , then α(ψ ) = v k V .
i=1 i 6 ∅ i{ i ∈ i=1 i } ∗ m ∈ i=1 i
Proof of LemmTa 23. The construction is similar to LTemma 17. First, we considerTan arbitrary enu-
merationofP(U) = V1,...V P(U) anddefineg : P(U) R2,g(Vi)= sin 2πi ,cos 2πi .
{ | | } → P(U) P(U)
Here, we refer to a vector a R2n as a concatenation of n vectors in(cid:16)R2,(cid:16)a(| 1),...| ,(cid:17)a(n). (cid:16)T| hen,| (cid:17)w(cid:17)e
∈
define δ = 1 cos 2π , ǫ = δ and
− P(U) n2
| |
(cid:16) (cid:17)
g(V) i= j
φ(V,j)(i) =
0 otherwise
(
40As a result, for every V ,j it holds that
i
2πi 2 2πi 2
φ(Vi,j) = g(Vi) = sin +cos = 1
k k k k s P(U) P(U)
(cid:18)| |(cid:19) (cid:18)| |(cid:19)
Moreover, if j = j ,
1 2
6
φ(Vi,j ),φ(Vi,j ) = 0,
1 2
h i
and if i > k,
φ(Vi,j),φ(Vk,j) = g(Vi),g(Vk)
h i h i
2πi 2πk 2πi 2πk
= sin sin +cos cos
P(U) P(U) P(U) P(U)
(cid:18)| |(cid:19) (cid:18)| |(cid:19) (cid:18)| |(cid:19) (cid:18)| |(cid:19)
2π(i k)
= cos −
P(U)
(cid:18) | | (cid:19)
2π
cos (cos is monotonic decreasing in [0,π/2])
≤ P(U)
(cid:18)| |(cid:19)
= 1 δ
−
Wenoticethat0 < δ < 1. Now,weconsideranarbitraryenumerationofU = v ,...v ,anddefine
1 U
the following sets Ψ ,...Ψ R2n and the following two mappings σ : R2n { P(U)| ,α|} :R2n U,
1 n
⊆ → →
k
1
Ψ = φ(V ,i) : i V U
k i i
{n ∀ ⊆ }
i=1
X
Note that, for every ψ Ψ,
∈
k k
1 1
ψ = φ(V ,j ) φ(V ,j ) 1.
i i i i
k k kn k ≤ n k k ≤
i=1 i=1
X X
Then, for every a R2n and j [n], we denote the index q(a,j) [P(U)] as
∈ ∈ ∈ | |
q(a,j) = argmax g(V ),a(j) ,
r
r h i
and define the following mapping σ :R2n P(U),
→
n
σ(a) = V .
q(a,j)
j=1,\a(j)=0
6
Moreover, for every a R2n, we denote the index p(a) [U ] as
∈ ∈ | |
p(a) = argmin i : v σ(a) ,
i
{ ∈ }
i
and define the following mapping α:
R2n2
U,
→
v σ(a) =
α(a) = |U | ∅ .
v σ(a) =
( p(a)
6 ∅
41Note that for every a R2n, α(a) U, thus, α(a) 1.
∈ ∈ k k ≤
Now, Let V ,...,V U, k [n] and ψ = 1 k φ(V ,i). Then,
1 n ⊆ ∈ k∗ n i=1 i
k Pk k
1 1 1
ψ , φ(V ,i) = φ(V ,i), φ(V ,i)
∗ i i i
h n i hn n i
i=1 i=1 i=1
X X X
k
1
= φ(V ,i),φ(V ,i)
n2 h i i i
i=1
X
k
=
n2
For ψ = 1 k φ(V ,i) such that ψ = ψ , there exists a index r such that V = V ,thus,
n i=1 i′ 6 ∗ r′ 6 r
P k k k
1 1 1
ψ, φ(V ,i) = φ(V ,i), φ(V ,i)
h n
i
i hn
i′
n
i
i
l=1 i=1 i=1
X X X
k
1
= φ(V ,i),φ(V ,i)
n2 h i i′ i
i=1
X
k
1
1 δ+ 1
≤ n2  − 
i=1,i=r
X6
1  
(1 δ+k 1)
≤ n2 − −
k δ
=
n2 − n2
n
1
= ψ , φ(V ,j ) ǫ
h
k∗
n
i i
i−
i=1
X
Furthermore, it holds that, 1 n φ(V ,i)(i) = 1g(V ), thus,
n i=1 i n i
P (i)
k k
1 1
q φ(V ,i),i = argmax g(V ), φ(V ,i)
i r i
n ! r h n i
i=1 i=1
X X
1
= argmax g(V ), g(V )
r i
r h n i
= i,
thus, we get,
k
1
σ(ψ ) = σ φ(V ,i)
∗ i
n !
i=1
X
n
= V
j=1, n1 k i=\ 1φ(Vi,i)(j) 6=0
q( n1 Pk i=1φ(Vi,i)(j) ,j)
k
P
= V (The indices that are non-zero are j = 1,...,k)
j=1
q( n1 k i=1φ(Vi,i),j)
\
k P
= V
i
i=1
\
42Then, assuming that k V = , and let and m = argmin i :v k V , p(a) = m and,
i=1 i 6 ∅ i{ i ∈ i=1 i }
T k T
α(ψ )= v V .
∗ m i
∈
i=1
\
(cid:3)
Proof of Lemma 8. First, ℓSGD is convex and 1-Lipschitz by the fact that ℓSGD = ℓ and Lemma 2.
1 1 1
Moreover, by Lemma 23, ℓSGD is a maximum over 1-Lipschitz linear functions, thus, ℓSGD is convex
2 2
and 1-Lipschitz. Finally, ℓSGD is a summation of two 1-Lipschitz linear functions, thus, ℓSGD is
3 3
convex and 2-Lipschitz. Combining all together, we get the lemma. (cid:3)
C.2 Proof of algorithm’s dynamics
In this section we describe the dynamics of SGD. We begin with showing that the good event
′
E
(Eq. (15)) occurs with a constant probability.
Proof of Lemma 9. First, by union bound,
1
Pr( t [n] P = and J S ) = 1 Pr( t P = or J / S )
t t t t t t
∀ ∈ 6 ∅ ∈ ≥ 2 − ∃ ∅ ∈
n
1 Pr(P = or (P = and J / S ))
t t t t
≥ − ∅ 6 ∅ ∈
t=1
X
n n
1 Pr(P = ) Pr(P = and J / S )
t t t t
≥ − ∅ − 6 ∅ ∈
t=1 t=1
X X
n n
= 1 Pr(P = ) Pr(P = )Pr(J / S P = ).
t t t t t
− ∅ − 6 ∅ ∈ | 6 ∅
t=1 t=1
X X
Now, for every v U,
l
∈
t 1 t 1
Pr(v / − V ) = 1 Pr(v / − V )= 1 δt 1,
l i l i −
∈ − ∈ −
i=1 i=1
\ \
and,
Pr(v / S )= 1 (1 δ)n t+1 1 (1 δ)n.
l t −
∈ − − ≤ − −
Then,
t
Pr(P = ) = Pr V =
t i
∅ ∅!
i=1
\
t
= Pr( v U w / V )
l i
∀ ∈ ∈
i=1
\
= (1 δt 1)U
− | |
−
(1 δn)U .
| |
≤ −
Moreover, by the fact that for every t, P is independent of V ,...V ,
t t+1 n
Pr(P = )Pr(J / S P = ) = Pr(P = )Pr(v / S P = )Pr(J = v )
t t t t t l t t t l
6 ∅ ∈ | 6 ∅ 6 ∅ ∈ | 6 ∅
l: Xvl∈U
43= Pr(P = )Pr(v / S )Pr(J = v )
t l t t l
6 ∅ ∈
l: Xvl∈U
1 (1 δ)n
≤ − −
Combining all of the above, we get that,
Pr( t [n] P = and J S )
t t t
∀ ∈ 6 ∅ ∈
n n
= 1 Pr(P = ) Pr(P = )Pr(J / S P = )
t t t t t
− ∅ − 6 ∅ ∈ | 6 ∅
t=1 t=1
X X
1 n(1 δn)U n(1 (1 δ)n).
| |
≥ − − − − −
′
For δ = 4n1 2, by the fact that |U
| ≥
21d 78 = 24nlog(n) = n4n,
U δn n4nn 2n4 n n2n4 n log(4n)
− − −
| | ≥ ≥ ≥
1
Pr( t [n] P
t
= and J
t
S t) 1 n(1 δ5n 00) |U
|
n(1 (1 δ)n)
∀ ∈ 6 ∅ ∈ ≥ 2 ≥ − − − − −
n
1 ne U δ500 n(1 (1 nδ))
−| |
≥ − − − −
1 ne log(4n) n2δ
−
≥ − −
1 1
1
≥ − 4 − 4
1
= .
2
(cid:3)
Proof of Lemma 11. First, by the fact that for every t k T, w(k) = 0, for every such k,
≤ ≤
3η
max u,w(k) = 0 < ,
u Vth i 32
∈
For 2 k t 1, w(k) = cηu , where c 1 and every u T V V , thus,
≤ ≤ − k ≤ 2 k ∈ i=k i ⊆ t
η 1 3Tη
max u,w(k) < .
u Vth i≤ 2 · 8 32
∈
We derive that ℓSGD(w ,V )= 0. (cid:3)
∇ 1 t t
Proof of Lemma 12. First, we show that the maximum of ℓSGD(w,V) is attained with k = m and
2
u= u . For k m+1, for every u U and ψ Ψ ,
m k
≥ ∈ ∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1) = 0.
8h i− 2h i h 4n i−h 4n i h −4n2 i
For k = 1, for every u U and ψ Ψ , by Lemma 23, we know that for every ψ,V,j,
1
∈ ∈
ψ , φ(V,j) 1, and α(ψ) U, thus,
k k k k ≤ ∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
8h i− 2h i h 4n i−h 4n i h −4n2 i
3c η 1
= u ,u u ,α(ψ) + w(0,k), ψ 0+0
1 2
8 h i− 16h i h 4n i−
449η η η
+ +
≤ 512 128 4n
η
< . (n 4)
8 ≥
For 2 k m 2, for every u U and ψ Ψ , by Lemma 23, we know that for every ψ,V,j,
k
≤ ≤ − ∈ ∈
ψ , φ(V,j) 1, and α(ψ) U, thus,
k k k k ≤ ∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
8h i− 2h i h 4n i−h 4n i h −4n2 i
3 η
= u ,u u ,α(ψ) +0 0+0
k k+1
64h i− 16h i −
3η η
+
≤ 64 16
η
< .
8
For k = m 1, for every u U and ψ Ψ , by Lemma 23, we know that for every ψ,V,j,
k
− ∈ ∈
ψ , φ(V,j) 1, and α(ψ) U, thus,
k k k k ≤ ∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
8h i− 2h i h 4n i−h 4n i h −4n2 i
3 η 1 1
= u ,u u ,α(ψ) +0 w(0,k+1), ψ + w(0,k+1), φ(V,m)
64h k i− 4h k+1 i −h 4n i h 4n2 i
3η η 1 1
+ + +
≤ 64 32 16n2 16n3
η
< . (n 4)
8 ≥
For k = m, u = u and every ψ Ψ , by Lemma 23, we know that for every ψ,V,j,
m m
6 ∈
ψ , φ(V,j) 1, and α(ψ) U, thus,
k k k k ≤ ∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
8h i− 2h i h 4n i−h 4n i h −4n2 i
3 1
= u,w(k) + ψ,w(0,k)
8h i h4n i
3 η 1
= u, u + ψ,w(0,k)
m
8h 2 i h4n i
3η η
+
≤ 128 16n2
η
< . (n 4)
32 ≥
Fork = m,u= u andeveryψ Ψ ,byLemma23,weknowthatforeveryψ,V,j, ψ , φ(V,j)
m m
∈ k k k k ≤
1, and α(ψ) U, thus,
∈
3 1 1 1 1
u,w(k) α(ψ),w(k+1) + w(0,k), ψ w(0,k+1), ψ + w(0,k+1), φ(V,k+1)
8h i− 2h i h 4n i−h 4n i h −4n2 i
3 1
= u,w (k) + ψ,w (0,k)
t t
8h i h4n i
3 η 1
= u, u + ψ,w (0,k)
m t
8h 2 i h4n i
3η η
≥ 16 − 16n2
455η
> (n 4)
32 ≥
> δ .
1
Second, we show that when k = m and u = u , the maximum among ψ Ψ is attained
m m
∈
uniquely in ψ = 1 m φ(V ,t). For any ψ Ψ , with ψ = ψ , by Lemma 23, for k = m,
m∗ n t=1 t ∈ m 6 m∗
u= u ,
m P
3 1 1 1 1
u,w(m) α(ψ ),w(m+1) + w(0,m), ψ w(0,m+1), ψ + w(0,m+1), φ(V,m+1)
8h i− 2h
m∗
i h 4n
m∗
i−h 4n
m∗
i h −4n2 i
3 1
= u,w(m) + ψ ,w(0,m)
8h i h4n
m∗
i
m
3η η 1
= + ψ , φ(V ,t)
16 16n2h m∗ n t i
t=1
X
m
3η η 1 ηǫ
+ ψ, φ(V ,t) +
≥ 16 16n2h n t i 16n2
t=1
X
3 1 ηǫ
= u,w(k) + ψ,w(0,m) +
8h i h4n i 16n2
3 1 1 1 1 ηǫ
= u,w(m) α(ψ),w(m+1) + w(0,m), ψ w(0,m+1), ψ + w(0,m+1), φ(V,m+1) +
8h i− 2h i h 4n i−h 4n i h −4n2 i 16n2
We derive that,
3u k = m
8 m
ℓSGD(w,V)(k)
=  1α(ψ ) k = m+1
∇ 2 0−2 m∗
k / m,m+1
∈ { }

1 m φ(V ,t) k = m
4n2 t=1 t
ℓSGD(w,V)(0,k) =  1 m φ(V ,t) 1 φ(V,m+1) k = m+1
∇ 2 0−4nP2 t=1 t − 4n2
k / m,m+1 .
P
∈ { }

(cid:3)
Lemma 24. Under the conditions of Theorem 4, if occurs and w is the iterate of Unprojected
′ t
E
SGD with step size η 1 and w = 0,
≤ √n 1
η u k = 1
w (k) = n3 1 ,
2
(0 k 2
≥
and,
η φ(V ,1) k = 1
w (0,k) = 4n2 1
2
(0 k = 1.
6
Proof. w = 0, thus, for every k,
1
3η
max u,w (k) = 0< ,
1
u V1h i 32
∈
46and we derive that ℓSGD(w ,V ) = 0. By the same argument, ℓSGD(w ,V ) = 0 (where the
∇ 1 1 1 ∇ 2 1 1
maximum is attained uniquely in δ ). Moreover, ℓSGD is a linear function, then, we get that,
2 3
1 u k = 1
ℓSGD(w ,V )(k) = −n3 1 ,
∇ 3 1 1 (0 k 2
≥
and,
ℓSGD(w ,V )(0,k) = −4n1 2φ(V 1,1) k = 1
∇ 3 1 1 (0 k = 1,
6
and the lemma follows. (cid:3)
Lemma 25. Under the conditions of Theorem 4, if occurs and w is the iterate of Unprojected
′ t
E
SGD with step size η 1 and w = 0,
≤ √n 1
2ηu 3ηu k = 1
n3 1 − 8 1
w 3(k) = η 2u
2
k = 2
0
3 k n
≤ ≤

η φ(V ,1) k = 1
4n2 2
w 3(0,k) =  4nη 2φ(V 1,1)+ 4nη 2φ(V 2,2) k = 2
0
k 3.
≥
where u U, and u holds u
P
S .
1 2 2 2 2
∈ ∈ ∩
Proof. First, by the fact that for every 2 k T, w (k) = 0, for every such k,
2
≤ ≤
3η
max u,w (k) = 0< ,
2
u V2h i 32
∈
and we derive that ℓSGD(w ,V ) = 0.
∇ 1 2 2
Moreover, ℓSGD is a linear function, thus,
3
η u k = 1
ℓSGD(w ,V )(k) = n3 1 ,
3 2 2
(0 k 2
≥
and,
ℓSGD(w ,V )(k) = 4nη 2φ(V 2,1) k = 1
3 2 2
(0 k = 1.
6
For ℓSGD(w ,V ), we get by the fact that for every k 1, w (k+1) = w (0,k+1) = 0,
2 2 2 ≥ 2 2
3 1
ℓSGD(w ,V ) = max δ , max u,w (k) + ψ,w (0,k)
2 2 2 2 k ∈[n −1],u ∈U,ψ ∈Ψk(cid:18)8h 2 i h4n 2 i (cid:19)!
As a first step, we show that the the maximum is attained with k = 1 and u = u , For k = 1, for
1
6
every u U and ψ Ψ ,
k
∈ ∈ 3 1
u,w (k) + ψ,w (0,k) = 0.
2 2
8h i h4n i
47For k = 1, u= u and every ψ Ψ , by the fact that ψ , φ(V ,1) 1,
1 1 1
6 ∈ k k k k ≤
3 1 3η η 7η 3η
u,w (k) + ψ,w (0,k) + = < .
8h 2 i h4n 2 i ≤ 64n3 16n3 64n3 16n3
For k = 1, u= u and every ψ Ψ , by the fact that ψ , φ(V ,1) 1,
1 1 1
∈ k k k k ≤
3 1 3η η 3η
u,w (k) + ψ,w (0,k) > > δ .
8h 2 i h4n2 2 i ≥ 8n3 − 16n3 16n3 1
As a second step we show that the maximum among ψ Ψ is attained uniquely in ψ =
∈
1 1∗
1φ(V ,1). For any ψ Ψ , with ψ = ψ . By Lemma 23, for k = 1, u = u ,
n 1 ∈ 1 6 1∗ 1
3 1 3η 1 η
u,w (k) + ψ ,w (0,k) = + ψ , φ(V ,1)
8h 2 i h4n 1∗ 2 i 8n3 h4n 1∗ 4n2 1 i
3η η 1
= + ψ , φ(V ,1)
8n3 16n2h 1∗ n 1 i
3η η 1 ηǫ
+ ψ, φ(V ,1) +
≥ 8n3 16n2h n 1 i 16n2
3 1 ηǫ
= u,w (k) + ψ,w (0,k) +
8h 2 i h4n 2 i 16n2
Wegotthatthemaximumisuniquelyattainedatk = 1,u = u ,ψ = 1φ(V ,1). Now,byLemma23,
1 n 1
for j = argmin i : v V , we get that
i{ i ∈ 1 }
α(ψ) = v V .
j 1
∈
We notice that V = P and thus α(ψ) = J . Then, by , α(ψ) also holds α(ψ) S . Combining
1 2 2 ′ 2
E ∈
the above together, we get, for u = α(ψ) P S ,
2 2 2
∈ ∩
3u 1 u k = 1
8 1 − n3 1
∇f(w 2,V 2)(k) =  0−21u
2
k
k
= 32
≥
and,

1 φ(V ,1) 1 φ(V ,1) k = 1
4n2 1 − 4n2 2
∇f(w 2,V 2)(0,k) = 
−
0
4n1 2φ(V 1,1)
−
4n1 2φ(V 2,2) kk = 32
,
≥
and the lemma follows.  (cid:3)
Lemma 26. Under the conditions of Theorem 4, if occurs and w is the iterate of Unprojected
′ t
E
SGD with step size η 1 and w = 0,
≤ √n 1
3ηu 3ηu k =1
n3 1 − 8 1
ηu k =2
w 4(k) = η8 2u2
3
k =3
,
0 k 4
and,
 ≥
η φ(V ,1)+ η φ(V ,1) k = 1
4n2 2 4n2 3
w 4(0,k) = 4nη 2φ(V 1,1)+ 4nη 2φ(V 2,2)+ 4nη 2φ(V 3,3) k = 3 .
0
k / 1,3
∈ { }

48Proof. First, we notice that by Lemma 25, it holds that w (2) = cηu for c 1 and u holds
3 2 ≤ 2 2
u V n V , and for every 3 k T, w (k) = 0. Then, by Lemma 11, we have that
2 ∈ 1 ∩ i=2 i ≤ ≤ t
ℓSGD(w ,V ) = 0. Moreover, ℓSGD is a linear function, thus,
∇ 1 3 T3 3
η u k = 1
ℓSGD(w ,V )(k) = n3 1 ,
3 3 3
(0 k 2
≥
and,
ℓSGD(w ,V )(k) = 4nη 2φ(V 3,1) k = 1
3 3 3
(0 k = 1.
6
For ℓSGD(w ,V ), we first show that the the maximum is attained with k = 2 and u = u . For
2 3 3 2
k 3, for every u U and ψ Ψ ,
k
≥ ∈ ∈
3 1 1 1 1
u,w (k) α(ψ),w (k+1) + w (0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1) = 0.
8h 3 i− 2h 3 i h 3 4n i−h 3 4n i h 3 −4n2 i
For k = 1, for every u U and ψ Ψ , by the fact that for every ψ,V,j, ψ , φ(V,j) 1,
1
∈ ∈ k k k k ≤
3 1 1 1 1
u,w (k) α(ψ),w (k+1) + w(0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1)
8h 3 i− 2h 3 i h 4n i−h 3 4n i h 3 −4n2 i
3 2η 3η η 1 η η
= ( ) u ,u u ,α(ψ) + φ(V ,1),ψ φ(V ,1)+ φ(V ,2),ψ
8 n3 − 8 h 1 i− 4h 2 i h4n2 2 i−h4n2 1 4n2 2 i
η η 1
+ φ(V ,1)+ φ(V ,2), φ(V ,2)
h4n2 1 4n2 2 4n2 3 i
9η η η η η
+ + + +
≤ 512 32 4n2 2n2 8n4
29η
< (n 4)
256 ≥
η
< .
8
For k = 2, u= u and every ψ Ψ , , by the fact that for every ψ,V,j, ψ , φ(V,j) 1,
2 2
6 ∈ k k k k ≤
3 1 1 1 1
u,w (k) α(ψ),w (k+1) + w (0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1)
8h 3 i− 2h 3 i h 3 4n i−h 3 4n i h 3 −4n2 i
3 1
= u,w (k) + ψ,w (0,k)
3 3
8h i h4n i
3 η 1 η η
= u, u + ψ, φ(V ,1)+ φ(V ,2)
8h 2 2 i h4n 4n2 1 4n2 2 i
3η η
+
≤ 128 8n3
η
< . (n 4)
32 ≥
For k = 2, u= u and every ψ Ψ , by the fact that ψ , φ(V ,1) 1,
2 2 1
∈ k k k k ≤
3 1 1 1 1
u,w (k) α(ψ),w (k+1) + w (0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1)
8h 3 i− 2h 3 i h 3 4n i−h 3 4n i h 3 −4n2 i
3 1
= u,w (k) + ψ,w (0,k)
3 3
8h i h4n i
493 η 1 η η
= u, u + ψ, φ(V ,1)+ φ(V ,2)
8h 2 2 i h4n 4n2 1 4n2 2 i
3η η
≥ 16 − 8n3
5η
> (n 4)
32 ≥
> δ .
1
Second, we show that the maximum among ψ Ψ is attained uniquely in ψ = 1φ(V ,1) +
∈ 2 2∗ n 1
1φ(V ,2). For any ψ Ψ , with ψ = ψ , by Lemma 23, for k = 2, u= u ,
n 2 ∈ 2 6 2∗ 2
3 1 1 1 1
u,w (k) α(ψ ),w (k+1) + w (0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1)
8h 3 i− 2h 2∗ 3 i h 3 4n 2∗ i−h 3 4n 2∗ i h 3 −4n2 i
3 1
= u,w (k) + ψ ,w (0,k)
8h
3
i h4n
2∗ 3
i
3η 1 η η
= + ψ , φ(V ,1)+ φ(V ,2)
16 h4n 2∗ 4n2 1 4n2 2 i
3η η 1 1
= + ψ , φ(V ,1)+ φ(V ,2)
16 16n2h 2∗ n 1 n 2 i
3η η 1 1 ηǫ
+ ψ, φ(V ,1)+ φ(V ,2) +
≥ 16 16n2h n 1 n 2 i 16n2
3 1 ηǫ
= u,w (k) + ψ,w (0,k) +
8h 3 i h4n 3 i 16n2
3 1 1 1 1 ηǫ
= u,w (k) α(ψ),w (k+1) + w (0,k), ψ w (0,k+1), ψ + w (0,k+1), φ(V,k+1) +
8h 3 i− 2h 3 i h 3 4n i−h 3 4n i h 3 −4n2 i 16n2
We got that the maximum is uniquely attained at k = 2,u = u ,ψ = ψ . Now, by Lemma 23, for
2 2∗
j = argmin i : v V V , we get that
i{ i ∈ 1 ∩ 2 }
α(ψ) = v V V .
j 1 2
∈ ∩
We notice that V V = P and thus α(ψ) = J . Then, by , α(ψ) also holds α(ψ) S .
1 2 3 3 ′ 3
∩ E ∈
Combining the above together, we get, for u U, u P S and u = α(ψ ) P S ,
1
∈
2
∈
2
∩
2 3 2∗
∈
3
∩
3
1 u s = 1
−n3 1
 83u 2 s = 2
∇f(w 3,V 3) =
−
0
−1
2
4n1u
23
φ(V 3,1)
ss
4
==
≤
03
s
,≤
1
n
1 φ(V ,1)+ 1 φ(V ,2) s = 0,2
and the lemma
follows.− 04n 42
n1
2φ(1
V 1,1)
−4n 42
n1
2φ(2
V 2,2)
−
4n1 2φ(V 3,3) s
s
=
=
0 0, ,3
k for k
≥
3,
(cid:3)
C.3 Proof of Theorem 4
Proof of Theorem 4. We show that the theorem holds if the event occurs. First, we prove that
′
E
for every t, w 1. By Lemma 10,
t
k k ≤
d
w w [i]2
k t k≤ v t
ui=1
uX
t
50n n
w (k) 2+ w (0,l) 2
t t
≤ v k k k k
uk=1 l=1
uX X
t
η 2 η 2 η 2
< 2 +(n 2) +2
s · 2 − 8 · 4n
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
η2 η2(n 2)
+ − +2η2
≤ s 2 64
(cid:18) (cid:19)
1 5
+ (η 1 )
≤ 64 2n ≤ √n
r
1 (n 4)
≤ ≥
Now, denote α Rn 3 the vector which its kth entry is max η ,max u,(n k+2)ηu .
V ∈ − 16 u ∈Vih − 8 k+1 i
For w = w , and any 2 s n 2,
n n,n ≤ ≤ − (cid:0) (cid:1)
η η η
w (s) = u +(n s 1) u = (n s+3) u .
n s s s
2n − − 8n − 8n
Then,
1 n n 3η 2 1 n n −2 3η 2
max ,max u,w (k) max ,max u,w (k)
n i=1v uk=2 (cid:18)32 u ∈Vih n i (cid:19) ≥ n i=1v uk=2 (cid:18)32 u ∈Vih n i (cid:19)
XuX XuX
t t
1 n n −2 3η η 2
= max ,max u,(n k+3) u
n i=1v uk=2 (cid:18)32 u ∈Vih − 8n k i (cid:19)
XuX
t
1 n n −3 3η η 2
= max ,max u,(n k+2) u
n i=1v uk=1 (cid:18)32 u ∈Vih − 8n k+1 i (cid:19)
XuX
t
1 n n −3 3η η 2
= max ,max u,(n k+2) u
n i=1v uk=1 (cid:18)32 u ∈Vih − 8n k+1 i (cid:19)
XuX
n t
1
= α
n k
Vik
i=1
X
n
1
α
≥ kn
Vik
i=1
X
n 2 n 2
− 1 3η η
= max ,max u,(n k+3) u
v u uk X=2 n Xi=1 (cid:18)32 u ∈Vih − 8n k i (cid:19)!
t
n 2 n 2
η − 1 3 n k+3
= max ,max u, − u
8v u uk X=2 n Xi=1 (cid:18)4 u ∈Vih n k i (cid:19)!
t
n 2 n 2
η − 1 3 n k+2
= max ,max u, − u
8v u uk X=2 n Xi=1 (cid:18)4 u ∈Vih n k i (cid:19)!
t
Now, by the fact that if holds, by Lemma 10, for 2 k n 2, u P = k 1V ,
E′
≤ ≤ −
k
∈
k i=−1 k
1 n n 3η 2 T
max ,max u,w (k)
n
n i=1v
uk=2
(cid:18)32 u ∈Vih i
(cid:19)
XuX
t
512
n 2 k 1 n
η − 1 − 3 n k+2 1 3 n k+2
v max ,max u, − u k + max ,max u, − u k
≥ 8u uk=2 n i=1 (cid:18)4 u ∈Vih n i (cid:19) n i=k (cid:18)4 u ∈Vih n i (cid:19)!
uX X X
t
η n −2 3(n k+1) k 1 3 n k+2 2
− + − max , −
≥ 8v 4n n 4 n
uk=2(cid:18) (cid:18) (cid:19)(cid:19)
uX
t
η 3(n k+1) (k 1)(n k+1) 2 3(n k+1) 3(k 1) 2
− + − − + − + −
≥ 8v 4n n2 4n 4n
u u u2 ≤k X≤n 4−2(cid:18) (cid:19) n 4−3< Xk ≤n −2(cid:18) (cid:19)
t
η (n k+1)(3n+4(k 1)) 2 27n
= − − +
8v 4n2 64
u u u2 ≤k X≤n 4−2(cid:18) (cid:19)
t
η (n k)(3n+4k) 2 27n
= − +
8v 4n2 64
u u u1 ≤k X≤n 4−3(cid:18) (cid:19)
t
η 3 k k2 2 27n
+ +
≥ 8v 4 4n − n2 64
u u u1 ≤k X≤n 4−3(cid:18) (cid:19)
t
Now, the fact that for n k n, k k2 and for k n, k k2 ,
8 ≤ ≤ 4 4n ≤ n2 ≤ 8 8n ≤ n2
1 n n 3η 2
max ,max u,w (k)
n
n i=1v
uk=2
(cid:18)32 u ∈Vih i
(cid:19)
XuX
t
η 3 k 2 9n 27 27n
+ + +
≥ 8v 4 8n 128 − 16 64
u1 k n(cid:18) (cid:19)
u ≤X≤8
t
n
η 9n 3 ⌊8⌋ 9n 27 27n
v + k+ +
≥ 8u128 64n 128 − 16 64
u k=1
u X
t
η 1 n 2 27 36n
1 +
≥ 8s2 8 − − 16 64
(cid:18) (cid:19)
η n 27 36n
+ (n 16)
≥ 8 512 − 16 64 ≥
r
η 577n
(n 2048)
≥ 8 1024 ≥
r
3η 2001
≥ 32 · 2000
Now, for m < n and 2 k n 2,
≤ ≤ −
ηu k n m 1
w (k) = 8 k ≤ − −
n,m ( m1 η 2u k +(n −k −1)η 8u s k
≥
n −m
ηu(cid:0) k n m(cid:1) 1
= 8 k ≤ − −
η(n k+3)
( − 8m u s k ≥ n −m.
52Then, by similar arguments, it holds that,
1 n n 3η 2 1 n n −2 3η 2
max ,max u,w (k) max ,max u,w (k)
n Xi=1v u uk X=2 (cid:18)32 u ∈Vih n,m i (cid:19) ≥ n Xi=1v u uk X=2 (cid:18)32 u ∈Vih n,m i (cid:19)
t t
n 2 n 2
− 1 3η
max ,max u,w (k)
≥ v u uk X=2 n Xi=1 (cid:18)32 u ∈Vih n,m i (cid:19)!
t
n m 1 n 2 n 2 n 2
η − − 1 3 − 1 3 n k+3
= max ,max u,u + max ,max u, − u
v k k
8u
u
u
k X=2
n
Xi=1
(cid:18)4 u ∈Vih i (cid:19)!
k= Xn −m
n
Xi=1
(cid:18)4 u ∈Vih m i (cid:19)!
t
n m 1 n 2 n 2 n 2
η − − 1 3 − 1 3 n k+2
max ,max u,u + max ,max u, − u
v k k
≥ 8u
u
u
k X=2
n
Xi=1
(cid:18)4 u ∈Vih i (cid:19)!
k= Xn −m
n
Xi=1
(cid:18)4 u ∈Vih n i (cid:19)!
t
n 2 n 2
η − 1 max 3 ,max u, n −k+2 u (k 2 = n k+2 1)
≥ 8v u uk X=2 n Xi=1 (cid:18)4 u ∈Vih n k i (cid:19)! ≥ ⇒ −n ≤
3ηt 2001
(calculation for w )
n,n
≥ 32 · 2000
As a result, we notice that for every t, ℓSGD(w ) 1 1 and ℓ (w ) δ thus, it holds
2 t ≥ −4n2 − n3 2 t ≥ 1
that,
3η√n 2001 1 1
F(w ) +δ
n,m ≥ 32 · 2000 − 4n2 − n3 1
3η√n 2001 η
b
≥ 32 · 2000 − 2n2
3η√n 2001 η√n
(n 256)
≥ 32 · 2000 − 80000 ≥
3η√n 2001 1
≥ 32 · 2000 − 4000
(cid:18) (cid:19)
3η√n 4001
≥ 32 · 4000
and
3η
F(w ) F(0) √n
∗ ≤ ≤ 32
Then, if E′ holds b b b
3η√n 2001 3η
F(w ) F(w ) √n
n,m
− ∗ ≥ 32 · 2000 − 32
η√n
b b b =
64000
(cid:3)
D Proofs of Appendix A
D.1 Proofs of Appendix A.1
The proof of Theorem 5 appears in Appendix A.1. Here we prove some auxiliary lemmas that are
used for the proof.
53Proof of Lemma 13. First, differentiability can be derived immediately from Lemma 27. Second,
for 5-Lipschitzness, for every (V,j) Z, we define f˜ : Rd R as f˜ (w) := f˜(w,(V,j)). By the
V,j V,j
∈ →
5-Lipschitzness of f with respect to its first argument and Jensen Inequality, for every x,y Rd, it
∈
holds that
f˜ (x) f˜ (y) = E (f (y+v)) E (f (w+v))
V,j V,j v δB V,j v δB V,j
| − | | ∈ − ∈ |
= E (f (x+v) f (y+v))
v δB V,j V,j
| ∈ − |
E (f (x+v) f (y+v))
v δB V,j V,j
≤ ∈ | − |
5x y .
≤ | − |
Third, for convexity, by the convexity of f for every x,y Rd and α [0,1],
∈ ∈
f˜ (αx+(1 α)y) = E (f (αx+(1 α)y+v))
V,j v δB V,j
− ∈ −
= E (f (α(x+v)+(1 α)(y+v)))
v δB V,j
∈ −
E (αf (x+v)+(1 α)f (y+v)))
v δB V,j V,j
≤ ∈ −
= αE (f (x+v))+(1 α)(E f (y+v))
v δB V,j v δB V,j
∈ − ∈
= αf˜ (x)+(1 α)f˜ (y).
V,j V,j
−
(cid:3)
Lemma 27. (Lemma 1 in Flaxman et al. (2005)) Let d and δ > 0, B be the d-dimensional unit
ball and S be the d-dimensional unit sphere. Moreover, let B and S be the uniform distributions
on B,S respectively. If f˜(x) = E [f(x+δv)], then, D D
v B
∼D
d
f˜(x) = E [f(x+δa)a]
∇ δ a ∼DS
Lemma 28. (e.g., Muller (1959)) Let d. Let S be the d-dimensional unit sphere and S the
D
uniform distributions on S. Moreover, we define random variables Y ,...,Y R,X ,...,X R
1 d 1 d
∈ ∈
and Y Rd such that X N(0,1) (where N(0,1) is the normal univariate distribution with
i
∈ ∼
expectation 0 and variance 1), Y
i
= xi and Y = (Y 1,...,Y d). Then, Y S.
d X2 ∼ D
i=1 i
q
Lemma 29. Let d. Let B be the d-dPimensional unit ball and B the uniform distributions on
D
B. Let ζ > ζ > 0, a function g : R R and a ,...a B. Moreover, let h : B R,
1 2 1 l
→ ∈ →
h(x) = g(max(ζ ,max a ,x ) and x B such that max a ,x ζ . We define
1 1 r l r 0 1 r l r 0 2
h˜(x) := E [h(x+δv)≤ ]. ≤ Thh en, fi or any 0 <∈ δ < ζ ζ , ≤ ≤ h i ≤
v ∼DB 1 − 2
h˜(x ) = 0,
0
∇
h˜(x ) = g(ζ ).
0 1
Proof. First, for every r and v B, by Cauchy-Schwartz Inequality,
∈
a ,x +δv = a ,x + a ,δv ζ +δ < ζ
r 0 r 0 r 2 1
h i h i h i ≤
Then,
max(ζ , max a ,x +δv ) = ζ ,
1 r 0 1
1 r lh i
≤ ≤
and
h(x +δv) = g(max(ζ , max a ,x +δv ) = g(ζ ).
0 1 r 0 1
1 r lh i
≤ ≤
54As a result,
h˜(x )= E [h(x +δv)] = g(ζ )
0 v B 0 1
∼D
and by Lemma 27,
d
h˜(x ) = E [h(x +δv)v]
∇ 0 δ v ∼DS 0
d
= E g max(ζ , max a ,x +δv v
δ v ∼DS 1 1 r lh r 0 i
(cid:20) (cid:18) ≤ ≤ (cid:19) (cid:21)
d
= E [g(ζ )v]
δ v ∼DS 1
d
= g(ζ )E [v]
δ 1 v ∼DS
= 0
(cid:3)
Lemma 30. Let d and K. Let B be the dK-dimensional unit ball and B the uniform distributions
D
onB. Letζ > ζ > 0and a ,...a Bd. Moreover, letg : Bd R, g(x) = max(ζ ,max a ,x )
1 2 1 l 1 1 r l r
∈ → ≤ ≤ h i
and h : B R, h(x) = K g(x(k))2. Let x B such that for every k, max a ,x (k) ζ .
→ k=1 0 ∈ 1 ≤r ≤l h r 0 i ≤ 2
We define h˜(x) :=E q[h(x+δv)]. Then, for any 0 < δ < ζ ζ ,
v ∼DBP 1
−
2
h˜(x ) = 0,
0
∇
h˜(x ) = ζ √K.
0 1
Proof. First, for every k,r and u Bd, by Cauchy-Schwartz Inequality,
∈
a ,x (k)+δu = a ,x (k) + a ,δu ζ +δ < ζ
r 0 r 0 r 2 1
h i h i h i ≤
Then,
g(x (k)+δu) = max(ζ , max a ,x (k)+δu ) = ζ ,
0 1 r 0 1
1 r lh i
≤ ≤
and for every v B,
∈
K
h(x +δv) = g(max(ζ , max a ,x (k)+δv(k) ) = ζ √K.
0 v u uk X=1 1 1 ≤r ≤lh r 0 i 1
t
As a result,
h˜(x ) = E [h(x +δv)] = ζ √K.
0 v B 0 1
∼D
Now, by Lemma 27,
d
h˜(x ) = E [h(x +δv)v]
∇ 0 δ v ∼DS 0
d K 2
= E max(ζ , max a ,x (k)+δv(k) v
δ v ∼DSv u uk X=1(cid:18) 1 1 ≤r ≤lh r 0 i (cid:19) · 
d t  
= E ζ √Kv
δ v ∼DS 1
h i
55d
= ζ √KE [v]
δ 1 v ∼DS
= 0.
(cid:3)
Lemma 31. Let d. Let B be the d-dimensional unit ball and B the uniform distributions on
D
B. Let ζ > ζ ,ζ > 0 and vectors a ,...a Bd(0). Moreover, let h : B R, h(x) =
1 2 3 1 l ∈ G →
max(ζ ,max a ,x ) and x B,r [l] such that a ,x = ζ and max a ,x
ζ .
We3 define1
≤
h˜r
(≤
xl
)h
:=r
Ei
[h(x0
∈
+δv)]0
.∈ Then, for anyh 0
<r0
δ
<0
i 1
(1
ζ
max(1
ζ≤
,r ζ≤l, )r )6= ,r0h r 0
i ≤
2 v ∼DB 2G 1 − 2 3
h˜(x )= a ,x
0
h
r0 0
i
h˜(x ) = a
∇
0 r0
Proof. First, by Cauchy-Schwartz Inequality,
max ζ ,max a ,x +δv max ζ ,max a ,x +max δv,a
3 r 0 3 r 0 r
(cid:18)
r 6=r0h i
(cid:19)
≤
(cid:18)
r 6=r0h i r 6=r0h i
(cid:19)
max(ζ ,ζ +Gδ)
3 2
≤
max(ζ ,ζ )+Gδ
3 2
≤
1
< (ζ +max(ζ ,ζ )),
1 3 2
2
and for r ,
0
1
a ,x +δv = a ,x + δv,a ζ Gδ > (ζ +max(ζ ,ζ )).
h
r0 0
i h
r0 0
i h
r0i≥ 1
− 2
1 2 3
We derive that for every v B,
∈
h(x +δv) = max ζ , max a ,x+δv ) = a ,x+δv .
0 3
1 r lh
r
i h
r0
i
(cid:18) ≤ ≤ (cid:19)
and that the maximum is attained in r . Then,
0
h˜(x ) = E [h(x +δv)]
0 v B 0
∼D
= E [ a ,x +δv ]
v ∼DB h r0 0 i
= a ,x +δE v
h r0 0 v ∼DB i
= a ,x
h
r0 0
i
and by Lemma 27,
d
h˜(x )= E max ζ , max a ,x +δv v
∇ 0 δ v ∼DS 3 1 r lh r 0 i
(cid:20) (cid:18) (cid:18) ≤ ≤ (cid:19)(cid:19) (cid:21)
d
= E [( a ,x +δv )v]
δ v ∼DS h r0 0 i
d d
= a ,x E [v]+ E [ a ,δv v]
h r0 0 iδ v ∼DS δ v ∼DS h r0 i
= 0+daT E vvT
r0 v ∼DS
= daT E vvTh . i
r0 v ∼DS
h i
56Now, we define random variables Y ,...,Y R,X ,...,X R and Y Rd such that X
1 d 1 d i
∈ ∈ ∈ ∼
N(0,1) (where N(0,1) is the normal univariate distribution with expectation 0 and variance 1),
Y = xi . By Lemma 28, we get, for the standard basis vectors e ...e ,
i 1 d
d X2
i=1 i
q
P
d
h˜(x)= daT E Y2e eT
∇ r0 Y1,...,Yd " i i i #
i=1
X
d
= daT E Y2 e eT
r0 Yi i i i
Xi=1 h i
d X2
= daT E i e eT
r0 Xi
"
d X2
#
i i
i=1 l=1 l
X
d 1 P
= daT e eT
r0 d i i
i=1
X
= a
r0
(cid:3)
Proof of Lemma 14. We assume that (Eq. (12)) holds and show Lemma 14 under this event. We
E
prove the claim by induction on t. For t = 1, it is trivial. Now, we assume that w = w˜ .
t t
For ℓ , in every t, by the proofs of Lemmas 18 to 21 and Lemma 4, it can be observed that for
1
every i [n], k 2, max max u,w (k) η , thus, in every iteration the term that gets the
maxima∈ l value is≥ 3η. Thent , by u L∈ eV mih ma 3t 0 ai nd≤ t1 h6 e hypothesis of the induction, for every i,
32
ℓ˜ (w˜ ,V ) = ℓ˜ (w ,V )= 0 = ℓ (w ,V ).
1 t i 1 t i 1 t i
∇ ∇ ∇
For ℓ˜ and every w Rd, V U and j [n2], by linearity of expectation,
2
∈ ⊆ ∈
ℓ˜ (w,(V,j)) = E w(0) +v(0), φ(V,j)
2 v δB
∈ h − i
= ℓ (w,((cid:16) V,j))+ E v(0), φ(cid:17) (V,j)
2 v δB
h ∈ − i
(cid:16) (cid:17)
= ℓ (w,(V,j))
2
Then, we derive that for every w and i, ℓ˜ (w,(V ,j )) = ℓ (w,(V ,j )).
2 i i 2 i i
For ℓ˜ , which is a 2-Lipschitz linear∇ function, for t = ∇ 1, by the proof of Lemma 18, the term
3
that gets the maximal value is δ . Moreover, it can be observed that for such t, and every ψ Ψ,
1
∈
1 ǫ
max w(0) ,ψ α(ψ),w (1) = 0.
ψ Ψ h 1 i− 4T2h 1 i
∈ (cid:18) (cid:19)
Then, we can apply Lemma 29, and get by the hypothesis of the induction,
ℓ˜ (w˜ ) = ℓ˜ (w )= 0 = ℓ (w ).
3 1 3 1 3 1
∇ ∇ ∇
If t 2, it can be observed that
≥
1 ǫ
ℓ (w )= max δ ,max w(0) ,ψ α(ψ),w (1)
3 t 2 ψ Ψ h t i− 4T2h t i
(cid:18) ∈ (cid:18) (cid:19)(cid:19)
1 ǫ
= max w(0) ,ψ α(ψ),w (1)
ψ Ψ h t i− 4T2h t i
∈ (cid:18) (cid:19)
57Then,bytheproofsofLemmas19to21andLemma4,themaximalvalueof w(0),ψ 1 ǫ α(ψ),w(1)
h i−4T2h i
is attained in ψ = ψ and the difference from the second maximal possible value of this term is at
∗
most ǫ . As a result, usingthe fact that this maximum is also larger than δ by at least η (which
2T2 2 8n
is also larger than δ), we can apply Lemma 31 and get by the hypothesis of the induction that,
ℓ˜ (w˜ )(k) = ℓ˜ (w )(k)
3 t 3 t
∇ ∇
1 n φ(V ,j ) k =0
n i=1 i i
=  ǫ α(1 n φ(V ,j )) k =1
0−P4T2 n i=1 i i
otherwise
P
= ℓ 3(w t)(k).
∇
For ℓ˜ , for t 1,2 , by the proofs of Lemmas 18 and 19, the term that gets the maximal value
4
∈ { }
is δ . Moreover, it can be observed that for every such t, and every k [T 1] and u U,
2
∈ − ∈
3 1
u,w (k) u,w (k+1) = 0.
t t
8h i− 2h i
Then, we can apply Lemma 29, and get by the hypothesis of the induction,
ℓ˜ (w˜ ) = ℓ˜ (w ) = 0= ℓ (w ).
4 t 4 t 4 t
∇ ∇ ∇
For t = 3, it can be observed by the proof of Lemma 20 that,
3 1
ℓ (w ) = max δ , max u,w (k) u,w (k+1)
4 t 2 t t
k ∈[T −1],u ∈U (cid:18)8h i− 2h i (cid:19)!
3 1
= max u,w (k) u,w (k+1)
t t
k [T 1],u U 8h i− 2h i
∈ − ∈ (cid:18) (cid:19)
Moreover, the maximal value is 3ηǫ and is attained in k = 1,u = u = α(ψ ). The second
32T2 0 0 ∗
maximal possible value of this term is δ = 3ηǫ , then, by the fact that δ < 3ηǫ 3ηǫ = 3ηǫ ,
2 64T2 32T2 − 64T2 64T2
we can apply Lemma 31 and get by the hypothesis of the induction that
ℓ˜ (w˜ )(k) = ℓ˜ (w )(k)
4 t 4 t
∇ ∇
3u k = 1
8 0
=  1u k = 2
−
0
2 0
otherwise
= ℓ 4(w t)(k).
∇
For t 4, it can be observed by the proofs of Lemmas 4 and 21 that,
≥
3 1
ℓ (w ) = max δ , max u,w (k) u,w (k+1)
4 t 2 t t
k ∈[T −1],u ∈U (cid:18)8h i− 2h i (cid:19)!
3 1
= max u,w (k) u,w (k+1)
t t
k [T 1],u U 8h i− 2h i
∈ − ∈ (cid:18) (cid:19)
Moreover, the maximal value is 3η and is attained in k = t 2,u = u = α(ψ ). The second
16 0 − 0 ∗
maximal possible value of this term is smaller then 5η, then we can apply again Lemma 31 and get
64
by the hypothesis of the induction that
ℓ˜ (w˜ )(k) = ℓ˜ (w )(k)
4 t 4 t
∇ ∇
583u k = t 2
8 0 −
=  1u k = t 1
−
0
2 0 otherw−
ise
= ℓ 4(w t)(k).
∇
In conclusion, we proved that F(w ) = F˜(w˜ ), thus, by the hypothesis of the induction,
t t
∇ ∇
w = wb F(w )b= w˜ F˜(w˜ ) = w˜
t+1 t t t t t+1
−∇ −∇
(cid:3)
b b
Lemma 32. Letd andδ > 0. Letf :Rd Rbe aG-Lipschitz function. LetBbe the d-dimensional
unit ball. Moreover, let DB be the unifor→ m distributions on B. If f˜(x) = E v ∼DB[f(x+δv)], then
for every x,
f˜(x) f(x) Gδ
| − | ≤
Proof. By the fact that f is G-Lipschitz,
f˜(x) f(x) = E [f(x+δv)] f(x)
| − | | v ∼DB − |
E [f(x)]+GδE +[ v ] f(x)
≤ | v ∼DB v ∼DB k k − |
= GδE [ v ]
v ∼DB k k
Gδ
≤
(cid:3)
D.2 Proofs of Appendix A.2
Proof of Lemma 15. First, differentiability can be derived immediately from Lemma 27. Second,
for 4-Lipschitzness, for every V Z, we define f˜SGD : Rd R as f˜SGD(w) := f˜SGD(w,V). By the
∈ V → V
5-LipschitznessoffSGD withrespecttoitsfirstargumentandJensenInequality, foreveryx,y Rd,
∈
it holds that
f˜SGD(x) f˜SGD(y) = E fSGD(y+v) E fSGD(w+v)
| V − V | v ∈δB V − v ∈δB V
= (cid:12) (cid:12)E (cid:16) fSGD(x+v)(cid:17) fSGD(y(cid:16) +v) (cid:17)(cid:12) (cid:12)
(cid:12) v ∈δB V − V (cid:12)
E(cid:12)
(cid:12)
(cid:16)
fSGD(x+v)
fSGD(y+v)(cid:17)(cid:12)
(cid:12)
≤ (cid:12) v ∈δB V − V (cid:12)
(cid:12)(cid:16) (cid:17)(cid:12)
4x y(cid:12) . (cid:12)
≤ | − (cid:12)| (cid:12)
Third, for convexity, by the convexity of fSGD for every x,y Rd and α [0,1],
∈ ∈
f˜SGD(αx+(1 α)y) = E fSGD(αx+(1 α)y+v)
V − v ∈δB V −
= E (cid:16) fSGD(α(x+v)+(1 α)((cid:17) y+v))
v ∈δB V −
E (cid:16) αfSGD(x+v)+(1 α)f (y+v(cid:17) ))
≤ v ∈δB V − V
= αE (cid:16) fSGD(x+v) +(1 α) E fS(cid:17) GD(y+v)
v ∈δB V − v ∈δB V
=
αf˜SGD(x(cid:16)
)+(1
α)f˜S(cid:17)GD(y). (cid:16) (cid:17)
V − V,j
(cid:3)
59Proof of Lemma 16. We assume that (Eq. (15)) holds and prove Lemma 16 under this event.
′
E
We prove the claim by induction on t. For t = 1, it is trivial. Now, we assume that w = w˜. First,
t t
for ℓ˜SGD and every w and V, by linearity of expectation,
3
1 1
ℓ˜SGD(w,V)= E w(0,1) +v(0,1), φ(V,1) u ,w(1) +v(1)
3 v ∈δB h −4n2 i−hn3 1 i
(cid:18) (cid:19)
1 1
= ℓSGD(w,V)+ E v(0,1), φ(V,1) u ,E v(1)
3 h v ∈δB −4n2 i−hn3 1 v ∈δB i
(cid:18) (cid:19)
= ℓSGD(w,V)
3
Then, we derive that for every w, ℓ˜SGD(w,V) = ℓSGD(w,V). Now, for r 1,2 we show that
in each term ℓ˜SGD(w ,V ), the argu∇ me3 nt that gives∇ the3 maximum value is the∈ sa{ me a} s ℓSGD(w ,V ).
r t t r t t
For ℓ˜SGD(w ,V ), inevery t,by theproofsof Lemma24, Lemma25andLemma10,themaximal
1 t t
value is 3η. Moreover, it can be observed that for every k 2, max max u,wSGD(k) η .
32 ≥ t u ∈Vth t i ≤ 16
Then, by Lemma 30, and the hypothesis of the induction,
ℓ˜SGD(w˜,V ) = ℓ˜SGD(w ,V ) = 0= ℓSGD(w ,V ).
∇ 1 t t ∇ 1 t t ∇ 1 t t
Now, for ℓ˜SGD, for t = 1, ℓSGD(w ,V ) = 0 and the maximum is attained uniquely in δ = η
2 ∇ 2 1 1 1 8n3
(the second maximal value is zero). Then, we can apply Lemma 29 and by the hypothesis of the
induction, it follows that,
ℓ˜SGD(w˜ ,V ) = ℓ˜SGD(w ,V )= 0 = ℓSGD(w ,V ).
∇ 2 1 1 ∇ 2 1 1 ∇ 2 1 1
For every t 2, the maximum is attained uniquely in the linear term of k = t 1,u = u and
t 1
≥ − −
ψ = ψ such that the difference between the maximal value the second largest value is larger
t∗ 1
than η−ǫ . Then, we can apply Lemma 31 and by the hypothesis of the induction, it follows that,
16n2
ℓ˜SGD(w˜,V ) = ℓ˜SGD(w ,V ) = ℓSGD(w ,V ).
∇ 2 t t ∇ 2 t t ∇ t t t
In conclusion, we proved that f˜SGD(w˜,V ) = fSGD(w ,V ), thus, by the hypothesis of the
t t t t
∇ ∇
induction,
w = w fSGD(w ,V ) = w˜ f˜SGD(w˜ ,V )= w˜ .
t+1 t t t t t t t+1
−∇ −∇
(cid:3)
E Lower bound of Ω min 1, 1
ηT
(cid:18) (cid:18) (cid:19)(cid:19)
In this section, we prove the Ω min 1, 1 lower bound. Since our hard construction for getting
ηT
this bound involves a determin(cid:16)istic (cid:16)loss fu(cid:17)n(cid:17)ction, GD is equivalent to SGD. For clarity, we refer
in our proof to the performance of GD, however, the same result is applicable also for SGD with
T = n iterations.
E.1 Construction of a non-differentiable loss function.
For d = max(25η2T2,1), we define the hard loss function fOPT : Rd R, as follows,
→
1 ηi
fOPT(w) =max 0,max w[i] . (19)
i [d]{√d − − 4d}!
∈
For this loss function, we prove the following lemma,
60Lemma 33. Assume n,T > 0,η 1 . Consider the loss function fOPT that isdefined inEq.(19)
≤ 5√T
for d = max(25η2T2,1). Then, for Unprojected GD (cf. Eq. (1) with W = Rd) on fOPT , initialized
at w = 0 with step size η, we have,
1
(i) The iterates of GD remain within the unit ball, namely w Bd for all t = 1,...,T;
t
∈
(ii) For all m = 1,...,T, the m-suffix averaged iterate has:
1
OPT OPT
f (w ) f (w )= Ω min 1, .
T,m
− ∗ (cid:18) ηT (cid:19)!
Algorithm’s dynamics We start by proving a lemma that characterizes the dynamics of the
algorithm.
Lemma 34. Assume the conditions of Lemma 33, and consider the iterate of Unprojected GD on
fOPT , initialized at w = 0 with step size η 1 Let w be the iterate of Then, it holds that,
1 ≤ 5√T t
(i) For every i [d] and for every t [T],
∈ ∈
1
w [i]
t
≤ 2√d
(ii) For every t [T], there exists an index j [d] such that k = j ,
t t
∈ ∈ 6
1 ηj 1 ηk η
w [j ] > w [k] + .
t t t
√d − − 4d √d − − 4d 8d
(iii) For every t [T], j also holds
t
∈
1 ηj η
t
w [j ] > .
t t
√d − − 4d 8d
Proof. We prove by induction on t. For t = 1, w = 0, thus,
t
1
w [i] = 0 .
1
≤ 2√d
Moreover, the maximizer is j = 1. Then, we notice that for both d = 1 and d = 25η2T2,
1
η 1 = η 1 . Then, it holds that,
≤ 5√T ⇒ ≤ 5√d
1 ηj 1 η
1
w [j ] w [j ]
1 1 1 1
√d − − 4d ≥ √d − − 4
19
≥ 20√d
η
> ,
8d
and, for every k = j ,
1
6
1 ηj 1 ηk η(k j )
1 1
w [j ] = w [k] + −
1 1 1
√d − − 4d √d − − 4d 4d
611 ηk η
w [k] +
1
≥ √d − − 4d 4d
1 ηk η
> w [k] + .
1
√d − − 4d 8d
In the step of the induction we assume that the lemma holds for every s t and prove it for
≤
s = t+1. By the hypothesis of the induction, we know that for every iteration s t, w 1,
≤ k t k2 ≤ 2
as a result, we know that the projections does not affect the dynamics of the algorithm until the
iteration t. Moreover, we know that for every iteration s t there exists an index j [d] such
s
≤ ∈
that the term that achieve the maximum value in w is 1 w [j ] ηj. This maximum is attained
s √d− s s −4d
uniquely in j by margin that is strictly larger than η . As a result, we derive that, for every s t,
s 8d ≤
f(w ) = e . Now, for every index m [d], we define,
∇
s
−
js
∈
1 ηi
nm = s t :m = argmax w [i] .
t |{ ≤ i [d]{√d − s − 4d}}|
∈
We get that, for every i it holds that,
w [i] = ηni.
t+1 t
Then,
w = ηni ηt,
k t+1 k1 t ≤
i
X
and ,thus, there exists a entry k [d] with w [k] ηt. Now, we prove the first part of the lemma
∈ t+1 ≤ d
using this observation and the step of the induction. For every i= j ,
t
6
1
w [i] = w [i] .
t+1 t
≤ 2√d
Otherwise, we know that, by the definition of j
t
1 ηi 1 ηk η
w [i] > w [k] + ,
t t
√d − − 4d √d − − 4d 8d
η(k i) η
w [i] < w [k]+ −
t t
4d − 8d
ηt η
+
≤ d 4
1 1
+
≤ 25√d 20√d
and,
w [i] w [i]+η
t+1 t
≤
1 1 1
+ +
≤ 25√d 20√d 5√d
1
,
≤ 2√d
where we again used the fact that η 1 implies η 1 for both d = 1 and d = 25η2T2.
≤ 5√T ≤ 5√d
62j
For the second partof thelemma, we defineJ [d], J = argmin n and j = min j J
t ⊆ t j{ t} t+1 { ∈ t }
and show that j holds the required. We know, for every j = i [d],
t+1
6 ∈
w [i] w [j] = η(ni nj ).
t+1 − t+1 t− t
For k = j with nk > njt+1,
6 t+1 t t
1 ηj 1 ηj
t+1 t+1
w [j ] w [k] η
t+1 t+1 t+1
√d − − 4d ≤ √d − − − 4d
1 ηk η(k j )
t+1
= w [k] η + −
t+1
√d − − − 4d 4d
1 ηk η
w [k] η +
t+1
≤ √d − − − 4d 4
1 ηk η
< w [k] .
t+1
√d − − 4d − 2
in contradiction to the fact that j gets the maximal value. For k = j with nk > njt+1, it holds
t+1 6 t+1 t t
that w [j ] w [k] η, and,
t+1 t+1 t+1
≤ −
1 ηj 1 ηj
t+1 t+1
w [j ] w [k]+η
t+1 t+1 t+1
√d − − 4d ≥ √d − − 4d
1 ηk η(k j )
t+1
= w [k]+η + −
t+1
√d − − 4d 4d
1 ηk η
w [k]+η
t+1
≥ √d − − 4d − 4
1 ηk η
> w [k] + ,
t+1
√d − − 4d 8d
as required. For the third part of the lemma, we know that for every i [d],
∈
1 ηi 1 η
w [i]
t+1
√d − − 4d ≥ 2√d − 4
9
=
20√d
η
> .
8d
(cid:3)
Proof of lower bound. Now we can prove Lemma 33.
Proof of Lemma 33. The first part of the theorem is an immediate corollary from Lemma 34.
Moreover, by applying this lemma again, we know that, for every i [d],
∈
1
w [i] ,
T,m
≤ 2√d
thus,
1 η
fOPT(w ) fOPT(w ) 0
T,m
− ∗ ≥ 2√d − 4 −
631 η
≥ 2√d − 20√d
1
>
4√d
1 1
= min , .
4 20ηT
(cid:18) (cid:19)
(cid:3)
E.2 Construction of a differentiable loss function.
In this section, we prove the lower bound for a smoothing of fOPT, defined as
1 ηi
f˜OPT(w) = E
v
∈Bdmax 0,m
i
a [dx
]{√d
−w[i] −δv[i]
−
4d}!, (20)
∈
namely, we prove the following lemma,
Lemma 35. Assume n,T > 0,η 1 . Consider the loss function f˜OPT that isdefined inEq.(20)
≤ 5√T
for d = max(25η2T2,1) and δ = η . Then, for Unprojected GD (cf. Eq. (1) with W = Rd) on
16d
OPT
f , initialized at w = 0 with step size η, we have,
1
(i) The iterates of GD remain within the unit ball, namely w Bd for all t = 1,...,T;
t
∈
(ii) For all m = 1,...,T, the m-suffix averaged iterate has:
1
f˜OPT
(w )
f˜OPT
(w )= Ω min 1, .
T,m
− ∗ (cid:18) ηT (cid:19)!
First, we prove that the smoothing of the loss function does not affect the dynamics of the
algorithm, as stated in the following lemma,
Lemma 36. Under the conditions of Lemmas 33 and 35, let w ,w˜ be the iterates of Unprojected
t t
GD with step size η 1 and w = 0, on fOPT and f˜OPT respectively. Then, for every t [T],
≤ 5√T 1 ∈
it holds that w = w˜ .
t t
Proof. We proof the lemma by induction on t. For t = 1, we know that w = w˜ = 0. Now, we
1 1
assume that w = w˜ . By Lemma 34, we know that the maximum of the loss function is attained
t t
uniquely with the property that the difference between the maximal value and the second maximal
value is larger then η . As a result, by the facts that f is 1-Lipschitz and δ = η , we can use
8d 16d
Lemma 31 for F(w ) and get that,
t
b F(w )= F˜(w ) = F˜(w˜ ).
t t t
∇ ∇ ∇
It follows by the hypothesis of the inbduction thbat, b
w = w F(w ) = w˜ F˜(w˜ )= w˜ .
t+1 t t t t t+1
−∇ −∇
b b (cid:3)
Now we can prove Lemma 35.
64Proof of Lemma 35. Let w be the m-suffix average of GD when is applied on fOPT. Let
T,m
w = argmin fOPT(w). By Lemma 36, we know that, w = w . Then, by Lemma 33 and
w T,m T,m
∗
Lemma 32,
1
fOPT(w ) fOPT(w )
T,m
4√d ≤ − ∗
= fOPT(w ) fOPT(w )
T,m
− ∗
f˜OPT(w )+δ f˜OPT(w )+δ
T,m
≤ − ∗
f˜OPT(w )+δ f˜OPT(w )+δ,
T,m
≤ − ∗
and,
1 η
f˜OPT(w ) f˜OPT(w )
T,m
− ∗ ≥ 4√d − 8d
1 1
≥ 4√d − 8√d
1
≥ 8√d
1 1
min( , ).
≥ 8 40ηT
(cid:3)
65