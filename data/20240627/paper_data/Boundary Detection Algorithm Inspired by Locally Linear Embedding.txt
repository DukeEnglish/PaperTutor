BOUNDARY DETECTION ALGORITHM INSPIRED BY LOCALLY LINEAR
EMBEDDING
PEI-CHENGKUOANDNANWU
ABSTRACT. Inthestudyofhigh-dimensionaldata,itisoftenassumedthatthedatasetpossessesanunder-
lyinglower-dimensionalstructure. Apracticalmodelforthisstructureisanembeddedcompactmanifold
withboundary.Sincetheunderlyingmanifoldstructureistypicallyunknown,identifyingboundarypoints
fromthedatadistributedonthemanifoldiscrucialforvariousapplications. Inthiswork,weproposea
methodfordetectingboundarypointsinspiredbythewidelyusedlocallylinearembeddingalgorithm.We
implementthismethodusingtwonearestneighborhoodsearchschemes:theε-radiusballschemeandthe
K-nearestneighborscheme. Thisalgorithmincorporatesthegeometricinformationofthedatastructure,
particularlythroughitscloserelationwiththelocalcovariancematrix.Wediscusstheselectionthekeypa-
rameterandanalyzethealgorithmthroughourexplorationofthespectralpropertiesofthelocalcovariance
matrixinbothneighborhoodsearchschemes. Furthermore,wedemonstratethealgorithm’sperformance
withsimulatedexamples.
1. INTRODUCTION
In modern data analysis, it is common to assume that high-dimensional data concentrate around a
low-dimensionalstructure. Atypicalmodelforthislow-dimensionalstructureisanunknownmanifold,
whichmotivatesmanifoldlearningtechniques.However,manyapproachesinmanifoldlearningassume
theunderlyingmanifoldofthedatatobeclosed(compactandwithoutboundary),whichdoesnotalways
alignwithrealisticscenarioswherethemanifoldmayhaveboundaries. Thisworkaimstoaddressthe
identificationofboundarypointsfordatadistributedonanunknowncompactmanifoldwithboundary.
Due to the distinct geometric properties of boundary points compared to interior points, boundary
detectioniscrucialfordevelopingnon-parametricstatisticalmethods(see[3]andPropositionA.1inthe
SupplementaryMaterialforkerneldensityestimation)anddimensionreductiontechniques. Moreover,
itplaysanimportantroleinkernel-basedmethodsforapproximatingdifferentialoperatorsonmanifolds
undervariousboundaryconditions([18,15,25]).However,identifyingboundarypointsonanunknown
manifoldpresentssignificantchallenges. Traditionalmethodsforboundarydetectionmaystruggledue
to the extrinsic geometric properties of the underlying manifold and the non-uniform distribution of
data.
LocallyLinearEmbedding(LLE)[21]isawidelyappliednonlineardimensionreductiontechnique.
Inthiswork,weproposeaBoundaryDetectionalgorithminspiredbyLocallyLinearEmbedding(BD-
LLE). BD-LLE leverages barycentric coordinates within the framework of the LLE, implemented via
either an ε-radius ball scheme or a K-nearest neighbor (KNN) scheme. It incorporates manifold’s
geometry through its relation with the local covariance matrix. Across sampled data points, BD-LLE
approximatesabumpfunctionthatconcentratesattheboundaryofthemanifold,exhibitingaconstant
value on the boundary and zero within the interior. This characteristic remains consistent regardless
ofextrinsiccurvatureanddatadistribution. Thecleardistinctioninbumpfunctionvaluesbetweenthe
boundaryandtheinteriorfacilitatesstraightforwardidentificationofpointsinasmallneighborhoodof
the boundary by applying a simple threshold. Particularly in the ε-radius scheme, BD-LLE identifies
pointswithinanarrow,uniformcollarregionoftheboundary.
Keywordsandphrases. ManifoldLearning;Manifoldwithboundary;Boundarydetection;Localcovariancematrix;Locally
linearembedding;Nearestneighborhoodsearchscheme.
1
4202
nuJ
62
]LM.tats[
1v65481.6042:viXra2 PEI-CHENGKUOANDNANWU
Weoutlineourtheoreticalcontributionsinthiswork. Utilizingresultsfrom[28],wepresentthebias
andvarianceanalysesofthelocalcovariancematrixconstructedunderboththeε-radiusballschemeand
theKNNscheme,fordatasampledfrommanifoldswithboundary.Weexplorethespectralpropertiesof
thelocalcovariancematrixtoaidinparameterselectionandanalyzetheBD-LLEalgorithm. Previous
theoretical analyses of manifold learning algorithms have predominantly focused on the ε-radius ball
search scheme, with fewer results available for the KNN scheme. (Refer to [6, 8] for analyses of
the Diffusion maps (Graph Laplacians) on a closed manifold in the KNN scheme.) The framework
developedinthispaperprovidesusefultoolsforanalyzingkernel-basedmanifoldlearningalgorithms
intheKNNschemeapplicabletomanifoldswithboundary.
We provide a brief overview of the related literature concerning the local covariance matrix con-
structed from samples on embedded manifolds in Euclidean space. Most research focuses on closed
manifolds. [2]explicitlycalculatesahigherorderexpansioninthebiasanalysisofthelocalcovariance
matrixusingtheε-radiusballscheme. [24]studiesthespectralpropertiesofthelocalcovariancematrix
intheε-radiusballschemefordataunderspecificdistributionsontheclosedmanifold. [26]presents
the bias and variance analyses of the local covariance matrix in the ε-radius ball scheme. Notably,
[22]providesthebiasandvarianceanalysesofthelocalcovariancematrixconstructedusingasmooth
kernelforsamplesonmanifoldswithandwithoutboundary. Recentstudiesincludeconsiderationsof
noise. [16]investigatesthelocalcovariancematrixintheKNNscheme,focusingondatasampledfrom
aspecificclassofclosedmanifoldscontaminatedbyGaussiannoise. [17,12]explorethespectralprop-
ertiesofthelocalcovariancematrixconstructedintheε-radiusballscheme,fordatasampledonclosed
manifoldswithGaussiannoise.
We further review the boundary detection methods developed in recent decays. The α-shape al-
gorithm and its variations [13, 14, 9] are widely applied in boundary detection. Other approaches
[11,4,10]utilizeconvexityandconcavityrelativetotheinwardnormaldirectionoftheboundary.How-
ever, these methods are most effective when applied to data on manifolds with boundary of the same
dimensionastheambientEuclideanspace. Severalmethods[30,29,19,7,20]aredevelopedbasedon
theasymmetryandthevolumevariationneartheboundary;e.g. asapointmovesfromtheboundaryto
theinterior,itsneighborhoodshouldencompassmorepoints.Nevertheless,theperformanceoftheseal-
gorithmsissensitivetothemanifold’sextrinsicgeometryanddatadistribution. Recently,[1]proposes
identifying boundary points using Voronoi tessellations over projections of neighbors onto estimated
tangentspaces. [5]detectsboundarypointsbydirectlyestimatingthedistancetotheboundaryfunction
forpointsneartheboundary.
The remainder of the paper is structured as follows. We review the LLE algorithm and its relation
with the local covariance matrix in Section 2. In Section 3.1, we define the detected boundary points
basedonthemanifoldwithboundarysetupandintroducetheBD-LLEalgorithminboththeε-radius
ball and KNN schemes. Section 3.2 discusses the relation between BD-LLE and the local covariance
matrix. InSection3.3,weproposetheselectionofakeyparameterforBD-LLEbasedonthespectral
propertiesofthelocalcovariancematrix. Section4presentsthebiasandvarianceanalysesofthelocal
covariancematrixandBD-LLEinboththeε-radiusballandKNNschemes. Section5providesnumer-
icalsimulationscomparingtheperformanceofBD-LLEwithdifferentboundarydetectionalgorithms.
Table1summarizesthecommonlyusednotations.
2. REVIEWOFTHELOCALLYLINEAREMBEDDING
Recallthedefinitionsofthefollowingtwonearestneighborhoodsearchschemes.
Definition2.1. SupposeX ={z}n ⊂Rp. Denotethenearestneighborofz ∈X asO ={z }Nk
i i=1 k k k,i i=1
withN tobethenumberofpointsinO .
k k
Intheε-radiusballschemewithε >0,
O k={z i∈X|0<∥z i−z k∥Rp ≤ε}.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 3
TABLE1. Commonlyusednotationsinthispaper.
Symbol Meaning
M d-dimensionalcompactsmoothmanifoldwithsmoothboundary
∂M TheboundaryofM
ι AnisometricembeddingofMinRp
P P.d.f. onMwithlowerandupperboundsP andP respectively
m M
{x}n PointssampledbasedonPfromM
i i=1
X ={z =ι(x)}n Thepointcloud
i i i=1
ε,K Thescaleparameters
O Thenearestneighborsofz
k k
B Thevalueoftheboundaryindicatoratz
k k
B(x),B˜(x) ThebumpfunctionsintheanalysesofBD-LLEindifferent
nearestneighborhoodsearchschemes
IntheKNNschemewith1≤K≤n−1,foranyz ∈X,werearrangeX \{z }={z′}n−1basedon
k k i i=1
theirdistancestoz k,i.e. ∥z′ 1−z k∥Rp ≤···≤∥z′ K−z k∥Rp ≤···≤∥z′ n−1−z k∥Rp. Then
O k={z i∈X|0<∥z i−z k∥Rp ≤∥z′ K−z k∥Rp}.
Remark2.1. IntheKNNscheme,iftherearez i̸=z jinX with∥z i−z k∥Rp=∥z j−z k∥Rp=∥z′ K−z k∥Rp,
thenN ̸=K. OtherwiseN =K.
k k
We summarize the essential details of the LLE and direct readers to [21, 26, 28] for an in-depth
discussion.ForthepointcloudX ={z}n ⊂Rp,weapplyeithertheε-radiusballschemeortheKNN
i i=1
schemetodetermineO . Thebarycentriccoordinatesofz associatedwithO ={z }Nk ,denotedas
k k k k,i i=1
w ,aredefinedasthesolutionofthefollowingoptimizationproblem:
k
(cid:13) Nk (cid:13)2
(2.1) w = argmin (cid:13)z −∑w(j)z (cid:13) = argmin w⊤G⊤ G w∈RNk,
k (cid:13) k k,j(cid:13) n,k n,k
w∈RNk,w⊤111Nk=1 j=1 w∈RNk,w⊤111Nk=1
where111
Nk
isavectorinRNk withallentries1and
 
| |
(2.2) G n,k:=z k,1−z
k
... z k,Nk−z k∈Rp×Nk
| |
is called the local data matrix. By employing the Lagrange multiplier method, solving optimization
problem(2.1)isreformulatedasfindingthesolutiontothefollowingequation:
y
(2.3) G⊤ G y =111 , w = k .
n,k n,k k Nk k y⊤111
k Nk
SinceG⊤ G mightbesingular, itissuggestedin[21]tostabilizeaboveequationthrougharegular-
n,k n,k
izationandsolve
y
(2.4) (G⊤ G +cI )y =111 , w = k ,
n,k n,k Nk×Nk k Nk k y⊤111
k Nk
wherec>0istheregularizerchosenbytheuser. Asshownin[26],theregularizerplaysacriticalrole
inLLE.TheLLEmatrixW ∈Rn×n isdefinedthroughthebarycentriccoordinatesofz fork=1,...,n
k
as
(cid:26) w (j) ifz =z ∈O ;
(2.5) W = k i k,j k
ki 0 otherwise.4 PEI-CHENGKUOANDNANWU
ToreducethedimensionofX,itissuggestedin[21]toembedX intoalowdimensionEuclidean
spacevia
(2.6) z (cid:55)→Y =[v (k),···,v (k)]⊤∈Rℓ
k k 1 ℓ
for each z ∈ X, where ℓ ∈ N is the dimension of the embedded points chosen by the user and
k
v ,···,v ∈Rnaretheeigenvectorsof(I−W)⊤(I−W)correspondingtotheℓsmallesteigenvalues.
1 ℓ
Next,wediscusstherelationbetweentheLLEandthelocalcovariancematrix. LetG bethelocal
n,k
datamatrixaroundz definedin(2.2)whichisconstructedthrougheithertheε radiusballschemeor
k
theKNNscheme. Define
Nk
(2.7) C =G G⊤ =∑(z −z )(z −z )⊤∈Rp×p.
n,k n,k n,k k,i k k,i k
i=1
Then 1C isthelocalcovarianceatz matrixconstructedinthenearestneighborhoodsearchscheme.If
n n,k k
r =rank(G⊤ G ),thenr =rank(G )=rank(G⊤ G )=rank(G G⊤ )≤min(N ,p)≤pand
n n,k n,k n n,k n,k n,k n,k n,k k
G G⊤ ispositivesemidefinite.Denotetheeigen-decompositionofthematrixG G⊤ asU Λ U⊤,
n,k n,k n,k n,k n,k n,k n,k
whereΛ =diag(λ (z ),λ (z ),...,λ (z )),
n,k n,1 k n,2 k n,p k
(2.8) λ (z )≥λ (z )≥···≥λ (z )>λ (z )=···=λ (z )=0,
n,1 k n,2 k n,rn k n,rn+1 k n,p k
(cid:20) (cid:21)
I 0
andU ∈O(p). LetI := rn ∈Rp×p. DefinetheregularizedpseudoinverseofC tobe
n,k p,rn 0 0 n,k
(2.9) I (C ):=U I (Λ +cI )−1U⊤,
c n,k n,k p,rn n,k p×p n,k
where c is the regularizer of the LLE. Note that I (C ) is symmetric, e.g. I (C )=I (C )⊤.
c n,k c n,k c n,k
Define
(2.10) T :=I (C )G 111 .
n,xk c n,k n,k Nk
Then,itisshownin[26,Section2]thatthesolutionto(2.4)is
(2.11) y =c−1111 −c−1G⊤ T ,
k Nk n,k n,xk
andhence
111 −G⊤ T 111⊤ −G⊤ I (C )G 111
(2.12) w =
Nk n,k n,xk
=
Nk n,k c n,k n,k Nk
.
k N −111⊤G⊤ T N −111⊤G⊤ I (C )G 111
k Nk n,k n,xk k Nk n,k c n,k n,k Nk
NotethatN −111⊤G⊤ T inthedenominatorof(2.12)isthesumofentriesof111 −G⊤ T inthe
k Nk n,k n,xk Nk n,k n,xk
numerator,sowecouldviewy in(2.11)asthekernelfunctionassociatedwithLLE,andw in(2.12)
k k
asthenormalizedkernel.
3. BOUNDARYDETECTIONALGORITHMINSPIREDBYTHELLE
3.1. Setup of the problem and the main idea of the algorithm. In this section, we focus on the
identification of boundary points distributed on a manifold with boundary. Prior to delving into the
BD-LLEalgorithm,weintroducethefollowingmodelofamanifoldwithboundary.
Assumption3.1. Let(M,g)bead-dimensionalcompact,smoothRiemannianmanifoldwithboundary
isometrically embedded in Rp via ι :M (cid:44)→Rp. We assume the boundary of M, denoted as ∂M, is
smooth. Denotethepushforwardasι .
∗
Since ι is an embedding, the boundary of ι(M) satisfies ∂ι(M)=ι(∂M). Next, we provide the
followingassumptionaboutthesamplesonthemanifoldwithboundaryM.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 5
Assumption3.2. Suppose(Ω,F,P)isaprobabilityspace,wherePisaprobabilitymeasuredefinedon
theBorelsigmaalgebraF onΩ. LetX bearandomvariableon(Ω,F,P)withtherangeon(M,g).
WeassumeP:=X PisabsolutelycontinuouswithrespecttothevolumemeasureonMassociatedwith
∗
g so that dP=PdV by the Radon-Nikodym theorem, where dV is the volume form of M and P is a
non-negativefunctiondefinedonM. WecallPtheprobabilitydensityfunction(p.d.f.) associatedwith
X. WefurtherassumeP∈C2(M)and0<P ≤P(x)≤P forallx∈M. Weassume{x ···,x }⊂M
m M 1 n
arei.i.d. sampledfromP.
UnderAssumptions3.1and3.2,weconsiderthepointcloudX ={z =ι(x)}n . Inthiswork,the
i i i=1
geometricinformationofι(M)isnotaccessible, andweproposetheBD-LLEalgorithmtodetectthe
boundary points on ι(M) through the Euclidean coordinates of X. Since ∂M is a measure 0 subset
of M and P is absolutely continuous with respect to the volume measure on M, the probability for a
sampleinX tolieon∂ι(M)is0.Thebestwecandoisfindingallpoints∂X fromX lyinginasmall
neighborhoodof∂ι(M)inι(M). Wecall∂X thedetectedboundarypointsfromX.
The BD-LLE algorithm includes the construction of a boundary indicator (BI) over X using the
barycentric coordinates of each sample point z . We describe the intuition behind this construction.
k
Specifically,thevalueoftheBIatz ,B ,approximatesthevalueofafunctionB(x)onMatx=x . The
k k k
function B(x) is constant on ∂M and attains maximum on ∂M. It decreases rapidly along the normal
direction of ∂M towards the interior of M. The value of B(x) at a point x is 0 whenever x is away
from ∂M. If we choose a threshold, then the preimage of the values larger than the threshold under
B(x) is a neighborhood of ∂M. In the context of the ε radius ball scheme, this preimage is a narrow,
uniformcollarregionof∂M. Referto(6)inTheorem4.2foraprecisedescription. Therefore,pointsz
k
correspondingtoB greaterthanthethresholdareidentifiedasboundarypoints.
k
WesummarizethestepsofBD-LLEinAlgorithm1. Theinputsofthealgorithmincludethepoint
cloud X, the scale parameters ε or K, and the regularizer c. The outputs of the algorithm are the
detectedboundarypoints∂X ⊂X.
Algorithm1:BD-LLEalgorithm
1: Inputs: X,ε orK,andc
2: Foreachk,findtheneighborhoodO k={z k,i}N i=k 1⊂X ofz k througheithertheε-ballschemeor
theKNNscheme.
 
| | |
3: ConstructG n,k=... z k,j−z k .... z k,j∈O k.;
| | |
4: Lety k=(G⊤ n,kG n,k+cI Nk×Nk)−1111 Nk. LetB k= Nk−c Ny k⊤ k111Nk.
5: Set∂X :={x k|B k≥ 1 2max kB k}.;
3.2. Relation between the local covariance matrix and the boundary indicator. We express BI
explicitlythroughthelocaldatamatrixG andthelocalcovariancematrix 1C definedin(2.2)and
n,k n n,k
(2.7)respectively. SinceG isinvariantundertranslation,andG⊤ G isinvariantunderorthogonal
n,k n,k n,k
transformation on Rp, y in Step 3 of Algorithm 1 is invariant under orthogonal transformation and
k
translation. Hence, B is invariant under translation and orthogonal transformation on Rp. Moreover,
k
B isrelatedtothelocalcovariancematrix 1C through(2.10)and(2.11). Wesummarizethefactas
k n n,k
thefollowingproposition.6 PEI-CHENGKUOANDNANWU
Proposition 3.1. The values of the BI in Algorithm 1 at each z , B , is invariant under translation of
k k
X andorthogonaltransformationonRp. Moreover,
(3.1) B =
N k−cy⊤ k111 Nk
=
T⊤ n,xkG n,k111 Nk
=
111⊤ NkG⊤ n,kI c(C n,k)G n,k111 Nk,
k
N N N
k k k
whereT andI (C )aredefinedin(2.10)and(2.9)respectively.
n,xk c n,k
3.3. Selectionoftheregularizer. Fromthediscussionintheprevioussubsection,weobservethatan
ideal BI should satisfy two main criteria: (1) it should be smaller within the interior of the manifold
to distinguish interior points from boundary points, and (2) it should approximate a constant near the
boundary to facilitate straightforward threshold selection. Proposition 3.1 establishes that the BI de-
pendsontheregularizedpseudoinverseI (C ). Accordingto(2.9),iftheregularizercoutweighsthe
c n,k
eigenvaluesofC ,thenI (C )isdominatedbyc−1U I U⊤ andB losesthegeometricinforma-
n,k c n,k n,k p,rn n,k k
tionofthemanifold. Consequently,thevaluesofB overtheinteriorandneartheboundarymaynotbe
k
distinguishable. Conversely,theinversionofG⊤ G +cI inStep3ofthealgorithmimpliesthat
n,k n,k Nk×Nk
ifcistoosmall,thenBIisnotstable. Moreover,thesmalleigenvaluesofG⊤ G encodethelocalex-
n,k n,k
trinsicgeometricinformationofι(M),suchasthesecondfundamentalform[26]. Therefore,choosing
ctoosmallcontaminatesthevaluesofB neartheboundarywiththeextrinsicgeometricinformation.
k
In section 4, we demonstrate that within the ε-radius ball (or the KNN ) scheme, given certain
relations between ε (or K) and n, the d largest eigenvalues ofC
n,k
are of order nεd+2 (or n(K n)d+ d2 ),
while the remaining smaller eigenvalues are of order O(nεd+4) (or O(n(K)d+ d4 )). Therefore, in our
n
theoreticalanalysisoftheBI,weproposec=nεd+3(orn(K)d+ d3
). Moreover,theaboveresultssuggest
n
thatforanyz ontheembeddedmanifoldwithboundary,thereexistd largeeigenvaluesofC inboth
k n,k
neighborhoodsearchschemes. Consequently, referringtothenotationsin(2.8)fortheeigenvaluesof
C ,weproposethefollowingmorepracticalchoiceofc,
n,k
(cid:115)
1 (cid:0) n (cid:1)(cid:0) n (cid:1)
(3.2) c= ∑λ (z) ∑λ (z) .
n
n,d i n,d+1 i
i=1 i=1
Note that based on our analysis of the eigenvalues ofC , this choice of c is of order O(nεd+3) (or
n,k
O(cid:0) n(K n)d+ d3(cid:1) ) and exceeds 1 n∑n i=1λ n,d+1(z i). We illustrate the performance of the BI on a unit disc
basedonthesuggestedcinFigure1.
4. THEORETICALANALYSIS
Inthissection,wedelveintothetheoreticalanalysesoftheBIandthelocalcovariancematrix,which
arecloselyrelated. Wepresenttheseanalysesinboththeε-radiusballschemeandtheKNNscheme.
Tostart,weprovideanintroductionoftheessentialgeometricpreliminaries.
4.1. Preliminary definitions. Suppose g is the Riemannian metric on M. Denote d (·,·) to be the
g
distancefunctiononMassociatedwithg. WedefinethefollowingconceptsaroundtheboundaryofM.
Definition4.1.
(1) Denotex :=argmin d (y,x)anddefinethedistancetotheboundaryfunction
∂ y∈∂M g
(4.1) ε˜(x)=d (x,∂M)= mind (y,x).
g g
y∈∂M
When x∈M and ε is sufficiently small, due to the smoothness of the boundary, such x is
ε ∂
uniqueandwehave0≤ε˜(x)≤ε.
(2) Forε >0,wedefinetheε-neighborhoodof∂Mas
M ={x∈M|d (x,∂M)<ε}.
ε gBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 7
FIGURE 1. TheplotsoftheBIconstructedover4000non-uniformlysampledpoints
ontheunitdisc.LeftPanel:TheBIisconstructedintheε-radiusballschemewithε=
0.2,andtheregularizercischosenasin(3.2). MiddlePanel:TheBIisconstructedin
theKNNschemewithK=70andtheregularizercischosenasin(3.2). RightPanel:
The BI is constructed in the ε-radius ball scheme with ε =0.2 and the regularizer
c= n1∑n i=1λ n,d(z i). The values of the BI are large over some interior points. When
theregularizeristoosmallsuchasc= n1∑n i=1λ n,d+1(z i),theBIisnotstable.
(3) Foranyx∈∂M,letγ (t)betheunitspeedgeodesicsuchthatγ (0)=xandγ′(0)istheunit
x x x
inwardnormalvectoratx.
Thedistancetotheboundaryfunctiond (x,∂M)satisfiesthefollowingproperties.
g
Proposition 4.1. Under Assumption 3.1, d (x,∂M) is a continuous function on M and differentiable
g
almosteverywhereonM. Inparticular,whenε issmallenough,d (x,∂M)issmoothonM .
g ε
Recall that both the BI and the local covariance matrix are invariant under translation. Moreover,
theBIisinvariantunderorthogonaltransformation. Hence,weintroducethefollowingassumptionto
simplifytheproofsandthestatementsofofthemainresults.
Assumption4.1. Foreachfixedx ,wetranslateandrotateι(M)inRpasfollows.
k
(1) Wetranslateι(M)inRpsothatι(x )=0.
k
(2) Denote{e}p tobethecanonicalbasisofRp,wheree isaunitvectorwith1inthei-thentry.
i i=1 i
Denote ι T M to be the embedded tangent space of ι(M) at ι(x) in Rp and (ι T M)⊥ be the
∗ x ∗ x
normalspaceatι(x).Fixanyι(x )=0∈ι(M),weassumethatι(M)hasbeenproperlyrotated
k
sothatι T Misspannedbye ,...,e .
∗ xk 1 d
(3) Whenx ∈M andε issufficientlysmall,letx betheuniquepointon∂Mwhichrealizesthe
k ε ∂,k
distancefromx to∂M definedin(1)ofDefinition4.1. γ (t)istheunitspeedgeodesicwith
k x ∂,k
γ (0)=x andγ (ε˜(x ))=x . Wefurtherrotateι(M)sothat
x ∂,k ∂,k x ∂,k k k
d
e =ι γ (ε˜(x )).
d ∗ dt x ∂,k k
Inparticular,whenx∈∂M,e istheinwardnormaldirectionof∂ι(M)atι(x).
d
Atlast,weintroducethefollowingfunctionsthatwillbeusedinthemainresults.8 PEI-CHENGKUOANDNANWU
Definition4.2. Let|Sm|denotethevolumeofthemdimensionalunitsphere. Wedefinethefollowing
functionson[0,∞),wheretheconstant
|Sd−2|
isdefinedtobe1whend=1.
d−1
(cid:40) |Sd−1|+|Sd−2|(cid:82)εt (1−x2)d− 21
dx for0≤t≤ε
σ (t,ε):= 2d d−1 0
0 |Sd−1|
fort>ε
d
(cid:40)
σ 1,d(t,ε):=
−| dS 2d −−2 1|(1−( εt)2)d+ 21 for0≤t≤ε
0 otherwise


|Sd−1| +|Sd−2|(cid:82)εt (1−x2)d+ 21
dx for0≤t≤ε
σ (t,ε):= 2d(d+2) d2−1 0
2

|Sd−1|
otherwise
d(d+2)
  |Sd−1| +|Sd−2|(cid:82)εt (1−x2)d− 21 x2dx for0≤t≤ε
σ (t,ε):= 2d(d+2) d−1 0
2,d

|Sd−1|
otherwise
d(d+2)
(cid:40)
−
|Sd−2| (1−(t)2)d+ 23
for0≤t≤ε
σ 3(t,ε):= (d2−1)(d+3) ε
0 otherwise
(cid:40)
−
|Sd−2| (2+(d+1)(t)2)(1−(t)2)d+ 21
for0≤t≤ε
σ 3,d(t,ε):= (d2−1)(d+3) ε ε
0 otherwise
Notethatthefunctionsσ (t,ε),σ (t,ε),andσ (t,ε)areboundedfrombelowby0andaboveby
1,d 3 3,d
constantsdependingond. Thefunctionsσ (t,ε),σ (t,ε),andσ (t,ε)areboundedfrombelowand
0 2 2,d
abovebyconstantsdependingond. Thesefunctionsaresmootheverywhereexceptatt =ε. Att =ε,
theyarecontinuousandtheirlevelofsmoothnessdependsond.
4.2. Analyses of the local covariance matrix and the boundary indicator in the ε-radius ball
scheme. Weprovidethebiasandvarianceanalysisofthelocalcovariancematrixintheε-radiusball
scheme. TheproofofthetheoremisacombinationofLemma31andLemma37in[28].
Theorem 4.1. Under Assumptions 3.1, 3.2, and 4.1, let 1C be the local covariance matrix at z
n n,k k
constructed in the ε-radius ball scheme, where C is defined in (2.7). Suppose ε =ε(n) such that
√ n,k
log(n) →0 and ε →0 as n→∞. We have with probability greater than 1−n−2 that for all k=
n1/2εd/2+1
1,...,n,
1
C =P(x
)(cid:20) M(0)(x k,ε) 0(cid:21) +(cid:20) M(11)(x k,ε) M(12)(x k,ε)(cid:21) ε+O(ε2)+O(cid:16)(cid:112) log(n)(cid:17)
.
nεd+2 n,k k 0 0 M(21)(x k,ε) 0 n1/2εd/2
Theblockmatricesintheaboveexpressionsatisfythefollowingproperties.
(1) M(0)(x,ε)∈Rd×d isadiagonalmatrix. Theithdiagonalentryisσ (ε˜(x ),ε)for1≤i≤d−1
2 k
andthedthdiagonalentryisσ (ε˜(x ),ε).
2,d k
(2) M(11)(x ,ε)issymmetricandM(12)(x ,ε)=M(21)(x ,ε)⊤.TheentriesinM(11)(x ,ε),M(12)(x ,ε),
k k k k k
andM(21)(x ,ε)are0whenx ∈M\M .
k k ε
(3) For all x , the magnitude of the entries in M(11)(x ,ε), M(12)(x ,ε), and M(21)(x ,ε) can be
k k k k
boundedfromabovebyaconstantdependingond,theC1 normofP,thesecondfundamental
formofι(M)inRpatι(x ),andthesecondfundamentalformof∂MinMatx .
√ k ∂,k √
(cid:16) (cid:17) (cid:16) (cid:17)
(4) O(ε2)andO log(n) representp×pmatriceswhoseentriesareofordersO(ε2)andO log(n)
n1/2εd/2 n1/2εd/2
respectively.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 9
√
log(n)
Undertheassumptionsintheabovetheorem,supposeε =ε(n)suchthat →0andε →0
n1/2εd/2+1
asn→∞. Theabovetheoremimpliesthatwithprobabilitygreaterthan1−n−2,forallx ∈M\M ,
k ε
1 P(x)|Sd−1|(cid:20) I 0(cid:21) (cid:16)(cid:112) log(n)(cid:17)
C = d×d +O(ε2)+O .
nεd+2 n,k d(d+2) 0 0 n1/2εd/2
This result matches the analysis of the local covariance matrix constructed from samples on a closed
manifold.
Sincetheeigenvalues{λ (z )}p ofC areinvariantundertranslationofX andorthogonaltrans-
n,i k i=1 n,k
formationonRp. Byapplyingaperturbationargument(AppendixAin[26]),forallk
(cid:114)
λ (z ) (cid:16) log(n) (cid:17)
n,i k =P(x )σ (ε˜(x ),ε)εd+2+O(εd+3)+O εd/2+2 fori=1,···,d−1;
k 2 k
n n
(cid:114)
λ (z ) (cid:16) log(n) (cid:17)
n,i k =P(x )σ (ε˜(x ),ε)εd+2+O(εd+3)+O εd/2+2 fori=d;
n
k 2,d k
n
(cid:114)
λ (z ) (cid:16) log(n) (cid:17)
n,i k =O(εd+4)+O εd/2+2 fori=d+1,···p.
n n
SupposeU ∈O(p)isthecorrespondingorthonormaleigenvectormatrixofC . SupposeX ∈O(d)
n,k n,k k,1
andX ∈O(p−d). Ifx ∈M ,then
k,2 k ε
(cid:20) X 0 (cid:21) (cid:16)(cid:112) log(n)(cid:17)
U = k,1 +O(ε)+O .
n,k 0 X
k,2
n1/2εd/2
Ifx ∈M\M ,then
k ε
(cid:20) X 0 (cid:21) (cid:16)(cid:112) log(n)(cid:17)
U = k,1 +O(ε2)+O .
n,k 0 X
k,2
n1/2εd/2
(cid:20) (cid:21) (cid:20) (cid:21)
X 0
SinceweproposeAssumption4.1, k,1 formsanorthonormalbasisofι T M,and forms
0 ∗ xk X
k,2
anorthonormalbasisof(ι T M)⊥. Therefore, whenx ∈M , anorthonormalbasisofι T M canbe
approximatedbyU
(cid:20) I d∗ ×dxk (cid:21) ,uptoamatrixwhosek entrieε sareoforderO(ε)+O(cid:16)√ l∗ og(x nk )(cid:17)
.
n,k 0
(p−d)×d
n1/2εd/2
Next,weprovidethefollowingbiasandvarianceanalysisoftheBIundertheε-radiusballscheme.
TheproofofthetheoremisinSectionAoftheSupplementaryMaterial.
Theorem4.2. UnderAssumptions3.1,3.2,4.1,andtheε-radiusballscheme,supposetheregularizer
√
c=nεd+3 andsupposeε =ε(n)sothat log(n) →0andε →0asn→∞. Whenε issmallenough,
n1/2εd/2+1
withprobabilitygreaterthan1−2n−2,forallk=1,...,n,
(cid:112)
(cid:16) log(n)(cid:17)
B =B(x )+O(ε)+O ,
k k n1/2εd/2
√
(cid:16) (cid:17)
where the constants in O(ε) and O log(n) depend on P , theC1 norm of P and the second funda-
n1/2εd/2 m
mentalformofι(M).
ThefunctionB(x):M→Rhasthefollowingproperties:
(1) B(x)=
(σ1,d(ε˜(x),ε))2
. Hence,B(x)isalwayscontinuousonM. Whenε issmallenough,it
σ0(ε˜(x),ε)σ2,d(ε˜(x),ε)
issmoothexceptattheset{x∈M|d (x,∂M)=ε}.
g
(2) B(x)=
4d2(d+2)|Sd−2|2
whenx∈∂M.
(d2−1)2|Sd−1|2
(3) B(x)=0whenx∈M\M .
ε
(4) Forx ,x ∈∂M,B(γ (t))=B(γ (t))for0≤t≤ε.
1 2 x1 x210 PEI-CHENGKUOANDNANWU
(5) Fix any x∈∂M, B(γ (t)) is a monotone decreasing function of t for 0≤t ≤ε. Moreover
x
d2(d+2)|Sd−2|2 (1−(t)2)d+1≤B(γ (t))≤ 4d2(d+2)|Sd−2|2 (1−(t)2)d+1for0≤t≤ε.
(d2−1)2|Sd−1|2 ε x (d2−1)2|Sd−1|2 ε
(6) Forany0<τ < 4d2(d+2)|Sd−2|2 ,B−1(τ,∞)=M withM ⊂M .
(d2−1)2|Sd−1|2 r r ε
We discuss the implications of the above results regarding the BI in the ε-radius ball scheme. By
(2)and(4),B(x)remainsconstantandattainsmaximumon∂M. Additionally,(4)and(5)indicatethat
B(x) decreases monotonically at the same speed along any geodesic perpendicular to ∂M. Therefore,
accordingto(3), thefunctionB(x)behaveslikeabumpfunction, concentratingon∂M andvanishing
inM\M .
ε
Suppose ε and n satisfy the conditions in Theorem 4.2. For n large enough, with high probability,
wehave|B −B(x )|=O(ε). Thus,whenx isneartheboundary,B approximatesanorder1constant.
k k k k
Specifically, from (3.1), we have B =
111⊤ NkG⊤ n,kI c(Cn,k)Gn,k111Nk.
The denominator N acts like the 0−1
k Nk k
kernel density estimator, eliminating the impact of the non-uniform distribution of the samples and
ensuringthatB remainsclosetoaconstantneartheboundary. RefertoLemmaA.2inSectionAofthe
k
SupplementaryMaterialforadetaileddiscussion. Additionally,refertoPropositionA.1inSectionAof
theSupplementaryMaterialforastronguniformconsistencyresultofkerneldensityestimationthrough
0−1kernelonamanifoldwithboundary. Whenx ∈M\M ,B isoforderO(ε). Therefore,by(6),
k ε k
we can select a threshold on B to identify points in ι(M ) for some M ⊂M . Moreover, according
k r r ε
to the conditions in Theorem 4.2, choosing a smaller ε for larger n reduces the error between B and
k
B(x )anddecreasesthesizeofM . Inconclusion,largernenablesmoreaccuratedetectionofboundary
k ε
points.
4.3. AnalysesoftheboundaryindicatorandthelocalcovariancematrixintheKNNscheme. We
startwiththefollowingdefinition.
Definition 4.3. Let BRp (z) be the p dimensional closed ball of radius a centered at z in Rp. For any
a
x∈M,defineN (x)=|BRp (ι(x))∩X|. WedefinethefollowingradiusatxassociatedwithK:
a a
R(x)=inf{a>0,N (x)≥K+1}.
a
a
Then,R(x)hasthefollowingproperties. TheproofofthepropositionisinSectionBoftheSupple-
mentaryMaterial.
Proposition4.2.
(1) R(x)isacontinuousfunctiononM.
(2) Foranyx∈∂M, supposeγ (t)isminimizingon[0,t ]. ThenR(x)isLipschitzalongγ (t)for
x 2 x
0≤t ≤t . Specifically, ift <t , then |R(γ (t ))−R(γ (t ))|≤t −t . Moreover, t1 <
2 1 2 x 1 x 2 2 1 R(γx(t1))
t2 whenevert <R(γ (t )).
R(γx(t2)) 1 x 1
SinceR(x)isacontinuousfunctiononMandMiscompact,R(x)attainsamaximumwith
R∗=maxR(x).
x∈M
Recallthefunctionσ inDefinition4.2. Forafixedt≥0,let
0
V(t,r)=σ (t,r)rd.
0
Let(x ,x ,···,x )denotethecoordinatesinRd.ThefunctionV(t,r)representsthevolumeoftheregion
1 2 d
R between the ball of radius r centered at the origin in Rd and the hyperplane x =t. Specifically,
t,r d
when r≤t,V(t,r)=
|Sd−1|rd
is the volume of the ball of radius r. Note thatV(t,r):[0,∞)→[0,∞)
d
is a continuous, monotone increasing function of r for a fixedt, andV(t,r) is differentiable except at
r=t. Hence, s=V(t,r) has an inverse r=U(t,s), whereU(t,s):[0,∞)→[0,∞) is also monotoneBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 11
increasing. Specifically,U(t,s)=( ds )d1 fors< |Sd−1|td. Moreover,bytheinversefunctiontheorem,
|Sd−1| d
U(t,s) is differentiable everywhere except at s=0 for d >1 and at s=
|Sd−1|td.
Suppose ε˜(x) is the
d
distancefromx∈Mto∂Masdefinedin(4.1). Let
K+1
R˜(x)=U(ε˜(x), ).
P(x)n
WeshowthatR˜(x)isanestimatorofR(x). TheproofofthepropositionisinSectionBoftheSupple-
mentaryMaterial.
Proposition4.3. Supposewehave K →0and log(n)(n)2/d →0asn→∞. Then, forallx∈M, with
n K K
probabilitygreaterthan1−2n−2,wehaveR(x)=R˜(x)(1+O((K)d1 )),wheretheconstantinO((K)d1
)
n n
dependsond,C1normofP,andP . Moreover,
m
1 ( d )d1 ( K )d1 ≤R∗≤3( 2d )d1 ( K )d1
2 |Sd−1| P n |Sd−1| P n
M m
.
Observe that for any z ∈X,C constructed through the KNN scheme is equal to theC con-
k n,k n,k
structed through the R(x )-radius ball scheme. Hence, by applying Proposition 4.3 and Theorem 4.1,
k
weprovidethebiasandvarianceanalysisofthelocalcovariancematrixintheKNNscheme. Theproof
oftheoremisinSectionCoftheSupplementaryMaterial.
Theorem 4.3. Under Assumptions 3.1, 3.2, and 4.1, let 1C be the local covariance matrix at z
n n,k k
constructedintheKNNscheme, whereC isdefinedin(2.7). SupposeK =K(n)sothat K →0and
n,k n
log(n)(n)2/d →0asn→∞. Then,withprobabilitygreaterthan1−4n−2,forallk,
K K
1 nC n,k=(cid:20) M˜(0 0)(x k) 00(cid:21) +(cid:20) MM ˜˜ (( 21 11 )) (( xx k ,, KK n)
)
M˜(12)( 0x k,K n)(cid:21) +O((K n)d+ d4 )+O(cid:16)(cid:112) Kl nog(n) (K n)d2(cid:17) .
k n
Thepropertiesoftheblockmatricesaresummarizedasfollows.
(1) Forx∈M,M˜(0)(x)∈Rd×d isadiagonalmatrix.
(a) The ith diagonal entry of M˜(0)(x) is µ 1(x)+O((K n)d+ d3 ), for i=1,···,d−1. The dth
diagonalentryofM˜(0)(x)isµ 2(x)+O((K n)d+ d3 ).
(b) µ (x)andµ (x)arecontinuousfunctionsonM. Forallx∈M,
1 2
1 d 2 K+1 d+2 2 2d 2 K+1 d+2
2(d+2)(
|Sd−1|P
)d(
n
) d ≤µ 1(x),µ 2(x)≤ d+2(
|Sd−1|P
)d(
n
) d .
M m
(c) Whenx∈∂M,
1 2d 2 K+1 d+2
µ 1(x)=µ 2(x)= (d+2)( |Sd−1|P(x))d(
n
) d .
(2) M˜(11)(x ,K)issymmetricandM˜(12)(x ,K)=M˜(21)(x ,K)⊤. Theentriesinthosematricesare
k n k n k n
oforderO((K n)d+ d3 ),wheretheconstantinO((K n)d+ d3 )dependsond,P m,theC1 normofP,the
secondfundamentalformofι(M)inRpatι(x ),andthesecondfundamentalformof∂MinM
k
atx .
∂,k
(3) Forx k∈M\M R∗,
1
nC
n,k=(cid:20) M˜(0 0)(x k) 00(cid:21) +O((K n)d+ d4 )+O(cid:16)(cid:112) Kl nog(n) (K n)d2(cid:17)
.
TheithdiagonalentryofM˜(0)(x k)is (d+1 2)( |Sd−1d |P(xk))d2 (K+ n1)d+ d2 +O((K n)d+ d3 ),for1≤i≤d.12 PEI-CHENGKUOANDNANWU
√
(cid:16) (cid:17)
(4)
O((K)d+ d4
)andO
Klog(n) (K)d2 representp×pmatriceswhoseentriesareofordersO((K)d+ d4
)
n √ n n n
(cid:16) (cid:17)
andO
Klog(n) (K)d2
respectively.
n n
SimilartothediscussionofthespectralpropertiesofC intheε-radiusscheme,basedontheabove
n,k
theorem,theeigenvalues{λ (z )}p ofC constructedintheKNNschemecanbecharacterizedas
n,i k i=1 n,k
follows. Forallk,
(cid:112)
λ n,i(z k) K d+3 (cid:16) Klog(n) K 2(cid:17)
=µ 1(x k)+O(( ) d )+O ( )d fori=1,···,d−1;
n n n n
(cid:112)
λ n,i(z k) K d+3 (cid:16) Klog(n) K 2(cid:17)
=µ 2(x k)+O(( ) d )+O ( )d fori=d;
n n n n
(cid:112)
λ n,i(z k) K d+4 (cid:16) Klog(n) K 2(cid:17)
=O(( ) d )+O ( )d fori=d+1,···p.
n n n n
Inparticular,whenx k∈M\M R∗,µ 1(x k)=µ 2(x k)= (d+1 2)( |Sd−1d |P(xk))d2 (K+ n1)d+ d2 .
SupposeU ∈O(p)isthe correspondingorthonormaleigenvector matrixofC . Suppose X ∈
n,k n,k k,1
O(d)andX ∈O(p−d). Foranyk,
k,2
U n,k=(cid:20) X 0k,1 X0 k,2(cid:21) +O((K n)d+ d3 )+O(cid:16)(cid:112) Kl nog(n) (K n)d2(cid:17) .
Ifx k∈M\M R∗,then
U n,k=(cid:20) X 0k,1 X0 k,2(cid:21) +O((K n)d+ d4 )+O(cid:16)(cid:112) Kl nog(n) (K n)d2(cid:17) .
To end this subsection, we provide the following bias and variance analysis of the BI in the KNN
scheme. TheproofofthetheoremisinSectionCoftheSupplementaryMaterial.
Theorem4.4.
UnderAssumptions3.1,3.2,4.1,andtheKNNscheme,supposec=n(K)d+ d3
andsup-
n
pose K =K(n) so that K →0 and log(n)(n)2/d →0 as n→∞. Then, with probability greater than
n K K
1−4n−2,forallk,
(cid:114)
B k=B˜(x
k)+O((K
)d1
)+O(cid:16) log(n)(cid:17)
,
n K
(cid:16)(cid:113) (cid:17)
TheconstantsinO((K n)d1 )andO log K(n) dependonP m,theC1normofPandthesecondfundamental
formofι(M). ThefunctionB˜(x):M→Rhasthefollowingproperties:
(1) B˜(x)iscontinuousonM.
(2) Define |Sd−2| =1whend=1. B˜(x)= 4d2(d+2)|Sd−2|2 whenx∈∂M.
d−1 (d2−1)2|Sd−1|2
(3) Ifnislargeenough,thenR∗ issmallenoughandγ (t)ismimizingon[0,2R∗]forallx∈∂M.
x
Thereexists0<t∗<R∗withB˜(γ (t))=0fort≥t∗andB˜(γ (t))decreasingfor0<t<t∗.
x x x x x
WediscusstheimplicationsoftheaboveresultsconcerningtheBIintheKNNscheme. By(2)and
(3),B˜(x)remainsconstantandattainsmaximumon∂M. Furthermore,foranypointxon∂M,B˜(γ (t))
x
decreases along the geodesic γ (t) from x to B˜(γ (t∗)) and B˜(γ (t))=0 when t ≥t∗. Since t∗ <R∗,
x x x x x x
the region where B˜(x) is non zero is contained in M R∗. Hence, B˜(x) behaves like a bump function,
concentratingon∂MandvanishinginM\M R∗. However,unlikeB(x)intheε-radiusballscheme,B˜(x)
intheKNNschememaynotdecreaseatthesamespeedalonggeodesicsperpendicularto∂M. Referto
Figure2foranillustration. Ifwechoose0<τ < 4 (d d2 2( −d+ 1)2 2) |S|S dd −− 12 |2|2 ,B˜−1(τ,∞)=N τ,whereN τ ⊂M R∗ isa
neighborhoodof∂MinM.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 13
(cid:113)
SupposeK andnsatisfytheconditionsinTheorem4.4. Whennislargeenough, log(n) ≤(K)d1 .
K n
With high probability, we have |B k−B˜(x k)|=O((K n)d1 ). Therefore, when x
k
is near the boundary,
B
k
approximates a constant value, and within M\M R∗, B
k
is of order O((K n)d1 ). Thus, we can set a
thresholdonB ktoidentifyallpointsinaneighborhoodoftheboundarycontainedinM R∗. Accordingto
Proposition4.3,asnincreases,R∗deceases,leadingtomorepreciseidentificationofboundarypoints.
FIGURE 2. An illustration to the function B˜(x) in the KNN scheme in a neighbor-
hood near the boundary of M. The green region is the intersection of M R∗ and the
neighborhood. The red curve is the union of γ (t∗) corresponding to all x∈∂M.
x x
Foranyx∈∂M,B˜(γ (t))decreasesalongthegeodesicγ (t)fromxtoB˜(γ (t∗))and
x x x x
B˜(γ x(t))=0whent≥t x∗. Sincet x∗≤R∗,B˜=0onM\M R∗.
5. NUMERICALRESULTS
Inthissection,wecomparetheperformancesofBD-LLEinthreeexampleswithdifferentboundary
detectionalgorithmsincludingα-shape[13,14],BAND[30],BORDER[29],BRIM[19],LEVER[7],
SPINVER [20], and the CPS algorithm [5](abbreviated by authors’ initials for brevity). Note that all
algorithms, except α-shape, require either the ε-radius ball scheme or the KNN scheme for nearest
neighborhood search. For α-shape, we apply the boundary function in MATLAB, which includes a
shrinkfactors∈[0,1]correspondingtoα. Detaileddescriptionsofallthealgorithmaresummarizedin
SectionDoftheSupplementaryMaterial, whereeachalgorithmispresentedalongwiththenotations
andsetupsusedinthiswork.
Weintroducethefollowingmethodtoevaluatetheperformanceofaboundarydetectionalgorithm.
Suppose we fix the scale parameter, ε or K, for an algorithm. Let ∂X denote the boundary points
detectedfromX. LetM representther-neighborhoodof∂M asdefinedinDefinition4.1. Wedefine
r
theF1scoreof∂X associatedwithrasfollows:
2 2|∂X ∩ι(M )|
F1(∂X,r)= = r
|∂X∩1
ι(Mr)|
+ |∂X∩1
ι(Mr)|
|∂X|+|X ∩ι(M r)|
|∂X| |X∩ι(Mr)|
Since ∂M is a measure 0 subset of M, based on Assumption 3.2, the probability for a sample in X
to lie on the boundary of ι(M) is 0. Therefore, our objective is to determine whether the detected
boundarypoints∂X coincidewiththepointswithinsomeregularneighborhoodoftheboundary,e.g.
ther-neighborhood. WeproposethemetricF1 ,definedasthemaximumF1scoreoverasequence
max
{r =0.05i}k ,i.e. F1 =max F1(∂X,r).
i i=1 max 1≤i≤k i14 PEI-CHENGKUOANDNANWU
TABLE 2. Summary of the nearest neighborhood search schemes and the scale pa-
rametersindifferentalgorithms.
Algorithms Nearestneighborhood Unitdisc Vertical-cuttorus Tilted-cuttorus
BD-LLE ε-radiusball ε =0.15 ε =1 ε =1.25
α-shape Shrinkfactor 1 0 0
BAND KNN K=50 K=50 K=50
BORDER KNN K=50 K=50 K=50
BRIM ε-radiusball ε =0.15 ε =1 ε =1.25
CPS ε-radiusball ε =0.15 ε =1 ε =0.8
LEVER KNN K=50 K=50 K=50
SPINVER KNN K=50 K=50 K=50
TABLE 3. Summary of F1
max
for all the algorithms. The largest F1
max
in each ex-
ampleishighlighted.
Algorithms Unitdisc Vertical-cuttorus Tilted-cuttorus
BD-LLE 0.8814 0.9344 0.8356
α-shape 0.7129 0.1511 0.2096
BAND 0.1289 0.3679 0.3491
BORDER 0.4754 0.4895 0.3833
BRIM 0.6969 0.1238 0.1073
CPS 0.8867 0.9022 0.8000
LEVER 0.4020 0.6679 0.5609
SPINVER 0.3705 0.5607 0.3313
Note that unlike other algorithms, the CPS algorithm detects the boundary points through directly
estimating the distance to the boundary function. In other words, for z ∈ X close to the bound-
k
ary, d (ι−1(z ),∂M) is estimated. By introducing an additional parameter r alongside the scale pa-
g k
rameter, the algorithm outputs ∂X(r) which estimates X ∩ι(M ). Therefore, for a given sequence
r
{r = 0.05i}k , we apply the CPS algorithm to output the corresponding ∂X(r), and we define
i i=1 i
F1 =max F1(∂X(r),r).
max 1≤i≤k i i
Next,wedescribetheconstructionofthepointcloudforeachexample.
5.1. Unitdisc. Weuniformlyrandomlysample{s}104 and{t }104 from[0,1]respectively. LetY =
i j=1 j j=1
{z˜ =(x ,y )}104 ⊂R2 where x =exp(
−s2
j ) and y =exp(
−t2
j ). X ⊂R2 consists of 4171 points
j j j j=1 j s2+1 j t2+1
j j
from Y such that if ∥z˜ ∥ ≤1, then z˜ ∈X. Thus, we generate 4171 non-uniform samples X =
j R2 j
{z}4171 on the unit disc. We apply BD-LLE in the ε-radius ball scheme to X with ε =0.15. We
i i=1
summarizethescaleparametersusedinotheralgorithmsinTable2,andF1 forallthealgorithmsin
max
Table3. WeplotX andthedetectedboundarypoints∂X foreachalgorithminFigure3.
5.2. Vertical-cuttorus. Weuniformlyrandomlysample{θ}5056and{φ }5056from[−π,π)and[−π,π)\
i i=1 j i=1
(−0.5,0.5)respectively. LetX ={z}5056⊂R3,where
i i=1
z =(3+1.2cos(θ)cos(φ),3+1.2cos(θ)sin(φ),1.2sin(θ)).
i i i i i i
Thus, we generate 5056 non-uniform samples X ={z}5056 on the vertical-cut torus. We apply BD-
i i=1
LLEinthe ε-radiusballscheme toX with ε =1. Wesummarizethescaleparameters usedinotherBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 15
(a) BD-LLE (b) α-shape (c) BAND (d) BORDER
(e) BRIM (f) CPS (g) LEVER (h) SPINVER
FIGURE 3. TheplotofX (greenandred)and∂X (red)fordifferentalgorithmsin
theunitdiscexample.
(a) BD-LLE (b) α-shape (c) BAND (d) BORDER
(e) BRIM (f) CPS (g) LEVER (h) SPINVER
FIGURE 4. TheplotofX (greenandred)and∂X (red)fordifferentalgorithmsin
thevertical-cuttorusexample.
algorithmsinTable2,andF1 forallthealgorithmsinTable3.WeplotX andthedetectedboundary
max
points∂X foreachalgorithminFigure4.
5.3. Tilted-cut torus. We uniformly randomly sample {θ }8000 and {φ }8000 from [−π,π) respec-
j j=1 j i=1
tively. Let(u ,v ,w )=(3+1.2cosθ cosφ ,3+1.2cosθ sinφ ,1.2sinθ )beapointonatorusinR3.
j j j j j j j j16 PEI-CHENGKUOANDNANWU
(a) BD-LLE (b) α-shape (c) BAND (d) BORDER
(e) BRIM (f) Calder (g) LEVER (h) SPINVER
FIGURE 5. TheplotofX (greenandred)and∂X (red)fordifferentalgorithmsin
thetilted-cuttorusexample.
Werotatethepoints{(x ,y ,z )}8000aroundthey-axisthroughthefollowingmap,
j j j j=1
3π 3π 3π 3π
(u ,v ,w )→(u′,v′,w′)=(cos( )u −sin( )w ,v ,sin( )u +cos( )w ).
j j j j j j 4 j 4 j j 4 j 4 j
X ⊂R3 consists of the points {(u′,v′,w′)} with w′ <2.8. Thus, we generate 7596 non-uniform
j j j j
samplesX ={z}7596onthetilted-cuttorus. WeapplyBD-LLEintheε-radiusballschemetoX with
i i=1
ε=1.25. WesummarizethescaleparametersusedinotheralgorithmsinTable2,andF1 forallthe
max
algorithmsinTable3. WeplotX andthedetectedboundarypoints∂X foreachalgorithminFigure
5.
In the above results, α-shape algorithm can successfully detects the boundary points when the di-
mension of M equals the dimension of the ambient space, regardless of the distributions of the data.
However, it fails to handle the scenario when the manifold M has a lower dimension. BAND, BOR-
DER, BRIM, LEVER, and SPINVER algorithms struggle to detect boundary points due to both the
non-uniformdistributionofthedataandtheextrinsiccurvatureofι(M). Incontrast,BD-LLEsuccess-
fully identifies the boundary points in all examples and exhibits the best performance in vertical-cut
torus and tilted-cut torus examples, regardless of the extrinsic geometry of the manifold and data dis-
tributions. ForamoredetaileddiscussionofalgorithmsotherthanBD-LLE,refertoSectionDofthe
SupplementaryMaterial.
6. DISCUSSION
Inthiswork,wedelveintothechallengeofidentifyingboundarypointsfromsamplesonanembed-
dedcompactmanifoldwithboundary. WeintroducetheBD-LLEalgorithm,whichutilizesbarycentric
coordinateswithintheframeworkofLLE.Thisalgorithmcanbeimplementedusingeitheranε-radius
ball scheme or a KNN scheme. Barycentric coordinates are closely related to the local covarianceBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 17
matrix. Weconductbiasandvarianceanalysesandexplorethespectralpropertiesofthelocalcovari-
ancematrixunderbothnearestneighborsearchschemestoaidinparameterselectionandanalyzethe
BD-LLEalgorithm. Wehighlightseveraldirectionsforfutureresearch.
Asdiscussedpreviously,theLLEcanbeconsideredasakernel-baseddimensionreductionmethod
with(2.11)representinganasymmetrickernelfunctionadaptivetothedatadistributionandthegeom-
etry of the underlying manifold. The previous studies [26, 28] analyze the LLE within the ε-radius
ballscheme. AfuturedirectioninvolvesapplyingourdevelopedtoolstoanalyzeLLEwithintheKNN
scheme. WeexpectestablishingevenmorechallengingresultsofthespectralconvergenceoftheLLE
intheKKNschemeonmanifoldswithorwithoutboundary.
Anotherpotentialdirectionofresearchconcernstheboundarypointsaugmentation. Giventhatthe
boundaryisalowerdimensionalsubsetofthemanifold,thelimitednumberofboundarypointsmaynot
sufficeforaccuratelycapturingthegeometryoftheboundary. Notably,theboundarycomprisesdisjoint
unions of closed manifolds without boundary. Hence, one strategy involves applying spectral clus-
tering method to organize detected boundary points into groups corresponding to different connected
components. Closedmanifoldreconstructionmethods[12]canbefurtheremployedoneachgroupto
interpolatemorepointsontheboundary.
ACKNOWLEDGMENT
TheauthorsthankDr. Hau-TiengWuforvaluablediscussionsandinsightfulsuggestions.
APPENDIXA. PROOFOFTHEOREM4.2
A.1. Preliminarydefinitions. UnderAssumptions3.1and3.2,letXbetherandomvariableassociated
with the probability density function P on M. Then, for any function f on M and any function F on
ι(M),wehave
(cid:90) (cid:90)
E[f(X)]:= f(x)dP= f(x)P(x)dV(x),
M M
(cid:90) (cid:90)
E[F(ι(X))f(X)]:= F(ι(x))f(x)dP= F(ι(x))f(x)P(x)dV(x)∈Rp.
M M
Basedontheabovedefinitions,theexpectationofthelocalcovariancematrixatι(x)isdefinedas
C x:=E[(ι(X)−ι(x))(ι(X)−ι(x))⊤χ(cid:0)
BR εp
(ι(x))∩ι(M)(cid:1)(ι(X))]∈Rp×p.
Suppose rank(C )=r≤ p. Clearly r depends on x, but we ignore x for the simplicity. Denote the
x
eigen-decompositionofC asC =U Λ U⊤,whereU ∈O(p)iscomposedofeigenvectorsandΛ isa
x x x x x x x
diagonalmatrixwiththeassociatedeigenvaluesλ ≥λ ≥···≥λ >λ =···=λ =0.
1 2 r r+1 p
ThroughtheeigenpairsofC ,wecanconstructanaugmentedvectorT(x)atx∈M.
x
DefinitionA.1. Theaugmentedvectoratx∈Mis
T(x)⊤=E[(ι(X)−ι(x))χ(cid:0)
BR εp
(ι(x))∩ι(M)(cid:1)(ι(X))]⊤U xI p,r(Λ x+εd+3I p×p)−1U x⊤∈Rp,
whichisaRp-valuedvectorfieldonM.
A.2. Lemmasforthevarianceanalysis. Form(3.1),wehave
B =
T⊤ n,xkG n,k111
Nk
=
nε1 dT⊤ n,xkG n,k111
Nk.
k N k nε1 dN k
We will study the terms 1 N and 1 T⊤ G 111 seperately in the next two lemmas. We first
nεd k nεd n,xk n,k Nk
introducethefollowingdefinitions.18 PEI-CHENGKUOANDNANWU
Definition A.2. Denote BRp to be a closed ball in Rp without specifying the center. We define the
followingcollectionsofballsintersectingι(M),
(cid:110) (cid:12) (cid:111)
(A.1) B (ι(M))= BRp ∩ι(M)(cid:12)BRp ∩ι(M)̸=0/,radiusofBRp ≤r .
r (cid:12)
IfA∈B (ι(M)),thenN(A)=|A∩X|.
r
By Definition 4.3, for any x∈M, N (x)=|BRp (ι(x))∩X|. Now, we are ready to provide the
a a
varianceanalysiswhichrelates nε1 dN ε(x)to ε1 dE[χ(cid:0)
BR εp
(ι(x))∩ι(M)(cid:1)(ι(X))]foranyx∈M.
LemmaA.1.
(1) Supposesup
A∈B
2r(ι(M))E[χ A(ι(X))]≤b≤ 41.Fornlargeenough,withprobabilitygreaterthan
1−n−2,
(cid:114)
N(A) blog(n)
sup | −E[χ (ι(X))]|=O( ).
A
n n
A∈B r(ι(M))
√
log(n)
(2) Supposeε=ε(n)sothat →0andε→0asn→∞. Wehavewithprobabilitygreater
n1/2εd/2+1
than1−n−2thatforallx∈M,
(cid:12) (cid:12) (cid:112)
(cid:12) (cid:12) (cid:12)N nε ε( dx) − ε1 dE[χ(cid:0) BR εp (ι(x))∩ι(M)(cid:1)(ι(X))](cid:12) (cid:12) (cid:12)=O(cid:16) n1/lo 2εg d(n /2)(cid:17) ,
√
(cid:16) (cid:17)
where the constant in O log(n) depends on theC0 norm of P and the second fundamental
n1/2εd/2
formofι(M).
The proof of (1) in the above lemma is a direct consequence of Lemma A.3 in [27]. As shown
in Remark A.1 in [27], the proof of Lemma A.3 in [27] does not rely on the underlying manifold
structure. Hence, it still holds when M is a manifold with boundary. The proof of (2) in Lemma A.1
isaconsequenceof(1)andisthesameastheproofofCorollary2.2in[27]. Themanifoldstructureis
involvedintheestimationofsup A∈B 2ε(ι√(M))E[χ A(ι(X))]whichisoforderεd. √
NotethatN =N (x )−1. When log(n) →0andnislargeenough, 1 < log(n) . Hence, the
k ε k n1/2εd/2+1 nεd n1/2εd/2
followinglemmaisaconsequenceof(2)inLemmaA.1.
√
log(n)
LemmaA.2. Supposeε =ε(n)sothat →0andε →0asn→∞. Wehavewithprobability
n1/2εd/2+1
greaterthan1−n−2thatfork=1,···,n,
(cid:12) (cid:12) 1 Nk 1 (cid:12) (cid:12) (cid:16)(cid:112) log(n)(cid:17)
(cid:12)
(cid:12) (cid:12)nεd
j∑ =11− εdE[χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X))](cid:12)
(cid:12)
(cid:12)=O
n1/2εd/2
,
√
(cid:16) (cid:17)
where the constant in O log(n) depends on theC0 norm of P and the second fundamental form of
n1/2εd/2
ι(M).
In the next lemma, we show that ε1 dT(x k)⊤E(ι(X)−ι(x k))χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X)) is the limit of
1 T⊤ G 111 asn→∞andwecontrolthesizeoffluctuation. Thelemmacanbefoundas(F.50)in
nεd n,xk n,k Nk
[28].
√
LemmaA.3. Supposeε =ε(n)sothat log(n) →0andε →0asn→∞. Supposec=nεd+3 inthe
n1/2εd/2+1
constructionofT⊤ in(2.10). Wehavewithprobabilitygreaterthan1−n−2thatforallk=1,...,n,
n,xk
(cid:112)
1 1 (cid:16) log(n)(cid:17)
(A.2) nεdT⊤ n,xkG n,k111
Nk
= εdT(x k)⊤E(ι(X)−ι(x k))χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X))+O
n1/2εd/2
,BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 19
√
(cid:16) (cid:17)
wheretheconstantinO log(n) dependsonP ,theC1 normofPandthesecondfundamentalform
n1/2εd/2 m
ofι(M)atι(x ).
k
A.3. Lemmasforthebiasanalysis. RecallthenotationsintroducedinDefinition4.1,
x :=argmind (y,x), ε˜(x)=d (x ,x).
∂ g g ∂
y∈∂M
In this subsection, we study the terms ε1 dE[χ BR εp (ι(xk))(ι(X))] and E[(ι(X)−ι(x k))χ BR εp (ι(xk))(ι(X))].
ThefollowinglemmaisacombinationofCorollaryB.1andLemmaB.3in[28].
Lemma A.4. Under Assumptions 3.1, 3.2, and 4.1, when ε >0 is sufficiently small, the following
expansionshold.
(1) E[χ(cid:0)
BR εp
(ι(x))∩ι(M)(cid:1)(ι(X))]=P(x)σ 0(ε˜(x),ε)εd+O(εd+1), where σ
0
is defined in Definition
4.2andtheconstantinO(εd+1)dependsontheC1normofP.
(2) E[(ι(X)−ι(x))χ(cid:0)
BR εp
(ι(x))∩ι(M)(cid:1)(ι(X))]=P(x)σ 1,d(ε˜(x),ε)εd+1e d+O(εd+2). σ
1,d
isdefined
inDefinition4.2. O(εd+2)representsavectorinRp whoseentriesareoforderO(εd+2). The
constantsinO(εd+2)dependontheC1normofPandthesecondfundamentalformofι(M).
If we combine (2) in Lemma A.1 and (1) in Lemma A.4, we have the following strong uniform
consistencyofkerneldensityestimationthrough0−1kernelonamanifoldwithboundary.
√
log(n)
PropositionA.1. Supposeε=ε(n)sothat →0andε→0asn→∞.Wehavewithprobability
n1/2εd/2+1
greaterthan1−n−2thatforallx∈M,
(cid:12) (cid:12) (cid:112)
(cid:12)
(cid:12)
N ε(x) −P(x)(cid:12) (cid:12)=O(ε)+O(cid:16) log(n)(cid:17)
,
(cid:12)nεdσ 0(ε˜(x),ε) (cid:12) n1/2εd/2
whereσ isdefinedinDefinition4.2,theconstantO(ε)dependsontheC1 normofPandtheconstant
√0
(cid:16) (cid:17)
inO log(n) dependsontheC0normofPandthesecondfundamentalformofι(M).
n1/2εd/2
ByusingthefunctioninDefinition4.2,thebiasanalysisoftheaugmentedvectorissummarizedin
the following lemma. The lemma can be found as Proposition 3.1(or a combination of Corollary B.1
andLemmaD.1)in[28].
LemmaA.5. SupposeAssumptions3.1,3.2,and4.1hold. Ifx∈M ,then
ε
(cid:34)
σ (ε˜(x),ε)1 P(x) (cid:16) σ (ε˜(x),ε) (cid:17)
T(x)= 1,d e + σ (ε˜(x),ε)− 1,d σ (ε˜(x),ε) v (x)
σ (ε˜(x),ε)ε d 2 2 σ (ε˜(x),ε) 3 1
2,d 2,d
(cid:35)
(cid:16) σ (ε˜(x),ε) (cid:17) 1
+ σ (ε˜(x),ε)− 1,d σ (ε˜(x),ε) v (x) +O(1).
2,d σ (ε˜(x),ε) 3,d 2 ε
2,d
Wehavev (x),v (x)∈(ι T M)⊥. O(1)representsavectorinRp whoseentriesareoforderO(1). The
1 2 ∗ x
constantsinO(1)dependonP ,theC1normofPandthesecondfundamentalformofι(M)atι(x).
m
Ifx∈M\M ,then
ε
P(x)(cid:20) |Sd−1| (cid:21) 1
T(x)= v (x) +O(1),
3
2 d(d+2) ε
wherev (x)∈(ι T M)⊥.O(1)representsavectorinRpwhoseentriesareoforderO(1).Theconstants
3 ∗ x
inO(1)dependonP ,theC1normofP,andthesecondfundamentalformofι(M)atι(x).
m20 PEI-CHENGKUOANDNANWU
A.4. Combining the bias and the variance analyses to prove Theorem 4.2. For any x , since e
k d
belongstoι T M,wehavee⊤v (x )=0for j=1,2,3. Thus,by(2)inLemmaA.4andLemmaA.5,
∗ xk d j k
whenx ∈M ,
k ε
(σ (ε˜(x ),ε))2
(A.3) T(x k)⊤E(ι(X)−ι(x k))χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X))=P(x k) σ1 2,d ,d(ε˜(xk
k),ε)
εd+O(εd+1),
wheretheconstantinO(εd+1)dependsonP , theC1 normofPandthesecondfundamentalformof
m
ι(M)atι(x ). Whenx ∈M\M ,
k k ε
(A.4) T(x k)⊤E(ι(X)−ι(x k))χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X))=O(εd+1),
theconstantinO(εd+1)dependsonP ,theC1 normofPandthesecondfundamentalformofι(M)at
m
ι(x ).
k √
log(n)
Supposeε=ε(n)sothat →0andε→0asn→∞. By(A.3),(A.4),andLemmaA.3,with
n1/2εd/2+1
probabilitygreaterthan1−n−2thatforanyx ∈M ,
k ε
(cid:112)
1 1 (cid:16) log(n)(cid:17)
nεdT⊤ n,xkG n,k111
Nk
= εdT(x k)⊤E(ι(X)−ι(x k))χ(cid:0)
BR εp
(ι(xk))∩ι(M)(cid:1)(ι(X))+O
n1/2εd/2
(cid:112)
(σ (ε˜(x ),ε))2 (cid:16) log(n)(cid:17)
1,d k
=P(x ) +O(ε)+O ,
k σ 2,d(ε˜(x k),ε) n1/2εd/2
andanyx ∈M\M ,
k ε
(cid:112)
1 (cid:16) log(n)(cid:17)
T⊤ G 111 =O(ε)+O ,
nεd n,xk n,k Nk n1/2εd/2
√
(cid:16) (cid:17)
where the constants in O(ε) and O log(n) depend on P , theC1 norm of P and the second funda-
n1/2εd/2 m
mental form of ι(M) at ι(x ). Note that when x ∈M\M , we have ε˜(x )≥ε. By the definition of
k k ε k
σ (ε˜(x ),ε),
(σ1,d(ε˜(xk),ε))2
=0whenε˜(x )≥ε. Thus, wecancombinetheabovetwocasesandwe
1,d k σ2,d(ε˜(xk),ε) k
concludethatwithprobabilitygreaterthan1−n−2foranyx ,
k
(cid:112)
1 (σ (ε˜(x ),ε))2 (cid:16) log(n)(cid:17)
(A.5) T⊤ G 111 =P(x ) 1,d k +O(ε)+O .
nεd n,xk n,k Nk k σ 2,d(ε˜(x k),ε) n1/2εd/2
ByLemmaA.2and(1)inLemmaA.4,withprobabilitygreaterthan1−n−2foranyx ,
k
(cid:112)
1 (cid:16) log(n)(cid:17)
(A.6) N =P(x )σ (ε˜(x ),ε)+O(ε)+O ,
nεd k k 0 k n1/2εd/2
√
(cid:16) (cid:17)
wheretheconstantsinO(ε)andO log(n) dependontheC1 normofPandthesecondfundamental
n1/2εd/2
formofι(M).
By (3.1), B =
nε1 dT⊤ n,xkGn,k(xk)111Nk.
By (A.5) and (A.6) and taking a union bound, with probability
k nε1 dNk
greaterthan1−2n−2foranyx ,
k
√
P(x
)(σ1,d(ε˜(xk),ε))2 +O(ε)+O(cid:16) log(n)(cid:17)
B =
k σ2,d(ε˜(xk),ε) √n1/2εd/2
.
k (cid:16) (cid:17)
log(n)
P(x )σ (ε˜(x ),ε)+O(ε)+O
k 0 k n1/2εd/2BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 21
Notethatσ (ε˜(x ),ε)isboundedfrombelowandfromabovebyconstants. Hence,
0 k
(cid:112)
(σ (ε˜(x ),ε))2 (cid:16) log(n)(cid:17)
1,d k
(A.7) B = +O(ε)+O ,
k σ 0(ε˜(x k),ε)σ 2,d(ε˜(x k),ε) n1/2εd/2
√
(cid:16) (cid:17)
where the constants in O(ε) and O log(n) depend on P , theC1 norm of P and the second funda-
n1/2εd/2 m
mentalformofι(M).
The properties (1), (2), (3), (4) and (5) follow directly from Proposition 4.1 and the definitions of
ε˜(x),σ (ε˜(x),ε),σ (ε˜(x),ε),andσ (ε˜(x),ε). (6)followsfrom(1),(3),and(4).
0 1,d 2,d
APPENDIXB. PROOFSOFPROPOSITION4.2ANDPROPOSITION4.3
B.1. ProofofProposition4.3. WefirstprovethefollowinglemmaaboutV(t,r)andU(t,s).
LemmaB.1.
(1) Whenδ issmallenoughdependingond,V(t,r(1−δ))≤V(t,r)(1−Cδ)andV(t,r(1+δ))≥
V(t,r)(1+Cδ),whereC>0isaconstantdependingond.
(2) Foranyt,wehave( d )d1 sd1 ≤U(t,s)≤( 2d )d1 sd1
|Sd−1| |Sd−1|
Proof. (1) We proveV(t,r(1−δ))≥V(t,r)(1−Cδ), whileV(t,r(1+δ))≤V(t,r)(1+Cδ) can be
provedsimilarly. Withoutlossofgenerality,supposet<r(1−δ)<r. Thecaseswhenr(1−δ)<t<r
orr(1−δ)<r<t arestraightforward. BythedefinitionofV(t,r),
V(t,r)−V(t,r(1−δ))
=|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(cid:2) (r2−x2)d− 21 −(r2(1−δ)2−x2)d− 21(cid:3)
dx
2d d−1
0
=|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(r2−x2)d− 21(cid:2)
1−(r2(1−δ)2−x2
)d− 21(cid:3)
dx
2d d−1 r2−x2
0
=|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(r2−x2)d− 21(cid:2)
1−(1−2δr2−r2δ2
)d− 21(cid:3)
dx
2d d−1 r2−x2
0
=|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(r2−x2)d− 21(cid:2)
1−(1−
2δ−δ2
)d− 21(cid:3)
dx
2d d−1 1−x2/r2
0
≥|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(r2−x2)d− 21(cid:2) 1−(1−2δ+δ2)d− 21(cid:3)
dx
2d d−1
0
=|Sd−1| rd(1−(1−δ)d)+|Sd−2|(cid:90) t
(r2−x2)d− 21(cid:2) 1−(1−δ)d−1(cid:3)
dx
2d d−1
0
≥d δ|Sd−1| rd+d−1|Sd−2|(cid:90) t (r2−x2)d− 21
dx≥
d−1
δV(t,r).
2 2d 2 d−1 2
0
Notethatinthesecondlaststepweusethefactthat1−(1−δ)d≥dδ whenδ issmallenoughdepending
2
ond.
(2) Fix any s, r=U(t,s) is the radius of the region R with volume s bounded between the ball
t,r
of radius r centered at the origin in Rd and the hyperplane x =t. The radius of the region achieves
d
maximumwhent=0,i.e. s= |Sd−1|rd. HenceU(t,s)≤( 2d )d1 sd1 . Theradiusoftheregionachieves
2d |Sd−1|
minimumwhent≥( |Sdd −1|)d1 sd1 ,i.e. whenR
t,r
istheballofvolumeofs. HenceU(t,s)≥( |Sdd −1|)d1 sd1
□
ProveProposition4.3byapplyingLemmaB.122 PEI-CHENGKUOANDNANWU
Weestimatetheprobabilityoftheevents{R(x)≤R˜(x)(1−δ)}and{R(x)≥R˜(x)(1+δ)}. Based
onthedefinitionofR(x),theeventof{R(x)≤R˜(x)(1−δ)}issameastheeventthat{N (x)≥
R˜(x)(1−δ)
K+1}. Thus,wehave
(B.1)
Pr(cid:8) R(x)≤R˜(x)(1−δ)(cid:9) =Pr(cid:8)1
N (x)≥
K+1(cid:9)
.
n
R˜(x)(1−δ)
n
Similarly,wehave
(B.2)
Pr(cid:8) R(x)≥R˜(x)(1+δ)(cid:9) =Pr(cid:8)1
N (x)≤
K+1(cid:9)
.
n
R˜(x)(1+δ)
n
WestarttoevaluatePr(cid:8)1N
(x)≥
K+1(cid:9)
. By(2)inLemmaB.1,
n R˜(x)(1−δ) n
(B.3) R˜(x)=U(ε˜(x), PK (+ x)1 n)≤( |S2 d−d 1|)d1 (K P+ n1 )d1 :=C 1(K+
n
1 )d1 .
m
DefineR˜∗:=C 1(K+ n1)d1 .RecallthedefinitionsofBR rp andB r(ι(M))inDefinitionA.2.Observethatfor
anyr>0,nomatterwherethecenterofBRp is,ifBRp ∩ι(M)̸=0/,thenBRp ∩ι(M)⊂BRp (ι(x′))∩ι(M)
r r r 2r
forι(x′)∈BRp
∩ι(M). Hence,by(1)inLemmaA.4,
r
K+1
(B.4)
A∈B
4s R˜u ∗p (ι(M))E[χ A(ι(X))]≤ xs ′u ∈p ME[χ(cid:0)
BR 8R˜p
∗(ι(x′))∩ι(M)(cid:1)(ι(X))]≤C 2(
n
),
whereC dependsonC0normofPandP .
2 m
By (1) in Lemma A.1, Suppose K →0 as n→∞, then C (K+1)≤ 1. For n large enough, with
n 2 n 4
probabilitygreaterthan1−n−2,forallx,
1
(B.5) | nN R˜(x)(1−δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]|
R˜(x)(1−δ)
(cid:112)
N(A) (K+1)log(n)
≤ sup | −E[χ (ι(X))]|≤C ,
A 3
n n
A∈B 2R˜∗(ι(M))
whereC dependsonC0normofPandP .
3 m
Next,wederivetheconditiononδ suchthat 1N (x)≥ K+1 implies
n R˜(x)(1−δ) n
(cid:112)
1 (K+1)log(n)
(B.6) nN R˜(x)(1−δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]≥C
3 n
.
R˜(x)(1−δ)
Ifwesubtractbothsidesof 1 nN R˜(x)(1−δ)(x)≥ K+ n1 byE[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))],wehave
R˜(x)(1−δ)
1
(B.7) nN R˜(x)(1−δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]
R˜(x)(1−δ)
K+1
≥
n
−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]
R˜(x)(1−δ)
≥K+1 −P(x)V(ε˜(x),R˜(x)(1−δ))−C (cid:0) R˜(x)(1−δ)(cid:1)d+1
4
n
≥K+1 −P(x)V(ε˜(x),R˜(x))+CδP(x)V(ε˜(x),R˜(x))−C (cid:0) R˜(x)(1−δ)(cid:1)d+1
4
n
=CδK+1
−C
(cid:0) R˜(x)(1−δ)(cid:1)d+1
.
4
nBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 23
whereC >0 depends onC1 norm of P. Lemma A.4 is applied in the third last step, Lemma B.1 is
4
appliedinthesecondlaststep,andthedefinitionsofthefunctionV andthetermR˜(x)areappliedinthe
laststep. If
(cid:112)
(B.8)
CδK+1
−C
(cid:0) R˜(x)(1−δ)(cid:1)d+1
≥C
(K+1)log(n)
,
4 3
n n
thenwehave(B.6). Hence,
(cid:8)1 K+1(cid:9)
Pr N (x)≥
n
R˜(x)(1−δ)
n
(cid:40) (cid:112) (cid:41)
(cid:16)1 (cid:17) (K+1)log(n)
≤Pr nN R˜(x)(1−δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))] ≥C
3 n
R˜(x)(1−δ)
(cid:40) (cid:112) (cid:41)
(cid:12)1 (cid:12) (K+1)log(n)
≤Pr (cid:12) (cid:12)nN R˜(x)(1−δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))](cid:12) (cid:12)≥C
3 n
≤n−2.
R˜(x)(1−δ)
Inordertohave(B.8),itsufficestorequire
(B.9) C δK+1 ≥C (R˜∗)d+1≥C (cid:0) R˜(x)(1−δ)(cid:1)d+1 ,
4 4
2 n
and
(cid:112)
C K+1 (K+1)log(n)
(B.10) δ ≥C .
3
2 n n
(cid:113)
(B.9)isequivalenttoδ≥2C4Cd+1(K+1)d1 and(B.10)isequivalenttoδ≥2C3 log(n) .If log(n)( n )2/d→
C 1 n C K+1 K+1 K+1
(cid:113)
0asn→∞,thenwehave 2C4Cd+1(K+1)d1 ≥2C3 log(n) .Hence,itsufficestorequireδ≥2C4Cd+1(K+1)d1
C 1 n C K+1 C 1 n
whichisguaranteedbyδ ≥
4C4Cd+1(K)d1
. Therefore,wechooseδ =
4C4Cd+1(K)d1
. Atlast,notethat
C 1 n C 1 n
log(n)( n )2/d →0isequivalentto log(n)(n)2/d →0.
K+1 K+1 K K
Hence,weshowthatif K →0and log(n)(n)2/d →0asn→∞,thanwithprobabilitylessthann−2,
n K K
forallx,R(x)≤R˜(x)(1−δ),whereδ = 4C4Cd+1(K)d1 .
C 1 n
By(B.3), ifδ issmall, R˜(x)(1+δ)≤2R˜∗. By(1)inLemmaA.1, suppose K →0asn→∞, then
n
C (K+1)≤ 1. Hence,fornlargeenough,withprobabilitygreaterthan1−n−2,forallx,
2 n 4
1
(B.11) | nN R˜(x)(1+δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]|
R˜(x)(1+δ)
(cid:112)
N(A) (K+1)log(n)
≤ sup | −E[χ (ι(X))]|≤C ,
A 3
n n
A∈B 2R˜∗(ι(M))
whereC dependsonC0normofPandP .
3 m
Wederivetheconditiononδ suchthat 1N (x)≤ K+1 implies
n R˜(x)(1+δ) n
(cid:112)
1 (K+1)log(n)
(B.12) nN R˜(x)(1+δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]≤−C
3 n
.
R˜(x)(1+δ)24 PEI-CHENGKUOANDNANWU
Ifwesubtractbothsidesof 1 nN R˜(x)(1+δ)(x)≤ K+ n1 byE[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))],wehave
R˜(x)(1+δ)
1
(B.13) nN R˜(x)(1+δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]
R˜(x)(1+δ)
K+1
≤
n
−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))]
R˜(x)(1+δ)
≤K+1 −P(x)V(ε˜(x),R˜(x)(1+δ))+C (cid:0) R˜(x)(1+δ)(cid:1)d+1
4
n
≤K+1 −P(x)V(ε˜(x),R˜(x))−CδP(x)V(ε˜(x),R˜(x))+C (cid:0) R˜(x)(1+δ)(cid:1)d+1
4
n
=C
(cid:0) R˜(x)(1+δ)(cid:1)d+1 −CδK+1
.
4
n
whereC >0 depends onC1 norm of P. Lemma A.4 is applied in the third last step, Lemma B.1 is
4
appliedinthesecondlaststep,andthedefinitionsofthefunctionV andthetermR˜(x)areappliedinthe
laststep. If
(cid:112)
(B.14) C
(cid:0) R˜(x)(1+δ)(cid:1)d+1 −CδK+1
≤−C
(K+1)log(n)
,
4 3
n n
thenwehave(B.12). Hence,
(cid:8)1 K+1(cid:9)
Pr N (x)≤
n
R˜(x)(1+δ)
n
(cid:40) (cid:112) (cid:41)
(cid:16)1 (cid:17) (K+1)log(n)
≤Pr nN R˜(x)(1+δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))] ≤−C
3 n
R˜(x)(1+δ)
(cid:40) (cid:112) (cid:41)
(cid:12)1 (cid:12) (K+1)log(n)
≤Pr (cid:12) (cid:12)nN R˜(x)(1+δ)(x)−E[χ(cid:0)
BRp
(ι(x))∩ι(M)(cid:1)(ι(X))](cid:12) (cid:12)≥C
3 n
≤n−2.
R˜(x)(1+δ)
Inordertohave(B.14),itsufficestorequire
(B.15) C δK+1 ≥C (2R˜∗)d+1≥C (cid:0) R˜(x)(1+δ)(cid:1)d+1 ,
4 4
2 n
and
(cid:112)
C K+1 (K+1)log(n)
(B.16) δ ≥C .
3
2 n n
(cid:113)
Notethat(B.15)isequivalenttoδ ≥ 2d+2C4Cd+1(K+1)d1 and(B.16)isequivalenttoδ ≥ 2C3 log(n) .
C 1 n C K+1
(cid:113)
If log(n)( n )2/d →0asn→∞,thenwehave 2d+2C4Cd+1(K+1)d1 ≥ 2C3 log(n) . Hence,itsufficesto
K+1 K+1 C 1 n C K+1
require δ ≥
2d+2C4Cd+1(K+1)d1
which is guaranteed by δ ≥
2d+3C4Cd+1(K)d1
. Therefore, we choose
C 1 n C 1 n
δ = 2d+3C4Cd+1(K)d1 . Atlast,notethat log(n)( n )2/d →0isequivalentto log(n)(n)2/d →0.
C 1 n K+1 K+1 K K
Hence,weshowthatif K →0and log(n)(n)2/d →0asn→∞,thanwithprobabilitylessthann−2,
n K K
forallx,R(x)≥R˜(x)(1+δ),whereδ = 2d+3C4Cd+1(K)d1 .
C 1 n
Inconclusionif K →0and log(n)(n)2/d →0asn→∞,thanwithprobabilitygreaterthan1−2n−2,
n K K
forallx,R(x)=R˜(x)(1+O((K)d1 )),wheretheconstantinO((K)d1 )dependsond,C1 normofP,and
n n
P
mBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 25
When n is large enough, we have 1R˜(x)≤R(x)≤ 3R˜(x). Hence, by (2) in Lemma B.1 and the
2 2
definitionofR˜(x),
1 d 1 K 1 1 d(K+1) 1 3 2d(K+1) 1 2d 1 K 1
( )d( )d ≤ ( )d ≤R(x)≤ ( )d ≤3( )d( )d.
2 |Sd−1| P n 2 |Sd−1|P n 2 |Sd−1|P n |Sd−1| P n
M M m m
Hence,
1 ( d )d1 ( K )d1 ≤R∗≤3( 2d )d1 ( K )d1 .
2 |Sd−1| P n |Sd−1| P n
M m
B.2. Proof Proposition 4.2. (1) Consider x,x′ ∈M. Assume R(x′)≥R(x). Observe that B (x)⊂
R(x)
B R(x)+∥ι(x)−ι(x′)∥Rp(x′). Hence,B R(x)+∥ι(x)−ι(x′)∥Rp(x′)containsatleastK+1points. WehaveR(x′)≤
R(x)+∥ι(x)−ι(x′)∥Rp ,i.e. R(x′)−R(x)≤∥ι(x)−ι(x′)∥Rp. Similarly,whenR(x′)≤R(x),wehave
R(x)−R(x′)≤∥ι(x)−ι(x′)∥Rp. Hence, |R(x′)−R(x)|≤∥ι(x)−ι(x′)∥Rp. When d g(x,x′)→0, then
∥ι(x)−ι(x′)∥Rp →0and|R(x′)−R(x)|→0.
(2)Fromtheproofof(1),|R(γ x(t 1))−R(γ x(t 2))|≤∥ι(γ x(t 1))−ι(γ x(t 2))∥Rp.Sinceγ x(t)isunitspeed
andmimizingon[0,t ],wehave
2
(B.17) |R(γ x(t 1))−R(γ x(t 2))|≤∥ι(γ x(t 1))−ι(γ x(t 2))∥Rp ≤t 2−t 1.
Observethat
t
2 −
t
1 =
R(γ x(t 1))−t 1R(γx(t2) t2)− −tR 1(γx(t1))
R(γ (t )) R(γ (t )) R(γ (t ))R(γ (t ))/(t −t ).
x 2 x 1 x 1 x 2 2 1
IfR(γ (t ))≤R(γ (t )),then t2 > t1 . IfR(γ (t ))>R(γ (t )),wehave R(γx(t2))−R(γx(t1)) <1.
x 2 x 1 R(γx(t2)) R(γx(t1)) x 2 x 1 t2−t1
Hence,ift <R(γ (t )),then t1 < t2 . Theconclusionfollows.
1 x 1 R(γx(t1)) R(γx(t2))
APPENDIXC. PROOFSOFTHEOREM4.3ANDTHEOREM4.4
C.1. Proof of Theorem 4.3. First, we relateC constructed through the KNN scheme toC con-
n,k n,k
structedthroughtheε radiusballschemethroughR(x)definedinDefinition4.3. Observethatforeach
x ,C constructedthroughtheKNNschemeisequaltotheC constructedthroughtheR(x )-radius
k n,k √n,k k
log(n)
ballscheme. ByTheorem4.1, ifforanyk, R(x )→0and →0andasn→∞, thenwith
k n1/2R(xk)d/2+1
probabilitygreaterthan1−2n−2,forallk,
1 (cid:20) M(0)(x ,R(x )) 0(cid:21) (cid:20) M(11)(x ,R(x )) M(12)(x ,R(x ))(cid:21)
(C.1) C =P(x ) k k R(x )d+2+ k k k k R(x )d+3
n n,k k 0 0 k M(21)(x ,R(x )) 0 k
k k
(cid:112)
(cid:16) log(n) (cid:17)
+O(R(x )d+4)+O R(x )d/2+2 .
k n1/2 k
Whenε˜(x )≥R∗,
k
1 (cid:20) M(0)(x ,R(x )) 0(cid:21) (cid:16)(cid:112) log(n) (cid:17)
(C.2) C =P(x ) k k R(x )d+2+O(R(x )d+4)+O R(x )d/2+2 .
n n,k k 0 0 k k n1/2 k
Second, we bound R(x) by K. Using the same argument as in (C.3), by Proposition 4.3, suppose we
n
have K →0and log(n)(n)2/d →0asn→∞. ,forallx,withprobabilitygreaterthan1−2n−2,
n K K
1 d 1 K 1 2d 1 K 1
( )d( )d ≤R(x)≤3( )d( )d.
2 |Sd−1| P n |Sd−1| P n
M m26 PEI-CHENGKUOANDNANWU
√
Hence, K →0isequivalenttoR(x )→0and log(n)(n)2/d→0isequivalentto log(n) →0. Ifwe
n k K K n1/2R(xk)d/2+1
substitute the above bounds of R(x) into (C.1) and (C.2), then with probability greater than 1−4n−2,
wehave
1 (cid:20) M(0)(x ,R(x )) 0(cid:21) (cid:20) M˜(11)(x ,K) M˜(12)(x ,K)(cid:21)
C =P(x ) k k R(x )d+2+ k n k n
n n,k k 0 0 k M˜(21)(x ,K) 0
k n
(cid:112)
K d+4 (cid:16) Klog(n) K 2(cid:17)
+O(( ) d )+O ( )d .
n n n
ThemagnitudesoftheentriesinM˜(11)(x k,K n),M˜(12)(x k,K n),andM˜(21)(x k,K n)areboundedbyC˜(K n)d+ d3 ,
whereC˜isconstantdependingond,P ,theC1normofP,thesecondfundamentalformofι(M)inRp
m
atι(x ),andthesecondfundamentalformof∂MinMatx .
k ∂,k
Whenε˜(x )≥R∗,
k
1 nC n,k=P(x k)(cid:20) M(0)(x k 0,R(x k)) 00(cid:21) R(x k)d+2+O((K n)d+ d4 )+O(cid:16)(cid:112) Kl nog(n) (K n)d2(cid:17) .
Atlast,wediscusstheentriesinM˜(0)(x)=P(x)M(0)(x,R(x))R(x)d+2forx∈M.M˜(0)(x)isadiagonal
matrix. ByTheorem4.1andProposition4.3,theithdiagonalentryofM˜(0)(x)is
K
P(x)σ 2(ε˜(x),R(x))R(x)d+2=P(x)σ 2(ε˜(x),R(x))(R˜(x)(1+O(( )d1 )))d+2,
n
fori=1,···,d−1. Andthedthdiagonalentryis
K
P(x)σ 2,d(ε˜(x),R(x))R(x)d+2=P(x)σ 2,d(ε˜(x),R(x))(R˜(x)(1+O(( n)d1 )))d+2.
By(B.3),wecanderivethefollowingequalities,
P(x)σ 2(ε˜(x),R(x))R(x)d+2=P(x)σ 2(ε˜(x),R(x))R˜(x)d+2+O((K )d+ d3 ).
n
P(x)σ 2,d(ε˜(x),R(x))R(x)d+2=P(x)σ 2,d(ε˜(x),R(x))R˜(x)d+2+O((K n)d+ d3 ).
Defineµ (x)=P(x)σ (ε˜(x),R(x))R˜(x)d+2andµ (x)=P(x)σ (ε˜(x),R(x))R˜(x)d+2.
1 2 2 2,d
Both µ (x) and µ (x) are continuous functions. We focus on µ (x), while µ (x) can be discussed
1 2 1 2
similarly. Notethat |Sd−1| ≤σ (ε˜(x),R(x))≤ |Sd−1| . By(2)inLemmaB.1andthedefinitionofR˜(x),
2d(d+2) 2 d(d+2)
( d )d+ d2 (K+1)d+ d2 ≤R˜(x)d+2≤( 2d )d+ d2 (K+1)d+ d2 . Hence,
|Sd−1| P(x)n |Sd−1| P(x)n
1 d 2 K+1 d+2 2 2d 2 K+1 d+2
2(d+2)(
|Sd−1|P
)d(
n
) d ≤µ 1(x)≤ d+2(
|Sd−1|P
)d(
n
) d .
M m
Whenx∈∂M,σ 2(ε˜(x),R(x))= 2d|S (d d− +1 2|
)
andR˜(x)d+2=( |S2 d−d 1|)d+ d2 ( PK (+ x)1 n)d+ d2 . Therefore,
1 2d 2 K+1 d+2
µ 1(x)= (d+2)( |Sd−1|P(x))d(
n
) d .
Thesameresultsholdforµ (x).
2
Whenε˜(x )≥R∗,
k
|Sd−1|
σ (ε˜(x ),R(x ))=σ (ε˜(x ),R(x ))= .
2 k k 2,d k k
d(d+2)
Moreover,by(2)inLemmaB.1,R˜(x k)=( |Sdd −1|)d1 ( PK (x+ k)1 n)d1 . Therefore,
1 d 2 K+1 d+2
µ 1(x k)=µ 2(x k)= (d+2)(
|Sd−1|P(x
))d(
n
) d .
kBOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 27
C.2. Proof of Theorem 4.4. By Proposition 4.3, suppose K →0 and log(n)(n)2/d →0 as n→∞.
n K K
Then,forallx,withprobabilitygreaterthan1−2n−2,wehave 1R˜(x)≤R(x)≤ 3R˜(x). Hence,by(2)
2 2
inLemmaB.1andthedefinitionofR˜(x),
1 d 1 K 1 2d 1 K 1
(C.3) ( )d( )d ≤R(x)≤3( )d( )d.
2 |Sd−1| P n |Sd−1| P n
M m
Observe that for each x , B constructed through the KNN scheme is equal to the B constructed
k k k
throughtheR(x )-radiusballscheme.BasedontheproofofLemmaA.3andA.5in[28],theconclusion
k
ofthelemmasstillholdwheneverwechooseC˜ nεd+3≤c≤C˜ nεd+3,whereC˜ andC˜ areconstants
1 2 1 2
independent of n and ε. Suppose we choose C˜ nR(x )d+3 ≤c≤C˜ nR(x )d+3 where C˜ and C˜ are
1 k 2 k √ 1 2
log(n)
constants independent of n and K. By (A.7), if for any k, R(x )→0 and →0 and as
k n1/2R(xk)d/2+1
n→∞,thenwithprobabilitygreaterthan1−2n−2,forallk,
(cid:112)
(σ (ε˜(x ),R(x )))2 (cid:16) log(n) (cid:17)
1,d k k
(C.4) B = +O(R(x ))+O .
k σ (ε˜(x ),R(x ))σ (ε˜(x ),R(x )) k n1/2R(x )d/2
0 k k 2,d k k k
where ε˜(x ) is the distance from x ∈M to ∂M as defined in (4.1). The constants in O(R(x )) and
√ k k k
(cid:16) (cid:17)
O log(n) dependonP ,theC1 normofPandthesecondfundamentalformofι(M). Moreover,
n1/2R(xk)d/2 m
ifε˜(x)isthedistancefromx∈Mto∂M,thenwedefine
(σ (ε˜(x),R(x)))2
B˜(x)= 1,d .
σ (ε˜(x),R(x))σ (ε˜(x),R(x))
0 2,d
√
By (C.3), K →0 is equivalent to R(x )→0 and log(n)(n)2/d →0 is equivalent to log(n) →0.
n k K K n1/2R(xk)d/2+1
Moreover,ifc=n(K)d+ d3
,then
n
( 32 )d+3(|S 2d− d1| )d+ d3 P md+ d3 nR(x k)d+3≤c≤2d+3(|Sd d−1| )d+ d3 P Md+ d3 nR(x k)d+3.
Bytakingtheunionboundfortheprobability, withprobabilitygreaterthan1−4n−2, forallk, we
have(C.3)forallx and(C.4). Ifwesubstitute(C.3)into(C.4),
k
(cid:114)
(σ 1,d(ε˜(x k),R(x k)))2 K
1
(cid:16) log(n)(cid:17)
B k=
σ (ε˜(x ),R(x ))σ (ε˜(x ),R(x
))+O(( n)d)+O
K
.
0 k k 2,d k k
(cid:16)(cid:113) (cid:17)
TheconstantsinO(K n)d1 andO log K(n) dependonP m,theC1 normofPandthesecondfundamental
formofι(M).
Next,wediscussthepropertiesofB˜(x). ByProposition4.2andthedefinitionsofσ ,σ ,andσ ,
0 1,d 2,d
B˜(x)isacontinuousfunctiononM. Whenx∈∂M,ε˜(x)=0andwehaveB˜(x)= 4d2(d+2)|Sd−2|2 .
(d2−1)2|Sd−1|2
Supposethatwehavet >R(γ (t ))andt <t <R∗. Sinceγ (t)ismimizingon[0,2R∗],by(B.17),
1 x 1 1 2 x
R(γ (t ))<R(γ (t ))+t −t <t . SinceR(x)iscontinuous,R(γ (0))>0,andR(γ (R∗))≤0,bythe
x 2 x 1 2 1 2 x x
intermediatevaluetheoremandtheabovediscussion,thereisa0<t∗≤R∗suchthat
x
(1) R(γ (t∗))=t∗,
x x x
(2) R(γ (t))>t,fort<t∗,
x x
(3) R(γ (t))<t,fort>t∗.
x x
Fixx∈∂M,d (γ (t),∂M)=t for0≤t≤2R∗. Then,
g x
(σ (t,R(γ (t))))2
B˜(γ (t))= 1,d x .
x
σ (t,R(γ (t)))σ (t,R(γ (t)))
0 x 2,d x28 PEI-CHENGKUOANDNANWU
Based on the definitions of σ , σ , and σ , B˜(γ (t))=0 for t ≥t∗. Suppose t <t <t∗, then
0 1,d 2,d x x 1 2 x
t <R(γ (t )). Hence, by Proposition 4.2, we have t1 < t2 . Since B˜(γ (t)) is a decreasing
1 x 1 R(γx(t1)) R(γx(t2)) x
functionof t basedonthedefinitions,theconclusionfollows.
R(γx(t))
APPENDIXD. REVIEWOFTHEBOUNDARYDETECTIONALGORITHMS
Let(M,g)bead-dimensionalcompact,smoothRiemannianmanifoldwithboundaryisometrically
embeddedinRp viaι :M(cid:44)→Rp. WeassumetheboundaryofM,denotedas∂M,issmooth. Suppose
{x ···,x }⊂M arei.i.d. samplesbasedonap.d.fPonM.GivenX ={z =ι(x)}n , thedetected
1 n i i i=1
boundarypointsfromX aredenotedas∂X. Inthissection,wereviewtheboundarydetectionalgo-
rithms that we apply in Section 5. Furthermore, in the original formulations of some algorithms, the
thresholdparametersarenotexplicitlyspecified. Wedescribeourchosenthresholdsforthealgorithm
implementationsinSection5.
D.1. α-shapealgorithm. Theα-shapealgorithm[13,14]iswidelyappliedalgorithminboundaryde-
tection. It works effectively when M has the same dimension p as the ambient space Rp. Intuitively,
sinceeachconnectedcomponentof∂ι(M)isahypersurfaceinRp, weapproximate∂ι(M)usinghy-
perspheres,wherepointsonthesehyperspherescanbeclassifiedas∂X. Thealgorithmissummarized
asfollows. First, thegeneralizedα ballinRp forα ∈Risdefinedinthefollowingway. Forα >0,
a generalized α ball is a closed p-ball of radius 1/α; for α <0, it is the closure of complement of a
p-ballofradius−1/α;ifα =0,itistheclosedhalfspace. Usingthegeneralizedα ball,wecandefine
theα-boundary. Ifthereisanα ballcontainingX andthereare ppointsofX ontheboundaryofthe
α ball, then these p points are called α-neighbours. The union of all α-neighbors is called α bound-
ary points, denoted as ∂X. However, identifying α-boundary points directly from the definition is
generallychallenging. Inpractice,therelationshipbetweenα-boundarypointsandtheDelaunaytrian-
gulationisutilized. RecallthattheDelaunaytriangulationofX isatriangulation,denotedasDT(X),
suchthatnopointinX isinthecircumhypersphereofany p-simplexinDT(X). Foreachk-simplex
T inDT(X),where0≤k≤ p,letσ betheradiusofcircumhypersphereofT. Theα-complexC is
T α
definedas{T ∈DT(X)|σ <1/|α|}. TheverticesontheboundaryofC constitutetheα-boundary.
T α
ForacomprehensivereviewoftheDelaunaytriangulationandα-complex,referto[23].
D.2. BORDERalgorithm. InBORDERalgorithm[29],letO ⊂X bethenearestneighborsofz ∈
k k
X intheKNNscheme. ThereverseK nearestneighborsofz isdefinedasR :={z ∈X|z ∈O}.
k k i k i
If |R | is smaller than a specified threshold, z is classified as a boundary point. Otherwise, it is an
k k
interior point. Note that distinguishing |R | between boundary and interior points can be challenging
k
whenthepointsinX arenotuniformlydistributedonanembeddedmanifoldwithinEuclideanspace.
Consequently,thealgorithm’sperformancemaybesensitivetothedatadistribution.
Supposeδ representsthevalueatthe5thpercentileof{|R|}n . InthesimulationsinSection5,we
i i=1
implementBORDERsuchthatz ∈∂X if|R |<δ.
k k
D.3. BRIM algorithm. In BRIM algorithm [19], let O ⊂X be the nearest neighbors of z ∈X
k k
in the ε-radius ball scheme, consisting of N points. For each z , the attractor of z is defined as
k k k
Att(z k)=argmax zi∈O kN i. For each z i ∈O k, define θ(z i)=∠ zi,zk,Att(zk) ∈[0,π]. Using the θ func-
tion, define PN(z ):={z ∈O |θ(z)≤π/2} and NN(z ):={z ∈O |θ(z)>π/2}. Finally, define
k i k i k i k i
BD(z k):= | |NP NN( (zzk k)) ||(cid:12) (cid:12)|PN(z k)|−|NN(z k)|(cid:12) (cid:12). Athresholdδ ischosensuchthatifBD(z k)>δ,thenz
k
∈∂X;
otherwise, itisaninteriorpoint. However, thedistinctioninBD(z )betweenaboundarypointandan
k
interiorpointissignificantonlyiftheattractorisselectedappropriately.Specifically,underthemanifold
assumption,foranyz ∈O (z ),N isofordernεd uptoaconstantdependingonthedensityofthedata.
i ε k i
Therefore,thealgorithm’saccuracydependsoncomparingquantitiesofthesameorderwithrespectto
ε andcouldbesensitivetothedatadistribution.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 29
Supposeδ representsthevalueatthe95thpercentileof{BD(z)}n . InthesimulationsinSection5,
i i=1
weimplementBRIMsuchthatz ∈∂X ifBD(z )>δ.
k k
D.4. BAND,LEVER,andSPINVERalgorithms. LetO ⊂X denotethenearestneighborsofz ∈
k k
X intheKNNscheme,consistingofN points.
k
In BAND [30], define D(z ) as the inverse of the average distance between z and the points in
k k
O k, given by D(z k)=( N1 k∑ zi∈O k∥z i−z k∥Rp)−1. This makes D(z k) function as a density estimator.
LetVD(z ) represent the variance of D(z) over the points z in z ∪O . Suppose the data points are
k i i k k
distributedaccordingtoadensityfunctionwithasmallderivative. Intuitively,neartheboundary,D(z )
k
shouldbesmallerthanintheinteriortoreflectthelackofsymmetryneartheboundary. Conversely,the
varianceVD(z )shouldbesmallintheinterior,indicatingaslowchangeindensity. Consequently,the
k
authorsproposethresholdsδ andδ′suchthatz ∈∂X ifD(z )<δ andVD(z )>δ′.
k k k
In SPINVER [20], let s(z k)=||∑ zi∈O k(z i−z k)|| 1, where ∥·∥ 1 denotes the L1 norm. Thus, s(z k)
quantifies the asymmetry of the neighborhood O with respect to z . Moreover, the authors propose
k k
u ds isin trg ibf u( tiz ok n) ,= we hx ep n( N z1 k∑ iszi n∈ eO ak r∥ tz hi e− bz ok u∥ n2 R dp a) rt yo ,m the ea dsu atr aet ph oe inlo tsca inld Oata sd he on us li dty bi en sO pk a. rsA es rs au nm din leg ssun syif mor mm ed tra it ca
.
k k
Therefore,thresholdsδ andδ′aresuggestedsuchthatz ∈∂X ifs(z )>δ and f(z )<δ′.
k k k
TheideaofLEVER[7]issimilartoSPINVER.LetH(z k)=||z k− N1 k∑ zi∈O kz i|| 1. Infact,H(z k)=
1 s(z ), where s(z ) is defined in the SPINVER. Hence, H(z ) assesses the asymmetry of O with
Nk k k k k
respecttoz k. DefineD(z k)=∑ zi∈O kexp(∥z i−z k∥Rp)toquantifythedatadensityinO k. Similarly,z k is
identifiedasaboundarypointifH(z )>δ andD(z )<δ′ forthresholdsδ andδ′. Alternatively,the
k k
authorssuggestselectingboundsδ <δ′suchthatz ∈∂X ifδ <H(z )D(z )<δ′.
k k k
Clearly,theBANDSPINVER,andLEVERaresensitivetothedatadistribution,andselectingappro-
priatethresholdsbecomesespeciallychallengingwhenthedatapointsarenon-uniformlydistributed.
Let δ denote the value at the 20th percentile of {D(z)}n , and δ′ denote the value at the 80th
i i=1
percentileof{VD(z)}n . InthesimulationsinSection5,BANDisimplementedsuchthatz ∈∂X if
i i=1 k
D(z )<δ andVD(z )>δ′. Similarly,letδ representthevalueatthe95thpercentileof{s(z)}n ,and
k k i i=1
δ′ representthevalueatthe5thpercentileof{f(z)}n . ForSPINVERinthesimulationsinSection
i i=1
5,z ∈∂X ifs(z )>δ and f(z )<δ′. Lastly,supposeδ indicatesthevalueatthe95thpercentileof
k k k
{H(z)}n ,andδ′ indicatesthevalueatthe5thpercentileof{D(z)}n . InthesimulationsinSection
i i=1 i i=1
5,LEVERisimplementedsuchthatz ∈∂X ifH(z )>δ andD(z )<δ′.
k k k
D.5. CPSalgorithm. WeintroducetheCPSalgorithm[5](abbreviatedbyauthors’initialsforbrevity).
Theauthorsproposedetectingtheboundarypointsbydirectlyestimatingthedistancetotheboundary
function:
d (ι(x),∂ι(M))= mind (ι(x),ι(y)).
g g
y∈∂M
AkeyobservationisthatifBRp
(ι(x))∩∂ι(M)̸=0/,then
ε
(cid:0) (cid:1)
d (ι(x),∂ι(M))= max d (ι(x),∂ι(M))−d (ι(y),∂ι(M)) ,
g g g
ι(y)∈BR εp (ι(x))∩ι(M)
where the maximum is attained when y∈∂M. Let γ(t) be the unit speed geodesic defined as in (3)
of Assumption 4.1, perpendicular to ∂M and passing through x at t =t =d (ι(x),∂ι(M)). Define
0 g
v(ι(x))=ι dγ(t0) to be the unit tangent vector at ι(x). Through a second order Taylor expansion of
∗ dt
d (ι(x),∂ι(M))−d (ι(y),∂ι(M))withrespecttoι(x)−ι(y),theauthorsapproximated (ι(x),∂ι(M))
g g g
as
(cid:0) (cid:1) 1(cid:0) (cid:1)
(D.1) max ι(x)−ι(y) · v(ι(x))+v(ι(y)) .
ι(y)∈BR εp (ι(x))∩ι(M) 230 PEI-CHENGKUOANDNANWU
With the above motivation, the steps of the CPS algorithm can be summarized as follows. Let
O ⊂X denotethenearestneighborsofz ∈X intheε-radiusballscheme. Supposethe ε-radiusball
k k 2
neighborhoodofz containsN˜ points. Foranyz ∈X closeto∂ι(M),v(z )canbeapproximatedby
k k k k
takingthemeanofz −z inO ,adjustedbya0−1kerneldensityestimation. Specifically,define
i k k
v˜(z ) |Sd−1| ε z −z
vˆ(z )= k , v˜(z )= ( )d ∑ i k .
k ∥v˜(z k)∥Rp k d 2
zi∈O
k
N˜
i
Then,vˆ(z )isanestimatorofv(z ). Let 1C bethelocalcovariancematrixassociatedwithO defined
k k n n,k k
in(2.7). LetT bethesubspacegeneratedbytheeigenvectorscorrespondingtothefirstd eigenvalues
k
of 1C . Thus,T approximatesthetangentspaceofι(M)atz . IfP istheprojectionoperatorfrom
n n,k k k k
RpontoT ,then(cid:0) z −z (cid:1) ·1(cid:0) v(z)+v(z )(cid:1) canbeapproximatedby
k i k 2 i k
(cid:32) (cid:33) (cid:32) (cid:33)
P (z −z (cid:1) · vˆ(z i)+vˆ(z k) =P (z −z (cid:1) · vˆ(z )+vˆ(z i)−vˆ(z k) .
k i k k i k k
2 2
However,whenz andz areawayfrom∂ι(M).Theestimationsvˆ(z)andvˆ(z )maynotbeaccurateand
i k i k
canevenformanangleclosetoπ. Therefore,theauthorssuggestaddingacutofffunctionto
vˆ(zi)−vˆ(zk)
.
2
Accordingto(D.1),theestimatorofd (z ,∂ι(M))isdefinedas
g k
(cid:32) (cid:33)
dˆ k=maxP k(z i−z k(cid:1) · vˆ(z k)+vˆ(z i)−vˆ(z k) χR+(cid:16) P k(vˆ(z i))·P k(vˆ(z k))(cid:17) ,
zi∈O
k
2
whereχR+ isthecharacteristicfunctionsupportedonR+. Byapplyingasmallthresholdr,z k∈∂X if
dˆ <r.
k
REFERENCES
[1] Eddie Aamari, Catherine Aaron, and Cle´ment Levrard. Minimax boundary estimation and estimation with boundary.
Bernoulli,29(4):3334–3368,2023.
[2] JavierA´lvarez-Vizoso,MichaelKirby,andChrisPeterson.Localeigenvaluedecompositionforembeddedriemannianman-
ifolds.LinearAlgebraanditsApplications,604:21–51,2020.
[3] TyrusBerryandTimothySauer.Densityestimationonmanifoldswithboundary.ComputationalStatistics&DataAnalysis,
107:1–17,2017.
[4] L.Bo,H.Zhang,andW.Chen.Boundaryconstrainedmanifoldunfolding.InMachineLearningandApplications,2008.
ICMLA’08.SeventhInternationalConferenceon,pages174–181.IEEE,2008.
[5] JeffCalder,SangminPark,andDejanSlepcˇev.Boundaryestimationfrompointclouds:Algorithms,guaranteesandappli-
cations.JournalofScientificComputing,92(2):56,2022.
[6] Jeff Calder and Nicolas Garcia Trillos. Improved spectral convergence rates for graph laplacians on ε-graphs and k-nn
graphs.AppliedandComputationalHarmonicAnalysis,60:123–175,2022.
[7] XiaofengCao,BaozhiQiu,XiangliLi,ZenglinShi,GuandongXu,andJianliangXu.Multidimensionalbalance-basedclus-
terboundarydetectionforhigh-dimensionaldata.IEEEtransactionsonneuralnetworksandlearningsystems,30(6):1867–
1880,2018.
[8] XiuyuanChengandHau-TiengWu.Convergenceofgraphlaplacianwithknnself-tunedkernels.InformationandInference:
AJournaloftheIMA,11(3):889–957,2022.
[9] HarishChintakuntaandHamidKrim.Distributedboundarytrackingusingalphaanddelaunay-cechshapes.arXivpreprint
arXiv:1302.3982,2013.
[10] AlejandroCholaquidis,RicardoFraiman,Ga´borLugosi,andBeatrizPateiro-Lo´pez.Setestimationfromreflectedbrownian
motion.JournaloftheRoyalStatisticalSociety:SeriesB(StatisticalMethodology),78(5):1057–1078,2016.
[11] SenDibakarandTSMruthyunjaya.Acomputationalgeometryapproachfordeterminationofboundaryofworkspacesof
planarmanipulatorswitharbitrarytopology.MechanismandMachinetheory,34(1):149–169,1999.
[12] David B Dunson and Nan Wu. Inferring manifolds from noisy data using Gaussian processes. arXiv preprint
arXiv:2110.07478,2021.
[13] H.Edelsbrunner,D.Kirkpatrick,andR.Seidel.Ontheshapeofasetofpointsintheplane.IEEETransactionsoninformation
theory,29(4):551–559,1983.
[14] H.EdelsbrunnerandE.P.Mu¨cke.Three-dimensionalalphashapes.ACMTransactionsonGraphics(TOG),13(1):43–72,
1994.BOUNDARYDETECTIONALGORITHMINSPIREDBYLOCALLYLINEAREMBEDDING 31
[15] ShixiaoWillingJiangandJohnHarlim.Ghostpointdiffusionmapsforsolvingellipticpdesonmanifoldswithclassical
boundaryconditions.CommunicationsonPureandAppliedMathematics,76(2):337–405,2023.
[16] D.N.KaslovskyandF.G.Meyer.Non-asymptoticanalysisoftangentspaceperturbation.InformationandInference: a
JournaloftheIMA,3(2):134–187,2014.
[17] A.V.Little,M.Maggioni,andL.Rosasco.MultiscalegeometricmethodsfordatasetsI:MultiscaleSVD,noiseandcurva-
ture.AppliedandComputationalHarmonicAnalysis,43(3):504–567,2017.
[18] JWilsonPeoplesandJohnHarlim.Spectralconvergenceofsymmetrizedgraphlaplacianonmanifoldswithboundary.arXiv
preprintarXiv:2110.06988,2021.
[19] B.Qiu,F.Yue,andJ.Shen.Brim:Anefficientboundarypointsdetectingalgorithm.AdvancesinKnowledgeDiscoveryand
DataMining,pages761–768,2007.
[20] BaozhiQiuandXiaofengCao.Clusteringboundarydetectionforhighdimensionalspacebasedonspaceinversionand
hopkinsstatistics.Knowledge-BasedSystems,98:216–225,2016.
[21] S.T.RoweisandL.K.Saul.Nonlineardimensionalityreductionbylocallylinearembedding.Science,290(5500):2323–
2326,2000.
[22] Amit Singer and H-T Wu. Vector diffusion maps and the connection Laplacian. Communications on Pure and Applied
Mathematics,65(8):1067–1144,2012.
[23] CsabaDToth,JosephO’Rourke,andJacobEGoodman.Handbookofdiscreteandcomputationalgeometry.CRCpress,
2017.
[24] H.Tyagi,E.Vural,andP.Frossard.TangentspaceestimationforsmoothembeddingsofRiemannianmanifolds.Information
andInference,2(1):69–114,2013.
[25] RyanVaughn,TyrusBerry,andHarbirAntil.Diffusionmapsforembeddedmanifoldswithboundarywithapplicationsto
pdes.AppliedandComputationalHarmonicAnalysis,68:101593,2024.
[26] H.-T.WuandNWu.Thinkglobally,fitlocallyundertheManifoldSetup:AsymptoticAnalysisofLocallyLinearEmbed-
ding.AnnalsofStatistics,46(6B):3805–3837,2018.
[27] Hau-TiengWuandNanWu.Stronguniformconsistencywithratesforkerneldensityestimatorswithgeneralkernelson
manifolds.InformationandInference:AJournaloftheIMA,11(2):781–799,2022.
[28] Hau-Tieng Wu and Nan Wu. When locally linear embedding hits boundary. Journal of Machine Learning Research,
24(69):1–80,2023.
[29] C.Xia, W.Hsu, M.-L.Lee, andB.C.Ooi.BORDER:efficientcomputationofboundarypoints.IEEETransactionson
KnowledgeandDataEngineering,18(3):289–303,2006.
[30] Li-XiangXueandBao-ZhiQiu.Boundarypointsdetectionalgorithmbasedoncoefficientofvariation.PatternRecognition
andArtificialIntelligence,22(5):799–802,2009.
DEPARTMENTOFMATHEMATICS,NATIONALTAIWANUNIVERSITY,TAIPEI,10617,TAIWAN
Emailaddress:r12221017@ntu.edu.tw
DEPARTMENT OF MATHEMATICAL SCIENCES, THE UNIVERSITY OF TEXAS AT DALLAS, RICHARDSON, TX 75080,
UNITEDSTATES
Emailaddress:nan.wu@utdallas.edu