BADGE: BADminton report Generation and Evaluation with LLM
Shang-HsuanChiang, Lin-WeiChao, Kuang-DaWang, Chih-ChuanWang, Wen-ChihPeng
DepartmentofComputerScience,NationalYangMingChiaoTungUniversity,Hsinchu,Taiwan
andy10801@gmail.com,william09172000@gmail.com,gdwang.cs10@nycu.edu.tw,
wangcc@nycu.edu.tw,wcpeng@cs.nycu.edu.tw
Abstract
Badminton enjoys widespread popularity, and re-
ports on matches generally include details such as
player names, game scores, and ball types, pro-
viding audiences with a comprehensive view of
the games. However, writing these reports can be
a time-consuming task. This challenge led us to
explore whether a Large Language Model (LLM)
could automate the generation and evaluation of
badminton reports. We introduce a novel frame-
worknamedBADGE,designedforthispurposeus-
ingLLM.Ourmethodconsistsoftwomainphases:
ReportGenerationandReportEvaluation.Initially,
badminton-related data is processed by the LLM, Figure 1: The example of the badminton report, where red is the
whichthengeneratesadetailedreportofthematch. playername,greenisthegamescore,andblueistheballtype.
We tested different Input Data Types, In-Context
Learning(ICL),andLLM,findingthatGPT-4per-
widely used and publicly available tool, capable of gener-
formsbestwhenusingCSVdatatypeandtheChain
ating coherent and contextually relevant text based on input
of Thought prompting. Following report gener-
prompts. In this paper, we explore its application in the do-
ation, the LLM evaluates and scores the reports
main of badminton game analysis, particularly focusing on
to assess their quality. Our comparisons between
the generation of comprehensive game reports, as shown in
the scores evaluated by GPT-4 and human judges
Figure1,usingdatasetsderivedfrombadmintonmatches.
showatendencytopreferGPT-4generatedreports.
Inthispaper,weseektoaddressseveralkeyresearchques-
Since the application of LLM in badminton re-
tions: HowdoestheperformanceofGPT-3.5compareacross
porting remains largely unexplored, our research
differentIn-ContextLearningmethodsinthecontextofbad-
serves as a foundational step for future advance-
minton game report generation? What are the strengths and
ments in this area. Moreover, our method can be
limitations of using structured (CSV files) versus unstruc-
extendedtoothersportsgames,therebyenhancing
tured (Question-Answer pairs) input data for prompting the
sportspromotion. Formoredetails,pleasereferto
model? Towhatextentcangeneratedreportscapturethenu-
https://github.com/AndyChiangSH/BADGE.
ances of badminton gameplay, player strategies, and match
outcomescomparedtomanuallycraftedreports?
1 Introduction
The primary objective of this study is twofold. Firstly, to
Badminton, as one of the most popular racket sports glob- investigatetheperformanceofdifferentIn-ContextLearning
ally,demandsanuancedunderstandingofgameplaydynam- methods and Input Data Types in enhancing the quality of
ics,playerstrategies,andmatchoutcomes. However,manual generated badminton game reports. Secondly, to quantify
analysis can be subjective and time-consuming. Therefore, badmintonreportsandcomparedifferentgenerationmethods
weaimtoautomatetheprocessofreportgeneration,thereby inordertoidentifytheoptimalapproach.
facilitatingfasterinsightsextractionandbroaderaccessibility By answering these questions, we aim to contribute valu-
to game analysis. In recent years, the advent of Large Lan- ableinsightsintothefeasibilityandeffectivenessofemploy-
guage Models (LLM) has revolutionized Natural Language ingLLMs,forautomatedgameanalysisintherealmofbad-
Processing(NLP)tasksacrossvariousdomains,rangingfrom minton, and provide insights into the shift of human pref-
text generation to language understanding [OpenAI, 2022]. erences on how reports are created, paving the way for en-
Among these cutting-edge models, GPT-3.5 stands out as a hancedreportgenerationandevaluation.
4202
nuJ
62
]LC.sc[
1v61181.6042:viXra2 RelatedWorks tionmechanisms[Zhangetal.,2022]infacilitatingefficient
and effective narrative construction. Leveraging the explo-
2.1 BadmintonDataset
ration of self-consistency mechanisms [Wang et al., 2023c],
ThecurrentstateofsportsreportgenerationusingLargeLan- ourmethodaimstoelicitcoherentnarrativesthatcapturethe
guage Models (LLMs) leverages the power of artificial in- essenceofbadmintongameplay.Wealsoconsiderthesignifi-
telligence to produce detailed, accurate, and engaging con- canceofdeliberateproblem-solvingstrategies,asproposedin
tent. Thesemodelsarecapableofanalyzingvastamountsof the”TreeofThoughts”framework[Yaoetal.,2023],toguide
real-time data, including scores, player statistics, and game thegenerationprocesstowardproducinginsightfulreports.
highlights,togeneratecomprehensivereportsandsummaries. Informed by a comprehensive review of the recent work
Theycancraftnarrativesthatcapturetheexcitementandnu- mentioned above, we synthesized insights from various
ancesofsportingevents,providinginsightsandcommentary methodologiesofprompting,includingZero-shot,One-shot,
akin to human sports journalists. The integration of LLMs Few-shot, Chain of Thought, Auto Chain of Thought, and
insportsjournalismrepresentsasignificantleapforward,en- TreeofThoughttocomeupwithsuitablepromptsforreport
hancingboththeefficiencyandrichnessofsportscoverage. generation, seeking to enhance the coherence and depth of
Taking in the above, we consider the following require- generatedbadmintongamereports,aligningwiththenuances
ments for our base dataset used to generate relevant input ofmatchdynamicsandplayerperformances.
prompts: (1) relating to the field of badminton, and (2) pro-
vidingawidespreadofinformationoutsideofthegameitself, 2.3 EvaluationwithLLM
such as tournament title, player names, location and so on,
Toevaluatethegeneratedreports,wesurveyedseveralevalu-
that are useful to generate comprehensive reports. Thus we
turntoShuttleSet[Wangetal.,2023b],introducedasametic- ationmethods. Saietal.’ssurvey[Saietal., 2020]provides
an overview of various evaluation metrics for Natural Lan-
ulouslycuratedstroke-levelsinglesdatasetdesignedforfacil-
guageGeneration(NLG)systems, offeringabroadperspec-
itating in-depth tactical analysis in badminton. This dataset,
tiveontheirapplicability, orlackthereof, withintherapidly
comprising human-annotated match data, provides a granu-
evolving field of NLG. Fu et al.’s work [Fu et al., 2023] in-
larperspectiveonplayerperformanceandstrategicdecision-
troduces GPTScore, a flexible method for evaluating NLG
makingduringsinglesmatches.Bycapturingstroke-levelde-
systems, tested on a multitude of different LLM structures
tailssuchasshottypes,placement,andrallydynamics,Shut-
and sizes, to emphasize its adaptability of diverse evalua-
tleSetenablesresearcherstodelveintotheintricaciesofbad-
tion criteria and domains. Wang et al.’s study [Wang et al.,
mintongameplayandextractactionableinsightsforplayers,
2023a]presentsapreliminaryexaminationofChatGPT’sef-
coaches,andanalysts.
fectiveness as an NLG evaluator, highlighting its strengths
TheShuttleSetdatasetencompassesadiverserangeofsin-
andweaknessesthroughempiricalanalysisoffiveNLGmeta-
gles matches, featuring players of varying skill levels and
evaluation datasets (including summarization, story genera-
playingstyles. Eachmatchinthedatasetismeticulouslyan-
tion and data-to-text tasks). Liu et al. proposed the G-Eval
notatedtocapturecrucialaspectsofgameplay,includingshot
framework [Liu et al., 2023], which encompasses chain-of-
trajectories, rally duration, and point outcomes. Moreover,
thought and weighting techniques for assessing the coher-
the dataset includes contextual information such as player
ence,consistency,andfluencyofnewssummaries.
names,matchsettings,andtournamentcontext,enrichingthe
Afterconsideringthesemethods,wefindG-Evalsufficient
analytical capabilities and applicability of the dataset in di-
andapplicable,ultimatelydecidingtoutilizetheirframework,
verseresearchsettings.
sinceempiricalevidenceshowresultsofitsevaluationbetter
Utilizing ShuttleSet, researchers have the opportunity to
aligning with human judgments. By systematically evaluat-
explore a multitude of research questions related to bad-
ingthegeneratedreportsagainsthuman-authoredreferences
minton tacticalanalysis, playerperformance evaluation, and
andbenchmarkingagainstestablishedevaluationcriteria,we
strategicdecision-making. Byleveragingthedetailedstroke-
aim to gain insights into the performance characteristics of
levelannotationsprovidedinthedataset,researcherscangain
our proposed generation method and identify areas for im-
valuableinsightsintoplayerstrategies, tacticalpatterns, and
provement.
match dynamics, ultimately enhancing our understanding of
thesportandinformingcoachingmethodologiesandtraining
regimens. 3 Methods
2.2 GenerationwithLLM 3.1 Overview
Our approach draws inspiration from In-Context Learning Figure 2 presents an overview of our proposed framework,
frameworks [Dong et al., 2022], emphasizing the role of BADGE. This framework separates the whole process into
contextual information and tailored prompts. Recognizing two distinct stages: (1) Report Generation and (2) Report
the importance of roles for In-Context Learning demonstra- Evaluation. Duringthefirststage, theinputconsistsofbad-
tions [Min et al., 2022], for their potential impact on en- minton data retrieved from ShuttleSet [Wang et al., 2023b].
hancing narrative coherence and content relevance. We ac- This data is then processed by the LLM to generate a bad-
knowledgetheadvancementsinpromptingengineering,such minton report. In the second stage, the LLM evaluates the
asZero-shot,One-shot,Few-shot[Brownetal.,2020],Chain report generated in the previous stage, resulting in a corre-
ofThought[Weietal., 2022]andautomaticpromptgenera- spondingevaluationscore.Q&A:
Q1: Which player won the game? How many
points did the winner get?
A1: An Se Young won the game with 22 points.
Figure2:Theoverviewofourproposedframework,BADGE Q2: Which player lost the game? How many
points did the loser get?
A2: Ratchanok Intanon lost the game with 20
points.
...
In-ContextLearning(ICL)
To facilitate In-Context Learning, we design four distinct
prompt types, drawing inspiration from existing literature
[Dong et al., 2022]: Zero-shot, One-shot, Few-shot [Brown
etal.,2020],andChainofThought(CoT)[Weietal.,2022].
Zero-shot prompts involve no illustrative examples during
inference. One-shot prompts provide a single example,
whileFew-shotpromptsofferalimitednumberofexamples
at inference time. Chain of Thought (CoT) is a technique
that empowers LLM to tackle complex reasoning tasks by
Figure3:TheflowchartofReportGeneration thinking them step by step. It essentially breaks down the
problemintosmaller,moremanageablechunksfortheLLM
to process. The prompts of In-Context Learning are shown
3.2 ReportGeneration below:
For report generation, we employ diverse Input Data Types,
methodsofIn-ContextLearning(ICL),andLargeLanguage Zero-shot:
Models (LLM). The flowchart of the Report Generation is You are a reporter for badminton games.
showninFigure3. ...
InputDataType
One-shot:
To compare the differences between structured and unstruc-
You are a reporter for badminton games.
tureddata,weutilizetwodistinctinputdatatypestorepresent
...
the badminton game: CSV and Q&A. CSV, an acronym for
I give you an example report as a reference:
”Comma-Separated Values,” denotes a straightforward and
Example:
widely adopted file format for storing tabular data, such as
...
spreadsheetsordatabases. InaCSVfile,eachlinerepresents
arowofdata,withthefeatureswithineachrowseparatedby
commas. This format represents the rally-level data of the Few-shot:
badmintongame. Ontheotherhand,Q&A,whichstandsfor You are a reporter for badminton games.
”Question and Answer,” involves designing eight questions ...
pertinent to a badminton set. A rule-based Python code is I give you some example reports as reference:
responsible for computing the answer to each question and Example 1:
then filling the answers into the predefined template. This ...
format represents the set-level data of the badminton game. Example 2:
Examples illustrating CSV and Q&A formats are provided ...
below:
CoT:
You are a reporter for badminton games.
CSV:
...
win point player, win reason, ball types,
Let’s think step by step:
lose reason, roundscore A, roundscore B
1. Read the CSV table carefully and understand
Ratchanok Intanon, opponent goes out of
this badminton game.
bounds, lob, goes out of bounds, 0, 1
2. ...
An Se Young, opponent hits the net, push, hits
the net, 1, 1
Ratchanok Intanon, wins by landing, smash, LargeLanguageModels(LLM)
opponent wins by landing, 1, 2 To compare the different LLMs for report generation, we
... utilize GPT-3.5 (GPT-3.5-turbo-0125) [OpenAI, 2022] and• Coherence (1-10): means being logical and clear in
thought or communication, where ideas fit together
smoothly to form a unified whole.
• Consistency (1-10): refers to the quality of being
steadfast, reliable, and uniform in behavior, perfor-
mance, or appearance over time.
• Excitement (1-10): is a feeling of enthusiasm or
thrill, often before or during an event or activity.
• Fluency (1-10): the quality of the summary in terms
of grammar, spelling, punctuation, word choice, and
sentence structure.
Subsequently, we will utilize the task introduction and
evaluation criteria to automatically generate the evaluation
steps by GPT-4. Examples of these evaluation steps are
providedbelow:
Figure4:TheflowchartofGPT-4Evaluation
Evaluation Steps:
1. Read for Structure and Organization: ...
GPT-4 (GPT-4-turbo-2024-04-09) [Achiam et al., 2023] to 2. Sentence-Level Analysis: ...
generatethebadmintonreports.BothGPT-3.5andGPT-4are 3. Overall Coherence Assessment: ...
accessedthroughtheOpenAIAPI.
Finally, we integrate the task introduction, evaluation cri-
3.3 ReportEvaluation
teria,evaluationsteps,badmintonreport,andevaluationform
Evaluating the quality of texts generated by Natural Lan- into the input prompt. GPT-4 will then assign a score on a
guage Generation (NLG) systems presents challenges in au- scale of 1 to 10, where 1 represents the lowest and 10 de-
tomatedmeasurement. Furthermore,conventionalreference- notes the highest, based on the specified evaluation criteria.
basedmetricslikeBLEU[Papinenietal.,2002]andROUGE Each evaluation criterion is assessed individually during the
[Lin, 2004] have demonstrated limited correlation with hu- evaluationprocess.
man judgments, particularly in tasks demanding creativity
HumanEvaluation
and diversity. Consequently, recent research advocates for
leveraging LLMs as reference-free metrics for NLG evalua- To compare the correlation between evaluations by GPT-4
tion[Wangetal.,2023a][Liuetal.,2023]. Inourstudy,we and humans, we conduct human evaluations on our bad-
introduce two evaluation methodologies: GPT-4 Evaluation minton reports. For the human evaluation, we prepared a
andHumanEvaluation. form containing three badminton reports authored by GPT-
3.5, GPT-4, and humans, respectively. Subsequently, evalu-
GPT-4Evaluation ators will assign scores to each badminton report based on
four evaluation criteria: coherence, consistency, excitement,
We follow the framework presented in the G-EVAL paper
[Liuetal.,2023],withthecorrespondingflowchartdepicted andfluency. Additionally,evaluatorswillattempttoidentify
theauthorofeachreport. Finally,wewillcalculatetheaver-
inFigure4. Initially,wedesignthepromptforthetaskintro-
agescoresassignedbytheevaluatorsandcomparethemwith
duction and establish the evaluation criteria. An example of
thescoresevaluatedbyGPT-4.
thetaskintroductionisasfollows:
4 Experiments
Task Introduction:
You are a reviewer of the badminton reports. 4.1 Dataset
I will give a badminton report, please follow the
We sample 10 badminton games spanning the years 2018
Evaluation Steps to score this badminton report
to 2021 from ShuttleSet [Wang et al., 2023b]. Among
based on the Evaluation Criteria.
these games, 5 pertain to men’s singles, while the remain-
...
ing 5 feature women’s singles matches. Each game com-
prises 2 or 3 sets, with each set containing 30 columns
Our evaluation framework encompasses four criteria: of features. However, for the sake of simplification, we
coherence, consistency, excitement, and fluency. Here are only extract the 6 most crucial columns, which include
thedefinitionsforeachoftheseevaluationcriteria: win point player,win reason,lose reason,ball types,round-
score A,androundscore B.DataType+ICL Coherence Consistency Excitement Fluency Avg. Writer Coherence Consistency Excitement Fluency Avg.
CSV+zero-shot 8.2 7.5 7.9 8.8 8.100 Human 7.5 8.9 6.8 8.5 7.925
CSV+one-shot 8.4 8.3 7.8 8.8 8.325
GPT-3.5 8.4 9.2 8.0 8.9 8.625
CSV+few-shot 8.3 9.0 7.7 8.7 8.425
CSV+CoT 8.4 9.2 8.0 8.9 8.625 GPT-4 8.6 9.4 8.2 9.1 8.825
Q&A+zero-shot 7.9 8.6 7.3 8.7 8.125
Q&A+one-shot 8.6 8.4 7.4 8.8 8.300 Table2: TheresultofGPT-4evaluationforreportswrittenbyhu-
Q&A+few-shot 8.3 8.5 7.5 8.6 8.225 mans,GPT-3.5,andGPT-4,wherebolddenotesthebestresultand
Q&A+CoT 7.9 8.7 7.4 8.5 8.125
italicsindicatestheworstresult.
Table 1: The result of GPT-4 evaluation for reports with different
input data types and ICL, where bold denotes the best result and
Writer Coherence Consistency Excitement Fluency Avg.
italicsindicatestheworstresult.
Human 7.6 7.5 6.9 7.8 7.450
GPT-3.5 6.5 7.3 5.2 6.4 6.350
GPT-4 8.3 8.2 8.0 8.4 8.225
Table3: Theresultofhumanevaluationforreportswrittenbyhu-
mans,GPT-3.5,andGPT-4,wherebolddenotesthebestresultand
italicsindicatestheworstresult.
Figure 5: The example of generated reports with CSV and Q&A
datatypes. Greenindicatesthecorrectscore,whileredindicatesan
incorrectscore. scores represent the average score for each evaluation crite-
rionacross10games. Theexperimentalresultsarepresented
inTable2.
4.2 ResultforInputDataType
We observe that reports generated by GPT-4 exhibit the
To compare the reports generated with different data types highestperformance,whereashuman-writtenreportsreceive
and ICL, we generate reports using two data types and four thelowestscoresacrossallfourevaluationcriteria.
ICL techniques with GPT-3.5. Subsequently, all reports are
evaluatedbyGPT-4,withthescoresrepresentingtheaverage
4.5 ResultforHumanEvaluation
scoreforeachevaluationcriterionacross10games. There-
sultsarepresentedinTable1.
TheexperimentalresultsarepresentedinTable3. Mosteval-
As observed, reports utilizing the CSV data type exhibit
uatorsratedthereportgeneratedbyGPT-4asthebest,while
slightly better performance in terms of consistency, excite-
preferring the human-written report over the one generated
ment, and fluency compared to those employing the Q&A
byGPT-3.5. ThisfindingcontradictstheevaluationbyGPT-
data type. However, it is notable that reports with the CSV
4, where GPT-3.5 outperformed humans. This bias aligns
datatypearemorepronetohallucinations. Forexample,re- withobservationsfromtheG-EVALpaper[Liuetal.,2023],
ferringtoFigure5,whilethegroundtruthscoreis21-19,the
whichcomparedtheGPT-4andhumanevaluationandfound
score in the report with the Q&A data type is correct. Con-
that G-EVAL prefers the output generated by LLMs. Addi-
versely,thescoreinthereportwiththeCSVdatatypeis21-
tionally, the Pearson product-moment correlation coefficient
21,whichisincorrect.
between the GPT-4 evaluation and human evaluation is cal-
culated to be 0.333, indicating a small positive correlation
4.3 ResultforIn-ContextLearning(ICL)
betweenthetwoevaluations.
InTable1,weobservedthatChainofThoughtdemonstrated Figure6isthepiechartillustratingthepercentageofcor-
the best overall performance with an approximately 0.2 im- rect guesses for each report. The accuracy rates are as fol-
provementoverthefew-shotontheCSVdatatype,followed lows: human reports 80%, GPT-3 80%, and GPT-4 70%.
by one-shot, and zero-shot, in descending order. Therefore, Theseresultsindicatethatevaluatorscanreadilydiscernthe
wespeculatethatChainofThoughtdividesthetaskintomul- author of the report in most cases, suggesting differences in
tiple smaller tasks, enabling the LLM to generate better re- the stylistic characteristics between reports authored by hu-
ports step by step. We also discovered that increasing the mans and those generated by LLMs. The examples of the
number of demonstrations improves the evaluation scores, reportscanbefoundintheAppendixA.
provingtheeffectivenessofdemonstrations. However,asim-
ilar pattern was not evident for the Q&A data type. Conse-
quently,wehypothesizethatthedatatypemayalsobeafactor
influencingtheperformanceofICL.
4.4 ResultforLargeLanguageModels(LLM)
To compare the quality of reports generated by GPT-3.5,
GPT-4, and human writers, we generate reports using GPT-
3.5 and GPT-4, and collect human-written reports from the
Internet. All reports are then evaluated by GPT-4, and the Figure6:Theaccuracyofguessingwhowrotethereport.5 Limitations&FutureWorks [Fuetal.,2023] Jinlan Fu, See-Kiong Ng, Zhengbao Jiang,
andPengfeiLiu. Gptscore: Evaluateasyoudesire,2023.
Therearesomelimitationsandfutureworkinourframework.
Firstly,badmintonreportgenerationisarelativelyunexplored [Lin,2004] Chin-YewLin. Rouge: Apackageforautomatic
topicintheresearchfield,leavinguswithoutotherbaselines evaluationofsummaries. InTextsummarizationbranches
forcomparison. Ourfutureworkcouldinvolveconstructing out,pages74–81,2004.
a benchmark (comprising dataset and evaluation metrics) to
inspireandfacilitatefurtherresearch. [Liuetal.,2023] YangLiu,DanIter,YichongXu,Shuohang
Secondly,wecurrentlylackaquantitativemethodtomea- Wang, Ruochen Xu, and Chenguang Zhu. G-eval: Nlg
sure the occurrence of hallucinations in the reports. In the evaluationusinggpt-4withbetterhumanalignment,2023.
future,employingaQ&Amodeltoextractanswersfromre-
[Minetal.,2022] Sewon Min, Xinxi Lyu, Ari Holtzman,
portsandcomparingthemwiththeanswersobtainedfroma
Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and
rule-based Python code could offer a means to calculate the
LukeZettlemoyer. Rethinkingtheroleofdemonstrations:
accuracyrate.
Whatmakesin-contextlearningwork?,2022.
Finally, the bias that GPT-4 prefers the reports generated
byLLMmayleadtounfairevaluation.Exploringsolutionsto [OpenAI,2022] OpenAI. Introducing chatgpt. https://
thisissuerepresentsapromisingdirectionforfutureresearch. openai.com/blog/chatgpt,2022.
6 Conclusion [Papinenietal.,2002] Kishore Papineni, Salim Roukos,
Todd Ward, and Wei-Jing Zhu. Bleu: a method for au-
In conclusion, our work marks a pioneering venture into tomaticevaluationofmachinetranslation. InProceedings
badminton report generation and evaluation. Our innovative ofthe40thannualmeetingoftheAssociationforCompu-
framework, BADGE, separates the process into two stages: tationalLinguistics,pages311–318,2002.
Report Generation and Report Evaluation. Initially, bad-
minton data sourced from ShuttleSet serves as input, pro- [Saietal.,2020] Ananya B. Sai, Akash Kumar Mohanku-
cessed by the LLM to generate the reports to describe the mar,andMiteshM.Khapra. Asurveyofevaluationmet-
badminton game. Subsequently, in the evaluation stage, the ricsusedfornlgsystems,2020.
LLMassessesthereports,yieldingcorrespondingscores.Our
[Wangetal.,2023a] Jiaan Wang, Yunlong Liang, Fandong
experiments encompass comparisons across different Input
Meng, Zengkui Sun, Haoxiang Shi, Zhixu Li, Jinan Xu,
DataTypes,In-ContextLearning(ICL),andLargeLanguage
JianfengQu, andJieZhou. Ischatgptagoodnlgevalua-
Models(LLMs). WefoundthatreportsgeneratedbyGPT-4
tor? apreliminarystudy,2023.
withCSVandChainofThoughtexhibitthebestperformance.
Moreover, we compared the scores evaluated by GPT-4 and [Wangetal.,2023b] Wei-Yao Wang, Yung-Chang Huang,
humans, revealing a bias where GPT-4 favors reports gener- Tsi-Ui Ik, and Wen-Chih Peng. Shuttleset: A human-
ated by LLMs. Despite existing limitations, our work sets annotated stroke-level singles dataset for badminton tac-
thestageforfutureadvancementsinbadmintonreportgener- tical analysis. In Proceedings of the 29th ACM SIGKDD
ationandevaluation,potentiallypavingthewayforresearch Conference on Knowledge Discovery and Data Mining,
andinnovationinthisfield. pages5126–5136,2023.
Acknowledgments [Wangetal.,2023c] Xuezhi Wang, Jason Wei, Dale Schu-
urmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha
This work was supported by the Ministry of Science and Chowdhery,andDennyZhou. Self-consistencyimproves
TechnologyofTaiwanunderGrants113-2425-H-A49-001. chainofthoughtreasoninginlanguagemodels,2023.
References [Weietal.,2022] Jason Wei, Xuezhi Wang, Dale Schuur-
mans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,
[Achiametal.,2023] Josh Achiam, Steven Adler, Sandhini
Denny Zhou, et al. Chain-of-thought prompting elicits
Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni
reasoning in large language models. Advances in neural
Aleman, Diogo Almeida, Janko Altenschmidt, Sam Alt-
informationprocessingsystems,35:24824–24837,2022.
man, Shyamal Anadkat, et al. Gpt-4 technical report.
arXivpreprintarXiv:2303.08774,2023. [Yaoetal.,2023] Shunyu Yao, Dian Yu, Jeffrey Zhao,
[Brownetal.,2020] TomBrown,BenjaminMann,NickRy- Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik
Narasimhan. Tree of thoughts: Deliberate problem solv-
der, Melanie Subbiah, Jared D Kaplan, Prafulla Dhari-
ing with large language models. In A. Oh, T. Neumann,
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,
A. Globerson, K. Saenko, M. Hardt, and S. Levine, edi-
Amanda Askell, et al. Language models are few-shot
learners. Advances in neural information processing sys-
tors,AdvancesinNeuralInformationProcessingSystems,
tems,33:1877–1901,2020. volume 36, pages 11809–11822. Curran Associates, Inc.,
2023.
[Dongetal.,2022] Qingxiu Dong, Lei Li, Damai Dai,
CeZheng,ZhiyongWu,BaobaoChang,XuSun,Jingjing [Zhangetal.,2022] Zhuosheng Zhang, Aston Zhang,
Xu, and Zhifang Sui. A survey on in-context learning. Mu Li, and Alex Smola. Automatic chain of thought
arXivpreprintarXiv:2301.00234,2022. promptinginlargelanguagemodels,2022.A Example 5-4andsecuredthegamebyforcingCHOUTienChenout
of bounds with a push shot.
A.1 ReportWrittenbyHuman
In the final set, It was CHOU Tien Chen who emerged
KentoMomotawasthetopseedbuthetookovertheworld victorious with a score of 21-16 against Kento MOMOTA.
#1spotfromViktorAxelseninlateSeptember. Hecamein CHOUTienChengained7pointsfromopponentsgoingout
with a 3-match winning streak over Chinese Taipei’s Chou of bounds, while MOMOTA lost 7 points due to going out
TienChenbuttheworld#4wontheirfirstmeetingin2018 of bounds. CHOU Tien Chen excelled with 2 points from
en route to winning the German Open. smash shots, while MOMOTA struggled with 3 points lost
Chou Tien Chen has been one of the busiest top ten from lobs. CHOU Tien Chen sealed the game by forcing
playersinthepastfewmonths,ifnotthepastyear. Hehas MOMOTA out of bounds with a lob shot.
played 7 tournaments (plus the Asian Games team event) Overall,itwasathrillingmatchbetweentwoskilledplay-
inthelast12weeksandinthelast8weeks,hehasreached ers, with MOMOTA showcasing his talent in the first two
5semi-finals, converting3ofthoseintoappearancesinthe sets, and CHOU Tien Chen making a strong comeback in
finals. the final set to claim the Denmark Open 2018 title.
Chou’s stamina issues were not helped by the end of the
first game. After the two players battled to 20-all, Kento A.3 ReportWrittenbyGPT-4
Momota(picturedright)hitanimpossiblygoodnettumble At the gripping Denmark Open 2018 finals, Kento Mo-
then was not faulted even though the reply clearly showed motaandChouTienChenbattledfiercelyacrossthreesets,
he’d reached over the net to kill a reply from Chou that showcasing the best of international badminton. Kento
was not going to even make it over the net. Momota beat Momota, demonstratingremarkableprecisionandstrategy,
Chouonthesamefrontforehandcorneronerallylaterand clinched a decisive victory against Chou Tien Chen, capti-
claimed the first game 22-20. vating badminton enthusiasts with an exhilarating perfor-
Chou bounced back to win the second game – despite mance.
being unable to convert on his first 4 game point opportu- The contest began intensely in the first set, where both
nities – but then Momota surged ahead late in the decider players exchanged close points. Momota emerged victori-
to cap off his victory. Momota thus claimed his 5th title ouswithanarrow22-20win. Notably,heobtained7points
of the year. As two of these were the World and the Asian through skilled plays that landed successfully into Chou’s
Championships, he has been accumulating slightly fewer court, hinting at his dominant net-play and court cover-
points on the BWF World Tour and is now the only world age capabilities. Chou also demonstrated skill but yielded
#1whodidnotalsofinishtheweekendontopoftheRace 7 points to Momota under the same condition, with his
to Guangzhou standings. returns just falling short. The critical juncture came when
All of the finalists will now head to Paris for the French Momota used a masterful return net to gain a slight edge
Open Super 750. Chou Tien Chen and Zheng/Huang have at 16:15, showing his calm under pressure. He sealed the
putthemselvesinthepositionsuchthattheyareassuredof set strategically with a net shot that decisively ended the
qualifying for the World Tour Finals as long as they merely game.
steponcourtfortheirfirstroundmatchesinParis,Fuzhou, Inthesecondset, Momotaincreasedhismomentum, se-
and Hong Kong. curing a 21-15 victory. Here, his ability to force errors be-
cameevident,asheearned8pointswhenChou’sresponses
A.2 ReportWrittenbyGPT-3.5
went out of bounds. Momota’s offensive was spearheaded
IntheDenmarkOpen2018Finals, KentoMOMOTAfaced by powerful smashes, recording 5 points, displaying his ag-
offagainstCHOUTienCheninanintensebadmintonshow- gressive yet precise playstyle. Again, he skillfully overtook
down. a close score of 5:4 using a lob, showcasing versatile skills
Inthefirstset,KentoMOMOTAemergedvictoriouswith to mesmerize the audience and outmaneuver Chou. He fi-
a score of 22-20 against CHOU Tien Chen. MOMOTA nalizedthesetvictorywithapushthatsenttheshuttleout
secured 7 points with wins by landing, while CHOU Tien of Chou’s reach, marking a defining moment in the match.
Chen struggled with 7 points lost due to opponent wins In a surprising turnaround during the third set, Chou
by landing. MOMOTA excelled with 2 points from rush Tien Chen revitalized his gameplay to claim a 21-16 set
shots, while CHOU Tien Chen faltered with 5 points lost win. Although he could not overturn the match result,
from return nets. MOMOTA displayed his determination he displayed resilience and skill, managing to secure points
by using a return net to overtake the lead at 16-15 and frequently when Momota’s shots went beyond the bounds.
ultimately ended the game with a net shot. Chou’s defense turned robust, particularly evident in how
Moving on to the second set, MOMOTA continued his heendedtheset,usingastrategiclobthatMomotapushed
winning streak with a score of 21-15 against CHOU Tien out, securing his only set win of the match.
Chen. MOMOTAcapitalizedon8pointsgainedfromoppo- Overall, the finals were a testament to both players’ ca-
nentsgoingoutofbounds,whileCHOUTienChensuffered pabilities and the intense competitiveness of professional
with 8 points lost from going out of bounds as well. MO- badminton. KentoMomota’stwo-setwindemonstratedhis
MOTA’s strong performance included 5 points from smash championship caliber through tactical superiority and un-
shots, while CHOU Tien Chen struggled with 4 points lost yielding determination, leaving the audience both thrilled
from lobs. MOMOTA used a lob to overtake the lead at and eager for future contests in the world of badminton.