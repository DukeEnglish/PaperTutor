Towards Compositionality in Concept Learning
AdamStein1 AadityaNaik1 YinjunWu2 MayurNaik1 EricWong1
Abstract color: white size: 3-5in ?
Concept-based interpretability methods offer a
lens into the internals of foundation models by
decomposing their embeddings into high-level
concepts. Theseconceptrepresentationsaremost
usefulwhentheyarecompositional,meaningthat
the individual concepts compose to explain the
fullsample. Weshowthatexistingunsupervised
color: white
conceptextractionmethodsfindconceptswhich
color: white size: 3-5in size: 3-5in
arenotcompositional. Toautomaticallydiscover
compositionalconceptrepresentations,weiden-
tifytwosalientpropertiesofsuchrepresentations,
andproposeCompositionalConceptExtraction
(CCE)forfindingconceptswhichobeytheseprop-
erties. WeevaluateCCEonfivedifferentdatasets
overimageandtextdata. Ourevaluationshows
thatCCEfindsmorecompositionalconceptrep-
Figure1.Weillustratetheissueofconceptcompositionalitywith
resentationsthan baselinesand yieldsbetterac-
respecttoconceptsextractedfromtheembeddingsoftheCLIP
curacy on four downstream classification tasks.
modelovertheCUBdataset. Specifically,wevisualizethecon-
1
ceptswhite birdsandsmall birdslearnedbyPCA(Zou
etal.,2023a)andCCEalongwiththeircompositions. Weshow
1.Introduction thetoptwoimagesthatbestrepresenteachconcept.Ideally,com-
posingthewhite birdsandsmall birdsconceptsshould
Foundation models continue to enable impressive perfor- resultinaconceptrepresentingsmallwhitebirds.Thisisnotthe
mance gains across a variety of domains, tasks, and data casewiththeconceptslearnedbyPCA.Ontheotherhand,the
conceptsextractedbyCCEarecomposable,asshownbytheim-
modalities(Srivastavaetal.,2023). However,theirblack-
agesofsmallwhitebirdsthatbestrepresenttheresultingconcept.
box nature severely limits the ability to debug, monitor,
control,andtrustthem(Turpinetal.,2024;Tamkinetal.,
model’sembeddingofadogimagemaydecomposeintothe
2023;Schaefferetal.,2024).
sumofconceptvectorsrepresentingitsfur,snout,andtail.
Concept-basedexplanations(Kimetal.,2018;Zhouetal.,
ExistingworksbasedonmethodssuchasPCA(Zouetal.,
2018) are a promising approach that seeks to explain
2023a) or KMeans (Ghorbani et al., 2019) extract such
a model’s behavior using individual concepts such as
concept vectors reasonably well for basic concepts. For
object attributes (e.g. striped) or linguistic sentiment
instance,Figure1showsimagesfromtheCUB(Wahetal.,
(e.g. happiness). Decomposing a model’s learned rep-
2011)datasetcontainingconceptsextractedbyPCAfrom
resentation can derive these concepts. For instance, a
theCLIP(Radfordetal.,2021)model. Thesetechniques
1DepartmentofComputerandInformationScience,University areabletocorrectlyextracttherepresentationsofconcepts
ofPennsylvania,Pennsylvania,USA2SchoolofComputerScience,
likewhite birdsandsmall birds,however,compos-
PekingUniversity,Beijing,China.Correspondenceto:AdamStein
ingthembyaddingtheirrepresentationsdoesnotyieldthe
<steinad@seas.upenn.edu>.
representationoftheconceptofsmall white birds.
Proceedings of the 41st International Conference on Machine
The compositionality of concepts is vital for several use
Learning,Vienna,Austria.PMLR235,2024.Copyright2024by
cases. First,modelpredictionscanbeexplainedbycombin-
theauthor(s).
1Code and data are available at https://github.com/ ingconcepts(Abidetal.,2022). Compositionalconcepts
adaminsky/compositional_concepts. alsoallowforeditingfine-grainedmodelbehavior,likeim-
1
4202
nuJ
62
]LC.sc[
1v43581.6042:viXra
ACP
ruO
stpecnoC
stpecnoCTowardsCompositionalityinConceptLearning
provingthetruthfulnessofanLLMwithoutcompromising conceptsthanbaselinesonvisionandlanguagedatasets,
other behaviors (Zou et al., 2023a). Models can also be andtheyimprovedownstreamperformance.
trainedtocomposebasicconceptsfornewtasks,e.g. using
conceptsforbeakshapes,wingcolors,andenvironmentsto
2.ConceptsandCompositionality
classifybirdspecies(Yuksekgonuletal.,2023).
ConceptRepresentations. Inmachinelearning,concepts
Inthispaper,westudytheunsupervisedextractionofcom-
are symbols that are assigned some human-interpretable
positionalconcepts. Existingworkdoesnotdirectlyeval-
meaning,oftenusedtoexplainpredictionsmadebymodels.
uatethecompositionalityofextractedconcepts,butrather
focusesontheindividualconceptrepresentations. Wethere- AconceptextractorE extractsconceptsfromtheinterme-
foreevaluatethecompositionalityofconceptsextractedby diate representation of some pretrained model M over a
existingunsupervisedapproaches. dataset D. E(M,D) thus yields a set of concept vectors
representingtheconceptsC ={c ,...,c }. Conceptvec-
Forthispurpose,wefirstvalidatethecompositionalityof 1 i
torsaredenotedasR(c),whereR:C→Rdistheconcept
ground-truthrepresentationsofconceptsincontrolledset-
representationfunction,Cisthesetofallpossibleconcepts,
tings. We observe that concepts can be grouped into at-
andRdisanembeddingspaceinsomedimensiond.Theset
tributes,whereeachattributeconsistsofconceptsoversome
ofextractedconceptsC canbegroupedintomutuallyexclu-
commonproperty,suchasthecolorofobjectsortheshape
siveattributesA ,...A eachcontainingconceptsabout
of objects. Concepts from different attributes (e.g. blue 1 k
somecommonpropertysuchthatC
=(cid:83)k
A .
and cube) can be composed, while those from the same i=1 i
attribute (e.g. red and green) cannot. We also observe To measure the presence (or degree of expression) of a
that the concepts from different attributes are roughly or- conceptinasample’sembedding,weborrowthefollowing
thogonal,whilethosefromthesameattributearenot. We definitionofconceptscorefrom(Yehetal.,2020).
proveinageneralizedsettingthatthesepropertiesarecru-
Definition2.1. (ConceptScore)Foraconceptc∈Cand
cial for the compositionality of concepts. Since existing
conceptrepresentationfunctionR:C→Rd,asampleem-
approachesdonotenforcetheseproperties,theyoftenex-
beddingz ∈Rd hasconceptscores(z,c)=S (z,R(c))
cos
tractnon-composableconceptrepresentations.
whereS isthecosinesimilarityfunction.
cos
Toextractcompositionalconceptsinanunsupervisedman-
ner,weproposeCompositionalConceptExtraction(CCE). Existingworkmakesuseofconceptscorestoquantifythe
Our key insight is to search for entire subspaces of con- presenceofconceptsonaper-samplebasis. Thishasuses
ceptsatonceinsteadofindividualconcepts,allowingCCE inseveralapplications,suchascreatingconceptbottleneck
toenforcetheaforementionedpropertiesofcompositional modelswhereasample’sembeddingisconvertedtoconcept
concepts. WeshowthatCCErecoverstherepresentation scores used for classification (Yuksekgonul et al., 2023),
ofknowncompositionalconceptsbetterthanexistingap- andsortingsamplesbyaconcept(Kimetal.,2018).
proaches,candiscovercompositionalconceptsinexisting
Compositionality. Followingworkoncompositionalrep-
image and text datasets, and the discovered concepts im-
resentations (Andreas, 2019) and pretrained embeddings
provedownstreamclassificationaccuracy.
(Trageretal.,2023),wedefinethecompositionalityofcon-
Wethussummarizethecontributionsofourpaper: ceptrepresentations.
Definition2.2. (CompositionalConceptRepresentations)
• Westudyconcept-basedexplanationsoffoundationmod-
For concepts c ,c ∈ C, the concept representation
elsfromthelensofcompositionality—apropertydesir- i j
R: C → Rdiscompositionalifforsomew ,w ∈R+,
able for many use-cases. We observe that concept rep- ci cj
resentationsextractedbystate-of-the-artmethodsfailto
R(c ∪c )=w R(c )+w R(c ).
compose,andsetouttoremedythisproblem.
i j ci i cj j
• We validate that models can in fact represent concepts In other words, the representation of the composition of
compositionally in embedding space. We identify two conceptscorrespondstotheweightedsumoftheindividual
salient properties of compositional concept representa- conceptvectorsintheembeddingspace.
tionsthatexistingmethodsfailtosatisfy.
Furthermore,conceptscoresfortheconceptssatisfyingDef-
• Weproveinageneralizedsettingthattheidentifiedprop-
inition2.2alsobehavecompositionally,sinceeachconcept
ertiesarenecessaryforcompositionality. Wepresenta
scorequantifiesthepresenceofthatconceptinasample.
novelmethodcalledCompositionalConceptExtraction
(CCE) that guarantees to yield concept representations Lemma 2.3. For compositional concepts c i,c j ∈ C, the
thatsatisfythesepropertiesbyconstruction. concept score of their composition c k = c i ∪ c j over a
• We demonstrate that CCE extracts more compositional sampleembeddingz ∈Rdisthecompositionoftheconcept
scoresofc andc ,weightedbyw ,w ∈R+:
i j ci cj
2TowardsCompositionalityinConceptLearning
s(z,c )=w s(z,c )+w s(z,c ). (sphere, cube, or cylinder) and one of three colors (red,
k ci i cj j
green, or blue). We also consider a subset of the CUB
Sinceconceptscoresareusedforseveraldownstreamtasks
datasetconsistingofbirdimageslabelledasoneofthree
discussedabove,thispropertyaboutthecompositionality
colorsandoneofthreesizes. Finally,weconsiderasubset
ofconceptscorescansimplifysuchtasksandimprovethe
oftheTruth(Zouetal.,2023b)datasetconsistingoffacts
overallperformanceonthem.
relatingtooneofthreetopicsandlabelledtrueorfalse.
Besides finding compositional concepts, we also want to
explainembeddingsbasedontheconceptswhichcompose 3.2.Ground-TruthConceptCompositionality
it. Priorworkalsoperformsadecompositionintoasumof
Weevaluatethecompositionalityofground-truthconcept
conceptrepresentations(Zhouetal.,2018),butwemodify
representations learned by the CLIP model over each la-
the definition of such a decomposition so that a sample
belleddataset. Sincetheserepresentationsarenotprovided,
embeddingiscomposedofonlytheconceptrepresentations
for each concept, we consider the mean of the model’s
thataretrulypresentforthesample.
embeddingsforsamplesbelongingtothatconceptasasur-
Definition2.4. (Concept-basedDecomposition)Considera rogateofitstruerepresentation(Zouetal.,2023a).
samplethatisassociatedwithasetofconceptsC ⊆C,such
Forexample,fortheCLEVRdataset,weextracttheground-
that each attribute A ⊆ C contains exactly one concept.
i
A concept representation R : C → Rd decomposes that truthrepresentationoftheredconceptbycalculatingthe
sample’sembeddingz ∈ Rd ifitcanbeexpressedasthe meanofallsampleembeddingsofimageswithredobjects.
i
We similarly extract the ground-truth representations for
weightedsumofthesample’sassociatedconcepts:
theothertwocolorconcepts,thethreeshapeconcepts,and
(cid:88)
z = λ R(c),suchthatλ >0. compositeconceptslike{red, sphere},foratotalof15
i i,c i,j
c∈C concepts. Werepeatthisprocessforeachdataset.
As an example, consider the CLEVR dataset (Johnson
AsstatedinLemma2.3,theconceptscoreforacomposite
et al., 2017) consisting of images of objects of differ-
oftwoconceptsistheweightedsumoftheconceptscores
ent shapes and colors. A concept extractor for a vi-
ofeachconcept. Thisimpliesthatalinearmodelshouldbe
sion model may extract the set of concepts C =
CLEVR abletopredicttheconceptscoreforacomposedconcept
{{red},{blue},{cube},{sphere}}. C can also
CLEVR giventheconceptscoresforeachofthebaseconcepts. We
be grouped into attributes A = {{red},{blue}} and
1 thustrainalinearmodeltopredictthepresenceorabsence
A = {{cube},{sphere}} containing color and shape
2 ofacomposedconceptgivenitsbaseconcepts. Wemeasure
conceptsrespectively. Assuch, acompositeconceptlike
theaverageprecisionofthemodelforeachcomposedcon-
{red, sphere}canberepresentedastheweightedsum
cept,andreportthemeanaverageprecision(MAP)score
ofR({red})andR({sphere}).
inTable2aforeachdataset. Weseethatinallcases, the
groundtruth(GT)conceptshavehighMAP(upto0.971for
3.EvaluatingConceptCompositionality CLEVR)whenpredictingconceptcompositionsfromtheir
components,meaningtheground-truthconceptrepresenta-
Inthissection,wevalidatethecompositionalityofground-
tionsarereasonablycompositional.
truthconceptrepresentationsandevaluatethesameforcon-
ceptsextractedusingexistingapproaches. Wefirstdiscuss
3.3.CompositionalityIssueswithExistingMethods
ourcontrolledsettingandshowthatconceptrepresentations
fromtheCLIPmodelarecompositional. Wethenevaluate Wenextstudythecompositionalityofconceptrepresenta-
thecompositionalityofconceptsextractedbyexistingap- tionsdiscoveredbyexistingunsupervisedconceptextrac-
proaches. Finally, we outline the necessary properties of tion methods. We train a linear model similar to the one
compositionalconceptrepresentations. described in Section 3.2, but with concepts extracted by
baseline methods instead of the ground truths. From the
3.1.Setup MAPresultsinTable2aweseethatallthebaselineshave
significantlylowercompositionalitythantheground-truth.
In order to validate the compositionality of ground-truth
concepts,wefocusonconceptsextractedfromsubsetsof Thisisthecaseevenfortechniquesthatextracttheconcepts
theCLEVR(Johnsonetal.,2017),CUB(Wahetal.,2011), reasonablywell,i.e.wheretheextractedconceptsareableto
andTruth(Azaria&Mitchell,2023)datasets,allofwhich discriminatebetweenpositiveandnegativesamplesofthat
havelabelledattributeswithcompositionalstructure. concept. Foreachdatasetandconceptextractionmethod,
we calculate the ROC-AUC score to measure the ability
We follow a setup similar to (Lewis et al., 2022) for the
oftheextractedconcepttoperformsuchadiscrimination.
syntheticCLEVR(Johnsonetal.,2017)datasetandconsider
We provide the full ROC-AUC results in Appendix E.6.
imageswithsingleobjectslabelledasoneofthreeshapes
3TowardsCompositionalityinConceptLearning
red 1.0 -0.49 -0.49 -0.03 0.17 -0.15
Method CLEVR CUB-sub Truth-sub
green -0.49 1.0 -0.52 0.05 -0.02 -0.04
GT 1.000±0.000 0.808±0.000 0.625±0.000
PCA 0.981±0.000 0.663±0.000 0.467±0.000 blue -0.49 -0.52 1.0 -0.05 -0.12 0.19
ACE 0.834±0.029 0.651±0.011 0.551±0.017
DictLearn 0.891±0.005 0.650±0.010 0.533±0.006 sphere -0.03 0.05 -0.05 1.0 -0.68 -0.64
SemiNMF 0.780±0.029 0.629±0.029 0.525±0.050
CT 0.575±0.039 0.510±0.003 0.428±0.055 cube 0.17 -0.02 -0.12 -0.68 1.0 -0.13
Random 0.568±0.087 0.445±0.079 0.461±0.034
cylinder -0.15 -0.04 0.19 -0.64 -0.13 1.0
CCE 1.000±0.000 0.648±0.008 0.545±0.004
red green blue sphere cube cylinder
(a)MAPscoreofpredictingconceptcompositions. (b)CosinesimilaritiesbetweenCLEVRconcepts.
Figure2.Compositionalityofground-truthconceptscomparedwithconceptsextractedbyexistingapproachesandCCE.Figure2ashows
thattheground-truthconcepts(GT)arequitecompositional,butexistingmethodsarenot.Figure2bshowsthecosinesimilaritiesbetween
pairsofground-truthconceptsfortheCLEVRdataset. Thedarkerbluecellsrepresentconceptsthatareorthogonal,whilethelighter
yellowonesrepresentnon-orthogonalones.Weobservethatconceptstendtobemoreorthogonaliftheybelongtodifferentattributes.
Compositional concepts 3.4.DesiredPropertiesofCompositionalConcepts
To extract compositional concepts, we must first identify
characteristicsofsuchconcepts. Sincetheground-truthcon-
ceptswerecompositional,weinvestigatethesalientcharac-
teristicsofthoseconcepts.
Considertheground-truthconceptsfortheCLEVRdataset.
In order to understand the relationship between different
Incorrect compositionality
ground-truthconceptsandtheircompositionality,wecen-
terthesampleembeddingsandvisualizecosinesimilarities
betweenpairsoftheseconceptsinFigure2b. Weobserve
thattheground-truthrepresentationsofcolorconceptsare
roughly orthogonal (cosine similarity near 0) to those of
shapeconcepts. Incontrast,therepresentationsofconcepts
within the same attribute, such as the red and blue con-
Figure3.Illustrationofconceptsonadatasetofcubesandspheres
cepts,arenon-orthogonal. Furthermore,theorthogonalcon-
thatareeitherredorblue. Theconceptsonthetoparecomposi-
ceptsarealsothosethatcancomposetoformnewconcepts,
tionalwhilethoseonthebottomarenot.Eventhoughtheconcepts
sincetheylieindifferentattributes. Forinstance,thered
onthebottomcanperfectlyrepresentthefoursamples,theystill
andsphereconceptsareorthogonal,andcancomposeto
failtocomposeproperly.Forinstance,thecompositionofthered
andblueconceptscanformthe{red, sphere}concepteven
formthe{red, sphere}concept,whiletheredconcept
thoughtheblueconceptisnotpresentinaredsphere. can’tcomposewiththeblueconcept.
We visualize the same for the CUB-sub and Truth-sub
datasets in Appendix C, and empirically observe the fol-
lowing trend over all three datasets: concept representa-
tionsfromdifferentattributesareroughlyorthogonalwhile
In the case of NMF, despite this score averaging as high
thosefromthesameattributearenon-orthogonal. Also,the
as 0.907 for the CLEVR dataset, the extracted concepts
orthogonal concepts tend to be compositional, while the
are not compositional. This implies that finding concept
non-orthogonalonescan’tbecomposed.
representationssimplybasedontheirabilitytodiscriminate
positiveandnegativesamplesofaconceptdoesnotmean Orthogonalityisagenerallyhelpfulpropertyforseveraluse
thatthoserepresentationswillcomposeasexpected. cases,suchasdisentanglingconceptsinembeddingspace
(Chenetal.,2020). Someapproachesthereforetrytoen-
Wefurtherdemonstratethispointwithatoyillustrationin
forceorthogonalityontheconceptsbeingextracted. Table1
Figure3. Thisfiguredepictsfourperfectlycomposedcon-
summarizesexistingunsupervisedapproachesforconcept
ceptsatthetop,andfourincorrectlycomposedconceptsat
extractionandwhetherthemethodenforcesanyorthogo-
thebottom,eventhougheachconceptisperfectlydiscrimi-
nality constraints (Ortho.) between concepts of different
nativeofthesampleswiththeconcept. Therefore,wemust
attributesandallowsfornon-orthogonalitybetweenthose
ensurethatweexplicitlyextractcompositionalconcepts.
4TowardsCompositionalityinConceptLearning
Algorithm1CompositionalConceptExtraction
Table1.Propertiesenforcedbyunsupervisedconceptextraction.
Input: embeddingsZ, num. attr. M, conceptsperattr. K,
Method Example Ortho. Corr.
subspacedimensionS
PCA RepE(Zouetal.,2023a) ✓ ✗ InitializeconceptsC ={}
KMeans ACE(Ghorbanietal.,2019) ✗ ✓ form=1...M do
Dictionary- TransformerVis(Yunetal., ✗ ✓ InitializeP ∈Rd×S suchthatPTP =I.
Learning 2021) InitializeKconceptsV ={v 1,...,v K}.
NMF CRAFT(Feletal.,2023) ✗ ✓ repeat
Custom Concept Tf (Rigotti et al., ✗ ✓ P =LearnSubspace(P,Z,V)
2022) V =LearnConcepts(ZP,K)
untilConverged
Custom CCE(Ours) ✓ ✓
C =C∪V
Z =Z−ZPPT
endfor
ReturnC
ofthesameattribute(Corr.). Weseethattheseapproaches
allowforonlyoneofthetwo,butnotboth.
Wenowformallyprovethattheobservedpropertiesregard- Concepts, as illustrated in Figure 4. The LearnSubspace
ingconceptcompositionalityholdinageneralizedsetting. step,shownontheleft,isgivenaclusteringofthedata(in
termsofcentroidsV)andoptimizesasubspace,definedby
Theorem 3.1. For some dataset, consider two attributes
P ∈Rd×S,sothatthedatainthissubspace(ZP)becomes
A and A′ where A has l concepts c ,...c and A′ has l′
1 l well clustered according to the fixed centroids V. In the
conceptsc′,...c′ . Assumingthatforeachcompositional
1 l′ nextstep,LearnConcepts,shownontheright,weidentify
conceptc={c ,c′},itsrepresentationv ,followsaspher-
i j i,j conceptsbyperformingsphericalK-Meansclusteringon
icalnormaldistributionwithzeromeanandunitcovariance,
ZP,thedatawithinsubspaceP.
i.e. v ∼N(0,Id),thefollowingstatementsaretruewith
i,j
highprobabilityforalargedimensiond: Thisclusteringprocessisperformedwithinalearnedsub-
spaceandthesubspaceislearnedaccordingtothelearned
• Thereexistsc ,c ∈Aandc′,c′ ∈A′suchthattherep-
1 2 1 2 clustering. Therefore,wejointlylearnthesubspaceP and
resentationsofthesebaseconceptsarenonorthogonal.
theclusteringcentroidsV. Specifically,forLearnSubspace,
• Forallc ∈Aandc ∈A′,therepresentationsofc and
1 2 1 weemploytheSilhouettescore(Rousseeuw,1987)toquan-
c areorthogonalwithhighprobability.
2 tifyhowwellclusteredtheprojecteddataZP isgivenaclus-
terassignmentLdeterminedbythecentroidsfromspherical
We show the proof in Appendix B. The takeaway from
K-Meansclustering. TheSilhouettescoremeasuresthera-
this result is that compositional concepts will be roughly
tio of average within cluster distance to average between
orthogonal, whileconceptsofthesameattributemaynot
clusterdistance. SincetheSilhouettescoreisdifferentiable,
beorthogonal. Inaddition,weshowinCorollaryB.4that
oncewefixaclusteringLfromLearnConcepts,weperform
givenconceptswhichfollowtheconsequentoftheabove
astepofgradientascentinLearnSubspacetoincreasethe
theorem,thattheconceptswillhavecompositionalconcept
Silhouettescore. Thus,wesolvethefollowingoptimization
representations,meaningtherepresentationsofcomposite
problembyiterativelyfixingP tolearnL(withLearnCon-
conceptsconsistofasumoftheircomponentbaseconcept
cepts)andthenfixingLtolearnP byagradientstep(with
representations,asdefinedinDefinition2.2. Weleverage
LearnSubspace)untilconvergence:
thistodesignanunsupervisedconceptextractionmethod
argmax Sil(ZP,L).
whichcanfindcompositionalconceptswhentheyexist. P,L
Wefurtherobservethatsimplymaximizingtheaboveobjec-
4.CompositionalConceptExtraction(CCE) tiveleadstooverfittingissuessinceprojectingthelearned
clustercentroidsfromLearnConceptsbacktotheoriginal
Toachievethisorthogonalitypropertybetweenconcepts,we spacemaynotnecessarilycorrespondtoclustercentroids
proposeCCE,summarizedinAlgorithm1andvisualizedin intheoriginalspace. Therefore,intheLearnSubspacestep
Figure4. Astheouterloopofthealgorithmsuggests,once weadditionallytrytomatchtheclustercentroidslearned
wefindconceptsforanattributeinasubspaceP,weremove withinthesubspaceandprojectedouttotheoriginalspace
thatsubspaceusingorthogonalrejectionandfindconcepts tothecentroidsoftheclustersintheoriginalspace. Thisis
in a new subspace. This enforces orthogonality between integratedintotheabovefullobjectivefunctionasaregular-
thediscoveredsubspaces,thusrespectingtheorthogonality izationterm,i.e.:
propertydescribedinSection3. argmax (cid:16) Sil(ZP,L)+(cid:88) S (C PT,Cˆ )(cid:17) ,
P,L cos k k
To discover concepts within each attribute, we employ a k
two-stepprocessconsistingofLearnSubspaceandLearn- whereC representstheclusteringcentroidsinthesubspace
k
5TowardsCompositionalityinConceptLearning
Remove from :
Joint Learning
LearnSubspace LearnConcepts
Find subspace where Find concepts
is clustered with in subspace .
centroids .
Concepts: Subspace:
Figure4.FindingcolorconceptsinoneiterationofCCE,whichcanbeproceededbyfindingotherconcepts,suchasshapes.
P whileCˆ = 1 (cid:80) 1[L = k]Z representsthe Experiment Design. We aim to answer these questions
clusteringck entro(cid:80) idi s1 i[L ni t= hk e] origi inali space. i regardingthequalityofthelearnedconceptrepresentations:
RQ1 Inthecontrolledsettingwithknowncompositional
5.Experiments ground-truthconceptrepresentations,doesCCEcom-
poseconceptsmoreeffectivelythanbaselines?
5.1.ExperimentalSetup
RQ2 Inthefullsettingwheretheground-truthconceptsare
Datasets and Models. We evaluate using five datasets typically unknown, can CCE successfully discover
acrossvisionandlanguagesettings:CLEVR(Johnsonetal., newandmeaningfulcompositionalconcepts?
2017)(vision),CUB(Wahetal.,2011)(vision),HAM10000 RQ3 In both controlled and full settings, how can the
(Tschandletal.,2018)(vision), Truth(Zouetal.,2023b) learnedcompositionalconceptrepresentationsimpact
(language),andNews(Mitchell,1999)(language). Weper- downstreamperformance?
formexperimentsonbothcontrolledandfullsettings. In
To address RQ1, we evaluate the compositionality score
thecontrolledsetting,wefollowthesameconfigurationas
(Andreas,2019)ontheconceptrepresentationsextractedby
Section3.1fortheCLEVR,CUBandTruthdatasets. Fur-
CCEandthebaselines,whichisdefinedasfollows:
therinformationonourdatasetsisincludedinAppendixF.
Definition5.1. (CompositionalityScore)GivenadatasetD
ThefullsettingconsidersallsamplesfromtheCUB,Ham,
consistingofembeddingsz ∈Rd,theirassociatedground-
Truth,andNewsdatasets.
truthconceptsC ⊂C,andaconceptrepresentationfunction
Fortheimagedatasets, weobtainsamplerepresentations R:C→Rdobtainedfromaconceptextractor,thecompo-
fromtheCLIPmodel(Radfordetal.,2021)whileforthe sitionalityscoreisthefollowing:
(cid:13) (cid:13)
NLPdataset,thisisachievedwithLlama-213BChatmodel (cid:13) |C| (cid:13)
1 (cid:88) (cid:13) (cid:88) (cid:13)
(Touvronetal.,2023). Wealsoperformablationstudieson m Λ≥in
0 |D|
(cid:13) (cid:13)z− Λ z,iR(C i)(cid:13)
(cid:13)
thechoicesofdifferentmodelsinAppendixE.8. (z,C)∈D(cid:13) i=1 (cid:13)
BaselineMethods. Sincetheconceptrepresentationsare Intuitivelyspeaking,forasampleembeddingz,thismetric
learnedbyCCEinanunsupervisedmanner,wetherefore quantifieshowmuchzcanbereconstructedbycomposing
primarilycompareCCEagainstthefollowingstate-of-the- alistofconceptrepresentationR(c i)’sthatcorrespondto
artunsupervisedconceptextractionmethods,i.e.,PCA(Zou thei thground-truthconceptsofz. EachR(c i)isweighted
etal.,2023a),NMF(Feletal.,2023),ACE(KMeans)(Ghor- byacoefficientΛ z,i,whichisdeterminedbyoptimizingthe
banietal.,2019),andDictionaryLearning(Brickenetal., aboveformulawithrespecttoallΛ z,i.
2023;Yunetal.,2021). Inaddition,weincludeaRandom
Inaddition,foreachground-truthconcept,wealsoreportthe
baselinewherewerandomlyinitializeconceptvectorsfrom
cosinesimilaritybetweenthelearnedconceptrepresentation
anormaldistributionofmeanzeroandvarianceone.
R(c )andthecorrespondingground-truthrepresentation.
i
Recent studies like Concept Transformer (Rigotti et al.,
To study RQ2 for the full setting, we primarily perform
2022)explorehowtojointlylearnconceptrepresentations
qualitativestudiestoidentifywhetherCCEiscapableofdis-
andperformtrainingofdownstreamclassificationtaskswith
coveringreasonablecompositionalconcepts. Specifically,
learnedconceptrepresentations. Hence,wetreatConcept
foreachlearnedconceptrepresentation,weassignaname
Transformer(ConceptTf)(Rigottietal.,2022)asanother
totheconceptbyinspectingthetenimageswiththetopcon-
baseline. NotethatConceptTfcanoptionallyincorporate
ceptscore. Thenforeachpairofthelearnedconcepts,we
concept labels as additional supervisions, which are not
firstidentifythosesampleswiththehighestconceptscores.
consideredinourexperimentsforfaircomparison.
Then, we sum the two concept representations, and find
6TowardsCompositionalityinConceptLearning
Framed Birds Birds in Hands
Orange Birds Framed Orange Birds White Birds White Birds in Hands
+ = + =
Flying Birds Framed Flying Birds Black Birds Black Birds in Hands
+ = + =
(a) (b)
Asking for suggestions Items for sale Asking for purchasing suggestions
HELP! Please reply to the seller below. Which would YOU choose, and
I am trying to find software that For Sale: why?
will allow COM port redirection Sun SCSI-2 Host Adapter
Text Ending in "..." Sports Sports text ending in "..." [...] Can anyone out there make Assembly Like lots of people, I'd really like to
a suggestion or reccommend -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=- increase my data transfer rate
H p H meo i e r tp .s h .e .o ef n ru eall ,ly . m, . .h ae y bd eo e ys on ut cta ak ne h i et lp + I t a Q 2 t hf o h s euI w p ip s ew e de e ob r ie l c di. ne o r t T ee c bdoh lsf d f oP e r t o woaa hw m mnt e 2diB i n nng b u og daa er ns tmn i ge n lyds od ge o a RI . H' rm ld oo .a i uyt n bh t a ,ksr o t e a e fw p lod thtr i e on fiv ur t se gh tr he y = G b N w r c l uee ue po er aa ra t ., i grt .lr n le .eda y ut r nn l e t sF tc h e lu iyou o s nr ah su p in *cr ,g r w ih nh h s th ae o ea s e ls t s khi m n sttd i oh n *c eo .pa e g . n S n J 1t we oh e 0B o me ft r fh iu i n eLa Ki ls d tan ti hn ht v o iS g e na u gla il sit et il seo rert ... s H I o s s o u oa si m c g uma i g rl le cl l el, oot eh sso tci fn ik oooig rn np . tg se h eof [o . mn.r . ] .aa a ln n oe d ww w -po riu cl ed d like + = P 2 D - = [ .= .1- -l i .e - =s R ]0[ =ka. -M. o- s. =3] d e -.F i5 = mr o " -e r e=p m -l 3=y a 2- tt =t 5o e - 9 =dt Th - S = Se -C s = (Se - 3=l I l ae -H = vr a - ab =r ie d l- a=lo b-w = le-. ) = f H I o s sr u oa so i c g umm a i g rl l cl l el, oo esso tc fik oooi rn np tg se h eof [o . mn.r . ] .aa a ln n oe d ww w -po riu cl ed d like
(c) (d)
Figure5.ExamplesofcompositionalconceptsidentifiedbyCCE.Figures5aand5barefromtheCUBdatasetwhileFigures5cand5d
arefromtheNewsdataset. ThesefiguressuggestthatCCEcannotonlydiscovernewmeaningfulconceptsoutsidetheground-truth
concepts,suchastheBirds in HandsconceptinFigure5b,butalsocomposetheseconceptscorrectly,e.g. White Birds+
Birds in Hands=White Birds in Hands.
Table2. CompositionalityScores(lowerisbetter). showsthattheconceptslearnedbyCCEalmostalignwith
CLEVR CUB-sub Truth-sub theground-truthconceptrepresentations.
GT 3.162±0.000 0.462±0.000 3.743±0.000 ThisisfurthersupportedbytheresultsinTable3. Thistable
PCA 3.684±0.000 0.472±0.000 3.975±0.000
summarizesthecosinesimilaritiesbetweentheground-truth
ACE 3.474±0.134 0.496±0.007 3.727±0.032
conceptrepresentationsandtheoneslearnedbythebase-
DictLearn 3.367±0.016 0.498±0.002 3.708±0.007
SemiNMF 3.716±0.053 0.495±0.004 3.781±0.074 linesandCCE.Again,theconceptslearnedbyCCEarethe
CT 4.929±0.002 0.545±0.000 4.348±0.000 closesttothegroundtruths. Notethatsomebaselineslike
Random 4.925±0.000 0.545±0.000 4.348±0.000 Dictlearnalsoproducehighlyaccurateconceptrepresenta-
CCE 3.163±0.000 0.459±0.004 3.689±0.002
tions. However,asTable2shows,theircompositionsfailto
beconsistentwiththegroundtruths.
thesampleswithlargestconceptscoreforthisaggregated Compositionality in Real Data Settings. To address
representation.Byinvestigatingtheseexamples,wevisually RQ2, we perform some qualitative studies on compo-
examinewhetherthecompositionisreasonableornot. sitional concepts discovered by CCE on the CUB and
News dataset, which are visualized in Figure 5. As
Lastly,weanswerRQ3byevaluatingthedownstreamclas-
shown in this figure, CCE is capable of identifying rea-
sificationperformancewiththelearnedconceptrepresenta-
sonableconcepts,suchasWhite Birds,Framed Birds
tions. Specifically,wefollowYuksekgonuletal.(2023)to
andText Ending in ‘‘...’’. Someoftheseconcepts
learnalinearclassifierbypredictingclasslabelswiththe
areevenbeyondtheground-truthconceptlabelsthatarepro-
concept scores of a sample. We further report the perfor-
videdbythedatasetitself. Forexample,CCEidentifiesthe
manceoftrainingalinearclassifieronsampleembeddings
“BirdsinHands”conceptwhichisnotlabeledintheCUB
withoutinvolvinganyconcepts,denotedby“Noconcept”.
dataset. Butitstopactivatedsamplesareimageswithabird
insomeone’shand(seeFigure5b).Furthermore,thecompo-
5.2.ExperimentalResults sitionofthoselearnedconceptsisalsorepresentativeofthe
propertiesofeachconcept. Forexample,inFigure5c,the
CompositionalityinControlledSettings. Wefirstevalu-
composition of the concept Text Ending in ‘‘...’’
atethecompositionalityscoresontheCLEVR,CUB-sub,
andSportsrepresentssentencesabout“sports”endingin
and Truth-sub datasets andreport themin Table2. Inall
“...”.
cases,CCEobtainsthebestscorecomparedtothebaselines,
indicatingtheadvantageofCCEindiscoveringcomposi- DownstreamPerformanceAnalysis. ForRQ3,westud-
tionalconcepts. Moreover, CCE’sscoresarecomparable iedtheimpactoftheextractedcompositionalconceptson
tothoseoftheground-truthconceptrepresentations. This
7TowardsCompositionalityinConceptLearning
Figure6. Downstreamclassificationaccuracyonthefullsetting.
Table3.Theaveragecosinesimilaritybetweenindividuallearned we choose which concepts to use? Some existing work
conceptrepresentationsandthegroundtruth(higherisbetter). specifies concepts using human supervision to select and
CLEVR CUB-sub Truth-sub providetheirlabels(Kimetal.,2018),large-scaleconcept
annotationdatasets(Bauetal.,2017),generalknowledge
PCA 0.580±0.000 0.503±0.000 0.459±0.000
ACE 0.728±0.009 0.719±0.016 0.648±0.007 bases(Yuksekgonuletal.,2023),andlargelanguagemodels
DictLearn 0.745±0.003 0.661±0.010 0.686±0.007 (Yangetal.,2023). Anotherlineofworkusesregulariza-
SemiNMF 0.732±0.014 0.696±0.002 0.673±0.052 tion(Wongetal.,2021),orotherinductivebiases(Rigotti
CT 0.044±0.009 0.066±0.001 0.019±0.002
etal.,2022)tolearnconceptsduringstandardsupervised
Random 0.059±0.003 0.043±0.011 0.024±0.001
trainingofamodel. Finally,thereisworkwhichleverages
CCE 0.992±0.000 0.770±0.001 0.804±0.001
unsupervisedmethodstoautomaticallydiscoverconcepts
(Ghorbani et al., 2019; Fel et al., 2023; Yun et al., 2021;
downstreamperformanceacrossalldatasetsinthefullset- Brickenetal.,2023)whichistheapproachtakeninthispa-
ting. Throughouttheexperiments,weobservethatthetotal per. Unlikeexistingunsupervisedconceptlearningmethods
numberofconceptsisacrucialfactorindeterminingthe whichfocusonpropertiessuchasfaithfulness(Ghorbani
performance. Therefore,wealsovarythisnumberandre- etal.,2019)orhuman-meaningfulness(Feletal.,2023),we
porttheperformancenumbersaccordinglyforalldatasets focusspecificallyoncompositionality.
and methods in Figure 6. As this figure suggests, across
Compositionality in Foundation Models. Since the ob-
allthedatasets,despitethepoorperformancewithasmall
servationofcompositionalwordvectorsbyMikolovetal.
numberofconcepts,CCEgraduallygainsperformancewith
(2013)therehasbeeninterestinfindingandutilizingcompo-
anincreasingnumberofconcepts,eventuallyoutperforming
sitionalbehaviorofdeeplearningmodels.Existingworkhas
alltheunsupervisedbaselinemethods.
leveragedinsightsfrompsychologyandcognitivescience
Also,itisworthnotingthatCCEoutperformsConceptTf tofindconceptslearnedbygenerativemodels(Frankland&
mosttimesandisonparwithitintheworstcase(seethe Greene,2020;Lake,2014). Compositionalityhasbeenused
experimentalresultsonthehamdatasetwith500concepts). touncoverandmitigatebiasinwordembeddings(Boluk-
ThisthusindicatestheperformanceadvantageofCCEeven basietal.,2016),editclassifierbehavior(Santurkaretal.,
intheabsenceofsupervisionfromdownstreamtasks. 2021),andrecentlytomonitorandcontrolthebehaviorof
foundationallanguage(Toddetal.,2023;Zouetal.,2023a)
Furthermore, CCE discovers concept representations by
andvisionmodels(Wangetal.,2023;Kwonetal.,2023).
performingaseriesoflineartransformationsontopofthe
Tothebestofourknowledge, wearethefirsttoevaluate
sampleembeddings.Butbycomparingagainst“Noconcept”
compositionalityofconceptrepresentationslearnedbyun-
wheresampleembeddingsaredirectlyusedfordownstream
supervisedapproachesandtoproposeamethodtoimprove
tasks, CCE can even outperform it by a large margin on
compositionalityofdiscoveredconcepts.
CUBandHamdataset. Thisimpliesthattheconceptrepre-
sentationsextractedbyCCEmightbemorerelevanttothe Compositional and Disentangled Representations. In
downstreamclassificationtasksthantherawembeddings. representationlearning, thereisconsiderableefforttoen-
couragedisentangledrepresentations(Bengioetal.,2013;
Higgins et al., 2016; Wang et al., 2022). While disentan-
6.RelatedWork
glementconcernshowtodistinguishseparateconceptsin
Concept-based Interpretability. Concept-based inter- embeddingspace,compositionalityconcernswhathappens
pretability encompasses the building of models using whenseparateconceptsgetcombined. Existingworkhas
human-interpretable concepts (Koh et al., 2020; Es- shown that disentanglement and compositionality do not
pinosa Zarlenga et al., 2022; Yuksekgonul et al., 2023) havetobecorrelated(Xuetal.,2022). Unlikerepresenta-
andextractingsuchconceptspost-hocfrommodels(Kim tionlearning, westartwithapretrainedmodelandtryto
et al., 2018; Zhou et al., 2018). In either case, how do uncoverthecompositionalconceptsitlearned.
8TowardsCompositionalityinConceptLearning
Structuresbeyondcompositionality. Thispaperfocuses Universities,PekingUniversity”.
oncompositionalityinconcept-basedinterpretability,but
otherimportantstructuresincludesubpopulation,relational,
ImpactStatement
andcausalstructures. Group, orsubpopulation, structure
hasbeenusedasawaytointerpretdatasetswithexisting Thispaperpresentsworkwhosegoalistoadvancethefield
work on automatically finding such structure (Blei et al., of Machine Learning. There are many potential societal
2001)andexplainingmodelswithrespecttothisstructure consequences of our work, none which we feel must be
(Havaldaretal.,2023). Inaddition,existingworkhasdevel- specificallyhighlightedhere.
opedmethodstosteerexplanationstorespectgroupstruc-
tures (Stein et al., 2023). Relational structures have also
References
beenstudiedasalensintounderstandingthebehaviorof
pretrainedmodels(Toddetal.,2024;Lovering&Pavlick, HelloGPT-4o. URLhttps://openai.com/index/
2022;Hilletal.,2018). Beyondgroupandrelationalstruc- hello-gpt-4o/.
tures, recent work proposes a method to identify known
Abid,A.,Yuksekgonul,M.,andZou,J. Meaningfullyde-
causalstructuresinpretrainedLLMs(Wuetal.,2023).
buggingmodelmistakesusingconceptualcounterfactual
explanations. InInternationalConferenceonMachine
7.Limitations
Learning,pp.66–88.PMLR,2022.
Westudythecasewhereconceptscomposecompositionally,
Andreas,J. Measuringcompositionalityinrepresentation
butconceptsmayalsobenon-compositional. Forinstance,
learning. InInternationalConferenceonLearningRep-
theconceptsofhotanddogdonotcomposetoformthe
resentations,2019.
meaning of hot dog (Zhai, 1997). In addition, we sup-
posedaflatconceptstructure,whichdoesnotdistinguish
Azaria, A. and Mitchell, T. The internal state of an llm
between “(small blue) car” and “small (blue car)”. We
knowswhenitslying. arXivpreprintarXiv:2304.13734,
leavethestudyofsuchnon-compositionalandhierarchical
2023.
conceptstofuturework.
Bau, D., Zhou, B., Khosla, A., Oliva, A., and Torralba,
Anotherlimitationofunsupervisedconceptextractionisthat
A. Networkdissection: Quantifyinginterpretabilityof
discoveredconceptvectorsarenotassociatedwithanyname.
deepvisualrepresentations. InProceedingsoftheIEEE
Weassignnamestotheconceptthroughmanualinspection
conferenceoncomputervisionandpatternrecognition,
ofsampleswithahighconceptscore,butthiscanrequire
pp.6541–6549,2017.
significanteffortwithlargenumbersofconcepts.
Bengio,Y.,Courville,A.,andVincent,P. Representation
8.Conclusion learning: Areviewandnewperspectives. IEEEtransac-
tionsonpatternanalysisandmachineintelligence,35(8):
In this paper, we studied concept-based explanations of
1798–1828,2013.
foundationmodelsfromthelensofcompositionality. We
validatedthattheground-truthconceptsextractedfromthese Blei,D.,Ng,A.,andJordan,M. Latentdirichletallocation.
modelsarecompositionalwhiletheexistingunsupervised Advancesinneuralinformationprocessingsystems,14,
conceptextractionmethodsusuallyfailtoguaranteecom- 2001.
positionality. Toaddressthisissue,wefirstidentifiedtwo
salientpropertiesforcompositionalconceptrepresentations Bolukbasi,T.,Chang,K.-W.,Zou,J.Y.,Saligrama,V.,and
anddesignedanovelconceptextractionmethodcalledCCE Kalai,A.T. Manistocomputerprogrammeraswoman
thatrespectsthesepropertiesbydesign. Throughextensive istohomemaker? debiasingwordembeddings. Advances
experimentsacrossvisionandlanguagedatasets,wedemon- inneuralinformationprocessingsystems,29,2016.
stratedthatCCEnotonlylearnscompositionalconceptsbut
alsoenhancesdownstreamperformance. Bricken,T.,Templeton,A.,Batson,J.,Chen,B.,Jermyn,A.,
Conerly,T.,Turner,N.,Anil,C.,Denison,C.,Askell,A.,
Lasenby,R.,Wu,Y.,Kravec,S.,Schiefer,N.,Maxwell,
Acknowledgements
T.,Joseph,N.,Hatfield-Dodds,Z.,Tamkin,A.,Nguyen,
ThismaterialisbaseduponworksupportedbytheNational K., McLean, B., Burke, J. E., Hume, T., Carter, S.,
ScienceFoundationGraduateResearchFellowshipunder Henighan,T.,andOlah,C. Towardsmonosemanticity:
Grand No. DGE-2236662, the Google Research Fellow- Decomposinglanguagemodelswithdictionarylearning.
ship,and“TheFundamentalResearchFundsfortheCentral TransformerCircuitsThread,2023. https://transformer-
circuits.pub/2023/monosemantic-features/index.html.
9TowardsCompositionalityinConceptLearning
Caron,M.,Bojanowski,P.,Joulin,A.,andDouze,M. Deep Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J.,
clustering for unsupervised learning of visual features. Viegas,F.,etal. Interpretabilitybeyondfeatureattribu-
InProceedingsoftheEuropeanconferenceoncomputer tion: Quantitativetestingwithconceptactivationvectors
vision(ECCV),pp.132–149,2018. (tcav). InInternationalconferenceonmachinelearning,
pp.2668–2677.PMLR,2018.
Chen,Z.,Bei,Y.,andRudin,C.Conceptwhiteningforinter-
pretableimagerecognition. NatureMachineIntelligence, Koh,P.W.,Nguyen,T.,Tang,Y.S.,Mussmann,S.,Pierson,
E.,Kim,B.,andLiang,P. Conceptbottleneckmodels. In
2(12):772–782,2020.
Internationalconferenceonmachinelearning,pp.5338–
EspinosaZarlenga,M.,Barbiero,P.,Ciravegna,G.,Marra, 5348.PMLR,2020.
G.,Giannini,F.,Diligenti,M.,Shams,Z.,Precioso,F.,
Kwon,M.,Jeong,J.,andUh,Y. Diffusionmodelsalready
Melacci,S.,Weller,A.,etal.Conceptembeddingmodels:
haveasemanticlatentspace. InTheEleventhInterna-
Beyondtheaccuracy-explainabilitytrade-off. Advances
tionalConferenceonLearningRepresentations,2023.
in Neural Information Processing Systems, 35:21400–
21413,2022. Lake,B.M. Towardsmorehuman-likeconceptlearningin
machines: Compositionality,causality,andlearning-to-
Fel, T., Picard, A., Bethune, L., Boissin, T., Vigouroux, learn. PhDthesis,MassachusettsInstituteofTechnology,
D.,Colin,J.,Cade`ne,R.,andSerre,T. Craft: Concept 2014.
recursive activation factorization for explainability. In
ProceedingsoftheIEEE/CVFConferenceonComputer Lewis,M.,Nayak,N.V.,Yu,P.,Yu,Q.,Merullo,J.,Bach,
VisionandPatternRecognition,pp.2711–2721,2023. S.H.,andPavlick,E. Doesclipbindconcepts? probing
compositionalityinlargeimagemodels. arXivpreprint
Frankland,S.M.andGreene,J.D. Conceptsandcompo- arXiv:2212.10537,2022.
sitionality: insearchofthebrain’slanguageofthought.
Lovering, C.andPavlick, E. Unittestingforconceptsin
Annualreviewofpsychology,71:273–303,2020.
neural networks. Transactions of the Association for
ComputationalLinguistics,10:1193–1208,2022. doi: 10.
Ghorbani,A.,Wexler,J.,Zou,J.Y.,andKim,B. Towards
1162/tacl a 00514. URLhttps://aclanthology.
automaticconcept-basedexplanations. Advancesinneu-
org/2022.tacl-1.69.
ralinformationprocessingsystems,32,2019.
Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and
Havaldar,S.,Stein,A.,Wong,E.,andUngar,L.H. Topex:
Dean,J. Distributedrepresentationsofwordsandphrases
Topic-based explanations for model comparison. In
andtheircompositionality. Advancesinneuralinforma-
Maughan, K., Liu, R., and Burns, T. F. (eds.), The
tionprocessingsystems,26,2013.
First Tiny Papers Track at ICLR 2023, Tiny Papers @
ICLR 2023, Kigali, Rwanda, May 5, 2023. OpenRe- Mitchell, T. Twenty Newsgroups. UCI Ma-
view.net,2023. URLhttps://openreview.net/ chine Learning Repository, 1999. DOI:
pdf?id=AidIUjh__t. https://doi.org/10.24432/C5C323.
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Radford,A.,Kim,J.W.,Hallacy,C.,Ramesh,A.,Goh,G.,
Botvinick, M., Mohamed, S., and Lerchner, A. beta- Agarwal,S.,Sastry,G.,Askell,A.,Mishkin,P.,Clark,J.,
vae: Learningbasicvisualconceptswithaconstrained etal. Learningtransferablevisualmodelsfromnatural
variational framework. In International conference on language supervision. In International conference on
learningrepresentations,2016. machinelearning,pp.8748–8763.PMLR,2021.
Rigotti, M., Miksovic, C., Giurgiu, I., Gschwind, T., and
Hill,F.,Santoro,A.,Barrett,D.,Morcos,A.,andLillicrap,
Scotton,P. Attention-basedinterpretabilitywithconcept
T.Learningtomakeanalogiesbycontrastingabstractrela-
transformers. In International conference on learning
tionalstructure. InInternationalConferenceonLearning
representations,2022.
Representations,2018.
Rousseeuw,P.J. Silhouettes: agraphicalaidtotheinter-
Johnson, J., Hariharan, B., Van Der Maaten, L., Fei-Fei,
pretationandvalidationofclusteranalysis. Journalof
L., Lawrence Zitnick, C., and Girshick, R. Clevr: A
computationalandappliedmathematics,20:53–65,1987.
diagnostic dataset for compositional language and ele-
mentary visualreasoning. In Proceedings ofthe IEEE Russakovsky,O.,Deng,J.,Su,H.,Krause,J.,Satheesh,S.,
conferenceoncomputervisionandpatternrecognition, Ma,S.,Huang,Z.,Karpathy,A.,Khosla,A.,Bernstein,
pp.2901–2910,2017. M.,Berg,A.C.,andFei-Fei,L. ImageNetLargeScale
10TowardsCompositionalityinConceptLearning
VisualRecognitionChallenge. InternationalJournalof Turpin, M., Michael, J., Perez, E., andBowman, S. Lan-
Computer Vision (IJCV), 115(3):211–252, 2015. doi: guagemodelsdon’talwayssaywhattheythink: unfaith-
10.1007/s11263-015-0816-y. fulexplanationsinchain-of-thoughtprompting.Advances
inNeuralInformationProcessingSystems,36,2024.
Santurkar,S.,Tsipras,D.,Elango,M.,Bau,D.,Torralba,A.,
andMadry,A. Editingaclassifierbyrewritingitspredic- Wah,C.,Branson,S.,Welinder,P.,Perona,P.,andBelongie,
tionrules. AdvancesinNeuralInformationProcessing S. Thecaltech-ucsdbirds-200-2011dataset. 2011.
Systems,34:23359–23373,2021.
Wang, X., Chen, H., Tang, S., Wu, Z., and Zhu, W.
Disentangled representation learning. arXiv preprint
Schaeffer,R.,Miranda,B.,andKoyejo,S. Areemergent
arXiv:2211.11695,2022.
abilitiesoflargelanguagemodelsamirage? Advancesin
NeuralInformationProcessingSystems,36,2024.
Wang, Z., Gui, L., Negrea, J., and Veitch, V. Concept
algebrafor(score-based)text-controlledgenerativemod-
Srivastava,A.,Rastogi,A.,Rao,A.,Shoeb,A.A.M.,Abid,
els. InThirty-seventhConferenceonNeuralInformation
A., Fisch, A., Brown, A. R., Santoro, A., Gupta, A.,
ProcessingSystems,2023.
Garriga-Alonso, A., et al. Beyond the imitation game:
Quantifyingandextrapolatingthecapabilitiesoflanguage Wegner, S.-A. Lecture notes on high-dimensional data.
models. Transactions on Machine Learning Research, arXivpreprintarXiv:2101.05841,2021.
2023.
Wong,E.,Santurkar,S.,andMadry,A. Leveragingsparse
Stein,A.,Wu,Y.,Wong,E.,andNaik,M. Rectifyinggroup linear layers for debuggable deep networks. In Inter-
irregularitiesinexplanationsfordistributionshift. arXiv nationalConferenceonMachineLearning,pp.11205–
preprintarXiv:2305.16308,2023. 11216.PMLR,2021.
Wu,Z.,Geiger,A.,Icard,T.,Potts,C.,andGoodman,N.
Tamkin, A., Askell, A., Lovitt, L., Durmus, E., Joseph,
Interpretabilityatscale: Identifyingcausalmechanisms
N., Kravec, S., Nguyen, K., Kaplan, J., and Ganguli,
inalpaca. AdvancesinNeuralInformationProcessing
D. Evaluatingandmitigatingdiscriminationinlanguage
modeldecisions. arXivpreprintarXiv:2312.03689,2023.
Systems,36,2023.
Xu,Z.,Niethammer,M.,andRaffel,C.A. Compositional
Todd, E., Li, M.L., Sharma, A.S., Mueller, A., Wallace,
generalizationinunsupervisedcompositionalrepresenta-
B.C., andBau, D. Functionvectorsinlargelanguage
tionlearning: Astudyondisentanglementandemergent
models. arXivpreprintarXiv:2310.15213,2023.
language. AdvancesinNeuralInformationProcessing
Systems,35:25074–25087,2022.
Todd,E.,Li,M.,Sharma,A.S.,Mueller,A.,Wallace,B.C.,
andBau,D. Functionvectorsinlargelanguagemodels.
Yang, Y., Panagopoulou, A., Zhou, S., Jin, D., Callison-
In The Twelfth International Conference on Learning
Burch, C., andYatskar, M. Languageinabottle: Lan-
Representations,2024. URLhttps://openreview.
guagemodelguidedconceptbottlenecksforinterpretable
net/forum?id=AwyxtyMwaG.
image classification. In Proceedings of the IEEE/CVF
ConferenceonComputerVisionandPatternRecognition,
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,
pp.19187–19197,2023.
A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P.,
Bhosale,S.,etal. Llama2: Openfoundationandfine- Yeh, C.-K., Kim, B., Arik, S., Li, C.-L., Pfister, T., and
tuned chat models. arXiv preprint arXiv:2307.09288, Ravikumar, P. On completeness-aware concept-based
2023. explanationsindeepneuralnetworks. InLarochelle,H.,
Ranzato,M.,Hadsell,R.,Balcan,M.,andLin,H.(eds.),
Trager,M.,Perera,P.,Zancato,L.,Achille,A.,Bhatia,P., Advances in Neural Information Processing Systems,
andSoatto,S. Linearspacesofmeanings: compositional volume 33, pp. 20554–20565. Curran Associates, Inc.,
structuresinvision-languagemodels. InProceedingsof 2020. URL https://proceedings.neurips.
the IEEE/CVF International Conference on Computer cc/paper_files/paper/2020/file/
Vision,pp.15395–15404,2023. ecb287ff763c169694f682af52c1f309-Paper.
pdf.
Tschandl,P.,Rosendahl,C.,andKittler,H. Theham10000
dataset,alargecollectionofmulti-sourcedermatoscopic Yuksekgonul, M., Wang, M., and Zou, J. Post-hoc con-
images of common pigmented skin lesions. Scientific ceptbottleneckmodels. InTheEleventhInternational
data,5(1):1–9,2018. ConferenceonLearningRepresentations,2023.
11TowardsCompositionalityinConceptLearning
Yun,Z.,Chen,Y.,Olshausen,B.,andLecun,Y.Transformer
visualizationviadictionarylearning: contextualizedem-
beddingasalinearsuperpositionoftransformerfactors.
InProceedingsofDeepLearningInsideOut(DeeLIO):
The2ndWorkshoponKnowledgeExtractionandIntegra-
tionforDeepLearningArchitectures,pp.1–10,2021.
Zhai, C. Exploiting context to identify lexical atoms–a
statisticalviewoflinguisticcontext. arXivpreprintcmp-
lg/9701001,1997.
Zhou,B.,Sun,Y.,Bau,D.,andTorralba,A. Interpretable
basisdecompositionforvisualexplanation. InProceed-
ings of the European Conference on Computer Vision
(ECCV),pp.119–134,2018.
Zou,A.,Phan,L.,Chen,S.,Campbell,J.,Guo,P.,Ren,R.,
Pan,A.,Yin,X.,Mazeika,M.,Dombrowski,A.-K.,etal.
Representationengineering: Atop-downapproachtoai
transparency. arXivpreprintarXiv:2310.01405,2023a.
Zou,A.,Phan,L.,Chen,S.,Campbell,J.,Guo,P.,Ren,R.,
Pan,A.,Yin,X.,Mazeika,M.,Dombrowski,A.-K.,etal.
Representationengineering: Atop-downapproachtoai
transparency. arXivpreprintarXiv:2310.01405,2023b.
12TowardsCompositionalityinConceptLearning
A.ProofofLemma2.3
Proof. Letz ∈Rdbeasampleembedding,R:C→Rdbeacompositionalconceptrepresentationfunction,andc ,c ∈C
i j
betwocompositionalconceptswhichcomposeasc =c ∪c . FromDefinition5.1,theconceptscoresforc andc arethe
k i j i j
following:
s(z,c )=S (z,R(c ))
i cos i
s(z,c )=S (z,R(c )).
j cos j
Theconceptscoreforthecompositionc canthenbewrittenas:
k
s(z,c )=s(z,c ∪c )
k i j
=S (z,R(c ∪c ))
cos i j
=S (z,w R(c )+w R(c )) (sinceRiscompositional)
cos ci i cj j
z·(w R(c )+w R(c ))
=
ci i cj j
(definitionofcosinesimilarity)
∥z∥∥w R(c )+w R(c )∥
ci i cj j
z·w R(c ) z·w R(c )
= ci i + cj j
∥z∥∥R(c )∥ ∥z∥∥R(c )∥
k k
(w ∥R(c )∥)z·R(c ) (w ∥R(c )∥)z·R(c )
= ci i i + cj j j
∥R(c )∥∥z∥∥R(c )∥ ∥R(c )∥∥z∥∥R(c )∥
k i k j
w ∥R(c )∥ w ∥R(c )∥
= ci i S (z,R(c ))+ cj j S (z,R(c )) (definitionofcosinesimilarity)
∥R(c )∥ cos i ∥R(c )∥ cos j
k k
B.ProofofTheorem3.1
LemmaB.1(curseofdimensionality). (Wegner,2021)ForapairofvectorsxandyrandomlysampledfromN(0,Id),x
andyareorthogonalwithhighprobabilityforlargeenoughd. Mathematicallyspeaking,forafixedsmallconstant,ϵ,the
followinginequalityholds:
(cid:20) (cid:21)
x y M M
P |⟨ , ⟩|≤ϵ ≥1− √ 1 − √2,
|x| |y| dϵ d
whereM =2andM =7
1 2
Lemma B.2 (Gaussian Annulus Theorem). (Wegner, 2021) For a vector v randomly sampled from N(0,Id), ∥v∥ is
√
approaching dwithhighprobabilityforlargeenoughd. Mathematicallyspeaking,thefollowinginequalityholds:
(cid:104) √ (cid:105)
P |∥x∥− d|≤ϵ ≥2exp(−M ϵ2),
3
inwhichM = 1
3 16
Basedontheabovetwolemmas,foranytworandomlysampledvectorsxandyfromN(0,Id),thefollowingequality
holdswithhighprobability:
⟨x,y⟩=o(d) (1)
LemmaB.3. AsdefinedinTheorem3.1,foracompositeconceptc={c ,c′},itsrepresentationisdenotedbyv ,thenthe
i j i,j
representationofthebaseconceptc belongingtoattributeAis:
i
l′
1 (cid:88)
v = v .
i l′ i,j
j=1
13TowardsCompositionalityinConceptLearning
Similarly,therepresentationofthebaseconceptc′ ∈A′is:
j
l
1(cid:88)
v′ = v .
j l i,j
i=1
Proof. v couldbederivedbycalculatingthemeanoftherepresentationsofallsampleswithconceptc intheattributeA.
i i
SincethosesamplesmayhavedifferentconceptsintheattributeA′,thenthecompositeconceptamongthesesamplescould
be{c ,c′},{c ,c′},...,{c ,c′}. Therefore,v isderivedby:
i 1 i 2 i l i
l′
1 (cid:88) 1 (cid:88) (cid:88)
v = x= x,
i N N
xwithconceptciinattributeA j=1xwithconcept{ci,c′ j}
inwhichN representsthenumberofsampleswithconceptc inattributeA. Byfurtherassumingthatthereisalargeenough
i
numberofsamplesforeachcompositeconcept,thisimpliesthatthenumberofeachcompositeconceptisroughlythesame,
i.e.,aroundN/l′. Thentheaboveformulacouldbetransformedto:
l′ l′ l′
1 (cid:88) (cid:88) 1 (cid:88)N 1 (cid:88)
v = x= v = v .
i N N l′ i,j l′ i,j
j=1xwithconcept{ci,c′ j} j=1 j=1
Thelaststepintheaboveformulaleveragesthefactthatv iscalculatedbythemeanofallsamplesbelongingtocomposite
i,j
concept{c ,c′}.
i j
WecanfurtherillustratethiswithoneconcreteexamplefromtheCLEVRdataset. Byreusingtherunningexamplefrom
Section3,weassumethattherearethreecolors{red,green,blue}andthreeshapes{sphere,cube,cylinder}intheCLEVR
dataset. By following the notations of Theorem 3.1, the representation of a composite concept, say, {c ,c }, is
red sphere
representedbyv . Thentherepresentationofthebaseconceptsphereshouldbethemeanofallsamplesbelongingto
red,sphere
thisbaseconcept. Thiscanbederivedbythemeanofthesamplesbelongingtotheconcept{c ,c },theonesbelonging
red sphere
to{c ,c }andtheonesbelongingto{c ,c }. Therefore,therepresentationofc isdenotedby:
green sphere blue sphere sphere
1
v = [v +v +v ].
sphere 3 red,sphere green,sphere blue,sphere
WenextpresenttheformalproofofTheorem3.1:
Proof. Wesplitourproofintotwoparts. Thefirstpartisforproving“Forthebaseconceptsbelongingtothesameattribute,
thereexistsatleastonepairofnon-orthogonalconcepts.” whilethesecondpartisforproving“Foranypairofbaseconcepts
fromtwodifferentattributes,theyareorthogonalwithhighprobability.”
Part 1: There exists c ,c ∈ A and c′,c′ ∈ A′ such that the representations of these base concepts are non
1 2 1 2
orthogonal.
AccordingtoLemmaB.3,theconceptrepresentationforthebaseconceptc (denotedbyvˆ)is:
i i
l′
1 (cid:88)
vˆ = v , (2)
i l′ i,j
j=1
whichsumsoverallconceptsinA′.
Sincewealsowanttoperformcenteringoperationsovertheentiredataset,thenthissuggeststhatweneedtoleveragethe
meanofallconcepts,i.e.,:
1 (cid:88)
µ= v . (3)
ll′ i,j
i,j
14TowardsCompositionalityinConceptLearning
Thenafterthecenteringoperation,vˆ istransformedinto:
i
vˆ −µ
v = i . (4)
i σ
Intheformulaabove,weuseσtorepresentthestandarddeviationvectorcalculatedovertheentiredataset.
Thenletusfixiandsumupallv overalli,whichyields:
i
l l l
(cid:88) v =(cid:88)vˆ i−µ =(cid:88)vˆ i − lµ (5)
i σ σ σ
i=1 i=1 i=1
ThenbyintegratingEquation2andEquation3intotheaboveformula,weget:
l l
(cid:88) v =(cid:88)vˆ i − lµ
i σ σ
i=1 i=1
l l′
1 (cid:88) 1 (cid:88) lµ
= v −
σ l′ i,j σ
i=1 j=1
l l′ l l′
1 (cid:88)(cid:88) 1 (cid:88)(cid:88)
= v − v
σl′ i,j σl′ i,j
i=1j=1 i=1j=1
=0
Wecanequivalentlyshowthat(cid:80)l′ v′ =0.
j=1 j
Therefore,theconceptrepresentationsv withintheattributeAarelinearlydependentandtherepresentationsv′ withinthe
i i
attributeA′arelinearlydependent,meaningthereexistconceptsc andc suchthat⟨v ,v ⟩≠ 0,andconceptsc′ andc′
i j i j k m
suchthat⟨v′,v′ ⟩≠ 0.
k m
Part2: Forallc ∈Aandc ∈A′,therepresentationsofc andc areorthogonalwithhighprobability.
1 2 1 2
ToprovethatallconceptrepresentationsfromAareorthogonaltoallconceptrepresentationsfromA′,wewillshowthat
thedotproductbetweenthesetworepresentationsiszero. Letc ∈Aandc′ ∈A′andv ,v′ aretheconceptrepresentations
i j i j
forc andc′ respectively. Wecanexpandthedotproductasfollows:
i j
(cid:28) vˆ µ vˆ′ µ(cid:29)
⟨v ,v′⟩= i − , j −
i j σ σ σ σ
ThenbyintegratingEquation2andEquation3intotheaboveformula,wecanexpandtheaboveintothefollowing:
(cid:42) l′ l (cid:43)
1 1 (cid:88) 1(cid:88)
⟨v ,v′⟩= v −µ, v −µ
i j σ2 l′ i,j l i,j
j=1 i=1
Wenotethatforarbitrarypairsofv andv withi̸=i′orj ̸=j′,sincetheyaretwodifferentrandomvectorssampled
i,j i′,j′
fromasphericalnormaldistributionN(0,Id),theirdotproductiso(d)accordingtoEquation1. Therefore,throughsome
15TowardsCompositionalityinConceptLearning
linearalgebraicoperations,theaboveformulacouldbereformulatedasfollows:
(cid:42) l′ l (cid:43)
1 1 (cid:88) 1(cid:88)
⟨v ,v′⟩= v −µ, v −µ
i j σ2 l′ i,s l t,j
s=1 t=1
(cid:42) l′ l (cid:43)
1 1 (cid:88) 1 (cid:88) 1(cid:88) 1 (cid:88)
= v − v , v − v
σ2 l′ i,s ll′ t,s l t,j ll′ t,s
s=1 t,s t=1 t,s
(cid:42) l′ l (cid:43)
1 (cid:88) 1(cid:88) (cid:88) 1 (cid:88)
= v − v , v − v
σ2ll′ i,s l t,s t,j l′ t,s
s=1 t,s t=1 t,s
 
l′ l l′ l
1 (cid:88) (cid:88) 1 (cid:88) (cid:88) 1(cid:88) (cid:88) 1 (cid:88) (cid:88)
= σ2ll′  v i,s v t,j − l′ v i,s v t,s− l v t,j v t,s+ ll′ v t,s v t,s
s=1 t=1 s=1 t,s t=1 t,s t,s t,s
 
l′ l
1 1 (cid:88) 1(cid:88) 1 (cid:88)
=
σ2ll′
∥v i,j∥2−
l′
∥v i,s∥2−
l
∥v t,j∥2+
ll′
∥v t,s∥2 +o(d)
s=1 t=1 t,s
inwhicho(d)isderivedbyapplyingEquation1toallthecrosstermsoftheform⟨v ,v ⟩whereatleastonepairofi,i′
i,j i′,j′
andj,j′aredifferent.
We can further simplify this expression using Lemma B.2 which says that for each vector x randomly sampled from
√ √
N(0,Id),itsnormisboundedby[ d−ϵ, d+ϵ]withhighprobability,whichappliestoeachv . Therefore,wecan
i,j
boundtheaboveequationby:
1 (cid:20) √ 1 √ 1 √ 1 √ (cid:21)
⟨v ,v′⟩≤ ( d+ϵ)2− l′( d−ϵ)2− l( d−ϵ)2+ ll′( d+ϵ)2 o(d)
i j σ2ll′ l′ l ll′
√
8 dϵ
= +o(d)
σ2ll′
√
Similarly,wecanprovethat⟨v ,v′⟩≥−8 dϵ +o(d),sowecanconcludethat
i j σ2ll′
|⟨v ,v′⟩|=o(d) (6)
i j
Ourgoalistogetaboundonthecosinesimilarityofv andv′ toshowthatitiszero. Thecosinesimilarityiswritten
i j
S (v ,v′)= ⟨vi,v j′⟩ ,sowehaveaboundonthenumerator,butwenowwantaboundonthetermsinthedenominator.
cos i j ∥vi∥∥v j′∥
Wecancomputethenormofv andv′ andfollowthesamederivationasabovebyleveragingEquation1,whichresultsin:
i j
∥v ∥2 =⟨v ,v ⟩
i 2 i i
(cid:42) l′ l′ (cid:43)
1 (cid:88) 1(cid:88) (cid:88) 1(cid:88)
= v − v , v − v
σ2l′2 i,s l t,s i,s l t,s
s=1 t,s s=1 t,s
 
l′ l′ l′
1 (cid:88) (cid:88) 1(cid:88) (cid:88) 1 (cid:88) (cid:88)
= σ2l′2  v i,s v i,s−2 l v i,s v t,s+ l2 v t,s v t,s
s=1 s=1 s=1 t,s t,s t,s
 
l′ l′
1 (cid:88) 2(cid:88) 1 (cid:88)
=
σ2l′2
 ∥v i,s∥2−
l
∥v i,s∥2+
l2
∥v t,s∥2 +o(d)
s=1 s=1 t,s
Similarly,wecangetthefollowing:
 
l l′
1 (cid:88) 2 (cid:88) 1 (cid:88)
∥v j′∥2 2 = σ2l2  ∥v t,j∥2− l′ ∥v t,j∥2+ l′2 ∥v t,s∥2 +o(d)
t=1 t=1 t,s
16TowardsCompositionalityinConceptLearning
√ √
ByLemmaB.2,thenormofeachv isboundedby d−ϵand d+ϵwithhighprobability,sotheaboveformulacanbe
i,j
boundedby:
1 √ 1 √
((l−1)d−(2l+6) dϵ+(l−1)ϵ2)+o(d)≤∥v ∥2 ≤ ((l−1)d+(2l+6) dϵ+(l−1)ϵ2)+o(d),
σ2ll′ i 2 σ2ll′
Therefore,
∥v ∥2 =O(d) (7)
i 2
andwecanequivalentlyshowthat∥v′∥=O(d).
j
Asaconsequence,wecannowcalculatethecosinesimilaritybetweenv andv′:
i j
S (v ,v′)=
⟨v i,v j′⟩
=
o(d)
=o(1),
cos i j ∥v ∥·∥v′∥ O(d)
i j
whichmeansthatthisconvergestozeroasdesired.
Corollary B.4. Given Theorem 3.1, for the representation of the composite concepts v , it can be (approximately)
i,j
decomposedintothelinearcombinationsoftherepresentationsofthebaseconcepts(afterthecenteringoperation),v ,v
i j
butisorthogonaltotherepresentationsofotherbaseconceptswithhighprobability. Inotherwords,compositionalityholds
withhighprobability.
Proof. Toprovethis,letusconsiderthecosinesimilaritybetweenv andv .
i,j t
AccordingtoEquation2,wefirstcomputetheinnerproductbetweenthesetwovectors,i.e.:
l′
1 (cid:88)
⟨v ,v ⟩= ⟨v ,v ⟩, (8)
i,j t l′ i,j t,n
n=1
Dependingonwhethert=iornot,therearetwodifferentcases.
Case1:t̸=i NotethataccordingtoLemmaB.2,sincev andv aretwowvectorsrandomlysampledfromthespherical
i,j t,n
normaldistribution,theirinnerproductiso(d). Therefore,theaboveinnerproductbetweenv andv becomes:
i,j t
⟨v ,µ ⟩=o(d).
i,j t
Also note that according to Equation 4, v = vˆt−µ, we thus need to leverage this equation to derive the inner product
t σ
betweenv andv . Furthermore,accordingtoequation3,µisthemeanofalltherepresentationsofthecompositeconcepts,
i,j t
whichareallrandomlysampledfromasphericalnormaldistribution. Therefore,µisapproaching0withhighprobability
andthusthefollowingequationholdswithhighprobability:
vˆ −µ vˆ
⟨v ,v ⟩=⟨v , t ⟩=⟨v , t⟩=o(d),t̸=i.
i,j t i,j σ i,j σ
√
In addition, according to Lemma B.2 and Equation 7, the norms of v and v are both O( d). Therefore, the cosine
i,j t
similaritybetweenv andv :
i,j t
⟨v ,v ⟩ o(d) o(d)
cosine(v ,v )= i,j t = = =o(1).
i,j t ∥v ∥·∥v ∥ ∥v ∥·∥v ∥ O(d)
i,j t i,j t
Intuitively speaking, this indicates that for the representation of a composite concept v , it is not correlated with the
i,j
representationofabaseconceptthatdoesnotappearinthiscompositeconceptwithhighprobability. Forexample,this
could mean that the representation of the composite concept {c ,c } is not correlated to the representation of the
red sphere
conceptc ,whichisintuitivelytrue.
blue
17TowardsCompositionalityinConceptLearning
Case2: t=i InEquation8,accordingtoLemmaB.2,theinnerproductbetweenv andmostv iso(d)exceptwhen
i,j t,m
j =m. Therefore,Equation8becomes:
⟨v ,v ⟩=∥v ∥2+o(d),
i,j t i,j 2
√
ThenaccordingtoLemmaB.2,since∥v ∥isapproaching d,thentheaboveformulaistransformedto:
i,j
⟨v ,v ⟩=O(d),
i,j t
√
ThenaccordingtoLemmaB.2andEquation7,thenormsofv andv arebothO( d). Therefore,thecosinesimilarity
i,j t
betweenv andv is:
i,j t
⟨v ,v ⟩ O(d) O(d)
cosine(v ,v )= i,j t = = =O(1),
i,j t ∥v ∥·∥v ∥ ∥v ∥·∥v ∥ O(d)
i,j t i,j t
whichisthusanonzerovalue.
As indicated by the above analysis, we can conclude that each v is only correlated to the representation of the base
i,j
conceptsv ,andv′. Sincetherepresentationsofthosebaseconceptsarefromdifferentattributes,thusorthogonaltoeach
i j
other,thenwecanregardthemasthebasisvectorsinthevectorspace,whichcanthenbelinearlycombinedtoapproximately
reconstructv ,i.e.:
i,j
v =cosine(v ,v )v +cosine(v ,v′)v′
i,j i,j i i i,j j j
Thisthusmatchesthedefinitionofthecompositionality(seeDefinition2.2).
Theorem B.5. For some dataset, consider two attributes A and A′ where we have l concepts for A, c ,...,c , and l′
1 l
conceptsforA′,c′,...,c′ . Definenormalizedconceptrepresentationsv ,...,v andv′,...,v′ fortheconceptsinAand
1 l′ 1 l 1 l′
A′suchthatv isorthogonaltov′ foralliandj andforv andsamplesxandx′suchthatxhasconceptc andx′does
i j i i
not,thenS (x,v )>S (x′,v ). Thentheconceptrepresentationsarecompositional.
cos i cos i
Proof. Letv betheconceptrepresentationforc andv′ betheconceptrepresentationforc′. Wearegiventhatforanytwo
i i j j
samplesxandx′withandwithoutconceptc respectively,S (x,v )>S (x′,v )andsimilarlyforanytwosamplesx
i cos i cos i
andx′withandwithoutconceptc′ respectively,S (x,v′)>S (x′,v′). Wewillshowthataconceptrepresentationfor
j cos j cos j
c ,thecompositionofconceptc andc′,existsandisrepresentedbyv =v +v′.
i,j i j i,j i j
Letv =v +v′. Wewillshowthatthisconceptcanperfectlyranksampleswiththeconceptc . Sincev andv′ resultin
i,j i j i,j i j
perfectrankings,forallx,x′suchthatxhasc andx′doesnot,S (x,v )−S (x′,v )>0. Similarly,foranyx,x′such
i cos i cos i
thatxhasc′ andx′doesnot,S (x,v′)−S (x′,v′)>0.
j cos j cos j
Nowlet,x,x′besuchthatxhasconceptc andx′doesnot. Wecanwritethefollowing:
i,j
⟨x,v +v′⟩
S (x,v +v′)= i j
cos i j ∥x∥∥v +v′∥
i j
⟨x,v ⟩+⟨x,v′⟩
= i √ j Since⟨v ,v′⟩=0,⟨v ,v ⟩=1,and⟨v′,v′⟩=1
i j i i j j
∥x∥ 2
1
= √ (S (x,v )+S (x,v′))
cos i cos j
2
Therefore,wecannowshowthattheconceptscoreforthecomposedconceptislargerforxthanx′:
1 1
S (x,v +v′)−S (x′,v +v′)= √ (S (x,v )+S (x,v′))− √ (S (x′,v )+S (x′,v′))
cos i j cos i j cos i cos j cos i cos j
2 2
= √1 (cid:0) (S (x,v )−S (x′,v ))+(S (x,v′)−S (x′,v′))(cid:1)
cos i cos i cos j cos j
2
>0.
18TowardsCompositionalityinConceptLearning
truth 1.0 -0.15 0.18 -0.04
animal -0.15 1.0 -0.61 -0.41
company 0.18 -0.61 1.0 -0.47
invention -0.04 -0.41 -0.47 1.0
truth animal company invention
(a)CUB-sub (b)Truth-sub
Figure7. CompositionalityofGround-TruthConceptsfortheCUB-subandTruth-subdatasets.
C.CompositionalityofGround-TruthConcepts
ThecosinesimilaritiesbetweenconceptsisshownfortheCUB-subandTruth-subdatasetsinFigure7. Weseesimilar
findingsasinFigure2b.
D.QualitativeExamples
WeprovideadditionalqualitativeresultsfortheCUBdatasetinFigure8andtheImageNet(Russakovskyetal.,2015)
validationsetinFigure9. Theconceptsarenamedbymanuallylookingatthetop20imagesforeachconceptandcoming
upwithashortdescriptionwhichisasspecificaspossibletotheimageswhilebeinggeneralenoughtoapplytoeachimage.
Asanalternativetomanualconceptlabelling,wealsoexperimentedwithusingavision-textlanguagemodeltoautomatically
nameconceptsfromtheirtop20examples. WeusedGPT-4o(gpt)togetconceptlabels. Foreachconcept,weproducea
singleimagecontainingthetop20samplesfortheconceptandwepasstheimagetoGPT-4owiththefollowingprompt:
You are given 20 images representing a single concept and your task is to label
the name of the concept from just the 20 images. First, output a detailed caption
for each image. Then output a concept name which is specific to the images but
summarizes what is common among all of them. For example, for images of red cars
in different environments and positions, the concept name could be ’Red cars’.
Output the name of the concept after ’Concept Name:’.
ThelabelsfortheadditionalCUBexamplesinFigure8arethefollowingwhereeachlinelabelsarowofthefigure:
Hummingbirds, Birds, Hummingbirds
Black Birds, Birds in Natural Habitats, Black Birds
Wrens, Birds with food in their beaks, Wrens
Seagulls, Birds with food in their beaks, Birds with fish in their beaks
Similarly,thelabelsfromGPT-4oforFigure9arethefollowing:
Dogs, Sleeping in various environments, Sleeping Dogs
Reptiles and Amphibians in Natural Habitats, Pairs of Dogs, Pairs of Animals
Wild Animals, Pairs of Dogs, Animals in Pairs
Waterfront Structures and Transportation,
Outdoor Activities and Wildlife,
British Heritage and Infrastructure
19TowardsCompositionalityinConceptLearning
Tools and Objects in Close-Up,
Laboratory and Scientific Equipment,
Vintage and Everyday Objects
E.Additionalquantitativeresults
E.1.Runtimeanalysis
Table4. Runtimesinseconds
Dataset PCA ACE DictLearn SemiNMF CT CCE
CLEVR 0.10±0.12 0.02±0.00 28.65±0.29 8.13±1.03 63.66±0.73 190.98±2.38
CUB-sub 0.11±0.15 0.03±0.01 14.38±0.15 3.99±0.09 6.89±0.15 112.73±2.67
CUB 0.84±0.06 0.46±0.03 51.53±1.51 25.85±0.22 495.49±10.81 207.17±0.70
Truth-sub 0.16±0.03 0.06±0.02 43.36±4.35 29.83±0.62 165.06±1.21 316.45±2.63
Truth 1.10±0.16 2.64±0.09 88.81±6.54 194.67±10.18 712.16±7.70 1574.88±17.68
HAM 1.89±0.03 2.97±0.03 367.67±8.71 165.80±2.22 693.73±1.88 7460.52±47.95
News 3.28±0.72 25.75±2.39 241.75±38.70 934.69±117.66 431.78±7.11 7947.31±70.64
E.2.Downstreamperformanceerrorbars
WeincludeerrorbarsforthedownstreamperformanceresultsusingthegreatestnumberofconceptsinTable5.
Table5.Errorbarsofthedownstreamperformance(%). Threedecimalplacesaregivenwhennecessarytoshownon-zerostandard
deviation.
Method CUB Truth HAM News
PCA 72.71±0.01 87.137±0.000 77.42±0.01 62.029±0.001
ACE 74.99±0.06 87.161±0.001 78.67±0.12 57.019±0.004
DictLearn 75.33±0.07 87.500±0.002 79.65±0.01 61.015±0.002
SemiNMF 75.81±0.11 87.355±0.001 76.30±0.03 62.215±0.002
CT 65.60±0.12 84.520±0.004 72.71±0.06 47.207±0.007
CCE 76.49±0.47 87.888±0.001 80.05±0.01 61.670±0.003
E.3.AblationonregularizationinCCE
ToseetheimpactoftheregularizationstepintheLearnSubspacestepofCCE,weperformananadditionalablationonthe
CLEVRdataset. WecompareCCEwithoutthisregularizationsteptothefullimplementationofCCEinTable6,andwesee
thatregularizationimprovesallthreemetrics.
E.4.Ablationonclusteringlossfunction
WeperformanablationontheuseoftheSilhouettescoreasourclusteringloss. InsteadofSilhouetteweexperimentwith
thecrossentropylossbasedonthetechniquefromCaronetal.(2018),butourresultsinTable7showthattheSilhouette
resultsinbettercompositionality.
Table6. RegularizationablationonCLEVR.
Method MAP Comp. Score MeanCosine
CCE 1.00±0.00 3.41±0.18 0.99±0.00
CCE-NoReg 0.97±0.03 3.81±0.21 0.78±0.09
20TowardsCompositionalityinConceptLearning
White birds Eating birds White birds eating
Brown birds Eating birds Brown birds eating
Humming birds Framed birds Framed humming birds
Black birds Foliage Black birds in foliage
Figure8. AdditionalCUBqualitativeexamples.
21TowardsCompositionalityinConceptLearning
Dogs Sleeping Dogs sleeping
Pairs of
Insects/Reptiles/ Insects/Reptiles/
Amphibians/Birds Pairs Amphibians/Birds
Wild animals Pairs Pairs of wild animals
Bridges/ships Green foliage Bridges with green
Artistic photography Scientific Artistic and scientific
Figure9. ImageNetqualitativeexamples.
22TowardsCompositionalityinConceptLearning
Table7. LossfunctionablationonCLEVR.
Dataset Loss MAP Comp. Score MeanCosine
CLEVR Silhouette 1.00±0.00 3.41±0.18 0.99±0.00
CLEVR CrossEntropy 0.94±0.08 3.44±0.14 0.89±0.10
Truth-sub Silhouette 0.56±0.02 3.68±0.01 0.81±0.01
Truth-sub CrossEntropy 0.50±0.04 3.94±0.04 0.75±0.02
CUB-sub Silhouette 0.65±0.01 0.48±0.00 0.77±0.01
CUB-sub CrossEntropy 0.62±0.04 0.49±0.00 0.76±0.01
1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Fraction of red samples removed
Figure10.Cosinesimilaritybetweendiscovered“red”conceptandtheground-truth“red”conceptafterremovingacertainfractionofthe
redsamplesinthetrainingset.Astheattributeimbalancebecomeslarger,meaningtherearelessredsamplesthanothercoloredsamples,
CCEperformsworseatfindingthetrueredconcept.
23
TG
htiw
ytiralimis
enisoc
naeMTowardsCompositionalityinConceptLearning
E.5.Ablationonattributeimbalance
WeperformanablationexperimentontheeffectofattributeimbalancebytestingCCE’sabilitytorecoverthegroundtruth
conceptsontheCLEVRdatasetafterremovingdifferentfractionsofsampleslabeledwiththe“red”concept. Theresultsare
showninFigure10whereweseethatremovingmoreredsamples,whichcreatesagreaterimbalance,decreasestheaverage
cosinesimilarityofthediscoveredconceptswiththegroundtruth.
E.6.ROC-AUCScoresbetweenConceptRepresentationsandGround-Truth
ThemaximumROC-AUCbetweentheconceptscoreandthetruelabelfortheground-truthconceptsispresentedinTable8
forCLEVR,Table9forCUB-sub,andTable10forTruth-sub.
Table8. MaxAUCscoreCLEVRv/sGT
Concepts CCE ACE ACE PCA DictLearn SemiNMF
red 1.000 0.765 0.728 0.985 0.757 0.793
green 1.000 0.771 0.711 0.996 0.797 0.818
blue 1.000 0.753 0.745 0.972 0.782 0.836
sphere 1.000 1.000 0.736 1.000 1.000 1.000
cube 1.000 0.998 0.742 0.971 0.994 0.999
cylinder 1.000 0.998 0.831 0.977 0.992 0.998
(redandsphere)object 0.987 0.993 0.911 0.950 0.978 0.983
(redandcube)object 0.923 0.999 1.000 0.965 0.983 0.999
(redandcylinder)object 0.899 0.940 0.932 0.964 0.998 0.943
(greenandsphere)object 0.858 0.991 0.870 0.863 0.980 0.986
(greenandcube)object 0.878 1.000 1.000 0.877 0.951 1.000
(greenandcylinder)object 0.936 0.916 0.960 0.969 1.000 0.994
(blueandsphere)object 0.952 0.996 1.000 0.834 0.940 0.997
(blueandcube)object 0.878 1.000 1.000 0.973 0.842 0.978
(blueandcylinder)object 0.923 0.992 1.000 0.990 0.995 0.995
Table9. ROCAUCofbaselinemethodsonrecoveringthelabeledconcepts.
Method Brown White Black Small Medium Large
GT 0.984 0.999 0.998 1.000 0.923 0.847
PCA 0.881 0.985 0.931 0.997 0.886 0.677
ACE 0.895 0.785 0.677 0.726 0.584 0.678
DictLearn 0.849 0.645 0.650 0.702 0.519 0.551
SemiNMF 0.086 0.164 0.099 0.116 0.066 0.168
CT 0.923 0.837 0.887 0.926 0.754 0.736
Random 0.867 0.933 0.855 0.888 0.849 0.723
CCE 0.894 0.834 0.710 0.743 0.656 0.661
E.7.Theanalysisofthecosinesimilarityscorebetweenlearnedconceptrepresentationsandground-truth
WefurtherbreakdowntheresultsreportedinTable3averagecosinesimilaritybetweenthelearnedconceptrepresentation
andtheground-truthconceptrepresentations.
E.8.Ablationstudiesonotherpretrainedmodels
Recallthatintheexperimentsection,weprimarilyfocusondiscoveringconceptsfrompretrainedCLIPmodel. Inthis
section,westudywithdifferentchoicesofpretrainedmodels,canweobtainsimilarresultsasthatinSection5?
Toanswerthisquestion,weleveragevisiontransformer(ViT),anotherwidelyusedpretrainedvisionmodel,torepeatthe
24TowardsCompositionalityinConceptLearning
Table10. ROCAUCofbaselinemethodsonrecoveringthelabeledconcepts.
Method Truth Animal Company Invention
GT 0.91 1.00 1.00 1.00
PCA 0.829 0.917 0.832 0.863
ACE 0.777 0.999 0.941 0.795
DictLearn 0.353 0.734 0.627 0.539
SemiNMF 0.759 0.708 0.629 0.521
CCE 0.91 1.00 0.96 0.78
Table11. MaxAUCscoreCLEVRv/sGTViT
Concepts CCE ACE PCA DictLearn SemiNMF
red 1.000 0.735 0.945 0.710 0.712
green 1.000 0.711 0.922 0.716 0.680
blue 1.000 0.642 0.995 0.704 0.629
sphere 1.000 0.610 1.000 1.000 1.000
cube 1.000 0.735 0.970 0.999 1.000
cylinder 1.000 0.695 1.000 1.000 1.000
(redandsphere)object 0.972 1.000 0.980 0.997 0.991
(redandcube)object 0.884 0.720 0.881 0.992 0.967
(redandcylinder)object 0.933 0.837 0.962 0.998 1.000
(greenandsphere)object 0.904 1.000 0.923 0.998 0.985
(greenandcube)object 0.913 0.731 0.886 0.920 0.937
(greenandcylinder)object 0.895 0.660 0.866 0.988 0.939
(blueandsphere)object 0.939 0.844 0.970 0.954 0.949
(blueandcube)object 0.825 0.770 0.905 0.838 0.851
(blueandcylinder)object 0.854 0.766 0.842 0.913 0.875
experimentsonCLEVRdataset. TheresultsaresummarizedinTable12-13. Theresultsfromthesetablesmaintainthe
sametrendsastheoneshowninSection5.
Table12. ViTresultsonCLEVR
Method MAP Comp. Score MeanCosine
GT 1.00±0.00 3.69±0.00 1.00±0.00
PCA 0.90±0.00 4.33±0.00 0.64±0.00
ACE 0.70±0.05 4.36±0.11 0.67±0.00
DictLearn 0.80±0.04 3.98±0.06 0.70±0.01
SemiNMF 0.76±0.01 4.29±0.02 0.67±0.00
CT 0.58±0.05 6.26±0.00 0.04±0.01
Random 0.64±0.03 6.26±0.00 0.05±0.00
CCE 1.00±0.00 3.87±0.25 1.00±0.00
F.DatasetDetails
WeprovidethedetailsforalldatasetsinTable15.
G.Hyperparameters
ThehyperparametersofallexperimentsaregiveninTable16.
25TowardsCompositionalityinConceptLearning
Table13. ResNet-50resultsonCLEVR
Method MAP Comp. Score MeanCosine
GT 0.95±0.00 1.77±0.00 1.00±0.00
PCA 0.90±0.00 2.08±0.00 0.58±0.00
ACE 0.77±0.04 1.92±0.02 0.68±0.01
DictLearn 0.71±0.08 1.95±0.11 0.68±0.01
SemiNMF 0.64±0.00 2.01±0.01 0.69±0.00
CT 0.63±0.08 2.83±0.00 0.03±0.00
Random 0.57±0.03 2.83±0.00 0.03±0.00
CCE 0.92±0.01 1.78±0.01 0.96±0.04
Table14. Cosinesimilarityofbaselinemethodsforrecoveringthelabeledconcepts.
Method Truth Animal Company Invention
PCA 0.367 0.139 0.688 0.583
ACE 0.244 0.956 0.733 0.642
DictLearn 0.760 0.988 0.917 0.879
SemiNMF 0.824 0.898 0.931 0.725
CCE 0.90 0.94 0.85 0.64
Table15. Datasetdetailsforallexperiments
Dataset TotalSamples NumberofGTConcepts Modality
CLEVR 1001 6 Image
CUB 11788 NA Image
CUB-sub 261 6 Image
Truth 4127 NA Text
Truth-sub 1125 4 Text
HAM 10015 NA Image
News 18846 NA Text
Table16. Hyperparameters
Dataset K M learningrate
CLEVR 3 3 0.001
CUB 20 5 0.001
CUB-sub 5 4 0.1
Truth 12 10 0.001
Truth-sub [4,2,3] 3 0.001
HAM 20 25 0.02
News 15 30 0.001
26