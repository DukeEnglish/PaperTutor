1
Differential error feedback for
communication-efficient decentralized learning
Roula Nassif, Member, IEEE, Stefan Vlaski, Member, IEEE, Marco Carpentiero, Student Member, IEEE
Vincenzo Matta, Senior Member, IEEE, Ali H. Sayed, Fellow, IEEE
Abstract
Communication-constrainedalgorithmsfordecentralizedlearningandoptimizationrelyonlocalupdatescoupled
with the exchange of compressed signals. In this context, differential quantization is an effective technique to
mitigate the negative impact of compression by leveraging correlations between successive iterates. In addition, the
use of error feedback, which consists of incorporating the compression error into subsequent steps, is a powerful
mechanism to compensate for the bias caused by the compression. Under error feedback, performance guarantees
in the literature have so far focused on algorithms employing a fusion center or a special class of contractive
compressors that cannot be implemented with a finite number of bits. In this work, we propose a new decentralized
communication-efficient learning approach that blends differential quantization with error feedback. The approach
is specifically tailored for decentralized learning problems where agents have individual risk functions to minimize
subject to subspace constraints that require the minimizers across the network to lie in low-dimensional subspaces.
This constrained formulation includes consensus or single-task optimization as special cases, and allows for more
general task relatedness models such as multitask smoothness and coupled optimization. We show that, under some
general conditions on the compression noise, and for sufficiently small step-sizes µ, the resulting communication-
efficient strategy is stable both in terms of mean-square error and average bit rate: by reducing µ, it is possible to
keeptheestimationerrorssmall(ontheorderofµ)withoutincreasingindefinitelythebitrateasµ 0.Theresults
→
establish that, in the small step-size regime and with a finite number of bits, it is possible to attain the performance
achievable in the absence of compression.
Index Terms
Error feedback, differential quantization, compression operator, decentralized subspace projection, single-task
learning, multitask learning, mean-square-error analysis, bit rate analysis.
A short conference version of this work appears in [1]. This extended version includes proofs, derivations, and new results.
R. Nassif is with Universite´ Coˆte d’Azur, I3S Laboratory, CNRS, France (email: roula.nassif@unice.fr). S. Vlaski is with Imperial
College London, UK (e-mail: s.vlaski@imperial.ac.uk). M. Carpentiero and V. Matta are with University of Salerno, Italy (e-mail:
{mcarpentiero,vmatta}@unisa.it). A. H. Sayed is with the Institute of Electrical and Micro Engineering, EPFL, Switzerland (e-mail:
ali.sayed@epfl.ch).
4202
nuJ
62
]AM.sc[
1v81481.6042:viXra2
I. INTRODUCTION
Data is increasingly being collected in a distributed and streaming manner, in an environment where com-
munication and data privacy are becoming major concerns. In this context, centralized learning schemes with
fusion centers tend to be replaced by new paradigms, such as federated and decentralized learning [2]–[9]. In
these approaches, each participating device (which is referred to as agent or node) has a local training dataset,
which is never uploaded to the server. The training data is kept locally on users’ devices, and the devices act as
agents performing local computations to learn global models of interest. In applications where communication with
a server becomes a bottleneck, decentralized topologies (where agents only communicate with their neighbors)
become attractive alternatives to federated topologies (where a server connects with all remote devices). These
decentralizedimplementationsreducethecommunicationburdensincemodelupdatesareexchangedlocallybetween
agentswithoutrelyingonacentralcoordinator[6]–[11].Studieshaveshownthatdecentralizedapproachescanbeas
efficient as the centralized schemes when considering, for instance, steady-state mean-square-error performance [6],
[12].
In traditional decentralized implementations, agents need to exchange (possibly high-dimensional and dense)
parameter vectors at every iteration of the learning algorithm, leading to high communication costs. In modern
distributed networks comprising a massive number of devices (e.g., thousands of participating smartphones),
communication can be slower than local computation by many orders of magnitude (due to limited resources
such as energy and bandwidth). Designers are typically limited by an upload bandwidth of 1MB/s or less [2].
Therefore, in practice, if not addressed adequately, the scarcity of the communication resources may limit the
application of decentralized learning [13]. A variety of methods have been proposed to reduce the communication
overhead of decentralized learning. These methods can be divided into two main categories. In the first one,
communication is reduced by skipping communication rounds while performing a certain number of local updates
in between [2], [14], [15], thus trading-off communication overhead, computation, and learning performance. In the
secondone,informationiscompressedbyemployingeitherquantization(e.g.,employingditheredquantization[16]),
sparsification (e.g., employing top-k or rand-k sparsifiers [10]), or both (e.g., employing top-k combined with
dithering [17]), before being exchanged. Compression operators and learning algorithms are then jointly designed to
preventthecompressionerrorfromaccumulatingduringthelearningprocessandfromsignificantlydeterioratingthe
performanceofthedecentralizedapproach[10],[11],[18]–[28].Otherworksproposetocombinetheaforementioned
two categories to further reduce the communication overhead [29], [30].
In this work, we introduce a new communication-efficient approach for decentralized learning. The approach ex-
ploitsdifferentialquantizationanderrorfeedback tomitigatethenegativeimpactofcompressedcommunicationson
the learning performance. Differential quantization is a common technique for mitigating the impact of compression
by leveraging correlations between successive iterates. In this case, instead of communicating compressed versions
of the iterates, agents communicate compressed versions of the differences between current estimates and their3
predictions based on previous iterations. Several recent works have focused on studying the benefits of differential
quantization in the context of decentralized learning. For instance, the work [11] shows that, in a diminishing step-
size regime, differential quantization can reduce communication overhead without degrading muchthe learning rate.
In [31], it is shown that decentralized learning can achieve the same convergence rate as centralized learning in
non-convex settings, under very high accuracy constraints on the compression operators. The constraints are relaxed
in the study [27], which also assumes decentralized non-convex optimization. The work [29] studies the benefits of
differential quantization and event-triggered communications. The analysis shows that compression affects slightly
the convergence rate when gradients are bounded. Similar results are established in [30] under a weaker bounded
gradient dissimilarity assumption, and in [24] in the context of decentralized learning over directed graphs. The
works [21], [22], [26] study the benefits of differential quantization without imposing any assumptions on the
gradients, and by allowing for the use of combination matrices1 that are not symmetric [21], [22] or that have
matrix valued entries [26]. While the works [11], [21], [22], [24], [26], [27], [29]–[31] focus on studying primal
stochastic optimization techniques (that are based on propagating and estimating primal variables), the works [10],
[28] consider primal-dual techniques and the work [25] considers deterministic optimization.
Error feedback, on the other hand, consists of locally storing the compression error (i.e., the difference between
the input and output of the compression operator), and incorporating it into the next iteration. This technique has
been previously employed for stochastic gradient descent (SGD) algorithms. Specifically, it has been applied to the
SignSGD algorithm in the single-agent context under 1-bit quantization [32], and to the distributed SGD to handle
biased compression operators [17]. In the context of decentralized learning, the DeepSqueeze approach in [33] uses
error feedback without differential quantization.
In the current work, we show how to blend differential quantization and error feedback in order to obtain a
communication-efficient decentralized learning algorithm. First, we describe in Sec. II the decentralized learning
framework and the class of compression operators considered in the study. While most existing works on de-
centralized learning with compressed communications are focused on single-task or consensus algorithm design,
the design in the current work goes beyond this traditional focus by allowing for both single-task and multitask
implementations. In single-task learning, nodes collaborate to reach an agreement on a single parameter vector
(also referred to as task or objective) despite having different local data distributions. Multitask learning, on
the other hand, involves training multiple tasks simultaneously and exploiting their intrinsic relationship. This
approach offers several advantages, including improved network performance, especially when the tasks share
commonalities in their underlying features [9]. Compared with previous works, another contribution in the current
study is the consideration of a general class of compression operators. Specifically, rather than being confined to
the set of probabilistic unbiased operators as in [10], [21], [22], [26], [31], we allow for the use of biased (possibly
deterministic) compression operators. Moreover, while most existing works assume that some quantities (e.g., the
1As we will see, combination matrices in decentralized learning are used to control the exchange of information between neighboring
agents.4
norm or some components of the vector to be quantized) are represented with very high precision (e.g., machine
precision) and neglect the associated quantization error [10], [11], [21], [22], [24], [27]–[31], [33], the current
work incorporates realistic quantization models into the compression process and shows how to effectively manage
the errors and minimize their impact on the learning performance. In Secs. III and IV, we present and analyze
the proposed learning strategy. While there exist several theoretical works investigating communication-efficient
learning, the analysis in the current work is more general in the following sense. First, it considers a general class
of compression schemes. Moreover, unlike the studies in [10], [11], [25], [27]–[31], [33], it does not require the
combination matrices to be symmetric. We further allow the entries of the combination matrix to be matrix-valued
(as opposed to scalar valued as in traditional implementations) in order to solve general multitask optimization
problems. Finally, we do not assume bounded gradients as in [11], [24], [28], [29], [33]. For ease of reference, the
modeling conditions from this and related works are summarized in Table I. We establish in Sec. IV the mean-
square-error stability of the proposed decentralized communication-efficient approach. In addition to investigating
the mean-square-error stability, we characterize the steady-state average bit rate of the proposed approach when
variable-rate quantizers are used. The analysis shows that, by properly designing the quantization operators, the
iterates generated by the proposed approach lead to small estimation errors on the order of the step-size µ (as
it happens in the ideal case without compression), while concurrently guaranteeing a bounded average bit rate
as µ 0. Our theoretical findings show that, in the small step-size regime, the proposed strategy attains the
→
performance achievable in the absence of compression, despite the use of a finite number of bits. This demonstrates
the effectiveness of the approach in maintaining performance while reducing communication overhead. Finally, we
present in Sec. V experimental results illustrating the theoretical findings and showing that blending differential
compression and error feedback can achieve superior performance compared to state-of-the-art baselines.
Notation: All vectors are column vectors. Random quantities are denoted in boldface. Matrices are denoted in
uppercase letters while vectors and scalars are denoted in lowercase letters. The symbol ( ) denotes matrix
⊤
·
transposition. The operator col stacks the column vector entries on top of each other. The operator diag forms
{·} {·}
a matrix from block arguments by placing each block immediately below and to the right of its predecessor. The
symbol denotes the Kronecker product. The ceiling and floor functions are denoted by and , respectively.
⊗ ⌈·⌉ ⌊·⌋
The M M identity matrix is denoted by I . The abbreviation “w.p.” is used for “with probability”. The notation
M
×
α = O(µ) signifies that there exist two positive constants c and µ such that α cµ for all µ µ . Vectors or
0 0
| | ≤ ≤
matrices of all zeros are denoted by 0.
II. PROBLEM SETUP
In this section, we formally state the decentralized optimization problem and introduce strategies, quantities, and
assumptions that will be used in subsequent sections.5
TABLE I
COMPARISONOFMODELINGASSUMPTIONSFORDECENTRALIZEDSTOCHASTICOPTIMIZATIONSTUDIES.ALLWORKSEMPLOY
DIFFERENTIALQUANTIZATIONWITHOUTERRORFEEDBACK,EXCEPTTHEONEMARKEDWITH⋆ANDOURWORK.WHILETHEWORK
WITH⋆USESERRORFEEDBACK,OURWORKEMPLOYSERRORFEEDBACKWITHDIFFERENTIALQUANTIZATION.ALLWORKSASSUME
THATSOMEQUANTITIESAREEXCHANGEDWITHVERYHIGHPRECISION,EXCEPTTHEONEMARKEDWITH†ANDTHISWORK.WEUSE
THESYMBOL–INTHELASTCOLUMNFORWORKSTHATDONOTHAVEBOUNDEDGRADIENTASSUMPTIONS.
Reference Stochasticoptimizationcontext Combinationmatrix Compressionoperator Step-size Gradientassumption
[11] Primal,consensus-type Symmetric Canbedeterministic&biased Diminishing Bounded
[10] Primal-dual,consensus-type Symmetric Probabilistic&unbiased Constant –
[29] Primal,consensus-type Symmetric Canbedeterministic&biased Diminishing Bounded
[30] Primal,consensus-type Symmetric Canbedeterministic&biased Constant Boundeddissimilarities
[28] Primal-dual,multitask Symmetric Canbedeterministic&biased Constant Bounded
[31] Primal,consensus-type Symmetric Probabilistic&unbiased Constant –
[27] Primal,consensus-type Symmetric Canbedeterministic&biased Constant –
[24] Primal,consensus-type Canbenon-symmetric Probabilistic&unbiased Constant Bounded
[33]⋆ Primal,consensus-type Symmetric Canbedeterministic&biased Constant Boundeddissimilarities
[21] Primal,consensus-type Canbenon-symmetric Probabilistic&unbiased Constant –
Canbenon-symmetric Probabilistic&unbiased
[26]† Primal,consensus-type&multitask Constant –
withmatrix-valuedblockentries nohighprecisionrepresentations
Canbenon-symmetric Canbedeterministic&biased
Thiswork Primal,consensus-type&multitask Constant –
withmatrix-valuedblockentries nohighprecisionrepresentations
A. Decentralized optimization under subspace constraints
Weconsideraconnectedgraph(ornetwork) ( , ),where and denotethesetofK agentsornodes(labeled
G V E V E
k = 1,...,K) and the set of possible communication links or edges, respectively. Let w
k
RMk denote some
∈
parametervectoratagentkandlet = col w ,...,w denotetheM-dimensionalvector(whereM = K M )
W { 1 K } k=1 k
collectingtheparametervectorsfromacrossthenetwork.Weassociatewitheachagentk adifferentiablec(cid:80)onvexrisk
J k(w k) : RMk
→
R,expressedastheexpectationofsomelossfunctionL k( ·)andwrittenasJ k(w k) = EL k(w k;y k),
where y denotes the random data at agent k. The expectation is computed relative to the distribution of the local
k
data. In the stochastic setting, when the data distribution is unknown, the risks J ( ) and their gradients J ( )
k
·
∇wk k
·
are unknown. In this case, instead of using the true gradient, it is common to use approximate gradient vectors
(cid:92)
based on the loss functions such as J (w ) = L (w ;y ) where y represents the data observed at
∇wk k k ∇wk k k k,i k,i
iteration i [6], [34].
In traditional single-task or consensus problems, agents need to agree on a common parameter vector (also called
model or task) corresponding to the minimizer of the following weighted sum of individual risks:
K
1
wo = arg min J (w), (1)
k
w RMc K
∈ k=1
(cid:88)
where M represents a common vector length, i.e., in this case, the dimensions M for all agents are identical
c k
and equal to M . Moreover, w is the global parameter vector, which all agents need to agree upon. Each agent
c6
seeks to estimate wo through local computations and communications among neighboring agents without the need
to know any of the risks or losses besides its own. Among many useful strategies that have been proposed in the
literature [6]–[8], [35]–[37], diffusion strategies [6]–[8] are particularly attractive since they are scalable, robust,
and enable continuous learning and adaptation in response to drifts in the location of the minimizer.
In this work, instead of considering the single-task formulation (1), we consider a generalization that allows the
network to solve multitask optimization problems. Multitask learning is suitable for network applications where
differences in the data distributions require more complex models and more flexible algorithms than single-task
implementations.Inmultitasknetworks,agentsgenerallyneedtoestimateandtrackmultipledistinct,thoughrelated,
modelsorobjectives.Forinstance,indistributedpowersystemstateestimation,thelocalstatevectorstobeestimated
at neighboring control centers may overlap partially since the areas in a power system are interconnected [38].
Likewise, in weather forecasting applications, regional differences in the collected data distributions require agents
to exploit the correlation profile in the data for enhanced decision rules [39]. Existing strategies to address multitask
problemsgenerallyexploitpriorknowledgeonhowthetasksacrossthenetworkrelatetoeachother[9].Forexample,
one way to model relationships among tasks is to formulate convex optimization problems with appropriate co-
regularizers between neighboring agents [9], [39]. Another way to leverage the relationships among tasks is to
constrain the model parameters to lie within certain subspaces that can represent for instance shared latent patterns
thatarecommonacrosstasks[9],[40],[41].Thechoicebetweenthesetechniquesdependsingeneralonthespecific
characteristics of the tasks and the desired trade-offs between model complexity and performance [9], [41].
In this work, we study decentralized learning under subspace constraints in the presence of compressed com-
munications. Specifically, we consider inference problems of the form:
K
o =argmin J (w ),
k k
W W (2)
k=1
(cid:88)
subject to Range( )
W ∈ U
where the matrix is an M P full-column rank matrix (with P M) assumed to be semi-unitary, i.e., its
U × ≪
columns are orthonormal ( = I ). By using the stochastic gradient of the individual risk J (w ), agent k
⊤ P k k
U U
seeks to estimate the k th M 1 subvector wo of the network vector o = col wo,...,wo , which is required
− k × k W { 1 K}
to lie in a low-dimensional subspace. While the objective in (2) is additively separable, the subspace constraint
couples the models across the agents. Constrained formulations of the form (2) have been studied previously in
decentralizedsettingswherecommunicationconstraintsareabsent[40],[42].Asexplainedin[9],[42],[40,Sec.II],
byproperlyselectingthematrix ,formulation(2)canbetailoredtoaddressawiderangeofoptimizationproblems
U
encountered in network applications. Examples include i) consensus or single-task optimization (where the agents’
objective is to reach consensus on the minimizer wo in (1)), ii) decentralized coupled optimization (where the
parameter vectors to be estimated at neighboring agents are partially overlapping) [38], [41], [43], [44], and iii)
multitask inference under smoothness (where the network parameter vector to be estimated is required to be
W
smooth w.r.t. the underlying network topology) [39], [40]. For instance, setting in (2) = 1 (1 I ) where
U √K K ⊗ Mc7
1 is the K 1 vector of all ones, we obtain an optimization problem equivalent to the consensus problem (1).
K
×
While projecting onto the space spanned by the vector of all ones allows to enforce consensus across the network,
graph smoothness can in general be promoted by projecting onto the space spanned by the eigenvectors of the
graph Laplacian corresponding to small eigenvalues [9], [40], [42].
B. Decentralized diffusion-based approach
To solve problem (2) in a decentralized manner, we consider the primal approach proposed and studied in [12],
[40], namely,
(cid:92)
ψ = w µ J (w ) (3a)
k,i k,i −1 − ∇wk k k,i −1

w = A ψ (3b)
  k,i kℓ ℓ,i

ℓ (cid:88)∈Nk
where denotes the set of nodes co nnected to agent k by a communication link (including node k itself) and
k 
N
µ > 0 is a small step-size parameter. Note that the information sharing across agents in (3) is implemented by
means of a K K block combination matrix = [A ] that has a zero M M block element (k,ℓ) if nodes k
kℓ k ℓ
× A ×
and ℓ are not neighbors, i.e., A = 0 if ℓ / , and satisfies the following conditions [40]:
kℓ k
∈ N
= , = , and ρ( ) < 1, (4)
AU U U⊤ A U⊤ A−PU
where ρ( ) denotes the spectral radius of its matrix argument, and = is the orthogonal projection matrix
· PU UU⊤
onto Range( ). It is shown [12], [42] how combination matrices satisfying (4) can be constructed. If strategy (3)
U A
is employed to solve the single-task problem (1), we can select the combination matrix in the form A I ,
A ⊗
Mc
where A = [a ] is a K K doubly-stochastic matrix satisfying:
kℓ
×
a 0, A1 = 1 , 1 A = 1 , a = 0 if ℓ / , (5)
kℓ
≥
K K ⊤K ⊤K kℓ
∈
Nk
In this case, conditions (4) are satisfied for = 1 (1 I ) [40] and strategy (3) reduces to the standard
U √K K ⊗ Mc
diffusion Adapt-Then-Combine (ATC) approach [6]–[8]:
(cid:92)
ψ = w µ J (w ) (6a)
k,i k,i −1 − ∇wk k k,i −1

w = a ψ (6b)
  k,i kℓ ℓ,i

ℓ (cid:88)∈Nk
Thisfactmotivatestheuseofthetermin ology“diffusionAdapt-Then-Combine(ATC)approach”inthesequelwhen

referring to the decentralized strategy (3) for solving general constrained optimization problems of the form (2).
Thefirststep(3a)intheATCapproach(3)istheself-learningstepcorrespondingtothestochasticgradientdescent
step on the individual risk J ( ). This step is followed by the social learning step (3b) where agent k receives the
k
·
intermediate estimates ψ from its neighbors ℓ and combines them through A to form w , which
{ ℓ,i} ∈ Nk { kℓ } k,i
corresponds to the estimate of wo at agent k and iteration i. To alleviate the communication bottleneck resulting
k
from the exchange of the intermediate estimates among agents over many iterations, compressed communication8
must be considered. Before presenting the communication-efficient variant of the ATC approach (3), we describe
in the following the class of compression operators considered in this study.
C. Compression operator
For the sake of clarity, we first introduce the following formal definitions for key concepts relating to data
compression.
Definition 1. (Compression operator). Let L represent a generic vector length. A compression operator : RL
C →
RL associates to every input x RL a random quantity (x) RL that is governed by the conditional probability
∈ C ∈
measure P( x).
·|
Note that the above family of compression operators includes deterministic mappings as a particular case.
Definition 2. (Bounded-distortion compression operator). A bounded-distortion compression operator is a com-
pression operator that fulfills the property:
E x (x) 2 β2 x 2+σ2, (7)
∥ −C ∥ ≤ c∥ ∥ c
for some β2 0 and σ2 0, and where the expectation is taken over the conditional probability measure P( x).
c ≥ c ≥ ·|
Definition 3. (Unbiased compression operator). An unbiased compression operator is a compression operator
that fulfills the property:
E[ (x)] = x. (8)
C
Inthisstudy,weconsiderbounded-distortioncompressionoperators.TableIIprovidesalistofbounded-distortion
operators commonly used in decentralized learning, with the corresponding compression noise parameters β2 and
c
σ2, and the bit-budget required to encode an input vector x RL. By comparing the reported schemes, we observe
c ∈
that the “rand-c”, “randomized Gossip”, and “top-c” can be considered as sparsifiers that map a full vector into
a sparse version thereof. For instance, the rand-c scheme selects randomly c components of the input vector and
encodes them with very high precision (32 or 64 bits are typical values for encoding a scalar). These bits are then
communicated over the links in addition to the bits encoding the locations of the selected entries. On the other
hand, the QSGD scheme encodes the norm of the input vector with very high precision. In addition to encoding the
norm, L-bits are used to encode the signs of the input vector components and L log (s) to encode the levels. In
⌈ 2 ⌉
comparison, the probabilistic uniform and probabilistic ANQ quantizers do not make any assumptions on the high-
precision representation of specific variables. In the following, we highlight the key facts regarding the compression
operators considered in this study.
1) Allowing for an absolute compression noise term: Many existing works focus on studying decentralized
learning in the presence of bounded-distortion compression operators that satisfy condition (7) with the absolute
noise term σ2 = 0 [10], [11], [21], [22], [24], [27]–[31], [33]. In contrast, the analysis in the current work is
c9
TABLE II
EXAMPLESOFBOUNDED-DISTORTIONCOMPRESSIONOPERATORS.FOREACHSCHEME,WEREPORTTHECOMPRESSIONRULE,THE
PARAMETERSβ c2 ANDσ c2 IN(7),ANDTHEBIT-BUDGET.B HP DENOTESTHENUMBEROFBITSREQUIREDTOENCODEASCALARWITH
HIGHPRECISION(TYPICALVALUESFORB
HP
ARE32OR64).THEOPERATORMARKEDWITH†ISDETERMINISTIC.THEOPERATORS
MARKEDWITH⋆AREUNBIASED.
Name Rule βc2 σc2 Bit-budget
Nocompression[40] C(x)=x 0 0 LBHP
[C(x)]j=∆ ·n(xj)
Proba ob ril dis itt hic eru en diform n(xj)= 

mm,
+1,
ww .. pp .. x(m j−+ ∆m1 ∆) ∆∆− ,xj, m=(cid:106)x ∆j(cid:107) 0 L∆ 42 r(x)definedin(9)
quantizer⋆[16],[23] ∆isthequantizationstep
[C(x)]j=yn(xj)
ProbabilisticANQ⋆[25]
n(xj)= 

mm,
+1,
ww .. pp .. y yy m mm xj+ ++ −1 11 y− −− my yx m mj ,
,
m=    sign(xj) 2ll nn (cid:18)(cid:16) 1 ω+ +ω (cid:113)η 1|x +j ω|(cid:17) 2(cid:19)   

2ω2 2Lη2 r(x)definedin(9)
ym=sign(m) ωη (cid:20)(cid:16) ω+(cid:112) 1+ω2(cid:17)2|m| −1(cid:21)
ωandηaretwonon-negativedesignparameters
 
Rand-c[10],[11]
[C(x)]j=α ·

x 0,j, i of thx ej rw∈ iseΩc whereα=

1
L
c,
,
b ui na bs ie ad sev der vs eio rsn
ion α(cid:16) 1 −Lc(cid:17) 0 cBHP+c ⌈log2(L)
⌉
Ωcisasetofcrandomlyselectedcoordinates,c ∈{1,...,L
}
 
 x, w.p.q  1, biasedversion
C(x)=α whereα=
RandomizedGossip[11] · 0, w.p.1 −q  q1, unbiasedversion α(1 −q) 0 LBHPq (onaverage)
q (0,1]isthetransmissionprobability
∈
QSGD⋆[4] n(xj,x)= 

mm[C , +(x 1) ,]j= ww ..∥ ppx ..(∥
|
∥m
x
x·
j
∥s + |ig sn 1( −)x −j m) ,· | ∥x xn j ∥( |x ssj ,,x) m=(cid:22) s| ∥x xj ∥|(cid:23) min(cid:16) sL 2,√ sL(cid:17) 0 BHP+L+L ⌈log2(s) ⌉
sisthenumberofquantizationlevels

Top-c†sparsifier[11]
[ C(x)]j=

0x ,j, oif thx ej rw∈ iseΩc (c ∈{1,...,L })
1 −Lc 0 cBHP+c ⌈log2(L)
⌉
Ωcisasetoftheccoordinateswithhighestmagnitude
conducted in the presence of both the relative (captured through β2) and the absolute compression noise terms. As
c
explained in [25], neglecting the effect of σ2 requires that some quantities (e.g., the norm of the vector in QSGD)
c
are represented with no quantization error, in practice at the machine precision. We refer the reader to [26] for
a description of a framework for designing randomized compression operators that do not require high-precision
quantization of specific variables. Particularly, Sec. II in [26] describes the design of the probabilistic uniform and
ANQ quantizers endowed with a variable-rate coding scheme from [25] to adapt the bit rate based on the quantizer
input. When these rules, which are listed in Table II (rows 2–3), are applied entrywise to a vector x RL, the
∈
overall (random) bit budget will be equal to [26]:
L
r(x) = log (3) (1+ log ( n(x ) +1) ). (9)
2 ⌈ 2 | j | ⌉
j=1
(cid:88)
2) Allowing for the use of biased compression operators: Although the communication-efficient approach devel-
oped in [26] can be used for solving decentralized learning under subspace constraints and makes no assumptions
about encoding quantities with high precision, it is not designed to handle biased compression operators, i.e.,
operators that do not satisfy the unbiasedness condition (8). As we will see, by incorporating explicitly the error10
feedbackmechanismintothedifferentialquantizationapproachproposedin[26],wecanaddressbiasedcompression
by filtering the compression error over time. In general, biased compression operators tend to outperform their
unbiased counterparts [17].
While the list of compression operators in Table II provides several examples of interest, it is not exhaustive. As
we will see, through concatenation, it is possible to achieve other meaningful schemes.
Example 1. (Concatenation of compression schemes). In this example, we investigate a specific type of com-
pression operator consisting of concatenating two distinct bounded-distortion compression operators. The first
operation, known as the top-c sparsifier, entails retaining only the c largest-magnitude components of the input
vector.The secondoperationinvolvesquantizing theoutputof thetop-csparsifier.This concatenationisparticularly
noteworthy as it tends to require the fewest number of bits for representation by exploiting the inherent sparsity
induced by the sparsifier and by concentrating the quantization process on the most significant components of the
input. Numerical results illustrating the benefits of the concatenation are provided in Sec. V.
Definition 4. (Top-c quantizer). Let ( ) be a bounded-distortion compression operator with parameters β2 and
Q · q
σ2. Let ( ) be the top-c sparsifier, i.e., the deterministic compression operator listed in Table II (row 7), which
q S ·
can also be defined as [45], [46]:
x , if j
j c
[ (x)] = ∈ I (10)
S j  0, otherwise

where is the set containing the indices of the c largest-magnitude components of x. In case of ties (i.e., when
c 
I
the first c components are not uniquely determined), any tie-break rule is permitted. The top-c quantizer operator
is defined as:
1 , if ( ) is an unbiased scheme
(x) = α ( (x)), where α = 1+β q2 Q · (11)
C ·Q S  1, if ( ) is a biased scheme with β2 1.
 Q · q ≤
Lemma 1. (Property of the top-c quantizer). The compression operator defined by (11) is a bounded-distortion

compression operator with parameters:
c
β2 = 1 1 (1 α)2+α2β2 and σ2 = α2σ2, (12)
c − L − − q c q
(cid:0) (cid:0) (cid:1)(cid:1)
where the expectation in (7) is taken over the conditional probability measure P( x) that governs the random
·|
behavior of the compression operator ( ). By choosing α according to (11), we find that the parameters β2,σ2
Q · { c c}
reduce to 1 c , σ q2 for unbiased ( ) and to 1 (1 β2)c,σ2 for biased ( ).
− L(1+β q2) (1+β q2)2 Q · − − q L q Q ·
(cid:110) (cid:111)
(cid:8) (cid:9)
Proof. See Appendix A.
■
D. Contributions: Significant reduction in communication, with almost no effect on steady-state performance
In summary, we provide the following main contributions.11
We propose a communication-efficient variant of the ATC diffusion approach (3) for solving decentralized
•
learning under subspace constraints. The strategy blends differential quantization and error feedback.
We provide a detailed characterization of the proposed approach for a general class of bounded-distortion
•
compression operators satisfying (7), both in terms of mean-square stability and communication resources.
In terms of steady-state performance: We show that, in the small step-size regime, i.e., when µ 0 (so that
• →
higherordertermsofthestep-sizecanbeneglected),theiteratesw generatedbythecommunication-efficient
k,i
approach resulting from incorporating differential quantization and error feedback into the ATC diffusion
approach (3) satisfy:
limsupE wo w 2 κµ, (13)
∥ k − k,i ∥ ≈
i
→∞
where κ is a constant that depends mainly on the gradient noise (i.e., the difference between the true gradient
and its approximation) variance, and does not depend on the compression noise terms β2,σ2 . The same
{ c c}
result holds when studying the ATC diffusion approach (3) in the absence of compression [40, Theorem 1].
As we will show later, this asymptotic equivalence is achievable because the compression error is contained
in higher-order terms that vanish faster than µ as µ 0.
→
In terms of bit rate: While result (13) provides important reassurance about the accuracy of the compressed
•
approach, it does not address the communication efficiency directly, which is often quantified in terms of bit-
rate. In the absence of the absolute quantization noise term (σ2 = 0), result (13) is achieved at the expense of
c
communicating some quantities with high precision (as previously explained). In the presence of the absolute
noise term, the analysis reveals that, to guarantee (13), the parameters of the compression schemes (which are
chosen by the designer) should be set so that the absolute noise term converges to zero as µ 0. We prove
→
that this result can be achieved with a bit rate that remains bounded as µ 0, despite the fact that we are
→
requiring an increasing precision as the step-size decreases.
Thus, our theoretical findings reveal that, in the small step-size regime, the proposed strategy attains the per-
formance achievable in the absence of compression, despite the use of a finite number of bits. This demonstrates
the effectiveness of the approach in maintaining performance while reducing communication overheads. While
the theoretical findings show the optimality of the strategy in the small step-size regime, the experimental results
in Sec. V illustrate its practical effectiveness in terms of achieving superior or competitive performance against
state-of-the-art baselines in various scenarios, including those beyond the small step-size regime.
III. DECENTRALIZED ALGORITHMIC FRAMEWORK: COMPRESSED COMMUNICATIONS
In this work, we propose the DEF-ATC (differential error feedback - adapt then combine) diffusion strategy
listed in Algorithm 1 and in (18a)–(18c) for solving problem (2) in a decentralized and communication-efficient
manner. At each iteration i, each agent k in the network performs three steps. The first step, which corresponds
to the adaptation step, is identical to the adaptation step (3a), except that the step-size µ in (3a) is replaced by12
µ/ζ in (14), where ζ (0,1] is a damping parameter appearing in the compression step (15). This parameter is
∈
used to counteract the instability induced by the compression errors. The second step is the compression step. To
update ϕ , each agent k first encodes the error compensated difference ψ ϕ +z (using a
{ ℓ,i}ℓ ∈Nk k,i − k,i −1 k,i −1
bounded-distortion compression operator2 ( )), and broadcasts the result to its neighbors. Then, agent k updates
k
C ·
the local compression error vector z according to (16) and performs the reconstruction on each received vector
k,i
by first decoding it to obtain δ , and then computing the predictor ϕ according to (15) where δ is scaled
ℓ,i ℓ,i ℓ,i
by the aforementioned damping parameter ζ. Observe that implementing the compression step in Algorithm 1
requires storing the previous compression error z and the previous predictors ϕ by agent k. The
k,i −1 { ℓ,i −1}ℓ ∈Nk
compression step is followed by the combination step (17) where agent k combines the reconstructed vectors
ϕ using the combination coefficients A and a mixing parameter γ (0,1]. The resulting vector w is
{ ℓ,i} { kℓ } ∈ k,i
the estimate of wo, the k-th subvector of o in (2), at agent k and iteration i. As we will see in Sec. IV, and as
k W
for the damping coefficient ζ, the mixing parameter γ in the combination step (17) can also be used to control the
algorithm stability. A block diagram illustrating the implementation of the DEF-ATC diffusion approach at agent
k is provided in Fig. 1.
For the sake of convenience, we rewrite Algorithm 1 in the following compact form:
µ (cid:92)
ψ = w J (w ) (18a)
k,i k,i −1 − ζ∇wk k k,i −1

ϕ = ϕ +ζ (ψ ϕ +z ) (18b)
 


k,i k,i −1 Ck k,i− k,i −1 k,i −1


w = (1 γ)ϕ +γ A ϕ (18c)
k,i − k,i kℓ ℓ,i
 

ℓ (cid:88)∈Nk


where the compression error z k,i is updated according to:
z = (ψ ϕ +z ) (ψ ϕ +z ). (19)
k,i k,i− k,i −1 k,i −1 −Ck k,i− k,i −1 k,i −1
Observe that, in the absence of compression (i.e., when the operator ( ) in (18b) and (19) is replaced by the
k
C ·
identity operator and the parameters ζ and γ in (18b) and (18c), respectively, are set to 1) we recover the diffusion
ATC approach (3). Therefore, Algorithm 1 can be seen as a communication-efficient variant of the Adapt-Then-
Combine (ATC) approach. To mitigate the negative impact of compression, the DEF-ATC approach uses differential
quantization and error-feedback in step (18b). Differential quantization consists of compressing differences of the
formψ ϕ andtransmittingthem,insteadofcommunicatingcompressedversionsoftheestimatesψ .Error
k,i− k,i −1 k,i
feedback, on the other hand, consists of locally storing the compression error z (i.e., the difference between the
k,i
input and output of the compression operator), and incorporating it back into the next iteration. In Remark 1 further
ahead, we explain the role of the compression error z and how its introduction helps mitigate the accumulation
k,i
of errors over time.
2Since the compression scheme characteristics can vary across agents, the compression operator becomes C (·) instead of C(·) with a
k
subscript k added to C.13
Compression step
Self-learning step Forward compression
χ k,i Encoding p k,i
µ
ζ
Ck Transmitting
Stochastic
Gradient Local error computation and
reconstruction
yk,i δk,i Decoding
zk,i −1
Delay
zk,i Ck
φ k,i ζ
φ Delay
k,i 1
−
Receiving
{φ !,i}! ∈Nk
Social reconstruction:
{p 1!,i}! ∈Nk−
Social learning step ` 2Nk  3
(1 −γ)φk,i+γ !!∈NkAk!φ!,i
Delay
φφ !,!
i
−,i
1
ζ δ!,i Dec Cod !ing 7!
Fig. 1. (Left) An illustration of a multitask network [9], [26]. The objective at agent k is to estimate wo (of dimension M ×1), the k-th
k k
subvector of o in (2). In this example, the neighborhood set of agent k is given by N = {1,k,3,ℓ,7}. (Right) The implementation
k
W
of the DEF-ATC diffusion approach listed in Alg. 1 at agent k. The set N k− is the neighborhood set of agent k, excluding k itself. The
compression step consists of three sub-steps: i) the forward compression step where agent k encodes the error-compensated difference
χ = ψ −ϕ +z and sends the resulting vector p (sequence of symbols or bits) to its neighbors; ii) the local error
k,i k,i k,i −1 k,i −1 k,i
computationandreconstructionstepwhereagentk decodesthelocalvectorp toobtainδ =C (ψ −ϕ +z ),updatesthe
k,i k,i k k,i k,i −1 k,i −1
local compression error vector z according to (16) and the local predictor ϕ according to (18b); and iii) the (social) reconstruction
k,i k,i
stepwhere agentk receivesthe encodedvectors{p } fromits neighbors,decodesthemto obtain{δ } ,and thenupdatesthe
ℓ,i ℓ − ℓ,i ℓ −
∈Nk ∈Nk
predictors{ϕ } accordingto(15).Theresultingvectorsϕ and{ϕ } arethenusedinthesociallearningstep(17).Observe
ℓ,i ℓ − k,i ℓ,i ℓ −
∈Nk ∈Nk
thatimplementingthecompressionsteprequiresstoringthepreviouscompressionerrorz andthepreviousestimates{ϕ } by
k,i −1 ℓ,i −1 ℓ ∈Nk
agent k.
IV. MEAN-SQUARE-ERROR AND BIT RATE STABILITY ANALYSIS
A. Modeling assumptions
In this section, we analyze strategy (18) with a matrix satisfying (4) by examining the average squared distance
A
between w and wo, namely, E wo w 2, under the following assumptions on the risks J ( ) , the gradient
k,i k ∥ k− k,i ∥ { k · }
noise processes s ( ) defined by [6]:
k,i
{ · }
s (w) ≜ J (w) (cid:92) J (w), (20)
k,i ∇wk k −∇wk k
and the compression operators ( ) .
k
{C · }
Assumption 1. (Conditions on individual and aggregate risks). The individual risks J (w ) are assumed to be
k k
twice differentiable and convex such that:
λ I 2 J (w ) λ I , (21)
k,min Mk ≤ ∇wk k k ≤ k,max Mk
where λ
k,min
0 for k = 1,...,K. It is further assumed that, for any w
k
RMk , the individual risks satisfy:
≥ { ∈ }
0 < λ I diag 2 J (w ) K λ I , (22)
min P ≤ U⊤ ∇wk k k k=1U ≤ max P
(cid:8) (cid:9)14
Algorithm 1: DEF-ATC (differential error feedback - adapt then combine) diffusion strategy for solving (2)
Input: initializations w = 0, ϕ = 0, and z = 0, small step-size µ, damping coefficient ζ (0,1],
k,0 k,0 k,0 ∈
mixing parameter γ (0,1], combination matrix satisfying (4).
∈ A
for i = 1,2,..., on the k-th node do
Adapt: update w according to:
k,i 1
−
µ (cid:92)
ψ = w J (w ) (14)
k,i k,i −1 − ζ∇wk k k,i −1
Compress and broadcast:
encode the error compensated difference ψ ϕ +z using a bounded-distortion
• k,i− k,i −1 k,i −1
compression operator ( ) and broadcast the result p to the neighbors
Ck · k,i Nk
upon receiving the compressed messages p from neighbors ℓ , first decode them to obtain
• { ℓ,i} ∈ Nk
δ = (ψ ϕ +z ) , and then compute ϕ according to:
{ ℓ,i Cℓ ℓ,i− ℓ,i −1 ℓ,i −1 }ℓ ∈Nk { ℓ,i}ℓ ∈Nk
ϕ = ϕ +ζδ , ℓ (15)
ℓ,i ℓ,i −1 ℓ,i ∈ Nk
update the local compression error:
•
z = (ψ ϕ +z ) δ (16)
k,i k,i− k,i −1 k,i −1 − k,i
Combine: Update local model according to:
w = (1 γ)ϕ +γ A ϕ (17)
k,i − k,i kℓ ℓ,i
ℓ (cid:88)∈Nk
for some positive parameters λ λ .
min max
≤
As explained in [40], condition (22) ensures that problem (2) has a unique minimizer o.
W
Assumption 2. (Conditions on gradient noise). The gradient noise process defined in (20) satisfies for k =
1,...,K:
E s (w ) ϕ ,z K = 0, (23)
k,i k,i −1 |{ ℓ,i −1 ℓ,i −1 }ℓ=1
E s(cid:2) (w ) 2 ϕ ,z K (cid:3) β2 wo w 2+σ2 , (24)
∥ k,i k,i −1 ∥ |{ ℓ,i −1 ℓ,i −1 }ℓ=1 ≤ s,k∥ k − k,i −1 ∥ s,k
(cid:2) (cid:3)
for some β2 0 and σ2 0.
s,k ≥ s,k ≥
As explained in [6]–[8], these conditions are satisfied by many risk functions of interest in learning and adaptation
such as quadratic and regularized logistic costs. Condition (23) states that the gradient vector approximation should
be unbiased conditioned on the iterates generated at the previous time instant. Condition (24) states that the second-
order moment of the gradient noise should get smaller for better estimates, since it is bounded by the squared norm
of the iterate.15
Assumption 3. (Conditions on compression operators). In step (18b) of the DEF-ATC strategy, each agent k at
time i applies to the error compensated difference χ = ψ ϕ +z a bounded-distortion compression
k,i k,i− k,i −1 k,i −1
operator ( ) (see Definition 2) with compression noise parameters β2 and σ2 . It is assumed that given the past
Ck · c,k c,k
history, the randomized compression mechanism depends only on the quantizer input χ . Consequently, from (7),
k,i
we get:
E χ (χ ) 2 h = E χ (χ ) 2 χ β2 χ 2+σ2 , (25)
∥ k,i−Ck k,i ∥ | i ∥ k,i−Ck k,i ∥ | k,i ≤ c,k∥ k,i∥ c,k
(cid:2) (cid:3) (cid:2) (cid:3)
where h is the vector collecting all iterates generated by (18) before the quantizer is applied to χ , namely,
i k,i
K
ϕ i 1, ψ i , z i 1 .
{ ℓ,j}j−=1 { ℓ,j}j=1 { ℓ,j }j−=1 ℓ=1
(cid:110) (cid:111)
B. Network error vector recursion
In the following, we derive a useful recursion that allows to examine the time-evolution across the network
of the error dynamics relative to the reference vector o = col wo K defined in (2). Let w = wo w ,
W { k}k=1 k,i k − k,i
ψ = wo ψ , and ϕ = wo ϕ . Using (20) and the mean-value theorem [47, pp. 24], [6, Appendix D],
k,i k − k,i k,i k − k,i (cid:101)
we can express the stochastic gradient vector appearing in (18a) as follows:
(cid:101) (cid:101)
(cid:92)
J (w ) = H w +b s (w ), (26)
∇wk k k,i −1
−
k,i −1 k,i −1 k
−
k,i k,i −1
where H ≜ 1 2 J (wo tw )dt and b ≜ (cid:101) J (wo). By subtracting wo from both sides of (18a),
k,i −1 0 ∇wk k k − k,i −1 k ∇wk k k k
by using (26), and(cid:82)by introducing the following network quantities:
(cid:101)
b ≜ col b ,...,b , (27)
1 K
{ }
s ≜ col s (w ),...,s (w ) , (28)
i 1,i 1,i 1 K,i K,i 1
{ − − }
≜ diag H ,...,H , (29)
i 1 1,i 1 K,i 1
H− { − − }
Wi 1 ≜ col w 1,i 1,...,w K,i 1 , (30)
− { − − }
we can show that the network erro(cid:101)r vector ψ =(cid:101) col ψ K(cid:101) evolves according to:
i { k,i}k=1
µ µ µ
(cid:101) (cid:101)
ψ i = I M − ζHi −1 Wi −1 − ζs i+ ζb. (31)
(cid:18) (cid:19)
Bysubtractingwo frombothsidesof(cid:101) (18c),byreplacingwo b(cid:101)y(1 γ)wo+γwo,andbyusingwo = A wo [40,
k k − k k k ℓ ∈Nk kℓ ℓ
Sec. III-B], we obtain: (cid:80)
w = (1 γ)ϕ +γ A ϕ .
k,i − k,i kℓ ℓ,i (32)
ℓ (cid:88)∈Nk
(cid:101) (cid:101) (cid:101)
From (32), we find that the network error vector Wi 1 in (30) evolves according to:
−
Wi −1 = (1 −γ(cid:101))ϕ i −1+γ Aϕ i −1 = A′ϕ i −1, (33)
(cid:101) (cid:101) (cid:101) (cid:101)16
where
ϕ ≜ col ϕ ,...,ϕ , (34)
i { 1,i K,i}
≜ (1 γ)I +γ . (35)
(cid:101)′ (cid:101) M (cid:101)
A − A
By subtracting wo from both sides of (18b) and by adding and subtracting wo to the difference ψ ϕ , we
k k k,i− k,i −1
can write:
ϕ = ϕ ζ (ϕ ψ +z ). (36)
k,i k,i −1− Ck k,i −1− k,i k,i −1
Now, by adding and subtracting ζ((cid:101)ϕ (cid:101) ψ +z (cid:101)) to the(cid:101)RHS of the above equation, we obtain:
k,i −1− k,i k,i −1
ϕ (cid:101) = (1 (cid:101)ζ)ϕ +ζψ +ζ(z z ), (37)
k,i − k,i −1 k,i k,i − k,i −1
in terms of the compression error(cid:101)vector z de(cid:101)fined in (1(cid:101)9). By combining (31), (33), and (37), we conclude that
k,i
the network error vector ϕ in (34) evolves according to the following dynamics:
i
(cid:101) ϕ = ϕ µs +µb+(z z ), (38)
i Bi −1 i −1− i i − i −1
where (cid:101) (cid:101)
µ
≜ (1 ζ)I +ζ I , (39)
i 1 M M i 1 ′
B − − − ζH− A
(cid:18) (cid:19)
z ≜ ζcol z K . (40)
i { k,i }k=1
Remark 1 (Temporal filtering of the compression error): A direct consequence of feeding back the error in
the compression step (18b) is to subtract the compression error from previous instants in recursion (38), thereby
allowing for a correction mechanism3. This correction helps mitigate the accumulation of errors over time, leading
to improved network performance. ■
Asthepresentationwillreveal,thestudyofthenetworkbehaviorinthepresenceoferrorfeedbackisachallenging
task since, in addition to analyzing the dynamics of the network error vector ϕ , we need to examine how the
i
compression error (40), which is fed back into the network through the compression step (18b), affects its behavior.
(cid:101)
When all is said and done, the results will help clarify the effect of network topology, step-size µ, damping
coefficient ζ, mixing parameter γ, gradient (through β2 ,σ2 ) and compression (through β2 ,σ2 ) noise
{ s,k s,k} { c,k c,k}
processes on the network mean-square-error stability and performance, and will provide insights into the design of
effective compression operators for decentralized learning.
3To see this, we can simply remove the error feedback mechanism from the approach (18) by replacing the compression step (18b) by
ϕ
k,i
=ϕ
k,i
1+ζC k(ψ k,i−ϕ
k,i
1)andderivethenetworkerrorvectorϕ(cid:101)
i
in(34)byfollowingsimilarargumentsasin(26)–(40).Instead
− −
of (38), we would arrive at the following dynamics:
ϕ(cid:101)
i
=B
i
−1ϕ(cid:101)
i
−1−µs i+µb+z i, (41)
where we obtain in (41) the instantaneous noise vector z instead of the difference vector z −z as in (38).
i i i 1
−17
C. Mean-square-error stability
The mean-square-error analysis will be carried out by first establishing the boundedness of limsup E ϕ
i →∞ ∥ i−
z i ∥2,andthenusingrelation(33)andHolder’sandJensen’sinequalitiestodeduceboundednessoflimsup i →∞E (cid:101)∥Wi ∥2.
Therefore, in the following, we first study the stability of the network error vector ϕz defined as ϕz ≜ ϕ z and
i i i− i
(cid:101)
evolving according to:
(cid:101) (cid:101) (cid:101)
z z
ϕ = ϕ µs +µb (I )z (42)
i Bi −1 i −1− i − M −Bi −1 i −1
The above identity can be found(cid:101)by adding(cid:101)and subtracting the term z to the RHS of (38). We analyze
i 1 i 1
B − −
the stability of recursion (42) by first transforming it into a more convenient form (shown later in (49) and (50))
using the Jordan canonical decomposition [48] of the matrix defined in (35). To exploit the eigen-structure of
′
A
, we first recall that a matrix satisfying the conditions in (4) (for a full-column rank semi-unitary matrix )
′
A A U
has a Jordan decomposition of the form = Λ 1 with [40, Lemma 2]:
A
Vϵ ϵ Vϵ−
I 0
= , Λ = P , 1 = U⊤ , (43)
Vϵ U VR,ϵ ϵ  0  Vϵ−  
(cid:104) (cid:105) Jϵ VL⊤,ϵ
   
where is a Jordan matrix with eigenvalues (which may be complex but have magnitude less than one) on the
ϵ
J
diagonal and ϵ > 0 on the super-diagonal [40, Lemma 2], [6, pp. 510]. The parameter ϵ is chosen small enough
to ensure ρ( )+ϵ (0,1) [40]. Consequently, the matrix in (35) has a Jordan decomposition of the form
ϵ ′
J ∈ A
= Λ 1 where:
A′ Vϵ ′ϵVϵ−
I 0
Λ = P , with ≜ (1 γ)I +γ . (44)
′ϵ

0

Jϵ′
−
M −P Jϵ
Jϵ′
 
By multiplying both sides of (42) from the left by 1 in (43), we obtain the transformed iterates and variables:
Vϵ−
z z
ϕ ϕ
1ϕz = U⊤ i ≜ i , (45)
Vϵ− i  z   qz 
ϕ ϕ
VL⊤,ϵ(cid:101)i i
(cid:101)    
s s
1s = U⊤ (cid:101)i ≜ i , (46)
Vϵ− i
 s   qs 
VL⊤,ϵ i i
   
b 0
1b = U⊤ ≜ , (47)
Vϵ−    q 
b b
VL⊤,ϵ
   
z z
Vϵ−1z
i −1
=

U⊤ zi −1

≜

zqi −1 , (48)
VL⊤,ϵ i −1 i −1
   
where in (47) we used the fact that b = 0 as shown in [40, Sec. III-B]. In particular, the transformed components
⊤
U
z qz
ϕ and ϕ evolve according to the recursions:
i i
ϕz = (I µ )ϕz µ ϕqz µs µ z µ zq (49)
i P − D11,i −1 i −1− D12,i −1 i −1− i − D11,i −1 i −1 − D12,i −1 i −1
ϕqz = ( µ )ϕqz µ ϕz +µq b µqs µ z ζ(I )+µ zq (50)
i Jϵ′′ − D22,i −1 i −1− D21,i −1 i −1 − i − D21,i −1 i −1 − −Jϵ′ D22,i −1 i −1
(cid:0) (cid:1)18
where
≜ , (51)
11,i 1 ⊤ i 1
D − U H− U
≜ , (52)
D12,i −1 U⊤ Hi −1 VR,ϵ Jϵ′
≜ , (53)
D21,i −1 VL⊤,ϵHi −1
U
≜ , (54)
D22,i −1 VL⊤,ϵHi −1 VR,ϵ Jϵ′
≜ (1 ζ)I +ζ . (55)
Jϵ′′
−
M −P Jϵ′
Theorem 1. (Mean-square-error stability). Consider a network of K agents running the DEF-ATC diffusion
approach (listed in Algorithm 1) to solve problem (2) under Assumptions 1, 2, and 3, with a matrix satisfying (4).
A
In the absence of the relative compression noise term (i.e., β2 = 0, k), let the damping and mixing parameters
c,k ∀
be such that ζ = γ = 1. In the presence of the relative compression noise (i.e., at least one β2 is positive for
c,k
some agent k), let ζ (0,1] and γ (0,1] be such that the two following conditions are satisfied:
∈ ∈
1 (ρ( )+ϵ)
0 < γζ < − Jϵ , (56)
4v2v2β2 (ρ(I )+ϵ)2
1 2 c,max −Jϵ
and
(ρ(I )+ϵ)2 1
γζ −Jϵ +ζ2β2 v2v2 1+((1+γ) γ(ρ( )+ϵ))2 < , (57)
1 (ρ( )+ϵ) c,max 1 2 − Jϵ 2
ϵ
− J (cid:16) (cid:17)
where v = 1 , v = , and β2 ≜ max β2 . Then, for sufficiently small step-size µ, the network
1 ∥Vϵ− ∥ 2 ∥Vϵ ∥ c,max 1 ≤k ≤K { c,k}
is mean-square-error stable, and it holds that:
limsupE ϕz 2 = κµ+σ2O(1), (58)
∥ i∥ c
i
→∞
where σ2 = K σ2 . The constant κ is positive, i(cid:101)ndependent of the step-size µ and the compression noise terms
c k=1 c,k
{β c2 ,k,σ c2 ,k},(cid:80)and is given by κ = v 12v 22 σσ 12 s
1
with σ2
s
= K k=1σ s2 ,k, and σ
11
is some positive constant resulting from
the derivation of inequality (74) in Appendix B. Mor(cid:80)eover, by choosing compression schemes with σ2 µ1+ε
c,k ∝
(where the symbol hides a proportionality constant independent of µ) and ε (0,1], we obtain:
∝ ∈
limsupE ϕz 2 = κµ+O(µ1+ε). (59)
∥ i∥
i
→∞
It then holds that: (cid:101)
limsupE Wi 2 = κµ+O(µ1+ 2ε), (60)
∥ ∥
i
→∞
from which we conclude that: (cid:101)
1
lim limsup E wo w 2 = κ, (61)
µ 0 i µ ∥ k − k,i ∥
→ →∞
for k = 1,...,K.
Proof. See Appendix B.19
Whileexpressions(58)–(61)inTheorem1revealtheinfluenceofthestep-sizeµ,thecompressionnoise(captured
by σ2,β2 ), and the gradient noise (captured by σ2) on the steady-state mean-square error, expressions (56)
{ c c,max} s
and (57) reveal the influence of the relative compression noise term (captured by β2 ) on the network stability,
c,max
andhowthisinfluencecanbemitigatedbyproperlychoosingthedampingcoefficientζ andthemixingparameterγ.
One main conclusion stemming from Theorem 1 (expression (58)) is that the mean-square-error contains two terms.
The first term is κµ where κ is a constant independent of the compression noise β2 ,σ2 , but depends on the
{ c,k c,k}
gradient noise σ2 . This term, which we refer to as the gradient noise term, is classically encountered in the
{ s,k}
uncompressed case [40]. The second factor is an O(1) term that is proportional to the quantizers’ absolute noise
components σ2 .Interestingly,bychoosingcompressionschemeswithσ2 µ1+ε andε (0,1],forsufficiently
{ c,k} c,k ∝ ∈
small step-sizes µ we obtain limsup E wo w 2 κµ. This result is reassuring since it implies that the
i →∞ ∥ k − k,i ∥ ≈
impact of the compression noise can be minimized to the point where it only affects higher-order terms of the
step-size. Consequently, the primary noise influencing the learning process will be the gradient noise, which is
consistent with the classical results observed in the uncompressed case studied in [40].
While result (61) is appealing, it is not sufficient to characterize the DEF-ATC diffusion approach. To fully
characterizeadecentralizedstrategyendowedwithacompressionmechanism,itisessentialtoconsiderthelearning-
communication tradeoff. In other words, we need to assess also how the design choice σ2 µ1+ε impacts
c,k ∝
the amount of communication resources (e.g., quantization bits). For instance, consider the probabilistic uniform
quantizer from Table II. For this scheme, setting σ2 µ1+ε is equivalent to requiring the quantization step ∆ to be
c,k ∝
proportional to µ1+ 2ε . Thus, while small values of σ c2
,k
imply small compression errors in view of (7), they might in
principlerequirelargebitrates.Moreover,asµ 0,thequantizationstep∆becomesverysmall,potentiallyleading
→
to an unbounded bit rate increase. It becomes therefore important to find a quantization scheme that achieves the
same performance as the uncompressed case, i.e., limsup E wo w 2 κµ, while guaranteeing a finite bit
i →∞ ∥ k− k,i ∥ ≈
rate as µ 0. In the next theorem, we show that the DEF-ATC diffusion approach equipped with the variable-rate
→
coding scheme from [25], [26, Sec. II] achieves both objectives.
D. Bit rate stability
We first assume that the top-c quantizer in Definition 4 (with a subscript k added to c to highlight the fact that
k
the compression characteristics can vary across agents) is used at each iteration i and agent k. We then recall that
the quantizer input is given by the error compensated difference χ = ψ ϕ +z , and assume that
k,i k,i − k,i −1 k,i −1
the probabilistic ANQ scheme4 (Table II, row 3) is employed at the output of the top-c sparsifier. Consequently,
k
from (9), the bit rate at agent k and iteration i is given by:
r = log (3) 1+E log ( n([χ ] ) +1) +(M c )log (3), (62)
k,i 2 2 | k,i j | k − k 2
j ∈(cid:88)Ick,i(cid:16) (cid:104)
(cid:6)
(cid:7)(cid:105)(cid:17)
4The probabilistic uniform rule (Table II, row 2) can be obtained from the ANQ rule by letting ω→0 [26].20
where [χ ] denotes the j-th entry of χ , is the set containing the indices of the c largest-magnitude
k,i j k,i Ick,i k
components of χ , and (M c )log (3) is the number of bits required to encode the M c zero components
k,i k − k 2 k − k
at the output of the top-c sparsifier5.
k
Theorem 2. (Bit rate stability). Assume that each agent k employs the top-c quantizer (see Definition 4) with
k
the probabilistic ANQ scheme. Assume further that the design parameters of the compression operators are chosen
such that:
1+ε
ω k = t, η k µ 2 , (63)
∝
where t is a constant independent of µ and 0 < ε 1. First, under conditions (63), we have:
≤
σ2 µ1+ε. (64)
c,k ∝
Second, in the steady state, the average number of bits at agent k stays bounded as µ 0, namely,
→
limsup r = O(1). (65)
k,i
i
→∞
Proof. See Appendix C.
The bit rate stability result (65) can be explained by considering again the uniform quantization rule (Table II,
row 2) which, as explained previously, requires setting ∆
∝
µ1+ 2ε in order to guarantee that σ c2
,k ∝
µ1+ε. The
result (131) reveals that the input to the compression operators of the DEF-ATC strategy in (18b), namely, the
error compensated difference χ
k,i
= ψ
k,i
−ϕ
k,i −1
+z
k,i
−1, under (64) is on the order of µ1+ 2ε at steady-state.
This means that as µ 0, the quantizer resolution ∆ µ1+ 2ε decreases, but in proportion to the effective range
→ ∝
of the quantizers’ inputs. Theorem 2 reveals the adaptability of the variable-rate scheme, ensuring that even as the
quantization becomes increasingly precise (as µ 0), the DEF-ATC strategy can still maintain a finite expected
→
bit rate, which is crucial for efficient data transmission.
V. SIMULATION RESULTS
In this section, we first illustrate the theoretical results of Theorems 1 and 2. Then, we illustrate the benefit of
the top-c quantizer over other quantizers, particularly those that quantize a vector element-wise, without prioritizing
the c most important components. In the third part, we compare DEF-ATC to state-of-the-art baselines in various
scenarios, including those beyond the small step-size regime. The first three parts focus on solving single-task
optimization problems of the form (1). The last part illustrates the performance of the DEF-ATC approach when
used to solve multitask estimation problems with overlapping parameter vectors.
We consider a network of K = 30 nodes with the communication link matrix shown in Fig. 2 (left), where the
(k,ℓ)-thentryisequalto1ifthereisalinkbetweenk andℓandis0otherwise.Eachagentissubjectedtostreaming
5Encoding the 0 input using the variable-rate coding scheme from [25], [26, Sec. II] requires only a parsing symbol, i.e., log (3) bits.
2
Instead of encoding the zero components, agent k can send the location of the c largest-magnitude components. In this case, the term
k
(M −c )log (3) is replaced by c ⌈log (M )⌉. This alternative solution does not affect the main conclusions of Sec. IV-D.
k k 2 k 2 k21
Fig. 2. Experimental setup. (Left) Communication link matrix. (Right) Regression and noise variances.
data d (i),u assumed to satisfy a linear regression model of the form d (i) = u w⋆+v (i) for some M 1
{ k k,i } k ⊤k,i k k c ×
vector w⋆ with v (i) denoting a zero-mean measurement noise and M = 10. A mean-square-error risk of the
k k c
form J (w ) = E d (i) u w 2 is associated with each agent k. The processes u ,v (i) are assumed to
k k
|
k
−
⊤k,i k
| {
k,i k
}
be zero-mean Gaussian with: i) Eu u = R = σ2 I if k = ℓ and 0 otherwise; ii) Ev (i)v (i) = σ2
k,i ⊤ℓ,i u,k u,k Mc k ℓ v,k
if k = ℓ and 0 otherwise; and iii) u and v (i) are independent of each other. The variances σ2 and σ2 are
k,i k u,k v,k
shown in Fig. 2 (right). Throughout Sec. V, we assume that all agents employ the same compression rule, i.e.,
k
= k. We use the terminology “top-c quantizer-name” to refer to the top-c quantizer of Definition 4 where, as
C C ∀
compression scheme , we use quantizer-name. For instance, “top-4 probabilistic ANQ” is the quantizer obtained
Q
by applying the probabilistic ANQ scheme at the output of the top-4 sparsifier.
A. Illustrating the theoretical findings
In this section and the following Secs. V-B and V-C, we assume that agents have a common model parameter
w⋆ = wo k. The model wo is generated by normalizing to unit norm a randomly generated Gaussian vector,
k ∀
with zero mean and unit variance. To promote consensus (i.e., to solve problem (1) or, equivalently, (2) with
= 1 (1 I )), we run Alg. 1 using a combination matrix of the form = A I , where A is generated
U √K K ⊗ Mc A ⊗ Mc
according to the Metropolis rule [6, Chap. 8].
In Fig. 3 (left), we report the network mean-square-deviation (MSD) learning curves:
K
1
MSD(i) = E wo w 2, (66)
K ∥ k − k,i ∥
k=1
(cid:88)
for 3 different values of the step-size µ. The results are averaged over 100 Monte-Carlo runs. For each value of the
step-size, we run Alg. 1 for 4 different choices of the compression operator : i) top-4 sparsifier, ii) top-4 QSGD
C
(Table II, row 6, s = 2), iii) top-4 probabilistic uniform (Table II, row 2, ∆ = µ), and iv) top-4 probabilistic
ANQ (Table II, row 3, ω = 0.5, η = µ). We set γ = ζ = 0.9. As it can be observed, despite compression, the
DEF-ATC approach achieves a performance that is almost identical to the uncompressed ATC approach (which can22
Fig.3. Networkperformancew.r.t.wo forthreedifferentvaluesofthestep-size(µ =0.001).(Left)EvolutionoftheMSDlearningcurves.
0
(Right) Evolution of the average number of bits per node, per component, when the variable-rate probabilistic uniform and ANQ schemes
are used at the output of the top-4 sparsifier to encode the error compensated difference χ =ψ −ϕ +z in (18b).
k,i k,i k,i −1 k,i −1
be obtained from Alg. 1 by setting γ = ζ = 1 and replacing the compression operator by identity). We further
observe that, in steady-state, the network MSD increases by approximately 3 dB when µ goes from µ to 2µ . This
0 0
means that the performance is on the order of µ, as expected from Theorem 1 since in the simulations the absolute
noise component is such that σ2 µ2. For the top-4 probabilistic uniform and ANQ quantizers, we report in
c,k ∝
Fig. 3 (right) the average number of bits per node, per component, computed according to:
K
1 1
R(i) = r , (67)
k,i
K M
k
k=1
(cid:88)
where r is the bit rate given by (62), which is associated with the encoding of the error compensated difference
k,i
vector χ = ψ ϕ +z transmitted by agent k at iteration i. As it can be observed, for the three
k,i k,i − k,i −1 k,i −1
different values of the step-size, we approximately obtain the same finite average number of bits in steady-state
(approximately 2.4 bits/component/iteration are required on average in steady-state when the top-4 probabilistic
ANQ quantizer is used). From Table II (row 7), the top-4 sparsifier would require an average of 4(32+4) = 14.4
10
bits/node/component/iteration6, which is almost six times higher than the one obtained in steady-state when the
probabilistic ANQ is used. This is expected since the top-4 sparsifier requires encoding the 4 largest magnitude
components of the input with very high precision. On the other hand, the top-4 QSGD (Table II, row 6, s = 2),
which requires encoding the norm of the input with high precision, would need an average of 32+10+10 = 5.2
10
bits/node/component/iteration, which is almost two times higher than the one obtained for the probabilistic ANQ.
Evaluating the performance of a learning approach requires considering both the attained learning error (MSD)
andtheassociatedbitexpense.Therefore,inthefollowing,wefocus onreportingrate-distortion(RD)curves,where
the bit budget quantifies the rate and the MSD quantifies the distortion.
6NotethatwereplacedB by32sinceweareperformingtheexperimentsonMATLAB2022awhichuses32bitstorepresentafloating
HP
number in single-precision.23
Fig. 4. Rate-distortion curves of the DEF-ATC approach with probabilistic uniform and top-4 probabilistic uniform quantization.
B. Top-c quantization outperforms other compression rules
We report in Fig. 4 the RD curves of the DEF-ATC approach with probabilistic uniform and top-4 probabilistic
uniform quantization. We set µ = 0.001 and γ = ζ = 0.9. Each point of the rate-distortion curve corresponds to one
value of the parameter ε, which determines the quantization step ∆ = µ1+ 2ε . In the example, we selected 25 values
of ε linearly spaced in the interval [10 3,1]. For each value of ∆ (i.e., each point of the curve), the resulting MSD
−
(distortion) and average number of bits/node/component (rate) were obtained by averaging the instantaneous mean-
square-deviation MSD(i) in (66) and averaging the number of bits R(i) in (67) over 100 samples after convergence
of the algorithm (the expectations in (66) and (67) are estimated empirically over 100 Monte Carlo runs). The
trade-off between rate and distortion can be observed from Fig. 4, namely, as the rate decreases, the distortion
increases, and vice versa. For comparison purposes, we illustrate in Fig. 4 the distortion (horizontal dashed line)
of the uncompressed ATC approach obtained by averaging MSD(i) in (66) over 100 samples after convergence.
We also illustrate the specific log (3) bit rate (vertical dashed line) corresponding to minimum number of bits
2
possible for the considered scheme, namely, the variable-rate coding scheme from [25], [26, Sec. II]. Under this
scheme, each component is appended with a parsing symbol, and the 0 value is encoded as an empty element.
Thus, the minimum number of bits/component would correspond to sending only one symbol per component. As
it can be observed, top-4 probabilistic uniform is more efficient than probabilistic uniform, namely, it approaches
the uncompressed performance (low distortion) at a lower bit rate compared to probabilistic uniform quantization.
C. Performance w.r.t. state-of-the-art baselines
In this part, we compare the DEF-ATC diffusion to the following approaches: i) ChocoSGD [11], ii) Deep-
Squeeze [33], iii) diffusion ACTC [21], and iv) compressed diffusion ATC approach (which we refer to as the
“compressed ATC 2”) [26]. We assume that all agents employ the top-4 probabilistic uniform quantizer with the24
Fig.5. DEF-ATCperformancew.r.t.tostate-of-the-artbaselines.EvolutionoftheMSDandaveragenumberofbits/node/component(when
top-4 probabilistic uniform with variable-rate encoding scheme is used) for different values of the step-size. (Left) µ = 0.01. (Right)
µ=0.001.
variable rate encoding scheme from [25], [26, Sec. II]. In Fig. 5, we report the network MSD learning curves
with the corresponding bit rates, for 2 different values of the step-size µ = 0.01 (left) and µ = 0.001 (right). The
results are averaged over 100 Monte-Carlo runs. We set the quantization parameter ∆ = µ. For the ACTC [21] and
compressed ATC 2 [26] approaches (which were originally designed to handle unbiased probabilistic compression),
we used a step-size µ = 0.0125 and µ = 0.00125, in place of µ = 0.01 and µ = 0.001, respectively, in order
to ensure that they have the same learning rate as the uncompressed ATC approach. This configuration ensures
that all approaches are compared at the same learning rate. The other parameters of the baselines approaches are
set as follows: i) ChocoSGD: γ = 0.9, ii) DeepSqueeze: (consensus parameter) η = 0.05 when µ = 0.01 and
η = 0.2 when µ = 0.001, iii) ACTC: ζ = 0.9, iv) compressed ATC 2: γ = 0.9, and v) DEF-ATC: γ = ζ = 0.9.
While the space of algorithms’ hyperparameters (γ, ζ, etc.) is explored in the next experiment, it is worth noting
that the values chosen in the current experiment ensure a stable compressed strategy with the lowest MSD level.
As it can be observed from the MSD learning curves, the DEF-ATC approach tends to outperform state-of-the-art25
Fig. 6. Rate-distortion curves of the DEF-ATC and state-of-the-art baselines approaches for different values of the step-size. The top-4
probabilistic uniform quantizer with variable-rate encoding scheme is used. (Left) µ=0.01. (Right) µ=0.001.
baselines in various step-size regimes. In order to identify which method provides better compression efficiency
for a given level of distortion, we report in Fig. 6 the RD curves of the different approaches. Before analyzing the
results, it is noteworthy that the bit rate curves reported in Fig. 5 indicate that the DeepSqueeze approach tends
to require a larger number of bits as the step-size decreases. Thus, for very fine quantization (i.e., small step-sizes
since ∆ = µ), the number of bits required tends to grow, making it impractical for use in such scenarios. By noting
that DeepSqueeze does not employ differential quantization, the increase in bit rate with decreasing quantization
step is expected. In fact, in this case, the input values at the compressor remain large (in particular, their effective
range does not scale with the step-size µ), leading to an increase in the bit rate with decreasing quantization step.
For each approach, the process for generating the rate-distortion curves in Fig. 6 consists of three main steps.
First, we select a set of algorithm’s hyperparameters (γ, ζ, etc.). In particular, for ACTC [21], we select 10
values of the damping coefficient ζ uniformly spaced in the interval [0.1,0.9]. For compressed ATC 2 [26] (and
ChocoSGD [11]), we select 10 values of the mixing parameter γ uniformly spaced in the interval [0.1,0.9]. For the
DEF-ATC approach, we create two sets of 5 uniformly spaced values in the interval [0.1,0.9] for the coefficients ζ
and γ, and then consider all possible pairs from these sets. In the second step, and for each hyperparameter setting
(i.e., each element in the sets of step 1), we generate the RD curve by following the same method as in Sec. V-B,
namely, we vary the quantization step according to ∆ = µ1+ 2ε , where 25 values of ε linearly spaced in the interval
[10 3,1] are chosen. For each value of ∆, distortion and rate are evaluated by averaging over 100 samples after
−
convergence (expectations are computed empirically over 50 Monte Carlo runs). Each RD curve then represents the
performance of the algorithm under a specific choice of hyperparameters. In the last step, we generate and report
in Fig. 6 the optimal RD curve given by the convex hull of the empirical curves collected in step 2. This process
allows us to identify the best possible performance trade-offs by varying the algorithms’ hyperparameters (γ, ζ,
etc.) and the compression parameters, namely, ε. Two learning step-size regimes are considered, namely, µ = 0.0126
(left plot) and µ = 0.001 (right plot). By exploring the hyperparameter space and by considering different step-size
regimes, the results show that the DEF-ATC approach can still achieve the closest performance to the uncompressed
approach with a relatively small number of bits (approximately 2.2–2.4 bits/component/iteration are required on
average in steady-state), outperforming state-of-the-art baselines.
D. Beyond single-task estimation
ToillustratetheeffectivenessoftheDEF-ATCapproachinsolvinggeneraloptimizationproblemsoftheform(2),
we conduct an experiment in which agents seek consensus on certain components of their estimates while seeking
partial consensus on others. In particular, we assume that we have 5 connected7 groups of agents, namely, =
1
G
1,...,15 , = 16,...,30 , = 1,...,10 , = 11,...,20 , and = 21,...,30 , and that the
2 3 4 5
{ } G { } G { } G { } G { }
model parameter vector w⋆ at agent k is of the form w⋆ = w +∆ , where ∆ is a 10 1 vector with each
k k k• k,i k,i ×
component randomly generated from the Gaussian distribution, with zero mean and variance 0.1. The vectors w
{
k•
}
are generated in such a way that the first 5 components are common across the network, the components 6,7,8
are separately common for agents in and , and the last two components are separately common for agents
1 2
G G
in groups , , and . Then, we choose the constraints in (2) (i.e., the matrix ) in order to enforce global
3 4 5
G G G U
consensus on the first 5 components of the estimates and partial consensus on the remaining components. The
partial consensus is as follows. Agents in should converge to a consensus on components 6–8, and agents in
1 2
G G
should also converge to a consensus on components 6–8, independently from the first group. For the remaining two
components 9 and 10, consensus is enforced within each of the groups , , and . The matrix satisfying the
3 4 5
G G G A
conditions in (4) and having the same sparsity structure as the link matrix in Fig. 2 (left) is found by following the
same approach as in [40].We assume that all agents employ the top-4 probabilistic uniform quantizer. In Fig. 7 (left)
and (middle), we report the network MSD (66) and average number of bits/node/component (67) for 3 different
valuesofthestep-sizeµ.Theresultsareaveragedover100Monte-Carloruns.Wesetγ = ζ = 0.9andthequantizer
parameter ∆ = µ. As in Sec. V-A, we observe, in the small step-size regime, that the DEF-ATC achieves the same
performance (which is on the order of µ) as the uncompressed ATC approach, and is able to maintain a finite
bit rate when the step-size approaches zero. This illustrates the effectiveness of DEF-ATC in handling different
problem settings, beyond traditional single-task estimation. In Fig. 7 (right), we report the RD curves of DEF-ATC
with probabilistic uniform and top-4 probabilistic uniform quantization. These curves have been generated in the
same way as those in Fig. 4. The results show that quantizing only the highest magnitude components of a vector,
as opposed to the entire vector, can reduce the number of bits required while maintaining a low level of distortion.
VI. CONCLUSION
In this work, we presented an approach for solving decentralized learning problems where agents have individual
risks to minimize subject to subspace constraints that require the minimizers across the network to lie in low-
7A group of nodes is said to be connected if there is a path between every pair of nodes.27
Fig. 7. Beyond single-task estimation. (Left) Network MSD learning curves w.r.t. wo in (2) for three different values of the step-size
k
(µ = 0.001). (Middle) Evolution of the average number of bits/node/component when the variable-rate scheme is used. (Right) Rate-
0
distortion curves of the DEF-ATC (when µ=µ ) with probabilistic uniform and top-4 probabilistic uniform quantization.
0
dimensional subspaces. This constrained formulation includes consensus or single-task optimization as a special
case, and allows for more general task relatedness models such as multitask smoothness and coupled optimization.
To reduce the communication cost among agents, we incorporated compression into the decentralized approach
by employing differential quantization at the agent level to compress the iterates before communicating them to
neighbors. In addition, we implemented in the learning approach an error-feedback mechanism, which consists of
incorporating the compression error into subsequent steps. We then showed that, under some general conditions
on the compression noise, and for sufficiently small step-sizes µ, the resulting communication-efficient strategy is
stablebothintermsofmean-squareerrorandaveragebitrate.Theresultsshowedthat,inthesmallstep-sizeregime,
the iterates generated by the decentralized communication-efficient approach achieve the same performance as the
decentralized baseline full-precision approach where no communication compression is performed. Simulations
illustrated the theoretical findings and the effectiveness of the approach.
APPENDIX A
PROOF OF LEMMA 1
Let denote the complement set of . Since all the components x ,j are in magnitude greater than or
Ic′ Ic
{
j
∈
Ic
}
equal to the components x ,j , we can write:
{
j
∈
Ic′
}
L
1 1
x2 x2, (68)
c j ≥ L j
j (cid:88)∈Ic (cid:88)j=1
from which we conclude the following useful identity:
c
x2 x 2. (69)
j ≥ L∥ ∥
j (cid:88)∈Ic28
Now, to show that the top-c quantizer is a bounded-distortion compression operator with parameters given by (12),
we can manipulate the compression error as follows:
E x (x) 2 = E x α ( (x)) 2 = E x α (x)+α( (x) ( (x))) 2
∥ −C ∥ ∥ − Q S ∥ ∥ − S S −Q S ∥
( =a) x α (x) 2+α2E (x) ( (x)) 2
∥ − S ∥ ∥S −Q S ∥
x α (x) 2+α2β2 (x) 2+α2σ2
≤ ∥ − S ∥ q∥S ∥ q
= (1 α)2 x2+ x 2+α2β2 (x) 2+α2σ2
− j ∥ j ∥ q∥S ∥ q
j (cid:88)∈Ic j (cid:88)∈Ic′
= (1 α)2+α2β2 x2+ x 2+α2σ2
− q j ∥ j ∥ q
(cid:0) (cid:1)j (cid:88)∈Ic j (cid:88)∈Ic′
= x 2 1 (1 α)2+α2β2 x 2+α2σ2
∥ ∥ − − − q ∥ j ∥ q
(cid:0) (cid:0) (cid:1)(cid:1)j (cid:88)∈Ic
(69) c
1 1 (1 α)2+α2β2 x 2+α2σ2, (70)
≤ − − − q L ∥ ∥ q
(cid:16) (cid:17)
(cid:0) (cid:0) (cid:1)(cid:1)
where in (a) we used the fact that α x α (x),E[ (x) ( (x))] = 0 in both cases: biased (α = 1) and
⟨ − S S − Q S ⟩
unbiased (α = 1 ) quantizer ( ).
1+β q2 Q ·
APPENDIX B
MEAN-SQUARE-ERROR ANALYSIS
z qz
We consider the transformed iterates ϕ and ϕ in (49) and (50), respectively. Computing the second-order
i i
moment of both sides of (49), we get:
E ϕz 2 = E (I µ )ϕz µ ϕqz µ z µ zq 2+µ2E s 2, (71)
∥ i∥ ∥ P − D11,i −1 i −1− D12,i −1 i −1− D11,i −1 i −1 − D12,i −1 i −1 ∥ ∥ i ∥
where, from Assumption 2 on the gradient noise processes, we used the fact that:
E[x s ] = E E x s ϕ ,z K = E x E s ϕ ,z K = 0 (72)
⊤i −1 i ⊤i −1 i { ℓ,i −1 ℓ,i −1 }ℓ=1 ⊤i −1 i { ℓ,i −1 ℓ,i −1 }ℓ=1
(cid:104) (cid:104) (cid:12) (cid:105)(cid:105) (cid:104) (cid:104) (cid:12) (cid:105)(cid:105)
with x i −1 = (I P −µ D11,i −1)ϕz i −1−µ(cid:12) (cid:12) D12,i −1ϕqz i −1−µ D11,i −1z i −1 −µ D12,(cid:12) (cid:12)i −1zq i −1. Using similar arguments, we
can also show that:
E ϕqz 2 =E ( µ )ϕqz µ ϕz +µq b µ z ζ(I )+µ zq 2
∥ i∥ ∥ Jϵ′′ − D22,i −1 i −1− D21,i −1 i −1 − D21,i −1 i −1 − −Jϵ′ D22,i −1 i −1 ∥
+µ2E qs 2. (cid:0) (cid:1) (73)
i
∥ ∥
By using similar arguments as those used to establish inequalities (119) and (124) in [40, Appendix D], we can
show that:
E ϕz 2 (1 µσ )E ϕz 2+ µ E ϕqz + z + zq 2+µ2E s 2
∥ i∥ ≤ − 11 ∥ i −1∥ σ
11
∥D12,i −1 i −1 D11,i −1 i −1 D12,i −1 i −1 ∥ ∥ i ∥
(1 µσ )E ϕz 2+ 3µσ 12 2E ϕqz 2+3µσ E z 2+ 3µσ 12 2E zq 2+µ2E s 2 (74)
≤ − 11 ∥ i −1∥ σ
11
∥ i −1∥ 11 ∥ i −1 ∥ σ
11
∥ i −1 ∥ ∥ i ∥
(1 µσ )E ϕz 2+ 3µσ 12 2E ϕqz 2+ 3µσ + 3µσ 12 2 E 1z 2+µ2E s 2,
≤ − 11 ∥ i −1∥ σ
11
∥ i −1∥
(cid:18)
11 σ
11 (cid:19)
∥Vϵ− i −1 ∥ ∥ i ∥29
and
E ϕqz 2 E ϕqz 2+
2µ2
E ϕqz + ϕz q b+ z + zq 2+
∥ i∥ ≤ ∥Jϵ′′ ∥ ∥ i −1∥ 1
−∥Jϵ′′
∥
∥D22,i −1 i −1 D21,i −1 i −1− D21,i −1 i −1 D22,i −1 i −1 ∥
2ζ2 I 2
∥ −Jϵ′ ∥ E zq 2+µ2E qs 2
i 1 i
1 −∥Jϵ′′
∥
∥ − ∥ ∥ ∥
+
10µ2σ 22
2 E ϕqz 2+
10µ2σ 22
1 E ϕz 2+
10µ2
q b 2+
≤ (cid:18)∥Jϵ′′ ∥ 1
−∥Jϵ′′ ∥(cid:19)
∥ i −1∥ (cid:18)1
−∥Jϵ′′ ∥(cid:19)
∥ i −1∥ (cid:18)1
−∥Jϵ′′
∥(cid:19)∥ ∥
10µ2σ2 2ζ2 I 2 10µ2σ2
21 E z 2+ ∥ −Jϵ′ ∥ + 22 E zq 2+µ2E qs 2
i 1 i 1 i
(cid:18)1 −∥Jϵ′′ ∥(cid:19) ∥ − ∥ (cid:18) 1 −∥Jϵ′′ ∥ 1 −∥Jϵ′′ ∥(cid:19) ∥ − ∥ ∥ ∥
+
10µ2σ 22
2 E ϕqz 2+
10µ2σ 22
1 E ϕz 2+
10µ2
q b 2+
≤ (cid:18)∥Jϵ′′ ∥ 1
−∥Jϵ′′ ∥(cid:19)
∥ i −1∥ (cid:18)1
−∥Jϵ′′ ∥(cid:19)
∥ i −1∥ (cid:18)1
−∥Jϵ′′
∥(cid:19)∥ ∥
2ζ2 I 2 10µ2(σ2 +σ2 )
(cid:18)
1∥ −∥− JJ ϵ′′ϵ ∥′ ∥ +
1
−2 ∥2
Jϵ′′
∥21 (cid:19)E ∥Vϵ−1z
i −1
∥2+µ2E ∥qs
i
∥2,
(75)
for some positive constant σ and non-negative constants σ ,σ , and σ independent of µ, and where we used
11 12 21 22
the fact that the 2 induced matrix norm of the block diagonal matrix in (55) satisfies (0,1). In fact,
−
Jϵ′′ ∥Jϵ′′
∥ ∈
from (44), we can re-write in the following form:
Jϵ′′
= (1 γζ)I +γζ . (76)
Jϵ′′
−
M −P Jϵ
By following similar arguments as in [6, pp. 516–517], we can first show that in (76) satisfies:
Jϵ′′
2 (ρ( )+γζϵ)2. (77)
∥Jϵ′′
∥ ≤
Jϵ′′
From (76), we can also show that:
ρ( ) (1 γζ)+γζρ( ). (78)
Jϵ′′
≤ −
Jϵ
Using the fact that ρ( ) (0,1) from [40, Lemma 2] and the fact that γζ (0,1], we obtain ρ( ) (0,1).
Jϵ
∈ ∈
Jϵ′′
∈
Moreover, since ρ( )+γζϵ is non-negative, by replacing (78) into (77), we obtain:
Jϵ′′
(1 γζ)+γζρ( )+γζϵ
∥Jϵ′′
∥ ≤ −
Jϵ
(79)
= 1 γζ(1 ρ( ) ϵ).
ϵ
− − J −
This identity will be used in the subsequent analysis. Returning to the result (75), and as it can be seen from (47),
q
b = b depends on b in (27), which is defined in terms of the gradients J (wo) . Since the costs J (w )
VL⊤,ϵ {∇wk k k } k k
q
are twice differentiable, then b 2 is bounded and we obtain b 2 = O(1).
∥ ∥ ∥ ∥
For the gradient noise terms, by following similar arguments as in [6, Chapter 9], [40, Appendix D] and by using
Assumption 2, we can show that:
E ∥s i ∥2+E ∥qs i ∥2 = E ∥Vϵ−1s i ∥2
≤
v 12β s2 ,maxE ∥Wi −1 ∥2+v 12σ2 s, (80)
(cid:101)30
where v = 1 , β2 = max β2 , and σ2 = K σ2 . Using expression (33), the fact that ϕ =
1 ∥Vϵ− ∥ s,max 1 ≤k ≤K s,k s k=1 s,k i −1
z
ϕ
i
−1+z
i
−1, and the Jordan decomposition of the matrix(cid:80)
A′
in (44), we obtain:
(cid:101)
(cid:101) E ∥s
i
∥2+E ∥qs
i
∥2
≤
v 12β s2 ,maxE ∥A′(ϕz
i
−1+z
i
−1) ∥2+v 12σ2
s
v2β2 E Λ( 1ϕz + 1z ) 2+v2σ2
≤ 1 s,max ∥Vϵ (cid:101)′ Vϵ− i −1 Vϵ− i −1 ∥ 1 s
( ≤a) v 12β s2 ,maxv 22(E ∥Vϵ−1ϕz i −(cid:101) 1+ Vϵ−1z i −1 ∥2)+v 12σ2 s
2v2β2 v2(E ϕz 2+E ϕqz 2)+2v2β2 v2E 1z 2+v2σ2, (81)
≤ 1 s,max 2 ∥ i −(cid:101)1∥ ∥ i −1∥ 1 s,max 2 ∥Vϵ− i −1 ∥ 1 s
where v = . In step (a) we used the sub-multiplicative property of norms and the fact that the 2 induced
2 ϵ
∥V ∥ −
matrix norm of the block diagonal matrix Λ in (44) is equal to 1. Using the bound (81) into (74) and (75), we
′
obtain:
E ϕz 2 1 µσ +2µ2v2β2 v2 E ϕz 2+ 3µσ 12 2 +2µ2v2β2 v2 E ϕqz 2+
∥ i∥ ≤ − 11 1 s,max 2 ∥ i −1∥
(cid:18)
σ
11
1 s,max 2
(cid:19)
∥ i −1∥
(82)
(cid:0) 3µσ2 (cid:1)
3µσ + 12 +2µ2v2β2 v2 E 1z 2+µ2v2σ2,
(cid:18)
11 σ
11
1 s,max 2
(cid:19)
∥Vϵ− i −1 ∥ 1 s
and
E ϕqz 2 +
10µ2σ 22
2 +2µ2v2β2 v2 E ϕqz 2+
10µ2σ 22
1 +2µ2v2β2 v2 E ϕz 2+
∥ i∥ ≤ (cid:18)∥Jϵ′′ ∥ 1
−∥Jϵ′′ ∥
1 s,max 2
(cid:19)
∥ i −1∥ (cid:18)1
−∥Jϵ′′ ∥
1 s,max 2
(cid:19)
∥ i −1∥
(cid:18)2ζ 12 ∥ −I ∥− JJ ϵ′′ϵ ∥′ ∥2 + 10µ 12( −σ 22 ∥2 J+
ϵ′′
∥σ 22 1) +2µ2v 12β s2 ,maxv 22 (cid:19)E ∥Vϵ−1z
i −1
∥2+
(cid:18)1
−10 ∥µ J2
ϵ′′
∥(cid:19)∥q b ∥2+µ2v 12σ2 s.
(83)
Now, for the quantization noise vector z in (40), we have:
i
K
E 1z 2 ζ2v2 E z 2 . (84)
∥Vϵ− i ∥ ≤ 1 ∥ k,i ∥
(cid:32) (cid:33)
k=1
(cid:88)
From (19) and Assumption 3, and since ψ ϕ = ϕ ψ , we can write:
k,i− k,i −1 k,i −1− k,i
E z 2 β2 E ϕ (cid:101) ψ +z(cid:101) 2+σ2 , (85)
∥ k,i ∥ ≤ c,k ∥ k,i −1− k,i k,i −1 ∥ c,k
and, therefore, (cid:101) (cid:101)
K
E z 2 β2 E ϕ ψ +z 2+σ2, (86)
∥ k,i ∥ ≤ c,max ∥ i −1− i i −1 ∥ c
k=1
(cid:88)
whereβ2 = max β2 andσ2 = K σ2 .S(cid:101) incethe(cid:101) analysisisfacilitatedbytransformingthenetwork
c,max 1 ≤k ≤K { c,k} c k=1 c,k
vectors into the Jordan decomposition basis(cid:80)of the matrix A′, we proceed by noting that the term K k=1E ∥z
k,i
∥2
can be bounded as follows: (cid:80)
K
(86)
E z 2 β2 E 1(ϕ ψ +z ) 2+σ2
∥ k,i ∥ ≤ c,max ∥Vϵ Vϵ− i −1− i i −1 ∥ c
k=1
(cid:88)
≤ β c2 ,max∥Vϵ ∥2E ∥Vϵ−(cid:101)1(ϕ i −1(cid:101) −ψ i+z i −1) ∥2+σ2 c (87)
= v2β2 E 1(ϕ ψ +z ) 2+σ2
2 c,max ∥Vϵ− i −(cid:101)1− i (cid:101) i −1 ∥ c
= v2β2 E χ 2+E χq 2 +σ2,
2 c,max ∥ i∥(cid:101) ∥ (cid:101)i∥ c
(cid:0) (cid:1)31
where
χ ≜ (ϕ ψ +z ), (88)
i U⊤ i −1− i i −1
χq ≜ (ϕ ψ +z ). (89)
i VL⊤,ϵ(cid:101) i −1−(cid:101) i i −1
(cid:101) (cid:101)
Therefore, by combining (84) and (87), we obtain:
E 1z 2 ζ2v2v2β2 [E χ 2+E χq 2]+ζ2v2σ2. (90)
∥Vϵ− i ∥ ≤ 1 2 c,max ∥ i∥ ∥ i∥ 1 c
We focus now on deriving the recursions that allow to examine the time-evolution of the transformed vectors χ
i
and χq . Subtracting ϕ from both sides of (31), adding z , and using (33), we can write:
i i 1 i 1
− −
(cid:101)
µ µ µ
ϕ ψ +z = I I ϕ + s b+z
i −1− i i −1 M − M − ζHi −1 A′ i −1 ζ i − ζ i −1
(cid:18) (cid:18) (cid:19) (cid:19)
(cid:101) (cid:101) ( =a) I I µ ϕ(cid:101)z + µ s µ b+ 2I I µ z ,
M − M − ζHi −1 A′ i −1 ζ i − ζ M − M − ζHi −1 A′ i −1
(cid:18) (cid:18) (cid:19) (cid:19) (cid:18) (cid:18) (cid:19) (cid:19)
(cid:101) (91)
z
where in (a) we used the fact that ϕ = ϕ + z . By multiplying both sides of (91) by 1 and by
i −1 i −1 i −1 Vϵ−
using (45)–(48), (51)–(54), and the Jordan decomposition of the matrix , we obtain:
(cid:101) (cid:101) A′
χ i
=
µ ζD11,i −1 µ ζD12,i −1 ϕz i −1
+
µ s i µ 0
+
 χq   µ I + µ  ϕqz  ζ  qs − ζ  q b 
i ζD21,i −1 M −P −Jϵ′ ζD22,i −1 i −1 i
(92)
        
I + µ µ z
P ζD11,i −1 ζD12,i −1 i −1
.
 µ 2I + µ  zq 
ζD21,i −1 M −P −Jϵ′ ζD22,i −1 i −1
  
Again, by using similar arguments as those used to establish inequalities (119) and (124) in [40, Appendix D], we
can verify that:
E χ 2 = E (I + µ )z + µ zq + µ ϕz + µ ϕqz 2 + µ2 E s 2
∥ i∥ P ζD11,i −1 i −1 ζD12,i −1 i −1 ζD11,i −1 i −1 ζD12,i −1 i −1 ζ2 ∥ i ∥
(cid:13) (cid:13)
2((cid:13) (cid:13)1+ µ σ )2E z 2+ 2µ2 E zq + ϕz + ϕqz (cid:13) (cid:13)2+ µ2 E s 2
≤ (cid:13) ζ 11 ∥ i −1 ∥ ζ2 ∥D12,i −1 i −1 D11,i −1 i −1 D12,i −1 i −1∥(cid:13) ζ2 ∥ i ∥
2(1+ µ σ )2E z 2+ 6µ2σ 12 2E zq 2+ 6µ2σ 12 1E ϕz 2+ 6µ2σ 12 2E ϕqz 2+ µ2 E s 2
≤ ζ 11 ∥ i −1 ∥ ζ2 ∥ i −1 ∥ ζ2 ∥ i −1∥ ζ2 ∥ i −1∥ ζ2 ∥ i ∥
(a) 2(1+ µ σ )2+ 6µ2σ 12 2 E 1z 2+ 6µ2σ 12 1E ϕz 2+ 6µ2σ 12 2E ϕqz 2+ µ2 E s 2,
≤ ζ 11 ζ2 ∥Vϵ− i −1 ∥ ζ2 ∥ i −1∥ ζ2 ∥ i −1∥ ζ2 ∥ i ∥
(cid:18) (cid:19)
(93)32
and
2
E χq 2 = E (2I )zq + µ zq + µ z + µ ϕz +(I )ϕqz + µ ϕqz µq b
∥ i∥ −Jϵ′ i −1 ζD22,i −1 i −1 ζD21,i −1 i −1 ζD21,i −1 i −1 −Jϵ′ i −1 ζD22,i −1 i −1− ζ
(cid:13) (cid:13)
(cid:13) µ2 (cid:13)
(cid:13)+ E qs 2 (cid:13)
(cid:13) ζ2 ∥ i ∥ (cid:13)
2 2I 2E zq 2+
4µ2
E zq + z + ϕz + ϕqz q b 2+
≤ ∥ −Jϵ′ ∥ ∥ i −1 ∥ ζ2 ∥D22,i −1 i −1 D21,i −1 i −1 D21,i −1 i −1 D22,i −1 i −1− ∥
4 I 2E ϕqz 2+
µ2
E qs 2
∥ −Jϵ′ ∥ ∥ i −1∥ ζ2 ∥ i ∥
2 2I 2+
20µ2σ 22
2 E zq 2+
20µ2σ 22
1E z 2+
20µ2σ 22
1E ϕz 2+
20µ2
q b 2+
≤ ∥ −Jϵ′ ∥ ζ2 ∥ i −1 ∥ ζ2 ∥ i −1 ∥ ζ2 ∥ i −1∥ ζ2 ∥ ∥
(cid:18) (cid:19)
4 I 2+
20µ2σ 22
2 E ϕqz 2+
µ2
E qs 2
∥ −Jϵ′ ∥ ζ2 ∥ i −1∥ ζ2 ∥ i ∥
(cid:18) (cid:19)
(b) 2 2I 2+ 20µ2(σ 22 2+σ 22 1) E 1z 2+ 20µ2σ 22 1E ϕz 2+ 20µ2 q b 2+
≤ ∥ −Jϵ′ ∥ ζ2 ∥Vϵ− i −1 ∥ ζ2 ∥ i −1∥ ζ2 ∥ ∥
(cid:18) (cid:19)
4 I 2+
20µ2σ 22
2 E ϕqz 2+
µ2
E qs 2.
∥ −Jϵ′ ∥ ζ2 ∥ i −1∥ ζ2 ∥ i ∥
(cid:18) (cid:19)
(94)
In steps (a) and (b) we used the fact that the norm of the components z ,zq is smaller than the norm of the
i 1 i 1
{ − − }
transformed vector 1z . By combining expressions (93) and (94), we obtain:
Vϵ− i −1
µ 2 6µ2σ2 20µ2(σ2 +σ2 )
E χ 2+E χq 2 2 1+ σ +2 2I 2+ 12 + 22 21 E 1z 2+
∥ i∥ ∥ i∥ ≤
(cid:32)
ζ 11 ∥ −Jϵ′ ∥ ζ2 ζ2
(cid:33)
∥Vϵ− i −1 ∥
(cid:18) (cid:19)
6µ2σ 12
1 +
20µ2σ 22
1 E ϕz 2+ 4 I 2+
6µ2σ 12
2 +
20µ2σ 22
2 E ϕqz 2+ (95)
ζ2 ζ2 ∥ i −1∥ ∥ −Jϵ′ ∥ ζ2 ζ2 ∥ i −1∥
(cid:18) (cid:19) (cid:18) (cid:19)
20µ2
q b 2+
µ2
E s 2+E qs 2 ,
ζ2 ∥ ∥ ζ2 ∥ i ∥ ∥ i ∥
(cid:0) (cid:1)
and by using the bound (81) in (95), we get:
µ 6µ2σ2 20µ2(σ2 +σ2 ) µ2
E χ 2+E χq 2 2(1+ σ )2+2 2I 2+ 12 + 22 21 +2 v2β2 v2 E 1z 2
∥ i∥ ∥ i∥ ≤ ζ 11 ∥ −Jϵ′ ∥ ζ2 ζ2 ζ2 1 s,max 2 ∥Vϵ− i −1 ∥
(cid:18) (cid:19)
+
6µ2σ 12
1 +
20µ2σ 22
1
+2µ2
v2β2 v2 E ϕz 2+
ζ2 ζ2 ζ2 1 s,max 2 ∥ i −1∥
(cid:18) (cid:19)
4 I 2+
6µ2σ 12
2 +
20µ2σ 22
2
+2µ2
v2β2 v2 E ϕqz 2+
20µ2
q b 2+
µ2
v2σ2.
∥ −Jϵ′ ∥ ζ2 ζ2 ζ2 1 s,max 2 ∥ i −1∥ ζ2 ∥ ∥ ζ2 1 s
(cid:18) (cid:19)
(96)
Finally, by using (96) in (90), we find the following inequality that describes the evolution of the compression error33
vector z :
i
E 1z 2
∥Vϵ− i
∥ ≤
µ
β2 v2v2 2ζ2(1+ σ )2+2ζ2 2I 2+6µ2σ2 +20µ2(σ2 +σ2 )+2µ2v2β2 v2 E 1z 2
c,max 1 2 ζ 11 ∥ −Jϵ′ ∥ 12 22 21 1 s,max 2 ∥Vϵ− i −1 ∥
(cid:18) (cid:19)
+β2 v2v2 6µ2σ2 +20µ2σ2 +2µ2v2β2 v2 E ϕz 2
c,max 1 2 11 21 1 s,max 2 ∥ i −1∥
+β2 v2v2(cid:0)4ζ2 I 2+6µ2σ2 +20µ2σ2 +(cid:1) 2µ2v2β2 v2 E ϕqz 2
c,max 1 2 ∥ −Jϵ′ ∥ 12 22 1 s,max 2 ∥ i −1∥
q
+20β2 v2v(cid:0)2µ2 b 2+µ2β2 v2v4σ2+ζ2v2σ2. (cid:1)
c,max 1 2 ∥ ∥ c,max 2 1 s 1 c
(97)
From (82), (83), and (97), we finally find that E ϕz 2, E ϕqz 2, and E 1z 2 are coupled and recursively
∥ i∥ ∥ i∥ ∥Vϵ− i ∥
bounded as:
E ϕz 2 E ϕz 2 l
∥ i∥ ∥ i −1∥
 E ϕqz 2  Γ E ϕqz 2 + m , (98)
∥ i∥ ⪯ ∥ i −1∥
 

E ∥Vϵ−1z i ∥2  

 

E ∥Vϵ−1z i −1 ∥2  

 

n  

     
where Γ is the 3 3 matrix given by:
×
a b c
Γ =  d e f , (99)
 
 g h j 
 
 34
with
a ≜ 1 µσ +2µ2v2β2 v2 = 1 µσ +O(µ2), (100)
− 11 1 s,max 2 − 11
3µσ2
b ≜ 12 +2µ2v2β2 v2 = O(µ), (101)
σ 1 s,max 2
11
3µσ2
c ≜ 3µσ + 12 +2µ2v2β2 v2 = O(µ), (102)
11 σ 1 s,max 2
11
10µ2σ2
d ≜ 21 +2µ2v2β2 v2 = O(µ2), (103)
1 1 s,max 2
−∥Jϵ′′
∥
10µ2σ2
e ≜ + 22 +2µ2v2β2 v2 = +O(µ2), (104)
∥Jϵ′′ ∥ 1 1 s,max 2 ∥Jϵ′′ ∥
−∥Jϵ′′
∥
2ζ2 I 2 10µ2(σ2 +σ2 ) 2ζ2 I 2
f ≜ ∥ −Jϵ′ ∥ + 22 21 +2µ2v2β2 v2 = ∥ −Jϵ′ ∥ +O(µ2), (105)
1 1 1 s,max 2 1
−∥Jϵ′′
∥
−∥Jϵ′′
∥
−∥Jϵ′′
∥
g ≜ β2 v2v2 6µ2σ2 +20µ2σ2 +2µ2v2β2 v2 = O(µ2), (106)
c,max 1 2 11 21 1 s,max 2
h ≜ β2 v2v2(cid:0)4ζ2 I 2+6µ2σ2 +20µ2σ2 +(cid:1) 2µ2v2β2 v2 = 4ζ2β2 v2v2 I 2+O(µ2),
c,max 1 2 ∥ −Jϵ′ ∥ 12 22 1 s,max 2 c,max 1 2∥ −Jϵ′ ∥
(cid:0) (cid:1) (107)
µ
j ≜ 2β2 v2v2 ζ2(1+ σ )2+ζ2 2I 2+3µ2σ2 +10µ2(σ2 +σ2 )+µ2v2β2 v2
c,max 1 2 ζ 11 ∥ −Jϵ′ ∥ 12 22 21 1 s,max 2
(cid:18) (cid:19)
µ
= 2ζ2β2 v2v2 (1+ σ )2+ 2I 2 +O(µ2), (108)
c,max 1 2 ζ 11 ∥ −Jϵ′ ∥
(cid:18) (cid:19)
l ≜ µ2v2σ2 = O(µ2), (109)
1 s
q
10µ2 b 2
m ≜ µ2v2σ2+ ∥ ∥ = O(µ2), (110)
1 s 1
−∥Jϵ′′
∥
n ≜ ζ2v2σ2+µ2v4v2β2 σ2+20β2 v2v2µ2 q b 2 = ζ2v2σ2+O(µ2). (111)
1 c 1 2 c,max s c,max 1 2 ∥ ∥ 1 c
If the matrix Γ is stable, i.e., ρ(Γ) < 1, then by iterating (98), we arrive at:
E ϕz 2 l
∥ i∥
lim
i
sup E ∥ϕqz i∥2 
⪯
(I 3 −Γ) −1 m . (112)
→∞  

E ∥Vϵ−1z i ∥2  

 

n  

   
Aswewillseeinthefollowing,forsomegivenlearningproblemsettings(capturedby σ2 ,σ2 ,σ2 ,σ2 ,β2 ,σ2 ),
{ 11 12 21 22 s,max s}
small step-size parameter µ, network topology (captured by the matrix and the variables v2,v2, resulting
A { 1 2 Jϵ }
from its eigendecomposition), and quantizer settings (captured by β2 ,σ2 ), the stability of Γ can be controlled
{ c,max c}
by the damping coefficient ζ and the mixing parameter γ used in steps (18b) and (18c), respectively. Generally
speaking, and since the spectral radius of a matrix is upper bounded by its 1 norm, the matrix Γ is stable if:
−
ρ(Γ) max a + d + g , b + e + h , c + f + j < 1. (113)
≤ {| | | | | | | | | | | | | | | | | |}
Since σ > 0, a sufficiently small µ can make a + d + g strictly smaller than 1. For b + e + h , observe
11
| | | | | | | | | | | |
that if the damping coefficient ζ and the mixing parameter γ are chosen such that:
+4ζ2v2v2β2 I 2 < 1, (114)
∥Jϵ′′ ∥ 1 2 c,max∥ −Jϵ′ ∥35
then b + e + h can be made strictly smaller than 1 for sufficiently small µ. Finally, for c + f + j , observe
| | | | | | | | | | | |
that if the parameters γ and ζ are chosen such that:
2ζ2 I 2
1∥ −Jϵ′ ∥ +2β c2 ,maxζ2v 12v 22 1+ ∥2I −Jϵ′ ∥2 < 1, (115)
−∥Jϵ′′
∥
(cid:0) (cid:1)
then c + f + j can be made strictly smaller than 1 for sufficiently small µ. It is therefore clear that the RHS
| | | | | |
of (113) can be made strictly smaller than 1 for sufficiently small µ and for a damping coefficient ζ (0,1]
∈
and mixing parameter γ (0,1] satisfying conditions (114) and (115). In the following, we analyze in details
∈
conditions (114) and (115). By following similar arguments as in [6, pp. 516–517], we can establish the following
identities on the block diagonal matrices I and 2I appearing in conditions (114) and (115):
−Jϵ′ −Jϵ′
I 2 ( =44) γ(I ) 2 = γ2 I 2 γ2(ρ(I )+ϵ)2, (116)
∥
−Jϵ′
∥ ∥
−Jϵ
∥ ∥
−Jϵ
∥ ≤
−Jϵ
(44)
2I = (1+γ)I γ (1+γ) γ(ρ( )+ϵ) (1,1+γ), (117)
∥
−Jϵ′
∥ ∥ −
Jϵ
∥ ≤ −
Jϵ
∈
where ρ(I ) (0,2) since ρ( ) (0,1). By using the bounds (79) and (116) into (114), we can upper bound
ϵ ϵ
−J ∈ J ∈
the LHS of (114) by:
+4v2v2β2 ζ2 I 2 1 γζ(1 ρ( ) ϵ)+4v2v2β2 (γζ)2(ρ(I )+ϵ)2. (118)
∥Jϵ′′ ∥ 1 2 c,max ∥ −Jϵ′ ∥ ≤ − − Jϵ − 1 2 c,max −Jϵ
The upper bound in the above inequality is guaranteed to be strictly smaller than 1 if:
4v2v2β2 (γζ)2(ρ(I )+ϵ)2 γζ(1 ρ( ) ϵ) < 0. (119)
1 2 c,max −Jϵ − − Jϵ −
Now, by using the above condition and the fact that γζ must be in (0,1], we obtain condition (56) on γζ. For the
second condition (115), we start by noting that its LHS can be upper bounded by:
2ζ2 I 2
1∥ −Jϵ′ ∥ +2β c2 ,maxζ2v 12v 22 1+ ∥2I −Jϵ′ ∥2
−∥Jϵ′′ ∥ (120)
(79),(116),(117) (ρ(I )+ϵ)(cid:0)2 (cid:1)
2γζ −Jϵ +2β2 ζ2v2v2 1+((1+γ) γ(ρ( )+ϵ))2
≤ 1 (ρ( )+ϵ) c,max 1 2 − Jϵ
ϵ
− J (cid:16) (cid:17)
Thus, (115) is guaranteed to be satisfied under condition (57).
Under conditions (56) and (57), ρ(Γ) < 1, and consequently, the matrix Γ is stable. Moreover, it holds that8:
µσ O(µ) O(µ)
11
(I Γ) =  O(µ2) 1 e f , (121)
− −
  O(µ2) h 1 j  
 − 
 
and:
1 O(1) O(1)
µσ11
(I Γ) −1 =  O(µ) O(1) O(1) . (122)
−
 
 O(µ) O(1) O(1) 
 
 
8While constants crucial to understanding the algorithm’s behavior are written explicitly in (121) and (122), the other constants that are
less significant are encapsulated in the Big O notation.36
Now, using (109), (110), (111), and (122) into (112), we arrive at:
E ϕz 2 µv2 σ2 s +O(µ2)+σ2O(1)
∥ i∥ 1σ11 c
limsup E ϕqz 2   O(µ2)+σ2O(1) . (123)
i ∥ i∥ ⪯ c
→∞  

E ∥Vϵ−1z i ∥2  

 

O(µ2)+σ2 cO(1)  

   
By noting that:
limsupE ϕz 2 = limsupE ( 1ϕz ) 2 limsup 2 E ϕz 2+E ϕqz 2
∥ i∥ ∥Vϵ Vϵ− i ∥ ≤ ∥Vϵ ∥ ∥ i∥ ∥ i∥
i i i
→∞ →∞ →∞ (cid:104) (cid:105)
(cid:101) (cid:101) (1 =23) κµ+O(µ2)+σ2O(1), (124)
c
we can finally conclude that (58) holds. Result (59) follows from (124) by replacing σ2O(1) by O(µ1+ε).
c
z
To establish (60), we first show that the mean-square difference between the trajectories {ϕ i,Wi
}
is asymptoti-
z
cally bounded by O(µ1+ε). By subtracting Wi and ϕ i, we can write:
(cid:101) (cid:101)
limsupE ∥Wi −ϕz i∥2 ( =33) lims(cid:101)upE ∥A(cid:101) ′ϕ i−ϕz i∥2
i i
→∞ →∞
(cid:101) (cid:101) = limsupE ∥A′(ϕ(cid:101)z
i
+(cid:101)z i) −ϕz i∥2
i
→∞
= limsupE ((cid:101)Λ I ) (cid:101)1ϕz + Λ 1z 2
Vϵ ′ϵ− M Vϵ− i Vϵ ′ϵVϵ− i
i
→∞ (cid:13) (cid:13)
(43 =),(44) limsup(cid:13) (cid:13)E VR,ϵ( Jϵ′ −I)ϕqz i(cid:101)+ VϵΛ ′ϵVϵ−1z i 2(cid:13) (cid:13)
i
→∞ (cid:13) (cid:13)
≤
limsup 2 ∥V(cid:13) (cid:13)R,ϵ(
Jϵ′
−I) ∥2E ∥ϕqz i∥2+2 ∥VϵΛ(cid:13) (cid:13)′ϵ∥2E Vϵ−1z
i
2 . (125)
i
→∞ (cid:104) (cid:13) (cid:13) (cid:105)
Now, using (123) with σ2O(1) replaced by O(µ1+ε), we can conclude that: (cid:13) (cid:13)
c
limsupE ∥Wi −ϕz i∥2 = O(µ1+ε). (126)
i
→∞
Finally, note that: (cid:101) (cid:101)
E ∥Wi ∥2 = E ∥Wi −ϕz
i
+ϕz i∥2
(cid:101) ≤ E ∥W (cid:101)i −ϕ (cid:101)z i∥2+ (cid:101) E ∥ϕz i∥2+2 |E(Wi −ϕz i) ⊤ϕz i|
( ≤a) E ∥W(cid:101)i −ϕ(cid:101)z i∥2+E ∥ϕ(cid:101)z i∥2+2 E (cid:101) ∥Wi −(cid:101)ϕz i∥(cid:101)2E ∥ϕz i∥2, (127)
(cid:113)
and, hence, from the sub-additivity prop(cid:101)erty o(cid:101)f the limit(cid:101)superior, and(cid:101)from (cid:101)(59) and(cid:101)(126), we get:
limsupE ∥Wi ∥2
≤
limsupE ∥ϕz i∥2+O(µ1+ 2ε), (128)
i i
→∞ →∞
whichestablishes(60).Instep(a),weused E (cid:101)x E x fromJen(cid:101)sen’sinequalityandweappliedHolder’sinequality,
| | ≤ | |
namely, E x ⊤y (E x p)p1 (E y q)q1 when 1/p+1/q = 1, with p = q = 2.
| | ≤ | | | |
The analysis can be simplified in settings where the compression operators are such that their relative
k
{C }
compression noise terms β2 = 0, k. In fact, in such settings, we can replace β2 in (97) by 0, and use the
c,k ∀ c,max
resulting inequality E 1z 2 ζ2v2σ2 directly into (82) and (83), without the need to study the evolution of
∥Vϵ− i ∥ ≤ 1 c37
E 1z 2 as in (98). By doing so, we find that the variances of ϕz and ϕqz are coupled and recursively bounded
∥Vϵ− i ∥ i i
as:
E ϕz 2 a b E ϕz 2 l
∥ i∥ ∥ i −1∥ + ′ , (129)
 E ϕqz 2  ⪯  d e  E ϕqz 2   m 
∥ i∥ ∥ i −1∥ ′
      
where l = l+σ2O(µ), and m = m+σ2O(1). By setting γ = ζ = 1 (so that = ), and by using similar
′ c ′ c Jϵ′′ Jϵ
arguments as in (112)–(124), we can establish the mean-square-error stability for a sufficiently small step-size µ
and obtain the performance result (58).
APPENDIX C
BIT RATE STABILITY
Equation (64) follows from Lemma 1 and Table II (row 3, col. 3–4). Invoking similar arguments to the ones
used to establish Theorem 2 in [26], the individual summands in (62) can be upper bounded by:
ω
ln 1+ E χ 2
η ∥ k,i∥
2+log 2 (cid:18) (cid:113) (cid:19) +2. (130)
2ln ω+√1+ω2
 
 (cid:16) (cid:17) 
 
By taking the limit superior of (96) as i and by using (123) and (64), we obtain:
→ ∞
limsupE χ 2 κ µ1+ε+κ µ2, (131)
∥ k,i∥ ≤ 1 2
i
→∞
for sufficiently small µ, and where κ and κ are some positive constants independent of µ. Applying the limit
1 2
superior to (130), using the fact that (130) is a continuous and increasing function in the argument E χ 2, and
∥ k,i∥
using (131), in view of (64), we find that each summand in (62) is O(1), which in turn implies (65).
REFERENCES
[1] R.Nassif,S.Vlaski,M.Carpentiero,V.Matta,andA.H.Sayed, “Differentialerrorfeedbackforcommunication-efficientdecentralized
optimization,” in Proc. IEEE Sens. Array Multichannel Signal Process. Workshop, Corvallis, OR, USA, Jul. 2024.
[2] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Y. Arcas, “Communication-efficient learning of deep networks from
decentralized data,” in Proc. Int. Conf. Artif. Intell. Stat., Ft. Lauderdale, FL, USA, 2017, vol. 54, pp. 1273–1282.
[3] T. Li, A. K. Sahu, A. S. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE Signal
Process. Mag., vol. 37, pp. 50–60, May 2020.
[4] D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, “QSGD: Communication-efficient SGD via gradient quantization and
encoding,” in Proc. Adv. Neural Inf. Process. Syst., Long Beach, CA, USA, 2017, pp. 1709–1720.
[5] V. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated multi-task learning,” in Proc. Adv. Neural Inf. Process. Syst.,
Long Beach, CA, USA, Dec. 2017, vol. 30.
[6] A.H.Sayed, “Adaptation,learning,andoptimizationovernetworks,” Found.TrendsMach.Learn.,vol.7,no.4-5,pp.311–801,2014.
[7] A. H. Sayed, “Adaptive networks,” Proc. IEEE, vol. 102, no. 4, pp. 460–497, 2014.
[8] A.H.Sayed,S.-Y.Tu,J.Chen,X.Zhao,andZ.Towfic, “Diffusionstrategiesforadaptationandlearningovernetworks,” IEEESignal
Process. Mag., vol. 30, no. 3, pp. 155–171, May 2013.
[9] R. Nassif, S. Vlaski, C. Richard, J. Chen, and A. H. Sayed, “Multitask learning over graphs: An approach for distributed, streaming
machine learning,” IEEE Signal Process. Mag., vol. 37, no. 3, pp. 14–25, 2020.38
[10] D.Kovalev,A.Koloskova,M.Jaggi,P.Richtarik,andS.Stich,“Alinearlyconvergentalgorithmfordecentralizedoptimization:Sending
less bits for free!,” in Proc. Int. Conf. Artif. Intell. Stat., Virtual, 2021, pp. 4087–4095.
[11] A.Koloskova,S.Stich,andM.Jaggi, “Decentralizedstochasticoptimizationandgossipalgorithmswithcompressedcommunication,”
in Proc. Int. Conf. Mach. Learn., 2019, vol. 97, pp. 3478–3487.
[12] R. Nassif, S. Vlaski, and A. H. Sayed, “Adaptation and learning over networks under subspace constraints–Part II: Performance
analysis,” IEEE Trans. Signal Process., vol. 68, pp. 2948–2962, 2020.
[13] X. Cao, T. Bas¸ar, S. Diggavi, Y. C. Eldar, K. B. Letaief, H. V. Poor, and J. Zhang, “Communication-efficient distributed learning: An
overview,” IEEE J. Sel. Areas Commun., vol. 41, no. 4, pp. 851–873, 2023.
[14] A.Koloskova,N.Loizou,S.Boreiri,M.Jaggi,andS.Stich, “AunifiedtheoryofdecentralizedSGDwithchangingtopologyandlocal
updates,” in Proc. Int. Conf. Mach. Learn., Virtual, Jul. 2020, vol. 119, pp. 5381–5393.
[15] Y. Liu, T. Lin, A. Koloskova, and S. U. Stich, “Decentralized gradient tracking with local steps,” Available as arXiv:2301.01313v1,
2023.
[16] T.C.Aysal,M.J.Coates,andM.G.Rabbat, “Distributedaverageconsensuswithditheredquantization,” IEEETrans.SignalProcess.,
vol. 56, no. 10, pp. 4905–4918, 2008.
[17] A.Beznosikov,S.Horvath,P.Richta´rik,andM.H.Safaryan, “Onbiasedcompressionfordistributedlearning,” J.Mach.Learn.Res.,
vol. 24, no. 276, pp. 1–50, 2023.
[18] A. Nedic, A. Olshevsky, A. Ozdaglar, and J. N. Tsitsiklis, “Distributed subgradient methods and quantization effects,” in Proc. IEEE
Conf. Decis. Control, Cancun, Mexico, Dec. 2008, pp. 4177–4184.
[19] X. Zhao, S.-Y. Tu, and A. H. Sayed, “Diffusion adaptation over networks under imperfect information exchange and non-stationary
data,” IEEE Trans. Signal Process., vol. 60, no. 7, pp. 3460–3475, 2012.
[20] D.Thanou,E.Kokiopoulou,Y.Pu,andP.Frossard, “Distributedaverageconsensuswithquantizationrefinement,” IEEETrans.Signal
Process., vol. 61, no. 1, pp. 194–205, 2013.
[21] M. Carpentiero, V. Matta, and A. H. Sayed, “Distributed adaptive learning under communication constraints,” IEEE Open J. Signal
Process., vol. 5, pp. 321–358, 2024.
[22] M. Carpentiero, V. Matta, and A. H. Sayed, “Compressed regression over adaptive networks,” To appear in IEEE Trans. Signal Inf.
Process. Netw.. Available as arXiv:2304.03638v1, 2024.
[23] A.Reisizadeh,A.Mokhtari,H.Hassani,andR.Pedarsani, “Anexactquantizeddecentralizedgradientdescentalgorithm,” IEEETrans.
Signal Process., vol. 67, no. 19, pp. 4934–4947, 2019.
[24] H.Taheri,A.Mokhtari,H.Hassani,andR.Pedarsani, “Quantizeddecentralizedstochasticlearningoverdirectedgraphs,” inProc.Int.
Conf. Mach. Learn., Jul. 2020, vol. 119, pp. 9324–9333.
[25] N. Michelusi, G. Scutari, and C.-S. Lee, “Finite-bit quantization for distributed algorithms with linear convergence,” IEEE Trans. Inf.
Theory., vol. 68, no. 11, pp. 7254–7280, 2022.
[26] R.Nassif,S.Vlaski,M.Carpentiero,V.Matta,M.Antonini,andA.H.Sayed, “Quantizationfordecentralizedlearningundersubspace
constraints,” IEEE Trans. Signal Process., vol. 71, pp. 2320–2335, 2023.
[27] H.Zhao,B.Li,Z.Li,P.Richtarik,andY.Chi, “BEER:FastO(1/T)ratefordecentralizednonconvexoptimizationwithcommunication
compression,” in Proc. Adv. Neural Inf. Process. Syst., New Orleans, Louisiana, USA, 2022, vol. 35, pp. 31653–31667.
[28] N. Singh, X. Cao, S. Diggavi, and T. Bas¸ar, “Decentralized multi-task stochastic optimization with compressed communications,”
Automatica, vol. 159, pp. 111363, 2024.
[29] N. Singh, D. Data, J. George, and S. Diggavi, “SPARQ-SGD: Event-triggered and compressed communication in decentralized
optimization,” IEEE Trans. Automat. Contr., vol. 68, no. 2, pp. 721–736, 2023.
[30] N. Singh, D. Data, J. George, and S. Diggavi, “SQuARM-SGD: Communication-efficient momentum SGD for decentralized
optimization,” in Proc. IEEE Int. Symp. Inf. Theory, Melbourne, Victoria, Australia, 2021, pp. 1212–1217.
[31] H. Tang, S. Gan, C. Zhang, T. Zhang, and J. Liu, “Communication compression for decentralized training,” in Proc. Adv. Neural Inf.
Process. Syst., Montreal, Canada, Dec. 2018, vol. 31, pp. 7663–7673.39
[32] S. P. Karimireddy, Q. Rebjock, S. Stich, and M. Jaggi, “Error feedback fixes SignSGD and other gradient compression schemes,” in
Proc. Int. Conf. Mach. Learn., Long Beach, CA, USA, Jun. 2019, vol. 97, pp. 3252–3261.
[33] H. Tang, X. Lian, S. Qiu, L. Yuan, C. Zhang, T. Zhang, and J. Liu, “DeepSqueeze: Decentralization meets error-compensated
compression,” Available as arXiv:1907.07346, 2019.
[34] A. H. Sayed, Inference and Learning from Data, 3 vols., Cambridge University Press, 2022.
[35] A. Nedic and A. Ozdaglar, “Distributed subgradient methods for multi-agent optimization,” IEEE Trans. Automat. Contr., vol. 54, no.
1, pp. 48–61, Jan. 2009.
[36] D.P.Bertsekas, “Anewclassofincrementalgradientmethodsforleastsquaresproblems,” SIAMJ.Optim,vol.7,no.4,pp.913–926,
1997.
[37] A. G. Dimakis, S. Kar, J. M. F. Moura, M. G. Rabbat, and A. Scaglione, “Gossip algorithms for distributed signal processing,” Proc.
IEEE, vol. 98, no. 11, pp. 1847–1864, 2010.
[38] V. Kekatos and G. B. Giannakis, “Distributed robust power system state estimation,” IEEE Trans. Power Syst., vol. 28, no. 2, pp.
1617–1626, 2013.
[39] R. Nassif, S. Vlaski, C. Richard, and A. H. Sayed, “Learning over multitask graphs–Part I: Stability analysis,” IEEE Open Journal of
Signal Processing, vol. 1, pp. 28–45, 2020.
[40] R. Nassif, S. Vlaski, and A. H. Sayed, “Adaptation and learning over networks under subspace constraints–Part I: Stability analysis,”
IEEE Trans. Signal Process., vol. 68, pp. 1346–1360, 2020.
[41] J. Plata-Chaves, A. Bertrand, M. Moonen, S. Theodoridis, and A. M. Zoubir, “Heterogeneous and multitask wireless sensor networks
– Algorithms, applications, and challenges,” IEEE J. Sel. Top. Signal Process., vol. 11, no. 3, pp. 450–465, 2017.
[42] P. Di Lorenzo, S. Barbarossa, and S. Sardellitti, “Distributed signal processing and optimization based on in-network subspace
projections,” IEEE Trans. Signal Process., vol. 68, pp. 2061–2076, 2020.
[43] J. F. C. Mota, J. M. F. Xavier, P. M. Q. Aguiar, and M. Pu¨schel, “Distributed optimization with local domains: Applications in MPC
and network flows,” IEEE Trans. Automat. Contr., vol. 60, no. 7, pp. 2004–2009, 2015.
[44] S. A. Alghunaim and A. H. Sayed, “Distributed coupled multiagent stochastic optimization,” IEEE Trans. Automat. Contr., vol. 65,
no. 1, pp. 175–190, 2020.
[45] S.U.Stich,J.-B.Cordonnier,andM.Jaggi, “SparsifiedSGDwithmemory,” inProc.Adv.NeuralInf.Process.Syst.,Montre´al,Canada,
2018, pp. 4452–4463.
[46] D. Basu, D. Data, C. Karakus, and S. Diggavi, “Qsparse-local-SGD: Distributed SGD with quantization, sparsification, and local
computations,” in Proc. Adv. Neural Inf. Process. Syst., Vancouver, Canada, 2019, pp. 14695–14706.
[47] B. T. Polyak, Introduction to Optimization, Optimization Software, New York, 1987.
[48] R. A. Horn and C. R. Johnson, Matrix Analysis, Cambridge University Press, 2012.