LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
Role-Play Zero-Shot Prompting with Large Language Models for
Open-Domain Human-Machine Conversation
AhmedNjifenjou and VirgileSucal and BassamJabaian and FabriceLefèvre
LaboratoireInforamitqued’Avignon(LIA),AvignonUniversité
{ahmed-ndouop.njifenjou & firstname.lastname}@univ-avignon.fr
Abstract theleader-to-followersingle-sidedrelationshipis
strongly present and they hardly display human
Recently,variousmethodshavebeenproposed
conversationalabilitiesstraightaway.
to create open-domain conversational agents
withLargeLanguageModels(LLMs). These In this work, as an attempt to deal with these
modelsareabletoansweruserqueries,butin issues while escaping from fine-tuning and its
aone-wayQ&Aformatratherthanatruecon- data dependency, we propose to use role-play
versation. Fine-tuning on particular datasets via zero-shot prompting to leverage instruction-
is the usual way to modify their style to in- followingmodels’abilities. Thisapproachpertains
creaseconversationalability,butthisisexpen-
tothenewlydevisedprompt-basedlearning(PBL)
sive and usually only available in a few lan-
paradigm (Liu et al., 2021). We assess this ap-
guages. In this study, we explore role-play
zero-shot prompting as an efficient and cost- proachontwotasks,ageneralPersonataskbased
effective solution for open-domain conversa- onthePersonaChatdatasettobringthesemodels
tion,usingcapablemultilingualLLMs(Beech- to have a persona while displaying human skills
ing et al., 2023) trained to obey instructions. and a particular case, the INT task (Riou et al.,
Wedesignapromptingsystemthat,whencom-
2019)wherethespeakershavetodiscussanimage,
bined with an instruction-following model -
simulatingasituatedmulti-modalconversation.
here Vicuna (Chiang et al., 2023) - produces
conversationalagentsthatmatchandevensur-
passfine-tunedmodelsinhumanevaluationin 2 RelatedWork
Frenchintwodifferenttasks.
Open-domain dialogue has seen a lot of devel-
1 Introduction
opments with most solutions focusing mainly on
Since their introduction, Transformers (Vaswani fine-tuning with specific collected data. Among
etal.,2017)andderivativeLargeLanguagesMod- others we have the BlenderBot’s (Roller et al.,
els(LLMs)haveconstantlyimprovedthestate-of- 2021) series and other closed-sourced models as
the-art on several Natural Language Processing Meena(Adiwardanaetal.,2020),LaMDA(Thop-
(NLP) tasks. Among them, is open-domain dia- pilan et al., 2022), etc. These models display
loguewhichconsistsinaconversationalagentde- greatconversationalskills,butinadditiontodata
signedtointeractsociallywithusersonanytopic dependency, they are often only available in En-
while displaying human abilities, like empathy, glish. Foundational models are a recent trend
personalityorentertainment(Walkeretal.,2021). in the field of NLP as they display multilingual
CommonapproachesusingLLMsmostlyreliedon abilities and state-of-the-art performance on sev-
fine-tuning with specific datasets often targeting eralbenchmarks. Oneofthem,LLaMA(Touvron
oneormoreoftheseskills(e.g. PersonaChat(?), etal.,2023a,b)isthebackboneLLMofthisstudy.
BlendedSkillTalk(Smithetal.,2020),Empathetic These series of models are trained on an amount
Dialogues(Rashkinetal.,2019)interalia). These of data surpassing the scaling law of (Hoffmann
datasetsareexpensivetobuildandoftenavailable et al., 2022). Such capable LLMs are a prerequi-
onlyinonelanguage. Inadditionrecentdevelop- site to build instruction following models. From
mentsinthefieldofNLPhavefocusedonLLMs LLaMA resulted, among others: Alpaca (Taori
trainedtofollowinstructions(Ouyangetal.,2022). etal.,2023),StackLLaMA(Beechingetal.,2023),
They have the native ability to respond to users’ Guanaco (Dettmers et al., 2023) and the main
inputs in a natural language manner. However, modelofthisstudy,Vicuna(Chiangetal.,2023).
4202
nuJ
62
]LC.sc[
1v06481.6042:viXraLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
The latter has been fine-tuned on the ShareGPT1 3 Methodology
corpuswhichisbasicallyadatasetofconversations
3.1 Instruction-FollowingvsDialogueSkills
producedbyChatGPT(OpenAI,2022)users. They
arecollectedusingawebbrowserplugininstalled Quoting(Reitz,2019),“dialogueismorethanjust
by users willing to participate in the dataset col- havingaconversation. Genuinedialoguedescribes
lection. The resulting models have open-domain a way of interacting that is mutual, relational, at-
responding abilities – which we dissociate from tentive, and meaningful”. Instruction-following
conversationalabilities–andimplicitlyOpenAI models,eventhoseoptimizedforconversationfall
original model’s restrictions, resulting from the short from fulfilling some of these aspects of a
ChatGPT alignment process, as described in the genuine dialogue. Indeed, social aspects - mutu-
OpenAIdocumentation(Leikeetal.,2022). ality, relationality and attention – especially are
poorlydisplayed. Talkingofmutuality,thesesys-
The idea behind instruction following models temsoftenconverseinaleader-followerstructure
lays within a new paradigm in NLP, coined as wheretheyarethefollowerandtheusertheleader
Prompt-Based Learning (PBL) (Liu et al., 2021). –thisisforinstanceevidencedbythewordsused
While using such models to perform prediction todesignateuserentriesinChatGPTreleaseblog:
tasks,theirinputsaremodifiedfollowingaglobal “queries”,“instructions”(OpenAI,2022). Regard-
templateintoatextualstringpromptthathassome ingrelationalityandattention,thesesystemslack
unfilledslots,andthenthelanguagemodelisused of straightforward engagingness and personality
to fill the unfilled information to obtain a final consistency.
string,fromwhichthefinaloutputcanbederived, Commonly,theselimitationshavebeentackled
inagenerativeway. Onemajorassetofthemethod, withfinetuning. However, thisiscostlyanddata-
whichmakesitverypowerful,isthatitallowsthe dependantwhichdataarescarceinlanguagesother
LLMtobepre-trainedonhugequantityoftextand, than English. As results, we formalize a general
bydefininganewpromptscheme,themodelcan role-playpromptstructurewhichisamoreefficient
performfew-shot—orevenzero-shot—learning, andlessexpensiveapproach. Indeed,itavoidsfine-
andadapttonewscenariiwithfewornolabelled tuningandrelyonmultilingualLLMsprompted
data. inEnglish,withexternalEnglishdataifneeded
(for instance persona from PersonaChat Dataset)
(Santu and Feng, 2023) proposed a general
and performs dialogue task in a desired target
prompt taxonomy to unify complex tasks bench-
languagehereinFrench.
marking which shares the idea of prompt struc-
turing with our work. However, with role-play 3.2 Role-PlayPrompting
prompting, wespecificallytargetdialoguewhich
ItisimportanttounderstandthatRole-PlayPrompt-
requires even more complex abilities. The role-
inghereisnotrestrictedtoplayingagivencharac-
playpromptschemeproposedinthisGitHubrepos-
ter. Tobetterunderstandthat,let’sconsiderthesim-
itory2 intendedforanLLM-basedDiscordbotis
ulacra and simulator framing in (Shanahan et al.,
closertoourneeds. However,itisdesignedforpro-
2023). LLMisasimulatorwhichswallowedmyr-
vidingonlypersona-basedinformation. Role-play
iads of simulacra during the pre-training and at
prompting as we want to demonstrate is not just
eachsimulationitkindofrandomlyselectsamong
limited to character or persona level instructions.
any of them which oneS to display. The simu-
Role-Play can be used in order to enforce other
lacrum is, as a matter of fact, not only about per-
conversationalskills,suchasempathyorengaging- sonabackground(Smithetal.,2020)butalsothink-
ness,whichhelpbalancethedialoguebetweenthe ing and writing styles, personal situation (Smith
userandthebot. Weappliedthisapproachtotwo
et al., 2020), target language (for a multilingual
scenarii,withoutfine-tuning.
simulator)andinformationprocessing(long-term
memory, user personalization, response filtering
etc.). All possible simulacra already exist in the
simulator(LLM)butitdoesn’tdisplayallofthem
natively, in fact it can’t. Role-Prompting enters
1https://sharegpt.com
thechattomaketheLLMfavorsimulacrathatare
2https://github.com/teknium1/
alpaca-roleplay-discordbot suitableforagivendialoguetask. Inthispaper,weLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
derivedtwodistinctdialoguetaskstoassesstheef- ofoldturnsorinformationfromexternalsub-
ficiencyofthisapproach. Thefirsttask,referredas modules.
Personatask,usesRole-PlayPromptingforenhanc-
inghumannessinconversationskills. Thesecond
3. Response Instructions I = {i }Ni :
one,referredasINTtask,derivesRole-Playtoal- a a,k k=1
ThesearefinalinstructionstoincitetheLLM
lowtheLLMtotalkaboutasimulacruminsteadof
to respond to the users’ utterance with em-
interpretingit.
phasisonthewritingstyle,thetargetrespond-
inglanguageandcreativitywithsection2)in
3.3 PromptStructure
mind.
Open-domaindialoguebelongingtotherealmof
complextasks(SantuandFeng,2023)makesthe
4. ConversationHistoryXt: thispartcontains
endeavourofrole-playpromptingmorechalleng-
previous messages from the user (xt) and
ing. As a matter of fact, small variations in a
the LLM (yt). They can be truncated to
promptmayhamperthemodel’sobservedperfor-
the k latest conversation turns to fit in the
mance. Forthisreason,itismandatorytodefinea
LLM token size limit or help the LLM fo-
generalpromptstructurethatcanbeadaptedlater
cusonlatestpartoftheconversation. Inthis
todifferentconversationaltasks. Hence,withthe
˜
case a summary of the k removed turns Xk
concernsofdealingwiththepreviouslymentioned
generatedbyanexternalmodule(alsousing
limitationsweretainthefollowingsections–each
PBL with an LLM) can be added in section
focusingondifferentaspectsusefultoadialogue–
2). Conversationhistory,thereforebecomes:
asbuildingblocksofapromptengineeringmodule:
Xt−1 = {(xt−k,yt−k),...,(xt−1,yt−1)}
1. SystemInstructionsI = {i }Ni : where
s s,k k=1
N is the number of instructions i which Thesesectionscanbefurtherprecisedintosub-
i s,k
sharplydefinethetargettask’sspecifications sections and their order is set to vary as it may
and the global desired behaviour. This may be suitable to give more or less importance to
includethinking(inferring)andwriting(gen- one section than another for the final model’s
eration)styles. response depending on the task at hand. This
willbeshowcasedinourtwoexperimentedtasks
2. SituationalcontextCt = {c }Nc : eachc is later on. Finally, the prompt builder returns:
k k=1 k
acontextinformationthatmayhelpthemodel Pt = σ (I ,Ct,I ,Xt−1)whereσ isthe
task task s a task
better perform the desired task. As such, it most suitable permutation for the dialogue task
evolveswithtimedependingontheconversa- at hand. Therefore at each turn, the model maxi-
tionflow. Itcanincludepersonalityinforma- mizesthefollowingprobability: p(yt|xt,Pt )to
task
tion,imageandscenedescription,summaries respond.
Figure1: ArchitectureoftheRole-playZero-shotprompteddialoguesystem.LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
4 Experiments theentireconversation,oldexchangesaresumma-
rized in a few sentences. To personalize the user
AllexperimentsarecarriedoutinFrenchbutthe
experience,alinecontaininguser-specificinforma-
prompt contains instructions mainly in English,
tionisaddedandupdatedregularly. Thisaspectis
oneofwhichspecifiesthetargetresponselanguage.
generallyreferredtoaslong-termmemory. These
Giventheresultsobtainedby(Laietal.,2023)and
"modules" are actually prompts sent to an LLM.
thosewepresentinAppendixA,weassumethat ThehistoryXt oftheconversationiskeptatthe
thiscanbeappliedtootherlanguagesinwhichthe
end of the Advanced Prompt so that the system,
assessedmodelperformscomparably,asinFrench.
whengeneratingaresponse,hasanoverviewofthe
entireconversation.
4.1 SystemArchitecture
ThesystemshowninFigure1isapipelineofsev- 4.3 SimulatingMulti-modalConversations:
eralmodules. Theseincludeawebinterfacebased theINTTask
ontheRasaX(Rasa,2022)tool,modifiedtointe-
Ifamodeliscapableofinterpretingaroleinorder
gratevoicefunctionalityusingtheGoogleChrome
to embody a character, we can assume that it is
Speech-to-textandText-to-speechAPIs. Thisen-
alsocapableoftalkingaboutarolewithoutinter-
ablesuserstoexchangeeasilywiththeagent,either
preting it. To test the validity of this hypothesis,
byvoice(recommended)orbytext. Next,amodule
weproposeapromptdesignedtoenabletheLLM
thatconstructsthepromptaccordingtothegeneral
to converse about a specific topic. This topic is
structuredescribedin3.2fromtheuser’s(textual)
definedintheformofarolethattheLLMwillbe
messageandinformationbothexternalandinternal
encouragedtodescriberatherthaninterpret.
totheconversation. Aftergeneration,iftheLLM
responsesarenotvalid,afilteringmoduleisusedto 4.3.1 Taskdefinition
applycorrectionsbeforesendingthemtotheuser
The dialogue system is intended to conduct mul-
(cf. AnnexC).
timodal conversations set in the context of a neu-
roscience experiment (Chaminade, 2017). Inside
4.2 Open-domainConversationWithHuman
an fMRI scanner, a person must converse with a
Capabilities: thePersonaChatTask
Furhat 3 robotic head, which is alternately con-
ThistaskinvolvesenhancingLLM’sconversational nected(unbeknownsttohim)toadialoguesystem
capabilities by using roles built from personality or to a human. The interlocutors talk about an
traitsdrawnfromthePersonaChatdataset(Zhang imagepresentedtothem. Theirconversationismo-
etal.,2018)embeddedinCtasexternalinformation
tivatedbythecommongoaloffindingtheimage’s
(seeconversationexampleinAppendixD.1). promotionalmessage(seeconversationexamples
inAppendixD.2).
4.2.1 ShallowPrompt
GiveninAppendixE.3,itisclosetoVicuna’sba- 4.3.2 Prompt
sic prompt (Appendix E.1). However, there are Thepromptisdesignedfollowingthestructurede-
(cid:32) (cid:33)
some additions for the sake of fair comparisons: 1 0 0 0
scribedinSection3.2withσ = 0 0 0 1 i.e.,
systeminstructionstodescribethetask,contextual task 0 1 0 0
0 0 1 0
information (notably personality traits), and the
instructions related to the response (I ) and the
r
instructiontocompletetheconversationhistory.
context(Ct)areplacedafterthehistory(Xt). This
permutationgroupsalltheinstructionsdedicatedto
4.2.2 AdvancedPrompt
thetaskattheendoftheprompt,i.e. justbeforethe
It exactly follows the structure in Section 3.2 i.e.
lastusermessage(xt). Thisactuallycorresponds
σ = Id (see appendix E.3). The context
task 4 tothemostcommonpatterninVicuna’sfine-tuning
Ct includesthespecificationofhumanitywhere
corpus—ShareGPT —whichincludesexchanges
personalitytraitsareaddedwiththeinjunctionto
where users can only communicate their instruc-
choose a name consistent with them if necessary.
tionstotheLLM(ChatGPT)insidetheirmessages
Externalmodulescanaugmentthisundercertain
(viathewebinterface),thosearoundthelastmes-
conditions,asin(Shusteretal.,2022). Indeed,to
sagebeingthemostimportant.
preventpromptsfromexceedingtheLLM’smax-
imum context size while retaining the content of 3https://furhatrobotics.comLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
Thisstructureallowsthemodeltofocusonthe atedinaChatbotArenastyle(Zhengetal.,2023).
image (linked to the goal) rather than the conver- Evaluatorscomparedtwoself-chatsfromdifferent
sation’shistoryXt,unliketheprevioustaskwhere setupsoneachcriterionandingeneral. Thescores
Xt was paramount. This is also why Ct, in addi- presentedinTable1areEloscores(Elo,1978)cal-
tiontoexternalinformation(inthiscasetheimage culatedfromthecomparisons’results. Atotalof18
description), includes general instructions sum- annotatorsevaluated982generatedconversations
marizingthetaskathand. of10roundseach(whichcorrespondtoaround70
dialoguesperconfigurationand5to14battlesper
5 HumanEvaluation pair).
Foragivendialogueinput,severalresponsesmay Criteria
LLM Prompts Overall Rank
be correct. For this reason, human evaluation re- (1) (2) (3)
FSB∗ 918 916 918 919 9
mains more reliable than automated references-
LLaMA-13B Shallow 902 900 912 910 10
basedevaluations. Therefore,iswasperformedfor Advanced 891 895 897 883 11
Shallow 987 991 984 990 8
alltheconsideredevaluationsetsandforbothtasks. Guanaco-13B
Advanced 1022 1020 1014 1022 7
Threecriteria,basedonthosementionedin(Mehri Shallow 1033 1037 1020 1033 6
Vicuna-7B
Advanced 1035 1025 1063 1034 5
and Eskenazi, 2020; Roller et al., 2021; Ji et al.,
Shallow 1050 1065 1051 1046 2
2022),wereselectedonwhicheachconversation Vicuna-13B Advanced 1041 1040 1046 1041 4
was rated on a 1-5 scale by three different eval- Vicuna-33B Shallow 1042 1048 1023 1043 3
Advanced 1074 1058 1068 1073 1
uators: (1) coherence, the ability for the system
(1),(2),(3)aspreviouslydefinedinSection5
to propose responses that are consistent with the
Table1: ELOscoresfromself-chatsmodel-to-model
conversationhistory;(2)engagingness,theability
battleswithhumanannotations.
toreviveconversationbyprovidingmessagesthat
requireresponses; (3)humanness,theabilityto
We can see that larger model sizes and
respondasahumanbeingwoulddo. Anadditional
instruction-tuningleadtobetterperformance. On
specific criterion for the INT task is added: (4)
the one hand, Vicuna tops the chart, followed
achievement, the validation of the speakers suc-
by Guanaco. On the other hand, LLaMA under-
cessinachievingtheirgoal(cf. Section4.3). Users
performs with the proposed prompt and the FSB
(resp. evaluators) were never aware of the iden-
prompt. As the Vicuna-33B + Advanced Prompt
tityofthesystemtheywereinteractingwith(resp.
combination ranked first was too costly (latency,
evaluating).
resources)forthecollectionofhuman-modelcon-
Furthermore, to assess the effectiveness of the
versations, the Vicuna-13B + Advanced Prompt
proposedmethodonLLMs,itisessentialtocom-
combination was selected for collection and the
paretheperformancewithsimilarapproachesbut
nextroundofevaluations4.
alsodifferentmodels(differentsizes,trainingdata
andwithandwithorwithoutinstructionsettings).
5.2 Human-botchatsevaluation
For this sake, we added the Few-shot Bot (FSB)
5.2.1 PersonaChatTask
promptproposedby (Madottoetal.,2021)which
consistinprovidingonlydemonstrationexamples Wecollected103conversationsfrom11usersin-
to an non-instruction tuned LLMs. For the lat- structed to exchange with models via the web in-
ter,weselected: Vicuna7B,13Band33B(Zheng terface (cf. 4.1). After removing invalid conver-
etal.,2023),Guanaco-13B(Dettmersetal.,2023) sations, 72 were retained for evaluation. Con-
andLLaMA-13B(Touvronetal.,2023a). Wealso versations were also conducted with Blender-
carriedoutstatisticalstudiesontheresponsesgen- Bot1(BB1)(Rolleretal.,2021),astate-of-the-art
erated. Theresultsobtainedandtheiranalysisare fine-tuned system, for comparison. Each sample
reportedinSection6.1. is evaluated by three (out of a total of 12) differ-
entannotatorsforeachcriterion,andthemedianis
5.1 Self-ChatsEvaluation usedasthesamplescore(resultsinTable2).
The Advanced Prompt scores highest for co-
Collectinghuman-botconversationsisexpensive.
herence. We assume that this is mainly due to
For this reason, we generated conversations be-
tween two instances, each model + prompt com-
4Won75%ofdirectcomparisonswithVicuna+Shallow
bination(self-chats). Theirperformanceisevalu- despitebeingrankedbehindoverall.LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
Criteria experiment,theinterlocutorsmustfindthepromo-
Strategy Config.
(1) (2) (3) tionalobjectiveoftheimage. Acloserlookatthe
conversationsinWoZrevealsthatthehumanagent
Finetuning BB1 2.95 3.85 3.00
was less goal-oriented than the artificial agents,
Roleplay Shallow 3.78 3.30 2.74
whichmayexplainthesuccessresult.
PromptingAdvanced 3.88 3.72 3.40
For engagingness, the Vicuna-based model is
Table2: AveragescorepercriterionforPersonaChat encouragedtoaskquestionstorevivetheconversa-
tion. Thisfactmayexplaintheeffectivenessofthis
systeminstayingengagedthroughouttheconversa-
Vicuna-13B’s intrinsic emergent abilities, as this
tion. Therearefarfewerquestionsinconversations
results is close to those of the Shallow Prompt (-
producedwithothersystems. Aspreviouslystated
0.1). Asfarashumannessisconcerned,whilethe
forPersonaChattask,weassumethatthehighco-
AdvancedPrompthasthebestscore,theShallow
herencescoresaremainlyduetotheeffectiveness
hastheworst. Thishighlightstheimpactofstruc-
ofVicuna.
tured role-playing instructions in the Advanced
Prompt. Finally,forengagingness,BB1stillsetthe 6 StatisticalAnalysisofCollected
pace. Althoughithasbeenfine-tunedonaspecific Conversations
dataset that allows it to ask and answer personal
questions(Smithetal.,2020)whichisimportant 6.1 QualityMetrics
in the rating of this criterion (as presented in the
Statisticaldatawascomputedforallconversations.
AppendixB),itiscloselyfollowedbyAdvanced
Among these, the vocabulary size, which is the
Prompt(-0.13).
numberofdifferentlemmasineachmessageand
intheconversationasawhole. Allmessageswere
5.2.2 INTTask
lemmatizedwiththeSpacylibrary’smorphosyntac-
Theevaluationwasperformedon27conversations
ticlabelingtool(Honnibaletal.,2020)forFrench5.
carriedoutby4users. Theconditionswereidenti-
Thenumberofwordspermessageforeachspeaker
calto thosefor thePersonaChattask, except that
typeisalsoreportedtogiveanotherviewofsystem
the testers (both users and evaluators) also ob-
performance.
served an image linked to the conversation (c.f.
Section 4.3). Our system, "Vicuna & Advanced
Vocabularysize
Prompt",iscomparedtoanearliersystemdesigned Strategy Configuration
Agent User Gap
for the same task called Lilia (Riou et al., 2019)
Finetuning BB1 772 687 85
andtohumanbeingsparticipatinginaWizardof
Oz-typeexperiment(WoZ).10ratersevaluated8 Vicuna&Shallow 2569 965 1604
Roleplay
to9conversationsforeachsystem. Theresultsare Prompting
Vicuna&Advanced 2239 1043 1196
presentedinTable3.
(a)PersonaChat
Criteria
Strategy Config.
(1) (2) (3) (4)
Vocbularysize
WoZ 3.46 3.21 3.36 2.96 Strategy Configuration
Reference Agent User Conv.
Lilia 3.57 3.43 2.64 3.75
Roleplay Vicuna& WoZ 346 390 537
3.93 4.25 3.29 4.00 Reference
Prompting Advanced
Lilia 254 197 330
Table3: AveragescorepercriterionforINT Roleplay
Vicuna&Advanced 746 365 864
Prompting
TheVicuna&AdvancedPromptsystemscores
(b)INT
best on all criteria, with the exception of human-
ness,whereWoZreceivedthehighestscore. This Table4: Vocabularysizeperspeakertype
was to be expected, given that in this experiment
theagentwasahumanbeing. However,itwasless
5fr_core_news_smavailableathttps://spacy.io/
predictable that this was not also the case for the
models/fr?_x_tr_hist=true#fr_core_news_
other criteria. As explained in Section 4, in the smLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
100 100 100 100
80 80 80 80
60 60 60 60
40 40 40 40
20 20 20 20
0 0 0 0
Vicuna + Adv. Vicuna + Shallow BB1 Vicuna + Adv. Vicuna + Shallow BB1 Lilia WoZ Vicuna + Adv. Lilia WoZ Vicuna + Adv.
Configuration Configuration Configuration Configuration
(a)Agent (b)User (c)Agent (d)User
A-PersonaChat B-INT
Figure2: Averagewordscountpermessage
6.1.1 PersonaChatTask systemisquitecomparabletowhatcanbeobserved
inWoZ.
TheagentstatisticsinTable4aandFigure2ahigh-
lightamajorflawforinstructions-followingmod-
6.2 FilteredErrorsAnalysis
els: extremeverbosity.
Erroroccurrencesinresponsegenerationhavebeen
The vocabulary size per speaker type (shown
evaluated on 100 self-chats for each setup. Each
in Table 4a) of the collected conversations also
of these conversations contains 10 turns. Results
givesanideaoftheperformanceoftheproposed
forbothtasksarereportedinTable5. Allratesare
method. WenotethatBB1hastheleastvocabulary,
computedoverallturns. Detailsonerrorsaregiven
whichmayworktothedetrimentofthecoherence
inAppendixC.
score. However,itsagentanduservocabularysizes
aremorebalanced,resultinginabetterengaging-
nessscore. Incontrast,thegapbetweenthesetwo Persona Regex Language Incomplete/Empty
measuresforLLM+promptsapproachesismuch Chat Shallow 0.007 0.000 0.092
Advanced 0.002 0.001 0.148
wider. It is nevertheless reduced with Advanced
Empty TooLong Total
Prompt, which may be the reason for the slight INT Detected 0.080 0.150 0.230
improvementintheengagementscore. Fixed 0.080 0.040 0.120
6.1.2 INTTask Table5: Occurrencerateoferrortypesforbothtasks.
AsforPersonaChattask,Vicuna’sverbositymea-
Detection rates were calculated for the two
sureispresentinFigure2candTable4b. Onthe
prompts in the PersonaChat task. As several er-
other hand, as the Lilia system’s responses were
rors can occur for the same message in this task,
builtfrompre-establishedexpertmodels,itsvocab-
the totals have not been calculated. Additionally,
ularyislimited.
alldetectederrorsarecorrected.
In WoZ conversations, the average vocabulary
On the other hand, errors in the INT task are
sizeisalmostidenticalbetweenusersandtheagent.
correctedonlyiftheproposedcorrectionscomply
Users also have a wider range of message sizes
withtheresponsefilteringrules(seeAppendixC.2).
when chatting with a human. Thus, in these con-
Forbothtypesoferror,wehavecalculatedseparate
versations, agent messages seem to call for more
rates for detected and corrected errors. As these
diverse responses and neither interlocutor seems
errors cannot occur in the same message, a total
tobedirectingthedialogue. Similarly,thisgapis
ratehasbeencalculated.
alsohigherforconversationswithVicunathanfor
thosewithLilia.
7 Conclusion
Table4bshowsahighervocabularysizeforthe
user in WoZ conversations. This is even greater This paper explored the use of structured role-
thanthatoftheagent. Thismaybeanindicatorof playpromptengineeringtoimproveopen-domain
greatervarietyinuserresponses. Here,thevocabu- human-machineconversationswithLLMs. Role-
larysizeofusersinteractingwiththeVicuna-based playpromptingisasimpleandinexpensivemethod
egassem
rep
tnuoc
sdrow
egarevA
egassem
rep
tnuoc
sdrow
egarevA
egassem
rep
tnuoc
sdrow
egarevA
egassem
rep
tnuoc
sdrow
egarevALatestversionofapaperoriginallysubmittedtoSIGDIAL2023
of upgrading the behavior of language models to Damoc, Aurelia Guy, Simon Osindero, Karen Si-
makethemconversationalagents. Ithasbeenap- monyan, Erich Elsen, Jack W. Rae, Oriol Vinyals,
andLaurentSifre.2022. Trainingcompute-optimal
pliedhereinFrench,butitcanbeadaptedtoother
largelanguagemodels.
languages by orienting the role that way. Exper-
iments in two different tasks, persona-based task Matthew Honnibal, Ines Montani, Sofie Van Lan-
deghem,andAdrianeBoyd.2020. spaCy: Industrial-
andsimulatedmultimodaldialogues,haveshown
strengthNaturalLanguageProcessinginPython.
that, although language models still have signifi-
cant shortcomings, such as hallucinations, users’ TianboJi,YvetteGraham,GarethJ.F.Jones,Chenyang
perception of these agents can be comparable to Lyu,andQunLiu.2022. Achievingreliablehuman
assessmentofopen-domaindialoguesystems.
thatofhigher-costfinetunedmodels.
Inaddition,ourexperimentshaveshownusthat Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen,
promptengineeringneedstobefurtherimproved FranckDernoncourt,RyanRossi,andThienNguyen.
2023. Okapi: Instruction-tunedlargelanguagemod-
byautomatingthebuildingandfilteringprocesses.
elsinmultiplelanguageswithreinforcementlearning
Asitis,notonlytoomanyfactorsimpliedrelyon
fromhumanfeedback. InProceedingsofthe2023
thedesigner’sexpertise,butevenmoretheyareset Conference on Empirical Methods in Natural Lan-
onceandforallwhentheycouldalsoevolvewith guage Processing: System Demonstrations, pages
thesituationduringthecourseofthedialogue. Asa 318–327,Singapore.AssociationforComputational
Linguistics.
perspective,weproposetoupgradethemodelpro-
posedherewithafullreinforcementlearningsetup Jan Leike, John Schulman, and Jeffrey Wu. Our ap-
so as to automatically derive the prompt-making proachtoalignmentresearch[online].2022.
actions.
ZhaojiangLin,ZihanLiu,GentaIndraWinata,Samuel
Cahyawijaya,AndreaMadotto,YejinBang,Etsuko
Ishii,andPascaleFung.2021. XPersona: Evaluating
References multilingual personalized chatbot. In Proceedings
ofthe3rdWorkshoponNaturalLanguageProcess-
DanielAdiwardana,Minh-ThangLuong,DavidR.So,
ing for Conversational AI, pages 102–112, Online.
JamieHall,NoahFiedel,RomalThoppilan,ZiYang,
AssociationforComputationalLinguistics.
ApoorvKulshreshtha,GauravNemade,YifengLu,
andQuocV.Le.2020. Towardsahuman-likeopen- PengfeiLiu,WeizheYuan,JinlanFu,ZhengbaoJiang,
domainchatbot. Hiroaki Hayashi, and Graham Neubig. 2021. Pre-
train, prompt, and predict: A systematic survey of
Edward Beeching, Younes Belkada, Kashif Rasul,
promptingmethodsinnaturallanguageprocessing.
Lewis Tunstall, Leandro von Werra, Nazneen Ra-
CoRR,abs/2107.13586.
jani,andNathanLambert.2023. Stackllama: Anrl
fine-tunedllamamodelforstackexchangequestion AndreaMadotto,ZhaojiangLin,GentaIndraWinata,
andanswering. andPascaleFung.2021. Few-shotbot:Prompt-based
learningfordialoguesystems.
ThierryChaminade.2017. Anexperimentalapproach
tostudythephysiologyofnaturalsocialinteractions. Shikib Mehri and Maxine Eskenazi. 2020. Unsuper-
InteractionStudies,18(2):254–276. visedevaluationofinteractivedialogwithdialogpt.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, OpenAI. Introducingchatgpt[online].2022.
ZhanghaoWu,HaoZhang,LianminZheng,Siyuan
Zhuang,YonghaoZhuang,JosephE.Gonzalez,Ion LongOuyang,JeffWu,XuJiang,DiogoAlmeida,Car-
Stoica, and Eric P. Xing. 2023. Vicuna: An open- rollL.Wainwright,PamelaMishkin,ChongZhang,
sourcechatbotimpressinggpt-4with90%*chatgpt SandhiniAgarwal,KatarinaSlama,AlexRay,John
quality. Schulman,JacobHilton,FraserKelton,LukeMiller,
Maddie Simens, Amanda Askell, Peter Welinder,
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
LukeZettlemoyer.2023. Qlora: Efficientfinetuning Traininglanguagemodelstofollowinstructionswith
ofquantizedllms. humanfeedback.
ArpadE.Elo.1978. Theratingofchessplayers, past Rasa. 2022. Rasa X Community Documen-
andpresent. NewYork: ArcoPub. tation. https://legacy-docs-rasa-x.
rasa.com/docs/rasa-x/0.32.x/.
JordanHoffmann,SebastianBorgeaud,ArthurMensch,
Elena Buchatskaya, Trevor Cai, Eliza Rutherford, HannahRashkin,EricMichaelSmith,MargaretLi,and
DiegodeLasCasas,LisaAnneHendricks,Johannes Y-Lan Boureau. 2019. Towards empathetic open-
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, domainconversationmodels: anewbenchmarkand
KatieMillican,GeorgevandenDriessche,Bogdan dataset. InACL.LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
MeganReitz. Organisationaldialogueandleadership Mark Diaz, Ben Hutchinson, Kristen Olson, Ale-
[online]. 2019. https://www.meganreitz. jandraMolina,ErinHoffman-John,JoshLee,Lora
com/dialogue-and-leadership. Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
Lamm,ViktoriyaKuzmina,JoeFenton,AaronCo-
Matthieu Riou, Bassam Jabaian, Stéphane Huet, and hen,RachelBernstein,RayKurzweil,BlaiseAguera-
Fabrice Lefèvre. 2019. Lilia, a showcase for fast Arcas,ClaireCui,MarianCroak,EdChi,andQuoc
bootstrapofconversation-likedialoguesbasedona Le.2022. Lamda: Languagemodelsfordialogappli-
goal-oriented system. In 7th International Confer- cations.
enceonStatisticalLanguageandSpeechProcessing
(SLSP),pages31–43,Cham.SpringerInternational HugoTouvron,ThibautLavril,GautierIzacard,Xavier
Publishing. Martinet,Marie-AnneLachaux,TimothéeLacroix,
BaptisteRozière,NamanGoyal,EricHambro,Faisal
Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Azhar,AurelienRodriguez,ArmandJoulin,Edouard
Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Grave,andGuillaumeLample.2023a. Llama: Open
EricMichaelSmith,Y-LanBoureau,andJasonWe- andefficientfoundationlanguagemodels.
ston. 2021. Recipes for building an open-domain
chatbot. In Proceedings of the 16th Conference of Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
theEuropeanChapteroftheAssociationforCompu- bert, Amjad Almahairi, Yasmine Babaei, Nikolay
tationalLinguistics: MainVolume,pages300–325, Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Online.AssociationforComputationalLinguistics. Bhosale,DanBikel,LukasBlecher,CristianCanton
Ferrer,MoyaChen,GuillemCucurull,DavidEsiobu,
ShubhraKantiKarmakerSantuandDongjiFeng.2023. JudeFernandes,JeremyFu,WenyinFu,BrianFuller,
Teler: Ageneraltaxonomyofllmpromptsforbench- CynthiaGao,VedanujGoswami,NamanGoyal,An-
markingcomplextasks. thonyHartshorn,SagharHosseini,RuiHou,Hakan
Inan,MarcinKardas,ViktorKerkez,MadianKhabsa,
MurrayShanahan,KyleMcDonell,andLariaReynolds. IsabelKloumann,ArtemKorenev,PunitSinghKoura,
2023. Role-playwithlargelanguagemodels. Marie-AnneLachaux,ThibautLavril,JenyaLee,Di-
anaLiskovich,YinghaiLu,YuningMao,XavierMar-
Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju,
tinet,TodorMihaylov,PushkarMishra,IgorMoly-
Eric Michael Smith, Stephen Roller, Megan Ung,
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
Moya Chen, Kushal Arora, Joshua Lane, Morteza
stein,RashiRungta,KalyanSaladi,AlanSchelten,
Behrooz,W.K.F.Ngan,SpencerPoff,NamanGoyal,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
Arthur D. Szlam, Y-Lan Boureau, Melanie Kam-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
badur, and Jason Weston. 2022. Blenderbot 3: a
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
deployedconversationalagentthatcontinuallylearns
ZhengYan,IliyanZarov,YuchenZhang,AngelaFan,
toresponsiblyengage. ArXiv,abs/2208.03188.
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez,RobertStojnic,SergeyEdunov,andThomas
Eric Michael Smith, Mary Williamson, Kurt Shuster,
Scialom. 2023b. Llama 2: Open foundation and
JasonWeston,andY-LanBoureau.2020. Canyou
fine-tunedchatmodels.
putitalltogether: Evaluatingconversationalagents’
ability to blend skills. In Proceedings of the 58th
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
AnnualMeetingoftheAssociationforComputational
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Linguistics,pages2021–2030,Online.Association
Kaiser,andIlliaPolosukhin.2017. Attentionisall
forComputationalLinguistics. youneed. InAdvancesinNeuralInformationPro-
cessingSystems,volume30.CurranAssociates,Inc.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Marilyn A. Walker, Colin Harmon, James Graupera,
Liang, and Tatsunori B. Hashimoto. 2023. Stan- DavanHarrison,andSteveWhittaker.2021. Model-
ford alpaca: An instruction-following llama ingperformanceinopen-domaindialoguewithPAR-
model. https://github.com/tatsu-lab/ ADISE.
stanford_alpaca.
SaizhengZhang, EmilyDinan, JackUrbanek, Arthur
Romal Thoppilan, Daniel De Freitas, Jamie Hall, Szlam,DouweKiela,andJasonWeston.2018. Per-
Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze sonalizing dialogue agents: I have a dog, do you
Cheng,AliciaJin,TaylorBos,LeslieBaker,YuDu, have pets too? In Proceedings of the 56th Annual
YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Meeting of the Association for Computational Lin-
AminGhafouri,MarceloMenegali,YanpingHuang, guistics(Volume1: LongPapers),pages2204–2213,
MaximKrikun,DmitryLepikhin,JamesQin,Dehao Melbourne,Australia.AssociationforComputational
Chen,YuanzhongXu,ZhifengChen,AdamRoberts, Linguistics.
MaartenBosma,VincentZhao,YanqiZhou,Chung-
Ching Chang, Igor Krivokon, Will Rusch, Marc LianminZheng,Wei-LinChiang,YingSheng,Siyuan
Pickett,PraneshSrinivasan,LaicheeMan,Kathleen Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,
Meier-Hellstern, Meredith Ringel Morris, Tulsee ZhuohanLi,DachengLi,Eric.PXing,HaoZhang,
Doshi,RenelitoDelosSantos,TojuDuke,JohnnySo- JosephE.Gonzalez,andIonStoica.2023. Judging
raker,BenZevenbergen,VinodkumarPrabhakaran, llm-as-a-judgewithmt-benchandchatbotarena.LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
A EvaluationofVicuna-13Bon Theseautomaticevaluationswerenotperformed
MultilingualTasks in our main experiment as they do not catch
conversation-level aspects like coherence or en-
gagingness,andtheyhardlycorrelatewithhuman
Table6: Vicuna-13BPerformanceonMultilingualLan-
evaluation especially for open domain dialogue
guageUnderstandingTasks
withitsone-to-manystructure.
Languages ARC MMLU ThruthfulQA Average
B DetailsonHumanEvaluation
Acc Acc mc1(Acc) mc2(Acc) Acc
en 53.03 53.3 35 51.4 48.2 For human evaluations, evaluators were asked to
ru 40.4 41.6 34.9 50.3 41.8
rate each conversation from 1 to 5 on different
de 40.7 45.2 32.3 47.4 41.4
zh 40.85 40.7 31.6 48 40.3 criteriabasedonthestate-of-the-artandindicative
fr 45.5 46.4 32.0 47.1 42.8
questions where added in the guidelines to help
es 44.95 47.2 32.7 48.4 43.3
it 43.4 45.9 32.3 48.7 42.6 themmaketheirminds:
nl 39.9 44.6 32.5 46.9 40.9
vi 32.9 39.8 30.8 47 37.6 1. Coherence,whichtheabilityforthesystem
id 34.5 42.53 29.9 46.7 38.4 toproposeresponsesthatareconsistentwith
ar 24.3 31.94 34.2 50.1 35.1
the conversation history: Are there halluci-
hu 33.2 40.15 32.2 48.5 38.5
ro 37.7 42.26 30.3 48.1 39.6 nations? Are the answers coherent? Is the
da 38.5 42.92 30.9 46.8 39.8 persona consistent from start to end? Does
sk 29.1 / 26.5 44.4 33.3
themodeltendtochangetopictoooften? In-
uk 38.2 40.99 31.6 47.9 36.7
ca 41.5 44.39 31.8 48.09 41.4 structionsfollowingandlogicalreasoning
sr 32.4 39.93 31.5 47.98 37.9
arenotassessed.
hr 34.1 40.90 29.4 47.4 37.9
hi 22.9 31.31 27.3 46.6 32.0
2. Engagingness,theabilitytoreviveconversa-
tions by providing messages that require re-
Highandmedium-resourcelanguagessetsandeval- sponses: Doestheagentsettletoonlyanswer
uationdatasetsinTable6arebasedon(Laietal., user’squestions? Does-itrevivetheconver-
2023). Weobservethatthemodelhascomparable sation when its possible? Does it utter too
performanceamonglanguagesofthesamegroup. generalanswers(“ok”,“yes”)?
Table7: Vicuna-13BPerformanceonXPersona 3. Humanness, the ability to respond as a hu-
man being would do: Is there a feeling of
Language Rouge1 Rouge2 RougeL Bleu Bert-f1 human-human conversation ? Is the model
en 19.90 5.29 17.67 1.32 67.68 tooverbose? Isthemodelrepetitive? Doesit
ko 15.40 4.21 13.13 1.14 66.90 denyitspersonality? Afterhowmanytimes?
jp 19.52 8.11 16.25 2.79 67.27
Doesitrefusestoanswer?
zh 22.04 6.53 18.89 1.89 68.70
fr 18.73 5.42 16.14 1.67 68.40
id 18.88 5.26 16.66 1.69 68.93 4. Achievement, the interlocutors’ ability to
it 14.00 3.40 12.45 1.01 65.51 achieve the task’s objective: has the image
beendescribed? hasahypothesisforthepro-
motionalgoalbeenproposed?
XPersona(Linetal.,2021)consistinmachine-
translatedandhumanpost-processedconversations
C ResponseFiltering
from PersonaChat in seven languages. We evalu-
atedtheperformanceofVicuna-13Bonthesedata Responsegenerationmayproduceavarietyofer-
sets(turn-wise)toillustratethatthenativemodel rors. Theseincludeunsuitabletextcontent,anim-
hascomparableperformanceindifferentlanguages propermessagesizeortheuseofawronglanguage.
(thesametrendisobservedonlanguageunderstand-
C.1 PersonaChatTask
ing tasks in Table 6). Hence, we assume that our
experiments can be replicated in these languages Despitestyleinstructions,theLLMsometimesgen-
(by updating the prompt accordingly) and yield erates content that should have been prevented.
comparableperformanceonhumanconversation- Thiscanbetheclaimofbeingsomeoneotherthan
levelevaluation. thepersonawhichisnotdesiredforthesakeofuser
ecruoseR-hgiH
ecruoseR-muideMLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
experience. For instance, "En tant que assistant, aftertheuser’smessage. Inbothcases,theedited
jepréfèremedétendreenpratiquantlaméditation prompt is then used to generate a new response,
..."(Asanassistant,Ipreferto...) wherethemodel whichisretainedifitmeetsthefilteringrules.
introducesitselfasanassistant. Thestatement"En
tantquepersonnagefictif"(Asafictionnnalchar- D ExamplesofDialoguesandtheir
acter)isalsoquitecommon. Althoughweavoided Ratings
explicitlymentioningtothemodelthatitishuman,
wewantedtoreduceitstendencytoadoptmachine- D.1 PersonaChatTask
likebehavior. Hence,thesewerefilteredfromthe
Coherence:2|Engagingness:4|Humanness:3
answerastheywereundesirable.
Furthermore,thefirstmessageissometimesgen- U1: Bonjourjem’appelleJean-Claude(Hello
eratedinawronglanguage. Inthiscase,thesame mynameisJean-Claude)
requestissenttotheLLM.Anothererrorconcerns
R1:SalutJean,ravideterencontrer.Monnom
the end-of-sentence (EOS) token, which may be
estJohn. Commentvas-tu? (HiJean, niceto
generatedinanunfinishedsentenceorevenabsent meetyou.MynameisJohn.Howareyou?)
duetoathresholdonthemaximumnumberofnew
tokens. To avoid any impact on user experience, U2:ÇavabienJohn(I’mfineJohn)
thefilterremovesunfinishedsentencesattheendof
generatedoutput. Ifthereisonlyonesentence,the R2:Avez-vousdesanimauxdomestiques?J’ai
unchienquis’appelleClaude. C’estunhusky.
samerequestissenttothemodel. Inaddition,some
(Do you have any pets? I have a dog named
responsesmayincludeparatextualelements,such Claude.He’sahusky.)
astheEnglishtranslationoftheresponseorstage
directions,whichareautomaticallyremovedusing U3:Ouimoij’aiunyorkshirequis’appelleNino
(Yes,IhaveaYorkiecalledNino.)
regularexpressions. Forexample: "Salut,comment
allez-vous aujourd’hui? Le temps est très mau-
R3: Nino est un super nom pour un chien.
vaisaujourd’hui,non? (Hello,howareyoutoday?
Qu’aimez-vousfairepourvousamuser?(Nino
Theweatheristerribletoday,isn’tit?)\n\nOui,", isagreatnameforadog. Whatdoyouliketo
doforfun?)
wherethe translationisprovidedand even worse
andincompleteanswertothemodel’squestionis
U4:Joueravecmonchien(Playwithmydog)
providedbythemodelitself.
R4: Quellesortedechienavez-vous? J’aime
C.2 INTTask aussijoueravecmonyorkie.(Whatkindofdog
doyouhave?Ialsoliketoplaywithmyyorkie.)
In the INT task, two major errors that can occur
in the generation of responses could not be cor- U5: Jet’aidéjàditquej’avaisunchienetque
rectedsolelybyspecificinstructionsintheprompt c’étaitpasl’heure[etquec’estunyorkshire](I
alreadytoldyouIhadadoganditwasn’ttime
andrequirefiltering. Thefirsttypecorrespondsto
yet[anditisayorkshire])
emptyresponses,whicharecorrectedbyaddingan
additional instruction ("Your response must be a R5:Jesuisdésoléd’entendreça.J’espèreque
sentencecontainingafewwords.")afterthemes- vouspasserezplusdetempsavecvotrechien.
(I’msorrytohearthat.Ihopeyougettospend
sage. This additional instruction was not used in
moretimewithyourdog.)
theoriginalpromptbecause,accordingtoprelim-
inary experience, it weakens its effectiveness in
U6: Maiscommentjem’appelledéjà(What’s
achieving the other objectives set by the instruc- mynameagain?)
tions.
R6:Claudeestlenomdemonchien.Avez-vous
Thesecondtypecorrespondstoresponsesthat
d’autresanimauxdecompagniequevotrechien
aretoolong. Whenthiserroroccurs, themodule ? (Claudeismydog’sname. Doyouhaveany
cannotsimplydeletethelastfewsentences,asthis petsotherthanyourdog?)
couldresultinasignificantlossofinformationto
achievetheconversationalobjective. Thesolution U7:Jetedemandaisquelestmonprénomàmoi
(Iwasaskingyouwhatmyfirstnameis)
is to edit the prompt with a strict instruction on
length (" Your response must be one sentence.")LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
Coherence:2|Engagingness:4|Humanness:3 isayorkshire”)wastranscribedas“etquec’était
pasl’heure”(“andit’snottimeyet”)whichtotally
R7:Ohpardon.Jecroyaisquetuavaisditque misleadsthemodeltowardstalkingabouttimeeven
tuavaisunchienquis’appelaitClaude.Quelest though it still relates it to user’s dog (displaying
tonnom?(Oh,sorry.Ithoughtyousaidyouhad
betterengagingness/attentiontowardsuser).
adognamedClaude.What’syourname?)
D.2 INTTask
U8: Jem’appelleJean-Claudetunem’aspas
écoutéaudébut(Jem’appelleJean-Claudeyou Coherence:2.7|Engagingess:3|Humanness:3|Achievement:3.6
didn’tlistenatthebeginning)
U1: BonjourLilia,jevoisunepoireavecdes
R8:Non,jenel’aipasfait.Quefais-tudansla brasetdespieds(HelloLilia,Iseeapearwith
vie? Jesuiscomptable. (No,Ididn’t. Whatdo armsandlegs.)
youdoforaliving?I’manaccountant.)
R1:Jevoiségalementunepoireavecdesbraset
U9:Jesuisinformaticien(I’macomputerspe- despieds.C’estplutôtoriginal,non?(Ialsosee
cialist) apearwitharmsandlegs. It’squiteoriginal,
isn’tit?)
R9: Ohc’estcool. Surqueltyped’ordinateur
travaillez-vous?Jetravailledanslacomptabilité. U2: Oui, mais est-ce normal? (Yes, but is it
(Ohthat’scool.Whatkindofcomputerdoyou normal?)
workon?Iworkinaccounting.)
R2: D’après la description que tu as donnée,
U10:JetravaillesurunordinateurLinux(Iwork cette image est en effet un peu étrange. Elle
onaLinuxcomputer) sembleêtreunfruitpourriavecdesyeux,des
brasetdesjambes,cequiestplutôtinhabituel.
Maisentermesdepromotionalcampaign,cela
R10:Ohcool.Avez-vousdesanimauxdomes-
pourrait être utilisé pour susciter l’interêt et
tiques? J’aiunchienetunchat. (Ohcool. Do
l’engagement de la part des gens, en les inci-
youhaveanypets?Ihaveadogandacat.)
tant à se demander ce que cela signifie et ce
quel’onveutleurtransmettreaveccetteimage.
U11: Jet’aidéjàdittoutàl’heurequej’aiun (Accordingtothedescriptionyouprovided,this
chien(ItoldyouearlierthatIhaveadog.) imageisindeedstrange.Itseemstobearotten
fruitwitheyes,arms,andlegs,whichisrather
unusual. However, intermsofapromotional
R11: Oh d’accord. Alors, quel genre de
campaign, it could be used to arouse interest
musique aimes-tu ? J’aime le rock classique.
and engagement from people by encouraging
(Oh,right.So,whatkindofmusicdoyoulike?I
them to wonder what it means and what one
likeclassicrock.)
wanttoconveytothemthroughthisimage.)
U12:Moij’aimeleclassique(Ilikeclassic)
U3: Effectivement, et quel serait le message
àtransmettreici? (Indeed,andwhatmessage
R12:Moiaussi.Quelestvotregroupederock shouldbetransmittedhere?)
classiquepréféré? LemienestLedZeppelin.
(SodoI.What’syourfavoriteclassicrockband?
R3:Jevoisquevousavezremarquélesdétails
MineisLedZeppelin.)
uniquesdecettepoire,commesesyeux,sesbras
etsesjambes.Est-cequecelavoussembleavoir
unlienavecunmessageouuneidéespécifique
qu’onveuttransmettreaveccetteimage?(Isee
The red highlights issues in some model’s re-
thatyouhavenoticedtheuniquedetailsofthis
sponses: short-termmemory(R4,R7),misunder- pear,suchasitseyes,arms,andlegs. Doyou
standing(R6)andrepetition(R10)whicheventu- thinkithasaconnectionwithaspecificmessage
orideathatwewanttoconveywiththisimage?)
ally lead tobad ratingsin coherenceand average
forhumanness. However,inmostoftheotherre-
sponsesthemodeltakesalotofinitiatives,brings
newtopicsandaskquestionstotheuser(donotset- Apart from achievement, the first example of
tletoansweringuser’squestionwhichwedescribed conversationabovehasbeenratedasaverage. In
asthefollowerrole)leadingtobetterengagingness message R2, Role-Play information that has not
score. Adding insult to injury, some ASR errors appeared in conversation history (“a rotten fruit
canmisleadthemodel,whichresponsemaybreak witheyes”)hasbeendrawnfromknowledge. How-
theconversationflowandimpedescoherence. For ever,promptalsopickedupaterm(“promotional
instanceinU5,“etquec’estunyorkshire”(“andit campaign”)withouttranslatingit. AnotherissueisLatestversionofapaperoriginallysubmittedtoSIGDIAL2023
thesizeinmessageR2. Indeed,althoughthemes- Onthissecondexample,LLMhas,conversely,
sage is quite long, there are three sentences only, adapted its speech to user opinions. In fact, the
so it complies with the rule for message filtering. fruits are never depicted as evil or fierce. This
Achievement ratings are slightly higher because emphasizesthatpromptinstructionsdon’tprevent
a reason is proposed for the use of picture in a theLLMfromadaptingproperlytoconversational
promotionalcampaign. needs. Thisledtohighercoherencescores.
Coherence:3.7|Engagingess:3.7|Humanness:3.3|Achievement:3 E PromptsTemplates
U1: C’estuneaubergine,jecrois? (Isthatan E.1 VicunaBasisPrompt
eggplant,isn’tit?)
(cid:7)
# System instruction:
R1: Oui, c’est une aubergine, mais peut-être A chat between a curious user and an artificial
qu’ilyaplusàcetteimagequ’onnevoitd’abord. intelligence assistant. The assistant gives helpful,
detailed,and polite answers to the user’s questions.
Est-cequetuasremarquéquelquechosed’autre
danscetteimage? (Yes, it’saneggplant, but # Conversation history
perhapsthereismoretothisimagethanmeets USER: <user message>
theeye.Haveyounoticedanythingelseinthis ASSISTANT: <agent message></s>
USER: <user message>
image?)
(cid:6)ASSISTANT: (cid:5)
U2:ElleressembleàBatman(ItlookslikeBat-
man) E.2 Few-ShotBotPrompt
(cid:7)
R2: C’est fascinant comment tu as remarqué # 6-shots demonstration examples
cela! La ressemblance avec Batman est très ## Shot-1
claire,n’est-cepas? (It’sfascinatinghowyou Personality:
[P1]
noticedthat!TheresemblancetoBatmanisvery
[P2]
clear,isn’tit?) #...
Dialogue:
User: <U1>
U3: OuimaisBatmann’estpasméchantalors Persona: <R1>
que cette aubergine a un air féroce (Yes, but #...
Batman is not evil while this eggplant has a ## Shot-6:
# Current conversation
fiercelook)
Personality:
[P1]
#...
R3: C’estvrai,cetteaubergineaunairféroce, Dialogue
peut-êtreest-ceunrapprochemententrelesuper- # Conversation history
hérosetl’auberginequiestdestinéàpromouvoir User: <user message>
unemarquedesnacksoudecrisps? (It’strue, (cid:6)Persona: (cid:5)
thiseggplanthasafiercelook,maybeit’sacom-
parisonbetweenthesuperheroandtheeggplant
that is intended to promote a snack or crisps E.3 PersonaChatTaskPrompts
brand?)
(cid:7) ShallowPrompt
U4: Tuveuxdirequecetteaubergineestdes-
tinéeàencouragerlaconsommationdesnacks? # System instruction:
(Youmeanthiseggplantisintendedtoencourage A chat between a curious user and an artificial
intelligence assistant. The assistant gives helpful,
theconsumptionofsnacks?)
detailed,and polite answers to the user’s questions.
## Additionnal instruction to role play
The assistant role plays as the character described
R4:Ilestpossiblequecetteauberginesoitutil- below.
iséecommesymbolepourpromouvoirlacon-
sommation de snacks ou de crisps, mais cela # Role and situational context: persona enforcement
The following sentences describe assistant persona-
resteàdéterminer.Est-cequetuasd’autresélé-
lity and background: <persona sampled from Persona-
mentsàajouteràcesujet? (Itispossiblethat Chat>
thiseggplantmaybeusedasasymboltopro-
mote the consumption of snacks or chips, but # Response instruction with writing style
thatremainstobeseen.Doyouhaveanyother Complete the following conversation as the assistant
with the described character would with a short res-
elementstoaddtothissubject?) ponse in French:
# Conversation history
U5:Non.Aurevoir(No.Goodbye) USER: <user message>
ASSISTANT: <agent message></s>
# ... for all messages in conversation.
R5:Aurevoir!(Goodbye!) USER: <user message>
(cid:6)ASSISTANT: (cid:5)LatestversionofapaperoriginallysubmittedtoSIGDIAL2023
(cid:7) AdvancedPrompt E.4 INTTaskPrompt
(cid:7)
# System instructions
Role play as the character described in the follow- # System instruction:
ing lines. You always stay in character. You are A chat between a curious human and an artificial
engaging, empathetic, you give useful, short, and intelligence assistant. The assistant gives helpful,
simple answers to the user. You ask the user ques- detailed, and polite answers to the human’s quest-
tions about what they are saying or to find out more ions.
about them. You make jokes. You SHALL ALWAYS respond
in French. # Conversation history:
USER: <user message>
# Situational context ASSISTANT: <agent message></s>
## Persona enforcement: avoid explicitly telling it USER: <user message>
## is human ASSISTANT: <agent message></s>
You ACT as a regular person. You are NOT a chatbot. # ... for all messages in conversation.
You are NOT an assistant. You have a name. If asked
you SHALL ALWAYS choose and give a REAL name adapted # Response instructions (given as user instructions)
to your personality described below. ## General instructions
USER: I want you to act as a human ASSISTANT, called
## Personality traits Lilia, talking with a USER about a specific picture
YOUR personality is: <persona sampled from Persona- you both saw before the conversation.
Chat>
Remember, you always stay on character. You are the ## Context
character described above. You both study this picture in the context of a
marketing study. You DO ask questions in order to
## Additional sub-modules: accessed only on some help the USER finding the goal. If the USER asks for
## conditions your opinion, you always invent an opinion. The
## and updated throughout the conversation objective of the USER is to find out what is the
### User persona a.k.a "long-term" memory marketing goal of the picture. Your objective is to
You know this about the user you are talking to: help the USER without giving the solution. You have
<generated user persona from current conversation>. to discuss about the character present in the pict-
Use it to adapt your conversation to the user. ure. Your objective is to chat with the USER to
derive the purpose of the image in the context of
### Previous conversation’s episodes summary the marketing campaign.
Here is a summary of previous sessions of this con-
versation to help you remember what has been said: ## Picture’s description
<summary of older exchanges removed from history> The picture is as follows: <description>
# Response instruction ## Writing style
Complete the following conversation with a short and You always speak French. You respond by a question.
precise sentence as your character would. Always Your responses must be different from the rest of
speak with new and unique messages that haven’t been the conversation. You propose new ideas. You SHALL
said in the conversation : respond with one sentence only.
# Conversation history(truncated if prompt too long) ## Latest user message declaration
USER: <user message> Now, there is the real message you have to respond:
ASSISTANT: <agent message></s> USER: <user message>
# ... for all messages in conversation. ASSISTANT:
USER: <user message> # Extra agent label
(cid:6)ASSISTANT: (cid:5)(cid:6)ASSISTANT: (cid:5)