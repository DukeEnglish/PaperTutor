[
    {
        "title": "Differential error feedback for communication-efficient decentralized learning",
        "authors": "Roula NassifStefan VlaskiMarco CarpentieroVincenzo MattaAli H. Sayed",
        "links": "http://arxiv.org/abs/2406.18418v1",
        "entry_id": "http://arxiv.org/abs/2406.18418v1",
        "pdf_url": "http://arxiv.org/pdf/2406.18418v1",
        "summary": "Communication-constrained algorithms for decentralized learning and\noptimization rely on local updates coupled with the exchange of compressed\nsignals. In this context, differential quantization is an effective technique\nto mitigate the negative impact of compression by leveraging correlations\nbetween successive iterates. In addition, the use of error feedback, which\nconsists of incorporating the compression error into subsequent steps, is a\npowerful mechanism to compensate for the bias caused by the compression. Under\nerror feedback, performance guarantees in the literature have so far focused on\nalgorithms employing a fusion center or a special class of contractive\ncompressors that cannot be implemented with a finite number of bits. In this\nwork, we propose a new decentralized communication-efficient learning approach\nthat blends differential quantization with error feedback. The approach is\nspecifically tailored for decentralized learning problems where agents have\nindividual risk functions to minimize subject to subspace constraints that\nrequire the minimizers across the network to lie in low-dimensional subspaces.\nThis constrained formulation includes consensus or single-task optimization as\nspecial cases, and allows for more general task relatedness models such as\nmultitask smoothness and coupled optimization. We show that, under some general\nconditions on the compression noise, and for sufficiently small step-sizes\n$\\mu$, the resulting communication-efficient strategy is stable both in terms\nof mean-square error and average bit rate: by reducing $\\mu$, it is possible to\nkeep the estimation errors small (on the order of $\\mu$) without increasing\nindefinitely the bit rate as $\\mu\\rightarrow 0$. The results establish that, in\nthe small step-size regime and with a finite number of bits, it is possible to\nattain the performance achievable in the absence of compression.",
        "updated": "2024-06-26 15:11:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.18418v1"
    },
    {
        "title": "Building multiscale models with PhysiBoSS, an agent-based modeling tool",
        "authors": "Marco RusconeAndrea CheccoliRandy HeilandEmmanuel BarillotPaul MacklinLaurence CalzoneVincent Noël",
        "links": "http://arxiv.org/abs/2406.18371v1",
        "entry_id": "http://arxiv.org/abs/2406.18371v1",
        "pdf_url": "http://arxiv.org/pdf/2406.18371v1",
        "summary": "Multiscale models provide a unique tool for studying complex processes that\nstudy events occurring at different scales across space and time. In the\ncontext of biological systems, such models can simulate mechanisms happening at\nthe intracellular level such as signaling, and at the extracellular level where\ncells communicate and coordinate with other cells. They aim to understand the\nimpact of genetic or environmental deregulation observed in complex diseases,\ndescribe the interplay between a pathological tissue and the immune system, and\nsuggest strategies to revert the diseased phenotypes. The construction of these\nmultiscale models remains a very complex task, including the choice of the\ncomponents to consider, the level of details of the processes to simulate, or\nthe fitting of the parameters to the data. One additional difficulty is the\nexpert knowledge needed to program these models in languages such as C++ or\nPython, which may discourage the participation of non-experts. Simplifying this\nprocess through structured description formalisms -- coupled with a graphical\ninterface -- is crucial in making modeling more accessible to the broader\nscientific community, as well as streamlining the process for advanced users.\nThis article introduces three examples of multiscale models which rely on the\nframework PhysiBoSS, an add-on of PhysiCell that includes intracellular\ndescriptions as continuous time Boolean models to the agent-based approach. The\narticle demonstrates how to easily construct such models, relying on PhysiCell\nStudio, the PhysiCell Graphical User Interface. A step-by-step tutorial is\nprovided as a Supplementary Material and all models are provided at:\nhttps://physiboss.github.io/tutorial/.",
        "updated": "2024-06-26 14:14:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.18371v1"
    },
    {
        "title": "Emergence of social hierarchies in a society with two competitive classes",
        "authors": "Marc SadurníJosep PerellóMiquel Montero",
        "links": "http://arxiv.org/abs/2406.18168v1",
        "entry_id": "http://arxiv.org/abs/2406.18168v1",
        "pdf_url": "http://arxiv.org/pdf/2406.18168v1",
        "summary": "Agent-based models describing social interactions among individuals can help\nto better understand emerging macroscopic patterns in societies. One of the\ntopics which is worth tackling is the formation of different kinds of\nhierarchies that emerge in social spaces such as cities. Here we propose a\nBonabeau-like model by adding a second class of agents. The fundamental\nparticularity of our model is that only a pairwise interaction between agents\nof the opposite class is allowed. Agent fitness can thus only change by\ncompetition among the two classes, while the total fitness in the society\nremains constant. The main result is that for a broad range of values of the\nmodel parameters, the fitness of the agents of each class show a decay in time\nexcept for one or very few agents which capture almost all the fitness in the\nsociety. Numerical simulations also reveal a singular shift from egalitarian to\nhierarchical society for each class. This behaviour depends on the control\nparameter $\\eta$, playing the role of the inverse of the temperature of the\nsystem. Results are invariant with regard to the system size, contingent solely\non the quantity of agents within each class. Finally, a couple of scaling laws\nare provided thus showing a data collapse from different model parameters and\nthey follow a shape which can be related to the presence of a phase transition\nin the model.",
        "updated": "2024-06-26 08:33:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.18168v1"
    },
    {
        "title": "Intrinsic Action Tendency Consistency for Cooperative Multi-Agent Reinforcement Learning",
        "authors": "Junkai ZhangYifan ZhangXi Sheryl ZhangYifan ZangJian Cheng",
        "links": "http://arxiv.org/abs/2406.18152v1",
        "entry_id": "http://arxiv.org/abs/2406.18152v1",
        "pdf_url": "http://arxiv.org/pdf/2406.18152v1",
        "summary": "Efficient collaboration in the centralized training with decentralized\nexecution (CTDE) paradigm remains a challenge in cooperative multi-agent\nsystems. We identify divergent action tendencies among agents as a significant\nobstacle to CTDE's training efficiency, requiring a large number of training\nsamples to achieve a unified consensus on agents' policies. This divergence\nstems from the lack of adequate team consensus-related guidance signals during\ncredit assignments in CTDE. To address this, we propose Intrinsic Action\nTendency Consistency, a novel approach for cooperative multi-agent\nreinforcement learning. It integrates intrinsic rewards, obtained through an\naction model, into a reward-additive CTDE (RA-CTDE) framework. We formulate an\naction model that enables surrounding agents to predict the central agent's\naction tendency. Leveraging these predictions, we compute a cooperative\nintrinsic reward that encourages agents to match their actions with their\nneighbors' predictions. We establish the equivalence between RA-CTDE and CTDE\nthrough theoretical analyses, demonstrating that CTDE's training process can be\nachieved using agents' individual targets. Building on this insight, we\nintroduce a novel method to combine intrinsic rewards and CTDE. Extensive\nexperiments on challenging tasks in SMAC and GRF benchmarks showcase the\nimproved performance of our method.",
        "updated": "2024-06-26 08:06:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.18152v1"
    },
    {
        "title": "The Overcooked Generalisation Challenge",
        "authors": "Constantin RuhdorferMatteo BortolettoAnna PenzkoferAndreas Bulling",
        "links": "http://arxiv.org/abs/2406.17949v1",
        "entry_id": "http://arxiv.org/abs/2406.17949v1",
        "pdf_url": "http://arxiv.org/pdf/2406.17949v1",
        "summary": "We introduce the Overcooked Generalisation Challenge (OGC) - the first\nbenchmark to study agents' zero-shot cooperation abilities when faced with\nnovel partners and levels in the Overcooked-AI environment. This perspective\nstarkly contrasts a large body of previous work that has trained and evaluated\ncooperating agents only on the same level, failing to capture generalisation\nabilities required for real-world human-AI cooperation. Our challenge\ninterfaces with state-of-the-art dual curriculum design (DCD) methods to\ngenerate auto-curricula for training general agents in Overcooked. It is the\nfirst cooperative multi-agent environment specially designed for DCD methods\nand, consequently, the first benchmarked with state-of-the-art methods. It is\nfully GPU-accelerated, built on the DCD benchmark suite minimax, and freely\navailable under an open-source license:\nhttps://git.hcics.simtech.uni-stuttgart.de/public-projects/OGC. We show that\ncurrent DCD algorithms struggle to produce useful policies in this novel\nchallenge, even if combined with recent network architectures that were\ndesigned for scalability and generalisability. The OGC pushes the boundaries of\nreal-world human-AI cooperation by enabling the research community to study the\nimpact of generalisation on cooperating agents.",
        "updated": "2024-06-25 21:51:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2406.17949v1"
    }
]