SUBMITTEDTOREVIEWANDPOSSIBLEPUBLICATION.COPYRIGHTWILLBETRANSFERREDWITHOUTNOTICE.
Personaluseofthismaterialispermitted.Permissionmustbeobtainedforallotheruses,inanycurrentorfuturemedia,including
reprinting/republishingthismaterialforadvertisingorpromotionalpurposes,creatingnewcollectiveworks,forresaleorredistributiontoservers
orlists,orreuseofanycopyrightedcomponentofthisworkinotherworks.
Pioneering SE(2)-Equivariant Trajectory Planning
for Automated Driving
Steffen Hagedorn1, Marcel Milich2, and Alexandru P. Condurache1
Abstract—Planning the trajectory of the controlled ego
vehicle is a key challenge in automated driving. As for human
drivers, predicting the motions of surrounding vehicles is
important to plan the own actions. Recent motion prediction
methods utilize equivariant neural networks to exploit geo-
metric symmetries in the scene. However, no existing method
combines motion prediction and trajectory planning in a joint
SE(2)
stepwhileguaranteeingequivarianceunderroto-translationsof Transformation
theinputspace.Weaddressthisgapbyproposingalightweight
equivariant planning model that generates multi-modal joint Fig.1:Exemplarytrafficscenethatdemonstratestheintuition
predictionsforallvehiclesandselectsonemodeastheegoplan.
behind SE(2)-equivariant trajectory prediction and planning:
The equivariant network design improves sample efficiency,
Roto-translations of the input scene should result in an
guarantees output stability, and reduces model parameters.
We further propose equivariant route attraction to guide the equivalent transformation of the trajectory output.
ego vehicle along a high-level route provided by an off-the-
shelfGPSnavigationsystem.Thismodulecreatesamomentum When given a fixed-size dataset, inducing prior knowledge
from embedded vehicle positions toward the route in latent bymeansofequivariancecanincreasetheperformance[12].
spacewhilekeepingtheequivarianceproperty.Routeattraction
Whilemethodsforjointpredictionandplanninghavebeen
enables goal-oriented behavior without forcing the vehicle to
stick to the exact route. We conduct experiments on the presentedandtheadvantagesofequivariancehavebeenused
challengingnuScenesdatasettoinvestigatethecapabilityofour instand-alonemotionprediction,noexistingplanningmodel
planner. The results show that the planned trajectory is stable combines both techniques.
under roto-translations of the input scene which demonstrates
Instead, many methods transform the whole scene into a
the equivariance of our model. Despite using only a small split
coordinate system centered around one vehicle, typically the
of the dataset for training, our method improves L2 distance
at 3s by 20.6% and surpasses the state of the art. ego vehicle [13]–[15]. However, this approach has proven
sample-inefficient and vulnerable to domain shifts as the
I. INTRODUCTION scene representation is viewpoint-dependent [7], [16]. Other
works alleviate this problem by taking the perspective of
In automated driving, trajectory planning is the task of
each vehicle [17]–[19]. Such methods are more robust but
finding a safe and efficient path and speed profile of a
computationallyexpensive[20]whichalsoisaknowndown-
controlled ego vehicle (EV) toward a goal position [1]. In
sideofuniversallyapplicableequivariantapproachesthatare
additiontopastpositions,map,androuteinformation,many
based on irreducible representations of the transformation
planning methods rely on motion prediction of surrounding
group [21], [22]. In contrast, EqMotion reduces the compu-
vehicles (SVs) to model interactions [1]–[4]. Combining
tation by explicitly designed equivariant operations that do
prediction and planning by handling all vehicles jointly is
not rely on irreducible representations [9]. EqDrive applies
a promising approach to reduce computation and overcome
EqMotionforvehiclemotionpredictionintrafficscenes[23].
purely reactive behavior [2], [5], [6]. To increase sample
Their results demonstrate that equivariant neural networks
efficiency and robustness, the predicted trajectories of all
can improve the performance in automated driving tasks.
vehicles must be independent of the viewpoint from which
the scene is observed (cf. Fig. 1) [7]. Equivariant models Since the benefits of joining prediction and planning as
fulfill this requirement and are therefore utilized in many well as the advantages of equivariant models are shown in
tasksthatsolveproblemsinobservablephysicalsystems[8]– recent methods, we want to pioneer the field of combining
[10]. Equivariance means that transformations of the input both aspects. Therefore we propose PEP (Pioneering Equiv-
transform the output in an equivalent way. Designing equiv- ariant Planning): A lightweight equivariant planning method
ariant neural networks (NNs) is beneficial in multiple ways. that integrates prediction and planning in a joint approach.
Beside guaranteeing output stability they have an increased SimilartoEqMotion[9],PEPisagraphneuralnetwork[24]
sample efficiency and can reduce model parameters [11]. that consists of an equivariant feature learning branch that
processes vehicle positions and an invariant branch that
1Robert Bosch GmbH, 71229 Leonberg, Germany and Institute for processes invariant features such as the distance between
Signal Processing, Universita¨t zu Lu¨beck, 23562 Lu¨beck, Germany. two positions. We extend the architecture by adding another
steffen.hagedorn@de.bosch.com, 2Bosch Center for Artificial Intel-
equivariantbranchthatupdatestheEVpositionbyproviding
ligence, 71272 Renningen, Germany and Institute for Parallel Distributed
Systems,Universita¨tStuttgart,70569Stuttgart,Germany routeinformation.ThisallowsthejointprocessingofEVand
4202
raM
71
]OR.sc[
1v40311.3042:viXraSVs while conditioning the EV prediction on a goal. We B. Equivariant Motion Prediction
further add a mode selection layer that selects the EV plan
Equivariant convolutional neural networks add rotation
from K predicted modes. The network is trained with a loss
equivariance to the inherent translation equivariance of the
that jointly optimizes planning and prediction, and promotes
convolution operation [31]. Rotation equivariance in the
diverse multi-modal predictions.
2D image domain is achieved by oriented convolutional
We evaluate PEP on the prediction split of nuScenes [25].
filters [32], log-polar coordinates [33], circular harmon-
Alongside the open-loop evaluation, we present a compre-
ics [34] or steerable filters [12], [35]. With the advent
hensive ablation study and equivariance analysis.
of Graph Neural Networks (GNNs) [24] which work on
In summary, our contributions are:
sparse data representations, equivariant adaptions of this
• We present the first equivariant planner integrated with architecture emerged. To extract roto-translation-equivariant
multi-modal joint prediction. featuresfrompointcloudsorgraphs,someapproachesutilize
• We propose an equivariant route attraction mechanism irreducible representations of the transformation group such
that allows following a high-level route. as spherical harmonics [36], [37]. Others base their method
• We report state-of-the-art performance on the nuScenes on specifically designed and computationally less expensive
dataset in open-loop planning. layers[38]–[40].Forexample,[39]embedtherepresentation
II. RELATEDWORK of neurons into a 3D space where they leverage basic
principles of matrix algebra to induce equivariance.
A. Joint Prediction and Planning
Equivariant GNNs are a common choice for solving tasks
EarlyplanningmodelsforautomateddrivingplantheEV’s
in physical systems since these often possess rotational and
trajectory directly from perception inputs without explicitly
translational symmetries [41], [42]. Since motion prediction
considering the interplay with SVs [6]. Alternatively, many
models a physical system, equivariant NNs are well-suited
solutions sequentially employ separate subsystems for pre-
for this task. [43] first apply learning-based equivariant mo-
diction and planning [3], [26]–[28]. While increasing ex-
tion prediction to predict fluid flow. SE(3)-equivariant trans-
plainability,suchmethodsstillhandleEVandSVsseparately
formersmarkanothermilestonebyregressingpedestriantra-
and lead to reactive behavior [6]. By modeling the future
jectories [37]. The first equivariant motion prediction model
of all vehicles simultaneously, joint prediction and planning
for autonomous driving utilizes polar coordinate-indexed
goes beyond reactive behavior and can reduce computa-
filterstodesignanequivariantcontinuousconvolutionopera-
tion [2], [5]. Joint prediction and planning approaches can
tor [10]. Recently, the motion prediction network EqMotion
be categorized into iterative methods and regression.
presents strong performance on various tasks [9]. Similar
The iterative probabilistic method PRECOG predicts the
to [39], its specifically designed layers exploit geometrical
state of all vehicles one step into the future and uses the
symmetries. In addition to the equivariant feature learning
outcome as input for the next iteration [2]. Goal information
they present an invariant interaction reasoning module and
is provided for the EV and leads to more precise predictions
an invariant pattern feature. This design allows to integrate
forallvehicles.TheEV’splanistheninferredbyoptimizing
prior knowledge efficiently. Features like absolute distances
the expectation of the predicted distribution. GameFormer
which are inherently SE(3)-invariant can be processed in the
is another iterative approach based on game theory [5].
invariant layers while absolute positions are handled by the
Interactions are modeled as a level-k game in which the
SE(3)-equivariant layers. EqDrive finally applies EqMotion
individual predictions are updated based on the predicted
forvehicletrajectoryprediction[9].Inthiswork,wepropose
behaviorofallvehiclesfromthepreviouslevel.Theencoder-
an equivariant model based on EqMotion that extends the
decodertransformerarchitecturepredictsmultiplemodesfor
motion prediction to a trajectory planner for the EV and
SVs while restricting EV prediction to a single mode that
integrates prior knowledge of its intended route.
serves as the plan.
In contrast, regressive methods learn a joint feature for the III. METHOD
whole prediction horizon from which complete trajectories In this section, we introduce our equivariant trajectory
are regressed. SafePathNet employs a transformer for multi- plannerPEP,whichisanexpansionofEqMotion.Foramore
modal joint prediction of EV and SVs [29]. Every predicted detailed overview of EqMotion, we refer the reader to [9].
EV mode is then checked for collisions with the most Fig. 2 provides an overview of our model.
probable mode of each SV. The EV mode with the lowest
A. Problem Formulation
predicted collision rate is selected as the plan. Similarly,
DIPP starts with a multi-modal joint prediction and selects PEP is an equivariant trajectory planner based on multi-
the mode with the highest probability for each vehicle [30]. modaljointpredictionofallvehiclesandtrainedbyimitation
To infer the EV plan, a differentiable nonlinear optimizer learning.GiventhepasttrajectoriesX
=[x1,x2,...,xTp]∈
i i i i
refines the EV prediction under consideration of the SV RTp×2 of i=1,...,M vehicles, including the EV, and EV
predictions and additional hand-crafted constraints. routeinformationL∈RC×2,theplanningtaskistoforecast
We also base our planner on multi-modal joint prediction Yˆ
EV
= [yˆ E1 V,yˆ E2 V,...,yˆ ETf V] ∈ RTf×2 as close to the real
for all vehicles but further design the whole network to be future trajectory Y as possible. We further denote the set
EV
equivariant under 2D roto-translations of the input. of all past trajectories as X=[X ,...,X ].
1 MEquivariant
Route Attraction
High-Level Route
Equivariant Equivariant Ego Trajectory
Feature Learning Trajectory Decoder Selector
Feature Modes Planned Ego
Initialization Invariant Multimodal Trajectory Trajectory
Feature Learning
Predictions
Past Trajectories Feature Update Block
Fig. 2: PEP model overview. After feature initialization, the features are updated N times in three parallel but interacting
branches. A multi-modal decoder then predicts multiple future scenarios for all vehicles jointly. Alongside the trajectories,
a probability for each scenario is estimated. The EV trajectory of the most probable mode is selected as the plan.
Especially, we require the planning function F (X,L) = prioritizes social interactions over route following, which is
plan
Yˆ to be equivariant under transformations T in the Eu- important for collision avoidance. Since the goal is only
EV g
clidean group SE(2), which comprises rotations R∈SO(2) known for the EV (i=0), we update only this feature:
and translations t∈R2. All feature updates f in F plan must f :G(l) ←G(l)+ϕ(l)(L−G(l))∈RC×2. (3)
satisfy the equivariance condition f(xT ) = f(x)T where ra 0 0 ra 0
g g
the roto-translation right group action T acts on 2D inputs The FCL ϕ takes vector L−G(l) as input, which points
g ra 0
x via matrix-multiplication and addition xT =xR+t. fromtheequivariantEVfeatureembeddingtowardtheroute.
g
Superscript (l) denotes the l-th of N feature update blocks.
B. Feature Initialization
We show that the route attraction module f fulfills the
ra
The key idea of handling a set of positions translation- equivariance condition stated in the problem formulation:
equivariantly is to shift the viewpoint into the center, i.e. the
meancoordinateX¯.Toreturntotheinitialcoordinatesystem f ra(xR+t)=G( 0l)R+t+ϕ ra(LR+t−(G( 0l)R+t))
afteratransformation,X¯ isre-added.LikeEqMotion[9],we =G(l)R+t+ϕ ((L−G(l))R)
0 ra 0
initialize the equivariant feature of vehicle i as =G(l)R+t+ϕ (L−G(l))R (4)
0 ra 0
G( i0) =ϕ initg(X i−X¯)+X¯ ∈RC×2 (1) =(G( 0l)+ϕ ra(L−G( 0l)))R+t
where function ϕ initg is realized by a fully connected layer =f ra(x)R+t □
(FCL) [9]. In the following, all ϕ describe FCLs. Since an 2) EquivariantFeatureLearning: Thisfeatureupdatestep
FCL is a linear transformation and can be expressed as comprisesinneraggregationandneighboraggregation.Inner
a matrix multiplication, rotation-equivariance follows from aggregationupdatestheequivariantfeatureofvehicleiusing
the multiplicative associative law. We initialize the invariant a weight computed from its invariant feature. G¯(l) is the
feature of vehicle i as a function of velocity ∆X i and mean position of equivariant features G(l) [9]:
i
heading angle, which are both inferred from positions X as
i
in EqMotion [9]. The [·;·] operator denotes concatenation. G( il) ←ϕ( atl t)(h( il))·(G( il)−G¯(l))+G¯(l) ∈RC×2 (5)
h(0) =ϕ ([||∆X || ;angle(∆Xτ,∆Xτ−1)])∈RD (2) Neighbor aggregation first defines an edge weight for each
i inith i 2 i i neighbor based on relationship feature c , equivariant, and
ij
EqMotion further adds an invariant relationship learning, invariantfeatures.Thei-thequivariantfeatureisthenupdated
which computes c ∈ [0,1]Q between agents i and j from by a weighted sum over all its neighbors N [9].
ij i
the initial equivariant and invariant feature [9]. c describes
ij K
the relationship of i and j in Q categories. For instance, the e(l) =(cid:88) c ϕ(l)([h(l);h(l);||G(l)−G(l)|| ])∈RC (6)
ij ij,k e,k i j i j 2
network could learn to extract distance, velocity differences
k=1
or heading differences of i and j. G(l) ←G(l)+ (cid:88) e(l)·(G(l)−G(l))∈RC×2 (7)
i i ij i j
C. Feature Update j∈Ni
1) EquivariantRouteAttraction: Manyautomateddriving Finally, we apply the equivariant non-linear function pro-
systems comprise a tactical planner or navigation system to posed in [9] to infer G(l+1).
i
provide a coarse intended route at lane level. We introduce 3) InvariantFeatureLearning: Thelaststepofthefeature
a novel module called ’equivariant route attraction’ to incor- update in EqMotion [9] is invariant feature learning:
porate the intended EV route into the joint prediction. The p(l) = (cid:88) ϕ(l)([h(l);h(l);||G(l)−G(l)|| ])∈RD (8)
intuitionistomovetheequivariantfeatureoftheEVtoward i m i j i j 2
the high-level route L in latent space before considering
j∈Ni
interactionswithothervehicles.Thisorderoffeatureupdates h(l+1) =ϕ(l)([h(l);p(l)])∈RD (9)
i h i iTABLE I: Planning results on nuScenes
D. Trajectory Decoding
Toachievemulti-modalpredictions,weintroduceK paral-
L2(m) CR(%)
Model Per GC Vel Acc Traj
lelFCLtrajectorydecoders.Eachdecoderpredictsallagents 3s Avg. 3s Avg.
NMP[45] ✓ - - - - 2.31 - 1.92 -
simulateneously based on their equivariant features: SA-NMP[45] ✓ - - - - 2.05 - 1.59 -
FF[46] ✓ - - - - 2.54 1.43 1.07 0.43
Yˆk =ϕk (GN −G¯N)+G¯N ∈R(Tf+1)×2 (10) EO[47] ✓ - - - - 2.78 1.60 0.88 0.33
i dec i ST-P3[48] ✓ ✓ - - - 2.90 2.11 1.27 0.71
UniAD[4] ✓ ✓ - - - 1.65 1.03 0.71 0.31
Note that we predict an additional output beyond prediction DeepEM[49] ✓ ✓ - - - 0.73 0.48 0.36 0.19
horizon T . It serves as a probability indicator for the FusionAD[50] ✓ ✓ ✓ ✓ ✓ - 0.81 0.27 0.12
f VAD-Tiny[51] ✓ ✓ ✓ ✓ ✓ 0.65 0.41 0.27 0.16
trajectory selector, which outputs the final EV plan. VAD-Base[51] ✓ ✓ ✓ ✓ ✓ 0.60 0.37 0.24 0.14
BEV-Planner++[52] ✓ ✓ ✓ ✓ ✓ 0.57 0.35 0.73 0.34
E. Trajectory Selection AD-MLP-I[15] - - - - ✓ 1.48 0.97 0.83 0.49
AD-MLP-II[15] - - ✓ ✓ ✓ 0.49 0.35 0.28 0.23
We define mode probability as the mean of the spatial AD-MLP-IV[15] - ✓ ✓ ✓ ✓ 0.41 0.29 0.24 0.19
PEP(Ours) - ✓ - - ✓ 0.32 0.28 0.43 0.37
coordinate dimension C of the additionally predicted point.
Pk =mean (Yˆk,Tf+1 )∈RK (11) D. Planning
i C i
Planning performance is evaluated in open loop. Table I
Selecting the most probable mode yields the EV plan:
provides a broad comparison with other methods. Except
Yˆ EV =Yˆk 0∗ where k∗ = argmaxPk 0 (12) for our model, results are taken from [15], [49], [50], [52].
k=1,...,K To facilitate an overview, the methods are categorized based
To promote mode diversity we apply a winner-takes-all on model design criteria. ’Per’ indicates that a method uses
(WTA) loss as described below. additionalinformationfromperception,’GC’standsforgoal
F. Training Objective conditioning of the EV, and ’Vel’, ’Acc’, and ’Traj’ encode
whether ground truth velocity, acceleration, and trajectory
In accordance with the problem statement, we focus on
are provided, respectively. L2 distance between the planned
the planning performance in the loss function. Additionally,
trajectory and ground truth trajectory is used as the main
prediction performance for SVs is optimized in order to
metric. Additionally, the Collision Rate (CR) is evaluated.
benefit from realistic interaction modeling:
PEP achieves the lowest L2 distance at the last planned
L=L plan+L wta+α·L pred. (13) position, 3s into the future as well as averaged along the
trajectory. Regarding the CR, PEP performs slightly worse
Here, L is the average L2 distance between the planned
plan
than methods, which additionally use ground truth velocity
EV trajectory and ground truth. L considers mode selec-
wta
and acceleration as input. However, the performance is
tionbyassigningalossof0iftheclosestmodetotheground
similar to other methods that, like PEP, do not do so.
truth is selected correctly and else 1. L is the minimal
pred
Theresultssuggestthatrouteattractionbecomesincreasingly
average L2 error for SVs, weighted with α=0.1.
beneficialthelongertheplanninghorizongets.Comparedto
IV. RESULTS&DISCUSSION
SOTA, the L2(3s) is reduced by 28.1% while the L2(Avg.)
A. Implementation decreases by 3.6%. We assume that the L2(Avg.) and CR
All results are gathered with the same architecture using could be further reduced by incorporating map information
N = 4 feature update blocks with Q = 4 relationship underconsiderationofroto-translationequivariance.Mapin-
categories, a coordinate dimension of C = D = 64, and formationshouldleadtomoreaccurateinteractionmodeling,
K = 6 trajectory decoders. Past and future trajectories are which increases prediction and, thus, planning performance.
encodedasT =4andT =6positions,whichcorresponds Including a map will therefore be the next step to further
p f
tot =1.5sandt =3sintheselecteddataset,respectively. improve our lightweight map-less approach. The qualitative
p f
resultsinFig.3showcasehowPEPbenefitsfromprediction,
B. Dataset
route, and multi-modality.
Since PEP performs joint prediction and planning, we use
E. Prediction
only multi-vehicle scenes in the official nuScenes prediction
split, i.e. 471 training and 136 test scenes [25]. These are Even though prediction is not the primary task of PEP,
only607of1000totalscenes.Routeattractionusesthehigh- it leverages joint prediction for realistic interaction model-
level route the driver was supposed to follow during data ing when planning the EV trajectory. During our planning
acquisition, which is provided in the CAN-Bus expansion. experiments, we measured an SV prediction performance
with a minL2(Avg.) of 0.82m and a minL2(3s) of 0.99m.
C. Training Setup
Considering that no map is available for the SVs, these
PEP is implemented in PyTorch and has 1.3M trainable
resultsareworthmentioning.Inthefollowing,weinvestigate
parameters when configured as described in A. It is trained
whether planning really benefits from joint prediction.
over 400 epochs with batch size 512. We used the Adam
optimizer [44] with an initial learning rate of 5×10−4 that F. Ablation
decreaseswithafactorof0.8everyotherepoch.Onasingle We present ablation studies for the major design choices
GTX 1080Ti training to convergence takes about 1.25h. of our model. To assess the impact of SV predictions on1240
Past 2570
GT Future 917.5
1235 EV Plan 2565
SV Predictions 915.0
Route Section
1230 2560
912.5
1225 2555
910.0
1220 2550 907.5
1215 2545
1735 1740 1745 1750 1755 1760 2185 2190 2195 2200 2205 2210 270 275 280 285 290 295
Global x-Coordinate (m) Global x-Coordinate (m) Global x-Coordinate (m)
Fig. 3: Qualitative results. While the EV (red) uses the route (dashed) for guidance, it does not stick to it (left). Predicting
actions of SVs improves EV planning, for example by anticipating SVs to decelerate (blue, left) or to cross the EV lane
(blue, middle). Multi-modal predictions help the planner to consider diverse future scenarios (green, right).
TABLE II: Ablations of PEP model
1.25 AD-MLP
PEP (Ours)
1.00
L2(m) CR(%)
Prediction Route Equivariance 3s Avg. 3s Avg. 0.75
- - - 4.94 2.88 1.33 1.79 0.50
✓ ✓ - 2.81 2.24 1.73 1.23 0.25
✓ - ✓ 1.71 1.46 1.40 0.85
- ✓ ✓ 0.35 0.31 0.48 0.42 0.00
0 90 180 270 360
✓ ✓ ✓ 0.32 0.28 0.43 0.37 Rotation Angle (°)
Fig.4:Outputstability.Inferredoutsidethetrainingdistribu-
EV planning performance, L is removed from the loss
pred tion,ourSE(2)-equivariantmodelguaranteesastableoutput.
function (c.f. Eq. 13) so that the model is not explicitly
trainedtopredictSVs.Routeablationisrealizedbyskipping G. Equivariance
the route attraction module described in Eq. 3. Finally,
To investigate equivariance, we measure the output stabil-
we deliberately destroy the SE(2)-equivariance of PEP by
not subtracting and re-adding the mean position X¯ during ity under input transformations. To this, the input trajectory
androutearerotatedbyθ ∈[1◦,2◦,...,359◦].Then,theEV
equivariant feature initialization (c.f. Eq. 1). All networks
trajectory is planned and transformed back into the baseline
are trained until convergence.
coordinatesystembyarotationof−θ.Thetrajectoryplanned
Overall, the ablation experiments show that each component
without applying any rotation, i.e. θ = 0, serves as the
contributestotheplanningperformance.Ablatingallcompo-
baseline. For an ideal equivariant model, the L2 distance to
nents at once yields the highest L2 distances and CR(Avg.)
the baseline should be zero for all θ.
but not the highest CR(3s). This is explainable by poor
Fig. 4 depicts the output stability under rotation. Except for
behaviors like driving off-road or stopping, which are the
negligible numerical effects from rotation, the L2-distance
consequence of a map-less and route-less approach without
is constant around zero, demonstrating that PEP is rotation-
explicit prediction. Such behaviors increase the L2 distance
equivariant.Repeatingtheexperimentwithaddedrandom2D
and reduce the CR in an unreasonable way. Next, we inves-
translations confirms the results. In contrast, AD-MLP [15]
tigate the effect of ablating individual components. Ablating
which is trained on EV-centered data, is sensitive to input
equivariance results in the highest L2(3s) and L2(Avg.)
rotations which could, for example, arise from measurement
increase, which indicates that the model benefits from the
errors.Especiallywhendesigningsafety-relevantsystemsfor
prior knowledge on scene symmetry that is integrated by
automated driving, output stability and explainable behavior
meansofSE(2)-equivariance.Notintegratingthisknowledge
under input transformations are crucial.
intothemodelarchitecturemeansthatthemodelhastolearn
it itself, which reduces the sample efficiency and requires V. CONCLUSION
model capacity. Discarding the route also leads to a severe
In this work, we have proposed PEP, a simplistic equiv-
performancedecreaseasittakesawaytheonlyavailablemap
ariant planning model that integrates prediction and plan-
information, making the model fully interaction-based. In
ning in a joint approach. Our experiments show that PEP
contrast,PEPperformsonlymarginallyworsewhenablating
achieves state-of-the-art performance in open-loop planning
explicit prediction, which is consistent with recent findings
on nuScenes. Three major design choices contribute to the
that EV information is decisive for open loop planning on
performance: Joint prediction and planning, our novel route
nuSceneswhereinteractionsplayaminorrole[15],[52].Our
attractionmodule,andtheSE(2)-equivariantnetworkdesign.
resultsshowthatpredictionislessimportantthanrouteinfor-
Wedemonstrateoutputstabilityundertransformationsofthe
mation and equivariant model design. Nevertheless, ablating
input.Thispropertyofequivariantmodelscanprovidesafety
prediction leads to −10.7% L2(Avg.) and −9.4% L2(3s)
guarantees and might become an important aspect in the
compared to the complete model.
future of automated driving.
)m(
etanidrooC-y
labolG
)m(
etanidrooC-y
labolG
)m(
enilesaB
ot
ecnatsiD
2L
)m(
etanidrooC-y
labolGREFERENCES [26] A. Cui, S. Casas, A. Sadat, R. Liao, and R. Urtasun, “Lookout:
Diversemulti-futurepredictionandplanningforself-driving,”inProc.
[1] M. Hallgarten, M. Stoll, and A. Zell, “From prediction to planning ofIEEE/CVFICCV,2021,pp.16107–16116.
withgoalconditionedlanegraphtraversals,”arXiv:2302.07753,2023. [27] D. Dauner, M. Hallgarten, A. Geiger, and K. Chitta, “Parting
[2] N. Rhinehart, R. McAllister, K. Kitani, and S. Levine, “Precog: with misconceptions about learning-based vehicle motion planning,”
Predictionconditionedongoalsinvisualmulti-agentsettings,”inProc. arXiv:2306.07962,2023.
ofIEEE/CVFICCV,2019,pp.2821–2830. [28] Y. Chen, P. Karkus, B. Ivanovic, X. Weng, and M. Pavone,
[3] H. Song, W. Ding, Y. Chen, S. Shen, M. Y. Wang, and Q. Chen, “Tree-structured policy planning with learned behavior models,”
“Pip:Planning-informedtrajectorypredictionforautonomousdriving,” arXiv:2301.11902,2023.
inComputerVision–ECCV2020,Glasgow,UK,August23–28,2020, [29] S.Pini,C.S.Perone,A.Ahuja,A.S.R.Ferreira,M.Niendorf,and
Proceedings,PartXXI16. Springer,2020,pp.598–614. S. Zagoruyko, “Safe real-world autonomous driving by learning to
[4] Y. Hu, J. Yang, L. Chen, K. Li, C. Sima, X. Zhu, S. Chai, S. Du, predictandplanwithamixtureofexperts,”arXiv:2211.02131,2022.
T. Lin, W. Wang, et al., “Planning-oriented autonomous driving,” in [30] Z.Huang,H.Liu,J.Wu,andC.Lv,“Differentiableintegratedmotion
Proc.ofIEEE/CVFCVPR,2023,pp.17853–17862. predictionandplanningwithlearnablecostfunctionforautonomous
[5] Z.Huang,H.Liu,andC.Lv,“Gameformer:Game-theoreticmodeling driving,”arXiv:2207.10422,2022.
andlearningoftransformer-basedinteractivepredictionandplanning [31] T.CohenandM.Welling,“Groupequivariantconvolutionalnetworks,”
forautonomousdriving,”arXiv:2303.05760,2023. inICML. PMLR,2016,pp.2990–2999.
[6] S.Hagedorn,M.Hallgarten,M.Stoll,andA.Condurache,“Rethinking [32] D. Marcos, M. Volpi, N. Komodakis, and D. Tuia, “Rotation equiv-
integration of prediction and planning in deep learning-based auto- ariantvectorfieldnetworks,”inIEEEICCV,2017,pp.5048–5057.
mateddrivingsystems:areview,”arXiv:2308.05731,2023. [33] C. Esteves, C. Allen-Blanchette, X. Zhou, and K. Daniilidis, “Polar
[7] A. Cui, S. Casas, K. Wong, S. Suo, and R. Urtasun, “Gorela: Go transformernetworks,”arXiv:1709.01889,2017.
relative for viewpoint-invariant motion forecasting,” in 2023 IEEE [34] D.E.Worrall,S.J.Garbin,D.Turmukhambetov,andG.J.Brostow,
ICRA. IEEE,2023,pp.7801–7807. “Harmonic networks: Deep translation and rotation equivariance,” in
[8] V. G. Satorras, E. Hoogeboom, and M. Welling, “E (n) equivariant Proc.ofIEEECVPR,2017,pp.5028–5037.
graphneuralnetworks,”inICML. PMLR,2021,pp.9323–9332. [35] M.Weiler,F.A.Hamprecht,andM.Storath,“Learningsteerablefilters
[9] C.Xu,R.T.Tan,Y.Tan,S.Chen,Y.G.Wang,X.Wang,andY.Wang, forrotationequivariantcnns,”inIEEECVPR,2018,pp.849–858.
“Eqmotion: Equivariant multi-agent motion prediction with invariant [36] N. Thomas, T. Smidt, S. Kearnes, L. Yang, L. Li, K. Kohlhoff, and
interactionreasoning,”inIEEE/CVFCVPR,2023,pp.1410–1420. P. Riley, “Tensor field networks: Rotation-and translation-equivariant
[10] R.Walters,J.Li,andR.Yu,“Trajectorypredictionusingequivariant neuralnetworksfor3dpointclouds,”arXiv:1802.08219,2018.
continuousconvolution,”arXiv:2010.11344,2020. [37] F.Fuchs,D.Worrall,V.Fischer,andM.Welling,“Se(3)-transformers:
[11] M. Rath and A. P. Condurache, “Improving the sample-complexity 3droto-translationequivariantattentionnetworks,”Advancesinneural
of deep classification networks with invariant integration,” informationprocessingsystems,vol.33,pp.1970–1981,2020.
arXiv:2202.03967,2022. [38] B. Jing, S. Eismann, P. Suriana, R. J. Townshend, and R. Dror,
[12] ——,“Boostingdeepneuralnetworkswithgeometricalpriorknowl- “Learningfromproteinstructurewithgeometricvectorperceptrons,”
edge:Asurvey,”arXiv:2006.16867,2020. arXiv:2009.01411,2020.
[13] J. Ngiam, V. Vasudevan, B. Caine, Z. Zhang, H.-T. L. Chiang, [39] C.Deng,O.Litany,Y.Duan,A.Poulenard,A.Tagliasacchi,andL.J.
J.Ling,R.Roelofs,A.Bewley,C.Liu,A.Venugopal,etal.,“Scene Guibas,“Vectorneurons:Ageneralframeworkforso(3)-equivariant
transformer:Aunifiedarchitectureforpredictingfuturetrajectoriesof
networks,”inProc.ofIEEE/CVFICCV,2021,pp.12200–12209.
multipleagents,”inICLR,2021. [40] M. Kofinas, N. Nagaraja, and E. Gavves, “Roto-translated local
coordinate frames for interacting dynamical systems,” Advances in
[14] T.Gilles,S.Sabatini,D.Tsishkou,B.Stanciulescu,andF.Moutarde,
NeuralInformationProcessingSystems,vol.34,pp.6417–6429,2021.
“Thomas: Trajectory heatmap output with learned multi-agent sam-
pling,”arXiv:2110.06607,2021. [41] B. Ummenhofer, L. Prantl, N. Thuerey, and V. Koltun, “Lagrangian
fluidsimulationwithcontinuousconvolutions,”inICLR,2019.
[15] J.-T. Zhai, Z. Feng, J. Du, Y. Mao, J.-J. Liu, Z. Tan, Y. Zhang,
[42] A. Sanchez-Gonzalez, J. Godwin, T. Pfaff, R. Ying, J. Leskovec,
X. Ye, and J. Wang, “Rethinking the open-loop evaluation of end-
and P. Battaglia, “Learning to simulate complex physics with graph
to-endautonomousdrivinginnuscenes,”arXiv:2305.10430,2023.
networks,”inICML. PMLR,2020,pp.8459–8468.
[16] M. Hallgarten, I. Kisa, M. Stoll, and A. Zell, “Stay on track: A
[43] R.Wang,R.Walters,andR.Yu,“Incorporatingsymmetryintodeep
frenet wrapper to overcome off-road trajectories in vehicle motion
dynamics models for improved generalization,” arXiv:2002.03061,
prediction,”arXiv:2306.00605,2023.
2020.
[17] J.Gao,C.Sun,H.Zhao,Y.Shen,D.Anguelov,C.Li,andC.Schmid,
[44] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimiza-
“Vectornet: Encoding hd maps and agent dynamics from vectorized
tion,”arXiv:1412.6980,2014.
representation,”inIEEE/CVFCVPR,2020,pp.11525–11533.
[45] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas, and R. Ur-
[18] H. Cui, V. Radosavljevic, F.-C. Chou, T.-H. Lin, T. Nguyen, T.-K.
tasun, “End-to-end interpretable neural motion planner,” in Proc. of
Huang,J.Schneider,andN.Djuric,“Multimodaltrajectorypredictions
IEEE/CVFCVPR,2019,pp.8660–8669.
forautonomousdrivingusingdeepconvolutionalnetworks,”in2019
[46] P. Hu, A. Huang, J. Dolan, D. Held, and D. Ramanan, “Safe local
ICRA. IEEE,2019,pp.2090–2096.
motionplanningwithself-supervisedfreespaceforecasting,”inProc.
[19] F.Janjosˇ, M.Dolgov, andJ.M. Zo¨llner,“Starnet: Jointaction-space
ofIEEE/CVFCVPR,2021,pp.12732–12741.
prediction with star graphs and implicit global-frame self-attention,”
[47] T. Khurana, P. Hu, A. Dave, J. Ziglar, D. Held, and D. Ramanan,
in2022IEEEIV. IEEE,2022,pp.280–286.
“Differentiableraycastingforself-supervisedoccupancyforecasting,”
[20] J.Kim,R.Mahjourian,S.Ettinger,M.Bansal,B.White,B.Sapp,and
inECCV. Springer,2022,pp.353–369.
D.Anguelov,“Stopnet:Scalabletrajectoryandoccupancyprediction
[48] S. Hu, L. Chen, P. Wu, H. Li, J. Yan, and D. Tao, “St-p3: End-
forurbanautonomousdriving,”inIEEEICRA,2022,pp.8957–8963.
to-end vision-based autonomous driving via spatial-temporal feature
[21] M.Weiler,M.Geiger,M.Welling,W.Boomsma,andT.S.Cohen,“3d
learning,”inECCV. Springer,2022,pp.533–549.
steerablecnns:Learningrotationallyequivariantfeaturesinvolumetric
[49] Z.Chen,M.Ye,S.Xu,T.Cao,andQ.Chen,“Deepemplanner:Anem
data,”AdvancesinNeuIPS,vol.31,2018.
motionplannerwithiterativeinteractions,”arXiv:2311.08100,2023.
[22] M. Weiler and G. Cesa, “General e (2)-equivariant steerable cnns,”
[50] T. Ye, W. Jing, C. Hu, S. Huang, L. Gao, F. Li, J. Wang, K. Guo,
Advancesinneuralinformationprocessingsystems,vol.32,2019.
W. Xiao, W. Mao, et al., “Fusionad: Multi-modality fusion for pre-
[23] Y.WangandJ.Chen,“Eqdrive:Efficientequivariantmotionforecast-
dictionandplanningtasksofautonomousdriving,”arXiv:2308.01006,
ing with multi-modality for autonomous driving,” arXiv:2310.17540,
2023.
2023.
[51] B.Jiang,S.Chen,Q.Xu,B.Liao,J.Chen,H.Zhou,Q.Zhang,W.Liu,
[24] T.N.KipfandM.Welling,“Semi-supervisedclassificationwithgraph
C. Huang, and X. Wang, “Vad: Vectorized scene representation for
convolutionalnetworks,”arXiv:1609.02907,2016.
efficientautonomousdriving,”arXiv:2303.12077,2023.
[25] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong, Q. Xu, [52] Z.Li,Z.Yu,S.Lan,J.Li,J.Kautz,T.Lu,andJ.M.Alvarez,“Isego
A. Krishnan, Y. Pan, G. Baldan, and O. Beijbom, “nuscenes: A status all you need for open-loop end-to-end autonomous driving?”
multimodal dataset for autonomous driving,” in Proc. of IEEE/CVF arXiv:2312.03031,2023.
CVPR,2020,pp.11621–11631.