Guiding the generation of counterfactual
explanations through temporal background
knowledge for Predictive Process Monitoring
Andrei Buliga1,2*, Chiara Di Francescomarino3, Chiara Ghidini1,
Ivan Donadello1, Fabrizio Maria Maggi1
1Free University of Bozen-Bolzano, Bolzano,Italy.
2Fondazione Bruno Kessler, Trento Italy.
3University of Trento, Trento,Italy.
*Corresponding author(s). E-mail(s): abuliga@fbk.eu;
Abstract
Counterfactual explanations suggest what should be different in the input
instancetochangetheoutcomeofanAIsystem.Whendealingwithcounterfac-
tual explanations in the field of Predictive Process Monitoring, however, control
flowrelationshipsamongeventshavetobecarefullyconsidered.Acounterfactual,
indeed, should not violate control flow relationships among activities (temporal
background knowledge). Within the field of Explainability in Predictive Process
Monitoring, there have been a series of works regarding counterfactual explana-
tionsforoutcome-basedpredictions.However,noneofthemconsidertheinclusion
of temporal background knowledge when generating these counterfactuals.
In this work, we adapt state-of-the-art techniques for counterfactual generation
in the domain of XAI that are based on genetic algorithms to consider a series
of temporal constraints at runtime. We assume that this temporal background
knowledge is given, and we adapt the fitness function, as well as the crossover
andmutationoperators,tomaintainthesatisfactionoftheconstraints.Thepro-
posed methods are evaluated with respect to state-of-the-art genetic algorithms
forcounterfactualgenerationandtheresultsarepresented.Weshowcasethatthe
inclusionoftemporalbackgroundknowledgeallowsthegenerationofcounterfac-
tualsmoreconformanttothetemporalbackgroundknowledge,withouthowever
losing in terms of the counterfactual traditional quality metrics.
Keywords:predictiveprocessmonitoring,counterfactuals,explainableAI,
backgroundknowledge
1
4202
raM
81
]IA.sc[
1v24611.3042:viXra1 Introduction
A branch of Process Mining known as Predictive Process Monitoring (PPM) [1]
dealswithmakingpredictionsregardingthecontinuationofpartiallyexecutedprocess
instances using a historical record of past complete process executions. State-of-the-
art efforts in PPM have focused on delivering accurate predictive models through the
applicationofensemblelearninganddeeplearningtechniques[2,3].Duetotheinher-
ent complexity of these models, commonly referred to as black-box models, they are
oftenchallengingforuserstocomprehend.Forthisreason,eXplainableArtificialIntel-
ligence (XAI) techniques have been recently adopted in PPM to help interpret their
predictions and foster adoption of these advanced predictive models [4–7].
One example of such XAI techniques are counterfactual explanations, which sug-
gest what should be different in the input instance to change the outcome of a
predictionreturnedbyablack-boxpredictivemodel.Moststate-of-the-artcounterfac-
tual generation techniques in XAI are based around optimisation techniques [8]. Such
techniques find the minimum change to the input that flips the prediction. Although
the XAI literature has explored the utilization of GAs for the generation of coun-
terfactuals, no clear mapping exists to go from counterfactual desiderata to concrete
optimisation objectives. We thus contribute to the literature by providing a system-
aticmappingfromthecounterfactualexplanationdesideratadefinedin[9]toconcrete
optimization objectives for GA-based approaches for counterfactual generation.
Counterfactual explanations are essential for providing alternatives to achieve a
certain outcome (outcome-based predictions) in the PPM domain. They can guide
users in modifying the process instance to reach a desired outcome by assisting them
inunderstandinghowvariousactivitiesorattributesmayaffecttheprocessinstance’s
outcome. When dealing with counterfactual explanations in the PPM field, however,
process constraints, as control flow relationships among events have to be carefully
considered. A counterfactual, indeed, should not violate such process constraints. For
instance,supposeacounterfactualsuggeststoacustomerthat,tobeaccepted,aloan
application submission has to be performed before the loan application is actually
filled in. This scenario would not benefit the customer as it goes against the logical
sequence of events, violating certain temporal constraints and generating infeasible
counterfactuals.
State-of-the-artmethodsforcounterfactualsinPPMeitherutilizeagradient-based
search, incorporating terms to maintain generated counterfactual feasibility [7], or
employ genetic algorithms (GAs) [6, 10], preserving feasibility by treating the entire
processexecutionasasinglefeature[10]orbybuildingcounterfactualsinastate-wise
mannertodeterminetheirlikelihoodbasedontheobserveddata[6].However,noneof
the approaches so far explicitly incorporate these temporal process constraints, that
we can assume to know about the process (temporal background knowledge), at run-
time to ensure the feasibility of the generated counterfactual explanations. In this
work,inspiredbytheprocess-awaredimensionoftheevaluationframeworkintroduced
in [11], we adapt XAI GA-based state-of-the-art techniques for the counterfactual
generation to the PPM scenario by explicitly incorporating temporal background
knowledge. To this aim, we adapt the fitness function, as well as the crossover and
mutationoperators,toincorporatethetemporalbackgroundknowledge atruntime.We
2investigate both the single and multi-objective formulation of the GA problem. We
compare the proposed adapted methods to state-of-the-art methods using an exten-
sive evaluation protocol over different real-life datasets. The results suggest that the
approaches that include the temporal background knowledge can produce better coun-
terfactualsexplanations,especiallyintermsofconformancewiththeprovidedtemporal
background knowledge, while still maintaining or improving traditional counterfactual
quality metrics.
The main contributions of the work are:
• Thefirstsystematicmappingfromcounterfactualexplanationdesideratatoopti-
misation objectives for GAs. Indeed, although the XAI literature has explored
theusageofGAsforthegenerationofcounterfactuals,theconcreteoptimisation
objectives used in these approaches have never been systematically mapped to
the desiderata that a counterfactual should have [8, 9].
• The formulation of a multi-objective optimisation problem for the generation
of counterfactuals in the field of PPM. Indeed, although both single and multi-
objective approaches have been explored in the XAI literature, concluding that
multi-objective allows for obtaining better results [12], counterfactual generation
methods based on GAs in PPM focus only on the single-objective optimisation
case.
• A GA-based optimisation approach for the generation of counterfactual explana-
tions for PPM that incorporate temporal background knowledge at runtime.
• Anextensiveevaluationcomparingtheproposedapproacheswithstate-of-the-art
techniques over different real-life datasets.
Thefollowingsection(Section2)delvesintoamotivatingexampletohighlightthe
importanceofsuchcontributions.Section3introducestheneededbackgroundtograsp
the contents of the paper, Section 4 discusses related work, Section 5 highlights the
contributionsofthiswork,whileSection6introducestheevaluationandexperimental
settings. The analysis of the results is reported in Section 7, while the conclusions are
outlined in Section 8.
2 Motivating example
To illustrate a motivating scenario, we consider Bob, a customer of a bank that has
applied for a loan and is waiting for a decision from the bank. Bob’s application is
shown in the upper part of Fig. 1. He has a credit score of 540 euros and has applied
for a new credit application without specifying the goal of the loan. He requested
an amount of 15000 euros. After he has created the application (event1 Create appli-
cation), he submits the documents for the application (Submit documents). He then
receives an email from the bank asking for some missing information in the applica-
tion request (Receive missing info email) and, after 30 days, a reminder email, since he
forgot to answer to the first one (Receive reminder). Only at that point in time, Bob
provides an answer with the missing information to the bank (Provide missing info).
At some point during the processing of Bob’s case, the bank returns, saying that
hisloanapplicationhasbeenrejected.Bobwouldliketoknowwhatchangesheneeds
to make to get his loan application accepted. If we consider Bob’s case as the original
3query instance, a possible set of counterfactual explanations that Bob could obtain is
the one reported in the bottom part of Fig. 1.
Fig. 1 Example of an extract from an event long σ1 and a set of counterfactual explanations in
PredictiveProcessmonitoring.
This set of counterfactuals offers Bob a series of different feasible alternatives:
(i) Bob could specify the loan goal and lower the requested amount, (ii) Bob could
improve his credit score while keeping the same requested amount, or (iii) Bob could
immediately answer to the bank’s email by providing the missing info (Provide miss-
ing info) and then review his Loan application (Review Loan application). Among the
returned counterfactuals, however, we also find a fourth alternative, highlighted in
red in Fig. 1, suggesting that Bob should submit the documents for the application
even before the application was created by Bob, something that is impossible to do.
This counterfactual example shows a potential problem of traditional counterfactual
generationapproaches.Whencounterfactualgenerationtechniquesaresimplyapplied
to Predictive Process Monitoring in an out-of-the-box manner, they are not aware
of the temporal relations between certain features, such as the control-flow activities
that have certain constraints on their sequentiality. This highlights the importance
of adapting counterfactual generation techniques to the field of Predictive Process
Monitoring.
3 Background and Preliminaries
In this section, we introduce the main concepts useful to understand the remain-
der of the paper: event logs and the Declare language, as well as counterfactual
explanations and genetic algorithms.
43.1 Event Logs
An event log L is a set of traces (a.k.a. cases), each representing one execution of a
process. A trace σ = ⟨e ,e ,...e ⟩ consists of a sequence of events e , each referring
1 2 n i
to the execution of an activity (a.k.a. an event class). Moreover, a trace may have
staticanddynamicattributes.Theformer,trace attributes,pertaintothewholetrace
and are shared by all events within that same trace. The value of a trace attribute
remains the same throughout trace execution, i.e., it remains static. The latter (event
attribute) include, instead, in addition to the timestamp indicating the time in which
the event has occurred, attributes such as the resource(s) involved in the execution
of the corresponding activity, or other data specific to the event. In our motivating
example in Section 2, the trace attributes are Bob’s Application Type, Loan Goal,
RequestedAmount andBob’sCreditScore.Aneventattributeisinsteadthetimestamp
related to the time in which the activities in the trace have been carried.
Definition1(Event).Aneventisatuple(a,c,time,(d ,v ),...,(d ,v ))where
1 1 m m
a∈Σ is the activity name, c is the case identifier, time refers to the timestamp, and
(d ,v ),...,(d ,v ) (with m≥1) are the event attributes and their values.
1 1 m m
Definition 2 (Case). A case is a non-empty sequence σ =⟨e ,...,e ⟩ of events
1 n
such that ∀i ∈ {1,...,n},e ∈ E and ∀i,j ∈ {1,...,n},e .c = e .c, that is, all events
i i j
in the sequence refer to the same case.
We denote with Σ the set of all the activity names, and with E the universe of all
events. A case is the sequence of events generated by a given process execution.
Definition 3 (Trace). A trace of a case σ = ⟨e ,e ,...,e ⟩ is the sequence of
1 2 n
activity names in σ, ⟨e .a,e .a,...,e .a⟩.
1 2 n
We use S to show all possible traces, and we use sigma to show both cases and
traceswhenthereisnochanceofconfusion.TheeventlogLisacollectionofcomplete
traces (i.e., the tracks documenting the completion of a complete process execution).
For instance, we consider an event log that comprises a singular trace σ in Fig. 1,
1
pertaining to Bob’s application process. The activity name of the first event in the
case σ is Create Application (a); this event occurred on the 27th of January (time)
1
and refers to Bob’s case (c).
Given a case σ = ⟨e ,...,e ⟩ and a positive integer k < n, σ = ⟨e ,...,e ⟩ is
1 n k 1 k
the prefix of σ of length k. Furthermore, we define the prefix log as the log composed
of all possible case prefixes, as is typically used in Predictive Process Monitoring
settings [13]. In Fig. 2, σ refers to a prefix of Bob’s case, where k =5.
1
Definition 4 (Prefix Log). Given a log L, the prefix log L∗ of L is the event log
that contains all prefixes of L, i.e., L∗ ={σ :σ ∈L,1≤k <|σ|}.
k
3.2 Declare
When generating counterfactuals for a process execution, it is critical to determine
whether these alternative scenarios preserve specific process constraints (expressed in
the form of temporal constraints). The temporal constraints used in this paper are
based on Declare, a language for describing declarative process models first intro-
duced in [14]. A Declare model consists of a set of constraints applied to (atomic)
activities. These constraints, in essence, are built upon templates. Templates serve as
abstract, parameterized representations of common patterns or structures inherent in
5Template Description
existence(1,A) Aoccursatleastonce
absence(2,A) Aoccursatmostonce
responded existence(A,B) IfAoccurs,thenBoccurs
response(A,B) IfAoccurs,thenBoccursafterA
Alt.Response(A,B) EachtimeAoccurs,thenBoccursafter,beforeAoccurs
ChainResponse(A,B) EachtimeAoccurs,thenBoccursimmediatelyafter
precedence(A,B) BoccursonlyifprecededbyA
Table 1 MainDeclaretemplates
the behaviour of the underlying process. Templates have formal semantics expressed
in Linear Temporal Logic for finite traces (LTL ), making them verifiable and exe-
f
cutable. Table 1 summarizes the main Declare constructs used in this paper. The
reader can refer to [14] for a full description of the language.
Forbinaryconstraints(i.e.,constraintsspecifyingarelationshipbetweentwoactiv-
ities), one of the two activities is called activation, and the other target. When testing
a trace for conformance over one of these constraints, the presence of the activation
in the trace triggers the clause verification, requiring the (non-)execution of an event
containing the target in the same trace. When the activation does not occur, the con-
straint is said to be vacuously satisfied. For example, the template response(A,B) in
Table1isabinarytemplatespecifyingthat,shouldAoccur,thenBshouldoccurafter
A. In this case, A would represent the activation, while B the target. Unary templates
(i.e., templates that refer only to a single activity), instead, define the cardinality or
the position of the occurrence of an event in a process instance. In the case of unary
templates, we always consider the activities in the Declare constraints to be the
activations. For instance, existence(1,A) in Table 1 is a unary template specifying
that the activity A should occur at least once in a process execution. In this case, A
represents the activation.
GivenaDeclaremodelandaneventlog,conformancecheckingisusedtomeasure
the conformance of the traces with respect to the model. Rule checking is one of the
techniques typically used to perform conformance checking of models described in
terms of rules and constraints [13]. The idea is to evaluate the conformance of the
log with respect to rules, that is, constraints imposed by the process model. In the
case of Declare, conformance checking measures how many (and which) Declare
constraintsaresatisfiedorviolatedforagiveneventlog.Thisisneededtomeasurethe
fitness of the event log, i.e., how conformant the event log is regarding the Declare
model [13]. The more conformant an event log is, the higher its fitness score will be.
The formula for the rule-based log fitness1 is hence defined as:
|{φ∈M |∀σ ∈L,σ |=φ}|
F (M )= decl
L decl |M |
decl
where L represents the event log and M the Declare model containing only the
decl
single Declare constraint φ.
1Fromhereonweusethetermlogfitness fordenotingtherule-basedlogfitness.
6In our case, we extend the definition of rule-based fitness from [13], to the case of
a single trace, thus defining the notion of rule-based trace fitness 2:
|{φ∈M |σ |=φ}|
F (M )= decl
σ decl |M |
decl
where σ represents a single trace and M the Declare model containing only the
decl
single Declare constraint φ.
For instance, given the trace σ
1
= ⟨a,b,c,a,b,c,d,a,b⟩ and a Declare model
composed of two constraints Init(a) and ChainResponse(a,b), both constraints are
fullysatisfiedasthetracestartswitheventa,andeverytimeahappens,boccursright
after(eachofthethreeactivationsissatisfied).Sinceboththeconstraintsofthemodel
aresatisfied,thetracefitnessforσ
1
is1.Giveninsteadatraceσ
2
=⟨a,b,c,a,b,c,d,a⟩,
the constraint ChainResponse(a,b) would be violated, so that only one out of the
two constraints of the model is fulfilled by the trace. The trace fitness for σ would
2
hence be 0.5.
3.3 Predictive (Business) Process Monitoring
Predictive Process Monitoring (PPM) is a branch of Process Mining that aims to
use predictive techniques, such as Machine Learning models, to predict the future
of running cases of a business process by using historical executions of completed
traces(cases)fromaneventlog[1,2].WithinPPM,thereareseveralpredictiontasks
that one could aim to solve: predicting whether a certain predicate will be fulfilled
or not [15], predicting the next activity or the continuation of a running incomplete
case [2, 16], predicting the outcome of a specific case [3, 17], or predicting the time it
takestocompleteataskorthetimeremaininguntilthecompletionofacase[18].Such
prediction tasks support users in a decision-making process by offering an overview of
the future of trace executions. For example, predicting the outcome of a case could
allow a company to decide if and how resources or time should be allocated to cases
depending on their outcome.
Trainingapredictivemodelusuallyrequirespreprocessingtracesinsuchawaythat
is understandable for these models. For this reason, in the PPM literature, different
encoding strategies are deployed to include the different attributes present in a trace.
Apopularencodingmethodusedistheindex-basedencoding,wheretheorderofevents
is preserved, as opposed to other encoding techniques [17].
To give an example, each trace (prefix) σm =< e ,...,e >, i = 1...k, has to
i i1 im
be represented through a feature vector F =< g ,g ,...,g >. In this paper, the
i i1 i2 ih
simple-index and simple-trace index encodings are used.
• In the simple-index encoding [19], the focus is on the events and on the order in
whichtheyoccurinthetrace.Eachfeaturecorrespondstoapositioninthetrace,
andthepossiblevaluesforeachfeaturearetheeventclasses.Theresultingfeature
vector F , for a trace prefix σm of length m, is F =<a ,...,a ,...,a >, where
i i i i1 i2 im
a is the event class of the event at position j. Given the motivating example in
ij
Section 2 , Bob’s case would take the following vector form:
2Fromhereonweusethetermtracefitness fordenotingtherule-basedtracefitness.
7F =<Create application,Submit Documents,Receive missing info email,
Bob
Receive Reminder,Provide missing info>.
• The simple-trace index encoding [11] leverages the same dynamic information
related to the sequence of events as the simple-index encoding, but it also
includes static information related to data (i.e., the trace attributes) in its fea-
ture vector. The resulting feature vector F , for the trace prefix σm of length
i i
m, is represented as F =< s1,...,su,a ,a ,...,a >, where each s is a
i i i i1 i2 im i
static feature — corresponding to a trace attribute. Given the motivating exam-
ple in Section 2 , Bob’s case would take the following vector form: F =<
Bob
New credit,Not specified,15000.0,540,Create application,Submit Documents,
Receive missing info email,Receive Reminder,Provide missing info>.
Definition 5 (Sequence/trace encoder). A sequence (or trace) encoder e :
S→D ×...×D is a function that takes a (prefix) trace σ and transforms it into
1 m i
a feature vector x =e(σ ) in the p-dimensional vector space D ×...×D , with D ,
i i 1 m j
1≤j ≤p being the domain of the j-th feature.
Definition 6 (Feature vector decoder).Atracedecoderdec:D ×...×D →
1 m
S is a function that takes a feature vector x ∈ D ×...×D and decodes it into a
i 1 m
(prefix) trace σ .
i
For both encodings, we use the notation F [k] to denote the k-th feature of the
i
vectorF .Forinstance,inthecaseofthesimple-indexencoding,F [k]=a .Moreover,
i i ik
we denote with S the set of numeric indexes of static features and with CF the set
of numeric indexes related to control-flow features, that is F [k] is a static feature if
i
k ∈S and a control-flow one (an event class name) if k ∈CF.
Althoughmoreencodingscanbederivedfromtheindexencodingfamily,thefocus
inthispaperisonthecontrol-flowofthetraces,whichallowsonetobettercontrolthe
generation of the counterfactual explanations that satisfy the background knowledge.
The presented approaches in this paper could easily be extended to this other types
of encodings as well.
3.4 Counterfactual explanations
CounterfactualexplanationsbelongtothefamilyofXAImethods.However,compared
toothertypesofXAImethods,suchasfeatureattributionmethods[4],counterfactuals
do not attempt to explain the inner logic of a predictive model but instead offer an
alternative to the user to obtain a desired prediction [20]. When dealing with black-
box models, indeed, the internal logic of a model h mapping a sample x to a label y
θ
(also called class value) is unknown, or otherwise uninterpretable to humans.
A counterfactual c of x is a sample for which the prediction of the black box is
different from the one of x (i.e., h (c) ̸= h (x)). For example, in the case of binary
θ θ
classification, if h (x) = y, i.e., the sample is predicted to belong to class y, a coun-
θ
terfactual should flip the prediction such that h (c) = y′. A counterfactual explainer
θ
is a function f , where k is the number of requested counterfactuals, such that, for
k
a given sample of interest x, a black box model h , and the set X of known samples
θ
from the training set, returns a set C ={c ,...,c } of counterfactuals (with h≤k),
1 h
i.e., f (x,h ,X)=C.
k θ
83.5 Genetic algorithms
Genetic Algorithms (GAs) represent a powerful class of optimisation techniques,
drawing inspiration from the natural processes of evolution. They have found
widespreaduseacrossdiversedomainsduetotheireffectivenessinaddressingintricate
optimisation problems [21].
GAs are fundamentally based on several key principles, acting as the pillars of
their functioning. GAs operate within a population of potential solutions, evaluating
their quality through a fitness function. Building on the concept of “survival of the
fittest”, the algorithm selects the most promising solutions to serve as parents for the
next generation based on the results of the fitness function. These parent solutions
undergo a set of genetic operations, where their genetic information is combined to
createoffsprings[21].Thisnewgenerationcompetesandevolvesoversuccessiveitera-
tions until one or more optimal solutions are identified. The GA terminates when the
improvementwithrespecttothelastgenerationisbelowacertainthreshold,orwhen
the maximum number of iterations is reached.
Each candidate solution in the search space, that is, each individual of the popu-
lation, is described through a set of genes representing its chromosome or genotype.
Besides the definition of the genotype representation of a candidate solution, a GA
usually requires the specification of the fitness function, of the initial population, as
well as of the GA operators (selection, crossover, and mutation).
The fitness function defines the aspect(s) to optimise, thus helping select the best
solution according to such aspect(s) [21]. Based on the nature of the optimisation
problem, the aspect(s) to be optimised can be expressed in terms of a single objective
or in terms of multiple objectives.
In single-objective optimisation, the goal is to optimise a single, well-defined cri-
terion. The fitness function, in this case, quantifies how well a solution satisfies the
objective.Itprovidesaclearmeasureofsuccess,guidingthealgorithmtowardsolutions
that perform better with respect to the single criterion. Multi-objective optimisation,
on the other hand, deals with problems where there are multiple, often conflicting,
objectivestobeconsideredsimultaneously.Insuchcases,thefitnessfunctionbecomes
more complex as it needs to account for the trade-offs between different objectives.
Thechallengeistofindasetofsolutionsthatrepresentatrade-offbetweenconflicting
objectives,formingaParetofront.Thefitnessfunctioninmulti-objectiveoptimisation
assesses how well a solution balances conflicting criteria. The choice between single
and multi-objective optimisation depends on the problem at hand.
Theinitial population representsaninitialsetofcandidatesolutions.Usually,itis
randomly generated; however, it can also be a set of already “good” solutions.
The crossover operator determines how two parents share their genetic informa-
tion. The quality of the parents significantly influences the quality of the offspring.
This step helps to eliminate less desirable traits within the population. However, the
offspring may inherit unwanted characteristics from the parents. The mutation oper-
ator introduces random changes to the offspring’s genetic makeup. These changes are
determined by a mutation rate, representing the probability of altering specific traits
withinagivenpopulation.Mutation’sprimaryroleistomaintaindiversitywithinthe
population. The selection operator determines the members of the population that
9will be selected to be mated using the crossover and mutaiton operations. Different
selectionoperatorsexist,suchasrandomselectionortournamentselection.Inrandom
selection, members of the population are chosen randomly for mating, while tourna-
ment selection picks random pairs of solutions from the population at each round,
choosing the one that has the better fitness function score [21].
In the case of counterfactual generation, the initial population is a starting set of
counterfactual candidates [12, 22]. The fitness function helps select the most promis-
ing counterfactuals to move into the mating phase, based on some desired properties.
Depending upon the desired properties of the generated counterfactuals and possible
trade-offs, the problem could be formulated as either a single-objective optimisation
problemoramulti-objectiveproblem.Thefittestcounterfactualsolutionswillundergo
the crossover and mutations operators to produce better offsprings, i.e., more suit-
able counterfactual explanations given the input sample of interest [12]. Both these
operators help maintain the diversity of the set of generated counterfactuals C.
4 Related Work
In this section, we will offer a detailed picture of the works related to counterfac-
tual explanations in general settings in Section 4.1 and counterfactual explanation
techniques specifically applied to Predictive Process Monitoring in Section 4.2
4.1 Counterfactual explanations
Recently,DeepLearninghascontinuedtooutperformtraditionalstatisticalMLmodels
across different domains. Despite this, in domains where critical decisions are made,
such as the medical or the banking domain, such complex models have been generally
avoidedduetotheirinabilitytoprovideanyreasoningforthepredictionofferedbysuch
models. To overcome the black-box issue, Explainable Artificial Intelligence (XAI),
and in particular, counterfactual explanations, have emerged as a potential solution
toofferamorein-depthlookathowMLmodelsandespeciallyDeepLearningmodels
function and what do they consider relevant from the input they receive.
Counterfactual explanations identify the smallest change in the input instance
neededtoflipthepredictedoutcomeofadatainstance[20,23].Counterfactualgener-
ationtechniquescanbeclassifiedintwomaincategories[9]:case-basedandgenerative
methods. We define case-based methods as methods that search for counterfactuals
withinthesamplepopulationbyusingadistancemetric.Generativemethods,instead,
aim at generating synthetic counterfactuals that do not exist within the sample pop-
ulation through the use of an optimisation function that updates the input until the
desired outcome is reached [23, 24], or through Reinforcement Learning techniques,
whereanagentlearnsarewardfunctionthatchangesthepredictedoutcomeforagiven
sample [25]. GAs are a popular optimisation-based solution used to create a popula-
tion of potential counterfactual candidates by employing a fitness function [6, 12, 22].
Intheliterature,bothsingle-objectiveandmulti-objectiveGAsolutionsarepresented
for generating counterfactuals. While single-objective solutions may converge faster
due to a lower complexity [22], multi-objective GAs have the advantage of providing
10a Pareto Front of optimal solutions, where trade-offs are made between different opti-
misation objectives [12]. The advantage of GAs is that they maximise the diversity of
thepopulation,whilsthavingthedisadvantagethattheyareoftenstochastic,making
it difficult to obtain consistent results.
One example of a single-objective solution for counterfactual generation is pre-
sentedbySchleichetal.[22],namedGeneticCounterfactuals(GeCO).GeCOemploys
a single-objective genetic algorithm to fetch various counterfactuals, incorporating
considerations of plausibility and accountability during mutation and crossover oper-
ations by utilizing a plausibility-feasibility constraint language outlined in the paper,
named PLAF. These PLAF constraints only regard numerical features and aim to
ensure that causal relationships between variables have to be maintained when gen-
erating counterfactuals. The downside of this approach is that these constraints have
to be defined by a domain expert and cannot be extracted from data.
An example of a multi-objective genetic algorithm for the generation of counter-
factuals is proposed by Dandl et al. [12]. The concept behind the Multi-objective
Counterfactuals (MoC) involves conceptualizing the exploration of counterfactual
instancesasamulti-objectivegeneticoptimisationproblem.Theresultingsetofcoun-
terfactualinstances,encompassesadiversearrayofsolutionsthatbalancesthevarious
objectives. This balance is essential in achieving distinct trade-offs among the defined
objectives. The choice of a multi-objective optimisation problem allows one to avoid
the process of finding the optimal balance of weights between the different terms of a
single-objective collapsed fitness function [12].
In many of the presented works, the feasibility of counterfactual explanations is
presentedasanimportantdesideratum.Feasibility,orsometimesalsocalledplausibil-
ity, should ensure that the counterfactuals that one generates are valid. This is done
eitherbyrestrictingthedatamanifoldfromwhereonecouldgeneratethecounterfactu-
als[26],specifyingsomeconstraintsonindividualorpairsofattributes,orminimizing
the distance with respect to the closest point in the training set, when available.
However, no methods thus far leverage background knowledge to ensure that the
generated solutions respect it. As mentioned by Beckh et al. [27] in their review of
formalmethodsinXAI,nobackgroundknowledgeinjectionhasbeenexploredforthe
generation of counterfactual explanations. As pointed out in their review on evolu-
tionary algorithms (EAs) for XAI, Zhou and Hu [28] mention that one of the main
challengesforEAs,andinXAI,isthelackofmethodsabletoensurethatthegenerated
explanations are in line with the background knowledge.
4.2 Counterfactual explanations for Predictive Process
Monitoring
The adoption of Deep Learning models in Predictive Process Monitoring (PPM) has
synchronouslybroughtupontheadoptionofexplanatorytechniquesintendingtopro-
vide explanations for different prediction tasks [13]. The challenge that arises with
XAI in PPM is the way in which the data is structured. In static data, such as tab-
ular data or images, every input has the same size, and the expectation is that all
features will be present. In Process Mining, however, the format of the data is that
11of sequences that can be of varying lengths, thus resulting in a very dynamic setting,
making the process of generating explanations much more complex.
Counterfactualexplanationshelpusersunderstandratherwhattochangetoreach
a desired outcome through what-if scenarios [9]. Four works so far have tackled the
counterfactual explanation problem in the PPM domain [6, 7, 10, 11].
The first paper introduces LORELEY, an adaptation of the Local Rule-Based
Explanations (LORE) framework [24], which generates counterfactual explanations
leveragingasurrogatedecisiontreemodelusingageneticallygeneratedneighbourhood
of artificial data instances to be trained [10, 24]. The prediction task the authors
address is the one of multi-class outcome prediction. To ensure the generation of
feasible counterfactuals, LORELEY imposes process constraints in the counterfactual
generation process by using the whole prefix of activities as a single feature, encoding
the whole control-flow execution as a variant of the process.
The second work presents dice for Event Logs (DICE4EL) [7], which extends a
gradient-based optimisation method found in dice by adding a feasibility term to
ensure that the generated counterfactuals maximize the likelihood of belonging to
the training set. The prediction task addressed in the paper is that of next activity
prediction with a milestone-aware focus.
Thethird,themostrecentapproachforgeneratingcounterfactualexplanationsfor
PPM,CREATED,leveragesa geneticalgorithmtogenerate candidatecounterfactual
sequences[6].Toensurethefeasibilityofthedata,theauthorsbuildaMarkovChain,
where each event is a state. Then, using the transition probabilities from one state to
another, they can determine how likely a counterfactual is, given the product of the
states.
The fourth and final paper identified the need for a consolidated evaluation
framework for assessing the efficacy of various counterfactual generation methods in
PPM [11]. The work aims to understand the differences in these techniques’ perfor-
mance and offer a standardized evaluation framework for counterfactual explanations
in PPM. State-of-the-art metrics are adapted, and a novel evaluation metrics is
introduced for measuring the compliance of counterfactuals to some process back-
ground knowledge, described in terms of Declare constraints. The obtained results
highlight the need for techniques able to meet process-specific desiderata for trace
counterfactuals.
It can be noted that none of the previous approaches make use of background
knowledge explicitly when generating counterfactual explanations. However, as men-
tionedinSection4.1,backgroundknowledgecanplayanimportantroleinensuringthe
feasibility of the generated counterfactuals, especially from the control-flow perspec-
tive,wheredifferentconstraintsmayhaveadifferentimpactontheoutcomeofatrace
execution.Furthermore,noneofthepreviousapproacheshaveposedthecounterfactual
generation problem for Predictive Process Monitoring as a multi-objective optimisa-
tionproblem.Thepresentworkaimstospecificallyfillthesetwogapsidentifiedinthe
literature.
125 Methodology
Inthissection,wefirstfocusonthegeneralcounterfactualexplanations(Section5.1).
In detail, we first describe the desiderata that general counterfactual explanations
shouldsatisfy.Wethencontributetotheliteraturebyprovidinganovelmappingfrom
desiderata to concrete optimisation objectives for optimisation-based counterfactual
generation techniques. This addresses a gap in the current body of knowledge, as
priorresearchhasnotsystematicallyexploredthealignmentofdesiredcounterfactual
qualities with optimisation goals. We then describe two existing solutions for the
generation of counterfactual explanations through genetic algorithms (GAs).
Afterwards, in Section 5.2, we focus on the PPM scenario, by introducing two
methodologies for the counterfactual generation process through GAs when dealing
withcounterfactualsforPPM.Indetail,wefirstintroducetheadaptationsrequiredin
termsofdesiderata(Section5.2.1),wethenpresenthowtheseadapteddesideratacan
be satisfied through the adaptation of the single and multi-objective fitness functions
(Section 5.2.2), and we finally introduce the updates carried out to the crossover and
mutationoperatorsoftheproposedGAsforthegenerationofcounterfactualsforPPM
(Section 5.2.3)
5.1 From counterfactual desiderata to GA objectives
In this section, we report the desiderata for counterfactual explanations presented
in [9].
These counterfactual explanations desiderata can be summarised in the following
six categories:
(D1) Validity: Counterfactual explanations should change features in a way that the
prediction of the original input is flipped, thus ensuring that the explanation
aligns with the desired class.
(D2) Input Closeness: Effective counterfactuals should minimize the change to
provide a more understandable explanation.
(D3) Sparsity: Effective counterfactuals should change as few attributes as possible
to provide a more concise explanation.
(D4) Plausibility: Counterfactuals must be plausible by adhering to observed corre-
lations among features in the training data, thus ensuring they are feasible and
realistic.
(D5) Causality: Acknowledging the interdependence of features, counterfactuals
should respect known causal relations between features to be both realistic and
actionable.
(D6) Diversity: When generating a set of counterfactuals, the differences among the
counterfactuals in the set should be maximised to provide different alternatives
that a user could choose from.
When considering optimisation-based techniques for generating counterfactual
explanations, these desiderata can be targeted by directly translating them into opti-
misationobjectives. Intheirwork, Schleich etal.[22] andDandlet al.[12]instantiate
only the first four desiderata into different optimisation objectives for the fitness
function.
13Thevalidityofacounterfactual c(desideratumD1)istranslatedintoanobjective
o that is measured as the difference in probability between b(c) and y′. It is defined
1
as:
(cid:40)
0 if h (c)=y′,
o (h (c),y′)= θ
1 θ inf |h (c)−y′| otherwise.
y θ
where inf refers to infimum, or lowest greater bound over the possible values of y,
y
measuring the closeness between the predicted value h (c) and the target y′.
θ
Input closeness of the counterfactual c to x (desideratum D2) is targeted through
an objective o that measures the distance between the two values in terms of the
2
editdistanceforcategoricalvariables,oranumericaldistancebetweenthecontinuous
variables. It is defined as:
f (cid:40)
o (x,c)= 1 (cid:88) d(x ,c ) d(x ,c )= ||x j −c j|| 1 if x j is numerical,
2 f j j j j I if x is categorical,
j=1 xj̸=cj j
where f is the number of features, and d(x ,c ) depends on the feature type. When
j j
the feature is numerical, the L norm is used, while if the feature is categorical, the
1
indicator function is used to check whether c matches x .
j j
The sparsity of the counterfactual c with respect to x (desideratum D3) is trans-
lated into an objective o that measures the number of changes in the counterfactual
3
in terms of
the L norm:
0
f
(cid:88)
o (x,c)=||x−c|| = I . (1)
3 0 xj̸=cj
j=1
The plausibility of a counterfactual c (desideratum D4) is targeted through an
object o , measured in terms of the distance between the counterfactual c and the
4
closest point in the reference population X. This measure allows for determining the
implausibility of the candidate in the context of the reference population:
o (c,X)=mind(c,x) (2)
4
x∈X
Thefifthdesideratum(D5),causality,isusuallyaddressedthroughtheinsertionof
constraintsduringtheGA’s optimisationprocess.AsmentionedinSection4.1,Schle-
ich et al. [22] make use of PLAF constraints to ensure that the generated counterfac-
tuals satisfy causal relationships between features. However, these PLAF constraints
onlyregardnumericalfeaturesandcannotaccountfortemporalrelationshipsbetween
categorical attributes.
When using GAs, the diversity desideratum, (D6), is addressed by construction,
as the main advantage of GAs is the maximisation of the diversity of the population,
due to crossover and mutation operators that enhance the diversity.
Weincorporatetwooptimisationmethodsgroundedingeneticalgorithms[12,22],
strategically positioned as essential benchmarks to establish a comparative baseline
14for the framework under consideration. By introducing these optimisation methods,
we aim to contextualize and evaluate the performance of our proposed framework
againstestablishedtechniques,thushighlightingitsinnovationandresults.Therefore,
we denote the two optimisation methods as baselines in our study.
Theresultingfitnessfunction,consideringthefourdesiderataaddressedbythefour
objectives o ,...,o described above, results in the following single-objective fitness
1 4
function for the GA, which we call fsingle :
baseline
fsingle :=o (h (c),y)+α·o (x,c)+β·o (x,c)+γ·o (c,X) (3)
baseline 1 θ 2 3 4
where α,β,γ, are weighting factors for each term, controlling their influence on the fitness.
A natural solution to the complex problem of balancing the different objectives
posedintheprevioussingle-objectiveproblemismovingtoamulti-objectiveproblem.
In the multi-objective setting, a fitness function is constructed to evaluate solutions
based on multiple objectives, allowing for a more nuanced representation of trade-
offs. In their work, Dandl et al. [12] propose a fitness function based on the same
four desiderata, foregoing the causality desideratum D5, and addressing the diversity
desideratum D6 by employing a multi-objective optimisation technique. The multi-
objective fitness function, which we call Fmulti , takes the following form:
baseline
Fmulti :=(o (h (c),y),o (x,c),o (x,c),o (c,X)) (4)
baseline 1 θ 2 3 4
where the different objectives are the same as the ones detailed above. In this case,
the objectives are no longer weighted and collapsed into a single-objective function.
A trade-off among the different objectives can rather be directly extracted from the
Pareto Set of the solutions, thus also reinforcing the diversity between the different
counterfactuals.
5.2 Counterfactuals explanation for PPM with GAs
In this section, we introduce the proposed approaches for the generation of counter-
factualexplanations,startingfromtheadaptationofthegenericdesiderataandhence
GAsapproachestothedomainofPredictiveProcessMonitoring.Westartbydescrib-
ing the adaptations in terms of desiderata, and we then report how these adaptations
are reflected in the formulation of the fitness functions (both single-objective and
multi-objective), as well as in terms of the mating operators.
5.2.1 Adaptation of desiderata for PPM
When creating counterfactual explanations for Predictive Process Monitoring, the
requireddesideratacanmostlybedirectlytakenfromthegeneralcase.However,inthe
context of process mining, process relationships, as control flow relationships among
events, have to be also preserved. A counterfactual, indeed, should not violate control
flowrelationshipsamongactivities.Forinstance,acounterfactualcannotpretendthat
aloanapplicationsubmissionisperformedbeforealoanapplicationisfilled,asinthe
case of Bob (see Section 2) or that a loan request is approved before it is evaluated.
15The optimisation function should hence consider: (1) counterfactual validity (D1),
(2) similarity to the query instance (D2); (3) sparsity in the feature vector (D3); (4)
similaritytothetrainingdata(D4);(5)adherencetosomeknowledgemakingexplicit
the temporal ordering relationship among activities (temporal background knowledge)
(D5).
Having translated these desiderata to the PPM domain, we now move on to the
formulation of the optimisation problem for the generation of counterfactual expla-
nations in the field of PPM. We use the baseline previously introduced as a starting
point and expand the objective function for both the single and multi-objective case.
5.2.2 Optimisation problem formulations for counterfactual
explanations in PPM
In the previous section, we introduced the formulation of the optimisation problem
for the generation of general counterfactual explanations in both the single-objective
and multi-objective scenarios.
TocustomizethegeneralformulationtothecaseofPredictiveProcessMonitoring,
we need to consider the updated desiderata. To this aim we update the optimisation
functions so that they consider also the desideratum D5.
Toextendthebaselinefitnessfunctionpreviouslyintroduced,afifthobjectiveo is
5
introduced, aiming to address the causality desideratum directly D5 in the Predictive
Process Monitoring context, that is the adherence to temporal background knowledge
onthecontrolflow,thatweassumetobeavailableintheformof Declareconstraints.
To measure this aspect, this objective leverages the trace fitness metrics defined in
Section 3.2, which measures the number of satisfied temporal constraints present in
the Declare model M , leveraged as temporal background knowledge related to
Decl
the process underlying the data. This component is a way to check how fit c is with
respect to x:
o (x,c,M )=F (M )≡F (M )) (5)
5 Decl dec(x) Decl dec(c) Decl
where, for each Declare constraint φ ∈ M , if dec(x) |= φ, that is, if d(x)
Decl
satisfies the proposition φ, then dec(c) should also satisfy the proposition φ. The dec
function represents the decoder function, allowing us to go from the feature vector
representation to the trace representation.
The adapted single-objective fitness function, which we call fsingle , takes the
adapted
following form:
fsingle :=o (h (c),y)+α·o (x,c)+β·o (x,c)+γ·o (x,c,X )+δ·o (x,c,M )
adapted 1 θ 2 3 4 obs 5 Decl
(6)
where α,β,γ,δ are weighting factors for each term, controlling their influence on the
fitness.
However, in this setting, if one wants to obtain counterfactuals close to the query
instance,thedifferencebetweencounterfactualoutcomeanddesiredoutcomebecomes
more difficult to minimize while minimizing also the distance to the input query
instanceandtheconformancewithrespecttothetemporal background knowledge.For
16thisreason,wealsoextendthecounterfactualgenerationproblemtoamulti-objective
optimisation setting.
In the multi-objective case, the fifth objective o is once again introduced, to
5
address the causality desideratum (D5) in the PPM context, i.e., the adherence to
thetemporal background knowledge,assumingitsavailabilityintheformof Declare
constraints.Wehighlightthefactthatmulti-objectiveoptimisationforcounterfactual
generation within the context of PPM has not been explored before. The multi-
objective optimisation adapted fitness function, which we call Fmulti , takes the
adapted
following form:
Fmulti :=(o (h (c),y),o (x,c),o (x,c),o (c,X),o (x,c,M ) (7)
adapted 1 θ 2 3 4 5 Decl
where the different objectives are the same as the ones detailed for the single-
objective function.
Inthiscase,however,asforthegeneralcase,theobjectivesarenolongerweighted
and collapsed into a single-objective function. A trade-off among the different objec-
tives can rather be directly extracted from the Pareto Set of the solutions, ensuring
the diversity between the different counterfactuals.
5.2.3 Temporal knowledge-aware crossover and mutation operators
In this section, we introduce both a novel crossover and a novel mutation operator
that integrate temporal background knowledge, represented as Declare constraints.
Theseoperatorsreplace thebaselinecrossoverandmutation operators intheadapted
genetic algorithms – both in the single-objective and in the multi-objective case.
The idea behind the adapted crossover and mutation operators is generating off-
spring individuals that preserve the satisfaction3 of the Declare constraints of the
original query, while still encouraging the diversity within the generated offspring.
Intuitively, this means that the adapted operators should change the features of the
original query instance as the classical operators, while being careful that (i) the
constraints satisfied in the original query instance are not violated in the offspring
individual (that is, the target activities in the constraints remain unchanged); (ii) the
constraints that are not activated in the original query instance are not activated in
the offspring individuals (that is, no new activation activities are introduced in the
offspring instance). To this aim, starting from a Declare model M , we build the
decl
set of all the activation activities A and the set of all the target activities T. Assum-
ing that Σ is the alphabet of the activities used for instantiating the Declare
Mdecl
templates and generating the constraints in M , A = {a ∈ Σ | ∃ φ ∈ M
decl Mdecl decl
andaisanactivationofφ}andT ={a∈Σ |∃φ∈M andaisatargetofφ}.
Mdecl decl
For instance, in the case of Bob from the motivating example in
Section 2, we can assume to have a Declare model M (reported at
decl
the top of Fig. 2), provided to us by an expert, that represents our tem-
poral background knowledge. M is composed of 3 Declare constraints:
decl
Init(Create application), ChainResponse(Create application,Submit documents),
absence(2,Receive reminder). According to M , every application has to begin
Decl
with the Create application activity, that has to be directly followed by the Submit
3Weconsiderassatisfiedonlynon-vacuouslysatisfiedconstraints.
17documents activity. Finally, the activity Receive Reminder can be performed at most
once during the processing of a loan application.
Given M , the set of activations is A = {Create application,Receive reminder}
decl
and the set of target activities is T ={Submit documents}.
Crossover: The Adapted Crossover Operator, presented in Algorithm 1, is
designedforgeneratingoffspringindividualsfromtwoparentindividuals(P andP ),
1 2
astheclassicalcrossoveroperator,whilehoweverguaranteeingthattheDeclarecon-
straintssatisfiedintheoriginalqueryinstanceQarestillsatisfiedfortheoffspringO.
It takes as input the original query instance Q, two parent individuals, P and P ,
1 2
the crossover probability p , the activation, and target sets T and A extracted from
c
the Declare constraints, as well as the indexes for the control-flow features CF.
The Adapted Crossover Operator starts by initiating an offspring individual (O)
by retaining from Q the control flow phenotype that enables the satisfaction of the
Declare constraints, that is, any activities that appear in either the target set T
or activation set A (lines 1-7). This ensures that any of the Declare constraints
activated and satisfied in Q are also satisfied in O. Next, for each feature, a random
probabilitypissampledforthechoicebetweenthetwoparentsP orP (line8).The
1 2
emptyfeaturesintheoffspringindividualphenotypearethenfilledwithoneofthetwo
parents’geneticmaterialbutonlyiftheparent’scontrolflowfeaturesarenotactivation
activities,thatis,theydonotbelongtothesetA(lines8-18).Specifically,thecrossover
probability(p ),togetherwiththedrawnprobabilityp,guidestherandomselectionof
c
geneticmaterialfromeitherparentP orP asinclassicalcrossoveroperators,ifthe
1 2
selected item is not an activation activity. Otherwise, the crossover operator resorts
to using the corresponding segment from the original query instance Q. This ensures
that no new constraint activations are introduced in the offspring population.
Figure 2 showcases how the adapted crossover operator could work in the case of
themotivatingexampleofBobintroducedinSection2.GivenBob’scase,twoparents
from the previous population and the sets A and T, the adapted crossover operator
starts by checking the part of Bob’s case that is present in either of the two sets, and
thenimposesthatontotheoffspring.Specifically,itcanbeseenthatthevaluesofthe
control-flow features Event 1, Event 2 and Event 4 appear either in T or in A, thus
thefollowingactivitiesCreateapplication,Submitdocuments,andReceivereminder are
directly imposed onto the offspring individual O.
For the other event features, the gene Event 3 = Receive missing info email is
crossed over from P , while Event 5 = Update missing info is crossed over from P .
1 2
For the non-control-flow features, since they are attributes that are not related to the
control-flow of the trace, the genes are randomly chosen from either P or P .
1 2
Adapted Mutation operator: The Adapted Mutation Operator, presented in
Algorithm 2, focuses on mutating an offspring individual (O) while preserving the
satisfaction of the temporal constraints. The operator takes as input the offspring O,
(cid:83)
themutationprobabilityp ,thesetofthedomainofthefeaturesD = D extracted
m i
from the trace encoder, the set of the activation activities A, and the control-flow
indexesCF.Theoperatorreturnsasoutputamutatedoffspringindividual.Bydomain
of the features, we refer to the possible values that a certain attribute can take.
Thealgorithmstartsbysamplingarandomprobabilityofmutationp(line1).The
algorithmtheniteratesthrougheachfeaturefrom1to|O|(lines2-9).Forcontrol-flow
18Algorithm 1 Adapted Crossover Operator
Require: Parent Individuals P and P , Crossover Probability p , Original Query
1 2 c
Instance Q, activation A and target T activity sets extracted from the Declare
constraints, control-flow indexes CF
Ensure: Offspring Individual O
1: for i from 1 to |Q| do
2: if Q[i]∈T ∪A then
3: O[i]=Q[i]
4: else
5: O[i]=null
6: end if
7: end for
8: for i from 1 to |O| do
9: p∼U(0,1)
10: if O[i] is null then
11: if p<p c∧(i∈/ CF ∨P 1[i]∈/ A then)
12: O[i]=P 1[i]
13: else if p>p c∧(i∈/ CF ∨P 2[i]∈/ A then)
14: O[i]=P 2[i]
15: else
16: O[i]=Q[i]
17: end if
18: end if
19: end for
20: return O
features, if the probability of mutation is under the set threshold probability p , the
m
value of O[i] is then uniformly sampled from the set D \A, i.e., excluding activities
i
in the set A from the domain of the i-th feature to avoid introducing new constraint
activations and hence potential violations (lines 4-5). For non-control-flow features, if
themutationprobabilitypislowerthanthepredefinedthresholdp ,thevalueofO[i]
m
is sampled uniformly from the set D (lines 6-7). The algorithm proceeds mutating
i
each feature accordingly, and the mutated offspring O is returned as the result. This
operator ensures that mutations align with temporal constraints, contributing to the
diversity and adaptability of the genetic algorithm.
Sticking with Bob’s case, the mutation operator then mutates the gene Event 5
using the adapted mutation operator, picking a value in the domain of the activities
while ensuring that we exclude the activities in the activation set A, that is Create
application and Receive reminder, from the set of possible values. In this way, we avoid
a violation of the constraint ChainResponse(Create application,Submit documents),
as well as of the constraint absence(2,Receive reminder), considering that Receive
reminder has already been performed in Event 3. The Credit Score attribute, is also
mutated, by randomly sampling from the distribution of its domain.
19Algorithm 2 Adapted Mutation Operator
Require: Offspring O, Mutation Probability p , temporal constraint activations A,
m
Set of the domain of the features D, control-flow features indexes CF
Ensure: Mutated Offspring O
1: p∼U(0,1)
2: for i from 1 to |O| do
3: p∼U(0,1)
4: if p<p m∧i∈CF then
5: O[i]∼U(D i\A)
6: else if p<p m∧i∈/ CF then
7: O[i]∼U(D i)
8: end if
9: end for
10: return O
Fig. 2 Exampleshowcasingthefunctioningoftheadaptedgeneticoperator.
6 Evaluation
ToevaluatethecontributionsproposedforthegenerationofcounterfactualsforPPM,
we focus on answering the following research questions:
(RQ1) How do the adapted fitness functions and genetic operators impact the quality
of the generated counterfactual explanations?
(RQ2) What are the differences between single-objective optimisation and multi-
objectiveforgeneratingcounterfactualsinPredictiveProcessMonitoring(PPM)?
While the first research question (RQ1) focuses on the impact of the adapted
fitness functions and the new crossover and mutation operators, the second (RQ2)
aims at comparing the single and the multi-objective formulations of the problem for
the counterfactual explanation in PPM.
20To answer these research questions, our focus lies on evaluating and comparing
variousapproaches.Thisinvolvesleveragingeitherthebaselineoradaptedfitnessfunc-
tion—be it single-objective or multi-objective—of the optimisation problem, coupled
with the baseline or adapted crossover and mutation operators. This approach results
in the identification of four distinct counterfactual generation strategies:
• BOSO (Baseline Operators/fitness function and Single-objective optimisation)
using the baseline crossover & mutation operators and the baseline fitness
function in terms of single-objective optimisation as reported in Eq. 3 [11].
• AOSO (Adapted Operators/fitness function and Single-objective optimisation)
using the adapted crossover & mutation operators and the adapted fitness
function in terms of single-objective optimisation found as reported in Eq. 6.
• BOMO (Baseline Operators/fitness function and Multi-objective optimisation)
using the baseline crossover & mutation operators and the baseline fitness
function in terms of multi-objective optimisation as reported in Eq. 4 [12].
• AOMO (Adapted Operators/fitness function and Multi-objective optimisation)
using adapted crossover & mutation operators and the adapted fitness function
in terms of multi-objective optimisation as reported in Eq. 7.
Inthefollowingsectionswedetailthedatasetsusedforcarryingoutthecomparison
(Section 6.1), the metrics used for the evaluation (Section 6.2) and the experimental
settings (Section 6.3).
6.1 Datasets
To compare the counterfactual approaches, we selected 5 different publicly available
real-life event logs, labelled according to the satisfaction of their traces with respect
to the 11 Declare constraints shown in Table 2. We used, in total, 15 datasets
(combinations of event logs and labellings). Most of the datasets are taken from the
Business Process Intelligence Challenge (BPIC), a challenge held every year where
participantscanapplyvariousProcessMiningtechniquestouncoverinsightsfromthe
data.ThelabellingsusedinthispaperarethesameonesusedbyTeinemaaetal.[17].
The event logs were chosen due to the wide range of different characteristics,
such as the number of trace attributes, varying trace lengths and log size. Table 3
reports,foreachdataset,thenumberoftraces,variants(i.e.,uniquesequencesofevent
classes),eventattributes,andtraceattributesofthelog,aswellastheconstraintused
for labelling the log and the range of prefix lengths inspected for the counterfactual
generation.
BPIC2012. [29] This dataset, which was first made available in connection with
theBusinessProcessIntelligenceChallenge(BPIC)in2012,includestheloanapplica-
tion process execution history for a Dutch banking institution. Every instance in this
logdocumentstheeventssurroundingacertainloanapplication.Labellingswereestab-
lishedforclassificationreasonsdependingupontheoutcomeofacase,i.e.,whetherthe
applicationisapproved,denied,orcancelled.Thisseemstobeamulti-classclassifica-
tion problem intuitively. However, it is treated as three distinct binary classification
taskstomaintainconsistencywiththebinarytaskofoutcome-orientedpredictivepro-
cessmonitoring.ThesetasksarecalledBPIC2012 1,BPIC2012 2,andBPIC2012 3in
21ϕ1 =existence(1,Acceptloanapplication)
ϕ2 =existence(1,CancelLoanApplication)
ϕ3 =existence(1,RejectLoanApplication)
ϕ4 =response(Sendconfirmationreceipt,Retrievemissingdata)
ϕ5 =existence(1,Acceptloanapplication)
ϕ6 =existence(1,CancelLoanApplication)
ϕ7 =existence(1,RejectLoanApplication)
ϕ8 =existence(1,Patientreturnstotheemergencyroomwithin28daysfromdischarge)
ϕ9 =existence(1,Patientis(eventually)admittedtointensivecare)
ϕ10=existence(1,PatientisdischargedfromthehospitalonthebasisofsomethingotherthanReleaseA)
ϕ11=existence(1,PublicContestRecourse)
Table 2 TheDeclareconstraintsusedforthelabellings
the experiments. From each event log, three separate labellings are created, namely
ϕ for BPIC2012 1, ϕ for BPIC2012 2, and ϕ for BPIC2012 3 reported in Table 2.
1 2 3
BPIC2015.[30]Thisdatasetconsistsofeventlogsfrom5differentmunicipalities
fromtheNetherlands,regardingabuildingpermitapplicationprocess.Thedatafrom
each municipality is treated as a separate event log and a single labelling function is
appliedtoeachone.Thelabellingfunctionisbasedonthesatisfaction/violationofthe
Declareconstraintϕ inTable2.Thepredictiontaskforeachofthe5municipalities
4
is denoted as BPIC2015 i, where i=1...5 indicates the number of the municipality.
BPIC2017. [31] This event log originates from the same financial institution as
the BPIC2012 one. However, the data collection has been improved, resulting in a
richer and cleaner dataset. As in the previous case, the event log records execution
traces of a loan application process.
Similarly to BPIC2012, three separate labellings are created: ϕ for BPIC2017 1,
5
ϕ for BPIC2017 2, and ϕ for BPIC2017 3 reported in Table 2.
6 7
Sepsis. [32] This event log records cases of patients with possible symptoms of a
life-threatening sepsis condition in a hospital in the Netherlands. Each case belongs
to a patient’s admission into the emergency room up until their discharge from the
hospital.Laboratorytestsarerecordedasevents,andthedischargereasonisavailable
in the data in an obfuscated manner. From this event log, three separate labellings
are created, namely ϕ for Sepsis 1, ϕ for Sepsis 2, and ϕ for Sepsis 3, that can be
8 9 10
found in Table 2.
Legal Complaints. [33] This event log records execution traces of a public con-
tract auction in Italy and whether any recourses have been registered. A public
contractauctioniswhenthePublicAdministrationofaregionrequiresaservicetobe
done and holds a public contest where private contractors can bid to provide the ser-
vice.Whoeverwinsthecontest,isobligatedtocarryouttheservice.Asinglelabelling
is used to determine whether there is a recourse to the public contest or not, defined
in Table 2 as ϕ .
11
Thechosendatasetsexhibitdifferentcharacteristics,whichcanbeseeninTable3.
The smallest log is BPIC15 4, which contains 577 cases, while the largest one is
BPIC2017 with 31413 cases. The most imbalanced class labels are found in the Legal
22event trace avg.trace prefix labeling positive
Dataset EventLog trace# variant#
class# att.# length lengths formula class%
BPIC20121 ϕ1 47%
BPIC20122 BPIC2012 4685 3790 36 1 35 [20,25,30,35] ϕ2 17%
BPIC20123 ϕ3 35%
BPIC20151 BPIC20151 696 677 380 15 42 ϕ4 23%
BPIC20152 BPIC20152 753 752 396 15 55 ϕ4 19%
BPIC20153 BPIC20153 1328 1285 380 15 42 [15,20,25,30] ϕ4 20%
BPIC20154 BPIC20154 577 576 319 15 42 ϕ4 16%
BPIC20155 BPIC20155 1051 1049 376 15 50 ϕ4 31%
BPIC20171 ϕ5 41%
BPIC20172 BPIC2017 31413 2087 36 3 35 [20,25,30,35] ϕ6 12%
BPIC20173 ϕ7 47%
Sepsis1 ϕ8 14%
Sepsis2 Sepsis 782 709 15 24 13 [7,10,13,16] ϕ9 14%
Sepsis3 ϕ10 14%
LegalComplaints LegalComplaints 1101 636 14 4 2 [4,6,8,11] ϕ11 5%
Table 3 Eventlogstatisticsandlabellings
complaints dataset, where only 5% of the cases are labelled as positive. Conversely,
in BPIC2012 and BPIC2017, the classes are almost perfectly balanced. In terms of
event classes, the Legal complaints dataset is the one with the smallest number, with
only 14 distinct activity classes. The ones with the largest activity alphabet size
(number of different event classes), are, instead, the BPIC2015 datasets, reaching 396
event classes in BPIC2015 2. The datasets also differ in terms of the number of static
attributes, i.e., trace attributes, ranging from a single trace attribute for BPIC2012
to 24 trace attributes in Sepsis. Furthermore, an important aspect to consider is the
trace-to-variant ratio. This statistic characterises the level of variability observed in
the event log. The higher the number of variants to traces is, the more heterogeneous
an event log is considered to be. This, in turn, will also affect the results reported in
the evaluation across the different datasets.
6.2 Evaluation metrics
To evaluate the performance of the selected counterfactual approaches, we make use
of the evaluation protocol presented in [11], composed of seven evaluation metrics.
The chosen metrics refer to a single query instance x to be explained and consider
thereturnedcounterfactualsetC =f (x,b,X).Threeofthesevenmetricsconsidered
k
for the evaluation, that is, distance (o ), sparsity (o ), and implausibility (o ) are the
2 3 4
same ones usedfor three ofthe four objectivesdescribed in Section5.1 and ofthe five
objectivesofthePPMapproachesdescribedinSection5.2.Moreover,afourthmetrics,
the trace fitness, is the same one specifically introduced for the fifth objective of the
PPM fitness function formulation (Section 5). In other words, these four metrics are
used to evaluate three or four dimensions optimised through the GA counterfactual
generationapproachforthebaselineandadaptedalgorithms,respectively.Attheend
of the counterfactual generation process, we check that the predicted outcome of the
counterfactuals is alway the desired outcome, as such we do not leverage the metrics
related to the objective o for the evaluation, as it is always 1 for all the generated
1
counterfactuals. Besides these, we also measure for the evaluation (i) a fifth quality
metrics(thediversity),(ii)thehitrate,whichfocusesonthecapabilityofthemethods
to return the requested number of counterfactuals (k), as well as (iii) the runtime,
which measures the time required to generate the counterfactuals. For completeness,
we shortly summarize in the following the considered evaluation metrics:
23• The distance metrics measures the average distance between the query instance
x and the counterfactuals in C.
For good counterfactuals, the distance metrics is low. This metrics is the same
used for measuring the objective o .
2
• The sparsity metrics measures how many features have been changed in each
counterfactualwithrespecttothequeryinstance,averagedoverthetotalnumber
ofcounterfactualsgenerated.Alownumberofchangedfeaturesispreferred.This
metrics is the same used for measuring objective o .
3
• Theimplausibility metricsdetermineshowclosethegeneratedcounterfactualsare
to the reference population. For good counterfactuals, the implausibility metrics
is low. This metrics is the same used for measuring the objective o .
4
• The trace fitness metrics determines the ratio of Declare constraints under-
lying the considered process that are satisfied in the query instance x that are
also satisfied by each counterfactual in C, averaged over the set of all generated
counterfactuals. A high average trace fitness indicates a high compliance of the
generated counterfactuals with the constraints. This metrics is the same used for
measuring the objective o .
5
• The diversity metrics measures the average pairwise distance between the
counterfactuals in C. The diversity in C should be high.
• The hit rate metrics is defined as h/k, where h=|C| is the number of generated
counterfactuals,andk thenumberofrequestedcounterfactuals(seeSection3.4).
The value of hit rate should be high.
• Theruntime (measuredinseconds)isthetimetocomputetherequestednumber
of counterfactuals.
6.3 Experimental setting
To compare the four counterfactual generation approaches, we carried out different
experiments with different datasets, trace prefix lengths, as well as different number
of requested counterfactuals.
The experiments were performed over traces with variable prefix lengths to deter-
minewhetherdifferentprefixlengthsaffecttheresultsofthecounterfactualgeneration
process. We also performed experiments on both the simple-index and simple-trace
index encodings introduced in Section 3.3. This was done (similarly to other PPM
evaluations) to determine how the technique performs based on the amount of infor-
mationavailableuptoacertaincut-offpoint.Theprefixlengthsusedforeachdataset
are based on the results of Teinemaa et al. [17], where the selected prefix lengths
ensure that the predictive model can perform adequately and provide good predictive
performance. They are reported in Table 3. We also examined different settings for
the counterfactual generation process, where we ask for 5, 10, 15 and 20 counterfac-
tual examples to be returned [8]. This was done to determine whether the number of
counterfactuals has an impact on the quality of the generated counterfactuals, exe-
cution time and satisfiability of the counterfactuals. In the following we report first
some details on the experimental procedure and then the specific settings related to
the genetic algorithms.
24Experimental procedure. For each dataset, trace encoding, prefix length, We
splitthedatainto70%−10%−20%partitioningitintotraining,validation,andtest-
ing, respectively, using a sequential order split. A Random Forest (RF) model was
trained using the Python library scikit-learn. For the predictive model, hyperpa-
rameter optimisation was performed using the Hyperopt Python library to identify
thebestmodelconfigurationforeachdataset,prefixlengthandencodingcombination.
The training set used to train the RF model was used as input for the counterfactual
generationmethodstoobtainX.Sincewedidnothaveknowledgeontheprocessmod-
els generating the different logs, the Declare process constraints used as temporal
background knowledge, as well as for computing the trace fitness metrics in the evalu-
ation, were discovered from the traces in the event log. This was done by considering
all the Declare constraints satisfied by the traces in the whole training event log.
To discover these constraints, a support threshold of 90% was chosen for all datasets,
exceptfortheSepsisdatasetswherealevelofsupportof99%waschosen.Thischoice
was made as it provided the best trade-off between the number of constraints discov-
ered from each dataset and the ratio of non-conformant traces.4 The non-conformant
traces are then discarded from the datasets, to ensure that all traces are compliant to
the temporal background knowledge. Afterwards, fifteen instances were sampled from
the testing set and used for the counterfactual generation, one test set instance x a
time, where x is a prefix of the trace. We then evaluate the generated counterfac-
tuals using the evaluation framework presented in Section 6.2. All experiments were
performed on a M1 Macbook Pro machine with 16GB RAM 5.
GA setting. For all four settings, the initial population is created through a
hybrid procedure, either by finding points from the training set close to our test set
instance x or by randomly sampling values from the domain of the attributes.
In the single-objective setting, the algorithm presented in Schleich et al. [22]
is instantiated to find the most suitable counterfactual explanations. Since the PLAF
specifications do not allow us to constrain control-flow categorical variables, they are
notusedinthissetting.WemakeuseoftheimplementationavailablewithinDiCE[23].
ForBOSO,wemakeuseofthebaselinecrossoverandmutationoperatorsavailable
within DiCE, and the single-objective baseline fitness function presented in Eq. 3.
For AOSO, instead, we use the adapted crossover and mutation operators presented
in Section 5.2.3, and the single-objective adapted fitness function reported in Eq. 6.
The values of α, β, γ from Eq. 3 are set to α = 0.5,β = 0.5,γ = 0.5, the default
configuration in DiCE. For AOSO, in Eq. 6, the values for α, β, γ are the same, while
the value of δ is set to δ =0.5, to balance the different objectives.
Regarding the population selection, for both the single-objective approaches, at
eachiteration,thetop50%oftheoldpopulationispropagatedtothenewgeneration.
For the algorithm, a predefined number of generations is set to 100 along with a
performancethresholdfromonegenerationtoanother.Ifthenumberoftotaliterations
is reached or a considerable improvement is not observed over the last generation, the
algorithm terminates.
In the multi-objective setting, we make use of the framework presented
in Dandl et al. [12], but we replace the multi-objective optimisation algorithm with
4WeusedtheDeclare4PyPythonPackaged4py[34]forthediscoveryoftheDeclareconstraints.
5Thecodeusedtoruntheexperimentscanbefoundatrepository
25the Adaptive Geometry Estimation-based Many Objective Evolutionary Algorithm
(AGE-MOEA) [35] to find the non-dominated counterfactual candidates.6
AGE-MOEAcanprovideasetofnon-dominatedsolutionsthatarewell-distributed
and that cover the entire hyperbolic surface of the objective space [35]. Thus, it
becomes an ideal algorithm to be used for generating a set of diverse counterfactual
explanations, especially in a multi-objective setting.
FortheBOMO,wemakeuseofthebaselinecrossoverandmutationoperatorsavail-
able in the implementation package, and the multi-objective baseline fitness function
presented in Eq. 4. For AOMO, instead, we use the adapted crossover and mutation
operators presented in Section 5.2.3, and the multi-objective adapted fitness function
reported in Eq. 7.
As for the population selection, for both the multi-objective algorithms, at each
iteration, the members of the next generation are selected from the non-dominated
fronts,onefront(orlevel)atatime.Then,AGE-MOEAselectstheremainingsolutions
from the last non-dominated front according to the descending order of their survival
scores,computedasthedistancefromtheneighboursandproximitytotheidealpoint.
Thealgorithmstopsifeitherthepredefinednumberofgenerationsisreached(100)or
the performance no longer improves for a given number of successive generations.
7 Results and Discussion
In this section, we aim at presenting the results of the experiments carried out and to
answer the research questions introduced in Section 6. We report the overall results
in Fig. 3. In the following, we first focus on RQ1 (Section 7.1), we then address RQ2
(Section 7.2), and we finally provide an overall discussion on the obtained results
(Section 7.3).
7.1 Results regarding RQ1
To answer RQ1, we compare the performance of the methods AOSO and AOMO,
which make use of the single-objective or multi-objective adapted fitness functions
together with the mating and crossover operators, with their baseline counterparts,
that are, the BOSO and BOMO methods. In Figure 3, we report the overall results
forthetwotraceencodingsused,thedifferentprefixlengthsandthedifferentnumber
of requested counterfactuals. By looking at Fig. 3, we can make some general consid-
erations concerning the impact of the inclusion of the adapted fitness functions and
operators.
Overall, across the various datasets, the adapted counterfactual generation meth-
ods,namelyAOSOandAOMO,consistentlyshoweithersuperiororequalperformance
compared to their baseline counterparts, BOSO and BOMO. This conclusion holds
across multiple evaluation metrics, especially in terms of conformance to the temporal
background knowledge (i.e., trace fitness) as expected, but also, in general, in terms of
distance, sparsity and implausibility. Indeed, by constraining the counterfactual gen-
eration process, we can generate counterfactuals closer to the original instance input
6WeusedtheimplementationavailableinthePythonpackagepymoo[36].
26Fig.3 Resultsrelatedtocounterfactualquality,hit-rate,runtimeandtracefitnessforeacheventlog.
(lower distance), less sparse, i.e., with a lower number of attributes changed, (lower
sparsity) and, in general, slightly more plausible (lower implausibility).
The only metrics for which the adapted versions do not outperform their baseline
counterparts are diversity and runtime. The difference in terms of diversity is mainly
attributabletothefactthatweareconstrainingthecontrol-flowexecutionduringthe
generationprocesswiththeadaptedoperators,whichweexpectedtohaveasaneffect
areductionindiversity.Actually,thisisespeciallytrueforAOSO,whichalwayshasa
lower average diversity compared to the baseline method BOSO, while AOMO always
produces counterfactuals with a higher average diversity compared to the baseline
method BOMO.
Thedifferenceintermsofruntime isinsteadduetotheconformancechecksthatare
carried out when using the adapted fitness function, although the increase in runtime
varies from dataset to dataset. For AOMO the worst datasets in terms of runtime are
BPIC2012 and BPIC2017, while for AOSO the worst dataset is Sepsis.
27We also note that differences in dataset characteristics, such as outcome distri-
bution and the number of event classes, impact the performance and runtime of the
methods. For instance, skewed distributions of the outcome labels and low event class
numbers may contribute to longer convergence times or impact the quality of gen-
erated counterfactuals. In datasets that exhibit these behaviours, i.e., the Sepsis or
Legal Complaints dataset, the differences in runtime between the adapted methods
andthebaselinemethodsarelesspronouncedthanintheotherdatasets,i.e.,BPIC15,
BPIC2012, BPIC2017.
In conclusion, the adapted methods AOSO and AOMO consistently outperform
baselinemethodsBOSOandBOMOingeneratingcounterfactualinstancesacrossmost
of the evaluation metrics, except for a lower average diversity for AOSO and a higher
runtime for both the adapted metrics (RQ1).
7.2 Results regarding RQ2
To answer RQ2, we compare the performance of the methods leveraging a single
objectivefitnessfunction(AOSOandBOSO)withthemulti-objectivemethods(AOMO
and BOMO).
By looking at the plots in Fig. 3, we can observe some notable differences. In
general, we can observe that BOSO outperforms BOMO in several metrics. It is, in
general, closer to the original query, less sparse (except for BPIC2015), more plau-
sible (except for Legal Complaints), more diverse (except for comparable results for
the BPIC2012 and BPIC2015 datasets), more compliant to the temporal background
knowledge (exceptfortheBPIC2015datasets),althoughslightlymorecostlyinterms
of runtime.
On the other hand, when looking at the adapted fitness function and operators,
AOMOoutperformsAOSOintermsofdistance (exceptforBPIC2012andBPIC2017),
in terms of implausibility, trace fitness, diversity, as well as hit rate. In terms of
sparsity, instead, AOMO seems to perform better for more unbalanced datasets with
a low number of event classes (Sepsis and Legal Complaints), while AOSO performs
better on BPIC2012, BPIC2015 and BPIC2017. Finally, in terms of runtime, AOSO
significantly outperforms AOMO.
By looking at these observations, we can conclude that the choice between AOSO
and AOMO depends on specific priorities. AOSO may be preferred for applications
wherelowerdistanceandsparsityarecrucial,whileAOMOmightbemoresuitablefor
scenarios requiring higher diversity and where the runtime is not that important.
Overall,thedifferentformulationsofthefitnessfunctionintermsofsingle-objective
or multi-objective optimization have an impact on the obtained results, however, the
multi-objective optimization method benefits more from the inclusion of the adapted
operators compared to the single-objective optimization, whereas for the baseline
method, the single-objective BOSO outperforms the multi-objective BOMO (RQ2).
7.3 Discussion
Overall, we cannot identify a clear winner among the four investigated approaches.
Indeed, although the adapted approaches outperform their counterparts in most of
the metrics, the choice between AOSO and AOMO depends on specific priorities, such
28as the need for lower runtime or higher diversity, depending upon the requirements
of the user.
To better understand other possible factors impacting the results, we also inves-
tigated and analysed the results by looking at different prefix lengths and different
values of requested counterfactuals (k).
Fig. 4 reports the results of the evaluation varying the prefix lengths (according
to the prefix length ranges defined in Table 3), where the results concerning different
trace encodings and different datasets related to the same log are averaged. The plot
showsthattheprefixlengthhasanimpactontheresults.Asaverygeneraltrend,we
canobservethatastheprefixlengthincreases,thedistance fromtheoriginalinstance,
the sparsity, the diversity and the runtime increase. However, the trend is not the
same for all the datasets. Indeed, for some datasets (e.g., BPIC2012, BPIC2017) we
can observe peaks for certain prefix lengths and anomalous behaviours and no clear
trendastheprefixlengthincreases.Additionally,wealsonotedifferencesbetweenthe
different datasets in terms of implausibility. While in some cases implausibility tends
to decrease with longer prefixes, for other datasets (e.g., Sepsis), the opposite is true.
This behaviour seems to depend on the dataset and the number of traces with longer
prefixlengths.Thesepointscanbemainlyexplainedbytheheterogeneityofthetraces
of different lengths, and no clear trend can be identified by looking at the plot.
Moreover, in line with the evaluation of Mothilal et al. [23], and Buliga et al. [11],
we also show the results of the evaluation measured over an increasing number of
requestedcounterfactualsk inFig.5.Alsointhiscase,theresultsconcerningdifferent
trace encodings, different datasets, and different prefix lengths related to the same
log are averaged. The plot shows that in this case we can identify some clear trends.
In particular, as expected, as the number of requested counterfactuals increases, the
implausibility increases along with the runtime.
Overall, in Fig. 4 and Fig. 5, we can see a correlation between the implausibility
oftheresultsandthetrace fitness,especiallyfortheBOMOmethodintheBPIC2017
and BPIC2015 datasets. As implausibility decreases, trace fitness increases, which
confirms the fact that by using the adapted fitness function and genetic operators
(i.e., the AOMO method), we can greatly improve both the implausibility and the
trace fitness ofthegeneratedcounterfactualsatthesametime.Moreover,wecanalso
observe a strong correlation among distance and sparsity metrics, which is especially
clear for those datasets characterized by a large ratio of numerical trace attributes
(e.g. BPIC2015, BPIC2012).
8 Conclusions and Future work
In this paper, we introduced a framework for generating counterfactual explanations
withtheinclusionoftemporalbackgroundknowledge atruntimeforGeneticAlgorithms
(GAs). We first provided a systematic mapping from desiderata to concrete optimi-
sation objectives for counterfactual generation using GAs. We then formalised the
problemofgeneratingcounterfactualexplanationsthroughbothasingle-objectiveand
multi-objective problem formulation for Predictive Process Monitoring. An adapted
GA-based optimisation method was introduced that maintains the satisfaction of the
29Fig. 4 Results related to counterfactual quality, hit-rate, runtime and trace fitness for each event
log,measuredovervariableprefixlengths.
temporal background knowledge.Theadaptedmethodwasappliedforboththesingle-
objective and multi-objective problem formulation and compared to state-of-the-art
counterfactual GA approaches.
The results of the evaluation show that the adapted approaches that incorporate
thetemporal background knowledge producemoreconformantresults,whilealsobeing
on average less distant from the original instance and more plausible with the data
manifold. However, as expected, this comes at the cost of an increase in complexity.
30Fig. 5 Results related to counterfactual quality, hit-rate, runtime and trace fitness for each event
log,measuredoveranincreasingnumberofrequestedcounterfactuals.
In the future, we would like to extend the constraints used in the approaches to
also include the data-aware variants of such constraints, where other attributes are
included together with the Declare constraints. Moreover, we would like to fur-
ther refine our method to reduce the gap in terms of runtime required to return
the generated counterfactual explanations. Finally, we would like to integrate tem-
poral background knowledge also for gradient-based optimisation techniques for the
generation of counterfactual explanations.
31References
[1] Maggi, F.M., Di Francescomarino, C., Dumas, M., Ghidini, C.: Predictive
monitoring of business processes. In: International Conference on Advanced
Information Systems Engineering, pp. 457–472 (2014). Springer
[2] Tax, N., Verenich, I., Rosa, M.L., Dumas, M.: Predictive business process mon-
itoring with lstm neural networks. In: International Conference on Advanced
Information Systems Engineering, pp. 477–492 (2017). Springer
[3] Teinemaa,I.,Dumas,M., Rosa,M.L.,Maggi,F.M.:Outcome-orientedpredictive
process monitoring: Review and benchmark. ACM Transactions on Knowledge
Discovery from Data (TKDD) 13(2), 1–57 (2019)
[4] Stierle, M., Brunk, J., Weinzierl, S., Zilker, S., Matzner, M., Becker, J.: Bringing
light into the darkness-a systematic literature review on explainable predic-
tive business process monitoring techniques. ECIS Research-in-Progress Papers
(2021)
[5] Rizzi, W., Di Francescomarino, C., Maggi, F.M.: Explainability in predictive
process monitoring: When understanding helps improving. In: International
Conference on Business Process Management, pp. 141–158 (2020). Springer
[6] Hundogan, O., Lu, X., Du, Y., Reijers, H.A.: Created: Generating viable
counterfactual sequences for predictive process analytics. In: Indulska, M.,
Reinhartz-Berger,I.,Cetina,C.,Pastor,O.(eds.)AdvancedInformationSystems
Engineering, pp. 541–557. Springer, Cham (2023)
[7] Hsieh,C.,Moreira,C.,Ouyang,C.:Dice4el:Interpretingprocesspredictionsusing
a milestone-aware counterfactual approach. In: ICPM, pp. 88–95 (2021)
[8] Guidotti,R.:Counterfactualexplanationsandhowtofindthem:literaturereview
and benchmarking. Data Mining and Knowledge Discovery (2022) https://doi.
org/10.1007/s10618-022-00831-6
[9] Verma, S., Dickerson, J.P., Hines, K.: Counterfactual explanations for machine
learning: A review. CoRR abs/2010.10596 (2020)
[10] Huang, T.-H., Metzger, A., Pohl, K.: Counterfactual explanations for predic-
tive business process monitoring. In: Themistocleous, M., Papadaki, M. (eds.)
Information Systems, pp. 399–413. Springer, Cham (2022)
[11] Buliga, A., Di Francescomarino, C., Ghidini, C., Maggi, F.M.: Counterfactuals
andwaystobuildthem:Evaluatingapproachesinpredictiveprocessmonitoring.
In: Indulska, M., Reinhartz-Berger, I., Cetina, C., Pastor, O. (eds.) Advanced
Information Systems Engineering, pp. 558–574. Springer, Cham (2023)
[12] Dandl, S., Molnar, C., Binder, M., Bischl, B.: Multi-objective counterfactual
32explanations.In:B¨ack,T.,Preuss,M.,Deutz,A.,Wang,H.,Doerr,C.,Emmerich,
M., Trautmann, H. (eds.) Parallel Problem Solving from Nature – PPSN XVI,
pp. 448–469. Springer, Cham (2020)
[13] van der Aalst, W.M.P., Carmona, J. (eds.): Process Mining Handbook. Lecture
notes in business information processing, vol. 448. Springer, Cham, Switzerland
(2022). https://doi.org/10.1007/978-3-031-08848-3
[14] Sch¨onig, S., Di Ciccio, C., Maggi, F.M., Mendling, J.: Discovery of multi-
perspective declarative process models. In: Sheng, Q.Z., Stroulia, E., Tata, S.,
Bhiri,S.(eds.)Service-OrientedComputing,pp.87–103.Springer,Cham(2016)
[15] DiFrancescomarino,C.,Dumas,M.,Maggi,F.M.,Teinemaa,I.:Clustering-based
predictive process monitoring. IEEE transactions on services computing 12(6),
896–909 (2016)
[16] Pasquadibisceglie, V., Appice, A., Castellano, G., Malerba, D.: Using convolu-
tional neural networks for predictive process analytics. In: 2019 International
Conference on Process Mining (ICPM), pp. 129–136 (2019). IEEE
[17] Teinemaa,I.,Dumas,M.,LaRosa,M.,Maggi,F.M.:Outcome-orientedpredictive
process monitoring: Review and benchmark. ACM Trans. Knowl. Discov. Data
13(2) (2019)
[18] Aalst, W.M., Schonenberg, M.H., Song, M.: Time prediction based on process
mining. Information systems 36(2), 450–475 (2011)
[19] Leontjeva, A., Conforti, R., Di Francescomarino, C., Dumas, M., Maggi, F.M.:
Complex symbolic sequence encodings for predictive monitoring of business
processes. In: BPM 2015, vol. 9253, pp. 297–313 (2015)
[20] Wachter, S., Mittelstadt, B.D., Russell, C.: Counterfactual explanations with-
out opening the black box: Automated decisions and the GDPR. CoRR
abs/1711.00399 (2017)
[21] Mitchell, M.: An Introduction to Genetic Algorithms. MIT Press, Cambridge,
MA, USA (1998)
[22] Schleich, M., Geng, Z., Zhang, Y., Suciu, D.: Geco: Quality counterfactual
explanations in real time. Proc. VLDB Endow. 14(9), 1681–1693 (2021) https:
//doi.org/10.14778/3461535.3461555
[23] Mothilal, R.K., Sharma, A., Tan, C.: Explaining machine learning classifiers
through diverse counterfactual explanations. FAT* ’20, pp. 607–617 (2020)
[24] Guidotti, R., Monreale, A., Giannotti, F., Pedreschi, D., Ruggieri, S., Turini, F.:
Factual and counterfactual explanations for black box decision making. IEEE
Intelligent Systems 34, 14–23 (2019)
33[25] Chen,Z.,Silvestri,F.,Wang,J.,Zhu,H.,Ahn,H.,Tolomei,G.:Relax:Reinforce-
ment learning agent explainer for arbitrary predictive models. In: Proceedings of
the 31st ACM International Conference on Information & Knowledge Manage-
ment. CIKM’22,pp. 252–261.Associationfor Computing Machinery,NewYork,
NY, USA (2022). https://doi.org/10.1145/3511808.3557429 . https://doi.org/10.
1145/3511808.3557429
[26] Maragno, D., Kurtz, J., R¨ober, T.E., Goedhart, R., Birbil, S.I., Hertog, D.:
Finding regions of counterfactual explanations via robust optimization. CoRR
abs/2301.11113(2023)https://doi.org/10.48550/arXiv.2301.111132301.11113
[27] Beckh, K., Mu¨ller, S., Jakobs, M., Toborek, V., Tan, H., Fischer, R., Welke,
P., Houben, S., Rueden, L.: Harnessing prior knowledge for explainable machine
learning: An overview. In: 2023 IEEE Conference on Secure and Trustwor-
thy Machine Learning (SaTML), pp. 450–463 (2023). https://doi.org/10.1109/
SaTML54575.2023.00038
[28] Zhou, R., Hu, T.-K.: Evolutionary approaches to explainable machine learning.
ArXiv abs/2306.14786 (2023)
[29] vanDongen,B.:BPIChallenge2012.EindhovenUniversityofTechnology(2012).
https://doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f . https://
data.4tu.nl/articles/dataset/BPI Challenge 2012/12689204/1
[30] van Dongen, B.F.B.: BPI Challenge 2015. Eindhoven Uni-
versity of Technology (2015). https://doi.org/10.4121/UUID:
31A308EF-C844-48DA-948C-305D167A0EC1 . https://data.4tu.nl/collections/
/5065424/1
[31] vanDongen,B.:BPIChallenge2017.EindhovenUniversityofTechnology(2017).
https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b . https://
data.4tu.nl/articles/dataset/BPI Challenge 2017/12696884/1
[32] Mannhardt, F.: Sepsis Cases - Event Log. Eindhoven University of Technology
(2016). https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460 .
https://data.4tu.nl/articles/dataset/Sepsis Cases - Event Log/12707639/1
[33] Nai, R., Meo, R., Morina, G., Pasteris, P.: Public tenders, complaints, machine
learning and recommender systems: a case study in public administration. Com-
puter Law & Security Review 51, 105887 (2023) https://doi.org/10.1016/j.clsr.
2023.105887
[34] Donadello, I., Riva, F., Maggi, F.M., Shikhizada, A.: Declare4py: A python
libraryfordeclarativeprocessmining.In:BPM2022(PhD/Demos).CEURWork-
shop Proceedings, vol. 3216, pp. 117–121. CEUR-WS.org. https://ceur-ws.org/
Vol-3216/paper 249.pdf
34[35] Panichella, A.: An adaptive evolutionary algorithm based on non-euclidean
geometry for many-objective optimization. In: Proceedings of the Genetic and
Evolutionary Computation Conference. GECCO ’19, pp. 595–603. Association
forComputingMachinery,NewYork,NY,USA(2019).https://doi.org/10.1145/
3321707.3321839 . https://doi.org/10.1145/3321707.3321839
[36] Blank,J.,Deb,K.:Pymoo:Multi-objectiveoptimizationinpython.IEEEAccess
8, 89497–89509 (2020) https://doi.org/10.1109/ACCESS.2020.2990567
35