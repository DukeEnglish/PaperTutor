Dateofpublicationxxxx00,0000,dateofcurrentversionxxxx00,0000.
DigitalObjectIdentifier10.1109/ACCESS.2024.DOI
TrajectoryNAS: A Neural Architecture Search for
Trajectory Prediction
ALIASGHARSHARIFI1,ALIZOLJODI1,andMasoudDaneshtalab1 (SeniorMember,IEEE)
1MälardalenUniversity,Västerås,Sweden(e-mail:author@mdu.se)
Correspondingauthor:AliZoljodi(e-mail:ali.zoljodi@mdu.se)
ABSTRACT Autonomousdrivingsystemsarearapidlyevolvingtechnologythatenablesdriverless
car production. Trajectory prediction is a critical component of autonomous driving systems,
enabling cars to anticipate the movements of surrounding objects for safe navigation. Trajectory
prediction using Lidar point-cloud data performs better than 2D images due to providing 3D
information. However, processing point-cloud data is more complicated and time-consuming than
2D images. Hence, state-of-the-art 3D trajectory predictions using point-cloud data suffer from
slow and erroneous predictions. This paper introduces TrajectoryNAS, a pioneering method that
focuses on utilizing point cloud data for trajectory prediction. By leveraging Neural Architecture
Search(NAS),TrajectoryNASautomatesthedesignoftrajectorypredictionmodels,encompassing
object detection, tracking, and forecasting in a cohesive manner. This approach not only addresses
the complex interdependencies among these tasks but also emphasizes the importance of accuracy
and efficiency in trajectory modeling. Through empirical studies, TrajectoryNAS demonstrates its
effectiveness in enhancing the performance of autonomous driving systems, marking a significant
advancement in the field. Experimental results reveal that TrajcetoryNAS yield a minimum of 4.8
higger accuracy and 1.1* lower latency over competing methods on the NuScenes dataset.
INDEX TERMS Autonomous driving, neural architecture search, trajectory prediction, 3D point
cloud
I. INTRODUCTION Distancesandvelocitiescanbeestimatedwithveryhigh
accuracy.Therefore,itisthepreferredrepresentationfor
PREDICTING future actions or states of objects many scene-understanding-related applications such as
around an intelligent system, such as an au- autonomous driving and robotics.
tonomous driving (AD) vehicle, is crucial in preventing
disasters or crashes. Driving in the real world is a Our paper presents TrajectoryNAS, an application-
stochastic process due to the presence of other vehicles specific Neural Architecture Search (NAS) that aims to
and pedestrians that can take their next step result- create a trajectory model with high accuracy and mini-
ing in accidents or congestion. Therefore, AD systems mum displacement errors, both final and average (FDE
require the crucial ability to predict the trajectory of and ADE (Section IV-B)). Our empirical studies reveal
surrounding objects [1]–[3]. To perform the task of fore- that accurate object detection is crucial to achieve pre-
casting in self-driving vehicles, 2D and 3D data can be cise trajectory predictions. Therefore, TrajectoryNAS is
utilized. 3D data can usually be represented in different designed to localize objects with a minimum error and
formats, including depth images, point clouds, meshes, improvetheaccuracyoffinaltrajectorypredictions.Ad-
andvolumetricgrids.Theopticalcameraisusuallygood ditionally, to minimize the time required for inference,
forclassificationtaskssuchasdistinguishingthetypeof the final objective of TrajectoryNAS is to reduce the
surrounding objects or detecting lane markers or traffic model latency. The experimental results demonstrate
signs. While the performance on measuring distances that TrajcetoryNAS outperforms other approaches on
and velocities is rather weak, this information can be the NuScenes dataset, achieving a significant increase
retrieved well from radars. LIDARs are complementary in accuracy by at least 4.8% and a reduction in latency
to the other two sensors, showing competitive results. by 1.1 times compared to its competitors. Finally, our
VOLUME11,2023 1
4202
raM
81
]VC.sc[
1v59611.3042:viXraAuthoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
contributions in this challenge can be concluded as
follows:
DDDeeettteeecccttt TTTrrraaaccckkk FFFooorrreeecccaaasssttt
• Novelty of TrajectoryNAS: TrajectoryNAS, stands
out as a pioneering effort in the domain of tra-
SSeennssoorr ddaattaa iinn DDeetteeccttss oobbjjeeccttss OObbjjeecctt ttrraajjeeccttoorriieess OObbjjeecctt ttrraajjeeccttoorriieess
jectory prediction for autonomous driving. Unlike ppaasstt MM ffrraammeess iinn ppaasstt MM ffrraammeess IInn ppaasstt MM ffrraammeess IInn ffuuttuurree NN ffrraammeess
previous works, our method is the first to im-
plement Neural Architecture Search (NAS) in an
DDeetteecctt//TTrraacckk//FFoorreeccaasstt
end-to-end fashion, encompassing object detection,
tracking, and forecasting. This comprehensive in-
SSeennssoorr ddaattaa iinn OObbjjeecctt ttrraajjeeccttoorriieess
tegration addresses the intricate challenges arising ppaasstt MM ffrraammeess IInn ffuuttuurree NN ffrraammeess
from the interdependencies among subtasks, such
as point cloud processing, detection, and tracking, FIGURE 1: (Top Row) Cascade methods that indepen-
each contributing to the final trajectory forecast. dentlyaddressdetection,tracking,andforecasting,they
Also, the complexities of the search space further inherentlycarrytheriskofcompoundingerrorsthrough-
amplifythecomplexity,makingourTrajectoryNAS outthepipeline.Thisoriginatesfromeachsub-module’s
a unique and noteworthy contribution. assumptionofreceivingperfectinput,whichrarelyholds
• Efficient Mini Dataset Utilization: In response to true in real-world applications. Consequently, errors in-
thecomputationaldemandsassociatedwithNeural troduced in earlier stages propagate and magnify down-
architecture search, on large datasets, our method stream,potentiallyleadingtoinaccuratefinaloutcomes.
introduces an efficient two-step process. Initially, (BottomRow)End-to-endmethodsthatforecastfuture
we employ a mini dataset to speed up the identi- movement directly from raw data, enabling end-to-end
fication of the optimal architecture. Subsequently, training and benefiting from the joint optimization of
the identified architecture is applied to the com- object detection, tracking, and prediction tasks.
plete dataset, ensuring scalability and accuracy.
This streamlined approach is particularly valuable
when dealing with extensive datasets. revealing a
1) cascadeapproaches
noteworthy reduction in architecture search time.
Traditionalself-drivingautonomydecomposestheprob-
• PioneeringMulti-ObjectiveEnergyFunction:Akey lem into three subtasks: object detection, object track-
innovationofourworkistheintroductionofanovel
ing, and motion forecasting, and relies on independent
multi-objective energy function. This energy func-
components that perform these subtasks sequentially.
tion uniquely integrates considerations for object
These modules are usually learned independently, and
detection, tracking, forecasting, and temporal con-
uncertainty is usually propagated [1].In these methods,
straints. By incorporating these diverse elements
it is assumed that the exact paths taken by the agents
into a unified framework, our approach transcends
are known. By examining the trajectory data over a
existing methodologies that often overlook the in-
short period of time, predictions can be made for future
tricate relationship between these objectives. The
moments. For instance, the NuScenes [4] and Argoverse
novel energy function enhances the predictive ca-
[5]datasetsprovidetrajectoriesandtheircorresponding
pabilities of TrajectoryNAS, reinforcing its efficacy
labels for this purpose.
in real-world scenarios where temporal constraints
Many of the approaches presented in the literature
play a crucial role.
are based on neural networks that use recurrent neural
networks (RNNs), which explicitly take into account a
II. RELATEDWORKS history composed of the past states of the agents [6].
A. TRAJECTORYPREDICTION In RNNs and their variants, memory is a single hidden
In this section, we will provide a brief overview of the state vector that encodes all the temporal information.
literature focused on predicting trajectories using point Thus, memory is addressable as a whole, and it lacks
cloud data. We begin by explaining cascade approaches the ability to address individual elements of knowledge
(traditional approaches). In these approaches, the out- [3]. [3] presents the Memory Augmented Neural Tra-
put of a detector serves as input to a tracker. The jectory predictor (MANTRA). In this model, an exter-
tracker’s output is then used by a trajectory forecast- nal, associative memory is trained to store useful and
ing algorithm to estimate the anticipated movements non-redundant trajectories. Instead of a single hidden
of traffic participants in the upcoming seconds as in representation addressable as a whole, the memory is
Figure 1 (top row). Following that, the state-of-the-art element-wise addressable, permitting selective access to
approaches that do detection, tracking, and forecasting only relevant pieces of information at runtime.
in an end-to-end manner are reviewed, depicted in Fig- Spatial and temporal learning will be two key com-
ure 1 (bottom row) . ponents in prediction learning. Ignoring either infor-
2 VOLUME11,2023Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
X epochs
Select Architecure
n
o
ti
a
or Mini Dataset
pl
x Feedback
E
n X epochs nt
o e
ti m Trajectory
a
t y Prediction
oi Complete Dataset o
pl pl
Ex De
FIGURE 2: TrajectoryNAS state diagram. A model generated from the search space. The generated model trains
using the mini dataset. The results are sent back to search space to generate a new model. The best final model is
fully trained using the original dataset.
mation will lead to information loss and reduce the new transformer that simultaneously models the time
model’scapabilityofcontextlearning.Consequently,re- and social dimensions. Their method allows an agent’s
searchersarefocusingonjointlylearningRecurrentNeu- state at one time to directly affect another agent’s state
ral Networks(RNN) spatial and temporal information. in the future. In parallel, [13] develops an RNN-based
[7] utilize rasterization to encode both the agents and approach for context-aware multi-modal behavior fore-
high-definition map details, transforming corresponding casting. The model input includes both a road network
elements such as lanes and crosswalks into lines and attention module and a dynamic interaction graph to
polygonsofdiversecolors.However,therasterizedimage captureinterpretablegeometricandsocialrelationships.
is an overly complex representation of environment and As mentioned, cascade approaches in order to tra-
agent history and requires significantly more compu- jectory prediction are developed separately from their
tation and data to train and deploy. In an effort to upstream perception. As a result, their performance de-
address this, VectorNet [8] proposes a vector repre- gradessignificantlywhenusingreal-worldnoisytracking
sentation to exploit the spatial locality of individual results as inputs. [14] presents a novel prediction frame-
roadcomponentswithgraphneuralnetworks.LaneConv work that uses affinity matrices rather than tracklets
[9] constructs a lane graph from vectorized map data as inputs, thereby completely removing the chances of
and proposes LaneGCN to capture the topology and errors occurring in data association and passing more
long dependency of the agents and map information. information to prediction. To consider this propagation
Both VectorNet [8] and LaneConv [9] can be viewed of errors, [14] applies three types of data augmentation
as extensions of graph neural networks in prediction to increase the robustness of prediction with respect
with a strong capability to extract spatial locality. Nev- to tracking errors. They inject identity switches (IDS),
ertheless, both works fail to fully utilize the temporal fragments (FRAG), and noise.
informationofagentswithlessfocusontemporalfeature
extraction. In order to combine spatial and temporal 2) End-to-Endapproaches
learning in a flexible and unified framework, [10] pro- To prevent the propagation of errors and reduce infer-
poses Temporal Point Cloud Networks (TPCN). TPCN encetimeintraditionalmethods,astheylearnindepen-
models the prediction learning task as joint learning dently, researchers [15]–[18] attempted to perform de-
between a spatial module and a temporal module. tectionandtrackinginanend-to-endmanner.Withthe
same purpose, [19] proposed a network that parallelized
Across a range of visual benchmarks, transformer- tracking and prediction using a Graph Neural Network.
based models exhibit comparable or superior perfor- To our best knowledge, FaF [20] proposes the first
mance when compared to other network types like con- deep neural network capable of jointly performing 3D
volutionalandrecurrentneuralnetworks[11].Thistrend detection, tracking, and motion forecasting using data
extends to trajectory prediction as well. [12] proposes a captured by a 3D sensor. However, [20] limited its
VOLUME11,2023 3Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
predictions to a mere 1-second duration. In contrast, FutureDet. The new metric integrates both detection
IntentNet [21] enlarges the prediction horizon and es- and forecasting tasks. Notably, this approach surpasses
timates future high-level driver behavior. [22] moved a state-of-the-art methods without the necessity of object
step further and performed detection, forecasting, and tracks or HD maps as model inputs.
motionplanningjointly.Furthermore,[22]introducesan
additional perception loss that encourages the interme- B. NEURALARCHITECTURESEARCH
diaterepresentationstogenerateaccurate3Ddetections Optimizing model hyper-parameters is an effective way
and motion forecasts. This ensures the interoperability toimproveintelligentsystemsusingAutomatedmachine
of these intermediate representations and enables sig- learning (AutoML). [26]. Neural Architecture Search
nificantly accelerated learning. The statistical intercon- (NAS) is a subset of AutoML that aims to create
nections among actors are overlooked by all the previ- efficient neural networks for complex learning tasks.
ouslymentionedmethods,andinstead,theyindividually [27]. Early NAS methods used Reinforcement Learning
forecast each trajectory using the provided features. (RL) [28], [29] or evolutionary algorithms [30], [31].
[2] designed a novel network that explicitly takes into However, evaluating 20,000 neural architectures over
account the interactions among actors. To capture their four days requires remarkable computing capacity, such
spatial-temporal dependencies, [2] proposes a recurrent as 500 NVIDIA® GPUs [28]. Recently, methods for dif-
neural network with a Transformer architecture. ferentiable neural architecture search (NAS) have been
[23] suggests a reversing of the detect-then-forecast proven to achieve state-of-the-art results across various
pipelineratherthanfollowingtheconventionalsequence learning tasks [32]–[34]. DARTS [33] is a differentiable
of detecting, tracking, and subsequently forecasting ob- NASmethodthatusesthegradientdescentalgorithmto
jects. Afterward, object detection and tracking are per- searchandtrainneuralarchitecturecellsjointly.Despite
formedontheprojectedpointcloudsequencestoobtain the success of differentiable NAS methods in various
future poses. A notable advantage of this methodology domains [34], they suffer from inefficient training due
lies in the comprehensive representation of predictions, tointerferingwiththetrainingofdifferentsub-networks
incorporating details about RNNs, the background and each other [35]. Moreover, it has been proved that with
foreground objects existing within the scene. Similarly, equal search spaces and training setups, differentiable
inacomparablefashion,FutureDet[24]directlypredicts NAS methods converge to similar results [36].
the future locations of objects observed at a specific Meta-heuristic-based NAS methods [37]–[39] benefit
time instead of predicting point cloud sequences over from fast and flexible algorithms to search a discrete
time and then backcasting them to determine their search space. FastStereoNet [39] is a state-of-the-art
origin in the current frame. This allows the model to meta-heuristic method that designs an accurate depth
reason about multiple possible futures by linking future estimation pipeline. TrajectoryNAS is a fast multi-
and current locations in a many-to-one manner. This objective meta-heuristic NAS designed to optimize tra-
approach leverages existing LiDAR detectors to predict jectory prediction approaches by searching a wider de-
object positions in unseen future scans. Building upon sign space compared to differentiable methods or evolu-
therecentlyproposedCenterPointLiDARdetector[25], tionary NAS approaches.
FutureDetpredictsnotonlyfuturelocationsbutalsove-
locityvectorsforeachobjectineveryframebetweenthe III. TRAJECTORYNAS
current and final predicted future frame. This enables A. FRAMEWORK
the model to estimate consistent object trajectories Current trajectory prediction techniques rely on hand-
throughouttheentireforecastinghorizon.Intheprocess crafted neural network architectures. These models,
offorecasting,itisessentialtolinkalltrajectoriestothe while effective for tasks like 3D object detection, are
collection of object detections in the current (observed) sub-optimal for trajectory prediction. Building on the
LiDAR scan. For each future detection i, FutureDet success of Neural Architecture Search (NAS), Trajec-
computes the distance to every detection j from the toryNAS offers an interactive approach to designing
previous time step. Subsequently, for each i, FutureDet neural networks specifically for 3D trajectory predic-
selects the most suitable j (permitting multiple-to-one tion. However, it’s important to note that training a
matching). trajectory prediction model is both costly and time-
Additionally, it is argued that current evaluation consuming, requiring approximately 12 GPU hours for
metrics for forecasting directly from raw LiDAR data asinglemodel.Asaresult,theNASprocedurebecomes
are inadequate as they can be manipulated by simplis- significantly slow, requiring approxmately 1200 GPU
tic forecasters, leading to inflated performance. These hours. To expedite the process, each model generated
metrics, originally designed for trajectory-based fore- by the NAS is trained on a standard subset of the
casting, do not effectively address the interconnected NuScenes [4] dataset. This technique reduces the evalu-
tasks of detection and forecasting. To overcome these ation time for each model to nearly 1 hour, making the
limitations, a novel evaluation procedure is proposed by process approximately 12 times faster.
4 VOLUME11,2023Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
Figure 2 elaborates TrajectoryNAS state diagram. comprehensive and forward-looking perspective on en-
TrajectoryNAS is a one-stage trajectory prediction vironmental dynamics.
[20], [24]. The model takes a sequence of Lidar data TheTrajectoryNASsystemautomaticallydesignsthe
captured from the scene, which integrates a robust Region Proposal Network (RPN) and the prediction
3D backbone with cutting-edge Neural Architecture headsusingtheaforementionedlayers.Itexploresanex-
Search (NAS) to refine map-view feature extraction pansive space of 2300 potential architectures to identify
from LiDAR point clouds. This innovative architecture an optimal balance between speed and accuracy. This
further evolves by automating the design of multi-2D approach enables the selection of a highly efficient and
CNN detection heads, specifically tailored for future accurate architecture tailored for specific applications.
objectdetectionandtrajectoryprediction.Bydetecting
objects across multiple future timesteps and accurately C. SEARCHALGORITHM
projectingtheirmovementsbacktothecurrentmoment, To improve the accuracy of trajectory prediction while
TrajectoryNAS stands out for its precision in trajec- reducing network inference time, we employ the multi-
tory forecasting. This system not only anticipates the objective simulated annealing (MOSA) algorithm, as
dynamic positioning of objects but also adjusts its com- described in [40]. MOSA selects candidates based on
putationalstrategiesinreal-time,ensuringahighdegree the probability of min(1,exp(−∆/T)), where ∆ is the
ofaccuracyandefficiencyinprocessing.Theinclusionof energy difference between present and newly gener-
NASallowsforcontinuousimprovementofthedetection ated candidates, and T is the regulating parameter
and forecasting heads, making TrajectoryNAS a highly for annealing temperature. Initially, T starts from a
adaptive and forward-thinking solution in the realm of large value (TMax) and gradually decreases to a small
autonomous navigation and surveillance technologies. value (TMin). Setting TMax to a large value allows for
exploration of non-optimal choices, while TMin being
small gives the maximum selection chance to optimal
B. SEARCHSPACE
candidates (exploitation).
The TrajectryNAS architecture stands out as a so-
Toachievethisoptimization,weuseamulti-objective
lution for object detection and trajectory prediction,
energy function (Eq. 1). The fitness function (F) is the
particularly in scenarios like autonomous driving where
product of the network latency (t) and the weighted
understanding dynamic environments is paramount. It
mean average precision of the predicted future place
skillfully merges spatial and temporal object analyses,
of the object and its actual place (mAP), weighted
predicting not only the present state but also future
average displacement (ADE) error, and weighted final
trajectories. At its core, the VoxelNet Backbone trans-
displacement error (FDE).
forms point clouds into structured voxel representa-
tions, enabling the extraction of comprehensive spatial F =Latency×mAPα×ADEβ ×FDEγ (1)
features. This is complemented by a Sparse Feature
Pyramid Network (FPN), which builds a pyramid of Where α, β, and γ are weights of mAP, ADE, and
varying resolution features while efficiently managing FDE respectively. We do not use any proxy, such as
computational complexity by concentrating on relevant Floating-Point-Operations-per-Second (FLOPs), for in-
areas within the voxel space. ferencetimeestimation.Instead,werunthenetworkdi-
TrajectoryNAScontainsfiveparallelpredictionheads, rectly on the target hardware (NVIDIA® RTX A4000)
each dedicated to a specific aspect of object state: to measure the exact inference time.
Velocity, Rotation, Dimension, Regression, and Height.
These heads work in tandem to provide a multifaceted IV. EXPERIMENTALSETUP
description of an object’s current position and orien- We demonstrate the effectiveness of our approach on
tation at time t. The architecture’s prowess extends a large-scale real-world driving dataset. We focus on
to predicting future object trajectories. By leveraging modularmetricsfordetectionandforecasting,aswellas
the initial predictions, it projects the object’s state to systemmetricsforend-to-endperceptionandprediction.
time t+1, then cyclically feeds this data back into the
predictionheadstoforecasttheobject’spathoverfuture A. DATASET
steps. Our experimental analysis was performed on the
Such an approach allows TrajectryNAS to not only nuScenes [4] dataset, which contains 1000 log snippets,
navigatebutalsoanticipatecomplexdynamicbehaviors, each lasting 20 seconds. We utilized two officially re-
making it an invaluable asset in fields where predicting leased divisions of the dataset: the Mini and Trainval
future states is crucial for proactive decision-making. splits. The Mini split, which consists of 10 scenes, is a
This architecture’s ability to foresee the direction and subset of the Trainval split. The Trainval split contains
movement of objects enriches scene understanding and 700 scenes for training purposes and 150 scenes for
enhances planning for autonomous systems, offering a validation. Additionally, the Test split, containing 150
VOLUME11,2023 5Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
2
4 Height
1 3DBox
3 Regression MLP ADE
Dimension FDE
Rotation Score
Velocity mAP
VoxelNet RPN Sparse FPN Detection Heads Latency
FIGURE 3: The overview of TrajcetoryNAS process.
scenes, is designated for challenges and lacks object For cars, while Fast and Furious and FutureDet offer
annotations. a marginal improvement in specific aspects when com-
paredwithTrajectoryNAS,TrajectoryNASsignificantly
B. EVALUATIONMETRICS surpasses the state-of-the-art in most parameters. This
The performance of the End-to-End object forecasting is evidenced by its top performance in average precision
method is assessed using two standard metrics: Average for static, linear, and non-linear trajectories, as well
Precision for object detection (APdet) and Forecasting as its mean average precision (mAP), both for single
Average Precision (APf). Inspired by FuterDet [24], we (K = 1) and multiple (K = 5) predictions. Specifically,
have defined three subclasses: static cars, linearly mov- TrajectoryNAS achieves the highest detection accuracy
ing cars, and non-linearly moving cars, and we report and future average precision in almost all scenarios,
APf and APdet for these three classes. Subsequently, highlighting its robustness and efficacy in car trajectory
we evaluate the mean Average Precision for forecasting prediction.
(mAPf) as follows mAPf
=1/3×(APl fin.+AP fnon−lin.+
Similarly,forpedestriantrajectoryprediction,Trajec-
APs ftat.).
Similarly, mAPdet is evaluated as the average toryNAS demonstrates outstanding performance, par-
APdet over the three subclasses. ticularly in accurately predicting linear and non-linear
movements.Itnotonlyachievesthehighestaveragepre-
C. CONFIGURATIONSETUP cision scores across various scenarios but also maintains
For this study, Table 1 provides a brief overview of the a competitive latency, underscoring its effectiveness in
configuration setup. real-time applications.
In conclusion, TrajectoryNAS advances the field of
TABLE 1: Summarizing hardware specification, train,
trajectory prediction by offering a highly accurate and
and search parameters.
efficient model. Its ability to provide better future av-
erage precision under different conditions for both cars
Train/TestHardwareDevice Specification
GPU NVIDIA® RTXA4000 andpedestrians,coupledwithitscomparablelatencyto
GPUCompiler CUDAv11.7&cuDNNv8.2.0 leading models, positions TrajectoryNAS as a superior
DLFramework PyTorchv1.9.1
choice for trajectory prediction in dynamic environ-
TrainingandSearchParameters Value
ments.
Full-TrainingEpochs 20
BatchSize 1
LearningRate 5×10−4
B. ANALYSINGSEARCHMETHODS
Optimizer Adam
TMax /TMin 2500/2.5 Figure 4 presents a detailed comparison of the en-
ergy function reduction (as defined in Eq. 1) during
V. RESULTS the search process employed by the TrajectoryNAS
A. TRAJECTORYPREDICTIONPERFORMANCE algorithm against those of Random Search and Lo-
As presented in Tables 2 and 3, the comparison of cal Search methods. This comparative analysis clearly
car and pedestrian trajectory prediction results demon- demonstrates the limitations of both Local Search and
strates that TrajectoryNAS outperforms other state- Random Search techniques in effectively identifying the
of-the-art trajectory prediction methods in numerous most optimal solution. Specifically, the best outcome
parameters for car trajectory prediction and the major- identified through Random Search, characterized by an
ity of parameters for pedestrian trajectory prediction. energy value of e=0.19 as per Eq. (1), was achieved
Notably,thelatencyofTrajectoryNASiscomparableto in iteration 52. Similarly, Local Search’s most effective
thatofFastandFurious[20]andbetterthanFutureDet solution registered an energy value of e=0.186, and this
[24],whileTrajectoryNASprovidessuperiorfutureaver- result was obtained in iteration 50.
age precision (APf) across all conditions for both linear Despite these efforts, both methods fall significantly
and non-linear trajectories of cars and pedestrians. short when compared to the capabilities of the Trajec-
6 VOLUME11,2023Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
TABLE2:ComparisonTrajcetoryNASandstate-of-the-arttrajectorypredictionmodeloncarsaccordingtoaccuracy
and latency metrics.
Method Time(ms)
APstat. APlin.
K=1
APnon−lin. mAP APstat. APlin.
K=5
APnon−lin. mAP
APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf
Detection+ConstantVelocity 21 70.3 66.0 65.8 21.2 90.0 6.5 75.4 31.12 70.3 66.0 65.8 21.2 90.0 6.5 75.4 31.2
Detection+Forecast [20] 20 69.1 64.7 66.1 22.2 86.3 7.5 73.8 31.5 69.1 64.7 66.1 22.2 86.3 7.5 73.8 31.5
FutureDet[24] 24 70.0 65.5 62.9 24.9 91.8 10.1 74.9 33.5 70.1 67.3 62.9 27.7 91.7 11.7 74.9 35.6
TrajectoryNAS(ours) 22 71.0 65.6 63.8 26 91.2 10.3 75 34 71 67.4 63.8 29.2 91.1 12.1 75.3 36.2
TABLE 3: Comparison TrajcetoryNAS and state-of-the-art trajectory prediction model on pedestrian according to
accuracy and latency metrics.
Method Time(ms)
APstat. APlin.
K=1
APnon−lin. mAP APstat. APlin.
K=5
APnon−lin. mAP
APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf APdet. APf
Detection+ConstantVelocity 21 55.1 33.3 73.5 27.8 96.9 12.4 75.2 25.5 55.1 33.3 73.5 27.8 96.9 12.4 75.2 24.5
Detection+Forecast [20] 20 53.7 35.0 73.9 30.8 97.2 13.3 74.9 26.4 53.7 35.0 73.9 30.8 97.2 13.3 74.9 26.4
FutureDet[24] 24 53.1 33.3 72.4 32.6 95.2 14.7 73.6 26.9 53.1 35.1 72.4 34.0 95.2 15.0 73.6 28.0
TrajectoryNAS(ours) 22 55.8 37.1 77.9 39.9 95.2 17.7 76.3 31.3 55.8 38.6 77.9 40.9 95.2 17.9 76.3 32.5
toryNAS algorithm. TrajectoryNAS not only surpasses REFERENCES
thesetraditionalsearchmethodologiesinefficientlynav- [1] M.Liang,B.Yang,W.Zeng,Y.Chen,R.Hu,S.Casas,and
igating towards more optimal solutions but also show- R. Urtasun, “Pnpnet: End-to-end perception and prediction
withtrackingintheloop,” inProceedingsoftheIEEE/CVF
cases its superiority by discovering an exceptionally
Conference on Computer Vision and Pattern Recognition,
lowerenergyvalueof0.113.Thislandmarkachievement 2020,pp.11553–11562.
wasrealizediniteration108,underliningthealgorithm’s [2] L. L. Li, B. Yang, M. Liang, W. Zeng, M. Ren, S. Se-
gal,andR.Urtasun,“End-to-endcontextualperceptionand
advanced optimization prowess. Notably, the energy
predictionwithinteractiontransformer,” in2020IEEE/RSJ
value associated with the best solution found by Tra- International Conference on Intelligent Robots and Systems
jectoryNAS is nearly half that of the best solutions (IROS). IEEE,2020,pp.5784–5791.
unearthed by both Random Search and Local Search. [3] F. Marchetti, F. Becattini, L. Seidenari, and A. Del Bimbo,
“Multiple trajectory prediction of moving agents with mem-
This stark contrast underscores the advanced and so-
ory augmented networks,” IEEE Transactions on Pattern
phisticated nature of TrajectoryNAS in exploring and AnalysisandMachineIntelligence,2020.
exploiting the search space to find significantly more ef- [4] H. Caesar, V. Bankiti, A. H. Lang, S. Vora, V. E. Liong,
Q. Xu, A. Krishnan, Y. Pan, G. Baldan, and O. Beijbom,
ficient solutions, thereby establishing a new benchmark
“nuscenes: A multimodal dataset for autonomous driving,”
in the quest for optimization within this context. arXivpreprintarXiv:1903.11027,2019.
[5] M.-F.Chang,J.W.Lambert,P.Sangkloy,J.Singh,S.Bak,
A. Hartnett, D. Wang, P. Carr, S. Lucey, D. Ramanan,
VI. CONCLUSION
and J. Hays, “Argoverse: 3d tracking and forecasting with
Our paper presents TrajectoryNAS, an automated rich maps,” in Conference on Computer Vision and Pattern
model design approach that significantly enhances 3D Recognition(CVPR),2019.
[6] F. Leon and M. Gavrilescu, “A review of tracking and tra-
trajectory prediction for autonomous driving. By opti-
jectorypredictionmethodsforautonomousdriving,” Mathe-
mizing for both speed and accuracy while considering matics,vol.9,no.6,p.660,2021.
key performance metrics, TrajectoryNAS outperforms [7] T.Phan-Minh,E.C.Grigore,F.A.Boulton,O.Beijbom,and
E.M.Wolff,“Covernet:Multimodalbehaviorpredictionusing
existing methods by achieving a minimum of 4.8%
trajectorysets,” inProceedingsoftheIEEE/CVFconference
higher accuracy and 1.1 times lower latency on the oncomputervisionandpatternrecognition,2020,pp.14074–
NuScenes dataset. 14083.
[8] J. Gao, C. Sun, H. Zhao, Y. Shen, D. Anguelov, C. Li,
and C. Schmid, “Vectornet: Encoding hd maps and agent
dynamics from vectorized representation,” in Proceedings of
VOLUME11,2023 7Authoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
TrajectoryNAS Random Search Local Search
0.3
0.25
0.2
0.15
0.1
0 10 20 30 40 50 60 70 80 90 100 110
Search iterations
FIGURE 4: TrajectoryNAS optimization curve.
theIEEE/CVFConferenceonComputerVisionandPattern [20] W. Luo, B. Yang, and R. Urtasun, “Fast and furious: Real
Recognition,2020,pp.11525–11533. timeend-to-end3ddetection,trackingandmotionforecasting
[9] M. Liang, B. Yang, R. Hu, Y. Chen, R. Liao, S. Feng, withasingleconvolutionalnet,” inProceedingsoftheIEEE
and R. Urtasun, “Learning lane graph representations for conference on Computer Vision and Pattern Recognition,
motion forecasting,” in Computer Vision–ECCV 2020: 16th 2018,pp.3569–3577.
European Conference, Glasgow, UK, August 23–28, 2020, [21] S. Casas, W. Luo, and R. Urtasun, “Intentnet: Learning to
Proceedings,PartII16. Springer,2020,pp.541–556. predict intention from raw sensor data,” in Conference on
[10] M. Ye, T. Cao, and Q. Chen, “Tpcn: Temporal point cloud RobotLearning. PMLR,2018,pp.947–956.
networks for motion forecasting,” in Proceedings of the [22] W. Zeng, W. Luo, S. Suo, A. Sadat, B. Yang, S. Casas,
IEEE/CVF Conference on Computer Vision and Pattern and R. Urtasun, “End-to-end interpretable neural motion
Recognition,2021,pp.11318–11327. planner,” in Proceedings of the IEEE/CVF Conference on
[11] K.Han,Y.Wang,H.Chen,X.Chen,J.Guo,Z.Liu,Y.Tang, Computer Vision and Pattern Recognition, 2019, pp. 8660–
A.Xiao,C.Xu,Y.Xuetal.,“Asurveyonvisiontransformer,” 8669.
IEEE transactions on pattern analysis and machine intelli- [23] X. Weng, J. Wang, S. Levine, K. Kitani, and N. Rhinehart,
gence,vol.45,no.1,pp.87–110,2022. “Invertingtheposeforecastingpipelinewithspf2:Sequential
[12] Y. Yuan, X. Weng, Y. Ou, and K. M. Kitani, “Agent- pointcloud forecasting for sequential pose forecasting,” in
former: Agent-aware transformers for socio-temporal multi- Conferenceonrobotlearning. PMLR,2021,pp.11–20.
agentforecasting,”inProceedingsoftheIEEE/CVFInterna- [24] N.Peri,J.Luiten,M.Li,A.Ošep,L.Leal-Taixé,andD.Ra-
tionalConferenceonComputerVision,2021,pp.9813–9823. manan, “Forecasting from lidar via future object detection,”
[13] S. Khandelwal, W. Qi, J. Singh, A. Hartnett, and D. Ra- in Proceedings of the IEEE/CVF Conference on Computer
manan,“What-ifmotionpredictionforautonomousdriving,” VisionandPatternRecognition,2022,pp.17202–17211.
arXivpreprintarXiv:2008.10587,2020. [25] T.Yin,X.Zhou,andP.Krahenbuhl,“Center-based3dobject
[14] X. Weng, B. Ivanovic, K. Kitani, and M. Pavone, “Whose detection and tracking,” in Proceedings of the IEEE/CVF
track is it anyway? improving robustness to tracking errors Conference on Computer Vision and Pattern Recognition
with affinity-based trajectory prediction,” in Proceedings of (CVPR),June2021,pp.11784–11793.
theIEEE/CVFConferenceonComputerVisionandPattern [26] X.He,K.Zhao,andX.Chu,“Automl:Asurveyofthestate-
Recognition,2022,pp.6573–6582. of-the-art,” Knowledge-Based Systems, vol. 212, p. 106622,
[15] S. Wang, Y. Sun, C. Liu, and M. Liu, “Pointtracknet: An 2021.
end-to-endnetworkfor3-dobjectdetectionandtrackingfrom [27] T.Elsken,J.H.Metzen,andF.Hutter,“Neuralarchitecture
pointclouds,”IEEERoboticsandAutomationLetters,vol.5, search:Asurvey,”TheJournalofMachineLearningResearch,
no.2,pp.3206–3212,2020. vol.20,no.1,pp.1997–2017,2019.
[16] T.Yin,X.Zhou,andP.Krahenbuhl,“Center-based3dobject [28] B.ZophandQ.V.Le,“Neuralarchitecturesearchwithrein-
detection and tracking,” in Proceedings of the IEEE/CVF forcementlearning,” arXivpreprintarXiv:1611.01578,2016.
conferenceoncomputervisionandpatternrecognition,2021, [29] C.-H.Hsu,S.-H.Chang,J.-H.Liang,H.-P.Chou,C.-H.Liu,
pp.11784–11793. S.-C.Chang,J.-Y.Pan,Y.-T.Chen,W.Wei,andD.-C.Juan,
[17] X. Li and J. E. Guivant, “Efficient and accurate object de- “Monas:Multi-objectiveneuralarchitecturesearchusingrein-
tection with simultaneous classification and tracking under forcementlearning,” arXivpreprintarXiv:1806.10332,2018.
limitedcomputingpower,” IEEETransactionsonIntelligent [30] M.Loni,S.Sinaei,A.Zoljodi,M.Daneshtalab,andM.Sjödin,
TransportationSystems,2023. “Deepmaker: A multi-objective optimization framework for
[18] M. Simon, K. Amende, A. Kraus, J. Honer, T. Samann, deepneuralnetworksinembeddedsystems,”Microprocessors
H. Kaulbersch, S. Milz, and H. Michael Gross, “Complexer- andMicrosystems,vol.73,p.102989,2020.
yolo:Real-time3dobjectdetectionandtrackingonsemantic [31] M.Loni,A.Zoljodi,S.Sinaei,M.Daneshtalab,andM.Sjödin,
point clouds,” in Proceedings of the IEEE/CVF Conference “Neuropower:Designingenergyefficientconvolutionalneural
on Computer Vision and Pattern Recognition Workshops, networkarchitectureforembeddedsystems,”inInternational
2019,pp.0–0. Conference on Artificial Neural Networks. Springer, 2019,
[19] X.Weng,Y.Yuan,andK.Kitani,“Ptp:Parallelizedtracking pp.208–222.
and prediction with graph neural networks and diversity [32] C. Liu, L.-C. Chen, F. Schroff, H. Adam, W. Hua, A. L.
sampling,” IEEE Robotics and Automation Letters, vol. 6, Yuille, and L. Fei-Fei, “Auto-deeplab: Hierarchical neural
no.3,pp.4640–4647,2021. architecturesearchforsemanticimagesegmentation,”inPro-
8 VOLUME11,2023
noitcnuf
ygrenEAuthoretal.:PreparationofPapersforIEEETRANSACTIONSandJOURNALS
ceedings of the IEEE/CVF Conference on Computer Vision ALI ZOLJODI is Ph.D. student in Artifi-
andPatternRecognition,2019,pp.82–92. cial Intelligence at Mälardalen University,
[33] H. Liu, K. Simonyan, and Y. Yang, “Darts: Differentiable Västerås, Sweden. His main research inter-
architecturesearch,” arXivpreprintarXiv:1806.09055,2018. est is Autonomous driving systems. He is
[34] M. Loni, H. Mousavi, M. Riazati, M. Daneshtalab, and currentlyworkingonlanedetectionpercep-
M. Sjödin, “Tas:ternarized neural architecture search for tion.DuringhisPh.D.studies,hepublished
resource-constrainededgedevices,” inDesign,Automation&
apaperon3Dlanedetectionenhancement
TestinEuropeConference&ExhibitionDATE’22,14March
using Neural Architecture Search (NAS).
2022, Antwerp, Belgium. IEEE, March 2022. [Online].
Healsohasaready-to-submitpaperonus-
Available:http://www.es.mdh.se/publications/6351-
ingself-supervisedlearninginlanedetection
[35] H.Cai,C.Gan,T.Wang,Z.Zhang,andS.Han,“Once-for-all:
Trainonenetworkandspecializeitforefficientdeployment,” applications.BeforehisPh.D.studies,AliZoljodiexperiencedde-
arXivpreprintarXiv:1908.09791,2019. velopingNASforvariousapplicationssuchasimageclassification
[36] X. Dong, L. Liu, K. Musial, and B. Gabrys, “Nats-bench: andStereoVisionalgorithms.
Benchmarking nas algorithms for architecture topology and
size,” IEEE Transactions on Pattern Analysis and Machine
Intelligence,pp.1–1,2021.
[37] M. Loni, A. Zoljodi, D. Maier, A. Majd, M. Daneshtalab,
M.Sjödin,B.Juurlink,andR.Akbari,“Densedisp:Resource-
awaredisparitymapestimationbycompressingsiameseneu-
ral architecture,” in 2020 IEEE Congress on Evolutionary
Computation(CEC),2020,pp.1–8.
[38] H. Xu, S. Wang, X. Cai, W. Zhang, X. Liang, and Z. Li,
“Curvelane-nas: Unifying lane-sensitive architecture search
and adaptive point blending,” in Computer Vision–ECCV
2020: 16th European Conference, Glasgow, UK, August 23–
28,2020,Proceedings,PartXV16. Springer,2020,pp.689–
704.
[39] M. Loni, A. Zoljodi, A. Majd, B. H. Ahn, M. Daneshtalab,
M.Sjödin,andH.Esmaeilzadeh,“Faststereonet:Afastneural
architecturesearchforimprovingtheinferenceofdisparityes-
timation on resource-limited platforms,” IEEE Transactions
onSystems,Man,andCybernetics:Systems,pp.1–13,2021.
[40] K. Amine, “Multiobjective simulated annealing: Principles
and algorithm variants,” Advances in Operations Research,
vol.2019,2019.
MASOUDDANESHTALABreceivedthePh.D.
degreeincomputersciencefromtheUniver-
sityofTurku,Turku,Finland,in2011.Heis
currentlyaProfessorwithMälardalenUni-
versity(MDU),Västerås,Sweden.Heisan
Adjacent Professor with TalTech, Tallinn,
Estonia, and co-leading the Heterogeneous
System Research Group. He is on the Eu-
romicro board of directors and has pub-
lishedover200refereedpapers.Hisresearch
interestsincludeHW/SWco-design,reliability,anddeeplearning
acceleration.Prof.DaneshtalabisanEditoroftheMicroprocessors
andMicrosystems:EmbeddedHardwareDesign.
ALIASGHARSHARIFIreceivedhisB.Sc.and
M.Sc.degreesinCommunicationsEngineer-
ing from Arak University, Arak, Iran, in
2015,andCommunicationEngineeringwith
a specialization in Computer Vision from
Shahid Beheshti University, Tehran, Iran,
in 2017, respectively. He joined the Het-
erogeneous System Research Group as an
MLEngineerinVästerås,Sweden,in2021,
focusing on trajectory prediction and ob-
ject detection for autonomous driving systems. Prior to this, he
served as a Research Assistant at the Digital Signal Processing
Laboratory(DiSPLaY)GroupinTehran,Iran,from2017to2021,
wherehisworkinvolvedvariousaspectsofdigitalsignalandimage
processing. His research interests span machine learning, deep
learning,computervision,andsignalprocessing,asevidencedby
hiscontributionstoprestigiousIEEEpublications.
VOLUME11,2023 9