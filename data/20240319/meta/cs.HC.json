[
    {
        "title": "Inter-individual and inter-site neural code conversion and image reconstruction without shared stimuli",
        "authors": "Haibao WangJun Kai HoFan L. ChengShuntaro C. AokiYusuke MurakiMisato TanakaYukiyasu Kamitani",
        "links": "http://arxiv.org/abs/2403.11517v1",
        "entry_id": "http://arxiv.org/abs/2403.11517v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11517v1",
        "summary": "The human brain demonstrates substantial inter-individual variability in\nfine-grained functional topography, posing challenges in identifying common\nneural representations across individuals. Functional alignment has the\npotential to harmonize these individual differences. However, it typically\nrequires an identical set of stimuli presented to different individuals, which\nis often unavailable. To address this, we propose a content loss-based neural\ncode converter, designed to convert brain activity from one subject to another\nrepresenting the same content. The converter is optimized so that the source\nsubject's converted brain activity is decoded into a latent image\nrepresentation that closely resembles that of the stimulus given to the source\nsubject. We show that converters optimized using hierarchical image\nrepresentations achieve conversion accuracy comparable to those optimized by\npaired brain activity as in conventional methods. The brain activity converted\nfrom a different individual and even from a different site sharing no stimuli\nproduced reconstructions that approached the quality of within-individual\nreconstructions. The converted brain activity had a generalizable\nrepresentation that can be read out by different decoding schemes. The\nconverter required much fewer training samples than that typically required for\ndecoder training to produce recognizable reconstructions. These results\ndemonstrate that our method can effectively combine image representations to\nconvert brain activity across individuals without the need for shared stimuli,\nproviding a promising tool for flexibly aligning data from complex cognitive\ntasks and a basis for brain-to-brain communication.",
        "updated": "2024-03-18 07:10:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11517v1"
    },
    {
        "title": "A Browser Extension for in-place Signaling and Assessment of Misinformation",
        "authors": "Farnaz JahanbakhshDavid R. Karger",
        "links": "http://dx.doi.org/10.1145/3613904.3642473",
        "entry_id": "http://arxiv.org/abs/2403.11485v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11485v1",
        "summary": "The status-quo of misinformation moderation is a central authority, usually\nsocial platforms, deciding what content constitutes misinformation and how it\nshould be handled. However, to preserve users' autonomy, researchers have\nexplored democratized misinformation moderation. One proposition is to enable\nusers to assess content accuracy and specify whose assessments they trust. We\nexplore how these affordances can be provided on the web, without cooperation\nfrom the platforms where users consume content. We present a browser extension\nthat empowers users to assess the accuracy of any content on the web and shows\nthe user assessments from their trusted sources in-situ. Through a two-week\nuser study, we report on how users perceive such a tool, the kind of content\nusers want to assess, and the rationales they use in their assessments. We\nidentify implications for designing tools that enable users to moderate content\nfor themselves with the help of those they trust.",
        "updated": "2024-03-18 05:29:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11485v1"
    },
    {
        "title": "Holistic HMI Design for Automated Vehicles: Bridging In-Vehicle and External Communication",
        "authors": "Haoyu DongTram Thi Minh TranPavlo BazilinskyyMarius HoggenmüllerDebargha DeySilvia CazacuMervyn FranssenRuolin Gao",
        "links": "http://dx.doi.org/10.1145/3581961.3609837",
        "entry_id": "http://arxiv.org/abs/2403.11386v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11386v1",
        "summary": "As the field of automated vehicles (AVs) advances, it has become increasingly\ncritical to develop human-machine interfaces (HMI) for both internal and\nexternal communication. Critical dialogue is emerging around the potential\nnecessity for a holistic approach to HMI designs, which promotes the\nintegration of both in-vehicle user and external road user perspectives. This\napproach aims to create a unified and coherent experience for different\nstakeholders interacting with AVs. This workshop seeks to bring together\ndesigners, engineers, researchers, and other stakeholders to delve into\nrelevant use cases, exploring the potential advantages and challenges of this\napproach. The insights generated from this workshop aim to inform further\ndesign and research in the development of coherent HMIs for AVs, ultimately for\nmore seamless integration of AVs into existing traffic.",
        "updated": "2024-03-18 00:23:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11386v1"
    },
    {
        "title": "A Systematic Review of XR-based Remote Human-Robot Interaction Systems",
        "authors": "Xian WangLuyao ShenLik-Hang Lee",
        "links": "http://arxiv.org/abs/2403.11384v1",
        "entry_id": "http://arxiv.org/abs/2403.11384v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11384v1",
        "summary": "This survey provides an exhaustive review of the applications of extended\nreality (XR) technologies in the field of remote human-computer interaction\n(HRI). We developed a systematic search strategy based on the PRISMA\nmethodology. From the initial 2,561 articles selected, 100 research papers that\nmet our inclusion criteria were included. We categorized and summarized the\ndomain in detail, delving into XR technologies, including augmented reality\n(AR), virtual reality (VR), and mixed reality (MR), and their applications in\nfacilitating intuitive and effective remote control and interaction with\nrobotic systems.The survey highlights existing articles on the application of\nXR technologies, user experience enhancement, and various interaction designs\nfor XR in remote HRI, providing insights into current trends and future\ndirections. We also identified potential gaps and opportunities for future\nresearch to improve remote HRI systems through XR technology to guide and\ninform future XR and robotics research.",
        "updated": "2024-03-18 00:22:30 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11384v1"
    },
    {
        "title": "A Review of Virtual Reality Studies on Autonomous Vehicle--Pedestrian Interaction",
        "authors": "Tram Thi Minh TranCallum ParkerMartin Tomitsch",
        "links": "http://dx.doi.org/10.1109/THMS.2021.3107517",
        "entry_id": "http://arxiv.org/abs/2403.11378v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11378v1",
        "summary": "An increasing number of studies employ virtual reality (VR) to evaluate\ninteractions between autonomous vehicles (AVs) and pedestrians. VR simulators\nare valued for their cost-effectiveness, flexibility in developing various\ntraffic scenarios, safe conduct of user studies, and acceptable ecological\nvalidity. Reviewing the literature between 2010 and 2020, we found 31 empirical\nstudies using VR as a testing apparatus for both implicit and explicit\ncommunication. By performing a systematic analysis, we identified current\ncoverage of critical use cases, obtained a comprehensive account of factors\ninfluencing pedestrian behavior in simulated traffic scenarios, and assessed\nevaluation measures. Based on the findings, we present a set of recommendations\nfor implementing VR pedestrian simulators and propose directions for future\nresearch.",
        "updated": "2024-03-18 00:08:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11378v1"
    }
]