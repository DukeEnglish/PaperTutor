[
    {
        "title": "Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large Language Model",
        "authors": "Haoyun XuRunzhe ZhanDerek F. WongLidia S. Chao",
        "links": "http://arxiv.org/abs/2403.11621v1",
        "entry_id": "http://arxiv.org/abs/2403.11621v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11621v1",
        "summary": "Large Language Models (LLMs) are composed of neurons that exhibit various\nbehaviors and roles, which become increasingly diversified as models scale.\nRecent studies have revealed that not all neurons are active across different\ndatasets, and this sparsity correlates positively with the task-specific\nability, leading to advancements in model pruning and training efficiency.\nTraditional fine-tuning methods engage all parameters of LLMs, which is\ncomputationally expensive and may not be necessary. In contrast,\nParameter-Efficient Fine-Tuning (PEFT) approaches aim to minimize the number of\ntrainable parameters, yet they still operate at a relatively macro scale (e.g.,\nlayer-level). We introduce Neuron-Level Fine-Tuning (NeFT), a novel approach\nthat refines the granularity of parameter training down to the individual\nneuron, enabling more precise and computationally efficient model updates. The\nexperimental results show that NeFT not only exceeded the performance of\nfull-parameter fine-tuning and PEFT but also provided insights into the\nanalysis of neurons.",
        "updated": "2024-03-18 09:55:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11621v1"
    },
    {
        "title": "Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines",
        "authors": "Ekaterina TrofimovaEmil SataevAndrey E. Ustyuzhanin",
        "links": "http://arxiv.org/abs/2403.11585v1",
        "entry_id": "http://arxiv.org/abs/2403.11585v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11585v1",
        "summary": "In the ever-evolving landscape of machine learning, seamless translation of\nnatural language descriptions into executable code remains a formidable\nchallenge. This paper introduces Linguacodus, an innovative framework designed\nto tackle this challenge by deploying a dynamic pipeline that iteratively\ntransforms natural language task descriptions into code through high-level\ndata-shaping instructions. The core of Linguacodus is a fine-tuned large\nlanguage model (LLM), empowered to evaluate diverse solutions for various\nproblems and select the most fitting one for a given task. This paper details\nthe fine-tuning process, and sheds light on how natural language descriptions\ncan be translated into functional code. Linguacodus represents a substantial\nleap towards automated code generation, effectively bridging the gap between\ntask descriptions and executable code. It holds great promise for advancing\nmachine learning applications across diverse domains. Additionally, we propose\nan algorithm capable of transforming a natural description of an ML task into\ncode with minimal human interaction. In extensive experiments on a vast machine\nlearning code dataset originating from Kaggle, we showcase the effectiveness of\nLinguacodus. The investigations highlight its potential applications across\ndiverse domains, emphasizing its impact on applied machine learning in various\nscientific fields.",
        "updated": "2024-03-18 08:58:47 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11585v1"
    },
    {
        "title": "Reinforcement Learning with Token-level Feedback for Controllable Text Generation",
        "authors": "Wendi LiWei WeiKaihe XuWenfeng XieDangyang ChenYu Cheng",
        "links": "http://arxiv.org/abs/2403.11558v1",
        "entry_id": "http://arxiv.org/abs/2403.11558v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11558v1",
        "summary": "To meet the requirements of real-world applications, it is essential to\ncontrol generations of large language models (LLMs). Prior research has tried\nto introduce reinforcement learning (RL) into controllable text generation\nwhile most existing methods suffer from overfitting issues (finetuning-based\nmethods) or semantic collapse (post-processing methods). However, current RL\nmethods are generally guided by coarse-grained (sentence/paragraph-level)\nfeedback, which may lead to suboptimal performance owing to semantic twists or\nprogressions within sentences. To tackle that, we propose a novel reinforcement\nlearning algorithm named TOLE which formulates TOken-LEvel rewards for\ncontrollable text generation, and employs a \"first-quantize-then-noise\"\nparadigm to enhance the robustness of the RL algorithm.Furthermore, TOLE can be\nflexibly extended to multiple constraints with little computational expense.\nExperimental results show that our algorithm can achieve superior performance\non both single-attribute and multi-attribute control tasks. We have released\nour codes at https://github.com/WindyLee0822/CTG",
        "updated": "2024-03-18 08:18:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11558v1"
    },
    {
        "title": "DEE: Dual-stage Explainable Evaluation Method for Text Generation",
        "authors": "Shenyu ZhangYu LiRui WuXiutian HuangYongrui ChenWenhao XuGuilin Qi",
        "links": "http://arxiv.org/abs/2403.11509v1",
        "entry_id": "http://arxiv.org/abs/2403.11509v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11509v1",
        "summary": "Automatic methods for evaluating machine-generated texts hold significant\nimportance due to the expanding applications of generative systems.\nConventional methods tend to grapple with a lack of explainability, issuing a\nsolitary numerical score to signify the assessment outcome. Recent advancements\nhave sought to mitigate this limitation by incorporating large language models\n(LLMs) to offer more detailed error analyses, yet their applicability remains\nconstrained, particularly in industrial contexts where comprehensive error\ncoverage and swift detection are paramount. To alleviate these challenges, we\nintroduce DEE, a Dual-stage Explainable Evaluation method for estimating the\nquality of text generation. Built upon Llama 2, DEE follows a dual-stage\nprinciple guided by stage-specific instructions to perform efficient\nidentification of errors in generated texts in the initial stage and\nsubsequently delves into providing comprehensive diagnostic reports in the\nsecond stage. DEE is fine-tuned on our elaborately assembled dataset AntEval,\nwhich encompasses 15K examples from 4 real-world applications of Alipay that\nemploy generative systems. The dataset concerns newly emerged issues like\nhallucination and toxicity, thereby broadening the scope of DEE's evaluation\ncriteria. Experimental results affirm that DEE's superiority over existing\nevaluation methods, achieving significant improvements in both human\ncorrelation as well as efficiency.",
        "updated": "2024-03-18 06:30:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11509v1"
    },
    {
        "title": "Word Order's Impacts: Insights from Reordering and Generation Analysis",
        "authors": "Qinghua ZhaoJiaang LiLei LiZenghui ZhouJunfeng Liu",
        "links": "http://arxiv.org/abs/2403.11473v1",
        "entry_id": "http://arxiv.org/abs/2403.11473v1",
        "pdf_url": "http://arxiv.org/pdf/2403.11473v1",
        "summary": "Existing works have studied the impacts of the order of words within natural\ntext. They usually analyze it by destroying the original order of words to\ncreate a scrambled sequence, and then comparing the models' performance between\nthe original and scrambled sequences. The experimental results demonstrate\nmarginal drops. Considering this findings, different hypothesis about word\norder is proposed, including ``the order of words is redundant with lexical\nsemantics'', and ``models do not rely on word order''. In this paper, we\nrevisit the aforementioned hypotheses by adding a order reconstruction\nperspective, and selecting datasets of different spectrum. Specifically, we\nfirst select four different datasets, and then design order reconstruction and\ncontinuing generation tasks. Empirical findings support that ChatGPT relies on\nword order to infer, but cannot support or negate the redundancy relations\nbetween word order lexical semantics.",
        "updated": "2024-03-18 04:45:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2403.11473v1"
    }
]