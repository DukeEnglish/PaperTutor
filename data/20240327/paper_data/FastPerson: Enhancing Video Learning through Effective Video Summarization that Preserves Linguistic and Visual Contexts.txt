FastPerson: Enhancing Video-Based Learning through Video
Summarization that Preserves Linguistic and Visual Contexts
KazukiKawamura JunRekimoto
TheUniversityofTokyo,Tokyo TheUniversityofTokyo,Tokyo
SonyCSLKyoto,Kyoto SonyCSLKyoto,Kyoto
Japan Japan
kwmr@acm.org rekimoto@acm.org
ABSTRACT 1 INTRODUCTION
Quicklyunderstandinglengthylecturevideosisessentialforlearn- Theproliferationofvideo-sharingplatformshassignificantlyen-
erswithlimitedtimeandinterestinvarioustopicstoimprovetheir hancedtheuseofvideosacrossvariousfields,includingentertain-
learningefficiency.Tothisend,videosummarizationhasbeenac- ment(film),music,blogging,andnotably,education.Asanexample
tivelyresearchedtoenableuserstoviewonlyimportantscenes ofusingvideosineducation,flippedlearninginvertstheconven-
fromavideo.However,thesestudiesfocusoneitherthevisualor tionalclassroommodelbyencouragingstudentstoengagewith
audioinformationofavideoandextractimportantsegmentsinthe videolecturesandcontentbeforeclass.Thispreparatoryengage-
video.Therefore,thereisariskofmissingimportantinformation mentenablesin-classsessionstobededicatedtomoreinteractive
whenboththeteacher’sspeechandvisualinformationontheblack- discussions,problem-solvingactivities,andhands-onlearningexpe-
boardorslidesareimportant,suchasinalecturevideo.Totackle riences,enhancingtheeducationalprocess[5].Further,theriseof
thisissue,weproposeFastPerson,avideosummarizationapproach massiveopenonlinecourses(MOOCs)hasdemocratizedaccessto
thatconsidersboththevisualandauditoryinformationinlecture education,enablingaglobalaudiencetoparticipateinhigh-quality
videos.FastPersoncreatessummaryvideosbyutilizingaudiotran- learningexperiences.MOOCsofferanextensivearrayofvideo
scriptionsalongwithon-screenimagesandtext,minimizingthe lecturesandeducationalresources,enablinglearnersworldwideto
riskofoverlookingcrucialinformationforlearners.Further,itpro- accessandengagewithcoursematerialsattheirownpace[16,20].
videsafeaturethatallowslearnerstoswitchbetweenthesummary Manypreviousstudieshaveconfirmedtheeffectivenessofthese
andoriginalvideosforeachchapterofthevideo,enablingthem video-basedlearningmethods.Forexample,Zhangetal.showed
toadjustthepaceoflearningbasedontheirinterestsandlevelof thatinteractivevideosimprovelearners’comprehension[56].Fur-
understanding.Weconductedanevaluationwith40participants ther,Kayetal.underscoredtheefficacyofvideo-basedlearning
toassesstheeffectivenessofourmethodandconfirmedthatit (VBL),showingitspositiveimpactoncomprehension,adaptation,
reducedviewingtimeby53%atthesamelevelofcomprehension andachievement[24].Althoughtheresultsofthesestudiesillus-
asthatwhenusingtraditionalvideoplaybackmethods. tratethebenefitsofvideo-basedlearningmethods,challengessuch
asthetime-consumingsearchforappropriatevideosanddifficulty
CCSCONCEPTS inadjustingthelearningpacetoindividualcomprehensionand
• Human-centered computing → Interactive systems and interestscontinuetopersist.Infact,Chenetal.showedthatusers
tools;•Computingmethodologies→Videosummarization. spent80%oftheirtimeonvideo-sharingplatformsforbrowsing
andpartialviewing[9],whichsuggeststhatefficientlyfindingthe
KEYWORDS desired content from a large number of videos is a major chal-
lengefacedbycurrentvideo-sharingplatforms.Inaddition,online
Videosummarization,e-learning,human–computerinteraction,
learningplatformssuchasYouTube’seducationchannel,Coursera,
multimodalinformationprocessing,learningefficiency,user-centered
andEdXcontainvideosthatare30minto2hlong.However,un-
design,largelanguagemodel,speechsynthesis
likewrittencontent,videosmakeitdifficulttoobtainanoverview
ACMReferenceFormat: quicklybyskimmingoradjusttheamountofinformationviewed
KazukiKawamuraandJunRekimoto.2024.FastPerson:EnhancingVideo- foreachchapter.Thislimitationisabarriertolearnersusingvideos
BasedLearningthroughVideoSummarizationthatPreservesLinguistic
asalearningtool.
andVisualContexts.InTheAugmentedHumansInternationalConference
Toaddresstheseproblems,videosummarizationmethodshave
(AHs2024),April4–6,2024,Melbourne,VIC,Australia.ACM,NewYork,NY,
beenproposedforhelpingusersgraspthecontentofvideosina
USA,12pages.https://doi.org/10.1145/3652920.3652922
shortperiodoftime,andvariousmethodsforextractingkeyinfor-
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor mationhavebeenstudied[30,50].Theseexistingmethodsfocuson
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed visualoraudioinformationtodeterminetheimportantpartsofthe
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
videoandgenerateasummarizedvideobyjoiningtheimportant
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or parts.However,theseapproachesarelimitedinlecturevideos,be-
republish,topostonserversortoredistributetolists,requirespriorspecificpermission causeinnarratedvideos,interestingorusefulelementsarepresent
and/orafee.Requestpermissionsfrompermissions@acm.org.
onthescreenandintheaudio,andtheymaynotalwaysoverlap.
AHs2024,April4–6,2024,Melbourne,VIC,Australia
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. Forexample,inaneducationalvideowheretheinstructorpoints
ACMISBN979-8-4007-0980-7/24/04 toaspecificdiagramandprovidesanexplanation,theimportance
https://doi.org/10.1145/3652920.3652922
4202
raM
62
]VC.sc[
1v72771.3042:viXraAHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
Figure1:FastPerson:Videosummarizationmethodthatgeneratesasummarysentenceusingvisual(objectsandsentenceson
theframe)andaudioinformation(speaker’svoice)beforesynthesizingthesentenceintospeechusingthespeechcharacteristics
oftheoriginalspeaker.
oftheexplanationisconveyedbytheaudio,whilethediagram isrequired,thelearnercanwatchthefulloriginalvideoofthat
appearsinthevideo.Iftheviewerlistensonlytotheaudio,heor chapter.Indeed,itispossibletoonlywatchthesummaryvideoto
shemaymissthevisualexplanationandnotfullyunderstandthe obtainanoverviewofthevideo.Further,thetitle,summarytext,
importanceandcontentofthediagram. andthumbnailsofeachvideochapteraredisplayedinalist.The
Toovercometheselimitations,weproposeanewvideosum- learnercandirectlyselectandwatchonlychaptersthatinterest
marizationtechniquereferredtoasFastPerson,whichcomprehen- them.
sivelyconsidersbothvisualandaudioinformation.Incontrastto Weconductedanevaluationexperimentwith40participants
conventionalvideosummarization,whichextractsimportantparts toassessthelearningeffectivenessandusabilityoftheproposed
ofavideo,theproposedmethodcreatesasummarytextthatconsid- method.Afterwatchingtwolecturevideos,weadministeredaquiz
ersbothvisualandaudioinformationbeforegeneratingasummary onthevideosandconfirmedthatusingFastPersonreducedthe
videousingnarrationofthetext.Inaddition,thesummaryrateis viewing time for the two videos by 53.24% and 53.11% and the
adjustedtoreflecttheamountofvisualandaudioinformationin userscouldunderstandthevideosatthesamelevelasthatwhen
thesummaryvideotoavoidpresentingover-orunder-information theywatchedtheoriginalvideos.Inaddition,although78%ofthe
whilepreservingtheimportantcontentforthelearner.Thisresults usersratedtheabilitytoswitchbetweenthesummaryandoriginal
inmoredetailedsummariesforthecontent-richpartsofthevideo, videosasuseful,theresultssuggestthatseveralimprovementscan
suchaswhenthespeakerspeaksforalongtimeorwhenslides bemade,includingimprovementstothetransitionbetweenvideo
withalotoftextualinformationareshown.Thisreducestherisk chaptersandtheaudioqualityofthesummaryvideo.
oflearnersmissingimportantvisualoraudioinformation. Themaincontributionsofthecurrentpaperareasfollows:
Thepresentpaperalsofocusesonthedesignofinteractionmeth-
• Weproposeamethod,"FastPerson,"whichgeneratessum-
odstoprovideauser-centeredlearningexperience,addressingthe
maryvideosreflectingimportantinformationfromboththe
challengethatsummaryvideosdonotallowadjustingtheamount
visualandaudioelementsoflecturevideosbycomprehen-
ofinformationviewedonachapter-by-chapterbasistoenableusers
sivelyconsideringthem.
quicklygrasptheoutlineofthecontent.Toovercomethislimita-
• Wesuggestauser-centeredlearningexperiencedesignthat
tion,theproposedsystemprovidessummaryandoriginalvideos
enablesuserstoswitchbetweentheoriginalandsummary
foreachvideochapter,therebyallowingtheusertoswitchbetween
videos,allowingthemtochoosebetweenconciseandde-
thembypressingbuttons.Thisallowslearnerstochoosewhich
tailedinformationacquisitionineachchapterofthevideo.
videotowatchbasedonthecontent,interest,orcomprehension.
• Wedemonstratethatapplyingourproposedmethodtovideo-
Forexample,thesummaryvideoallowsthelearnertoobtainan
basedlearningcanenablelearnerstoefficientlyacquirein-
overviewofeachchapterquickly,andifmoredetailedinformation
formationfromlengthyvideocontent.FastPerson:EffectiveVideoSummarizationPreservingLinguisticandVisualContexts AHs2024,April4–6,2024,Melbourne,VIC,Australia
2 RELATEDWORK eachsegmentfaceofavideofromvideofeaturessuchasfaces,
objects,andaestheticfeatures[17].Recentmethodsincorporate
2.1 Video-BasedLearning
high-levelfeaturesextractedfromdeepneuralnetworkssuchas
Inthiscontemporarydigitalera,VBLhasbecomepivotalfored-
convolutionalneuralnetworks(CNN)[14,26]andrecurrentneu-
ucation.Thistransformationcanbeattributedtothewidespread
ralnetworks(RNN)[22]toimprovevideosummarizationperfor-
availabilityoftheinternetandtheproliferationofonlinelearning
mance[17,55,57,59].Attentionmechanism[60],graphconvolu-
platforms.MOOCs,exemplifiedbyplatformssuchasCourseraand
tionalnetwork[32],andTransformer[27]havealsocontributedto
EdX,haveplayedapivotalroleinsteeringthisshifttowardvideo-
improvingtheperformanceofvideosummarization.Othermeth-
centricpedagogy.Forexample,studiesbyKheetal.andGuoetal.
odsdetectvideosegmentsthathaveobjectsrelatedtothetitle[47].
demonstratedtheimportanceandexpandedtheuseofvideolec-
Althoughthesemethodsarepromisingforvideosurveillanceand
turesinMOOCs[16,20].Furthermore,videotutorialsfeaturedon
sportsvideohighlightgeneration,theirapplicationtovideosthat
platformssuchasKhanAcademyandUdemyareinstrumentalin
displayslidesorboardswithconsiderabletextualinformationon
democratizingskillacquisition,spanningadiversespectrumfrom
theframe,suchasonlinelecturesandhow-tovideos,whichare
codingtotheculinaryarts[8,49].Inprofessionalsettings,plat-
thetargetofthepresentstudy,isyettobeexplored.Further,there
formssuchasLinkedInLearninghaveharnessedthepowerofvideo
areseveralmethodstopredictimportantsegmentsofavideousing
contenttofacilitatecareerdevelopmentandtraining.Theseexam-
audiofeaturesinadditiontovisualfeatures,especiallyforcooking
plessuggestthatvideo-basedresourceshavebecomeomnipresent
andsportsvideos[44,58].However,itisverydifficulttoprepare
inmoderneducationandtrainingandarewidelyusedtoacquire
suchdataforlecturevideoscoveringawiderangeoffields,and
knowledgeandskills.Theinstructionalvideosofteninvolvean
therefore,weaimtoestablishatechniquethatcangeneratesum-
instructorspeakingandusingslidestoprovideexplanations.Al-
marizedvideosforlecturevideoswithoutsuperviseddatabyusing
thoughthereareasmallnumberofvideosthatconveyinformation
alargelanguagemodel(LLM).
andskillsinVBLwithoutrelyingonsound,suchassilentdemon-
Auditory-element-basedsummarizationmethodsconvert
strationvideos,wefocusonvideosthataremorecommonlyrich
the audio in a video into transcribed text and apply document
inaudioandvisualinformation.
summarizationtechniquestothistextforgeneratingasummary
Theefficacyofvideoasapedagogicaltoolhasbeenextensively
textofthevideo[11,41].Thesummarizationtechnique[31],which
researchedandvalidated[42].Zhangetal.foundthatinteractive
usestheSeq2seqmodel,isanexampleofsuchatechniqueandcan
videos,whichallowlearnerstoengagewithcontent,enhancecom-
generateasummarywhilemodifyingthecontentoftheoriginal
prehension[56].Kay’sresearchonvideopodcastsrevealedtheir
text.Inrecentyears,therehasbeenanincreaseinthenumberof
positiveinfluenceonstudents’understandingandachievement[24].
examplesthatuseLLMs,suchasChatGPT[28],togeneratevideo
Althoughtraditionalteacher-centeredteachingstylesoftenleave summarydocuments1.Thesemethodsconsidertheimportanceof
studentsreluctantandunabletofullydevelopcriticalthinkingskills,
linguisticinformationandcaneffectivelyunderstandthecontentof
instructionalvideoenableashifttolearner-centeredlearning[2].
audio-basedvideossuchaslecturesandpresentations.However,the
MasatsandDooly’sresearchshowedthattheuseofvideoforin-
informationprovidedbythesedocument-centeredsummarization
structionalpurposesintroducedinnovativeandcreativeteaching
methodsneglectstheimportanceofvisualelementsinvideos.In
perspectives[29].Furthermore,Brechtetal.claimedthatlearners
lecturevideos,visualinformationsuchasslidesandchartsplayan
whocouldnotfullyunderstandtheinstructionalcontentinlec-
importantroleinmanyscenarios,anditisdifficultforlearnersto
turesortextbookscouldlearnbyrepeatedlyviewingthelessonsas
understandthecontentofavideobyreadingonlythesummary
requiredtomeettheirindividuallearningneeds[6].However,it
textofthespeaker.Recognizingtheimportanceofthespeaker’s
remainsdifficulttocontrolwhichpartsofavideoareimportantto
speechinavideoandbelievingthatthevisualrepresentationofthe
viewfortheirneedssimplybyskippingoradjustingtheplayback
videoisalsoimportant,weaimtoestablishavideosummarization
speed.Oursystemaddressesthischallengebyprovidinganactive,
technologythatconsidersbothaudioandlanguageinformation
personalizedlearningexperience.
andproducesvideoratherthantextastheoutput.Thereareother
methodsthatfocusonthepitchratherthanthecontentandidentify
2.2 VideoSummarization high-pitchedpartsasimportantsegmentsofalecturevideo[19];
Videosummarizationinvolvescreatingshort-formcontentfrom however,theyprovidelessinformationthanthespeechcontent
anoriginallongervideosothatuserscanquicklygraspthemain andarelessrobusttogeneralnoise.Therefore,ourmethoduses
contentofinterest.Videosummarizationmethodscanbedivided thespeechcontentdirectlyforsummarization.
intothreecategories: Learner-preference-basedmethodsincludemanyproposed
video summarization methods that consider interaction history
• Methodsbasedonvisuallyimportantelements and user preference information [1, 12]. There are methods for
• Methodsbasedonaurallyimportantelements generating summaries based on user interaction data, such as
• Methodsbasedonelementsofimportancetothelearner Lecturescape[25],whichretrievesframesfrequentlyviewedby
other learners, and EpicPlay, which identifies key moments in
Visual-element-basedsummarizationmethodshavebeen
continuouslystudiedinthefieldofcomputervisiontoidentify
importantframesorsegmentsusingvisualinformation.Inearly
work,supervisedlearningmethodspredictedtheimportanceof 1https://glasp.co/youtube-summaryAHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
sportsvideosbyleveragingsocialmediaviewerinteractioninfor- 3.2 VisualandAudioInformationExtraction
mation[48].Videosummarizationbasedontheinterestlevelofindi- Ourmethodconvertsvisualandauditoryinformationintotextual
vidualusershasalsobeendeveloped.Forexample,Varinietal.pro- informationforgeneratingasummaryvideothatconsidersboth.
posedamethodforgeneratingpersonalizedtravelsummaryvideos Weuseopticalcharacterrecognition(OCR)andobjectdetection
byusersdirectlyprovidingtheirpreferredgenres[52].EgoScan- techniquestoobtainvisualinformation.OCRisusedfordigitiz-
ningallowsuserstoenterkeywordsrelatedtotheeventstheyare ingimageddocumentinformation,anditcandetectcharactersin
interestedintospeeduptheplaybackofthenon-corresponding imagesandvideosandconvertthemintodocuments[46].This
parts[21].Further,ElasticPlayhasafeaturethatallowsusersto technologycaneffectivelycapturedocumentinformationinvideo
interactivelyadjusttheoveralllengthofthesummaryvideo[23]. images,suchasthecontentofslidesorhandwrittennotesona
Ourmethoddoesnotdirectlyinputorestimateuserpreferences, whiteboardinalecturevideo.Thisinformationcanthenbeusedto
andinstead,itallowseachusertofreelyadjustthepaceofvideo reflectthetopicandcontentofthedocumentsinthevideointhe
viewingaccordingtotheirownpreferences. summary.Objectdetectionisatechniquefordetectingandidenti-
fyingspecificobjectsorentitiesineachframeofavideo[40].The
objectsinthevideoareoftencloselyrelatedtothestoryfocusor
3 FASTPERSON’SVIDEOSUMMARIZATION themeofthesegment.Ifacarisshownonaslideinascenefrom
METHOD anonlinelectureonmachinelearning,thespeakerisexpectedto
talkaboutautomateddrivingorimagerecognition,andtheobject
FastPersoncancreateasummarizedvideothatconsidersbothvisual
“car”isconsideredakeypointinthatvideosegment.Therefore,
(textandobjectsonthescreen)andaudioinformation(speaker’s
keyscenesandimportantentitiesinthevideocanbeidentified
voice). FastPerson automatically divides the original video into
usingobjectdetection,andeffectivesummariescanbegenerated
multiplecoherentvideosegments,providingtheuserwiththesum-
basedonthisinformation.OursystemusestheTesseractOCRen-
marizedvideoandoriginalvideoforeachsegment.Thequalityof
gine[46]forOCRandthefasterR-CNN[40]withResNet-50-FPN
thesummaryandoriginalvideosarematchedbycombiningthis
astheobjectmodelbackbone.
summarytextwithasynthesizedvoiceofthesamevoicequality
Theaccurateextractionofspeechinformationisnecessaryfor
asthespeakeroftheoriginalvideoandthecorrespondingvideo
academiccontentinvideos,especiallylecturesandseminars.Audio
oftheoriginalvideo,therebyprovidingtheuserwithaseamless
informationisextractedfromavideoasfollows:
transitionbetweenthesummaryandoriginalvideos.Inaddition,
whengeneratingthesummaryvideo,thesummaryratioisadjusted (1) Anaudiostreamisextractedfromthevideofile.
byreflectingtheamountofvisualandaudioinformationtoavoid (2) Thisaudiostreamisfedasaninputtoaspeechrecognition
over-orunder-informationwhilepreservingimportantcontentfor modeltoobtainatranscriptionofthedocument.
thelearner.Thismethodisexpectedtobeappliedtoawiderange Thespeechsignalneedstobeconvertedintodocumentdatawith
oflecturevideos,andtherefore,theuseofLLM-basedsummariza- high accuracy because the accuracy at this stage can affect the
tionisdesignedtoeliminatetheneedfortrainingwithsupervised qualityofthesummary.Recentadvancesinspeechrecognition
data.Wedescribethesummarizationmethodbyfocusingonthe havebeenattributedtomodelsbasedonRNN[15,18]andTrans-
FastPersonarchitecture,asshowninFig.1. former[53,54].Inourmethod,oneofthesemodels,namelyWhis-
per,isusedasthespeechrecognitionmodel[34].Whisperhasbeen
trainedonapproximately680,000hofmultilingualspeechcollected
3.1 VideoChapterSegmentation fromtheWeb,anditsrecognitionaccuracyhasbeenshowntobe
FastPersonfirstdetectsscenetransitionsandsilenceinavideo comparabletothatofhumans.Despitethehighperformanceof
anddividesthemintosegmentstosummarizethevideointocoher- thismethod,therecognitionrateisnotzero.Therefore,weuse
entchaptersandgenerateavideosummary.Forscenetransition OCRtorecognizethetextinthevideotocoverthemisrecognition
detection,weuseatechniqueproposedbyNisreenetal.[37]to inspeechandensurethatimportantwordsinthevideoarenot
analyzethevariationofthecolordistribution(histogram)between omitted.
consecutiveframesanddeterminetheboundariesofthesegments
3.3 SummaryAudioGeneration
basedonthemagnitudeofthevariation.AccordingtoTruonget
al.[50],distinctvariationsbetweenconsecutiveframesindicatea Videosummarizationusesdatalabeledwithimportantpointsin
changeinscene,andhistogramvariationsindicatechangesinthe avideo,alongwithsupervisedlearningmethodstodetectimpor-
moodorbackgroundofthevideo.Weuseanalgorithmthatdetects tantlocationsinthevideo.However,ourtargeteducationalvideos
periodswhenthesoundwaveformhasanamplitudebelowacertain coverawidevarietyofdomains,anditisdifficulttousetraining
thresholdassilencebecausevisualandaudiobreaksdonotalways datatoextractsuchimportantpoints.Recently,anumberofLLMs
coincide.ThismethodisbasedontheworkofScheireretal.,which havebeenproposedinthenaturallanguageprocessingdomain
enablesdetectingperiodsoflowamplitudeortheabsenceofcertain basedonTransformerarchitectures,includingBERT[13],T5[38],
frequencieswhileidentifyingsegmentsofsilenceorstillness[43]. andGPT[7,35,36].Thesemodelsaretrainedondocumentsand
Thesevisualscenetransitionsandperiodsofsilenceinaudioare dialoguesfromdifferentdomainsandhaveawiderangeofdomain
consideredtoseparateandsegmentthevideoatthecutpoint.This knowledge,henceenablingthemtoperformvariousnaturallan-
functionalityenablesautomaticchaptering(segmentation)without guageprocessing,includingsummarygeneration[4].Oursystem
theneedforthevideocreatortotageachcontiguoussegment. cansummarizelecturevideoswithouttheneedforteacherdataFastPerson:EffectiveVideoSummarizationPreservingLinguisticandVisualContexts AHs2024,April4–6,2024,Melbourne,VIC,Australia
usingthisLLM.Usually,whenasummaryisgeneratedfromspeech, Theweightcoefficients𝑤 𝑠 and𝑤 𝑖 areselectedbasedonexperimen-
atranscriptofthespeechisusedasinputtogeneratethesummary. taldataanduserpreferences.Thesecoefficientscanbevariedto
However, this method generates a summary based on both the adjusttheemphasisonvisualorauditoryinformation.Although
transcriptofthespeechandvisualmetadataobtainedthroughOCR thebalancecanbealteredaccordingtouserinterestandcomprehen-
andobjectrecognition,therebyreflectingthevisualinformationof sionlevelstoprovidepersonalizedsummaryvideos,inthepresent
thevideointhesummary.Thefollowinginstructionsareentered study,fixedvaluesof0.3and2.5aresetfor𝑤 𝑠 and𝑤 𝑖,respectively.
intoLLM[39]togenerateasummarythatincludesbothvisualand
audioinformation,andthen,adocumentsummaryisgeneratedfor
3.5 SummaryVideoGeneration
eachvideosegment.
Aconventionalaudiosummarizationmethodusedforaudiobooks
(cid:19) Instructions (cid:16) evaluatestheimportanceofeachaudiotranscriptiononasentence-
by-sentencebasisanddirectlyextractsandcombinesimportant
Using the provided transcription of spoken content, OCR- audiosegments.However,thismethodposesachallengetothecon-
derivedtextualdata,andobjectdetectioninformation,synthe- tinuityofaudioandvideowhenmergingtheextractedsegments.
sizeacomprehensivesummary.Thissummaryshouldhigh- Thismethodcannotproduceavideosummarythatreflectsthe
lightthekeythemesandactionsdepictedinthevideo.Focus visualrepresentationofthevideo.Therefore,thismethodusesa
ondistillingtheessenceofthevideobycombininginsights speechsynthesis[45,51]method,whichusesadocumentsummary
fromthetranscription(whichcapturesthespokenwords), withvisualandaudioinformationastheinputandspeechsynthe-
theOCRdata(whichprovidestextfoundwithinthevideo), sistechnologytogenerateitsreadingvoice.Afterthesynthesized
andobjectdetection(whichidentifiessignificantobjectsand speechisgenerated,theoptimalvideosegmentisselectedfrom
actions). theoriginalvideobasedonthelengthofthespeech.Thevideo
(cid:18) (cid:17)
segmentiscutfromthebeginning,middle,orendoftheoriginal
video,dependingonthelengthofthesummarizedvideo.Basedon
Alongwiththeseinstructions,thetranscribedtextofeachvideo theresultsofasimpleuserexperiment,thevideosegmentinthe
segment,OCR,andresultingvisualinformationfromobjectrecog- middleoftheoriginalvideoisusedasthedefaultjoiningmethod.
nitionareenteredintotheLLMasdocuments.Thismethodenables Acontinuousandconcisevideosummaryisachievedbycombin-
creatingasummarythatemphasizesnuancesnotincludedinthe ingthisselectedvideosegmentwiththesynthesizedaudio.This
speechcontent,speaker’smovements,visualobjects,anddocu- methodavoidsunnaturalconnectionscausedbycombiningdiffer-
mentswithinslidesandvisualpresentations. entpartsofthevideo.Inaddition,usersareexpectedtofrequently
switchbetweentheoriginalandsynthesizedvideoswhenusing
3.4 SummaryLengthCalculation thismethod,andtherefore,itisnecessarytoprovideaseamless
experience.Thus,weadoptamethodthatminimizesthechangein
Thelengthofthedocumentsummarymustappropriatelyreflect
theaudiobetweentheoriginalandsummarizedvideosusingthe
theamountofinformationintheoriginalvideowhensummarizing
speakeradaptationtechniquewhensynthesizingtheaudio[3].The
avideo.Inotherwords,ifthevideoislongorrichincontent,itis
featuresofthespeaker’svoiceintheoriginalvideoareextracted,
necessarytoprovidesufficientinformationinthesummary,andif
andasynthesizedvoiceisgeneratedthatreflectsthespeaker’svoice
theoriginalvideoisshort,thesummaryshouldbeshortenedby
quality.Thismethodreducesthemismatchofvoicefeatureswhen
thesameamounttoeliminateredundancy.Therefore,weadjustthe
switchingbetweentheoriginalandsynthesizedvideos,thereby
numberofcharactersintheoutputsummarybasedonthelength
enablingseamlessswitching.
ofthetranscribeddocument.Inaddition,thenumberofoutput
charactersaftersummarizationisadjustedbasedontheamountof
visualinformationbecauseourmethodgeneratesvideosummaries 4 FASTPERSONAPPLICATIONAND
basedonvisualinformationaswellasaudio.Forexample,ifthe INTERACTION
amountoftextonaslideislargeevenifthespeaker’sspeechis
4.1 Application
short,itmustbesummarizedtoaccuratelyreflecttheinformation
contentoftheslide.Fromthispointofview,theproposedsystem FastPersonenablesuserstoswitchbetweentheoriginallonger
calculatesthenumberofoutputcharacters𝑁 ofthesummaryusing videoandsummarizedvideoforeachsegmentwithineachvideo,
dependingontheirlevelofinterestandunderstanding.Inaddition,
𝑁 =max(50,𝑤
𝑠
∗𝐿
𝑡
+𝑤
𝑖
∗(𝐿
𝑜
+𝐿 𝑐)),
astaticcomponentplacedonthesideofthevideodisplaysathumb-
nailimageandsummarytextforeachvideosegment,enablingthe
where
usertoquicklyaccessthecorrespondingvideochapter.
• 𝑁 representsthefinaloutputwordcountofthesummary. TheentireuserinterfaceisshowninFig.2;○a VideoWindow
• 𝐿 𝑡 isshowninthelengthofthetranscribedtext. allowsuserstoviewvideosinthewindowineitherasummarized
• 𝐿 𝑜 representsthenumberofobjectsidentifiedonthescreen. ororiginalformat.Theplaybackspeedcanbeadjustedbasedon
• 𝐿 𝑐 representsthewordcountofOCR-processedvisualele- preference,enablingflexibleviewingofcontent.○b VideoTitleis
ments. placedatthetopofthevideowindowanddisplaysthetitleofthe
• 𝑤 𝑠 and𝑤 𝑖 representtheweightcoefficientstoadjustthe segmentthatiscurrentlyplaying.○c SummaryandOriginalbut-
importancebetweenaudioandvisualinformation. tonsallowstheusertoquicklyswitchbetweenthesummaryandAHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
Figure2:OverviewoftheFastPersonuserinterface.A.VideoWindowshowcasesthecurrentvideoplaybackandoffersuser-
controlledspeedadjustments.B.VideoTitleprovidessegment-specifictitles.C.SummaryandOriginalbuttonsallowseamless
togglingbetweenvideoversionsandfacilitatesegmentswitches.D.SearchContaineroffersatext-basedsearchmechanism.E.
SegmentsContainerdisplaysthethumbnailsofvideosegments,ensuringquicknavigation.
originalfullversionofthevideo.Inthiscase,makingthevoicequal- isusedtocontrolvideoplayback,implementthesearchfunction,
ityofthesummaryvideosimilartothatoftheoriginalvideoallows andrespondtouserinteractions.
theusertoeasilyperceivecontinuityandmaintaintheconsistency
ofthevideoexperience.Nexttothevideoisawindowdisplay- 4.2 UserInteraction
ingapairoftextsummariesandthumbnailimagesrepresenting FastPersonprovidesapersonalizedlearningexperiencebyallowing
thechaptersofthevideo.Thesewindowsareeffectiveinhelping userstoadjusttheamountoftimetheyspendwatchingavideo
usersquicklyaccessthesegmentofinterestinthevideo[10,33]. andwheretheyspendtime.Forexample,userscanquicklygrasp
○d SearchWindowprovidesadocumententryboxandasearch thegistofanentirevideobywatchingonlytheabridgedversion.
buttontosearchforspecifickeywordsinavideosegment.This Alternatively,userscanviewtheabridgedversionfortheparts
featureallowstheusertoseewheretheirtopicsofinterestare theyunderstandandtheoriginaldetailedvideoforthepartsthey
discussedinthevideo.○e SegmentWindowdisplaysthumbnails, donot.Thedesignofthislearningexperienceisinspiredbythe
titles,andsummarytextforeachvideosegment.Userscanquickly flexibilityoftheinformationacquisitionexperiencewhenreading
accesstheappropriatevideosegmentbyclickingontheappropriate abook.Anexampleofhowthesystemcanbeusedtoviewavideo
thumbnail. ispresentedbelow.
TheapplicationisbuiltusingFlask,alightweightPythonweb
(1) Skimming through the entire summary: By clicking
framework.TheFastPersonbackendmanagesthefilesforeach
theSummarybutton(C)andplayingthevideo,userscan
videosegmentanddeliversthemefficiently.Thebackendincludes
watchthesummarizedversionofthevideo.Thisissimilar
functionstoloadtheassociatedthumbnailandtextfilesbasedon
totheactionofquicklyskimmingthroughtheentiretext
thenameofaspecificsegmentinthevideo,enablingaquickdeliv-
content.
eryofthevideosegmentrequestedbytheuser.Onthefrontend,
(2) Skimmingoverpartsthatareinteresting:UsingtheSeg-
theuserinterfaceisbuiltusingHTML,CSS,andJavaScript.The
mentsContainer(E),userscanobtainabriefoverviewof
interfaceincludesavideoplayer,videotitledisplay,abuttonto
eachsegmentbasedontheassociatedthumbnailandtext.
togglebetweenthesummarizedandoriginalvideos,asearchfunc-
Clickingonanysegmentwillplayitsrespectivevideoaf-
tion,andthumbnailsandsummariesforeachsegment.JavaScript
terclickingtheSummarybutton(C),enablinguserstoFastPerson:EffectiveVideoSummarizationPreservingLinguisticandVisualContexts AHs2024,April4–6,2024,Melbourne,VIC,Australia
Table1:Detailsaboutthevideosusedintheevaluationexperiment
Video1 Video2
Title OriginofLife MarketRevolution
Thumbnail
Length 12:58 21:55
Question1 Whatmolecule,alsocalledthebiologicalblueprintforlife,do Theactivityshownintheimagecontributedmostdirectlyto
alllivingorganismspossess? whichofthefollowing?
Question2 AlllivingthingsonEarthshareimportantprocesses.What Whichofthefollowingdevelopmentsmostdirectlyrelatesto
arethosefourprocesses? theoveralltrendfrom1800to1840depictedonthegraph?
Question3 In1828,aGermanchemist,FriedrichWohler,provedthat Accordingtothepassage,whichofthefollowingbest
organiclifeiscomposedofthesamecomponentsasinorganic explainsthemostimportanteffectthattechnological
matter.Howdidhedothis? developmentshadontheAmericansociety?
Question4 Whatingredient(s)areconsiderednecessaryforthecreation Whichofthefollowinghadasignificantlong-termresultof
oflife? themajorpatterndepictedonthemap?
Question5 Whatqualityoflifeallowsforitsslowdiversification? None
samplecontentbeforedecidingtowatchthedetailedvideo. • Toevaluatetheeffectivenessofsummarizationusingthe
Ifthesummaryissufficientlyclear,userscanmovetothe FastPersonsystemanditsfeatureofswitchingbetweenthe
nextsegment,orifuserswantmoredetails,theycancheck summarizedandoriginalvideosinaidingunderstanding.
theoriginalvideoofthatsegmentforabetterunderstand- • ToassesstheusabilityandusersatisfactionoftheFastPerson
ingbyclickingtheOriginalbutton(C).Thisissimilarto interface.
thebehaviorofauserselectingasectionoftextthatthey
like,quicklyreadingthatsection,anddecidingwhetherthe
sectionreallyfitstheirinterests.
5.1 Participants
(3) Watchingonlythepartsofinterestrepeatedly:Users
canreplayanysegmentmultipletimesforathoroughunder- Participantsfromdiversebackgroundswererecruitedthroughthe
standing,whichmirrorstheexperienceofrereadingone’s crowdsourcingplatformProlific.Atotalof40participantspartic-
favoritesectionofabook. ipatedinthestudy,randomlyassignedtoaninterventiongroup
(4) Searchingforspecificcontent:TheSearchContainer thatusedFastPerson(19participants)orthecontrolgroupthat
(D)allowsuserstosearchforspecifictermsorkeywords usedagenericvideoplayer(21participants).Theparticipantswere
acrosssegments,providingdirectaccesstodesiredcontent, selectedbasedontheirfluencyinEnglishandcompletionofatleast
whichissimilartousinganindexinabook. secondaryeduction,becausethevideoswereinEnglishandthepar-
(5) Switchingbetweenthesummaryandthedetailedview: ticipantsneededtobeabletounderstandthecontentofthevideos.
Atanygivenpoint,userscantogglebetweenthesummarized The participants’ demographics (gender, age, educational back-
andoriginalvideosusingtheSummaryandOriginalbut- ground,etc.)werecollectedasadditionalinformationtoassessthe
tons(C),cateringtotheircomprehensionandinterestlevels. effectoftheexperiment.Theparticipantscomprised23malesand
Thisenablesabehaviorsimilartothatofauserreadingtext, 17females,withanaverageageof26.05years(𝜎 =7.05).Among
wherethepartsofthetextthattheuserfullyunderstandsor theparticipants,35,35,15,and15%hadahighschooldiplomaor
isinterestedinarereadquickly,whilethepartsthattheuser GED,universitybachelor’sdegree(BA/BSc/other),technicalschool
doesnotfullyunderstandorisinterestedinarereadslowly. orcommunitycollege,andgraduatedegree(MA/MSc/MPhil/etc.),
respectively.Apostexperimentquestionnairemeasuredthepartic-
ipants’priorknowledgeofthevideostheywatchedona5-point
5 EVALUATIONEXPERIMENTS
scale(1being“nopriorknowledge”and5being“extensiveknowl-
Aseriesofquantitativeandqualitativeevaluationexperimentswere edge”),andtheresultsshowedthat,forthefirstvideo,theinter-
conductedtoassessthelearningeffectivenessanduserexperience ventionandcontrolgroupshadmeansof2.63(𝜎 =1.16)and2.10
oftheFastPersonsystem,Thespecificobjectiveswereasfollows: (𝜎 =0.94),respectively.Forthesecondvideo,theinterventionand
controlgroupshadmeansof1.32(𝜎 = 0.58)and1.38(𝜎 = 0.59),
• TocomparethelearningeffectswhenusingtheFastPerson respectively.At-testbetweenthetwogroupsrevealedt-statistic
systemversusastandardvideoplaybackplayer. valuesof1.607withap-valueof0.116and-0.351withap-valueAHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
Figure3:CorrectAnswerRatesforEachQuestionoftheVideo
of0.727forthefirstandsecondvideos,withnostatisticallysig-
nificant difference between the two groups at the 0.05 level of
significance.Thus,therewasnocleardifferenceinpreconditioning
knowledgebetweenthetwogroups.Further,theparticipantswere
motivatedtoachievehighscoresbecauseitwasclearlystatedthat
theexperimentparticipantswiththehighestscoreswouldreceive
abonusreward.Alltheparticipantsintheexperimentunderstood
andagreedthattheprocesswasvoluntaryandthattheyhadthe
righttowithdrawatanytime.
5.2 Procedure
Inthisexperiment,participantsgatheredthroughcrowdsourcing
wererandomlyassignedtoaninterventiongroupusingFastPerson
andacontrolgroupthatusedageneralvideoplayer.Twovideos
wereselectedfromKhanAcademy,anonlinelearningservice,for
viewing,andtheaccompanyingquestionswereusedtomeasure Figure4:AverageVideoViewingTimebyViewingMethod
thelearningeffectofthevideos.Topreventtheparticipants’un-
derstandingofthevideosfromchangingdrasticallybasedontheir
prerequisiteknowledge,weselectedlecturevideoswithalevelof experimentwasconductedthroughProlific,withamedianworking
difficultythatcouldbeunderstoodbythevideoalone.Theselected timeof46minand26s,andeachparticipantwaspaid7£.
videoswerefromthefieldsofbiologyandhistory,asshownin
5.3 EvaluationofLearningEffectiveness
Table1.Thevideoswereaccompaniedbyanumberofquestionsto
judgetheparticipants’understandingofitscontent.Severalques- Weanalyzedthepercentageofcorrectanswerstoquestionsabout
tionsforthefirstvideocouldnotbeansweredcorrectlywithout thevideosandthetimetakentoviewthevideosafterwatching
lookingatmaterialsbesidesthevideo,andtherefore,fivequestions thesametwovideosforthecontrolandtheinterventiongroupsto
excludingtheseoneswereusedtochecktheparticipants’under- evaluatethelearningeffectiveness.TherightsideofFig.3shows
standing of the video. For the second video, the four questions graphscomparingtheaveragecorrectresponserateofusersto
includedinthevideowereusedtoassesscomprehension.Thefirst thequestionsinVideos1and2(“Q1”and“Q2,”respectively).For
videoisalecturevideoinwhichthefocusisonthespeakerand Video1,thecorrectanswerrateforthecontrolgroup(redbar)
thevisualelements,whileinthesecondvideo,thefocusisonthe was0.70(𝜎 =0.33)andthatofinterventiongroup(bluebar)was
board.Theparticipantsviewedthesevideosinthemannerassigned 0.71(𝜎 =0.42)whilethoseforVideo2are0.63(𝜎 =0.39)and0.67
totheirconfidence,andsubsequently,theywereaskedtoanswer (𝜎 =0.46),respectively.Therefore,thereisnocleardifferencein
similarquestions.FortheinterventiongroupthatusedFastPerson, thepercentageofcorrectanswersbetweenbothgroups.Infact,a
anadditionalquestionnaireaboutthesystemwascollected.The t-testbetweenthetwogroupsyieldst-statisticvaluesof0.170withFastPerson:EffectiveVideoSummarizationPreservingLinguisticandVisualContexts AHs2024,April4–6,2024,Melbourne,VIC,Australia
ap-valueof0.864and0.528withap-valueof0.598forthefirst Q7: Howwouldyourateyourlearningexperiencewithour
andsecondvideos,respectively,neitherofwhichisstatistically system compared to that with other methods? (Open-
significantwhenthesignificancelevelissetat0.05.Further,the endedResponse)
percentageofcorrectanswersforeachquestion(leftsideofFig.3) (3) UsefulnessofSummaryandOriginalVideos
showsthatthescoreforviewingonageneralvideoplayerwas Q8: Wasthesummarizedvideohelpfulinunderstandingthe
higherforquestion1ofvideo1(Q1-1),whilethescoreforview- information?(1:NotHelpfulAtAll-5:ExtremelyHelpful)
ingonFastPersonwashigherforquestion3ofvideo1(Q1-3)and Q9: WasthefeaturetoswitchbetweentheOriginalandSum-
question1ofvideo2(Q2-1).Q1-1is“Whatmolecule,alsocalled maryvideosuseful?(1:NotUsefulAtAll-5:Extremely
thebiologicalblueprintforlife,isfoundinalllivingorganisms?” Useful)
andthecorrectansweris“DNA,”whichispickedupasakeyword Q10: How did you perceive the quality of the summarized
intheFastPersonsummary,indicatingthatitisakeywordthat videos?(Open-endedResponse)
“alllivingorganismspossess.”However,thepercentageofcorrect (4) EvaluationofSpecificFeatures
answersislikelytohavedecreasedbecauseofalackofexplana- Q11: Wasitconvenienttoaccessspecificvideosegmentsusing
tionoftheterm“biologicalblueprintforlife.”Meanwhile,although thumbnailsandsummarytexts?(1:NotConvenientAt
Q1-3andQ2-1areadequatelycoveredinboththesimplevideo All-5:ExtremelyConvenient)
playbackandFastPerson,thetopicsoftheotherincorrectchoices Q12: Wasiteasytofindinformationinthevideosusingthe
inthequestionarerelativelyfewerinFastPerson.Therefore,users searchwindow?(1:VeryDifficult-5:VeryEasy)
whowatchedFastPersonarenotexpectedtoselecttheseincorrect
choices,resultinginahigherpercentageofcorrectanswers.The Thequestionsincludedbothnumericalandopen-endedquestions,
timetakentowatchthevideosissummarizedinFig.4,wherethe andtheresultsforthenumericalquestionsareshowninFig.5.For
averagetimetakenbyuserstowatchVideos1and2was1003 eachquestion,thepercentageofuserswhorespondedtoeachof
(𝜎 =312)and1352(𝜎 =270)s,respectively,usingtheregularvideo thefivelevelsispresentedasabargraph.
player.FastPerson,whichprovidessummaryvideos,tookusersan
averageof469(𝜎 = 424)and634(𝜎 = 496)stowatchVideos1 5.4.1 EvaluationofInterfaceUsability. Theaverageratingwas3.89
and2,respectively.UsingFastPersonreducedtheviewingtimesfor
(𝜎 =1.20)forthequestionaboutthesystem’seaseofuse,especially
Videos1and2by53.24and53.11%,respectively.At-testbetween intuitiveness(Q1).Thisindicatesthat,onaverage,theusersfound
thetwogroupsshowedthatthet-statisticvaluesforthefirstand theinterfaceintuitive.Forthequestionabouttheeaseoffindingin-
secondvideoswere4.409,withap-valueof1.063·10−3,and5.281, formationinthesystem(Q2),theaverageratingwas3.11(𝜎 =1.33).
withap-valueof9.955·10−6,respectively,bothofwhicharestatis- Thisratingreflectsthatusersfinditmoderatelyeasytofindthere-
ticallysignificantdifferencesat𝑝 <0.001.Therefore,learningwith quiredinformation.However,therelativelyhighstandarddeviation
FastPersonenablesustoreachalevelofunderstandingidenticalto highlightsthediversityinuserexperience,indicatingthatsome
thatoftheoriginalvideoinashortertimecomparedtothatwhen userswereabletonavigateandfindinformationmoreeasilythan
watchingtheoriginalvideo. theothers.Theopen-endedquestionsprovidedadditionalinsights.
Forexample,intermsoftheusabilityoftheSummaryandOrig-
inalbuttons,manyparticipantsstatesthattheywere“veryeasy
5.4 EvaluationofUserExperience touseandunderstand”andtheyappreciatedtheusefulnessand
Weconductedaquestionnairesurveyontheproposedmethodaf- convenienceofswitchingbetweenthedifferentvideomodes(Q3).
ter19participantsintheFastPersoninterventiongroupfinished However,oneusercommented,“Theinterfaceisallovertheplace,
learningfromthevideostoevaluatetheusability,learningeffec- andyouhavetospendalotoftimetounderstandit.”Thissuggests
tiveness,anduserexperienceofthesystem.Thesurveyincluded thatthereisroomforimprovementintheplacementofbuttons
thefollowingaspects: andcomponents.Suggestionsforinterfacedesignimprovementsre-
ceivedawiderangeofresponses(Q4).Althoughsomeparticipants
(1) InterfaceUsability feltthatthehumanizationofthesummarydescriptionsandvoice
Q1: Wasthesysteminterfaceintuitivetouse?(1:VeryDifficult readingneededfurtherimprovements,otherscalledforimprove-
-5:VeryIntuitive) mentstotheoverallvisualaspectofthesite.Generalsuggestions
Q2: Was it easy to find the required information? (1: Very includedimprovingthemonotonyofthedesignandincreasingthe
Difficult-5:VeryEasy) visibilityofthekeywordsearchfunction.Thesesuggestionsunder-
Q3: HowwasyourexperienceofusingtheSummaryandOrig- scoredthedesireforavisuallyappealingandfunctionallyrobust
inalbuttons?(Open-endedResponse) interface.Anothercommentwasthat“thevideosarefragmented,
Q4: Whatimprovementswouldyousuggestfortheuserinter- sousershavetowaitforeachparttofinishbeforetheycanmove
facedesign?(Open-endedResponse) ontoanotherpart.”Infact,theuserscouldmovefreelytoanother
(2) LearningExperienceSatisfaction partbyclickingonthethumbnailofthevideosegment;however,
Q5: Waslearningwithoursystemenjoyable?(1:NotEnjoyable thiswasnotclearlycommunicatedtotheuser,indicatingroomfor
AtAll-5:ExtremelyEnjoyable) improvement.
Q6: Comparedwithregularvideoplayers,howsatisfiedare
youwithlearningusingoursystem?(1:NotSatisfiedAt 5.4.2 EvaluationofLearningExperienceSatisfaction. Aquantita-
All-5:ExtremelySatisfied) tivemeasureoftheenjoymentoflearningwithFastPersonwasAHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
Figure5:SurveyResultsonUserExperience
obtainedwithameanratingof3.00(Q5).Althoughthisratingin- controloverthelearningprocess.Inthequalitativefeedback(Q10),
dicatesamoderatelevelofenjoymentamongusers,thestandard manyuserspraisedtheconceptofthesummaryvideos,notingthat
deviationof1.29suggeststhatthereisawiderangeofvariation theycouldhelpthemquicklyunderstandkeyconcepts,especially
intheparticipants’experiences.Next,wemeasuredlearningsatis- whenreviewingatopicorwhentimeislimited.However,they
factioncomparedtothatwiththeregularvideoplayerandfound raisedconcernsaboutthequalityofthecontentinthesummaries.
a slightly lower mean satisfaction of 2.95 (𝜎 = 1.43) (Q6). This Themainissueswererelatedtothedepthofcontentandthenar-
couldbeattributedtosomeusershavingapreferenceorcomfort rationofthesummaryvideo.Thesummarieswerefoundtobe
levelwithusingtraditionalvideoplayers.Higherstandarddevi- useful;however,theysometimeslackedsufficientdetailtofully
ationsindicatelargerdifferencesinusersatisfaction,suggesting understandcomplextopics.Inaddition,severaluserspointedout
thattheymaynotperfectlymatchthelearningpreferencesandex- thatthepronunciationofthewordsinthesummaryvideowas
pectationsofallusers.Inthequalitativefeedbackreceivedthrough different,confirmingthatthequalityofthesummaryvideocould
theopen-endedquestionQ7,userswhoratedtheirexperiencepos- beimprovedbyusingamorepowerfulspeechsynthesizer.
itivelyindicatedthatthefeaturesofFastPersonthatallowedthem
toquicklyobtaintheinformationtheyneededandtheinteractive
natureofthelearningexperiencecontributedtotheirenjoyment
andsatisfaction.Incontrast,userswhoratedtheirexperienceasun-
satisfactorycitedunfamiliaritywiththeinterfaceandapreference
5.4.4 EvaluationofSpecificFeatures. Theeaseofaccessingvideo
forthesimplerapproachoftraditionalvideoplayers,suggesting
segmentsusingthumbnailsandsummarytextreceivedanaverage
thatasimplerpresentationofthecomponentscouldcontributeto
ratingof3.53(𝜎 =1.50)(Q11).Similarly,theeaseofretrievinginfor-
usersatisfaction.
mationinthevideousingthesearchwindowreceivedanaverage
5.4.3 EvaluationoftheUsefulnessofSummaryVideos. Themean ratingof3.47(𝜎 =1.39)(Q12).Thesefeaturesarenotuniqueto
ratingfortheusefulnessofthesummaryvideosinunderstanding FastPerson;however,theyarecompatiblewiththeabilitytoswitch
theinformationwas3.42(𝜎 = 1.61)(Q8).Thisratingindicatesa betweenthesummaryandoriginalvideos.Themajorityofusers
moderatelypositiveacceptanceoftheeffectivenessofthesummary ratedboththethumbnailandsummarytextaswellastheability
videosinconveyinginformation.Similarly,theaverageratingfor toswitchbetweentheoriginalandsummarizedvideos(average
theabilitytoswitchbetweensummaryandoriginalvideoformats rating3.84)asuseful,whichindicatesthatpresentingtheuserwith
was3.84(𝜎 = 1.26)(Q9).Usersappreciatedtheabilitytoswitch boththesummaryvideoandsummarytext,ratherthanjustthe
betweenin-depthandsummaryvideoformats,givingthemmore summarytextofthevideo,improvesusabilityandconvenience.FastPerson:EffectiveVideoSummarizationPreservingLinguisticandVisualContexts AHs2024,April4–6,2024,Melbourne,VIC,Australia
6 DISCUSSION moreaccessiblebutalsomoreengagingforviewers,especiallyfor
visuallearners.
6.1 AdvantagesofFastPersoninEducational
ContentSummarization
6.4 BroaderImplicationsandApplicationsof
FastPersonhasshownsignificantadvantagesinlearningthrough
FastPerson
theuseofeducationalvideocontent.Itcanefficientlyreducevideo
viewingtimeby53%andachievethesamelevelofcomprehension ThebroaderimplicationsofFastPersongobeyonditsimmediate
aswiththeoriginalvideo.Interestingly,forquestionsrelatedto applicationineducationalvideosummarization.FastPersonhas
importantpartsofthevideo,FastPersonoccasionallyproducesa thepotentialtorevolutionizehowweinteractwithawiderange
higherpercentageofcorrectanswersthanthatwiththeoriginal ofvideocontent.Forexample,inprofessionalsettings,FastPer-
full-lengthvideo,suggestingthatitcaneffectivelyfocusonthe soncouldbeusedtodistilllongtrainingsessionsormeetingsinto
importantpartsofthecontent.Theabilitytoswitchbetweensum- concisesummaries,allowingforefficientreviewandbettertime
maryandoriginalvideoformatswasparticularlyappreciatedby management.Further,FastPersonhaspotentialapplicationsrelated
users,offeringflexibilityinlearningandcontentconsumptionthat tomediaconsumption,whereuserscanquicklyviewnewsoren-
isnotavailableintraditionalmethods.Thisfeatureallowslearners tertainmenthighlights.Inaddition,itsapplicationcouldextendto
toquicklygraspessentialconceptsthroughsummariesanddelve contentcreatorsandmarketers,givingthemavideoeditingtool
intodetailedexplanationsasneeded,therebycateringtodiverse tocreateengaging,summarizedversionsoftheircontentforbet-
learningpreferencesandneeds.Inaddition,FastPerson’suseof teraudienceengagement.FastPerson’sadaptabilitycouldenable
visualelementssynthesizedwithsummarizedaudioenhancesthe itsintegrationintovariousplatforms,makinginformationmore
educationalvalueofthecontent,makingcomplexinformationmore accessibleanddigestibleforabroaderaudience.
accessibleandengaging,especiallyforvisuallearners.
7 CONCLUSION
6.2 IdentifiedLimitationsandAreasfor Inthisstudy,weproposedanewvideosummarizationtechnol-
ogycalled"FastPerson"thatcomprehensivelyconsidersvisualand
Improvement
auditoryinformationinlecturevideostoimprovetheefficiency
FastPersonhassomelimitations.Forsomequestions,thepercentage
ofthelearningexperience.FastPersonproducesasummaryvideo
ofcorrectanswerswashigherwhentheoriginalvideowasviewed,
byconvertingvisualandauditoryelementsofavideointotext
suggestingthatinformationmaybemissedinthesummarizedvideo.
and generating a summary sentence that integrates them. This
Webelievethatthesystemcanbeimprovedbyencouragingusers
systemhelpslearnersunderstandimportantinformationquickly
toviewtheoriginalvideowheninformationismissing.Further,
andefficiently,especiallywhentheyhavelimitedstudytimeorare
usershavealsoindicatedthattransitionsbetweenvideosegments
interestedinmultipletopics.Theresultsoftheevaluationexperi-
arenotseamlessandthatthesoundqualityneedsimprovement.
mentsindicatednosignificantdifferenceinvideocomprehension
Weanticipatethattheseissuescouldbeaddressedbyimproving
whenusingFastPersonandtheconventionalvideoplaybackmeth-
theimplementationandreplacingitwithahigherqualityspeech
ods;however,theformersuccessfullyreducedviewingtimeby53%.
synthesismethod.Otherusersalsopointedouttheneedforamore
ThisresultsuggeststhatFastPersoncanprovideanefficientlearn-
intuitiveuserinterfacebecausetheyfounditdifficulttounderstand
ingexperience.Inaddition,theusabilityandinteractionfeedback
thefunctionalityofthevariousfeatures.Inaddition,weobserved
demonstratestheintuitivenessoftheinterfaceandusefulnessof
thatsomeusersprefertheoriginalsimplevideoplaybackplayer,
theabilitytoswitchbetweensummaryandoriginalvideos.The
andwebelievethatsimplifyingtheoverallstructureofFastPerson
resultsalsoshowroomforimprovementintermsofthedepthof
canhelpimproveuseraccessibility.
thesummarycontentandthequalityoftheaudio.
6.3 TechnologicalEnhancementsandFuture ACKNOWLEDGMENTS
Directions ThisworkwassupportedbyJSTMoonshotR&DGrantJPMJMS2012,
FastPerson extracts visual elements to be synthesized with the JSTCRESTGrantJPMJCR17A3,andthecommissionedresearchby
summarizedaudiofromtheoriginalvideo.Usingatext-to-video NICTJapanGrantJPJ012368C02901.
model,othermethodscanbeemployedtogenerateavideofromthe
summarizedtext;Runway’sGen-2andOpenAI’sSoraarepossible REFERENCES
candidatesforthesemethods.Thesemethodsfocusongenerating [1] LalithaAgnihotri,JohnKender,NevenkaDimitrova,andJohnZimmerman.2005.
object-centeredvideos,andtherefore,itcurrentlyrequiresmore Frameworkforpersonalizedmultimediasummarization.InProc.SIGMMinterna-
tionalworkshoponMultimediainformationretrieval.81–88.
worktocreatelecturevideosthataretext-heavyandslide-centered.
[2] GökçeAkçayırandMuratAkçayır.2018.Theflippedclassroom:Areviewofits
However,itmaybepossibletocreatehelpfulsummaryvideosfor advantagesandchallenges.Computers&Education126(2018),334–345.
generatinglecturevideosfocusedonsometopics.Forexample,ifa [3] SercanÖ.Arik,MikeChrzanowski,AdamCoates,GregoryDiamos,Andrew
Gibiansky,YongguoKang,XianLi,JohnMiller,AndrewNg,JonathanRaiman,
lectureiscenteredaroundtheintricaciesofplantbiology,atext-to- ShubhoSengupta,andMohammadShoeybi.2017.DeepVoice:Real-TimeNeural
videomodelcouldbeusedtogeneratevideosegmentsillustrating Text-to-Speech.InProc.ICML.195–204.
[4] LochanBasyalandMihirSanghvi.2023.TextSummarizationUsingLargeLan-
keyconceptssuchasphotosynthesis,cellularstructuresofplants,
guageModels:AComparativeStudyofMPT-7b-instruct,Falcon-7b-instruct,and
orgrowthcycles.Thisapproachwouldnotonlymakethecontent OpenAIChat-GPTModels.arXivpreprint(2023).AHs2024,April4–6,2024,Melbourne,VIC,Australia Kawamuraetal.
[5] VasilikiBetihavas,HeatherBridgman,RachelKornhaber,andMerylinCross.2016. [35] AlecRadford,KarthikNarasimhan,TimSalimans,IlyaSutskever,etal.2018.
Theevidencefor‘flippingout’:Asystematicreviewoftheflippedclassroomin Improvinglanguageunderstandingbygenerativepre-training.(2018).
nursingeducation.NurseEducationToday38(2016),15–21. [36] AlecRadford,JeffreyWu,RewonChild,DavidLuan,DarioAmodei,IlyaSutskever,
[6] HDavidBrechtandSuzanneMOgilby.2008.Enablingacomprehensiveteaching etal.2019.Languagemodelsareunsupervisedmultitasklearners.OpenAIblog
strategy:Videolectures.JournalofInformationTechnologyEducation.Innovations 1,8(2019),9.
inPractice7(2008),71. [37] NisreenI.Radwan,NancyM.Salem,andMohamedI.ElAdawy.2012.Histogram
[7] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan, CorrelationforVideoSceneChangeDetection.InProc.ICCSEA.765–773.
PrafullaDhariwal,ArvindNeelakantan,PranavShyam,GirishSastry,Amanda [38] ColinRaffel,NoamShazeer,AdamRoberts,KatherineLee,SharanNarang,
Askell,etal.2020. Languagemodelsarefew-shotlearners. Proc.NeurIPS33 MichaelMatena,YanqiZhou,WeiLi,andPeterJLiu.2020.Exploringthelimits
(2020),1877–1901. oftransferlearningwithaunifiedtext-to-texttransformer.J.MachineLearning
[8] IulianaCetina,DumitruGoldbach,andNataliaManea.2018.Udemy:acasestudy Research21,1(2020),5485–5551.
inonlineeducationandtraining.RevistaEconomică70,3(2018),46–54. [39] ParthaPratimRay.2023. ChatGPT:Acomprehensivereviewonbackground,
[9] LiangChen,YipengZhou,andDahMingChiu.2013.VideoBrowsing-AStudy applications,keychallenges,bias,ethics,limitationsandfuturescope.Internetof
ofUserBehaviorinOnlineVoDServices.InProc.ICCCN.1–7. ThingsandCyber-PhysicalSystems(2023).
[10] Pei-YuChi,SallyAhn,AmandaRen,MiraDontcheva,WilmotLi,andBjörn [40] ShaoqingRen,KaimingHe,RossGirshick,andJianSun.2015. FasterR-CNN:
Hartmann.2012. MixT:automaticgenerationofstep-by-stepmixedmedia TowardsReal-TimeObjectDetectionwithRegionProposalNetworks.InProc.
tutorials.InProc.UIST.93–102. NeurIPS,C.Cortes,N.Lawrence,D.Lee,M.Sugiyama,andR.Garnett(Eds.),
[11] SumitChopra,MichaelAuli,andAlexanderMRush.2016.Abstractivesentence Vol.28.
summarizationwithattentiverecurrentneuralnetworks.InProc.NAACL.93–98. [41] AlexanderMRush,SumitChopra,andJasonWeston.2015.Aneuralattention
[12] AnaGarciadelMolino,XavierBoix,Joo-HweeLim,andAh-HweeTan.2017. modelforabstractivesentencesummarization.arXivpreprint(2015).
Activevideosummarization:Customizedsummariesviaon-lineinteractionwith [42] MarijaSablić,AnaMirosavljević,andAlmaŠkugor.2021.Video-basedlearning
theuser.InProc.AAAI,Vol.31. (VBL)—past,presentandfuture:Anoverviewoftheresearchpublishedfrom
[13] JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018.Bert: 2008to2019.Technology,KnowledgeandLearning26,4(2021),1061–1077.
Pre-trainingofdeepbidirectionaltransformersforlanguageunderstanding.arXiv [43] E.ScheirerandM.Slaney.1997.Constructionandevaluationofarobustmulti-
preprint(2018). featurespeech/musicdiscriminator.InProc.ICASSP,Vol.2.1331–1334.
[14] KunihikoFukushima.1980. Neocognitron:Aself-organizingneuralnetwork [44] XindiShang,ZehuanYuan,AnranWang,andChanghuWang.2021.Multimodal
modelforamechanismofpatternrecognitionunaffectedbyshiftinposition. videosummarizationviatime-awaretransformers.InProc.MM.1756–1765.
Biologicalcybernetics36,4(1980),193–202. [45] JonathanShen,RuomingPang,RonJ.Weiss,MikeSchuster,NavdeepJaitly,
[15] AlexGraves,Abdel-rahmanMohamed,andGeoffreyHinton.2013. Speech ZonghengYang,ZhifengChen,YuZhang,YuxuanWang,RjSkerrv-Ryan,RifA.
recognitionwithdeeprecurrentneuralnetworks.InProc.ICASSP.6645–6649. Saurous,YannisAgiomvrgiannakis,andYonghuiWu.2018.NaturalTTSSynthe-
[16] PhilipJ.Guo,JuhoKim,andRobRubin.2014.HowVideoProductionAffectsStu- sisbyConditioningWavenetonMELSpectrogramPredictions.InProc.ICASSP.
dentEngagement:AnEmpiricalStudyofMOOCVideos.InProc.L@s.Association 4779–4783.
forComputingMachinery,41–50. [46] R.Smith.2007.AnOverviewoftheTesseractOCREngine.InProc.ICDAR,Vol.2.
[17] MichaelGygli,HelmutGrabner,HaykoRiemenschneider,andLucVanGool. 629–633.
2014.Creatingsummariesfromuservideos.InProc.ECCV.505–520. [47] YaleSong,JordiVallmitjana,AmandaStent,andAlejandroJaimes.2015.Tvsum:
[18] AwniHannun,CarlCase,JaredCasper,BryanCatanzaro,GregDiamos,Erich Summarizingwebvideosusingtitles.InProc.CVPR.5179–5187.
Elsen,RyanPrenger,SanjeevSatheesh,ShubhoSengupta,AdamCoates,etal. [48] AnthonyTangandSebastianBoring.2012. EpicPlay:Crowd-SourcingSports
2014. Deepspeech:Scalingupend-to-endspeechrecognition. arXivpreprint VideoHighlights.InProc.CHI.1569–1572.
(2014). [49] CliveThompson.2011.HowKhanAcademyischangingtherulesofeducation.
[19] LiweiHe,ElizabethSanocki,AnoopGupta,andJonathanGrudin.1999.Auto- WiredMagazine126(2011),1–5.
summarizationofaudio-videopresentations.InProc.MM.489–498. [50] BaTuTruongandSvethaVenkatesh.2007. VideoAbstraction:ASystematic
[20] KheFoonHewandWingSumCheung.2014.Students’andinstructors’useof ReviewandClassification.Trans.MultimediaComput.Commun.Appl.3,1(2007),
massiveopenonlinecourses(MOOCs):Motivationsandchallenges.Educational 3–es.
ResearchReview12(2014),45–58. [51] AaronvandenOord,SanderDieleman,HeigaZen,KarenSimonyan,Oriol
[21] KeitaHiguchi,RyoYonetani,andYoichiSato.2017.Egoscanning:Quicklyscan- Vinyals,AlexGraves,NalKalchbrenner,AndrewSenior,andKorayKavukcuoglu.
ningfirst-personvideoswithegocentricelastictimelines.InProc.CHI.6536–6546. 2016.WaveNet:AGenerativeModelforRawAudio.InProc.SSW.125.
[22] SeppHochreiterandJürgenSchmidhuber.1997.Longshort-termmemory.Neural [52] PatriziaVarini,GiuseppeSerra,andRitaCucchiara.2015. Egocentricvideo
computation9,8(1997),1735–1780. summarizationofculturaltourbasedonuserpreferences.InProc.MM.931–934.
[23] HaojianJin,YaleSong,andKojiYatani.2017. Elasticplay:Interactivevideo [53] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,
summarizationwithdynamictimebudgets.InProc.MM.1164–1172. AidanNGomez,ŁukaszKaiser,andIlliaPolosukhin.2017. AttentionisAll
[24] RobinH.Kay.2012.Review:ExploringtheUseofVideoPodcastsinEducation: youNeed.InProc.NeurIPS,Vol.30.
AComprehensiveReviewoftheLiterature.CHB28,3(May2012),820–831. [54] ChanghanWang,YunTang,XutaiMa,AnneWu,DmytroOkhonko,andJuan
[25] JuhoKim,PhilipJGuo,CarrieJCai,Shang-WenLi,KrzysztofZGajos,and Pino.2020. FairseqS2T:FastSpeech-to-TextModelingwithFairseq.InProc.
RobertCMiller.2014.Data-driveninteractiontechniquesforimprovingnaviga- AACL/IJCNLP.33–39.
tionofeducationalvideos.InProc.UIST.563–572. [55] TingYao,TaoMei,andYongRui.2016.Highlightdetectionwithpairwisedeep
[26] YannLeCun,BernhardBoser,JohnSDenker,DonnieHenderson,RichardE rankingforfirst-personvideosummarization.InProc.CVPR.982–990.
Howard,WayneHubbard,andLawrenceDJackel.1989.Backpropagationapplied [56] DongsongZhang,LinaZhou,RobertO.Briggs,andJayF.Nunamaker.2006.
tohandwrittenzipcoderecognition.Neuralcomputation1,4(1989),541–551. Instructionalvideoine-learning:Assessingtheimpactofinteractivevideoon
[27] Yen-TingLiu,Yu-JheLi,andYu-ChiangFrankWang.2020.Transformingmulti- learningeffectiveness.Information&Management43,1(2006),15–27.
conceptattentionintovideosummarization.InProc.ACCV. [57] KeZhang,Wei-LunChao,FeiSha,andKristenGrauman.2016.Videosumma-
[28] BradyDLundandTingWang.2023.ChattingaboutChatGPT:howmayAIand rizationwithlongshort-termmemory.InProc.ECCV.766–782.
GPTimpactacademiaandlibraries?LibraryHiTechNews40,3(2023),26–29. [58] BinZhao,MaoguoGong,andXuelongLi.2021.Audiovisualvideosummarization.
[29] DolorsMasatsandMelindaDooly.2011.Rethinkingtheuseofvideointeacher IEEETransactionsonNeuralNetworksandLearningSystems(2021).
education:Aholisticapproach. TeachingandTeacherEducation27,7(2011), [59] BinZhao,XuelongLi,andXiaoqiangLu.2017. Hierarchicalrecurrentneural
1151–1162. networkforvideosummarization.InProc.MM.863–871.
[30] ArthurG.MoneyandHarryAgius.2008.Videosummarisation:Aconceptual [60] KaiyangZhou,YuQiao,andTaoXiang.2018.Deepreinforcementlearningfor
frameworkandsurveyofthestateoftheart.J.VisualCommunicationandImage unsupervisedvideosummarizationwithdiversity-representativenessreward.In
Representation19,2(2008),121–143. Proc.AAAI,Vol.32.
[31] ShrutiPalaskar,JindrichLibovicky`,SpandanaGella,andFlorianMetze.2019.
Multimodalabstractivesummarizationforhow2videos.arXivpreprint(2019).
[32] JunginPark,JiyoungLee,Ig-JaeKim,andKwanghoonSohn.2020.Sumgraph:
Videosummarizationviarecursivegraphmodeling.InProc.ECCV.647–663.
[33] AmyPavel,ColoradoReed,BjörnHartmann,andManeeshAgrawala.2014.Video
digests:abrowsable,skimmableformatforinformationallecturevideos..InProc.
UIST,Vol.10.2642918–2647400.
[34] AlecRadford,JongWookKim,TaoXu,GregBrockman,ChristineMcLeavey,and
IlyaSutskever.2023.Robustspeechrecognitionvialarge-scaleweaksupervision.
InProc.ICML.28492–28518.