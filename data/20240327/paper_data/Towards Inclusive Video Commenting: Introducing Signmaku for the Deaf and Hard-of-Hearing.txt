Towards Inclusive Video Commenting: Introducing Signmaku for
the Deaf and Hard-of-Hearing
SiChen HaocongCheng JasonSitu
sic3@illiois.edu haocong2@illinois.edu junsitu2@illinois.edu
SchoolofInformationSciences, SchoolofInformationSciences, ComputerScience,Universityof
UniversityofIllinois UniversityofIllinois IllinoisUrbana-Champaign
Urbana-Champaign Urbana-Champaign Urbana,Illinois,USA
Champaign,Illinois,USA Champaign,Illinois,USA
DesiréeKirst SuzySu SaumyaMalhotra
deskirst@gmail.com xiaoyus4@illinois.edu saumyam2@illinois.edu
GallaudetUniversity SchoolofInformationSciences, CollegeofLiberalArts&Sciences,
Washington,DistrictofColumbia UniversityofIllinois UniversityofIllinois
USA Urbana-Champaign Urbana-Champaign
Champaign,Illinois,USA Urbana,Illinois,USA
LawrenceAngrave QiWang YunHuang
angrave@illinois.edu qi.wang@gallaudet.edu yunhuang@illinois.edu
ComputerScience,Universityof GallaudetUniversity SchoolofInformationSciences,
IllinoisUrbana-Champaign Washington,DistrictofColumbia UniversityofIllinois
Urbana,Illinois,USA USA Urbana-Champaign
Champaign,Illinois,USA
ABSTRACT CCSCONCEPTS
Previousresearchunderscoredthepotentialofdanmaku–atext- •Human-centeredcomputing→Empiricalstudiesinaccessi-
basedcommentingfeatureonvideos–inengaginghearingaudi- bility;Web-basedinteraction;•Socialandprofessionaltopics
ences.Yet,formanyDeafandhard-of-hearing(DHH)individuals, →Peoplewithdisabilities;•Appliedcomputing→Interac-
AmericanSignLanguage(ASL)takesprecedenceoverEnglish.To tivelearningenvironments.
improveinclusivity,weintroduce“Signmaku,”anewcommenting
mechanismthatusesASL,servingasasignlanguagecounterpart KEYWORDS
todanmaku.Throughaneed-findingstudy(N=12)andawithin- DHH,SocialInteractions,Danmaku,Signmaku
subjectexperiment(N=20),weevaluatedthreedesignstyles:real
humanfaces,cartoon-likefigures,androboticrepresentations.The ACMReferenceFormat:
SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMal-
resultsshowedthatcartoon-likesignmakunotonlyentertained
hotra,LawrenceAngrave,QiWang,andYunHuang.2024.TowardsInclu-
but also encouraged participants to create and share ASL com-
siveVideoCommenting:IntroducingSignmakufortheDeafandHard-of-
ments,withfewerprivacyconcernscomparedtotheotherdesigns.
Hearing.InProceedingsoftheCHIConferenceonHumanFactorsinComputing
Conversely,theroboticrepresentationsfacedchallengesinaccu- Systems(CHI’24),May11–16,2024,Honolulu,HI,USA.ACM,NewYork,NY,
ratelydepictinghandmovementsandfacialexpressions,resulting USA,18pages.https://doi.org/10.1145/3613904.3642287
inhighercognitivedemandsonusers.Signmakufeaturingreal
humanfaceselicitedthelowestcognitiveloadandwasthemost 1 INTRODUCTION
comprehensibleamongallthreetypes.Ourfindingsofferednovel
“Danmaku”isavideo-commentingfeaturewhereusersoverlay
designimplicationsforleveraginggenerativeAItocreatesignmaku
their text comments directly onto videos; its effect on learning
comments,enrichingco-learningexperiencesforDHHindividuals.
liesinfosteringamoreinteractiveandengaginglearningenvi-
ronmentbyallowinglearnerstoviewcommentsfromtheirpeers,
encouragingactiveparticipationandsocialconnectionduringthe
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor video-basedlearningprocess[73].However,textislessaccessible
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation forDeafandhard-of-hearing(DHH)users,asmanyofthemprefer
onthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe signedlanguageovertext,inourcontextAmericanSignLanguage
author(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or
(ASL)overEnglish[45].Morethan500,000peopleintheUnited
republish,topostonserversortoredistributetolists,requirespriorspecificpermission
and/orafee.Requestpermissionsfrompermissions@acm.org. StatesuseAmericanSignLanguage(ASL)astheirprimarymode
CHI’24,May11–16,2024,Honolulu,HI,USA ofcommunication[49].
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM. Existingresearchfocusesonimprovingtheaccessibilityofvideo-
ACMISBN979-8-4007-0330-0/24/05...$15.00
https://doi.org/10.1145/3613904.3642287 basedlearningforDHHpopulationsviageneratingclosedcaptions,
4202
raM
62
]CH.sc[
1v70871.3042:viXraCHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
andtextversionsoftheaudiocontent.Despiteaccountingforread- emotionsofDHHuserswithsignlanguage,whichisoftenover-
ingproficiency,thedifferencesinbackgroundknowledgeandin- lookedbygenerativeAItechnologies.Ourstudyprimarilyfocuses
formationprocessingstrategiesmaketext-basedinformationless oninteractiondesignandunderstandinguserbehavioranddoes
accessibleforDHHthanhearing[46].Ontheotherhand,signlan- notcontributetotechnicaladvancements.
guageisaformofvisualcommunicationthatemploysgestures,
facialexpressions,andbodylanguage.Itisafirst-classlanguage
withthesamelevelofcomplexityasspokenEnglish,butitusesa 2 RELATEDWORK
differentsentencestructure[57].LittleisknownabouthowDHH
2.1 ChallengesFacedbyDHHStudentsin
usersperceiveandsharecommentsinASL.
Thus,inthispaper,weintroduceanewASL-basedcommenting Video-basedLearning
featurecalledSignmaku,whichislikeasignlanguageversionof Video-based Learning is a remote learning approach that relies
danmaku.Unliketext-basedcomments,signmakuoffersASL-based onliveorprerecordedvideototeachnewskillsandknowledge.
commentsthatcontainvisualinformationwithfacialexpressions Manyvideo-basedlearningplatformshaveattractedhundredsof
andhandmovements,asshowninFig.1.Theuniquechallengeof thousandsofstudents,suchasMOOC,andYouTube.Theyallow
signlanguage,comparedtotext,isitsheightenedprivacyconcerns peoplefromaroundtheglobetoparticipateincoursesviavideos.
ofrevealingindividuals’faces.Therefore,wedesignedthreevisual ForDHH,video-basedlearningisnotyetfullyaccessible.Themajor
stylesbyapplyingdifferentgenerativeAItechniques:1)Realistic reasonisbecauseofonlinevideosingenerallackgood-qualitycap-
(unfilteredororiginalASLrecordingwithusers’realfaces);2)Car- tions,ifany.SomeresearchshowsDHHpeopleusedfilteringtools
toon(filteredfaceswithrealtorsoandhandsusingVToonify[79]); tofindvideoswithcaptionsforthemtowatch[40].Evenwhen
and3)Robotic(filteredfaces,torsos,andhandsusingDeepMotion1) captionsexist,manyareerroneousastheyareauto-generatedfrom
thataddressdifferentlevelsofprivacyconcerns.Weaimtoexplore automaticspeechrecognitionalgorithms[13].Itisnotunusualfor
howitcanimprovetheinclusivityofvideo-basedlearningforDHH. thesealgorithmstomisssomewordsduetonoiseandtorecog-
Whileourcurrentsignmakudesigncouldnotfullyreplicatethe nizetheincorrectwordwhengeneratingcaptions[12,35].Human
experiencewithtext-baseddanmaku,weexpectsignmakutoen- effortsareneededtocorrectthoseerrorshowevervideocontent
richthelearningexperienceofDHHstudentsbyallowingthemto creatorswerefrequentlyunwillingorunabletodoso[40,47].Be-
makeandviewcommentsforandfromtheirpeersinsignlanguage, yondthecaption’saccuracy,captions’appearanceisalsoimportant
fosteringapseudo-synchronousco-learningenvironment. tounderstanding[11].Low-qualitycaptionsforonlinelearning
InordertodesignandexploretheeffectofsignmakuonDHH’s videoscreatedgreatchallengesforDHHlearnerstounderstand
video-basedlearning,wecompletedatwo-phasestudy.InPhase thelearningcontentwhenstudyingremotelyfromschoolthrough
I,weconductedaneed-findingstudywith12DHHparticipants, videolecturesduringtheCOVID-19period,andaggravatedmental
whichallowedustoidentifyseveralkeyrequirementsofthesign- healthissues[5].Furthermore,theUnitedNationsacknowledged
makufeatureandcollecthigh-qualitysignmakucommentsthat thatCOVID-19exacerbatesinequalitiesbetweenpeoplewithand
wereusedinthenextphase.InPhaseII,wegenerateddifferently withoutdisabilities,includingaccesstoeducationandinclusionin
styledsignmakusanddesignedawithin-subjectexperimentwith thecommunity[51].
20DHHparticipants,duringwhichtheyviewedcontentwiththe Social interaction encouraged within a video-based learning
collected signmakus while watching a video. Participants were platformcanhelpstudentsstayengagedandenhancetheirown
alsoaskedtocreateandsharetheirownSignmakucommentsand learning[19,60,78].Socialengagementwithpeersisparamount
choosetheirpreferredstyleforsharing.Thedesignaimforthetwo foralllearners,butitholdsevengreatersignificanceforDHHstu-
filteredstylesistoprovideoptionsforlearnerstoremainanony- dents.Thisimportanceismagnifiedbythefactthataconsiderable
mousiftheysochoose,andtherebyelicitingtheirwillingnessto numberofDHHindividualshaveexperiencedorperceivedexclu-
makeandsharetheirownASLcomments.Theexperimentalstudy sionwithinmainstreameducation(Mainstreamisthepracticeof
addresses: placingstudentswithspecialeducationneedsinageneraledu-
• RQ1:HowdoesviewingthreestylesofsignmakuimpactDHH cationclassroom.)Researchindicatesthatdeafchildrencanhave
socialdifficultiescomparedwiththeirhearingpeers[23,66].The
learners’video-basedlearning?
• RQ2:HowdoDHHlearnersperceivethecreationandsharing video-basedlearningexperienceduringtheCOVID-19pandemic
hasworsenedsocialexclusionamongdeafstudents,especiallywith
ofthethreestyledsignmaku?
thedisruptionofdailyinteractionswithotherpeopleandinade-
Ourresearchmakessignificantcontributions:1)weproposea
quatesignlanguageinterpreters[5,69].Researchsuggestedparents
novelinteractiondesign,Signmaku,whichnotonlyimprovesthe
ofDHHlookforsuitableonlineeducationalprograms,andoppor-
inclusivityofvideo-basedlearningforDHHbutalsoenhancestheir
tunitiesfortheirchildrentosocializewiththeirDHHpeers[36].
senseofsocialconnectedness;2)weprovideempiricalevidence
Givencurrenttechnologicaladvancements,thereisagreatpoten-
oftheeffectivenessofcartoon-styledsignmakuonlearners’im-
tialtoconducttechnologyresearch,targetinginclusionandproper
provedengagementandtheirreducedeffortsofsharingcomments
educationforDHHstudentsbyenablingpositivesocialinteractions
withtheirpeers,withfewerprivacyconcernsthantheothertwo
andcollaborationwiththeirpeers[9].
signmakustyles;and3)wereinforcetheimportanceofreproduc-
Socialmediafeatureshaveproventofacilitateinteractionnot
ingmovementsofcertainfacialareasfordeliveringmeaningand
justamonghearinglearners[19,62],butforthosewhoareDHH.
1https://www.deepmotion.com A survey on predominant social media usage patterns of DHHSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
Figure1:ThreeStylesofSignmakudesignsexploredinownstudy:realistic(unfiltered),cartoon(filteredfacewithrealtorso
andhands),androbotic(filteredface,torso,andhands)leveragesAItechnologytofiltersignedvideoclips,consideringdifferent
stylesofprivacypreservation.Cartoonfilter’sbackgroundwasselectedtocontrastanindividual’sskincolorformorevisible
handmovementsusingVToonify[79].Roboticfilter’sappearancewascustomizedbytheDHHindividualinDeepMotion.
teenagersinSaudiArabiarevealedthatamajorityengagedwithso- Researchononlinelearningusingdanmaku,foundthatwatch-
cialmediadaily[50].Additionally,anothersurveyhighlightedhow ingvideoswithdanmakuandprovidingdanmakuisawayformany
socialmediaempowersDHHstudentstofosterconnectionsandcol- userstoentertainthemselvesandincreasetheirsenseofbelonging
laborationsoninformationdiscovery,contentcreation,andsharing amongotheraudiences[21,43,44,77].Danmakuallowsstudents
[4].Thepositiveimpactofsocialmediaonacademicperformance tocollaboratewiththeirtutorsandpeerstocreatelearningcontent
wasfurtheremphasizedbystudents,whoreportedheightenedin- byaddingcommentsthathelpexplainlearningmaterials[77].For
teraction,support,andfeedback[70].Notably,researchersfound teachers,danmakucanbridgethegapbetweenteachersandstu-
thatindividualswithintheDHHcommunitypredominantlyengage dents,andreducelearners’feelingsofloneliness[41].Conversely,
insharingcontentthroughwrittenEnglish,despiteapreferencefor someresearchpointedoutthatdanmakuisdistractingduetoits
signlanguage.Thisinclinationcanbeattributedtochallengessuch richabundanceofinformationcontentandunevencontentqual-
asdifficultiesincaptioningsignedvideosandobstaclesrelatedto ity[21].Furthermore,usingdanmakuaslearner-sourcedmaterial
recording,suchasdevicelimitations,lighting,storagespace,etc. raisesthepossibilitythatthecontentcreatedwillbeineffective,
[17,45].Insummary,thesesocialmediafeaturesarebeneficialfor inappropriate,orincorrect[1].
socialinteractionbuthavelimitationsduetothelackofsupport Meanwhile,researchinvestigatingtheuseofdanmakuinvideo
forthenativelanguageoftheDHHcommunity-signlanguage.In learningwithDHHstudentsremainssparse,particularlyduetothe
ourresearch,weprovidesocialinteractionsforDHHlearnersby factthatthecurrentdanmakuistext-basedwhichisnotfullyacces-
supportingtheuseofsignlanguage. sibletoDHHpeopleastheirnativelanguagesaresignandgesture-
basedlanguages.Despiteaccountingforreadingproficiency,the
differencesinbackgroundknowledgeandinformationprocessing
2.2 DanmakuforSocialInteractionand
strategiesmaketext-basedinformationlessaccessibleforDHHthan
KnowledgeSharinginVideo-basedLearning hearingpeople[46].Ourstudyaddressesthisgapbyaccommodat-
Danmakuisacommentarydesignforonlinevideosthatoriginated ingsignlanguagepreferencesinredesigningtext-baseddanmaku
inJapanandisnowpopularonAsianvideowebsites,e.g.,Bili- intosignmaku(signlanguagedanmaku).Thoughsignmakuisa
bili.com[73,74,80].Incontrasttotraditionalvideoforums,where new concept, a few known or generally accepted facts support
commentsareasynchronouslydisplayedbelowthevideo,danmaku thepossibilitiesforDHHtobenefitfromsynchronousASLvideos
commentsoverlaythevideoscreen.Thesecommentsalignwith alongwiththeoriginalvideocontent.Firstly,manyTVshowshave
specificsceneschosenbyonlineusersandscrollfromrighttoleft asignlanguageinterpreternexttothevideocontentandsome
acrossthevideoscreen.Userscananonymouslysendandview videoserviceshaveaclosedASLinterpreting[34,37].Secondly,
danmakucommentsinasynchronouswaywhilewatchingvideos. instructorsbelieveDHHstudentshaverelativelybettervisualskills
Wuetal.compareddanmakucommentswithtraditionalvideofo- thanhearing[58]andDHHstudentsfrequentlyswitchtheirvisual
rumsandfoundthedanmakudesignsignificantlypromoteduser attentionbetweentheboard,slides,instructors,andinterpreters
participationandsocialinteractions[73].Theworkalsofounddan- [58].
makuandforumcomplementeachotherintherealmofknowledge
sharing.Danmakucommentsprimarilyfacilitateexplicit(know-
2.3 AnonymizationofSignLanguageVideosfor
what)knowledgesharing,whileforumcommentstendtoshowcase
moretacit(know-how)knowledgesharing.Heetal.foundthat PrivacyConcerns
viewersweremoreemotionalandexpressiveindanmakucomments Theabilitytocommunicateanonymouslyusingone’spreferred
[33]. languageholdsvitalimportanceacrossdiversesocial,professional,CHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
and societal settings. As outlined earlier, anonymous comment PositionalityofResearchTeamTheresearchteamconsistedof
sharing is a crucial aspect of danmaku interaction and we, too, members with diverse backgrounds, including hearing, hard of
wouldneedtoprovideanonymizationfeaturesinsignmakuinour hearing, and Deaf individuals: one Deaf research assistant, one
study.Whileachievinganonymouswrittencommunicationonline hearingresearchassistantwhoisaPh.D.studentinlinguistics,and
isrelativelyuncomplicatedforusersofwrittenlanguages,suchop- anASLinterpreter.Allstudysessionsweresupervisedbyahearing
tionshavenotbeenreadilyavailabletousersofsignlanguages.For professorwith30yearsofexperienceinteachingDHHstudents
video-basedcommunication,individualswhousespokenlanguages atthecollegiatelevel.Thedataanalysisprimarilyinvolvedfour
canconcealtheirfacesononlinevideo-sharingplatformshowever hearingcoauthorswhohadpriorexperienceinbothquantitative
sign-languageuserscannotduetothecruciallinguisticinformation andqualitativeanalysis.TheyregularlyhelddiscussionswithDeaf
conveyedthroughfacialexpressions[8,15,25,39].Respondents researchassistantsandthehearingprofessortorefinethecodebook
expressedwillingnesstoviewvideoscreatedbyindividualswith andensurecomprehensiveanalysis.
theirfacesdisguisedaslongastherewasanethicalpurpose[39].
Signlanguageisaformofvisualcommunicationthatemploys 3.1 PhaseI:DesigningSignmaku–Video
gestures,facialexpressions,andbodylanguage.Itisacompletefirst- CommentsinSignLanguage
classlanguagewiththesamelevelofcomplexityasspokenEnglish,
Todelveintothedesignofvideo-basedlearningexperiencewith
butitdoesnotusethesamesentencestructure[57].Anonymizing
signmaku,weconductedauniversityInstitutionalReviewBoard
signlanguagevideosposeschallengesasit’snotfeasibletodirectly
(IRB)-approvedpilotstudywith12DHHstudents(8males,4fe-
covertheirface.Recenteffortshaveemergedtoassistsignlanguage
males),including8d/Deafstudentsand4hard-of-hearingstudents,
usersinautomaticallyconcealingtheirfacesinvideoswhileretain-
allfromaUShighereducationschoolforDHHstudents.Through-
ingvitalfacialexpressions;however,thistaskremainschallenging
outthestudy,weengagedininterviewsandfollow-upemailcon-
andnoneofthecurrentapproachesofferasufficientlyeffective
versationswiththesestudentstoidentifytheessentialdesigncon-
solution.Leeetal.’sworkpresentedseveralprototypestoDHH
siderationsnecessaryfortheconceptstobeeffective.
ASLsignersandrevealedusers’perceptionofkeytrade-offsamong
Theformativestudyconsistedoftworounds.Round1wasused
threedimensions-understandability,naturalnessofappearance,and
tounderstandtheviewingandsharingneedsofsignmakuandcol-
degreeofanonymityprotection[39].Clearlyrepresentingfacialex-
lectdatatobepresentedinround2.Round2wasusedtoiteratively
pressionsincludingeyebrowandmouthmovementsplaysacrucial
informtheactualdesignofsignamku(Figure1showsthefinalde-
roleinconveyingcontentaccuratelyinsignlanguage.Alimitation
sign)viainterviewstorevealkeydesignparameters.12participants
oftheirstudyisitdidnotstudysharers’perspective.Additionally,
wererecruitedinround1,andseveralweekslater,round2included
emergingresearchfocusedonsignlanguagerecognition[55,57],
sixoftheseoriginalparticipants.InRound1,eachparticipantwas
animation-basedgeneration[48,61],andmachinelearning-driven
compensated$40fortheirinvolvementinthe2-hoursession.No
translationsystems[24,67],demonstratingapromisingtrajectory
compensationwasofferedforfollow-upparticipationinRound2.
forthefuture.Toadvancethedevelopmentofsignlanguagepro-
Weanalyzedtheinterviewtranscriptanddiscussedthefindingsas
cessing,theactiveparticipationoftheDeafcommunityisimper-
wellasimprovementstothesignmakudesignattheendofeach
ativeacrossallstages.Thisinvolvementiscrucialfordesigning
round.
systemsthatalignwithuserrequirements,ensuringusability,and
promotingtechnologyadoption[14,54,71]. 3.1.1 Round1:NeedfindingofSignmakuforSocialConnectedness.
Intheinitialsession,theparticipantswerepresentedwitha15-
minutevideoaboutAugmentedReality(AR),accompaniedbyerror-
freeopencaptions.Followingthevideoviewing,theparticipants
3 METHOD were requested to provide their comments regarding the video
Inspiredbytheideaoftext-baseddanmaku[74]anditseffectof content,usingeitherASL(assignmaku),English,oracombination
creatingapseudo-synchronouslearningexperiencetoengageusers ofboth.Additionally,theywereaskediftheywerewillingtoshare
[73],weintroduceSignmaku,whichdisplayspeerlearners’com- their comments for future learners, which would be utilized as
mentsinsignlanguagealongsidethevideo,fosteringapseudo- supplementarylearningmaterial.Weinquiredaboutthefactors
synchronousco-learningexperience.Notethatinthisstudy,we thatinfluencedtheirwillingnesstoshare.Participantsweregiven
usedAmericanSignLanguage(ASL)asthesignlanguage,andall the opportunity to express their preferences regarding viewing
signmakuswerecreatedinASL. others’commentsineitherASLorEnglishaswellasthemanner
Weconductedatwo-phasedstudytodesignandevaluatethe inwhichtheywouldliketoaccesssuchcommentsduringvideo
onlinelearningexperiencewithsignmaku.PhaseIisatwo-round learning.Onaverage,eachparticipantmade9comments,withtwo-
formativedesignstudy(N=12)toexplorethedesignparameters thirdsinASLandone-thirdinEnglish.ASL-basedvideocomments
ofsignmaku.Round1,describedinSection3.1focusedon(1)un- lastedbetween5and45seconds,withlongerASL-basedcomments
derstanding willingness to view (2) filtering styles to maintain includingmultiplesentences.
anonymityifneeded(3)collectASLdatasignmakustobeused Ourround1findingsindicatedthatincorporatingcomments,
inround2.Round2focusedonfine-tuningthesignmakudesign. bothasviewersandasproviders,hasthepotentialtofosterin-
PhaseII,detailedinSection3.2,isanevaluationstudy(N=20)to creasedsocialconnectednessamongstudentsduringonlineses-
evaluatehowDHHstudentsviewandcreatesignmakuinonline sionsbyaddressingfeelingsoflonelinessthatmayarise.Notably,it
learning,withafocusonthreestyles. wasobservedthatASL-basedcommentsweregenerallyperceivedSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
tobemorecomprehensibleandengenderedastrongersenseofcon- signingafullsentenceinASL.Itisimportanttonotethat
nectionamongDHHparticipants.Especiallyasaminoritygroup, thisparameterwastailoredandrefinedbasedonthepaceof
DHHcommunitymembersusedtheirownlanguagetofullyex- theselectedvideocontent.Itmayrequirefurtherexploration
pressthemselvesandfeelincludedinthelearningprocess.However, andadaptationwhenappliedtodifferentvideocontextswith
someparticipantsexpressedconcernsaboutprivacy,becausepro- varyingtempos.
vidingASL-basedcommentsentailedrevealingtheirfaces,which • Dimension:Participantsfounditcrucialforthesignmakuto
canholdgrammaticalmeaningsinASLandcannotbedirectlyre- besufficientlylarge,ensuringclearvisibilityofthesigner’s
moved.Consequently,someparticipantssuggestedimplementing facialexpressions,fingers,andelbowsforthepartici-
filterstomask/swaptheirfaces,whileothersexhibitedapreference pantstounderstandthelanguage.Simultaneously,itises-
formorecomprehensivemasking,suchasswappingtheirentire sentialtoavoidoverlapwithcaptionsandvideocontent.
torsoandface.Insummary,participantsshowedapositiveincli- Toaddressthis,wepositionedthesignmakuinthelower
nationtowardsparticipatinginsuchcommentingactivities,and rightcorner,aligningitwiththeheightofthetextcaptions.
anonymitywasessentialforsomeparticipants. Thisplacementallowedlearnerstoseamlesslyswitchtheir
visual focus between the two sources with ease. In the
3.1.2 Round2:SpecifyingDesignFeaturesofSignmaku. Basedon initialsetup,anadditionalpanelfortext-basedcomments
theliteraturereviewandtheresultsfromthefirstround,wesynthe-
wasincorporatedalongsidethevideopanel.Thispanelau-
sizedandlearnedthatsignmakucouldserveasavaluableparadigm
tomaticallyscrolledduringvideoplaybackwhileshowing
forpromotingsocialconnectednessandknowledgesharing.Subse-
text-basedpeercomments.However,welaterremovedthis
quently,asecondroundwasconducted1-2monthsafterthefirst
panelfromtheformalstudytoprovidealargervideoplayer
roundtoidentifykeydesignparametersofsignmaku,particularly
thatcouldensurebettervisibilityofsignmakuandcaptions.
itsdisplayduringvideoconsumption.Forthisround,all12partici-
• Placementinrelationtothevideocontent:Participants
pantsfromthepreviousinterviewwerere-invitedand6choseto
expressedadesireforthesignmakustoaccuratelycorre-
participate.Weselected15signmakusfromRound1andembedded
spondtothevideo’scontent,particularlywhenreferencing
themintothelowerrightcornerofthesame15-minutevideoabout
specific elements like equations. However, they also sug-
AR.Thisgaveparticipantsonaverageonesignmakuperminute.
gestedthatthepop-updoesnotnecessarilyneedtoappear
Wethenaskedourparticipantstowatchthisvideowithsignmakus.
directlynexttothereferencedcontent.Theyfeltthatthe
Thevisuallayoutdesignunderwentseveralroundsofimprove-
unpredictabilityofwherethesignmakumightappearcould
mentprocessbasedonfeedbackfromeachofthesixparticipants.
addtotheconfusionandpressure,leadingthemtoprefera
Onceparticipantsviewedthevideowithsignmaku,weaskedfor
consistentpresentation,allowingthemtoknowclearly
suggestionstoenhanceitseffectivenessforbettercomprehension
wheretoexpectthesignmaku.
andlearning.Thedraftversionissimilartopriorliterature[20].In
• Categories:Wefoundthatsomesignmakusfromround1
thatwork,Chenetal.foundwiththeembedded layout,learners
focusedmoretowardscomplaintsofvideocontentandless
alteredtheirattentionmorefrequentlybetweentwocommentsand
towardstheknowledgeofthevideo(e.g.,“Whencanthis
rememberedmoresurface-levelcomments.Therefore,weselected
videoend,Iamtired.”).Forknowledge-sharingpurposes,
theembeddedlayoutforsignmaku.
wemanuallyselectedsignmakusthatcommentedonthe
Theparticipants’feedbackwascarefullyincorporatedintothe
actualvideocontentinsteadofemotion-onlycontent,ina
design,andsubsequentemailsweresenttothemtoconfirmtheir
similarapproachtopreviousdanmakuresearch[74](e.g.,
willingnesstoprovideadditionalinputs.Theoriginallayoutfor
“Theprototypewouldnotflynowadays.ButIwilladmitit
video-watchingunderwentmultiplerefinementstoarriveatthe
doeslookprettycool.”)
finallayoutusedinthesubsequentformalstudy.Thefinaldesignof
• TwoFiltersvsUnfiltered:Followingparticipants’feedback,
signmakuisshowninFigure1.Below,weprovideanoutlineofthe
weappliedfiltersonsignmakuswithadvancedface-swap
keyparametersthatweremanuallyadjustedduringtheimprove-
technology,similartoapriorstudy[39]thatusedseveral
mentprocess,alongwiththereasonsbehindthoseadjustments.
prototypestoautomaticallydisguisethefaceinASLvideos
Round2wasdedicatedtoadjustingtheparametersforoursecond
while preserving essential facial expressions and natural
study;however,theseparametersmightnotbeuniversallyapplica-
humanappearance.Weexploredmultipletechnologiesof
bletosignmakuindifferentvideocontexts.Futureresearchshould
facefilteringandeventuallydecidedtoexaminein-depththe
exploremethodsforautomaticallycompletingtheadjustmentof
twomostpromisingfilters.Thefirstfilterwasthecartoon
designparameters.
filterusingVToonify[76],aportraitstyletransfertool,which
• Duration:Participantswererequiredtoalternatebetween retainsfacialmovementswhilegivingthefaceacartoon-
readingsignmakuandcaptionswhilealsoattendingtothe likeappearanceandprovidingabasiclevelofprivacy.The
video’svisualcontent.Consequently,itwascrucialforthe originalhumanhandsarepreservedinthisfilter.Thesecond
signmakudurationtostrikeabalance.Ifitwastoolengthy, filterwastheroboticfilterusingDeepMotion,anAI-based
itwouldinterrupttheparticipants’comprehensionflow motioncaptureandbodytrackingtool,whichmasksthe
and attention span, but if it was too short and limited entirebodyandutilizesartificialhandsandfacestocreatea
toasinglesign,itmightineffectivelyconveytheintended roboticappearance.Thisfilterprovidesanincreasedlevelof
message.Thus,wereducedrecommendeddurationfrom30 privacythanthecartoonfilter.
to10seconds.ThisallowedDHHindividualstocompleteCHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
• Quantity: Upon further discussion, we retained 15 sign- ASLandEnglishintheclassroom.Asforethnicity,2participants
makuswiththeaverageofonesignmakuperminute.With identifiedasBlack,1asAsian,11asWhite,5asMultiracial,and
2filteroptionsandunfilteredsignmakus,thisallowedusto 1asPortuguese.Mostwerenon-STEMmajorse.g.,business.See
splitthesignmakusinto3groupsof5signmakusanddistrib- Table1forthedemographicsoftheparticipants.Eachparticipant
utethemevenlyacrossthree5-minutesegmentsofthevideo, wascompensatedat20USDperhour.Thedurationofeachstudy
i.e.,thebeginning,themiddlesegment,andthefinalmin- rangedfromonehourtotwohours.Thestudyplanwasapproved
utesofthevideo.Foreachgroupofsignmakus,weincluded bytheuniversityIRB.
diverseemotions(twonegatives,twopositives,oneneural).
Notably,participantsmentionedhowhavingall3stylesof 3.2.2 ExperimentalDesign. Weconductedatwo-stepuserstudy,
signmakusrandomlypoppingupcouldbedistractingasthe asshowninFig.2.ThefirststepaddressedRQ1,whilethesecond
viewerwouldneverknowwhichstylewouldappearnext. stepwastoaddressRQ2.Thestudywasfollowedbyasurveyand
Therefore,eachgrouphadthesamestylebeforeswitchingto concludedwithaninterview.Theprototypeusedforthisstudy
thenextstyleofsignmaku,sothatparticipantswouldonly wasdevelopedbasedontheproposeddesignfromtheformative
encountertwochangesinstylesofsignmakusthroughout study,asshowninFig.2(outcomeofround2).Tohelpparticipants
thevideo. navigatethroughtheprototypeandstudyprocedure,weprepared
• QualityandClarity:Thesigningqualityandclaritywere instructionsinapre-recordedASLvideo,spokenandwrittenEng-
manuallyassessedbyfourresearchersontheteam.When lishtotheparticipantsthroughoutthestudy.Participantscould
creatingfilteredsignmakusfromround1,wenoticedvaria- alsoaskquestionsinASLorbytypinginthechatboxinZoom.The
tionsinvideosigningqualityandclarityamongparticipants. researchersturnedofftheircameraswhileparticipantscompleted
Someparticipants’filteredsignmakusweredifficulttounder- eachsteptoavoiddistractionandfreeupvisualspace,butcameras
stand.Uponfurtherdiscussion,weretainedsignmakusfrom wereturnedoniftheparticipantrequestedhelporstrayedfrom
onlyoneoftheparticipantsthathadbestqualityandclarity theprocedure.AllbutoneparticipantpreferredtouseASL,while
inbothunfilteredandfilteredsignmakus.Thisparticipant theremainingparticipantspreferredtousespokenEnglish.During
hadmade11signmakusthatspreadacrossthe15-minute theonboardingprocess,participantswereintroducedtotheoverall
videotimeline,andwecuttheirlongerASLrecordingsinto goals,proceduralsteps,andvisualformat,(e.g.,whereandhowsign-
severalsignmakusandremappedsmallersignmakusbackto makuwouldpopup).Thispreviewgaveparticipantsaclearidea
thevideotimestampbasedonthecontentsinhersignmakus. ofwheretolookandwhattoexpect.Eachstepoftheprocedure
Otherfactorsrelatedtosigningqualityandclaritywereleft wasreintroducedbeforeeachsection,grantingtheparticipants
forfutureexploration. additionalopportunitiestoreviewtheprocessandaskclarifying
questions.TheDeafindividualandhearingresearchassistantswith
3.2 PhaseII:ComparingThreeStyledSignmaku interpretingexperiencetookturnsleading19outof20userstudy
sessions(T1-T19),andallrecordingsweretranscribedbythese
Followingtheformativestudy,weconductedexperimentstoevalu-
sameassistants.Theremainingsessionwasledbythefirstauthor
atetheimpactofdifferentlystyledsignmakuonusers’experience
withaninterpreter.
duringvideo-watching(RQ1)andcreatingnewsignmakusafter
video-watching(RQ2).Asmentionedinsection3.1.2,wechosetwo
Step1-VideoWatchingwithSignmaku.First,participants
watcheda15-minuteerror-freeopen-captionedvideoaboutAR,the
filterstylestoaddressprivacyconcernswhensharingsignmakus
samevideousedduringtheformativestudydescribedinSection
withotherlearners:roboticandcartoon.Weprovidedathirdop-
3.1.Thisstepallowedustoobservehowparticipantsviewedthe
tion,realistic,toserveasaprivacy-agnosticcomparisonwithout
signmakus.Participantskepttheirwebcamsturnedonandcon-
applyinganyfilterstothesignmaku.
sentedforAItorecognizetheirfacialexpressionswhilewatching
3.2.1 Participants Information. A total of 20 DHH participants thevideo.However,participantscouldopttohidetheirwebcam
wererecruited.Allparticipantsinourstudywerestudentscurrently viewerontheirinterfaceiftheydidnotwishtoseethemselves
enrolledincollege,ranginginagefrom18to43.Allparticipants whilewatchingthevideo.Duringthevideo,15peers’signmakus,
werefromaprivateuniversityintheUSfocusingoneducation ascollectedfromtheformativestudy,appearedonthebottomright
forDHHstudents.Noneoftheparticipantswereinvolvedinthe ofthevideo-onaverageonesignmakuperminutesimilartothe
formativestudydescribedinSection3.1.Outofthe20participants, formativestudy.Eachsignmakupoppedupinreal-timeandrelated
sevenwereidentifiedasfemale,oneasnon-binary,andtheremain- totheinformationinthevideoatthatmoment.
ing12asmale.Themajority,17,identifiedtheirhearingstatusas Duringtheformativestudy,participantssuggestedusingfilters
d/DeafwithintheDHHcommunity,whiletheotherthreepartici- topreserveprivacywhilekeepingthecontentinasignmaku.To
pantsidentifiedashardofhearing.Sevenparticipantswerefroma explorehowthestylesofsignmakusmayimpacthowparticipants
familywherenoimmediatefamilymemberwereDHH,whereas perceivethesesignmakus,weusedthecartoonandroboticfilters,
theother13participantshadoneormoreDHHfamilymembers. inadditiontotherealisticunfilteredsignmakus,asshowninFig.
AllparticipantshadlearnedASLforatleastoneyear,including11 2.Therewere15totalsignmakus,groupedintothreesetsoffive
participantswhostartedlearningASLfrombirth.Regardingtheir signmakus,thateachparticipantviewedatthesametimestamps
classroomlanguagepreferences,11participantsfeltcomfortable in the video. We detailed the process of choosing and refining
withusingASLonly,oneparticipantfeltcomfortablewithEng- signmakususedinthisphaseofthestudyinsection3.1.Theorder
lishonly,andtheother8participantswerecomfortablewithboth of appearance of the styles in the three sets of signmakus wasSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
Table1:Demographicsoftheparticipants.AllparticipantswererecruitedfromauniversitythatfocusesoneducationforDHH.
Eachparticipantexperiencedthethreeconditions,featuringstylisticallyrelevantstyledsignmakucomments,inarandomly
assignedorderwhilewatchingthevideo.
PID Gender HearingStatus Age Ethnicity RandomlyAssignedConditions
T1 Male Deaf 32 Black Cartoon-Robot-Raw
T2 Male HardofHearing 19 Black Raw-Robot-Cartoon
T3 Female Deaf 19 Asian Cartoon-Robot-Raw
T4 Female Deaf 22 White Raw-Robot-Cartoon
T5 Female Deaf 43 White Raw-Robot-Cartoon
T6 Male Deaf 22 Portugal Robot-Raw-Cartoon
T7 Male Deaf 19 White Robot-Raw-Cartoon
T8 Male Deaf 22 Multiracial Robot-Raw-Cartoon
T9 Male Deaf 22 White Robot-Cartoon-Raw
T10 Female Deaf 21 Multiracial Cartoon-Raw-Robot
T11 Female Deaf 31 White Cartoon-Raw-Robot
T12 Male Deaf 18 White Robot-Cartoon-Raw
T13 Male Deaf 28 White Cartoon-Raw-Robot
T14 Female Deaf 20 Multiracial Raw-Cartoon-Robot
T15 Male Deaf 19 White Robot-Cartoon-Raw
T16 Female Deaf 43 White Raw-Cartoon-Robot
T17 Non-binary Deaf 28 Multiracial Raw-Cartoon-Robot
T18 Male Deaf 22 Multiracial Raw-Robot-Cartoon
T19 Male HardofHearing 26 White Robot-Raw-Cartoon
T20 Male HardofHearing 31 White Cartoon-Robot-Raw
Figure2:ExperimentDesign.Eachparticipantcompletedtwoactivitiesduringthestudy.First,theywatchedavideoabout
augmentedreality(AR)witherror-freeopencaptionsandsignmakus(RQ1).Second,theyprovidedtheircommentsinsignmaku
(ASLcomment)ortextcomments(RQ2).Acommentmaybeconsistedentirelyoftext,solelyuseASL,or,onveryrareoccasions,
includeamixofboth.Theythencompletedapost-studysurveyandinterviews.Participantswereasktoprovidesignmaku
onlyaftertheyfinishedwatchingthevideoforthefirsttime.
randomized.Table1includestheorderofstylesreceivedbyeach selectionandseparatedtheviewing(RQ1)andsharing(RQ2)ef-
participant. fectsofsignmakuindividually.Participantswereallowedtoaddtext
Step2-CreatingSignmakuduringVideoReviewing.Af- comments,whichemphasizedthedifferencesbetweenrecording
terfinishingthevideoforthefirsttime,participantscouldreview anASLcommentandtypinganEnglishcomment.
thevideoinpartorinwholeinordertoaddtheirownsignmaku Thevideowithembeddedsignmakuswasidenticalinbothstep
ortextcomments.Thisstepprovidedinsightsintowhatoptions 1and2.Whenaddingacomment,participantscouldjumpdirectly
participantsmightconsiderwhensharingsignmakuwithother tothedesiredtimestampandselectalanguagepreference:typea
learners.Participantssawallthreesignmakustylesbeforetheyde- writtenEnglishcommentorrecordanASLsignmakucomment.
cidedwhichstyletheywantedtoshare.Thisprovidedaninformed WeencouragedparticipantstoaddatleastonesignmakuandoneCHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
textcomment,buttheywerenotrequiredtoaddboth.Signmaku twocompositescoresandeachstyle’sthreequestionsfortaskload.
selectionshadtwoadditionaloptions:filtersandsharing.Partici- Theresultswereoverallsimilaracrossthethreestyles,sowefur-
pantscouldapplyoneofthreefilters:robotic,cartoon,andrealistic. therconductedcorrelationanalysesoneachofthe20questions.
Signmakuscouldbemadepublicorkeptprivate.Suchcustomiza- Wecomparedeachofthe20questionswiththethreetaskload
tionenhancedparticipants’privacycontrolovereachcomment, questionsspecifictoeachstyle.
whichwasaconcernraisedintheformativestudy. Learners’EmotionsAutomaticallyDetected: Priorworks
Notethatthefocusofourstudyisonunderstandinguserbe- showed that learners’ emotions could be estimated using facial
havioranddoesnotaimtomakeanytechnicalcontribution.Our recognitiontechnologiescontinuously[38,52].Inourstudy,we
prototypedidnotimplementreal-timefilteringduetothelengthy notonlygathereddataonparticipants’subjectiveperceptionsbut
processingtime.Iftimepermittedduringtheinterview,somepar- alsoutilizedfacialrecognitiontechnology,asdescribedby[27],to
ticipants’ASLcommentswereprocessedoutsideourcurrentpro- identifytheiremotionalresponsesduringthelearningprocess.To
totype,allowingthemtoprovideadditionalfeedbackonthefilters. addressRQ1,weconductedastatisticalanalysistoexaminechanges
inparticipants’emotionsbeforeandaftertheywereexposedto
3.2.3 MeasurementsandDataAnalysis. Foreachuserstudycon- variousstylesofsignmakuinPhase1.Specifically,welookedatthe
ductedtogatherandassessfeedbackontheprototype,wecollected “valencechanges”inparticipants’emotionalvalencetriggeredby
thefollowingdata:responsesfromapost-studysurvey,emotions theappearanceofasignmakuonthevideodisplay.Wecalculated
detectedviawebcamduringvideoviewing,actionlogs,andinter- thevalencechangebytakingthevaluefromthefirsttwoseconds
viewresponses. ofthesignmakupopupandsubtractingtheaveragevalencevalue
Post-StudySurvey:Thesurveyconsistedoftwomajorparts: overtheentire15minutesofvideoviewing.
Part1focusedontheviewingexperience(RQ1),andPart2concen- Eachparticipantcontributedatotalof15emotionexpression
tratedonthecreatingexperience(RQ2).Additionally,wecollected changes,comprisingfivetimesforeachofthethreestyles.Weuti-
participants’demographicinformationaswellastheirpreferred lizedrepeatedmeasuresANOVAstoassesstheimpactofsignmaku
languageinlearning.Pleaserefertotheappendix(AppendixA.1) styleonvalencechanges,whichrangedfrom-1to1(representing
forfullsurveyquestions. aspectrumfromnegativetopositive,with0indicatinganeutral
Part1-viewingexperience:Participantswereaskedtoratetheir state).Toaccountforindividualdifferencesamongparticipants,
subjectivetaskloadwhileviewingthethreesignmakustyles.We “1/PID”wasalsoincludedasarandomeffectinthemodel,similarto
focusedonparticipants’opinionstowardthetaskload(mentalde- thesurveyanalysis.Sincethesetechnologiesarenotalways100%
mand,physicaldemand,temporalpressure)whilewatchingvideos accurateinreal-lifeapplications,weprovidedparticipantswith
withdifferentstylesofsignmaku.WeadaptedNASATaskLoad visualizationsoftheiremotionsoverthevideotimeline,derived
Index[31](Likertscale1-10),asithasbeenusedtostudyDHHinter- fromfacialdata(asin[17]).Atthebeginningoftheinterview,we
actionswithtechnology,e.g.,[29,42].Eachparticipantresponded explainedthedatausage,allowingparticipantstoreviewitand
toninequestions,dividedequallyamongthreestyles(threeques- opt-outifdesired.Participantsweregenerallycomfortablewithour
tionsperstyle).Forexample,asamplequestionwas“Howmentally approach,suggestingitwasadequatetoconductwithin-subject
demandingwasviewingthepop-upASL-onlycomments?” comparison.Notethatallstatisticallysignificanttestswithfacial
Aftercollectingthesurveyscores,weperformedthreerepeated data remained significant (p_adj < 0.05) after a Bonferroni cor-
measuresANOVAtestswitharandomizedeffecttocomparethe rection;westillused“p”insteadof“p_adj”whenreportingdata
effectofsignmakustyleon(1)mentaldemand,(2)physicaldemand, analysisinthefindings.
and(3)timepressure.Arandomeffect,“1/PID,”wasincludedto ActionLog:Weusedparticipants’actionlogstounderstandthe
accountforindividualdifferencesamongparticipantsthatcouldnot learningbehaviorswhenprovidingsignmaku.Morespecifically,
beexplainedbythefixedeffectsinthemodel[16],where“PID”was wecollectedthefollowinglogs:thewrittentextinEnglish,the
ParticipantIDasshowninTable1column1.Thepoweranalysis durationoftypingtext,thedurationofcraftingeachsignmaku,
wasconductedinRusingtheWebPowerpackage.Notethatall thenumberofre-recordedsignmaku,theoptionofchoosingthe
statisticallysignificanttestswiththispartofsurveydataremained threestylesofsignmakufilter,andthechoiceofsharingornot.
significant(p_adj<0.05)afteraBonferronicorrection;westillused Wecomparedcountsofcommentsbetweenthethreetypesusing
“p”insteadof“p_adj”whenreportingdataanalysisinthefindings. WilcoxonSigned-RankTest,withtheresultspresentedinsection
Part2-creatingexperience:Participantswereaskedtoanswer 4.2.2.Wealsocomparedthetimespentperpersonandperclip
20questionsabouttheirperceivedsenseofcommunitywhenus- on private/shared options using the same text, with the results
ingourprototypedesigntoviewandsharetoanswerRQ2.These presentedinsection4.2.3.Duetoourlimitedsamplesize,wedidnot
questionswerebasedontheClassroomCommunityScale[26,59]. conductafurtherstatisticalcomparisonofeffortforeachtypeinthe
Aftercollectingparticipants’ratings,wefirstaddedupthesur- contextofprivatevspublicoptions.Additionally,wecomparedtime
veyresponsestotwocompositescoresofsenseofcommunityin spentperpersonandcliponASL/typedEnglishoptionsusingthe
learning-“senseofconnectedness”and“senseoflearning”.Then, sametext.Thedetailsofthiscomparisonarepresentedinsection
werancorrelationsbetweensurveyresponsesontaskloadand 4.2.4.
surveyresponsesonsenseofcommunity,becausewewerecurious PostStudyInterview:Duringthesemi-structuredinterviews,
iftheincreasedloadofsignmaku,especiallyroboticfoundinRQ1 participantswereaskedabouttheirthoughtswhenusingtheproto-
(presentedinsection4.1.1),hadanypositiveornegativerelation type,theirreasoningbehindcertainactionsduringprevioussteps,
withtheoverallexperience.Wefirstranthecorrelationbetween andtheirsuggestionstowardprototypeimprovement.ParticipantsSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
eitheroptedtouseASLorspokenEnglishtocompletetheinterview.
Sampleinterviewquestionsincluded,“whichfilterdoyoupreferor
notpreferwhenviewingothers’signmakusandwhy;”“whenshar-
ingyoursignmakustoothers,doyouhaveanyconcernsabouttwo
filteredoptions.”Athematicanalysisofthetranscriptionsextracted
themainthemes[68].Twocoauthorsindependentlycodedthreeof
thetranscriptsanddiscussedtogethertocreateaninitialversion
ofthecodebook.Onecoauthorfurthercompletedtheremaining
transcripts.Thetwocoauthorsdiscussedfrequentlytorevisethe
codebookandgroupcodesintothemes.Somesamplecodesinclude
positivesanddifficultiesofviewingorsharingsignmakus,strate-
giesadaptedwhenusingtheinterface,andaccessibilityorusability
suggestions.
Figure3:Boxplotsofparticipants’reportedmentaldemand,
physicaldemand,andtimepressureofviewingthreestyles
4 FINDINGS
ofsignmakus(N=20)on10-pointLikertscales(LowtoHigh).
4.1 EngagingLearnersthroughViewingThree Thementaldemand,physicaldemand,andtimepressure
StylesofSignmaku(RQ1) wereallsignificantlyhigherwhenviewingroboticASLsign-
Overall,themajorityoftheinterviewedparticipantsreportedthat makuscomparedtotherealisticstyles.Note**,***signify
signmakuswereabletoreengageandamusethemafterbeingtired, p<.01and.001,respectively.
becausereadingtext-onlycaptionscouldbe“tedious”,“boring” and
“tiring”.Andthesignmakusmadeparticipantsfeelmoreconnected,
e.g.,theywondered“what’sthenextcommentwouldsay”,andfelt 4.1.1 Significantdifferencesinperceptionsofviewingthethreesign-
they“wewerewatchingthevideotogetheratthesametime...notjust makustyles. Participantswereaskedtorankthethreestylesof
passivelywatching”(T1).Thesignmakuprovidedparticipantsmore signmakufor’enjoyingthesignmakuwiththevideo.’Themajority
visualinformationviaASLwhenfeeling‘’struggled...likescience, (66%)selectedrealisticastheirfirstchoice,33%chosecartoonas
withbigwords,”,whichinturnincreasedtheirmotivation:“thepeer theirfirstchoice,and90%consideredtheroboticversionastheleast
commentactuallyhelpedwith“visualizing”...ASLhelpsmelearn enjoyable.Toinvestigatefurther,weconductedastatisticaltest
more!” (T15).T11hopedtohavesignmakuforlongvideostomake todetermineifthedifferentstylesofsignmakuhaddifferenttask
thelearningprocessmoreengagingandmotivating. demandswhenviewing.ThreerepeatedmeasuresANOVAtests
Whenaskediftheyfoundcompetitionbetweendifferentinfor- witharandomizedeffectwereperformedtocomparetheeffectof
mation sources, some disagreed and further said they used dif- signmakustyleon(1)mentaldemand,(2)physicaldemand,and(3)
ferentdatasourcestodoubleconfirmtheirunderstandingandto timepressure.Apoweranalysisfoundsufficientstatisticalpower
“fillintheblank.”T11specificallymentioned,asDHHtheyareused forthestudy(0.81).ResultsareshowninFigure3.
toandisgoodatusingdifferentinformationsourcestoguessand MentalDemand:Therewasastatisticallysignificantdiffer-
disambiguate.Thesignmakuisanadditionalinformationsource enceinmentaldemand(F(2,57)=17.25,p<.001)betweenatleast
that provided cues to support the process. Notably, some DHH twogroups.Onaverage,participantsfoundthementaldemandof
learnerssharedthattheydevelopedstrategiestopayattentionto viewingrealistictobeverylowon10-pointLikertscales(M=3.5,
multiplevisualelementsinvideos,allowingthemtocompensate SD=2.7).Thementaldemandforthecartoon,wasslightlyhigher
forthelackofauditoryinformation. (M=5.7,SD=2.9)thancartoon.Therobotic hadveryhighmental
However,challengesremainedwhenwatchingvideoswithsign- demand(M=8.4,SD=2.3).Aposthocanalysisfoundthattherobotic
maku. Interview data revealed that the main challenges agreed signmakushadsignificantlyhighermentaldemandthanthecar-
uponamongparticipantsweretoquicklyformtheirownnewvi- toonandrealisticsignmakus(p<.01andp<.001respectively).The
sualattentionmanagementstrategytofullycomprehendthevideo cartoonhadsimilarmentaldemandasrealistic.
contenttogetherwithcaptionsandsignmaku.Theywouldcon- PhysicalDemand:Therewasastatisticallysignificantdiffer-
stantlyswitchvisualattentiontoviewingvideocontentandcaption enceinphysicaldemand(F(2,57)=10.32,p<.001)betweenatleast
andsignmaku.Theyconsideredtheabilitytounderstandbothat twogroups.Forthecartoon,thephysicaldemands(M=5.3,SD=2.6)
thesametimeasaskillthatneededpracticing:“Icanseethevideo weremediumandsimilartorealistic(M=4.7,SD=2.7).Therobotic
andpeers’commentssimultaneously,butIamnotthatskilled.It hadveryhighphysicaldemand(M=8,SD=2.1).Aposthocanalysis
ischallenginganddistracting...Needpracticing” (T16).T4alsode- foundthattheroboticsignmakushadsignificantlyhigherphysical
scribedaconflictinattentionbetweencaptionandsignmaku,“It demandcomparedtocartoonandrealisticsignmakus(p<.01and
wasinterestingwhenIsawtheASLcomments.Iwasexcitedtosee p<.001respectively).
andwatchthoseandIjuststoppedlookingatthecaptioning.Yeah... TemporalPressure:Therewasastatisticallysignificantdiffer-
WhenIwasreadingthecomments,Ifoundmyselfagreeing...” enceintemporaldemand(F(2,57)=5.983,p<.01)betweenatleast
Wenextpresentadetailedcomparisonbetweenthethreestyles twogroups.Forthecartoon,thetimepressure(M=6.0,SD=2.6)of
ofsignmaku. viewingwassimilartorealistic(M=4.9,SD=2.6),andparticipantsCHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
feltneitherrushednorrelaxed.Theroboticmadeparticipantsfeel Someagreedviewingroboticrequiredtoomuchcognitiveload
veryrushed(M=7.8,SD=2.8)hadhighertemporalpressurethan thattheyintentionallydecidedtoignoreitandtoprioritizefocus
realistic(p<.01)(posthocanalysis). onthecaptions,whichweremorecommonlymentionedforrobotic
thanthetwootherstyles. SomefurthersuggestedgivingDHH
4.1.2 RealisticASLyieldedtheleastcognitiveload,followedbyCar- learnersmorecontrolsotheycanbetterknowwhattoexpectand
toonASL. Interviewfindingsexplainthatrealhandsinbothcartoon wheretolookastheysaidwithoutcontrol“IwillbelostandIdon’t
andrealisticsignmakugreatlycontributedtotheunderstandability
knowwhattolookat” (T16).Someparticipantswereattractedby
ofthecontent,whichwasabsentinrobotic.T1explainedthathands
thesignmakuandforgottolookbackatthecaptions.T4found
andlipsheavilyneedimprovementforrobotic.T4foundcartoon
roboticsignmakutobechallengingtounderstandandeventually
andrealisticbothlookedlikerealhumansigning,butthey“didn’t
ignoredit:
noticethatitwasatallhuman.”andthought“therobotisveryhard
tounderstand,handsarecompletelyoff...” 4.1.4 Cartoonsignmakubroughtalotofjoy. Whileparticipants
Additionally,theuseoffacialexpressionswaskeytohelping watchedthevideo,theirfacialmovementswerecollectedtoesti-
one’s understanding of the signed content including emotions, matetheiremotionalresponses[27].Therewasastatisticallysignif-
whichwassuppressedincartooncomparedtorealistic.Whilethe icantdifferenceinvalence(negativetopositive)changesbetweenat
limitationsoffacialexpressionsofcartoonwerenotedbysomeof leasttwosignmakustyles(F(2,247)=4.078,p<.05),indicatingthat
theparticipants.Forexample,T10foundcartoonunderstandable theemotionalchangesfromnegativetopositivewasinfluencedby
andcommentedonsomefacialmovements: thestyleofsignmakuwatched.Nosignificantdifferencewasfound
forarousalchangesbetweensignmakustyles.Thepoweranalysis
“Ilikedthecartoon.The(cartoon’s)signingwasclear
indicatesagoodstatisticalpowerforthestudy(0.84).
butitreallywasn’tthesameastherealASLsigning.
It’sharderbecausetheclarityofthecartoon’sfacialex-
Posthocanalysesrevealedthatcartoonincreasedpositiveemo-
pressionswashardertounderstand.It(cartoon)wasn’t
tions(M=0.16,SD=0.08)morethanrobotic(p<.05)(M=0.008,SD=
asclear.Butthe(realistic)ASLcommentswereclear,
0.05)andrealistic(p<.05)(M=0.007,SD=0.05);andnosignificant
andthosefacialexpressionswereclear.”" differenceswerefoundbetweenroboticandrealistic.Insummary,
Whenexperiencingwithroboticsignmaku,participantscreated
theseresultssuggestedthatwatchingcartoonsignmakusbroughta
themetric,“smoothness,”formeasuringhowwellsigningavatars
positiveemotionaleffectcomparedtowatchingroboticorrealistic
signmakus.
presenteddifferentmodalitiestogether.T15commented:“Therobot
Thisresultwasalignedwithparticipants’interviewfeedback,
wasnotnatural.Itneedsmoreflow.Notchoppy.Iwasn’tsurewhatit
said.”T3alsocomplained:“Therobotisstiff,notflexiblelikeareal
thatthemostcommonreasonforcartoontobepreferredwasthatit
person.” T16providedamoredetailedexplanation:
feltfuntowatch,asit“remindsmeofDisneyduetobigeyes.” (T11).
Cartoonwasalsoregardedwithhighpotentialforcustomization
“Idon’tlikearobotavataratall.Itisuselessbecause andawiderangeofchoicesitcouldoffer,suchascreatingfunny
itischunky,anditishardtounderstanditssigning.I orrole-playingcontentinvariedlearningandsocialcontexts.For
couldnotrecommendusingitatallforASL.Ilearned instance,T4commented:
an interesting tidbit from Dr. Annelies Kusters, who
mentionedhowyouperceivesignlanguageintexture.
“...sometimesyoucanbecomeananimal.Oryourhead
ThatgotmethinkingaboutASL’stexture,anditgotme canbecomeacharacter?Orit’llmakeyourfaceand
tounderstandthatASLisverysmooth,flexiblelikewa-
bodyadifferentcolor...funny.”
ter.SotheavatarforASLshouldbecurvyandsmooth, T16alsoaddedthatcartoonsignmakusmightnotbepreferredif
whereastherobotistheopposite.” thevideowasforaseriouscontext,e.g.,ameetingorbusiness:
4.1.3 InaccurateRoboticASLtriggeredthehighestcognitiveload, “Thecartoon-stylecommentsarefuntouse.Itdepends
comparedtoCartoonandRealisticbeingsimilar. Overall,robotic on the seriousness of the context. Keeping a cartoon
washardtounderstandwithfakeandinaccuratehandsandfaces, avatarwouldbeagoodideatomakethelearningex-
whichinclinedsomelearnerstozoominandenlargethesignmaku– periencefunlearning.Forchildren,playingislearning,
tryingtoseethesignsmoreclearly.Also,thehandswereusing anditappliestoanyage.Ifyouenjoyandyouwillenjoy
timeandspaceawkwardly,makingithardtointerpretsemantic learning.Usingcartoonavatardependonthecontext.
meaning.Thiswasalsoassociatedwithmissingthechancetolook Inaninformalenvironment,itcouldbefuntouse.”
attheoriginalvideocontentandthesenseofpressureassociated Summary-RQ1Whilesignmaku, video,andcaptionsmight
withfeelingleftout.Someeventuallydecidetoignoretherobotic, competeforDHH’svisualattention,theyprovidecomplementary
asT5explained: andvisualinformationfordisambiguatingcaptionsthatarebor-
“with the robot, I really had to concentrate. I didn’t ingandtedioustofollow.Participants’surveyresultsshowedthat
understanditatall.Itwasn’tworththework.Ifeltlike viewingroboticputthehighesttaskload(mentaldemand,physical
itateupallofmyenergythatshouldhavebeenon demand,timepressure)onthem.Accordingtotheirinterviewfeed-
thecontentvideo.So,Istartedcompletelyignoringthe back,theroboticsignmakusweretheleastaccurateindelivering
robot.Icontinuedtomonitorthecomments,butifit handmovementsandfacialexpressions.Onthecontrary,cartoon
wastherobot,Iwouldn’tlook.I’dcontinuetolookat signmakusdidnotposemorephysicaldemandandtimepressure
thevideo.” thantherealisticones.Moreover,cartoonsignmakuswerefavoredSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
byparticipantsfortheirentertainingeffect,whichalignedwith cartoon style was an appropriate compromise between both re-
participants’facialexpressionchangescapturedbytheautomatic quirements.Incontrast,therealisticstylefailedtomaintainany
emotionrecognitiontool. levelofprivacy.BetterASLunderstandabilityisnecessaryforself
(usedaspersonnote-takingforfurtherreviews)andothers(sharing
4.2 EngagingLearnersviaCreatingandSharing
publicly).Forexample,T15,whofoundroboticsignmakusmore
mentallychallengingandhardertointerpretthancartoonandre-
Signmaku(RQ2)
alistic,switchedbetweenthetwostylesbuteventuallydecidedto
RQ2revealsusers’perceptionsofcreatingandsharingsignmaku useroboticforanonymitywhenprovidingsignmakus:
afterviewingsignmakuinRQ1,usingsurvey,systemloganalysis,
andinterview.Wecomparedtheuserexperienceofcreatingand
“...Iwasn’tsurewhatitsaid,it’salotofwork...(for
sharingASLcommentstotextcomments,uncoveringdesignop- sharing)Ipreferthatone[realistic]becausefeelsmore
portunities.Intotal,ourparticipantscreated68signmakuswithan natural, like peer-to-peer...However, for those people
averageof3.4signmakusperparticipant(SD=3.8). whodon’tfeelcomfortablerevealingthemselves,Iwould
recommendtherobot..Ithinktherobotisthebest(for
stayinganonymousinsharing).”
4.2.1 CreatingandSharingsignmakupromotedasenseoflearning
community. Duringthepost-studysurvey,participantsreportedan Whilehavinggoodunderstandability,cartoonalsopreservedan
increasein“senseofconnectedness”(averagescore=33.8/50,SD= acceptableanonymityabilityforsomeparticipants.T3,T5T7,and
3.9)and“senseoflearning”(averagescore=28.8/50,SD=5.9),when T11onlymadecartoonwiththe89%ofthemmadepublic.T11:
theywereaskedtocomparetheproposeddesignagainstvideo-
“Inaclassroomsetting,itwouldbefinenottousethe
basedlearningwithoutviewingorcreatingsignmakuthemselves.
privacyoptionsbecauseIknowthepeople.Butifit’son
Among all three styles, increased mental and physical demand
aplatformsuchasYouTube,Iwouldusethecartoon....
positivelycorrelateswitha“senseofconnectedness”butnotwith IprefertheavataroptionbecauseI’mshy.”.
temporalpressure.Increasedphysicaldemandpositivelycorrelates
Thoughourparticipantswereinstructedtogenerateandshare
with “sense of connectedness” among realistic (𝜌= 0.61, p< .01)
ASLcomments,theirprimaryfocusremainedoncomprehending
andcartoon(𝜌=0.50,p<.05),butnotforrobotic(𝜌=0.25,p>.05).
ASLcontent,withASLanonymizationconsideredimportantbut
Increasedmentaldemandpositivelycorrelateswith“learningop-
lesssoincomparisontounderstandingASLcontent.Inthesecases,
portunities”amongrealistic(𝜌=0.50,p<.05)andcartoon(𝜌=0.53,
cartoonmettheirneedsasabalanceofbothneeds.Fromtheinter-
p<.05),butnotforrobotic(𝜌=0.33,p>.05).Furtherresearchshould
viewcomments,therationalebehindnotsharing,insteadofprivacy
understandwhythereappeartobedifferencesamongthethree
andanonymityconcerns,wasthatsomeparticipantsbelievedthat
styles.
certaincommentscontentwerelessbeneficialforpeerlearners
Theinterviewfindingssuggestedthatbeingabletocreateand
andweremorecloselytiedtotheirindividuallearningexperiences,
sharecommentsalsofosteredafeelingofconnectedness.Forex-
servingaspersonalnotes.
ample,T1wasoneofthemanyparticipantswhore-watchedall
signmakuonceagainwhenprovidingtheirowncommentsand
4.2.3 Sharingrealisticsignmakuincreaseeffortinself-representation.
triedtoreplytoothers.Whenaskedwhy,T1said, ThetimespentonsharedASLclips(M=108.8secondsperperson,
SD=91.3)waslongerthanthosesetasprivate(M=97.7secondsper
“...Ifeltconnected.Itwaslike,‘Iseeyou!’andIwanted
person,SD=200.8)(p=.052),indicatingsigningsharedcomments
toaddtothatinmycomment.IfeltlikeIcouldrelate.
increasedusers’effort.
‘Ifeelyou...’Connectedtothatcomment...Enoughthat
Sharingsignedcommentwasalsoaccompaniedwiththeneedsin
youfeltmotivatedtoprovideyourowncomment...”
self-representation.Fiveparticipantsre-recordedtheirASLvideos,
afterdecidingtheywouldsharethesignmakuwithothers.After
4.2.2 Cartoon offered a balance between anonymity and under-
including the ASL re-recording, the total time for crafting ASL
standability. Whencreatingsignmaku,theoptionsforrealisticand
increased.ThetotaltimeforcraftingASLcommentsaveraged168.7
cartoonwerepreferredoverrobotic.Userinteractionactionlogs
seconds(SD=108.0)perparticipant,similartothetimefortyping
recordedthatourparticipants(N=20)created33realisticsignmakus,
text. On average, participants had 0.8 re-recorded attempts per
25cartoonsignmakus,and10roboticsignmakus.Thereweresignif-
participant.Theinterviewresultexplainstheyre-recordedtheASL
icantlyfewerroboticcommentsthanthetwootherstyles(p<.05).
Amongthethreestyles,25uploadedcartooncommentsofwhich11
clipsforbetter“precision,clarityandtobemorerelatedtothevideo
wereprivateand14public,whileforrealistic21wereprivateand context” and“betterlightingandplacinginthecamera.” Thetwo
participantswhofavoredprovidingtext-onlycomments(alltext
12werepublic,andforrobotic3wereprivateand7werepublic,
commentswereshared).Theymentionedthattextcommenting
respectively.Ineachstyle,approximatelyhalfofthecomments
wasforthepurposeofsharing;typingtextallowedthemtoavoid
wereselectedforsharing,andhalfwerekeptprivate.Regarding
thestressassociatedwithimpressionmanagement,expeditedthe
thesharingrateofvarioussignmakustyles,therewerenosignifi-
studyprocess,andenabledmorepreciseexpressionthroughtext
cantdifferencesamongthethreestyleswhenusingachi-square
editing.Andtheprocessof“editing”ASLcommentsmaynecessitate
test.Thelimitedsamplesizedidnotsupportfurthercomparative
re-recordingattempts,aselaboratedinthequotesbelow:
analysisofeachstyle.
The interview results found that the robotic style prioritized “Iwanttosignofcourse,butsometimesIfeellikeIhave
privacyattheexpenseofunderstandabilityinsharing,whilethe toseteverythingup,looknicewiththerightclothes,CHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
havemymakeupandhairstyled,andallthat.Ugh!It fromT15encapsulatesthissentiment:“AsaDeafperson,fullyex-
seemstotakesomuchtimewhenIcouldjusttypeit pressingmyselfinEnglishischallenging.InASL,Icandosofluently
allupandedititeasierandfaster...WithASL,Ihaveto andeffectively”
thinkitthroughtomakesureIusetherightsignand ThecontentbetweentextandASLcommentswassimilar.Both
thecorrectfacialexpression.” –T4 commentingmechanismswereusedtoshareemotionsandtorelate
personalexperiencestowardsthevideocontentaswellaspeers’
signmakus.Forexample,T8commentedonthevideocontentusing
Participantsfoundthatusingtwoproposedfiltersforsharingre-
quiredlessself-representationeffortcomparedtotherealisticstyle.
textcomment:Theuseofaugmentedrealityinretailandshoppingis
Afterincludingre-recording,time,thetimespentonrealistic(M=
intriguing.Theyalsocreatedasignmakutoreplytopeer’ssignmaku
45.8secondspercomment,SD=30.8)waslongerthantimespent
inthesamecontext:At4:20inthevideo,thestudentmadeacomment
onrobotic(M=20.5secondspercomment,SD=17.1)(p<.05).Some thatIreallyagreewith.Ilikeaugmentedrealityshopping.It’scool
wereinterestedinusingtwoproposedfiltersforself-presentation, thatyoucanpanyouphonearoundtheroomtoseeifacouchcanbe
however,thecurrentprototypelackedreal-timefilteredviews,leav- movedaroundinaroom.Onceyouknowitfits,thenyoucanbuyit
ingparticipantsuncertainabouthowwellthefilterssuitedthem.
inperson(ASLcliptranscribedtoEnglish).
Participantssuggestedthathavingapreviewofthefilteredvideo
Summary-RQ2Afterparticipantscreatedtheirownsignmaku
comments,wefoundapositivecorrelationbetweenparticipants’
wouldboosttheirwillingnesstouseandsharewithtwoAIfilters
perceivedphysicalloadwhenviewingthecartoonsignmakuand
byallowingthemtocheckforclearsigningandfacialmovements.
somequestionsinperceivedsocialconnectednessandenthusiasm
Wedidnotconductfurthercomparisonofeffortforeachtypein
forlearning.Sucharelationshipwasnotfoundwhenparticipants
thecontextofprivatevspublicoptionsduetoourlimitedsample
viewedtheothertwosignmakustyles.Additionally,comparedto
size.
traditionaltext-basedcommenting,commentingusingASLcosts
lesstimeandismoreexpressiveforDHHtocreate,thoughthey
4.2.4 Signmakureducedthecostofcreatingcomparedtotext-based wouldsparemoretimeonthesetupforself-representation,e.g.,
commenting. Eachparticipantwasencouragedtocreateatleastone clothingright,iftosharerealisticsignmaku.
textcommentandoneASLcomment.Theyhadthechoicetocreate
commentssolelyintext,exclusivelyinASL,or,onrareoccasions,to 5 DISCUSSION
optforacombinationofboth.Theprototypetoolshowedtext-only
5.1 SignmakuasanEdu-tainmentFeature
commentsanonymouslybydefault,andparticipantswereinformed
PromotinganInclusiveVideo-based
oftheoptionsduringon-boarding.
Amongalltheparticipants,threepreferredASLcommentsonly, LearningCommunity
andtwopreferredtocreatetextcommentsonly.Wethencompared Inourwithin-subjectstudyexploringtheimpactofthreestylesof
theeffortofparticipants’signmakuandtextcomments.Afterdrop- signmaku(realistic,cartoon,androbotic)onlearning,thefindings
pingfiveparticipantswhopreferredonlyonecommentingmethod fromRQ1andRQ2revealedthatcartoonwerepreferredoverrobotic
only,theremainingparticipants(N=15)uploaded2.6realisticASL andrealistic.Cartoonprovidedgoodunderstandability(RQ1&RQ2)
commentsand2.5textcommentsonaverage.Giventhetimecost whilepreservingsomeanonymity(RQ2)whichmeetstheirneedto
of converting the realistic ones to the other two styles and the shareowncomments,increasessenseoflearningcommunity(e.g.,
constraintofeachstudy,wedidnothavetheparticipantsconvert inter-dependency)andfurtherelicitsthemostpositiveemotion
theirrealisticcommentstootherstyles.Notably,apaired-samples change(RQ2).
Wilcoxonsigned-ranktestindicatedthatthetotaltimelengthof InRQ1,additionalremarkshighlightedthatsignmaku,regardless
ASLcomments(M=74.0seconds,SD=66.7)wassignificantlylower ofstyle,enhancestheparticipationandre-engagementofDHH
thanthatfortypingtextcomments(M=190.6seconds,SD=153.6) duringthelearningprocess.Italsoimpartsagreaterwealthofvisual
(p<.05).Similarly,theaveragedurationforeachASLcomment(M= informationthroughsignlanguage,adimensionthatisabsentin
26.9seconds,SD=22.8)wasconsiderablyshorterthanthetyping writtenEnglish.Additionally,itassistsinalleviatingboredomoften
timefortextcomments(M=94.4seconds,SD=80.6)(p<.001).After associatedwithreadingtext-onlycaptions.Ourdiscoveriesprovide
includingASLredo,timespentpercliponASLaveraged61.0sec- avaluableexpansiontothecurrentvideo-basedlearningexperience
onds(SD=19.8),andtimespentperpersononASLaveraged168.7 forDHH,whichpredominantlyconcentratesonimprovingvideo
seconds(SD=108.0).Bothwerecomparabletotypingtextperclip captionaccuracyanddesigns(asseenin[13]).
andperperson,respectively(paired-samplesWilcoxonsigned-rank RQ1andRQ2resultssuggestthatsignmakucanenhanceinclu-
test,p>.05). sivityinvideo-basedlearningcommunitiesthroughentertainment
Inotherwords,timespentonASL,includingredo,wascompa- andemotionalengagement.Thesefindingsempiricallyreinforce
rabletothetimetakenfortextcomments,bothlongerthanASL thevalueofsignmakuasan“edu-tainment”feature,aligningwith
withoutredo.However,despitethesimilarityintimebetweenASL BuckinghamandScanlon’sconceptofcaptivatinglearners’atten-
withredoandtextcomments,participantinterviewsshedlighton tionandevokingemotionstopromoteinclusivevideolearning
thedistinctdifferences:themajorityofparticipantsdisplayedmore [2].Wecontributesignmakuasanew“edu-tainment”andlearner-
fluencyandexpressivenessinASLthanintypingtextcomments. sourcingfeatureandrevealitsapplicabilityinaminorityonline
Furthermore,theirpreferenceforASLovertextforlanguageinput learnerpopulation-DHH.Inthiscase,thesesignmakucomments
wasevidentfromtheirbackgroundsurveys.Anotablestatement couldbeviewedasaco-createdandsustainedoutcomestemmingSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
fromtherelationshipbetweenDHHandthevideo.Existing“edu- Languagecomprehensionisfundamental,andparticipantsfur-
tainment” features in video-based learning include vibrant ani- thercontributedthemetric“smoothness”forsigningavatars,sig-
mations[2],creatorsofferingauthentic,casual,andpersonalized nifyingtheAI-generatedsigningavatar’scapacitytoseamlessly
content[75],andteachersincorporatingentertainmentelementson integratevariousmodalities.Whenformulatingspecificmetricsfor
live-streamingplatforms[19].Earlierstudieshaveexploredtheuse thedevelopmentofAI-generatedASLcontent,itiscrucialtobe
of“edu-tainment”featurestomakesignlanguagelearningmaterial includedasanevaluationcriteria.It’salsoimportanttonotethat
moreenjoyableforDHHchildren[56]. previousresearchhashighlighteddistinctionsintemporalprefer-
Ourfindingsshowthepromiseofsignmakuinenhancingin- enceswheninteractingwithhumansignersversusAI-generated
clusivevideo-basedlearningthroughtheintegrationofsocialin- signingavatars.Forexample,DHHusersmayrequirefastersigns
teractionviaamoreaccessiblecommentingmechanismandan andslowertransitionsthanthosetypicallyemployedbyhuman
improvedsenseofsocialconnectedness.Specifically,ourresearch signers[3].Therefore,whilethemetricsforhumansignerscan
builds on previous research by introducing DHH learners to a serveasafoundationalreference,theymaynotdirectlyapplyto
pseudo-synchronouslearningexperienceandallowingthemtouse AI-generatedsigningavatars,necessitatingtailoredadjustments
theirpreferredlanguage(signlanguage)tointeractwithonline andrefinements.
learnerstheydonotknow,ifneeded,anonymously.Ashighlighted
5.2.2 TheImpactofAI-GeneratedFacialExpressionsonSignLan-
inpreviousresearch,socialinteractionshavealwaysheldimpor-
guageComprehension. Ourfindingsdemonstrateapreferencefor
tancebuthavebeenlackingforDHHindividualsduringtheirfor-
realisticandcartoonsignmakuoverroboticsignmakuinbothview-
mativeyears[23,63,66].Howwillsignmakubeadoptedinthe
ing,creating,andsharingduetonaturalhandandbodymovements
wild?Similarchallengeshavebeenidentifiedamongotherminor-
andatleastsomefacialexpressionsmakingthelanguagepossibleto
itylearnersaswell(e.g.,[64]).Howmaythisnewcommenting
understand.Thecartoonsignmakuhassomefacialmovementwith
featurebeadoptedbyabroaderaudience?Howcanitbeutilizedto
unfilteredhands,andthetaskdemandwassimilartorealisticin
promoteinteractionbetweenlearnerswhohavevariedaccessibility
allthreedimensions,indicatingthatwhenfacialcuesarelessened,
challenges?Ourworkhaspavedthewayforgreaterinclusivityin
thecommunicationisstillunderstandable.Andwhenhand,body,
onlinelearning,markingavastandpromisingavenueforfurther
andfacialmovementsarealllessened,themessagebecomeshard
explorationandresearch.
tounderstand.Theaboveimpliesthefundamentalimportanceof
handandbodymovements.
5.2 DesignImplicationsforDHH-Inclusive
Meanwhile,asshowninRQ2,realisticisstillpreferredovercar-
Video-basedLearning toonforitsunderstandability,especiallyinsharing.Itrevealsthat
OurfindingsdemonstratethatASLoffersamoreaccessiblemeans facialmovementmakesitnotonlyunderstandablebuttrulyex-
forindividualswhoareDHHtobothviewtheirpeers’comments pressive.Forexample,facialexpressionandbodypostureareoften
andmaketheirowncomments.Additionally,ASLprovidesavisu- usedtoconveyemotionalmagnitude(surprisedvs.shocked.vs.
allyrichersourceofinformationcomparedtotext-basedcomments. aghast)andeyebrowsmayberaisedorlowereddependingonthe
CulturallyDeafindividualsprimarilyrelyonvisualcommunica- formofquestionbeingasked[72].Theimportanceoftheexpres-
tionchannelsratherthanauditoryones,assupportedbyprevious sivebodyhasbeenbroughtupbyresearchersintheaccessible
research[10,30,53].Thisunderscoresthesignificanceofaccom- computingfieldingeneral[65].Expandingonpreviousresearch
modatingDHHuserswithASLandvisuallearninginvideo-based thatfocusedonhowaudiencesperceivevariousASLfilteringstyles
learning,parallelingtheimportanceofaudiodesignforhearing [39],ourstudyalsoconsideredtheperspectiveofthosesharing
usersinauditory-focusedenvironments,asdemonstratedbyprevi- content.Wediscoveredthatusersarelessinclinedtocreateand
ousresearch.Forexample,Arakawaetal.developedavideo-based sharesignmakuswithfilteredstylesthatlackfacialmovements.
learningsystemthatperturbsthevoiceinthevideotohelpmind-
wanderinghearingusersrefocustheirattentionwithoutconsuming 5.2.3 The Role of AI-Generated “Make-Up” Filters in Enhancing
theirconsciousawareness[7].Chenetal.studiedaudionote-taking Sharing. RQ2resultssuggestedthatthequalityofASLcomments
influencesparticipants’willinesstoshare.Someoptforre-recording
invideo-basedlearningtendstobemoreexpressiveandlengthy
toenhancequality,andT4emphasizestheimportanceofreview-
incomparisontotext-basednote-taking[18].Ourfindingsprovide
ingandimproving,particularlyinfacialmovements.Therefore,
newdesignimplicationscenteringonhowgenerativeAIcouldbe
’Make-up’filtersthatautomaticallyimproverecordingqualitycould
appliedforinclusivevideo-basedlearning.
improvewillingnesstosharingbyreducingcreationefforts.For
5.2.1 GenerativeAIforASLandText. ThecommentmadeinEng- example,filtersshouldbeabletomakesignedcommentstoshow
lishcouldbetranslatedtoASLforDHHlearners.Viceversa,ASL moreexpressiveshouldbemorevividfacialandeyebrowmove-
commentsshouldbetranslatedintoEnglishforgeneralhearing ments.Othernon-linguisticfeaturescouldbeusefulaswell,such
users.WithrecentadvancementsinAI,thereal-timegeneration aslightingimprovements.Thesefiltersunderscorethepotentialof
forASLispossible,e.g.,[28].ItalsoallowsDHHlearnerstobreak generativeAItechnologyinprovidingunderstandableandexpres-
thecircleandcommunicatewithusersinanotherlanguageintheir siveASLcontent.
ownpreferredmodality.ASLgeneratedfromEnglishisalsoneeded InRQ1,participantsemphasizedthedesireforself-presentation
fromthoseDHHwhoprefertotypeorsignonly,duetostrong options,includingfunfilters,alongsidetheanonymityfeature,con-
English&ASLskillsandeaseineditingtypedEnglishcompared sistent with findings in our formative study, RQ2, and prior re-
toeditingorre-recordingsignedcomments(RQ2). search[39].FutureresearchshouldexplorediversefilteroptionsCHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
forfacialexpressions,bodylanguage,andsigningstyles.AsRQ2 engagementandlanguagelearningbetweenDeafandhearingindi-
suggests,signlanguageisrichinculturalandlinguisticdiversity, viduals.Futureresearchshouldalsoinvestigatehearingindividuals’
withvariationsinregionaldialects,signingstyles,andpersonalized perceptionofsignmaku,exploringdesignfeatureslikesignmaku
expressions.FurthergenerativeAItechnologyshouldallowidentity frequencycontrolandAI-generatedtextcaptionsusingrecentAI
expressionwithinsignlanguageavatarsenablinglearnerstoshow- technology[15].Additionally,furtherresearchisrequiredtounder-
casetheiruniqueculturalandlinguisticbackgrounds,preserving standmeaningfultwo-waytranslationusingAI,movingbeyond
thediversityofsignlanguagecommunitiesandauthenticityofthe word-for-wordtranslations.
individuals.Thisdatasetmightalsobeinterestingtoresearchers
whowanttocontrastfluentandnon-fluentsigning–[32].Simi- 5.3 Limitations
lartoastudybyArakawaetal.[6],whichdiscoveredthatvoice
Weacknowledgeafewlimitationsinourstudy.First,ourpartic-
conversionimpactedspeechownershipandimplicitbiasinself-
ipantsarefromahighereducationschoolspecificallyforDHH
presentation,itisessentialtoconsiderpotentialbiasesintroduced
students.DHHstudentsfrommainstreamhighereducationschools
bysignlanguagefilters.
mighthavedifferentperspectivestowardtheirinteractionswith
5.2.4 ScalabilityofSignmakuDesignParameters. Asignificantarea otherstudentsandtechnology.Futurestudiesshouldconductstud-
whereAIcanmakevaluablecontributionsisinautomatingthefine- ieswithmoreDHHstudentswithamorediversebackground.Sec-
tuningofdesignparametersduringround2offormativestudies ond,ourstudyisconductedusingAmericanSignLanguage(ASL),
(PhaseI).Specifically,designaspectslike“duration,”“dimension,” andtheresultsmaybedifferentusingothersignlanguages.Fu-
and“placementinrelationtothevideocontent”canbeoptimized turestudiesmayexplorehowdifferentsignlanguagesmayimpact
by harnessing large-scale data and adapting to various user in- theimplementationofsignmakuforonlinelearning.Third,our
terfacelayouts.Forexample,amongtheseparameters,managing currentsignmakudesigndidnotallowparticipantstocustomize
the duration can be particularly challenging. We observed that theparametersofsignmaku.Duringtheinterview,participants
participantscomfortablydivertedtheirattentionfromthelearn- suggestedmorewaystocustomizethesignmakuexperience,such
ingcontentforupto10secondsandstilleasilyre-assumedthe aschangingsizeandlocationofthesignmakusorturnonoroff
contentwithoutfeelingstressed.Typically,foreducationalASL signmakus.Futurestudiesmayexplorehowtheseinteractionsmay
sentences,onefullsentence,asdeterminedinourinitialformative impact the experience and effects of using signmakus in video-
study,takesapproximately10seconds.However,it’sworthnoting basedlearning.Futureresearchcouldbuildbeyondourworkon
thatlearnersmightprefersigningforalongerduration,andin understandingsharingeffectaftervideowatchingtoduringvideo
ourevaluationstudy(PhaseII),ourparticipantssignedcomments watching.Fourth,weusedfacialexpressionrecognitiontechnology
lastedabout30seconds.Inourcurrentapproach,wemanuallyedit toautomaticallydetectparticipants’emotionwhilewatchingthe
thevideos,butthereispotentialfordesigningatoolthatoffers video.Wedidnotuseittoexaminethedetectedemotions,rather
auto-editingandstreamlinesthisprocess.Also,ourcurrentdesign weonlycomparedtheemotionchanges.Futurestudiescouldapply
onlypresentsonesignmakuatoneparticulartimeofthevideo, moreadvancedtoolstocapturelearnersemotionsmoreaccurately
futureresearchmightexplorethepossibilityofdisplayingmultiple andre-evaluateourfindings.
signmakusimultaneously.
Wewanttoemphasizethattheparametersweselectedforeach 6 CONCLUSION
designaspectaresolelyforourevaluationstudy(PhaseII),which Weintroducedanewvideocommentingfeature,Signmaku,which
isbasedonourselectedvideoonAR.Wedonotclaimthesepa- demonstratedpromisingresultsinenhancingvideo-basedlearning
rametersaregeneralizedtobroadercontexts.Importantly,future forDHHstudents.Thecartoonsignmakucreatedamoreengaging
researchshouldinvestigatehowparticipants’experiencesareim- andinteractivelearningenvironment,positivelyimpactingusers’
pactedwhenmultipleusers’commentsarepresented,asdanmaku perceivedlearningengagementandsocialinteraction.Ournovelin-
innatureallowsmultipleuserscommentingonthesamevideo teractiondesignhasthepotentialtoencouragelearnerstoactively
scene[22,74].Additionally,futureresearchwouldneedtoevaluate participateinthelearningprocessandempowerthemtoexpress
howfiltersworkforsomesignersbutnotforothers,andhowthe theiropinionsopenly.Ourresearchexpandsthedesignspacefor
filterscanbefurtherpersonalizedbasedonhowindividualsexpress onlinelearning,thusaddressingthespecificneedsofDHHindivid-
differently.Thisisparticularlyrelevantinlightofourneedfinding, ualsandprovidingaccesstoawiderangeofeducationalresources.
whichrevealedsignificantvariationsinindividuals’signingquality WeemphasizetheneedtoaddressthelimitationsofgenerativeAI
andclaritywhenusingfilteredsignmaku. techniquesincreatingsignlanguagetoensureaccurateandcom-
prehensivecontent.Adoptingsignmakuandprioritizinginclusive
5.2.5 Promoting Deaf Cultural Identity in Online Social Interac-
onlinelearningcanunlocksignificantlearningopportunitiesfor
tions. It’scrucialtorecognizeDeafasaculturalidentity,notas
DHHstudents,therebypromotingequityineducationandenabling
adisability,andpromotemutualinclusivitythroughintercultural
DHHstudentstothrivealongsidetheirhearingpeers.
dialogue.TofosterasenseofbelongingwithintheDeafculture,
futurevideosystemscanconsiderencouragingDHHindividuals
toteachASLduringinteractionswithhearingpeople.Macketal. ACKNOWLEDGMENTS
foundthatDeafsignerswanttosharetheirlanguageandculture ThismaterialisbaseduponworksupportedbytheNationalSci-
withbothhearingfamilymembersandfriends[45],highlighting enceFoundationunderGrantNo.2119589.Anyopinions,findings,
theneedforonlinelearningtechnologytofacilitateintercultural andconclusionsorrecommendationsexpressedinthismaterialareSignmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
thoseoftheauthor(s)anddonotnecessarilyreflecttheviewsof [19] XinyueChen,SiChen,XuWang,andYunHuang.2021."Iwasafraid,butnowI
theNationalScienceFoundation.Theauthorswouldliketothank enjoybeingastreamer!"UnderstandingtheChallengesandProspectsofUsing
theanonymousreviewersfortheireffortsandvaluablecomments.
LiveStreamingforOnlineEducation.ProceedingsoftheACMonHuman-Computer
Interaction4,CSCW3(2021),1–32.
Additionally,wewouldliketoexpressourgratitudetoallthepar- [20] YueChen,QinGao,andGeGao.2022.Timeline-anchoredcommentsinvideo-
ticipantsfortheirthoughtfulandreflectivefeedback. basedlearning:Theimpactofvisuallayoutandcontentdepth. International
JournalofHuman–ComputerInteraction38,9(2022),868–883.
[21] YueChen,QinGao,andPei-LuenPatrickRau.2015.Understandinggratifications
ofwatchingdanmakuvideos–videoswithoverlaidcomments.InCross-Cultural
REFERENCES DesignMethods,PracticeandImpact:7thInternationalConference,CCD2015,
HeldasPartofHCIInternational2015,LosAngeles,CA,USA,August2-7,2015,
[1] SolmazAbdi,HassanKhosravi,ShaziaSadiq,andGianlucaDemartini.2021. Proceedings,PartI7.Springer,153–163.
EvaluatingtheQualityofLearningResources:ALearnersourcingApproach. [22] YueChen,QinGao,andPei-LuenPatrickRau.2017.Watchingamoviealoneyet
IEEETransactionsonLearningTechnologies14,1(2021),81–92. https://doi.org/ together:understandingreasonsforwatchingDanmakuvideos.International
10.1109/TLT.2021.3058644 JournalofHuman–ComputerInteraction33,9(2017),731–743.
[2] NalanAksakal.2015. Theoreticalviewtotheapproachoftheedutainment. [23] VasoConstantinou,AndriIoannou,IosifKlironomos,MargheritaAntona,and
Procedia-SocialandBehavioralSciences186(2015),1232–1239. ConstantineStephanidis.2020.Technologysupportfortheinclusionofdeafstu-
[3] SedeeqAl-khazraji,BeccaDingman,SooyeonLee,andMattHuenerfauth.2021. dentsinmainstreamschools:asummaryofresearchfrom2007to2017.Universal
AtaDifferentPace:EvaluatingWhetherUsersPreferTimingParametersin AccessintheInformationSociety19(2020),195–200.
AmericanSignLanguageAnimationstoDifferfromHumanSigners’Timing.In [24] MathieuDeCoster,DimitarShterionov,MiekeVanHerreweghe,andJoniDambre.
Proceedingsofthe23rdInternationalACMSIGACCESSConferenceonComputers 2023. Machinetranslationfromsignedtospokenlanguages:stateoftheart
andAccessibility.1–12. andchallenges. UniversalAccessintheInformationSociety(apr2023). https:
[4] MuhammadAliandAnzaNasir.2023.InvestigatingtheSocialMediaPractices //doi.org/10.1007/s10209-023-00992-1
amongAurallyChallengedStudents(ACS):TheChallengesandIssues.Human [25] GeoffreyRestallCoulter.1979.Americansignlanguagetypology.Universityof
NatureJournalofSocialSciences4,1(2023),518–532. California,SanDiego.
[5] WajdiAljedaani,RrezartaKrasniqi,SanaaAljedaani,MohamedWiemMkaouer, [26] ShaneDawson.2006.Astudyoftherelationshipbetweenstudentcommunication
StephanieLudi,andKhaledAl-Raddah.2022.Ifonlinelearningworksforyou, interactionandsenseofcommunity.TheInternetandHigherEducation9,3(2006),
whataboutdeafstudents?Emergingchallengesofonlinelearningfordeafand 153–162.
hearing-impairedstudentsduringCOVID-19:aliteraturereview.Universalaccess [27] DidanDeng,ZhaokangChen,andBertramEShi.2020. Multitaskemotion
intheinformationsociety(2022),1–20. recognitionwithincompletelabels.In202015thIEEEInternationalConferenceon
[6] RikuArakawa,ZendaiKashino,ShinnosukeTakamichi,AdrienVerhulst,and AutomaticFaceandGestureRecognition(FG2020).IEEE,592–599.
MasahikoInami.2021.DigitalSpeechMakeup:VoiceConversionBasedAltered [28] AashakaDesai,LaurenBerger,FyodorOMinakov,VanessaMilan,Chinmay
AuditoryFeedbackforTransformingSelf-Representation.InProceedingsofthe Singh,KristonPumphrey,RichardELadner,HalDauméIII,AlexXLu,Naomi
2021InternationalConferenceonMultimodalInteraction.159–167. Caselli,etal.2023.ASLCitizen:ACommunity-SourcedDatasetforAdvancing
[7] RikuArakawaandHiromuYakura.2021.MindlessAttractor:AFalse-Positive IsolatedSignLanguageRecognition.arXivpreprintarXiv:2304.05934(2023).
ResistantInterventionforDrawingAttentionUsingAuditoryPerturbation.In [29] A’diDust,CarolaGonzalez-Lebron,ShannonConnell,SauravSingh,Reynold
Proceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems. Bailey,CeciliaOvesdotterAlm,andJamisonHeard.2023.UnderstandingDiffer-
1–15. encesinHuman-RobotTeamingDynamicsbetweenDeaf/HardofHearingand
[8] CharlotteBaker-Shenk.1985.Thefacialbehaviorofdeafsigners:Evidenceofa HearingIndividuals.InCompanionofthe2023ACM/IEEEInternationalConference
complexlanguage.AmericanAnnalsoftheDeaf 130,4(1985),297–304. onHuman-RobotInteraction.552–556.
[9] GeorginaBatten,PeterMOakes,andTimAlexander.2014.Factorsassociatedwith [30] MicheleFriednerandAnneliesKusters.2015. It’sasmallworld:International
socialinteractionsbetweendeafchildrenandtheirhearingpeers:Asystematic deafspacesandencounters.GallaudetUniversityPress.
literaturereview.Journalofdeafstudiesanddeafeducation19,3(2014),285–302. [31] SandraGHartandLowellEStaveland.1988.DevelopmentofNASA-TLX(Task
[10] HDirksenBaumanandJosephMurray.2009.Reframing:Fromhearinglossto LoadIndex):Resultsofempiricalandtheoreticalresearch.InAdvancesinpsy-
deafgain.DeafStudiesDigitalJournal1,1(2009),1–10. chology.Vol.52.Elsevier,139–183.
[11] LarwanBerke,KhaledAlbusays,MatthewSeita,andMattHuenerfauth.2019. [32] SaadHassan,MatthewSeita,LarwanBerke,YingliTian,ElaineGale,Sooyeon
Preferredappearanceofcaptionsgeneratedbyautomaticspeechrecognition Lee,andMattHuenerfauth.2022.ASL-Homework-RGBDDataset:Anannotated
fordeafandhard-of-hearingviewers.InExtendedAbstractsofthe2019CHI datasetof45fluentandnon-fluentsignersperformingAmericanSignLanguage
ConferenceonHumanFactorsinComputingSystems.1–6. homeworks.arXivpreprintarXiv:2207.04021(2022).
[12] LarwanBerke,MatthewSeita,andMattHuenerfauth.2020.Deafandhard-of- [33] ChangyangHe,LuHe,TunLu,andBoLi.2021.BeyondEntertainment:Unpacking
hearingusers’prioritizationofgenresofonlinevideocontentrequiringaccurate DanmakuandComments’RoleofInformationSharingandSentimentExpression
captions.InProceedingsofthe17thInternationalWebforAllConference.1–12. inOnlineCrisisVideos.ProceedingsoftheACMonHuman-ComputerInteraction
[13] BhavyaBhavya,SiChen,ZhilinZhang,WentingLi,ChengxiangZhai,Lawrence 5,CSCW2(2021),1–27.
Angrave,andYunHuang.2022. Exploringcollaborativecaptioneditingto [34] CarlJensema,RalphMcCann,andScottRamsey.1996.Closed-captionedtele-
augmentvideo-basedlearning.Educationaltechnologyresearchanddevelopment visionpresentationspeedandvocabulary.AmericanAnnalsofthedeaf (1996),
70,5(2022),1755–1779. 284–292.
[14] DanielleBragg,OscarKoller,MaryBellard,LarwanBerke,PatrickBoudreault, [35] SushantKafleandMattHuenerfauth.2016.Effectofspeechrecognitionerrors
AnneliesBraffort,NaomiCaselli,MattHuenerfauth,HernisaKacorri,Tessa ontextunderstandabilityforpeoplewhoaredeaforhardofhearing.(2016).
Verhoef,etal.2019. Signlanguagerecognition,generation,andtranslation: [36] KarenLKritzerandChadESmith.2020. Educatingdeafandhard-of-hearing
Aninterdisciplinaryperspective.InProceedingsofthe21stInternationalACM studentsduringCOVID-19:Whatparentsneedtoknow.TheHearingJournal73,
SIGACCESSConferenceonComputersandAccessibility.16–31. 8(2020),32.
[15] DanielleBragg,OscarKoller,NaomiCaselli,andWilliamThies.2020.Exploring [37] RajaKushalnagar,MatthewSeita,andAbrahamGlasser.2017. ClosedASL
collectionofsignlanguagedatasets:Privacy,participation,andmodelperfor- interpretingforonlinevideos.InProceedingsofthe14thInternationalWebforAll
mance.InProceedingsofthe22ndInternationalACMSIGACCESSConferenceon Conference.1–4.
ComputersandAccessibility.1–14. [38] ImaneLasri,AnouarRiadSolh,andMouradElBelkacemi.2019. Facialemo-
[16] JosephCheeChang,AmyXZhang,JonathanBragg,AndrewHead,KyleLo,Doug tionrecognitionofstudentsusingconvolutionalneuralnetwork.In2019third
Downey,andDanielSWeld.2023.CiteSee:AugmentingCitationsinScientific internationalconferenceonintelligentcomputingindatasciences(ICDS).IEEE,
PaperswithPersistentandPersonalizedHistoricalContext.InProceedingsofthe 1–6.
2023CHIConferenceonHumanFactorsinComputingSystems.1–15. [39] SooyeonLee,AbrahamGlasser,BeccaDingman,ZhaoyangXia,DimitrisMetaxas,
[17] SiChen,DesiréeKirst,QiWang,andYunHuang.2023.ExploringThink-Aloud CarolNeidle,andMattHuenerfauth.2021. Americansignlanguagevideo
MethodwithDeafandHardofHearingCollegeStudents.InProceedingsofthe anonymizationtosupportonlineparticipationofdeafandhardofhearingusers.
2023ACMDesigningInteractiveSystemsConference(Pittsburgh,PA,USA)(DIS InProceedingsofthe23rdInternationalACMSIGACCESSConferenceonComputers
’23).AssociationforComputingMachinery,NewYork,NY,USA,1757–1772. andAccessibility.1–13.
https://doi.org/10.1145/3563657.3595980 [40] FranklinMingzheLi,ChengLu,ZhicongLu,PatrickCarrington,andKhaiN
[18] SiChen,DennisWang,andYunHuang.2021. Exploringthecomplementary Truong.2022.Anexplorationofcaptioningpracticesandchallengesofindividual
featuresofaudioandtextnotesforvideo-basedlearninginmobilesettings.In contentcreatorsonYouTubeforpeoplewithhearingimpairments.arXivpreprint
ExtendedAbstractsofthe2021CHIConferenceonHumanFactorsinComputing arXiv:2201.11226(2022).
Systems.1–7.CHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
[41] ShugangLi,HeZhu,YingQian,ShiqiRen,andBingFang.2022.Classificationand [65] KattaSpielandRobinAngelini.2022.ExpressiveBodiesEngagingwithEmbodied
quantificationofDanmakuInteractionsinonlinevideolectures:Anexploratory DisabilityCulturesforCollaborativeDesignCritiques.InProceedingsofthe24th
study. https://www.hindawi.com/journals/wcmc/2022/5656669/ InternationalACMSIGACCESSConferenceonComputersandAccessibility.1–6.
[42] ZimingLi,ShannonConnell,WendyDannels,andRoshanPeiris.2022.Sound- [66] MichaelStinsonandShirinAntia.1999.Considerationsineducatingdeafand
VizVR:SoundIndicatorsforAccessibleSoundsinVirtualRealityforDeafor hard-of-hearingstudentsininclusivesettings.Journalofdeafstudiesanddeaf
Hard-of-HearingUsers.InConferenceonComputersandAccessibility(ASSETS’22). education4,3(1999),163–175.
[43] JunfengLiao,RundongLi,HuizhongLiao,andJunkaiHuang.2023.Researchon [67] ShengengTang,DanGuo,RichangHong,andMengWang.2021.Graph-based
theInfluencingFactorsofOnlineVideoDanmakuWatchingandParticipation. multimodalsequentialembeddingforsignlanguagetranslation.IEEETransac-
In20234thInternationalConferenceonEducation,KnowledgeandInformation tionsonMultimedia24(2021),4433–4445.
Management(ICEKIM2023).AtlantisPress,711–721. [68] DavidRThomas.2006.Ageneralinductiveapproachforanalyzingqualitative
[44] XiLin,MingyuHuang,andLeslieCordie.2018. Anexploratorystudy:using evaluationdata.Americanjournalofevaluation27,2(2006),237–246.
Danmakuinonlinevideo-basedlectures.EducationalMediaInternational55,3 [69] ElenaTomasuolo,TizianaGulli,VirginiaVolterra,andSabinaFontana.2021.The
(2018),273–286. ItalianDeafcommunityatthetimeofCoronavirus.FrontiersinSociology5(2021),
[45] KellyMack,DanielleBragg,MeredithRingelMorris,MaartenWBos,Isabelle 125.
Albi,andAndrésMonroy-Hernández.2020. Socialappaccessibilityfordeaf [70] EhsanToofaninejad,EsmaeilZaraiiZavaraki,ShaneDawson,OleksandraPoquet,
signers. ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW2 andParvizSharifiDaramadi.2017.Socialmediausefordeafandhardofhearing
(2020),1–31. studentsineducationalsettings:asystematicreviewofliterature.Deafness&
[46] MarcMarschark,PatriciaSapere,CarolConvertino,andRosemarieSeewagen. EducationInternational19,3-4(2017),144–161.
2005. Accesstopostsecondaryeducationthroughsignlanguageinterpreting. [71] AshleyWalker,YaxingYao,ChristineGeeng,RobertoHoyle,andPamelaWis-
JournalofDeafStudiesanddeafeducation10,1(2005),38–50. niewski. 2019. Moving beyond ’one size fits all’: research considerations
[47] EmmaMcDonnell.2022. UnderstandingSocialandEnvironmentalFactorsto forworkingwithvulnerablepopulations. Interactions26(102019),34–39.
EnableCollectiveAccessApproachestotheDesignofCaptioningTechnology.In https://doi.org/10.1145/3358904
Proceedingsofthe24thInternationalACMSIGACCESSConferenceonComputers [72] TraciPatriciaWeast.2008.QuestionsinAmericanSignLanguage:Aquantitative
andAccessibility.1–8. analysisofraisedandloweredeyebrows.TheUniversityofTexasatArlington.
[48] NayanMehta,SurajPai,andSanjaySingh.2020.Automated3Dsignlanguage [73] QunfangWu,YisiSang,andYunHuang.2019.Danmaku:Anewparadigmof
captiongenerationforvideo.UniversalAccessintheInformationSociety19(2020), socialinteractionviaonlinevideos.ACMTransactionsonSocialComputing2,2
725–738. (2019),1–24.
[49] RossMitchell,TravasYoung,BellamieBachleda,andMichaelKarchmer.2006. [74] QunfangWu,YisiSang,ShanZhang,andYunHuang.2018.Danmakuvs.forum
HowManyPeopleUseASLintheUnitedStates?WhyEstimatesNeedUpdating. comments:understandinguserparticipationandknowledgesharinginonline
SignLanguageStudies6(032006). https://doi.org/10.1353/sls.2006.0019 videos.InProceedingsofthe2018ACMInternationalConferenceonSupporting
[50] HudaShaabanAwedMohammadAhmedHammad.2023.InvestigatingSocial GroupWork.209–218.
MediaUsageAmongtheDeafandHardofHearingStudents.JournalofSouthwest [75] HaijunXia,HuiXinNg,ZhutianChen,andJamesHollan.2022.Millionsand
JiaotongUniversity58,1(2023). billionsofviews:Understandingpopularscienceandknowledgecommunication
[51] UnitedNations.2022. https://www.un.org/en/coronavirus/disability-inclusion onvideo-sharingplatforms.InProceedingsoftheNinthACMConferenceon
[52] OmidNoroozi,HéctorJPijeira-Díaz,MartaSobocinski,MuhteremDindar,Sanna Learning@Scale.163–174.
Järvelä,andPaulAKirschner.2020.Multimodaldataindicatorsforcapturing [76] ShuaiYang,LimingJiang,ZiweiLiu,andChenChangeLoy.2022. Vtoonify:
cognitive,motivational,andemotionallearningprocesses:Asystematicliterature Controllablehigh-resolutionportraitvideostyletransfer.ACMTransactionson
review.EducationandInformationTechnologies25(2020),5499–5547. Graphics(TOG)41,6(2022),1–15.
[53] CarolPadden,TomHumphries,andCarolPadden.2009. Insidedeafculture. [77] YaxingYao,JenniferBort,andYunHuang.2017. UnderstandingDanmaku’s
HarvardUniversityPress. potentialinonlinevideolearning.InProceedingsofthe2017CHIconference
[54] SoraiaPrietch,JAlfredoSánchez,andJosefinaGuerrero.2022. ASystematic extendedabstractsonhumanfactorsincomputingsystems.3034–3040.
ReviewofUserStudiesasaBasisfortheDesignofSystemsforAutomaticSign [78] MeehyunYoon,JungeunLee,andIl-HyunJo.2021. Videolearninganalytics:
LanguageProcessing.ACMTransactionsonAccessibleComputing15,4(2022), Investigatingbehavioralpatternsandlearnerclustersinvideo-basedonline
1–33. learning.TheInternetandHigherEducation50(2021),100806.
[55] SrijithRadhakrishnan,NikhilCMohan,ManisimhaVarma,JaithraVarma,and [79] KexinZhang,ElmiraDeldari,ZhicongLu,YaxingYao,andYuhangZhao.2022.
SmithaNPai.2022. CrossTransferringActivityRecognitiontoWordLevel “It’sJustPartofMe:”UnderstandingAvatarDiversityandSelf-presentation
SignLanguageDetection.InProceedingsoftheIEEE/CVFConferenceonComputer ofPeoplewithDisabilitiesinSocialVirtualReality.InProceedingsofthe24th
VisionandPatternRecognition.2446–2453. InternationalACMSIGACCESSConferenceonComputersandAccessibility.1–16.
[56] HidayahBintiRahmalan,ZuraidaBintiAbalAbas,ZaheeraBintiZainalAbidin, [80] YuZhang,ChangyangHe,HuanchenWang,andZhicongLu.2023.Understanding
AbdulSamadBinShibghatullah,AhmadFadzliNizamBinAbdulRahman, CommunicationStrategiesandViewerEngagementwithScienceKnowledge
ChongWeiShin,etal.2018.EdutainmentToolsforDeafandImpairmentHearing VideosonBilibili.InProceedingsofthe2023CHIConferenceonHumanFactorsin
Children:ASurvey.AdvancedScienceLetters24,3(2018),1805–1808. ComputingSystems(Hamburg,Germany)(CHI’23).AssociationforComputing
[57] RaziehRastgoo,KouroshKiani,andSergioEscalera.2021.Signlanguagerecog- Machinery,NewYork,NY,USA,Article668,18pages. https://doi.org/10.1145/
nition:Adeepsurvey.ExpertSystemswithApplications164(2021),113794. 3544548.3581476
[58] FilipaMRodrigues,JoanaRRato,AnaMineiro,andIngelaHolmström.2022.
Unveilingteachers’beliefsonvisualcognitionandlearningstylesofdeafand
hardofhearingstudents:APortuguese-Swedishstudy. Plosone17,2(2022),
e0263216.
[59] AlfredPRovai.2002. Developmentofaninstrumenttomeasureclassroom
community.TheInternetandhighereducation5,3(2002),197–211.
[60] MarijaSablić,AnaMirosavljević,andAlmaŠkugor.2021.Video-basedlearning
(VBL)—past,presentandfuture:Anoverviewoftheresearchpublishedfrom
2008to2019.Technology,KnowledgeandLearning26,4(2021),1061–1077.
[61] BenSaunders,NecatiCihanCamgoz,andRichardBowden.2022. Signingat
scale:Learningtoco-articulatesignsforlarge-scalephoto-realisticsignlanguage
production.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition.5141–5151.
[62] JeffSeamanandHesterTinti-Kane.2013.Socialmediaforteachingandlearning.
PearsonLearningSystemsLondon.
[63] MatthewSeita,KhaledAlbusays,SushantKafle,MichaelStinson,andMattHuen-
erfauth.2018.Behavioralchangesinspeakerswhoareautomaticallycaptioned
inmeetingswithdeaforhard-of-hearingpeers.InProceedingsofthe20thInter-
nationalACMSIGACCESSConferenceonComputersandAccessibility.68–80.
[64] UmeshSharmaandSpencerJSalend.2016. Teachingassistantsininclusive
classrooms:Asystematicanalysisoftheinternationalresearch. Australian
JournalofTeacherEducation(Online)41,8(2016),118–134.Signmaku:SignLanguageDanmaku CHI’24,May11–16,2024,Honolulu,HI,USA
A APPENDICES
A.1 SurveyQuestions
Below,wepresentthesurveyquestionsusedinourPhaseIIevaluationstudy.Note:Inthesurveys,weusedtheterm“ASL-basedDanmaku”
insteadof“signmaku.”Thethreetypesofsignmakuswerealsoreferredtousingdifferenttermsforeasierunderstanding:realisticsignmakus
werereferredtoas“ASL-onlycomments;”cartoonsignmakuswerereferredtoas“CartoonASLcomments;”androboticsignmakuswere
referredtoas“RobotASLcomments.”
A.1.1 Part1:ThreetypesofSignmakusforVideo-basedLearning. DanmakuisaYouTube-likevideo-sharingplatform.Viewers’comments
appearonthescreenandeachcommentcanbecustomized(e.g.,size,color,etc.).Thecommentsgobeyondreal-time,withpreviousand
latercommentsbeingshowntogether.
Inourtool,youexperiencedthreetypesofASL-basedDanmaku:ASL-onlycomments,CartoonASLcomments,andRobotASLcomments.
RankhowmuchyouenjoyedthethreeASL-basedDanmakutypesyousawinthevideo.(Tiedrankingisnotallowed.).
RealisticSignmakus.
• Howmentallydemandingwasviewingthepop-upASL-onlycomments?Mentallydemandingreferstoactions(e.g.,thinking,
deciding,remembering,looking,searching,etc.)thatwerehardtodoWHILEviewingtheASL-onlycomments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowphysicallydemandingwasviewingtheASL-onlycomments?Physicallydemandingreferstoactions(e.g.,clicking,pausing,
movingbodyforwardtoread,switchingeyegazebetweenfeatures,etc.)thatwerehardtodoWHILEviewingtheASL-onlycomments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowmuchtimepressuredidyoufeelviewingtheASL-onlycommentsandthevideoatthesametime?Wasthepaceslow&
relaxedORrapid&rushed?
Chooseona10-pointLikertscale,where1isSlow&Relaxedand10isRapid&Rushed.
CartoonSignmakus.
• Howmentallydemandingwasviewingthepop-upCartoonASLcomments?Mentallydemandingreferstoactions(e.g.,thinking,
deciding,remembering,looking,searching,etc.)thatwerehardtodoWHILEviewingtheCartoonASLcomments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowphysicallydemandingwasviewingtheCartoonASLcomments?Physicallydemandingreferstoactions(e.g.,clicking,
pausing,movingbodyforwardtoread,switchingeyegazebetweenfeatures,etc.)thatwerehardtodoWHILEviewingtheCartoon
ASLcomments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowmuchtimepressuredidyoufeelviewingtheCartoonASLcommentsandthevideoatthesametime?Wasthepaceslow&
relaxedORrapid&rushed?
Chooseona10-pointLikertscale,where1isSlow&Relaxedand10isRapid&Rushed.
RoboticSignmakus.
• Howmentallydemandingwasviewingthepop-upRobotASLcomments?Mentallydemandingreferstoactions(e.g.,thinking,
deciding,remembering,looking,searching,etc.)thatwerehardtodoWHILEviewingtheRobotASLcomments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowphysicallydemandingwasviewingtheRobotASLcomments?Physicallydemandingreferstoactions(e.g.,clicking,pausing,
movingbodyforwardtoread,switchingeyegazebetweenfeatures,etc.)thatwerehardtodoWHILEviewingtheRobotASL
comments.
Chooseona10-pointLikertscale,where1isEasy(lowdemand)and10isHard(highdemand).
• HowmuchtimepressuredidyoufeelviewingtheRobotASLcommentsandthevideoatthesametime?Wasthepaceslow&
relaxedORrapid&rushed?
Chooseona10-pointLikertscale,where1isSlow&Relaxedand10isRapid&Rushed.
A.1.2 Part2:PerceivedSenseofCommunityforLearning.(20Questions). These20questionsweredevelopedbasedonRovai’sClassroom
CommunityScales[26,59].Thequestionsweredividedinto2setsof10questionsmeasuringtwofactors:connectednessandlearning.Below,
wepresentthesetwosetsofquestionsseparately.Thenumberbeforeeachquestionrepresentstheorderofappearance.Foreachquestion,
participantsmaychoosebetweenthefollowingoptions:Stronglydisagree,Disagree,Neutral,Agree,Stronglyagree,whichisconvertedto1-5
intheanalysis,andcertainstatements’answersareconvertedto5-1accordingto[26,59].
First,rankhowmuchyouenjoyedprovidingthreeASL-basedDanmakutofuturelearners.(Tiedrankingisnotallowed.)
Then,answerthefollowingquestions.Whenwereferto“tool”,pleaseconsideryoucreatingandsharingyourownASLcomments.
SenseofConnectedness:Comparedtousingvideotolearnbymyself,
1. Ifeelstudentsusingthistoolcareabouteachothers.
3. Ifeelconnectedtoothersusingthistool.CHI’24,May11–16,2024,Honolulu,HI,USA SiChen,HaocongCheng,JasonSitu,DesiréeKirst,SuzySu,SaumyaMalhotra,LawrenceAngrave,QiWang,andYunHuang
5. IdoNOTfeelasenseofcommunityusingthistool.
7. Ifeelusingthistoolislikefamily.
9. Ifeelisolatedusingthistool.
11. Itrustothersusingthistool.
13. IfeelIcanrelyonothersusingthistool.
15. Ifeellikeothersusingthistooldependonme.
17. Ifeeluncertainaboutothersusingthistool.
19. Ifeelconfidentotherswillsupportmeusingthistool.
SenseofLearning:Comparedtousingvideotolearnbymyself,
2. IfeelIamencouragedtoaskquestionsusingthistool.
4. IfeelithardtogethelpwhenIhaveaquestionusingthistool.
6. IfeelIreceivetimelyfeedbackusingthistool.
8. IfeelUNeasythatthistoolexposesgapsinmyunderstanding.
10. Ifeelreluctanttosign/speakopenlyusingthistool.
12. Ifeelusingthistoolresultsinonlymodestlearning.
14. IfeelothersdoNOThelpmelearnusingthistool.
16. IfeelIamgivenplentyopportunitiestolearnusingthistool.
18. IfeelmyeducationalneedsareNOTbeingmetusingthistool.
20. IfeelthatusingthistooldoesNOTpromotemydesiretolearn.
A.1.3 DemographicsInformation.
• Whatisyourstatusasundergraduatestudent?
Chooseoneofthefollowing:Freshman;Sophomore;Junior;Senior;Other:[textbox].
• Whatisyourgenderidentity?
[textbox]
• Whatisyourethnicity?
[textbox]
• Whatisyourage?
[textbox]
• Howdoyouidentify(withintheDeafcommunity)?
Chooseoneofthefollowing:Deaf;HardofHearing;Hearing.
• Whichofthefollowingstatementsistrueaboutyourimmediatefamily(parentsandsiblings)?
Chooseoneofthefollowing:Oneormoreofmyfamilymembersaredeaforhardofhearing;Noneofmyimmediatefamilymembersis
deaforhardofhearing.
• Whatlanguagedidyouusegrowingupinface-to-facecommunication?
Rankthefollowingoptions:English;OtherSPOKENlanguage;ASL;OtherSIGNlanguage.Participantsmaychoose“Doesnotapply”for
anyoftheoptions.
• AtwhatagedidyoulearnASL?
Choose“Frombirth(0-12months)”oranynumberfromdropdownbox.
• Whatisyourcountryoforigin?
[textbox]
• IsEnglishyour1stwrittenlanguage?
Chooseoneofthefollowing:Yes;No.
• Whichareyoumostcomfortablewithasaclassroominstructionallanguage?
Chooseoneofthefollowing:ASL;English;BothASLandEnglish.
• Whatisyourmajor(orplannedmajor)?
[textbox]