Scalable Non-Cartesian Magnetic Resonance
Imaging with R2D2
Yiwei Chen1, Chao Tang1,2, Amir Aghabiglou1, Chung San Chu1, Yves Wiaux1†
1Institute of Sensors, Signals and Systems, Heriot-Watt University, Edinburgh EH14 4AS, United Kingdom
2EPCC, University of Edinburgh, Edinburgh EH8 9BT, United Kingdom
Email: †y.wiaux@hw.ac.uk
Abstract—Weproposeanewapproachfornon-Cartesianmag- wherey ∈CM denotesthek-spacemeasurements,Φ: RN →
netic resonance image reconstruction. While unrolled architec- CM isanon-uniformFouriersamplingmeasurementoperator,
tures provide robustness via data-consistency layers, embedding x¯ ∈ RN is the Ground Truth (GT) image and n ∈ CM
measurement operators in Deep Neural Network (DNN) can +
representsacomplex-valuedGaussianrandomnoisefollowing
become impractical at large scale. Alternative Plug-and-Play
(PnP) approaches, where the denoising DNNs are blind to the N(0,τ2). Φ can be implemented via the Non-Uniform Fast
measurementsetting,arenotaffectedbythislimitationandhave Fourier Transform (NUFFT), i.e. as the product of U,F,Z,
alsoproveneffective,buttheirhighlyiterativenaturealsoaffects whereZisazero-paddingoperator,FdenotestheFastFourier
scalability. To address this scalability challenge, we leverage
Transform (FFT), and U is an interpolation operator.
the “Residual-to-Residual DNN series for high-Dynamic range
To accelerate the acquisition process, reducing the number
imaging (R2D2)” approach recently introduced in astronomical
imaging. R2D2’s reconstruction is formed as a series of residual of k-space measurements is common. DNN models like PnP
images, iteratively estimated as outputs of DNNs taking the algorithms [3] and unrolled networks [4] have gained atten-
previous iteration’s image estimate and associated data residual tion for their promising performance on undersampled MRI
as inputs. The method can be interpreted as a learned version
data. PnP algorithms, bridging optimization theory and deep
of the Matching Pursuit algorithm. We demonstrate R2D2
learning, train denoising DNNs deployed within optimization
in simulation, considering radial k-space sampling acquisition
sequences. Our preliminary results suggest that R2D2 achieves: algorithms to replace handcrafted regularization operators.
(i)suboptimalperformancecomparedtoitsunrolledincarnation While effective and unaffected by measurement settings, they
R2D2-Net, which is however non-scalable due to the necessary face scalability challenges due to their highly iterative na-
embedding of NUFFT-based data-consistency layers; (ii) supe-
ture. Unrolled DNNs ensure the consistency between the
rior reconstruction quality to a scalable version of R2D2-Net
reconstructions and measurements by mirroring optimization
embedding an FFT-based approximation for data consistency;
(iii) superior reconstruction quality to PnP, while only requiring algorithmiterationsacrosslayers,achievinghighimagingpre-
few iterations. cision in non-Cartesian MRI. However, in large-dimensional
settings, typically when a high number of acquisition coils
I. INTRODUCTION are involved or in 3D or 4D dynamic MRI [5], embedding
NUFFT operators into DNN architectures entails large com-
MagneticResonanceImaging(MRI)enableshigh-precision
putational cost and memory requirements at both training and
reconstructionofstructuresandorganswithinthehumanbody
inference stages. These can rapidly become prohibitive due to
via the interaction of magnetic fields and radio waves. In
corresponding limitation of GPU hardware [4].
MRI, signals are measured in the spatial frequency domain,
Recently, the R2D2 approach, a learned variant of the
namely k-space, using multiple receiver coils. The complex-
Matching Pursuit approach [6], has been demonstrated to
valuedMRimageisreconstructedbasedontheinverseFourier
deliver a new regime of joint image reconstruction quality
transform. For this proof of concept and without loss of
and speed in radio astronomical imaging [7], [8], [9]. R2D2’s
generality, similarly to [1], we consider real-valued positive
reconstruction is formed as a series of residual images, it-
images,whichwouldcorrespondtothemagnitudeofcomplex-
eratively estimated as outputs of DNNs taking the previous
valued MR images. We also restrict the study to a single-coil
iteration’s image estimate and associated back-projected data
setting. We consider non-Cartesian k-space sampling, more
residualasinputs.IncontrastwithanunrolledDNNapproach,
precisely radial sampling sequences, which are commonly
R2D2 thus utilizes a series of DNNs without embedding
used and possess advantages such as reduced motion artifacts
the measurement operator into their individual architectures.
in dynamic scenes [2]. The acquisition process can thus be
Interestingly,thenumberofrequirednetworks(iterations)was
formulated as
shown to be extremely small compared to the typical number
y =Φx¯+n, (1) of iterations of a PnP algorithm.
We propose two unrolled variants of the R2D2 model,
The work was supported by EPSRC under grants EP/T028270/1 and named R2D2-Net (FFT) and R2D2-Net (NUFFT), embed-
ST/W000970/1.ComputingresourcescamefromtheCirrusUKNationalTier-
ding distinct data-consistency layers, respectively based on
2 HPC Service at EPCC (http://www.cirrus.ac.uk) funded by the University
ofEdinburghandEPSRC(EP/P020267/1). the NUFFT and an FFT approximation. Preliminary results
4202
raM
62
]VI.ssee[
1v50971.3042:viXrasuggest that R2D2 naturally exhibits suboptimal performance C. R2D2-Net
compared to the R2D2-Net (NUFFT), which, however, is
Formally, an unrolled variant of R2D2, named R2D2-Net
non-scalable due to the essential embedding of NUFFT-based
[8], can be developed by unrolling the R2D2 approach itself,
data-consistency layers. However, R2D2 largely outperforms
with a predetermined number of internal iterations. Two im-
the scalable R2D2-Net (FFT) variant. With respect to the
plementations,distinguishedbydata-consistencycomputation,
state of the art, R2D2 also largely outperforms the (non-
areconsidered.Thefirst,denotedbyR2D2-Net(NUFFT),uses
scalable)unrollednetworknamedNC-PDNet,alsoembedding
the exact measurement operator based on the NUFFT to cal-
the NUFFT [4], and a (non-scalable) PnP benchmark [10].
culatethedataconsistency.Topromotescalability,weemploy
an FFT approximation of the exact measurement operator to
II. METHODOLOGY estimatethedataconsistency.Firstly,thepointspreadfunction
image is calculated as h = κRe{Φ†Φδ} ∈ RN. Secondly,
A. R2D2 approach
we replace κRe{Φ†Φ} by Re{F†(Fh)F}, where the FFT
Givenanimageestimatex,theback-projecteddataresidual operatoranditsadjointaredenotedbyFandF†,respectively.
denoted by r, also named the data-consistency term [11], is Note that Fh is precomputed once and stored. Although this
given by mapping to the back-projected data space is approximate, it
r =x −κRe{Φ†Φx}, (2) is fast and memory-efficient. This substitution results in a
d
scalable unrolled DNN denoted by R2D2-Net (FFT).
where x = κRe{Φ†y} is the data back-projected from the
d D. Normalization procedures
raw measurements. Here, κ = 1/max(Re{Φ†Φδ}) is the
Normalization procedures are employed to avoid general-
normalization parameter with δ being the Dirac image with
izability issues arising from large variations in pixel value
the central pixel value as 1 and others as 0.
ranges and stabilize the training process. An iteration-specific
The R2D2 approach aims to utilize the previous image
normalization factor for the i-th network is denoted as αi−1
estimate xi−1 and corresponding ri−1 to reduce the discrep-
and given by the mean pixel value of the previous estimate
ancies between the image estimate and GT image by a series
xi−1. Note that α0 is the mean pixel value of x . In training,
of DNNs, denoted as {G } , with learnable parameters d
θi 1≤i≤I x¯,xi−1 andri−1 aredividedbyαi−1.Attheinferencestage,
denoted as {θ } . The iteration structure reads
i 1≤i≤I the normalization mapping: G (·) (cid:55)→ αi−1G (·/αi−1) is
θi θi
xi =xi−1+G (ri−1,xi−1), (3) applied to each subnetwork to make the input normalized and
θi
the output denormalized accordingly.
with the initialized image estimate and back-projected data
E. Related works
residual as x0 = 0 and r0 = x , respectively. DNNs are
d
Firstly, compared to PnP algorithms, DNNs in R2D2 aim
trained sequentially. Specifically, for the i-th DNN, the loss
to learn high-level features rather than being trained solely as
function is defined as:
denoisers[3].Secondly,incontrasttounrolledDNNs[11],[4],
1 (cid:88)K R2D2 externalizes the data consistency calculation from the
m θi in
K
k=1∥x¯ k−[xi k−1+G θi(r ki−1,xi k−1)] +∥ 1, (4) n tae tt iw ono ar lk cs otr su tc ot fu Nre U.T Fh Fi Tss intra trt ae ig ny inr ge ,li le ev ae ds inth ge tosi bg en ti tfi ec ra sn ct ac lao bm ilp itu y-
.
Formally, R2D2-Net shares the same network architecture as
where ∥·∥ is the L1 norm, K is the number of training
1
NC-PDNet [4], with the key distinction being that the core
samples, and [·] denotes the projection onto the positive
+
orthant RN. subnetwork architecture of R2D2-Net is a U-Net instead of a
+ shallow convolution neural network. Furthermore, R2D2-Net
At the inference stage, the last output of the DNN series
introduces a novel variant employing the FFT approximation
denoted as xI gives the final reconstruction. It is noteworthy
to enhance scalability.
thatthefirstiterationofR2D2isequivalenttoastandardend-
to-end learning approach. III. DATASIMULATION
A. Denoised GT images
B. DNN structure
WeadoptthemagnitudeMRimageswithasizeof320×320
ThestandardU-Net[12]servesasthefoundationalstructure from the FastMRI single-coil knee dataset [13]. As depicted
for DNNs, featuring both a contracting and expanding path. in Fig. 1 (a), the raw GT image exhibits noticeable noise. To
The contracting path integrates multiple convolutional and improvetheimagequalityandgeneratek-spacemeasurements
pooling layers to gradually reduce the spatial dimensions of with diverse noise levels, the raw images undergo preprocess-
the input image. Conversely, the expanding path incorporates ing by the denoising network SCUNet [14], followed by soft-
convolutional and upsampling layers to progressively upsam- thresholding to remove residual backgrounds. The denoised
ple the feature maps, resulting in an output with identical imageisthennormalizedwithintensitiesrangingfrom0to1.
dimensions to the input image. Skip connections are added We split denoised images into training and validation datasets
to link layers between the contracting and expanding paths. consisting of 25743 and 6605 images, respectively.(a) E. Noise
RawGT DenoisedGT
Inourdataset,thehighestintensityofGTimagesis1dueto
Denoising the normalization. The faintest image intensity, denoted by σ,
is the standard deviation of the background Gaussian noise in
the image domain, which is predicated on the assumption that
allpredictableintensitiessurpassthenoiselevel.TheDynamic
(b)
DenoisedGT NoisyMeasurements Dirty Range (DR) is defined as the ratio between the intensities of
the maximum and faintest features, which in our dataset is
+ specificallythereciprocalofσ.WeconfiguredtheDRtospan
from 10 to 104, covering both low- and high-noise samples,
facilitating robust evaluation of imaging methods. Following
[16], we model the relationship between the additive noise
Fig. 1. Data simulation process. (a) Denoising the raw GT image; (b) in the k-space and its back-projection in the image domain
Generatingthesimulatedmeasurementsandback-projectedimage. as τ = (cid:112) 2L2/L σ , where L and L are the spectral norm
p n p
of the measurement operator when the weighting is applied
B. Radial sampling
once and twice, respectively. Setting σ =σ ensures that the
n
Radial sampling starts at the centre of k-space and ex- Gaussian noise in the synthetic measurements preserves the
tends outward in an angular fashion. The radial sampling DR of the GT images.
trajectory in k-space is formulated as k (n) = rcos(α ),
x n F. Details of the data generation
k (n)=rsin(α ), where k (n) and k (n) are the Cartesian
y n x y
In training, we randomly selected N from the integer set
coordinates of the sampled point at the n-th spoke and r s
{8,9,...,79,80}, corresponding to the AFs from 4 to 40, to
represents the radial distance from the k-space origin with
r ∈ Z,−R ≤ r ≤ R. Generally, for a square image, R is generate k-space trajectories. We simulated k-space measure-
ments using these radial trajectories and added corresponding
the unilateral dimension of the image [4]. α is the angle of
n
noiseasshowninFig.1(b).ForeachGTimage,wegenerated
the n-th spoke with respect to the k axis. The golden angle,
x
one back-projected image with a randomly selected sampling
α =111.25◦ forthe2Dcase[2],isacommonchoiceforthe
g
pattern to construct pairs of samples for supervised learning.
specificangularincrementtoachieveanefficientandrelatively
In testing, we randomly selected 20 GT images from the
uniformangulardistributionfortheradialsamplingtrajectory,
validationdatasetandthenappliedsamplingpatternsthatvary
resulting in α =nα .
n g
thenumberofspokesfrom10to80withastepof10,resulting
in a total of 160 inverse problems.
C. Density compensation
IV. EXPERIMENTALRESULTS
During the measurement process of radial sampling, large
A. Comparison methods
intensities are allocated to the densely sampled region at
the centre of the k-space, which leads to a back-projected Wecomparetheproposedmethods,includingR2D2,R2D2-
image with abnormally large values. Density Compensation Net (NUFFT), and R2D2-Net (PSF), to the state-of-the-art
(DC), as proposed in [15], calculates factors in k-space that imaging methods, from the vanilla DNN baseline U-Net [12],
evenlyweighdifferentsamplelocationsbyiterativelyapplying to the unrolled DNN baseline NC-PDNet [4], and to the
the interpolation matrix and the adjoint interpolation matrix advanced PnP algorithm AIRI1, also recently introduced in
over m iterations. In our implementation, m is set to be 10 astronomical imaging [10], [18].
following [4]. After obtaining the DC weights denoted by d,
B. Implementation details
we multiply the k-space data by d before the back-projection.
The DNN models were implemented using PyTorch [19].
We used the PyTorch implementation of NUFFT from [20],
D. Acceleration factor
which benefits from GPU acceleration. We utilized the Adam
Indataacquisition,oversamplingcanbeappliedalongeach optimizer[21]withabasiclearningrateof0.0001.Inlinewith
spokewithoutincreasingthescantime.Thenumberofspokes, the previous work [8], the number of output channels of the
denoted by N
s
∈ Z +, determines the sparsity of the k-space firstconvolutionlayerforU-Netissetas64.AllDNNmodels,
sampling, directly related to the speed of data acquisition, but including the denoisers in AIRI, were trained using a single
with sparser sampling implying a more challenging inverse
problem for image reconstruction. Following [4], we define 1AIRI is a PnP algorithm based on a Forward-Backward optimisation
structure.Itsdenoisersaretrainedtosatisfyfirmanonexpansivenessconstraint
an Acceleration Factor (AF) for 2D radial sampling based on
√ necessarytoPnPconverge[17].Itleveragesashelfofdenoiserstrainedfor
N s as AF= N/N s. In previous studies, AF was set to be a a range noise levels, which are used adaptively across the iteration process.
constant,e.g.4or8.Aimingtodevelopamodeladaptablefor The combination of its convergence guarantees and its adaptive noise level
functionalitywasshowntodeliverprecisionandrobustnesssuperiortomore
a range of AFs, and to demonstrate R2D2’s performance at
basicPnPapproaches.Forthepurposeofthiscomparison,thedenoiserswere
highAFs,thenumberofspokeisleftvariableduringtraining. trainedonthesameGTdatasetastheDNNsoftheR2D2family.R2D2-Net R2D2-Net
GT and AIRI: U-Net: NC-PDNet: R2D2:
(FFT): (NUFFT):
Back-projected (15.55, 18.96) (14.93, 17.88) (14.40, 17.65) (18.44, 23.15)
(17.46, 22.85) (19.39, 25.10)
Fig.2. ReconstructedimagesinthefirstrowandcorrespondingdifferencescomparedtotheGTimageinthesecondrowbydifferentmethodsfor
oneofthevalidationsamples.Here,DR=167andAF=16.SNRandlogSNRvalues(dB)aredisplayedbelow.
TABLEI
ADDITIONALACCELERATIONRATIOSFORR2D2.
Algorithm\SNR 16 21 26 Scalability
U-Net 1.92 2.17 - Yes
AIRI 1.69 1.21 1.35 No
R2D2-Net (FFT) 1.15 1.14 1.35 Yes
NC-PDNet 1.54 1.14 0.98 No
R2D2-Net (NUFFT) 0.77 0.76 0.79 No
(a) SNR (b) logSNR
logSNR(x,x¯) = SNR(rlog(x),rlog(x¯)), where a is set as
the DR of the image.
D. Results
Fig. 3 (a) and (b) depict the results in terms of SNR
and logSNR, respectively, averaged from the 160 inverse
problems. We categorize the considered methods into two
groups: scalable and non-scalable, based on their capability
to be applied to large-dimensional scenarios. As the number
(c) SNR (d) logSNR
Fig. 3. The reconstruction performances of considered methods across of iterations increases, the performance exhibits a rising and
(a),(b)thenumberofiterations,and(c),(d)thenumberofspokes.The
converging trend for R2D2, surpassing all other algorithms
scalablemethodsaredenotedbycontinuouslines,whilenon-scalablemethods
aredenotedbydottedlines. aside R2D2-Net (NUFFT). Fig. 3 (c) and (d) show the results
across the AFs, averaged from the 20 inverse problems for
NVIDIA Tesla V100-SXM2-16GB GPU with a batch size of eachsamplingpattern.NC-PDNetperformspoorlyinhigh-AF
4 on Cirrus 4, a high-performance computing system. They scenariosduetothesimplesubnetworkstructure.Asexpected,
were initialized randomly and trained until convergence. The R2D2-Net (NUFFT) delivers superior outcomes compared to
same GPU was utilized in reconstruction for DNN models, R2D2 due to the joint training of its networks. However, its
while AIRI’s iterative reconstruction process employed the non-scalabilitytolargedimensionsrendersitakintoanoracle.
GPU combined with the dual Intel 18-core Xeon E5-2695 Based on Fig. 3 (c), we provide the additional acceleration
processor on Cirrus 4. ratio for R2D2 to show its capability of reducing scan time
compared to other methods in Tab. I. The ratio is defined as
AF /AF , where AF is the AF of R2D2 and AF
C. Evaluation metrics R2D2 Algo R2D2 Algo
is the AF of another algorithm at the same imaging quality
Weadoptlinearandlogarithmicsignal-to-noiseratiometrics (SNR). In Fig. 2, R2D2 and R2D2-Net (NUFFT) provide
to evaluate imaging quality. Firstly, Signal-to-Noise Ratio the best reconstruction results in terms of metrics and visual
(SNR)isdefinedasSNR(x,x¯)=20log (∥x¯∥ /∥x¯−x∥ ), performance,whileonlysubtledifferencesbetweenR2D2and
10 2 2
where ∥ · ∥ is the L2 norm. Secondly, based on the loga- R2D2-Net (NUFFT) can be observed in the zoomed areas.
2
rithmic mapping of the images parameterized by a > 0 is Tab. II provides the number of trainable parameters, Train-
rlog: x (cid:55)→ log (ax+1), the logarithmic SNR (logSNR) to ing Times (TTs), Inference Times (ITs) and number of itera-
a
evaluate the ability of recovering faint signals is defined as tions,averagedfromthe160inverseproblems.WeclassifytheTABLEII [2] KatherineLWright,JesseIHamilton,MarkAGriswold,VikasGulani,
THENUMBEROFPARAMETERS,TTS,ITS,ANDTHENUMBEROF andNicoleSeiberlich, “Non-cartesianparallelimagingreconstruction,”
ITERATIONSFORTHEDIFFERENTMETHODSCONSIDERED. JournalofMagneticResonanceImaging,vol.40,no.5,pp.1022–1040,
2014.
Algorithm Par. (M) TT (h) IT (s) Iteration [3] UlugbekSKamilov,CharlesABouman,GregeryTBuzzard,andBrendt
Wohlberg, “Plug-and-playmethodsforintegratingphysicalandlearned
AIRI 0.6 48 1857±387 616±138 modelsincomputationalimaging:Theory,algorithms,andapplications,”
IEEESignalProcessingMagazine,vol.40,no.1,pp.85–97,2023.
U-Net 31 52 0.053±0.007 1 [4] ZaccharieRamzi,GRChaithya,Jean-LucStarck,andPhilippeCiuciu,
R2D2-Net (FFT) 248 152 0.129±0.004 1 “Nc-pdnet:Adensity-compensatedunrollednetworkfor2dand3dnon-
R2D2 248 140 0.237±0.005 8 cartesianmrireconstruction,” IEEETransactionsonMedicalImaging,
vol.41,no.7,pp.1625–1638,2022.
NC-PDNet 1.6 230 0.263±0.011 1
[5] Zoran Stankovic, Bradley D Allen, Julio Garcia, Kelly B Jarvis, and
R2D2-Net (NUFFT) 248 315 0.237±0.005 1 MichaelMarkl, “4dflowimagingwithmri,” CardiovascularDiagnosis
andTherapy,vol.4,no.2,pp.173,2014.
considered methods into three categories: the PnP algorithm, [6] Ste´phaneGMallatandZhifengZhang, “Matchingpursuitswithtime-
scalable DNN models and non-scalable DNN models, delin- frequency dictionaries,” IEEE Transactions on Signal Processing, vol.
41,no.12,pp.3397–3415,1993.
eated by a horizontal line in the table. The TTs of scalable
[7] Amir Aghabiglou, Matthieu Terris, Adrian Jackson, and Yves Wiaux,
DNNs are notably shorter compared to non-scalable ones. “Deep network series for large-scale high-dynamic range imaging,”
Specifically, when comparing the TT of R2D2-Net (NUFFT) in IEEE International Conference on Acoustics, Speech and Signal
Processing(ICASSP).IEEE,2023,pp.1–5.
to R2D2-Net (FFT), we observe an increase of approximately
[8] AmirAghabiglou,ChungSanChu,AdrianJackson,ArwaDabbech,and
163 hours, primarily due to the NUFFT-related computation YvesWiaux, “Ultra-fasthigh-dynamicrangeimagingofcygnusawith
during training. In terms of ITs, R2D2 is four orders of ther2d2deepneuralnetworkseries,” arXivpreprintarXiv:2309.03291,
2023.
magnitude faster than AIRI, attributed to its smaller number
[9] Amir Aghabiglou, Chung San Chu, Arwa Dabbech, and Yves Wiaux,
of iterations. “The r2d2 deep neural network series paradigm for fast precision
imaginginradioastronomy,” arXivpreprintarXiv:2403.05452,2024.
V. CONCLUSION
[10] MatthieuTerris,ArwaDabbech,ChaoTang,andYvesWiaux, “Image
We have introduced the R2D2 deep learning-based image reconstruction algorithms in radio interferometry: From handcrafted
to learned regularization denoisers,” Monthly Notices of the Royal
reconstructionparadigmtoMRI,leveragingaseriesofend-to-
AstronomicalSociety,vol.518,no.1,pp.604–622,092022.
end DNNs in a “Matching Pursuit” flavour. Each network in [11] Anuroop Sriram, Jure Zbontar, Tullie Murrell, Aaron Defazio,
theseriesutilizestheback-projecteddataresidualandprevious C Lawrence Zitnick, Nafissa Yakubova, Florian Knoll, and Patricia
Johnson, “End-to-end variational networks for accelerated mri recon-
estimate to enhance the reconstruction. Two unrolled variants
struction,” in International Conference on Medical Image Computing
were proposed: R2D2-Net (NUFFT), utilizing NUFFT-based andComputerAssistedIntervention(MICCAI).Springer,2020,pp.Part
data-consistency layers, and R2D2-Net (FFT), employing the II23,64–73.
[12] OlafRonneberger,PhilippFischer,andThomasBrox, “U-net:Convo-
FFT approximation for data consistency. For this proof of
lutionalnetworksforbiomedicalimagesegmentation,” inInternational
concept, and without loss of generality, we have concentrated ConferenceonMedicalImageComputingandComputerAssistedInter-
on the single-coil scenario to facilitate a comparison between vention(MICCAI).Springer,2015,pp.PartIII18,234–241.
[13] JureZbontar,FlorianKnoll,AnuroopSriram,TullieMurrell,Zhengnan
scalable and non-scalable methods. Preliminary simulations
Huang, Matthew J Muckley, Aaron Defazio, Ruben Stern, Patricia
on magnitude MR images with single-coil radial sampling Johnson,MaryBruno,etal., “fastmri:Anopendatasetandbenchmarks
demonstrate that R2D2 achieves: (i) suboptimal performance foracceleratedmri,” arXivpreprintarXiv:1811.08839,2018.
[14] KaiZhang,YaweiLi,JingyunLiang,JiezhangCao,YulunZhang,Hao
compared to its unrolled counterpart R2D2-Net (NUFFT),
Tang, Deng-Ping Fan, Radu Timofte, and Luc Van Gool, “Practical
which is non-scalable due to embedded NUFFT-based layers; blindimagedenoisingviaswin-conv-unetanddatasynthesis,” Machine
(ii) superior reconstruction quality to R2D2-Net (FFT); (iii) IntelligenceResearch,vol.20,no.6,pp.822–836,2023.
[15] James G Pipe and Padmanabhan Menon, “Sampling density compen-
superior reconstruction quality to state-of-the-art methods,
sation in mri: rationale and an iterative numerical solution,” Magnetic
including AIRI and NC-PDNet. ResonanceinMedicine,vol.41,no.1,pp.179–186,1999.
Future research includes: (i) studying more evolved in- [16] Amanda G Wilber, Arwa Dabbech, Adrian Jackson, and Yves Wiaux,
“Scalableprecisionwide-fieldimaginginradiointerferometry:I.usara
carnations than those considered, in particular investigating
validated on askap data,” Monthly Notices of the Royal Astronomical
advanced DNN architectures in lieu of R2D2’s U-Net core Society,vol.522,no.4,pp.5558–5575,2023.
module; (ii) accounting for the complex-valued nature of [17] Jean-Christophe Pesquet, Audrey Repetti, Matthieu Terris, and Yves
Wiaux, “Learningmaximallymonotoneoperatorsforimagerecovery,”
real-world MRI data; (iii) confirming R2D2’s practical per-
SIAMJournalonImagingSciences,vol.14,no.3,pp.1206–1237,2021.
formance in large-dimensional scenarios, including multi-coil [18] MatthieuTerris,ChaoTang,AdrianJackson,andYvesWiaux, “Plug-
settings, and for 3D and 4D MRI. It is worth mentioning that and-playimagingwithmodeluncertaintyquantificationinradioastron-
omy,” arXivpreprintarXiv:2312.07137,2023.
preliminary experiments suggest that embedding the NUFFT
[19] AdamPaszke,SamGross,FranciscoMassa,Lerer,etal., “Pytorch:An
into R2D2-Net already becomes impractical for training in a imperativestyle,high-performancedeeplearninglibrary,” Advancesin
2D multi-coil setting with 32 coils at the same image sizes as neuralinformationprocessingsystems(NIPS),pp.8024–8035,2019.
[20] M. J. Muckley, R. Stern, T. Murrell, and F. Knoll, “Torchkbnufft: A
those considered here.
high-level, hardware-agnostic non-uniform fast fourier transform,” in
ISMRMWorkshoponDataSampling&ImageReconstruction,2020.
REFERENCES
[21] Diederik P Kingma and Jimmy Ba, “Adam: A method for stochastic
[1] ChangMinHyun,HwaPyungKim,SungMinLee,SungchulLee,and optimization,” arXivpreprintarXiv:1412.6980,2014.
Jin Keun Seo, “Deep learning for undersampled mri reconstruction,”
PhysicsinMedicine&Biology,vol.63,no.13,pp.135007,2018.