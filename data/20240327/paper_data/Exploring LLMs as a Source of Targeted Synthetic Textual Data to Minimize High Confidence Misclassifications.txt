Illuminating Blind Spots: Exploring LLMs as a Source of Targeted
Synthetic Textual Data to Minimize High Confidence Misclassifications
PhilipLippmann,MatthijsSpaan,JieYang
DelftUniversityofTechnology
p.lippmann@tudelft.nl
Abstract Original Sample: “I’m honestly so sad, you
know. Beenfeelinglikethisforalongtimeand
NaturalLanguageProcessing(NLP)modelsop-
don’tknowwhattodo.”
timizedforpredictiveperformanceoftenmake
SentimentPrediction: Negative
highconfidenceerrorsandsufferfromvulnera-
Confidence: 0.98
bilitytoadversarialandout-of-distributiondata.
Existing work has mainly focused on mitiga- PerturbedSample: “I’mhonestlysodejected,
tionofsucherrorsusingeitherhumansoran youknow. Beenfeelinglikethisforalongtime
automatedapproach. Inthisstudy,weexplore anddon’tknowwhattodo.”
the usage of large language models (LLMs) SentimentPrediction: Positive
fordataaugmentationasapotentialsolutionto
Confidence: 0.94 Outcome: UU
theissueofNLPmodelsmakingwrongpredic-
ExampleAbstractionHypothesis: “Themis-
tionswithhighconfidenceduringclassification
classificationmaybecausedbythemodel’ssen- tasks. We compare the effectiveness of syn-
sitivity to less common word choices, such as
theticdatageneratedbyLLMswiththatofhu-
mandataobtainedviathesameprocedure. For substituting“sad”with“dejected,”bothofwhich
mitigation, humans or LLMs provide natural expressnegativeemotions.”
languagecharacterizationsofhighconfidence ExampleExplorationHypothesis: “Themis-
misclassifications to generate synthetic data,
classificationmightbeduetothemodel’ssensi-
whicharethenusedtoextendthetrainingset.
tivitytotheinclusionof“despairing”insteadof
Weconductanextensiveevaluationofourap-
“sad,”causingadeviationfromfamiliarsyntactic
proachonthreeclassificationtasksanddemon-
patternspresentinthetrainingdata.”
strateitseffectivenessinreducingthenumber
ofhighconfidencemisclassificationspresentin
Table1: Rows1&2showanattackonasentimentclas-
themodel,allwhilemaintainingthesamelevel
sifierusingaperturbationmethod. Substitutionofthe
of accuracy. Moreover, we find that the cost
perturbedtextleadstochangeforacorrectpredictionto
gapbetweenhumansandLLMssurpassesan
awrongpredictionathighconfidence,leadingtoaUU.
orderofmagnitude,asLLMsattainhuman-like
Row 3 is a generalized hypothesis that describes the
performancewhilebeingmorescalable.1
causeoftheUU.Row4istheexplorationhypothesis
1 Introduction basedontheoriginalhypothesisinRow3.
NaturalLanguageProcessing(NLP)modelswith
thesolegoalofoptimizingpredictiveperformance
Predictionerrorscanbecategorizedaccording
haveachievedremarkableaccuracyacrossawide
tothemodel’sconfidenceinitsprediction,withun-
rangeoftasksbutareoftenvulnerabletodatathat
knownunknowns(UUs)correspondingtomisclassi-
isadversarialinnature(Papernotetal.,2016;Wang
ficationswherethemodelisveryconfident(Atten-
et al., 2019; Brown et al., 2020). Robustness – a
bergetal.,2015). UUshavebeenshowntocluster
model’sabilitytodealwithdiverseandchalleng-
to form blind spots, which represent areas in the
ing data – plays a crucial role in addressing the
featurespacethatleadamodeltoproducehighcon-
vulnerability of NLP models to adversarial and
fidencemisclassifications(Lakkarajuetal.,2017;
out-of-distribution data (Wang et al., 2022; Du
Liu et al., 2020). NLP models are prone to pro-
et al., 2023), though it may be at odds with ac-
duceUUsasaconsequenceoftextperturbations,
curacy(Tsiprasetal.,2019).
suchasthesubstitutionsofrelevantsynonyms(Ren
1Codeismadeavailableat:seesupplementarymaterials. et al., 2019). In the first two rows of table 1, we
4202
raM
62
]LC.sc[
1v06871.3042:viXrax̅’
Generate
Abstraction Abstraction
Sample
Feature Space
Unknown
Unknown
x̅’
Generate
Exploration Exploration
Sample
Feature Space
Generalization Generation
Figure1: ProcedureperformedbyhumanorLLM,beginningfromasingleUUpresentinablindspot(denotedby
across). ThisUUisthenusedtogenerateaninitialhypothesisviaabstraction. Thisabstractionhypothesiscanthen
eitherbyusedtogenerateasyntheticsamplethattargetstheexistingblindspotortogenerateanewhypothesisvia
exploration,whichinturnisthenusedtogenerateasyntheticsamplethattargetsanunknownblindspot.
show an example of such a perturbation that suc- etal.,2011;BanichandCaccamise,2010;Allaway
cessfullychangesthepredictedlabel,resultingina and McKeown, 2020). We pose that by utiliz-
UU.Discoveringandmitigatingblindspotsiscriti- inggeneralizedpatternsandsimilaritiesbetween
calinhigh-stakesNLPtasks,wheretheirpresence seenandunseenhighconfidencemisclassifications,
canresultinunwantedadverseoutcomes,suchas blindspotscanbeeffectivelydescribedbyhumans
unreliablesuicidepredictionmodels(Largeetal., or LLMs. To accomplish this, we guide both hu-
2017)andbiasedsentencingdecisionsincriminal mans and LLMs in formulating natural language
justice(Crawford,2016). hypothesesthatdescribetheunderlyingprinciples
contributingtotheformationofblindspots. After
TheidentificationofUUshasbeenextensively
generating hypotheses based on discovered UUs,
explored in existing literature (Attenberg et al.,
wegeneraterelevantadditionalsyntheticsamples
2015; Bansal and Weld, 2018; Vandenhof, 2019;
which target UUs. In our study, we specifically
Liu et al., 2020; Han et al., 2021), with more re-
comparetheeffectivenessofthesyntheticdatacon-
centresearcherinvolvinghumanstoaidblindspot
tributedbyhumansandLLMs,respectively.
identification efforts (Cabrera et al., 2021; Han
et al., 2021). However, current methods incorpo- Wefindthatourapproachiscapableofgreatly
rate humans in a heuristic manner, not designing reducingthenumberofhighconfidencemisclassif-
thetaskeffectivelytofullyleveragetheirgeneral- cationswithoutdecreasingaccuracy. Further,we
izationabilitiesforblindspotmitigation. Thenon- find LLMs exhibit a greater capacity for charac-
trivialityofmitigatingblindspotsinNLPmodels terizing blind spots compared to humans, as evi-
lies in the challenge of generalizing from previ- dencedbyalargeraveragedecreaseinthenumber
ously identified individual UUs to the mitigation of UUs via our LLM-based approach (19.54%)
of unseen blind spots. It remains an open ques- compared to our human-based one (16.80%). Fi-
tion how to best engage humans – or alternative nally,thedifferenceincostperhuman-generated
agents,suchaslargelanguagemodels(LLMs)–to datumversusLLM-generateddatumissubstantial,
effectivelymitigateblindspotsatscale. withLLM-generateddatabeingsignificantlymore
cost-effective.
Tothisend, weexplorethecharacterizationof
existingblindspotsbyeitherhumansorLLMsasa
potentialsolutiontotheissueofNLPmodelsmak- 2 RelatedWork
ing wrong predictions with high confidence, em-
phasizing the importance of generalization. Gen- Before outlining our methodology, we introduce
eralizationreferstotheideathatintelligentagents relevantpriorresearchforapproachestohighcon-
employpriorknowledgefornewlearningsituations fidence misclassifications, as well as how others
thatsharesimilaritieswithpastexperiences(Gluck havetriedtoavoidsuchmodelbehaviour.2.1 UnknownUnknowns tices,ourmethodfocusesnotongeneralrobustness
–butratheronhighconfidencemisclassifications
Attenberg et al. (2015) introduce the concept of
–andisnotlimitedtojustadversarialsamples,as
queryinghumanstofindUUsinagame-likesetting
wealsoconsiderUUsthatoccurnaturally,without
andshowthattherewerepatternstothefoundUUs.
anyperturbation.
Vandenhof (2019) proposes an approach to iden-
FortheNLPresearcharea, severalapproaches
tifyUUswherehuman-interpretabledecisionrules
havebeenproposedtoutilizesyntheticdatatoex-
are learned to approximate how a model makes
pandtrainingsets(Purietal.,2020;Claveauetal.,
high-confidencepredictions. Crowdworkersthen
2021). Synthetictextualdatahaspreviouslybeen
contradict these rules by finding an instance that
proposed specifically for sentiment classification
wouldclassifyasaUU.Hanetal.(2021)propose
tasks (Maqsud, 2015). He et al. (2022) explore
anapproachwherecrowdworkerscontinuouslyex-
few-shotpromptingLLMstogeneratetaskspecific
tendadatasetwithadditionalUUs,thatthechosen
synthetictrainingdata. Unlikepriorwork,wepro-
modelisiterativelytrainedon. Cabreraetal.(2021)
poseamethodtogeneratetargetedsyntheticdata
exploretheuseofcrowdworkerstogeneratefailure
with the purpose of eliminating blind spots that
reports for NLP models to describe how or why
leadtohighconfidencemisclassifications.
the model failed. There are also algorithmic ap-
proachestofindingUUs, suchasLakkarajuetal. 3 Methodology
(2017), who propose utilizing an explore-exploit
Inourproposedapproach,forthepurposeofblind
approachtofindgroupsofUUs. BansalandWeld
spotmitigation,ahumanorLLMisaskedtoper-
(2018)extendthisbyproposingautilitymodelthat
formoneofthreepossibletasks: hypothesisgen-
rewardsthedegreetowhichthefoundUUscover
erationviaabstraction,hypothesisgenerationvia
asampledistribution,thusencouragingthediscov-
exploration, or sample generation. These are de-
ery of new blind spots. Instead, we do not find
scribedbelowandshownschematicallyinfigure1.
theUUsalgorithmically,butinsteaduseanLLM
orcrowdworkerstofindexistingUUs,extrapolate
3.1 ProblemFormulation
fromthesetounseenUUs,andgeneratesynthetic
ForpassiveUUdiscovery,letthedatasetbeD =
datatargetingthese.
{(x ,y ),...,(x ,y )},wherexistheoriginaltext
1 1 n n
sample and y the original label. Without having
2.2 ModelCalibrationandRobustTraining
accesstoy,apredictivemodelθ isusedtoobtain
TheconceptofUUsandblindspotsisconnected y = θ(x) at a confidence c ∈ [0,1]. Formally, a
to model calibration (Guo et al., 2017; Minderer UUoccurswhen(1)thewronglabelispredicted
et al., 2021; Tian et al., 2023). A model that is by θ and (2) the prediction is made at c ≥ τ, in-
well-calibratedwillhaveitspredictionconfidence dicatinghighconfidence. Inthecaseofproactive
aligned with the likelihood of the correctness of UU discovery, as is performed in this work, an
the prediction. Investigating a model with blind additional technique is used to increase the mis-
spotsisanexaminationofamodelthatisnotwell- classificationsproducedbyθ. Forthis,ablack-box
calibrated. Therefore,ourapproachimprovesthe adversarial perturbation model G generates per-
calibrationofthemodel. turbed samples x′ = G(x), where x′ ̸= x. Then
InthecasewheretheUUsarespecificallygen- θ is used to predict the new label for every sam-
eratedthroughadversarialattacks,illuminationof ple y′ = θ(x′) at c ∈ [0,1]. The newly formed
model blind spots is also related to robust train- perturbeddatasetP constitutesofthesenewlabels
ing. UUs that populate these blind spots, when andtheircorrespondingx′. Aperturbationmaybe
created by such attacks, may be identified as ad- consideredsuccessfulify′ ̸= y. Ifaperturbation
versarial examples (Ribeiro et al., 2018; Wallace occurs,thereisanadditionalrequirementforaUU:
etal.,2019;Wangetal.,2020). Thisunderscores (3)x′,regardlessofitslabelindicatedbytheclas-
therelationshipbetweenourproposedmethodand sifier,maintainsthesameunderlyingtruelabelas
robust training practices, as well as the creation xpostperturbation.
andidentificationofadversarialexamplesthrough
3.2 GeneralizationviaHypothesisCreation
adversarialattacks,withtheaimofimprovingthe
robustnessofthemodel(Madryetal.,2018;Pang For generalization, we present humans or LLMs
etal.,2021). Unlikegeneralrobusttrainingprac- withrelatedpairsfrom(x,y) ∼ D and(x′,y′) ∼P consisting of UUs and ask them to create hy- (a) (b) (c)
pothesesregardingtheunderlyingcausesofpresent
Validation Set UUs Test Set
blindspots. Duetotheabilityofhumanstolearn
andgeneralizeeffectivelyusingsparseamountsof
data(Lakeetal.,2015),wecanfocusonsubsetsof
Attack Generalization Attack
UUsasrelevantsamplesforthehypothesisgenera-
tiontask. Inourstudy,hypothesestaketheformof
simplesentencesthatdescribewhyaUUoccurred
Perturbed Perturbed Test
Extended Set ( )
and what information can be generalized from it Validation Set Set
to other potential UUs. As such, it does not act Attack Retrain Evaluate
as a simple explanation of the failure case. Any
Model Retrained Model Retrained Model
hypothesisshouldcovermultiplesentencesindis-
criminately,shouldthesamecharacteristicspersist
across them. This allows a hypothesis to address
UUs UUs
multipleUUsthatclustertogethertoformablind
spotandthusilluminateit. Examplesofwhatthese
Figure2: Workflow: (a)Attackingtheoriginalmodelto
hypothesesmightlooklikeinpracticeareshown
obtainUUs;(b)UsingtheseUUstoextendthetraining
inthefinaltworowsoftable1.
dataviageneralization(figure1)andthusobtainamore
AbstractionAbstractionconstitutestheusageof
robustmodel;(c)Evaluatingthisretrainedmodel.
asinglehypothesistodescribepartof, orideally,
an entire blind spot, to expand the knowledge re-
garding that particular blind spot. During the ab- 3.3 SyntheticSampleGeneration
stractionstep,wepresentUUstobothhumanpar-
Aftergeneratinghypothesesviaabstractionorex-
ticipants and the LLM. They are shown a sam-
ploration, participants, whether human or LLM,
ple(x ,y )anditsperturbedform(x′,y′),andare
i i i i areaskedtogeneratesyntheticsamples,whichwe
taskedwithgeneratingahypothesisthatexplains
denote as x¯′, that follow these new hypotheses.
anyfactorsthatcouldhaveledtoitbeingaUU.We
These new samples must fit the overall structure
frame the task in a way that this could be related
oftheuseddataset,aswellasbeapplicabletothe
toapattern,semantics,syntax,specificwords,or
overall context of the task (e.g., a movie-related
somethingelsebetweentheoriginalandperturbed
sampleforamoviereviewdataset). Wethusobtain
samples. Theyaretaskedwithemployingabstract
additional samples that should, according to our
reasoningtocomeupwithanaturallanguagehy-
intuition,correspondtoblindspotsthatthepredic-
pothesis, while being reminded that this should
tivemodelθ mighthave. Usingthesesamplesthe
generalize to other, similar UUs. An example of
trainingdatasetisextended,resultinginE,which
abstractionbeingperformedisshownintable3.
consistsofD andtheadditionalgeneratedsamples
ExplorationExplorationasastrategygoesbeyond
x¯′ andtheircorrespondinglabelsy¯′,whichwealso
attempting to reason about blind spots that result
askparticipantstoprovide. Thegenerationproce-
fromdiscoveredUUs. Instead,explorationfocuses
dure is the same, regardless of whether the used
on using existing hypotheses to generalize to a
hypothesiswasobtainedviaabstractionorexplo-
newhypothesisandthusfindadditional,previously
ration,andhumansperformgenerationexclusively
undiscovered blind spots to gain new knowledge
onhuman-generatedhypothesesandviceversa.
regardingthemodel’sfailuremodes. Humansand
LLMs are encouraged to use extrapolative think-
4 ExperimentalSetup
ing to form a hypothesis that they believe covers
new potential failure modes. To this end, we re- Initially,weprovideanoverviewoftheoverallex-
quest they ensure that the generated hypothesis perimentalsetup,followedbyadetaileddescription
is dissimilar compared to the already established ofthesetupforourexperiments,shownschemati-
hypothesiswhiletargetinganotherpotentialweak- callyinfigure2. Additionallytoaddressingnatural
ness. Fortheexplorationstep,wepresenthuman- blind spots (section 5), we performed a study on
generated hypotheses to the human participants human-inducedblindspots(appendixA),inwhich
andviceversa. Anexampleofexplorationbeing weshowthatonecancreateblindspotsinamodel
performedisshownintable4. that do not naturally occur when training on theDataset Task #Classes #Train #Validation #Test this end, we use the popular IMDB (Maas et al.,
MRPC SE 2 3,668 408 1,725
2011) dataset for the SA task, the MRPC (Dolan
IMDB SA 2 25,000 12,500 12,500
and Brockett, 2005) dataset for the SE task, and
QNLI NLI 2 104,743 5,463 5,463
theQNLI(Rajpurkaretal.,2016)datasetsforthe
Table2: Datasetsused,includingthetasktype,number NLIportionofourexperiment. Anoverviewofthe
ofclassesandnumberofsamplesineachofthetest,val-
detailsoftheuseddatasetscanbefoundintable2.
idation,andtrainingsets. Notethesplitoftheoriginal
We choose this combination of datasets because
IMDBtestsetintovalidationandtestset.
they exhibit significant disparities in the training
samplesizes,alongwithvaryinglevelsoftaskcom-
data set, and subsequently successfully target its plexity. WefinetuneaBERT(Devlinetal.,2019)
UUsviaourapproach,thuseliminatingthatblind model to perform the classification task and use
spot. Forfurthercontextualizationofthedatawe thebert-base-uncasedimplementationprovided
collect,weshowaselectionofdatafortheIMDB byWolfetal.(2020).
task. Intable3,wepresentanexampleofhypoth- For blind spot mitigation, we restrict the num-
esisgeneralizationfromaUUviaabstractionand berofhypothesesto1%ofthetrainingsetsizefor
intable4anexampleofhypothesisgeneralization both abstraction-derived and exploration-derived
fromaprevioushypothesisbyexploration. hypotheses. Additionally,eachgeneratedsample
corresponds to a single hypothesis, and we uti-
4.1 Verification
lize each hypothesis, resulting in the number of
Forqualitycontrolpurposesofthehumancontri- new samples being equal to 2% of the training
butions we include two attention checks in each setsize. Thesevaluescanbeeffectivelyregarded
survey to determine if crowdworkers are paying as budget-dependent hyperparameters. The even
attention (Oppenheimer et al., 2009). Addition- splitbetweenabstraction-derivedandexploration-
ally,weeliminatelow-effortresponsessubmitted derivedhypothesesisalsoachoicethatcanbeopti-
by crowdworkers. Our goal for this is not to se- mized,whichweleaveforfuturework. Inlinewith
lecthigh-qualityresponses,butinsteadtoeliminate previousworks(Lakkarajuetal.,2017;Bansaland
answersthatweremadeinbadfaith,e.g. bycopy- Weld,2018;Hanetal.,2021),wedefineτ = 0.65.
pasting the same response repeatedly. For auto- For the generation of hypotheses or samples via
matedqualitycontrolforresponsesbyhumansand LLM,weuseGPTversiongpt-3.5-turbo-1106
LLMsourapproachistwo-fold. Forallgenerated atatemperatureT = 0.7withthedefaultsystem
text, whether hypothesis or sample, we ensure a prompt. Allmodelsaretrainedusingalearningrate
certaincharacterlength(char = 40)toexclude of2×10−4 andabatchsizeof64for10epochs.
min
responsesthathaveinsufficientusablecontent. Fi-
4.3 Perturbations
nally,weemployanautomaticquantitativeevalua-
tiontechniqueintheformofBERTScore(Zhang Weassumenoknowledgeofthemodelparameters,
etal.,2020). Here,weusethehandcraftedhypoth- i.e. a black-box setting, and focus on perturba-
esis set and generations from appendix A as the tion techniques that are most likely to maintain
referenceset. If thescoreofanewhypothesisor thesamemeaningpostperturbationandthuspre-
sample fall below a threshold S , then we ex- serve the underlying true label. We implement
min
clude it and repeat the previous step to obtain a two state-of-the-art perturbation techniques via
replacement. Inpractice,wefindthatS = 0.5 the TextAttack framework (Morris et al., 2020),
min
givesagoodbalancebetweenaccuracyandensur- namely TextFooler (Jin et al., 2020) and Deep-
ingtextualdiversity. WordBug (Gao et al., 2018). TextFooler focuses
onsemanticallyandsyntacticallysimilarsynonym
4.2 DatasetsandModels
swap perturbations. It identifies the most impor-
Wesystematicallyevaluatetheeffectivenessofour tantwordsforthetargetmodelandthenreplaces
approachonarangeofdistinctclassificationtasks, themwithsemanticallysimilarandgrammatically
whichwereselectedgaugetheadaptabilityofour correctwordsuntilthepredictionisaltered. Deep-
approach across different levels of task complex- WordBuginsteadfocusesonarangeofcharacter
ity. Wefocusonsentimentanalysis(SA),seman- level perturbations that aim to minimize the edit
tic equivalence (SE), and natural language infer- distance of the perturbation. We thus cover two
ence (NLI) for our experimental evaluation. To majorlinesofadversarialperturbations,i.e. world-Original/PerturbedSamples O:[...]Footageofbusyhighways,planesflyingoverhead,poorlightningeffects,soldiersdoingtheirthing,they’reall
usedina[[haphazard]]manner,sometimesrepeatedly,andtheyoftenonlyhavealooseconnectiontothestoryWoodis
tryingtotell.[...]P:[...]Footageofbusyhighways,planesflyingoverhead,poorlightningeffects,soldiersdoingtheir
thing,they’reallusedina[[thoughtless]]manner,sometimesrepeatedly,andtheyoftenonlyhavealooseconnectionto
thestoryWoodistryingtotell.[...]
HumanAbstractionHypothesis “Haphazardcanbeintentional,vsthoughtlessisunplanned.Itfeelsmoreofanunwillingnessratherthanalackofability”
LLMAbstractionHypothesis “Hypothesis: Thereplacementofspecificadjectivesintheperturbedsamplealtersthesentimentandcontributesto
misclassification.Reasoning:Theadjective"thoughtless"intheperturbedsample,replacing"haphazard"maychange
theperceptionofthedirector’sskillsanduseofstockfootage. Thisalterationinsentimentcouldleadtoadifferent
classificationoutcome.”
Table3: ExamplesofhypothesisgeneralizationusingabstractionfortheIMDBdataset. StartingfromaUUmade
upofanoriginalanditscorrespondingperturbedsample,abstractionisperformedbyahumanorLLM.
HumanAbstractionHypothesis “Thepatternthatmayhavecausedthewrongpredictionmayberelatedtothesubstitutionofthewordswiththeirsynonym,
forexample""bad""withit’ssynonym""wicked"".”
HumanExplorationHypothesis “Thehypothesiscouldbethatthewordswerepotentiallyswapppedorreplaced,suchas""bad""beenreplacedby""evil""
whichcouldleadtoanincorrectprediction.”
LLMAbstractionHypothesis “Thechangeintheword"appalling"to"horrifying"mayhavecausedthemisclassification. Both"appalling"and
"horrifying"havenegativeconnotationsandcanbeusedtodescribesomethingthatisdisturbingorshocking.However,the
word"appalling"maybeconsideredmoreextremeandmayhaveastrongernegativeconnotationcomparedto"horrifying".
Thissubtledifferenceintheintensityofthenegativesentimentmayhavecausedthemisclassificationbythealgorithm.”
LLMExplorationHypothesis “Theuseoftheword"hypocrite"mayhavecausedthemisclassification.Reasoning:Theword"hypocrite"impliesthat
thepersonissayingonethingbutdoinganother,whichmaybeconsideredanegativetrait.However,somepeoplemay
notinterpretthepersoninthesampleasahypocrite,leadingtoadifferenceinsentimentanalysis.Thisdifferencein
interpretationmayhavecausedthemisclassificationbythealgorithm.”
Table4: ExamplesofhypothesisgeneralizationusingexplorationfortheIMDBdataset. Startingfromahypothesis
obtainedviaabstraction,explorationisperformedbyahumanorLLM.
level and character-level. Note that perturbation 5 NaturalBlindSpots
methodsarenotanecessitytouncoverblindspots.
Unlike synthetic blind spots, which are induced
Instead,weemploythemtoperformproactivein-
via biasing, natural blind spots are present in the
stead of reactive illumination of blind spots and
modelduetonaturalbiasesinthetrainset. Beyond
thusfindadditionalinstancesfailuremodes.
studyingwhetherourapproachisindeedsuccessful
inreducingblindspotsacrossourdiversechoiceof
classificationtasks,weaimtocomparehumanto
4.4 Evaluation
LLMperformanceintermsofeffectiveness,ability
toscale,andeaseofuse.
Weexplorearangeofmetricstoevaluatetheeffec- One crucial difference in instruction between
tiveness of our approach. Specifically, we assess thehumanandLLMproceduresisthenumberof
the accuracy of a model, the percentage of suc- examplesgiven,withhumansreceivingtwo,fully
cessfulperturbationsachievedbytheperturbation workedoutexamplesperparticipant,whilenoex-
technique,andthenumberofUUsthatoccurdue ampleisgiventotheLLM.Thiswasdonetolower
totheperturbations. Allofthesearerecordedfor theamountofguidancegiventothemodel,asfew-
the model trained on the original dataset and for shotpromptingtheLLMleadstoahighlyuniform
theoneretrainedonE. Theoverallaccuracyofthe setofsamples,evenathighertemperaturevalues.
model on the test set gives basic insight into the We thus intentionally introduce more variability,
generalperformance,whilethesuccessfulpertur- akintowhatnaturallytranspiresinthehumanpro-
bationpercentageandthenumberofUUsindicate cedure,wherecrowdworkerspossessdistinctper-
theoverallrobustnessofthemodelandprevalence spectivesandthoughts. Thestructureandcontent
ofblindspotsthatleadtohighconfidencemisclas- oftheuserstudypresentedtothecrowdworkersis
sifications,respectively. Itisdesirabletomaximize showninappendixC,whilethepromptstructure
the first while minimizing the latter two. As an usedfortheLLMisshowninappendixD.
increasing number of blind spots are illuminated
5.1 NaturalBlindSpotStudyResults
in the classification model, the number of UUs
is reduced. As such, the model is less prone to Theresultsfortheadditionofthehuman-andLLM-
catastrophicmisclassificationsduetoperturbation generatedsamplesareshownintable5.
attacksorotherout-of-distributiondata. Accuracy and UUs Regarding accuracy, whichTextFooler DeepWordBug
Acc. (%)↑ UUs(#)↓ Acc. (%)↑ UUs(#)↓
Original 82.38 952 82.38 936
LLMData 81.57 851 82.23 882
HumanData 81.58 418 82.10 802
Original 94.84 1882 95.40 1682
LLMData 95.40 1241 94.41 1448
HumanData 94.43 1518 95.74 1412
Original 89.88 1923 89.88 2597
LLMData 89.31 1536 89.38 1746
HumanData 89.42 2028 89.38 2325
Table5: Resultsofnaturalblindspotstudyforaccuracy,perturbationsuccessrate,andnumberofUUs. Rowsshow
resultsfortheoriginalandretrainedmodels(usinghuman-orLLM-generatedsyntheticsamples)bydataset.
servesasaproxyforgeneralperformance,wefind exhibits a remarkable reduction in UUs, outper-
thattheprocedureemployed, whetherhuman-or forming the LLM-based one significantly. This
LLM-based,hasnosignificantimpact. Acrossthe indicatesastrongtaskdependencyoftheeffective-
variousdatasets,theaccuracyremainsconsistent, nessofhumansincharacterizingblindspotsusing
withadifferenceofnomorethan±1%between ourproposedapproach.
the original and retrained models. With regards Thetask-dependentvariabilityinhumanperfor-
to our main metric, the number of UUs, we ob- manceisevidentintheundesiredoutcomesforthe
servethatourmethodcansuccessfullyleadtode- QNLIdatasetwhenusingTextFooler. Contraryto
creases,withamaximumreductionof56.09%for expectations,theresponsesgeneratedbyhumans
thehuman-basedretrainingontheMRPCdataset actuallyresultinanincreaseinUUs. Theobserved
usingTextFooler. Theonlyexceptiontothisisthe variabilityinperformancecanlikelybeattributed
human-basedprocedureontheQNLIdatasetwith totheintuitivenessoftheSEandSAtasks,which
the TextFooler attack, where we saw an increase contrasts with the complex NLI task. Determin-
of5.46%. Onaverage,acrossthetwoperturbation ingtheequivalenceoftwosentencesordiscerning
methods, there is a reduction in UUs of 19.54% the sentiment of a movie review aligns with the
and16.80%forLLM-basedandhuman-basedre- everyday experience of individuals. As a result,
training,respectively. thesetasksareperceivedaslesscomplexandmore
intuitive to crowdworkers. This underscores the
PerturbationsAdetailedoverviewofthepertur-
taskdependencyofnon-experthumanabilitiesand
bationstatisticscanbeseeninappendixB.Pertur-
highlightshowhumanperformancecanvarybased
bation success rate, which serves as a proxy for
onthenatureofthetaskathand.
generalmodelrobustnessagainstattacks,indicates
that leveraging the LLM-based method leads to
morestableresults,withreductionsofupto8.82% 5.2 DistributionofSuccessfulPerturbations
fortheIMDBdatasetusingDeepWordBug,while
To visualize the effect of the retraining across
thehuman-baseddataleadstowiderswingsinper-
theperturbedsamples,wetracktheconfidenceat
formance.
whichpredictionsaremade. Theconfidenceplots
HumanVersusLLMPerformanceThedecrease acrossdatasetsareshowninfigure3andfigure4
in UUs for LLMs is more substantial compared fortheTextFoolerandDeepWordBugperturbation
to the decrease observed as a result of the use of methods,respectively. Wecanobserveareduction
human-generated samples, as well as more pre- inhighconfidencepredictionsacrosstheretrained
dictable,suggestingthatLLMscreatequalityhy- models; specifically, predictions with confidence
pothesesandsamplesmoreconsistently. However, ofabove90%arereducedasaresultofretraining.
inthecaseoftheTextFoolerperturbationmethod Additionally,weobservesimilarresultsacrossper-
ontheMRPCdataset,thehuman-basedapproach turbationmethods,indicatingthattheperformance
CPRM
BDMI
ILNQof our approach is not dependent on the type of inforces the fact that the LLM-based approach is
perturbationmethodemployed. significantlymorescalable,asitisnotonlycheaper
butalsoyieldsdataalmostinstantaneously,while
6 Discussion
obtaining data from humans comes with a signif-
Ourresultsdemonstratethataccuracyremainscon- icant delay. Even though the LLM-based proce-
sistent regardless of whether the additional syn- dure is clearly the most scalable, there might be
theticsamplesaregeneratedbyahumanorLLM, somehigh-stakesorspecialistapplicationswhere
whiletheperturbationsuccessrateexhibitsvarying ahuman-basedorhybridprocedureismostuseful.
degreesofchange. TheLLM-basedapproachhas Thesefindingsshedlightontheresourceimplica-
agreatercapacityforreducingUUscomparedto tionsofconductinghumanandLLMcharacteriza-
human-generated samples. However, it is impor- tionstudies,therebyaidingresearchersinplanning
tant to note that human-generated samples have andallocatingresourceseffectively.
the potential to be more effective in certain cir-
7 Conclusion
cumstances. Overall, our findings highlight the
strengthsandlimitationsofbothLLM-andhuman-
We propose an approach to identify and mitigate
basedapproaches,andtheirpotentialsynergiesin
blindspotsinNLPmodelsthroughgeneralization
improvingmodelperformanceandrobustness.
by humans or LLMs, followed by synthetic sam-
ple generation to address UUs and thus enhance
6.1 LLMCapabilities
modelrobustness. Ourevaluationshowsthatour
In our investigation, we found that the quality of
approach is successful in achieving a significant
responses obtained from human participants sur-
reductioninUUsacrossdatasetswhilemaintaining
passesthoseofLLMinalimitednumberofcases,
accuracy. WefindthatLLMsoutperformhumans
particularlywhenhigher-orderthinkingskillswere
incharacterizingblindspotsandthatthereisasig-
necessary. For example, in one of our perturbed
nificant task dependency to the quality of human
samples, we had the date “June 15” in a sample
contributions.
changedto“John15”. Ahigh-performingcrowd-
workerwasabletodiscerntherelationtotheBible 8 Limitations
verse that was most likely the cause of the UU,
whiletheLLMwasnot. Whilethenumberofsuch Itshouldbenotedthatthechosenmethodofpertur-
high-qualityresponsesissmall,whenpresent,their bationinevitablyinfluencesthehypothesesgener-
impact on reducing UUs can be significant and atedbyhumanparticipantsandLLMsalike. Since
compensates for the many low-quality responses. our chosen perturbation approaches aim to swap
Thus,wepositthatthequalityceilingforhumansis insynonymsforvulnerablewordsormodifychar-
higher,althoughLLMsmoreconsistentlyprovide acters,foundblindspotswillonlybeduetothese
acceptable hypotheses and samples. It is worth particular perturbations, thus biasing the charac-
noting that the leading reasons for poor-quality terization and generation in favor of such errors.
responsesareeitherinsufficientunderstandingof Anotherlimitationisthepotentialfallibilityofhu-
the task or a lack of motivation among partici- mansorLLMs. Leveraginghumansforthegener-
pants(Gadirajuetal.,2017). alizationandgenerationtasksrisksignoringblind
spots that are not identifiable by humans. The
6.2 ScalabilityandEaseofUse
same can be said for LLMs, which might miss
Turningtothepracticalaspectsofourstudy,weob- human-identifiableblindspots. Further,contribu-
tainimportantinsightsregardingthecostsandtime tionsmadebyhumansmaybebiasedthemselves
requiredforconductinghumanandLLMgeneral- due to personal biases or motivations. We try to
izationexperiments. Thehumanstudy,involving addressthisthroughthepreviouslydiscussedver-
168 participants, incurred a cost of $1072 at an ification step. Finally, one notable challenge we
hourlyrateof$12,whereastheLLMexperiment encounteredwasthedifficultyofdefinitivelyprov-
hadasignificantlylowercostof$46forthesame ingtheoriginoftheresponsesprovidedbyasmall
numberofgeneralizationsandsamplesgenerated. minorityofparticipants,astheirresponsesappear
Thoughdifficulttoquantify, thecollectionofthe to resemble those generated by ChatGPT when
data from humans via surveys also takes signifi- asked to perform the same task. This echos the
cantly longer than collecting LLM data. This re- findings by other researchers, that crowdworkers400 400 400
200 200 200
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(a)MRPCOriginal (b)MRPCRetrainLLM (c)MRPCRetrainHuman
6,000 6,000 6,000
4,000 4,000 4,000
2,000 2,000 2,000
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(d)IMDBOriginal (e)IDMBRetrainLLM (f)IMDBRetrainHuman
1,500 1,500 1,500
1,000 1,000 1,000
500 500 500
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(g)QNLIOriginal (h)QNLIRetrainLLM (i)QNLIRetrainHuman
Figure3: PlotsofsuccessfulperturbationsforalldatasetswhenusingTextFooler,showingthedistributionofthe
numberofinstancesacrossconfidencebins.
are increasingly using LLMs to generate their re- Gagan Bansal and Daniel Weld. 2018. A coverage-
sponses(Veselovskyetal.,2023). Whilethisisjust based utility model for identifying unknown un-
knowns. Proceedings of the AAAI Conference on
anobservationthatwecannotdefinitivelyprove,it
ArtificialIntelligence,32(1).
raisestheconcernthatsomeparticipantsmaynot
have authored their responses themselves, under- Tom Brown, Benjamin Mann, Nick Ryder, Melanie
miningtheintegrityofourstudy. Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Neelakantan,PranavShyam,GirishSastry,Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child,
References
AdityaRamesh,DanielZiegler,JeffreyWu,Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Ma-
EmilyAllawayandKathleenMcKeown.2020. Zero-
teusz Litwin, Scott Gray, Benjamin Chess, Jack
ShotStanceDetection: ADatasetandModelusing
Clark, ChristopherBerner, SamMcCandlish, Alec
GeneralizedTopicRepresentations. InProceedings
Radford, Ilya Sutskever, and Dario Amodei. 2020.
of the 2020 Conference on Empirical Methods in
Language models are few-shot learners. In Ad-
NaturalLanguageProcessing(EMNLP),pages8913–
vances in Neural Information Processing Systems,
8931, Online. Association for Computational Lin-
volume 33, pages 1877–1901. Curran Associates,
guistics.
Inc.
JoshuaAttenberg,PanosIpeirotis,andFosterProvost. ÁngelAlexanderCabrera,AbrahamJ.Druck,JasonI.
2015. Beatthemachine: Challenginghumanstofind Hong,andAdamPerer.2021. Discoveringandval-
apredictivemodel’s“unknownunknowns”. J.Data idatingaierrorswithcrowdsourcedfailurereports.
andInformationQuality,6(1). Proc.ACMHum.-Comput.Interact.,5(CSCW2).
MarieT.BanichandDonnaCaccamise.2010. General- VincentClaveau,AntoineChaffin,andEwaKijak.2021.
izationofknowledge: Multidisciplinaryperspectives Generatingartificialtextsassubstitutionorcomple-
(1sted.). mentoftrainingdata.
secnatsnIfo#
secnatsnIfo#
secnatsnIfo#300 300 300
200 200 200
100 100 100
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(a)MRPCOriginal (b)MRPCRetrainLLM (c)MRPCRetrainHuman
4,000 4,000 4,000
2,000 2,000 2,000
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(d)IMDBOriginal (e)IDMBRetrainLLM (f)IMDBRetrainHuman
1,500 1,500 1,500
1,000 1,000 1,000
500 500 500
0 0 0
0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1
Confidence Confidence Confidence
(g)QNLIOriginal (h)QNLIRetrainLLM (i)QNLIRetrainHuman
Figure4: PlotsofsuccessfulperturbationsforalldatasetswhenusingDeepWordBug,showingthedistributionof
thenumberofinstancesacrossconfidencebins.
KateCrawford.2016. Cananalgorithmbeagonistic? clarityinmicrotaskcrowdsourcing. InProceedings
tenscenesfromlifeincalculatedpublics. Science, ofthe28thACMConferenceonHypertextandSocial
Technology,&HumanValues,41(1):77–92. Media, HT ’17, page 5–14, New York, NY, USA.
AssociationforComputingMachinery.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of J. Gao, J. Lanchantin, M. L. Soffa, and Y. Qi. 2018.
deepbidirectionaltransformersforlanguageunder- Black-boxgenerationofadversarialtextsequences
standing. InProceedingsofthe2019Conferenceof to evade deep learning classifiers. In 2018 IEEE
theNorthAmericanChapteroftheAssociationfor SecurityandPrivacyWorkshops(SPW),pages50–
ComputationalLinguistics: HumanLanguageTech- 56.
nologies,Volume1(LongandShortPapers),pages
Mark A. Gluck, Eduardo Mercado, and Catherine E.
4171–4186,Minneapolis,Minnesota.Associationfor
Myers.2011. Learningandmemory: Frombrainto
ComputationalLinguistics.
behavior(2nded.).
WilliamB.DolanandChrisBrockett.2005. Automati-
ChuanGuo,GeoffPleiss,YuSun,andKilianQ.Wein-
callyconstructingacorpusofsententialparaphrases.
berger.2017. Oncalibrationofmodernneuralnet-
InProceedingsoftheThirdInternationalWorkshop
works. InProceedingsofthe34thInternationalCon-
onParaphrasing(IWP2005).
ference on Machine Learning, volume 70 of Pro-
ceedingsofMachineLearningResearch,pages1321–
MengnanDu,SubhabrataMukherjee,YuCheng,Milad
1330.PMLR.
Shokouhi, XiaHu, andAhmedHassan.2023. Ro-
bustnesschallengesinmodeldistillationandpruning LeiHan,XiaoDong,andGianlucaDemartini.2021. It-
fornaturallanguageunderstanding. InProceedings erativehuman-in-the-loopdiscoveryofunknownun-
ofthe17thConferenceoftheEuropeanChapterof knownsinimagedatasets. ProceedingsoftheAAAI
theAssociationforComputationalLinguistics,pages ConferenceonHumanComputationandCrowdsourc-
1758–1770. ing,9(1):72–83.
UjwalGadiraju,JieYang,andAlessandroBozzon.2017. XuanliHe,IslamNassar,JamieKiros,GholamrezaHaf-
Clarityisaworthwhilequality: Ontheroleoftask fari,andMohammadNorouzi.2022. Generate,an-
secnatsnIfo#
secnatsnIfo#
secnatsnIfo#notate,andlearn: Nlpwithsynthetictext. Transac- Matthias Minderer, Josip Djolonga, Rob Romijnders,
tionsoftheAssociationforComputationalLinguis- FrancesHubis,XiaohuaZhai,NeilHoulsby,Dustin
tics,10:826–842. Tran, and Mario Lucic. 2021. Revisiting the cali-
brationofmodernneuralnetworks. InAdvancesin
SeppHochreiterandJürgenSchmidhuber.1997. Long NeuralInformationProcessingSystems,volume34,
short-termmemory. NeuralComputation,9(8):1735– pages15682–15694.CurranAssociates,Inc.
1780.
JohnMorris,EliLifland,JinYongYoo,JakeGrigsby,
Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter DiJin,andYanjunQi.2020. TextAttack: Aframe-
Szolovits.2020. Isbertreallyrobust? astrongbase- workforadversarialattacks,dataaugmentation,and
linefornaturallanguageattackontextclassification adversarialtraininginNLP. InProceedingsofthe
andentailment. ProceedingsoftheAAAIConference 2020 Conference on Empirical Methods in Natu-
onArtificialIntelligence,34(05):8018–8025. ralLanguageProcessing: SystemDemonstrations,
pages 119–126, Online. Association for Computa-
BrendenM.Lake,RuslanSalakhutdinov,andJoshuaB. tionalLinguistics.
Tenenbaum. 2015. Human-level concept learning
through probabilistic program induction. Science, Meike Nauta, Jan Trienes, Shreyasi Pathak, Elisa
350(6266):1332–1338. Nguyen, Michelle Peters, Yasmin Schmitt, Jörg
Schlötterer,MauricevanKeulen,andChristinSeifert.
HimabinduLakkaraju,EceKamar,RichCaruana,and 2023. Fromanecdotalevidencetoquantitativeeval-
EricHorvitz.2017. Identifyingunknownunknowns uationmethods: Asystematicreviewonevaluating
intheopenworld: Representationsandpoliciesfor explainableAI. ACMComputingSurveys.
guided exploration. In Proceedings of the Thirty-
First AAAI Conference on Artificial Intelligence, Daniel M. Oppenheimer, Tom Meyvis, and Nico-
AAAI’17,page2124–2132.AAAIPress. las Davidenko. 2009. Instructional manipulation
checks: Detecting satisficing to increase statistical
Matthew Large, Cherrie Galletly, Nicholas Myles, power. JournalofExperimentalSocialPsychology,
ChristopherJamesRyan,andHannahMyles.2017. 45(4):867–872.
Knownunknownsandunknownunknownsinsuicide
TianyuPang,XiaoYang,YinpengDong,HangSu,and
risk assessment: Evidence from meta-analyses of
JunZhu.2021. Bagoftricksforadversarialtraining.
aleatoryandepistemicuncertainty. BJPsychBulletin,
41(3):160–163.
NicolasPapernot,PatrickMcDaniel,SomeshJha,Matt
Fredrikson,Z.BerkayCelik,andAnanthramSwami.
Anthony Liu, Santiago Guerra, Isaac Fung, Gabriel
2016. Thelimitationsofdeeplearninginadversarial
Matute,EceKamar,andWalterLasecki.2020. To-
settings. In 2016 IEEE European Symposium on
wardshybridhuman-aiworkflowsforunknownun-
SecurityandPrivacy(EuroS&P),pages372–387.
knowndetection. InProceedingsofTheWebConfer-
ence2020,WWW’20,page2432–2442,NewYork, RaulPuri,RyanSpring,MohammadShoeybi,Mostofa
NY,USA.AssociationforComputingMachinery. Patwary, and Bryan Catanzaro. 2020. Training
questionansweringmodelsfromsyntheticdata. In
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Proceedings of the 2020 Conference on Empirical
Opinionobserver: Analyzing andcomparingopin-
MethodsinNaturalLanguageProcessing(EMNLP),
ionsontheweb. InProceedingsofthe14thInterna-
pages5811–5826.
tionalConferenceonWorldWideWeb,WWW’05,
page342–351,NewYork,NY,USA.Associationfor PranavRajpurkar,JianZhang,KonstantinLopyrev,and
ComputingMachinery. PercyLiang.2016. SQuAD:100,000+questionsfor
machinecomprehensionoftext. InProceedingsof
Andrew L. Maas, Raymond E. Daly, Peter T. Pham, the2016ConferenceonEmpiricalMethodsinNatu-
DanHuang, AndrewY.Ng, andChristopherPotts. ralLanguageProcessing,pages2383–2392,Austin,
2011. Learningwordvectorsforsentimentanalysis. Texas.AssociationforComputationalLinguistics.
In Proceedings of the 49th Annual Meeting of the
AssociationforComputationalLinguistics: Human ShuhuaiRen,YiheDeng,KunHe,andWanxiangChe.
Language Technologies, pages 142–150, Portland, 2019. Generatingnaturallanguageadversarialexam-
Oregon, USA. Association for Computational Lin- plesthroughprobabilityweightedwordsaliency. In
guistics. Proceedingsofthe57thAnnualMeetingoftheAsso-
ciationforComputationalLinguistics,pages1085–
Aleksander Madry, Aleksandar Makelov, Ludwig 1097,Florence,Italy.AssociationforComputational
Schmidt,DimitrisTsipras,andAdrianVladu.2018. Linguistics.
Towardsdeeplearningmodelsresistanttoadversarial
attacks. In International Conference on Learning Marco Tulio Ribeiro, Sameer Singh, and Carlos
Representations. Guestrin. 2018. Semantically equivalent adversar-
ialrulesfordebuggingNLPmodels. InProceedings
UmarMaqsud.2015. Synthetictextgenerationforsen- of the 56th Annual Meeting of the Association for
timentanalysis. InProceedingsofthe6thWorkshop ComputationalLinguistics(Volume1: LongPapers),
onComputationalApproachestoSubjectivity,Senti- pages856–865,Melbourne,Australia.Association
mentandSocialMediaAnalysis,pages156–161. forComputationalLinguistics.Katherine Tian, Eric Mitchell, Allan Zhou, Archit Methods in Natural Language Processing: System
Sharma,RafaelRafailov,HuaxiuYao,ChelseaFinn, Demonstrations,pages38–45,Online.Association
and Christopher Manning. 2023. Just ask for cali- forComputationalLinguistics.
bration: Strategiesforelicitingcalibratedconfidence
scoresfromlanguagemodelsfine-tunedwithhuman Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
feedback. In Proceedings of the 2023 Conference Weinberger,andYoavArtzi.2020. Bertscore: Eval-
onEmpiricalMethodsinNaturalLanguageProcess- uating text generation with bert. In International
ing, pages 5433–5442, Singapore. Association for ConferenceonLearningRepresentations.
ComputationalLinguistics.
A SyntheticBlindSpots
DimitrisTsipras,ShibaniSanturkar,LoganEngstrom,
AlexanderTurner,andAleksanderMadry.2019. Ro- Weusethesyntheticblindspotstudyakintoasan-
bustnessmaybeatoddswithaccuracy. InInterna- ity check for our approach. As such, compared
tionalConferenceonLearningRepresentations.
tothefullnaturalblindspotstudy, weuseaonly
ColinVandenhof.2019. Ahybridapproachtoidentify- a single task, a simpler model architecture, and
ingunknownunknownsofpredictivemodels. Pro- make other simplifications to our mitigation pro-
ceedingsoftheAAAIConferenceonHumanCompu-
cess. WeselectanLSTM(HochreiterandSchmid-
tationandCrowdsourcing,7(1):180–187.
huber, 1997) as our model of choice due to the
Veniamin Veselovsky, Manoel Horta Ribeiro, and absence of pretraining and apply the TextFooler
RobertWest.2023. Artificialartificialartificialintel- perturbation method on the SA task. The LSTM
ligence: Crowdworkerswidelyuselargelanguage
usedisthestandardversionoftheBi-LSTMpro-
modelsfortextproductiontasks.
videdbyMorrisetal.(2020).
Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gard- BlindspotCreationToassesswhetherourmethod
ner,andSameerSingh.2019. Universaladversarial cantackleexistingsyntheticblindspotsweperform
triggersforattackingandanalyzingNLP. InProceed-
atypeofControlledSyntheticDataCheck(Nauta
ingsofthe2019ConferenceonEmpiricalMethods
et al., 2023). We create synthetic blind spots by
inNaturalLanguageProcessingandthe9thInter-
nationalJointConferenceonNaturalLanguagePro- systematicallyexcludingsomedatafromtraining
cessing(EMNLP-IJCNLP),pages2153–2162,Hong thathavecommonalities,namelycontainingapos-
Kong,China.AssociationforComputationalLinguis-
itive or negative term according to lexica by Liu
tics.
et al. (2005). Here, we randomly subsample 600
TianluWang,XuezhiWang,YaoQin,BenPacker,Kang of each as our selection of positive and negative
Li,JilinChen,AlexBeutel,andEdChi.2020. CAT- terms,duetotheextensivenatureofthelexica.
gen: ImprovingrobustnessinNLPmodelsviacon-
Wecreateafalsepositiveblindspotbyremov-
trolledadversarialtextgeneration. InProceedings
ingsamplesfromthetrainsetusingourselection
of the 2020 Conference on Empirical Methods in
NaturalLanguageProcessing(EMNLP),pages5141– ofnegativeterms,resultinginanegativelybiased
5146, Online. Association for Computational Lin- LSTM (N). Similarly, we create a false negative
guistics.
blindspot,resultinginapositivelybiased LSTM
(P), as well as a blind spot resulting from a se-
WenqiWang,RunWang,LinaWang,ZhiboWang,and
AoshuangYe.2019. Towardsarobustdeepneural lectionof50%randomlychosentermsfromeach,
networkintexts: Asurvey. leadingtoapositive/negativebiased LSTM(PN).
Forcomparison,wealsoincludearandomlybiased
Xuezhi Wang, Haohan Wang, and Diyi Yang. 2022.
MeasureandimproverobustnessinNLPmodels: A LSTM(R),wheresampleswereremovedfromthe
survey. In Proceedings of the 2022 Conference of trainsetrandomlytoobtainasizecomparableto
theNorthAmericanChapteroftheAssociationfor theP,N,andPNones.2
ComputationalLinguistics: HumanLanguageTech-
BlindSpotMitigationAftercreatingthesynthetic
nologies, pages 4569–4586, Seattle, United States.
AssociationforComputationalLinguistics. blindspotsthroughbiasing,theauthorsperformthe
generalizationprocedureandprovidehandcrafted
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
hypothesesthatpreciselydescribethese,similarto
Chaumond,ClementDelangue,AnthonyMoi,Pier-
goldenlabels. Togeneratethenewsamplesfrom
ricCistac,TimRault,RemiLouf,MorganFuntow-
icz,JoeDavison,SamShleifer,PatrickvonPlaten, ourhandcraftedhypotheses,wepromptChatGPT
Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, togeneratemoviereview-relatedsentences(tofit
Teven Le Scao, Sylvain Gugger, Mariama Drame, the chosen task) that follow a given hypothesis.
QuentinLhoest,andAlexanderRush.2020. Trans-
formers:State-of-the-artnaturallanguageprocessing. 2Sizeoftrainingsets: N =25,000,N =2,500,
Clean R
InProceedingsofthe2020ConferenceonEmpirical N =2,439,N =3,138,andN =2,438.
P N PNOriginal Retrain
Accuracy(%) Perturbation(%) UUs(#) Accuracy(%) Perturbation(%) UUs(#)
Clean 88.03 82.22 1725 88.03 82.21 784
BiasedR 78.55 78.56 3785 78.61 78.58 2593
BiasedP 75.10 75.02 4607 74.25 73.12 1201
BiasedN 76.64 76.64 4394 77.38 77.35 845
BiasedPN 74.17 73.94 9231 74.81 74.01 2331
Table6: Resultsofsyntheticblindspotstudyforaccuracy,perturbationsuccessrate,andnumberofUUsbeforeand
afterretrainingforallLSTMmodelvariants. TheusedperturbationmethodisTextFoolerandthedatasetisIMDB.
Thiswasdoneinanattempttosimplifytheproce- useofhypothesesandgeneratedinstances,without
durebytakingadvantageofhumanstrengths,gen- significantlyaffectingtheperformanceorgeneral
eralization and extrapolative thinking, and LLM robustnessofthemodel.
strengths,low-costtextgeneration,simultaneously.
B PerturbationStatistics
A.1 SyntheticBlindSpotStudyResults
To add additional context to the perturbation per-
The mitigation results of this human-LLM ap-
formed, we supply the detailed attack statistics
proach for our Controlled Synthetic Data Check
acrossallperformedperturbations. Specifically,we
canbeseenintable6.
reportOriginalAccuracyandAccuracyUnderAt-
Outcomes of Biasing As can be seen in the first
tackarereported,whicharetheclassifieraccuracy
column of table 6, before retraining, the overall
onitsownandwhileunderattack. Further,Attack
test accuracy declines in line with the degree to
SuccessRateisshown,whichisthepercentageof
whichthetrainsetisbiased. Interestingly,theper-
successfulperturbationattemptstofailedones. Fi-
centageofsuccessfulperturbationsbyTextFooler,
nally,wereportthenumberofPerturbedWords,the
i.e.,thepercentageofsuccessfullabelflips,closely
percentageofwordsthatareperturbed,theWords
followstheoverallaccuracy. Thismirrorsthefind-
perInput,theaveragenumberofwordsperinput,
ingsofTsiprasetal.(2019),thatthereisastrong
andtheAverageNumberofQueries,whichishow
relationshipbetweenhighaccuracyandbrittleness
manytriesittooktheperturbationmethodtofind
– or a lack of robustness. The number of occur-
thebestattack. TheattackstatisticsforTextFooler
ring UUs as a result of the perturbation does not
attacks are shown in table 7 while the ones for
follow this trend, instead increasing as the train-
DeepWordBugattacksareshownintable8.
ingdatabecomesmorebiased,asexpected. This
posesaninterestingoptimizationproblemsincethe
C UserStudyStructure
modelbecomesmostrobustingeneralterms,i.e.,
thesuccessfulperturbationpercentagefalls,butsi- WeuseProlificasacrowdsourcingplatformforall
multaneouslythereisasignificantuptickinblind our participants. Below, we present the structure
spotsasthetrainingsetsbecomemorebiased. followed by all survey participants for the gener-
BlindSpotMitigationTheeffectofretrainingon alization user study, consisting of an initial dis-
theoverallaccuracyandperturbationsuccessrate claimer, an instruction set, examples, and finally
is minimal, with accuracy changing by no more the questions. Here, we use the abstraction and
than ± 1% and perturbation success rate chang- explorationassignmentsontheIMDBdatasetasan
ing no more than ± 2%. However, the number example. Theworkflowisverysimilarbetweenthe
of found UUs decreases drastically due to the re- differentgeneralizationassignmentsanddatasets
training,withreductionsof73.93%,80.77%,and (MRPC,IMDB,orQNLI),withonlyslightdiffer-
74.75%forthebiasedP,N,andPNmodels,respec- ences in the wording between the surveys to fit
tively. Thecleanandrandomlybiasedmodelsalso the task and dataset used, as they all present the
showareduction,thoughlesssignificantat54.55% crowdworkerwithsomeinputandresultinplain
and 31.49%, respectively. These results confirm textoutput. Forthegenerationassignment,crowd-
that our method can be used to target synthetic workersareaskedtoperformthesamesteps,with
blind spots found in biased models through the relevant examples related to the structure of theMRPC MRPC MRPC IMDB IMDB IMDB QNLI QNLI QNLI
O L H O L H O L H
OriginalAccuracy(%) 82.38 81.57 81.58 94.84 95.40 94.43 89.88 89.31 89.42
AccuracyUnderAttack(%) 9.80 17.40 12.99 10.18 10.44 19.21 8.91 11.67 14.89
AttackSuccessRate(%) 71.83 64.87 68.29 88.46 93.18 63.85 87.35 86.80 78.84
PerturbedWords(%) 7.70 9.9 8.51 4.59 7.62 9.02 6.12 8.80 9.57
WordsperInput 39.3 39.3 39.3 230.0 230.0 230.0 37.9 37.9 37.9
Avg.NumberofQueries 51.40 68.62 55.17 185.24 184.94 198.31 49.38 51.27 56.11
Table7: PerturbationstatisticsacrossdatasetsandmodelsforattackswithTextFooler. SubscriptsO,L,andH
denotetheoriginal,LLM-retrained,andhuman-retrainedmodels,respectively.
MRPC MRPC MRPC IMDB IMDB IMDB QNLI QNLI QNLI
O L H O L H O L H
OriginalAccuracy(%) 82.38 82.23 82.10 95.40 95.41 95.74 89.88 89.38 89.38
AccuracyUnderAttack(%) 7.78 13.73 11.94 9.54 21.43 15.32 8.21 9.90 7.30
AttackSuccessRate(%) 72.00 70.38 72.64 59.41 50.59 79.70 77.54 79.74 82.08
PerturbedWords(%) 8.47 9.18 9.03 6.43 8.11 13.09 7.99 8.32 11.03
WordsperInput 39.3 39.3 39.3 230.0 230.0 230.0 37.9 37.9 37.9
Avg.NumberofQueries 56.92 64.37 58.61 199.32 211.65 201.44 34.91 33.53 49.09
Table8: PerturbationstatisticsacrossdatasetsandmodelsforattackswithDeepWordBug. SubscriptsO,L,andH
denotetheoriginal,LLM-retrained,andhuman-retrainedmodels,respectively.
dataset being shown, before finally contributing • “Pleasereadthefollowingexamplescarefully.
usablesamplesbasedonshownhypotheses. All tasks in this survey are related to a sin-
gle task, sentiment analysis, which tests the
C.1 AbstractiononIMDB
sentiment of a sentence is either positive or
DisclaimerCrowdworkerswereshownaninitial negative,appliedtomoviereviews. Thegoal
disclaimertoinformthemthatourgoverningethics hereistouseyourcreativityandabilitytogen-
bodysanctionsthissurveyandtoremindthemnot eralizetospotpatternsandcomeupwithnew
tosharepersonalinformation: possiblesamples. Afullyworked-outexam-
plecanbefoundbelow,withuser-generated
• “WelcometotheHypothesisExplorationSur-
text,similartowhatyouareexpectedtowrite,
vey! Pleasecarefullyreadthefollowing: You
in italic and instructions bold. You will re-
areinvitedtoparticipateinourresearchstudy.
ceiveallrelevantinstructionsagainwhenfor
Thisstudyisfullysanctionedbyourgovern-
eachquestion.”
ingethicsbody,asisthehandlingandstoring
oftheresultingdata. Thisresearchstudyaims
ExamplesThen,theywerepresentedwithtwoex-
touseyourcreativityandgeneralizationabil-
amplesthatmatchthedatasetused,aswellasthe
itytocomeupwithnewabstractions. Itwill
task(abstraction,expansion,orgeneration),before
take you approximately 25 minutes to com-
beingaskediftheyunderstoodtheexamples:
plete. Aswithanyonlineactivity,theriskof
a breach is always possible. To the best of
• “There is a sentence pair below, with one
ourability,youranswersinthisstudywillre-
original sample (O) and a perturbed one
mainconfidential. Wewillminimizeanyrisks
(P), which is similar but had some things
bymakingthissurveycompletelyanonymous.
changed(shownindoublesquarebrackets).
Therefore,pleasedonotprovideanypersonal
Thesechangesmayrelatetoapattern,re-
information anywhere. The anonymous re-
lated to semantics, syntax, specific words,
sults might be shared publicly in the future.
orsomethingelseinthesamples,thatleads
Participationinthisstudyisentirelyvoluntary,
tothewrongTrueorFalselabelbeingpre-
and you can withdraw anytime. Feel free to
dictedforsemanticsimilarity.
contactuswithanyquestionsorfeedbackyou
mighthave.” • Example1–Thetwosamplesare:
InstructionsCrowdworkerswerethenintroduced O:Therewasanoverarching[[story]]thatwas
tothespecifictask(SE,SA,orNLI)asfollows: [[refusing]] to reveal itself to me. P: Therewasanoverarching[[narrative]]thatwas[[un- the reason the sample is misclassified by a
able]]torevealitselftome. classification algorithm. This misclassifica-
tionismadeatahighlevelofconfidence.
Formulate a hypothesis on what this pat-
ternforOandPmightbeandenteritbe- Themodelisnottrainedonthetwosamples.
low. Trytobespecificwhenformulatinga Thetwosamplesrelateto{task}andare:
hypothesis.
O:{sentence[0]}
Thepatternthatcausedthewrongprediction
P:{sentence[1]}
mayberelatedtothesubstitutionoftheword
Formulate a hypothesis on what this pattern
""story""withitssynonym""narrative"".
mightbe. Trytobespecificwhenformulating
• Example2–Thetwosamplesare: a hypothesis. Your response should always
followtheformat:
O:Overall,I[[loved]]thecinematographyof
this through and [[through]]. P: Overall, I Hypothesis: «hypothesis»
[[looved]]thecinematographyofthisthrough Reasoning: «reasoning»”
and[[thr0ugh]].
D.2 ExplorationPrompt
Formulate a hypothesis on what this pat-
ternforOandPmightbeandenteritbe- • “There is a sentence pair, with one original
low. Trytobespecificwhenformulatinga sample(O)andaperturbedone(P),whichis
hypothesis. similarbuthadsomethingschanged. These
changesmayrelatetoapattern,relatedtose-
Several words have been misspelled in the
mantics,syntax,specificwords,orsomething
samples,allrelatedtotheletter""o"". Either
else, that leads to them being the reason the
more letters are added ""oo"" or the letter
sampleismisclassifiedbyaclassificational-
issubstitutedwithanumber""0""thatlooks
gorithm. This misclassification is made at a
similar,makingiteasytomisread.”
highlevelofconfidence.
MainQuestionsFinally,theactualquestionspre- Themodelisnottrainedonthetwosamples.
cedingthetextentryfieldusedfordatacollection Thetwosamplesrelateto{task}
allhavethesamestructurewiththeuniqueOand
Thereisanexistinghypothesisregardingthe
Psentencessubstitutedinforeachquestion:
samples,thatmaycaptureapatternrelatedto
semantics, syntax, specific words, or some-
• “Thetwosamplesare:
thing else in the sample pair. This pattern
O: <original sentence> P: <perturbed sen-
leadstoamisclassificationofthesample.
tence>
Thehypothesisis: {hypothesis}
Formulate a hypothesis on what this pat-
Formulateanewhypothesisregardingthose
ternmightbeandenteritbelow. Trytobe
sentence samples that is concerned with the
specificwhenformulatingahypothesis.”
sametopicbutisappliedtoadifferentpossi-
D UsedLLMPrompts blepatternthatcouldalsoleadtoamisclassifi-
cation. Trytobespecificwhenformulatinga
WespecificallyinstructtheLLMtosplititshypoth-
newhypothesis. Yourresponseshouldalways
esisfromitsreasoningbecause,inourexperience,
followtheformat:
thisleadstoaclearerandmoreusefulanswerfor
Hypothesis: «hypothesis»
furthersteps.
Reasoning: «reasoning»”
D.1 AbstractionPrompt
D.3 GenerationPrompt
• “Thereisasentencepairbelow,withoneorigi-
nalsample(O)andaperturbedone(P),which • “There is a sentence pair, with one original
issimilarbuthadsomethingschanged. These sample(O)andaperturbedone(P),whichis
changesmayrelatetoapattern,relatedtose- similarbuthadsomethingschanged. These
mantics,syntax,specificwords,orsomething changesmayrelatetoapattern,relatedtose-
elseinthesamples,thatleadstothembeing mantics,syntax,specificwords,orsomethingelse, that leads to them being the reason the
sampleismisclassifiedbyaclassificational-
gorithm. This misclassification is made at a
highlevelofconfidence.
Themodelisnottrainedonthetwosamples.
Ahypothesishasbeenformulatedregarding
thesamples,thatmaycaptureapatternrelated
tosemantics,syntax,specificwords,orsome-
thingelseinthesamplepair. Thesesamples
ledtoaclassificationalgorithmmisclassifying
thematahighlevelofconfidence.
Given the samples and a previously gener-
alized hypothesis, generate one new sample
madeupofoneormoresentencesthatrelate
to {task} and could have a similar effect on
theclassificationalgorithm.
Thenewsampleshouldbevariedanddetailed.
Followthelogiclaidoutinthegivenhypoth-
esisandfollowtheformatofthesamplepair
(OandP)exactly. Alsoincludewhetherthe
new sample should be given a «positive» or
«negative»labelforthetask: {task}.
Thehypothesisis: {hypothesis}
Your response should always follow the for-
mat:
Sample: «sample»
Label: «label»
Reasoning: «reasoning»”