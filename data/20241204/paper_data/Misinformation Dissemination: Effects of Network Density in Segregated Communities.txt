Misinformation Dissemination: Effects of Network
Density in Segregated Communities
Soroush Karimi,∗ Marcos Oliveira, and Diogo Pacheco
DepartmentofComputerScience,UniversityofExeter,UK
∗sk931@exeter.ac.uk
Abstract.
Understandingtherelationshipbetweennetworkfeaturesandmisinformationprop-
agation is crucial for mitigating the spread of false information. Here, we investi-
gate how network density and segregation affect the dissemination of misinfor-
mation using a susceptible-infectious-recovered framework. We find that a higher
densityconsistentlyincreasestheproportionofmisinformationbelievers. Insegre-
gatednetworks,ourresultsrevealthatminoritiesaffectthemajority: denserminor-
ity groups increase the number of believers in the majority, demonstrating how the
structure of a segregated minority can influence misinformation dynamics within
themajoritygroup.
Introduction
Misinformationposesasignificantchallengeintoday’sdigitizedsociety(1–3),withsocialme-
dia platforms often serving as primary vectors for its dissemination, fueling polarisation (4),
anti-vax sentiments (5), violence (6,7), and political interference (8,9). Despite its widespread
effects, our understanding of the mechanisms underlying misinformation remains elusive (10).
Inparticular,westilldonotfullyunderstandtheroleofsocialgroups(andtheirstructure)inthe
spread of misinformation. In this work, we investigate the dynamics of misinformation spread,
focusingontheroleofnetworkdensityindiversesocialstructures.
Previous works have highlighted the main role of network structure in amplifying false-
hoods and the need for a better understanding of group density (11–13). For example, a higher
density of social networks is associated with higher levels of dissemination of misinformation,
1
4202
voN
92
]IS.sc[
1v66891.1142:viXraparticularlywithinconservativeclusters(11). Similarly,conservativeTwitterusersofteninhabit
denser networks and are more exposed to low-credibility content, perpetuating the circulation
of partisan content (12). Such homogeneous social networks foster an environment conducive
to misinformation proliferation, making individuals more susceptible to misinformation and
triggeringcascadeeffectsthatextendtothebroaderpopulation(13).
To understand these dynamics, simulation provides a valuable framework to gain insights
into real-world phenomena and pinpoint influential factors (14). For instance, Tambuscio et
al. proposed a model that simulates individuals transitioning among susceptible, fact-checker,
and believer states, shedding light on the mechanisms driving misinformation propagation and
guiding counter-strategies (15). However, their model focuses primarily on individual traits,
suchasgullibility,withoutaccountingfortheimpactofnetworkdensity(16).
In our work, we highlight the fundamental role of network density in both segregated and
non-segregated networks. We explore how denser networks correlate with a higher percentage
of believers in hoaxes and investigate the impact of a dense minority on the belief percentage
within the majority. Our results unveils a positive correlation between network density and
the prevalence of believers—individuals propagating misinformation—within a network. This
correlationechoesfindingsfrompriorempiricalstudies(12,17,18)andsuggeststhatdensernet-
works facilitate misinformation dissemination. This trend persists within segregated networks,
whereincreaseddensitywithingroupscorrespondstoagreaternumberofbelieverswithinthose
groups.
We also explore cross-group effects and reveal that in networks with both majority and
minority groups, the majority influences the minority, as expected. Surprisingly, however, we
uncover a reciprocal effect: changing the density of the minority group—while keeping the
majority’sdensityconstant—affectsthemajorityaswell.
These insights carry significant implications for mitigating and addressing misinforma-
tion(19),emphasizingthecriticalroleofoursocialconnections. Theydemonstratethatactions
from even highly segregated groups can influence the broader population, shaping collective
behaviour. The interplay between these findings and the impact of superspreaders remains an
openquestion(20).
2Modelling misinformation spread
Tounderstandhownetworkdensityaffectsthespreadofthemisinformation,weuseasusceptible-
infectious-recovered model (15). We apply it to networks with varying densities in segregated
andunsegregatedscenarios.
The susceptible-believer-fact-checker model
We use the susceptible-believer-fact-checker (SBFC) spread model, previously proposed for
modelling misinformation dissemination in networks (15). This model, rooted in epidemic
modelling, treats hoaxes as viral infections and integrates a mechanism for fact-checking to
combattheirpropagation. Thedynamicsofthemodelaregovernedbytheinteractionsbetween
individualswiththeirneighbours,eachofwhomcanbeinoneofthemodel’sstates(seeFig.1).
In the model, individuals in the network can be in one of three states: susceptible (S),
believer (B), or fact-checker (F). Those in the susceptible state have not been exposed to the
hoaxorhaveforgottenaboutit. Believershavebeenexposedtothehoaxandbelieveit. Finally,
fact-checkershaveverifiedthehoaxandnolongerbelieveit.
The model is characterized by four parameters: the overall spreading rate β, the agents’
gullibility α, the probability p to verify a hoax (i.e., the probability that a believer will
verify
fact-checkahoaxandbecomeafact-checker),andtheprobabilityp thatanindividualwill
forget
forget their current belief state and become susceptible again. The spread of a hoax and its
1 −𝑓(𝑡) − 𝑔(𝑡)
𝑖 𝑖
Susceptible
𝑔 𝑡 𝑓 𝑡
𝑖 𝑖
𝑝
𝑓𝑜𝑟𝑔𝑒𝑡
Fact-Checker Believer
𝑝
𝑣𝑒𝑟𝑖𝑓𝑦
1− 𝑝
𝑓𝑜𝑟𝑔𝑒𝑡
1 − 𝑝
𝑣𝑒𝑟𝑖𝑓𝑦
− 𝑝
𝑓𝑜𝑟𝑔𝑒𝑡
Fig.1. SBFCmodel–transitionsbetweenstates. Adaptedfrom(15).
3debunkingcanbedescribedasfollows:
1. Spread of the hoax: When a susceptible agent i interacts with a believer at time step t,
thisagentmayadoptthehoaxandbecomeabelieverwithaprobabilitygivenby:
nB(t)(1+α)
f (t) = β i ,
i nB(t)(1+α)+nF(t)(1−α)
i i
where nB(t) and nF(t) are the counts of the i-th agent’s neighbors in the believer and
i i
fact-checkerstates,respectively.
2. Fact-checkinganddebunking: Believersmayfact-checkthehoaxandbecomefact-checkers
withprobabilityp . Likewise,susceptibleagentscanalsotransitiondirectlytoafact-
verify
checkerstate,withthefollowingprobability:
nF(t)(1−α)
g (t) = β i .
i nB(t)(1+α)+nF(t)(1−α)
i i
Once in the fact-checker state, individuals stop spreading the hoax and instead dissemi-
natedebunkinginformation.
3. Forgetting: Bothbelieversandfact-checkerscanforgettheircurrentbeliefstateovertime
andreverttothesusceptiblestate. Thisprocessisgovernedbyasingleprobabilityp
forget
andappliestobothbelieversandfact-checkers.
Let s (t) represent the state of the ith agent at time t, and define the state indicator function
i
for X ∈ {B,F,S} as si (t) = δ(s (t),X). The triple p (t) = (pi (t),pi (t),pi (t)) describes
X i i B F S
theprobabilitythatnodeiisineachofthethreestatesattimet.
Network Generation
We use the SBFC model to understand how network density influences the spread of misin-
formation in both segregated and unsegregated structures. Our analysis considers networks
composedoftwogroupsofdifferentsizes—amajoritygroupandaminoritygroup—whilealso
accountingforthedensitiesofinter-andintra-groupties.
To generate segregated networks, we use the edge probability matrix to independently con-
trol the probability of intra- and inter-group links (21,22). The edge probability matrix H is
definedasfollows:
(cid:20) (cid:21)
h h
H = 00 01 , (1)
h h
01 11
4where h and h are the probabilities of intra-group edges, whereas h is the probability of
00 11 01
creating an inter-group edge. In our work, we denote f as the proportion of nodes belonging
0
totheminoritygroup.
Results
Weinvestigatehownetworkdensityinfluencesthespreadofmisinformationinbothsegregated
and unsegregated networks. To model unsegregated networks, we use the Erdo˝s-Re´nyi model,
whereas we construct segregated networks by tuning h , h , and h . This setup allows us to
00 11 01
examinetheeffectsofgroupsizeandconnectionpatternsonmisinformationspreading.
Unsegregated Networks
Inunsegregatednetworks,ourresultsshowthatdensernetworksleadtomorebelievers. Fig.2a
shows the impact of network density on the percentage of believers with the same level of
gullibility (α = 0.3), where the parameter p represents the probability of any two nodes in
an Erdo˝s-Re´nyi network. As p increases (i.e., a higher network density), the percentage of
individualsendorsingthemisinformationalsoincreases.
We find that this result holds regardless of gullibility level. Fig. 2b shows the final percent-
ages of believers in a network comprising 1000 nodes, with varying values of the parameter p
and gullibility α. Each line in the plot represents a different level of gullibility, indicating how
belief formation is influenced by both network density and individual susceptibility. Across all
p=0.020 =0.8
   p=0.010    =0.7
p=0.006 =0.6
      =0.5
=0.4
=0.3
          
    
   
   
                                               
 7 L P H  6 W H S V  1 H W Z R U N  ' H Q V L W \
(a) (b)
Fig.2. (a)PercentageofBelieversovertime(α=0.3). (b)EffectofNetworkDensityonPercentageofBelievers
(n=1000,iterations=50,p =0.05,p =0.1,β =0.5).
verify forget
5
     V U H Y H L O H %  I R  H J D W Q H F U H 3      V U H Y H L O H %  I R  H J D W Q H F U H 3linesrepresentingdifferentlevelsofgullibility,anincreaseinpcorrespondstoahigherpercent-
ageofbelievers. Thistrendunderscorestheroleofnetworkdensityinfacilitatingthespreadof
misinformation, highlighting the importance of understanding network structure in combating
falsebeliefs.
Segregated Networks
In segregated networks, we find that increasing the density of the minority group not only
increases the percentage of believers within that group but also affects the majority group, es-
peciallyastheminoritysizegrows. Weexaminetheaveragepercentageofbelievermembersin
the majority group across varying minority group sizes, ranging from 10% to 30% of the total
population (see Fig. 3). Consistent with the results of unsegregated networks, we find that an
increase in the density of the majority group (i.e., h ) yields a higher percentage of believers
11
withinthisgroup.
Remarkably, increasing the density within the minority group (i.e., h ) raises the percent-
00
age of believers in the majority group, with this effect intensifying as the minority group size
increases. For example, with h = 0.007 and a minority group comprising 20% of the pop-
11
ulation, increasing the density of the minority group results in a five-fold increase in believers
withinthemajoritygroup,fromaround2%to10%.
 0 L Q R U L W \  V L ] H         0 L Q R U L W \  V L ] H         0 L Q R U L W \  V L ] H       
  
  
 0 D M R U L W \  ' H Q V L W \
 
h 11=0.009
h 11=0.007
h 11=0.005
  h 11=0.003
 
 
                                                        
 ' H Q V L W \  R I  W K H  0 L Q R U L W \  * U R X S  h  
00
Fig.3. PercentageofBelieversintheMajorityforDifferentMinorityNetworkDensities(n=1000,h =0.002,
01
steps=1000,iterations=100,p =0.05,p =0.1,β =0.5,α=0.3)
verify forget
6
     \ W L U R M D 0  Q L  V U H Y H L O H %Discussion
Our work demonstrates the critical role of network density in the spread of misinformation.
Denser networks, whether unsegregated or segregated, foster a greater prevalence of false be-
liefs. Insegregatednetworks,adenseminoritygroupnotonlyincreasesthepercentagebelievers
within itself but also amplifies this effect in the majority group. Here, the minority refers to a
segregated group that shares the same characteristics as the majority group, except for having
greater network density. These insights highlight the need to consider network structure when
developingstrategiestocombatmisinformation.
Our results indicate that targeting dense communities could be an effective strategy for
combatingthespreadofmisinformation. Suchcommunitiesarenotonlyhighlysuitableforthe
diffusion of misinformation but also amplify the percentage of believers in hoax news within
the broader population. By targeting these dense clusters, interventions can be more effective
inreducingtheoverallproliferationofmisinformation.
Furthermore, our findings serve as a caution even for skeptical individuals with low gulli-
bility: they may find themselves trapped in dense communities, inadvertently playing a role in
spreading misinformation. Despite their skepticism, the high frequency of interactions within
thesenetworksincreasesthelikelihoodthattheyencounterandsharefalseinformation.
In summary, our study sheds light on how network effects influence the spread of misinfor-
mation, providing a foundation for understanding its underlying mechanisms. Future research
should explore other network configurations and real-world scenarios to guide the design of
interventionsaimedatbuildingsocietalresilienceagainstmisinformation.
References
1. MuhammedT,S.&Mathew,S.K. Thedisasterofmisinformation: areviewofresearchin
socialmedia. Internationaljournalofdatascienceandanalytics13,271–285(2022).
2. Ferrara,E.,Chang,H.,Chen,E.,Muric,G.&Patel,J. Characterizingsocialmediamanip-
ulationinthe2020uspresidentialelection. FirstMonday(2020).
3. Pacheco, D. Bots, elections, and controversies: Twitter insights from brazil’s polarised
elections. In Proceedings of the ACM on Web Conference 2024, WWW ’24, 2651–2659
(AssociationforComputingMachinery,NewYork,NY,USA,2024).
74. Au, C. H., Ho, K. K. & Chiu, D. K. The role of online misinformation and fake news in
ideologicalpolarization: barriers,catalysts,andimplications. Informationsystemsfrontiers
1–24(2022).
5. Benoit, S. L. & Mauldin, R. F. The “anti-vax” movement: a quantitative report on vaccine
beliefsandknowledgeacrosssocialmedia. BMCpublichealth21,1–11(2021).
6. Paul, A. K. & Biswas, M. H. A. A mathematical model for the dynamics of the violence
epidemicspreadingduetomisinformation. InMathematicalandComputationalModelling
ofCovid-19Transmission,167–195(RiverPublishers,2023).
7. Pacheco, D., Flammini, A. & Menczer, F. Unveiling coordinated groups behind white
helmets disinformation. In Companion proceedings of the web conference 2020, 611–616
(2020).
8. Swire, B., Berinsky, A. J., Lewandowsky, S. & Ecker, U. K. Processing political misin-
formation: Comprehendingthetrumpphenomenon. RoyalSocietyopenscience4,160802
(2017).
9. Jerit,J.&Zhao,Y. Politicalmisinformation. AnnualReviewofPoliticalScience23,77–94
(2020).
10. Meng, Y., Broom, M. & Li, A. Impact of misinformation in the evolution of collective
cooperationonnetworks. JournaloftheRoyalSocietyInterface20,20230295(2023).
11. Chen,E.etal. Covid-19misinformationandthe2020uspresidentialelection. TheHarvard
KennedySchoolMisinformationReview(2021).
12. Chen, W., Pacheco, D., Yang, K.-C. & Menczer, F. Neutral bots probe political bias on
socialmedia. Naturecommunications12,5580(2021).
13. Jost, J. T., van der Linden, S., Panagopoulos, C. & Hardin, C. D. Ideological asymmetries
in conformity, desire for shared reality, and the spread of misinformation. Current opinion
inpsychology23,77–83(2018).
14. Raponi, S., Khalifa, Z., Oligeri, G. & Di Pietro, R. Fake news propagation: A review of
epidemic models, datasets, and insights. ACM Transactions on the Web (TWEB) 16, 1–34
(2022).
815. Tambuscio, M., Ruffo, G., Flammini, A. & Menczer, F. Fact-checking effect on viral
hoaxes: A model of misinformation spread in social networks. In Proceedings of the 24th
internationalconferenceonWorldWideWeb,977–982(2015).
16. Tambuscio, M., Oliveira, D. F., Ciampaglia, G. L. & Ruffo, G. Network segregation in a
model of misinformation and fact-checking. Journal of Computational Social Science 1,
261–275(2018).
17. Shao, C. et al. Anatomy of an online misinformation network. Plos one 13, e0196087
(2018).
18. DelVicario,M.etal. Thespreadingofmisinformationonline. Proceedingsofthenational
academyofSciences113,554–559(2016).
19. Van Der Linden, S. Misinformation: susceptibility, spread, and interventions to immunize
thepublic. Naturemedicine28,460–467(2022).
20. DeVerna,M.R.,Aiyappa,R.,Pacheco,D.,Bryden,J.&Menczer,F. Identifyingandchar-
acterizing superspreaders of low-credibility content on twitter. PLOS One 19, e0302201
(2024).
21. Oliveira,M.etal. Groupmixingdrivesinequalityinface-to-facegatherings. Communica-
tionsPhysics5,1–9(2022).
22. Karimi, F. & Oliveira, M. On the inadequacy of nominal assortativity for assessing ho-
mophilyinnetworks. ScientificReports13,21053(2023).
9