AlphaTablets: A Generic Plane Representation for 3D
Planar Reconstruction from Monocular Videos
YuzeHe1,WangZhao1,ShaohuiLiu2,YubinHu1,
YushiBai1,Yu-HuiWen3,Yong-JinLiu1∗
1TsinghuaUniversity 2ETHZurich 3BeijingJiaotongUniversity
Abstract
WeintroduceAlphaTablets,anovelandgenericrepresentationof3Dplanesthat
featurescontinuous3Dsurfaceandpreciseboundarydelineation. Byrepresenting
3Dplanesasrectangleswithalphachannels,AlphaTabletscombinetheadvantages
of current 2D and 3D plane representations, enabling accurate, consistent and
flexiblemodelingof3Dplanes. Wederivedifferentiablerasterizationontopof
AlphaTablets to efficiently render 3D planes into images, and propose a novel
bottom-uppipelinefor3Dplanarreconstructionfrommonocularvideos. Starting
with 2D superpixels and geometric cues from pre-trained models, we initialize
3D planes as AlphaTablets and optimize them via differentiable rendering. An
effectivemergingschemeisintroducedtofacilitatethegrowthandrefinementof
AlphaTablets. Throughiterativeoptimizationandmerging,wereconstructcom-
pleteandaccurate3Dplaneswithsolidsurfacesandclearboundaries. Extensive
experimentsontheScanNetdatasetdemonstratestate-of-the-artperformancein
3Dplanarreconstruction,underscoringthegreatpotentialofAlphaTabletsasa
generic3Dplanerepresentationforvariousapplications. Projectpageisavailable
at: https://hyzcluster.github.io/alphatablets.
1 Introduction
3Dplanarreconstructionfrommonocularvideosisacrucialaspectof3Dcomputervision,dedicated
totheprecisedetectionandreconstructionofunderlying3Dplanesfromconsecutive2Dimagery.The
reconstructed3Dplanesserveasaflexiblerepresentationofsurfaces,facilitatingvariousapplications
suchasscenemodeling,mixedrealityandrobotics.
Traditionalmethodsfor3Dplanarreconstructionrelyheavilyonexplicitgeometricinputs[36,41],
hand-crafted features [6, 4], strong assumptions [10, 15] and solvers [37, 42, 16] to detect and
reconstructtheplanes,therebyimposinglimitationsonscalabilityandrobustness. Learning-based
methods [27, 26, 2, 28, 48] leverage the power of data-driven training to directly segment the
plane instances and regress the plane parameters from single or sparse-view images. Notably,
PlanarRecon[50], apioneering monocularvideo-basedlearning method, operates withinthe3D
volumespacetodetectandtrackplanes,andhasdemonstratedpromisingresultsinrecoveringplanar
structures. However,itoftenfallsshortindetectingcompleteplanarreconstructionsandstruggles
withgeneralizationacrossdiversescenes. Howtobuildanaccurate,completeandgeneralizable3d
planarreconstructionsystemisstillachallengingopenproblem.
Weinspectthisproblemfromtheperspectiveofplanerepresentation. Currentmethodologiesemploy
variousrepresentations,suchasview-based2Dmasks[42,16,3,9,26,2,48],3Dpoints[37,30],
surfels[36],andvoxels[50]. While2Dmaskscanpreciselyillustrateplanecontours,this2Dplane
representationfacesinconsistenciesacrossdifferentviewsandnecessitatescomplexmatchingand
fusionprocessestoreconstruct3Dsurfaces. Incontrast,3Drepresentationsdirectlydepict3Dplanar
surfaces. However,theysufferfromdiscontinuousgeometryandtextureduetodiscretizedsampling,
andstruggletoaccuratelymodelcomplexplaneboundaries.
∗CorrespondingAuthor.
38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024).
4202
voN
92
]VC.sc[
1v05991.1142:viXraToaddressabovelimitations,weproposeanovelplanerepresentationtermedAlphaTablets. AlphaT-
abletsdefine3Dplanesasrectangleswithalphachannels,providinganaturaldelineationofirregular
planeboundariesandenablingcontinuoussolid3Dsurfacerepresentation. AlphaTabletscombine
thebestof2Dand3Dplanepresentations: bydefiningandoptimizingin3D,AlphaTabletsensure
efficiencyandconsistencyacrossallviews;meanwhile,byintroducingalphachannelsandtexture
mapsinplane’scanonicalcoordinates,AlphaTabletscanaccuratelymodelsolidsurfacesandcomplex
irregularplaneboundaries. Furthermore,weintroducerasterizationformulationsforAlphaTablets,
facilitatingdifferentiablerenderingintoimages.
BasedonAlphaTablets,wepresentabottom-uppipelinefor3Dplanarreconstructionfromposed
monocular videos. Initially, leveraging 2D superpixels [1], we initialize the AlphaTablets using
pre-traineddepthandsurfacenormalmodels[19,12]. Thisinitializationyieldsadenseyetnoisy
assemblyofrelativelysmallandoverlappingAlphaTablets.Next,thesesmallplanesareoptimizedvia
differentiablerenderingwithhybridregularizerstoadjustbothgeometry,textureandalphachannels.
Wefurtherintroduceaneffectivemergingschemethatfacilitatesthefusionofneighboringtablets,
therebypromotingthegrowthoflarger,cohesiveplanes. Throughiterativecyclesofoptimization
and merging, our final reconstructions boast solid surfaces, clear boundaries, and interpolatable
texture maps, delivering accurate 3D planar structures. Moreover, our approach enables flexible
plane-basedsceneediting. ExtensiveexperimentsonScanNet[11]datasetdemonstratestate-of-the-
artperformanceof3Dplanarreconstruction,showingthegreatpotentialofbeingageneric3Dplane
representationforsubsequentapplications.
Insummary,ourcontributionsarethreefold:
• We propose AlphaTablets, a novel and generic 3D plane representation which features
effectiveandflexiblemodelingofplanegeometry,textureandboundaries. Wederivethe
rasterizationformulationforAlphaTablets,enablingdifferentiablerenderingtoimages.
• Webuildanaccurateandgeneralizable3Dplanarreconstructionsystemfrommonocular
videosuponAlphaTablets. Thekeycomponentsareeffectiveinitializationfrompre-trained
monocular cues, differentiable rendering based optimization, and the proposed merging
mechanismforAlphaTablets.
• Theproposedsystemachievesstate-of-the-artperformancefor3dplanarreconstruction,
whilealsoenablingflexibleplane-basedsceneeditingforvariousapplications.
2 RelatedWorks
Classical3DPlaneReconstruction. Traditional3Dplanereconstructionmethodstypicallyfitplanes
fromgeometricinputslikeRGB-Dimages[36,41,35,21]and3Dpointcloud[7,43],usingrobust
estimatorssuchasRANSAC[14]anditsvariants[37]. Anotherlineofresearchapproachesutilize
multi-viewimagesasinput. Earlyworks[42,16,15,3]detect3Dplanesfromreconstructedsparse
3Dpointsandlines,andthenoptimizeplanemasksasmulti-labelsegmentationthroughimage-based
solverssuchasMarkovRandomFields(MRF)andGraphCut[23]. Argilesetal.[3]proposeaplane
consistencychecktodetermineplaneboundariesusingsquarecellsratherthansparsepointcontours.
Manhattanworldassumptionisintroduced[10,53]tobetterreconstructthedominantplanes. While
thesemethodscansegment2Dcomplexplanes,the2Dmaskrepresentationofplanescausesview
inconsistency,visibilityissuesandrequiresadditionaleffortstoreconstruct3Dplanes. Incontrast,
AlphaTabletsdirectlymodelandoptimizeplanesin3Dwithdifferentiablerendering,eliminatingthe
inconsistencyandocclusionproblems. Givenamonocularvideoasinput,DPPTAM[9]reconstructs
both the 3D planar and non-planar structure in a SLAM fashion, and adapt superpixel to group
homogeneouspixelsfortexturelessregions. Ourmethodalsousessuperpixelsas2Dunitstoinitialize
AlphaTablets,butprovidesgreaterflexibilityinadjustinggeometry,texture,andboundariesthrough
optimization.
Learning-based3DPlaneReconstruction. Data-drivenmethodsleveragelarge-scaletrainingdata
tolearngeometricpriors,enablingthereconstructionof3Dplanesfromsingleorsparseviewimages.
PlaneNet[27],PlaneRecover[52]andPlaneRCNN[26]createtrainingdatasetsforplanedetection
andreconstruction,andtraindeepneuralnetworkstodirectlysegmentplaneinstancesandregress
planeparametersfromsingleRGBimage. Furtherenhancementsalongthislineincludetheuseof
transformerarchitectures[47],multi-taskcollaboration[40],pairwiseplanerelations[34],andfeature
clustering[54],etc. Duetothehighlyill-posednatureofsingle-imageplanereconstruction,many
2UpVector
RGBTexture
Transparency
Initializedfrom Position Distance
Keyframeimages Ratios
Normal Pixel
Range
Pixel
Range
3D Properties 2D Properties VolumetricRendering
Figure1: Illustrationoftabletpropertiesandrendering. Normalandupvectordeterminesthe
rotationofatabletin3Dspace,whileeverytabletmaintainsadistanceratiobetweenthecoordinates
ofthe3Dfieldand2D-pixelspace.
works[2,22,28,48]adoptsparseviewimagesasinputs,andexplorejointplanedetection,association
andoptimizationtohelpthefinalreconstruction. However,thesemethodscanonlyrecoverlocal
3Dplanarstructuresfromsparseviews,anditischallengingtoextendthemtoimagesequences.
PlanarRecon[50]proposesa3Dvolume-basedplanarreconstructionsystemwithplanedetection
andtrackingmodulesthatsequentiallyprocessvideoframesandupdate3Dplanarreconstructions.
Whileeffectiveinproducingcleanandconsistent3Dplanes,PlanarReconoftenoversimplifiesplanar
structures,resultinginincompletereconstructions.Furthermore,beingtrainedonindoordatasetswith
gravity-alignedcameraposes,PlanarReconstrugglestogeneralizetounseendata. Onthecontrary,
ourmethodoptimizesAlphaTabletsforeachscene,thuscangeneralizetoanyvideosequence.
3DPlanarSurfaceRepresentation. Whilemostofcurrentworksemploy2Dplanerepresentation
fordetectionandreconstruction,3Drepresentationismoreefficientandconsistentbyaggregating
2Dimageinformationdirectlyin3D.3Dpointcloud[37,38,33,51,32]isoneofthemostwidely
used3Dsurfacerepresentation,yettheyarediscretesamplesofasurfaceandcannotfullycapture
continuousgeometryandtextures. Extendingpointsintoplanarprimitives,surfels[36,17]and2D
gaussians[18,20]representsurfacewith2Ddisksin3Dspace,anddemonstrateimpressiveresults
forbothplanarandnon-planarsurfaces. Unfortunately,bothsurfelsand2Dgaussiansonlyprovide
localplanarstructurewithinoneunit,makingitdifficulttodirectlyrepresentlargegeometricplanes.
Intermsofcontinuoussurfacerepresentation,meshisthemostpopularrepresentationwithmature
graphicpipelines. Manyworks[50,42,49,39]convertother3Dsurfacerepresentationsintomesh
forvisualizationorfurtheroptimization. Whilemeshesusing3Dtrianglesorrectanglescanrepresent
3Dplaneswithregularquadrangularshapes,theystrugglewithirregularcomplexboundariesand
aredifficulttobuildandoptimizefromscratch. AlphaTabletsinherittheadvantagesofcontinuous
geometryandcanonicaltexturemodelingfrommesh,andfurtherintroducealphachannelstohandle
theirregularplaneboundaries,actingas"rectanglesoupwithalphachannels". Withthepopularity
ofimplicitneuralrepresentation,severalworks[25,8]haveexploredencoding3Dplaneprimitives
with MLPs. Compared to implicit representations, AlphaTablets offer the advantages of explicit
representation,suchaseasyeditingandfastrenderingwithoutnetworkinference.
3 Method
OurproposedAlphaTabletsisanovelandgeneric3Dplanerepresentation,whichenablesaccurateand
generalizable3Dplanarreconstructionfrommonocularvideoinputs. InSec.3.1,wefirstintroduce
the data format of AlphaTablets, then discuss the differentiable rasterization of AlphaTablets in
Sec.3.2. Finally,inSec.3.3,weintroduceabottom-uppipelinebasedonAlphaTabletstoconduct3D
planarreconstructionfrommonocularvideoinput.
3.1 AlphaTablets: Representing3DPlaneswithSemi-TransparentRectangularPrimitives
As illustrated in Figure 1, our proposed AlphaTablet is shaped as a rectangle with 3D geometry
propertiesand2Din-tabletproperties. The3Dgeometryincludesthetabletcenterpointp,normal
vector n, up vector u and right vector r. The normal, up and right vectors are orthogonal. The
2Din-tabletinformationcontainsatexturemapc,analphachannelα,andapixelrange(ru,rv)
thatindicatesthe2Dresolutionofthetextureandtransparencymap. Thealphachannelαensures
thatarbitraryshapescanbemodeledbyourtabletformation. Sincetheratioofunitdistancein3D
spaceand2Din-tabletcanonicalspacevariesacrossdifferenttablets,distanceratiosλ ,λ oftwo
u v
directionsonthetexturemapisalsomaintainedforeverytablettoacquirethetabletsizein3Dspace.
33.2 DifferentiableRasterization
Asageneric3Dplanarsurfacerepresentation,efficientprojectionfrom3Dto2Dimagesishighly
demandingforAlphaTablets. Therefore,weintroducethedifferentiablerasterizationofAlphaTablets.
The data format of AlphaTablets is the 3D rectangle soup with alpha channels, allowing us to
easilyadaptandutilizeexistingmesh-basedefficientdifferentiablerenderingframeworks,suchas
NVDiffrast[24]tocompositeandrenderanarbitrarynumber,shape,andpositionoftabletsinafully
differentiablemanner.
Pseudo Mesh Construction. We can leverage differentiable mesh rendering frameworks like
NVDiffrast[24]byconvertingthetabletsintopseudomeshesbeforeeachrenderingpass. Notethat
thisconversionisjustusedfortheadaptionofNVDiffrast. Givenasingletablett ,wecanconvertit
i
totwomeshtrianglefacesthroughthefollowingprocess:
[p −ru /λ −rv /λ , p −ru /λ +rv /λ ,
i i u,i i v,i i i u,i i v,i
v = (1)
i p +ru /λ +rv /λ , p +ru /λ −rv /λ ]
i i u,i i v,i i i u,i i v,i
f =[[0,1,2],[0,2,3]] (2)
i
Wherev representsthe3Dvertexcoordinates,andf denotesthefaceindices,consistentwiththe
i i
generalmeshdefinition. Thetextureandalphamapsofalltabletsaretiledontoaglobaltexturemap
accordingtotheirrespectiveresolutions(ru ,rv ). Thespecifictilelocationservesasthetexture
i i
coordinatesforthefourverticesofeachtablet.
Multi-layerRasterization. AstransparencyinformationisusedinAlphaTablets,therasterization
processinourapproachrequiresrasterizingmultiplelayersthroughdepthpeelingtoextractmultiple
closestsurfacesforeachpixel. Giventhemodel-view-projection(MVP)matrixM ofaspecific
k
viewk,therasterizationresultofthel-thclosestsurfacefortheimagepixel(i,j)canbeformedas:
R (M ,i,j)=(u ,v ,tri ) (3)
l k i,j i,j i,j
whereu andv arethebarycentriccoordinateswithinatriangle,andtri isthetriangleindex.
i,j i,j i,j
Thecolorandalphavaluesc(i,j)andα(i,j)arethenacquiredfromthetexturemapusingthetwo
coordinatesandthetriangleindex.
Anti-aliasingforAlphaTablets. Previousanti-aliasingtechniquesinrasterizationpredominantly
work on non-transparent primitives without considering learnable alpha values of each face, yet
alphachannelisacrucialcomponentforAlphaTablets. Anintuitiveapproachtoincorporatealpha
channelswouldbetoconductanti-aliasingforbothtextureandalphawithineachrasterizationlayer.
However,thisstraight-forwardmethoddoesnotworkwellontabletswithalphachannels. Asimple
counterexampleistwooverlappingplaneswithconstantalphavaluesof0and1,respectively. The
rasterizationresultsintworasterizedlayersfortheintersectionpixelofthetwoplanes. Andthe
anti-aliasingwouldresultinbothlayershavinganalphavaluebelow1,causingincorrecttransparency
andcolorsattheintersectedboundariesinthefinalalphablendingprocess.
Toaddressthisissue,weproposeananti-aliasingmethodforthesemi-transparentprimitives. Given
apixelthroughwhichtheboundarylinesoftwoplanespass,withtheoriginalcolorsc andc ,and
1 2
alphavaluesa anda ,respectively,andanti-aliasingweightswand1−w,theprocesstoobtainthe
1 2
anti-aliasedcolorc isasfollows:
aa
α c w+α c (1−w)
c = 1 1 2 2 (4)
aa α w+α (1−w)
1 2
Andthealphavalueisnotanti-aliased. Theintuitiveideaisthattheblendingweightsofanti-aliasing
shouldnotonlybedeterminedbyoverlappingareas,butalsotakealphavaluesintoconsideration.
Foreachrasterizationlayer,anti-aliasingcanbefurtherexpressedusingthefollowingformula:
AA(αc)
c = , α =α (5)
aa AA(α) aa
Whereαandcarethealphaandcolorvaluesbeforeanti-aliasing,c andα arethealphaand
aa aa
colorvaluesafteranti-aliasing,andAAistheanti-aliasingfunction. Weshowanexamplefigure9in
appendixtodemonstratetheclearimprovementsaftertheanti-aliasformulacorrection.
AlphaComposition. Oncewehavemultiplerasterizedlayers,wecanstackthemindepthorderand
blendthemusingthealphacompositingprocesswidelyemployedinvolumerenderingandneural
4Tablet Initialization Texture & Geometry Optimization
Video
Keyframes Normal Position
Joint
Photometric
M Don epo tc hu slar Back Projection Guidance Texture Transparency
To 3D Space
Iterative Refinement
with estimated
CameraPose
Merging Scheme
Monocular
Normals
SuperPixel
Division
Bottom-UpMerging with arbitrary shapes
Figure2: Pipelineofourproposed3Dplanarreconstruction. Givenamonocularvideoasinput,
wefirstinitializeAlphaTabletsusingoff-the-shelfsuperpixel,depth,andnormalestimationmodels.
The3DAlphaTabletsarethenoptimizedthroughphotometricguidance,followedbythemerging
scheme. Thisiterativeprocessofoptimizationandmergingrefinesthe3DAlphaTablets,resultingin
accurateandcomplete3Dplanarreconstruction.
radiancefields. Thefinalcolorofpixel(i,j)canbecalculatedas:
L l−1
(cid:88) (cid:89)
c = T α c , T = (1−α ) (6)
i,j i,j,l i,j,l i,j,l i,j,l i,j,m
l=1 m=1
Wherec andα arethecolorandalphavaluesatpixel(i,j)ofthel-thrasterizationlayer. T
i,j,l i,j,l i,j,l
representstheaccumulatedtransmittanceofthepreviousl−1layersforthegivenpixel.
3.3 ABottom-upPlanarReconstructionPipelinewithAlphaTablets
AlphaTabletsprovideflexible3Dplanemodelingandefficientdifferentiablerendering. Building
onthis,weproposeabottom-up3Dplanarreconstructionpipelineformonocularvideoinput. As
illustratedinFigure2,AlphaTabletsarefirstinitializedviaoff-the-shelfgeometricestimations,then
thetextureandgeometryparametersofAlphaTabletsareoptimizedusingdifferentiablerendering.
Tabletsareexaminedandmergedtowardslargerandmorecomplete3Dplanes. Theoptimizationand
mergingbenefitfromeachotherthroughiterativerefinement. Byformulatingtheplanesegmentation
asabottom-upclusteringof3DAlphaTabletsandplaneparameterestimationasrenderingbased
optimization,ourpipelinecanaccuratelyreconstructdetailedplanarsurfaces.
Initialization. We initialize the AlphaTablets using off-the-shelf geometric prediction models,
includingthosefordepth,surfacenormalandsuperpixel. Specifically,foreachkeyframeoftheinput
video,wefirstapplySLIC[1]methodtosegmentimagesinto2Dsuperpixelsbasedonlocalcolor
homogeneity. Next,weutilizepretrainedgeometricmodels[19,12]toestimatedepthandsurface
normalforeachimage. Toobtaininitialdepthandsurfacenormalvaluesforeachsuperpixel,we
perform2Daveragepoolingwithineachsuperpixel’sregion. These2Dsuperpixelsarethenback-
projectedinto3Dspacetoformtheinitialtabletrepresentation. Besides3Dgeometry,thetexture
mapsandalphachannelsareinitializedusing2Dpixelcolorsandsuperpixelmasks,respectively.
Therectangleboundingboxisdeterminedbytheminimumandmaximumvaluesoneach3Dtablet’s
twoorthogonalaxes: upandrightvector.
Optimization. Initializedfrom2Dview-baseddepth,surfacenormalandsuperpixelestimations,
the initial 3D AlphaTablets may contain errors, overlaps, and inconsistency. We thus perform
differentiablerenderingbasedoptimizationtoupdatetheparametersof3DAlphaTablets.
LearnableParameters. Whilethe3DAlphaTabletsoffersignificantflexibility,directlyoptimizing
themforunrestrictedmovementin3Dspacecancauseinstability. Tomitigatethis,weconstraineach
tablet’scentertoremainonitsinitialcameraray. Inthisway,wethusoptimizethenormalvectorn
5anddistanced,ratherthan3Dcenterpositionp,wheredrepresentsthedistancebetweenthetablet’s
centerandthecameracenteroftheviewfromwhichitwasinitialized. Theupvectorsoftablets
areupdatedwithnormaltokeeptherigidtransformationcharacteristicsofthetablet. Additionally,
the texture and alpha channel values of each tablet are treated as learnable parameters, enabling
appearancerefinementtoenhancethefidelityofthereconstructedplanarsurfaces.
LossDesign. Theoptimizationprocessisdrivenbyasetofcarefullydesignedlossfunctionsthat
collectively refine the tablet parameters to achieve accurate planar reconstruction. Given input
monocularvideo,weadoptthephotometriclossasthemeansquarederrorbetweentherendered
imagecofthetabletsandtheobservedinputimagesc : L = ||c−c ||2. Byminimizingthe
gt pho gt 2
photometricloss,the3DAlphaTabletscanbeoptimizedtobetterfittheinputimages. However,due
totheambiguityofphotometricalignmentandthecomplexityofoptimization,updatingAlphaTablets
onlywithphotometriclossresultsinfuzzyreconstructions. Wethusintroduceseveralimportant
lossestohelpmitigatetheambiguityandregularizethereconstruction.
Specifically,weusealphainverselosstopreventtheemergenceofsemi-transparentregionsafter
alphacomposition,whichisdefinedasL
=(cid:81)L
(1−α ). Moreover,weobservedthatmultiple
ainv l=1 l
semi-transparencytablets,insteadofonesolidtablet,mayoccupythesamesurfaceregiontoblend
therendering,whichharmsthegeometricsurfacereconstruction. Inspiredbymip-NeRF-360[5],we
utilizethedistortionlossforAlphaTabletstopenalizethemultiplesemi-transparencysurfacesand
promotethemergingoftabletsthatareincloseproximity. Thedistortionlossisdefinedasbelow:
L−1
(cid:88)
L = T T ||p −p || (7)
dist i i+1 i i+1 2
i=1
Where T is the blending weight of the i-th rasterization layer defined in Sec. 3.2, p is the 3D
i i
intersection point of the i-th rasterization layer. To further regularize the surface geometry and
smoothness,werenderthetabletstogetthedepthsd andsurfacenormalmapsn ,andsupervise
r r
thembytheinputmonoculardepthandsurfacenormalestimationsd ,n withmeansquarederror:
m m
L L
(cid:88) (cid:88)
d = T α d , n = T α n (8)
r l l l r l l l
l=1 l=1
d n
d= r , n= r (9)
(cid:81)L l=1(1−α l) ||n r|| 2
L =||d−d ||2, L =||n−n ||2 (10)
depth m 2 normal m 2
Thefinalobjectiveisdefinedas:
L=w L +w L +w L +w L +w L (11)
1 pho 2 ainv 3 dist 4 depth 5 normal
wherew ,w ,w ,w ,w arehyperparameterstobalancethelosses.
1 2 3 4 5
Merging Scheme. The optimized 3D AlphaTablets are still describing local 3D planar surface,
boundedbythe2Dsuperpixels. Therefore,torepresenttheexact3Dplanes,weneedtocoherently
mergetheindividualtabletsintolargertablets. Weintroduceahierarchicalmergingstrategythat
considershybridinformationincludingcolor,distance,andnormal,topreventthewrongmerging.
Specifically,wefirstconstructaKD-treetofindthetabletneighborhoods,andinitializeaunion-find
datastructureforalltablets. Eachunion-findsetdynamicallymaintainstheaveragecolor,center,
andnormalofallitsconstituentunittablets. Foreachtablet,wesearchtheKD-treetofindtheK
nearesttabletsandevaluatewhethertheysatisfythefollowingconstraintsformerging: (1)Theangle
betweenthenormalsofthetwotabletsshouldbesmallerthanathresholdθ. (2)Theanglebetween
theaveragenormalsoftheunion-findsetstowhichthetwotabletsbelongshouldbesmallerthan
athresholdθ . (3)Theprojecteddistancebetweentheaveragecentersoftheunion-findsetsalong
s
theiraveragenormalshouldbesmallerthanathresholdd. (4)Thedifferencebetweentheaverage
colorsoftheunion-findsetsshouldbesmallerthanathresholdc.
If all these constraints are satisfied, the two tablets are merged into the same union-find set. We
repeatthisprocessforalltablets,continuallyupdatingtheaveragecolor,center,andnormalofeach
union-findsetasmergesoccur. Thisiterativemergingprocedurecontinuesuntilnofurthermerges
arepossible,resultinginasetofcoherentplanarsurfacesrepresentedbythefinalmergedtablets.
Moredetailsaboutmergingareincludedintheappendix.
6Metric3D + Seq-RANSAC SuGaR+ Seq-RANSAC PlanarRecon Ours Ground Truth
High
Low
High
Low
Figure3: QualitativeresultsonScanNet. Errormapsareincluded. Betterviewedwhenzoomedin.
Table1: 3DgeometryreconstructionresultsonScanNet.
Method Comp↓ Acc↓ Recall↑ Prec↑ F-Score↑
NeuralRecon[46]+Seq-RANSAC 0.144 0.128 0.296 0.306 0.296
Atlas[31]+Seq-RANSAC 0.102 0.190 0.316 0.348 0.331
ESTDepth[29]+PEAC[13] 0.174 0.135 0.289 0.335 0.304
PlanarRecon[50] 0.154 0.105 0.355 0.398 0.372
Metric3D[19]+Seq-RANSAC 0.074 0.379 0.426 0.161 0.231
SuGaR[18]+Seq-RANSAC 0.121 0.324 0.385 0.296 0.327
Ours 0.108 0.161 0.481 0.447 0.456
4 Experiments
4.1 Evaluationon3DPlaneDetectionandReconstruction
Implementation Details. We use Metric3Dv2 [19] for predicting monocular depths and Om-
nidata[12]forsurfacenormals. WeleveragethekeyframeselectionmethodinNeuralRecon[46]
tosegmentthesceneintomultipleparts. Eachpartundergoesseparateoptimization,followedby
jointoptimizations. Thekeyframenumberofeachpartissetto9. Theseparateoptimizationfor
eachpartisperformedfor32epochs,whilethejointoptimizationstepisexecutedfor9epochs. The
weightsforthelossfunctionsaresetasfollows: [w ,w ,w ,w ,w ]=[1.0,1.0,20.0,4.0,4.0]. We
1 2 3 4 5
useAdamoptimizer,andthelearningratesforthetablet’stexture,alpha,normal,anddistanceare
setto0.01,0.03,1e-4,and5e-4,respectively. Afterthesecondmergestep,thelearningrateforthe
distanceisreducedto2e-4. Thenormalthresholdissetto0.93. Theentirereconstructionprocessfor
asinglescenetakesaround2hoursonaveragewhenexecutedonasingleA100GPU.
DatasetandEvaluationMetrics. WeuseScanNetv2[11]datasettoevaluatethe3Dplanedetection
andreconstructionperformanceofourproposedmethod. FollowingPlanarRecon[50],ourmethod
istestedonthevalidationsetofAtlas[31]usinggenerated3Dplanegroundtruth. Forevaluation
metrics,wefollowpreviousworks[50,26,54]touseMurez’s3Dmetrics[31]forgeometry,and
randindex(RI),variationofinformation(VOI),segmentationcovering(SC)asplanesegmentation
metrics. Toassessthesegmentationperformance,thereconstructedplaneinstancesaretransferred
ontothegroundtruthplanesusingthenearestneighborhoodapproach,followingcommonpractices.
7Table2: 3DplanesegmentationresultsonScanNet.
Method VOI↓ RI↑ SC↑
NeuralRecon[46]+Seq-RANSAC 8.087 0.828 0.066
Atlas[31]+Seq-RANSAC 8.485 0.838 0.057
ESTDepth[29]+PEAC[13] 4.470 0.877 0.163
PlanarRecon[50] 3.622 0.897 0.248
Metric3D[19]+Seq-RANSAC 4.648 0.862 0.209
SuGaR[18]+Seq-RANSAC 5.558 0.775 0.082
Ours 3.468 0.928 0.273
TUMDataset ReplicaDataset
Figure4: QualitativeresultsonTUM-RGBDandReplicadatasets.
Baselines. Wecompareourmethodwithdifferenttypesofrepresentativeworks. PlanarRecon[50]
is the state-of-the-art method of learning-based 3D planar reconstruction from monocular video.
Followingit,wecomparewithstrongbaselinesthatfirstreconstructthe3Dsceneandthenfit3D
planesusingRANSAC,includingsingleormulti-viewdepth-basedmethods[29,19],3Dvolume-
basedmethods[46,31],andtherecent3Dgaussianbasedmethod[18].
Quantitative Results. The evaluation results for 3D plane geometry and segmentation are pre-
sented in Table 1 and Table 2, respectively. Our proposed method achieves clear improvements
comparedtootherstate-of-the-artapproachesacrossvariousevaluationmetrics. 3Dvolume-based
reconstruct-then-fitmethodssufferfromreconstructionerrorsandnoisethreshold-sensitiveRANSAC,
andexhibitrelativelylowperformanceintermsofplanes’geometryand3Dcoherence. Depth-based
methodsinherentlyencounter3Dinconsistency,resultinginfragmentedandmulti-layeredpredictions.
PlanarRecon[50],whichisspeciallytrainedontheScanNetdataset,demonstratesthecapabilityto
predictmajorplaneswithhighgeometricaccuracy. However,itsperformanceishinderedbythe
limitedcoverageofthepredictedplanesandthefailuretodetectmanysmallplaneinstances. Ap-
proachesbasedon2DGaussianSplatting[18]tendtobeheavilyinfluencedbythepoorinitialization,
texturelessregionsandmotionblursinScanNet,resultingindegradedreconstructionperformance.
Comparedtoothermethods,ourapproachdemonstratesmuchimprovedoverallperformancefor
bothgeometryandsegmentation.
QualitativeResults. Toprovideaqualitativeassessmentofourmethod’sperformance,wefollow
PlanarRecon [50] and present the plane reconstruction results in Figure 3, along with the recall
errormaps. TheSuGaR+Seq-RANSACmethodsuffersfromerroneousgeometricreconstructions,
andtheMetric3D+Seq-RANSACisconstrainedbyinconsistentfuzzypointsandsub-optimalplane
segmentations. PlanarRecon,whilecapableofreconstructinglargeplanarsurfaceswithhighgeomet-
ricaccuracy,strugglestocaptureandreconstructsmallerplaneinstances,resultinginincomplete
representationsofthescene. Ourmethodbenefitsfromthebottom-upplanarreconstructionscheme,
andcanaccuratelypredictthe3Dplaneinstanceswhileexcellingindetectingandreconstructing
details, particularly for smaller plane instances. This capability significantly outperforms other
methodsinhandlingfine-grainedplanarstructures. Todemonstratethegeneralizationabilityofour
method,wefurthertestitonTUM-RGBD[45]andReplica[44]datasets. Qualitativeresultsare
showninFigure4. Ourmethodcanfaithfullyreconstruct3Dplanarsurfacesinvariousscenarios.
4.2 AblationStudies
To validate the efficacy of our method’s design, we conducted a series of ablation experiments
exploringtheimpactofvariouscomponents,includingthelossfunctions,mergeschemes,andtablet
anti-aliasing. The results are presented in Table 3. Tablet distortion loss encourages the planar
surfacestoconvergeandmerge,leadingtoimprovedperformance. Furthermore,thenormallossand
depthlosssignificantlycontributetothegeometricaccuracyofthereconstructedplanes,particularly
8Table3: Ablationstudies. AlphaInvdenotesthealphainverseloss.
Method F-score↑ VOI↓ RI↑ SC↑
OnlyPhotometricandAlphaInvloss 0.240 4.096 0.936 0.191
+TabletDistortionloss 0.271 3.741 0.937 0.253
+Normalloss 0.425 3.490 0.944 0.263
+Depthloss 0.456 3.466 0.944 0.284
w/otabletanti-aliasing 0.415 3.545 0.937 0.280
w/otabletmerge 0.188 6.991 0.939 0.098
Full 0.456 3.466 0.944 0.284
OriginalScene 3DCoherentSceneEditings
Figure5: 3Dsceneeditingexamplesofourmethod.
intexturelessregionswherephotometriclossconstraintsareinsufficient. Mergingschemeiscrucial
forproducingappropriate3Dplanes. Withoutmerging,the3DAlphaTabletsremainsmallplane
fragments,andthuscannotreconstruct3Dplanes,asshowninTable3. Moreover,tabletantialiasing
contributestosmootherresults,leadingtoenhancedoverallperformance.
4.3 ExampleApplication: 3DPlane-basedSceneEditing
OneofthesignificantadvantagesofAlphaTabletsrepresentationisitsabilitytoperformconsistent
3Dsceneeditingbysimplymodifyingthe2Dtexturemapsassociatedwiththereconstructedplanes.
AsillustratedinFig.5,ourmethodcanachieveimpressiveresultsforediting3Dscenes. Theaccurate
planereconstructionallowsforprecisetexturemapping,enablingtheseamlessapplicationoftextures,
text,orothervisualelementsontotheplanarregionswithinthescene. Furthermore,ourmethod
offerstheflexibilitytomodifythecolororperformstyletransferonindividualplanes,providinga
powerfultoolforcreativescenemanipulation.
4.4 LimitationsandFutureWork
AlphaTabletseffectivelyrepresent3Dplanes,butitmaystruggleinhighlynon-planarregionswhere
theplanarassumptionforasinglesuperpixeldoesnothold. Additionally,thecurrentAlphaTablets
representationdoesnotaccountforview-dependenteffects. Asaresult,theoptimizationrelieson
colorconsistencyacrossviews,whichcanbecompromisedbynon-Lambertiansurfacesorchangesin
lighting. Inthefuture,weaimtoenhanceAlphaTabletswithview-dependentmodeling,andexplore
hybridscenerepresentationsuchasAlphaTabletswithGaussians.
5 Conclusion
Inthiswork, weintroduceAlphaTablets, anovelandversatile3Dplanerepresentation. AlphaT-
abletsuserectangleswithalphachannelstorepresent3Dplanes,allowingforflexibleandeffective
arbitrary3Dplanemodeling. WederiveadifferentiablerasterizationprocessforAlphaTabletsto
enable efficient 3D-to-2D rendering. Building on this, we propose a novel bottom-up 3D planar
reconstructionpipelinefrommonocularvideoinput. LeveragingtheAlphaTabletsrepresentation,
alongwithcarefullydesignedoptimizationandmergingschemes,ourpipelinecanreconstructhighly
accurateandcomplete3Dplanarsurfacesinageneralizablemanner. ExperimentsontheScanNet
datasetdemonstratesignificantimprovementsoverbaselinemethods,highlightingthepotentialof
AlphaTabletsasageneralrepresentationfor3Dplanarsurfaces.
9Acknowledgement
ThisworkwassupportedbyBeijingScienceandTechnologyplanproject(Z231100005923029),
theNaturalScienceFoundationofChina(ProjectNumber62332019)andBeijingNaturalScience
Foundation(L222008).
References
[1] RadhakrishnaAchanta,AppuShaji,KevinSmith,AurelienLucchi,PascalFua,andSabineSüsstrunk. Slic
superpixelscomparedtostate-of-the-artsuperpixelmethods. IEEEtransactionsonpatternanalysisand
machineintelligence,34(11):2274–2282,2012.
[2] SamirAgarwala,LinyiJin,ChrisRockwell,andDavidFFouhey. Planeformers:Fromsparseviewplanes
to3dreconstruction. InEuropeanConferenceonComputerVision,pages192–209.Springer,2022.
[3] AlbertoArgiles,JavierCivera,andLuisMontesano. Densemulti-planarsceneestimationfromasparse
setofimages. In2011IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems, pages
4448–4454.IEEE,2011.
[4] CarolineBaillardandAndrewZisserman. Automaticreconstructionofpiecewiseplanarmodelsfrom
multipleviews. InProceedings.1999IEEEComputerSocietyConferenceonComputerVisionandPattern
Recognition(Cat.NoPR00149),volume2,pages559–565.IEEE,1999.
[5] JonathanTBarron,BenMildenhall,DorVerbin,PratulPSrinivasan,andPeterHedman. Mip-nerf360:
Unboundedanti-aliasedneuralradiancefields. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages5470–5479,2022.
[6] AdrienBartoli. Arandomsamplingstrategyforpiecewiseplanarscenesegmentation. ComputerVision
andImageUnderstanding,105(1):42–59,2007.
[7] DoritBorrmann,JanElseberg,KaiLingemann,andAndreasNüchter. The3dhoughtransformforplane
detectioninpointclouds:Areviewandanewaccumulatordesign. 3DResearch,2(2):1–13,2011.
[8] ZhengChen,QinganYan,HuangyingZhan,ChangjiangCai,XiangyuXu,YuzhongHuang,WeihanWang,
ZiyueFeng,LantaoLiu,andYiXu. Planarnerf:Onlinelearningofplanarprimitiveswithneuralradiance
fields. arXivpreprintarXiv:2401.00871,2023.
[9] AlejoConchaandJavierCivera.Dpptam:Densepiecewiseplanartrackingandmappingfromamonocular
sequence. In2015IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS),pages
5686–5693.IEEE,2015.
[10] AlejoConcha,MuhammadWajahatHussain,LuisMontano,andJavierCivera. Manhattanandpiecewise-
planarconstraintsfordensemonocularmapping. InRobotics:Scienceandsystems,2014.
[11] AngelaDai,AngelXChang,ManolisSavva,MaciejHalber,ThomasFunkhouser,andMatthiasNießner.
Scannet:Richly-annotated3dreconstructionsofindoorscenes. InProceedingsoftheIEEEconferenceon
computervisionandpatternrecognition,pages5828–5839,2017.
[12] AinazEftekhar, AlexanderSax, JitendraMalik, andAmirZamir. Omnidata: Ascalablepipelinefor
makingmulti-taskmid-levelvisiondatasetsfrom3dscans. InProceedingsoftheIEEE/CVFInternational
ConferenceonComputerVision,pages10786–10796,2021.
[13] ChenFeng,YuichiTaguchi,andVineetRKamat. Fastplaneextractioninorganizedpointcloudsusing
agglomerativehierarchicalclustering.In2014IEEEInternationalConferenceonRoboticsandAutomation
(ICRA),pages6218–6225.IEEE,2014.
[14] MartinAFischlerandRobertCBolles. Randomsampleconsensus: aparadigmformodelfittingwith
applicationstoimageanalysisandautomatedcartography. CommunicationsoftheACM,24(6):381–395,
1981.
[15] YasutakaFurukawa,BrianCurless,StevenMSeitz,andRichardSzeliski. Manhattan-worldstereo. In
2009IEEEConferenceonComputerVisionandPatternRecognition,pages1422–1429.IEEE,2009.
[16] DavidGallup,Jan-MichaelFrahm,andMarcPollefeys. Piecewiseplanarandnon-planarstereoforurban
scene reconstruction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition,pages1418–1425.IEEE,2010.
[17] YimingGao,Yan-PeiCao,andYingShan.Surfelnerf:Neuralsurfelradiancefieldsforonlinephotorealistic
reconstructionofindoorscenes. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages108–118,2023.
[18] AntoineGuédonandVincentLepetit. Sugar: Surface-alignedgaussiansplattingforefficient3dmesh
reconstructionandhigh-qualitymeshrendering. arXivpreprintarXiv:2311.12775,2023.
[19] MuHu,WeiYin,ChiZhang,ZhipengCai,XiaoxiaoLong,HaoChen,KaixuanWang,GangYu,Chunhua
Shen,andShaojieShen. Metric3dv2:Aversatilemonoculargeometricfoundationmodelforzero-shot
metricdepthandsurfacenormalestimation. arXivpreprintarXiv:2404.15506,2024.
[20] BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao. 2dgaussiansplattingfor
geometricallyaccurateradiancefields. arXivpreprintarXiv:2403.17888,2024.
[21] JingweiHuang,AngelaDai,LeonidasJGuibas,andMatthiasNießner. 3dlite: towardscommodity3d
scanningforcontentcreation. ACMTrans.Graph.,36(6):203–1,2017.
[22] LinyiJin,ShengyiQian,AndrewOwens,andDavidFFouhey. Planarsurfacereconstructionfromsparse
views. InProc.oftheIEEE/CVFInternationalConferenceonComputerVision,pages12991–13000,2021.
10[23] VladimirKolmogorovandRaminZabin. Whatenergyfunctionscanbeminimizedviagraphcuts? IEEE
transactionsonpatternanalysisandmachineintelligence,26(2):147–159,2004.
[24] SamuliLaine,JanneHellsten,TeroKarras,YeonghoSeol,JaakkoLehtinen,andTimoAila. Modular
primitivesforhigh-performancedifferentiablerendering. ACMTransactionsonGraphics(ToG),39(6):1–
14,2020.
[25] Zhi-HaoLin,Wei-ChiuMa,Hao-YuHsu,Yu-ChiangFrankWang,andShenlongWang. Neurmips:Neural
mixtureofplanarexpertsforviewsynthesis. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages15702–15712,2022.
[26] ChenLiu,KihwanKim,JinweiGu,YasutakaFurukawa,andJanKautz. Planercnn:3dplanedetectionand
reconstructionfromasingleimage. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,pages4450–4459,2019.
[27] ChenLiu,JimeiYang,DuyguCeylan,ErsinYumer,andYasutakaFurukawa. Planenet:Piece-wiseplanar
reconstructionfromasinglergbimage. InProceedingsoftheIEEEConferenceonComputerVisionand
PatternRecognition,pages2579–2588,2018.
[28] JiachenLiu,PanJi,NitinBansal,ChangjiangCai,QinganYan,XiaoleiHuang,andYiXu. Planemvs:3d
planereconstructionfrommulti-viewstereo. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages8665–8675,2022.
[29] XiaoxiaoLong,LingjieLiu,WeiLi,ChristianTheobalt,andWenpingWang. Multi-viewdepthestimation
usingepipolarspatio-temporalnetworks.InProceedingsoftheIEEE/CVFConferenceonComputerVision
andPatternRecognition,pages8258–8267,2021.
[30] HannesMöls,KailaiLi,andUweDHanebeck. Highlyparallelizableplaneextractionfororganizedpoint
cloudsusingsphericalconvexhulls. In2020IEEEInternationalConferenceonRoboticsandAutomation
(ICRA),pages7920–7926.IEEE,2020.
[31] ZakMurez,TarrenceVanAs,JamesBartolozzi,AyanSinha,VijayBadrinarayanan,andAndrewRabi-
novich. Atlas:End-to-end3dscenereconstructionfromposedimages. InComputerVision–ECCV2020:
16thEuropeanConference,Glasgow,UK,August23–28,2020,Proceedings,PartVII16,pages414–431.
Springer,2020.
[32] AlexNichol,HeewooJun,PrafullaDhariwal,PamelaMishkin,andMarkChen. Point-e: Asystemfor
generating3dpointcloudsfromcomplexprompts. arXivpreprintarXiv:2212.08751,2022.
[33] CharlesRQi,HaoSu,KaichunMo,andLeonidasJGuibas. Pointnet:Deeplearningonpointsetsfor3d
classificationandsegmentation. InProceedingsoftheIEEEconferenceoncomputervisionandpattern
recognition,pages652–660,2017.
[34] Yiming Qian and Yasutaka Furukawa. Learning pairwise inter-plane relations for piecewise planar
reconstruction. InComputerVision–ECCV2020:16thEuropeanConference,Glasgow,UK,August23–28,
2020,Proceedings,PartVII16,pages330–345.Springer,2020.
[35] CarolinaRaposo,MiguelLourenço,MichelAntunes,andJoaoPedroBarreto. Plane-basedodometryusing
anrgb-dcamera. InBMVC,volume2,page6,2013.
[36] RenatoFSalas-Moreno,BenGlocken,PaulHJKelly,andAndrewJDavison. Denseplanarslam. In2014
IEEEinternationalsymposiumonmixedandaugmentedreality(ISMAR),pages157–164.IEEE,2014.
[37] RuwenSchnabel,RolandWahl,andReinhardKlein. Efficientransacforpoint-cloudshapedetection. In
Computergraphicsforum,volume26,pages214–226.WileyOnlineLibrary,2007.
[38] JohannesLSchonbergerandJan-MichaelFrahm. Structure-from-motionrevisited. InProceedingsofthe
IEEEconferenceoncomputervisionandpatternrecognition,pages4104–4113,2016.
[39] TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler. Deepmarchingtetrahedra: a
hybridrepresentationforhigh-resolution3dshapesynthesis. AdvancesinNeuralInformationProcessing
Systems,34:6087–6101,2021.
[40] JingjiaShi,ShuaifengZhi,andKaiXu. Planerectr: Unifiedquerylearningfor3dplanerecoveryfrom
asingleview. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,pages
9377–9386,2023.
[41] NathanSilberman,DerekHoiem,PushmeetKohli,andRobFergus. Indoorsegmentationandsupport
inferencefromrgbdimages. InComputerVision–ECCV2012:12thEuropeanConferenceonComputer
Vision,Florence,Italy,October7-13,2012,Proceedings,PartV12,pages746–760.Springer,2012.
[42] SudiptaSinha,DrewSteedly,andRickSzeliski. Piecewiseplanarstereoforimage-basedrendering. In
2009InternationalConferenceonComputerVision,pages1881–1888,2009.
[43] ChristianeSommer,YuminSun,LeonidasGuibas,DanielCremers,andTolgaBirdal. Fromplanesto
corners:Multi-purposeprimitivedetectioninunorganized3dpointclouds. IEEERoboticsandAutomation
Letters,5(2):1764–1771,2020.
[44] JulianStraub,ThomasWhelan,LingniMa,YufanChen,ErikWijmans,SimonGreen,JakobJEngel,Raul
Mur-Artal,CarlRen,ShobhitVerma,etal. Thereplicadataset:Adigitalreplicaofindoorspaces. arXiv
preprintarXiv:1906.05797,2019.
[45] J.Sturm,N.Engelhard,F.Endres,W.Burgard,andD.Cremers. Abenchmarkfortheevaluationofrgb-d
slamsystems. InProc.oftheInternationalConferenceonIntelligentRobotSystems(IROS),Oct.2012.
[46] JiamingSun,YimingXie,LinghaoChen,XiaoweiZhou,andHujunBao.Neuralrecon:Real-timecoherent
3dreconstructionfrommonocularvideo. InProceedingsoftheIEEE/CVFconferenceoncomputervision
andpatternrecognition,pages15598–15607,2021.
[47] BinTan,NanXue,SongBai,TianfuWu,andGui-SongXia. Planetr:Structure-guidedtransformersfor3d
planerecovery. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,pages
114186–4195,2021.
[48] BinTan,NanXue,TianfuWu,andGui-SongXia. Nope-sac: Neuralone-planeransacforsparse-view
planar3dreconstruction. IEEETransactionsonPatternAnalysisandMachineIntelligence,2023.
[49] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus:
Learningneuralimplicitsurfacesbyvolumerenderingformulti-viewreconstruction. arXivpreprint
arXiv:2106.10689,2021.
[50] YimingXie,MatheusGadelha,FengtingYang,XiaoweiZhou,andHuaizuJiang. Planarrecon:Real-time
3dplanedetectionandreconstructionfromposedmonocularvideos. InProceedingsoftheIEEE/CVF
ConferenceonComputerVisionandPatternRecognition,pages6219–6228,2022.
[51] QiangengXu,ZexiangXu,JulienPhilip,SaiBi,ZhixinShu,KalyanSunkavalli,andUlrichNeumann.
Point-nerf:Point-basedneuralradiancefields. InProceedingsoftheIEEE/CVFconferenceoncomputer
visionandpatternrecognition,pages5438–5448,2022.
[52] FengtingYangandZihanZhou. Recovering3dplanesfromasingleimageviaconvolutionalneural
networks. InProceedingsoftheEuropeanConferenceonComputerVision(ECCV),pages85–100,2018.
[53] ShichaoYangandSebastianScherer. Monocularobjectandplaneslaminstructuredenvironments. IEEE
RoboticsandAutomationLetters,4(4):3145–3152,2019.
[54] ZehaoYu,JiaZheng,DongzeLian,ZihanZhou,andShenghuaGao. Single-imagepiece-wiseplanar3d
reconstructionviaassociativeembedding. InProceedingsoftheIEEE/CVFConferenceonComputer
VisionandPatternRecognition,pages1029–1037,2019.
12A Appendix
A.1 MoreDetailsofAlphaTabletsOptimization
Updateofupvector. Notethatthetablet’supvectorshouldnotbelearnedduringtheoptimization
process. Byconsideringthetablet’smotionasarigidtransformation,anyin-planerotationcanbe
accountedforbyoptimizingthetextureandalphavalues. However,weneedtoestablishanupdate
rulefortheupvectortokeeptherigidtransformationcharacteristicsofthetablet. Ourdesignisto
applythesamerotationtotheupvectorastheoneappliedtothenormalvectorduringtheupdate.
Giventhenormalvectorsnandn′(beforeandaftertheupdate),andtheupvectoru,wecanacquire
thenewupvectoru′by:
θ =n·n′, (12)
r
r=n×n′, (13)
(cid:32) 0 −r r (cid:33)
3 2
K = r 0 −r (14)
3 1
−r r 0,
2 1
R=Icosθ +Ksinθ +rrT(1−cosθ ), (15)
r r r
u′ =Ru (16)
Merging Scheme. As explained in Section 3.3, we first construct a KD-tree to find the tablet
neighborhoods,andinitializeaunion-finddatastructureforalltablets. Hereweactuallyusetheunit
tablets,whicharedefinedastheprojectionsofallinitial3Dtabletstothecurrenttablets,tobuild
theKD-tree. Inotherwords,wemaintaintheaffiliationsofinitialandcurrenttablets,andusethe
updatedinitialtabletstoperformthemerging. Thereasonisthatusing3Dcenterpointdistances
amongtabletswithdifferent3Dsizesisambiguous. Forexample,asmalltabletcanhaveasmaller
centerpointdistancethananon-adjacentsmalltablet,comparedtoaspatiallyadjacentbigtablet.
Using the unit tablets with similar sizes, the neighboring adjacency can be easily determined by
checkingthecenterpointdistances.
These unit tablets are used only because they have easily defined neighborhoods. Since the unit
tablets of one current tablet come from the projection on this tablet, they share the same surface
normalandadjacentpositions. Thus, mergingwithunittabletswilldefinitelyproducelarger(or
thesame)tabletsthancurrenttablets. Aftereachmerging, alltheunittabletsareupdatedbythe
projectionontothemergednewtablets,andthemergednewtabletsarefedintothenextoptimization.
UsingSLICsuperpixelonScanNet1296x968resolutionimageresultsinaround10ksuperpixelsfor
eachkeyframe,leadingtoalargenumberofinitialtablets. Toaddresstheissue,Weconductaninitial
mergeprocessafterAlphaTabletsinitialization. Inpractice,wefinditisbeneficialtotheaccuracy
andconvergencespeed. Table5showstheablationsoftheinitialmerge.
Table4: Ablationstudiesoninitialmerge.
Method F-score↑ VOI↓ RI↑ SC↑
w/oin-trainingmergeandinitmerge 0.188 6.991 0.939 0.098
w/oin-trainingmerge 0.438 5.171 0.941 0.138
w/oinitmerge 0.454 3.754 0.944 0.273
w/allmergeschemes 0.456 3.466 0.944 0.284
WeightCheckScheme. Duringtheoptimizationprocess,theremaybecaseswheresometablets
arenearlyinvisiblefromallviewpoints,yettheyhavearelativelylargetransparencyvalue. Insuch
situations, thesetabletsshouldberemoved. Additionally, therecouldbeinstanceswherecertain
regionsofatabletarenotvisiblefromanyviewpoint. Inthesecases,thosespecificregionsofthe
tabletshouldbeexcluded.
Toaddressthesescenarios,wedesignedaweightcheckmechanism: Weperformarasterizationstep
atallviewpointsandextractthepointswherethealphablendingweightexceedsacertainthreshold
(wechoose0.3inourimplementation). Werecordthetabletindexcorrespondingtoeachofthese
points.Beforethemergingstep,weperformtheweightcheckbyremovingtabletswithanexcessively
13lownumberofassociatedpoints. Furthermore,foreachtablet,werecalculateitsboundarybasedon
thetexturemapcoordinaterangesofallthepointsassociatedwiththattablet.
Tablet-camera assignment. We always maintain affiliations between the initial tablets and the
current(merged)tablets(asstatedinSecA.1),andwekeeptrackofthecameraindexthatinitially
generatedeachinitialtablet. Whentabletsaremerged,wecountthenumberofeachcameraindex
correspondingtoallaffiliatedinitialtabletsandassignthemostfrequentlyoccurringcameratothe
newlymergedtablet.
A.2 AdditionalImplementationDetails
Baselines. For3Dvolume-basedmethodsincludingAtlas,NeuralRecon,PlanarRecon,andMetric3D
withTSDFfusion,wefollowedPlanarRecontousetheirenhancedversionofSeq-RANSAC.We
refer to PlanarRecon for detailed descriptions. For point-based methods such as SuGaR, since
PlanarRecon’sSeq-RANSACrequires3DTSDFvolumeasinputsandcannotbeeasilyadaptedto
pointsormeshes,weusetheclassicalvanillaSeq-RANSAC,whichiterativelyappliesRANSAC
tofitplanes. HereweusedOpen3DplaneRANSACimplementationforeachiteration. Thehyper-
parametersarecarefullytunedforoptimalperformance. FortheMetric3Dbaseline,Weusedthe
officialMetric3Dv2implementationandpre-trainedweights(v2-g)runningoneachkeyframetoget
depthmaps,followedbyTSDFfusiontofuseinto3Dvolume. Finally,PlanarRecon’sSeq-RANSAC
isappliedtothe3DTSDFvolumetogettheplanarresults. Weadoptedtheoriginalimplementation
fortheSuGaRbaseline,duringtheCOLMAPpre-processing,wefeedground-truthcameraposes
intothepipeline,whichprovidesbetterinitialsparsepoints. Afteroptimization,SuGaRoutputsthe
meshmodel,andweuniformlysampled100ksurfacepointsandappliedvanillaSeq-RANSACon
topofsampledpointstogetthe3Dplanarresults. Quantitativeresultsforotherbaselines(Atlas,
NeuralRecon,PEAC,PlanarRecon)weretakenfromPlanerRecon.
Detailsoftabletproperties. Forpixelrange(r ,r ),eachtablet’sgeometryislocatedin3Dspace,
u v
whileitstextureisstoredin2D.Thepixelrangerepresentstheresolutionatwhichthetextureis
stored: itisderiveddirectlyfromtherangeinthesourceimageforinitialtablets;formergedtablets,
thepixelrangeiscalculatedastheaverageofallcorrespondinginitialtablets. Thedistanceratios
(λ ,λ )establishtherelationshipbetweenthe2Dtextureresolutionandthe3Dsizeofthetablet.
u v
Forinitialtablets,thedistanceratioiscalculatedbydividingthecamera’sfocallengthbytheaverage
initialdistanceofthetablet. Formergedtablets,thedistanceratioistheaverageofallcorresponding
initialtablets’ratios. Thealphachanneloftabletsisalearnablesingle-channelmapwiththesame
shapeasthetexturemap.
A.3 AdditionalDiscussions
Different initialization for SuGaR baseline. We further experiment on our ablation subset to
comparetheCOLMAPinitializationwithMetric3D’sdensedepth-basedinitializationsimilartoour
method. ForMetric3Dinit,weusethesamekeyframesasourmethodandrandomlysampleatotal
of100,000pointsasinitialpoints. Theresultsareshowninthetable:
Table5: AblationstudiesondifferentinitializationofSuGaR.
Method F-score↑ VOI↓ RI↑ SC↑
SuGaR+COLMAPInitialization 0.300 5.759 0.797 0.090
SuGaR+Metric3DInitialization 0.326 5.670 0.789 0.102
Ours 0.456 3.466 0.944 0.284
TheScanNetdatasetpresentssignificantchallengeslikenumerousblurryandtexturelessregions,
whichareespeciallyproblematicforGaussian-basedmethodslikeSuGaRwhenreconstructingclear
geometry. Also,SuGaRheavilyreliesonCOLMAPreconstructiontoinitialize,buttheCOLMAP
reconstruction on ScanNet is sometimes noisy, affecting the final performance. The Metric3D
initializationmethoddoesindeedenhancethereconstructionqualityofSuGaR(asshowninFig.6),
buttheoverallreconstructionqualityremainsconstrained,withnoticeablejitterandchallengesin
accuratelydelineatingplanarregions,leadingtoaninferiorperformancetoourapproach.
14SuGaRwith COLMAP Initialization SuGaRwith Metric3D Initialization
Figure6: QualitativeComparisonofInitializationMethodsforSuGaR.
BreakdownofTimeBudget. Belowisabreakdownofthetimebudgetfortheoptimizationprocess
ofasinglescene:
Table6: Breakdownofthetimebudgetofasinglescene.
Stage Task Time(s)
Initialization textureinit 1517.38
geometryinit 1672.57
Render pseudomesh 10.39
rasterization 316.62
alphacomposition 2.15
LossCalculation photometricloss 1.07
depthloss 28.28
normalloss 102.44
distortionloss 5.90
Training backward 3347.83
Merge kd-tree,union-findset 96.41
geometriccalculation 23.14
tabletprojection 22.26
weightcheck 62.14
The merge and rendering pipeline is relatively efficient, while the initialization process (which
includesconvertingeverysuperpixeltoaninitialtablet,andtextureinitialization)consumesasignifi-
cantamountoftime. Thisisduetothecurrentnaivedemonstrationimplementation,wheretensof
thousandsofPythonloopsarecalled,whichcanbeimprovedtoenableparallelizedinitializationin
futurework. Furthermore,theNVDiffRastrendersmorethantenlayerstoperformalphacomposition
everyforwardpass,butmostofthescene’sstructureissingle-layered,resultinginasubstantialback-
wardcomputationburdenduringtraining. Weregardthisasanotherpotentialareaforconsiderable
optimizationinthefuturework.
3D reconstruction accuracy. The difference in 3D accuracy (termed as Acc in Tab. 1 of the
main paper) between our method and PlanarRecon on the ScanNet dataset can be attributed to
several factors. First is the scope of reconstruction: PlanarRecon often only reconstructs large
planarregions. Thisallowsforeasierlocalizationandhighaccuracyinthesespecificareas,butit
limitsoverallcoverageandperformance. Ourmethodenablesmorecomprehensivereconstruction,
includingsmallerplanarregions,whichcanimpacttheaccuracymetricsbutprovideamorecomplete
representationofthescene. Anotheristheground-truthcoverage: Itisworthnotingthatthe3D
groundtruthplanesinScanNetonlypartiallycoverthescenewithinthecamera’sview. Evenafter
15Ground-Truth Labels PlanarRecon Ours (Accuracy) Original Image
*Red area denotes low accuracy area,including manyregions indeed exist but did not appear in the ground-truth.
*Redrectangles show regions reconstructed by our method but did not included by ground-truth.
Figure7: DemonstrationofInsufficientCoverageof3DGround-TruthLabels: The3Dground
truth labels only partially cover the range within the camera’s view. Most of the red regions in
the figure highlight this issue. While these uncovered areas reduce accuracy, they should not be
consideredanegativeoutcome.
Tablets amount after every merge
106
735157
105
44243
104
103 881 799
496 451
Training Stage
Figure8: VisualizationofTabletCountEvolution.
excluding areas too distant to be relevant using the camera frustum, significant portions remain
uncovered. PlanarReconlearnstoexcludedistantreconstructionsduringitstrainingstage,leadingto
improvedaccuracymetrics. Ourmethod,however,iscapableofidentifyingplanarregionsforall
visibleareas(evidentinFig.7wheremostoftheredregionshighlightthisphenomenon). While
theseuncoveredareasaffecttheevaluationaccuracy,theyshouldnotnecessarilybeconsidereda
negativeoutcome. Ourmethodprovidesamorecompletereconstructionofthescene,includingareas
notrepresentedinthegroundtruthdata.
Tabletcountevolution. WedemonstratethetabletcountevolutionofasinglesceneinFig.8. The
numberoftabletsdecreasesrapidlyintheearlymergingstagesandgraduallyconvergesintoseveral
hundred. Notably,thefinaltabletscontainalargeportionofsmalltabletsrepresentingnon-planar
regions,whiletheprimaryplanarscenestructureisadequatelyrepresentedwithfewertablets.
A.4 AdditionalQualitativeResults
WeprovidemorequalitativeresultsinFig.10andFig.11.
A.5 BroaderImpacts
3D planar reconstruction and editing have the potential to revolutionize numerous fields such as
entertainment,media,accessibility,manufacturing,etc,byenhancingvisualization,interaction,and
16
)elacS
goL(
rebmun
telbaTNaiveAnti-aliasing OurTabletAnti-aliasing
Figure9: Qualitativecomparisonofourtabletanti-aliasingscheme. Naiveanti-aliasingwilllead
towrongstripartifacts,whileouranti-aliasingschemeeffectivelymitigatesthoseartifacts.
understanding. However,itmayraiseconcernsaboutprivacyanddatasecurity,necessitatingrobust
policiesandsafeguards.
17Metric3D + Seq-RANSAC SuGaR+ Seq-RANSAC PlanarRecon Ours Ground Truth
High
Low
High
Low
High
Low
Figure10: MorequalitativeresultsonScanNet. Errormapsareincluded. Betterviewedwhen
zoomedin.
Figure11: MorequalitativeresultsonTUM-RGBDandReplicadatasets.
18