Knowledge-Data Fusion Based Source-Free Semi-Supervised
Domain Adaptation for Seizure Subtype Classification
Ruimin Peng, Jiayu An, Dongrui Wu
Abstract—Electroencephalogram (EEG)-based seizure sub-
typeclassificationenhancesclinicaldiagnosisefficiency.Source-
free semi-supervised domain adaptation (SF-SSDA), which
transfers a pre-trained model to a new dataset with no source
data and limited labeled target data, can be used for privacy-
preserving seizure subtype classification. This paper considers
two challenges in SF-SSDA for EEG-based seizure subtype
classification:1)HowtoeffectivelyfusebothrawEEGdataand
expertknowledgeinclassifierdesign?2)Howtoalignthesource
and target domain distributions for SF-SSDA? We propose
a Knowledge-Data Fusion based SF-SSDA approach, KDF-
MutualSHOT, for EEG-based seizure subtype classification.
In source model training, KDF uses Jensen-Shannon Diver-
Fig. 1. Traditional machine learning and deep learning approaches for
gence to facilitate mutual learning between a feature-driven
seizuresubtypeclassification.
Decision Tree-based model and a data-driven Transformer-
based model. To adapt KDF to a new target dataset, an SF-
SSDA algorithm, MutualSHOT, is developed, which features a
extraction.[6] reviewedthe research thatemployedmachine
consistency-based pseudo-label selection strategy. Experiments
on the public TUSZ and CHSZ datasets demonstrated that learning classifiers with temporal, spectral, and nonlinear
KDF-MutualSHOToutperformedothersupervisedandsource- handcrafted features. [7] compared the performance of dif-
free domain adaptation approaches in cross-subject seizure ferent feature extraction approaches.
subtype classification. For deep learning approaches, the feature extractor and
Index Terms—EEG, seizure subtype classification, source-
classifier areintegratedintooneneuralnetwork.Bothmodel
free domain adaptation, semi-supervised learning, knowledge-
data fusion structures and training algorithms impact the classification
performance. [8] grouped deep models for seizure detec-
I. INTRODUCTION tion into Convolutional Neural Networks, Recurrent Neural
Networks, and AutoEncoders. Recently, [9] and [10] pro-
Epilepsy is one of the most common neurological dis-
posed Transformer [11] based models for seizure subtype
orders, affecting millions of patients and their families
classification. These deep models are usually data hungry;
worldwide [1], [2]. Clinically, electroencephalogram (EEG)
however, labeled data are scarce and expensive in seizure
is the golden criterion for seizure diagnosis, with ictal EEG
subtype classification.
typically presenting a spike-and-wave pattern. Automated
Source-free domain adaptation (SFDA) [12], [13] can be
seizurediagnosiscangreatlyreducetheclinicians’workload
used for patient privacy protection in cross-dataset transfer
in analyzing long-term EEG records [3].
learning. As illustrated in Fig. 2, SFDA aims to reduce
This paper focuses on EEG-based seizure subtype classi-
the distribution discrepancy between the source and target
fication, which determines seizure subtypes for further opti-
domains, and the alignment process does not use the source
mization of surgery and medical treatments [4]. According
data [12]. Source HypOthesis Transfer (SHOT) [14] is a
to the 2017InternationalLeague AgainstEpilepsy guideline
popular SFDA approach, which includes a self-supervised
[5], we categorize epileptic seizure into four subtypes: Ab-
pseudo-labeling strategy and an information maximization
sence Seizure (ABSZ), Focal Seizure (FSZ), Tonic Seizure
loss in training. BAIT [15] inserts an extra classifier (bait
(TNSZ), and Tonic-Clonic Seizure (TCSZ).
classifier) in the source model to recognize and push the
Generally, both traditional machine learning and deep
unaligned target features to the correct side of the source
learning approaches are viable for seizure subtype classi-
decision boundary.
fication. Fig. 1 shows their training processes.
This study investigates few-shot source-free semi-
For traditional machine learning approaches, an effective
supervised domain adaptation (SF-SSDA) for EEG-based
handcrafted feature extractor is vital. Lots of valuable hu-
seizure subtype classification, where very limited data of
man expert knowledge has been accumulated for feature
each class in the target domain are labeled. Our main
contributions are:
R. Peng, J. An and D. Wu are with Key Laboratory of the Ministry
of Education for Image Processing and Intelligent Control, School of 1) We propose a Knowledge-Data Fusion (KDF) based
ArtificialIntelligenceandAutomation,HuazhongUniversityofScienceand
SF-SSDA algorithm, KDF-MutualSHOT, for seizure
Technology, Wuhan430074,China.
D.Wuisthecorresponding author. E-mail:drwu@hust.edu.cn. subtypeclassification.Tothebestofourknowledge,this
4202
voN
92
]GL.sc[
1v20591.1142:viXrafeatures,4 spectralfeatures,24 time-frequencyfeatures,and
3nonlinearfeatures.AnSDT[17]classifieristhenoptimized
by gradient descent.
To learn from raw EEG data, a ViT [22] is selected
as the base model, whose superior performance has been
demonstrated in [10]. It includes four Transformer encoder
layers. First, EEG signals with dimensionality [C×1×N],
whereC isthenumberofchannelsandN thenumberoftime
domainsamples, are patchfied and mappedinto embeddings
with position information. Then, the Transformer encoders
process these embeddings with a self-attention mechanism
[11]. Finally, a feed-forward layer outputs the classification
Fig.2. Source-free domainadaptation. probability from the averaged representation of all patches’
features.
ThetrainingofbothSDTandViTinvolvesacross-entropy
is the first work that fuses expertknowledgeon feature loss L :
CE
extractionandtherawEEGdatainbothpre-trainingand
fine-tuningoftheclassifiers. Experimentsdemonstrated LV Ci ET =− K1 K k=1log p(y =k|s,θ V)
, (1)
2)
t Fh oe rsu sp oe ur ri co er p mer of do erm
l
a pn rc ee -to raf inK inD gF ,-M wu etua dl eS vH elO opT.
a su-
 LS CD ET =− K1 PK k=1log(cid:16)p(y =k|f,θ S)(cid:17)
(cid:16) (cid:17)
pervised training approach, KDF, that employs the whereK isthenumberPofclasses, sisthedatainputofViT,

Jensen–Shannon divergence (JSD) to facilitate mutual f isthefeatureinputofSDT,andθ V andθ S arerespectively
learning between a Soft Decision Tree (SDT) based ViT and SDT model parameters.
on expert features and a raw EEG data driven Vision Tofurtherenhancethelearningefficiency,weadditionally
Transformer (ViT). incorporate a mutual distillation mechanism to utilize com-
3) Tofine-tunethepre-trainedKDFonanewtargetdataset plementaryinformationfromknowledgeanddata.AsL KLis
without access to the source data, we propose Mu- asymmetric,weadopttheJSD lossL JSD astheconsistency
tualSHOT, which improves SHOT with an innovative constraintformutuallearning.Theoveralllossfunctionsfor
consistency-based pseudo-label selection strategy. ViT and SDT in KDF are hence:
II. METHODOLOGY
LV eiT =LV Ci ET+αL
JSD
, (2)
This section introduces our proposed KDF-MutualSHOT,
(LS eDT =LS CD ET+αL
JSD
whichfuse expertknowledgeandraw EEGdata in classifier where
training. We first pre-train a KDF model in the source
1
domain,thenadaptittothetargetdatasetwithMutualSHOT. L = L (p ||p )+L (p ||p )
JSD KL s f KL f s
2
A. The Overall Training Process (cid:16) (cid:17)
Inspired by deep mutual learning [16] for image classi- K
1 p (y =k|s,θ )
fication, which introduces a mutual distillation mechanism =−
2K
p s(y =k|s,θ V)log ps
(y
=k|f,θV
)
withtheKullback-LeiblerdivergencelossL KL toencourage k X=1 f S
two networks with different parameters to learn from each K p (y =k|f,θ )
+ p (y =k|f,θ )log f S . (3)
other,weproposeKDFtoenhancethecollaborationbetween f S p (y =k|s,θ )
s V !
a knowledge-driven SDT and a data-driven ViT. To adapt Xk=1
a pre-trained model to a new dataset, we design an SF- C. Mutual-SHOT for SF-SSDA
SSDAapproach,MutualSHOT,toalignthesourceandtarget Inthefine-tuningstage,SDTandViTinthetargetdomain
domain distributions without the source data. model are first initialized by the pre-trained KDF model in
Fig. 3 illustrates the training process of KDF- the source domain. Then, their classifiers are fixed while
MutualSHOT, which contains two stages: 1) Pre-train the feature encoding layers are updated to align the feature
the KDF model in the source domain; and, 2) fine-tune it distributions between the source and target domains by
by MutualSHOT in the target domain. In the testing phase, minimizing an information maximization loss L [14],
IM
the SDT and ViT models are used independently. [23]:
B. Expert knowledge-Raw data Combined Training K K
To learn from knowledge-based features, following [12], L IM =−E x∈X δ k(f(x))logδ k(f(x))+ pˆ klogpˆ k,
we extract 41 handcrafted features1 per EEG channel, as k X=1 Xk=1 (4)
listed in Table I. Morespecifically,theyinclude10temporal
where X is either the features f or EEG data s in the
1https://github.com/rmpeng/Epilepsy-Seizure-Detection target domain, depending on the type of model f. δ
k
=Fig. 3. KDF-MutualSHOT in pre-training and fine-tuning stages. In the fine-tuning stage, the source EEG data and features are unavailable, and the
sourcemodelsareusedtoinitialize thetargetmodels.
TABLEI
SUMMARYOFTHEFEATURESET.
Temporal Features (10) Spectral Features (4) Time-Frequency Features (24) Nonlinear Features (3)
CurveLength[18] MeanPowerFrequency, Mean,StandardDeviation, Approximate Entropy
AverageNonlinear Energy[19] Maximum PowerFrequency, andKurtosisoftheformer SampleEntropy
RootMeanSquareoftheAmplitude Minimum PowerFrequency, andthelaterpartofthefour HurstExponent [20]
NumberofLocalMaximaandMinima andTotalPower of components decomposedby
ZeroCrossingRate PowerSpectral Density. 3-level WaveletTransform
KurtosisandSkewness (with’db5’).
Hjorth[21](Activity, Mobility, Complexity)
exp(xk) is the softmax output of f, and pˆ is the where D is the cosine similarity2 between a and b.
eP xpK i= ek ce tex dp(x oi u) tput over the whole target domain. k Sincewrongpseudo-labelsareharmfulfordomainadapta-
To alleviate the negative effects of incorrect outputs tion, we propose a consistency-based pseudo-label selection
and pseudo-labels, we improve the self-supervised pseudo- strategy. Rather than taking all target domain pseudo-labels,
labeling strategy of [14] to generate more confidentpseudo- we only select samples that have consistent pseudo-labels
labels for unlabeled target domain samples. generated by manual features and raw data to form the
First, the class centroids are calculated for SDT and ViT confident sample set S+:
separately by:
ct =
P Px∈ xX ∈Xδk δ( kfˆ (( fx ˆ() x)gˆ )( )x) ,t=0
, (5)
S+ = (s,f,yˆ)|yˆSDT(s)==yˆViT(f) !. (7)
k  Px∈X1(yˆ=k)gˆ(x) ,t>0 Then, L+ , the cross-entropy loss between model predic-
 Px∈X1(yˆ=k)
tions
andCE
pseudo-labels for samples in S+ is calculated by
wheretisthepseudo-label’supdatinground,gˆ(x)thefeature
 (1).
map’s expectation,and 1(·) an indicator function. Then, the
For few-shot semi-supervised learning, this fine-tuning
pseudo-labelsareassignedaccordingtothenearestcentroid:
process includes an additional supervision loss Llabeled for
e
yˆ(x)=argminD(gˆ(x),ct), (6)
k
k 2https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.htmlFig.4. Thetraininglosscalculation processingofMutualSHOT.
the labeled target domain samples by using (2) in II-B, a To evaluate KDF’s performance in the pre-training stage,
cross-entropy loss Llabeled, and a JSD loss Llabeled. Fig. 4 we adopted five handcrafted feature based machine learning
CE JSD
illustrates the training loss calculation process of Mutual- approachesasbaselines,i.e.,Gradientboostingdecisiontree
SHOT. (GBDT) [26],SVM [27],Ridge Classifier (RC) [28],Logis-
The final loss function is: ticRegression(LR)[29],andSDT.Alltheseapproachesused
the same features as input. Four deep learning approaches
L=L +L+ +Llabeled+αLlabeled. (8)
IM CE CE JSD takingrawEEGdataasinputwerealsoemployed,including
EEGNet[30],TIE-EEGNet[24],CE-stSENet[31],andViT.
Insummary,theoverallgoalistoachieveeffectivedomain
ToevaluateMutualSHOT’sperformanceinthefine-tuning
adaptationwhilepreservingthesourcedomainprivacy,lever-
stage,wetookSHOT-IM[14],SHOT[14],andBAIT[15]as
aging the strengths of both expert knowledge and raw EEG
baselines. Different from SHOT, SHOT-IM was trained by
data for seizure subtype classification.
minimizing L but without the pseudo-labeling strategy.
IM
III. EXPERIMENTS Sincethesesource-freeunsuperviseddomainadaptation(SF-
UDA)approachesdonotutilizethefew-shotlabelsinthetar-
This section evaluates the performance of our pro-
get domain, we transferred them into SF-SSDA approaches,
posed KDF-MutualSHOT on two seizure datasets with
i.e., SSL-SHOT-IM, SSL-SHOT, and SSL-BAIT, by adding
subtype annotations. The Python code is available at
the same supervisedlossLlabeled with MutualSHOT.For all
https://github.com/rmpeng/MutualSHOT. e
SF-SSDA approaches, we randomly labeled one sample per
class (one-shot) in each batch.
A. Datasets and Experimental Setup
3) Performance Measures: Due to class-imbalance, our
1) Datasets: CHSZ [24] and TUSZ [25] datasets were
performancemeasuresincludedtherawaccuracy(ACC),the
used in our experiments. Table II summarizes their charac-
balancedclassificationaccuracy(BCA),andtheweightedF
teristics. 1
score (F ). All measures were implemented by scikit-learn
1
TABLEII
package4.
SUMMARYOFCHSZANDTUSZDATASETS.
B. Results
ABSZ FSZ TNSZ TCSZ 1) EffectivenessofKDF: TableIIIshowstheperformance
CHSZ 81 87 15 16 ofSDT andViTinKDFinthepre-trainingstage.BothSDT
TUSZ 76 418 62 48
andViTachievedthehighestBCA.Throughmutuallearning
between expert features and raw EEG data, SDT and ViT
We followed the preprocessing steps and obtainedbetterperformancethanusingeitherexpertfeatures
training/validation/test set partition in [24], and performed or EEG data alone. Moreover, on the CHSZ dataset, both
cross-patient experiments, i.e., the training and testing sets SDT and ViT achieved the best or the second-best ACC,
came from different patients. All reported results were the BCA and F 1 score.
average of three-fold cross-validation with 10 repeats. 2) Effectiveness of MutualSHOT: Table IV compares the
2) Baselines: Forallexperiments,SDTusedsevenlayers, proposed MutualSHOT with SF-UDA and SF-SSDA ap-
andlearningrate0.01.ViT’sparametersfollowed[10].Both proaches in “CHSZ→TUSZ” and “TUSZ→CHSZ”. Results
models were optimized by AdamW3. on testing the source KDF model in the target domain
3https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html 4https://scikit-learn.org/stable/index.htmlTABLEIII
PERFORMANCE(MEAN±STD)OFDIFFERENTALGORITHMSONCHSZANDTUSZINSUPERVISEDTRAINING.THEBESTACC/BCA/F 1AREMARKED
INBOLD,ANDTHESECONDBESTWITHANUNDERLINE.
Datasets CHSZ TUSZ
Approaches ACC BCA F 1 ACC BCA F 1
SVM 0.526±0.152 0.461±0.083 0.498±0.109 0.627±0.077 0.532±0.111 0.641±0.068
RC 0.516±0.209 0.474±0.066 0.475±0.183 0.646±0.145 0.512±0.028 0.652±0.143
LR 0.471±0.231 0.449±0.084 0.450±0.199 0.663±0.135 0.512±0.035 0.663±0.125
GBDT 0.621±0.113 0.562±0.025 0.606±0.067 0.718±0.093 0.459±0.077 0.704±0.088
SDT 0.661±0.066 0.672±0.059 0.666±0.076 0.729±0.029 0.547±0.060 0.709±0.031
SDTinKDF 0.648±0.095 0.705±0.060 0.663±0.081 0.702±0.027 0.608±0.050 0.698±0.029
EEGNet 0.309±0.052 0.356±0.069 0.309±0.039 0.471±0.062 0.514±0.043 0.510±0.071
TIE-EEGNet 0.593±0.034 0.575±0.036 0.615±0.032 0.635±0.025 0.561±0.027 0.655±0.019
CE-stSENet 0.577±0.026 0.567±0.043 0.539±0.022 0.745±0.070 0.545±0.028 0.703±0.050
ViT 0.590±0.089 0.643±0.065 0.610±0.092 0.719±0.030 0.672±0.051 0.720±0.030
ViTinKDF 0.647±0.055 0.685±0.056 0.659±0.064 0.738±0.018 0.676±0.045 0.733±0.026
TABLEIV
PERFORMANCEOFDIFFERENTALGORITHMSIN“CHSZ→TUSZ”AND“TUSZ→CHSZ”,ONLYONESAMPLEPERCLASSINTHETARGETDOMAIN
WASLABELED.THEBESTACC/BCA/F 1AREMARKEDINBOLD.
SDT ViT
TUSZ→CHSZ CHSZ→TUSZ TUSZ→CHSZ CHSZ→TUSZ
ACC BCA F 1 ACC BCA F 1 ACC BCA F 1 ACC BCA F 1 Avg. Rank
SourceModelOnly 0.286 0.264 0.333 0.217 0.205 0.239 0.362 0.421 0.398 0.205 0.224 0.204
SHOT-IM 0.484 0.483 0.480 0.351 0.274 0.403 0.356 0.376 0.360 0.398 0.286 0.427
SHOT 0.473 0.481 0.464 0.354 0.276 0.408 0.392 0.296 0.394 0.415 0.282 0.454
BAIT 0.452 0.461 0.438 0.617 0.353 0.573 0.262 0.344 0.200 0.335 0.318 0.273
SSL-SHOT-IM 0.643 0.618 0.648 0.693 0.567 0.694 0.615 0.650 0.637 0.685 0.606 0.702 2.667
SSL-SHOT 0.661 0.623 0.672 0.702 0.574 0.700 0.625 0.665 0.646 0.685 0.615 0.696 1.750
SSL-BAIT 0.449 0.493 0.432 0.570 0.442 0.561 0.471 0.532 0.437 0.471 0.529 0.458 3.917
Mutual-SHOT 0.662 0.650 0.669 0.701 0.579 0.702 0.650 0.681 0.672 0.677 0.632 0.696 1.333
Supervised (TargetDomain) 0.648 0.705 0.663 0.702 0.608 0.698 0.647 0.685 0.659 0.738 0.676 0.733
(SourceModelOnly)andsupervisedtrainedKDFin thetar- domain.
getdomain[Supervised(TargetDomain)]werealsoprovided
IV. CONCLUSIONS
for reference.
This paper has introduced a novel SF-SSDA approach,
Using only one labeled target sample per class, SF-
KDF-MutualSHOT, for EEG-based seizure subtype classifi-
SSDA outperformed all SF-UDA approaches. For both
cation.AnSDTandaViTareadoptedasthebasemodelsto
SDT and ViT, MutualSHOT obtained the best BCA in
learnfromexpertfeaturesandrawEEGdata,respectively.In
“CHSZ→TUSZ” and “TUSZ→CHSZ”, and the highest av-
the pre-trainingstage, KDF enhancesthe learning efficiency
erage rank among the three measures. Compared with SSL-
byutilizingaJSDlosstoencouragemutuallearningbetween
SHOT,the consistency-basedpseudo-labelselectionstrategy
SDTandViTmodels.Thesubsequentfine-tuningstagewith
in MutualSHOT is clearly advantageous.
MutualSHOT effectively adapts the model to a new target
3) Effect of Labeled Target Sample Size: We also inves- domain while preserving the source data privacy. Mutual-
tigated the effect of the amount of labeled samples in the SHOT improves SHOT with a consistency-based pseudo-
target domain. Fig. 5 shows the comparison between 1-, 3- label selection strategy, which selects only the confident
and5-shotMutualSHOTs.Acrossdifferentsettings, Mutual- samples with consistent pseudo-labels from expert features
SHOT maintained strong performance on “CHSZ→TUSZ” and raw data. Experiments on two public seizure subtype
and “TUSZ→CHSZ”. With limited labeled target samples, classificationdatasetsdemonstratedthesuperiorperformance
MutualSHOTenabledthepre-trainedKDFmodeltoperform of KDF-MutualSHOT in both pre-training and fine-tuning
comparably with a supervised learning model in the target stages.
ADU-FS
ADSS-FS
desab-erutaeF
desab-GEE
waR(a) (b)
Fig.5. Performance w.r.t.thenumberoflabeled target samples.(a)TUSZ→CHSZ;and,(b)CHSZ→TUSZ.
REFERENCES [16] Y. Zhang, T. Xiang, T. M. Hospedales, and H. Lu, “Deep mutual
learning,” in Proc. the IEEE Conf. on Computer Vision and Pattern
[1] G.Beraldo,A.Suppiej,C.Forest,L.Tonin,andE.Menegatti,“Brain- Recognition, SaltLakeCity,Utah,Jun.2018.
Computer Interface for children: State-of-the-art and challenges,” in [17] N. Frosst and G. Hinton, “Distilling a neural network into a
Proc. IEEE International Conference on Systems, Man, and Cyber- soft decision tree,” arXiv:1711.09784, 2017. [Online]. Available:
netics (SMC),Toronto,Canada, Oct.2020. https://arxiv.org/abs/1711.09784
[18] R.Esteller, J.Echauz,T.Tcheng,B.Litt,andB.Pless,“Linelength:
[2] A. H. Shoeb and J. V. Guttag, “Application of machine learning to
Anefficientfeatureforseizureonsetdetection,” inProc.AnnualInt’l
epilepticseizuredetection,”inProc.Int’lConf.onMachineLearning,
Conf. of the IEEE Engineering in Medicine and Biology Society,
Haifa, Israel,Jun.2010.
Istanbul, Turkey,Oct.2001.
[3] Z. Li, Y. Fang, Y. Li et al., “Protecting the future: Neonatal seizure
[19] M.D’Alessandro,R.Esteller,G.Vachtsevanos,A.Hinson,J.Echauz,
detection with spatial-temporal modeling,” in Proc. IEEEInt’l Conf.
andB.Litt,“Epilepticseizurepredictionusinghybridfeatureselection
onSystems,Man,andCybernetics (SMC),Honolulu, HI,Oct.2023.
over multiple intracranial EEG electrode contacts: A report of four
[4] S. Tang, J. Dunnmon, K. K. Saab, X. Zhang, Q. Huang, F. Dubost,
patients,”IEEETrans.onBiomedicalEngineering,vol.50,no.5,pp.
D. Rubin, and C. Lee-Messer, “Self-supervised Graph Neural Net-
603–615,2003.
worksforimprovedelectroencephalographicseizureanalysis,”inProc.
[20] Q. Yuan, W. Zhou, S. Li, and D. Cai, “Epileptic EEG classification
Int’lConf.onLearningRepresentations, VirtualEvent,Apr.2022.
basedonextremelearning machine andnonlinear features,” Epilepsy
[5] R.S.Fisher,J.H.Cross,J.A.Frenchetal.,“Operationalclassification
Research,vol.96,no.1,pp.29–38,2011.
ofseizuretypesbytheInternationalLeagueAgainstEpilepsy:Position
[21] B. Hjorth, “EEG analysis based on time domain properties,” Elec-
paper of the ILAE commission for classification and terminology,”
troencephalography andClinicalNeurophysiology, vol.29,no.3,pp.
Epilepsia, vol.58,no.4,pp.522–530, 2017.
306–310,1970.
[6] M. K. Siddiqui, R. Morales-Menendez, X. Huang, and N. Hussain,
[22] A. Dosovitskiy, L. Beyer, A. Kolesnikov et al., “An image is worth
“A review of epileptic seizure detection using machine learning
16x16 words: Transformers for image recognition at scale,” inProc.
classifiers,” Braininformatics, vol.7,no.1,p.5,2020.
Int’lConf.onLearningRepresentations, VirtualEvent,May2021.
[7] P. Boonyakitanont, A. Lek-Uthai, K. Chomtho, and J. Songsiri, “A
[23] W. Hu, T. Miyato, S. Tokui, E. Matsumoto, and M. Sugiyama,
review of feature extraction and performance evaluation in epileptic
“Learning discrete representations via information maximizing self-
seizure detection using EEG,” Biomedical Signal Processing and
augmented training,” in Proc. Int’l Conf. on Machine Learning,
Control, vol.57,p.101702, 2020.
Sydney,Australia, Aug.2017.
[8] A. Shoeibi, M. Khodatars, N. Ghassemi et al., “Epileptic seizures [24] R.Peng,C.Zhao,J.Jiang,G.Kuang,Y.Cui,Y.Xu,H.Du,J.Shao,
detection using deep learning techniques: A review,” Int’l journal of and D.Wu,“TIE-EEGNet:Temporalinformation enhanced EEGNet
environmental research and public health, vol. 18, no. 11, p. 5780, forseizuresubtypeclassification,”IEEETrans.onNeuralSystemsand
2021. Rehabilitation Engineering, vol.30,pp.2567–2576,2022.
[9] R. Peng, C. Zhao, Y. Xu, J. Jiang, G. Kuang, J. Shao, and D. Wu, [25] V. Shah, E. Von Weltin, S. Lopez et al., “The Temple university
“WAVELET2VEC:Afilterbankmaskedautoencoder forEEG-based hospital seizure detection corpus,” Frontiers in Neuroinformatics,
seizuresubtypeclassification,”inProc.IEEEInt’lConf.onAcoustics, vol.12,p.83,2018.
Speech andSignalProcessing,Rhodes Island,Greece, Jun.2023. [26] J.H.Friedman,“Greedyfunctionapproximation:Agradientboosting
[10] R.Peng,Z.Du,C.Zhao,J.Luo,W.Liu,X.Chen,andD.Wu,“Multi- machine,” AnnalsofStatistics, vol.29,no.5,pp.1189–1232,2001.
Branch Mutual-Distillation Transformer for EEG-based seizure sub- [27] C.-C. Chang and C.-J. Lin, “LIBSVM: A library for support vector
typeclassification,”IEEETrans.onNeuralSystemsandRehabilitation machines,”ACMTrans.Intelligent SystemsTechnology, vol.2,no.3,
Engineering, vol.32,pp.831–839, 2024. pp.1–27,2011.
[11] A.Vaswani,N.Shazeer,N.Parmaretal.,“Attentionisallyouneed,” [28] A.E.HoerlandR.W.Kennard,“Ridgeregression:Biasedestimation
in Proc. Advances in Neural Information Processing Systems, Long fornonorthogonalproblems,”Technometrics,vol.12,no.1,pp.55–67,
Beach, CA,Dec.2017. 1970.
[12] C.Zhao,R.Peng,andD.Wu,“Source-freedomainadaptation(SFDA) [29] S.Sperandei,“Understandinglogisticregressionanalysis,”Biochemia
forprivacy-preserving seizuresubtypeclassification,” IEEETrans.on medica, vol.24,no.1,pp.12–18,2014.
Neural Systems and Rehabilitation Engineering, vol. 31, pp. 2315– [30] V. J. Lawhern, A. J. Solon, N. R. Waytowich et al., “EEGNet: A
2325,2023. compactconvolutional neuralnetworkforEEG-basedbrain-computer
[13] J.Li,Z.Yu,Z.Du,L.Zhu,andH.T.Shen,“Acomprehensivesurvey interfaces,” JournalofNeuralEngineering,vol.15,no.5,p.056013,
on source-free domain adaptation,” IEEE Transactions on Pattern 2018.
AnalysisandMachine Intelligence, 2024. [31] Y. Li, Y. Liu, W.-G. Cui et al., “Epileptic seizure detection in
[14] J.Liang,D.Hu,andJ.Feng,“Dowereallyneedtoaccessthesource EEGsignals usingaunifiedtemporal-spectral squeeze-and-excitation
data?sourcehypothesistransferforunsuperviseddomainadaptation,” network,” IEEE Trans. on Neural Systems and Rehabilitation Engi-
inProc.Int’lConf.onMachine Learning,VirtualEvent,April2020. neering, vol.28,no.4,pp.782–794,2020.
[15] S.Yang,Y.Wang,L.Herranz,S.Jui,andJ.vandeWeijer,“Castinga
BAITforofflineandonlinesource-freedomainadaptation,”Computer
VisionandImageUnderstanding, vol.234,p.103747,2023.