mhGPT: A Lightweight Generative Pre-Trained
Transformer for Mental Health Text Analysis
Dae-young Kim1, Rebecca Hwa2, Muhammad Mahbubur Rahman1,2†
1Center for Translational Research, Children’s National Hospital, Washington, DC
{dkim1, mmrahman}@childrensnational.org
2George Washington University, Washington, DC
rebecca.hwa@email.gwu.edu
Abstract—This paper introduces mhGPT, a lightweight gen- press their symptoms in relatively casually structured words
erativepre-trainedtransformertrainedonmentalhealth-related due to their lack of professional knowledge, while physicians
socialmediaandPubMedarticles.Fine-tunedforspecificmental
have to organize mental illnesses or disorders in a formal
health tasks, mhGPT was evaluated under limited hardware
and professional structure, such as clinical notes and standard
constraintsandcomparedwithstate-of-the-artmodelslikeMen-
taLLaMA and Gemma. Despite having only 1.98 billion param- test results. This research illustrates decision-making on data
eters and using just 5% of the dataset, mhGPT outperformed preparation and fine-tuning methods as illustrated in figure 1
largermodelsandmatchedtheperformanceofmodelstrainedon whiledevelopingmhGPT.Also,weevaluatedtheperformance
significantlymoredata.Thekeycontributionsincludeintegrating
of mhGPT with state-of-the-art LLMs, such as MentaLLaMA
diverse mental health data, creating a custom tokenizer, and
and Google’s Gemma.
optimizing a smaller architecture for low-resource settings. This
research could advance AI-driven mental health care, especially Our key contributions are as follows. First, this study is the
in areas with limited computing power. firsttointegrateresearcharticlesfromPubMedtotrainamen-
tal health-specialized LLM. This approach benefits LLMs by
I. INTRODUCTION
allowing them to learn contexts from professional knowledge.
Mental health has a profound impact on the overall quality Also, this study demonstrated that expert knowledge-infused
of life [1]–[3]. However, access to mental health services is LLMswithsmallerparametersizescanperformsimilarlytoor
challenging due to stigma, human resource shortages, frag- evenbetterthanthelateststate-of-the-artmentalhealthLLMs.
mented service delivery models, and lack of research capacity Specifically, mhGPT outperformed MentaLLaMA [12] with
forimplementationandpolicychange[4].Meanwhile,Natural notablylargerparametersizesandtrainingdatasets.Lastly,this
Language Processing (NLP) techniques have demonstrated studyexploredfine-tuningmethodstoovercomethestructural
their capability to aid with mental disorders [5]. For example, differencebetweentrainingdataanddownstreamtaskdataand
Jackson et al. developed a sentence classification model that suggested that NEFTune [13] can enhance the performance
captures key symptoms of Severe Mental Illness (SMI) from of Parameter-Efficient Fine-Tuning (PEFT) even though the
theclinicaltextforthesecondaryuseofmentalhealthcaredata authors of NEFTune developed it to enhance the performance
in research [6]. Also, Desouza et al. presented the possibility of instruction-based fine-tuning.
of NLP to assess Late-Life Depression (LLD) and other We hypothesized that incorporating mental health-related
comorbidities in elderly demographics [7]. Furthermore, as PubMed articles as expert knowledge and Reddit posts as
LLMs came into the spotlight, Dai et al. trained the BERT a casual expression into the training dataset could improve
[8] model with mental health clinical notes and fine-tuned the performance of mental health LLM in a limited hardware
the pre-trained model to classify five major mental disorders resource environment. Secondly, we hypothesized that the
[9]. However, while the application of NLP or LLM meth- expert knowledge infused LLM could provide more precise
ods demonstrated its promising capability, developing NLP answers to the more narrowed-down fields of the domains,
models or training large language models (LLMs) requires such as postpartum depression. Lastly, we hypothesized that
highcomputationalresources[10],whichareoftenunavailable careful decisions on fine-tuning methods, such as data sam-
for many organizations [11]. Also, regulations such as the pling, tokenizer selection, and regularization, can overcome
Health Insurance Portability and Accountability Act (HIPAA) the overfitting problems caused by a model memorizing small
and General Data Protection Regulation (GDPR) hinder the datasets.
utilization of Infrastructure as a Service (IaaS) to overcome ThispaperintroducesmhGPT,amentalhealthLLMtrained
the lack of computing resources. on PubMed articles and Reddit posts related to mental health.
This paper introduces mhGPT, a high-performance mental Our study explores different data preparation options and
health LLM with a small parameter size for low computing fine-tuning methods to identify high-performance settings for
resourceenvironments.Thetrainingdatasetconsistsofmental small-parameter-sized LLMs in low-resource environments as
health-related PubMed articles and Reddit posts, considering illustrated in figure 1.
the patient-physician communication perspective: patients ex- Our key contributions are as follows. First, this study
4202
guA
51
]LC.sc[
1v16280.8042:viXramhGPT Training Flowchart and Future Applications
Dataset Selection Data Preparation Data Sampling Tokenizer Selection Model Selection Fine-tuning Tasks
Train custom tokenizer << Performance Metric: Weighted F1 Score >>
with whole data point
IRF: Interpersonal Risk Factors of
1. Parse full-text XML. mhGPT-2.8B / mental disturbance in social media
2. Retrieve texts in <p> tag. Get first 512 tokens and Custom Tokenizer custom tokenizer posts (binary classification)
3. Remove citation notations. truncate overflows
Mental health related M ae nr dge Dreaddit: Reddit Dataset for Stress
articles / posts shuffle Analysis in Social Media (binary
classification)
1. Remove empty posts. Dataset A
2 . R c noe anm mso eev dce u h tu tiv mn ei lc lo eind nee t i, tf ie ee sd , s e, tc. pre-m trh aiG nP edT- t2 o.8 kB en / izer S foA r D re: c T oh ge n izS intr ge s es v eA rn yn do at ya t se td re sD sa ot ra ss e int
SMS-like conversational systems
Chunk dataset with Pre-trained Tokenizer (Multi-class classification)
sliding window size 512 (GPT-NeoX)
Development environment:
Python 3.8 with Hugging Face library MultiWD: The Multiple Wellness
Dimensions in social media posts
mhGPT-1.98 with custom tokenizer trained on Dataset B demonstrated mhGPT-1.98B / (multi-label classification)
the best training performance and selected for fine-tuning base model. Dataset B custom tokenizer
Google Gemma-2B is selected for baseline comparison and fine-tuned for
IRF, Dreaddit, SAD, and MultiWD dataset except PPD-NER. PPD-NER: Postpartum Depression -
Named Entity Dataset (Named Entity
C fino em -tp una ir nis go mn e g thr oo du sp ) ,L ML eM ns ta a lBre E RM Te , n Mta eL nL taa lM RA o B(m ERul Tti aple parameter size and P (Gre o-t or ga li en e Gd e T mo mke an -2iz Be )r Google Gemma-2B Recognition)
Future Applications
Early detection of mental health Clinical decision support for preliminary Fast and precise mental Personalized mental health Communication enhancement between
symptoms for preventive care assessments and complex mental health health and boarding intervention and education clinicians, patients, and guardians for
symptoms. for public resilience. better treatment and continuity of care.
Fig.1. mhGPTOverview
is the first to integrate research articles from PubMed to ideation from social content, facilitating effective social in-
trainamentalhealth-specializedLLM.Thisapproachbenefits tervention. They outperformed general pre-trained language
LLMs by allowing them to learn contexts from professional models in mental disorder detection tasks, demonstrating the
knowledge. We have validated this by fine-tuning mhGPT value of domain-specific language representations for mental
for the named entity recognition task on the postpartum healthdetection.Daietal.alsopre-trainedtheBERT[8]model
depression dataset [14] and demonstrated that mhGPT outper- with Brief History (BH) and Physical and Mental status Ex-
formed MetaMapLite (MMLite) developed by mental health amination (PME) from EHRs. They fine-tuned the pre-trained
professionals (table II). Also, this study demonstrated that binary classification models for five mental disorders - major
expert knowledge-infused LLMs with smaller parameter sizes depressive disorder, schizophrenia, bipolar, minor depressive
can perform similarly to or even better than the latest state- disorder,anddementiaanddemonstratedthatthemodelswith
of-the-art mental health LLMs. Specifically, mhGPT outper- transferred knowledge from the LLM outperformed models
formedMentaLLaMA[12]withnotablylargerparametersizes without transferred knowledge [9].
and training datasets. Lastly, this study explored fine-tuning
B. Fine-tuning LLMs
methodstoovercomethestructuraldifferencebetweentraining
data and downstream task data and suggested that NEFTune Fine-tuningisstillnecessarytoimprovemodelperformance
[13]canenhancetheperformanceofParameter-EfficientFine- [17] beyond few-shot baselines despite the remarkable zero-
Tuning (PEFT) even though the authors of NEFTune devel- shot and few-shot learning performance of the latest LLMs
oped it to enhance the performance of instruction-based fine- [18] such as Google’s Gemini [19] and OpenAI’s ChatGPT
tuning. [20]. PEFT methods enable modifying a small portion of
model parameters and efficient fine-tuning for large models.
II. RELATEDWORK Among them, Low-Rank Adaptation (LoRA) introduces low-
rank decomposition matrices for efficient adaptation of LLMs
A. Mental Health LLMs Trained on Social Media Text [21]. It is one of the best methods for low-resource envi-
ronments since it reduces GPU memory usage and training
There are few studies on developed mental health LLMs,
time[22].Furthermore,itispossibletoreducememoryusage
and they have trained LLMs predominantly on social media
by QLoRA [23], which introduced 4-bit quantization while
data. For example, MentaLLaMA [12] is trained on the
backpropagating gradients into LoRA.
comprehensive interpretable mental health instruction (IMHI)
dataset sourced from various mental health tasks on social
III. LLMTRAININGMETHOD
media [15] to automate mental health analysis enhanced
A. Dataset
zero/few-shotscenariostoimprovethequalityofexplanations.
MentalBERT[16]modeladdressesagapinmentalhealthcare 49,812 PubMed Central (PMC) articles related to mental
by enabling early detection of mental disorders and suicidal health were collected from the PMC Open Access repositoryTABLEI customtokenizerhasthevocabularysizeof52,000withmax-
REDDITDATAINFORMATION imuminputlengthas512whilekeepingpretrainedtokenizer’s
original hyper parameter configuration.
Subreddit # Submissions # Comments
r/ADHD 482,369 3,775,167
D. Base Model
r/ADHD Programmers 3,373 39,449
r/ADHD partners 3,588 44,167
The GPT-NeoX model architecture is a base model of the
r/ADHDers 1,512 14,539
mhGPT. The GPT-NeoX model is an augmented model of
r/AdultADHDSupportGroup 1,292 9,005
NVIDIA’s Megatron Language Model (Megatron-LM) and
r/Anxiety 78,952 321,096
r/TwoXADHD 5,090 67,865 has similar architecture to GPT-3 with new techniques and
r/adhd anxiety 7,946 52,261 novel optimizations, released with Apache-2.0 license [28].
r/adhd college 671 3,113 The GPT-NeoX adopted RoPE [29] to the first 25% of
r/ADHDwomen 54,764 543,591 embeddingvectordimensionsforfasterconvergenceandbetter
r/Depression 225,561 510,775
generalization [30] instead of adding the learned positional
r/SocialAnxiety 139,909 655,566
embeddingstothetokenembedding[31]usedinGPTmodels.
Total Before Pre-processing 1,005,027 6,036,594
We’ve trained two different parameter size models - 2.8
Total After Pre-processing 786,716 5,765,005
billionand1.98billionparameters.The2.8Bmodelconsistsof
22layers,3,072hiddensize,12,288intermediatefeedforward
in BioC format via their API [24]. This API provides access layersize,and32attentionheads.Ontheotherhand,the1.98B
to full-text research articles for text mining and information model has 22 layers, 3,072 hidden size, 6,144 intermediate
retrieval research. We parsed the full-text XML files, ex- feed forward layer size, and 64 attention heads.
tractedthetextparagraph-by-paragraph,andshuffledtheentire
E. Training Configuration
dataset.
Also, We have collected 1,005,027 submission body text, We set three different configurations for data sampling
and 6,036,594 comment sections from twelve subreddits are methods, tokenizers, and model parameter sizes as illustrated
collected by Reddit API with compliance to their policy insubsectionsIII-B,III-C,andIII-D.Ourfinalmodeltraining
[25] as illustrated in table I. To pre-preprocess the data, configurations are listed below: noitemsep,topsep=0pt
we removed entries with empty submission body text and • Model A: 2.8B parameters, pretrained tokenizer, trained
content that was too short, with less than five words. Then on dataset A.
we removed Unicode, consecutive line feeds, named HTML • Model B: 2.8B parameters, custom tokenizer, trained on
entities, URLs, decimal character reference, and hexadecimal dataset A.
character reference. As a result, we have included 786,716 • ModelC:1.98Bparameters,customtokenizer,trainedon
submissions and 5,765,005 comments to train our mhGPT. dataset B.
The training configuration of mhGPT is as follows: we
B. Data Sampling
set 100 warmup steps with a maximum learning rate of
We have sampled our dataset with two approaches for 0.97 × 10−5. The weight decay is set to 0.01 to prevent
efficient model training on limited environments. First, we overfitting. The training batch size is configured to occupy
set our maximum input length as 512, truncated overflowing all GPU memory except for 1 GB reserved as a buffer for
tokens, and discarded them. As a result, every row has a memory usage spikes, aiming for optimal results [32]. The
maximum length of 512 (dataset A). On the contrary, we default number of epochs is set to 5 unless the model starts
did not discard overflowing tokens for the second approach. to overfit.
Instead,wehavechunkedthedatasetusingtheslidingwindow Models A and B are trained in our organization’s High-
method, which has a length 512 and a step size 512. So, Performance Computing cluster (HPC), which is configured
the dataset is divided into chunks of identical size. Then, with NVIDIA H100 GPUs with a maximum VRAM capacity
we sampled 5% from the chunked dataset with a stratified of 60 GB, managed by the Slurm workload manager on Red
methodtomaintainPubMed,Redditsubmissionbodytext,and Hat Enterprise Linux release 8.9 (Ootpa). Model C and all
commenttextratio(datasetB).Therationalebehindadopting fine-tuning models are trained on an Amazon EC2 instance
sliding window data sampling is that it can increase diversity (g5.12xlarge)consistingofNVIDIAA10GTensorCoreGPUs
of continuous data [26], [27]. with a maximum VRAM capacity of 96 GB, using the
Deep Learning Proprietary Nvidia Driver AMI GPU PyTorch
C. Vocabulary
2.1.0AmazonMachineImage(AMI).Averagememoryusage
We used two tokenizers and compared fine-tuning perfor- during the fine-tuning was around 24 GB.
mances of mhGPT with each tokenizer. First, we adopted de- For data preparations and model trainings, Python 3.8
fault GPT-NeoX tokenizer (pretrained tokenizer). Secondly, and following packages with compatible versions are used:
we trained GPT-NeoX tokenizer from the scratch on original Pandas[33],[34],Scikit-learn[35],Spacy[36],HuggingFace
full-sized dataset (custom tokenizer) before sampling. The Datasets [37], and Hugging Face Transformers [38].Fig.2. LLMtrainingprogresscomparison.
F. Model Selection fine-tunedmodelsaretrainedwiththesedefaultconfigurations
if no changes are specified.
We compared the training performance of three models, A,
Inmostcases,thedefaulthyperparametersillustratedabove
B, and C, based on different tokenizers and data sampling
worked well during the fine-tuning process. However, when
methods.
we had to change values of the hyperparameters to improve
First, we compared the training performance of models
performance,wesetandfolloweda“regulationovercomplex-
A and B to compare model training performance based on
ity” criteria. The rationale behind the criteria is that mhGPT
different tokenizer configurations. As illustrated in figure 2,
already knows how to understand input texts and all we have
model B’s validation loss in epoch five was smaller than that
todoistolesstrainaspossibletoperformdownstreamtasksto
of model A in epoch seven. Then, we compared the training
makesurethatitappliespre-trainedknowledgetodownstream
performance of models B and C to compare model training
tasks, rather than it fits parameters to the dataset. The second
performance based on data sample methods. Model C has
important criteria was to be aware of consequent trade-offs
shown better performance on validation loss. Specifically, it
hyperparameters value change.
was trained on a 5% sampled dataset, tokenized by a custom
tokenizer, and chunked using a sliding window method. This
B. NEFTune Application to PEFT
approach allowed for a more comprehensive representation of
We adopted NEFTune noise embeddings to enhance PEFT
the dataset, as the randomly selected chunks from the entire
fine-tuning performance, especially to overcome overfitting
dataset exhibited a greater diversity in structure and content
and imbalanced datasets. We adopted NEFTune because it
comparedtothesumofthefirst512tokensofeachdatapoint.
adds noise to the data but does not change the semantic
IV. FINE-TUNINGMETHOD relationshipbetweentokens[13].Thoughtheprimarypurpose
of the method is to improve the performance of instruction-
A. Fine-Tuning Configurations
basedfine-tuning,wefocusedonthefactthatthemethodadds
We adopted PEFT method to fine-tune mhGPT. The PEFT noise to the tokens in the vocabulary. Then, we hypothesized
fine-tuning processes are done as follows. First, a dataset is that NEFTune could improve PEFT fine-tuning performance
tokenizedbyourcustomGPT-NeoXtokenizertrainedonLLM sincePEFTandinstruction-basedmethodssharethesamedata
training dataset. Secondly, a task-specific layers are added input formats. Our default NEFTune noise alpha value is ten
on top of mhGPT. Then, newly added layers and part of a because the number resulted in the best performances in its
pretrained mhGPT parameters are trained on a down-stream original paper.
task dataset according to PEFT configurations. In particular,
C. Baseline Comparison
we adopted LoRA [21] because of its advantages on reducing
GPUmemoryusageandtrainingtime[22].Wetargetedlinear We fine-tuned Google Gemma-2B for each task as a
layersonlywiththeLoRAconfigurationsofrank64andalpha baseline performace and evaluate fine-tuning performance
32. To further reduce GPU memory usage, we adopted 4-bit of mhGPT. The LoRA hyperparameters are the same with
quantization with QLoRA method [23], [39]. mhGPT fine-tuning configuration and maximum learning rate
One challenge of the LoRA method with 4-bit quantization is set to 2e-5.
was rapid overfitting. To address this issue, we incorporated
NEFTune[13]duringtraining(IV-B)becausethecombination
V. FINE-TUNINGDATASETS
of LoRA and NEFTune proved to be effective in maintain- Inthissection,weexplaindatasetsthatareusedtofine-tune
ing model performance without compromising generalization. and evaluate downstream models of the pre-treained mhGPT.
Lastly, Default leraning rate is set to 0.9e-5 since mhGPT is We fine-tuned mhGPT on five datasets for four downstream
trained with learning rate 0.97e-5. In the following sections, tasks.C. Multi-Label Sequence Classification
We used the Multiple Wellness Dimensions in social media
posts (MultiWD) [45] dataset to fine-tune and evaluate the
multi-label classification models. Multiple Wellness Dimen-
sions in Social Media Posts (MultiWD) comprises 3,281
instances, serves as a curated collection specifically designed
andannotatedforidentifyingwellnessdimensionsfromReddit
posts, with 6 labels: “Emotional,” “Intellectual,” “Physical,”
“Social,” “Spiritual,” “Vocational.” As illustratead in figure
3, the data set has severly unbalanced class distribution.
Therefore, NEFTune noise alpha is set to 20 for an attempt to
overcome highly imbalanced characteristic of the dataset.
D. Named Entity Recognition
Fig.3. MultiWDdatasetclassdistribution. We used Postpartum Depression Named Entity Dataset
(PPD-NER) [14] dataset to fine-tune and evaluate the NER
A. Binary Sequence Classification
task model. PPD-NER [14] is a NER dataset, Postpartum
We utilized an annotated dataset for explainable Interper- Depression (PPD) related terms annotated on 10,584 forum
sonalRiskFactorsofmentaldisturbanceinsocialmediaposts threads about PPD and its preliminary assessment of top-
(IRF) [40] and the Reddit Dataset for Stress Analysis in ics from BabyCenter.com online health communities. The
Social Media (Dreaddit) [41] for our binary classification authors of the developed the MetaMapLite (MMLite) [44]
experiments. that annotate PPD related terms based on the Human Pheno-
The IRF [40] dataset is dataset with human-labelled expla- type Ontology (HPO) [46], [47] concept recognition software
nations of interpersonal risk factors that affects mental dis- to identify biomedical terms. The dataset provides Fielded
turbance on social media, which are Thwarted Belongingness MetaMap Indexing file (MMI) [48] for each thread, which
(TBE), and Perceived Burdensomeness (PBU). The author of include UMLS preferred name, actual text mapped to the
thedatasetcollected3,522postsfromRedditr/depressionand UMLS concept, and positional information in the original
r/SuicideWatch subreddits and developed binary classification thread file.
modelsforeachlabel.SincetheirbestF1scorewasfromTBE
VI. RESULT
classification model [12]. The classes “TBE” and “No TBE”
We reported the best performance metric score before any
are fairly evenly distributed.
possible overfitting occurred. Figure 4 describes the training
TheDreaddit[41]isadatasetthatidentifiedpercievedstress
loss,validationloss,andweightedaverageF1scoreofmhGPT
of authors from their Reddit posts. It is a comprehensive
and the baseline during the fine-tunings. Table II presents
collection of social media posts from Reddit across five
a summary of the fine-tuning performance, as well as a
categories, totaling 190,000 posts. Researchers have manually
comparison with our baseline and the previously reported
labeled 3,500 segments from 3,000 posts to facilitate the
performance of state-of-the-art LLMs specialized in mental
identification of stress using supervised learning methods.
health.
The dataset explored stress across diverse online contexts,
An initial hypothesis of this project was that LLMs trained
addressing a gap in existing research that often focuses on
onexpertknowledge-infusedmentalhealthdatacouldperform
specific domains or short-form platforms.
similarly to or even better than the comparison group of
LLMs trained on social media about mental health. Table II
B. Multi-Class Sequence Classification
illustrates that mhGPT outperformed at least one variation of
We used the Stress Annotated Dataset for recognizing MentaLLaMAforeverytaskanddataset,anditshowedsimilar
everyday stressors in SMS-like conversational systems (SAD) performance compared to MentalBERT and MentalRoBERTa.
[42]toevaluatethemodel’smulti-classsequenceclassification Compared to mhGPT, all three models were trained on only
performance. The Stress Annotated Dataset for Recogniz- social media data and had much higher parameterized archi-
ing Everyday Stressors in SMS-like Conversational Systems tecture.
(SAD)isacollectionof6,850SMS-likesentencescategorized It was also hypothesized that the expert knowledge-infused
into nine stressor categories. These categories were developed LLMcouldprovidemorepreciseanswerstosubdomainfields
from stress management literature, live chatbot conversations, of mental health. This research compared the NER task
crowdsourcing,andtargetedwebscraping.Thepurposeofthe performance of the mhGPT and MMLite [44] from the PPD-
datasetistoenablechatbotstoclassifystressinputstoprovide NERdataset’soriginalresearchpaper[14].Theauthorsofthe
appropriate advice during conversations. The NEFTune alpha paper reported recall and precision scores only, so we derived
is set to 5 because the fine-tuning model did not fit well on their F1 score by calculating the harmonic mean of the recall
the training dataset. and precision scores. The result showed that mhGPT alsoFig.4. mhGPT-1.98Bfine-tuningcomparisonwithbaselinemodelGoogleGemma-2B.
outperformedhumanannotatorsinthedataset,whichindicates scores were 49.32 and 49.30, respectively. The other two
that the hypothesis is true. datasets, Dreaddit and SAD, were added later to provide a
However, the baseline Gemma-2B also performed well, firm comparison for the mhGPT-1.98B model.
particularly in the binary classification task with the IRF
VII. CONCLUSION
dataset and the multi-label classification task with the Mul-
In this paper, we introduced mhGPT, a lightweight gen-
tiWDdataset.InthecaseofIRFbinaryclassification,Gemma-
erative pre-trained transformer for mental health text anal-
2B achieved the best score. We conjecture that this result is
ysis. mhGPT is based on the GPT-NeoX architecture and
due to the substantial size difference in the training datasets.
was trained using social media and PubMed articles related
The Gemma-2B model’s actual parameter size is 2.51B and
to mental health. Evaluations are done by fine-tuning on
themodelistrainedonatotalof6trilliontokensfromawide
five mental health-related downstream tasks using the IRF,
variety of sources such as web documents, programming lan-
Dreaddit, SAD, MultiWD, and PPD-NER datasets. The fine-
guages, and mathematics [43]. Additionally, we hypothesize
tuningperformancewascomparedwithcurrentstate-of-the-art
that although Gemma-2B has good performance, it may have
mental health-specific language models and a general-purpose
less interpretability in its decisions since it was not trained on
language model. The results demonstrated that mhGPT out-
mental health domain-specific data. However, this is beyond
performed MentaLLaMA and showed similar performance to
the scope of this research and will be explored in subsequent
otherLLMssuchasMentalBERTandMentalRoBERTa,which
studies.
have notably larger parameter sizes and training datasets.
The third question in the study was whether adopting an
Our findings indicate that it is possible to enhance
appropriate fine-tuning method can overcome the structural
domain-specific LLM’s performance by incorporating expert
difference between the training dataset and downstream task
knowledge-infuseddataset,customtokenizer,andslidingwin-
data. We found out that NEFTune [13] can enhance the per-
dow data sampling. Also, we found out that it is possible to
formance of PEFT fine-tuning on small-sized and imbalanced
enhance PEFT peformance and overcome imbalanced dataset
datasets.TheauthorsofNEFTuneevaluatedthemethodonan
issue by leveraging NEFTune noise embeddings.
instructiondatasetwith7BparameterLLMs—LLaMA-1[49],
LLaMA-2 [50], and OPT-6.7B [51]. The best NEFTune alpha VIII. LIMITATIONS
value of 10 from their research worked well with the plain Despite the promising results demonstrated by mhGPT,
labeled dataset we used in the much smaller 1.98B parameter our research has limitations. First, we fine-tuned mhGPT for
model with a different architecture, GPT-NeoX. Additionally, only four downstream tasks. Second, a more comprehensive
it was possible to regularize highly imbalanced dataset Mul- exploration of interpretability is needed, as any potential
tiWD(figure3).ByincreasingtheNEFTunealphavalueto20, decision-making failure in the mental health domain could
themhGPTfine-tunedmodeloutperformedMentaLLaMA-7B, have severe implications for patients. Third, mhGPT has not
which has more than three times the number of parameters. beentestedbymentalhealthprofessionalsforitsvalidationin
We also fine-tuned Model A and Model B. The best F1 real-world settings. Fourth, the social media dataset used for
scores for Model A’s fine-tuning on the MultiWD multi-label LLM training may have misinformation and disinformation.
sequence classification and IRF binary sequence classification Wedidnotverifythesedata,andthereisariskthatthemodel
tasks were 46.52 and 49.30, respectively. For Model B, the may produce biased output.TABLEII
FINE-TUNINGPERFORMANCECOMPARISON
Task Dataset Base Model Fine-tuning Method F1
mhGPT-1.98B PEFT - LoRA 71.99
MentaLLaMA-7B [12] Instruction-tuning 67.53
IRF MentaLLaMA-chat-7B [12] Instruction-tuning 72.88
MentaLLaMA-chat-13B [12] Instruction-tuning 76.49
Binary Gemma-2B [43] PEFT - LoRA 81.22
Classification mhGPT-1.98B PEFT - LoRA 73.55
MentaLLaMA-7B Instruction-tuning 71.65
Dreaddit MentaLLaMA-chat-7B Instruction-tuning 62.20
MentaLLaMA-chat-13B Instruction-tuning 75.79
Gemma-2B PEFT - LoRA 68.66
mhGPT-1.98B PEFT - LoRA 57.71
MentaLLaMA-7B Instruction-tuning 49.93
Multi-Class
SAD MentaLLaMA-chat-7B Instruction-tuning 62.18
Classification
MentaLLaMA-chat-13B Instruction-tuning 63.62
Gemma-2B PEFT - LoRA 45.16
mhGPT-1.98B PEFT - LoRA 70.34
MentaLLaMA-7B Instruction-tuning 68.44
Multi-Label
MultiWD MentaLLaMA-chat-7B Instruction-tuning 75.79
Classification
MentaLLaMA-chat-13B Instruction-tuning 75.11
Gemma-2B PEFT - LoRA 72.73
Named Entity mhGPT-1.98B PEFT - LoRA 88.04
PPD-NER
Recognition MMLite [14], [44] 84.36
IX. ETHICALCONSIDERATIONS [2] B. Olatunji, J. Cisler, and D. Tolin, “Quality of life in the anxiety
disorders: a meta-analytic review.” Clinical psychology review, vol. 27
Weunderstandtheresponsibilityofcomputingprofessionals
5,pp.572–81,2007.
andpursuethepublicgoodthroughourresearch.Toavoidany [3] S. Evans, S. Banerjee, M. Leese, and P. Huxley, “The impact of
harm and respect privacy, we excluded personally identifiable mentalillnessonqualityoflife:Acomparisonofseverementalillness,
common mental disorder and healthy population samples,” Quality of
information (PII) from Reddit posts and PubMed articles on
LifeResearch,vol.16,pp.17–29,2006.
mental health, such as user IDs or information about authors, [4] M. L. Wainberg, P. Scorza, J. M. Shultz, L. Helpman, J. J. Mootz,
during the data preparation for LLM training and downstream K. A. Johnson, Y. Neria, J.-M. E. Bradford, M. A. Oquendo, and
M.R.Arbuckle,“Challengesandopportunitiesinglobalmentalhealth:
tasks fine-tuning.
aresearch-to-practiceperspective,”Currentpsychiatryreports,vol.19,
pp.1–10,2017.
APPENDIX
[5] Z.Binggui,G.Yang,Z.Shi,andS.Ma,“Naturallanguageprocessing
We spent $3,187.83 on our LLM training on AWS using forsmarthealthcare,”IEEEReviewsinBiomedicalEngineering,2022.
on-demand instances. To get the job done, we used different [6] R.G.Jackson,R.Patel,N.Jayatilleke,A.Kolliakou,M.Ball,G.Gorrell,
A.Roberts,R.J.Dobson,andR.Stewart,“Naturallanguageprocessing
types of GPU instances, such as p3, g5, trn1, gr6, and g6, for
to extract symptoms of severe mental illness from clinical text: the
a total of 534.839 hours. We also used Local HPC for LLM clinical record interactive search comprehensive data extraction (cris-
training.
code)project,”BMJopen,vol.7,no.1,p.e012012,2017.
[7] D.D.DeSouza,J.Robin,M.Gumus,andA.Yeung,“Naturallanguage
processingasanemergingtooltodetectlate-lifedepression,”Frontiers
REFERENCES
inPsychiatry,vol.12,p.719125,2021.
[1] A.Bergho¨fer,L.Martin,S.Hense,S.Weinmann,andS.Roll,“Quality [8] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova,“Bert:Pre-training
oflifeinpatientswithseverementalillness:across-sectionalsurveyin of deep bidirectional transformers for language understanding,” arXiv
an integrated outpatient health care model,” Quality of Life Research, preprintarXiv:1810.04805,2018.
vol.29,pp.2073–2087,2020. [9] H.-J. Dai, C.-H. Su, Y.-Q. Lee, Y.-C. Zhang, C.-K. Wang, C.-J. Kuo,and C.-S. Wu, “Deep learning-based natural language processing for [33] T.pandasdevelopmentteam,“pandas-dev/pandas:Pandas,”Feb.2020.
screening psychiatric patients,” Frontiers in psychiatry, vol. 11, p. [Online].Available:https://doi.org/10.5281/zenodo.3509134
533949,2021. [34] WesMcKinney,“DataStructuresforStatisticalComputinginPython,”
[10] Y.Qin,Y.Lin,J.Yi,J.Zhang,X.Han,Z.Zhang,Y.Su,Z.Liu,P.Li, inProceedingsofthe9thPythoninScienceConference,Ste´fanvander
M.Sunetal.,“Knowledgeinheritanceforpre-trainedlanguagemodels,” WaltandJarrodMillman,Eds.,2010,pp.56–61.
arXivpreprintarXiv:2105.13880,2021. [35] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,
[11] M.Kim,J.Yun,Y.Cho,K.Shin,R.Jang,H.-j.Bae,andN.Kim,“Deep O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg et al.,
learninginmedicalimaging,”Neurospine,vol.16,no.4,p.657,2019. “Scikit-learn:Machinelearninginpython,”Journalofmachinelearning
[12] K.Yang,T.Zhang,Z.Kuang,Q.Xie,andS.Ananiadou,“Mentalllama: research,vol.12,no.Oct,pp.2825–2830,2011.
Interpretablementalhealthanalysisonsocialmediawithlargelanguage [36] M. Honnibal, I. Montani, S. Van Landeghem, and A. Boyd, “spaCy:
models,”arXivpreprintarXiv:2309.13567,2023. Industrial-strengthNaturalLanguageProcessinginPython,”2020.
[13] N.Jain,P.-y.Chiang,Y.Wen,J.Kirchenbauer,H.-M.Chu,G.Somepalli, [37] Q.Lhoest,A.VillanovadelMoral,Y.Jernite,A.Thakur,P.vonPlaten,
B. R. Bartoldson, B. Kailkhura, A. Schwarzschild, A. Saha et al., S. Patil, J. Chaumond, M. Drame, J. Plu, L. Tunstall, J. Davison,
“Neftune: Noisy embeddings improve instruction finetuning,” arXiv M. Sˇasˇko, G. Chhablani, B. Malik, S. Brandeis, T. Le Scao, V. Sanh,
preprintarXiv:2310.05914,2023. C.Xu,N.Patry,A.McMillan-Major,P.Schmid,S.Gugger,C.Delangue,
[14] S.Chowdhuri,S.McCrea,D.D.Fushman,andC.O.Taylor,“Extracting T.Matussie`re,L.Debut,S.Bekman,P.Cistac,T.Goehringer,V.Mustar,
biomedical terms from postpartum depression online health communi- F.Lagunas,A.Rush,andT.Wolf,“Datasets:Acommunitylibraryfor
ties,” AMIA Summits on Translational Science Proceedings, vol. 2019, natural language processing,” in Proceedings of the 2021 Conference
p.592,2019. on Empirical Methods in Natural Language Processing: System
[15] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, Demonstrations. Online and Punta Cana, Dominican Republic:
C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language Association for Computational Linguistics, Nov. 2021, pp. 175–184.
modelstofollowinstructionswithhumanfeedback,”Advancesinneural [Online].Available:https://aclanthology.org/2021.emnlp-demo.21
informationprocessingsystems,vol.35,pp.27730–27744,2022. [38] T. Wolf, L. Debut, V. Sanh, J. Chaumond, C. Delangue, A. Moi,
[16] S.Ji,T.Zhang,L.Ansari,J.Fu,P.Tiwari,andE.Cambria,“Mentalbert: P.Cistac,T.Rault,R.Louf,M.Funtowiczetal.,“Huggingface’strans-
Publicly available pretrained language models for mental healthcare,” formers: State-of-the-art natural language processing,” arXiv preprint
arXivpreprintarXiv:2110.15621,2021. arXiv:1910.03771,2019.
[17] N. Ding, Y. Qin, G. Yang, F. Wei, Z. Yang, Y. Su, S. Hu, Y. Chen, [39] S.-y.Liu,Z.Liu,X.Huang,P.Dong,andK.-T.Cheng,“Llm-fp4:4-bit
C.-M. Chan, W. Chen et al., “Parameter-efficient fine-tuning of large- floating-pointquantizedtransformers,”arXivpreprintarXiv:2310.16836,
scalepre-trainedlanguagemodels,”NatureMachineIntelligence,vol.5, 2023.
no.3,pp.220–235,2023. [40] M. Garg, A. Shahbandegan, A. Chadha, and V. Mago, “An annotated
[18] J.Huang,S.S.Gu,L.Hou,Y.Wu,X.Wang,H.Yu,andJ.Han,“Large dataset for explainable interpersonal risk factors of mental disturbance
language models can self-improve,” arXiv preprint arXiv:2210.11610, insocialmediaposts,”arXivpreprintarXiv:2305.18727,2023.
2022. [41] T. Elsbeth, “Dreaddit: A reddit dataset for stress analysis in social
[19] G.Team,R.Anil,S.Borgeaud,Y.Wu,J.-B.Alayrac,J.Yu,R.Soricut, media,” in Proceedings of the 10th International Workshop on Health
J.Schalkwyk,A.M.Dai,A.Hauthetal.,“Gemini:afamilyofhighly TextMiningandInformationAnalysis,2019.
capablemultimodalmodels,”arXivpreprintarXiv:2312.11805,2023. [42] M. L. Mauriello, T. Lincoln, G. Hon, D. Simon, D. Jurafsky, and
[20] J.Achiam,S.Adler,S.Agarwal,L.Ahmad,I.Akkaya,F.L.Aleman, P. Paredes, “Sad: A stress annotated dataset for recognizing everyday
D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4 stressors in sms-like conversational systems,” in Extended abstracts of
technicalreport,”arXivpreprintarXiv:2303.08774,2023. the2021CHIconferenceonhumanfactorsincomputingsystems,2021,
[21] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, pp.1–7.
and W. Chen, “Lora: Low-rank adaptation of large language models,” [43] G.Team,T.Mesnard,C.Hardin,R.Dadashi,S.Bhupatiraju,S.Pathak,
arXivpreprintarXiv:2106.09685,2021. L. Sifre, M. Rivie`re, M. S. Kale, J. Love et al., “Gemma: Open
[22] Z. Hou, J. Salazar, and G. Polovets, “Meta-learning the difference: models based on gemini research and technology,” arXiv preprint
preparinglargelanguagemodelsforefficientadaptation,”Transactions arXiv:2403.08295,2024.
of the Association for Computational Linguistics, vol. 10, pp. 1249– [44] D.Demner-Fushman,W.J.Rogers,andA.R.Aronson,“Metamaplite:
1265,2022. anevaluationofanewjavaimplementationofmetamap,”Journalofthe
[23] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, “Qlora: AmericanMedicalInformaticsAssociation,vol.24,no.4,pp.841–844,
Efficientfinetuningofquantizedllms,”AdvancesinNeuralInformation 2017.
ProcessingSystems,vol.36,2024. [45] M. Sathvik and M. Garg, “Multiwd: Multiple wellness dimensions in
[24] D. C. Comeau, C.-H. Wei, R. Islamaj Dog˘an, and Z. Lu, “Pmc text socialmediaposts,”AuthoreaPreprints,2023.
miningsubsetinbioc:aboutthreemillionfull-textarticlesandgrowing,” [46] S.Ko¨hler,S.C.Doelken,C.J.Mungall,S.Bauer,H.V.Firth,I.Bailleul-
Bioinformatics,vol.35,no.18,pp.3533–3535,2019. Forestier, G. C. Black, D. L. Brown, M. Brudno, J. Campbell et al.,
[25] reddit inc., “reddit.com: api documentation,” https://www.reddit.com/ “Thehumanphenotypeontologyproject:linkingmolecularbiologyand
dev/api/,accessed:2024-05-03. diseasethroughphenotypedata,”Nucleicacidsresearch,vol.42,no.D1,
[26] M.DrosouandE.Pitoura,“Diversityovercontinuousdata.”IEEEData pp.D966–D974,2014.
Eng.Bull.,vol.32,no.4,pp.49–56,2009. [47] T. Groza, S. Ko¨hler, D. Moldenhauer, N. Vasilevsky, G. Baynam,
[27] L.Zhou,B.Chen,H.Liu,andL.Wang,“Personalizedslidingwindow T.Zemojtel,L.M.Schriml,W.A.Kibbe,P.N.Schofield,T.Becketal.,
recommendation algorithm based on sequence alignment,” Entropy, “Thehumanphenotypeontology:semanticunificationofcommonand
vol.24,no.11,p.1662,2022. raredisease,”TheAmericanJournalofHumanGenetics,vol.97,no.1,
[28] A. Andonian, Q. Anthony, S. Biderman, S. Black, P. Gali, L. Gao, pp.111–124,2015.
E.Hallahan,J.Levy-Kramer,C.Leahy,L.Nestler,K.Parker,M.Pieler, [48] A.R.Aronson,“Themmirankingfunction,”Availableinthewebsite:
J. Phang, S. Purohit, H. Schoelkopf, D. Stander, T. Songz, C. Tigges, https://ii.nlm.nih.gov/MTI/Details/mmi.shtml,1997.
B. The´rien, P. Wang, and S. Weinbach, “GPT-NeoX: Large Scale [49] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,
Autoregressive Language Modeling in PyTorch,” Aug. 2021. [Online]. T. Lacroix, B. Rozie`re, N. Goyal, E. Hambro, F. Azhar et al.,
Available:https://www.github.com/eleutherai/gpt-neox “Llama:Openandefficientfoundationlanguagemodels,”arXivpreprint
[29] J. Su, M. Ahmed, Y. Lu, S. Pan, W. Bo, and Y. Liu, “Roformer: En- arXiv:2302.13971,2023.
hanced transformer with rotary position embedding,” Neurocomputing, [50] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei,
vol.568,p.127063,2024. N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale et al., “Llama
[30] B.WangandA.Komatsuzaki,“Gpt-j-6b:A6billionparameterautore- 2: Open foundation and fine-tuned chat models,” arXiv preprint
gressivelanguagemodel,”2021. arXiv:2307.09288,2023.
[31] A.Radford,K.Narasimhan,T.Salimans,I.Sutskeveretal.,“Improving [51] S.Zhang,S.Roller,N.Goyal,M.Artetxe,M.Chen,S.Chen,C.Dewan,
languageunderstandingbygenerativepre-training,”2018. M. Diab, X. Li, X. V. Lin et al., “Opt: Open pre-trained transformer
[32] S.McCandlish,J.Kaplan,D.Amodei,andO.D.Team,“Anempirical
languagemodels,”arXivpreprintarXiv:2205.01068,2022.
modeloflarge-batchtraining,”arXivpreprintarXiv:1812.06162,2018.