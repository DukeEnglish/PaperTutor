[
    {
        "title": "LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner",
        "authors": "Xiaopan ZhangHao QinFuquan WangYue DongJiachen Li",
        "links": "http://arxiv.org/abs/2409.20560v1",
        "entry_id": "http://arxiv.org/abs/2409.20560v1",
        "pdf_url": "http://arxiv.org/pdf/2409.20560v1",
        "summary": "Language models (LMs) possess a strong capability to comprehend natural\nlanguage, making them effective in translating human instructions into detailed\nplans for simple robot tasks. Nevertheless, it remains a significant challenge\nto handle long-horizon tasks, especially in subtask identification and\nallocation for cooperative heterogeneous robot teams. To address this issue, we\npropose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel\nmulti-agent task planning framework that achieves state-of-the-art performance\non long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning\ncapability and the traditional heuristic search planner to achieve a high\nsuccess rate and efficiency while demonstrating strong generalization across\ntasks. Additionally, we create MAT-THOR, a comprehensive benchmark that\nfeatures household tasks with two different levels of complexity based on the\nAI2-THOR environment. The experimental results demonstrate that LaMMA-P\nachieves a 105% higher success rate and 36% higher efficiency than existing\nLM-based multi-agent planners. The experimental videos, code, and datasets of\nthis work as well as the detailed prompts used in each module are available at\nhttps://lamma-p.github.io.",
        "updated": "2024-09-30 17:58:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.20560v1"
    },
    {
        "title": "MARLadona -- Towards Cooperative Team Play Using Multi-Agent Reinforcement Learning",
        "authors": "Zichong LiFilip BjelonicVictor KlemmMarco Hutter",
        "links": "http://arxiv.org/abs/2409.20326v1",
        "entry_id": "http://arxiv.org/abs/2409.20326v1",
        "pdf_url": "http://arxiv.org/pdf/2409.20326v1",
        "summary": "Robot soccer, in its full complexity, poses an unsolved research challenge.\nCurrent solutions heavily rely on engineered heuristic strategies, which lack\nrobustness and adaptability. Deep reinforcement learning has gained significant\ntraction in various complex robotics tasks such as locomotion, manipulation,\nand competitive games (e.g., AlphaZero, OpenAI Five), making it a promising\nsolution to the robot soccer problem. This paper introduces MARLadona. A\ndecentralized multi-agent reinforcement learning (MARL) training pipeline\ncapable of producing agents with sophisticated team play behavior, bridging the\nshortcomings of heuristic methods. Further, we created an open-source\nmulti-agent soccer environment based on Isaac Gym. Utilizing our MARL framework\nand a modified a global entity encoder as our core architecture, our approach\nachieves a 66.8% win rate against HELIOS agent, which employs a\nstate-of-the-art heuristic strategy. Furthermore, we provided an in-depth\nanalysis of the policy behavior and interpreted the agent's intention using the\ncritic network.",
        "updated": "2024-09-30 14:26:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.20326v1"
    },
    {
        "title": "Can We Break the Curse of Multiagency in Robust Multi-Agent Reinforcement Learning?",
        "authors": "Laixi ShiJingchu GaiEric MazumdarYuejie ChiAdam Wierman",
        "links": "http://arxiv.org/abs/2409.20067v1",
        "entry_id": "http://arxiv.org/abs/2409.20067v1",
        "pdf_url": "http://arxiv.org/pdf/2409.20067v1",
        "summary": "Standard multi-agent reinforcement learning (MARL) algorithms are vulnerable\nto sim-to-real gaps. To address this, distributionally robust Markov games\n(RMGs) have been proposed to enhance robustness in MARL by optimizing the\nworst-case performance when game dynamics shift within a prescribed uncertainty\nset. Solving RMGs remains under-explored, from problem formulation to the\ndevelopment of sample-efficient algorithms. A notorious yet open challenge is\nif RMGs can escape the curse of multiagency, where the sample complexity scales\nexponentially with the number of agents. In this work, we propose a natural\nclass of RMGs where the uncertainty set of each agent is shaped by both the\nenvironment and other agents' strategies in a best-response manner. We first\nestablish the well-posedness of these RMGs by proving the existence of\ngame-theoretic solutions such as robust Nash equilibria and coarse correlated\nequilibria (CCE). Assuming access to a generative model, we then introduce a\nsample-efficient algorithm for learning the CCE whose sample complexity scales\npolynomially with all relevant parameters. To the best of our knowledge, this\nis the first algorithm to break the curse of multiagency for RMGs.",
        "updated": "2024-09-30 08:09:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.20067v1"
    },
    {
        "title": "Fuel tax loss in a world of electric mobility: A window of opportunity for congestion pricing",
        "authors": "Thi Ngoc NguyenFelix Muesgens",
        "links": "http://arxiv.org/abs/2409.20033v1",
        "entry_id": "http://arxiv.org/abs/2409.20033v1",
        "pdf_url": "http://arxiv.org/pdf/2409.20033v1",
        "summary": "The continued transition towards electric mobility will decrease energy tax\nrevenues worldwide, which has substantial implications for government funds. At\nthe same time, demand for transportation is ever increasing, which in turn\nincreases congestion problems. Combining both challenges, this paper assesses\nthe effectiveness of congestion pricing as a sustainable revenue stream to\noffset fuel tax loss in 2030 while simultaneously enhancing efficiency in the\ntransport sector. A congestion-based toll that is road-and-time-variant is\nsimulated for the greater Berlin area in Germany using the multi-agent\ntransport simulation (MATSim) software. Through the simulation results, this\npaper quantifies the impacts of the toll on the governmental revenue, traffic\nmanagement, environment, social welfare, and the distribution effects. We find\nthat the revenue from congestion tolls in a metropolitan area can compensate\nthe reduction in passenger car fuel tax. Furthermore, a remarkable welfare\nsurplus is observed. The toll also successfully incentivises transport users to\nadjust their travel behaviour, which reduces traffic delay time by 28%. CO2\nemissions as a key metric for decarbonisation of the transport sector decrease\nby more than 5%. The analysis of the distribution effects suggests that a\nredistribution plan with a focus on the middle-low-income residents and the\nouter boroughs could help the policy gain more public acceptance.",
        "updated": "2024-09-30 07:39:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.20033v1"
    },
    {
        "title": "Variational Auto-encoder Based Solutions to Interactive Dynamic Influence Diagrams",
        "authors": "Yinghui PanBiyang MaHanyi ZhangYifeng Zeng",
        "links": "http://arxiv.org/abs/2409.19965v1",
        "entry_id": "http://arxiv.org/abs/2409.19965v1",
        "pdf_url": "http://arxiv.org/pdf/2409.19965v1",
        "summary": "Addressing multiagent decision problems in AI, especially those involving\ncollaborative or competitive agents acting concurrently in a partially\nobservable and stochastic environment, remains a formidable challenge. While\nInteractive Dynamic Influence Diagrams~(I-DIDs) have offered a promising\ndecision framework for such problems, they encounter limitations when the\nsubject agent encounters unknown behaviors exhibited by other agents that are\nnot explicitly modeled within the I-DID. This can lead to sub-optimal responses\nfrom the subject agent. In this paper, we propose a novel data-driven approach\nthat utilizes an encoder-decoder architecture, particularly a variational\nautoencoder, to enhance I-DID solutions. By integrating a perplexity-based tree\nloss function into the optimization algorithm of the variational autoencoder,\ncoupled with the advantages of Zig-Zag One-Hot encoding and decoding, we\ngenerate potential behaviors of other agents within the I-DID that are more\nlikely to contain their true behaviors, even from limited interactions. This\nnew approach enables the subject agent to respond more appropriately to unknown\nbehaviors, thus improving its decision quality. We empirically demonstrate the\neffectiveness of the proposed approach in two well-established problem domains,\nhighlighting its potential for handling multi-agent decision problems with\nunknown behaviors. This work is the first time of using neural networks based\napproaches to deal with the I-DID challenge in agent planning and learning\nproblems.",
        "updated": "2024-09-30 05:35:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.19965v1"
    }
]