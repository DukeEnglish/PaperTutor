Maia-2: A Unified Model for Human-AI Alignment in
Chess
ZhenweiTang DifanJiao
UniversityofToronto UniversityofToronto
josephtang@cs.toronto.edu difanjiao@cs.toronto.edu
ReidMcIlroy-Young JonKleinberg SiddharthaSen
HarvardUniversity CornellUniversity MicrosoftResearch
reidmcy@seas.harvard.edu kleinberg@cornell.edu sidsen@microsoft.com
AshtonAnderson
UniversityofToronto
ashton@cs.toronto.edu
Abstract
Thereareanincreasingnumberofdomainsinwhichartificialintelligence(AI)
systemsbothsurpasshumanabilityandaccuratelymodelhumanbehavior. This
introducesthepossibilityofalgorithmically-informedteachinginthesedomains
throughmorerelatableAIpartnersanddeeperinsightsintohumandecision-making.
Criticaltoachievingthisgoal,however,iscoherentlymodelinghumanbehavior
at various skill levels. Chess is an ideal model system for conducting research
into this kind of human-AI alignment, with its rich history as a pivotal testbed
for AI research, mature superhuman AI systems like AlphaZero, and precise
measurementsofskillviachessratingsystems. Previousworkinmodelinghuman
decision-makinginchessusescompletelyindependentmodelstocapturehuman
styleatdifferentskilllevels,meaningtheylackcoherenceintheirabilitytoadapt
to the full spectrum of human improvement and are ultimately limited in their
effectivenessasAIpartnersandteachingtools. Inthiswork,weproposeaunified
modeling approach for human–AI alignment in chess that coherently captures
humanstyleacrossdifferentskilllevelsanddirectlycaptureshowpeopleimprove.
Recognizingthecomplex, non-linearnatureofhumanlearning, weintroducea
skill-awareattentionmechanismtodynamicallyintegrateplayers’strengthswith
encodedchesspositions,enablingourmodeltobesensitivetoevolvingplayerskill.
Our experimental results demonstrate that this unified framework significantly
enhancesthealignmentbetweenAIandhumanplayersacrossadiverserangeof
expertiselevels,pavingthewayfordeeperinsightsintohumandecision-making
andAI-guidedteachingtools. Maia-2implementationisavailablehere
1 Introduction
Thereareanincreasingnumberofdomainsinwhichartificialintelligence(AI)systemsbothsurpass
humanabilityandaccuratelymodelhumanbehavior. Thiscombinationofmachinemasteryover
a domain and computational understanding of human behavior in it introduces the possibility of
algorithmically-informedteachingandlearning. AI-poweredaidscouldguidepeoplealongreliable
andefficientimprovementpaths,synthesizedfromtheirknowledgeofbothhumantrajectoriesand
38thConferenceonNeuralInformationProcessingSystems(NeurIPS2024).
4202
peS
03
]IA.sc[
1v35502.9042:viXraobjectiveperformance. RelatableAIpartners,ontheotherhand,couldlearntoactalongsidehuman
counterpartsinsynergisticandcomplementaryways.
Researchershavebeguntotacklethischallengeinthemodelsystemofchess. Onceheldtobean
idealtestbedfordevelopingartificialintelligence,itisnowtheperfectdomaintopursuehuman-AI
alignment. TheAIcommunityfinallysurpassedallhumanabilityinchessapproximately20years
ago,amilestoneachievementandwatershedculturalmoment. Now,superhumanAIchessengines
areubiquitousandwidelyused. Despitethistransformation, chesshasneverbeenmorepopular,
becoming a mainstream activity in many countries during the last few years. There is now both
unprecedenteddemandforchesseducation,aswellasmaturesuperhumanAIthatcouldinprinciple
helpmeetit.
However,existingmodelsfallshortofbeingeffectivelearningtoolsandrelatablepartners.Traditional
chessenginessuchasStockfishandAlphaZeroareunimaginablystrong,buttheydon’tplayinways
that humans can easily understand or learn from. Comparing one’s own decisions with those of
traditionalengines,itiseasytoseehownear-perfectAIwouldhaveimproveduponyourplaybut
hardtoseehowyoucouldrealisticallydothesame. Recentworkhasresultedinthedevelopmentof
Maia,asuiteofmodelsthataimtomimichumanbehaviorinchessatvariousskilllevelsbylearning
topredictactualhumanmovesfromawealthofonlinegameplaydata[1]. Whilesubstantiallymore
human-like,thesemodelsstillcannotpowereffectivealgorithmicteachingtoolsbecauseofseveral
limitations.
Firstandforemost,Maiamodelsplayersatdifferentskilllevelscompletelyindependently;gamesby
playersatoneskilllevelandthosebyanadjacentskilllevelarefedintoseparateinstancesofthe
samearchitectureandresultinseparatemodels. Thishasthedownsidethatpredictionsfromone
modelareindependentlymadeofpredictionsfromanyother. Viewedasawhole,theyarevolatile:
theMaiamodelsmightpredictthatatonelevelplayerswillapproachapositioncorrectly,thenatthe
nextleveltheywillmakeahorriblemistake,thenatthenextleveltheywilldofineagain,andsoon.
Inaword,theyfailtocohere. Peopledon’timprovealongvolatilepaths,theysteadilygetbetter. The
unrealisticallyincoherentpredictionsmadebyseparatemodelsdon’tsuggestrealisticpathwaysthat
peoplecantakeinordertogetbetter. Inordertoserveasalgorithmicteachersorlearningaids,our
modelsofhumanbehaviormustbecoherent.
Buildingacoherentmodelofhumanskillinchessisdifficult,becausethebreadthofskillinchessis
almostincomprehensiblylarge. Decisionsmadebybeginnersbearonlythefaintestofrelationsto
thosemadebymasters. Adifferenceof200pointsinchessratingsystemsroughlyequatestoa75%
winrateforthehigher-ratedplayer—typicallyhigherthanthebestrecordofanyteamintheentire
NationalBasketballAssociation. Ontheonlinechessplatformwestudy,thereareplayerswhoare
2600ratingpointsapart—or13successivestepsof75%-vs.-25%dominanceapartfromeachother.
Capturingthisbreadthofskillinasinglemodel,inacoherent,smoothfashion,isachallenge.
Wecontributeaunifiedmodelingapproachforhuman-AIalignmentinchessthatcoherentlycaptures
humanstyleacrossdifferentskilllevelsanddirectlycaptureshowpeopleimprove. Sinceourmodel
buildsdirectlyonoriginalMaia,wecallitMaia-2. Maia-2consistsofastandardresidualnetwork
towerthatprocesseschesspositionsintofeatures,andournovelcontributionofaskill-awareattention
module with channel-wise patching. This innovation takes the position representation outputted
bytheresidualnetworktowerandsimpleplayerskillencodingsandlearnshowplayerskilllevels
interactwithchesspositionstoproducethemoveshumansmake. Unlikepreviousmodels,Maia-2
onlyrequiresthecurrentboardpositionasinput(asopposedtosix),whichdramaticallyreduces
trainingtimeandincreasesflexibility(e.g.forapplyingthemodelinnon-gamecontextswherethere
maybeno6-boardhistory). Inadditiontopolicyandvalueheadslikeinpreviouswork,wealsoadd
anadditionalauxiliaryinformationheadthathelpsthemodellearnadeeperunderstandingofhuman
chessmoves.
WeevaluateMaia-2alongtwokeydimensions: movepredictionaccuracyandcoherence. Testingit
againsttheoriginalMaiamodels,Stockfish,andAlphaZero,Maia-2emergesasthemostaccurate
humanmovepredictorbyfar,surpassingoriginalMaiabyalmost2fullpercentagepoints. Analyzing
move prediction accuracy by skill level, Maia-2 matches and surpasses all other models on all
skill levels. Furthermore, Maia-2’s gains in perplexity are similarly striking, reducing average
perplexityfromapreviousrecordof4.67bitsdownto4.07bits. Maia-2achievestheseaccuracy
gainswhilebeingsubstantiallymorecoherentthantheoriginalMaiamodels. Forexample,calla
model’streatmentofapositionmonotonicifitassignsamonotonicallyincreasingprobabilitytothe
2correctmoveasweincreaseskill. WhileoriginalMaiatreats1%ofarandomsampleofpositions
monotonically, Maia-2 treats a remarkable 27% of the same positions monotonically. This is in
keepingwithourintuitiveunderstandingofhowchessplayerssteadilyandsmoothlyimproveacross
the skill range. Finally, we conduct an investigation of the human chess concepts Maia-2 learns
and varies with skill via linear probes, and find that skill-dependent concepts like overall board
evaluationindeedvarywithskill,butskill-independentconceptsdonot,whichalsoaccordswithour
understandingofhowhumanplayersmakedecisions.
2 RelatedWork
2.1 ChessandAI
ThispaperdrawsonthelonghistoryofchessattheforefrontofAIresearch[2,3,4,5]. Weengage
with3distinctapproachestobuildingchessAI:heuristic[6],learned[7],andtextual[8].
Heuristicsearch. Theoriginalapproachtocomputerchesswasheuristics-based[4,9]. Thismethod
was famously used by IBM’s Deep Blue to defeat Garry Kasparov [2] and is currently used by
Stockfish[6],oneofthestrongestchessenginesintheworld.
Learned search. Alpha(Zero) Go [7, 10] is a set of neural networks that learn to play Go with
methodsthatgeneralizedtoothergames,includingchess,withAlphaZero[10]. Theconvolutional
neuralnetworkstacktheyintroducediswhatMaia-2’sisbasedon.
Chessastext. Largelanguagemodels[11,12,13]haverecentlybeenfoundtoperformwellon
tasksthatthemodelswerenotexplicitlytrainedon[14],includingplayingchesswithoutfine-tuning
[15,16,17]. ThishasleadtochessknowledgebeingoneofthetestedfeaturesinBIG-Bench[18],a
popularLLMevaluationsuite. Additionally,fine-tuningalanguagemodelcanleadtosystemsthat
notonlyplaychess,butcanalsogeneratecomments,describepositions, andcreateothersimple
analysesofagame[19,20,8].
2.2 Human-AIAlignmentinChess
Buildingachessenginethatcandefeatanyhumanhasbeenasolvedproblemforover20years. This
hasledtoanewresearchagendainextractingusefulknowledgefromthesesuperhumansystems. A
directwayofdoingthisistoprobeanAIchessengineinahumanrepresentationspace. Without
anypriorhumanknowledgeorguidance,evidenceofhumanchessconceptslearnedbyAlphaZero
isfoundandmeasuredbylinearprobes[21]. Goingfurther, AlphaZeroalsoencodesknowledge
thatextendsbeyondexistinghumanknowledgebutisultimatelylearnablebyhumans[22].Another
directionwasthecreationofa‘behavioralstylometry’modelthatcanidentifychessplayersfromthe
movestheyplay[23].
Human-likechessAI.Analternativeapproachtocreatingsystemsthatcanactasguidestohumans
isdemonstratedbyMaia[1,24],inwhichamodelistrainedtopredictthenextmoveahumanat
agivenskilllevelwillplay,insteadofoptimizingforwinningthegame. Inadditiontopredicting
humanactions,themodelshavebeenfine-tunedtopredictagivenplayer’sactions[24]. Thismethod
suggeststhatplayershaveadistinctandmeasurablestylethatcanbelearnedbyobservingasufficient
number of games. The prediction accuracy can be improved via a reinforcement learning-style
search[25].
3 Methodology
Weproposeaunifiedmodelarchitecturetocapturehumandecision-makinginchessacrossabroad
spectrumofskilllevels. SincethismodelbuildsuponthepreviousMaiamove-matchingmodels,
wecallitMaia-2. AsshowninFigure1,Maia-2firstencodesactiveandopponentskilllevelsand
thechesspositions, respectively. Thentheencodedskilllevelsandpositionsarefusedusingour
skill-awareattentionwithchannel-wisepatchingarchitecture. Thefusedrepresentationsarethenused
formoveprediction(policyhead),auxiliaryinformationprediction(infohead),andgameoutcome
prediction(valuehead). Wenowdiscusseachofthesecomponentsindetail.
3$(cid:15)(cid:8)(cid:18)(cid:18)(cid:2)(cid:11)(cid:14)(cid:7)(cid:13)<(cid:2)(cid:4)6(cid:8)(cid:12)+(cid:15)(cid:13)(cid:18)7
555
(cid:16),(cid:13)(cid:11)(cid:11)(cid:4)-(cid:2)%(cid:2)(cid:11)(cid:4).(cid:18)+(cid:5)(cid:3)(cid:2)(cid:6)
(cid:19)(cid:20)(cid:21)(cid:22)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:4)(cid:24)(cid:29)(cid:29)(cid:28)(cid:30)(cid:29)(cid:21)(cid:31)(cid:30)
/(cid:28)01(cid:28)(cid:29)(cid:4)2(cid:26)3(cid:20)4(cid:31)(cid:30)(cid:28)
$(cid:5)(cid:18)%&’( )(cid:4) *
(cid:0)(cid:2)(cid:2)(cid:3)(cid:4)(cid:0)(cid:5)(cid:6)(cid:7)(cid:8)(cid:6)(cid:3)
(cid:16)(cid:15)(cid:5)(cid:6)(cid:12)+(cid:10)(cid:12) (cid:10)(cid:2)(cid:6)!
$(cid:5)(cid:18)%&’( )(cid:4) * (cid:19)(cid:20)(cid:21)(cid:22)(cid:22)(cid:23)(cid:24)(cid:25)(cid:26)(cid:27)(cid:28)(cid:4) (cid:10)(cid:2)(cid:6)!
#(cid:8)(cid:11)(cid:10)(cid:2) 6(cid:5)(cid:5)(cid:11)(cid:13)(cid:18)7(cid:4)8
6(cid:5)<(cid:13)(cid:12)(cid:13)(cid:5)(cid:18)(cid:4).(cid:18)+(cid:5)(cid:3)(cid:2)(cid:6) (cid:0)(cid:2)(cid:2)(cid:3)(cid:4)(cid:0)(cid:5)(cid:6)(cid:7)(cid:8)(cid:6)(cid:3)
$(cid:5)(cid:18)%&’( )(cid:4) * "(cid:2)! (cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:2)(cid:8)(cid:3)(cid:4)(cid:16)(cid:2)(cid:11)(cid:17)(cid:14)(cid:8)(cid:12)(cid:12)(cid:2)(cid:18)(cid:12)(cid:13)(cid:5)(cid:18)
Figure1: OverviewoftheMaia-2modelarchitecture.
555 $(cid:5)(cid:18)%&’( )(cid:4) *
(cid:0)(cid:2)(cid:2)(cid:3)(cid:4)(cid:0)(cid:5)(cid:6)(cid:7)(cid:8)(cid:6)(cid:3) (cid:9)(cid:5)%(cid:2) 9(cid:10):(cid:13)(cid:11)(cid:13)(cid:8)(cid:6)! #(cid:8)(cid:11)(cid:10)(cid:2)
;(cid:2)(cid:8)(cid:3) ;(cid:2)(cid:8)(cid:3) ;(cid:2)(cid:8)(cid:3)
3.1 SkillLevelEncoder
Insteadofdirectlyincorporatingplayerratingsasnumericalinputs,weusecategoricalskilllevel
embeddingsfortworeasons. First,playerbehavioranddecision-makinginchessarenotlinearly
relatedtotheirrating. Categoricalembeddingsallowforcapturingcomplex,non-linearrelationships
betweenplayerstrengthandtheirmoves. Theycanencodenuanceddifferencesinplaystyleand
strategythatarenotdirectlyproportionaltoplayerratings. Second,Generalizationacrosssimilar
skilllevels: Playerswithinacertainskilllevelmayexhibitsimilarplayingstyles, strategies, and
common mistakes. Categorical embeddings group players into these ranges, helping the model
to better generalize across players with similar strengths, as opposed to treating each rating as a
numericalinput.
Let E ∈ R|E|×ds bethe matrixof playerratingembeddings, where eachrow correspondsto the
embeddingofaskilllevelwithdimensiond : E=[e ,e ,...,e ]⊤. Given
s (0,1000] (1000,1100] (2000,+∞)
theskilllevelsaandoofanactiveplayer(i.e.theplayertomove)andtheopponentplayer,welook
uptheembeddingmatrixEbyrowstomaptheskilllevelstoactiveandopponentskillembeddings:
e =E[a],e =E[o].
a o
Notethatpreviouswork[1,25]usescompletelyindependentmodelsforhuman-AIalignmentat
different skill levels—e.g. decisions by 1100-rated chess players are encoded in one model and
decisions by 1500-rated players are encoded in a separate model. Further, these models ignore
opponent skill level, meaning that predictions cannot vary as a function of opponent strength.
However,theactiveplayer’sdecisionsmaybesignificantlyaffectedbytheopponent’sskilllevel
incertaintypesofsituations,oreveningeneral. Playersmayadjusttheirstrategybasedontheir
perceptionoftheopponent’sskill,e.g.ahigher-skillopponentmightpromptmore(orless)cautious
play,whileagainstalower-skillopponentaplayermaypursuemoreaggressivetactics. Thus,the
interactionbetweentheskilllevelsofbothplayersisanimportantcomponentofmatchinghuman
moves. Unlikeexistingmodelsthatignoreopponentskilllevel(andactuallyonlyconsidergamesin
whichbothplayersareatthesameskilllevel),weexplicitlymodelnotonlyopponentskillbutalsothe
complexinterplaybetweenthetwoplayers’skilllevels,andhowitaffectshumandecision-making.
3.2 PositionEncoder
Positionrepresentation. Weuseawell-establishedmethod[10,1]torepresenteachchessposition
as a multi-channel tensor P
input
∈ RCboard×8×8, which includes channels for each type of chess
piece, which color is to move, and states of the position that are not derivable from the position
alone(castlingrightsandenpassant),whereC denotesthenumberofchannels. Oneimportant
board
departurefrompreviousworkisthatweonlyusethecurrentchessposition,andnotthelastfewchess
positionsthatoccurredinthegame(modelshavetypicallyincorporatedthesixmostrecentpositions
inthegame). Manygameswithperfectinformation,includingchess,canbemodeledasalternating
Markovgames[26,7], wherefuturestatesareindependentofpaststatesgiventhecurrentgame
state. Therefore,thecurrentchesspositiontheoreticallyencapsulatesalltheinformationnecessaryto
makefuturedecisions. Althoughhumandecision-makinginchessmaysometimessubtlydepend
onthehistoricallead-uptothecurrentposition,theseeffectsareanecdotallysmall. Inexchange,
4wegaintwolargepracticalbenefits. First,modelingAI-humanmovematchinginaMarkovianway
vastlyimprovestrainingefficiencybyreducingthecomputationalloadviasignificantlysmallerdata
usageforeachdecision. Second,italsoenhancesflexibility,enablingourresultingmodeltomake
predictionsevenwithouthistoricaldata,whichisparticularlyadvantageousinsituationswhereonly
thecurrentpositionisavailable,likechesstrainingpuzzlesoranypositionthatdidn’tnecessarily
occurinafullgame.
Position encoding. Toprocess theposition representationP , we encodeP with the well-
input input
establishedResNet-based[27]backbonearchitectureforchesspositionmodelingwithK sequen-
Conv
tiallyconnectedblocks[1]:P
encoded
=Backbone ×KConv(P input)∈RCpatch×8×8,whereP encodeddenotes
theencodedpositionrepresentationofC channels. Moredetailsaboutpositionrepresentation
patch
andthebackbonearchitecturecanbefoundinAppendixSectionB.
3.3 BridgingSkillLevelsandPositions
A central challenge we face is learning how players at different skill levels interact with chess
positionsdifferently. Howdoesanexpertplayerevaluateandprocessachesspositiontocomeup
withamove,andhowdoesthisdifferfromanovice? Therelationshipbetweenpositionsandskill
levelsiscomplicatedbythenon-linearityinhowplayersofvariousskilllevelsinterpretandreactto
chesspositions. Thiscomplexitypresentsasignificantchallengeinhumanmovepredictionusing
aunifiedmodelfordiverseskilllevels. Tobridgeskilllevelsandpositions—decision-makersand
decisions—weproposeskill-awareattentionwithchannel-wisepatching.
Channel-wise patching. In contrast to the area-wise patching approach in Vision Transformers
(ViTs)[28],weemploychannel-wisepatching. Eachchannelisflattenedandlinearlytransformed,
regardingthenumberofchannelsinP ,i.e.,C ,asthesequencelength.
encoded patch
P =Patching(P )∈RCpatch×64,
patched encoded
P =P W+b∈RCpatch×datt,
patched
whereW∈R64×datt andb∈Rdatt denotetheparametersofthelinearprojectionfromthepatching
dimensiontothehiddendimensionoftheskill-awareattentionblocksd .Thisisparticularlysuitable
att
forpatchingencodedchesspositionsasinputstoTransformer-likearchitectures,wherechannelsare
essentiallyfeaturemapsthatrepresentdifferentlearnedlatentconcepts. Theseconceptsinfeature
mapsaretheninteractivelyselectedandaggregatedconsideringskilllevelsviaskill-awareattention.
Skill-awareAttention. GivenpositionrepresentationsP andskilllevelrepresentationse and
patched a
e ,ourproposedskill-awaremulti-headself-attentioniscomputedasfollows.
o
Foreachheadk,welearnweightmatricesWQ ∈Rdatt×dh,WK ∈Rdatt×dh,andWV ∈Rdatt×dh,
k k k
whered denotethedimensionofeachhead. ThequeriesQ ,keysK ,andvaluesV foreachhead
h k k k
arecomputedas:
Q =P WQ, K =P WK, V =P WV
k patched k k patched k k patched k
In order to fuse player skill levels and chess positions progressively and interactively, we inject
skilllevelembeddingsintoquerieswithinthemulti-headself-attention: Q∗ =Q +(e ⊕e )W∗,
k k a o
whereW∗ ∈R2ds×dh denotestheweightmatrixforfeaturetransformationtothequeryspace,and
⊕istheconcatenationoperator. Wechoosetoincorporateskilllevelsinqueriesbecausequeries
directlyinfluencehowattentionisdistributedacrosspatchedchannels. Usingskill-awarequeries
Q∗,theattentionmechanismcanadjustitsfocustoreflectthestrategicconsiderationsandpositional
k
understanding of players at different skill levels. This adjustment allows Maia-2 to adaptively
prioritizefeaturesofthepositionsthataremorerelevanttotheskilllevelsinvolved,enhancingthe
model’scontextualsensitivity. Theskill-awarescaleddot-productattentionforeachheadisthus
definedas:
(cid:18) Q∗KT(cid:19)
h =softmax √k k V
k k
d
k
The outputs of all heads h ,h ,...,h are concatenated and then linearly transformed: P =
1 2 h att
σ((h
1
⊕h
2
⊕...⊕h h)WO), where WO ∈ Rhdh×datt denote the weight matrix for multi-head
attentionandσ(·)denotestheactivationfunction. WeapplythevanillaViT’sfeed-forwardnetwork
5andadd&normcomponentsuponP toobtaintheoutputofeachskill-awareattentionblockP .
att out
InMaia-2,weemployasequenceofskill-awareattentionblockstoprogressivelyfuseskilllevels
andpositions. Specifically,theoutputP forthepreviousblockisfedintothenextblockasthe
out
input. WedenotethefinaloutputafterK blocksasP. Thisprocedureenablesthemodeltorefine
Att
itsunderstandingandinterpretationofthepositionswitheachsuccessiveblock.
3.4 ModelTraining
Infusingauxiliaryinformation. Toenhancethemodel’sunderstandingofthegamestate,weinject
auxiliaryinformationaslabels,includinglegalmovesrepresentedbymulti-hotvectorsandhuman
moveinformation: one-hotvectorsofwhichpieceismoved,whichpieceiscaptured(ifany),the
move’soriginatingsquare,themove’sdestinationsquare,andwhetherornotthemovewilldelivera
check. Fornuancedmoveslikecastling,weensureboththeking’sandrook’smovesareaccurately
representedwith2-hotvectors. Thesesegmentsarethenconcatenatedintoacomprehensivemulti-hot
vectortobeusedaslabelsforclassification, servingadualpurpose: 1)Itoffersamoregranular
understandingofhumanmovesbyprovidingdetailedcontextbeyondjustthemoveindicesproduced
bythepolicyheadlabels,enrichingthemodel’sinsightofplayerdecisions;and2)Itensuresthe
modelalsolearnsaboutobjective(i.e.chess-specificasopposedtobehavioral)knowledgeinchess,
which is essential for developing a comprehensive understanding of both human moves and the
fundamentalmechanicsofthegame.
Databalancing. Chessgamesbetweenplayersofsignificantlydifferentskilllevelsarerelatively
rarebuthelpusunderstandhowplayersoflowerskilllevelsapproachgamesagainstfarstronger
opponentsandviceversa. Whilepreviousworkhasignoredthesegamescompletely,theyplaya
centralroleinourapproach. Sincegamesbetweenplayersofsimilarskilllevelsvastlyoutnumber
moreunevenmatchups,weuseadatabalancingstrategytoeffectivelytrainourunifiedmodelfor
aligningplayersacrossallskilllevels,inwhichgamesbetweenplayersofdifferentskilllevelsare
over-sampled. Tobeprecise,wepre-processthedatainchunksofN gameseach. Wethenscan
chunk
eachdatachunktofindgamessatisfyingvarious(activeplayerskill,opponentskill)combinations.
Each skill combination can include at most N games. We continue scanning the data chunk
range
untilalltheskillcombinationshaveN gamesorthedatachunkisfullyconsumed. Notethat
range
thehigherthebalancingfactor Nrange,thelesslikelyitisthatrareskillcombinationswillfullyreach
Nchunk
N ,whichwillleadtolessbalanceddataoverall. Ontheotherhand,ifthebalancingfactoristoo
range
small,fewergameswillbeselectedfromeachdatachunk,whichisdata-inefficient. Wechoosea
faircompromisebetweendataefficiencyandbalanceddatasothatourtrainingdataencompasses
abroadspectrumofskilllevelswithoutbiasingexcessivelytowardsthemorefrequently-occurring
equal-skillmatchups.
Datafiltering. Onlinechessplatformsfeatureavarietyofgametypes,includingblitz,rapid,and
classical,eachrepresentinggamesplayedatdifferenttimecontrols(amountoftimegiventoeach
player for the whole game). We use data from Lichess, a well-known large open-source chess
platform,anditsopendatabase. InLichess,sinceeachgametypeisgivenaseparaterating,ratings
across different game types are not comparable (e.g. a rating of 1800 in “Rapid” is significantly
weakerthanaratingof1800in“Blitz”onLichess). Previouswork[1,24]mixesplayerratingsacross
thesegametypestogetherfortrainingandevaluation. Insteadofmixingdataacrossgametypes,
we focus on Rapid games only, which are medium-length games that lie between the fast-paced
decisionsof“Blitz”gamesandtheslower,morestrategicconsiderationsof“Classical”games. “Blitz”
and“Bullet”games,characterizedbytheirquickpace,arecomposedofmanydecisionsmadeunder
timepressure,introducingrandomnessthatmaynotaccuratelyreflectplayerintentionsandskills.
Incontrast,Classicalgamesareplayedlessfrequently,leadingtodatascarcity. Rapidchessisan
idealcompromisebetweenqualityofplayandquantityofdata. Inaddition,wefollowtheprocedures
in[1]tofiltervalidpositionswithineachgame(moredetailscanbefoundinAppendixSectionB).
Trainingobjectives. WiththefusedskilllevelandpositionrepresentationP asinput,weconstruct
thepolicyheadontoptopredicthumanmoves,whichisoptimizedusingcross-entropylosswith
one-hotlabelsrepresentingtherecordedhumanmove. Wealsobuildtheauxiliaryinformationhead
toinfuseadditionalknowledgeintoMaia-2asintroducedinSection3.4. Thisheadistrainedusing
bit-wisebinarycross-entropylosswithmulti-hotlabels. Finally,followingpreviouswork[1,24]we
6includeavalueheadtopredictthegameoutcomeasaregressiontask,wherethelabels1,0,-1denote
winning,drawing,andlosing,respectively. Thetrainingobjectivesoftheseheadsarebalancedto
contributeequallytoMaia-2modeloptimization. HyperparametersettingsusedforMaia-2training
canbefoundinAppendixTable5.
4 Results
WeempiricallyevaluateMaia-2alongtwokeydimensions: movepredictionaccuracy,howwellit
canpredicthumanmovesatvaryingskilllevels,andmovepredictioncoherence,howalignedits
predictionsareacrossskilllevels.
4.1 ExperimentalSetup
Maia-2. WetrainMaia-2onLichessgamesplayedbetweenJan2013andNov2023(inclusive),with
theexceptionofDec2019,sincethatisthemonthusedfortestingintheoriginalMaiapaper(andwe
alsotestonthismonthforconsistency)[1]. Aftergamefilteringandbalancing,weendupwitha
trainingsetof169Mgames(9.1Bpositions)playedbetweenMay2018andNov2023(inclusive).
To control for differences in training sets when comparing Maia-2 against Maia-1, we also train
Maia-2 withidenticalmodelarchitectureandtrainingconfigurationsasMaia-2,exceptitonly
subset
hasaccesstothesametrainingdatathatMaia-1had(i.e.gamesplayedfromJan2013toNov2019in
theLichessDatabase). TrainingdatasetstatisticsarereportedinAppendixTables7,9,and10.
Model comparison. We compare Maia-2 with several baselines. The first is Stockfish [6], the
strongestchessengineintheworldatthetimeofwriting. Sincethemostcommonmethodofusing
Stockfish to play in a “human-like” way is to limit its search depth, we test it at various search
depths. ThesecondisLeela,anopen-sourcecounterparttoAlphaZero[10],whichwealsotestat
variousstrengths,sincechesscommentatorshaveanecdotallyobservedthatitsdecisionsaremore
reminiscentofhuman-likeplayatlowerstrengths. Finally,ourmainmodelcomparisonwillbewith
Maia(whichwewillrefertoas“Maia-1”toavoidconfusionwithourmodel),thestate-of-the-art
modelforhuman-likechessplay[1]. Maia-1isactuallyasetof9separatemodels,eachtrainedon
adifferentsetofplayersatdifferentskilllevelsfrom1100to1900. Maia-1100modelstheweaker
players,Maia-1500theintermediateplayers,andMaia-1900thehigher-skillplayers.
Evaluation Datasets. We evaluate using three main test sets. To enhance fair comparison with
baselinemodels,weusethebenchmarkingMaia-1Testset [1]forperformancecomparisonswhere
bothplayershaveidenticalskilllevels. WereporttheresultsonMaia-1Testsetbygroupingplayers
into three categories: Skilled (Rapid rating up to 1600, which slightly exceeds the initial rating
of1500),Advanced (Rapidratingbetween1600and2000),andMaster (Rapidratingover2000,
roughlycomprisingthetop10%ofplayers[29]). Inaddition,weaimtoevaluatemoveprediction
acrossdiverseskillcombinations,whichMaia-1Testsetexcludes. Therefore,weconstructtheCross-
skillTestset,anewtestingdatasetfromLichessgamesplayedinDec2023,ensuringthatpositions
undereachskilllevelcombinationhavesufficientdatatobestatisticallyreliable. Detailedstatistics
of this dataset are summarized in Appendix Table 8. Finally, we construct Grounded Testset by
extracting450,000positionsfromDec2023gamesinLichessDatabasewhereStockfishevaluations
areavailable. Suchrecordedevaluationsserveasgroundedfactstomeasuremovequality.
4.2 MovePredictionAccuracy
InTable1,weshowthetop-1movepredictionaccuracyofallmodelsacrossallgroupsofplayerson
theMaia-1Testset.
Maia-2. Maia-2demonstratesstrongandconsistentperformanceacrossallskilllevels,surpassing
allbaselines. Specifically,despiteMaia-1modelsbeingspecificallytrainedtomimicchessmoves
byplayersatspecificskilllevels,Maia-2emergesasaunifiedone-for-allmodelthatisconsistently
effectiveacrosstheentirespectrumofchessskills. ThelargestimprovementisonAdvancedplayers,
whereMaia-2gains1.5percentagepointsoverthenearestcompetitor(Maia1500).Recallthathuman
movepredictionhasalargeamountofintrinsicnoise: differentplayersofequalskillfacingthesame
7Table1: MovepredictionaccuracyontheMaia-1Testset. Skilled,Advanced,andMasteraregrouped
accordingtoSection4.1andAvgdenotesmacro-averagedresults.
Skilled Advanced Master Avg
Stockfish3 36.22 38.25 40.71 38.39
Stockfish7 35.66 38.08 42.25 38.66
Stockfish9 36.00 38.78 43.26 39.35
Stockfish11 36.38 39.33 43.71 39.81
Stockfish15 36.86 39.83 44.61 40.43
Leela1500 40.46 44.45 48.69 44.53
Leela2200 39.79 43.97 47.11 43.62
Leela3200 39.97 44.29 47.75 44.00
Leela3700 40.47 44.65 48.12 44.41
Maia1100 51.48 49.13 45.85 48.82
Maia1500 50.79 52.61 50.76 51.39
Maia1900 48.51 52.26 53.20 51.32
Maia-2 51.51 53.54 53.16 52.74
subset
Maia-2 51.72 54.15 53.87 53.25
Maia 1100 Maia 1900 Maia-2
48.0 47.5 47.3 46.1 51.1 52.0 52.5 52.9 52.4 53.1 53.8 53.6 55
49.2 48.4 48.8 48.1 47.5 51.1 51.5 52.8 52.9 53.3 52.7 53.3 54.2 54.2 54.3 54
49.5 49.3 49.0 49.1 48.4 47.8 49.4 51.2 51.6 52.9 53.0 54.0 51.5 53.0 53.2 54.3 54.5 55.0
50.1 50.0 49.9 49.8 49.2 48.7 48.6 49.0 49.9 51.4 52.0 52.7 53.5 54.4 51.6 52.2 53.4 53.8 54.4 54.9 55.7 53
50.4 50.8 50.6 50.4 50.1 50.1 49.6 47.8 49.5 50.9 51.6 52.2 53.3 54.2 51.1 52.1 53.1 53.7 54.2 55.2 55.6 52
51.0 50.9 51.5 50.9 51.0 50.7 50.8 47.5 48.3 50.4 50.5 51.8 52.9 53.9 51.1 51.5 53.4 53.1 54.0 54.8 55.6 51
50.2 50.5 51.5 51.6 51.5 51.5 51.4 46.2 47.3 49.6 50.3 50.7 52.0 53.0 50.0 50.6 52.8 53.4 53.3 54.5 55.1 50
50.5 51.9 51.6 52.0 50.8 51.8 46.3 48.7 49.2 50.3 49.8 52.3 50.2 52.2 52.6 53.4 52.3 54.8 49
51.5 51.9 52.2 52.2 50.6 47.7 48.4 49.4 50.2 49.0 51.4 52.0 52.9 53.3 52.2 48
51.6 51.8 52.0 52.8 47.3 48.3 48.8 50.2 51.2 52.1 52.4 53.9
47
1200 1600 2000 1200 1600 2000 1200 1600 2000
Active Player's Skill Level Active Player's Skill Level Active Player's Skill Level
Figure2: Movepredictionaccuracyacrossdiverseskilllevels. Colorsrepresentperformance,with
warmertonesindicatinghigheraccuracy. Missingskillcombinationsweretooraretobestatistically
reliable.
positionmaymakedifferentpoints,andindeed,eventhesameplayerfacingthesamepositionmay
vary in their decision-making. When averaging across skill levels, Maia-2 outperforms all other
modelsbyalmost2fullpercentagepointsinoverallaccuracy.
Baselinemodels. BothMaia-2andMaia-1significantlyoutperformStockfishandLeela,typicallyby
5–15percentagepoints. NotethatStockfishandLeelaaimtoplayoptimalchess(asmosthumansdo
too),andonly“predict”humanmoveswhentheirapproximationstooptimalityhappentooverlap
withthoseofhumanplayers. However,wecomparetothesetraditionalchessenginesbecausebesides
Maia-1, therearestillthedefaultmethodofcreating“human-like”AIagents. Theaccuracygap
betweenMaiaarchitecturesandtraditionalchessenginesdemonstratesthenecessityofdeveloping
specializedmodelstomimichumanchessmoves.
Maia-2 . Maia-2differsfromMaia-1intwomainways: ithasadifferentarchitectureandit
subset
hasaccesstomoretrainingdata. Tocontrolforthedifferenceintrainingdataandisolatetheeffects
of our architecture, we create Maia-2 which has access to the exact same training data that
subset
Maia-1wasdevelopedwith. Comparingthetwo,weseethatMaia-2 matchesoroutperforms
subset
allbaselinesandalternatemodels. RecallthatMaia-2andMaia-2 don’thavetherecenthistory
subset
passedasinputtothem, yetstillachievestate-of-the-artresults. Itisimportanttonotethateach
Maiamodelisspecificallytrainedforitsrespectiveskilllevel,relyingsolelyongameswherethe
activeandopponentskilllevelsmatchforitstrainingdata. Onthecontrary,theunifiedmodeling
approachwithskill-awareattentionofMaia-2 allowsittoutilizeabroaderspectrumofgames,
subset
featuringavarietyofskill-levelpairings,fortrainingpurposes. Consequently,whilebothMaia-1
8
leveL
llikS
s'reyalP
tnenoppO
0002
0061
0021
ycaruccA
noitciderP
evoMTable2: MovepredictionperplexityontheGroundedTestset.
Skilled Advanced Master Avg
Maia1100 5.05 5.56 6.01 5.54
Maia1500 4.98 5.31 5.50 5.26
Maia1900 4.44 4.71 4.86 4.67
Maia-2 4.30 3.90 4.02 4.07
andMaia-2 drawfromthesamesourcedataset,Maia-2 canleverageasignificantlylarger
subset subset
portionofthisdataforitstraining,improvingitslearningandpredictivecapabilities.
TheimprovementfromMaia-2 toMaia-2underscorestheimportanceofextensivetrainingwith
subset
vastdatasets. AbroaderrangeofgamesprovidesMaia-2withaccesstomorecomprehensiveand
nuancedpatternsinhumanchessmoves. UsingMaia-2 asacomparison,wecandeterminethe
subset
relativecontributionsofmodelarchitectureandtrainingdatatoMaia-2’s1.9percentagepointgap
overitsnearestrival(Maia1500). Thiscalculationsuggeststhat73%oftheincreaseinperformance
isduetothearchitectureimprovementsand27%isduetoincreasedtrainingdata.
Move prediction perplexity. While top-1 accuracy gains are important, they may overshadow
largerimprovementsinpredictionquality. Toaccountforthis,wealsomeasuretheperplexityof
move predictions , which reflects the model’s confidence in its predictions. A lower perplexity
indicatesthemodelismoreconfidentandaccurateinhumanmoveprediction,asitcorrespondstoa
higherlikelihood(lowerlog-likelihood)ofthecorrecthumanmove. AsshowninTable2,Maia-2
consistentlyyieldssubstantiallylowerperplexityinallgroupsofskilllevelscomparedtoMaia-1. In
particular,Maia-2significantlyoutperformsMaia-1inAdvancedandMastermoveswithrelatively
largemargins,demonstratingtheeffectivenessofourunifiedmodelingapproachacrossdiverseskill
levels.
Adaptivemovepredictions. WenowevaluateMaia-2’sabilitytopredictcompareacrossdiverse
skillcombinationsusingtheCross-skillTestset.
AsshowninFigure2,Maia-2consistentlyoutperformsbothMaia1100andMaia1900inalmostall
combinationsofactiveplayerandopponentplayerskilllevels. Inparticular,althoughMaia1100and
Maia1900demonstratecompetentperformancewithintheirrespectivedomainsofexpertise,their
predictiveaccuracydecreasessubstantiallyoutsideofthesetargetedskilllevels. ThisisbecauseMaia-
1modelsarestaticandcannotrespondtovariedskilllevelsandadjusttheirpredictionsaccordingly.
Incontrast,ourproposedunifiedmodelingapproachwithskill-awareattentionenablesMaia-2to
adaptitspredictionstoaccountfortheskilllevelsofboththeactiveplayerandtheopponentplayer,
sothatvaryingskilllevelconfigurationscorrespondinglycanresultinbetteralignedhumanmove
predictions. MoreresultsoncomparisonswithotherMaia-1versionscanbefoundinFigure7inthe
Appendix.
Movequality. Oneofourkeymotivationsforcreatingaunifiedmodelofhumanchessbehavioristo
guidethedevelopmentoffuturealgorithmiclearningtools. Assuch,understandingthemistakesthat
peoplemakeisoffundamentalinterest. CanMaia-2predictmistakesbetterthanMaia-1? Figure11
in the Appendix shows the move prediction accuracy on the Grounded Testset as a function of
movequality,measuredbywin-rateloss,whichiscalculatedfollowingthesameproceduresasprior
studies[1,24]. Allmodelsgenerallydecreaseintheirabilitytopredictworsemoves,sincehumans
aregenerallytryingtoavoidmistakes,andhigh-qualitymovesaremorecertainwhereaslower-quality
movescanbemorerandomandthushardtopredict. Nevertheless,Maia-2outperformsallversionsof
Maiaacrossmostofthemovequalityrange,demonstratingtheeffectivenessofourunifiedmodeling
approachforhumanmoveprediction.
Wearealsointerestedinhowcertainthemodelsareabouttheirpredictionsofvariousmovequalities.
Figure3(top)showstheprobabilitiesthatMaia-2(x-axis)andMaia-1(y-axis)attributetothemoves
peopleactuallyplayedinGroundedTestset. Theconcentrationofpointsinthelowerrightquadrant
(closertoP(Maia-2)=1andP(Maia1900)=0)suggeststhatMaia-2assignsahigherprobabilitytothe
truemovethanMaia-1does,indicatingsuperiorpredictiveperformance. Conversely,thelessdense
upperleftquadrantindicatesfewerinstanceswhereMaia1900outperformsMaia-2. Remarkably,
9Blunders Errors Optimal
1.0 1e-02
0.8
1e-03
0.6
1e-04
0.4
0.2 1e-05
0.0
Log Odds Ratio
1.0
5.0
0.8
2.5
0.6
0.0
0.4
-2.5
0.2
-5.0
0.0
0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0
P(Maia-2)
Figure3: (Top)JointprobabilityassignedtohumanmovesplayedbyMaia-2(x)andMaia1900(y),
splitbymovequality. Blunders(left)reducetheexpectedwin-rateby≥10%,Errors(middle)by
5–10%,andOptimal(right)by≤0%. (Bottom)Logoddsratioofp(x,y)andp(y,x)fromtop.
Table3: Ablationstudyresults,whereMaia-2 iscomparedwithversionswithoutskill-aware
subset
attention(“w/oAtt”)andwithoutinfusingauxiliaryinformation(“w/oAux”).
Skilled Advanced Master Avg
w/oAtt 50.63 52.89 51.73 51.75
w/oAux 50.96 52.98 52.34 52.09
Maia-2 51.51 53.54 53.16 52.74
subset
while this consistenly occurs across all move qualities, the distinction is more pronounced for
BlundersandErrorscomparedtoOptimalmoves. Additionally,thebottomrowofFigure3shows
thelogoddsratiobetweenP(x,y)andP(y,x)inthetoprow. Theabundanceofbluepointsbelow
thediagonalindicatethatMaia-2isalmostalwaysmoreconfidentinthecorrectmovethanMaia-1is,
indicatinganacross-the-boardimprovementinmoveprediction. Maia-2offerssuperiorandmore
confidentpredictionacrossdiversemovequalities.
Ablation study. To understand which components of our architecture are most responsible for
the performance gains, we conduct an ablation study on the Maia-1 Testset. We train a version
of Maia-2 using a naive method of incorporating encoded skill levels without the proposed
subset
skill-aware attention module (“w/o Att”). In this model, the skill level encodings e and eo are
a
directlyconcatenatedwithflattenedP ,withoutbridgingthemwiththeskill-awareattention
encoded
(skippingSection3.3),anddirectlyconnectedtopredictionheads. AsshowninTable3,Maia-2
subset
consistentlyperformsbetterwithskill-awareattention,demonstratingthenecessityofmodelingthe
complexityandnon-linearityinplayer’sskilldevelopmentinsophisticatedwaysandtheeffectiveness
ofourproposedunifiedmodelingapproachwithskill-awareattentiontomodelsuchnuances. We
alsotrainaversionofMaia-2 withouttheauxiliaryinformationhead(“w/oAux”). Theseresults
subset
showthatinfusingauxiliaryinformationaslabelsduringmodeltrainingalsoresultsinasignificant
performanceimprovement,althoughnotasdramaticallyasskill-awareattention.
4.3 MovePredictionCoherence
Maia-2’saccuracyacrossthespectrumofhumanskilliscertainlydesirable,butperhapsanevenmore
importantdimensionispredictioncoherenceasskillvaries. AcentraldrawbackofMaia-1isthatit
modelsplayersatdifferentskilllevelsindependentlyfromeachother,whichresultsinparticularly
volatilepredictions: thesamepositionmightelicitverydifferentpredictedbehaviorfrommodelsof
10
)0091
aiaM(PTable4: Percentageofmonotonicandtransitionalpositions.
%Monotonic %Transitional
Skilled Advanced Master Skilled Advanced Master
Maia-1 1.61 1.42 1.14 13.34 18.14 20.48
Maia-2 27.61 28.51 26.38 22.59 23.39 21.72
Varying Active Player's Skill Level Varying Opponent Player's Skill Level
1.00
0.780.800.820.840.860.890.910.930.961.00 0.940.950.950.960.960.970.970.980.981.00
0.800.820.840.870.890.920.940.971.000.96 0.950.950.960.970.970.980.980.991.000.98
0.95
0.820.840.860.890.910.940.971.000.980.94 0.950.960.960.970.970.980.991.000.990.97
0.840.860.890.910.940.971.000.970.950.92 0.950.960.960.970.980.991.000.990.980.97 0.90
0.860.890.910.940.961.000.970.950.920.89 0.950.960.970.980.991.000.990.980.970.96
0.900.920.940.971.000.960.930.910.890.86 0.940.950.970.991.000.990.980.970.960.96 0.85
0.920.940.971.000.970.940.910.890.870.84 0.960.970.991.000.990.980.970.970.960.95
0.940.971.000.970.940.900.880.860.840.82 0.970.991.000.990.980.970.960.960.950.94 0.80
0.971.000.970.920.900.870.850.830.820.79 0.991.000.990.980.960.960.960.950.950.93
1.000.970.920.880.860.840.820.800.790.77 1.000.990.970.960.950.950.950.940.940.93 0.75
1200 1600 2000 1200 1600 2000
Active Player's Skill Level Opponent Player's Skill Level
Figure4: Movepredictionagreementas(left)activeplayerand(right)opponentplayerskillare
varied. Allcellsareevaluatedonthesamesetofpositionsbutwithalteredskilllevelconfigurations.
Thevalueineachcelldenotesthepercentageofpredictionsthatagreewiththediagonalofthesame
row,whereactiveandopponentskilllevelsaresetequal.
adjacentskilllevels. Thisisproblematicbecauseweknowfrompersonalexperiencethatthistype
ofvolatilityisrare: playersdon’tchangethatmuchastheyimprove. ThislimitsMaia-1’sability
toperformwellindownstreamtaskssuchasservingasateachingaid,asitsunderstandingofone
skilllevelbearslittleresemblancetoitsunderstandingofthenext. Inreality,playersmovefromone
skillleveltoanotherbymakingsmall,consistentadjustments. DoesMaia-2reflectthisbehavioral
coherence?
Predictionsmoothness.WemeasurethecoherenceofMaia-2’spredictionsbytestingforsmoothness
featuresinitsentiresetofpredictions.Callamodel’streatmentofapositionmonotonicifthepredicted
probabilityofthecorrectmoveincreaseswithskillmonotonically. IntheGroundedTestsetof100K
positions, wefindthatMaia-1onlytreats1%ofthemmonotonically. Instarkcontrast, however,
Maia-2treats27%ofthemmonotonically,clearlydemonstratingthatMaia-2ismuchmorecoherent.
Similarly, call a model’s treatment of a position transitional if it predicts a suboptimal move for
someprefixofskillsandthentransitionstoanoptimalmoveforallsubsequentskilllevels. Again,
Maia-2treatssubstantiallymorepositionstransitionally—around22%ofthemcomparedwith17%
forMaia-1.
Movepredictionagreement.Asafirsttest,wemeasuremovepredictioncoherenceaswevaryactive
playerskillandopponentplayerskillinMaia-2. TheresultsshowninFigure4revealseveraltrends.
First,increasinglyvaryingeithertheactiveoropponentratingresultsinloweragreement,suggesting
thatMaia-2smoothlyvariesitspredictionswithskill. Second,comparingthetwoheatmapsreveals
thatMaia-2hasclearlylearnedthatvaryingone’sownskillhasmuchlargereffectsthanvaryingthe
opponent’s—changingone’sownskillagainstafixedopponentcanchangethedecisionupto22%of
thetime,butchangingtheopponent’sskillwhilefixingourownskillwillonlychangethedecision
upto6%ofthetime. Thisisintuitive,asplayersmustchangetheirdecisionsinordertoplayata
higherlevel,whileintheoryone’sopponentshouldn’taffectone’sdecision. Ofcourse,humansare
notoptimalagentsandsometimestaketheiropponent’sskilllevelintoaccountwhendecidingona
move—willfullyornot—whichisreflectedinourresults.
Chessconceptunderstanding. Humanchessplayersofvaryingstrengthsdifferintheirabilityto
recognize important features and patterns on the board. Stronger players are adept at discerning
11
leveL
llikS
s'reyalP
tnenoppO
0002
0061
0021
leveL
llikS
s'reyalP
evitcA
tnemeergA
fo
eergeDmiddle_game_evaluation middle_game_piece_value
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 Pre Skill-Aware Attention 0.5 Pre Skill-Aware Attention
Post Skill-Aware Attention Post Skill-Aware Attention
0.4 0.4
1200 1600 2000 1200 1600 2000
Player Skill Level Player Skill Level
(a) SSSSkkkkiiiillllllll DDDDeeeeppppeeeennnnddddeeeennnntttt CCCCoooonnnncccceeeeppppttttssss (b)
has_bishop_pair_active can_capture_queen_active
0.68 0.65
Pre Skill-Aware Attention Pre Skill-Aware Attention
0.67 Post Skill-Aware Attention Post Skill-Aware Attention
0.60
0.66
0.65 0.55
0.64
0.50
0.63
0.62 0.45
1200 1600 2000 1200 1600 2000
Player Skill Level Player Skill Level
(c) SSSSkkkkiiiillllllll IIIInnnnddddeeeeppppeeeennnnddddeeeennnntttt CCCCoooonnnncccceeeeppppttttssss (d)
Figure 5: Maia-2’s chess concept recognition as a function of skill level, as measured by linear
activationprobesrightbefore(blue)andafter(orange)skill-awareattention. (A)Stockfishoverall
boardevaluationformiddle-gamepositions. (B)Stockfishevaluationofmiddle-gamebonusesand
penaltiestopiecesforwhite. (C)Doestheactiveplayerowntwobishops? (D)Cantheactiveplayer
capturetheopponent’squeen?
subtlenuances,includingaccuratelyevaluatingthestateoftheboardandunderstandingthestrengths
andweaknessesoftheirposition,thatofteneludetheirweakercounterparts. Whilewe’vealready
shownthatMaia-2hasaremarkablecapabilitytoadaptitsmovepredictionsaccordingtodifferent
skilllevels,wenowturnourfocustoacriticalquestion: doesMaia-2varyinitsabilitytocapture
humanchessconceptswhengivendifferentskilllevels?
FollowingthesamestrategypresentedinrecentworkofprobingchessconceptsinAlphaZero [21],
wetrainlinearprobesoninternalrepresentationsbeforeandaftertheskill-awareattentionblocks
of Maia-2, and use their test performance as a proxy for capturing chess concepts. In Figure 5,
we show how Maia-2’s grasp of various concepts varies with skill. The upper two plots show
conceptsforwhichMaia-2clearlydistinguishesbetweenskilllevels,withhigher-skillplayerspaying
moreattentiontothemthanlower-skillplayers. Thesearegeneralboardevaluationsasgivenby
Stockfish[6],oraggregatepiecevalues. Notethatpre-skill-awareattentionisalwaysflatbecauseby
constructionitcannotvarywithskill,sinceskill-awareattentionhasnotbeenappliedyet. Thelower
twoplotsdepictconceptsthatliveclosertofundamentalchessrules,andassucharelessdependent
on player skill. For skill-dependent concepts, the figures reveal an increasing trend in mastery
levelafterskill-awareattention,aligningwiththeincreaseindedicatedskilllevels. Meanwhile,the
model’smasteryleveldecreasesafterpassingthroughtheskill-awareattentionmodules,potentially
adjustingfortheimperfectionsofhumanplayers. Conversely,theskill-awareattentionblocksare
notresponsivetoskill-independentconcepts. FourmoreplotsinthisveinareshowninAppendix
Figure10.
5 Discussion
Maia-2isaunifiedmodelarchitecturethatcanaccuratelyandcoherentlycapturehumandecision-
making in chess across a broad spectrum of skill levels. As such, Maia-2 can be regarded as a
12
ycaruccA
ycaruccA
ycaruccA
ycaruccAfoundationmodelforhuman-AIalignmentinchess,servingasabasemodelforgeneral-purpose
explorations of human-like AI. For example, fine-tuning Maia-2 with personal historical data of
increasingactiveplayerskilllevelsanddiverseopponentplayerskilllevelscanyieldpersonalized
movepredictions,facilitatingalgorithmiceducationtoolsandmorerelatableAIpartners. Also,the
priorknowledgeandgeneralunderstandingacquiredduringpre-trainingcanhelpMaia-2tobedata
efficientwhenextendingtograndmasterlevelmoves,whicharerelativelyrareandthuscannotbe
learnedwiththepreviousskill-independentmodelingapproaches.
Thedevelopmentofhuman-likemodelsraisesethicalconcernsdiscussedinpreviouswork[24,30].
We believe Maia-2 poses limited risk while offering large potential benefits. Our data is highly
aggregated,withalmost1billiongamesbeingusedfortraining,andchessasadomainisgenerally
low-risk. Meanwhile, helping people improve in chess could lead to increased cognitive skills,
confidence boosts, and help with general life satisfaction. Our vision is for Maia-2 to power AI
partnersandtrainingaids;itcannotcurrentlyreplaceskilledhumantutorsandcoaches.
Ourworkhaslimitationsandnaturalextensions. First,weareexcitedbytheapplicationsthatMaia-2
will enable, such as more relatable AI partners and AI-powered learning aids, the development
ofwhichareoutofscopeforthecurrentwork. Maia-2doesnotyetincorporatesearch,although
previousworkhasdemonstratedthatwithproperregularizationitcanhelpimprovemoveprediction
performance[25]. Relatedly,wegroupthestrongestplayersinasinglebucket,althoughmodeling
theverybestplayersintheworldremainsdifficultduetothecomplexityanddepthoftheirmoves.
13References
[1] ReidMcIlroy-Young,SiddharthaSen,JonKleinberg,andAshtonAnderson. Aligningsuper-
humanaiwithhumanbehavior: Chessasamodelsystem. InProceedingsofthe26thACM
SIGKDDInternationalConferenceonKnowledgeDiscovery&DataMining,pages1677–1687,
2020.
[2] Feng-hsiungHsu. Ibm’sdeepbluechessgrandmasterchips. IEEEmicro,19(2):70–81,1999.
[3] WilliamClark,JanGolinski,andSimonSchaffer. ThesciencesinenlightenedEurope. Univer-
sityofChicagoPress,1999.
[4] FredericFriedel. Reconstructingturing’s"papermachine".
[5] ClaudeE.Shannon. Amathematicaltheoryofcommunication. BellSyst.Tech.J.,27:623–656,
1948.
[6] TordRomstad,MarcoCostalba,JoonaKiiski,andetal. Stockfish. stockfishchess.org,2023.
Accessed: 2024-01-05.
[7] DavidSilver,AjaHuang,ChrisJMaddison,ArthurGuez,LaurentSifre,GeorgeVanDenDriess-
che,JulianSchrittwieser,IoannisAntonoglou,VedaPanneershelvam,MarcLanctot,etal. Mas-
teringthegameofgowithdeepneuralnetworksandtreesearch. nature,529(7587):484–489,
2016.
[8] XidongFeng,YichengLuo,ZiyanWang,HongruiTang,MengyueYang,KunShao,David
Mguni,YaliDu,andJunWang. Chessgpt: Bridgingpolicylearningandlanguagemodeling.
arXivpreprintarXiv:2306.09200,2023.
[9] Feng-HsiungHsu. BehindDeepBlue: Buildingthecomputerthatdefeatedtheworldchess
champion. PrincetonUniversityPress,2002.
[10] DavidSilver,ThomasHubert,JulianSchrittwieser,IoannisAntonoglou,MatthewLai,Arthur
Guez,MarcLanctot,LaurentSifre,DharshanKumaran,ThoreGraepel,etal. Masteringchess
andshogibyself-playwithageneralreinforcementlearningalgorithm. arXiv,2017.
[11] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanNGomez,
ŁukaszKaiser,andIlliaPolosukhin. Attentionisallyouneed. Advancesinneuralinformation
processingsystems,30,2017.
[12] TomBrown,BenjaminMann,NickRyder,MelanieSubbiah,JaredDKaplan,PrafullaDhariwal,
ArvindNeelakantan,PranavShyam,GirishSastry,AmandaAskell,etal. Languagemodelsare
few-shotlearners. Advancesinneuralinformationprocessingsystems,33:1877–1901,2020.
[13] HugoTouvron,LouisMartin,KevinStone,PeterAlbert,AmjadAlmahairi,YasmineBabaei,
NikolayBashlykov,SoumyaBatra,PrajjwalBhargava,ShrutiBhosale,etal. Llama2: Open
foundationandfine-tunedchatmodels. arXivpreprintarXiv:2307.09288,2023.
[14] TakeshiKojima,ShixiangShaneGu,MachelReid,YutakaMatsuo,andYusukeIwasawa. Large
languagemodelsarezero-shotreasoners. Advancesinneuralinformationprocessingsystems,
35:22199–22213,2022.
[15] QingyunWu,GaganBansal,JieyuZhang,YiranWu,ShaokunZhang,ErkangZhu,BeibinLi,
LiJiang,XiaoyunZhang,andChiWang. Autogen: Enablingnext-genllmapplicationsvia
multi-agentconversationframework. arXivpreprintarXiv:2308.08155,2023.
[16] MaxHager. LLMChess.
[17] NicholasCarlini. carlini/chess-llm.
[18] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid,
Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adrià Garriga-Alonso, et al.
Beyondtheimitationgame: Quantifyingandextrapolatingthecapabilitiesoflanguagemodels.
arXivpreprintarXiv:2206.04615,2022.
[19] AndrewLee,DavidWu,EmilyDinan,andMikeLewis. Improvingchesscommentariesby
combininglanguagemodelswithsymbolicreasoningengines.arXivpreprintarXiv:2212.08195,
2022.
[20] DavidNoever, MattCiolino, andJoshKalin. Thechesstransformer: Masteringplayusing
generativelanguagemodels. arXivpreprintarXiv:2008.04057,2020.
14[21] ThomasMcGrath,AndreiKapishnikov,NenadTomašev,AdamPearce,MartinWattenberg,
DemisHassabis,BeenKim,UlrichPaquet,andVladimirKramnik. Acquisitionofchessknowl-
edgeinalphazero. ProceedingsoftheNationalAcademyofSciences,119(47):e2206625119,
2022.
[22] LisaSchut,NenadTomasev,TomMcGrath,DemisHassabis,UlrichPaquet,andBeenKim.
Bridgingthehuman-aiknowledgegap: Conceptdiscoveryandtransferinalphazero. arXiv
preprintarXiv:2310.16410,2023.
[23] ReidMcIlroy-Young,YuWang,SiddharthaSen,JonKleinberg,andAshtonAnderson.Detecting
individualdecision-makingstyle:Exploringbehavioralstylometryinchess. AdvancesinNeural
InformationProcessingSystems,34:24482–24497,2021.
[24] ReidMcIlroy-Young, RussellWang, SiddharthaSen, JonKleinberg, andAshtonAnderson.
Learningmodelsofindividualbehaviorinchess. InProceedingsofthe28thACMSIGKDD
ConferenceonKnowledgeDiscoveryandDataMining,pages1253–1263,2022.
[25] AthulPaulJacob,DavidJWu,GabrieleFarina,AdamLerer,HengyuanHu,AntonBakhtin,Ja-
cobAndreas,andNoamBrown. Modelingstrongandhuman-likegameplaywithkl-regularized
search. InInternationalConferenceonMachineLearning,pages9695–9728.PMLR,2022.
[26] MichaelLLittman. Markovgamesasaframeworkformulti-agentreinforcementlearning. In
Machinelearningproceedings1994,pages157–163.Elsevier,1994.
[27] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun. Deepresiduallearningforimage
recognition. InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition,
pages770–778,2016.
[28] AlexeyDosovitskiy,LucasBeyer,AlexanderKolesnikov,DirkWeissenborn,XiaohuaZhai,
ThomasUnterthiner,MostafaDehghani,MatthiasMinderer,GeorgHeigold,SylvainGelly,etal.
Animageisworth16x16words: Transformersforimagerecognitionatscale. arXivpreprint
arXiv:2010.11929,2020.
[29] ThibaultDuplessis. Weeklyrapidratingdistribution•lichess.org.
[30] ReidMcIlroy-Young,JonKleinberg,SiddharthaSen,SolonBarocas,andAshtonAnderson.
Mimetic models: Ethical implications of ai that acts like you. In Proceedings of the 2022
AAAI/ACMConferenceonAI,Ethics,andSociety(AIES’22),2022.
15Position Encoder Skill Level Encoder
Skill-Aware Attention
...
Feed Forward
Query
ResNet Backbone
Skill-Aware Query
Conv2D( , ) Value
Shortcut
Key Multi-head Self-attention
Conv2D( , )
Feed Forward
Conv2D( , )
Conv2D( , )
Pooling & Feed Forward
...
Move Head Auxiliary Head Value Head
Maia 1100 Maia 1300 Maia 1500 Maia 1700 Maia 1900
✅ ❌ ❌ ❌ ✅
Stronger Players
Mate-in-1 Puzzle
of rating 1500
1100 1300 1500 1700 1900
❌ ❌ ✅ ✅ ✅
Maia-2 with Increasing Player's Skill Levels
Figure6: Maia-2andMaiasolvingaMate-in-1chesspuzzleofrating1500. Greenarrowsrepresent
correctmovepredictions,whileredarrowsindicateincorrectpredictions. Thedarknessofthegreen
colorcorrelateswiththemodel’sconfidence,withdarkerarrowsdenotingahigherprobabilityof
makingthecorrectmove.
Maia 1100 Maia 1500 Maia 1900
48.0 47.5 47.3 46.1 51.3 51.4 51.5 50.4 51.152.052.552.9 55 49.2 48.4 48.8 48.1 47.5 52.1 51.8 52.6 52.1 51.8 51.151.552.852.953.3
54
49.5 49.3 49.0 49.1 48.4 47.8 51.4 52.1 52.1 52.9 52.5 51.9 49.451.251.652.953.054.0
50.1 50.0 49.9 49.8 49.2 48.7 48.6 51.1 51.7 52.5 52.8 52.9 52.6 52.5 49.049.951.452.052.753.554.4 53 50.4 50.8 50.6 50.4 50.1 50.1 49.6 50.3 51.5 52.4 53.0 53.0 53.6 53.4 47.849.550.951.652.253.354.2 52
51.0 50.9 51.5 50.9 51.0 50.7 50.8 50.3 51.1 52.5 52.4 53.2 53.5 53.9 47.548.350.450.551.852.953.9 51
50.2 50.5 51.5 51.6 51.5 51.5 51.4 48.8 49.9 51.8 52.6 52.9 53.4 53.9 46.247.349.650.350.752.053.0 50
50.5 51.9 51.6 52.0 50.8 51.8 49.3 51.5 51.9 52.7 51.7 53.7 46.348.749.250.349.852.3 49
51.5 51.9 52.2 52.2 50.6 50.3 51.3 52.2 52.6 51.1 47.748.449.450.249.0 48
51.6 51.8 52.0 52.8 50.2 51.1 51.5 52.7 47.348.348.850.2
47
Maia Avg Maia Best Maia-2
50.1 50.3 50.4 49.8 51.3 52.0 52.5 52.9 52.453.153.853.6 55 50.8 50.6 51.4 51.0 50.8 52.1 51.8 52.8 52.9 53.3 52.753.354.254.254.3
54
50.1 50.9 50.9 51.6 51.3 51.2 51.4 52.1 52.1 52.9 53.0 54.0 51.553.053.254.354.555.0
50.1 50.5 51.3 51.5 51.6 51.6 51.9 51.1 51.7 52.5 52.8 52.9 53.5 54.4 51.652.253.453.854.454.955.7 53 49.5 50.6 51.3 51.7 51.8 52.4 52.4 50.4 51.5 52.4 53.0 53.0 53.6 54.2 51.152.153.153.754.255.255.6 52
49.6 50.1 51.5 51.3 52.0 52.4 52.9 51.0 51.1 52.5 52.4 53.2 53.5 53.9 51.151.553.453.154.054.855.6 51
48.4 49.2 51.0 51.5 51.7 52.3 52.8 50.2 50.5 51.8 52.6 52.9 53.4 53.9 50.050.652.853.453.354.555.1 50
48.7 50.7 50.9 51.7 50.8 52.6 50.5 51.9 51.9 52.7 51.7 53.7 50.252.252.653.452.354.8 49
49.8 50.5 51.3 51.7 50.2 51.5 51.9 52.2 52.6 51.1 51.452.052.953.352.2 48
49.7 50.4 50.8 51.9 51.6 51.8 52.0 52.8 51.252.152.453.9
47
1200 1600 2000 1200 1600 2000 1200 1600 2000
Active Player's Skill Level Active Player's Skill Level Active Player's Skill Level
Figure7: Movepredictionaccuracyacrossdiverseskilllevels. Colorsrepresentperformance,with
warmertonesindicatinghigheraccuracy. Missingskillcombinationsweretooraretobestatistically
reliable.
A MoreExperimentalResults
Casestudy: Smoothness. WeevaluatethesmoothnessofMaia-1andMaia-2byacasestudyin
puzzlesolving: aMate-in-1puzzleof1500skilllevelispresentedtobothMaia-1andMaia-2,where
smoothnesscanbeevaluatedbycheckingwhetherthepredictionsaremonotonicandtransitionalas
skilllevelincreases. Callamodel’streatmentofapositionasmonotonicifthepredictedprobability
ofthecorrectmoveincreaseswithskillmonotonically,wecanobservefromFigure6thattheMaia-2
predictedprobabilitiesofthebestmove(ingreenarrows)increasemonotonicallyfrom0.22to0.45
astheskilllevelsrisefrom1100to1900,whileMaia-1predictionsareratherturbulent. Similarly,we
callamodel’streatmentofapositiontransitionalifitpredictsasuboptimalmoveforsomeprefixof
skillsandthentransitionstoanoptimalmoveforallsubsequentskilllevels. AsshowninFigure6,
Maia-2canmimicweakerplayerstowhomthepuzzleishardtosolve,whilestrongerMaia-2with
skilllevelconfiguredaboveorequalto1500cansuccessfullysolvethepuzzle. However,Maia1100
surprisinglysolvedthepuzzle,whilethestrongerMaia-1models,e.g.,Maia1700failedtomake
theoptimalmove. Therefore,intheconsideredcase,asopposedtoMaia-1,Maia-2yieldssmooth
predictionsprovidedthatitstreatmentofthispositionismonotonicandtransitional.
16
leveL
llikS
s'reyalP
tnenoppO
leveL
llikS
s'reyalP
tnenoppO
0002
0061
0021
0002
0061
0021
Channel-wise
Patching
ycaruccA
noitciderP
evoM
ycaruccA
noitciderP
evoM75
Average Blunder Rate
0.16
Average Centipawn Loss
70
0.14
65
0.12
60
0.10
55
0.08
50
1200 1600 2000
Player's Skill Level
Figure8: QualityofpredictedmovesquantifiedbyblunderrateandcentipawnLoss.
Qualityofpredictedmoves. Giventhesamechesspositionbutincreasingskilllevels,acoherent,
skill-aware human move prediction model should make progressively higher-quality moves. We
measuretheaveragecentipawnloss(astandardmovequalitymetric,thelowerthebetter)andthe
average blunder rate (fraction of times an egregious mistake is predicted) in positions randomly
sampledfromDecember2023games. Thecentipawnlossisdeterminedbycomparingthemoves
predictedbyMaia-2againstthetopmoveasevaluatedbyStockfishatdepth20(humangrandmaster-
levelplay),whileblundersareclassifiedasmovesresultinginawin-ratelossof10%ormore. As
showninFigure8,boththecentipawnlossandtheblunderrateexhibitasmooth,monotonicdecrease
asplayerskillrises,demonstratingMaia-2’scapabilityofadjustingitspredictionscoherentlytoalign
withtheincreasinglyskilledplayers.
Valuehead. Asaproxyofmodelevaluationgivenaboardposition,wetrainthemodelvaluehead
whichispotentiallysignificantforawidevarietyofdownstreamtasks. Thevalueheadistrainedasa
regressiontaskfrom-1to1indicatingfromlosingtowinningpositions,andfinallynormalizedtoa
continuousvaluebetween0and1similartoAlphaZero. Thecorrectlabelforvalueheadistheactual
gameresults. Tochecktheevaluationqualityofourmodelvaluehead,wecalibratethevaluehead
resultswithactualgameoutcomes,andgenerateaquantile-quantileplotinFigure9wherethewin
probabilityisdiscretizeduniformlyinto100binsfrom0to1.
1.0
0.8
0.6
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0
Predicted Win Probability
Figure9: ValueheadQ-Qplot.
17
etaR
rednulB
egarevA
ytilibaborP
niW
laciripmE
ssoL
nwapitneC
egarevAend_game_evaluation end_game_piece_value
1.0 1.0
0.9 0.9
0.8 0.8
0.7 0.7
0.6 0.6
0.5 Pre Skill-Aware Attention 0.5 Pre Skill-Aware Attention
Post Skill-Aware Attention Post Skill-Aware Attention
0.4 0.4
1200 1600 2000 1200 1600 2000
Player Skill Level Player Skill Level
(a) SSSSkkkkiiiillllllll DDDDeeeeppppeeeennnnddddeeeennnntttt CCCCoooonnnncccceeeeppppttttssss (b)
has_bishop_pair_opponent capture_possible_on_d3_active
0.68 0.65
Pre Skill-Aware Attention Pre Skill-Aware Attention
0.67 Post Skill-Aware Attention Post Skill-Aware Attention
0.60
0.66
0.65 0.55
0.64
0.50
0.63
0.62 0.45
1200 1600 2000 1200 1600 2000
Player Skill Level Player Skill Level
(c) SSSSkkkkiiiillllllll IIIInnnnddddeeeeppppeeeennnnddddeeeennnntttt CCCCoooonnnncccceeeeppppttttssss (d)
Figure10: Maia-2’schessconceptrecognitionasafunctionofskilllevel, asmeasuredbylinear
activationprobesrightbefore(blue)andafter(orange)skill-awareattention. (A)Stockfishoverall
boardevaluationforend-gamepositions. (B)Stockfishevaluationofend-gamebonusesandpenalties
topiecesforwhite. (C)Doestheopponentplayerowntwobishops? (D)Iscapturepossibleonsquare
d3fortheactiveplayer?
70
Maia 1900
Maia 1500
60
Maia 1100
Maia-2
50
40
30
20
10
0.00 0.05 0.10 0.15 0.20 0.25
Win-rate Loss
Figure11: Movepredictionaccuracyasafunctionofmovequality,quantifiedbywin-rateloss.
18
ycaruccA
ycaruccA
noitciderP
evoM
ycaruccA
ycaruccA
ycaruccAAccuracyasafunctionofmovequality. Figure11showsthemovepredictionaccuracyonthe
Grounded Testset as a function of move quality, measured by win-rate loss, which is calculated
following the same procedures as prior studies [1, 24]. All models generally decrease in their
ability to predict worse moves, since humans are generally trying to avoid mistakes, and high-
qualitymovesaremorecertainwhereaslower-qualitymovescanbemorerandomandthushard
topredict. Nevertheless,Maia-2outperformsallversionsofMaiaacrossmostofthemovequality
range,demonstratingtheeffectivenessofourunifiedmodelingapproachforhumanmoveprediction.
Maia-2’soverallgainsarenotconstrainedtoanyspecificmovequalitytype,butarespreadacrossthe
entirerange.
B Reproductibility
Table5: HyperparameterSettings.
#GamesperchunkN 20000
chunk
#MaximumgamesperskilllevelN 20
range
Initiallearningrate 1e−4
Weightdecay 1e−5
Batchsize(positions) 8192
Minimummoveply 10
Maximummoveply 300
Remainingsecondsthreshold 30
#BackboneblocksK 12
Conv
#AttentionblockK 2
Att
#InputchannelsC 18
input
#IntermediatechannelsC 256
mid
#EncodedchannelsC 8
patch
Skilllevelembeddingdimensiond 128
s
Attentionheaddimensiond 64
h
Attentionintermediatedimensiond 1024
att
#Attentionheadsh 16
Table6: StatisticsoftheMaia-1Testset.
#Positions RatingRange
Total 106,740 -
Skilled 56,812 <1599
Advanced 41,747 1600-1999
Master 8,181 ≥2000
Table7: Statisticsoftrainingdatasets.
Maia-2 Maia-2
subset
#GamesConsumed 930.19M 5.14B
#GamesTrained 21.31M 168.93M
#PositionsTrained 1.18B 9.15B
Implementation details. To maintain a consistent perspective from both sides of players, we
implemented board flipping to train and test Maia-2; that is, positions with black to move were
mirrored such that all analyses could be conducted from the white side’s viewpoint. We further
refinedourdatasetthroughgameandpositionfiltering,selectingonlyrapidgamesfromLichesswith
availableclockinformationanddisregardingtheinitial10plysofeachgameaswellaspositions
whereeitherplayerhadlessthanthirtysecondsremaining. Thefiltrationissignificanttoeliminatethe
noiseintroducedbyrusheddecisionsundertimeconstraints,whichcouldskewthetruerepresentation
ofaplayer’sskill. Thechoiceofexclusiverapidgamesisalsoinformedbythedistinctratingsystems
19acrossdifferentgametypes,whichnecessitatestheseparationofdatatomaintainratingconsistency.
WereportallhyperparametersinvolvedintrainingMaia-2inTable5.
Chesspositionrepresentation. Wefollowthewell-establishedpriorworks[10,1]torepresentchess
positionsasmulti-channel8×8matrices,including:
• PieceRepresentation: Thefirst12channelscategorizetheboard’spiecesbytypeandcolor,
withonechanneleachforwhiteandblackPawns,Knights,Bishops,Rooks,Queens,and
Kings. Acellismarked1todenotethepresenceofapieceinthecorrespondinglocation,
and0otherwise.
• Player’sTurn: Asinglechannel(the13th)indicatesthecurrentplayer’sturn,filledentirely
with1sforwhiteand0sforblack,providingthemodelwithcontextonwhosemoveisbeing
evaluated.
• CastlingRights: Fourchannels(14thto17th)encodethecastlingrightsforbothplayers,
withtheentirechannelsetto1iftherightisavailableor0otherwise.
• EnPassantTarget:Thefinalchannel(18th)marksthesquareavailableforenpassantcapture,
ifany,with1and0selsewhere.
Chess concepts probing. Given a board position, we vary the skill level injected to Maia-2 to
extracttheP
encoded
∈RCpatch×8×8asthelearnedrespresentationoftheResNet-basedbackboneserved
as the control group which remain constant to varying skill ratings, and the output hidden states
P ∈ RCpatch×datt afterskill-awareattentiondirectlyconnectedtomodelheads. Werandomlypick
500,000positionsfromLichessDecember2023databaseandcalculateStockfishbuilt-inorcustom
implementedconceptsusingtheForsyth-EdwardsNotationofthepositions.
We carefully choose P and P as internal representations for the reason that P is the
encoded encoded
comprehensive understanding of chess board for the backbone network right before skill-aware
attention, and P is the final hidden states that directly influence model decision and evaluation.
FollowingtheworkofAlphazeroconceptprobing [21],forchessconceptswithcontinuousvalues
wetrainLassoregressorswithcoefficientforL1-regularizationselectedby5-foldcross-validation,
and for binary concepts we train logistic regressors with downsampling. During evaluation on
unbalancedtestset,wemeasuretheperformanceofcontinuous-valuedprobeswiththecoefficientof
determinationr2,andscorethebinary-valuedprobeswiththeMacroF1.
Table8: StatisticsoftheCross-skillTestset.
Active
Opponent 1100-1199 1200-1299 1300-1399 1400-1499 1500-1599 1600-1699 1700-1799 1800-1899 ≥2000
≥2000 - - - - - 91,264 100,000 100,000 100,000
1800-1899 - - - - 83,337 99,931 100,000 100,000 100,000
1700-1799 - - - 91,054 100,000 100,000 100,000 100,000 100,000
1600-1699 - - 81,386 99,998 100,000 100,000 100,000 99,933 91,610
1500-1599 - 82,059 99,500 100,000 100,000 100,000 99,974 83,650 -
1400-1499 89,666 100,000 100,000 100,000 100,000 100,000 91,291 - -
1300-1399 97,602 100,000 100,000 100,000 99,544 81,692 - - -
1200-1299 100,000 100,000 100,000 100,000 82,230 - - - -
1100-1199 100,000 100,000 97,635 89,643 - - - - -
Table9: NumberofgamesinthebalanceddatasetusedfortrainingMaia-2 .
subset
White
Black <1100 1100-1199 1200-1299 1300-1399 1400-1499 1500-1599 1600-1699 1700-1799 1800-1899 1900-1999 >=2000
<1100 583,437 - - - - - - - - - -
1100-1199 583,403 583,433 - - - - - - - - -
1200-1299 427,160 583,402 583,443 - - - - - - - -
1300-1399 176,930 408,819 583,421 583,443 - - - - - - -
1400-1499 113,683 204,425 499,185 583,433 583,445 - - - - - -
1500-1599 101,756 139,741 307,446 559,722 583,440 583,439 - - - - -
1600-1699 57,381 85,483 174,417 384,670 566,851 583,436 583,435 - - - -
1700-1799 32,621 47,671 100,841 188,967 359,056 571,666 583,421 583,428 - - -
1800-1899 16,656 26,195 52,043 105,095 178,957 348,979 557,921 583,415 583,422 - -
1900-1999 8,032 11,736 23,800 48,965 84,808 150,182 272,451 529,071 583,388 582,715 -
>2000 5,927 7,953 14,825 28,929 49,237 88,317 134,432 280,452 531,162 582,993 582,542
20Table10: NumberofgamesinthebalanceddatasetusedfortrainingMaia-2.
White
Black <1100 1100-1199 1200-1299 1300-1399 1400-1499 1500-1599 1600-1699 1700-1799 1800-1899 1900-1999 >=2000
<1100 4,698,087 - - - - - - - - - -
1100-1199 4,697,937 4,697,979 - - - - - - - - -
1200-1299 3,165,114 4,697,972 4,698,076 - - - - - - - -
1300-1399 2,015,110 2,561,344 4,698,015 4,698,073 - - - - - - -
1400-1499 1,509,456 1,549,218 3,008,520 4,698,033 4,698,093 - - - - - -
1500-1599 1,259,824 1,402,474 2,348,863 3,895,270 4,698,047 4,698,106 - - - - -
1600-1699 627,583 780,364 1,415,147 2,257,063 3,514,829 4,698,065 4,698,092 - - - -
1700-1799 419,889 408,444 891,818 1,499,773 2,228,952 3,999,818 4,698,035 4,698,088 - - -
1800-1899 281,902 286,769 447,341 893,978 1,468,987 2,439,832 3,665,572 4,698,000 4,698,059 - -
1900-1999 190,385 171,133 272,258 448,351 818,918 1,452,505 1,940,287 3,486,275 4,697,958 4,697,311 -
>2000 228,477 186,001 277,431 423,692 651,232 1,206,468 1,718,683 2,587,573 3,967,891 4,697,533 4,697,178
21