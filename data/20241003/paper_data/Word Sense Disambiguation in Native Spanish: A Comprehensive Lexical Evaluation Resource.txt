Word Sense Disambiguation in Native Spanish:
A Comprehensive Lexical Evaluation Resource
PabloOrtega,JordiLuque, LuisLamiable,RodrigoLo´pez, RichardBenjamins
Telefo´nicaInnovacio´nDigital,Research, Spain
jordi.luque@telefonica.com
Abstract togetherwithsomeparallelcorpusannotatedwithsenses, like
MultiSemCorandBabel,justmultilingualversionsofWordNet.
Human language, while aimed at conveying meaning, in-
Nonethelesstheysufferbytheuseofsemi-automaticmethods
herentlycarriesambiguity. Itposeschallengesforspeechand
for dataharvesting [4], non-accurate automatictranslations or
language processing, but also serves crucial communicative
bythesemi-automaticvalidationofthewordsensesandgran-
functions. Efficientlysolve ambiguity isboth a desired and a
ularity[5]. Adrawbackstemmingfromthefactthateverylan-
necessarycharacteristic.Thelexicalmeaningofawordincon-
guageisinherentlysubjecttochangeandinterpretationwhich
text can be determined automatically by Word Sense Disam-
undoubtedly requires a native speaker validation and a high
biguation(WSD)algorithmsthatrelyonexternalknowledgeof-
levelofexpertise.
tenlimitedandbiasedtowardEnglish. Whenadaptingcontent
However,asmentionedinapreviousstudy[3],allofthese
tootherlanguages, automatedtranslationsarefrequentlyinac-
inventoriesencounterachallengeknownasthefine-granularity
curateandahighdegreeofexperthumanvalidationisnecessary
problem.Thisissueariseswhendistinguishingbetweenvarious
toensurebothaccuracyandunderstanding. Thecurrentstudy
meaningsofthesamewordbecomeschallenging,evenforhu-
addresses previous limitations by introducing a new resource
mans. Forinstance,WordNetlists29sensesforthenounline,
for Spanish WSD. It includes a sense inventory and a lexical
including two that differentiate between a set of horizontally
dataset sourced from the Diccionario de la Lengua Espan˜ola
laidout things and one laidout vertically. To address theex-
whichismaintainedbytheRealAcademiaEspan˜ola. Wealso
cessivegranularity,coarser-grainedinventorieshavebeensug-
reviewcurrentresourcesforSpanishandreportmetricsonthem
gested,butmainlyperformedontheEnglishlanguagewithfew
byastate-of-the-artsystem.
extensions to other main languages, such as French, German,
IndexTerms:wordsensedisambiguation,wordsensediscrim-
Italian and Spanish. Moreover, the meanings of non-English
ination,WSD,lexicalsemantics,sensedataset,senseinventory
words are translated from English, ignoring many of the nu-
ancesofdifferentsensesinspecificsituations.
1. Introduction
The Spanish language has several specific characteristics
The goal of language is the communication of meaning but thatjustifiesadeeperlookinrelationtoWSD.Itisspokenby
thehumanlanguageisinherentlyambiguous,withuncertainty almost 600 million1 people in the world of which about 100
broughtonbypragmatic,syntacticandlexicalfactors. Aterm millionarenon-nativespeakers. Adistinguishingfactorofthe
becomeslexicallyambiguouswhenithasseveralmeanings.For Spanishlanguage,comparedtomostotherlanguages,isthatit
instance, the Spanish term ”banco” can be used to describe isaglobally“regulated”languagewithrespectforlocalvaria-
both a financial organization and a bench in a public space. tions. TheSpanishRoyalLanguageAcademy(RealAcademia
If the intended meaning cannot be determined from the con- Espan˜ola, RAE2) isa300-year-oldInstitutionthat, incollab-
text, this form of ambiguity may cause misunderstanding and oration withall local Spanish language academies, isactively
misinterpretation. InthefieldofNaturalLanguageProcessing monitoring andmanaging theSpanishlanguage inallitsgeo-
(NLP),thedifficulttaskofcomputationallydeterminingtheap- graphicalregions.Themainmaterialisationofthisworkarethe
propriate meaning of a word in a particular context is known official dictionary of Spanish language DLE, with more than
asword sense disambiguation (WSD).Theabilitytonavigate 94,000entries,30%morethanothercommercial Spanishdic-
and resolve ambiguity is crucial for successful computational tionaries, and an average of 2.5 meanings per entry and the
systems. Despite the intended lexical meaning of a word in Student´s Dictionary in Spanish (SDS) a lexicographic work
context can be, to some extend, determined automatically by specially designed for students of Spanish. The wide usage
WSDalgorithms,unfortunately,externalknowledgelikeapre- ofSpanishacrosstheworld,combinedwiththenormativeap-
defined senseinventory isafundamental component forthese proachforitsevolution,clearlyjustifiesaSpanish-specificap-
algorithms. It provides the essential data to associate senses proachforWSD.
withwords,andusuallyisascarceresource,mainlyinEnglish, Among the contributions in this work, we provide a new
anissueknownastheknownledgeacquisitionbottleneck[1]. lexiconresourceforWSDinnative-Spanish. Furthermore,we
The NLP community tends to maintain the working as- provide a comprehensive review of the existing resources and
sumptionthatwordmeaningcanbediscretizedinafinitenum- approaches to Spanish WSD and a specific approach by fine-
berofclasses[2],thuscastingpolysemyresolutionasamulti- tuning BERTand RoBERTabased models, by using different
classclassificationproblem,wheretheclasses,e.g. thesenses combinationsofSpanishWSDresources.Finally,wereportthe
are specific to a word. Senses are registered in a dictionary
likeresourcecalledthesenseinventory. InWSDthesensein- 1https://www.ethnologue.com/language/spa/
ventoryisvirtuallyalwaysThePrincetonWordNet(WNG)[3] 2https://www.rae.es/
4202
peS
03
]LC.sc[
1v42502.9042:viXraperformance metrics on the most popular benchmarks and on nations. In their experiments they train UKB, a graph based
thenewevaluationresourceinnativeSpanish. Theevalutation system [8], achieving remarkable performance when combin-
dataset3 andthefinalsystemsareprovided,asaresourcepub- ingwithvariousLexicalKnowledgeBases(LKBs).Finally,we
liclyaccessibleinHuggingface4. Themodels’performanceis found mBERT-UNI[15], a supervised model and knowledge-
abletoeitherachieveorsurpassstate-of-the-artresultsattained based.Itisasupervisedframeworkincorporatingalexicaluni-
by most of the supervised neural approaches on the Spanish fiedrepresentationspaceformultilingualWSD.
WSD task. This demonstrates the advantages of incorporat-
inglexicalknowledge,specificallyexpertvalidatedsensesand
3. Resources forWSD
glosses,infine-tuningneuralmodelsforWSD.
2. RelatedWork TheeffectiveexecutionofWSDalgorithmsheavilyrelyonthe
availabilityandqualityofresourceslikeLKBs. Inthissection,
Early WSD experiments included manually crafted lexicons wedelve intothemost popular resources that have driventhe
and rules [6]. But as this field’s study has advanced, more WSDtask.
complex answershavebeen put forth. Therearedifferent ap-
proachesintheliteraturetotackleWSD,includingsupervised
methods,unsupervisedmethodsandknowledgeorgraph-based 3.1. SenseInventories
methods[3].
Supervisedmethodsuselabeledtrainingdata,e.g.,setsof The sense inventories list the various meanings a word may
encoded examples together with their sense classes or labels, have.Themostpopularare:
to learn a classifier that can predict the correct meaning of a
word in context assigning, e.g., by maximizing the similar- • Wordnet[16]isalargelexicaldatabasewithover120kcon-
ity to a single meaning like a single-label classification prob- ceptsthatarerelatedbyover25typesofsemanticrelations
lem or as a soft multi-label classification problem in which andcompriseover155kwords(lemmas),fromthecategories
multiple senses can be assigned to each target word [7]. On Noun,Verb,AdjectiveandAdverb. Itorganizesconceptsin
the other hand, unsupervised methods are based on unlabeled synsets–setsofsynonyms–andprovides,foreachofthem,
corpora and do not exploit any manually sense-tagged corpus oneormoresentencesinwhicheachoneisusedwitheach
to assign senses to words in context, e.g., based on their co- meaning.
occurrencepatterns[6].Finally,knowledge-basedmethods[8], • Babelnet [17] is a multilingual semantic network with the
assign senses to words based on their semantic relationships, principal objective of functioning as an extensive ”ency-
relying on external resources such as Machine-readable dic- clopedic dictionary”. Its initial iteration was primarily fo-
tionaries (MRDs), like as WordNet [3], or other structured or cusedonautomaticallylinkingWikipediaarticlesandWord-
non-structured knowledge sources like Sense-Annotated Cor- Net senses. However, the current iteration, BabelNet 5.0,
pora,SemCor[9],amongothers. Supervisedsystems,particu- hasconsiderablyexpandeditsknowledgeacquisitionscope,
larlythosebasedonTransformer-basedlanguagemodels,have drawinginsightsfrom51distinctsources.
become the standard approach for WSD [10]. These systems
leveragelarge-scalepre-trainedmodelstolearncontextualrep-
3.2. Sense-AnnotatedData
resentationsofwordsandtheirsenses,whichcanthenbeused
fordisambiguation.
AlthoughthereisnomodelexclusivelydevelopedforSpan- The resources for WSD in languages other than English are
ish, there are several multilingual models capable of disam- muchmorelimited. Wefocusprimarilyonthemostprominent
biguatingSpanishtexts.Amongthesemodelswefoundmainly multilingualdatasetsandpresenttwonewSpanishresources.
both supervised and knowledge-based methods. In the super-
visedcategory,weencounteredsystemssuchasAMuSE-WSD
3.2.1. TrainingData
[11] or Multimirror [12]. The former was the first approach
toframetheWSDtaskasdown-streamtask,usingmulti-class
• SemCor[9]isthelargestmanuallysense-annotatedEnglish
classificationandofferingamultilingualWSDsystembuilton
corpora,isasignificantresourcefortrainingsupervisedWord
topofmodernpre-trainedlanguagemodel. Incontrast,Multi-
SenseDisambiguation systems. Itconsists of over 226,000
mirror [12] is an approach that addresses the data scarcity is-
senseannotationsacross352documents.
sueinatargetlanguagebyproposingacross-lingualsensepro-
jection approach. It involves aligning parallel sentences from • MuLaN [18]is a specialized tool for WSD, which can au-
Englishtoatargetlanguageforaugmentingthelow-resourced tomaticallycreatesense-taggedtrainingdatasetsinmultiple
language. languages. WhatdistinguishesMuLaNisitsextensiverange
Ontheotherhand,wealsoencounteredafewmultilingual ofsensecategories,achievedthroughitsintegrationwiththe
knowledge-basedsystems. FirstamongthemisSensEmBERT BabelNetinventory,incontrasttoSemCor,whichexclusively
[13], where the authors create latent representations of word depends onWordNetinventory. Thedatasetincludes trans-
meaningsandglossesinvariouslanguages, byusingsentence lationsinfourdistinctlanguages: German,Spanish,French,
embeddings from a multilingual mBERT model and compar- andItalian.
ing distances with candidate meanings. Additionally, there is • SDS5theStudent´sDictionaryinSpanishisalexicographic
theworkreportedin[14],thatintroducesSyntagNetaresource workspeciallydesigned forstudentsof Spanish. Itiscom-
made up of manually disambiguated lexical-semantic combi- posedofaround40Ktermsandiselaboratedtakingintoac-
counttextandreferencebooksemployedintheeducational
3Removedduetoanonymisationreasons. systemsofSpainandAmerica. Thisresourceisavailablein
4Removedduetoanonymisationreasons. bothprintedformandasamobileapplication.Set Instances WT WAP IAP PM DLEval sentence example and meaning tags and
glosses
SE13-wn 1260 541 4.20 5.52 421 Sietetazasdecaldo
SE15-wn 1043 507 6.17 6.99 446 Taza#NOUN:A183451A121616
A22450A139788
Table 1: Comparison between SemEval-2013 and SemEval-
A139788:Recepta´culodelretrete.
2015inthewnsplit.HereitisshowedtheamountofInstances,
A121616:Cantidadquecabeenunataza.
WordTypes(WT),WordAveragePolysemy(WAP),InstanceAv-
XMLexample
eragePolysemy(IAP),PolysemousWords(PW).
<sentenceid=”d001.s10699”>
<wflemma=”siete”pos=”ADJ”>Siete</wf>
Set Instances SW MW Entities MSI MSL <instance id=”d001.s10699.t0001” lemma=”taza”
pos=”NOUN”>tazas</instance>
SE13 1481 1103 129 249 1.15 1.19 <wflemma=”de”pos=”ADP”>de</wf>
SE15 1239 1088 67 84 6.8 6.8 <wflemma=”caldo”pos=”NOUN”>caldo</wf>
DLEval 12269 12269 0 0 1.67 1.67
</sentence>
SDS 46224 46224 0 0 2.78 2.78 Goldfile
d001.s10699.t0001A121616
Table 2: Comparison of Spanish Test Sets between SemEval-
2013, SemEval-2015, DLEvalandSDS. Hereitisshowedthe Table3:DLEvalsentenceexampleandXMLfollowingtheWSD
amount of Instances, Single-words (SW), Multi-words (MW), standard format for the target word ”taza” and four different
Entities,Meansensesperinstance(MSI),andMeansensesper meanings.
lemma(MSL).
alsocontainsasensefromtheWordNet. Thewnsplitisused
forbothevaluationdatasets.Inthetable1wereportthenumber
ofinstances, comprisingatotalof1260and1043samplesfor
3.2.2. EvaluationData
theSE13andSE15,respectively.
• SemEval-2013task12[19]:Thetestsetwasmadeupof13 To create the DLEval evaluation resource we collected,
articlesthatweredrawnfromdatasetsfromtheworkshopson by a web crawling, a subset of the official DLE dictionary
StatisticalMachine Translation. Thearticleswereavailable (see section 3.2.2). It is comprised of m more than 12K tar-
in4differentlanguages,inwhichwecanfindSpanish. The get words w, the set of meanings Sw for each w, Sw =
processofannotationwassuccessfullycarriedoutbyapair sw1,sw2,...,swk, and along with its corresponding set of
ofnativespeakers. glosses Gw = gw1,gw2,...,gwk, which adds the contextu-
• SemEval-2015 task 13 [20]: Isadataset that encompasses alizedinformation. Everyglossdemonstratesthepreciseinter-
bothtypesofinventories,includingnamedentitiesandword pretationofatargetword,providingasentenceexampleforits
senses,withindistinctdomainssuchasbiomedicine,mathe- useandcontextualizingaconcretemeaning.
maticsand computer science, aswell asabroader domain- Finally,forbuildingatestingexampleforclassification,we
focused on social issues. This dataset was meticulously composeitbythelemmaofthetargetword,thelemmatizedtar-
developed in three languages, namely English, Italian, and getglossalongwithfour differentsenses, includingthetarget
Spanish, using parallel texts. The annotations were carried wordsense. FollowingthestandardintheWSDtask,wegen-
out independently and manually by various native or fluent erate a XML filecontaining all lemmatized glosses annotated
speakers. withthePartofSpeech(PoS)information,alongsideagoldfile
• DLE6:TheDiccionariodelaLenguaEspan˜ola,holdssignifi- thatmapsthesenseofeachwordtothetargetlemmawithincor-
respondinggloss. ForthePoStaggingandwordlemmatization
cantvalueasthefundamentalreferencefordefining,spelling,
weusetheFreeling[21]tool.
grammarandproperusageofSpanishwords.Thecreationof
Table 2 reports on the number of extracted instances. In
theDLEistheresultofacollaborativeeffortamongvarious
academies worldwide7, including those from Spain, North ordertopromotetransparency,reproducibilityandthecompari-
sonwithpreviousandfutureWSDapporaches,wewillpublicly
America, Equatorial Guinea, Filipinas and South America
releaseasmallportion oftheDLEeval resourcetogether with
andCentralAmerica.
themodelsandthepythoncodeuponacceptanceofthiswork.
Itsbroadscopeencompassesthelexiconcommonlyutilized
The full DLEeval employed in this work, consists of around
inSpainandacrossSpanish-speakingnations
12,000samples,beingallinstancessingle-words(SW).Itrepre-
4. Experiments and Results sentsarounda20%ofthetotalnumberoflemmasintheofficial
DLEdictionary.Nonetheless,thisnumberrepresentsalmostten
4.1. Constructionofthetrainingandevaluationdatasets timescomparedtotheinstancesavailableinSE13orSE15.
FortheMULANandSemCortrainingdatasetsweusethe
WeusetheSpanishversionsoftheSE13andSE15evaluation
SpanishversionsofMuLaNandSemCorprovidedby[15],con-
datasetsfromthemwsd-datasets8 repositorythatareextracted
tainingthetargetdefinitionorsense, thecontextandtheword
fromtheBabelnetandWordnetinventories,seesection3.1,For
translatedintoSpanish.Forthecompletionoftheclassification
this work, we decide to employ the wn split, which includes
instances, we employ Wordnet to add three additional senses.
asubsetofthoseinstancestaggedwithaBabelNetsynsetthat
Thesedefinitions,originallyinEnglish,aretranslatedusingthe
Googletranslationtool[22].
5https://www.rae.es/obras-academicas/
FortheSDStrainingsetasnapshotofthedictionary,pro-
diccionarios/diccionario-del-estudiante
6https://dle.rae.es/ videdbytheRAE,wasprocessedfollowingthesameapproach
7https://www.asale.org/ as for the DLEeval dataset construction. In this case, given
8https://github.com/SapienzaNLP/mwsd-datasets thedictionary’sextensivewordcountofapproximately40,000Model Dataset SE13 SE15 DLEval algorithm.Thelearningratewassetto2e-5withaweightdecay
of0.01andwithabatchsizeof16andkeptallotherhyperpa-
mBERT-UNI[15] MuLaN 69.68 67.11 - rameters at their default values. We perform model selection
UKB-Graph[14] Syntagnet 73.4 61.2 - choosingthecheckpoint withhighestaccuracyonavalidation
AMuSE-WSD∗[11] SC-WNG 80.0 73.0 - datasetbasedonaccuracy. Notethatfortrainingweusek =4
SensEMBERT[13] SC-BN 74.6 64.1 - senses, including the target sense. For testing we perform as
Multimirror[12] SC-WNG-BN 82.17 70.42 - many testasnecessary toreach thetotalnumber of meanings
ofagiventargetword,andthecandidatesensewiththehighest
SDS 63.71 68.72 73.89
scoreisthepredictedsenseproducedbythesystem.
MuLaN 76.35 74.33 44.01
BETO SemCor(SC) 82.06 77.22 55.48 4.3. Evaluation
MuLaN-SC 78.44 74.91 41.29
SC-SDS 83.83 79.00 73.97 Table 4 displays the results obtained for the BERT and
MuLaN-SDS 74.54 76.13 73.40 RoBERTa models fine-tuned using various combinations of
datasets,aswellastheperformanceofrecentmultilingualap-
SDS 66.00 64.53 72.36
proaches for the Spanish WSD task in the SE13 and SE15
MuLaN 78.47 70.18 42.69
benchmarks. TheSDSdataset offersaremarkably significant
SemCor(SC) 83.24 77.57 53.00
enhancementontheSE15benchmarkovertheprecedingmul-
RoBERTa-base MuLaN-SC 83.87 77.95 48.29
tilingualWSDsystemsinSpanishWSD.Thisimprovementis
SC-SDS 83.48 78.23 70.59
consistentforbothBERTandRoBERTamodels.Insuchacase,
MuLaN-SDS 75.71 76.82 70.50
allSpanishlanguagemodelstrainedwithacombinationinclud-
SDS 65.11 63.35 74.83 ingtheSDSdatasetsurpassedtheMultimirrorsystem,withthe
MuLaN 78.08 75.90 43.80 RoBERTa-largemodelachievingasubstantialimprovementof
SemCor(SC) 81.54 77.30 53.18 +9.5 points in F1-score. For the SE13 benchmark, only the
RoBERTa-large MuLaN-SC 79.50 80.59 53.65 SemCor+SDSdatasetstillsurpassesthebestmultilingualWSD
SC-SDS 82.45 78.96 71.11 systembutwithamoderatedimprovementof+1.6pointsinF1-
MuLaN-SDS 79.60 77.52 78.12 score for the BETOsystem. The improvement in F1-score is
also observed when comparing within each Spanish language
Table4: F1-score(%)comparisonofcurrentSOTAmodelsfor
model. Specifically, the combination of the MuLaN and SC
Multilingual/SpanishWSDagainstpre-trainedSpanishmodels
finetunedwithdifferentdatasets. ∗AMuSE-WSDresultsonfull trainingdatasetsalongwiththeSDStrainingsetyieldstoanim-
provementof+1pointinF1-scoreforbothSE13andSE15.Itis
multilingualdataset.
worthnotingthattheRoBERTa-largemodelisabletoleverage
thepotential of combining MuLaN-SDSbyreporting thebest
words, we were able to extract a total of 46,000 different in-
F1-score,78.12%ontheDLEvalbenchmark.
stanceswithitscorresponding definitionandexamplesofuse.
Inadditiontothethreeoriginaldatasets,MULAN,SemCor(SC) 4.4. Discussion
and SDS, we generated three different combinations of them
Table4 shows the benefit of using a lexicon knowledge man-
aimingtoperformanablationstudyoftheirimportancedepend-
ually curated by experts and Spanish-only trained models, in
ingontheevaluationdata.
comparisontocurrentlymultilingualsystemsfornativeSpanish
4.2. Fine-tuningLargeLanguageModels WSDtask. ThebestresultsobtainedontheDLEvalarethose
reported by themodels fine-tuned employing theSDSdataset
We adopt a similar approach as in [23], treating the task as a
incontrastwiththeresultsfortheSemEvalbenchmarks. Asig-
multi-labelclassificationproblem.Inthissetting,theWSDtask
nificantdisparityofapproximately15-25%wasobservedwhen
consists on disambiguate the senses of a target word wt in a
comparingthemodelstrainedwithSC-SDScomparedtothose
sentenceW =w1,...,wt,...,wm. Foreachtargetwordwt,
trained using the SDS dataset, indicating a considerable mis-
the goal is to map it to a pre-defined sense s ∈ Swk, where
match between the two benchmarks that might be due to the
Skw = s1w,s2w,...,skw is the set of k pre-defined candi-
automatic translations in the case of SE benchmarks. Finally
datesensesforw. Themeaningofeachsenseisdefinedbythe
and based on the results, it is reported that RoBERTamodels
gloss. Thecandidatesenseshaveacorrespondingglosssetde-
consistentlydemonstratesuperiorperformancecomparedtothe
finedasGwk =gw1,gw2,...,gwk.Themodelsusedinourex-
BETOmodel.Thisislikelyattributedtothebetterdatacuration
perimentsareBERTandRoBERTabasedmodelsandfullypre-
of the datasets utilized during the pre-training and the higher
trainedusingSpanishcorpus.BETO[24]isaBERT-basemodel
numberofparametersforthelargemodel.
with110MparameterstrainedonacompilationoflargeSpanish
unannotated corpora[?] andbyusingtheWholeWordMask- 5. Conclusion
ingtechnique. RoBERTa-baseandRoBERTa-largearemodels
thatweredevelopedsimultaneously[25]bytheBarceloanSu- ThispaperpresentsanovelSpanishlexiconevaluationresource,
percomputing Center (BSC). They are RoBERTa based mod- which offers an extensive coverage and encompasses a wide
elsthat differ mainlyinthenumber of parameters, 115M and range of potential lexical combinations. TheDLEval exhibits
774M respectively. We fine-tune the models, using the train- exceptionalprecision,owingtoitsentirelymanualvalidationby
ing datasets from the section 3.2.1, for five epochs on a dis- high-level experts. Themodels’ performanceiscapableofei-
tributedNVIDIA3090RTX24GBGPUscluster, using24-72 thermatchingorsurpassingthestate-of-the-artresultsachieved
GPUhoursintotal,dependingonthesizeofboththemodeland bymost approaches fortheSpanishWordSenseDisambigua-
thedataset. WeusedthetrainerclassoftheHuggingfacetrans- tion task. This demonstrates the advantages of incorporat-
formers[26]libraryinpython,adaptedforthemultiplechoice inglexicalknowledge,specificallyexpertvalidatedsensesand
paradigmwithcross-entropylossandAdamastheoptimization glosses,infine-tuningneuralmodels.6. References
[14] M.Maru,F.Scozzafava,F.Martelli,andR.Navigli,“SyntagNet:
Challengingsupervisedwordsensedisambiguationwithlexical-
[1] R. Navigli, “Natural language understanding: Instructions for
semanticcombinations,” inProceedingsofthe2019Conference
(present and future) use,” in Proceedings of the Twenty-
on EMNLP and the 9th International Joint Conference on
SeventhInternationalJointConferenceonArtificialIntelligence,
NaturalLanguageProcessing(EMNLP-IJCNLP). HongKong,
IJCAI-18, 7 2018, pp. 5697–5702. [Online]. Available: https:
China: ACL, Nov. 2019, pp. 3534–3540. [Online]. Available:
//doi.org/10.24963/ijcai.2018/812
https://aclanthology.org/D19-1359
[2] A. El Sheikh, M. Bevilacqua, and R. Navigli, “Integrating [15] Y. Su, H. Zhang, Y. Song, and T. Zhang, “Multilingual word
personalized PageRankintoneuralwordsensedisambiguation,” sense disambiguation with unified sense representation,” in
in Proceedings of the 2021 Conference on EMNLP. Online Proceedings ofthe29thICCL. Gyeongju, Republic ofKorea:
and Punta Cana, Dominican Republic: ACL, Nov. 2021, pp. International Committee on Computational Linguistics, Oct.
9092–9098. [Online]. Available: https://aclanthology.org/2021. 2022, pp. 4193–4202. [Online]. Available: https://aclanthology.
emnlp-main.715 org/2022.coling-1.368
[3] M. Bevilacqua, T. Pasini, A. Raganato, and R. Navigli, [16] G. A. Miller, “WordNet: A lexical database for English,” in
“Recent trends in word sense disambiguation: A survey,” in SpeechandNaturalLanguage: ProceedingsofaWorkshopHeld
Proceedings of the Thirtieth International Joint Conference atHarriman,NewYork,February23-26,1992, 1992.[Online].
on Artificial Intelligence, IJCAI-21, Z.-H. Zhou, Ed., 8 Available:https://aclanthology.org/H92-1116
2021, pp. 4330–4338, survey Track. [Online]. Available:
[17] R. Navigli and S. P. Ponzetto, “Babelnet: The automatic
https://doi.org/10.24963/ijcai.2021/593
construction, evaluation and application of a wide-coverage
[4] K.TaghipourandH.T.Ng,“Onemillionsense-taggedinstances multilingual semantic network,” Artificial Intelligence, vol.
forwordsensedisambiguationandinduction,”inProceedingsof 193, pp. 217–250, 2012. [Online]. Available: https://www.
theNineteenthConferenceonComputationalNaturalLanguage sciencedirect.com/science/article/pii/S0004370212000793
Learning. Beijing, China: ACL, Jul. 2015, pp. 338–344.
[18] E. Barba, L. Procopio, N. Campolungo, T. Pasini, and
[Online].Available:https://aclanthology.org/K15-1037
R. Navigli, “Mulan: Multilingual label propagation for word
[5] C. Lacerra, M. Bevilacqua, T. Pasini, and R. Navigli, “Csi: A sense disambiguation,” in Proceedings of the Twenty-Ninth
coarse sense inventory for 85% word sense disambiguation,” International JointConference onArtificial Intelligence, IJCAI-
Proceedings ofthe AAAI,vol.34, no.05, pp. 8123–8130, Apr. 20, C. Bessiere, Ed., 7 2020, pp. 3837–3844, main track.
2020. [Online]. Available: https://ojs.aaai.org/index.php/AAAI/ [Online].Available:https://doi.org/10.24963/ijcai.2020/531
article/view/6324
[19] R. Navigli, D. Jurgens, and D. Vannella, “SemEval-2013 task
[6] R. Navigli, “Word sense disambiguation: A survey,” ACM 12: Multilingual word sense disambiguation,” in Second Joint
Comput. Surv., vol. 41, no. 2, feb 2009. [Online]. Available: Conference on Lexical and Computational Semantics (*SEM),
https://doi.org/10.1145/1459352.1459355 Volume 2: Proceedings of the Seventh International Workshop
on Semantic Evaluation (SemEval 2013). Atlanta, Georgia,
[7] S.ConiaandR.Navigli,“Framingwordsensedisambiguationas
USA: ACL, Jun. 2013, pp. 222–231. [Online]. Available:
amulti-labelproblemformodel-agnosticknowledgeintegration,”
https://aclanthology.org/S13-2040
inProceedingsofthe16thConferenceoftheEuropeanChapterof
theACL:MainVolume. Online:ACL,Apr.2021,pp.3269–3275. [20] A.MoroandR.Navigli, “SemEval-2015 task13: Multilingual
[Online].Available:https://aclanthology.org/2021.eacl-main.286 all-words sensedisambiguation andentity linking,” inProceed-
ings ofthe9th International Workshop onSemantic Evaluation
[8] E.Agirre,O.Lo´pezdeLacalle,andA.Soroa,“RandomWalksfor (SemEval 2015). Denver, Colorado: ACL, Jun. 2015, pp.
Knowledge-BasedWordSenseDisambiguation,”Computational
288–297.[Online].Available:https://aclanthology.org/S15-2049
Linguistics, vol. 40, no. 1, pp. 57–84, 03 2014. [Online].
Available:https://doi.org/10.1162/COLI a00164 [21] L. Padro´ and E. Stanilovsky, “FreeLing 3.0: Towards wider
multilinguality,” in Proceedings (LREC’12). Istanbul, Turkey:
[9] G.A.Miller,C.Leacock,R.Tengi,andR.T.Bunker,“Asemantic EuropeanLanguageResourcesAssociation(ELRA),May2012,
concordance,” inHumanLanguageTechnology: Proceedingsof pp. 2473–2479. [Online]. Available: http://www.lrec-conf.org/
aWorkshopHeldatPlainsboro,NewJersey,March21-24,1993, proceedings/lrec2012/pdf/430 Paper.pdf
1993.[Online].Available:https://aclanthology.org/H93-1061
[22] Y.Wu,M.Schuster,Z.Chen,andetal.,“Google’sneuralmachine
[10] E. Barba, L. Procopio, and R. Navigli, “ConSeC: Word translationsystem:Bridgingthegapbetweenhumanandmachine
sense disambiguation as continuous sense comprehension,” in translation,”2016.
Proceedings of the 2021 Conference on EMNLP. Online
[23] B. P. Yap, A. Koh, and E. S. Chng, “Adapting BERT for
and Punta Cana, Dominican Republic: ACL, Nov. 2021, pp.
word sense disambiguation with gloss selection objective and
1492–1503. [Online]. Available: https://aclanthology.org/2021.
example sentences,” in Findings of the ACL: EMNLP 2020.
emnlp-main.112
Online: ACL, Nov. 2020, pp. 41–46. [Online]. Available:
[11] R.Orlando, S.Conia, F.Brignone, F.Cecconi, andR.Navigli, https://aclanthology.org/2020.findings-emnlp.4
“AMuSE-WSD:Anall-in-onemultilingualsystemforeasyWord
[24] J. Can˜ete, G. Chaperon, R. Fuentes, J.-H. Ho, H. Kang, and
SenseDisambiguation,” inProceedings ofthe2021Conference
J. Pe´rez, “Spanish pre-trained bert model and evaluation data,”
on EMNLP:System Demonstrations. Online and Punta Cana,
inPML4DCatICLR2020,2020.
Dominican Republic: ACL,Nov. 2021, pp. 298–307. [Online].
Available:https://aclanthology.org/2021.emnlp-demo.34 [25] A. G. Fandin˜o, J. A. Estape´, M. Pa`mies, J. L. Palao,
J. S. Ocampo, C. P. Carrino, C. A. Oller, C. R. Penagos,
[12] L.Procopio,E.Barba,F.Martelli,andR.Navigli,“Multimirror:
A. G. Agirre, and M. Villegas, “Maria: Spanish language
Neuralcross-lingualwordalignmentformultilingualwordsense
models,” Procesamiento del Lenguaje Natural, vol. 68, 2022.
disambiguation,” in Proceedings of the Thirtieth International
[Online]. Available: https://upcommons.upc.edu/handle/2117/
JointConferenceonArtificialIntelligence,IJCAI-21,Z.-H.Zhou,
367156#.YyMTB4X9A-0.mendeley
Ed., 8 2021, pp. 3915–3921, main Track. [Online]. Available:
https://doi.org/10.24963/ijcai.2021/539 [26] T. Wolf, L. Debut, and et al., “Transformers: State-
of-the-art natural language processing,” in Proceedings of
[13] B. Scarlini, T. Pasini, and R. Navigli, “Sensembert: the 2020 Conference on EMNLP: System Demonstrations.
Context-enhanced sense embeddings for multilingual word Online: ACL, Oct. 2020, pp. 38–45. [Online]. Available:
sense disambiguation,” Proceedings of the AAAI, vol. 34, https://aclanthology.org/2020.emnlp-demos.6
no. 05, pp. 8758–8765, Apr. 2020. [Online]. Available:
https://ojs.aaai.org/index.php/AAAI/article/view/6402