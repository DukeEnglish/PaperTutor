[
    {
        "title": "MobA: A Two-Level Agent System for Efficient Mobile Task Automation",
        "authors": "Zichen ZhuHao TangYansi LiKunyao LanYixuan JiangHao ZhouYixiao WangSituo ZhangLiangtai SunLu ChenKai Yu",
        "links": "http://arxiv.org/abs/2410.13757v1",
        "entry_id": "http://arxiv.org/abs/2410.13757v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13757v1",
        "summary": "Current mobile assistants are limited by dependence on system APIs or\nstruggle with complex user instructions and diverse interfaces due to\nrestricted comprehension and decision-making abilities. To address these\nchallenges, we propose MobA, a novel Mobile phone Agent powered by multimodal\nlarge language models that enhances comprehension and planning capabilities\nthrough a sophisticated two-level agent architecture. The high-level Global\nAgent (GA) is responsible for understanding user commands, tracking history\nmemories, and planning tasks. The low-level Local Agent (LA) predicts detailed\nactions in the form of function calls, guided by sub-tasks and memory from the\nGA. Integrating a Reflection Module allows for efficient task completion and\nenables the system to handle previously unseen complex tasks. MobA demonstrates\nsignificant improvements in task execution efficiency and completion rate in\nreal-life evaluations, underscoring the potential of MLLM-empowered mobile\nassistants.",
        "updated": "2024-10-17 16:53:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13757v1"
    },
    {
        "title": "Scaling Wearable Foundation Models",
        "authors": "Girish NarayanswamyXin LiuKumar AyushYuzhe YangXuhai XuShun LiaoJake GarrisonShyam TailorJake SunshineYun LiuTim AlthoffShrikanth NarayananPushmeet KohliJiening ZhanMark MalhotraShwetak PatelSamy Abdel-GhaffarDaniel McDuff",
        "links": "http://arxiv.org/abs/2410.13638v1",
        "entry_id": "http://arxiv.org/abs/2410.13638v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13638v1",
        "summary": "Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.",
        "updated": "2024-10-17 15:08:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13638v1"
    },
    {
        "title": "Neural Correlates of Augmented Reality Safety Warnings: EEG Analysis of Situational Awareness and Cognitive Performance in Roadway Work Zones",
        "authors": "Fatemeh Banani ArdecaniAmit KumarSepehr SabetiOmidreza Shoghli",
        "links": "http://arxiv.org/abs/2410.13623v1",
        "entry_id": "http://arxiv.org/abs/2410.13623v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13623v1",
        "summary": "Despite the research and implementation efforts involving various safety\nstrategies, protocols, and technologies, work zone crashes and fatalities\ncontinue to occur at an alarming rate each year. This study investigates the\nneurophysiological responses to Augmented Reality safety warnings in roadway\nwork zones under varying workload conditions. Using electroencephalogram (EEG)\ntechnology, we objectively assessed situational awareness, attention, and\ncognitive load in simulated low-intensity (LA) and moderate-intensity (MA) work\nactivities. The research analyzed key EEG indicators including beta, gamma,\nalpha, and theta waves, as well as various combined wave ratios. Results\nrevealed that AR warnings effectively triggered neurological responses\nassociated with increased situational awareness and attention across both\nworkload conditions. However, significant differences were observed in the\ntiming and intensity of these responses. In the LA condition, peak responses\noccurred earlier (within 125 ms post-warning) and were more pronounced,\nsuggesting a more robust cognitive response when physical demands were lower.\nConversely, the MA condition showed delayed peak responses (125-250 ms\npost-warning) and more gradual changes, indicating a potential impact of\nincreased physical activity on cognitive processing speed. These findings\nunderscore the importance of considering physical workload when designing\nAR-based safety systems for roadway work zones. The research contributes to the\nunderstanding of how AR can enhance worker safety and provides insights for\ndeveloping more effective, context-aware safety interventions in high-risk work\nenvironments.",
        "updated": "2024-10-17 14:56:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13623v1"
    },
    {
        "title": "Co-creation and evaluation of an app to support reminiscence therapy interventions for older people with dementia",
        "authors": "Iván De-Rosende-CeleiroVirginia Francisco-GilmartínSusana Bautista-BlascoAdriana Ávila-Álvarez",
        "links": "http://dx.doi.org/10.1177/20552076241261849",
        "entry_id": "http://arxiv.org/abs/2410.13556v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13556v1",
        "summary": "Objective: The objectives encompassed (1) the creation of Recuerdame, a\ndigital app specifically designed for occupational therapists, aiming to\nsupport these professionals in the processes of planning, organizing,\ndeveloping, and documenting reminiscence therapies for older people with\ndementia, and (2) the evaluation of the designed prototype through a\nparticipatory and user-centered design approach, exploring the perceptions of\nend-users. Methods: This exploratory research used a mixed-methods design. The\napp was developed in two phases. In the first phase, the research team\nidentified the requirements and designed a prototype. In the second phase,\nexperienced occupational therapists evaluated the prototype. Results: The\nresearch team determined the app's required functionalities, grouped into eight\nmajor themes: register related persons and caregivers; record the patient's\nlife story memories; prepare a reminiscence therapy session; conduct a session;\nend a session; assess the patient; automatically generate a life story; other\nrequirements. The first phase ended with the development of a prototype. In the\nsecond phase, eight occupational therapists performed a series of tasks using\nall the application's functionalities. Most of these tasks were very easy\n(Single Ease Question). The level of usability was considered excellent (System\nUsability Scale). Participants believed that the app would save practitioners\ntime, enrich therapy sessions and improve their effectiveness. The qualitative\nresults were summarized in two broad themes: (a) acceptability of the app; and\n(b) areas for improvement.ConclusionsParticipating occupational therapists\ngenerally agreed that the co-designed app appears to be a versatile tool that\nempowers these professionals to manage reminiscence interventions.",
        "updated": "2024-10-17 13:55:32 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13556v1"
    },
    {
        "title": "RAMPA: Robotic Augmented Reality for Machine Programming and Automation",
        "authors": "Fatih DogangunSerdar BaharYigit YildirimBora Toprak TemirEmre UgurMustafa Doga Dogan",
        "links": "http://arxiv.org/abs/2410.13412v1",
        "entry_id": "http://arxiv.org/abs/2410.13412v1",
        "pdf_url": "http://arxiv.org/pdf/2410.13412v1",
        "summary": "As robotics continue to enter various sectors beyond traditional industrial\napplications, the need for intuitive robot training and interaction systems\nbecomes increasingly more important. This paper introduces Robotic Augmented\nReality for Machine Programming (RAMPA), a system that utilizes the\ncapabilities of state-of-the-art and commercially available AR headsets, e.g.,\nMeta Quest 3, to facilitate the application of Programming from Demonstration\n(PfD) approaches on industrial robotic arms, such as Universal Robots UR10. Our\napproach enables in-situ data recording, visualization, and fine-tuning of\nskill demonstrations directly within the user's physical environment. RAMPA\naddresses critical challenges of PfD, such as safety concerns, programming\nbarriers, and the inefficiency of collecting demonstrations on the actual\nhardware. The performance of our system is evaluated against the traditional\nmethod of kinesthetic control in teaching three different robotic manipulation\ntasks and analyzed with quantitative metrics, measuring task performance and\ncompletion time, trajectory smoothness, system usability, user experience, and\ntask load using standardized surveys. Our findings indicate a substantial\nadvancement in how robotic tasks are taught and refined, promising improvements\nin operational safety, efficiency, and user engagement in robotic programming.",
        "updated": "2024-10-17 10:21:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.13412v1"
    }
]