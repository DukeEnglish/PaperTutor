[
    {
        "title": "ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems",
        "authors": "Andrew ZhuLiam DuganChris Callison-Burch",
        "links": "http://arxiv.org/abs/2408.02248v1",
        "entry_id": "http://arxiv.org/abs/2408.02248v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02248v1",
        "summary": "Recently, there has been increasing interest in using Large Language Models\n(LLMs) to construct complex multi-agent systems to perform tasks such as\ncompiling literature reviews, drafting consumer reports, and planning\nvacations. Many tools and libraries exist for helping create such systems,\nhowever none support recursive multi-agent systems -- where the models\nthemselves flexibly decide when to delegate tasks and how to organize their\ndelegation structure. In this work, we introduce ReDel: a toolkit for recursive\nmulti-agent systems that supports custom tool-use, delegation schemes,\nevent-based logging, and interactive replay in an easy-to-use web interface. We\nshow that, using ReDel, we are able to achieve significant performance gains on\nagentic benchmarks and easily identify potential areas of improvements through\nthe visualization and debugging tools. Our code, documentation, and PyPI\npackage are open-source and free to use under the MIT license.",
        "updated": "2024-08-05 05:43:23 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02248v1"
    },
    {
        "title": "Environment Complexity and Nash Equilibria in a Sequential Social Dilemma",
        "authors": "Mustafa YasirAndrew HowesVasilios MavroudisChris Hicks",
        "links": "http://arxiv.org/abs/2408.02148v1",
        "entry_id": "http://arxiv.org/abs/2408.02148v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02148v1",
        "summary": "Multi-agent reinforcement learning (MARL) methods, while effective in\nzero-sum or positive-sum games, often yield suboptimal outcomes in general-sum\ngames where cooperation is essential for achieving globally optimal outcomes.\nMatrix game social dilemmas, which abstract key aspects of general-sum\ninteractions, such as cooperation, risk, and trust, fail to model the temporal\nand spatial dynamics characteristic of real-world scenarios. In response, our\nstudy extends matrix game social dilemmas into more complex, higher-dimensional\nMARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma\nto more closely match the decision-space of a one-shot matrix game while also\nintroducing variable environment complexity. Our findings indicate that as\ncomplexity increases, MARL agents trained in these environments converge to\nsuboptimal strategies, consistent with the risk-dominant Nash equilibria\nstrategies found in matrix games. Our work highlights the impact of environment\ncomplexity on achieving optimal outcomes in higher-dimensional game-theoretic\nMARL environments.",
        "updated": "2024-08-04 21:27:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02148v1"
    },
    {
        "title": "Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study",
        "authors": "Sz-Ting TzengNirav AjmeriMunindar P. Singh",
        "links": "http://arxiv.org/abs/2408.02117v1",
        "entry_id": "http://arxiv.org/abs/2408.02117v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02117v1",
        "summary": "We propose Exanna, a framework to realize agents that incorporate values in\ndecision making. An Exannaagent considers the values of itself and others when\nproviding rationales for its actions and evaluating the rationales provided by\nothers. Via multiagent simulation, we demonstrate that considering values in\ndecision making and producing rationales, especially for norm-deviating\nactions, leads to (1) higher conflict resolution, (2) better social experience,\n(3) higher privacy, and (4) higher flexibility.",
        "updated": "2024-08-04 19:14:36 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02117v1"
    },
    {
        "title": "MALADE: Orchestration of LLM-powered Agents with Retrieval Augmented Generation for Pharmacovigilance",
        "authors": "Jihye ChoiNils PalumboPrasad ChalasaniMatthew M. EngelhardSomesh JhaAnivarya KumarDavid Page",
        "links": "http://arxiv.org/abs/2408.01869v1",
        "entry_id": "http://arxiv.org/abs/2408.01869v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01869v1",
        "summary": "In the era of Large Language Models (LLMs), given their remarkable text\nunderstanding and generation abilities, there is an unprecedented opportunity\nto develop new, LLM-based methods for trustworthy medical knowledge synthesis,\nextraction and summarization. This paper focuses on the problem of\nPharmacovigilance (PhV), where the significance and challenges lie in\nidentifying Adverse Drug Events (ADEs) from diverse text sources, such as\nmedical literature, clinical notes, and drug labels. Unfortunately, this task\nis hindered by factors including variations in the terminologies of drugs and\noutcomes, and ADE descriptions often being buried in large amounts of narrative\ntext. We present MALADE, the first effective collaborative multi-agent system\npowered by LLM with Retrieval Augmented Generation for ADE extraction from drug\nlabel data. This technique involves augmenting a query to an LLM with relevant\ninformation extracted from text resources, and instructing the LLM to compose a\nresponse consistent with the augmented data. MALADE is a general LLM-agnostic\narchitecture, and its unique capabilities are: (1) leveraging a variety of\nexternal sources, such as medical literature, drug labels, and FDA tools (e.g.,\nOpenFDA drug information API), (2) extracting drug-outcome association in a\nstructured format along with the strength of the association, and (3) providing\nexplanations for established associations. Instantiated with GPT-4 Turbo or\nGPT-4o, and FDA drug label data, MALADE demonstrates its efficacy with an Area\nUnder ROC Curve of 0.90 against the OMOP Ground Truth table of ADEs. Our\nimplementation leverages the Langroid multi-agent LLM framework and can be\nfound at https://github.com/jihyechoi77/malade.",
        "updated": "2024-08-03 22:14:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01869v1"
    },
    {
        "title": "Opinion Dynamics with Set-Based Confidence: Convergence Criteria and Periodic Solutions",
        "authors": "Iryna ZabarianskaAnton V. Proskurnikov",
        "links": "http://arxiv.org/abs/2408.01753v1",
        "entry_id": "http://arxiv.org/abs/2408.01753v1",
        "pdf_url": "http://arxiv.org/pdf/2408.01753v1",
        "summary": "This paper introduces a new multidimensional extension of the\nHegselmann-Krause (HK) opinion dynamics model, where opinion proximity is not\ndetermined by a norm or metric. Instead, each agent trusts opinions within the\nMinkowski sum $\\xi+\\mathcal{O}$, where $\\xi$ is the agent's current opinion and\n$\\mathcal{O}$ is the confidence set defining acceptable deviations. During each\niteration, agents update their opinions by simultaneously averaging the trusted\nopinions. Unlike traditional HK systems, where $\\mathcal{O}$ is a ball in some\nnorm, our model allows the confidence set to be non-convex and even unbounded.\n  We demonstrate that the new model, referred to as SCOD (Set-based Confidence\nOpinion Dynamics), can exhibit properties absent in the conventional HK model.\nSome solutions may converge to non-equilibrium points in the state space, while\nothers oscillate periodically. These ``pathologies'' disappear if the set\n$\\mathcal{O}$ is symmetric and contains zero in its interior: similar to the\nusual HK model, SCOD then converges in a finite number of iterations to one of\nthe equilibrium points. The latter property is also preserved if one agent is\n\"stubborn\" and resists changing their opinion, yet still influences the others;\nhowever, two stubborn agents can lead to oscillations.",
        "updated": "2024-08-03 11:29:40 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.01753v1"
    }
]