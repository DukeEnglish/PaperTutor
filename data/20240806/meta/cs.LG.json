[
    {
        "title": "On Using Quasirandom Sequences in Machine Learning for Model Weight Initialization",
        "authors": "Andriy MiranskyyAdam SorrentiViral Thakar",
        "links": "http://arxiv.org/abs/2408.02654v1",
        "entry_id": "http://arxiv.org/abs/2408.02654v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02654v1",
        "summary": "The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.",
        "updated": "2024-08-05 17:33:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02654v1"
    },
    {
        "title": "Detection of Compromised Functions in a Serverless Cloud Environment",
        "authors": "Danielle LaviOleg BrodtDudu MimranYuval EloviciAsaf Shabtai",
        "links": "http://arxiv.org/abs/2408.02641v1",
        "entry_id": "http://arxiv.org/abs/2408.02641v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02641v1",
        "summary": "Serverless computing is an emerging cloud paradigm with serverless functions\nat its core. While serverless environments enable software developers to focus\non developing applications without the need to actively manage the underlying\nruntime infrastructure, they open the door to a wide variety of security\nthreats that can be challenging to mitigate with existing methods. Existing\nsecurity solutions do not apply to all serverless architectures, since they\nrequire significant modifications to the serverless infrastructure or rely on\nthird-party services for the collection of more detailed data. In this paper,\nwe present an extendable serverless security threat detection model that\nleverages cloud providers' native monitoring tools to detect anomalous behavior\nin serverless applications. Our model aims to detect compromised serverless\nfunctions by identifying post-exploitation abnormal behavior related to\ndifferent types of attacks on serverless functions, and therefore, it is a last\nline of defense. Our approach is not tied to any specific serverless\napplication, is agnostic to the type of threats, and is adaptable through model\nadjustments. To evaluate our model's performance, we developed a serverless\ncybersecurity testbed in an AWS cloud environment, which includes two different\nserverless applications and simulates a variety of attack scenarios that cover\nthe main security threats faced by serverless functions. Our evaluation\ndemonstrates our model's ability to detect all implemented attacks while\nmaintaining a negligible false alarm rate.",
        "updated": "2024-08-05 17:14:35 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02641v1"
    },
    {
        "title": "Command-line Obfuscation Detection using Small Language Models",
        "authors": "Vojtech OutrataMichael Adam PolakMartin Kopp",
        "links": "http://arxiv.org/abs/2408.02637v1",
        "entry_id": "http://arxiv.org/abs/2408.02637v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02637v1",
        "summary": "To avoid detection, adversaries often use command-line obfuscation. There are\nnumerous techniques of the command-line obfuscation, all designed to alter the\ncommand-line syntax without affecting its original functionality. This\nvariability forces most security solutions to create an exhaustive enumeration\nof signatures for even a single pattern. In contrast to using signatures, we\nhave implemented a scalable NLP-based detection method that leverages a\ncustom-trained, small transformer language model that can be applied to any\nsource of execution logs. The evaluation on top of real-world telemetry\ndemonstrates that our approach yields high-precision detections even on\nhigh-volume telemetry from a diverse set of environments spanning from\nuniversities and businesses to healthcare or finance. The practical value is\ndemonstrated in a case study of real-world samples detected by our model. We\nshow the model's superiority to signatures on established malware known to\nemploy obfuscation and showcase previously unseen obfuscated samples detected\nby our model.",
        "updated": "2024-08-05 17:01:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02637v1"
    },
    {
        "title": "Learning rheological parameters of non-Newtonian fluids from velocimetry data",
        "authors": "Alexandros KontogiannisRichard HodgkinsonEmily L. Manchester",
        "links": "http://arxiv.org/abs/2408.02604v1",
        "entry_id": "http://arxiv.org/abs/2408.02604v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02604v1",
        "summary": "We solve a Bayesian inverse Navier-Stokes (N-S) problem that assimilates\nvelocimetry data in order to jointly reconstruct the flow field and learn the\nunknown N-S parameters. By incorporating a Carreau shear-thinning viscosity\nmodel into the N-S problem, we devise an algorithm that learns the most likely\nCarreau parameters of a shear-thinning fluid, and estimates their\nuncertainties, from velocimetry data alone. We then conduct a flow-MRI\nexperiment to obtain velocimetry data of an axisymmetric laminar jet through an\nidealised medical device (FDA nozzle) for a blood analogue fluid. We show that\nthe algorithm can successfully reconstruct the flow field by learning the most\nlikely Carreau parameters, and that the learned parameters are in very good\nagreement with rheometry measurements. The algorithm accepts any algebraic\neffective viscosity model, as long as the model is differentiable, and it can\nbe extended to more complicated non-Newtonian fluids (e.g. Oldroyd-B fluid) if\na viscoelastic model is incorporated into the N-S problem.",
        "updated": "2024-08-05 16:27:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02604v1"
    },
    {
        "title": "AI-Driven Strategies for Reducing Student Withdrawal -- A Study of EMU Student Stopout",
        "authors": "Yan ZhaoAmy Otteson",
        "links": "http://arxiv.org/abs/2408.02598v1",
        "entry_id": "http://arxiv.org/abs/2408.02598v1",
        "pdf_url": "http://arxiv.org/pdf/2408.02598v1",
        "summary": "Not everyone who enrolls in college will leave with a certificate or degree,\nbut the number of people who drop out or take a break is much higher than\nexperts previously believed. In December 2013, there were 29 million people\nwith some college education but no degree. That number jumped to 36 million by\nDecember of 2018, according to a new report from the National Student\nClearinghouse Research Center[1]. It is imperative to understand the underlying\nfactors contributing to student withdrawal and to assist decision-makers to\nidentify effective strategies to prevent it. By analyzing the characteristics\nand educational pathways of the stopout student population, our aim is to\nprovide actionable insights that can benefit institutions facing similar\nchallenges. Eastern Michigan University (EMU) faces significant challenges in\nstudent retention, with approximately 55% of its undergraduate students not\ncompleting their degrees within six years. As an institution committed to\nstudent success, EMU conducted a comprehensive study of student withdrawals to\nunderstand the influencing factors. And the paper revealed a high correlation\nbetween certain factors and withdrawals, even in the early stages of university\nattendance. Based on these findings, we developed a predictive model that\nemploys artificial intelligence techniques to assess the potential risk that\nstudents abandon their studies. These models enable universities to implement\nearly intervention strategies, support at-risk students, and improve overall\nhigher education success.",
        "updated": "2024-08-05 16:15:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.02598v1"
    }
]