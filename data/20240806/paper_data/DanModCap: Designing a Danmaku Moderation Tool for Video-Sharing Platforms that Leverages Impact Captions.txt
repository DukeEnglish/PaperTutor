DanModCap: Designing a Danmaku Moderation Tool for
Video-Sharing Platforms that Leverages Impact Captions
SIYINGHU,CityUniversityofHongKong,China
HUANCHEN WANG,CityUniversityofHongKong,ChinaandSouthernUniversityofScienceand
Technology,China
YUZHANG,CityUniversityofHongKong,China
PIAOHONGWANG,CityUniversityofHongKong,China
ZHICONGLU,CityUniversityofHongKong,China
1
4202
guA
5
]CH.sc[
1v47520.8042:viXraFig.1. OurDanmakumoderationapproach.1)TypicalDanmakuinvolvespositive,inappropriate,orirrelevant
content.2)Onvideo-sharingplatforms,Danmakuisabuilt-insocialfeaturethatsupportsend-users’social
communication and is synchronized with the video. 3) To moderate Danmaku content, we introduce a
proactiveapproachcalledImpactCaptions,thatleveragesakeyfeatureinEastAsianvarietyshows.4)
Buildingonthisconceptualfoundation,weintroduceDanModCap,atoolforDanmakucontentmoderation
thatusesgenerativeAItocreateImpactCaptions.5and6)ThepipelineofImpactCaptiongenerationand
examplecaptions,whichincludetheTasukkomistyle(red),theExplanatorystyle(blue),andtheHumorous
andPraisingstyle(orange).
Onlinevideoplatformshavegainedincreasedpopularityduetotheirabilitytosupportinformationconsump-
tionandsharingandthediversesocialinteractionstheyafford.Danmaku,areal-timecommentaryfeature
thatoverlaysusercommentsonavideo,hasbeenfoundtoimproveuserengagement,however,theuseof
Danmakucanleadtotoxicbehaviorsandinappropriatecomments.Toaddresstheseissues,weproposea
proactivemoderationapproachinspiredbyImpactCaptions,avisualtechniqueusedinEastAsianvariety
shows.ImpactCaptionscombinetextualcontentandvisualelementstoconstructemotionalandcognitive
resonance.Withinthecontextofthiswork,ImpactCaptionswereusedtoguideviewerstowardspositive
Danmaku-relatedactivitiesandelicitmorepro-socialbehaviors.LeveragingImpactCaptions,wedeveloped
DanModCap,anmoderationtoolthatcollectedandanalyzedDanmakuanduseditasinputtolargegenerative
languagemodelstoproduceImpactCaptions.OurevaluationofDanModCapdemonstratedthatImpact
Captionsreducednegativeantagonisticemotions,increasedusers’desiretosharepositivecontent,andelicited
self-controlinDanmakusocialactiontofosteringproactivecommunitymaintenancebehaviors.Ourapproach
highlightsthebenefitsofusingLLM-supportedcontentmoderationmethodsforproactivemoderationina
large-scalelivecontentcontexts.
CCSConcepts:•Human-centeredcomputing→Collaborativeandsocialcomputingsystemsand
tools;Collaborativeandsocialcomputingdesignandevaluationmethods.
AdditionalKeyWordsandPhrases:ContentModeration,UserEngagement,Danmaku,LargeLanguageModels,
EmotionalResonance,CognitiveResonance,Pro-socialBehavior
ACMReferenceFormat:
SiyingHU,HuanchenWang,YuZhang,PiaohongWang,andZhicongLu.2024.DanModCap:Designinga
DanmakuModerationToolforVideo-SharingPlatformsthatLeveragesImpactCaptions.In.ACM,NewYork,
NY,USA,27pages.https://doi.org/XXXXXXX.XXXXXXX
1 INTRODUCTION
Onlinevideo-sharingplatforms(VSPs)havebecomeincreasinglypopularwaysforindividualsto
consumeandshareinformation[57].Toenhanceuserengagement,theseplatformshaveseveral
built-insocialfeatures.Forexample,userscanprovidecommentsorsharemessageswithinlivechat
rooms,orpostDanmaku.Danmakuisareal-timecommentarymethodthatoverlaysusercomments
containinginternetslangandmemesonvideostofosteremotionalexpressionandinteraction
amongviewers[17,79].Danmaku’scontinuouspresenceinrepeatedvideoloopsenhancesthe
effectofeachcommentandshapestheviewer’sexperienceoverrepeatedviewings.Itspseudo-
synchronousnatureisalsoanoteworthydeparturefromtraditionalforum-basedcommunication,
Permissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfee
providedthatcopiesarenotmadeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthe
fullcitationonthefirstpage.Copyrightsforcomponentsofthisworkownedbyothersthantheauthor(s)mustbehonored.
Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requires
priorspecificpermissionand/orafee.Requestpermissionsfrompermissions@acm.org.
Conferenceacronym’XX,June03–05,2018,Woodstock,NY
©2024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.
ACMISBN978-x-xxxx-xxxx-x/YY/MM...$15.00
https://doi.org/XXXXXXX.XXXXXXX
2DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
aimingtofosterasenseofcommunitywhileenhancinguserparticipation[49,51,79,82].This
featurehasthusbecomeincreasinglypopularonpopularvideo-sharingplatformssuchasAcFun,
Bilibili,TikTok,andTwitch.
WhileDanmakuoffersanimmersiveandsociallyinteractiveviewingexperience,italsointro-
duceschallengesrelatedtoanonymity,therapidspreadofinappropriatemessages[7,18,33,79],
comment overload, negative interactions, and language conflicts [79, 82]. There is thus a need
forreal-timeDanmakumoderation.ModeratingDanmaku,however,isasignificantlydifferent
challengethanmoderatingnon-real-timecontent.Forexample,therapidandvoluminousstream
ofDanmakucommentsoftenleadstoinformationoverload[79]forusersandmoderators.The
anonymityofexpressionalsolendsitselftoincreaseduser-to-usertoxicitybecausethediversity
andambiguityofoffensiveorimplicitharmfulcontentcomplicatesthemoderationprocess.Existing
moderationapproachesalsorelymoreonposthocinspection,whichmakestheminappropriatefor
livesettings[57].ModerationmustalsomaintainacontextualunderstandingofDanmakuwithina
periodoftimesosimplyremovingorblockingcontentwithoutconsideringitscontextmaydistort
thecommunicationandinteractionfacilitatedbyDanmaku.
Thisresearchfirstconductedavideo-contentanalysistounderstandtheexistingusesofImpact
Captiondesign.WeidentifiedataxonomyofImpactCaptiontypesthatwasorganizedintothree
categories and seven design dimensions. We then ran an expert-based co-design workshop to
solicit design recommendations to steer Danmaku content toward the promotion of prosocial
behaviors.Spurredbytheexpertrecommendationsandourtaxonomy,wedevelopedaDanmaku
moderationtool,DanModCap,thatwouldsupportusersinmoderatinglivecontentwhilebeing
mindfulofcommunityengagementandthedynamicnatureofviewerpro-socialinteractions.A
keytenantofDanModCapistheImpactCaption,apopularfeatureinEastAsianvarietyshows
[9,64].ImpactCaptionsarevisuallycompellingandcontext-sensitivetextualandnon-textualelem
thataredesignedtocaptivatethereader’sattentionandenhancetheiremotionalexperience[4].
Theyarepowerfultriggersthatadddepthandmeaningtocontent.OurimplementationofImpact
Captionswasrootedintheresonancetheory [23,55],whichsuggeststhatwhenweseeorhear
somethingthatresonateswithusemotionallyandcognitively,itcreatesastrongerconnectionto
us.Byusingfamiliarphrasestoencouragecognitiveresonance[43]andvividcolorsandspeech
bubblestoencourageemotionalresonance[77],ImpactCaptionshavethepotentialtobridgethe
gapbetweenusersandcontent,thushelpingtoshapemoreprosocialbehaviorsonVSPs.
WithinDanModCap,thethematicinformationandemotionaltendencyofDanmakuisanalyzed
viaLatentDirichletAllocationandgenerativeAImodelsincludingLlama2createcorresponding
ImpactCaptions.Oursystemintegratescontextualawareness,visualappeal,andcognitiveand
emotionalresonancetoinfluenceviewerintentions,perceptions,interpretations,andthesocial
practicesofviewingDanmaku-embeddedvideos.DanModCapnotonlyfiltersoutinappropriate
contentbutalsoamplifiespositivecontenttofosterasenseofcommunityandengagement.
ToexploretheinfluenceofthegenerativeImpactCaptionsinterventiononviewers’internal
emotions,cognition,attitudes,andexternalsocialbehaviors,wethenconductedauserstudy.The
studyfoundthatviewersexperiencedbothcognitiveandemotionalresonancewiththegenerative
ImpactCaptions,perceivingthemasalignedwiththeirownthoughts,experiences,andintentions
–particularlyaroundonlineactivismandcommunitybelonging.Thecaptionsinfluencedviewers’
attentiondynamics,attimesdivertingfocusfromthemainvideocontenttothecaptionsthemselves.
Theyalsofosteredaheightenedsenseofcommunitycohesion,belongingness,companionship,and
security,amongotherfindings.
Duetotheseresearchactivities,wethuscontribute:
3Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
• Anovelfeedbackmethod,ImpactCaptions,whichcanbeusedtomoderateDanmakucom-
mentsandsubtlyshapeviewerinterpretationsandemotions.
• ThedesignandimplementationofDanModCap,aDanmakucontentmoderationsystemfor
VSPthatintegratesImpactCaptions.
• AnuancedunderstandingoftheroleofcognitiveandemotionalresonanceinVSPcontent
moderation.
2 RELATEDWORK
Ofmostrelevancetoourresearchispriorworkoncontentmoderation.
2.1 ContentModerationonSocialMediaPlatforms
Thereisaconsiderableresearchgapinrelationtotheeffectivemoderationofcontentthatevades
standardcensorshipmeasures.WhetherthispertainstoconventionalsocialmediaorDanmakuon
videoplatforms,thecentralobjectiveofmoderationremainsconsistent:toidentifyandneutralize
detrimentalcontent,ensuringuserprotectionandapositivesocialenvironment.Todate,research
oncontentmoderationhasfocusedprimarilyonsocialmediaplatforms,emphasizingtheregu-
lationofstatictextualcontentanddynamicmultimediaelements.Indeed,existingstudieshave
largelytargetedtheidentificationandmitigationofharmful,fraudulent,orhatespeechwithin
textualcontent[40,66,69]andelementsofviolence,pornography,orcopyrightinfringementin
multimediamaterials[30,31].Withinthesestudies,themoderationofinteractivebehaviorshas
been consistently identified as important in terms of identifying abusive behaviors [13, 40] or
socialengineeringthreats[31,33,66].Theprimaryobjectiveofthisfieldofstudyistosafeguard
thecontentuploadedonsocialmediaplatforms,ensuringthatitcomplieswithlegalandethical
standardsanddiscouragesharmfulbehavior.
Despiterecentadvancementsinalgorithmicautomation(seeSection2.2),issuessuchasimplicit
offensivecontentandsubstitutinginappropriateorsensitiveinformationpersist[32].Whencoupled
withDanmaku’sreal-timenatureanditsinherentanonymityandculturalspecificity,moderation
challengeswhenDanmakuispresentexceedthoseseeninconventionalsocialmedia.Toaddress
theseadditionalissues,thepresentresearchshiftsfocustowardreal-timeVSPs.
2.2 ContentModerationApproaches
Onlinecontentmoderationisacriticalaspectofmaintainingsafeandproductivedigitalenviron-
ments.Recentworkhashighlighteddisparitiesintheimpactofmoderation,whichhasbeenfound
tofrequentlyreplicateofflinesocialmarginalizationwithinonlinespaces[29,44,67,74].
Previously,rule-basedworkhasshownthatincorporatingvariousnaturallanguageprocessing
techniques, such as sentiment analysis [34, 59] and text normalization, with machine learning
methods[63,70]canenhancetheeffectivenessofautomatedmoderation.Thesesystemsidentify
andfilterinappropriatecontentusingpresetrules,suchasusingblacklistsandregularexpressions
todetectandremoveviolations.
Whiletraditionalmethodsaresimplerandlessresource-intensive,theyfallshortinhandling
the complexity and volume of modern online content. To date, numerous automated content
moderationtechnologieshavebeendeveloped,includingblocklisttools,textfilters,andhuman-
assistedscreeningtechniques[21,37].Nevertheless,eachextanttechnologycomeswithitsown
limitations,manyofwhichconcernaninabilitytotrulyadapttodiverseuserexperiencesand
societal contexts [48]. As such, a move toward proactive moderation strategies has emerged,
drivenbythelimitationsofreactivemethods.Theseproactivestrategies,representedbydesigns
such as CAPTCHAs [68], Storychat [81], and the GLHF pledge [11], indicate a move toward
4DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
subtle,persuasiveapproachesthatencouragepositivecommunityparticipationwhilepromoting
inclusivityandequity.
AlgorithmslikeLatentDirichletAllocation(LDA)havealsobeenshowntoprovidemoreaccurate
andefficientcontentmoderation[45,76].LDAisoftenusedtoextracthiddentopicinformationfrom
largeamountsoftextdataasatopicmodelingtechnology.Ammarietal.,forexample,transformed
RedditthreadsintoaBagofWordsmodelandapplyiedLDAtoidentifydistincttopicsthatparents
werelikelytodiscussanonymously[5].Jhaveretal.utilizedLDAtoanalyzethecontentofremoval
explanationsonReddit,aimingtounderstandhowthesecommunicationsimpactuserbehavior
[39].Inspiredbythisresearch,weusedLDAtoextracthiddenthematicinformationfromDanmaku
commenttexttoidentifythecorethemesofuserdiscussions.
OtherworkhasdemonstratedthepotentialofLLMsforcontentmoderation[45,46,62].Kollaet
al.introducedanLLM-basedmoderationtool,LLM-Mod,toautomatetheprocessofidentifyingand
flaggingcontentthatviolatescommunityguidelinesonReddit[45].Itusedamulti-stepprompting
approach,summarizingandhighlightingcommunityrules,definingkeytermswithinthoserules,
and generating hypothetical examples of rule-violating posts, for textual content moderation.
WithinDanModCap,weharnessedasimilarapproach,alongwithpromptengineering,toproduce
modulatedtextandvisualelements.Kumaretal.conductedanevaluationoftheefficacyofLLMs
incontentmoderationtasks,focusingonrule-basedcommunitymoderationandtoxiccontent
detection [46]. They found that while LLMs demonstrated comparable performance to human
moderatorsincertainrule-basedtasks,therewasamarginalimprovementintoxicitydetection
performanceasmodelsizesincreased,suggestingapotentialplateauinthecapabilityofLLMsfor
thismoderationtask.
Manyoftheseautomatedmethods,however,oftenfailtoinfermeaningfromasequenceof
sentences,andlinguisticfeatureslikesarcasm,metaphors,andironycouldresultinusercontent
being inaccurately flagged as inappropriate. Thus, although these methods are effective they
strugglewiththevolumeandcomplexityofmodernonlinecontent[58].Toaddressthechallenges
posedbyautomatedcontentmoderation,anotherwidelyadoptedapproachistointegratehuman
intervention,suchascommunity-basedcontentmoderationMechanisms[78],crowdsourcing[34]
oremployingprofessionalmediators.Thisinvolvesutilizingspecializedhumancontentmoderation
teamstoexecutethecontentmoderationtasks.Theseimplementationsaremorestraightforward
butlessadaptabletothenuancesofhumanlanguageandcontext,whichcanbetime-consuming
andlessscalable.Someinappropriatecontentmaystillbefreeofgrammaticalerrorsandsound
veryeloquent,makingitdifficultforevenexperiencedmoderatorstospotatfirstglance.
3 STUDY1:IMPACTCAPTIONVIDEOANALYSIS
TobetterunderstandexistingImpactCaptiondesign,wefirstperformedanin-depthvideo-based
analysis of popular TV series featuring Impact Captions. Our analysis focused on the visual
representationofImpactCaptions,theircontextualrelevance,designconsiderations,andtheirrole
asguidingelementsforincreasedviewerinterpretation.
3.1 Procedure
Weinitiallyconsultedthreeglobalinternetfilmandtelevisiondatabases,i.e.,IMDB1,TVTime2,and
Douban3,toidentifyhighlypopularvarietyshowsfromEastAsiathathadanairinghistoryofat
leasteightyearsandhadconsistentlyincorporatedImpactCaptioncontent.TheseincludedChina’s
1IMDB:https://www.imdb.com/
2TVTime:https://www.tvtime.com/
3Douban:https://www.douban.com/
5Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
WhoistheMurderer4,SouthKorea’sRunningMan5,andJapan’sVSARASHI6.Wethenwatched
the top three episodes from each show that had the highest viewership to gain a preliminary
understandingoftheshow’scontent.Whilewatching,weidentifiedthatImpactCaptionshad
severaldiversevisualdesignfeaturesthatinfluencedaudienceappealandmanipulationbasedon
previouslywork[64].Forexample,wefoundthatvideoswithImpactCaptionemployedaseriesof
strikingvisualdesignelements,includingvividcolorcontrasts,dynamictypographylayouts,and
theme-coordinatedbackgroundimages.
Followingthis,weexaminedYouTube7 andBilibili8 toanalyzecurrentdesigntrendsandthe
utilizationofImpactCaptionsinvarietyshowsontheseplatformsasonlinevideoplatformsallow
formoreexperimentationandinnovationinvisualdesigncomparedtomoreconstrainedtelevision
formats.Threeresearchersconductedkeywordsearchesonthesevideo-sharingplatforms(e.g.,
“varietyshowImpactCaption”,“ImpactCaptionintheTVprogram”and“videoImpactCaption”)to
findandselectrepresentativesamplesbasedonthenumberofviews.Afterfilteringoutirrelevant
andduplicatecontent,27videoswithanaveragedurationof43.23minutesand33.83kviewswere
selectedforanalysis.Theresearchersthenconductedindependentopencodingofasubsetofthe
videostoidentifycriticalaspectsofImpactCaptions,includingvisualelements,interactionpatterns,
andtheperspective,usingmethodsestablishedinpriorwork([53,64]).Followingmultiplerounds
ofreflectionanddiscussion,ataxonomyofImpactCaptionswasdeveloped,withthreetypesof
captionsthatspannedsevendesigndimensions(Figure2).Theoutcomesfromthisanalysiswere
usedtoinformoursubsequentresearchactivities.
3.2 IdentifiedCaptionTaxonomy
Withinourtaxonomy,threecategorizationsofcaptionswereidentified.
3.2.1 CaptionStyle1:VisualElements. Forthefirstcategorizationofcaption,twoprimarycate-
gorieswereidentified:TextualandNon-textualelements.Textualelementsconveyedinformation
likenamesanddialogueusingtypography,color,size,andorientation.Non-textualelements,used
speechbubbles,emoticons,andornamentstocatchviewers’attentionandconveyemotions.These
categoriescollaborativelyshapedImpactCaptions’visualandtextuallexicontoengageviewers.
3.2.2 CaptionStyle2:Multi-PerspectiveInformation. WithMulti-PerspectiveInformation,two
perspectiveswereused:firstpersonpointsofview(POV)andthirdpersonPOV.FirstpersonPOVs
centeredontheprotagonist’sperspective,directlydisclosingtheirexperiences,thoughts,actions,
andemotions.Thesecaptionswereinstrumentalinforginganempatheticconnectionbetween
theleadcharacterandtheaudience.Incontrast,thirdpersonPOVsofferedamorecomprehensive,
‘removed’ viewpoint, encompassing additional details, commentaries, and humorous response
styleslikeTsukkomi(Roasting),ExpositoryorHumorousandPraise.Thisapproachsignificantly
broadenedtheentertainmentvalueanddeepenedaudienceunderstanding,offeringanenriched
viewingexperience.
3.2.3 CaptionStyle3:InteractionPatterns. WithInteractivePatterns,threemethodsfacilitated
videointeraction:Interactivity,Spatiality,andFigurativeness.Interactivitywascharacterizedby
visualoranimatedelementswithinthevideoframethatcreateddynamicinteractions.Spatiality
adornedcharacterswithwearableelements,integratingvisualeffectsoranimationsthataltered
4WhoistheMurderer:https://en.wikipedia.org/wiki/Who%27s_the_Murderer
5RunningMan:https://en.wikipedia.org/wiki/Running_Man_(TV_video)
6VSARASHI:https://zh.wikipedia.org/wiki/VS%E5%B5%90
7YouTube:https://www.youtube.com/
8Bilibili:https://www.bilibili.com/
6DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
MULTI-PERSPECTIVE
VISUAL ELEMENTS INTERACTION PATTERNS
INFORMATION
Typography Onomatopoeia Static
Dynamic
Color Action
Interactive
Size Emotion
Floating in Screen
Orientation Monologue
Attached Characters
Speech Bubble Tsukkomi/ Roasting
Global Filters
Emoticon/ Memes Additional Info
With Entitles
Ornaments Transition
With Voice/ Audio
Fig.2. TheTaxonomyofImpactCaptionsthatwasidentifiedfromourvideo-basedanalysisofpopularonline
varietyshows.
thespatialarrangementofinformationonthescreen,includingdynamicannotationsfollowing
charactermovements.Figurativeness,usedvisualelementssuchaslyricsorsoundeffectdescriptors
inconjunctionwithauditorycomponentstoofferamultifacetedperspective,therebyenhancing
theoverallaudiovisualexperienceoftheviewer.
4 STUDY2:EXPERTCO-DESIGNWORKSHOP
Oncewedevelopedourtaxonomy,weconductedaco-designworkshoptosolicitdesigninsights
fromprofessionalsinvideopost-productionthatfocusedonhowtheywoulddesignImpactCaptions
topromotepro-socailbehavior.ThesedesigninsightswerethenusedwithinourDanModCap
systemtofosterprosocialbehaviorswhenusingDanmaku.
7
LAUTXET
LAUTXET-NON
WEIV
FO
TNIOP-TSRIF
WEIV
FO
TNIOP-DRIHT
YTIVITICARETNI
YTILAITAPS
SSENEVITARUGIFConferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
4.1 Participants
Weutilizedapurposivesamplingapproachtoensurethattheindividualswerecruitedpossessed
theexpertiseandexperiencerelevanttoourresearchfocus[12].Wehadtwoinclusioncriteria.
First,allparticipantsneededtohavedirectexperienceproducingvideoimpactcaptionsaspartof
theirvideopost-productionwork.Possessingsuchexperiencewouldenableparticipantstoprovide
insightsintothechallengesinvolvedinthisspecializedcraft.Section,participantswererequiredto
haveatleast1yearofexperienceinthevideopost-productionindustry.Thisensuredthattheyhad
accumulatedrichpracticalknowledgeandcouldprovidein-depthperspectivesonthechallenges
andneedsinImpactCaptioncreation.
Werecruitedsixparticipantsforourco-designworkshop.Thegroupwascomprisedofthreemales
andthreefemales(allagedbetween27and35)withbackgroundsspanningbroadcasting,television
editing and directing, and visual design Participants included motion graphic designers, video
editors,andpost-productionsupervisors,eachofwhomhadhands-onexperienceincorporating
videoimpactcaptionsintotheirwork.Toavoidbias,ourrecruitmentprocessintentionallyomitted
termslike“varietyshowImpactCaption”and“Danmaku”,insteadframingtheworkas“Designand
ResearchonVideoSharingPlatforms”.Whilethesmallnumberofparticipantscouldbeconsidered
apotentiallimitation,thedepthoftheirindustryexpertiseandspecializedknowledgeprovided
rich,context-specificinsightsthatinformedthesubsequentstagesofourresearch.
4.2 Procedure
Weutilizedatwo-phaseco-designsessionmethodologythatwasemployedinpriorwork[8,24,80].
Eachphaselastedonehour.
4.2.1 Phase1.GroupInterviewforSensitization. Thephasecommencedwitharesearchershowcas-
ingImpactCaptionexamplesfrompopularshowstoallparticipantstoclarifytheImpactCaption’s
designelements(Figure2).Semi-structuredinterviewsfollowed,focusingoneachparticipant’s
personalexperienceswithvideopost-production,especiallyinImpactCaptiondesign.Thisphase
exploredparticipantmotivationsanddesignconsiderationsandprovidedillustrativeexamplesof
variousImpactCaptionapplications.
4.2.2 Phase2.DesigningActivityandGroupDiscussion. Aftertheinterviews,participantsworked
togethertodevelopImpactCaptionsthatpromotedpositivesocialbehaviorwhenusingDanmaku.
They used the taxonomy derived in Section 3 to design Impact Captions that would create a
healthyonlineenvironment.TheyusedDanmakuvideosandcreativetools(suchasSlidesand
Figma)toconceptualizetheirideasandbrainstormedwaystointegrateImpactCaptionsintoa
Danmakumoderationtool.Theconversationcoveredviewerengagement,perceptions,challenges,
andpotentialsolutions.
4.3 DataCollectionandAnalysis
Withtheparticipants’consent,theirengagementduringthestudywasrecordedandtranscribed
intotext,andtheirdesignprototypeswerecollected.Then,usingthemethodologyproposedby
ChenandZhang,open-endedcodingofboththetranscriptsandprototypesfromtheworkshops
wereundertaken[61,65].Twoauthorsinitiallyselected20%ofthetranscribedtextsandprototype
designsforopencoding,reachingaconsensusonthecodingapproach.Followingthis,twoauthors
collaboratedtocodetheremainingdata.
Thecodingfocusedoncomponentswithineachmoderationdesign(e.g.,challenges,Impact
Captionelements,input,andoutput),workflows,contexts,andothervisualelements(e.g.,pre-
sentationstyle,textualcontent,andcolors).Thiscodingprocessdrewuponexistingresearchon
8DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
visualelements,implications,andinteractionpatternswithinvideocoding[15].Finally,oneauthor
categorizedallcodedcomponentsintothemes.
Table1. Themoderationanddesignchallengesidentifiedduringtheexpertco-designsessions.
Challenge Description
ModeratingDanmakuContent
Real-TimeNatureandScale Respondto,andprocess,alargeamountofreal-timeDanmakuinformation.
ComplexityofContent UnderstandandmoderateDanmakuthatcontainimplicitoffensivecontent,slang,puns,andculturally-specificexpressions.
Behavior Viewershavedifferentpersonalizationpreferences,whichmakesitdifficulttohandletheirchangingbehavior.
UnpredictabilityofUserCognition Viewershavedifferentdefinitionsofnegativeorirrelevantcomments,whichrequiresflexiblemoderation.
BalancingFreeSpeechandModeration Findingabalancebetweentheprotectionoffreeexpressionandappropriateregulation.
ImpactCaptionDesign
ContentRelevanceandTimeliness Thereneedstobeaclosecorrelationandreal-timeupdatingofDanmakucontentandthevideo’scontent.
CulturalSensitivityandAppropriateness Culturallyinsensitiveorcontroversialcontentneedstobeavoided.
VisualAppealandReadabilityConsistency ImpactCaptionshouldbevisuallyappealingwhileensuringtheirmessageiseasytounderstandandconsistent.
4.4 Results
Weidentifiedseveralchallengesthatparticipantsencounteredwhiledesigningcaptionstopromote
prosocialbehaviorforDanmakuthatrelatedtomoderatingcontentandthedesignofcaptions
themselves(Table1).Moderationchallengesincludedhandlingthescaleandreal-timenatureof
Danmakucomments,understandingnuanceslikeslangandculture-specificexpressions,managing
unpredictableuserbehavior,andbalancingfreespeechwithmoderation.Designchallenges,mean-
while,focusedonmaintainingrelevanceandtimeliness,avoidingculturallyinsensitivecontent,
andensuringvisualappealandconsistency.
5 DANMODCAPSYSTEMDESIGN
DanModCapintegrateslinguisticandvisualstrategieswhengeneratingImpactCaptionstofoster
emotionalresonanceandencourageprosocialbehavior.
5.1 DesignGoals
Basedonthechallengesidentifiedduringtheco-designworkshops(Section4),wederivedthree
designgoalsforDanModCap:
• G1:SupporttheproactivemoderationofDanmakuthroughtextualandnon-textualImpact
Captionelementstoimprovetheefficiencyofcurationandreducetheneedforpost-video
processing.
• G2: Encourage spontaneous prosocial user behavior for Danmaku-streaming content to
reducemoderationburdensandimprovetheoveralluserexperience.
• G3:Constructcognitiveandemotionalresonanceviatextualandnon-textualelementswhile
beingmindfulofrelevance,culturalsensitivity,andvisualappeal.
WithG1,wesoughttoactivelymanageDanmakucontentonvideoplatformsviaseveralmethods.
First,byimplementinganAI-basedautomaticcontentfilteringsystemwewantedtoanalyzethe
contentandemotionaltendenciesoftheDanmakuinrealtimeandidentifyandfilteroutundesired
words,offensivespeech,hatefulspeech,andinappropriatejokes.Second,thecreationofareal-time
monitoringmechanism,especiallyduringpeakhoursorwhenpopularprogramsarebroadcast,
wouldallowustoquicklyidentifyanddealwithproblematicDanmakuinformation.Lastly,we
wantedtounderstandcommunitynormssowecouldconveyclearDanmakuusagenorms.
9Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
WithG2,wewantedtoguideuserstoactivelyabidebycommunitynormsbypromotingpositive
andresponsiblesocialbehaviors.Wesoughttorealizethisinseveralways.First,througheduca-
tionalactivitiesandguidance,wewantedtohelpusersrealizeandunderstandtheimportanceof
communitynorms,encouragethemtoabidebythesenorms,andeducatethemonhowtouse
Danmakuwithresponsibilityandrespect.Rewardmechanisms(e.g.,positivefeedbackorresponses
suchasechoesandpraises)werealsodesignedtorecognizeusersandcommentsthatshowpositive
prosocialbehaviors.UserscanbeencouragedtoparticipateintheprocessofDanmakusupervision
bybringingpersonalperspectivestotheroleofcommunitymoderatorandencouragingpositive
interactionsbetweenuserstoreducenegativeorharmfulDanmakucontent.
WithG3,wewillharnessImpactCaptionstonurtureprosocialbehaviorwithinvideoplatform
communities.Ourcaptionswillbecraftedtoevokeemotionalresonancethroughrelatabletextand
graphicstoencourageactivecommunityengagement,offeringasubtlenudgetowardsthoughtful
participation.Celebratingpositivecontributionsthroughthesecaptionswillnotonlyhighlight
modelbehaviorbutalsosetacommunalstandard,motivatinguserstocontributetoarespectful
andengagingdialogue.
Insummary,ourapproachismorethancontentpolicingasitaimstofosteracommunityethos
wheremoderationisacollectiveendeavor,andpositiveengagementisthenorm.
5.2 TenantsofImpactCaptions
By leveraging verbal communication strategies and techniques to facilitate emotional support,
Danmaku-inspiredImpactCaptionscanfunctionnotonlyasavisualenhancementtoolbutalso
asasignificantmeansofshapingDanmakucultureandfosteringpositiveuserbehavior.Impact
Captionscanbethoughtofasresonanttriggersthataddaninteractivenarrativelayertocontent.
They translate intangible elements such as emotional responses or social themes into tangible
textual expressions to subtly guide viewer comprehension and emotional engagement. Impact
Captionscanalsofunctionaslinguisticmetaphors,playingapivotalroleintheclassificationand
conveyanceofemotionswithinDanmakucontent.Suchcaptionscanbedesignedtoalignwith
theemotionalstatesofviewersbyemployingcommonlyobservedonlinecommunicationstyles.
Withinthiswork,weusedtheTsukkomi(Roasts),Expository,andHumorousandPraiseresponse
styles.EachstyleservesauniquepurposewhenaugmentingDanmakuasoutlinednext.
Tsukkomi(Roasts)styleisutilizedwithnegativelyorientedDanmakucontent.Itleveragesan
informalcommunicationapproach,commonlyidentifyingloopholesorkeywordsinanother’s
languageorbehavior,followedbytheexpressionofironyordoubt.Accordingtointerpersonal
communication theory, thisstyle employs humorto addresscritical comments whileavoiding
excessivenegativity,thuspreventingthetreatmentofviewersas“emotionalgarbage”[36].For
instance,hyperbolicmetaphorsmightbeusedtohumorouslyaddressnarcissistictendencies,like
“这位自恋狂是不是以为自己是全宇宙的中心啊？你有皇位要继承吗? (Does this narcissist
thinktheyarethecenteroftheuniverse?Dotheyhaveathronetoinherit?)".Thisstylefacilitates
thecollectivecriticismofdisruptiveDanmakucontent,promotingemotionalregulationthrough
sharedcomplaints,whichcanengenderasenseofunityandintimacyamongstrangers[25,72].
TheExpositorystyleistargetedatDanmakuthatareirrelevantorambiguousandservesto
redirecttheviewer’sattentionbacktothevideo.Theuseofmetaphorsrelatedto’adventures’or
’deciphering,’suchas"前方高能！(Highenergyahead.)"or"路飞的尼卡太阳神形态来了！(Here
comesLuffyinhisSunGodNikaform!)",assistsinclarifyingthevideocontentfortheviewer.
Lastly,theHumorousandPraisestyleechoesandamplifiespositiveDanmakucontenttofoster
apleasantatmosphereandevokepositiveemotions.Itisusefulincontextsthatwarrantenjoyable
commentary,suchascompliments.Forexample,inavibranttravelvlog,employingphraseslike
"神仙UP主(God-tier UP)" or "优雅！实在是太优雅了！(Elegant! Truly, utterly elegant!)" can
10DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
Fig.3. DanModCap’sImpactCaptionGenerationModel,whichusedLDAtoextracttopicsfromDanmaku
andsupervisedlearningonapre-trainedmodeltoidentifyDanmakusentiment.Next,LLaMA2,which
incorporatespromptengineering,wasusedtogeneratemoderationtext.Followingthis,StableDiffusion
generatedaspeechbubble.
createalivelyDanmakuenvironment.Thisstyleenhancesviewerengagementandstrengthensthe
emotionalconnectionbetweentheviewerandthecontent,ultimatelyleadingtopositiveviewer
responses[42].
AshighlightedinSection4,employingbothfirst-personandthird-personperspectivesinImpact
Captions can also create a more intimate connection between the viewer and the video. The
first-personperspectiveisinstrumentalinforgingrichemotionalconnectionsasitcanmirror
personalizedandemotionalviewpointsakintothoseaviewermightnaturallyexpress.Thiscan
cultivateaninclusiveandcohesiveatmospherebyaligningwiththesentimentsorinclinations
presentedinDanmakucomments.Thedeliberatechoiceofpronounslike"we"insteadof"you"
or"they"contributestothisinclusiveenvironment,makingviewersfeeldirectlyaddressedand
involved, thus enhancing their emotional engagement. The third-person perspective provides
anobjectivelens,aidingviewersincomprehendingthecontextofthevideoandtheassociated
Danmakucomments.Thisperspectivecanemployanalyticalinsightstogeneratecommentsthat
expressobjectiveanddialecticalviewpoints.Thisapproachcanenrichtheviewer’sunderstanding
andexperiencebyofferingabroaderperspective.Itallowsforamoredetachedandcomprehensive
interpretationofthecontent,facilitatingbalancedandinformedengagementwiththevideo.
5.3 ImpactCaptionGenerationModel
DanModCapestablishesafeedbackloopbyanalyzingviewerreactionstoImpactCaptionsand
generatingImpactCaptionsthatadapttochangingviewerdiscussionsandemotionaldynamics.
Within DanModCap, there are three main steps for creating Impact Captions: (1) Identifying
DanmakuTopicsandSentiment,(2)AnalyzingDanmakuContextoverDifferentDurations,and(3)
GeneratingImpactCaptionTextandGraphics.
11Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
5.3.1 Step1:IdentifyingDanmakuTopicsandSentiment. ToidentifyDanmakubehavior,thecontent
andcontextofuserdiscussionsmustbecapturedwithinadesignatedtimeintervalandthenthe
sentimentandexpressedemotionsmustbeevaluatedtodiscerntheirbehavioralpatterns.Utilizing
LatentDirichletAllocation(LDA)[10],themaintopicsfromeachDanmakuwereextracted.LDA
waschosendueitssuitabilitytohandletextualdata,whichisnecessaryforDanmakucomments.
Thismethodisparticularlyaptforscenariosinvolvinglargevolumesofopen-endedcommentdata,
asitallowsfortheidentificationofthetopicswithinthedatawithouttheneedforpredefined
categoriesofthemes.Oncethetopicswereidentified,amulti-lingualfine-tunedBERTmodel[60],
trainedontheGoEmotionsdatasetwith28sentimentlabels,wasusedtocategorizetheemotions
expressedinthetopics.Thisapproachfacilitatedthecomprehensionofthecontentandsentiment
ofDanmakudiscussions.
5.3.2 Step2:AnalyzingDanmakuContextOverDifferentDurations. Followingtheextractionof
thecontenttopicsandsentiment,DanModCapthenassessedtheoverarchingcontextsharedby
multipleDanmakuwithinaspecifieddurationtocreateappropriateImpactCaptions.Informedby
insightsfromco-designsession(Section4),thedurationforImpactCaptionsshouldbeeither8
secondsor12seconds.Asaresult,separateresamplingandaggregationtechniqueswereapplied
to the Danmaku to construct the overall context and determine which duration was the most
suitable. As each Danmaku can acquire 28 logits of sentiment labels (as per the multi-lingual
BERTmodel),thesummationofthesevalueswithinthesamedurationenabledfortheselection
ofthehighestrepresentativesentimentforthatduration.Anaggregationofthecontentfromall
DanmakuwasthenconductedandLDAwasagainemployedtoextracthigh-levelsemanticthemes
thatencapsulatedthecontextduringthatduration.
5.3.3 Step3:GeneratingImpactCaptionTextandGraphics. InSection4,wefoundthatspeech-
relatedvisualrepresentationswerefrequentlyusedtovisuallyconveyinformationsuchasvoice-
oversorsupplementarydetails.Thisfindingledtothedecisiontoadoptspeechbubblestoelicit
emotionalconnectionsfromviewers,notjustforaesthetics[6,16]butalsotofosterasenseof
communitybyenhancingexpressiveness[6,16,22,47,71].
Inourdesign,speechbubbleshavetwoessentialcomponents,acolorandashape.Theseelements
shouldalignwiththeemotionaltoneofthetexttoamplifyemotionalresonanceandintensify
viewers’ sense of empathy and connection. For speech bubble color, Expository-style Impact
CaptionsemployabluecolortosymbolizecalmnesswhilemoderatingirrelevantDanmaku.In
contrast,theHumorousandPraise-styleImpactCaptions,whichrespondstopositiveDanmaku,
utilize orange to evoke warmth and happiness. The Tsukkomi (Roasts)-style captions, which
addressmorenegativelychargedDanmaku,useadarkredcolortodenotenegativity.Translucent
backgroundsarealsousedtomaintainvisualharmonywiththevideocontent.Forspeechbubble
shape,theshapeboundarieshavevaryingdegreesofsharpnesstoreflectthenatureoftheconveyed
emotions.Forexample,alightningbolt-shapeindicatesthatDanmakuisassociatedwithnegative
emotionstocommunicatetheintendedemotionalcontext.
TogeneratetheImpactCaptiontext,weutilizedLLaMA2withprompt-tuningontheChinese
dataset[60]togeneratetextcorrespondingtotheemotionsandthemesofDanmakufortheChinese
context[46,56].Weconstructedtheprompttoinstructthemodeltogivetherationalandregular
outputandusedthreeresponsetypes(i.e.,Tsukkomi,Expository,andHumorous/Praise)asinput
toevaluatetheeffectofmoderationfromthedifferentresponsestyles.
TogeneratetheImpactCaptionspeechbubbles,weusedLLaMA2togeneratepromptsasinput
forStableDiffusion([35])andusedStableDiffusiontogeneratevisualspeechbubbles.Inaddition,
wemappedcolorstosentimentsforvisualharmony.Aftergeneratingthetextandspeechbubbles,
wecombinedthemwithourscript.TheapplicationofLLaMA2notonlyenhancedthequalityof
12DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
thetextgenerationbutalsoimprovedthealignmentbetweenuseremotionsandvideocontent,
therebyincreasingtheaccuracyandeffectivenessofthegeneration.
ByintegratingLDA,LLaMA2,andStableDiffusion,DanModCapcouldunderstandandmodulate
thecontentofImpactCaptionstohandletherapidflowDanmakuanditsculturalnuances.Byusing
datapre-processing,topicextraction,andsentimentanalysis(Step1),alongsidetextgeneration
(Step3),andtheintelligentdesignofvisualelements(Step3),DanModCapshouldenableImpact
Captionstoresonateemotionallyandvisuallywiththeaudience.
5.3.4 AssessmentofImpactCaptionGenerationByExperts. TounderstandtheefficacyofDan-
ModCap’sImpactCaptiongeneration,weconductedapreliminaryexpertassessmentwithfour
professionalsfromvideodesign,psychology,linguistics,andhuman-computerinteraction.
WefirstselectedvideosfromthetopfivetrendingcategoriesontheBilibiliplatform,covering
GamesandEsports,Original,Anime,CarandTechchannels.Fromeachcategory,wechosetwo
videosthathadatleast50,000viewsand8,000Danmakucomments,andadurationofbetween
10and15minutes.Weinitiallycollected10videos,eachofwhichhadacomprehensiverangeof
responsetypes(i.e.,Tsukkomi/Roasts,Expository,andHumorousandPraise).Toenhancethe
depictionofvariedviewpointsandexperiences,eachvideowasclassifiedintooneoftwocategories
basedonitsnarrativeperspective:first-personorthird-person.Thisclassificationwasnecessaryto
generatetwouniquestylesofImpactCaptionsforeachvideo,guidedbytheirrespectiveDanmaku
data. Consequently, the original set of 10 videos was expanded to 20 individual versions, each
distinguished by its perspective and linguistic style, to enrich the diversity and depth of our
experimentalcontent.ImpactCaptionswerethengeneratedbyDanModCapforthevideos.
EachexpertwasrequiredtoviewatleastfivevideoswithembeddedImpactCaptions,onefrom
eachvideocategory.TheythenprovidedfeedbackonImpactCaptions’emotionalexpression,visual
design,andoverallefficacy,adheringtoestablishedevaluationcriteria.Interviewswereconducted
togatherexperts’opinionsandrecommendationstoimprovetheImpactCaptions.
Theopinionsandrecommendationsunderscoredthemodel’seffectivenessinenhancingviewer
engagement and providing emotional guidance. However, the timing and frequency of Impact
Captionsemergedassignificantconcerns.Expertsnotedthatconcurrentlydisplayingmultiple
Impact Captions created visual clutter. They also highlighted how authenticity and accurately
reflectingviewersentimentwaslostbecausepopularDanmakucommentswerenotdisplayed
alongsidetheImpactCaptions.Lastly,topreventimplicitlyharmfuloroffensivecommentsthat
mayyieldonlineconflicts,shiftingfromcriticismtohumorwasrecommended.
Thefeedbackshowedthatthelanguagethatwasgenerated,particularlywhenrespondingto
negativeDanmakuwiththeTsukkomi(Roasts)responsestyle,neededtoberevised.Thus,we
revisedDanModCap’sgenerationtorespondtonegatively-valencedDanmakuwithhumorand
jokeswhilereservingTsukkomi-stylelanguageforpositivecontentandcertainambiguousremarks.
Thisadjustmentsoughttofosteramoreengagingandpositiveviewingexperience.
5.4 DanModCap’sInterfaceandImplementation
Following the refinement of DanModCap’s Impact Caption generation model, we developed a
web-basedprototypeplatformthatwouldenablemoderatorst0modifycategories,playbackspeed,
andthescreenplacementofgeneratedImpactCaptionsandviewerstocustomizeImpactCaption
types,sources,andvisualdesignsbasedontheirindividualpreferences.
Thesystem’sinterfacewasdesignedtoreplicateanauthenticviewingexperience,resembling
Bilibili’svideoplaybackpage(Figure4).ByemulatingBilibili’swidescreenmode,theinterface
minimizespotentialdistractionsfromsecondaryvisualelementssuchasthesidebarandcomments,
thereby focusing on Danmaku comments and video interaction. The Danmaku Editor allows
13Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
multipleviewerstotransmitscreenmessagesconcurrently.Thesemessages,displayedalongside
theoriginalDanmakucontent,areessentialinputtotheImpactCaptiongenerationmodel.Using
anadaptivevisualpattern,ImpactCaption’sdynamicallyadjusttheircharactersizeinresponse
tothenumberofDanmakumessageswithinaspecifiedtimeframetoalleviatethevisualclutter
mentionedduringtheexpertassessment(Section5.3.4).
IntheAdminControl,userscanmakereal-timeadjustmentstothein-videodisplayofImpact
Captions.Afterlogginginasamoderator,theusercanadjusttheImpactCaptionsettings(including
theDanmakuscaleandcommentthreshold),choosevariousImpactCaptionstylesrangingfrom
firstpersonPoVTsukkomitothirdpersonPoVexplanations(orablendofthetwo),anddefine
displaypositions,embeddingmethods,andDanmakutextobscurationpreferencestocustomize
thevisuallayoutofImpactCaptions.
Fig.4. DanModCapInterfaceincludingtheAdminControl,anexampleImpactCaption,theVideoContent,
andtheDanmakuEditor.
5.4.1 Implementation. DesignedusingnativeJavaScript,CSS,andHTML,DanModCapusedby
Bootstrap[73]foritslayoutandFontAwe-some[28]foritsicons.p5.js[3]wasalsoutilizedto
developalayertodisplaythedynamicDanmakuandImpactCaptionsonthenativevideoplayer.
TointeractwiththeImpactCaptiongenerationmodel,theback-endusedtheFlaskFramework[2]
withPython3.GeneratedImpactCaptionswerestoredasstaticfilesonaback-endserverthatalso
loadedvariousvideoswithprepreparedDanmakuandperformedbasictaskssuchascountingthe
numberofreal-timeDanmaku.
6 DANMODCAPEVALUATION
WeconductedauserstudytounderstandtheinfluenceofgenerativeImpactCaptionsonviewers’
emotions, cognition, attitudes, and social behavior. The study aimed to address the following
researchquestions:
• RQ1:WhichemotionsandinformationareconveyedbyImpactCaptions?
14DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
• RQ2:HowdousersresonatewiththeemotionselicitedbyDanModCap’sImpactCaptions?
• RQ3:HowdoesDanModCapimpactusers’perceptionoftheDanmaku,thecommunity,and
VSPs?
• RQ4:WhichsocialbehaviorsdoesDanModCapelicit?
• RQ5:WhichpracticesdousersfollowwhenusingDanModCap?
6.1 Participants
Werecruited18participants(i.e.,ninemaleandninefemale)fromalocaluniversitytoparticipate
inourstudy.Snowballsamplingwasusedforrecruitment.Everyparticipantreportedwatchingand
commentingonvideosusingDanmakuatleastfivetimesperweekforoverayear.Allparticipants
werebetween20to29,aligningwiththepredominantviewergroup(49%)onBilibilibasedontheir
publishedviewerstatistics[1].Ourparticipantswerenotcompensated,andeachexperimentlasted
approximatelytwohours.
6.2 StudyStimuliandApparatus
Videosfromfivepopularvideogenreswereusedinthestudy(i.e.,Game&Esports,Knowledge
sharing,Lifestyle,Anime,andShortvideo)toincreasethegeneralizabilityandreliabilityofthe
resultsandincreasetheirappealtodifferentparticipants.Weselectedthetopthreemostwatched
videoswithineachgenretouseinthestudy.AsweweregoingtocreateImpactCaptionswith
twodifferentPOVs,thisresultedin30videosbeingprepared(i.e.,5genresx3videosx2PoV).
Tosupportreal-timeusage,DanModCapwasinstalledonthecomputersinalabwithinalocal
university.ItshouldbenotedthatasDanModCapusedpre-selectedvideosandonlyoneparticipant
participatedatatime,participantswerereactingtopre-generatedDanmakuratherthanDanmaku
generatedbyotherparticipants.
6.3 ProcedureandTask
Afterprovidinginformedconsent,participantsreceivedtrainingonhowtousetheDanModCap
system. They watched a 10-minute video on how to use the system. Then, they were tasked
withcontributingDanmakucommentstosimulatetherealisticusageofDanmakuonVSPs.Each
participantviewedaminimumoffivevideos(atleastonefromeachcategory),with5-10minute
breakinbetweeneachvideo.Videopresentationwascounterbalancedtopreventlearningeffects.
Aftercompletingthevideotask,semi-structuredinterviewswereconductedtounderstandthe
impact of generative Impact Captions on participants. Drawing inspiration from the Stimulus-
Organism-ResponseModelembeddedinthestructureofMediaSynchronyTheory[38,50,52],
the interview questions between participants and the video content (Table 2). This theoretical
frameworkallowedforadeeperexplorationofthedynamics,interactions,andenhancingeffectsof
generatedImpactCaptionsonparticipants.Additionally,valuableinformationaboutmoderation-
relatedcontentdesigncouldobtained.
6.4 ModerationDuringtheStudy
Duringapilotstudywithsixparticipants,wefoundthatparticipantshadadifficulttimeposting
spontaneousDanmakucommentswhileregulatingtheirviewsandemotions,i.e.,theyaimedto
maintainaneutralandunbiasedtoneintheircommentstoavoidrevealingtheirpersonalvalues
duringthepilotstudy.HavinganabundanceofneutralDanmakuthatdonotrequiremoderation
unlesstheywereirrelevanttothevideocontent,reducedopportunitiesforDanModCap’sfeatures
tobeexploredandexperimentedwith.Addressingthisrequiredtheintegrationofmoderatorsinto
theexperiment.Moderators’rolewastoartificiallyadjustthethresholdsofemotionaljudgment
andthegenerationofImpactCaptionstodeliberatelyfavormoreextremecontent.Thiswould
15Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
thencultivateanatmospherewherethegenerationofImpactCaptionsintensified,leadingtothe
formulationofactionablemetricstoimprovecontentmoderation.Theabundanceofemotionally
chargedcontentwouldalsoactasatrigger,compellingparticipantstoreactandprovidefeedback,
therebypromptingawiderspectrumofparticipantengagement andinteractiontoinvestigate
theaforementionedresearchquestions.Thismethodologicalchoicealsounveiledhowvarious
Danmakutypesinfluenceparticipants’emotions,cognition,andbehavior,therebycontributingto
moderationpractices.
6.5 DataCollectionandAnalysis
Followingpreviouscontentmoderationwork[40,54,81],weaudiorecordedeachsessionand
transcribedtherecordingsforlateranalysis.Togaininsightintoparticipants’perspectives,feelings,
andbehaviors,weperformedaqualitativeinterpretiveanalysis,inspiredbypriorwork[41].
6.6 Results
Webeginbypresentingfindingsrelatingtoparticipants’perceptionsofgenerativeImpactCaptions.
Wethenfocusonuserunderstandingandengagement,extendingbeyondsocialandcommunity
activismtoencompassuserattention,communitydynamics,andvideoplatforms.Weconclude
withresultsrelatedtomoderationpractices.
6.6.1 PerceptionsofGenerativeImpactCaptions. Herein,weexploreparticipant’sperceptionswith
respecttotheirperceivedcognitiveandemotionalresonanceandtheroleoftextualelementsin
ImpactCaptions.
PerceivedCognitiveResonance. Ourresearchfindingssuggestthatparticipants’cognitivereso-
nancewithImpactCaptionsstemsprimarilyfromtheircomprehensionoftheunderlyingintent
inthecaptions’creation.Thiscomprehensionwasrootedinsharedexperiencesandarticulated
intentions.Apredominantsegmentofparticipants(i.e.,P2-P11,andP13)reportedaheightened
understandingofImpactCaptionsandattributedthistoacongruencebetweenthecontentofthe
captionsandtheirthoughts,attitudes,andintentions.Forinstance,P9remarked,“havingfollowed
LOLgamesextensively,IamintimatelyfamiliarwiththediscourseinDanmaku;whenImpactCaptions
echoedsentimentsaboutaplayer’ssubparperformance,itresonateddeeply,reflectingacomprehen-
sionoftheperspectiveofane-sportsaficionado.” Thisalignmentfosteredadeeperconnectionand
resonancewiththeirexperiences.
Furthermore,severalparticipantsnotedhowImpactCaptionsthatmirroredtheirownopinions
orvaluesreinforcedtheirconnectiontothecontent.P4noted,‘oObservingunanimousDanmaku
praiseinvloggers’videosandcontributingsimilarcommentscreatesasharedatmosphere.Inthese
instances,IperceivetheImpactCaptionsasreflectingasimilardispositionandsenseofbelonging
toacommoncommunity.” Additionally,somehighlightedhowImpactCaptionsoftenarticulated
desirestheythemselvesharboredbuthadnotexpressed,providinganalternativeavenueforonline
expression,e.g.,“Idonotusuallyliketoexpressmyselfonline,butImpactCaptionsiskindalikea
representativethatcanspeakformeonline”(P1).
Perceived Emotional Resonance. Participants experienced emotional resonance when Impact
Captionsdisplayedemotionscongruentwiththeirown.Someparticipants(e.g.,P4,P7,P9andP13)
oftenfoundthemselvesvicariouslyexpressingemotionsthroughthesecaptions.Forexample,P9
shareddiscomfortwhenencounteringderogatoryonlinemessagesagainstafavoredteam,yetfound
solaceintheImpactCaptions’empatheticresponse.AsP9expressed,“whenIseemessagesonline
tauntingandcallingnamestoateamIsupportaftertheyloseagame,itmakesmeuncomfortable,
however,ImpactCaptionsseemedtounderstandmyemotionsandrespondedtotheothers.”
16DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
Wealsoobservedthatsomeparticipants(i.e.,P2,P7andP15)wereinfluencedbyImpactCaption’s
visualelements.Emotionswereoftenguidedbythevisualcuesofthecaptions,suchastheshape
andcolorofspeechbubblesintheTsukkomiresponsestyle,whichsomeparticipantsassociated
withfeelingsofangerandrepulsiontowardsprovocativeDanmaku.Forexample,P9mentioned,
“therewereinstanceswhenIwasfuriousatwhattheDanmakuweresayingandwasabouttoretaliate,
butthentheImpactCaptionsalsoappearedandexpressedtheirdisapproval,makingmefeelthatthey
werejustasdisgustedasIwaswiththeothers’comments.”
InterpretingTextualElementsinImpactCaptions. Allparticipantsdemonstratedanawareness
ofthepurposeoftextinImpactCaptionsandthecontextoftheiremergence.P3,forexample,
commented on the potency and appeal of the Tsukkomi response style finding it particularly
impactful,“Thisexpressionissopowerfulandinteresting,itistoofunny.” Otherparticipants,likeP1
andP8,perceivedthetoneofcertaincaptionsasmechanicalandrigidorlackingdistinctiveness,
particularlyintermsofthetext.Forexample,P1stated,“Iunderstandthepointofthetextdepictions,
butIdidnotfindanythingspecialordifferent.Maybetheonlydifferenceisthelengthbecausethese
areallshowninthevideo.Maybeexceptforthedifferentcolorandshapeunderneath,fromatextual
aspect,IdidnotfindtheseImpactCaptionstobedifferent.”
6.6.2 UserUnderstandingandEngagement. Ourstudyalsouncoveredseveralinterestingfindings
relatedtoparticipants’attention,senseofcommunityconnection,andheightenedawarenessof
VSPs’abilitytoutilizeuserdataforcontentgeneration.Italsoshedlightonhowparticipantswere
cognizantoftheirsocialimpactandresponsibilities.
TheDynamicsofAttention. Weidentifiedadynamicshiftinparticipants’attention,wherethey
wereinitiallydrawntoDanmaku,oftentimesattheexpenseoftheprimaryvideocontent.However,
theintroductionofImpactCaptionsgraduallyfosteredarealignmentoftheirfocuseithertowards
thecaptionsortowardsthevideo.ThiswasparticularlyprominentwithExpositoryresponsestyle
captions,whichdiscouragedoverindulgenceinDanmaku.AsnotedbyP2,“Ihaveactuallyforgotten
what this video is for, you know, I think it is fine to listen to the voice-over of the video is all, the
Danmakuismuchmoreexciting,soIammostlygoingtowatchthecontentoftheDanmakuandnot
payattentiontothevideoscreenbecausethescreenisnotthatimportant,Ithink.ThisImpactCaption
poppinguptotellmewhatthevideoisaboutisfine;ifitissomethingIaminterestedinandImissedit,
Iwillrewindandgobacktocheckitout.” AsubsetofparticipantsalsoreportedthatImpactCaptions
coulddiverttheirattentiontowardsDanmakucontent,e.g.,“InitiallyIwasunawareofwhatwas
goingonwithDanmaku,payingattentiontosee[thevideocreator]inmake-upandexplaining,and
suddenlynoticedwhattheImpactCaptionsweresayinginside‘注意言辞，尊重他人(Payattention
towordsandrespectothers)’,andIpausedtoseewhattheywerefightingabout.” (P4).
SensemakingforCommunityCohesion. Ourfindingsalsosuggestedthatparticipantsexperienced
aheightenedsenseofcommunitycohesion,characterizedbyfeelingsofbelongingandsecurity.
Weobservedthatcertainlinguisticconstructswereusedasadistinctandflexiblelanguageby
someparticipants(e.g.,P4,P9andP13).Thislanguageplayedacrucialroleincultivatingasenseof
groupbelongingandsharedinterests.ImpactCaptions’capabilitytoreflectparticipants’emotions
andperceptionssignificantlycontributedtoreinforcingthissenseofbelonging.P13remarked,“I
haveseentheKingofThievesvideowrittentoappear“感谢凯多老师！(Thankyou,Kaido-sensei!).”
,‘恭喜路飞新帝(CongratulationstoLuffyShindei!)’WhenIseetheDanmakuvideo,Ifeelthatit
[ImpactCaptions]andIarebothsecondarycharacterswhoalsowatchanimeandunderstandusand
thateveryoneswipessuchDanmaku.” AsP4expressed,"theImpactCaptionsfeltlikealike-minded
friend,accompanyingandinteractingwithmethroughoutthevideo."
17Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
Severalparticipants(P1,P7andP9)reportedasenseofsecuritywhenImpactCaptionsarticulated
theirunspokenthoughtsoremotions.P9notedhowImpactCaptionsprovidedavoiceforher
unexpressedthoughts:“therearetimeswhenIamafraidtopostDanmakuforfearofbeingcyberbullied,
especiallybysomefans,however,this[ImpactCaptions]makesmerelaxmystress,likeanalternative
tomyexpression,insteadofexpressingmyselfonapublicplatform,withthefeelingofbeingprotected.”
ImplicationsforSocietalEthosinVSPsUtilizingGenerativeAI. Wefoundsomeconsensusonthe
societalresponsibilitiesofvideoplatforms,especiallythoseemployinggenerativeAItechnologies
(i.e.,P1,P2,P13andP14).Contentontheseplatforms,rangingfromentertainmenttouser-generated
material,mirrorsandpotentiallymoldssocietalcultureandvalues.Danmakuoftenservesasaforum
forsocialdiscourse,influencingpublicconsciousnessandattitudes.ImpactCaptionscansubtly
guideparticipants’behaviorbyendorsingpositiveDanmakuinteractionsorcritiquingnegative
ones. P1 reflected how, “the deployment of Impact Captions carries inherent social responsibility.
Thesecaptionsdomorethanconveyinformation;theysteerDanmakutrends.Positivecaptionscan
fosteraconstructiveviewingatmosphere,whereasnegativeorsarcasticusemightdeteriorateit.Hence,
platformswithsuchcapabilitiesmustexercisediscretionintheirgenerativeuse,consideringthebroader
impactontheonlineenvironment.”
6.7 ModerationPractices
We also identified several moderation practises that Impact Captions had an impact on (e.g.,
selfreflection,self-regulation,sharinganddebatingdesires,andthespontaneousupholdingofa
community’sdiscourse).
Self-ReflectionFacilitatedByDanmakuLanguage. Someparticipants(i.e.,P7,P9andP12)spon-
taneously self-reflected on the speech patterns and word choices they used in Danmaku. This
introspectionwasprimarilytriggeredbytheperceptionthatthegeneratedImpactCaptionsmag-
nifiednegativeemotionsandremarks,adverselyaffectingtheviewingexperienceforothers.For
instance,P12thoughtthattheImpactCaptionsseemedtoberespondingdirectlytohisDanmaku
message,promptingare-evaluationofhiscontributions.Hereflected,“IwouldfeellikethatImpact
CaptionwastheretotrollmelikeanotherusersawmyDanmakuandcameovertoremindme.”
EmotionalSelf-RegulationandResilience. Otherparticipants(i.e.,P3,P4,P5,P7,andP14)reported
thattheydeployedstrategiesforemotionalself-regulationasareactiontoImpactCaptions,particu-
larlyduringheightenedemotionalfluctuation.Whileparticipantsgenerallyexhibitedtoleranceand
restrainttowardsoffensiveorirrelevantDanmakucontent,prolongedexposuretosuchcontent,and
particularlythatwhichinvolvedpersonalinsults,frequentlyprovokedstrongemotionalresponses.
Intheseinstances,ImpactCaptionsservedasaproxyforparticipants’reactions,alleviatingstress
andfacilitatinganemotionalequilibrium.Forexample,whenparticipantsencounteredderogatory
Danmaku,theyperceivedImpactCaptionsasameansofcounter-expression,helpingtoalleviate
theirirritationandprovidingasenseofsolidarity.
Inthiscontext,ImpactCaptionswerecatalystsforemotionalself-control.P7illustratedthis,“I
amveryuptightsometimeslikethatDanmakukeptsayingthatthatbloggerwasunattractive,itis
justalifeattack.Igetfuriousatthatkindofthing,andtheword‘舔(lick),’whichgirlsespeciallyhate,
isveryerotic,butaverbthesystemdoesnotrecognizeasasensitiveword,soitcannotbeblocked.
Nevertheless,atthispoint,ImpactCaptionsislikeawaytohelpmefightagainstthoseDanmaku,or
maybeIamnottheonlyonewhoresentsit.Themoodwasmuchbetterallofasudden.” Moreover,
someparticipantsnotedthatImpactCaptionshelpedreorienttheirfocusfromDanmakutovideo
content,especiallywhenencounteringexpositorycaptions(asdiscussedinSection6.6.2).
18DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
TransformationoftheSharingandDebatingDesire. ImpactCaptionswerealsofoundtoinfluence
participants’inclinationtoshareandexpressopinions,fosteringamoreproactiveapproachto
moderation.Reducedengagementinprovocative,conflicting,ornegativediscussionscharacterized
thisshift.SomeparticipantsadaptedtheirparticipationinDanmakubyreducingthefrequency
oftheircommentsasImpactCaptionsechoedtheirsentiments,ortransformingtheiroriginally
negativeorconfrontationalcommentsintopositivecontributions.P3commented,“whenImpact
Captionsarticulatemythoughts,Inolongerfeelcompelledtoexpressthemseparately”.Similarly,P8
andP13thoughtthatImpactCaptionssteeredthemtowardmorepositiveinteractions,prompting
themtodeletenegativemessagesandcontributemoreconstructively.AsP8said:“Irealizedthat
theimpactcaptionsaretryingtoguideme,tomakemedosomethingelse.Torelievemynegative
emotions,IwilldeletethenegativemessageorsomethingthatpeoplewouldnotlikeIwanttoshare
andrespondtothecalloftheImpactCaptions,eithergoingbacktowatchingvideosorjustcopying
theroastingcontentsaidbytheImpactCaptions,itisreallyfunny,tolivenuptheatmosphere.”
SpontaneouslyMaintaininganOnlineEnvironment. TheaffirmativenatureofImpactCaptions
inspiredseveralparticipantstoactivelysupportconstructiveDanmakucontent.Thisincludedmas-
siveDanmakuthattakeoverthescreen,echoingpositivecomments,andencouragingengagement
withvideocontent.Someparticipants(i.e.,P8,P11,P13,andP14)spontaneouslycontributedto
fosteringahealthyonlinediscourse,particularlyresonatingwiththepositivecommunityculture
reflectedintheImpactCaptions.AsP6stated,“Imadeaconsciousefforttomaintainapositivetone
inDanmaku,focusingdiscussionsonvideo-relatedtopicsandemployingneutrallanguagetoinitiate
newconversations.” WhileP11explained,“IwantedtomimicthebehaviorofthatImpactCaptions,it
mademefeellikeIwasn’taloneintryingtobeniceandtalknormallyonline.”
7 DISCUSSION
OurresearchuncoveredseveralnovelinsightsaboutImpactCaptionusage,potentialvideo-sharing
moderation approaches, how to implement automatic moderation by leveraging emotional an
cognitiveresonance,anduseropinionsaboutsuchmoderationtechniques.Herein,wehighlight
ourmainfindingsastheyrelatetothechallengesofDanmakucontentmoderation,thepotentialof
ImpactCaptions,andtherisksofautomatedcontentmoderationtools.
7.1 TheChallengesofDanmakuContentModerationonVSPs
Danmaku’sreal-time,succinctnatureaddsincreasedcomplexitytothemoderationprocess,arguably
exceedingthechallengesencounteredintraditionalsocialmediasettings.Ourstrategyforhandling
Danmakudataincludedcategorizingcontentbasedonitsemotionalsentimentandresponding
withinspecificdurations.OurexpertsnotedthedifficultiesinprocessinglargeamountsofDanmaku
andaccuratelyaddressingthediversityofcommentsthataremade(Section4).Similarly,participants
in our DanModCap user study (Section 6) reported mixed experiences, with some expressing
dissatisfactionwiththesystem’semotionrecognitioncapabilitiesandothersadvocatingformore
nuancedengagementwithcontentexhibitingnegativeemotions.Wealsofoundthatinappropriate
orharmfulDanmakucontentcanquicklyproliferate,thusadverselyaffectingtheviewingexperience
andtheoverallcommunityatmosphere.
Giventhesefindings,thesuccessfulmoderationofDanmakuthusrequiresadeepunderstanding
ofthecomplexrelationshipbetweenanonymity,freedomofexpression,andthepotentialtoxicity
associatedwithanonymity.Implementinginnovativemoderationstrategiesthateffectivelyaddress
these challenges can go a long way in maintaining a healthy and constructive community on
video-sharingplatforms.
19Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
7.2 ImpactCaptionsasaNovelModerationApproach
ThisresearchintroducedImpactCaptionsasawaytoautomaticallyandproactivelymoderate
Danmakucontentonvideo-sharingplatforms.ImpactCaptionscombinecognitiveandemotional
resonanceprincipleswithgenerativeAImodelstoenhancetheoverallqualityofsocialinteractions
whenusingVSPs.AlthoughImpactCaptionsfosteractiveuserparticipationinmoderationvia
bidirectionalcommunication,itremainsunclearwhetherthisapproachiseffectiveataddressing
allthechallengesrelatedtocontentmoderation.
Further,DanModCapusedgenerativeAImodelstocraftideogrammaticImpactCaptionsthat
were primarily in Chinese. While incorporating ideograms into Impact Captions can amplify
cultural resonance and emotional expressiveness, our findings also indicated a need for more
balancedandculturallysensitiveapproachestocontentmoderationonVSPstoeffectivelyaddress
thediverseculturalandcommunalperceptionsofonlineharm.Devisingauniversallyapplicable
contentmoderationpolicy,however,isadifficulttaskasitiscompoundedbydiversecultural,
communal,andindividualperceptionsofonlineharm.
7.3 RiskswithAutomatedModerationMethods
Ourresearchhasshownthatapplyingaffectivecomputingcanresultinmoreemotionallyresonant
ImpactCaptions,however,whenusedforcontentmoderation,itcanalsopresentseveralchallenges
thatrequirecontinuedresearch.Oneofthemostsignificantchallengesconcernsthedualeffects
of emotional resonance. Although designed to align with viewers’ emotions [19, 27], Impact
Captionscaninadvertentlyamplifynegativesentiments,leadingtoextremeresponsesoremotional
polarization.Therefore,itiscrucialtobalancetheenhancementofviewerengagementwiththe
riskofreinforcingnegativeemotionalstates.
Anotherchallengeistheriskofcreatingcontentbubblesthatareemotionalorfilteroutside
perspectives.Emotion-basedDanmakumoderationcaninadvertentlysurrounduserswithuniform
emotionalcontentthatmaycurtailtheirexposuretodiverseviewpointsandemotions[83].Filter
bubbles, which emerge from algorithmic content filtration, can lead users to only encounter
informationthatalignswiththeirpre-existinginterestsandviewpoints[20].Itispossiblethat
anover-relianceonalgorithmicfilteringinDanmakumoderationcouldexacerbatethesebubbles,
limitinginformationaldiversityandpotentiallyreinforcinguserbiases,thusobstructingopenand
variedcommunication.
Finally,anover-relianceonAIgeneratedcontentposesasignificantriskinrelationtoconsistency
andaccuracyoutput[14,75].Thepotentialinaccuraciesthatcanemergewhiletryingtogenerate
complexhumanemotionsandculturalsubtleties,coupledwiththereducedlevelofhumancreativity
andauthorship,canleadtoundesirableuserexperiences.
7.4 Summary
TheuseofImpactCaptionsforcontentmoderationwasanovelapproachtoenhanceuserexperi-
encesonVSPs,however,itiscrucialtoevaluatethepotentialrisksandchallengesassociatedwith
emotionalresonance,emotionalandfilterbubbles,andtheuseofLLMs.Futureresearchleveraging
ImpactCaptionsandaffectivecomputingmustoptimizethebenefitsofaffectivecomputingwhile
minimizingitsadverseeffectstoensureabalancedandresponsibleapproachtocontentmoderation.
8 LIMITATIONSANDFUTUREWORK
DespiteDanModCap’sdata-drivenimplementation,manydata-driventechnologiesexhibitlimita-
tionswhenunderstandinguser-generatedtextanditsconnectiontoothercontent.Inthecurrent
implementation,wefocusedonusingDanmakutexttogenerateImpactCaptions,asthistextual
20DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
dataprovidesvaluableinsightsintoviewers’emotionalresponses,attention,andcognitivestates
whileviewingvideos.However,ourlackofconsiderationofthevideocontentitselfmayresultin
ImpactCaptionsthatdonotalwaysaccuratelyreflectallthecontextualinformationavailableto
viewers.Thiscouldpotentiallyimpacttheconsistencyofthecaptions.Toaddresstheselimitations,
furtherresearchisneededtointegratevideocontentanalysis(suchasanalyzingvideocontent
using computer vision models) and multimodal sentiment analysis to enhance the contextual
understandingandgeneratedImpactCaptions.
WithinDanModCap,whenevertheweightedfrequencyofemotionalcommentssurpassedapre-
determinedthresholdwithinadesignatedtimeinterval,thesystemwouldinitiatethegeneration
ofmoreextremeanddiverseImpactCaptions.Thus,thesettingofthisthresholdplayedapivotal
roleindetermininghowthesystemreactedtotheintensityandnatureofDanmakuinteractions.
Consequently,ithadasignificantimpactontheoveralldynamicsofviewerengagementandcontent
moderation.Assuch,thegeneralizabilityofourresultsshouldbecarefullyconsideredinlightof
thismethodologicalchoice.
AlthoughDanModCapwasintendedtoconvertviewerfeedbackandemotionalempathyinto
visualfeedbackusingemotionalandcognitiveresonance,itseffectivenessdependsonaviewer’s
abilitytoexpressemotionsandtheircognitiveunderstanding.Notallviewersmayexhibitthesame
capacitytodosoorwillingnesstosharetheiremotions.Furthermore,becauseallparticipantswere
fromthesamelocalinstitution,theremaybeapotentialforsamplingbias,whereinparticipants’
reactionstothegeneratedImpactCaptionsmaydifferfromthosefromotherculturalbackgrounds.
Participants’familiarityandreceptivenesstotheconceptofDanmaku,whichhasitsoriginsin
EastAsianculture,mayhavealsoinfluencedtheirperceptionsandsuggestionsregardingImpact
Captions.Thisculturalpredispositioncouldpotentiallylimitthegeneralizabilityofourfindingsto
moreculturallydiverseusergroupswhomayhavedifferentviewingpreferencesandacceptance
thresholdsforvideoannotations.
WhileourDanModCapevaluation(Section6)providedvaluableinsightsintouserperceptions
andreactionstotheDanModCapmoderationapproach,thelimitedscaleandscopeofthecurrent
evaluationlimitsourabilitytodrawstrongconclusionsabouttheoveralleffectivenessofDan-
ModCap.Theevaluationfocusedprimarilyonexploringuserexperiencesanddidnotinvolvea
larger-scale,quantitativeassessmentofDanModCap’soutputs.Futureworkshouldconductamore
rigorous,large-scaleevaluationthatexaminesthedeploymenteffectivenessofDanModCapand
thenaturalreactionsofviewersviaanin-the-wildmethodology[26,70].
9 CONCLUSION
ThisresearchintroducedDanModCap,anLLM-basedtoolthatmoderatedDanmakucontenton
video-sharingplatformsthroughAI-generatedImpactCaptions.DanModCapaimedtoachieve
non-intrusivemoderationthroughcognitiveandemotionalresonance.Duringalab-basedstudy,we
foundthatImpactCaptionspositivelyimpactedviewers’emotions,cognition,attitudes,andexternal
socialbehaviors.Thesefindingsshedlightonthepotentialofautomated,generativeapproachesto
moderationonvideo-sharingplatforms.Ourapproachleveragedthecomplexdynamicsofonline
communitiesandprovidednewwaystobuildproactivecontentmoderationthroughresonant
experiencedesign.
21Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
REFERENCES
[1] 2023.BilibiliInterimReport. RetrievedSep05,2023fromhttps://ir.bilibili.com/media/zjdpfrvb/bilibili-inc-2023-interim-
report.pdf
[2] 2023.Flask. RetrievedSep05,2023fromhttps://flask.palletsprojects.com/
[3] 2023.p5.js. RetrievedSep05,2023fromhttps://p5js.org/
[4] PanosAchlioptas,MaksOvsjanikov,KilichbekHaydarov,MohamedElhoseiny,andLeonidasJGuibas.2021.Artemis:
Affectivelanguageforvisualart.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.
11569–11579.
[5] TawfiqAmmari,SaritaSchoenebeck,andDanielRomero.2019.Self-declaredthrowawayaccountsonReddit:How
platformaffordancesandsharednormsenableparentingdisclosureandsupport.ProceedingsoftheACMonHuman-
ComputerInteraction3,CSCW(2019),1–30.
[6] ToshikiAoki,RintaroChujo,KatsufumiMatsui,SaemiChoi,andAriHautasaari.2022. Emoballoon-conveying
emotionalarousalintextchatswithspeechballoons.InProceedingsofthe2022CHIConferenceonHumanFactorsin
ComputingSystems.1–16.
[7] QingchunBai,QinminVivianHu,LinhuiGe,andLiangHe.2019. Storiesthatbigdanmakudatacantellasanew
media.IEEEAccess7(2019),53509–53519.
[8] AvaBartolomeandShuoNiu.2023.ALiteratureReviewofVideo-SharingPlatformResearchinHCI.InProceedingsof
the2023CHIConferenceonHumanFactorsinComputingSystems.1–20.
[9] SuleymanBasaranandEyupDilber.2013. EffectsofCaptionedTVShowsonLanguageLearnersMotivationand
Perception.RespectusPhilologicus23,28(2013),83–96.
[10] DavidMBlei,AndrewYNg,andMichaelIJordan.2003. Latentdirichletallocation. JournalofmachineLearning
research3,Jan(2003),993–1022.
[11] JohannaBrewer,MorganRomine,andTLTaylor.2020.Inclusionatscale:Deployingacommunity-drivenmoderation
interventionontwitch.InProceedingsofthe2020ACMDesigningInteractiveSystemsConference.757–769.
[12] SteveCampbell,MelanieGreenwood,SarahPrior,TonieleShearer,KerrieWalkem,SarahYoung,DanielleBywaters,
andKimWalker.2020.Purposivesampling:complexorsimple?Researchcaseexamples.JournalofresearchinNursing
25,8(2020),652–661.
[13] EshwarChandrasekharan,MattiaSamory,AnirudhSrinivasan,andEricGilbert.2017. Thebagofcommunities:
Identifyingabusivebehavioronlinewithpreexistinginternetdata.InProceedingsofthe2017CHIconferenceonhuman
factorsincomputingsystems.3175–3187.
[14] CanyuChenandKaiShu.2023.Canllm-generatedmisinformationbedetected?arXivpreprintarXiv:2309.13788(2023).
[15] KevinChenandHaoqiZhang.2015.Remotepaperprototypetesting.InProceedingsofthe33rdannualACMconference
onhumanfactorsincomputingsystems.77–80.
[16] QinyueChen,YuchunYan,andHyeon-JeongSuk.2021.Bubblecoloringtovisualizethespeechemotion.InExtended
Abstractsofthe2021CHIConferenceonHumanFactorsinComputingSystems.1–6.
[17] YuanyuanChenandRebeccaCrawford.2022. Danmakucommenting:AnewinteractionexperienceonChina’s
streamingplatforms.WorldCinemaOnDemand:GlobalFilmCulturesintheEraofOnlineDistribution(2022),89.
[18] YueChen,QinGao,andPei-LuenPatrickRau.2017.Watchingamoviealoneyettogether:understandingreasonsfor
watchingDanmakuvideos.InternationalJournalofHuman–ComputerInteraction33,9(2017),731–743.
[19] YueChen,QinGao,QuanYuan,andYuanliTang.2019.Facilitatingstudents’interactioninMOOCsthroughtimeline-
anchoreddiscussion.InternationalJournalofHuman–ComputerInteraction35,19(2019),1781–1799.
[20] UthsavChitraandChristopherMusco.2020.Analyzingtheimpactoffilterbubblesonsocialnetworkpolarization.In
Proceedingsofthe13thInternationalConferenceonWebSearchandDataMining.115–123.
[21] StefanoCresci.2018.Harnessingthesocialsensingrevolution:challengesandopportunities.UniversityofPisa(2018).
[22] CaluãdeLacerdaPataca,MatthewWatkins,RoshanPeiris,SooyeonLee,andMattHuenerfauth.2023.Visualizationof
SpeechProsodyandEmotioninCaptions:AccessibilityforDeafandHard-of-HearingUsers.InProceedingsofthe2023
CHIConferenceonHumanFactorsinComputingSystems.1–15.
[23] JeanDecetyandMeghanMeyer.2008.Fromemotionresonancetoempathicunderstanding:Asocialdevelopmental
neuroscienceaccount.Developmentandpsychopathology20,4(2008),1053–1080.
[24] BriannaDym,NamitaPasupuleti,andCaseyFiesler.2022.Buildingapillowfort:Politicaltensionsinplatformdesign
andpolicy.ProceedingsoftheACMonHuman-ComputerInteraction6,GROUP(2022),1–23.
[25] NaomiEllemers,RussellSpears,andBertjanDoosje.2002.Selfandsocialidentity.Annualreviewofpsychology53,1
(2002),161–186.
[26] NeeleFalk,EvaMariaVecchi,ImanJundi,andGabriellaLapesa.2024.ModerationintheWild:InvestigatingUser-Driven
ModerationinOnlineDiscussions.InProceedingsofthe18thConferenceoftheEuropeanChapteroftheAssociationfor
ComputationalLinguistics(Volume1:LongPapers).992–1013.
22DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
[27] JiamingFang,LeiChen,ChaoWen,andVictorRPrybutok.2018.Co-viewingexperienceinvideowebsites:Theeffect
ofsocialpresenceone-loyalty.InternationalJournalofElectronicCommerce22,3(2018),446–476.
[28] Inc.Fonticons.2023.FontAwesome. RetrievedSep05,2023fromhttps://fontawesome.com/
[29] GabrielLuisSantosFreire,TalesPanoutsos,LucasPerez,FabricioBenevenuto,andFlavioFigueiredo.2022.Under-
standingEffectsofModerationandMigrationonOnlineVideoSharingPlatforms.InProceedingsofthe33rdACM
ConferenceonHypertextandSocialMedia.220–224.
[30] FedericoGalli,AndreaLoreggia,andGiovanniSartor.2022.TheRegulationofContentModeration.InInternational
ConferenceontheLegalChallengesoftheFourthIndustrialRevolution.Springer,63–87.
[31] VaishaliUGongane,MousamiVMunot,andAlwinDAnuse.2022.Detectionandmoderationofdetrimentalcontent
onsocialmediaplatforms:currentstatusandfuturedirections.SocialNetworkAnalysisandMining12,1(2022),129.
[32] RobertGorwa,ReubenBinns,andChristianKatzenbach.2020.Algorithmiccontentmoderation:Technicalandpolitical
challengesintheautomationofplatformgovernance.BigData&Society7,1(2020),2053951719897945.
[33] ChangyangHe,LuHe,TunLu,andBoLi.2021.BeyondEntertainment:UnpackingDanmakuandComments’Roleof
InformationSharingandSentimentExpressioninOnlineCrisisVideos.ProceedingsoftheACMonHuman-Computer
Interaction5,CSCW2(2021),1–27.
[34] DanulaHettiachchiandJorgeGoncalves.2019. Towardseffectivecrowd-poweredonlinecontentmoderation.In
Proceedingsofthe31stAustralianConferenceonHuman-Computer-Interaction.342–346.
[35] JonathanHo,AjayJain,andPieterAbbeel.2020. Denoisingdiffusionprobabilisticmodels. Advancesinneural
informationprocessingsystems33(2020),6840–6851.
[36] StefanGHofmann,JosephKCarpenter,andJoshuaCurtiss.2016.Interpersonalemotionregulationquestionnaire
(IERQ):Scaledevelopmentandpsychometriccharacteristics.Cognitivetherapyandresearch40(2016),341–356.
[37] AlešHorák,VítBaisa,andOndřejHerman.2021.TechnologicalApproachestoDetectingOnlineDisinformationand
Manipulation.ChallengingOnlinePropagandaandDisinformationinthe21stCentury(2021),139–166.
[38] JacobJacoby.2002.Stimulus-organism-responsereconsidered:anevolutionarystepinmodeling(consumer)behavior.
Journalofconsumerpsychology12,1(2002),51–57.
[39] ShagunJhaver,AmyBruckman,andEricGilbert.2019.Doestransparencyinmoderationreallymatter?Userbehavior
aftercontentremovalexplanationsonreddit.ProceedingsoftheACMonHuman-ComputerInteraction3,CSCW(2019),
1–27.
[40] ShagunJhaver,SuchetaGhoshal,AmyBruckman,andEricGilbert.2018.Onlineharassmentandcontentmoderation:
Thecaseofblocklists.ACMTransactionsonComputer-HumanInteraction(TOCHI)25,2(2018),1–33.
[41] ShagunJhaver,AliceQianZhang,QuanZeChen,NikhilaNatarajan,RuotongWang,andAmyXZhang.2023.
Personalizingcontentmoderationonsocialmedia:Userperspectivesonmoderationchoices,interfacedesign,and
labor.ProceedingsoftheACMonHuman-ComputerInteraction7,CSCW2(2023),1–33.
[42] OliverPJohnandJamesJGross.2004.Healthyandunhealthyemotionregulation:Personalityprocesses,individual
differences,andlifespandevelopment.Journalofpersonality72,6(2004),1301–1334.
[43] DavidKirsh.2013.Embodiedcognitionandthemagicalfutureofinteractiondesign.ACMTransactionsonComputer-
HumanInteraction(TOCHI)20,1(2013),1–30.
[44] ShamikaKlassenandCaseyFiesler.2023.TheStoop:SpeculationonPositiveFuturesofBlackDigitalSpaces.Proceedings
oftheACMonHuman-ComputerInteraction7,GROUP(2023),1–24.
[45] MahiKolla,SiddharthSalunkhe,EshwarChandrasekharan,andKoustuvSaha.2024.LLM-Mod:CanLargeLanguage
ModelsAssistContentModeration?.InExtendedAbstractsoftheCHIConferenceonHumanFactorsinComputing
Systems.1–8.
[46] DeepakKumar,YousefAbuHashem,andZakirDurumeric.2024. WatchYourLanguage:InvestigatingContent
ModerationwithLargeLanguageModels.arXivpreprintarXiv:2309.14517(2024).
[47] XingyuLan,YanqiuWu,andNanCao.2023.AffectiveVisualizationDesign:LeveragingtheEmotionalImpactofData.
arXivpreprintarXiv:2308.02831(2023).
[48] EffieLai-ChongLaw,VirpiRoto,MarcHassenzahl,ArnoldPOSVermeeren,andJokeKort.2009. Understanding,
scopinganddefininguserexperience:asurveyapproach.InProceedingsoftheSIGCHIconferenceonhumanfactorsin
computingsystems.719–728.
[49] JinyingLi.2017.Theinterfaceaffectofacontactzone:Danmakuonvideo-streamingplatforms.Asiascape:Digital
Asia4,3(2017),233–256.
[50] Mao-HuaLi.2019.Exploringshortvideoapplicationusers’visitintention:Applyingthestimulus-organism-response
model.AsianSocialScience15,12(2019),8–19.
[51] XiLin,MingyuHuang,andLeslieCordie.2018.Anexploratorystudy:usingDanmakuinonlinevideo-basedlectures.
EducationalMediaInternational55,3(2018),273–286.
[52] LiliLiu,AyoungSuh,andChristianWagner.2016.Watchingonlinevideosinteractively:theimpactofmediacapabilities
inChineseDanmakuvideosites.ChineseJournalofCommunication9,3(2016),283–303.
23Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
[53] SiwenLuandSijingLu.2022.ApostmodernanalysisofintralingualsubtitlesinChina’sweb-onlyvarietyshows:A
caseofMarsIntelligenceAgency.InternationalJournalofCommunication16(2022),21.
[54] RenkaiMaandYuboKou.2021."Howadvertiser-friendlyismyvideo?":YouTuber’sSocioeconomicInteractionswith
AlgorithmicContentModeration.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–25.
[55] TerenceEMcDonnell,ChristopherABail,andIddoTavory.2017.Atheoryofresonance.SociologicalTheory35,1
(2017),1–14.
[56] GabrielNicholasandAliyaBhatia.2023.TowardBetterAutomatedContentModerationinLow-ResourceLanguages.
JournalofOnlineTrustandSafety2,1(2023).
[57] ShuoNiu,ZhicongLu,AmyXZhang,JieCai,CarlaFGriggio,andHendrikHeuer.2023.BuildingCredibility,Trust,and
SafetyonVideo-SharingPlatforms.InExtendedAbstractsofthe2023CHIConferenceonHumanFactorsinComputing
Systems.1–7.
[58] ChikashiNobata,JoelTetreault,AchintThomas,YasharMehdad,andYiChang.2016.Abusivelanguagedetectionin
onlineusercontent.InProceedingsofthe25thinternationalconferenceonworldwideweb.145–153.
[59] JohnPavlopoulos,ProdromosMalakasiotis,andIonAndroutsopoulos.2017.Deeperattentiontoabusiveusercontent
moderation.InProceedingsofthe2017conferenceonempiricalmethodsinnaturallanguageprocessing.1125–1135.
[60] Telmo Pires, Eva Schlinger, and Dan Garrette. 2019. How multilingual is multilingual BERT? arXiv preprint
arXiv:1906.01502(2019).
[61] RoelPopping.2015.Analyzingopen-endedquestionsbymeansoftextanalysisprocedures.BulletinofSociological
Methodology/BulletindeMéthodologieSociologique128,1(2015),23–39.
[62] WeiQiao,TusharDogra,OtiliaStretcu,Yu-HanLyu,TiantianFang,DongjinKwon,Chun-TaLu,EnmingLuo,Yuan
Wang,Chih-ChunChia,etal.2024.ScalingUpLLMReviewsforGoogleAdsContentModeration.InProceedingsof
the17thACMInternationalConferenceonWebSearchandDataMining.1174–1175.
[63] MohammadRashidujjamanRifat,AshratuzZavinAsha,ShiveshJadon,XinyiYan,ShionGuha,andSyedIshtiaque
Ahmed.2024. CombatingIslamophobia:Compromise,Community,andHarmonyinMitigatingHarmfulOnline
Content.ACMTransactionsonSocialComputing(2024).
[64] RyokoSasamoto.2014.Impactcaptionasahighlightingdevice:AttemptsatviewermanipulationonTV.Discourse,
Context&Media6(2014),1–10.
[65] RyokoSasamoto,StephenDoherty,andMinakoO’Hagan.2021.The‘hookability’ofmultimodalimpactcaptions:A
mixed-methodsexploratorystudyofJapaneseTVviewers.Translation,Cognition&Behavior4,2(2021),253–280.
[66] MorganKlausScheuerman,JialunAaronJiang,CaseyFiesler,andJedRBrubaker.2021.Aframeworkofseverityfor
harmfulcontentonline.ProceedingsoftheACMonHuman-ComputerInteraction5,CSCW2(2021),1–33.
[67] CharlotteSchluger,JonathanPChang,CristianDanescu-Niculescu-Mizil,andKarenLevy.2022.ProactiveModeration
ofOnlineDiscussions:ExistingPracticesandthePotentialforAlgorithmicSupport. ProceedingsoftheACMon
Human-ComputerInteraction6,CSCW2(2022),1–27.
[68] JosephSeering,TianmiFang,LucaDamasco,Mianhong’Cherie’Chen,LikangSun,andGeoffKaufman.2019.Designing
userinterfaceelementstoimprovethequalityandcivilityofdiscourseinonlinecommentingbehaviors.InProceedings
ofthe2019CHIConferenceonHumanFactorsinComputingSystems.1–14.
[69] JosephSeering,RobertKraut,andLauraDabbish.2017. Shapingproandanti-socialbehaviorontwitchthrough
moderationandexample-setting.InProceedingsofthe2017ACMconferenceoncomputersupportedcooperativework
andsocialcomputing.111–125.
[70] DonghyunSon,ByounggyuLew,KwangheeChoi,YongsuBaek,SeungwooChoi,BeomjunShin,SungjooHa,and
BuruChang.2023.Reliabledecisionfrommultiplesubtasksthroughthresholdoptimization:Contentmoderationin
thewild.InProceedingsoftheSixteenthACMInternationalConferenceonWebSearchandDataMining.285–293.
[71] EScottStella.2007. BubbleStories:UsingComicBubblestoFacilitateDiscussionwithChildren. Ph.D.Dissertation.
CaliforniaStateUniversity,Northridge.
[72] JerrySuls,ReneMartin,andLaddWheeler.2002.Socialcomparison:Why,withwhom,andwithwhateffect?Current
directionsinpsychologicalscience11,5(2002),159–163.
[73] Bootstrapteam.2023.Bootstrap. RetrievedSep05,2023fromhttps://getbootstrap.com/
[74] HibbyThach,SamuelMayworm,DanielDelmonaco,andOliverHaimson.2022. (In)visiblemoderation:Adigital
ethnographyofmarginalizedusersandcontentmoderationonTwitchandReddit. newmedia&society (2022),
14614448221109804.
[75] AdakuUchendu,JooyoungLee,HuaShen,ThaiLe,DongwonLee,etal.2023.Doeshumancollaborationenhancethe
accuracyofidentifyingllm-generateddeepfaketexts?.InProceedingsoftheAAAIConferenceonHumanComputation
andCrowdsourcing,Vol.11.163–174.
[76] TamásVörös,SeanPaulBergeron,andKonstantinBerlin.2023.Webcontentfilteringthroughknowledgedistillation
oflargelanguagemodels.In2023IEEEInternationalConferenceonWebIntelligenceandIntelligentAgentTechnology
(WI-IAT).IEEE,357–361.
24DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
[77] QianWan,XinFeng,YiningBei,ZhiqiGao,andZhicongLu.2024.Metamorpheus:Interactive,Affective,andCreative
DreamNarrationThroughMetaphoricalVisualStorytelling.InProceedingsoftheCHIConferenceonHumanFactorsin
ComputingSystems.1–16.
[78] ChenlongWangandPabloLucas.2024.EfficiencyofCommunity-BasedContentModerationMechanisms:ADiscussion
FocusedonBirdwatch.GroupDecisionandNegotiation(2024),1–37.
[79] QunfangWu,YisiSang,andYunHuang.2019. Danmaku:Anewparadigmofsocialinteractionviaonlinevideos.
ACMTransactionsonSocialComputing2,2(2019),1–24.
[80] HaijunXia,HuiXinNg,ZhutianChen,andJamesHollan.2022.Millionsandbillionsofviews:Understandingpopular
scienceandknowledgecommunicationonvideo-sharingplatforms.InProceedingsoftheNinthACMConferenceon
Learning@Scale.163–174.
[81] RyanYen,LiFeng,BrindaMehra,ChingChristiePang,SiyingHu,andZhicongLu.2023. StoryChat:Designinga
Narrative-BasedViewerParticipationToolforLiveStreamingChatrooms.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems.1–18.
[82] Leticia-TianZhangandDanielCassany.2020.Makingsenseofdanmu:Coherenceinmassiveanonymouschatson
Bilibili.com.DiscourseStudies22,4(2020),483–502.
[83] AssemZhunis,GabrielLima,HyeonhoSong,JiyoungHan,andMeeyoungCha.2022.Emotionbubbles:Emotional
compositionofonlinediscoursebeforeandaftertheCOVID-19outbreak.InProceedingsoftheACMWebConference
2022.2603–2613.
25Conferenceacronym’XX,June03–05,2018,Woodstock,NY SiyingHU,etal.
A APPENDIX:PROMPTENGINEERING–CONSTRAININGOUTPUT
1 def gen_text_template(emotion28, emotion_dict, topics, comm_style, video_title , time_interval):
2 """Generating the moderation text by prompt template
3
4 :param emotion28: fine−grained word (28 emotional types) to describe the emotion of the majority of
danmaku
5 :type emotion28: str
6 :param emotion_dict: a dictionary representing commands related to the coarse−grained emotions (3
emotional types). Each dictionary has the following keys
7 − 'emotion': a string representing the emotion of the danmaku
8 − 'view': a string representing the moderation style based on the emotion of danmaku
9 − 'action ': a string representing the action of moderation based on the emotion of danmaku
10 :type emotion_dict: dict
11 :param topics: the main topics of the majority of danmaku
12 :type topics: str
13 :param comm_style: the communication style (3 types) to configure the generated text style
14 :type comm_style: str
15 :param video_title: the title of the video being moderated
16 :type video_title: str
17 :param time_interval: the time interval to configure the frequency of text−generating (moderation)
18 :type time_interval: int
19 :return: the generated moderation text
20 :rtype: str
21 """
22 prompt = """"Assuming you are a moderator responsible for reviewing barrage content and regulating user
behavior on a barrage video site. You notice that the barrages around {at_time} seconds of the
current video mainly discuss {topics}, with an overall {emotion3} and a sentiment tendency towards {
emotion28}. As a moderator, how would you generate an appropriate barrage in a {flower_type}
language style, from the perspective of {view}, to {action}? Please output your suggestion as a
string with a total word count of no more than 20 characters, ensuring only one output."""
23
24 data = {
25 "prompt": prompt.format(
26 at_time=time_interval,
27 emotion3=emotion_dict['emotion'],
28 flower_type=comm_style,
29 action=emotion_dict['action'],
30 video_title=video_title ,
31 topics=topics,
32 emotion28=emotion28,
33 view=emotion_dict['view']
34 ),
35 "temperature": 0.2
36 }
26DanModCap Conferenceacronym’XX,June03–05,2018,Woodstock,NY
B APPENDIX:EXAMPLEQUESTIONSUSEDINTHEDANMODCAPUSERSTUDY
Table2. Examplequestionnaireusedduringthesemi-structuredinterview,whichwasbasedontheStimulus-
Organism-ResponseModelthatispartofMediaSynchronyTheory.
Section ExampleQuestions Goals
1.1Inthecourseofinteractingwiththein- Thefactorsthatimpactedtheirperception
Stimulus
terface,didelements(suchasDanmakucom- ofthevideocontent.
mentsortext-basedandnon-textualeffects)
influenceorreshapethecomprehensionof
thevideocontent?
1.2Afterwatchingthevideo,whattransfor- The changes they noticed in their under-
mationsdidyounoticeinyourunderstand- standing.
ing?
2.1Whilewatchingthevideoandthegener- Theviewer’scognitive,emotional,andphys-
atedImpactCaption,didyouundergopar- iologicalreactionsandthefactorsthatled
ticularlyintenseemotionalresponses(such tothem.
asanger,happiness,orsurprise)?Canyou
pinpoint the specific elements of the gen-
eratedImpactCaptionthattriggeredthese
emotionalreactions?
2.2Consideringyourexperience,didthegen- HowtheImpactCaptioninfluencedtheirso-
Organism eratedImpactCaptioncontributetoanen- cialconnectionsandinteractionswithoth-
hancementorhindranceinyourconnection ers.
withotherviewers?
2.3 Did your emotional state impact your Thedegreetowhichtheirvideocontentin-
interpretationofthevideocontent,andto terpretationwasaffectedbytheiremotional
whatdegreedoyoubelievethisinfluence state.
occurred?
3.1 To what extent did the visual content Howaestheticsinfluencedtheirperceptions.
ofthegeneratedImpactCaptioninfluence
your attitude or perception of the related
Danmakuorvideocontent?
3.2TowhatextentdidthegeneratedImpact Howviewerresponseswereinfluencedby
Response Caption alter your interpretation or emo- theImpactCaption.
tionalresponsetotheDanmakucomments?
3.3Towhatextentdidthesechangesmoti- Whichbehavioralresponsesmanifested.
vateyoutoengageinactions,suchasjoin-
ingonlinecommunitiesorleavingDanmaku
commentsonthevideo?
27