Full error analysis of policy gradient learning algorithms for
exploratory linear quadratic mean-field control problem in
continuous time with common noise
Noufel FRIKHA∗ Huyên PHAM † Xuanye SONG‡
Abstract
We consider reinforcement learning (RL) methods for finding optimal policies in linear
quadratic (LQ) mean field control (MFC) problems over an infinite horizon in continuous
time, with common noise and entropy regularization. We study policy gradient (PG)
learning and first demonstrate convergence in a model-based setting by establishing a
suitable gradient domination condition. Next, our main contribution is a comprehensive
error analysis, where we prove the global linear convergence and sample complexity of
thePGalgorithmwithtwo-pointgradientestimatesinamodel-freesettingwithunknown
parameters. Inthissetting,theparameterizedoptimalpoliciesarelearnedfromsamplesof
the states and population distribution. Finally, we provide numerical evidence supporting
the convergence of our implemented algorithms.
Key words: Mean-field control; reinforcement learning; linear-quadratic; two-point gradient
estimation; Polyak-Lojasiewicz inequality; gradient descent; sample complexity.
Contents
1 Introduction 3
2 Problem formulation 5
2.1 Setup and preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2 Model free perspective and reparametrization . . . . . . . . . . . . . . . . . . . 7
∗Université Paris 1 Panthéon-Sorbonne, Centre d’Economie de la Sorbonne (CES), 106 Boulevard de
l’Hôpital, 75642 Paris Cedex 13, noufel.frikha at univ-paris1.fr. The work of this author has benefited from the
support of the Institut Europlace de Finance.
†LPSM, Université Paris Cité and Sorbonne University, pham at lpsm.paris. The work of this author is
partially supported by the BNP-PAR Chair “Futures of Quantitative Finance", and the Chair Finance & Sustainable
Development / the FiME Lab (Institut Europlace de Finance)
‡LPSM, Université Paris Cité, xsong at lpsm.paris; Research assistant at Hong Kong Polytechnic University.
1
4202
guA
5
]CO.htam[
1v98420.8042:viXra3 Model-based PG algorithm 10
3.1 Gradient domination condition . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3.2 Global convergence of model-based PG algorithm . . . . . . . . . . . . . . . . . 11
4 Model-free PG algorithm 14
4.1 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.2 Model-free PG algorithm with population simulator . . . . . . . . . . . . . . . . 15
5 Numerical example 19
5.1 Model-based algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
5.2 Model-free algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
A Explicit solution to LQ MFC 22
B Proof of Propositions 2.1 and 2.2 27
B.1 Proof of Proposition 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
B.2 Proof of the Proposition 2.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
C Proofs of results for model-based algorithms 30
C.1 Proof of Proposition 3.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
C.2 Proof of Theorem 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
C.3 Proof of Proposition 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
C.3.1 Auxiliary results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
C.3.2 Lipschitz regularity of Σ , Σˆ , K and Λ . . . . . . . . . . . . . . . . . . 38
θ ζ θ ζ
C.3.3 Proof of Proposition 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
D Proofs of the results for the model-free algorithm 40
D.1 Strategy of proof of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . 41
D.2 Proof of Theorem 4.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
D.3 Analysis of the single step GD algorithm . . . . . . . . . . . . . . . . . . . . . . 45
D.4 Error analysis of J and its gradient . . . . . . . . . . . . . . . . . . . . . . . . . 47
D.4.1 Proof of Proposition D.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
D.4.2 Proof of Proposition D.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
D.4.3 Proof of Proposition D.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
D.4.4 Proof of Proposition D.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
D.4.5 Proof of Proposition D.6. . . . . . . . . . . . . . . . . . . . . . . . . . . 62
21 Introduction
The last decade has seen significant advances in solving optimal control of dynamical systems
in unknown environments using reinforcement learning (RL) methods. The essence of RL is
to learn optimal decisions through trial and error, which involves repeatedly trying a policy,
observing the state, receiving and evaluating the reward, and subsequently improving the
policy. There are two main approaches in RL: (i) Q-learning, which is based on dynamic
programming, and (ii) policy gradient (PG), which is based on the parametrization of policies.
A key feature of RL is the exploration of the unknown environment to broaden the search
space, achievable through randomized policies. RL is a very active branch of machine learning.
For an overview of this field in the discrete-time setting, we refer to the second edition of the
monograph [20], and for recent advances in the continuous-time setting, see [14] and [15].
Mean-field control (MFC), also known as the McKean-Vlasov (MKV) control problem, is
a class of stochastic control problems that focuses on the study of large population models of
interacting agents who cooperate and act for collective welfare according to a central decision-
maker (or social planner). This field has attracted growing interest over the last decade,
resulting in a substantial body of literature on both its theory and its various applications in
economics, finance, population dynamics, social sciences, and herd behavior. For a detailed
treatment of the topic, we refer to the seminal two-volume monograph [4,5].
RLforMFChasrecentlyattractedattentionintheresearchcommunity,seee.g.[6],[11],[1],
[9], [19]. The challenge lies in accurately learning optimal policies and value functions defined
on the infinite-dimensional space of probability measures. The mathematical understanding
and convergence analysis of these RL algorithms are still in their infancy.
Inthispaper, weaimtoaddressquestionssurroundingconvergenceandsamplecomplexity,
focusingonpolicygradientmethodsinRLwithinthecontextofinfinitehorizonlinearquadratic
(LQ) MFC with common noise for continuous time systems. The LQ problem is indeed
the cornerstone of optimal control theory due to its tractability and can be viewed as an
approximationofmoregeneralnonlinearcontrolproblems. Toencourageexplorationinunknown
environments, we employ randomized policies and add entropy regularization, following the
approach of recent papers [14], [12], [22], [10], [21].
Our main contributions. Our paper proposes and analyzes convergent PG algorithms to
solveinfinitehorizonexploratoryLQMFCproblemsinacontinuoustimesetting,withcommon
noise and entropy regularization.
• Our first contribution is to derive the explicit form of the optimal solution using coupled
algebraic Riccati equations, thereby generalizing the results in [2] to include entropy
regularization for randomized policies (Theorem A.1). Motivated by the explicit form of
theoptimalrandomizedpolicy, wereformulatetheLQMFCproblemintoaminimization
3problem over Gaussian policies. The mean of each Gaussian policy being linear in the
state and conditional mean with respect to the common noise is parameterised using
two matrix-valued coefficients Θ = (θ,ζ). The parameterized cost function is shown
to be smooth and satisfy a gradient domination condition, also known as the Polyak-
Lojasiewicz inequality (Propositions 3.1 and 3.2) following the approach of [8] and [23].
Such inequality is known to be crucial to ensure the convergence of PG algorithms in
non-convex landscape.
• WethenproposeandstudyPGmethodsinbothexactandmodel-freesettings. Ourwork
provides theoretical guarantees of convergence for the gradient descent (GD) algorithms
with suitable step sizes (Theorems 3.1 and 4.1). In the model-free case, where the
exact gradient is unavailable, we adapt the two-point gradient estimation method of
[16] to our mean-field setting by relying on samples of discrete-time trajectories and
population distributions. For the first time to the best of our knowledge, we provide
a comprehensive error analysis accounting respectively for the error of perturbation
with respect to the exact expected functional cost, for the horizon truncation, for the
time and particle discretizations, for the statistical error and finally for the optimization
error from gradient iterations, demonstrating global linear convergence with polynomial
computational sample complexities.
Related works. The closest papers related to our work are [6] and [23]. In [6], the authors
consider an LQ MFC problem with common noise in a discrete time setting and prove the
convergence of PG algorithms for deterministic policies in both model-based and model-free
settings. The paper [23] addresses an infinite-horizon time average LQ MFC control problem
in a continuous time setting without an entropy regularizer and demonstrates the convergence
of PG with deterministic policies in the exact model-based setting, using a varying step size at
each iteration. Finally, it is worth mentioning that our proofs extend the arguments presented
in [8] and [13] for the discrete time setting, covering both finite and infinite horizons, as
well as those in [16] and [3] for the continuous time setting. In these references, the authors
demonstrated convergence results for standard LQ problems.
Outline. The paper is organized as follows. In Section 2, we formulate the exploratory
LQ MFC problem in continuous time with common noise, provide the theoretical optimal
policy, and discuss parameterization in the model-free case. In Section 3, we demonstrate
the convergence of the model-based gradient descent algorithm using the gradient domination
condition. Section 4 presents the gradient estimation algorithm employing the population
simulator and develops the convergence analysis of the model-free gradient descent algorithm.
In Section 5, we provide numerical experiments that illustrate our convergence results for
both the model-based and model-free algorithms. The proofs of all results are included in the
Appendix.
4Notations.
• We denote by x · y the scalar product between the two vectors x, y, and by M : N
= tr(MN⊺) the inner product of the two matrices M,N with compatible dimensions,
where N⊺ is the transpose matrix of N. The Frobenius norm of a matrix A is defined by
√
∥A∥ := A : A.
F
• Sd is the set of symmetric d×d matrices, and Sd (resp. Sd ) is the set of nonnegative
+ >+
(resp. positive definite) matrices in Sd. The partial order ≥ on Sd is defined as: M ≥ N
if M −N ∈ Sd. We also write M > 0 to mean that M ∈ Sd .
+ >+
2 Problem formulation
2.1 Setup and preliminaries
The linear dynamics of the mean-field state equation with randomized controls and common
noise is described by
(cid:104) (cid:90) (cid:105)
dX = BX +B¯E [X ]+D aπ (da) dt+γdW +γ dW0, (2.1)
t t 0 t t t 0 t
onaprobabilityspace(Ω,F,P)supportingtwoindependentBrownianmotionsW (theidiosyn-
cratic noise), and W0 (the common noise), of dimension d and d . For convenience, we
0
choose the probability space in the product form (Ω0×Ω1,F0⊗F1,P0⊗P1), and denote by
F1 = (F1) the right-continuous P1−completion of the canonical filtration generated by W,
t t≥0
and by F0 = (F0) the right-continuous P0−completion of the canonical filtration generated
t t≥0
by W0. The initial condition X is an Rd-random variable, which is G-measurable, where G is
0
a σ-algebra independent of (W,W0). We denote by F = F0∨F1∨G.
Here, E [.] stands for the conditional expectation given F0, B, B¯ are constant matrices in
0
Rd×d, D is a constant matrix in Rd×m, γ is a constant matrix in Rd×d, γ0 is a constant matrix
in Rd×d0, and in the sequel, we shall denote by Bˆ := B+B¯.
The randomized control π = (π ) is an F-progressively measurable process in P (Rm), the
t t 2
set of probability measures on the action space A = Rm with a finite second order moment.
We shall consider randomized controls π with densities a (cid:55)→ p (a), t ≥ 0.
t
TheinfinitehorizonLQMFCproblemconsistsinminimizingoversuchrandomizedcontrols
π the quadratic cost functional with entropy regularizer of parameter λ > 0:
(cid:104)(cid:90) ∞ (cid:16)
J(π;λ) = E e−βt X⊺QX +E [X ]⊺Q¯E [X ]
t t 0 t 0 t
0
(cid:90) (cid:90) (cid:17) (cid:105)
+ a⊺Ra π (da)+λ logp (a)π (da) dt .
t t t
5Here Q, Q¯ are constant matrices in Sd such that Q > 0, Qˆ := Q+Q¯ > 0 and R ∈ Sm . Notice
>+
that the cost functional is written equivalently as
(cid:104)(cid:90) ∞ (cid:16)
J(π;λ) = E e−βt (X −E [X ])⊺Q(X −E [X ])+E [X ]⊺QˆE [X ] (2.2)
t 0 t t 0 t 0 t 0 t
0
(cid:90) (cid:90) (cid:17) (cid:105)
+ a⊺Ra π (da)+λ logp (a)π (da) dt .
t t t
Assumption 2.1. The two following Algebraic Riccati Equations (ARE) for K ∈ Sd and
Λ ∈ Sd respectively admit a unique positive definite solutions:
−βK +KB+B⊺K +Q−KDR−1D⊺K = 0, (2.3)
−βΛ+ΛBˆ +Bˆ⊺Λ+Qˆ −ΛDR−1D⊺Λ = 0. (2.4)
Remark 2.1. According to Section 6 in [2], the condition: Q > 0,Qˆ = Q + Q¯ > 0,R >
0, guarantees the existence of positive definite solutions to (2.3)-(2.4) and Assumption 2.1 is
specifically for ensuring uniqueness.
UnderAssumption2.1,theoptimalrandomizedcontrol,solutionto(2.2)isgiveninfeedback
policy form as π∗ = π∗(.|X∗−E [X∗],E [X∗]), where π∗(.|y,z) is the normal distribution
t t 0 t 0 t
(cid:16) λ (cid:17)
π∗(.|y,z) = N −R−1D⊺Ky−R−1D⊺Λz; R−1 , y,z ∈ Rd, (2.5)
2
and where (X∗) is the state process with randomized control π∗ and (K,Λ) is the unique
t t∈[0,T]
positive definite solution to (2.3)-(2.4). Moreover, the optimal cost is given by
J(π∗;λ) = K : M +Λ : Mˆ +υ(λ) (2.6)
where
1 1
M := Var(X )+ γγ⊺, Mˆ := E[X ]E[X ]⊺+ γ γ⊺,
0 β 0 0 β 0 0
(2.7)
1(cid:16) λm λ (cid:12) (cid:12)(cid:17)
υ(λ) := − log(πλ)+ log(cid:12)det(R)(cid:12) .
β 2 2
Here, Var(X ) denotes the covariance matrix of X . In Appendix A, we state and prove this
0 0
result in a more general case.
Throughouttheremainderofthispaper,weshallalsoassumethatthefollowingassumption
is in force.
Assumption 2.2. M,Mˆ belongs to Sd , i.e. σ (M),σ (Mˆ) > 0, where σ (·) denotes
>+ min min min
the smallest eigenvalue of a square matrix.
Remark 2.2. The above assumption for M is satisfied when Var(X ) > 0. As for Mˆ, denoting
0
by γ¯
0
= [E[X 0], √1 γ 0] ∈ Rd×(d0+1), the augmented matrix formed by E[X 0] and γ 0, we have
β
Mˆ = γ¯ γ¯⊺. Thus, Mˆ > 0 if and only if γ¯ is of rank d, which requires that that d ≥ d−1.
0 0 0 0
62.2 Model free perspective and reparametrization
In this section, we are interested in the model-free setting for the linear mean-field dynamics
of state process, i.e., when the parameters B,B¯,D,γ,γ in (2.1) are unknown, and so the
0
optimal policy in (2.5) cannot be implemented from the unique solution to the Riccati system
(2.3)-(2.4).
Motivated by the Gaussian distribution of the optimal randomized policy, whose mean
is a linear combination of Y = X − E [X ] and Z = E [X ], we propose the following
t t 0 t t 0 t
parameterization of the randomized policy:
πΘ(·|y,z) = N(cid:0) θy+ζz; λ R−1(cid:1) , y,z ∈ Rd,
2
where Θ = (θ,ζ) ∈ (Rm×d)2 are the two-parameter matrices to be optimized. The density of
the parametrized randomized policy is explicitly given by
(cid:115)
a ∈ Rm (cid:55)−→ pΘ(y,z,a) = det(R) exp(cid:16) − 1(cid:0) a−(θy+ζz)(cid:1)⊺ R(cid:0) a−(θy+ζz)(cid:1)(cid:17) .
(πλ)m λ
The associated dynamics of the parametrized process (XΘ), starting from XΘ = X , is given
t 0 0
by
(cid:104) (cid:90) (cid:105)
dXΘ = BXΘ+B¯E [XΘ]+D aπΘ(da) dt+γdW +γ dW0, (2.8)
t t 0 t t t 0 t
where πΘ = πΘ(·|XΘ−E [XΘ],E [XΘ]), with density pΘ(a) = pΘ(XΘ−E [XΘ],E [XΘ],a).
t t 0 t 0 t t t 0 t 0 t
The corresponding cost function, now defined as a function on (Rm×d)2, is expressed (with a
slight abuse of notation) as follows:
J(θ,ζ;λ) := J(πΘ;λ)
(cid:104)(cid:90) ∞
= E e−βt(cid:0) (XΘ−E [XΘ])⊺Q(XΘ−E [XΘ])+E [XΘ]⊺QˆE [XΘ]
t 0 t t 0 t 0 t 0 t
0
(cid:90) (cid:90) (cid:17) (cid:105)
+ a⊺Ra πΘ(da)+λ logpΘ(a)πΘ(da) dt (2.9)
t t t
where Qˆ := Q+Q¯, with the objective of minimizing the parameterized cost function J(θ,ζ;λ)
over Θ = (θ,ζ) ∈ (Rm×d)2. It is clear from (2.5) that infJ(π;λ) = infJ(θ,ζ;λ), and the
π Θ
solution to this minimization problem is given by
θ∗ = −R−1D⊺K, ζ∗ = −R−1D⊺Λ, (2.10)
where (K,Λ) ∈ (Sd )2 is the solution to the ARE (2.3) and (2.4), ensuring that J(θ∗,ζ∗;λ) =
>+
J(π∗;λ).
7Let us introduce the parametrized auxiliary processes
YΘ = XΘ−E [XΘ], ZΘ = E [XΘ], t ≥ 0, Θ = (θ,ζ) ∈ (Rm×d)2.
t t 0 t t 0 t
By observing from the definition of πΘ = πΘ(·|YΘ,ZΘ) that
t t t
(cid:90) (cid:104)(cid:90) (cid:105)
aπΘ(da) = θYΘ+ζZΘ, E aπΘ(da) = ζZΘ,
t t t 0 t t
we see from (2.8) that the dynamics of (YΘ,ZΘ) is decoupled and governed by
(cid:40)
dYΘ = (B+Dθ)YΘdt+γdW ,
t t t t ≥ 0 (2.11)
dZΘ = (Bˆ +Dζ)ZΘ dt+γ0dW0,
t t t
with YΘ := Y = X −E[X ] and ZΘ := Z = E[X ]. Notice that YΘ (resp. ZΘ) depends on
0 0 0 0 0 0 0
Θ only via the first (resp. second) component parameter θ (resp. ζ), and we shall then write
Yθ = YΘ, Zζ = ZΘ.
Moreover, by noting that
(cid:90)
λm
a⊺RaπΘ(da) = θYθ +ζ(Zζ)⊺RθYθ +ζZζ +
t t t t t 2
(cid:90)
m m λ
logpΘ(a)π (da) = − (1+log(2π))− log| |
t t 2 2 2det(R)
the parametrized cost in (2.9) can be written as a quadratic function of (Yθ,Zζ), namely:
t t
(cid:104)(cid:90) ∞ (cid:16) (cid:17) (cid:105)
J(θ,ζ;λ) = E e−βt (Yθ)⊺(Q+θ⊺Rθ)Yθ +(Zζ)⊺(Qˆ +ζ⊺Rζ)Zζ dt +υ(λ),
t t t t
0
recalling that v(λ) is given by (2.7). An important observation is that it can be decomposed
as follows
J(θ,ζ;λ) = J (θ)+J (ζ)+υ(λ),
1 2
where
J (θ) := (cid:0) Q+θ⊺Rθ(cid:1) : Σ , J (ζ) := (cid:0) Qˆ +ζ⊺Rζ(cid:1) : Σˆ , (2.12)
1 θ 2 ζ
with
(cid:90) ∞ (cid:90) ∞
Σ := e−βtE(cid:2) Yθ(Yθ)⊺(cid:3) dt, Σˆ := e−βtE(cid:2) Zζ(Zζ)⊺(cid:3) dt, (2.13)
θ t t ζ t t
0 0
so that the minimization over Θ = (θ,ζ) amounts to separate minimization problems:
inf J (θ), and inf J (ζ). (2.14)
1 2
θ∈Rm×d ζ∈Rm×d
8In fact, we now demonstrate that the two aforementioned minimization problems over θ
and ζ can be reduced to suitable smaller sets defined by
(cid:110) β (cid:111) (cid:110) β (cid:111)
S = θ ∈ Rm×d : B− I +Dθ is stable , Sˆ = ζ ∈ Rm×d : Bˆ − I +Dζ is stable ,
d d
2 2
recalling that Bˆ = B+B¯, on which the problem is well-posed.
Lemma 2.1. The minimizers in (2.10) satisfy θ∗ ∈ S, ζ∗ ∈ Sˆ, and thus
inf J (θ) = inf J (θ), and inf J (θ) = inf J (θ).
1 1 2 2
θ∈Rm×d θ∈S ζ∈Rm×d ζ∈Sˆ
Proof. The ARE (2.3) for K rewrites as
β β
(B− I −DR−1D⊺K)⊺K +K(B− I −DR−1D⊺K) = −(Q+KDR−1D⊺K).(2.15)
d d
2 2
Since Q > 0 then Q+KDR−1D⊺K > 0 , hence all the eigenvalues of the matrix on the r.h.s.
of (2.15) are strictly negative. Moreover, since K > 0, if the matrix (B − βI −DR−1D⊺K)
2 d
has a non-negative real part eigenvalue, then the largest eigenvalue of the matrix on the l.h.s.
of (2.15) is non-negative and therefore cannot be equal to the matrix on the r.h.s. It follows
that B− βI −DR−1D⊺K is stable, which means tht θ∗ ∈ S.
2 d
Similarly, by using the ARE (2.4) for Λ, we show that Bˆ− βI −DR−1D⊺Λ is also stable,
2 d
i.e., ζ∗ ∈ Sˆ
We now state a characterization of the two matrices Σ and Σˆ defined in (2.13).
θ ζ
Proposition 2.1. For all θ ∈ S,ζ ∈ Sˆ, the matrices Σ and Σˆ are well-defined in Sd and are
θ ζ
the unique positive definite solution to the following Algebraic Lyapunov Equations (ALE):
−βΣ +(B+Dθ)Σ +Σ (B+Dθ)⊺+M = 0,
θ θ θ (2.16)
−βΣˆ +(Bˆ +Dζ)Σˆ +Σˆ (Bˆ +Dζ)⊺+Mˆ = 0.
ζ ζ ζ
Proof. Cf Appendix B.1
We conclude this section by providing an alternate useful expression of the cost functions
J andJ definedby(2.12)onwhichtheminimizationoverθ ∈S andζ ∈Sˆwillbeperformed.
1 2
Proposition 2.2. For all θ ∈ S,ζ ∈ Sˆ, we have
J (θ) = K : M, J (ζ) = Λ : Mˆ,
1 θ 2 ζ
where K and Λ are the unique elements in Sd solutions to the ALE
θ ζ >+
−βK +(B+Dθ)⊺K +K (B+Dθ)+Q+θ⊺Rθ = 0 (2.17)
θ θ θ
−βΛ +(Bˆ +Dζ)⊺Λ +Λ (Bˆ +Dζ)+Qˆ +ζ⊺Rζ = 0. (2.18)
ζ ζ ζ
Proof. Cf Appendix B.2
Remark 2.3. Note that, according to (2.6), we have K = K and Λ = Λ.
θ∗ ζ∗
93 Model-based PG algorithm
In this section, we establish the convergence of the gradient descent algorithm towards the
optimal parameters (θ∗,ζ∗) assuming full knowledge of the model parameters, thus allowing
for the exact computation of the gradient. This foundation will facilitate the learning of
optimal parameters in the model-free setting in the subsequent section, despite the nonconvex
optimizationframework. Furthermore,thegradientdescentmethodinthemodel-basedscenario
offersanalternativetosolvingtheRiccatisystem(2.3)-(2.4),whichiscomputationallyintensive,
while the convergence result (Theorem 3.1) remains dimension-free.
Given (θ ,ζ ) ∈ S ×Sˆ, the updating rule at step k ≥ 0 for the exact gradient descent of
[0] [0]
the minimization problem (2.14) is given by
(cid:40)
θ = θ −ρ∇J (θ ),
[k+1] [k] 1 [k] (3.1)
ζ = ζ −ρ∇J (ζ ),
[k+1] [k] 2 [k]
where ρ > 0 is the constant step size (learning rate), and ∇J (θ) and ∇J (ζ) are the gradients
1 2
of J and J with respect to their respective parameters.
1 2
3.1 Gradient domination condition
We first provide an explicit formula for the gradient that will be used for the implementation
of the (exact) gradient descent rule.
Proposition 3.1 (Expression of the gradients). For θ ∈ S, ζ ∈ Sˆ, it holds
∇J (θ) = 2E Σ , and ∇J (ζ) = 2Eˆ Σˆ ,
1 θ θ 2 ζ ζ
where E = Rθ+D⊺K and Eˆ = Rζ +D⊺Λ .
θ θ ζ ζ
Proof. Cf. Appendix C.1
Next, to assess the convergence of the aforementioned gradient descent algorithm in this
nonconvex landscape, we will demonstrate that the cost functions J and J satisfy a Polyak-
1 2
Lojasiewicz (PL) inequality on S and Sˆ, respectively, also known as the gradient domination
condition.
Proposition 3.2 (Gradient domination). There exist two positive constants κ ,κ > 0 such
1 2
that for any θ ∈ S,ζ ∈ Sˆ,
J (θ)−J (θ∗) ≤ κ ∥∇J (θ)∥2, and J (ζ)−J (ζ∗) ≤ κ ∥∇J (ζ)∥2.
1 1 1 1 F 2 2 2 2 F
More precisely, the constants κ and κ are given by
1 2
∥Σ ∥ ∥Σˆ ∥
θ∗ F ζ∗ F
κ = , κ = .
1 4σ min(R)σ m2 in(M) 2 4σ min(R)σ m2 in(Mˆ)
Proof. Cf. Appendix C.2
103.2 Global convergence of model-based PG algorithm
For fixed ℓ,ℓˆ∈ R , we define the level subsets of S and Sˆ as follows:
+
(cid:110) (cid:111) (cid:110) (cid:111)
S(ℓ) = θ ∈ S : J (θ) ≤ ℓ and Sˆ(ℓˆ) = ζ ∈ S : J (ζ) ≤ ℓˆ .
1 2
In the sequel, we shall naturally restrict to ℓ > J (θ∗) and ℓˆ> J (ζ∗) to avoid empty level sets.
1 2
We now show that both gradient maps θ (cid:55)→ ∇J (θ) and ζ (cid:55)→ ∇J (ζ) are Lipschitz-
1 2
continuous on S(a) and Sˆ(aˆ) respectively.
Proposition 3.3. There exist explicit positive constants
L(ℓ) = L(cid:0) ℓ;σ (Q),σ (M),∥R∥ ,∥D∥ ,J (θ∗)(cid:1) , (3.2)
min min F F 1
Lˆ(ℓˆ) = Lˆ(cid:0) ℓˆ;σ (Qˆ),σ (Mˆ),∥R∥ ,∥D∥ ,J (ζ∗)(cid:1) ,
min min F F 2
such that θ (cid:55)→ ∇J (θ) is L(ℓ)-Lipschitz continuous on S(ℓ) and ζ (cid:55)→ ∇J (ζ) is Lˆ(ℓˆ)-Lipschitz
1 2
continuous on Sˆ(ℓˆ), that is, for all θ,θ′ ∈ S(ℓ) and all ζ,ζ′ ∈ Sˆ(ℓˆ)
∥∇J (θ′)−∇J (θ)∥ ≤ L(ℓ)∥θ′−θ∥ , ∥∇J (ζ′)−∇J (ζ)∥ ≤ Lˆ(ℓˆ)∥ζ′−ζ∥ .
1 1 F F 2 2 F F
Proof. Cf. Appendix C.3
The following theorem is the main result of this section and states the linear convergence
rate of the gradient descent method. A key point is to prove that the sequence (θ ,ζ )
[k] [k] k≥0
always lies in S(ℓ)×Sˆ(ℓˆ) provided that one starts from an initial point (θ ,ζ ) ∈ S(ℓ)×Sˆ(ℓˆ)
[0] [0]
with a suitably chosen common step size ρ = ρ := ρ > 0.
θ ζ
Theorem 3.1 (Global convergence of the exact gradient descent method). Let (θ ,ζ ) ∈
[0] [0]
S(ℓ)×Sˆ(ℓˆ) and select a constant step size ρ ∈ (cid:0) 0, 2 (cid:1) where
Lˇ(ℓ,ℓˆ)
Lˇ(ℓ,ℓˆ) = max(cid:0) L(ℓ),Lˆ(ℓˆ)(cid:1) .
Then, the sequence (θ ,ζ ) generated by the exact GD algorithm (3.1) stays in S(ℓ)×Sˆ(ℓˆ).
[k] [k] k≥0
Moreover, for any fixed accuracy ε > 0, we achieve
J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ) ≤ ε
[k] [k]
with a number of iterations satisfying
log(cid:0) ε (cid:1)
J(θ ,ζ )−J(θ∗,ζ∗)
k ≥ [0] [0] ,
(cid:0) ρ(2−ρLˇ(ℓ,ℓˆ))(cid:1)
log 1−
2κ(ℓ,ℓˆ)
where
(cid:16) 2 (cid:17) 1
κ(ℓ,ℓˆ) = max κ ,κ , + .
1 2 Lˇ(ℓ,ℓˆ) 2
11Remark 3.1. In the model-based case, since we can compute J and J explicitly, one can
1 2
choose a = J (θ ) and aˆ = J (ζ ) for any (θ ,ζ ) ∈ S ×Sˆ.
1 [0] 2 [0] [0] [0]
The proof of the above convergence result is based on the following stability result which
shows that both S and Sˆ are stable by the one step transition of the GD algorithm.
Lemma 3.1. If θ ∈ S(ℓ),θ ̸= θ∗ and ζ ∈ Sˆ(ℓˆ),ζ ̸= ζ∗, then for all ρ ∈ (0, 2 ) =
Lˇ(ℓ,ℓˆ)
(0,min( 2 , 2 )), it holds
L(ℓ) Lˆ(ℓˆ)
θ := θ−ρ∇J (θ) ∈ S(ℓ), ζ := ζ −ρ∇J (ζ) ∈ Sˆ(ℓˆ).
ρ 1 ρ 2
Proof. For a fixed θ ∈ S(ℓ), we let
ρ = sup(cid:8) ρ′ ≥ 0 : θ−ρ∇J (θ) ∈ S(ℓ),∀ρ ∈ [0,ρ′](cid:9) .
max 1
From the first order Taylor expansion and the continuity of ∇J , one has
1
J (θ ) = J (θ)−ρ∥∇J (θ)∥2 +o(ρ).
1 ρ 1 1 F
Since θ ̸= θ∗, we have ∥∇J (θ)∥2 > 0 and then for all ρ small enough, we have J (θ ) ≤
1 F 1 ρ
J (θ) ≤ ℓ which implies that θ ∈ S(ℓ) and thus ρ > 0. Moreover, from Proposition C.1
1 ρ max
where it is shown that S(ℓ) is bounded, we deduce that ρ < +∞.
max
The definition of ρ implies that for any ρ ∈ (0,ρ ] and any t ∈ [0,1], tθ +(1−t)θ =
max max ρ
θ−(tρ)∇J (θ) = θ ∈ S(ℓ) since tρ ∈ (0,ρ ].
1 tρ max
Now the second-order Taylor’s expansion for J (θ) combined with the local Lipschitz
1
continuity of ∇J stated in Proposition 3.3 guarantees that
1
L(a)
J (θ ) ≤ J (θ)+⟨∇J (θ),θ −θ⟩+ ∥θ −θ∥2. (3.3)
1 ρ 1 1 ρ 2 ρ F
Suppose that ρ < 2 . From the continuity of ρ (cid:55)→ J (θ−ρ∇J (θ)), and the definition of
max L(ℓ) 1 1
S(ℓ), we have J (cid:0) θ−ρ ∇J (θ)(cid:1) = ℓ. Then, by (3.3), we get
1 max 1
ρ2L(a)
J (θ−ρ∇J (θ)) ≤ J (θ)−ρ∥∇J (θ)∥2 + ∥∇J (θ)∥2, (3.4)
1 1 1 1 F 2 1 F
which implies (as 2−ρ L(ℓ) > 0) that
max
(cid:0) (cid:1)
J θ−ρ ∇J (θ) < J (θ) ≤ ℓ.
1 max 1 1
ThiscontradictsthefactthatJ (cid:0) θ−ρ ∇J (θ)(cid:1) = ℓ. Therefore,weconcludethatρ ≥ 2
1 max 1 max L(ℓ)
and for all ρ ∈ (0, 2 ), θ = θ − ρ∇J (θ) ∈ S(ℓ). Similar arguments show the result for
L(ℓ) ρ 1
12ζ . In particular, one shows that for all ρ ∈ (0, 2 ), ζ ∈ Sˆ(ℓˆ). In conclusion, for all
ρ Lˆ(ℓˆ) ρ
ρ ∈ (0,min( 2 , 2 )), it holds at the same time
L(ℓ) Lˆ(aˆ)
θ := θ−ρ∇J (θ) ∈ S(ℓ) and ζ := ζ −ρ∇J (ζ) ∈ Sˆ(ℓˆ).
ρ 1 ρ 2
Proof of Theorem 3.1. Start from some fixed stabilizing initial parameter (θ ,ζ ) ∈
[0] [0]
S(ℓ)×Sˆ(ℓˆ). Since Lˇ(ℓ,ℓˆ) = max(L(ℓ),Lˆ(ℓˆ)), by choosing a step size ρ ∈ (0, 2 ), Lemma 3.1
Lˇ(ℓ,ℓˆ)
guarantees that
θ = θ −ρ∇J (θ ) ∈ S(ℓ), and ζ = ζ −ρ∇J (ζ ) ∈ Sˆ(ℓˆ).
[1] [0] 1 [0] [1] [0] 2 [0]
Moreover, by (3.4), the following inequalities hold

J (θ )−J (θ ) ≤
−ρ(2−ρLˇ(ℓ,ℓˆ))
∥∇J (θ )∥2
1 [1] 1 [0] 2 1 [0] F (3.5)
J 2(ζ [1])−J 2(ζ [0]) ≤ −ρ(2− 2ρLˇ(ℓ,ℓˆ)) ∥∇J 2(ζ [0])∥2 F.
The definition of κ(ℓ,ℓˆ) together with the gradient domination condition of Proposition 3.2,
ensures that for all θ ∈ S(ℓ), ζ ∈ Sˆ(ℓˆ)
J (θ)−J (θ∗) ≤ κ(ℓ,ℓˆ)∥∇J (θ)∥2, J (ζ)−J (ζ∗) ≤ κ(ℓ,ℓˆ)∥∇J (ζ)∥2,
1 1 1 F 2 1 2 F
and that for all ρ ∈ (cid:0) 0, 2 (cid:1)
Lˇ(ℓ,ℓˆ)
ρ(2−ρLˇ(ℓ,ℓˆ))
∈ (0,1).
2κ(ℓ,ℓˆ)
Hence, coming back to (3.5), we deduce
J (θ )−J (θ ) ≤
−ρ(2−ρLˇ(ℓ,ℓˆ))(cid:0)
J (θ )−J
(θ∗)(cid:1)
,
1 [1] 1 [0] 2κ(ℓ,ℓˆ) 1 [0] 1
J (ζ )−J (ζ ) ≤
−ρ(2−ρLˇ(ℓ,ℓˆ))(cid:0)
J (ζ )−J
(ζ∗)(cid:1)
.
2 [1] 2 [0] 2κ(ℓ,ℓˆ) 2 [0] 2
Summing the two previous inequalities, we obtain
(cid:0) (cid:1) (cid:0) (cid:1)
J(θ ,ζ ;λ)−J(θ ,ζ ;λ) = J (θ )−J (θ ) + J (ζ )−J (ζ )
[1] [1] [0] [0] 1 [1] 1 [0] 2 [1] 2 [0]
≤
−ρ(2−ρLˇ(ℓ,ℓˆ))(cid:0)
(J (θ )−J (θ∗))+(J (ζ )−J (ζ∗))(cid:1)
2κ(ℓ,ℓˆ) 1 [0] 1 2 [0] 2
−ρ(2−ρLˇ(ℓ,ℓˆ))
= (J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ)).
2κ(ℓ,ℓˆ) [0] [0]
13By a direct induction argument, at each step k ≥ 0, it holds
J(θ ,ζ ;λ)−J(θ ,ζ ;λ) ≤
−ρ(2−ρLˇ(ℓ,ℓˆ))(cid:0)
J(θ ,ζ
;λ)−J(θ∗,ζ∗;λ)(cid:1)
,
[k+1] [k+1] [k] [k] 2κ(ℓ,ℓˆ) [k] [k]
so that
J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ) ≤
(cid:16)
1−
ρ(2−ρLˇ(ℓ,ℓˆ))(cid:17)
(cid:0) J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ)(cid:1) .
[k+1] [k+1] 2κ(ℓ,ℓˆ) [k] [k]
We thus conclude
J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ) ≤
(cid:16)
1−
ρ(2−ρLˇ(ℓ,ℓˆ))(cid:17)k(cid:0)
J(θ ,ζ ;λ)−J(θ∗,ζ∗;λ)(cid:1) .
[k] [k] 2κ(ℓ,ℓˆ) [0] [0]
The above inequality readily leads to the rest of the assertions in the theorem. (cid:50)
Remark 3.2. The problem of the solvability of the Lyapunov equations (2.17)-(2.18) have been
investigated in [23]. The main difference with our result is that the authors in [23] have shown
that if θ ∈ S and ∥θ′ − θ∥ ≤ c(θ) with the perturbation c(θ) depending on θ then θ′ ∈ S.
Therefore, at each step θ′ = θ−ρ∇J(θ), they choose the step size ρ > 0 according to ∇J(θ) in
order to make ∥ρ∇J(θ)∥ = ∥θ′−θ∥ the perturbation less than c(θ).
Here, we adopt a different approach: we truncate S and define a compact subset S(ℓ). We
demonstrate that ∇J is Lipschitz continuous on S(ℓ) with a Lipschitz constant L(ℓ) and directly
choose the step size ρ > 0 according to L(ℓ), ensuring that the sequence (θ ) remains in
k k≥0
S(ℓ). Thus, ρ > 0 remains constant throughout all iterations. We refer to [16] for a detailed
description of the method we have extended to solve an LQ MFC problem. It is important to
note that in [16], the only source of randomness is the initial value.
4 Model-free PG algorithm
4.1 Notations
In the model-free setting, we do not have access to the values of the functions J and J , or
1 2
their gradients, as the model coefficients are unknown. Hence, we combine the two parameters
Θ = (θ,ζ) ∈ H = Rm×d ×Rm×d. The value function J +J is then regarded as a function
1 2
defined on H.
For all Θ = (θ,ζ) ∈ H, we define the norm of Θ by
(cid:113)
∥Θ∥ = ∥θ∥2 +∥ζ∥2,
H F F
and for Θ = (θ ,ζ ),Θ = (θ ,ζ ) ∈ H, their inner product is defined by
1 1 1 2 2 2
⟨Θ ,Θ ⟩ := θ : θ + ζ : ζ .
1 2 H 1 2 1 2
14We let
(cid:110) (cid:111)
R := Θ = (θ,ζ) ∈ H : (θ,ζ) ∈ S ×Sˆ ⊂ H,
and, for b > 0, we define the level subset of R by
(cid:110) (cid:111)
R(b) := Θ = (θ,ζ) ∈ R : Jˇ(Θ) ≤ b , (4.1)
where
Jˇ(Θ) := J(Θ;λ)−υ(λ) = J (θ)+J (ζ). (4.2)
1 2
Note that Jˇis obtained by removing the constant part that depends only on λ from J.
Since J and J are non-negative functions, one has R(b) ⊂ S(b)×Sˆ(b). Having shown
1 2
that both S(b) and Sˆ(b) are compact subsets of Rm×d, we get that R(b) is bounded. The
continuity of Jˇon H also implies that R(b) is closed. Since H is of finite dimension, we deduce
that R(b) is compact.
Finally, one can define the total gradient of J and Jˇas
∇Jˇ(Θ) = ∇ J(Θ;λ) := (∇ J(θ,ζ;λ),∇ J(θ,ζ;λ)) = (∇J (θ),∇J (ζ)).
Θ θ ζ 1 2
According to Theorem 3.2, the gradient domination inequality holds:
J(Θ;λ)−J(Θ∗;λ) = J (θ)−J (θ∗)+J (ζ)−J (ζ∗) ≤ κ∥∇J(Θ)∥2 , (4.3)
1 1 2 2 H
where κ = max{κ ,κ }. The same inequality also holds for Jˇ.
1 2
4.2 Model-free PG algorithm with population simulator
In the current model-free setting, we do not explicitly know the gradient ∇Jˇ(θ,ζ). Therefore,
the GD algorithm from the previous section cannot be directly applied. Instead, we rely
on a stochastic PG algorithm based on a stochastic population simulator, which provides an
approximation of the controlled MKV dynamics (2.8) along with the associated cost J (2.9).
For a finite terminal horizon T > 0 and a positive integer n, we consider the uniform time
grid of the interval [0,T] given by ∆ := ∆(T,n) = {0 = t < t < ··· < t = T} where t = lh,
0 1 n l
l = 0,1,...n, and h := T. For a given positive integer N, the N interacting agents system
n
with states (XΘ,∆,(j) ) evolves according to the dynamics
t 1≤j≤N;0≤l≤n
l
XΘ,∆,(j) = XΘ,∆,(j) +(BXΘ,∆,(j) +B¯µˆΘ,∆,N +DαΘ,∆,(j) )h
t l+1 t l t l t l t l (4.4)
+ γ(W(j) −W(j) )+γ (W0 −W0), j = 1,...,N, l = 0,··· ,n−1,
t l+1 t l 0 t l+1 t l
where XΘ,∆,(j) = X(j), µˆΘ,∆,N := 1 (cid:80)N XΘ,∆,(j), and the action that the j-th agent
0 0 t l N j=1 t l
takes at time t = t is drawn as αΘ,∆,(j) ∼ πΘ(·|XΘ,∆,(i) − µˆΘ,∆,N,µˆΘ,∆,N) independently
l t t t t
l l l l
15of ((W(j)) ,W0). Here, (W(j)) are i.i.d. d-dimensional Brownian motions on
j=1,...,N j=1,...,N
(Ω1,F1,P1) and W0 is the common noise on (Ω0,F0,P0), and (X(j) ) is independent of
0 1≤j≤N
((W(j)) ,W0).
j=1,...,N
In the spirit of [21], the population simulator samples the randomized actions αΘ,∆,(j) as
t
l
follows
αΘ,∆,(j) = θ(XΘ,∆,(j) −µˆΘ,∆,N)
t t t
l l l
(cid:114) (4.5)
λ
+ζµˆΘ,∆,N + R−1ξ(j) , j = 1,...,N, l = 0,...,n−1,
t l 2 t l
wheretheactionsimulationnoises (ξ(j) ) arei.i.d. randomvariablesindependent
t 1≤j≤N;0≤l≤n−1
l
of ((X(j) ,W(j)) ,W0) with law N(0,I ). In particular, one may assume that F is rich
0 j=1,...,N m 0
enough to support not only (X(j) ) but also the sequence (ξ(j) ) .
0 1≤j≤N t l 1≤j≤N;0≤l≤n
Introducing the notations w(j) = √1 (W(j) −W(j) ),w0 = √1 (W0 −W0), the dynamics
l h t l+1 t l l h t l+1 t l
(4.4) writes
(cid:16)
XΘ,∆,(j) = XΘ,∆,(j) + BXΘ,∆,(j) +B¯µˆΘ,∆,N +D(cid:0) θ(XΘ,∆,(j) −µˆΘ,∆,N)+ζµˆΘ,∆,N
t t t t t t t
l+1 l l l l l l
(cid:114)
+
λ R−1ξ(j)(cid:1)(cid:17) h+√
hγw(j)
+√
hγ w0, j = 1,...,N, l = 0,··· ,n−1,
2 t l l 0 l
(4.6)
and we notice that (XΘ,∆,(j)) are exchangeable in law.
j=1,...,N
The discounted running cost at time t of the j-th agent is defined by
l
RuncΘ,∆,(j) = e−βt l(cid:0) (XΘ,∆,(j) −µˆΘ,∆,N)⊺Q(XΘ,∆,(j) −µˆΘ,∆,N)+(µˆΘ,∆,N)⊺QˆµˆΘ,∆,N
t t t t t t t
l l l l l l l
+
(αΘ,∆,(j) )⊺RαΘ,∆,(j)(cid:1)
,
t t
l l
and the average cost estimation of the population over the interval [0,T] for a given Θ ∈ H is
given by
N n−1(cid:32)
J∆,N(Θ) := h (cid:88)(cid:88) RuncΘ,∆,(j)
pop N t l
j=1 l=0
(cid:33)
+λe−βt llogpΘ(XΘ,∆,(j) −µˆΘ,∆,N,µˆΘ,∆,N,αΘ,∆,(j) )
t t t t
l l l l
N (cid:32) n (4.7)
= h (cid:88) (cid:88) e−βt l(cid:0) (XΘ,∆,(j) −µˆΘ,∆,N)⊺Q(XΘ,∆,(j) −µˆΘ,∆,N)
N t l t l t l t l
j=1 l=1
+(µˆΘ,∆,N)⊺QˆµˆΘ,∆,N +(αΘ,∆,(j) )⊺RαΘ,∆,(j)
t t t t
l l l l
(cid:33)
+λlogpΘ(XΘ,∆,(j) −µˆΘ,∆,N,µˆΘ,∆,N,αΘ,∆,(j) )(cid:1)
.
t t t t
l l l l
16Notethat,sinceβ,λ > 0,RandthedensitypΘ areknown,thelasttermintheaboveexpression
can be computed explicitly.
In the spirit of [8], see also [7] and [6], we compute in Algorithm 1 a biased estimator of
the true gradient ∇Jˇ= (∇ Jˇ,∇ Jˇ) based solely on the average cost estimation (4.7). We let
θ ζ
B ⊂ Rm×d be the ball of radius r (with respect to the Frobenius norm) centered at the origin,
r
and S
r
= ∂B
r
be its boundary. The uniform distribution on S
r
is denoted by µS r.
Algorithm 1: Model Free Population-Based Gradient Estimation
Input data: Feedback parameters (θ,ζ) ∈ S ×Sˆ , number of agents N, number of
perturbations N˜, finite horizon T > 0, number of period of discrete grid n, radius r.
for i = 1,...,N˜ do
• Sample U
i
and V
i
i.i.d. ∼ µS
r
• Define perturbed feedback parameters
θ = θ+U ; ζ = ζ +V .
i i i i
• Sample J∆,N,i via the population simulator (4.7) for Θ = Θ = (θ ,ζ ) .
pop i i i
end
Return: The estimations of the gradient of the functional cost with respect to
Θ = (θ,ζ):
N˜
∇˜∆,N,popJ(Θ) = d 1 (cid:88) J∆,N,iU ,
θ r2N˜ pop i
i=1
N˜
∇˜∆,N,popJ(Θ) = d 1 (cid:88) J∆,N,iV .
ζ r2N˜ pop i
i=1
Wearenowinpositiontodefineour(stochastic)model-freePGalgorithm. Given(θ ,ζ ) ∈
[0] [0]
R(b), for some b > 0, recalling (4.1), we update the parameters as follows
θ = θ −ρ∇˜∆,N,popJ(θ ,ζ ), ζ = ζ −ρ∇˜∆,N,popJ(θ ,ζ ), k ≥ 0, (4.8)
[k+1] [k] θ [k] [k] [k+1] [k] ζ [k] [k]
for some well-chosen constant positive learning rate ρ.
Our main contribution is the following convergence result of the model-free PG sequence
(Θ := (θ ,ζ )) as given by (4.8).
[k] [k] [k] k≥0
17Theorem 4.1. Let ε > 0 be a prescribed accuracy and ρ ∈ (0, 4 ) be the constant learning
9Lˇ(b)
rate. Then, choosing r small enough such that
(cid:16) 1 1 (cid:17)
r ≤ r˘(ε) := min rˇ(b), , ,
h r(b,1/( 101√ 2(cid:112) κε)) h′ r(b,1/( 101√ 2(cid:112) κε))
recalling that κ is the coefficient in the gradient domination condition appearing in (4.3),
choosing T large enough such that
√
(cid:114)
T ≥ T˘(ε) :=
1 log(cid:0)10 2dc 1(2b) κ
),
c (2b) r˘(ε) ε
2
choosing the number of periods in the grid n large enough such that
√
10 2dT˘(ε)c (2b)(cid:114) κ
3
n ≥ n˘(ε) := ,
r˘(ε) ε
taking the number of particles N large enough such that
√
10 2dc
(2b,T˘(ε),n˘(ε))(cid:114)
κ
N ≥ N˘(ε) := 4 ,
r˘(ε) ε
and finally taking the number of samples N˜ in Algorithm 1 large enough such that
(cid:26) (cid:114) (cid:114) (cid:27)
N˜ ≥ N˘˜(ε) :=max h (b, 1 ,1/( 1 √ ε )),h′ (b, 1 ,T˘(ε),n˘(ε),N˘(ε),1/( 1 √ ε )) ,
N˜ r˘(ε) 10 2 κ N˜ r˘(ε) 10 2 κ
it holds
J(Θ )−J(Θ∗) ≤ ε
[k]
√ √
with probability at least 1−4k(cid:0)10 √2d κ(cid:1)−d in at most
ε
(cid:0) ε (cid:1) (cid:0) ρ(4−9ρLˇ(b))(cid:1)
k ≥ log /log 1−
J(Θ )−J(Θ∗) 8κ¯(b)
[0]
iterations.
TheproofisdeferredtoSectionDoftheappendix. Intheaboveconvergenceresult,rˇ(b),h ,
r
h′, c (2b), c (2b), c (2b), c (2b), h and h′ are explicit functions whose definition is provided
r 1 2 3 4 N˜ N˜
in the proof. In particular, rˇ(b) is defined in Lemma D.1, h ,h′ are defined in Propositions
r r
D.2, D.5, c (2b), c (2b) are defined in Proposition D.3, c (2b) is defined in Proposition D.4,
1 2 3
c (2b) is defined in Proposition D.6 and h ,h′ are defined in Propositions D.2, D.5.
4 N˜ N˜
Remark 4.1. Regarding the choice of b, we recall the definition of the level set, in (4.1)-(4.2)-
and b > 0 is the superior limit of Jˇ, where Jˇis the expected function cost J in which we removed
the known constant υ(λ) (since β > 0,λ > 0,R are known). Hence, a natural choice is to take
b ≥ Jˇ(Θ ) = J(Θ )−υ(λ) and one can replace J(Θ ) by its sample average approximation
[0] [0] [0]
using the average cost estimation of the population (4.7).
185 Numerical example
We demonstrate the convergence analysis of our algorithms using a one-dimensional example
with the following model parameters:
Q Qˆ B Bˆ β γ γ D R X
0 0
0.1 0.2 0.1 0.2 20 0.05 0.05 0.05 0.2 N(1,1)
Table 1: The parameters of the model
The optimal parameters (2.10) are (θ∗,ζ∗) = (−0.00126,−0.00255). Thus, the optimal
cost is given by J (θ∗) = 0.005051, J (ζ∗) = 0.010205. Both model-based and model-free
1 2
algorithms are initialized with (θ ,ζ ) = (−2,−2).
[0] [0]
5.1 Model-based algorithm
In the model-based case, we can derive explicit formulas for θ (cid:55)→ J (θ) and ζ (cid:55)→ J (ζ), along
1 2
with their derivatives J′(θ) and J′(ζ), using the results obtained in Sections 2 and 3.
1 2
We evaluate the PG algorithm (Algorithm 3.1) using three different step sizes: ρ =
0.5,0.9,1.2. Figure 1 illustrates the convergence of the sequence (θ ,ζ ) towards (θ⋆,ζ⋆)
[k] [k] n≥0
in terms of the number of iterations.
Figure 1: Convergence of the sequence (θ ,ζ ) towards (θ⋆, ζ⋆) (dashed lines).
[k] [k] k≥0
Then, Figure 2 illustrates the convergence of the cost functions J and J by plotting the
1 2
relative errors k (cid:55)→ (J (θ )−J (θ∗))/J (θ∗) and k (cid:55)→ (J (ζ )−J (ζ∗))/J (ζ∗).
1 [k] 1 1 2 [k] 2 2
19Figure 2: Convergence of the error rates (J (θ )) − J (θ⋆))/J (θ⋆) and (J (ζ ) −
1 [k] 1 1 2 [k]
J (ζ⋆))/J (θ⋆).
2 2
The PG algorithm 3.1 demonstrates very good performance. The error and the error rate
of the value function converge to zero after roughly 200 iterations for different values of the
learning rate.
5.2 Model-free algorithm
We use the following parameter values for the model-free PG algorithm:
T n N N˜ r λ
1 100 100 100 0.05 0.001
Table 2: Parameters of the model-free PG algorithm.
The optimal cost corresponding to the parameters given in Table 1 is J(θ∗,ζ∗) = 0.015360.
First, we test whether the parameters in Table 2 allow for accurate gradient estimations. In
Figure 3, we evaluate this for (θ ,ζ ) = (−2,−2), by generating 100 gradient estimations
[0] [0]
using the gradient estimation algorithm (Algorithm 1).
20Figure 3: 100 gradient estimations vs exact values of ∇ J(θ,ζ) and ∇ J(θ,ζ) (dashed lines).
θ ζ
Inthefiguresabove,theverticalcoordinatesofthepointsrepresenttheestimatedgradients,
with the dashed line indicating the exact gradients. We observe that most points cluster
around the dashed line, remaining within 10−2 above and below it. This suggests that, with
high probability, the error in gradient estimation is controlled within 10−2, indicating that the
parameters in Table 2 are well-chosen.
Our main result (Theorem 4.1) is established for a constant step size ρ > 0. However, from
a numerical standpoint, one might consider exploring adaptive selection of ρ by adjusting it
based on the observed behavior of the cost function J. Specifically, if ρ > 0 is in an acceptable
interval (an open interval), the cost function J should decrease. According to the findings
of the model-based algorithm, increasing ρ (while ensuring it remains within the acceptable
interval) may accelerate convergence.
Therefore, we can initialize with a ρ > 0 and run the algorithm for several iterations (e.g.,
100) initially. If we observe a clear downward trend in the (estimated) cost function J, it
indicates that our chosen ρ > 0 falls within the acceptable interval. We can then consider
increasing ρ slightly to potentially accelerate convergence. Conversely, if we do not observe a
decreasing trend, we should consider reducing ρ > 0.
The above results are based on the following choice of the step size as a function of the
iteration index k:

0.5 if k ≤ 100,


ρ(k) = 0.9 if 100 < k ≤ 200,

 1.2 if 200 < k ≤ 350
In Figure 4, we observe the convergence of both sequences (θ ) and (ζ ) towards
[k] k≥0 [k] k≥0
θ⋆ and ζ⋆ respectively.
21Figure4: Convergenceofthesequences(θ ) and(ζ ) towardsθ⋆ andζ⋆ (dashedlines).
[k] k≥0 [k] k≥0
In Figure 5, we plot the error (J(θ ,ζ )−J(θ∗,ζ∗)) (on the left side) and the error
[k] [k] k≥0
rate (J(θ ,ζ )−J(θ∗,ζ∗))/J(θ∗,ζ∗)) (on the right side) as a function of the number of
[k] [k] k≥0
iterations. As in the model-based case, we observe excellent performance of the policy gradient
algorithm. Both the error and the error rate on the value function vanish after approximately
200 iterations.
Figure5: ConvergenceofthecosterrorJ(θ ,ζ )−J(θ⋆,ζ⋆)anderrorrate(J(θ ,ζ )−J(θ⋆,ζ⋆))/J(θ⋆,ζ⋆).
[k] [k] [k] [n]
A Explicit solution to LQ MFC
Let us consider the more general linear mean-field dynamics

 dX t = (cid:0) BX t+B¯E 0[X t]+D(cid:82) aπ t(da)(cid:1) dt

+ (cid:0) γ +FX +F¯E [X ](cid:1) dW + (cid:0) γ +F X +F¯ E [X ](cid:1) dW0, (A.1)
t 0 t t 0 0 t 0 0 t t


X ∼ µ,
0
22and a quadratic cost with entropy regularizer
(cid:104)(cid:90) ∞ (cid:16)
J(π) = E e−βt X⊺QX +E [X ]⊺Q¯E [X ]
t t 0 t 0 t
0
(cid:90) (cid:90) (cid:17) (cid:105)
+ a⊺Ra π (da)+λ logp (a)π (da) dt
t t t
to be minimized over randomized controls π = (π ) with density a ∈ Rm (cid:55)→ (p (a)) of
t t t t
feedback form: π = π(.|t,X ,E [X ]) for some randomized policy (t,x,µ) (cid:55)→ π(.|t,x,µ) ∈
t t 0 t
P (Rm). For simplicity of presentation, we assume here that W and W0 are one-dimensional
2
Brownian motions, see Remark A.2 for the extension to the multi-dimensional case.
TheoremA.1. AssumethatthetwofollowingcoupledRiccatiequationsforK ∈ Sd andΛ ∈ Sd
have a unique positive definite solutions

 −βK +Q+KB+B⊺K +F⊺KF +F 0⊺KF 0−K⊺DR−1D⊺K = 0

−βΛ+(Q+Q¯)+Λ(B+B¯)+(B+B¯)⊺Λ+(F +F¯)⊺K(F +F¯)+(F +F¯ )⊺Λ(F +F¯ )
0 0 0 0

 −Λ⊺DR−1D⊺Λ = 0,
(A.2)
Let (K,Λ) ∈ (Sd )2 be the unique positive definite solutions to (A.2) and Y ∈ Rd be the
>+
solution to
−βY +(B+B¯)⊺Y +(F +F¯)⊺Kγ⊺+(F +F¯ )⊺Λγ⊺−Λ⊺DR−1D⊺Y = 0 (A.3)
0 0 0
Then the optimal randomised control is of feedback form with Gaussian distribution, namely
for all t ≥ 0, π∗(·) = π∗(·|X∗,E [X∗]) with
t t 0 t
(cid:32) (cid:33)
λ
π∗(·|x,x¯) = N −R−1D⊺K(x−x¯)−R−1D⊺Λx¯−R−1D⊺Y; R−1
2
where X⋆ is the unique solution to (A.1) with π = π∗. Moreover, the optimal functional cost
satisfies
J(π∗) = E(cid:2) (X −E[X ])⊺K(X −E[X ])+E[X ]⊺ΛE[X ]+2Y⊺X (cid:3)
0 0 0 0 0 0 0
(cid:32) (cid:12) (cid:12)(cid:33)
1 λm λ (cid:12) λ (cid:12)
+ γ⊺Kγ +γ⊺Λγ −Y⊺DR−1D⊺Y − log(2π)− log(cid:12) (cid:12) .
β 0 0 2 2 (cid:12)2det(R)(cid:12)
(cid:12) (cid:12)
Proof. We employ the same Martingale approach as in [9] and [2] to prove that π⋆ is the
optimal policy, noting that the value function is time-independent in the infinite horizon case.
In what follows, we omit the dependence of the process w.r.t the control.
Step 1. Let us consider the function defined on Rd ×P (Rd) by w(x,µ) = w¯(x,µ¯), recalling
2
that µ¯ stands for the mean of µ, where w¯ is defined by
w¯(x,x¯) = (x−x¯)⊺K(x−x¯)+x¯⊺Λx¯+2Y⊺x+r, Rd×Rd
23for some matrices/vectors K,Λ ∈ Sd, Y ∈ Rd and r ∈ R. Then, given π ∈ Π with density p
+
and X := Xπ the unique solution to (A.1), we introduce the following process
(cid:90) t (cid:16)
Sπ := e−βtw¯(X ,E [X ])+ e−βs (X )⊺QX +E [X ]⊺Q¯E [X ]
t t 0 t s s 0 s 0 s
0
(cid:90) (cid:90) (cid:17)
+ a⊺Raπ (da)+λ logp (a)π (da) ds, t ≥ 0,
s s s
where we set p (a) = π (a) the density function of π for t ≥ 0. Note that E [X ] satisfies
t t 0 t
(cid:90)
dE [X ] = (cid:0) (B+B¯)E [X ]+DE [ aπ (da)](cid:1) dt+(γ +(F +F¯ )E [X ])dW0.
0 t 0 t 0 t 0 0 0 0 t t
Step 2. The derivatives of w are given by
∂ w¯(x,x¯) = 2K(x−x¯)+2Y, ∂ w¯(x,x¯) = −2K(x−x¯)+2Λx¯,
x x¯
∂2 w¯(x,x¯) = 2K, ∂2 w¯(x,x¯) = 2(K +Λ), ∂2 w¯(x,x¯) = ∂2 w¯(x,x¯) = −2K.
xx x¯x¯ xx¯ x¯x
Moreover, using the dynamics of X and E [X ], we obtain
t 0 t
d⟨X,X⟩ = (cid:0) (γ +FX +F¯E [X ])(γ +FX +F¯E [X ])⊺
t t 0 t t 0 t
+(γ +F X +F¯ E [X ])(γ +F X +F¯ E [X ])⊺(cid:1) dt,
0 0 t 0 0 t 0 0 t 0 0 t
d⟨E [X],E [X]⟩ = (γ +(F +F¯ )E [X ])(γ +(F +F¯ )E [X ])⊺dt,
0 0 t 0 0 0 0 t 0 0 0 0 t
d⟨X,E [X]⟩ = (γ +(F +F¯ )E [X ])(γ +F X +F¯ E [X ])⊺dt.
0 t 0 0 0 0 t 0 0 t 0 0 t
Applying Ito’s rule to (w(X ,E [X ])) , we obtain
t 0 t t≥0
1
dw¯(X ,E [X ]) = ∂ w¯(X ,E [X ])·dX +∂ w¯(X ,E [X ])·dE [X ]+ ∂2 w¯(X ,E [X ]) : d⟨X,X⟩
t 0 t x t 0 t t x¯ t 0 t 0 t 2 xx t 0 t t
1
+ ∂2 w¯(X ,E [X ]) : d⟨E [X],E [X]⟩ +∂2 w¯(X ,E [X ]) : d⟨X,E [X]⟩
2 x¯x¯ t 0 t 0 0 t xx¯ t 0 t 0 t
(cid:32)
(cid:90)
= 2(cid:0) (X −E [X ])⊺K +Y⊺(cid:1) (BX +B¯E [X ]+D aπ (da))
t 0 t t 0 t t
(cid:90)
+2(cid:0) −(X −E [X ])⊺K +E [X ]⊺Λ(cid:1)(cid:0) (B+B¯)E [X ]+DE [ aπ (da)](cid:1)
t 0 t 0 t 0 t 0 t
+⟨K,(cid:0) (γ +FX +F¯E [X ])(γ +FX +F¯E [X ])⊺+(γ +F X +F¯ E [X ])(γ +F X +F¯ E [X ])⊺(cid:1) ⟩
t 0 t t 0 t 0 0 t 0 0 t 0 0 t 0 0 t
+⟨K +Λ,(γ +(F +F¯ )E [X ])(γ +(F +F¯ )E [X ])⊺⟩
0 0 0 0 t 0 0 0 0 t
(cid:33) (cid:32) (cid:33) (cid:32) (cid:33)
+⟨−2K,(γ +(F +F¯ )E [X ])(γ +F X +F¯ E [X ])⊺⟩ dt+ ... dW + ... dW0
0 0 0 0 t 0 0 t 0 0 t t t
(A.4)
24and taking conditional expectation E on both sides of the preceding equality
0
(cid:32) (cid:34)
(cid:90)
dE [w¯(X ,E [X ])] = E 2(cid:0) (X −E [X ])⊺K +Y⊺(cid:1) (B(X −E [X ])+(B+B¯)E [X ]+D aπ (da))
0 t 0 t 0 t 0 t t 0 t 0 t t
(cid:90)
+2(cid:0) −(X −E [X ])⊺K +E [X ]⊺Λ(cid:1)(cid:0) (B+B¯)E [X ]+DE [ aπ (da)](cid:1)
t 0 t 0 t 0 t 0 t
+⟨K,(cid:0) (γ +FX +F¯E [X ])(γ +FX +F¯E [X ])⊺+(γ +F X +F¯ E [X ])(γ +F X +F¯ E [X ])⊺(cid:1) ⟩
t 0 t t 0 t 0 0 t 0 0 t 0 0 t 0 0 t
(cid:35)(cid:33) (cid:32) (cid:33)
+⟨−K +Λ,(γ +(F +F¯ )E [X ])(γ +(F +F¯ )E [X ])⊺⟩ dt+ ... dW0.
0 0 0 0 t 0 0 0 0 t t
(A.5)
Step 3. Referring to Lemma 6.3 in [2], we try to show that t ∈ R (cid:55)→ E[Sπ] is non-decreasing
+ t
for all π ∈ Π and t ∈ R (cid:55)→ E[Sπ∗] is constant for π⋆. Applying Ito’s formula to Sπ and
+ t t
taking expectation we get
dE[Sπ] = e−βtE[Dπ]dt.
t t
with
d
Dπ = −βw¯(X ,E [X ])+ E[w¯(X ,E [X ])]+X⊺QX +E [X ]⊺Q¯E [X ]
t t 0 t dt t 0 t t t 0 t 0 t
(cid:90) (cid:90)
+ a⊺Raπ (da)+λ (logp (a))π (da).
t t t
Then, using (A.4) and (A.5), we obtain
d d
E[w¯(X ,E [X ])] = E[E [w¯(X ,E [X ])]]
t 0 t 0 t 0 t
dt dt
(cid:34)
= E (X −E [X ])⊺(KB+B⊺K +F⊺KF +F⊺KF )(X −E [X ])
t 0 t 0 0 t 0 t
+E [X ]⊺(Λ(B+B¯)+(B+B¯)⊺Λ+(F +F¯)⊺K(F +F¯)+(F +F¯ )⊺Λ(F +F¯ ))E [Xt]
0 t 0 0 0 0 0
+2(Y⊺(B+B¯)+γ⊺K(F +F¯)+γ⊺Λ(F +F¯ ))X
0 0 0 t
(cid:35)
(cid:90)
+2(cid:0) (X −E [X ])⊺KD+E [X ]⊺ΛD+Y⊺D(cid:1) aπ (da) +γ⊺Kγ +γ⊺Λγ
t 0 t 0 t t 0 0
A
25so that
(cid:34)
E[Dπ] = E (X −E [X ])⊺(−βK +KB+B⊺K +F⊺KF +F⊺KF +Q)(X −E [X ])
t t 0 t 0 0 t 0 t
+E [X ]⊺(−βΛ+Λ(B+B¯)+(B+B¯)⊺Λ+(F +F¯)⊺K(F +F¯)+(F +F¯ )⊺Λ(F +F¯ )+Q+Q¯)E [X ]
0 t 0 0 0 0 0 t
+2(−βY⊺+Y⊺(B+B¯)+γ⊺K(F +F¯)+γ⊺Λ(F +F¯ ))X
0 0 0 t
(cid:90) (cid:90) (cid:90)
+ a⊺Raπ (da)+2(cid:0) (X −E [X ])⊺KD+E [X ]⊺ΛD+Y⊺D(cid:1) aπ (da)+λ (logp (a))π (da)
t t 0 t 0 t t t t
(cid:35)
+γ⊺Kγ +γ⊺Λγ −βr .
0 0
Step 4. We introduce the map
(cid:34) (cid:35)
(cid:90) (cid:90) (cid:90)
I(π ) = E a⊺Raπ (da)+2(cid:0) (X −E [X ])⊺KD+E [X ]⊺ΛD+Y⊺D(cid:1) aπ (da)+λ (logp (u))π (du) .
t 0 t t 0 t 0 t t t t
FollowingtheapproachoutlinedinStep3oftheproofofTheoremB.1in[9], theoptimalpolicy
that minimizes I is given by:
λ
π∗(·|X ,E [X ]) = N(−R−1D⊺K(X −E [X ])−R−1D⊺ΛE [X ]−R−1D⊺Y; R−1)
t t 0 t t 0 t 0 t 2
and the infimum writes
(cid:34)
I(π∗) = E −(X −E [X ])⊺KDR−1D⊺K(X −E [X ])−E [X ]⊺ΛDR−1D⊺ΛE [X ]
t 0 t 0 t t 0 t 0 t 0 t
(cid:35) (cid:12) (cid:12)
λm λ (cid:12) λ (cid:12)
−2Y⊺DR−1D⊺ΛX −Y⊺DR−1D⊺Y − log(2π)− log(cid:12) (cid:12).
t 2 2 (cid:12)2det(R)(cid:12)
(cid:12) (cid:12)
Step 5. Noting that R is strictly positive-definite, for all π ∈ Π, we have
(cid:34)
E[Dπ]=E (X −E [X ])⊺(−βK+KB+B⊺K+F⊺KF +F⊺KF +Q)(X −E [X ])
t t 0 t 0 0 t 0 t
+E [X ]⊺(−βΛ+Λ(B+B¯)+(B+B¯)⊺Λ+(F +F¯)⊺K(F +F¯)+(F +F¯ )⊺K(F +F¯ )+Q+Q¯)E [X ]
0 t 0 0 0 0 0 t
(cid:35)
+2(−βY⊺+Y⊺(B+B¯)+γ⊺K(F +F¯)+γ⊺Λ(F +F¯ ))X +⟨K,γγ⊺⟩+⟨Λ,γ γ⊺⟩−βr+I(π )
0 0 0 t 0 0 t
(cid:34)
≥E (X −E [X ])⊺(−βK+KB+B⊺K+F⊺KF +F⊺KF +Q−KDR−1D⊺K)(X −E [X ])
t 0 t 0 0 t 0 t
+E [X ]⊺(−βΛ+Λ(B+B¯)+(B+B¯)⊺Λ+(F +F¯)⊺K(F +F¯)+(F +F¯ )⊺Λ(F +F¯ )
0 t 0 0 0 0
+Q+Q¯−ΛDR−1D⊺Λ)E [X ]+2(−βY⊺+Y⊺(B+B¯)+γ⊺K(F +F¯)+γ⊺Λ(F +F¯ )
0 t 0 0 0
(cid:12) (cid:12)
λm λ (cid:12) λ (cid:12)
−Y⊺DR−1D⊺Λ)X +γ⊺Kγ+γ⊺Λγ −βr−Y⊺DR−1D⊺Y − log(2π)− log(cid:12) (cid:12).
t 0 0 2 2 (cid:12)2det(R)(cid:12)
(cid:12) (cid:12)
(A.6)
26Now, taking (K,Λ,Y) as the solutions to (A.2)-(A.3) and letting
(cid:12) (cid:12)
1(cid:16) λm λ (cid:12) λ (cid:12)(cid:17)
r = γ⊺Kγ +γ⊺Λγ −Y⊺DR−1D⊺Y − log(2π)− log(cid:12) (cid:12) ,
β 0 0 2 2 (cid:12)2det(R)(cid:12)
(cid:12) (cid:12)
we observe that the right hand side of (A.6) vanishes, which means that for allπ ∈ Π, E[Dπ] ≥
t
0. Moreover, equality in (A.6) holds true for π = π∗ so that
inf E[Dπ] = E[Dπ∗ ] = 0.
t t
π∈Π
We thus conclude that for any π ∈ Π, t (cid:55)→ E[Sπ] is non-decreasing on [0,+∞) and t (cid:55)→ E[Sπ∗]
t t
is constant on [0,+∞) which eventually implies
J(π∗) = E[Sπ∗ ] = E[Sπ∗ ] = E[w¯(X ,E [X ])].
∞ 0 0 0 0
The proof is now complete.
Remark A.1. According to Section 6 [2], if R > 0, Q > 0 and Qˆ = Q+Q¯ > 0, the existence
of a positive definite solution to the coupled Riccati equations (A.2) is guaranteed and the
assumption is specifically for the uniqueness part.
Remark A.2. As noted in Remark 5.2 in [2], one may extend Theorem A.1 to the case where
W andW0 aremulti-dimensionalBrownianmotions. OnemayconsiderW = (W{1} ,...,W{q} )
t t t≥0
(resp. W0 = (W0,{1} ,...,W0,{q0} ) ) is a q-dimensional (resp. q -dimensional) standard
t t t≥0 0
Brownian motion and the dynamics of the controlled state process writes as



dX tπ = (BX tπ +B¯E 0[X tπ]+D(cid:82) Aaπ t(da))dt+(cid:80)q i=1(γ{i}+F{i}X tπ +F¯{i}E 0[X tπ])dW t{i}
+(cid:80)q0 (γ{i} +F{i} Xπ +F¯{i}E [Xπ])dW0,{i} ,
i=1 0 0 t 0 0 t t

 Xπ ∼ µ.
0
B Proof of Propositions 2.1 and 2.2
B.1 Proof of Proposition 2.1
We first provide two auxiliary technical results.
Lemma B.1. (Solution to the ODE for symmetric matrix-valued function)
Let Γ : [0,T] (cid:55)→ Sd be the solution the following ODE
dΓ
t = Γ A⊺+AΓ +O (B.1)
t t
dt
for some A ∈ Rd×d and O ∈ Sd. Then, it holds
(cid:90) t
Γ = exp(tA)Γ exp(tA⊺)+ exp(−(s−t)A)Oexp(−(s−t)A⊺)ds,
t 0
0
where exp(A) :=
(cid:80)+∞ An
.
n=0 n!
27Lemma B.2. If (θ,ζ) ∈ S ×Sˆ, then it holds
lim e−βtE[Yθ(Yθ)⊺] = 0 , lim e−βtE[Zζ(Zζ)⊺] = 0.
t t t t
t→+∞ t→+∞
Proof. From the dynamics (2.11) of (Yθ,Zζ) and Itô’s rule for t (cid:55)→ E[Yθ(Yθ)⊺] and t (cid:55)→
t t t≥0 t t
E[Zζ(Zζ)⊺], we get
t t
d(cid:0)E[Yθ(Yθ)⊺](cid:1)
=
(cid:0)E[Yθ(Yθ)⊺](B+Dθ)⊺+(B+Dθ)E[Yθ(Yθ)⊺]+γγ⊺(cid:1)
dt
t t t t t t (B.2)
d(cid:0)E[Zζ(Zζ)⊺](cid:1) = (cid:0)E[Zζ(Zζ)⊺](Bˆ +Dζ)⊺+(Bˆ +Dζ)E[Zζ(Zζ)⊺]+γ γ⊺(cid:1) dt.
t t t t t t 0 0
Noting that both t (cid:55)→ E[Yθ(Yθ)⊺] and t (cid:55)→ E[Zζ(Zζ)⊺] are solution of an ODE of the form
t t t t
(B.1), Lemma B.1 guarantees that
E[Yθ(Yθ)⊺] = exp(t(B+Dθ))E[Y (Y )⊺]exp(t(B+Dθ)⊺)
t t 0 0
(cid:90) t
+ exp(−(s−t)(B+Dθ))γγ⊺exp(−(s−t)(B+Dθ)⊺)ds,
0
E[Zζ(Zζ)⊺] = exp(t(Bˆ +Dζ))E[Z (Z )⊺]exp(t(Bˆ +Dζ)⊺)
t t 0 0
(cid:90) t
+ exp(−(s−t)(Bˆ +Dζ))γ γ⊺exp(−(s−t)(Bˆ +Dζ)⊺)ds
0 0
0
so that
β β
e−βtE[Yθ(Yθ)⊺] = exp(t(B− I +Dθ))E[Y (Y )⊺]exp(t(B− I +Dθ)⊺)
t t 2 d 0 0 2 d
(cid:90) t β β
+ exp(−(s−t)(B− I +Dθ))γγ⊺exp(−(s−t)(B− I +Dθ)⊺)ds,
d d
2 2
0
β β
e−βtE[Zζ(Zζ)⊺] = exp(t(Bˆ − I +Dζ))E[Z (Z )⊺]exp(t(Bˆ − I +Dζ)⊺)
t t 2 d 0 0 2 d
(cid:90) t β β
+ exp(−(s−t)(Bˆ − I +Dζ))γ γ⊺exp(−(s−t)(Bˆ − I +Dζ)⊺)ds.
2 d 0 0 2 d
0
Now, if (θ,ζ) ∈ S ×Sˆ, then both B− βI +Dθ and Bˆ − βI +Dζ are stable which allows to
2 d 2 d
conclude.
Proof of Proposition 2.1: Using the integration by parts, we have
(cid:90) ∞ (cid:90) ∞ (cid:12)t=+∞
e−βtd(cid:0)E[Y tθ(Y tθ)⊺](cid:1) +(−β) e−βtE[Y tθ(Y tθ)⊺]dt = e−βtE[Y tθ(Y tθ)⊺](cid:12) (cid:12) = −E[Y 0(Y 0)⊺].
(cid:12)
0 0 t=0
Using (B.2) together with the previous identity, we get
(cid:90) ∞ e−βtd(cid:0)E[Yθ(Yθ)⊺](cid:1) = Σ (B+Dθ)⊺+(B+Dθ)Σ + 1 γγ⊺
t t θ θ β
0
= −E[Y (Y )⊺]+βΣ
0 0 θ
28so that Σ defined by (2.13) satisfies
θ
1
−βΣ +Σ (B+Dθ)⊺+(B+Dθ)Σ +E[Y (Y )⊺]+ γγ⊺ = 0
θ θ θ 0 0
β
which in turn, recalling that M = E[Y (Y )⊺]+ 1γγ⊺, allows to conclude. The proof for Σˆ is
0 0 β ζ
similar. We thus omit the remaining technical details.
Expressing (2.16) in the standard form of the Lyapounov equation
β β
(B− I +Dθ)Σ +Σ (B− I +Dθ)⊺+M = 0,
d θ θ d
2 2
β β
(Bˆ − I +Dζ)Σˆ +Σˆ (Bˆ − I +Dζ)⊺+Mˆ = 0
d ζ ζ d
2 2
and, recalling that (θ,ζ) ∈ S × Sˆ, we conclude that they admit a unique positive definite
solution. (cid:50)
B.2 Proof of the Proposition 2.2
We write (2.17) and (2.18) as
β β
(B− I +Dθ)⊺K +K (B− I +Dθ)+Q+θ⊺Rθ = 0,
d θ θ d
2 2
β β
(Bˆ − I +Dζ)⊺Λ +Λ (Bˆ − I +Dζ)+Qˆ +ζ⊺Rζ = 0.
d ζ ζ d
2 2
Since (θ,ζ) ∈ S ×Sˆ, the above equations admit a unique positive definite solutions.
From the dynamics (2.11) of (Yθ,Zζ) and Itô’s rule, for all positive definite symmetric
t t t≥0
matrix Γ, one has
(cid:32) (cid:33)
d(cid:0) e−βt(Yθ)⊺ΓYθ(cid:1) = e−βt (Yθ)⊺(cid:0) −βΓ+(B+Dθ)⊺Γ+Γ(B+Dθ)(cid:1) Yθ +γ⊺Γγ dt
t t t t
+ e−βt(cid:0) (Yθ)⊺Γγ +γ⊺ΓYθ(cid:1) dW ,
t t t
(cid:32) (cid:33)
d(cid:0) e−βt((Zζ)⊺ΓZζ)(cid:1) = e−βt (Zζ)⊺(cid:0) −βΓ+(Bˆ +Dζ)⊺Γ+Γ(Bˆ +Dζ)(cid:1) Zζ +γ⊺Γγ dt
t t t t 0 0
+ e−βt(cid:0) (Zζ)⊺Γγ +γ⊺ΓZζ(cid:1) dW0.
t 0 0 t t
Then, from the very definition (2.12) of J and J , denoting by K and Λ the respective
1 2 θ ζ
29unique solutions to (2.17) and (2.18), we get
J (θ) = (Q+θ⊺Rθ) : Σ
1 θ
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Yθ)⊺(Q+θ⊺Rθ))Yθ(cid:1) dt
t t
0
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Yθ)⊺(cid:0) βK −(B+Dθ)⊺K −K (B+Dθ)(cid:1) Yθdt
t θ θ θ t
0
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Yθ)⊺(cid:0) βK −(B+Dθ)⊺K −K (B+Dθ)(cid:1) Yθdt+(cid:0) ...(cid:1) dW
t θ θ θ t t
0
(cid:34) (cid:32) (cid:33)(cid:35)
(cid:90) ∞ (cid:90) ∞ 1
= −E d e−βt(Yθ)⊺K Yθ + e−βt(γ⊺K γ)dt = E[(Y )⊺K Y ]+ γ⊺K γ,
t θ t θ 0 θ 0 β θ
0 0
and
J (ζ) = (Qˆ +ζ⊺Rζ) : Σˆ
2 ζ
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Zζ)⊺(Qˆ +ζ⊺Rζ)Zζ(cid:1) dt
t t
0
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Zζ)⊺(cid:0) βΛ −(Bˆ +Dζ)⊺Λ −Λ (Bˆ +Dζ)(cid:1) Zζ(cid:1) dt
t ζ ζ ζ t
0
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (Zζ)⊺(cid:0) βΛ −(Bˆ +Dζ)⊺Λ −Λ (Bˆ +Dζ)(cid:1) Zζ(cid:1) dt+(...)dW0
t ζ ζ ζ t t
0
(cid:34) (cid:32) (cid:33)(cid:35)
(cid:90) ∞ (cid:90) ∞ 1
= −E d e−βt(Zζ)⊺Λ Zζ + e−βtγ⊺Λ γ dt = E[(Z )⊺Λ Z ]+ γ⊺Λ γ .
t ζ t 0 ζ 0 0 ζ 0 β 0 ζ 0
0 0
The proof of Proposition 2.2 is now complete. (cid:50)
C Proofs of results for model-based algorithms
C.1 Proof of Proposition 3.1
We prove Proposition 3.1 only for J , as the part concerning J follows similar reasoning.
1 2
First, we recall an auxiliary result regarding the exponential form of the solution to continuous
Lyapunov equations.
Lemma C.1. (Solution of continuous Lyapunov equation). Let W be a stable matrix and Q a
symmetric matrix. The following continuous Lyapunov equation
WY +YW⊺+Q = 0
admits a unique solution Y which satisfies
(cid:90) ∞
Y =
eWtQeW⊺tdt.
0
30Hence, recalling the algebraic Riccati equation (2.18) for K , we deduce that
θ
(cid:90) ∞
K
θ
= e(B−β 2I d+Dθ)⊺t(Q+θ⊺Rθ)e(B−β 2I d+Dθ)tdt.
0
In order to differentiate J , we will rely on the following definition of the derivatives of a
1
matrix-valued map.
Definition C.1. (Differentiability of the matrix applications)The map M : Rm1×n1 (cid:55)→ Rm2×n2
is differentiable at X if there exists a matrix mapping: Z : Rm1×n1 (cid:55)→ Rm2n2×m1n1 such that
for any ∆X ∈ Rm1×n1
vec(M(X+∆X)−M(X)) = Z(X)vec(∆X)+O(tr((∆X)⊺(∆X)))
where ’vec’ stands for the vectorization operator defined for Y = (y ) by
ij 1≤i≤n,1≤j≤m
vec(Y) = (y ,...,y ,y ,...,y ,...,y ,...,y )⊺.
11 n1 12 n2 1m nm
Lemma C.2. (Diffentiability of K with respect to θ) Denoting E = Rθ+D⊺K , for all θ,
θ θ θ
θ′ ∈ S, we have
(cid:90) ∞
K
θ′
−K
θ
= e(B−β 2I d+Dθ′)⊺t[(E θ)⊺(θ′−θ)+(θ′−θ)⊺E
θ
+(θ′−θ)⊺R(θ′−θ)]e(B−β 2I d+Dθ′)tdt
0
from which it readily follows that there exists a matrix Z depending only on θ′ such that
θ′
vec(K −K ) = Z vec(θ−θ′)+O(∥θ′−θ∥2).
θ θ′ θ′ F
Proof. Taking the difference between the two equations (2.17) solved by K and K , we get
θ θ′
β β β β
0 = (B− I +Dθ′)⊺K +K (B− I +Dθ′)−((B− I +Dθ)⊺K +K (B− I +Dθ))
d θ′ θ′ d d θ θ d
2 2 2 2
+(θ′)⊺Rθ′−θ⊺Rθ
β β
= (B− I +Dθ′)⊺K +K (B− I +Dθ′)
d θ′ θ′ d
2 2
β β
−(((B− I +Dθ′)−D(θ′−θ))⊺K +K ((B− I +Dθ′)−D(θ′−θ))
d θ θ d
2 2
+(θ′−θ+θ)⊺R(θ′−θ+θ)−θ⊺Rθ
β β
= (B− I +Dθ′)⊺(K −K )+(K −K )(B− I +Dθ′)
d θ′ θ θ′ θ d
2 2
+(θ′−θ)⊺D⊺K +K D(θ′−θ)+(θ′−θ+θ)⊺R(θ′−θ+θ)−θ⊺Rθ
θ θ
β β
= (B− I +Dθ′)⊺(K −K )+(K −K )(B− I +Dθ′)
d θ′ θ θ′ θ d
2 2
+(θ′−θ)⊺(Rθ+D⊺K )+(Rθ+D⊺K )⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ)
θ θ
β β
= (B− I +Dθ′)⊺(K −K )+(K −K )(B− I +Dθ′)
d θ′ θ θ′ θ d
2 2
+(θ′−θ)⊺E +E⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ)
θ θ
31so that K −K is the unique solution to the following Algebraic Lyapounov equation for Y
θ′ θ
β β
(B− I +Dθ′)⊺Y +Y(B− I +Dθ′)+(θ′−θ)⊺E +E⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ) = 0.
2 d 2 d θ θ
From Lemma C.1, we thus obtain
(cid:90) ∞
K
θ′
−K
θ
= e(B−β 2I d+Dθ′)⊺t[(θ′−θ)⊺E
θ
+E θ⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ)]e(B−β 2I d+Dθ′)tdt.
0
The previous identity directly gives
(cid:90) ∞
vec(K
θ′
−K θ) = vec(e(B−β 2I d+Dθ′)⊺t[(θ′−θ)⊺E
θ
+E θ⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ)]e(B−β 2I d+Dθ′)t)dt
0
(cid:90) ∞
= (cid:0) e(B−β 2I d+Dθ′)⊺t⊗e(B−β 2I d+Dθ′)⊺tdt(cid:1) vec(cid:0) (θ′−θ)⊺E
θ
+E θ⊺(θ′−θ)+(θ′−θ)⊺R(θ′−θ)(cid:1)
0
(cid:90) ∞
= (cid:0) e(B−β 2I d+Dθ′)⊺t⊗e(B−β 2I d+Dθ′)⊺tdt(cid:1) vec(cid:0) (θ′−θ)⊺E
θ′
+(E θ′)⊺(θ′−θ)+U(cid:1)
0
where
U = (θ′−θ)⊺R(θ′−θ)+(E −E )⊺(θ′−θ)+(θ′−θ)⊺(E −E )
θ θ′ θ θ′
= −(θ′−θ)⊺R(θ′−θ)+(K −K ))D(θ′−θ)+(θ′−θ)⊺D⊺(K −K )
θ′ θ θ′ θ
= O(∥θ′−θ∥2).
F
Note that in the last line we again used the expression of K −K . Thus, there exists Z that
θ′ θ θ′
depends on B− βI +Dθ′ and E such that
2 d θ′
vec(K −K ) = Z (θ−θ′)+O(∥θ′−θ∥2).
θ′ θ θ′ F
We conclude that K is indeed differentiable with respect to θ.
θ
We recall the rules of the total differentiation of the matrices:
(1) d(X±Y) = dX±dY
(2) d(XY) = (dX)Y+X(dY)
(3) d(X⊺) = (dX)⊺
(4) d(X−1) = −X−1(dX)X−1
WearenowinpositiontoproveProposition3.1. Weonlyprovetheidentityforthegradient
of J , as the gradient of J can be treated similarly.
1 2
By the definition of the differentiation
dJ (θ) = tr(∇J (θ)⊺dθ) = ∇J (θ) : dθ.
1 1 1
32Since J (θ) = K : M, we have dJ (θ) = dK : M so that
1 θ 1 θ
∇J (θ) : dθ = dK : M.
1 θ
Then, we differentiate totally the Lyapunov equation of K and obtain
θ
−βdK +dK (B+Dθ)+(B+Dθ)⊺dK +K Ddθ+dθ⊺D⊺K +θ⊺Rdθ+dθ⊺Rθ = 0
θ θ θ θ θ
which writes
−βdK +dK (B+Dθ)+(B+Dθ)⊺dK +E⊺dθ+dθ⊺E = 0.
θ θ θ θ θ
We then multiply from the right the above equation by Σ . We obtain
θ
−βdK Σ +dK (B+Dθ)Σ +(B+Dθ)⊺dK Σ +(E⊺dθ+dθ⊺E )Σ = 0.
θ θ θ θ θ θ θ θ θ
Using the fact that Σ satisfies the equation
θ
−βΣ +(B+Dθ)Σ +Σ (B+Dθ)⊺+M = 0
θ θ θ
we get
tr(cid:0)
(dK
)M(cid:1)
=
tr(cid:0)
(dK )(βΣ −(B+Dθ)Σ −Σ
(B+Dθ)⊺)(cid:1)
θ θ θ θ θ
= tr(cid:0) β(dK )Σ −dK (B+Dθ)Σ −(B+Dθ)⊺dK Σ (cid:1)
θ θ θ θ θ θ
= tr((E dθ+dθ⊺E )Σ )
θ θ θ
= 2tr((E Σ )⊺dθ)
θ θ
where in the second and the fourth lines we used the commutative property of the trace
operator. Comparing the left and the right sides of the previous identity, we eventually get
∇J (θ) = 2E Σ .
1 θ θ
The proof of Proposition 3.1 is now complete. (cid:50)
C.2 Proof of Theorem 3.2
We here prove the Polyak-Lojasiewocz inequality stated in Theorem 3.2. We will only prove
it for J , as J can be treated in a completely similar manner. We first need the following
1 2
auxiliary result.
Lemma C.3. (Perturbation analysis of J ) For all θ,θ′ ∈ S, it holds
1
J (θ′)−J (θ) = tr[Σ ((θ′−θ+R−1E )⊺R(θ′−θ+R−1E )−E⊺R−1E )].
1 1 θ′ θ θ θ θ
33Proof. We have
J (θ′)−J (θ) = tr((K −K )M)
1 1 θ′ θ
(cid:16)(cid:90) ∞ (cid:17)
= tr e(B−β 2I d+Dθ′)⊺t[(E θ)⊺(θ′−θ)+(θ′−θ)⊺E
θ
+(θ′−θ)⊺R(θ′−θ)]e(B−β 2I d+Dθ′)tMdt
0
(cid:16) (cid:90) ∞
= tr (cid:0) e(B−β 2I d+Dθ′)tMe(B−β 2I d+Dθ′)⊺tdt(cid:1) [(E θ)⊺(θ′−θ)+(θ′−θ)⊺E
θ
0
(cid:17)
+(θ′−θ)⊺R(θ′−θ)]
(cid:16) (cid:17)
= tr Σ ((θ′−θ+R−1E )⊺R(θ′−θ+R−1E )−E⊺R−1E ) ,
θ′ θ θ θ θ
where for the last equality we used the algebraic Riccati equation of Σ .
θ
Proof of Theorem 3.2. From Lemma C.3, we deduce
J (θ)−J (θ∗) = tr[Σ (E⊺R−1E −(θ∗−θ+R−1E )⊺R(θ∗−θ+R−1E )]
1 1 θ∗ θ θ θ θ
≤ tr[Σ (E⊺R−1E )]
θ∗ θ θ
∥Σ ∥
≤ θ∗ F tr(E⊺E )
σ (R) θ θ
min
(♢) ∥Σ ∥
≤ θ∗ F tr(∇J (θ)⊺∇J (θ))
4σ (R)σ2 (Σ ) 1 1
min min θ
(▽) ∥Σ ∥ tr(∇J (θ)⊺∇J (θ))
θ∗ F 1 1
≤ .
4σ (R)σ2 (M)
min min
The inequality (♢) is a consequence of the inequality
tr(∇J (θ)⊺∇J (θ)) = 4tr(Σ E⊺E Σ ) ≥ 4σ2 (Σ )tr(E E )
1 1 θ θ θ θ min θ θ θ
which stems from Proposition 3.1. The inequality (▽) follows from the fact that B−βI +Dθ
2 d
is stable which combined with Lemma C.1 guarantees that
(cid:90) ∞
Σ
θ
= e(B−β 2I d+Dθ)tMe(B−β 2I d+Dθ)⊺tdt ⪰ M.
0
(cid:50)
C.3 Proof of Proposition 3.3
Let us recall that ∇J (θ) and ∇J (ζ) are given by
1 2
∇J (θ) = 2(Rθ+D⊺K )Σ = 2E Σ ,
1 θ θ θ θ
∇J (ζ) = 2(Rζ +D⊺Λ )Σˆ = 2Eˆ Σˆ ,
2 ζ ζ ζ ζ
34with E = Rθ+D⊺K ,Eˆ = Rζ +D⊺Λ and where K ,Λ are the unique solutions to
θ θ ζ ζ θ ζ
−βK +(B+Dθ)⊺K +K (B+Dθ)+Q+θ⊺Rθ = 0,
θ θ θ
−βΛ +(Bˆ +Dζ)⊺Λ +Λ (Bˆ +Dζ)+Qˆ +ζ⊺Rζ = 0,
ζ ζ ζ
and Σ ,Σˆ are the unique solutions to
θ ζ
−βΣ +(B+Dθ)Σ +Σ (B+Dθ)⊺+M = 0,
θ θ θ
−βΣˆ +(Bˆ +Dζ)Σˆ +Σˆ (Bˆ +Dζ)⊺+Mˆ = 0.
ζ ζ ζ
Here again, we will only prove the Lipschitz continuity of ∇J , as ∇J can be treated in a
1 2
similar manner.
C.3.1 Auxiliary results
We start by proving some useful bounds on ∥θ∥ ,∥K ∥ ,∥Σ ∥ ,∥E ∥ when θ ∈ S(ℓ), and
F θ F θ F θ F
similar bounds for ∥ζ∥ ,∥Λ ∥ ,∥Σˆ ∥ ,∥Eˆ ∥ when ζ ∈ Sˆ(ℓˆ),
F ζ F ζ F ζ F
Proposition C.1. For all θ ∈ S(ℓ), it holds
ℓ
∥K ∥ ≤ Bd (ℓ) = ,
θ F K
σ (M)
min
ℓ
∥Σ ∥ ≤ Bd (ℓ) = ,
θ F Σ
σ (Q)
min
(cid:115)
∥R∥ (ℓ−J (θ∗))
F 1
∥E ∥ ≤ Bd (ℓ) = ,
θ F E
σ (M)
min
(cid:32)(cid:115) (cid:33)
1 ∥R∥ (ℓ−J (θ∗)) ∥D∥ ℓ
F 1 F
∥θ∥ ≤ Bd (ℓ) = + .
F θ
σ (R) σ (M) σ (M)
min min min
Similarly, for all ζ ∈ Sˆ(ℓˆ), it holds
ℓˆ
∥Λ ∥ ≤ Bd (ℓˆ) = ,
ζ F Λ σ (Mˆ)
min
ℓˆ
∥Σˆ ∥ ≤ Bd (ℓˆ) = ,
ζ F Σˆ σ (Qˆ)
min
(cid:115)
∥R∥ (ℓˆ−J (ζ∗))
∥Eˆ ∥ ≤ Bd (ℓˆ) = F 2 ,
ζ F Eˆ σ (Mˆ)
min
(cid:32)(cid:115) (cid:33)
1 ∥R∥ (ℓˆ−J (ζ∗)) ∥D∥ ℓˆ
∥ζ∥ ≤ Bd (ℓˆ) = F 2 + F .
F ζ σ min(R) σ min(Mˆ) σ min(Mˆ)
35Before proving the above proposition, we will need the following technical result.
Lemma C.4. For all θ ∈ S, the following lower bound holds
σ (M)
J (θ)−J (θ∗) ≥ min ∥E ∥2.
1 1 ∥R∥ θ F
F
Proof. Applying Lemma C.3 for θ′ = θ−R−1E = −R−1D⊺K , we get
θ θ
J (θ)−J (θ′) = tr(Σ (E )⊺R−1E )
1 1 θ′ θ θ
so that
J (θ)−J (θ∗) ≥ J (θ)−J (θ′)
1 1 1 1
= tr(Σ E⊺R−1E )
θ′ θ θ
σ (M) σ (M)
≥ min tr(E⊺E ) = min ∥E ∥2
∥R∥ θ θ ∥R∥ θ F
F F
where for the last inequality we used the fact that Σ ⪰ M.
θ
Proof of Proposition C.1
Step 1 (Bound for K ). Recalling that J (θ) = Tr(K M), we directly deduce
θ 1 θ
J (θ) ≥ Tr(K )σ (M) ≥ ∥K ∥ σ (M)
1 θ min θ F min
so that
J (θ) ℓ
1
∥K ∥ ≤ ≤ .
θ F
σ (M) σ (M)
min min
Step 2 (Bound for Σ ). We use the fact that J (θ) = tr(Σ (Q+θ⊺Rθ)) to deduce
θ 1 θ
J (θ) ≥ Tr(Σ )σ (Q+θ⊺Rθ) ≥ ∥Σ ∥ σ (Q)
1 θ min θ F min
which in turn implies
J (θ) ℓ
1
∥Σ ∥ ≤ ≤ .
θ F
σ (Q) σ (Q)
min min
Step 3 (Bound for E ). From Lemma C.4, we get
θ
(cid:115) (cid:115)
∥R∥ (J (θ)−J (θ∗)) ∥R∥ (ℓ−J (θ∗))
F 1 1 F 1
∥E ∥ ≤ ≤ .
θ F
σ (M) σ (M)
min min
Step 4 (Bound for ∥θ∥ ). We first write
F
∥θ∥ ≤ ∥Rθ∥ ∥R−1∥
F F F
∥Rθ+D⊺K ∥ +∥−D⊺K ∥
θ F θ F
≤
σ (R)
min
∥E ∥ +∥D∥ ∥K ∥
θ F F θ F
≤
σ (R)
min
36which combined with Lemma C.4 and the bound on ∥K ∥ clearly yields
θ F
(cid:32)(cid:115) (cid:33)
1 ∥R∥ (J (θ)−J (θ∗)) ∥D∥ J (θ)
F 1 1 F 1
∥θ∥ ≤ +
F
σ (R) σ (M) σ (M)
min min min
(cid:32)(cid:115) (cid:33)
1 ∥R∥ (ℓ−J (θ∗)) ∥D∥ ℓ
F 1 F
≤ + .
σ (R) σ (M) σ (M)
min min min
(cid:50)
New operators. Taking a given d×d stable matrix S and a symmetric matrix X, we define
the two operators T· and F· by
(cid:90) ∞
TS(X) = eSrXeS⊺rdr, FS(X) = SX +XS⊺.
0
It is known that
FS ◦TS +I = 0
which means that TS = −(FS)−1.
Lemma C.5. For all H ∈ Sd , it holds
>+
∥TS(H)∥
TS ≤ F .
F
σ (H)
(cid:57) (cid:57) min
Proof. For any unit vector v ∈ Rd and any unit spectral norm matrix X, it holds
(cid:90) ∞
v⊺TS(X)v = tr(XeS⊺rvv⊺eSr)dr
0
(cid:90) ∞
≤
tr(HeS⊺rvv⊺eSr)dr∥H−1/2XH−1/2∥
F
0
= v⊺TS(H)v·∥H−1/2XH−1/2∥
F
≤ ∥TS(H)∥ σ−1 (H)
F min
which clearly yields the conclusion.
Lemma C.6. It holds
TS = TS⊺ .
F F
(cid:57) (cid:57) (cid:57) (cid:57)
Proof. From the commutative property of the trace operator, for any unit vector v ∈ Rd and
any unit spectral norm matrix X, one has
(cid:90) ∞
v⊺TS⊺
(X)v =
tr(XeSrvv⊺eS⊺r)dr
0
= tr(XTS(vv⊺))
≤ ∥X∥ ∥TS(vv⊺)∥
F F
≤ ∥X∥ TS⊺ ∥vv⊺∥ = TS⊺
F F F F
(cid:57) (cid:57) (cid:57) (cid:57)
37which yields
TS⊺ ≤ TS .
F F
(cid:57) (cid:57) (cid:57) (cid:57)
Noting that S = (S⊺)⊺, the reverse inequality directly follows.
In what follows, we introduce the notations
β β
Ξ = B− I +Dθ and Ξˆ = Bˆ − I +Dζ.
θ d ζ d
2 2
C.3.2 Lipschitz regularity of Σ , Σˆ , K and Λ .
θ ζ θ ζ
Perturbation analysis for Σ and Σˆ
θ ζ
Recalling that Σ and Σˆ are the unique solution to the ALE (2.16), from Lemma C.1, it
θ ζ
holds
Σ = TΞ θ(M), Σˆ = TΞˆ ζ(Mˆ).
θ ζ
Hence, from Lemma C.5, we directly get
∥Σ ∥ ∥Σˆ ∥
TΞ θ ≤ θ F , TΞˆ ζ ≤ ζ F . (C.1)
(cid:57) (cid:57)F σ min(M) (cid:57) (cid:57)F σ min(Mˆ)
Proposition C.2. For all θ, θ′ ∈ S(ℓ), it holds
∥Σ −Σ ∥ ≤ Lip (ℓ)∥θ′−θ∥ ,
θ′ θ F Σ F
where Lip (ℓ) = 2∥D∥F(BdΣ(ℓ))2 . Similarly, for all ζ,ζ′ ∈ Sˆ(ℓˆ), it holds
Σ σmin(M)
∥Σˆ −Σˆ ∥ ≤ Lip (ℓˆ)∥ζ′−ζ∥ ,
ζ′ ζ F Σˆ F
where Lip (ℓˆ) = 2∥D∥F(Bd Σˆ(ℓˆ))2 .
Σˆ σmin(Mˆ)
Proof. From
∥FΞ θ′(X)−FΞ θ(X)∥
F
= ∥D(θ′−θ)X +X(θ′−θ)⊺D⊺∥
≤ 2∥D∥ ∥X∥ ∥θ′−θ∥
F F F
we get
FΞ θ′ −FΞ θ
F
≤ 2∥D∥ F∥θ′−θ∥ F.
(cid:57) (cid:57)
Then, using Proposition C.1 and the inequality (C.1), we get
∥Σ ∥ Bd (ℓ)
TΞ θ ≤ θ F ≤ Σ .
F
σ (M) σ (M)
(cid:57) (cid:57) min min
38Since FΞ θ(Σ θ) = FΞ θ′(Σ θ′) = −M we have
∥Σ
θ′
−Σ θ∥
F
= ∥TΞ θ(FΞ θ(Σ
θ′
−Σ θ))∥
F
= ∥TΞ θ(FΞ θ(Σ θ′)−FΞ θ(Σ θ))∥
F
= ∥TΞ θ(FΞ θ(Σ θ′)−FΞ θ′(Σ θ′))∥
F
≤ TΞ θ
F
FΞ θ′ −FΞ θ
F
∥Σ θ′∥
F
(cid:57) (cid:57) (cid:57) (cid:57)
2∥D∥ (Bd (ℓ))2
≤ F Σ ∥θ′−θ∥ .
F
σ (M)
min
The Lipschitz regularity of Σˆ is handled by similar arguments. The remaining technical
ζ
details are omitted.
Perturbation analysis of K and Λ .
θ ζ
Proposition C.3. For all θ,θ′ ∈ S(ℓ), one has
∥K −K ∥ ≤ Lip (ℓ)∥θ′−θ∥
θ′ θ F K F
where
(cid:90) ∞
Lip (ℓ) = 2(cid:0) Bd (ℓ)+∥R∥ Bd (ℓ)(cid:1) sup ∥ eΞ θte(Ξ θ)⊺tdt∥ < +∞.
K E F θ F
θ∈S(ℓ) 0
Similarly, one can show that for all ζ,ζ′ ∈ Sˆ(aˆ), it holds
∥Λ −Λ ∥ ≤ Lip (ℓˆ)∥ζ′−ζ∥
ζ′ ζ F Λ F
where
(cid:90) ∞
Lip (ℓˆ) = 2(cid:0) Bd (ℓˆ)+∥R∥ Bd (ℓˆ)(cid:1) sup ∥ eΞˆ ζte(Ξˆ ζ)⊺tdt∥ < +∞.
Λ Eˆ F ζ F
ζ∈Sˆ(ℓˆ) 0
Proof. From Lemma C.2, we get
(cid:90) ∞
⊺
K
θ′
−K
θ
= eΞ θ′t[(E θ)⊺(θ′−θ)+(θ′−θ)⊺E
θ
+(θ′−θ)⊺R(θ′−θ)]eΞ θ′tdt
0
so that
(cid:90) ∞
⊺
∥K
θ′
−K θ∥
F
≤ ∥(E θ)⊺(θ′−θ)+(θ′−θ)⊺E
θ
+(θ′−θ)⊺R(θ′−θ)∥ F∥ eΞ θ′teΞ θ′tdt∥ F.
0
The compactness of S(ℓ) together with the continuity of θ ∈ S(ℓ) (cid:55)→ ∥(cid:82) 0∞ eΞ θteΞ⊺ θtdt∥
F
yields
sup θ∈S(ℓ)∥(cid:82) 0∞ eΞ θteΞ⊺ θtdt∥
F
< +∞. The triangle inequality together with Proposition C.1 gives
∥θ′−θ∥ ≤ ∥θ′∥ +∥θ∥ ≤ 2Bd (ℓ)
F F F θ
39so that
∥E⊺(θ′−θ)+(θ′−θ)⊺E +(θ′−θ)⊺R(θ′−θ)∥ ≤ 2(cid:0) Bd (ℓ)+∥R∥ Bd (ℓ)(cid:1) ∥θ′−θ∥ .
θ θ F E F θ F
Gathering the previous bounds allows to conclude that θ (cid:55)→ K is Lip (ℓ)-Lipschitz
θ K
continuous on S(ℓ). Similar arguments yield the Lipschitz regularity of Λ. We omit the
remaining technical details.
C.3.3 Proof of Proposition 3.3
In order to establish the Lipschitz regularity of ∇J and ∇J on S(ℓ), we start from the
1 2
representation provided by Proposition 3.1. Namely, one has
∇J (θ) = 2E Σ
1 θ θ
where E = Rθ+D⊺K . Hence,
θ θ
∇J (θ′)−∇J (θ) = 2(E −E )Σ +2E (Σ −Σ ).
1 1 θ′ θ θ′ θ θ′ θ
Noting that
E −E = R(θ′−θ)+D⊺(K −K )
θ′ θ θ′ θ
and using Proposition C.3, we obtain
∥E −E ∥ ≤ ∥R∥ ∥θ′−θ∥ +∥D∥ ∥K −K ∥
θ′ θ F F F F θ′ θ F
≤ (∥R∥ +∥D∥ Lip (ℓ))∥θ′−θ∥ .
F F K F
The previous bound, along again with Proposition C.3, provides
∥∇J (θ′)−∇J (θ)∥ ≤ 2∥E −E ∥ ∥Σ ∥ +2∥E ∥ ∥Σ −Σ ∥
1 1 F θ′ θ F θ′ F θ F θ′ θ F
≤ 2((∥R∥ +∥D∥ Lip (ℓ))Bd (ℓ)+Bd (ℓ)Lip (ℓ))∥θ′−θ∥ .
F F K Σ E Σ F
Using similar arguments, we find that for all ζ,ζ′ ∈ Sˆ(ℓˆ),
∥∇J (ζ′)−∇J (ζ)∥ ≤ Lˆ(ℓˆ)∥ζ′−ζ∥
2 2 F F
where
Lˆ(ℓˆ) = 2((∥R∥ +∥D∥ Lip (ℓˆ))Bd (ℓˆ)+Bd (ℓˆ)Lip (ℓˆ)).
F F Λ Σˆ Eˆ Σˆ
D Proofs of the results for the model-free algorithm
In the first subsection, we describe the strategy of the proof of Theorem 4.1. In Subsection
D.2, we provide its proof. Several auxiliary results are postponed to the next subsections.
40D.1 Strategy of proof of Theorem 4.1
We first solve the well-posedness problem of the perturbation of the parameters. The following
lemma is directly taken from Lemma 4 of [16].
Lemma D.1. There exists rˇ(b) depending only upon b ∈ R , m, d and the model parameters
+
such that for all 0 < r ≤ rˇ(b), for any U = (U,V) ∈ H, such that ∥U∥ ≤ r,∥V∥ ≤ r and
F F
for all Θ = (θ,ζ) ∈ R(b), we have
Θ+U = (θ+U,ζ +V) ∈ R(2b).
From now on, we assume that r > 0 is small enough (r < rˇ(b), rˇ(b) defined in Lemma D.1),
so that for all Θ = (θ,ζ) ∈ R(b), for all U,V with ∥U∥ = ∥V∥ = r,(θ+U,ζ +V) ∈ R(2b).
F F
Themainingredientsoftheproofcanbedescribedasfollows. Denotingby∇˜∆,N,popJ(Θ) =
(∇˜∆,N,popJ(Θ),∇˜∆,N,popJ(Θ)) ∈ H where ∇˜∆,N,popJ(Θ) and ∇˜∆,N,popJ(Θ) are the results of
θ ζ θ ζ
Algorithm 1, the key idea is to show that the two following events
(cid:40) (cid:41)
M = ⟨∇˜∆,N,popJ(Θ),∇J(Θ)⟩ ≥ ν ∥∇J(Θ)∥2
1 H 1 H
(D.1)
(cid:40) (cid:41)
M = ∥∇˜∆,N,popJ(Θ)∥2 ≤ ν ∥∇J(Θ)∥2
2 H 2 H
occur together with high probability, for some ν ,ν > 0. More precisely, by writing
1 2
⟨∇˜∆,N,popJ(Θ),∇J(Θ)⟩ = ∥∇J(Θ)∥2 +⟨(∇˜∆,N,pop−∇)J(Θ),∇J(Θ)⟩
H H H
≥∥∇J(Θ)∥2 −∥(∇˜∆,N,pop−∇)J(Θ)∥ ∥∇J(Θ)∥
H H H
and
∥∇˜∆,N,popJ(Θ)∥ ≤ ∥∇J(Θ)∥ +∥(∇˜∆,N,pop−∇)J(Θ)∥
H H H
we notice that if the event
1
∥(∇˜∆,N,pop−∇)J(Θ)∥ ≤ ∥∇J(Θ)∥ (D.2)
H H
2
occurs with high probability, then so does M ∩M with ν = 1 and ν = 9.
1 2 1 2 2 4
Next, for any fixed ε > 0, the P.-L. inequality (4.3) guarantees that if Θ ∈ R is such that
J(Θ)−J(Θ∗) > ε, then (D.2) is satisfied as soon as
∥(∇˜∆,N,pop−∇)J(Θ)∥ ≤ ε′
H
41with ε′ = 1(cid:112)ε. Indeed, it suffices to notice that
2 κ
(cid:114) (cid:114)
1 ε 1 J(Θ)−J(Θ∗) 1
∥(∇˜∆,N,pop−∇)J(Θ)∥ ≤ ε′ = ≤ ≤ ∥∇J(Θ)∥ .
H H
2 κ 2 κ 2
Noting that
(cid:113)
∥(∇˜∆,N,pop−∇)J(Θ)∥ = ∥(∇˜∆,N,pop−∇ )J(Θ)∥2 +∥(∇˜∆,N,pop−∇ )J(Θ)∥2
H θ θ F ζ ζ F
we will show that for all ε > 0, the event
∥(∇˜∆,N,pop−∇ )J(Θ)∥ ≤ ε and ∥(∇˜∆,N,pop−∇ )J(Θ)∥ ≤ ε
θ θ F ζ ζ F
holds with high probability as soon as the parameters T,n,N,N˜ are large enough and r is
small enough.
D.2 Proof of Theorem 4.1
Step 1: The central idea is to use the following decomposition
(∇˜∆,N,pop−∇ )J(Θ) = (∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)+(∇ˆ∆,N,pop−∇ˆ(T),∆ )J(Θ)
θ θ θ θ θ θ
+(∇ˆ(T),∆ −∇ˆ(T) )J(Θ)+(∇ˆ(T) −∇ˆ )J(Θ)
θ θ θ θ
+(∇ˆ −∇ )J(Θ)
θ θ
(1) (2) (3) (4) (5)
=: E +E +E +E +E ,
θ θ θ θ θ
and similarly
∥(∇˜∆,N,pop−∇ )J(Θ)∥ = (∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)+(∇ˆ∆,N,pop−∇ˆ(T),∆ )J(Θ)
ζ ζ F ζ ζ ζ ζ
+(∇ˆ(T),∆ −∇ˆ(T) )J(Θ)+(∇ˆ(T) −∇ˆ )J(Θ)
ζ ζ ζ ζ
+(∇ˆ −∇ )J(Θ)
ζ ζ
(1) (2) (3) (4) (5)
=: E +E +E +E +E ,
ζ ζ ζ ζ ζ
where we introduced the following notations which will be useful for our convergence analysis:
• The perturbed policy gradients:
N˜ N˜
d 1 (cid:88) d 1 (cid:88)
∇ˆ J(Θ) = J(Θ )U and ∇ˆ J(Θ) = J(Θ )V .
θ r2N˜ i i ζ r2N˜ i i
i=1 i=1
• The truncated policy gradients:
N˜ N˜
∇ˆ(T) J(Θ) = d 1 (cid:88) J(T)(Θ )U and ∇ˆ(T) J(Θ) = d 1 (cid:88) J(T)(Θ )V .
θ r2N˜ i i ζ r2N˜ i i
i=1 i=1
42• The policy gradients with time discretization:
N˜ N˜
∇ˆ(T),∆ J(Θ) = d 1 (cid:88) J(T),∆(Θ )U and ∇ˆ(T) J(Θ) = d 1 (cid:88) J(T),∆(Θ )V .
θ r2N˜ i i ζ r2N˜ i i
i=1 i=1
• The output of Algorithm 1 averaged over the randomness of the state trajectories:
∇ˆ∆,N,popJ(Θ) = E[∇˜∆,N,popJ(Θ)|U,V],
θ θ (D.3)
∇ˆ∆,N,popJ(Θ) = E[∇˜∆,N,popJ(Θ)|U,V],
ζ ζ
where U = (U ,...,U ) and V = (V ,...,V ).
1 N˜ 1 N˜
Intheabovenotations,givenafinitehorizonT > 0(tobechosenlateron)andΘ = (θ,ζ) ∈
H, we introduced the following time-truncated expected cost functional
(cid:34)
(cid:90) T
J(T)(Θ) = E e−βt(cid:0) (YΘ)⊺QYΘ+(ZΘ)⊺QˆZΘ
t t t t
0
(cid:35)
(cid:90)
+
(cid:0) a⊺Ra+λlogpΘ(YΘ,ZΘ,a)(cid:1) pΘ(YΘ,ZΘ,a)da(cid:1)
dt ,
t t t t
and also introduced the corresponding time discretized cost functional, with action execution
noise
(cid:34)n−1
J(T),∆(Θ) = hE (cid:88) e−βt l(cid:16) (xΘ,∆−E [xΘ,∆])⊺Q(xΘ,∆−E [xΘ,∆])+E [xΘ,∆]⊺QˆE [xΘ,∆]
t 0 t t 0 t 0 t 0 t
l l l l l l
l=0
(cid:35)
(cid:17)
+(αΘ,∆)⊺RαΘ,∆+λlogpΘ(xΘ,∆−E [xΘ,∆],E [xΘ,∆],αΘ,∆) ,
t t t 0 t 0 t t
l l l l l l
(D.4)
where (xΘ,∆) is the time-discretization scheme of (XΘ) , over the same time grid ∆
t 0≤l≤n t t∈[0,T]
l
as the interacting agents dynamics (4.4), with dynamics

  xΘ t l+,∆ 1 = xΘ t l,∆+(B √xΘ t l,∆+B¯E √0[x tΘ l,∆]+Dα tΘ l,∆))h
+ γ hw +γ hw0 , (D.5)
l 0 l

 xΘ,∆ = X
0 0
(cid:113)
with αΘ,∆ = θ(xΘ,∆ −E [xΘ,∆])+ζE [xΘ,∆]+ λR−1ξ , (ξ ) being i.i.d. random
t l t l 0 t l 0 t l 2 t l t l 0≤l≤n−1
variables with law N(0,I ).
m
Step 2: Denoting by ε˜ = √ε′ = 1√ (cid:112)ε, choosing r < min(rˇ(b), 1 , 1 ) and
5 2 10 2 κ hr(b,1/ε˜) h′ r(b,1/ε˜)
N˜ > h (b, 1), Proposition D.2 guarantees that with probability 1−4(d)−d
N˜ ε ε˜
∥E5∥ ≤ ε˜ and ∥E5∥ ≤ ε˜.
θ F ζ F
43Choosing T = T˘(ε) as in the statement of Theorem 4.1, according to Proposition D.3, it
holds
∥E4∥ ≤ ε˜ and ∥E4∥ ≤ ε˜, P−a.s.
θ F ζ F
Next choosing n = n˘(ε) as in the statement of Theorem 4.1, it follows from Proposition
D.4 that
∥E3∥ ≤ ε˜ and ∥E3∥ ≤ ε˜, P−a.s.
θ F ζ F
Choosing N = N˘(ε) large enough (again as in the statement of Theorem 4.1), according to
estimates (D.9) in Proposition D.6, it holds
∥E2∥ ≤ ε˜ and ∥E2∥ ≤ ε˜, P−a.s.
θ F ζ F
Finally, according to Proposition D.5, up to a modification of N˜, namely taking N˜ large
enough such that
1 1 1
N˜ > max{h (b, , ),h′ (b, ,T˘(ε),n˘(ε),N˘(ε),1/ε˜)}
N˜ r˘(ε) ε N˜ r˘(ε)
one has
∥E1∥ ≤ ε˜ and ∥E1∥ ≤ ε˜
θ F ζ F
with probability 1−(d)−d.
ε˜
Putting the above estimates together yields
ε′ ε′
∥(∇˜∆,N,pop−∇ )J(Θ)∥ ≤ √ and ∥(∇˜∆,N,pop−∇ )J(Θ)∥ ≤ √
θ θ F 2 ζ ζ F 2
so that
∥(∇˜∆,N,pop−∇)J(Θ)∥ ≤ ε′
H
with probability at least 1−4(d)−d.
ε˜
Step 3: As discussed in Subsection D.1, the previous inequality implies that the probability
of M ∩M defined in (D.1) with ν = 1 and ν = 9 is not smaller than 1−4(d)−d.
1 2 1 2 2 4 ε˜
ItthenfollowsfromLemmaD.1thatforanyρ ∈ (0, 4 ),stillwiththeprobabilitynotsmaller
9Lˇ(b)
than 1−4(d)−d, one has
ε˜
Θ = Θ −ρ∇˜∆,N,popJ(Θ ) ∈ R(b)
[1] [0] [0]
and
(cid:16) ρ(4−9ρLˇ(b))(cid:17)
J(Θ )−J(Θ∗) ≤ 1− (J(Θ )−J(Θ∗)).
[1] 8κ¯(b) [0]
By induction, we eventually deduce that
J(Θ )−J(Θ∗) ≤ (cid:0) 1−
ρ(4−9ρLˇ(b))(cid:1)k
(J(Θ )−J(Θ∗))
[k] 8κ¯(b) [0]
with probability at least 1−4k(d)−d. The conclusion of Theorem 4.1 easily follows from the
ε˜
previous inequality.
44D.3 Analysis of the single step GD algorithm
In this section, we analyze the convergence of a general single-step GD algorithm. This
part serves as an important building block in the proof of Theorem 4.1. Our main result
is Proposition D.1. We first prove some technical results.
Lemma D.2. The map (θ,ζ) (cid:55)→ ∇J(Θ) is Lˇ(b)−Lipschitz continuous on R(b), that is, for all
Θ = (θ,ζ),Θ′ = (θ′,ζ′) ∈ R(b),
∥∇J(Θ)−∇J(Θ′)∥ ≤ Lˇ(b)∥Θ−Θ′∥ ,
H H
recalling that Lˇ(b) = max{L(b),Lˆ(b)}, where L(b) and Lˆ(b) are the Lipschitz constants of
∇J (θ) and ∇J (ζ) on S(b) and Sˆ(b) respectively, defined in (3.2) of Proposition 3.3.
1 2
Proof. It is clear that Θ ∈ R(b) implies (θ,ζ) ∈ S(b)×Sˆ(b) so that
∥∇J (θ)−∇J (θ′)∥ ≤ L(b)∥θ−θ′∥ ≤ Lˇ(b)∥θ−θ′∥
1 1 F F F
∥∇J (ζ)−∇J (ζ′)∥ ≤ Lˆ(b)∥ζ −ζ′∥ ≤ Lˇ(b)∥ζ −ζ′∥
2 2 F F F
which in turn clearly yields
∥∇J(Θ)−∇J(Θ′)∥2 = ∥∇ J(θ,ζ)−∇ J(θ′,ζ′)∥2 +∥∇ J(θ,ζ)−∇ J(θ′,ζ′)∥2
H θ θ F ζ ζ F
= ∥∇J (θ)−∇J (θ′)∥2 +∥∇J (ζ)−∇J (ζ′)∥2
1 1 F 2 2 F
≤ Lˇ2(b)(∥θ−θ′∥2 +∥ζ −ζ′∥2) = Lˇ2(b)∥Θ−Θ′∥2 .
F F H
The proof is now complete.
For Θ = (θ,ζ) ∈ R(b) and G = (G ,G ) ∈ H satisfying
1 2
⟨G,∇J(Θ)⟩ ≥ ν ∥∇J(Θ)∥2 , ∥G∥2 ≤ ν ∥∇J(Θ)∥2 , (D.6)
H 1 H H 2 H
we set
Θ := Θ−ρG = (θ−ρG ,ζ −ρG ). (D.7)
ρ 1 2
Lemma D.3. For any Θ = (θ,ζ) ∈ R(b), any G ∈ H satisfying (D.6) and any ρ ∈ (0, 2ν1 ),
ν2Lˇ(b)
Θ defined by (D.7) satisfies
ρ
Θ ∈ R(b).
ρ
Proof. We let
ρ = sup{ρ′ ≥ 0|Θ := Θ−ρG = (θ−ρG ,ζ −ρG ) ∈ R(b),∀ρ ∈ [0,ρ′]}.
max ρ 1 2
Firstly, from the first condition of G, G is also a descent direction of the function J, we have
ρ > 0. Next, R(b) is compact thus bounded, we have ρ < +∞.
max max
45Assumethatρ < 2ν1 . Bythecontinuityofρ (cid:55)→ J(cid:0) θ−ρG(cid:1)andthedefinitionofR(b),
max ν2Lˇ(b)
wehaveJ(cid:0) Θ−ρ G(cid:1) = Jˇ(cid:0) Θ−ρ G(cid:1) +υ(λ) = b+υ(λ). Therefore, foranyρ ∈ (0,ρ ], we
max max max
have Θ−ρG ∈ R(b). A second order Taylor’s expansion together with the Lipschitz continuity
of ∇J and (D.6) gives
J(cid:0) Θ−ρG(cid:1) ≤ J(Θ)−ρ⟨∇J(Θ),G⟩ +
ρ2Lˇ(b)
∥G∥2
H 2 H
ρ2ν Lˇ(b)
≤ J(Θ)−ρν ∥∇J(Θ)∥2 + 2 ∥∇J(Θ)∥2
1 H 2 H
so that
J(cid:0) Θ−ρG(cid:1) −J(Θ) ≤ −ρ(2ν 1−ρν 2Lˇ(b)) ∥∇J(Θ)∥2 < 0
2 H
which in turn clearly gives
J(cid:0) Θ−ρG(cid:1) < J(Θ) = Jˇ(Θ)+υ(λ) ≤ b+υ(λ).
This last inequality contradicts the fact that J(cid:0) Θ−ρ G(cid:1) = b+υ(λ). We thus conclude
max
that ρ ≥ 2ν1 and Θ = Θ−ρG ∈ R(b) for all ρ ∈ (0, 2ν1 ).
max ν2Lˇ(b) ρ ν2Lˇ(b)
Proposition D.1. For any Θ = (θ,ζ) ∈ R(b), any G ∈ H satisfying (D.6) and any ρ ∈
(0, 2ν1 ), Θ defined by (D.7) satisfies
ν2Lˇ(b) ρ
J(cid:0) Θ )−J(Θ∗) ≤ (cid:0) 1− ρ(2ν 1−ρLˇ(b)ν 2)(cid:1) (J(Θ)−J(Θ∗)),
ρ
2κ¯(b)
where κ¯(b) := max(cid:16) κ ,κ , ν 12 (cid:17) + 1.
1 2 2ν2Lˇ(b) 2
Proof. Writing again a second order Taylor expansion and using (D.6), we get
J(cid:0) Θ−ρG(cid:1) ≤ J(Θ)−ρ⟨∇J(Θ),G⟩ +
ρ2Lˇ(b)
∥G∥2
H 2 H
ρ2ν Lˇ(b)
≤ J(Θ)−ρν ∥∇J(Θ)∥2 + 2 ∥∇J(Θ)∥2
1 H 2 H
≤
J(Θ)+(cid:0)ρ2ν 2Lˇ(b)
−ρν (cid:1) ∥∇J(Θ)∥2 .
2 1 H
Note that the gradient domination inequality (4.3) is satisfied with κ¯(b) instead of κ and since
ρ(2ν −ρLˇ(b)ν )
1 2
∈ (0,1),
2κ¯(b)
we get
J(Θ−ρG)−J(Θ) ≤ (cid:0)ρ2ν 2Lˇ(b) −ρν (cid:1) ∥∇J(Θ)∥2 ≤ 1 (cid:0)ρ2ν 2Lˇ(b) −ρν (cid:1) (J(Θ)−J(Θ∗))
2 1 F κ¯(b) 2 1
46so that
J(Θ−ρG)−J(Θ∗) ≤ (cid:0) 1− ρ(2ν 1−ρν 2Lˇ(b))(cid:1) (J(Θ)−J(Θ∗)).
2κ¯(b)
D.4 Error analysis of J and its gradient
We here study the five terms appearing in the decomposition of the error of (∇˜∆,N,pop−∇ )J
θ θ
and (∇˜∆,N,pop−∇ )J introduced in Step 1 of Section D.2.
ζ ζ
• Bounding ∥∇ˆ −∇∥ (Error of perturbation with the exact expected functional
F
cost).
The proof of the following result is postponed to Section D.4.1.
Proposition D.2. For all ε > 0, there exist h (b, 1) with at most polynomial growth in b
r ε
and 1 and h (b, 1, 1) with at most polynomial growth in b, 1 and 1 such that for all r <
ε N˜ r ε r ε
min(rˇ(b), 1 ), all N˜ > h (b, 1, 1) and all Θ = (θ,ζ) ∈ R(b),
hr(b,1 ε) N˜ r ε
∥(∇ˆ −∇ )J(Θ)∥ ≤ ε and ∥(∇ˆ −∇ )J(Θ)∥ ≤ ε,
θ θ F ζ ζ F
with probability at least 1−(d/ε)−d.
• Bounding ∥∇ˆ(T)−∇ˆ∥ (Horizon truncation error).
F
The proof of the following result is postponed to Section D.4.2.
Proposition D.3. P−a.s., for all Θ ∈ R(b), one has
d
∥(∇ˆ −∇ˆ(T) )J(Θ)∥ ≤ c (2b)e−c2(2b)T,
θ θ F r 1
d
∥(∇ˆ −∇ˆ(T) )J(Θ)∥ ≤ c (2b)e−c2(2b)T.
ζ ζ F r 1
• Bounding ∥∇ˆ(T)−∇ˆ(T),∆∥ (Time discretization error).
F
The proof of the following result is postponed to Section D.4.3.
Proposition D.4. There exists a constant c = c (2b) > 0 (non-decreasing with respect to b)
3 3
such that P−a.s., for all Θ ∈ R(b), it holds
d T
∥(∇ˆ(T) −∇ˆ(T),∆
)J(Θ)∥ ≤ c (2b) ,
θ θ F r 3 n
d T
∥(∇ˆ(T) −∇ˆ(T),∆
)J(Θ)∥ ≤ c (2b) .
ζ ζ F r 3 n
47• Bounding ∥∇˜∆,N,pop−∇ˆ∆,N,pop∥ (Statistical error).
F
The proof of the following result is postponed to Section D.4.4.
Proposition D.5. (Statistical error on gradient estimators) For all ε > 0, there exist h′(b, 1)
r ε
and h′ (b, 1,T,n,N, 1) with at most polynomial growth in 1, b, 1, logN, logn, logT such
N˜ r ε r ε
that for all r < min{rˇ(b),1/h′(b, 1)} and all N˜ ≥ h′ (b, 1,T,n,N, 1), with probability at least
r ε N˜ r ε
1−(d/ε)−d, for all Θ ∈ R(b), it holds
∥(∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)∥ ≤ ε,
θ θ F
∥(∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)∥ ≤ ε.
ζ ζ F
• Bounding ∥∇ˆ∆,N,pop−∇ˆ(T),∆∥ (Particle discretization error).
F
The proof of the following result is postponed to Section D.4.5.
Proposition D.6. Let J¯∆,N(Θ) := E[J∆,N(Θ)], Θ ∈ R(b), recalling that J∆,N is defined by
pop pop pop
(4.7). There exists c = c (b) > 0 such that for all Θ ∈ R(b),
4 4
c
|(J¯∆,N −J(T),∆)(Θ)| ≤ 4 . (D.8)
pop N
Moreover, P−a.s., for all Θ ∈ R(b), it holds
dc (2b)
∥(∇ˆ∆,N,pop−∇ˆ(T),∆
)J(Θ)∥ ≤
4
,
θ θ F r N (D.9)
dc (2b)
∥(∇ˆ∆,N,pop−∇ˆ(T),∆
)J(Θ)∥ ≤
4
.
ζ ζ F r N
D.4.1 Proof of Proposition D.2
The proof is reminiscent of Lemma 31 [6] or Lemma 30 [8]. For any Θ = (θ,ζ) ∈ S ×Sˆ and
r > 0, let us introduce the following smooth approximation of J defined by
J (θ,ζ) = E [J(θ+P ,ζ +Pˆ )] = E [J (θ+P )+J (ζ +Pˆ )]+υ(λ) (D.10)
r (Pr,Pˆ r) r r (Pr,Pˆ r) 1 r 2 r
whereP andPˆ aretwoindependentrandomvariablesuniformlydistributedinS andE
r r r (Pr,Pˆ r)
stands for the expectation taken with respect to the random variables P ,Pˆ .
r r
The following result is directly taken from Lemma 26 in [8]. For any (θ,ζ) ∈ S×Sˆ, it holds
d d
∇ J (θ,ζ) = E [J (θ+P )P ] = E [J(θ+P ,ζ +Pˆ )P ]
θ r r2 Pr 1 r r r2 (Pr,Pˆ r) r r r
(D.11)
d d
∇ J (θ,ζ) = E [J (ζ +Pˆ )Pˆ ] = E [J(θ+P ,ζ +Pˆ )Pˆ ].
ζ r r2 Pˆ r 2 r r r2 (Pr,Pˆ r) r r r
48We then write
∥(∇ˆ −∇ )J(Θ)∥ ≤ ∥∇ˆ J(Θ)−∇ J (Θ)∥ +∥∇ J (Θ)−∇ J(Θ)∥ .
θ θ F θ θ r F θ r θ F
For the second term ∥∇ J (Θ)−∇ J(Θ)∥ , using the Lipschitz property of the gradient
θ r θ F
∇J(Θ) shown in the Section C.3, there exists h˜ (b, 1) with polynomial growth in b and 1 such
r ε ε
that for all r < 1/h˜ (b, 1), for all Θ = (θ,ζ) ∈ R(b) and Θ′ = (θ′,ζ′) such that ∥θ′ −θ∥ ≤ r
r ε F
and ∥ζ′ −ζ∥ ≤ r, we have ∥∇ J(Θ′)−∇ J(Θ)∥ ≤ ε. Then according to (D.10), noticing
F θ θ F 2
that ∇ J (Θ) = E [∇ J(θ+P ,ζ +Pˆ )], we have
θ r (Pr,Pˆ r) θ r r
ε
∥∇ J (Θ)−∇ J(Θ)∥ ≤ E [∥∇ J(θ+P ,ζ +Pˆ )−∇ J(Θ)∥ ] ≤ .
θ r θ F (Pr,Pˆ r) θ r r θ F 2
Then, for the first term ∥∇ˆ J(Θ)−∇ J (Θ)∥ , using (D.11), we notice that ∇ˆ J(Θ) is
θ θ r F θ
exactly the Monte-Carlo approximation for the expectation ∇ J (Θ). Assuming that r <
θ r
rˇ(b), according to Lemma D.1, for all Θ ∈ R(b),i = 1,...,N˜,(θ +U ,ζ +V ) ∈ R(2b) and
i i
each individual sample has the norm bounded by d(2b+υ(λ)) according to (4.1)-(4.2). Thus
r
we can apply vector Bernstein’s Inequality to deduce that there exists h (b, 1, 1) with
sample r ε
polynomial growth in b, 1 and 1 such that for all N˜ ≥ h (b, 1, 1), for all Θ ∈ R(b), we
r ε sample r ε
have ∥∇ˆ J(Θ)−∇ J (Θ)∥ ≤ ε with probability at least 1−(d/ε)−d.
θ θ r F 2
The bound for ∥(∇ˆ − ∇ )J(Θ)∥ is derived in a similar manner, and thus its proof is
ζ ζ F
omitted.
D.4.2 Proof of Proposition D.3
In order to establish our result on ∥(∇ˆ −∇ˆ(T) )J(Θ)∥ and ∥(∇ˆ −∇ˆ(T) )J(Θ)∥ , we first need
θ θ F ζ ζ F
to derive an error bound on |(J(T)−J)(Θ)|.
Lemma D.4. There exist two positive constants c = c (b) and c = c (b) depending only
1 1 2 2
upon b ∈ R , the model parameters and λ such that for all Θ ∈ R(b)
+
|(J(T)−J)(Θ)| ≤ c (b)e−c2(b)T.
1
Besides, c (.) and c (.) are non-decreasing functions.
1 2
Beforeprovingtheabovelemma,wewillneedthefollowingtechnicalresultwhichisdirectly
taken from Lemma 12 [16]. Its proof is thus omitted.
Lemma D.5. Let the matrices F,X ≻ 0 and Ω ≻ 0 satisfy
FX +XF⊺+Ω = 0
then for any t ≥ 0,
∥eFt∥2
2
≤ σ∥X (∥ X2 )e−σm ∥Xin ∥( 2Ω)t
min
where ∥·∥ denotes the largest singular value of the matrices.
2
49Proof of Lemma D.4. From the definition of J and J(T), we get
(J −J(T))(Θ)
(cid:104)(cid:90) ∞ (cid:90) (cid:105)
= E e−βt(cid:0) (YΘ)⊺QYΘ+(ZΘ)⊺QˆZΘ+ (a⊺Ra+λlogpΘ(YΘ,ZΘ,a))pΘ(YΘ,ZΘ,a)da(cid:1) dt
t t t t t t t t
T Rm
(cid:104)(cid:90) ∞ (cid:105)
= E e−βt(cid:0) (YΘ)⊺(Q+θ⊺Rθ)YΘ+(ZΘ)⊺(Qˆ +ζ⊺Rζ)ZΘ(cid:1) dt +υ(T)(λ)
t t t t
T
where
υ(T)(λ) = (cid:16) −λm log(πλ)+λ log(cid:12) (cid:12)det(R)(cid:12) (cid:12)(cid:17)(cid:90) ∞ e−βtdt = e−βT(cid:16) −λm log(πλ)+λ log(cid:12) (cid:12)det(R)(cid:12) (cid:12)(cid:17) .
2 2 β 2 2
T
In particular, note that υ(λ) defined in (2.7) is in fact υ(0)(λ) for T = 0.
Denoting for simplicity C = E[Yθ(Yθ)⊺] and Cˆ = E[Zζ(Zζ)⊺], one has
t t t t t t
(cid:90) ∞ (cid:90) ∞
(J −J(T))(Θ) = ⟨Q+θ⊺Rθ, e−βtC dt⟩+⟨Qˆ +ζ⊺Rζ, e−βtCˆ dt⟩+υ(T)(λ) (D.12)
t t
T T
As proved in Lemma B.2 (using Itô’s formula),
(cid:90) t
C = exp(t(B+Dθ))C exp(t(B+Dθ)⊺)+ exp(−(s−t)(B+Dθ))γγ⊺exp(−(s−t)(B+Dθ)⊺)ds,
t 0
0
(cid:90) t
Cˆ = exp(t(Bˆ +Dζ))Cˆ exp(t(Bˆ +Dζ)⊺)+ exp(−(s−t)(Bˆ +Dζ))γ γ⊺exp(−(s−t)(Bˆ +Dζ)⊺)ds.
t 0 0 0
0
The equations (2.1) satisfied by Σ and Σˆ together with Lemma D.5 guarantee that
θ ζ
∥e(B−β 2I d+Dθ)t∥2
2
≤ σ∥Σ θ (∥ Σ2 )e−σm ∥Σin θ( ∥M 2)t ,
min θ
∥e(Bˆ−β 2I d+Dζ)t∥2
2
≤ σ∥Σˆ ζ (∥ Σˆ2 )e−σm ∥Σˆin ζ( ∥M 2ˆ)t ,
min ζ
so that
∥e(B+Dθ)t∥2
2
≤ ∥e(B−β 2I d+Dθ)t∥2 2∥eβ 2I dt∥2
2
≤ σ∥Σ θ (∥ Σ2 )e−σm ∥Σin θ( ∥M 2)t e2∥β 2tI d∥2 = σ∥Σ θ (∥ Σ2 )e(β−σm ∥Σin θ( ∥M 2))t ,
min θ min θ
∥e(Bˆ+Dζ)t∥2
2
≤ ∥e(Bˆ−β 2I d+Dζ)t∥2 2∥eβ 2I dt∥2
2
≤ σ∥Σˆ ζ (∥ Σˆ2 )e−σm ∥Σˆin ζ( ∥M 2ˆ)t e2∥β 2tI d∥2 = σ∥Σˆ ζ (∥ Σˆ2 )e(β−σm ∥Σˆin ζ( ∥M 2ˆ))t .
min ζ min ζ
Hence,
(cid:90) t
∥C ∥ ≤ ∥C ∥ ∥e(B+Dθ)t∥2+∥γ∥2 ∥e(B+Dθ)v∥2dv
t F 0 F 2 2
0
(cid:32) (cid:33)
≤ ∥Σ θ∥ 2 (cid:0) ∥C 0∥
F
+ ∥γ∥2 F (cid:1) e(β−σm ∥Σin θ( ∥M 2))t − ∥γ∥2 F
σ min(Σ θ) β− σmin(M) β − σmin(M)
∥Σ θ∥2 ∥Σ θ∥2
50and similarly
(cid:32) (cid:33)
∥Cˆ t∥
F
≤
σ
m∥Σ iˆ nζ (∥ Σˆ2
ζ)
(cid:0) ∥Cˆ 0∥
F
+
β
−∥γ σ0 m∥ in2 F (Mˆ)(cid:1) e(β−σm ∥Σˆin ζ( ∥M 2ˆ))t − β−∥γ σ0 m∥ in2 F
(Mˆ)
.
∥Σˆ ζ∥2 ∥Σˆ ζ∥2
Since Θ = (θ,ζ) ∈ R(b) ⊂ S(b)×Sˆ(b), recalling that S(b) as well as Sˆ(b) are compact sets,
using the continuity to θ (cid:55)→ ∥Σ ∥ and ζ (cid:55)→ ∥Σˆ ∥ , there exist c˜ (b), c˜ (b) > 0 such that for
θ 2 ζ 2 1 2
all Θ = (θ,ζ) ∈ R(b)
c˜ (b) ≤ ∥Σ ∥ ≤ c˜ (b), c˜ (b) ≤ ∥Σˆ ∥ ≤ c˜ (b)
2 θ 2 1 2 ζ 2 1
and using the fact that Σ ⪰ M,Σˆ ⪰ Mˆ, we get
θ θ
(cid:32) (cid:33)
e−βt∥C t∥
F
≤ ∥Σ θ∥ 2 (cid:0) ∥C 0∥
F
+ ∥γ∥2 F (cid:1) e−σm ∥Σin θ( ∥M 2)t − ∥γ∥2 Fe−βt
σ min(Σ θ) β− σmin(M) β− σmin(M)
∥Σ θ∥2 ∥Σ θ∥2
(cid:32) (cid:33)
≤ c˜ 1(b) (cid:0) ∥C 0∥
F
+ ∥γ∥2 F (cid:1) e−σm c˜2in (( bM ) )t − ∥γ∥2 Fe−βt ,
σ min(M) β− σmin(M) β − σmin(M)
c˜2(b) c˜1(b)
and
(cid:32) (cid:33)
e−βt∥Cˆ t∥
F
≤
σ
m∥Σ iˆ nζ (∥ Σˆ2
ζ)
(cid:0) ∥Cˆ 0∥
F
+ β−∥γ σ0 m∥ in2 F (Mˆ)(cid:1) e−σm ∥Σˆin ζ( ∥M 2ˆ)t − β∥γ −0∥ σ2 F me in− (Mβ ˆt
)
∥Σˆ ζ∥2 ∥Σˆ ζ∥2
(cid:32) (cid:33)
≤
σ
mc˜ i1 n( (b M)
ˆ)
(cid:0) ∥Cˆ 0∥
F
+ β−∥γ σ0 m∥ in2 F (Mˆ)(cid:1) e−σm c˜1in (( bM )ˆ)t − β∥γ −0∥ σ2 F me in− (Mβ ˆt
)
.
c˜2(b) c˜1(b)
By using again the fact that R(b) is compact, there exists a constant c˜ (b) such that for
3
all Θ = (θ,ζ) ∈ R(b):
max{∥Q+θ⊺Rθ∥ ,∥Qˆ +ζ⊺Rζ∥ } ≤ c˜ (b).
F F 3
Combing back to (D.12) and plugging the above estimates, we obtain for all Θ ∈ R(b)
(cid:90) ∞ (cid:90) ∞
|(J(T)−J)(Θ)| ≤ ∥Q+θ⊺Rθ∥ e−βt∥C ∥ dt+∥Qˆ +ζ⊺Rζ∥ e−βt∥Cˆ ∥ dt+|υ(T)(λ)|
F t F F t F
T T
(cid:90) ∞ (cid:90) ∞
≤ c˜ (b)C (b) e−C2(b)tdt+c˜ (b)C (b) e−C4(b)tdt+O (e−βT)
3 1 3 3 λ
T T
≤ c (b)e−c2(b)T,
1
for some c (b) > 0 and c (b) > 0 depending only upon b and λ.
1 2
Finally, the monotonicity of c and c with respect to b is a consequence of the fact that if
1 2
b ≤ b then R(b ) ⊂ R(b ). (cid:50)
1 2 1 2
51Proof of Proposition D.3. Noticing that P-a.s. (θ+U ,ζ +V ) ∈ R(2b), from Lemma D.4,
i i
|(J(T)−J)(Θ )| ≤ c (2b)e−c2(2b)T, P-a.s.
i 1
and, recalling that ∥U ∥ = ∥V ∥ = r, P-a.s. it holds
i F i
N˜
∥(∇ˆ −∇ˆ(T) )J(Θ )∥ ≤ d 1 (cid:88) |(J(T)−J)(Θ )|∥U ∥ ≤ d c (2b)e−c2(2b)T,
θ θ i F r2N˜ i i F r 1
i=1
N˜
∥(∇ˆ −∇ˆ(T) )J(Θ )∥ ≤ d 1 (cid:88) |(J(T)−J)(Θ )|∥V ∥ ≤ d c (2b)e−c2(2b)T.
ζ ζ i F r2N˜ i i F r 1
i=1
(cid:50)
D.4.3 Proof of Proposition D.4
We start with the following technical result related to the weak discretization error on the cost
value function.
Lemma D.6. There exists a constant c = c (b) > 0 (non-decreasing with respect to b) such
3 3
that for all Θ ∈ R(b), it holds
T
|(J(T),∆−J(T))(Θ)| ≤ c (b)h = c (b) .
3 3
n
Proof. Step 1: We introduce the two processes (yΘ,∆) and (zΘ,∆) defined by
t 0≤l≤n t 0≤l≤n
l l
yΘ,∆ = xΘ,∆−E [xΘ,∆] and zΘ,∆ = E [xΘ,∆],
t t 0 t t 0 t
l l l l l
with dynamics
(cid:114)
λ √
yΘ,∆ = yΘ,∆+((B+Dθ)yΘ,∆+D R−1ξ )h+ hγw , yΘ,∆ = X −E [X ],
t l+1 t l t l 2 t l l 0 0 0 0 (D.13)
√
zΘ,∆ = zΘ,∆+(Bˆ +Dζ)zΘ,∆h+ hγ w0, zΘ,∆ = E [X ].
t l+1 t l t l 0 l 0 0 0
Recalling (D.4) together with the dynamics defined in (D.5), one has
(cid:34)n−1 (cid:35)
J(T),∆(Θ) = hE (cid:88) e−βt l(cid:16) (yΘ,∆)⊺(Q+θ⊺Rθ)yΘ,∆+(zΘ,∆)⊺(Qˆ +ζ⊺Rζ)zΘ,∆+βυ(λ)(cid:17) .
t t t t
l l l l
l=0
We also define another auxiliary functional cost:
(cid:34)n−1
J˜(T),∆(Θ) = hE (cid:88) e−βt l(cid:16) (x˜Θ,∆−E [x˜Θ,∆])⊺Q(x˜Θ,∆−E [x˜Θ,∆])+E [x˜Θ,∆]⊺QˆE [x˜Θ,∆]
t 0 t t 0 t 0 t 0 t
l l l l l l
l=0
(cid:35)
(cid:90) (cid:17)
+ (cid:0) a⊺Ra+λlogpΘ(x˜Θ,∆−E [x˜Θ,∆],E [x˜Θ,∆],a)(cid:1) pΘ(x˜Θ,∆−E [x˜Θ,∆],E [x˜Θ,∆],a)da ,
t 0 t 0 t t 0 t 0 t
l l l l l l
(D.14)
52where (x˜Θ,∆) is the time-discretization scheme of (XΘ) , over the same time grid ∆
t 0≤l≤n t t∈[0,T]
l
as the interacting agents dynamics (4.4), with dynamics


 
x˜Θ
t
l+,∆
1
= x˜Θ
t
l,∆+( √Bx˜Θ
t
l,∆+B √¯E 0[x˜Θ
t
l,∆]+D(cid:82) aπΘ(da|x˜Θ
t
l,∆−E 0[x˜Θ
t
l,∆],E 0[x˜Θ
t
l,∆]))h
  + hγw + hγ w0 ;
l 0 l √ √
 

= x˜Θ t l,∆+((B+Dθ)x˜Θ t l,∆+(B¯ −Dθ+Dζ)E 0[x˜Θ t l,∆])h+ hγw l + hγ 0w l0

 x˜Θ,∆ = X
0 0
with Θ = (θ,ζ) ∈ R(b).
Let us also introduce the two processes (y˜Θ,∆) and (z˜Θ,∆) defined by
t l=0,...,n t l=0,...,n
l l
y˜Θ,∆ = x˜Θ,∆−E [˜˜x˜Θ,∆], z˜Θ,∆ = E [z˜Θ,∆], (D.15)
t t 0 t t 0 t
l l l l l
with dynamics
√
y˜Θ,∆ = y˜Θ,∆+(B+Dθ)y˜Θ,∆h+ hγw , y˜Θ,∆ = X −E [X ],
t l+1 t l t l √ l 0 0 0 0
z˜Θ,∆ = z˜Θ,∆+(Bˆ +Dζ)z˜Θ,∆h+ hγ w0, z˜Θ,∆ = E [X ].
t l+1 t l t l 0 l 0 0 0
NotethatJ˜(T),∆in(D.14),canbewrittenusingthedynamicsof(y˜Θ,∆) and(z˜Θ,∆) .
t l=0,···,n t l=0,···,n
l l
Namely, one has
(cid:34)n−1
J˜(T),∆(Θ) = hE (cid:88) e−βt l(cid:16) (y˜Θ,∆)⊺Qy˜Θ,∆+(z˜Θ,∆)⊺Qˆz˜Θ,∆
t t t t
l l l l
l=0
(cid:35)
(cid:90) (cid:17)
+ (a⊺Ra+λlogpΘ(y˜Θ,∆,z˜Θ,∆,z))pΘ(y˜Θ,∆,z˜Θ,∆,z)dz
t t t t
l l l l
A
(cid:34)n−1
= hE (cid:88) e−βt l(cid:16) (y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆+(z˜Θ,∆)⊺(Qˆ +ζ⊺Rζ)z˜Θ,∆
t t t t
l l l l
l=0
(cid:35)
λm λ (cid:12) (cid:12) (cid:17)
+ (− log(πλ)+ log(cid:12)det(R)(cid:12))
2 2
(cid:34)n−1 (cid:35)
= hE (cid:88) e−βt l(cid:0) (y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆+(zΘ,∆)⊺(Qˆ +ζ⊺Rζ)z˜Θ,∆(cid:1)
t t t t
l l l l
l=0
n−1
(cid:88)
+ βυ(λ)h e−βt l.
l=0
Step 2: We first prove an upper-bound on |(J˜(T),∆−J(T),∆)(Θ)|. From (D.13)-(D.15), we get
that z˜Θ,∆ = zΘ,∆, for all l = 0,...n and
t t
l l
(cid:114)
(cid:0) yΘ,∆−y˜Θ,∆(cid:1) = (yΘ,∆−y˜Θ,∆)+(cid:0) (B+Dθ)(yΘ,∆−y˜Θ,∆)+D λ R−1ξ (cid:1) h, yΘ,∆−y˜Θ,∆ = 0,
t l+1 t l+1 t l t l t l t l 2 t l 0 0
53so that
l−1 (cid:114)
yΘ,∆−y˜Θ,∆ = (cid:88) (I +h(B+Dθ))l−1−l′ hD λ R−1ξ .
t l t l d 2 t l′
l′=0
Therefore,
E(cid:2) (yΘ,∆)⊺(Q+θ⊺Rθ)yΘ,∆−(y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆(cid:3)
t t t t
l l l l
=
2E(cid:2) (yΘ,∆−y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆(cid:3) +E(cid:2) (yΘ,∆−y˜Θ,∆)⊺(Q+θ⊺Rθ)(yΘ,∆−y˜Θ,∆)(cid:3)
t t t t t t t
l l l l l l l
l−1 (cid:114)
= 2E(cid:2)(cid:0)(cid:88) (I +h(B+Dθ))l−1−l′ hD λ R−1ξ (cid:1)⊺ (Q+θ⊺Rθ)y˜Θ,∆(cid:3)
d 2 t l′ t l
l′=0
l−1 (cid:114) l−1 (cid:114)
+E(cid:2)(cid:0)(cid:88) (I +h(B+Dθ))l−1−l′ hD λ R−1ξ (cid:1)⊺ (Q+θ⊺Rθ)(cid:0)(cid:88) (I +h(B+Dθ))l−1−l′ hD λ R−1ξ (cid:1)(cid:3)
d 2 t l′ d 2 t l′
l′=0 l′=0
=: A +A .
1 2
Since (ξ ) is independent of (y˜Θ,∆) which has zero-mean, we have A = 0. As
t l 0≤l≤n t l 0≤l≤n 1
for A , also using the independence of (ξ ) , we have for any S ∈ Sm , E[ξ⊺Sξ ] =
2 t l l=0,...,n ≥0 ti tj
δ tr(S),i,j = 0,...,n, δ = 1 , so that
i,j i,j i̸=j
l−1 l−1 (cid:114)
A = (cid:88)(cid:88) E(cid:2)(cid:0) (I +h(B+Dθ))l−1−ihD λ R−1ξ (cid:1)⊺
2 d
2
ti
i=0 j=0
(cid:114)
(Q+θ⊺Rθ)(cid:0) (I +h(B+Dθ))l−1−jhD λ R−1ξ (cid:1)(cid:3)
d
2
tj
l−1 (cid:114) (cid:114)
= h2(cid:88) tr(cid:0) ((I +h(B+Dθ))l−1−l′ D λ R−1)⊺(Q+θ⊺Rθ)((I +h(B+Dθ))l−1−l′ D λ R−1)(cid:1) .
d d
2 2
l′=0
Consequently, there exists a constant C > 0 depending only upon T, Q, D, λ, R and Θ
1
(with at most of polynomial growth in ∥Θ∥) such that |A | ≤ C1 for all l = 0,··· ,n. Hence,
2 n
up to a modification of C , for all Θ ∈ R(b), it holds
1
(cid:12) (cid:34)n−1 (cid:35)(cid:12)
|(J˜(T),∆−J(T),∆)(Θ)| = (cid:12) (cid:12)hE (cid:88) e−βt l(cid:0) (yΘ,∆)⊺(Q+θ⊺Rθ)yΘ,∆−(y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆(cid:1) (cid:12) (cid:12)
(cid:12) t t t t (cid:12)
l l l l
(cid:12) (cid:12)
l=0
(cid:12) (cid:12)
n−1
= (cid:12) (cid:12)h(cid:88) e−βt lE(cid:2) (yΘ,∆)⊺(Q+θ⊺Rθ)yΘ,∆−(y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆(cid:3)(cid:12) (cid:12)
(cid:12) t t t t (cid:12)
l l l l
(cid:12) (cid:12)
l=0
n−1
(cid:88) C 1(θ)
≤ h
n
l=0
C (θ)
1
≤ .
n
(D.16)
54Step 3: We now establish an upper-bound for |(J(T)−J˜(T),∆)(Θ)|. Let us recall that
(cid:104)(cid:90) T (cid:105) (cid:90) T
J(T)(Θ) = E e−βt(cid:0) (YΘ)⊺(Q+θ⊺Rθ)YΘ+(ZΘ)⊺(Qˆ +ζ⊺Rζ)ZΘ(cid:1) dt +βυ(λ) e−βtdt.
t t t t
0 0
Note carefully that (y˜Θ,∆) (resp. (z˜Θ,∆) ) is the time discretized version of the
t 0≤l≤n t 0≤l≤n
l l
process (YΘ) (resp. (ZΘ) ) with linear drift and constant diffusion coefficients.
t t∈[0,T] t t∈[0,T]
Hence, it follows from standard results on the weak approximation error (see e.g. [17], [18])
that
(cid:12)
(cid:12) (cid:104)(cid:90) T (cid:105)
(cid:12)E e−βt(cid:0) (YΘ)⊺(Q+θ⊺Rθ)YΘ+(ZΘ)⊺(Qˆ +ζ⊺Rζ)ZΘ(cid:1) dt
(cid:12) t t t t
(cid:12) 0
(cid:12)
n−1
−E(cid:104)(cid:88)
e−βt lh(cid:0) (y˜Θ,∆)⊺(Q+θ⊺Rθ)y˜Θ,∆+(z˜Θ,∆)⊺(Qˆ
+ζ⊺Rζ)z˜Θ,∆(cid:1)(cid:105)(cid:12)
(cid:12) ≤ c (Θ)h,
t t t t (cid:12) 3
l l l l
(cid:12)
l=0
for some Θ (cid:55)→ c (Θ) with at most polynomial growth. Moreover, standard results on Riemann
3
integrals give |h(cid:80)n−1e−βt l −(cid:82)T e−βtdt| ≤ Ch.
l=0 0
Combiningthetwopreviousboundswith(D.16),weconcludethatthereexistsc = c (Θ) >
3 3
0 (with at most polynomial growth in Θ) such that
|(J(T),∆−J(T))(Θ)| ≤ |(J(T),∆−J˜(T),∆)(Θ)|+|(J˜(T),∆−J(T))(Θ)| ≤ c h.
3
Since R(b) is compact, c may be considered to depend on Θ only through b.
3
Proof of Proposition D.4 Recalling that P-a.s. (θ+U ,ζ+V ) ∈ R(2b), it follows from Lemma
i i
D.6 and the fact that ∥U ∥ = ∥V ∥ = r that P-a.s.
i F i
N˜
∥(∇ˆ(T) −∇ˆ(T),∆ )J(Θ)∥ ≤ d 1 (cid:88) |(J(T)−J(T),∆)(Θ )|∥U ∥ ≤ d c (2b)T ,
θ θ F r2N˜ i i F r 3 n
i=1
N˜
∥(∇ˆ(T) −∇ˆ(T),∆ )J(Θ)∥ ≤ d 1 (cid:88) |(J(T)−J(T),∆)(Θ )|∥V ∥ ≤ d c (2b)T .
ζ ζ F r2N˜ i i F r 3 n
i=1
(cid:50)
D.4.4 Proof of Proposition D.5
Taking the empirical average over the particles in both sides of (4.6), we deduce that the
dynamics of the process (µˆΘ,∆,N := 1 (cid:80)N XΘ,∆,(j) ) is given by
t l N j=1 t l 0≤l≤N
(cid:114)
λ √ √
µˆΘ,∆,N = µˆΘ,∆,N +((Bˆ +Dζ)µˆΘ,∆,N +D R−1ξ¯N)h+ hγw¯N + hγ w0,
t l+1 t l t l 2 t l l 0 l
(D.17)
N
µˆΘ,∆,N = µˆN := 1 (cid:88) X(j) ,
0 0 N 0
j=1
55where ξ¯N = 1 (cid:80)N ξ(j) and w¯N = 1 (cid:80)N w(j). Then, let us introduce the auxiliary process
t l N j=1 t l l N j=1 l
(YΘ,∆,(j) ) defined by
t
l
YΘ,∆,(j) = XΘ,∆,(j) −µˆΘ,∆,N.
t t t
l l l
From (4.6) and (D.17), we get
(cid:114)
YΘ,∆,(j) = YΘ,∆,(j) +(cid:0) (B+Dθ)YΘ,∆,(j) +D λ R−1(ξ(j) −ξ¯N)(cid:1) h+√ hγ(w(j) −w¯N),
t l+1 t l t l 2 t l t l l l
YΘ,∆,(j) = Y(j) := X(j) −µˆN.
0 0 0 0
(D.18)
Note that (YΘ,∆,(j)) (resp. µˆΘ,∆,N) depends on Θ only through θ (resp. ζ). In order
1≤j≤N
to simplify the notation, from now on, we will write (Yθ,∆,(j)) and µˆζ,∆,N.
1≤j≤N
The average cost (4.7) can be decomposed as follows
N (cid:32)n−1
J∆,N(Θ) : = h (cid:88) (cid:88) e−βt l(cid:0) (XΘ,∆,(j) −µˆΘ,∆,N)⊺(Q+θ⊺Rθ)(XΘ,∆,(j) −µˆΘ,∆,N)
pop N t l t l t l t l
j=1 l=0
+(µˆΘ,∆,N)⊺(Qˆ +ζ⊺Rζ)µˆΘ,∆,N +2(XΘ,∆,(j) −µˆΘ,∆,N)⊺θ⊺RζµˆΘ,∆,N
t t t t t
l l l l l
(cid:114) (cid:114) (cid:114)
+2(θ(XΘ,∆,(j) −µˆΘ,∆,N)+ζµˆΘ,∆,N)⊺R λ R−1ξ(j) +(cid:0) λ R−1ξ(j)(cid:1)⊺ R λ R−1ξ(j)
t l t l t l 2 t l 2 t l 2 t l
(cid:114) (cid:114) (cid:33)
−(cid:0) λ R−1ξ(j)(cid:1)⊺
R
λ R−1ξ(j)
−
λ log((πλ)m )(cid:1)
2 t l 2 t l 2 det(R)
N (cid:32)n−1
= h (cid:88) (cid:88) e−βt l(cid:0) (Yθ,∆,(j) )⊺(Q+θ⊺Rθ)Yθ,∆,(j) +(µˆζ,∆,N)⊺(Qˆ +ζ⊺Rζ)µˆζ,∆,N
N t l t l t l t l
j=1 l=0
(cid:114) (cid:33)
+2(θYθ,∆,(j) +ζµˆζ,∆,N)⊺R λ R−1ξ(j) +βυ(λ)(cid:1)
t l t l 2 t l
n−1
(cid:88)
= J (θ)+J (ζ)+βυ(λ)h e−βt l,
1 2
l=0
(D.19)
where
N n−1 (cid:114)
J (θ) := h (cid:88)(cid:88) e−βt l(cid:0) (Yθ,∆,(j) )⊺(Q+θ⊺Rθ)Yθ,∆,(j) +2(Yθ,∆,(j) )⊺θ⊺R λ R−1ξ(j)(cid:1) ,
1 N t l t l t l 2 t l
j=1 l=0
n−1 (cid:114)
J (ζ) := h(cid:88) e−βt l(cid:0) (µˆζ,∆,N)⊺(Qˆ +ζ⊺Rζ)µˆζ,∆,N +2(µˆζ,∆,N)⊺ζ⊺R λ R−1ξ¯N(cid:1) .
2 t l t l t l 2 t l
l=0
(D.20)
56Step 1. Recall that, for Θ = (θ,ζ), Algorithm 1 gives
N˜ N˜
∇˜∆,N,popJ(Θ) = d 1 (cid:88) J∆,N,iU = d 1 (cid:88) J∆,N,iU ,
θ r2N˜ pop i r2N˜ pop i
i=1 i=1
N˜ N˜
∇˜∆,N,popJ(Θ) = d 1 (cid:88) J∆,N,iV = d 1 (cid:88) J∆,N,iV ,
ζ r2N˜ pop i r2N˜ pop i
i=1 i=1
and observe that J∆,N,i can be decomposed as follows
pop
n
J∆,N,i =
J∆,N,i+J∆,N,i+βυ(λ)h(cid:88)
e−βt l
pop pop,1 pop,2
l=1
with
N n (cid:114)
J∆,N,i := h (cid:88)(cid:88) e−βt l(cid:0) (Yθi,∆,(j) )⊺(Q+θ⊺Rθ )Yθi,∆,(j) +2(Yθi,∆,(j) )⊺θ⊺R λ R−1ξi,(j)(cid:1) ,
pop,1 N t l i i t l t l i 2 t l
j=1 l=0
n−1 (cid:114)
J∆,N,i := h(cid:88) e−βt l(cid:0) (µˆζi,∆,N)⊺(Qˆ +ζ⊺Rζ )µˆζi,∆,N +2(µˆζi,∆,N)⊺ζ⊺R λ R−1ξ¯i,N(cid:1) ,
pop,2 t l i i t l t l 2 t l
l=0
(D.21)
where (θ ,ζ ) = (θ+U ,ζ +V ) and the two processes (Yθi,∆,(j) ) , (µˆζi,∆,N) satisfy
i i i i t 0≤l≤n t 0≤l≤n
l l
(cid:114)
Yθi,∆,(j) = Yθi,∆,(j) +(cid:0) (B+Dθ )Yθi,∆,(j) +D λ R−1(ξi,(j) −ξ¯i,N)(cid:1) h+√ hγ(wi,(j) −w¯i,N),
t l+1 t l i t l 2 t l t l l l
Yθi,∆,(j) = Yi,(j) := Xi,(j) −µˆi,N,
0 0 0 0
(cid:114)
λ √ √
µˆζi,∆,N = µˆζi,∆,N +((Bˆ +Dζ )µˆζi,∆,N +D R−1ξ¯i,N)h+ hγw¯i,N + hγ wi,0,
t l+1 t l i t l 2 t l l 0 l
N
µˆζi,∆,N = µˆi,N := 1 (cid:88) Xi,(j) .
0 0 N 0
j=1
(D.22)
(cid:110) (cid:111)
Here, (ξi,(j),wi,(j),Xi,(j) ) ,wi,0;i = 1,...,N˜ arei.i.d. copiesof(ξ(j),w(j),X(j) ) ,
0 1≤j≤N 0 1≤j≤N
w0 and ξ¯i,N = 1 (cid:80)N ξj, w¯i,N = 1 (cid:80)N wj.
N j=1 N j=1
Step 2: We adapt the arguments of Lemma 35 and Lemma 44 in [6]. We introduce the sub-
exponential norm ∥·∥ and sub-Gaussian norm ∥·∥ of the random vector X:
ψ1 ψ2
(cid:40) (cid:34) (cid:35) (cid:41) (cid:40) (cid:34) (cid:35) (cid:41)
∥X∥ = inf t > 0,E exp(cid:0)|X|(cid:1) ≤ 2 ; ∥X∥ = inf t > 0,E exp(cid:0)|X|2 (cid:1) ≤ 2 .
ψ1 t ψ2 t2
57Recalling (D.3), one has
∥(∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)∥
θ θ F
N˜
= ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ,V ](cid:1) U ∥
r2N˜ pop pop i i i F
i=1
N˜ N˜
≤ ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ +∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ,
r2N˜ pop,1 pop,1 i i F r2N˜ pop,2 pop,2 i i F
i=1 i=1
and
∥(∇˜∆,N,pop−∇ˆ∆,N,pop)J(Θ)∥
ζ ζ F
N˜
= ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ,V ](cid:1) V ∥
r2N˜ pop pop i i i F
i=1
N˜ N˜
≤ ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|V ](cid:1) V ∥ +∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|V ](cid:1) V ∥ .
r2N˜ pop,1 pop,1 i i F r2N˜ pop,2 pop,2 i i F
i=1 i=1
Wenowprovidesomeupper-estimateontheprobabilitiesP(∥ d 1 (cid:80)N˜ (cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥
r2N˜ i=1 pop,ℓ pop,ℓ i i F
ε) and P(∥ d 1 (cid:80)N˜ (cid:0) J∆,N,i−E[J∆,N,i|V ](cid:1) V ∥ ≥ ε) for ℓ = 1,2.
r2N˜ i=1 pop,ℓ pop,ℓ i i F
We only deal with P(∥ d 1 (cid:80)N˜ (cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥ ε) inasmuch the proof for
r2N˜ i=1 pop,1 pop,1 i i F
the other terms are similar.
For i = 1,...,N˜, j = 1,...,N and l = 0,...,n−1, we let
(cid:114)
λ
ηi,j = (Yθi,∆,(j) )⊺(Q+θ⊺Rθ )Yθi,∆,(j) +2(Yθi,∆,(j) )⊺θ⊺R R−1ξi,(j)
l t l i i t l t l i 2 t l
(cid:114)
λ
−E[(Yθi,∆,(j) )⊺(Q+θ⊺Rθ )Yθi,∆,(j) +2(Yθi,∆,(j) )⊺θ⊺R R−1ξi,(j) |U ]
t l i i t l t l i 2 t l i
(cid:114)
λ
= (Yθi,∆,(j) )⊺(Q+θ⊺Rθ )Yθi,∆,(j) +2(Yθi,∆,(j) )⊺θ⊺R R−1ξi,(j)
t l i i t l t l i 2 t l
−E[(Yθi,∆,(j) )⊺(Q+θ⊺Rθ )Yθi,∆,(j) |U ].
t l i i t l i
where the second equality come from the fact that, conditionally on U , the two random
i
variables Yθi,∆,(j) and ξi,(j) are independent and that E[Yθi,∆,(j) |U ] = E[Yθ,∆,(j) ] = 0.
t
l
t
l
t
l
i t
l
|θ=θi
From (D.21) and the definition of ηi,j, we get
l
N n−1
J∆,N,i−E[J∆,N,i|U ] = h (cid:88)(cid:88) e−βt lηi,j
pop,1 pop,1 i N l
j=1 l=0
58so that
N˜
∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥
r2N˜ pop,1 pop,1 i i F
i=1
N˜ N n−1
= ∥ d 1 (cid:88)(cid:0) h (cid:88)(cid:88) e−βt lηi,j(cid:1) U ∥
r2N˜ N l i F
i=1 j=1 l=0
=
hd ∥(cid:0) 1 (cid:88)N n (cid:88)−1 e−βt l (cid:88)N˜ ηi,j(cid:1)
U ∥
r2 N N˜ l i F
j=1 l=0 i=1
≤
Td
sup
∥e−βt l
(cid:88)N˜
ηi,jU ∥ .
r2
1≤j≤N,0≤l≤n−1
N˜ l i F
i=1
Hence, noting that the random variables (ηi,j) have the same law and letting δ = r2ε,
1≤j≤N 2Td
the previous estimate yields
(cid:32) N˜ (cid:33)
P ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥ ε
r2N˜ pop,1 pop,1 i i F 2
i=1
≤
P(cid:32)
Td
sup sup
∥e−βt l
(cid:88)N˜
ηi,jU ∥ ≥
ε(cid:33)
r2
j=1,...,Nl=0,...,n−1
N˜ l i F 2
i=1
=
P(cid:32)
sup sup
∥e−βt
l
(cid:88)N˜
ηi,jU ∥ ≥
δ(cid:33)
(D.23)
j=1,...,Nl=0,...,n−1
N˜ l i F
i=1
≤
(cid:88)N n (cid:88)−1 P(cid:32) ∥e−βt
l
(cid:88)N˜
ηi,jU ∥ ≥
δ(cid:33)
N˜ l i F
j=1 l=0 i=1
n−1 (cid:32) N˜ (cid:33)
= N (cid:88) P ∥ 1 (cid:88) (e−βt lηi,1)U ∥ ≥ δ .
N˜ l i F
l=0 i=1
Now,iteasilyfollowsfromstandardcomputationsbasedonthedynamics(D.22)ofYθi,∆,(1)
andsincetheθ areboundedthattherandomvariablesYθi,∆,(1) havefinitesub-Gaussiannorm
i t
l
∥Yθi,∆,(1) ∥ and since ∥ξi,(j) ∥ < ∞ we deduce that ∥ηi,1∥ < ∞ uniformly in (l,i). By
t l Ψ2 t l Ψ2 l Ψ1
Lemma 37 in [6], we get
P(cid:32)
∥ 1
(cid:88)N˜
ηi,1U ∥ ≥
δ(cid:33)
≤ 2dexp(cid:0) − N˜δ2 (cid:1) , (D.24)
N˜
i=1
l i F 2(χ2
l
+χ lδ)
59where χ := C rsup ∥ηθ′,1∥ and C is a universal constant1. Hence, combining (D.23)
l 1 θ′∈B(θ,r) l ψ1 1
and (D.24), we obtain
P(cid:32)
∥ d 1
(cid:88)N˜
(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥
ε(cid:33)
≤ 2dNnexp(cid:16) − N˜δ2 (cid:17) (D.25)
r2N˜ pop,1 pop,1 i i F 2 2(χˇ2+χˇδ)
i=1
with χˇ = sup 0≤l≤n−1(cid:0) e−βt lχ l(cid:1).
Then, from Lemma D.7 (see below), taking r ≤ min{rˇ(b),inf 1 } (recalling that
Θ∈R(b) h1(Θ)
R(b) ⊆ S(b)×Sˆ(b) is compact and that according to Proposition C.1, ∥θ∥ ≤ Bd (b)) and
F θ
letting
χˆ(b) = Crˇ(b)(1+Bd (b)2+rˇ(b)2)),
θ
one has χˇ ≤ χˆ(b) uniformly for all Θ ∈ R(b).
The previous bound on χˇ together with (D.25) implies that if
(χˆ(b)2+χˆ(b)δ)(cid:16) d (cid:17)
N˜ ≥ h(1,1) (r,b) := 2 (d+1)log( )+logN +logn+log(4ε) ,
N˜ δ2 ε
then, for all Θ ∈ R(b), one has
(cid:32) N˜ (cid:33) (cid:32) (cid:33)−d
P ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥ ε ≤ 1 d .
r2N˜ pop,1 pop,1 i i F 2 2 ε
i=1
Similarly, there exists h(1,2) (r,b) such that for any N˜ ≥ h(1,2) (r,b) and any Θ ∈ R(b),
N˜ N˜
(cid:32) N˜ (cid:33) (cid:32) (cid:33)−d
P ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,2|U ](cid:1) U ∥ ≥ ε ≤ 1 d .
r2N˜ pop,2 pop,1 i i F 2 2 ε
i=1
Hence, choosing N˜ ≥ max{h(1,1) (r,b),h(1,2) (r,b)}, we get
N˜ N˜
(cid:32) (cid:33) (cid:32) N˜ (cid:33)
P ∥∇˜∆,N,popJ(Θ)−∇ˆ∆,N,popJ(Θ)∥ ≥ ε ≤ P ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥ ε
θ θ F r2N˜ pop,1 pop,1 i i F 2
i=1
(cid:32) N˜ (cid:33)
+P ∥ d 1 (cid:88)(cid:0) J∆,N,i−E[J∆,N,i|U ](cid:1) U ∥ ≥ ε
r2N˜ pop,2 pop,2 i i F 2
i=1
(cid:32) (cid:33)−d
d
≤ .
ε
The proof of the upper-bound on P(∥∇˜∆,N,popJ(Θ)−∇ˆ∆,N,popJ(Θ)∥ ≥ ε) being similar
ζ ζ F
is omitted. The proof of Proposition D.5 is now complete. (cid:50)
1Referringto[6],onewouldusethestandardoperatornorm∥·∥in(D.24). However,duetotheequivalence
of the matrix norms, we can replace ∥·∥ by the Frobenius norm ∥·∥ , up to a modification of the constant
F
C >0 which may depend on the dimensions m and d.
1
60Lemma D.7. There exists h (∥θ∥) with at most of polynomial growth in ∥θ∥ and a constant
1
C < ∞ such that for all r ≤ 1 , it holds
h1(Θ)
χˇ ≤ Cr(1+∥θ∥2 +r2).
F
Proof. Let
(cid:114)
Ψθ′ = (Yθ′,∆,(1) )⊺(Q+(θ′)⊺Rθ′)Yθ′,∆,(1) +2(Yθ′,∆,(1) )⊺(θ′)⊺R λ R−1ξ(1) , θ′ ∈ B(θ,r),
l t l t l t l 2 t l
recalling that Yθ′,∆,(1) is given by (D.18) with θ = θ′.
Since
∥Ψθ′ −E[Ψθ′
]∥ ≤
2∥Ψθ′
∥ ,
l l ψ1 l ψ1
and ηθ′,1 = Ψθ′ −E[Ψθ′], we get
l l l
χˇ ≤ 2C r sup (cid:0) e−βt l∥Ψθ′ ∥ (cid:1) .
1 l ψ1
0≤l≤n−1,θ′∈B(θ,r)
The triangle inequality for the sub-exponential norm ∥.∥ yields
Ψ1
(cid:114)
∥Ψθ′ ∥ ≤ ∥(Yθ′,∆,(1) )⊺(Q+(θ′)⊺Rθ′)Yθ′,∆,(1) ∥ +2∥(Yθ′,∆,(1) )⊺(θ′)⊺R λ R−1ξ(1) ∥ . (D.26)
l ψ1 t l t l ψ1 t l 2 t l ψ1
From Proposition 2.4 [24],
∥(Yθ′,∆,(1) )⊺(Q+(θ′)⊺Rθ′)Yθ′,∆,(1) ∥ ≤ Tr(Q+(θ′)⊺Rθ′)∥Yθ′,∆,(1) ∥2
t
l
t
l
ψ1 t
l
ψ2
≤ Cd(∥Q∥ +∥R∥ (∥θ∥ +r)2)∥Yθ′,∆,(1) ∥2 ,
F F F t
l
ψ2
and, fromtheinequality∥XY∥ ≤ ∥X∥ ∥Y∥ stemmingfromstandardYoung’sinequality,
Ψ1 Ψ2 Ψ2
(cid:114) (cid:114)
∥(Yθ′,∆,(1) )⊺(θ′)⊺R λ R−1ξ(1) ∥ = ∥(cid:0) θ′Yθ′,∆,(1)(cid:1) ·(cid:0) R λ R−1ξ(1)(cid:1) ∥
t l 2 t l ψ1 t l 2 t l ψ1
(cid:114)
≤
∥θ′Yθ′,∆,(1)
∥ ∥R
λ R−1ξ(1)
∥
t l ψ2 2 t l ψ2
(cid:114)
≤ C∥θ′∥ ∥Yθ′,∆,(1) ∥ ∥R λ R−1ξ(1) ∥
F t l ψ2 2 t l ψ2
θ′,∆,(1)
≤ C(∥θ∥ +r)∥Y ∥
F t
l
ψ2
for some constant C = C(λ,∥R∥ ).
F
Similarly to Lemma 36 [6], we can establish an universal upper-bound for the sub-Gaussian
norm of Yθ′,∆,(j) for all θ′ ∈ B(θ,r), where r ≤ 1/h (∥θ∥), h (∥θ∥) being at most of polynomial
t 1 1
l
growth in ∥θ∥. Namely, it holds
sup e−βt l∥Yθ′,∆,(j) ∥ ≤ Csup{∥Y(j) ∥ , sup ∥w(j) −w¯N∥ , sup ∥ξ(j) −ξ¯N∥ }.
t l ψ2 0 ψ2 l l ψ2 l l ψ2
0≤l≤n−1 0≤l≤n−1 0≤l≤n−1
61Plugging the three previous inequalities into (D.26), we get
∥Ψθ′ ∥ ≤ C(1+∥θ∥2 +r2)
l ψ1 F
which eventually yields
χˇ ≤ 2C r sup sup (cid:0) e−βt l∥Ψθ′ ∥ (cid:1) ≤ Cr(1+∥θ∥2 +r2),
1 l ψ1 F
l=1,...,nθ′∈B(θ,r)
for all r ≤ 1/h (∥θ∥).
1
D.4.5 Proof of Proposition D.6.
Recalling that J¯∆,N(Θ) = E[J∆,N(Θ)] and using the fact that (U ,V ) is independent
pop pop i i 1≤i≤N
of ((X(j) ,(ξ(j) ) ,W(j)) ,W0), we get E[J∆,N,i|U ,V ] = J¯∆,N(Θ ) and
0 t l 0≤l≤n−1 j=1,...,N pop i i pop i
N˜
∇ˆ∆,N,popJ(Θ) = d 1 (cid:88) J¯∆,N(θ+U ,ζ +V )U ,
θ r2N˜ pop i i i
i=1
N˜
∇ˆ∆,N,popJ(Θ) = d 1 (cid:88) J¯∆,N(θ+U ,ζ +V )V .
ζ r2N˜ pop i i i
i=1
Step 1: We introduce the process (xΘ,∆,(j)) with dynamics
j=1,...,N
√ √
xΘ,∆,(j) = xΘ,∆,(j) +(BxΘ,∆,(j) +B¯E [xΘ,∆,(j) ]+DαΘ,∆,(j) )h+ hγw(j) + hγ w0,
t l+1 t l t l 0 t l t l l 0 l
Θ,∆,(j) (j)
x = X ,
0 0
with
(cid:114)
λ
αΘ,∆,(j) = θ(xΘ,∆,(j) −E [xΘ,∆,(j) ])+ζE [xΘ,∆,(j) ]+ R−1ξ(j) ,
t l t l 0 t l 0 t l 2 t l
and where the random variables (X(j) ) , (ξ(j) := (ξ(j) ) ) , (w(j)) and
0 1≤j≤N t l 0≤l≤n−1 1≤j≤N 1≤j≤N
w0 are the same as those employed in (4.5)-(4.6).
We then define the two processes yθ,∆,(j) and zζ,∆ by
yΘ,∆,(j) = xΘ,∆,(j) −E [xΘ,∆,(j) ], zΘ,∆ = E [xΘ,∆],
t t 0 t t 0 t
l l l l l
with yΘ,∆,(j) = X(j) −E[X ] and zΘ,∆ = E[X ]. Their dynamics are given by
0 0 0 0 0
(cid:114)
yΘ,∆,(j)
=
yΘ,∆,(j) +(cid:0) (B+Dθ)yΘ,∆,(j)
+D
λ R−1ξ(j)(cid:1) h+γ√ hw(j)
,
t l+1 t l t l 2 t l l (D.27)
√
zΘ,∆ = zΘ,∆+(Bˆ +Dζ)zΘ,∆h+γ hw0.
t t t 0 l
l+1 l l
62We again notice that yΘ,∆,(j) (resp. zΘ,∆) depends only on θ (resp. ζ). Hence, in order to
simplify the notation, from now on, we will write yθ,∆,(j) and zζ,∆. Note that (yΘ,∆,(j) )
t j=1,...N
l
are i.i.d. copies of yΘ,∆ and zζ,∆ = zΘ,∆ where (yΘ,∆,zΘ,∆) are defined by (D.13). Hence,
N (cid:34)n−1
J(T),∆,N(Θ) := h (cid:88) E (cid:88) e−βt l((xΘ,∆,(j) −E [xΘ,∆])⊺Q(xΘ,∆,(j) −E [xΘ,∆])
N t l 0 t l t l 0 t l
j=1 l=0
(cid:35)
+ E [xΘ,∆,(j) ]⊺QˆE [xΘ,∆]+(αΘ,∆,(j) )⊺RαΘ,∆,(j) +λlogπΘ(αΘ,∆,(j) |xΘ,∆,(j) ,E [xΘ,∆])
0 t 0 t t t t t 0 t
l l l l l l l
N (cid:34)n−1 (cid:35)
= h (cid:88) E (cid:88) e−βt l(cid:0) (yθ,∆,(j) )⊺(Q+θ⊺Rθ)yθ,∆,(j) +(zζ,∆)⊺(Qˆ +ζ⊺Rζ)zζ,∆+βυ(λ)(cid:1)
N t l t l t l t l
j=1 l=0
= J(T),∆(Θ),
recalling that J(T),∆(Θ) is defined by (D.4). We will also use the decomposition J(T),∆,N =
J(T),∆ +J(T),∆ ++βυ(λ)h(cid:80)n e−βt
l
with
1 2 l=1
N n−1 (cid:34) (cid:35)
J(T),∆ (θ) := h (cid:88)(cid:88) e−βt lE (yθ,∆,(j) )⊺(Q+θ⊺Rθ)yθ,∆,(j) ,
1 N t l t l
j=1 l=0
n−1 (cid:34) (cid:35)
J(T),∆ (ζ) := h(cid:88) e−βt lE (zζ,∆)⊺(Qˆ +ζ⊺Rζ)zζ,∆ .
2 t l t l
l=0
Then, according to (D.19) and (D.20),
n
(cid:88)
J¯∆,N(Θ) = E[J∆,N(Θ)] = J¯(θ)+J¯(ζ)+βυ(λ)h e−βt l
pop pop 1 2
l=1
where
N n−1
J¯(θ) = E[J (θ)] = h (cid:88)(cid:88) e−βt lE[(Yθ,∆,(j) )⊺(Q+θ⊺Rθ)Yθ,∆,(j) ]
1 1 N t l t l
j=1 l=0
n−1
J¯(ζ) = E[J (ζ)] = h(cid:88) e−βt lE(cid:2) (µˆζ,∆,N)⊺(Qˆ +ζ⊺Rζ)µˆζ,∆,N(cid:3) .
2 2 t t
l l
l=0
Hence, in order toestablishanupper-boundfor(J(T),∆,N−J¯∆,N)(Θ) = (J(T),∆ −J¯)(θ)+
pop 1 1
(J(T),∆ −J¯)(ζ), we need to quantity the Lp(P) error for the difference yθ,∆,(j) −Yθ,∆,(j) and
2 2 t l t l
zζ,∆−µζ,∆,N, j = 1,...,N and l = 0,··· ,n−1.
t t
l l
Step 2: Let
θ,∆,(j) θ,∆,(j) θ,∆,(j)
Q = y −Y , j = 1,...,N,
t t t
l l l
Qˆζ,∆,N = zζ,∆−µˆζ,∆,N.
t t t
l l l
63From (D.17)-(D.18) and (D.27), we easily get
(cid:114)
Qθ,∆,(j) = Qθ,∆,(j) +h(cid:0) (B+Dθ)Qθ,∆,(j) +D λ R−1ξ¯N(cid:1) +√ hγw¯N,
t l+1 t l t l 2 t l l (D.28)
(cid:114)
Qˆζ,∆,N = Qˆζ,∆,N +h(cid:0) (Bˆ +Dζ)Qˆζ,∆,N −D λ R−1ξ¯N(cid:1) −√ hγw¯N,
t l+1 t l t l 2 t l l
with Qθ,∆,(j) = Q := µˆN −E[X ], Qˆζ,∆ = Qˆ := E[X ]−µˆN. Note carefully that for any
0 0 0 0 0 0 0 0
l = 0,...,n, the random variables (Qθ,∆,(j) ) are equal. We thus omit the superscript j
t 1≤j≤N
l
and simply write Qθ,∆ in what follows.
t
l
From (D.28), we get
(cid:114)
λ √
|Qθ,∆,(j) |2 = |Qθ,∆,(j) |2+2⟨Qθ,∆,(j) ,h(B+Dθ))Qθ,∆,(j) +hD R−1ξ¯N + hγw¯N⟩
t l+1 t l t l t l 2 t l l
(cid:114)
(cid:12) λ √ (cid:12)2
+(cid:12)h(B+Dθ))Qθ,∆,(j) +hD R−1ξ¯N + hγw¯N(cid:12)
(cid:12) t l 2 t l l (cid:12)
(cid:114)
λ √
≤ (1+hC (θ))|Qθ,∆,(j) |2+2⟨Qθ,∆,(j) ,hD R−1ξ¯N + hγw¯N⟩
1 t l t l 2 t l l
(cid:114)
(cid:12) λ √ (cid:12)2
+2(cid:12)hD R−1ξ¯N + hγw¯N(cid:12) ,
(cid:12) 2 t l l (cid:12)
for some θ (cid:55)→ C (θ) with at most of quadratic growth in ∥θ∥. Taking expectation in both sides
1
of the previous inequality and recalling that Qθ,∆,(j) is independent of ξ¯N and w¯N, we get
t
l
(cid:114)
(cid:12) λ √ (cid:12)2
E[|Qθ,∆,(j) |2] ≤ (1+hC (θ))E[|Qθ,∆,(j) |2]+2E(cid:12)hD R−1ξ¯N + hγw¯N(cid:12)
t l+1 1 t l (cid:12) 2 t l l (cid:12)
h
≤ (1+hC (θ))E[|Qθ,∆,(j) |2]+C ,
1 t l 2 N
for some constant C < ∞ and where, for the last inequality, we used the fact that E|ξ¯N|2 =
2 t
l
m/N and E|w¯N|2 = d/N, l = 0,...,n − 1. From the discrete Grönwall lemma, up to a
l
modification of C , we get
2
(cid:16) C (cid:17)
E[|Qθ,∆,(j) |2] ≤ (1+hC (θ))l E[|Qθ,∆,(j) |2]+ 2 .
t l 1 0 C (θ)N
1
Now, since E[|Qθ,∆,(j) |2] = Var(X )/N, using the standard inequality 1+x ≤ exp(x), x ∈ R,
0 0
the previous inequality eventually implies
exp(C (θ))
sup E[|Qθ,∆,(j) |2] ≤ 1 ,
t l N
0≤l≤n
up to a modification of C (θ) (with at most of quadratic growth). Similar arguments yield
1
exp(C (ζ))
sup E[|Qˆζ,∆,N|2] ≤ 2 .
t l N
0≤l≤n
64The two previous upper-bounds in turn imply
N n−1
|(J(T),∆ −J¯)(θ)| ≤ C(∥Q∥ +∥R∥ ∥θ∥2) h (cid:88)(cid:88) e−βt lE[|Yθ,∆,(j) −yθ,∆,(j) |2]
1 1 F F F N t l t l
j=1 l=0
≤ CT(∥Q∥ +∥R∥ ∥θ∥2) sup E[|Qθ,∆|2]
F F F t
l
l=0,...,n−1
exp(C (θ))
≤ 1 (∥Q∥ +∥R∥ ∥θ∥2),
N F F F
and similarly
exp(C (ζ))
|(J(T),∆ −J¯)(ζ)| ≤ 2 (∥Q∥ +∥R∥ ∥ζ∥2),
2 2 N F F F
up to a modification of C (θ) and C (ζ). Recalling that R(b) is compact, the right-hand side
1 2
of the two previous inequalities can be uniformly bounded by a constant depending only upon
b. The proof of (D.8) is now complete.
Step 3: After recalling that Θ ∈ R(2b), it directly follows from (D.8) that
i
c (2b)
|(J¯∆,N −J(T),∆)(Θ )| ≤ 4
pop i N
and, since ∥U ∥ = ∥V ∥ = r, P− a.s
i F i
N˜
∥(∇ˆ∆,N,pop−∇ˆ(T),∆ )J(Θ)∥ ≤ d 1 (cid:88) |(J¯∆,N −J(T),∆)(Θ )|∥U ∥ ≤ dc 4(2b) ,
θ θ F r2N˜ pop i i F r N
i=1
N˜
∥(∇ˆ∆,N,pop−∇ˆ(T),∆ )J(Θ)∥ ≤ d 1 (cid:88) |(J¯∆,N −J(T),∆)(Θ )|∥V ∥ ≤ dc 4(2b) ,
ζ ζ F r2N˜ pop i i F r N
i=1
which ends the proof. (cid:50)
References
[1] A.Angiuli,J-.P.Fouque,andM.Laurière. UnifiedreinforcementQ-learningformeanfield
game and control problems. Mathematics of Control, Signals and Systems, 34:217–271,
2022.
[2] M. Basei and H. Pham. A weak martingale approach to linear-quadratic mckean-
vlasov stochastic control problems. Journal of Optimization Theory and Applications,
181(2):347–382, 2019.
65[3] J.Bu, A.Mesbahi, andM.Mesbahi. Policygradient-basedalgorithmsforcontinuous-time
linear quadratic control. arXiv:2006.09178, 2020.
[4] R. Carmona and F. Delarue. Probabilistic Theory of Mean Field Games: vol. I, Mean
Field FBSDEs, Control, and Games. Springer, 2018.
[5] R. Carmona and F. Delarue. Probabilistic Theory of Mean Field Games: vol. II, Mean
Field game with common noise and Master equations. Springer, 2018.
[6] R.Carmona,M.Laurière,andZ.Tan. Linear-quadraticmean-fieldreinforcementlearning:
convergence of policy gradient methods. arXiv:1910.04295, 2019.
[7] R. Carmona, M. Laurière, and Z. Tan. Model-free mean-field reinforcement learning:
Mean-field MDP and mean-field Q-learning. The Annals of Applied Probability,
33(6B):5334 – 5381, 2023.
[8] M. Fazel, R. Ge, S.M. Kakade, and M. Mesbahi. Global convergence of policy gradient
methods for the linear quadratic regulator. Proceedings of the 35th International
Conference on Machine Learning, pages 1467–1476, 2018.
[9] N. Frikha, M. Germain, M. Laurière, H. Pham, and X. Song. Actor-critic learning for
mean-field control in continuous time. arXiv: 2303.06993, 2023.
[10] M. Giegrich, C. Reisinger, and Y. Zhang. Convergence of policy gradient methods for
finite-horizon exploratory linear-quadratic control problems. SIAM Journal on Control
and Optimization, 62(2):1060–1092, 2024.
[11] H. Gu, X. Guo, X. Wei, and R. Xu. Mean field controls with Q-learning for cooperative
MARL: convergence and complexity analysis. SIAM Journal on Mathematics of Data
Science, 3(4), 2021.
[12] X. Guo, X. Li, and R. Xu. Fast policy learning for linear-quadratic control with entropy
regularization. arXiv:2311.14168v3, 2023.
[13] B. Hambly, R. Xu, and H. Yang. Policy gradient methods for the noisy linear quadratic
regulator over a finite horizon. SIAM Journal on Control and Optimization, 59(5):3359–
3391, 2021.
[14] Y. Jia and X.Y. Zhou. Policy gradient and actor–critic learning in continuous time and
space: Theory and algorithms. Journal of Machine Learning Research, 2021.
[15] Y. Jia and X.Y. Zhou. q learning in continuous time. Journal of Machine Learning
Research, 2023.
66[16] H. Mohammadi, A. Zare, M. Soltanolkotabi, and M. R. Jovanović. Convergence and
sample complexity of gradient methods for the model-free linear–quadratic regulator
problem. IEEE Transactions on Automatic Control, 67(5):2435–2450, 2022.
[17] Rémi Munos. Policy gradient in continuous time. Journal of Machine Learning Research,
7(27):771–791, 2006.
[18] EckhardPlatenPeterE.Kloeden. NumericalSolutionofStochasticDifferentialEquations.
Springer Berlin, Heidelberg, 1992.
[19] H. Pham and X. Warin. Actor-critic learning algorithms for mean-field control with
moment neural networks. arXiv: 2309.04317, 2023.
[20] R.SuttonandA.Barto. Reinforcement Learning: An Introduction. Cambridge, MA:MIT,
2018.
[21] L. Szpruch, T. Treetanthiploet, and Y. Zhang. Optimal scheduling of entropy regularizer
for continuous-time linear-quadratic reinforcement learning. SIAM Journal on Control
and Optimization, 62(1):135–166, 2024.
[22] H. Wang, T. Zariphopoulou, and X.Y. Zhou. Reinforcement learning in continuous
time and space: A stochastic control approach. Journal of Machine Learning Research,
21(198):1–34,, 2020.
[23] W.Wang, J.Han, Z.Yang, andZ.Wang. Globalconvergenceofpolicygradientforlinear-
quadratic mean-field control/game in continuous time. Proceedings of Machine Learning
Research, 2021.
[24] K. Zajkowski. Bounds on tail probabilities for quadratic forms in dependent sub-gaussian
random variables. Statistics & Probability Letters, 167:108898, 2020.
67