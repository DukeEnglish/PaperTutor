Detection of Compromised Functions in a Serverless
Cloud Environment
Danielle Lavi, Oleg Brodt, Dudu Mimran, Yuval Elovici, Asaf Shabtai
Dept. of Software and Information Systems Engineering
Ben-Gurion University of the Negev,
Abstract
Serverless computing is an emerging cloud paradigm with serverless func-
tions at its core. While serverless environments enable software developers
to focus on developing applications without the need to actively manage the
underlying runtime infrastructure, they open the door to a wide variety of
security threats that can be challenging to mitigate with existing methods.
Existing security solutions do not apply to all serverless architectures, since
they require significant modifications to the serverless infrastructure or rely
on third-party services for the collection of more detailed data. In this pa-
per, we present an extendable serverless security threat detection model that
leverages cloud providers’ native monitoring tools to detect anomalous be-
havior in serverless applications. Our model aims to detect compromised
serverless functions by identifying post-exploitation abnormal behavior re-
lated to different types of attacks on serverless functions, and therefore, it is
a last line of defense. Our approach is not tied to any specific serverless ap-
plication, is agnostic to the type of threats, and is adaptable through model
adjustments. To evaluate our model’s performance, we developed a server-
less cybersecurity testbed in an AWS cloud environment, which includes two
4202
guA
5
]RC.sc[
1v14620.8042:viXradifferent serverless applications and simulates a variety of attack scenarios
that cover the main security threats faced by serverless functions. Our eval-
uation demonstrates our model’s ability to detect all implemented attacks
while maintaining a negligible false alarm rate.
Keywords: Serverless Computing, Anomaly Detection, Deep Learning
1. Introduction
Serverlesscomputingisanincreasinglypopularcloudcomputingparadigm
that enables organizations to build and deploy software and services in the
cloud, without the need to maintain, provide, or scale resources like physi-
cal or virtual servers [1], and to pay only for the resources their applications
consume. ItprimarilyprovidescloudusagemodelscenteredaroundBackend-
as-a-Service (BaaS) and Function-as-a-Service (FaaS) [2], with Function-as-
a-Service being the predominant serverless model [3]. Within the context
of Function-as-a-Service (FaaS), serverless functions (e.g., AWS Lambda [4],
Microsoft Azure Functions [5], Google Cloud Functions [6]) are compact,
stateless, single-purpose components of business logic within a serverless ap-
plication, and are intended to be activated in response to predefined events.
The rapid shift from on-premises to cloud computing and serverless com-
puting has presented cybersecurity defenders with a wider attack surface [7]
and a growing number of challenges [8], some of which are described below.
Limited access to the underlying infrastructure. In serverless com-
puting, organizations typically operate within predefined infrastructure con-
figurations, lacking the capability to customize them to meet their specific
security requirements. As a result, security teams cannot add lower-level
2defenses or monitoring capabilities, and they must rely on the existing mea-
sures and logging provided by the cloud platform. Thus, their ability to
assess their system’s threats and determine the organization’s defense pos-
ture is limited [9, 10].
Short development cycles. In an agile application development setting,
many code changes are made, and new resources are often created, making
the application more dynamic, which in turn makes application monitoring
much more challenging. As serverless applications’ code changes frequently,
maintaining a consistent security posture is challenging due to a constantly
shifting attack surface and changes in logging data, application configura-
tions, and permissions.
Large and complex attack surface. While serverless applications have
inherited the security problems typically associated with cloud computing
(e.g., configuration mismanagement, identity management, data leakage),
they also have their own security issues, resulting in a larger attack sur-
face [11, 12]. In most cases, serverless functions perform a single atomic task
and are able to run in parallel with other functions. Therefore, thousands of
serverless functions may use the same resources at the same time and need
to communicate with one another and with additional services, which creates
a complex and wide attack surface. In addition, serverless functions may be
invoked by a plethora of internal and external events, providing an attacker
with a variety of avenues to try and exploit.
Although the challenges of and threats to serverless computing are well
documented, in many cases, the research community has yet to provide ef-
fective solutions [9]. The solutions proposed in prior research in the field
3relied on rule-based methods [13], required the cooperation of third-party
services [14, 15], or demanded modifications that could not be made in a
fully managed environment [15, 16, 17, 18]. The majority of the suggested
approaches involve either static or dynamic analysis of applications. This
analysis aims to identify irregularities in the applications’ data flow and
to enforce access control measures. For example, static analysis solutions
can be used to audit and detect “bad practices” concerning serverless secu-
rity [13, 19]. However, this approach does not detect external threats (e.g.,
injections) or scale well in fast-moving, dynamic environments. Furthermore,
static analysis techniques may misclassify malicious code as benign, as these
methods can encounter difficulties in distinguishing subtle distinctions be-
tween malicious and legitimate code.
Previous research that employed dynamic analysis techniques used mod-
ified versions of the functions’ runtime environment to monitor and detect
malicious activity [15, 16, 17, 18]. Those methods, however, do not address
the need for threat detection solutions in a fully managed serverless environ-
ment. Their ability to control and modify the existing infrastructure is only
possible when operating in a non-managed environment, which is unrealistic
in the major cloud providers’ settings. Moreover, the approach adopted by
many of these solutions [15, 16, 20, 18] in countering injection attacks or
the introduction of malicious code through the supply chain, involves the
blocking of suspicious requests, rather than actively identifying and flagging
malicious behavior, and take the “presumption of compromise” approach. In
addition to the fact that prevention is usually prone to failure, this approach
could also lead to a high false alarm rate, which would interfere with the
4application’s availability.
While serverless computing poses many security challenges, it also offers
new threat detection opportunities, since atomic units of serverless functions
enable native function-level logging with high granularity. Among other
things, high-resolution logging allows application administrators to gain a
deeper understanding of serverless applications and security teams to iden-
tify anomalies and potential threats. In this study, we address threats to
serverless functions by leveraging native function-level logging. There are
several issues arising when developing a threat detection model for serverless
functions, including issues stemming from their dynamic nature, high vol-
ume, and the wide variety of activities that take place during their lifetimes.
These create a lot of noise in a system and enable attackers to “stay below
the radar.”
In this paper, we propose an unsupervised deep learning anomaly detec-
tionmodelthatreliessolelyonthecloud provider’s native monitoring tools to
detect abnormal behavior in serverless applications. Rather than addressing
the many ways in which a system can be attacked, our model concentrates
on an attack’s impact on the application’s behavior. It is designed to de-
tect abnormal behavior as manifested in the native activity logs while being
agnostic to the type of threat (known or unknown).
Our detection model can be used in an online or offline mode. Regardless
of the mode, the model learns the normal behavior of the serverless envi-
ronment, specifically, serverless functions. In an online mode, the model is
used continuously to issue alerts for anomalies in real-time. In an offline
mode, the model is only used when the enterprise requires hyper-logging and
5hyper-monitoring capabilities, as in the case of incident response, to allow
responders to monitor and quickly zero in on abnormal behavior. Since there
is often a trade-off between security and resource utilization, each organiza-
tion can determine the appropriate mode of operation based on its security
policy and risk assessment.
Our model does not require any changes to the existing infrastructure,
as it uses the monitoring tools that exist in cloud environments. The unique
features extracted by our threat detection model enrich the basic informa-
tion provided by the activity logs and create a more in-depth informative
perspective on the behavior of serverless functions.
To evaluate the proposed model, we developed a serverless evaluation
testbed in an AWS environment that contains two open-source serverless
applications. As part of the testbed, we simulated benign user activity as
wellasavarietyofattacks. Inourevaluation, themodelsuccessfullydetected
all of the implemented attacks while maintaining a very low false alarm rate
(0.003). Such capabilities are crucial for improving the security of today’s
widely used serverless platforms and the performance of the security teams
responsible for defending them.
To summarize, the contributions of our paper are as follows:
• We present a novel threat detection model specifically designed for the
identificationofcompromisedserverlessfunctions. Theproposedmodel
is built on top of cloud providers’ native hyper-logging and monitor-
ing tools, and security teams can use it without the need for external
collaboration (e.g., asking a developer to change the source code or
enlisting the cooperation of third-party services).
6• Our approach is serverless application agnostic, threat agnostic, easy
to expand with model fine-tuning, and easy to maintain, since orga-
nizations can use the same model to monitor multiple functions and
applications (instead of creating a model for each function).
• We collected a unique anomaly detection dataset that contains data
reflecting the activity of two different serverless applications, each of
which was developed in a different serverless paradigm and has its own
unique characteristics.
• We have made the dataset, testbed, code, and application activity sim-
ulator available to the research community (the relevant details will be
published with this paper).
2. Threat Model
In addition to being prone to cloud-related threats, serverless environ-
ments have a unique threat landscape of their own [11, 12]. Serverless func-
tions, which are the main component of serverless environments, provide
attackers with new opportunities to exploit the functions’ permissions and
accomplish their goals [11, 12, 9, 21]. These functions are often composed
of different components and services, creating many potential entry points
for attackers (e.g., the function’s code or dependencies, the underlying in-
frastructure). Serverless functions are event-driven and can be invoked in
response to a wide variety of events (e.g., HTTP requests, database updates,
storage modifications), which increases their attack surface. They are also
stateless and short-lived. As a result, it is complicated to determine their
7role within the application flow and the context in which they run.
In addition to the security complexity associated with the intrinsic na-
tureofserverlessfunctions,misconfigurationerrorsmayalsoplayasignificant
role. A misconfigured function (e.g., over-privileged, having an excessively
long timeout) may result in vulnerabilities that allow an attacker to exploit
the function [22]. In our research, we define a compromised serverless func-
tion as one that acts in a way that was unintended as a result of the action of
a malicious actor. Our challenge is to detect compromised functions among a
large number of functions running simultaneously and operating on the same
resources.
Since serverless environments rely heavily on serverless functions, in this
paper we explore the threat associated with serverless function hijacking and
demonstrate how it may inflict damage on the CIA triad of confidentiality,
integrity, and availability.
2.1. Attacks on integrity - permission misuse
Permission misuse, which is a deliberate and malicious attack pattern,
occurs when a user’s (either a human user or a system resource) permission
is used inappropriately. In many cases, misusing permissions is possible due
to excessive privileges being granted to resources and functions in violation
of the least privilege principle [23, 12]. These over-privileged functions allow
attackers to manipulate execution flows to their advantage. For example,
when permissions are granted too broadly, a function may be able to access
resources or perform actions it should not be allowed to perform [11]. In this
paper, we consider permission misuse as any action that deviates from the
intended utilization of a serverless function’s permissions.
82.2. Attacks on confidentiality - data leakage
In general, data leakage is the exposure of sensitive data outside a specific
network. Data sources are an integral component of serverless applications,
and any activity involving a data source can initiate the execution of func-
tions, promoting the exchange of data between them. This behavior is a
result of the event-driven nature inherent to the serverless paradigm. This,
along with misconfigured resources, can lead to the leakage of confidential
data. For example, one of the most common data leakage scenarios in AWS-
based environments occurs when an Amazon Simple Storage Service (S3)
bucket is misconfigured, and its permissions are set as public, thereby allow-
ing public access to internal private data [24, 25]. In this study, we examined
the act of writing sensitive and confidential information to a public access
bucket performed by a compromised serverless function.
2.3. Attacks on availability - denial-of-wallet
A denial-of-wallet (DoW) attack targets cloud applications in general and
serverless applications in particular. Similar to a typical DoS attack, a DoW
attack attempts to exhaust a specific resource. In this case, the resource is
the budget allocated by the cloud administrator for computational resources.
Accordingly, the attacker seeks to over-utilize cloud-based resources, which
results in higher cloud-use bills, exceeds the allotted budget, or even pushes
the application owner into bankruptcy [11]. DoW attacks take advantage
of the scalability of serverless applications to artificially increase cloud re-
source consumption, which may eventually inflate the application’s cost and
exhaust its budget [26]. DoW attacks have become a significant threat to
serverless applications, requiring consideration, detection, and mitigation. In
9this study, we examined cases where a function excessively consumes cloud
resources.
In Section 6.3, we describe our implementation of permission misuse,
data leakage, and DoW attacks using compromised serverless functions and
demonstrate how our proposed method can detect such attacks.
3. Background
In this paper, we focus on the following elements of serverless computing:
• Serverless functions - Event-driven computing services that allow code
to be run without provisioning or managing servers and automatically
manage the computing resources required by that code.
• Data resources - Cloud services that are responsible for data storage.
• Trigger events - A Group of services that trigger and orchestrate the
activation of serverless functions by leveraging the serverless applications’
event-drivennature(e.g.,AWSEventBridge,API Gateway,andStep Func-
tion).
• Monitoring tools - Services that audit and monitor the activities of the
different entities in the cloud environment. These tools can monitor both
interactions between different cloud entities and the inner flow of serverless
functions.
Our evaluation was performed using applications we deployed in the AWS
cloud environment. We used AWS Lambda to implement the serverless func-
tions, AWS Simple Storage Service (S3) as a data storage service, and AWS
10DynamoDB as a database service. The following three trigger events were
used:
• EventBridge - A serverless bus event used to trigger event-driven func-
tions (e.g., trigger Lambda functions on timed events).
• API Gateway -AservicethatenablesthemaintenanceofRESTfulAPIs.
Inourevaluationtestbed, theapplicationreceivesAPIrequestsfromusers,
and the API Gateway service triggers Lambda functions in response.
• Step Function - A workflow service used to orchestrate microservices,
build pipelines using AWS services, and combine multiple Lambda func-
tions in responsive serverless applications and microservices. The Step
Function service allows us to orchestrate complete application workflows.
We also use the following monitoring and application logging tools in our
AWS evaluation environment:
• CloudTrail1 - A service that provides logs for every API call in the cloud
environment. These API calls may be a database operation, an invocation
ofaserverlessfunction, oranyotheruseofanAWSservicebythefunction.
• CloudWatch2 - A monitoring and observability service that collects the
logs provided by CloudTrail.
• X-Ray3 - A debugging tool for AWS services which can be utilized in
both development and production settings. It collects detailed information
1https://aws.amazon.com/cloudtrail/
2https://aws.amazon.com/cloudwatch/
3https://aws.amazon.com/xray/
11about application flows’ activities, tracks the relationships among different
components, and builds an execution graph for each session.
4. Related Work
In this section, we review recent work in two areas: threat detection
methods in serverless environments and anomaly detection models that use
logs as their data source.
4.1. Threat detection in serverless environments
Several approaches for serverless security have been explored in previous
research (a comparative analysis of these works is presented in Table 1).
Obetz et al. [13] proposed a static analysis technique for extended call
graphs that considers the relationships among functions and other backend
services. The information that can be obtained through static analysis is,
however, limited and covers very few of the possible threats. In several
studies, dynamic analysis techniques were suggested to better understand
the behind-the-scenes activity that takes place when an application runs.
Some focused on an application’s data flow [14, 15], while others focused on
an application’s control flow [20, 16, 18].
Alpernas et al. [14] introduced Trapeze, a dynamic information flow con-
trol model designed to monitor and track the global information flow in
JavaScript serverless applications. Their solution, however, mandates ad-
justments to all utilized services within the application, presumes specific
programming language choices for serverless functions, and requires that de-
velopers configure the information flow policies. Datta et al. [15] presented
12Valve, a platform for dynamic information flow control that uses network-
level tainting to monitor functions’ activity and detect attacks. Valve and
Trapeze both rely on the collaboration of third-party services to track and
monitor the functions’ activity, which can raise concerns related to depen-
dency and compliance, and is not feasible with all serverless architectures.
SecLambda, an architecture for securing serverless applications, was in-
troduced by Jegan et al. [20]. Their solution provides an extension that
monitors and blocks requests within each serverless runtime environment in
addition to a control program that monitors the system. Sankaran et al. [16]
proposedWILL.IAM,anaccesscontrolflowmodelforserverlessapplications,
which creates workflow-based policies to enforce. The solutions mentioned
above focus on signatures of previously observed legitimate flows and specific
patterns of serverless applications, without aiming to obtain any knowledge
ofmoresophisticatedpatterns. Contrarytothis, ourobjectiveistoidentifya
wide variety of anomalies using deep neural networks’ ability to learn hidden
behavioral patterns in applications’ activities. By doing so, we aim to detect
both known and unknown attacks with no need for prior knowledge of their
signatures. Furthermore, the proposed solutions primarily adopt preventive
measures to address attacks in cloud-based environments, by reducing the
attack surface through the enforcement of stringent flow and access control
policies, which involve rejecting suspicious access requests. In contrast, our
approach serves as a final line of defense, granting users the ability to assess
the detected anomalies’ severity and determine the proper response to them
to gain a better security position.
Datta et al. [17] presented ALASTOR, a framework that collects the
13system and application layers’ information regarding functions’ activity. A
global data provenance graph is then created based on the information gath-
ered. Kalium, an extensible security framework to enforce control-flow in-
tegrity for serverless functions and serverless applications, was proposed by
Jegan et al. [18].
Multiple previously proposed solutions [15, 16, 17, 20, 18] were imple-
mented in a non-managed serverless environment, thus not meeting the need
for threat detection solutions in a fully managed serverless environment. In
a non-managed serverless architecture, the organization is responsible for in-
frastructure management. This gives the organization greater control of the
infrastructure and allows it to modify the infrastructure based on its secu-
rity needs. In this paper, we show that threat detection can be achieved in a
fully managed serverless environment, using only the monitoring and logging
tools provided by the cloud provider, without the need to modify the existing
infrastructure.
4.2. Log analysis for anomaly detection
Logging and monitoring system activities are vital for evaluating a sys-
tem’s state and performance, and obtaining a complete picture of the activ-
ities in it. The ability to debug, identify root causes, and detect anomalies
relies on the availability of detailed information about the system’s activities.
Automated analysis of log files enables the detection of critical incidents, like
system failures, at an early stage.
Anomaly detection within log files is a broad field of study. Examples of
Previous research in this domain have utilized conventional machine learning
techniques, such as SVM [27] and clustering [28], as well as deep learning
14methods, such as LSTM [29, 30, 31], autoencoders [32], transformers [33],
and graph embedding [34]. Other studies modeled logs generically [29, 35]
or modeled specific activities like network traffic [36], user activity [37], or
other domains [38].
With the growth in log volume, traditional anomaly detection methods
that rely on manual inspection have become impractical. Manually crafted
signatures and rule-based approaches that search for predefined keywords in
logs exhibit limited flexibility and are unsuitable for unknown scenarios that
are not pre-identified. Self-learning anomaly detection methods can identify
anomalous log events by recognizing patterns within log files without manual
intervention or pre-modeling of abnormalities. This issue has been addressed
through extensive research using deep-learning neural networks [39].
Deep learning methods have also been shown to perform better than
conventional anomaly detection methods when it comes to learning feature
representations and using them to detect anomalies in real-world applica-
tions [39, 40].
Our model also employs anomaly detection in log data via a deep learning
approach. However, wecustomizedourdatapreprocessingspecificallyforthe
task of analyzing serverless application logs, taking into account their unique
characteristics (e.g., combining log files from various sources that contain
different details with different granularity levels about a specific request, so
we can gather as much information as possible, and use it to generate new
features for our model).
15Table 1: Comparative analysis of related work solutions
Doesn’trequire Compatibilitywith
Non-managed Dynamic Noinfrastructure Language- Detective
Reference 3rd-Party Cloudproviders’
environment analysis modifications agnostic approach
collaboration nativelogging
Trapeze[14] X
StaticCallGraph[13] X X X X X X
Valve[15] X X
SecLambda[20] X X X
WILL.IAM[16] X X X
ALASTOR[17] X X X X
Kalium[18] X X X
OurSolution X X X X X X X
5. Proposed Method
In this section, we present the proposed methodology of our anomaly de-
tection model. We start by introducing the notations used, then we describe
our method for the compromised function detection model, and finally, we
present the update component integrated into our model.
5.1. Notations
The logs used by our threat detection model contain application flows.
An application flow is usually triggered by an action outside of the cloud
environment (e.g., a REST API call or a file upload to a public storage
service). Each application flow is constructed by sequences of function flows,
where each function flow is composed of a sequence of function events such
as internal functions’ calls or resource operations.
An example of an application flow in our testbed is presented in Figure 1
(denoted by AF ). As can be seen in our booking application flow example,
5
the application flow is triggered by a REST API call and is composed of
four function flows. In this example, the third function flow is the flow
16of a function named ConfirmBooking (denoted by FF ), which contains a
3
sequence of four function events.
Each function event is defined by the following properties:
• ApplicationName is the name of the application in which the event
occurred.
• ApplicationFlowId is the identifier of the application flow in which
the event occurred.
• FunctionName is the name of the Function in which the event oc-
curred.
• FunctionFlowId is the identifier of the function flow in which the
event occurred.
• EventId is the identifier of the event.
• StartTime is the event’s start time.
• EndTime is the event’s end time.
• EventName is the name of the operation that took place (e.g., initial-
ization, invocation, overhead, a resource operation (GetItem, PutItem,
etc.), or the name of an internal function that was called).
• EventType is the type of event (e.g., an internal function call, the
event’s serverless service name (DynamoDB, S3, SNS, etc.), or other).
• EventParentName is the name of the event’s predecessor. In some
cases,aneventmaybetriggeredbyanotherevent. Insuchcases,thelog
17provides information about the calling event. For example, in Figure 1
the “Update Item” event (E ) is called by the “Lambda Handler” event
3
(E ).
2
• EventTargetResource is the event operation’s target resource.
Figure 1: An application flow of a booking process in our testbed. This application flow
is comprised of a series of function flows, each containing a sequence of function events.
Each function event has a log entry that provides comprehensive details about it.
5.2. Compromised function detection model
The compromised function detection model focuses on serverless func-
tions’ flow and aims to detect deviations from their normal activity. The
events that occur during the execution of each function are represented by a
18sequence of vectors, where each vector represents an event in the sequence.
This way we are able to use the high granularity of the cloud provider’s logs
to model and detect abnormalities in the order of the events in a function’s
execution as well as in the events’ attributes. This is done by training several
LSTM autoencoders. The LSTM autoencoder is a deep learning architecture
that learns to encode and decode sequences. Each autoencoder processes the
sequences of the event vectors, capturing temporal dependencies and com-
plex patterns present both within the data and in each event within these
sequences. Ultimately, it identifies anomalous sequences based on the in-
sights it has gained. Figure 2 provides an overview of the key steps in the
model’s workflow.
Figure 2: An overview of the essential processes in our compromised functions anomaly
detection model.
5.2.1. Data collection
We use the cloud provider’s native hyper-logging and monitoring tools
to collect our data. The platforms of all major cloud providers include
19such tools.4 (i.e., AWS, Microsoft Azure, Google Cloud) We collect the raw
logs containing information regarding the activity of the serverless applica-
tionsimplementedandusethemtotrainourcompromisedfunctiondetection
model under the assumptions that (1) the attacker is unable to control log-
ging, and (2) the logs are unmodified and reflect the real activity of the
system (i.e., functions).
5.2.2. Preprocessing
AsdescribedinSection5.1,thedatawecollectconsistsofapplicationflows
representing the activities of the examined applications in a serverless envi-
ronment. From these applicationflows, we use the functionflows of the
examined functions. In order to represent each function execution, in the
preprocessing phase, we create a sequence of n vectors. Each vector rep-
resents an event that occurred as part of the functionflow. The relevant
features of each event are extracted from the log entry associated with the
event, and new features are generated based on these features.
The features extracted directly from the event’s log entry include (see Sec-
tion5.1): ApplicationName, EventName, EventType, EventParentName, and
EventTargetResource.
The new features generated based on the event’s log entry include: Event-
Duration - the difference between the event’s StartTime and EndTime; Rel-
ativeStartTime - the time that passed since the StartTime of the first event
in the sequence; and the depth of the event - the depth of the parent event
plus one or one if the event has no EventParentName.
4https://cloud.google.com/free/docs/aws-azure-gcp-service-comparison
20These features are used to construct the event vectors.
In order to represent categorical features, we use the Chars2vec library,5
which embeds words using a pretrained model (eng 50) and returns a vector
of 50 dimensions for each word. To represent each word, we use the first
four dimensions of the vector. Our vocabulary is primarily comprised of
the names of serverless services, resources, and operations. Consequently,
despitethemodel’spotentialuseacrossnumerousapplicationsandfunctions,
the vocabulary will consistently encompass a finite number of unique words.
As a result, the use of the first four dimensions for each vector effectively
gives distinct meanings for each word within the limited vocabulary. In the
training phase, the minimal and maximal values of each feature are stored.
Using these values, we employ min-max normalization to the feature values
within both the training and test sets. Figure 3 presents an example of an
event vector associated with a UpdateItem operation in DynamoDB, before
and after it was encoded and normalized.
5.2.3. Anomaly detection
In order to learn the normal behavior patterns of the serverless functions,
we train an LSTM autoencoder using the vector sequences we created as
training samples. Using the sequences generated in the preprocessing stage
as input to the LSTM autoencoders, each autoencoder learns the typical pat-
terns of the functions’ sequences. The LSTM autoencoder encodes and de-
codes each function instance represented by a sequence of vectors. Then, we
use the reconstruction error (computed using the mean square error (MSE))
5https://github.com/IntuitionEngineeringTeam/chars2vec
21Figure 3: Example of an event vector associated with the UpdateItem operation. Each
categorical feature is represented by a pair of numerical values, and subsequently, all the
values in the vector are normalized to fit within the [0,1] range based on their respective
minimal and maximal values.
of each sequence to determine the anomaly score of the instance it represents.
Sequences with a reconstruction error exceeding the predefined threshold are
marked as potential attacks, suggesting that the observed activities deviate
from the expected norm. Conversely, if the reconstruction error falls be-
22low the threshold, the sequence is classified as benign, indicating that the
activities align with the anticipated behavior.
We trained three distinct autoencoders, each customized for a specific
sequence size. We handle vector sequences whose length differs from the
autoencoder’s input layer length (referred to as the window size) as follows:
• Iftheeventsequenceofafunctionexceedsthewindowsize, wegenerate
new sequences by applying a sliding window technique with a stride of
one. For instance, if the window size is three and the function sequence
contains four events, we create two new sequences. The first sequence
consists of the initial three events from the function sequence, and the
second sequence is comprised of the last three events from the function
sequence.
• If the event sequence of a function is shorter than the window size, the
sequence is padded with zero vectors.
To identify the optimal window size for detecting attacks, we performed
a comprehensive grid search. This analysis revealed that different attacks
were effectively captured within distinct timeframes. The most favorable
results were achieved using window sizes of 3, 5, and 10. The architecture
of the network is identical for all of the autoencoders and is described in
Section 7. An event sequence is classified as anomalous if at least one of the
autoencoders classified it as such.
The classification threshold for categorizing each sample as either benign
or anomalous is determined based on the reconstruction errors observed in
the validation set during the training phase. Our objective is to establish a
23threshold that strikes a balance, ensuring it is neither overly strict nor overly
lenient. To achieve this balance, we apply the DBSCAN algorithm to the
validation set errors.
DBSCAN is a density-based clustering algorithm designed to identify
dense clusters within the data, differentiating them from regions of lower
density [41]. This approach enables us to base the threshold value solely
on the normal samples while disregarding the outliers in the dataset. The
DBSCANalgorithmreliesontwoessentialparameters: epsilonandminimum
samples. Epsilon determines the maximum distance between two points for
them to be considered part of the same cluster. The minimum samples
parameter dictates the minimum number of data points required to form a
cluster. The algorithm’s epsilon parameter is set to the 99th percentile of
the validation set’s reconstruction errors, and the minimum sample size is
set at five. In the process of eliminating outliers, we focus on clusters that
comprise more than 5% of the total validation set size. This criterion helps
remove noise and spurious clusters, ensuring that only meaningful clusters
are retained for analysis. Finally, to determine our threshold, we set it as
double the highest reconstruction error within the remaining clusters.
Figure 4 illustrates the errors observed in the validation set of one of
the autoencoders, and the threshold established based on them through the
described procedure.
5.3. Updating the model
Understandingthesignificanceofathreatdetectiontool’sabilitytoadapt
to evolving circumstances and its need to stay current with the latest infor-
mation, we have integrated a model update component into our framework.
24Figure 4: An illustration of the errors observed in the validation set of an autoencoder
with a window size of 10; the red line indicates the threshold (0.0187) established based
on these errors.
This component serves the following purposes:
• Incorporating new functions. As organizations maintain and develop
their applications, they frequently introduce new functionalities. Our
model needs to stay aligned with these developments.
• Managing code modifications and concept drifts. As the application
evolves, code updates enhance features and resolve issues, while con-
cept drifts occur due to changing data patterns influenced by user be-
havior, market dynamics, or external factors. To ensure the model’s
25effectiveness, it must seamlessly adapt to these changes.
• Enhancing the model’s capability to identify rare legitimate events.
This ensures that genuine occurrences are not mistakenly flagged as
threats.
Updating the entire model can be a resource-intensive task, requiring
significant computational power and time. In recognition of this challenge,
our model update component offers a more efficient approach through it-
erative updates (delta updates). This way, only the necessary adjustments
or changes to the model are implemented, rather than retraining the entire
model from scratch.
In this procedure, we fine-tune the model using the new data along with
approximately 10% of the original training set used to train the original
model. We found this combination of training data and new data yields the
best results. It is worth noting that the data from the original training set
which is employed when updating the model, may be deliberately chosen.
This planned selection approach can be tailored to account for outliers, such
as rare legitimate events identified using the original model, or to accommo-
date outdated data, such as refactored and modified functions. We discuss
this point further in the evaluation section.
To establish the new threshold, the entire original validation set is re-
tained, and the new validation data is added to it. To determine the new
threshold, we predict the errors of the combined validation set using the
updated model and subsequently apply the original automated threshold
procedure to calculate the adjusted threshold.
266. Serverless Cybersecurity Evaluation Testbed
To analyze and assess our model’s performance, we required an experi-
mentalserverlesscloudenvironment. Forthispurpose,wecreatedaserverless
cybersecurity evaluation testbed, designed to achieve the following goals: (1)
cover various serverless development paradigms employing a wide range of
serverless cloud resources, (2) generate a large amount of authentic log data
reflecting real-life activities, and (3) simulate the consequences of typical at-
tack scenarios. We created our testbed on the AWS platform, and employed
the AWS X-Ray service as a native fine-grained logging tool.
6.1. Testbed applications
The testbed consists of two different applications: (1) an airline book-
ing application,6 and (2) a video on demand (VOD) application.7 These
applications were selected, because they represent two different serverless
development approaches. They also provide an opportunity to explore a
wide range of AWS serverless services in the testbed. In the airline booking
application, each serverless function serves a specific, well-defined purpose in
the workflow. Conversely, in the VOD application, the functions have a more
versatile and generic nature and are capable of being used in various con-
texts and scenarios. The architectures of the two applications are presented
in Figure 5.
6https://github.com/aws-samples/aws-serverless-airline-booking
7https://github.com/aws-solutions/video-on-demand-on-aws
27(a) Airline Booking Application
(b) VOD Application
Figure 5: An overview of the architectures of the testbed applications, highlighting the
interactions and processes facilitated by various AWS services employed by each of these
applications [42, 43].
286.1.1. Airline booking application
This application is comprised of multiple REST API endpoints that fa-
cilitate user interaction. It leverages various AWS services, including four
DynamoDB tables, four S3 buckets, SQS and SNS services for queuing and
notifications, the AppSync API service, and 12 Lambda functions. Notably,
some of these Lambda functions are coordinated using the AWS Step Func-
tion service.
This application encompasses three main types of business processes:
• Data Retrieval: This type of business process involves API requests
that retrieve information from a DynamoDB table and subsequently
deliver the data to the user. These events are characterized by their
brief duration and involve single accesses to data sources within the
system.
• Booking Process: In this process, an API request to book a flight
initiates a sequence of data access operations and Lambda function
invocations that exchange information. These events are orchestrated
by a step function, ensuring the coordination of various steps.
• Time-Based Events: The third type of business process is triggered
by AWS EventBridge, which initiates specific actions at predetermined
time-based intervals.
6.1.2. VOD application
As a core part of its functionality, this application plays a role in decoding
videos into a streaming format and storing them in a public S3 bucket. It
utilizes three S3 buckets, two DynamoDB tables, and 17 Lambda functions.
29In contrast to the airline booking application where only one of the busi-
ness processes is orchestrated by a Step Function, the VOD application em-
ploys four Step Functions, each of which is responsible for a distinct core
business process. The three processes in the main video format conversion
workflow are as follows:
• Ingest: verifies the validity of the uploaded video files.
• Process: converts the video files from their original coding format to a
different format using the AWS Elemental MediaConvert service.
• Publish: generates a link to the file’s location in the cloud and dis-
patchesitviaemailtoapredefinedemailaddressusingtheAWSSimple
Notification Service (SNS).
The fourth process is added to the original application’s code by us and does
not appear in Figure 5. It is dedicated to handling video uploads through
emails and utilizes the AWS Simple Email Service (SES).
Users can interact with the application in two ways: manually uploading
files to the source S3 bucket or sending emails to a predefined mail endpoint.
Once a file is added to the source S3 bucket, the subsequent processes are
automated via EventBridge triggers and Step Functions.
Each application is equipped with its own dedicated DynamoDB table,
which contains configuration information for the simulation process (mainly
the probabilities associated with each execution in order to run anomalous
code).
306.2. Data simulation
In our testbed environment, we strive to generate experimental data that
faithfullyreplicatesthebehaviorofreal-lifeapplications. Tosimulategenuine
user actions, we developed Python scripts that execute functions in various
sequences, mimicking users who follow different paths and perform distinct
operations. Furthermore, wesimulatepotentialerrorsthatcouldariseduring
the executions carried out in these varied pathways.
6.2.1. Airline booking application
Our simulation involves traffic through the airline booking application’s
frontendwebsiteandincorporatesfixedprobabilitiesassociatedwithdifferent
types of booking reservations (i.e., one-way or two-way flights). To elaborate:
• There is an 80% probability of booking two-way tickets, which involves
reserving two tickets with opposite source and target airports. The
remaining 20% is allocated for checking the booking page and ordering
one-way tickets.
• During the booking process, there is a 70% probability of navigating
to the profile page to obtain a response from the “get loyalty” lambda
function.
• The simulated user can visit two different pages: the loyalty page and
the booking page. Each visit triggers a distinct REST API call which,
in turn, activates the APPSync API service in the cloud environment.
• Whenbookingtickets,therearetwooptions: one-wayortwo-waybook-
ings. For one-way bookings, a random airport is selected from a pre-
31defined list as the starting location, and another random airport from
the list is chosen as the target location.
• In the case of two-way bookings, the first ticket’s starting location is
set at a specific airport, while a random airport from the list is selected
as the target. For the second ticket, the roles are reversed, with the
same airports used in the opposite roles.
This simulation process generates various booking scenarios, including
different types of reservations and the associated API interactions.
Completion of the process of booking a flight in the simulator triggers
the step function within the cloud environment, initiating the step function’s
workflow. To ensure that a wide range of activity patterns are seen in the
testbed, this workflow incorporates different error-handling mechanisms that
activate various combinations of Lambda functions. The likelihood of these
paths being executed is determined by the configuration table of the airline
booking application.
To mimic genuine user activity within the application, we insert time
intervalsthatintroducetimegapsbetweenusers’actions, takingintoaccount
the time of day and the specific actions users tend to perform. This approach
produces a distributed activity load that closely resembles the patterns seen
in actual user behavior.
6.2.2. VOD application
In the simulation of the VOD application, we established a staging S3
bucket that functions as a virtual local drive” for users, enabling them to
upload video files to the application’s source bucket. To perform cloud op-
32erations that trigger the application’s workflow, we employ the AWS SDK
for Python, commonly known as Boto3. This facilitates actions such as file
uploads to the S3 buckets. For the mailing process that was added by us,
we configured Amazon SES to receive and store emails originating from our
AmazonRoute53servicedomain. Thissetupensuresthatthemailingflowis
properly initiated. In addition to the direct uploads facilitated by Boto3, the
simulator also employs Python’s email library to send emails to our domain,
adding another layer of functionality to the simulation process.
To simulate realistic timing for file uploads in the VOD application sim-
ulation, we leverage the Trending YouTube Video Statistics dataset from
Kaggle8. This dataset provides information about the upload times of pop-
ular videos in the United States, serving as the basis for simulating activity
in the VOD application. We employ the distribution of video uploads from
this dataset in order to model the activity patterns in the VOD application:
• There is an 80% probability that a standard ”put object” operation
will be initiated by an S3 upload, while there is a 20% chance of a mail
upload, unless the mailing service has already handled 200 emails, in
which case it reaches the defined limit.
• In the case of a regular upload, there is a 90% chance of a successful
upload,whilethereisa10%chancethattheformatnamewillbealtered
to a format that the MediaConvert service cannot process.
• Mail uploads are guaranteed to be successful.
8https://www.kaggle.com/datasets/datasnaek/youtube-new
33This approach ensures that the simulation closely mimics real-world up-
load scenarios, incorporating factors such as the upload type and success
rates.
6.3. Attacks implemented
To demonstrate the feasibility of our proposed method, we implemented
several attack scenarios in the testbed which demonstrate common threats
in the serverless threat landscape. These attacks illustrate the effects that
real attacks can have on a serverless application, including the artifacts they
leave behind in serverless activity logs.
6.3.1. Attack on integrity - permission misuse
In this scenario, we simulate an attack that modifies the serverless func-
tion’s execution flow. Specifically, we simulate the abuse of permissions by
a serverless function that was granted permission to access and operate on
a data source. In this case, the permissions are misused in order to change
the context in which the function operates for the benefit of the attacker.
In the first version of this scenario, the order of the data operations in the
function’s event sequence is different than usual (e.g., instead of updating an
item and then obtaining an item from a table, the function performs a get
item operation and then updates that item). In the second version of the
attack, the function performs a different operation than the one it usually
performs (e.g., updating an entry in a table instead of writing a new entry to
it). The third version involves adding an additional action to the function’s
workflow (e.g., additional access to a DynamoDB table).
346.3.2. Attack on confidentiality - data leakage
Inthisparticularattackscenario, themaliciousactorleveragestheserver-
lessfunctiontoillicitlyexfiltratesensitiveinformationtoapubliclyaccessible
data source. To achieve this, the attacker enhances the function’s custom-
ary workflow by incorporating functionality that directs it to transfer private
data to an external AWS S3 bucket.
6.3.3. Attack on availability - denial-of-wallet
Two versions of this attack scenario are simulated. In the first version,
the function repetitively invokes the same API call as part of its execution,
resulting in multiple accesses to a data source. Consequently, both the data
transported and the function’s runtime experience an increase. The second
version of the attack is designed to leave fewer tracks compared to the first.
In this version, the runtime of some of the functions is increased by just a
few seconds (4-5). This might not raise suspicion if it is a one-time occur-
rence, but if numerous functions execute for an extended duration, they will
consume more resources and ultimately increase the cost to the user.
These attacks are implemented in the main workflow of the applications
examined in this study. For each application, we chose specific functions
and “infected” them with the attack scenarios. During data collection, we
configured 10% of the instances of each “infected” function to run the mali-
cious code and logged the anomalous instances in order to label each of the
instances in the test set as benign or anomalous.
357. Evaluation
In this section, we evaluate our model’s performance. We introduce our
dataset statistics, describe the network architecture and hyperparameters
used in our solution, present the results for the primary model and the ad-
ditional update component, and discuss their implications.
7.1. Dataset
Toevaluatetheperformanceofourcompromisedfunctiondetectionmodel,
weconductedsimulationsoftheactivitiesoftwodistinctapplications, asout-
lined in Section 6.
The execution time of the VOD application simulator is directly derived
from the number of files uploaded and processed. In each of the phases, the
training and testing, we uploaded 3,000 files, which resulted in an approxi-
mate six-hour runtime for each set of simulations. The execution time of the
airline booking application simulator is derived from the number of iterations
the simulator is required to perform. In each of the phases, the training and
testing, we configured the simulator to run for 800 iterations, resulting in an
estimated runtime of around four hours for each set of simulations.
For each function, we established a consistent anomaly rate of 0.1. Then,
each function invocation in the test set was chosen at random to execute
either the anomalous or benign code, in accordance with this predetermined
rate.
Our evaluation focused on the functions with the most prominent roles
in each application, a total of 12 functions — eight from the Airline Booking
application and four from the VOD application were considered to have the
36most prominent roles. In this assessment, we simulated attacks on three
functions in the Airline Booking application and all four functions in the
VOD application.
We divided the training data into training and validation sets using an
80/20 ratio. Table 3 provides details regarding the number of instances
(vector sequences) and anomalies for each dataset of each application. The
amount of attacks simulated in each application is presented in Table 2.
Table 2: The number of attacks simulated in each application
Attack Airline VOD
Data Leakage 52 117
Denial of Wallet - Repeated Operation 141 800
Denial of Wallet - Increased Duration 80 277
Permission Misuse - Change Operation Order 72 265
Permission Misuse - Different Action 139 0
Permission Misuse - Additional Action 0 118
Table 3: The number of instances (vector sequences) and anomalies for each dataset of
each application
Application Train Set Validation Set Test Set Anomalies
Airline 5,927 1,481 4,497 484
VOD 14,568 3,642 16,374 1,577
7.2. Network architecture, hyperparameters, and experiment details
We conducted a grid search to select the optimal hyperparameters for the
autoencoders and the model itself. The selection of parameters was guided
37by identifying the clearest delineation between the reconstruction errors of
anomalous and benign instances, as derived from the outputs of each au-
toencoder. Figure 6 illustrates an optimal scenario in which benign instances
exhibit minimal reconstruction errors, while anomalous instances display sig-
nificantly elevated reconstruction errors. This clear distinction between the
two types of instances results in a perfect separation.
Figure 6: A visualization of the autoencoder’s output: reconstruction errors of a test
set comprised of around 20,000 instances. The blue dots correspond to sequences within
benign function executions, while the red dots denote sequences in anomalous function
executions. The chosen threshold, derived from the validation set, is depicted by the red
line.
First, we experimented with the number of hidden layers and neurons in
each layer, the activation functions within each layer, and the optimization
algorithm for the network. The final network architecture we selected is
38identical for all of the autoencoders, and it consists of seven fully connected
feed-forward hidden layers. The encoder and decoder layers consist of 128,
64, and 32 neurons (from the outer layer to the inner one), and the activation
function for these layers is ReLU. A middle layer containing 64 neurons
replicates the inner layer of the encoder by a factor equal to the number
of events in the sequence. We used the Adam optimizer for the network, and
the loss function is the mean squared error.
We also examined factors such as the number of epochs, the batch size,
the learning rate, the dimensions of the input sequences, and the threshold
used for the classification of instances. The optimal approach was training
three separate autoencoders, each with a distinct sequence size: 3, 5, and 10.
These autoencoders were trained over the course of 15 epochs, with a batch
size of 32 instances, and a learning rate of 0.0001. An instance (sequence) is
classified as anomalous if at least one of the autoencoders classifies it as such.
The method for choosing the threshold for each autoencoder is described in
Section 5.2.
When updating the model, all hyperparameters but the learning rate re-
main unchanged (compared to the hyperparameters used to train the original
model). This includes the original minimum and maximum values for each
feature used for feature normalization. The learning rate used in this phase
is set at 0.0001.
Ourexperimentswereperformedusingacomputerequippedwitha4-core
Intel Core i7-10510U CPU @ 1.80GHz with 16 GB of RAM.
397.3. Results
The threat detection results obtained for each application and attack are
presented in Table 5. Further details regarding the implementation of each
attack can be found in Section 6.3. The overall results obtained for both
applications are presented in Table 4. Table 4 provides a comprehensive
summary of the results for all significant functions within both applications,
including those unaffected by simulated attacks, while Table 5 presents the
results for each attacked function.
Table 4: Detection results for both applications
Application Presicion Recall F1 Score FPR FNR
Airline + VOD 0.967 1 0.983 0.003 0
As evident from the tables, high values were obtained for the precision,
recall, and F1 score, while the false positive rate (FPR) and false negative
rate (FNR) were reasonably low for all types of attacks.
In general, the precision scores achieved for the VOD application were
inferior to those of the airline booking application. This discrepancy can
be attributed to a greater occurrence of false alarms associated with a par-
ticular function within the VOD application. Both the permission misuse
(additional operation) and data leakage attacks were directed at this partic-
ular function. While there were very few cases where benign sequences were
classified as anomalous, we sought to understand what was causing these
misclassifications. Our analysis showed the vast majority of them involved
cold-starting function instances. As such an event was relatively rare in the
training set, the model was not sufficiently experienced with sequences that
40included it. We conclude that most of such cases stem from events in the
functions’ executions that were not seen in the training set. Accordingly, we
conclude that the more diverse the training set is in terms of the event se-
quencesitcontains, themore complete themodelwillbecome, andthebetter
the results. Nevertheless, the model has the ability to highlight valuable log
data for a manual inspection of the security analysts in both applications.
Given the perfect recall and the low false positive rate, we believe that our
model will serve as an invaluable tool for data analysts - instead of going
through all of the available logs, an analyst can focus on those log entries
that are the most likely to be relevant.
It should be emphasized that the proposed method is used to model
serverless functions. In a typical serverless application, each function gener-
ally performs a small atomic role. Therefore, the expected number of exe-
cution flow variations for each is limited, as is the expected number of rare
events.
Still,amodel’sabilitytolearnrarebenignbehaviorsandadapttochanges
is critical in reducing the number of false alerts. To achieve that, our model
can be retrained to accommodate legitimate changes in the code and rare
benign events. Our future work will involve utilizing imbalanced data cor-
rection methods, such as the oversampling of rare benign sequences, in order
to provide the model with an improved training set and enhance its learning
process.
The duration for each phase of the model, which includes training, test-
ing, and retraining the model using our datasets, is presented in Table 6.
This table also presents the average time required for training, testing, and
41retraining the model per individual sample, emphasizing the negligible time
investment needed to apply the model on an extremely large dataset.
7.4. Updated Model Results
As mentioned earlier, our approach facilitates model updates by fine-
tuning the model based on new data. To achieve optimal outcomes during
this updating process, based on empirical findings, we recommend construct-
ing a training set that combines 90% of new data with the remaining 10%
consisting of a random selection from the original training dataset.
Toassesshowwellanupdatedmodelperforms, wefirsttrainedandtested
it using all the functions examined in the original experiment, except for the
VOD-dynamo function, which was randomly excluded. The results closely
resembled those of the original model.
Following that, we constructed a new training dataset to update the
model with. The data from the ’new’ VOD-dynamo function accounted for
90% of the new training dataset, while the remaining 10% was sourced from
the initial training dataset, as detailed in Table 3.
The results of this experiment are presented in Table 7. In this case, the
resultsremainedconsistentwiththeresultsobtainedwiththeprimarymodel.
This demonstrates the ability of the model to adapt to new information
without compromising its performance.
7.5. Discussion
Some of the key strengths of our model are rooted in its generality (e.g.,
there is no need for a separate model per function or even per application)
and ability to be fine-tuned based on new information. In addition, our
42evaluation results suggest that the model is capable of scaling well (the per-
formance remained similar despite expanding the model to more functions
and adding another application). Initially, our approach involved creating
separate models for each function and every application. Each function was
associated with its dedicated autoencoder, trained exclusively on the event
sequences specific to that function’s executions. Later, we expanded our ap-
proach by consolidating multiple functions under a single autoencoder. We
started with functions from the same application and eventually extended
this consolidation to encompass all event sequences, regardless of their func-
tion or application origins.
In order to maintain the quality of results achieved with individual au-
toencoders, we introduced two additional features to each event vector: the
function name and the associated application name. However, our experi-
mentation revealed that including the function name was unnecessary, as we
were able to achieve nearly identical results by relying solely on the applica-
tion name. This enables the use of a single model, simplifying the application
of our model while preserving its ability to effectively differentiate between
benign and anomalous instances.
8. Conclusion
In this paper, we present a deep-learning threat detection model specifi-
cally designed for the identification of compromised serverless functions. As
the serverless application’s activity logs are analyzed, our model scrutinizes
them for any potential forensic evidence that might have been left behind
by an attack that exploited serverless functions. This is accomplished by
43using LSTM autoencoders to model the normal behavioral patterns of each
serverless function. Consequently, our proposed method is threat-agnostic
and designed to detect different types of threats, both known and unknown,
across various threat categories.
Ourmethodusesnativehyper-loggingcapabilitiesprovidedbytheserver-
less platform, and therefore it is self-contained and does not require any
external information obtained through infrastructure modifications or third-
party collaboration. To evaluate our method’s effectiveness, we created a
serverless testbed consisting of two different applications that cover different
typical serverless development paradigms. We implemented several attack
scenarios for each application in the testbed, demonstrating typical server-
less threats against confidentiality, integrity, and availability.
Our evaluation demonstrates that it is possible to develop a threat detec-
tionmodelbasedsolelyontheinformationobtainedfromthecloudprovider’s
native monitoring tools that is capable of successfully detecting various at-
tacks against serverless applications while maintaining a very low false alarm
rate. Furthermore, our approach has demonstrated its ability to be deployed
across various applications and functions. It exhibits adaptability through
fine-tuning with new data, scalability, and utility for both online and offline
detection scenarios.
References
[1] T. Lynn, P. Rosati, A. Lejeune, V. Emeakaroha, A preliminary re-
view of enterprise serverless cloud computing (function-as-a-service)
platforms, in: 2017 IEEE International Conference on Cloud Com-
44puting Technology and Science (CloudCom), 2017, pp. 162–169. doi:
10.1109/CloudCom.2017.15.
[2] J. Nupponen, D. Taibi, Serverless: What it is, what to do and what not
to do, in: 2020 IEEE International Conference on Software Architecture
Companion (ICSA-C), 2020, pp. 49–50. doi:10.1109/ICSA-C50368.
2020.00016.
[3] H. B. Hassan, S. A. Barakat, Q. I. Sarhan, Survey on serverless com-
puting, Journal of Cloud Computing 10 (1) (2021) 1–29.
[4] Aws lambda documentation, https://docs.aws.amazon.com/lambda/
?icmpid=docs_homepage_featuredsvcs(2023(accessedSeptember28,
2023)).
[5] Azure functions, https://azure.microsoft.com/en-us/products/
functions (2023 (accessed September 28, 2023)).
[6] Cloud functions, https://cloud.google.com/functions/docs (2023
(accessed September 28, 2023)).
[7] Owasp serverless top 10, https://owasp.org/
www-project-serverless-top-10/ (2023 (accessed September
28, 2023)).
[8] D. Zissis, D. Lekkas, Addressing cloud computing security issues, Future
Generation computer systems 28 (3) (2012) 583–592.
[9] X. Li, X. Leng, Y. Chen, Securing serverless computing: Challenges,
solutions, and opportunities, IEEE Network.
45[10] A. S. Ibrahim, J. Hamlyn-Harris, J. Grundy, Emerging security chal-
lenges of cloud virtual infrastructure, arXiv, 2016. doi:10.48550/
ARXIV.1612.09059.
URL https://arxiv.org/abs/1612.09059
[11] V. S. R. Pusuluri, Taxonomy of security and privacy issues in serverless
computing.
[12] E. Marin, D. Perino, R. Di Pietro, Serverless computing: a security
perspective, Journal of Cloud Computing 11 (1) (2022) 1–12.
[13] M. Obetz, S. Patterson, A. Milanova, Static call graph construction in
{AWS} lambda serverless applications, in: 11th USENIX Workshop on
Hot Topics in Cloud Computing (HotCloud 19), 2019.
[14] K. Alpernas, C. Flanagan, S. Fouladi, L. Ryzhyk, M. Sagiv, T. Schmitz,
K. Winstein, Secure serverless computing using dynamic information
flow control, arXiv preprint arXiv:1802.08984.
[15] P. Datta, P. Kumar, T. Morris, M. Grace, A. Rahmati, A. Bates, Valve:
Securing function workflows on serverless computing platforms, in: Pro-
ceedings of The Web Conference 2020, 2020, pp. 939–950.
[16] A.Sankaran,P.Datta,A.Bates,Workflowintegrationalleviatesidentity
and access management in serverless computing, in: Annual Computer
Security Applications Conference, 2020, pp. 496–509.
[17] P. Datta, I. Polinsky, M. A. Inam, A. Bates, W. Enck, {ALASTOR}:
Reconstructingtheprovenanceofserverlessintrusions, in: 31stUSENIX
Security Symposium (USENIX Security 22), 2022, pp. 2443–2460.
46[18] D. S. Jegan, L. Wang, S. Bhagat, M. Swift, Guarding serverless appli-
cations with kalium.
[19] Skyscanner, Lambdaguard (2020).
URL https://github.com/Skyscanner/LambdaGuard
[20] D. S. Jegan, L. Wang, S. Bhagat, T. Ristenpart, M. Swift, Guarding
serverlessapplicationswithseclambda,arXivpreprintarXiv:2011.05322.
[21] R.Chawla, Informationflowcontrolforserverlesssystems, International
Journal of Advanced Computer Science and Applications 12 (9).
[22] J. Wen, Z. Chen, X. Jin, X. Liu, Rise of the planet of serverless comput-
ing: A systematic review, ACM Transactions on Software Engineering
and Methodology.
[23] P. Gill, W. Dietl, M. V. Tripunitara, Least-privilege calls to amazon web
services, IEEE Transactions on Dependable and Secure Computing.
[24] N. Eddy, Cloud misconfig exposes 3tb of sensitive airport data in
amazon s3 bucket: ’lives at stake’ (Jul 2022).
URL https://www.darkreading.com/application-security/
cloud-misconfig-exposes-3tb-sensitive-airport-data-amazon-s3-bucket
[25] A. Seals, T. Seals, Microsoft leaves 250m customer service records open
to the web (Jan 2020).
URLhttps://threatpost.com/microsoft-250m-customer-service-records-open/
152086/
47[26] D. Kelly, F. G. Glavin, E. Barrett, Denial of wallet—defining a loom-
ing threat to serverless computing, Journal of Information Security and
Applications 60 (2021) 102843.
[27] P. Duessel, S. Luo, U. Flegel, S. Dietrich, M. Meier, Tracing privilege
misuse through behavioral anomaly detection in geometric spaces, in:
202013thInternationalConferenceonSystematicApproachestoDigital
Forensic Engineering (SADFE), IEEE, 2020, pp. 22–31.
[28] Z. Liu, T. Qin, X. Guan, H. Jiang, C. Wang, An integrated method
for anomaly detection from massive system logs, IEEE Access 6 (2018)
30602–30611.
[29] M. Du, F. Li, G. Zheng, V. Srikumar, Deeplog: Anomaly detection and
diagnosis from system logs through deep learning, in: Proceedings of
the 2017 ACM SIGSAC Conference on Computer and Communications
Security, 2017, pp. 1285–1298.
[30] Z. Zhao, C. Xu, B. Li, A lstm-based anomaly detection model for log
analysis, Journal of Signal Processing Systems 93 (7) (2021) 745–751.
[31] X. Zhang, Y. Xu, Lin, et al., Robust log-based anomaly detection on
unstable log data, in: Proceedings of the 2019 27th ACM Joint Meeting
on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, 2019, pp. 807–817.
[32] C. Zhou, R. C. Paffenroth, Anomaly detection with robust deep au-
toencoders, in: Proceedings of the 23rd ACM SIGKDD international
conference on knowledge discovery and data mining, 2017, pp. 665–674.
48[33] H. Guo, S. Yuan, X. Wu, Logbert: Log anomaly detection via bert,
in: 2021 International Joint Conference on Neural Networks (IJCNN),
IEEE, 2021, pp. 1–8.
[34] F. Liu, Y. Wen, D. Zhang, X. Jiang, X. Xing, D. Meng, Log2vec: A het-
erogeneous graph embedding based approach for detecting cyber threats
withinenterprise, in: Proceedingsofthe2019ACMSIGSACConference
on Computer and Communications Security, 2019, pp. 1777–1794.
[35] A. R. Tuor, R. Baerwolf, N. Knowles, B. Hutchinson, N. Nichols,
R. Jasper, Recurrent neural network language models for open vocabu-
lary event-level cyber anomaly detection, in: Workshops at the thirty-
second AAAI conference on artificial intelligence, 2018.
[36] R.-H. Hwang, M.-C. Peng, C.-W. Huang, P.-C. Lin, V.-L. Nguyen, An
unsupervised deep learning model for early network traffic anomaly de-
tection, IEEE Access 8 (2020) 30387–30399.
[37] B. Sharma, P. Pokharel, B. Joshi, User behavior analytics for anomaly
detection using lstm autoencoder-insider threat detection, in: Proceed-
ings of the 11th International Conference on Advances in Information
Technology, 2020, pp. 1–9.
[38] E. Habler, A. Shabtai, Using lstm encoder-decoder algorithm for detect-
ing anomalous ads-b messages, Computers & Security 78 (2018) 155–
173.
[39] M. Landauer, S. Onder, F. Skopik, M. Wurzenberger, Deep learning
49for anomaly detection in log data: A survey, Machine Learning with
Applications 12 (2023) 100470.
[40] G. Pang, C. Shen, L. Cao, A. V. D. Hengel, Deep learning for anomaly
detection: A review, ACM Computing Surveys (CSUR) 54 (2) (2021)
1–38.
[41] A. Sharma, How to master the popular dbscan clustering algo-
rithm for machine learning, https://www.analyticsvidhya.com/
blog/2020/09/how-dbscan-clustering-works/ (2023 (accessed Oc-
tober 1, 2023)).
[42] Aws serverless airline booking, https://github.com/aws-samples/
aws-serverless-airline-booking (2023 (accessed September 28,
2023)).
[43] Video on demand on aws, https://github.com/aws-solutions/
video-on-demand-on-aws (2023 (accessed September 28, 2023)).
50Table 5: Detection results for each simulated attack & application
Application Attack Precision Recall F1 Score FPR FNR
PermissionMisuse:
0.973 1 0.986 0.003 0
DifferentOrderof Operations
PermissionMisuse:
Airline 0.993 1 0.996 0.001 0
DifferentOperation
DataLeakage 0.963 1 0.981 0.003 0
Denial-of-Wallet:
1 1 1 0 0
RepeatedOperation
Denial-of-Wallet:
0.976 1 0.988 0.002 0
IncreasedFunctionDuration
PermissionMisuse:
0.960 1 0.980 0.005 0
DifferentOrderof Operations
PermissionMisuse:
VOD 0.893 1 0.944 0.006 0
AdditionalOperation
DataLeakage 0.893 1 0.944 0.006 0
Denial-of-Wallet:
0.977 1 0.988 0.003 0
RepeatedOperation
Denial-of-Wallet:
0.969 1 0.984 0.004 0
IncreasedFunctionDuration
51Table 6: The number of instances for each model phase and the corresponding execution
times
# of Instances Time (sec) Time/Sample (sec)
Training 24,189 994.959 0.041
Testing 23,147 132.743 0.006
Retraining 8,243 325.731 0.039
Table 7: Detection results for the initial training and subsequent model update
Application Functions Precision Recall F1 Score FPR FNR
All functions
Airline 0.959 1 0.979 0.004 0
but one
+ VOD
All functions 0.967 1 0.983 0.003 0
52