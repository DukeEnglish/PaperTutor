Backward explanations via redefinition of predicates
LéoSaulières a,*,MartinC.Cooper a andFlorenceDupindeSaint-Cyr b
aIRIT,UniversityofToulouseIII,CNRS,Toulouse,France
bLab-STICC_COMMEDIA,CNRS,Brest,France.
Abstract. HistoryeXplanationbasedonPredicates(HXP),studies historyofagentinteractionswiththeenvironmentthroughtheprism
thebehaviorofaReinforcementLearning(RL)agentinasequence ofacertainpredicate,ahistorybeingasequenceofpairs(state,ac-
ofagent’sinteractionswiththeenvironment(ahistory),throughthe tion).Apredicatedisanybooleanfunctionofstateswhichistruein
prismofanarbitrarypredicate[21].Tothisend,anactionimportance thefinalstateofthehistory.ThisXRLmethodanswersthequestion:
scoreiscomputedforeachactioninthehistory.Theexplanationcon- “Whichactionswereimportanttoensurethatdwasachieved,given
sistsindisplayingthemostimportantactionstotheuser.Asthecal- theagent’spolicyπ?".Thispaperfollowsthisparadigmofexplana-
culationofanaction’simportanceis#W[1]-hard,itisnecessaryfor tionofahistorywithrespecttoapredicate,byproposinganewway
longhistoriestoapproximatethescores,attheexpenseoftheirqual- ofdefiningtheimportantactionsofahistory,calledBackward-HXP
ity.WethereforeproposeanewHXPmethod,calledBackward-HXP, (B-HXP).Inparticular,B-HXPwasinvestigatedbecauseofthelim-
toprovideexplanationsforthesehistorieswithouthavingtoapprox- itsof(forward)HXPinexplaininglonghistoriesduetothe#W[1]-
imatescores.ExperimentsshowtheabilityofB-HXPtosummarise hardnessofHXP[21].
longhistories. The paper is structured as follows. The theoretical principle of
HXPisoutlinedinSection2,beforedefiningB-HXPinSection3.
Section4presentstheexperimentalresultscarriedouton3problems.
1 Introduction
Section5presentsrelatedworksandSection6concludes.
Nowadays, Artificial Intelligence (AI) models are used in a wide
rangeoftasksindifferentfields,suchasmedicine,agricultureand
2 HistoryeXplanationviaPredicates(HXP) education [12, 8, 3]. Most of these models cannot be explained or
interpreted without specific tools, mainly due to the use of neural
AnRLproblemismodeledusingaMarkovDecisionProcess[24],
networkswhichareeffectivelyblack-boxfunctions.Numerousinsti-
whichisatuple⟨S,A,R,p⟩.SrepresentsthestatespaceandAthe
tutions[25,9]andresearchers[6,15]haveemphasizedtheimpor-
action space. A(s) denotes the set of available actions that can be
tanceofprovidingcomprehensiblemodelstoendusers.Thisiswhy
performedfroms.R : S ×A → Randp : S ×A → Pr(S)are
theeXplainableAI(XAI)researchfield,whichconsistsinproviding
respectivelytherewardfunctionandthetransitionfunctionoftheen- methods to explain AI behavior, is flourishing. In this context, we
vironment.p(s′|s,a)representstheprobabilityofreachingstates′,
proposeamethodforexplainingAImodelsthathavelearnedusing
havingperformedactionafromstates.π : S → Adenotesade-
ReinforcementLearning(RL).
terministicpolicythatmapsanactionatoeachstates;thus,π(s)is
InRL,theagentlearnsbytrialanderrortoperformataskinan
theactionperformedbytheagentinstates.DuetotheMarkovian
environment.Ateachtimestep,theagentchoosesanactionfroma
natureoftheprocess,transitionsatdifferentinstantsareindependent
state,arrivesinanewstateandreceivesareward.Thedynamicsof
andhencetheprobabilitiesgivenbythetransitionfunctionpcanbe
theenvironmentaredefinedbythenon-deterministictransitionfunc-
multipliedwhencalculatingtheprobabilityofascenario(sequence
tionandtherewardfunction.Theagentlearnsapolicyπtomaximize
ofstates).Inthefollowing,weusethefunctionnext,basedonthe
itsreward;thispolicyassignsanactiontoeachstate(definingade-
policyπ andthetransitionfunctiondescribedbyp,tocomputethe
terministicpolicy).OureXplainableReinforcementLearning(XRL)
nextpossiblestates(associatedwiththeirprobabilities)givenaset
methodisrestrictedtotheexplanationofdeterministicpolicies.
S of(state,probability)pairs:next (S) = {(s′,pr×p(s′|s,a))
Various works focus on explaining RL agents using a notion of π,p
: (s,pr) ∈ S, a = π(s) and p(s′|s,a) ̸= 0}. In order to com-
importance.Toprovideavisualsummaryoftheagent’spolicy,Amir
pute the set of final states reachable at horizon k from a set of
and Amir [2] select a set of interactions of the agent with the en-
states S, using the agent’s policy π and the transition function p,
vironment (sequences) using “state importance” [4]. From a set of
thefunctionsucck isdefinedrecursivelybysucc0 (S) = S and
sequences, Sequeira et Gervasio propose to learn a set of informa- π,p π,p
succn+1(S)=next (succn (S)).
tion,todeduceinterestingelementstoshowtheuserintheformofa π,p π,p π,p
HXPs [21] provide to the user important actions for the respect
visualsummary[23].Usingaself-explainablemodel,Guoetal.de-
ofapredicated,givenanagent’spolicyπ,bycomputinganimpor-
terminethecriticaltime-stepsofasequenceforobtainingtheagent’s
tancescoreforeachactioninthehistory.Thelanguageusedforthe
finalreward[11].
predicateisbasedonthefeaturesthatcharacterizeastate.Eachfea-
To explain an RL agent, explanation must capture concepts of
turef hasarangeofvaluesdefinedbyadomainD ,thesetofall
RL[16].Tothisend,theHXPmethod[21],consistsofstudyinga i i
featuresisdenotedF ={f ,...,f }.Thefeaturespaceistherefore
1 n
∗Correspondingauthoremail:leo.saulieres@irit.fr. F=D ×...×D .ThestatespaceSisasubsetofF.Apredicateis
1 n
4202
guA
5
]IA.sc[
1v60620.8042:viXraFigure1. Anexampleofhistorywith13statess0,...,s12fortheFLproblemonwhichaB-HXPiscomputedforthewinpredicate.Theagentissymbolized
byareddot,thedarkbluecellsareholesandthedestinationcellismarkedbyastar.Actionsidentifiedasimportantarehighlightedbyagreenframe.
givenbyapropositionalformulawithliteralsoftheforml where When an important action is found, we look at its associated state
i,j
l meansthatthefeaturef takesthevaluejindomainD .Astate s to define the new predicate to be studied. The process then iter-
i,j i i
s ∈ S isaninterpretationinthelanguagebasedonthevocabulary atestreatingsasthefinalstatewiththisnewpredicate.Indeed,by
(l ) suchthats(l )=Trueifandonlyifthefeature observingonlyasubsetoftheactionsinthehistory(nearpast),the
i,j i∈[1,n],j∈Di i,j
iasthevaluej inthestates.Itfollowsthatthepredicatedcanbe horizonforcalculatingimportancescoresisrelativelysmall.Inthis
evaluatedinlineartimeforagivenstate.Theimportancescorerepre- sense,importancescorescanbecalculatedexhaustively.Thepredi-
sentsthebenefitofperforminganactionafromsratherthananother cateisthenmodifiedsothatactionscanbeevaluatedwithrespectto
actiona′ ∈A(s)\{a},wherethisbenefitistheprobabilityofreach- apredicatethattheycanachievewithinashorterhorizon.Thefol-
ingastateatahorizonofkthatsatisfiesd.Toevaluateanactionwe lowingexamplewillbeusedthroughoutthissectiontoillustratethe
firstrequirethenotionofutilityofasetof(state,probability)pairs. method.
Definition1(utility). Givenapredicated,theutilityu d ofasetof Example 1. Consider the end of Bob’s day. The history of Bob’s
(state,probability)pairsSis: actionsis:[work,shop,watchTV,nap,eat,watertheplants,read].
(cid:88) Bob’sstateisrepresentedby5binaryfeatures:hungry,happy,tired,
u (S)= pr
d fridge,fuel.Fridgeandfuelmeansrespectivelythatthefridgeisfull
(s,pr)∈S,s|=d and that the car’s fuel level is full. Bob’s final state is: (¬hungry,
Finally,theimportanceofanactionafromastatesisdefinedby: happy, tired, ¬fridge, ¬fuel) (for the sake of conciseness, Bob’s
states are represented by a boolean 5-tuple. Thus, Bob’s last state
Definition2(importance). Givenapredicated,apolicyπ,atran-
is:(0,1,1,0,0)).Theenvironmentisdeterministicandthepredicate
sitionfunctionp,theimportancescoreofafromsathorizonkis:
understudyis“Bobisnothungry".Wearelookingforthemostim-
impk d,π,p(s,a)=u d(succk π,p(S (s,a)))− avg u d(succk π,p(S (s,a′)))
portantactionsforBobnottobehungry.Startingfromthefinalstate,
a′∈A(s)\{a}
themostimportantactioninthenearpastis‘eat’.Weareinterested
whereavgistheaverageandS isthesupportofp(.|s,a).1
(s,a) in its associated state, i.e. the state in the history before doing the
The importance score lies in the range [−1,1], where a positive action‘eat’,whichisassumedtobe(1,0,0,1,0).Thenewpredicate
deducedfromthisstateis“Bobishungryandhasafullfridge".In
(negative)scoredenotesanimportant(resp.notimportant)actionin
comparisonwithotherpossibleactions.Itscomputationis#W[1]- thenearpastof(1,0,0,1,0),the‘shop’actionisthemostimpor-
tantone(amongwork,shop,watchTVandnap)forrespectingthis
hard[21],soitisnecessarytoapproximateit,inparticularbygener-
atingonlypartofthelength-kscenarioswiththesuccfunction. newpredicate.Tosumup,wecansaythatthereasonthatBobisnot
hungryinthefinalstateisthathewentshopping(tofillhisfridge)
Tohandlelonghistoriesonproblemswherethenumberofpossi-
bletransitionsislarge,i.e.largehorizonkandlargebranchingfactor andthenate.
(denotedbhereafter),itisnecessarytouseapproximatemethodsto
BeforedescribingtheB-HXPmethodindetail,weintroducesome
provideexplanationsinreasonabletime,attheexpenseofonlyap-
notations. H = (s ,a ,s ,...,a ,s ) denotes a length-k his-
proximatingtheimportancescores.Inthenextsection,wepropose 0 0 1 k−1 k
tory, with H = (s ,a ) denoting the state and action performed
a new way of explaining histories in a step-by-step backward ap- i i i
attimei,andfori < j,H denotesthesub-sequenceH =
proach,whichallowsustoprovideexplanationsinreasonabletime (i,j) (i,j)
(s ,a ,...,s ).TodefinethenearpastofastateinH,itisnecessary
forlonghistories,withouthavingtoapproximatethecalculationof i i j
to introduce the maximum length of sub-sequences: l. This length
scores.Aswewillsee,thisleadstoothercomputationaldifficulties.
must be sufficiently short to allow importance scores to be calcu-
Theresultisthusanovelmethodfortheexplanationofhistorieswith
latedinareasonabletime.ThevalueofldependsontheRLproblem
differentprosandconscomparedtoforward-basedhistoryexplana-
beingaddressed,andspecificallyonthemaximalnumberofpossible
tion.
transitionsfromanyobservablestate-actionpair,namelyb.Itfollows
thatthelowerbis,thehigherlcanbechosentobe.
3 BackwardHXP(B-HXP)
Toprovideexplanationsforlonghistories,weneedawayofdefin-
ingnewintermediatepredicates(suchasBobishungryandthefridge
TheideaofB-HXPistoiterativelylookforthemostimportantaction
isfullinExample1).ForthisweuseProbabilisticAbductiveeXpla-
inthenearpastofthestatethatrespectsthepredicateunderstudy.
nations, shortened to PAXp [13]. The aim of this formal explana-
1i.e.S (s,a)={(s′,p(s′|s,a))|p(s′|s,a)̸=0} tion method is to explain the prediction of a class c by a classifierκbyprovidinganimportantsetoffeaturesamongF.Settingthese Example 1 (Cont). For this history, δ is set to 1 and l is 4. The
featuresguarantees(withaprobabilityatleastδ)thattheclassifier firstsub-sequencestudiedis:[nap,eat,watertheplants,read].The
outputsclassc,whateverthevalueoftheotherfeatures.Aclassifier mostimportantactionrelativetotheachievementof“Bobisnothun-
mapsthefeaturespaceintothesetofclasses:κ:F→K.Werepre- gry"is‘eat’,withascoreof,say,0.5anditsassociatedstate,say,
sentbyx = (x ,...,x )anarbitrarypointofthefeaturespaceand (1,0,0,1,0).WeextractaPAXp,whichincludesthefeaturesfridge
1 n
v = (v ,...,v ) a specific point, where each v has a fixed value andhungrysetto1.Thismeansthat,whateverthevaluesoftheother
1 n i
ofdomainD .[13]definesaweakPAXpasasubsetoffeaturesfor features,astatewithfridgeandhungrysetto1has(with100%prob-
i
which the probability of predicting the class c = κ(v) is above a ability)autilitygreaterthanorequalto0.5.Indeed,thisistheonly
giventhresholdδwhenthesefeaturesarefixedtothevaluesinv.A PAXp,soPAXPredis(fridge=1∧hungry=1).Now,westudythesub-
PAXpissimplyasubset-minimalweakPAXp. sequence[work,shop,watchTV,nap],inwhichthemostimportant
actiontoachievethenewintermediatepredicateis‘shop’.
Definition3(PAXp[13]). Givenathresholdδ ∈ [0,1],aspecific
pointv ∈ Fandtheclassc ∈ Ksuchthatκ(v) = c,X ⊆ F isa InthebackwardanalysisofH,thechangeofpredicateallowsusto
weakPAXpif: lookatashort-termobjectivetobereached,thuskeepingthecalcula-
tionofHXPreasonable.Ourmethodisexplainedinpseudo-codein
Prop(κ(x)=c|x =v )≥δ
X X Algorithm1.Thisalgorithmallowsustogobackwardsthroughthe
where x and v are the projection of x and v onto features X history H, successively determining in each sub-sequence studied,
X X
respectively and Prop(κ(x) = c | x = v ) is the proportion theimportantactionanditsassociatedstatepredicate.Theargmax
X X
of the states x ∈ F satisfying x
X
= v X, that the classifier maps functionisusedtofind,inagivensub-sequenceH (i,j),themostim-
toc,inotherwords|{x ∈ F | x =v andκ(x)=c}|/|{x ∈ F | portantactiona,itsassociatedstates,anditsindexinH.Thelatter
X X
x =v }|. isusedtodeterminethenextsub-sequencetoconsider.ThePAXpred
X X
ThesetofallweakPAXp’sforκ(v) = cwrtthethresholdδ is function is used to generate the new predicate to study in the next
denotedWeakPAXp(κ,v,c,δ,F). sub-sequence,basedonDefinition5.Theprocessstopswhenallac-
X ⊆ F is a PAXp if it is a subset-minimal weak PAXp. The tionshavebeenstudiedatleastonce,orwhentheutilityofthemost
set of all PAXp’s for κ(v) = c wrt the threshold δ is denoted importantactioninthecurrentsub-sequenceis0.Finally,thealgo-
PAXp(κ,v,c,δ,F). rithmreturnsalistofimportantactionsandthedifferentpredicates
found.
TheideaistousePAXp’storedefinethepredicatetobestudiedfor
thenextsub-sequenceasweprogressbackwards.Inordertofitinto Algorithm1B-HXPalgorithm
thePAXpframeworkwedefinetheclassifierκ asabinary
s,π,p,d,k Input:historyH,maximalsub-sequencelengthl,
classifier based on the utility of the state s. We note uk (s) =
d,π,p agent’spolicyπ,predicated,transitionfunctionp,
u d(succk π,p({(s,1)})),theutilityof swrtdgivenanhorizonk,a probabilitythresholdδ,statespaceS
policyπ andatransitionfunctionp.Theclassκ s,π,p,d,k(x)ofany Output:importantactionsA,predicatesD
statexistheresultofacomparisonbetweentheutilityofsandthe
A←[];D←[];u←1
utilityofxfortherespectofd.
i ←len(H);i ←max(0,i −l)
max min max
Definition4(B-HXPclassifier). Givenastates,apolicyπ,atransi- whilei min ̸=0andu̸=0do
i,s,a←argmax impl (s,a)
tionfunctionp,apredicatedandahorizonk.TheB-HXPclassifier, i∈[imin,imax] d,π,p
(s,a)=Hi
denotedκ s,π,p,d,k,isafunctionsuchthat:forallx∈S, u←ul d,π,p(s)
(cid:26) True ifuk (x)≥uk (s) d←PAXpred κs,π,p,d,l(s,δ)
κ s,π,p,d,k(x)=
False
othed r,π w, ip
se
d,π,p A.append(a);D.append(d)
i ←i;i ←max(0,i −l)
max min max
This classifier is specific to B-HXP. The utility threshold value endwhile
returnA,D
depends on the state s which is the state associated with the most
importantactioninthesub-sequencestudied.Itisusedtogeneratea
predicated′whichreflectsasetofstatesatleastasusefulass(with
WithB-HXPs,itisinterestingtonotethatthenumberofactions
aprobabilityofatleastδ)fortherespectofd.Thepredicated′ can to be presented to the user is not fixed. In the worst-case scenario,
thenbeseenasasub-goalfortheagentinordertosatisfyd. ausercouldendupwithanexplanationthatreferstoallactionsas
ToassesswhetherasubsetX ⊆ F isaPAXp,itisnecessaryto important.Thiswouldhappenifitwasalwaysthelastactionineach
calculatetheutilityofeachstatehavingthissubsetoffeatures,which subsequence which is the most important for achieving the current
involves using the agent’s policy π and the environment transition predicate. However, this problem was not observed in our experi-
functionp.AweakPAXpisthenasufficientsubsetofstatefeatures ments.
whichensuresthatastateutilityisgreaterthanorequaltotheutility B-HXP provides the user with an explanation even for long his-
ofswithprobabilityatleastδ.Thenewpredicateisdefinedasthe tories.OurmotivationbehindB-HXPistoreducethecomplexityof
disjunctionofeverypossiblePAXpfroms. calculating important actions in comparison with forward HXP. In
theremainderofthissection,wejustifythechoicesmadeindefining
Definition5. Givenastates = (s ,...,s ) ∈ S,aB-HXPclas-
1 n
B-HXP by analysing in detail the theoretical complexity of certain
sifier κ on S, the predicate PAXpred associated with s for a given
subproblemsencounteredbyHXPandB-HXP.
thresholdδis:
 
Proposition1. Givenapolicyπ,atransitionfunctionpandpredi-
(cid:95) (cid:94)
PAXpred κ(s,δ)=  f i =s i cated,theimportancescorecomputationofanactionaathorizonk
X∈PAXp(κ,s,True,δ,S) fi∈X fromanystatesfortherespectofd,impk d,π,p(s,a),is#P-hard.Figure2. B-HXPforthewinpredicateintheC4problem.Above:aninputhistoryof13statess0,...,s12and12moves(whereamoveisthechoiceofa
columnbytheagent(yellow)towhichtheenvironment(red)responds).Below:thepredicatesfoundbyB-HXPcorrespondingtothefourimportantmovesit
finds,eachhighlightedbyagreenframeinthehistory.
Proof. Thiscomplexityisadirectconsequenceoftheresultin[21]: Moreover, any state with at least (n-1)/2 assignments of 1 among
giventhelengthofthesearchhorizonkasaparameter,calculating thefirstn−1features,allowsustoattainthegoalinonestepbyas-
theimportanceofanactionis#W[1]-hard. signingntothelastfeaturef .Hence,thePAXp’softhispredicate
n
dfromsandforl =1,δ =1arepreciselythesubsetsof(n−1)/2
To avoid this computational complexity, the search horizon l is literalsoftheformf =1(1≤i≤n−1).Thereare(cid:0) n−1 (cid:1) such
chosentobeasmallconstantintheB-HXPcalculationofimportance i (n−1)/2
PAXp’s,sothecorrespondingpredicatePAXpred(forδ = 1)isof
scores.Usingbtodenotethemaximumnumberofsuccessorstates
exponentialsize.
fromanygivenstate(i.e.b = max |{s′ ∈ S : p(s|s,π(s)) >
s∈S
0}|),thereareamaximumofbl scenariosgenerated,andhencewe To exhaustively determine an intermediate predicate PAXpred,
havethefollowinglemma. therefore, exponential space in the size of the state s is required.
One approximation to PAXpred is to calculate only one AXp (i.e.
Lemma1. Givenapolicyπandatransitionfunctionp,weassume
aPAXpwithδ = 1).Thisreducestheproblemtoamoreamenable
thatb,themaximumnumberofsuccessorstatesisapolynomialfunc- co-NPproblem[5]whereonlyacounterexamplestates′ isneeded
tionoftheinstancesize(i.e.thenumberofbitsnecessarytospecify
to show that the set of features X ⊆ F is not an AXp. Unfortu-
the history together with π, p and the predicate d). For a constant
nately,thisapproximationyieldspredicatesthatareoftentoospecific
searchhorizonl,thecomputationoftheimportancescoreofanyac-
because of δ = 1. Instead, in order to provide sparser intermedi-
tionafromanystatesfortherespectofd(impl (s,a))andthe
d,π,p atepredicates,theconsideredapproximationconsistsincomputing
utilityofthestatesareintimewhichispolynomialinthesizeofthe
one PAXp, or more precisely one locally-minimal PAXp. Locally-
instance.
minimal PAXp’s is a particular class of weak PAXp which are not
necessarilysubset-minimal.Formally,asetoffeaturesX ⊆ F isa
However, in comparison with forward HXP, it is necessary to
locally-minimalPAXpifX ∈ WeakPAXp(κ,v,c,δ,F)andforall
compute intermediate predicates, in particular with PAXpred (Def-
j ∈X,X\{j}̸∈WeakPAXp(κ,v,c,δ,F).
inition 5). It is interesting to note that the B-HXP classifier (Defi-
The findLmPAXp algorithm [13] is used to calculate a locally-
nition 4) κ used in PAXpred can be evaluated in polynomial time
minimalPAXp.Althoughtheapproximationconsistsofcalculating
because it is based on the calculation of the utility of a state (the
justoneLmPAXp,itremainsahardcountingproblem.Wefirstprove
main component in the importance score computation). Unfortu-
hardnessbeforeexplainingwhythisisneverthelessanimprovement
nately, from a state s, the number of PAXp’s according to κ, can
overthehardnessofforwardHXP.
beexponentialinthesizeofs.
Lemma 3. Given a state s, the computation of a locally-minimal
Lemma 2. Given a state s, in the worst case, PAXpred returns a
PAXp is in FP#P (i.e. in polynomial time using a #P-oracle) and
predicateofsizewhichmaybeexponentialinthesizeofs.
determiningwhetheragivensubsetoffeaturesisalocally-minimal
Tosupportthisassertion,considerthefollowingexample. PAXpis#P-hard.
Example 2. A state consists of n features f 1,...,f n, initially all Proof. We first show the inclusion in FP#P. From a specific state
set to 0. An agent’s ith action consists in assigning a value to f i s,thesearchforalocally-minimalPAXpX ⊆ F beginsbyinitial-
from its domain D i, where D i = {0,1} (i = 1,...,n−1) and ising X to F (the trivially-correct explanation consisting of all the
D n = {0,1,n}. The transition function is deterministic and the features).Then,thefollowingtestiscarriedoutforafeaturef i ∈X:
agent obtains a reward only by reaching any state sgoal such that iff isremovedfromX,doesX remainaWeakPAXp?Ifso,f isre-
i i
(cid:80)n i=1f i ≥ n+ n− 21.Letthepredicatedbegoal,i.e.apredicate moved,otherwiseretained.Thistestisperformedforeachfeatureof
checkingwhethertheagentreachesastatesgoal.Considerthestate X.DeterminingwhetherasubsetX ⊆FisaWeakPAXpamountsto
s = (1,...,1,0) after the agent has made n − 1 assignments. countingthenumberofstatesxwhichmatchsonX (i.e.x =s )
X X
Clearly, assigning n to f establishes the predicate in one step. thatareclassifiedasTrue(i.e.suchthatκ =True).Lemma1
n x,π,p,d,ktellsusthatκcanbeevaluatedinpolynomialtime,soWeakPAXp Proposition3. Givenasequenceofkstates,witheachstateofsize
belongs to #P. The search for a locally-minimal PAXp can thus be n,apolicyπ,apredicated,atransitionfunctionp,athresholdδ,
performedinpolynomialtimeinthesizeofs,i.e.itsnumberoffea- aconstantlengthlandb,themaximumnumberofsuccessorstates
tures,usinga#P-oracleWeakPAXp. fromanygivenstateusingπ whichisassumedtobepolynomialin
To prove #P-hardness, it suffices to give a polynomial reduction theinstance’ssize,thecomplexityoffindingaB-HXPisFPTinn.
from PERFECT MATCHINGS whichisa#P-completeproblem[27].
ConsideragraphG = (V,E)whereV isthesetofverticesandE Proof. Recallthattheinputincludesalength-khistorymadeupof
isthesetofedges.V isdecomposedintotwopartsV andV sothat kstatesofsizen.Anexhaustivesearchoverallpossiblealternative
1 2
eachedgehasoneendinV andanotherinV .Inotherwords,Gis length-kscenarioswouldrequireΩ(nbk)time(andhenceisnotFPT
1 2
abipartitegraph.Aperfectmatchingisasetofedgessuchthatno innbecauseoftheexponentialdependenceonk,evenifbisacon-
pairsofverticeshasacommonvertex. stant).Ontheotherhand,B-HXPneedonlyexhaustoverscenariosof
Let us define a set of n features f ∈ F such that each feature constantlengthl.Thecomplexityofredefiningthepredicatebyfind-
i
f correspondstoavertex,sayi,inV .WedefinethedomainD of ingoneLmPAXpisf(n)blforsomefunctionf ofn(thestatesize).
i 1 i
eachfeaturef asthesetofverticesinV thatarerelatedtoibyE.In Thisredefinitionofthepredicatemustbeperformedatmostktimes,
i 2
otherwords,anedgee∈Eisapossibleassignmentofafeaturef to givingacomplexityinO(f(n)blk).ItfollowsthatB-HXPisFPTin
i
avaluev .ThefeaturespaceFismodeledbyG.Indeed,eachpoint nsinceblkisapolynomialfunctionofthesizeofaninstance.
j
x = (f ,...,f ) ∈ Fcanbeobtainedbyassigningeachfeaturein
1 n
V 1 toavalueinV 2.Thus,astatexisrepresentedbyasetofedges In short, B-HXP keeps the calculation of importance scores ex-
E x ⊆E.TocomputeWeakPAXp,thefollowingclassifierisused: haustive,bycuttingthelength-khistoryintosub-sequencesoflength
l,startingfromtheend.Themostimportantactionofasub-sequence
(cid:26)
κ(x)=
True if∀i̸=j,f
i
̸=f
j
isretained,anditsassociatedstateisusedtodefined′,thenewpred-
False otherwise icate to study, using locally-minimal PAXp. d′ is then studied in a
new sub-sequence. This process is iterated throughout the history.
ThisclassifieroutputsTrueforanystatexcomprisingadistinct
ThenextsectionpresentsexamplesofB-HXP.
valuationforeachfeature.InG,suchastatexisrepresentedbyaset
Thecalculationofnewpredicatesiscomputationallychallenging
ofedgesE ⊆ E insuchawaythateachpairofedgesinE has
x x but is feasible (using certain approximations: calculating just one
no common vertices. Thus, E is a perfect matching. From a spe-
x rather than all PAXp’s and, as we will see later, the use of sam-
cificpointvsuchthatκ(v) = True,weareinterestedinknowing
plingratherthanexhaustivesearchoverfeaturespace).Theresulting
whetherX = ∅isaweakPAXp,fordifferentvaluesofδ.Basedon
methodB-HXPprovidesanovelapproachtoexplaininghistories.
Definition3,itisnecessarytocalculatetheproportionofstatesclas-
sifiedasTruetodeterminewhetherX isaweakPAXp.WithX =∅,
thetotalnumberofstatesthatmatchX correspondstothenumberof 4 Experiments
statesinF.Thisiseasilyobtainedbymultiplyingthedomain-sizes
|D i|, |F| = Πn i=1|D i|. The number of states which match X and The experiments were carried out on 3 RL problems: Frozen Lake
areclassifiedbyκtoTrue,isobtainedbycountingthestateswhich (FL),Connect4(C4)andDroneCoverage(DC)[20].Q-learning[29]
haveadistinctvaluationforeachfeature,i.e.bycountingtheperfect wasusedtosolvetheFLproblem,andDeep-Q-Network[17]forC4
matchingsinG.X = ∅isaweakPAXpiffitisa(locally-minimal) andDC.Theagents’trainingwasperformedusingaNvidiaGeForce
PAXp.Thus,wehavereducedthePERFECTMATCHINGSproblemto GTX 1080 TI GPU, with 11 GB of RAM. The B-HXP examples
apolynomialnumberofcallstothelocally-minimalPAXpproblem. wererunonanHPElitebook855G8with16GBofRAM(source
Hence there is a polynomial-time Turing reduction from PERFECT codeavailable[22]).
MATCHINGStothelocally-minimalPAXpproblem,whichisthere- Thefirstpartofthissectiondescribestheproblemsandthestud-
fore#P-hard. ied predicates. The second part presents B-HXP examples. In the
associatedfigures,thehistoryisdisplayedovertwolines.Eachhis-
Consequently, the B-HXP complexity is deduced from the com- tory is composed of 13 states and 12 actions. The action taken by
plexityofthecomputationofimportancescoresandthegeneration theagentfromastateisshownaboveit.Importantactionsandtheir
oftheintermediatepredicates. statesarehighlightedbyagreenframe.Thethirdlineinfigures2,4
correspondstothepredicatesgeneratedduringtheB-HXP,wherea
Proposition2. TheB-HXPcomputationisinFP#P andis#P-hard.
darkgreycellmeansthatthisfeatureisnotpartofthepredicate.In
Tables 1, 2 and 3, the importance scores given are w.r.t. either the
Proof. FromLemma1andLemma3,wededucethatthecomputa-
initialpredicateortheintermediateones.
tionalcomplexityofB-HXPisinFP#P andis#P-hard,inparticular
duetothecomplexityofthegenerationofanewpredicate.
ThecomputationofaB-HXPandtheimportancescorecomputa-
tion in forward HXP are both #P-hard. But, it is important to note
that counting states (in B-HXP) is less computationally expensive
thancountingscenarios(i.e.asequenceofkstates).
We can provide a finer analysis by studying fixed-parameter
tractability in n, the size of a state. A problem is fixed parameter
tractable(FPT)withrespecttoparameternifitcanbesolvedbyan
algorithmrunningintimeO(f(n)×Nh)),wheref isafunctionof
nindependentofthesizeN oftheinstance,andhisaconstant[7]. Figure3. FrozenLake8×8map.Figure4. B-HXPfortheperfectcoverpredicateinaDCproblemhistory.Therightmostsituationinthelastrow,correspondingtothefirstPAXpredpredicate,
statesthatthebluedroneisinrow7andthatthelightgreysquaresarefree.Theotherintermediatepredicatesimposetherelativepositionsoftwootherdrones
andthatsomesquaresarefree.Thedronesarerepresentedbydotsandthetreesbygreentriangles.
4.1 Descriptionoftheproblems knowthenextmoveoftheopponent,transitionsarestochastic.
Fivepredicateswerestudied,includingtheobviouswinandlose.
FrozenLake Inthisproblem,theagentmovesonthesurfaceof Fortheotherthree,theinitialstateiscomparedwiththefinalstates
a frozen lake (2D grid) to reach a certain goal position, avoiding ofthegeneratedscenarios.Thepredicatecontrolmid-columnissat-
fallingintotheholes.Theagentcanmoveinanyofthe4cardinal isfied when the agent has more tokens in the middle column. The
directionsandreceivesarewardonlybyreachingthegoalposition. predicates3inarowandcounter3inarowaresatisfiedrespectively
However,duetotheslipperysurfaceofthefrozenlake,iftheagent when the agent obtains more alignments of 3 tokens on the board,
choosesadirection(e.g.upasinthesecondstateofFigure1),ithas
andpreventstheopponentfromobtainingmorealignmentsof3to-
0.6probabilitytogointhisdirectionand0.2togotowardseachre-
kensontheboard.
mainingdirectionexcepttheoppositeone(e.g.,forup,0.2togoleft
and 0.2 to go right, as occurred in the scenario of Figure 1 where
the agent moved right in the third state after performing up in the
secondone).Theagent’sstateiscomposedof5features:itsposition
(P)andpreviousposition(PP)onthemap,thepositionofoneofthe
twoholesclosesttotheagent(HP),theManhattandistancebetween
theagent’sinitialpositionandhiscurrentposition(PD),andthetotal
numberofholesonthemap(HN).Thislastfeaturewasaddedasa
check:sinceitisaconstantitshouldneverappearintheredefined
predicate,whichwasindeedthecase.
Predicateswin,holesandregionwerestudied.Theyrespectively
determine whether the agent reaches the goal, falls into a hole or
Figure6. DroneCoverage10×10map.
reachesapre-definedsetofmappositions.
DroneCoverage Inthisproblem,fourdronesmustcover(observe)
thelargestareaofawindy2Dmap,whileavoidingcrashingintoa
treeoranotherdrone.Adronecanmoveinanyofthe4cardinaldi-
rections or remain stationary. A drone’s cover is the 3×3 square
centeredonit.Adrone’scoverisoptimalwhenitdoesnotcontain
anytreesandthereisnooverlapwiththecoversoftheotherdrones.
Hence, its reward is based on its cover and neighbourhood. More-
over,itreceivesanegativerewardinthecaseofacrash.Anagent’s
stateismadeupofitsview,a5×5imagecenteredonit,anditspo-
sition,representedby(x,y)coordinates.Afteranagent’saction,the
windpushestheagentleft,down,right,upaccordingtothefollow-
Figure5. Connect4board. ing distribution: [0.1,0.2,0.4,0.3] unless the action is stop or the
Connect4 TheConnect4gameisplayedona6by7verticalboard, agentandwinddirectionsareopposite(inthesecasesthewindhas
wherethegoalistoalign4tokensinarow,columnordiagonal.Two noeffect).
playersplayinturn.Anagent’sstateisthewholeboard.Anaction TenpredicatesfortheDCproblemwerestudied(localandglobal
correspondstodroppingatokeninacolumn.Theagentreceivesa versionsof):perfectcover,maximumreward,nodrones,crashand
rewardonlybyreachingterminalstates:1,−1,0.5ifthestaterepre- region. Local versions concern a single agent, whereas the global
sentsanagent’swin,lossordrawrespectively.Astheagentdoesnot versions concern all agents. Local versions of predicates allow tocheckwhetheranagentreachesaperfectcover(perfectcover),gets Table2. ImportancescoresintheC4history2
a maximum reward (maximum reward), has no drones in its view Predicate Time-step/Importancescore
range(nodrones)anddidnotcrash(crash).Asanexample,thelocal 9 10 11
win
no drones predicate checks whether the agent has no drones in its 0.726 0.099 0.16
viewrangewhiletheglobalnodronespredicatecheckswhethereach PAXpred (s ,0.8) 6 7 8
κ 9 -0.006 0.03 0.113
agent has no drones in its view range. The map was divided into
5 6 7
4regionsofdimension5×5fortheregionpredicate.Inthelocal PAXpred κ(s 8,0.8) 0.003 0.0 0.0
version,thepredicatecheckswhethertheagenthasreachedacertain 2 3 4
PAXpred (s ,0.8)
region.Intheglobalversion,eachagentmustbeinitsowndistinct κ 5 0.003 0.0 0.0
region.
Connect4 InFigure2,weareinterestedintheactionsoftheagent
playingtheyellowstokens.Theotherplayerisconsideredastheen-
4.2 B-HXPexamples vironment’s response. Each action performed by the agent is rep-
resented by a number which corresponds to the column number in
To provide B-HXPs in reasonable time, the sample parameter,
whichtheagenthaschosentodropatoken.Thepredicatesdisplayed
which corresponds to the maximum number of states observed for
onthethirdlinehavebeencalculatedfromthestatesassociatedwith
afeatureevaluationinthefindLmPAXpalgorithm[13],i.e.thepred-
themostimportantactions.
icate generation, was set to 10 in the following examples. In other
words,toavoidanexhaustivesearchoverF,theproportioninDefi- Withlsetto3andδ to0.8,aB-HXP(computedin10seconds)
for a C4 history is shown in Figure 2. A large part of the board is
nition3wascomputedbasedon10samples.
ignored in the PAXpred predicates (see the line below the history
Table1. ImportancescoresintheFLhistory1 inFigure2),whichgivestheuseranintuitionofthetypeofstates
that the agent must reach. Importance scores are presented in Ta-
Predicate Time-step/Importancescore
8 9 10 11 ble 2. Almost all the actions returned are related to setting up the
win
-0.001 0.04 0.012 0.114 tokenalignmentleadingtovictory,whichisinterestingbecausethe
PAXpred κ(s11,0.7) 7 8 9 10 predicate win is only studied on the last three states of the history.
(a.k.a.purple) 0.006 -0.008 0.102 0.087
Theotherpredicatesprovideactionslinkedtoachievingawin.The
PAXpred κ(s9,0.7) 5 6 7 8
firstredefinedpredicate(therightmostimageonthethirdlineofFig-
(a.k.a.green) -0.0003 0.0 -0.001 -0.0003
ure2)describesapartialboardconfiguration:frompositionssatis-
fyingthispredicate,anagentfollowingthelearntpolicyhasatleast
Frozen Lake In Figure 1, the agent is symbolized by a red dot, 80%chanceofachievingawininthefinalposition.However,asin
thedarkbluecellsareholesandthedestinationcellismarkedbya theFLB-HXP,apartfromthepredicatedefinedattime-step9,the
star.Eachactionperformedisrepresentedbyaredarrowwhichcor- otherpredicatesgeneratedseemtobenotsufficientlygeneric,which
respondstothedirectionchosenbytheagentinthestatedescribed canbeseeninthescores.Indeed,thesecondredefinedpredicate(the
below.Inthestatesassociatedwiththemostimportantactions,the second-from-rightimageinthelastlineofFigure2)issospecificas
genericityofthecomputedpredicatesisrepresentedbycoloredcells. touniquelydeterminetheexactboardconfiguration(giventheheight
A predicate is said to be generic if it is respected by a large num- ofcolumnsandthenumberoftokensplayed).Nevertheless,3outof
ber of different states. The first predicate is represented in purple, the4importantactionsreturnedsetupthewinningdiagonal.
thesecondingreen.Acoloredcell(purpleorgreen)meansthatthe
predicateisvalidforallthestateswhoseposition(P)isthiscellon Table3. ImportancescoresintheDChistory4
thegrid(i.e.thestateswhosefeaturevaluePisthiscell). Predicate Time-step/Importancescore
AB-HXP(computedin2seconds)foraFLhistoryisshownin 9 10 11
perfectcover
Figure1,withl=4,δ=0.7.ImportancescoresarepresentedinTa- 0.114 0.063 0.056
6 7 8
ble1.Therightactionlinkedtothepenultimatestates
11
= {P = PAXpred κ(s 9,1.0)
0.008 0.006 0.002
(7,8),PP = (6,8),HP = (6,7),PD = 13,HN = 10}isthe 3 4 5
PAXpred (s ,1.0)
mostimportantinthefirstsub-sequencestudiedinordertowin.The κ 6 0.053 -0.013 0.09
predicatePAXpred κ(s 11,0.7)=(PD=13),computedfroms
11 PAXpred (s ,1.0)
2 3 4
with δ = 0.7, is named purple hereafter. The states described by κ 5 0.034 -0.036 0.023
thepredicateareshowninpurpleinFigure1.Inthefollowingsub-
sequence,thedownactionlinkedtostates ={P =(5,8),PP = Drone Coverage In Figure 4, we look at the actions of the blue
9
(5,7),HP = (6,7),PD = 11,HN = 10} is the most impor- drone.Inthehistory,eachdroneisrepresentedbyacoloreddot,and
tanttorespectpurple.ThepredicatePAXpred (s ,0.7) = (P = treesbygreentriangles.Thecoverageofadroneisrepresentedby
κ 9
(5,8))∧(PP = (5,7))∧(HP = (6,7)),computedfroms ,is cellsofthesamecolorasthedrone.Darkgreycellsmeanthatthere
9
namedgreen(thestatesdescribedareshowningreeninFigure1). isanoverlapofcoveragebetweentwodrones.Aboveeachenviron-
Wenotethatpurpledescribesmorestatesthangreen.Thelatterisnot mentdisplay,onlytheactionperformedbythebluedroneisshown.
genericenough,whichisreflectedintheimportancescores,which The actions are represented by an arrow or a square to represent,
arecloseto0:whatevertheaction,itisunlikelytorespectthispredi- respectively, the direction chosen by the agent or the action of re-
cateafter4timesteps.Theentirehistoryisnotexploredwhencalcu- mainingstationary.EachpredicatepresentedonthethirdlineofFig-
latingtheB-HXP,astheutilityofthelaststateselecteds is0.The ure4representsapartialdescriptionofastateofthebluedronein
6
selectedactionsformameaningfulexplanationwhenwelookatthe thehistory,includingitspositionanditsvision.Inthevisionpartof
predicatesstudied.However,theredefinedpredicatesfairlyquickly thepredicate,adarkgreyboxmeansthatthefeatureisnotpartof
becomeveryspecificandprobablyoflittlehelpinexplainingwhy thepredicate.Therightmostsituationinthelastrow,corresponding
theagentwon. tothefirstPAXpredpredicate,statesthatthebluedroneisinrow7andthatthelightgreysquaresarefree.Theotherintermediatepredi- the case. If we consider the first redefined predicate as a possible
catesimposetherelativepositionsoftwootherdronesandthatsome causeofthepredicatebeingsatisfiedinthefinalstate,thenthesecond
squaresarefree. redefinedpredicateisapossiblecauseofapossiblecause.Thenotion
AB-HXP(calculatedin13seconds)foraDChistoryisshownin ofcausalitycanquicklybecomehighlydiluted(duetothefactthat
Figure4,withl=3andδ=1.Theexplanationisforthebluedrone forcomputationalreasons,westudyasinglecauseateachstep).The
with the original predicate that this agent has a perfect cover. Im- usermustbeawareofthiseffectwhencomputingB-HXPs.
portancescoresarepresentedinTable3.Themostimportantactions B-HXPofferstheuseracrediblealternativetoforwardHXPwhen
reflectthebluedronestrategyofmovingawayfromthedronesand studying the behaviour of an agent in long histories. Furthermore,
treesinitscover.Thepredicatesgiveagoodintuitionofthetypeof thisapproachisagnosticwithregardtotheagentlearningalgorithm.
state(positionand5×5view)theagentistryingtoreach. Asdonein[21]forHXP,wealsomadethestrongassumptionforthe
useofB-HXPthatthetransitionfunctionisknown.Itmustbeknown
duringtheexplanationphase(notnecessarilyduringtraining),orat
5 Relatedwork
leastapproximated,forexampleusinganRLmodel-basedmethod.
XRLmethodscanbeclusteredaccordingtothescopeoftheexpla- Moreexperimentsareneededtoensurethequalityandscalability
nation(e.g.explainingadecisioninagivensituationorthepolicyin ofB-HXP,speciallyinenvironmentswithalargenumberoftransi-
general),thekeyRLelementsusedtoproducetheexplanation(e.g. tions.Whencalculatingalocally-minimalPAXp,theorderinwhich
states[10,18],rewards[14,1]),ortheformoftheexplanation(e.g. featuresareprocessedisimportant.Anavenueoffutureworkwould
saliencymaps[10]sequence-basedvisualsummaries[2,23,20]). betodirectthegenerationoflocally-minimalPAXpusingafeature
One approach consists in generating counterfactual trajectories orderingheuristic,suchasLIME[19].Inthisway,itwouldbepos-
(state-actionsequences)andcomparingthemwiththeagent’strajec- sibletocomparetheintermediatepredicatesandcheckwhetherthis
tory.In[1],rewardinfluencepredictorsarelearnttocomparetrajec- changestheimportantactionsreturned.
tories.Thecounterfactualoneisgeneratedbasedontheuser’ssug- Our experiments have shown the feasibility of finding the im-
gestion.In[28],acontrastivepolicybasedontheuser’squestionis portant actions in a long sequence of actions by redefining predi-
built to produce the counterfactual trajectory. In the MDP context, cates, working backwards from the end of the sequence. However,
Tsirtsisetal.generateoptimalcounterfactualtrajectoriesthatdiffer wefoundthattheintermediatepredicatescanquicklybecomevery
atmostbykactions[26].Theimportancescoreusedinthispaperis specificleadingtothedifficultyofcalculatingtheimportancescores
inlinewiththecounterfactualviewbyevaluatingscenarioswherea of actions w.r.t. these very specific predicates. Further research is
differentactiontookplaceatagiventime. requiredtoinvestigatethispoint.Thevariouscomplexityresultsob-
EDGE[11]isaself-explainablemodel.LikeHXP,itidentifiesthe tainedindicatetheinherentdifficultyoftheproblem.
importantelementsofasequence.However,EDGEislimitedtoim-
portance based on the final reward achieved, whereas HXPs allow Acknowledgements
thestudyofvariouspredicates.Inaddition,HXPreliesonthetransi-
tionfunction(whichisassumedtobeknown)andtheagent’spolicy This work has been supported in part by the ForML ANR project
toexplain,whereasEDGE[11]requiresthelearningofapredictive ANR-23-CE25-0009.
modelofthefinal-episodereward.
References
6 Conclusion
[1] A.AlabdulkarimandM.O.Riedl. Experientialexplanationsforre-
inforcementlearning. CoRR,abs/2210.04723,2022. doi:10.48550/
HXP(HistoryeXplanationviaPredicates) [21]isaparadigmthat, ARXIV.2210.04723.URLhttps://doi.org/10.48550/arXiv.2210.04723.
foragivenhistory,answersthequestion:“Whichactionswereim- [2] D. Amir and O. Amir. HIGHLIGHTS: summarizing agent behavior
portanttoensurethatthepredicatedwasachieved,giventheagent’s topeople. InAAMAS,pages1168–1176.InternationalFoundationfor
AutonomousAgentsandMultiagentSystems/ACM,2018. URLhttp:
policyπ?".Todothis,animportancescoreiscomputedforeachac-
//dl.acm.org/citation.cfm?id=3237869.
tioninthehistory.Unfortunatelythiscalculationis#W[1]-hardwith [3] L.Chen,P.Chen,andZ.Lin. Artificialintelligenceineducation:A
respecttothelengthofthehistorytoexplain.Toprovideexplanations review. IEEEAccess,8:75264–75278,2020. doi:10.1109/ACCESS.
2020.2988510.URLhttps://doi.org/10.1109/ACCESS.2020.2988510.
forlonghistories,withoutresortingtoimportancescoreapproxima-
[4] J. A. Clouse. On integrating apprentice learning and reinforce-
tion,weproposetheBackward-HXPapproach:startingfromtheend ment learning. PhD thesis, 1996. URL https://www.proquest.com/
of the history, it iteratively studies a subsequence, highlighting the dissertations-theses/on-integrating-apprentice-learning-reinforcement/
most important action in it and defining a new intermediate predi- docview/304308206/se-2.
[5] M.C.CooperandJ.Marques-Silva.Tractabilityofexplainingclassifier
cate to study for the next sub-sequence (working backwards). The
decisions. Artif.Intell.,316:103841,2023. doi:10.1016/J.ARTINT.
intermediate predicate is a locally-minimal PAXp corresponding to 2022.103841.URLhttps://doi.org/10.1016/j.artint.2022.103841.
thestatewherethemostimportantactiontookplace. [6] A.Darwiche. Human-levelintelligenceoranimal-likeabilities? Com-
mun.ACM,61(10):56–67,2018. doi:10.1145/3271625. URLhttps:
Intheexperiments,weobservedthatthegenericityofapredicate
//doi.org/10.1145/3271625.
dandthesearchhorizonlinfluencetheimportancescores.Themore
[7] R.G.DowneyandM.R.Fellows. ParameterizedComplexity. Mono-
genericthepredicated,thegreatertheprobabilityoffindingstatesat graphsinComputerScience.Springer,1999.ISBN978-1-4612-6798-0.
anhorizonlthatrespectd.Conversely,alessgenericpredicatemakes URLhttps://doi.org/10.1007/978-1-4612-0515-9.
[8] N.C.Eli-Chukwu.Applicationsofartificialintelligenceinagriculture:
itmoredifficulttoevaluateanaction.Atoospecificpredicatedcan
Areview. Engineering,Technology&AppliedScienceResearch,9(4),
leadtoinsignificantimportancescores(closeto0)fortherespectof 2019.
d.Inseveralhistories,notablyC4ones,thepredicatesgeneratedare [9] EuropeanCommission. ArtificialIntelligenceAct,2021. URLhttps://
notgenericenough,leadingtolessinterestingexplanations. eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206.
[10] S.Greydanus,A.Koul,J.Dodge,andA.Fern. Visualizingandunder-
Although in the examples the actions identified as important are
standingAtariagents.InICML,pages1787–1796.PMLR,2018.URL
oftenrelatedtotherespectoftheinitialpredicate,thisisnotalways http://proceedings.mlr.press/v80/greydanus18a.html.[11] W. Guo, X. Wu, U. Khan, and X. Xing. EDGE: explaining
deep reinforcement learning policies. In NeurIPS, pages 12222–
12236, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
65c89f5a9501a04c073b354f03791b1f-Abstract.html.
[12] P. Hamet and J. Tremblay. Artificial intelligence in medicine.
Metabolism,69:S36–S40,2017.
[13] Y. Izza, X. Huang, A. Ignatiev, N. Narodytska, M. C. Cooper, and
J.Marques-Silva. Oncomputingprobabilisticabductiveexplanations.
Int. J. Approx. Reason., 159:108939, 2023. doi: 10.1016/j.ijar.2023.
108939.URLhttps://doi.org/10.1016/j.ijar.2023.108939.
[14] Z.Juozapaitis,A.Koul,A.Fern,M.Erwig,andF.Doshi-Velez. Ex-
plainable reinforcement learning via reward decomposition. In IJ-
CAI/ECAIworkshoponexplainableartificialintelligence,page7,2019.
[15] Z.C.Lipton.Themythosofmodelinterpretability.Commun.ACM,61
(10):36–43,2018.URLhttps://doi.org/10.1145/3233231.
[16] S.Milani,N.Topin,M.Veloso,andF.Fang. Asurveyofexplainable
reinforcement learning. CoRR, abs/2202.08434, 2022. URL https://
arxiv.org/abs/2202.08434.
[17] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare,A.Graves,M.Riedmiller, A.K.Fidjeland,G.Ostrovski,
S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Ku-
maran, D. Wierstra, S. Legg, and D. Hassabis. Human-level con-
trolthroughdeepreinforcementlearning. Nature,518(7540):529–533,
2015. ISSN 0028-0836, 1476-4687. URL http://www.nature.com/
articles/nature14236.
[18] M.L.Olson,L.Neal,F.Li,andW.Wong. Counterfactualstatesfor
atariagentsviagenerativedeeplearning.CoRR,abs/1909.12969,2019.
URLhttp://arxiv.org/abs/1909.12969.
[19] M.T.Ribeiro,S.Singh,andC.Guestrin. “WhyshouldItrustyou?":
Explainingthepredictionsofanyclassifier. InSIGKDD,pages1135–
1144.ACM,2016. doi:10.1145/2939672.2939778. URLhttps://doi.
org/10.1145/2939672.2939778.
[20] L. Saulières, M. C. Cooper, and F. Dupin de Saint-Cyr. Reinforce-
mentlearningexplainedviareinforcementlearning:Towardsexplain-
ablepoliciesthroughpredictiveexplanation. InICAART2023,Volume
2, pages 35–44. SCITEPRESS, 2023. URL https://doi.org/10.5220/
0011619600003393.
[21] L.Saulières,M.C.Cooper,andF.DupindeSaint-Cyr.Predicate-based
explanationofaReinforcementLearningagentviaactionimportance
evaluation. InECML/PKDDworkshoponAdvancesinInterpretable
Machine Learning and Artificial Intelligence, page to appear, Turin,
Italy,2023.URLhttps://hal.science/hal-04170188.
[22] L.Saulières,M.Cooper,andF.DupindeSaint-Cyr. Codeanddatafor
"Backwardexplanationsviaredefinitionofpredicates",July2024.URL
https://doi.org/10.5281/zenodo.13120510.
[23] P.SequeiraandM.T.Gervasio. Interestingnesselementsforexplain-
able reinforcement learning: Understanding agents’ capabilities and
limitations. Artif.Intell.,288:103367,2020. doi:10.1016/J.ARTINT.
2020.103367.URLhttps://doi.org/10.1016/j.artint.2020.103367.
[24] R.S.SuttonandA.G.Barto.Reinforcementlearning:Anintroduction.
MITpress,2018.
[25] TheWhiteHouseOSTP.BlueprintforanAIBillofRights.Oct.2022.
URLhttps://www.whitehouse.gov/ostp/ai-bill-of-rights/.
[26] S. Tsirtsis, A. De, and M. Rodriguez. Counterfactual explanations
in sequential decision making under uncertainty. In NeurIPS, pages
30127–30139,2021. URLhttps://proceedings.neurips.cc/paper/2021/
hash/fd0a5a5e367a0955d81278062ef37429-Abstract.html.
[27] L.G.Valiant.Thecomplexityofenumerationandreliabilityproblems.
SIAMJ.Comput.,8(3):410–421,1979. doi:10.1137/0208032. URL
https://doi.org/10.1137/0208032.
[28] J.vanderWaa,J.vanDiggelen,K.vandenBosch,andM.A.Neer-
incx. Contrastiveexplanationsforreinforcementlearningintermsof
expected consequences. CoRR, abs/1807.08706, 2018. URL http:
//arxiv.org/abs/1807.08706.
[29] C.J.WatkinsandP.Dayan. Q-learning. Machinelearning,8(3):279–
292,1992.