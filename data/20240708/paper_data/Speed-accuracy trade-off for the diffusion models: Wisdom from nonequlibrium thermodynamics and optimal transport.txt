Speed-accuracytrade-offforthediffusionmodels: Wisdomfromnonequlibriumthermodynamics
andoptimaltransport
Kotaro Ikeda,1,∗ Tomoya Uda,2 Daisuke Okanohara,3 and Sosuke Ito4,†
1DepartmentofMathematicalEngineeringandInformationPhysics, SchoolofEngineering,
The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan
2Department of Earth and Planetary Physics, School of Science,
The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan
3Preferred Networks Inc., 1-6-1, Otemachi, Chiyoda-ku, Tokyo 100-0004, Japan
4Universal Biology Institute, Graduate School of Science,
The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan
(Dated:July8,2024)
Wediscussaconnectionbetweenagenerativemodel,calledthediffusionmodel,andnonequilibriumther-
modynamics for the Fokker-Planck equation, called stochastic thermodynamics. Based on the techniques of
stochasticthermodynamics,wederivethespeed-accuracytrade-offforthediffusionmodels,whichisatrade-
off relationship between the speed and accuracy of data generation in diffusion models. Our result implies
thattheentropyproductionrateintheforwardprocessaffectstheerrorsindatageneration. Fromastochastic
thermodynamicperspective,ourresultsprovidequantitativeinsightintohowbesttogeneratedataindiffusion
models. Theoptimallearningprotocolisintroducedbytheconservativeforceinstochasticthermodynamics
andthegeodesicofspacebythe2-Wassersteindistanceinoptimaltransporttheory. Wenumericallyillustrate
thevalidityofthespeed-accuracytrade-offforthediffusionmodelswithdifferentnoiseschedulessuchasthe
cosineschedule,theconditionaloptimaltransport,andtheoptimaltransport.
I. INTRODUCTION ics, and the improved diffusion models are regarded as vari-
ants of other statistical machine learning models. For exam-
The diffusion processes are irreversible phenomena that ple,thediffusionmodels[42]arerelatedtothescoreestima-
cause thermodynamic dissipation. The diffusion processes tion methods including the score matching [56–58]. By in-
are described by stochastic processes such as Brownian mo- corporatingtheexistingflow-basedmethod [59–62],another
tion[1],andthermodynamicirreversibilityisquantifiedbythe improved method called the flow matching method [63] has
entropy production in stochastic thermodynamics [2, 3]. In alsobeenproposedinthecontextofthediffusionmodels.
stochastic thermodynamics, there have been various discus- Because the diffusion models have been improved out-
sions about the relationship with information processing and side the context of nonequilibrium thermodynamics, the in-
thermodynamicdissipationforthediffusionprocesses[4–24]. sightsofstochasticthermodynamicsarenotfullyexploitedin
Basedonoptimaltransporttheory[25],inevitablethermody- the diffusion models. For example, the discussion of mini-
namic dissipation for the diffusion processes has been dis- mumentropyproductioninstochasticthermodynamicsisre-
cussed in stochastic thermodynamics [26–29], and the ther- latedtotheWassersteindistance[25]inoptimaltransportthe-
modynamic trade-off relationships between speed, accuracy, ory [29, 30], which is well used in generative models such
and dissipation for the diffusion processes have been dis- as the Wasserstein generative adversarial network [64] and
cussedasageneralizationofthesecondlawofthermodynam- the diffusion models [65–67]. Discussions on the relation-
ics[29–33]. shipbetweenoptimaltransportanddynamicsinthediffusion
The diffusion processes have recently been discussed in modelhaveonlyrecentlybegun[68–73].Inthesediscussions,
thecontextofstatisticalmachinelearningmodelscalledgen- various findings in stochastic thermodynamics, such as the
erative models [34]. The diffusion-based generative models thermodynamic trade-off relationships for the diffusion pro-
called the diffusion models [35, 36] were originally inspired cessesbasedonoptimaltransporttheory[29–32],arenotwell
by nonequilibrium thermodynamics [35]. By introducing used.Thereisonlyonepaperthatdiscussestheflowmatching
time-reverseddynamics,whicharewellstudiedinthecontext method from the viewpoint of both optimal transport theory
of the fluctuation theorem [5, 37, 38] and Jarzynski’s equal- andstochasticthermodynamics[74].
ity[39],diffusionmodelsgeneratedatawithspatialstructure In this paper, we reconsider diffusion models in terms of
from noisy data without spatial structure. Several improve- stochasticthermodynamicsandderiveaspeed-accuracytrade-
ments have been made from different perspectives [40–53], off for the diffusion models, which is analogous to the ther-
andtheimproveddiffusionmodelshaveachievedstate-of-the- modynamictrade-offrelationshipbasedonoptimaltransport
artintheimagegenerationtask [40,42]. theory.Thespeed-accuracytrade-offexplainsthatthetheoret-
Theproposeddiffusionmodels[42,44,51,54,55]arecur- ical limits of accurate data generation are generally bounded
rentlyunderstandablewithoutnonequilibriumthermodynam- bythespeedofthediffusiondynamics,whichisgivenbythe
entropyproductionrateandthetemperature. Furthermore,an
upperboundonthespeed-accuracytrade-offexplainsthatthe
∗kotaro-ikeda@g.ecc.u-tokyo.ac.jp optimal diffusion dynamics for learning is given by the opti-
†sosuke.ito@ubi.s.u-tokyo.ac.jp maltransport. Theresultsprovidetheoreticalsupportforthe
4202
luJ
5
]hcem-tats.tam-dnoc[
1v59440.7042:viXra2
trial-and-errorprotocolsofdiffusiondynamicsthathavebeen probability density function q(x) > 0 is required for quan-
characterized by noise schedules such as the cosine sched- tities such as lnq(x) or 1/q(x) not to diverge, and we will
ule [43] and the conditional optimal transport schedule [63]. implicitly assume that any probability density functions are
Wenumericallyillustratethisspeed-accuracytrade-offforthe positive throughout this paper. We consider the problem of
diffusionmodelsusingsimpleone-dimensionaldiffusionpro- constructinganewprobabilitydensityfunctionp(x)thatsat-
(cid:82)
cesses. We show that the possibility of accurate data gener- isfies p(x) > 0 and that dxp(x) = 1, based on the es-
ation can be discussed from a quantitative comparison of in- timation of the probability density function q(x). Statistical
equalitiesbetweendifferentdiffusionprocessesdescribedby machinelearningmodelsthatgeneratesamplesfromtheprob-
thecosineschedule,theconditionaloptimaltransport,andthe abilitydensityfunctionp(x)arecalledgenerativemodels.
optimaltransport. Several studies have shown that generative models can be
This paper is organized as follows. In Sec. II, we discuss appliedtopracticaldatasetssuchasimages[75],naturallan-
thegenerativemodelsandthediffusionmodels. Wefirstex- guage [76], and audio [77]. In these applications, gener-
plain the generative models [Sec. IIA] and then move on to ative models are constructed by solving optimization prob-
the basic concepts of the diffusion models [Sec. IIB]. We lems using machine learning methods such as deep learn-
then present the mathematical details of the diffusion model ing [34, 78]. Machine learning optimization problems are
[Sec. IIC, IID]. We also explain the practical formulation solved by numerically minimizing or maximizing some ob-
based on the conditional Gaussian probabilities [Sec. IIE], jective function [34, 78]. To judge whether learning has
as well as some examples [Sec. IIF]. In Sec. III, we explain been successful, we sometimes discuss whether the distance
stochasticthermodynamics,especiallyfromtheperspectiveof orpseudo-distancebetweenthedistributionoftheinputdata
itsrelationshiptodiffusionmodelsandoptimaltransportthe- q(x)andthedistributionofthegenerateddatap(x)becomes
ory. In Sec IIIA, we introduce the entropy production rate smaller[79–82]. Wecallthevalueofthisdistanceorpseudo-
in stochastic thermodynamics. In Sec. IIIB, we explain ap- distancetheestimationerror. Typicalexamplesoftheestima-
plications of the optimal transport theory in stochastic ther- tionerroraretheKullback-Leiblerdivergence[83],apseudo-
modynamics such as the thermodynamic trade-off relations. distanceininformationtheoryandinformationgeometry,and
In Sec. IV, we derive the main result, which is the speed- theWassersteindistance[25],adistanceinoptimaltransport
accuracy trade-off for the diffusion models. The main re- theory.
sult implies that the entropy production rate introduced in
Sec.IIIAprovidesafundamentallimitontheaccuracyofdata
generationinthediffusionmodel,andthemainresultisanal-
B. Diffusionmodels
ogous to the thermodynamic trade-off relations in Sec. IIIB.
Furthermore, we discuss the optimal protocol based on the
Amongthesemachinelearningbasedgenerativemodels,a
main result in Sec. IVC, and confirm the main result by nu-
methodcalleddiffusionmodels[35,36,40,42,48]achieves
mericalcalculationsofthediffusionmodelsinSec.IVD.We
lower estimation errors rather than previous generative mod-
finallyconcludethepresentedresultinthepaper[Sec.V].
els for various data [36, 47, 73, 84–90] including image
data [36, 47, 73], video [87, 88], and audio [89, 90]. Dif-
fusion models generate samples from the probability density
II. GENERATIVEMODELSANDDIFFUSIONMODELS
function p(x) by estimating the time-reversed diffusion pro-
cesswhichgeneratesthedatastructure,whilethecorrespond-
A. Generativemodels
ing forward process destroys the data structure by adding
stochasticnoisetotheinputdatasetd [seeFig.1][35,36].
in
Inthispaper,wediscussaclassofstatisticalmachinelearn- In practice, we sometimes convert the raw data into a low-
ing models known as generative models [34]. A generative dimensional latent space and discuss a diffusion process in
modelisaclassofstatisticalmodelscapableofgeneratinga thelatentspacetoextractthefeaturesofthedataandreduce
newdatasetthatresemblestheinputdataset. Thedatagener- thecomputationalcost[44]. Inthiscase,theinputdatasetd
in
ationingenerativemodelscanbeconsideredasanestimation can be regarded as the data set of latent variables created by
oftheinputdatadistribution,whilethegenerateddatasetsare convertingtherawdatasetintothelatentspace.
samplesfromtheestimateddistribution.
More specifically, generative models can be described as
follows. Let D be a set of random variables, denoted by
in
D = {X(1),...,X(N)}, which together represent the in- Specifically,theinputprobabilitydensityfunctionP (x)=
in 0
put data set. Each random variable, denoted by X(n) (n = q(x)istransformedintoaknownnoisedistributionP (x)by
τ
1,...,N), represents a data point, and its event is repre- adding noise to the input data, where P (x) is the probabil-
t
sented by a vector in the n -dimensional Euclidean space ity density function at time t ∈ [0,τ]. The time evolution
d
x(n) ∈ Rnd. We denote the set of events corresponding to ofP t(x)isgivenbythediffusionprocessesdescribedbythe
D as d = {x(1),...,x(N)}. The data x(n) are assumed Fokker-Planck equation [92] or the master equation [93] in
in in
to be independent and identically distributed, and are sam- the diffusion models [35, 36]. Sometimes we consider the
pled from a probability density function q(x) that satisfies stochasticdynamicsofthedata[36]fromtheinitialstatex
t=0
(cid:82)
q(x) > 0andthat dxq(x) = 1. Here,thepositivityofthe tothefinalstatex wherex isthestateofthedataattime
t=τ t3
thetimeevolutionoftheprobabilitydensityfunction. Forex-
ample,thereareseveralmethodstogeneratethedatafromthe
Forward process
estimatedprocessusingtheLangevinequation[36,42]orthe
deterministictimeevolutionviaflow[63]..
Training data
Reverse process
Estimation error C. Fokker–Planckequationfortheforwardprocess
Estimated process
WediscussthetimeevolutionofP (x)fortheforwardpro-
t
Generated data
cessinthediffusionmodels[36]basedontheFokker–Planck
equation [92]. The time evolution of the probability density
functionP (x)isdescribedbytheFokker–Planckequationas
t
FIG.1.Illustrationofthediffusionmodelsinthecaseofimagedata. follows.
Theforwardprocess,denotedbyP (x),isastochasticprocessfor
t
addingnoisetothetrainingdatasampledfromq(x). Byinverting ∂ P (x)=−∇·(cid:0) νP(x)P (x)(cid:1) ,
t t t t
thisforwardprocessintime,wepreparethereverseprocessP†(x).
t˜ νP(x):=f (x)−T ∇lnP (x), (1)
Thegenerateddatasampledfromp(x)isconstructedbyanestimated t t t t
process P˜†(x) that mimics the reverse process. The image in the
t˜ where∂ := ∂/∂tisthepartialdifferentialoperatorand∇is
figureistakenfromthedataset[91]. t
thedeloperator. νP(x) ∈ Rnd isthevelocityfieldinacon-
t
tinuousequation.TheparametersT
t
∈R ≥0andf t(x)∈Rnd
are functions of the time t in general. The forward pro-
tinsteadofthetimeevolutionoftheprobabilitydensityfunc-
cess can be regarded as the time evolution of P (x) by the
tion P (x). In this case, the stochastic time evolution of x t
t t
Fokker–Planck equation [Eq. (1)] under the initial condition
canbedescribedbytheLangevinequation[1]ortheMarkov
P (x) = q(x)withfixedtimedependenceoftheparameters
chainMonteCarlo(MCMC)method[94–96]. Thediffusion 0
T and f (x). The time dependence of T characterizes the
processfromt=0tot=τ iscalledtheforwardprocess[35], t t t
time variation of the noise intensity in the diffusion process,
andthedependenceofthenoiseintensityattimetinthefor-
whichisknownasthenoisescheduleinthediffusionmodels.
wardprocessiscalledthenoiseschedule,whichcharacterizes
TheFokker–Planckequation[Eq.(1)]isstatisticallyequiv-
thetimeevolutionofthediffusiondynamics[35,43,97].
alent to the stochastic differential equation, namely the
Next,wewillexplainthereverseprocess,whichisthetime-
Langevinequation[92,93]forthestatex ,
reverseddynamicsoftheforwardprocess. Here,weconsider t
the forward process described by the time evolution of the
(cid:112)
probabilitydensityfunctionP t(x). Wewritethereversepro- dx t =f t(x t)dt+ 2T tdB t, (2)
cessasP†(x),definedasP†(x) := P (x). Inthereverse
t˜ t˜ τ−t˜ wheredB =B −B istherandomwhiteGaussiannoise,
process,weconsiderthetimeevolutionfromt˜= 0tot˜= τ. t t+dt t
mathematically defined as the difference of the Wiener pro-
Ifτ islargeenough, thefinalprobabilityoftheforwardpro-
cesses B . If the Langevin equation is considered as Brow-
cessP (x)canbeconsideredasanoisystatewherethedata t
τ nian dynamics for the position of a Brownian particle, the
structureiswellbroken. Thus,thereverseprocessmeansthat
parameters T and f (x ) correspond to the temperature and
thisnoisystateP†(x) = P (x)istheinitialprobabilityden- t t t
0 τ the external force, respectively [92]. In the context of diffu-
sityfunctionattimet˜=0inthereverseprocess,andthetime
sion models, the forward process described by the Langevin
evolutioninthereverseprocessallowsthereproductionofthe
equation can be viewed as a time-evolving process in which
inputdatadistributionP†(x)=P (x)=q(x)containingthe
τ 0 therandomnoiseissequentiallyaddedtothedata. Usingthe
datastructureatthefinaltimet˜=τ.
Langevinequation,thetimeevolutionoftheforwardprocess
Weintroducethestochasticprocessforgeneratingthedata iscalculatedusingtheinputdatax(n) ∈ d (n = 1,...,N)
in
from p(x), namely the estimated process, as an imitation of
for fixed time dependence of the parameters T and f (x ).
t t t
the reverse process. This estimated process may differ from
ThetimeevolutionoftheprobabilitydensityfunctionP (x)
the reverse process in general, and so we write it as P˜ t˜†(x) canbecalculatednumericallybyMonteCarlosamplingut sing
anddistinguishitfromthereverseprocessP†(x)(̸=P˜†(x)). Langevindynamics[96].
t˜ t˜
Sincetheinitialprobabilitydensityfunctionoftheestimated
process P˜†(x) can be different from the initial probability
0
density function of the reverse process P†(x)(̸= P˜†(x)), D. Reverseandestimatedprocess
0 0
thefinalprobabilitydensityfunctionoftheestimatedprocess
P˜†(x) can be different from the input distribution q(x)(̸= Next, we discuss the reverse process by considering the
τ
P˜†(x)). Here,theideaofdiffusionmodelsistosetthisprob- time-reverseddynamicsoftheFokker-Planckequationforthe
τ
abilitydensityfunctionP˜†(x),whichistheoutputofthees- forwardprocess[Eq.(1)]. Usingthereversedtimet˜=τ −t,
τ
timatedprocess,asthegenerateddatadistributionp(x)[35]. thetimeevolutionofP†(x)=P (x)=P (x)isgivenby
t˜ τ−t˜ t
Inpracticaldiffusionmodels,wedonotnecessarilycompute theFokker–Planckequationfortheforwardprocess[Eq.(1)]4
asfollows, In this optimization problem, sθ S∗ M(x), which reaches the
t
minimum value L (θ∗ ) = 0, can be the score function
∂ P†(x)=−∂ P (x) SM SM
t˜ t˜ t t ∇lnP t(x).
=∇·(cid:0) νP(x)P (x)(cid:1)
t t
(cid:16) (cid:17)
=−∇· ν†(x)P†(x) , (3)
t˜ t˜ Example1-1:Stochasticdifferentialequation
where the velocity field for the reverse process ν†(x) is de-
t˜ For the data generation by the estimated process, we first
finedasν†(x):=−νP (x). explainthemethodbasedonthestochasticdifferentialequa-
t˜ τ−t˜
Thediffusionmodelsareintroducedbytheestimatedpro- tions[36,40,42]. Theestimatedscorefunction, sθ S∗ M(x), is
t
cessthatmimicsthereverseprocess[Eq.(3)]. Wedenotethe employedtoreconstructthevelocityfieldoftheforwardpro-
probabilitydensityfunctionofthedataxintheestimatedpro- cessνP(x)as,
cess by P˜†(x). We assume that the time evolution of this t
t˜
probabilitydensityfunctionP˜†(x)canbewrittenbythecon- νˆ (x):=f (x)−T sθ S∗ M(x). (7)
t˜ t t t t
tinuityequation,
Withthisestimatedvelocityfieldνˆ (x),weconstructtheve-
(cid:16) (cid:17) t
∂ t˜P˜ t˜†(x)=−∇· ν˜ t˜†(x)P˜ t˜†(x) . (4) locityfieldoftheestimatedprocessν˜ t˜†(x)as
cH ee sr se ,, wν˜ ht˜† i( cx h) mre ap yr des ife fn et rs ft rh oe mv te hl ao tc oit fy tfi heel rd evin ert sh ee pe rs ot cim esa ste νd t˜†(p xro )-
.
ν˜ t˜†(x) == −[ν ft˜P˜ †† (( xx ))] +†− 2T2 †νˆ
sτ θ−
S∗
Mt˜( †x ()
x)−T†∇lnP˜†(x), (8)
The velocity field ν˜†(x) is estimated numerically from the t˜ t˜ t˜ t˜ t˜
t˜
dynamicsoftheforwardprocess. sothattheestimatedprocess[Eq.(4)]mimicsthereversepro-
In the following section, we will explain two methods for cess [Eq. (3)], where [νP˜†(x)]† := f†(x)−T†∇lnP˜†(x),
estimating the velocity field in the reverse process and con- t˜ t˜ t˜ t˜
s fotr ruc dt ai tn ag gt eh ne erv ae tl io oc ni ,ty cafi lle el dd to hf et sh ce ore es -t bim asa et ded gep nr eo rc ae ts ivs eν˜ mt˜†( ox d)
-
f Ift˜† s( θx S∗) M: (= x)f iτ s− et˜ x( ax c) tl, yT et˜† qu:= alT toτ− ∇t˜, lnan Pd (s xθ t˜ )S∗ M a† n( dx t) he:= ins itθ τ iaS∗ −M lt˜ c( ox n) -.
t t
eling[42]andtheflow-basedgenerativemodeling[63]. ditionfortheestimatedprocessisequivalenttotheinitialcon-
ditionforthereverseprocess(P˜†(x)=P†(x)),theequation
0 0
ν˜†(x)=ν†(x)holdsandthereverseprocess[Eq.(3)]iscon-
Example1:Score-basedgenerativemodeling t˜ t˜
sistentwiththeestimatedprocess[Eq.(4)].
The continuity equation of the estimated process
First, we explain a method called score-based generative (cid:16) (cid:17)
∂ P˜†(x) = −∇ · ν˜†(x)P˜†(x) using the estimated
modeling [42]. This method consists of two components, t˜ t˜ t˜ t˜
scorematching[42,56–58]anddatageneration.Scorematch- velocity field ν˜†(x) can be regarded as the Fokker–Planck
t˜
ing is a method that estimates the score function ∇lnP t(x) equation with the external force −f†(x) + 2T†sθ S∗ M† (x).
in the forward process [Eq. (1)] in order to arrange the esti- t˜ t˜ t˜
Thestochasticdifferentialequation,(i.e.,Langevinequation)
mated process [36, 42]. The score function is typically es-
correspondingtothisFokker–Planckequationis[36,98],
timated using neural networks. Specifically, we consider a
asit nu ea ut rio aln nw eth we ore rkth de ens oco ter de bfu yn sc θ tti (o xn )∇ whln erP et θ(x re) pi rs esm eno td se tl hed esb ey t dx˜† t˜=(cid:16) −f t˜†(x˜† t˜)+2T t˜†sθ t˜S∗ M† (x˜† t˜)(cid:17) dt˜+(cid:113) 2T t˜†dB t˜, (9)
of the network’s parameters. We then solve an optimization
problemnumericallytoestimatethescorefunction. Theopti- where dB t˜ = B t˜+dt˜− B t˜ is the difference of the Wiener
mizedparameters,denotedbyθ∗ ,areemployedtogenerate processB andx˜†isthestateofthedataintheestimatedpro-
SM t˜ t˜
thevelocityfieldoftheestimatedprocessν˜†(x). cess. By simulating this stochastic differential equation nu-
t˜
The optimization problem is constructed as follows. merically,wecangeneratethedatainscore-basedgenerative
The optimization problem to estimate the score function modeling[36,40,42].
∇lnP (x) is formulated as a minimization problem of the
t
followingscorematchingobjectivefunction.
Example1-2:Probabilityflowordinarydifferentialequation
L (θ)=E (cid:2) ∥sθ(x)−∇lnP (x)∥2(cid:3) . (5)
SM Pt,U t t
Here, the uniform distribution for t ∈ [0,τ] is given by Next,wediscussanalternativemethodfordatageneration
U(t) = 1/τ. The expected value with respect to this uni- in score-based generative modeling, namely the probability
form distribution and the distribution P (x) is defined as flow ordinary differential equation (ODE) [36]. The proba-
t
E [···] = (cid:82)τ dtU(t)(cid:82) dxP (x)···. Then, the optimal bility flow ODE is a method in which we use an ODE in-
Pt,U 0 t
setoftheparametersθ∗ isobtainedas[36,57], steadofthestochasticdifferentialequation[Eq.(9)]fordata
SM
generation under the same objective function [Eq. (5)]. At
θ∗ ∈argmin L (θ). (6)
SM θ SM present,thisprobabilityflowODEiswellusedinsteadofthe5
stochasticdifferentialequationbecauseitispossibletogener- E. FormulationswithconditionalGaussiandistributions
atedatafasterandmoreaccuratelybyperformingtimeevolu-
tionbasedonnumericalODEsolvers[99–101].
In a practical implementation of the diffusion models, we
Specifically, using the velocity field νˆ t(x) [Eq. (7)] esti- may consider a process such that the external force f t(x) is
mated through the objective function [Eq. (5)], the velocity linear,
fieldoftheestimatedprocessν˜†(x)isarrangedasfollows.
t˜
f (x)=A x+b , (16)
t t t
ν˜†(x)=−νˆ (x). (10)
t˜ τ−t˜
to reduce the computational complexity [35, 36, 40, 42, 63],
This expression is parallel to the expression of the velocity where A t ∈ Rnd×nd and b t ∈ Rnd are the matrix and the
fieldinthereverseprocessν†(x) = −νP (x). Inthiscase, vector,respectively. WhentheinitialconditionisP t=0(x) =
t˜ τ−t˜ q(x),thesolutionP (x)fortheprocesscanbegivenby
thecontinuityequation[Eq.(4)]correspondstothefollowing t
ODE[36,61]. (cid:90)
P (x)= Pc(x|y)q(y)dy. (17)
t t
dx˜†
t˜ =−νˆ (x˜†)=−f†(x˜†)+T†sθ S∗ M† (x˜†), (11)
dt˜ τ−t˜ t˜ t˜ t˜ t˜ t˜ t˜ Here,thetransitionprobabilityPc(x|y)isaGaussiandistri-
t
butionPc(x|y)=N(x|µ (y),Σ )duetothelinearityofthe
where x˜† t˜ denotes the sample from P˜ t˜†(x). The probability externalt force[92],wheret µ t(y)it sthemean,whichdepends
flow ODE method generates data by numerically simulating ony,andΣ isthecovariancematrixΣ . WeassumethatΣ
t t t
thisODE[36]. does not depend on the state y. The equation (17) at t = 0
gives the condition Pc(x|y) = δ(x−y), where δ(x−y)
0
isthedeltafunction. Thus, thecovariancematrixatt = 0is
Example2:Flow-basedgenerativemodeling Σ =O,andthemeanisµ (y)=y,whereOisthezero
t=0 t=0
matrix.
Next, we explain the flow-based generative modeling [63] Under the above condition, the optimization problems
which consists of flow matching and data generation via the [Eqs. (5), (12)] are easier to solve [42, 63]. These train-
ODE.Flowmatching[63]isamethodtoestimatetheveloc- ing methods using conditional probability in score match-
ity field of the forward process without estimating the score ing and flow matching are known as denoising score match-
function. Inflowmatching,wemodelthevelocityfieldofthe ing[57]andconditionalflowmatching[63],respectively. To
forwardprocessνP(x)byaneuralnetworkuθ ∈Rnd where reduce the computational complexity, we consider new ob-
t t
θisthesetofparameters. Theobjectivefunction, jectivefunctions,whichcorrespondtotheobjectivefunctions
[Eqs.(5),(12)]asfollows,
L (θ)=E (cid:2) ∥uθ(x)−νP(x)∥2(cid:3) , (12)
FM Pt,U t t Lc SM(θ)=E
P
tc,q,U(cid:2) ∥sθ t(x)−∇lnP tc(x|y)∥2(cid:3) , (18)
i ms em thi on dim s,i az ned dθw ∗ith ir se ts hp eec ot pt to imθ alu ss ein tg ofn tu hm ee pr ai rc aa ml eo tp et ri sm si az ta it si fo yn
-
Lc FM(θ)=E
P
tc,q,U(cid:104) ∥uθ t(x)−ν tPc (x|y)∥2(cid:105) , (19)
FM
ing
θ F∗
M
∈argmin θL FM(θ). (13) t
aw
h
nh
e
de er νxe
p
PE
e
cP
c (t
xtc e, |dq y,U
v
)a[·
l :u
=· e·]
w
f=
it (h
x(cid:82) 0 )rτ
e
−d sptU
e
Tc(
t
∇t) to(cid:82) lnPd Ptx
c(
cd
x
(y x|yP |y)tc
,
)( .qx (|
y
Ay )) s,q pa(y
n
rod) v· eU· d(·
t
ii
)
ns
,
t t t t
Theoptimalsetoftheparametersθ F∗ Mgivesthevelocityfield Appendix A, new objective functions satisfy ∇ θLc SM(θ) =
fortheestimatedprocessν˜†(x)asfollows, ∇ θL SM(θ) and ∇ θLc FM(θ) = ∇ θL FM(θ), where ∇ θ is
t˜ the gradient through θ. Since the optimal solutions are
given by the conditions ∇ Lc (θ) = ∇ L (θ) = 0 and
ν˜ t˜†(x)=−uθ τF∗ −M t˜(x). (14) ∇ θLc FM(θ)=∇ θL FM(θ)=θ 0S ,M wegettheθ optS iM malsolutions,
Thisexpressioncorrespondstothevelocityfieldofthereverse θ∗ ∈argmin Lc (θ), (20)
SM θ SM
processν t˜†(x)=−ν τP −t˜(x). θ F∗
M
∈argmin θLc FM(θ), (21)
Intheflow-basedgenerativemodeling,thedatageneration
isdonebysimulatingtheODE[63,102], whichareequivalenttothesolutionsoftheoriginalproblems
[Eqs. (6) and (13)]. Here, the quantities ∇lnPc(x|y) and
t
dx˜† νPc(x|y) are linear functions of x because of the Gaussian
dt˜t˜ =−uθ τF∗ −M t˜(x˜† t˜), (15) prt operty,andtheconditionalprobabilityP tc(x|y)canbesam-
pledmoreeasilythanP (x)duetothereproductiveproperty
t
which is similar to that used in the probability flow ODE ofGaussiandistributions.Therefore,theseoptimizationprob-
method [Eq. (11)]. This ODE corresponds to the continuity lems [Eqs. (18) and (19)] are numerically simpler than the
equationfortheestimatedprocess[Eq.(4)]. originaloptimizationproblems[Eqs.(5)and(12)].6
F. Examplesofdiffusionmodels Example2:Optimaltransportconditionalflowmatching
Wepresentsomerepresentativeexamplesofexistingdiffu- Next,weintroducetheconditionaloptimaltransport(cond-
sionmodels[40,43,48,63]. Herewediscusstheconditional OT)scheduleusedinflowmatching. Thecond-OTschedule
Gaussianformulationsfromtheprevioussection.Weconsider is known as a noise schedule that optimizes the transport of
the temperature T and the external force f (x) as functions theconditionaldistributionPc(x|y)[63],whichisdescribed
t t t
ofnon-negativeparametersσ (≥0),m (≥0)suchthat asfollows,
t t
T t =m tσ t∂
t(cid:18)
mσ t
t(cid:19)
=∂
t(cid:18)
σ
2t2(cid:19)
−σ t2∂ tlnm t, (22) m t =1− τt ,
(28)
(cid:18) (cid:19) t
∂ lnm
f t(x)=∇ t
2
t ∥x∥2 =(∂ tlnm t)x. (23) σ t = τ.
The external force f (x) is described by the linear function This noise schedule represents the change of the parameters
t
[Eq.(16)]withA
t
= (∂ tlnm t)I,b
t
= 0,whereIistheiden- along the geodesic from (σ t,m t) = (0,1) to (σ t,m t) =
titymatrixand0isthezerovector. Thetimedependenceof (1,0) on the 2-dimensional Euclidean space of the standard
m tandσ tisalsocalledthenoiseschedule[40,43,48,63]be- deviation σ t and the mean m t. The dynamics along the
cause the diffusion dynamics can be determined by the time geodesic can be regarded as optimal transport based on the
dependence of m and σ instead of the time dependence of 2-Wasserstein distance for the conditional probability distri-
t t
T andf (x). butions[63,70].
t t
Wesometimesmakethefollowingassumptionforthenoise
schedules. TosatisfyT ≥0,themonotonycondition
t
Example3:VariancePreservingdiffusion(VP-diffusion)
(cid:18) (cid:19)
σ
∂ t ≥0, (24)
t m
t Finally, we introduce the variance preserving diffusion
isassumed. Thetermm /σ iscalledthesignal-to-noisera- (VP-diffusion) [36]. The VP-diffusion is a method based
t t
tio [41], which must be monotonically non-increasing. Fur- onthedenoisingdiffusionprobabilisticmodel(DDPM)[43].
thermore, we assume the initial conditions m = 1 and The DDPM is a diffusion model that uses the diffusion
t=0
σ = 0. Under these initial conditions, the solutions of from the input data distribution to the Gaussian distribution
t=0
themeanµ (y)andthecovariancematrixΣ inPc(x|y)are N(x|0,I). The VP-diffusion is described by the following
t t t
givenby Langevinequation[36],
µ (y)=m y, Σ =σ2I, (25) (cid:112)
t t t t dx =−T x dt+ 2T dB . (29)
t t t t t
[seeAppendixB].Forhigh-dimensionaldatasetssuchasim-
ages, we often use this assumption [36, 40, 48, 63]. In the FromEq.(2)and(23)wegetf t(x) = −T txand∂ tlnm t =
following,weshowsomeexamplesofthenoiseschedules. −T t. By substituting ∂ tlnm t = −T t for Eq. (22), we also
obtaintherelation
Example1:Varianceexplodingdiffusion(VE-diffusion) ∂ ln(cid:0) m2(cid:1) = ∂ t(σ t2) =∂ ln(cid:0) 1−σ2(cid:1) . (30)
t t σ2−1 t t
t
We first introduce the variance exploding diffusion (VE- Sincetheinitialconditionsaregivenbyσ = 0andm = 1,
0 0
diffusion) [36]. The VE-diffusion is a method based on the thecondition
noise conditional score networks (NCSN) [42], which is de-
scribedbythefollowingLangevinequation[36] m2+σ2 =1, (31)
t t
(cid:112)
dx t = 2T tdB t. (26) holds. This condition implies that m t and σ t are on the unit
This equation corresponds to the condition that there is no circle. Thus, we can consider a noise schedule that changes
externalforcef (x)=0. FromEqs.(22)and(23),weobtain the parameters along the geodesic on the unit circle from
t
∂ tlnm
t
=0and (σ t,m t)=(0,1)to(σ t,m t)=(1,0)asfollows,
T t =∂
t(cid:18) σ 2t2(cid:19)
. (27) m t
=cos(cid:18) π 2τt(cid:19)
,
(32)
Thecondition ∂ tlnm t = 0meansthatthe noisescheduleis (cid:18) π t(cid:19)
σ =sin .
given by m t = 1(0 ≤ t ≤ τ) because the initial condition t 2τ
is given by m = 1. Because of Eq. (24), σ should be a
0 t
monotonicallynon-decreasingfunctionoftime. Whileweex- Thisnoisescheduleiscalledthecosineschedule[43].
plaintheVE-diffusionintermsoftheLangevinequation,this Under the condition of the VP-diffusion (σ2 +m2 = 1),
t t
methodcanbedescribedintheimplementationastheproba- we consider the coordinate transformation to treat the diffu-
bilisticflowODE. sionprocesswithouttheexternalforce. Themethodbasedon7
(cid:82)
thecoordinatetransformationiscalledthedenoisingdiffusion whereweusedthepartialintegrationand dx∂ P (x)=0to
t t
implicit model (DDIM) [48]. The coordinate transformation derivetheexpressionS˙sys. Thus,theentropyproductionrate
t
intheDDIMisintroducedasfollows, S˙totisregardedastheentropychangerateinthetotalsystem.
t
x Itsnon-negativityS˙tot ≥ 0meansthesecondlawofthermo-
t
x¯ = . (33)
dynamics. As a measure of thermodynamic dissipation, the
m
t
entropyproductionfromtimet = 0tot = τ isalsodefined
Underthiscoordinatetransformation,theconditionsEq.(22) as
withT =−∂ lnm ,theFokker-Planckequationisgivenby
t t t (cid:90) τ
Stot = dtS˙tot. (40)
(cid:20)(cid:20) ∂ lnm (cid:21) (cid:21) τ t
∂ P¯ (x¯)=−∇ · t t∇ lnP¯ (x¯) P¯ (x¯) , (34) 0
t t x¯ (m )2 x¯ t t
t Intheoriginalpaperofthediffusionmodel[35],theideaof
(see Appendix C), where P¯ (x¯) := P (x)(|dx¯/dx|)−1, areverseprocessindiffusionmodelsmaybeinspiredbythe
t t fluctuationtheorem[8,37,38]ortheJarzynskiequality[39],
∇ := m ∇, and |dx¯/dx| is the Jacobian. Therefore, the
x¯ t which are the relations between the entropy production and
correspondingLangevinequationis
the path probabilities of the forward and backward trajecto-
(cid:115) ries. Basedonmathematicaltechniquesinthefluctuationthe-
2T
dx¯ = t dB . (35) orem such as dual dynamics [3], we introduce the following
t (m t)2 t dynamics
(cid:112)
ThisLangevinequationdescribesasituationwheretheexter- dx =f (x )dt−2νP(x )dt+ 2T dB , (41)
t t t t t t t
nalforceisabsent. IntheDDIM,wegeneratedatausingthe
probabilityflowODE[Eq.(11)][48]. whichcorrespondstotheestimatedprocessofthescore-based
generativemodeling[Eq.(9)]andisaspecialcaseofthein-
terpolateddynamics[32]forthevelocityfield−νP(x ).
t t
III. RELATIONSHIPSBETWEENSTOCHASTIC Here, we discuss two path probabilities of the path Γ =
THERMODYNAMICSANDDIFFUSIONMODELS {x ,x ,··· ,x }. Here, ∆t(> 0) is the infinitesimal
0 ∆t Nτ∆t
time interval, and thus we consider the limit ∆t → 0 with
In this section, we review stochastic thermodynam- fixed τ = N τ∆t. For the Langevin equation [Eq. (2)], the
ics (Sec. IIIA) and the relationship between stochastic ther- transition probability from the state x at time t to the state
modynamics and optimal transport theory (Sec. IIIB) from y at time t+∆t is given by the expression of the Onsager–
theperspectiveofdiffusionmodels. Machlupfunction[92]asfollows,
A. Reviewonstochasticthermodynamics
T t(y|x)=
(4πT
t1
∆t)n 2d
e−∥y−x− 4Tf tt ∆(x t)∆t∥2
. (42)
Similarly,thetransitionprobabilityfromthestatexattimet
Weintroducenonequilibriumthermodynamicsfortheover-
tothestateyattimet+∆tfortheprocess[Eq.(41)]isgiven
dampedFokker–Planckequation[Eq.(1)],namelystochastic
by
thermodynamics [3], and discuss its relation to the diffusion
m
t th
ho
e
erd
q
me ul oas dn. ytiI ntn
y
amcst
a
io
l
clc
e
dh
d
ia ss
t
sht ii
e
pc aet tnh iote
r
nr om
p
rayo td
ep
.y ron Fda om
u rc
ti htc
i
es o,
n
ow
vra
ee
t re
dm aaa msi an pl emy dec Fao osn
u
ks
r
ki ed
eo
re –r
f T t†(y|x)=
(4πT
t1
∆t)n 2d
e−∥y−x−ft(x 4)∆ Ttt ∆+ t2νtP(x)∆t∥2
. (43)
Planckequation[Eq.(1)],theentropyproductionrateS˙tot is
t Usingthetransitionprobability[Eq.(42)],wedefinethepath
definedas
probabilityfortheforwardprocessas
1 (cid:90)
S˙ ttot =
T
dx∥ν tP(x)∥2P t(x). (36) N (cid:89)τ−1
t P (Γ)=P (x ) T (x |x ), (44)
F 0 0 N∆t (N+1)∆t N∆t
Here, the Boltzmann constant k is regularized to k = 1. N=0
B B
Thisentropyproductionratecanbedecomposedintotheen- ThispathprobabilityP (Γ)isrelatedtothedistributionofthe
tropy change rate in the system S˙sys and the entropy change F
t forwardprocessP (x). Ifweconsiderthepathexcludingthe
rateintheheatbathS˙bathasfollows, t
t state {x n∆t} defined as Γ t̸=n∆t = Γ \ {x n∆t}, marginal-
izing the path probability P (Γ) gives P (x ) =
S˙ ttot =S˙ tsys+S˙ tbath, (37) (cid:82) dΓ t̸=n∆tP F(Γ). Similarly,thF epathprobabiln i∆ tyt forn t∆ ht epro-
(cid:20) (cid:90) (cid:21)
cessinEq.(41)isgivenby
S˙sys =∂ − dxP (x)lnP (x) , (38)
t t t t
S˙bath =(cid:82) dxf t(x)·ν tP(x)P t(x) , (39) P B(Γ)=P 0(x
0)N (cid:89)τ−1
T N† ∆t(x (N+1)∆t|x N∆t). (45)
t T t N=08
We remark that this path probability P is not related to the Weremarkontheanalogousconnectionbetweenthefluc-
B
reverse process or the estimated process, and marginalizing tuationtheoremandthediffusionmodeldiscussedintheorig-
the path probability P (Γ) does not yield P†(x) or P˜†(x) inal paper on diffusion models [35]. In Ref. [35], the path
becausethispathprobaB bilityP Bisnotintroduct˜ edasthett˜ ime- probabilityfortheestimatedprocessP Eisintroducedas
reversed dynamics from the probability distribution function
P 0†orP˜ 0†.
P (Γ)=P˜†(x
)N (cid:89)τ−1
TE (x |x ), (51)
Theentropyproductioncanbeinterpretedasthestatistical E 0 Nτ∆t N∆t N∆t (N+1)∆t
difference between two path probabilities P and P . If we N=0
F B
considertheKullback–LeiblerdivergencebetweenP F(Γ)and and p(x 0) is obtained from the marginalization p(x 0) =
P B(Γ)definedas (cid:82) dΓ t̸=0P E(Γ),whereT tE isthetransitionprobabilityforthe
estimated process. The expression of P is analogous to the
D KL(P F∥P B)=(cid:90) dΓP F(Γ)ln PP BF( (Γ Γ) ), (46) e ex np cere bss ei to wn eeo nf PP F′ B. anW dh Pi
′
Ble iw ne stc oo cn hs ai sd tie crE tt hh ee rmst oa dti yst ni ac mal icd si ,ff wer e-
considerthesituationwhereP statisticallymimicsP inthe
E F
weobtainthefollowingrelationbetweentheKullback-Leibler diffusionmodels.InRef.[35],thetransitionprobabilityTEis
t
divergenceandtheentropyproduction[3,22,32]
estimatedfromtheproblemofmaximizingthelowerboundK
(cid:82)
on the model log-likelihood L(q∥p) = dxq(x)lnp(x)(≥
Stot =D (P ∥P ), (47)
τ KL F B K). ThelowerboundK includesthetermsoftheKullback-
Leiblerdivergenceandthedifferentialentropy,andthederiva-
(seealsoAppendixD).
tionofKisanalogoustothederivationoftheJarzynskiequal-
Weremarkthatthereareseveralexpressionsoftheentropy
ity.ThemaximizationofKissolvedasapartialminimization
productionastheKullback-Leiblerdivergence. Forexample,
ofthetermsoftheKullback-Leiblerdivergence.
theentropyproductioncanbeformulatedastheprojectionin
As described, there are several analogous connections be-
informationgeometry,whichisaminimizationproblemofthe
tween stochastic thermodynamics and the diffusion models.
Kullback-Leibler divergence [32, 103]. In the context of the
Itmaybepossibletoapplythetechniquesofstochasticther-
fluctuation theorem, the expression based on the path proba-
modynamics to the diffusion models. In particular, inter-
bilityforthebackwardtrajectoryiswelldiscussed. Thepath
esting techniques in stochastic thermodynamics are optimal
probabilityforthebackwardtrajectoryisdefinedas
transport theoretic techniques for the minimum entropy pro-
duction problem. We next discuss the optimal transport the-
P′ (Γ)=P (x
)N (cid:89)τ−1
T (x |x ). (48) ory[25,105].
B τ Nτ∆t N∆t N∆t (N+1)∆t
N=0
WeremarkthatthispathprobabilityP′ isnotrelatedtothere- B. Optimaltransporttheoryandminimumentropy
B
production
verseprocessortheestimatedprocessbecausethispathprob-
abilityP′ usesthetransitionprobabilityT , whichisnotthe
B t
transition probability of the reverse process or the estimated In this section, we introduce the optimal transport the-
process, in the time-reversed dynamics from the initial con- ory and its application to stochastic thermodynamics. We
dition P = P†. We can also obtain the similar relation be- start with the distance in optimal transport theory, namely
τ 0
tween the Kullback-Leibler divergence and the entropy pro- the p-Wasserstein distance [25]. The p-Wasserstein distance
duction[3,32,104] W p(P,Q) between probability density functions P(x) and
(cid:82)
Q(y) satisfying P(x) ≥ 0, dxP(x) = 1, Q(y) ≥ 0 and
(cid:82)
Stot =D (P ∥P′ ), (49) dyQ(y)=1,isdefinedas
τ KL F B
(seealsoAppendixD).Weheredefinethestochasticentropy (cid:18) (cid:90) (cid:19) p1
production for the path Γ as stot(Γ) = ln[P (Γ)/P′ (Γ)]. W p(P,Q):= inf dxdy∥x−y∥pπ(x,y) .
τ F B π∈Π(P,Q)
In stochastic thermodynamics, the identity exp[stot(Γ)] =
τ (52)
P (Γ)/P′ (Γ) is known as the detailed fluctuation theo-
F B
rem [8, 37, 38]. If we introduce the expected value with re- Here Π(P,Q) is a set of joint probability density functions
spect to P F as E P F[···] = (cid:82) dΓP F(Γ)···, the entropy pro- definedas
duction satisfies S τtot = E P F[st τot]. We also can obtain the
(cid:90)
followingidentity
Π(P,Q)={π(x,y)|π(x,y)≥0, dyπ(x,y)=P(x),.
E P F[exp(cid:0) −st τot(cid:1) ]=1, (50) (cid:90)
dxπ(x,y)=Q(y)}. (53)
where we used the normalization (cid:82) dΓP′ (Γ) = 1, This for-
B
mula is known as the integral fluctuation theorem [37, 38], Ifthep-thordermomentisfinite, thep-Wassersteindistance
andaspecialcaseoftheintegralfluctuationtheoremisknown W (P,Q) remains finite. In the space of probability distri-
p
astheJarnzynskiequality[39]. bution functions which have a finite p-th order moment, the9
metricspaceaxiomsaresatisfied[25]asfollows, where the infimum is taken among all paths
(v (x),q (x)) satisfying
W (P,Q)≥0, (54) t t 0≤t≤τ
p
W p(P,Q)=0⇔P =Q, (55) ∂ tq t(x)=−∇·(v t(x)q t(x)),
W p(P,Q)=W p(Q,P), (56) q 0(x)=P 0(x), q τ(x)=P τ(x). (62)
W (P,Q)≤W (P,R)+W (R,Q), (57)
p p p
BecausetheFokker–Planckequation[Eq.(1)]isthecontinu-
where P,Q,R are probability density functions. It is also
ityequation,weobtain
known that W (P,Q) ≤ W (P,Q) for p ≤ q because of
p q
Ho¨lder’sinequality[25]. The1-Wassersteindistanceandthe (cid:90) τ (cid:90)
2-Wassersteindistancearewellusedinmachinelearningand [W 2(P 0,P τ)]2 ≤τ dt dx∥ν tP(x)∥2P t(x), (63)
stochasticthermodynamicsduetosomemathematicalproper- 0
ties. from Eq. (61). If T does not depend on t, this result can be
t
For example, the 1-Wasserstein distance has a computa- writtenas
tional advantage because it is computed from expected val-
ues. Due to the Kantorovich–Rubinstein duality [25], the 1- W (P ,P )2
Stot ≥ 2 0 τ . (64)
Wasserstein distance is given by the following maximization τ τT
problem,
where T(= T ) is the time-independent temperature. Thus,
W (P,Q)= sup (E [f]−E [f]), (58) t
1 P Q the2-Wassersteindistanceprovidestheformulaforthemini-
f∈Lip1
mumentropyproductioninafinitetimeτ underthecondition
whereLip1isthesetofscalarfunctionssatisfying1-Lipschitz thattheinitialdistributionP andthefinaldistributionP are
0 τ
continuity defined as Lip1 = {f(x) | ∥∇f(x)∥ ≤ 1}, and fixed[30].
E [f] is the expected value with respect to the probability Thisresult[Eq.(64)]canbeinterpretedfromtheperspec-
P
density function P(x) defined as E [f] = (cid:82) dxP(x)f(x). tive of the geodesic in the space of the 2-Wasserstein dis-
P
The computational complexity of the 1-Wasserstein distance tance[29,32]. Ifweconsidertheinfinitesimaltimeevolution
via the above maximization problem is relatively simple. fromttot+∆t,Eq. (61)indicates
Therefore, the 1-Wasserstein distance is well used as an ob-
jectivefunctioningenerativemodelssuchastheWasserstein [W (P ,P )]2
2 t t+∆t
generativeadversarialnetwork[64]. (cid:90) t+∆t (cid:90)
In addition, the 2-Wasserstein distance has good differen- ≤∆t dt′ dx∥νP(x)∥2P (x)
t′ t′
tial geometric properties. If P and Q are n -dimensional t
d (cid:90)
Gaussian distributions N(µ P,Σ P),N(µ Q,Σ Q), then the =(∆t)2 dx∥νP(x)∥2P (x)+O((∆t)3), (65)
2-Wasserstein distance can be computed as follows [106], t t
[106],
whereO((∆t)3)denotestheLandau’sbigOnotation. Ifwe
W (P,Q)2 =∥µ −µ ∥2
2 P Q definethespeedinthespaceofthe2-Wassersteindistanceas
(59)
+tr[Σ
P
+Σ Q−2((Σ P)1 2Σ Q(Σ P)1 2)1 2],
W (P ,P )
where tr denotes the trace of the matrix. If the variance- v 2(t)= ∆tl →im
+0
2 t ∆tt+∆t , (66)
covariancematricesaregivenbyΣ = σ2IandΣ = σ2I,
P P Q Q
Eq.(59)isrewrittenas weobtainthelowerboundoftheentropyproductionrate[29]
W (P,Q)2 =∥µ −µ ∥2+tr[(σ −σ )2I] fromEq.(65)as
2 P Q P Q
=∥µ P −µ Q∥2+(σ P −σ Q)2n d S˙tot ≥ [v 2(t)]2 . (67)
=∥µ P −µ Q∥2+∥σ P1−σ Q1∥2, (60) t T t
where 1 is the vector defined as [1] i = 1, (i = 1,...,n d). Thislowerbound[v (t)]2/T iscalledtheexcessentropypro-
2 t
In this case, the 2-Wasserstein distance is equivalent to the duction rate [31, 32, 108]. The equality S˙tot = [v (t)]2/T
distance between (µ ,σ 1) and (µ ,σ 1) in the 2n - t 2 t
P P Q Q d holdswhenthevelocityfieldisgivenbyagradientofapoten-
dimensional Euclidean space of the means and the standard
tialfunctionϕ (x)asνP(x)=T ∇ϕ (x)[29,32,109]. The
deviations. t t t t
equality condition physically means the situation where the
Next, we explain that the 2-Wasserstein distance provides
external force f (x) is given by conservative force f (x) =
t t
alowerboundonentropyproductioninstochasticthermody-
−∇U (x) with the potential U (x). For the case where the
t t
namics. We start with the following Benamou-Brenier for-
external force is given by f (x) = A x + b , the equality
t t t
mula[107],
holds if A is a symmetric matrix [110]. The equation (67)
t
(cid:115) (cid:90) τ (cid:90) canbewrittenasT tS˙ ttot ≥ [v 2(t)]2. TheupperboundT tS˙ ttot
W (P ,P )= infτ dt dx∥v (x)∥2q (x), (61) can be regarded as the instantaneous dissipative work [111]
2 τ 0 t t
0 whenweconsiderthetransitionbetweenequilibriumstates.10
IfT (= T)doesnotdependont, weobtainthefollowing integration.FromEqs.(67)and(72),weobtainthethermody-
t
hierarchyofinequalitiesfortheminimumentropyproduction namic uncertainty relation for the excess entropy production
knownasthethermodynamicspeedlimit[29], rate[31,108],
Stot
=(cid:90) τ
dtS˙tot ≥
(cid:82) 0τ dt[v 2(t)]2 S˙ ttot ≥ [v 2 T(t)]2 ≥ T[ E∂ tE P [∥t ∇[r r]] ∥2 2], (73)
τ t T t t Pt
0
whichimpliesatrade-offrelationbetweenthespeedoftheob-
L2
≥ τ servable|∂ E [r]|andthermodynamicdissipationrateS˙tot.
τT t Pt t
If we define the normalized speed of the observable r(x) as
≥ W 2(P τ0 T,P τ)2 , (68) v r(t) = |∂ tE Pt[r]|/(cid:112)E Pt[∥∇r∥2],thisinequality[Eq.(73)]
canbewrittenas
whereL = (cid:82)τ dtv (t)isthepathlengthinthespaceofthe [v (t)]2 ≥[v (t)]2. (74)
τ 0 2 2 r
2-Wassersteindistance,andweusedtheCauchy-Schwarzin-
equality[(cid:82)τ dt][(cid:82)τ dt[v (t)]2] ≥ [(cid:82)τ dtv (t)]2 andthetrian- Thus, thisexpression[Eq.(74)]impliesthatthespeedinthe
0 0 2 0 2 spaceofthe2-Wassersteindistanceistheupperboundonthe
gleinequalityL ≥ W (P ,P ). ThepathlengthL canbe
τ 2 0 τ τ speed of any time-independent observable r(x). We remark
calculatedasL τ = lim ∆t→+0(cid:80)N n=τ− 01W 2(P (n+1)∆t,P n∆t) that the inequality W 2(P t,P t+∆t) ≥ W 1(P t,P t+∆t) can be
withfixedτ = N τ∆t. IftheprobabilitydensityfunctionP t derived by substituting the 1-Lipshitz function f ∈ Lip1
evolves along the geodesic in the space of the 2-Wasserstein whichgivesthe1-Wassersteindistanceintor(x)[33].
distance,thefollowingcondition Byconsideringthefollowingmaximizationproblemofthis
lowerboundwithrespecttotheobservabler(x)
W (P ,P )
v 2(t)= 2 τ0 τ , (69)
r∗(x)∈argmax
[∂ tE Pt[r]]2
, (75)
r(x)T E [∥∇r∥2]
holds. This condition provides the equality condition of
t Pt
Eq.(68),
theoptimalobservabler∗(x)givesthespeed
|∂ E [r∗]|
(cid:82) 0τ dt[ Tv 2(t)]2 = W 2(P τ0 T,P τ)2 . (70) v 2(t)= (cid:112)E Pt t[P ∥t ∇r∗∥2], (76)
andthegradientoftheoptimalobservable∇r∗(x)ispropor-
[I vf t (h te )]2s /y Tste hm oldis s.dr Tiv he un s,b ty hea mc io nn imse urv mati ev ne trofo pr yce p, roS˙ dtt uo ct tio=
n
pti ro on pa ol rt to ionth ae lcv oe el fo fic cit iy enfi te cld =T vt∇ (tϕ )/t( (cid:112)x) E= [∥c ∇∇ rr ∗∗ ∥( 2x ]) [3w 1i ,th 10t 8h ]e
.
2 2 Pt
Stot = [W (P ,P )]2/(τT) is achieved when the system Eveniftheexternalforcef (x)isnotconservative,thereex-
τ 2 0 τ t
is driven by a conservative force and the probability density istsamethodtoestimatethevelocityfieldfromatimeseries
functionP evolvesalongthegeodesicinthespaceofthe2- dataoftheLangevindynamicsbyconsideringthemaximiza-
t
Wassersteindistance. tion problem based on the other thermodynamic uncertainty
We discuss the thermodynamic uncertainty relations [31, relation [18, 21, 23]. The method based on the thermody-
32, 108, 112] as other lower bounds on the the entropy namicuncertaintyrelationcanbeusefulforestimatingtheve-
production rate S˙tot and the excess entropy production rate locityfieldinthediffusionmodels.
t
[v (t)]2/T . Since the equality in Eq. (67) is achieved when
2 t
νP(x)=T ∇ϕ (x),thefollowingequality
t t t
IV. MAINRESULT
[v (t)]2 (cid:90)
2 =T dx∥∇ϕ (x)∥2P (x), (71)
T t t t In this section, we explain the main result of the paper.
t
Based on optimal transport theory and stochastic thermody-
holds. Thisgivesusthefollowinginequality namics, we derive an upper bound on the estimation error in
datagenerationofthediffusionmodelsbytheentropyproduc-
(cid:20)(cid:90) (cid:21)
dx∥∇ϕ (x)∥2P (x) E [∥∇r∥2] tionrate,namelythespeed-accuracytrade-offforthediffusion
t t Pt
models. Thisupperboundisderivedbasedonananalogyto
(cid:20)(cid:90) (cid:21)2 thethermodynamicspeedlimitandthethermodynamicuncer-
≥ dx[∇ϕ t(x)]·[∇r(x)]P t(x) tainty relation. Based on the upper bound, we can introduce
anoptimalprotocolfortheaccuracyofdatagenerationinthe
(cid:20) 1 (cid:90) (cid:21)2 (cid:20) 1 (cid:21)2 diffusion models given by the geodesic in the space of the
= dxr(x)∂ P (x) = ∂ E [r] , (72)
T t t T t Pt 2-Wassersteindistance. Thisprotocolisanalogoustotheop-
t t
timal protocol for minimum entropy production. We discuss
for any time-independent observable r(x), where the ex- the relationship between the optimal protocol and the noise
pected value E [r] is defined as E [r] = (cid:82) dxP (x)r(x) schedulessuchasthecond-OTscheduleandthecosinesched-
Pt Pt t
and we used the Cauchy-Schwarz inequality, the continuity ule,andwenumericallyillustratethemainresultinthesimple
equation∂ P (x)=−∇·(T [∇ϕ (x)]P (x))andthepartial 1-dimensionaldiffusionmodel.
t t t t t11
A. Speed-accuracytrade-offforthediffusionmodels Forward process / Reverse process
Diffusion speed cost
We explain the main result of the paper. If the veloc-
ity field of the forward process is accurately reconstructed
(νˆ (x) = νP(x)) in the probability flow ODE or the flow-
t t
based generative modeling, we can derive the following in-
equality Difference in
1-Wasserstein Estimated process
1(∆W )2 (cid:90) τ distance
1 ≤ dtT S˙tot, (77)
τ D t t Speed-accuracy trade-off
0 0
for the diffusion models
which is a relation between the thermodynamic quantity and
the estimation error in data generation. The right-hand side
of this inequality is given by thermodynamic quantities such
as the entropy production rate S˙tot and temperature T , and FIG.2. Illustrationofthespeed-accuracytrade-offforthediffusion
t t
thesethermodynamicquantitiesarecalculatedintheforward models. We evaluate the difference between the initial conditions
process. Thequantitiesontheleft-handsideofthisinequality ofthereverseprocessP 0† andtheestimatedprocessP˜ 0† bythePer-
son’s χ2-divergence D , and the estimation error of the generated
are given by the difference between the reverse process and 0
databythechangeofthe1-Wassersteindistance∆W . Thespeed-
the estimated process. The quantity D is the Pearson’s χ2- 1
0 accuracytrade-offforthediffusionmodelsimpliesthatthediffusion
divergence[113]definedas speedcost(cid:82)τdt[v (t)]2 measuredbythe2-Wassersteindistancein
0 2
theforwardprocessaffectstheaccuracyofthegenerateddatagiven
D
:=(cid:90) dx(P˜ 0†(x)−P 0†(x))2
, (78)
bytheresponsefunction(∆W 1)2/D 0.
0 P†(x)
0
whichquantifiesthedifferencebetweentheinitialconditions
by the 2-Wasserstein distance v (t) in the forward process.
o atf tt ˜h =ere 0v .er Ts he ip sr Poc ee as rss oP n0 ’† s(x χ) 2a dn id veth rge ee ns ct eim isat te hd ep fro -dc ie vs es rP g˜ e0† n( cx e)
,
This quantity (cid:82) 0τ dt[v 2(t)]2 is a2 purely information-theoretic
quantity which is considered as the diffusion speed cost in
which becomes the Fisher information when the difference
the forward process [see also Fig 2]. As a trade-off relation
P˜†(x) − P†(x) is sufficiently small [83]. The quantity
0 0 betweenthediffusionspeedcostandtheaccuracyofthedif-
∆W 1 := W 1(q,p) − W 1(P 0†,P˜ 0†) is the change of the 1- fusion model, this result is called the speed-accuracy trade-
Wassersteindistancebetweenreverseandestimatedprocesses off for the diffusion models which is the main result in the
fromtimet˜=0tot˜=τ.Ingenerativemodels,wesometimes
paper. Accordingtothisresult[Eq.(79)],theresponsefunc-
considertheestimationerrorusingthe1-Wassersteindistance tion (∆W )2/D becomes larger as the diffusion speed cost
1 0
W tia1 l( cq o, np d) itf ioo nr m sao tid se fyl ie nv gal Wuat (io Pn †,[6 P˜6 †] ). ≈If 0w ,e ∆c Wons bid ee cr omth ee si tn hi e- (cid:82) o0 fτ td ht e[v g2 e( nt e)] r2 ateb dec do am taes cal nar dg ee cr. reaIn seo ath se tr hew do ir fd fus, sit oh ne sa pc ec eu dra ic ny
-
1 0 0 1
estimationerror∆W ≈ W (q,p). Therefore, (∆W )2/D creases in the forward process. Since we usually consider a
1 1 1 0
is considered as a response function, which quantifies how conservative force in the implementations of the flow-based
much the perturbation of the initial distribution D for the generativemodelingandtheprobabilityflowODE,thisresult
0
estimated process at t˜ = 0 affects the estimation error of withoutanexplicitexpressionbythermodynamicdissipation
the generated data ∆W at t˜ = τ [see also Fig 2]. If the maybemoreusefulandintuitiveratherthanthegeneralresult
1
response function (∆W )2/D is smaller, the accuracy of [Eq.(77)].
1 0
generated data is better regardless of initial condition devia-
tions. Thus, (∆W )2/D means the robustness of the dif-
1 0
fusion models against the change of the initial distribution
P˜†(x). Our result shows that the thermodynamic quantities
0
Accordingtothespeed-accuracytrade-offforthediffusion
corresponding to the thermodynamic dissipation in the for-
wardprocess(cid:82)τ dtT S˙totgivetheupperboundontherobust- models[Eq.(79)], wecanconsiderminimizingthediffusion
0 t t speedcost(cid:82)τ dt[v (t)]2 toincreasetheaccuracyofdatagen-
nessofthediffusionmodels(∆W 1)2/D 0. 0 2
eration, which is quantified by the smallness of the response
In particular, when the external force is conservative and
function (∆W )2/D . Therefore, minimizing the diffusion
thus the velocity field of the forward process is given by the speedcost(cid:82)τ d1 t[v (t0 )]2 canimprovetheperformanceofthe
gradientofapotential(ν tP(x)=T t∇ϕ t(x)),wealsoobtain diffusionmo0
del.
W2
hentheinitialstateP ,thefinalstateP ,
0 τ
1(∆W )2 (cid:90) τ and the time duration τ are fixed, the minimization problem
τ
D1 ≤ dt[v 2(t)]2, (79) can be discussed based on the geodesic in the 2-Wasserstein
0 0 metric space. We discuss this minimization problem of the
fromtheequalityconditionofEq.(67).Theright-handsideof diffusionspeedcostinSec.IVC.
thisinequality(cid:82)τ dt[v (t)]2,whichcorrespondstotheexcess As an instantaneous expression of the speed-accuracy
0 2
entropyproduction,isgivenbythediffusionspeedmeasured trade-off for the diffusion models, the following detailed in-12
equalitycanbederived, δP (x)disappearsatinfinity. FromtheCauchy–Schwarzin-
t
equalityandthe1-Lipshitzcontinuity∥∇ψ(x)∥ ≤ 1,weob-
[∂ tW 1(P τ† −t,P˜ τ† −t)]2
≤T S˙tot. (80)
tain
D t t
0 (cid:0) ∂ (cid:0)E [ψ]−E [ψ](cid:1)(cid:1)2
When the external force is conservative, T tS˙ ttot = [v 2(t)]2
t (cid:18)(cid:90)Pt P˜
t (cid:19)2
holdsandthisinequalityindicatesthatthespeedinthespace = dx∇ψ(x)·νP(x)δP (x)
t t
ofthe2-Wassersteindistancev (t)istheupperboundonthe
2
change rate of the no √rmalized estimation error v loss(t) :=
≤(cid:18)(cid:90)
dx∥νP(x)∥2P
(x)(cid:19)(cid:18)(cid:90)
dx∥∇ψ(x)∥2(δP
t(x))2(cid:19)
|∂ tW 1(P τ† −t,P˜ τ† −t)|/ D 0asfollows, t t P t(x)
(cid:18)(cid:90) (cid:19)(cid:18)(cid:90)
(δP
(x))2(cid:19)
[v 2(t)]2 ≥[v loss(t)]2. (81) ≤ dx∥ν tP(x)∥2P t(x) dx Pt
(x)
t
This inequality is analogous to the thermodynamic uncer- =T S˙totD , (86)
t t τ−t
tainty relation [Eq. (74)]. Using v (t), we also obtain the
loss
hierarchy of inequalities corresponding to the speed-accracy whereD isthePearson’sχ2-divergenceattimet˜=τ −t
τ−t
trade-offforthediffusionmodelasfollows, defined as D := (cid:82) dx[P† (x) − P˜† (x)]2/P† (x).
τ−t τ−t τ−t τ−t
WecanshowthatthetimederivativeofD is∂ D = 0
(∆W )2 (cid:90) τ (cid:90) τ τ−t t τ−t
τD1 ≤ dt[v loss(t)]2 ≤ dt[v 2(t)]2, (82) (seeAppendixE).Therefore,D τ−t = D 0 (= const.)holds,
0 0 0 andweobtaintheinequality
whichisanalogoustothethermodynamicspeedlimit. (cid:113)
(cid:12) (cid:12)∂ t(cid:0)E Pt[ψ]−E
P˜
t[ψ](cid:1)(cid:12) (cid:12)≤ T tS˙ ttotD 0, (87)
B. Proofsofthemainresult forany1-Lipshitzfunctionψ ∈ Lip1. Wenowimplicitlyas-
sumetheexistenceof∂ W (P† ,P˜† ), whichcanbejus-
t 1 τ−t τ−t
We show here the derivation of the main result. We start tifiedbythesmoothnessofW (P† ,P˜† )asafunctionof
1 τ−t τ−t
withthederivationofEq.(80). Forthesakeofsimplicity,we t. Inthecaseof∂ W (P† ,P˜† )≥0,weobtainthelower
introduceanotationfortheprobabilitydensityfunctionofthe (cid:113) t 1 τ−t τ−t
estimated process P˜ t(x) := P˜ τ† −t(x) according to the time boundon T tS˙ ttotD 0asfollows,
direction of the forward process. Based on the Kantrovich-
Rubinsteinduality,the1-Wassersteindistanceisgivenby 0≤∂ W (P† ,P˜† )
t 1 τ−t τ−t
W 1(P τ† −t,P˜ τ† −t)=W 1(P t,P˜ t)=E Pt[ψ t∗]−E P˜ t[ψ t∗ (],
83)
= ∆tl →im +0W 1(P t,P˜ t)−W ∆1 t(P t−∆t,P˜ t−∆t)
(cid:34)E [ψ∗]−E [ψ∗]−E [ψ∗]+E [ψ∗](cid:35)
whereψ t∗ = a fr ∈g Lm ipa 1x(cid:0)E Pt[f]−E
P˜
t[f](cid:1) istheoptimalsolu- ≤ ∆tl →im
+0
Pt t P˜ t t ∆P tt−∆t t P˜ t−∆t t
t ti ho an to thf ethe vem loa cx ii tm yi fiza et li don op fr to hb ele fm or[ wE aq r. d(5 p8 r) o] c. eS si snc ie sw ace ca us rs au tm elye =∂ t(cid:0)E Pt[ψ s∗]−E P˜ t[ψ s∗](cid:1)(cid:12) (cid:12)
s=t
≤(cid:113) T tS˙ ttotD 0, (88)
reconstructed (νˆ (x) = νP(x)), the continuity equations
for the reverse pt rocess andt the estimated process [Eqs. (3) where we used the fact that W 1(P t−∆t,P˜ t−∆t) =
and (4)] are given by ∂ tP t(x) = −∇·(cid:0) ν tP(x)P t(x)(cid:1) and E Pt−∆t[ψ t∗ −∆t]−E P˜ t−∆t[ψ t∗ −∆t]≥E Pt−∆t[ψ t∗]−E P˜ t−∆t[ψ t∗]
(cid:16) (cid:17) holds because of the definition of the 1-Wasserstein dis-
∂ P˜ (x) = −∇· νP(x)P˜ (x) . Therefore, the time evo-
t t t t tance, and we used the fact that Eq. (86) holds for any t-
lutionofthedifferencebetweentwoprobabilitydensityfunc- independent 1-Lipshitz function ψ∗ ∈ Lip1. In the case
tionsδP t(x):=P t(x)−P˜ t(x)isgivenby of ∂ W (P† ,P˜† ) ≤ 0, we obs tain the lower bound on
t 1 τ−t τ−t
(cid:113)
∂ tδP t(x)=−∇·(cid:0) ν tP(x)δP t(x)(cid:1) . (84) T tS˙ ttotD 0similarlyasfollows,
UsingEq.(84),weobtain
0≤−∂ W (P† ,P˜† )
t 1 τ−t τ−t
(cid:90)
∂ t(cid:0)E Pt[ψ]−E P˜ t[ψ](cid:1) = dxψ(x)∂ tδP t(x) = ∆tl →im +0W 1(P t,P˜ t)−W ∆1 t(P t+∆t,P˜ t+∆t)
(cid:90)
(cid:113)
= dx∇ψ(x)·ν tP(x)δP t(x), ≤−∂ t(cid:0)E Pt[ψ s∗]−E P˜ t[ψ s∗](cid:1)(cid:12) (cid:12)
s=t
≤ T tS˙ ttotD 0, (89)
(85)
where we used the inequality W (P ,P˜ ) =
1 t+∆t t+∆t
for any time-independent 1-Lipshitz function ψ ∈ Lip1, E Pt+∆t[ψ t∗ +∆t]−E P˜ t+∆t[ψ t∗ +∆t]≥E Pt+∆t[ψ t∗]−E P˜ t+∆t[ψ t∗]
where we used the partial integration and we assumed that andEq.(86). Bysquaringbothsidesoftheinequalities(88)13
and(89),theresultinginequalitiesareequivalenttoEq.(80).
Thus,ourmainresultEq.(80)isprovedregardlessofthesign Cosine schedule
Forward
of∂ tW 1(P τ† −t,P˜ τ† −t). process
We next derive Eq. (77). By integrating Eq. (80) with re-
Estimated
spect to time and applying the Cauchy-Schwartz inequality, process
weobtain
Cond-OT schedule
(cid:90) τ 1 (cid:90) τ Forward
dtT S˙tot ≥ dt[∂ W (P ,P˜ )]2 process
t t D t 1 t t
0 0 0 Estimated
1 (cid:18)(cid:90) τ (cid:19)2 process
≥ dt∂ W (P ,P˜ )
τD t 1 t t Optimal transport
0 0
Forward
=
(∆W 1)2
, (90)
process
τD
0 Estimated
process
which is equivalent to Eq. (77). When the external force
is conservative, Eq. (90) can be written as Eq. (82) because
√
T S˙tot =[v (t)]2andv (t)=|∂ W (P† ,P˜† )|/ D .
t t 2 loss t 1 τ−t τ−t 0
FIG.3. Examplesoftheforwardprocessandtheestimatedprocess
accordingtothreenoiseschedules: thecosineschedule[Eq.(32)],
C. Optimalityinthenoiseschedule the cond-OT schedule [Eq. (28)], and the optimal transport which
gives the dynamics along the geodesic in the space of the 2-
We discuss the diffusion speed cost (cid:82)τ dt[v (t)]2, which Wassersteindistance.Thesefiguresshowthetimeevolutionofsam-
0 2 plesfroma2-dimensionalSwissrolldataset(n d = 2)intheflow-
is the upper bound on the response function in the speed- basedgenerativemodeling. Comparedwiththecosinescheduleand
accuracy trade-off for the diffusion models [Eq. (79)]. Low- thecond-OTschedule,thenoiseinthegeneratedfigureisrelatively
ering this upper bound means making the response function smallwhenweconsidertheoptimaltransport. Thisresultisconsis-
(∆W )2/D small, and this lowering leads to robust data tentwiththeoptimalitybasedonthespeed-accuracytrade-offforthe
1 0
generation against perturbations of the initial distribution in diffusionmodels.
theestimatedprocess. Sincethediffusionspeedcostdepends
onlyonthedynamicsoftheforwardprocess,itispossibleto
givenasymptoticallybytheconditionalkineticenergyE [69]
discussanoptimalityofthenoiseschedulesbasedonthedif- √ c
inthelimitN/ n →0,
fusion speed cost. Similar to the discussion of the minimum d
entropy production [Eq. (68)], the lower bound of the diffu-
(cid:90) τ
sionspeedcostisgivenby dt[v (t)]2 ≃τn E , (92)
2 d c
0
(cid:90) τ L2 (W (P ,P ))2
dt[v 2(t)]2 ≥ ττ ≥ 2 τ0 τ . (91) wherethedimensionofthedatan dissufficientlylargeagainst
0 the number of data N [Theorem 4.2 in Ref. [69]]. Here,
the conditional kinetic energy E for the conditional Gaus-
Theequalityconditionisv (t) = W (P ,P )/τ thatmakes c
2 2 0 τ sian probabilities are given by E = (1/τ)(cid:82)τ dt[(∂ σ )2 +
the time evolution of P t be driven along the geodesic in the c 0 t t
spaceofthe2-Wassersteindistance. Thistimeevolutioncan (∂ tm t)2] [69]. Thus, if the data dimension is sufficiently
be discussed in terms of the optimal transport protocol dis- larger than the number of data, the optimality based on
cussed in Ref. [107]. At least from the perspective of the the speed-accuracy trade-off for the diffusion model can be
speed-accuracytrade-offforthediffusionmodels,anoptimal discussed by considering the minimization of this quantity
noisescheduleisintroducedbyconsideringtheoptimaltrans- n d(cid:82) 0τ dt[(∂ tσ t)2 +(∂ tm t)2] instead of the minimization of
port which makes the time evolution of P
t
driven along the thediffusionspeedcost(cid:82) 0τ dt[v 2(t)]2.
geodesicinthespaceofthe2-Wassersteindistance. Weillus- We explain that minimizing n (cid:82)τ dt[(∂ σ )2 + (∂ m )2]
d 0 t t t t
trate the example of an optimal noise schedule given by the leadstothecond-OTschedule[Eq.(28)]andthecosinesched-
optimal transport compared to other noise schedules such as ule[Eq.(32)]. Whenσ andm areunconstrained,weobtain
t t
thecosinescheduleandthecond-OTschedule(seeFig.3). anlowerbound
While optimal transport can lead to accurate data genera-
(cid:90) τ
tion, it is computationally difficult to construct the diffusion n dt[(∂ σ )2+(∂ m )2]
d t t t t
process that achieves optimal transport in high-dimensional
0
data. Therefore,thecond-OTschedule,whichcanbeconsid- (σ −σ )2+(m −m )2
eredasanapproximateoptimaltransport,isproposed. Ifthe ≥n d 0 τ τ 0 τ , (93)
inputdistributionq(x)isnormalizedsuchthatE [x]=0and
q
E [∥x∥2] = n , and the external force and the temperature from the Cauchy-Schwarz inequality. The equality condi-
q d
are given by Eqs. (22) and (23), the diffusion speed cost is tionsofthisinequalityare∂ σ = (σ −σ )/τ and∂ m =
t t τ 0 t t14
(m −m )/τ,whichcanberegardedasthecond-OTsched- schedule,thecond-OTscheduleandtheoptimaltransport.We
τ 0
ule [Eq. (28)]. Under the constraint of the VP-diffusion, remarkthatthecosineandcond-OTschedulesarenotconsid-
σ2 + m2 = 1, we can introduce the angle θ which satis- eredtheoptimaltransportbecausewenowconsiderthesitu-
t t t √
fies (m ,σ ) = (cosθ ,sinθ ). From the Cauchy-Schwarz ationwhereN/ n isnotsufficientlysmall. Theinitialcon-
t t t t d
inequality,wealsoobtainanotherlowerbound ditionintheestimatedprocessP†(x)isfixedtotheGaussian
0
distributionN(x|1,1)whilethefinalstateintheforwardpro-
(cid:90) τ (cid:90) τ
n dt[(∂ σ )2+(∂ m )2]=n dt[(∂ θ )2] cessisgivenbytheGaussiandistributionN(x|0,1). InAp-
d t t t t d t t
0 0 pendix F, we also show the cases of other initial conditions
≥n
(θ 0−θ τ)2
. (94)
P 0†(x) (see also Fig. 5). In Fig. 4(a), the probability density
d τ functionsintheforwardprocesswiththecosinescheduleand
thecond-OTschedulearesignificantlychangedbetweentime
The equality condition of this inequality is ∂ tθ t = (θ τ − t = 0 and t = (1/3)τ compared to the optimal transport.
θ )/τ, which can be regarded as the cosine schedule
0 Thus, the data structure corresponding to the two peaks of
[Eq. (32)]. The cond-OT schedule or the cosine schedule
the probability density function is not well recovered in the
areconsideredpracticalsuboptimalprotocolsintermsofthe
estimatedprocesswiththecosineandcond-OTschedulesbe-
speed-accuracytrade-offforthediffusionmodelwhenthedi- tweent=(1/3)τ andt=τ whilethetwopeakscanbeseen
mension of the data is sufficiently larger than the number of betweent = (1/3)τ andt = (2/3)τ intheestimatedprocess
data.
withtheoptimaltransport.
D. Numericalexperiments Next, we numerically confirm the speed-accuracy trade-
off for the diffusion models [Eqs. (79) and (82)] and the de-
Finally, we illustrate the validity of the speed-accuracy tailedinequality[Eq.(80)]holdunderthevariousconditions
trade-offforthediffusionmodelsbysimplenumericalexper- of P†(x) in Fig. 4(b)-(e): (b) a Gaussian distribution with
0
iments. We consider the 1-dimensional flow-based genera- differentmean,(c)aGaussiandistributionwithdifferentvari-
tivemodeling(x ∈ R). Wenowconsiderthesituationwhere ance, (d) a Gaussian mixture distribution and (e) a uniform
the velocity field of the forward process is accurately recon- distribution. Here, we used the notation η ≤ c ≤ c for
1 2
structed and q(x) is given by the Gaussian mixture distribu- Eq. (82), where η = (∆W )2/D , c = (cid:82)τ dt[v (t)]2
1 0 1 0 loss
tion andc = (cid:82)τ dt[v (t)]2. Weconfirmthatthespeed-accuracy
2 0 2
1 1 trade-off for the diffusion models are valid under all condi-
q(x)= N(x|ma,σ2)+ N(x|mb,σ2). (95) tions. WealsoobservethattheboundsinEq.(80)aretighter
2 2
in the case of optimal transport (OT) than the bounds in the
Here,N(x|m,σ2)isthe1-dimensionalGaussiandistribution cases of cosine and cond-OT schedules. There is a tendency
with the mean m and the variance σ2. The velocity field fortheboundinthedetailedinequality[Eq.(80)]tobecome
νP(x)(∈ R) can be calculated analytically as follows (see loose during the time evolution for the cosine schedule, and
t
AppendixFforthedetailofthenumericalcalculation), theboundinthedetailedinequality[Eq.(80)]tobecomeloose
at the beginning and at the end of the time evolution for the
(cid:18) (cid:19)
νP(x)= ∂ tσ tx− m t ∂ tσ t − ∂ tm t E [y], cond-OT schedule. Interestingly, while the upper bounds of
t σ t P t(x) σ t m t P tc,q theresponsefunctionη,namelyc 1 andc 2,aretighterforthe
(96) optimaltransportcomparedtothecosineandcond-OTsched-
ules,thevalueoftheresponsefunctionηitselfisequallysmall
1σ2m x+σ2ma1 1σ2m x+σ2mb1
E [y]= t t Na+ t t Nb, forallschedules.Infact,theprobabilitydensityfunctionscor-
P tc,q 2 σ t2+σ2m2
t
2 σ t2+σ2m2
t respondingtothegenerateddatap(x)inFig. 4(a)arenotsig-
(97)
nificantlydifferentunderdifferentconditions. Therefore,our
discussion based on the speed-accuracy trade-off for the dif-
where Na and Nb are the Gaussian distributions defined as
fusionmodelsmaynotbesufficienttoexplainwhythecosine
Nx = N (cid:0) x|m mx,σ2+σ2m2(cid:1) (x = a,b). We set the √
t t √ t and cond-OT schedules work well even when N/ n d is not
parameters ma = −mb = 0.35 and σ = 0.3. We now sufficientlysmall. However, sinceη isindeedapproximately
consider the several perturbations of the initial condition in equaltoc fortheoptimaltransport,thevalueofη itselfcan
1
the estimated process P˜†(x) at t˜= 0 (see also Appendix F beconsideredtobedeterminedbythespeed-accuracytrade-
0
forthedetail). Wenumericallycalculatethequantitiesinthe offforthediffusionmodels. Thereasonwhyη isnotsignifi-
speed-accuracy trade-off for the diffusion models [Eqs. (79) cantlydifferentunderdifferentconditionsmaybethatthedata
and(82)]anditsdifferentialform[Eq.(80)]inFig. 4. structureofthe1-dimensionalGaussianmixtureistoosimple.
We discuss the interpretations of the numerical results in Ifthedatastructureismorecomplex, thedifferenceinη be-
Fig.4. InFig.4(a),weshowthetimeevolutionoftheproba- tweenthevariousnoiseschedulesmayoccur. Differencesin
bilitydensityfunctionsintheforwardprocessP (x)andthe ηbetweendifferentnoiseschedulesmayalsooccurbyreduc-
t
time evolution of the probability density functions in the es- ingthetimedurationτ andallowingforrapidchangesintime
timatedprocessP˜ (x)withthreenoiseschedules: thecosine evolutionintheforwardprocess.
t15
(a) (b)Gaussian distribution 0.5(a.u.) (c)Gaussian distribution 0.5(a.u.)
Cosine schedule with different mean 0.4 Cond-OT with different variance 0.4 Cond-OT
Forward process
0.3 0.3
Cosine Cosine
0.2 OT 0.2 OT
0.1 0.1
Estimated process
0.0 0.0
Cosine Cond-OT OT Cosine Cond-OT OT
(a.u.) (a.u.)
Cond-OT schedule
Forward process
Estimated process
(d)Gaussian mixture 0.5(a.u.) (e)Uniform distribution 0.5(a.u.)
distribution Cond-OT Cond-OT
0.4 0.4
0.3 0.3
Cosine Cosine
0.2 OT 0.2 OT
Optimal transport (OT)
Forward process 0.1 0.1
0.0 0.0
Cosine Cond-OT OT Cosine Cond-OT OT
(a.u.) (a.u.)
Estimated process
FIG.4. Numericalcalculationsofthespeed-accuracytrade-offforthediffusionmodels[Eqs.(79), (80)and(82)]. (a)Thetimeevolution
of the probability density functions in the forward process and the estimated process with the cosine schedule, the cond-OT schedule and
theoptimaltransport(OT).Heretdenotestimeintheforwarddirection,andweshowtheprobabilitydensityfunctionsatt = 0,t = τ/3,
t = 2τ/3andt = τ. ThefinalstateoftheforwardprocessisP (x) = N(x|0,1). WeusedaGaussiandistributionwithdifferentmean
τ
P˜†(x)=N(x|1,1)astheinitialconditionoftheestimatedprocess. (b-e)Weshowthesituationwheretheinitialconditionoftheestimated
0
processP˜†(x)is(b)aGaussiandistributionwithdifferentmean,(c)aGaussiandistributionwithdifferentvariance,(d)aGaussianmixture
0
distribution,(e)auniformdistribution.TheplotatthetopleftofeachsectionshowsthecomparisonbetweenP˜†(x)andP (x)=N(x|0,1),
0 τ
whereN(x|0,1)isshowningrey. Inthetopright-handsection,weshowthebargraphwhichdisplaysthequantitiesη =(∆W )2/(τD ),
1 0
c =(cid:82)τdt[v (t)]2,c =(cid:82)τdt[v (t)]2,andthisfigureshowsthevalidityoftheinequalityη≤c ≤c [Eq. (82)].Inthebottomrowwe
l 0 loss 2 0 2 1 2
showthetimeevolutionof[v (t)]2and[v (t)]2,andthisfigureshowsthevalidityoftheinequality[v (t)]2 ≥[v (t)]2[Eq.(80)]. Since
2 loss 2 loss
[v (t)]2andc dependonlyontheforwardprocess,thesevaluesareconsistentwithindifferentinitialconditionsin(b)-(e).SeealsoTableIin
2 2
AppendixFformoredetailedexplanations,includingtheprobabilitydensityfunctionP˜†(x)usedin(b)-(e).
0
V. DISCUSSIONS considers thermodynamic limits on the speed of the observ-
able in a stochastic process, the speed-accuracy trade-off for
thediffusionmodelisconceptuallydifferentbecauseitgives
In this paper, we summarize the relationship between dif-
alimitonhowthedifferencebetweentwodifferentprocesses,
fusion models and nonequilibrium thermodynamics, and de-
theforwardprocessandtheestimatedprocess,changes. This
rive the speed-accuracy trade-off for diffusion models based
resultisduetotheerror-freeestimationofthevelocityfieldin
on techniques from stochastic thermodynamics and optimal
theforwardprocessanditsuseintheestimatedprocess.Ifthe
transport theory. The speed-accuracy trade-off for diffusion
velocityfieldestimationisincomplete,thencorrectionstothe
modelsexplainsthattherobustnessofdatagenerationtoper-
speed-accuracy trade-off for the diffusion model would have
turbations is generally limited by the thermodynamic dissi-
tobemadeduetotheincompleteness. Eveninthecaseofin-
pation in the forward diffusion process. The speed-accuracy
completeestimation,itisanopenquestionwhetherusingthe
trade-offfordiffusionmodelsalsoquantitativelyexplainsthe
dynamics of optimal transport as the forward process is best
validity of using the cosine and cond-OT schedules as the
intermsofrobustnessofdatageneration.
noiseschedulesinthediffusionmodelandtheimportanceof
usingoptimaltransportintheforwarddiffusionprocess.
We believe that in this paper we have demonstrated only
Inthispaper,wederivethespeed-accuracytrade-offforthe one aspect of the usefulness of the analogy between diffu-
diffusion models as analogs of the thermodynamic trade-off sionmodelsandstochasticthermodynamics. Webelievethat
relationssuchasthethermodynamicuncertaintyrelation[108, theconventionalthermodynamicuncertaintyrelations[21,24,
112, 114] and the thermodynamic speed limit [29, 30]. Un- 108, 112, 114] are also useful because we can consider the
liketheconventionalthermodynamictrade-offrelation,which speedofanyobservableintheforwardprocess,forexample,16
thespeedofdatastructurebreakageinthediffusionprocess. timationonthegenerativedata.Thus,thesestudiesarefunda-
It is also noteworthy that the short-time thermodynamic un- mentally different from our approach, which assumes an ac-
certaintyrelationisusedtoestimatethetime-varyingvelocity curateestimationofthevelocityfieldandevaluatestheeffect
field [21, 23], which is important in the flow-based genera- oftheperturbationontheinitialstateoftheestimatedprocess
tive modeling, and it is worth considering whether there are and the noise schedules. In other words, the speed-accuracy
anyaspectsinwhichsuchathermodynamic-basedmethodis trade-offforthediffusionmodelscanbethoughtofasabound
superiortoconventionalflowmatchingmethods. thatevaluatesstructure-basedpropertiesofthediffusionmod-
Itisalsointerestingtoreconsiderthepathprobabilitybased elsthatareindependentoftheestimationmethod.
method as discussed in the original paper on the diffusion Whiletherehavebeenmanynumericalattemptstoinvesti-
modelfromathermodynamicpointofview. Thisisbecause gatetheeffectofnoiseschedulesonthequalityofdatagenera-
themethoddiscussedintheoriginalpapercanhandlenotonly tion[43,63,73,97,124],therearealmostnotheoreticalstud-
thesimplediffusionprocessesdescribedbytheLangevinand ies that investigate their effect on the estimation error based
Fokker-Planckequations,butalsothediffusionprocessonthe on the universal upper bound. The speed-accuracy trade-off
graph described by the Markov jump processes, which may for the diffusion models derived in this study may provide
provide a scalable method than the current one. In such a insight into how to determine this noise schedule for accu-
case,thethermodynamictrade-offrelationsandoptimaltrans- ratedatageneration. Infact,wehaveshownthattheexisting
port for the Markov jump process [115–118] may be useful methods,suchasthecosineandcond-OTschedules,aresub-
to consider the optimality of the diffusion model. In such optimal from the perspective of the speed-accuracy trade-off
a case, analogies to an information geometric structure of forthediffusionmodels. Thus,thesemethodshaveroomfor
the Kullback-Leibler divergence in stochastic thermodynam- improvement,andtheroomforimprovementcanbediscussed
ics[32,103,118]mayalsobeimportant,sincethelossfunc- quantitativelybasedonthetightnessoftheinequalities.
tionisintroducedbytheKullback-Leiblerdivergenceandits Our conclusion for the noise schedule is also justified in
minimizationismathematicallywelldiscussedastheprojec- light of recent developments in the diffusion model. In our
tiontheoremininformationgeometry[83]. Infact, thereare conclusion, the optimal forward process for the data genera-
severalstochasticmethodsbasedontheSchro¨dingerbridgein tion should be given by the geodesic in the space of the 2-
thediffusionmodel[50,71,119,120],whichisgivenbythe Wasserstein distance. In recent years, several methods have
minimizationoftheKullback-Leiblerdivergence. Wemaybe beenproposedtorealizethedynamicsalongthegeodesicap-
able to obtain some trade-off relations for such a system by proximately in the flow-based generative modeling and the
considering an analogy to stochastic thermodynamics based probability flow ODE [68–70, 72, 125], which is becoming
onpathprobability. themainstreammethods.
We explain how the speed-accuracy trade-off for the dif-
fusion models can be positioned within the existing evalua-
tion of diffusion models. The speed-accuracy trade-off for ACKNOWLEDGMENTS
the diffusion models gives the upper bound on the estima-
tion error using the 1-Wasserstein distance. Several studies S.I. thanks Sachinori Watanabe for discussions on the
areknowntoprovideboundsontheestimationerror,suchas diffusion models. S.I. is supported by JSPS KAKENHI
theKullback-Leiblerdivergence[121],thetotalvariationdis- Grants No. 21H01560, No. 22H01141, No. 23H00467, and
tance[122,123],andtheWassersteindistance[65–67].These No. 24H00834, JST ERATO Grant No. JPMJER2302, and
studiesmainlyfocusonevaluatingtheeffectofincompletees- UTEC-UTokyoFSIResearchGrantProgram.
AppendixA:Derivationoftherelationsbetweenthetwogradientsoftheobjectivefunctions
We show ∇ Lc (θ) = ∇ L (θ) for solving the optimization problem by score matching, and that ∇ Lc (θ) =
θ SM θ SM θ FM
∇ L (θ)issatisfiedforsolvingtheoptimizationproblembyflowmatching.
θ FM
a. ScoreMatching
Weshowthattwoobjectivefunctions
L (θ)=E (cid:2) ∥sθ(x)−∇lnP (x)∥2(cid:3) , (A1)
SM Pt,U t t
and
Lc SM(θ)=E
P
tc,q,U(cid:2) ∥sθ t(x)−∇lnP tc(x|y)∥2(cid:3) , (A2)17
givethesamegradientfortheparameterθ. Thegradient∇ Lc (θ)canbecalculatedasfollows,
θ SM
2 (cid:90) τ (cid:90) (cid:90) (cid:18) ∇Pc(x|y)(cid:19)
∇ Lc (θ)= dt dx dyPc(x|y)q(y)[∇ sθ(x)]· sθ(x)− t
θ SM τ t θ t t Pc(x|y)
0 t
2 (cid:90) τ (cid:90) (cid:18) ∇P (x)(cid:19)
= dt dxP (x)[∇ sθ(x)]· sθ(x)− t
τ t θ t t P (x)
0 t
=∇ L (θ), (A3)
θ SM
which means that ∇ Lc (θ) coincides with ∇ L (θ). Here, we used (cid:82) dyPc(x|y)q(y) = P (x) and q(y)∇Pc(x|y) =
θ SM θ SM t t t
∇[Pc(x|y)q(y)].
t
b. FlowMatching
Similarly,inflowmatching,weshowthattwoobjectivefunctions
L (θ)=E (cid:2) ∥uθ(x)−νP(x)∥2(cid:3) , (A4)
FM Pt,U t t
and
(cid:104) (cid:105)
Lc (θ)=E ∥uθ(x)−νPc (x|y)∥2 , (A5)
FM Pt,q,U t t
givesthesamegradientfortheparameterθ. Thegradient∇ Lc (θ)canbecalculatedasfollows,
θ FM
2 (cid:90) (cid:90) (cid:90)
∇ Lc (θ)= dt dy dxPc(x|y)q(y)[∇ uθ(x)]·(uθ(x)−νPc (x|y))
θ FM τ t θ t t t
2 (cid:90) (cid:90)
= dt dxP (x)[∇ uθ(x)]·(uθ(x)−νP(x))
τ t θ t t t
=∇ L (θ), (A6)
θ FM
whichmeansthat∇ Lc (θ)coincideswith∇ L (θ). Here,weused(cid:82) dyPc(x|y)q(y)=P (x)and
θ FM θ FM t t
(cid:90)
νP(x)P (x)= dyνPc (x|y)Pc(x|y)q(y). (A7)
t t t t
AppendixB:Parametersoftheconditionalprobabilitydensityfunction
Here, we explain the specific expressions for the parameters µ (y) and Σ of the conditional probability density function
t t
Pc(x|y) = N(x|µ (y),Σ ).TheFokker–PlanckequationfortheconditionalprobabilitydensityfunctionPc(x|y)isgivenas
t t t t
follows,
(cid:16) (cid:17)
∂ Pc(x|y)=−∇· νPc (x|y)Pc(x|y) , (B1)
t t t t
νPc (x|y):=A x+b −T ∇lnPc(x|y)=(A +T Σ−1)(x−µ (y))+A µ (y)+b . (B2)
t t t t t t t t t t t t
Thus,thetimeevolutionoftheparameterµ (y)canbecalculatedasfollows,
t
(cid:90)
∂ µ (y)=∂ dxxPc(x|y)
t t t t
(cid:90) (cid:16) (cid:16) (cid:17)(cid:17)
= dxx −∇· νPc (x|y)Pc(x|y)
t t
(cid:90)
= dxνPc (x|y)Pc(x|y)
t t
(cid:90) (cid:90)
= dx[A x+b ]Pc(x|y)− dxT ∇Pc(x|y)
t t t t t
=A µ (y)+b , (B3)
t t t18
whereweassumedthatthecontributionvanishesatinfinityinthepartialintegration,andweusedµ (y)=(cid:82) dxxPc(x|y)and
(cid:82) dx∇Pc(x|y)=0. ThetimeevolutionoftheparameterΣ isalsocalculatedasfollows, t t
t t
(cid:90)
∂ Σ =∂ dx(x−µ (y))(x−µ (y))⊤Pc(x|y)
t t t t t t
(cid:90) (cid:16) (cid:16) (cid:17)(cid:17)
= dx(x−µ (y))(x−µ (y))⊤ −∇· νPc (x|y)Pc(x|y)
t t t t
(cid:90) (cid:90)
= dx(A +T Σ−1)(x−µ (y))(x−µ (y))⊤Pc(x|y)+ dx(x−µ (y))(cid:2) (A +T Σ−1)(x−µ (y))(cid:3)⊤ Pc(x|y)
t t t t t t t t t t t t
=A Σ +Σ A⊤+2T I, (B4)
t t t t t
where⊤standsforthetranspose,andweusedΣ =(cid:82) dx(x−µ (y))(x−µ (y))⊤Pc(x|y),(cid:82) dx(x−µ (y))Pc(x|y)=0
t t t t t t
and(Σ−1)⊤ =Σ−1.
t t
Now,weconsiderasituationwhereA ,b andT areexpressedasA =(∂ lnm )I,b =0,T =∂ (σ2/2)−σ2∂ lnm with
t t t t t t t t t t t t t
non-negativeparametersσ (≥ 0),m (≥ 0),andtheinitialconditionsoftheparametersaregivenbym = 1andσ = 0.
t t t=0 t=0
Inthissituation,Eqs.(B3)and(B4)aregivenasfollows,
∂ µ (y)=(∂ lnm )µ (y), (B5)
t t t t t
∂ Σ (y)=(2∂ lnm )Σ (y)+(∂ (σ2)−2σ2∂ lnm )I. (B6)
t t t t t t t t t t
Therefore,thek-thelementofthevector[µ (y)] and,the(k,l)elementofthematrix[Σ (y)] satisfiesthefollowingequations,
t k t kl
∂ [µ (y)] =(∂ lnm )[µ (y)] , (B7)
t t k t t t k
∂ ([Σ (y)] −σ2δ )=(2∂ lnm )([Σ (y)] −σ2δ ), (B8)
t t kl t kl t t t kl t kl
whereδ =[I] istheKroneckerdelta.Becauseµ (y)=yandΣ =O,performingatimeintegralfromt=0totyields
kl kl t=0 t=0
[µ (y)] =m [y] , (B9)
t k t k
[Σ (y)] −σ2δ =0, (B10)
t kl t kl
andthusthefollowingspecificexpressionsareobtained,
µ (y)=m y, Σ =σ2I. (B11)
t t t t
AppendixC:CoordinatetransformationintheDDIM
WeshowthedetailedcalculationofthecoordinatetransformationintheDDIM.TheFokker–Planckequation[Eq.(1)]with
Eq.(23)isgivenasfollows,
∂ P (x)=−∇·[[(∂ lnm )x−T ∇lnP (x)]P (x)]. (C1)
t t t t t t t
Fromthecoordinatetransform
x
x¯ = , (C2)
m
t
weobtainP t(x)=P¯ t(x¯)(|dx¯/dx|)=P¯ t(x¯)(m t)−nd. BysubstitutingthisintoEq.(C1),theleft-handsideiscalculatedas
∂ tP t(x)=(m t)−nd∂ tP¯ t(x¯)−n d(∂ tlnm t)(m t)−ndP¯ t(x¯)−(∂ tlnm t)(m t)−(nd+1)x·∇ x¯P¯ t(x¯), (C3)
wherewedefined∇ as∇ =m ∇. TherighthandsideofEq.(C1)iscalculatedas
x¯ x¯ t
−∇·[[(∂ lnm )x−T ∇lnP (x)]P (x)]
t t t t t
=−n d(∂ tlnm t)(m t)−ndP¯ t(x¯)−(∂ tlnm t)(m t)−(nd+1)x·∇ x¯P¯ t(x¯)+∇
x¯
·(cid:104)(cid:2) T t∇ x¯lnP¯ t(x¯)(cid:3) P¯ t(x¯)(m t)−(nd+2)(cid:105) .
(C4)19
FromEqs.(C3)and(C4),weobtain
(cid:20)(cid:20) (cid:21) (cid:21)
T
∂ P¯ (x¯)=−∇ · − t ∇ lnP¯ (x¯) P¯ (x¯) . (C5)
t t x¯ (m )2 x¯ t t
t
BysubstitutingT =−∂ lnm ,
t t t
(cid:20)(cid:20) (cid:21) (cid:21)
∂ lnm
∂ P¯ (x¯)=−∇ · t t∇ lnP¯ (x¯) P¯ (x¯) , (C6)
t t x¯ (m )2 x¯ t t
t
isderived.
AppendixD:TherelationsbetweentheKullback–Leiblerdivergenceandtheentropyproduction
First,weprovethattheKullback–Leiblerdivergence
D (P ∥P
)=N (cid:88)τ−1(cid:90)
dΓP
(Γ)lnT N∆t(x (N+1)∆t|x N∆t)
, (D1)
KL F B F T† (x |x )
N=0 N∆t (N+1)∆t N∆t
coincideswiththeentropyproduction
(cid:90) τ (cid:20) 1 (cid:90) (cid:21)
Stot = dt dx∥νP(x)∥2P (x) , (D2)
τ T t t
0 t
inthelimit∆t→0withfixedτ. Bycalculatingln[T (x |x )/T† (x |x )],weobtain
N∆t (N+1)∆t N∆t N∆t (N+1)∆t N∆t
T (x |x )
N∆t (N+1)∆t N∆t
ln
T† (x |x )
N∆t (N+1)∆t N∆t
=(cid:13) (cid:13)x (N+1)∆t−x N∆t−f N∆t(x N∆t)∆t+2ν NP ∆t(x N∆t)∆t(cid:13) (cid:13)2
−
(cid:13) (cid:13)x (N+1)∆t−x N∆t−f N∆t(x N∆t)∆t(cid:13) (cid:13)2
4T ∆t 4T ∆t
N∆t N∆t
=(cid:13) (cid:13)ν NP ∆t(x N∆t)(cid:13) (cid:13)2
∆t+
(x (N+1)∆t−x N∆t−f N∆t(x N∆t)∆t)·ν NP ∆t(x N∆t)
. (D3)
T T
N∆t N∆t
(cid:82)
Byusing dx T (x |x )[x −x −f (x )∆t]=0andthenormalizationofprobability
(N+1)∆t N∆t (N+1)∆t N∆t (N+1)∆t N∆t N∆t N∆t
distributions,weobtain
(cid:90) T (x |x )
dΓPF(Γ)ln N∆t (N+1)∆t N∆t
T† (x |x )
N∆t (N+1)∆t N∆t
(cid:90) (cid:90) T (x |x )
N∆t (N+1)∆t N∆t
= dx dx T (x |x )P (x )ln
N∆t (N+1)∆t N∆t (N+1)∆t N∆t N∆t N∆t T† (x |x )
N∆t (N+1)∆t N∆t
= T∆t (cid:90) dx N∆t(cid:13) (cid:13)ν NP ∆t(x N∆t)(cid:13) (cid:13)2 P N∆t(x N∆t). (D4)
N∆t
Bytakingthelimit∆t→0withfixedτ,weobtain
D KL(P F∥P B)=N (cid:88)τ−1 T∆t (cid:90) dx(cid:13) (cid:13)ν NP ∆t(x)(cid:13) (cid:13)2 P N∆t(x)
N∆t
N=0
(cid:90) τ (cid:20) 1 (cid:90) (cid:21)
→ dt dx∥νP(x)∥2P (x) =Stot. (D5)
T t t τ
0 t
Next,weprovethatKullback-LeiblerdivergenceD KL(P F∥P′ B) = E P F[st τot]coincideswithS τtot = (cid:82) 0τ dtS˙ tsys+(cid:82) 0τ dtS˙ tbath
inthelimit∆t→0withfixedτ. Sincethestochasticentropyproductionisgivenby
stot =ln
P 0(x 0) +N (cid:88)τ−1 lnT N∆t(x (N+1)∆t|x N∆t)
, (D6)
τ P (x ) T (x |x )
Nτ∆t Nτ∆t
N=0
N∆t N∆t (N+1)∆t20
D (P ∥P′ )iscalculatedasfollows,
KL F B
D KL(P F∥P′ B)=E P F[st τot]
=(cid:90)
dΓP (Γ)ln
P 0(x 0) +N (cid:88)τ−1(cid:90)
dΓP
(Γ)lnT N∆t(x (N+1)∆t|x N∆t)
. (D7)
F P (x ) F T (x |x )
Nτ∆t Nτ∆t
N=0
N∆t N∆t (N+1)∆t
Fromthemarginalizationofthepathprobability,thefirsttermofEq.(D7)isrewrittenasfollows,
(cid:90) P (x ) (cid:90) (cid:90)
dΓP (Γ)ln 0 0 = dx P (x )lnP (x )− dx P (x )lnP (x )
F P (x ) 0 0 0 0 0 Nτ∆t Nτ∆t Nτ∆t Nτ∆t Nτ∆t
Nτ∆t Nτ∆t
(cid:90) τ (cid:20) (cid:90) (cid:21)
= dt∂ − dxP (x)lnP (x)
t t t
0
(cid:90) τ
= dtS˙sys. (D8)
t
0
ThesecondtermofEq.(D7)isalsocalculatedas
(cid:90) T (x |x )
dΓP (Γ)ln N∆t (N+1)∆t N∆t
F T (x |x )
N∆t N∆t (N+1)∆t
=(cid:90)
dΓP
(Γ)(cid:34) −(cid:13) (cid:13)x (N+1)∆t−x N∆t−f N∆t(x N∆t)∆t(cid:13) (cid:13)2
+
(cid:13) (cid:13)x N∆t−x (N+1)∆t−f N∆t(x (N+1)∆t)∆t(cid:13) (cid:13)2(cid:35)
F 4T ∆t 4T ∆t
N∆t N∆t
(cid:90) (cid:34) (x −x )· fN∆t(xN∆t)+fN∆t(x(N+1)∆t) ∥f (x )∥2−∥f (x )∥2 (cid:35)
= dΓP (Γ) (N+1)∆t N∆t 2 + N∆t (N+1)∆t N∆t N∆t ∆t
F T 4T
N∆t N∆t
(cid:34) (cid:35)
(cid:90) (cid:90) (y−x)· fN∆t(x)+fN∆t(y)
= dxP (x) dyT (y|x) 2
N∆t N∆t T
N∆t
(cid:90) (cid:90) (cid:20) ∥f (y)∥2−∥f (x)∥2 (cid:21)
+ dxP (x) dyT (y|x) N∆t N∆t ∆t
N∆t N∆t 4T
N∆t
1 (cid:90) (cid:90)
= dxP (x) dyT (y|x)[(y−x)·f (x)]
T N∆t N∆t N∆t
N∆t
 
+
T
1 (cid:90)
dxP
N∆t(x)(cid:90)
dyT
N∆t(y|x)(cid:88)[y i−x i] 2[y
j
−x j]
∇ xj[f N∆t(x)] i+O((∆t)2)
N∆t
i,j
∆t (cid:90) (cid:90)
= dxP (x)∥f (x)∥2+∆t dxP (x)∇·f (x)+O((∆t)2)
T N∆t N∆t N∆t N∆t
N∆t
∆t (cid:90)
= dxP (x)f (x)·νP (x)+O((∆t)2). (D9)
T N∆t N∆t N∆t
N∆t
Therefore,inthelimit∆t→0withfixedτ,weobtain
N (cid:88)τ−1(cid:90)
dΓP
(Γ)lnT N∆t(x (N+1)∆t|x N∆t) =(cid:90) τ dt(cid:82) dxP t(x)f t(x)·ν tP(x) =(cid:90) τ
dtS˙bath. (D10)
F T (x |x ) T t
N=0 N∆t N∆t (N+1)∆t 0 t 0
FromEqs.(D7),(D8)and(D10),weobtain
(cid:90) τ (cid:90) τ
D (P ∥P′ )= dtS˙sys+ dtS˙bath =Stot. (D11)
KL F B t t τ
0 0
WeremarkthatE P F[lnP B]=E P F[lnP′ B]issatisfiedbecauseS ttot =D KL(P F∥P B)=D KL(P F∥P′ B),whileP B(Γ)̸=P′ B(Γ).
AppendixE:Time-independenceofthePearson’sχ2-divergence
WeshowthatD isindependentoftimeifthevelocityfieldoftheforwardprocessisaccuratelyreconstructed(νˆ (x) =
τ−t t
νP(x)) in the flow-based generative modeling or the probability flow ODE. From Eq. (84) and the continuity equation
t21
∂ P (x)=−∇·(cid:0) νP(x)P (x)(cid:1) ,thetimederivativeofD iscalculatedas
t t t t τ−t
(cid:90) (δP (x))2
∂ D = dx∂ t
t τ−t t P (x)
t
(cid:90) (cid:34) 2δP (x) (cid:18) δP (x)(cid:19)2 (cid:35)
= dx t ∂ δP (x)− t ∂ P (x)
P (x) t t P (x) t t
t t
(cid:90) (cid:20) 2δP (x) (cid:21) (cid:90) (cid:34)(cid:18) δP (x)(cid:19)2 (cid:35)
=− dx t (∇·(νP(x)δP (x))) + dx t (∇·(νP(x)P (x)))
P (x) t t P (x) t t
t t
(cid:90) (cid:20) (cid:18) δP (x)(cid:19) (cid:21) (cid:90) (cid:20) (cid:18) δP (x)(cid:19) δP (x) (cid:21)
= dx 2∇ t ·νP(x)δP (x) − dx 2∇ t ·νP(x) t P (x)
P (x) t t P (x) t P (x) t
t t t
=0,
whereweusedthepartialintegrationandweassumedthatP (x)andδP (x)vanishatinfinity. Therefore,weobtain∂ D =
t t t τ−t
0,whichmeansthatD isindependentoftime.
τ−t
AppendixF:Detailsofthenumericalexperiments
Wehereexplainthedetailsofthenumericalcalculations. Inthenumericalcalculation,theinputdistributionq(x)isgivenby
the1-dimensionalsituationGaussianmixturedistribution
1 1
q(x)= N(x|ma,σ2)+ N(x|mb,σ2), (F1)
2 2
√
with σ = 0.3 and ma = −mb = 0.35. Here, we can analytically obtain νP(x) as follows. By considering the Fokker–
t
Planck equation for the conditional distribution, ∂ Pc(x|y) = −∇ · (νPc(x|y)Pc(x|y)), the time evolution of P (x) =
(cid:82) dyPc(x|y)q(y)isgivenby t t t t t
t
(cid:20)(cid:90) (cid:21)
∂ P (x)=∂ dyPc(x|y)q(y)
t t t t
(cid:18)(cid:82) dyνPc(x|y)Pc(x|y)q(y) (cid:19)
=−∇· t t P (x) . (F2)
P (x) t
t
BycomparingthisequationandEq.(1),weobtain
(cid:90) νPc(x|y)Pc(x|y)q(y)
νP(x)= dy t t . (F3)
t P (x)
t
FromνPc(x|y)=f (x)−T ∇lnPc(x|y)andEqs.(22),(23),weobtain
t t t t
(cid:20) (cid:18) σ2(cid:19) (cid:21)
νPc (x|y)=(∂ lnm )x− ∂ t −σ2∂ lnm ∇lnPc(x|y)
t t t t 2 t t t t
(cid:18) (cid:19)
∂ m ∂ σ ∂ m
= t tx−σ2 t t − t t ∇lnPc(x|y). (F4)
m t σ m t
t t t
Therefore,νP(x)iscalculatedas,
t
(cid:90) (cid:20) ∂ m (cid:18) ∂ σ ∂ m (cid:19) (cid:21) Pc(x|y)q(y)
νP(x)= dy t tx−σ2 t t − t t ∇lnPc(x|y) t
t m t σ m t P (x)
t t t t
(cid:90) (cid:20) ∂ m (cid:18) ∂ σ ∂ m (cid:19) (cid:21) Pc(x|y)q(y)
= dy t tx+ t t − t t (x−m y) t
m σ m t P (x)
t t t t
(cid:18) (cid:19)
∂ σ m ∂ σ ∂ m
= σt tx−
P
(xt
)
σt t − mt t E
P
tc,q[y], (F5)
t t t t22
w
E
Phe cr ,qe [yw ]e isus ce ad lcP ultc a( tx ed|y a) s=N(x|m ty,σ t2)andtheexpectedvalueE
P
tc,q[y]isdefinedasE
P
tc,q[y]=(cid:82) dyyP tc(x|y)q(y). Here,
t
1(cid:90) 1(cid:90)
E [y]= dyyN(x|m y,σ2)N(y|ma,σ2)+ dyyN(x|m y,σ2)N(y|mb,σ2)
P tc,q 2 t t 2 t t
=
1σ2m tx+σ t2ma1
N
(cid:0)
x|m
ma,σ2+σ2m2(cid:1)
+
1σ2m tx+σ t2mb1
N
(cid:0)
x|m
mb,σ2+σ2m2(cid:1)
2 σ2+σ2m2 t t t 2 σ2+σ2m2 t t t
t t t t
1σ2m x+σ2ma1 1σ2m x+σ2mb1
= t t Na+ t t Nb. (F6)
2 σ2+σ2m2 2 σ2+σ2m2
t t t t
WeusethisanalyticalexpressionofthevelocityfieldνP(x)[Eq.(97)]forthecosineandcond-OTschedules.
t
Tocomputethevelocityfieldfortheoptimaltransport,weadoptedtheoptimaltransportconditionalflowmatching(OTCFM)
method[70]. Thismethodisaconditionalflowmatchingmethodthatestimatesthevelocityfieldfortheoptimaltransportby
usingsamplesgeneratedfromtheoptimaltransportplan. Tocomputetheoptimaltransportplan, weusedthePythonoptimal
transport (POT) library [126]. As an estimation architecture, we used a fully connected multi-layer perceptron (MLP) with
5 layers consisting of 1024 neurons in each layer. The hyperbolic tangent function was used as the activation function. For
training, weusedtheAdamoptimizer[127]withalearningrateof3×10−4 forlearning107 datapointswithabatchsizeof
4056.
Toobtaintheprobabilitydensityfunctionfortheestimatedprocess,wenumericallycomputedtheODEdx˜†/dt˜=ν˜†(x˜†)=
t˜ t˜ t˜
−νP (x˜†) for the velocity fields of the cosine schedule, the cond-OT schedule and the optimal transport with various initial
τ−t˜ t˜
conditions,usingthe4-thorderexplicitRunge–Kuttamethod[128].Specifically,wecomputed3×109samplesandusedacubic
splineinterpolationforthehistogramofthesamplestoapproximatetheprobabilitydensityfunction. Tonumericallycompute
the each term in the inequality [Eq. (80)], we used numerical integration methods for D = (cid:82) dx (δP (x))2/P (x) and
τ−t t t
[v (t)]2 = (cid:82) dx ∥ν (x)∥2P (x), and we used the POT library for the 1-Wasserstein distance. We used τ/∆t = 100 for the
2 t t
timestep∆t, andcreatedauniformgridforthespatialstep∆xas(4.5−(−4.5))/∆x = 5×102 inx ∈ [−4.5,4.5]. When
theinitialconditionisgivenbytheuniformdistribution,wesetthespatialstepto(4.5−(−4.5))/∆x = 5×103 becausethe
computationcanbenumericallyunstableforalargespatialstepduetothediscontinuityofthedistribution. Weshowtheinitial
conditionsinTab.I.Wealsoshowthetimeevolutionoftheprobabilitydensityfunctionsintheforwardandestimatedprocess
foreachconditioninFig.(5).
Initialconditions Probabilitydensityfunctions
Gaussiandistributionwithdifferentmean q(x)=N(x|1.0,1.0)
Gaussiandistributionwithdifferentvariance q(x)=N(x|0.0,0.82)
Gaussianmixturedistribution q(x)= 1[N(x| −1 ,(cid:0) 0.3 (cid:1)2)+N(x|0,(cid:0) 0.8 (cid:1)2)+N(x| 1 ,(cid:0) 0.3 (cid:1)2)
3 0.94 0.94 √0.94√ 0.94 0.94
Uniformdistribution q(x)= √1 (x∈[− 3, 3])
2 3
TABLEI.Theinitialconditionsusedinthenumericalcalculations[Fig.4].HereN(x|µ,σ2)denotesthe1-dimensionalGaussiandistribution
withmeanµandvarianceσ2.
[1] N.G.VanKampen,Stochasticprocessesinphysicsandchem- [7] U. Seifert, Entropy production along a stochastic trajectory
istry,Vol.1(Elsevier,1992). andanintegralfluctuationtheorem,Physicalreviewletters95,
[2] K.Sekimoto,Stochasticenergetics(2010). 040602(2005).
[3] U. Seifert, Stochastic thermodynamics, fluctuation theorems [8] V.Y.Chernyak,M.Chertkov,andC.Jarzynski,Path-integral
and molecular machines, Reports on progress in physics 75, analysis of fluctuation theorems for general langevin pro-
126001(2012). cesses, Journal of Statistical Mechanics: Theory and Exper-
[4] K. Sekimoto, Langevin equation and thermodynamics, iment2006,P08001(2006).
ProgressofTheoreticalPhysicsSupplement130,17(1998). [9] T.SchmiedlandU.Seifert,Efficiencyatmaximumpower:An
[5] J.Kurchan,Fluctuationtheoremforstochasticdynamics,Jour- analyticallysolvablemodelforstochasticheatengines,Euro-
nalofPhysicsA:MathematicalandGeneral31,3719(1998). physicsletters81,20003(2007).
[6] T. Hatano and S.-i. Sasa, Steady-state thermodynamics of [10] A. E. Allahverdyan, D. Janzing, and G. Mahler, Thermody-
langevinsystems,Physicalreviewletters86,3463(2001). namicefficiencyofinformationandheatflow,JournalofSta-23
Cosine schedule Cond-OT schedule Optimal transport
Forward process Forward process Forward process
Estimated process Estimated process Estimated process
Gaussian distribution with different mean Gaussian distribution with different mean Gaussian distribution with different mean
Gaussian distribution with different variance Gaussian distribution with different variance Gaussian distribution with different variance
Gaussian mixture distribution Gaussian mixture distribution Gaussian mixture distribution
Uniform distribution Uniform distribution Uniform distribution
FIG.5.Thetimeevolutionoftheprobabilitydensityfunctionsintheforwardandestimatedprocesses,foreachconditionusedinthenumerical
calculations[Fig.4].
tistical Mechanics: Theory and Experiment 2009, P09011 tropyproductionbymachinelearningofshort-timefluctuating
(2009). currents,PhysicalReviewE101,062106(2020).
[11] C.VandenBroeckandM.Esposito,Threefacesofthesec- [22] A.DechantandS.-i.Sasa,Continuoustimereversalandequal-
ondlaw.ii.fokker-planckformulation,PhysicalReviewE82, ity in the thermodynamic uncertainty relation, Physical Re-
011144(2010). viewResearch3,L042012(2021).
[12] T.SagawaandM.Ueda,Nonequilibriumthermodynamicsof [23] S. Otsubo, S. K. Manikandan, T. Sagawa, and S. Krishna-
feedbackcontrol,PhysicalReviewE85,021104(2012). murthy, Estimating time-dependent entropy production from
[13] S.ItoandT.Sagawa,Informationthermodynamicsoncausal non-equilibrium trajectories, Communications Physics 5, 11
networks,Physicalreviewletters111,180603(2013). (2022).
[14] J. M. Horowitz and H. Sandberg, Second-law-like inequali- [24] T. Koyuk and U. Seifert, Thermodynamic uncertainty rela-
tieswithinformationandtheirinterpretations,NewJournalof tionfortime-dependentdriving,PhysicalReviewLetters125,
Physics16,125007(2014). 260604(2020).
[15] S.ItoandT.Sagawa,Maxwell’sdemoninbiochemicalsignal [25] C. Villani et al., Optimal transport: old and new, Vol. 338
transductionwithfeedbackloop,Naturecommunications6,1 (Springer,2009).
(2015). [26] R.Jordan,D.Kinderlehrer,andF.Otto,Thevariationalformu-
[16] T. R. Gingrich, G. M. Rotskoff, and J. M. Horowitz, Infer- lationofthefokker–planckequation,SIAMjournalonmath-
ringdissipationfromcurrentfluctuations,JournalofPhysics ematicalanalysis29,1(1998).
A:MathematicalandTheoretical50,184004(2017). [27] E.Aurell,C.Mej´ıa-Monasterio,andP.Muratore-Ginanneschi,
[17] A. Dechant and S.-i. Sasa, Entropic bounds on currents in Optimalprotocolsandoptimaltransportinstochasticthermo-
langevinsystems,PhysicalReviewE97,062101(2018). dynamics,Physicalreviewletters106,250601(2011).
[18] J.Li,J.M.Horowitz,T.R.Gingrich,andN.Fakhri,Quanti- [28] Y.Chen,T.T.Georgiou,andA.Tannenbaum,Stochasticcon-
fyingdissipationusingfluctuatingcurrents,Naturecommuni- trol and nonequilibrium thermodynamics: Fundamental lim-
cations10,1666(2019). its,IEEEtransactionsonautomaticcontrol65,2979(2019).
[19] Y.HasegawaandT.VanVu,Uncertaintyrelationsinstochas- [29] M.NakazatoandS.Ito,Geometricalaspectsofentropypro-
tic processes: An information inequality approach, Physical duction in stochastic thermodynamics based on wasserstein
ReviewE99,062126(2019). distance,PhysicalReviewResearch3,043093(2021).
[20] S.ItoandA.Dechant,Stochastictimeevolution,information [30] E.Aurell,K.Gawe¸dzki,C.Mej´ıa-Monasterio,R.Mohayaee,
geometry, andthecrame´r-raobound,PhysicalReviewX10, and P. Muratore-Ginanneschi, Refined second law of ther-
021056(2020). modynamicsforfastrandomprocesses,JournalofStatistical
[21] S.Otsubo,S.Ito,A.Dechant,andT.Sagawa,Estimatingen- Physics147,487(2012).24
[31] A. Dechant, S.-i.Sasa, and S.Ito, Geometricdecomposition arXivpreprintarXiv:2207.12598 (2022).
ofentropyproductionintoexcess,housekeeping,andcoupling [53] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin,
parts,PhysicalReviewE106,024125(2022). B.McGrew,I.Sutskever,andM.Chen,Glide: Towardspho-
[32] S. Ito, Geometric thermodynamics for the fokker–planck torealisticimagegenerationandeditingwithtext-guideddif-
equation: stochastic thermodynamic links between informa- fusionmodels,arXivpreprintarXiv:2112.10741 (2021).
tiongeometryandoptimaltransport,InformationGeometry7, [54] A. Sauer, F. Boesel, T. Dockhorn, A. Blattmann, P. Esser,
441(2024). and R. Rombach, Fast high-resolution image synthesis
[33] R.Nagayama, K.Yoshimura, A.Kolchinsky,andS.Ito,Ge- with latent adversarial diffusion distillation, arXiv preprint
ometricthermodynamicsofreaction-diffusionsystems:Ther- arXiv:2403.12015 (2024).
modynamictrade-offrelationsandoptimaltransportforpat- [55] D.Podell,Z.English,K.Lacey,A.Blattmann,T.Dockhorn,
ternformation,arXivpreprintarXiv:2311.16569 (2023). J.Mu¨ller,J.Penna,andR.Rombach,Sdxl: Improvinglatent
[34] J.M.Tomczak,Deepgenerativemodeling(Springer,2022). diffusion models for high-resolution image synthesis, arXiv
[35] J.Sohl-Dickstein,E.Weiss,N.Maheswaranathan,andS.Gan- preprintarXiv:2307.01952 (2023).
guli, Deep unsupervised learning using nonequilibrium ther- [56] A.Hyva¨rinenandP.Dayan,Estimationofnon-normalizedsta-
modynamics,inInternationalconferenceonmachinelearning tisticalmodelsbyscorematching.,JournalofMachineLearn-
(PMLR,2015)pp.2256–2265. ingResearch6(2005).
[36] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Er- [57] P.Vincent,Aconnectionbetweenscorematchinganddenois-
mon,andB.Poole,Score-basedgenerativemodelingthrough ingautoencoders,Neuralcomputation23,1661(2011).
stochasticdifferentialequations,inInternationalConference [58] D. P. Kingma and Y. Cun, Regularized estimation of image
onLearningRepresentations(2020). statisticsbyscorematching,Advancesinneuralinformation
[37] D. J. Evans and D. J. Searles, The fluctuation theorem, Ad- processingsystems23(2010).
vancesinPhysics51,1529(2002). [59] L. Dinh, D. Krueger, and Y. Bengio, Nice: Non-
[38] G. E. Crooks, Entropy production fluctuation theorem and linear independent components estimation, arXiv preprint
thenonequilibriumworkrelationforfreeenergydifferences, arXiv:1410.8516 (2014).
PhysicalReviewE60,2721(1999). [60] D.RezendeandS.Mohamed,Variationalinferencewithnor-
[39] C.Jarzynski,Nonequilibriumequalityforfreeenergydiffer- malizingflows,inInternationalconferenceonmachinelearn-
ences,PhysicalReviewLetters78,2690(1997). ing(PMLR,2015)pp.1530–1538.
[40] J.Ho,A.Jain,andP.Abbeel,Denoisingdiffusionprobabilistic [61] R.T.Chen,Y.Rubanova,J.Bettencourt,andD.K.Duvenaud,
models, Advances in neural information processing systems Neuralordinarydifferentialequations,Advancesinneuralin-
33,6840(2020). formationprocessingsystems31(2018).
[41] D.Kingma,T.Salimans,B.Poole,andJ.Ho,Variationaldiffu- [62] K.-U. Song, Applying regularized schr\” odinger-bridge-
sionmodels,Advancesinneuralinformationprocessingsys- based stochastic process in generative modeling, arXiv
tems34,21696(2021). preprintarXiv:2208.07131 (2022).
[42] Y. Song and S. Ermon, Generative modeling by estimating [63] Y.Lipman,R.T.Chen,H.Ben-Hamu,M.Nickel,andM.Le,
gradients of the data distribution, Advances in neural infor- Flow matching for generative modeling, in The Eleventh In-
mationprocessingsystems32(2019). ternationalConferenceonLearningRepresentations(2022).
[43] A.Q.NicholandP.Dhariwal,Improveddenoisingdiffusion [64] M.Arjovsky,S.Chintala,andL.Bottou,Wassersteingenera-
probabilisticmodels,inInternationalConferenceonMachine tiveadversarialnetworks,inInternationalconferenceonma-
Learning(PMLR,2021)pp.8162–8171. chinelearning(PMLR,2017)pp.214–223.
[44] R.Rombach,A.Blattmann,D.Lorenz,P.Esser,andB.Om- [65] D.Kwon,Y.Fan,andK.Lee,Score-basedgenerativemodel-
mer, High-resolution image synthesis with latent diffusion ingsecretlyminimizesthewassersteindistance,Advancesin
models,inProceedingsoftheIEEE/CVFconferenceoncom- NeuralInformationProcessingSystems35,20205(2022).
putervisionandpatternrecognition(2022)pp.10684–10695. [66] K.Oko,S.Akiyama,andT.Suzuki,Diffusionmodelsaremin-
[45] Y.SongandS.Ermon,Improvedtechniquesfortrainingscore- imaxoptimaldistributionestimators,inInternationalConfer-
basedgenerativemodels,Advancesinneuralinformationpro- enceonMachineLearning(PMLR,2023)pp.26517–26582.
cessingsystems33,12438(2020). [67] V.DeBortoli,Convergenceofdenoisingdiffusionmodelsun-
[46] Y.Song,P.Dhariwal,M.Chen,andI.Sutskever,Consistency derthemanifoldhypothesis,arXivpreprintarXiv:2208.05314
models,arXivpreprintarXiv:2303.01469 (2023). (2022).
[47] P.DhariwalandA.Nichol,Diffusionmodelsbeatgansonim- [68] N. Kornilov, A. Gasnikov, and A. Korotin, Optimal flow
agesynthesis,Advancesinneuralinformationprocessingsys- matching:Learningstraighttrajectoriesinjustonestep,arXiv
tems34,8780(2021). preprintarXiv:2403.13117 (2024).
[48] J.Song,C.Meng,andS.Ermon,Denoisingdiffusionimplicit [69] N.Shaul,R.T.Chen,M.Nickel,M.Le,andY.Lipman,On
models,inInternationalConferenceonLearningRepresenta- kineticoptimalprobabilitypathsforgenerativemodels,inIn-
tions(2020). ternationalConferenceonMachineLearning(PMLR,2023)
[49] T. Karras, M. Aittala, T. Aila, and S. Laine, Elucidating the pp.30883–30907.
designspaceofdiffusion-basedgenerativemodels,Advances [70] A.Tong,N.Malkin,G.Huguet,Y.Zhang,J.Rector-Brooks,
inNeuralInformationProcessingSystems35,26565(2022). K. Fatras, G. Wolf, and Y. Bengio, Improving and general-
[50] T.Chen,G.-H.Liu,andE.Theodorou,Likelihoodtrainingof izing flow-based generative models with minibatch optimal
schro¨dingerbridgeusingforward-backwardsdestheory,inIn- transport,inICMLWorkshoponNewFrontiersinLearning,
ternationalConferenceonLearningRepresentations(2021). Control,andDynamicalSystems(2023).
[51] A.Ramesh,P.Dhariwal,A.Nichol,C.Chu,andM.Chen,Hi- [71] Y.Shi,V.DeBortoli,G.Deligiannidis,andA.Doucet,Condi-
erarchicaltext-conditionalimagegenerationwithcliplatents, tionalsimulationusingdiffusionschro¨dingerbridges,inUn-
arXivpreprintarXiv:2204.061251,3(2022). certainty in Artificial Intelligence (PMLR, 2022) pp. 1792–
[52] J. Ho and T. Salimans, Classifier-free diffusion guidance, 1802.25
[72] X.Liu,C.Gong,andQ.Liu,Flowstraightandfast:Learning ternationalConferenceonLearningRepresentations(2020).
togenerateandtransferdatawithrectifiedflow,arXivpreprint [91] Smithsonianbutterfliessubset,accessed:2024-02-09.
arXiv:2209.03003 (2022). [92] H. Risken and H. Risken, Fokker-planck equation (Springer,
[73] P. Esser, S. Kulal, A. Blattmann, R. Entezari, J. Mu¨ller, 1996).
H.Saini,Y.Levi,D.Lorenz,A.Sauer,F.Boesel,etal.,Scal- [93] N.G.VanKampen,Stochasticdifferentialequations,Physics
ingrectifiedflowtransformersforhigh-resolutionimagesyn- reports24,171(1976).
thesis,arXivpreprintarXiv:2403.03206 (2024). [94] S. Brooks, Markov chain monte carlo method and its appli-
[74] J. Klinger and G. M. Rotskoff, Universal energy-speed- cation, Journal of the royal statistical society: series D (the
accuracytrade-offsindrivennonequilibriumsystems(2024), Statistician)47,69(1998).
arXiv:2402.17931[cond-mat.stat-mech]. [95] C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan, An
[75] A.Brock,J.Donahue,andK.Simonyan,Largescalegantrain- introductiontomcmcformachinelearning,Machinelearning
ing for high fidelity natural image synthesis, arXiv preprint 50,5(2003).
arXiv:1809.11096 (2018). [96] M. Welling and Y. W. Teh, Bayesian learning via stochastic
[76] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, gradient langevin dynamics, in Proceedings of the 28th in-
P.Dhariwal,A.Neelakantan,P.Shyam,G.Sastry,A.Askell, ternationalconferenceonmachinelearning(ICML-11)(Cite-
et al., Language models are few-shot learners, Advances in seer,2011)pp.681–688.
neuralinformationprocessingsystems33,1877(2020). [97] T.Chen,Ontheimportanceofnoiseschedulingfordiffusion
[77] A.v.d.Oord,S.Dieleman,H.Zen,K.Simonyan,O.Vinyals, models,arXivpreprintarXiv:2301.10972 (2023).
A.Graves,N.Kalchbrenner,A.Senior,andK.Kavukcuoglu, [98] B. D. Anderson, Reverse-time diffusion equation models,
Wavenet: A generative model for raw audio, arXiv preprint StochasticProcessesandtheirApplications12,313(1982).
arXiv:1609.03499 (2016). [99] C.Lu,Y.Zhou,F.Bao,J.Chen,C.Li,andJ.Zhu,Dpm-solver:
[78] I. Goodfellow, Y. Bengio, and A. Courville, Deep Learning Afastodesolverfordiffusionprobabilisticmodelsamplingin
(MITPress,2016). around10steps,AdvancesinNeuralInformationProcessing
[79] L.Theis,A.v.d.Oord,andM.Bethge,Anoteontheevalu- Systems35,5775(2022).
ationofgenerativemodels,arXivpreprintarXiv:1511.01844 [100] C.Lu,K.Zheng,F.Bao,J.Chen,C.Li,andJ.Zhu,Maximum
(2015). likelihoodtrainingforscore-baseddiffusionodesbyhighor-
[80] E. Betzalel, C. Penso, A. Navon, and E. Fetaya, A study derdenoisingscorematching,inInternationalConferenceon
on the evaluation of generative models, arXiv preprint MachineLearning(PMLR,2022)pp.14429–14460.
arXiv:2206.10935 (2022). [101] Q. Zhang and Y. Chen, Fast sampling of diffusion models
[81] S. Bischoff, A. Darcher, M. Deistler, R. Gao, F. Gerken, withexponentialintegrator,arXivpreprintarXiv:2204.13902
M. Gloeckler, L. Haxel, J. Kapoor, J. K. Lappalainen, (2022).
J. H. Macke, et al., A practical guide to statistical distances [102] I. Kobyzev, S. J. Prince, and M. A. Brubaker, Normalizing
for evaluating generative models in science, arXiv preprint flows: Anintroductionandreviewofcurrentmethods,IEEE
arXiv:2403.12636 (2024). transactionsonpatternanalysisandmachineintelligence43,
[82] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and 3964(2020).
S. Hochreiter, Gans trained by a two time-scale update rule [103] S. Ito, M. Oizumi, and S.-i. Amari, Unified framework for
convergetoalocalnashequilibrium,Advancesinneuralin- theentropyproductionandthestochasticinteractionbasedon
formationprocessingsystems30(2017). information geometry, Physical Review Research 2, 033048
[83] S.-i. Amari, Information geometry and its applications, Vol. (2020).
194(Springer,2016). [104] R. Kawai, J. M. Parrondo, and C. Van den Broeck, Dissipa-
[84] B. Poole, A. Jain, J. T. Barron, and B. Mildenhall, tion: Thephase-spaceperspective,Physicalreviewletters98,
Dreamfusion: Text-to-3d using 2d diffusion, arXiv preprint 080602(2007).
arXiv:2209.14988 (2022). [105] C.Villani,Topicsinoptimaltransportation,Vol.58(Ameri-
[85] M.Xu,L.Yu,Y.Song,C.Shi,S.Ermon,andJ.Tang,Geod- canMathematicalSoc.,2021).
iff: Ageometricdiffusionmodelformolecularconformation [106] C.R.GivensandR.M.Shortt,Aclassofwassersteinmetrics
generation,arXivpreprintarXiv:2203.02923 (2022). forprobabilitydistributions,MichiganMathematicalJournal
[86] J. Abramson, J. Adler, J. Dunger, R. Evans, T. Green, 31,231 (1984).
A.Pritzel,O.Ronneberger,L.Willmore,A.J.Ballard,J.Bam- [107] J.-D.BenamouandY.Brenier,Acomputationalfluidmechan-
brick,etal.,Accuratestructurepredictionofbiomolecularin- icssolutiontothemonge-kantorovichmasstransferproblem,
teractionswithalphafold3,Nature,1(2024). NumerischeMathematik84,375(2000).
[87] J.Ho,W.Chan,C.Saharia,J.Whang,R.Gao,A.Gritsenko, [108] A. Dechant, S.-i.Sasa, and S.Ito, Geometricdecomposition
D.P.Kingma,B.Poole,M.Norouzi,D.J.Fleet,etal.,Imagen ofentropyproductioninout-of-equilibriumsystems,Physical
video:Highdefinitionvideogenerationwithdiffusionmodels, ReviewResearch4,L012034(2022).
arXivpreprintarXiv:2210.02303 (2022). [109] J.-D. Benamou and Y. Brenier, A numerical method for the
[88] T.Brooks,B.Peebles,C.Holmes,W.DePue,Y.Guo,L.Jing, optimal time-continuous mass transport problem and related
D.Schnurr,J.Taylor,T.Luhman,E.Luhman,C.Ng,R.Wang, problems,Contemporarymathematics226,1(1999).
andA.Ramesh,Videogenerationmodelsasworldsimulators, [110] D. Sekizawa, S. Ito, and M. Oizumi, Decomposing thermo-
(2024). dynamic dissipation of neural dynamics via spatio-temporal
[89] N. Chen, Y. Zhang, H. Zen, R. J. Weiss, M. Norouzi, and oscillatorymodes,arXivpreprintarXiv:2312.03489 (2023).
W.Chan,Wavegrad: Estimatinggradientsforwaveformgen- [111] G. E. Crooks, Path-ensemble averages in systems driven far
eration,inInternationalConferenceonLearningRepresenta- fromequilibrium,PhysicalreviewE61,2361(2000).
tions(2020). [112] J. M. Horowitz and T. R. Gingrich, Thermodynamic uncer-
[90] Z.Kong,W.Ping,J.Huang,K.Zhao,andB.Catanzaro,Dif- taintyrelationsconstrainnon-equilibriumfluctuations,Nature
fwave: Aversatilediffusionmodelforaudiosynthesis,inIn- Physics16,15(2020).26
[113] K.Pearson,X.onthecriterionthatagivensystemofdevia-
tionsfromtheprobableinthecaseofacorrelatedsystemof
variables is such that it can be reasonably supposed to have
arisen from random sampling, The London, Edinburgh, and
Dublin Philosophical Magazine and Journal of Science 50,
157(1900).
[114] A.C.BaratoandU.Seifert,Thermodynamicuncertaintyre-
lationforbiomolecularprocesses,Physicalreviewletters114,
158101(2015).
[115] A. Dechant, Minimum entropy production, detailed balance
and wasserstein distance for continuous-time markov pro-
cesses, Journal of Physics A: Mathematical and Theoretical
55,094001(2022).
[116] K.Yoshimura,A.Kolchinsky,A.Dechant,andS.Ito,House-
keepingandexcessentropyproductionforgeneralnonlinear
dynamics,PhysicalReviewResearch5,013017(2023).
[117] T.VanVuandK.Saito,Thermodynamicunificationofopti-
maltransport:Thermodynamicuncertaintyrelation,minimum
dissipation,andthermodynamicspeedlimits,PhysicalReview
X13,011013(2023).
[118] A.Kolchinsky, A.Dechant, K.Yoshimura,andS.Ito,Infor-
mationgeometryofexcessandhousekeepingentropyproduc-
tion,arXivpreprintarXiv:2206.14599 (2022).
[119] G.Wang,Y.Jiao,Q.Xu,Y.Wang,andC.Yang,Deepgener-
ativelearningviaschro¨dingerbridge,inInternationalconfer-
enceonmachinelearning(PMLR,2021)pp.10794–10804.
[120] V. De Bortoli, J. Thornton, J. Heng, and A. Doucet, Diffu-
sionschro¨dingerbridgewithapplicationstoscore-basedgen-
erativemodeling,AdvancesinNeuralInformationProcessing
Systems34,17695(2021).
[121] Y.Song,C.Durkan,I.Murray,andS.Ermon,Maximumlike-
lihoodtrainingofscore-baseddiffusionmodels,Advancesin
neuralinformationprocessingsystems34,1415(2021).
[122] H.Lee,J.Lu,andY.Tan,Convergenceforscore-basedgener-
ativemodelingwithpolynomialcomplexity,AdvancesinNeu-
ralInformationProcessingSystems35,22870(2022).
[123] S. Chen, S. Chewi, J. Li, Y. Li, A. Salim, and A. R. Zhang,
Sampling is as easy as learning the score: theory for diffu-
sionmodelswithminimaldataassumptions,inInternational
ConferenceonLearningRepresentations(2023).
[124] M. S. Albergo and E. Vanden-Eijnden, Building normal-
izing flows with stochastic interpolants, arXiv preprint
arXiv:2209.15571 (2022).
[125] A. A. Pooladian, H. Ben-Hamu, C. Domingo-Enrich,
B. Amos, Y. Lipman, and R. T. Chen, Multisample flow
matching:Straighteningflowswithminibatchcouplings,Pro-
ceedingsofMachineLearningResearch202,28100(2023).
[126] R. Flamary, N. Courty, A. Gramfort, M. Z. Alaya, A. Bois-
bunon, S. Chambon, L. Chapel, A. Corenflos, K. Fatras,
N.Fournier, etal.,Pot: Pythonoptimaltransport,Journalof
MachineLearningResearch22,1(2021).
[127] D. Kingma and J. Ba, Adam: A method for stochastic opti-
mization,inInternationalConferenceonLearningRepresen-
tations(2015).
[128] W. Kutta, Beitrag zur na¨herungsweisen Integration totaler
Differentialgleichungen(Teubner,1901).