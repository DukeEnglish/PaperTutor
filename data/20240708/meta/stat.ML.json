[
    {
        "title": "Linear causal disentanglement via higher-order cumulants",
        "authors": "Paula Leyes CarrenoChiara MeroniAnna Seigal",
        "links": "http://arxiv.org/abs/2407.04605v1",
        "entry_id": "http://arxiv.org/abs/2407.04605v1",
        "pdf_url": "http://arxiv.org/pdf/2407.04605v1",
        "summary": "Linear causal disentanglement is a recent method in causal representation\nlearning to describe a collection of observed variables via latent variables\nwith causal dependencies between them. It can be viewed as a generalization of\nboth independent component analysis and linear structural equation models. We\nstudy the identifiability of linear causal disentanglement, assuming access to\ndata under multiple contexts, each given by an intervention on a latent\nvariable. We show that one perfect intervention on each latent variable is\nsufficient and in the worst case necessary to recover parameters under perfect\ninterventions, generalizing previous work to allow more latent than observed\nvariables. We give a constructive proof that computes parameters via a coupled\ntensor decomposition. For soft interventions, we find the equivalence class of\nlatent graphs and parameters that are consistent with observed data, via the\nstudy of a system of polynomial equations. Our results hold assuming the\nexistence of non-zero higher-order cumulants, which implies non-Gaussianity of\nvariables.",
        "updated": "2024-07-05 15:53:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.04605v1"
    },
    {
        "title": "Understanding the Gains from Repeated Self-Distillation",
        "authors": "Divyansh PareekSimon S. DuSewoong Oh",
        "links": "http://arxiv.org/abs/2407.04600v1",
        "entry_id": "http://arxiv.org/abs/2407.04600v1",
        "pdf_url": "http://arxiv.org/pdf/2407.04600v1",
        "summary": "Self-Distillation is a special type of knowledge distillation where the\nstudent model has the same architecture as the teacher model. Despite using the\nsame architecture and the same training data, self-distillation has been\nempirically observed to improve performance, especially when applied\nrepeatedly. For such a process, there is a fundamental question of interest:\nHow much gain is possible by applying multiple steps of self-distillation? To\ninvestigate this relative gain, we propose studying the simple but canonical\ntask of linear regression. Our analysis shows that the excess risk achieved by\nmulti-step self-distillation can significantly improve upon a single step of\nself-distillation, reducing the excess risk by a factor as large as $d$, where\n$d$ is the input dimension. Empirical results on regression tasks from the UCI\nrepository show a reduction in the learnt model's risk (MSE) by up to 47%.",
        "updated": "2024-07-05 15:48:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.04600v1"
    },
    {
        "title": "Speed-accuracy trade-off for the diffusion models: Wisdom from nonequlibrium thermodynamics and optimal transport",
        "authors": "Kotaro IkedaTomoya UdaDaisuke OkanoharaSosuke Ito",
        "links": "http://arxiv.org/abs/2407.04495v1",
        "entry_id": "http://arxiv.org/abs/2407.04495v1",
        "pdf_url": "http://arxiv.org/pdf/2407.04495v1",
        "summary": "We discuss a connection between a generative model, called the diffusion\nmodel, and nonequilibrium thermodynamics for the Fokker-Planck equation, called\nstochastic thermodynamics. Based on the techniques of stochastic\nthermodynamics, we derive the speed-accuracy trade-off for the diffusion\nmodels, which is a trade-off relationship between the speed and accuracy of\ndata generation in diffusion models. Our result implies that the entropy\nproduction rate in the forward process affects the errors in data generation.\nFrom a stochastic thermodynamic perspective, our results provide quantitative\ninsight into how best to generate data in diffusion models. The optimal\nlearning protocol is introduced by the conservative force in stochastic\nthermodynamics and the geodesic of space by the 2-Wasserstein distance in\noptimal transport theory. We numerically illustrate the validity of the\nspeed-accuracy trade-off for the diffusion models with different noise\nschedules such as the cosine schedule, the conditional optimal transport, and\nthe optimal transport.",
        "updated": "2024-07-05 13:35:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.04495v1"
    },
    {
        "title": "Machine Learning for Complex Systems with Abnormal Pattern by Exception Maximization Outlier Detection Method",
        "authors": "Zhikun ZhangYiting DuanXiangjun WangMingyuan Zhang",
        "links": "http://arxiv.org/abs/2407.04248v1",
        "entry_id": "http://arxiv.org/abs/2407.04248v1",
        "pdf_url": "http://arxiv.org/pdf/2407.04248v1",
        "summary": "This paper proposes a novel fast online methodology for outlier detection\ncalled the exception maximization outlier detection method(EMODM), which\nemploys probabilistic models and statistical algorithms to detect abnormal\npatterns from the outputs of complex systems. The EMODM is based on a two-state\nGaussian mixture model and demonstrates strong performance in probability\nanomaly detection working on real-time raw data rather than using special prior\ndistribution information. We confirm this using the synthetic data from two\nnumerical cases. For the real-world data, we have detected the short circuit\npattern of the circuit system using EMODM by the current and voltage output of\na three-phase inverter. The EMODM also found an abnormal period due to COVID-19\nin the insured unemployment data of 53 regions in the United States from 2000\nto 2024. The application of EMODM to these two real-life datasets demonstrated\nthe effectiveness and accuracy of our algorithm.",
        "updated": "2024-07-05 04:30:41 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.04248v1"
    },
    {
        "title": "Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs",
        "authors": "Faisal HammanPasan DissanayakeSaumitra MishraFreddy LecueSanghamitra Dutta",
        "links": "http://arxiv.org/abs/2407.04173v1",
        "entry_id": "http://arxiv.org/abs/2407.04173v1",
        "pdf_url": "http://arxiv.org/pdf/2407.04173v1",
        "summary": "Fine-tuning large language models (LLMs) on limited tabular data for\nclassification tasks can lead to \\textit{fine-tuning multiplicity}, where\nequally well-performing models make conflicting predictions on the same inputs\ndue to variations in the training process (i.e., seed, random weight\ninitialization, retraining on additional or deleted samples). This raises\ncritical concerns about the robustness and reliability of Tabular LLMs,\nparticularly when deployed for high-stakes decision-making, such as finance,\nhiring, education, healthcare, etc. This work formalizes the challenge of\nfine-tuning multiplicity in Tabular LLMs and proposes a novel metric to\nquantify the robustness of individual predictions without expensive model\nretraining. Our metric quantifies a prediction's stability by analyzing\n(sampling) the model's local behavior around the input in the embedding space.\nInterestingly, we show that sampling in the local neighborhood can be leveraged\nto provide probabilistic robustness guarantees against a broad class of\nfine-tuned models. By leveraging Bernstein's Inequality, we show that\npredictions with sufficiently high robustness (as defined by our measure) will\nremain consistent with high probability. We also provide empirical evaluation\non real-world datasets to support our theoretical results. Our work highlights\nthe importance of addressing fine-tuning instabilities to enable trustworthy\ndeployment of LLMs in high-stakes and safety-critical applications.",
        "updated": "2024-07-04 22:22:09 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.04173v1"
    }
]