Pre-print, under peer-review, to IEEE ICRA2025.
Control Industrial Automation System with Large Language Models
Yuchen Xia, Nasser Jazdi, Jize Zhang, Chaitanya Shah, Michael Weyrich *
Abstract— Traditional industrial automation systems require A structured approach is required to link the digital
specialized expertise to operate and complex reprogramming to functionality of LLMs with the physical realm of industrial
adapt to new processes. Large language models offer the automation.
intelligence to make them more flexible and easier to use.
In this paper, we introduce a novel framework for
However, LLMs’ application in industrial settings is
controlling and configuring industrial automation equipment
underexplored. This paper introduces a framework for
using large language models, enabling more flexible, intuitive
integrating LLMs to achieve end-to-end control of industrial
and knowledge-informed automation systems. As our
automation systems. At the core of the framework are an agent
system designed for industrial tasks, a structured prompting contribution, this framework includes:
method, and an event-driven information modeling mechanism
• An integral system design for applying large
that provides real-time data for LLM inference. The framework
language models in industrial automation.
supplies LLMs with real-time events on different context
semantic levels, allowing them to interpret the information, • A proof-of-concept implementation on a physical
generate production plans, and control operations on the production system with quantitative evaluation.
automation system. It also supports structured dataset creation
for fine-tuning on this downstream application of LLMs. Our • A systematic approach for creating datasets for fine-
contribution includes a formal system design, proof-of-concept tuning LLMs to adapt a general pre-trained model for
implementation, and a method for generating task-specific this specific industrial application.
datasets for LLM fine-tuning and testing. This approach enables
As a result, we present an LLM-controlled automation
a more adaptive automation system that can respond to
spontaneous events, while allowing easier operation and system that can interpret user tasks specified in natural
configuration through natural language for more intuitive language, generate a production plan, and execute operations
human-machine interaction. We provide demo videos and on the physical shop floor. The configuration of control logic
detailed data on GitHub: https://github.com/YuchenXia/LLM4IAS is enabled by prompt design, and the application-specific
adaptation of the LLMs is enabled by supervised fine-tuning
I. INTRODUCTION
on data collected during system operation.
Traditional industrial automation systems are rigid,
II. REQUIREMENTS AND SYSTEM SETUP
requiring specialized expertise for any modification or
reconfiguration. For instance, when the system needs to be This section introduces the required technological
adapted to produce new product variants or execute different foundation in typical industrial automation domain that
operations, significant effort is required to design and enables the downstream application of LLM. Based on this
implement the necessary changes. This process is often foundation, we establish a system depicted in Figure 1.
hampered by several challenges, including the need for an in-
A. Interoperability
depth understanding of the complicated equipment and the
time-consuming effort in translating user requirements into Interoperability is a fundamental prerequisite for
executable programs. These factors contribute to delays and implementing intelligent systems. This concept involves two
increased costs, with reconfiguration often constrained by key aspects: synchronized data acquisition and unified control
knowledge barriers, the intricate nature of reprogramming interface.
tasks, and possibly inefficient communication between user
PLCs are commonly central to industrial automation,
and programmer. As a result, traditional industrial automation
serving as nodes for field data collection and control point
systems are not only inflexible but also costly and time-
exposure. Building on this, OPC UA[3] enables seamless
inefficient when adapting to new demands[1].
interoperability by providing a unified interface to connect
Large language models offer transformative potential in PLCs with higher-level systems across various devices and
industrial automation. They can perform reasoning based on platforms. In robotics and automation systems that utilize
the knowledge internalized during pre-training, interpret both ROS, unified data and control interfaces can be established via
general and domain-specific language, and generate on- ROS communication mechanisms. For proprietary automation
demand responses to varied inputs. While LLMs have modules, communication can be achieved through industrial
demonstrated their utility in general chatbot applications[2], Ethernet TCP/IP.
their tailored application in industrial contexts remains
Utilizing these technology stacks, various automation
underexplored. The challenge lies in effectively adapting these
modules can be digitally integrated through a unified data and
capabilities to deliver tangible value in the industrial domain.
control interface. This integration facilitates the creation of a
*All authors are with the Institute of Industrial Automation and Software Accompanying demo video available: https://youtu.be/GhBoxGfjRIE
Engineering, University of Stuttgart, Stuttgart 70550, Germany. Institutional e-mail contacts:
GitHub Repository: https://github.com/YuchenXia/LLM4IAS {yuchen.xia | nasser.jazdi | michael.weyrich}@ias.uni-stuttgart.de
1
Institutional email contacts: yuchen.xia@ias.uni-stuttgart.de; nasser.jazdi@ias.uni-stuttgart.de; michael.weyrich@ias.uni-stuttgart.de.
Students’ email contacts: st171260@stud.uni-stuttgart.de (Jize Zhang); st181599@stud.uni-stuttgart.de (Chaitanya Shah)cyber environment, providing access to the physical system， determining which events should be emitted on data changes
also referred to as a Cyber-Physical System[4]. and customize the text content for each agent, as shown in
Figure 3.
Figure 3 A snippet of the events subscribed by an LLM agent.
C. LLM Agent
Recent studies on LLM applications have focused on the
concept of LLM agents [8]. In the scope of this paper, an agent
is defined as a software component that 1) is responsible for
solving specific task requirements, 2) is associated with a
physical asset and can be embodied in the form of an
automation module.
Building on our previous work [9], [10], which introduced
a hierarchical manager/operator LLM agent structure for
Figure 1 The overall system setup
automation system planning and control, this paper presents a
refined and more scalable system design. A new fundamental
B. Digital Twins and Semantics
component of this system design is an event log memory,
A digital twin is software that provides a synchronized
combined with subscription and broadcasting mechanism that
digital representation of physical assets[5], [6]. It maintains
provides time-ordered information to agents, thereby keeping
information models that integrate field data and offers services
them informed about ongoing activities.
to other software components. Overall, it serves as the
foundation for a runtime environment supporting high-level Based on the tasks, the system features three distinct agent
applications, especially indispensable for LLM system. roles:
Another critical aspect for integrating LLM in industrial • Manager Agent: This agent responds to user
applications is semantics. Systems operating at different levels commands or events and generates an operational plan.
often interpret the same data differently depending on the It assigns subtasks to operator agents through the event
context[7]. For instance, “a bit flip from 0 to 1” in a PLC log and monitors the plan execution. This agent type
program indicates “motor on” at the field device level, leverages the reasoning capability of LLMs in
“workpiece transport initiation” at a higher control level, and problem-solving and planning.
“logistics task starts” at the production planning level. These
• Operator Agent: This agent executes tasks assigned
variations of semantics become more apparent when viewed
by the manager agent or reacts to events by generating
through the lens of the automation pyramid, as illustrated in
function call commands to control the ongoing
Figure 2.
production process. The operator agents are embodied
with diverse automation modules to execute
operations. This agent type leverages the reasoning and
code understanding capabilities to control the
operations within the automation system.
• Summarization Agent: This agent subscribes to the
event log and provides a summary of system operations
for the user. LLMs’ long context understanding and
alignment with human preferences are highly relevant
for this task role. (cf. Figure 1)
Figure 2 View of automation system modules and components from
Each agent type has clearly defined responsibilities and
a hierarchy perspective: Automation Pyramid.
interacts with the system according to its role using prompts.
This necessitates a semantic enhancement process across
D. Data-driven LLM Application and Testing
various abstraction levels. We develop a data observer
software component (refer to Figure 1) for this purpose. The To assess the performance of the agent system performing
data observer monitors data in information models and automation tasks, we utilize this setup to generate test datasets.
converts them into textual expressions on different semantic These datasets comprise pairs of system-generated events and
abstraction levels. As different LLM-agents have distinct agent prompts alongside the expected outputs. This enables
requirements for how data and changes should be interpreted systematic testing of the LLMs’ responses under various
in their specific task contexts, we pre-define the rules operational conditions.
2Furthermore, the established framework enables the
runtime environment for LLM agents through digital twins of
the industrial automation system. If historical records of
changes in the information model in the digital twin system are
available, these can be utilized to develop datasets tailored for
,
downstream automation and robotics tasks. This not only
allows for testing of the LLMs but also facilitates the post-
training of general LLMs to adapt them for the use case of
controlling automation system. This agent system primarily
processes textual data, where the effectiveness of the system Figure 5 LLM agent processing cycle for command generation
hinges on the LLMs’ ability to accurately interpret and reason
with the digital twin system generated textual events. Agent System 𝓐𝓢:
𝒜𝒮 ={𝒜 ,𝒜 ,…,𝒜 }
In the following section, we further elaborate on the details ℳ1 ℳ2 ℳ𝒾
An agent system 𝒜𝒮 consists of several agents, and each
of the proposed system for this application and provide a
formal description of the framework’s conceptual and agent 𝒜 ℳ𝒾 (as illustrated in Figure 5) is responsible for
structural composition. controlling a specific automation module ℳ𝒾.
Automation Module 𝓜 :
𝓲
III. THE AGENT SYSTEM FRAMEWORK DESIGN
ℳ =(𝒞 ,ℱ ,ℰ )
𝒾 ℳ𝒾 ℳ𝒾 ℳ𝒾
The organization of agent collaboration is crucial for Note that an overall automation system consists of multiple
effective application. For manufacturing process planning and automation modules {ℳ ,ℳ ,…,ℳ}.
1 2 𝒾
control, we adopt a manager-operator model, applied across Each individual automation module ℳ comprises a tuple,
𝒾
different abstraction levels following the automation pyramid where:
(cf. Figure 2). Additionally, we introduce a summarization
- 𝒞 is the set of components of the ℳ.
agent to generate reports based on the event log for users, as
ℳ𝒾 𝒾
- ℱ is the set of functions exposed by ℳ.
shown in Figure 1, though it is omitted in this section for ℳ𝒾 𝒾
- ℰ is the set of events that are in the scope of ℳ.
brevity. ℳ𝒾 𝒾
The individual events in set ℰ are pre-defined,
A. Manager Agent and Operator Agent for Planning and
ℳ𝒾
automatically emitted upon state changes in the module. This
Control
events generation mechanism maps low-semantic data to
The manager agent is a planning module responsible for high-semantic information for process planning and control.
processing user input tasks and decomposing them into sub-
Event Log Memory 𝓔 that collects all the events:
tasks to form a production plan. Operator agents are designed
ℰ ={(ℯ ,𝑡 ),(ℯ ,𝑡 ),…,(ℯ ,𝑡 )∣𝑡 <𝑡 <⋯<𝑡 }
to control specific automation modules, receiving tasks from 1 1 2 2 𝓉 𝑡 1 2 𝑡
The event log memory records a sequence of all events
the manager and executing them accordingly.
(ℯ ,𝑡 ) ordered chronologically, representing the history of
𝓉 𝑡
state changes in the automation system.
Subscription Mechanism 𝓢:
ℰ =𝒮(𝒜 )⊆ℰ
𝒜ℳ𝒾 ℳ𝒾
An agent 𝒜 subscribes to the event log memory ℰ to
ℳ𝒾
retrieve relevant events into its own event log memory ℰ .
𝒜ℳ𝒾
𝒮(𝒜 )⊆ℰ denotes a selective function 𝒮 that allows the
ℳ𝒾
agent 𝒜 to subscribe to events from ℰ, thereby limiting the
ℳ𝒾
agent’s scope of observation to relevant events.
Agent Prompt 𝓟 :
Figure 4 The agent system consisting of manager agent for planning 𝓐𝓜𝓲
and operator agents for controlling 𝒫 =Textual(ℛ ,𝒞 ,ℱ ,𝒮𝒪𝒫 ,ℰ )
𝒜ℳ𝒾 𝒜ℳ𝒾 ℳ𝒾 ℳ𝒾 𝒜ℳ𝒾 𝒜ℳ𝒾
A textual represented prompt 𝒫 for an agent 𝒜 that
We provide a formal specification of the agent 𝒜ℳ𝒾 ℳ𝒾
integrates the elements listed in TABLE I.
framework’s conceptual and structural composition, as well as
From LLM Generated Output 𝓞 :
the relationships between the components, which underpin its 𝓵𝓵𝓶
software-technical implementation. 𝒪 ℓℓ𝓂 =(𝒪 𝓇ℯ𝒶𝓈ℴ𝓃,𝒪 𝒻𝒸)
𝒪 consists of LLM’s generated reasoning and a function
B. Formal Description of the LLM Agent System ℓℓ𝓂
call.
In the context of this paper, an LLM agent is a software
C. The Prompting Method
component that processes textual data to control an
automation module. The collaborating LLM agents form an The design of the prompt is pivotal in this framework. The
agent system, as illustrated in Figure 4, with the LLM agent prompt serves several purposes except as merely instruction
construct shown in Figure 5. for LLM agents, but also to 1) incorporate knowledge about
the automation system, 2) serve as an integration point to
connect the LLM with real-time events, and 3) later serves as
prefix when training a LLM in a supervised fine-tuning
manner, and, notably, tokens in the prompt are not included in
3the loss calculation. The construct of the prompt is described event descriptions are pre-defined in the data observer and use
in TABLE I. natural language to describe high-level semantic information
about system activities. The emitted events are recorded in the
TABLE I. CONSTRUCT OF THE PROMPT event log and are then consumed by the LLM agents according
to their subscription scopes, allowing the agents to generate
Prompt
Definition Typical Examples a appropriate commands in response.
Section
Role You are the operator of an automation module
Describe the role and the 3) Standard Operation Procedure (SOP)
Definition task responsibility of the called “Storage Station”, responsible for
𝓡 𝓐𝓜𝓲 agent. h tra an nd spli on rg t o of n w coo nrk vp ei ye oc re ss . and directing material provIn
id
em
s
a gn uu if da ec lt iu nr ei sn g f,
o
rS cta on nd sa isr td
e
nO
t
p ae nr da t sin afg
e
P or po ec re ad tiu or ne
.
I( nS O oP ur)
- BG56 is a proximity sensor located at one end
of the Conveyor C1… approach, we repurpose this concept of “SOP” to refer to
Component - H1 is a holder located in the middle of the
Description Entries of component Conveyor C2 at the export verification point, instructions for the LLM on how to respond to specific
𝓒 description about the Holder H1 can hold the workpiece in position. conditions during machine operation.
𝓜𝓲 sensors and actuators. - TF81 is an RFID sensor located in the middle
of the Conveyor C1 and at Holder H2 of the
pick and place point; it can read the workpiece Similar to how traditional SOPs guide human operators,
information. the SOP in the prompt informs the LLM about standard
Callable The parametrized functions - conveyor_1_run(direction, time)
Function provided by digital twins - This function is used to start Conveyor C1 and protocols for operating machines in specified situations.
middleware that can be run it in a specified direction for a specified
𝓕 𝓜𝓲 invoked by the agent. duration. In contrast to “n-shot” prompting methods , this SOP-
Standard - After detecting a carrier at the entrance, based approach enables the configuration of LLMs at a higher
Operation Specify the behavior of the transport the carrier to the pick and place point.
agent under normal - When the carrier arrives at the pick and place level of abstraction and allows for integration of behavioral
Procedure
operation. point, query the workpiece position in the
𝓢𝓞𝓟 𝓐𝓜𝓲 storage. knowledge. From the perspective of the user who needs to
- A series of events will provide you the modify system behaviors, this approach facilitates
A Inu stx ri uli ca tr ioy n O g ou uth i td pe i ur n t g Lin L ws Mt ir thu c tt oio n g ds e e n sie er rf a eo t der - i s Yn y of so uter m sm ha . o t uio ldn fa ob lo lou wt t h the e c fu or lr le on wt is nt ga t ie n o pf u tt h ae n d p Sr Oo Pgr fa om r m LLin Mg t ah ge e s ny ts st . e m using natural language by specifying
format. output pattern to generate your response in
JSON format. First provide a short reason and For situations that are not considered in SOP, the LLM
then generate a function call.
[Manager][12:04:23] task assigned: retrieve a agents usually, according to our experiment observation,
Event Log The dynamic information 'white plastic cylinder' from the storage station. generate commands based on common sense, enabling them to
Input that require an agent to [ 'wSy hs itt ee m pl] a[ s1 t2 ic:0 c4 y: l2 i3 n] d eta r's k fr ore mc e ti hv ee d st: o r re at gri ee v ste a ta i on. handle scenarios flexibly based on the information given in the
𝓔 𝓐𝓜𝓲 react. [System][12:04:23] BG56 detects a carrier at the prompt, though the responses are not always accurate.
infeed of conveyor C1.
Output (to be { “reason”: “Carrier detected at entrance,
generated)
T thh ee g ae gn ee nr ta te tod c co om nm troan
l
d
t
b hy
e initiate transport to pick and place point”, 4) Reason in LLM output
“command”: “conveyor_1_run('forward',
𝓞 𝓵𝓵𝓶 system. 13)” } Before generating a command, an LLM is instructed to
a. more comprehensive examples can be accessed from GitHub first generate a reason. This serves three main purposes: First,
Next, we provide a detailed explanation of several special this design mirrors the Reflection-Act (ReAct) process [11] in
components within this prompt design. a minimalist manner. Second, it enhances transparency and
explainability, allowing for deeper evaluation by comparing
1) Event log
the generated reason with the reference reason. Third,
This design of the event log is driven by the rationale that
reference reasons in the dataset can provide additional
time and information are indispensable in control and
knowledge during fine-tuning and enable calculating loss and
planning tasks. The event log provides the LLM with dynamic
weight update on more data, helping the LLM to learn how
information about production operations in a time-sequential
and why specific planning and control decisions are made.
order, organized as events. Based on our consideration and
evaluation, this is a succinct way to represent the required IV. DATASET CREATION
information in text form. The first label indicates the scope of
In this section, we introduce how we create and organize
the message subscription, the second label indicates the source
the dataset for testing and training the LLM for this
of the message, and the third label is a timestamp,
downstream use case, as illustrated in Figure 7.
accompanied by a textual description of the event occurring at
that moment, as illustrated in Figure 6.
Figure 7 The construct of the dataset for testing and training
Figure 6 A snippet of the subscribed events from the digital twin A. Dataset Creation Based on the Agents System and
middleware for “Storage Station”. Prompting Method
The LLM agents generate function calls based on the
2) Event emission from digital twin middleware
information provided in the prompt. During operation, the
An event emission is automatically triggered upon state
underlying digital twin system automatically emits new events
changes in the information models, messages from other
in the event log. The agent is continuously updated with real-
agents, or the initiation or completion of an operation. These
time textual information to generate a response, which
4includes a function call to control the equipment and a brief V. EXPERIMENTS
explanation for the reason.
Using the created dataset, we first evaluate several open-
Each prompt, updated with a new event, is considered an source pre-trained and a proprietary model GPT-4o. Then, we
individual test point. The combination of this input (the applied supervised fine-tuning to further train these models on
prompt with the new event) and the expected correct output the created dataset.
(the LLM’s generated function call and reasoning) forms a
The objectives are twofold: firstly, to evaluate the fine-
test case. These test cases are organized into test suites, each
tuning enhancement of the LLM agent’s performance on this
corresponding to a specific operational task procedure—such
specific task; and secondly, to gain insight into the cost-
as an inventory management process or a sequence of steps in performance trade-offs involved.
a painting process. Collectively, these test suites form a
comprehensive dataset designed to evaluate the LLM’s A. Test case creation
ability to perform control tasks within the automation system. In contrast to normal operation where LLM agents observe
events before deciding on machine operation, dataset creation
B. Formal Description of the Dataset
involves a reverse process, as depicted in Figure 9.
Again, we provide a formal specification of the
In this case, the dataset is created without LLM agents, but
conceptual and structural composition that underpins the
with direct user input. With a specific task in mind, the user
software technical implementation.
manually operates the command interface to interact with the
Test Point 𝓣 : automation system. As this process unfolds, the digital twin
𝓹
𝒯 =(𝒫 ∪{ℰ }) system automatically generates and records relevant events.
𝓅 𝒜ℳ𝒾 𝒜ℳ𝒾,[𝓉+1,𝓉+𝓀]
The user finally provides a description of the intended task
A test point 𝒯 is defined as an agent prompt 𝒫 containing
𝓅 𝒜ℳ𝒾 process. This approach captures the three essential elements
incremental 𝓀 new events ℰ for testing the
𝒜ℳ𝒾,[𝓉+1,𝓉+𝓀] for dataset: the events, the command calls, and the initial user
output of an agent 𝒜 ℳ𝒾. When expanded: task request. The dataset contains the knowledge necessary for
𝒯 = successful execution of intended tasks.
𝓅
Textual(ℛ ,𝒞 ,ℱ ,𝒮𝒪𝒫 ,ℰ ∪ℰ )
𝒜ℳ𝒾 ℳ𝒾 ℳ𝒾 𝒜ℳ𝒾 𝒜ℳ𝒾,[0,𝓉] 𝒜ℳ𝒾,[𝓉+1,𝓉+𝓀]
Test Case 𝓣 :
𝓬
𝒯 =(𝒯 ,𝒪∗ )
𝒸 𝓅 ℓℓ𝓂
A test case is the combination of a test point 𝒯 and the
𝓅
expected reference output 𝒪∗ from the LLM, where 𝒪∗
ℓℓ𝓂 ℓℓ𝓂
consists of the expected function call to be generated and a
reference reason:
𝒪 ℓ∗
ℓ𝓂
=(𝒪 𝓇∗ ℯ𝒶𝓈ℴ𝓃,𝒪 𝒻∗ 𝒸)
Test Suite 𝓣 :
𝓼 Figure 9 Dataset creation process
𝒯 ={𝒯1,𝒯2,…,𝒯𝓃}
𝓈 𝒸 𝒸 𝒸
Test cases 𝒯1 to 𝒯𝓃 are organized into test suite 𝒯, each Using this approach, we create various task scenarios for
𝒸 𝒸 𝓈
corresponding to a specific operational task scenario. handling typical situations in factory operations, such as
Dataset 𝓓: processing user orders, responding to spontaneous events, or
𝒟 ={𝒯1,𝒯2,…,𝒯𝓃} handling abnormalities. Our initial collected dataset contains
𝓈 𝓈 𝓈
The complete dataset 𝒟 consists of a collection of test suites 100 test cases 𝒯 =(𝒯 ,𝒪∗ ), each consisting of a complete
𝒸 𝓅 ℓℓ𝓂
from 𝒯1 to 𝒯𝓃, representing various task scenarios. The prompt and the expected LLM output. This dataset can be used
𝓈 𝓈
dataset is used for both testing and fine-tuning the LLM for the to assess the performance of pre-trained LLMs in controlling
application. industrial automation systems.
Besides its usage in testing, it also serves as training data In our initial dataset, 68% of the control command
for supervised fine-tuning, as illustrated in Figure 8. This fine- generation involves repetitive tasks in our initially prepared
tuning helps train a general LLM to internalize application- dataset, where the LLM agents should follow the SOP
specific knowledge for controlling automation equipment and routines. The remaining 32% consist of non-routine tasks,
learn patterns from process knowledge, as specified in the requiring LLM agents to respond to unprecedented events
prompts, the correct function calls and the reasons. through autonomous decision-making.
B. Metrics for Evaluation
We apply two metrics to evaluate the system’s performance.
• Correctness Rate: Measures whether the generated
command matches the reference command in the dataset.
• Reason Plausibility: Assessed through human evaluation,
using a Likert scale from 1 to 5 to rate the plausibility of
the generated reason.
Figure 8 Two uses of the created dataset: Testing and Post-training
5These two metrics together provide a more granular metric which reactions have not been instructed in agent prompts. We
to identify loss. In some cases, the command is incorrect while distinguish between these two types of tasks in our evaluation.
the reason may be plausible.
Based on the evaluation results, GPT-4 generally
C. Special requirements of automation tasks outperforms other open-source models in interpreting agent
prompts and events to generate control commands, though
Given the nature of industrial automation, there are two
their performance varies significantly. Each model also
main aspects of the requirements:
exhibits distinct “personalities” in this use case.
• Accuracy in Repetitive Operations: Industrial
2) Evaluation of post-trained LLM based on created
automation tasks often require 100% accuracy in repetitive
dataset
operations. This repeatability implies that some routine
Using the collected dataset, we apply supervised fine-
tasks can be anticipated. This requirement can be evaluated
tuning (SFT) to assess how training open-source models can
by assessing whether the LLM agents follow the SOP to
improve the LLM’s performance for this specific downstream
successfully complete the tests, or whether the model
task. This training has the potential to enable the customization
improves by learning from the dataset to perform in-
of a general LLM for intelligent control of specialized
sample tasks.
automation equipment. For GPT-4o, we used OpenAI’s
• Handling Unexpected Events: The system shall be proprietary fine-tuning API to explore the capabilities that
capable of responding to unexpected events not predefined LLMs can achieve, even though the training methods may
in the SOP or present in the training dataset. It should vary.
demonstrate generalization by flexibly handling
For two main considerations, we train the models on the
unforeseen situations that were not anticipated during
test dataset: 1) the machine is designed to execute specialized
development. The language model should use its learned
tasks most of time repetitively, and 2) the goal of fine-tuning
knowledge to generate appropriate responses to
is to evaluate whether the model can effectively learn the
spontaneous events—an ability typically lacking in
machine’s operational knowledge. Additionally, in one of our
traditional automation systems.
concurrent research experiments, we observed that larger
Based on these considerations, we perform a LLMs generally exhibit less significant overfitting or
comprehensive evaluation and model fine-tuning. catastrophic forgetting than smaller LLM during a k-fold
cross-validation fine-tuning based on limited results for this
D. The evaluation
use case. However, we will address this interesting
We use different LLMs as inference engines to power the hypothetical finding in the future as we work to overcome cost
agent systems. GPT-4o is selected to represent the state-of-the- constraints and dataset scarcity issue.
art performance achievable by LLMs, while other open-source
models are chosen to represent those that can be practically OpenAI’s model and fine-tuning services outperform other
deployed in on-premises industrial settings. To account for the models, and the GPT-4o model quickly learns from the
trade-off between model complexity and performance, we samples how to control the automation systems. Other models
compare larger models (70B range) with smaller ones (7B also demonstrated reasonably good performance.
range). We chose GPT-4o[2], Llama3 models[12], Qwen2 Interestingly, fine-tuned smaller LLMs did not necessarily
models[13] and Mistral models[14] for our experiments. underperform in this particular use case. However, our
contingency LoRA[15] fine-tuning yielded poor results in our
TABLE II. EVALUATION OF PRE-TRAINED AND FINE-TUNED LLMS experiments and led to a decrease in model performance.
An accuracy of less than 100% means that the results are
Evaluation based on 100 test points***
GPT-4o 70L Bl -a Im nsa t- r3 u- ct Lla Inm sa tr- u3- c8 t B-Qw Ine sn t2 r- u7 c2 tB - Q Iw ne sn tr2 u-7 ctB - M Inis st tr ra ul c- t7 -B v0x .8 2- IM nsi ts rt ura cl t- -7 v0B .- 2 n aso t f itu ll cy o r ue ll di ab rl ee s ufo ltr d ii nr ec st tl oy p c so n at nro dl li en rg ro a rn s au dt uo rm ina gt io on p s ey ras tt ie om n, .
Pre-trained
81% | 4.7 75% | 4.3 37% | 2.8 70% | 4.0 65 | 3.7 29% | 2.4 45% | 2.9
(all) However, they can be developed as an assistant system,
Pre-trained
(SOP) 100% | 5.0 87% | 4.5 53% | 3.1 85% | 4.5 63% | 3.6 34% | 2.4 37% | 2.5 proposing next actions for human supervisors to approve in a
Pre-trained 41% | 4.0 50% | 3.8 3% | 2.2 38% | 3.0 69% | 4.0 19% | 2.3 63% | 3.7 human-machine collaboration use case scenarios.
(Unexpected)
SFT
100% | 5.0 95% | 4.8 96% | 4.9 * 66% | 3.9 97% | 4.9 45% | 3.1 ** N.A.
(all)
SFT
100% | 5.0 94% | 4.8 99% | 4.9 * 82% | 4.4 97% | 4.9 61% | 3.6 ** N.A.
VI. CONCLUSION
(SOP)
SFT
100% | 5.0 97% | 4.9 91% | 4.7 * 31% | 2.8 97% | 5.0 9% | 2.3 ** N.A.
In this paper, we introduce a novel application-oriented
(Unexpected) framework that enables the use of LLMs to control industrial
Value: (accuracy of their generated commands)% | (averaged reason plausibility 1-5) automation systems. For system developers, the development
* : we ran out of GPU capacity and used LoRA instead of full fine-tuning for the Qwen2-72B-model.
can be divided into two phases: 1) modularizing the system
** N.A.: Our full-fine-tuning made Mistral-7B model unstable, and it generated unusable echo texts.
and creating interoperable interfaces to establish the physical
***: Details about the SFT, dataset and evaluation sheets on GitHub: YuchenXia/LLM4IAS
and digital foundation for agents, and 2) creating datasets and
1) Evaluation of pre-trained LLM applying LLM-specific prompting and training methods. The
We begin by evaluating the original pre-trained models. In result is an end-to-end solution that allows an LLM to control
automation tasks, 1) some are routine processes where the automation systems, with the reconfiguration process and
LLM agent can follow SOP guidelines in agent prompts to human machine interactions made more intuitive through
operate the automation system, while 2) others require the natural language. We are continuing to refine our design and
agent to autonomously respond to unexpected events, for implementation to further increase the technology readiness
level and will post new results from this ongoing research.
6REFERENCES ACKNOWLEDGMENT
[1] Y. Fan et al., “A digital-twin visualized architecture for This work was supported by Stiftung der Deutschen
Flexible Manufacturing System,” J Manuf Syst, vol. 60, Wirtschaft (SDW) and the Ministry of Science, Research and
pp. 176–201, Jul. 2021, doi: the Arts of the State of Baden-Wuerttemberg within the
10.1016/J.JMSY.2021.05.010. support of the projects of the Exzellenzinitiative II.
[2] OpenAI et al., “GPT-4 Technical Report,” Mar. 2023,
[Online]. Available: https://arxiv.org/abs/2303.08774v6
[3] A. Veichtlbauer, M. Ortmayer, and T. Heistracher, “OPC
UA integration for field devices,” Proceedings - 2017
IEEE 15th International Conference on Industrial
Informatics, INDIN 2017, pp. 419–424, Nov. 2017, doi:
10.1109/INDIN.2017.8104808.
[4] T. Müller, N. Jazdi, J. P. Schmidt, and M. Weyrich,
“Cyber-physical production systems: enhancement with a
self-organized reconfiguration management,” Procedia
CIRP, vol. 99, pp. 549–554, Jan. 2021, doi:
10.1016/J.PROCIR.2021.03.075.
[5] B. Ashtari Talkhestani et al., “An architecture of an
Intelligent Digital Twin in a Cyber-Physical Production
System,” At-Automatisierungstechnik, vol. 67, no. 9, pp.
762–782, Sep. 2019, doi: 10.1515/AUTO-2019-
0039/MACHINEREADABLECITATION/RIS.
[6] D. Dittler, P. Lierhammer, D. Braun, T. Müller, N. Jazdi,
and M. Weyrich, “A Novel Model Adaption Approach for
intelligent Digital Twins of Modular Production Systems,”
IEEE International Conference on Emerging Technologies
and Factory Automation, ETFA, vol. 2023-September,
2023, doi: 10.1109/ETFA54631.2023.10275384.
[7] N. Sahlab, N. Jazdi, and M. Weyrich, “An Approach for
Context-Aware Cyber-Physical Automation Systems,”
IFAC-PapersOnLine, vol. 54, no. 4, pp. 171–176, Jan.
2021, doi: 10.1016/J.IFACOL.2021.10.029.
[8] L. Wang et al., “A survey on large language model based
autonomous agents,” Front Comput Sci, vol. 18, no. 6, pp.
1–26, Dec. 2024, doi: 10.1007/S11704-024-40231-
1/METRICS.
[9] Y. Xia, M. Shenoy, N. Jazdi, and M. Weyrich, “Towards
autonomous system: Flexible modular production system
enhanced with large language model agents,” IEEE
International Conference on Emerging Technologies and
Factory Automation, ETFA, vol. 2023-September, 2023,
doi: 10.1109/ETFA54631.2023.10275362.
[10] Y. Xia, J. Zhang, N. Jazdi, and M. Weyrich,
“Incorporating Large Language Models into Production
Systems for Enhanced Task Automation and Flexibility,”
Automation 2024, Jul. 2024, doi:
10.51202/9783181024379.
[11] S. Yao et al., “ReAct: Synergizing Reasoning and Acting
in Language Models,” Oct. 2022, [Online]. Available:
https://arxiv.org/abs/2210.03629v3
[12] A. Dubey et al., “The Llama 3 Herd of Models,” Jul. 2024,
[Online]. Available: https://arxiv.org/abs/2407.21783v2
[13] A. Yang et al., “Qwen2 Technical Report,” Jul. 2024,
[Online]. Available: https://arxiv.org/abs/2407.10671v4
[14] A. Q. Jiang et al., “Mixtral of Experts,” Jan. 2024,
[Online]. Available: https://arxiv.org/abs/2401.04088v1
[15] E. Hu et al., “LoRA: Low-Rank Adaptation of Large
Language Models,” ICLR 2022 - 10th International
Conference on Learning Representations, 2022.
7