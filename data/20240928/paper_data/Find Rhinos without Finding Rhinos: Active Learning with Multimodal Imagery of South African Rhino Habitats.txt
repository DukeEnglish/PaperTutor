Find Rhinos without Finding Rhinos: Active Learning with Multimodal Imagery
of South African Rhino Habitats
LuciaGordon1, NikhilBehari2, SamuelCollier1, ElizabethBondi-Kelly2, JacksonA.
Killian1, CatherineRessijac1, PeterBoucher1, AndrewDavies1 and MilindTambe1
1HarvardUniversity
2MasssachusettsInstituteofTechnology
luciagordon@g.harvard.edu,nbehari@media.mit.edu,scollier1@g.harvard.edu,ecbk@umich.edu,
{jkillian,catherine ressijac,pboucher,andrew davies}@g.harvard.edu,milind tambe@harvard.edu
Abstract
Much of Earth’s charismatic megafauna is endan-
gered by human activities, particularly the rhino,
which is at risk of extinction due to the poach-
ing crisis in Africa. Monitoring rhinos’ move-
ment is crucial to their protection but has unfortu-
nately proven difficult because rhinos are elusive.
Therefore, instead of tracking rhinos, we propose Figure 1: Left: A white rhino midden next to a road in iMfolozi
[Marneweck,2013]. Right: Amiddeninourdatasetphotographed
the novel approach of mapping communal defe-
byadrone.Middensboxedingreen. cation sites, called middens, which give informa-
tionaboutrhinos’spatialbehaviorvaluabletoanti-
poaching,management,andreintroductionefforts.
In South Africa, one of the rhino’s last strongholds, poach-
This paper provides the first-ever mapping of
inghasdrivena59%declineinKrugerNationalPark’srhino
rhino midden locations by building classifiers to
population since 2013 [SavetheRhinoInternational, 2022].
detect them using remotely sensed thermal, RGB,
As rhinos have disproportionately large impacts on ecosys-
and LiDAR imagery in passive and active learn-
temstructureandfunctionduetotheirroleasmegaherbivores
ing settings. As existing active learning methods
[Ferreiraetal.,2015],itisimperativetostrengtheneffortsto
performpoorlyduetotheextremeclassimbalance
protect them. Protecting endangered species like the rhino
in our dataset, we design MultimodAL, an active
involves studying their patterns of habitat use [Johnson and
learningsystememployingarankingtechniqueand
Gillingham,2005],butthisischallengingduetorhinosbeing
multimodalitytoachievecompetitiveperformance
reclusive and dangerous to observe in the wild [Linklater et
with passive learning models with 94% fewer la-
al., 2013]. Moreover, efforts to study rhinos are often con-
bels. Our methods could therefore save over 76
strained by the limited human and financial resources avail-
hours in labeling time when used on a similarly-
ableintheAfricansavannalandscapesrhinosinhabit,which
sized dataset. Unexpectedly, our midden map re-
canbelargeandinaccessible[AndersonandGaston,2013].
veals that rhino middens are not randomly dis-
Rather than study rhinos directly, we propose for the first
tributed throughout the landscape; rather, they are
time to use rhino middens, depicted in Figure 1, to im-
clustered.Consequently,rangersshouldbetargeted
proveourunderstandingofrhinos’spatialbehavior. Middens
at areas with high midden densities to strengthen
are communal defecation sites used for territorial marking
anti-poachingefforts,inlinewithUNTarget15.7.
and social communication [Owen-Smith and Smith, 1973].
Thus, understanding midden spatial patterning is a noninva-
1 Introduction
sivemeansforgaininginsightintorhinolocationsandmove-
Vertebratesaregoingextinct100xfasterthanbeforetheAn- ment,providingconservationpractitionerswithspatialinfor-
thropocene, indicating that the Earth is undergoing the sixth mation key to effective poaching prevention, management
mass extinction [Ceballos et al., 2015]. Among the hu- efforts, and reintroduction plans for rhinos. Unfortunately,
manthreatstobiodiversity,poachinghasendangeredmyriad rhino midden locations have not yet been mapped because
species, particularly the rhino. The poaching epidemic is a they are distributed throughout huge areas. Manually locat-
barriertoachievingtheUnitedNation’sFifteenthSustainable ingallthemiddensfromthegroundispracticallyimpossible,
DevelopmentGoal: LifeonLand[UN,2023b]. Inparticular, andwhetherdronescanbeusedforthispurposeisuntested.
Target15.7callsfor“urgentactiontoendpoachingandtraf- Against this background, this paper provides the first re-
fickingofprotectedspeciesoffloraandfauna”[UN,2023b]. sults from harnessing remotely sensed data to detect rhino
Poaching as well as habitat loss have exterminated African middensalongwiththefirstspatialmapofmiddens.Middens
rhinos across much of their historical range [WWF, 2023]. areconsiderablyeasiertodetectinremotelysensedimagery
4202
peS
62
]VC.sc[
1v40181.9042:viXraeralproblemofidentifyingararesignalofinterestabout
which we have knowledge in an imbalanced dataset for
whichcompleteannotationisimpractical.
We train and evaluate our methods using 9,772 images of
asiteinKrugerNationalParkcapturedinthreemodalitiesin
collaborationwithSouthAfricanNationalParks.Weperform
Figure2:Eachpairshowsthethermal(left)andRGB(right)images image classification to identify midden and non-midden im-
ofthesameareacontainingamidden.Greenboxesoutlinemiddens. agesandmapmiddensgeographicallyforthefirsttime. We
Red boxes outline areas that falsely appear to be middens. In (a), trainapassiveneuralnetworkoneachofourdatamodalities
themiddenismoreobviousinthethermalimagethanintheRGB
(thermal,RGB,andLiDAR)aswellasonfusedcombinations
image,andin(b)thereverseistrue.
ofthesedatatypes. Forthemiddensinthissite,thermalim-
ageryisthemostinformative,RGBprovidesaslightboostin
accuracy when fused with thermal, and fusing thermal with
thantheelusiverhinosthemselves,astheformerarestation-
LiDAR improves recall. Next, we design and implement a
ary and larger. While remote sensing technology is increas-
novel multimodal active learning system, MultimodAL, that
inglybeingusedinecologicalresearch[Marvinetal.,2016],
exploits the fact that middens are warm. We compare the
the rate at which large volumes of data are collected often
performance of our query strategies against several standard
outpacesprocessingandanalysis,preventingcrucialinsights
baselines. MultimodAL achieves statistically identical per-
frombeinggainedrapidlyandatscale[Tuiaetal.,2022].
formancetothebestpassivelearningmodelwith94%fewer
To overcome this challenge, we develop machine learn- labels,greatlyeasingthelabelingburdenondomainexperts.
ing models utilizing thermal (heat), RGB (color), and Li- Finally, mapping the rhino middens in this site reveals that
DAR(lightdetectionandranging)imageryofasiteinKruger theyarenotdistributedrandomlyacrosstheregionbutrather
National Park with identified middens. We believe all three formclusters,sorangerpatrolsoughttobetargetedatthear-
modalitiescanplayanimportantroleinrhinomiddendetec- easwithhighmiddendensities. Thus, wehaveprovidedac-
tion. Duetotheirwarmtemperature,middensoftenshowup tionableinformationforrhinoconservationasaresultofour
asbrightareasinthermalimagery,asseenintheleftimageof endeavor to map rhino middens rather than rhinos directly,
Figure 2(a). In RGB imagery, middens often appear brown, andourmethodsfacilitatescalingtheseinsightstoadditional
as seen in the right image of Figure 2(b). LiDAR imagery rhinohabitats.
isexpectedtobemorehelpfulinothersiteswithhighnum-
bers of termite mounds because although both middens and
2 RelatedWork
moundstendtobewarm,thelatteroftenhaveahigherslope.
First, we consider whether passive (i.e., supervised) deep Wediscussrelatedmultimodaldeeplearningandactivelearn-
learningtechniquesareabletodetectrhinomiddensinmul- ingmethodsinthissection. Severalstudieshavefusedther-
timodal imagery. Second, we determine which data modal- malandRGBdatatoimprovetheperformanceofdeeplearn-
ities and combinations thereof are most informative for au- ingmodels. Alexanderetal. [2022]andSpethetal. [2022]
tomaticmiddendetectionefforts,whichissalientbecauseof utilized thermal and RGB fusion in a deep learning method
the limited resources available for conservation and ecosys- to detect cracks in civil infrastructure and locate civilians in
tem monitoring. However, due to geographic differences disaster zones, respectively. In our setting, we consider fu-
between ecological sites, a deep learning model that per- sionsofthermal,RGB,andLiDARimagery.Whiletheabove
forms well on one site may not perform well on another worksconsideronlypassivelearningsettings,wealsoinves-
[Beeryetal.,2018],creatingacumbersomelabelingbur- tigatemultimodalityinactivelearningenvironments. Forour
den. Our third contribution is therefore to develop active active learning models, we both evaluate performance when
learning methods that strategically select images to be la- fusingseveraltypesofimagerybeforehandandwhenallow-
beled by an expert in order to find rhino middens in an un- ing distinct models trained on different image modalities to
labeled dataset in which most images are empty. The goal forma“committee”fortheactivelearningsystem.
is to reach an accuracy that competes with passive learning Active learning algorithms are generally distinguished by
methods despite having far fewer labeled data points. How- their strategy for evaluating how informative an unlabeled
ever, when the dataset has extreme class imbalance, pre- sample is [Settles, 2009]. One of the most common ac-
dominant active learning methods [Lewis and Gale, 1994; tive learning techniques is uncertainty sampling [Lewis and
Kellenberger et al., 2019] are unlikely to query rare posi- Gale, 1994], wherein the model requests labels for the im-
tive samples, impeding the model’s learning. To overcome agesaboutwhichitismostuncertain. Thismethoddoesnot
this challenge, we introduce the MultimodAL active learn- explicitlyprioritizeaparticularclass,soitisnotdesignedto
ing system, which leverages information about the signal of find extremely rare positive samples in a highly imbalanced
interest to rank the instances. We then prioritize querying dataset. Inordertoaddressthismismatch,Kellenbergeretal.
thosemostlikelytoberarepositivesamples,acceleratingthe [2019]introducedpositivecertaintysampling, insteadprior-
model’slearning. WithinMultimodAL,wealsointroducean itizingimagesforlabelingthatarelikelytobepositivesam-
ensemble active learning strategy that dynamically weights ples. Both uncertainty and positive certainty sampling were
thepredictionsfromseveralmodelstoqueryinstancesmore designedforasingledatamodality. Zhangetal. [2021]de-
likelytobepositivesamples.Ourmethodsapplytothegen- veloped an active learning algorithm for thermal and RGBbands,wewereleftwith89imageswithmiddensand9,683
emptyimages,whichmeansthatourdatasethas9,772images
(ineachmodality),0.91%ofwhichhaveamidden. Wefused
theimagesusingtheblendfunctioninthePILclass,yielding
fusionsofthermalandRGB,thermalandLiDAR,RGBand
Figure3: Thermal(left),RGB(middle),andLiDAR(right)ortho- LiDAR, and thermal, RGB, and LiDAR images, with each
mosaicscomprisingthedatasetunderstudy. datamodalityweightedequally.
3.2 Model
data that prioritizes images that are classified differently by
theseparatethermalandRGBmodels.Whilethismethodac- WeemploytransferlearningwithaVGG16modelpretrained
commodatestwodatamodalities,likeuncertaintysamplingit on the ImageNet dataset [Simonyan and Zisserman, 2015].
isnotdesignedforimbalanceddatasets. Weintroduceaform Wefreezealltheparametersinthemodelexceptforthosein
of multimodal positive certainty sampling, which prioritizes the classifier. We alter the final linear layer to have a single
images that an ensemble of models (one for each modality) out feature and then end with a sigmoid function so that the
determinesarelikelyrarepositivesamples. output of the model represents the probability that an image
Becauseofthedifficultyinidentifyingtheseraresamples, containsamidden. Forallourmodels,weuseabatchsizeof
we need to make the query method as powerful as possi- 10, the Binary Cross Entropy loss function in PyTorch, and
ble. An example of a method that uses expert knowledge anAdamoptimizerwithalearningrateof0.0001.
to identify images likely to contain an object of interest is
describedinDeOliveiraandWehrmeister[2016],whichuses 4 ActiveLearningMethodology
theknownhumanbodytemperaturetoidentifypeopleinther-
4.1 MultimodALAlgorithm
mal images. This technique is not, however, used within an
activelearningalgorithm. WhileDeOliveiraandWehrmeis- Active learning aims to reduce the number of instances that
ter[2016]knewthehumanbodytemperaturewithreasonably need to be labeled to train a model by requesting labels for
highprecision,wefacethechallengeofnotknowingthetem- thosethataremostusefulforitslearning. Thegeneralproce-
perature of rhino middens. We do know, however, that they dureworksasfollows:(i)asmallbatchoflabeledinstancesis
areoftenwarmerthanthesurroundinggroundandvegetation. usedtobegintrainingamodel,(ii)themodelthenusessome
Thus,inouractivelearningsystem,weprioritizeimagesfor criteriatoselectthenextbatchofinstancestobelabeled,typ-
labeling that have higher pixel values in the thermal band. icallythoseaboutwhichthemodelisleastcertain[Lewisand
Withthismethod,thesystemisabletomorequicklylearnto Gale,1994],(iii)thisprocesscontinuesuntilalabelingbud-
distinguishbetweenmiddensandnon-middens. getisreached,and(iv)thetrainedmodelcanthenbeusedfor
inferenceontheremainingunlabeledinstances.
3 Setup Problematically, however, traditional active learning ap-
proachescanhavepoorperformanceinthepresenceofsevere
3.1 Data
classimbalance. Toaddressthischallenge, ouractivelearn-
The remote sensing data used for this project was collected ing algorithm, MultimodAL, is designed to detect as many
by a DJI M600 multicopter flown over a 284-hectare site of the rare positive samples as possible in each round. To
in Kruger National Park in January 2020. This drone was achievethis,ratherthanhavethemodelpredictontheentire
equippedwithananimallandscapeobservatorysensorpack- trainingdatasetasisdoneinmanytypicalactivelearningsys-
age, consisting of a FLIR Tau-2 thermal camera, a Sony tems, weproposeconstrainingthesetofinstancesonwhich
A6000camera,andaRieglVUX-1LRLiDARscanner,which the model predicts through a novel technique that exploits
simultaneouslycollectedthermal,RGB,andLiDARdata,re- somecharacteristicoftheobjectofinterestthatcanbeused
spectively, throughout the drone’s flight. The thermal im- forranking. Furthermore,weproposeadynamicmethodfor
agery was rectified and mosaicked at a resolution of 0.5 m, combiningtheoutputsofseveralmodelstrainedondifferent
theRGBimageryat0.05m,andtheLiDARimageryat0.25 datamodalitiestofurtherspeeduplearning.
m,yieldingtheorthomosaicsshowninFigure3. Wefirstdescribeourmethodassumingasingledatamodal-
Theecologistsonourteamidentifiedcandidatemiddensin ity,diagrammedinFigure4. Weassumeeachinstanceinthe
thethermalandRGBorthomosaicsandconfirmedtheirpres- datasetcanbeassignedavaluecorrespondingtoametric(e.g.
enceontheground,yieldingalistofthexandycoordinates temperature, color, etc.) that is associated with the desired
of the centers of 52 rhino middens. We mapped these mid- rare signal of interest. We then rank all the instances by the
dens onto the orthomosaics and then cropped them using an distancebetweentheirvalueoftheinformativemetricanda
intervalof20m(40pixelsforthermal,400forRGB,and80 specifiedtargetvalue(e.g. humanbodytemperature,colorof
forLiDAR)andastrideof5m(10pixelsforthermal,100for grass,etc.) characteristicofthedesiredsignal(topleftboxof
RGB,and20forLiDAR).Eachcroppedimagewasassigned Figure4). Oncetheimagesareranked,weselectasubsetto
alabelof1ifitcontainedthecenterofamiddenand0other- belabeled. Letbbethesizeofabatchofimagesselectedby
wise. Wedownshiftedthepixelvaluesofeachthermalimage the activelearning system forlabeling. (1) To produceeach
such that the cropped thermal images all had a minimum of of the batches, we first compute the output of the model on
0toenableameaningfulcomparisonamongthem. Afterre- the sample with the highest ranking out of those remaining
moving images with all zeros in either the thermal or RGB unlabeled. Toreflecttheuncertaintycapturedinthemodel’sels with possibly differing accuracies, so we want to weight
their predictions accordingly. In particular, we assign each
instance a score for each of the possible classes given by a
weightedsumofthemodels’outputs. IfthereareM models,
then the score for an instance belonging to class i is calcu-
lated using Equation 1. Then as in the unimodal case, the
prediction for the instance is obtained by sampling from a
multinomialdistributionwiththeclassscoresasinputs.
M
(cid:88)
Figure4:Activelearningcyclewheretheimagesarerankedbytheir score = weight ×output (1)
i m m,i
brightness. (1)Predictonhighest-rankedimages. (2)Queryimages
m=1
predicted to be positive. (3) Assign labels to queried images. (4)
Afterbeinginitializedto1/M,theweightsareupdatedin
Addthenewlylabeledimagestothesetofalllabeledimages. (5)
eachsubsequentroundaccordingtothenumberofqueriedin-
Trainthemodelonaselectionofthelabeledimages.(6)Restart.
stancesthatthemodelshaveclassifiedcorrectly. Theweight
for model m is given by Equation 2, where correct is the
m
output,wedonotsimplyassigntheinstancethehighestprob- number of instances queried so far that were classified cor-
abilityclass. Instead, weclassifyitbyrandomlysamplinga rectlybymodelm. Byconstructiontheweightssumto1,so
class according to the model’s output (i.e., the output speci- theresultingscorescanbeinterpretedasprobabilities.
fies the parameters of a multinomial distribution). If the in-
correct
stanceisultimatelypredictedtobeapositivesample,weadd weight = m (2)
ittothebatch. Wethenfeedthesamplewiththenexthighest
m (cid:80)M
correct
n=1 n
rankingtothemodelandcontinuethisprocessuntilwehave
4.2 IntuitionforRankingIdea
abatchwithbsamplespredictedbythemodeltobepositive.
Inthisway,webiasthemodeltowardsselectinghigh-ranking Having described our active learning algorithm, we now
imagesthatweknowaremorelikelytobepositiveinstances. present additional analysis that provides intuition for our
(2) Next, the batch is sent to the labeler. (3) The batch is choice of ranking metric for our dataset. Note that the fol-
labeled by the annotator and then (4) added to the set of in- lowing analysis is not necessary to use the algorithm and is
stances queried so far. Because positive samples may be so solelyforexplanatorypurposes.
rare,batchescanbeimbalancedtowardthenegativeclass(es). For our setting, we have chosen the maximum thermal
(5)Ifalltheinstancesqueriedsofararenegative,thenwese- pixel value as the metric to be used for ranking in descend-
lect all of them for training. If any are positive, we take all ing order. This sets the target as the maximum pixel value
ofthosefortrainingandrandomlyselectanequivalentnum- across all of the thermal images, exploiting our knowledge
ber of negative instances to get a balanced training set. At thatthesought-afterrhinomiddensarewarm.Todemonstrate
thispointthemodelweightsareresettotheirinitialvaluesto thatthisrankingtechniqueeffectivelyprioritizesmiddenim-
preventoverfittingonasmalllabeleddataset,andthemodel agesforlabeling,wecomputetheprobabilityofathermalim-
is then trained on the selected instances. (6) This process is agecontainingamiddengiventhatitsmaximumpixelvalue
repeated until we exhaust a budget on the number of labels (MPV)isnolessthanathresholdt. Tocalculatethis,wefirst
thatcanbeprovided. applyBayes’rule,showninEquation3.
Sincewearealsointerestedinsettingswithmultipledata
modalities,wedevelopamodificationoftheaboveprocedure P(MPV≥t|midden)P(midden)
P(midden|MPV≥t)=
to accommodate an ensemble of models, each of which is P(MPV≥t)
trainedonitsowndatamodality. Specifically,wemodifythe (3)
way in which the prediction for each instance is calculated. Letmbethetotalnumberofmiddensandm bethenum-
t
Above, the prediction was simply extracted from the output ber of midden images with MPV no less than t. The first
ofasinglemodel,wheretheoutputcontainstheprobabilities factorinthenumeratoristhenP(MPV ≥ t|midden) = mt.
m
that the instance belongs to each of the possible classes. In PluggingthisintoEquation3givesEquation4.
themultimodalsetting,wehavetheoutputsofmultiplemod-
m ×P(midden)
P(midden|MPV≥t)= t (4)
m×P(MPV≥t)
WeplotEquation4inFigure5,whichshowsthattheprob-
abilityofanimagecontainingamiddentendstoincreaseas
its maximum pixel value nears the target value, demonstrat-
ing the utility of the ranking method. More generally, we
expectanydatasetwithanappropriatelychoseninforma-
tivemetricandtargettoobeyasimilarpattern: theprob-
ability of being a positive instance drops with increasing
Figure5: Probabilitythatanimagecontainsamiddentendstoin- distance from the target value. Our ranking-based active
creasewithitsmaximumthermalpixelvalue. learningquerystrategyisdesignedforanysuchdataset.cision, and the Thermal+LiDAR Fused model achieves the
best recall and F1 score. Among the three data modalities,
the Thermal model significantly outperforms the RGB and
LiDAR models on our dataset. Thus, based on our results,
if resources on the ground are very constrained, it could be
helpfultoprioritizethermalsensorsformiddendetection.
5.2 EfficientQueryingwithActiveLearning
Figure6:Meanaccuracyforthepassivemodelsacross30trialsafter The passive learning systems achieve high accuracy but re-
trainingfor10epochs. Modelsarerankedindescendingorderby quire9,736labeledimages, sosuchsystemscannot beused
accuracy. to map middens in other sites where we do not have any of
their coordinates beforehand. Moreover, differing topogra-
phy among sites makes transfer learning challenging. La-
5 Results
belingenoughimagesforpassivelearningsystemstobeac-
In this section, we present the performance of models pas- curate would take domain experts dozens of hours. In this
sively trained on thermal, RGB, LiDAR, and fused imagery subsection wedemonstrate thatour MultimodALalgorithm,
and show the trained models are able to detect middens in described in Subsection 4.1, is able to match the best pas-
a held-out test set with high accuracy. We also display the sivelearningperformancewith94%fewerlabeledimagesby
performanceofourMultimodALactivelearningalgorithmin employinganefficientquerystrategy. Whilewedohavethe
comparisontoseveralbaselines. Wedemonstrateourmethod ground-truthmiddenlocationsforthissite,enablingustotest
efficientlyselectsimagesforlabelingandachievesfastmid- variousdetectionmethods,weusetheresultshereinafterasa
den retrieval in a large, imbalanced, and initially unlabeled proofofconceptforoursystem.
dataset. All error bars in Subsections 5.1 and 5.2 show one Foractivelearningweusethesamedatasetandperformthe
standarderrorofthemeanineachdirection. Allmodelsare sametrain-testsplitprocedureasforpassivelearningexcept
trained for 10 epochs, and a threshold of 0.5 is used on the that we do not balance the training set, so all the empty im-
models’ sigmoid output for test image classification. Each agesnotsetasidefortesting(9,665)areavailabletothesys-
experimentisrun30times. tem during training. We test two versions of MultimodAL.
First, MultimodAL: Thermal+RGB Fused uses the version
5.1 DetectingMiddenswithPassiveLearning
of our proposed algorithm for a single model trained on the
Wepassivelytrainmodelswithimagesindifferentmodalities pre-fused thermal+RGB images, and second, MultimodAL:
toestablishthatneuralnetworksarecapableofaccuratelyde- Thermal + RGB maintains separate models trained on the
tecting rhino middens in remotely sensed imagery. To train thermal and RGB images and uses the version of the algo-
our passive learning models we assume that the system has rithmthataccommodatesmultiplemodalities. Inadditionto
accesstoalloftheimages’labelsfromthestart. Wesplitthis ourproposedMultimodALalgorithm,weimplementseveral
labeleddataintotrainingandtestsetswiththefollowingran- baselines: (1) Random: randomly chooses images to be la-
domselections. First,weadd80%ofthemiddenimages(71) beled in each round, (2) Uncertainty: requests labels for the
tothetrainingsetandleave20%(18)forthetestset.Wethen images with model outputs closest to 0.5, a very common
add18empty(non-midden)imagestothetestset,yieldinga activelearningstrategy[LewisandGale, 1994],(3)Positive
balanced test set of 36 images. Of the remaining empty im- Certainty: requests labels for the images with outputs clos-
ages,werandomlysample71andaddthemtothetrainingset est to 1, an active learning strategy more tailored to imbal-
tobalanceit,yieldingabalancedtrainingsetof142images. anced datasets like ours [Kellenberger et al., 2019], and (4)
Foreachtrial,wetrainthemodelonthethermal,RGB,Li- Disagree: askstheusertolabeltheimageswiththegreatest
DAR, or fused imagery and then record the accuracy on the difference in output between the thermal and RGB models
test set at the end, graphed in Figure 6, where each trial has [Zhangetal.,2021]. Wetrainandevaluatethesingle-model
a different random assignment of images to the training and systemsonthethermal+RGBfuseddatasincethatmodelper-
testsets. Wealsoreportthemeanandstandarderrorsofthe formed the best in the passive setting. For the multi-model
accuracy, precision, recall, and F1 score across the passive systems,weuseseparatethermalandRGBmodels. Wetrain
trials in Table 1. We observe that the Thermal+RGB Fused each of these on the images in its modality. In evaluating
model achieves the best performance on accuracy and pre- thesystemasawhole,imagesinthetestsetareclassifiedby
T+RFused Thermal T+LFused T+R+LFused RGB R+LFused LiDAR
Accuracy .864±.008 .862±.012 .858±.008 .818±.011 .632±.014 .608±.016 .595±.012
Precision .875±.010 .846±.014 .826±.011 .823±.012 .629±.015 .616±.020 .632±.023
Recall .855±.016 .894±.016 .917±.011 .818±.017 .670±.023 .678±.028 .576±.041
F1 .861±.009 .866±.012 .866±.007 .817±.012 .642±.015 .631±.015 .565±.024
Table1: Passivelearningstatistics. T=Thermal,R=RGB,andL=LiDAR.TheThermal+RGB(T+R)Fusedmodelachievesthebestperfor-
manceonaccuracyandprecision,andtheThermal+LiDAR(T+L)FusedmodelachievesthebestrecallandF1score.Figure7:Meanaccuracyonthetestsetfortheactivelearningmeth- Figure 8: Mean fraction of middens found in the training set for
odswithupto500imageslabeledacross30trials.Bothversionsof the active learning methods with up to 500 images labeled across
MultimodALoutperformthebaselinesandwith500labelsaresta- 30 trials. Both versions of MultimodAL find more middens more
tisticallyindistinguishablefromthebestpassivemethod. quicklythanthebaselineswithupto400labels.
weighting the models’ outputs by their weights learned dur- duringqueryingbytheactivelearningsystemoutofallthose
ingtraining,calculatedusingEquation2. presentinthetrainingsetasmorelabelsareprovided. Figure
We graph the accuracy of our proposed methods in com- 8 shows that both versions of the MultimodAL system are
parison to the baselines’ as the labeling budget increases in able to find more middens more quickly than the baselines.
Figure7. WefindthatbothversionsofMultimodALoutper- At around 400 labels the Positive Certainty model is accu-
formallofthebaselinesbyastatisticallysignificantamount rate enough to compete with MultimodAL in terms of mid-
(p<0.05)at500labels. ThisisdespitethefactthatPositive denfindingdespitemaintainingalowertestsetaccuracy,but
Certainty is statistically significantly better (p < 0.05) than for smaller numbers of labels its midden retrieval is signifi-
Random,demonstratingitisastrongbaseline. PositiveCer- cantly inferior. This suggests that Positive Certainty is find-
taintyoutperformingtheotherbaselinesisconsistentwithour inglessinformativemiddensthanMultimodAL,whichisbi-
hypothesisthatprioritizingimagesthesystemthinksarepos- ased towards selecting the warmest middens. A comparison
itivesamplesismoresuitableforhighlyimbalanceddatasets of Figures 7 and 8 indicates a positive relationship between
thanprioritizingimagesaboutwhichthesystemisuncertain. the accuracy achieved by the active learning system and the
Evenso,itisthetwovariantsofMultimodALthatgetwithin numberofpositivesamplesitisabletofind. Inaddition,the
0.026% of the best passive learning accuracy by 500 labels, factthatbothversionsofMultimodALfindroughlythesame
whichisnot astatisticallysignificantdifference(p > 0.05). numberofmiddensthroughouttheactivelearningprocessde-
Hence,thereisanegligibledifferenceinperformancedespite spite MultimodAL: T + R achieving higher accuracy at the
the94%differenceinthenumberoflabeledimagesprovided beginningisfurtherevidenceforitfindingmoreinformative
tothepassivesystemandMultimodAL. middensthanMultimodAL:Thermal+RGBFused.
Interestingly, MultimodAL: Thermal + RGB outperforms Figure 8 also demonstrates that MultimodAL is success-
MultimodAL: Thermal+RGB Fused for small numbers of fullyaddressingtheclassimbalanceissueinourdataset.Both
labels (< 200), despite the opposite pattern holding for versions of MultimodAL find over 65% of the middens by
larger numbers of labels. Because MultimodAL: Thermal 500imageslabeled. Thisisquiteremarkablegiventhatonly
+ RGB combines the scores across two modalities, it will 71 out of the 9,736 images in the training set are middens.
morestronglyprioritizeimagesthatareveryclearlymiddens Hence,althoughlessthan1%oftheimagesgiventotheactive
in both imagery types than the single-model MultimodAL: learningsystemaremiddens,ouractivelearningalgorithmis
Thermal+RGB Fused, which will assign a high score to im- abletodiscover46ofthembythetime500labelshavebeen
ages that are clear in either data type. This could result in requested. This9%positivityrateis12xlargerthantheover-
moreinformativemiddenimagesbeingselectedintheformer allpositivityrateofmiddensinthetrainingset.Perhapsmore
caseandleadingtoimprovedperformancewhenthenumber impressively, after just 100 queries MultimodAL has found
ofdiscoveredmiddensislow.Overall,theadvantagesofMul- over 34% of all the middens, whereas none of the baselines
timodALaregreatestwhenthelabelingbudgetisverysmall managetofindmorethan8%. Thenumberofmiddensfound
(<150).Forexample,weseethatforupto50imageslabeled issignificantbecausetheseareconfirmedbyhumans, sowe
only MultimodAL does better than Random. Furthermore, arehighlyconfidentthattheseareindeedmiddens. Oncethe
we see diminishing returns in accuracy for MultimodAL af- labelingbudgethasbeenexhausted,theremainingunlabeled
ter around 200 labels once the system has been trained on imagesareclassifiedusingthetrainedmodel,butbecausethe
enoughmiddens(∼33)toserveasareasonabledetector. modelisnot100%accurate,wehavemoreuncertaintyasto
To dig deeper into the origin of MultimodAL’s perfor- whethertheimagesclassifiedasmiddensaretrulymiddens.
mance gains over the baselines, we consider another impor- By achieving competitive accuracy and quickly identify-
tant evaluation metric: the fraction of middens discovered ingmiddensinanunlabeleddataset,MultimodALdrasticallyLabeling 6 FutureWork
Mode TestAccuracy LabelingTime
Budget
Inadvancingadecade-longcollaborationwithSouthAfrican
Passive 0.86±0.01 9,736 81hours
National Parks, we will use MultimodAL to map middens
Active 0.84±0.01 500 250mins
across other sites in Kruger National Park. To do this, we
Active 0.81±0.01 200 100mins
will use a model pre-trained on the labeled dataset studied
Active 0.73±0.01 50 25mins
herein to warm-start an active learning system, further less-
ening the labeling burden. Unique terrain features such as
Table2: Comparisonofpassive(Thermal+RGBFused)andactive
termitemoundspresentinsomeothersitescouldincreasethe
(MultimodAL:Thermal+RGB)testaccuracy,labelingbudget,and
advantagesofmultimodality. Tosupportthiswork,wehope
labelingtime.
to develop an interactive user interface for MultimodAL to
allowdomainexpertstolabelimagesqueriedbythemodel(s)
alleviates the labeling burden, as quantified in Table 2. If without needing to work directly with computer scientists.
weassumeeachimagetakes30secondsforadomainexpert We also present two ideas for building on the MultimodAL
to label, then labeling every image in the dataset would re- system. First, the algorithm could be extended by dynami-
quireover80hours,butlabeling500imageswouldtakeun- cally weighting the maximum thermal pixel values and the
der4.2hours,whichisasignificantamountoftimesavedina model(s)’output. Second,wecoulddefinethemiddendetec-
resource-constraineddomain—allwhileidentifying65%of tiontaskasoneofimagesegmentationratherthanclassifica-
all the middens in the dataset. This demonstrates the power tion and use the model from Kirillov et al. [2023]. We also
ofanactivelearningsystemthatemploysadomain-inspired encouragetheevaluationoftheMultimodALsystemonim-
ranking technique to find rare positive samples in a highly ageryfromotherdomains(e.g.,wildfireoranimaldetection).
imbalanceddataset. To facilitate this future work, we make our code pub-
liclyavailableathttps://github.com/lgordon99/rhino-midden-
5.3 MiddenMapping
detector. In contributing to the UN’s Fifteenth Sustainable
From the locations of the middens in the site, we create the Development Goal, we encourage protected area managers
first-ever midden map, presented in Figure 9, and extract tousetheMultimodALsystemtomaprhinomiddensacross
actionable insights. We emphasize that we are not show- theirlandscapes. However,wemustkeepourdatasetprivate
inglandscapefeaturesonourmaptoprotectrhinoterritories duetoitssensitivenaturewithrespecttotherhinopoaching
frompoachers.Becauserhinomiddensareusedforterritorial crisis. Inaccordancewiththe“Leavenoonebehind”princi-
marking, by mapping these middens we can also figure out ple[UN,2023a],webelieverhinomiddenmapscanempower
where the rhinos’ territories are. We can then target ranger parkrangersandecologicalmonitorsincarryingouttheirin-
patrolsandecologicalmonitorsatthemiddenstobetterpro- dispensableworkinconservingtheplanet’slastwildplaces.
tecttherhinosfrompoachers.Unexpectedly,themiddenmap
revealsthatthemiddensarenotdistributedrandomlyacross
7 Conclusion
theregionbutinsteadformclusters. UsingK-meanswehave
identified six such clusters in our site. We recommend anti- Wemakeseveralcontributionsinthispaper. Incollaboration
poachingeffortsprioritizethoseareasofhighmiddendensity withSouthAfricanNationalParks,wemaprhinomiddensfor
toincreasetheirefficacy. thefirsttimeanddisplaywhereanti-poachingpatrolsoughtto
Furthermore, we find that the rhino middens are often lo- focustheirefforts.Thus,wehavedemonstratedawayoffind-
catedalonganimalpaths. Ecologicalmonitorscanthusfocus ingandprotectingrhinoswithoutdirectlytrackingthem. We
theireffortsalongthesepathssincetheyarelikelybeingused findthatmodelspassivelytrainedonthermal,thermal+RGB
by rhinos. Additionally, knowing where the middens are is fused, or thermal+LiDAR fused imagery achieve high accu-
useful because monitors can visit them to more quickly find racy in distinguishing between midden and empty images.
rhinos or check for fresh dung as a way of confirming the Toalleviatethelabelingburdenintrinsictopassivelearning,
presenceofrhinosinthearea. Thisiscrucialtodemonstrat- we introduce MultimodAL, a novel active learning method-
ingthattherhinosarebeingeffectivelymanagedandthatthe ologyforhighlyimbalanceddatasetsthatisapplicablewhen
area should continue to be funded and resourced. Thus, by theinstancescanberankedaccordingtoaninformativemet-
moreeffectivelytargetingscarceresources,weexpectMulti- ric. Inadditiontoexploitingdomainknowledge,thismethod
modALtohaveasignificantimpactonrhinoconservation. also accommodates multimodal data. We demonstrate that
themulti-modelinstantiationofthealgorithmoutperformsa
single-modelsystemonourdatasetforasmalllabelingbud-
get. Overall,bothMultimodALsystemsoutperformbaseline
querystrategiesandfindmoremiddensthanthebaselinesfor
up to 400 labels provided. Furthermore, only MultimodAL
achievesanaccuracystatisticallyindistinguishablefromthat
ofthebestpassivemodelwith94%fewerlabels, savingdo-
main experts dozens of hours in data annotation efforts. By
introducing this scalable method for mapping middens, we
Figure9: Middenmapfora2x2-kmsiteinKrugerNationalPark. presentnew insightsto supportconservation practitionersin
Bluedotsaremiddens.Redstarsarecentersofmiddenclusters. advancingrhinoconservationacrosssouthernAfrica.Acknowledgments [Kirillovetal.,2023] Alexander Kirillov, Eric Mintun,
Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
Research was sponsored by the DARPA and was accom-
Gustafson, Tete Xiao, Spencer Whitehead, Alexander C.
plished under Grant Number: HR001122C0182. The views
Berg, Wan-Yen Lo, Piotr Dolla´r, and Ross Girshick.
and conclusions contained in this document are those of the
Segment Anything. https://arxiv.org/pdf/2304.02643.pdf,
authorsandshouldnotbeinterpretedasrepresentingtheoffi-
2023. Accessed: 2023-05-24.
cial policies, either expressed or implied, of DARPA or the
U.S. Government. The U.S. Government is authorized to [LewisandGale,1994] David D. Lewis and William A.
reproduce and distribute reprints for Government purposes Gale. A sequential algorithm for training text classifiers.
notwithstanding any copyright notation herein. J.A.K. was InBruceW.CroftandC.J.vanRijsbergen,editors,SIGIR
supported by an NSF Graduate Research Fellowship under ’94,pages3–12,London,1994.SpringerLondon.
grantDGE1745303. SouthAfricanNationalParksisthanked
[Linklateretal.,2013] WayneLLinklater,KatharinaMayer,
forlogisticalandscientificsupport, aswellaspermissionto
and Ronald R Swaisgood. Chemical signals of age,
work in Kruger National Park. All drone flights were per-
sex and identity in black rhinoceros. Animal behaviour,
formedwithapprovalfromtheSouthAfricanCivilAviation
85(3):671–677,2013.
AuthorityandSouthAfricanNationalParksAirwing.
[Marneweck,2013] Courtney Marneweck. What is a
Rhino Midden? https://www.wildlifeact.com/blog/
References
what-is-a-rhino-midden/,2013. Accessed: 2023-05-24.
[Alexanderetal.,2022] Quincy Alexander, Vedhus
[Marvinetal.,2016] David C. Marvin, Lian Pin Koh,
Hoskere, Yasutaka Narazaki, Andrew Maxwell, and
AntonyJ.Lynam,SergeWich,AndrewB.Davies,Ramesh
Billie Spencer. Fusion of thermal and RGB images for
Krishnamurthy, Emma Stokes, Ruth Starkey, and Gre-
automated deep learning based crack detection in civil
goryP.Asner. Integratingtechnologiesforscalableecol-
infrastructure. AIinCivilEngineering,1(3),2022.
ogyandconservation. GlobalEcologyandConservation,
[AndersonandGaston,2013] Karen Anderson and Kevin J 7:262–275,2016.
Gaston. Lightweight unmanned aerial vehicles will rev-
[Owen-SmithandSmith,1973] Rupert Norman Owen-
olutionize spatial ecology. Frontiers in Ecology and the
SmithandRupertNormanOwenSmith. Thebehavioural
Environment,11(3):138–146,2013.
ecologyofthewhiterhinoceros. PhDthesis,Universityof
[Beeryetal.,2018] SaraBeery, GrantVanHorn,andPietro WisconsinMadison,1973.
Perona. Recognition in terra incognita. In Proceedings
[Settles,2009] Burr Settles. Active learning literature sur-
oftheEuropeanConferenceonComputerVision(ECCV),
vey. https://burrsettles.com/pub/settles.activelearning.pdf,
September2018.
2009. Accessed: 2023-05-24.
[Ceballosetal.,2015] Gerardo Ceballos, Paul R. Ehrlich,
[SimonyanandZisserman,2015] Karen Simonyan and An-
AnthonyD.Barnosky,Andre´sGarc´ıa,RobertM.Pringle,
drew Zisserman. Very deep convolutional networks for
andToddM.Palmer. Acceleratedmodernhuman-induced
large-scale image recognition. https://arxiv.org/pdf/1409.
specieslosses:Enteringthesixthmassextinction. Science
1556.pdf,2015. Accessed: 2023-05-24.
Advances,1(5):e1400253,2015.
[Spethetal.,2022] Simon Speth, Artur Gonc¸alves, Bastien
[DeOliveiraandWehrmeister,2016] Diulhio Candido
Rigault, Satoshi Suzuki, Mondher Bouazizi, Yutaka Mat-
De Oliveira and Marco Aurelio Wehrmeister. Towards
suo, and Helmut Prendinger. Deep learning with RGB
real-time people recognition on aerial imagery using
and thermal images onboard a drone for monitoring op-
convolutional neural networks. In 2016 IEEE 19th Inter-
erations. JournalofFieldRobotics,39(6):840–868,2022.
nationalSymposiumonReal-TimeDistributedComputing
(ISORC),pages27–34,2016. [SavetheRhinoInternational,2022]
SavetheRhinoInternational. Poaching statistics.
[Ferreiraetal.,2015] Sam M Ferreira, Cathy Greaver,
https://www.savetherhino.org/rhino-info/poaching-stats/,
GrantAKnight,MikeHKnight,IzakPJSmit,andDanie
2022. Accessed: 2023-05-24.
Pienaar.Disruptionofrhinodemographybypoachersmay
leadtopopulationdeclinesinKrugerNationalPark,South [Tuiaetal.,2022] Devis Tuia, Benjamin Kellenberger, Sara
Africa. PLoSOne,10(6):e0127783,2015. Beery, Blair R. Costelloe, Silvia Zuffi, Benjamin Risse,
Alexander Mathis, Mackenzie W. Mathis, Frank van
[JohnsonandGillingham,2005] Chris J. Johnson and
Langevelde,TiloBurghardt,andetal. Perspectivesinma-
MichaelP.Gillingham. Anevaluationofmappedspecies
chinelearningforwildlifeconservation,Feb2022.
distribution models used for conservation planning.
EnvironmentalConservation,32(2):117–128,2005. [UN,2023a] Sustainable Development Group UN.
[Kellenbergeretal.,2019] Benjamin Kellenberger, Diego LeaveNoOneBehind.https://unsdg.un.org/2030-agenda/
universal-values/leave-no-one-behind, 2023. Accessed:
Marcos, Sylvain Lobry, and Devis Tuia. Half a percent
2023-05-24.
oflabelsisenough: EfficientanimaldetectioninUAVim-
ageryusingdeepCNNsandactivelearning. IEEETrans- [UN,2023b] DepartmentofEconomicandSocialAffairs
actionsonGeoscienceandRemoteSensing,57(12):9524– UN. Goal 15. https://sdgs.un.org/goals/goal15, 2023.
9533,2019. Accessed: 2023-05-24.[WWF,2023] WWF. Rhino. https://www.worldwildlife.org/
species/rhino,2023. Accessed: 2023-05-24.
[Zhangetal.,2021] Heng Zhang, Elisa Fromont, Se´bastien
Lefevre, and Bruno Avignon. Deep active learning from
multispectral data through cross-modality prediction in-
consistency. In 2021 IEEE International Conference on
ImageProcessing(ICIP),pages449–453,2021.