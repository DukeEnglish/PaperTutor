EfficientCrackNet: A Lightweight Model for Crack Segmentation
AbidHasanZim1,∗ AquibIqbal2,∗ ZaidAl-Huda3 AsadMalik4 MinoruKuribayash5
1AligarhMuslimUniversity 2UniversityofMassachusettsAmherst
3StirlingCollege,ChengduUniversity 4MonashUniversityMalaysia 5TohokuUniversity
Abstract
Crack detection, particularly from pavement images,
presentsaformidablechallengeinthedomainofcomputer
visionduetoseveralinherentcomplexitiessuchasintensity
inhomogeneity,intricatetopologies,lowcontrast,andnoisy
backgrounds. Automated crack detection is crucial for
maintaining the structural integrity of essential infrastruc-
tures,includingbuildings,pavements,andbridges.Existing
lightweightmethodsoftenfacechallengesincludingcompu-
tational inefficiency, complex crack patterns, and difficult
backgrounds, leading to inaccurate detection and imprac-
ticality for real-world applications. To address these limi-
tations,weproposeEfficientCrackNet,alightweighthybrid
model combining Convolutional Neural Networks (CNNs)
and transformers for precise crack segmentation. Effi-
cientCrackNetintegratesdepthwiseseparableconvolutions
(DSC) layers and MobileViT block to capture both global
and local features. The model employs an Edge Extrac-
Figure1. Evaluationofparameters,mIoU,andFLOPs(G)onthe
tion Method (EEM) and for efficient crack edge detection
Crack500testdataset. Bubbleradiusrepresentsthemodel’ssize
withoutpretraining,andUltra-LightweightSubspaceAtten-
intermsofFLOPs(G).
tion Module (ULSAM) to enhance feature extraction. Ex-
tensiveexperimentsonthreebenchmarkdatasetsCrack500,
DeepCrack,andGAPs384demonstratethatEfficientCrack-
ingcracksisessentialforassessingandmaintainingstruc-
Net achieves superior performance compared to existing
tural security [9,10]. According to the findings of a re-
lightweight models, while requiring only 0.26M parame-
search that was carried out in 2006, the cost of traffic ac-
ters, and 0.483 FLOPs (G). The proposed model offers an
cidents that were caused by the state of the roads was es-
optimalbalancebetweenaccuracyandcomputationaleffi-
timated tobe 217.5 billion. Thisfigure represented 43.6%
ciency, outperforming state-of-the-art lightweight models,
of the overall cost of accidents that occurred in the United
and providing a robust and adaptable solution for real-
States. [54]. The American Society of Civil Engineers
worldcracksegmentation.
(ASCE) classified US road infrastructure in the 2021 In-
frastructure Report Card as a ”D” grade, indicating poor
condition and at risk. An analysis by the U.S. Interstate
1.Introduction
Highway System reveals that 11% of interstate highways
Cracks are common structural faults found on residen- havepavementsthatareeitherinpoororaveragecondition.
tial buildings, pavements, and bridges. They often re- Specifically, 3% of the pavements are categorized as poor,
sult from inadequate load-bearing capacity, compromising while 8% are categorized as mediocre. Given these criti-
safety. Progressivecrackpropagationimpactsstructuralin- calissues,itisessentialtoenhancethesafety,functionality,
tegrity and longevity. Therefore, identifying and examin- and durability of road infrastructure. Effective methods to
monitorstructuralhealthandassessroadconditionsenable
*Theseauthorscontributedequally. rapiddecision-makingandtreatment [63].
1
4202
peS
62
]VC.sc[
1v99081.9042:viXraManually crack detection and segmentation is a labori- compactformfactor,makingthemidealforreal-worldap-
oustaskthatdemandshighlyskilleddomainspecialists. In plications. These devices can be mounted on unmanned
order to expedite the advancement of pavement surveys, it aerial vehicles (UAVs) or robotic platforms to inspect in-
is essential to accomplish automated crack segmentation. frastructures such as high-rise buildings, bridges, tunnels,
Crack segmentation is a significant challenge due to un- androadways. Therefore,whiledeeplearningmodelshave
even intensity, inconsistent contrast, and a very cluttered achieved precise segmentation performance, their use in
background.Furthermore,roadsofdifferenttypeshavedis- practical, on-site applications remains constrained. Edge
tinct textures that resemble cracks and have very low con- computing devices offer a more viable solution for these
trast, therefore complicating the crack recognition process challengingenvironments [28,47,56,62].
[3,12,29]. Duetoadvantagesintermsofobjectivity,cost- This study introduces a hybrid model combining CNN
effectiveness,efficiency,andsafety,vision-basedcrackseg- andtransformerarchitecturesforcracksegmentation, built
mentationmethodshaverecentlyattractedsignificantinter- upon the UNet framework. The visual comparison be-
estfrombothacademiaandindustry [12,64].Overthepast tween the proposed model and other lightweight segmen-
decade,deeplearninghasexperiencedaresurgence,marked tationmethodsontheCrack500dataset,asshowninFig. 1,
by significant successes in various computer vision appli- illustratestherelationshipbetweenmodelperformanceand
cations. Most semantic segmentation algorithms currently complexity. Extensiveexperimentalevaluationsconducted
usedincracksegmentationresearchrelyonConvolutional onthreedatasetsshowthatEfficientCrackNetstrikesanex-
NeuralNetworks(CNNs) [6,19,63].ThestrengthofCNNs cellent balance between accuracy and computational effi-
liesintheirconvolutionalkernels,whichexhibittranslation ciency. The primary contributions of this research include
invarianceandlocalsensitivity, allowingthemtoprecisely thefollowing:
capture local spatial features. The convolution operation,
characterizedbyitsfixedreceptivefield,iseffectiveatiden- • We introduced a lightweight hybrid model combin-
tifyinglocalpatternsbutislimitedincapturingglobalcon- ingCNNandtransformerarchitecturesthateffectively
textual features or long-range dependencies. In semantic balances high accuracy, low computational cost, and
segmentation, relyingsolelyonlocalfeaturesforper-pixel efficiency for crack segmentation tasks. The model
classificationcanleadtoambiguity,whereasincorporating containsjust0.26millionparametersand0.483FLOPs
globalcontextualfeaturesenhancestheaccuracyofthese- (G).
manticcontentforeachpixel. However,convolutionalker-
• The Ultra-Lightweight Subspace Attention Module
nelshavelimitationsinunderstandingtheoverallstructure
(ULSAM) and MobileViT block are utilized to effi-
of an image and establishing relationships between differ-
cientlycapturebothlocalandglobalfeatures.
ent characteristics. Consequently, improving the precision
of crack segmentation remains challenging [44]. In con-
• An efficient Edge Extraction Method (EEM) is em-
trast, transformer-based networks can capture global con-
ployed for crack edge detection without the need for
textualfeatures, offeringapotentialsolutiontothesechal-
pretraining.
lenges [4,11,24,66,67]. Nevertheless,theseenhancements
in performance are accompanied by sacrifices such as the • We performed extensive experiments on three bench-
largersizeofmodels. Asignificantnumberofpracticalap- mark datasets to validate the effectiveness of the pro-
plications need the prompt execution of visual recognition posedapproach.
tasksonmobiledeviceswithlimitedresources.
2.RelatedWorks
Numerous studies have introduced various deep learn-
ingmodelsforcracksegmentation,whichoftendependon Most previous studieson crack segmentation are CNN-
high-performancecomputingdevices,suchasgraphicspro- based models. U-Net is the most well-known CNN-based
cessingunits(GPUs) [16]. Thesemodelsoftenhaveasig- model, and various architectures of U-Net have been ex-
nificantnumberofparametersandrequirestable,controlled tensively used for crack segmentation [14,15,20]. Other
environmentslikedatacenterstoensurereliableoperation. CNN based models like FCNs [2,45], SegNet [7,37],
However, thepracticalapplicationofthesemodelsinreal- DeepLab [42], andMaskR-CNN [55]usedincrackseg-
worldoutdoorenvironments,typicalofcracksegmentation mentation in various study. Moreover, various attention
tasks, is limited due to these dependencies. In contrast, moduleshavealsobeenusedwithCNN-basedmodels [13].
physical-basedsystemssuchasdronesandmobilerobotics Forexample,theattentiongatemodulewasintegratedinto
have demonstrated significant success in real-world appli- U-Net to enhance the extraction of fracture characteristics
cations. Devices such as the NVIDIA Jetson TX2, Jetson byprioritizingimportantregionsandreconstructingseman-
Nano,andJetsonXavierNXarewidelyusedinedgecom- tic features, leading to improved crack segmentation per-
puting because of their portability, energy efficiency, and formance [27]. AnotherstudyenhancedDeepLabv3+with
2a multiscale attention module to combine multiscale crack
features [42]. Similarly, an attention module was incor-
porated into the DCANet backbone network to combine
both detailed and abstract features, enhancing the model’s
overall performance to recover edge information from the
crack [38]. However, CNN-based models often strug-
gletocaptureexplicitlong-rangedependenciesbecauseof
their inherently localized nature. Given that most cracks
display narrow, elongated structures, it is essential to cap-
ture both local and non-local features for accurate crack
segmentation [8]. Transformer-based models have shown
remarkable performance in crack segmentation [29,61].
A study developed SegCrack using MMSegmentation and
the OHEM strategy to enhance crack segmentation accu-
racy [41,46]. Subsequently,anotherstudyproposedCrack
Transformer [17], a model that integrates elements from
the Swin Transformer [32] and SegFormer [50]. How-
ever, transformer-based models can be initially challeng- Figure2.EdgeExtractionMethod(EEM).
ingtotrainandarepronetooverfittingwhenworkingwith
limited datasets [31]. Recently, there has been increasing
attention towards hybrid models that combine CNNs and EEM initially applies Gaussian Blur (GB) to the input by
transformers [23,34,43,52].UnlikeCNNs,transformerhas convolving it with a Gaussian kernel of size (3, 3), which
robustlong-rangemodellingcapabilities. However, cracks smoothsouthigh-frequencycomponentsandhighlightsthe
often only occupy a limited part of the picture. Therefore, overall structure of objects in the image by retaining low-
relyingonlyonatransformermightbesusceptibletoback- frequencyfeatures. Secondly,themathematicalformulaof
groundinterference,resultinginanoveralldecreaseinseg- DoGisdescribedbyEq. 1,whichinvolvessubtractingthe
mentationperformance. Usingthehybridmodelcancom- blurred input from the original input to extract the bound-
pensate for this deficiency [49,51,65]. Mobile devices, aries and borders of objects between the complete image
like drones and phones, often execute crack segmentation andthelow-frequencyfeaturesintheinput. Thisprocessis
activities with limited computational capabilities, memory analogoustotheband-passfiltereffect. Furthermore,com-
capacity, and battery support [43]. Hence, our objective biningtheGaussianandLaplaciankernelsresultsinaLoG
is to investigate the use of a compact hybrid model in or- kernel, as formulated in Eq. 2. When this LoG kernel is
dertocreateanetworkthatenhancestheprecisionofcrack convolvedwiththeinputimage,itperformsasecond-order
segmentationwithalightweightstructure. derivative,therebyextractingonlytheedgeswherethereare
significant changes. The edges extracted by each method
3.Methodology areprocessedthrougha(1,1)convolutionallayerindepen-
dently, then multiplied and passed through a (3, 3) max-
This section presents a concise overview of the archi-
poolinglayer,followedbyanother(1,1)convolutionallayer
tecturalcomponentsoftheproposedmodel. Theproposed
[1,5,26]. Topreventthelossofedgefeatures,residualcon-
model’s architecture design is based on U-Net. The pro-
nections are incorporated around the EEM, facilitated by
posedEfficientCrackNetmodelconsistsofthreemainparts:
theSqueeze-ExcitationModule(SEM) [22].
theencoder,bottleneck,anddecoder.Themaincomponents
o (Ef Eth Me ),E Uffi lc tri ae -n LtC igr ha tc wk eN iget htar Se ubth se paE cedg Ae ttE ex nt tr ioac nti Mon ecM hae nth iso md DoG=I∗(cid:18)
1−
1 e−x2 2+ σ2y2(cid:19)
(1)
2πσ2
(ULSAM),andMobileViTblock.
3.1.EdgeExtractionMethod(EEM)
We employed an Edge Extraction Method (EEM) by
LoG=I∗(cid:18)
−
π1
σ4
(cid:20)
1−
x2 2+ σ2y2(cid:21) e−x2 2+ σ2y2(cid:19)
(2)
combining two conventional edge detection methods, Dif-
ference of Gaussian (DoG) and Laplacian of Gaussian ThisintegrationofSEMwithintheresidualconnections
(LoG), with convolutional layers. This ultimately resulted accentuates critical features, ensuring the preservation and
in a trainable EEM that was able to learn edge features effectiveutilizationofedgefeaturesforcracksegmentation.
without the need for separate edge label training and with Consequently, incorporating SEM within the residual con-
a minimal number of parameters. For edge extraction, the nectionsallowstheEEMtoenhanceandmaintainedgefea-
3Figure3.StructureofULSAM.
tures, which are vital for precise crack detection and seg-
mentation. ThestructureofEEMisillustratedinFig. 2. Fˆ =concat([Fˆ ,Fˆ ,...,Fˆ ,...,Fˆ ]) (5)
1 2 n˜ g
3.2.Ultra-LightweightSubspaceAttentionModule In Eq. 3, A represents an attention map derived from
n˜
(ULSAM) a group of intermediate feature maps F . Eq. 4 describes
n˜
the process in which each set of feature maps undergoes
The attention mechanism is capable of performing effi-
refinementtoobtaintheaugmentedfeaturemapsFˆ ,utiliz-
cient computational modelling of global dependencies and n˜
ingfeaturedistribution; here⊗denoteselement-wisemul-
offers an unlimited receptive field. The multi-scale con-
tiplicationand⊕signifieselement-wiseaddition. Theout-
volutionstructurehasthepotentialtoderivemoredetailed
put Fˆ produced by ULSAM is obtained by concatenating
features; however, interference may result from irrelevant
the feature maps from each groups, as outlined in Eq. 5.
features [48,60]. In order to resolve this issue, it is im-
This approach allows ULSAM to capture features at mul-
perative to implement attention mechanisms. The current
tiplescalesandfrequencieswhilealsofacilitatingeffective
state-of-the-art attention mechanism is not appropriate for
cross-channel feature utilization within the network [39].
ourlightweightmodelduetoitshighcomputationaland/or
ThestructureofULSAMisillustratedinFig. 3.
parameter overhead. Therefore, this study employs a sim-
ple, effective, and lightweight attention mechanism UL- 3.3.MobileViTblock
SAM.TheULSAMemploysasingleattentionmapforeach
featuresubspace. Initially,ULSAMusesdepthwiseconvo- TheMobileViTblockiscomposedofthreedistinctsub-
lutions (DW) and subsequently applies only one filter dur- modules: local feature encoding, global feature encoding,
ing the pointwise convolution (PW) phase to produce the and feature fusion. Each submodule is tasked with either
attention maps. This approach significantly reduces com- extractinglocalfeatures,capturingglobalfeatures,ormerg-
putationalcomplexity. ing the extracted features. MobileViT excels at efficiently
LetF ∈ Rm×h×w denotethefeaturemapsfromacon- extractingimagefeaturewhilemaintainingalowparameter
volutional layer, where m is the number of input chan- count,makingitanidealoptionforapplicationsconstrained
nels and h and w are the spatial dimensions. In UL- bylimitedcomputationalresources.
SAM, the feature maps F are segmented into g distinct Given an input tensor X ∈ RH×W×C, MobileViT first
groups [F ,F ,...,F ,...,F ], with each group contain- usesaconvolutionallayern×n,followedbyapointwise(or
1 2 n˜ g
ingGfeaturemaps. ThegroupF n˜ representsaspecificset 1×1)convolutionallayer,whichoutputsX L ∈RH×W×d.
oftheseintermediatefeaturemaps,andthefollowingsteps The n × n convolution layer captures local spatial fea-
outlinethesubsequentprocessing. tures,whilethepoint-wiseconvolutionmapsthetensortoa
higher-dimensionalspace(d-dimensional, withd > C)by
learninglinearcombinationsoftheinputchannels.
A =softmax(PW1(maxpool3×3,1(DW1×1(F )))) (3) ToequipMobileViTwiththeabilitytolearnglobalrep-
n˜ n˜
resentationsincorporatingspatialinductivebias,wedivide
X into N non-overlapping flattened patches, denoted as
L
Fˆ =(A ⊗F )⊕F (4) X ∈ RP×N×d. Inthiscontext, P = wh, andN = HW
n˜ n˜ n˜ n˜ U P
4Figure4.TheframeworkoftheEfficientCrackNet.
represents the number of patches, with h ≤ n and w ≤ n thecomputationalloadandthetotalnumberofparameters
beingtheheightandwidthofeachpatch,respectively. For inthenetwork,leadingtoimprovedefficiency.DWandPW
every p ∈ {1,··· ,P}, inter-patch relationships are cap- serve distinct purposes in feature generation: DW focuses
turedbyutilizingtransformerstoproduceX ∈ RP×N×d on identifying spatial relationships, while PW emphasizes
G
asfollows: capturingcorrelationsacrosschannels [18]. Batchnormal-
ization(BN)andReLUactivationareusedaftereachDSC
X (p)=Transformer(X (p)), 1≤p≤P (6)
G U layer.
The X ∈ RP×N×d is folded to produce X ∈ TheencoderpartofthenetworkleveragestheEEM,the
G F
RH×W×d. Then,X isprojectedtoalowerC-dimensional ULSAM, and the MobileViT block. EEM is incorporated
F
space through point-wise convolution and merged with X to improve the model’s capability in delineating the exter-
through concatenation. A subsequent n×n convolutional nal boundaries of the cracks. EEM employs a combina-
layer is used to integrate these concatenated features. It is tion of Gaussian and Laplacian filters to extract edges ef-
important to note that X (p) captures local features from fectively. The module’s ability to highlight edges and fine
U
ann×nregionusingconvolutions,whileX (p)captures detailsmakesitparticularlyusefulforcracksegmentation.
G
globalfeatureacrossP patchesforthep-thlocation. Con- ULSAM primarily employs a subspace attention mecha-
sequently,eachpixelinX canencompassfeaturesfromall nism. This allows the proposed model to capture features
G
pixels in X. Therefore, the overall effective receptive field atvariousscalesandfrequencieswhilealsofacilitatingef-
ofMobileViTisH ×W. fectiveuseofcross-channelfeatures.Theconvolutionoper-
The MobileViT block improves the network’s ability to ation,characterizedbyitsfixedreceptivefield,isdesigned
perceive both global and local features, thereby enhancing to detect local patterns but inherently struggles to capture
itsfeatureextractioncapabilitycomparedtotraditionalcon- globalcontextorlong-rangedependencies. TheMobileViT
volution modules. This convolution-like operation allows blockaddressesthislimitationbyenablingthemodeltoef-
thetransformertoincorporatepositionalfeatures,meaning ficientlyencodebothlocalandglobalfeatures.
fewer transformer modules are required to learn more fea-
3.5.Decoder
tures,makingitlightweight [36].
Like the encoder, the decoder part of the network in-
3.4.Encoder
tegrates advanced components such as DSC, upsampling,
Thenetworkisdesignedtobelight,efficient,androbust. concatenation blocks, ULSAM, and the MobileViT block
To make the model lightweight, in this study, depthwise to achieve a robust and efficient design. The decoder path
separable convolutions (DSC) were used. Numerous effi- begins by increasing the resolution of the feature maps
cientnetworkarchitecturesutilizeDSCastheirfundamen- andthencombinesthemwithmatchingfeaturemapsfrom
tal components [21,40,58]. DSC notably decreases both the encoder, maintaining spatial information. DSCs are
5Figure5. SegmentationresultsontheDeepCrackdataset(a)OriginalImage,(b)GroundTruth,(c)EfficientCrackNet(our),(d)LLM,(e)
ShuffleNetV2,(f)MobileNetV3,(g)EfficientNet,(h)DeepCrack.
also utilized in the decoder to maintain the efficiency and tions (p = 0.2). Additionally, Gaussian noise (p = 0.2),
lightweight nature of the network. Each upsampling step color inversion (p = 0.2) were applied. These augmen-
is followed by concatenation with the corresponding fea- tations simulate various real-world conditions, enhancing
ture maps from the encoder, allowing the decoder to take themodel’srobustnessandabilitytogeneralizeeffectively
advantageofbothhigh-levelabstractfeaturesandlow-level acrossdifferentscenarios.
detailedfeatures.Thisskipconnectionstrategyensuresthat
4.3.LossFunction
the decoder retains important spatial features from the en-
coder. ULSAMisintegratedwithinthedecodertoenhance TheDiceCoefficientLossisusedinthisstudy. Itisde-
thelearningofcross-channelinterdependenciesandmulti- finedas:
scale features. The MobileViT block is integrated into the
decodertoimprovethemodel’scapacityforcapturingfea- 2|A∩B|
DiceCoefficient= (7)
turesatbothlocalandgloballevels. |A|+|B|
Where A is the set of predicted pixels and B is the set
4.Experimentsandanalysis
ofgroundtruthpixels. TousetheDiceCoefficientasaloss
function,wedefinetheDiceLossas:
This section provides detailed information on the
datasets,comparativestudy,andimplementationdetails.
DiceLoss=1−DiceCoefficient (8)
4.1.Datasets
In practice, this can be written for continuous variables
The Crack500, DeepCrack, and GAPs384 benchmark as:
datasetsisusedinthisstudy.
2(cid:80)N
p g
Crack500: The Crack500 dataset consists of 447 im- DiceLoss=1− i=1 i i (9)
agesataresolutionof2560×2592pixels,featuringdiverse (cid:80)N p2+(cid:80)N g2
i=1 i i=1 i
crack shapes and widths against complex background tex-
wherep andg representthepredictedandgroundtruth
i i
tures,makingsegmentationchallenging [57].
valuesforpixeli,respectively,andN isthetotalnumberof
DeepCrack: DeepCrackisawidelyrecognizeddataset
pixels[25,59].
used for assessing crack detection algorithms. It consists
of537images, eachwitharesolutionof384×544pixels. 4.4.Evaluationmetrics
The dataset features clear differences in intensity between
Four widely recognized evaluation metrics are em-
the cracks and the background, which aids in the effective
ployed: Recall (Re), Precision (Pr), F-score (F1), and the
identificationofcracksinpavementimages [30].
mean Intersection-over-Union (mIoU). These metrics are
GAPs384: The GAPs384 dataset features 384 high-
definedasfollows:
resolution images (1080 × 1920 pixels) with diverse noise
types and complex road textures, making crack segmenta- TP
Re= (10)
tionchallengingandcrucialfordevelopingadvancedalgo- TP +FN
rithms [53].
TP
Pr = (11)
4.2.DataAugmentation TP +FP
Toenhancethegeneralizationofourmodel,weutilized Re×Pr
F1=2× (12)
various data enhancement techniques. The images were
Re+Pr
augmentedusingflipping(p=0.7),rotation(p=0.7),ran-
(cid:80)
dom brightness and contrast adjustments (p = 0.2), Gaus- mIoU = 1 in ii (13)
sian blurring (p = 0.2) and shift scale-rotate transforma- n t +(cid:80) n −n
cl i j ji ii
6Model Crack500 DeepCrack GAPs384
Re Pr F1 mIoU Re Pr F1 mIoU Re Pr F1 mIoU
EfficientNet [33] 77.03 57.23 65.67 66.07 86.14 69.25 76.78 78.21 46.73 30.53 36.93 58.63
DeepCrack [30] 44.2 73.46 55.19 62.54 61.73 94.7 74.74 77.57 3.85 65.71 7.27 50.42
ShuffleNetV2 [35] 73.64 67.70 70.54 71.30 85.01 79.71 82.27 82.72 51.22 43.63 47.12 63.26
MobileNetV3 [21] 76.28 62.49 68.7 69.47 87.01 68.40 76.59 78.04 50.43 31.09 38.46 59.11
LMM [1] 80.86 69.74 74.89 74.81 88.15 84.77 86.43 86.43 60.66 46.65 52.74 65.87
EfficientCrackNet(our) 78.43 79.77 79.10 81.33 83.37 88.54 85.88 87.10 76.87 58.43 66.40 71.94
Table1.ComparisonresultsofallmodelsonCrack500,DeepCrack,andGAPs384testimages.
ThequantitiesTP,FP,FN,andTNrepresentthefollow- ally, it obtained a mIoU of 71.94%, which represents the
ing: truepositives,falsepositives,falsenegatives,andtrue highest value among the models evaluated. In comparison
negatives, respectively. Here, n denotes the number of to other models, EfficientCrackNet demonstrated superior
ij
pixelsclassifiedasclassjinclassi,n representsthenum- performance, with an mIoU that was 8.44% higher than
cl
berofclasses,andt isthetotalnumberofpixelsinclassi, LMM, 21.71% higher than MobileNetV3, 13.72% higher
i
(cid:80)
calculatedast = n . than ShuffleNetV2, 29.91% higher than DeepCrack, and
i j ij
22.70%higherthanEfficientNet.
4.5.Comparisonwiththelightweightmodels
TheconsistentlybetterperformanceoftheproposedEf-
ficientCrackNet indicates its robustness and adaptability
We evaluate the performance of several state-of-the-
whilemaintainingcomputationalefficiency.
art and lightweight segmentation models with our model
on three datasets. The models compared are EfficientNet
[33], DeepCrack [30], ShuffleNetV2 [35], MobileNetV3 Model FLOPs(G) Parameters(M)
[21], LMM [1]. Here, Table 1 shows the results. Fig. EfficientNet[33] 0.906 6.97
5 compares the segmentation outputs of our model and DeepCrack [30] 15.42 14.72
other lightweight models to the ground truth on the Deep- ShuffleNetV2[35] 1.105 1.38
Crackdataset,demonstratingtherobustnessoftheproposed MobileNetv3[21] 0.132 1.06
model. LMM [1] 6.56 0.87
EfficientCrackNet(our) 0.483 0.26
The Results on the Crack500 dataset: On the
Crack500 test dataset, the proposed EfficientCrackNet
Table2.ComparisonofmodelscomplexityintermsofFLOPs(G)
demonstrated a mIoU of 81.33%, Re of 78.43%, and Pr
andParameters(M).
of 79.77%. In terms of the F1-score, which evaluates the
balancebetweenPrandRe,EfficientCrackNetachievedthe
highest score of 79.10%. In comparison to other mod-
4.6.ModelComplexity
els, EfficientCrackNet demonstrated significantly superior
performance, achieving a mean Intersection over Union Lightweight networks seek to reduce the complexity of
(mIoU) that was 8.02% higher than LMM, 17.07% higher modelsbyaddressingthreekeyfactors:floating-pointoper-
than MobileNetV3, 14.07% higher than ShuffleNetV2, ationspersecond(FLOPs),andthenumberofparameters.
18.79% higher than DeepCrack, and 30.04% higher than TheFLOPsandparameterscanbequantifiedusingthefor-
EfficientNet. mulasoutlinedinEq. 14and15.
The Results on the DeepCrack dataset: When tested
on the DeepCrack dataset, the proposed EfficientCrackNet FLOPs=2HW(C inK2+1)C out (14)
modelachievedamIoUof87.10%,aReof83.37%,anda
Params=(C K2+1)C (15)
Prof88.54%. IntermsoftheF1-score, EfficientCrackNet in out
reached 85.88%. Comparative analysis reveals that Effi- In this context, H and W refer to the height and width
cientCrackNetsubstantiallyoutperformsothermodels,with of the input feature map, respectively. C represents the
in
anotablemIoUimprovementof0.77%overLMM,11.61% numberofinputchannels,andC signifiesthenumberof
out
overMobileNetV3,5.29%overShuffleNetV2,12.29%over outputchannels. ThevariableK correspondstothekernel
DeepCrack,and11.37%overEfficientNet. size.
TheResultsontheGAPs384dataset:OntheGAPs384 Table 2 presents the FLOPs (G) and parameters (M)
test dataset, EfficientCrackNet achieved a Re of 76.87%, of the models. Our model, EfficientCrackNet, has the
a Pr of 58.43%, and an F1-score of 66.40%. Addition- fewest parameters, with 0.61M and 0.80M fewer than
7Baseline F1 mIoU
w/oULSAM 77.93 80.38
w/oMobileVitblock 75.40 78.61
Our 79.10 81.33
Table3.ImpactofULSAMandMobileVitblock.
Baseline F1 mIoU
w/oEEM 71.06 75.47
Our 79.10 81.33
Table4.InfluenceofEEMonCrack500datasets.
Figure6. FeaturemapsofeachpartofEEM,(a)OriginalImage,
5.2.EffectofEEM
(b)SegmentationResult,(c)GaussianBlur(GB),(d)Differentof
Gaussian(DoG),(e)LaplacianofGaussian(LoG),(f)Multiplied
Edgesandobjectboundariesarecrucialforvarioushigh-
DoGandLoG.
levelcomputervisiontasks,suchasimagesegmentation.In
the early layers of a model, feature maps retain more spa-
tialdetailsoftheoriginalshapesofobjects,makingtheex-
LMM and MobileNetv3, respectively, due to its efficient tractionoftheseedgesparticularlyimportantfortaskslike
design. EfficientCrackNet has the second-lowest FLOPs cracksegmentation. Inourproposedmodel,weemployan
(G), which is 0.483, with only MobileNetv3 having fewer EEM in the earlier layers of the encoder. We conducted
FLOPs (G). However, EfficientCrackNet significantly out- experiments to evaluate the impact of EEM on our model
performs MobileNetv3 across all three datasets. Despite usingtheCrack500dataset. Theresults,presentedinTable
being lightweight, our model performs well on all three 4,showthattheexclusionofEEMledtoasignificantreduc-
datasets, indicating its suitability for real-world crack seg- tioninperformance,withtheF1scoredroppingby10.71%
mentationonmobiledevices. andthemIoUby7.48%. Thishighlightstheimportanceof
EEMinenhancingsegmentationaccuracy.Fig.6illustrates
theeffectofeachcomponentofEEMonthesegmentation
5.AblationStudy mask.
ThissectiondiscussestheeffectofULSAM,MobileViT
6.Conclusion
block, and EEM on our model. The Crack500 dataset is
usedasan illustrativecasedueto itswiderangeof shapes
EfficientCrackNet is a lightweight hybrid model de-
and widths, as well as the intricate background textures
signed for automatic crack detection and segmentation in
presentinmostoftheimages.
infrastructuremaintenance. ItcombinesDSCandMobile-
ViT blocks to capture global and local features, enhanc-
5.1.EffectofULSAMandMobileVitblock ing segmentation precision. The model uses an innova-
tiveEEMwithDoGandLoGforfeatureextractionwithout
WeconductedexperimentstoevaluatetheimpactofUL- additionaltrainingandincorporatesULSAMforimproved
SAM and the MobileViT block within our model. The featurerepresentation. EfficientCrackNetachievesstate-of-
results, presented in Table 3, are based on the Crack500 the-art results on three benchmark datasets, outperforming
dataset. WithoutULSAMresultedinareductionoftheF1 other lightweight models with just 0.26M parameters and
scoreby1.49%andthemIoUby1.18%. Similarly,theex- 0.483GFLOPs,makingitidealforreal-worldapplications.
clusionoftheMobileViTblockledtoadecreaseintheF1 Despite its strengths, EfficientCrackNet has limitations
score by 4.79% and the mIoU by 3.40%. ULSAM is in- thatrequirefurtherexploration. Itstruggleswithdetecting
tegratedwithintheencoder,bottleneck,anddecoderofthe extremelythincracks,whichmayneedmoreadvancedfea-
model. ULSAM improve the network’s ability to under- tureextractiontechniques. Additionally,variationsinlight-
standcomplexvisualpatterns,withoutsignificantlyincreas- ing and background conditions can affect its performance.
ing model parameters. On the other hand, the MobileViT Futureresearchshouldrefinethemodelandexpanditsuse
block aids in capturing global features without escalating in structural health monitoring, enhancing automated in-
themodel’scomplexitysignificantly. spectionforbetterinfrastructuremaintenanceandsafety.
8References [12] Mingfei Cheng, Kaili Zhao, Xuhong Guo, Yajing Xu, and
JunGuo. Jointtopology-preservingandfeature-refinement
[1] OmarAl-maqtari,BoPeng,ZaidAl-Huda,AbdulrahmanAl- networkforcurvilinearstructuresegmentation. InProceed-
Malahi,andNaseebahMaqtary.Lightweightyeteffective:A ings of the IEEE/CVF International Conference on Com-
modularapproachtocracksegmentation.IEEETransactions
puterVision,pages7147–7156,2021. 2
onIntelligentVehicles,2024. 3,7
[13] Xiaoning Cui, Qicai Wang, Jinpeng Dai, Yanjin Xue, and
[2] RazaAli, JoonHuangChuah, MohamadSofianAbuTalip, Yun Duan. Intelligent crack detection based on attention
NorrimaMokhtar, andMuhammadAliShoaib. Automatic mechanism in convolution neural network. Advances in
pixel-levelcracksegmentationinimagesusingfullyconvo- StructuralEngineering,24(9):1859–1868,2021. 2
lutional neural network based on residual blocks and pixel
[14] Xinwen Gao and Bairui Tong. Mra-unet: balancing speed
localweights. EngineeringApplicationsofArtificialIntelli-
and accuracy in road crack segmentation network. Signal,
gence,104:104391,2021. 2
ImageandVideoProcessing,17(5):2093–2100,2023. 2
[3] Christian Benz and Volker Rodehorst. Omnicrack30k: A [15] YuxiGao,HongbinCao,WeiweiCai,andGuoxiongZhou.
benchmark for crack segmentation and the reasonable ef- Pixel-level road crack detection in uav remote sensing im-
fectiveness of transfer learning. In Proceedings of the ages based on ard-unet. Measurement, 219:113252, 2023.
IEEE/CVF Conference on Computer Vision and Pattern
2
Recognition,pages3876–3886,2024. 2
[16] HongrenGong,LimingLiu,HaimeiLiang,YuhuiZhou,and
[4] Hu Cao, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xi- LinCong. Astate-of-the-artsurveyofdeeplearningmodels
aopeng Zhang, Qi Tian, and Manning Wang. Swin-unet: forautomatedpavementcracksegmentation. International
Unet-likepuretransformerformedicalimagesegmentation. JournalofTransportationScienceandTechnology,2023. 2
InEuropeanconferenceoncomputervision,pages205–218.
[17] FengGuo, YuQian, JianLiu, andHuayangYu. Pavement
Springer,2022. 2
crackdetectionbasedontransformernetwork. Automation
[5] Liang-ChiehChen,JonathanTBarron,GeorgePapandreou, inConstruction,145:104646,2023. 3
KevinMurphy,andAlanLYuille. Semanticimagesegmen- [18] YunhuiGuo,YandongLi,LiqiangWang,andTajanaRosing.
tationwithtask-specificedgedetectionusingcnnsandadis- Depthwiseconvolutionisallyouneedforlearningmultiple
criminatively trained domain transform. In Proceedings of visualdomains. InProceedingsoftheAAAIConferenceon
theIEEEconferenceoncomputervisionandpatternrecog- ArtificialIntelligence,volume33,pages8368–8375,2019.5
nition,pages4545–4554,2016. 3
[19] Chengjia Han, Tao Ma, Ju Huyan, Xiaoming Huang, and
[6] Liang-ChiehChen,YukunZhu,GeorgePapandreou,Florian YanningZhang.Crackw-net:Anovelpavementcrackimage
Schroff, and Hartwig Adam. Encoder-decoder with atrous segmentationconvolutionalneuralnetwork. IEEETransac-
separableconvolutionforsemanticimagesegmentation. In tions on Intelligent Transportation Systems, 23(11):22135–
ProceedingsoftheEuropeanconferenceoncomputervision 22144,2021. 2
(ECCV),pages801–818,2018. 2
[20] MianqingHeandTzeLiangLau. Crackham: Anovelau-
[7] TingyangChen,ZhenhuaCai,XiZhao,ChenChen,Xufeng tomatic crack detection network based on u-net for asphalt
Liang,TieruiZou,andPanWang. Pavementcrackdetection pavement. IEEEAccess,2024. 2
andrecognitionusingthearchitectureofsegnet. Journalof [21] Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry
IndustrialInformationIntegration,18:100144,2020. 2 Kalenichenko, Weijun Wang, Tobias Weyand, Marco An-
[8] ZhuangzhuangChen,ZhuonanLai,JieChen,andJianqiang dreetto,andHartwigAdam. Mobilenets: Efficientconvolu-
Li. Mind marginal non-crack regions: Clustering-inspired tionalneuralnetworksformobilevisionapplications. arXiv
representationlearningforcracksegmentation. InProceed- preprintarXiv:1704.04861,2017. 5,7
ingsoftheIEEE/CVFConferenceonComputerVisionand [22] JieHu,LiShen,andGangSun. Squeeze-and-excitationnet-
PatternRecognition,pages12698–12708,2024. 3 works. InProceedingsoftheIEEEconferenceoncomputer
[9] ZhuangzhuangChen,JinZhang,ZhuonanLai,JieChen,Zun visionandpatternrecognition,pages7132–7141,2018. 3
Liu,andJianqiangLi. Geometry-awareguidedlossfordeep [23] HuiminHuang,ShiaoXie,LanfenLin,RuofengTong,Yen-
crack recognition. In Proceedings of the IEEE/CVF Con- Wei Chen, Yuexiang Li, Hong Wang, Yawen Huang, and
ferenceonComputerVisionandPatternRecognition,pages YefengZheng. Semicvt: Semi-supervisedconvolutionalvi-
4703–4712,2022. 1 siontransformerforsemanticsegmentation. InProceedings
[10] Zhuangzhuang Chen, Jin Zhang, Zhuonan Lai, Guanming oftheIEEE/CVFConferenceonComputerVisionandPat-
Zhu,ZunLiu,JieChen,andJianqiangLi.Thedevilisinthe ternRecognition,pages11340–11349,2023. 3
crackorientation: Anewperspectiveforcrackdetection. In [24] Aquib Iqbal, Abid Hasan Zim, Md Asaduzzaman Tonmoy,
ProceedingsoftheIEEE/CVFInternationalConferenceon Limengnan Zhou, Asad Malik, and Minoru Kuribayashi.
ComputerVision,pages6653–6663,2023. 1 Eavit: External attentionvisiontransformerfor audioclas-
[11] BowenCheng,IshanMisra,AlexanderGSchwing,Alexan- sification. arXivpreprintarXiv:2408.13201,2024. 2
der Kirillov, and Rohit Girdhar. Masked-attention mask [25] ShrutiJadon. Asurveyoflossfunctionsforsemanticseg-
transformerforuniversalimagesegmentation. InProceed- mentation. In 2020 IEEE Conference on Computational
ings of the IEEE/CVF conference on computer vision and Intelligence in Bioinformatics and Computational Biology
patternrecognition,pages1290–1299,2022. 2 (CIBCB),pages1–7,2020. 6
9[26] JunfengJing,ShenjuanLiu,GangWang,WeichuanZhang, attentionmoduleforcompactconvolutionalneuralnetworks.
andChangmingSun. Recentadvancesonimageedgedetec- InProceedingsoftheIEEE/CVFWinterConferenceonAp-
tion: Acomprehensivereview. Neurocomputing, 503:259– plicationsofComputerVision,pages1627–1636,2020. 4
271,2022. 3 [40] MarkSandler,AndrewHoward,MenglongZhu,AndreyZh-
[27] JacobKo¨nig,MarkDavidJenkins,PeterBarrie,MikeMan- moginov, and Liang-Chieh Chen. Mobilenetv2: Inverted
nion,andGordonMorison. Aconvolutionalneuralnetwork residuals and linear bottlenecks. In Proceedings of the
forpavementsurfacecracksegmentationusingresidualcon- IEEE conference on computer vision and pattern recogni-
nections and attention gating. In 2019 IEEE international tion,pages4510–4520,2018. 5
conference on image processing (ICIP), pages 1460–1464. [41] Abhinav Shrivastava, Abhinav Gupta, and Ross Girshick.
IEEE,2019. 2 Trainingregion-basedobjectdetectorswithonlinehardex-
[28] Ruoxian Li, Jiayong Yu, Feng Li, Ruitao Yang, Yudong ample mining. In Proceedings of the IEEE conference on
Wang,andZhihaoPeng. Automaticbridgecrackdetection computer vision and pattern recognition, pages 761–769,
usingunmannedaerialvehicleandfasterr-cnn.Construction 2016. 3
andBuildingMaterials,362:129659,2023. 2 [42] Xinzi Sun, Yuanchang Xie, Liming Jiang, Yu Cao, and
[29] HuajunLiu,JingYang,XiangyuMiao,ChristophMertz,and Benyuan Liu. Dma-net: Deeplab with multi-scale atten-
Hui Kong. Crackformer network for pavement crack seg- tion for pavement crack segmentation. IEEE Transactions
mentation. IEEETransactionsonIntelligentTransportation onIntelligentTransportationSystems,23(10):18392–18403,
Systems,24(9):9240–9252,2023. 2,3 2022. 2,3
[43] HuaqiTao, BingxiLiu, JinqiangCui, andHongZhang. A
[30] Yahui Liu, Jian Yao, Xiaohu Lu, Renping Xie, and Li Li.
convolutional-transformer network for crack segmentation
Deepcrack: A deep hierarchical feature learning architec-
withboundaryawareness. In2023IEEEInternationalCon-
tureforcracksegmentation.Neurocomputing,338:139–153,
ference on Image Processing (ICIP), pages 86–90. IEEE,
2019. 6,7
2023. 3
[31] YuhengLiu,YifanZhang,YeWang,andShaohuiMei. Re-
[44] LiboWang,RuiLi,CeZhang,ShenghuiFang,ChenxiDuan,
thinking transformers for semantic segmentation of remote
Xiaoliang Meng, and Peter M Atkinson. Unetformer: A
sensingimages. IEEETransactionsonGeoscienceandRe-
unet-liketransformerforefficientsemanticsegmentationof
moteSensing,2023. 3
remotesensingurbansceneimagery. ISPRSJournalofPho-
[32] ZeLiu,YutongLin,YueCao,HanHu,YixuanWei,Zheng
togrammetryandRemoteSensing,190:196–214,2022. 2
Zhang, Stephen Lin, and Baining Guo. Swin transformer:
[45] SenWang,XingWu,YinghuiZhang,XiaoqinLiu,andLun
Hierarchical vision transformer using shifted windows. In
Zhao.Aneuralnetworkensemblemethodforeffectivecrack
Proceedings of the IEEE/CVF international conference on
segmentationusingfullyconvolutionalnetworksandmulti-
computervision,pages10012–10022,2021. 3
scale structured forests. Machine Vision and Applications,
[33] Shao-Yuan Lo, Hsueh-Ming Hang, Sheng-Wei Chan, and
31(7):60,2020. 2
Jing-JhihLin. Efficientdensemodulesofasymmetriccon-
[46] WenjunWangandChaoSu. Automaticconcretecrackseg-
volutionforreal-timesemanticsegmentation,2019. 7
mentationmodelbasedontransformer. AutomationinCon-
[34] Xiangde Luo, Minhao Hu, Tao Song, Guotai Wang, and
struction,139:104275,2022. 3
Shaoting Zhang. Semi-supervised medical image segmen-
[47] WenjunWang,ChaoSu,GuohuiHan,andHengZhang. A
tationviacrossteachingbetweencnnandtransformer.InIn-
lightweightcracksegmentationnetworkbasedonknowledge
ternationalconferenceonmedicalimagingwithdeeplearn-
distillation. Journal of Building Engineering, 76:107200,
ing,pages820–833.PMLR,2022. 3
2023. 2
[35] NingningMa,XiangyuZhang,Hai-TaoZheng,andJianSun.
[48] SanghyunWoo,JongchanPark,Joon-YoungLee,andInSo
Shufflenetv2:Practicalguidelinesforefficientcnnarchitec-
Kweon. Cbam: Convolutional block attention module. In
turedesign,2018. 7
ProceedingsoftheEuropeanconferenceoncomputervision
[36] SachinMehtaandMohammadRastegari. Mobilevit: light- (ECCV),pages3–19,2018. 4
weight, general-purpose, and mobile-friendly vision trans- [49] Chao Xiang, Jingjing Guo, Ran Cao, and Lu Deng. A
former. arXivpreprintarXiv:2110.02178,2021. 5 crack-segmentationalgorithmfusingtransformersandcon-
[37] RongPang,HaoTan,YanYang,XunXu,NanqingLiu,and volutionalneuralnetworksforcomplexdetectionscenarios.
PengZhang. Anovelsegnetmodelforcrackimageseman- AutomationinConstruction,152:104894,2023. 3
ticsegmentationinbridgeinspection. InPacific-AsiaCon- [50] EnzeXie,WenhaiWang,ZhidingYu,AnimaAnandkumar,
ference on Knowledge Discovery and Data Mining, pages Jose M Alvarez, and Ping Luo. Segformer: Simple and
344–355.Springer,2024. 2 efficient design for semantic segmentation with transform-
[38] Zhong Qu, Cai-Yun Wang, Shi-Yan Wang, and Fang-Rong ers. Advances in neural information processing systems,
Ju. A method of hierarchical feature fusion and con- 34:12077–12090,2021. 3
nected attention architecture for pavement crack detection. [51] Guoan Xu, Juncheng Li, Guangwei Gao, Huimin Lu, Jian
IEEE Transactions on Intelligent Transportation Systems, Yang, and Dong Yue. Lightweight real-time semantic
23(9):16038–16047,2022. 3 segmentation network with efficient transformer and cnn.
[39] RajatSaini,NandanKumarJha,BedantaDas,SparshMittal, IEEE Transactions on Intelligent Transportation Systems,
andCKrishnaMohan. Ulsam: Ultra-lightweightsubspace 24(12):15897–15906,2023. 3
10[52] ZhengzeXu,DongyueWu,ChangqianYu,XiangxiangChu, mentcrackdetection. Computer-AidedCivilandInfrastruc-
NongSang,andChangxinGao. Sctnet: Single-branchcnn tureEngineering,39(12):1743–1765,2024. 2
withtransformersemanticinformationforreal-timesegmen- [65] Jinjing Zhu, Yunhao Luo, Xu Zheng, Hao Wang, and Lin
tation. InProceedingsoftheAAAIConferenceonArtificial Wang. A good student is cooperative and reliable: Cnn-
Intelligence,volume38,pages6378–6386,2024. 3 transformer collaborative learning for semantic segmenta-
[53] FanYang,LeiZhang,SijiaYu,DanilProkhorov,XueMei, tion. In Proceedings of the IEEE/CVF International Con-
andHaibinLing. Featurepyramidandhierarchicalboosting ferenceonComputerVision,pages11720–11730,2023. 3
networkforpavementcrackdetection.IEEETransactionson [66] AbidHasanZim, AeyanAshraf, AquibIqbal, AsadMalik,
IntelligentTransportationSystems,21(4):1525–1535,2019. and Minoru Kuribayashi. A vision transformer-based ap-
6 proachtobearingfaultclassificationviavibrationsignals.In
[54] Eduard Zaloshnja and Ted R Miller. Cost of crashes re- 2022Asia-PacificSignalandInformationProcessingAssoci-
lated to road conditions, united states, 2006. In Annals of ationAnnualSummitandConference(APSIPAASC),pages
AdvancesinAutomotiveMedicine/AnnualScientificConfer- 1321–1326.IEEE,2022. 2
ence, volume 53, page 141. Association for the Advance- [67] AbidHasanZim,AquibIqbal,AsadMalik,ZhichengDong,
mentofAutomotiveMedicine,2009. 1 andHanzhouWu. Tcnformer: Temporalconvolutionalnet-
[55] HaoZhang, JiaxiuDong, andZiqiaoGao. Automaticseg- work former for short-term wind speed forecasting. arXiv
mentationofairportpavementdamagebyam-maskr-cnnal- preprintarXiv:2408.15737,2024. 2
gorithm. EngineeringReports,5(8):e12628,2023. 2
[56] Jianqi Zhang, Xu Yang, Wei Wang, Ioannis Brilakis, Di-
anaDavletshina,HainianWang,andMinCao. Segment-to-
track for pavement crack with light-weight neural network
on unmanned wheeled robot. Automation in Construction,
161:105346,2024. 2
[57] LeiZhang, FanYang, YiminDanielZhang, andYingJulie
Zhu. Roadcrackdetectionusingdeepconvolutionalneural
network. In2016IEEEinternationalconferenceonimage
processing(ICIP),pages3708–3712.IEEE,2016. 6
[58] XiangyuZhang,XinyuZhou,MengxiaoLin,andJianSun.
Shufflenet: Anextremelyefficientconvolutionalneuralnet-
workformobiledevices. InProceedingsoftheIEEEcon-
ference on computer vision and pattern recognition, pages
6848–6856,2018. 5
[59] RongjianZhao, BuyueQian, XianliZhang, YangLi, Rong
Wei,YangLiu,andYinggangPan. Rethinkingdicelossfor
medical image segmentation. In 2020 IEEE International
ConferenceonDataMining(ICDM),pages851–860.IEEE,
2020. 6
[60] HeliangZheng,JianlongFu,TaoMei,andJieboLuo.Learn-
ing multi-attention convolutional neural network for fine-
grainedimagerecognition.InProceedingsoftheIEEEinter-
nationalconferenceoncomputervision, pages5209–5217,
2017. 4
[61] HuapingZhou,BinDeng,KeleiSun,ShunxiangZhang,and
YongqiZhang. Ute-cracknet: transformer-guidedandedge
featureextractionu-shapedroadcrackimagesegmentation.
TheVisualComputer,pages1–13,2024. 3
[62] Qiang Zhou, Zhong Qu, and Fang-rong Ju. A lightweight
networkforcrackdetectionwithsplitexchangeconvolution
andmulti-scalefeaturesfusion. IEEETransactionsonIntel-
ligentVehicles,8(3):2296–2306,2022. 2
[63] Shanglian Zhou, Carlos Canchila, and Wei Song. Deep
learning-based crack segmentation for civil infrastructure:
Data types, architectures, and benchmarked performance.
AutomationinConstruction,146:104678,2023. 1,2
[64] GuijieZhu,JiachengLiu,ZhunFan,DuanYuan,PeiliMa,
Meihua Wang, Weihua Sheng, and Kelvin CP Wang. A
lightweight encoder–decoder network for automatic pave-
11