HARMONIC: A Framework for Explanatory Cognitive Robots
Sanjay Oruganti1, Sergei Nirenburg1, Marjorie McShane1, Jesse English1,
Michael Roberts1 and Christian Arndt1
Abstract—We present HARMONIC, a framework for im-
plementing cognitive robots that transforms general-purpose
robots into trusted teammates capable of complex decision-
making, natural communication and human-level explanation.
The framework supports interoperability between a strategic
(cognitive) layer for high-level decision-making and a tactical
(robot) layer for low-level control and execution. We describe
thecorefeaturesoftheframeworkandourinitialimplementa-
tion,inwhichHARMONICwasdeployedonasimulatedUGV
and drone involved in a multi-robot search and retrieval task.
I. INTRODUCTION Fig.1. AnoverviewoftheHARMONICframeworkshowingthestrategic
andtacticallayers.
While today’s general-purpose robots are rapidly advanc-
ing towards achieving dexterous capabilities comparable to The HARMONIC framework (Figure 1) is an extension
human workers [1], [2], [3], they still face several signifi- of hybrid control systems and architectures as summarized
cant limitations. They lack cognitive abilities to assess the by Dennis et al. [4] and is an enhancement over the type
semanticsofsituations,states,andactionsofboththemselves 2 integration in the DIARC framework [5], [6], in which
and others, or engage in meaning-oriented, human-level concurrent and dynamic operation is facilitated by incorpo-
dialog. They also struggle to deal with disturbances and rating the strategic layer as a subsystem within the tactical
novel situations, which limits their adaptability in dynamic layer. In HARMONIC, by contrast, the strategic and tactical
environments.Finally,theyfallshortofbeingtrustedbecause layer components function independently and interactively.
they are unable to generate causal explanations of their Moreover, while we implemented HARMONIC using spe-
reasoning and action. cific cognitive and robotic control systems, this framework
To serve as trusted partners, robots must be able to: was designed to facilitate implementation using any state-
reliably collaborate on complex and novel tasks and mis- of-the-art cognitive and robotic system that supports all the
sions;interpretandanticipateteammates’actionsandneeds; required functionalities.
communicate with teammates in natural language; learn While basic strategic layer functionality can be imple-
new skills on the job from language and demonstration; mented using generalist models [7], including Large Lan-
explain their own and others’ decisions and actions; and guage Models (LLMs) and Vision-Language-Action (VLA)
teach teammates through language and demonstration. models [8], these cannot support human-level explainability,
The HARMONIC framework we present aims to meet which is crucial for establishing trust with humans [9].
these challenges by facilitating the implementation of em- To ensure explainability, VLAs and LLMs are limited to
bodied robots that can remember, plan, reason, explain, ne- specificmodulesandfunctionalitieswithintheHARMONIC
gotiate,learn,andteach.Specifically,thearchitectureenables framework.Fordetailsofsuchintegration,see[10]and[11].
robots to perform:
1) physicalactions,suchasrepairing,cleaningandgofer-
II. THEFRAMEWORK
ing; HARMONIC is a dual control architecture consisting of
2) the mental actions needed to emulate human-like be- a strategic (cognitive) layer for high-level decision-making
havior, such asmeaning-oriented language processing; and planning, a tactical (robot) layer for low-level robot
reasoning about plans, goals, and attitudes; explaining controlandexecution,andabidirectionalinterfacetosupport
the reasons for their own and others’ actions; and communication between the layers, as shown in Figure 1.
accessing and archiving institutional memory (which The strategic layer includes modules for attention man-
is key to operating in complex environments); and agement,perceptioninterpretation,andutility-basedandana-
3) hybrid actions, such as teaching and learning physical logicaldecision-making,enhancedbymetacognitiveabilities
andmentalactionsthroughnaturallanguageandvisual supported by the microtheories of the OntoAgent cognitive
demonstration. architecture[12],[13].Thesemodulesprioritizethestrategic
goal and plan agenda, and select actions while monitoring
1Authors are with the Cognitive Science Department at
Rensselaer Polytechnic Institute, Troy, NY, USA. e-mail: their execution. Additional team-oriented operations include
sanjayovs@ieee.org natural language communication, explaining decisions, as-
4202
peS
62
]OR.sc[
1v73081.9042:viXraFig.2. AsnapshotofthesimulationenvironmentfeaturingaUGVandadronesearchingforlostkeys,asrequestedbyahumannamedDanny.Inthe
centeristheteam-wideverbalcommunication.Totherightareunder-the-hoodpanelsthatshowreal-timetracesofthinkinginthestrategiclayer,including
interpretingvisualinformation(VMRs)andreasoning(Thoughts).
sessing decision confidence, and evaluating the trustworthi- oritiesandactionsinrealtime.Thisisparticularlyimportant
ness of one’s teammates [14]. for capabilities such as responding to computational delays
The tactical layer includes controllers, algorithms, and in the strategic component, handling contingencies, ensuring
models responsible for decision-making at the robot control safety (as by avoiding collisions), and optimizing resources
level. This involves processing sensor inputs and planning byengagingreactiveplanningalgorithmsinthetacticallayer.
motor actions to execute high-level commands received
III. INITIALIMPLEMENTATION
from the strategic layer. For example, a command from
Our initial implementation of the HARMONIC architec-
the strategic layer to ”pick up a screwdriver” requires the
ture involves a human-robot team carrying out simulated
tactical component to identify the screwdriver, determine its
search and retrieval tasks in an apartment environment. The
positionandorientation,computetheend-effectortrajectory,
team includes a human and two HARMONIC-based robots
and send control signals to the actuators. This layer also
– a UGV and a drone, as shown in Figure 2. In this
handles reactive responses, such as collision avoidance in
simulation, the robots are searching for a set of lost keys
robots, which are managed by a dedicated controller.
at the request of a human named Danny. They use dialogue
The strategic layer of the architecture relies on substantial
toestablishsearchparameters,selectandexecuteastrategic-
knowledge bases: an ontological world model with 9,000
level plan, and coordinate their efforts. In the center is the
concepts; a lexicon that describes the meanings of ∼25,000
team-wide verbal communication. To the right are under-
English word and phrase senses in terms of ontological
the-hood panels that show real-time traces of thinking in
concepts; and profiles of human and robotic agents that
the strategic layer, including interpreting visual information
detail team roles, skills, preferences, and states. The current
(VMRs) and reasoning (Thoughts). Each robot is equipped
implementation of the strategic layer employs the OntoSem
withcustomizedBTs,whichincludehigher-prioritysub-trees
naturallanguageanalyzer[15],anattentionmanagerforgoal
to ensure the robots’ safety and needs.
prioritization, a deliberation module for decision-making,
an action rendering module, a semantically-oriented text IV. CONCLUSIONSANDFUTUREWORK
generator,andtheDEKADEsoftwareenvironment,whichall
The development of the HARMONIC framework is part
oftheneedsofthestrategiclayer–Development,Evaluation,
of a comprehensive research program to integrate advanced
Knowledge Acquisition, and DEmonstration [16].
strategic, tactical, and infrastructure components of robots
Onthetacticalside,weutilizeBehaviorTrees(BTs)[17],
capable of effectively functioning as team members that can
[18]forexecutingphysicalactionplansandensuringreactive
perform physical, mental, and hybrid actions. At this time
control. BTs facilitate effective reactive robot control, they
we are planning to deploy the HARMONIC framework on
provide robust and modular representations for skills and
advanced robotic systems and test them in real-time in the
low-levelplans[19],[20]indynamicenvironments,andthey
domain of ship maintenance tasks.
support HARMONIC’s safety and operational needs.
The strategic layer of HARMONIC implements Daniel REFERENCES
Kahneman’s [21] System 2, or slow reasoning. The tactical [1] L. Rossini, E. M. Hoffman, S. H. Bang, L. Sentis, and N. G.
layer implements System 1, or fast reasoning and reflex- Tsagarakis, “A real-time approach for humanoid robot walking in-
cluding dynamic obstacles avoidance,” in 2023 IEEE-RAS 22nd In-
ive action. At its core, the architecture facilitates dynamic
ternational Conference on Humanoid Robots (Humanoids). IEEE,
schedulingandadaptation,enablingthesystemtoadjustpri- 2023,pp.1–8.[2] A.A.Malik,T.Masood,andA.Brem,“Intelligenthumanoidrobotsin centric cognitive models,” in Proceedings of the Annual Conference
manufacturing,” in Companion of the 2024 ACM/IEEE International onAdvancesinCognitiveSystems,2020.
ConferenceonHuman-RobotInteraction,2024,pp.20–27. [13] S. Nirenburg, M. McShane, S. Beale, and R. Catizone, “A cogni-
[3] C.G.Atkeson,B.P.W.Babu,N.Banerjee,D.Berenson,C.P.Bove, tive architecture for simulating bodies and minds,” in AMIA Annual
X.Cui,M.DeDonato,R.Du,S.Feng,P.Franklinetal.,“Nofalls,no Symposium Proceedings, vol. 2011. American Medical Informatics
resets:Reliablehumanoidbehaviorinthedarparoboticschallenge,”in Association,2011,p.905.
2015IEEE-RAS15thInternationalConferenceonHumanoidRobots [14] S.Nirenburg,T.Ferguson,andM.McShane,“Mutualtrustinhuman-
(Humanoids). IEEE,2015,pp.623–630. ai teams relies on metacognition,” in Metacognitive Artificial Intelli-
[4] L.A.Dennis,M.Fisher,N.K.Lincoln,A.Lisitsa,andS.M.Veres, gence, H. Wei and P. Shakarian, Eds. Cambridge University Press,
“Practicalverificationofdecision-makinginagent-basedautonomous 2024.
systems,” Automated Software Engineering, vol. 23, pp. 305–359, [15] M. McShane and S. Nirenburg, Linguistics for the Age of AI. Mit
2016. Press,2021.
[5] M.Scheutz,J.Harris,andP.Schermerhorn,“Systematicintegrationof [16] J. English and S. Nirenburg, “Dekade: An environment supporting
cognitive and robotic architectures,” Advances in Cognitive Systems, developmentofnlpsystems,”InstituteforLanguageandInformation
vol.2,pp.277–296,2013. Technologies, University of Maryland, Baltimore County, Technical
[6] P. W. Schermerhorn, J. F. Kramer, C. Middendorff, and M. Scheutz, Report,2007.
“Diarc:Atestbedfornaturalhuman-robotinteraction.”inAAAI,vol.6, [17] M.ColledanchiseandP.O¨gren,BehaviortreesinroboticsandAI:An
2006,pp.1972–1973. introduction. CRCPress,2018.
[18] M.Iovino,E.Scukins,J.Styrud,P.O¨gren,andC.Smith,“Asurveyof
[7] A. Padalkar, A. Pooley, A. Jain, A. Bewley, A. Herzog, A. Ir-
behaviortreesinroboticsandai,”RoboticsandAutonomousSystems,
pan, A. Khazatsky, A. Rai, A. Singh, A. Brohan et al., “Open
vol.154,p.104096,2022.
x-embodiment: Robotic learning datasets and rt-x models,” arXiv
[19] S.Oruganti,R.Parasuraman,andR.Pidaparti,“Kt-bt:Aframework
preprintarXiv:2310.08864,2023.
forknowledgetransferthroughbehaviortreesinmultirobotsystems,”
[8] A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, X. Chen, K. Choro-
IEEETransactionsonRobotics,2023.
manski,T.Ding,D.Driess,A.Dubey,C.Finnetal.,“Rt-2:Vision-
[20] S. Oruganti,R.Parasuraman,andR.Pidaparti,“Ikt-bt:Indirectknowl-
language-action models transfer web knowledge to robotic control,”
edgetransferbehaviortreeframeworkformulti-robotsystemsthrough
arXivpreprintarXiv:2307.15818,2023.
communication eavesdropping,” arXiv preprint arXiv:2312.11802,
[9] S. Kambhampati, K. Valmeekam, L. Guan, K. Stechly, M. Verma,
2023.
S. Bhambri, L. Saldyt, and A. Murthy, “Llms can’t plan, but
[21] D.Kahneman,Thinking,fastandslow. macmillan,2011.
can help planning in llm-modulo frameworks,” arXiv preprint
arXiv:2402.01817,2024.
[10] S.Oruganti,S.Nirenburg,J.English,andM.McShane,“Automating
knowledgeacquisitionforcontent-centriccognitiveagentsusingllms,”
inProceedingsoftheAAAISymposiumSeries,vol.2,no.1,2023,pp.
379–385.
[11] M.McShane,S.Nirenburg,andJ.English,Agentsinthelonggame
ofAI. MITPress,2024.
[12] J. English and S. Nirenburg, “Ontoagent: Implementing content-