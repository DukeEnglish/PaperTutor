Self-supervised pretraining for cardiovascular
magnetic resonance cine segmentation
Rob A.J. de Mooij((cid:0)) , Josien P.W. Pluim, and Cian M. Scannell
Department of Biomedical Engineering, Eindhoven University of Technology,
Eindhoven, The Netherlands
r.a.j.d.mooij@tue.nl
Abstract. Self-supervised pretraining (SSP) has shown promising re-
sultsinlearningfromlargeunlabeleddatasetsand,thus,couldbeuseful
forautomatedcardiovascularmagneticresonance(CMR)short-axiscine
segmentation. However, inconsistent reports of the benefits of SSP for
segmentation have made it difficult to apply SSP to CMR. Therefore,
this study aimed to evaluate SSP methods for CMR cine segmentation.
To this end, short-axis cine stacks of 296 subjects (90618 2D slices)
wereusedforunlabeledpretrainingwithfourSSPmethods;SimCLR,po-
sitionalcontrastivelearning,DINO,andmaskedimagemodeling(MIM).
Subsets of varying numbers of subjects were used for supervised fine-
tuningof2DmodelsforeachSSPmethod,aswellastotraina2Dbase-
line model from scratch. The fine-tuned models were compared to the
baseline using the 3D Dice similarity coefficient (DSC) in a test dataset
of 140 subjects.
The SSP methods showed no performance gains with the largest
supervised fine-tuning subset compared to the baseline (DSC = 0.89).
Whenonly10subjects(2312Dslices)areavailableforsupervisedtrain-
ing, SSP using MIM (DSC = 0.86) improves over training from scratch
(DSC = 0.82).
This study found that SSP is valuable for CMR cine segmentation
when labeled training data is scarce, but does not aid state-of-the-art
deep learning methods when ample labeled data is available. Moreover,
the choice of SSP method is important. The code is publicly available
at: https://github.com/q-cardIA/ssp-cmr-cine-segmentation
Keywords: Self-supervised learning · Image segmentation · Cardiovas-
cular magnetic resonance · Deep learning.
1 Introduction
Self-supervised learning allows deep learning models to learn useful information
from unlabeled data [1]. Self-supervised and traditional supervised learning are
often combined for specific tasks, where a model first trains on unlabeled data
with self-supervised pretraining (SSP), before supervised fine-tuning on labeled
data for a specific downstream task [17]. SSP could be especially important in
medical imaging, due to the lack of high quality labeled datasets.
4202
peS
62
]VC.sc[
1v00181.9042:viXra2 R.A.J. de Mooij et al.
Cardiovascular magnetic resonance (CMR) short-axis cine segmentation is
aninterestingproblemonwhichtoinvestigateSSP,bothfromamethodological
and clinical perspective. CMR short-axis cine data consists of 4D (3D + time)
images,allowingSSPmethodsthatincorporatespatialandtemporalinformation
into the pretraining task [11,15]. Additionally, labeled short-axis cine datasets
consist of many unlabeled images as only certain cardiac phases are annotated.
Therefore, models can be pretrained with SSP on all available images and fine-
tuned on the labeled cardiac phases. Finally, improving the accuracy of CMR
segmentation, potentially with SSP, could improve the evaluation of cardiac
structure and function in the clinic [6,13].
However, SSP has yielded conflicting results in its application in medical
imaging.ManySSPmethodshavebeenproposedformedicalimaging,butmany
resultshavebeendifficulttogeneralizetodifferentproblemsanddata[16].Med-
icalclassificationproblemshaveseenmultiplepromisingSSPmethods[9].How-
ever, benefits of SSP in segmentation tasks often hold only with very limited
labeled training data [11,14,16]. Additionally, it is difficult to disentangle the
effect of SSP from that of novel architectures such as vision transformers (ViT),
and results depend on data and training hyperparameters [16]. These inconsis-
tent findings make it challenging to choose the most effective SSP method in
medical imaging problems, especially for segmentation tasks.
This study investigates SSP methods for CMR cine segmentation with con-
volutional neural networks (CNNs), and the effectiveness of SSP methods with
varying amounts of labeled data available during supervised fine-tuning. In par-
ticular, we will: (1) develop a strong CMR cine segmentation model to serve as
baseline, (2) optimize four promising SSP methods for unlabeled pretraining of
the baseline model, (3) compare the fine-tuned models, after SSP, to the base-
line in downstream segmentation performance with varying amounts of labeled
fine-tuning data, and (4) investigate the effects of data augmentation and SSP
on model generalizability.
2 Methods
2.1 Data
Short-axiscinedataoftheM&Ms[2]andM&Ms-2[12]challengeswereusedfor
a total of 510 subjects. For each subject, a 4D cine image was available with a
varying number of slices (median 11) and time frames (median 25). Each cine
image had labels for the end diastole (ED) and end systole (ES) time frames,
delineatingtheleftventricle(LV),myocardium(MYO),andrightventricle(RV).
All 345 publicly available subjects of the M&Ms challenge data were included.
Only165subjectsoftheM&Ms-2challengedatawereincludedtoavoidpossible
overlapping subjects.
Data were split on a subject level into 296 training, 74 validation, and 140
test subjects. First, 60 test subjects were selected from the M&Ms data, using
random sampling stratified by MR scanner vendor. The 80 test subjects for theSelf-supervised pretraining for CMR cine segmentation 3
M&Ms-2 challenge data were obtained from the original challenge test set, after
removing the subjects with possible overlap. The remaining 370 subjects were
then randomly divided into training and validation using an 80/20% split.
The training set consisted of 90618 2D slices, of which 6738 were labeled.
To simulate the effect of smaller labeled datasets, three subsets of 50, 25, 15
and 10 random training subjects were used, consisting of on average 1151, 582,
349, and 231 slices respectively, depending on the subject subset. The labeled
validation dataset was used for hyperparameter optimization, while the labeled
test dataset was only used for the final evaluation.
2.2 Baseline model
A 2D fully convolutional U-Net baseline model was developed based on the
nnU-Net method [10]. All hyperparameters were set based on the automatic
configuration and CMR data experiments of the original nnU-Net work, includ-
ing deep supervision, with more extreme data augmentation implemented to
improve robustness and stability. The baseline was trained from scratch sepa-
rately on the fully labeled training dataset and its subsets, which was repeated
with three training seeds. This model setup served as a realistic baseline with a
competitive performance in 2D cine segmentation against which to compare the
SSP methods.
2.3 Self-supervised pretraining methods
FourSSPmethodswerecompared;asimpleframeworkforcontrastivelearningof
visual representations (SimCLR) [4], positional contrastive learning (PCL) [15],
self-distillation with no labels (DINO) [3], and masked image modeling (MIM)
[5,7,8].Thesemethodsareillustratedinfigure1.SimCLR,PCL,andDINOwere
used to pretrain the encoder of the 2D U-Net, while MIM was used to pretrain
both the encoder and decoder of the 2D U-Net.
Contrastive learning methods like SimCLR and PCL aim to train the model
to extract useful features from the images by contrasting positive and negative
image pairs. It aims for a feature space where positive image pairs are close
together, while negative image pairs are further apart [16]. For SimCLR and
PCL, positive and negative image pairs are obtained from a training batch of
augmented images, containing two instances of the same image with different
dataaugmentations.ForSimCLR,onlythetwoaugmentedversionsofthesame
image are considered a positive pair, while every other image pair is a negative
pair [4]. In PCL, each 2D image is assigned a relative position in the range [0,
1],indicatingitsrelativepositioninthe3Dvolumeitoriginatedfrom.Animage
pair is considered positive when the difference between their relative positions
is below a certain threshold [15].
With DINO, a student network learns from a teacher network how to pre-
dict global image features from local image patches [3]. For each image, eight
augmented copies are used; two global crops, and six local crops. The teacher
network receives the two global crops, while the student network receives both4 R.A.J. de Mooij et al.
minimize maximize ∆pos = 0.03 ∆pos = 0.56 minimize cross entropy
distance distance minimize distancemaximize distance
feature feature
(positive pair)(negative pair) (positive pair) (negative pair)
stop grad
feature feature feature feature feature feature softmax softmax
centering
head head head head head head head head
encoder encoder encoder encoder encoder encoder student ema teacher encoder
encoder encoder
pos=0.30 pos=0.33 pos=0.89
augment augment augment augment augment local+global global mask
augment augment
image 1 image 2 1 1
0 0
(a) SimCLR (b) PCL (c) DINO (d)MIM
Fig.1: Visualizations of the four SSP methods that were used.
the global and local crops. The student is trained to output the same as the
teacher, while the teacher is only updated with the exponential moving average
of the student network.
MIM trains a model to restore an image that has been partially masked. An
augmented image is first divided into equally sized patches, after which some
of these patches are masked out. Patches are masked out by setting their pixel
intensities to a predetermined value [7].
2.4 Pretraining
Allmethodswerepretrained,withoutlabels,onthefulltrainingdatasetof90618
slices. Pretraining hyperparameters were based on the hyperparameters from
the original implementation. Hyperparameters were further fine-tuned for each
method based on pretraining stability and cine segmentation performance af-
ter fine-tuning. Choices that worked well for all pretraining methods included:
(1) 100 epochs, (2) stochastic gradient descent (SGD) optimizer, (3) extensive
data augmentation, and (4) cosine learning rate scheduler. Details for all model
trainings can be found in supplementary material A.
SimCLRhadnomethod-specifichyperparameters,whiletherelativeposition
threshold for positive pairs in PCL was chosen as 0.1. For DINO, the original
hyperparameters from the CNN experiments were used for reference [3]. Global
andlocalpatchsizeswereincreasedto256x256and128x128respectivelydueto
thedeepCNNarchitecturerequiringtheimagesizetobedivisibleby64.Finally,
the DINO head output dimensionality was reduced to 8192.
The MIM hyperparameters were adapted based on multiple similar imple-
mentations [5,7,8]. A patch size of 32x32 was used, with a mask ratio of 0.75,
1
tcejbus
2
tcejbusSelf-supervised pretraining for CMR cine segmentation 5
and a constant masking value of 0.0, applied after image standardization and
data augmentation. The architecture was the same as that of the 2D baseline
model,exceptfortheremovaloftheadditionaloutputs,asdeepsupervisionwas
not used during MIM pretraining. Transferring the weights of the encoder and
decoder, but without the output convolution at the end, resulted in the best
downstream performance. A mean squared error loss was used, applied only on
the masked patches.
2.5 Fine-tuning
After SSP with all available images, models were fine-tuned separately on all
labeled time frames and subsets of that. Fine-tuning was repeated three times
for each pretrained model, changing the training seed that determined data
loading, data augmentation, and model weight initialization for weights that
had not been pretrained. The training seed was also used to select the subjects
in the subset experiments. Fine-tuning used the hyperparameters of the fully-
supervised training of the baseline from scratch with the learning rate lowered
to 0.005.
2.6 Generalization evaluation
The best performing SSP method was further investigated to give insights into
its behaviour. Two experiments investigated the generalizability of fine-tuned
models after SSP on all data. For each experiment, the best performing SSP
method was used to pretrain on all available data, while fine-tuning and test
data were varied. Data augmentation was investigated separately, for a total of
three experiments:
Generalization to unseen cardiac phases. To evaluate the benefit of
SSPingeneralizingtodataunseenduringfine-tuning,welimitedthefine-tuning
datatoasinglecardiacphase,allowingforout-of-domainevaluation.Abaseline
model was trained from scratch on a single time frame per subject forreference.
Then,themodelpretrainedonalldatawasfine-tunedonasingletimeframeper
subject.EachexperimentwasperformedseparatelyforEDandEStimeframes.
Generalization to unseen vendors. A similar experiment was performed
toinvestigatethegeneralizabilitytovendorsunseenduringfine-tuning.Thefour
vendors of the M&Ms challenge datasets were divided into two groups: Siemens
and Philips (A+B), and General Electric and Canon (C+D). Baseline training
and SSP fine-tuning were trained on both vendor groups separately. The in-
domain and out-of-domain performance of the resulting models was compared
separately on the test data.
Generalizationfromdataaugmentation.Sofar,allmodelsweretrained
withdataaugmentation,makingitdifficulttoknowtowhatextentmodelperfor-
manceandrobustnesswasduetoSSP,andtowhatextenttodataaugmentation.
Therefore, this final experiment trained versions of the baseline and best per-
forming SSP method without data augmentation during training from scratch
and fine-tuning respectively.6 R.A.J. de Mooij et al.
2.7 Evaluation
Segmentation performance was evaluated with the Dice similarity coefficient
(DSC) in 3D, for both the ED and ES time frames. The metric was calculated
separatelyfortheLV,MYOandRVclasses.Foreachfine-tunedmodel,themean
DSC across the three classes and for all test subjects was calculated. The SSP
methods were compared with the baseline model for the three random training
seeds.Forthegeneralizationexperiments,testsubsetsfordifferentcardiacphases
and vendors were also evaluated separately.
All pretraining and fine-tuning used custom implementations that are avail-
able at https://github.com/q-cardIA/ssp-cmr-cine-segmentation.
3 Results
The mean test DSCs across all foreground classes and varying numbers of fine-
tuning subjects can be seen in table 1. All models show similar performances
whentrainedorfine-tunedonallavailablelabeledtrainingdata.Thisalsoholds
when looking at individual classes. All models showed mean 3D test DSCs of
0.93, 0.85, and 0.90 for the LV, MYO, and RV classes respectively. More details
are shown in supplementary material B.
Table 1: Mean test DSC across all 140 test subjects and foreground classes for
thebaselineandfine-tunedSSPmodels,forvaryingnumbersoflabeledsubjects
± sample standard deviation across different training seeds. For each number of
labeled subjects, the average number of slices across all training seeds is shown.
The biggest performance increase compared to the baseline is indicated in bold.
#subjects
Baseline SimCLR PCL DINO MIM
(#slices)
296 (6738) 0.89 ± 0.001 0.89 ± 0.002 0.89 ± 0.003 0.89 ± 0.001 0.89 ± 0.001
50 (1151) 0.87 ± 0.007 0.87 ± 0.011 0.88 ± 0.005 0.87 ± 0.006 0.88 ± 0.006
25 (582) 0.86 ± 0.003 0.86 ± 0.014 0.85 ± 0.014 0.84 ± 0.002 0.87 ± 0.007
15 (349) 0.84 ± 0.007 0.83 ± 0.024 0.85 ± 0.009 0.79 ± 0.009 0.86 ± 0.015
10 (231) 0.82 ± 0.009 0.80 ± 0.024 0.84 ± 0.009 0.74 ± 0.022 0.86 ± 0.007
Asshownintable1,PCLandMIMpretrainingoutperformthebaselineper-
formance for smaller labeled fine-tuning subsets. The biggest increase compared
to the baseline can be seen for MIM pretraining and fine-tuning on the smallest
labeled subset. SimCLR and DINO pretraining, on the other hand, show a per-
formance decrease for fine-tuning on smaller labeled subsets, as well as a higher
sample standard deviation.
Since MIM pretraining consistently showed the best results, MIM was used
forthegeneralizationevaluation.Tables2and3showtheresultsforthefirsttwo
generalization experiments, investigating fine-tuned model generalization to un-
seen (during fine-tuning) cardiac phases and vendors. Both experiments showedSelf-supervised pretraining for CMR cine segmentation 7
similaroverall,in-domain,andout-of-domainbaselineperformances.Forlabeled
ED time frames fine-tuning, both overall and out-of-domain performances in-
creasedslightlywithSSP.Contrastingly,labeledEStimeframesfine-tuningonly
showed a slight in-domain performance increase with SSP. SSP did not result in
changes in performance when fine-tuning on labeled vendors A and B. A slight
increase in out-of-domain performance can be seen after fine-tuning on labeled
vendors C and D.
Table 2: Mean test DSC ± sample standard deviation, comparing fine-tuned
model generalization to unseen cardiac phases. Improvements after SSP are in-
dicated in bold.
Both time ED time ES time
Pretraining Fine-tuning
frames frames frames
None ED time frames 0.88 ± 0.001 0.90 ± 0.002 0.86 ± 0.002
All data ED time frames 0.89 ± 0.001 0.90 ± 0.001 0.87 ± 0.001
None ES time frames 0.88 ± 0.007 0.88 ± 0.012 0.88 ± 0.002
All data ES time frames 0.88 ± 0.001 0.88 ± 0.001 0.89 ± 0.000
Table 3: Mean test DSC ± sample standard deviation, comparing fine-tuned
model generalization to unseen vendors. Improvements after SSP are indicated
in bold.
Pretraining Fine-tuning All vendors Vendors A+B Vendors C+D
None Vendors A+B 0.89 ± 0.001 0.89 ± 0.001 0.88 ± 0.002
All data Vendors A+B 0.89 ± 0.001 0.89 ± 0.001 0.88 ± 0.000
None Vendors C+D 0.88 ± 0.002 0.87 ± 0.001 0.89 ± 0.004
All data Vendors C+D 0.88 ± 0.001 0.88 ± 0.002 0.89 ± 0.002
The baseline mean test DSC (± sample standard deviation across training
seeds) of 0.89 ± 0.001 decreased to 0.69 ± 0.039 when trained without data
augmentation. With MIM pretraining, the mean test DSC of 0.89 ± 0.001 low-
eredto0.78±0.040withoutdataaugmentation,asmallerdecreasethanforthe
baseline model.
The DSCs for varying cardiac phase and vendor subsets for baseline models
trained on all labeled data with and without data augmentation can be seen in
table 4. This shows that without data augmentation, there is a large difference
inDSCbetweenEDandEStimeframes,aswellasbetweenbothvendorgroups.
With data augmentation the performance gap between times frames is mostly
bridged, while the performance gap between vendors is bridged completely.8 R.A.J. de Mooij et al.
Table 4: Mean test DSC ± standard deviation, for varying cardiac phases and
vendor subsets, for baseline models with and without data augmentation.
ED time ES time Vendors Vendors
Data augmentation
frames frames A+B C+D
Yes 0.90 ± 0.001 0.88 ± 0.003 0.89 ± 0.001 0.89 ± 0.006
No 0.71 ± 0.042 0.66 ± 0.036 0.72 ± 0.036 0.61 ± 0.049
4 Discussion
This study aimed to investigate SSP methods for CMR cine segmentation with
CNNs,andtheeffectivenessofSSPmethodswithvaryingamountsoffine-tuning
data.More specifically, fourSSP methodswere comparedto abaseline forvary-
ingnumbersoflabeledsubjectsforfine-tuning.Additionally,furtherexperiments
investigated generalizability of fine-tuned models for unseen cardiac phases and
MR scanner vendors after SSP, and generalizability due to data augmentation.
Table1indicatesthatSSPwithunlabeleddataonlyyieldsanimprovementin
CMRcinesegmentationwhenverylimitedamountsoflabeleddataareavailable
for fine-tuning. Moreover, choice of SSP method is important. PCL and MIM
showed performance increases for small labeled fine-tuning datasets, indicating
that these methods contribute useful information for the problem. MIM may
be the most effective because it pretrains both the encoder and decoder of the
U-Net architecture.
SimCLR and DINO show decreased performances for limited amounts of la-
beleddata,withagenerallyhigherstandarddeviation.DINOpretrainingshows
the largest performance decrease, a potential explanation is that it is ill-suited
for CNN architectures, as it is designed for ViTs. Additionally, both SimCLR
and DINO generally require large batch sizes during training which was limited
by our available hardware [3,4].
ThecardiacphasegeneralizationexperimentshowsaslightbenefitinSSPin
generalizing to unseen (during fine-tuning) cardiac phases. Out-of-domain per-
formancescanslightlyincreasewithSSP,whilein-domainperformancesdidnot
decrease.ThisindicatesthattheremaybebenefitinSSPinthissituation.How-
ever,thebaselinemodelsalreadyshowtheabilitytogeneralizetounseencardiac
phases,leavinglittleroomforimprovementasaresultofSSP.Thiscouldbeex-
plainedbythedataaugmentation.Table4showsthatthereisaperformancegap
between cardiacphases whentrainingon alllabeleddatawithoutdataaugmen-
tation. However, adding data augmentation largely closes this gap, indicating
that data augmentation accounts for most of the generalizability shown in the
unseen cardiac phase experiment.
Similar results can be seen for the unseen vendor experiment, showing a
small out-of-domain performance increase. For the two vendor groups, table 4
also shows a large performance gap without data augmentation, which is closed
with data augmentation. While these models were trained on all labeled data,
these results do indicate the importance of data augmentation in general modelSelf-supervised pretraining for CMR cine segmentation 9
performance and generalizability to unseen data. The results of the data aug-
mentation experiment in combination with MIM pretraining further show the
importance of data augmentation, even when using SSP. While SSP shows a
clearbenefitwhennotusingdataaugmentationinfine-tuningandtrainingfrom
scratch, data augmentation is still necessary to achieve the best performance.
This indicates that data augmentation can better cover the data distribution
compared to our SSP methods with larger unlabeled datasets. These results
support claims that data augmentation can mostly meet or exceed the benefits
of SSP, when appropriately selected for the downstream task [16]. However, our
results also indicate that data augmentation is a crucial step in enabling the
possible benefits of SSP.
Future research should further investigate whether these findings hold when
usingothermodelarchitectures,includingViTs.SSPmethodssuchasDINOand
MIMaregenerallydevelopedforandperformbetteronViTs[3,5].However,this
studyintentionallyfocusedonCNNarchitectures,toseparatetheeffectsofSSP
from new model architectures.
In conclusion, SSP can be beneficial for CMR cine segmentation with lim-
ited amounts of labeled data, but its effectiveness depends on the SSP method.
Additionally, SSP with large unlabeled datasets can provide slight benefits in
generalizing to unseen domains for which labeled data is not available but unla-
beled data is available for SSP.
Disclosure of Interests. The authors have no competing interests to declare that
are relevant to the content of this article.
References
1. Balestriero, R., Ibrahim, M., Sobal, V., Morcos, A., Shekhar, S., Goldstein, T.,
Bordes, F., Bardes, A., Mialon, G., Tian, Y., Schwarzschild, A., Wilson, A.G.,
Geiping, J., Garrido, Q., Fernandez, P., Bar, A., Pirsiavash, H., LeCun, Y., Gold-
blum, M.: A Cookbook of Self-Supervised Learning (Jun 2023), http://arxiv.
org/abs/2304.12210, arXiv:2304.12210 [cs]
2. Campello, V.M., Gkontra, P., Izquierdo, C., Martin-Isla, C., Sojoudi, A., Full,
P.M., Maier-Hein, K., Zhang, Y., He, Z., Ma, J., Parreno, M., Albiol, A., Kong,
F., Shadden, S.C., Acero, J.C., Sundaresan, V., Saber, M., Elattar, M., Li, H.,
Menze,B.,Khader,F.,Haarburger,C.,Scannell,C.M.,Veta,M.,Carscadden,A.,
Punithakumar, K., Liu, X., Tsaftaris, S.A., Huang, X., Yang, X., Li, L., Zhuang,
X., Vilades, D., Descalzo, M.L., Guala, A., Mura, L.L., Friedrich, M.G., Garg,
R., Lebel, J., Henriques, F., Karakas, M., Cavus, E., Petersen, S.E., Escalera, S.,
Segui,S.,Rodriguez-Palomares,J.F.,Lekadir,K.:Multi-Centre,Multi-Vendorand
Multi-DiseaseCardiacSegmentation:TheM&MsChallenge.IEEETransactionson
Medical Imaging 40(12), 3543–3554 (Dec 2021). https://doi.org/10.1109/TMI.
2021.3090082
3. Caron,M.,Touvron,H.,Misra,I.,Jegou,H.,Mairal,J.,Bojanowski,P.,Joulin,A.:
EmergingPropertiesinSelf-SupervisedVisionTransformers.In:2021IEEE/CVF
InternationalConferenceonComputerVision(ICCV).pp.9630–9640.IEEE,Mon-
treal,QC,Canada(Oct2021).https://doi.org/10.1109/ICCV48922.2021.0095110 R.A.J. de Mooij et al.
4. Chen, T., Kornblith, S., Norouzi, M., Hinton, G.: A Simple Framework for Con-
trastive Learning of Visual Representations (Jun 2020), http://arxiv.org/abs/
2002.05709, arXiv:2002.05709 [cs, stat]
5. Chen,Z.,Agarwal,D.,Aggarwal,K.,Safta,W.,Balan,M.M.,Brown,K.:Masked
ImageModelingAdvances3DMedicalImageAnalysis.In:2023IEEE/CVFWin-
ter Conference on Applications of Computer Vision (WACV). pp. 1969–1979.
IEEE, Waikoloa, HI, USA (Jan 2023). https://doi.org/10.1109/WACV56688.
2023.00201
6. Davies, R.H., Augusto, J.B., Bhuva, A., Xue, H., Treibel, T.A., Ye, Y., Hughes,
R.K., Bai, W., Lau, C., Shiwani, H., Fontana, M., Kozor, R., Herrey, A., Lopes,
L.R.,Maestrini,V.,Rosmini,S.,Petersen,S.E.,Kellman,P.,Rueckert,D.,Green-
wood,J.P.,Captur,G.,Manisty,C.,Schelbert,E.,Moon,J.C.:Precisionmeasure-
mentofcardiacstructureandfunctionincardiovascularmagneticresonanceusing
machine learning. Journal of Cardiovascular Magnetic Resonance 24(1), 16 (Jan
2022). https://doi.org/10.1186/s12968-022-00846-4
7. Dominic, J., Bhaskhar, N., Desai, A.D., Schmidt, A., Rubin, E., Gunel, B., Gold,
G.E.,Hargreaves,B.A.,Lenchik,L.,Boutin,R.,Chaudhari,A.S.:ImprovingData-
Efficiency and Robustness of Medical Imaging Segmentation Using Inpainting-
Based Self-Supervised Learning. Bioengineering 10(2), 207 (Feb 2023). https:
//doi.org/10.3390/bioengineering10020207
8. He, K., Chen, X., Xie, S., Li, Y., Dollár, P., Girshick, R.: Masked Autoencoders
Are Scalable Vision Learners (Dec 2021), http://arxiv.org/abs/2111.06377,
arXiv:2111.06377 [cs]
9. Huang, S.C., Pareek, A., Jensen, M., Lungren, M.P., Yeung, S., Chaudhari, A.S.:
Self-supervised learning for medical image classification: a systematic review and
implementation guidelines. npj Digital Medicine 6(1), 74 (Apr 2023). https://
doi.org/10.1038/s41746-023-00811-0
10. Isensee, F., Jaeger, P.F., Kohl, S.A.A., Petersen, J., Maier-Hein, K.H.: nnU-Net:
a self-configuring method for deep learning-based biomedical image segmenta-
tion. Nature Methods 18(2), 203–211 (Feb 2021). https://doi.org/10.1038/
s41592-020-01008-z
11. Kalapos, A., Gyires-Tóth, B.: Self-Supervised Pretraining for 2D Medical Image
Segmentation (2023), http://arxiv.org/abs/2209.00314, arXiv:2209.00314 [cs]
12. Martín-Isla,C.,Campello,V.M.,Izquierdo,C.,Kushibar,K.,Sendra-Balcells,C.,
Gkontra, P., Sojoudi, A., Fulton, M.J., Arega, T.W., Punithakumar, K., Li, L.,
Sun, X., Al Khalil, Y., Liu, D., Jabbar, S., Queirós, S., Galati, F., Mazher, M.,
Gao, Z., Beetz, M., Tautz, L., Galazis, C., Varela, M., Hüllebrand, M., Grau, V.,
Zhuang,X.,Puig,D.,Zuluaga,M.A.,Mohy-udDin,H.,Metaxas,D.,Breeuwer,M.,
Van Der Geest, R.J., Noga, M., Bricq, S., Rentschler, M.E., Guala, A., Petersen,
S.E., Escalera, S., Palomares, J.F.R., Lekadir, K.: Deep Learning Segmentation
of the Right Ventricle in Cardiac MRI: The M&Ms Challenge. IEEE Journal of
Biomedical and Health Informatics 27(7), 3302–3313 (Jul 2023). https://doi.
org/10.1109/JBHI.2023.3267857
13. Sirajuddin, A., Mirmomen, S.M., Kligerman, S.J., Groves, D.W., Burke, A.P.,
Kureshi,F.,White,C.S.,Arai,A.E.:IschemicHeartDisease:NoninvasiveImaging
Techniques and Findings. RadioGraphics 41(4), E990–E1021 (Jul 2021). https:
//doi.org/10.1148/rg.2021200125
14. VanBerlo, B., Hoey, J., Wong, A.: A survey of the impact of self-supervised
pretraining for diagnostic tasks in medical X-ray, CT, MRI, and ultrasound.Self-supervised pretraining for CMR cine segmentation 11
BMC Medical Imaging 24(1), 79 (Apr 2024). https://doi.org/10.1186/
s12880-024-01253-0
15. Zeng, D., Wu, Y., Hu, X., Xu, X., Yuan, H., Huang, M., Zhuang, J., Hu, J., Shi,
Y.: Positional Contrastive Learning for Volumetric Medical Image Segmentation
(Sep 2021), http://arxiv.org/abs/2106.09157, arXiv:2106.09157 [cs]
16. Zhang, C., Zheng, H., Gu, Y.: Dive into the details of self-supervised learning for
medical image analysis. Medical Image Analysis 89, 102879 (Oct 2023). https:
//doi.org/10.1016/j.media.2023.102879
17. Zoph,B.,Ghiasi,G.,Lin,T.Y.,Cui,Y.,Liu,H.,Cubuk,E.D.,Le,Q.V.:Rethinking
Pre-training and Self-training. CoRR abs/2006.06882 (2020)12 R.A.J. de Mooij et al.
Supplementary materials
A Training details
Hyperparameters for each model training. The DINO learning rate is reported
after applying the linear scaling rule based on batch size.
Hyperparameter Baseline SimCLR PCL DINO MIM Fine-tuning
Epochs 1000 100 100 100 100 1000
Learning rate 0.01 0.1 0.1 0.0075 0.01 0.005
Scheduler Polynomial Cosine Cosine Cosine Cosine Polynomial
Optimizer SGD SGD SGD SGD SGD SGD
Nesterov momentum yes no no no yes yes
Momentum 0.99 0.9 0.9 0.9 0.99 0.99
Weight decay 3.0e-05 1.0e-04 1.0e-05 1.0e-04 3.0e-05 3.0e-05
Batch size 32 224 64 64 128 32
Mixed precision no yes no yes yes no
B Test DSC per class
Mean test DSC for the baseline and fine-tuned SSP models, for separate fore-
ground classes ± mean sample standard deviation across all 140 test subjects.
Class Baseline SimCLR PCL DINO MIM
LV 0.93 ± 0.047 0.93 ± 0.047 0.93 ± 0.048 0.93 ± 0.048 0.93 ± 0.048
MYO 0.85 ± 0.055 0.85 ± 0.048 0.85 ± 0.052 0.85 ± 0.052 0.85 ± 0.053
RV 0.90 ± 0.062 0.90 ± 0.064 0.90 ± 0.061 0.90 ± 0.068 0.90 ± 0.068