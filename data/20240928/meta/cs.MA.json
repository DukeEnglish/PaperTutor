[
    {
        "title": "Explaining Explaining",
        "authors": "Sergei NirenburgMarjorie McShaneKenneth W. GoodmanSanjay Oruganti",
        "links": "http://arxiv.org/abs/2409.18052v1",
        "entry_id": "http://arxiv.org/abs/2409.18052v1",
        "pdf_url": "http://arxiv.org/pdf/2409.18052v1",
        "summary": "Explanation is key to people having confidence in high-stakes AI systems.\nHowever, machine-learning-based systems - which account for almost all current\nAI - can't explain because they are usually black boxes. The explainable AI\n(XAI) movement hedges this problem by redefining \"explanation\". The\nhuman-centered explainable AI (HCXAI) movement identifies the\nexplanation-oriented needs of users but can't fulfill them because of its\ncommitment to machine learning. In order to achieve the kinds of explanations\nneeded by real people operating in critical domains, we must rethink how to\napproach AI. We describe a hybrid approach to developing cognitive agents that\nuses a knowledge-based infrastructure supplemented by data obtained through\nmachine learning when applicable. These agents will serve as assistants to\nhumans who will bear ultimate responsibility for the decisions and actions of\nthe human-robot team. We illustrate the explanatory potential of such agents\nusing the under-the-hood panels of a demonstration system in which a team of\nsimulated robots collaborates on a search task assigned by a human.",
        "updated": "2024-09-26 16:55:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.18052v1"
    },
    {
        "title": "HARMONIC: Cognitive and Control Collaboration in Human-Robotic Teams",
        "authors": "Sanjay OrugantiSergei NirenburgMarjorie McShaneJesse EnglishMichael K. RobertsChristian Arndt",
        "links": "http://arxiv.org/abs/2409.18047v1",
        "entry_id": "http://arxiv.org/abs/2409.18047v1",
        "pdf_url": "http://arxiv.org/pdf/2409.18047v1",
        "summary": "This paper presents a novel approach to multi-robot planning and\ncollaboration. We demonstrate a cognitive strategy for robots in human-robot\nteams that incorporates metacognition, natural language communication, and\nexplainability. The system is embodied using the HARMONIC architecture that\nflexibly integrates cognitive and control capabilities across the team. We\nevaluate our approach through simulation experiments involving a joint search\ntask by a team of heterogeneous robots (a UGV and a drone) and a human. We\ndetail the system's handling of complex, real-world scenarios, effective action\ncoordination between robots with different capabilities, and natural\nhuman-robot communication. This work demonstrates that the robots' ability to\nreason about plans, goals, and attitudes, and to provide explanations for\nactions and decisions are essential prerequisites for realistic human-robot\nteaming.",
        "updated": "2024-09-26 16:48:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.18047v1"
    },
    {
        "title": "HARMONIC: A Framework for Explanatory Cognitive Robots",
        "authors": "Sanjay OrugantiSergei NirenburgMarjorie McShaneJesse EnglishMichael K. RobertsChristian Arndt",
        "links": "http://arxiv.org/abs/2409.18037v1",
        "entry_id": "http://arxiv.org/abs/2409.18037v1",
        "pdf_url": "http://arxiv.org/pdf/2409.18037v1",
        "summary": "We present HARMONIC, a framework for implementing cognitive robots that\ntransforms general-purpose robots into trusted teammates capable of complex\ndecision-making, natural communication and human-level explanation. The\nframework supports interoperability between a strategic (cognitive) layer for\nhigh-level decision-making and a tactical (robot) layer for low-level control\nand execution. We describe the core features of the framework and our initial\nimplementation, in which HARMONIC was deployed on a simulated UGV and drone\ninvolved in a multi-robot search and retrieval task.",
        "updated": "2024-09-26 16:42:13 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.18037v1"
    },
    {
        "title": "Control Industrial Automation System with Large Language Models",
        "authors": "Yuchen XiaNasser JazdiJize ZhangChaitanya ShahMichael Weyrich",
        "links": "http://arxiv.org/abs/2409.18009v1",
        "entry_id": "http://arxiv.org/abs/2409.18009v1",
        "pdf_url": "http://arxiv.org/pdf/2409.18009v1",
        "summary": "Traditional industrial automation systems require specialized expertise to\noperate and complex reprogramming to adapt to new processes. Large language\nmodels offer the intelligence to make them more flexible and easier to use.\nHowever, LLMs' application in industrial settings is underexplored. This paper\nintroduces a framework for integrating LLMs to achieve end-to-end control of\nindustrial automation systems. At the core of the framework are an agent system\ndesigned for industrial tasks, a structured prompting method, and an\nevent-driven information modeling mechanism that provides real-time data for\nLLM inference. The framework supplies LLMs with real-time events on different\ncontext semantic levels, allowing them to interpret the information, generate\nproduction plans, and control operations on the automation system. It also\nsupports structured dataset creation for fine-tuning on this downstream\napplication of LLMs. Our contribution includes a formal system design,\nproof-of-concept implementation, and a method for generating task-specific\ndatasets for LLM fine-tuning and testing. This approach enables a more adaptive\nautomation system that can respond to spontaneous events, while allowing easier\noperation and configuration through natural language for more intuitive\nhuman-machine interaction. We provide demo videos and detailed data on GitHub:\nhttps://github.com/YuchenXia/LLM4IAS",
        "updated": "2024-09-26 16:19:37 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.18009v1"
    },
    {
        "title": "Modular Autonomous Vehicle in Heterogeneous Traffic Flow: Modeling, Simulation, and Implication",
        "authors": "Lanhang YeToshiyuki Yamamoto",
        "links": "http://arxiv.org/abs/2409.17945v1",
        "entry_id": "http://arxiv.org/abs/2409.17945v1",
        "pdf_url": "http://arxiv.org/pdf/2409.17945v1",
        "summary": "Modular autonomous vehicles (MAVs) represent a groundbreaking concept that\nintegrates modularity into the ongoing development of autonomous vehicles. This\ninnovative design introduces unique features to traffic flow, allowing multiple\nmodules to seamlessly join together and operate collectively. To understand the\ntraffic flow characteristics involving these vehicles and their collective\noperations, this study established a modeling framework specifically designed\nto simulate their behavior within traffic flow. The mixed traffic flow,\nincorporating arbitrarily formed trains of various modular sizes, is modeled\nand studied. Simulations are conducted under varying levels of traffic demand\nand penetration rates to examine the traffic flow dynamics in the presence of\nthese vehicles and their operations. The microscopic trajectories, MAV train\ncompositions, and macroscopic fundamental diagrams of the mixed traffic flow\nare analyzed. The simulation findings indicate that integrating MAVs and their\ncollective operations can substantially enhance capacity, with the extent of\nimprovement depending on the penetration rate in mixed traffic flow. Notably,\nthe capacity nearly doubles when the penetration rate exceeds 75%. Furthermore,\ntheir presence significantly influences and regulates the free-flow speed of\nthe mixed traffic. Particularly, when variations in operational speed limits\nexist between the MAVs and the background traffic, the mixed traffic adjusts to\nthe operating velocity of these vehicles. This study provides insights into\npotential future traffic flow systems incorporating emerging MAV technologies.",
        "updated": "2024-09-26 15:20:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.17945v1"
    }
]