Unlocking Insights: Semantic Search in Jupyter
Notebooks⋆
Lan Li1[0000−0003−4499−4126] and Jinpeng Lv2
1 Center for Informatics Research in Science & Scholarship
School of Information Sciences
University of Illinois at Urbana-Champaign, USA
lanl2@illinois.edu
2 Research System Team, Microsoft, Redmond, USA
jinpeng.lv@microsoft.com
Abstract. Semantic search, a process aimed at delivering highly rele-
vant search results by comprehending the searcher’s intent and the con-
textual meaning of terms within a searchable dataspace, plays a pivotal
roleininformationretrieval.Inthispaper,weinvestigatetheapplication
oflargelanguagemodelstoenhancesemanticsearchcapabilities,specif-
ically tailored for the domain of Jupyter Notebooks. Our objective is to
retrievegeneratedoutputs,suchasfiguresortables,associatedfunctions
and methods, and other pertinent information.
Wedemonstrateasemanticsearchframeworkthatachievesacomprehen-
sive semantic understanding of the entire notebook’s contents, enabling
ittoeffectivelyhandlevarioustypesofuserqueries.Keycomponentsof
this framework include:
1).Adatapreprocessorisdesignedtohandlediversetypesofcellswithin
Jupyter Notebooks, encompassing both markdown and code cells.
2).Aninnovativemethodologyisdevisedtoaddresstokensizelimitations
that arise with code-type cells. We implement a finer-grained approach
to data input, transitioning from the cell level to the function level,
effectively resolving these issues.
Keywords: semanticsearch·largelanguagemodel·JupyterNotebook
1 Introduction
In contrast to traditional keyword-based searches, which seek literal matches or
variations of query terms without full comprehension of their contextual mean-
ing, semantic search requires an understanding of the searcher’s intent and the
contextual meaning of terms within the searching space. Embedding generated
by language models has been applied to various areas, such as finding relat-
edness among entities in Knowledge Graphs (KGs) [11], generating KGs from
semi-structured data, querying, and managing Knowledge Graph Engineering
(KGE)[12],andcomparingwhetherrecordsfromapairofrelationaltablesrefer
⋆ Supported by Microsoft Research.
4202
beF
02
]RI.sc[
1v43231.2042:viXra2 Lan Li et al.
to the same entity or not [10]. All these applications have demonstrated that
embeddings can appropriately reflect the semantics for different types of data,
ranging from unstructured, semi-structured, to structured datasets.
Jupyter Notebook empowers users to create narratives comprising live, re-
executablecode,mathematicalequations,descriptivetext,interactivedashboards,
andvariousmultimediaelements[7].Therefore,asingleJupyterNotebook,usu-
ally loaded in JSON format, is composed of various types of information. With
the widespread adoption of large language models (LLMs) across diverse appli-
cations, yielding remarkable results, we extend an invitation to LLMs to play
a pivotal role in enhancing and empowering the semantic search process within
the domain of Jupyter Notebooks.
Based on our study on user requirements for searching Jupyter Notebooks
within the team, users are interested in exploring data visualizations, analyzing
plotted results, accessing tutorials for specific method usage, inspecting code
implementations of ad-hoc functions, and reviewing general output information
fromthenotebookcontents.Theserequirementsdependonacomprehensiveand
nuanced semantic grasp of Jupyter Notebook. In a nutshell, our assumption is
that LLMs can comprehend and generate meaningful embeddings for Jupyter
Notebooks, thereby supporting the query process in a robust manner.
Insummary,thisprojectisdrivenbyseveralkeygoals,whichincludeexplor-
ingthepotentialofLLMsandaddressingchallengesfromthefollowingperspec-
tives:
– IdentifyingDataInputsforJupyterNotebookcontentembeddings:pinpoint
the essential data inputs necessary for generating embeddings from Jupyter
Notebook content.
– Resolving token size limitation restricted by embedding model: propose a
finer-grained granularity of data inputs (code-type cell) from cell level to
function level.
– Studying code summaries by the latest GPT-4 model: study and confirm
thepreservationofinformationwhentransitioningfrom theoriginalcodeto
code summaries generated by the GPT-4 model.
– Evaluating the ability of addressing users’ queries: accommodate various
types of user queries comprehensively.
2 Related Work: Transformers in Semantic Search and
Code Summarization
Semantic search is composed of two tasks: 1. understanding the semantics of
queries and documents beyond keywords; 2. finding top k answers from a docu-
mentcorpusgivenaqueryassearch result[1].Withourcase,semanticsearchfor
JupyterNotebooks,aJSONformatdatawhichiscomposedofbothtextualpart
(i.e., markdown) and code part, requires a good understanding of both types of
contents.
Transformers are widely applied to Natural Language Process tasks, also
shed lights on semantic search area. Search applications like Google [2] andUnlocking Insights: Semantic Search in Jupyter Notebooks 3
Bing [3] employ transformers to provide semantically meaningful search results.
However, it’s important to note that these applications utilize limited BERT-
like encoder-only transformers. In contrast, Muennighoff et al. [1] introduce a
different approach by applying decoder-only transformers, referred to as SGPT,
for semantic search and the generating meaningful sentence embeddings. The
primary emphasis of the paper lies in evaluating SGPT’s performance on the
BEIRsearchbenchmark,raisinguncertaintyaboutitseffectivenessinaddressing
various other semantic search tasks [4].
GPT-based models hold substantial promise for application in diverse do-
mains,encompassingeducation,medicine,history,mathematics,physics,andbe-
yond.Thesemodelscanstreamlinevarioustasks,suchasgeneratingsummaries,
answeringquestions,andofferingpersonalizedrecommendationsforusers[5].In
particular, The foundation models pretrained on massive data and finetuned to
downstream tasks have been widely applied for code summarization, reducing
the burden of software development and maintenance [6].
Codesummarizationisthetaskofgeneratingdescriptionsinnaturallanguage
to document the implementation details, data inputs, and data outputs, which
playsanimportantroleinunderstandingthesemanticsofcodesnippets[6](See
Table 1). In contrast to the automatic code summarization models supported
by CodeBERT and GPT-2, as discussed by [6], we leverage the state-of-the-art
GPT-4 3 model for code summarization. GPT-4 model allows for a larger token
sizeinput,trainingonmoreextensivedatasets,andtheabilitytogeneratemore
complex responses.
3 Approach and Demonstration
We develop a semantic search framework for Jupyter Notebooks (see the archi-
tecture on the left and the detailed pipeline of embedding generation process on
the right of Figure 1).
DataPreprocessing Themosttime-consumingandintricateaspectofourproject
lies in the process of generating embeddings. To ensure the effectiveness of our
semantic search system for Jupyter Notebooks, we began by conducting a com-
prehensivesurveytogatheruserrequirementsregardingthesearchfunctionality.
We decide to focus on two fundamental types of cells within Jupyter Notebooks
accordingly: markdown cells, which typically contain descriptive overviews of
the notebook’s contents, and code cells, where implementation details are docu-
mented.
Once we segmented the Jupyter Notebook files into these cells, various data
preprocessing methods are provided for each cell type. For markdown cells, our
preparators would remove various elements such as hyperlinks, special charac-
ters (e.g, {,},:,“,”,’,!), and meaningless JSON field names. The well-documented
and explained markdown cells greatly enhances the semantic value of the note-
book’s content. However, we also recognized the diversity in documentation
3 https://platform.openai.com/docs/models/gpt-44 Lan Li et al.
Table 1: One example code from the LeetCode website: the first solution from
two-sumandcodesummarygeneratedbygpt-4-32k model.Codesummarygen-
erated by the Language Model (LLM) is well-structured and provides in-depth
explanations of its internal logic and mechanisms.
Code
class Solution:
def twoSum(self , nums: List[int], target:
int) −> List[int]:
seen = {}
for i , value in enumerate(nums): #1
remaining = target − nums[i] #2
if remaining in seen: #3
return [i , seen[remaining]] #4
else:
seen[value] = i #5
Code Summary The given code defines a class Solution with a method
twoSum. This method takes a list of integers (numbers) and
an integer target as input and returns a list of two indices
from numbers that add up to the target. It uses a dictionary
(seen) to store the numbers and their indices encountered so
far, and calculates the remaining value needed to reach
the target. If this remaining value is found in the dictionary,
it returns the corresponding indices.Unlocking Insights: Semantic Search in Jupyter Notebooks 5
Embeddings
text-embedding-ada-002-v2
Request Jupyter Jupyter Notebook
Notebooks [JSON File]
Completion Repo
GPT-4
Document Chunking
Update
Markdown Cells Code Cells
[Unstructured Data] [Semi-Structured Data]
nearVector Top k
Search results
Data Preprocessing
User Queries Search Engine
[API]
Embeddings Generation
(a) This is the overall architecture, (b) Our embedding generation
consisting of: 1). Embedding and pipeline consists of three stages:
Completion models are used to Document chunking: Dividing the
generate embeddings for cells of Jupyter Notebook file into cells.
each Jupyter Notebook file; 2). Data preprocessing: Employing
Data insertion and database distinct preparation methods for
update: save the cell contents and markdown and code cells.
corresponding embeddings vectors Requesting GPT models to
into a vector database named generate embeddings.
Weaviate [8], and update it every
fifteen minutes; 3). Search engine:
similarity search and return top k
related results.
Fig.1: Architecture of Semantic Search Framework (Left) and Pipeline of Em-
bedding Generation (Right)
styles among domain experts, data scientists, and engineers who contribute
to the Jupyter Notebook repository. In some cases, notebooks did not contain
markdown cells at all, but utilize separate files for documentation purposes or
instructions.
Complete Embedding In addressing these challenging situations, we recognized
the necessity of adapting our approach to generate embeddings exclusively from
thecodecells.Theprimarychallengeweencounterisbythetokensizelimitation
issuesimposedbyourchosenembeddingmodel,namely,text-embedding-ada-002-
v2,whichallowsforamaximumof8191tokensasinput.Thereareseveralfailed
practical use cases list as follows: 1). Long manual input of data values within
code cells. 2). Classes and functions are often consolidated into a single cell in6 Lan Li et al.
case of tutorial notebooks. 3). Functions are of intricate and complex structures
within individual cells.
To condense the code contents while retaining essential information, we
switch from creating embeddings at the cell level to a finer-grained approach
that focuses on individual functions. Firstly, we apply the Abstract Syntax Tree
(AST),anPythonbuilt-inmoduledesignedtofacilitatetheprocessingofPython
abstract syntax grammar trees. Our aim is to retain the core components of the
code, specifically class and function modules. However, if the token size of the
executed core code still exceeds our imposed limitations, we turn to the latest
GPT models to generate code summaries.
InastudyconductedbySunandChen[9],variouscodesummarizationmod-
els, including ChatGPT, were evaluated. ChatGPT, which is fine-tuned from a
GPT-3.5seriesmodelthroughreinforcementlearningbasedonhumanfeedback,
demonstrates noteworthy strengths. As highlighted by [9], ChatGPT exhibites
an enhanced ability to grasp the underlying meaning of the code, unaffected by
the code’s specific vocabulary. Additionally, ChatGPT tends to provide more
detailed descriptions of code behavior in the generated comments.
In our project, we leverage the capabilities of the cutting-edge GPT model,
specifically the gpt-4-32k model, for code summarization. The gpt-4-32k model
accommodates input sizes of up to 32,000 tokens and excels at understanding
code semantics. We use a simple prompt to generate summaries: “Generate a
summary for the following code: \n <code>”.
Data Storage and Queries After finalizing the embedding generation process,
data objects and their corresponding embeddings are inserted into a vector
database named Weaviate (see Table 2). To ensure data consistency with the
Jupyter Notebook Repository, the database will be updated every 15 minutes.
Subsequently, our search engine accommodates various query types, including
Exact Query (EQ), User Defined Query (UDQ), and Code Summary Query
(CSQ).
The first query type, EQ, is used to test whether the original cell can be
retrieved by inputting partial code or text copied and pasted from notebooks.
The second query type, UDQ, offers greater flexibility, allowing users to express
their requests and retrieve relevant content accordingly. Lastly, CSQ, a form of
‘reverseengineering’,isemployedtoassessthesystem’sabilitytoretrieveoriginal
code blocks with code summaries (in particular, to preserve model consistency,
we use the same gpt-4-32k model to generate the code summary).
These three query types represent distinct perspectives for understanding
notebooks, and we postulate that the search process for each query type serves
as a robustness test for large language models, guarantee their ability to com-
prehend semantics across varying levels of complexity.
Due to data privacy considerations, we avoid disclosing specific contents uti-
lized in semantic search. Instead, we present a table depicting the distances
betweenqueryresultsgeneratedbydifferentqueryinputsandtherelevantnote-
books (see Table 3). We figure out that the distance (calculated by 1-cosine
similarity) between the code summaries generated by the GPT model and theUnlocking Insights: Semantic Search in Jupyter Notebooks 7
actual content is remarkably close. This astonishing finding suggests that GPT
models might possess a deeper understanding of content semantics compared to
human searchers and even the original authors themselves!
Table 2: Schema Design
notebook idcontents cell typeauthor name modified at created at vector
“string” “text” “string” “string” “number” “number” “list of
floats”
Notebook cell con-[text, author name modification creation OpenAI
path tents code] time time Client
Embed-
ding
Table 3: Distances between Queries and Retrieved Contents
Query Types Perspective of UnderstandingDistance
Exact Query Author 0.116
User Defined Query Searcher 0.163
Code Summary QueryGPT 0.065
4 Conclusions and Future Work
In this study, we have delved into the potential of applying large language mod-
els(LLMs)tosemanticsearcheswithinJupyterNotebooks.Ourfindingsconfirm
that these models exhibit a remarkable capability to comprehend both textual
and code-based data. They are adept at capturing the intricate internal mech-
anisms and profound logic within the code, summarizing semantics in a well-
structured manner.
For future work, we have identified several key objectives:
– Augmenting data inputs for LLMs: We plan to enrich the information pro-
vided to LLMs by including additional details about cell contents, such as
file paths, cell types, and author names.
– In addition to generating embeddings for Markdown-type and Code-type
cells, one potential task is to include outputs and graphs, which require a
more advanced multimodal LLMs.
– Exploring code summarization at the cell level: We intend to investigate
the impact of applying code summarization to all cells without decompos-
ing them into function-level segments, aiming to assess its effect on search
results.8 Lan Li et al.
– Conductingqualitativeandquantitativeanalyses:Wewilldevelopacompre-
hensivesetofbothqualitativeandquantitativeanalysesbasedonthesearch
results.Theseanalyseswillscrutinizehowrobustandadaptableembeddings
generated by LLMs are when dealing with codes of varying ’quality’.
Alltheseanalyseswillcontributetounderstandandevaluatehowrobustand
adaptable LLM-generated embeddings are when dealing with codes of varying
“quality” and across different programming languages.
References
1. Muennighoff,N.(2022).Sgpt:Gptsentenceembeddingsforsemanticsearch.arXiv
preprint arXiv:2202.08904.
2. Nayak, P. (2019). Understanding searches better than ever before.
3. JeffreyZhu,MingqinLi,JasonLi,andCassandraOduola.(2021).Bingdeliversmore
contextualized search using quantized transformer inference on NVIDIA GPUs in
Azure.
4. Koubaa, A., Boulila, W., Ghouti, L., Alzahem, A., & Latif, S. (2023). Exploring
ChatGPT capabilities and limitations: A critical review of the nlp game changer.
5. Liu, Y., Han, T., Ma, S., Zhang, J., Yang, Y., Tian, J., ... & Ge, B. (2023). Sum-
mary of ChatGPT-Related Research and Perspective Towards the Future of Large
Language Models. Meta-Radiology, 100017.
6. Gu, J., Salza, P., & Gall, H. C. (2022, March). Assemble foundation models for
automaticcodesummarization.In2022IEEEInternationalConferenceonSoftware
Analysis, Evolution and Reengineering (SANER) (pp. 935-946). IEEE.
7. Kluyver,T.,Ragan-Kelley,B.,P´erez,F.,Granger,B.E.,Bussonnier,M.,Frederic,
J.,...&Willing,C.(2016).JupyterNotebooks-apublishingformatforreproducible
computational workflows. Elpub, 2016, 87-90.
8. Weaviate: an open-source vector database. (2023). Retrieved from
https://weaviate.io/.
9. Sun, W., Fang, C., You, Y., Miao, Y., Liu, Y., Li, Y., ... & Chen, Z. (2023). Au-
tomatic Code Summarization via ChatGPT: How Far Are We?. arXiv preprint
arXiv:2305.12865.
10. Fang,L.,Li,L.,Liu,Y.,Torvik,V.I.,andLuda¨scher,B.(2023).Kaer:Aknowledge
augmentedpre-trainedlanguagemodelforentityresolution.KnowledgeAugmented
Methods for Natural Language Processing workshop in conjunction with AAAI
2023.
11. Morales, C., Collarana, D., Vidal, M. E., & Auer, S. (2017). Matetee: A semantic
similarity metric based on translation embeddings for knowledge graphs. In Web
Engineering: 17th International Conference, ICWE 2017, Rome, Italy, June 5-8,
2017, Proceedings 17 (pp. 246-263). Springer International Publishing.
12. Meyer, L. P., Stadler, C., Frey, J., Radtke, N., Junghanns, K., Meissner, R., ...
&Martin,M.(2023).Llm-assistedknowledgegraphengineering:Experimentswith
chatgpt. arXiv preprint arXiv:2307.06917.