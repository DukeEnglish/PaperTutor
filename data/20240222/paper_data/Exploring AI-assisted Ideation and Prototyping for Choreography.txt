ExploringAI-assistedIdeationandPrototypingforChoreography
YIMENGLIU,UniversityofCalifornia,SantaBarbara,USA
MISHASRA,UniversityofCalifornia,SantaBarbara,USA
Choreographycreationisamultimodalendeavor,demandingcognitiveabilitiestodevelopcreativeideasandtechnicalexpertise
toconvertchoreographicideasintophysicaldancemovements.Previousendeavorshavesoughttoreducethecomplexitiesinthe
choreographycreationprocessinbothdimensions.Amongthem,non-AI-basedsystemshavefocusedonreinforcingcognitiveactivities
byhelpinganalyzeandunderstanddancemovementsandaugmentingphysicalcapabilitiesbyenhancingbodyexpressivity.On
theotherhand,AI-basedmethodshavehelpedthecreationofnovelchoreographicmaterialswithgenerativeAIalgorithms.The
choreographycreationprocessisconstrainedbytimeandrequiresarichsetofresourcestostimulatenovelideas,buttheneedfor
iterativeprototypingandreducedphysicaldependencehavenotbeenadequatelyaddressedbypriorresearch.Recognizingthese
challengesandtheresearchgap,wepresentaninnovativeAI-basedchoreography-supportsystem.Ourgoalistofacilitaterapid
ideationbyutilizingagenerativeAImodelthatcanproducediverseandnoveldancesequences.Thesystemisdesignedtosupport
iterativedigitaldanceprototypingthroughaninteractiveweb-baseduserinterfacethatenablestheeditingandmodificationof
generatedmotion.Weevaluatedoursystembyinvitingsixchoreographerstoanalyzeitslimitationsandbenefitsandpresentthe
evaluationresultsalongwithpotentialdirectionsforfuturework.
CCSConcepts:•Human-centeredcomputing→Interactivesystemsandtools.
AdditionalKeyWordsandPhrases:AI-supportedchoreography,human-AIinteraction
ACMReferenceFormat:
YimengLiuandMishaSra.2024.ExploringAI-assistedIdeationandPrototypingforChoreography.In29thInternationalConferenceon
IntelligentUserInterfaces-Companion(IUICompanion’24),March18–21,2024,Greenville,SC,USA.ACM,NewYork,NY,USA,9pages.
https://doi.org/10.1145/3640544.3645227
1 INTRODUCTION
Choreographycreationisacomplicatedprocessthatdemandssignificantcognitiveandphysicalcapabilities[24,37].
Choreographersdevelopideasbasedontheirknowledgebase,experience,artistictaste,andchoreographicthemesto
craftappealingchoreography[11].Additionally,theyutilizetheirtechnicalexpertisetotranslatethesechoreographic
ideasintophysicaldancemovements.Aharmoniousfusionofcreativityandphysicalexecutionisessentialincreating
dancepiecesthateffectivelyconveychoreographers’creativevisionandengageaudiences[14,22].
Toassistchoreographycreation,priorresearchhasdesignednon-AIsystemsandAIapproachestosupportthe
cognitiveandphysicalrequirements.Non-AIsystemshavebeenproventobeeffectiveinanalyzingdancemovements
foradeeperunderstandingandimprovedexecutionofthemovements[31,41].Thesesystemshavealsohelpedto
extenddancers’physicalexpressivitytoinspirenovelconceptsandmotivatenewformsofdancechoreographyand
performance[12,13].Ontheotherhand,AIchoreography-supportmethodshaveallowedthegenerationofdance
movementsandsequencesforideationbasedonvariousinputmodalities,includingtext[16],music[46],andvideo[10].
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenot
madeordistributedforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationonthefirstpage.Copyrightsforthird-party
componentsofthisworkmustbehonored.Forallotheruses,contacttheowner/author(s).
©2024Copyrightheldbytheowner/author(s).
ManuscriptsubmittedtoACM
1
4202
beF
02
]CH.sc[
1v32131.2042:viXraIUICompanion’24,March18–21,2024,Greenville,SC,USA LiuandSra
According to a prior study [7], motivating novel concepts, reducing physical demands, and allowing iterative
prototypingallcontributetothesuccessofchoreographycreation.Thisismainlyduetothetimeconstraintsappliedto
thechoreographycreationprocess,requiringwisemanagementofeffortandtimeandensuringproductivitywithin
thelimitedtimeframe.Althoughexistingnon-AIsystemshaveshowneffectivenessfordancemovementanalysisand
inspiration,theyfallshortofsavingphysicaleffortduetoheavyrelianceonhumanprototypingtocraftandadjust
dancemovements.Additionally,priorAImethodshavebeenleveragedtosupportideationthroughAI-generated
content;however,mostofthemfailtosupportiterativeprototypingoftheoutcomes–acrucialdemandtopolish
choreographicideasanddancemovements[11].
Tofillthisresearchgap,weintroduceanAIchoreography-supportsystemthatintegratesagenerativeAImodelto
facilitateideationanddigitalprototypingofchoreographymaterials.First,thesystemallowsthegenerationofdiverse
dancesequencesbasedontextualdescriptionsforideation.Second,weaddressthelimitationsofpriorAIalgorithmsby
supportingtheiterativeeditingofAI-generatedoutcomesthroughaweb-baseduserinterface.Byinteractingwith
theinterface,userscandigitallyprototypechoreographicideasandmaterialswithoutrequiringphysicalprototyping.
Moreover,thesystemenablesthedocumentationofintermediateandrefinedresults,capturingusers’attemptsandfinal
productsinvideosand3Danimatedmotions.Inconclusion,wepresenttheopportunitiesandlimitationsidentified
throughasystemevaluationandoutlinefuturedirectionsbasedontheinsightsobtainedfromtheevaluationresults.
2 RELATEDWORK
2.1 Non-AIChoreography-supportSystems
Inarecentreviewpaper[44],existingnon-AIchoreography-supportsystemshavebeencategorizedbasedontheir
intenttoenhancehumanbodyexpressivityandfacilitatetheanalysisofbodymovements.First,choreographershave
utilizedcomputingtechnologiestoaugmentthehumanbodyexpressivecapabilities[13,15,18–21,25,35].Further,
choreographers have embraced motion capture and 3D modeling techniques to analyze and understand abstract
physicalmovementcharacteristicsindance[2,3,8,9,12,31,36,41].Additionally,technologieshavebeenspecifically
developedtosupportcreativeprocessesinchoreography,suchasideation[13,29,35]anddocumentation[12,45].
Whilethesesystemscaneffectivelycontributetotheanalysisofdancemovements,theexpressiveenhancementof
dancers,andthestimulationofnovelideas,theydependontheactivephysicalinvolvementofchoreographersand
dancersforchoreographycreation,refinement,andperformance.Thisdemandcanbechallenging,particularlydue
totimeconstraints,aschoreographersmustwiselydistributetheireffortandtimeacrossvarioustasksduringthe
choreographycreationprocess,suchasthinking,communicating,andphysicalprototyping,toachievesuccesswhile
minimizingstress.
2.2 AIChoreography-supportMethods
AI choreography-support methods have proven useful in producing choreography materials for ideation during
choreographycreation.ThesemethodsutilizegenerativeAIalgorithms,suchasgenerativeadversarialnetworksand
diffusionmodels,togeneratedancemovementsandsequencesbasedonvariousinputmodalities.Oneoftheinput
optionsthathavebeenextensivelyexploredismusic-conditioneddancegeneration[4,42,46].However,theinitiation
ofchoreographycreationdoesnotnecessarilyrequiremusic[28];choreographersmayevenintentionallyrefrainfrom
usingmusictopreventexcessiverelianceonitduringdancecreation[38].Alternatively,texthasbeenusedasauseful
meanstoconveychoreographicideasfordancemaking[16].Moreover,dancevideosencodevisualinformationactedby
2ExploringAI-assistedIdeationandPrototypingforChoreography IUICompanion’24,March18–21,2024,Greenville,SC,USA
dancersandhavebeenutilizedtodrivethegenerationofnewdancesequences[10].Theseinputoptionscaneffectively
generatedanceandcontributetoarichsetofmaterialsforchoreographerstoincorporateintotheirdancepieces.These
materialsalsohavethepotentialtostimulatecreativethinkingbyencouragingtherecombinationandexplorationof
materialsininnovativeways.DespitetheadvantagesofexistingAIchoreography-supportmethods,theyusuallyfailto
allowuserstoeditoutcomes,limitingthemtoone-timeautomaticdancegeneration.Weaddressthislimitationby
enablingtheeditingofAI-generatedresultstoalignwiththeiterativechoreographyprocess.
3 SYSTEM
Fig.1. Userinterface.Theinterfaceacceptstextandvideoasinput.Typingtextdescriptionsleadstodancegeneration,anduploading
videosoffersconverted3Ddancesequencesforediting.Afterdancesequencesaregeneratedoruploaded,userscanfurtheredit
themusingtheeditingoptions.Danceextensionisallowedbytypinginthelengthtoextendbyupto5seconds.Forstylecontrol,
userscanpickstylesfromadrop-downmenu.Toeditpartialbodymovements,userscanchooseabodypartanddescribehowthey
wanttochangeitinthetextboxbelow.Aftercreatingdancesequences,userscanaddthemtotheGalleryforfutureuse,shownas
thumbnails.IfusersselectdancesequencesfromtheGallery,theycanblendthem.Ontheright,userscanviewandinteractwith
thegenerateddancesequencesrepresentedbyadigitalavatar.Thevisibilityoftheavatar’smeshandskeletonisadjustableviathe
checkboxes.Threetypesofavatarmeshesareavailableinourcurrentprototype:SMPL[27]male,female,andMixamo[1]mesh.
Lastly,userscandownloadgenerateddancesequencesas2Dvideosand3Danimatedmeshes.
3.1 UserInterface
Figure1showstheuserinterface.Featuresontheuserinterfacearemotivatedbyaformativestudyinvolvingseven
choreographers.Theleftsidepresentstwotabsforuserinput:textandvideo.Optingforthetexttabprovidesatextbox
foruserstodescribedancemovements,witha+buttonallowingtheadditionofmoreinputboxesasneeded.Below
this,aneditingpanelenablesuserstomodifygeneratedcontent:expanddancesequences,alterdancestyles,change
partialbodymovements,andblendtwodancesequences.Choosingthevideotabreplacesthetextinputboxwith
afileuploadbuttontoimportdancevideoswhiletheeditingpanelremainsunchanged.Bycombiningtextualand
3IUICompanion’24,March18–21,2024,Greenville,SC,USA LiuandSra
visualcontent,oursystemmaximizesthepotentialtoconveycreativeideas,particularlywhenusingasinglemode
ofexpressionisinsufficient.Therightsideisthedisplayarea.Tovisualizedancesequences,userscanswitchthe
meshtypetoaSMPL[27]male,female,orMixamo[1]meshthroughthecorrespondingcheckboxes.Themeshesare
interactive,allowingrotation,scaling,andmovement.Thevisibilityofthemeshesandskeletonisalsoadjustableusing
checkboxes.TheAddtoGallerybuttonsavesusercreationsintotheGalleryforfuturereference.TheDownloadbutton
permitsexportingtheanimatedmeshin.gltf formatforusein3Dscenariosandin.mp4formatasavideo.
3.2 Functionality
DanceGeneration. Userscaninputadancegenreorspecifydancemovementsasfoundationalcomponentsto
obtainthreedancesequenceseachtime.Generatingdiversedancesequencesbasedonatextdescriptionleveragesthe
probabilisticnatureofthegenerativeAImodelweemploy.Thesystemgeneratesdancesequencesupto10seconds.On
average,generatingthreeoutputstakes10seconds,withthetimevaryingbasedoninternetlatency.
DanceExtension.Danceextensionempowersuserstoexpandsequencestheyuploadfromvideosorthosethe
systemgenerates.Thisfeaturefacilitatesimprovisationfromexistingdata,aligningwithaprevalentchoreography
methodfavoredbymanychoreographers[11].Italsoallowsoursystemtoovercomedurationconstraintsimposed
bythelengthofmotionsequencesusedtotraintheunderlyingAImodel.Tosurpassthe10-secondlimitsetbythis
model,wepermita5-secondextensionforeachuser-initiatedextension.Thisdecisionemergedfromexperimentation,
revealingthata5-secondextensionmaintainsthequalityoftheextendedportion.Longerextensionsledtomotionless
segments,whileshorteronesfailedtocapturetheentiretyofthedancemovements.Userscanrepetitivelyextend
sequencesthroughthisprocesstoobtainlongerdurations.
StyleControl.Oursystemfacilitatestheeditingofdancesequencestyles,offeringoptionsincludingangry,childlike,
depressed,happy,proud,andstrutting.Incorporatingthesesixstylesservesasaproof-of-conceptpipelinetointroduce
emotionalchangesindancemovements.ThesestyleswereinitiallyintroducedbySinMDM[33]aspartofamotion
harmonizationspecialcase.GiventhattheHumanML3Ddataset[17]usedtotraintheunderlyingAImodellacksstyle
labels,directlydescribingemotionsintextpromptsdoesnotinherentlymodifydancestyles.Toaddressthis,weexplicitly
definedthesixstylesbasedontheHumanML3Ddatasetandtrainedmodelsforeachtypeofemotion-to-motionstyle
transferusingasimilartrainingmethodasSinMDM[33].
PartialBodyEdit.Minoradjustments,suchasmodificationstopartialbodymotions,areoftennecessaryinthe
choreographicprocess.Thesystemallowschangingthemovementsoftheupperandlowerbody,arms,andlegs.
Asaneditingfeature,changesmadetopartialbodymovementsallowuserstoobservehowtheremainingbody
movementsadjustaccordingtotheeditedsegment.Alternatively,partialbodyeditscanserveasadancegeneration
feature.Forinstance,usingapromptlike“Apersonisdoingamoonwalk;restrictmovementsofarms”generatesa
dancesequenceadheringtothespecifiedconstraintonarms.Thisshowshowpartialbodycontroldirectlyinfluences
thedancegenerationprocess,presentingadistinctionfromtheeffectsobservedduringtheeditingphase.
Dance Blending. Users can concatenate two dance sequences to obtain a longer one that seamlessly merges
thechosensequences,incorporatinga5-secondconnectingsegmenttoensureasmoothtransition.Blendingdance
sequencesempowersuserstoexpandcreativeoutcomesandexplorenovelcombinationsofdancegenres,e.g.,deviating
fromclassicdancestylesbyblendingmultipledancegenres.Thisbecomesparticularlyrelevantasmasteringmultiple
dancegenresandmixingthemforchoreographycreationisanon-trivialtaskforhumans.
Documentation.Userscanexport2Ddocumentationcontaininggenerateddancesequencesbeforeandaftereditsina
.mp4format.Thesevideosshowcaseanimatedhumanskeletonsexecutingthegenerateddancemovements.Additionally,
4ExploringAI-assistedIdeationandPrototypingforChoreography IUICompanion’24,March18–21,2024,Greenville,SC,USA
userscandownloadthegenerateddancemovementsin3D,storedina.gltf format.This3Drepresentationcanbeused
invarious3Dscenarios,suchasAR/VR/MR.Supportingboth2Dand3Ddocumentationoffersclearadvantages.Videos
areeasytostoreandshare;however,theyonlydisplayoneperspectiveatatime,makingitchallengingtoobserve
hiddenbodymovements.3Danimationsaddressthisissuebyenablinguserstoviewdancemovementsfromdifferent
angles.Moreover,oursystemautomaticallysavestextpromptsusedtogenerateandeditdancesequences,allowing
userstokeeptrackoftheirattemptswithinthesystem.
3.3 ExampleResults
Figure2presentsafewresultsobtainedusingoursystem,includinga10-seconddancesequencegeneratedfrom“A
manisdancingballet”andeditedresultsbasedonthissequenceusingtheeditingoptions.Eachdancesequenceis
shownasfiveframesexecutedbytheSMPLmalemesh[27].
(a)Danceextensionof“Amanisdancingballet”.
(b)Stylecontrol:angry. (c)Partialbody:“Keepthearmsraisedup”.
(d)“Amanisdancingballet”. (e)Connectingdancesequence. (f)“Amanisdancinghip-hop”.
Fig.2. Resultsofadancesequencegeneratedfrom“Amanisdancingballet”andeditedsequencesbasedonit.(a)Theoriginal
dancesequenceis10seconds,showningray,andtheextendedsegmentby5secondsisblue.(b)Thestyle“angry”isappliedtothe
originaldancesequence.(c)Thepartialbodymovementsarealteredaccordingto“Keepthearmsraisedup”.(d)-(f)Theblending
resultsoftheoriginalsequenceanda10-seconddancesequencegeneratedfrom“Amanisdancinghip-hop”inblue,witha5-second
connectingdancesequencemergingthemingreen.
3.4 TechnicalDetails
FrontendUserInterfaceandBackendServer. ThefrontenduserinterfaceisconstructedusingHTML/CSSand
JavaScript.ItcommunicateswiththebackendserverthroughaTCPsocket[32].Figure3showsthefrontendand
backendconnectionsviadashedarrowsandtheoperationswithineachofthem.
Whenuserschoosetextasinput,itisencodedasaquery,placedinaqueue,andtransmittedtothebackend.The
backendprocessesthisqueue–extractsallthequeries,encodesthemintotextembeddingsusingCLIP[34],andpasses
theembeddingstothegenerativemodelfordancesequencegeneration.Alternatively,thevideofileissenttothe
backendifusersuploadadancevideoasinput.ThevideoisprocessedbyVIBE[23]totrackthedancingpersonand
5IUICompanion’24,March18–21,2024,Greenville,SC,USA LiuandSra
Fig.3. Technicaldetails.Thesystem’suserinterfaceandbackendserverareconnectedviaaTCPsocket,shownasdashedarrows.
Theuserinterfacesendsusers’textdescriptions,uploadedvideos,andeditingoperationstothebackendandreceivesgenerated
dancesequencesfordisplayandinteraction.ThebackendserverencodeseachtextdescriptionfromthequeryqueuewithCLIP[34]
embeddingsandconvertsdancemovementsfromthevideofilesinto3DsequencesusingVIBE[23].Theseinputsanduser-initiated
editoperationsarefedintothefine-tunedMDM[39]togeneratedancesequences.Dataflowswithinthebackendserverare
representedassolidarrows.
obtaina3Ddancesequence.EachdancesequenceisidentifiedwithauniqueID;theIDsareupdatedifanydance
sequenceisedited.Specifically,ifadancesequenceispickedtoedit,thefrontendsendstheeditingoperations,andthe
backendloadsthedancesequencetobeeditedthroughitsIDandpassesitintothegenerativemodel.Theresulting
dancesequences,generatedoreditedbyusers,arereturnedtotheuserinterfacefordisplayandinteraction.Weusethe
three.jslibrary[40]toload3Dmeshesandanimationparametersintoawebbrowser.WeemploySMPLmeshes[27]in
bothfemaleandmaletypes,alongwithaMixamomesh[1],asavatarstoshowcasethegenerateddancesequences.
GenerativeAIModel.WeusetheMotionDiffusionModel(MDM)[39]astheunderlyingAImodelfordance
generationandediting.Thismodelwasinitiallypre-trainedontheHumanML3Ddataset[17],coveringalargenumber
ofnaturallanguagedescriptionsforvariousdailyhumanmotions.Wefurtherfine-tunedthismodelusingtheAIST++
dancedataset[26].Inthisprocess,theauthorsmanuallylabeledtheAIST++datasetwiththetenavailabledancegenres,
providingtextdescriptionsforfine-tuning.Thefine-tuningtookapproximately13hoursonamachineequippedwitha
singleNVIDIARTX3090graphicscard.Thefine-tunedmodelallowsdancesequencegenerationandeditinginthe
modelinferencephase.InthebackendservermoduleshowninFigure3,weillustratetheinputandeditoptionsand
theinferenceprocesstogeneratedancesequencesusingthefine-tunedmodel.
4 SYSTEMEVALUATION
Tohelpusunderstandoursystem’sabilitytosupportprofessionalchoreographers,weinvitedsixparticipants(five
femalesandonemale),eachassignedanIDfromP01toP06,for1:1systemevaluations.Theparticipantshadfour
toovertenyearsofchoreographyexperienceinhip-hop,jazz,contemporary,andballetfordanceinstructionand
commercialperformance.ThestudywasconductedfollowingapprovalfromthelocalInstitutionalReviewBoard(IRB)
underprotocol#21-23-0275.Participantsprovideduswithinformedconsentandunderwentparticipanttrainingbefore
theevaluation.Duringthestudy,theyusedthesystemfor20minutestocreatemultipledancesequencesasthey
wanted.Followingtheirinteractionwiththesystem,weconductedsemi-structuredinterviewswitheachparticipantto
understandtheirexperienceandgatherfeedback.Afterthestudy,weperformedareflexivethematicanalysis[5,6]on
theinterviewdata.Thissectionoutlinestheinsightsextractedfromourdataanalysis.
6ExploringAI-assistedIdeationandPrototypingforChoreography IUICompanion’24,March18–21,2024,Greenville,SC,USA
4.1 AI-assistedChoreographyIdeation
Participantsfoundthevariedoutcomesproducedbythesystemofferedthemchoreographicmaterialsandcould
potentiallysparktheirnewthinkingfordancemaking.Forinstance,theycommentedthattheAI-generateddance
sequencesallowedthemtoexplore“abroadscopeofmaterials”(P01)thattheycanadapt“forfutureuseorinspireme
tothinkofnewmovesorcombinations”(P01).Moreover,theythoughtthat“thediverseresultscouldhelpmebemore
efficientasIcouldsimplyrecombinethemtogetanewdancesequence”(P02).
SomeparticipantsraisedconcernsregardingtheefficiencyofusingagenerativeAIsystemvs.asearchengine
tocollectmaterialsforchoreographyideation,withcommentslike“comparedwithsearchingforonlinevideos,one
limitationofthissystemissearchingonlineispossiblymoreefficientthanusingAItogenerateresults.Theformertakesa
fewsecondstoobtainhundredsofresults,butthelatteroffersonlythreeoutputs”(P06).Thisfeedbackraisesaquestionof
howin-demandvs.ahighvolumeofresultsaffectschoreographyideation.Bothmethodscouldbetime-consumingto
obtainusefulmaterials,withtheformerrequiringpromptengineeringandthelatterdemandingcarefulselection.A
harmoniouscombinationofthetwoapproachesmayenhancethedevelopmentoffutureideationtechniques,e.g.,using
AI-generatedcontentformoreprecisesearchesorincorporatingsearchedresultsforAI-drivenpolishment.
4.2 AI-assistedChoreographyPrototyping
Participantsprovidedfeedbackontheefficacyofusingtheeditingoptionstomodifyandrefinedancemovements.For
example,theyfoundthat“theeditingoptionsarehelpfultospeedupearlyprototypingofideasusingmycomputer”(P04),
andthedocumenteddancesequencesallowedthemto“saveresultsformyselftorevisit”(P05)and“updatebasedon
whatIleftfromprevioustries”(P04).
Although digital prototyping assisted by an AI system could save time and physical effort for early testing of
choreographicideas,someparticipantscommentedthatthedigitalformat“couldonlyrevealdancemovementsbut
failedtoconveyemotionandenergy”(P03)throughthemovements.Implicitinformation,includingemotion,iscrucial
fordanceperformanceandcreation[22].Whileoursystemutilizesemotionasastyleconditionforchoreography
modification,thisfeedbacksuggestsaneedforimproveddigitaltoolstoconveyinformationimplicitlyincorporatedin
choreographythroughfacialexpressions[30]ormusclemotions[43]ofadigitalavatarformoreaccurateandthorough
visualizationandprototypingofbothimplicitandexplicitchoreographicideas.
5 CONCLUSIONANDFUTUREWORK
ThispaperintroducesaninteractiveAI-basedsystemdesignedtosupportchoreographyideationtostimulatenew
conceptsanddigitalprototypingtoreducephysicaldemandsforchoreographicideatestingandpolishment.Our
systemfeaturesaninteractivewebinterfaceandagenerativeAI-poweredbackend,enablingfastgeneration,iterative
editing,and2Dand3Ddocumentationofdancesequences.Weobtainedinitialfeedbackonthesystem’sstrengthsand
weaknessesfromasystemevaluation.Weaimtorefinethesysteminourfutureworkandgaindeeperinsightsthrough
extensiveevaluationsanddiscussionstoinformthedevelopmentoffutureAI-basedchoreography-supportsystems.
ACKNOWLEDGMENTS
WewanttothankJenniferJacobsforofferingusvaluableinsightsregardingthesystemevaluationdesignandmembersof
theHuman-AIIntegrationLabandExpressiveComputationLabatUCSBfortheirfeedbackonthesystemfunctionality.
7IUICompanion’24,March18–21,2024,Greenville,SC,USA LiuandSra
REFERENCES
[1] Adobe.2024.Mixamo.Adobe. https://www.mixamo.com/#/
[2] JulieAkerly.2015.EmbodiedFlowinExperientialMediaSystems:AStudyoftheDancer’sLivedExperienceinaResponsiveAudioSystem.In
Proceedingsofthe2ndInternationalWorkshoponMovementandComputing(Vancouver,BritishColumbia,Canada)(MOCO’15).Associationfor
ComputingMachinery,NewYork,NY,USA,9–16. https://doi.org/10.1145/2790994.2790997
[3] SarahFdiliAlaoui,BaptisteCaramiaux,MarcosSerrano,andFrédéricBevilacqua.2012.MovementQualitiesasInteractionModality.InProceedings
oftheDesigningInteractiveSystemsConference(NewcastleUponTyne,UnitedKingdom)(DIS’12).AssociationforComputingMachinery,NewYork,
NY,USA,761–769. https://doi.org/10.1145/2317956.2318071
[4] SimonAlexanderson,RajmundNagy,JonasBeskow,andGustavEjeHenter.2023.Listen,Denoise,Action!Audio-DrivenMotionSynthesiswith
DiffusionModels.ACMTrans.Graph.42,4,Article44(jul2023),20pages. https://doi.org/10.1145/3592458
[5] VirginiaBraunandVictoriaClarke.2006.Usingthematicanalysisinpsychology.Qualitativeresearchinpsychology3,2(2006),77–101.
[6] VirginiaBraunandVictoriaClarke.2012.Thematicanalysis.AmericanPsychologicalAssociation,AppleValley,NM,USA.
[7] ThomasW.Calvert,ChristopherWelman,SeverinGaudet,andCatherineLee.1989. Compositionofmultiplefiguresequencesfordanceand
animation.InNewAdvancesinComputerGraphics:ProceedingsofCGInternational’89.Springer,Springer-Verlag,Berlin,Heidelberg,245–255.
[8] KristinCarlson,TheclaSchiphorst,KarenCochrane,JordonPhillips,HerbertH.Tsang,andTomCalvert.2015.MomentbyMoment:Creating
MovementSketcheswithCameraStillframes.InProceedingsofthe2015ACMSIGCHIConferenceonCreativityandCognition(Glasgow,United
Kingdom)(C&C’15).AssociationforComputingMachinery,NewYork,NY,USA,131–140. https://doi.org/10.1145/2757226.2757237
[9] KristinCarlson,HerbertH.Tsang,JordonPhillips,TheclaSchiphorst,andTomCalvert.2015.SketchingMovement:DesigningCreativityTools
forin-Situ,Whole-BodyAuthorship.InProceedingsofthe2ndInternationalWorkshoponMovementandComputing(Vancouver,BritishColumbia,
Canada)(MOCO’15).AssociationforComputingMachinery,NewYork,NY,USA,68–75. https://doi.org/10.1145/2790994.2791007
[10] CarolineChan,ShiryGinosar,TinghuiZhou,andAlexeiAEfros.2019.Everybodydancenow.InProceedingsoftheIEEE/CVFinternationalconference
oncomputervision.IEEE,NewYork,NY,USA,5933–5942.
[11] MarianelaCiolfiFelice,SarahFdiliAlaoui,andWendyE.Mackay.2016.HowDoChoreographersCraftDance?DesigningforaChoreographer-
TechnologyPartnership.InProceedingsofthe3rdInternationalSymposiumonMovementandComputing(Thessaloniki,GA,Greece)(MOCO’16).
AssociationforComputingMachinery,NewYork,NY,USA,Article20,8pages. https://doi.org/10.1145/2948910.2948941
[12] MarianelaCiolfiFelice,SarahFdiliAlaoui,andWendyEMackay.2018. Knotation:exploringanddocumentingchoreographicprocesses.In
Proceedingsofthe2018CHIConferenceonHumanFactorsinComputingSystems.AssociationforComputingMachinery,NewYork,NY,USA,1–12.
[13] SaraEriksson,ÅsaUnander-Scharin,VincentTrichon,CarlUnander-Scharin,HedvigKjellström,andKristinaHöök.2019.DancingWithDrones:
CraftingNovelArtisticExpressionsThroughIntercorporeality.InProceedingsofthe2019CHIConferenceonHumanFactorsinComputingSystems
(Glasgow,ScotlandUk)(CHI’19).AssociationforComputingMachinery,NewYork,NY,USA,1–12. https://doi.org/10.1145/3290605.3300847
[14] SarahFdiliAlaoui,JulesFrançoise,TheclaSchiphorst,KarenStudd,andFredericBevilacqua.2017.Seeing,SensingandRecognizingLabanMovement
Qualities.InProceedingsofthe2017CHIConferenceonHumanFactorsinComputingSystems(Denver,Colorado,USA)(CHI’17).Associationfor
ComputingMachinery,NewYork,NY,USA,4009–4020. https://doi.org/10.1145/3025453.3025530
[15] PetraGemeinboeckandRobSaunders.2017.MovementMatters:HowaRobotBecomesBody.InProceedingsofthe4thInternationalConference
onMovementComputing(London,UnitedKingdom)(MOCO’17).AssociationforComputingMachinery,NewYork,NY,USA,Article8,8pages.
https://doi.org/10.1145/3077981.3078035
[16] KehongGong,DongzeLian,HengChang,ChuanGuo,ZihangJiang,XinxinZuo,MichaelBiMi,andXinchaoWang.2023.Tm2d:Bimodalitydriven
3ddancegenerationviamusic-textintegration.InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.IEEE,NewYork,NY,
USA,9942–9952.
[17] ChuanGuo,ShihaoZou,XinxinZuo,SenWang,WeiJi,XingyuLi,andLiCheng.2022.GeneratingDiverseandNatural3DHumanMotionsFrom
Text.InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR).IEEE,NewYork,NY,USA,5152–5161.
[18] LevaJanauskaitundefinedandGeorgePalamas.2019.EstablishingDialoguesBetweenMovementandAtmosphericAmbiances.InProceedingsofthe
6thInternationalConferenceonMovementandComputing(Tempe,AZ,USA)(MOCO’19).AssociationforComputingMachinery,NewYork,NY,
USA,Article28,11pages. https://doi.org/10.1145/3347122.3359602
[19] ElizabethJochumandJeroenDerks.2019.TonightWeImprovise!Real-TimeTrackingforHuman-RobotImprovisationalDance.InProceedingsof
the6thInternationalConferenceonMovementandComputing(Tempe,AZ,USA)(MOCO’19).AssociationforComputingMachinery,NewYork,NY,
USA,Article7,11pages. https://doi.org/10.1145/3347122.3347129
[20] AndrewJohnston.2015.ConceptualisingInteractioninLivePerformance:Reflectionson’Encoded’.InProceedingsofthe2ndInternationalWorkshop
onMovementandComputing(Vancouver,BritishColumbia,Canada)(MOCO’15).AssociationforComputingMachinery,NewYork,NY,USA,60–67.
https://doi.org/10.1145/2790994.2791003
[21] PavelKarpashevich,EvaHornecker,MichaelaHonauer,andPedroSanches.2018.ReinterpretingSchlemmer’sTriadicBallet:interactivecostumefor
unthinkablemovements.InProceedingsofthe2018CHIConferenceonHumanFactorsinComputingSystems.AssociationforComputingMachinery,
NewYork,NY,USA,1–13.
[22] DavidKirsh,DafneMuntanyola,RJoanneJao,AmyLew,andMattSugihara.2009.Choreographicmethodsforcreatingnovel,highqualitydance.
InProceedings,DESFORM5thinternationalworkshopondesign&semantics&form.DeSForM,NorthumbriaUniversity,188–195.
8ExploringAI-assistedIdeationandPrototypingforChoreography IUICompanion’24,March18–21,2024,Greenville,SC,USA
[23] MuhammedKocabas,NikosAthanasiou,andMichaelJBlack.2020.Vibe:Videoinferenceforhumanbodyposeandshapeestimation.InProceedings
oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.IEEE,NewYork,NY,USA,5253–5263.
[24] NathanKogan.2002.Careersintheperformingarts:Apsychologicalperspective.CommunicationResearchJournal14,1(2002),1–16.
[25] KateLadenheim,ReikaMcNish,WaliRizvi,andAmyLaViers.2020.Livedanceperformanceinvestigatingthefemininecyborgmetaphorwitha
motion-activatedwearablerobot.InProceedingsofthe2020ACM/IEEEinternationalconferenceonhuman-robotinteraction.AssociationforComputing
Machinery,NewYork,NY,USA,243–251.
[26] RuilongLi,ShanYang,DavidA.Ross,andAngjooKanazawa.2021.AIChoreographer:MusicConditioned3DDanceGenerationWithAIST++.In
ProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision(ICCV).IEEE,NewYork,NY,USA,13401–13412.
[27] MatthewLoper,NaureenMahmood,JavierRomero,GerardPons-Moll,andMichaelJ.Black.2015.SMPL:ASkinnedMulti-PersonLinearModel.
ACMTrans.Graphics(Proc.SIGGRAPHAsia)34,6(Oct.2015),248:1–248:16.
[28] PaulHMason.2012.Music,danceandthetotalartwork:choreomusicologyintheoryandpractice.Researchindanceeducation13,1(2012),5–24.
[29] LuisMolina-Tanco,CarmenGarcía-Berdonés,andArcadioReyes-Lecuona.2017.TheDelaymirror:Atechnologicalinnovationspecifictothedance
studio.InProceedingsofthe4thInternationalConferenceonMovementComputing.AssociationforComputingMachinery,NewYork,NY,USA,1–6.
[30] Nvidia.2024.OmniverseAudio2Face.Nvidia. https://www.nvidia.com/en-us/omniverse/apps/audio2face/
[31] AnttiOulasvirta,TeemuRoos,ArttuModig,andLauraLeppänen.2013.Informationcapacityoffull-bodymovements.InProceedingsoftheSIGCHI
conferenceonhumanfactorsincomputingsystems.AssociationforComputingMachinery,NewYork,NY,USA,1289–1298.
[32] Python.2024.HTTPservers.Python. https://docs.python.org/3/library/http.server.html
[33] SigalRaab,InbalLeibovitch,GuyTevet,MoabArar,AmitH.Bermano,andDanielCohen-Or.2023.SingleMotionDiffusion.arXiv:2302.05905[cs.CV]
[34] AlecRadford,JongWookKim,ChrisHallacy,AdityaRamesh,GabrielGoh,SandhiniAgarwal,GirishSastry,AmandaAskell,PamelaMishkin,Jack
Clark,etal.2021.Learningtransferablevisualmodelsfromnaturallanguagesupervision.InInternationalConferenceonMachineLearning.PMLR,
Pittsburgh,PA,USA,8748–8763.
[35] KaterinaElRaheb,GeorgeTsampounaris,AkriviKatifori,andYannisIoannidis.2018.Choreomorphy:Awhole-bodyinteractionexperiencefor
danceimprovisationandvisualexperimentation.InProceedingsofthe2018InternationalConferenceonAdvancedVisualInterfaces.Associationfor
ComputingMachinery,NewYork,NY,USA,1–9.
[36] VikashSingh,CelineLatulipe,ErinCarroll,andDanielleLottridge.2011.Thechoreographer’snotebook:avideoannotationsystemfordancersand
choreographers.InProceedingsofthe8thACMConferenceonCreativityandCognition.AssociationforComputingMachinery,NewYork,NY,USA,
197–206.
[37] CatherineStevens,StephenMalloch,ShirleyMcKechnie,andNicoleSteven.2003.Choreographiccognition:Thetime-courseandphenomenology
ofcreatingadance.Pragmatics&Cognition11,2(2003),297–326.
[38] CatherineJStevens,EmerySchubert,ShuaiWang,ChristianKroos,andShaunHalovic.2009.Movingwithandwithoutmusic:scalingandlapsing
intimeintheperformanceofcontemporarydance.MusicPerception26,5(2009),451–464.
[39] Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and Amit H. Bermano. 2022. Human Motion Diffusion Model.
arXiv:2209.14916[cs.CV]
[40] Three.js.2024.JavaScript3DLibrary.https://github.com/mrdoob/three.js.
[41] EduardoVelloso,AndreasBulling,andHansGellersen.2013.Motionma:motionmodellingandanalysisbydemonstration.InProceedingsofthe
SIGCHIConferenceonHumanFactorsinComputingSystems.AssociationforComputingMachinery,NewYork,NY,USA,1309–1318.
[42] MingaoZhang,ChanghongLiu,YongChen,ZhenchunLei,andMingwenWang.2022.Music-to-DanceGenerationwithMultipleConformer.In
Proceedingsofthe2022InternationalConferenceonMultimediaRetrieval(Newark,NJ,USA)(ICMR’22).AssociationforComputingMachinery,New
York,NY,USA,34–38. https://doi.org/10.1145/3512527.3531430
[43] MianlunZheng,YiZhou,DuyguCeylan,andJernejBarbic.2021.Adeepemulatorforsecondarymotionof3dcharacters.InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition.IEEE,NewYork,NY,USA,5932–5940.
[44] QiushiZhou,ChengChengChua,JarrodKnibbe,JorgeGoncalves,andEduardoVelloso.2021. DanceandchoreographyinHCI:atwo-decade
retrospective.InProceedingsofthe2021CHIConferenceonHumanFactorsinComputingSystems.AssociationforComputingMachinery,NewYork,
NY,USA,1–14.
[45] QiushiZhou,LouiseGrebel,AndrewIrlitti,JulieAnnMinaai,JorgeGoncalves,andEduardoVelloso.2023.HereandNow:CreatingImprovisational
DanceMovementswithaMixedRealityMirror.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputingSystems(Hamburg,
Germany)(CHI’23).AssociationforComputingMachinery,NewYork,NY,USA,Article183,16pages. https://doi.org/10.1145/3544548.3580666
[46] WenlinZhuang,CongyiWang,JinxiangChai,YangangWang,MingShao,andSiyuXia.2022.Music2Dance:DanceNetforMusic-DrivenDance
Generation.ACMTrans.MultimediaComput.Commun.Appl.18,2,Article65(feb2022),21pages. https://doi.org/10.1145/3485664
9