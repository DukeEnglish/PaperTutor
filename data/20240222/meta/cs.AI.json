[
    {
        "title": "CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples",
        "authors": "Jianrui ZhangMu CaiTengyang XieYong Jae Lee",
        "links": "http://arxiv.org/abs/2402.13254v1",
        "entry_id": "http://arxiv.org/abs/2402.13254v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13254v1",
        "summary": "We propose CounterCurate, a framework to comprehensively improve the\nvisio-linguistic compositional reasoning capability for both contrastive and\ngenerative multimodal models. In particular, we identify two under-explored\ncritical problems: the neglect of the physically grounded reasoning (counting\nand position understanding) and the potential of using highly capable text and\nimage generation models for semantic counterfactual fine-tuning. Our work\npioneers an approach that addresses these gaps. We first spotlight the\nnear-chance performance of multimodal models like CLIP and LLaVA in physically\ngrounded compositional reasoning. We then apply simple data augmentation using\na grounded image generation model, GLIGEN, to generate finetuning data,\nresulting in significant performance improvements: +33% and +37% for CLIP and\nLLaVA, respectively, on our newly curated Flickr30k-Positions benchmark.\nMoreover, we exploit the capabilities of high-performing text generation and\nimage generation models, specifically GPT-4V and DALLE-3, to curate challenging\nsemantic counterfactuals, thereby further enhancing compositional reasoning\ncapabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms\nGPT-4V.",
        "updated": "2024-02-20 18:59:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13254v1"
    },
    {
        "title": "TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization",
        "authors": "Liyan TangIgor ShalyminovAmy Wing-mei WongJon BurnskyJake W. VincentYu'an YangSiffi SinghSong FengHwanjun SongHang SuLijia SunYi ZhangSaab MansourKathleen McKeown",
        "links": "http://arxiv.org/abs/2402.13249v1",
        "entry_id": "http://arxiv.org/abs/2402.13249v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13249v1",
        "summary": "Single document news summarization has seen substantial progress on\nfaithfulness in recent years, driven by research on the evaluation of factual\nconsistency, or hallucinations. We ask whether these advances carry over to\nother text summarization domains. We propose a new evaluation benchmark on\ntopic-focused dialogue summarization, generated by LLMs of varying sizes. We\nprovide binary sentence-level human annotations of the factual consistency of\nthese summaries along with detailed explanations of factually inconsistent\nsentences. Our analysis shows that existing LLMs hallucinate significant\namounts of factual errors in the dialogue domain, regardless of the model's\nsize. On the other hand, when LLMs, including GPT-4, serve as binary factual\nevaluators, they perform poorly and can be outperformed by prevailing\nstate-of-the-art specialized factuality evaluation metrics. Finally, we\nconducted an analysis of hallucination types with a curated error taxonomy. We\nfind that there are diverse errors and error distributions in model-generated\nsummaries and that non-LLM based metrics can capture all error types better\nthan LLM-based evaluators.",
        "updated": "2024-02-20 18:58:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13249v1"
    },
    {
        "title": "Federated Causal Discovery from Heterogeneous Data",
        "authors": "Loka LiIgnavier NgGongxu LuoBiwei HuangGuangyi ChenTongliang LiuBin GuKun Zhang",
        "links": "http://arxiv.org/abs/2402.13241v1",
        "entry_id": "http://arxiv.org/abs/2402.13241v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13241v1",
        "summary": "Conventional causal discovery methods rely on centralized data, which is\ninconsistent with the decentralized nature of data in many real-world\nsituations. This discrepancy has motivated the development of federated causal\ndiscovery (FCD) approaches. However, existing FCD methods may be limited by\ntheir potentially restrictive assumptions of identifiable functional causal\nmodels or homogeneous data distributions, narrowing their applicability in\ndiverse scenarios. In this paper, we propose a novel FCD method attempting to\naccommodate arbitrary causal models and heterogeneous data. We first utilize a\nsurrogate variable corresponding to the client index to account for the data\nheterogeneity across different clients. We then develop a federated conditional\nindependence test (FCIT) for causal skeleton discovery and establish a\nfederated independent change principle (FICP) to determine causal directions.\nThese approaches involve constructing summary statistics as a proxy of the raw\ndata to protect data privacy. Owing to the nonparametric properties, FCIT and\nFICP make no assumption about particular functional forms, thereby facilitating\nthe handling of arbitrary causal models. We conduct extensive experiments on\nsynthetic and real datasets to show the efficacy of our method. The code is\navailable at \\url{https://github.com/lokali/FedCDH.git}.",
        "updated": "2024-02-20 18:53:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13241v1"
    },
    {
        "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive",
        "authors": "Arka PalDeep KarkhanisSamuel DooleyManley RobertsSiddartha NaiduColin White",
        "links": "http://arxiv.org/abs/2402.13228v1",
        "entry_id": "http://arxiv.org/abs/2402.13228v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13228v1",
        "summary": "Direct Preference Optimisation (DPO) is effective at significantly improving\nthe performance of large language models (LLMs) on downstream tasks such as\nreasoning, summarisation, and alignment. Using pairs of preferred and\ndispreferred data, DPO models the \\textit{relative} probability of picking one\nresponse over another. In this work, first we show theoretically that the\nstandard DPO loss can lead to a \\textit{reduction} of the model's likelihood of\nthe preferred examples, as long as the relative probability between the\npreferred and dispreferred classes increases. We then show empirically that\nthis phenomenon occurs when fine-tuning LLMs on common datasets, especially\ndatasets in which the edit distance between pairs of completions is low. Using\nthese insights, we design DPO-Positive (DPOP), a new loss function and training\nprocedure which avoids this failure mode. Surprisingly, we also find that DPOP\nsignificantly outperforms DPO across a wide variety of datasets and downstream\ntasks, including datasets with high edit distances between completions. By\nfine-tuning with DPOP, we create and release Smaug-34B and Smaug-72B, which\nachieve state-of-the-art open-source performance. Notably, Smaug-72B is nearly\n2\\% better than any other open-source model on the HuggingFace Open LLM\nLeaderboard and becomes the first open-source LLM to surpass an average\naccuracy of 80\\%.",
        "updated": "2024-02-20 18:42:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13228v1"
    },
    {
        "title": "NeRF Solves Undersampled MRI Reconstruction",
        "authors": "Tae Jun JangChang Min Hyun",
        "links": "http://arxiv.org/abs/2402.13226v1",
        "entry_id": "http://arxiv.org/abs/2402.13226v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13226v1",
        "summary": "This article presents a novel undersampled magnetic resonance imaging (MRI)\ntechnique that leverages the concept of Neural Radiance Field (NeRF). With\nradial undersampling, the corresponding imaging problem can be reformulated\ninto an image modeling task from sparse-view rendered data; therefore, a high\ndimensional MR image is obtainable from undersampled $k$-space data by taking\nadvantage of implicit neural representation. A multi-layer perceptron, which is\ndesigned to output an image intensity from a spatial coordinate, learns the MR\nphysics-driven rendering relation between given measurement data and desired\nimage. Effective undersampling strategies for high-quality neural\nrepresentation are investigated. The proposed method serves two benefits: (i)\nThe learning is based fully on single undersampled $k$-space data, not a bunch\nof measured data and target image sets. It can be used potentially for\ndiagnostic MR imaging, such as fetal MRI, where data acquisition is relatively\nrare or limited against diversity of clinical images while undersampled\nreconstruction is highly demanded. (ii) A reconstructed MR image is a\nscan-specific representation highly adaptive to the given $k$-space\nmeasurement. Numerous experiments validate the feasibility and capability of\nthe proposed approach.",
        "updated": "2024-02-20 18:37:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13226v1"
    }
]