[
    {
        "title": "CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples",
        "authors": "Jianrui ZhangMu CaiTengyang XieYong Jae Lee",
        "links": "http://arxiv.org/abs/2402.13254v1",
        "entry_id": "http://arxiv.org/abs/2402.13254v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13254v1",
        "summary": "We propose CounterCurate, a framework to comprehensively improve the\nvisio-linguistic compositional reasoning capability for both contrastive and\ngenerative multimodal models. In particular, we identify two under-explored\ncritical problems: the neglect of the physically grounded reasoning (counting\nand position understanding) and the potential of using highly capable text and\nimage generation models for semantic counterfactual fine-tuning. Our work\npioneers an approach that addresses these gaps. We first spotlight the\nnear-chance performance of multimodal models like CLIP and LLaVA in physically\ngrounded compositional reasoning. We then apply simple data augmentation using\na grounded image generation model, GLIGEN, to generate finetuning data,\nresulting in significant performance improvements: +33% and +37% for CLIP and\nLLaVA, respectively, on our newly curated Flickr30k-Positions benchmark.\nMoreover, we exploit the capabilities of high-performing text generation and\nimage generation models, specifically GPT-4V and DALLE-3, to curate challenging\nsemantic counterfactuals, thereby further enhancing compositional reasoning\ncapabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms\nGPT-4V.",
        "updated": "2024-02-20 18:59:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13254v1"
    },
    {
        "title": "FlashTex: Fast Relightable Mesh Texturing with LightControlNet",
        "authors": "Kangle DengTimothy OmernickAlexander WeissDeva RamananJun-Yan ZhuTinghui ZhouManeesh Agrawala",
        "links": "http://arxiv.org/abs/2402.13251v1",
        "entry_id": "http://arxiv.org/abs/2402.13251v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13251v1",
        "summary": "Manually creating textures for 3D meshes is time-consuming, even for expert\nvisual content creators. We propose a fast approach for automatically texturing\nan input 3D mesh based on a user-provided text prompt. Importantly, our\napproach disentangles lighting from surface material/reflectance in the\nresulting texture so that the mesh can be properly relit and rendered in any\nlighting environment. We introduce LightControlNet, a new text-to-image model\nbased on the ControlNet architecture, which allows the specification of the\ndesired lighting as a conditioning image to the model. Our text-to-texture\npipeline then constructs the texture in two stages. The first stage produces a\nsparse set of visually consistent reference views of the mesh using\nLightControlNet. The second stage applies a texture optimization based on Score\nDistillation Sampling (SDS) that works with LightControlNet to increase the\ntexture quality while disentangling surface material from lighting. Our\npipeline is significantly faster than previous text-to-texture methods, while\nproducing high-quality and relightable textures.",
        "updated": "2024-02-20 18:59:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13251v1"
    },
    {
        "title": "Federated Causal Discovery from Heterogeneous Data",
        "authors": "Loka LiIgnavier NgGongxu LuoBiwei HuangGuangyi ChenTongliang LiuBin GuKun Zhang",
        "links": "http://arxiv.org/abs/2402.13241v1",
        "entry_id": "http://arxiv.org/abs/2402.13241v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13241v1",
        "summary": "Conventional causal discovery methods rely on centralized data, which is\ninconsistent with the decentralized nature of data in many real-world\nsituations. This discrepancy has motivated the development of federated causal\ndiscovery (FCD) approaches. However, existing FCD methods may be limited by\ntheir potentially restrictive assumptions of identifiable functional causal\nmodels or homogeneous data distributions, narrowing their applicability in\ndiverse scenarios. In this paper, we propose a novel FCD method attempting to\naccommodate arbitrary causal models and heterogeneous data. We first utilize a\nsurrogate variable corresponding to the client index to account for the data\nheterogeneity across different clients. We then develop a federated conditional\nindependence test (FCIT) for causal skeleton discovery and establish a\nfederated independent change principle (FICP) to determine causal directions.\nThese approaches involve constructing summary statistics as a proxy of the raw\ndata to protect data privacy. Owing to the nonparametric properties, FCIT and\nFICP make no assumption about particular functional forms, thereby facilitating\nthe handling of arbitrary causal models. We conduct extensive experiments on\nsynthetic and real datasets to show the efficacy of our method. The code is\navailable at \\url{https://github.com/lokali/FedCDH.git}.",
        "updated": "2024-02-20 18:53:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13241v1"
    },
    {
        "title": "SMORE: Similarity-based Hyperdimensional Domain Adaptation for Multi-Sensor Time Series Classification",
        "authors": "Junyao WangMohammad Abdullah Al Faruque",
        "links": "http://arxiv.org/abs/2402.13233v1",
        "entry_id": "http://arxiv.org/abs/2402.13233v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13233v1",
        "summary": "Many real-world applications of the Internet of Things (IoT) employ machine\nlearning (ML) algorithms to analyze time series information collected by\ninterconnected sensors. However, distribution shift, a fundamental challenge in\ndata-driven ML, arises when a model is deployed on a data distribution\ndifferent from the training data and can substantially degrade model\nperformance. Additionally, increasingly sophisticated deep neural networks\n(DNNs) are required to capture intricate spatial and temporal dependencies in\nmulti-sensor time series data, often exceeding the capabilities of today's edge\ndevices. In this paper, we propose SMORE, a novel resource-efficient domain\nadaptation (DA) algorithm for multi-sensor time series classification,\nleveraging the efficient and parallel operations of hyperdimensional computing.\nSMORE dynamically customizes test-time models with explicit consideration of\nthe domain context of each sample to mitigate the negative impacts of domain\nshifts. Our evaluation on a variety of multi-sensor time series classification\ntasks shows that SMORE achieves on average 1.98% higher accuracy than\nstate-of-the-art (SOTA) DNN-based DA algorithms with 18.81x faster training and\n4.63x faster inference.",
        "updated": "2024-02-20 18:48:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13233v1"
    },
    {
        "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive",
        "authors": "Arka PalDeep KarkhanisSamuel DooleyManley RobertsSiddartha NaiduColin White",
        "links": "http://arxiv.org/abs/2402.13228v1",
        "entry_id": "http://arxiv.org/abs/2402.13228v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13228v1",
        "summary": "Direct Preference Optimisation (DPO) is effective at significantly improving\nthe performance of large language models (LLMs) on downstream tasks such as\nreasoning, summarisation, and alignment. Using pairs of preferred and\ndispreferred data, DPO models the \\textit{relative} probability of picking one\nresponse over another. In this work, first we show theoretically that the\nstandard DPO loss can lead to a \\textit{reduction} of the model's likelihood of\nthe preferred examples, as long as the relative probability between the\npreferred and dispreferred classes increases. We then show empirically that\nthis phenomenon occurs when fine-tuning LLMs on common datasets, especially\ndatasets in which the edit distance between pairs of completions is low. Using\nthese insights, we design DPO-Positive (DPOP), a new loss function and training\nprocedure which avoids this failure mode. Surprisingly, we also find that DPOP\nsignificantly outperforms DPO across a wide variety of datasets and downstream\ntasks, including datasets with high edit distances between completions. By\nfine-tuning with DPOP, we create and release Smaug-34B and Smaug-72B, which\nachieve state-of-the-art open-source performance. Notably, Smaug-72B is nearly\n2\\% better than any other open-source model on the HuggingFace Open LLM\nLeaderboard and becomes the first open-source LLM to surpass an average\naccuracy of 80\\%.",
        "updated": "2024-02-20 18:42:34 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13228v1"
    }
]