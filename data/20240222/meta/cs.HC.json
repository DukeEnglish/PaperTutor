[
    {
        "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies",
        "authors": "Ammar N. AbbasChidera W. AmazuJoseph MietkiewiczHouda BriwaAndres Alonzo PerezGabriele BaldissoneMicaela DemichelaGeorgios G. ChasparisJohn D. KelleherMaria Chiara Leva",
        "links": "http://arxiv.org/abs/2402.13219v1",
        "entry_id": "http://arxiv.org/abs/2402.13219v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13219v1",
        "summary": "In complex industrial and chemical process control rooms, effective\ndecision-making is crucial for safety and efficiency. The experiments in this\npaper evaluate the impact and applications of an AI-based decision support\nsystem integrated into an improved human-machine interface, using dynamic\ninfluence diagrams, a hidden Markov model, and deep reinforcement learning. The\nenhanced support system aims to reduce operator workload, improve situational\nawareness, and provide different intervention strategies to the operator\nadapted to the current state of both the system and human performance. Such a\nsystem can be particularly useful in cases of information overload when many\nalarms and inputs are presented all within the same time window, or for junior\noperators during training. A comprehensive cross-data analysis was conducted,\ninvolving 47 participants and a diverse range of data sources such as\nsmartwatch metrics, eye-tracking data, process logs, and responses from\nquestionnaires. The results indicate interesting insights regarding the\neffectiveness of the approach in aiding decision-making, decreasing perceived\nworkload, and increasing situational awareness for the scenarios considered.\nAdditionally, the results provide valuable insights to compare differences\nbetween styles of information gathering when using the system by individual\nparticipants. These findings are particularly relevant when predicting the\noverall performance of the individual participant and their capacity to\nsuccessfully handle a plant upset and the alarms connected to it using process\nand human-machine interaction logs in real-time. These predictions enable the\ndevelopment of more effective intervention strategies.",
        "updated": "2024-02-20 18:31:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13219v1"
    },
    {
        "title": "Exploring AI-assisted Ideation and Prototyping for Choreography",
        "authors": "Yimeng LiuMisha Sra",
        "links": "http://dx.doi.org/10.1145/3640544.3645227",
        "entry_id": "http://arxiv.org/abs/2402.13123v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13123v1",
        "summary": "Choreography creation is a multimodal endeavor, demanding cognitive abilities\nto develop creative ideas and technical expertise to convert choreographic\nideas into physical dance movements. Previous endeavors have sought to reduce\nthe complexities in the choreography creation process in both dimensions. Among\nthem, non-AI-based systems have focused on reinforcing cognitive activities by\nhelping analyze and understand dance movements and augmenting physical\ncapabilities by enhancing body expressivity. On the other hand, AI-based\nmethods have helped the creation of novel choreographic materials with\ngenerative AI algorithms. The choreography creation process is constrained by\ntime and requires a rich set of resources to stimulate novel ideas, but the\nneed for iterative prototyping and reduced physical dependence have not been\nadequately addressed by prior research. Recognizing these challenges and the\nresearch gap, we present an innovative AI-based choreography-support system.\nOur goal is to facilitate rapid ideation by utilizing a generative AI model\nthat can produce diverse and novel dance sequences. The system is designed to\nsupport iterative digital dance prototyping through an interactive web-based\nuser interface that enables the editing and modification of generated motion.\nWe evaluated our system by inviting six choreographers to analyze its\nlimitations and benefits and present the evaluation results along with\npotential directions for future work.",
        "updated": "2024-02-20 16:36:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13123v1"
    },
    {
        "title": "Tactile Weight Rendering: A Review for Researchers and Developers",
        "authors": "Rubén Martín-RodríguezAlexandre L. RatschatLaura Marchal-CrespoYasemin Vardar",
        "links": "http://arxiv.org/abs/2402.13120v1",
        "entry_id": "http://arxiv.org/abs/2402.13120v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13120v1",
        "summary": "Haptic rendering of weight plays an essential role in naturalistic object\ninteraction in virtual environments. While kinesthetic devices have\ntraditionally been used for this aim by applying forces on the limbs, tactile\ninterfaces acting on the skin have recently offered potential solutions to\nenhance or substitute kinesthetic ones. Here, we aim to provide an in-depth\noverview and comparison of existing tactile weight rendering approaches. We\ncategorized these approaches based on their type of stimulation into asymmetric\nvibration and skin stretch, further divided according to the working mechanism\nof the devices. Then, we compared these approaches using various criteria,\nincluding physical, mechanical, and perceptual characteristics of the reported\ndevices and their potential applications. We found that asymmetric vibration\ndevices have the smallest form factor, while skin stretch devices relying on\nthe motion of flat surfaces, belts, or tactors present numerous mechanical and\nperceptual advantages for scenarios requiring more accurate weight rendering.\nFinally, we discussed the selection of the proposed categorization of devices\nand their application scopes, together with the limitations and opportunities\nfor future research. We hope this study guides the development and use of\ntactile interfaces to achieve a more naturalistic object interaction and\nmanipulation in virtual environments.",
        "updated": "2024-02-20 16:27:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13120v1"
    },
    {
        "title": "Digital Comprehensibility Assessment of Simplified Texts among Persons with Intellectual Disabilities",
        "authors": "Andreas SäuberliFranz HolzknechtPatrick HallerSilvana DeilenLaura SchifflSilvia Hansen-SchirraSarah Ebling",
        "links": "http://arxiv.org/abs/2402.13094v1",
        "entry_id": "http://arxiv.org/abs/2402.13094v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13094v1",
        "summary": "Text simplification refers to the process of increasing the comprehensibility\nof texts. Automatic text simplification models are most commonly evaluated by\nexperts or crowdworkers instead of the primary target groups of simplified\ntexts, such as persons with intellectual disabilities. We conducted an\nevaluation study of text comprehensibility including participants with and\nwithout intellectual disabilities reading unsimplified, automatically and\nmanually simplified German texts on a tablet computer. We explored four\ndifferent approaches to measuring comprehensibility: multiple-choice\ncomprehension questions, perceived difficulty ratings, response time, and\nreading speed. The results revealed significant variations in these\nmeasurements, depending on the reader group and whether the text had undergone\nautomatic or manual simplification. For the target group of persons with\nintellectual disabilities, comprehension questions emerged as the most reliable\nmeasure, while analyzing reading speed provided valuable insights into\nparticipants' reading behavior.",
        "updated": "2024-02-20 15:37:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13094v1"
    },
    {
        "title": "Solving the decision-making analysis differential equation using eye fixation data in Unity software with Hermite Long-Short-Term Memory",
        "authors": "Kourosh ParandSaeed SetayeshiMir Mohsen PedramAli YoonesiAida Pakniyat",
        "links": "http://arxiv.org/abs/2402.13027v1",
        "entry_id": "http://arxiv.org/abs/2402.13027v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13027v1",
        "summary": "Decision-making is a fundamental component of our personal and professional\nlives. To analyze decision-making accuracy, this study proposes a virtual\nenvironment designed as an industrial town to investigate the relationship\nbetween eye movements and decision-making. Eye tracking provides a tool to\nexamine eye movements, which contain information related to eye position, head\nposition, and gaze direction. The game is designed using Unity software, with\nthe collected data being analyzed using a differential equation and the Hermite\nneural network method. The game is used to identify the behaviors exhibited by\nbad and good individuals and differentiate between them before taking action.\nThis paper investigates the accuracy of an individual's decision-making process\nby analyzing their eye movements and the correctness of the decisions made.",
        "updated": "2024-02-20 14:09:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13027v1"
    }
]