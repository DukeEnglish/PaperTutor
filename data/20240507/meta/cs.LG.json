[
    {
        "title": "Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames",
        "authors": "Keith BurghardtKai ChenKristina Lerman",
        "links": "http://arxiv.org/abs/2405.03688v1",
        "entry_id": "http://arxiv.org/abs/2405.03688v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03688v1",
        "summary": "Adversarial information operations can destabilize societies by undermining\nfair elections, manipulating public opinions on policies, and promoting scams.\nDespite their widespread occurrence and potential impacts, our understanding of\ninfluence campaigns is limited by manual analysis of messages and subjective\ninterpretation of their observable behavior. In this paper, we explore whether\nthese limitations can be mitigated with large language models (LLMs), using\nGPT-3.5 as a case-study for coordinated campaign annotation. We first use\nGPT-3.5 to scrutinize 126 identified information operations spanning over a\ndecade. We utilize a number of metrics to quantify the close (if imperfect)\nagreement between LLM and ground truth descriptions. We next extract\ncoordinated campaigns from two large multilingual datasets from X (formerly\nTwitter) that respectively discuss the 2022 French election and 2023 Balikaran\nPhilippine-U.S. military exercise in 2023. For each coordinated campaign, we\nuse GPT-3.5 to analyze posts related to a specific concern and extract goals,\ntactics, and narrative frames, both before and after critical events (such as\nthe date of an election). While the GPT-3.5 sometimes disagrees with subjective\ninterpretation, its ability to summarize and interpret demonstrates LLMs'\npotential to extract higher-order indicators from text to provide a more\ncomplete picture of the information campaigns compared to previous methods.",
        "updated": "2024-05-06 17:59:07 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03688v1"
    },
    {
        "title": "Language-Image Models with 3D Understanding",
        "authors": "Jang Hyun ChoBoris IvanovicYulong CaoEdward SchmerlingYue WangXinshuo WengBoyi LiYurong YouPhilipp KrähenbühlYan WangMarco Pavone",
        "links": "http://arxiv.org/abs/2405.03685v1",
        "entry_id": "http://arxiv.org/abs/2405.03685v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03685v1",
        "summary": "Multi-modal large language models (MLLMs) have shown incredible capabilities\nin a variety of 2D vision and language tasks. We extend MLLMs' perceptual\ncapabilities to ground and reason about images in 3-dimensional space. To that\nend, we first develop a large-scale pre-training dataset for 2D and 3D called\nLV3D by combining multiple existing 2D and 3D recognition datasets under a\ncommon task formulation: as multi-turn question-answering. Next, we introduce a\nnew MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data\nscaling makes a strong 3D perception capability without 3D specific\narchitectural design or training objective. Cube-LLM exhibits intriguing\nproperties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting\nto improve 3D understanding from 2D context information. (2) Cube-LLM can\nfollow complex and diverse instructions and adapt to versatile input and output\nformats. (3) Cube-LLM can be visually prompted such as 2D box or a set of\ncandidate 3D boxes from specialists. Our experiments on outdoor benchmarks\ndemonstrate that Cube-LLM significantly outperforms existing baselines by 21.3\npoints of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7\npoints on the DriveLM dataset for complex reasoning about driving scenarios,\nrespectively. Cube-LLM also shows competitive results in general MLLM\nbenchmarks such as refCOCO for 2D grounding with (87.0) average score, as well\nas visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for\ncomplex reasoning. Our project is available at\nhttps://janghyuncho.github.io/Cube-LLM.",
        "updated": "2024-05-06 17:57:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03685v1"
    },
    {
        "title": "Why is SAM Robust to Label Noise?",
        "authors": "Christina BaekZico KolterAditi Raghunathan",
        "links": "http://arxiv.org/abs/2405.03676v1",
        "entry_id": "http://arxiv.org/abs/2405.03676v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03676v1",
        "summary": "Sharpness-Aware Minimization (SAM) is most known for achieving state-of\nthe-art performances on natural image and language tasks. However, its most\npronounced improvements (of tens of percent) is rather in the presence of label\nnoise. Understanding SAM's label noise robustness requires a departure from\ncharacterizing the robustness of minimas lying in \"flatter\" regions of the loss\nlandscape. In particular, the peak performance under label noise occurs with\nearly stopping, far before the loss converges. We decompose SAM's robustness\ninto two effects: one induced by changes to the logit term and the other\ninduced by changes to the network Jacobian. The first can be observed in linear\nlogistic regression where SAM provably up-weights the gradient contribution\nfrom clean examples. Although this explicit up-weighting is also observable in\nneural networks, when we intervene and modify SAM to remove this effect,\nsurprisingly, we see no visible degradation in performance. We infer that SAM's\neffect in deeper networks is instead explained entirely by the effect SAM has\non the network Jacobian. We theoretically derive the implicit regularization\ninduced by this Jacobian effect in two layer linear networks. Motivated by our\nanalysis, we see that cheaper alternatives to SAM that explicitly induce these\nregularization effects largely recover the benefits in deep networks trained on\nreal-world datasets.",
        "updated": "2024-05-06 17:52:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03676v1"
    },
    {
        "title": "Cutting through buggy adversarial example defenses: fixing 1 line of code breaks Sabre",
        "authors": "Nicholas Carlini",
        "links": "http://arxiv.org/abs/2405.03672v1",
        "entry_id": "http://arxiv.org/abs/2405.03672v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03672v1",
        "summary": "Sabre is a defense to adversarial examples that was accepted at IEEE S&P\n2024. We first reveal significant flaws in the evaluation that point to clear\nsigns of gradient masking. We then show the cause of this gradient masking: a\nbug in the original evaluation code. By fixing a single line of code in the\noriginal repository, we reduce Sabre's robust accuracy to 0%. In response to\nthis, the authors modify the defense and introduce a new defense component not\ndescribed in the original paper. But this fix contains a second bug; modifying\none more line of code reduces robust accuracy to below baseline levels.",
        "updated": "2024-05-06 17:48:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03672v1"
    },
    {
        "title": "Fault Detection and Monitoring using an Information-Driven Strategy: Method, Theory, and Application",
        "authors": "Camilo RamírezJorge F. SilvaFerhat TamssaouetTomás RojasMarcos E. Orchard",
        "links": "http://arxiv.org/abs/2405.03667v1",
        "entry_id": "http://arxiv.org/abs/2405.03667v1",
        "pdf_url": "http://arxiv.org/pdf/2405.03667v1",
        "summary": "The ability to detect when a system undergoes an incipient fault is of\nparamount importance in preventing a critical failure. In this work, we propose\nan information-driven fault detection method based on a novel concept drift\ndetector. The method is tailored to identifying drifts in input-output\nrelationships of additive noise models (i.e., model drifts) and is based on a\ndistribution-free mutual information (MI) estimator. Our scheme does not\nrequire prior faulty examples and can be applied distribution-free over a large\nclass of system models. Our core contributions are twofold. First, we\ndemonstrate the connection between fault detection, model drift detection, and\ntesting independence between two random variables. Second, we prove several\ntheoretical properties of the proposed MI-based fault detection scheme: (i)\nstrong consistency, (ii) exponentially fast detection of the non-faulty case,\nand (iii) control of both significance levels and power of the test. To\nconclude, we validate our theory with synthetic data and the benchmark dataset\nN-CMAPSS of aircraft turbofan engines. These empirical results support the\nusefulness of our methodology in many practical and realistic settings, and the\ntheoretical results show performance guarantees that other methods cannot\noffer.",
        "updated": "2024-05-06 17:43:39 UTC",
        "interpretation": "解释内容未找到",
        "id": "2405.03667v1"
    }
]