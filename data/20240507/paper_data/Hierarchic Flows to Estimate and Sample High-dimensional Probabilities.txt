HIERARCHIC FLOWS TO ESTIMATE AND SAMPLE
HIGH-DIMENSIONAL PROBABILITIES
APREPRINT
EtienneLempereur*1andSte´phaneMallat2,3
1De´partementd’informatique,Ecolenormalesupe´rieure,Paris,France
2Colle`gedeFrance,Paris,France
3FlatironInstitute,NewYork,USA
May7,2024
ABSTRACT
Findinglow-dimensionalinterpretablemodelsofcomplexphysicalfieldssuchasturbulenceremains
an open question, 80 years after the pioneer work of Kolmogorov. Estimating high-dimensional
probability distributions from data samples suffers from an optimization and an approximation
curseofdimensionality. Itmaybeavoidedbyfollowingahierarchicprobabilityflowfromcoarse
to fine scales. This inverse renormalization group is defined by conditional probabilities across
scales,renormalizedinawaveletbasis. Foraφ4scalarpotential,samplingthesehierarchicmodels
avoidsthecriticalslowingdownatthephasetransition. Anoutstandingissueistoalsoapproximate
non-Gaussianfieldshavinglong-rangeinteractionsinspaceandacrossscales. Weintroducelow-
dimensionalmodelswithrobustmultiscaleapproximationsofhighorderpolynomialenergies. They
arecalculatedwithasecondwavelettransform,whichdefinesinteractionsovertwohierarchiesof
scales. Weestimateandsamplethesewaveletscatteringmodelstogenerate2Dvorticityfieldsof
turbulence,andimagesofdarkmatterdensities.
1 Introduction
Estimatingmodelsofhigh-dimensionalprobabilitydistributionsfromdataisattheheartofdatascienceandstatistical
physics. Foraphysicalsystematequilibrium,theprobabilitydistributionofafieldφ∈Rd(suchasanimage)hasa
densityp(φ)=Z−1e−U(φ),whereU(φ)istheGibbsenergy[LL13]. Learningmeansapproximatingandoptimizing
anestimationofthehigh-dimensionalenergyfunctionU,frommdatasamples{φ(i)} resultingfrommeasurementsor
i
numericalsimulations. Newdatacanthenbegeneratedbysamplingtheestimatedmodelofp,whichisalsousedto
estimatesolutionsofinverseproblems[KS06,ABT18]. TheestimationofaGibbsenergyisparticularlydifficultwhen
φhaslongrangedependencies,anditsdimensiondislarge. Anoutstandingproblemistobuildprobabilisticmodelsof
turbulentflows,whichdatesbacktotheworkofKolmogorovin1942[kol41,Kol42].
In statistics, p is estimated by defining an approximation class p and by optimizing θ. These approximation and
θ
optimizationproblemsareplaguedbythecurseofdimensionality. Section2reviewsbothaspects. Itincludeslinear
approximationsofGibbsenergies,maximumlikelihoodestimationversusscorematching,andsamplingbyLangevin
diffusions. Onecandefinelow-dimensionalapproximationclassesifinteractionsarelocalwithinφ,asinMarkov
randomfields[GG84]. Theoptimizationcurseisalsoavoidedifthelog-Sobolevconstantofpremainsboundedwhend
increases[Gro75,Led00,BGL+14]. Sadlyenough,noneofthesetwopropertiesaresatisfiedbycomplexdatasuchas
turbulencefields. Addressingtheapproximationandoptimizationcurseofdimensionalityrequiresintroducingmore
flexiblemodels.
Fromacyberneticsperspective,HerbertSimonsobservedthatthearchitectureofmostcomplexsystemsishierarchic,
inphysics,biology,economic,symboliclanguages,orsocialorganizations. Hearguesthatitprobablyresultsfromtheir
dynamicevolution,whereintermediatestatesmustbestable[Sim62]. Thisattractiveideacouldexplainwhythecurse
∗etienne.lempereur@ens.fr
4202
yaM
6
]LM.tats[
1v86430.5042:viXraHierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
p
J J
p
J
p
j
p
j
p
j-1
p
j-1
p
0
Figure1: Therenormalizationgroup(illustratedinblue)computestheprobabilitydistributionsp (φ )ofimagesφ at
j j j
progressivelylargerscales2j,withmarginalintegrationsofhigh-frequencydegreesoffreedom,uptoamaximumscale
2J. Ahierarchicflow(illustratedinred)isatop-downinverseMarkovchainwhichrecoverspfromp byestimating
J
eachtransitionprobabilityp¯ fromp top . Difficultiesarisewhenp¯ isnon-local,asinturbulentflows.
j j j−1 j
ofdimensionalitycanbeavoidedwhenanalyzingsuchsystems,butthenotionofhierarchyislooselydefined. The
coreprincipleofhierarchicorganizationsistobuildlongrangeinteractionsfromalimitednumberoflocalinteractions
betweenneighborsinthehierarchy. Butlargesystemsincludemultiplehierarchiesproducingcomplexlong-range
interactionsinmultidimensionalmatrixorganizations, asopposedtoatree. Forexample, largecorporationsoften
includehorizontalhierarchicorganizationsdedicatedtospecificprojects,ateachverticalhierarchiclevel[Tur18]. It
createslong-rangeinteractionsbetweenemployeesworkingonasameproject. Inphysics,therenormalizationgroup
theoryprovidesahierarchicanalysisofmultiplebodyinteractions. Itcomputesaflowofprobabilitiesfromafine
microscopicscaletowardslargermacroscopicscales[Kad66,Wil71,WF72,Del12].
However,majordifficultieshavebeenencounteredtotakeintoaccountnon-localinteractionsinspaceandacrossscales.
Particularlyfornon-renormalizablesystemssuchasturbulence,whosedegreesoffreedomincreasewiththedimension
dofφ[BJPV98].
Thispaperdefineshierarchicmodelstoestimateandsamplehigh-dimensionalnon-Gaussianprocesseshavingnon-local
interactions.Section3considersdataφ∈Rddefinedongraphs,orimages.Afirsthierarchicorganizationisconstructed
withcoarsegrainingapproximationsφ ofφ,ofprogressivelysmallersizesasthescale2j increases. Figure1givesan
j
illustrationofthevorticityfieldofa2Dturbulence. Theprobabilitydensityp(φ)isprogressivelymappedintodensities
p (φ )fromfinetocoarsescales2j.Thisrenormalizationgrouptransformationiscomputedbymarginalintegrationsof
j j
thehighfrequencydegreesoffreedom,whichprogressivelydisappearasj increases. Thereisnodifficultytoestimate
andsamplep (φ )ifφ hasalowdimension. Fromthisestimation,thehigh-dimensionalmodelofpcanbeestimated
J J J
andsampledwithareverseMarkovchain. Ittransformsp intopbyiterativelycomputingp fromp ,asshownby
J j−1 j
Figure1. Eachtransitionkernelp¯ ofthishierarchicflowistheconditionalprobabilityofφ givenφ . Themain
j j−1 j
difficultyistounderstandonwhatconditionsonecanestimateandsamplethesetransitionkernels,withoutsuffering
fromthecurseofdimensionality.
A hierarchic probability flow across scales is an inverse to Wilson renormalization group. If we represent high
frequenciesinwaveletbasesthenthetransitionkernelscanbewrittenasconditionalprobabilitiesofwaveletcoefficients.
Renormalizingwaveletcoefficientsisastrategytocontrollog-Sobolevconstantsoftransitionprobabilities. Forthe
φ4 model of ferromagnetism at phase transition, it was shown in [MOBM22] that a renormalization in a wavelet
basiseliminatesthe”criticalslowingdown”ofLangevinsamplingalgorithms[ZJ21]. Thisisverifiedandanalyzed
fordifferenttypesofwaveletbasesinSection4. Theφ4 scalarpotentialmodelhaslocalspatialinteractions. Itis
”renormalizable,”whichmeansthatitcanbeapproximatedwithanumberofcouplingparameters,whichdoesnot
dependonthefielddimensiond,atallscales. Thispropertydoesnotapplytocomplexsystemssuchasfluidturbulence,
whichhaveprogressivelymoredegreesoffreedomasthedimensiondincreases[BJPV98]. Tofacethisissue, we
introducehierarchicpotentialmodels,whosedimensionsincreasewhenthescale2j decreases. Thehierarchypreserves
acouplingflowequation,whichrelatesthecouplingparametersofenergiesfromonescaletothenext.
2HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
In physics and statistics, Gibbs energies of non-Gaussian probability distributions are often approximated with
polynomialsofdegreeslargerthan2,typically3or4[LL13]. Forastationaryfieldofdimensiond,itinvolvesd2or
d3approximationterms,whoseestimationshavealargevariance. Section5introducesinteractionenergymodelsof
dimensionO(log3d),withrobustmultiscaleapproximationsofhighorderpolynomialenergies. Theyarecomputed
withasecondwavelettransform,appliedtothemodulusofthefirstwavelettransform.Itdefinesasecondhierarchy,with
asecondscaleparameter. Theresultingscatteringcoefficients[Mal12]capturelong-rangenon-Gaussianinteractions
acrossspaceandscales[CMA+23]. Theseinteractionenergymodelsprovidearenormalizationgrouprepresentation
of non-renormalizable systems, with O(log3d) degrees of freedom, which increases slowly with the dimension d.
NumericalapplicationsareshowntoestimateandsampleGibbsenergymodelsoftwo-dimensionalturbulentvorticity
fieldsanddarkmatterdensityfields.
2 ProbabilityModels,EstimationandSampling
Wedenotebyφ∈Rdadatavectorofdimensiond. Wesupposethatithasaprobabilitydensityp(φ)=Z−1e−U(φ)
withrespecttotheLebesguemeasure,withaGibbsenergyU whichistwicedifferentiable. Ourgoalistoestimate
anaccuratemodelofpfrommsamples{φ(i)} ,andtogeneratenewdatabysamplingthismodel. Thissectionis
i≤m
abriefintroductiontosamplingofhigh-dimensionalprobabilitieswithLangevindiffusions,andtotheestimationof
parametricmodelsbymaximumlikelihoodandscorematching.
2.1 LangevinSamplingandLogSobolevInequalities
IfU(φ)isknown,onecansamplepwithaLangevindynamics,whichisaMarkovprocessthatiterativelyupdatesa
fieldφ withthestochasticdifferentialequation
t
√
dφ =−∇ U(φ )dt+ 2dB ,
t φ t t
whereB isaBrownianmotion. Itisagradientdescentontheenergy,whichisperturbedbytheadditionofaGaussian
t
white noise. Let φ be a sample of a density p at time t = 0. At time t, φ is a sample of a density p which is
0 0 t t
guaranteedtoconvergetothedensitypofGibbsenergyU(φ)[LS16]. TheuniqueinvariantmeasureofthisMarkov
chainisp. WecanthussamplepbyrunningLangevinequationoversamplesofaninitialmeasurep ,forexample
0
Gaussian,buttheconvergencemaybeextremelyslow.
Theconvergenceofp towardspisdefinedwithaKLdivergence
t
(cid:90) p (φ)
KL(p ,p)= p (φ) log t dφ≥0.
t t p(φ)
DeBruinidentity[BBD23]provesthat
dKL(p ,p)
t =−I(p ,p), (1)
dt t
whereI istherelativeFisherinformation
(cid:90) q(φ)
I(q,p)= q(φ)∥∇ log ∥2dφ.
φ p(φ)
Theexponentialconvergenceofp towardspisguaranteedifpsatisfiesalog-Sobolevinequality,whichisrecalled.
t
Definition2.1. Thelog-Sobolevconstantc(p)ofpisthesmallestconstantsothatforanyprobabilitydensityq
KL(q,p)≤c(p)I(q,p). (2)
Log-Sobolev constants relate entropy and gradients of smooth normalized functions f(φ) in the functional space
L2(pdφ). Indeed, f2 = q/p satisfies ∥f∥ = 1 in L2(pdφ) because (cid:82) q(φ)dφ = 1, and one can verify that the
2
log-Sobolevinequality(2)isequivalentto
(cid:90) (cid:90)
f2(φ) logf2(φ)p(φ)dφ≤4c(p) ∥∇f(φ)∥2p(φ)dφ. (3)
IfpisanormalGaussianthenc(p) = 1/2.Thelog-Sobolevconstantgivesanexponentialrateofconvergenceofa
Langevindiffusion. Indeed,insertingthelog-Sobolevdefinition(2)in(1)provesthat
KL(p ,p)≤e−t/c(p)KL(p ,p). (4)
t 0
3HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ThetimeittakesforLangevindiffusionstoreachafixedprecisionisthusatmostproportionaltothelog-Sobolev
constantc(p). Thetroubleisthatc(p)typicallygrowsexponentiallywiththedimensiondofφ.
Upperboundsofthelog-Sobolevconstantcanbecomputedintwocases[BBD23]. Underindependenceconditions,if
(cid:81)
φ=(φ ) andpcanbeseparatedasatensorproductofdensitiesp(φ)= p (φ )then
k k k k k
(cid:0) (cid:1)
c(p)=max c(p ) . (5)
k k k
Inotherwords,thelog-Sobolevconstantofindependentrandomvariablesisthemaximumlog-Sobolevconstantof
eachvariable. Thesecondcase,whenU isstronglyconvex,istheBakry-Emerytheorem[BGL+14],whichprovesthat
1
∀φ , ∇2U(φ)≥αId ⇒ c(p)≤ . (6)
φ 2α
ThemaximumconstantαsatisfyingthisequalityistheinfimumoverφofalleigenvaluesoftheHessianmatrices
∇2U(φ). Thefollowingpropositiongivesalowerboundofthelog-Sobolevconstantfromthecovarianceofp.
φ
Proposition2.1. Letµ bethelargesteigenvalueofthecovarianceofp. Thelog-Sobolevconstantsatisfies
max
c(p)≥µ /2. (7)
max
ThispropositionisprovedinAppendixE.1. Itcomesfromtheinequalitybetweenlog-SobolevandPoincare´ constants
[Led00].
TheLangevindiffusionisnumericallycalculatedwithanEuler-Maruyamadiscretization. If∇ U(φ)isuniformly
φ
L−Lipschitz,thenthediscretizationtimestepcanbesmallerorequaltoL−1[VW22]. SinceListhesupremumofall
eigenvaluesoftheHessians∇2U(φ),itresultsfrom(4)thatthenumberofLangevindiffusionstepstoachieveagiven
φ
precisionisproportionaltothelog-Sobolevconstantmultipliedbythiseigenvaluesupremum. Itisanormalizationof
thelog-Sobolevconstant,whichspecifiesthecomputationalcomplexityoftheLangevinsamplingalgorithm.
Numerically,theconvergencerateofaLangevindiffusionisestimatedfromtherelaxationtimeτ oftheauto-correlation
A(t)=E
p
(cid:0)(cid:0) φ
t+t
−E[φ
t+t
](cid:1)T(cid:0) φ
t
−E[φ
t
](cid:1)(cid:1) ∝e− τt , (8)
t0 0 0 0 0
fort bigenough[Sok91,Sok97]. Therelaxationtimegivesanestimationofthelog-Sobolevconstant.
0
To eliminate the bias introduced by the discretization step of Langevin diffusion, synthesis are generated using a
Metropolis-AdjustedLangevinAlgorithm(MALA)[GM94]. ItiteratesoverdiscretizedLangevindynamicsproposals
thatareacceptedorrejectedusingtheMetropolis-Hastingsalgorithm.
2.2 ApproximationandLearningGibbsEnergies
TheGibbsenergyU ofaprobabilitydensitypisusuallynotknownapriori. Itisapproximatedbyaparametrizedmodel
p =Z−1e−U θ whereθisoptimizedbyminimizingKL(p,p ). Learningθfromadatasetofmsamples{φ(i)} is
θ θ θ i≤m
usuallydonewithamaximumlikelihoodestimation. Weshallseethatitcanbereplacedbyscorematchingestimations,
whichrequiremuchfewercalculations,butwhoseprecisiondependsuponthelog-Sobolevconstantc(p).
Exponential models We concentrate on linear approximations U of the Gibbs energy U, over a family of m′
θ
functionsΦ={ϕ } weightedbyθ ={θ }
k k≤m′ k k≤m′
U (φ)=θTΦ(φ)= (cid:88) θ ϕ (φ). (9)
θ k k
k≤m′
Itdefinesanexponentialfamilyofprobabilitydensities
p
(φ)=Z−1e−θTΦ(φ).
θ θ
AmajorissueistofindafamilyΦprovidinganaccurateapproximationU ofU inhighdimensiond, despitethe
θ
curseofdimensionality. Instatistics,eachϕ iscalledamomentgeneratingfunctionbecausethemaximumlikelihood
k
estimatorsofθisspecifiedbythevectorofmomentsE [Φ]asweshallsee. Theϕ canbepolynomialsofφ. However,
p k
ifweuseallhighorderpolynomialsofafixeddegree,thenthedimensionofΦhasapolynomialgrowthind. The
resultingestimationhasahighvariance,whichrequiresalargenumbermoftrainingsamples[CCL+20]. Markov
random fields [GG84] provide a powerful framework where all interactions are supposed to be local over native
variables,whichdefineslow-dimensionalmodels. However,itdoesnotapplytodatahavinglong-rangeinteractions,
which is the case for many image textures [PS00]. In physics, U is called an Ansatz. The ϕ are considered as
θ k
interactionpotentials. Physicalmodelsoftenrelyonmultilinearfunctionsofderivativesofφ. TheresultingAnsatzare
usuallylocalandlow-dimensional,butareunabletocapturecomplexsystemssuchasturbulence.
4HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
MaximumLikelihoodEstimation Thenextstepistooptimizeθinordertobestapproximatepbyp . Amaximum
θ
likelihood estimator θ maximizes −E (logp ), which is equivalent to minimize the KL-divergence KL(p,p ). If
p θ θ
U (φ)=θTΦ(φ)thenthisKLdivergenceisaconvexfunctionofθ. Themaximumlikelihoodestimatorcanthusbe
θ
calculatedwithagradient-descentalgorithmofstepsizeϵ,whichcomputes
(cid:16) (cid:17)
θ −θ =ϵ E (Φ)−E (Φ) . (10)
k+1 k p p
θk
ThemaximumlikelihoodparameterθsatisfiesE (Φ)=E (Φ). Theresultingp iscalledamomentprojectionofp
p p θ
θ
[Bis06]. IfthepotentialsofΦarelinearlyindependent,thenitisuniquelydefinedifitexists. Onecanverifythatthis
(cid:82)
momentprojectionisthedistributionp whichmaximizestheentropyH(p )=− p (φ) logp (φ)dφsubjecttothe
θ θ θ θ
momentconditionE (Φ)=E (Φ)[Jay57].
p p
θ
The expected value E (Φ) is estimated from the m samples φ(i) with a Monte Carlo sum m−1(cid:80) Φ(φ(i)). The
p i
estimationofE (Φ)withaMonteCarlosumrequirescomputingenoughsamplesofp . Itcanbedonewitha
p θ
θk k
Langevindiffusion,butitrequiresaconsiderableamountofcomputationssinceitmustberunforasufficientlylong
timesothattheLangevinalgorithmconverges,anditmustberepeatedenoughsothatMonteCarlosumconverges.
ThisisunfeasibleiftheLangevinconvergencerateistoolow.
Score Matching Estimation Optimizing p = Z−1e−U θ by minimizing the KL divergence is computationally
expensivebecausethegradientdescentonθ iθ ncludeθ stheterm∇ logZ = −E (cid:0) Φ(φ)(cid:1) . Scorematching[HD05]
θ θ p
θ
is an appealing alternative. It eliminates the normalization constant Z by replacing the KL minimization by a
θ
minimizationoftherelativeFisherinformation,whichdependson∇ logp
φ
I(p,p )=E (cid:0)1 ∥∇ logp (φ)−∇ logp(φ)∥2(cid:1) .
θ p 2 φ θ φ
Withanintegrationbyparts,[HD05]provesthatitisequivalenttominimizeaquadraticlossinθ:
ℓ(θ)=E (cid:0)1 ∥∇ U ∥2−∆ U (cid:1)
p 2 φ θ φ θ
=E (cid:0)1 ∥θT∇ Φ(φ)∥2−θT∆ Φ(φ)(cid:1) , (11)
p 2 φ φ
whosesolutionisobtainedwithoutsamplingp
θ
θ =M−1E (cid:0) ∆ Φ(φ)(cid:1) with M =E (cid:0) ∇ Φ(φ)∇ Φ(φ)T(cid:1) . (12)
p φ p φ φ
MinimizingthescorematchinglossisthusmuchfasterthanaminimizationoftheKLdivergence. Expectedvaluesare
estimatedbyenempiricalsumoverthemsamplesφ(i)ofp. EstimationerrorsintroducedbytheinversionofM must
oftenberegularized,whichisdonebyaddingϵIdtoM,whereϵdecreaseslikem−1foranestimationwithmsamples.
Scorematchingisaconsistentestimator,whichmeansthatifthereexistsauniqueθ∗suchthatp=p θ∗ >0thenwhen
mgoestoinfinity,theminimizerθofthescorematchinglossconvergestoθ∗[HD05]. However,therelativeprecision
ofascorematchingrelativelytoamaximumlikelihoodestimationdependsoniftheKLdivergencecanbecontrolled
bytherelativeFisherinformation. Thisiscapturedbythelog-Sobolevconstantc(p)definedin(2). Forexponential
modelsp ,Theorem2in[KHR22]boundsthecovarianceofthescorematchingestimationwiththecovarianceofthe
θ
maximumlikelihoodestimatormultipliedbyc(p)2. Theboundinvolvesamultiplicativeconstantwhichalsodepends
upontheregularityofU . ItsamplitudecanbeapproximatedbythelargesteigenvaluesquaredoftheHessianofU .
θ θ
SimilarlytotheLangevindiffusiontime,thelog-Sobolevconstantneedstobenormalizedbythislargesteigenvalue
amplitude. Ascorematchingthusachievesacomparableaccuracyasamaximumlikelihoodestimatorifthenumberm
ofsamplesismultipliedbythisnormalizedlog-Sobolevconstant,whichmaybeverylarge.
MultiscaleGaussianandnon-Gaussiandensities Ifp = Z−1e−U isazero-meangaussiandistribution,thenits
Gibbsenergyisquadratic
1
U(φ)= φTKφ ⇒ ∇2U(φ)=K ≥0. (13)
2 φ
The matrix K is symmetric positive and its inverse K−1 = C is the covariance matrix of p. The variance of φ is
normalizedbyimposingthatTrace(C)=d.Letµ bethelargesteigenvalueofC. TheBakry-Emeryupperbound
max
ofthelog-Sobolevconstantin(6)togetherwiththelowerbounds(7)provesthat
1
c(p)= µ . (14)
2 max
5HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
WeexplainedthatthenumberofstepsofaLangevindiffusionaswellastheinefficiencyofscorematchingrelatively
to maximum likelihood estimation is proportional to the normalized Sobolev constant, which is multiplied by the
supremumoftheeigenvaluesof∇2U =K. Itisthusdividedbythesmallesteigenvalueµ ofC =K−1andhence
φ min
proportionaltotheconditionnumberµ /µ ofthecovarianceC.
max min
Ifpisstationaryorhasstationaryincrements,thenC isdiagonalizedintheFourierbasis. Multiscalefieldshavea
covarianceeigenvalueateachfrequencyωwhichistypicallyoftheorderof|ω|−η forsomeη > 0andω ̸= 0. For
example,ifK =−∆thenφisaBrownianmotionandη =2.Thegrowthofeigenvaluesatlowfrequenciesmeansthat
φhaslongrangecorrelations. Intwodimensions,π ≥|ω|≥πd−1/2soc(p)=µ /2∝dη/2growswithd,whichis
max
notmodifiedbythenormalization. Ifpisnon-Gaussianthen,usingproposition2.1,westillhavec(p)≥µ /2which
max
meansthatitgrowsatleastlikedη/2.Toeliminatethegrowthduetothisbad-conditioningofthecovariance,wemust
separatedifferentfrequencybandswhereeigenvalueshavedifferentamplitudes. Thisisakeyideawhichmotivates
hierarchicalprobabilityfactorizationandtherenormalizationgroupintroducedinthenextsection.
3 Approximation,LearningandSamplingwithHierarchicFlows
SamplingaprobabilitydensitypwithaLangevindiffusionorestimatingitsGibbsenergybyscorematchingbecomes
unfeasiblewhenthelog-Sobolevconstantgrowswiththedimensiond. Thisistypicallythecaseforlargemultiscale
fieldsφ. Thissectionshowsthatthisdifficultymaybeavoidedifwedecomposepintoahierarchicflowofprobabilities
acrossscales,andifwerenormalizetheirtransitionprobabilitiestoboundtheirlog-Sobolevconstants.
Section3.1reviewsmultiresolutionapproximationsandwavelettransforms. Section3.2explainsthatahierarchicflow
ofprobabilitiescomputesaninverserenormalizationgroupstudiedin[MOBM22]. Sections3.3and3.4reviewsthe
estimationandsamplingoftheresultingprobabilitymodels,withscorematchingandMetropolisadjustedLangevin
diffusions. Forstationaryprobabilities,modelparameterssatisfyacouplingflowequationgiveninSection3.5. Section
3.6relateswaveletpropertiestothelog-Sobolevconstantsoftransitionprobabilities.
3.1 MultiresolutionApproximationsandWavelets
Multiresolutionsdefinecoarse-grainingapproximationswhoseevolutionsacrossscalesdependupondecomposition
coefficientsinawaveletbasis[Mal89b,Mey93]. Theycanbeextendedtoarbitrarydatadefinedonagraph. Webegin
fromtheconstructionofmultiresolutionapproximationongraphstoshowthathierarchicflowscanbeappliedtogeneral
datastructures. Wethenconcentrateonimageswhereweperformnumericalexperiments.
Multiresolutionandwaveletsongraphs Weconsiderφ∈Rddefinedbyitsdvaluesφ(n)onthenodesofagraph.
Multiresolutionapproximationscomputecoarsegrainingapproximationsofφofprogressivelysmallerdimensions,by
iteratingovercoarsegrainingoperators[HK22]. Letuswriteφ =φ. Foreachj >0,φ iscalculatedfromφ with
0 j j−1
acoarse-grainingaveragingoperatorG
j
φ =G φ . (15)
j j j−1
The rows of G sum to 1. It is a sparse in matrix which averages groups of neighbor coefficients of φ . The
j j−1
dimensionofφ isproportionalto2−rj whereristhedimensionofthegraph. Ifφisanimageandhencedefinedona
j
two-dimensionalgraph,thenr =2. Atalevelj,eachvalueofφ iscomputedbyaveragingvaluesofφ overgroups
j 0
ofneighbornodesinthegraph,whosesizesareproportionalto2rj. Itprovidesanapproximationatthescale2j. The
graphtopologyisthepriorinformationallowingtobuildthesemultiscalegroups. Inthesimplestcases,theaveraged
groupsarenon-overlappingandthecoarsegrainingdefinesacomputationaltree[GNC10]. TheoperatorG canalso
j
bedefinedasadiagonaloperatorintheorthogonalbasiswhichdiagonalizesthegraphLaplacian[HVG11]. Itcanthen
beinterpretedasaconvolutiononthegraph,whichprojectsφonthelower-frequencyeigenvectors.
Thecoarsegrainingisinvertedbyalsocomputingthehigh-frequencyvariationsofφ whichhavebeeneliminatedby
j−1
theaveragingoperatorG . Forthispurpose,wedefineacomplementoperatorG¯ whoserowsaresparsewithnearly
j j
(cid:16) (cid:17)
thesamesupportasG ,andsuchthat G j isaninvertiblesquarematrix. Waveletcoefficientsarethehighfrequencies
j G¯
j
φ¯ ofφ computedbythiscomplement
j j−1
φ¯ =G¯ φ . (16)
j j j−1
Theymeasurethevariationsofφ overlocalneighborhoodswhereG averagesφ .Let(H ,H¯ )betheinverse
j−1 j j−1 j j
(cid:16) (cid:17)
G
matrixof j :
G¯
j
H G +H¯ G¯ =Id, (17)
j j j j
Itresultsfrom(15)and(16)thatφ canberecoveredfrom(φ ,φ¯ )
j−1 j j
φ =H φ +H¯ φ¯ . (18)
j−1 j j j j
6HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
(cid:16) (cid:17)
If G j isanorthogonalmatrixthenH =GTandH¯ =G¯Tandthisdecompositionisorthogonal.
G¯ j j j j
j
Cascading(G ,G¯ )fromφcomputesamultiscaleaveragingφ =A φandwaveletcoefficientsφ¯ =W φwith
j j j j j j
A =G G ...G and W =G¯ G ...G . (19)
j j j−1 1 j j j−1 1
ThematrixW =(A ,W , ...W )isinvertibleandcomputesawavelettransformatallscales. Itisorthogonalifeach
J J 1
(cid:16) (cid:17)
G
j isorthogonal.
G¯
j
MultiresolutionofImages ImagesaresampledonauniformgridwhichisaEuclideangraphofdimensionr =2.
Fastwavelettransforms[Mal89a]arecalculatedwithconvolutionalandsubsamplingoperatorsonthisgraph,whichdo
notdependonj. TheoperatorsG =GandG¯ =G¯ aredefinedby
j j
Gφ(n)=φ∗g(2n) and G¯φ(n)=φ∗g¯(2n). (20)
The filter g is a low-pass filter which averages neighbor pixels in the image. The complement g¯ = (g¯ ) is
k 1≤k≤3
composedof3separablehigh-passfilterswhichcomputetheimagevariationsoverthesameneighborhood. Theinverse
operators H and H¯ inserts zeros between each coefficient of φ and φ¯ before computing convolutions with dual
j j
bi-orthogonalfiltershandh¯ [Dau92]. ThisfastwavelettransformisillustratedinFigure2. AppendixAreviewsthe
(cid:16) (cid:17)
propertiesofconjugatemirrorfilters(g,g¯)whichdefineanorthogonalmatrix G . Itimpliesthath(n) = g(−n)
G¯
andh¯(n)=g¯(−n).Allnumericalapplicationsarecomputedwithconjugatemirrorfilters,butthisisnotarequired
conditiontodefineahierarchicprobabilityflow.
Coarse Grained Fields
H
H
Wavelet Fields
Length Scale
Figure2: Afastwavelettransformiterativelydecomposesanimageapproximationφ intoacoarserapproximation
j−1
φ with a sub-sampled low-pass filtering G, and 3 wavelet coefficient images φ¯ . They are calculated by G¯ with
j j
subsampledconvolutionswith3band-passfiltersalongdifferentorientations. Afinerscaleimageφ isreconstructed
j−1
from(φ ,φ¯ )withtheinverseoperator(H,H¯).
j j
TheoperatorsA andW in(19)areacascadeofj convolutionsandsub-samplingsby2. Theyarethusconvolutional
j j
operators,followedbyasubsamplingby2j. Coarse-grainedimagesandwaveletcoefficientscanthereforebewrittenas
convolutionswithascalingfilterϕ andwaveletsψ subsampledby2j:
j j,k
φ
=(cid:0)
φ∗ϕ
(2jn)(cid:1)
and φ¯
=(cid:0)
φ∗ψ
(2jn)(cid:1)
. (21)
j j n j j,k k≤3,n
Thesescalingfiltersandwaveletsarespecifiedbythefilters(g,g¯)asexplainedinAppendixA.Thesupportwidthof
ϕ andψ isproportionalto2j. TheFouriertransformψˆ ofeachwaveletψ isdilatedby2−j.TheseFourier
j j,k j,k j,k
transformsareessentiallylocalizedinfrequencyannuliillustratedinFigure3(a),aroundthelowerfrequenciescovered
byϕˆ .
j
TherowsofthewavelettransformW =(A ,W , ...W )aretranslatedwaveletsatallscales,whichdefineabasis
J J 1
ofRd. ItisanorthogonalbasisifGandG¯ areconjugatemirrorfilters. Tostudyasymptoticpropertiesofwavelet
coefficientswhendgoesto∞,weneedtocontroltheconvergenceofthesebases. Ifwerenormalizethesupportofφto
[0,1]2thendiscreteorthonormalwaveletbasesconvergetowaveletorthonormalbasesofL2([0,1]2). Whentheimage
sizedgoesto∞thennormalizeddiscretewaveletsψ convergetowaveletfunctionsψ (x)=2−jψ (2−jx),such
j,k j,k k
that{x(cid:55)→ψ (x−2jn)} isanorthonormalbasisofL2([0,1]2)[Mal09].
j,k j≤0,n≤2−j,k≤3
7HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
𝜓^ 𝜓^
1,1 1,2
𝜓^ 𝜓^
2,1 2,2
𝜓^
𝜓^ 𝜓^ 1,3
3,1 3,2 𝜓^
𝜙^ 𝜓^ 2,3
3 3,3
(a) (b)
Figure3: (a): FrequencysupportsofFouriertransformsoftwo-dimensionalwaveletsψˆ (ω ,ω )for1≤k ≤3over
j,k 1 2
3scales2j. (b): Frequencysubdivisionsofwaveletpacketsovera levelsateachscale2j,witha =2,a =1and
j 1 2
a =0.
3
Wavelet packets The frequency resolution of wavelets can be improved with wavelet packet bases introduced
in [CMW92]. A wavelet packets transform sub-decomposes the frequency support of each wavelet. This is done
(cid:16) (cid:17)
by iteratively applying a times the convolutions and subsampling G , after applying G¯ to φ . It computes
j G¯ j−1
φ¯ =G¯ φ with
j j j−1
(cid:18) G(cid:19)a
j
G¯ = G¯. (22)
j G¯
(cid:16) (cid:17) (cid:16) (cid:17)
Thematrix G isorthogonalif G isorthogonal. Itthencomputesdecompositioncoefficientsinanorthogonal
G¯ G¯
j
basisofwaveletpacketvectors. Thefilter(22)performsafrequencysubdivisionofeachwaveletfrequencybandinto
22a j bands,illustratedinFigure3(b). ThesewaveletpacketsthushaveaFouriertransformwhichareconcentratedon
squaredomains,whichare2a j timesmorenarrowthanforwavelets. However,thespatialsupportofthesewavelet
packetsis2a j timeslargerthanforwavelets. Propertiesofwaveletpacketsarestudiedin[CMW92].
3.2 HierarchicFlowsandRenormalizationGroup
Wenowconsiderarandomvectorφdefinedonagraphwhoseprobabilitydensityisp(φ). IfphasalargeSobolev
constant, we avoid estimating and sampling p directly. A hierarchic representation of p is defined as a product of
conditionalprobabilitiesofwaveletcoefficients[MOBM22],whoselog-Sobolevconstantsarerenormalizedthrough
the renormalization of the wavelet coefficients. This hierarchic representation is calculated as an inverse of the
renormalizationgrouptransformation,whichiterativelycomputestheprobabilitydensityp (φ )fromp (φ ).
j j j−1 j−1
Forwardrenormalisation TherenormalizationgroupofKadanoff[KHY76]andWilson[Wil71]computesallp (φ )
j j
givenp(φ)atthefinestscale. Ititerativelycomputesp fromp withamarginalintegrationoverthehighfrequency
j j−1
degreesoffreedom, whichwerepresentwiththewaveletvariablesφ¯ . Waveletcoefficientsφ¯ arenormalizedby
j j
dividingeachcoordinateφ¯ (n)byitsstandarddeviationσ . LetD = diag(σ−1) bethecorrespondingdiagonal
j j,i j j,i i
matrix. Normalizingφ¯ isequivalenttoreplaceG¯ byD G¯ andH¯ byH¯ D−1.
j j j j j j j
Sinceφ =H φ +H¯ φ¯ wehavedφ =w dφ dφ¯ wherew =|det(H ,H¯ )|istheJacobianmodulus,and
j−1 j j j j j−1 j j j j j j
(cid:90)
p (φ )=w p (φ )dφ¯ . (23)
j j j j−1 j−1 j
The use of an appropriate coordinate system to compute the marginal integration of high frequencies φ¯ has been
j
thoroughlystudied[Del12]. Kadanoffrenormalizationgroup[KHY76]computesφ fromφ withablockaveraging,
j j−1
whichamountstodefineφ¯ asorthogonalwaveletcoefficientsintheHaarbasis,whichhasaminimalspatialsupportbut
j
isdiscontinuous.Inhisfirstversion,Wilsonrenormalization[Wil71]iscomputedwithShannonwavelets,whoseFourier
transformshaveaminimumsupportbutarediscontinuous. Shannonwaveletsthushaveaslowspatialdecay. These
waveletpropertiesarereviewedinAppendixA.OtherwaveletbasesadaptedtospecificclassesofHamiltonianshave
beendesignedbyBattle[Bat99],whoanalyzedrelationsbetweentherenormalizationgroupandwavelettransforms.
8HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Hierarchicflowasaninverserenormalization Ifφ isofsufficientlylowdimensionthenthereisnodifficultyto
J
estimatep (φ )fromdata,orsamplethisprobabilitydensity. Ahierarchicflowisaninverserenormalizationgroup
J J
transformationwhichmapsp intopwithaMarkovchain. Itcomputesp (φ )bymultiplyingp (φ )witha
J j−1 j−1 j j
conditionalprobabilityofφ givenφ ,whichisalsoequaltotheconditionaldensityofφ¯ givenφ
j−1 j j j
p (φ )=w−1p (φ )p¯ (φ¯ |φ ). (24)
j−1 j−1 j j j j j j
Cascading(24)transformsp intopwithtransitionkernelsdefinedbytheseconditionalprobabilities
J
J J
p(φ)=w−1p (φ )(cid:89) p¯ (φ¯ |φ ) with w = (cid:89) w . (25)
J J j j j j
j=1 j=1
Thisinversewaveletrenormalizationgroup[MOBM22]computespstartingfromp .
J
3.3 EstimationofaConditionalProbabilityModel
Givenmsamples{φ(i)} ofp,amodelofpisestimatedwiththehierarchicalfactorization(25),fromexponential
i≤m
modelsofeachconditionalprobability. Eachconditionalprobabilitymodelisestimatedfromdatabyscorematching,
whoseprecisiondependsuponitslog-Sobolevconstant.
Hierarchicmodel Anexponentialmodelp θ ofpisdefinedfromexponentialmodelsp θ
J
andp¯ θ¯
j
ofp J andp¯ j:
J
p θ(φ)=w−1p θ J(φ J)(cid:89) p¯ θ¯ j(φ¯ j|φ j). (26)
j=1
Anexponentialmodelofp isdefinedasin(9)by
J
p (φ )=Z−1e−θ JTΦ J(φ J). (27)
θ J J J
WechooseJ largeenoughsothatφ issufficientlylow-dimensionaltoeasilycomputethisestimation. Foranyj ≥J,
J
anexponentialmodelofp¯ isdefinedby
j
p¯ θ¯ (φ¯ j|φ j)=eF j(φ j)−θ¯ jTΨ j(φ j−1), (28)
j
whereF isafreeenergywhichnormalizestheconditionalprobability:
j
(cid:90) (cid:90)
p¯ θ¯ (φ¯ j|φ j)dφ¯ j =eF j(φ j) e−θ¯ jTΨ j(φ j−1)dφ¯ j =1. (29)
j
EachfreeenergyF j isspecifiedbyθ¯ j,butitdoesneedtobecomputedtoestimateθ¯ j orsamplep¯ θ¯ .
j
Themodelp =Z−1e−U θ hasaGibbsenergy
θ θ
J
U =θTΦ +(cid:88)(cid:0) θ¯TΨ −F (cid:1) . (30)
θ J J j j j
j=1
Section3.5explainsthatitcanbecalculatedwithacouplingflowequation,whichrequiresregressingeachF .
j
ScoreMatching Amaximumlikelihoodestimationcomputesθ =(θ ,θ¯ ) byminimizingKL(p,p ). Itresults
J j j≤J θ
fromthefactorization(25)ofpand(26)ofp that
θ
J
KL(p,p θ)=KL(p J,p θ J)+(cid:88) E p j(cid:0) KL(p¯ j,p¯ θ¯ j)(cid:1) . (31)
j=1
TheminimizationofKL(p,p θ)isthusobtainedbyminimizingeachE p j(cid:0) KL(p¯ j,p¯ θ¯ j)(cid:1) .
AsexplainedinSection2.2,minimizingaKLdivergencewithagradientdescentiscomputationallyexpensivebecause
itrequirescomputingnormalizationconstants. Wethusoptimize{θ ,θ¯ } byscorematching,whichreplacestheKL
J j j
divergencebyarelativeFisherinformation. Theparametersθ arecalculatedbyminimizingtheFisherinformation
J
I(p ,p¯ ),whichamounttominimizeaquadraticloss(11). Interactionparametersθ¯Tarecalculatedbyminimizing
J θ j
J
theaveragedFisherinformation
E p j(cid:0) I(p¯ θ¯ j,p¯ j)(cid:1) =E p j−1(cid:16) ∥∇ φ¯ jlogp¯ j(φ¯ j|φ j)−∇ φ¯ jlogp¯ θ¯ j(φ¯ j|φ j)∥2(cid:17) .
Thescoregradientiscomputedonφ¯ forφ fixed,andtheFisherinformationdoesnotdependonthefreeenergyF .
j j j
AppendixC.1showsthatθ¯ isalsoasolutionofaquadraticminimization.
j
9HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Conditionallog-Sobolevconstants AnupperboundofE p j(KL(p¯ j,p¯ θ¯ j))computedfromE p j(I(p¯ j,p¯ θ¯ j))depends
onalog-Sobolevconstantc(p¯ )averagedoverp . Theconditionallog-Sobolevconstantc(p¯ )ofp¯ (φ¯ |φ )isdefined
j j j j j j
asthesmallestconstantsothatforanyconditionalprobabilityq¯(φ¯ |φ )
j j
E (cid:0) KL(q¯,p¯ )(cid:1) ≤c(p¯ )E (cid:0) I(q¯,p¯ )(cid:1) . (32)
p j j p j
j j
OnecanapplyTheorem2in[KHR22]toprovethatthenumbermofsamplesneededforascorematchingtoachievea
comparableaccuracyasaKullback-Leiblerdivergenceminimizationisasymptoticallymultipliedbythisconditional
log-Sobolevconstant. Section2.2showsthatforexponentialmodels,minimizingaKLdivergenceisequivalentto
matchmoments,andhencethatminimizingE p j(cid:0) KL(p¯ j,p¯ θ¯ j)(cid:1) isequivalenttofindθ¯ j suchthat
E E (Ψ )=E (Ψ ).
p j p¯ θ¯ j j p j−1 j
Wecanthusevaluatethenumericalprecisionofscorematchingestimatorsfromthismomentmatchingcondition.
3.4 HierarchicSampling
A sample φ of a hierarchic model p of p is calculated from coarse to fine scales, by first sampling p and then
θ θ
J
iterativelysamplingeachp¯ θ¯ . TheseprobabilitydensitiesaresampledwithaMetropolisAdjustedLangevindiffusion
j
[GM94,RR98],andwerelatetherateofconvergenceoftheunadjusteddynamictolog-Sobolevconstants. Thisis
furtherdevelopedinappendixF.1.
Ahierarchicsamplingcomputesasampleφofp asfollows.
θ
• Initialization: computeasampleφ ofp .
J θ
J
• Forj fromJ to1,givenφ j computeasampleφ¯ j ofp¯ θ¯ (·|φ j)andsetφ j−1 =H jφ j +H¯ jφ¯ j.
j
Thesampleφ = φ ofp isthuscalculatedbyiteratingonastochasticequation,whichrecoversφ fromφ by
0 θ j−1 j
samplingrandomhighfrequencies. Theconditionalprobabilitiesp¯ θ¯ (·|φ j)aresampledwithaLangevin(orMALA)
j
algorithm,whichdoesnotdependuponthenormalizationfreeenergyF .
j
Convergenceofsampling Langevindiffusionshasanexponentialconvergenceiftheirlog-Sobolevconstantsare
uniformlybounded. Tosimplifyexplanations,weneglectthemodelapproximationerror,sop θ
J
=p J andp θ¯
j
=p¯ j.
Forafixedφ ,aLangevindiffusionapproximatesp¯ (.|φ )byp¯ aftertimet. Theproductp =w−1p (cid:81)J p¯
j j j j,t t J,t j=1 j,t
definesanapproximationofp. TheKLdivergenceerrorbetweenpandp canbedecomposedasasum
t
J
KL(p ,p)=KL(p ,p )+(cid:88) E (cid:0) KL(p¯ ,p¯ )(cid:1) . (33)
t J,t J p j,t j
j,t
j=1
ThedecayofKL(p ,p )isdrivenbythelog-Sobolevconstantc(p ),accordingto(4). Thesameresultappliestothe
J,t J J
conditionalprobabilitiesp¯ ifweincorporatetheexpectationinp .
j j
Similarlyto(4),DeBruinidentity(1)impliesanexponentialconvergenceoftheexpectedKLdivergence:
E (cid:0) KL(p¯ ,p¯ )(cid:1) ≤e−t/c(p¯ j)E (cid:0) KL(p ,p¯ )(cid:1) . (34)
p j,t j p j,0 j
j j
Notice that the expected value is in p and not in p as in (33) but they converge to the same value because p
j j,t j,t
convergestop whentincreases.
j
3.5 CouplingFlowEquationofStationaryEnergyModels
In some applications, the Gibbs energy model U in eq. (30) needs to be explicitly calculated. For example, to
θ
computehigh-dimensionalintegralswithMonteCarloreweighing[GRVE22],ortoanalyzetheinteractionproperties
ofaphysicalsystem. ItthenrequiresregressingthefreeenergiesF overpredefinedpotentialvectors. Wedefine
j
hierarchicalpotentials,allowingtobuildenergymodelswhosedimensionsincreasewiththefieldsize. Thisisneeded
toapproximatecomplexfieldshavingprogressivelymoredegreesoffreedomwhentheirresolutionincreases. For
stationaryprobabilities,weprovethatU canthenbecalculatedwithadiscretecouplingflowequation.
θ
10HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Energycalculation Eachconditionalprobabilitymodelp¯ θ¯ (φ¯ j|φ j) = eF j(φ j)−θ¯ jTΨ j(φ j−1) involvesafreeenergy
j
F (φ )thatisapproximatedbyalinearregressionαTΦ (φ ). Insertingthisapproximationintheenergymodel(30)
j j j j j
gives
J
U =θTΦ +(cid:88)(cid:0) θ¯TΨ −αTΦ (cid:1) . (35)
θ J J j j j j
j=1
Thecoefficientsα arecalculatedfromtheconditionalprobabilitynormalization(29),uptoanadditiveconstant
j
(cid:90)
eαT jΦ j(φ j) e−θ¯ jTΨ j(φ j−1)dφ¯ ≈cst. (36)
j
AppendixC.2showsthatcalculatingthegradientalongφ allowsustocomputeα byminimizingaquadraticform.
j j
Stationarymodels Ifp(φ)isstationaryandhencehasaGibbsenergyU(φ)whichisinvarianttotranslationsonthe
samplinggridofφthenp (φ )isinvariantbytranslationonthecoarsersamplinggridofφ . Hierarchicmodelsin
j j j
waveletbasesarenotstrictlystationarybecauseawaveletorthonormalwaveletbasisisnotinvariantbytranslations. To
defineastationarymodel,weiterativelyprojectthehierarchicmodelovertranslationinvariantfunctions.
LetT beatranslationofφ byτ (moduloperiodicboundaryconditions). Aprojectionoff(φ )overtranslation
τ j−1 j−1
invariantfunctionsofφ iscomputedbyaveragingitsvaluesoverallthetranslationsofφ onitsgridG ofsize
j−1 j−1 j−1
|G |
j−1
1 (cid:88)
(Ave f)(φ )= f(T φ ). (37)
j−1 j−1 |G | τ j−1
j−1 τ∈G
j−1
Iff(φ )isafunctionofφ =Gφ thenwewriteAve f =Ave f withf (φ )=f(Gφ ). Iff(φ )is
j j j−1 j−1 j−1 G G j−1 j−1 j
invarianttotranslationsofφ onitsgridG thenthesum(37)canbereducedtothe4translationsτ ∈G /G . The
j j j−1 j
followingtheoremprovesthatthistranslationinvariantprojectionofGibbsenergiesreducestheKullback-Leiblererror
onstationarydensities.
Proposition3.1. Letp(φ )beastationarydensity. Ifq(φ )isadensityofenergyU andifq˜(φ )isthedensity
j−1 j−1 j−1
ofenergyAve U then
j−1
KL(p,q˜)≤KL(p,q). (38)
TheproofisinAppendixE.2. Thispropositionprovesthatenergymodelsofstationaryprobabilitiesareimprovedby
theprojection(37)ontranslationinvariantfunctions.
Coupling flow equation with hierarchic potentials We introduce hierarchic stationary models where coupling
parameterscanbecalculatedawithaflowequationfromcoarsetofinescales,usingdatatoestimateeachterm. It
invertstherenormalizationgroupcouplingflowequation,whichgoesfromfinetocoarsescales[Del12].
Atthelargestscale2J,wehavecomputedamodelU oftheGibbsenergyofp .Ateachscale2j,wecancomputean
θ J
J
approximationU oftheGibbsenergyofp fromanapproximationU oftheGibbsenergyofp ,byaddingthe
θ j−1 θ j
j−1 j
interactionenergymodelθ¯TΨ −αTΦ ofp¯ =p /p . Proposition3.1provesthattheprojectionAve reduces
j j j j j j−1 j j−1
theapproximationerror. AtranslationinvariantGibbsenergymodelhavingareducederroristhus
U =Ave (U +θ¯TΨ −αTΦ ). (39)
θ j−1 θ j j j j
j−1 j
ThefollowingdefinitionimposesahierarchicconditiononΦ sothatθ canbecalculatedfrom(θ ,θ¯ ,α )witha
j−1 j−1 j j j
linearequation.
Definition 3.1. We say that {Φ } are hierarchic stationary with interactions {Ψ } if all Φ (φ ) are
j 0≤j≤J j 1≤j≤J j j
invarianttotranslationsofφ andifthereexistsalinearoperatorQ suchthat
j j
Ave (Φ ,Ψ )=Q Φ . (40)
j−1 j j j j−1
Thisdefinitiongeneralizesrenormalizablemodelswhichareself-similarandhavethesamedimensionatallscales.
hierarchicstationarypotentialsareconstructedbyprogressivelyincorporatingnewinteractionpotentialsΨ foreach
j
j. ThedimensionofΦ isthereforeincreasingasthescale2j decreases. Thisgeneralizationwillallowustobuild
j
potentialvectorsthatcanapproximateenergiesofcomplexfieldsinSection5.
Forhierarchystationarymodels,thefollowingpropositionderivesthattheparametervectorθ ofU satisfiesa
j−1 θ
j−1
linearequation,whichrelatesitto(θ ,θ¯,α ).
j j
11HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Proposition3.2. If{Φ } arehierarchicstationarysatisfying(40)thentheGibbsenergyU in(39)isgivenby
j j≤J θ
j−1
U =θT Φ with
θ j−1 j−1
j−1
θ =QT(θ −α ,θ¯ ). (41)
j−1 j j j j−1
Proof. Thispropertyisprovedbyinductiononj. Itisvalidforj =J whereU =θTΦ .Supposethatitisvalidfor
θ J J
J
j ≥J. InsertingU =θTΦ in(39)implieswith(40)that
θ j j
j
U =(θ −α , θ¯ )T(Φ ,Ψ )=θT Φ ,
θ j j j j j j−1 j−1
j−1
whereθ satisfies(41).
j−1
This proposition computes energy models with a discrete coupling flow equation in a wavelet basis, from coarse
to fine scales. It inverts the renormalization group equation, which goes from fine to coarse scale. In a Fourier
basis,thisrenormalizationgroupequationcanbewrittenasadifferentialequation,whichdefinesaPolchinskiflow
[Pol84,BBD23]. Theinverseequationinvolvestheparametersofconditionalprobabilities,whichspecifiesfinescale
probabilitiesfromcoarserscales. Thedimensionofthecouplingflowvectorθ alsoincreasesasthescaledecreases,
j
whichisnecessarytoobtainaccuratemodelsofcomplexfieldswhicharenotexactlyself-similar. Atthefinestscale
j =0,weobtainatranslationinvariantGibbsenergyU =θTΦ ofastationarymodelp ofp=p .
θ 0 0 θ 0
0 0
3.6 Log-SobolevConstantsandWaveletChoice
Wewanttodecomposephavingalargelog-Sobolevconstantintoconditionalprobabilitiesp¯ havingsmallerlog-
j
Sobolevconstants,whichcanthereforebelearnedandsampledmoreeasily. Todoso,westudythechoiceofbasisand
(cid:16) (cid:17)
ofthehierarchicalprojectorsG andG¯ .Inthefollowing,wesupposethat G j isanorthogonalmatrix.
j j G¯
j
Selectionofeigenvectors TheBakry-Emerytheoremgivesanupperboundofc(p¯ )fromtheinverseofthesmallest
j
eigenvalue of the Hessians ∇2 U¯ , if it is positive. This suggests choosing G and G¯ so that it maximizes this
φ¯ j j j
j
minimumeigenvalue. Intheorthogonalcase,φ =G¯Tφ¯ +GTφ so
j−1 j j j j
∇2 U¯ =G¯ (∇2 U )G¯T. (42)
φ¯ j j φ j−1 j
j j−1
TheHessianeigenvaluesofU¯ arethusobtainedbyselectingtheHessianeigenvaluesofU withtheorthogonaloper-
j j−1
atorG¯ . Tominimizethelog-Sobolevconstant,G¯ musteliminatesmallornegativeeigenvaluesof∇2 U (φ ).
j j φ j−1 j−1
j−1
Ifthehighamplitudeeigenvectorsof∇2 U (φ )areconcentratedinafixedlinearspacewithhighprobability,
φ j−1 j−1
j−1
thentherangeofG¯Tshouldbeincludedinthisspace.
j
Renormalizedlog-Sobolevlower-bound Therenormalizationofφ¯ byD aimsatpreconditioningthecovarianceof
j j
p¯ toavoidcreatingalargelog-Sobolevconstant. Ifµ¯ isthelargesteigenvalueofthecovarianceC¯ ofφ¯ then(7)
j max,j j j
provesthat
1
c(p¯ )≥ µ¯ . (43)
j 2 max,j
IfpisGaussianthenp¯ (.|φ )isthenalsoGaussiansoc(p¯ ) = µ¯ /2. Thelog-Sobolevnormalizationamounts
j j j max,j
to multiply by the largest eigenvalue of ∇2 U¯ . In the Gaussian case it divides by the smallest eigenvalue of the
φ¯ j
j
covarianceandisthusequaltothecovarianceconditionnumber. ThecovarianceC ofφ iscomputediterativelyfrom
j j
C with(15),whichimpliesthatC =G C GT. ThecovarianceC¯ ofφ¯ iscomputedfromG¯ ,whichincludesthe
0 j j j−1 j j j j
renormalization. Itgives
C¯ =G¯ C G¯T with diag(C¯ )=Id. (44)
j j j−1 j j
ThecovarianceC isprojectedandrenormalizedbyG¯ ,whichsetsthediagonalvaluesofC¯ to1. Themaximum
j−1 j j
eigenvalueandtheconditionnumberofC¯ donotgrowwiththedimensiondifG¯ representsC overabasisof
j j j−1
nearlyeigenvectors,sothatalleigenvaluesremainoftheorderof1. Thisnecessaryconditiontocontrolthelog-Sobolev
constantisnotsufficient. Non-convexGibbsenergiesmayhavemuchlargerlog-Sobolevconstants. Thisissueisstudied
numericallyinSections4.2and5.2forscalarpotentialenergiesand2dturbulencedata.
12HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Choice of wavelet and wavelet packet basis For multiscale stationary processes, we explain that the largest
eigenvalues and the condition numbers of all C¯ remain bounded if the wavelet has a Fourier transform which is
j
sufficientlywelllocalized. Wedonotgivemathematicaldetailsbutquotethemainresults. Itgivesnecessaryconditions
tocontrolthegrowthofc(p¯ )anditsnormalization,withthedimensiond.
j
MultiscalestationaryfieldshaveadensitypwhosecovarianceisdiagonalizedinaFourierbasis, witheigenvalues
whichgrowlike|ω|−η atlow-frequencies. Inanimageofwidthd1/2,ifthesmallesteigenvalueisoftheorderof1then
thelargesteigenvalueisoftheorderofdη/2,whichimpliesthatthelog-Sobolevconstantc(p)increasesatleastlike
dη/2. Ahierarchicalfactorizationtriestoavoidthisgrowthbyrenormalizingφ¯ sothatthenormalizedlog-Sobolev
j
constantremainsboundedforalld. Anecessaryconditionisthattheconditionnumberofthenormalizedcovarianceof
φ¯ doesnotgrowwithd. Computingthisconditionnumberwhendgoestoinfinityamountstostudythedecomposition
j
ofthelimitcovarianceoperatorofφinawaveletorthonormalbasisofL2([0,1]2),bynormalizingthemaximumto1.
TherenormalizationsetsthediagonalofC¯ to1sothatitslowestandlargesteigenvaluesremainoftheorderof1. It
j
isvalidifthecovarianceispreconditionedbyitsdiagonalinthewaveletbasis. Classesoflinearsingularoperators,
preconditionedbytheirdiagonalinawaveletbasis,havebeenthoroughlystudiedinharmonicanalysis[Mey93]. Itis
usedtoprovethatsuchbasesareunconditionalbasesofSobolev,HolderandBesovspaces. Preconditioninginwavelet
basesisalsoappliedtothefastresolutionofellipticproblems[Jaf92]. Forappropriatewavelets,itisvalidforlarge
classesofpseudo-differentialoperators,andforsingularhomogeneousoperatorsdiagonalizedinaFourierbasiswith
eigenvaluesproportionalto|ω|−η. ItrequiresthattheFouriertransformofwaveletsaresufficientlywelllocalized.
Atlowfrequencies,eachwaveletψ musthaveaFouriertransformψˆ satisfying|ψˆ (ω)|=O(|ω|η/2),toavoidbeing
k k k
contaminatedbytheexplosionofthelargesteigenvaluesatlow-frequencies. Ifawavelethasmvanishingmoments,
thenAppendixAshowsthat|ψˆ (ω)|=O(|ω|m). Wethuschooseawaveletwithm≥η/2vanishingmoments. At
k
highfrequencies,|ψˆ (ω)|musthaveadecayfasterthan|ω|−η/2,whichissatisfiedifψ hasm≥η/2derivativesin
k k
L2([0,1]2). Iftheψ haveacompactsupport,morethanη/2vanishingmomentsandη/2boundedderivatives,then
k
onecanprove[Mey93,MOBM22]thatthemaximumeigenvalueandtheconditionnumberofthecovarianceofallφ¯
j
areuniformlyboundedforallj andd.
Abadconditioningmaybeproducedbythesmallesteigenvaluesofthecovariance,whichareproperlyrenormalized
iftheyhaveadecaywhichisfasterthanapowerlawatthehighestfrequencies. Athighfrequencies,thefrequency
resolution of wavelets is not sufficient to follow this fast decay and thus renormalize these small eigenvalues. To
ensurethattheconditionnumberofthecovariancedoesnotincreasewithd,onecanrepresentthehigh-frequencyφ¯
j
inawaveletpacketbasishavingabetterfrequencyresolution. EachwaveletpacketmusthaveaFouriertransform
concentratedinasufficientlynarrowfrequencydomain,wherethecovarianceeigenvaluesvarybyalimitedmultiplicative
factor. Thefrequencywidthofthesewaveletpacketsis2a j timesmorenarrowthanwaveletsifcomputedwithawavelet
packetfilterG¯ definedin(22). Theconstanta isadjustedtodefinewaveletpacketcoefficientsφ¯ whosenormalized
j j j
covarianceC¯ hasaconditionnumberoftheorderof1. Improvingwaveletpacketfrequencyresolutionsby2a j also
j
increasestheirspatialsupportbyafactor2a j. Wethuschoosea tobeassmallaspossible. ThisisappliedinSection
j
5.2toimprovetheLangevinmixingtimefor2Dturbulencevorticityfields.
4 HierarchicalModelsofLocalScalarPotentials
Scalarpotentialmodelsintroducedinthissectionarelocalinteractionmodelsoftenusedinstatisticalphysics. Westudy
theparticularcaseoftheφ4modeltoillustratetheestimationandsamplingpropertiesofhierarchicalprobabilityflows
atphasetransitions.
4.1 Scalarpotentialenergiesandφ4model
Physicalsystemsatequilibriumhaveaprobabilitydensityp=Z−1e−U withanenergyU decomposedinaquadratic
termcorrespondingtotwopointinteractionsandanon-linearpotentialV(φ)whichspecifiesallotherinteractions:
−β
U(φ)= φT∆φ+V(φ). (45)
2
TheLaplacian∆isdiscretizedoverthegridofφanddefinesthekineticenergyatatemperature1/β. Somephysical
systems[Ram20]haveapotentialV whichisreducedtoasumofscalarpotentialsatalllocationsn
(cid:88)
V(φ)= v(φ(n)). (46)
n
13HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Itenforcesnointeractionsbetweendifferentsitesnbutfavorsvaluesofφ(n)wherevisnearlyminimum. Ferromag-
netismandsecondorderphasetransitionsarecapturedbytheφ4model[ZJ21].Itsscalarpotentialv(t)=t4−(1+2β)t2
isnon-convex,withadouble-wellwhichpushesthevaluesofeachφ(n)towards+1or−1[ZJ21].
(a) (b) (c) (d)
Figure4: TopRow: Realisationsofφ4 fieldsattemperature1/β,andsystemsized=1282. (a): Forβ =0.5<β
c
, the system is disordered with short range correlations. (b): At the phase transition, β = 0.68 ≈ β , the field is
c
self-similar, withlongrangecorrelations. (c): Forβ = 0.76 > β , thesystemisinaferromagneticphase, witha
c
non-zeromean(herepositive). Bottomrow: samplesgeneratedwithahierarchicfactorizationinaHaarwaveletbasis
withthesameβ in(a,b,c). (d): Thegraphshowsthecovarianceeigenvalues(powerspectrum)inthese3cases,asa
functionofthetwo-dimensionalfrequencyradius|ω|=(|ω |2+|ω |2)1/2. Forβ =β ,eigenvalueshaveapower-law
1 2 c
decayanddevelopasingularityatlowfrequencies,whichcorrespondtolong-rangecorrelations. Wesuperimposed
indashedlinethecovarianceeigenvaluesofahierarchicmodelestimatedbyscorematching. Forvisualization,the
spectrumatdifferenttemperaturesaremultipliedbyaconstantwhichalignstheirminimumeigenvalue.
Ifβ =0thenU(φ)=(cid:80) v(φ(n)). Eachφ(n)aretheni.i.dindependentrandomvariablesofdensityp˜(t)=ηe−v(t).
n
Thepowerspectrumisconstant. Wesawin(5)thattheindependenceimpliesthatthelog-Sobolevconstantsatisfies
c(p) = c(p˜), and thus does not depend upon the dimension of φ. If β > 0 the Laplacian correlate pixels over
a progressively larger neighborhood as β increases. It increases the power spectrum at low frequencies. In the
thermodynamiclimitd→∞ofinfinitesystemsize,theφ4energyhasaphasetransitionatβ ≈0.68[KMR16]. The
c
powerspectrumthenhasapower|ω|−η withη =1.75asshowninFigure4(d). Itissingularatlow-frequencies,which
correspondstoafieldhavinglongrangecorrelations. Figure4showsrealizationsofφ4fieldsforβ <β ,β =β and
c c
β >β . Forβ >β (low-temperature),therearetwophaseswheretheaveragefieldvalueisstrictlypositiveorstrictly
c c
negative,whichexplainsferromagnetism. Figure4(d)correspondstoonephasewheremostfieldvaluesarecloseto1.
Hessianseigenvalues Theprobabilitydensityphasanon-convexenergyU whoseHessianis
∇2U(φ)=−β∆+diag(µ ) with µ =v′′(φ(n)).
φ n n n
TheLaplacian∆isdiagonalintheFourierbasiswitheigenvalues|ω|2.ThescalarpotentialisdiagonalinaDirac
basiswithpositiveandnegativeeigenvalues. TheseeigenvaluesaremuchlargerthantheLaplacianeigenvaluesat
low-frequenciesandproduceeigenvectorsoftheHessian∇2U havingnegativeeigenvalues.
φ
Todefineahierarchicmodelwithconditionalprobabilitiesp¯ (φ¯ |φ )havingsmalllog-Sobolevconstants,Section
j j j
3.6explainsthatwemaychooseprojectorsG¯ thatselecteigenvectorshavinghighamplitudepositiveeigenvalues,
j
anddiscardnegativeeigenvalues. Atthefinestscale,thiscanbedone[GLBM23]withafirsthigh-frequencyfilterG¯
1
whicheliminateslowfrequenciesandselectshigh-frequencyvariablesφ¯ . TheresultinginteractionenergyU¯ hasa
1 1
projectedHessian
∇2 U¯ (φ)=−βG¯ ∆G¯T+G¯ (diag(µ ) )G¯T.
φ¯ 1 1 1 1 i i 1
1
14HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Figure5(a)comparesthehistogramsoftheeigenvaluesof∇2 U andtheHessian∇2 U¯ (withoutnormalizationfor
φ 0 φ¯ 1
0 1
comparisonpurposes). ItiscomputedwithaSymlet-4waveletforφ4 atcriticaltemperatureβ = β . Asexpected,
c
∇2 U¯ hasfewernegativeeigenvaluesthan∇2 U ,butsomestillremain. Thesenegativeeigenvaluescanbealmost
φ¯ 1 φ 0
eve1 rywhereeliminatedbyanorthogonalG¯ se0 lectingamorenarrowhigh-frequencybandthanwavelets. Thiscan
1
bedonewithwaveletpackets[GLBM23]. Sinceφ4hasaself-similarprobabilitydistributionatthephasetransition
β =β ,thesameresultisobtainedatallotherscales2j.
c
(a) (b)
Figure5:(a):Weconsiderimagesφ oftheφ4modelofdimensiond=1282,foracriticalβ =β .Theapproximations
0 c
φ arecalculatedwithaSymlet-4filteratthefinestscale21. Thegraphshowsthedistributionsofeigenvaluesofthe
1
Hessian∇2 U inblue,andof∇2 U¯ =∇2 U (withoutrenormalization)inorange. Themostnegativeeigenvalues
φ 0 φ¯ 1 φ¯ 0
0 1 1
of∇2 U correspondtolowfrequencyeigenvectors. Theydonotappearin∇2 U¯ . (b): Distributionsofeigenvalues
φ 0 φ¯ 1
0 1
ofHessians∇2 U¯ atallscales2j ≤2J,ford=322,withJ =3,forsamplesofhierarchicalmodelsofφ4atphase
φ¯ θ
j j
transition. TheyarecomputedforHaar(blue),Symlet-4(orange)andShannonwavelets(green). Eigenvaluesaremore
concentratedwhenthewavelethasabetterfrequencylocalization.
Figure5(b)displaysthedistributionofeigenvaluesof∇2 φ¯ jU¯ θ¯ j(φ j−1),forsamplesφ j−1ofahierarchicmodel,computed
at all scales 2j ≤ 2J. These distributions are calculated for hierarchical factorization computed with Haar (blue),
Symlet-4(orange)andShannon(green)wavelets. TheHessianeigenvaluesarenearlythesameforShannonwavelets
andSymlet-4. ForHaarwaveletstherearemuchmorehighamplitudeeigenvalues. Indeed, Haarwaveletsarenot
aswelllocalizedinfrequency. ForaHaarwavelet, |ψˆ(ω)|2 decayslike|ω|−2 athighfrequenciesbecauseψ(x)is
discontinuous. Thehighamplitudeeigenvaluesareduetothisslowhigh-frequencydecay,whichslowlycompensatefor
thegrowthsoftheHessianeigenvaluesproportionalto|ω|η forη =1.75[Ta¨u14].
TheexistenceofnegativeHessianeigenvaluespreventsusingtheBakry-Emerytheoremtocomputeanupperbound
onthelog-Sobolevconstantofwaveletconditionalprobabilities. However,weshallseeinthenextsectionthatthese
remainingnegativeeigenvaluesdonotpreventtheLangevindiffusionfromexponentialconvergence,evenatthephase
transition. Thesenumericalresultsareanindicationthatlog-Sobolevconstantofwaveletconditionalprobabilitiesdo
notdependuponthescale.
4.2 LearningandSamplinghierarchicScalarPotentialEnergies
This section reviews the estimation of hierarchic models of scalar potentials introduced in [MOBM22], and its
applicationtotheestimationandsamplingoftheφ4modelatcriticaltemperature. Itisshownin[MOBM22]thatthe
criticalslowingdowndisappearswhensamplingtheconditionalprobabilitiesofahierarchicfactorization,althoughthe
HessiansstillhavenegativeeigenvaluesinFigure5. Wecomparedifferentwaveletsforlearningandsamplingtheφ4
modelatcriticaltemperature. Weshallseethatthemodelerrorsdecreasebydecreasingthewaveletsupport. Learning
precisionversussamplingconvergenceintroducesatrade-offbetweenspatialandfrequencylocalization,whichjustifies
theuseofwaveletsasopposedtoaFourierbasis,andwhereHaarwaveletsarethewinners.
Hierarchicscalarpotentials AhierarchicmodelisdefinedwithacoarsescalemodelU =θTΦ andinteraction
θ J J
J
energymodelsU¯ θ¯ =θ¯ jTΨ j ateachscale2j ≥2J. WedefineΦ J andeachΨ j forscalarpotentialenergies,andprove
j
thatitdefinesastationaryhierarchicmodel,whosecouplingparametersarecomputedwithacoarsetofinecoupling
flowequation.
15HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Atthecoarsestscale,U =θTΦ includesatwo-pointinteractionmatrixandaparametricscalarpotential
θ J J
J
1
θTΦ (φ )= φTK φ +V (φ ), (47)
J J J 2 J J J γ J J
(cid:80)
whereV (φ)hasascalarpotentialv (t)= γ ρ (t)decomposedoverafiniteapproximationfamily{ρ (t)} with
γ γ k k k k k
coefficientsγ =(γ ) . Itresultsthat
k k
V (φ)=γTΓ(φ) with
Γ(φ)=(cid:16)(cid:88)
ρ
(φ(n))(cid:17)
. (48)
γ k
k
n
Weusetranslatedsigmoidswhichdonotgrowatinfinity: ρ (t)=(1+exp((t−t )/σ ))−1. Innumericalcalculations
k ℓ k
thereare40evenlyspacedtranslationst ,onthesupportofthedistributionofeachφ (n),andσ = 3(t −t ). To
k J k 2 k+1 k
defineamodelofp whichisstationaryisequivalenttoimposethatK isaconvolutionaloperator.
J J
TheinteractionGibbsenergyU¯ θ¯ ofp j(φ¯ j|φ j)includestwo-pointinteractionswithinthehighfrequenciesφ¯ j,between
j
highfrequenciesφ¯ ,andthelowerfrequenciesφ ,withconvolutionmatricesK¯ andK¯′,plusascalarpotential
j j j j
U¯ θ¯ j(φ j−1)=φ¯T jK¯ jφ¯ j +φ¯T jK¯ j′φ j +V¯ γ¯ j(φ j−1)=θ¯ jTΨ j(φ j−1). (49)
Itdefines
 K¯   φ¯ φ¯T 
j j j
θ¯ j = K¯ j′  and Ψ j(φ j−1)= φ¯ jφT j . (50)
γ¯ Γ(φ )
j j−1
ThestationaryinteractionK¯′ betweenhighandlow-frequencieshasanenergycontributionwhichistypicallymuch
j
smallerthantheinteractionK¯ withinhighfrequencies,becauseφ andφ¯ arecomputedoverfrequencydomainshaving
j j j
asmalloverlap. ThefollowingtheoremdefinesastationaryhierarchicmodelfromthisscalarpotentialinteractionsΨ .
j
Withanabuseofnotation,wewriteφ∗φTtheconvolutionbetweenφandφT(n)=φ(−n). Werecallfrom(65)that
φ (n)=φ∗ϕ (2jn).
j j
Theorem4.1. Foranyj ≥J,
(cid:18) φ ∗φT (cid:19)
Φ (φ )= j j (51)
j j Γ(φ ∗ϕ )
j ℓ J−j≥ℓ≥0
definesstationaryhierarchicpotentialswithinteractionsΨ in(49). RegressingeachfreeenergyF overΦ definesa
j j j
finescaleGibbsstationarymodelforj =0
J
U (φ)= 1 φTKφ+(cid:88) V (φ) with V (φ)=γTΓ(φ∗ϕ ), (52)
θ 2 j j j j
j=0
whereK isaconvolutionmatrixand(γ ) arescalarpotentialparameterscomputedbyacouplingflowequation.
j 0≤j≤J
TheproofisinAppendixE.3. Ateachscale2j,thisGibbsenergyhasadifferentscalarpotentialV (φ)=γTΓ(φ∗ϕ ).
j j j
Theconvolutionwithϕ averagesφoveradomainproportionalto2j. Asthescale2j increases,itbecomesmoreand
j
morenon-local. Scalarpotentialenergies(45),suchastheφ4model,haveasinglepotentialV (φ)=(cid:80) v (φ(n))at
0 n 0
thefinestscalej = 0andarethuslocal. Theycorrespondtoaparticularcasewhereγ = 0forj < 0. However,a
j
singlefinescalescalarpotentialisnotalwayssufficient. Thisisthecaseofcosmologicalweak-lensingfields,which
canbeapproximatedbyincorporatingdifferentscalarpotentialsV atdifferentscales. Inthiscase,numericalresults
j
showthathierarchicscalarpotentialmodelsprovideaccurateapproximationsofU [GLBM23,MOBM22].
Hierarchicmodelestimationandsampling Theparameters{θ ,θ¯ } areestimatedfrommsamples{φ(i)}
J j j≤J i≤m
ofp,withtheconditionalscorematchingalgorithmofSection3.3. Samplesφofp θ =w−1p θ
J
(cid:81) jp¯ θ¯
j
arecomputed
withthehierarchicalsamplingalgorithmofSection3.4,whichdoesnotrequiretheknowledgeofthefreeenergies,or
normalizations,ofthep¯ . TheMALAalgorithmincludesarejectionofLangevindiffusionpropositions. Thescalar
θ
j
potentialalsorejectsproposalsoutsideahighprobabilityinterval. Figure4comparesoriginalsamplesfrompcomputed
withexactφ4energiesatdifferenttemperatures,andsamplesofahierarchicalmodelp¯ estimatedinaHaarwavelet
θ
basis. Generatedimageshavetextureswhichcannotbedistinguishedvisuallyfromtheoriginalimagetextures.
Themodelprecisioncanbeevaluatedbycomputingtheresultingstationaryenergyandbycomparingitwiththetrueφ4
energy. Ahierarchicstationarymodel(52)ofφ4iscalculatedintheHaarbasisfromtheestimatedinteractionenergy
16HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
(a) (b) (c)
Figure 6: Original and estimated energy of φ4 at critical temperature, for images of size d = 128 × 128. (a):
Superpositionofthescalarpotentialv(t)oftheφ4 modelforβ =β andtheestimatedscalarpotentialv (t)ofthe
c 0
hierarchicalstationaryenergymodelU . (b): SuperpositionoftheLaplacianeigenvalues(intheFourierbasis)andthe
θ
eigenvalueoftheestimated2-pointinteractionmatrixK ofU . (c): EstimatedconvolutionkernelofK. Theseresult
θ
showthatthehierarchicalstationarymodelcalculatedinaHaarbasisgivesapreciseapproximationoftheφ4energy.
parametersθ¯ andthefreeenergyparametersα . Theonlynon-zeroscalarpotentialisatthefinestscalej = 0. It
j j
impliesthatthescalarpotentialofthefreeenergyF cancelsthescalarpotentialoftheenergyatthepreviousscale.
j
Figure6comparestheestimatedenergyU andoriginalφ4 energy. Figure6(a)comparestheestimatedv (t)and
θ 0
originalscalarpotentialfunctionv(t). Figure6(b)comparestheeigenvaluesoftheestimatedtwo-pointinteraction
matrixK andofaLaplacian,whichisthetwo-pointinteractionsoftheφ4model. Figure6(c)showstheconvolution
kernelofK isindeedclosetoaLaplacian. ItshowsthatthehierarchicstationarymodelinaHaarwaveletbasisgives
anaccurateapproximationoftheφ4energymodelatthephasetransition. Weshallseeattheendofthissectionthatthe
estimationerrorbecomeslargerwithDaubechiesandShannonwavelets,whichhaveaspatialsupportlargerthanHaar
wavelets.
105
10 2
104 Haar
Daubechies Symlet
Shannon 10 3
103
Direct Sampling
102 Haar
10 4
Daubechies Symlet
Shannon
101
103 104 103 104
d d
(a) (b)
Figure7: (a): NormalizedLangevinauto-correlationrelaxationtimeoftheφ4modelatcriticaltemperatureandfor
hierarchicalmodelscomputedindifferentwaveletbases. InredisshownthenormalizedrelaxationtimeofaLangevin
applieddirectlyontheenergyoftheφ4modelgrowswiththeimagedimensiond.Itillustratesthecriticalslowingdown.
Onthecontrary,itremainsconstantforallwavelethierarchicalmodels. Thisconstantdependsuponthelog-Sobolev
constantofwaveletconditionalprobabilities,whichdependsuponthewaveletchoice. Itdecreaseswhenthewavelet
hasaFouriertransformwhichisbetterconcentrated. ItismaximumforHaarandsmallerforDaubechies-4Symletand
Shannonwavelets.
(b):Approximationerrorofhierarchicalmodelscomputedinthesamebasesasin(a).Thiserrormeasuresthedifference
betweenthemarginalandsecondordermomentsofsamplesofφ4andthesamemomentscomputedfromsamplesof
hierarchicalmodelsineachwaveletbasis. ItisquantifiedwithaKLdivergencecalculatedin(84). Theerrordecreases
whenthewaveletsupportdecreasesbecauseitisdominatedbytheestimationerrorofthenon-convexscalarpotential.
ItismuchsmallerforaHaarwaveletthanforSymlet-4wavelets. TheShannonwaveletwhichhasanon-compact
supportwithaslowspatialdecayyieldsamuchlargererrorthanHaarandSymlet−4wavelets.
17HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Criticalslowingdownatphasetransition Samplingp = Z−1e−U withanundajustedLangevinalgorithmhas
a computational complexity proportional to the number of iterations after discretization. It is proportional to the
log-Sobolevconstantc(p)multipliedbythelargesteigenvalueoftheHessianofU,asexplainedinSection2.1. For
β = β ,itsuffersfromacriticalslowingdownduetoagrowthofthelog-Sobolevconstantwhenthesystemsized
c
increases. TheconvergenceofLangevindiffusionisestimatedbytheauto-correlationrelaxationtimedefinedin(8),
whichistypicallyproportionaltothelog-Sobolevconstantc(p). Thecomputationalcomplexityisevaluatedbythe
normalizedrelaxationτ equaltoauto-correlationrelaxationtimedividedbythediscretisationtimestep. Figure7(a)
givestheevolutionofthisnormalizedhierarchicrelaxationtimeτ asafunctionofthesystemsizedforβ = β . It
c
growslikedη 0/2forη =2[Pod96,Set21,Ta¨u14]. Thisbehaviorispartlyexplainedbythelog-Sobolevlower-bound
0
c(p)≥µ /2whereµ isthelargesteigenvalueofthecovariance. Itgrowsliked1.75/2forβ =β ,asshownby
max max c
thepowerspectruminFigure4. However,thisexplanationisnotcompletesincethecovarianceisonlyalower-bound.
Thelog-Sobolevconstanthasafastergrowthexponentwhere1.75isreplacedby2whichgivesd. Indeed,italsosuffers
fromthenon-convexityofthescalarpotential,whichisnotcapturedbythecovariancelower-bound.
Ithasbeenshownin[MOBM22]thatahierarchicalfactorizationinawaveletbasisavoidsthiscriticalslowingdown. To
computethenormalizedauto-correlationrelaxationtimeofthehierarchicalsamplingalgorithm,wecomputeforeachj
therelaxationtimeτ¯ j ofprobabilityp θ¯ (φ¯ j|φ j),likein(8). Thehierarchicnormalizedauto-correlationrelaxationtime
j
τ,isdefinedby
τ
=(cid:88)J d¯
j τ¯ +
d
J τ , (53)
d j d J
j=1
where (d¯,d ) are the dimensions of (φ¯ ,φ ). Appendix F.1 explains how to estimate the relaxation time of each
j j j j
conditionalprobability. Eachnormalizedrelaxationtimeτ¯ isdividedbythediscretizationtime-step. Toevaluatethe
j
overallcomputationalcomplexity,eachτ¯ j ismultipliedbytherelativesized¯ j/dofthegradient∇ φ¯ jU¯ θ¯ j.
Figure7(a)givesthehierarchicnormalizedauto-correlationrelaxationtime,dependingonthesystemsized,fordifferent
waveletbasis. ForHaar,DaubechiesSymletsandShannonwavelets,Figure7(a)showsthathierarchicnormalized
auto-correlationrelaxationtimesdonotincreasewiththedimensiond,whatverifiesthattheydonotsufferfromthe
phase-transitioncriticalslowingdown. Itreproducestheabsenceofcriticalslowingdownobservedin[MOBM22]with
anMetropolis-Hastingsampling,asweknowthattheMCMCmixingtimetendstoanundadjustedLangevindiffusion
inthecontinuumtimelimit[ABBL06,GGR97].
Theseexperimentsgiveastrongindicationthatlog-Sobolevconstantsofwaveletconditionalprobabilitiesareuniformly
boundedindependentlyofd,despitethefactthattheenergyHessianshavenegativeeigenvalues. Thisisamathematical
conjecturewhichhasnotbeenproved.Calculationsofthelog-Sobolevconstantofφ4havebeencarriedfortemperatures
abovethecriticaltemperature[BD22,BBD23,CE22,BB19],buthavenotbeenextendeduptothephasetransition. As
expected,Figure7(a)alsoshowsthathierarchicnormalizedauto-correlationrelaxationtimebecomessmallerwhen
improving the frequency localization of wavelets. Shannon wavelets have more vanishing moments and are more
regularthanDaubechiesSymletswhicharethemselvesbetterlocalisedinfrequencythanHaarwavelets. Becausethe
Haarwavelethasapoorfrequencylocalization,thecoarsegrainingdoesnoteliminateallthehighfrequencyfrom
φ ,whichareresponsibleforbigeigenvaluesin∇2 U¯ . Thistail,observedFigure5(b)requiresreducingthetime
j−1 φ¯ j
j
samplingstepoftheLangevindynamic,anditincreasesthenormalizedrelaxationtimes.
Energyestimationerror Approximatingscalarpotentialenergiesrequirestoaccuratelyapproximatethekinetic
energytermandthescalarpotential. TheHessianofthekineticenergyisaLaplacian,whichisdiagonalinaFourier
basiswithpositiveeigenvalues. Thescalarpotentialisnon-convexwithaHessianwhichisdiagonalinaDiracbasis
withnegativeeigenvalues. Itisthedifficulttermtoestimate.
Hierarchicalmodelscanbesampledwithoutestimatingthefreeenergiesofconditionalprobabilities. Toevaluatethe
modelprecisionwithoutestimatingthefreeenergies,wequantifyestimationerrorsbycomputingmodelerrorsona
sufficientsetofmoments. ThesemomentsareestimatedbyMonteCarlo,overthedatabasisofsamplesofφ4andby
generatingsampleswiththehierarchicsamplingalgorithmforeachhierarchicmodel. Forscalarpotentialenergies,
thesufficientstatisticsaredefinedbysecondordermomentsandbythemarginaldistributionoftheφ(n). Appendix
Dcomputesin(84)aKullbackdivergenceerrore(p,p )whichaddsaKullbackdivergenceerrorfromsecondorder
θ
momentsandfrommarginaldistributions.
Figure7(b)givesthevalueofthemomenterrorforhierarchicalmodelscomputedwithHaar,Symlet-4andShannon
wavelets. Thesemodelsarelearnedwithlargeenoughdatasetssothatthevarianceofstatisticalestimatorsbecomes
negligible. TheerrorisminimumforHaarwavelets. ItismuchlargerforaSymlets-4wavelet,whosesupportis7
timeslarger. ForaShannonwavelet,whichhasaslowspatialdecay,theestimationerrorofmarginaldensitiesbecomes
18HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
extremelylarge. Thiserrorcomesfromthemixingproducedbywaveletsofwidesupport. Thecentrallimittheorem
proves that a linear combination of a sufficiently large number of independent variables converges to a Gaussian.
Non-convexitiesthusdisappearfromthemarginalsofwaveletcoefficientsiftheirsupportistoolarge,butitstraceis
presentinhighorderinteractionsofthesewaveletvariables. Thisismuchmoredifficulttoestimate. Thisisalsowhyit
wouldbedifficulttoestimateaφ4modelinaFourierbasis. ThemarginaldistributionofeachFourierbasisisconvex,
whichlooksgoodandsimple,butthemodelestimationthenrequiresincorporatingthehighorderdependenciesof
Fouriercoefficients,torecoverthenon-convexityofthescalarpotential.
Waveletbasesseemtohaveanear-optimaltrade-offtoestimatetheprobabilitydistributionofφ4atthephasetransition
whileavoidingthecriticalslowingdown. Surprisingly,theHaarwaveletcorrespondingtoKadanoffrenormalizing
groupisthebestwaveletchoice. Itminimizesthemodelestimationerrorwhileavoidingthecriticalslowingdown.
5 RobustMultiscaleHighOrderInteractions
Non-Gaussianrandomfieldscanhavelongrangeinteractionsacrossspaceandscales. Inimages, itoftenappears
throughtheexistenceofsharptransitionswhichpropagatealongpiece-wiseregularcurvessuchasfilamentsoredges.
Non-Gaussianpropertiesmaybecapturedbyhigherorderpolynomials,butittypicallyleadstohigh-dimensionalmodels
andhighvarianceestimators. Section5.1introduceslowdimensionalmodelsofmultiscaleprobabilityinteractions.
Itdefinesrobustapproximationsofhighordermodels. Section5.2studiesnumericalapplicationstomodellingand
generationofdarkmatterdensitiesand2Dturbulentvorticities.
5.1 InteractionsoverMultipleHierarchiesbyWaveletScattering
Hierarchicmodelsdecomposepintoacascadeofconditionalprobabilitiesacrossscales,whicharerewrittenasthe
conditionalprobabilitiesofwaveletcoefficients. Inthefollowing,webuildmodelsofsuchconditionalprobabilities,
by computing a complex wavelet transform which explicitly provides a complex phase. Non-Gaussian properties
are captured with a second wavelet transform, on the complex modulus of the first wavelet transform, leading to
low-dimensionalmodelsoflong-rangespatialdependenciesanddependenciesacrossscales.
Complexwavelettransform Tomodeltheprobabilitydistributionofφ conditionedonφ ,wecomputeacomplex
j−1 j
wavelettransformofφ . Thecomplexwaveletcoefficientscalculatedfromφ canalsobewrittenasconvolutions
j−1 j−1
ofφwithcomplexwaveletsψ˜ atscales2j′ ≥2j. TheyhaveQorientationsindexedbyk,sampledonthegridof
j′,k
φ atintervals2j−1
j−1
(cid:16) (cid:17)
φ∗ψ˜ (2j−1n) .
j′,k
n
Letgbethelow-passfilterofthecoarse-grainingoperatorGwhichcomputesφ fromφ.AppendixAshowsthat
j−1
φ∗ψ˜ iscalculatedfromφ withana-trousalgorithm. Itisacascadeofj′−j−1convolutionsofg,followedby
j′,k j−1
convolutionswithafamilyofcomplexband-passfilterg˜=(g˜ ) . Thesefiltersaredilatedbyintroducingzerosin
k k≤Q
betweentheircoefficients. Innumericalapplications,g˜hasQ=4MorletfiltersspecifiedinAppendixA.Ateachscale
2j,theydefine4waveletsψ˜ whosesupportisproportionalto2j. Theyareapproximatelyrotatedby0,π/4,π/2and
j,k
3π/4. Figure8showtherealandimaginarypartsofthewaveletsψ forj =3computedwiththeseMorletfilters
j,k
andtheSymlet-4filtersg. ThesecomplexwaveletshaveaHermitiansymmetryψ˜ (−n)=ψ˜∗ (n). Theirrealand
j,k j,k
imaginarypartsarethereforesymmetricandantisymmetric. Thelowestfrequenciesareretainedbythescalingfilterϕ ,
J
thatwewriteϕ =ψ˜ tosimplifynotations.
J J+1,k
Figure8: Complexwaveletψ˜ computedwitha2DSymlet-4low-passfilterg,and4orientedMorletfilters(g˜ ) ,
j,k k k≤4
atthescale2j = 8. Theupperandlowerrowsshowrespectivelytherealpartandtheimaginarypartsofψ˜ ,for
j,k
k =1,2,3,4.
19HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Scale 2j’
Orientation k’
(a) (b)
Scale 2j’ Scale 2j’
Orientation k’ Orientation k’
(c) (d)
Figure9: (a):φ isavorticityfieldofa2Dturbulence. (b):Complexwavelettransformatscales2j′ ≥2j computed
j−1
fromφ withoutsubsampling. Foregroundandbackgroundimagesshowrespectivelytherealandimaginaryparts
j−1
ofφ∗ψ˜ ,computedwithMorlettypewavelets. Eachrowcorrespondstoascale2j′ ≥2j andeachcolumntothe
j′,k′
Q = 4orientationindicesk′. (c)Modulus|φ∗ψ˜ |ofwaveletcoefficientimages. Theyhavealargeamplitude
j′,k′
atsharptransitions,withlong-rangedependenciesinspaceandacrossscalesandorientations. (d)Theforeground
andbackgroundimagesaretherealandimaginarypartsof|φ∗ψ˜ |∗ψ˜ fordifferentj′ andk′,andforafixed
j′,k′ ℓ,k
ℓ = 3andk = 1. Theseimageslook-alike,whichshowsthatwaveletcoefficientmodulus|φ∗ψ˜ |havestrong
j′,k′
dependenciesacrossscales2j′ andorientationsk′.
Figure9(b)showsthewaveletcoefficientsofavorticityimageof2Dturbulencefield. Thewaveletcoefficientsofsucha
stationaryfieldarealmostnotcorrelatedacrossscales,becausewaveletshaveaFouriertransformlocalizedindifferent
frequencybands. Waveletcoefficientsindifferentfrequencybandshavephaseswhichoscillateatdifferentratesor
alongdifferentorientations,whichcancelcorrelations. However,theamplitudes|φ∗ψ˜ |ofwaveletcoefficientsare
j′,k
stronglycorrelatedacrossscales,asshownbyFigure9(b). Thevorticityfieldhassharpvariationswhichcreatelarge
amplitudewaveletcoefficientsatthesamepositionsovermultiplescalesandorientations.
Wavelet scattering Most wavelet modulus |φ ∗ ψ˜ | have long range spatial dependencies. This long range
j′,k′
dependency is represented by local interactions with a second hierarchic decomposition, computed with a second
wavelettransformof|φ∗ψ˜ |.
j′,k′
Thewaveletcoefficientsφ∗ψ andthesecondwavelettransformof|φ∗ψ |q forq =1orq =2areincorporated
j′,k′ j′,k′
intoavectorofscatteringcoefficients:
(cid:32) (cid:33)
φ∗ψ˜ (2j−1n)
S (φ )=
j′,k′
. (54)
j′ j−1 |φ∗ψ˜ |q∗ψ˜ (2j−1n)
j′,k′ ℓ,k ℓ≥j′,k,k′≤Q,n
20HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Ifq =2thenupperandlowertermsofS arearepolynomialsofdegree1and2ofthevaluesφ(n). Ifq =1theneach
j′
termremainsLipschitz,butthecomplexmodulusmaycreatesingularitieswhencomplexwaveletcoefficientsvanish,
whichisaddressedbyreplacing|z|by(|z|2+ϵ)1/2,forasmallϵ. Scatteringcoefficients|φ∗ψ˜ |q∗ψ˜ areindexed
j′,k′ ℓ,k
bytwoscales2j′ ≥2j and2ℓ ≥2j′ . Thisdoublehierarchymeasuresthevariationsof|φ∗ψ˜ |q overneighborhoods
j′,k′
ofsizesproportionalto2ℓ,inadirectionindexedbyk. Figure9(b)showsthesescatteringcoefficientsforafixed(ℓ,k).
Robustscatteringinteractionenergies Weintroduceahierarchicprobabilitymodelfromscatteringcoefficients. At
thelargestscale2J,theGibbsenergymodelU = θTΦ ofp (φ )isdefinedwithaquadratictermandascalar
θ J J θ J
J J
potential,asin(47). Atscales2j ≥2J,wedefineaGibbsenergymodelU¯ θ¯ ofp(φ¯ j|φ j)frominteractionsofscattering
j
coefficients. LetzTbethecomplexconjugatetransposeofthecomplexvaluedvectorz. Theenergymodelincludes
twopointinteractionsbetweenscatteringcoefficientsS atthescale2j withS for2j′ ≥2j,plusascalarpotential:
j j′
J+1
U¯ θ¯
j
= (cid:88) S jTK j,j′S j′ +V¯ γ¯
j
=θ¯ jTΨ j , (55)
j′=j
where
Ψ =(cid:18) S jS jT ′ (cid:19) and θ¯ =(cid:18) K j,j′ (cid:19) . (56)
j Γ j γ¯
j′≥j j j′≥j
Thedimensionalityofthismodelcanbereducedfromknownsymmetriesofp. Ifpisstationary,thenp (φ )is
j−1 j−1
invarianttotranslation. ThetranslationinvarianceofU¯ θ¯
j
isequivalenttoimposingthateachK j,j′ isaconvolutional
operatoroverthespatialgridofφ . Symmetriestoactionsofothergroupscanbeenforcedwithotherconditions
j−1
discussedinthenextsection.
Ifq =2,thenthecoordinatesofeachS arepolynomialsofdegree1and2ofthevaluesφ (n),soeachinteraction
j′ j−1
term STK S is a a polynomial of degree 4. If q = 1, then the complex wavelet phase is treated similarly but
j j,j′ j′
U¯ θ¯ hasaquadraticgrowthinφasopposedtoadegree4. Itisobtainedbyreplacing|z|2 by|z|. Thepolynomialof
j
degree4ischangedintoapolynomialofdegree2withphaseharmonics,whosepropertiesarestudiedin[ZM21]. It
improvesstatisticalrobustnessbecause|z|isLipschitzasopposedto|z|2. Similarlytoalinearrectifierusedinneural
networks,|z|ishomogeneousandcanbecomputedasalinearcombinationofrectifiers[ZM21]. Modelscomputed
with q = 1 have similar properties to models computed with q = 2, but are often more accurate because of their
statisticalrobustnessstudiedinthenextsection.
Localscatteringspectruminteractions Ahierarchicorganizationaimsatcreatingtheneededlong-rangeinteractions
throughlocalinteractionsinthehierarchy. Similarly,ascatteringspectrumdefineslong-rangemodelsofstationary
fieldswithlocallow-dimensionalinteractionsamongscatteringcoefficients.
Ascatteringspectruminteractionmodelisconstructedbyeliminatingtheinteractiontermsin(55)whichareapriori
negligible. Forstationaryprobabilities,theinteractionmatricesK areconvolutionoperators. ImagesofS are
j,j′ j′
complexwaveletcoefficientcomputedwithψ˜ orwithψ˜ for2ℓ ≥2j′ . TwoimagesofS andS haveanenergy
j′,k′ ℓ,k j j′
mostlyconcentratedindisjointfrequencydomainsiftheyarecomputedwithdifferentwavelets. Theirinteractionthus
hasanegligiblecontributiontotheenergyU¯ θ¯
j
becauseeachK j,j′ in(55)isconvolutional.
TwoimagesofS andS computedwithasameψ˜ haveapriorianon-zerointeraction. Ascatteringspectrummodel
j j′ ℓ,k
furtherassumesthatwaveletcoefficientinteractionsarelocalinspace. Thisassumptionisvalidformultiscalestationary
processeswhichdonotproduceoscillatoryphenomena. Ascatteringspectrummodelkeepsonlytheinteractionof
pairsofscatteringcoefficientsinS andS whichhavethesamespatialposition.
j j′
Theresultingscatteringspectrummodelassumesthatinteractionsarelocalinspaceandoverthescatteringscales.
However, it defines long-range interactions in space and across the wavelet coefficients of the original image φ.
Appendix B shows that this scattering spectrum model reduces Ψ to a vector of dimension O(log2d) if φ has a
j
dimensiond. ThefullhierarchicenergymodelU θ aggregatestheinteractionmodelsU¯ θ¯ atallscalesd≥2j ≥1. Itis
j
thusdefinedbyacouplingvectorθofdimensionO(log3d).
21HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
StationaryScatteringEnergyModel Wegiveananalyticalformulationofthestationaryscatteringenergymodel
U θ obtainedfrominteractionenergymodelsU¯ θ¯ atallscales2j. Itiscalculatedwithhierarchicstationarypotentials
j
definedfromthescatteringinteractionenergiesΨ in(55). Letuswritethecomplexwavelettransformofφ
j
(cid:16) (cid:17)
Wφ= φ∗ψ˜ (n) , (57)
j,k
0<j≤J+1,k,n
This wavelet transform without subsampling is computed with the a-trous algorithm of Appendix A. From φ =
j
φ∗ϕ (2jn),AppendixAshowsthatthea-trousalgorithmcomputeswaveletcoefficientsofφatscales2J ≥2j′ ≥2j
j
subsampledatintervals2j. Wewrite
(cid:32) (cid:33)
φ∗ϕ (2jn)
R(φ )= j .
j |φ∗ψ˜ (2jn)|q
j′,k′
j′≥j,k′,n
Iff =(f ) isafamilyofrealvaluedfields,wealsowritef ∗fT =(f ∗fT) withfT(n)=f (−n).
k k k k′ k,k′ k k
Theorem5.1. Thepotentials
(cid:18) R(φ )∗R(φ )T (cid:19)
Φ (φ )= j j (58)
j j Γ(φ ∗ϕ )
j ℓ J−j≥ℓ≥0
arestationaryhierarchicwithinteractionsΨ definedin(55). RegressingeachfreeenergyF overΦ definesafine
j j j
scaleGibbsstationarymodel
J
U (φ)=
1 φTKφ+(cid:88)
V (φ)+V (φ), (59)
θ 2 j int
j=0
withV (φ)=γTΓ(φ∗ϕ )and
j j j
1
V (φ)=φTL(|Wφ|q)+ (|Wφ|q)TM(|Wφ|q), (60)
int 2
whereγ andtheconvolutionoperators(K,L,M)arecomputedwithalinearcouplingflowequation.
j
TheproofisinAppendixE.4. Whenq = 2, theinteractionpotentialisthusasumofthirdorderandfourthorder
polynomialswhichcaptureinteractionsbetweenwaveletcoefficientsatthescale2j andlargerscales. Settingq =1
givesarobustapproximation,wherealltermshaveaquadraticgrowth. TheconvolutionalmatricesLandM have
non-localkernelsinspace. Alocalscatteringspectrummodelonlykeepsinteractioncoefficientsbetweenpairsof
scatteringcoefficientscomputedwithasamewavelet,atasameposition. ItimpliesthatK =WTK′W,L=WTL′W
andM = WTM′W,whereK′ isdiagonalandL′ andM′ areblockdiagonalconvolutionalmatrix,withatotalof
O(log3d)non-zerointeractioncoefficients.
5.2 NumericalApplicationstoDarkMatterandTurbulenceFields
WeevaluatetheprecisionofhierarchicalwaveletscatteringmodelsU fortwotypesofnon-Gaussianphysicalfields
θ
havingcoherentgeometricstructures. WecomputetheLangevinnormalizedauto-correlationrelaxationtimeasaproxy
toevaluatetheevolutionofnormalizedlog-Sobolevconstants,afterrenormalization.
Numericalexperimentsarecarriedon2Dfieldsofdarkmatterimages,whicharethelogarithmof2Dslicesofsimulated
3Dlarge-scaledistributionofdarkmatterintheUniverse[VNHM+20]showninFigure10(a). Wealsomodel2D
turbulencevorticityfieldsofincompressible2Dfluidsstirredatthescalearound32pixels,atafixedtime,simulated
from2DNavier-Stokesequations[SZFA06],showninFigure10(a). Thetimeevolutionof2Dturbulenceisaninverse
cascadewhichtransferstheenergytowardsthelowestscales[Kra67]. The2DNavier-Stokesimulationinitializedwith
aGaussianwhitenoiseatt = 0definesatransportofthisGaussianwhitedistributionintoastationarydistribution
atafixedt. Thevorticityfieldisstationaryinspaceatafixedtime,butitdoescomefromasystematequilibriumin
time. ThereisnoclosedformulaforHamiltoniansofsuchoutofequilibriumsystems,exceptinparticular1Dcases
[DLS02,BDSG+15]. Bothdatasets(100and3000independentrealizations)haveperiodicboundaryconditionsandare
down-sampledtod=1282pixels. Theyareaugmentedwithrotationsandspatialsymmetriesbecausetheirprobability
distributionisisotropic.
22HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Original Scalar Potentials Scattering q=1 Scattering q=2
2.0
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
2.0
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
(a) (b) (c) (d)
Figure10: (a): Toprow: 2Dslideofa3Ddark-mattersdensitysimulation[VNHM+20]. Bottomrow: vorticityfields
ofa2Dperiodicturbulentflowatafixedtimet,generatednumericallywiththe2DNavierStokesequationfroman
initialGaussianwhitenoise[SZFA06]. (b): Samplesofthehierarchicalscalarpotentialmodeldefinedin(49). (c):
Samplesofthehierarchicwaveletscatteringmodel,withanexponentq =1. (d): Sameas(c)withanexponentq =2.
Hierarchicmodelgenerations Figure10(b,c,d)showsimagesgeneratedfromhierarchicalmodels,respectivelywith
ascalarpotential,robustwaveletscatteringinteractionswithq = 1andhigherorderwaveletscatteringwithq = 2.
Overallscales,thescalarpotentialmodelandthewaveletscatteringmodelshaverespectivelyabout300and2500
couplingparameters. Thereisnoscalarpotentialterminthescatteringmodels.
GenerationsfromscalarpotentialmodelsinFigure10(b)donotrestorerandomgeometricstructuresappearinginthe
originalfields. Fordarkmatterfields,thewaveletscatteringmodelsinFigure10(c,d)reproducewellthevisualtexture
oftheseimages. Forthevorticityfieldsof2Dturbulence,eddiesandvorticityflowsarewellreproducedonlywithq =1
butaredegradedforq =2. Indeed,asshownby(12)andinAppendixC.1,computingthecouplingflowparametersθ¯
j
ofthehierarchicalmodelrequiresinvertingamatrixofempiricalmomentsestimatedonthetrainingdataset. Higher
orderpolynomialsamplifyoutliers. Itincreasestheestimationvarianceofhighordermoments,andthusintroduces
moreerrors. Asexpected,thescatteringmodelwithq =1ismorerobustthanthehighordermodelwithq =2. For
turbulenceimages,estimationerrorscanintroduceadivergenceoftheLangevindiffusionatthefinestscale,wherethe
spectrumhasafastdecay. Thisisavoidedbyaddingasmallconfinementtermforlargeamplitudecoefficients. Itadds
ϵD jφ¯4 j totheenergyU¯ θ¯ . Thevalueofϵisabout10timeslargerforq =2thanforq =1,whichaffectsthegenerated
j
imagequality.
Langevinrelaxationtime Therenormalizationaimsatreducingtheamplitudeofnormalizedlog-Sobolevconstantto
estimateamodelbyscorediffusionwithasfewsamplesaspossibleandtoreducethecomputationalcomplexityof
theLangevindiffusion. Anecessaryconditionistocontrolthelargesteigenvalueofthecovarianceanditscondition
number. AsexplainedinSection3.6,ahierarchicalmodelmustusewaveletshavingenoughvanishingmomentsand
whicharesufficientlyregular. ForDarkmatterimagesandturbulencefields,werespectivelyuseSymlet-3andSymlet-4
wavelets. Thesedarkmatterand2Dturbulenceimageshaveapowerspectrumwhichdecaysfasterthanapowerlawat
thehighestfrequencies. Torenormalizethesmallesteigenvaluesofthecovarianceathighfrequencies,Section3.6also
explainsthatφ¯ canberepresentedinawaveletpacketbasishavingasufficientfrequencyresolution. Thewavelet
j
packetfiltering(22)reducesthewidthofwaveletfrequencysupportsbyafactor2a j. Innumericalexperiments,weset
a =min(a,J−j)andweadjusta. Fora=0,thewavelet-packetbasisisawaveletbasis. Choosingawaveletpacket
j
basisasopposedtoawaveletbasisdoesnotmodifythehierarchicenergymodel. Itonlymodifiesthecoordinatesystem
representingφ¯ andhencetherenormalizationwhichmodifiesthelog-Sobolevconstant.
j
Figure11givestheevolutionoftheLangevinnormalizedauto-correlationrelaxationtimeτ ofthehierarchicalmodel
in(53),asafunctionofthesystemsized. Fora=0correspondingtowavelets,therelaxationtimeτ increaseswith
23HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
102
a=0 a=0
a=1 a=1
a=2 a=2
a=3 a=3
101
100
103 104
d
Figure11: Langevinnormalizedauto-correlationrelaxationtime(53)forscatteringhierarchicalmodelscomputedin
waveletorwaveletpacketbases,witha =min(a,J −j),asafunctionoftheimagesized. Langevinrelaxationtime
j
fordarkmatter,(computedwithq =2,inaSymlet-3basis)areinblueandfordark-matterfields(computedwithq =1,
inaSymlet-4basis)inred. IncreasingthewaveletpacketFourierresolutionwithaslightlyreducestherelaxationtime,
butitdoesnotavoidanexponentialgrowthwithd.
thesystemsized,bothfordark-matterandturbulencefields. Thisisdifferentfromtherelaxationtimeofhierarchical
modelsofφ4showninFigure7(a),whichdoesnotgrowwithd. However,afterrenormalization,therelaxationtimefor
dark-matterandturbulenceis3ordersofmagnitudebelowtheoneforφ4withoutanyrenormalization. Itshowsthat
thehierarchicalrenormalizationacceleratesconsiderablythesampling,althoughitstilldegradeswithd.
IncreasingthefrequencyresolutionofwaveletpacketswithahasasmalleffectontheLangevinrelaxationtimegrowth
in Figure 11. The remaining growth is due to the non-Gaussian multiscale behavior of the model. It is produced
by scaling properties of third and fourth order energy components, which are different from second order scaling
propertiesofthecovariance,andarethereforenotcompensatedbyarenormalizationbasedonthecovariance. Such
phenomenaappearinmultifractalrandomprocesses[Jaf04,AGV13]. ThescatteringmodelgeneratedinFigure10(b,c)
arecalculatedbyrenormalizingwaveletcoefficientsinawaveletpacketbasis,witha=3forturbulenceimagesand
witha=2fordarkmatterfields.
Hierarchicmodelprecision Wehavenoenergymodelforthedarkmatterandturbulencefieldsusedinnumerical
experiments. Themodelprecisionisthusevaluatednumericallyoverafamilyofstandardmomentsusedinstatisticsand
physics. Wetestthedistributionofpoint-wisemarginals,theFourierspectrum(secondordermoments),thebi-spectrum
(thirdordermoments)alsocalculatedinthefrequencydomain,andstructurefunctions. Eachmomentisestimatedwith
aMonteCarlosumovermtrainingsamplesofp. Thesemomentsarecomparedwithmomentsofhierarchicalmodels,
alsoestimatedwithaMonteCarlosumoverenoughmodelsamplesgeneratedbyMALAsampling.
Figure12(a,b)showthatscalarpotentialmodelsgeneratestationaryfieldsφ,whereφ(n)haveamarginaldistribution
nearly equal to the marginals of the original fields, since the model is optimized from these marginals. The same
resultisobtainedforthewaveletscatteringmodels,althoughtheydonotincorporateascalarpotentialwhichimposes
thesemarginalmoments. Allmodelsreproducewellthepowerspectrum,whichisonlyspecifiedinthesemodelsbya
reduceddiagonalmatrixwithlessthanlogdwaveletsecondordermoments.
Thebi-spectrumisathird-ordermomentscomputedoverFouriercoefficients,whichiszeroforaGaussianprocess.
Itisalsozeroifp(φ) = p(−φ)whichisthecaseforthe2Dturbulencevorticity. Itisthusonlycomputedforthe
dark-matterdensityimages. Thebi-spectrumcalculationisexplainedinAppendixF.2. Figure12(d)showsthatthe
bi-spectrumiswellreproducedbyawaveletscatteringmodelwithq =2,whichincorporatesthirdorderpolynomial
terms. Itisalsowellreproducedwithq =1. Thisrobustmodeldoesnotincludethirdordertermsbutalowerorder
equivalenttermwhichisalsoantisymmetric. Ontheopposite,thebi-spectrumofthescalarpotentialmodelisquite
differentfromthebi-spectrumoftheoriginaldark-matterfield.
Kolmogorovstructurefunctions[kol41]aremomentsofordermoverthefieldofincrements,indexedbythespatiallag
δ
SF (δ)=E (cid:0) |φ(n)−φ(n−δ)|m(cid:1) . (61)
m p
Figures12(e,f)plotthestructurefunctionsrespectivelyform=1andm=4since2ndand3rdordermomentshave
alreadybeenevaluated. Theonlymodelprovidinganaccurateapproximationbothfortheturbulenceanddark-matter
24HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
0.7
A B 101 A
10 1 10 1 0.6 B
10 2 10 2 100 0.5
Original Original Original Original
A
10 3 q=1 10 3 q=1 q=1 0.4 q=1
10 1
q=2 q=2 q=2 q=2
10 4 10 4 B 0.3
Scalar Scalar Scalar Scalar
10 2 0.2
0 5 -5 0 5 100 101 102 100 101
| |
(a) (b) (c) (d)
0.7 5
A
0.08 Original A
q=2
0.06 0.6 4
q=1
0.04 Scalar B
0.5 3
A B
0.02
0.4 2
0.00 Original Original
q=2 q=2
-0.02 0.3 q=1 1 q=1
-0.04 Scalar Scalar
0.2 0
0 20 40 60 80 100 101 100 101
(e) (f) (g)
Figure12: Eachgraphshowsaspecificfamilyofmomentsestimatedonthetrainingdata(inblack)andonsamplesof
ahierarchicalmodel(waveletscatteringwithq = 1inred,withq = 2ingreen,andscalarpotentialmodelinblue).
Modelsarelabeled(A)fordark-matterand(B)for2Dturbulence. Grayzonesrepresenttheestimationvarianceof
theseshigherordermomentsoverthetrainingdataset. (a,b): marginalprobabilitydensitiesofφ(n). (c): covariance
eigenvalues(power-spectrum). (d): Structurefunctionoforderm=1asafunctionofδ. (e): thirdorderbi-spectrum
moments,orderedfromlowtohighfrequencies. Notshownforthe2Dturbulence(B),becausetheyallvanish. (f):
Structurefunctionoforderm=4. (g): Structurefunctionoforderm=6.
fieldsistherobustwaveletscatteringmodelforq =1. Theerrorofthewavelethigh-ordermodelforq =2overthe
turbulencefieldisduetothelargerregularizationneededtoconfinetheLangevindiffusion. Thereproductionofhigher
ordermomentsslowlydegradewhenincreasingtheorderofthemoments. Figure12(g)showsthatnoneofthemodel
faithfullyreproducesthestructurefunctionoforder6ondarkmatter,butitiswellreproducedontheturbulencewhich
ismoreGaussian.
Two-point interaction model Since the wavelet scattering model have no scalar potential, Theorem 5.1 proves
thatthestationarymodelischaracterizedby3convolutionaloperators: K,L,M in(59). Theyarecomputedfrom
thelearnedinteractionparametersθ¯ ateachscale,withthecouplingflowequation(41). Figure13(a,b)showsthe
j
convolutionkernelK forturbulenceanddark-matterdatasets. Bothkernelsarelocalinspaceandnearlyisotropic,
whichisnotimposedbythemodel. TheyresembletoaLaplacian. Figure13(c)showstheirFouriertransformas
a function of the frequency amplitude |ω|. The estimated kernel for 2D turbulence has higher eigenvalues at high
frequenciesthantheonefordarkmatter,whatiscoherentwiththefasterdecreaseofitspowerspectrum.
6 Conclusion
Hierarchicmodelsprovideaninverserenormalizationgroupdecompositionofprobabilitydistributionsintoconditional
probabilities in wavelet bases. The renormalization partly avoids the bad conditioning of learning and sampling
algorithms,byreducinglog-Sobolevconstants. Fortheφ4model,weconjecturethatiteliminatesthecriticalslowing
down,asshownbynumericalexperiments.
25HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
3 1.5 3 6 0.8 2d Turbulence
2 2 Dark Matter
1.0
0.6
1 1 4
0 0.5 0 0.4
2
-1 -1
0.0 0.2
-2 -2
0
-3 -0.5 -3 0.0 | |
-3 -2 -1 0 1 2 3 -3 -2 -1 0 1 2 3 0 1 2 3
(a) (b) (c)
Figure13: Estimated2-pointconvolutionalkernelK ofU definedineq.(59),forq =1. (a): kernelfordarkmatter
θ
images. (b): kernelfor2Dturbulence. Theyarelocalandnearlyrotationinvariant. (c): Fouriertransformofeachkernel
asafunctionof|ω|.
For multiscale non-Gaussian processes such as dark matter distribution or 2D turbulence, we introduced a low-
dimensionalwaveletscatteringmodel,basedonrobustmultiscalehighorderinteractions. Numericaltestsshowthat
theycanprovideanaccuratemodelofcomplexfieldsbeyondscalarpotentialmodels,butweremainfarfromasatisfying
modelofturbulence. Morecomplexstructuresappearin3Dwheretheenergycascadeisnotinverted,andwedonot
considerthetimeevolution.
Numericalexperimentsshowthatrobustmultiscalescatteringmodelsimprovetheestimationbyreducingtheamplitude
growthofhighorderpolynomials. Asopposedtoφ4,forturbulenceanddark-matterfields,therenormalizationreduces
butdoesnotavoidtheexponentialincreaseoflog-Sobolevconstantswiththefielddimension. Moreover,estimation
errorscancreateadivergenceofLangevindiffusions,ifnotregularized.
RegularizationissuescanbeaddressedbyreplacingtheLangevindiffusionbyascorediffusion[SSK+21,RBL+22]for
eachp¯ θ¯ (φ¯ j|φ j),asin[GCDBM22]. Anintegratedrenormalizationgroupapproachofscorediffusionandmultiscale
j
coarsegrainingschemesisproposedin[CR23]. Thisisalsomotivatedbythespectacularresultsofscorediffusion
generations with deep neural networks, and particularly with U-Nets [RFB15] which integrate multiscale image
decompositions. Understandingthecorrespondencebetweenthesemultiscaledeepnetworkdecompositionsandrobust
highorderwaveletscatteringenergiesisyetanotherchallengingquestion.
Acknowledgments
This work was supported by a grant from the PRAIRIE 3IA Institute of the French ANR-19-P3IA-0001 program.
WethankRudyMorel,ErwanAllysandMisakiOzawaforprovidingthetrainingdatasets.WealsothankNathanae¨l
Cuvelle-MagarandJean-BaptisteHimbertforfeedbackonthemanuscript.
A WaveletTransforms
Wereviewthepropertiesofrealandcomplexwavelettransformscomputedbyiteratingoverlow-passandband-pass
filters,inoneandtwodimensions.
Conjugatemirrorfilters Orthogonalwaveletsarecomputedwithconjugatemirrorfilters. Indimensionr =1,apair
ofconjugatemirrorfilter(g,g¯)includesalow-passfiltergwhoseFouriertransformgˆ(ω)=(cid:80) g(n)e−inω satisfies
n
√
|gˆ(ω)|2+|gˆ(ω+π)|2 =2 and gˆ(0)= 2. (62)
Thesecondfilterg¯hasasinglehigh-passfilterdefinedbyg¯(n)=(−1)1−ng(1−n). Onecanverifythattheresulting
convolutionandsubsamplingoperators
Gφ(n)=φ∗g(2n) and G¯φ(n)=φ∗g¯(2n) (63)
(cid:16) (cid:17)
defineanorthognalmatrix G [Mal09]. Allconvolutionsarecomputedwithperiodicboundaryconditions.
G¯
Forimages(r =2),two-dimensionalconjugatemirrorfiltersarecomputedasseparableproductsofone-dimensional
conjugatemirrorfilters(g,g¯)[Mal09]. Forn = (n ,n )thereisasingletwo-dimensionalseparablelow-passfilter
1 2
g(n ,n )=g(n )g(n )and3high-passfiltersing¯=(g¯ ) ,with
1 2 1 2 k 1≤k≤3
g¯ (n ,n )=g(n )g¯(n ), g¯ (n ,n )=g¯(n )g(n ), g¯ (n ,n )=g¯(n )g¯(n ).
1 1 2 1 2 2 1 2 1 2 3 1 2 1 2
26HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
TheconvolutionaloperatorGandG¯ intwodimensionsarestilldefinedby(63)withthesetwo-dimensionalseparable
filters,andG¯φhas3outputimages.
A-trousfilters Averagedcoefficientsandwaveletcoefficientsareiterativelycomputedforj >0with
φ (n)=φ ∗g(2n) and φ¯ =φ ∗g¯(2n). (64)
j j−1 j j−1
These coefficients can be written as convolutions of the input φ = φ with a scaling filter ϕ and wavelets ψ
0 j j,k
subsampledby2j:
φ
=(cid:0)
φ∗ϕ
(2jn)(cid:1)
and φ¯
=(cid:0)
φ∗ψ
(2jn)(cid:1)
. (65)
j j n j j,k k,n
Thesescalingfiltersandwaveletssatisfyrecursiveequationscomputedwith”a-trous”filtersresultingfromthecascaded
subsampling. Inonedimension,foranyfilterhwewriteh thea-trousfiltersuchthath (2jn)=h(n)andh (n)=0
j j j
if2−jnisnotanintegerinonedimensionordoesnotbelongtothetwo-dimensionalgridN2intwodimensions. The
a-trousfilterh isadilationofhby2j,bysettingintermediatecoefficientstozero. Onecanderivefrom(64)that
j
ϕ =ϕ ∗g and ψ =ϕ ∗g¯ . (66)
j j−1 j−1 j,k j−1 j−1,k
Scalingfiltersandwaveletsarethusobtainedwithacascadeofa-trousfilters. Onecanverifythat
φ ∗ϕ (n)=φ ∗ϕ (2n), (67)
j ℓ j−1 ℓ+1
and
φ ∗ψ (n)=φ ∗ψ (2n). (68)
j ℓ j−1 ℓ+1
Asymptoticwaveletbases Whenj goesto∞,forappropriatefiltersg¯andlow-passfiltersg,onecanprove[Dau92]
thatϕ andψ convergetoϕ(x)andwaveletsψ (x),uptoadilationby2j.Theselimitfunctionsaresquareintegrable,
j j,k k
(cid:82) |ϕ(x)|2dx<∞and(cid:82) |ψ (x)|2dx<∞. In1dimension,conjugatemirrorfiltersdefineascalingfunctionϕ(x)and
k
asingleasymptoticwaveletψ(x)whoseFouriertransformsϕˆ(ω)andψˆ(ω)satisfy
ψˆ(ω)=
√1
gˆ¯(2−1ω)ϕˆ(2−1ω) with
ϕˆ(ω)=+ (cid:89)∞ gˆ(2 √−qω)
.
2 2
q=1
Ifweimposethatgˆ(ω)>0forω ∈[−π/2,π/2],thenonecanprove[Mal09]that{2−j/2ψ(2−jx−n)} n∈Z,j∈Zisan
orthonormalbasisofL2(R). Ifwelimitthemaximumscaleto1,withperiodicboundaryconditions,weobtainan
orthonormalbasisofL2([0,1]2). Waveletswithnon-periodicboundaryconditionsmayalsobedesigned[Dau92].
AHaarfilteristheconjugatemirrorfilterhavingaminimumsizespatialsupport: g(n)=1ifn=0,1andg(n)=0
otherwise. ItdefinestheHaarwaveletψshowninFigure14(a). TheShannonlow-passfilterhasaFouriertransform
havingaminimumsizesupport: gˆ=1 . ItdefinesaShannonwavelet,showninfigure14(c). ADaubechies
[−π/2,π/2]
Symletfiltergoforderm[Dau92]hasasupportofsize2m−1anddefinesacompactlysupportedwavelethavingm
vanishingmoments:
(cid:90)
∀0≤k <m, xkψ(x)dx=0.
Theseintegralsimplythatψˆanditsm−1firstderivativesvanishatthefrequencyω = 0andhencethat|ψˆ(ω)| =
O(|ω|m). ASymletfilterisassymmetricaspossible[Dau92]. Theregularityofψalsoincreaseswithm. TheSymlet-4
waveletisshowninfigure14(b).
ComplexMorletfilters Complexwaveletsψ˜ aredefinedbyreplacingtherealfiltersg¯= (g¯ ) byafamilyof
j,k k k
complexfiltersg˜=(g˜ ) . Similarlyto(66)
k k
ϕ =ϕ ∗g and ψ˜ =ϕ ∗g˜ , (69)
j j−1 j−1 j,k j−1 j−1,k
whereg˜ isthea-trousfilterdefinedfromg˜ .
j,k k
InnumericalapplicationsweuseQ=4complexMorletfiltersg˜={g˜ } definedby
k k≤Q
g˜ (n ,n )=γe−η(n2 1+n2 2)(cid:0) eiξ(n 1cosα k+n 2sinα k)−β (cid:1) , (70)
k 1 2 k
(cid:80)
α =kπ/Qandeachβ isadjustedsothat g˜ (n ,n )=0.Wechooseη =1.67andξ =π. Figure8shows
k k n ,n k 1 2
1 2
thetwo-dimensionalcomplexwaveletsψ˜ ,computedwiththe2Dseparablelow-passSymlet-4conjugatemirrorfilter
j,k
gandthesecomplexMorletfiltersg˜.
Attheverylargescalesclosetotheimagesize,toavoidissuescreatedbyperiodicboundaryconditions,thefiltersg˜ are
k
modified. Theyareconstructedfromtheanalyticpartoftheconjugatefilters{g¯ } associatedtog. Computingthe
k k≤3
analyticpartamountstorestricttheFouriertransformoverhalfoftheFourierplane[Mal09],whichdefinesacomplex
filter. Thethirddiagonalfilterisdividedintotwoanalyticfilterslocatedinthetwodiagonaldirections.
27HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Haar Symlet Shannon
1 1 1
0 0 0
-1 -1 -1
-5 0 5 -5 0 5 -5 0 5
1 1 1
0 0 0
-25 0 25 -25 0 25 -25 0 25
(a) (b) (c)
Figure14: Toprow: Graphsofdifferentone-dimensionalwaveletsψ(t). Bottomrow: GraphsoftheirFouriertransform
modulus|ψˆ(ω)|. (a)Haar(1vanishingmoment),(b)DaubechiesSymlet(4vanishingmoments),(c)ShannonWavelet.
A-trouswavelettransform Foranyj >0,φ (n)=φ∗ϕ (2jn). Moreover,(69)impliesthat,forj ≤j′,
j j
ψ˜ =ϕ ∗g ∗...∗g ∗g˜ .
j′,k j−1 j−1 j′−2 j′−1
Onecanthusverifythatφ∗ψ˜ (2j−1n)iscalculatedfromφ byana-trousalgorithmwhichcascadesconvolutions
j′,k j−1
withdilatedlow-passfiltersgandthecomplexMorletwaveletfilterg˜
k
φ∗ψ˜ (2j−1n)=φ ∗g∗...∗g ∗g˜ (n). (71)
j′,k j−1 j′−j−1 j′−j,k
ThecomplexwavelettransformW in(57)iscomputedbyconvolutionswithϕ andψ˜ withoutsubsampling. Since
j j
thesefiltersarecascadeofa-trousfiltersg andg¯ in(69),theseconvolutionscanbecalculatedasacascadeofa-trous
j j
filterings,fromφ=φ :
0
φ∗ψ˜ (n)=φ∗g∗..∗g ∗g˜ (n). (72)
j,k j−2 j−1
B ScatteringSpectrumInteractions
ThisappendixspecifiesscatteringspectruminteractionmatricesK ,forthewaveletscatteringmodel(55),with
j,j′
S (φ )=(cid:0) φ∗ψ˜ (2j−1n), |φ∗ψ˜ |q∗ψ˜ (2j−1n)(cid:1) .
j′ j−1 j′,k j′,k′ ℓ,k k,k′≤Q,ℓ≥j′,n
AscatteringspectrummodelforstationaryprocessesretainsinteractionsbetweencoefficientsofS andS in(55)
j j′
computedwiththesamewaveletsatasamespatialposition. ThepairsofcoefficientsofS andS whichinteractare
j j′
thus
φ∗ψ˜ (2j−1n) and φ∗ψ˜ (2j′−1n) forj′ =j,1≤k ≤Q, (73)
j,k j′,k
|φ∗ψ˜ |q∗ψ˜ (2j−1n) and φ∗ψ˜ (2j−1n) forj′ =ℓ,1≤k′,k ≤Q, (74)
j,k′ ℓ,k j′,k
|φ∗ψ˜ |q∗ψ˜ (2j−1n) and |φ∗ψ˜ |q∗ψ (2j−1) forℓ≥j′ ≥j,1≤k,k′,k′′ ≤Q. (75)
j,k′ ℓ,k j′,k′′ ℓ,k
For translation invariant energies, the translation invariant version of the potential Ψ in (56) has four interaction
j
potentials:
(cid:16) (cid:17)
Ψ = Γ, Λ , Λ , Λ . (76)
j 2,j 3,j 4,j
ThepotentialvectorΓdefinedin(48)providesanapproximationofscalarpotentials. Fortheother3potentials,we
onlykeepinteractionsbetweencoefficientscomputedwithasamewaveletatasameposition. Theinteractions(73)
givetheaverageofsquaredwaveletcoefficientsineachdirectionk:
Λ (φ
)=(cid:16)(cid:88)
|φ∗ψ˜
(2j−1n)|2(cid:17)
. (77)
2,j j−1 j,k
k≤Q
n
28
)t(
)
(HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Theyprovideanestimationofthepowerspectrumoverthefrequencysupportwhereψˆ isconcentrated. Forprocesses
j,k
withpowerspectrumsthatdecreasefasterthanapowerlaw,weaswellincludeinΛ shiftedtwopointsinteractions,
2,j
oftheform(cid:80) φ∗ψ˜ (2j−1n)φ∗ψ˜∗ (2j−1(n+τ)),withsmallτ.
n j,k j,k
Theinteractionterms(74)capturetheinteractionbetweenwaveletcoefficientsatthescale2j′
andscatteringcoefficients
atasamescale2ℓ =2j′
Λ (φ
)=(cid:16)(cid:88)
|φ∗ψ |q∗ψ (2j−1n)φ∗ψ∗
(2j−1n)(cid:17)
. (78)
3,j j−1 j,m j′,k j′,k k,m≤Q,j′≥j
n
Itisantisymmetricinφanditcapturesphasealignmentpropertiesacrossscales. Ifq = 2thentheyarethirdorder
polynomial moments in φ. When q = 1 these these coefficients capture similar properties [CMA+23]. The last
interactionterms(75)givetheinteractionsbetweenwaveletmoduluscoefficientsatdifferentwaveletscales2j and2j′
butatthesamescatteringscales2ℓ
Λ (φ
)=(cid:16)(cid:88)
|φ∗ψ˜ |q∗ψ˜ (2j−1n)|φ∗ψ˜ |q∗ψ˜∗
(2j−1n)(cid:17)
. (79)
4,j j−1 j,k′ ℓ,k j′,k′′ ℓ,k k,k′,k′′≤Q,ℓ≥j′≥j
n
Ifq =2thentheydefinefourthordermoments. Whenq =1theyhavesimilarnumericalproperties[CMA+23]. The
largestnumberofcoefficientsiswithinΛ . ThedimensionofΨ isoftheorderofQ3(j−J)2.
4,j j
Furtherdimensionalityreduction Ifφhasaprobabilitydistributionwhichisinvarianttorotations,thentheenergy
remainsinvarianttotheflippingoperatorwhichtransformsφ(n)intoφ(−n). Sinceψ˜ (−n) = ψ˜∗ (n),onecan
j,k j,k
verify,similarlyto[MZR20,MRL+23],thattheimaginarypartsofΛ andΛ changesignwhenφ(n)istransformed
3,j 4,j
intoφ(−n). ItresultsthattheinteractioncoefficientsoftheenergyU overtheseimaginarypartsarezero. Weimpose
θ
thispropertyinallnumericalexamplesshowninthispaperbyeliminatingtheimaginarypartsofΛ andΛ from
3,j 4,j
Ψ . Wealsopointoutthatforasymmetricalprocess,suchthatφand−φhavethesamedistribution,onecanaswell
j
discardΛ .
3,j
C EstimationofConditionalEnergyparameters
C.1 Interactionenergyestimationbyscorematching
InsteadofminimizingdirectlyeachtermE p j(cid:0) KL(p¯ j,p¯ θ¯ j)(cid:1) ,andapplyingthealgorithmin(10),whichrequiresheavy
calculations,weuseascorematchingalgorithmwhichminimizesarelativeFisherinformation. Itiscalculatedwitha
gradientrelativelytoφ¯ ,whicheliminatesthefreeenergyF (φ ). ThecorrespondingFisherinformationisaveraged
j j j
withp :
j
E p j(cid:0) I(p¯ θ¯ j,p¯ j)(cid:1) =E p jE p¯ j(cid:16) ∥∇ φ¯ jlogp¯ j(φ¯ j|φ j)−∇ φ¯ jlogp¯ θ¯ j(φ¯ j|φ j)∥2(cid:17) .
Accordingto[HD05]andsimilarlyto(11),since∇ φ¯ jlogp¯ θ¯
j
=θ¯ jT∇Ψ j,onecanverifythatitisequivalenttominimize
(cid:16)1 (cid:17)
ℓ(θ¯ )=E ∥θ¯T∇ Ψ (φ )∥2−θ¯T∆ Ψ (φ ) . (80)
j p j−1 2 j φ¯ j j j−1 j φ¯ j j j−1
Thiscalculationcanbedoneinparallelforallj.
Likeeq.(12),aclosedformfortheminimizingθ¯ isgivenby
j
θ¯ =M¯−1E (cid:0) ∆ Ψ (φ )(cid:1) with M¯ =E (cid:0) ∇ Ψ (φ )∇ Ψ (φ )T(cid:1) (81)
j j p φ¯ j j−1 j p φ¯ j j−1 φ¯ j j−1
j−1 j j−1 j j
Forconsidereddatasets,withthepotentialΨ fromeq.(55),(80)isanill-conditionedquadraticlearningproblem. We
j
computethematrixM¯ fromeq.(81),andpreconditionθ,bydefiningθ˜ =(M¯ +ϵId)1/2θ¯ ,whoseoptimalvaluecan
j j j j
becomputedbyminimizingthequadraticloss
ℓ˜(θ˜)= 1 θ˜ θ˜T−θ˜TE (cid:0) (M¯ +ϵId)−1/2T∆ Ψ (φ )(cid:1) ,
2 j j j p j−1 j φ¯ j j j−1
whichhasaconditionnumberof1. Thislossfunctionisminimizedusingasinglebatchgradientdescent. Thesame
procedureappliestoθ ,atthecoarsestscale,forthequadraticlossdefinedineqs.(11)and(12). Duetothefinitesize
J
ofthedatasets,theexpectanciesarereplacedwiththeirempiricalestimations. Forapplicationsinthispaper,weused,
forϵ,valuesnotbiggerthan10%oftheeigenvaluesofM¯ .
j
29HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
C.2 Freeenergycalculation
ToderivetheGibbsenergyU (φ)inequation(30),wedefineandoptimizealinearapproximationF =αTΦ ofthe
θ α j j
j
freeenergyF j definedbythenormalizationintegral(29)ofp¯ θ¯ . Takingthederivativewithrespecttoφ j in(29)gives
j−1
∇ F (φ )−E (cid:0) θ¯T∇ Ψ (φ )(cid:1) =0. (82)
φ j j j p¯ θ¯ j(φ¯ j|φ j) j φ j j j−1
Using the previous equation, it can be proven that the free energy F is a minimizer of the quadratic function
j
f (cid:55)→E
(cid:0)(cid:13)
(cid:13)∇ f(φ )−θ¯T∇ Ψ (φ
)(cid:13) (cid:13)2(cid:1)
. Theparametersα areoptimizedwiththequadraticloss
p¯ θ¯ j(φ¯ j|φ j)p j(φ j) (cid:13) φ j j j φ j j j−1 (cid:13) j
ℓ(α )=E
(cid:0)(cid:13)
(cid:13)αT∇ Φ (φ )−θ¯T∇ Ψ (φ
)(cid:13) (cid:13)2(cid:1)
. (83)
j p¯ θ¯ j(φ¯ j|φ j)p j(φ j) (cid:13) j φ j j j j φ j j j−1 (cid:13)
Thisexpectedvalueiscalculatedwithanempiricalaverageoverthemsamplesφ(i)ofp . Foreachφ(i)weknowa
j j j
sampleφ¯( ji)ofp¯ j(φ¯ j|φ( ji)). WemodifythissamplewithaMALAalgorithmtoobtainasampleofp¯ θ¯ j(φ¯ j|φ( ji)),which
approximatesp¯ (φ¯ |φ(i)).
j j j
D Momenterrorsonφ4
Metriconmoments Weevaluatethemodelerrorsfromgeneratedsampledoverasufficientsetofmoments. For
φ4,thesestatisticsaresecondordermomentsandthemarginaldistributionofφ(n).ThisappendixdefinesaKullback-
divergenceerrorfromthesemoments.
102
Synthesis
10 1
Original
10 2 101
10 3
100
10 4
10 5
-2 -1 0 1 2 100 101 102
| |
(a) (b)
Figure15: (a): Themarginalprobabilitydistributionofeachφ(n)iscomputedfromsamplesoftheφ4modelatthe
phasetransition. Itissuperimposedwiththemarginalprobabilitydistributionofsamplesofthehierarchicmodelina
Haarwaveletbasis. (b): EigenvaluesofcovariancematricesintheFourierbasis. Theyarecomputedfromsamplesof
theφ4modelandwiththeHaarhierarchicmodel,forimagesofsized=1282. Thehierarchicmodelrecoversprecisely
bothtypesofmomentsin(a)and(b),whicharesufficientstatisticsforφ4.
The φ4 model has a Gibbs energy U(φ) = θTΦ(φ), where Φ is defined in (51), with a single scalar potential
Γ(φ∗ϕ ) = Γ(φ)forℓ = 0. Sections2.2showsthatpisequaltothemaximumentropydistributionp suchthat
ℓ θ
E (Φ)=E (Φ). ThesemomentsspecifiedbythecovarianceC ofp(φ)andbythemarginaldistributionp˜(t)offield
p p
θ
valuest=φ(n).
Toevaluatetheprecisionofahierarchicmodelp ,weevaluatethecovarianceC andthemarginaldistributionp˜ (t),
θ θ θ
with a Monte Carlo average over samples generated by this model. We compute the KL divergence between the
maximum entropy distributions having covariances a C and a C . Both distributions are gaussians and their KL
θ
divergenceis
1 d 1
log(|C C−1|)− + TrCC−1.
2 θ 2 2 θ
30HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
Themaximumentropydistributionshavingmarginalsp˜andp˜ arerandomvectorswithdindependentcoordinates.
θ
TheirKLdivergenceisthusdKL(p˜,p˜ ). AddingandrenormalizingtheseKLdivergencesbythedimensiondgivesan
θ
error:
1 1 1
e(p,p )= log(|C C−1|)− + TrCC−1+KL(p˜,p˜ ). (84)
θ 2d θ 2 2d θ θ
Figure15showsthattheestimatedmarginaldistributionsp˜andtheeigenvaluesofthecovarianceC ofpareprecisely
approximatedbythemarginalp˜ andthecovarianceC ofthehierarchicalmodelp computedinaHaarbasis.
θ θ θ
E ProofsofPropositionsandTheorems
E.1 ProofofProposition2.1
Thelog-Sobolevequation(2)impliesaPoincare´ inequality[Led00]
(cid:90)
E[|f(φ)−E(f(φ))|2]≤2c(p) ∥∇f(φ)∥2p(φ)dφ.
Thisisproven,forregularenoughfunctionsf ,byapplyingthelog-Sobolevinequalitytothedensityq =p+ϵ(pf −
E (cid:0) f(cid:1) ),andlettingϵgotozero. Lete beanormalizedeigenvectorofthecovarianceofpcorrespondingtothe
p max
maximumeigenvalueµ andf(φ)=⟨e ,φ⟩. ThePoincare´ inequalityappliedtof gives
max max
(cid:90)
µ ≤2c(p) ∥e ∥2p(φ)dφ=2c(p),
max max
whichprovesthatc(p)≥µ /2.
max
E.2 ProofofProposition3.1
ToprovethatKL(p,q˜)≤KL(p,q),wedecompose
(cid:90) (cid:90)
KL(p,q˜)= p(φ)logp(φ)dφ− p(φ)logq˜(φ)dφ,
withq˜=Z˜−1e−Ave j−1U. Letusverifythatthesecondtermincreaseswhenq˜isreplacedbyq =Z−1e−U.
Sincepistranslationinvariant,achangeofvariableprovesthat
(cid:90) (cid:90)
− p(φ)logq˜(φ)dφ=|G |−1 p(φ) (cid:88) U(T φ)dφ+logZ˜
j−1 τ
τ∈G
j−1
(cid:90)
= p(φ)U(φ)dφ+logZ˜, (85)
where
(cid:90) (cid:90)
Z˜= e−Ave j−1U(φ)dφ= (cid:89) (cid:0) e−U(T τφ)(cid:1)|G j−1|−1 dφ.
τ∈G
j−1
Wenowprovethat
(cid:90)
Z˜≤Z = e−U(φ)dφ, (86)
sothatwecanshowwith(85)that
(cid:90) (cid:90)
− p(φ)logq˜(φ)dφ≤− p(φ)q(φ)dφ,
whichprovesthetheoremresult(38).
Weprove(86)byiteratingontheHo¨lderinequalitywhichprovesthat
 |G |  |G |−1
(cid:90) j−1 (cid:90) j−1 (cid:90)
 (cid:89) (cid:0) e−U(T τφ)(cid:1)|G j−1|−1 dφ ≤ (cid:89) (cid:0) e−U(T τφ)(cid:1)(|G j−1|−1)−1 dφ e−U(T τ1φ)dφ.
τ∈G j−1 τ∈G j−1−{τ 1}
But(cid:82) e−U(T τφ)dφ=Z soreapplying|G |−1timestheHo¨lderinequalitytotheintegraltothepower|G |−1
j−1 j−1
provesthat(Z˜)|G j−1| ≤(Z)|G j−1|andhenceZ˜≤Z,whichfinishestheproof. □
31HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
E.3 ProofofTheorem4.1
Atthecoarsestscale2J,Φ isdefinedin(47)byaconvolutionaloperatorwhosekerneliswrittenK andascalar
J J
potentialdefinedin(48). Onecanthusverifythat
θ =(K /2,γ ) and Φ (φ )=(cid:0) φ ∗φT, Γ(φ )(cid:1) . (87)
J J J J J J J J
ThepotentialΦ thussatisfies(51)forj =J.
J
ToprovethattheΦ defineahierarchicpotential,weshallprovethatforanyj ≥J,if
j
Φ (φ )=(cid:0) φ ∗φT,Γ(φ ∗ϕ )(cid:1)
j j j j j ℓ J−j≥ℓ≥0
andifΨ isdefinedby(49)andhence
j
Ψ (φ )=(cid:0) φ¯ φ¯T, φ¯ φT, Γ(φ )(cid:1)
j j−1 j j j j j−1
thenAve (Φ ,Ψ )isalinearfunctionofΦ ,with
j−1 j j j−1
Φ (φ )=(cid:0) φ ∗φT ,Γ(φ ∗ϕ )(cid:1) .
j−1 j−1 j−1 j−1 j−1 ℓ J−j+1≥ℓ≥0
Let us first show that Ave (Ψ ) is a linear function of Φ . We consider the first two terms of Ψ . Since
j−1 j j−1 j
φ¯ =G¯φ andφ =Gφ ,itresultsthatφ¯ φ¯Tandφ¯ φTarelinearfunctionsofφ φT . Sinceφ φT =
j j−1 j j−1 j j j j j−1 j−1 j−1 j−1
(φ (n)φ (n′)) itresultsthat
j−1 j−1 n,n′
Ave (φ φT )=|G |−1(cid:16) (cid:88) φ (n−τ)φ (n′−τ)(cid:17)
j−1 j−1 j−1 j−1 j−1 j−1 n,n′
τ∈G
j−1
=|G |−1(cid:0) φ ∗φT (n′−n)(cid:1) .
j−1 j−1 j−1 n,n′
It results that applying Ave to the first two terms of Ψ is a linear function of Φ . For the third term of
j−1 j−1 j−1
Ave (Ψ )wehave
j−1 j
Ave Γ(φ )=Γ(φ )=Γ(φ ∗ϕ ),
j−1 j−1 j−1 j−1 0
becauseϕ =δ,whichalinearfunctionofthesecondtermofΨ whichincludesthisterm. Itconcludestheproofthat
0 j
Ave (Ψ )isalinearfunctionofΦ .
j−1 j j−1
LetusnowprovethatAve (Φ )isalinearfunctionofΦ . ForthefirstterminAve (Φ ),equation(64),which
j−1 j j−1 j−1 j
statesthatφ (n)=φ ∗g(2n),gives
j j−1
φ ∗φT =(cid:16) (cid:88) φ (−τ)φ (n−τ)(cid:17)
j j j j
n
τ∈G
j
(cid:16) (cid:88) (cid:17)
= (φ ∗g)(−2τ)(φ ∗g)(2n−2τ) .
j−1 j−1
n
τ∈G
j
AveragingoverallthetranslationsonthegridG eliminatesthesubsamplingintheprevioussum,andgives
j−1
Ave (φ ∗φT)= 1(cid:0) (φ ∗g)∗(φT ∗gT)(2n)(cid:1)
j−1 j j 4 j−1 j−1 n
= 1(cid:0) (g∗gT)∗(φ ∗φT )(2n)(cid:1) ,
4 j−1 j−1 n
wheregT(n)=g(−n). Ave (φ ∗φT)isthusalineartransformationofthefirsttermofΦ (φ ).
j−1 j j j−1 j−1
TocomputethesecondtermsofAve (Φ ),weuse(67)whichshowsthat
j−1 j
φ ∗ϕ (n)=φ ∗ϕ (2n). (88)
j ℓ j−1 ℓ+1
MoreoverΓcomputesasumonthegridG ofpointwisetransformationsρ whichcommutewithtranslations. Itresults
j k
thattheaveragingofalltranslationsonthegridG gives
j−1
Ave (Γ(φ ∗ϕ ))=|G
|−1(cid:16) (cid:88)
ρ (φ ∗ϕ
(2n−τ))(cid:17)
j−1 j ℓ j−1 k j−1 ℓ+1
k
τ∈G ,n∈G
j−1 j
1(cid:16) (cid:88) (cid:17)
= ρ (φ ∗ϕ (n)
4 k j−1 ℓ+1 k
n∈G
j−1
1
= Γ(φ ∗ϕ ).
4 j−1 ℓ+1
32HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
ThisprovesthatthesecondtermsofAve (Φ )isalinearfunctionofthesecondtermofΦ . Thisfinishesthe
j−1 j j−1
proofthattheΦ defineastationaryhierarchicpotential.
j
ObservethatthescalarpotentialofeachinteractionenergyΨ createsascalarpotentialateachscale,whichappears
j
in (51). If we approximate the free energies F by αTΦ then Proposition 3.2 defines stationary energy models
j j j
U = θTΦ ateachscale2j. Thecouplingvectorθ iscalculatedfromθ and(θ¯ ,α )withtheoperatorQ . It
θ j j j−1 j j j j
j
definesafinescalestationaryenergymodel
U (φ)=θTΦ (φ)=(K,γ )T (cid:0) φ∗φT,Γ(φ∗ϕ )(cid:1) ,
θ 0 0 j j≥J j J≥j≥0
andhence
J
U (φ)= 1 φTKφ+(cid:88) γTΓ(φ∗φ ),
θ 2 j j
j=0
whichfinishesthetheoremproof.
E.4 ProofofTheorem5.1
ToverifythattheΦ defineahierarchicpotentialweshallprovethatforanyj ≥J,if
j
Φ (φ )=(cid:0) R(φ )∗R(φ )T,Γ(φ ∗ϕ )(cid:1) with R(φ )=(φ ,|φ∗ψ˜ (2jn)|q) ,
j j j j j ℓ J−j≥ℓ≥0 j j j′,k′ j′>j,k′
and
Ψ =(cid:0) S ST,Γ(cid:1) with S (φ )=(cid:16) φ∗ψ˜ (2j−1n), |φ∗ψ˜ |q∗ψ (2j−1n)(cid:17) ,
j j j′ J+1≥j′≥j j′ j−1 j′,k′ j′,k′ ℓ,k ℓ≥j′,k,k′≤Q,n
thenAve (Φ )andAve (Ψ )arelinearfunctionsofΦ ,for
j−1 j j−1 j j−1
Φ (φ )=(cid:0) R(φ )∗R(φ )T,Γ(φ ∗ϕ )(cid:1) .
j−1 j−1 j−1 j−1 j−1 ℓ J−j+1≥ℓ≥0
FromtheproofofTheorem4.1,theΓ-termsofAve (Φ )andAve (Ψ )arelinearfunctionsoftheΓ-termsof
j−1 j j−1 j
Φ . WeconcentratethefirsttermsinAve (Ψ )andAve (Φ ).
j−1 j−1 j j−1 j
ForAve (Ψ ),considerAve (S ST). Foranyj′ ≥j,thescatteringvectorS isalinearfunctionof
j−1 j j−1 j j′ j′
R(φ ) = (φ ,|φ∗ψ˜ (2j−1n)|q) . NonlineartermsinS′ areincludedinR(φ ),and,from(71),
j−1 j−1 j′,k′ j′>0,k′≤Q j j−1
φ∗ψ˜ (2j−1n),isalinearfunctionofφ .
j′,k′ j−1
ItresultsthatthetermsAve (S ST)arelinearfunctionsofAve (R RT ). Inthesamewaythatweprovedfor
j−1 j j′ j−1 j−1 j−1
Theorem4.1thatAve (φ φT )isalinearfunctionofφ ∗φT ,weprovethatAve (R(φ )R(φ )T)
j−1 j−1 j−1 j−1 j−1 j−1 j−1 j−1
isalinearfunctionofR(φ )∗R(φ )T. ThetermAve (S ST)isthereforealinearfunctionofthefirsttermof
j−1 j−1 j−1 j j′
Φ .
j−1
Let us now prove that the first term of Ave (Φ ), and hence Ave (R(φ )∗R(φ )T), is a linear function of
j−1 j j−1 j j
R(φ )∗R(φ )T.
j−1 j−1
R(φ )isdeducedfromR(φ )using,thefilterGonφ ,andbysubsampling(ordiscarding)thenonlinearterms.
j j−1 j−1
Ave (R(φ )R(φ )T), is a linear function of Ave (R(φ )R(φ )T), which is itself a linear transform of
j−1 j j j−1 j−1 j−1
R(φ )∗R(φ )T.
j−1 j−1
ThisfinishestheproofthattheΦ defineastationaryhierarchicpotential.
j
Proposition3.2impliesthatapproximatingF byαTΦ yieldsacouplingflowequation(41). Itcomputesθ fromθ
j j j j−1 j
and(θ¯ ,α )withthelinearoperatorQ . Itdefines
j j j
U (φ)=θTΦ (φ)=θT(cid:0) R(φ)∗R(φ)T,Γ(φ∗ϕ )(cid:1) .
θ 0 0 0 ℓ J≥j≥0
Since R(φ) = (φ,|Wφ|q), for θ = (K,L,M,γ ) where (K,L,M) are convolutional operators, this can be
0 j j≥J
rewritten
J
U (φ)= 1 φTKφ+φTL(|Wφ|q)+ 1 (|Wφ|q)TM(|Wφ|q)+(cid:88) γTΓ(φ∗ϕ ),
θ 2 2 j j
j=0
whichproves(59).
33HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
F EstimationAlgorithms
F.1 NormalizedAutocorrelationRelaxationTimeofaLangevinDiffusion
ThisappendixspecifiesthecalculationofnormalizedrelaxationtimeofLangevindiffusionsinhierarchicmodels.
Conditional auto-correlation relaxation time As in [MOBM22, GLBM23], we compute the auto-correlation
relaxationtime(8)tosampletheconditionalprobabilitiesofahierarchicmodelwithanunadjustedLangevindiffusion.
ThisconditionalprobabilityhasanenergyU¯ θ¯ . TheunadjustedLangevindiffusionofφ¯ j isnumericallycomputed
j
withanEuler-Maruyamadiscretizationwithatimeintervalδ . Thistimeintervalmustbesmallerthantheinverseof
j
theLipschitzconstantof∇ φ¯ jU¯ θ¯
j
[VW22]. ThisLipschitzconstantisevaluatedbyestimatingthesupremumofthe
eigenvaluesoftheHessian∇2 φ¯ jU¯ θ¯ j(φ j−1)overtypicalrealizationsφ j−1. Wesetδ j tobeafixedfractionoftheinverse
ofthissupremum.
Letφ¯ bethewaveletcoefficientsofobtainedbytheLangevindiffusion,afterαstepsatintervalsδ ,thuscorresponding
j,α j
toatimet=αδ . Anormalizedconditionalauto-correlationatαis
j
E (cid:0)(cid:0) φ¯ −E (cid:0) φ¯ (cid:1)(cid:1)(cid:0) φ¯ −E (cid:0) φ¯ (cid:1)(cid:1)(cid:1)
A¯ (α|φ )= p¯ θ¯ j(·|φ j) j,α p¯ θ¯ j(·|φ j) j j,0 p¯ θ¯ j(·|φ j) j , (89)
j j E (cid:0)(cid:0) φ¯ −E (cid:0) φ¯ (cid:1)(cid:1)2(cid:1)
p¯ θ¯ j(·|φ j) j p¯ θ¯ j(·|φ j) j
Thisauto-correlationisaveragedoverthedistributionofφ
j
A (α)=E (cid:0) A¯ (α|φ )(cid:1) . (90)
j p j j
j
TheexponentialdecayA (α)ismeasuredbythenormalizedautocorrelationrelaxationtimeτ¯ ,
j j
(cid:18) (cid:19)
α
A (α)≈A (0)exp − . (91)
j j τ¯
j
ThisnormalizedrelaxationtimeisthenumberofLangeviniterationsneededtoreachafixedprecision.
CommentsonMALA TherejectionstepoftheMALAalgorithmmodifiesthevalueoftherelaxationtime. Whereas
Langevin and MCMC algorithm have hierarchical autocorrelation relaxation times which do not depend upon the
systemsized,theMALAalgorithmproducesahierarchicalrelaxationtimewhichhasaslowgrowthasafunctionofd,
highlightedin[GLBM23]. Indeed,MALAreliesonaglobalacceptancestep,whichdoesnottakeadvantageofthe
localityofinteractions,asopposedtoanMCMCsamplingoranunadjustedLangevindiffusion[MOBM22,MS06].
Forexample,MALAhasamixingtimethatgrowswiththedimensiond,forstronglylog-concavedistributionshavinga
log-Sobolevconstantwhichdoesnotdependond[CEL+21,LZT22,WSC22],whereasitisnotthecaseforanMCMC
samplingoraLangevinunadjusteddiffusions. However,MALAisthefastestalgorithmtocomputethehierarchic
samplingfortheimagesizesconsideredinthispaper[GLBM23]. Itisusedforthegenerationresultsbutnottoevaluate
therelaxationtimeinordertoavoidissuesrelatedtotherejection-approvalstep.
F.2 EstimationoftheBi-spectrum
Wedescribethecalculationofthebi-spectruminFigure12. Thebi-spectrumisdefinedastheexpectedvalueFourier
transform of the 3 points correlation function. We use a regularized estimation of these statistics for rotationally
invariantprobabilitydistributions,describedin[CMA+23]. Itperformsafrequencyaveraginginthinfrequencyannuli,
evenlyspacedinfrequencylog-scale,thatwewriteA .FortheFigure12(e),forimagesofsized=1282,thefrequency
k
planeisdecomposedinto9frequencyannuliA ,whichselectfrequenciesωsuchthat2−7k/9π ≤|ω|≤2−7(k+1)/9π.
k
Weconsiderprobabilitydistributionswhichareinvarianttorotations. Thepowerspectrumisthusestimatedwithan
averageoverfrequenciesωineachannulusA andovermultiplesamplesφ(i):
k
P(k)=Ave |φˆ(i)(ω)|2. (92)
i,ω∈A
k
For(k ,k ,k ), aregularizednormalizedbi-spectrumisdefinedasasumoverall(ω ,ω ,ω )from3frequencies
1 2 3 1 2 3
ω ∈ A
whichsumtozero(cid:80)3
ω = 0,bymultiplyingtheFouriertransformsatthesefrequenciesofmultiple
j k j j=1 j
samplesφ(i):
(cid:16)φˆ(ω(i))φˆ(ω(i))φˆ(i)(ω )(cid:17)
B(k ,k ,k )=Ave 1 2 3 . (93)
1 2 3 i,ω j∈A kj,(cid:80)3 j=1ω j=0 (cid:112) P(k i)P(k 2)P(k 3)
34HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
References
[ABBL06] AlexeiAndreanov,GiulioBiroli,Jean-PhilippeBouchaud,andAlexandreLefevre. Fieldtheoriesandexactstochastic
equationsforinteractingparticlesystems. PhysicalReviewE,74(3):030101,2006.
[ABT18] RichardCAster,BrianBorchers,andCliffordHThurber. Parameterestimationandinverseproblems. Elsevier,2018.
[AGV13] PatriceAbry,PaoloGoncalves,andJacquesLe´vyVe´hel. Scaling,fractalsandwavelets. JohnWiley&Sons,2013.
[Bat99] GuyBattle. Waveletsandrenormalization,volume10. WorldScientific,1999.
[BB19] RolandBauerschmidtandThierryBodineau. Averysimpleproofofthelsiforhightemperaturespinsystems.
JournalofFunctionalAnalysis,276(8):2582–2588,2019.
[BBD23] RolandBauerschmidt,ThierryBodineau,andBenoitDagallier. Stochasticdynamicsandthepolchinskiequation:an
introduction. arXivpreprintarXiv:2307.07619,2023.
[BD22] RolandBauerschmidtandBenoitDagallier. Log-sobolevinequalityfornearcriticalisingmodels. arXivpreprint
arXiv:2202.02301,2022.
[BDSG+15] LorenzoBertini,AlbertoDeSole,DavideGabrielli,GiovanniJona-Lasinio,andClaudioLandim. Macroscopic
fluctuationtheory. ReviewsofModernPhysics,87(2):593,2015.
[BGL+14] DominiqueBakry,IvanGentil,MichelLedoux,etal. AnalysisandgeometryofMarkovdiffusionoperators,volume
103. Springer,2014.
[Bis06] ChristopherBishop. Patternrecognitionandmachinelearning. Springergoogleschola,2:5–43,2006.
[BJPV98] TomasBohr,MogensH.Jensen,GiovanniPaladin,andAngeloVulpiani.DynamicalSystemsApproachtoTurbulence.
CambridgeNonlinearScienceSeries.CambridgeUniversityPress,1998.
[CCL+20] LokHangChan,KunChen,ChunxueLi,ChungWangWong,andChunYipYau. Onhigher-ordermomentand
cumulantestimation. JournalofStatisticalComputationandSimulation,90(4):747–771,2020.
[CE22] YuansiChenandRonenEldan. Localizationschemes:Aframeworkforprovingmixingboundsformarkovchains.
In2022IEEE63rdAnnualSymposiumonFoundationsofComputerScience(FOCS),pages110–122.IEEE,2022.
[CEL+21] SinhoChewi,MuratA.Erdogdu,MufanBillLi,RuoqiShen,andMatthewZhang. Analysisoflangevinmontecarlo
frompoincare´tolog-sobolev,2021.
[CMA+23] SihaoCheng,RudyMorel,ErwanAllys,BriceMe´nard,andSte´phaneMallat. Scatteringspectramodelsforphysics,
2023.
[CMW92] RonaldRCoifman,YvesMeyer,andVictorWickerhauser. Waveletanalysisandsignalprocessing. InInWavelets
andtheirapplications.Citeseer,1992.
[CR23] JordanCotlerandSemonRezchikov. Renormalizingdiffusionmodels. arXivpreprintarXiv:2308.12355,2023.
[Dau92] IngridDaubechies. TenLecturesonWavelets. SocietyforIndustrialandAppliedMathematics,1992.
[Del12] BertrandDelamotte. AnIntroductiontotheNonperturbativeRenormalizationGroup,page49–132. SpringerBerlin
Heidelberg,2012.
[DLS02] BernardDerrida,JLLebowitz,andERSpeer. Largedeviationofthedensityprofileinthesteadystateoftheopen
symmetricsimpleexclusionprocess. Journalofstatisticalphysics,107(3-4):599–634,2002.
[GCDBM22] FlorentinGuth,SimonCoste,ValentinDeBortoli,andSte´phaneMallat. Waveletscore-basedgenerativemodeling.
AdvancesinNeuralInformationProcessingSystems,2022.
[GG84] StuartGemanandDonaldGeman. Stochasticrelaxation,gibbsdistributions,andthebayesianrestorationofimages.
IEEETransactionsonpatternanalysisandmachineintelligence,(6):721–741,1984.
[GGR97] AndrewGelman,WalterRGilks,andGarethORoberts. Weakconvergenceandoptimalscalingofrandomwalk
metropolisalgorithms. Theannalsofappliedprobability,7(1):110–120,1997.
[GLBM23] FlorentinGuth,EtienneLempereur,JoanBruna,andSte´phaneMallat. Conditionallystronglylog-concavegenerative
models. InternationalConferenceonMachineLearning,2023.
[GM94] UlfGrenanderandMichaelIMiller. Representationsofknowledgeincomplexsystems. JournaloftheRoyal
StatisticalSociety:SeriesB(Methodological),56(4):549–581,1994.
[GNC10] MatanGavish,BoazNadler,andRonaldRCoifman. Multiscalewaveletsontrees,graphsandhighdimensionaldata:
theoryandapplicationstosemisupervisedlearning. InICML,volume10,pages367–74,2010.
[Gro75] LeonardGross. Logarithmicsobolevinequalities. AmericanJournalofMathematics,97(4):1061–1083,1975.
[GRVE22] MarylouGabrie´,GrantMRotskoff,andEricVanden-Eijnden. Adaptivemontecarloaugmentedwithnormalizing
flows. ProceedingsoftheNationalAcademyofSciences,119(10):e2109420119,2022.
[HD05] AapoHyva¨rinenandPeterDayan. Estimationofnon-normalizedstatisticalmodelsbyscorematching. Journalof
MachineLearningResearch,6(4),2005.
35HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
[HK22] TruongSonHyandRisiKondor. Multiresolutionmatrixfactorizationandwaveletnetworksongraphs. InICML
20222ndAIforScienceWorkshop,2022.
[HVG11] DavidKHammond, PierreVandergheynst, andRe´miGribonval. Waveletsongraphsviaspectralgraphtheory.
AppliedandComputationalHarmonicAnalysis,30(2):129–150,2011.
[Jaf92] StephaneJaffard. Waveletmethodsforfastresolutionofellipticproblems. SIAMJournalonNumericalAnalysis,
29(4):965–986,1992.
[Jaf04] StephaneJaffard. Wavelettechniquesinmultifractalanalysis. InProceedingsofsymposiainpuremathematics,
volume72,pages91–152,2004.
[Jay57] EdwinTJaynes. Informationtheoryandstatisticalmechanics. Physicalreview,106(4):620,1957.
[Kad66] LeoPKadanoff. Scalinglawsforisingmodelsneartc. PhysicsPhysiqueFizika,2(6):263,1966.
[KHR22] FredericKoehler,AlexanderHeckett,andAndrejRisteski. Statisticalefficiencyofscorematching:Theviewfrom
isoperimetry. arXivpreprintarXiv:2210.00726,2022.
[KHY76] LeoPKadanoff,AnthonyHoughton,andMehmetCYalabik. Variationalapproximationsforrenormalizationgroup
transformations. JournalofStatisticalPhysics,14(2):171–203,1976.
[KMR16] J.Kaupuzˇs,R.V.N.Melnik,andJ.Rimsˇa¯ns. Correctionstofinite-sizescalingintheφ4modelonsquarelattices.
InternationalJournalofModernPhysicsC,27(09):1650108,2016.
[kol41] Akolmogorov. Localstructureofturbulenceinanincompressiblefluidatveryhighreynoldsnumbers. CRAd.Sei.
UUSR,30:305,1941.
[Kol42] ANKolmogorov. Equationsofturbulentmotionofanincompressiblefluid,izv.acad.sci.,ussr. Physics,6(1):2,1942.
[Kra67] RobertHKraichnan. Inertialrangesintwo-dimensionalturbulence. Physicsoffluids,10(7):1417,1967.
[KS06] JariKaipioandErkkiSomersalo. Statisticalandcomputationalinverseproblems,volume160. SpringerScience&
BusinessMedia,2006.
[Led00] MichelLedoux. Thegeometryofmarkovdiffusiongenerators. InAnnalesdelaFaculte´dessciencesdeToulouse:
Mathe´matiques,volume9,pages305–366,2000.
[LL13] LevDavidovichLandauandEvgeniiMikhailovichLifshitz. StatisticalPhysics:Volume5,volume5. Elsevier,2013.
[LS16] TonyLelie`vreandGabrielStoltz. Partialdifferentialequationsandstochasticmethodsinmoleculardynamics. Acta
Numerica,25:681–880,2016.
[LZT22] RuilinLi,HongyuanZha,andMoleiTao. Sqrt(d)dimensiondependenceoflangevinmontecarlo,2022.
[Mal89a] Ste´phaneMallat.Atheoryformultiresolutionsignaldecomposition:Thewaveletrepresentation.IEEETrans.Pattern
Anal.Mach.Intell.,11:674–693,1989.
[Mal89b] StephaneGMallat.Atheoryformultiresolutionsignaldecomposition:thewaveletrepresentation. IEEEtransactions
onpatternanalysisandmachineintelligence,11(7):674–693,1989.
[Mal09] Ste´phaneMallat. Awavelettourofsignalprocessing. AcademicPress,thirdeditionedition,2009.
[Mal12] S.Mallat. Groupinvariantscattering. CommunicationsonPureandAppliedMathematics,65(10):1331–1398,2012.
[Mey93] YvesMeyer. WaveletsandOperators, volume1ofCambridgeStudiesinAdvancedMathematics. Cambridge
UniversityPress,1993.
[MOBM22] TanguyMarchand,MisakiOzawa,GiulioBiroli,andSte´phaneMallat. Waveletconditionalrenormalizationgroup.
arXivpreprintarXiv:2207.04941,2022.
[MRL+23] RudyMorel,GasparRochette,RobertoLeonarduzzi,Jean-PhilippeBouchaud,andSte´phaneMallat. Scaledependen-
ciesandself-similarmodelswithwaveletscatteringspectra. AvailableatSSRN4516767,2023.
[MS06] AndreaMontanariandGuilhemSemerjian. Rigorousinequalitiesbetweenlengthandtimescalesinglassysystems.
Journalofstatisticalphysics,125:23–54,2006.
[MZR20] Ste´phaneMallat,SixinZhang,andGasparRochette. Phaseharmoniccorrelationsandconvolutionalneuralnetworks.
InformationandInference:AJournaloftheIMA,9(3):721–747,2020.
[Pod96] RudolfPodgornik. Principlesofcondensedmatterphysics.p.m.chaikinandt.c.lubensky,cambridgeuniversity
press,cambridge,england,1995. JournalofStatisticalPhysics,83:1263–1265,061996.
[Pol84] JosephPolchinski. Renormalizationandeffectivelagrangians. NuclearPhysicsB,231(2):269–295,1984.
[PS00] JavierPortillaandEeroPSimoncelli. Aparametrictexturemodelbasedonjointstatisticsofcomplexwavelet
coefficients. Internationaljournalofcomputervision,40(1):49–70,2000.
[Ram20] PierreRamond. Fieldtheory:amodernprimer. Routledge,2020.
[RBL+22] RobinRombach,AndreasBlattmann,DominikLorenz,PatrickEsser,andBjo¨rnOmmer. High-resolutionimage
synthesiswithlatentdiffusionmodels. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
Recognition,pages10684–10695,2022.
36HierarchicFlowstoEstimateandSampleHigh-dimensionalProbabilities APREPRINT
[RFB15] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image
segmentation. InMedicalimagecomputingandcomputer-assistedintervention–MICCAI2015:18thinternational
conference,Munich,Germany,October5-9,2015,proceedings,partIII18,pages234–241.Springer,2015.
[RR98] GarethORobertsandJeffreySRosenthal.Optimalscalingofdiscreteapproximationstolangevindiffusions.Journal
oftheRoyalStatisticalSociety:SeriesB(StatisticalMethodology),60(1):255–268,1998.
[Set21] JamesPSethna. StatisticalMechanics:Entropy,OrderParameters,andComplexity,volume14. OxfordUniversity
Press,USA,2021.
[Sim62] HerbertASimon.Thearchitectureofcomplexity.ProceedingsoftheAmericanphilosophicalsociety,106(6):467–482,
1962.
[Sok91] AlanD.Sokal. Howtobeatcriticalslowingdown:1990update. Nucl.Phys.BProc.Suppl.,20:55–67,1991.
[Sok97] AlanSokal.Montecarlomethodsinstatisticalmechanics:foundationsandnewalgorithms.InFunctionalintegration:
Basicsandapplications,pages131–192.Springer,1997.
[SSK+21] YangSong,JaschaSohl-Dickstein,DiederikP.Kingma,AbhishekKumar,StefanoErmon,andBenPoole. Score-
based generative modeling through stochastic differential equations. In International Conference on Learning
Representations,2021.
[SZFA06] KaiSchneider,Jo¨rgZiuber,MarieFarge,andAlexandreAzzalini. Coherentvortexextractionandsimulationof2d
isotropicturbulence. JournalofTurbulence,(7):N44,2006.
[Ta¨u14] UweCTa¨uber. Criticaldynamics: afieldtheoryapproachtoequilibriumandnon-equilibriumscalingbehavior.
CambridgeUniversityPress,2014.
[Tur18] ThomasTurk. Matrixorganisation. Springer,2018.
[VNHM+20] FranciscoVillaescusa-Navarro,ChangHoonHahn,ElenaMassara,ArkaBanerjee,AnaMariaDelgado,DoogeshKodi
Ramanah,TomCharnock,ElenaGiusarma,YinLi,ErwanAllys,AntoineBrochard,CoraUhlemann,Chi-Ting
Chiang,SiyuHe,AlicePisani,AndrejObuljen,YuFeng,EmanueleCastorina,GabriellaContardo,ChristinaD.
Kreisch,AndrinaNicola,JustinAlsing,RomanScoccimarro,LiciaVerde,MatteoViel,ShirleyHo,StephaneMallat,
BenjaminWandelt,andDavidN.Spergel. Thequijotesimulations. TheAstrophysicalJournalSupplementSeries,
250(1):2,August2020.
[VW22] SantoshS.VempalaandAndreWibisono. Rapidconvergenceoftheunadjustedlangevinalgorithm:Isoperimetry
suffices,2022.
[WF72] KennethGWilsonandMichaelEFisher. Criticalexponentsin3.99dimensions. PhysicalReviewLetters,28(4):240,
1972.
[Wil71] KennethGWilson. Renormalizationgroupandcriticalphenomena.ii.phase-spacecellanalysisofcriticalbehavior.
PhysicalReviewB,4(9):3184,1971.
[WSC22] KeruWu,ScottSchmidler,andYuansiChen. Minimaxmixingtimeofthemetropolis-adjustedlangevinalgorithmfor
log-concavesampling,2022.
[ZJ21] JeanZinn-Justin. QuantumFieldTheoryandCriticalPhenomena:FifthEdition. OxfordUniversityPress,042021.
[ZM21] Sixin Zhang and Ste´phane Mallat. Maximum entropy models from phase harmonic covariances. Applied and
ComputationalHarmonicAnalysis,53:199–230,2021.
37