Fault Detection and Monitoring using an Information-Driven Strategy:
Method, Theory, and Application
CamiloRam´ırez a,JorgeF.Silva a,FerhatTamssaouet b,Toma´sRojas a,MarcosE.Orchard a
aInformationandDecisionSystemsGroup,DepartmentofElectricalEngineering,UniversityofChile,Santiago,Chile
bPROMES-CNRS,UPVD,Perpignan,France
Abstract
Theabilitytodetectwhenasystemundergoesanincipientfaultisofparamountimportanceinpreventingacriticalfailure. Inthis
work, we propose an information-driven fault detection method based on a novel concept drift detector. The method is tailored
toidentifyingdriftsininput-outputrelationshipsofadditivenoisemodels–i.e.,modeldrifts–andisbasedonadistribution-free
mutualinformation(MI)estimator. Ourschemedoesnotrequirepriorfaultyexamplesandcanbeapplieddistribution-freeovera
large class of system models. Our core contributions are twofold. First, we demonstrate the connection between fault detection,
model drift detection, and testing independence between two random variables. Second, we prove several theoretical properties
of the proposed MI-based fault detection scheme: (i) strong consistency, (ii) exponentially fast detection of the non-faulty case,
and(iii)controlofbothsignificancelevelsandpowerofthetest. Toconclude,wevalidateourtheorywithsyntheticdataandthe
benchmarkdatasetN-CMAPSSofaircraftturbofanengines. Theseempiricalresultssupporttheusefulnessofourmethodologyin
manypracticalandrealisticsettings,andthetheoreticalresultsshowperformanceguaranteesthatothermethodscannotoffer.
Keywords: Faultdetection,Conceptdrift,Systemmonitoring,Mutualinformation,Independencetesting,Turbofanengine
1. Introduction The literature offers a diverse range of FDI methods [5],
whichcanbeclassifiedintotwoapproaches: model-basedand
The objective of Prognostics and Health Management data-driven. Initially, FDI efforts focused on model-based ap-
(PHM) is to provide methodologies and tools for creating tai-
proaches such as eigenstructure assignment [6], parity-based
lored maintenance plans based on the specific characteristics,
methods [7], parameter identification-based methods [8],
operations,anddegradationscenariosofagivenasset[1]. This
observer-based methods [9], and structural graphs (e.g., bond
approachaimstoachieveoptimalsystemavailabilitywhilemin-
graph [10] and Petri net [11]). These methods are based on
imizingcosts,representingacomprehensiveandefficientstrat-
the idea of comparing system outputs with failure models and
egyforsystemhealthmanagement. PHMintegratesFaultDe- comparing this difference with a threshold; then, a fault is de-
tection and Isolation (FDI), health management, and prognos- tected when the value of the difference exceeds the threshold
ticcapabilities,includingRemainingUsefulLife(RUL)predic-
[12]. However, in the presence of significant noise or an un-
tion,toprovideinsightsintocurrentsystemconditions[2].
knownnoisedistribution,thesemethodsmayhavepoorperfor-
FaultDetectionandIsolation(FDI)isprimarilyconcerned
manceandmakethetaskofdeterminingthemostadequatefault
withidentifyingwhenafaultoccurs,understandingitscharac- decisionthresholddifficult[12,13]. Set-membershipmethods,
teristics, and pinpointing its location within a system. Degra-
where a set of models is generated for the system, emerge to
dationsareunavoidablephenomenawithinsystems,whichcan
overcome these limitations; in these methods, a fault is de-
be divided into incipient failures and critical failures. Incipi-
tectedwheneverameasurementisinconsistentwithanyofthe
ent failures can be defined as alterations that do not prohibit
members of this set [14]. However, the computational cost
thesystemfromoperating,whereascriticalfailuresoccurwhen
scales exponentially with the number of uncertain parameters
degradationlevelsresultinthesystemnotoperatingasrequired
[15], which is the case for complex systems. Overall, model-
[3].Asaconsequence,thedetectionofincipientfailuresissub- based methods are effective for simple systems whose
jecttoexhaustivestudy,especiallyincomplexandmultivariate
phenomenologycanbeunderstoodandrepresentedbyexplicit
systems[4],andisofparamountimportancebecauseearlyde-
mathematical models; although providing accurate and inter-
tectionofincipientfailurescanenablemaintenanceplanstobe
pretableresults,theyarechallengingtoimplementforcomplex
createdthatpreventtheoccurrenceofacriticalfailure[2].
systems[16].
Data-driven approaches, which contrast with model-based
Emailaddresses:camilo.ramirez@ug.uchile.cl approaches, are also prevalent in the current literature. These
(CamiloRam´ırez ),josilva@ing.uchile.cl(JorgeF.Silva ), phenomenological-agnosticmethodsinvolveperformingmath-
ferhat.tamssaouet@univ-perp.fr(FerhatTamssaouet ),
ematical or statistical operations on measurements or training
tomas.rojas.c@ug.uchile.cl(Toma´sRojas ),
morchard@ing.uchile.cl(MarcosE.Orchard ) neural networks using measurements to extract information
Preprint.
4202
yaM
6
]PS.ssee[
1v76630.5042:viXrafrom the system and predict faults. The information is ob- faults imply an alteration – namely, a drift – of the statistical
tainedthroughmeasuredsignalsandtheirconversionintofault- relationshipsexpressedinthesystemvariables[28]. Asacon-
characterizing features through time or frequency transforma- sequence, a link between detecting faults and statistical drifts
tions, or by leveraging prior knowledge of signal distribution arises[29,30]. Conceptdrift,awidely-usedterminthelitera-
[4, 17]. Machine fault detection and diagnosis, particularly in ture, occurswhenthedistributionofastochasticphenomenon
rotating machinery, employ various methods for data collec- changes over time [31, 32]. Much work has been done in the
tion, such as vibration monitoring and thermal imaging [18]. area of concept drift [32, 33] but using different names such
The collected data undergoes processing using methods like asdatashift[34]andanomalydetection[35]. Approachesfor
spectral analysis, wavelet analysis, short-term Fourier trans- detectingdriftscanbesupervisedorunsupervised. Supervised
form, and others, contributing to a comprehensive root cause methods,suchastheonedescribedin[35],relyontheavailabil-
failure analysis. The processed data can then be directly used ityofanomalousdata,whichisarestrictioninscenarioswhere
for fault detection by setting fixed [19] or adaptive thresholds this data is scarce or expensive [36]. Unsupervised methods
[20]. As the system state is generally not directly measurable are commonly based on error rates and compute p-values for
fromdata,twoapproachesareusedforitsestimation:statistical the observations as a measure of their abnormality [32]. We
and non-statistical. Statistical methods, such as Kalman filter highlight DMM [29], ADWIN [37], and STEPD [38] as pop-
[21],principalcomponentanalysis[22],amongothers,excelin ular error-based methods, but they have the disadvantage of
rapidfaultdetectionforlinearsystemsbutmaynotbeoptimal assuming discrete targets, and consequently, they are not suit-
for diagnosis and for detection in non-linear or non-Gaussian able for monitoring continuous variables. In [33], a variety of
systems. The non-statistical data-driven methods involve us- regression-suitedlearningmethodsareshown,buttheyareused
ing mathematical classification models from supervised learn- inadaptivescenariosandarerestrictedtotheiralgorithmcate-
ingmethods.Techniqueslikethek-nearestneighborsalgorithm gory as seen in [33, Table 6]; hence, they cannot be used in
(kNN)[23]andSupportVectorMachines(SVMs)[24]areem- already-deployed models or in problems with modeling more
ployed.Despitetheireffectiveness,SVMsaresensitivetoinitial complexthantheirbasealgorithm.
parameters, necessitating a parameter-tuning process for each In the current landscape, behavioral models offer real ad-
signal dataset. Artificial Neural Networks (ANNs) are widely vantages for FDI. This approach is particularly attractive as it
utilized for their self-learning capabilities and automatic fea- doesnotassumeahistory,makingitapplicabletoneworcriti-
tureextraction; however,theymaytendtoover-fitthetraining calsystems. However,thereareseveralopenchallenges,which
set,requiringregularizationtermsandpriorknowledgeforen- include (i) the nonexistence or scarcity of faulty data, which
hancedperformance[25]. RecentadvancementsinANNsand makes the supervised methods inoperable, (ii) the lack of de-
theadoptionofdeeplearningalgorithmshaveledtothedevel- cision guarantees for the majority of existing methods, partic-
opmentofnovelclassificationmodelsforfaultdetectionanddi- ularly in complex multi-variate non-linear and non-Gaussian
agnosis[26].DeeplearningarchitecturessuchasConvolutional systems, and (iii) the inability to work with already-deployed
NeuralNetworks,DeepBeliefNetworks,RestrictedBoltzmann behavioral models not necessarily dedicated to FDI. In addi-
Machines, and Autoencoders have performed successfully in tion, one can observe a link in the literature between concept
various industrial applications, including gearboxes, mechan- drift detection and FDI, but we do not observe a formal con-
ical bearings, compressors, wind and gas turbines, and steel nectionbetweenresultsfoundinconceptdriftliteratureandits
plates [27]. These deep learning models offer the ability to applicationstoFDI.
learn complex structures from datasets, although they require
larger samples and longer processing times to achieve higher 1.1. ContributionsofthisWork
accuracy. We propose a novel data-driven fault detection strategy
Comparedtomodel-basedmethods,data-drivenapproaches leveraged by a concept drift theory tailored to capture input-
aregenerallyeasiertoimplementbuthavedisadvantagessuch output relationship (model) drifts within the system. Remark-
asthelackofinterpretabilityanduncertaintymanagement[16]. ably, our method does not require the availability of previous
Inaddition,itisdifficulttoobtaindatathatidentifiesallpossi- faultydataandisagnostictolearningalgorithms,expertmodel-
ble faulty operations; moreover, conducting run-to-failure ex- ing,anddatadistributions,whichmakesitapplicabletoalarge
periments is not possible for complex systems where creating familyofscenarios. Ourkeycontributionsareasfollows:
a fault database is prohibitively expensive or impossible for • Weestablishaformalframeworkthatlinksthefaultde-
safety reasons. To overcome this problem, behavioral models
tection (FD) task with a kind of concept drift (model
can be used. Indeed, modern systems are increasingly relying
drift) detection that is especially suited to address alter-
on behavioral models, such as AI-based models, for monitor-
ations in input-output relationships. We develop a theo-
ing and control. The emergence of digital twins is notable in
reticalproofdemonstratingtheequivalencebetweentest-
this sense [16]. These models are constructed from data gath-
ing model drift and testing independence between a re-
eredwithdiversesensorsfacilitatedbythedevelopmentofthe
gressioninputanditsresidualfortherichclassofaddi-
IndustrialInternetofThings(IIoT).
tivenoisemodels.
Behavioralmodelsaredesignedtocapturethestatisticaldy-
namicsofthesystem. Thesedynamicsdependonwhetherthe • We introduce the use of a non-parametric mutual infor-
system is being subjected to a fault or not. In this context, mation estimator [39, 40] to perform model drift detec-
2tion. Weprovethattheresultingschemeisstronglycon- 2. Preliminaries
sistent(asymptoticexpressivenessformodeldriftdetec-
tion), has finite-length performance guarantees, and has In this section, we describe our main decision problem re-
aspecificvanishingerrorconvergencerate. latedtofaultdetection,stategeneraldefinitions,andintroduce
theconceptofmutualinformation.
• Wecomplementourtheoreticalandmethodologicalcon-
tributions with numerical analyses on controlled (syn- 2.1. FaultDetectionasaModelDriftDetectionTask
thetic)scenariosandintherealisticbenchmarkdatasetof
Inthispaper,wedealwithsystemmonitoringfromabehav-
turbofan engines N-CMAPSS [41]. Our empirical find-
ioraldata-drivenapproach. Thismeansthatdataobtainedfrom
ings support the practical capabilities of our method in
asystemistreatedasrealizationsoftherandomvariablesthat
complexfaultdetectionsettings.
composethesystem. Inthissetting,eachvariableofthesystem
corresponds to a random variable, and the system as a whole
1.2. RelatedWorks
isdescribedbythejointdistributionoftherandomvectorbuilt
Some related works use mutual information (MI) in their
uponallthesystem’svariables.
faultdetectionpipeline,butmostuseMItoselectfeatures(e.g.,
Conceptdriftcorrespondstoanarbitrarychangeinthesta-
[42]) or to circumvent the high-dimensionality of the process
tistical properties of a certain phenomenon over time [32].
(e.g., [43, 44]). Anexception isthe workof Lv etal. [45]; in
Moreover,whenconsideringanexplanatory-responserelation-
that work, they proposed to monitor the statistics of a
shipbetweentworandomvectorsX andY,theirjointdistribu-
component-pairwise MI estimation matrix of all variables in-
tion (P ) can be decomposed into the product of the
X,Y
volvedinthesystemtodetectfaultsandidentifythevariables
explanatory-marginal distribution (P ) and the predictive dis-
X
associatedwiththefaultbycheckingdeviations,intestingtime, tribution (P ), i.e., P = P · P . Then, we can distin-
Y|X X,Y X Y|X
fromthevaluesofthestatisticsobservedinahealthyscenario.
guish between virtual drifts (changes in P ) and actual drifts
X
FromthebasicfactthatMIisused,allthepreviouslymen-
(changesinP )[46].
Y|X
tionedworks([42,43,44,45])mightappeartoberelatedtothe
Afaulteventwithinasystemimpliesanalterationinitsin-
method presented in this paper; However, there are essential
nerdynamics,whichleadstoadisturbanceinthepredictivedis-
differencesworthmentioning. Fromaformulationperspective,
tributionoftheresponsegiventheexplanatoryvariables(P );
Y|X
ourworkisconstructedfromanoveltheory–developedinthis
i.e.,afaultisaneventthatleadstoanactualdrift. Incontrast,
paper–thatconnectsmodeldriftdetectionwithindependence amodeldriftcanhavedifferentorigins,whichincludechanges
testing. Notably, this formal path justifies the adoption of MI
inoperationalparameters,replacementofsub-componentsofa
to detect input-output deviations within a system and, conse-
system,andfaults. Inthiscontext,wecandefineanyunwanted
quently, the usage of MI features as health indicators, which
alterationoftheinnerdynamicsofasystemasafault. There-
strongly quantify the fault severity; this is a guarantee that is
fore, in a setting where no desired alterations are being made
not present in any of the mentioned methods. Moreover, our
toasystem,wecanestablishanequivalencebetweentheexis-
methodologyoffersuniqueperformanceguaranteesthatarenot
tenceofafaultandtheexistenceofanactualdrift.
offeredbyothermethods.
In Sec. 3, we show how this drift can be decoupled into
driftsontheunderlyingdeterministicexplanatory-responsere-
1.3. PaperOutline
lationship (model drift) and drifts on the noise model (noise
The outline of the remainder of our work is as follows. In drift),andconsequently,howthefault-driftequivalencereduces
Sec.2,weintroducethemodeldriftdetectiontask,stateitslink totheequivalencebetweenfaultexistenceandmodeldriftex-
withfaultdetection,andintroducedefinitionsusefulfortherest istence. Takingthisequivalenceintoconsideration,wepropose
ofthework. InSec.3,weformalizemodeldriftandshowthe an information-driven model drift detection method to imple-
equivalence between testing model drift and testing indepen- mentadata-drivenfaultdetector.
dence(Theorem1).InSec.4,ournewmethodologytoperform
model drift detection and, consequently, fault detection is in-
2.2. ModelDriftDetection
troduced. InSec.5,weshowaregimeofparametersinwhich
Letusconsidertworandomvectors(r.v.s) X andY,whose
ourmethodologyhasthefollowingdesirableproperties: strong
distributionsmightchangeovertime,takingvaluesinXandY,
consistency (Theorem 2), exponentially-fast decision conver-
respectively. Formally, we say that the r.v. (X,Y) has a nom-
genceonhealthysystems(Theorem3), anderrorconvergence
inal distribution P ∈ P(X × Y) and an actual distribution
guarantees (Theorem 4). In Sec. 6, we discuss our methodol- X,Y
P′ ∈ P(X×Y).1 As we are focusing on model drift (MD)
ogy and its properties. In Sec. 7, we apply our method to a X,Y
detection, we need to distinguish between two statistical hy-
diversityofsynthetic-definedsystems,visualizingandvalidat-
potheses: Thenullhypothesis(H :theabsenceofMD),under
ing our theoretical development, and in Sec. 8, we apply it to 0
which the actual distribution has the same underlying model
the N-CMAPSS dataset, a benchmark dataset of realistic sim-
ulations of turbofans; with this, we demonstrate our method’s
capability to detect faults in a real-life application. Finally, in
1Thenominaldistributionistheonedescribingthephenomenoninitsnom-
Sec.9,wesummarizeourcontributionsandproposedirections
inal, healthy, or desired behavior; the actual distribution describes the phe-
forfutureresearch. nomenoninitscurrentandpotentiallyunknownbehavior.
3asthenominaldistribution,andthealternativehypothesis(H : 2.3.3. PowerandSignificanceLevel
1
thepresenceofMD),underwhichtheactualdistributionhasa Finally, we introduce the significance level of the test and
differentunderlyingmodelthanthenominaldistribution.
thepowerofthetest[48].Thesearetheprobabilityofincurring
To test MD, we require i.i.d. samples from the actual dis- atypeIerror(erroneouslyrejectH )andtheprobabilityofnot
0
tribution (the evidence) of (X,Y) and a data-driven decision incurringatypeIIerror(successfullyrejectH whenH holds
0 1
rule. We denote by Z n = (Z j)n j=1 the n i.i.d. realizations from true),respectively.
(X,Y) ∼ P′ . A decision rule of length n, corresponds to a
X,Y
functionϕ
n
: (X×Y)n → {0,1}fromthen-sizesamplespace Definition3. Letϕ n(·)beadecisionruleoflengthn. Thesig-
((X×Y)n)tothedecisionspace({0,1}),where0meansaccept- nificance level (α ϕn) and the power (1−β ϕn) of ϕ n(·) are such
ingH and1meansrejectingH . Thecollectionofthen-size that
0 0
d toec bi esi aon der cu il se is onis sd ce hn eo mt eed ifb ϕy nΠ (·)n. ∈F Πin na ,l ∀ly n, ∈Φ N=
.
(ϕ n(·)) n∈N issaid
α
ϕn
=P(ϕ n(Z n)=1|H 0), (3)
β =P(ϕ (Z )=0|H ). (4)
ϕn n n 1
2.3. PerformanceMetricsforModelDriftDetection
Weintroducethreestandardconcepts–strongconsistency, 2.4. MutualInformation
detection time, and power and significance level – that are Ourworkproposesaninformation-drivenmethodforfault
widely used by the decision community to measure the qual- detection; in particular, we base our method on the celebrated
ity of an MD detection method, i.e., the quality of a scheme MutualInformation(MI),whichwasproposedbyClaudeShan-
Φ = (ϕ n(·)) n∈N. DuetotheequivalencebetweenMDdetection non [49] to quantify a higher order dependency between two
and fault detection, we can extend these properties to a fault r.v.s. [50]. We focus on the MI between two continuous r.v.s
detectionscheme. equippedwithajointdensity.3 LetX andY betwocontinuous
r.v.s taking values in X and Y, with a joint density
2.3.1. StrongConsistency f :X×Y→R. TheMIbetweenXandY is
X,Y
Animportantconceptinhypothesistestingisstrongconsis-
(cid:90) (cid:90) (cid:32) (cid:33)
tency[47]. Thisrequirementmeansthateventually,inthesam- f (x,y)
I(X;Y)≡ f (x,y)log X,Y dydx, (5)
ple size, a scheme converges to the correct decision (almost- X,Y f (x)· f (y)
X Y X Y
surely).
where f (·)and f (·)denotethemarginaldensitiesofX andY,
Definition1. A decision scheme Φ = (ϕ n(·)) n∈N is said to be respectivX ely,induY cedby f (·).
X,Y
strongly consistent if for any nominal and actual distributions
P ∈ P(X×Y)and P′ ∈ P(X×Y),thefollowingalmost-
X,Y X,Y
surelyconvergenceholdstrue: 3. ProblemFormalization
P(cid:18) nl →im ∞ϕ n(Z n)=i(cid:12) (cid:12) (cid:12) (cid:12)
(cid:12)
H i(cid:19) =1,∀i∈{0,1}, (1)
of
nW oie sead od ur te soss urM ciD ng,a [s 5p 1r ]e .s Ben yte td hai tn mSe ec a. n2 s,.2 w,u es din eg finth ee aco frn ac mep e-t
where P represents the process distribution of (Z n) n∈N, being work of MD detection suitable for monitoring a system in a
Z ∼ P′ ,∀n∈N. regressioncontext. Thestepsofthisformalizationareshownin
n X,Y Fig.1.
2.3.2. Finite-SampleAnalysis
3.1. GeneralModel
A refined (non-asymtotic) metric to evaluate a consistent
scheme is the number of samples required to converge to the LetV beacontinuousr.v. takingvaluesinRr (withr ∈N).
right decision [48]. For this purpose, given a sequence of bi- Thesystem(orphenomenonofinterest)isrepresentedbyVand
nary values s = (s )∞ ∈ {0,1}∞ (decisions) and i ∈ {0,1} is illustrated in Fig. 1a. In the context of input-output system
n n=1
(the right decision), the collapsing time of s is expressed by modeling,itiscommontoidentifyanexplanatory(input)sub-
col(s,i)≡sup{n∈N: s =1−i}.2 Ifcol(s,i)<∞,wesaythat setofV andaresponse(output)subsetofV [52]. Formally,the
n
scollapsestoiaftercol(s,i)observations. inputvariablesaredenotedbyX ≡ f (V),andtheoutputvari-
in
Given a sampling sequence z = (z )∞ ∈ (X × Y)∞, the ablesaredenotedbyY ≡ f (V),takingvaluesinX = Rp and
j j=1 out
sequenceofdecisionsobtainedbyapplyingaschemeΦinzis Y = Rq,respectively.4 Then,wemovefromthedescriptionof
denoted as sΦ,z ≡ (ϕ n((z j)n j=1))∞ n=1. Then, for i ∈ {0,1}, we are thedistributionofV tothedescriptionoftheinput-outputjoint
interestedinthesetSΦ
i
≡(cid:8) z∈(X×Y)∞ :col(sΦ,z,i)<∞(cid:9) . distributionof(X,Y)thatweconsiderasourobservablesystem.
A special case of this setting is illustrated in Fig. 1b, where a
Definition2. Let Φ = (ϕ n(·)) n∈N be a decision scheme and systemV isacollectionofvariables,andwepartitionasubset
i∈{0,1}. Foranyz=(z j)∞
j=1
∈SΦ
i
,thei-detectiontimeofΦis
ofthissetintoinput(X)andoutput(Y)variables.
T iΦ (z)=col(sΦ,z,i)<∞, (2)
otherwise,i.e.,ifz(cid:60)SΦ,wehavethatTΦ(z)=∞.
3Aprobabilitymeasureon(Rr,B(Rr))hasadensityifitisabsolutelycon-
i i tinuouswithrespecttotheLebesguemeasurein(Rr,B(Rr)).ForRrwitharbi-
traryr∈N,B(Rr)denotestheBorelσ-fieldofRr.
2Foranyi∈{0,1},ifs=(i)n∈N,thencol(s,i)=0. 4p∈N,q∈N,andr∈Narearbitrarynaturalnumbers.
4System input System input
Universal noise
Underlying Noise
model model
Generative model
System output System output
(a)Abstractsystem. (b)Input-outputselection. (c)Functionalgenerativemodel. (d) The additive noise model
(ANM).
Figure1:Diagramsoftheabstractionstagesofourformalframework.
3.2. FunctionalGenerativeModelviaNoiseOutsourcing SomeobservationsregardingDefinition4:
The following result offers a functional description of the • For the rest of the exposition, we focus on the rich case
distributionof(X,Y). where E[h(W)] = 0 ∈ Rq. This assumption induces no
lossofgenerality,asitissimpletoembedanynoisebias
Lemma1(see[51,Lemma3.1]5). LetX andY ber.v.staking
inη(·).7 ThisisfurtherjustifiedinAppendix G.1.
valuesinRp andRq,respectively. Thereexistsarandomvari-
ableW ∼Uniform([0,1]),independentofX,andameasurable • AsystemfollowinganANMisfullydefinedbyitstuple
function f :Rp×[0,1]→Rq,suchthat(X,Y)a=.s. (X, f(X,W)).6 (η,h,µ), anditspredictivedistributionisfullydescribed
bythetuple(η,h);hence,anactualdriftcanbedecoupled
Importantly,thislemmastatesthatanysystem(X,Y)admits intodriftsinη(·)andh(·). Wedenominatetheseasmodel
the following functional predictive structure: Y|X a=.s. f(X,W). driftsandnoisedrifts,respectively.
Therefore,ifthedistributionoftheinput(X)isknownorcon-
trolled,knowing f(·,·)issufficienttofullydescribethepredic- • Insystemmonitoring,wecanassumethatµisknownor
controlled, as this is the marginal distribution of the ex-
tive distribution of Y|X and the joint distribution of (X,Y). In
planatory(input)variable;notethatdriftsinµarevirtual
particular, f(X,W)canbeseenasagenerativemodel forY|X.
drifts. In addition, h(·) is the noise model, and its drifts
WeillustratethisinFig.1c.
donotaltertheunderlyingdeterministicinput-outputre-
lationship; hence, theycannotbeattributedtounwanted
3.3. TheClassofAdditiveNoiseModels
alterationsoftheinnerdynamicsofasystem(faults)but
UsingLemma1,wefocusontheexpressivefamilyofaddi-
to external disturbances, such as alterations in the mea-
tivenoisemodels(ANMs;seeFig.1d),whicharewidelyused
surement procedures. As neither virtual nor noise drifts
insystemtheoryandsystemmonitoringapplications[52].
canbeattributedtosystemfaultsandasfaultsdonotnec-
essarily imply either of those drifts, they are out of the
Definition4. Asystem(X,Y)issaidtofollowanadditivenoise
scopeofourstudy.
model,denotedby(X,Y)∼add(η,h;µ),ifbothfollowingprop-
ertiesholdtrue: • Asaconsequenceoftheabove,thefocusofourstudyis
todetectmodeldrifts,i.e.,disturbancesontheunderlying
(i) P(X ∈ A)=µ(A),∀A∈B(Rp), deterministic input-output relationship η(·). As distur-
bancesintheunderlyingmodelareaproxyforunwanted
(ii) (X,Y)a=.s. (X,η(X)+h(W)),
alterations in the system’s inner dynamics (faults), and
where µ is a probability measure over (Rp,B(Rp)), faults induce model drifts, we establish an equivalence
W ∼Uniform([0,1])ar.v. independentofX,andη:Rp →Rq betweenfaultdetectionandmodeldriftdetection.
and h : [0,1] → Rq two measurable functions, which are de-
3.4. ModelEquivalence
nominated as the system’s underlying model and noise model,
For the class of ANMs (Def. 4), it is crucial to have an
respectively.
equivalence relationship that can be used to represent the idea
ofMD.
5The result shown in [51, Lemma 3.1] can be traced back as a straight-
forward application of [53, Prop. 5.13] by noting that X and Y are trivially 7If E[h(W)] = b (cid:44) 0, then we can define η¯(·) and h¯(·) such that
conditionallyindependentgivenX. η¯(x) = η(x)+b,∀x ∈ Rp,andh¯(w) = h(w)−b,∀w ∈ [0,1],withthecon-
6“a.s.”standsfor“almost-surely.”Aa=.s. BmeansthatP(A=B)=1. sequencethatE[h¯(W)]=E[h(W)]−b=0∈Rq.
5
metsyS
.ddA .sySDefinition5. Let η : Rp → Rq and η : Rp → Rq be mea- Theorem1. LetXandY ber.v.swithvaluesinRp andRq,re-
1 2
surable functions. η (·) and η (·) are said to be almost-surely spectively,suchthat(X,Y) ∼ add(η˜,h˜;µ),andletη : Rp → Rq
1 2
equivalentw.r.t. µ,denotedbyη ≃ η ,ifforeveryr.v. X ∼ µ beameasurablefunction. Underthestandardassumptions,the
1 µ 2
it holds that η (X) a=.s. η (X). If η ≃ η does not hold, it is followingstatementsareequivalent:
1 2 1 µ 2
denotedasη (cid:59) η .
1 µ 2 (i) η˜ ≃ η,i.e.,H in(6).
µ 0
Remark1. It is worth noting that for an arbitrary system
(ii) XandY−η(X)areindependent.
(X,Y)∼add(η,h;µ),theminimummeansquareerror(MMSE)
estimationofYgivenXisE[Y|X]=η(X)+E[h(W)]=η(X)[54,
The proof of Theorem 1 is presented in Appendix C. As
Th.13-1]. Hence,itfollowsfortheoptimal(MMSE)estimator
shown in the proof, Theorem 1 is a consequence of a gener-
that Yˆ ≃ η, for any input distribution µ ∈ P(Rp). Equipped
µ alized version of this result – Theorem 5, see Appendix B –
with Def. 5, in the following sections, we show that MD over
whichrelaxesassumptions(i)and(ii).
thisclassofANMscanbeobservedbyusingtheMMSEesti-
Importantly,Theorem1showsthattestingthepossibilityof
matorofthereference(nominal)scenarioH .
0 modeldrift(seeSec.3.5)reducestoanalyzingthestatisticalde-
pendency(orhigherorderdependency)betweentheinputXand
3.5. ModelDriftDetection Y −η(X). Thislastvariable,whichwedenominateasresidual,
Within our class of models from Def. 4 and using the can be seen as the regression error obtained from the MMSE
almost-surely equivalence definition introduced in Def. 5, we estimatorbuiltfromH 0(thenominalmodel).
can state the hypothesis test required for dealing with model
drift. Let us consider a system with nominal distribution
add(η,h;µ) and actual distribution add(η˜,h˜;µ). We define the 4. Information-DrivenModelDriftDetection
absenceofmodeldriftasournullhypothesisH ,andthepres-
0
Inthissection,weshowourcoremethodologicalcontribu-
ence of model drift as our alternative hypothesis H . Then,
1
tion: anovelMI-basedpipelinefortestingmodeldrift. Mutual
formally,wehavethat
informationcanbeusedtodetermineiftwoarbitraryr.v.s. (A
H :η≃ η˜, and B)areindependentornot. Infact, I(A;B) = 0if,andonly
0 µ
(6) if, A and B are independent [39]. Using this expressive prop-
H :η(cid:59) η˜.
1 µ erty and driven by Theorem 1, we propose the adoption of a
As a consequence of Remark 1, if η (·) is the MMSE data-driven consistent estimation of the MI between Y −η(X)
nominal
and X toinformthedecisionaboutH andH . Toimplement
estimator built from the nominal distribution, then 0 1
η ≃ η˜ ⇔ η ≃ η˜ holds true for every µ ∈ P(Rp). this idea (in the form of a decision scheme – see Sec. 2.2 –),
µ nominal µ
Hence,η (·)canbeusedasasnapshotofthenominalsys- we adopt a distribution-free MI estimator [40] and extend its
nominal
statisticalpropertiesintoourMDdetectionproblemexpressed
temtobetestedwiththeactualunderlyingmodelviasamples
Z = (Z )n collectedfromtheactualsystemwithdistribution in(6).
n j j=1
add(η˜,h˜;µ).
4.1. Data-Driven Decision Strategy — The Residual Informa-
tionValue(RIV)Pipeline
3.6. ModelDriftandInput-ResidualDependency
The first main contribution of our work formalizes a link Returning to the problem formulated in Sec. 3.5, let
between MD and input-residual dependency. From this point (X,Y) ∼ add(η˜,h˜;µ) be a system and η : Rp → Rq be the
on,thefollowingassumptionswillbeconsidered:8 function that models its reference (nominal) scenario (H 0; in
other words, under H : η˜ ≃ η and under H : η˜ (cid:59) η), and
0 µ 1 µ
(i) E[h˜(W)]=0∈Rq. letZ = (X ,Y )n beni.i.d. samplesof(X,Y) ∼ add(η˜,h˜;µ).
n j j j=1
Our MI-based decision rule of length n, which we denote by
(ii) E[Y−η(X)]=0∈Rq. ψλ,n :(Rp+q)n →{0,1},iscomputedasfollows:
bn,dn,an
(iii) Bothr.v.s(X,Y−η(X))and(X,h˜(W))havedensities.
1. FromZ ,asamplingoftheresidualR≡Y−η(X)isbuilt:
n
R ≡(R )n ≡(Y −η(X ))n .
Wenametheseasour“standardassumptions.”9 n j j=1 j j j=1
2. ThevalueofI(X;R)–see(5)–isestimatedusinganMI
estimatorpresentedinSec.4.2. Inparticular,wedenote
assu8 mA plt th ioo nug (h iiia )s msu igm hp tt sio een ms( ti h) ea sn ad m( eii ,) nm eii tg hh et rs oe fe tm hoe sq eu si tv aa tele mn et na tn sd isb no et ch er s. sv a.s rii ln y I Xˆ n( aX n; dR) R≡ –I wbλ n, hn ,d in c( hJ n w) eas dt eh ne oe ms it nim ata ete td heM rI es( iE dM uaI l) ib ne fotw rmee an -
true;thisisbecauseY−η(X)isa.s.equaltoη˜(X)−η(X)+h˜(W)andnoth˜(W)
tion value (RIV) –, being J ≡ (X ,R )n the data and
when(X,Y)∼add(η˜,h˜;µ). n j j j=1
9Assumption(i)wasalreadydiscussedintheobservationsregardingDef.4. Iλ,n (·) the MI estimator. The estimator parameters are
Bothassumptions(i)and(ii)areformallyjustifiedinAppendix G.1andAp- (λbn ,,d bn ,d ),andtheirrolesareexplainedinSec.4.2.
n n
pendix G.2,respectively.Assumption(iii)emergesfromthecontinuousnature
3. Reject H if the RIV, Iˆ(X;R), is above or equal to a
ofoursetup.Alltheseassumptionscanberelaxedbutaretakenintoconsider- 0 n
ationforthesakeofclarityandsimplicityofourpresentation. thresholda n >0;otherwise,donotrejectH 0.
6The pipeline induced by our family of decision rules is illus- 5.1. StrongConsistency
tratedinFig.2. Theorem2. Underthestandardassumptions(seeSec.3.6),any
In summary, the decision rule corresponds to decisionscheme(seeSec.4.1)inthefamilyΨ expressedby
SC
a
s(ψ d cnλ b hn dn,n ), ed n mn λ∈,a N en ∈( ≡ aZ s(n d
0
a) ,a s∞n e= d
q).
u(a e1
T
nn[ ) cha n en e∈,∞ N
n
o,) f( ≡ wI dˆ n ea e( cX a
ic
s; r ae iR ons) n) e d, q
re
uu fiw le ennh sece Ψer oe s λuo ra f pl pl
r
≡o o( s
p
(cid:16)b i
o
ψtn i s) λv en ,e n∈ dN n du em (c≡ ·)ib
s
(cid:17)e iorb s n,,
Ψ SC
≡ 
Ψλ b,d,a :
b
1 a/
∈≈
d
o( ∈n (1−
O
)l ,) (n
e
λ∈ xN ∈p,
( (n 01 ,/ ∞3)) ), ,d l∈∈ (ℓ 01 ,( 1N /) 3,
)
 
 (8)
b,d,a bn,dn,an n∈N
parametrizedby(λ,b,d,a).
isstronglyconsistentfordetectingmodeldrift(Def.1).
4.2. TheDistribution-FreeMutualInformationEstimator
TheproofofTheorem2ispresentedinAppendix D.This
Inthissubsection,weshowthebasicstructureoftheMIes-
result shows a large regime of parameters in (8), where our
timatoradoptedforourscheme,i.e., Iλ,n : (Rp+q)n → [0,∞),
bn,dn scheme converges (with the number of samples) to the right
introduced in Sec. 4.1. This non-parametric estimator is pre-
decision almost-surely with respect to the process distribution
sentedinfulldetailin[40].
of(Z n) n∈N.
TheadoptedMIestimatorusesthedatainthreestages:
Stage one (Data-driven partition): it builds a partition of 5.2. Exponentially-FastDecisionUnderH
thesamplespace(Rp+q)usingaxis-parallelhyperplanes,which 0
Theorem3. Underthestandardassumptions(seeSec.3.6),for
perform a statistical equivalent division of the data anydecisionschemeΨinthefamilyΨ expressedby
FL
[40, Sec. III.A]. This produces a set of (data-driven) cells
A ≡ {A ℓ} ℓ∈Λ ⊆ B(Rp+q), indexed by the nodes of a binary
Ψ
≡(cid:40)
Ψλ :
b≈(n−l) n∈N,d≈(exp(n−1/3)), (cid:41)
, (9)
tree.Thistreeisgrownuntileachcellhasatmostn·b nsamples FL b,d,a a∈o(1),λ∈(0,∞),l∈(0,1/3)
[40, Eq. (8)]. Then, the resulting tree is pruned to achieve a
complexityregularizedoptimumwithafactorλ. Thispruning
wehavethat∀m∈N,
(regularization) stage is designed to ensure that the estimation
P(TΨ ((Z )∞ )<m|H )≥1−Kexp(−m1/3), (10)
iswithinaconfidenceintervalshownin[40,Corollary2]with 0 n n=1 0
aprobabilityofatleast1−δ n.10 forauniversal(distribution-free)constantK >0.11
Stagetwo(Distributionestimation):itestimates(fromdata)
both the joint distribution and the marginal distributions over TheproofofTheorem3ispresentedinAppendix E.This
the cells of A (the empirical probability), exploiting the fact resultrefinesTheorem2andsaysthatunderH 0,theprobabil-
thattheaxis-parallelconstructionimpliesthatforeveryℓ ∈ Λ, ity of arriving to the right decision (with less than m samples)
there exist A(1) ∈ B(Rp) and A(2) ∈ B(Rq) such that convergesexponentiallyfastto1.
ℓ ℓ
A = A(1) × A(2). The empirical probability is defined as
Pℓ (A)≡ ℓ 1(cid:80)n 1ℓ (J ),∀A∈B(Rp+q). 5.3. PowerandSignificanceLevel
n n j=1 A j
Stage three (MI estimation): it estimates the MI using an Theorem4. Underthestandardassumptions(seeSec.3.6),for
empiricalexpressionof(5). Thiscorrespondsto anydecisionschemeΨ = (ψ n(·)) n∈N inthefamilyexpressedin
(cid:88)
(cid:32)
P (A
)(cid:33) (9),i.e.,∀Ψ∈Ψ FL,itfollowsthat
Iˆ(X;R)= Iλ,n (J )≡ P (A )·log n ℓ , (7)
n bn,dn n
ℓ∈Λ
n ℓ Q n(A ℓ) nl →im ∞(1−β ψn)=1, (11)
whereQ n(A ℓ)≡ P n(A( ℓ1)×Rq)·P n(Rp×A( ℓ2)). α ψn ≤ K·exp(−n1/3),∀n∈N, (12)
withK >0,auniversal(distribution-free)constant.
5. PerformanceResults
TheproofofTheorem4ispresentedinAppendix F.
In this section, we state the theoretical properties of our
method illustrated in Fig. 2. We show concrete performance
results, from asymptotic to important finite-sample properties. 6. DiscussionoftheMethodologyandResults
These results support the capacity of our scheme to reach the
Regardingourmethodologicalcontributionandthesignifi-
right decision once sufficient evidence is collected from the
canceofourresults,wecanhighlightthefollowing:
input-outputdataobservedinthesystem: Z =(X ,Y )n .
n j j j=1
Beforestatingourresults,weneedtointroducethefollow- • Our method, illustrated in Fig. 2, works over the rich
ingnotation: Letu=(u n) n∈Nandv=(v n) n∈Nbetwosequences
family of ANMs. Importantly, beyond our standard as-
of non-negative numbers; first, we define 1/u ≡ (1/u n) n∈N;
sumptions,wedonotrequireanyspecialdistributionfor
second, u ≈ v ⇔ ∃C ∈ (0,∞) : lim u /v = C; third,
n→∞ n n ther.v.sthatdeterminethesystem,andwedonotimpose
u ∈ O(v n) ⇔ ∃C ∈ (0,∞),∃n 0 ∈ N : ∀n ≥ n 0,u n ≤ Cv n; anyrestrictionontheunderlyingmodel(i.e.,onη(·))and
fourth, u ∈ ℓ 1(N) ⇔ (cid:80) n∈N|u n| < ∞; and lastly, that thenoisedistribution(inducedbyh(·)intheANM).
u∈o(1)⇔lim u =0.
n→∞ n
10Whatwedenoteasdnisdenotedasδandδnin[40]. 11SeeDef.2forfurtherdetailsonthenotationT 0Ψ(·).
7Do not reject
Output
Universal noise
Decision output:
Joint
sampling Joint input-residual samples
Noise model Model noise
Compare
Residual
Input Underlying model Unnoised output
with
System
Input-residual EMI
Reject
Model to be tested Predicted output
Decision output:
Figure2:Blockdiagramforthepipelineinducedbyourfamilyofdecisionrules:ψλ,n (·).
bn,dn,an
• From Ψ , we provide a concrete parameter regime to
FL
practitioners–see(9)–toensurestrongconsistency,an
Table1:Expressionsforηθ,δ(x1,x2)intheexploredsystems.
exponentially-fastdecisiononH ,anderrorconvergence
0 System Valueofη (x ,x )
to0inthesamplesize. θ,δ 1 2
Linear (c +δ )x +(c +δ )x
• AnydecisionschemeΨ ∈ Ψ FL hasanexponentially-fast Polynomial (c1 +δ1 )x1 2+(c2 +δ2 )x2 3
decision convergence under H
0
(see Theorem 3). This
Trigonometric
(A1 +δ1 )si1
n(x
x2 +ϕ2 +2
δ )
1 1 2 2
finite-samplesizebehaviorisremarkableanddistinctive MLP fMLP(x ,x )
from other existing methods. To the best of our knowl- θ,δ 1 2
edge, this exponential velocity for detecting H is not
0
observedinothermethodsforfaultdetection.
that the system is non-drifted from its reference scenario, i.e.,
• Ourmethodisunsupervisedinthesensethatitdoesnot
add(η ,h;µ)=add(η ,h;µ).
θ,0 θ
requireexamplesfromfailurescenariostobeimplemented.
In practice, we only need healthy data or a phenomeno-
7.1. ExperimentalSetup
logicalinsightaboutthesystemtostartmonitoringitand
Our setup for analyzing MD detection considers a para-
detectitsfaultsviamodeldriftdetections.
metric system (X,Y) with an un-drifted nominal distribution
add(η ,h;µ)andapotentiallydrifteddistributionadd(η ,h;µ).
Inthefollowingtwosections,weapplyourmethodtoprac- θ θ,δ
Inthissetting,thenominalmodelforY givenXcorrespondsto
ticalscenarios,startingwithsystemsthathavesyntheticdistri-
η (·),andthevalueofδquantifiesthemodeldrift. TheMDde-
butions(seeSec.7)andfinishingwithabenchmarkdatasetof θ
tectorusesactualdataZ ,i.e.,ni.i.d. samplesfromtheactual
turbofanengines(seeSec.8). n
distribution(X,Y)∼add(η ,h;µ)totesttheactualunderlying
θ,δ
model(η (·))withthenominalmodel(η (·)).
θ,δ θ
7. NumericalAnalysisonSyntheticDistributions
For simplicity, in this section, we restrict our analysis to a
2-dimensional input space, a univariate output space, and a 2-
Inthissection,weperformanumericalanalysistovalidate
dimensionalδ-space,i.e., p = 2,q = 1,andν = 2. Weexplore
ourpipelinebyapplyingourmethodologytoseveralsynthetic
foursystems,denominatedasLinear,Polynomial,Trigonomet-
parametric systems. All experiments in this section are sub-
ricandMLP;theirexpressionsforη (·)areshowninTable1.12
jected to an error-bar analysis in Appendix I. We consider θ,δ
Additionaldetailsforallthedistributionsandfunctionsusedin
systems within the family of ANMs (see Def. 4) determined
by a parametric function expressed by η : Rp → Rq and ourexperimentalsetup,includingmarginaldistributions,noise
h : [0,1] → Rq. The parameter for η
(θ
·) is θ ∈ Θ ⊆ Rν,
models,andthevaluesofthecoefficientsthatmakeupthenom-
where ν ∈ N is the dimensionality of Θ,θ which varies accord- inalparameters(θ),arecontainedinAppendix H.
Forallcases,thenominalsystem(H )correspondstoη (·).
ing to the system in consideration. For these parametric con- 0 θ,0
In our experiments, we range δ and δ from −0.15 to 0.15
structions, we consider a nominal system to be determined by 1 2
its nominal parameters θ, i.e., (X,Y) ∼ add(η ,h;µ). On the
θ
otherhand,adriftedsystemisdescribedbyitsnominalparam- 12fMLP is the function defined by a simple multi-layer perceptron with a
θ,δ
eters (θ) and its drift; the latter is expressed as a perturbation singlehiddenlayeroftwounitsandparametersθdisturbedbyδ.Inparticular,
δ=(δ ℓ)ν
ℓ=1
∈Rν. Inconsequence,adriftedsystemisexpressed δ th1 ea fin rd stδ h2 id di ds etu nrb una id t.di Wtiv ee fily xt δh ℓe =we 0i ,g ∀h ℓts >fro 2m ,inth oe ufi rr es xt pa en rd imse ec no tsnd ovin erpu tht eun Mit Lt Po
by (X,Y) ∼ add(η θ,δ,h;µ). In particular, δ = 0 ∈ Rν implies system.
8with a step of 0.0015. Within this range, it holds that System
δ = 0 ⇔ η θ ≃ µ η θ,δ. Consequently, applying our method to Linear Polynomial Trigonometric MLP
observationsfrom(X,Y) ∼ add(η ,h;µ)willraiseanMDde- 0.1 0.75 θ,δ
tection(H )if,andonlyif,δ(cid:44)(0,0). 0.0 0.50
1 0.25
To better visualize our method, we compute the RIV, i.e., 0.1
0.00
the input-residual EMI (Iˆ(X;R)), and show its value prior to
n
thresholding it. This is done for every δ within the aforemen- 0.1 0.75
tioned range. These MI estimations are made using parame- 0.0 0.50
0.25
ters from the range expressed in (9); therefore, each decision 0.1
0.00
scheme Ψλ ∈ Ψ ⊆ Ψ satisfies the hypotheses
b,d,a FL SC 0.1 100 of Theorem 2, 3, and 4. In particular, we choose
λ = 2.3·10−5 ∈ (0,∞),d = (exp(n−1/3)) n∈N ≈ (exp(n−1/3)) n∈N, 0.0
and b = (wn−l) n∈N ≈ (n−l) n∈N with w = 5 · 10−2 and 0.1 101
l = 0.167 ∈ (0,1/3). As we simulated a fixed amount of
n = 2000 samples, the reported EMIs are computed with 1 value 1 value 1 value 1 value
b n ≈0.014051andd n ≈1.082605. Figure3:NumericalresultsforourMI-basedmodeldriftdetectionmethodand
Finally, we consider two baseline strategies with which to baselinesonparametrizeddrifts.
compareourmethod. Thefirst,whichwedenoteastheCorre-
lation method, is the maximum absolute value of the Pearson
with X (whoseweightisdisturbedbyδ )incontrastwiththe
correlationcoefficientsbetweentheresidualandeachinputco- 2 2
quadraticdependenceofY withX (whoseweightisdisturbed
ordinate;13 weselectthismethod,astheinput-errorcorrelation 1
byδ ). Thisimpliesthatδ -disturbancesinducestrongerinput-
1 2
isusedasacommonvalidationmeasureforsystemidentifica-
residualdependencies(cubic)thanδ -distrubances(quadratic).
1
tion [55, Ch. 9]. The second strategy, which we denote as the
Finally, regarding the MLP system, we can see oblique privi-
RMSE method, is the root mean squared error computed from
legedirections;thispatternisduetoasymmetricnon-linearities
theresidual;supportingthisselection,therearedifferentworks
induced by the activation function of the system. We remark
basedonthresholdingRMSE,bothinFDI(e.g.,[7,9,10])and
thatthesecolormaps,orhigh-dimensionalversionsofthem,can
conceptdriftdetectionappliedtoregression[33].
bebuiltforanysystemthatcanbeidentifiedwithawhite-box
model to have a clear phenomenological interpretation of its
7.2. NumericalResultsandDiscussionsaboutourMethod
possibledrifts.
Figure3showsthevaluesobtainedforallfoursystemsus-
ing our method and both baseline methods. Every single cell 7.2.1. Comparison
ofeverycolormaphastheaveragevalueover10differentseeds Contrastingourmethodwiththebaselines,wecanmakethe
forthatspecificδvalue, method, andsystem. Wecanseethat followingobservations. Regardingcorrelation,forthePolyno-
forallsystems,theresidualinformationvalue(RIV)reaches0 mial system, the MAPC approximates zero across the region
when δ = (0,0). In consequence, for any threshold sequence defined by δ = 0. This means that this method is unable to
2
a∈o(1),ourmethodreturnstherightdecisiononH . Inaddi- detectadriftcausedbyδ (cid:44) 0whenδ = 0. ThislackofMD
0 1 2
tion,wecanseeineverymodelaregionofδvaluesaroundthe observabilityisaconsequenceofthequadraticdependencybe-
H point,whichwouldraisefalsenegativesastheirRIVsare0; tweentheinputandtheresidualswhenδ =0becausethecor-
0 2
thisisduetothedifficultyofdetectingdependencyinslightly relationisunabletocapturehigh-orderdependencies.Thisisin
non-independentr.v.s. Ingeneral, asδisfartherfrom(0,0), it clearcontrastwiththecapacityofourMI-basedresidualanal-
iseasiertoidentifyinput-residualdependencies. ysis, as the MI captures high-order dependencies. As for the
Inaddition,wecanseethateachRIVcolormapgivesusan RMSE, we can see a local minimum at δ = (0,0) for all col-
insightintotheunderlyingmodelsubjectedtothedrift. Forex- ormaps. However, the value of the local minimum is system-
ample, the Linear and Trigonometric systems have colormaps dependent, whichimpliesthenecessityofasystem-dependent
where the RIV increases monotonically with ||δ|| following no threshold. This design is not straightforward and is a limita-
privileged directions (isotropic monotonicity); hence, if we tionof thiserror-based strategy.14 Incontrast, ourRIVs reach
weight equally drifts in δ and δ , the RIV is a clear indicator zerounderH independentlyofthesystem. Thisisexpressed
1 2 0
ofthedrift’smagnitude. ThegreaterRIVvaluesintheLinear intheexponentiallyfastconvergenceofthedecisionunderH
0
system,incontrastwiththeTrigonometricsystem,expressthat asshowninTheorem3.
itissimplertodetectmodeldriftintheLinearsystem.Inregard
tothePolynomialsystem,wecanseeaprivilegeddirectionof 7.3. ComplementaryAnalysis—AutoregressiveSystems
RIV increment (anisotropic monotonicity); this is the δ 1 = 0 We complement our results by applying our method and
axis. ThereasonforthisprivilegeisthecubicrelationshipofY bothbaselinesonautoregressive(AR)systems. TheseARsys-
13WedenotethisasMAPC(X,R)≡max{|corr(X1,R)|,|corr(X2,R)|};MAPC 14There exists a systematic study for error-based drift detection meth-
standsforMaximumAbsolutePearsonCorrelation. ods[33].
9
dohtem
VIR
noitalerroC
ESMR
)sruo(
dohtem
dohtem
eulav
2
eulav
2
eulav
2
1.0 0.0 1.0 1.0 0.0 1.0 1.0 0.0 1.0 1.0 0.0 1.0
]stib[
VIR
)R,X(CPAM
)R(ESMRSystem
Table2:Expressionsforηθ,δ(d,u)inautoregressivesystems.
ARX NARX
0.1 0.6 System Valueofη (d,u)
θ,δ 0.0 0.4
ARX (c +δ )d+(c +δ )u 0.1 0.2
1 1 2 2 0.0
NARX (c +δ +c exp(−d2))·d+(c +δ )·u2
3 1 4 5 2
0.1 0.75
0.0 0.50
0.25
0.1
0.00
temsaredescribedby
0.1
D
j
=η θ,δ(D j−1,U j)+H j, (13) 0.0 100
Y = D +W , (14) 0.1
j j j
whereallU, H,andW areindependentunivariater.v.s. repre- 1 value 1 value
sentingtheexogenousinput,themodelnoise,andthemeasure-
Figure4:NumericalresultsfortheRIVmethodandbaselinesonparametrized
mentnoise, respectively. Inthesesystems, thenominalmodel driftsoverARsystems.
isstillη (·,·). WeperformexperimentsonalinearARsystem
θ,0
(ARX) and a non-linear AR system (NARX); their expressions
(CMAPSS) turbofan model developed at NASA [56] using as
forη (·,·)arepresentedinTable2.15 FortheseARsystems,an
θ,δ
input sampling corresponds to (X )n = (Y ,U )n ; hence, inputrealrecordingsofenvironmentalvariablesobtainedinreal
j j=1 j−1 j j=1
commercialflights. TheN-CMAPSSdatasetiswidelyusedas
the temporal dependency between instances of the input im-
abenchmarkinthePHMcommunity.
plies that Z is not an i.i.d. sequence. We experimented with
n
thesesystemstoanalyzethecapabilitiesofourmethodbeyond
8.1. DatasetDescription
itsformalhypotheses.
In Fig. 4, we show the results of applying our method and The N-CMAPSS dataset provides 8 sub-datasets denomi-
both baselines using the same amount of samples (n) and pa- nated from DS01 to DS08; our work focuses on DS04. Each
rameters of the MI estimator (λ, b, and d; shown in Sec. 7.1) sub-datasetcontainssimulationsforanumberofturbofanunits
to both ARX and NARX systems. We can see that the main thatvariesaccordingtothesub-dataset. Theseunitsarealready
observations discussed in Sec. 7.2 remain valid for both sys- divided and specified as train or test units. Each turbofan unit
tems. Inparticular,wegetzeroRIVunderH andanincrease issimulatedinasequenceofflightsofthesameclass—short-
0
of the RIV when moving away from δ = (0,0). We also ob- length,medium-length,andlong-lengthflights;inDS04,there
serve an approximately isotropic monotonicity of the RIV for areonlyunitswithmediumandlong-lengthflights. Eachcom-
the ARX system; this is in contrast with the clear asymmetric plete flight is referred to as a cycle of the unit, which corre-
pattern for the NARX system. This last asymmetric informa- spondswiththerecordingofasimulatedflight. Eachrecording
tion pattern can be attributed to the non-linearities of the sys- is a multivariate series sampled at 1 Hz during the time inter-
tem.Moreover,wecanstillobservetheinabilityoftheCorrela- valwherethealtitudeoftheunitisabove10000ft(3048m).
tionmethodtoidentifynon-trivialdrifts(attributedtoquadratic The attributes of these recordings are divided into 4 scenario
input-residual dependencies; see MAPC values for the NARX descriptors, 14 sensor measurements, and 14 virtual measure-
system at δ = 0) and the system-dependent non-zero minima ments. Inaddition,thedatasetprovidestheground-truthmodel
1
oftheRMSEmethod. healthparameters, theremainingusefullife(RUL),andauxil-
Our results for the AR systems demonstrate the practical iarydatasuchastheflightclassandhealthstate.
potentialofourmethodinrealisticscenarios. Thiscapabilityis We discarded the virtual measurements to ensure a realis-
especiallyusefulforcontrolledsystems,astheyhaveaninher- ticapplicationofourmethodology;consequently,webuiltour
ent temporal dependence embedded in their signals due to the nominalmodelsandcomputedtheRIVsonlywiththescenario
controlloop. descriptors and the sensor measurements. In Table 3, we de-
tailthevariablesweconsiderinourpipeline.16 Todescribethe
application of our methodology, we refer to each variable by
8. StudyCase—N-CMAPSSDataset eitheritsnumberIDoritssymbolasasubscriptofV;e.g.,we
refertothefuelflowbyeitherV orV .
Wf 5
Inthissection,weapplyourdata-drivenfaultdetectionstrat-
Allunitsstartwitharandomsmalldegradationandaresub-
egy to the N-CMAPSS dataset [41]. This dataset corresponds
jectedtoincreasingnoisydegradationthroughouttheircycles.
to aircraft engine (turbofan) run-to-failure simulations under
Thisdegradationcanevolveinanormalorabnormalway,fol-
realistic flight scenarios; these simulations are run under the
lowing a linear or exponential fashion respectively. The latter
Commercial Modular Areo-Propulsion System Simulation
16LPC,HPC,LPT,andHPTstandforlowpressurecompressor,highpres-
15In-depthdetailsfortheseconstructionsareinAppendix H. surecompressor,lowpressureturbine,andhighpressureturbine,respectively.
10
dohtem
VIR
noitalerroC
ESMR
)sruo(
dohtem
dohtem
eulav
2
eulav
2
eulav
2
1.0 0.0 1.0 1.0 0.0 1.0
]stib[
VIR
)R,X(CPAM
)R(ESMRTable3:VariablesofinterestintheN-CMAPSSdataset.
Category NumberID Symbol Description Unit
1 alt Altitude ft
2 Mach FlightMachnumber –
Scenariodescriptor
3 TRA Throttle-resolverangle %
4 T2 Totaltemperatureatfaninlet ◦R
5 Wf Fuelflow pps
6 Nf Physicalfanspeed rpm
7 Nc Physicalcorespeed rpm
8 T24 TotaltemperatureatLPCoutlet ◦R
9 T30 TotaltemperatureatHPCoutlet ◦R
10 T48 TotaltemperatureatHPToutlet ◦R
11 T50 TotaltemperatureatLPToutlet ◦R
Sensormeasurements
12 P15 Totalpressureinbypass-duct psia
13 P2 Totalpressureatfaninlet psia
14 P21 Totalpressureatfanoutlet psia
15 P24 TotalpressureatLPCoutlet psia
16 Ps30 StaticpressureatHPCoutlet psia
17 P40 Totalpressureatburneroutlet psia
18 P50 TotalpressureatLPToutlet psia
starts at some number of cycles determined by the simulation ofallvariablesshowninTable3,i.e.,V ≡ (V )18 (takingval-
ℓ ℓ=1
followingcriteriaregardingenergyusageoftheunit’ssubcom- ues in R18) is the r.v. representing the system (see Fig. 1a).
ponent. In Table 4, we summarize the characteristics of the Next, we define the input and output. As this selection is left
unitssimulatedinDS04. Werefertothenumberofcyclesoc- to the user, we will choose an arbitrary variable from Table 3
curring prior to the onset of the exponential evolution for the with ID number k ∈ {1,2,...,18} as the target (response or
degradationashealthyflights. output) and will consider all the rest as explanatory (input).
Thedegradationisparametrizedwiththemodelhealthpa- This means that considering V as the target, the output is the
k
rameters(MHPs). InTable5,wedetailtheavailableMHPsin r.v. Y ≡ V (taking values in R), and the input is the r.v.
[k] k
theN-CMAPSSdataset(allMHPsareadimensional). Wecan X [k] ≡(X j,[k])1 j=7 1 ≡(V ℓ) ℓ∈{1,2,...,18}\{k} (takingvaluesinR17)–see
observethattheseMHPsareanalogoustothedriftparameters Fig.1b.
(δ) described in Sec. 7. Hence, we refer to each MHP by its ThenextstepistobuildanominalmodelforY |X . For
number ID as a subscript of δ, e.g., we refer to the LPT effi- [k] [k]
that, we need to obtain an approximation of the MMSE esti-
ciencymodifierbyδ .
9 mator of Y given X ; we denominate the optimal model as
[k] [k]
The units of a particular sub-dataset are only subjected to η : R17 → R. Weapproximateη (·)withamultilayerper-
[k] [k]
a particular kind of degradation. Units in DS04 are subjected ceptron(MLP)usingdatafromthefirstflightsofthetrainunits,
onlytofandegradations,i.e.,alterationsononlyfanefficiency
specifically, the first 15 cycles of units with medium-length
and fan flow modifiers. This means that in DS04, all from δ 3 flights(IDs1and3)andthefirst10cyclesofunitswithlong-
to δ 10 are fixed to 0, and only δ 1 and δ 2 are able to have non- lengthflights(IDs2,4,5,and6).Weusedthefirstcyclestoen-
zerovalues,implyingthat(δ 1,δ 2)=(0,0)representsaperfectly suredatacamefromnon-abnormaldegradedunits(seeFig.5).
healthyturbofan. InFig.5,weshowthetrajectoryoffanmod-
The18MLPsusedtomodeleachpossibletargetsharethe
ifiers as the unit’s number of cycles increases. We can see a
same properties and training hyperparameters: each MLP has
noisydegradationclosetoδ = (0,0)overthefirstflightsanda
4hiddenlayerswith1024hiddenunitsperlayer. Theinputat-
driftawayfrompoint(0,0)asthenumberofcyclesincreases.
tributesarenormalizedwithastandardscaler.Thelossfunction
Inallsub-datasets,thedegradationremainsconstantduringthe
istheMSEloss. TheoptimizerisADAM[57]withalearning
courseofacycle.Forthesakeofrealism,wenotethateachunit
rateof10−6 andvaluesofβ = 0.9andβ = 0.999. Thetrain-
followsitsowntrajectory,thatthedegradationisnoisy,andthat 1 2
ingisdonewithabatchsizeof256samplesandearlystopping
thereisnoperfectlyhealthyturbofaninanycase.
with32toleranceepochsandamaximumof256epochsusing
30%ofthenominaldataasvalidation.
8.2. MethodologySpecificsforN-CMAPSS
Building a nominal model is the only prerequisite of our
Thefirststepinapplyingourmethodologyistodefinethe method. This nominal model is built only with healthy flights
system. Wewillconsiderthataturbofanisasystemcomposed oftrainunits;hence,theunsupervisedcapabilityofourmethod-
11Table4:Summaryoftheunitssimulatedinsub-datasetDS04.
Division Flightclass UnitID Healthyflights Totalflights
1 21 87
Medium-length
3 21 100
Train 2 16 73
4 15 69
Long-length
5 16 100
6 16 83
7 21 87
Medium-length 8 21 99
Test
9 21 73
Long-length 10 16 85
Table5:ModelhealthparametersintheN-CMAPSSdataset. 0.00 Unit 1 100
Unit 2
0.02 Unit 3 80 #ID Symbol Description Unit 4
1 fan eff mod Fanefficiencymodifier 0.04 U Un ni it t 5 6 60
2 fan flow mod Fanflowmodifier 0.06 Unit 7
3 LPC eff mod LPCefficiencymodifier 0.08 U Un ni it t 8 9 40
4 LPC flow mod LPCflowmodifier 0.10 Unit 10 20
5 HPC eff mod HPCefficiencymodifier
0.12
6 HPC flow mod HPCflowmodifier
0.20 0.15 0.10 0.05 0.00
7 HPT eff mod HPTefficiencymodifier Value of fan_eff_mod ( 1)
8 HPT flow mod HPTflowmodifier
(a)Trajectoriesforthecompleteusageoftheunits.
9 LPT eff mod LPTefficiencymodifier
10 LPT flow mod LPTflowmodifier
50
0.000 Unit 1
Unit 2
Unit 3 40 0.002 Unit 4
ologytodetectfaultsisclear, asthereisnodatacomingfrom Unit 5 30
0.004 Unit 6
degraded units involved prior to the actual test. This is espe- Unit 7
ciallyusefulinscenarioswithascarcityoffaultyobservations. 0.006 U Un ni it t 8 9 20
Unit 10
10
0.008
8.3. NumericalResults—RIVandDegradation
0.010 0.008 0.006 0.004 0.002 0.000
Weareinterestedinanalyzinghowtheresidualinformation Value of fan_eff_mod ( 1)
value(RIV)evolvesasthedegradationoftheunitsevolves.For
(b)Trajectoriesforthefirst50cycles.
thisreason,weassociateaRIVtoeachcycleofeachunit. This
canbedonebyusingthewholerecordingofthatparticularcy- Figure5:Trajectoriesofthefanmodifiers(δ1andδ2)overunits’usage.
cleandunittoobtaintheinputandoutput(whichdependonthe
targetedvariable)asasamplingofthesysteminthatparticular
state. ThesampledinputisfedtotheMLPmodeltocompute Tocomplementthisanalysis,inFig.7,weshowhowRIVs
theresidualsandthentoobtaintheinput-residualEMI,i.e.,the correlatewithfaultmagnitudesforthedifferentpossiblemodels
RIV(seeFig.2)ofthatparticularunitandcycle. and different units. In Fig. 7a, we show the RIV-degradation
InFig.6,weshowhowtheRIVevolvesineachtestunitfor correlation for each unit and each possible targeted variable.
amodelwithP24(k = 15)asitstarget. Wealsoshowhowthe ThewhitecellsinFig.7aareundeterminedcorrelationscaused
faultmagnitude(||δ||)evolvesincomparison.Intheseexamples, bya0RIVsignalforallcyclesofthatspecifictargetedvariable
a detection is raised when the RIV goes above 0. This occurs andunit. InFig.7b,wegroupthecorrelationsbytrainandtest
intheneighborhoodofcyclenumber50ofeachunitwhenthe unitsandshowtheirsortedaverage;weremovethemodelsfor
fault magnitude goes above approximately 0.01. Importantly, T24, T30, and Nc of this analysis due to their undetermined
weobserveaclearcorrelationbetweentheRIVand||δ||. correlationatunitID3. Itiseasytoseethattheelectionofthe
12
)2
( dom_wolf_naf
fo eulaV
)2
( dom_wolf_naf
fo eulaV
rebmun
elcyc
:roloc
rekraM
rebmun
elcyc
:roloc
rekraM1.0
1
0.6 RIV 0.15 0.6 RIV 0.15 2 0.9 Fault magnitude Fault magnitude 3 0.4 0.10 0.4 0.10 4 5 0.8
6 0.7
0.2 0.05 0.2 0.05 7
8 0.6
0.0 0 25 50 75 0.00 0.0 0 50 1000.00 19 0 0.5
Cycle number Cycle number
(a)UnitID7. (b)UnitID8. Targeted variable
(a)Detailedcorrelationforallmodelsandunits.
0.6 RIV 0.15 0.6 RIV 0.15
Fault magnitude Fault magnitude
0.4 0.10 0.4 0.10 1.00 Train units
0.95 Test units
0.2 0.05 0.2 0.05 0.90
0.85
0.0 0.00 0.0 0.00
0 20 40 60 0 25 50 75 0.80
Cycle number Cycle number 0.75
(c)UnitID9. (d)UnitID10. 0.70
0.65
Figure6:Degradationmagnitude(||δ||)andRIV(k=15)evolutionoverusage
fortestunits. Targeted variable
(b)Trainandtestunits’averagecorrelation.
targetvariableiscrucialtoobtainbetterRIVsintermsoftheir
Figure7:PearsoncorrelationbetweentheRIVsandthefaultmagnitude(||δ||).
correlationwiththefaultmagnitude;inthiscase,P24(k = 15)
is the best variable to target as an output. These correlations
showthepotentialoftheRIVvaluestoestimatethehealthstate vectors of 17 components; if we concatenate these RIFs, we
ofthesystem. obtaina306-dimensionalvectordescribingthefault,i.e.,asig-
nature vector. To evaluate the signature capability to describe
8.4. BeyondDetection—ResidualInformationFeatures(RIF) thefault,wetrainanMLPregressorusingthevectorofconcate-
natedRIFsastheinputand||δ||asthetarget;forthisobjective,
AlthoughtheresultsshowninSec.8.3validateourmethod-
weusealldataavailablefromtrainingunits. TheMLPusedin
ologyinarealisticbenchmarkdataset,theseresultscanbeim-
the signature-||δ|| regression has 4 hidden layers with 128 hid-
proved. The RIVs are estimations of the MI between X and
[k]
R ≡ Y −ηˆ (X ); i.e., anEMIbetweena17-dimensional den units per layer. The signature coordinates are normalized
[k] [k] [k] [k]
withamin-maxscaler. ThelossfunctionistheMSEloss. The
(X ) and a unidimensional (R ) r.v. The estimator we are
[k] [k]
optimizerisADAMwithalearningrateof10−6,andvaluesof
using is tailored for low dimensionalities (see [58]); hence, a
β =0.9andβ =0.999. Thetrainingisdonewithabatchsize
straightforward way to enrich our analysis is not to compute 1 2
Iˆ(X ;R ) but to compute Iˆ(X ;R ) for each of256samplesandearlystoppingwith1024toleranceepochs
n [k] [k] n j,[k] [k]
j ∈ {1,2,...,17}. Thismeanscomputing17estimationsofMI andamaximumof32768epochsusing30%ofthedatafrom
thetrainingunitsasvalidation.
ofunivariatepairsinsteadofasinglevalueofEMIinvolvinga
InFig.10,weshowthetrue(real)andestimatedfaultmag-
high-dimensionalityvariable. Inpracticalterms,insteadofob-
nitude(||δ||)overeachtestunitusageandtherootmeansquared
tainingasinglevalue,weareobtainingarichvector;wename
error (RMSE) of the estimation. These estimations are made
thisvectorastheresidualinformationfeature(RIF).
with the signature-to-magnitude MLP regressor mentioned
In Fig. 8, we show how the RIFs evolve in each test unit
foramodelwithT50(k = 11)asitstarget. Wecanseeaclear above. Remarkably,here,wecanobservethepredictivepower
ofourinformationsignaturestodescribeandestimatethehid-
correlation between the RIF coordinates and the degradation.
InFig.9,weshowhowRIFmagnitudes(||RIF||)correlatewith dendegradationprofileofatestturbofan.
faultmagnitudes(||δ||)forthedifferentpossiblemodelsanddif-
ferentunits. InFig.9a, weshowthe||RIF||-||δ||correlationfor 8.5. FinalDiscussion
eachunitandeachpossibletargetedvariable,andinFig.9b,we Theresultsinthissectionvalidateourformalcontributions
showthesamecorrelationgroupedbytrainandtestunitssorted and synthetic analysis in a realistic benchmark scenario: N-
byaverage. Wecanmakethesameobservationsaboutthesere- CMAPSS.Moreover,wehavebuiltanobservablevaluetode-
sults as in Sec. 8.3 with two main differences: We are getting scribehiddendegradationandincipientfaultsinturbofans.Bet-
bettercorrelationswhencomputingcomponent-wiseEMIs,and ter models, such as physics-informed ones, a better tuning of
weobtainamoredetaileddescriptionofthefaultwhencomput- hyperparameters, and a consideration of the time dynamics of
ingafeature(RIF)insteadofasinglevalue(RIV). thefaultcouldsignificantlyimprovetheseresults. Thismeans
It should be noted that for each particular unit and cycle, thatevenwithsimpledata-drivenmodelsandnoknowledgeof
we have 18 (one per targeted variable) possible RIFs, i.e., 18 thesystemdynamicsordegradationmechanisms,itispossible
13
]stib[ VIR
fo
eulaV
]stib[
VIR
fo
eulaV
) |||| ( edutingam
tluaF
) ||||
( edutingam
tluaF
]stib[ VIR
fo
eulaV
]stib[
VIR
fo
eulaV
) |||| ( edutingam
tluaF
) ||||
( edutingam
tluaF
noitalerroc
nosraeP
||
||
- VIR
DI tinU stinu niarT
stinu
tseT
42P
tla
05T
hcaM
04P
ART 2T
03sP
42T
84T
03T 84T
fN
05T
2P
51P 2P
51P
12P
12P
42P 03sP
05P
04P 05P
fW
fN
hcaM
cN fW
tla 2T ART
noitalerroc
nosraeP
||
|| - VIR1 1
1.0 1.0
6 6
0.5 0.5 12 12
17 0.0 17 0.0
0 10 20 30 40 50 60 70 80 0 20 40 60 80
Cycle number Cycle number
(a)UnitID7. (b)UnitID8.
1 1
1.0 1.0
6 6
0.5 0.5 12 12
17 0.0 17 0.0
0 10 20 30 40 50 60 70 0 10 20 30 40 50 60 70 80
Cycle number Cycle number
(c)UnitID9. (d)UnitID10.
Figure8:RIF(Iˆ n(Xj,[k];R[k]))1 j=7 1evolutionfork=11overusagefortestunits.
1.0
1
2 0.9 RMSE: 0.029 RMSE: 0.022
3 0.20 Real magnitude 0.20 Real magnitude
4 0.8 0.15 Estimated magnitude 0.15 Estimated magnitude 5
6 0.7 0.10 0.10
7
8 0.6 0.05 0.05 19 0 0.5 0.00 0 20 40 60 80 0.00 0 20 40 60 80 100
Cycle number Cycle number
Targeted variable (a)UnitID7. (b)UnitID8.
(a)Detailedcorrelationforallmodelsandunits.
RMSE: 0.059 RMSE: 0.026
0.20 Real magnitude 0.20 Real magnitude
1.00 0.15 Estimated magnitude 0.15 Estimated magnitude Train units
0.95
Test units 0.10 0.10
0.90
0.05 0.05
0.85
0.00 0.00
0.80 0 20 40 60 0 20 40 60 80
0.75 Cycle number Cycle number
0.70 (c)UnitID9. (d)UnitID10.
0.65
Figure10:Realandestimatedvaluesof||δ||usingRIF’ssignatures.
Targeted variable
(b)Trainandtestunits’averagecorrelation.
tionships within the ANM family. On the theoretical side, we
Figure9: PearsoncorrelationbetweenRIFmagnitudesandthefaultmagni- formallystatethelinkbetweenfaultsandmodeldriftandprove
tudes. the equivalence between the latter and an independence test.
Onthepracticalside,ourproposedFDmethoddoesnotrequire
priorknowledgeoffaultydatatomakeaccuratedecisionsand
to build a successful fault descriptor. To summarize, in addi-
canbeappliedtocontinuousphenomenawithnorestrictionson
tiontofaultdetection,ourmethodologycanbeusedtodevelop
the regression learning algorithm or expert knowledge used to
diagnosisandprognosticapproachesforcomplexinput-output
captureitshealthydynamics. Thefollowingpointssummarize
systems.
thekeycontributionsofourwork.
9. SummaryandFuturePerspectives • We showthat thefault detection taskover therich class
ofadditivenoisemodelscanbeequivalenttothemachine
Inthiswork,weintroduceanovelinformation-drivenfault learning problem of testing independence (distribution-
detection (FD) method and a new theory for model drift de- free) between a regression input and its correspondent
tection tailored to systems with continuous input-output rela- regressionresidual.
14
)j(
rebmun
.drooC
)j(
rebmun
.drooC
noitalerroc
nosraeP
||
||-||FIR||
DI tinU
stinu
niarT
stinu
tseT
05T 42P
tla
03sP
hcaM ART
04P
2T
51P
42T
12P
03T 84T
2P
05T
03T
51P
fN
2P 12P
84T
42P
fW
03sP
05P
04P
ART
05P fN
hcaM
cN
2T
fW
cN tla 42T
noitalerroc
nosraeP
||
||-||FIR||
]stib[
)]k[R;]k[
jX(nI
]stib[
)]k[R;]k[
jX(nI
)j(
rebmun
.drooC
)j(
rebmun
.drooC
)
||||
( edutingam
tluaF
)
||||
( edutingam
tluaF
)
||||
( edutingam
tluaF
)
||||
( edutingam
tluaF
]stib[
)]k[R;]k[
jX(nI
]stib[
)]k[R;]k[
jX(nI• We propose a new decision scheme for fault detection residual dependency even outside our assumptions of the ab-
using the residual information values (RIVs), which are sence of bias, i.e., assumptions (i) and (ii) of our standard as-
mutualinformationestimations. sumptions (see Sec. 3.6). Before making the statement of this
generalizedtheorem,weneedtointroduceabroaderversionof
• We state a range of parameters for the MI estimator to
Def.5,whichenablesustoworkwiththeclassofequivalence
makeourmethodstronglyconsistent,abletoachieveex-
wedenoteasperfectlybiasedalmost-surelyequivalentmodels.
ponentially fast decision under H , and able to achieve
0 This definition captures the idea of models that are equivalent
both test power convergence to 1 and significance level
inthesenseofDef.5buthaveaperfectbiasbetweenthem,i.e.,
exponentialconvergenceto0.
anoffset.
• Weperformnumerousexperimentsonsyntheticsystems
for which we show the discrimination ability of our Definition6. Letη :Rp →Rq andη :Rp →Rq bemeasur-
1 2
methodforfaultdetection. Importantly,weobservethat ablefunctions,andc∈Rq. η (·)andη (·)aresaidtobealmost-
1 2
ourmethodevenworksforsystemsoutsidethei.i.d.sam- surelyequivalentw.r.t. µwithabiasc,denotedbyη ≈c η ,if
1 µ 2
plingassumption. for every r.v. X ∼ µ it holds that η (X) a=.s. η (X)+c. If there
1 2
• We validate our method in the benchmark N-CMAPSS does not exist any c ∈ Rq such that η 1 ≈c µ η 2, it is denoted as
η (cid:48) η .
dataset,evidencingitsusabilityinrealisticscenarios. In 1 µ 2
thiscontext,wealsoshowourmethod’scapabilityofde-
scribingthestateofhealth(diagnosis)oftheturbofansin Now,equippedwithDef.6,wecanstatethegeneralversion
termsofinformation-drivenfeatures(RIFs). ofTheorem1asfollows.
These formal, numerical, and empirical results lead us to Theorem 5. Let X and Y be random variables with values in
explore further practical applications for our method, such as Rp and Rq, respectively, such that (X,Y) ∼ add(η˜,h˜;µ), and
benchmarking its capacity to estimate the state of health of let η : Rp → Rq be a measurable function. The following
other realistic time series systems and working in real-world propertiesaretrue:
scenarios. The ability of the residual information features
(RIFs)todescribethestateofhealthsuggestsavarietyofnext (i) Ifthereexistsc∈Rqsuchthatη˜ ≈c η,thenXandY−η(X)
µ
stepstostudytheirpracticalusageinfaultdiagnosisandsystem areindependent.
prognostics.
(ii) Ifη˜ (cid:48) η,andbothr.v.s. (X,Y−η(X))and(X,h˜(W))have
µ
densities,thenXandY−η(X)arenotindependent.
Appendix A. AppendixOutline
Intheseappendices,wepresenttheproofsforallourtheo- Remark2. We highlight that property (i) of Theorem 5 does
reticalclaims,describethedetailsofthesystemsinvolvedinthe not require any r.v. to have densities. Then, it would remain
numerical analysis performed on synthetic distributions, and true even in a classification context where Y is a discrete ran-
providefurtherinsightintoourtheoreticalassumptionsandthe dom variable. The extension of our theory to discrete-output
experimentalresultsonthesyntheticscenarios. Onthetheoret- systemswouldrequirerethinkingthepropertiesoftheMMSE
ics, in Appendix B, we show and prove Theorem 5, a gener- estimator we exploited in this work to consider the properties
alizedversionofTheorem1,whichestablishestherelationship of a classifier that optimizes a classification loss, such as the
betweenmodeldriftandinput-residualdependency;thisproof cross-entropy. The idea is to use this classifier to capture the
issupportedwiththeaidofLemma2,whoseproofisshownin nominaldynamicsofthediscrete-outputsystem.
Appendix J.InAppendix C,weproveTheorem1asacorol-
lary of its extended version. In Appendix D, Appendix E, ProofofTheorem5. We divide this proof into proving each
andAppendix F,weproveTheorem2(strongconsistency),3 property(i)and(ii)thatconstituteTheorem5.
(exponentially-fastdecision), and4(errorrateguarantees), re-
spectively,andinAppendix G,wejustifythegeneralityofour • Proof of Th. 5 (i): This proof relies on the definition
assumptions. On the numerical analysis, in Appendix H, we ofindependencebetweenr.v.s,thismeans,thatweprove
provideafulldescriptionofthesystemsandmethodsemployed independence between X and Y −η(X) by proving that
in the results shownin Sec. 7; and in Appendix I, to enhance ∀A∈B(Rp),∀B∈B(Rq),
our analysis, we provide an error-bar analysis that showcases
the consistency of the asymptotic and finite-length properties P(X ∈ A,Y−η(X)∈ B)=P(X ∈ A)·P(Y−η(X)∈ B).
provedforourmethod. (B.1)
Letusstartthisproofbynotingthatη˜ ≈c η,fromDef.6,
µ
Appendix B. Generalized Link between Model Drift and implies that for every random variable X˜ ∼ µ, it holds
Input-ResidualDependency that η˜(X˜) a=.s. η(X˜) + c. This, in particular, is true for
In this section, we show a generalized version of Theo- the marginal input of (X,Y) ∼ add(η˜,h˜;µ); i.e., X ∼ µ
rem 1. This generalized theorem links model drift and input- satisfiesthatη˜(X)a=.s. η(X)+c.
15To continue this proof, we define the following events (B.3) and (B.2), respectively; Equation (B.14) is a con-
inΣ:17,18 sequenceofthedefinitionofB . Then,from(B.13)and
−c
(B.20),wegetthat
Eadd ≡{ω∈Ω:Y(ω)=η˜(X(ω))+h˜(W(ω))}, (B.2)
Ee cq ≡{ω∈Ω:η˜(X(ω))=η(X(ω))+c}, (B.3) P(X ∈ A,Y−η˜(X)∈ B)
and then, we have the following sequence of equalities =P(X ∈ A)·P(h˜(W)∈ B −c) (B.21)
foranyarbitrarysetsA∈B(Rp)andB∈B(Rq): =P(X ∈ A)·P(Y−η(X)∈ B). (B.22)
P(X ∈ A,Y−η(X)∈ B)
=P(X ∈ A,Y−η(X)∈ B,Eadd) (B.4) Finally, we can see that (B.22) is precisely what we
=P(X ∈ A,η˜(X)+h˜(W)−η(X)∈ B,Eadd) (B.5) wanted to show, as stated in (B.1), proving in this way
theproperty(i)ofTheorem5.
=P(X ∈ A,η˜(X)+h˜(W)−η(X)∈ B) (B.6)
=P(X ∈ A,η˜(X)+h˜(W)−η(X)∈ B,Eeq) (B.7)
c • ProofofTh.5(ii): Weprovepoint(ii)bycontradiction;
=P(X ∈ A,η(X)+c+h˜(W)−η(X)∈ B,Ee cq) (B.8) inparticular,weshowhowassumingbothη˜ (cid:48)
µ
ηandthe
=P(X ∈ A,h˜(W)+c∈ B), (B.9) independencebetweenX andY −η(X)leadstoacontra-
diction. Thiscontradictionhastodowiththeimpossibil-
where(B.4),(B.6),(B.7),and(B.9)areaconsequenceof ityoftheexistenceofprobabilitydensityfunctions(pdfs)
thefollowingproperty: forthecontinuousr.v.s(X,Y−η(X))and(X,h˜(W))under
thestatedassumptions.
∀E ∈Σ,∀E ∈Σ,P(E )=1⇒P(E ,E )=P(E );
1 2 1 1 2 2
(B.10) Let us start this proof by considering the mappings
f : Rp+q → [0,∞) and f : Rp+q → [0,∞] as
Equation(B.5)and(B.8)areconsequencesof(B.2)and X,R X,h˜(W)
pdfsof(X,Y −η(X))and(X,h˜(W)),respectively,andlet
(B.3),respectively.AsXandWareindependent,wehave
us consider f : Rq → [0,∞) as the marginal pdf of
thatXandh˜(W)areindependent. Moreover,ifwedefine R
Y−η(X)inducedfrom f (·)and f :Rq →[0,∞)as
thesetB ≡{x∈Rq :x+c∈ B},wecanseethat X,R h˜(W)
−c themarginalpdfofh˜(W)inducedfrom f (·,·).
X,h˜(W)
P(X ∈ A,Y−η(X)∈ B)
Let us define a function D : Rp → Rq in a way that
=P(X ∈ A,h˜(W)+c∈ B) (B.11) D (x)=η(x)−η˜(x),∀x∈η R,η˜ p. FromDef.4,wegetthat
η,η˜
=P(X ∈ A,h˜(W)∈ B −c) (B.12) (X,Y) ∼ add(η˜,h˜;µ)implies(X,Y) a=.s. (X,η˜(X)+h˜(W)),
=P(X ∈ A)·P(h˜(W)∈ B ), (B.13) inturnimplying(X,Y−η(X))a=.s. (X,η˜(X)+h˜(W)−η(X));
−c
asthelatterr.v.isequalto(X,h˜(W)−D (X)),wegetthat
η,η˜
where (B.11), (B.12), and (B.13) come from (B.9), the (X,Y−η(X))a=.s. (X,h˜(W)−D (X)).Then,as f (·,·)isa
η,η˜ X,R
definition of B −c, and the independence between X and pdfof(X,Y−η(X)),italsoisapdfof(X,h˜(W)−D (X)).
h˜(W), respectively. Developing further P(h˜(W) ∈ B ), η,η˜
−c
wecanseethat LetusconsideranarbitrarysetC ∈B(Rp+q),thenwecan
defineasetC˜ expressedby
P(h˜(W)∈ B )
−c
=P(h˜(W)+c∈ B) (B.14) C˜ ≡{(x,r+D (x)):x∈Rp,r∈Rq,(x,r)∈C}.
η,η˜
=P(h˜(W)+c∈ B,Eeq) (B.15) (B.23)
c
=P(h˜(W)+η˜(X)−η(X)∈ B,Eeq) (B.16)
Thisdefinitionsatisfiesthat∀x∈Rp,∀r∈Rq,theequiv-
c alence[(x,r)∈C ⇔(x,r+D (x))∈C˜]holds;then,we
=P(η˜(X)+h˜(W)−η(X)∈ B) (B.17) η,η˜
havethefollowingeventequality:
=P(η˜(X)+h˜(W)−η(X)∈ B,Eadd) (B.18)
=P(Y−η(X)∈ B,Eadd) (B.19) {ω∈Ω:(X(ω),h˜(W(ω))−D η,η˜(X(ω)))∈C}
=P(Y−η(X)∈ B), (B.20) ={ω∈Ω:(X(ω),h˜(W(ω)))∈C˜} (B.24)
where (B.15), (B.17), (B.18), and (B.20) are a conse-
and,asaconsequence,
quenceof(B.10);Equation(B.16)and(B.19)comefrom
P((X,h˜(W)−D (X))∈C)=P((X,h˜(W))∈C˜). (B.25)
η,η˜
17Wearedenotingtheprobabilityspaceofallther.v.sinvolvedinthiswork
as 1( 8Ω W,Σ e, hP ig). hlightfortheseeventsthat(X,Y)∼add(η˜,h˜;µ)⇔P(Eadd)=1and Hence,ifwedefine f˜:Rp+q →[0,∞)asafunctionsuch
η˜≈c µη⇔P(Ee cq)=1. that f˜(x,r) = f X,h˜(W)(x,r+D η,η˜(x)), ∀x ∈ Rp, ∀r ∈ Rq,
16wecanseethat whereλpandλqaretheLebesguemeasuresof(Rp,B(Rp))
and(Rq,B(Rq)),respectively.
P((X,h˜(W)−D (X))∈C)
η,η˜ Inaddition,asλp+q(Ec)=0,ifwedefineaset
=P((X,h˜(W))∈C˜) (B.26)
(cid:90)
M ≡{x∈Rp :λq(Ec)=0}∈B(Rp), (B.38)
= f (x,h)d(x,h) (B.27) x
X,h˜(W)
C˜
(cid:90) wegetfrom(B.37)thatλp(Mc)=0,forthecomplement
= f˜(x,h−D η,η˜(x))d(x,h) (B.28) set Mc ≡Rp\M ={x∈Rp :λq(Ec)>0}∈B(Rp). This
(cid:90)C˜ meansthatthereareλp-almostnonx
epointsx ∈ Rp such
= f˜(x,r)d(x,r), (B.29) thatthesetofpointsr ∈ Rq where(B.36)doesnothold
C hasaλq-measuregreaterthan0.
where(B.26)and(B.28)comefrom(B.25)andthedef-
Beforecontinuingthisproof,weneedtostatethefollow-
inition of f˜(·,·), respectively; hence, f˜(·,·) is a pdf of
ing lemma about degenerated random variable distribu-
(X,h˜(W) − D (X)), and in consequence, it is a pdf of
η,η˜ tions. This lemma is related to the concept of perfectly
(X,Y−η(X)). Thisletsusstatethatthefollowingequali-
biasedequivalenceweintroduceinDef.6.
tiesholdλp+q-almosteverywhere:19
Lemma2. 20 LetU bearandomvariabletakingvalues
f (x,r)
X,R in Rr with r ∈ N. If for every S ∈ B(Rr) it is satisfied
= f˜(x,r) (B.30) thatP(U ∈ S) ∈ {0,1},thenthereexistsc ∈ Rr suchthat
= f (x,r+D (x)), (B.31) P(U =c)=1.
X,h˜(W) η,η˜
where (B.30) and (B.31) come from both f (·,·) and
X,R Regardingtheotherassumptionthatleadstoacontradic-
f˜(·,·) being pdfs of (X,Y −η(X)), and the definition of tion, let us note that η˜ (cid:48) η, from Def. 6, corresponds
f˜(·,·), respectively. This means that if we define the set to the non-existence of cµ such that η˜ ≈c η, or which is
ofpointswherethepdfsareequalasE ⊆Rp+q,thisis
equivalent, that ∀c ∈ Rq, there exists
aµ
r.v. X˜ ∼ µ such
(cid:40) x∈Rp,r∈Rq, (cid:41) thatP(η˜(X˜)=η(X˜)+c)<1. Then,sinceXhasthesame
E ≡ (x,r)∈Rp+q : f (x,r)= f (x,r+D (x)) , distributionas X˜, wehavethatP(η˜(X) = η(X)+c) < 1,
X,R X,h˜(W) η,η˜ (B.32) ∀c ∈ Rq, or equivalently, that ∄c ∈ Rq : D η,η˜(X) a=.s. c.
wegetthat Ec ≡ Rp+q \E ∈ B(Rp+q)isaλp+q-nullset, DuetothecontrapositiveofLemma2, thenonexistence
i.e.,λp+q(Ec)=0. of c ∈ Rq such that P(D η,η˜(X) = c) = 1 implies that
theproposition[P(D (X) ∈ S) ∈ {0,1},∀S ∈ B(Rq)]is
Oneoftheassumptionsthatleadtoacontradictionisthe η,η˜
false,orwhichisequivalent,thatthereexistsG ∈ B(Rq)
independencebetweenXandY−η(X);thisindependence
suchthatP(D (X) ∈G) ∈ (0,1),whichinturn,implies
impliesthat η,η˜
theexistenceofH =Rq\G ∈B(Rq)whichalsosatisfies
∀x∈Rp,∀r∈Rq, f X,R(x,r)= f X(x)· f R(r). (B.33) thatP(D η,η˜(X)∈ H)=1−P(D η,η˜(X)∈G)∈(0,1).
Inaddition,letusnotethefollowingeventequality:
Then,wegetthefollowing∀(x,r)∈ E:
f X(x)· f R(r) {ω∈Ω: D η,η˜(X(ω))∈G}={ω∈Ω: X(ω)∈ D− η,1 η˜(G)};
(B.39)
= f (x,r) (B.34)
X,R this enables us to state that ∃A = D−1(G) ∈ B(Rp) :
= f X,h˜(W)(x,r+D η,η˜(x)) (B.35) P(X ∈ A) = P(D η,η˜(X) ∈ G) > 0 η a,η n˜ d, analogously,
= f (x)· f (r+D (x)), (B.36) it is possible to state that ∃B = D−1(H) ∈ B(Rp) :
X h˜(W) η,η˜ η,η˜
P(X ∈ B)=P(D (X)∈ H)>0.
η,η˜
where (B.34), (B.35), and (B.36) are a consequence of
Let us retrieve set M from (B.38), we can see that
(B.33),(B.31),andtheindependencebetweenther.v.sX
andh˜(W),respectively. Moreover,letusdefine∀x∈Rp, λp(Mc)=0impliesthatP(X ∈ Mc)=0.Inconsequence,
thesetsE ≡{r∈Rq :(x,r)∈ E}andEc ≡Rq\E . We as A ∩ Mc ⊆ Mc, it holds that P(X ∈ A ∩ Mc) = 0,
x x x
canseethatEc = {r ∈ Rq : (x,r) ∈ Ec},∀x ∈ Rp. Then, and therefore, it is possible to conclude the following:
as Ec is a λp+x q-measurable set, from Fubini’s theorem P(X ∈ A∩M)=P(X ∈ A)−P(X ∈ A∩Mc)=P(X ∈ A)
(see[59,Th.3.4.1.]),wegetthatλp-almosteverysetEc >0;analogously,P(X ∈ B∩M)=P(X ∈ B)>0.
x
isλq-measurableandthat Furthermore, let us consider f : Rp → [0,∞) as a pdf
X
(cid:90) inducedbythemarginalizationofXfromeitheradensity
λp+q(Ec)= λq(E xc)dx, (B.37) of(X,Y−η(X))or(X,h(W)).Wecanseethat∃a∈ A∩M
Rp
19λp+qcorrespondstotheLebesguemeasureof(Rp+q,B(Rp+q)). 20TheproofofLemma2ispresentedinAppendix J.
17suchthat f X(a)>0.21 Moreover,itispossibletoseethat apartitionR ≡ {r k} k∈Z ⊆ B(Rq)ofRq suchthat∀k ∈ Z,
evaluatingx = ain(B.36)anddividingthetermsofthe r ≡ {h = (h )q ∈ Rq : h ∈ [kp ,(k+1)p )}. Wecan
k j j=1 ℓ ℓ ℓ
equalityby f (a)>0,wegetthat observe that ∀k ∈ Z, [∀h ∈ r ,h+kp ∈ r ]; hence, we
X 0 k
obtainthefollowingpropertyforeveryk∈Z:
∀r∈ E , f (r)= f (r+D (a)). (B.40)
a R h˜(W) η,η˜
P(h˜(W)∈r )
Analogously, we can see that ∃b ∈ B ∩ M, such that k
(cid:90)
f X(b)>0and = f h˜(W)(h˜)dh˜ (B.46)
∀r∈ E , f (r)= f (r+D (b)). (B.41)
(cid:90)rk
b R h˜(W) η,η˜
= f (h+kp)dh (B.47)
h˜(W)
From(B.40)and(B.41),wegetthefollowing: (cid:90)r0
(cid:90)
= f (h+kp)dh+ f (h+kp)dh
∀r∈ E a,b, f h˜(W)(r+D η,η˜(a))= f h˜(W)(r+D η,η˜(b)), (B.42) r0∩E˜ Zc h˜(W) r0∩E˜Z h˜(W)
(B.48)
where E a,b ≡ E a ∩ E b ∈ B(Rq). Since a ∈ M and (cid:90)
b ∈ M, we get that λq(Ec) = λq(Ec) = 0. Then, for =0+ f (h)dh (B.49)
a b h˜(W)
E ac
,b
≡ Rq \ E
a,b
= E ac ∪ E bc ∈ B(Rq), we get that
(cid:90)
r0∩E˜Z
(cid:90)
λ λq q( (E
E
aa cc ,, bb )) ≤= λq(0 E;
ac)
+thi λs q(i Es bc)be =ca 0u .se Ino cf onth se equin eneq ceu ,al ti hty
e
=
r0∩E˜ Zc
f h˜(W)(h)dh+
r0∩E˜Z
f h˜(W)(h)dh (B.50)
equality shown in (B.42), i.e., a periodicity for the pdf (cid:90)
f h˜(W)(·),istrueλq-almosteverywhere. = f h˜(W)(h)dh (B.51)
Letusdefinep = (p j)q
j=1
∈ Rq asp ≡ D η,η˜(a)−D η,η˜(b). =P(r h˜0
(W)∈r 0) (B.52)
Duetoa ∈ A = D−1(G)andb ∈ B = D−1(H), wehave
η,η˜ η,η˜
t wh eat hD avη e,η˜( tha a) t∈ DG η,η˜(a an )d (cid:44)D Dη,η η˜ ,( η˜b (b) )∈ ;hH en; ct eh ,e pn, (cid:44)as 0G ∈∩ RqH
.
I= fw∅ e, w ofh h˜e (r We( )B ,(.4 B6 .4) 8a )n ad n( dB (. B52 .5) 1c )o cm oe mf ero frm omf h˜ t( hW e)( d·) isb je oi in ng tua np iod nf
wde efi gn ee tt th he atse ∀t hE˜ ∈≡ E˜{ ,h h∈ −R Dq η,: η˜(h b− )∈D Eη,η a˜( ,bb ;) h∈ enE ca e, ,b}∈B(Rq), λr 0 q(= E˜c(r )0 =∩ 0E˜ ,Z a) nd∪ (( Br 0 .4∩ 7)E˜ cZc o) m,( eB s.4 fr9 o) man ad c( hB an.5 g0 e) oc fo vm ae rif ar bo lm
e.
Z
∀h∈ E˜, f h˜(W)(h)= f h˜(W)(h+p). (B.43) Letusnotethat
ForE˜c ≡Rq\E˜ ={h∈Rq :h−D (b)∈ Ec }∈B(Rq),
η,η˜ a,b P(h˜(W)∈Rq)
wecanobservethatλq(E˜c)=λq(Ec )=0.
(cid:88)
a,b = P(h˜(W)∈r ) (B.53)
In addition, if for an arbitrary j ∈ Z we define a set k
E˜ ≡ {h ∈ Rq : h + jp ∈ E˜} ∈ B(Rq), we can see
(cid:88)k∈Z
thj atE˜c ≡Rq\E˜ ={h∈Rq :h+ jp∈ E˜c}∈B(Rq)has = P(h˜(W)∈r 0), (B.54)
j j
aλq-measureofλq(E˜c) = λq(E˜c) = 0andthat∀h ∈ E˜ , k∈Z
j j
h+ jp∈ E˜;hence, where(B.53)and(B.54)areaconsequenceofRbeinga
partitionofRq and(B.52), respectively. Then, thereare
∀h∈ E˜ , f (h+ jp)= f (h+(j+1)p). (B.44)
j h˜(W) h˜(W) onlytwopossiblecases,andbothleadtoacontradiction.
M pleo mre eo nv te ir s,i Ef
˜
Zcw ≡ed Re qfin \e E˜E Z˜ Z =≡ (cid:83)(cid:84) k∈k Z∈Z E˜E kc˜ k ∈∈ BB (R(R qq ).), Ait ss Ec ˜o Zcm is- (cid:80)In k∈t Zhe P(fi h˜r (s Wt c )a ∈se,
r
0P )( =h˜(W 0,) w∈ hicr h0) co= nt0 ra; dt ih ci ts
s
ti hm ep fli ae cs
t
t th ha at
t
the result of a countable union, we get that its P(h˜(W)∈Rq)=1. InthesecondcaseP(h˜(W)∈r )>0;
0
λλ qq (-m
E˜
Zce )as ≤ur (cid:80)e ki ∈s Zλ λq q( (E E˜ ˜Zc kc) )== (cid:80)0; k∈t Zhi 0s =is 0d .u Ne ot wo ,t whe ei cn ae nqu aa pl pit ly
y
t ch oi ns trim adp icli te ss thth aa tt P(cid:80)
(h˜k (∈
WZP )( ∈h˜( RW q) )=∈ r
1k
.)diverges,whichalso
(B.44)inductivelytoobtainthefollowingproperty:
In conclusion, we have shown that under the hypothe-
∀h∈ E˜ Z,[∀k∈Z, f h˜(W)(h)= f h˜(W)(h+kp)]. (B.45) sesofproperty(ii)ofTheorem5,assumingbothη˜ (cid:48)
µ
η
andtheindependencebetweenXandY−η(X)leadstoa
Let us note that p = (p )q (cid:44) 0 ∈ Rq implies the ex- contradiction. Thisleadsustoprovethatunderthemen-
istenceofℓ ∈ {1,2,...,qj },j= a1 dimensionindex, suchthat tionedhypotheses,η˜ (cid:48) µ ηimpliesthatXandY−η(X)are
p (cid:44) 0 ∈ R. Then,accordingtoℓ,itispossibletodefine notindependent, provinginthiswaytheproperty(ii)of
ℓ
Theorem5.
∄∀ ax2 ∈1 ∈∃ AAa ∩∩∈ MMA ,∩ :i fmM Xp (al: y )if >nX g( 0a P) w(X> ou∈0 ldi As co∩tr nu tM re a; ) do i= cth t(cid:82)e tAr hw ∩ aM tis Pe f (, X Xi (t x ∈w ) Ado xu ∩l =d Mh (cid:82) )o Al ∩ >d M 0th 0 .a dt xfX =(x 0) .= I.e0 .,, remH 5a ,v win eg cod ne cm luo dn est ora ut red prob oo fth fop rro Tp he er oti re es m(i 5) .and (ii) of Theo □-
18Appendix C. ProofofTheorem1—ModelDriftandInput- ni.i.d. realizationsof(X,Y −η(X)). Hence, ψλ,n (z )isthe
bn,dn,an n
ResidualDependencyEquivalence output of a decision rule of length n for testing independence
betweenXandY −η(X),andconsequently,Ψλ isadecision
Inthissection,weproveTheorem1. Withinthisproof,we b,d,a
scheme for testing independence between the mentioned r.v.s.
canobservethatTheorem1isacorollaryofTheorem5,which
The usage of the estimator presented in [40] for testing inde-
correspondstoabroaderversionofTheorem1.
pendencewasstudiedby[58].
ProofofTheorem1. As Theorem 1 states an equivalence re- From (8), let us notice that any Ψλ b,d,a ∈ Ψ SC satisfies that
lationship, in this proof, we will prove both implications that b ≈ (n−l) n∈N for l ∈ (0,1/3), d ∈ ℓ 1(N), 1/d ∈ O(exp(n1/3)),
constitutetheequivalence. a ∈ o(1), and λ ∈ (0,∞). Hence, from [58, Th. 3], Ψλ
b,d,a
For the first implication (i.e., [η˜ ≃ η] implies [X and is strongly consistent (see [58, Def. 1]) for detecting indepen-
µ
Y−η(X)areindependent]),theproofisstraightforward.Wecan dencebetweenXandY−η(X),whichmeansthat
seethatη˜ ≃ η(Def.5)isequivalenttoη˜ ≈0 η(Def.6); then,
thereexistscµ = 0 ∈ Rq suchthatη˜ ≈c ηandµ , inconsequence, XandY−η(X)areindependent (D.2)
µ (cid:18) (cid:19)
duetoTheorem5point(i),XandY−η(X)areindependent. ⇒P lim ψλ,n (Z )=0 =1 (D.3)
For the second implication (i.e., [X and Y − η(X) are in- n→∞ bn,dn,an n
dependent] implies [η˜ ≃ µ η]), we need to look at the contra- and
positiveofTheorem5point(ii); thisis, thattheindependence
between X and Y −η(X) implies that either η˜ (cid:48) η is false or XandY−η(X)arenotindependent (D.4)
µ
thattheexistenceofthedensitiesof(X,Y−η(X))and(X,h˜(W)) (cid:18) (cid:19)
⇒P lim ψλ,n (Z )=1 =1. (D.5)
isfalse.Astheexistenceofthedensitiesisensuredbyourstan- n→∞ bn,dn,an n
dard assumptions – point (iii) – we are only left with the fact
thatη˜ (cid:48) ηisfalse. Moreover, as we are under our standard assumptions and
Theµ
falsehood of η˜ (cid:48) η implies that there exists a value
(X,Y)∼add(η˜,h˜;µ),wegetfromTheorem1theequivalence
µ
c ∈ Rq such that η˜ ≈c η. Then, as X ∼ µ, we have that
µ [η˜ ≃ η]⇔[XandY−η(X)areindependent]; (D.6)
η˜(X) a=.s. η(X)+c. Moreover, as(X,Y) ∼ add(η˜,h˜;µ), wehave µ
that(X,Y)a=.s. (X,η˜(X)+h˜(W));hence hence,aswecanseein(6),Sec.3.5,ournullhypothesis(H
0
:
η˜ ≃ η) is equivalent to the input-residual independence hy-
µ
[η˜(X)a=.s. η(X)+c] ∧ [(X,Y)a=.s. (X,η˜(X)+h˜(W))] pothesis,andouralternatehypothesis(H : η˜ (cid:59) η)isequiva-
1 µ
⇒(X,Y)a=.s. (X,η(X)+h˜(W)+c). (C.1) lenttotheinput-residualnon-independencehypothesis. Incon-
sequence,from(D.3),(D.5),and(D.6),
Then,letusnotethefollowing: (cid:18) (cid:12) (cid:19)
P lim ψλ,n (Z )=i(cid:12) (cid:12) H =1,∀i∈{0,1}. (D.7)
E[Y−η(X)] n→∞ bn,dn,an n (cid:12) i
=E[η(X)+h˜(W)+c−η(X)] (C.2) Equation (D.7) shows that any Ψλ ∈ Ψ satisfies (1),
b,d,a SC
=E[h˜(W)]+c. (C.3) i.e.,Def.1;hence,anydecisionschemeinΨ SCisstronglycon-
sistent in detecting model drift. This concludes our proof for
Since our standard assumptions consider E[h˜(W)] = 0 ∈ Rq Theorem2. □
and E[Y −η(X)] = 0 ∈ Rq (points (i) and (ii), respectively),
by replacing these values in (C.3), we get that c = 0. This, in
Appendix E. ProofofTheorem3—Exponentially-FastDe-
turn, implies that η˜ ≈0 η (Def. 6) or, equivalently, that η˜ ≃ η
µ µ cisionunderH
(Def.5). 0
Finally, we can see that our proof concludes at this point, ProofofTheorem3. EverydecisionschemeΨ ∈ Ψ follows
FL
aswehaveproventheequivalencerelationshipstatedinTheo- theconstructionshowninSec.4.1;consequently,itsparameters
rem1byprovingthetwoimplicationsthatconstituteit. □ canbewrittenexplicitlyasΨ≡Ψλ
b,d,a
=(ψλ bn,n ,dn,an(·)) n∈N,andas
shown in the proof of Theorem 2 (see Appendix D), it corre-
Appendix D. ProofofTheorem2—StrongConsistency spondstoadecisionschemefortestingindependencebetween
XandY−η(X).
ProofofTheorem2. Let us note that every decision scheme From(10),letusnoticethatanyΨ ≡ Ψλ ∈ Ψ satisfies
(cid:16) (cid:17) b,d,a FL
Ψλ b,d,a = ψλ bn,n ,dn,an(·) n∈N ∈ Ψ SC followstheconstructionshown thatb≈(n−l) n∈N forl∈(0,1/3),d≈(exp(n−1/3)) n∈N,a∈o(1),
in Sec. 4.1; in consequence, Ψλ is a sequence of decision andλ∈(0,∞). Hence,from[58,Th.4],wecanseethat
b,d,a
rulessuchthat∀n∈N,∀z =(x ,y )n ∈(Rp+q)n,
n j j j=1
XandY−η(X)areindependent
(cid:16) (cid:17)
ψλ bn,n ,dn,an(z n)=1 [an,∞) I bλ n,n ,dn(j n) , (D.1) ⇒∀m∈N,P(CΨ 0(J ∞)≥m)≤ Kexp(−m1/3), (E.1)
wherej ≡ (x ,y −η(x ))n . Letusrecallthat Iλ,n (j )isan for some universal constant K ∈ (0,∞), where J denotes
estimatin onoftj hej MIbetwj ej e= n1 X andY −η(X)asjbn,d cn onn sistsof (X ,Y −η(X ))∞ and,from[58,Def.3],CΨ(J )co∞ rresponds
n j j j j=1 0 ∞
19totherandomvaluethatexpresseswhenthetree-structuredpar- ψ (·) ≡ ψλ,n (·). Theorem 4 states two assertions expressed
tition used for estimating the MI between X and Y −η(X) us- inn (11)andbn (,d 1n 2,a )n ;hence,wedividethisproofintotwoparts,one
ing the parameters of Ψ ≡ Ψλ
b,d,a
(A = {A ℓ} ℓ∈Λ; see Sec. 4.2, foreachequation.
Stage one) collapses to the trivial partition {Rp+q},22,23 which
• Proof of Eq. (11): Let us observe that for every
inturnimpliesanMIestimationof0.
As we have shown in the proof of Theorem 2, both
Ψ ≡ Ψλ
b,d,a
∈ Ψ FL, it is satisfied that b ≈ (n−l) n∈N with
(X,Y)∼add(η˜,h˜;µ)andbeingunderourstandardasumptions, l∈(0,1/3),a∈o(1),λ∈(0,∞),andd≈(exp(n1/3)) n∈N.
imply from Theorem 1 that [η˜ ≃ η] ⇔ [X and Y −η(X) are The latter asymptotic equivalence implies that
µ
independent]. Hence,asournullhypothesis(H )corresponds 1/d ≈ (exp(n1/3)) n∈N, and consequently, it implies that
0
toη˜ ≃ η(see(6),Sec.3.5),theconsequenceoftheimplication
1/d∈O(exp(n1/3)),andontheotherhand,itimpliesthat
µ (cid:80)∞
d converges due to the convergence of
shownin(E.1)reducesto (cid:80)n ∞=1 exn
p(n−1/3),whichinturn,duetothenon-negativity
∀m∈N,P(CΨ 0(J ∞)≥m|H 0)≤ Kexp(−m1/3). (E.2) ofn= d1 , implies that (cid:80)∞ n=1|d n| < ∞; this last property is
Let us consider an arbitrary m ∈ N, then we have that equivalent to d ∈ ℓ 1(N). Consequently, we get that
CΨ(j ) = m ⇒ ∀n > m,Iλ,n (j ) = 0;24 hence, ∀n > m, Ψ∈Ψ FL ⇒Ψ∈Ψ SC,i.e.,
0 ∞ bn,dn n
∀a=(a n) n∈N ∈o(1),I bλ n,n ,dn(j n)<a n. Furthermore,ifweobserve Ψ FL ⊆Ψ SC. (F.1)
the sequence of outputs from the decision rule, we have that
∀ san tis> fiem d∀= mC ∈Ψ 0 N(j ,∞ w), eψ gλ b en,n , tdn t, han e(z fon) llo= w0 in. gA res lat th ii os nl sa hs it p:statement is F wr eom ge( tF ,. f1 r) oa mnd Ta hs ew ore ea mre 2u ,n td he ar tth ae nysta Ψnd ∈ar Ψdassu ⊆mp Ψtion is s,
FL SC
TΨ (z )=sup(cid:110) n∈N:ψλ,n (z )=1(cid:111) ≤CΨ (j ). (E.3) stronglyconsistentfordetectingmodeldrift,i.e.,
0 ∞ bn,db,an n 0 ∞ (cid:18) (cid:12) (cid:12) (cid:19)
F ∀r mom ∈N(E :.3), we get the following relationship between events P nl →im ∞ψ n(Z n)=i(cid:12) (cid:12) (cid:12) H i =1,∀i∈{0,1}, (F.2)
which,inparticular,impliesthat
{ω∈Ω:CΨ (J (ω))<m}⊆{ω∈Ω:TΨ (Z (ω))<m},
0 ∞ 0 ∞ (E.4) (cid:18) (cid:12) (cid:12) (cid:19)
andconsequently,P(CΨ 0(J ∞)<m|H 0)≤P(T 0Ψ(Z ∞)<m|H 0), P nl →im ∞ψ n(Z n)=0(cid:12) (cid:12) (cid:12) H 1 =0. (F.3)
orequivalently,
Moreover,wecandevelopthefollowingsequenceofequal-
P(TΨ (Z )≥m|H )≤P(C (J )≥m|H ). (E.5)
0 ∞ 0 0 ∞ 0 ities:
From(E.2)and(E.5),wegetthatforeveryΨ∈Ψ ,itissatis- (cid:18) (cid:19)
FL P lim ψ (Z )=0
fiedthat n→∞ n n
(cid:18) (cid:19)
∀m∈N,P(T 0Ψ (Z ∞)≥m|H 0)≤ Kexp(−m1/3), (E.6) =P nl →im ∞{ω∈Ω:ψ n(Z n(ω))=0} (F.4)
(cid:32) (cid:33)
orwhichisequivalent,that
=P limsup{ω∈Ω:ψ (Z (ω))=0} (F.5)
n n
∀m∈N,P(TΨ (Z )<m|H )≥1−Kexp(−m1/3), (E.7) n→∞
0 ∞ 0 =P({ω∈Ω:[∀m∈N,∃n≥m:ψ (Z (ω))=0]})
n n
forsomeuniversalconstant K ∈ (0,∞). Equation(E.7)shows
(F.6)
that∀Ψ ∈ Ψ FL, (10)issatisfied; hence, itconcludesourproof (cid:18) (cid:19)
forTheorem3. □ =P lim{ω∈Ω:[∀m≤k,∃n≥m:ψ (Z (ω))=0]}
n n
k→∞
(F.7)
Appendix F. ProofofTheorem4—PowerandSignificance (cid:18) (cid:19)
=P lim{ω∈Ω:[∃n≥k:ψ (Z (ω))=0]} (F.8)
Level n n
k→∞
ProofofTheorem4. Let us recall that every decision scheme = limP({ω∈Ω:[∃n≥k:ψ n(Z n(ω))=0]}). (F.9)
k→∞
Ψ ∈ Ψ follows the construction shown in Sec. 4.1; conse-
FL
Equation(F.4)comesfromthedefinitionoftheeventsub-
quently, the parameters of the decision scheme and each deci-
sionrulecanbewrittenexplicitly,i.e.,Ψ ≡ Ψλ and∀n ∈ N, ject to the limit [ψ n(Z n) = 0], and (F.6) and (F.5) come
b,d,a
fromthedefinitionofthelimitsuperior(limsup)ofaset
sequenceandtheexistenceofitslimitsuperiorgiventhe
22ThiscollapsingtimefunctionalwedenoteasCΦ 0(·)isdenotedasT 0(·)in
existence of its limit, respectively [60]. To obtain (F.7)
[58](letusrecallthatwearedenotingarbitrarydecisionschemesandasΦand
thedecisionschemesinducedbyourpipelineintroducedinSec.4.1asΨ).We and (F.8), if we define the event
usethenotationCΦ(·)toavoidconfusionwithourfunctionalTΦ(Def.2). E ≡{ω∈Ω:ψ (Z (ω))=0},wecanseethat(F.7)and
e a Jx p ni p 22 s =43 lt i HL s e (e s Xeat rn t jeou ,d
,
Ys ti h
w
jsn e −eo g nt r ηde oe (ea t Xt a nth0 e t
o
ja ir )o tt )eo n
n
j[ =rC b[ 1Te y0 ,q(
0
rΦ zJ u en∞ (a sZ pl)
a
e∞t nh c≥ d)a tin ≥ vjm enm m]
l,
y, ]d
t
.h.oe Werno eC ret 0 ee a( xs lJ
ti
ez∞a nan )
t
die d
o
tv o
n
he e
s
in sst
o
nn fi oon tZt aw e
n
tixh oi =i nsc th t;0
(
ot Xe h ni jit ,sh =Ye s
j
∞r a )m nC
j
.=e0 1( iJ ad∞ ne da) a(
e
pF n
q
rn . od u8 ba) a(cid:84) lc
i
bto yk m ilm ,= it1 (e yF(cid:83) .f m9r ∞ no
)
e= ,m am
i
ssEn u(cid:84)
a
rn e∞ m cn = P= o1 .n(cid:83) s(cid:83) e∞ n q= ∞ n u=m k eE nE cn n e,= orl e fi sm tp hk e e→ c ct∞ i ov n(cid:84) e tl iyk m n.= u1 it(cid:83) T yh∞ n oe= fm l taE hs en t
20Letus observethat forany k ∈ N andsamplingrealiza- whichinturnimpliesthat
tionz ∈ (Rp+q)k,25 itissatisfiedthatψ (z ) = 0implies
that∃k n≥k:ψ n(z n)=0;then,wegetthk at∀k k∈N, P(ψ n(Z n)=1|H 0)≤P(T 0Ψ (Z ∞)≥n|H 0). (F.23)
{ω∈Ω:ψ k(Z k(ω))=0} (F.10) Recalling α ψn from Def. 3, we can see, from (F.23) and
(F.21),that∀n∈N,
⊆{ω∈Ω:[∃n≥k:ψ (Z )=0]}, (F.11)
n n
α
whichimpliesthat∀k∈N, ψn
=P(ψ (Z )=1|H ) (F.24)
n n 0
P(ψ k(Z k)=0|H 1)≤P(∃n≥k:ψ n(Z n)=0|H 1). ≤P(TΨ (Z )≥n|H ) (F.25)
(F.12) 0 ∞ 0
Ifwetakethelimitwhenktendstoinfinity,wegetthat ≤Kexp(−n1/3), (F.26)
limP(ψ (Z )=0|H ) whichproves(12),concludingthispartoftheproof.
k k 1
k→∞
≤ limP(∃n≥k:ψ (Z )=0|H ) (F.13) As we have proven both (11) and (12), we conclude our
n n 1
k→ (cid:18)∞ (cid:12) (cid:12) (cid:19) proofforTheorem4. □
=P nl →im ∞ψ n(Z n)=0(cid:12) (cid:12) (cid:12) H 1 (F.14)
=0, (F.15) Appendix G. GeneralityoftheNon-BiasAssumptionsand
theUniformUniversalNoise
where(F.13)comesfromtakingthelimitofktoinfinity
Inthissection,weshowhowtheassumptions(i)and(ii)of
on (F.12), (F.14) is a consequence of conditioning (F.9)
thestandardassumptions(seeSec.3.6)andtheuniformdistri-
onH ,and(F.15)comesfrom(F.3). Moreover,fromthe
1
butionforthe(universal)noiseterm(W)inDef.4donotimply
non-negativityoftheprobabilitymeasure,wegetthat
alossofgenerality.
limP(ψ (Z )=0|H )=0. (F.16)
k k 1
k→∞ Appendix G.1. AssumptionofUnbiasedNoise
Inconsequence, recallingthatβ = P(ψ (Z ) = 0|H ) The assumption of unbiased noise corresponds to assump-
ψn n n 1
fromDef.3,wecanseethat tion (i) of our standard assumptions, this is that
E[h˜(W)] = 0 ∈ Rq. This does not imply a loss of general-
nl →im ∞(1−β ψn) ity, as if (X,Y) ∼ add(η˜,h˜;µ) with E[h˜(W)] = b ∈ Rq and
=1− lim β (F.17) b (cid:44) 0 ∈ Rq, it is possible to embed the bias (b) into η˜(·).
n→∞ ψn Embedding the noise bias into η˜(·) can be done by consider-
=1− lim P(ψ (Z )=0|H ) (F.18) ingthemappingsη¯ : Rp → Rq andh¯ : [0,1] → Rq suchthat
n n 1
n→∞ ∀x ∈ Rp,η¯(x) = η˜(x)+b and ∀w ∈ [0,1],h¯(w) = h˜(w)−b,
=1, (F.19)
respectively. Then,wehavethat
whichproves(11),concludingthispartoftheproof.
(X,Y)
• Proof of Eq. (12): Let us observe that under the stan- a=.s. (X,η˜(X)+h˜(W)) (G.1)
dard assumptions, it is satisfied due to Theorem 3, that
=(X,(η˜(X)+b)+(h˜(W)−b)) (G.2)
foreveryΨ∈Ψ ,
FL
=(X,η¯(X)+h¯(W)). (G.3)
P(TΨ ((Z )∞ )<m|H )≥1−Kexp(−m−1/3),∀m∈N,
0 n n=1 0
(F.20) Thisimpliesthat
forauniversalconstantK >0,andinconsequence,
(X,Y)a=.s. (X,η˜(X)+h˜(W))⇔(X,Y)a=.s. (X,η¯(X)+h¯(W)). (G.4)
P(TΨ ((Z )∞ )≥m|H )≤ Kexp(−m1/3). (F.21)
0 n n=1 0
Hence,thefollowingequivalenceholds
In addition, let us note that for an arbitrary sample size
n∈Nandanarbitrarysamplingrealizationz ∈(Rp+q)∞, [(X,Y)∼add(η˜,h˜;µ)]⇔[(X,Y)∼add(η¯,h¯;µ)] (G.5)
∞
we have that ψ (z ) = 1 ⇒ TΨ(z ) ≥ n, and in conse-
n n 0 ∞ as a consequence of (G.4) – i.e., equivalence on point (ii) of
quence
Def.4–andthefactthatX ∼µholdsforbothtermsequivalent
{ω∈Ω:ψ (Z (ω))=1}⊆{ω∈Ω:TΨ (Z (ω))≥n}, in(G.5)–i.e.,equivalenceonpoint(i)ofDef.4.26 Theequiva-
n n 0 ∞
lencestatedin(G.5)letsusknowthatnogeneralityislostwhen
(F.22)
assumingE[h˜(W)]=0∈Rq.
25Formoredetailsonthenotationofrandomsamplingsandtheirrealiza-
tions,wereferthereadertotheproofofTheorem3inAppendix E. 26X∼µdenotesthatP(X∈A)=µ(A),∀A∈B(Rp).
21Appendix G.2. AssumptionofUnbiasedEstimator Appendix H. Experiment Description — Synthetic Distri-
butionDrifts
The assumption of unbiased estimator corresponds to as-
This section extends the experiment description presented
sumption (ii) of our standard assumptions, this is that
E[Y − η(X)] = 0 ∈ Rq for a system (X,Y) ∼ add(η˜,h˜;µ). in Sec. 7 regarding the numerical analysis performed on syn-
theticdistributionstomakeourresultsreproducible. Thecore
This does not imply a loss of generality, as if η(·) is a biased
estimator such that E[Y −η(X)] = b ∈ Rq with b (cid:44) 0 ∈ Rq, ideaoftheseexperimentsistoshowhowourmethodandbase-
lines behave when ranging a parametrized drift δ ∈ R2. For
it is possible to correct it to build an unbiased one. This cor-
rection can be made by considering a mapping η¯ : Rq → Rq this purpose, we consider a nominal model η θ(·) and a system
suchthatη¯(x) = η(x)+b,∀x ∈ Rp. Then,wecanobservethat with unknown drift (X[δ],Y[δ]) ∼ add(η θ,δ,h;µ).28 Let us note
E[Y−η¯(X)]=E[Y−η(X)−b]=E[Y−η(X)]−b=b−b=0.27 that the nominal model is the MMSE estimator of Y given X
Hence,nogeneralityislostwhenassumingE[Y−η(X)]=0. assuminganominalsystemdistributesasadd(η θ,0,h;µ).
Our numeric analysis consists of, first, obtaining a sam-
plingZ[δ] = (X[δ],Y[δ])n ofnsamplesfromtheδ-driftedsys-
n j j j=1
Appendix G.3. GeneralityoftheUniformUniversalNoise tem (X[δ],Y[δ]) ∼ add(η θ,δ,h;µ), then, building a joint input-
residual sampling as expressed in points 1 and 2 of Sec. 4.1:
Here, we clarify the generality of Def. 4 in terms of using J[ nδ] = (X[ jδ],Y[ jδ] −η θ(X[ jδ]))n j=1, and finally, obtaining a quan-
a universal noise with uniform distribution, i.e., the usage of tificationofthemodeldriftusingourmethodandtwobaseline
W ∼ Uniform([0,1]);thisgeneralityisaconsequenceofnoise methods.
outsourcing(seeLemma1).
Appendix H.1. DescriptionofSyntheticSystems
Let us consider a r.v. – i.e., a system – (X,Y) such that
X ∼ µ and (X,Y) a=.s. (X,η(X)+h(W˜)) with η : Rp → Rq and Here,wedescribethesixsystemsusedinourexperiments:
h : Rs → Rq, where W˜ takes values in (Rs,B(Rs)) with an fourforwardandtwoautoregressivesystems.Beforegoinginto
arbitrary s ∈ N and an arbitrary distribution. If we consider thedetailsofeachsystem, weshowthatallofthem(indepen-
K as a constant random variable, i.e., K : Ω → R, where dent of their drift) share the following common random vari-
∀ω ∈ Ω,K(ω) = 0;then,forther.v. (K,W˜),Lemma1ensures ables:
the existence of the mapping f : R × [0,1] → Rs such that
U ∼Uniform([a ,b ]), (H.1)
(K,W˜) a=.s. (K, f(K,W))withW ∼ Uniform([0,1])independent U U
of K. Moreover, as [∀ω ∈ Ω,K(ω) = 0] implies that K a=.s. 0, S ∼N(µ S,σ2 S), (H.2)
weobtainthefollowingsequenceofimplications: H ∼N(µ ,σ2), (H.3)
H H
W ∼Uniform([a ,b ]), (H.4)
W W
(K,W˜)a=.s. (K, f(K,W)) ∧ K a=.s. 0
whereallU,S,H,andW areindependentwitheachother. We
⇒P((K,W˜)=(K, f(K,W)),K =0)=1 (G.6)
denote the samplings of each r.v. as (U )n , (S )n , (H )n ,
⇒P((0,W˜)=(0, f(0,W)))=1 (G.7) and(W )n ,respectively. InTableH.2(j atj= t1 heenj dj= o1 fthisj suj= b1 -
j j=1
⇒W˜ a=.s. f(0,W), (G.8) section),weshowthevaluesofallconstantcoefficientsusedin
ouranalysis,includingthedistributionparametersofthemen-
tionedr.v.s.
where (G.6) is a consequence of intersecting almost-surely
events–see(B.10)inAppendix B–(G.7)comesfrom0being
Appendix H.1.1. ForwardSystems
the only possible value for the r.v. K, and (G.8) is a conse-
quenceofdecouplingthea.s. r.v.sin(G.7)intotheirtwocon- TheinputofthesemodelscorrespondstoX[δ] ≡ X =(U,S),
stitutivecoordinatesandconsideringthesecondones. and in consequence, a sampling of the input corresponds to
(X )n = (U ,S )n .29 The generative model of the output
Let us note that it is possible to define a mapping j j=1 j j j=1
h¯ : [0,1] → Rq suchthat∀w ∈ [0,1],h¯(w) = h(f(0,w)). From corresponds∀j∈{1,2,...,n}to
(G.8), wegetthath¯(W) = h(f(0,W)) a=.s. h(W˜). Thislastrela- Y[δ] =η (X )+h(W ). (H.5)
tionshipimplies(X,Y)a=.s. (X,η(X)+h(W˜))a=.s. (X,η(X)+h¯(W)). j θ,δ j j
Consequently, recalling Def. 4 (and that X ∼ µ), we get that The nominal model corresponds to η θ(·) = η θ,0(·); hence, the
(X,Y)∼add(η,h¯;µ). residualisasfollows∀j∈{1,2,...,n}:
The fact that for any system (X,Y) with X ∼ µ and
R[δ] ≡Y[δ]−η (X )=η (X )−η (X )+h(W ). (H.6)
(X,Y)a=.s. (X,η(X)+h(W˜))whereW˜ followsanarbitrarydistri- j j θ,0 j θ,δ j θ j j
bution,thereexistsafunctionh¯(·)suchthat(X,Y)∼add(η,h¯;µ)
showsthegeneralityofDef.4. 28Although in Sec. 7, a potentially drifted system is expressed as
(X,Y) ∼ add(ηθ,δ,h;µ), in this description, we express it with the notation
(X[δ],Y[δ]) ∼ add(ηθ,δ,h;µ))tomakeexplicittheeffectsofδintherandom
variables.
27Eventhoughbmaybeunknown,itcanbeeasilyestimatedfromasampling 29NotethatXdoesnotdependonδ;accordingtoournotation,thiscanbe
ofthesystem:Zn=(Xj,Yj)n j=1,asbˆ = 1 n(cid:80)n j=1Yj−η(Xj). writtenasX[ jδ]=Xj,∀δ∈R2.
22LinearSystem. Thelinearsystemsaredeterminedbyasimple
TableH.1:NominalparametersoftheMLPsystem.
linear combination of the input coordinates. The expressions
forη (·)andh(·)areasfollows∀(u,s)∈R2and∀w∈R:
θ,δ Parameter Value Parameter Value
η θ,δ(u,s)=(c 1+δ 1)u+(c 2+δ 2)s, (H.7) w −0.66612 w −0.13874
11 12
h(w)=kw. (H.8) w −0.33963 w −0.18860
21 22
b −0.62466 b 0.28375
In consequence, the (actual) output (H.9), nominal output 1 2
(H.10),andresidual(H.11),correspond∀j∈{1,2,...,n}to wh −0.63385 wh −0.04506
1 2
b 0.24580
hidden
Y[δ] =(c +δ )U +(c +δ )S +kW , (H.9)
j 1 1 j 2 2 j j
η (X )=c U +c S , (H.10)
θ j 1 j 2 j
R[ jδ] =δ 1U j+δ 2S j+kW j. (H.11) where σ(·) is a LeakyReLU activation function with positive
and negative slope of 1 and 0.01, respectively [61], and W ,
in
Polynomial System. The polynomial systems are determined
δ ,b ,andw aresuchthat
W in hidden
by a linear combination of non-linear transformations of the
(cid:32) (cid:33)
i fn op llu ot wc so ∀o (r ud ,in sa )t ∈es R. 2T ah ne de ∀x wpr ∈es Rsi :ons for η θ,δ(·) and h(·) are as
W
in
=
ww
11
ww
12 , (H.22)
21 22
(cid:32) (cid:33)
δ δ
η θ,δ(u,s)=(c 1+δ 1)u2+(c 2+δ 2)s3, (H.12) δ
W
= 01 02 , (H.23)
h(w)=kw. (H.13)
b
=(cid:16)
b b
(cid:17)T
, (H.24)
in 1 2
I (n H.1co 5n ),s ae nq due rn ec se id, ut ah le (H(a .1c 6tu ),al c) oro ru et sp pu ot nd(H ∀.1 j4 ∈), {1n ,o 2m ,.i .n .a ,l n}o tu otput
w
hidden
=(cid:16)
wh
1
wh
2
(cid:17)T
. (H.25)
Y[δ] =(c +δ )U2+(c +δ )S3+kW , (H.14) Thevaluesofthenominalparametersshownin(H.21)–(H.25)
j 1 1 j 2 2 j j
forthefixedrandomseedweusedinournumericanalysiscan
η (X )=c U2+c S3, (H.15)
θ j 1 j 2 j befound(uptofivedecimals)inTableH.1.
R[δ] =δ U2+δ S3+kW . (H.16) With respect to the noise model, h(·) is the identity func-
j 1 j 2 j j tion,i.e.,∀w ∈ R,h(w) = w. Inconclusion,the(actual)output
Trigonometric System. The trigonometric systems are deter- (H.26),nominaloutput(H.27)andresidual(H.28),correspond
minedbyaninput-outputrelationshipexpressedbytrigonomet- ∀j∈{1,2,...,n}to
ricfunctions. Theexpressionsforη (·)andh(·)areasfollows
θ,δ
∀(u,s)∈R2and∀w∈R: Y[ jδ] =wT hidden·σ((W in+δ W)·X j+b in)+b hidden+W j,
(H.26)
η (u,s)=(A+δ )sin(u·s+ϕ+δ ), (H.17)
θ,δ 1 2 η (X )=wT ·σ(W ·X +b )+b , (H.27)
h(w)= A sin(f ·w+ϕ ). (H.18) θ j hidden (cid:104) in j in hidden
W W W R[δ] =wT · σ((W +δ )·X +b )
j hidden in W j in
(cid:105)
Inconsequence,the(actual)output(H.19)andnominaloutput −σ(W ·X +b ) +W . (H.28)
in j in j
(H.20),correspond∀j∈{1,2,...,n}to
Appendix H.1.2. AutoregressiveSystems
Y[δ] =(A+δ )sin(U ·S +ϕ+δ )
j 1 j j 2 Autoregressive(AR)systemstreatedinourexperimentsare
+A Wsin(f W·W j+ϕ W), (H.19) a modification of Def. 4 that is described by the following re-
η (X )= Asin(U ·S +ϕ). (H.20) cursiveformula∀j∈{1,2,...,n}:30
θ j j j
Theresidualexpression(R[ jδ])cannotbesimplifiedfurtherthan D[ jδ] =η θ,δ(D[ jδ −] 1,U j)+H j, (H.29)
shownin(H.6). Y[δ] = D[δ]+W , (H.30)
j j j
MLPSystem. TheMLPsystemsarebuiltuponanMLP-based where the r.v.s U, H, and W are the exogenous input, model
deterministic input-output relationship affected by additive noise,andmeasurementnoise,respectively.Letusnotethatthe
noise. In this case, the MLP consists of a single hidden layer system output is Y[δ], so the inner state of the system (D[δ]) is
j j
withtwohiddenunits;thenominalparameterswerechosenran- not accessible without measurement noise contamination;
domlyfromafixedrandomseed. Theexpressionforthefunc- hence, our input for the nominal model, η (·), corresponds to
θ
tioninducedbytheδ-disturbedMLP,η (·),is∀x∈R2,
θ,δ
η θ,δ(x)=wT hidden·σ((W in+δ W)·x+b in)+b hidden, (H.21) 30WeconsiderthespecialcasesD0≡d0(seeTableH.2)andW0≡0.
23X[δ] = (Y[δ],U ). Thissaid,thenominaloutputcorrespondsto
j j−1 j TableH.2:Constantcoefficientvaluesforthenumericalanalysis.
η (X[δ]);hence,theresidualcorrespondsto
θ j
Coefficient Value Coefficient Value
R[δ] ≡Y[δ]−η (X[δ])=η (D[δ] ,U )−η (Y[δ],U )+H +W .
j j θ j θ,δ j−1 j θ j−1 j j j
(H.31) a U −2.0 c 3 0.8
b 2.0 c −0.5
U 4
ARXSystem. Thelinearautoregressivesystemwithexogenous µ 0.5 c 1.0
S √ 5
input (ARX) is similar to the Linear system, but rather than a σ 2 3/3 A 1.0
S
fullexogenousinput, onecomponentofitsinputisaprevious µ 0.0 ϕ 0.0
H
stepofthesystemstate. Theexpressionofη θ,δ(·)isasfollows σ
H
0.1 d
0
0.0
∀(d,u)∈R2:
a −0.1 k 1.0
W
η (d,u)=(c +δ )d+(c +δ )u. (H.32) b W 0.1 A W 1.5
θ,δ 1 1 2 2
c 0.6 f 1.0
1 W
In consequence, the (actual) output (H.33), nominal output c −0.4 ϕ 0.0
2 W
(H.34),andresidual(H.35)correspond∀j∈{1,2,...,n}to
Y[δ] =(c +δ )D[δ] +(c +δ )U +H +W , (H.33)
j 1 1 j−1 2 2 j j j
η (X[δ])=c (D[δ] +W )+c U , (H.34) Appendix H.2.2. CorrelationMethod
θ j 1 j−1 j−1 2 j
This method corresponds to the maximum absolute value
R[ jδ] =δ 1D[ jδ −] 1+δ 2U j−c 1W j−1+H j+W j. (H.35) ofthePearson correlationcoefficientofthe residualwithboth
NARX System. The non-linear autoregressive system with ex- coordinatesoftheinput;wedenotethisas
ogenous input (NARX) is a system with a non-linear relation-
MAPC(J[δ])≡max{|corr(X[δ] ,R[δ])|,|corr(X[δ] ,R[δ])|},
shipbetweenthecurrentoutputandtheARinput(previousout- n n,(1) n n,(2) n
(H.39)
putandexogenousinput).Theexpressionofη (·)isasfollows
∀(d,u)∈R2: θ,δ where we denote ∀j ∈ {1,2,...,n},X[ jδ] ≡ (X[ j,δ (] 1),X[ j,δ (] 2)),
X[δ] ≡ (X[δ] )n , and X[δ] ≡ (X[δ] )n ; and corr(·,·) is a
η δ(d,u)=(c 3+δ 1+c 4exp(−d2))·d+(c 5+δ 2)·u2. (H.36) mn a, p(1 p) ing sucj, h(1) thj= a1 t for twon, a(2 r) bitrary vj,( e2 c) toj= r1 s x = (x )n ∈ Rn
j j=1
and r = (r )n ∈ Rn, their Pearson correlation coefficient is
Inconsequence,the(actual)output(H.37)andnominaloutput j j=1
(H.38),correspond∀j∈{1,2,...,n}to expressedby
Y[ jδ] =(c 3+δ 1+c 4exp(−(D[ jδ −] 1)2))·D[ jδ −]
1 corr(x,r)≡
(cid:80)n
j=1(x j−x¯)(r j−r¯)
, (H.40)
+(c +δ )·U2+H +W , (H.37)
(cid:104)(cid:16)(cid:80)n
(x
−x¯)2(cid:17) ·(cid:16)(cid:80)n
(r
−r¯)2(cid:17)(cid:105)1/2
5 2 j j j j=1 j j=1 j
η θ(X[ jδ])=(c 3+c 4exp(−(D[ jδ −] 1+W j−1)2))·(D[ jδ −] 1+W j−1) wherex¯= 1(cid:80)n x andr¯= 1(cid:80)n r .
n j=1 j n j=1 j
+c ·U2. (H.38)
5 j
Appendix H.2.3. RMSEMethod
The residual expression (R[δ]) can be obtained by replacing
j Thismethodcorrespondstotheempiricalrootmeansquared
(H.37)and(H.38)in(H.31). errorcomputedfromtheresidual;wedenotethisasRMSE(R[δ]),
n
whichcanbeexpressedas
Appendix H.2. ModelDriftQuantificationMethods
Here,wedescribethemethodsweuseforquantifyingmodel (cid:118)(cid:116) 1(cid:88)n
drift; these methods were applied to all systems, as seen in RMSE(R[δ])≡ (R[δ])2. (H.41)
n n j
Fig. 3 and Fig. 4. One of these methods corresponds to our j=1
MI-basedRIVmethod,andtheothertwoarebaselinesweuse
tocompareourmethod. Toquantifymodeldrift, theRIVand Appendix H.3. SummaryofFigure3andFigure4
Correlation methods have the input-residual sampling (J[δ]) as Withalltheelementsdescribedinthissection,wesumma-
n
their own input, while the RMSE method only considers the rizethedescriptionofFig.3andFig.4. Thesefigurescontain
residualsampling(R[δ])asitsinput.
12 and 6 colormaps, respectively. Each figure is divided into
n
3 rows; Fig. 3 and Fig. 4 are divided into 4 and 2 columns,
Appendix H.2.1. RIVMethod respectively. The rows correspond to results for each one of
Thismethodisourmethodologicalcontribution,andasde- themethodsdescribedinSec.Appendix H.2,andthecolumns
tailed in Sec. 4, a RIV corresponds to the MI estimation be- correspond to results for each one of the systems described in
tweentheinputandtheresidualwiththeMIestimatorpresented Sec. Appendix H.1. The correspondence is made clear in the
in[40]. AnexplanationofhowthisMIestimationiscomputed labelsofeachrowandcolumn.
isshowninSec.4.2. Formally,givenasamplingJ[ nδ],wecom- Each colormap is a visualization of a matrix. Each cell of
puteI bλ n,n ,dn(J[ nδ]),whereλ=2.3·10−5,d n =exp(n−1/3),b n =wn−l these matrices is related to a single δ = (δ 1,δ 2) value where
withw=5·10−2andl=0.167,andn=2000. bothδ andδ rangefrom−0.15to0.15withastepof0.0015;
1 2
24i.e., each matrix has 201·201 = 40401 cells. The value of of the original interval by using a mapping d : R2 → B(R2)
y
thecellcorrespondstotheaveragevalueofapplyingthecorre- such that d (a,b) = {(a,(a + b)/2),((a + b)/2,b)};31 using
y
spondingmethodtoasamplingJ[δ] orR[δ],respectively,ofthe this mapping, we can define the partition of I as
n n (cid:110) a,(cid:111)b
corresponding δ-drifted system; this average value is obtained P ≡ ×r [x ,y ):∀j∈{1,2,...,r},(x ,y )∈d (a ,b ) .Let
over10differentrandomseeds. usa, nb otethaj= t1
P
j pj artitionstherectangleIj inj to2ry smj allej
rrect-
a,b a,b
angleswithhalfthesideoftheoriginal.
Anotherdefinitionweareinterestedinforoperatinginour
Appendix I. Error-BarAnalysisofModelDriftExperiment
sequence of sets is their generalized diagonal. If we consider
onSyntheticDistributionDrifts
d as the Euclidean distance, then (Rr,d ) is a metric space,
E E
Inthissection,weperformanerror-baranalysisfortheex- andwecandefinethegeneralizeddiagonal(GD)ofeverynon-
perimentconductedinSec.7.Thiserroranalysisissummarized emptysetS ⊆ Rr asdiag(S) ≡ sup d (x,y). Letusnote
(x,y)∈S2 E
(cid:113)
inFig.I.1,whichcontainsfiguresanalogoustoFig.3andFig.4 thatdiag(I ) = (cid:80)r (b −a )2,andthatforeveryS ∈ P ,
(Fig.I.1aandFig.I.1b,respectively)withtheonlydifferenceof a,b j=1 j j a,b
(cid:113)
reportingthestandarddeviationinsteadoftheaveragevalue. itsGDisdiag(S)= (cid:80)r ((b −a )/2)2 =diag(I )/2.
j=1 j j a,b
First, we can see that all the colormaps shown in Fig. I.1 As we are dealing with a r.v. (U) such that ∀A ∈ B(Rr),
displaystandarddeviationvaluesofatleastoneorderofmag- P(U ∈ A) ∈ {0,1};weneedtonotethatifwehaveanarbitrary
nitude smaller than the average values reported in Fig. 3 and setIandapartitionPofit,then32
Fig.4;thisvalidatestheconsistencyofourresultsoverdifferent
seeds, and in consequence, validates our discussion and inter- [P(U ∈ I)=1]⇒[∃!B∈ P:P(U ∈ B)=1]. (J.1)
pretationoftheresults. Moreover,thisconsistencystrengthens
thenumericalvalidationofourRIVmethodfordetectingmodel Moving now to the core of our proof, if we denote
drift. 1 ≡ (1)r j=1 ∈ Rr, we can see that {I k,k+1} k∈Zr is a partition of
We remark on two elements seen in Fig. I.1 regarding our Rr, and from (J.1), there exists a unique m ∈ Zr such that
method.First,wecanseeregionsofzeroempiricalstandardde- P(I m,m+1) = 1. Then, we can build a sequence of rectangles
viationattheregionswherezeroaverageestimatedMIwasre- (I an,bn) n∈Nsuchthat(a 1,b 1)=(m,m+1)and(a n+1,b n+1)corre-
portedinFig.3andFig.4;thishastodowiththeexponentially sponds to the unique element in the singleton
fast decision convergence of our method on the null hypothe- {(x,y) ∈ Rr+r : [I ∈ P ∧ P(U ∈ I ) = 1]}. This
x,y an,bn x,y
sis(Theorem3). Second,wehighlightthatoutsidetheregions means that the (n+1)-th term of the sequence corresponds to
with zero estimated MI, there is no clear increase or decrease theuniquerectanglewithaprobabilitymeasureof1withinthe
of standard deviation as we go farther from δ = 0; we under- onesgeneratedbythedyadicpartitionoftherectanglethatcor-
stand this as a display of uniform consistency of our method respondstothen-thterm.
regardlessofthedriftcharacteristics.
Weareinterestedindefiningasequenceofclosedsetssuch
thateachelementhasaprobabilitymeasureof1. Theideafor
Appendix J. SupportingResult—ProofofLemma2 thissequenceistoconvergetoasingletonandusethecontinuity
oftheprobabilitymeasuretoconcludethatthissingletonhasa
Lemma2statesthatifanyrandomvariable(U)hasadegen- probabilitymeasureof1. Todealwithclosedsets,wewillcon-
eratedistribution,i.e.,themeasureitinducesonlytakesvalues sidertheclosedrectangleastheclosureofan(open)rectangle,
in1or0,thenthisr.v. iscollapsedtoasinglemasspoint,i.e., i.e., cl(I ) ≡ ×r [a ,b ] ∈ B(Rr). Then, itispossibletode-
itisdeterministicinthesensethat∃c∈Rr :P(U =c)=1. finethesa, eb quencej= o1 fsej tsj (C n) n∈N,where∀n∈N,C
n
=cl(I an,bn);
thissequencesatisfiesthefollowingproperties∀n∈N:
ProofofLemma2. Beforestartingthisproof,weneedtostate
s vo em ctoe rsm aino =r d (e afi )n rition ∈s. RrLe at ndus bco =ns (id be )r ra p ∈air Ro rf sa ur cb hitr ta hr ay
t
[P(U ∈C n)=1] ∧ [C n+1 ⊆C n] ∧ [C nisaclosedset]. (J.2)
j j=1 j j=1 √
∀j ∈ {1,2,...,r}, a j < b j for an arbitrary r ∈ N, and let us Oneadditionalpropertyof(C n) n∈N, isthatdiag(C 1) = r and
d asefi I an ,be ≡the ×rr j=e 1c [t aan j,g ble j)w ∈h Bo (s Re rm ).ain opposite vertices are a and b d ∀i nag ∈(C Nn+ ,1 d) ia= g(d Ci na )g( =C n) √/ r2 /a 2s n−I 1a ,n+ a1, nbn d+1 in∈ pP aa rn t, ib cn u. laIn r,c wo ens he aq vu een thc ae t,
The idea of this proof is to build a sequence of nested
rectangle-based partitions and note that we can define a se-
quence of sets that converges to a singleton such that each of 31Weremark,toavoidconfusion,thatboth(a,(a+b)/2)and((a+b)/2,b)
its elements has a probability measure of 1. The value in the indy(a,b)arecoordinatepairsinR2 andnotopenintervals. Moreover,itis
singleton of convergence of the sequence will correspond to
easytoseethatanyintervaldefinedby(a,b)haslengthb−a,andanyinterval
thesingledeterministicpointtowhichther.v. isalmostsurely defi 32n Ee qd ub ay tio(x n,y (J) .1∈ )d cy a( na, bb e) ph ra os vl ee nng bt yh n(b ot− ina g)/ th2 a. tP(U ∈ I)=(cid:80) S∈PP(U ∈S).
equal. Existence of B can be proven easily, as else it would be satisfied that
We start by partitioning I in dyadic rectangles. For this ∀S ∈P,P(S ∈U)=0,which,inturn,wouldimplythatP(U∈I)=0,andcon-
a,b
purpose, let us consider any pair (a,b) ∈ R2 which defines an sequently,contradictingP(U∈I)=1.Uniquenesscanbeprovenbycontradic-
interval such that a < b; then, we can get the set that con- tt hio isn; wif ow ule dc io mn ps li yde tr haB t1 P∈ (UPa ∈nd I)B ≥2∈ P(P Usu ∈ch Bt 1h )at +P P(U (U∈ ∈B1 B) 2=
)
=P( 2U ,w∈ hB i2 c) h= is1 a,
tains both pair of values that define each dyadic sub-intervals contradiction.
25System System
Linear Polynomial Trigonometric MLP ARX NARX
0.03
0.1 0.1 0.02 0.02
0.0 0.0
0.01 0.01
0.1 0.1
0.00 0.00
0.1 0.03 0.1 0.02
0.02
0.0 0.0
0.01 0.01
0.1 0.1
0.00 0.00
0.1 0.1
0.0 102 0.0 102
0.1 103 0.1
1 value 1 value 1 value 1 value 1 value 1 value
(a)ForwardSystems. (b)AutorergessiveSystems.
FigureI.1:StandarddeviationsforthenumericalresultsofourRIVmethodandbaselinesonparametrizeddrifts.
lim n→∞diag(C n)=0. Thislastlimit,inadditionto(C n) n∈N be- Acknowledgements
ingasequenceofnestedclosednon-emptysets–see(J.2)–en-
ablesustoinferfromCantor’sIntersectionTheorem[62,Theo-
This material is based on work supported by grants of
rem C, Sec. 2.12] that there exists c ∈ Rr such that
CONICYT-Chile,Fondecyt1210315,andtheAdvancedCenter
(cid:84)∞ C ={c}. Then,wecanseethat
i=1 i for Electrical and Electronic Engineering, Basal Project
  FB0008. CamiloRam´ırezissupportedbyANID-Subdireccio´n
P(U =c)=P(U ∈{c})=PU
∈(cid:92)∞
C k, (J.3) de Capital Humano/Mag´ıster-Nacional/2023 - 22230232 mas-
k=1 ter’sscholarship. TheworkofMarcosOrchardissupportedby
grantsofCONICYT-Chile,Fondecyt1210031.WethankDiane
wherethelastterm,duetothecontinuityoftheprobabilitymea-
GreensteinandSebastia´nEspinozaforeditingandproofreading
surePandtheset-theoreticdefinitionoflimit[60], canbeex-
allthismaterial.
pressedas
     
PU
∈(cid:92)∞
C
k=PU
∈ lim
(cid:92)n
C
k=
lim
PU
∈(cid:92)n
C
k.
References
n→∞ n→∞
k=1 k=1 k=1
(J.4)
[1] M. Kordestani, M. Saif, M. E. Orchard, R. Razavi-Far, K. Khorasani,
Fromthenestedpropertyof(C n) n∈Nshownin(J.2),itisimplied
Failureprognosisandapplications—asurveyofrecentliterature, IEEE
that∀n∈N,
transactionsonreliability70(2)(2019)728–748. doi:10.1109/TR.
(cid:92)n 2019.2930195.
C k =C n. (J.5) [2] V. Atamuradov, K. Medjaher, P. Dersin, B. Lamoureux, N. Zer-
k=1 houni,Prognosticsandhealthmanagementformaintenancepractitioners-
review, implementation and tools evaluation, International Journal of
Asalaststep,letusnotethat
PrognosticsandHealthManagement8(3)(2017)1–31.doi:10.36001/
ijphm.2017.v8i3.2667.
P(U =c)
[3] C.Song, K.Liu, X.Zhang, Integrationofdata-levelfusionmodeland
=P
U
∈(cid:92)∞
C
k

(J.6)
k
T
2e 0rar 1n
n
7e
s
.l
a
2cm
t
7ie
o
1t
n
5h
s
1od 8os
0n
.f Ror eld iae bg ir la itd yat 6io 7n (2m )o (d 2e 0l 1in 7g )6an 4d 0–p 6r 5o 0g .no ds oti ic :a 1n 0a .ly 1s 1i 0s, 9I /E TE RE
.
k=1
  [4] A.Abid,M.T.Khan,J.Iqbal,Areviewonfaultdetectionanddiagnosis
= lim
PU
∈(cid:92)n
C
k
(J.7)
t 3e 6c 3h 9n –iq 3u 6e 6s 4: .b da os iic :s 1a 0n .d 10b 0ey 7o /n sd 1, 0A 46rt 2ifi -c 0i 2al 0-In 0t 9el 9li 3g 4e -n 2ce
.
Review54(2021)
n→∞
k=1 [5] D.Miljkovic´,Faultdetectionmethods:Aliteraturesurvey,in:2011Pro-
= lim P(U ∈C ) (J.8) ceedingsofthe34thinternationalconventionMIPRO,IEEE,2011,pp.
n
n→∞ 750–755.
= lim 1=1, (J.9) [6] R.J.Patton,J.Chen,Robustfaultdetectionofjetenginesensorsystems
n→∞ usingeigenstructureassignment,JournalofGuidance,Control,andDy-
namics15(6)(1992)1491–1497.doi:10.2514/3.11413.
where (J.6), (J.7), (J.8), and (J.9) come from (J.3), (J.4), (J.5) [7] P. M. Frank, Fault diagnosis in dynamic systems using analytical and
andthefirstpropertyshownin(J.2),respectively. knowledge-basedredundancy:Asurveyandsomenewresults,Automat-
Atthispoint, wehaveshowntheexistenceofc ∈ Rr such ica26(3)(1990)459–474.doi:10.1016/0005-1098(90)90018-D.
[8] T.Escobet,L.Trave´-Massuye`s,Parameterestimationmethodsforfault
that P(U = c) = 1, which was precisely what is stated in
detectionandisolation,in: BridgeWorkshopNotes,Vol.40,2001,pp.
Lemma2. Hence,concludingourproof. □ 1–11.
26
dohtem
VIR
noitalerroC
ESMR
)sruo(
dohtem
dohtem
eulav
2
eulav
2
eulav
2
1.0 0.0 1.0 1.0 0.0 1.0 1.0 0.0 1.0 1.0 0.0 1.0
]stib[
)VIR(dts
))R,X(CPAM(dts
))R(ESMR(dts
dohtem
VIR
noitalerroC
ESMR
)sruo(
dohtem
dohtem
eulav
2
eulav
2
eulav
2
1.0 0.0 1.0 1.0 0.0 1.0
]stib[
)VIR(dts
))R,X(CPAM(dts
))R(ESMR(dts[9] H. Li, Y. Gao, P. Shi, H.-K. Lam, Observer-based fault detection for turing systems: a behavioral model approach, in: [1990] Rensselaer’s
nonlinearsystemswithsensorfaultandlimitedcommunicationcapac- SecondInternationalConferenceonComputerIntegratedManufacturing,
ity,IEEETransactionsonAutomaticControl61(9)(2015)2745–2751. IEEEComputerSociety,1990,pp.252–253.doi:10.1109/CIM.1990.
doi:10.1109/TAC.2015.2503566. 128107.
[10] M.Said, R.Fazai, K.BenAbdellafou, O.Taouali, Decentralizedfault [29] J.Gama,P.Medas,G.Castillo,P.Rodrigues,Learningwithdriftdetec-
detectionandisolationusingbondgraphandPCAmethods,Theinterna- tion,in: AdvancesinArtificialIntelligence–SBIA2004,Springer,2004,
tionaljournalofadvancedmanufacturingtechnology99(2018)517–529. pp.286–295.doi:10.1007/978-3-540-28645-5\_29.
doi:10.1007/s00170-018-2526-4. [30] M. H. Ardakani, M. Askarian, G. Escudero, M. Graells, A. Espuna,
[11] M. P. Fanti, A. M. Mangini, W. Ukovich, Fault detection by labeled Toward online explore of concept drift for fault detection of chemical
petrinetsincentralizedanddistributedapproaches, IEEETransactions processes, in: Computer Aided Chemical Engineering, Vol. 40, Else-
onAutomationScienceandEngineering10(2)(2012)392–404. doi: vier, 2017, pp. 1657–1662. doi:10.1016/B978-0-444-63965-3.
10.1109/TASE.2012.2203596. 50278-6.
[12] S.M.Tabatabaeipour,Activefaultdetectionandisolationofdiscrete-time [31] J.Gama,I.Zˇliobaite˙,A.Bifet,M.Pechenizkiy,A.Bouchachia,Asurvey
linear time-varying systems: a set-membership approach, International onconceptdriftadaptation,ACMcomputingsurveys46(4)(2014)1–37.
JournalofSystemsScience46(11)(2015)1917–1933. doi:10.1080/ doi:10.1145/2523813.
00207721.2013.843213. [32] J.Lu,A.Liu,F.Dong,F.Gu,J.Gama,G.Zhang,Learningunderconcept
[13] C.Jauberthie,N.Verdie`re,L.Trave´-Massuye`s,Faultdetectionandiden- drift: Areview, IEEEtransactionsonknowledgeanddataengineering
tification relying on set-membership identifiability, Annual Reviews in 31(12)(2018)2346–2363.doi:10.1109/TKDE.2018.2876857.
Control37(1)(2013)129–136. doi:10.1016/j.arcontrol.2013. [33] M.Lima,M.Neto,T.S.Filho,R.A.deA.Fagundes,Learningunder
04.002. conceptdriftforregression—asystematicliteraturereview,IEEEAccess
[14] S.M.Tabatabaeipour,P.F.Odgaard,T.Bak,J.Stoustrup,Faultdetection 10(2022)45410–45429.doi:10.1109/ACCESS.2022.3169785.
ofwindturbineswithuncertainparameters:Aset-membershipapproach, [34] J. G. Moreno-Torres, T. Raeder, R. Alaiz-Rodr´ıguez, N. V. Chawla,
Energies5(7)(2012)2424–2448.doi:10.3390/en5072424. F. Herrera, A unifying view on dataset shift in classification, Pattern
[15] B. Mu, X. Yang, J. K. Scott, Comparison of advanced set-based fault recognition45(1)(2012)521–530. doi:10.1016/j.patcog.2011.
detectionmethodswithclassicaldata-drivenandobserver-basedmethods 06.019.
foruncertainnonlinearprocesses, Computers&ChemicalEngineering [35] Y. Yamanaka, T. Iwata, H. Takahashi, M. Yamada, S. Kanai, Autoen-
166(2022)107975.doi:10.1016/j.compchemeng.2022.107975. codingbinaryclassifiersforsupervisedanomalydetection,in: PRICAI
[16] F. Tamssaouet, K. T. Nguyen, K. Medjaher, M. E. Orchard, System- 2019: Trends in Artificial Intelligence, Springer, 2019, pp. 647–659.
level failure prognostics: Literature review and main challenges, Pro- doi:10.1007/978-3-030-29911-8\_50.
ceedings of the Institution of Mechanical Engineers, Part O: Jour- [36] M.A.Bansal, D.R.Sharma, D.M.Kathuria, Asystematicreviewon
nal of Risk and Reliability 237 (3) (2023) 524–545. doi:10.1177/ datascarcityproblemindeeplearning: Solutionandapplications,ACM
1748006X221118448. ComputingSurveys54(10s)(2022)1–29.doi:10.1145/3502287.
[17] K.T.P.Nguyen, Featureengineeringandhealthindicatorconstruction [37] A.Bifet, R.Gavalda`, Learningfromtime-changingdatawithadaptive
forfaultdetectionanddiagnostic,in:K.P.Tran(Ed.),ControlChartsand windowing, in: Proceedings of the 2007 SIAM international confer-
Machine Learning for Anomaly Detection in Manufacturing, Springer, ence on data mining, SIAM, 2007, pp. 443–448. doi:10.1137/1.
2022,pp.243–269.doi:10.1007/978-3-030-83819-5\_10. 9781611972771.42.
[18] S.Cheng,M.H.Azarian,M.G.Pecht,Sensorsystemsforprognostics [38] K.Nishida,K.Yamauchi,Detectingconceptdriftusingstatisticaltesting,
and health management, Sensors 10 (6) (2010) 5774–5797. doi:10. in: International conference on discovery science, Springer, 2007, pp.
3390/s100605774. 264–269.doi:10.1007/978-3-540-75488-6\_27.
[19] X.Ding,P.M.Frank,Frequencydomainapproachandthresholdselector [39] T.M.Cover,J.A.Thomas,ElementsofInformationTheory,2ndEdition,
forrobustmodel-basedfaultdetectionandisolation,in:FaultDetection, WileyInterscience,NewYork,2005.doi:10.1002/047174882X.
SupervisionandSafetyforTechnicalProcesses1991,Elsevier,1992,pp. [40] J.F.Silva, S.Narayanan, Complexity-regularizedtree-structuredparti-
271–276.doi:10.1016/B978-0-08-041275-7.50041-7. tionformutualinformationestimation,IEEEtransactionsoninformation
[20] S.-A. Raka, C. Combastel, Fault detection based on robust adaptive theory58(3)(2012)1940–1952.doi:10.1109/TIT.2011.2177771.
thresholds: A dynamic interval approach, Annual Reviews in Control [41] M.AriasChao,C.Kulkarni,K.Goebel,O.Fink,Aircraftenginerun-to-
37(1)(2013)119–128.doi:10.1016/j.arcontrol.2013.04.001. failuredatasetunderrealflightconditionsforprognosticsanddiagnostics,
[21] Z. Wang, H. Shang, Kalman filter based fault detection for two- Data6(1)(2021)5.doi:10.3390/data6010005.
dimensionalsystems,JournalofProcessControl28(2015)83–94. doi: [42] S.Verron,T.Tiplica,A.Kobi,Faultdetectionandidentificationwitha
10.1016/j.jprocont.2015.03.002. newfeatureselectionbasedonmutualinformation, JournalofProcess
[22] S.Yoon,J.F.MacGregor,Statisticalandcausalmodel-basedapproaches Control18(5)(2008)479–490.doi:10.1016/j.jprocont.2007.08.
tofaultdetectionandisolation,AIChEJournal46(9)(2000)1813–1824. 003.
doi:10.1002/aic.690460910. [43] M. M. Rashid, J. Yu, A new dissimilarity method integrating multidi-
[23] J.Guo,X.Wang,Y.Li,kNNbasedonprobabilitydensityforfaultde- mensionalmutualinformationandindependentcomponentanalysisfor
tectioninmultimodalprocesses,JournalofChemometrics32(7)(2018) non-gaussiandynamicprocessmonitoring,ChemometricsandIntelligent
e3021.doi:10.1002/cem.3021. Laboratory Systems 115 (2012) 44–58. doi:10.1016/j.chemolab.
[24] P.Santos,L.F.Villa,A.Ren˜ones,A.Bustillo,J.Maudes,AnSVM-based 2012.04.008.
solutionforfaultdetectioninwindturbines,Sensors15(3)(2015)5627– [44] B.Jiang,W.Sun,R.D.Braatz,Aninformation-theoreticframeworkfor
5648.doi:10.3390/s150305627. fault detection evaluation and design of optimal dimensionality reduc-
[25] A.A.A.MohdAmiruddin,H.Zabiri,S.A.A.Taqvi,L.D.Tufa,Neu- tion methods, IFAC-PapersOnLine 51 (24) (2018) 1311–1316. doi:
ralnetworkapplicationsinfaultdiagnosisanddetection:anoverviewof 10.1016/j.ifacol.2018.09.565.
implementationsinengineering-relatedsystems,NeuralComputingand [45] F.Lv,S.Yu,C.Wen,J.C.Principe,Interpretablefaultdetectionusing
Applications32(2020)447–472.doi:10.1007/s00521-018-3911-5. projectionsofmutualinformationmatrix,JournaloftheFranklinInsti-
[26] R.Iqbal,T.Maniak,F.Doctor,C.Karyotis,Faultdetectionandisolation tute358(7)(2021)4028–4057. doi:10.1016/j.jfranklin.2021.
in industrial processes using deep learning approaches, IEEE Transac- 02.016.
tionsonIndustrialInformatics15(5)(2019)3077–3084.doi:10.1109/ [46] M.M.Lazarescu,S.Venkatesh,H.H.Bui,Usingmultiplewindowsto
TII.2019.2902274. trackconceptdrift, Intelligentdataanalysis8(1)(2004)29–59. doi:
[27] R.Zhao,R.Yan,Z.Chen,K.Mao,P.Wang,R.X.Gao,Deeplearning 10.3233/IDA-2004-8103.
anditsapplicationstomachinehealthmonitoring,MechanicalSystems [47] W. K. Newey, D. McFadden, Large sample estimation and hypothesis
andSignalProcessing115(2019)213–237. doi:10.1016/j.ymssp. testing,Handbookofeconometrics4(1994)2111–2245.doi:10.1016/
2018.05.050. S1573-4412(05)80005-4.
[28] L.E.Holloway,B.H.Krogh,Faultdetectionanddiagnosisinmanufac- [48] E.L.Lehmann,J.P.Romano,Testingstatisticalhypotheses,4thEdition,
27Springer,2022.doi:10.1007/978-3-030-70578-7. [56] D.K.Frederick,J.A.DeCastro,J.S.Litt,User’sguideforthecommercial
[49] C. E. Shannon, A mathematical theory of communication, The Bell modularaero-propulsionsystemsimulation(C-MAPSS),Tech.Rep.E-
system technical journal 27 (3) (1948) 379–423. doi:10.1002/j. 16205,NASA(2007).
1538-7305.1948.tb01338.x. [57] D.P.Kingma,J.Ba,Adam:Amethodforstochasticoptimization,arXiv
[50] R. Steuer, J. Kurths, C. O. Daub, J. Weise, J. Selbig, The mu- preprintarXiv:1412.6980(2014).doi:10.48550/arXiv.1412.6980.
tualinformation: Detectingandevaluatingdependenciesbetweenvari- [58] M.E.Gonzalez,J.F.Silva,M.Videla,M.E.Orchard,Data-drivenrepre-
ables,Bioinformatics18(suppl2)(2002)S231–S240. doi:10.1093/ sentationsfortestingindependence: Modeling,analysisandconnection
bioinformatics/18.suppl\_2.S231. withmutualinformationestimation, IEEETransactionsonSignalPro-
[51] T.Austin, Exchangeablerandommeasures, Annalesdel’InstitutHenri cessing70(2021)158–173.doi:10.1109/TSP.2021.3135689.
Poincare´,Probabilite´setStatistiques51(3)(2015)842–861. doi:10. [59] V. I. Bogachev, Measure theory, Springer, 2007. doi:10.1007/
1214/13-AIHP584. 978-3-540-34514-5.
[52] N.R.Draper,H.Smith,Appliedregressionanalysis,3rdEdition,John [60] A. Gut, Probability: A graduate course, 2nd Edition, Springer, 2013.
Wiley&Sons,1998.doi:10.1002/9781118625590. doi:10.1007/978-1-4614-4708-5.
[53] O.Kallenberg,Foundationsofmodernprobability,Springer,1997.doi: [61] A.L.Maas,A.Y.Hannun,A.Y.Ng,etal.,Rectifiernonlinearitiesim-
10.1007/b98838. proveneuralnetworkacousticmodels,in:Proceedingsofthe30thInter-
[54] J.M.Mendel,Lessonsinestimationtheoryforsignalprocessing,com- nationalConferenceonMachineLearning,Vol.28,2013,p.3.
munications,andcontrol,PearsonEducation,1995. [62] G.F.Simmons,Introductiontotopologyandmodernanalysis,McGraw
[55] K.J.Keesman,Systemidentification:Anintroduction,SpringerLondon, HillBookCompany,1963.
2011.doi:10.1007/978-0-85729-522-4.
28