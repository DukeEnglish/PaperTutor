An Empty Room is All We Want:
Automatic Defurnishing of Indoor Panoramas
MiraSlavchevau DaveGausebecku KevinChenu DavidBuchhofer AzwadSabik ChenMa
SachalDhillon OlafBrandt AlanDolhasz
Matterport
Abstract
Inputpanorama
We propose a pipeline that leverages Stable Diffusion to
improve inpainting results in the context of defurnishing—
the removal of furniture items from indoor panorama
images. Specifically, we illustrate how increased context,
domain-specific model fine-tuning, and improved image
blending can produce high-fidelity inpaints that are geo- StableDiffusion2.0inpainting
metricallyplausiblewithoutneedingtorelyonroomlayout
estimation. We demonstrate qualitative and quantitative
improvementsoverotherfurnitureremovaltechniques.
1.Introduction
Ourpipeline
The recent advancement of digital technologies has rev-
olutionized various industries, and real estate is no ex-
ception [40]. The emergence of digital twins—virtual
replicas of physical assets—has significantly impacted
the way properties are marketed, managed, and visual-
ized[16]. Digitaltwinsofferaplethoraofbenefits,includ-
ing enhanced decision-making [24], improved design pro- Figure 1. Indoor panorama defurnishing. Our custom fine-
cesses[9],andimmersiveexperiencesforstakeholders[12]. tuningofStableDiffusioninpaintingreducesitstendencytohal-
While digital twins excel in replicating physical struc- lucinateobjectsnearshadowsandreflections,suchastheradiators
onthewallsandlampinthecorner.
tureswithremarkableaccuracy,theyoftenlacktheflexibil-
itytoadapttodifferentdownstreamscenariosandrequire-
ments. One critical aspect that remains underexplored is
representations of digital twins, such as polygon meshes,
defurnishing: removing furnishings and objects from vir-
to future work. Additionally, while a digital twin may be
tualrepresentationsofbuiltenvironments[14]. Defurnish-
composedofseveralposedpanoramaimages, wefocuson
ingoffersnumerousadvantages,suchasenablingpotential
defurnishingsingleimagesinisolationanddonotconsider
buyers or renters toenvision personalized layouts [47], fa-
consistencybetweenmultipleviews.
cilitating interior design experimentation [22], and provid-
Recentadvancesingenerativemodels,suchaslatentdif-
ing insights for property evaluation and renovation [7]. It
fusionmodels[36],havedramaticallyimprovedthequality
isafundamentalcomponentofanyworkflowdealingwith
of image inpainting [10] by leveraging learned contextual
digitaltwins,particularlywhencapturedfromabuiltenvi-
priorstobettercompletethemissinginformationinanim-
ronmentratherthansynthesizedfromthegroundup.
age. However, as these models are commonly trained to
Inthispaper,wefocusondefurnishingindoorpanorama
inpaint objects and scene content rather than empty space,
images, leaving the study of defurnishing other common
spuriousinpaintsorhallucinations[28,59]tendtobeasig-
udenotesequalcontribution. nificant problem when using these models in the context
#research@matterport.com of defurnishing. Specifically, Stable Diffusion attempts to
1
4202
yaM
6
]VC.sc[
1v28630.5042:viXra“explainaway”contextualinformationsuchasshadowsand 2. Inpaintonthecombinedfurnituremasks.
objectpartsleftbehindfromsmallimperfectionsinthein- Whileanoff-the-shelfsemanticsegmentationmodel[4,11,
painting mask by placing objects where empty space was 29,37,57]trainedonasuitableontology[58]issufficient
expected(seeFigure1).Thisissuecanbepartiallyresolved for the first step, a number of different approaches [13–
by applying morphological operations such as dilation to 15, 21, 25] have been explored to obtain realistic inpaints
theinpaintingmask[20],butthisdoesnotadequatelyhan- using CNN GAN inpainting models. PanoDR [14] pro-
dleallcasesofshadows,lightbeams,andothersimilaref- posed that in order to produce inpaints that preserve real-
fects, which are related to the furniture but not co-located life structures, predicting the room layout (e.g. segmenta-
withit[53]. tionforfloor,walls,andceiling)isacrucialpre-processing
Consequently, we present a system for automatic furni- step. Toaddressperspectivedistortionandmixingtextures
ture removal, at the core of which is a custom inpainting coming from different surfaces, Kulshreshtha et al. [25]
model that builds over Stable Diffusion in the following usedtheroomlayouttoseparatetheroomintodistinct3D
ways: planes [26], then inpainting each plane separately after or-
1. Leverages a custom dataset of unfurnished panoramas thographicreprojection. Gaoetal.[13]improveduponthis
andanaugmentationstrategytomakethemodelrobust byperforminginpaintingoneach3Dplaneinasingleend-
to imperfect masks, cast light beams, reflections, and to-endpipeline.
shadows,significantlyreducinghallucinations. These approaches all leverage a room layout estima-
2. Inpaints equirectangular images natively, significantly tor[42,56]toexplicitlyorimplicitlyguideinpainting. This
increasing the amount of available contextual informa- makesitdifficulttogeneralizethesemodelstohandlecer-
tioncomparedtoperspectiveimages. tain features common to real-life room layouts, such as
3. Incorporates superresolution and a custom blending curvedwalls,kitchenislandsandhalfwalls,andstaircases.
strategytoachieveahigh-quality,seamlessresult. With recent advances in image inpainting techniques, we
studywhetherstructuralcuesfromroomlayoutestimation
2.Relatedwork are necessary for creating high-fidelity and geometrically
plausibleinpaints.
Thekeycomponentofourmethodisanimprovedinpaint-
ingroutine,soherewefocusonworksrelatedtothistask. 2.3.StableDiffusion
2.1.Inpainting Latentdiffusionmodels,suchasStableDiffusion(SD)[36],
haverecentlyrisentotheforefrontofimagegenerationand
Digital inpainting is the task of generating pixels to com-
demonstrated results that out-perform their GAN counter-
plete missing regions of an image [2]. Many inpainting
parts [10]. Diffusion models are readily scalable to bet-
methodshavebeendevelopedoverthepastdecades, rang-
termodelthecomplexdistributionoftrainingdataandcan
ingfromapproachesusingclassicaltechniques[1,2,6,17,
samplediverseinpaintsathighfidelity[30].SDisatext-to-
33, 44] to those leveraging deep neural networks [19, 27,
imagemodeltrainedonalargeimagedataset[39]thatcan
32,34,36,41,43,50–52].
also be conditioned by multi-modal inputs, including line
Early learned approaches using Convolutional Neural
contours,depthmaps,andotherimagesforimage-to-image
Networks (CNNs) pioneered the use of Generative Adver-
translation[54].
sarial Networks (GANs) for inpainting [19, 34, 50]. Par-
Similar to other generative AI models, like large lan-
tialconvolutions[27]andtheirlearnedcounterparts, gated
guagemodels,SDsuffersfromhallucinations—generation
convolutions [51], allowed inpainting with arbitrary mask
of plausible but incorrect information—due to issues such
shapes by propagating masks through the network layers.
astrainingdataimpuritiesandbias,andattentiondilutionat
Many models employed a two-stage pipeline that gener-
inference[45,49].Understandingwhyhallucinationsoccur
atedintermediaterepresentationstoaidinthefinalinpaint-
and how they can be mitigated are research areas that are
ing step, such as coarse resolution inpaints [50–52], edge
critically important for using these generative models for
maps[32],andsemanticsegmentationmasks[41]. Tohan-
downstreamtasksandinourdailylives.
dlelargemasks,fastFourierconvolutions[43]wereshown
Inthecaseofinpaintingfordefurnishing,onerootcause
toincreasetheeffectivereceptivefieldoftheneuralnetwork
forhallucinations,whichwehypothesizeisverysignificant,
andaidinunderstandingtheglobalstructureoftheimage.
isdatabiasandobjectco-occurrence[28,59]. Ifthedataset
2.2.Panoramicfurnitureremoval usedtotrainSDcontainsmoreimagesoffurnishedindoor
roomsthanunfurnishedones,thenwhenthetrainedmodel
Given a panoramic image of an indoor scene, furniture re- is presented with an image of an indoor room, it would
movalgenerallyinvolvestwoimportantsteps[14]: be biased towards generating inpaints including furniture.
1. Segmentallinstancesoffurnituretoremove. In other words, the dataset may contain a bias where an
2Figure2. Defurnishingpipeline. Theinputtooursystemisa8192×4096pixelequirectangularpanorama,whichwecropto3:1aspect
ratiotoexcludethepoles.Pre-processing:Weobtainabinaryfurnituremaskviasemanticsegmentation.Bothinputandmaskarerolled,
sothatinpaintingregionsareinthecenteroftheimage,andpadded,toensuresufficientcontext(notetherepeateddoorwayandcupboardin
theexample).Theimagesarethendownsampledtoaheightof512pixels.Inpainting:Ourcustomprocessisrobusttoinexactmasksand
remnantshadows,asdetailedinthemethodsection.Post-processing:Weapply4×superresolutiontotheinpaintedoutputandthenblend
theoriginalandinpaintedpanoramasintothefinalresultusingthemask,keepingasmuchoftheoriginalresolutiondetailsaspossible.
“indoor room” and “furniture” often co-occur leading the work equally well on equirectangular and perspective im-
model to learn this association and spuriously hallucinate ages. Thissparesustheback-and-forthconversionbetween
furnitureinimagesofindoorrooms. apanoramaandasetofperspectiveimagesthatothermeth-
Regardingdatasetbias,oneremedywouldbetochoose odsnecessitate[21],yieldingacontinuousmaskandfaster
textpromptsthatguidetheinpainttowardsthedesiredout- processinginourcase.
come. Another approach is to fine-tune [18, 38] the diffu-
sionmodelonanotherdatasetwherethisbiashasbeenrec-
Context maximization Next, we ensure that our image
tified,tradingdiversityforfidelityinaparticularuse-case.
is set up optimally for inpainting. To this end, we roll the
panorama around horizontally so that the masked objects
3.Method
areasclosetothecenteraspossible. Thereisnoguarantee
Ourmethodtakesahighresolutionpanoramaimageasin- that there will be no masked object on the image edge, so
putandoutputsadefurnishedversionofit,asvisualizedin weadditionallywrap-padtheimagehorizontallytoprovide
Figure2.Westartbysemanticsegmentationofallfurniture. sufficientcontextfortheensuinginpainting. Weapplythe
Next,werunourcustomunfurnishedspaceinpainting. As sametransformationstothecorrespondingmaskimage.
it is SD-based, it is done at a lower resolution, so finally
3.2.Robustunfurnishedspaceinpainting
werunsuperresolutionandblendtheinpaintedandoriginal
imagesinordertoobtainavisuallypleasingfinalresult.We Figure1pointstothreemajorissueswithSDinpaintingthat
elaborateoneachofthesestepsinthefollowing. weaimtosolve:
1. Itisnotreadilyapplicabletonon-squareimages.
3.1.Pre-processing
2. Itispronetohallucinatingobjects.
Furnituresegmentation Weuseanoff-the-shelfseman- 3. Itislowresolutionandlackshighfrequencydetails.
tic segmentation network [4, 23] to identify all instances Hallucinationsareaknownissueforlargegenerativemod-
of furniture classes, as defined in the ADE20K bench- els [28, 49]. The same prompt gives different results with
mark [58]. Their union is our inpainting mask. Note that, different random seeds, some of which do not exhibit hal-
inourexperience,modernsemanticsegmentationnetworks lucinations, but this is unreliable in an automated system.
3Input Emptyprompt 1prompt
Figure3. Trainingdatasetexamples. Syntheticfurnitureitems
andshadowsarerenderedoverrealunfurnishedpanoramas.
32prompts 72prompts 180prompts
This issue is multi-faceted in the case of inpainting. First,
inpaintingmasksmaybeinaccurate,leavingvisiblepartsof Figure4. Effectofnumberoftrainingprompts. Fewerthan32
objectswhichSDpicksupandcompletesintofullobjects. promptsleadtohallucinationsneartheshadowontherightwall.
While this can be addressed with mask dilation, valuable
context and detail is lost. Even with perfect object masks,
thereareshadowsleft,whichSDaimstoexplainbyinpaint-
ing objects that may have cast them. Second, our case of
Noise100% Noise99% Noise98%
inpainting empty space is especially challenging, because Original Image0% Image1% Image2%
generativemodelsaregoodatcreatingconcreteobjectswith
describable properties (such as round wooden kitchen ta-
bles), but struggle with generating imagery for vague con- Noise97% Noise95% Noise97% Noise90%
Image3% Image5% Image3% Image10%
ceptslikeemptiness.Negativepromptsareanotherway,but
whiletheycanmakehallucinatedobjectslooklesslikethe Figure5. Initializationoflatentsforinpainting. Withdecreas-
negativeprompt,theydonotremovetheobjects. ingpercentageofnoiseintheinitialization, hallucinationsinthe
hallwaydecrease,butblurrinessontheinpaintedfloorincreases.
We fine-tune a version of SD inpainting to address the
first two issues. For the third one, we develop a post-
processingroutinedescribedinSection3.3.
Prompts SD is a text-to-image model, and consequently
the text prompt(s) used for our inpainting task play(s) an
Dataset To be able to successfully inpaint empty space, important role. The prompt we use at inference time is
we train on a proprietary dataset of 160k equirectangu- empty room, but we found that training with a set of simi-
lar panoramas of unfurnished residential spaces, similar to larpromptsfurtherreduceshallucinations,asshowninFig-
Matterport3D[3,35]. Asdiscussed,theuseofequirectan- ure4.Werandomlyselectonepromptfromthesetpertrain-
gularpanoramasensuresthatwemaximizethecontextatin- ingsample(promptsforthesamesamplemaydifferindif-
paintingtime. WefoundthatSDquicklyadaptstothiskind ferentepochs). Theadditionalpromptscontainsynonyms,
ofimageryafterbeingexposedtofewerthan1000panora- suchasunfurnished;space,home,house;aswellasappend-
mas. WefindthisstrategytobebetterthanapplyingSDto ingdescriptionssuchas“uniformlyblank”. Wetestedwith
atiledversionoftheequirect,becauseallcontextispresent 0(emptyprompt),1,8,32,72and180prompts. Inourex-
inoneimage. periments 0-8 prompts lead to models that are most prone
to hallucination, 32 and 72 yield results with much fewer
hallucinations,whilemorepromptsresultinincreasedhal-
Syntheticdata&augmentations Tomakeinpaintingro- lucinations again. Thus, in our experiments we choose to
bust to shadows and inaccurate masks, we augment the trainwith32variantsofthe“emptyroom”prompt.
empty spaces with synthetically rendered furniture objects
from a dataset like Objaverse [8]. The rendering is not
Initialization Atinferencetimeweinitializetheinpaint-
photorealistic,butincludesshadows,asshowninFigure3.
inglatentsasaweightedsumof97%randomnoiseand3%
We fine-tune a pre-trained SD inpainting model using as
latentsbasedontheinputimage,blurredundertheinpaint-
inputs the unfurnished space panoramas with synthetically
ing mask. We empirically found this combination to best
rendered objects and shadows, and masks that only cover
minimizebothhallucinationsandblur,asshowninFigure5.
theobjectsandnottheshadows. Thetargetoutputsarethe
original unfurnished panoramas. This fine-tuning discour-
agesSDfromhallucinatingobjectswhenseekingtoexplain Resources We train for 96 hours on 8 NVIDIA A10G
awayeffectsofthefurnitureonthescene,suchasshadows, GPUs (24 GB vRAM) with an effective batch size of 96
reflections,orlightbeams.Additionally,tomakeourmodel (usinggradientaccumulation).ThebaseSDversionthatwe
robusttomaskinaccuracies,weperturbtheinputmasksto fine-tuneisstabilityai/stable-diffusion-2-inpaintingandwe
simulateimperfectsemanticsegmentationoutput. only perform low-rank adaptation (LoRA) [18], whereby
4wecalculateupdatematricesforitsUNet,ratherthantrain- Method PSNR↑ SSIM↑ JOD↑ LPIPS↓
ingallitsweights.Weexperimentedwithtrainingtheentire
LaMa[43] 26.76 0.916 7.670 0.094
UNetandtheVAE,eachofwhichgaveinferiorresults.This
LGPN-Net[13] 25.57 0.867 7.439 0.206
couldbeduetoourdatasetsizeorotherfactors,whichwe
SD-2-inpaint 24.67 0.878 7.487 0.101
didnot investigatefurther. Wealsofine-tuned SDXL, but
Ours-inpaint 26.02 0.874 7.691 0.091
foundittobemorepronetohallucinations.
Ours-full 27.05 0.930 7.753 0.056
We only use one GPU for inference. We found that 10
inference steps are sufficient. Our pipeline takes approx-
Table 1. Quantitative evaluation. Our inpainting module is
imately 12 seconds to process a single panorama: 8s for
slightlyworsethanLaMa[43]onabsolutedifferencemetrics,be-
pre-processing and semantic segmentation, 3.5s per image
cause the underlying SD outputs lower-frequency textures. To-
forinpaintingalone,and0.5sforpost-processing.
getherwithsuperresolutionandblending,ourfullpipelineoutper-
formsallrelatedtechniques.
3.3.Post-processing
After inpainting, we apply an off-the-shelf superresolution
network[46]toupscaletheinpaintedimagefourtimes. We panoramaimageandacorrespondingmask,andtheoutput
then undo the padding and rolling pre-processing transfor- isofthesameresolution,i.e.nopre-processingtorolland
mations to restore the original panorama dimensions. Fi- padorpost-processingtoupsampleandblendisdone.
nally,wemakesurethattheinpaintedandoriginaltextures Wecomparetothefollowingrelatedapproaches:
matchwellviaacustomblendingroutine. • LaMa [43]: a ResNet-like inpainting network that relies
onfastFourierconvolutions[5]tohandlelargemasks;
• LGPN-Net[13]: estimatestheroomlayoutviaHorizon-
Blending SD-based inpainting tends to lack high fre-
Net[42]andusesitsedgestoguideaGANforinpainting;
quencydetails,whichisproblematicinoursetting,wherea
• StableDiffusion2.0inpainting[36].
high-resolutionfinaloutputisrequired. Therefore,weaim
Notethatmasksaredilatedby10-20pixelsforthesemeth-
topreserveasmuchdetailaspossiblefromtheoriginalfur-
ods,astheyarenotspecificallytrainedtohandlemaskinac-
nished panorama, and develop a tailored blending proce-
curacieslikeours,andrespectivelytheirresultswereworse
dure that uses the binary inpainting mask to select how to
withoutthedilation. Nodilationisappliedforourmethod.
combine the original and inpainted images. As explained
in Section 3.2, our inpainting strategy is guided by the in-
painting mask, but is trained to be robust to shadows by
Qualitativecomparison Wetestonfurnishedpanoramas
allowingforpixelsnearbythemasktoalsobemodified,as
from the Habitat dataset [35]. Figure 6 compares the re-
enforcedbythedatasetandtrainingobjective. Inthisway,
sults on a few examples. The ResNet- and GAN-based
wenotonlyavoidhallucinatingobjectsduetotheremain-
approaches, LaMa and LGPN-Net, tend to generate very
ingshadow,butwealsoremovetheshadowitselffromthe
blurryresults. Moreover,theyleavepiecesoffurnitureob-
image,leadingtoanoverallhigher-qualityinpaintedresult.
jects un-inpainted. This is an even more prevalent effect
Conversely, if we were to directly use the mask for blend-
with smaller or no mask dilation, as shown in the supple-
ing the original and inpainted panoramas, shadows would
mentarydocument. Ontheotherhand,SDandourcustom
be re-introduced in the final image. Therefore, we use the
modification of it generate much crisper textures, even in
pixelsfromtheinpaintedversionnotonlywherethemask
very complex scenes. While plain SD inpainting halluci-
indicates,butalsoinnearbyregionswheretheinpaintedim-
natesobjects,likethetablesinthefirstexample,ourmethod
ageissignificantlydifferentfromtheoriginal. Similarly,if
does not. In addition, SD leaves shadows behind as in the
those significant changes are far away from the inpainting
second example. The training of our method enables it to
mask,theyaremorelikelytobespurioushallucinations,so
modifypixelsoutsideoftheinpaintingmask,whichiswhy
weusepixelsfromtheoriginalimage. Figure8visualizes
itmanagestoremovetheshadowandinpaintitwithplausi-
thebenefitsofthisstrategy.
blefloortexture.
4.Results
Quantitative comparison To quantitatively compare re-
Inthissection,wecomparetorelatedworksandanalyzethe
sults,wegatheraselectionofunfurnishedpanoramasfrom
contributionsofthevariouscomponentsofourpipeline.
theHabitatdataset[35],insertsyntheticfurnituresuchasta-
blesandottomansonthefloors,andmeasurethedifference
4.1.Furnitureremoval
betweenthedefurnishedimagesproducedbyeachmethod
Wefirstanalyzeonlythecustom-trainedinpaintingcompo- and the original unfurnished images. Note that the spaces
nentofourpipeline.Theinputconsistsofa1536×512pixel producedthiswayhavesimplerfurnituresetupsthaninthe
5(a)Original (b)LaMa[43] (c)LGPN-Net[13] (d)SD-2-inpaint (e)Ours-inpaint
Figure6.Defurnishingcomparison.Examplesarearrangedinrowpairsoffullimagesandzoomed-inpatches.ResultsfromGAN-based
approaches,LaMaandLGPN-Net,areblurryandcontainremnantsoffurnitureobjects,eventhoughinpaintingmaskshadtobedilated
forthesemethodstorunoptimally.SDgeneratescrisperimages,butmayseektoexplainshadowsbyhallucinatingfurniture.Ourcustom
fine-tuningremovesthehallucinations,resultingincoherenttextures,eventhoughitistheonlyonethatdoesnotrequiremaskdilation.
natural images we used in the previous section. We eval- marizedinTable1. Asthesyntheticfurnituredoesnotin-
uate absolute differences via PSNR, and perceptual differ- clude rugs and leaves large areas from the original floor-
encesviaSSIM[48],LPIPS[55],andFovVideoVDP[31], ingvisible(showninsupplementarydocument),LaMaand
a kind of just-objectionable-difference (JOD) measure for LGPN-Netmanagetopropagatethesetextureswellintothe
wide field-of-view images or video. Here, in addition to inpaintedregions, andthusachievegoodPSNRandSSIM
ourinpaintingnetwork(Ours-inpaint),weevaluateourfull scores. However, the borders between inpainted and unin-
pipeline (Ours-full), for a fairer comparison to a complete paintedregionsareblurryanddisjoint,leavingthesemeth-
defurnishingmethodlikeLGPN-Net. Theresultsaresum- ods with low perceptual scores. On the other hand, our
6(a)Original (b)SD-2-inpaint,nomaskdilation (c)SD-2-inpaint,dilatedmask (d)Ours,nomaskdilation
Figure7.LoRAfine-tuning.Comparingoff-the-shelfweightsforStableDiffusionv2inpaintingandourfine-tunedweights.
(a)Original;maskoverlaidinblue (b)Generatedimage (c)Na¨ıvereplacement (d)Ourblending
Figure8.Blending.Ourblendingtechniquecombinestheoriginalandgeneratedimagesaccordingtotheinpaintingmask,showninblue.
methodandplainSDhavesomewhatlower-resolutiontex- painting network is combined with the original image ac-
tures, leading to worse PSNR. Conversely, they generate cording to the inpainting mask. The generated image
continuoustextureswithhigherLPIPSandJOD.Thepost- is low-resolution and often contains undesirable artifacts
processingcomponentofourpipelineisdevelopedexactly (e.g. there are no trees through the windows of 8b), so
to remedy the low-resolution imagery—indeed, its better we would prefer to use pixels of the original image when
scores across all metrics demonstrate that we have accom- possible. However, na¨ıvely replacing the generated image
plishedthisgoal. into the original image according to the inpainting mask
(i.e.result=original·(1−mask)+generated·mask)creates
4.2.Ablationstudies
visuallyjarringoutlinesduetophysicalshadowsanddiffer-
ences in white-balance. While it is difficult to completely
Figure7showsanexampleinpaintingresultusingoff-the-
reconcile the differences between the detail frequencies of
shelfSDweights,withandwithoutmaskdilation.Notethat
the original and generated images, our blending technique
withoutanymaskdilation,thenetworkhallucinatesobjects
smoothlycombinesthetwoimages.
due to imperfect semantic segmentation and context from
shadows. If the mask is generously dilated, the network Figure 9 demonstrates the effects of our rolling and
doesnothaveenoughcontexttogeneraterealisticinpaints padding pre-processing steps. As the goal of these steps
forthekitchenisland. Therefore,itisnecessarytofine-tune istoensurethatinpaintsareconsistentacrossthe“seam”of
SDonacustomdatasettogenerateinpaintsofunfurnished the panorama image, we show the crops at opposite edges
spaceswithoutrequiringmaskdilation. ofthepanoramajoinedtogether,sothepanoramaseamlies
Figure 8 shows how the image generated by our in- inthecenteroftheimage. Withnorolling,weobtainaver-
7(a)Original (b)Norolling (c)Nopadding (d)Withrollingandpadding
Figure9.RollingandPadding.Inpaintingresultsatthepanoramaseamwithandwithoutcertainpre-processingsteps.
OurrelianceontheStableDiffusion2.0inpaintingarchi-
tectureimposesconstraints,necessitatingmodificationsfor
higherresolutiontrainingandinference. Theresolutionof
theoutputofStableDiffusionmodelistoolow-only512
pixels in height, and the superresolution model sometimes
madetheoutputwarpedorunnatural. Oneareaofimprove-
mentwouldbetochooseanoptimalsuperresolutionmodel
ortotrainonespecificallyonequirectangularimages.
Theapplicabilityofourstrategytoothergenerativemod-
elsorimagerytypesbesidesindoorpanoramasisoutofthe
scopeofthisworkandremainsopenforfutureresearch.
Finally, our method lacks consideration for multi-view
consistency, which is important for applications like digi-
tal twins; each panorama is inpainted independently, over-
looking valuable contextual information from other views.
Future research should explore efficient and scalable ap-
(a)Original (b)Inpainted
proaches to incorporate geometric priors into the inpaint-
Figure 10. Failure cases. Structural changes or hallucinations ingpipeline[54]. Beingabletoinpaintconsistentlyacross
mayoccur. different views of the same underlying physical space
mayhelpwithdefurnishingotherrepresentationsofdigital
tical discontinuity where the seam lies. With no padding, twins,suchastexturedpolygonmeshes.
we obtain low-quality inpaints due to the reduced context.
5.Conclusion
While rolling and padding do not guarantee consistent in-
paintingaroundtheentirepanorama(e.g.thismayfailwhen
Wehavepresentedanovelapproachtopanoramadefurnish-
themaskspanstheentireimage),thesetwosimpleprocess-
ingbyutilizingdomain-specificfine-tuningforStableDif-
ingstepscovermostcases.
fusion inpainting. We have observed a notable reduction
4.3.Limitationsandfuturework inundesirablehallucinationsandimprovedthemodel’sro-
bustnesstoimperfectsegmentationmasks,makingitmuch
Whileourmethodrepresentsastepforwardindefurnishing,
less likely to explain away shadows, light beams, reflec-
ithaslimitations. Structuralalterationsandlingeringhallu-
tions, and other similar effects. When compared to exist-
cinationsmayoccur,likethebenchbeneaththewindowin
ingapproaches,ourmethodproduceshigher-qualityresults
Figure 10. Our training methodology, which involves ren-
withouttheneedforroomlayoutestimation,asindicatedin
dering synthetic furniture into unfurnished panoramas, in-
bothqualitativeandquantitativecomparisons.
troducespotentialdomainshiftissues.Thisdiscrepancybe-
tweensyntheticandreal-worlddatamayimpactthequality Acknowledgements
of results. While we fixed the number of training prompts
based on empirical evidence, the optimal prompting strat- WearegreatefultoDorraLarnaout,GregorMiller,Gunnar
egyremainsanopenquestion. Augmentingthefixedinfer- Hovden, Ky Waegel, Mykhaylo Kurinnyy, and Neil Jassal
ence prompt “empty room” with additional contextual in- fortheircontributions. WealsothankAlexanderDemidko
formationcouldimprovecontentgenerationaccuracy. andKevinBalkoskiforusefuldiscussions.
8References [14] V.Gkitsas,V.Sterzentsenko,N.Zioulis,G.Albanis,andD.
Zarpalas.Panodr:Sphericalpanoramadiminishedrealityfor
[1] Connelly Barnes, Eli Shechtman, Adam Finkelstein, and
indoorscenes,2021. 1,2
Dan B. Goldman. Patchmatch: a randomized correspon-
[15] Vasileios Gkitsas, Nikolaos Zioulis, Vladimiros
dence algorithm for structural image editing. ACM SIG-
Sterzentsenko, Alexandros Doumanoglou, and Dim-
GRAPH2009papers,2009. 2
itrios Zarpalas. Towards full-to-empty room generation
[2] MarceloBertalmio,GuillermoSapiro,VincentCaselles,and
with structure-aware feature encoding and soft semantic
Coloma Ballester. Image inpainting. In Proceedings of
region-adaptivenormalization,2021. 2
the 27th Annual Conference on Computer Graphics and
[16] Esa Halmetoja. The role of digital twins and their appli-
Interactive Techniques, page 417–424, USA, 2000. ACM
cation for the built environment. Industry 4.0 for the built
Press/Addison-WesleyPublishingCo. 2
environment: Methodologies,technologiesandskills,pages
[3] AngelChang,AngelaDai,ThomasFunkhouser,MaciejHal-
415–442,2022. 1
ber,MatthiasNiessner,ManolisSavva,ShuranSong,Andy
[17] James Hays and Alexei A. Efros. Scene completion using
Zeng,andYindaZhang. Matterport3d: Learningfromrgb-
millions of photographs. ACM Trans. Graph., 26(3):4–es,
ddatainindoorenvironments. InternationalConferenceon
2007. 2
3DVision(3DV),2017. 4
[18] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-
[4] Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong
Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhuChen.
Lu,JifengDai,andYuQiao.VisionTransformerAdapterfor
LoRA: Low-Rank Adaptation of Large Language Models.
DensePredictions.InTheEleventhInternationalConference
In International Conference on Learning Representations,
onLearningRepresentations(ICLR),2023. 2,3
2022. 3,4
[5] LuChi,BoruiJiang,andYadongMu.FastFourierConvolu- [19] Satoshi Iizuka, Edgar Simo-Serra, and Hiroshi Ishikawa.
tion. InAdvancesinNeuralInformationProcessingSystems Globally and locally consistent image completion. ACM
(NeurIPS),2020. 5 TransactionsonGraphics,36:1–14,2017. 2
[6] AntonioCriminisi,PatrickPe´rez,andKentaroToyama. Ob- [20] Isogawa, Mariko and Mikami, Dan and Iwai, Daisuke and
jectremovalbyexemplar-basedinpainting. pages721–728, Kimata,HideakiandSato,Kosuke. MaskOptimizationfor
2003. 2 ImageInpainting. IEEEAccess,2018. 2
[7] BrunoDaniotti,GabrieleMasera,CeciliaMariaBolognesi, [21] Guanzhou Ji, Azadeh O Sawyer, and Srinivasa G
Sonia Lupica Spagnolo, Alberto Pavan, Giuliana Iannac- Narasimhan. VirtualHomeStaging: InverseRenderingand
cone, MartinaSignorini, SimoneCiuffreda, ClaudioMirar- EditinganIndoorPanoramaunderNaturalIllumination. In
chi, Meherun Lucky, et al. The development of a bim- InternationalSymposiumonVisualComputing,2023. 2,3
basedinteroperabletoolkitforefficientrenovationinbuild- [22] SalehKalantariandJunRongJeffreyNeo. Virtualenviron-
ings: Frombimtodigitaltwin. Buildings,12(2):231,2022. mentsfordesignresearch:Lessonslearnedfromuseoffully
1 immersivevirtualrealityininteriordesignresearch. Journal
[8] MattDeitke, DustinSchwenk, JordiSalvador, LucaWeihs, ofInteriorDesign,45(3):27–42,2020. 1
Oscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana [23] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,
Ehsani,AniruddhaKembhavi,andAliFarhadi. Objaverse: ChloeRolland,LauraGustafson,TeteXiao,SpencerWhite-
AUniverseofAnnotated3DObjects,2022. 4 head, Alexander C. Berg, Wan-Yen Lo, Piotr Dolla´r, and
[9] JuanManuelDavilaDelgadoandLukumonOyedele. Digi- RossGirshick.SegmentAnything.arXiv:2304.02643,2023.
taltwinsforthebuiltenvironment:learningfromconceptual 3
andprocessmodelsinmanufacturing. AdvancedEngineer- [24] WolfgangKuehn. Digitaltwinsfordecisionmakingincom-
ingInformatics,49:101332,2021. 1 plexproductionandlogisticenterprises. InternationalJour-
[10] PrafullaDhariwalandAlexanderNichol. Diffusionmodels nal of Design & Nature and Ecodynamics, 13(3):260–271,
beatgansonimagesynthesis. InAdvancesinNeuralInfor- 2018. 1
mationProcessingSystems,pages8780–8794.CurranAsso- [25] Prakhar Kulshreshtha, Nektarios Lianos, Brian Pugh, and
ciates,Inc.,2021. 1,2 SalmaJiddi. LayoutAwareInpaintingforAutomatedFurni-
[11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, tureRemovalinIndoorScenes. InIEEEInternationalSym-
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, posiumonMixedandAugmentedRealityAdjunct(ISMAR-
MostafaDehghani,MatthiasMinderer,GeorgHeigold,Syl- Adjunct),2022. 2
vain Gelly, et al. An image is worth 16x16 words: Trans- [26] ChenLiu,KihwanKim,JinweiGu,YasutakaFurukawa,and
formers for image recognition at scale. arXiv preprint JanKautz. Planercnn:3dplanedetectionandreconstruction
arXiv:2010.11929,2020. 2 fromasingleimage,2019. 2
[12] JonathanEyreandChrisFreeman. Immersiveapplications [27] GuilinLiu,FitsumA.Reda,KevinJ.Shih,Ting-ChunWang,
ofindustrialdigitaltwins. TheIndustrialTrackofEuroVR AndrewTao,andBryanCatanzaro. Imageinpaintingforir-
2018,pages11–13,2018. 1 regularholesusingpartialconvolutions,2018. 2
[13] Chao-Chen Gao, Cheng-Hsiu Chen, Jheng-Wei Su, and [28] HanchaoLiu,WenyuanXue,YifeiChen,DapengChen,Xiu-
Hung-Kuo Chu. Layout-guided Indoor Panorama Inpaint- tianZhao,KeWang,LipingHou,RongjunLi,andWeiPeng.
ing with Plane-aware Normalization. In Asian Conference ASurveyonHallucinationinLargeVision-LanguageMod-
onComputerVision(ACCV),2022. 2,5,6,12,17 els,2024. 1,2,3
9[29] JonathanLong,EvanShelhamer,andTrevorDarrell. Fully [42] Cheng Sun, Chi-Wei Hsiao, Min Sun, and Hwann-Tzong
convolutionalnetworksforsemanticsegmentation,2015. 2 Chen. HorizonNet: LearningRoomLayoutWith1DRep-
[30] AndreasLugmayr,MartinDanelljan,AndresRomero,Fisher resentation and Pano Stretch Data Augmentation. In The
Yu,RaduTimofte,andLucVanGool. RePaint: Inpainting IEEE Conference on Computer Vision and Pattern Recog-
usingDenoisingDiffusionProbabilisticModels,2022. 2 nition(CVPR),2019. 2,5
[43] Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin,
[31] RafałK.Mantiuk,GyorgyDenes,AlexandreChapiro,Anton
Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov,
Kaplanyan, Gizem Rufo, Romain Bachy, Trisha Lian, and
Naejin Kong, Harshith Goka, Kiwoong Park, and Victor
AnjulPatney. FovVideoVDP:avisibledifferencepredictor
Lempitsky. Resolution-robust Large Mask Inpainting with
forwidefield-of-viewvideo.ACMTransactionsonGraphics
FourierConvolutions. WinterConferenceonApplicationsof
(SIGGRAPH),40(4),2021. 6
ComputerVision(WACV),2022. 2,5,6,12,17
[32] KamyarNazeri, EricNg, TonyJoseph, FaisalQureshi, and
[44] AlexandruTelea. Animageinpaintingtechniquebasedon
Mehran Ebrahimi. Edgeconnect: Structure guided image
the fast marching method. Journal of Graphics Tools, 9,
inpainting using edge prediction. In Proceedings of the
2004. 2
IEEE/CVF International Conference on Computer Vision
[45] S.MTowhidulIslamTonmoy, SMMehediZaman, Vinija
(ICCV)Workshops,2019. 2
Jain,AnkuRani,VipulaRawte,AmanChadha,andAmitava
[33] StanleyOsher,MartinBurger,DonaldGoldfarb,JinjunXu,
Das. AComprehensiveSurveyofHallucinationMitigation
andWotaoYin. Aniterativeregularizationmethodfortotal
TechniquesinLargeLanguageModels,2024. 2
variation-based image restoration. Multiscale Modeling &
[46] Xintao Wang, Liangbin Xie, Chao Dong, and Ying
Simulation,4(2):460–489,2005. 2
Shan. Real-ESRGAN: Training Real-World Blind Super-
[34] Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor
ResolutionwithPureSyntheticData. InInternationalCon-
Darrell, and Alexei A. Efros. Context encoders: Feature
ferenceonComputerVisionWorkshops(ICCVW),2021. 5
learningbyinpainting,2016. 2
[47] YTWang,CLiang,NHuai,JChen,andCJZhang. Asur-
[35] SanthoshKumarRamakrishnan,AaronGokaslan,ErikWi-
veyofpersonalizedinteriordesign. InComputerGraphics
jmans, Oleksandr Maksymets, Alexander Clegg, John M
Forum.WileyOnlineLibrary,2023. 1
Turner,EricUndersander,WojciechGaluba,AndrewWest-
[48] ZhouWang,A.C.Bovik,H.R.Sheikh,andE.P.Simoncelli.
bury,AngelXChang,ManolisSavva,YiliZhao,andDhruv
ImageQualityAssessment: FromErrorVisibilitytoStruc-
Batra.Habitat-Matterport3DDataset(HM3D):1000Large-
turalSimilarity.IEEETransactionsonImageProcessing,13
scale3DEnvironmentsforEmbodiedAI.InThirty-fifthCon-
(4),2004. 6
ferenceonNeuralInformationProcessingSystemsDatasets
[49] ZiweiXu,SanjayJain,andMohanKankanhalli. Hallucina-
andBenchmarksTrack,2021. 4,5
tionisInevitable: AnInnateLimitationofLargeLanguage
[36] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Models,2024. 2,3
PatrickEsser,andBjo¨rnOmmer.High-resolutionimagesyn-
[50] JiahuiYu,ZheLin,JimeiYang,XiaohuiShen,XinLu,and
thesiswithlatentdiffusionmodels,2022. 1,2,5,12
ThomasS.Huang.Generativeimageinpaintingwithcontex-
[37] OlafRonneberger,PhilippFischer,andThomasBrox.U-net: tualattention,2018. 2
Convolutionalnetworksforbiomedicalimagesegmentation,
[51] JiahuiYu,ZheLin,JimeiYang,XiaohuiShen,XinLu,and
2015. 2
ThomasHuang.Free-formimageinpaintingwithgatedcon-
[38] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, volution,2019. 2
MichaelRubinstein,andKfirAberman. DreamBooth: Fine [52] YuZeng,ZheLin,JimeiYang,JianmingZhang,EliShecht-
TuningText-to-imageDiffusionModelsforSubject-Driven man, and Huchuan Lu. High-resolution image inpainting
Generation. InIEEE/CVFConferenceonComputerVision with iterative confidence feedback and guided upsampling,
andPatternRecognition(CVPR),2023. 3 2020. 2
[39] Christoph Schuhmann, Romain Beaumont, Richard Vencu, [53] Edward Zhang, Ricardo Martin-Brualla, Janne Kontkanen,
Cade Gordon, Ross Wightman, Mehdi Cherti, Theo andBrianCurless. NoShadowLeftBehind:RemovingOb-
Coombes, Aarush Katta, Clayton Mullis, Mitchell Worts- jectsandtheirShadowsusingApproximateLightingandGe-
man, Patrick Schramowski, Srivatsa Kundurthy, Katherine ometry. InIEEE/CVFConferenceonComputerVisionand
Crowson,LudwigSchmidt,RobertKaczmarczyk,andJenia PatternRecognition(CVPR),2021. 2
Jitsev. LAION-5B:Anopenlarge-scaledatasetfortraining [54] LvminZhang, AnyiRao, andManeeshAgrawala. Adding
nextgenerationimage-textmodels. In36thConferenceon conditionalcontroltotext-to-imagediffusionmodels,2023.
NeuralInformationProcessingSystems(NeurIPS),2022. 2 2,8
[40] MuhammadShahzad,MuhammadTariqShafiq,DeanDou- [55] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,
glas,andMohamadKassem. Digitaltwinsinbuiltenviron- andOliverWang. TheUnreasonableEffectivenessofDeep
ments: an investigation of the characteristics, applications, FeaturesasaPerceptualMetric. InCVPR,2018. 6
andchallenges. Buildings,12(2):120,2022. 1 [56] Yinda Zhang, Shuran Song, Ping Tan, and Jianxiong
[41] Yuhang Song, Chao Yang, Yeji Shen, Peng Wang, Qin Xiao. PanoContext: A whole-room 3D context model for
Huang,andC.C.JayKuo.Spg-net:Segmentationprediction panoramicsceneunderstanding.InEuropeanConferenceon
andguidancenetworkforimageinpainting,2018. 2 ComputerVision(ECCV)oralpresentation,2014. 2
10[57] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
Wang,andJiayaJia. Pyramidsceneparsingnetwork,2017.
2
[58] Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela
Barriuso, and Antonio Torralba. Scene Parsing through
ADE20KDataset. InIEEEConferenceonComputerVision
andPatternRecognition(CVPR),2017. 2,3
[59] YiyangZhou,ChenhangCui,JaehongYoon,LinjunZhang,
ZhunDeng, ChelseaFinn, MohitBansal, andHuaxiuYao.
Analyzing and Mitigating Object Hallucination in Large
Vision-LanguageModels.InTheTwelfthInternationalCon-
ferenceonLearningRepresentations,2024. 1,2
11An Empty Room is All We Want:
Automatic Defurnishing of Indoor Panoramas
Supplementary Material
MiraSlavchevau DaveGausebecku KevinChenu DavidBuchhofer AzwadSabik ChenMa
SachalDhillon OlafBrandt AlanDolhasz
Matterport
Visualresults
In Figure 11, we provide larger versions of the defurnishing results from the main paper. In addition, we include results
fromthemethodswecomparetoinSection4.1,i.e.LaMa[43],LGPN-Net[13]andSD-inpainting[36],withasmallermask
dilationof10pixelsaswellaswithnomaskdilation.
LaMa and LGPN-Net demonstrate similar trends; a non-dilated mask is absolutely insufficient—large dark patches are
inpainted and the outlines of the inpainting mask are recognizable. Mask dilation remedies this effect, but the inpainted
regiontendstolooklikeablurryblobwithincreasingmasksize. Conversely,thetexturesaresharpestwiththenon-dilated
masks.
In all examples, SD-inpainting hallucinates objects when the inpainting mask is not dilated. With a mask dilated by 10
pixels,objectsarestillhallucinatedinthefirsttwoexamples. Withamaskdilatedby20pixels,onlythefirstexampleshows
very noticeable hallucinations, e.g. the tables on the right, but larger shadows cast by the objects that are being removed,
e.g.thecouchinthesecondexample,remainintheoutputimageandmayevenbeextendedbytheinpainting.
Notethatinthemainpaper,wechosethebest-lookingresultforeachofthesethreemethodsandeachexampleseparately.
Ours-inpaintbuildsuponSD-inpaintingbuttacklesthehallucinations—andindeednoneoftheexampleshavehallucina-
tions. Ours-fullmakessurethatoriginaltexturesarepreservedwhereverpossible,whichisvaluablebecauseoftheoriginal
image has more detail, e.g. the kitchen island in the first example, and because our method may sometimes remove more
detailsthannecessarysinceitisspecificallytrainedtoremoveshadowsoutsideoftheinpaintingmask.Intricatetexturesmay
stillbeanissueforourmethod,likethefloorinthelastimage,whereoneplankisinpaintedinanotablydarkercolor.
Inaddition,inFigure12wedemonstratethattheinpaintingcomponentofourmethodisnotinfluencedbymaskdilation.
Thereisnonoticeabledifferenceintheinpaintedresultinallexamplesbutthefirstone,wherethefarawaykitchenislandis
removedasthemaskgetslarger,whileitshouldremainbecauseitisbuilt-in. Thisexampledemonstratestheusefulnessof
non-dilatedmasksforkeepingfar-awaydetailsintact.
Finally,inFigure13weshowanexampleofanunfurnishedspacewithsyntheticfurnitureusedforquantitativeevaluation
inSection4.1.
Promptset
Thesetof32promptsthatweusedfortrainingisasfollows:
{X Y Z},where
X ={uV},whereu∈{∅,“an”},V ∈{“empty”,“unfurnished”},
Y ∈{“room”,“space”,“home”,“house”},
Z ∈{∅,P ifu̸=∅,PQifu̸=∅},whereP =“. uniformlyblank”,Q=“,straightedges”.
Notethatduringtraining,eachimageisassignedonepromptatrandom. Duetothisrandomness,thepromptinsubsequent
epochsforthesameimagemightbedifferent.
udenotesequalcontribution.
#research@matterport.com
12Inputpanorama LaManodilation
Ours-inpaint LaMadilation10px
Ours-full LaMadilation20px
SD-2-inpaintnodilation LGPN-Netnodilation
SD-2-inpaintdilation10px LGPN-Netdilation10px
SD-2-inpaintdilation20px LGPN-Netdilation20px
Figure11.Additionaldefurnishingcomparisons.Thenon-dilatedmaskisoverlaidinblue.Imagebestvieweddigitally.
13Inputpanorama LaManodilation
Ours-inpaint LaMadilation10px
Ours-full LaMadilation20px
SD-2-inpaintnodilation LGPN-Netnodilation
SD-2-inpaintdilation10px LGPN-Netdilation10px
SD-2-inpaintdilation20px LGPN-Netdilation20px
Figure11.Additionaldefurnishingcomparisons.Thenon-dilatedmaskisoverlaidinblue.Imagebestvieweddigitally.
14Inputpanorama LaManodilation
Ours-inpaint LaMadilation10px
Ours-full LaMadilation20px
SD-2-inpaintnodilation LGPN-Netnodilation
SD-2-inpaintdilation10px LGPN-Netdilation10px
SD-2-inpaintdilation20px LGPN-Netdilation20px
Figure11.Additionaldefurnishingcomparisons.Thenon-dilatedmaskisoverlaidinblue.Imagebestvieweddigitally.
15Inputpanorama LaManodilation
Ours-inpaint LaMadilation10px
Ours-full LaMadilation20px
SD-2-inpaintnodilation LGPN-Netnodilation
SD-2-inpaintdilation10px LGPN-Netdilation10px
SD-2-inpaintdilation20px LGPN-Netdilation20px
Figure11.Additionaldefurnishingcomparisons.Thenon-dilatedmaskisoverlaidinblue.Imagebestvieweddigitally.
16(a)Nomaskdilation (b)Dilation10pixels (c)Dilation20pixels
Figure 12. Effect of mask dilation on our inpainting. We show results from our inpainting component only. Our results are nearly
identicalregardlessoftheamountofmaskdilation,apartfromfarawaydetailslikethekitchenislandinthefirstexample.
Original LaMa[43]
LGPN-Net[13] SD-2-inpaint
Ours-inpaint Ours-full
Figure13. Exampleofunfurnishedspacewithsyntheticfurnitureforquantitativeevaluation. Thespaceislesscomplexthanreal
furnished ones, letting LaMa and LGPN-Net produce higher frequency textures than SD and our inpainting, which is remedied by the
blendinginourfullpipeline.
17