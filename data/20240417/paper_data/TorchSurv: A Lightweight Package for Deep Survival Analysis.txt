TorchSurv: A Lightweight Package for Deep Survival Analysis
M´elodie Monod melodie.monod@novartis.com
Novartis Pharma AG, Switzerland
Peter Krusche peter.krusche@novartis.com
Novartis Pharma AG, Switzerland
Qian Cao qian.cao@fda.hhs.gov
Center for Devices and Radiological Health, Food and Drug Administration, MD, USA
Berkman Sahiner berkman.sahiner@fda.hhs.gov
Center for Devices and Radiological Health, Food and Drug Administration, MD, USA
Nicholas Petrick nicholas.petrick@fda.hhs.gov
Center for Devices and Radiological Health, Food and Drug Administration, MD, USA
David Ohlssen david.ohlssen@novartis.com
Novartis Pharmaceuticals Corporation, NJ, USA
@
Thibaud Coroller thibaud.coroller@novartis.com
Novartis Pharmaceuticals Corporation, NJ, USA
@
Corresponding author
Abstract
TorchSurv123isaPythonpackagethatservesasacompaniontooltoperformdeepsurvival
modeling within the PyTorch environment. Unlike existing libraries that impose specific
parametricforms,TorchSurvenablesthe useofcustomPyTorch-baseddeepsurvivalmod-
els. With its lightweight design, minimal input requirements, full PyTorch backend, and
freedom from restrictive survival model parameterizations, TorchSurv facilitates efficient
deepsurvivalmodelimplementationandisparticularlybeneficialforhigh-dimensionaland
complex input data scenarios.
Keywords: Python package, Survival analysis, PyTorch, Deep learning, TorchSurv
1 Introduction
Survival analysis plays a crucial role in various domains, such as medicine and engineering.
Deep learning offers promising avenues for building complex survival models. However,
existing libraries often restrict users to predefined parameter forms and limit seamless inte-
gration with PyTorch (Paszke et al., 2019). We introduce TorchSurv (available on GitHub
andPyPI),atoolkittoempowerresearchersinbuildingandevaluatingdeepsurvivalmodels
within the PyTorch framework. TorchSurv provides a user-friendly workflow for defining a
survivalmodelwithparameters specifiedby aPyTorch-based(deep)neuralnetwork. Train-
ing is facilitated by leveraging one of TorchSurv’s built-in survival model loss functions.
Upon completion of model training, TorchSurvprovides metrics for evaluating the survival
model’s predictive performance. TorchSurv has undergone rigorous testing on open source
1. Thesource code of TorchSurv can befound at https://github.com/Novartis/torchsurv.
2. ThePython Package Indexof TorchSurv can befound at https://pypi.org/project/torchsurv.
3. Thelatest documentation of TorchSurv can be found at https://opensource.nibr.com/torchsurv/.
1
4202
rpA
61
]GL.sc[
1v16701.4042:viXradata and synthetically generated survival data that include edge cases. The package is
comprehensively documented and contains illustrative examples. Thelatest documentation
of TorchSurv can be found at https://opensource.nibr.com/torchsurv/.
At the core of TorchSurvlies its PyTorch-basedcalculation of log-likelihoods for promi-
nent survival models, including the Cox proportional hazards model (Cox, 1972) and the
Weibull Accelerated Time Failure (AFT) model (Carroll, 2003). In survival analysis, each
observation is associated with survival data denoted by y (comprising the event indicator
and the time-to-event or censoring) and covariates denoted by x. A survival model that
is able to capture the complexity of the survival data y, is parametrized by parameters
denoted by θ. For instance, in the Cox proportional hazards model, the survival model
parameters θ are the relative hazards. Within the TorchSurv framework, a PyTorch-based
neural network is defined to act as a flexible function that takes the covariates x as input
and outputs the survival model parameters θ. TorchSurv’s log-likelihoods are calculated
from the survival data y and the survival model parameters θ. Estimation of the param-
eters θ is achieved via maximum likelihood estimation facilitated by backpropagation. To
allow for automatic gradient computation and enable maximum likelihood estimation, the
log-likelihood computations are fully implemented in PyTorch. Theautomatic gradient cal-
culation is crucial as it allows for efficient optimization of complex models by automatically
computing the gradients of the loss function with respect to the survival model parame-
ters θ. To mitigate numerical instability and ensure stable training, all computations are
conducted on the logarithmic scale.
Additionally, TorchSurv offers evaluation metrics to characterize the predictive perfor-
manceofsurvivalmodels. Theseevaluation metrics includethetime-dependentAreaUnder
the cure (AUC) under the Receiver operating characteristic curve (ROC), the Concordance
index (C-index) and the Brier Score. The evaluation metric’s functionalities include the
point estimate, confidence interval, hypothesis test to determine whether the metric is bet-
ter than that of a random predictor and hypothesis test to compare two metrics obtained
with different models.
2 Related Work
Table1comparesthefunctionalitiesof TorchSurvwiththoseof auton-survival(Nagpal et al.,
2022),pycox(Kvamme et al.,2019),torchlife(Abeywardana,2021),scikit-surv-ival(Po¨lsterl,
2020) lifelines (Davidson-Pilon, 2019), and deepsurv (Katzman et al., 2018). While
several libraries offer survival modelling functionalities, as shown in Table 1, no existing
library provides the flexibility to use a custom PyTorch-based neural network to define the
survival model parameters θ given a set of covariates x. In existing libraries, users are lim-
ited to specific forms to define θ (e.g., linear function of covariates) and the log-likelihood
functions available cannot be leveraged because they do not allow for seamless integration
with PyTorch. Specifically, the limitations on the log-likelihood functions include protected
functions, specialized input requirements (format or class type), and reliance on external
libraries like NumPy or Pandas. Dependence on external libraries hinders automatic gradi-
ent calculation within PyTorch. Additionally, the implementation of likelihood functions
instead of log-likelihood functions, as done by some packages, introduces potential numer-
ical instability. With respect to the evaluation metrics, scikit-survival stands out as
2TorchSurv autonsurvival1 pycox2 torchlife3 scitkit-survival4 lifelines5 deepsurv6
PyTorch ✓ ✓ ✓ ✓ ✗ ✗ ✗
Standalonelossfunctions
Weibulllossfunction ✓ ✗ ✗ ✓ ✗ ✓ ✗
Coxlossfunction ✓ ✓ ✓ ✓ ✓ ✓ ✗
Handletiesineventtime ✓ ✗ ✗ ✗ ❅❅✓ ✓ ✗
Logarithmscale ✓ ✓ ✓ ✗ ✓ ✓ ✗
Standaloneevaluationmetrics
Concordanceindex ✓ ✗ ❅❅✓ ✗ ✓ ✓ ✗
AUC ✓ ✗ ✗ ✗ ✓ ✗ ✗
Brier-Score ✓ ✗ ✓ ✗ ✓ ✗ ✗
Time-dependentriskscore ✓ ✗ ❅❅✓ ✗ ❅❅✓ ✗ ✗
Subject-specificweights ✓ ✗ ❅❅✓ ✗ ❅❅✓ ✗ ✗
Confidenceinterval ✓ ✗ ✗ ✗ ✗ ✗ ✗
Comparetwometrics ✓ ✗ ✗ ✗ ✗ ✗ ✗
Momentum ✓ ✗ ✗ ✗ ✗ ✗ ✗
1 2 3 4
(Nagpal et al., 2022), (Kvamme et al., 2019), (Abeywardana, 2021), (Po¨lsterl, 2020),
5 (Davidson-Pilon, 2019), 6 (Katzman et al., 2018). ✓ indicates a fully supported feature,
✗ indicates an unsupported feature, ❅❅✓ indicates a partially supported feature.
Table 1: Survival analysis libraries in Python. For computing the concordance index,
pycoxrequirestheuseoftheestimated survivalfunctionas theriskscoreanddoes
not support other types of time-dependent risk scores. scikit-survival does
not support time-dependent risk scores in both the concordance index and AUC
computation. Additionally, both pycox and scikit-survival impose the use
of inverse probability of censoring weighting (IPCW) for subject-specific weights.
scikit-survival only offers the Breslow approximation of the Cox partial log-
likelihood in case of ties in the event time, while it lacks the Efron approximation.
a comprehensive library. However, it lacks certain desirable features, including confidence
intervalsandcomparisonoftheevaluationmetricbetweentwodifferentmodels,anditisim-
plemented with NumPy. Our package, TorchSurv, is specifically designed for use in Python,
butwe also provide a comparative analysis of its functionalities with popular R packages for
survival analysis in Appendix A. R packages do not make log-likelihood functions readily
accessible and restrict users to specific forms to define θ. However, R has extensive libraries
forevaluation metrics, suchas theRiskRegressionlibrary(Gerds et al.,2023). TorchSurv
offers a comparable range of evaluation metrics, ensuring comprehensive model evaluation
regardless of the chosen programming environment.
3 Core Functions
3.1 Overview
TheTorchSurvlibraryprovideslossfunctionstoestimatesurvivalmodel’sparametersusing
maximum likelihood estimation through backpropagation. In addition, the library offers a
set of evaluation metrics to characterize the predictive performance of survival models.
Below is an overview of the workflow for model inference and evaluation with TorchSurv:
31. InitializeaPyTorch-basedneuralnetworkthatdefinesthefunctionfromthecovariates
to the survival model’s parameters.
2. Initiate training: For each epoch on the training set,
train
◦ Draw survival data y (i.e., event indicator and time-to-event or censoring)
train
and covariates x from the training set.
train train
◦ Obtain parameters θ based on drawn covariates x using PyTorch-based
neural network.
◦
Calculatethelossgivensurvivaldataytrain andparametersθtrain
usingTorchSurv’s
loss function.
train
◦ Utilize backpropagation to update parameters θ .
test test
3. Obtain parameters θ based on covariates from the test set x using the trained
PyTorch-based neural network.
4. EvaluatethepredictiveperformanceofthemodelusingTorchSurv’sevaluationmetric
test
functions (e.g., C-index) given parameters θ and survival data from the test set
ytest
.
The outputs of both the log-likelihood functions and the evaluation metrics functions have
undergone thorough comparison with benchmarks generated with Python packages (Ta-
ble 1) and R packages (Appendix A) on open-source data and synthetic data. High agree-
mentbetweentheoutputsisconsistentlyobserved,providinguserswithconfidenceintheac-
curacy and reliability of TorchSurv’sfunctionalities. Thecomparison is summarized on the
package’swebsiteatthislink:https://opensource.nibr.com/torchsurv/benchmarks.html.
3.2 Loss Functions
Cox loss function. The Cox loss function is defined as the negative of the Cox pro-
portional hazards model’s partial log-likelihood (Cox, 1972). The function requires the
subject-specific log relative hazards and the survival data (i.e., event indicator and time-
to-event or censoring). The log relative hazards should be obtained from a PyTorch-based
model pre-specified by the user. In case of ties in the event times, the user can choose
between the Breslow (Breslow, 1975) and the Efron method (Efron, 1977) to approximate
the Cox partial log likelihood. We illustrate the use of the Cox loss function for a pseudo
training loop in the code snippet below.
from torchsurv.loss import cox
my_model = MyPyTorchModel() # PyTorch model for log hazards (1 output)
for data in dataloader:
x, event, time = data
log_hzs = my_model(x) # torch.Size([64, 1]), if batch size is 64
loss = cox.neg_partial_log_likelihood(log_hzs, event, time)
loss.backward() # native torch backend
Weibull lossfunction. TheWeibulllossfunctionisdefinedasthenegativeoftheWeibull
AFT’s log-likelihood (Carroll, 2003). Thefunction requires the subject-specific log parame-
ters of the Weibull distribution (i.e., the log scale and the log shape) and the survival data.
The log parameters of the Weibull distribution should be obtained from a PyTorch-based
model pre-specified by the user. We illustrate the use of the Weibull loss function for a
pseudo training loop in the code snippet below.
4from torchsurv.loss import weibull
my_model = MyPyTorchModel() # PyTorch model for log parameters (2 outputs)
for data in dataloader:
x, event, time = data
log_params = my_model(x) # torch.Size([64, 2]), if batch size is 64
loss = weibull.neg_log_likelihood(log_params, event, time)
loss.backward() # native torch backend
Momentum. When training a model with a large file, the batch size is greatly limited
by computational resources. This impacts the stability of model optimization, especially
when rank-based loss is used. Inspired from MoCO (He et al., 2020), we implemented a
momentum loss that decouples batch size from survival loss, increasing the effective batch
size and allowing robust train of a model, even when using a very limited batch size (e.g.,
batchsize ≤ 16). We illustrate the use of momentum for a pseudo training loop in the code
snippet below.
from torchsurv.loss import Momentum
my_model = MyPyTorchModel() # PyTorch model for log hazards (1 output)
my_loss = cox.neg_partial_log_likelihood # any torchsurv loss
momentum = Momentum(backbone=my_model, loss=my_loss)
for data in dataloader:
x, event, time = data
loss = model_momentum(x, event, time) # torch.Size([64, 1])
loss.backward() # native torch backend
# Inference is computed with target network (k)
log_hzs = model_momentum.infer(x) # torch.Size([64, 1])
3.3 Evaluation Metrics Functions
The TorchSurv package offers a comprehensive set of metrics to evaluate the predictive
performance of survival models, including the AUC, C-index, and Brier score. The inputs
of the evaluation metrics functions are the individual risk score estimated on the test set
and the survival data on the test set. The risk score measures the risk (or a proxy thereof)
that a subject has an event. We provide definitions for each metric and demonstrate their
use through illustrative code snippets.
AUC. The AUC measures the discriminatory capacity of a model at a given time t,
i.e., the model’s ability to provide a reliable ranking of times-to-event based on estimated
individual risk scores (Heagerty and Zheng, 2005; Uno et al., 2007; Blanche et al., 2013).
from torchsurv.metrics import Auc
auc = Auc()
auc(log_hzs, event, time) # AUC at each time
auc(log_hzs, event, time, new_time=torch.tensor(10.)) # AUC at time 10
C-index. The C-index is a generalization of the AUC that represents the assessment of
the discriminatory capacity of the model over time (Harrell et al., 1996; Uno et al., 2011).
5from torchsurv.metrics import ConcordanceIndex
cindex = ConcordanceIndex()
cindex(log_hzs, event, time) # c-index
Brier score. The Brier score evaluates the accuracy of a model at a given time t. It
represents the average squared distance between the observed survival status and the pre-
dicted survival probability (Graf et al., 1999). The Brier score cannot be obtained for the
Cox model because the survival function is not available, but it can be obtained for the
Weibull model.
from torchsurv.metrics import Brier
surv = survival_function(log_params, time)
brier = Brier()
brier(surv, event, time) # Brier score at each time
brier.integral() # integrated brier score
In TorchSurv, the evaluation metrics can be obtained for time-dependent and time-
independent risk scores (e.g., for proportional and non-proportional hazards). Additionally
subjects can be optionally weighted (e.g., by the inverse probability of censoring weighting
(IPCW)). Lastly, functionalities including the confidence interval, one-sample hypothesis
test to determine whether the metric is better than that of a random predictor, and two-
sample hypothesis test to compare two evaluation metrics between different models are
implemented. For the hypothesis tests, the significance level, typically referred to as α,
can be modified as needed. The following code snippet exemplifies the aforementioned
functionalities for the C-index.
cindex.confidence_interval() # CI, default alpha = .05
cindex.p_value(alternative=’greater’) # pvalue, H0: c = 0.5, HA: c > 0.5
cindex.compare(cindex_other) # pvalue, H0: c1 = c2, HA: c1 > c2
4 Conclusion
ThispaperintroducesTorchSurv,aPythonpackage fordeepsurvivalmodelinginPyTorch.
Unlike existing libraries, TorchSurv allows users to define custom PyTorch-based deep sur-
vival models, offering crucial flexibility for complex data. TorchSurv provides extensive
functionalities for computing log-likelihoods and evaluating the predictive performance of
survival models efficiently. In summary, TorchSurv is a flexible toolkit for researchers and
practitioners, enhancing the capabilities of deep survival modeling in the PyTorch frame-
work.
5 Disclosures
MM, PK, DO and TC are employees and stockholders of Novartis, a global pharmaceutical
company.
6Appendix A. Survival Analysis Libraries in R
TorchSurv survival survAUC timeROC RisksetROC survcomp
(Therneau,2024) (Potapov etal.,2023) (Blanche,2019) (Heagerty,2022a) (Schr¨oderetal.,2011)
Standalone evaluation metrics
Concordanceindex ✓ ❅❅✓ ✓ ✗ ❅❅✓ ✓
AUC ✓ ✗ ✓ ✓ ❅❅✓ ❅❅✓
Brier-Score ✓ ✗ ✓ ✗ ✗ ✗
Time-dependentriskscore ✓ ✓ ✗ ✗ ✗ ✗
Subject-specificweights ✓ ✓ ✓ ❅❅✓ ✗ ✗
Confidenceinterval ✓ ✗ ✗ ✓ ✗ ✓
Comparetwometrics ✓ ✗ ✗ ✓ ✗ ✓
Competingriskssetting ✗ ✗ ✗ ✓ ✗ ✗
TorchSurv SurvivalROC riskRegression SurvMetrics pec
(Heagerty,2022b) (Gerdsetal.,2023) (Zhouetal.,2022) (Gerds,2023)
Standalone evaluation metrics
Concordanceindex ✓ ✗ ✗ ❅❅✓ ❅❅✓
AUC ✓ ❅❅✓ ❅❅✓ ✗ ✗
Brier-Score ✓ ✗ ❅❅✓ ❅❅✓ ❅❅✓
Time-dependentriskscore ✓ ✗ ❅❅✓ ✓ ✓
Subject-specificweights ✓ ✗ ❅❅✓ ✗ ❅❅✓
Confidenceinterval ✓ ✗ ✓ ✗ ✓
Comparetwometrics ✓ ✗ ✓ ✗ ✗
Competingriskssetting ✗ ✗ ✓ ✓ ✓
✓ indicates a fully supported feature, ✗ indicates an unsupported feature, ❅❅✓ indicates a partially supported feature.
Table 2: Survival analysis libraries in R. For obtaining the evaluation metrics, packages survival, riskRegression,
SurvMetrics and pec require the fitted model object as input (a specific object format) and RisksetROC imposes
a smoothing method. Packages timeROC, riskRegression and pec force the user to choose a form for subject-specific
weights (e.g., inverse probability of censoring weighting (IPCW)). Packages survcomp and SurvivalROC do not imple-
ment the general AUC but the censoring-adjusted AUC estimator proposed by Heagerty et al. (2000).
7References
S. Abeywardana. torchlife: Survival Analysis using pytorch, 2021. URL
https://sachinruk.github.io/torchlife//index.html.
P. Blanche. Time-Dependent ROC Curve and AUC for Censored Survival Data, 2019. URL
https://CRAN.R-project.org/package=timeROC. R package version 0.4.
P. Blanche, J. Dartigues, and H. Jacqmin-Gadda. Review and comparison of roc curve
estimators for a time-dependent outcome with marker-dependent censoring. Biometrical
Journal, 55(5):687–704, June 2013. ISSN 1521-4036. doi: 10.1002/bimj.201200045. URL
http://dx.doi.org/10.1002/bimj.201200045.
N.E.Breslow. Analysisofsurvivaldataundertheproportionalhazardsmodel.International
Statistical Review / Revue Internationale de Statistique, 43(1):45, Apr. 1975. ISSN 0306-
7734. doi: 10.2307/1402659. URL http://dx.doi.org/10.2307/1402659.
K. J. Carroll. On the use and utility of the weibull model in the analysis of survival data.
Controlled Clinical Trials, 24(6):682–701, Dec. 2003. ISSN 0197-2456. doi: 10.1016/
s0197-2456(03)00072-2. URL http://dx.doi.org/10.1016/S0197-2456(03)00072-2.
D. R. Cox. Regression models and life-tables. Journal of the Royal Statistical Society:
Series B (Methodological), 34(2):187–202, Jan. 1972. ISSN 2517-6161.
C. Davidson-Pilon. lifelines: survival analysis in python. Journal of Open Source Software,
4(40):1317, 2019.
B. Efron. The efficiency of cox’s likelihood function for censored data.
Journal of the American Statistical Association, 72(359):557–565, Sept.
1977. ISSN 1537-274X. doi: 10.1080/01621459.1977.10480613. URL
http://dx.doi.org/10.1080/01621459.1977.10480613.
T.A.Gerds. Prediction Error Curves for Risk Prediction Models in Survival Analysis, 2023.
URL https://CRAN.R-project.org/package=pec. R package version 2023.04.12.
T. A. Gerds, J. S. Ohlendorff, P. Blanche, R. Mortensen, M. Wright, N. Tol-
lenaar, J. Muschelli, U. B. Mogensen, and B. Ozenne. Risk Regression Mod-
els and Prediction Scores for Survival Analysis with Competing Risks, 2023.
URL https://CRAN.R-project.org/package=riskRegression. R package version
2023.12.21.
E. Graf, C. Schmoor, W. Sauerbrei, and M. Schumacher. Assessment and
comparison of prognostic classification schemes for survival data. Statistics
in Medicine, 18(17–18):2529–2545, September 1999. ISSN 1097-0258. doi:
10.1002/(sici)1097-0258(19990915/30)18:17/18h2529::aid-sim274i3.0.co;2-5. URL
http://dx.doi.org/10.1002/(SICI)1097-0258(19990915/30)18:17/18<2529::AID-SIM274>3.0.CO;2-
F. E. Harrell, K. L. Lee, and D. B. Mark. Multivariate prognostic models: Is-
sues in developing models, evaluating assumptions and adequacy, and measuring
8and reducing errors. Statistics in Medicine, 15(4):361–387, February 1996. ISSN
1097-0258. doi: 10.1002/(sici)1097-0258(19960229)15:4h361::aid-sim168i3.0.co;2-4. URL
http://dx.doi.org/10.1002/(SICI)1097-0258(19960229)15:4<361::AID-SIM168>3.0.CO;2-4.
K.He, H. Fan, Y. Wu, S.Xie, andR. Girshick. Momentum contrast for unsupervisedvisual
representation learning. In Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition, pages 9729–9738, 2020.
P. J. Heagerty. Riskset ROC Curve Estimation from Censored Survival Data, 2022a. URL
https://CRAN.R-project.org/package=risksetROC. R package version 1.0.4.1.
P. J. Heagerty. Time-Dependent ROC Curve Estimation from Censored Survival Data,
2022b. URL https://CRAN.R-project.org/package=survivalROC. R package version
1.0.3.1.
P.J.HeagertyandY.Zheng.Survivalmodelpredictiveaccuracyandroccurves. Biometrics,
61(1):92–105, February 2005. ISSN 1541-0420. doi: 10.1111/j.0006-341x.2005.030814.x.
URL http://dx.doi.org/10.1111/j.0006-341x.2005.030814.x.
P. J. Heagerty, T. Lumley, and M. S. Pepe. Time-dependent roc curves for
censored survival data and a diagnostic marker. Biometrics, 56(2):337–344,
June 2000. ISSN 1541-0420. doi: 10.1111/j.0006-341x.2000.00337.x. URL
http://dx.doi.org/10.1111/j.0006-341x.2000.00337.x.
J. L. Katzman, U. Shaham, A. Cloninger, J. Bates, T. Jiang, and Y. Kluger. Deepsurv:
personalizedtreatmentrecommendersystemusingacoxproportionalhazardsdeepneural
network. BMC medical research methodology, 18(1):1–12, 2018.
H. Kvamme, Ørnulf Borgan, and I. Scheel. Time-to-event prediction with neural networks
and cox regression. Journal of Machine Learning Research, 20(129):1–30, 2019. URL
http://jmlr.org/papers/v20/18-424.html.
C. Nagpal, W. Potosnak, and A. Dubrawski. auton-survival: An open-source package for
regression, counterfactual estimation, evaluation and phenotyping with censored time-
to-event data. In Machine Learning for Healthcare Conference, pages 585–608. PMLR,
2022.
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin,
N. Gimelshein, L. Antiga, et al. Pytorch: An imperative style, high-performance deep
learning library. Advances in neural information processing systems, 32, 2019.
S. Po¨lsterl. scikit-survival: A library for time-to-event analysis built on top of scikit-learn.
The Journal of Machine Learning Research, 21(1):8747–8752, 2020.
S. Potapov, W. Adler, and M. Schmid. Estimators of prediction accuracy for time-to-event
data, 2023. URL https://CRAN.R-project.org/package=survAUC. R package version
1.2-0.
9M. S. Schro¨der, A. C. Culhane, J. Quackenbush, and B. Haibe-Kains. survcomp: an r/bio-
conductorpackage forperformanceassessmentandcomparison of survivalmodels. Bioin-
formatics, 27(22):3206–3208, Sept. 2011. ISSN 1367-4803. doi: 10.1093/bioinformatics/
btr511. URL http://dx.doi.org/10.1093/bioinformatics/btr511.
T. M. Therneau. A Package for Survival Analysis in R, 2024. URL
https://CRAN.R-project.org/package=survival. R package version 3.5-8.
H. Uno, T. Cai, L. Tian, and L. J. Wei. Evaluating prediction rules fort-year survivors
with censored regression models. Journal of the American Statistical Association, 102
(478):527–537, June 2007. ISSN 1537-274X. doi: 10.1198/016214507000000149. URL
http://dx.doi.org/10.1198/016214507000000149.
H. Uno, T. Cai, M. J. Pencina, R. B. D’Agostino, and L. J. Wei. On the c-statistics for
evaluating overall adequacy of risk prediction procedures with censored survival data.
Statistics in Medicine, 30(10):1105–1117, January 2011. ISSN 1097-0258. doi: 10.1002/
sim.4154. URL http://dx.doi.org/10.1002/sim.4154.
H. Zhou, X. Cheng, S. Wang, Y. Zou, and H. Wang. Predictive Evaluation Metrics in
Survival Analysis, 2022. URL https://CRAN.R-project.org/package=SurvMetrics.
R package version 0.5.0.
10