Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction
in Unbounded Scenes
ZEHAOYU,UniversityofTübingen,TübingenAICenter,Germany
TORSTENSATTLER,CzechTechnicalUniversityinPrague,CzechRepublic
ANDREASGEIGER,UniversityofTübingen,TübingenAICenter,Germany
https://niujinshuchong.github.io/gaussian-opacity-fields
Fig.1. ApplyingTSDFfusionwithrendereddepthmapsfromthestate-of-the-artMip-Splatting[Yuetal.2024a]modelsresultsinnoisyandincomplete
meshes,whilemeshesextractedwithourmethodarecomplete,smoothanddetailed.ThisisachievedbyestablishingaGaussianopacityfieldfrom3D
Gaussians,whichenablesgeometryextractionbydirectlyidentifyingitslevel-set.Moreover,wegeneratetetrahedralmeshesfrom3DGaussiansandutilize
marchingtetrahedratoextractcompactandadaptivemeshes.
Recently,3DGaussianSplatting(3DGS)hasdemonstratedimpressivenovel 2021;Yarivetal.2021].Whilerecentadvancements[Lietal.2023;
viewsynthesisresults,whileallowingtherenderingofhigh-resolutionim- Yarivetal.2023;Yuetal.2022a,b]haveshownimpressiverecon-
agesinreal-time.However,leveraging3DGaussiansforsurfacereconstruc- structionresults,thesemethodsaremostlylimitedtoreconstructing
tionposessignificantchallengesduetotheexplicitanddisconnectednature foregroundobjects[RosuandBehnke2023]andcomputationalex-
of3DGaussians.Inthiswork,wepresentGaussianOpacityFields(GOF), pensivetooptimize[Lietal.2023;Yarivetal.2023].Forinstance,
anovelapproachforefficient,high-quality,andcompactsurfacerecon-
Neuralangelo[Lietal.2023]modelsthebackgroundseparatelywith
structioninunboundedscenes.OurGOFisderivedfromray-tracing-based
NeRFsandnecessitatesapproximately128GPUhourstoreconstruct
volumerenderingof3DGaussians,enablingdirectgeometryextraction
asinglescene.
from3DGaussiansbyidentifyingitslevelset,withoutresortingtoPoisson
reconstructionorTSDFfusionasinpreviouswork.Weapproximatethe Anotherresearchavenuefocusesondirectlyextractingsurfaces
surfacenormalofGaussiansasthenormaloftheray-Gaussianintersection fromNeRF’sopacityfieldforreal-timerendering[Chenetal.2023a;
plane,enablingtheapplicationofregularizationthatsignificantlyenhances Rakotosaonaetal.2024;Reiseretal.2024;Tangetal.2022].These
geometry.Furthermore,wedevelopanefficientgeometryextractionmethod methodsemployamodularworkflowincludingopacityfieldtrain-
utilizingmarchingtetrahedra,wherethetetrahedralgridsareinducedfrom ing,meshextraction,simplification,andrefinement.Particularly
3DGaussiansandthusadapttothescene’scomplexity.Ourevaluations noteworthyistheBinaryOpacityGrids(BOG)[Reiseretal.2024],
revealthatGOFsurpassesexisting3DGS-basedmethodsinsurfacerecon- which excels at capturing intricate details in unbounded scenes
structionandnovelviewsynthesis.Further,itcomparesfavorablyto,or
through the use of super-sampling. To extract detailed surfaces,
evenoutperforms,neuralimplicitmethodsinbothqualityandspeed.
itrendersdepthmapstogenerateasparsehigh-resolutionvoxel
CCSConcepts:•Computingmethodologies→Reconstruction;Render- gridandappliesaheuristicfusiontechniquetolabelthevoxelsas
ing;Machinelearningapproaches. insideoroutside.TheMarchingcubealgorithm[LorensenandCline
1998]isappliedtoextractahigh-resolutionmeshwithhundredsof
AdditionalKeyWordsandPhrases:NovelViewSynthesis,Differentiable
millionsofpointsandthousandsofmillionsoftriangles,whichis
Rendering,GaussianSplatting,SurfaceReconstruction,Multi-view-to-3D
thenthensimplifiedusingslowpost-processingtechniques[Gar-
landandHeckbert1997].Notably,asitfocusesonNVSratherthan
1 INTRODUCTION
surfacereconstruction,theextractedmeshesarenoisyandcontain
3DReconstructionfrommulti-viewimageshasbeenalong-standing fewer details in the background region, probably due to lack of
goalincomputervision,withvariousapplicationsinrobotics,graph- regularizationandcontractedspace[Barronetal.2022a]fusion.
ics,animation,virtualreality,andmore.SinceNeuralRadianceField Morerecently,3DGaussianSplatting(3DGS)[Kerbletal.2023]
(NeRF)[Mildenhalletal.2020]demonstratedimpressivenovelview representscomplexscenesasasetof3DGaussians,demonstrating
synthesis(NVS)resultswithimplicitrepresentations[Mescheder photorealisticNVSresultswhiletrainedefficientlyandrendered
etal.2019;Parketal.2019]andvolumerendering[Drebinetal.1988; atreal-time.Ithasbeenquicklyextendedtosurfacereconstruc-
KajiyaandVonHerzen1984;Levoy1990;Max1995],ithasbeen tion[Chenetal.2023b;GuédonandLepetit2023;Huangetal.2024;
extendedtosurfacereconstructionwithoccupancynetworks[Oech-
sleetal.2021]andSignedDistanceFunctions(SDF)[Wangetal.
4202
rpA
61
]VC.sc[
1v27701.4042:viXra2 • ZehaoYu,TorstenSattler,andAndreasGeiger
Yuetal.2024b].Notably,Sugar[GuédonandLepetit2023]regular- 2 RELATEDWORK
izesthe3DGaussianstoalignwithsurfacesandemploysPoisson 2.1 Novelviewsynthesis
surfacereconstruction[KazhdanandHoppe2013]toextractamesh
NeRF[Mildenhalletal.2020]utilizesamulti-layerperception(MLP)
fromrendereddepthmaps.2DGaussianSplatting(2DGS)[Huang
forscenerepresentation,includinggeometryandview-dependent
etal.2024]uses2DGaussiansinsteadof3DGaussiansasascene
appearances.TheMLPisoptimizedviaaphotometriclossthrough
representationforbettersurfacesrepresentationandutilizesTSDF
volumerendering[Drebinetal.1988;KajiyaandVonHerzen1984;
fusiontoreconstructamesh.Whilethesemethodshaveshown
Levoy1990;Max1995].Subsequentenhancementshavefocusedon
improvedreconstruction,theystrugglewithextractingfine-grained
optimizingNeRF’strainingusingfeature-gridrepresentations[Chen
geometry[GuédonandLepetit2023]andreconstructingbackground
etal.2022;Fridovich-Keiletal.2022;KulhanekandSattler2023;
regions[Huangetal.2024].Aprimarychallengeistheinconsistency
Mülleretal.2022;Sunetal.2022]andimprovingrenderingspeed
betweenmeshextractionandvolumerenderingduringtraining.
viabaking[Hedmanetal.2021;Reiseretal.2021,2023;Yarivetal.
Specifically,Poissonreconstructionignorestheopacityandscaleof
2023].Moreover,NeRFhasbeenadaptedtoaddresschallengesin
Gaussianprimitivesandrendereddepthmapsarenotsufficiently
anti-aliasing[Barronetal.2022b,2023]andunboundedscenemod-
reliable.Moreover,TSDFfusionstrugglestoaccuratelymodelthin
eling[Barronetal.2022a;Zhangetal.2020].Morerecently,3D
structuresandtoreconstructunboundedscenes.Resortingtohigh-
Gaussiansplatting[Kerbletal.2023]representscomplexscenes
resolutionvoxelgridsforTSDFleadstothecreationoflargemeshes,
with3DGaussians.ItdemonstratedimpressiveNVSresultswhile
similartoBOG[Reiseretal.2024],duetothelackofadaptivityin
beingoptimizedefficientlyandrenderinghigh-resolutionimages
thegridresolutionrelativetothescene’sgeometriccomplexity.
inreal-time.Subsequentworksimproveditsrenderingqualityvia
Contributions:Inthispaper,weproposeGaussianOpacityFields
anti-aliasing [Yu et al. 2024a] or extended it to dynamic scenes
(GOF),anovelapproachtoachieveefficient,high-quality,andcom-
modeling[Zhouetal.2024],andmore[ChenandWang2024].In
pactsurfacereconstructionfrom3DGaussiansdirectly.Ourkey
thiswork,weextend3DGSforhigh-qualitysurfacereconstruction
insightsarethreefold:First,weestablishaGaussianopacityfield
throughthedevelopmentofGaussianOpacityFields.Wefurther
fromasetof3DGaussians.Specifically,unlikeprojection-based
introduceanefficienttetrahedrongrid-basedmeshextractionalgo-
volumerendering,ourmethodleveragesanexplicitray-Gaussian
rithmtoextractcompactandsceneadaptivemeshes.
intersectiontodetermineaGaussian’scontributionduringvolume
rendering.Ourray-tracing-inspiredformulafacilitatestheevalu- 2.2 3Dreconstruction
ationofopacityvaluesforanypointalongaray.Wethendefine
3DReconstructionfrommulti-viewimagesisafundamentalprob-
theopacityofany3Dpointastheminimalopacityoveralltraining
lemincomputervision.Multi-viewstereomethods[Schönberger
viewsthatobservedthepoint.OurGOFisconsistentwithvolume
etal.2016;Yaoetal.2018;YuandGao2020]oftenemploycomplex
renderingduringtrainingandenablessurfaceextractionfrom3D
multi-stagepipelinesthatincludefeaturematching,depthestima-
Gaussiansbydirectlyidentifyingalevelset,withoutresortingto
tion,pointcloudfusion,andultimately,surfacereconstructionfrom
PoissonreconstructionorTSDFfusion.Second,weapproximate
aggregatedpointclouds[KazhdanandHoppe2013].Incontrast,neu-
thesurfacenormalsof3DGaussiansasthenormalsofintersec-
ralimplicitmethods[Oechsleetal.2021;Wangetal.2021;Yarivetal.
tionplanesbetweentherayandGaussians.Thistechniqueallows
2021]significantlysimplifythepipelinebyoptimizinganimplicit
fortheincorporationofregularizations[Huangetal.2024]during
surfacerepresentationviavolumerendering.Afteroptimization,tri-
training,thusenhancingthefidelityofgeometryreconstruction.
anglemeshescanbeextractedeasilywithMarchingcubes[Lorensen
Third,weproposeanefficientsurfaceextractiontechniquebased
andCline1998]atanyresolution.Notableadvancementshavebeen
ontetrahedra-grids.Recognizingthat3DGaussianseffectivelyin-
madethroughtheadoptionofmoreexpressivescenerepresenta-
dicate potential surface locations, we focus opacity evaluations
tions[Lietal.2023],advancedtrainingstrategies[Lietal.2023],
ontheseareas.Inparticular,weusethecenterandcornersof3D
andtheintegrationofmonocularpriors[Yuetal.2022b].Despite
boundingboxesaroundthe3DGaussianprimitivesasvertexset
theseadvances,thesemethodsaremostlylimitedinreconstructing
forthetetrahedralmesh.Uponassessingtheopacityattetrahedral
foregroundobjects[RosuandBehnke2023]andarecomputationally
points,weutilizethemarchingtetrahedraalgorithmfortriangle
expensivetooptimize[Lietal.2023;Yarivetal.2023].Furthermore,
meshextraction.Giventhatouropacityfieldschallengetheassump-
theuseofhigh-resolutiongridsforcapturingfinedetailsoftenre-
tionthatopacitychangeslinearly,wefurtherimplementanbinary
sultsinexcessivelylargemeshes.Bycontrast,weestablishGaussian
searchalgorithmtoaccuratelyidentifytheopacityfield’slevelset,
OpacityFieldsusing3DGS[Kerbletal.2023],whichfacilitatesfast
substantiallyenhancingthequalityoftheresultingsurfaces.
training.Weutilizemarchingtetrahedra[DoiandKoide1991;Shen
TodemonstratetheeffectivenessandefficiencyofourGaussian
etal.2021]toextractcompact,adaptive,anddetailedmeshesin
OpacityFields(GOF),wecarryoutextensiveexperimentsacross
unboundedscenes.
threechallengingdatasets[Barronetal.2022a;Jensenetal.2014;
Knapitschetal.2017].OurresultsindicatethatGOFnotonlymatches
2.3 SurfaceReconstructionwithGaussians
but,insomecases,surpassestheperformanceofexistingSDF-based
methods,whilebeingmuchfaster.Moreover,GOFoutperformsall InspiredbytheimpressiveNVSperformanceof3DGaussianSplat-
other3DGS-basedmethodsinbothsurfacereconstructionandnovel ting(3DGS)[Kerbletal.2023],researchershaveproposedtoutilize
viewsynthesis. 3DGaussiansforsurfacereconstruction.Recentefforts[Chenetal.
2023b;Yuetal.2024b]haveintegrated3DGaussianswithneuralGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes • 3
implicitsurfaces,optimizingaSignedDistanceFunction(SDF)net-
workand3DGaussiansjointly.Whiletheseapproachesmarksome
advancements,theyalsoinherittheshortcomingsassociatedwith
implicitsurfacesaspreviouslydiscussed.Otherstudieshavefocused
onsurfaceextractionfromoptimizedGaussianprimitivesthrough
post-processingtechniques[GuédonandLepetit2023;Huangetal.
2024;Turkulainenetal.2024].Notably,Sugar[GuédonandLepetit
2023]adoptsPoissonsurfacereconstruction[KazhdanandHoppe
2013]toextractmeshesfromrendereddepthmaps.Meanwhile,2D Fig.2. Illustrationofraytracingvolumerendering.Evaluatinga3D
GaussianSplatting(2DGS)[Huangetal.2024]employsTSDFfusion Gaussianalongarayresultsina1DGaussian,whichhasaclosed-form
forthispurpose.Thoughthesemethodsachieveimprovedrecon- solutionforwhenitreachesmaximalvalue.Theopacityalongtherayis
structions,theyfacechallengesincapturingfine-grainedgeometry monotonouslyincreasinguntilitreachesthemaximalvalueandremains
andadequatelyreconstructingbackgroundareas.Inthiswork,we thesameafterwards.
deriveGaussianOpacityFieldsdirectlyfrom3DGaussians.OurGOF
isconsistentwiththevolumerenderingprocessforrenderingRGB systemofthe3DGaussianandnormalizethepointbyitsscale:
i sm eta ,g we is t. hI ot ue tn ra eb sl oe rs tid ni gre tc ot Psu or isf sa oc nee rex ctr oa nc st ti ro un ctb iy onid ae nn dti Tfy Si Dng Fa ful se iv oe nl
.
o𝑔 =(R𝑘(o−p𝑘))⊙s 𝑘−1 (2)
Additionally,weproposeatetrahedrongrid-basedtechniquefor r𝑔 =R𝑘r⊙s 𝑘−1 (3)
meshextraction,resultingindetailedandcompactmeshes. x𝑔 =o𝑔+𝑡r𝑔 (4)
where⊙denoteselement-wisemultiplication.Inthislocalcoordi-
3 METHOD natesystem,theGaussianvalueatanypointalongtheraybecomes
a1DGaussian,whichisdescribedby:
Givenmultipleposedandcalibratedimages,ourgoalistorecon-
structthe3Dsceneefficientlywhileallowingdetailedandcompact G 𝑘1𝐷 (𝑡)=G𝑘(x𝑔)=𝑒−1 2x𝑇 𝑔x𝑔 (5)
surfaceextractionandphotorealisticnovelviewsynthesis.Tothis
ThemaximumofEq.5hasaclosedformsolutionat
end,wefirstconstructaGaussianOpacityField(GOF)from3D
Gaussians,enablinggeometryextractiondirectlybyidentifyinga 𝐵
𝑡∗=− (6)
levelset,eliminatingtheneedfortraditionalPoissonreconstruc- 𝐴
tion or TSDF fusion. Next, we extend two effective regularizers where𝐴=r𝑇 𝑔r𝑔and𝐵=o𝑇 𝑔r𝑔.Now,wedefinethecontributionE
from2DGS[Huangetal.2024]toour3DGaussians,improving ofaGaussianG𝑘 foragivencameracenteroandraydirectionras:
reconstructionquality.Finally,weproposeanoveltetrahedra-based
methodtoextractdetailedandcompactmeshesfromGOFswith
E(G𝑘,o,r)=G 𝑘1𝐷 (𝑡∗) (7)
marchingtetrahedra.
VolumeRendering:Similarto3DGS[Kerbletal.2023],thecolor
ofacamerarayisrenderedviaalphablendingaccordingtothe
3.1 Modeling primitive’sdepthorder1,...,𝐾:
Similartopriorworks[Kerbletal.2023;Zwickeretal.2001],we 𝐾 𝑘−1
∑︁ (cid:214)
representthescenewithasetof3DGaussianprimitives{G𝑘|𝑘 =
c(o,r)= c𝑘𝛼 𝑘E(G𝑘,o,r) (1−𝛼 𝑗E(G𝑘,o,r)) (8)
1,···,𝐾}.Thegeometryofeach3DGaussianG𝑘 isparameterized 𝑘=1 𝑗=1
byanopacity𝛼 𝑘 ∈ [0,1],centerp𝑘 ∈ R3×1,scales ∈ R3×1,and wherec𝑘 istheview-dependentcolor,modeledwithsphericalhar-
rotationR∈R3×3parameterizedbyaquaternion: monics.Toefficientlyrenderanimage,weutilizethesametile-based
renderingprocessasin3DGS[Kerbletal.2023].
G𝑘(x)=𝛼 𝑘𝑒−1 2(x−p𝑘)𝑇𝚺 𝑘−1(x−p𝑘) (1) 3.2 GaussianOpacityFields
OnesignificantbenefitofusingexplicitRay-Gaussianintersection
insteadofprojectionisthatitallowsevaluatingtheopacityvalue
where𝚺
𝑘
∈R3×3isacovariancematrixdefinedas𝚺
𝑘
=R𝑘s𝑘s𝑇 𝑘R𝑇 𝑘. ortransmittanceofanypointalongtheray.Let’sfirstconsiderthe
RayGaussianIntersection:Insteadofprojecting3DGaussians casewhenthereisonlyasingleGaussianG𝑘 alongtheray.Inthis
to2DscreenspaceandevaluatingtheGaussianin2D,weevaluate case,theopacityofanypointalongtherayis:
thecontributionofaGaussiantoaraywithexplicitray-Gaussian (cid:40) G1𝐷(𝑡) if𝑡 ≤𝑡∗
intersection[Gaoetal.2023;KeselmanandHebert2022].Theray- O𝑘(G𝑘,o,r,𝑡)= G𝑘
1𝐷(𝑡∗) if𝑡 >𝑡∗
GaussianintersectionisdefinedasthepointwheretheGaussian 𝑘
reachesitsmaximumvaluealongtheray.Specifically,givenacam- wherex=o+𝑡r.Intuitively,theopacityincreasesuntilitreaches
eracenterato ∈ R3×1 andaraydirectionr ∈ R3×1,anypoint its maximal value, and after that it remains the same since the
x∈R3×1alongtheraycanbewrittenasx=o+𝑡r,where𝑡isdepth transmittance,e.g.1−O,ismonotonouslydecreasingalongaview
oftheray.Wefirsttransformthepointxtothelocalcoordinate ray,asillustratedinFigure2.Therefore,theopacityatanypoint4 • ZehaoYu,TorstenSattler,andAndreasGeiger
alongaraygivenasetofGaussianscanbedefinedsimilartothe To mitigate this issue,
volumerenderingprocessinEq.8as: wedefinethenormalofa
3DGaussianasthenormal
𝐾 𝑘−1
∑︁ (cid:214) of the intersection plane
O(o,r,𝑡)= 𝛼 𝑘O𝑘(G𝑘,o,r,𝑡) (1−𝛼 𝑗O𝑘(G𝑘,o,r,𝑡)) (9)
given a ray direction. An
𝑘=1 𝑗=1
illustrationisshowninthe
Now, we can define the opacity of a 3D point x as the minimal inset. Therefore, the nor-
opacityvalueamongalltrainingviewsorviewingdirections: mal is approximated as n𝑖 = −R𝑇(r𝑔 ⊙ s−1) and we apply the
depth-normalconsistencyregularisation:
O(x)=minO(o,r,𝑡) (10)
(r,𝑡) L𝑛 =∑︁ 𝜔 𝑖(1−n𝑖⊤N) (12)
WecallthisGaussianOpacityField(GOF)sinceitisanopacityfield
𝑖
derivedfrom3DGaussians.OurGOFsharessimilaritiestothevisual
where𝑖indexesoverintersectedGaussiansalongtheray,𝜔denotes
hull[Laurentini1994]orspacecarving[KutulakosandSeitz2000].
theblendingweight,andNisthenormalestimatedbythegradient
Butinsteadofusingasilhouettewheretheopacityvalueofaray
ofthedepthmap[Huangetal.2024].
(allpointsontheray)iseither1or0,GOFusesvolumerendering
foreachpointbasedon3DGaussians.
FinalLoss:Finally,weoptimizeourmodelfromaninitialsparse
pointcloudusingmultipleposedimagesbyminimizingthefollow-
OurGOFisconsistentwiththevolumerenderingprocessfor
ingloss:
RGBrenderingduringtraining.WithGOF,wecanextractsurfaces
directlybyidentifyingtheirlevelsets,similartoUNISURF[Oechsle L=L𝑐 +𝛼L𝑑 +𝛽L𝑛 (13)
etal.2021],withoutresortingtoPoissonreconstruction[Guédon whereL𝑐 isanRGBreconstructionlosscombiningL1 withthe
andLepetit2023]orTSDFfusion[Huangetal.2024].Wewilldiscuss D-SSIMtermfrom[Kerbletal.2023],whileL𝑑 andL𝑛 areregu-
ourmethodforefficientandcompactmeshextractioninSection3.4. larizationterms.Notethat,weutilizethedecoupledappearance
WealsonotethatGOFsareageneralformulaaslongasthescene modelingproposedinVastGaussian[Linetal.2024]tomodelthe
representationisasetof3DGaussians.Forexample,wecanuseit unevenilluminationfortheTanksandTemplesdataset[Knapitsch
toextractameshfromapretrained3DGS[Kerbletal.2023]orMip- etal.2017],whereasmallconvolutionalneuralnetworkisusedto
Splatting[Yuetal.2024a]model,whereprojection-basedvolume predictimage-dependentcolorssuchthatthemodelwillnotfake
renderingisusedfortraining,aswewillshownintheexperiments. inconsistentilluminationwithgeometry.
3.3 Optimization 3.4 SurfaceExtraction
Optimizing3DGaussianswithpurephotometriclossleadstonoisy Post-training, the conventional step towards surface or triangle
resultsas3Dreconstructionfrommulti-viewsisanunderconstrained mesh extraction involves densely evaluating the opacity values
problem[Barronetal.2022a;Zhangetal.2020].Therefore,weex- withinregionsofinterest,atechniquewell-suitedtosimplescenar-
tendtheregularizationtermsin2DGS[Huangetal.2024]toop- iosliketheDTUDataset[Jensenetal.2014],asdoneinprevious
timizeour3DGaussians,includingadepthdistortionlossanda work[Oechsleetal.2021;Wangetal.2021;Yarivetal.2021]Fora
normalconsistencyloss. largescaleunboundedscene,somehaveadopteddenseevaluation
DepthDistortion:Weapplythedepthdistortionloss[Huangetal. inacontractedspace[Yarivetal.2023].However,denseevaluation
2024]totheray-GaussianintersectiontoconcentrateGaussians forgridsincurssubstantialcomputationalcostsduetothecubic
alongtheray: growthofcomplexitywithgridresolution.Unfortunately,capturing
∑︁ finedetailsnecessitateshigh-resolutiongrids,leadingtosignificant
L𝑑 = 𝜔 𝑖𝜔 𝑗|𝑡 𝑖 −𝑡 𝑗| (11) overhead.Alternativesparsegridsmayreducedenseevaluation
𝑖,𝑗
needsbutstillresultinhugemeshes,oftencomprisinghundredsof
where𝑖,𝑗 indexoverGaussianscontributedtotherayand𝜔 𝑖 = millionsofpointsandbillionsoffaces.Simplifyingsuchlargeand
𝛼 𝑘E(G𝑘,o,r)(cid:206)𝑘 𝑗=− 11 (1−𝛼 𝑗E(G𝑘,o,r)) istheblendingweightof complexmeshestypicallyrequiresaslowpost-processingstep.For
the𝑖−thGaussianand𝑡 𝑖isthedepthoftheintersectionpointinEq.6. instance,meshsimplificationinBOG[Reiseretal.2024]requires
However,thedistortionlossminimizesboththedistancebetween approximately4hours.Tocircumventthesechallenges,weintro-
GaussiansandtheweightsofeachGaussianwhereasminimizingthe duceanovelmethodforextractingcompactandadaptivemeshes
weightsoftheGaussianscouldleadtoanincreaseinalphavalues usingtetrahedralgrids.
forGaussiansthatareblendedfirst,whichresultsinexaggerated
TetrahedralGridsGeneration:Ourprimaryinsightisthatthe
Gaussians,resultinginfloaters.Therefore,wedetachthegradient
positionandscaleof3DGaussianprimitivesserveasreliableindica-
ofweights𝑤 andonlyminimizethedistancebetweenGaussians.
𝑖 torsforthepresenceofsurfaces.Tocapitalizeonthis,wegeneratea
NormalConsistency:Akeychallengeofapplying2DGS’snormal 3Dboundingboxat3-sigmaaroundeachGaussianprimitive,where
consistencyregularization[Huangetal.2024]to3DGaussiansis itscenterhashighestopacityanditscornershavesmallestopacity.
thatthegradientof3DGaussiansalwayspointsoutwardsfromthe Wethenestablishtetrahedralgridswiththecenterandcornersof
centers.Thisleadstodiscontinuitywhentheraypassesthecenter 3Dboundingboxes.DrawinginspirationfromTetra-NeRF[Kul-
ofGaussians,makingthetheoptimizationdifficulty. hanekandSattler2023],weemploytheCGALLibrary[Jaminetal.GaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes • 5
Table 1. Quantitative results on the Tanks and Temples
Dataset [Knapitsch et al. 2017]. Reconstructions are evaluated
withtheofficialevaluationscriptsandwereportF1-scoreandaverage
optimizationtime.GOFoutperformsall3DGS-basedsurfacereconstruction
methodsbyalargemarginandperformscomparablywiththeSOTAneural
implicitmethodswhileoptimizingsignificantlyfaster.
Implicit Explicit
NeuS Geo-Neus Neurlangelo SuGaR 3DGS 2DGS Ours
Barn 0.29 0.33 0.70 0.14 0.13 0.36 0.51
(a)MarchingCubes (b)MarchingCubeswithbinarysearch Caterpillar 0.29 0.26 0.36 0.16 0.08 0.23 0.41
Fig.3. QualitycomparisonofapplyingbinarysearchtotheMarching Courthouse 0.17 0.12 0.28 0.08 0.09 0.13 0.28
cubesalgorithmonourGaussianOpacityField.Strongstepartifacts Ignatius 0.83 0.72 0.89 0.33 0.04 0.44 0.68
Meetingroom 0.24 0.20 0.32 0.15 0.01 0.16 0.28
canbeobservedinMarchingcubesresultssincethelinearassumptiondoes
Truck 0.45 0.45 0.48 0.26 0.19 0.26 0.59
notholdinourGOF.Applyingourbinarysearchalgorithmeliminatesthis Mean 0.38 0.35 0.50 0.19 0.09 0.30 0.46
artifact. Time >24h >24h >24h >1h 14.3m 34.2m 1h
2024]forDelaunaytriangulationtoconstructtetrahedralcells.The
4.1 ImplementationDetails
generatedtetrahedralgridmightconnectpointsacrosssignificant
distances. Therefore, we employ an additional filtering step for WebuildGOFupontheopen-source3DGScodebase[Kerbletal.
thetetrahedralcells,removinganycellwhoseedgesconnectnon- 2023]andimplementcustomCUDAkernelsforray-tracing-based
overlappingGaussians.Gaussiansareconsiderednon-overlapping volume rendering, regularizations, and opacity evaluation. Reg-
whenthelengthoftheedgeconnectingthemexceedsthesumof ularization parameters are set to𝛼 = 1000 for bounded scenes,
theirmaximumscales. 𝛼 =100forunboundedscenes,and𝛽 =0.05forallscenes,following
2DGS[Huangetal.2024].Wemakeaslightchangeto3DGS’sadap-
EfficientOpacityEvaluation:Toefficientlyevaluatetheopacityof
tivedensificationstrategy,whichincreasesthenumberofprimitives,
theverticesofthetetrahedralgrid,wedesignatile-basedevaluation
toenhanceuniformityofGaussiansandmitigateover-reconstructed
algorithm,inspiredby3DGS[Kerbletal.2023].Specifically,wefirst
regions.Moredetailsofourchangesareprovidedinthesupplemen-
projecttheverticestoimagespaceandidentifythecorresponding
tarymaterial.Similarto3DGS,westopdensificationat15kitera-
tilesfortheseprojections.Thesepointsarethenorganizedaccording
tionsandoptimizeallofourmodelsfor30kiterations.Formesh
totheirtileID.Foreachtile,weretrievethelistofpointsthatare
extraction,weadapttheMarchingTetrahedraalgorithm[Shenetal.
projectedwithinit,projectthesepointsagaintoidentifythepixel
2021]fromtheKaolinlibrary[FujiTsangetal.2022]withourbi-
thatitfallsinside,andidentifytheGaussiansthatcontributetothis
narysearchalgorithmandextractthemeshforthe0.5level-set.All
pixel.Finally,weenumerateallpointstoevaluatetheiropacitybased
experimentsareconductedonanNVIDIAA100GPU.
onthepre-filteredlistofGaussians.Anoverviewofthealgorithm
isprovidedinthesupplementarymaterial.
4.2 GeometryEvaluation
BinarySearchofLevelSet:Upondeterminingtheopacityval-
WefirstcompareagainstbothSOTAimplicitandexplicitsurface
uesforthetetrahedralgrid,weproceedtoextracttrianglemeshes
reconstructionmethodsontheTanksandTemplesDataset.Recon-
usingtheMarchingTetrahedramethod[Shenetal.2021].Tradi-
structionsareevaluatedonlyfortheforegroundobjectssincethe
tionalmarchingalgorithms,includingMarchingCubes[Lorensen
groundtruthpointclouddonotcontainbackgroundregions.As
andCline1998]andMarchingTetrahedra,typicallyrelyonlinear
showninTable1,ourmethodiscompetitivewithleadingimplicit
interpolationtoapproximatethelevelset,presumingtheunderly-
approach[Lietal.2023]whilebeingmuchmoreefficienttoopti-
ingfield’slinearity.Thisassumption,however,misalignswiththe
mize.Notethatmostimplicitapproaches[Lietal.2023;Wangetal.
characteristicsofourGaussianOpacityField,leadingtoartifacts
2021]onlyreconstructtheforegroundobjects,ourmethodisableto
duetolinearinterpolation,asshowninFigure3(a).Toovercome
reconstructdetailedmeshesalsoforthebackgroundregions,which
thisdiscrepancyandaccuratelyidentifythelevelsetwithinour
isofgreatimportanceformesh-basedreal-timerendering[Reiser
non-linearopacityfield,werelaxthelinearassumptiontoamono-
etal.2024].Furthermore,whileourmethodisslightlyslowerthan
tonically increasing assumption. This adjustment allows for the
3DGS[Kerbletal.2023]and2DGS[Huangetal.2024]duetothe
implementationofabinarysearchalgorithmtopreciselyidentify
ray-Gaussianintersectioncomputation,itsignificantlyoutperforms
thelevelset.Inpractice,wefoundthatconducting8iterationsof
allSOTA3DGS-basedmethodsintermsofreconstructionquality.A
binarysearch—effectivelysimulating256denseevaluations—yields
qualitativecomparisonisshowninFigure4.GOFreconstructsfine-
consistentandreliableoutcomes.Acomparisonhighlightingthe
detailedsurfacesforbothforegroundobjectsandthebackground
improvementsofbinarysearchisshowninFigure3.
regions.Bycontrast,meshesextractedfromSuGaR[Guédonand
Lepetit 2023] are noisy, while 2DGS [Huang et al. 2024] fails to
4 EXPERIMENTS
extractgeometryforthebackgroundregions.
WeconductathoroughevaluationofourGaussianOpacityField WefurthercompareagainstSOTAsurfacereconstructionmeth-
(GOF),comparingitssurfacereconstructionandnovelviewsysnthe- odsontheDTUdataset[Jensenetal.2014].AsshowninTable2,
sisagainstleadingmethods.Wefurthervalidatetheeffectiveness ourmethodoutperformsall3DGS-basedmethods.Despiteaper-
ofitskeycomponentsthroughablationstudies. formancegapwiththeleadingimplicitreconstructionmethod[Li6 • ZehaoYu,TorstenSattler,andAndreasGeiger
SuGar[GuédonandLepetit2023] 2DGS[Huangetal.2024] Ours GT
Fig.4. SurfaceReconstructionontheTanksandTemplesDataset[Knapitschetal.2017].Weshowtherenderednormalmapsfromextractmeshes
togetherwithGTimagesforreference.SuGaR’smeshisnoisy[GuédonandLepetit2023]and2DGSfailsatreconstructingbackgroundregions[Huangetal.
2024].Incontrast,ourmethodcanreconstructdetailedsurfacesforbothforegroundobjectsandbackgroundregions.
Table2. QuantitativecomparisonontheDTUDataset[Jensenetal.2014].WeshowtheChamferdistanceandaverageoptimizationtime.Ourmethod
achievesthehighestreconstructionaccuracyamongotherexplicitmethods.
24 37 40 55 63 65 69 83 97 105 106 110 114 118 122 Mean Time
NeRF[Mildenhalletal.2021] 1.90 1.60 1.85 0.58 2.28 1.27 1.47 1.67 2.05 1.07 0.88 2.53 1.06 1.15 0.96 1.49 >12h
VolSDF[Yarivetal.2021] 1.14 1.26 0.81 0.49 1.25 0.70 0.72 1.29 1.18 0.70 0.66 1.08 0.42 0.61 0.55 0.86 >12h
NeuS[Wangetal.2021] 1.00 1.37 0.93 0.43 1.10 0.65 0.57 1.48 1.09 0.83 0.52 1.20 0.35 0.49 0.54 0.84 >12h
Neuralangelo[Lietal.2023] 0.37 0.72 0.35 0.35 0.87 0.54 0.53 1.29 0.97 0.73 0.47 0.74 0.32 0.41 0.43 0.61 >12h
3DGS[Kerbletal.2023] 2.14 1.53 2.08 1.68 3.49 2.21 1.43 2.07 2.22 1.75 1.79 2.55 1.53 1.52 1.50 1.96 11.2m
SuGaR[GuédonandLepetit2023] 1.47 1.33 1.13 0.61 2.25 1.71 1.15 1.63 1.62 1.07 0.79 2.45 0.98 0.88 0.79 1.33 ∼1h
2DGS[Huangetal.2024] 0.48 0.91 0.39 0.39 1.01 0.83 0.81 1.36 1.27 0.76 0.70 1.40 0.40 0.76 0.52 0.80 18.8m
Ours 0.50 0.82 0.37 0.37 1.12 0.74 0.73 1.18 1.29 0.68 0.77 0.90 0.42 0.66 0.49 0.74 30m
etal.2023],GOF’soptimizationismuchfaster.Thisperformance Table3. QuantitativeresultsonMip-NeRF360[Barronetal.2022b]
disparityisattributedtotheDTUdataset’sstrongview-dependent
dataset.OurmethodachievedSOTANVSresults,especiallyintheoutdoor
scenesintermsofLPIPS.
appearance.Utilizingabetterview-dependentappearancemodel-
ing[Verbinetal.2022]oracoarse-to-finetrainingstrategy[Lietal.
OutdoorScene Indoorscene
2023]couldpotentiallyimprovethereconstructions.
PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LIPPS↓
NeRF 21.46 0.458 0.515 26.84 0.790 0.370
DeepBlending 21.54 0.524 0.364 26.40 0.844 0.261
4.3 NovelviewSynthesis
InstantNGP 22.90 0.566 0.371 29.15 0.880 0.216
ToevaluatetheNVSresultsofGOF,wefurthercompareagainst MERF 23.19 0.616 0.343 27.80 0.855 0.271
SOTANVSmethodsontheMip-NeRFdataset[Barronetal.2022a]. MipNeRF360 24.47 0.691 0.283 31.72 0.917 0.180
ThequantitativeresultsareshowninTable3.GOFnotonlyper- Mobile-NeRF 21.95 0.470 0.470 - - -
formsslightlybetterthanallother3DGS-basedmethodsinterms BakedSDF 22.47 0.585 0.349 27.06 0.836 0.258
SuGaR 22.93 0.629 0.356 29.43 0.906 0.225
ofPSNR,itoutperformsallothermethodssignificantlyinterms
BOG 23.94 0.680 0.263 27.71 0873 0.227
ofLPIPS[Zhangetal.2018]intheoutdoorscenes.Themainim-
3DGS 24.64 0.731 0.234 30.41 0.920 0.189
provementscomefromourimproveddensificationstrategy.Inthe
Mip-Splatting 24.65 0.729 0.245 30.90 0.921 0.194
supplementarymaterial,weshowthataddingourdensificationstrat- 2DGS 24.21 0.709 0.276 30.10 0.913 0.211
egyto3DGS[Kerbletal.2023]andMip-Splatting[Yuetal.2024a] Ours 24.82 0.750 0.202 30.79 0.924 0.184
improvestheNVSresultsbyalargemargin.Fortheindoorscenes,
ourresultsaresimilartoMip-Splatting[Yuetal.2024a],withless
than0.1PSNRdifference,whichweattributetoourregularization, outperformsSugar[GuédonandLepetit2023]and2DGS[Huang
whichtradesoffNVSandsurfacereconstruction.Ourmethodalso et al. 2024] in all metrics. We show a qualitative comparison of
ticilpmi
ticilpxeGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes • 7
SuGar[GuédonandLepetit2023] 2DGS[Huangetal.2024] Ours GT
Fig.5. ReconstructionsontheMip-NeRF360Dataset[Barronetal.2022a].WeshowtherenderednormalmapsfromextractmeshestogetherwithGT
imagesforreference.Ourmethodcanreconstructdetailedsurfacesforbothforegroundobjectsandbackgroundregionswhilemeshesfrompreviousworkare
noisy[GuédonandLepetit2023]orfailtoreconstructbackgroundregionsandthinstructures,suchasthespokesinthebicyclescene[Huangetal.2024].
SOTA3DGS-basedmodel,Mip-Splatting[Yuetal.2024a]andcom-
pareitwithTSDFfusion.Acomparisonoftheextractedmeshesis
showninFigure6.ThemeshextractedfromTSDFfusionisnoisyand
hasalotofholesontheground,duetotheinconsistencyofdepth.
Mip-Splatting+TSDFFusion Mip-Splatting+GOF GTImage Bycontrast,ourextractedmeshismorecomplete.Ourmethodalso
Fig.6. Comparisonofmeshextractionmethods.ApplyingGOFtoSOTA extractsdetailedsurfacesforthebackgroundregions.Resultsin
Mip-Splatting[Yuetal.2024a]yieldssignificantimprovementsoverTSDF, Table4(Avs.BandCvs.F)furtherindicatetheeffectivenessofour
enablingcompletemeshextractionforbackgroundregions. method.
RegularizationandAppearanceModeling:AsshowninTable4
Table4. AblationonTNTDataset.GOFsignificantlyimprovessurface
(Dvs.F),usingthenormalregularizationduringtrainingsignifi-
extractionqualityandourregularizationanddecoupledappearancemodel-
cantlyimprovesreconstructionquality,whichisconsistentwiththe
ingfurtherimprovetheresults.
observationin2DGS[Huangetal.2024].Includingthedecoupled
Precision↑ Recall↑ F-score↑ appearancemodeling[Linetal.2024]furtherimprovestherecon-
A.Mip-Splattingw/TSDF 0.15 0.25 0.16 structionresultsasshowninTable4(Evs.F),sincethemodelis
B.Mip-Splattingw/GOF 0.40 0.33 0.36
lesslikelytomodelview-dependentappearancewithgeometry.
C.Oursw/oGOF 0.37 0.45 0.39
D.Oursw/onormalconsistency 0.41 0.35 0.37
E.Oursw/odecoupledappearance 0.49 0.39 0.43
F.Ours 0.54 0.42 0.46 5 CONCLUSION
WehavepresentedGaussianOpacityFields(GOF),anovelmethod
forefficient,high-quality,andcompactsurfacereconstructionin
extractedmeshesinFigure5.Similartoourobservationsonthe
unboundedscenes.OurGOFisderivedfromray-tracing-basedvol-
TanksandTemplesdataset[Knapitschetal.2017],GOFisableto
umerenderingof3DGaussians,maintainingconsistencywithRGB
reconstructdetailedsurfacesforbothforegroundobjectsandback-
rendering.OurGOFenablesgeometryextractiondirectlyfrom3D
groundregions,whileSuGaR’s[GuédonandLepetit2023]meshis
Gaussiansbyidentifyingitslevelset,withoutPoissonreconstruc-
noisyandhasfewerdetailsand2DGS’sfailstoextractmeshesfor
tion or TSDF. We approximate the surface normal of Gaussians
thebackgroundregions.
as the normal of the ray-Gaussian intersection plane and apply
depth-normalconsistencyregularizationtoenhancegeometryre-
4.4 AblationStudy
constructions.Furthermore,weproposeanefficientandcompact
MeshExtraction:OurGOFenablesmeshextractionfrom3DGaus- meshextractionmethodutilizingmarchingtetrahedra,wherethe
siansdirectlybyidentifyingalevelsetwithoutresortingtoPoisson tetrahedralgridsareinducedfrom3DGaussians.Ourevaluations
reconstructionorTSDFfusion.Todemonstratetheeffectiveness revealthatGOFsurpassesexistingmethodsinbothsurfacerecon-
andgeneralizabilityofourmeshextractionstrategy,weapplyittoa structionandnovelviewsynthesisinunboundedscenes.8 • ZehaoYu,TorstenSattler,andAndreasGeiger
Acknowledgement:WethankChristianReiserforinsightfuldis- Graphics36,4(2017).
cussionsandvaluablefeedbackthroughouttheproject.Wealso JonasKulhanekandTorstenSattler.2023.Tetra-NeRF:RepresentingNeuralRadiance
thankBinbinHuangforproofreading.ZYandAGaresupportedby
FieldsUsingTetrahedra.arXivpreprintarXiv:2304.09987(2023).
KiriakosNKutulakosandStevenMSeitz.2000.Atheoryofshapebyspacecarving.
theERCStartingGrantLEGO-3D(850533)andDFGEXCnumber Internationaljournalofcomputervision38(2000),199–218.
2064/1-projectnumber390727645.TSissupportedbyaCzech AldoLaurentini.1994.Thevisualhullconceptforsilhouette-basedimageunderstanding.
IEEETransactionsonpatternanalysisandmachineintelligence16,2(1994),150–162.
ScienceFoundation(GACR)EXPROgrant(UNI-3D,grantno.23- MarcLevoy.1990.Efficientraytracingofvolumedata.ACMTransactionsonGraphics
07973X). (TOG)9,3(1990),245–261.
ZhaoshuoLi,ThomasMüller,AlexEvans,RussellHTaylor,MathiasUnberath,Ming-
YuLiu,andChen-HsuanLin.2023. Neuralangelo:High-FidelityNeuralSurface
REFERENCES Reconstruction.InIEEEConferenceonComputerVisionandPatternRecognition
(CVPR).
JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman. JiaqiLin,ZhihaoLi,XiaoTang,JianzhuangLiu,ShiyongLiu,JiayueLiu,YangdiLu,
2022a.Mip-NeRF360:UnboundedAnti-AliasedNeuralRadianceFields.CVPR(2022). XiaofeiWu,SongcenXu,YouliangYan,andWenmingYang.2024.VastGaussian:
JonathanTBarron,BenMildenhall,DorVerbin,PratulPSrinivasan,andPeterHedman. Vast3DGaussiansforLargeSceneReconstruction.InConferenceonComputerVision
2022b.Mip-nerf360:Unboundedanti-aliasedneuralradiancefields.InProceedings andPatternRecognition(CVPR).
oftheIEEE/CVFConferenceonComputerVisionandPatternRecognition.5470–5479. WilliamELorensenandHarveyECline.1998.Marchingcubes:Ahighresolution3D
JonathanT.Barron,BenMildenhall,DorVerbin,PratulP.Srinivasan,andPeterHedman. surfaceconstructionalgorithm.InSeminalgraphics:pioneeringeffortsthatshaped
2023.Zip-NeRF:Anti-AliasedGrid-BasedNeuralRadianceFields.(2023). thefield.347–353.
AnpeiChen,ZexiangXu,AndreasGeiger,JingyiYu,andHaoSu.2022. TensoRF: NelsonMax.1995.Opticalmodelsfordirectvolumerendering.IEEETransactionson
TensorialRadianceFields.InEuropeanConferenceonComputerVision(ECCV). VisualizationandComputerGraphics1,2(1995),99–108.
GuikunChenandWenguanWang.2024. Asurveyon3dgaussiansplatting. arXiv LarsMescheder,MichaelOechsle,MichaelNiemeyer,SebastianNowozin,andAndreas
preprintarXiv:2401.03890(2024). Geiger.2019.OccupancyNetworks:Learning3DReconstructioninFunctionSpace.
HanlinChen,ChenLi,andGimHeeLee.2023b.NeuSG:NeuralImplicitSurfaceRe- InConferenceonComputerVisionandPatternRecognition(CVPR).
constructionwith3DGaussianSplattingGuidance.arXivpreprintarXiv:2312.00846 BenMildenhall,PratulP.Srinivasan,MatthewTancik,JonathanT.Barron,RaviRa-
(2023). mamoorthi,andRenNg.2020.NeRF:RepresentingScenesasNeuralRadianceFields
ZhiqinChen,ThomasFunkhouser,PeterHedman,andAndreaTagliasacchi.2023a. forViewSynthesis.InECCV.
Mobilenerf:Exploitingthepolygonrasterizationpipelineforefficientneuralfield BenMildenhall,PratulPSrinivasan,MatthewTancik,JonathanTBarron,RaviRa-
renderingonmobilearchitectures.InProceedingsoftheIEEE/CVFConferenceon mamoorthi,andRenNg.2021.Nerf:Representingscenesasneuralradiancefields
ComputerVisionandPatternRecognition.16569–16578. forviewsynthesis.Commun.ACM65,1(2021),99–106.
AkioDoiandAkioKoide.1991. Anefficientmethodoftriangulatingequi-valued ThomasMüller,AlexEvans,ChristophSchied,andAlexanderKeller.2022. Instant
surfacesbyusingtetrahedralcells. IEICETRANSACTIONSonInformationand NeuralGraphicsPrimitiveswithaMultiresolutionHashEncoding. ACMTrans.
Systems74,1(1991),214–224. Graph.41,4,Article102(July2022),15pages. https://doi.org/10.1145/3528223.
RobertADrebin,LorenCarpenter,andPatHanrahan.1988.Volumerendering.ACM 3530127
SiggraphComputerGraphics22,4(1988),65–74. MichaelOechsle,SongyouPeng,andAndreasGeiger.2021.UNISURF:UnifyingNeural
SaraFridovich-Keil,AlexYu,MatthewTancik,QinhongChen,BenjaminRecht,and ImplicitSurfacesandRadianceFieldsforMulti-ViewReconstruction.InInternational
AngjooKanazawa.2022.Plenoxels:RadianceFieldswithoutNeuralNetworks.In ConferenceonComputerVision(ICCV).
CVPR. JeongJoonPark,PeterFlorence,JulianStraub,RichardNewcombe,andStevenLove-
ClementFujiTsang,MariaShugrina,JeanFrancoisLafleche,TowakiTakikawa,Jiehan grove.2019.DeepSDF:LearningContinuousSignedDistanceFunctionsforShape
Wang,CharlesLoop,WenzhengChen,KrishnaMurthyJatavallabhula,Edward Representation.InTheIEEEConferenceonComputerVisionandPatternRecognition
Smith,ArtemRozantsev,OrPerel,TianchangShen,JunGao,SanjaFidler,Gavriel (CVPR).
State,JasonGorski,TommyXiang,JianingLi,MichaelLi,andRevLebaredian. Marie-JulieRakotosaona,FabianManhardt,DiegoMartinArroyo,MichaelNiemeyer,
2022. Kaolin:APytorchLibraryforAccelerating3DDeepLearningResearch. AbhijitKundu,andFedericoTombari.2024.NeRFMeshing:DistillingNeuralRa-
https://github.com/NVIDIAGameWorks/kaolin. dianceFieldsintoGeometrically-Accurate3DMeshes.InProc.oftheInternational
JianGao,ChunGu,YoutianLin,HaoZhu,XunCao,LiZhang,andYaoYao.2023.Re- Conf.on3DVision(3DV).
lightable3DGaussian:Real-timePointCloudRelightingwithBRDFDecomposition ChristianReiser,StephanGarbin,PratulP.Srinivasan,DorVerbin,RichardSzeliski,Ben
andRayTracing.arXiv:2311.16043(2023). Mildenhall,JonathanT.Barron,PeterHedman,andAndreasGeiger.2024.Binary
MichaelGarlandandPaulSHeckbert.1997.Surfacesimplificationusingquadricerror OpacityGrids:CapturingFineGeometricDetailforMesh-BasedViewSynthesis.
metrics.InProceedingsofthe24thannualconferenceonComputergraphicsand arXiv2402.12377(2024).
interactivetechniques.209–216. ChristianReiser,SongyouPeng,YiyiLiao,andAndreasGeiger.2021.KiloNeRF:Speed-
AntoineGuédonandVincentLepetit.2023.SuGaR:Surface-AlignedGaussianSplatting ingupNeuralRadianceFieldswithThousandsofTinyMLPs.InInternational
forEfficient3DMeshReconstructionandHigh-QualityMeshRendering. arXiv ConferenceonComputerVision(ICCV).
preprintarXiv:2311.12775(2023). ChristianReiser,RickSzeliski,DorVerbin,PratulSrinivasan,BenMildenhall,Andreas
PeterHedman,PratulPSrinivasan,BenMildenhall,JonathanTBarron,andPaulDe- Geiger,JonBarron,andPeterHedman.2023.Merf:Memory-efficientradiancefields
bevec.2021.Bakingneuralradiancefieldsforreal-timeviewsynthesis.InProceedings forreal-timeviewsynthesisinunboundedscenes.ACMTransactionsonGraphics
oftheIEEE/CVFInternationalConferenceonComputerVision.5875–5884. (TOG)42,4(2023),1–12.
BinbinHuang,ZehaoYu,AnpeiChen,AndreasGeiger,andShenghuaGao.2024.2D RaduAlexandruRosuandSvenBehnke.2023.PermutoSDF:FastMulti-ViewReconstruc-
GaussianSplattingforGeometricallyAccurateRadianceFields.arXiv2403.17888 tionwithImplicitSurfacesusingPermutohedralLattices.InIEEE/CVFConference
(2024). onComputerVisionandPatternRecognition(CVPR).
ClémentJamin,SylvainPion,andMoniqueTeillaud.2024. 3DTriangulationData JohannesLutzSchönberger,EnliangZheng,MarcPollefeys,andJan-MichaelFrahm.
Structure.InCGALUserandReferenceManual(5.6.1ed.).CGALEditorialBoard. 2016.PixelwiseViewSelectionforUnstructuredMulti-ViewStereo.InEuropean
https://doc.cgal.org/5.6.1/Manual/packages.html#PkgTDS3 ConferenceonComputerVision(ECCV).
RasmusJensen,AndersDahl,GeorgeVogiatzis,EnginTola,andHenrikAanæs.2014. TianchangShen,JunGao,KangxueYin,Ming-YuLiu,andSanjaFidler.2021. Deep
Largescalemulti-viewstereopsisevaluation.InProceedingsoftheIEEEconference MarchingTetrahedra:aHybridRepresentationforHigh-Resolution3DShapeSyn-
oncomputervisionandpatternrecognition.406–413. thesis.InAdvancesinNeuralInformationProcessingSystems(NeurIPS).
JamesTKajiyaandBrianPVonHerzen.1984. Raytracingvolumedensities. ACM ChengSun,MinSun,andHwann-TzongChen.2022.DirectVoxelGridOptimization:
SIGGRAPHcomputergraphics18,3(1984),165–174. Super-fastConvergenceforRadianceFieldsReconstruction.
MichaelKazhdanandHuguesHoppe.2013.Screenedpoissonsurfacereconstruction. JiaxiangTang,HangZhou,XiaokangChen,TianshuHu,ErruiDing,JingdongWang,
ACMTransactionsonGraphics(ToG)32,3(2013),1–13. andGangZeng.2022.DelicateTexturedMeshRecoveryfromNeRFviaAdaptive
BernhardKerbl,GeorgiosKopanas,ThomasLeimkühler,andGeorgeDrettakis.2023. SurfaceRefinement.arXivpreprintarXiv:2303.02091(2022).
3DGaussianSplattingforReal-TimeRadianceFieldRendering.ACMTransactionson MatiasTurkulainen,XuqianRen,IaroslavMelekhov,OttoSeiskari,EsaRahtu,andJuho
Graphics42,4(July2023).https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/ Kannala.2024.DN-Splatter:DepthandNormalPriorsforGaussianSplattingand
LeonidKeselmanandMartialHebert.2022. ApproximateDifferentiableRendering Meshing.arXiv2403.17822(2024).
withAlgebraicSurfaces.InEuropeanConferenceonComputerVision(ECCV). DorVerbin,PeterHedman,BenMildenhall,ToddZickler,JonathanT.Barron,and
ArnoKnapitsch,JaesikPark,Qian-YiZhou,andVladlenKoltun.2017. Tanksand PratulP.Srinivasan.2022.Ref-NeRF:StructuredView-DependentAppearancefor
Temples:BenchmarkingLarge-ScaleSceneReconstruction.ACMTransactionsonGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes • 9
NeuralRadianceFields.CVPR(2022).
PengWang,LingjieLiu,YuanLiu,ChristianTheobalt,TakuKomura,andWenping
Wang.2021. NeuS:LearningNeuralImplicitSurfacesbyVolumeRenderingfor
Multi-viewReconstruction.AdvancesinNeuralInformationProcessingSystems34
(2021),27171–27183.
YaoYao,ZixinLuo,ShiweiLi,TianFang,andLongQuan.2018. MVSNet:Depth
InferenceforUnstructuredMulti-viewStereo.EuropeanConferenceonComputer
Vision(ECCV)(2018).
LiorYariv,JiataoGu,YoniKasten,andYaronLipman.2021.Volumerenderingofneural
implicitsurfaces. AdvancesinNeuralInformationProcessingSystems34(2021),
4805–4815.
LiorYariv,PeterHedman,ChristianReiser,DorVerbin,PratulP.Srinivasan,Richard
Szeliski,JonathanT.Barron,andBenMildenhall.2023.BakedSDF:MeshingNeural
SDFsforReal-TimeViewSynthesis.arXiv(2023).
MulinYu,TaoLu,LinningXu,LihanJiang,YuanboXiangli,andBoDai.2024b.GSDF:
3DGSMeetsSDFforImprovedRenderingandReconstruction.arXiv2403.16964
(2024).
ZehaoYu,AnpeiChen,BozidarAntic,SongyouPeng,ApratimBhattacharyya,Michael
Niemeyer,SiyuTang,TorstenSattler,andAndreasGeiger.2022a.SDFStudio:AUni-
fiedFrameworkforSurfaceReconstruction. https://github.com/autonomousvision/
sdfstudio
ZehaoYu,AnpeiChen,BinbinHuang,TorstenSattler,andAndreasGeiger.2024a.
Mip-Splatting:Alias-free3DGaussianSplatting.ConferenceonComputerVisionand
PatternRecognition(CVPR)(2024).
ZehaoYuandShenghuaGao.2020.Fast-MVSNet:Sparse-to-DenseMulti-ViewStereo
WithLearnedPropagationandGauss-NewtonRefinement.InConferenceonCom-
puterVisionandPatternRecognition(CVPR).
ZehaoYu,SongyouPeng,MichaelNiemeyer,TorstenSattler,andAndreasGeiger.
2022b.MonoSDF:ExploringMonocularGeometricCuesforNeuralImplicitSurface
Reconstruction.AdvancesinNeuralInformationProcessingSystems(NeurIPS)(2022).
KaiZhang,GernotRiegler,NoahSnavely,andVladlenKoltun.2020.NeRF++:Analyzing
andImprovingNeuralRadianceFields.arXiv:2010.07492(2020).
RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.2018.
TheUnreasonableEffectivenessofDeepFeaturesasaPerceptualMetric.InCVPR.
HongyuZhou,JiahaoShao,LuXu,DongfengBai,WeichaoQiu,BingbingLiu,YueWang,
AndreasGeiger,andYiyiLiao.2024.HUGS:HolisticUrban3DSceneUnderstanding
viaGaussianSplatting.arXivpreprintarXiv:2403.12722(2024).
MatthiasZwicker,HanspeterPfister,JeroenVanBaar,andMarkusGross.2001.EWA
volumesplatting.InProceedingsVisualization,2001.VIS’01.IEEE,29–538.10 • ZehaoYu,TorstenSattler,andAndreasGeiger
Table5. QuantitativeresultsonMip-NeRF360[Barronetal.2022b] ourMarchingTetrahedraaugmentedwithbinarysearchisshownin
dataset.OurdensificationstrategyimprovetheNVSresultssignificantly.
Algorithm3,thesameideacouldbeappliedtotheMarchingCubes
algorithm.
OutdoorScene Indoorscene
PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LIPPS↓
3DGS[Kerbletal.2023] 24.64 0.731 0.234 30.41 0.920 0.189 Algorithm1GaussianOpacityFieldevaluation
3DGSwithourdensification 24.62 0.743 0.199 31.10 0.928 0.174
Mip-Splatting[Yuetal.2024a] 24.65 0.729 0.245 30.90 0.921 0.194
𝑀,𝑆,𝐴:Gaussianmeans,covariances,andopacity
Mip-Splattingwithourdensification 24.77 0.745 0.205 31.18 0.926 0.180 𝑃:positionofpoints
𝑉:viewconfigurations
6 DENSIFICATION functionEvaluateOpacityField(𝑀,𝑆,𝐴,𝑉,𝑃)
Inthissection,wedescribeourmodificationsto3DGS’sdensification 𝑂 ←1 ⊲InitOpacity
strategy to overcome the over-blur regions in Gaussian density forallViews𝑣in𝑉 do
controlandclusteredissuesresultingfromcloneoperation. 𝑤,ℎ←GetImageSize(𝑉)
DensificationMetric:In3DGS[Kerbletal.2023],thedensifica-
𝑂
𝑣
←EvaluateSingleView(𝑤,ℎ,𝑀,𝑆,𝐴,𝑉,𝑃)
tionofaGaussian(eitherbycloningorsplitting)isguidedbythe
𝑂 ←Min(𝑂,𝑂 𝑣) ⊲TakeMinimalOpacity
magnitudeoftheview-spacepositiongradient 𝑑 𝑑𝐿 x,wherexisthe en red tufo rnr
𝑂
centerofprojectedGaussians.Specifically,𝑑𝐿 sumsoverpixelsthat
𝑑x endfunction
theGaussiancontributedto:
𝑑𝐿 ∑︁ 𝑑𝐿 𝑑p𝑖
= (14)
𝑑x
𝑖
𝑑p𝑖 𝑑x
Algorithm2GaussianOpacityFieldevaluationforasingleview
Ifthenormofthegradient∥𝑑 𝑑𝐿 x∥2isaboveapredefinedthreshold 𝑤 𝑀, ,ℎ 𝑆: ,w 𝐴i :d Gth aua sn sd iah ne mig eh at no sf ,t cr oa vin arin iag ni cm esa ,g ae
ndopacity
𝜏 ,theGaussianischosenasthecandidatefordensification.
x
𝑃:positionofpoints
However, we found this metric is not effective in identifying
𝑉:viewconfigurationofcurrentcamera
overly blurred areas, due to its inability to distinguish between
well-reconstructedregionsandthosewherethegradientsignals functionEvaluateSingleView(𝑤,ℎ,𝑀,𝑆,𝐴,𝑉,𝑃)
fromdifferentpixelsnegateeachother,leadingtominimaloverall CullGaussian(𝑀,𝑉) ⊲FrustumCulling
gradientmagnitudes.Therefore,weproposeasimplemodification 𝑀′,𝑆′←ScreenspaceGaussians(𝑀,𝑆,𝑉) ⊲Transform
tothemetricthataccumulatesthenormsoftheindividualpixel 𝑇 𝑔←CreateTiles(𝑤,ℎ)
gradientsinstead: 𝐿 𝑔,𝐾 𝑔←DuplicateWithKeys(𝑀′,𝑇 𝑔) ⊲IndicesandKeys
𝑑𝐿′ ∑︁ 𝑑𝐿 𝑑p𝑖 SortByKeys(𝐾 𝑔,𝐿 𝑔) ⊲GloballySort
𝑑x
= ∥
𝑑p𝑖 𝑑x
∥2 (15) 𝑅 𝑔←IdentifyTileRanges(𝑇 𝑔,𝐾 𝑔)
𝑖 CullPoints(𝑃,𝑉) ⊲FrustumCulling
O stru ur cm tioet nri ec rr∥ o𝑑
𝑑
r𝐿
x
s.′ ∥2betterindicatesregionswithsignificantrecon- 𝑇𝑃 𝑝′← ←S Cc rr ee ae tn eTsp ila ec se (𝑤Po ,i ℎn )ts(𝑃,𝑉) ⊲Transform
Toevaluatetheeffectivenessofourimproveddensificationmetric, 𝐿 𝑝,𝐾 𝑝 ←CreateWithKeys(𝑃′,𝑇 𝑝) ⊲IndicesandKeys
weapplyitto3DGS[Kerbletal.2023]andMip-Splatting[Yuetal. SortByKeys(𝐾 𝑝,𝐿 𝑝) ⊲GloballySort
2024a].ThequantitativeresultsareshowninTable5andqualitative 𝑅 𝑝 ←IdentifyTileRanges(𝑇 𝑝,𝐾 𝑝)
comparisonsareshowninFigure7.OurstrategyimprovesNVS 𝑂 ←1 ⊲InitOpacity
resultssignificantly,especiallyintermsofLPIPS[Zhangetal.2018]. forallTiles𝑡 in𝐼 do ⊲𝐼 istheCanvas
forallPixels𝑖in𝑡 do
ClonewithSampling:WefoundthatthepositionofGaussianis
relativelystable,whichisalsoobservedinMip-Splatting[Yuetal.
𝑟
𝑔
←GetTileRange(𝑅 𝑔,𝑡)
2024a].Therefore,Gaussiansclonedfromthesameparentsremain
𝐿 𝑔′ ←FilterGaussians(𝑖,𝐿 𝑝,𝑟 𝑔,𝐾 𝑔,𝑀,𝑆,𝐴) ⊲Select
Gaussiansthatcontributestopixel𝑖
clustered.Toaddressthisissue,insteadofusingthesameposition
fortheclonedGaussian,wesampleanewGaussianaccordingto
𝑟
𝑝
←GetTileRange(𝑅 𝑝,𝑡)
theGaussian’sparametersimilartotheproceduresforGaussian
𝐿 𝑝′ ←FilterPoints(𝑖,𝐿 𝑝,𝑟 𝑝,𝐾 𝑝,𝑃)⊲SelectPointsthat
projectedtopixel𝑖
split[Kerbletal.2023].Wefoundthissimplestrategyleadstomore
uniformlydistributedGaussians,asshowninFigure8.
forallPoints𝑝in𝐿 𝑝′ do
𝑂[𝑝] ←EvaluateOpacity(𝑖,𝐿 𝑔′,𝐾 𝑔,𝑀,𝑆,𝐴)
7 DETAILSFORSURFACEEXTRACTION endfor
endfor
Weprovideapseudo-codeofourtile-basedGaussianOpacityField
endfor
evaluationinAlgorithm1andAlgorithm2.Notethattheevaluation
return𝑂
takes3DGaussians,trainingviews,and3Dpointsasinputandit
endfunction
doesnotrelyonthetetrahedracells.Therefore,thesamealgorithm
alsoappliestotheMarchingCubesAlgorithm.Thepseudo-codeofGaussianOpacityFields:EfficientandCompactSurfaceReconstructioninUnboundedScenes • 11
3DGS[Kerbletal.2023] 3DGS+OurDensification Mip-Splatting[Yuetal.2024a] Mip-Splatting+OurDensification
Fig.7. ComparisonofdensificationstrategyontheMip-NeRF360Dataset[Barronetal.2022a].Applyingourdensificationto3DGS[Kerbletal.
2023]andMip-Splatting[Yuetal.2024a]significantimprovetheNVSresults.Pleasenotethattheglassregionsareblurinboth3DGSandMip-Splatting,
whileourmethodrendertheimagefaithfully.
3DGS[Kerbletal.2023] Ours 3DGS Ours[Kerbletal.2023]
Fig.8. ComparisonofclonestrategyontheMip-NeRF360Dataset[Barronetal.2022a].Ourclonestrategyleadstomoreuniformlydistributed
Gaussianprimitives.
Algorithm3MarchingTetrahedrawithBinarySearch Thisprocesscouldpotentiallybeoptimizedbyconsideringthespa-
𝑀,𝑆,𝐴:Gaussianmeans,covariances,andopacity tiallocalitysincethepointsaregeneratedfrom3DGaussians,orby
𝑃,𝐶:TetrahedraPointsandCells employingparallelprocessingtechniquesonGPUs.Additionally,
𝑉:viewconfigurations optimizingtheselectionandnumberofGaussianprimitivesused
𝐿:Levelsetvalue forconstructingtetrahedralgridscouldfurtherimproveefficiency.
𝑁:Stepofbinarysearch
OpacityEvaluationOptimization:Duringthebinarysearchof
functionMarchingTetrahedraBinarySearch(𝑀,𝑆,𝐴,𝑃,𝐶, marchingtetrahedra,ourmethodevaluatestheopacityofpoints
𝑉) usingalltrainingviews,whichmayleadtoredundantcomputations.
𝑂 ←EvaluateOpacityField(𝑀,𝑆,𝐴,𝑉,𝑃) Recognizingthatasingleviewcandetermineapoint’sminimal
𝐹,𝑃1,𝑃2,𝑂1,𝑂2←MarchingTetrahedra(𝑃,𝐶,𝑂,𝑆) opacityvaluesuggestsamoreefficientapproachcouldbedeveloped
foralli𝑣in{1,2,...,𝑁}do byassociatingpointswiththeirrespectiveinfluentialtrainingviews.
𝑃 𝑚 ←MidPoint(𝑃1,𝑃2) ViewDependentAppearanceModeling:Usingsphericalhar-
𝑂 𝑚 ←EvaluateOpacityField(𝑀,𝑆,𝐴,𝑉,𝑃 𝑚) monicsforview-dependentappearancemodelinghaslimitations,
𝑃1,𝑃2,𝑂1,𝑂2←ChangeEndPointsAndValues(𝑃1,𝑃2,𝑂1, such as potentially inaccurately representing reflections as geo-
𝑂2,𝐿,𝑃 𝑚,𝑂 𝑚) metricfeatures.Incorporatingabetterview-dependentappearance
endfor model[Verbinetal.2022]couldenhancethequalityofreconstruc-
𝑉 ←LinearInterpolate(𝑃1,𝑃2,𝑂1,𝑂2,𝐿) tions.
return𝐹,𝑉 ⊲returnfacesandverticesfortrianglemesh
Mesh-basedRendering:WhilethecurrentfocusofGOFison
endfunction
surfacereconstructionandnovelviewsynthesis,leveragingthe
extractedmeshesforreal-timerenderingisaninterestingfuture
direction[Reiseretal.2024].Thiscouldpotentiallyimprovethe
8 LIMITATIONSANDFUTUREDIRECTIONS qualityofmesh-basedrenderinggiventhedetailedandcompact
Wenowdiscusssomelimitationsandpotentialfutureextensionsof meshesextractedwithGOF.
ourmethod.
9 MORERESULTS
DelaunayTriangulationEfficiency:WeemploytheCGALLi-
brary[Jaminetal.2024]forDelaunaytriangulationtoconstruct BinarySearchforMarchingTetrahedra:Todemonstratethe
tetrahedralcells,whichhas𝑂(𝑁log𝑁)complexity.Itbecomesa effectivenessofapplyingbinarysearchtomarchingtetrahedra[Shen
bottleneckparticularlywhenthenumberofpointsincreases.For etal.2021],weapplybinarysearchwithdifferentnumbersofsteps.
example,ittakesaround8minutestoconstructthetetrahedralcells AsshowninFigure9,usingbinarysearchsignificantlyimproves
forthebicyclesceneintheMip-NeRFdataset[Barronetal.2022a]. thequalityofreconstructedmeshesinjustafewiterations.12 • ZehaoYu,TorstenSattler,andAndreasGeiger
Step0 Step1 Step3 Step7 GTImage
Fig.9. DifferentnumberofbinarysearchstepswithmarchingtetrahedraontheDTUdataset[Jensenetal.2014].Applyingourbinarysearchto
MarchingTetrahedra[Shenetal.2021]significantlyimprovethequalityofextractedmeshesinjustfewsteps.
0.1 0.3 0.5 0.7 0.9
Fig.10. MeshesextractedwithdifferentlevelsetsontheMip-NeRF360dataset[Barronetal.2022a].Ourmethodssupportsmulti-layermeshes
extractionbyusingdifferentlevelsetsformarchingtetrahedra.
Multi-layerMeshes:Whileweextractmeshesforthe0.5level-set levelsets0.1,0.3,0.5,0.7,and0.9andshowtherenderedmeshesin
inthemainpaper,ourmethodalsosupportsextractingmesheswith Figure10.Finerstructurecanbeextractedwithasmallerlevelset,
levelsets.Asaproofofconcept,weextractmesheswithdifferent butitmightresultinexpandedmeshes.