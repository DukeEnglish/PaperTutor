Attention-Aware Visualization: Tracking and Responding to User
Perception Over Time
ArvindSrinivasan∗ ,JohannesEllemose∗ ,PeterW.S.Butcher ,PanagiotisD.Ritsos ,NiklasElmqvist
Fig.1:Attention-awarevisualization.Ourworkproposestracking,recording,andrevisualizingauser’sattentiononavisualizationto
aidtheminunderstandingwhattheyhaveseenandnotseen,aswellascausethevisualizationtorespondtotheuser’sgaze.Ourtwo
implementations—3Dand2D,respectively—makeuseoftheheaddirectionofaMetaQuest3orsimilarXRHMD,themousepointer,
oranembodiedeye-trackertomeasuretheuser’sgazeonthevisualization. Wealsopresentseveralmethodsforrevisualization,
includingheatmapsandcontourplotsoverlaidonthechart,orcompactvisualizationsontheborderoftheviewport.
Abstract—Weproposethenotionofattention-awarevisualizations(AAVs)thattracktheuser’sperceptionofavisualrepresentation
overtimeandfeedthisinformationbacktothevisualization.Suchcontextawarenessisparticularlyusefulforubiquitousandimmersive
analyticswhereknowingwhichembeddedvisualizationstheuserislookingatcanbeusedtomakevisualizationsreactappropriatelyto
theuser’sattention:forexample,byhighlightingdatatheuserhasnotyetseen.Wecanseparatetheapproachintothreecomponents:
(1)measuringtheuser’sgazeonavisualizationanditsparts;(2)trackingtheuser’sattentionovertime;and(3)reactivelymodifying
thevisualrepresentationbasedonthecurrentattentionmetric. Inthispaper,wepresenttwoseparateimplementationsofAAV:a
2Ddata-agnosticmethodforweb-basedvisualizationsthatcanuseanembodiedeyetrackertocapturetheuser’sgaze,anda3D
data-awareonethatusesthestencilbuffertotrackthevisibilityofeachindividualmarkinavisualization.Bothmethodsprovidesimilar
mechanismsforaccumulatingattentionovertimeandchangingtheappearanceofmarksinresponse.Wealsopresentresultsfroma
qualitativeevaluationstudyingvisualfeedbackandtriggeringmechanismsforcapturingandrevisualizingattention.
IndexTerms—Attentiontracking,eyetracking,immersiveanalytics,ubiquitousanalytics,post-WIMPinteraction.
1 INTRODUCTION tions(AAVs):contextuallyawarevisualrepresentationsthattrackuser
attentionontheirsurfaceovertimeandmodifytheirvisualattributes
Theartandscienceofvisualizationdesignisprimarilyguidedbya
accordingly.Conceptually,thisapproachconsistsofthreelogicalsteps:
plethoraofprinciplesandguidelines—someempiricallyvalidated,oth-
ersmoreanecdotal—inthepursuitofcraftingvisualrepresentations
1. Measuringuserattentiononavisualizationanditsmarks.This
that are not only expressive and effective [28,30] but also visually
could be as simple as estimating attention based on the scroll
salient[25,29].Thisextensivebodyofknowledgespansboththeprac-
locationormousecursor[51],theuser’sheadorientation,ortheir
ticalrealmofvisualizationpractitionersandtheburgeoningacademic
exactgazelocationusinganeyetracker.
discipline. However,thesevisualizationdesignprinciplesprimarily
focusoncreatingstaticvisualartifactsthatonlyrespondtodirectuser 2. Recordingattentionovertimeastheuser’sperceptionmoves
interaction,suchasexplicitclicksandtaps.Whatifwecouldtranscend overthevisualization. Thisalsoincludesmodelingtheuser’s
thispassiveparadigmtodesignvisualizationsthatactivelyengagewith short-termmemoryasattentionsmoothlydecayingovertime.
theviewer’sattention?Imaginevisualizationsimbuedwiththecapa-
bilitytotrackandrespondtotheviewer’sgaze,dynamicallyadapting 3. Modifyingthevisualizationinresponsetouserattention.This
theirvisualattributesinrealtimetooptimallyconveythedata. couldbeusedasadiagnostic—allowingtheusertoseewhichpart
Inthispaper,weintroducetheconceptofattention-awarevisualiza- ofvisualizationtheyhavesurveyedandwhichtheyhavenot—or
asasubtlevisualcueforreadwear[22].
* Equalcontribution. Thecontributionsofthispaperareasfollows: (1)theconceptof
• ArvindSrinivasan,JohannesEllemose,andNiklasElmqvistarewithAarhus attention-awarevisualizationasacontext-aware[39]methodforcre-
UniversityinAarhus,Denmark.E-mail:{arvind,ellemose,elm}@cs.au.dk. atingvisualizationsresponsivetoimplicitgazeandnotjustexplicit
• PeterW.S.ButcherandPanagiotisRitsosarewithBangorUniversity, interaction;(2)alibraryimplementingattention-awarenessfor2Dvi-
Bangor,UnitedKingdom.E-mail:{p.butcher,p.ritsos}@bangor.ac.uk. sualizationsbasedonnumericintegration;(3)animplementationof
attention-awarenessandocclusion[16]for3Dvisualizationsusingthe
Manuscriptreceivedxxxxx.201x;acceptedxxxxx.201x.DateofPublication
stencilbuffer;and(4)resultsfromauserstudyinvestigatingtheutility
xxxxx.201x;dateofcurrentversionxxxxx.201x.Forinformationon
oftheapproachforboth2D(eye-tracker)and3Dsettings(XRHMD).1
obtainingreprintsofthisarticle,pleasesende-mailto:reprints@ieee.org.
DigitalObjectIdentifier:xx.xxxx/TVCG.201x.xxxxxxx
1ResearchmaterialsavailableonOSF:https://osf.io/8mfhp/
4202
rpA
61
]CH.sc[
1v23701.4042:viXra2 BACKGROUND priorworkoneyetrackingandproposeanovelapproachofcreatinga
virtualeyetrackerthatproducesgazeheatmapsusingdeeplearning.
Inthissectionwediscussourinspirationsfrompriorresearchforthis
Anothertakeonvisualizationandeyetrackingistheuseofvisu-
work,whichincludefundamentalconceptssuchascontextawareness,
alizationforeyetrackingdata. Blaschecketal.provideasomewhat
low-levelaspectsofattentioninvisualization,eyetrackingasameasure
datedsurveyonthispracticefrom2014[8].Notableexamplesinclude
ofattentionindatavisualization,andtheuseofgazeforinteractionin
Tsangetal.’sapproachforvisualizingfixationsequences[45],Alam
generalHCIsystems.Notethatinthispaperwedonotconsideratten-
andJianu[3]usevisualizationtoconnectgazepatternswithvisual
tionandawarenessbeyondtheindividual[20],suchasforcollaboration,
elementsonascreen,andtheVETAsystem[18]combineseyetracking
territoriality,andconflictmanagementingroupwork.
visualizationwithvideooftheunderlyingscene.Ourworkinthispaper
2.1 ContextAwareness bothuseseyetracking(inadditiontootheruserinput,suchastouch
eventsandmouseactions)tocollectthecontextfromtheuseraswellas
Oneoftheprimaryinspirationsforthisworkisthenotionofcontext-
visualizeattentioncollectedfromeyetrackingdataonavisualization.
aware(CA)systems[39]. CAsystemsmonitorandreacttoauser’s
Ourattention-awarevisualizationapproachbothbuildsonthispast
changingcontexttopromoteandmediatesaiduser’sinteractionwith
workandextendsitsignificantlybyusingtheeyetrackingdataasa
thesystemitself,aswellasothersystemsandusers.Thetermcontext
first-classinputchannelandnotmerelyadiagnostictool;morebelow.
isdefinedintheliteratureinseveralways[4],withthemostpopular
definitionfromDey[14,p.5],as“anyinformationthatcanbeused
2.4 GazeasInput
tocharacterizethesituationofanentity,”where“anentitycanbea
person,place,orobjectthatisconsideredrelevanttotheinteraction Theuseofgazeasamethodforcomputerinputismarkedbypioneering
betweenauserandanapplication,includingtheuserandapplications effortstoestablishitsviabilityandutility.Bolt[9]demonstratedoneof
themselves.”Moreimportantly,forthecontext(punintended)ofvisu- theearliestimplementations,showinghowdynamicwindowsystems
alizationexploredinthiswork,Dey[14,p.5]definesasystemasCA could be orchestrated through gaze. This foundational work led to
if“itusescontexttoproviderelevantinformationand/orservicesto followupefforts,includingWareandMikaelian[49],whoevaluated
theuser,whererelevancydependsontheuser’stask.” eyetrackingforcomputerinput,andJacob’sproposalofeyemovement-
Examplesof suchcontext rangefrom trackinglocation, environ- basedtechniquesthatlinkgazedirectionwithinterfacecontrol[24].
mentalfactors,usagepatterns,anduserbehavior.Suchcontext-aware Asgazetrackingtechnologymatured,researchersbeganexploring
systems are particularly central within the areas of mobile comput- itsintegrationwithotherinputmodalitiestocreatericher,morenuanced
ing[5],theinternetofthings[33],augmentedreality[19],andwear- interactionparadigms.Zhaietal.’sMAGICpointing[53],Salvucciand
ableubiquitouscomputing[1,50].Thisincludesubiquitous[15]and Anderson’sgaze-addedinterfaces[38],andFonoandVertegaal’sEye-
immersive/situatedanalytics[40],whichiswhyweexplorecontext Windows[17]eachcontributetothisdomainbycascadinggazewith
awarenessasaconceptinboth2Dand3Dinthispaper. manualinputstostreamlineselectiontasksandmanagefocuswithin
interfaces.Pfeufferetal.introducedgaze-touchin2014[34],combin-
2.2 AttentioninVisualization inggazewithmulti-touchonthesamesurfaceandtherebyillustrating
thesynergisticpotentialofgazewithotherinteractiontechniques.
Thehumanperceptualandcognitivesystemsgenerateawealthofinfor-
Thelastdecadehasseensignificantadvancementsingaze-supported
mationinrealtime,allofwhichcannotbeprocessedsimultaneously.
multimodalinteractions,particularlyforexploringlargedatasetsand
Attentionistheselectiveconcentrationofmentalawarenessonasubset
improvingtargetacquisition.
ofthisinformation,excludingtheremaininginformation[44]. Early
Stellmachetal.[43]andStellmachandDachselt[42]exploredgaze-
workoncognitiveprocessesinattentionnotedthatforhighlycomplex
supportedinteractionsforlargeimagecollectionexplorationandtarget
attentiveprocesses—suchasvisualsearch—tobepossible,theymust
beorganizedinbothlow-levelparallel—socalledpre-attentive—and acquisition,respectively.
complexserial—attentive—processes[23,31].Whilesubsequentwork Turneretal.[46], Pfeufferetal.[34,35], andVellosoetal.[47]
hascriticizedtheexistenceofacleardivisionbetweenpre-attentiveness furtherinvestigatedtheintegrationofgazewithtouchandmid-airges-
andattentiveness[52],itremainsausefulconstructforunderstanding tures,demonstratingthepotentialforseamlessandefficientinteractions
operationalaspectsofhumanperceptionandattention. acrossdevicesandinterfaces.
Fordatavisualization,theworkbyHealeyetal.[21]hasbeeninstru- Pfeufferetal.’sworkoncombininggazewithpinchinteractions
mentalinunderstandingtheeffectiveuseofcolor,shape,andmotion invirtualreality[36]representsthelatestevolutionofthisresearch
inpreattentiveprocessingofcomplexvisualrepresentations. Colin direction,highlightingthegrowingsophisticationandbreadthofgaze-
Ware[48]emphasizethecognitivelimitsofvisualattentionandmem-
supportedinteractions.2
ory,andprovideguidelinesfordesigningmoreeffectivevisualizations Thisisalsotheresearchmostcloselyrelatedtoourattention-aware
thatcatertohumanperception.Severalspecializedtopicsrelatedtoat- visualizations,butourapproachislessconcernedwithdirectgazeinput
tentionhasbeenstudiedwithinthevisualizationfield,includingchange tocontrolaninterface,andmorewithretrospectiveanalysisofgaze
blindness[32],visualsalience[25,29],andtheuseofeyetrackingfor patternsovertime.
visualization.Wediscussthelatterinmoredetailnext.
3 DESIGN: ATTENTION-AWAREVISUALIZATION
2.3 EyeTrackingforVisualization
Theintellectualcontributionproposedinthisworkistheconceptof
Eyetrackingisausefultoolforvisualizationresearchers[12];itcan attention-awarevisualizations(AAV):datavisualizationsthattrackthe
helpidentifyvisualexplorationbehaviors[13],assessperceptualand viewer’sattentionontheirsurfaceovertimeandreactaccordingly.We
cognitiveaspectsofengagingwithvisualizations[26], andevenbe seeseveralbenefitsofthisapproach,fromcreatingamoreresponsive
usedincombinationwithotherusabilitymetricstounderstanduser and engaging visual environment to showing data coverage, illumi-
behavior[7].ExamplesincludetheworkofBurchetal.[13]ontree- natingmissedoutliers,orevenpredictingattentionpatterns. Wecan
drawing perception, Alam et al. [2] on eye tracking analysis in the summarizeourapproachusingthefollowingresearchquestions:
dataspaceinsteadofthecommonlyusedimagespace,andPolatsek
etal.[37]onevaluationofsaliencemodelsforvisualanalysis. On RQ1 Howshouldaviewer’sattentiononavisualizationbemeasured
theotherhand,Kimetal.[26]assessthelimitationsofeyetrackers inrealtime?
ininformationvisualizationstudiesandfindthatincertainsituations
RQ2 Howshouldaviewer’sattentiononavisualizationberecorded
inferencesabouttheunderlyingcognitiveprocessesmaybemisleading.
overtime?
Kurzhalsetal.[27]presentasurveyofeyetrackingtechnologiesfor
theevaluationofvisualizationtechniques,identifyingfuturedirections 2Incidentally,gazeandpinchhasalsobeenadoptedbytheAppleVisionPro,
atthetimeofpublication.InmorerecentworkShinetal.[41]review makingitthefirstcommercialdeviceusingdedicatedgazeinteraction.RQ3 Howshouldavisualizationbemodifiedtodisplaytheviewer’s Data-agnostic. Sincewehavenoknowledgeoftheunderlying
attentionovertime? visualizationoritsdata,wecannotdirectlyassociateattentionwitha
specificmarkordataitem.Rather,thisapproachrequiressubdividing
Hereweproposeourdesignframeworkforattention-awarevisual-
thevisualspaceofthevisualizationintodiscretebins—typicallysquare
izationsthataddresseseachoftheseresearchquestionsinturn.
cellsonaregulargrid—thatwecanusetoaccumulateattentionover
time.Unfortunately,thislimitsourchancesofdetectingwhentheuser’s
attentionisdriftingbecausewecannotdetectsituationswhentheyare
Triggerless Explicit Triggers Implicit Triggers
fixatingonemptyspaceinavisualization.
Data-aware. Becausewecanassociatepointsonthevisualization
Always On Toggle with Activate with Activate at Activate on withvisualmarks,wecandirectlyaccumulateuserattentiononthese
hotkeys hotkeys intervals inactivity
marks(orevenpartsofmarks). Wecanalsodiscardattentionthatis
spentonemptypartsofavisualization—althoughwenaturallystill
Deactivate cannotreliablyunderstandwhentheuserisabsent-mindedlyviewing
Deactivate Deactivate after timeout
thevisualizationwithoutactuallyseeingit.
on timeout on timeout since last
inactivity
Representingattention. Eachattentiontarget—acellintheag-
nosticcaseoravisualmarkintheawarecase—canbeassignedan
Fig.2:Triggeringstrategies.Overviewofthedifferenttriggeringstrate-
attentionvaluethatstartsatzeroandthenaccumulatesforeverytime
giesforourattention-awarevisualizationinterventions.
unittheuser’sareaofattentionoverlapswiththecellormark.Ifmore
thanoneattentionmetricisactiveatthesametime—say,pointerand
gaze—then each target has two attention values. Finally, attention
3.1 MeasuringAttention
shouldbenormalizedorcappedacrosstheentirevisualizationsothat
Firstofall,whatisattention? AsdiscussedintheBackground(Sec-
viewingonetargetforalongtimewillnotovershadowallothertargets.
tion2),thereareseveralinterpretations.Fromacognitiveperspective,
attentionreferstotheselectivefocusingofmentalresourcesonspecific Attention decay. Peoplehavelimitedshort-memoriesandthus
informationorstimuli.Eventhoughthisviewencompassesallsenses, attentiondecaysovertime.Inotherwords,justbecauseapersonhas
wefocusonvisionheresincemostinteractivevisualizationsprimarily spentalongtimelookingataspecificsetofbarsinabarchartdoes
leveragethevisualsystem.Attention,then,determineswhichaspects notmeanthattheywillbeindeliblyfixedintheperson’smind.After
ofthevisualsceneareprioritizedformentalprocessing,guidingwhere awhilelookingatotherpartsofthechart,highattentionvaluesfor
andhowweallocateourvisualresources. specificattentiontargetsshoulddecaytowardszeroovertime.
Givenallthat,howshouldwemeasureit(RQ1)?Sinceitisapurely
3.3 RevisualizingAttention
cognitiveprocess,attentioncannotbemeasuredinitsownright—at
leastnotwithwidelyavailableequipment.However,dependingonthe Howdoweactuallyusetheaccumulatedattentionmetrictochangethe
contextwhenusingacomputingdevice,thereareseveralsituations visualization(RQ3)?Oneoptionistonotchangethevisualizationat
wheninteractionwiththedevicecanbeusedtomeasureattention: all,buttomerelyusethedataforevaluationpurposeswheretheviewers
themselvesdonoteverseeit.However,inthispaper,weareinterested
“ Tapsonatouchscreensignifiesaninterestinthatarea(ifthe
ininvestigatinghowthisdatacanbeutilizedbythevisualizationitself.
touchwasintentional); Wecallthisrevisualizingtheattentionontheoriginalvisualization.
W Pointermovementontheareasurroundingthepointeroritsdesti- Presentation. Thereareseveralpotentialmethodsofpresenting
nation(ifthepointerisbeinguseddeliberately);and theaccumulatedattentionmetric.Theydifferinhowinvasivetheyare
4 Eyemovementonthescreen(iftheuserisviewingthedevice tothetargetvisualization:
activelyandnotpreoccupiedbysomeothertask). ○ Marks:Modifytheoriginalmarkstoconveyattention;
We have experimented with all forms of attention measurement. (cid:9) Overlay:Visualizeattentiononanoverlayontopoftheview;
Theyallhavetheirparticularuses,especiallysincesomeofthemare
(cid:160) Border:Useviewbordertovisualizeattention;and
lessavailablethanothers.Forexample,eyemovementisindisputably
themostusefulmetric,butcapturingusergazerequiresadedicated , Minimap:Visualizeattentiononaseparatewindow.
eyetrackertoachievehighaccuracy,andthesearetypicallyexpensive
Therearemanyoptionsforthevisualrepresentationfortheattention
and not widely available. Mouse movement, on the other hand, is
metric. Theiravailabilitydependsvastlyonwhethertheapproachis
triviallyavailableonmostcomputingplatforms,butmaynotalwaysbe
data-agnostic or data-aware. For the former, the marks themselves
deliberate—anditcanbehardtodeterminewhenthisisthecase.
cannotbechangedsincewehavenoknowledgeoftheunderlyingvisu-
3.2 RecordingAttention alization.Instead,wehavetouseimageprocessingoperationsoncells
toconveythedata,suchascolortransforms(huerotate,desaturation,
Weassumeareliableattentionmeasurementmechanismthatreports
andluminance),blur,transparency,heatmaps,etc.Forthelatter,wecan
theuser’sattentiononavisualizationinrealtime.Wefurtherassume
modifythevisualattributesofthemarksusingobject-leveloperations.
thattheattentionfocusisaspecificpointintheuser’spointofvision,
presumablywithaspecificareasurroundingitandwithsomedegreeof Triggering. Finally,becausevisualizingattentionwhiletracking
uncertaintydependingonthemeasurementdevice(e.g.,anembodied attention easily becomes a circular and self-reinforcing system, we
eyetrackerbeingmuchmoreaccuratethanawebcam-basedeyetracker). mustbecarefultoconsiderwhenandhowtotriggerthesetechniques.
Now, howdowerecordthisattentionovertime(RQ2)? Atthis Figure2givesanoverviewofourproposedtriggeringstrategies. A
point,wecanidentifytwoseparateapproachestorecordingattention fullynaïvesolutionwouldbetriggerlessand“always-on,”bothforthe
dependingonwhetherwehaveknowledgeofthevisualizationornot: attentioncollectionaswellastherevisualization.However,thiswould
invariablymeanthatastherevisualizationupdatesinresponsetothe
• Data-agnostic:Wedonothavespecificknowledgeoftheunder-
user’sattention,thechangewilldrawtheuser’sattention,andsoon.
lyingdatainthevisualizationbeingtracked—inotherwords,we
Thiswillleadtoanunstableandpotentiallyconfusingdisplay.
donotknowwhatthepixelsofthevisualizationrepresent,only
Wefurtherdelineatetwoadditionalstrategies:explicitvs.implicit
thattheuser’sattentionismovingoverit;and
triggers. Theformerwouldrequireanexplicitactiontoactivateon
• Data-aware:Wehavespecificknowledgeofexactlywhatparts— behalfoftheuser;forexample,checkingaboxorpressingahotkey.
whatmarksrepresentingspecificdataitems—ofthevisualization Thishasthedisadvantagethatthetriggerisoutsidethemainworkflow
thattheuserisfocusingtheirattentionon. ofthevisualizationandmaythusbeforgottenandnevertriggered.Thelatterapproachwouldactivatenotbyuseraction,butbysomeexternal Finally,forIMPLICITtriggering,wedistinguishbetweentwoforms
implicitevent,suchasuserinactivity,regularintervals,orperhapsthe ofrevisualization:emphasisandde-emphasis.Whentheshort-termat-
presenceofconsistentlyoverlookedpartsofthedata.Itmakessense tentionforanentity(binormark)hasdecayedbelowalowerthreshold,
thatforboththesetriggers,attentiondatacollectionisdisabledwhile thismeansthatthereisariskthattheuserisnotseeingtheentity,so
thevisualizationisactivetopreventreinforcingloops. theemphasisrevisualizationisactivated.Analogously,whentheshort-
termattentionhasincreasedaboveanupperthreshold,thede-emphasis
4 IMPLEMENTINGATTENTION-AWAREVISUALIZATION revisualizationwillbeactivatedtodiscouragefurtherstudy.Oncethe
valuerisesabovethelowerordipsbelowtheupperthresholds, the
Wehaveimplementedtwoversionsoftheattention-awarevisualiza-
revisualizationisde-activated.Specificimplementationsmaychoose
tionmethod(Section3),onefor2Dsettingsusingthedata-agnostic
todisabletheemphasisorde-emphasisrevisualizationsasneeded.
approach,theotherfor3Dandthedata-awareapproach.Providingtwo
separateimplementationsenablesustoexploretwoquadrantsinthe
4.3 RevisualizingAttention
designspaceinTable1.Theothertwoquadrantsinthedesignspace
havenotbeenimplemented,buttheextensionshouldbetrivial. Finally,weuseacommonrevisualizationapproachforbothour2D
Atthecoreofthisendeavorliesacommonmodelformeasuring, and 3D implementations. Common between them is the use of a
recording,andrevisualizingattentionforbothimplementations.Inthis straightforwardheatmapwithaquantitativecolorscaletorevisualize
section,wedescribethiscommonmodel.Inthefollowingtwosections, attention.Furthermore,asdiscussedabove,thenotionofemphasisand
wedescribethe2Dand3Dimplementationsindetail,respectively. de-emphasisisusedforimplicittriggering,andissimilaracrossboth
implementations.Weusecolorsaturationasacommondenominator
for both: reducing saturation to de-emphasize and increasing it to
Table1:AAVimplementations.WeprovidetwoAAVimplementations;
emphasize. Inaddition,asdiscussedbelow,inthe2Dcasewealso
adata-agnosticonefor2D,andadata-awareonefor3D.
supportblurtode-emphasizeasegmentofavisualization.
Inthe3Dimplementation,weapplyallofourrevisualizationson
Data-agnostic Data-aware
the 3D scene itself; see Section 6 for detail. However, in the case
2D AAV2D(Section5) – ofthe2Dimplementation, thevisualizationsarenotimmersivebut
3D – AAV3D(Section6) bounded in 2D space, which allows us to revisualize attention also
outsidethevisualizationitself.Thishastheaddedbenefitofallowing
ustodisablecapturingattentionwhentheuser’sgazeisdirectedoutside
4.1 AttentionModel ofthevisualizationitself.SeeSection5formoredetails.
Drawing on Section 3, the common attention model underpinning
5 DATA-AGNOSTICAAVIN2D
bothofourimplementationsconceptualizesattentionasatransient,
ephemeralattributethatmirrorsthecharacteristicsofhumanshort-term AAV2Disour2Dimplementationofattention-awarevisualization.It
memory.Thismodelisbasedonmeasuringtheuser’sgazeatspecific isadata-agnosticJavaScriptpackagemadeavailableonnpm.Because
elementswithinthevisualization—whetherthesearediscretebinsin itisdata-agnostic,itcandecorateanygivenHTMLelementinaDOM
adata-agnosticapproach,ordistinctvisualmarks(representingdata and decorate it with attention capture and visualization. Below we
points)inadata-awareframework. Theattentionallocatedtothese discussattentioncapture,revisualizationmethods,andimplementation.
elementswillaccordinglyescalateataspecificrate. Theincrement
reflectstheelements’entryintotheviewer’sshort-termmemory,akin 5.1 AttentionCapture
tohowprolongedobservationmayenhancememorability. However, TheAAV2Dpackagemaintainsbothaglobalcumulativeandashort-
oncetheviewer’sgazeshiftsaway,themodeldictatesthatattention termcurrentattentionmap,asdescribedinSection4.1,intheformofa
diminishesatapredetermineddecayrate,analogoustothefadingof 2Dgridfittedtotheattachedelement.Thesizeofindividualgridcells
detailsfromshort-termmemory. canbecontrolledthroughprogramming-levelanduser-leveloptions;
Inpractice,ourmodelmanagestwoattentionmapsforthevisualiza- seebelow. TheAAV2Dpackageinstallsinputeventhandlersonthe
tion:(1)theglobalcumulativeattention,and(2)thecurrentshort-term element,includingbothmouseandeye-trackerevents(ifavailable).
attention. Foradata-awareimplementation, anattentionmapisan Thismakesitpossibletotracktheuser’sgazeormousepointerpo-
associativearrayrecordingattentionvalueperdatapoint.Foradata- sitionwheneveritmoveswithintheboundsoftheelement. Forboth
agnosticone,anattentionmapisaspatialdatastructure(2Dplanar approaches,theuser’sattentionpointistreatedlikethecenterofan
or3Dvolumetricgrid)recordingattentionperspatialcellinthevi- “attentioncircle,”andthepackageaccumulatesattentiontoallcells
sualizationsubstrate. Theglobalcumulativeattentionmapdoesnot intersectedbythiscircle.Attentiondataoutsidetheregionisignored.
decayovertime,butkeepstrackoftheattentionmeasureovertheentire This2Dgridemitseventsattheindividualcelllevel,enablingtheusers
lifecycleofthevisualization.Itisusedprimarilyasadiagnosticandis ofthislibrarytocreatecustomrenderersiftheysodesire,similarto
notdirectlyrevisualizedtotheuser(exceptpotentiallyattheendofa onesusedinthestudywiththecorrespondingtriggeringmechanisms.
session).Weusethecumulativeattentionmaptoupdatetheshort-term
attentionmap;thesecurrentattentionvalueswillebbandflowasthe 5.2 Revisualization
user’sgazemovesacrossdifferentpartsofthevisualization.Thisshort-
OurAAV2Dimplementationusesa“pictureframing”metaphorfor
termattentionmapisusedtodeterminebothwhen(triggering)and
itsrevisualizationmechanism,supportingseveralofthepresentation
how(revisualization)torendertheuser’sattentiononthevisualization.
methodsinSection4.3. Morespecifically, attachingAAV2Dtoan
HTMLelementisseenasmountingapicture.TheOverlaypresentation
4.2 TriggeringMechanisms
isaglazeappliedontopofthepicture. Thelibraryalsoprovidesa
AsnotedinSection3.3,weidentifythreestrategiesfortriggeringthe Borderpresentationthatservesasthedecorativeframeofthepicture.
revisualizationofthevisualization:ALWAYS-ON,EXPLICITtriggering, Finally,theMinimapisprovidedasanotherdecorationontheframe.
andIMPLICITtriggering(Figure2). ALWAYS-ONisconstantlyactive. Theframeisalsousedforshowinganoptionspanelthatcanbetoggled
Dependingontherevisualizationapproach,thisbehaviormayleadto tobevisibleornot.Figure3showsavisualoverviewofthismethod.
therevisualizationitselfaffectingtheuser’sattention. Furthermore,AAV2Dsupportsseveralrevisualizationapproaches
ForEXPLICITtriggering,weactivaterevisualizationwhentheuser depending on the presentation method. For both the glaze overlay
pressesahotkeyorcontrollerbutton—potentiallyspring-loaded,so andborderminimap,theapproachcanuseaheatmap,contourplot,
thatwhenthebuttonorkeyisreleasedtherevisualizationdisappears. or(Figure4);inthecaseoftheoverlay,thisrevisualizationisshown
Furthermore,aslongastherevisualizationisvisible,wetemporarily ontopoftheelement, whereasfortheminimap, itisshownonthe
disablecapturingattentiontoavoidself-reinforcingbehavior. miniature.Fortheframeborder,wesupportbarcharts,areacharts,and(a)Glazeoverlay. (b)Decorativeframeborder. (c)Minimapontheborder.
Fig.3:AAV2Dpictureframingmetaphor. AAV2Dprovidesseveralmethodsforrevisualizingattentionasan(a)(cid:9)OVERLAY,eitherontheº
MOUNTthatholdsthevisualizationorona(c),MINIMAParoundthe(b)decorated(cid:160)BORDERthatrevisualizesattention.
(a)Heatmap. (b)Contourplot. (c)Mesh.
Fig.4:AAV2Doverlay(glaze)revisualizations. Thethreeprimaryrevisualizationmechanismsinclude(a)heatmap,(b)contourplotand(c)
mesh.Thecolorsshowninthefigurearetailoredtofitthecorrespondingmountedvisualization,whichinthiscaseisJohnSnow’sCholeraMap.
heatmapsthatshowtheshort-termorcumulativeattentionontheplot normaldisplay.Insuchasetting,thescreencoordinatescanbefound
foraspecificxorycoordinate;seeFigure5forexamples. withaneye-tracker,orbyusingthecursorasaproxyforgaze.
Thesecondstrategyonlyapplyattentiontoelementsinthecenter
5.3 ImplementationNotes of the screen. This strategy is specifically designed for immersive
WeimplementedAAV2DusingvanillaJavaScriptwithouttheuseof environmentsusingXRheadsetsthatdonotincludeeyetracking,such
specializedlibrariesorbindings. D33 [10]wasusedforcomposing astheMetaQuest3.Insuchimmersiveenvironments,theuser’shead
ScalableVectorGraphics(SVG)ofcontourandheatmaps.Themesh orientationthusactsasaproxyfortheirattention.
implementationusesCSSimagefilterstoperformsomeofitsvisual Common for both of these strategies is that they apply attention
transformationsontheunderlyingHTMLelement,suchasblur,satura- to all elements that are within a specified distance from the user’s
tion,andhue-rotation.AllinputeventsareinterceptedbyAAV2Devent gaze position or center of the screen. This allows attention to be
handlers,butarethenpropagatedtotheunderlyingelement,meaning capturedforthegeneralareathattheuser’sattentionisdirected. By
thatitcanbeusedevenforinteractivevisualizationsandinterfaces. carefullyselectinganappropriatedistance,wecanapproximatethe
user’sattentionfromtheirheadorientationinXR.
6 DATA-AWAREAAVIN3D Beyondrecordingattentiontoindividualvisualmarks,wecancap-
ture attention at the level of individual 3D triangles based on their
Here we present AAV3D, our 3D data-aware implementation of
visibilitytotheuser.Thiscanbeusefultodealwithocclusionarising
attention-awarevisualizationssuitableforimmersiveanalyticssettings.
fromotherobjectsinthescene,orfromhiddensurfacesfacingaway
Belowwediscusstheattentioncaptureandtriggering,revisualization,
fromtheuser.WegointodetailsonhowthisisdoneinSection6.3.
andnotesaboutourimplementation.
6.1 AttentionCapture 6.2 Revisualization
Theimplementationhastwostrategiesforcapturingattention:using Ourimplementationcurrentlysupportstwotypesofrevisualizations:
screen coordinates, and using the center of the screen. The screen
• Heatmapbasedonthenormalized, cumulativeattentionmea-
coordinatesstrategyallowsattentiontobecapturedforelementscur-
suredtoallpartsofthevisualization.Thisrevisualizationrecolors
rentlyrenderedatanycoordinateofthescreen. Thisisusefulfora
eachfaceofthe3Dgeometriesinthevisualizationbasedonthe
non-immersivesetting,wheretheinteractive3Dsceneisrenderedona
cumulativeamountofattentionthefacehasreceived,normalized
3https://d3js.org betweenzeroandthemaximumamountofattention.width based on size
of attention bin
maximum cumulative attention along axis
minimum attention along axis
container width / height
(a)Barchart.
maximum cumulative attention along axis
Fig.7:GPUpickingbasedonIDs.Eachfaceofeveryobjectisassigned
minimum attention along axis
acolorinthepickingscene,basedontheIDoftheobjectandtheIDof
container width / height thefaceofthatobject. TheredRGBcolorspaceisreservedforobject
IDs,whilethegreenandblueRGBcolorspacesareusedforfaces.The
(b)Areachart. colorsinthisimageareexaggeratedtomakethemdistinguishable.
min cumulative max cumulative
attention along axis attention along axis
6.3 ImplementationNotes
Our3DvisualizationisimplementedasaWebXRapplicationusing
theThree.jslibrary.4 Ourvisualizationsarebespoke;i.e.,wedonot
useaspecific3Dvisualizationlibrary.Attentiononobjectsisachieved
container width / height
throughGPU-picking,whereeachframeisrenderedfirstinapicking
(c)Linearheatmap. scene,andtheninthenormalscene,whichisshownonscreen.Each
triangleofeveryobject’sgeometryisassignedauniqueRGBcolor
Fig.5:AAV2Dborderrevisualizations.AAV2Dprovidesseveralmeth- inthepickingscene. Theeightredcolorbitsareusedtoidentifythe
odsforrevisualizingattentiononthedecorativeborderoftheelement, object,whilethe16greenandbluecolorbitsareusedtoidentifyfaces
eachofwhichcanbetailoredtofitthemountedvisualization. intheobjectgeometry.Thiswayallowsustoknowwhichspecificpart
oftheobjecttoaddattentionto.Figure7illustrateshowanobject—in
thiscasealow-polygonsphere—iscoloredinthepickingscene.
The current implementation has a few limitations. Firstly, GPU
pickingisinitselfanexpensiveoperation.Toreducetheimpactsthis
operationhasonperformance,wedonotperformthisoperationatevery
frame,butratherataspecifiedintervalof100milliseconds.Secondly,
theuseofcolorslimitsthenumber,andcomplexities,ofobjectsinthe
scene,andthusthesizeofthedatasettobevisualized. Thishasnot
(a)ExplicitHeatmap.
beenaproblemforthedatasetswehaveused.
7 EVALUATIONSTUDY
TovalidateourproposedsolutiontotheresearchquestionsRQ1–RQ3
(b)ImplicitDesaturation. (Section3),wecarriedoutaqualitativeevaluationinvolvinghuman
participants,presentedinthissection. Ourgoalistounderstandthe
designchoicesandderivingoptimalstrategiesforvisualizingattention
aswellastheassociatedtriggeringmechanisms.
(c)AlwaysOnHeatmap.
Fig.6:AAV3Drevisualizations.AAV3Dprovidesseveralmethodsfor
revisualizingattentiononthevisualmarksthemselves.
• Emphasis/de-emphasisbasedonincreasinganddecreasingthe
colorsaturationofmarksinthevisualization.Theemphasiseffect
increasessaliencebyrecoloringthemarkintoabrightyellow,
whilethede-emphasiseffectlowersvisualsaliencebydesaturat-
ingthemarkthroughafilter.Ourimplementationcurrentlyuses
theshort-termattentionforthisapproach.
(a)AAV2Dcondition. (b)AAV3Dcondition.
Fig.8:Experimentalinterface.2Dand3Duserstudysetups.
The3Dimplementationfollowsthetriggeringstrategieslaidoutin
Section4.2,andeachoftherevisualizationscouldbeappliedtoeachof
thetriggeringstrategies.However,wehavecurrentlyonlyimplemented
emphasis/de-emphasisforIMPLICITtriggering. 4https://threejs.org
attention
attention
normalized

normalized

ezis
emarf
ezis
emarf
ezis
emarf7.1 StudyDesignRationale Table2: Experimentalconditions. Sixcombinationsofpresentation
andtriggersusedfortheexperiment;threeperplatform(2Dand3D).
Wemadethefollowingdecisionsforourdesignstudy:
• Nobaseline.Wechoosenottoconductacomparativeorgraph- Condition Platform Trigger Presentation
icalperceptionexperiment,partlybecausenosuitablebaseline 2D-Always AAV2D Always-on/Explicit Contour
comparisonexists,andpartlybecauseweareinterestedinthe 2D-Implicit AAV2D Implicit/Explicit Mesh
richerguidancethataqualitativeinterviewstudyprovides. 2D-Explicit AAV2D Explicit/Always-on Heatmap
3D-Always AAV3D Always-on Heatmap
• Experienced participants. We opted to recruit participants
3D-Implicit AAV3D Implicit Saturate
knowledgeableaboutdatavisualizationtoensurethattheiratten-
3D-Explicit AAV3D Explicit Heatmap
tionwouldberepresentativeofexperiencedvisualizationusage.
• Convenience population. Since our goal is to collect initial
qualitativeusagedataofattention-awarevisualizations,wefeel 7.5 Results
thatourspecializedpopulation(e.g.,studentsincomputerscience
Overall,allparticipantsunderstoodthevisualizationsandwereable
andengineering)isofminorconcern.
tocompletethetasks.Sincewearenotinterestedincompletiontime
• Between-participantsonplatform.Tokeepsessionsshort,we or task accuracy, we do not report such results here. Instead, here
split participants so that half did the study using the 2D data- wesummarizetheresultsofthequalitativeaspectsofourevaluation,
agnosticAAVmodule,andhalfusingthe3Ddata-awareone. includingobservations, thesubjectiveratings, andthemesfromthe
spokenandwrittenparticipantfeedback.
7.2 Participants 7.5.1 Observations
Werecruited12participants(9male,3female)fromaconvenience Participantswereallabletocompletetasks.Wemadenospecificdirect
population(studentsattwodifferentuniversities). Theparticipants observationsabouttaskperformanceduringeitherthe2Dor3Dstudy.
werescreenedtobeexperiencedcomputerusersandknowledgeable WeobservedthatthePupilLabsNeoneye-trackerisnotcompletely
aboutdatavisualization.Theiragerangedfrom24to52(mean30),all accurate.Forsomeparticipantsitmeasuredslightlybelowtheiractual
wereenrolledinacomputerscienceprogram,andallhadnormalor gaze,andforothersslightlyabove,whichlikelyskewedtheattention
corrected-to-normalvisionwithnocolorvisiondeficiencies. tracking.Thiswillslightlyoffsetthemeasuredattentiononthevisual-
ization,whichleadstoincorrectattentioncaptureandcorresponding
inaccuraterevisualizations.However,wedidnotobservethisbeingan
7.3 Apparatus
issueforourstudy,asthetaskswerenotdependantonrevisualization
For the 2D group, we used the data-agnostic implementation of accuracy,andtheparticipantsdidnotvoiceanyaccuracyconcerns.
attention-aware visualization in 2D (Section 5). We ran the experi-
ment on an Apple Macbook Pro connected to a 34 inch ultra-wide 7.5.2 SubjectiveRatings
monitor.Thesoftwarewasdisplayedinamaximizedwebbrowserin The results for the SUS questionnaire were overall just above aver-
a3024×1964pixelnativeresolution. WeusedaPupilLabsNeon age[6],withtheaveragescoreacrossparticipantsof70(SD=15).Per
embodiedeyetrackerconnectedtoanAndroidsmartphone,toprocess conditionscoreswereallaround65(belowaverageSUSscore),with
gazedatathatwasthenfedintotheAAV2Dmoduleonthecomputer. onenotableexception,the3DvisualizationwithEXPLICITtriggering,
Figure8ashowsanimageoftheexperimentalsetup. whichscored86(excellentSUSscore). Whenaskedtoratetheuse-
For the 3D group, we used the data-aware implementation of fulnessoftherevisualizations,theresponsesvariedsignificantly,with
attention-aware visualization in 3D (Section 6). This study was slightlymorepositivethannegativeresponses. Figure10illustrates
conducted using a Meta Quest Pro head-mounted display in video the reported usefulness of all the revisualizations. These dispersed
passthroughmode.Figure8bshowstheexperimentalsetup. responsesalignswiththeSUSquestionnaireresults.
Whenaskedtorankthetriggeringandrevisualizationtechniques,
theparticipantsusingthe3Dimplementationhadaclearpreference
7.4 Procedure
fortheEXPLICITtriggeringconditionanddislikedtheALWAYS-ON
Participantsfirstprovidedinformedconsentatthebeginningoftheir heatmap.Theypreferredhavingcontroloverwhentherevisualization
evaluationsession.Theyfilledoutademographicformandweregiven wastriggered,notingthattheconstantrecoloringintheALWAYS-ON
a brief introduction. They were then asked to complete three task conditionwashighlydistracting,particularlybecauseitoverrodethe
blocksinrandomorder. Eachtaskblockconsistedofavisualization colorsofthevisualizationitself.ThispreferenceforEXPLICITtrigger-
andalistoffouropen-endedquestions.Thevisualizationsareshownin ingissupportedbytheSUSscore.TheIMPLICITtriggeringconditions
Figure9.Participantswereassignedarandomcombinationofattention wereconsideredhardtounderstand,withoneparticipantreferringto
presentationandtriggeringmechanism.Table2givestheexperimental itas“mysterious.” Atthesametime, otherparticipantsconsidered
conditions,threefor2Dand3Deach.Participantsweregivenunlimited IMPLICITtriggeringtobeusefulforcertaintasksbyhelpingtodirect
timetofindanswerstoquestions. Theirperformancewasnottimed theirattention.
andcorrectnesswasnotmeasured. Participantswereencouragedto Theparticipantsusingthe2Dimplementationdidnothaveaclear
verbalizetheirthinking,butdidnotfollowastrictthink-aloudprotocol. preferenceforrevisualizationandtriggering.Whilesomeparticipants
Duringeachtaskblock,theAAVsoftwarewouldcontinuouslycol- likedthecontourmapforitsprecisemarkingofattentionanddisliked
lecttheuser’sgazeusingtheNeoneyetrackerorusingGPUpicking thefuzzynatureoftheheatmap,otherparticipantsdislikedhowthecon-
basedontheMetaQuestheaddirection.Theattentionrevisualization tourmapclutteredtheminimapwithlinesandlikedhowtheheatmap
wasdisplayeddependingonthetriggermechanismrandomlyassigned wasamoresubtlecoloroverlay. Mostparticipantsdidnotlikethe
totheparticipant:eithermanuallyorautomatically.Participantswere Meshcondition.Reasonsrangedfrombeinghardertounderstandwhat
shownhowtotriggerandusetheattentiondisplay. wasseen,tobeingannoyedthatitmadetheminimaphardtoread,since
After each block, participants were administered a brief System itdarkenedseenareastoomuchintheiropinion,andwasimprecise
UsabilityScale(SUS)[11]formandquestionnaireontheirexperience duetothebinsizeused.
anduseoftheattention-awarevisualization.Afterthestudy,theywere
7.5.3 ParticipantCommentsandFeedback
administeredasummaryquestionnaireandwereinterviewedontheir
experience.Beyondtheseresponses,wealsocapturedattentionmetrics Ourexaminationofparticipants’experienceswithrevisualizationtools
aswellasusagestatisticsforeachparticipant. in 2D and 3D contexts not only revealed the significant impact of(a)CharlesMinard’sNapoleon’sMarch(EnglishTranslation)(AAV2D). (b)FlorenceNightingale’sCoxcombPlots(AAV2D). (c)JohnSnow’sCholeraMap(AAV2D).
(d)Fisher’sIrisflowerdatasetasa3Dscatterplot(AAV3D). (e)Quinlan’sAutoMGPdatasetasa3Dbarchart(AAV3D) (f)Mt.Brunoelevation3Dsurface(AAV3D).
Fig.9:Studyvisualizations.Eachofthesesixvisualizations(threeforthe2Dandthreeforthe3Dplatform)wereassociatedwithfourtaskseach
(seesupplementalmaterial).Allthreeofthe2Dvisualizations(toprow)areinthepublicdomain,andareslightlyenhancedtoimprovereadability.
The3Dvisualizationswereourowndesigns.
where(they)choosetonotusethem”(P3,P5).Highlydynamic,vivid,
orclutteredvisualisztionswereoftenmetwithdisapprovalduetotheir
propensitytodistractorevenobscurecrucialdatapoints(P5in2D;
P2,P6in3D).Forinstance,morethanacoupleofparticipantsin2D
remarkedonthedistractingnatureoftheMeshimplementation,stating
how“the(Mesh)wasverycontrastingandchanging...addedtoomuch
clutter...” (P5)and“occludedpartsofthevisualization”(P2),even
leadingtosomeexplicitlydislikingit(P4). Similarresponseswere
Fig.10: Subjectiveusefulness. Thereportedusefulnessofthere-
seenfromthe3Dparticipantswheretheystatedthat“vibrantcolors”
visualizationswaswidelydispersed,withslightlymoreinfavorofthe
(P2)and“overridingorchangingcolorsfrequently”seemed“harmful
revisualizationswhilealargeportionoftheparticipantswereneutral.
toexperience”(P6).ThepreferenceforEXPLICITcontrolmechanisms
overALWAYS-ONfeatureswasalsonotablyprevalent,astheywereseen
toreducedistractionsandenhanceuserautonomyindataexploration
revisualizationsonuserengagement,attention,andanalyticaldepthbut
(P1,P3in2D;P1,P3,P6in3D).“Explicitisnotdistractingatall;I
alsoshedlightondesignpreferencesandthenuancedeffectsofthese
hadcontrol,”aparticipant(3D,P3)reflected,highlightingthevalueof
toolsonuserinteractionwithdatavisualizations. Weusedthematic
user-drivenengagementwithrevisualizationtools.
analysistodistilltheseinsightsintoseveralkeyareas,incorporating
participants’voicestogroundourfindingswithadditionalcontext. SubjectivePreferences. Participantfeedbackalsopointedtothe
highlysubjectivenatureofrevisualizationpreferencesandthecritical
Guiding Attention and Informing Curiosity. Revisualizations
roleoftasksuitabilityintheeffectivenessofthesetools. Thiswas
werepredominantlyusedbyparticipantstorefocusandredirecttheir
evident in the 2D context, as some participants gravitated towards
attention, often illuminating areas within the visual space that had
specificrevisualizationtechniquessuchasheatmapsorcontourmaps
eitherbeenoverlookedorrequiredfurtherexploration.Thisutilityof
basedontheirorientationtowardsprecisionandtheirdetail-oriented
revisualizationsbridgedboth2Dand3Dcontexts,enhancingusers’
utility, others valued minimaps for providing a holistic perspective
explorationthoroughnessbyguidingthemtowardsbothexploredand
of the data (P3, P2, P4, P5, P6 in 2D; P3, P5, P6 in 3D). “I did
unexploredareas(P2,P3,P4,P5in2D;P1,P3,P5in3D).Aparticipant
use the heatmap and the contour map more because I found them
(2D,P2)highlightedthisdualfunctionality,noting,“Itwasmorethat
itguidedmetowhereIhadbeenlookingandwhich,ofcourse,did
easiertounderstandhowtheycanhelpme,”notedaparticipant(2D,
tellmewhereIhaven’tbeenlooking.” Similarly,thestimulationof P3),exemplifyingthevariedpreferencesamongusers.Thisdiversity
underscorestheneedforadaptablerevisualizationtechniquesthatcan
curiosity,especiallywhenparticipantswereseekingspecificdetailsor
catertothepreferencesofindividualusersandspecificanalyticaltasks.
understandingthebreadthofvisualizationtechniques,wasarecurring
theme(P5,P2in2D;P2,P3in3D).Someparticipantsin3Dshared
LearningandAdaptationOverTime. Participantsincreasingly
thatthey“treateditlikeagame”(3D,P4)and“found(themselves)
engagedwiththerevisualizationtechniquesasthestudyprogressed.
wantingtogoinsidethevisualizationandseeitfrominside,”(3D,P2),
Initiallydrawntothesetoolsbytheirnovelty,participantsexperienced
underscoringthedepthofengagementrevisualizationscanfoster.
ariseintheircomfortandefficiencyinusingthemovertime(P4in2D;
Subtlety, Clarity, and Control. Participants leaned towards a P1,P2,P3,P5in3D).Oneparticipantinthe2Dsettingremarked,“At
preferenceforrevisualizationscharacterizedbysubtlety,clarity,and first,Iwasreallypayingattentionbecauseitwasnew...butaftergetting
theprovisionofEXPLICITcontrol.Forinstance,morethanacoupleof familiar,itfeelsroutineandIhardlygiveitasecondthought”(P4in
participantsin2Dappreciatedthesubtletyof“shading(frame)around 2D).Similarly,inthe3Dsetting,anotherparticipantnoted,“Indeed,
thescreen”(P1),withsomestatingthatit“didn’tdisturbinsituations as I became more accustomed to the effects, I found my attentionmoreeffectivelydirected,”highlightingthedynamicprocessoftheir moremeaningfuladjustments,suchashighlightingrelevantdatapoints
interactionwiththetools(3D,P1).Thissuggeststhatovertime,users orsuggestingalternativevisualizationsthatmightofferdeeperinsights
arelikelytonotjustgetusedtotherevisualizationfeaturesbutalso intothedata. Thislevelofadaptationrequiresadvancementsinma-
incorporatethemmorefluidlyintotheiranalyticalprocesses. chinelearningandartificialintelligencetointerpretcomplexpatterns
ofattentionandinteraction,pavingthewayforvisualizationsthatare
8 DISCUSSION notonlyreactivebutalsoproactiveinfacilitatingdatadiscovery.
Furthermore,whileweleftcollaborationoutofourtreatmentinthis
Wehavevalidatedourapproachtoattention-awarevisualizationsboth
paper,thesteptocollaborativeandeducationalsettingsisnotfar. In
throughtwoseparateimplementations—onein2Dandonein3D—as
environmentswheremultipleusersinteractwiththesamevisualization,
wellasthroughaqualitativeevaluationstudy. Herewediscusswhat
AAVscoulddynamicallyadjusttoaccommodatethefocusandneeds
thisworkmeansfordatavisualizationandcontext-awaredesignswithin
ofdifferentusers,enhancingcollaborativedataanalysisanddecision-
thisfield.Wealsoenumeratesomeofthelimitationsofourwork.
making.Ineducationalcontexts,AAVscouldtailorthepresentationof
8.1 ExplainingtheResults informationtothelearner’spaceandpointsofinterest,providingamore
engagingandeffectivelearningexperience. Realizingthesefutures
Overall,ourfindingsmostlyconfirmedourexpectations:participants
meansdevelopingsophisticatedalgorithmscapableofmanagingthe
perceivedattentionawarenesstobebothnovelanduseful,andconfi-
delicatebalancebetweenbeinginformativeandnon-disruptive,ensur-
dentlyincorporatedthesemechanismsintotheiranalyticalworkflow.
ingthatAAVsenrichtheuserexperiencebymakingdatavisualizations
Asexpected,however,thetriggeringandrevisualizationofattentionis
notjusttoolsforviewingbutalsoguidingexploration.
animportantdesignchallengethatrequirescarefulattention(nopun).
On the other hand, there were some nuanced differences observed 8.3 Limitations
betweenthe2Dand3Dimplementationsthatareworthcloserscrutiny.
Asdiscussedinourdesignframework(Section3),onelimitationof
Theimmersivequalityof3Denvironmentsaccentuatestheneedfor
ourapproachisthepotentialforreinforcingbehavior,whererevisual-
revisualizationmechanisms,likelyduetotheincreasedpotentialof
izingmechanismbasedonusergazemayinadvertentlyinfluencethe
theimmersiontooverwhelmordistract.“Quitelikebeingabletosee
user’ssubsequentattentionpatterns. Suchfeedbackcouldleadtoa
3Ddatafromanewperspectiveinsidetheheadset,thedifferenceof
self-reinforcingcycle,wherethevisualizationcontinuouslyemphasizes
beingabletowalkaroundtoseethingsfromdifferentanglesrather
areaspreviouslyfocusedonbytheuser, potentiallyovershadowing
thanrotating,”remarkedaparticipant(3D,P3),highlightingthenew
othervaluablebutlessattendeddatapoints.Understandingandmitigat-
perceptualpossibilitiesmadeaccessiblethroughtheadditionofdepth.
ingtheimpactofsuchreinforcingbehaviorontheuser’sexploration
Duringitsuse,aparticipantcommented,“Ifeellikemyattentionis
anddiscoveryprocessremainsachallengeforfutureiterationsofAAVs.
beingguidedaroundthevisualizations;Ihavetoactuallymovearound
Anotherlimitationconcernsthechoiceoftriggeringtoavoiddisrupt-
topaintthescene,encouragingexploration”(3D,P6),indicatingthat
ingtheuserexperience.Findingtherightbalancebetweenproviding
revisualizationmechanismscanbecomeessentialfornavigatingand
usefulfeedbackandavoidingoverwhelmingtheuserwithfrequentor
understanding data in 3D spaces by serving as a counterbalance to
intrusiveadjustmentstothevisualizationiscritical.Thisrequirescare-
thepotentialforsensoryoverloadandconfusion. Incontrast,in2D
fulconsiderationofthetiming,frequency,andextentofrevisualizations
environments,wheredepthisabsentandtheentirevisualizationisfully
toensuretheyenhanceratherthandetractfromthedataexploration
visibleatalltimes,theneedforrevisualizationappearslesscritical.
process.Weleavesuchfine-tuningandevaluationtofuturework.
TheseinsightssuggestthatthedesignofAAVsmightbenefitfroma
Whileeyetrackingtechnologyiscommoninthecurrentgeneration
nuancedunderstandingofhowusersinteractwithandperceivevisu-
ofAR/VRheadsets,itisstillnotcommonplaceintypicalcomputing
alizationsdifferentlyin2Dvs.3D.Whiletheimmersivecomplexity
setups,thuslimitingtheadoptionofAAVs. Thisrestrictstheimme-
of3Denvironmentscouldamplifytheneedforusercontrolanden-
diateapplicabilityofourproposedmethodsandlimitstheuserbase
gaginginteractionmechanisms,2Dspacesmightcallforsimplerand
thatcanbenefitfromthem. Wespeculatethattheprevalenceofgaze
moredirectapproaches.Anticipatingandadaptingtothesedifferences
interactionin,e.g.,theAppleVisionProwillleadtosuchtechnologies
couldbekeytounlockingthefullpotentialofAAVs,ensuringthatthey
alsobecomingpopularforregularcomputersandmobiledevices.
enhanceratherthancomplicatetheuserexperience.
Finally,theinformalnatureofourevaluationrepresentsamethod-
8.2 DesignImplications ologicallimitation.Thestudy’squalitativefocus,lackofquantitative
metrics,andabsenceofabaselinecomparisonrestrictourabilityto
Theintroductionofattention-awarevisualizations(AAVs)marksashift
drawdefinitiveconclusionsabouttheefficacyoftheframework.Fur-
towardscreatingmoreinteractiveandpersonalizeddataexploration
ther research involving more rigorous, quantitative evaluations and
experiences. Byleveraginguserattentiondatatodynamicallyadjust
comparisonswithexistingapproachesisnecessarytofullyunderstand
visualizations,wethinkthatAAVscanmakevisualdataexploration
thebenefitsandlimitationsofattention-awarevisualization.
moretailoredtoindividualusers’needs.However,ourstudyhighlights
acriticalbalancethatmustbestrucktoharnessthefullpotentialof 9 CONCLUSIONANDFUTUREWORK
AAVseffectively.Continuousactivemonitoringandadjustmentbased
Wehavepresentedattention-awarevisualizations(AAVs),acontext-
onusergazecanbedisruptive, creatingafeedbackloopthatmight
awaredatavisualizationparadigmthatleveragesuserattentiontody-
skewtheuser’snaturaldataexplorationprocess.Conversely,relying
namicallyadaptvisualcontent.Bytrackingandanalyzingwhereand
solelyonuser-initiatedtriggersforattention-awareadjustmentsrisks
howusersallocatetheirattentionovertime,AAVnotonlyoffersamore
underutilization due to forgetfulness or the extra cognitive load of
personalizeddataexplorationexperience,butalsodetectssituations
rememberingtoactivatethefeature. Thisunderscorestheneedfor
wheretheuserisnotseeingeverythinginagivenvisualization. Our
AAVsystemstointelligentlydiscernwhentoprovideguidancewithout
overwhelmingtheuser.5 Suchasystemwouldideallyanalyzepatterns approachhasbeenoperationalizedthroughtwodistinctimplementa-
tions:a2Ddata-agnosticmethodsuitableforweb-basedvisualizations
of user engagement to anticipate the need for attention redirection,
anda3Ddata-awaretechniqueutilizingthestencilbufferforimmer-
offeringaseamlessblendofautomatedanduser-controlledinteractions.
siveanalyticsenvironments.Bothmethodsunderscorethepotentialof
Lookingtothebiggerpicture,theintegrationofAAVsintovisualiza-
integratingattentionmetricstoenhancetheinterpretabilityanduser
tiondesignmayhelpimproveuserengagementwithdata.Onepotential
engagementofvisualizations. Accordingly, ourevaluationofthese
directioninvolvesthedevelopmentofcontext-awareAAVsthatadapt
implementationshasprovidedinsightsintotheeffectivenessofvisual
notjusttowhereuserslookbutalsotothecontextoftheirinteraction—
feedbackandattention-triggeringmechanisms,highlightingtheutility
whattheyarelookingforandtheirtaskathand.Byunderstandingthe
ofAAVsinfacilitatingadeeperunderstandingofcomplexdatasets.
user’sintentandthecontextoftheirexploration,AAVscouldprovide
Wefeelthatthisworkpointstofuturecontext-awarevisualization
5Afterall,noonewantsavisualizationversionofClippyj. techniques,wherethefocusisondevelopingvisualizationsystemsthatrespondtotheneedsoftheirusers.ExploringtheintegrationofAAVs [17] D.FonoandR.Vertegaal. EyeWindows: evaluationofeye-controlled
withothersensoryinputmethods,suchasauditoryfeedbackorhaptic zoomingwindowsforfocusselection.InProceedingsoftheACMConfer-
interfaces,couldofferaricher,moremultisensorydatainteractionex- enceonHumanFactorsinComputingSystems,pp.151–160.ACM,New
perience.Additionally,theapplicationofmachinelearningtechniques York,NY,USA,2005.doi:10.1145/1054972.10549942
topredictuserattentionshiftscouldrefinetheresponsivenessofAAVs, [18] S.Goodwin,A.Prouzeau,R.Whitelock-Jones,C.Hurter,L.Lee,U.Afzal,
makingvisualizationsevenmoreintuitiveanduser-centric. Another andT.Dwyer.VETA:visualeye-trackinganalyticsfortheexplorationof
promisingdirectioninvolvesinvestigatingthescalabilityofAAVsin gazepatternsandbehaviours. VisualInformatics,6(2):1–13,2022.doi:
handlinglarger,morecomplexdatasetsandtheirapplicabilityacross 10.1016/J.VISINF.2022.02.0042
[19] J. Grubert, T. Langlotz, S. Zollmann, and H. Regenbrecht. Towards
diversefieldssuchasmedicalimaging,financialanalysis,andsocial
pervasiveaugmentedreality: Context-awarenessinaugmentedreality.
networkvisualization.Finally,conductingextensiveuserstudiesacross
IEEETransactionsonVisualizationandComputerGraphics,23(6):1706–
different domains could shed light on the universal applicability of
1724,2017.doi:10.1109/TVCG.2016.25437202
AAVsandtailorthemmorecloselytouserneedsandpreferences.
[20] C.GutwinandS.Greenberg. Designforindividuals,designforgroups:
Tradeoffsbetweenpowerandworkspaceawareness.InProceedingsofthe
ACKNOWLEDGMENTS
ACMConferenceonComputer-SupportedCooperativeWorkandSocial
ThisworkwassupportedpartlybyVillumInvestigatorgrantVL-54492 Computing,pp.207–216.ACM,NewYork,NY,USA,1998.doi: 10.
byVillumFonden.Anyopinions,findings,andconclusionsexpressed 1145/289444.2894952
inthismaterialarethoseoftheauthorsanddonotnecessarilyreflect [21] C.G.Healey,K.S.Booth,andJ.T.Enns.High-speedvisualestimation
theviewsofthefundingagency. usingpreattentiveprocessing. ACMTransactionsonComputer-Human
Interaction,6(2):107–135,1999.doi:10.1145/230562.2305632
REFERENCES [22] W.C.Hill,J.D.Hollan,D.Wroblewski,andT.McCandless.Editwear
[1] D.Abowd,A.K.Dey,R.Orr,andJ.Brotherton. Context-awarenessin andreadwear.InProceedingsoftheACMConferenceonHumanFactors
wearableandubiquitouscomputing. VirtualReality,3(3):200–211,sep inComputingSystems,pp.3–9.ACM,NewYork,NY,USA,1992.doi:
1998.doi:10.1007/BF014085622 10.1145/142750.1427511
[2] S.S.AlamandR.Jianu.Analyzingeye-trackinginformationinvisualiza- [23] J. E. Hoffmann. A two-stage model of visual search. Perception &
tionanddataspace:Fromwhereonthescreentowhatonthescreen.IEEE Psychophysics,25:319–327,1979.doi:10.3758/BF031988112
TransactionsonVisualizationandComputerGraphics,23(5):1492–1505, [24] R.J.K.Jacob. Whatyoulookatiswhatyouget:eyemovement-based
2017.doi:10.1109/TVCG.2016.25353402 interactiontechniques.InProceedingsoftheACMConferenceonHuman
[3] S.S.AlamandR.Jianu.Analyzingeye-trackinginformationinvisualiza- FactorsinComputingSystems,pp.11–18.ACM,NewYork,NY,USA,
tionanddataspace:Fromwhereonthescreentowhatonthescreen.IEEE 1990.doi:10.1145/97243.972462
TransactionsonVisualizationandComputerGraphics,23(5):1492–1505, [25] H.JänickeandM.Chen.Asalience-basedqualitymetricforvisualization.
2017.doi:10.1109/TVCG.2016.25353402 ComputerGraphicsForum,29(3):1183–1192,2010.doi:10.1111/J.1467
[4] U.Alegre,J.C.Augusto,andT.Clark.Engineeringcontext-awaresystems -8659.2009.01667.X1,2
andapplications:Asurvey.JournalofSystemsandSoftware,117:55–83, [26] S.-H.Kim,Z.Dong,H.Xian,B.Upatising,andJ.S.Yi. Doesaneye
2016.doi:10.1016/j.jss.2016.02.0102 trackertellthetruthaboutvisualizations?:Findingswhileinvestigating
[5] C.B.Anagnostopoulos,A.Tsounis,andS.Hadjiefthymiades. Context visualizationsfordecisionmaking.IEEETransactionsonVisualization
awarenessinmobilecomputingenvironments. WirelessPersonalCom- andComputerGraphics,18(12):2421–2430,2012.doi:10.1109/TVCG.
munications,42(3):445–464,aug2007.doi:10.1007/s11277-006-9187-6 2012.2152
2 [27] K.Kurzhals,B.Fisher,M.Burch,andD.Weiskopf.Eyetrackingevalua-
[6] A.Bangor,P.Kortum,andJ.Miller. Determiningwhatindividualsus tionofvisualanalytics.InformationVisualization,15(4):340–358,2016.
scoresmean:addinganadjectiveratingscale.JournalofUsabilityStudies, doi:10.1177/14738716156097872
4(3):114–123,may2009.7 [28] J.D.Mackinlay. Automatingthedesignofgraphicalpresentationsof
[7] T.Blascheck,M.John,S.Koch,L.Bruder,andT.Ertl. Triangulating relationalinformation. ACMTransactionsonGraphics,5(2):110–141,
user behavior using eye movement, interaction, and think aloud data. 1986.doi:10.1145/22949.229501
In Proceedings ofthe ACMSymposium onEye Tracking Research& [29] L.E.Matzen,M.J.Haass,K.M.Divis,Z.Wang,andA.T.Wilson.Data
Applications,pp.175–182.ACM,NewYork,NY,USA,2016.doi: 10. visualizationsaliencymodel:Atoolforevaluatingabstractdatavisual-
1145/2857491.28575232 izations. IEEETransactionsonVisualizationandComputerGraphics,
[8] T.Blascheck,K.Kurzhals,M.Raschke,M.Burch,D.Weiskopf,and 24(1):563–573,2018.doi:10.1109/TVCG.2017.27439391,2
T.Ertl.State-of-the-artofvisualizationforeyetrackingdata.InStateofthe [30] T.Munzner.VisualizationAnalysisandDesign.AKPeters,BocaRaton,
ArtReportsoftheEurographicsConferenceonVisualization.Eurographics FL,USA,2014.1
Association,2014.doi:10.2312/EUROVISSTAR.201411732 [31] U.Neisser.CognitivePsychology.Appleton-Century-Crofts,NewYork,
[9] R.A.Bolt.Gaze-orchestrateddynamicwindows.InProceedingsofthe NY,USA,1967.2
ACMConferenceonComputerGraphicsandInteractiveTechniques,pp. [32] L.T.Nowell,E.G.Hetzler,andT.Tanasse.Changeblindnessininforma-
109–119.ACM,NewYork,NY,USA,1981.doi:10.1145/800224.806796 tionvisualization:Acasestudy.InProceedingsoftheIEEESymposium
2 onInformationVisualization,pp.15–22.IEEEComputerSociety,Los
[10] M.Bostock,V.Ogievetsky,andJ.Heer. D3 Data-DrivenDocuments. Alamitos,CA,USA,2001.doi:10.1109/INFVIS.2001.9632742
17(12):2301–2309,Dec.2011.doi:10.1109/TVCG.2011.1855 [33] C.Perera,A.Zaslavsky,P.Christen,andD.Georgakopoulos. Context
[11] J.Brookeetal.Sus-aquickanddirtyusabilityscale.Usabilityevaluation awarecomputingfortheinternetofthings: Asurvey. IEEECommuni-
inindustry,189(194):4–7,1996.7 cationsSurveys&Tutorials,16(1):414–454,2014.doi:10.1109/SURV.
[12] M.Burch.EyeTrackingandVisualAnalytics.RiverPublishers,Gistrup, 2013.042313.001972
Denmark,2021.2 [34] K.Pfeuffer,J.Alexander,M.K.Chong,andH.Gellersen. Gaze-touch:
[13] M.Burch,N.Konevtsova,J.Heinrich,M.Hoeferlin,andD.Weiskopf. combining gaze with multi-touch for interaction on the samesurface.
Evaluationoftraditional,orthogonal,andradialtreediagramsbyaneye InProceedingsoftheACMSymposiumonUserInterfaceSoftwareand
trackingstudy.IEEETransactionsonVisualizationandComputerGraph- Technology,pp.509–518.ACM,NewYork,NY,USA,2014.doi: 10.
ics,17(12):2440–2448,2011.doi:10.1109/TVCG.2011.1932 1145/2642918.26473972
[14] A.K.Dey.Understandingandusingcontext.PersonalUbiquitousCom- [35] K. Pfeuffer and H. Gellersen. Gaze and touch interaction on tablets.
put.,5(1):4–7,jan2001.doi:10.1007/s0077901700192 InProceedingsoftheACMSymposiumonUserInterfaceSoftwareand
[15] N.ElmqvistandP.Irani.UbiquitousAnalytics:InteractingwithBigData Technology,pp.301–311.ACM,NewYork,NY,USA,2016.doi: 10.
Anywhere,Anytime. Computer,46(4):86–89,2013.doi: 10.1109/MC. 1145/2984511.29845142
2013.1472 [36] K.Pfeuffer,B.Mayer,D.Mardanbegi,andH.Gellersen. Gaze+pinch
[16] N.ElmqvistandP.Tsigas.Ataxonomyof3Docclusionmanagementfor interactioninvirtualreality. InProceedingsoftheACMSymposiumon
visualization.IEEETransactionsonVisualizationandComputerGraphics, SpatialUserInteraction,pp.99–108.ACM,NewYork,NY,USA,2017.
14(5):1095–1109,2008.doi:10.1109/TVCG.2008.591 doi:10.1145/3131277.31321802[37] P.Polatsek,M.Waldner,I.Viola,P.Kapec,andW.Benesova.Exploring
visual attention and saliency modeling for task-based visual analysis.
Computers&Graphics,72:26–38,2018.doi:10.1016/j.cag.2018.01.010
2
[38] D.D.SalvucciandJ.R.Anderson.Intelligentgaze-addedinterfaces.In
ProceedingsoftheACMConferenceonHumanFactorsinComputing
Systems,pp.273–280.ACM,NewYork,NY,USA,2000.doi:10.1145/
332040.3324442
[39] B.Schilit,N.Adams,andR.Want.Context-awarecomputingapplications.
In1994FirstWorkshoponMobileComputingSystemsandApplications,
pp.85–90,1994.doi:10.1109/WMCSA.1994.161,2
[40] S.Shin,A.Batch,P.W.S.Butcher,P.D.Ritsos,andN.Elmqvist. The
RealityoftheSituation:ASurveyofSituatedAnalytics.IEEETransac-
tionsonVisualizationandComputerGraphics,2023.Toappear.doi:10.
1109/TVCG.2023.32855462
[41] S.Shin,S.Chung,S.Hong,andN.Elmqvist.Ascannerdeeply:Predicting
gazeheatmapsonvisualizationsusingcrowdsourcedeyemovementdata.
IEEETransactionsonVisualizationandComputerGraphics,29(1):396–
406,2023.doi:10.1109/TVCG.2022.32094722
[42] S.StellmachandR.Dachselt. Look&touch: gaze-supportedtarget
acquisition.InProceedingsoftheACMConferenceonHumanFactorsin
ComputingSystems,pp.2981–2990.ACM,NewYork,NY,USA,2012.
doi:10.1145/2207676.22087092
[43] S. Stellmach, S. Stober, A. Nürnberger, and R. Dachselt. Designing
gaze-supportedmultimodalinteractionsfortheexplorationoflargeimage
collections.InProceedingsoftheConferenceonNovelGaze-Controlled
Applications,pp.1:1–1:8.ACM,NewYork,NY,USA,2011.doi: 10.
1145/1983302.19833032
[44] A.M.TreismanandG.Gelade.Afeature-integrationtheoryofattention.
CognitivePsychology,12(1):97–136,1980.doi:10.1016/0010-0285(80)
90005-52
[45] H.Y.Tsang,M.Tory,andC.Swindells.eSeeTrack-visualizingsequential
fixation patterns. IEEE Transactions on Visualization and Computer
Graphics,16(6):953–962,2010.doi:10.1109/TVCG.2010.1492
[46] J.Turner,J.Alexander,A.Bulling,D.Schmidt,andH.Gellersen. Eye
pull,eyepush:Movingobjectsbetweenlargescreensandpersonaldevices
withgazeandtouch.InProceedingsoftheIFIPConferenceonHuman-
ComputerInteraction,vol.8118ofLectureNotesinComputerScience,
pp.170–186.Springer,NewYork,NY,USA,2013.doi:10.1007/978-3
-642-40480-1_112
[47] E.Velloso,J.Turner,J.Alexander,A.Bulling,andH.Gellersen.Anem-
piricalinvestigationofgazeselectioninmid-airgestural3Dmanipulation.
InProceedingsoftheIFIPConferenceonHuman-ComputerInteraction,
vol.9297ofLectureNotesinComputerScience,pp.315–330.Springer,
NewYork,NY,USA,2015.doi:10.1007/978-3-319-22668-2_252
[48] C.Ware. InformationVisualization: PerceptionforDesign. Morgan
Kaufmann,SanFrancisco,CA,USA,3ed.,2012.2
[49] C. Ware and H. H. Mikaelian. An evaluation of an eye tracker as a
deviceforcomputerinput.InProceedingsoftheSIGCHI/GIConference
onHumanFactorsinComputingSystemsandGraphicsInterface,pp.
183–188.ACM,NewYork,NY,USA,1987.doi:10.1145/29933.275627
2
[50] M.Weiser. Thecomputerforthe21stCentury. ScientificAmerican,
265(3):94–104,1991.doi:10.1145/329124.3291262
[51] J.H.R.WhiteandG.Buscher. Usersee,userpoint: Gazeandcursor
alignmentinwebsearch. InProceedingsoftheACMConferenceon
HumanFactorsinComputingSystems,pp.1341–1350.ACM,NewYork,
NY,USA,2012.doi:10.1145/2207676.22085911
[52] J.M.Wolfe.Guidedsearch2.0arevisedmodelofvisualsearch.Psycho-
nomicBulletin&Review,1(2):202–238,1994.doi:10.3758/BF03200774
2
[53] S.Zhai, C.Morimoto, andS.Ihde. Manualandgazeinputcascaded
(MAGIC)pointing. InProceedingsoftheACMConferenceonHuman
FactorsinComputingSystems,pp.246–253.ACM,NewYork,NY,USA,
1999.doi:10.1145/302979.3030532