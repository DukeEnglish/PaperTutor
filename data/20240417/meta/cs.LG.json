[
    {
        "title": "Nearly Optimal Algorithms for Contextual Dueling Bandits from Adversarial Feedback",
        "authors": "Qiwei DiJiafan HeQuanquan Gu",
        "links": "http://arxiv.org/abs/2404.10776v1",
        "entry_id": "http://arxiv.org/abs/2404.10776v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10776v1",
        "summary": "Learning from human feedback plays an important role in aligning generative\nmodels, such as large language models (LLM). However, the effectiveness of this\napproach can be influenced by adversaries, who may intentionally provide\nmisleading preferences to manipulate the output in an undesirable or harmful\ndirection. To tackle this challenge, we study a specific model within this\nproblem domain--contextual dueling bandits with adversarial feedback, where the\ntrue preference label can be flipped by an adversary. We propose an algorithm\nnamely robust contextual dueling bandit (\\algo), which is based on\nuncertainty-weighted maximum likelihood estimation. Our algorithm achieves an\n$\\tilde O(d\\sqrt{T}+dC)$ regret bound, where $T$ is the number of rounds, $d$\nis the dimension of the context, and $ 0 \\le C \\le T$ is the total number of\nadversarial feedback. We also prove a lower bound to show that our regret bound\nis nearly optimal, both in scenarios with and without ($C=0$) adversarial\nfeedback. Additionally, we conduct experiments to evaluate our proposed\nalgorithm against various types of adversarial feedback. Experimental results\ndemonstrate its superiority over the state-of-the-art dueling bandit algorithms\nin the presence of adversarial feedback.",
        "updated": "2024-04-16 17:59:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10776v1"
    },
    {
        "title": "TENG: Time-Evolving Natural Gradient for Solving PDEs with Deep Neural Net",
        "authors": "Zhuo ChenJacob McCarranEsteban VizcainoMarin SoljačićDi Luo",
        "links": "http://arxiv.org/abs/2404.10771v1",
        "entry_id": "http://arxiv.org/abs/2404.10771v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10771v1",
        "summary": "Partial differential equations (PDEs) are instrumental for modeling dynamical\nsystems in science and engineering. The advent of neural networks has initiated\na significant shift in tackling these complexities though challenges in\naccuracy persist, especially for initial value problems. In this paper, we\nintroduce the $\\textit{Time-Evolving Natural Gradient (TENG)}$, generalizing\ntime-dependent variational principles and optimization-based time integration,\nleveraging natural gradient optimization to obtain high accuracy in\nneural-network-based PDE solutions. Our comprehensive development includes\nalgorithms like TENG-Euler and its high-order variants, such as TENG-Heun,\ntailored for enhanced precision and efficiency. TENG's effectiveness is further\nvalidated through its performance, surpassing current leading methods and\nachieving machine precision in step-by-step optimizations across a spectrum of\nPDEs, including the heat equation, Allen-Cahn equation, and Burgers' equation.",
        "updated": "2024-04-16 17:55:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10771v1"
    },
    {
        "title": "Finite-dimensional approximations of push-forwards on locally analytic functionals and truncation of least-squares polynomials",
        "authors": "Isao Ishikawa",
        "links": "http://arxiv.org/abs/2404.10769v1",
        "entry_id": "http://arxiv.org/abs/2404.10769v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10769v1",
        "summary": "This paper introduces a theoretical framework for investigating analytic maps\nfrom finite discrete data, elucidating mathematical machinery underlying the\npolynomial approximation with least-squares in multivariate situations. Our\napproach is to consider the push-forward on the space of locally analytic\nfunctionals, instead of directly handling the analytic map itself. We establish\na methodology enabling appropriate finite-dimensional approximation of the\npush-forward from finite discrete data, through the theory of the\nFourier--Borel transform and the Fock space. Moreover, we prove a rigorous\nconvergence result with a convergence rate. As an application, we prove that it\nis not the least-squares polynomial, but the polynomial obtained by truncating\nits higher-degree terms, that approximates analytic functions and further\nallows for approximation beyond the support of the data distribution. One\nadvantage of our theory is that it enables us to apply linear algebraic\noperations to the finite-dimensional approximation of the push-forward.\nUtilizing this, we prove the convergence of a method for approximating an\nanalytic vector field from finite data of the flow map of an ordinary\ndifferential equation.",
        "updated": "2024-04-16 17:53:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10769v1"
    },
    {
        "title": "Confidential Federated Computations",
        "authors": "Hubert EichnerDaniel RamageKallista BonawitzDzmitry HubaTiziano SantoroBrett McLarnonTimon Van OverveldtNova FallenPeter KairouzAlbert CheuKatharine DalyAdria GasconMarco GruteserBrendan McMahan",
        "links": "http://arxiv.org/abs/2404.10764v1",
        "entry_id": "http://arxiv.org/abs/2404.10764v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10764v1",
        "summary": "Federated Learning and Analytics (FLA) have seen widespread adoption by\ntechnology platforms for processing sensitive on-device data. However, basic\nFLA systems have privacy limitations: they do not necessarily require\nanonymization mechanisms like differential privacy (DP), and provide limited\nprotections against a potentially malicious service provider. Adding DP to a\nbasic FLA system currently requires either adding excessive noise to each\ndevice's updates, or assuming an honest service provider that correctly\nimplements the mechanism and only uses the privatized outputs. Secure\nmultiparty computation (SMPC) -based oblivious aggregations can limit the\nservice provider's access to individual user updates and improve DP tradeoffs,\nbut the tradeoffs are still suboptimal, and they suffer from scalability\nchallenges and susceptibility to Sybil attacks. This paper introduces a novel\nsystem architecture that leverages trusted execution environments (TEEs) and\nopen-sourcing to both ensure confidentiality of server-side computations and\nprovide externally verifiable privacy properties, bolstering the robustness and\ntrustworthiness of private federated computations.",
        "updated": "2024-04-16 17:47:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10764v1"
    },
    {
        "title": "TorchSurv: A Lightweight Package for Deep Survival Analysis",
        "authors": "Melodie MonodPeter KruscheQian CaoBerkman SahinerNicholas PetrickDavid OhlssenThibaud Coroller",
        "links": "http://arxiv.org/abs/2404.10761v1",
        "entry_id": "http://arxiv.org/abs/2404.10761v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10761v1",
        "summary": "TorchSurv is a Python package that serves as a companion tool to perform deep\nsurvival modeling within the PyTorch environment. Unlike existing libraries\nthat impose specific parametric forms, TorchSurv enables the use of custom\nPyTorch-based deep survival mod- els. With its lightweight design, minimal\ninput requirements, full PyTorch backend, and freedom from restrictive survival\nmodel parameterizations, TorchSurv facilitates efficient deep survival model\nimplementation and is particularly beneficial for high-dimensional and complex\ninput data scenarios",
        "updated": "2024-04-16 17:41:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10761v1"
    }
]