HARMONIC: Cognitive and Control Collaboration in Human-Robotic
Teams
Sanjay Oruganti1, Sergei Nirenburg 1, Marjorie McShane1, Jesse English 1,
Michael K. Roberts 1 and Christian Arndt 1
Abstract—This paper presents a novel approach to multi-
robot planning and collaboration. We demonstrate a cognitive
strategy for robots in human-robot teams that incorporates
metacognition, natural language communication, and explain-
ability. The system is embodied using the HARMONIC ar-
chitecture that flexibly integrates cognitive and control capa-
bilities across the team. We evaluate our approach through
simulation experiments involving a joint search task by a
team of heterogeneous robots (a UGV and a drone) and a
human.Wedetailthesystem’shandlingofcomplex,real-world
scenarios, effective action coordination between robots with
Fig.1:Anoverviewoftheframework,showingtheStrategic
differentcapabilities,andnaturalhuman-robotcommunication.
andTacticalcomponentsrepresentingthehigh-levelplanning Thisworkdemonstratesthattherobots’abilitytoreasonabout
plans, goals, and attitudes, and to provide explanations for and low-level execution, respectively.
actions and decisions are essential prerequisites for realistic
human-robot teaming.
• communicating with teammates using interpreted,
meaningful natural language.
I. INTRODUCTION
Theabovecapabilitieswillfacilitatecomplexteaminterac-
Intoday’srapidlyevolvingtechnologicallandscape,robots tions, attention management, goal-setting, planning (includ-
are becoming increasingly ubiquitous across various do- ingincorporatingavarietyofMAPstrategies),andovercom-
mains, from manufacturing and healthcare to search and ing unexpected challenges in a way that humans can readily
rescue operations [1], [2]. This proliferation has given rise interpret. The integration of verbal and visual communica-
to a growing number of heterogeneous robot teams, where tion enhances the overall effectiveness of skill transfer and
machines with diverse capabilities collaborate to achieve knowledge sharing within human-robot teams. Furthermore,
common goals. To harness these distributed and varied meaning-oriented natural language communication allows
problem-solving capabilities, research in Multi-Agent Plan- robots to provide causal explanations for their actions and
ning (MAP) has focused on developing sophisticated plan- decisions, thereby enhancing overall transparency and ex-
ning and collaboration strategies. plainability,whicharesteppingstonestotrust[7].Agrowing
Despite significant advancements in multi-robot planning number of robots today are based on foundational models,
and collaboration [3], [4], a number of issues related to suchasLargeLanguageModels(LLMs)[8],[9]andVision-
human-robotic teaming remain relatively unexplored [5]. Language-Action (VLA) models [10], [11]. These black-
For robots to serve as trusted partners in human-robotic box technologies contribute to several components of our
teams, they must demonstrate a number of cognitive and architecture.However,wemakesurethatthemoduleswhose
metacognitive abilities, including: operationandoutputshouldbeexplanatorytohumanswillbe
fully glass-box inspectable and explainable in human terms
• developing and enhancing an understanding of team
both to team members and to external inspectors.
tasks and team organization;
We present our approach to human-robot teaming using
• developing and enhancing specific capabilities, involv-
the example of a team comprised of two robots and a
ing the responsibilities, preferences, and actions of self
human executing a joint task. We demonstrate the robots’
and other team members [6];
knowledge of team organization as well as, their ability
• maintaining and using an episodic memory of past
to (a) dynamically negotiate tasks and allocate responsibil-
activities, as when leveraging past experiences to make
ities, (b) select and modify plans, and (c) adapt language
informed predictions about future needs and actions;
communication to both the situation and the needs of their
• interpretinglanguage,visualperception,andhapticper-
interlocutors. We implement these robotic capabilities using
ception in terms of an underlying formal model of the
the novel HARMONIC architecture that operates in parallel
world (ontology); [7]
at two levels – the strategic cognitive level, which supports
operationsrequiringreasoning,andthetacticalcontrollevel,
1Authors are with the Cognitive Science Department at
which supports skill-based, ”automatic,” reflexive operation.
Rensselaer Polytechnic Institute, NY, 12180, USA e-mail:
sanjayovs@ieee.org Specifically, in this paper, we report:
4202
peS
62
]OR.sc[
1v74081.9042:viXra• A cognitive strategy for multi-robot planning and ex- between robots, Lemon et al. [20] and Natarajan et al.
ecution with metacognition, communication, and ex- [5] support the need for a unified, human-centric approach
plainability. This includes the robots’ natural language to team communication. Rather than maintaining separate
understanding and generation, their reasoning about protocols for inter-robot and human-robot interactions, a
plans, goals, and attitudes, and their ability to explain common cognitive architecture that emulates human-like
the reasons for their own and others’ actions. communication and reasoning offers a more cohesive solu-
• The distributed HARMONIC architecture, which en- tion, emulating human team dynamics.
ables a flexible integration of cognitive and robotic Early work by Clark et al. [21] proposed a framework
control and execution capabilities. for this process, which was later adapted by Klein et al.
• Results of simulation experiments on a search task [22]toteamcoordination,introducingthenotionofcommon
carried out by heterogeneous robots, which showcases ground. These studies highlight essential capabilities for
thehuman-robotteam’sabilitytohandlecomplex,real- robotic team members, including maintaining shared under-
world scenarios. standing, negotiating goals and plans, managing attention,
Section II briefly describes the state of the art. Sections andhandlingcommandsandrequests.Subsequentpioneering
III-VpresenttheHARMONICframeworkandtheimplemen- research in dialogue processing systems [23], [24], [25]
tationofitsstrategicandtacticallevels.SectionVIdescribes and grounding [26], [27], [28], [29] further developed these
the organization of planning tasks, and Section VII presents ideas, laying the groundwork for addressing communication
ourinitialevaluationofHARMONIConateamsearchtask. challenges in human-robot teams. Results of this research
andourownpriorworkonteamorganization[30]andnatural
II. BACKGROUNDANDRELATEDWORK
language communication [7] guided the implementation of
Multi-Agent Planning (MAP) in Heterogeneous Multi- cognitive processes for team organization and communica-
Robot (HMR) teams encompasses a spectrum of strategies tion in HARMONIC.
ranging from centralized to decentralized approaches, with
varying degrees of inter-agent coupling. In centralized plan-
III. THEHARMONICFRAMEWORK
ning, a single agent orchestrates the entire team’s actions, HARMONIC (Human-AI Robotic Team Member Operat-
potentially achieving globally optimal solutions but facing ing with Natural Intelligence and Communication), shown
scalability challenges in larger teams. Conversely, decentral- in Fig. 1, is a dual-control cognitive-robotic architecture
ized methods enable autonomous plan negotiation among thatintegratesstrategic,cognitive-leveldecision-makingwith
agents, offering enhanced scalability and adaptability at the tactical, skill-level robot control. It builds upon and extends
riskoflocalsuboptimality[12].Brafmanetal.[13]quantify the concept of hybrid control systems and architectures, as
this trade-off, noting that centralized planning in closely discussed in a comprehensive review by Dennis et al. [31].
coupled multi-agent systems is exponentially more complex Italsorepresentsanadvancementoverthetype2integration
than solving independent problems in decoupled systems. approach employed in the DIARC framework [32], [33].
To balance these extremes, modern HMR teams often Unlike DIARC, where the strategic layer is embedded as
implement hybrid MAP strategies. These may include cen- a subsystem within the tactical layer to enable concurrent
tralized hierarchical or collaborative planning coupled with and dynamic operations, HARMONIC introduces a more
decentralized execution [14], dynamic switching between sophisticated integration of these components.
localandglobalplansbasedoncontextualfactors[3],orcen- The strategic and tactical architectural layers of HAR-
tralized conflict resolution alongside decentralized planning MONIC are connected by a bidirectional interface for seam-
[15]. Advanced implementations of these hybrid approaches less communication. The strategic layer, built upon the On-
includehierarchicalplanningframeworks,auction-basedtask toAgent cognitive architecture [34], [35], [7], encompasses
allocationsystems[16],anddistributedpartial-orderplanners modulesforattentionmanagement,perceptioninterpretation,
[17], which have demonstrated significant collaborative ca- and decision-making (see Section. IV). It employs both
pabilities in complex multi-robot scenarios. utility-basedandanalogicalreasoning,enhancedbymetacog-
Intra-team communication in an HMR team involves both nitive abilities. This layer prioritizes strategic goals, man-
inter-robotandhuman-robotinteractions,eachrequiringdis- ages plan agendas, and selects actions while continuously
tinct protocols. To date, most research has focused on inter- monitoring their execution. It also facilitates team-oriented
robot communication using standardized Agent Communi- operations,includingcommunicatinginnaturallanguageand
cationLanguagestofacilitateefficientinformationexchange explaining decisions.
[18]. The implementation of frameworks, such as CORA Thetacticallayerisresponsibleforrobotcontrolatalower
(Core Ontologies for Robotics and Automation) [19], while level, processing sensor inputs, and planning motor actions
enhancing semantic interoperability and knowledge sharing to execute high-level commands from the strategic layer.
among robotic agents, cannot support natural, human-level It employs controllers, algorithms, and models to translate
communication. To engender human trust, human-robot in- abstractcommandsintoconcreterobotactions.Forinstance,
teractions must be carried out in everyday natural language. acommandPICK(KEY,AT-POSITION1)to”pickupakeyon
The communication modalities currently employed in the ground” initiates a series of precise operations, includ-
HMR teams, while effective for preprogrammed interactions ing object identification, position determination, trajectorycomputation,andactuation.Thislayeralsomanagesreactive and generates ontologically-grounded interpretations of text
responses, such as collision avoidance, through dedicated meaning. The language generator, for its part, generates
controllers. In the tactical layer, HARMONIC employs Be- natural language utterances from ontologically grounded
havior Trees (BTs) [36], which provide modular and robust meaning representations that the agent creates as part of its
representations for skills and low-level plans (see Section. reasoning about action. OntoAgent also supports ontological
V). interpretation of visual percepts using an opticon whose
The architecture’s design aligns with Kahneman’s dual- entries link images to ontological objects.
system approach [37], with the strategic layer implementing The architecture supports goal-directed behavior through
System 2 (slow, deliberative reasoning) and the tactical a goal agenda and a prioritizer that selects which goals to
layerimplementingSystem1(fast,intuitiveresponses).This pursue. It typically uses stored plans associated with goals
structure allows for dynamic scheduling and adaptation, but can also engage in reasoning from first principles when
enablingreal-timeadjustmentstoprioritiesandactions.Itef- necessary.
fectivelyhandlescomputationaldelays,contingencies,safety
V. BEHAVIORTREESFORTACTICALEXECUTION
concerns, and resource optimization through a combination
of low-level planning and reactive algorithms. BehaviorTrees(BTs),originallydevelopedforcontrolling
non-playercharactersinvideogames,havefoundsignificant
IV. ONTOAGENTFORSTRATEGICLEVELPLANNING applications in robotics and AI [36]. BTs are directed trees
OntoAgent is a content-centric cognitive architecture in- that provide a flexible and intuitive way to design control
corporated in HARMONIC. OntoAgent is designed to sup- actions and define task-planning hierarchies for agents. The
port the development of social intelligent agents through flexibility and modularity of BTs make them particularly
computational cognitive modeling [35], [7], [34]. This ap- suitable for complex, hierarchical task planning in robotics
proach emphasizes the need to acquire, maintain, and dy- and AI applications, allowing for easy modification and
namically expand large-scale knowledge bases, which are scaling of agent behaviors.
essential for an agent’s perception interpretation, reasoning, BTs in the tactical layer of HARMONIC enable effective
and action. The architecture’s memory structure is divided reactive control and support the system’s safety and opera-
into three main components: a Situation Model (SM) that tional requirements in dynamic environments. The tactical
contains currently active concept instances; a Long-Term layer also incorporates advanced control techniques such
Semantic Memory (LTS) that stores knowledge about in- as whole-body compliant control [38], [36] with motion
stancesofeventsandobjects,andanEpisodicMemory(LTE) planning, path planning [39] etc. In addition to these, BTs
that stores knowledge about instances of events and objects. can also be used for representing skills and low-level plans
OntoAgent supports goal-directed behavior through a goal that can directly be shared between the robots[40], [41].
agendaandaprioritizerthatselectswhichgoalstopursue.It BTs typically use a blackboard architecture to maintain
typicallyusesstoredplansassociatedwithgoalsbutcanalso andaccessfrequentlycheckedconditionvariables[42],[43].
engage in reasoning from first principles when necessary. In the context of HARMONIC, a state manager keeps track
The architecture is built on a service-based infrastructure, ofthesevariablesonthetacticallayerandallowsforefficient
with key services including perception interpretation, atten- queryingandupdatingofthesystem’sstateduringoperation
tion management, reasoning, and action rendering. OntoA- based on the sensory inputs and action commands received
gentcanintegratebothnativeservicesandimportedexternal from the strategic layer.
capabilities,suchasroboticvisionortest-to-speechmodules.
Thisflexibilityallowsittosupportmultipleperceptionchan-
nels, including language understanding, visual perception,
and simulated interoception (Chapter 8 of [35]).
A crucial component of OntoAgent is OntoGraph, a
knowledge base API that provides a unified format for
representing and accessing knowledge across the system.
OntoGraph supports inheritance, flexible organization of
knowledgeinto”spaces,”andefficientqueryingandretrieval.
Itimplementsagraphdatabaseviewofknowledge,allowing
for complex relational queries and supporting the represen-
tation of inheritance hierarchies.
OntoAgent places a strong emphasis on natural language
understanding and meaning-based text generation. These
Fig. 2: (a) Root, control flow, and execution nodes in BTs.
capabilities rely on a semantic lexicon that links words and
(b) BT design template for the tactical layer of robots
phrases with meanings grounded in a resident ontology.
running the HARMONIC architecture. (c) Sample BT on
The language analyzer treats a large range of complex
UGV.
linguistic phenomena (lexical disambiguation, reference res-
olution, ellipsis reconstruction, new-word learning, etc. [7]) BTs for HARMONIC robots follow a design templateprioritizing safety and needs [40], as shown in Fig. 2. The subordinate’s script for collaboration is:
Collisionavoidancesubtreesareplacedleftmost,followedby
@COLLABORATIVE-ACTIVITY (subordinate)
robotneedssubtrees,thenactioncommandsubtreestriggered [INIT]
by the strategic layer. Fallback subtrees on the far right
*identify-team-members
[WAIT-FOR-PLAN]
provide actions when the robot is idle or other conditions // Wait for a plan from the leader before
// continuing.
aren’t met, such as random walks or waiting at the base
AWAIT $.HAS-COLLABORATIVE-PLAN ISA @EVENT
station.Thisstructureleveragestheleft-to-rightexecutionof [RUN-PLAN]
// The subordinate has no plan yet.
BTs to ensure proper prioritization of tasks.
Thetranslationoftheaction commandstotheappropriate As the leader begins to process the meta-plan, it will
state flags and control variables is done through the action select the domain plan to pursue. In the example below,
data communication APIs, which modify the placeholder the selected plan is SEARCH-FOR-LOST-OBJECT. The
variables in the State Manager on the tactical layer. details of the selected plan can be placed into the [RUN-
PLAN] section of collaborative activity, and any precondi-
VI. DEVELOPMENTOFDISTRIBUTEDPLANS
tions that must be resolved can be added to the [PRECON-
In this section, we show how robots implemented in DITIONS] section. An excerpt from the leader’s script for
HARMONIC carry out a search task. They decide to act COLLABORATIVE-ACTIVITY is shown below.
based on reasoning carried out in the strategic layer. Their
@COLLABORATIVE-ACTIVITY (leader)
plans(whichareinstancesofontologicalscripts)aredivided [INIT]
into steps that are communicated to the tactical layer by
*identify-team-members
[SELECT-PLAN]
means of action commands. // Select a plan from available options.
RUN *identify-candidate-plans
A. High-level planning RUN *select-plan
[PRECONDITIONS]
The ontologies of agents in HARMONIC contain scripts // Preconditions from the selected plan
// to be checked.
for complex events that a particular agent can perform or RUN NEW @REQUEST-OBJECT-TYPE
understand other agents performing. Plans are as instances RUN NEW @REQUEST-OBJECT-FEATURES
RUN NEW @REQUEST-LAST-SEEN-AT
ofscripts,withparametervaluessetforthesituationathand. RUN NEW @REQUEST-LOCATION-CONSTRAINED
Plans are instantiated by executing one or more of onto- [SUGGEST-PLAN]
// Propose the selected plan to the team.
logically stored meta-plans, that is, plans that HARMONIC RUN NEW @PROPOSE-PLAN
robots instantiate to guide the generation of plans in their [RUN-PLAN]
// Execute the selected plan, step by step.
operational domain. One such meta-plan is the collaborative RUN NEW @SEARCH-FOR-LOST-OBJECT
@SEARCH-FOR-LOST-OBJECT
activity plan, whose purpose is to help agents operating in
[SEARCH-ZONES]
teams organize themselves to accomplish a goal. // Search in each ZONE the agent knows.
// Stop searching when the object has been located.
The details of the collaborative activity plan vary based
// Report the results (if necessary) to the team.
on the agent’s role in the team. For example, the team FOR #ZONE-1 IN #LOCATION-1.SEARCHABLE-ZONE
(or task) leader’s plan is typically more complex than the
RUN ASYNC AWAIT *search
INTERRUPT WHEN #OBJECT-1.LOCATION KNOWN
plans of its subordinates since team leaders select the plan RUN *consider-reporting
to accomplish the target goal, resolve preconditions, and
Once the leader has worked through the preconditions,
instruct their subordinates. Subordinates’ plans, by contrast,
it can move to SUGGEST-PLAN, in which it will share
include awaiting instructions from the leader and, passively
the domain plan with subordinates through natural language
absorbinganyotherrelatedinformationthatcomestheirway.
dialog. These agents will receive this information and adopt
Theleader’sscriptforcollaborationisshownbelow.Since
their assignment(s) within the suggested plan. This process
this is a meta-plan, it can be applied to many specific plans
results in the team adopting a shared collaborative plan.
and,startswithfewdetailspopulated.Partofitstaskistofill
intask-specificdetails.Selectcommentsareprovidedforthis VII. EVALUATION
human-readable formalism. For further information, please
A. Simulation Environment and Task Design
refer to [34], [35], [7].
WeevaluatedtheHARMONICframework’steamingstrat-
@COLLABORATIVE-ACTIVITY (leader)
[INIT] egyusingasimulatedsearchandretrievaltasksetinanapart-
*identify-team-members
ment environment, as illustrated in Figure 5. The scenario
[SELECT-PLAN]
// Select a plan from available options. involves a HMR team consisting of an unmanned ground
RUN *identify-candidate-plans
vehicle (UGV), a drone, and a human team member serving
RUN *select-plan
[PRECONDITIONS] astheteamleader.Theobjectiveistofindasetoflostkeys.
// Preconditions will be determined once
The human initiates the task by remotely communicating
// a plan has been picked.
[SUGGEST-PLAN] with the robotic team members.
// Propose the selected plan to the team.
The simulated apartment contains zones with varied robot
RUN NEW @PROPOSE-PLAN
[RUN-PLAN] accessibility,necessitatingcoordinatedefforts.Wecategorize
// The leader hasn’t picked a plan yet.
these as: a) spaces accessible to both robots, b) elevatedsurfaces accessible to only the drones, and c) spaces below within the team. For the current scenario, the UGV is the
surfaces accessible only to the UGVs, as shown in Fig. 3. robot team leader at the task level, making it responsible
Each zone comprises waypoints - strategically defined loca- for maintaining interactions with the human and the drone.
tions that are dynamically utilized by the strategic layer. For Currently, the leader assignment is randomized. In future
thisevaluation,wemanuallydesignatedthesewaypointsand work, we intend to develop and evaluate heuristic methods
zones. However, in the future this process will be automated for implementing dynamic team hierarchies. This approach
using machine learning models to classify and map zones willoptimizeleadershipselectionbasedoncontextualfactors
based on spatial characteristics and accessibility, which will and individual agent capabilities depending on the task.
enhance the system’s adaptability to new environments. In the tactical layer of both robots, sensor data is encoded
into data frames and periodically shared with the strategic
layer. Additionally, each robot incorporates reactive control
strategies for collision avoidance, that are embedded within
behavior trees in their respective tactical layers.
The UGV is a custom-designed robot featuring a manip-
ulator mounted atop a multidirectional mobile platform, as
illustrated in Fig. 4.a. The robot’s design allows it to access
all ground-level locations and maneuver under certain ob-
jects,enhancingitscapabilitytoperformintricatesearchand
manipulation tasks in confined spaces. Figure 2.c presents
an excerpt from the Behavior Tree (BT) running on the
Unmanned Ground Vehicle (UGV). This BT is based on the
template shown in Figure 2.a.
The drone, on the other hand, can effectively perform
search operations by scanning through a wide range of
environments with sensors to scan the objects below it, as
shown in Fig. 4.b. Its vertical mobility allows it to navigate
over obstacles and access areas that may be challenging for
the UGV (type-b zones).
Fig. 3: Zones in the search environment Since the robots communicate in natural language, their
dialog and actions are comprehensible to humans, and hu-
The simulation environment, developed using the Unity
mans can intervene when necessary.
game engine, incorporates abstracted versions of robot be-
haviors to reduce complexity. This approach allowed us to C. Collaborative Search for Lost Keys
focus on key aspects of the HARMONIC framework’s per- The simulation environment is connected to a chatroom
formance while simplifying the implementation of complex interface through which the human (Danny) communicates
robot actions that are not central to our current work. with the robots. A user interface (see Fig. 5) includes not
B. Heterogenous Robot Team Configuration only a chat window but additional widgets that display
the robots’ interpretations of language (TMRs) and visual
The simulations involved two robots, an Unmanned
inputs(VMRs), natural language renderings of the robots’
GroundVehicle(UGV)andadrone(Fig.4).Theserobotsare
thoughts, and their goal and plan agendas. This arrangement
both functionally and structurally heterogeneous [44], thus
illustratesthetransparencyoftherobots’operationsandpro-
providingadiverserangeofcomplementaryperspectivesand
vides insights into their cognitive processes. The discussion
capabilities to the team. Both robots are equipped with a
below makes reference to the labels in Fig. 5 1
suite of sensors that enable them with localization, collision
1) Task Initiation: The scenario begins with Danny, ini-
detection, and object recognition capabilities.
tiating the task by sending the robots a message (M1).
This input triggers the team leader (UGV) to place a
COLLABORATIVE-ACTIVITY on its agenda (Fig. 5.5)
andlaunchtheSEARCH-FOR-LOST-OBJECTplan.Con-
currently, the drone awaits instructions.
2) Information Gathering: The UGV proceeds to verify
preconditionsfortheSEARCH-FOR-LOST-OBJECTplan
(Fig. 5.5). Although the object type is already known, infor-
mationaboutitsfeaturesandlast-seenlocationwouldbeuse-
Fig. 4: (a) UGV for ground-level exploration. (b) Parrot
ful. The UGV queries Danny for this information (M2/M4),
drone conducting an aerial scan of objects.
andreceivesresponses(M3/M5).Thelatterresponseprompts
Eachrobotrunsitsowninstancesofthetacticalandstrate-
1A video of the complete simulation can be found at
gic modules, enabling decentralized planning and control https://youtu.be/LpuE0yN0SEIFig. 5: (1) Chat transcript between Danny and the robots. (2) UGV’s (leader) Text Meaning Representations (TMRs) (3, 6)
A sample Vision Meaning Representations (VMRs) of detected objects by the robots (5) Leader’s agenda. (4, 7) Complete
thought transcripts of UGV and Drone.
thesystemtoprioritizetheentry-waysub-zone(type-azone) geneous human-robot teams. The HARMONIC architecture,
in the search sequence. withitsdual-layerapproachthatcombinesstrategiccognitive
3) Search Execution: With preconditions met, the UGV processing and tactical control enables the embodiment of
instructs the drone to initiate the search (M6), and both cognitive architectures enhancing robots to exhibit metacog-
robots begin exploring their assigned areas. The individual nitive abilities, including team task understanding, episodic
tactical modules on the robots control the search process memory utilization, and multimodal perception interpreta-
using a waypoint strategy, while the strategic (cognitive) tion. By integrating natural language communication and
module maintains awareness of area existence without di- reasoningcapabilities,ourapproachfacilitatescomplexteam
rectly guiding robot navigation. This approach allows for interactions,enhancesexplainability,andbuildstrustthekey
efficient local path planning while preserving high-level factors in human-robot collaboration.
planning in the strategic layer. The glass-box nature of our system, unlike black-box
4) Communication and Coordination: Throughout the models based on LLMs or VLAs, provides transparency
search, robots report their findings to each other and the and interpretability to modules whose operation and output
human (M7-9). When a robot fails to locate the keys in a should be explainable to humans. Our demonstration system
searched area, it communicates this to its partner. ofasimulatedsearchtaskinvolvingtworobotsandahuman
5) TaskCompletion: TheVMRswidget(Fig.5.3andFig. teammate illustrates the potential for HARMONIC to be
5.6) displays the object detection results that the strategic appliedtoreal-worldapplications.Futureresearchwillfocus
layer processes from sensing frames communicated by the on expanding the range of tasks and scenarios in which
tacticallayer.Duringthesearchexecution,thestrategicmod- HARMONICagentscansuccessfullyoperate;enhancingthe
ule continuously analyzes the sensor data frames, grounding robots’learning capabilities;conductingreal-world trialsus-
theseVMRsagainsttheinstanceoftheKEYobjectstoredin ing physical robots to validate the framework’s effectiveness
its episodic memory. When the features match, the search is in diverse operational contexts; developing collaborative on-
haltedbyeitheroftherobots(leaderinthiscase),informsthe lineplanningstrategies;and,enhancingreal-timeadaptability
team (M8), and reports to Danny (M9). Notably, the UGV in dynamic environments.
usesdifferentlanguageconstructswhencommunicatingwith
ACKNOWLEDGMENT
thedroneversusDannyin(M9),demonstratingthecognitive
agent’s ability to generate context-appropriate language. This research was supported in part by grant ##N00014-
23-1-2060 from the U.S. Office of Naval Research. Any
VIII. CONCLUSIONANDFUTUREWORK
opinions or findings expressed in this material are those of
Thisworkpresentsasteptowardsthedevelopmentofcog- the authors and do not necessarily reflect the views of the
nitive robots capable of effectively collaborating in hetero- Office of Naval Research.REFERENCES [23] J. Allen, G. Ferguson, and A. Stent, “An architecture for more real-
isticconversationalsystems,”inProceedingsofthe6thinternational
[1] Y.Tong,H.Liu,andZ.Zhang,“Advancementsinhumanoidrobots: conferenceonIntelligentuserinterfaces,2001,pp.1–8.
Acomprehensivereviewandfutureprospects,”IEEE/CAAJournalof
[24] D.Traum,J.Rickel,J.Gratch,andS.Marsella,“Negotiationovertasks
AutomaticaSinica,vol.11,no.2,pp.301–328,2024.
in hybrid human-agent teams for simulation-based training,” in Pro-
[2] N.Sharma,J.K.Pandey,andS.Mondal,“Areviewofmobilerobots: ceedingsofthesecondinternationaljointconferenceonAutonomous
Applicationsandfutureprospect,”InternationalJournalofPrecision
agentsandmultiagentsystems,2003,pp.441–448.
EngineeringandManufacturing,vol.24,no.9,pp.1695–1706,2023.
[25] W. Swartout, “Lessons learned from virtual humans,” AI Magazine,
[3] A. Torreno, E. Onaindia, A. Komenda, and M. Sˇtolba, “Cooperative
vol.31,no.1,pp.9–20,2010.
multi-agent planning: A survey,” ACM Computing Surveys (CSUR), [26] S. Harnad, “The symbol grounding problem,” Physica D: Nonlinear
vol.50,no.6,pp.1–32,2017. Phenomena,vol.42,no.1-3,pp.335–346,1990.
[4] L.Antonyshyn,J.Silveira,S.Givigi,andJ.Marshall,“Multiplemobile
[27] D. Roy, “Grounding words in perception and action: computational
robottaskandmotionplanning:Asurvey,”ACMComputingSurveys,
insights,” Trends in cognitive sciences, vol. 9, no. 8, pp. 389–396,
vol.55,no.10,pp.1–35,2023.
2005.
[5] M. Natarajan, E. Seraj, B. Altundas, R. Paleja, S. Ye, L. Chen,
[28] P. Lindes, A. Mininger, J. R. Kirk, and J. E. Laird, “Grounding
R. Jensen, K. C. Chang, and M. Gombolay, “Human-robot teaming: language for interactive task learning,” in Proceedings of the First
grandchallenges,”CurrentRoboticsReports,vol.4,no.3,pp.81–100,
WorkshoponLanguageGroundingforRobotics,2017,pp.1–9.
2023.
[29] T. Silver, S. Dan, K. Srinivas, J. B. Tenenbaum, L. Kaelbling, and
[6] S.Nirenburg,T.Ferguson,andM.McShane,“Mutualtrustinhuman-
M.Katz,“Generalizedplanninginpddldomainswithpretrainedlarge
ai teams relies on metacognition,” in Metacognitive Artificial Intelli- languagemodels,”inProceedingsoftheAAAIConferenceonArtificial
gence, H. Wei and P. Shakarian, Eds. Cambridge University Press, Intelligence,vol.38,no.18,2024,pp.20256–20264.
2024.
[30] S. Nirenburg and V. Lesser, “Providing intelligent assistance in dis-
[7] M.McShane,S.Nirenburg,andJ.English,AgentsintheLongGame tributedofficeenvironments,”ACMSIGOISBulletin,vol.7,no.2-3,
ofAI:ComputationalCognitiveModelingforTrustworthy,HybridAI.
pp.104–112,1986.
MITPress,2024.
[31] L.A.Dennis,M.Fisher,N.K.Lincoln,A.Lisitsa,andS.M.Veres,
[8] V.Bhat,A.U.Kaypak,P.Krishnamurthy,R.Karri,andF.Khorrami,
“Practicalverificationofdecision-makinginagent-basedautonomous
“Grounding llms for robot task planning using closed-loop state systems,” Automated Software Engineering, vol. 23, pp. 305–359,
feedback,”arXivpreprintarXiv:2402.08546,2024.
2016.
[9] Z. Yang, S. S. Raman, A. Shah, and S. Tellex, “Plug in the safety
[32] M.Scheutz,J.Harris,andP.Schermerhorn,“Systematicintegrationof
chip:Enforcingconstraintsforllm-drivenrobotagents,”in2024IEEE
cognitive and robotic architectures,” Advances in Cognitive Systems,
InternationalConferenceonRoboticsandAutomation(ICRA). IEEE,
vol.2,pp.277–296,2013.
2024,pp.14435–14442.
[33] P. W. Schermerhorn, J. F. Kramer, C. Middendorff, and M. Scheutz,
[10] A. Padalkar, A. Pooley, A. Jain, A. Bewley, A. Herzog, A. Ir- “DIARC: a testbed for natural human-robot interaction.” in AAAI,
pan, A. Khazatsky, A. Rai, A. Singh, A. Brohan et al., “Open
vol.6,2006,pp.1972–1973.
x-embodiment: Robotic learning datasets and rt-x models,” arXiv
[34] J. English and S. Nirenburg, “OntoAgent: implementing content-
preprintarXiv:2310.08864,2023.
centric cognitive models,” in Proceedings of the Annual Conference
[11] A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, X. Chen, K. Choro- onAdvancesinCognitiveSystems,2020.
manski,T.Ding,D.Driess,A.Dubey,C.Finnetal.,“Rt-2:Vision-
[35] M.McShaneandS.Nirenburg,LinguisticsfortheAgeofAI. MIT
language-action models transfer web knowledge to robotic control,”
Press,2021.
arXivpreprintarXiv:2307.15818,2023. [36] M.ColledanchiseandP.O¨gren,BehaviortreesinroboticsandAI:An
[12] B. Horling and V. Lesser, “A survey of multi-agent organizational introduction. CRCPress,2018.
paradigms,” The Knowledge engineering review, vol. 19, no. 4, pp. [37] D.Kahneman,Thinking,fastandslow. macmillan,2011.
281–316,2004. [38] M. Iannotta, D. C. Dom´ınguez, J. A. Stork, E. Schaffernicht, and
[13] R. I. Brafman and C. Domshlak, “From one to many: Planning for
T. Stoyanov, “Heterogeneous full-body control of a mobile manip-
looselycoupledmulti-agentsystems.”inICAPS,vol.8,2008,pp.28–
ulatorwithbehaviortrees,”arXivpreprintarXiv:2210.08600,2022.
35.
[39] M.Olsson,“Behaviortreesfordecision-makinginautonomousdriv-
[14] C.Amato,G.Konidaris,G.Cruz,C.A.Maynor,J.P.How,andL.P.
ing,”2016.
Kaelbling,“Planningfordecentralizedcontrolofmultiplerobotsunder
[40] S.Oruganti,R.Parasuraman,andR.Pidaparti,“KT-BT:aframework
uncertainty,” in 2015 IEEE international conference on robotics and
forknowledgetransferthroughbehaviortreesinmultirobotsystems,”
automation(ICRA). IEEE,2015,pp.1241–1248. IEEETransactionsonRobotics,2023.
[15] C. Le Pape, “A combination of centralized and distributed methods
[41] ——,“IKT-BT:indirectknowledgetransferbehaviortreeframework
for multi-agent planning and scheduling,” in Proceedings., IEEE formulti-robotsystemsthroughcommunicationeavesdropping,”arXiv
InternationalConferenceonRoboticsandAutomation. IEEE,1990, preprintarXiv:2312.11802,2023.
pp.488–493.
[42] A. Shoulson, F. M. Garcia, M. Jones, R. Mead, and N. I. Badler,
[16] E. Schneider, E. I. Sklar, S. Parsons, and A. T. O¨zgelen, “Auction- “Parameterizing behavior trees,” in Motion in Games: 4th Interna-
basedtaskallocationformulti-robotteamsindynamicenvironments,” tionalConference,MIG2011,Edinburgh,UK,November13-15,2011.
in Towards Autonomous Robotic Systems: 16th Annual Conference, Proceedings4. Springer,2011,pp.144–155.
TAROS2015,Liverpool,UK,September8-10,2015,Proceedings16.
[43] M.ColledanchiseandL.Natale,“Ontheimplementationofbehavior
Springer,2015,pp.246–257. treesinrobotics,”IEEERoboticsandAutomationLetters,vol.6,no.3,
[17] C.BoutilierandR.I.Brafman,“Partial-orderplanningwithconcurrent
pp.5929–5936,2021.
interactingactions,”JournalofArtificialIntelligenceResearch,vol.14,
[44] S. Oruganti, R. Parasuraman, and R. Pidaparti, “Impact of hetero-
pp.105–136,2001.
geneityinmulti-robotsystemsoncollectivebehaviorsstudiedusinga
[18] G. K. Soon, C. K. On, P. Anthony, and A. R. Hamdan, “A Review search and rescue problem,” in 2020 IEEE International Symposium
on Agent Communication Language,” Lecture Notes in Electrical on Safety, Security, and Rescue Robotics (SSRR). IEEE, 2020, pp.
Engineering,vol.481,pp.481–491,2019.
290–297.
[19] C. Schlenoff, E. Prestes, R. Madhavan, P. Goncalves, H. Li, S. Bal-
akirsky,T.Kramer,andE.Miguelanez,“Anieeestandardontologyfor
roboticsandautomation,”in2012IEEE/RSJinternationalconference
onintelligentrobotsandsystems. IEEE,2012,pp.1337–1342.
[20] O. Lemon, “Conversational ai for multi-agent communication in
natural language,” AI Communications, vol. 35, no. 4, pp. 295–308,
2022.
[21] H.H.Clark,Usinglanguage. Cambridgeuniversitypress,1996.
[22] G.Klein,P.J.Feltovich,J.M.Bradshaw,andD.D.Woods,“Common
groundandcoordinationinjointactivity,”Organizationalsimulation,
vol.53,pp.139–184,2005.