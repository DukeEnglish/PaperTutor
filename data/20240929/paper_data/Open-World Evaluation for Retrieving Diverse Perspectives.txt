Open-World Evaluation for Retrieving Diverse Perspectives
Hung-TingChen and EunsolChoi
DepartmentofComputerScience
NewYorkUniversity
{hung-ting.chen, eunsol}@nyu.edu
Abstract models(LLMs)togenerateananswerthatencom-
passesdiverseperspectivesonitsownischalleng-
Westudyretrievingasetofdocumentsthatcov- ing(Sorensenetal.,2024;Hayatietal.,2023a),and
ersvariousperspectivesonacomplexandcon-
retrieval-augmentation(DivekarandDurrett,2024)
tentiousquestion(e.g.,willChatGPTdomore
canfacilitateLLMstogeneratemorecomprehen-
harm than good?). We curate a Benchmark
siveanswersthatrepresentdiverseperspectives.
forRetrievalDiversityforSubjectivequestions
Therefore,westudyretrievaldiversity,evaluat-
(BERDS),whereeachexampleconsistsofa
question and diverse perspectives associated ing whether a set of top-scored outputs from the
with the question, sourced from survey ques- retrievalsystemcoverdiverseperspectivesforan
tionsanddebatewebsites. Onthisdata,retriev- input query. We loosely define perspective as a
erspairedwithacorpusareevaluatedtosurface particular attitudeor viewpointtowards theques-
adocumentsetthatcontainsdiverseperspec-
tionexpressedtowardstheinputquery. Figure1
tives. Ourframingdivergesfrommostretrieval
showsexamplesofpossibleperspectivesfordiffer-
tasksinthatdocumentrelevancycannotbede-
entinputquestions. Totacklethistask,wecuratea
cided by simple string matches to references.
Instead,webuildalanguagemodelbasedau-
BenchmarkforRetrievalDiversityforSubjective
tomaticevaluatorthatdecideswhethereachre- questions, BERDS, which contains 3K complex
trieveddocumentcontainsaperspective. This questions, each paired with on average 2.3 per-
allowsustoevaluatetheperformanceofthree spectives. Thequestionscomefromthreesources:
differenttypesofcorpus(Wikipedia,websnap-
surveyquestioncollection(Santurkaretal.,2023),
shot, and corpus constructed on the fly with
debatequestioncorpus(Wachsmuthetal.,2018),
retrievedpagesfromthesearchengine)paired
and newly scrapped data from a debate platform
withretrievers. Retrievingdiversedocuments
(Kialo)withargumentmaps.
remainschallenging,withtheoutputsfromex-
isting retrievers covering all perspectives on Existing retrieval benchmarks are either eval-
only33.74%oftheexamples. Wefurtherstudy uated through string match to reference an-
the impact of query expansion and diversity- swers (Karpukhin et al., 2020b) or exact match
focusedrerankingapproachesandanalyzere- to the annotated document index in the cor-
trieversycophancy. Together,welaythefoun-
pus(Thakuretal.,2021;Xiaoetal.,2024). Wedo
dation for future studies in retrieval diversity
notassumeacorpuswithgolddocumentannotated
handlingcomplexqueries.
and evaluate retrievers in an open-world setting
(i.e.,withoutassumingspecificknowledgesources).
1 Introduction
Toevaluateinthismorerealisticscenario,wede-
Given a complex and contentious question (Xu velopanLLM-basedautomaticevaluatorthatdeter-
etal.,2024),suchas“WillChatGPTdomoreharm minesifadocumentcontainsacertainperspective.
than good?”, a retrieval system should be able to Weevaluatetheperformanceofaretrieverpaired
surfacediverseopinionsintheirtopretrievalout- with a corpus. To quantify retrieval perspective
puts. However,existinginformationretrieval(IR) diversity,wemodifytheevaluationmetricusedin
tasks and systems mostly optimize for relevance multi-answerretrieval(Minetal.,2021b),where
to the question, ignoring diversity. Surfacing di- eachquestionispairedwithmultiplevalidfactoid
versedocumentscanbeusefultotheusersdirectly, answers. MRECALL @k measureswhetheraset
but also can be improve retrieval-augmented lan- of top-k documents cover all valid perspectives.
guagemodels(RALMs). Promptinglargelanguage Figure 1 provides example instances in BERDS
1
4202
peS
62
]LC.sc[
1v01181.9042:viXraArguana OpinionQA Kialo
Does an increase in choice lead Do you feel safer with a gun in your What’s the best Twitter/X alternative?
Question to unhappiness and stress? household?
•The best Twitter/X alternative is Facebook.
•An increase in choice leads to •Having a gun in the household
Perspective unhappiness and stress. increases my sense of safety. •The best Twitter/X alternative is Kialo.
Set •An increase in choice does not •Having a gun in the household does •The best Twitter/X alternative is Instagram.
lead to unhappiness and stress. not increase my sense of safety. •The best Twitter/X alternative is reddit.
Perspective Set:
Q Cu oes rpti uo sn (a Cn )d Outputs (D={d 1,d 2,d 3,...})
{p 1=ChatGPT will do more harm than good.,
p 2=ChatGPT will do more good than harm.}
d: … What is ChatGPT good at? [… ] It’s really p p any p
1 1 2 i
good at coding as in writing Python or SQL, and
Will ChatGPT do
so can help engineers become more productive … Perspective d
more harm than Retriever Detection 1
good? d: … At the most basic level, a chatbot is a Model d Prec@2=0.5
co2 mputer program that simulates and processes 2
Wikipedia human conversation (either written or spoken)… {d,d} MRecall@2=0.5
1 2
p p any p
Will ChatGPT do d: … What is ChatGPT good at? [… ] It’s really 1 2 i
1 Perspective
more harm than good at coding as in writing Python or SQL,… d
Retriever Detection 1
good W? eb gd 2 e: t … an S swtu ed re sn ft os r a thre e iu r s hin og m i et w(C oh rka ,t ,G thP eT y) a ws il la s w ufa fy e rt . o Model d 2 Prec@2=1
snapshot {d,d} MRecall@2=1
1 2
Figure1: Overviewofourbenchmarkandtask. Theupperpartshowsexampleinstances. Eachinstanceconsistsof
aquestionandaperspectiveset. Thelowerpartillustratesthetask. Theretrieverwillreturnasetofdocuments,and
weevaluatewhethertheretrievedset(inthisexample,consistingoftwodocuments)containsmultipleanswers
orperspectives. MRecallmeasuresthecoverageofanswersandperspectives, andprecisionmeasureswhether
eachdocumentcontainsanyperspectives. Aseparatemodule(denotedas“PerspectiveDetection”)isdevelopedto
determinewhetheradocumentcontainsacertainperspective. WeexperimentwithretrievingfromWebcorpora
insteadofWikipedia,whichprovidesinsufficientinformationforthetask.
andillustratestheproposedtask. ates multiple perspectives regarding the question
usingLLM(GPT-4)andusesthemtoguidediverse
Havingconstructedanevaluationframework,we
retrieval. Encouragingly, both methods showed
testretrievers(Robertsonetal.,2009;Karpukhin
stronggainsondensebaseretriever(Izacardetal.,
et al., 2020a; Izacard et al., 2022) and different
2022). We further provide rich analysis studying
corpus. Given the subjectivity of the questions
thecoverageofeachcorpus,retrieversycophancy,
weconsider,Wikipediaaloneisinsufficientforan-
andwhetherretrieversprefersupportingoroppos-
sweringmanyquestionsinourproposeddatasets.
ingperspectivestotheinputquery.
Therefore, we use Sphere (Piktus et al., 2021), a
All our code, data, and trained model check-
subset of a web snapshot (CCNet (Wenzek et al.,
pointsarereleasedathttps://timchen0618.gi
2020)), and a retrieval corpus built on the fly for
thub.io/berds/topromotefutureworkinstudy-
eachquestionfromtheGooglesearchengineout-
ingretrievaldiversityforcomplexquestions.
put. Wefindthatpairingadenseretrieverwithweb
corpora(SphereandGoogleSearch)yieldsmore
2 RelatedWork
diverseoutputscomparedtoothersettings. Yet,our
experimentalresultsuggeststhatcurrentretrievers
DiversePerspectives Humansocietypossesses
surfacerelevantdocumentsbutcannotpresentdoc-
pluralistic values (Sorensen et al., 2024) and ex-
ument sets with diverse perspectives, even when
hibitsdiverseperspectivesinvariousscenarios,in-
retrievingfromtheweb.
cludingresponsestosurveyquestions(Santurkar
To enhance the diversity of the retrieval re- et al., 2023; Durmus et al., 2023), news edito-
sults,weimplementsimplere-ranking(Carbonell rials (Liu et al., 2021), and stance with respect
and Goldstein, 1998) and query expansion ap- to debate or controversial questions (Chen et al.,
proaches (Mao et al., 2021). The former re- 2019, 2022b; Wan et al., 2024). Hayati et al.
computesthescoresforeachdocumentbypenal- (2023b) looks into eliciting diverse perspectives
izingdocumentsthataresimilartothedocuments from LLM on social norm topics. Wan et al.
that were retrieved before. The latter first gener- (2024) studies LLM generation when in-context
2documentsprovidecontradictingstatements. Con- numberortypeofperspectives.
current work (Xu et al., 2024) studies evaluating
Retrieval from the Web Piktus et al. (2021)
perspectivediversityofdebatablequestions. One
proposes to retrieve from the web to account for
way to encourage diversity in LLM output is re-
theopen-domainnatureofreal-worldknowledge-
trievalaugmentation,byprovidingdocumentswith
intensive applications. Previous works explored
diverseperspectives. Wefocusondiverseretrieval
retrievalwithsearchengines(e.g. GoogleSearch
insteadofgenerationfromLLMs.
API) to help fact-checking (Chen et al., 2024),
RetrievalDiversity Previousworkshaveinvesti-
open-domainquestion-answering(Lazaridouetal.,
gatedretrievaldiversityinthecontextofentityam-
2022), answer-editing (Gao et al., 2023a), and
biguity(Clarkeetal.,2008;Agrawaletal.,2009;
retrieval-augmented generation (Li et al., 2023).
Wang et al., 2017). Closer to our definition of
OtherworkshaveinvestigatedattributingLMout-
diversity, Chen et al. (2019) propose a task sub-
puts to evidence documents retrieved from the
stantiated perspective discovery, where systems
web(Malaviyaetal.,2023;Gaoetal.,2023b).
aresupposedtodiscoveradiversesetofperspec-
tives taking stance against a given claim. Chen 3 TaskFormulation
etal.(2022b)furtherarguesfortheneedofamulti-
perspectivesearchenginethatprovidesmoredirect The retrieval system will be provided a question
anddiverseresponses. Despitetheseefforts,there q and a corpus C, and return a ranked list of k
isnoexistingbenchmarkforretrievingdiverseper- documents, D = {d 1,d 2,...,d k}, where d i ∈ C
spectivesinrealisticcorpora. Tofacilitateprogress and d i is the i-th most relevant document in the
towardsretrievingdiverseperspectivesforsubjec- corpustothequestionq.
tivequestions,weformalizethetaskandconstruct
Background: Multi-answerRetrieval Inearlier
abenchmarkforevaluation,pairedwithautomatic
work(Robertsonetal.,2009;Voorheesetal.,1999;
evaluationmetrics. Concurrentwork(Ziemsetal.,
Chenetal.,2017;Leeetal.,2019),eachquestion
2024)studiesthebiasofretrievalsystemsalonga
q isassumedtohaveasinglegoldanswera. Thus,
singlepolaraxis(e.g. capitalismvs. socialism)for
thesystemisevaluatedbyassigningabinarylabel,
debatablequestionsanddevelopsanunsupervised
automaticmetric.
RECALL@k,indicatingifanydocumentd
i
inthe
retrieveddocumentsetD containsa.
Concurrentwork(Zhaoetal.,2024)exploresthe
Min et al. (2021b) extended retrieval task to
perspective-awarenessofretrievalsystems,where
cover questions that have multiple valid answers.
theyrepurposeexistingdatasetstobuildaretrieval
Here, each question q is paired with gold answer
benchmarkwherequeriesaresupplementedwith
set{a ,a ,...a }whereeachgoldanswera isa
a perspective. While sharing a similar goal, they 1 2 m i
short string. The goal is to retrieve a diverse set
evaluate retrieval with perspectives as input and
of documents such that the retrieval output will
measureifsystemsfollowthem,whileinourset-
contain all m answers. New evaluation metric
tingstheretrieversarenotgiventargetperspectives.
Furthermore,ourworkexpandsknowledgesources
MRECALL @ k is defined as (1) when number
significantlyusingawebcorpus,whiletheirwork
of answers m > k, MRECALL @ k = 1 if the re-
trieveddocumentsetD containsallk answers. (2)
focusesonmuchsmallercorpora.
whenm ≤ k,MRECALL@k =1iftheretrieved
StanceDetection (Mohammadetal.,2016;Al-
document set D contains all m answers. Other-
DayelandMagdy,2021)evaluatesifapieceoftext
wiseMRECALL@k =0. Simplestringmatching
supports a target (an entity, idea, opinion, claim,
determinesifadocumentd containsanswera.
i
etc.). Senetal.(2018)investigatemulti-perspective
questionsinhealthinformationandproposemeth- Ours: Multi-perspectiveRetrieval Weconsider
ods to classify search results according to their questions on subjective topics that could be ap-
stancetowardsthequestion. Wanetal.(2024)de- proachedfromdifferentperspectives,andthereis
terminesthestanceofsearchresultstocontentious nofixedorcompletesetofreferenceanswers. We
questionsusingLLMs. Ourperspectivedetection assumeasetofmperspectives{p ,p ...,p }for
1 2 m
(Section3)subsumesstancedetection,whichclas- addressingquestionq. Thegoalofaretrieveristo
sifies the target as positive or negative (binary). output a diverse setof documents covering all m
Perspective detection can be generalized to any perspectives.
3Dataset #Total(Dev./Test) #p |p| Corpus Source #pas. #doc.
Arguana 1000(250/750) 2.0 12.71 Wikipedia Wikipedia 22M 5.9M
OpinionQA 1176(294/882) 2.0 16.51 Sphere CCNet 906M 134M
Kialo 1032(258/774) 2.9 12.49 GoogleSearchoutput 4461.7 74.2
All 3208(802/2407) 2.28 13.84
Table 2: Retrieval corpus statistics. # pas. denotes
thenumberofpassages;#doc. denotesthenumberof
Table1: Datasetstatistics. Thesecondcolumndenotes
documents,whereeachdocumentisa100-wordpassage.
thenumberofexamplesperdataset. Wespare25%of
For Google Search output, we construct a corpus for
each dataset as the development (Dev.) set, and use
eachexample,andwereporttheaveragestatisticsacross
theremainderasthetestset. #pdenotestheaverage
examples.
numberofperspectivesperquestion,and|p|denotesthe
averagenumberofwords(byNLTKword_tokenize)
ineachperspective.
fromeachother. Weprovidethedataselectionand
constructionprocessbelow.
EvaluationChallenges Decidingifadocument
4.1 DataConstruction
contains an answer can be approximated by sim-
ple string matching, but deciding if a document We aim to look for questions that elicit diverse
supportsaperspectiveisnontrivial. Themostaccu- valid perspectives naturally. Questions related to
ratemetricwouldbecollectinghumanjudgments. debatetopicswouldbegoodcandidatessincethey
However,thisisnotscalable,sowebuildamodel wouldinduceatleasttwocontradicting,validview-
thatapproximateshumanjudgment(presentedin points. Another natural choice is survey ques-
AppendixA).Werefertothistaskofdeterminingif tions,wherepeoplewouldexpressdifferingopin-
adocumentcontainsacertainperspectiveas“Per- ions. Wethuscollectquestionsfromadebateweb-
spective Detection”. We do not use off-the-shelf site (kialo.com) and a dataset of survey ques-
stancedetectionmodels(Zhangetal.,2023a;Al- tions, OpinionQA (Santurkar et al., 2023). We
turayeifetal.,2023)astheperspectivesmightnot alsogeneratequestionsfromArguana(Wachsmuth
bebinary. Asingledocumentcouldcontainmore etal.,2018),adatasetofcontradictingarguments.
thanoneperspective. WeprovideexamplesforeachdatasetinBERDS
inFigure1,anddatastatisticsinTable1. Forboth
Evaluation Metrics We use MRECALL @ k
Arguana and OpinionQA, we only consider two
frompriorwork(Minetal.,2021b). Thekeydif-
contradictoryperspectives,onesupportingandone
ferenceisinsteadofcheckingwhetheradocument
opposing. Theseperspectivesmaynotbeexhaus-
contains any of answer {a ,a ,...a }, we check
1 2 m tivebutcoverarangeofargumentsforthequestion.
whetheradocumentsupportsanyofperspectives
Weadditionallyprovideexamplesoftherawdata
{p 1,p 2...,p m}. We also report PRECISION @ k,
andgenerateddatainTable11.
thepercentageofdocumentsintheretrieveddoc-
ument set D that contain any perspectives. This Arguana is a dataset on the task of retrieving
measurestherelevanceoftheretrieveddocuments the best counterargument. As each instance in
tothequestion. the Arguana dataset contains contradicting argu-
Thisevaluationsetupdoesnotassumeannotated ments(thequeryanditscorrespondingcounterar-
“gold” documents or answers for each question, gument),itnaturallyinducestwodistinctperspec-
enablingcomparingdifferentcorpora. Weconsider tives. Wegeneratequestionsfromthecontradicting
thecorpusinSection4.2anddiscusstheeffectsof arguments, and then generate corresponding per-
corporainSection7. spectivesforeachargument,usingGPT-4.
Kialo Wecollect1,032questionsfromadebate
4 The BERDS Benchmark
website (kialo.com), which mostly consist of
The BERDS Benchmarkaimstomeasureretrieval Yes/Noquestions(91%). ForYes/Noquestions,the
diversityforquestionsthatareopinionatedorinvite websiteprovidessupportingstatementsconverted
diverseperspectives. Asingleinstancein BERDS fromthequestions. Weconsidertheprovidedstate-
willconsistofaquestionq andasetofmperspec- ment as one perspective and generate from it an
tives {p ,p ...,p }. Each perspective should be opposingperspectiveusingGPT-4. Fortherestof
1 2 m
relevant to the question and sufficiently different thequestions(9%)thatnaturallyinvitemorethan
4two perspectives (e.g. What’s the best Twitter/X Online Web Search: Google Search API In-
alternative?),wegeneratecorrespondingperspec- steadofbuildingastaticcorpusandretrievingdoc-
tives(e.g. ThebestTwitter/XalternativeisKialo) uments from it, one can use a web search engine
foreachanswer(e.g. Kialo)inthewebsite. toretrievenewdocumentsonthefly. Thisenables
thesystemtoaccessbigger,moreup-to-datesource
OpinionQA isadatasetofsurveyquestionson
documents. ThedownsideofusingwebsearchAPI
various topics including privacy, political views,
(Nakanoetal.,2021;Yoranetal.,2023)isthelack
and health, targeted toward the citizens of the
ofreproducibilityaswellaspotentiallyreturning
United States. The dataset originates from the
documentsfromlesscrediblesources.1
annual Pew American Trends Panel survey. The
We implement web search by retrieving docu-
datasetcontainsawiderangeofsurveyquestions,
ments from Google Search API.2 We first obtain
such as those asking about personal experiences
therawHTMLoftophundreddocuments,which
(Regardlessofwhetherornotyouownagun,have
arethenprocessedandconvertedtoplaintextusing
you ever fired a gun?). We filter such questions
html2text3 andreadability,4 followingChenetal.
bypromptingGPT-4,removing22.7%oftheques-
(2022a,2024). Wesplittheprocesseddocuments
tions(345outof1521intotal). Thesurveyques-
into100-wordsegmentsandtakeallthesegments
tionscomewithmultipleoptions,witheachrepre-
as the corpus. Unlike Wikipedia and Sphere, we
sentingacertaindegreeofsupportforthequestion.
buildaseparatecorpusforeachquestion.
Conditionedonthesurveyquestionandtheoptions,
weconverteachsurveyquestionintoanaturallan- 5 RetrievalApproaches
guage question and generate one supporting and
oneopposingperspectivewithGPT-4. Weconsiderasuiteofstandardretrievers(sparse
Weusegpt-4-0613forallthedatageneration. and dense) on our dataset. As these retrievers do
Alltheinputpromptsforgenerationcanbefound notencouragethediversityoftheiroutput,weim-
inAppendixB.1. Thetotalcostforgeneratingthe plementare-rankingmethodandaqueryexpansion
dataisabout$100USD. method.
4.2 RetrievalCorpus Baselines WeimplementBM25(Robertsonetal.,
2009),awidelyadoptedbag-of-wordretrievalfunc-
We consider three types of retrieval corpus:
tionconsideringtoken-matchingbetweenquestions
Wikipedia,websnapshot,andthewebitself. While
anddocuments. WeusetheLuceneSearcherofPy-
priorworkonfactoidQA(Chenetal.,2017;Lee
serinipackagetobuildtheWikipediacorpus. For
etal.,2019;Karpukhinetal.,2020a)focusedonre-
theSpherecorpus,weusethefaissindexprovided
trievingfromWikipediaonly,ourtask,designedto
by Piktusetal.(2021).
uncoverawiderangeofopinionsandperspectives,
We consider two dense retrievers,
willbenefitfromretrievingfromawebcorpus.
DPR (Karpukhin et al., 2020a) and CON-
Wikipedia WeconsidertheWikipediadumppro- TRIEVER (Izacard et al., 2022). The former is a
cessedby(Karpukhinetal.,2020a),consistingof dualencodertrainedwithcontrastivelearningon
disjoint100-wordsegments. theNaturalQuestions(NQ)dataset(Kwiatkowski
etal.,2019). Thelatterisanencodertrainedwith
Web Snapshot: Sphere Prior works on single-
aself-supervisedcontrastiveobjective. DPRuses
answer or multi-answer retrieval usually adopt
separate encoders for document and question
Wikipediaasthemainretrievalcorpus. However,
embeddings, and CONTRIEVER uses a shared
Wikipediaalonecannotcoveralltheinformation
encoder. Both models are initialized from a
required (Redi et al., 2020). This is even more
BERT-baseencoder. Weusetheversionof CON-
likelyasourquestionsareinherentlyopinionated
TRIEVER further fine-tuned on the MSMARCO
andWikipediatextsaresupposedtobeneutral. We
1Priorwork(Chenetal.,2024)studiedthereproducibility
proposetousetheSphere(Piktusetal.,2021)cor-
ofsearchAPIresults,comparingURLsbetweenthesetsof
pus, which is a subset of CCNet (Wenzek et al.,
documentsretrievedatdifferenttimestampswiththesame
2020),astheknowledgesource. Oneadvantageof query.Theyreportonly30%ofURLsoverlapwhenqueried
twomonthsapart.
retrievingfromwebcorpusoverusingacommer-
2https://serper.dev/
cialsearchengine(e.g. GoogleSearch)resultsis 3https://pypi.org/project/html2text/
reproducibility. 4https://github.com/buriy/python-readability
5Datasets Average
Corpus Model Arguana Kialo OpinionQA
Prec. MRec. Prec. MRec. Prec. MRec. Prec. MRec. Prec.@1
BM25 22.27 10.8 23.82 10.85 10.39 2.95 18.83 8.20 21.72
Wiki DPR 18.88 7.73 19.48 7.62 13.63 3.29 17.33 6.21 20.22
CONTRIEVER 35.79 19.2 32.97 15.63 23.99 8.28 30.92 14.37 36.85
BM25 44.96 27.6 43.33 24.16 50.11 22.45 46.13 24.74 51.26
Sphere DPR 10.80 4.00 13.85 5.43 8.34 2.15 11.00 3.86 11.65
CONTRIEVER 58.21 38.27 54.96 28.94 52.77 24.72 55.31 30.64 58.67
GoogleSearch BM25 35.15 21.07 35.43 22.61 41.27 21.09 37.28 21.59 43.02
Output CONTRIEVER 52.32 27.6 50.31 28.94 48.91 22.79 50.51 26.44 57.56
Table3: PerformanceofbaseretrieversonthetestsplitofBERDS.Inthelastthreecolumns,wereportmacro-
averageoverthethreedatasets.
dataset(Nguyenetal.,2016)afterself-supervised We take the top document from each document
learning, which performed better in the original set retrieved using the generated questions in
paper. a round-robin fashion k times to form a list of
n∗k documents. We then take the top k unique
Re-ranking We apply the Maximal Marginal
documentsfromthislist,skippingduplicateones,
Relevance (MMR) method (Carbonell and Gold-
as the same documents could be obtained from
stein, 1998), which uses the following selection
differentqueries. Wefollowtheorderinwhichthe
criteriaforre-ranking:
perspectives are generated. We include a visual
illustration in Appendix B.3. The prompts for
argmax[λSim (D ,Q)−(1−λ)maxSim (D ,D )]
1 i 2 i j
Di∈R\S Dj∈S generating the perspectives and examples are
(1)
inAppendixB.3andAppendixB.7.
whereRdenotesasetoftopretrieveddocuments
consideredforre-ranking(|R| = 100inourexper-
6 ExperimentalResults
iments),S denotesthedocumentsetthatisalready
selected,andλisahyperparameter. Wetuneλon
WereportMRECALL@5andPRECISION@5,7as
thedevelopmentsplit.5 Sim isthescorefromthe definedinSection3. Allevaluationmetricsrequire
1
retrieveritself. TocomputeSim ,weimplement judgingwhethereachretrieveddocumentcontains
2
theUniversalAnglEEmbedding(LiandLi,2023) aperspective(definedasperspectivedetection,and
toobtainthedocumentembeddingsandtaketheco- moredetailscanbefoundinAppendixA).Weuse
sinesimilaritybetweentwodocuments. Wechoose
afine-tunedMistral-7Bmodelastheevaluator.8
thisembeddingmodelasitisthetop-rankedopen Table 3 presents the performance of base re-
model on the MTEB leaderboard (Muennighoff trievers on BERDS using three retrieval corpus
etal.,2023)withlessthan1Bparameters(335M). described in Section 4.2. We do not report DPR
A more compact model is preferable as we com- resultsonGoogleSearchoutputsaswefinditdoes
pute document embeddings for the top hundred notgeneralizewellbeyondtheWikipediacorpus.
documentsperexample. Theexperimentaldetails Unlike prior work (Karpukhin et al., 2020a)
canbefoundinAppendixB.6. which assumes a gold corpus, our retrieval cor-
pusmightnotcontaindocumentsrepresentingdi-
Query Expansion Prior work on factoid
verseperspectivesontheprovidedquestion. Thus,
QA(Maoetal.,2021)showedthatfirstgenerating
theperformancemetricsreflectboththecoverage
ananswertothequestionwithLLMandthenusing
ofthecorpusandtheretriever’sabilitytosurface
thegeneratedanswertoaugmentthequestioncan
documents supporting diverse perspectives. We
improve retrieval. Similarly, we first generate
analyzethecoverageofeachcorpusinSection7.
multiple (n) perspectives on the given question
usingLLMs(inourcasegpt-4-0613),andquery Effect of Corpus. Comparing retrievers oper-
the retriever with each generated perspective.6 ating on Wikipedia and Sphere, most retrievers
achievehigher MRECALL and PRECISION when
5WenormalizetheSim scorestobebetween0and1,
1
andconsiderλvaluesof[0.5,0.75,0.9,0.95,0.99]. 7We additionally report the results for k = 10 in Ap-
6nisnotpredetermined; GPT-4couldgeneratevarying pendixC.1,whereverysimilartrendshold.
numbersofperspectives.n=6.1onaverage. 8Wewillopen-sourcethismodeltopromotefuturework.
6Default +Re-ranking +QueryExpansion
Corpus Retriever
Prec. MRec. Prec. MRec. Prec. MRec.
BM25 18.83 8.20 18.66(-0.9%) 8.03(-2.1%) 21.31(+13.2%) 10.39(+26.7%)
Wiki DPR 17.33 6.21 16.62(-4.1%) 6.06(-2.5%) 17.78(+2.6%) 6.65(+7.1%)
CONTRIEVER 30.92 14.37 27.89(-9.8%) 15.54(+8.2%) 33.23(+7.5%) 14.84(+3.3%)
BM25 46.13 24.74 45.43(-1.5%) 25.38(+2.6%) 44.16(-4.3%) 26.24(+6.1%)
Sphere DPR 11.00 3.86 8.16(-25.8%) 2.60(-32.6%) 6.20(-43.6%) 2.01(-48.0%)
CONTRIEVER 55.31 30.64 54.39(-1.7%) 33.55(+9.5%) 54.91(-0.7%) 33.74(+10.1%)
GoogleSearch BM25 37.28 21.59 36.75(-1.4%) 21.18(-1.9%) 44.87(+20.3%) 24.96(+15.6%)
Output CONTRIEVER 50.51 26.44 49.33(-2.3%) 26.56(+0.4%) 52.60(+4.1%) 24.83(-6.1%)
Table4:PerformancesonBERDSafterre-rankinganddiversity-awareretrieval.Eachcellreportsthemacro-average
over three datasets in BERDS. Bolded numbers are the best performance in each row. Blue numbers indicate
increasescomparedtothedefaultsetting.
retrieving from Sphere, except DPR. We hypoth- Corpus Model Avg.size(↓) %withintop100(↑)
esize that DPR is trained only on the documents BM25 29.8 41.5
Wiki DPR 30.9 36.7
fromtheWikipediacorpussothatitisnotgeneral-
CONT. 24.7 55.6
izingtothewebcorpus. Takingwebsearchresults
BM25 20.8 77.3
(Google Search) as a corpus shows improved di-
Sphere DPR 37.4 48.9
versityoverWikipedia,butlagsbehindretrieving CONT. 17.8 83.1
fromtheentireweb(Sphere). Thismightbecaused
BM25 21.0 72.1
Google
bythegapinthecorpussize–weonlytakethetop CONT. 18.2 76.2
100GoogleSearchresultsandbuildcorporawith
Table5: Theaveragesizeofthedocumentsetrequired
them(resultinginacorpussizeof4.4Kpassages
tocoverallperspectiveswithbaseretrievers. Theaver-
onaverage),whileSpherecontains906Mpassages.
agesizeisonlycomputedovertheexampleswherethe
setsofthetop100documentscontainallperspectives
Comparing Retrievers. Across all experimen-
(MRECALL@100=1),andwereport%ofdatathat
talsettings,CONTRIEVERachievesthehighestdi-
satisfiesthis(MRECALL@100)inthelastcolumn.
versity,followedbyBM25andDPR.BM25gen-
eralizes better than DPR, which is fine-tuned on
7 Analysis
NQwithWikipediacorpus. Eventhebestsetting
(CONTRIEVER onSphere)onlyachievesanaver- How many documents should one retrieve to
age MRECALL of 30.64. This indicates even the coverdiverseperspectives? Sofar,wehavere-
bestretrieverstrugglestoretrieveacomprehensive ported the performances of the retrieval outputs
set of documents. PRECISION @ 1 is as high as consisting of five documents and found that the
58.67,showingthatretrieverscouldsurfaceoneof model outputs do not cover diverse perspectives.
theperspectiveseffectively. If we consider up to the top 100 documents, can
we cover diverse perspectives? What is the aver-
Results: ApproachestoImproveDiversity We
age number of documents needed to be retrieved
report the results of re-ranking and query expan-
tocoverallperspectives? Table5reportsthesize
sionapproachesinTable4. Re-rankingimproves
of the retrieved document set needed to cover all
diversityonfourofeightretriever-corpussettings,
theperspectiveswithbaseretrievers. Wefindthat
atthecostof PRECISION forallsettings. Thelim-
thebestsetting(CONTRIVERwithSphere)canfind
itedperformancegainscouldbebecausesemantic
all the perspectives within the top 100 document
dissimilarity does not always infer differing per-
set83.1%ofthetime,andforthoseexamples,the
spectives. Itisencouragingthatweobservegainin
average number of documents required to cover
CONTRIEVERsettings,ourbestretriever. Queryex-
all the perspectives is 17.8. Other settings show
pansionimprovesthe PRECISIONforfivesettings
worseperformance,mostlyreflectingperformance
and boosts MRECALL for six settings (over 10%
reportedinTable3.
forthreeofthem). ThisindicatesthatGPT-4could
diversifythesearchspacebyprovidingquerieshint- Doretrieverspreferdocumentswithsupporting
ingdifferentperspectivestotheretrievers. Future oropposingperspectivestothequestion? Re-
workcanexplorecombiningbothapproaches. trieversoftenfailtosurfacedocumentsthatcover
71
Wiki_CONT.
0.8
0.6 Wiki_DPR
0.4
supportingperspective
both Wiki_BM25 defaultquery
none opposingperspective
0.2
supporting
0 10 20 30 40 50
opposing
Figure 3: Retriever sycophancy. X-axis reports the
0
BM. DPR CO. BM. DPR CO. BM. CO. propensity of retrieval output to prefer positive, the
∆= p−n,wherepisthenumberofretrieveddocuments
Wiki. Sphere Google p
thatcontainsupportingperspectiveandnisthenumber
Figure2: Wereportwhetherretrieverspreferthesup- ofretrieveddocumentsthatcontainopposingperspec-
portingortheopposingperspectives. Resultsarecom- tive. Welabeleachsettingas[corpus]_[retriever].
puted on the top-5 documents aggregated over three Inallretrievers,usingsupportingperspectiveasquery
datasets. All retrievers favor the supporting perspec- leadstohighersupportiveleaning,andusingopposing
tives. BM.denotesBM25retriever,CO. denotesCON- perspectiveasqueryleadstolowersupportiveleaning.
TRIEVER,andWiki. denotestheWikipediacorpus.
percentages of documents containing supporting
comprehensiveperspectives. Canwecharacterize
andopposingperspectives,respectively. Greater∆
theperspectivethatismorelikelytobesurfaced?
indicates the retrievers favor the supporting per-
Wefocusonquestionswithonlytwoperspectives,
spectives more. We present the results on the
onetakingthesupportingstancetowardstheques-
tionandtheotheropposing.9 Wereportwhetherthe SpherecorpusinFigure3.10 Queryingtheretriev-
erswithsupportingperspectivesincreases∆across
topfivedocumentsobtainedbytheretrieverscover
the board, and retrieving with opposing perspec-
only supporting, opposing, both, or neither per-
tivesdecreases∆. Retrieverstendtofavorperspec-
spectivesinFigure2. Weobservethatallretrievers
tives that they are prompted with. This partially
retrieve the supporting perspectives significantly
explainsthegainsfromthequeryexpansion.
moreoftenwhentheyfailtoretrieveboth.
Retriever Sycophancy. Sycophancy refers to Is retrieval diversity limited by the corpora?
one’s tendency to tailor their response to please Unlikepriorwork,wedonotassumeagoldcorpus
theirinteractionpartner. Priorworkhasexplored that contains target information. The best MRE-
howLLMsexhibitsycophancy(Perezetal.,2023). CALL @5onBERDS achievedbyanyapproach
We examine if similar behavior is observed with onaverageisbelow35. Howmuchofthefailure
the retrievers; i.e. do retrievers favor documents iscausedbythelimitationofthecorpusorthatof
thatsharetheperspectivewiththequestion? For retrievers? Weanswerthisquestionbycomputing
example,wouldtheretrieverssurfacemoredocu- MRECALL overalargerdocumentset,wherewe
mentssupportingaperspective,“ChatGPTwilldo combinethetop100retrieveddocumentsfromall
moreharmthangood.”,iftheperspectiveisusedas retrieversforeachcorpus. Ifthisnumbernears100,
thequestionfortheretrievers,comparedtousing wecouldtheoreticallyfindanoptimalsubsetofk
“Chat GPT will do more good than harm" as the documents for each question that achieve MRE-
question? We conduct a controlled study where CALL@k closeto1. WepresenttheresultsinTa-
weinputeitherthesupportingoropposingperspec- ble6. OnlytheWikipediacorpuscontaininsuffi-
tivesasthequerytotheretriever,andobservethe cientlydiverseinformation,achievingMRECALL
changestotheirleaning. of62%whencombiningthreeretrieveroutputs. In
Wequantifyleaningtowardssupportingperspec- contrast, the web corpora do not limit retrievers’
tives to be ∆ = (p - n)/p, where p and n are the performancesindiversity. Thisresulthintsatgreat
9WeidentifythisbypromptingGPT-4;detailsandprompts 10Resultsontheothercorporashowthesametrends,except
canbefoundinAppendixB.8. forDPRonthewebcorpus.
8Corpus Arguana Kialo OpinionQA Average • ThemajorityofdataisGPT-4generated. We
do not have a guarantee of the data quality,
Wiki. 71.87 61.24 55.10 62.74
Sphere 92.80 85.27 89.46 89.18 butmanuallyinspectingasmallportionofthe
Google 82.67 82.69 77.66 81.01
dataindicatesthatitisnotaseriousissue.
Table6: MRECALL overtheunionofthetop100re-
Acknowledgements
trieveddocumentsfromallretrieversforeachcorpus.
ThesevaluesaresubstantiallyhigherthanMRECALL
We thank the members of UT NLP, especially
@5, suggestingthecorpora(especiallySphere)have
FangyuanXu,fortheirfeedbackonthedraft. The
goodinformationcoverage.
projectispartiallysupportedbyagrantfromOpen
PhilanthropyandNSFgrantRI-2312948. Wealso
roomforimprovementfortheretrievers. thankChitrankGuptaforcontributingtotheearlier
phaseofthiswork.
8 Conclusion
Westudyretrievaldiversityforcomplex,subjective References
questions. We curate a benchmark BERDS that
RakeshAgrawal,SreenivasGollapudi,AlanHalverson,
evaluates retrieval diversity, provides automatic andSamuelIeong.2009. Diversifyingsearchresults.
metrics, and reports the performances of several InProceedingsofthesecondACMinternationalcon-
ferenceonwebsearchanddatamining,pages5–14.
retrieverbaselines. Ourexperimentsshowthatcur-
rentretrieverscannotretrievecomprehensiveinfor-
AbeerAlDayelandWalidMagdy.2021. Stancedetec-
mationintheproposedsetting. tiononsocialmedia: Stateoftheartandtrends. In-
Once we retrieve a set of diverse documents, formationProcessing&Management,58(4):102597.
summarizingsuchrichinformationintoacoherent
NoraAlturayeif,HamzahLuqman,andMoatazAhmed.
response (Laban et al., 2022; Huang et al., 2023;
2023. Asystematicreviewofmachinelearningtech-
Zhangetal.,2023b)couldbeusefulfortheusers. niquesforstancedetectionanditsapplications. Neu-
Connecting our work, which enables uncovering ralComputingandApplications,35(7):5113–5144.
diverse documents, with summarization can be a
JaimeCarbonellandJadeGoldstein.1998. Theuseof
fruitfuldirectionforfuturework.
mmr, diversity-basedrerankingforreorderingdoc-
umentsandproducingsummaries. InProceedings
Limitations ofthe21stannualinternationalACMSIGIRconfer-
ence on Research and development in information
• The perspective set in our dataset is mostly retrieval,pages335–336.
binary(theaveragenumberofperspectivesis
DanqiChen,AdamFisch,JasonWeston,andAntoine
2.9forKialoand2.0forArguanaandOpin- Bordes.2017. ReadingWikipediatoansweropen-
ionQA).Morefine-grainedperspectivescould domainquestions. InProceedingsofthe55thAnnual
beexplored. Meeting of the Association for Computational Lin-
guistics(Volume1: LongPapers),pages1870–1879,
Vancouver,Canada.AssociationforComputational
• Our dataset covers debate and opinion sur-
Linguistics.
veyquestions. Exploringotherdomainslike
healthcarewouldbeaninterestingfuturedi- JifanChen,GraceKim,AniruddhSriram,GregDurrett,
andEunsolChoi.2024. Complexclaimverification
rection.
withevidenceretrievedinthewild. InProceedings
ofthe2024ConferenceoftheNorthAmericanChap-
• The evaluator LM has 7B parameters, mak- teroftheAssociationforComputationalLinguistics:
ing evaluation slow. Evaluating one dataset Human Language Technologies (Volume 1: Long
in BERDS using the evaluator takes about Papers),pages3569–3587,MexicoCity,Mexico.As-
sociationforComputationalLinguistics.
three hours on an NVIDIA A40 GPU. A
vLLM (Kwon et al., 2023) implementation JifanChen,AniruddhSriram,EunsolChoi,andGreg
reducestheevaluationtimeto15minutes. We Durrett.2022a. Generatingliteralandimpliedsub-
donotdiscusstheefficiencyaspectaswefo- questionstofact-checkcomplexclaims. InProceed-
ingsofthe2022ConferenceonEmpiricalMethods
cus on the accuracy of the evaluator. Future
inNaturalLanguageProcessing,pages3495–3516,
workcouldbuildmoretime-efficientevalua-
AbuDhabi,UnitedArabEmirates.Associationfor
torsthatareasaccurate. ComputationalLinguistics.
9Sihao Chen, Daniel Khashabi, Wenpeng Yin, Chris OrHonovich, RoeeAharoni, JonathanHerzig, Hagai
Callison-Burch,andDanRoth.2019. Seeingthings Taitelbaum,DoronKukliansy,VeredCohen,Thomas
fromadifferentangle:discoveringdiverseperspec- Scialom, Idan Szpektor, Avinatan Hassidim, and
tivesaboutclaims. InProceedingsofthe2019Con- Yossi Matias. 2022. TRUE: Re-evaluating factual
ferenceoftheNorthAmericanChapteroftheAsso- consistencyevaluation. InProceedingsofthe2022
ciationforComputationalLinguistics: HumanLan- Conference of the North American Chapter of the
guageTechnologies,Volume1(LongandShortPa- AssociationforComputationalLinguistics: Human
pers),pages542–557,Minneapolis,Minnesota.As- LanguageTechnologies,pages3905–3920,Seattle,
sociationforComputationalLinguistics. United States. Association for Computational Lin-
guistics.
SihaoChen,SiyiLiu,XanderUyttendaele,YiZhang,
WilliamBruno,andDanRoth.2022b. Designchal- Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,
lengesforamulti-perspectivesearchengine. InFind- YuanzhiLi, SheanWang, LuWang, WeizhuChen,
ingsoftheAssociationforComputationalLinguistics: etal.2021. Lora: Low-rankadaptationoflargelan-
NAACL2022,pages293–303,Seattle,UnitedStates. guagemodels. InInternationalConferenceonLearn-
AssociationforComputationalLinguistics. ingRepresentations.
Kung-HsiangHuang,PhilippeLaban,AlexanderRFab-
Charles LA Clarke, Maheedhar Kolla, Gordon V
bri,PrafullaKumarChoubey,ShafiqJoty,Caiming
Cormack, Olga Vechtomova, Azin Ashkan, Stefan
Xiong,andChien-ShengWu.2023. Embracediver-
Büttcher, and Ian MacKinnon. 2008. Novelty and
genceforricherinsights: Amulti-documentsumma-
diversityininformationretrievalevaluation. InPro-
rizationbenchmarkandacasestudyonsummariz-
ceedingsofthe31stannualinternationalACMSIGIR
ing diverse information from news articles. arXiv
conferenceonResearchanddevelopmentininforma-
preprintarXiv:2309.09369.
tionretrieval,pages659–666.
GautierIzacard,MathildeCaron,LucasHosseini,Sebas-
AbhishekDivekarandGregDurrett.2024. Synthesizrr: tianRiedel,PiotrBojanowski,ArmandJoulin,and
Generatingdiversedatasetswithretrievalaugmenta- EdouardGrave.2022. Unsuperviseddenseinforma-
tion. Preprint,arXiv:2405.10040. tionretrievalwithcontrastivelearning. Transactions
onMachineLearningResearch.
EsinDurmus,KarinaNyugen,ThomasILiao,Nicholas
Schiefer, Amanda Askell, Anton Bakhtin, Carol Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-
Chen, Zac Hatfield-Dodds, Danny Hernandez, sch,ChrisBamford,DevendraSinghChaplot,Diego
Nicholas Joseph, et al. 2023. Towards measuring delasCasas,FlorianBressand,GiannaLengyel,Guil-
the representation of subjective global opinions in laumeLample,LucileSaulnier,etal.2023. Mistral
languagemodels. arXivpreprintarXiv:2306.16388. 7b. arXivpreprintarXiv:2310.06825.
Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony VladimirKarpukhin,BarlasOguz,SewonMin,Patrick
Chen,ArunTejasviChaganty,YichengFan,Vincent Lewis,LedellWu,SergeyEdunov,DanqiChen,and
Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, and Wen-tau Yih. 2020a. Dense passage retrieval for
KelvinGuu.2023a. RARR:Researchingandrevis- open-domain question answering. In Proceedings
ingwhatlanguagemodelssay,usinglanguagemod- of the 2020 Conference on Empirical Methods in
els. InProceedingsofthe61stAnnualMeetingofthe NaturalLanguageProcessing(EMNLP),pages6769–
AssociationforComputationalLinguistics(Volume1: 6781, Online. Association for Computational Lin-
LongPapers),pages16477–16508,Toronto,Canada. guistics.
AssociationforComputationalLinguistics.
VladimirKarpukhin,BarlasOg˘uz,SewonMin,Patrick
Lewis,LedellYuWu,SergeyEdunov,DanqiChen,
TianyuGao,HowardYen,JiatongYu,andDanqiChen.
and Wen tau Yih. 2020b. Dense passage re-
2023b. Enablinglargelanguagemodelstogenerate
trievalforopen-domainquestionanswering. ArXiv,
textwithcitations. InProceedingsofthe2023Con-
abs/2004.04906.
ferenceonEmpiricalMethodsinNaturalLanguage
Processing,pages6465–6488,Singapore.Associa-
TomKwiatkowski, JennimariaPalomaki, OliviaRed-
tionforComputationalLinguistics. field,MichaelCollins,AnkurParikh,ChrisAlberti,
DanielleEpstein,IlliaPolosukhin,JacobDevlin,Ken-
Shirley Anugrah Hayati, Minhwa Lee, Dheeraj Ra- tonLee,KristinaToutanova,LlionJones,Matthew
jagopal,andDongyeopKang.2023a. Howfarcan Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob
weextractdiverseperspectivesfromlargelanguage Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-
models? criteria-baseddiversityprompting! arXiv ralquestions: Abenchmarkforquestionanswering
preprintarXiv:2311.09799. research. TransactionsoftheAssociationforCompu-
tationalLinguistics,7:452–466.
Shirley Anugrah Hayati, Minhwa Lee, Dheeraj Ra-
jagopal,andDongyeopKang.2023b. Howfarcan Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying
weextractdiverseperspectivesfromlargelanguage Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E.
models? criteria-baseddiversityprompting! ArXiv, Gonzalez, Hao Zhang, and Ion Stoica. 2023. Effi-
abs/2311.09799. cientmemorymanagementforlargelanguagemodel
10servingwithpagedattention. InProceedingsofthe HannanehHajishirzi,KentonLee,JennimariaPalo-
ACMSIGOPS29thSymposiumonOperatingSystems maki, et al. 2021a. Neurips 2020 efficientqa com-
Principles. petition: Systems,analysesandlessonslearned. In
NeurIPS2020CompetitionandDemonstrationTrack,
Philippe Laban, Chien-Sheng Wu, Lidiya Mu- pages86–111.PMLR.
rakhovs’ka,XiangChen,andCaimingXiong.2022.
Discordquestions: Acomputationalapproachtodi- Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina
versityanalysisinnewscoverage. InFindingsofthe Toutanova, andHannanehHajishirzi.2021b. Joint
AssociationforComputationalLinguistics: EMNLP passage ranking for diverse multi-answer retrieval.
2022, pages 5180–5194, Abu Dhabi, United Arab In Proceedings of the 2021 Conference on Empiri-
Emirates.AssociationforComputationalLinguistics. calMethodsinNaturalLanguageProcessing,pages
6997–7008,OnlineandPuntaCana,DominicanRe-
Angeliki Lazaridou, Elena Gribovskaya, Wojciech public.AssociationforComputationalLinguistics.
Stokowiec, and Nikolai Grigorev. 2022. Internet-
Saif Mohammad, Svetlana Kiritchenko, Parinaz Sob-
augmented language models through few-shot
hani, Xiaodan Zhu, and Colin Cherry. 2016.
prompting for open-domain question answering.
SemEval-2016 task 6: Detecting stance in tweets.
arXivpreprintarXiv:2203.05115.
InProceedingsofthe10thInternationalWorkshop
onSemanticEvaluation(SemEval-2016),pages31–
KentonLee,Ming-WeiChang,andKristinaToutanova.
41,SanDiego,California.AssociationforComputa-
2019. Latent retrieval for weakly supervised open
tionalLinguistics.
domainquestionanswering. InProceedingsofthe
57thAnnualMeetingoftheAssociationforComputa-
NiklasMuennighoff,NouamaneTazi,LoicMagne,and
tionalLinguistics,pages6086–6096,Florence,Italy.
NilsReimers.2023. MTEB:Massivetextembedding
AssociationforComputationalLinguistics.
benchmark. InProceedingsofthe17thConference
oftheEuropeanChapteroftheAssociationforCom-
JunyiLi,TianyiTang,WayneXinZhao,JingyuanWang,
putationalLinguistics,pages2014–2037,Dubrovnik,
Jian-YunNie,andJi-RongWen.2023. Thewebcan
Croatia.AssociationforComputationalLinguistics.
be your oyster for improving language models. In
FindingsoftheAssociationforComputationalLin-
ReiichiroNakano,JacobHilton,SuchirBalaji,JeffWu,
guistics:ACL2023,pages728–746,Toronto,Canada.
Ouyang Long, Christina Kim, Christopher Hesse,
AssociationforComputationalLinguistics.
ShantanuJain,VineetKosaraju,WilliamSaunders,
Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen
XianmingLiandJingLi.2023. Angle-optimizedtext
Krueger,KevinButton,MatthewKnight,Benjamin
embeddings. arXivpreprintarXiv:2309.12871.
Chess,andJohnSchulman.2021. Webgpt: Browser-
assisted question-answering with human feedback.
Siyi Liu, Sihao Chen, Xander Uyttendaele, and Dan
ArXiv,abs/2112.09332.
Roth. 2021. MultiOpEd: A corpus of multi-
perspective news editorials. In Proceedings of the TriNguyen,MirRosenberg,XiaSong,JianfengGao,
2021ConferenceoftheNorthAmericanChapterof Saurabh Tiwary, Rangan Majumder, and Li Deng.
theAssociationforComputationalLinguistics: Hu- 2016. Msmarco: Ahumangeneratedmachineread-
manLanguageTechnologies,pages4345–4361,On- ingcomprehensiondataset. choice,2640:660.
line.AssociationforComputationalLinguistics.
Ethan Perez, Sam Ringer, Kamile Lukosiute, Karina
Ilya Loshchilov and Frank Hutter. 2018. Decoupled Nguyen, Edwin Chen, Scott Heiner, Craig Pettit,
weightdecayregularization. InInternationalConfer- Catherine Olsson, Sandipan Kundu, Saurav Kada-
enceonLearningRepresentations. vath, Andy Jones, Anna Chen, Benjamin Mann,
Brian Israel, Bryan Seethor, Cameron McKinnon,
ChaitanyaMalaviya,SubinLee,SihaoChen,Elizabeth ChristopherOlah,DaYan,DanielaAmodei,Dario
Sieber, Mark Yatskar, and Dan Roth. 2023. Ex- Amodei,DawnDrain,DustinLi,EliTran-Johnson,
pertqa: Expert-curatedquestionsandattributedan- Guro Khundadze, Jackson Kernion, James Landis,
swers. arXivpreprintarXiv:2309.07852. Jamie Kerr, Jared Mueller, Jeeyoon Hyun, Joshua
Landau,KamalNdousse,LandonGoldberg,Liane
Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Lovitt, Martin Lucas, Michael Sellitto, Miranda
Shen,JianfengGao,JiaweiHan,andWeizhuChen. Zhang,NeeravKingsland,NelsonElhage,Nicholas
2021. Generation-augmented retrieval for open- Joseph, Noemi Mercado, Nova DasSarma, Oliver
domainquestionanswering. InProceedingsofthe Rausch,RobinLarson,SamMcCandlish,ScottJohn-
59thAnnualMeetingoftheAssociationforCompu- ston,ShaunaKravec,SheerElShowk,TameraLan-
tationalLinguisticsandthe11thInternationalJoint ham, Timothy Telleen-Lawton, Tom Brown, Tom
Conference on Natural Language Processing (Vol- Henighan,TristanHume,YuntaoBai,ZacHatfield-
ume1: LongPapers),pages4089–4100,Online.As- Dodds, Jack Clark, Samuel R. Bowman, Amanda
sociationforComputationalLinguistics. Askell,RogerGrosse,DannyHernandez,DeepGan-
guli, Evan Hubinger, Nicholas Schiefer, and Jared
SewonMin,JordanBoyd-Graber,ChrisAlberti,Danqi Kaplan.2023. Discoveringlanguagemodelbehav-
Chen, Eunsol Choi, Michael Collins, Kelvin Guu, iorswithmodel-writtenevaluations. InFindingsof
11theAssociationforComputationalLinguistics: ACL Ellen M Voorhees et al. 1999. The trec-8 question
2023,pages13387–13434,Toronto,Canada.Associ- answering track report. In Trec, volume 99, pages
ationforComputationalLinguistics. 77–82.
AleksandraPiktus,FabioPetroni,VladimirKarpukhin, HenningWachsmuth,ShahbazSyed,andBennoStein.
DmytroOkhonko,SamuelBroscheit,GautierIzacard, 2018. Retrievalofthebestcounterargumentwithout
PatrickLewis,BarlasOg˘uz,EdouardGrave,Wen-tau priortopicknowledge. InProceedingsofthe56th
Yih,etal.2021. Thewebisyouroyster-knowledge- AnnualMeetingoftheAssociationforComputational
intensivenlpagainstaverylargewebcorpus. arXiv Linguistics(Volume1:LongPapers),pages241–251,
preprintarXiv:2112.09924. Melbourne,Australia.AssociationforComputational
Linguistics.
MiriamRedi,MartinGerlach,IsaacJohnson,Jonathan
Morgan,andLeilaZia.2020. Ataxonomyofknowl- Alexander Wan, Eric Wallace, and Dan Klein. 2024.
edge gaps for wikimedia projects (second draft). Whatevidencedolanguagemodelsfindconvincing?
arXivpreprintarXiv:2008.12314. arXivpreprintarXiv:2402.11782.
StephenRobertson,HugoZaragoza,etal.2009. The Xiaojie Wang, Ji-Rong Wen, Zhicheng Dou, Tetsuya
probabilistic relevance framework: Bm25 and be- Sakai, and Rui Zhang. 2017. Search result diver-
yond. FoundationsandTrends®inInformationRe- sity evaluation based on intent hierarchies. IEEE
trieval,3(4):333–389. TransactionsonKnowledgeandDataEngineering,
30(1):156–169.
ShibaniSanturkar,EsinDurmus,FaisalLadhak,Cinoo
Lee, Percy Liang, and Tatsunori Hashimoto. 2023. GuillaumeWenzek,Marie-AnneLachaux,AlexisCon-
Whoseopinionsdolanguagemodelsreflect? arXiv neau, Vishrav Chaudhary, Francisco Guzmán, Ar-
preprintarXiv:2303.17548. mand Joulin, and Edouard Grave. 2020. CCNet:
Extracting high quality monolingual datasets from
Anirban Sen, Manjira Sinha, Sandya Mannarswamy, webcrawldata. InProceedingsoftheTwelfthLan-
and Shourya Roy. 2018. Stance classification of guageResourcesandEvaluationConference,pages
multi-perspectiveconsumerhealthinformation. In 4003–4012,Marseille,France.EuropeanLanguage
Proceedings of the ACM India joint international ResourcesAssociation.
conferenceondatascienceandmanagementofdata,
pages273–281. Chenghao Xiao, G Thomas Hudson, and Noura Al
Moubayed. 2024. Rar-b: Reasoning as retrieval
Taylor Sorensen, Jared Moore, Jillian Fisher, benchmark. Preprint,arXiv:2404.06347.
Mitchell Gordon, Niloofar Mireshghallah,
Christopher Michael Rytting, Andre Ye, Li- Rongwu Xu, Xuan Qi, Zehan Qi, Wei Xu, and Zhi-
weiJiang,XimingLu,NouhaDziri,etal.2024. A jiang Guo. 2024. Debateqa: Evaluating question
roadmap to pluralistic alignment. arXiv preprint answeringondebatableknowledge. arXivpreprint
arXiv:2402.05070. arXiv:2408.01419.
Gemma Team, Thomas Mesnard, Cassidy Hardin, Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan
RobertDadashi,SuryaBhupatiraju,ShreyaPathak, Berant. 2023. Making retrieval-augmented lan-
LaurentSifre,MorganeRivière,MihirSanjayKale, guage models robust to irrelevant context. ArXiv,
Juliette Love, et al. 2024. Gemma: Open models abs/2310.01558.
based on gemini research and technology. arXiv
preprintarXiv:2403.08295. BowenZhang,XianghuaFu,DaijunDing,HuHuang,
YangyangLi,andLiwenJing.2023a. Investigating
Nandan Thakur, Nils Reimers, Andreas Ruckl’e, Ab- chain-of-thoughtwithchatgptforstancedetectionon
hishekSrivastava,andIrynaGurevych.2021. Beir: socialmedia. arXivpreprintarXiv:2304.03087.
A heterogenous benchmark for zero-shot evalu-
ation of information retrieval models. ArXiv, YusenZhang, NanZhang, YixinLiu, AlexanderFab-
abs/2104.08663. bri, Junru Liu, Ryo Kamoi, Xiaoxin Lu, Caiming
Xiong, Jieyu Zhao, Dragomir Radev, et al. 2023b.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al- Fair abstractive summarization of diverse perspec-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay tives. arXivpreprintarXiv:2311.07884.
Bashlykov,SoumyaBatra,PrajjwalBhargava,Shruti
Bhosale, et al. 2023. Llama 2: Open founda- Xinran Zhao, Tong Chen, Sihao Chen, Hongming
tion and fine-tuned chat models. arXiv preprint Zhang, and Tongshuang Wu. 2024. Beyond rele-
arXiv:2307.09288. vance: Evaluateandimproveretrieversonperspec-
tiveawareness. arXivpreprintarXiv:2405.02714.
Lewis Tunstall, Edward Beeching, Nathan Lambert,
Nazneen Rajani, Kashif Rasul, Younes Belkada, Caleb Ziems, William Held, Jane Dwivedi-Yu, and
Shengyi Huang, Leandro von Werra, Clémentine DiyiYang.2024. Measuringandaddressingindex-
Fourrier, Nathan Habib, et al. 2023. Zephyr: Di- ical bias in information retrieval. arXiv preprint
rect distillation of lm alignment. arXiv preprint arXiv:2406.04298.
arXiv:2310.16944.
12A Identifyingwhetheraperspectiveis Models %Pos Acc F1
representedinadocument
Referencehuman 16.8 - -
Anotherhuman 22.7 85.2 65.8
Ourprimarygoalisdevelopingandevaluatingre- Random 16.8 72.1 16.9
trievalmethodsforuncoveringdiverseperspectives.
NLImodel(T5-11B) 7.2 85.2 38.5
To this end, we need a system that can identify Llama-2-13b-chat(zero-shot) 31.1 70.7 42.6
Llama-2-70b-chat(zero-shot) 27.4 77.7 52.6
whethertheretrieveddocumentsetcontainsaper-
Zephyr(zero-shot) 22.4 80.6 53.3
spective. UnlikesimplefactoidQAsetting,where
Gemma(zero-shot) 58.4 48.9 37.2
we can evaluate whether a document contains an Mistral-7B(zero-shot) 19.2 82.2 52.0
GPT-4(zero-shot) 17.4 87.6 65.6
answerbystringmatch(Leeetal.,2019;Minetal.,
2021a,b),evaluatingwhetheradocumentcontains GPT-4(one-shot) 15.4 89.1 67.8
Mistral-7B(fine-tuned) 15.8 87.6 62.2
aperspectiveisnontrivial,aresearchquestiononits
own(Senetal.,2018;AlDayelandMagdy,2021).
Table7: Perspectivedetectionresultsonhuman-labeled
Inthissection,weaimtobuildanefficientmodel
data(n=542). “Anotherhuman”performanceiscom-
forthissubtask, whichisanecessarycomponent putedbytakingonesetofhumanlabelsastheground
fortheevaluationofdiverseretrievalmodels. truthandtheotheraspredictionsonthe176examples
wherewecomputeinter-annotatoragreement.
TaskandMetric Givenaperspectiveandadoc-
ument,themodelassignsabinarylabely indicat- adocumentcontainsaperspective. Fromtheopen-
ingwhetherthedocumentcontainstheperspective. source LMs, we choose Llama-2-chat (Touvron
Then,wemeasuretheperformanceofamodelby et al., 2023), an instruct fine-tuned version of
comparingitspredictionwiththereferencelabel, Mistral-7B (Jiang et al., 2023), Zephyr-7B (Tun-
measuringaccuracyandF1score. stall et al., 2023), and Gemma-7B (Team et al.,
2024). Lastly, we use GPT-4 (gpt-4-0613). To
Reference Annotation For each document-
reachabetterabsoluteperformance,weaddition-
perspectivepair,weconsiderhumanjudgmentas
allyexperimentwithpromptingwithonein-context
thegoldlabel.
exampleforGPT-4.
The human-labeled test set contains 542
document-perspectivepairs, whichareannotated Fine-tuned LMs Prompting GPT4 showed
by the authors of this paper. We compute inter- promisingresultsinthistask,butitwouldrequire
annotator agreement on 176 examples, yielding additionalAPIcalls,whichincurextracost,when-
a Cohen Kappa agreement of 0.56. 16.8% of ever we would like to evaluate new systems on
the data receive a positive label. The examples BERDS.Wethusfine-tunetheMistral-7Bmodel
are taken from top five retrieval results from the withGPT-4predictionswithonein-contextexam-
SpherecorpuswithBM25(Robertsonetal.,2009) pleaslabels. Thefine-tuningdatasetcontains3K
and DPR (Karpukhin et al., 2020a) retriever de- examples corresponding to 50 unique questions,
scribed in Section 5, and equally split between and implementation details can be found in Ap-
three datasets. Details on the construction of the pendixB.5.
humanreferencesetcanbefoundinAppendixB.4.
A.2 Results
A.1 EvaluatedApproaches
We report the results on the human-labeled
Random Wereportabaselinethatrandomlyas- document-perspectives pairs in Table 7. The off-
signpredictionsy = 1or0accordingtothelabel the-shelf entailment model (T5) does not work
distributionofeachdataset. well,whereasGPT-4isthebestmodel. Fine-tuned
Mistral-7Bobtainsthebestresultsinopen-source
Off-the-shelfNLImodels Wecouldinterpret“a
models,surpassingLlama-2-70b-chat. Thepredic-
documentd containsperspectivep "as“apremise
i j
tion from fine-tuned Mistral-7B matches that of
d supports a hypothesis p ". Then it becomes
i j
GPT-4on94%ofinstances.
natural to use NLI models to identify whether a
As the fine-tuned Mistral-7B comes close to
perspectiveisrepresentedinadocument. Weusea
GPT-4performance,weusethismodelastheauto-
T5-11BmodelprovidedbyHonovichetal.(2022).
maticmetricforevaluatingretrievaldiversity,pro-
PromptedLMs InsteadofusinganNLImodel, viding an open-source model that enables repro-
wecanpromptlarge-scaleLLMtodecidewhether ducible,cheaperevaluation.
13Corpus BM25 DPR CONTRIEVER inAppendixB.4,excepton50questions,yielding
fivetimesmoredata.
Wikipedia 0.99 0.95 0.75
Sphere 0.99 0.99 0.95 The model is trained using an
GoogleSearchOutput 0.95 - 0.95 AdamW (Loshchilov and Hutter, 2018) opti-
mizerwithalinearlearningschedule. Weperform
Table 8: The λ value in Equation (1) for different a hyperparameter search on learning rates (1e-4
retriever-corpussetting. 2e-4 1e-5 2e-5 3e-5 5e-5), warmup ratio (0.1 0.3
0.5),numberoftrainingepochs(0.5,1,2,3,4),and
weight decay (1e-4, 0.001, 0.01, 0). We evaluate
B ExperimentalDetails
eachcheckpointonaseparatedevelopmentsetof
B.1 PromptsandExamplesforData 100 examples annotated by the author and select
Generation the model with the highest F1 score. The final
hyperparameters we decided on are learning of
Prompts for generating each dataset are shown
1e-4, a warmupratio of0.1, 2epochsof training,
in Tables 9, 10 and 12. Examples showing the
andaweightdecayof0.001.
generateddataanddatatakenfromthesourcecan
befoundinTable11.
B.6 DetailofRe-rankingExperiments
B.2 PromptsforPerspectiveDetection We compute the Sim 2 scores in Equation (1) by
taking the cosine similarity between two docu-
Promptsweuseforperspectivedetectionareshown
mentembeddingscomputedbyasentenceembed-
inTable15. Wepromptallmodelswiththeprompt
ding model, the UAE-Large-V1 model on hug-
inthetoprowinTable15,andadditionallyreport
gingface 11. We follow their documentation for
resultspromptingGPT-4withthein-contextexam-
non-retrievaltasksandsetthepooling-strategy
pleshowninthebottomrow(thelastrowandthe
=‘cls’. We do not specify any prompt for the
bestperformanceinTable7). Thelabelsofthedata
model so the embeddings are only on the docu-
usedtofine-tuneMistral-7Barepredictedwiththe
mentsthemselves.
one-shotprompt.
Sim are obtained from the implemented re-
1
trievermodel,andthustheycouldbeofdifferent
B.3 PromptsforQuery-Expansion
scales. WethennormalizetheSim scorestobe
1
Promptsweusetogenerateperspectivesforquery-
between[0,1]bydividingSim bythemaximum
1
expansionareshowninTable13.
scoreobtainedonthewholedataset,anddoagrid
searchonλovervalues[0.5,0.75,0.9,0.95,0.99].
B.4 DetailsonConstructingPerspective
The actual values we choose for each retriever-
DetectionTestSet
corpussettingareshowninTable8.
Eachexampleinthetestsetconsistsofaperspec-
B.7 ExamplesofGeneratedPerspectivesfor
tiveandadocument. Werandomlyselect10ques-
QueryExpansion
tionswithtwoperspectivesfromeachofthethree
datasets, yielding a total of 60 perspectives. For Wepresentexamplesofperspectivesgeneratedby
eachquestion,wetakethetopfiveretrieveddocu- GPT-4oneachdatasetinTable14. Eachperspec-
mentsfromeitherBM25orDPRresultsobtained tive has a name separated by “_", and the corre-
fromSphere. Thustherearetendocumentstotest spondingtext. Theaveragelengthofperspectives
for each perspective, resulting in 600 document- is43.98words.
perspectivepairs. Wethencheckfornear-duplicate
B.8 DetailsofDeterminingSupportingand
documentsandfilterout58examples,leavingus
OpposingPerspectives
with542examples.
Weidentifythesupportingandopposingperspec-
B.5 DetailsofFine-tuningMistral-7BModels tives by prompting gpt4-0613, and the exact
Wefine-tunetheMistral-7BmodelwithLoRA(Hu promptcanbefoundinTable16. Weonlyperform
etal.,2021)oneightNVIDIAA40GPUs. Wetrain suchaprocessforexampleswithtwoperspectives.
themodelon3KexamplesofGPT-4labeleddata
on perspective detection. The training dataset is
11https://huggingface.co/WhereIsAI/UAE-Large-V
constructed using the same process as described 1
14Setting Prompt
Question Document1: NaturalhabitatsbeingaredestroyedAtougherapproachtotheprotectionofanimalsisneededto
Generation preventtheirnaturalhabitatsfrombeingdestroyedbylocals.AshumansexpandtheiragriculturalactivityinAfrica
(2-shot) theyaredestroyingtheenvironmentsofendangeredanimalsandpushingotherstowardsbeingendangered.Dueto
anincreaseinlargescalecottonplantationsandfoodcrops,theWestAfricanlionhasseenamarkeddecreasein
population;numberinglessthan400inearly2014[1].Tougherprotection,suchasfencingoffareasfromhuman
activity,hasbeensuggestedandhasseensuccessinSouthAfrica[2].[1]BBC,“Lions‘facingextinctioninWest
Africa’”[2]Morelle,R.“Fencingoffwildlionsfromhumans‘couldsavethem’”
Document2:FewerhumandeathsFewerlargebeastswillleadtofewerdeathsinAfrica.Someendangeredanimals
areaggressiveandwillattackhumans. HippopotamuseskillinexcessofthreehundredhumansayearinAfrica,
withotheranimalssuchastheelephantandlionalsocausingmanyfatalities.[1]Footagereleasedinearly2014ofa
bullelephantattackingatourist’scarinKrugerNationalPark,SouthAfricademonstratedthecontinuedthreatthese
animalscause.[2]Tougherprotectionwouldresultinhighernumbersoftheseanimalswhichincreasestheriskto
humanlives.[1]AnimalDanger‘MostDangerousAnimals’[2]Withnall,A.‘Rampagingbullelephantflipsover
BritishtouristcarinKrugerPark’
Instruction: Giventhetwodocuments,generateaquestionwherebothdocumentscouldbevalidevidence. The
questionshouldbeconcise,andshouldnotcopyverbatimfromthedocuments.ItshouldbeaYes/Noquestionwhere
onedocumentwouldsupportthe"Yes"answerandtheotherwouldsupport"No".
Question:Shouldweencouragemoreintenseprotectionofendangeredspecies?
Document1: Allowingthesaleofgenericdrugswillnothelptheplightofthedevelopingworld. Manydrug
companiesinvestsubstantialamountsofmoney,gleanedfromthesaleofprofitabledugsinthedevelopedworld,into
researchingtreatmentsforthedevelopingworld.Withouttherevenuesavailablefrompatent-protecteddrugsales,
companies’profitswillfall,precipitatingareductioninprobonogivingandresearch.Allowingtheproductionof
genericdrugswillthusinthelongrunhurtthedevelopingworld.
Document2:Allowingproductionofgenericdrugssaveslives,particularlyinthedevelopingworldManydeveloping
countriesarefraughtwithterribledisease.MuchofAfricaandAsiaaredevastatedbymalaria,andinmanypartsof
AfricaAIDSisahorrendousscourge,infectinglargepercentagesofmanycountriespopulations.Forexample,in
Swaziland,26%oftheadultpopulationisinfectedwiththevirus1.Inlightoftheseobscenelyhighinfectionrates,
Africangovernmentshavesoughttofindmeansofacquiringenoughdrugstotreattheirailingpopulations. The
producersofthemajorAIDSmedicationsdodonatesubstantialamountsofdrugstostrickencountries,yetatthe
sametimetheychargeruinouslyhighpricesforthatwhichtheydosell,leadingtoseriousshortagesincountries
thatcannotaffordthem.Thedenialoftherighttoproduceoracquiregenericdrugsiseffectivelyadeathsentence
topeopleinthesecountries.Withgenericdrugsfreelyavailableonthemarket,theaccesstosuchdrugswouldbe
facilitatedfarmorereadilyandcheaply;priceswouldbepusheddowntomarketlevelsandAfricangovernments
wouldbeabletostandachanceofprovidingtherequisitecaretotheirpeople2.Underthecurrentsystemattemptsby
governmentstoaccessgenericdrugscanbemetbydenialsoffreetreatments,leadingtoevenfurthersuffering.There
isnoethicaljustificationtoallowpharmaceuticalcompaniestochargeartificiallyhighpricesfordrugsthatsavelives.
Furthermore,manyfirmsthatdevelopandpatentdrugsdonotsharethem,nordotheyactuponthemthemselves
duetotheirunprofitability.Thishasbeenthecasewithvarioustreatmentsformalaria,whichaffectsthedeveloping
worldalmostexclusively,thuslimitingthemarkettocustomerswithlittlemoneytopayforthedrugs3.Theresultis
patentsandviabletreatmentssittingonshelves,effectivelygatheringdustwithincompanyrecords,whentheycould
beusedtosavelives.Butwhenthereisnoprofitthereisnoproduction.Allowingtheproductionofgenericdrugsis
toallowjusticetobedoneinthedevelopingworld,savinglivesandendinghumansuffering.1UnitedNations.2006.
"CountryProgramOutlineforSwaziland,2006-2010".UnitedNationsDevelopmentProgram.Available:2Mercer,
Illana.2001."PatentWrongs".MisesDaily.Available:3Boseley,Sarah.2006."RichCountries’BlockingCheap
DrugsforDevelopingWorld’".TheGuardian.Available:
Instruction: Giventhetwodocuments,generateaquestionwherebothdocumentscouldbevalidevidence. The
questionshouldbeconcise,andshouldnotcopyverbatimfromthedocuments.ItshouldbeaYes/Noquestionwhere
onedocumentwouldsupportthe"Yes"answerandtheotherwouldsupport"No".
Question:Shouldweallowtheproductionofgenericdrugs?
Document1:[Doc1]
Document2:[Doc2]
Instruction: Giventhetwodocuments,generateaquestionwherebothdocumentscouldbevalidevidence. The
questionshouldbeconcise,andshouldnotcopyverbatimfromthedocuments.ItshouldbeaYes/Noquestionwhere
onedocumentwouldsupportthe"Yes"answerandtheotherwouldsupport"No".
Question:
Perspective Convertthequestionintoastatementwithoutaddinganyextrainformation.Thenalsogeneratethenegationofthis
Generation statement.
Question:[Question]
Table9: ThepromptweuseforgeneratingdataforArguana. [Doc1],[Doc2],and[Question]aresubstitutedwith
theactualdocumentsandquestionsduringgeneration. Thequestionisfirstgeneratedwiththepromptinthefirst
row,andthenperspectivesaregeneratedwiththepromptinthesecondrowbasedonthequestion.
15Type Prompt
Yes/No Giventhequestionandapositivestatement,generateastatementofoppositestancewithrespecttothequestion.
PositiveStatement:[Statement]
Question:[Question]
NegativeStatement:
Multi Giventheanswersandthequestion,generatestatementsthatarefollowedbyanewlinecharacter.Thestatement
shouldcloselyfollowtheformatofthequestion,andthestatementshouldonlydifferbythesegmentwherethe
answeris.
Question:[Question]
Answers:[Answers]
Statements:
Table10: ThepromptsweuseforgeneratingdataforKialo. Differentpromptsareusedaccordingtothedatatype
(whetherthequestionallowsmorethantwoperspectives). [Statement],[Question],and[Answers]aresubstituted
withthestatement,thequestion,andtheanswersprovidedbyKialo.comrespectivelyduringgeneration. Notethat
alistofanswersisonlyprovidedforthequestionswithmorethantwoperspectives.
Dataset OriginalData(ProvidedbytheSource) GeneratedData
Arguana Document1: Question:
Peoplearegiventoomuchchoice,whichmakesthem Doesanincreaseinchoiceleadtounhappinessand
lesshappy. Advertisingleadstomanypeoplebeing stress?
overwhelmedbytheendlessneedtodecidebetween SupportingPerspective:
competingdemandsontheirattention-thisisknown Anincreaseinchoiceleadstounhappinessandstress.
asthetyrannyofchoiceorchoiceoverload.... OpposingPerspective:
Document2: Anincreaseinchoicedoesnotleadtounhappiness
Peopleareunhappybecausetheycan’thaveevery- andstress.
thing,notbecausetheyaregiventoomuchchoiceand
finditstressful.Infact,advertisementsplayacrucial
roleinensuring...
Kialo (Yes/No Question: OpposingPerspective:
Question) WillChatGPTdomoreharmthangood? ChatGPTwilldomoregoodthanharm.
SupportingPerspective:
ChatGPTwilldomoreharmthangood.
Kialo (More Question: Perspective1:
than two per- What’sthebestTwitter/Xalternative? ThebestTwitter/XalternativeisFacebook.
spectives) Answer1:Facebook Perspective2:
Answer2:Kialo ThebestTwitter/XalternativeisKialo.
Answer3:Instagram Perspective3:
Answer4:Reddit ThebestTwitter/XalternativeisInstagram.
Perspective4:
ThebestTwitter/XalternativeisReddit.
...
OpinionQA OriginalQuestion: GeneratedQuestion:
Wouldhavingaguninyourhouseholdmakeyoufeel Doyoufeelsaferwithaguninyourhousehold?
[’Saferthanyoufeelwithoutaguninyourhousehold’, Perspective1:
’Lesssafethanyoufeelwithoutaguninyourhouse- Havingaguninthehouseholdincreasesmysenseof
hold’,’Nomoreorlesssafe’,’Refused’] safety.
Perspective2:
Havingaguninthehouseholddoesnotincreasemy
senseofsafety.
Table11: Anexampleofdataprovidedbytheoriginalsourcevs. generated. Datainthe“OriginalData”column
iseitherprovidedbythesourcedataset(ArguanaandOpinionQA)orKialo.com. Kialo.comprovidedifferent
informationfordifferenttypesofquestions(whetherthequestionisayes/noquestionornot). Questionsinblue
andperspectivesinredaretheonesweincludeinBERDS.
16Setting Prompt
QuestionFil- Determineifthequestionisaskingaboutpersonalexperienceorinformation. Replywithonly"Yes"or"No". Only
tering answer"Yes"if(1)Thequestionisaskingaboutifyouhaveeverdonesomethingorifsomethinghashappenedtoyou.
(2)Thequestionisaskingaboutfactsaboutyou,forexample,ifyouownsomething,orhowyoudescribeyourself.(3)
Thequestionisaskingaboutsomethingthathashappenedtoyourlocalcommunity,orthecurrentstatusofyourlocal
community. Youshouldanswer"No"ifthequestionisaskingaboutyouropinion,suchasifyouareworriedabout
somethingorwhatyouthinkaboutacertainsubject.
Question:[Question]
Answer:
DataGenera- ConvertthefollowingsurveyquestionintoaYes/Noquestion,withthefirstandthelastchoiceinthebracketsasthetwo
tion answers.Generatethequestionfirst,andthenconvertthequestionintoapositiveandanegativestatementthatsupports
andopposethequestionrespectively.Thestatementsshouldbeconciseandnotcontainanyadditionalinformationthatis
notinthequestion.Thestatementsshouldalsobefluentandgrammaticallycorrect.
Question:[Question]
Convertedquestion:
Table12:ThepromptweuseforgeneratingdataforOpinionQA.[Question]issubstitutedwiththeoriginalquestion,
whichcomeswithalistofoptions,intheOpinionQAdatasetduringgeneration. Wefirstfilteroutdatathatarenot
relatedtopersonalexperienceorfactsaboutthesurveytaker. Thenwegeneratequestionsandperspectivesbasedon
theoriginalquestionprovidedbyOpinionQA.
Generatediverseperspectivesthatanswerthegivenquestion.PleaseanswerwithaJSONobject,whereeachfieldisaperspective.Do
notgeneratesimilarperspectives;theyshouldbedistinct.ThekeysintheJSONobjectshouldbemeaningful,andeachwordinthekeys
shouldbeseparatedbywhitespace.
Question:[Question]
Table13: Theinputpromptforgeneratingdiverseperspectivesforqueryexpansion. [Question]issubstitutedwith
thequestionofeachexample. TheoutputwouldbeaJSONobjectcontainingtheperspectives.
Dataset Question GPT-4-GeneratedPerpsectives
Arguana Question: Increased_Choice_Leads_to_Paralysis:Anincreaseinchoicemayleadtofeelingsofunhappinessand
Doesanincrease stress,duetothedecisionparalysisphenomena.Withtoomanyoptions,individualsmaystruggletomakea
inchoiceleadto choiceandfearmakingthewrongdecision.
unhappinessand Choice_Overload_Stress:Whenfacedwithnumerouschoices,individualsmayfeeloverwhelmed,raising
stress? theirstresslevels.Toomanyoptionsmaymakedecision-makingprocesseslengthyandtaxing,escalating
stressandleadingtounhappiness.
Regret_Fear_and_Happiness_Decrease:Increasedchoicecanpotentiallyleadtodecreasedhappinessand
increasedstress,asindividualsmayworryabouttheirdecisions,regretnotchoosingdifferentoptions,or
fearmissingoutonpotentiallybetterchoices.
Kialo Question: Artificial_Intelligence_Opportunity:ChatGPT,likeotherAImodels,canhaveimmensepotentialand
Will ChatGPT bringaboutsubstantialbenefits.Byenablingnaturallanguageinteraction,itcanbeusedinareassuchas
do more harm education,healthcare,customerservice,andmore,greatlyenhancingefficiencyanduserexperience.The
thangood? potentialgoodthatChatGPTcancontributefaroutweighsthepotentialharm,assumingthattheproper
controlsandethicalguidelinesareputinplace.
Miscommunication_Risk:WhileChatGPTisdesignedtounderstandandgeneratehuman-liketext,there’s
ariskofmiscommunication.TheAImodelmaynotfullygraspsubtlenuances,culturalcontexts,oremotions
whichcouldleadtomisunderstandingorevenharm,especiallyinsensitiveconversationscenarios.
Data_Privacy_Concern:There’sapotentialformisusepertainingtodataprivacywithChatGPT.It’strained
onincrediblylargedatasets,andtheremightbeinstanceswherepersonalorsensitivedatamightbeleaked
ormisused,posingaseriousthreattoprivacy.
OpinionQA Question: Second_amendment_advocate_perspective:Yes,Idofeelsaferwithaguninthehousehold.Itprovidesa
Doyoufeelsafer meansofdefendingmyfamily,propertyandmyselffrompotentialoffendersorburglars.
with a gun in Child_safety_concerned_perspective:No,Idon’tfeelsaferwithaguninthehome.Especiallywhenthere
yourhousehold? arekidsaround,theriskofaccidentsduetonegligenceissignificantandunnerving.
Non_violence_promoter_perspective: No,owningaguninsinuatesthereadinessforviolence,which
createsanatmosphereofconstantthreatandinsecurity.Ibelieveinresolvingconflictspeacefullyrather
thanaggressively.
Table14: ExamplesofdiverseperspectivesgeneratedbyGPT-4,laterusedforqueryexpansioninSection5. We
onlypresentthefirstthreegeneratedperspectivesduetothepagelimit.
17Prompt <|im_start|>system
Youareahelpfulassistantthatcanonlyanswerwith"Yes"or"No".Yourgoalistodetermineiftheprovideddocument
supporttheprovidedstatement.DoNOTprovideanyexplanationforyourchoice.
<|im_end|>
[Optional1-shotexample]
<|im_start|>user
Document:[Document]
Statement:[Statement]
Instruction:Doesthedocumentsupportthestatement?Answerwithonly"Yes"or"No".Onlyconsidertheinformation
providedinthedocument,anddonotinferanyadditionalinformation.ThedocumentisasnippettakenfromtheInternet,
andmightexhibitsupportfororoppositionagainstthestatement.Ifthedocumentopposesthestatement,theansweris
"No".Ifthedocumentdoesnotcontainrelevantinformationaboutthestatement,theanswerisalso"No".Theansweris
"Yes"onlyifthedocumentsupportsthestatement,eitherexplicitlyorimplicitly.Thinkcarefullyifthedocumentactually
supportsthestatement,orifthereisjustsomesuperficialtextualoverlapbetweenthetwo.
Answer:
<|im_end|>
One-ShotEx- <|im_start|>user
ample DocumentforExample1:WhyProp.19issoimportant|rescuetruth.TheUnitedStatestookastabatalcoholprohibition
from1920-1933viatheUnitedStatesConstitution. AlmostimmediatelyfollowingtheratificationoftheEighteenth
Amendment,whichoutlawedalcohol,speakeasyclubssprungupallover,effectivelycreatingablackmarketandhanding
alcoholsalesovertoorganizedcrime. Duringthistime,ourgovernmentpoisonedindustrialalcoholinanattemptto
curbusagebyscaringtheAmericanpublic,causinganestimated10,000deaths.[17]Becauseoftheillicitdrugmarket
createdbyprohibition,thegovernmentcouldnotregulatetheproductionofalcohol,andsometimespeoplebecameill
afterdrinkingbootleggedwhiskies.Thecurrent
StatementforExample1:Prohibitionisaneffectivemethodtocurbdrugusage.
InstructionforExample1:Doesthedocumentsupportthestatement?Answerwithonly"Yes"or"No".
Onlyconsidertheinformationprovidedinthedocument,anddonotinferanyadditionalinformation.Thedocumentisa
snippettakenfromtheInternet,andmightexhibitsupportfororoppositionagainstthestatement.Ifthedocumentopposes
thestatement,theansweris"No".Ifthedocumentdoesnotcontainrelevantinformationaboutthestatement,theansweris
also"No".Theansweris"Yes"onlyifthedocumentsupportsthestatement,eitherexplicitlyorimplicitly.Thinkcarefully
ifthedocumentactuallysupportsthestatement,orifthereisjustsomesuperficialtextualoverlapbetweenthetwo.
AnswerforExample1:
<|im_end|>
<|im_start|>assistant
No
<|im_end|>
Table15: Theinputpromptforperspectivedetection. Weprovideanoptionalone-shotexampleforsomemodels
thatdonotdowellzero-shot. [Document]and[Statement]aresubstitutedwiththedocumentandperspectivein
eachexamplerespectively.
Question:[Question]
Perspective1:[P1]
Perspective2:[P2]
Instruction:Giventhequestion,onesupportingandoneopposingperspectives,whichperspectiveissupportingthequestion?Answer
withonly“Perspective1”or“Perspective2”.
Answer:
Table 16: The input prompt for deciding which of the perspectives supports or opposes the question. We only
considerexampleswithtwoperspectives. Wereplace[Question]withtheactualquestion,and[P1],[P2]withthe
twoperspectiveswhenprompting.
18C AdditionalResults
C.1 ResultsforTop10Documents
Wereportresultsforretrievingk =10documents
inTable17. ComparingtheresultswiththoseinTa-
ble3showsthatincludingmoredocumentsleadsto
higherdiversity(MRECALL)atthecostofPRECI-
SIONduetothereducedrelevanceoflower-ranked
documents. Similar trends hold for k = 10, as
CONTRIEVER isstillthebestretrieverintermsof
diversity,andretrieversobtainmorediversedocu-
mentsonSphere,followedbyGoogleSearchAPI
outputsandWikipedia.
19Datasets
Corpus Model Arguana Kialo OpinionQA Average
Prec. MRec. Prec. MRec. Prec. MRec. Prec. MRec.
BM25 19.81 19.33 20.58 16.67 9.13 5.67 16.51 13.89
Wiki DPR 17.35 14.67 18.17 13.57 12.03 6.35 15.85 11.53
CONTRIEVER 32.37 31.07 30.71 26.10 21.50 13.83 28.19 23.67
BM25 42.44 43.20 41.54 37.34 44.09 33.67 42.69 38.07
Sphere DPR 44.09 33.67 13.51 12.40 8.16 6.12 21.92 17.40
CONTRIEVER 55.89 55.07 53.89 43.28 48.61 38.66 52.80 45.67
GoogleSearch BM25 33.0 36.40 34.92 38.50 33.81 29.25 33.91 34.72
Output CONTRIEVER 48.65 44.53 47.95 44.32 42.73 35.49 46.44 41.45
Table17: PerformanceonthetestsplitofBERDS,consideringtop10retrieveddocuments.
20