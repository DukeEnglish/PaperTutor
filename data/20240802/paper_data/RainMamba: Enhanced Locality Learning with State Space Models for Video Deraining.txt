RainMamba: Enhanced Locality Learning with State Space
Models for Video Deraining
HongtaoWu1,YijunYang1,HuihuiXu1,WeimingWang3,JinniZhou1,LeiZhu1,2‚àó
leizhu@ust.hk
1TheHongKongUniversityofScienceandTechnology(Guangzhou)
2TheHongKongUniversityofScienceandTechnology
3HongKongMetropolitanUniversity
ABSTRACT laboriouspriorsandtheyencountercomplexoptimizationchal-
Theoutdoorvisionsystemsarefrequentlycontaminatedbyrain lenges.Inrecentyears,deeplearning-basedmethods,including
streaksandraindrops,whichsignificantlydegeneratetheperfor- convolutionalneuralnetworks(CNN)andrecurrentneuralnet-
manceofvisualtasksandmultimediaapplications.Thenatureof works(RNN),havedemonstratedeffectivenessinvideoderaining
videos exhibits redundant temporal cues for rain removal with tasks.Thesuccessofvideoderainingmethods[40,67,70‚Äì73,82]
higherstability.Traditionalvideoderainingmethodsheavilyrely hingesonsomeelaboratedmodules,suchasopticalflowestimation
onopticalflowestimationandkernel-basedmanners,whichhave anddeformableconvolutions,toleveragingtemporalcorrections
alimitedreceptivefield.Yet,transformerarchitectures,whileen- fromneighboringframes.Nevertheless,theseCNN-basedmethods
ablinglong-termdependencies,bringaboutasignificantincreasein usuallyhavelimitedspatial-temporalreceptivefieldscompared
computationalcomplexity.Recently,thelinear-complexityoperator torecenttransformer-basedarchitectures[36,55,74,78,81].On
ofthestatespacemodels(SSMs)hascontrarilyfacilitatedefficient theotherhand,whilethesetransformer-basedmethodsachieve
long-termtemporalmodeling,whichiscrucialforrainstreaksand globalunderstandingonvideos,theyheavilyrelyonMulti-Head
raindrops removalin videos. Unexpectedly,its uni-dimensional Self-attention(MSA)mechanism,resultinginquadraticcomplex-
sequentialprocessonvideosdestroysthelocalcorrelationsacross ity related to sequence length. This poses significant efficiency
thespatio-temporaldimensionbydistancingadjacentpixels.To challengesinhandlinglongvideosequences[2]andimpedesits
addressthis,wepresentanimprovedSSMs-basedvideoderaining applicationinmodelinglong-terminter-framecorrelation.
network(RainMamba)withanovelHilbertscanningmechanismto Recently,StateSpaceModels(SSMs)[32],derivingfromcontrol
bettercapturesequence-levellocalinformation.Wealsointroduce systemstheory,havedemonstratedtheiradvantagesinnaturallan-
adifference-guideddynamiccontrastivelocalitylearningstrategy guageprocessing(NLP)[20,21]andcomputervision[41,89]by
toenhancethepatch-levelself-similaritylearningabilityofthepro- theirlinearcomplexityinhandlinglongsequences.Byformalizing
posednetwork.Extensiveexperimentsonfoursynthesizedvideo discretestatespaceequationsrecursively,Mambacancapturelong-
derainingdatasetsandreal-worldrainyvideosdemonstratethe rangedependencies[20],therebyimprovingvideoreconstruction
superiorityofournetworkintheremovalofrainstreaksandrain- qualitybyestablishingglobalconnectionsamongpixels.Nonethe-
drops.Ourcodeandresultsareavailableatthislink. less,theconventionalMambamodel[20],tailoredfor1Dsequential
datainNLP,encountersinherentbottlenecksinvideorestoration
tasksduetolocalpixelforgetting.AsillustratedinFig.1(a),the
KEYWORDS
Mambamodelrecursivelyprocessesframesflattenedinto1Dse-
Videoderaining,Statespacemodels,Hilbertscan
quences.Thisapproachunexpectedlydestroysthecausalitybe-
tweenspatio-temporallyadjacentpixelsinthevideosequences,
1 INTRODUCTION leadingtotheabsenceoflocalinformationinsequence-leveltem-
poralmodeling.
Videoscapturedfromoutdoorsystems,i.e.,surveillancecameras
Toaddresstheaforementionedissues,wedeviseanimproved
andmobilesensorsinautonomousvehicles,areoftencorruptedby
SSMs-basedframeworkdubbedRainMambaforrainremovalin
bothrainstreaksandraindrops.Thesedegradationssignificantly
videos.WepresentanovelHilbertscanmechanismthatleverages
damagethevisualperceptualqualityandtendtodegeneratetheper-
theinherentlocalitycharacteristic[3,44]ofHilbertcurve[26]to
formanceofsubsequentoutdoorcomputervisionandmultimedia
enhancethelocalitylearningofthevanillaMamba.Inparticular,
computingtasks,e.g.,objectdetection[1,14],semanticsegmen-
weconvertthespatio-temporalpixelsintoa1Dsequencefollowing
tation[54,56]andautonomousdriving[17,88].Therefore,rain
the trajectory of the Hilbert curve, thus leveraging the Hilbert
removalisanindispensablepre-processingsteptoenhancethe
curve‚Äôslocalitypreservationforfine-grainedrestoration.However,
robustnessandstabilityofoutdoorintelligentsystemsandmulti-
flatteningvideodataintoone1Dsequenceinevitablydiminishes
mediaapplications.
theinherentlocalspatialcorrelations,hinderingtherestorationof
Theearliestvideoderainingmethods[5,19,49,80]weredesigned
rainstreaksandraindropsareas.Basedontheobservationthatthe
basedonhandcraftpriorsandattemptedtomodelthephysicalchar-
patchesinagivenframeexhibitsimilaritywiththeneighboring
acteristicsandphotometricpropertiesoftherainlayertosolvethe
counterpartinthesameframeandsubsequentframes,weproposea
problem.However,theirperformanceisseverelyrestrictedbythe
difference-guideddynamiccontrastivelocalitylearningstrategyto
preservepatch-levelsemantics.Specifically,wederiverainlocation
‚àóCorrespondingauthor.
4202
luJ
13
]VC.sc[
1v37712.7042:viXraACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
Height
TimeWidth
(c) (d)
Vertical View
Time
Width Height
(a) (b)
[(0,0,0), (1,0,0), (2,0,0), (3,0,0), (0,1,0), (1,1,0) ‚Ä¶] [(0,0,0), (0,0,1), (0,1,1), (0,1,0), (1,1,0), (1,1,1) ‚Ä¶]
[ , , , , , ‚Ä¶] [ , , , , , ‚Ä¶]
Global Scan Hilbert Scan Ground truth
Trajectories of Global and Hilbert scans in the space-time dimension Front View Visual results of two types of scans
Figure1:Motivationillustrationandvisualcomparisonsoftwodifferentscanningmethods.(a)and(c)aretheillustrationof
theglobalscanmethod,while(b)and(d)aretheillustrationoftheHilbertscanmethod.Thetemporalscanningdifferencesare
emphasizedin(a)and(b),whereasthespatialscanningdifferencesaredepictedin(c)and(d).Thelinesandendpoints(represent
pixelpoints)areshadedingradientsfromdarktolight,signifyingthepathofthescan.Foramoreintuitiveunderstanding,
pleaserefertothedynamicdisplayintheSupplementaryVideo.WeleveragetheHilbertcurve‚Äôslocalityfeaturetoimprovethe
utilizationoflocalinformationinthetime-spacedimensionduringthescanningprocess.Thevisualresultsindicatethatour
localscanningmechanismimprovesspatialstructurepreservationofderivedresults.
fromthedifferencemapforanchorsampling,whileselectingthe consistingofdualattention-in-attentionmodelforjointremoval
spatio-temporally surrounding patches as positive samples and ofrainstreaksandraindrops.Recently,Video-levelderainingtech-
spatio-temporallydistantpatcheswithsignificantdifferencesas niques[53,58,70,71,73,76,82,86]havebeendevelopedtoleverage
negativesamples.MotivatedbyCurriculumLearning[7],wealso temporalcorrelationandinformationacrosssequentialframesto
introduceadynamicmechanismthatfacilitatestheoptimizationby improvederainingresults.FCRVD[71]constructedatwo-stage
adjustingthesamplingdistanceforpositiveandnegativesamples. recurrentnetworkincorporatingdualflowconstraintstoenhance
Insummary,ourcontributionsareasfollows: motioninformationforvideorainstreaksandaccumulationflow
removal. SAVD [70] employed deformable convolution to align
‚Ä¢ Weproposethefirstframeworktoadaptstatespacemodels
multi-framefeatures,effectivelyremovingbothrainstreaksand
tovideoderainingtasksbytheCoarse-to-FineMambaBlock.
rain accumulation in videos. RDD-Net [58] introduced the rain
‚Ä¢ WeequipSSMswithanovelHilbertscanningmechanism,
streakmotionpriortoarecurrentvideorainstreaksremovalnet-
whichachieveslocalizedscanningacrossbothtemporaland
work.ESTINet[86]employedlong-shorttermmemorytoeffec-
spatialdimensions.Thisapproachsubstantiallyimprovesour
tivelycapturespatio-temporalfeaturesandtemporalcorrelations
models‚Äôabilitytoexploresequence-levellocalinformation.
between neighboring frames. Considering the distinct physical
‚Ä¢ Weintroduceadifference-guideddynamiccontrastivelo-
propertiesofraindrops,VWR[64]developedaspatio-temporal
cality learning approach to enhance the patch-level self-
attentionmechanismforvideoraindropsremoval.Asrainstreaks
similaritylearningability.
‚Ä¢ Experimentalresultsonfoursynthesizedvideoderaining
andraindropsfrequentlyco-occurinvideos,Wuetal.[67]deviseda
videoderainingnetworkViMP-Netthatintegratesopticalflowand
datasetsandreal-worldrainyvideosdemonstratethatour
mask-guidedintra-frameandinter-frametransformerstosequen-
networkprominentlyoutperformsstate-of-the-artmethods.
tiallyremoverainstreaksandraindrops.Incontrast,weintroduce
SSMstocausallymodeltemporalinformation,replacingthemecha-
2 RELATEDWORK nismswithlowefficiencybasedonopticalflow,deformablekernel
2.1 VideoDeraining orself-attention.
Inthepastdecades,deeplearning-basedmethods[15,18,38,48]
haveachievedimpressiveresultsforrainstreakandraindropre- 2.2 StateSpaceModels
movalinimages.SPANet[59]introducedthefour-directionalIni- Recently,StateSpaceModels(SSMs)[32]havedemonstratedno-
tializeRecurrentNeuralNetworkstoobtainthecontextualinfor- tableefficiencyinutilizingstatespacetransformations[22]toman-
mationforrainstreaksremoval.CCN[47]employedneuralar- agelong-termdependencieswithinlanguagesequences.S4[21]
chitecture search to adaptively find an optimal architecture for introducedastructuredstate-spacesequencemodeltoexploitlong-
jointlytacklingrainstreaksandraindropsremoval.D-DAiAM[85] rangedependencieswiththebenefitoflinearcomplexity.Based
leveragedtheoutputdifferencesbetweenmultiplederainingstages on this, Mamba [20] integrates efficient hardware design and aRainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
selection mechanism employing parallel scan (S6), thereby sur- block (GMB, see 3.3.1) and local mamba block (LMB, see 3.3.2).
passing Transformers in processing extensive natural language Subsequently,aftermulti-scaleglobalityandlocalitylearningfrom
sequences.Subsequently,S4ND[45]exploresSSMs‚Äôcontinuous- temporalfeature,weaddùëÅ3CFMmodulesforfurtherfeaturerefine-
signalmodelingofmulti-dimensionaldatalikeimagesandvideos. ment.Finally,theenhancedfeaturebyCFMisprocessedthrough
Morerecently,VisionMamba[89]andVmamba[41]pioneered areconstructiondecoder,whichiscomposedofmultiple3Dcon-
genericvisiontasks,introducingbi-directionalscanandcross-scan volutionsandupsamplelayers,togeneratetherecoveredframes
mechanismstotacklethedirectionalsensitivitychallengeinSSMs. {ùë±ùë° ‚àà R3√óùêª√óùëä | ùë° ‚àà [0,ùëá)}. During training, we design and
Thankstothesuperiorityinaddressingcomplexvisionchallenges, enforcethedifference-guideddynamiccontrastiveregularization
SSMshavebeenintegratedintomanyvisiontasksincludingobject topromotethenetwork‚Äôsdynamiclearningofpatch-levellocal
detection[28],imagesegmentation[68],imagerestoration[23,51], self-similarity.
videoobjectsegmentation[69,77]andvideounderstanding[34].
Tothebestofourknowledge,SSMshavenotyetbeenexploredin 3.2 Preliminaries
thevideoderainingtask.UnlikepreviousSSMs-basedworks,wein- 3.2.1 StateSpaceModels. Inspiredbycontinuouslineartime-invariant
troduceaHilbertscanningapproachtoenhanceitssequence-level systems,StructuredStateSpaceModels(S4)andMambarepresent
localitylearninginspatio-temporalmodeling. aclassofsequencemodelsthatmapaone-dimensionalsequence
ùë•(ùëò) ‚àà R ‚Üí ùë¶(ùëò) ‚àà R through an intermediate hidden state
2.3 ContrastiveLearning ‚Ñé(ùëò) ‚àà RùëÅ√ó1,whereùëÅ isthehiddenstatesize.Mathematically,
Contrastive learning, an effective self-supervised learning tech- SSMs utilize the ordinary differential equation (ODE) below to
nique[12,25,46,75],seekstominimizethedistancebetweenan- transformtheinputdata:
chorsandpositivesampleswhilemaximizingthedistancefrom ‚Ñé‚Ä≤(ùëò)=A‚Ñé(ùëò)+Bùë•(ùëò),
negativesampleswithintherepresentationspace.Contrastivelearn- (1)
ùë¶(ùëò)=C‚Ñé(ùëò),
inghasbeenexploredinsomelow-levelvisiontaskslikeimage
translation[24],imagesuper-resolution[62],imagedehazing[65] whereA‚ààRùëÅ√óùëÅ representsthesystem‚Äôsevolutionparameter,and
, unsupervised image deraining [16, 79], image-to-image trans- B‚ààRùëÅ√ó1,C‚ààR1√óùëÅ aretheprojectionparameters,respectively.
lation [24], video desnowing [10, 66] and video deraining [57] . Forpracticalapplicationindeeplearning,thecontinuoussystem
DCD-GAN[16]utilizedcontrastivelearningtoleveragefeatures describedbyEq.1istransformedintoitsdiscretecounterparts,
from unpaired clean images for guiding rain removal in the la- throughadiscretizationprocessusingthezero-orderhold(ZOH)
tent.ANLCL[79]formulatedanunsupervisedcontrastivelearning method.ThisinvolvesatimescaleparameterŒî‚ààR>0,converting
basedontheself-similaritypropertywithinsamplesandthemu- continuousparameters(A,B)intodiscreteparameters(A,B),which
tuallyexclusivepropertybetweentherainlayerandimagelayer. canbedefinedasfollows:
UVDEC[57]constructedacross-modalcontrastivelearningtoin-
A=exp(ùö´A),
vestigatethemutualexclusionandsimilarityofrain-background B=(ùö´A)‚àí1(exp(ùö´A)‚àíI)¬∑ùö´B. (2)
layersbetweenpixeldomainandeventdomain.Thepivotalaspect
Thisresultsinthefollowingdiscretizedmodelformulation:
ofcontrastivelearningdependsontheselectionofanchor,posi-
tive,andnegativesamples.Unlikepreviousimage-levelmethods ‚Ñé
ùëò
=A‚Ñé ùëò‚àí1+Bùë• ùëò,ùë¶
ùëò
=C‚Ñé ùëò. (3)
thatsampledbasedoninputandpredictionsorrandomlyselected
Toenhancecomputationalefficiencyandscalability,theEq.3can
patches,wedevelopedadynamictemporalsamplingmethodto
bemathematicallytransformedintoanequivalentCNNform,lever-
explorespatio-temporalself-similaritybetweenvideoframes.
agingparallelcomputationviaaglobalconvolutionoperation:
3 METHODS ùë¥
=(cid:16) ùë™ùë©,ùë™ùë®ùë©,...,ùë™ùë®ùêø‚àí1 ùë©(cid:17)
,
(4)
3.1 NetworkArchitecture ùíö=ùíô‚äõùë¥,
Figure2displaystheoverviewoftheproposedRainMambafor
whereùë¥ ‚ààRùêøisaconvolutionalkerneloftheSSM,ùêøisthelength
video deraining task. Specifically, our video deraining network
oftheinputsequencexand‚äõrepresentstheconvolutionoperation.
iscomposedofafeatureencoder,aseriesofcascadedCoarse-to-
UnliketraditionalSSMsthatemployconstanttransitionparam-
FineMambamodules,andafeaturedecoder.Givenarainyvideo
sequence{ùë∞ùë° ‚ààR3√óùêª√óùëä |ùë° ‚àà [0,ùëá)},weemployauniversalback- e mte ar trs ic(A es, ùêµB ,) ùê∂,S a6 n[ d20 Œî] ,e wst ha ib chlis eh na abn lein sp bu et t- td erep pe en rcd ee pn tt iom ne oc fh ia nn pi usm tcofo nr
-
bone(i.e.,ConvNeXt[42])andalightweightheadastheencoderto
textinformationanddynamicupdatesoftheseparameters.
extracttheshallowfeature{ùë¨ùë° ‚ààRùê∂√óùêª/4√óùëä/4 |ùë° ‚àà [0,ùëá)},where
ùêª andùëä denotetheheightandwidthoftheinputframes,andùê∂ 3.2.2 Hilbert Curve. Hilbert curve [26] is a space filling curve
signifiesthenumberofchannels.Toaccommodatevariouspatterns (SFC)[43],extensivelydeployedinvariousfields,includingdata-
ofraininframes,weutilizeconvolutionallayerstodownsample base[4]andimagecompression[37].AsillustratedinFigure1,
andupsampletheextractedfeatures,therebylearningbackground theHilbertcurvehastheabilitytoconnectallelementswithina
semanticsinamulti-scalemanner.Insuchaway,thefeatureissuc- space,andisoftenutilizedasafractalfunction[50].TheHilbert
cessivelyfedintoCoarse-to-FineMambaModule(CFM)tocausally curve‚Äôsdefiningcharacteristicliesinitsstrongcapabilitytopreserve
learntheglobalandlocaltemporalcorrelationandalignmentby locality [29]whentransformingfromone-dimensionaltomulti-
two different submodules at different scales, i.e., global mamba dimensionalspaces,significantlyimprovingfeatureclustering[13].ACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
ùëØ ùëæ ùëØ ùëæ ùëØ ùëæ
ùë©√óùëª√óùë™√óùüí√óùüí ùë©√óùëª√óùüêùë™√óùüñ√óùüñ ùë©√óùëª√óùë™√óùüí√óùüí
ùìõùë∫ùíñùíë
√óùëµùüè
√óùëµùüê
√óùëµùüë
Difference Map
¬∑¬∑¬∑ Encoder B M
G
B M
L
vno
C
B M
G
B M
L
vno
C
B M
G
B M
L
Decoder ¬∑¬∑¬∑
CFM CFM CFM Different ce-Driven Anchor St ampling Local P[t o- s1 it, it v+ e 1 Sa] mplingNon-Loca[ lt - N2 e, g t a+ ti2 v] e Sampling
Forward SSM
¬∑¬∑¬∑ m roN
reyaL
abm
a iM
B-
m roN
reyaL
vnoCW
D Norm Flip
CC oo nn vv 11 dd BackwarSS dSS MM
SSM
¬∑¬∑¬∑ t+2
Activation
Mamba Block Bi-Mamba Layer
CFM Coarse-to-Fine Mamba Module Global Mamba Block Global t
8 6 Scanning 8 6
GMB Global Mamba Block 778 55656
Global Flatten
Function 778 55656
LMB Local Mamba Block 34 1212
1 2 3 4 5 6 7 8
Mamba Block Global Reshape 34 1212
Conv 3D Convolution Layer t-1
DWConv Depth-wise Convolution Layer Local Mamba Block 3D Hilbert
‚Ä¶
E
EF ll lea
em
mtte
e
en
n
ne
t
td
- -w w
1
i
iD
s se e
S
A
Me dq udu ltie itn pioc line
c ation
377 488 155 266 156
2 3D Hilb 1ert C 2urve 6 Flat 5ten 7 8 4 3
Cur Fv ue n S Mcc ta i aon mnn bin ag
B lock 3 InD d H exil ib ne g r Rt e C su harv pe e
377 488 155 266 156
2 NPA on es gc i ah ti to v ir ve e Difference-Guided T Dr ya ni an min icg C I ote nr tra at si to in ve Locality Learningùìõùë´ùë™ùë≥
Figure2:ThearchitectureofourproposedframeworkRainMambaforvideoderainingtask.Givenasequenceofrainyvideo
frames,thecascadingCoarse-to-FineMambaModule(CFM)receivestheencodedfeaturesasinputandcausallymodelstemporal
correctionsbytheimprovedstatespacemodels(SSMs).TheCFMemploysGlobalMambaBlock(GMB)andLocalMambaBlock
(LMB)tocapturesequence-levelglobalandlocalspatio-temporaldependencies.WedevelopanovelHilbertscanningparadigm
inLMBtopromotetheMamba‚Äôslocalitylearning.Moreover,weconstructadifference-guideddynamiccontrastivelocality
learningapproachtoenhancepatch-levellocalitylearning.Specifically,weutilizethedifferencebetweentheinputandthe
groundtruthtoselecttheanchor,samplingthepositivepatchataspatio-temporallyadjacentlocationtotheanchor,andthe
negativepatchatamoredistantlocation.Astrainingprogresses,thesamplingspaceforpositivesamplesexpandswhilethat
fornegativesamplescontracts.
Moreover,[44]shownthattheHilbertcurveachievesbetterclus- cancomplementeachotherinestablishingbothglobalandlocal
teringinthree-dimensionalspaces.Basedonthis,Hilbertscancan correlations.
enhancethecorrelationofspatio-temporallyadjacentfeaturesby
promotingclusteringofneighboringtokensonthesequence.More 3.3 Coarse-to-FineMambaModule
formally,aSFCcanbedenotedasùëù : [0,1] ‚Üí [0,1]√ó[0,1],which Previousworks[67,70,71,73]tendtoelaboratesomemodules
mapsanypointfromone-dimensionalinterval[0,1]toacoordinate basedonopticalflow,deformablekernelorquadratic-complexity
intwo-dimensionalunitsquare.Wealsodenoteùëõasthecurveorder self-attention,toexploittemporalinformationwithlowefficiency
oftheHilbertcurve,which,inourdiscretecase,approximatesto forrainremovalinvideos.OurmethodintroducestheStructured
heightandwidthofeachframe.Foranytwopointsùë¢,ùë£ in[0,1], StateSpaceModels(dubbedMamba),whichcanemploytheselec-
theirspacetolinearratio(SLR)isdefinedas: tivescanmechanismtocausallyprocessthetemporaldatawith
linearcomplexity.Specifically,weflattenthe3Dvideodataintoone-
|ùúé(ùë¢)‚àíùúé(ùë£)|2
dimensionalsequencesintwodifferentwaystoeffectivelyleverage
ùëÜùêøùëÖ= . (5)
|ùë¢‚àíùë£| spatio-temporal corrections from neighboring frames. Our pro-
posedCoarse-to-FineMambaModuleconsistingofGlobalMamba
Thedilationfactor(DF)ofaSFCisdefinedastheupperboundofthe
BlockandLocalMambaBlockcanprogressivelymitigatethedegra-
SLR.Forthesametwopointsin[0,1],ifanSFChaslowerDF,their
dationthroughholisticandregionalmulti-scaleperception.
mappingswillalsobecloserintheunitsquare,whichaccordswith
thelocalitypreservingrequirementinthescanningstage.Asproved 3.3.1 GlobalMambaBlock. AsillustratedinFigure2,inGlobal
in[6,13],theDFofHilbertcurveis6,whilethenormalZigzag MambaBlock,weapplyazigzagorderapproach(i.e.rowbyrow)to
(row-and-column-order)curveis4ùëõ‚àí2ùëõ+1+2,whichdivergesto‚àû constructglobalflattening.Thisglobalscanningmechanismenables
asthecurveorderùëõincreases.Therefore,astheimageresolution SSMstoestablishglobalcontextualdependenciesbetweeneach
increases, the Hilbert curve can better maintain the locality of pixelandallotherpixelsinalinearizedsequence.Wetransformthe
mappinganytwopointsonaone-dimensionalsequencetoamulti- inputvideofeatureùê∏ ‚àà Rùê∂√óùëá√óùêª/4√óùëä/4 intoaone-dimensional
dimensionalspacethantheZigzagcurve.Also,theDFcanprovide longsequenceùëâ ‚ààRùê∂√ó(ùëá√óùêª/4√óùëä/4)inaspatially-prioritizedman-
explicitmathematicalinterpretationforcomparingtheimpactof ner.Then,theflattenedsequenceùëâ isfedintoaMambaBlock.We
twoscans.Specifically,comparedtoHilbertscan‚Äôslocality,Zigzag incorporatetheBi-Mambalayer[89]intoourMambablockfor
scancancapturemoreglobalcorrelations.Ourresearchextends videoderaining.ThisBi-Mambalayerprocessesflattenedvisualse-
thelocalityofHilbertcurvestovideosequencesforenhancing quencesthroughabidirectionalfashion,i.e.,forwardandbackward
thepreservationoflocalpixelinformationduringspatial-temporal SSMs,whichhasbeenproventobeeffectiveonlow-levelvideo
scanningofSSMs.Inthismanner,thetwoscanningmechanisms tasks[8,36,86].Subsequently,adepth-wiseconvolutionlayerwithRainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
3.4 Difference-GuidedDynamicContrastive
LocalityLearning
AlthoughMambacaneffectivelytakeadvantageofthecausalityof
ùë∞ùíï ùë±ùíï ùë±‡∑†ùíã ùë∑ùíãùíî
videosbyflattening1Dcausalsequentialdatafortemporalmodel-
ùë∂ùíïùíî
ing,itfrequentlyunderestimatesinherent2Dspatialrelationships.
Toaddressthis,weintroducearegularizationstrategytoenhance
Difference Map Highlighted Rain Region Map ùë∞ùíï ùëµùíòùíî themodel‚Äôsintra-andinter-frameperceptionofspatialcorrela-
Figure 3: The motivation and operation of our proposed
tions.Inspiredbynon-localprior[39,61],weencouragethelocality
Difference-GuidedDynamicContrastiveLocalityLearning.
learningofspatial-temporallyneighboringpixelsbyconstructinga
thekernelsizeof3√ó3√ó3isemployedtopreservefine-grainedde- contrastlearningmechanismthatexploitstheself-similarityfrom
tails.TheoperationwithinthestackedMambaBlockcanbedefined thepatchlevel.Theraininvideosexhibitsvaryingintensitiesand
asfollows: types,makingrainremovalmorechallengingespeciallywhenrain
streaksandraindropsexistsimultaneously.Accordingto[47,67],
ùëâùëô =BM(cid:16) LN(cid:16) ùëâùëô‚àí1(cid:17)(cid:17) +ùëâùëô‚àí1,ùëâùëô =DWC(cid:16) LN(cid:16) ùëâùëô(cid:17)(cid:17) +ùëâùëô. (6) theùë°-thvideoframecontainingrainstreaksandraindropscanbe
representedas:
Finally,wereshapetheoutputone-dimensionalsequencefeatures
backtotheiroriginalthree-dimensionalfeaturesùê∏ÀÜ ‚ààRùê∂√óùëá√óùêª/4√óùëä/4 ùëÖùëÜùê∑ ùë° =(1‚àíùëÄ ùë°)‚äô(ùêµ ùë° +ùëÜ ùë°)+ùëÄ ùë° ‚äôùê∑ ùë°, (8)
intheglobalflattenedorder.
whereùëÖùëÜùê∑ denotestherainyvideoframecontainingtheclean
ùë°
3.3.2 LocalMambaBlock. Whileglobalscanningfacilitatesmod- backgroundlayerùêµ ùë°,rainstreakslayerùëÜ ùë° andraindropslayerùê∑ ùë°.
elingtemporalinformationbycausallyprocessingtimeseriesdata ùëÄ ùë° isabinarymask,andùëÄ ùë°(ùë•)=1meanspixelùë• isapartofthe
withSSMs,itdestroystheinherentlocalcorrelationsinvideos. regionoccludedbyraindrops.BasedonEq.8,wecanderivethe
AsshowninFig.1(a)and(c),theglobalscanningapproachsig- positioninformationofrainstreaksandraindropsbythedifference
nificantlyincreasesthedistancebetweenspatiallyandtemporally mapŒ© ùë° betweenrainyandcleanframes.
adjacent pixels, which leads to severe adjacent pixel forgetting.
Œ© ùë° =(1‚àíùëÄ ùë°)‚äôùëÜ ùë° +ùëÄ ùë° ‚äôùê∑ ùë° ‚àíùëÄ ùë° ‚äôùêµ ùë°. (9)
Toovercomethischallenge,wepresentanovelHilbertscanning
techniquetoenhancethelocalitylearningofvideodataduring As illustrated in Fig. 3, it‚Äôs observed that regions containing
scanning.TheproposedstrategyisillustratedinFig.1(b)and(d), streaksandraindropstypicallycorrespondtohigh-responseareas
highlightingthecontrastbetweenourmethodandglobalscanning onthedifferencemap.Weadopttheaveragethresholdmethodto
approach.AsshowninFig.2,wefirstconstructa3DHilbertcurve selectpatcheswithhighresponseinthedifferencemapfromthere-
thattraverseseverypointfollowingtheprinciplesofHilbertcurves. storedframe{ùë±ùë° |ùë° ‚àà [0,ùëá)}asanchors{ùë∂ùë° |ùë° ‚àà [0,ùëá)}.Wefocus
Inessence,the3DHilbertalgorithmisdesignedtorecursivelysub- theattentionofrecoveryonheavilydegradedareasbyeliminating
dividethecubicspaceandgenerateHilbertcurvesegmentswithin thepatcheswithlowerresponsethantheaverageresponse.
eachsmallercubicspace.Thesesmallersegmentsarethenmerged Moreover,wecanobservethatpatchesofthetargetframeshare
toconstructthefull3DHilbertcurve.Subsequently,wetransform similaritieswiththeiradjacentcounterpartsinthesameframeand
eachcoordinate(ùë•ÀÜ,ùë¶ÀÜ,ùëßÀÜ)onthe3DHilbertcurveintoauniqueone- alsosubsequentframes.Conversely,thesepatchesaresignificantly
dimensionalindex,therebyflatteningthethree-dimensionalspace differentfromthespatio-temporallydistantpatches.Basedonthese
bytheHilbertcurve‚Äôsscanningtrajectory.Thisindexingformula observations,weselectspatiallyadjacentpatchesfromtheneigh-
canberepresentedas: boringcleanframes{ùë±ÀÜ ùëó | ùëó ‚àà [ùë° ‚àí1,ùë° +1]}aspositivesamples
Index=ùë•ÀÜ¬∑ùëÑ¬∑ùëá +ùë¶ÀÜ¬∑ùëá +ùëßÀÜ, (7)
{ùë∑ùëó | ùëó ‚àà [ùë°‚àí1,ùë°+1]}.Ontheotherhand,wetreatspatiallydis-
tantpatchesfromtheentiredegradedinputsequenceasnegative
whereùëÑisthewidthlengthofinputfeatures.BasedontheHilbert samples{ùëµùë§ |ùë§ ‚àà [0,ùëá)}andenhancetheirdistinctivenessfrom
index,weflattentheinputfeaturesùê∏ÀÜ ‚àà Rùê∂√óùëá√óùêª/4√óùëä/4intothe positivesamplesbyperformingdataaugmentationsuchasrotation,
one-dimensionalsequenceùëâÀÜ ‚ààRùê∂√ó(ùêª/4√óùëä/4√óùëá) whichislocally flipping,andblurring.Furthermore,weintroducedynamiclearn-
enhancedagainsttheglobalsequenceùëâ.Afterward,thesequenceis ingtofacilitatetheoptimizationofintra-andinter-framelocality
fedintotheMambablock,whichhasthesamenetworkarchitecture learning.Weincrementallyincreasethespatialdistanceùëùbetween
astheglobalcounterpart,toexploitspatio-temporalcorrections positivesamplesandtheanchor,andsimultaneouslydecreasethe
inthelocalspirit.Finally,wereshapetheoutputsequenceback spatialdistanceùëëbetweennegativesamplesandtheanchorduring
to its original shape to construct the locally-enhanced features thetrainingprocess.Theentiredynamiclearningprocesscanbe
ùê∏ÀÜ‚Ä≤ ‚ààRùê∂√óùëá√óùêª/4√óùëä/4.Incontrasttotheglobalscanningapproach, representedas:
ùëí
ourHilbertscanningmethodisdesignedtomoreeffectivelycapture
ùëë =max(ùëë0¬∑ùúÉùëö,ùëë ùëöùëñùëõ), (10)
sequence-levellocaldependenciesacrossbothtemporalandspatial (cid:16) ùëí (cid:17)
ùëù =min ùëù0+ ¬∑(ùëù
ùëöùëéùë•
‚àíùëù0),ùëù
ùëöùëéùë•
, (11)
dimensions.ThisbenefitsfromtheHilbertcurve‚Äôsinherentcapacity ùëö
topreservelocality,ashighlightedinSec.3.2.2.BycascadingGlobal whereùëë0istheinitialminimumnegativedistance,ùúÉ denotesthe
MambaBlockandLocalMambaBlock,ournetworkfirstobtains decayrate,ùëí isthenumberofcompletedtrainingsteps,ùëöisthe
theholisticunderstandingofspatio-temporalinformationandthen totalnumberoftrainingsteps,ùëù0indicatestheinitialpositiverange
preservesitslocaldetailsfollowingthespiritofCoarse-to-Fine. andùëùisthesamplingdistanceofpositivesamples.ThisdynamicACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
learningapproachenablesthenetworktoprogressivelymaster 4.2 ImplementationDetails.
patch-leveldetails,advancingfromsimpletocomplexconcepts. OurnetworkistrainedonNVIDIARTX4090GPUsandimple-
Ultimately,weemploycontrastivelearningtoensuretheùë†‚àíùë°‚Ñé mentedonthePytorchplatform.Notethatwehavefourbench-
sampleùëÇ ùë°ùë† ispulledclosertopositivesamplesùëÉùë† ùëó andpushedfar markdatsetsfortestingournetworkandcomparedmethods.Due
away from the strongly augmented degraded negative samples tothepagelimit,wehereprovidethetrainingdetailsoftheVRDS
ùëÅ ùë§ùë† throughthepre-trainedVGGfeatureextractor.Ourproposed dataset.Specifically,ateachtrainingiteration,theinputframeis
contrastivelearninglosscanbeformulatedas: randomlycroppedtoaspatialresolutionof256√ó256,andthenum-
berofframespervideoclipis5.Thetotalnumberofthetraining
Lùê∑ùê∂ùêø = ùëÜ1‚àëÔ∏Å ùë†=ùëÜ 1(cid:169) (cid:173) (cid:173)‚àëÔ∏Å ùëü=2
1
LL LL 11 (cid:0)(cid:16) ùê∫ùê∫ ùëüùëü (( ùëÅùëÉ ùë§ùë† ùë†ùëó) ), ,ùê∫ ùê∫ùëü ùëü( (ùëÇ ùëÇùë°ùë† ùë°ùë†) )(cid:17) (cid:1)(cid:170) (cid:174) (cid:174), (12) i n ot uoe rr ma nt i eaio tl wn sc oi hs rke3 d0 isu0 lK se e. r tW w toe it 5a h √ód ao 1p p 0t o ‚àít w 4h e we rA ito hd fa a1m . b0 a.o tTp cht hi em siii znz eie t or ia f[ l3 8l3 e a] a na r dnn aid n wt gh are ra mp teo -ul oy pf-
(cid:171) (cid:172) startof2kiterations.Moreover,theencoderadoptstheImageNet
where{ùê∫ ùëü |ùëü ‚àà [1,2]}extractstheùëü ‚àíùë°‚Ñélow-levelhiddenlayer pre-trainedConvNeXt[42]backbone.ThenumberofCoarseto
featuresfromthepre-trainedVGG-19[52]model. FineMambaModulesùëÅ1,ùëÅ2,andùëÅ3aresetto2,3,and2respec-
tively.Fortrainingdetailsontheotherthreedatasets,pleaserefer
3.5 LossFunction toSupplementaryMaterial.
WeadopttheCharbonnierloss[9]andtheperceptualloss[31]to
improvethevisualqualityoftherestoredresults.Theperceptual 4.3 ComparisonswithState-of-the-artMethods
loss is to quantify the discrepancy between the features of the 4.3.1 QuantitativeComparisonsontheVRDSDataset. Asshown
prediction and the ground truth. The overall supervised loss is inTab.1,wequantitativelycompareourproposedmethodwith
formulatedas: 12 state-of-the-art (SOTA) image and video deraining methods,
includingCCN[47],PreNet[48],DRSformer[15],MPRNet[84],
Lsup =Lùëùùëñùë•ùëíùëô +ùúÜ1Lùëùùëíùëüùëêùëíùëùùë°ùë¢ùëéùëô +ùúÜ2Lùê∑ùê∂ùêø, (13) Restormer[83],S2VD[82],SLDNet[73],ESTINet[86],RDD[58],
RVRT [36], BasicVSR++ [8] and ViMP-Net [67]. Among the 12
whereùúÜ1andùúÜ2arethebalancinghyper-parameters,empirically comparedmethods,ViMP-NethasthebestPSNR,SSIM,andLPIPS
setas0.3and0.1,respectively.Andtheperceptuallossisformulated performance,andthePSNR,SSIM,andLPIPSscoresare31.02dB,
asfollows: 0.9283,and0.0862.Moreover,ourmethodhasbettermetricresults
thanViMP-Net,andourPSNR,SSIM,andLPIPSscoresare32.04
Lùëùùëíùëüùëêùëíùëùùë°ùë¢ùëéùëô =LùëÄùëÜùê∏ (cid:16) ùëâùê∫ùê∫3,8,15(ùêΩÀÜ ùë°),ùëâùê∫ùê∫3,8,15(ùêΩ ùë°)(cid:17) . (14) dB,0.9366,and0.0684.Itindicatesthatthestatespacemodelwith
enhanced locality learning enables our framework to achieve a
bettertemporalmodelingability,whencomparedtotheopticalflow,
4 EXPERIMENTS
deformablekernel,andself-attentionofSOTAcomparedmethods.
4.1 DatasetandMetric
Inthissection,weconductacomparativeevaluationofourvideo 4.3.2 Quantitative Comparison on RainVID&SS Dataset. Tab. 2
reports the quantitative results of our proposed method and 6
derainingnetworkagainststate-of-the-artmethodsonfourbench-
SOTA video deraining methods on the two testing sets, which
markdatasets,includingtwovideorainstreakremovaldatasets,a
are ImageNet-VID+ dataset and the Cam-Vid+ dataset. These 6
videoraindropremovaldataset,andavideorainstreakandraindrop
SOTAvideoderainingmethodsareMSCSC[35],FastDrain[30],
removaldataset.Weutilizethepeaksignal-to-noiseratio(PSNR),
PReNet[48],SLDNet[73],S2VD[82],andMPEVNet[53].Regarding
thestructuralsimilarityindex(SSIM)[63],andthelearnedpercep-
theImageNet-VID+dataset,ourmethodachievesthelargestPSNR
tualimagepatchsimilarity(LPIPS)[87]toquantitativelycompare
scoreof35.07dBandthelargestSSIMscoreof0.9561.Asthefirst
differentmethods.
place,ourmethodoutperformsthesecondplace(i.e.,MPEVNet)
Video Rain Streak Removal Datasets. These two video rain
byaPSNRmarginof1.24dBandaSSIMmarginof0.0109.Onthe
streakremovaldatasetsareRainVID&SS(RainVideoDetectionand
Cam-Vid+dataset,ourvideoderainingnetworkachievesthelargest
SemanticSegmentation)[53]andRainSynAll100[72].RainVID&SS
PSNRscoreof32.65dBandthelargestSSIMscoreof0.9328,which
includes205shortclipsfromImageNet-VIDand3longclipsfrom
outperformsallcomparedsixmethods.Itindicatesthatourmethod
CamVidfortraining.Thetrainingsethas86shortclipsand2long
canmoreeffectivelyremoverainstreaksandhasabettercapability
clips.TheRainSynAll100datasetcomprises900videosfortraining
insignificantlyimprovingtheimagequalityofinputrainyvideos
and100videosfortesting.
withrainstreaks.
VideoRaindropRemovalDataset.LWDDS(Large-scaleWater-
dropDatasetforDrivingScenes)[64]isthefirstsyntheticvideo
4.3.3 QuantitativeComparisononRainSynAll100Dataset. Tab.3
waterdrop dataset for raindrop removal in driving scenes. This
reportsthequantitativeresultsofournetworkwith6SOTAvideo
dataset has 67,500 triplets from 45 videos for training, and 600
deraining methods, and they are FastDerain [30], FCRVD [71],
tripletsobtainedfrom6videosfortesting.
RMFD[72],BasicVSR++[8],NCFL[27],andSALN[78].SALNhas
VideoRainStreakandRaindropRemovalDataset.VRDS[67]
thebetterPSNRandSSIMscoresamongthe6SOTAmethods.Com-
istheonlyvideoraindropandrainstreakremovaldatasetwitha
paredtoSALN,ourmethodimprovesthePSNRscorefrom29.78dB
totalof102videos.72videoswith7200framesareusedfortraining,
to32.16dB,andenhancestheSSIMscorefrom0.9315to0.9446.Our
while30videoswith3000framesarefortesting.RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
Table1:QuantitativecomparisonsbetweenournetworkandSOTAmethodsontheVRDSdataset[67].Resultsofcompared
methodsarefromViMP-Net[67].
Methods CCN[47] PreNet[48] DRSformer[15] MPRNet[84] Restormer[83] S2VD[82] SLDNet[73] ESTINet[86] RDD[58] RVRT[36] BasicVSR++[8] ViMP-Net[67] Ours
PSNR‚Üë 23.75 27.13 28.54 29.53 29.59 18.95 23.65 27.17 28.39 28.24 29.75 31.02 32.04
SSIM‚Üë 0.8410 0.9014 0.9075 0.9175 0.9206 0.6630 0.8736 0.8436 0.9096 0.8857 0.9171 0.9283 0.9366
LPIPS‚Üì 0.2091 0.1266 0.1143 0.0987 0.0925 0.2833 0.1790 0.2253 0.1168 0.1438 0.1023 0.0862 0.0684
Table2:QuantitativecomparisonbetweenournetworkSOTAvideoderainingmethodsonthetwodatasetsofRainVID&SS
dataset[53].ResultsofcomparedmethodsarefromMPEVNet[53].
Datasets ImageNet-VID+ Cam-Vid+
Methods MSCSC[35] FastDrain[30] PReNet[48] S2VD[82] MPEVNet[53] Ours MSCSC[35] FastDrain[30] PReNet[48] SLDNet[73] S2VD[82] MPEVNet[53] Ours
PSNR‚Üë 18.41 17.08 24.73 29.92 33.83 35.07 21.22 19.94 25.33 18.97 29.11 32.55 32.65
SSIM‚Üë 0.5148 0.4381 0.7393 0.9228 0.9452 0.9561 0.5515 0.4830 0.7647 0.6267 0.8899 0.9234 0.9328
Table 3: Quantitative comparisons between our network and completeness of the window area impacted by rain, while
andSOTAvideoderainingmethodsontheRainSynAll100 alsoretainingitsnaturalcoloration.Ournetworkdemonstrates
dataset[72].NotethatthePSNRandSSIMresultsofcom- superiorpreservationofnon-rainbackgrounddetailsbyleveraging
paredmethodsarefromSALN[78]andNCFL[27]. statespacemodelsforcausallytemporalmodeling,combinedwith
Methods FastDerain[30] FCRVD[71] RMFD[72] BasicVSR++[8] NCFL[27] SALN[78] Ours enhancedlocalitylearningatboththesequenceandpatchlevels.
PSNR 17.09 21.06 25.14 27.67 28.11 29.78 32.16 Moreover,Figure5showsthevisualresultsofournetworkand
SSIM 0.5824 0.7405 0.9172 0.9135 0.9235 0.9315 0.9446
state-of-the-artmethodsonreal-worldrainyvideoframes.These
Table4:Quantitativecomparisonsbetweenourmethodand
visualresultsindicatethatourmethodcanmoreeffectivelyremove
SOTAvideoderainingmethodsontheLWDDSdataset[64].
rainstreaksandraindropsinreal-worlddrivingscenesandduring
TheresultsofcomparedmethodsarefromSALN[78].
outdoorvideorecordings,makingitmoreapplicabletocommon
Methods CCN[47] Vid2Vid[60] VWR[64] BasicVSR++[8] ViMP-Net[67] SALN[78] Ours
PSNR‚Üë 27.53 28.73 30.72 32.37 34.22 36.57 37.21 outdoormultimediaapplications.
SSIM‚Üë 0.922 0.9542 0.9726 0.9792 0.9784 0.9802 0.9816 4.3.6 ModelComplexityandEfficiencyComparison. Asreported
Table5:Quantitativeresultsofournetworkandconstructed
in Table 6, we compare the number of parameters, FLOPs, and
baselinenetworksoftheablationstudyontheVRDSdataset.
runningtimeofournetworkandstate-of-the-artmethodsona
Model GMB LMB DCL PSNR‚Üë SSIM‚Üë LPIPS‚Üì GFLOPs Parameters(M) Inferencetime(s) Runtime(s/frame) NVIDIARTX4090GPU.TheGFLOPsandRuntimearecalculated
M1 29.35 0.9118 0.0893 49.82 30.23 0.0190 0.0038
M2 ‚úì 30.86 0.9277 0.0774 84.40 32.49 0.0348 0.0070 byinferringavideoclipoffiveframeswitharesolutionof256√ó256.
M3 ‚úì 31.04 0.9302 0.0753 84.40 32.49 0.0355 0.0071
M4 ‚úì ‚úì 31.79 0.9361 0.0704 118.99 34.75 0.0559 0.0112 Wefollow[34]tocalculatetheGFLOPsmetric.Andtheruntime
Ours ‚úì ‚úì ‚úì 32.04 0.9376 0.0684 118.99 34.75 0.0560 0.0112
Table6:Modelcomplexitycomparisonswithpreviousmodel. indicatesthetimeneededtoprocesseachframeduringinference.
ThankstothelinearcomplexityofSSMsandthecriticalcomponents
Method DRSformer[15] MPRNet[84] Restormer[83] BasicVSR++[8] ESTINet[86] Ours
GFLOPs 1101.89 706.19 704.95 1616.44 681.83 118.99 ofournetwork,ourapproachachievessignificantimprovements
R Pu an rt aim me e( ts e/ rf sr (a Mm )e) 0 3.0 33 .68 31 0 3.0 .636 47 0 2.0 66 .19 06 0. 60 .5 21 21 0 2.0 23 .94 61 0 3.0 41 .71 52 inbotheffectivenessandefficiency.Formorediscussionsonthe
superiorPSNRandSSIMperformanceexperimentalresultsdemon-
modelefficiency,pleaserefertoSupplementaryMaterial.
strateourproposedtechniquesignificantlysurpassesallcompeting 4.4 AblationStudy
methodsintermsofremovingrainstreaksfromrainyvideos. 4.4.1 BaselineDesign. Weperformablationexperimentstoverify
4.3.4 QuantitativeComparisononLWDDSDataset. Tab.4summa- theeffectivenessofthreecriticalcomponentsofournetwork,and
rizesthePSNRandSSIMscoresofourproposedmethodand6SOTA theyaretheGlobalMambaBlock(GMB),theLocalMambaBlock
videoraindropsremovalmethodsontheLWDDSdatasets.These6 (LMB),andtheDifference-GuidedDynamicContrastiveLocality
SOTAvideoraindropsremovalmethodsareCCN[47],Vid2Vid[60], Learning(DCL)ofourRainMamba.Initially,weestablishabaseline
VWR[64],BasicVSR++[8],ViMP-Net[67],andSALN[78].From (denotedas‚ÄúM1‚Äù)byremovingallthreemajorcomponentsfromour
thesequantitativeresultsinTab.4,wecanfindthatSALNhasthe network.Subsequently,theGlobalMambaBlockisincorporated
largestPSNRscoreof36.57dB,andthelargestSSIMscoreof0.9802 intothebaselinemodel‚ÄúM1"tobuild‚ÄúM2".Followingthis,‚ÄúM3"is
amongallcompared6SOTAvideoraindropsremovalmethods. constructedbyintegratingtheLocalMambaBlockinto‚ÄúM1".To
Moreimportantly,ourmethodfurtherimprovesthePSNRscore build‚ÄúM4",theGlobalMambaBlockisintegratedinto‚ÄúM3",thereby
from36.57dBto37.21dB,andtheSSIMscorefrom0.9802to0.9816. resultinginacompleteCoarse-to-FineMambaModule.Finally,we
Italsoverifiesthesuperioreffectofourmethodintermsofthe addourcontrastivelearningstrategyto‚ÄúM4"toreachafullsetting
videoraindropremovaltask. ofourRainMambamodel.
4.3.5 VisualComparisons. Fig.4visuallycomparestheresultsof 4.4.2 QuantitativeComparison. Tab.5presentsthequantitative
removingrainstreaksandraindropsfromvideoframesontheVRDS resultsofourproposedmethodalongsidethefourbaselinenet-
dataset with different rainfall intensity and lighting conditions. works(i.e.,‚ÄúM1"through‚ÄúM4")ontheVRDSdatasets.Specifically,
Ournetwork demonstratessuperiorperformanceinrecovering comparedwith‚ÄúM1‚Äù,‚ÄúM2‚ÄùimprovesthePSNRscorefrom29.35dB
cleanbackgroundimages,particularlyexcellinginraindropareas to30.86dB,theSSIMscorefrom0.9118to0.9277,andtheLPIPS
whereitmoreeffectivelyrestoresdetailedtexture.Thesevisual scorefrom0.0893to0.0774.Itdemonstratestheeffectivenessof
resultsdemonstratethatournetworkexcelsinrecoveringimage ourGlobalMambaBlockinemployingstatespacemodelstocap-
areasaffectedbyraindropsandrainstreaks.Forinstance,inthe turelong-rangedependenciesamongsequentialframes.Also,‚ÄúM3"
thirdsampleset,ourapproacheffectivelymaintainsthecoherence demonstratesafurthermetricimprovement,whichindicatesthatACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
Input Restormer BasicVSR++ DRSformer RDD ViMP-Net Ours Ground truth
Figure4:Visualcomparisonsofderainedresultsfromournetworkandstate-of-the-artderainingmethodsoninputvideo
framesfromtheVRDSdataset.(Pleasezoominforabetterillustration.)
Input DRSformer RDD BasicVSR++ ViMP-Net Ours
Figure5:Visualcomparisonsofderainedresultsproducedbyournetworkandstate-of-the-artderainingmethodsoninput
videoframesfromreal-worldrainyvideos.(Pleasezoominforabetterillustration.)
theLocalMambaBlockcanimprovethevideorestorationquality Table7:ComparisonsofotherHilbertscanningdirections.
ofournetworkbyenhancinglocalitylearning.Furthermore,‚ÄúM4" Methods PSNR‚Üë SSIM‚Üë LPIPS‚Üì
significantlyadvancesbeyondM3,whichprovestheeffectiveness Width-first 29.98 0.9359 0.0698
Height-first 32.01 0.9362 0.0691
ofincorporatinglocalscanningandHilbertscanningmechanism Time-first(Ours) 32.04 0.9366 0.0684
togethertomodeltemporalinformationinasequence-levelmanner. Table8:Quantitativecomparisonsbetweenournetworkand
Moreover,ournetworkfurtheroutperforms‚ÄúM4",whichindicates SOTAmethodsontheNTURaindataset[11].
thatleveragingourcontrastivelearningstrategybenefitsthelo-
Method MSCSC[35] J4RNet[40] SPAC[11] FCRNet[71] SLDNet[73] MPRNet[84] S2VD[82] ESTINet[86] Ours
calitylearningofournetworkinapatch-levelmanner,thereby PSNR‚Üë 27.31 32.14 33.11 36.05 34.89 36.11 37.37 37.48 37.87
SSIM‚Üë 0.7870 0.9480 0.9474 0.9676 0.9540 0.9637 0.9683 0.9700 0.9738
improvingthevideoderainingperformanceofournetwork.
Table9:Analysisoflongvideoprocessingbyournetwork
4.4.3 ComparisonsofHilbert-basedScanningdirections. Wealse ontheNTURaindataset[11].
comparedthreemainHilbert-basedscanningdirectionsonmodel
7 10 20 30 40 50 60 70 80 90 100 110
performanceinTable7.Startingfromthesamepoint,thereare P SS SN IMR ‚Üë‚Üë 03 .97 6.5 93 04 4 03 .97 7.7 32 32 1 03 .97 7.8 30 56 7 03 .97 7.8 33 68 7 03 .97 7.8 34 77 1 03 .97 7.8 35 78 4 03 .97 7.8 36 73 6 03 .97 7.8 36 77 8 03 .97 7.8 37 70 9 03 .97 7.8 37 85 0 03 .97 7.8 37 86 0 03 .97 7.8 37 85 0
Memory 5,082M 6,026M 9,530M 13,054M 17,296M 20,056M 23,556M 27,068M 32,056M 34,090M 37,594M 41,100M
threemainscanningdirections,namelywidth-first,height-first,
andtime-first.Theresultindicatesthatourmodelisinsensitiveto removerainstreaks.Formorevisualresultsanddiscussionson
theHilbert-basedscanningdirections,sinceHilbertscanenhances NTURaindataset,pleaserefertoSupplementaryMaterial.
theoverallspatio-temporallocalitybetweentheadjacenttokens
5 CONCLUSION
withinone-dimensionalsequence.
Inthiswork,wepresentanovelvideoderainingframeworkRain-
4.4.4 QuantitativeComparisonandAnalysisofLongVideoProcess- Mambawiththeimprovedstatespacemodels.Tothebestofour
ingonNTURainDataset. Wealsoconductedcomparisonsofour knowledge,wearethefirsttoapplystatespacemodelstoachieveef-
modelwithothervideoderainingmethodsonNTURaindataset
fectiverainstreaksandraindropsremovalinvideos.Tobetteradapt
forvideorainstreakremoval.Fromthesequantitativeresultsin
Mambatovideoderainingtasks,weintroduceaHilbertscanning
Tab.8,Ourmethoddemonstratesanenhancementinperformance
mechanismtopreservetheregionaldetailsbasedonthesequence
overtheESTINet[86].Wealsoexploredthepotentialofourmodel
level,whichisthecoreelementofourLocalMambaBlock.More-
inhandlingultralongvideos.AsreportedinTable 9,weinput
over,adifference-guideddynamiccontrastivelocalitylearningis
fullresolutionvideoclipsandcomparetheexperimentalresults
designedtofurtherenhancethelocalsemanticsfromthepatch
fromusingvideoclipsofdifferentlengths.Theexperimentalresults
level.Experimentalresultsonfourvideo-derainingbenchmarking
indicatethatastheinputframerateincreases,theeffectivenessof
datasetsdemonstratethesuperiorityofourproposedframework.
videorestorationalsoimproves.Thisdemonstratesthatthelong-
Webelievethiswillbeacompellingbaselineforthefutureofstate
sequencemodelingcapabilityofSSMscaneffectivelyleveragethe
spacemodelsinthecommunityoflow-levelvisiontasks.
spatio-temporalcontextualinformationinvideostosuccessfullyRainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
ACKNOWLEDGMENTS [19] KshitizGargandShreeKNayar.2004.Detectionandremovalofrainfromvideos.
This work was supported by the Guangzhou-HKUST(GZ) Joint I an ndPr Po ac te te ed ri nn Rgs eco of gt nh ie ti2 o0 n0 ,4 20IE 0E 4.E CC Vo Pm Rp 2u 0t 0e 4r .,S Voc oi le .t 1y .C IEo En Efe ,r Ie ‚Äìn Ic .eonComputerVision
FundingProgram(No.2023A03J0671),Thisworkissupported/funded [20] AlbertGuandTriDao.2023. Mamba:Linear-timesequencemodelingwith
bytheGuangzhouMunicipalScienceandTechnologyProject(No.
selectivestatespaces.arXivpreprintarXiv:2312.00752(2023).
[21] AlbertGu,KaranGoel,andChristopherR√©.2021. Efficientlymodelinglong
2024A04J4230),theGuangzhouIndustrialInformationandIntel- sequenceswithstructuredstatespaces.arXivpreprintarXiv:2111.00396(2021).
ligent Key Laboratory Project (No. 2024A03J0628), the Nansha [22] AlbertGu,IsysJohnson,KaranGoel,KhaledSaab,TriDao,AtriRudra,and
ChristopherR√©.2021.Combiningrecurrent,convolutional,andcontinuous-time
KeyAreaScienceandTechnologyProject(No.2023ZD003),and
modelswithlinearstatespacelayers.Advancesinneuralinformationprocessing
Guangzhou-HKUST(GZ)JointFundingProgram(No.2024A03J0618). systems34(2021),572‚Äì585.
[23] HangGuo,JinminLi,TaoDai,ZhihaoOuyang,XudongRen,andShu-TaoXia.
2024.MambaIR:ASimpleBaselineforImageRestorationwithState-SpaceModel.
REFERENCES arXivpreprintarXiv:2402.15648(2024).
[1] StefanoAlletto,CaseyCarlin,LucaRigazio,YasunoriIshii,andSotaroTsuk- [24] JunlinHan,MehrdadShoeiby,LarsPetersson,andMohammadAliArmin.2021.
izawa.2019.Adherentraindropremovalwithself-supervisedattentionmapsand Dualcontrastivelearningforunsupervisedimage-to-imagetranslation.InPro-
spatio-temporalgenerativeadversarialnetworks.InProceedingsoftheIEEE/CVF ceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
InternationalConferenceonComputerVisionWorkshops.0‚Äì0. 746‚Äì755.
[2] AnuragArnab,MostafaDehghani,GeorgHeigold,ChenSun,MarioLuƒçiƒá,and [25] KaimingHe,HaoqiFan,YuxinWu,SainingXie,andRossGirshick.2020.Mo-
CordeliaSchmid.2021.Vivit:Avideovisiontransformer.InProceedingsofthe mentumcontrastforunsupervisedvisualrepresentationlearning.InProceedings
IEEE/CVFinternationalconferenceoncomputervision.6836‚Äì6846. oftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.9729‚Äì9738.
[3] TetsuoAsano,DeshRanjan,ThomasRoos,EmoWelzl,andPeterWidmayer. [26] DavidHilbert.1935.√úberdiestetigeAbbildungeinerLinieaufeinFl√§chenst√ºck.
1997.Space-fillingcurvesandtheiruseinthedesignofgeometricdatastructures. SpringerBerlinHeidelberg,Berlin,Heidelberg,1‚Äì2. https://doi.org/10.1007/978-
TheoreticalComputerScience181,1(1997),3‚Äì15. 3-662-38452-7_1
[4] ZoranBalkiƒá,Damir≈†o≈°tariƒá,andGoranHorvat.2012. GeoHashandUUID [27] CongHuang,JiahaoLi,BinLi,DongLiu,andYanLu.2022.Neuralcompression-
identifierformulti-agentsystems.InAgentandMulti-AgentSystems.Technologies basedfeaturelearningforvideorestoration.InProceedingsoftheIEEE/CVF
andApplications:6thKESInternationalConference,KES-AMSTA2012,Dubrovnik,
conferenceoncomputervisionandpatternrecognition.5872‚Äì5881.
Croatia,June25-27,2012.Proceedings6.Springer,290‚Äì298. [28] TaoHuang,XiaohuanPei,ShanYou,FeiWang,ChenQian,andChangXu.2024.
[5] PeterCBarnum,SrinivasaNarasimhan,andTakeoKanade.2010.Analysisof Localmamba:Visualstatespacemodelwithwindowedselectivescan. arXiv
rainandsnowinfrequencyspace. Internationaljournalofcomputervision86 preprintarXiv:2403.09338(2024).
(2010),256‚Äì274. [29] HosagraharVJagadish.1990.Linearclusteringofobjectswithmultipleattributes.
[6] KonstantinEvgen‚ÄôevichBauman.2006.ThedilationfactorofthePeano-Hilbert InProceedingsofthe1990ACMSIGMODinternationalconferenceonManagement
curve.MathematicalNotes80(2006),609‚Äì620. ofdata.332‚Äì342.
[7] YoshuaBengio,J√©r√¥meLouradour,RonanCollobert,andJasonWeston.2009. [30] Tai-XiangJiang,Ting-ZhuHuang,Xi-LeZhao,Liang-JianDeng,andYaoWang.
Curriculumlearning.InProceedingsofthe26thannualinternationalconference 2018.Fastderain:Anovelvideorainstreakremovalmethodusingdirectional
onmachinelearning.41‚Äì48. gradientpriors.IEEETransactionsonImageProcessing28,4(2018),2089‚Äì2102.
[8] KelvinCKChan,ShangchenZhou,XiangyuXu,andChenChangeLoy.2022. [31] JustinJohnson,AlexandreAlahi,andLiFei-Fei.2016.Perceptuallossesforreal-
BasicVSR++:Improvingvideosuper-resolutionwithenhancedpropagationand timestyletransferandsuper-resolution.InComputerVision‚ÄìECCV2016:14th
alignment.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand EuropeanConference,Amsterdam,TheNetherlands,October11-14,2016,Proceed-
patternrecognition.5972‚Äì5981. ings,PartII14.Springer,694‚Äì711.
[9] PierreCharbonnier,LaureBlanc-Feraud,GillesAubert,andMichelBarlaud.1994. [32] RudolphEmilKalman.1960.Anewapproachtolinearfilteringandprediction
Twodeterministichalf-quadraticregularizationalgorithmsforcomputedimaging. problems.(1960).
InProceedingsof1stinternationalconferenceonimageprocessing,Vol.2.IEEE, [33] DiederikPKingmaandJimmyBa.2014.Adam:Amethodforstochasticopti-
168‚Äì172. mization.arXivpreprintarXiv:1412.6980(2014).
[10] HaoyuChen,JingjingRen,JinjinGu,HongtaoWu,XuequanLu,HaomingCai, [34] KunchangLi,XinhaoLi,YiWang,YinanHe,YaliWang,LiminWang,andYu
andLeiZhu.2023.SnowRemovalinVideo:ANewDatasetandANovelMethod. Qiao.2024.VideoMamba:StateSpaceModelforEfficientVideoUnderstanding.
InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision.13211‚Äì arXivpreprintarXiv:2403.06977(2024).
13222. [35] MinghanLi,QiXie,QianZhao,WeiWei,ShuhangGu,JingTao,andDeyuMeng.
[11] JieChen,Cheen-HauTan,JunhuiHou,Lap-PuiChau,andHeLi.2018.Robust 2018.Videorainstreakremovalbymultiscaleconvolutionalsparsecoding.In
videocontentalignmentandcompensationforrainremovalinacnnframework. ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.
InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition. 6644‚Äì6653.
6286‚Äì6295. [36] JingyunLiang,YuchenFan,XiaoyuXiang,RakeshRanjan,EddyIlg,SimonGreen,
[12] TingChen,SimonKornblith,MohammadNorouzi,andGeoffreyHinton.2020.A JiezhangCao,KaiZhang,RaduTimofte,andLucVGool.2022.Recurrentvideo
simpleframeworkforcontrastivelearningofvisualrepresentations.InInterna- restorationtransformerwithguideddeformableattention.AdvancesinNeural
tionalconferenceonmachinelearning.PMLR,1597‚Äì1607. InformationProcessingSystems35(2022),378‚Äì393.
[13] WanliChen,XingeZhu,GuojinChen,andBeiYu.2022.Efficientpointcloud [37] Jan-YieLiang,Chih-ShengChen,Chua-HuangHuang,andLiLiu.2008.Lossless
analysisusinghilbertcurve.InEuropeanConferenceonComputerVision.Springer, compressionofmedicalimagesusingHilbertspace-fillingcurves.Computerized
730‚Äì747. MedicalImagingandGraphics32,3(2008),174‚Äì182.
[14] XiaozhiChen,KaustavKundu,ZiyuZhang,HuiminMa,SanjaFidler,andRaquel [38] YuanchuLiang,SaeedAnwar,andYangLiu.2022. Drt:Alightweightsingle
Urtasun.2016.Monocular3dobjectdetectionforautonomousdriving.InProceed- imagederainingrecursivetransformer.InProceedingsoftheIEEE/CVFConference
ingsoftheIEEEconferenceoncomputervisionandpatternrecognition.2147‚Äì2156. onComputerVisionandPatternRecognition.589‚Äì598.
[15] XiangChen,HaoLi,MingqiangLi,andJinshanPan.2023. Learningasparse [39] DingLiu,BihanWen,YuchenFan,ChenChangeLoy,andThomasSHuang.
transformernetworkforeffectiveimagederaining.InProceedingsoftheIEEE/CVF 2018. Non-localrecurrentnetworkforimagerestoration. Advancesinneural
ConferenceonComputerVisionandPatternRecognition.5896‚Äì5905. informationprocessingsystems31(2018).
[16] XiangChen,JinshanPan,KuiJiang,YufengLi,YufengHuang,CaihuaKong, [40] JiayingLiu,WenhanYang,ShuaiYang,andZongmingGuo.2018.Eraseorfill?
LonggangDai,andZhentaoFan.2022. Unpaireddeepimagederainingusing deepjointrecurrentrainremovalandreconstructioninvideos.InProceedingsof
dualcontrastivelearning.InProceedingsoftheIEEE/CVFconferenceoncomputer theIEEEconferenceoncomputervisionandpatternrecognition.3233‚Äì3242.
visionandpatternrecognition.2017‚Äì2026. [41] YueLiu,YunjieTian,YuzhongZhao,HongtianYu,LingxiXie,YaoweiWang,
[17] JunkaiFan,JiangweiWeng,KunWang,YijunYang,JianjunQian,JunLi,andJian QixiangYe,andYunfanLiu.2024. Vmamba:Visualstatespacemodel. arXiv
Yang.2024.Driving-VideoDehazingwithNon-AlignedRegularizationforSafety preprintarXiv:2401.10166(2024).
Assistance.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand [42] ZhuangLiu,HanziMao,Chao-YuanWu,ChristophFeichtenhofer,TrevorDarrell,
PatternRecognition.26109‚Äì26119. andSainingXie.2022.Aconvnetforthe2020s.InProceedingsoftheIEEE/CVF
[18] XueyangFu,JiabinHuang,DeluZeng,YueHuang,XinghaoDing,andJohn conferenceoncomputervisionandpatternrecognition.11976‚Äì11986.
Paisley.2017.Removingrainfromsingleimagesviaadeepdetailnetwork.In [43] MohamedFMokbel,WalidGAref,andIbrahimKamel.2003.Analysisofmulti-
ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition. dimensionalspace-fillingcurves.GeoInformatica7(2003),179‚Äì209.
3855‚Äì3863. [44] BongkiMoon,HosagraharVJagadish,ChristosFaloutsos,andJoelH.Saltz.2001.
AnalysisoftheclusteringpropertiesoftheHilbertspace-fillingcurve. IEEE
Transactionsonknowledgeanddataengineering13,1(2001),124‚Äì141.ACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
[45] EricNguyen,KaranGoel,AlbertGu,GordonDowns,PreeyShah,TriDao,Stephen [68] ZhaohuXing,TianYe,YijunYang,GuangLiu,andLeiZhu.2024.Segmamba:
Baccus,andChristopherR√©.2022.S4nd:Modelingimagesandvideosasmultidi- Long-rangesequentialmodelingmambafor3dmedicalimagesegmentation.
mensionalsignalswithstatespaces.Advancesinneuralinformationprocessing arXivpreprintarXiv:2401.13560(2024).
systems35(2022),2846‚Äì2861. [69] HuihuiXu,YijunYang,AngelicaI.Avil√©s-Rivero,GuangYang,JingQin,and
[46] AaronvandenOord,YazheLi,andOriolVinyals.2018.Representationlearning LeiZhu.2024. LGRNet:Local-GlobalReciprocalNetworkforUterineFibroid
withcontrastivepredictivecoding.arXivpreprintarXiv:1807.03748(2018). SegmentationinUltrasoundVideos. https://api.semanticscholar.org/CorpusID:
[47] RuijieQuan,XinYu,YuanzhiLiang,andYiYang.2021.Removingraindropsand 271050719
rainstreaksinonego.InProceedingsoftheIEEE/CVFConferenceonComputer [70] WendingYan,RobbyTTan,WenhanYang,andDengxinDai.2021.Self-aligned
VisionandPatternRecognition.9147‚Äì9156. videoderainingwithtransmission-depthconsistency.InProceedingsofthe
[48] DongweiRen,WangmengZuo,QinghuaHu,PengfeiZhu,andDeyuMeng. IEEE/CVFConferenceonComputerVisionandPatternRecognition.11966‚Äì11976.
2019.Progressiveimagederainingnetworks:Abetterandsimplerbaseline.In [71] WenhanYang,JiayingLiu,andJiashiFeng.2019. Frame-consistentrecurrent
ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition. videoderainingwithdual-levelflow.InProceedingsoftheIEEE/CVFconference
3937‚Äì3946. oncomputervisionandpatternrecognition.1661‚Äì1670.
[49] WeihongRen,JiandongTian,ZhiHan,AntoniChan,andYandongTang.2017. [72] WenhanYang,RobbyTTan,JiashiFeng,ShiqiWang,BinCheng,andJiayingLiu.
Videodesnowingandderainingbasedonmatrixdecomposition.InProceedings 2021.Recurrentmulti-framederaining:Combiningphysicsguidanceandadver-
oftheIEEEconferenceoncomputervisionandpatternrecognition.4210‚Äì4219. sariallearning.IEEETransactionsonPatternAnalysisandMachineIntelligence44,
[50] HansSagan.2012.Space-fillingcurves.SpringerScience&BusinessMedia. 11(2021),8569‚Äì8586.
[51] YuanShi,BinXia,XiaoyuJin,XingWang,TianyuZhao,XinXia,XuefengXiao, [73] WenhanYang,RobbyTTan,ShiqiWang,andJiayingLiu.2020.Self-learningvideo
andWenmingYang.2024. VmambaIR:VisualStateSpaceModelforImage rainstreakremoval:Whencyclicconsistencymeetstemporalcorrespondence.In
Restoration.arXivpreprintarXiv:2403.11423(2024). ProceedingsoftheIEEE/CVFconferenceoncomputervisionandpatternrecognition.
[52] KarenSimonyanandAndrewZisserman.2014.Verydeepconvolutionalnetworks 1720‚Äì1729.
forlarge-scaleimagerecognition.arXivpreprintarXiv:1409.1556(2014). [74] YijunYang,AngelicaIAviles-Rivero,HuazhuFu,YeLiu,WeimingWang,and
[53] ShangquanSun,WenqiRen,JingzhiLi,KaihaoZhang,MeiyuLiang,andXiaochun LeiZhu.2023.VideoAdverse-Weather-ComponentSuppressionNetworkvia
Cao.2023.Event-awarevideoderainingviamulti-patchprogressivelearning. WeatherMessengerandAdversarialBackpropagation.InProceedingsofthe
IEEETransactionsonImageProcessing(2023). IEEE/CVFInternationalConferenceonComputerVision.13200‚Äì13210.
[54] HongqiuWang,JianChen,ShichenZhang,YuanHe,JinfengXu,MengwanWu, [75] YijunYang,ShujunWang,LihaoLiu,SarahHickman,FionaJGilbert,Carola-
JinlanHe,WenjunLiao,andXiangdeLuo.2024.Dual-referencesource-freeactive BibianeSch√∂nlieb,andAngelicaIAviles-Rivero.2023.MammoDG:Generalisable
domainadaptationfornasopharyngealcarcinomatumorsegmentationacross DeepLearningBreakstheLimitsofCross-DomainMulti-CenterBreastCancer
multiplehospitals.IEEETransactionsonMedicalImaging(2024). Screening.arXivpreprintarXiv:2308.01057(2023).
[55] HongqiuWang,YuemingJin,andLeiZhu.2023.DynamicInteractiveRelation [76] YijunYang,HongtaoWu,AngelicaIAviles-Rivero,YulunZhang,JingQin,andLei
CapturingviaSceneGraphLearningforRoboticSurgicalReportGeneration. Zhu.2024.GenuineKnowledgefromPractice:DiffusionTest-TimeAdaptation
In2023IEEEInternationalConferenceonRoboticsandAutomation(ICRA).IEEE, forVideoAdverseWeatherRemoval.InProceedingsoftheIEEE/CVFConference
2702‚Äì2709. onComputerVisionandPatternRecognition.25606‚Äì25616.
[56] HongqiuWang,GuangYang,ShichenZhang,JingQin,YikeGuo,BoXu,Yueming [77] YijunYang,ZhaohuXing,andLeiZhu.2024.Vivim:avideovisionmambafor
Jin,andLeiZhu.2024.Video-instrumentsynergisticnetworkforreferringvideo medicalvideoobjectsegmentation.arXivpreprintarXiv:2401.14168(2024).
instrumentsegmentationinroboticsurgery.IEEETransactionsonMedicalImaging [78] TianYe,SixiangChen,YunLiu,WenhaoChai,JinbinBai,WenbinZou,Yunchen
(2024). Zhang,MingchaoJiang,ErkangChen,andChenghaoXue.2023.SequentialAffin-
[57] JinWang,WenmingWeng,YueyiZhang,andZhiweiXiong.2023. Unsuper- ityLearningforVideoRestoration.InProceedingsofthe31stACMInternational
visedVideoDerainingwithAnEventCamera.InProceedingsoftheIEEE/CVF ConferenceonMultimedia.4147‚Äì4156.
InternationalConferenceonComputerVision.10831‚Äì10840. [79] YuntongYe,ChangfengYu,YiChang,LinZhu,Xi-LeZhao,LuxinYan,and
[58] ShuaiWang,LeiZhu,HuazhuFu,JingQin,Carola-BibianeSch√∂nlieb,WeiFeng, YonghongTian.2022.Unsupervisedderaining:Wherecontrastivelearningmeets
andSongWang.2022.RethinkingVideoRainStreakRemoval:ANewSynthesis self-similarity.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
ModelandaDerainingNetworkwithVideoRainPrior.InComputerVision‚ÄìECCV patternrecognition.5821‚Äì5830.
[80] ShaodiYou,RobbyTTan,ReiKawakami,YasuhiroMukaigawa,andKatsushi
2022:17thEuropeanConference,TelAviv,Israel,October23‚Äì27,2022,Proceedings,
PartXIX.Springer,565‚Äì582. Ikeuchi.2015.Adherentraindropmodeling,detectionandremovalinvideo.IEEE
[59] TianyuWang,XinYang,KeXu,ShaozheChen,QiangZhang,andRynsonWH transactionsonpatternanalysisandmachineintelligence38,9(2015),1721‚Äì1733.
Lau.2019.Spatialattentivesingle-imagederainingwithahighqualityrealrain [81] KaishenYuan,ZitongYu,XinLiu,WeichengXie,HuanjingYue,andJingyuYang.
dataset.InProceedingsoftheIEEE/CVFconferenceoncomputervisionandpattern 2024.Auformer:Visiontransformersareparameter-efficientfacialactionunit
recognition.12270‚Äì12279. detectors.arXivpreprintarXiv:2403.04697(2024).
[60] Ting-ChunWang,Ming-YuLiu,Jun-YanZhu,GuilinLiu,AndrewTao,Jan [82] ZongshengYue,JianwenXie,QianZhao,andDeyuMeng.2021.Semi-supervised
Kautz,andBryanCatanzaro.2018. Video-to-videosynthesis. arXivpreprint videoderainingwithdynamicalraingenerator.InProceedingsoftheIEEE/CVF
arXiv:1808.06601(2018). ConferenceonComputerVisionandPatternRecognition.642‚Äì652.
[61] XiaolongWang,RossGirshick,AbhinavGupta,andKaimingHe.2018.Non-local [83] SyedWaqasZamir,AdityaArora,SalmanKhan,MunawarHayat,FahadShah-
neuralnetworks.InProceedingsoftheIEEEconferenceoncomputervisionand bazKhan,andMing-HsuanYang.2022. Restormer:Efficienttransformerfor
patternrecognition.7794‚Äì7803. high-resolutionimagerestoration.InProceedingsoftheIEEE/CVFConferenceon
[62] YanboWang,ShaohuiLin,YanyunQu,HaiyanWu,ZhizhongZhang,Yuan ComputerVisionandPatternRecognition.5728‚Äì5739.
Xie,andAngelaYao.2021.Towardscompactsingleimagesuper-resolutionvia [84] SyedWaqasZamir,AdityaArora,SalmanKhan,MunawarHayat,FahadShahbaz
contrastiveself-distillation.arXivpreprintarXiv:2105.11683(2021). Khan,Ming-HsuanYang,andLingShao.2021.Multi-stageprogressiveimage
[63] ZhouWang,AlanCBovik,HamidRSheikh,andEeroPSimoncelli.2004.Image restoration.InProceedingsoftheIEEE/CVFconferenceoncomputervisionand
qualityassessment:fromerrorvisibilitytostructuralsimilarity.IEEEtransactions patternrecognition.14821‚Äì14831.
onimageprocessing13,4(2004),600‚Äì612. [85] KaihaoZhang,DongxuLi,WenhanLuo,andWenqiRen.2021.Dualattention-
[64] QiangWen,YueWu,andQifengChen.2023. VideoWaterdropRemovalvia in-attentionmodelforjointrainstreakandraindropremoval.IEEETransactions
Spatio-TemporalFusioninDrivingScenes.arXivpreprintarXiv:2302.05916(2023). onImageProcessing30(2021),7608‚Äì7619.
[65] HaiyanWu,YanyunQu,ShaohuiLin,JianZhou,RuizhiQiao,ZhizhongZhang, [86] KaihaoZhang,DongxuLi,WenhanLuo,WenqiRen,andWeiLiu.2022.Enhanced
YuanXie,andLizhuangMa.2021.Contrastivelearningforcompactsingleimage spatio-temporalinteractionlearningforvideoderaining:fasterandbetter.IEEE
dehazing.InProceedingsoftheIEEE/CVFConferenceonComputerVisionand TransactionsonPatternAnalysisandMachineIntelligence45,1(2022),1287‚Äì1293.
PatternRecognition.10551‚Äì10560. [87] RichardZhang,PhillipIsola,AlexeiAEfros,EliShechtman,andOliverWang.
[66] HongtaoWu,YijunYang,AngelicaAviles-Rivero,JingjingRen,Sixiangchen, 2018. Theunreasonableeffectivenessofdeepfeaturesasaperceptualmetric.
HaoyuChen,andLeiZhu.2024.Semi-SupervisedVideoDesnowingNetwork InProceedingsoftheIEEEconferenceoncomputervisionandpatternrecognition.
viaTemporalDecouplingExpertsandDistribution-DrivenContrastiveRegular- 586‚Äì595.
ization.InEuropeanConferenceonComputerVision. [88] YujunZhang,LeiZhu,WeiFeng,HuazhuFu,MingqianWang,QingxiaLi,Cheng
[67] HongtaoWu,YijunYang,HaoyuChen,JingjingRen,andLeiZhu.2023.Mask- Li,andSongWang.2021.Vil-100:Anewdatasetandabaselinemodelforvideo
GuidedProgressiveNetworkforJointRaindropandRainStreakRemovalin instancelanedetection.InProceedingsoftheIEEE/CVFinternationalconference
Videos.InProceedingsofthe31stACMInternationalConferenceonMultimedia. oncomputervision.15681‚Äì15690.
7216‚Äì7225. [89] LianghuiZhu,BenchengLiao,QianZhang,XinlongWang,WenyuLiu,and
XinggangWang.2024.VisionMamba:EfficientVisualRepresentationLearning
withBidirectionalStateSpaceModel.arXivpreprintarXiv:2401.09417(2024).SupplementaryMaterials:RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining
‚ÄìSupplementaryMaterial‚Äì
7 MOREABLATIONSTUDIES
7.1 VisualResultsofAblationStudy
AsshowninFigure7,inadditiontoquantitativelycomparingthe
ablationexperimentsofRainMambaonVRDSdataset,wealsocon-
ductedvisualcomparisonstoqualitativelyverifytheeffectiveness
ofthreecriticalcomponentsofournetwork.Byintroducingthe
GlobalMambaBlock(GMB),our‚ÄúM2‚Äùmodeleffectivelyeliminates
a significant number of artifacts associated with raindrops and
rainstreaks,comparedto‚ÄúM1‚Äù.However,the‚ÄúM3‚Äùmodelcannot
preservethespatialstructureofcertaindetailseffectivelyandin-
troducedextensiveartifactsoutsidethewindow.LeveragingLocal
MambaBlock(LMB),our‚ÄúM3‚Äùmodelachievessuperiordetailre-
tention,suchastheshapeofwindows.TheintegrationofGMBand
LMBsignificantlyenhancesthedetailrecoveryinareasobscured
Figure6:PSNRperformancev.sRuntimeandGFLOPson byraindrops,asour‚ÄúM4‚Äùmodelimprovesthemodelingabilityof
VRDSdataset.Thesizeofthecirclesandpentagramindicates spatiotemporalinformation.Bycombiningthesethreecomplemen-
theGFLOPsofmodel. tarycontributions,ourRainMambaclearlyremovestheartifacts
andbetterrestoresthescenestructures.
Inthissupplementarymaterial,wepresentnetworkcomplex-
ity(Section6),moreablationstudies(Section7)andextravisual 7.2 VisualComparisonsofDifferentScanning
demonstration(Section8).Inaddition,avideodemoisprovided Mechanisms
toshowcasethedynamicdisplayofourproposedlocalscanning Figure8illustratestheresultsof‚ÄúM2‚Äùand‚ÄúM3‚Äùmodel.The‚ÄúM2‚Äù
mechanismandtheeffectivenessofourmethodatthislink. modelcangenerateincorrectdirectionalextensionswhenrecon-
structingtheshapesofobjectsobscuredbyraindrops.Thisissue
6 MODELANALYSIS arisesbecause‚ÄúM2‚Äùutilizesaglobalscanningapproach(row-and-
6.1 ModelComplexityandParameters column-majororder),whichneglectsspatio-temporalcontinuity
andleadstolocalpixelforgetting.Ourproposedlocalscanning
Comparison
mechanismimprovesthenetwork‚Äôslocalinformationawareness
As reported in Table 6, we compare the number of parameters,
byrearrangingthescanpathofMambainsequence-leveltemporal
FLOPs,andrunningtimeofournetworkandstate-of-the-artmeth-
modeling.
odsonaNVIDIARTX4090GPU.TheGFLOPsandRuntimeare
calculatedbyinferringavideoclipoffiveframeswitharesolution
8 MOREEXPERIMENTALRESULTS
of256√ó256.Wefollow[34]tocalculatetheGFLOPsmetric.Andthe
runtimeindicatesthetimeneededtoprocesseachframeduringin- 8.1 MoreImplementationDetails
ference.AsshowninFigure6,wedemonstratetheeffectivenessof Theencoderextractmulti-scalefeaturemaps(i.e.,scalesof1/4,
ourRainMambabyachievingstate-of-the-artresultsontheVRDS 1/8,1/16,1/32),afterwhichalightweightheadmergesthesemaps
datasetswhilemaintainingacomparativelyminimalcomputational togenerateencodedfeaturesùê∏ .Wesetthehyperparametersfor
ùë°
expense.Inthepresentedtabulardata,ourmethodobtainedthebest differentdatasetsaccordingtotheoriginalpaper‚Äôssettings.For
restorationperformanceresultscomparedtoothercomparative theRainVID&SS[53]andRainSynAll100[72]datasets,inputframes
methodsandachievedthefastestspeed.Ourmodelboostsa4.68 arerandomlycroppedtoaspatialresolutionof128√ó128,withthe
dBimprovementinPSNRcomparedtothesecondfastestmethod numberofframespervideoclipbeing7and5respectively.Forthe
ESTINet[86].Thisrelativelyfastinferencespeedenablesourmodel LWDDSdataset[64],theinputframeiscroppedto256√ó256,with
tobeeffectivelyutilizedinreal-worldapplications.Thankstothe 5framesperclip.Theinitiallearningrateforournetworkissetat
linearcomplexityofstatespacemodelsandthecriticalcomponents 2√ó10‚àí4forRainVID&SSandRainSynAll100datasets,and4√ó10‚àí4
ofournetwork,ourapproachachievessignificantimprovements fortheLWDDSdataset.Aconsistentbatchsizeof4isusedacross
inbothperformanceandspeed. thesethreedatasets.
8.2 QuantitativeandQualitativeComparisons
ontheNTURainDataset
Wealsoconductedcomparisonsofourmodelwithstate-of-the-art
videoderainingmethodsonawidely-utilizedNTURaindatasetACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
Input M1 M2 M3 M4 RainMamba Ground Truth
Figure7:VisualcomparisonsoftheablationstudyoninputvideoframesfromtheVRDSdataset.(Pleasezoominforabetter
illustration.)
imagesbyeffectivelyeliminatingrainstreaksfrominputvideo
frames.
8.3 AnalysisofLongVideoProcessing
We selected the NTURain dataset as our test dataset due to its
lowerframeresolution(640√ó480)andtheextensivesequencelength
ofitsvideos(rangingfrom116to298frames).Ourexperiment
isimplementedonaNVIDIARTXA6000GPUwithagraphics
memoryof48GB.Weinitiallyselect7framesforinputaccording
tothetrainingsetting,andsubsequentlyincreasedthenumberof
inputframesinincrementsof10.AsreportedinTable9,weinput
fullresolutionvideoclipsandcomparetheexperimentalresults
fromusingvideoclipsofdifferentlengths.Theexperimentalresults
indicatethatastheinputframerateincreases,theeffectivenessof
videorestorationalsoimproves.Thisdemonstratesthatthelong-
sequencemodelingcapabilityofSSMscaneffectivelyleveragethe
spatio-temporalcontextualinformationinvideostosuccessfully
removerainstreaks.ItisnoteworthythatourRainMambaiscapable
ofprocessing110framesoffull-resolutionvideosimultaneously
Global Scan Local Scan Ground truth
onasingleGPU.Duetothecriticalroleofinter-frameinformation
invideorestorationtasks,thelongvideoprocessingcapabilities
Figure8:Visualcomparisonsoftwodifferentscanningmech- ofourRainMambaareanticipatedtobeapplicabletoothervideo
anisms. Our local scanning mechanism improves spatial restorationchallenges.
structurepreservationofderainedresults.
8.4 MoreResultsontheComparedDatasets
forvideorainstreakremoval.NTURain[11]datasetcontains25
Figure10,Figure11andFigure12demonstratemorevisualcompar-
videosfortrainingand8videosfortesting.Fromthesequantitative
isonsbetweentheresultsgeneratedbyourmethodsandtheother
resultsinTab.8,Ourmethoddemonstratesanenhancementin
comparedmethodsontheRainVID&SSdataset,theRainSynAll100
performance over the ESTINet [86], improving the PSNR score
datasetandtheLWDDSdataset,respectively.Wealsopresented
from37.48dBto37.87dB,andtheSSIMscorefrom0.9700to0.9738.
thevisualresultsandcomparisonofourmethodandtheother
Theseresultsdemonstratethecapabilityofourmethodtoeffectively
comparedmethodontheNTURaindataset‚Äôsreal-worlddataset
removerainstreaksinvideoswithoutincorporatinganyadditional
inFigure13.TheresultsfromthreedatasetsshowthatourRain-
physicalpriors.
Mambaeffectivelyremovesvariousrainpatterns,includingstreaks
Figure9visuallycomparesrainstreakremovalresultspredicted
andraindropsofdifferentsizes.Also,ourapproachpreservesthe
byournetworkandstate-of-the-artmethodESTINet[86]fromthe
mostnaturalcolorcomparedtoalternativecomparativemethods.
NTURaindatasetComparedwithESTINet,ournetworkdemon-
stratessuperiorperformanceinrestoringtheoriginalbackgroundSupplementaryMaterials:RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
Input ESTINet Ours Ground truth
Figure9:VisualcomparisonsofderainedresultsfromournetworkandESTINet[86]oninputvideoframesfromtheNTURain
dataset.(Pleasezoominforabetterillustration.)ACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
Input MSCSC S2VD MPEVNet Ours Ground truth
Figure10:Visualcomparisonsofderainedresultsfromournetworkandstate-of-the-artderainingmethodsoninputvideo
framesfromtheRainVID&SSdataset.(Pleasezoominforabetterillustration.)SupplementaryMaterials:RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
Input RMFD Ours Ground truth
Figure11:VisualcomparisonsofderainedresultsfromournetworkandRMFD[72]oninputvideoframesfromtheRainSy-
nAll100dataset.(Pleasezoominforabetterillustration.)ACMMM,2024,Melbourne,Australia Wu,Hongtao,etal.
Input VWR Ours Ground truth
Figure12:VisualcomparisonsofderainedresultsfromournetworkandVWR[64]oninputvideoframesfromtheLWDDS
dataset.(Pleasezoominforabetterillustration.)SupplementaryMaterials:RainMamba:EnhancedLocalityLearningwithStateSpaceModelsforVideoDeraining ACMMM,2024,Melbourne,Australia
Input ESTINet Ours
Figure13:VisualcomparisonsofderainedresultsfromournetworkandESTINet[86]oninputvideoframesfromthereal-world
datasetintheNTURaindataset.(Pleasezoominforabetterillustration.)