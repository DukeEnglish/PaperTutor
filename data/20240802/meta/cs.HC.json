[
    {
        "title": "Does empirical evidence from healthy aging studies predict a practical difference between visualizations for different age groups?",
        "authors": "S. ShaoY. LiA. I. MesoN. Holliman",
        "links": "http://arxiv.org/abs/2407.21767v1",
        "entry_id": "http://arxiv.org/abs/2407.21767v1",
        "pdf_url": "http://arxiv.org/pdf/2407.21767v1",
        "summary": "When communicating critical information to decision-makers, one of the major\nchallenges in visualization is whether the communication is affected by\ndifferent perceptual or cognitive abilities, one major influencing factor is\nage. We review both visualization and psychophysics literature to understand\nwhere quantitative evidence exists on age differences in visual perception.\nUsing contrast sensitivity data from the literature we show how the differences\nbetween visualizations for different age groups can be predicted using a new\nmodel of visible frequency range with age. The model assumed that at threshold\nvalues some visual data will not be visible to older people (spatial frequency\n> 2 and contrast <=0.01). We apply this result to a practical visualization and\nshow an example that at higher levels of contrast, the visual signal should be\nperceivable by all viewers over 20. Universally usable visualization should use\na contrast of 0.02 or higher and be designed to avoid spatial frequencies\ngreater than eight cycles per degree to accommodate all ages. There remains\nmuch research to do on to translate psychophysics results to practical\nquantitative guidelines for visualization producers.",
        "updated": "2024-07-31 17:44:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.21767v1"
    },
    {
        "title": "A State-of-the-Art Review of Computational Models for Analyzing Longitudinal Wearable Sensor Data in Healthcare",
        "authors": "Paula Lago",
        "links": "http://arxiv.org/abs/2407.21665v1",
        "entry_id": "http://arxiv.org/abs/2407.21665v1",
        "pdf_url": "http://arxiv.org/pdf/2407.21665v1",
        "summary": "Wearable devices are increasingly used as tools for biomedical research, as\nthe continuous stream of behavioral and physiological data they collect can\nprovide insights about our health in everyday contexts. Long-term tracking,\ndefined in the timescale of months of year, can provide insights of patterns\nand changes as indicators of health changes. These insights can make medicine\nand healthcare more predictive, preventive, personalized, and participative\n(The 4P's). However, the challenges in modeling, understanding and processing\nlongitudinal data are a significant barrier to their adoption in research\nstudies and clinical settings. In this paper, we review and discuss three\nmodels used to make sense of longitudinal data: routines, rhythms and stability\nmetrics. We present the challenges associated with the processing and analysis\nof longitudinal wearable sensor data, with a special focus on how to handle the\ndifferent temporal dynamics at various granularities. We then discuss current\nlimitations and identify directions for future work. This review is essential\nto the advancement of computational modeling and analysis of longitudinal\nsensor data for pervasive healthcare.",
        "updated": "2024-07-31 15:08:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.21665v1"
    },
    {
        "title": "Between the AI and Me: Analysing Listeners' Perspectives on AI- and Human-Composed Progressive Metal Music",
        "authors": "Pedro SarmentoJackson LothMathieu Barthet",
        "links": "http://arxiv.org/abs/2407.21615v1",
        "entry_id": "http://arxiv.org/abs/2407.21615v1",
        "pdf_url": "http://arxiv.org/pdf/2407.21615v1",
        "summary": "Generative AI models have recently blossomed, significantly impacting\nartistic and musical traditions. Research investigating how humans interact\nwith and deem these models is therefore crucial. Through a listening and\nreflection study, we explore participants' perspectives on AI- vs\nhuman-generated progressive metal, in symbolic format, using rock music as a\ncontrol group. AI-generated examples were produced by ProgGP, a\nTransformer-based model. We propose a mixed methods approach to assess the\neffects of generation type (human vs. AI), genre (progressive metal vs. rock),\nand curation process (random vs. cherry-picked). This combines quantitative\nfeedback on genre congruence, preference, creativity, consistency, playability,\nhumanness, and repeatability, and qualitative feedback to provide insights into\nlisteners' experiences. A total of 32 progressive metal fans completed the\nstudy. Our findings validate the use of fine-tuning to achieve genre-specific\nspecialization in AI music generation, as listeners could distinguish between\nAI-generated rock and progressive metal. Despite some AI-generated excerpts\nreceiving similar ratings to human music, listeners exhibited a preference for\nhuman compositions. Thematic analysis identified key features for genre and AI\nvs. human distinctions. Finally, we consider the ethical implications of our\nwork in promoting musical data diversity within MIR research by focusing on an\nunder-explored genre.",
        "updated": "2024-07-31 14:03:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.21615v1"
    },
    {
        "title": "LLM-for-X: Application-agnostic Integration of Large Language Models to Support Personal Writing Workflows",
        "authors": "Lukas TeufelbergerXintong LiuZhipeng LiMax MoebusChristian Holz",
        "links": "http://arxiv.org/abs/2407.21593v1",
        "entry_id": "http://arxiv.org/abs/2407.21593v1",
        "pdf_url": "http://arxiv.org/pdf/2407.21593v1",
        "summary": "To enhance productivity and to streamline workflows, there is a growing trend\nto embed large language model (LLM) functionality into applications, from\nbrowser-based web apps to native apps that run on personal computers. Here, we\nintroduce LLM-for-X, a system-wide shortcut layer that seamlessly augments any\napplication with LLM services through a lightweight popup dialog. Our native\nlayer seamlessly connects front-end applications to popular LLM backends, such\nas ChatGPT and Gemini, using their uniform chat front-ends as the programming\ninterface or their custom API calls. We demonstrate the benefits of LLM-for-X\nacross a wide variety of applications, including Microsoft Office, VSCode, and\nAdobe Acrobat as well as popular web apps such as Overleaf. In our evaluation,\nwe compared LLM-for-X with ChatGPT's web interface in a series of tasks,\nshowing that our approach can provide users with quick, efficient, and\neasy-to-use LLM assistance without context switching to support writing and\nreading tasks that is agnostic of the specific application.",
        "updated": "2024-07-31 13:29:22 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.21593v1"
    },
    {
        "title": "Does the Source of a Warning Matter? Examining the Effectiveness of Veracity Warning Labels Across Warners",
        "authors": "Benjamin D. Horne",
        "links": "http://arxiv.org/abs/2407.21592v1",
        "entry_id": "http://arxiv.org/abs/2407.21592v1",
        "pdf_url": "http://arxiv.org/pdf/2407.21592v1",
        "summary": "In this study, we conducted an online, between-subjects experiment (N =\n2,049) to better understand the impact of warning label sources on information\ntrust and sharing intentions. Across four warners (the social media platform,\nother social media users, Artificial Intelligence (AI), and fact checkers), we\nfound that all significantly decreased trust in false information relative to\ncontrol, but warnings from AI were modestly more effective. All warners\nsignificantly decreased the sharing intentions of false information, except\nwarnings from other social media users. AI was again the most effective. These\nresults were moderated by prior trust in media and the information itself. Most\nnoteworthy, we found that warning labels from AI were significantly more\neffective than all other warning labels for participants who reported a low\ntrust in news organizations, while warnings from AI were no more effective than\nany other warning label for participants who reported a high trust in news\norganizations.",
        "updated": "2024-07-31 13:27:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.21592v1"
    }
]