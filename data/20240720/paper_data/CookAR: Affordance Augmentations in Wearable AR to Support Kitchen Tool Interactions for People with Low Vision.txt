CookAR: Affordance Augmentations in Wearable AR to Support
Kitchen Tool Interactions for People with Low Vision
JaewookLee AndrewD.Tjahjadi JihoKim
UniversityofWashington UniversityofWashington UniversityofWashington
Seattle,WA,USA Seattle,WA,USA Seattle,WA,USA
JunpuYu MinjiPark JiawenZhang
UniversityofWashington SungkyunkwanUniversity UniversityofWashington
Seattle,WA,USA Suwon,Korea Seattle,WA,USA
JonE.Froehlich YapengTian YuhangZhao
UniversityofWashington UniversityofTexasatDallas UniversityofWisconsin-Madison
Seattle,WA,USA Richardson,TX,USA Madison,WI,USA
Figure1:CookARprovidesreal-timeobjectaffordanceaugmentationsinhead-mountedARtosupportcookinginteractions.
(A)alowvisionparticipantusesCookARtolocateandgrabaspoon;(B)theviewinCookARwherekitchentoolaffordances
(grabbablevs.hazardousareas)arerecognizedandaugmentedbysolid-coloredoverlays,withgreenoverlaysforgraspable
areassuchashandlesandredforhazardousareassuchasaknifebladeorthehotpartofateakettle.
ABSTRACT weconductedatechnicalevaluationofourfine-tunedmodelas
Cookingisacentralactivityofdailyliving,supportingindepen- wellasaqualitativelabstudywith10LVparticipantsforsuitable
denceandbothmentalandphysicalhealth.However,priorwork augmentationdesign.Ourtechnicalevaluationdemonstratesthat
hashighlightedkeybarriersforpeoplewithlowvision(LV)tocook, ourmodeloutperformsthebaselineonourtoolaffordancedataset,
particularlyaroundsafelyinteractingwithcookingtools,suchas whileouruserstudyindicatesapreferenceforaffordanceaugmen-
sharpknivesorhotpans.Drawingonrecentadvancementsincom- tationsoverthetraditionalwholeobjectaugmentations.Codeis
putervision(CV),wepresentCookAR,ahead-mountedARsystem availableat:https://github.com/makeabilitylab/CookAR.
withreal-timeobjectaffordanceaugmentationstosupportsafeand
efficientinteractionswithkitchentools.Todesignandimplement CCSCONCEPTS
CookAR,wemanuallycollectedandannotatedthefirstegocen- •Human-centeredcomputing→Mixed/augmentedreality;
tricdatasetofkitchentoolaffordances,fine-tunedanaffordance Accessibilitysystemsandtools;•Computingmethodologies
segmentationmodel,anddevelopedanARsystemwithastereo →Computervision.
camera to generate visual augmentations. To validate CookAR,
Permissiontomakedigitalorhardcopiesofpartorallofthisworkforpersonalor KEYWORDS
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
augmentedreality,accessibility,affordancesegmentation,visual
forprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation
onthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored. augmentation
Forallotheruses,contacttheowner/author(s).
UIST’24,October13–16,2024,Pittsburgh,PA,USA
ACMReferenceFormat:
©2024Copyrightheldbytheowner/author(s).
ACMISBN979-8-4007-0628-8/24/10 JaewookLee,AndrewD.Tjahjadi,JihoKim,JunpuYu,MinjiPark,Jiawen
https://doi.org/10.1145/3654777.3676449 Zhang,JonE.Froehlich,YapengTian,andYuhangZhao.2024.CookAR:
4202
luJ
81
]CH.sc[
1v51531.7042:viXraUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
AffordanceAugmentationsinWearableARtoSupportKitchenToolIn- displayingwholeobjectaugmentations,and(3)withCookARdis-
teractions for People with Low Vision. In The 37th Annual ACM Sym- playingaffordanceaugmentations.Theythencompletedafree-
posiumonUserInterfaceSoftwareandTechnology(UIST’24),October13– formcookingtaskwithCookAR(Part2)andbrainstormeddesired
16,2024,Pittsburgh,PA,USA.ACM,NewYork,NY,USA,15pages.https: augmentationdesignsusingdesignprobes(Part3).Findingsindi-
//doi.org/10.1145/3654777.3676449
catethatparticipantspreferaffordanceaugmentationsoverwhole
objectaugmentationsinakitchen,astheyenablefasterunderstand-
1 INTRODUCTION ingofanobject’sspatialarrangementandsafeinteractionparts.
Cookingisanessentialactivityofdailyliving,supportingindepen- Mostparticipantspreferredaffordanceaugmentationsconsisting
dence[54,56,70]andbothmentalandphysicalhealth[3,31,53,70]. ofgreensolidoverlayongrabbableareasandredoutlinesonhaz-
However,cookingalsoinvolvessignificantvisualtasksthatcanbe ardousareas.Moreover,participantsidentifiedfiveadditionaltool
challengingordangerousforblindandlowvision(BLV)people, affordanceswithdesiredaugmentations,includingentry(e.g.,cup
especiallywheninteractingwithkitchentools,suchassharpknives rim),exit(e.g.,carafespout),containment(e.g.,cupbase),intersec-
orhotpans[3,31,38,39,74]. tion(e.g.,knifebladeonbutter),andactivation(e.g.,carafebuttons)
Unlikethosewhoarecompletelyblind,peoplewithlowvision areas,allofwhichshouldbeoutlinedinacontrastingcolor(e.g.,
(LV)—visionlossthatcannotbecorrectedusingglassesorcontact blackorwhite).
lenses[10]—oftenrelyontheirresidualvisionindailyactivitiesand Insummary,ourresearchcontributionsinclude:(1)CookAR,a
usedifferentlowvisiontoolstoenhancevisualinformation[68,69]. fully-functionalAI-poweredwearableARprototypethataugments
WithrecentadvancementsinAI-poweredaugmentedreality(AR) kitchentoolaffordancesforlowvisionuserstoenablesafeand
technology,researchershaveexplorednewpossibilitiesforsupport- efficienttoolinteractions;(2)anegocentricaffordancedatasetfor
ingLVindividualsbyautomaticallyrecognizingtheirenvironment kitchentoolsandanaccompanyingfine-tunedaffordancesegmen-
andprovidingappropriatevisualaugmentations.PriorARresearch tationmodel;and(3)userstudyresultswith10LVparticipantsthat
prototypeshavebeendevelopedtoassistwithtaskssuchasvisual revealuserexperienceswithCookAR,preferencesforaugmenta-
search[82],stairnavigation[78],andsports[37].However,none tiondesigns,andfivenewlydesiredaffordanceareas.
havebeenspecificallydesignedtosupportmealpreparation.More-
over,priorARsystemsmainlyfocusonunderstandingeffective 2 RELATEDWORK
augmentationdesigns[78],oftenoversimplifyingthecomputer Ourworkbuildsonpriorformativeresearchexploringlow-vision
vision(CV)recognitionintheirdevelopment,thusneglectingthe cooking,wearableARtoenhanceaccessibility,andaffordanceseg-
effectsoftechnologicallimitations(e.g.,CVinaccuraciesandsystem mentation.
delays)onuserexperience.
WeintroduceCookAR,afully-functionalwearablestereoAR
2.1 ChallengesinLowVisionCooking
prototypethatrecognizesandaugmentstheaffordancesofcook-
ingtoolsinreal-timetosupportLVindividualswithefficientand Low vision people face various challenges in activities of daily
safeinteractionsinthekitchen.Incontrasttopriorresearchthat living,suchascooking[3,38,39,73,74],shopping[68],naviga-
augmentsobjectsasawhole[16,82],wedistinguishandaugment tion[68,80],andsports[37,62].Amongtheseactivities,cookingis
theobjectaffordance(i.e.,componentpartsthataffordinteractions), anessentialtaskforanindependentandhealthylife[70].However,
suchasthesafe-to-handle“grabbable”areasandthedangerous-to- cookingalsoposesmajorbarriersandsafetyconcernstoblindand
touch“hazardous”areas(Figure1).Toenableaccurateaffordance lowvision(BLV)peopleastheyneedtointeractwithvariousingre-
recognition,weconstructedacustomegocentricimagedatasetfor dientsandkitchentools,suchassharpknivesandhotpans[32,33].
kitchentoolaffordancesbyselectingandlabelingimagesfromthe Asaresult,BLVpeopletendtoeatmorepre-processedfoodor
EpicKitchensdataset[11]andfine-tunedanaffordancesegmenta- frequentlydineatrestaurants,whichcannegativelyimpacttheir
tionmodel.Wethenleveragedstereodepthestimationusingthe health[31,55].
ZEDMini1 stereocameraandanOculusQuest22 headsetwith TobetterunderstandhowBLVpeopleengageincookingtasks,
videopassthroughtopreciselyoverlayaffordanceaugmentations priorworkhasconductedbothinterviewandobservationalstudies
onthe3Denvironmentinreal-time. [38,40,73,74].Forexample,Jonesetal.[31]surveyed101BLVpar-
ToevaluateCookAR,weconductedatechnicalevaluationof ticipantsintheU.K.abouttheirshoppingandcookingexperiences,
ourfine-tunedmodelaswellasathree-partqualitativelabstudy revealingthatvisionlossmadecookingdifficultandthedifficulty
with10LVparticipantstoevaluatetheirexperienceswithCookAR levelwascorrelatedwiththeseverityofvisualimpairments.Li
andsolicitfeedbackaboutpotentialaffordanceaugmentationde- etal.[38]analyzed122YouTubevideosofBLVpeoplepreparing
signs. For the model assessment, we found that our fine-tuned mealsandinterviewed12BLVparticipantsabouttheircooking
affordancesegmentationmodel(mAPof46.3%)outperformedthe experiences.Theyidentifiedseveralcooking-relatedchallenges,
baseRTMDet[46]model(mAPof12.3%)inaccuratetoolaffordance suchasutilizingcookingtoolsandtrackingobjectdynamicsinthe
recognitionandsegmentation.Forthethree-partuserstudy,LVpar- kitchen.Afollow-upcontextualinquirystudy[39]examinedhow
ticipantswerefirstaskedtolocateandpickupcookingtoolsacross BLVpeoplerecognizecookwareandutensilsandmeasureingredi-
threeconditions:(1)withoutCookAR(baseline),(2)withCookAR ents.Thestudyidentifiedessentialcooking-relatedinformationto
convey,suchasposition,safety,andorientationinformation.
1https://store.stereolabs.com/products/zed-mini Specificallyforlow-vision(LV)people, Wanget al.[73]con-
2https://www.meta.com/quest/products/quest-2/ ductedacontextualinquirystudy,observingandcomparingtheCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
cookingexperiencesbetweensixLVparticipantsandfourblind thatrecognizesandaugmentskitchentoolaffordancesinreal-time
participants.Theyfoundthatwhileblindparticipantsreliedon tosupportsafeandefficientinteractionsinacookingscenario.
touch, LV people extensively used their vision during cooking.
However,comparedtoblindpeople,LVpeoplefeltlessconfident,
2.3 AffordanceSegmentation
lesssafe,andmoretiredandstressedduringcooking.Moreover,
theywerelesssatisfiedwiththecurrently-availablecookingtools Incontrasttomostpriorresearchthataugmentswholeobjects[16,
thanblindpeople,indicatinganeedfortechnologythatconsiders 37,82],ourresearchfocusesonrecognizingandaugmentingtoolaf-
lowvisionpeople’suniqueneeds.Thestudyalsoidentifiedkey fordances.Affordanceistraditionallydefinedas“theopportunities
challengesfacedbyLVpeople,suchasdistinguishingobjectswith foractionsthatobjectsoffer,relativetotheuser’sabilitytoperceive
lowcontrastandsafelyinteractingwithdangerouskitchentools. andactonthem”[18–20].Highlightingobjectaffordancescaneffec-
Wangetal.[74]furtherinterviewedsixlowvisionrehabilitation tivelyguidehumanattentionandactions[17,63,71].Despitethe
professionalstounderstandcurrenttrainingstrategiesandtoolsto prominenceofaffordancesegmentationinrobotics[2,7,8,57,58]
supportcooking.However,theyhighlightedthatcurrentsolutions andcomputervision[9,43,45],automaticaffordanceaugmentation
cannotfullyaddressallcookingchallengesfacedbyLVpeople. hasreceivedcomparativelylessattentionandapplicationsinthe
OurresearchfillsthisgapbybuildinganARsystemtosupport fieldofHCI.Notably,thereexistsagapforanaffordancedatasetin
safeandefficientcookingtoolinteractionsforlowvisionpeople thecontextofakitchenenvironment,especiallydesignedforthe
byprovidingvisualaugmentations. needsofindividualswithlowvision.Toaddressthis,webuiltanAR
systemthatfocusesonaffordancesegmentationandenhancement.
Wecreatedanewdatasetfocusedontheaffordancesofkitchen
toolsbyselectingandannotatingimageframesfromtheegocentric
2.2 UsingWearableARtoEnhanceAccessibility
EpicKitchensdataset[11]andfine-tunedaninstancesegmentation
InthefieldsofaccessibilityandHCI,wearableARhasbeenusedto modelonourdataset.
supportpeoplewithdiversedisabilities,forexample,ARsystems
thatcaptionandvisualizespeechandsoundsfordeaforhardof
3 SYSTEMIMPLEMENTATION
hearing(DHH)individuals[15,27–29,52,59,61,65],supporthands-
freeinteractionswithscreendisplaysforpeoplewithupperbody WedesignedandbuiltCookAR,aninnovativesolutionthatinte-
motorimpairments[47,48,51],offerspeechsupportforpeople gratesARandCVtechnologiestoimproveobjectinteractionsfor
withaphasia[76],andprovidesocialcuetherapyforchildrenwith individualswithlowvision.Unliketraditionalenhancementsthat
autism[75]. targetobjectsasawhole,ourprototypehighlightstheiraffordances
Withinthelow-visionaidcontext,head-wornARdevicescan (i.e.,functionalparts),facilitatingeasieridentificationandinter-
selectivelyenhanceuser’svisionbyinterpretingtheirenvironment actionwithareastograsporavoid.Tocreateafully-functional
andtasks[1,77].Forinstance,priorresearchhasdevelopedAR wearableARsystem,weneededtoaddressboththecomputervision
systemsthatcancapturereal-timevideofeedsofthesurroundings problemofaccuratelyrecognizingobjectaffordancesinreal-time
and apply image processing techniques [12, 49, 82] to enhance andtheHCIproblemofdesigningandrenderingsuitableaffordance
visualinformation,suchasedgeenhancement[26,35,50],scene augmentations.Inthissection,wedescribeourapproachforeach
recoloringbasedondistance[14,24,72],andpixelremappingfor step,including(1)collectingandannotatingadatasetfocusedon
visual field loss [21, 42, 44, 60]. However, while these solutions theaffordancesofkitchentools;(2)fine-tuninganinstanceseg-
arebeneficialforsimpletaskslikereading[12,25,66],theystill mentationandrecognitionmodelonourdatasettodetectthese
lacksemanticunderstandingofthesceneandcannoteffectively affordances;and(3)buildingahead-mountedARsystemwitha
supportmorecomplexactivitiesinvolvingobjectinteractions,such stereocameratorendervisualaugmentationsbasedontheoutputs
ascooking[74]. ofouraffordancerecognitionmodel.
Morerecently,researchershavecombinedARandCVtodevelop
scene-awarevisualaugmentationsaimedatassistingLVpeople
3.1 DataCollectionandAnnotation
withmoreintricateactivitieslikevisualsearch[82],stairnaviga-
tion[78],wayfinding[79],obstaclemaneuver[16],buttonpress- TotrainaneffectiveAImodelforaffordancesegmentation,wefirst
ing[36],andsports[37].Nonetheless,nopriorsystemshavead- needanappropriatedataset.However,tothebestofourknowledge,
dressedtheuniquecookingchallengethatinvolvesdynamictool thereisnopriorcookingtooldatasetwithannotationstoenable
interactions.Moreover,priorARresearchforlowvisionmainly affordancesegmentationandrecognition.Below,wedescribeour
focusesondesigningandevaluatingsuitablevisualaugmentations multi-stepprocesstocollectandannotateobjectaffordancesin
forlowvisionpeople.TheytendtooversimplifytheCVrecognition egocentriccookingimages.Thislabeleddatasetisonecontribution
insystemdevelopment,forexample,usingQRcodes[78,82]or ofourworkandwillbeopen-sourceduponpaperacceptanceto
existingspatialmappingAPIs[16,79]toanchoraugmentationsto enablefutureresearch.
thereal-worldenvironment.Asaresult,theyoverlookthetechnical Data Collection. To build a kitchen tool affordance image
challengesinbuildingareal-timeAI-poweredARsystem,aswellas dataset,weusedanegocentricvideodatasetcalledEpicKitchens[11],
thepotentialimpactofthetechnologicallimitations(e.g.,CVerrors, whichconsistsof100hoursofvideofootageofsightedpeoplecook-
systemlatency)onusers’experiences.Ourresearchaddressesthis ingintheirhomes.WeselectedtheEpicKitchensvideodataset
gapbydevelopingCookAR,afully-functionalwearableARsystem sinceitnotonlyinvolvesawiderangeofcookingscenarioswithUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
Figure2:Roboflowannotationexamplesforeachobjectclassinourdataset.
variouskitchentools,butalsocapturesvideofeedsfromthefirst- Base,andCarafeHandle(Figure2).Whenlabeling,weadheredto
person perspective, which aligns with the egocentric nature of thefollowingheuristic:(1)theobjectshouldvisuallyresemblethe
head-wornARdevices. classitisbeinglabeledas;and(2)theobjectshouldservefunctions
BecausetheEpicdatasetissolarge,weneededtofiltercritical similartothoseofthelabelclass.Forinstance,alargewooden
framesofinterest.WeusedYOLOv8[30]trainedontheMSCOCO spooncanbetrickytolabel,asitcanresembleaspoon,ladle,or
dataset[40]todetectandcollectframesfeaturingcooking-related spatula,andhaveversatileusesuchasstirringapan(likeaspoon),
objects,suchasspoons,knives,forks,cups,scissors,sinks,and scoopingcontentsfromapot(likealadle),orliftingeggs(likea
diningtables.Weskipped20framesafterfindingatleastoneof spatula)acrossdifferentimagesinthedataset.Welabeledthese
thoseobjectstominimizerepetition.Wethenmanuallyreviewed ambiguousobjectsbasedontheirshapeanduseinagivenframe.
theselectedframestoempiricallyremovesimilar,excessivelyblurry, Theannotationswerecross-checkedbetweensixmembersofthe
orirrelevantimages,resultingin4,928keyframes. researchteamtoreduceerrorsandbias.
DataAnnotation&Augmentation.Wethenlabeledthese Afterannotating,weusedvariousimageaugmentationtech-
framesusingtheimageannotationfeatureinRoboflow3,aplatform niques available on Roboflow to enhance the dataset for better
thatfacilitatesbuildinganddeployingend-to-endcomputervision generalizabilityacrossreal-worldscenarios,including:cropping
modelsbyofferingtoolsforannotation,training,andoptimization. with0%minimumzoomand40%maximumzoom,rotationbetween
RoboflowenableslabelingautomationusingtheSegmentAnything -15°and+15°,brightnessbetween-15%and+15%,blurupto2.5px,
model (SAM)[34],allowingustoeasilyselectandsegmentthe and noise up to 0.1% of pixels. We then adjusted the images to
interactivepartsofobjects(e.g.,knifebladevs.knifehandle)and fita640x480resolution(i.e.,theMSCOCOaverageimageresolu-
addcorrespondingclasslabels. tion[40])toaccommodateourchosenbasemodel’spreferences
Drawingonpriorworkinlow-visioncooking[38,39,74],the andfacilitatetheiruseinfutureresearch.Thisresultedinafinal
researchteamcollectivelydecidedon18distinctclasses:KnifeBlade, datasetof10,152images.Theentiredatasetispubliclyavailable
KnifeHandle,SpoonBowl,SpoonHandle,ForkTines,ForkHandle, here:https://github.com/makeabilitylab/CookAR.
ScissorBlade,ScissorHandle,LadleBowl,LadleHandle,SpatulaHead,
SpatulaHandle,PanBase,PanHandle,CupBase,CupHandle,Carafe
3https://roboflow.comCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
Figure3:SystemoverviewofCookARshowinghowdataflowsfromtheZEDMiniStereocameratoanexternalcamerafor
affordancesegmentation,thensentbacktoZEDforrenderingontheQuest2headset.
3.2 ModelFine-Tuning describes(Section5),wealsofurtherexploredandbrainstormed
Toprovidereal-timeobjectaffordanceinformationtoLVusers, otheraffordanceaugmentationdesigns.
wefine-tunedtheRTMDetmodel[46],specificallyitsRTMDet-Ins- Becauseourreal-timeCVmodeliscomputationallyexpensive,
l variant, on our kitchen tool affordance dataset. This model is CookARistetheredtoalaptopwithaNVIDIA4080mobileGPU.
thecurrentstate-of-the-artinreal-timeinstancesegmentation4, TheCookARsystemfirstcapturesimageframesusingtheZED
offeringrobustaccuracyand300+FPSonanNVIDIA3090GPU. Ministereocameraandstreamsthemtoanexternalserverviathe
RTMDetfeatureslargekerneldepthwiseconvolutionandbatch TransmissionControlProtocol(TCP)foraffordancesegmentation
normalizationlayers,pre-trainedonMSCOCO. byourRTMDet-Ins-l-Cookmodel(confidencethresholdof0.4).
Weoptedtofine-tuneRTMDetinsteadoftrainingitfromscratch, Then,itconvertstheresultingJSONwithaffordancemasksand
which allowed us to better leverage our smaller, class-specific
labelsintoaProtocolBuffersmessage5forefficientstreaming.This
dataset.Toachievethis,weinitializedthebaseRTMDet-Ins-lmodel messageisthensentbacktobeprocessedbytheZEDMiniAPI[67],
withpre-trainedweights,frozeitsbackbone,andadjustedthemodel whichdeserializesthemessagebackintoaJSONandcreatesaZED-
configurationfileforourlabelclasses,beforetrainingitonour compatibletexture(orcoloredoverlay)foreachaffordancemask.
kitchentoolaffordancedataset.Thiscustomizedmodel,dubbed Finally,theZEDMiniperformsstereodepthestimationandoverlays
RTMDet-Ins-l-Cook,wastrainedover150epochswithabatchsizeof thetexturesontotheleftandrightimageframesforbinocularvision
4onasingleCUDA-enabledNVIDIA4080GPU.BecauseRTMDet- intheQuest2headset.WhiletheZEDMinistereocameraallowed
Ins-l-Cook underwent fine-tuning on a dataset with affordance ustoprototypeCookAR,itrequiredoursystemtobetetheredtoa
annotations,itcanmimicanaffordancesegmentationmodel’sca- computer,whichwealleviatedbyusinglengthycables.
pabilities while retaining RTMDet’s real-time performance. We Inourlatencyanalysis,weranCookARforfiveminutesand
provideatechnicalevaluationinSection4. computedtheaveragelatencyofeachcomponent:videostreaming
fromZEDtocomputertook16.76ms;affordancerecognitiontook
3.3 TheCookARPrototype 15.95ms;resultstreamingbacktoZEDtook10.43ms;anddepth
estimation and augmentation rendering took 3.39ms. All other
Withourfine-tunedRTMDet-Ins-l-Cookmodel,webuiltCookAR,a
componentshadnegligibleimpactonruntime.Theoveralllatency
wearableARprototypethatcanrecognizeandvisuallyaugmentthe
isonaverage46.82msperframe(∼21.36FPS),resultinginanear
affordancesofkitchentoolsinreal-time.ToimplementCookAR,we
real-timesystem.SystemstructureissummarizedinFigure3.
neededtoaddresskeytechnicalandHCIchallenges,including:(1)
howtospatiallyhighlightobjectaffordancesin3Dspace;(2)howto
4 TECHNICALEVALUATION
runareal-timemodelcapableofprovidingaffordancefeedbackwith
minimallatency;(3)andhowtobestvisuallyindicateaffordances Wefirstconductedatechnicalevaluationofourfine-tunedRTMDet-
toLVuserstosupportbutnotoverwhelmtheirexistingperceptual Ins-l-Cook model, comparing its performance against the base
visionsystems. RTMDet-Ins-lmodelonourkitchentoolaffordancedataset.Find-
To generate visual augmentations that align with the object ingsindicatethatourfine-tunedmodelissignificantlymoreaccu-
partsina3Dspace,webuiltacustomstereovideosee-throughAR rateinrecognizingandsegmentingaffordancesofcookingthan
systembycombiningtheZEDMinistereocamerawithanOculus theunmodifiedmodel.
Quest2 VRheadset,asoff-the-shelfARheadsets(e.g.,Microsoft
4.1 Methods
HoloLens2)donotyetsupportlongrangereal-timedepthsensing
andheavyCVmodels.Theaffordancevisualizationsthemselvesare Toassesstheperformanceofthebaseandfine-tunedmodelson
renderedascoloredpolygonoverlays.Specifically,weusedgreen ourkitchentoolaffordancedataset,weleveragedthemodeltesting
(hexcode#3BE8B0)toindicateagraspableareaandred(#FC626A) pipelineprovidedbytheMMDetectionlibrary[6],aPyTorch-based
toindicateariskyarea.SeeFigure1.Asouruserstudysection open-sourcetoolkitforobjectdetectionandsegmentation,which
4https://paperswithcode.com/sota/real-time-instance-segmentation-on-mscoco 5https://protobuf.devUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
Figure4:Exampleinferencingresultsonimagesfromthetestsubsetofourdataset.Theseimagesdemonstratehowthe
RTMDet-Ins-l-Cookidentifiesandsegmentsgraspable,safeareas—eveninthepresenceofhandsorotherpartialocclusions.
performsevaluationsusingthetestsubsetofagivendataset.Using ModelName mAP AP@50 AP@75
Roboflow,wegeneratedatestingsetof596imageswithan82-12-6
RTMDet-Ins-l(onCOCO) 0.437 0.660 0.470
train-validation-testsplitandensuredthatourfine-tunedmodel
wasnotexposedtoimagesinthetestsubset. RTMDet-Ins-l(onourdataset) 0.123 0.199 0.310
Forinstancesegmentationtasks,accuracyisconventionallymea- RTMDet-Ins-l-Cook(onourdataset) 0.463 0.749 0.486
suredusingthreekeymetrics:segmentationmeanaveragepreci-
sion(mAP),APata50%IntersectionoverUnion(IOU)threshold Table1:Affordancesegmentationresults.Wecanseethat
(AP@50),andAPata75%IOUthreshold(AP@75)[22].Eachmetric ourfine-tunedaffordancesegmentationmodel,RTMDet-Ins-
servesadistinctpurpose: l-Cook,demonstratessuperiorperformanceacrossallmet-
ricsonourkitchentoolaffordancedataset,outperforming
• mAPoffersacomprehensiveassessmentofamodel’spreci-
RTMDet-Ins-lmodel.Forreference,weincludeRTMDet-Ins-l
sionacrossvariousdetectionthresholds,byaveragingpreci-
resultsontheCOCOdataset.Thehighestvaluesarebolded.
sionatmultiplerecalllevelsforeachclass.Italsoaggregates
resultsacrossarangeofIntersectionoverUnion(IoU)thresh-
andAP@75reaching74.9%and48.6%,significantlyoutperforming
olds,from0.5to0.95instepsof0.05,providingaholisticview
thebasemodel’s19.9%and13.2%.Theseresultshighlighttheen-
ofmodelperformanceacrossdifferentdegreesofoverlap
hancedaccuracyofourfine-tunedRTMDet-Ins-l-Cookmodelon
betweenthepredictedmasksandthegroundtruth;
ourkitchentoolaffordancedataset.
• AP@50focusesontheprecisionofsegmentationataspecific
Inaddition,weshowseveralinferenceresultsofRTMDet-Ins-
IoUthresholdof50%,amorelenientmeasurethatconsiders
l-CookonimagesfromthetestsubsetofourdatasetinFigure4.
apredictioncorrectiftheoverlapwiththegroundtruthis
Ourmodeldemonstratesimpressiverobustness,identifyingand
atleasthalf;
segmentinggraspable,safeareasevenwhenhandsorotherpartial
• AP@75 evaluates precision at a stricter IoU threshold of
occlusionsarepresentintheimages.
75%,demandinghigheraccuracyintheoverlapbetweenthe
predictedsegmentationandthegroundtruthforapositive 5 USERSTUDY
assessment.
WethenevaluatedourCookARprototypeinathree-partqualitative
IoU,centraltothesemetrics,quantitativelyevaluatestheoverlap labstudywith10lowvisionparticipants.Asinitialwork,ourgoals
betweenpredictedsegmentationmasksandtheactualgroundtruth, weretoevaluatehowLVparticipantsmightbenefitfromareal-
servingasadirectmeasureofaccuracyinspatialalignment.We timeobjectaffordanceaugmentationstocompletecookingtasks,
appliedthesemetricstocomparetheperformanceofourfine-tuned solicittheirreactionstoafully-functionalbutearly-stageprototype
modelagainstthebaseline,aimingtocapturethenuancesofim- (e.g.,howdotheyreacttoaugmentationerrors),andco-brainstorm
provement across different levels of strictness in segmentation visual overlay designs via design probes. Participants provided
accuracy.Wecomputedandcomparedthethreemetricsacrossthe feedbackthroughoutthestudyandansweredopen-endedquestions
baseandfine-tunedmodels. regardingtheirexperiences,whichwererecordedandtranscribed
forlateranalysis.
4.2 Results
5.1 Participants
Our findings (Table 1) show that the base RTMDet-Ins-l model
performspoorlyonouraffordance-specificdatasetdespiteitscom- Toachieveadiverseparticipantpool,werecruited10LVpartici-
petencyontheCOCOdataset[40]of43.7%segmentationmAP. pantsfromtwodifferentcitiesviamailinglistsandsnowballsam-
Conversely,ourfine-tunedRTMDet-Ins-l-Cookmodelexcelledin pling.Participantswerescreenedusingademographicquestion-
identifyingandsegmentingcookingtoolcomponents,demonstrat- naire,whichgatheredinformationonage,gender,visioncondition,
ingasignificantlyhighersegmentationmAPof46.3%,compared andpriorexperiencewithARandAItechnologies.Theaverage
tothebasemodel’s12.3%.Thisimprovementwasalsoevidentin agewas62.2years(𝑆𝐷 =19.6),withagenderdistributionof70%
ourmodel’sperformanceatdifferentIoUthresholds,withAP@50 femaleand30%male.ParticipantshadabroadrangeoflowvisionCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
conditionswithvisualacuityrangingfrom20/40to20/400and Part2:FullCookingTask.InPart2ofthestudy,weasked
visualfieldlossatdifferentareas—seeTable2.Mostparticipants participantstocookamacaroniandcheesedishusingARCookwith
reportedlittletonoexperiencewithARandAI,exceptforP1who affordanceaugmentations.Weprovidedparticipantswithstep-by-
hadusedbothtechnologies. stepinstructionstoensurethatparticipantsinteractwithallnine
objectsARCookcanrecognize:(1)grabacupofwaterandpour
5.2 Apparatus itintoacarafe,(2)pourwaterintoapotusingacarafe,(3)cuta
pieceofbutterusingaknife,(4)cutapieceofcheeseusingapairof
Thestudywasconductedinawell-litlabenvironment.Participants
scissors,(5)putthemacaroni,butter,andcheeseintoapot,(6)stir
satinfrontofalargetable,whereweplacedninedifferentkitchen
withaspoon,(7)stirwithaspatula,(8)placethefinishedmacaroni
tools—knife,spoon,fork,scissors,ladle,spatula,pan/pot,cup,and
carafe.Weusedadarkgreentableclothfortheexperimenttableto and cheese in a bowl using a ladle, and (9) pick up a fork and
producelowcontrast.Wealsopreparedayellowwoodencutting enjoy.Forthesafetyofourparticipants,wesuppliedaknifewitha
board,abowl,apieceofcheese,andastickofbutterforthepar- dulledgeandavoidedtheuseofheat.Asparticipantscompleted
ticipantstouseinthestudy,however,CookARcanonlyrecognize thistask,theywereencouragedtothinkaloud,articulatinghow
andaugmentthenineaforementionedkitchentoolsatthecurrent theaffordanceaugmentationssupportorhindertheiractivities,
stage.Lastly,werecordedtheexperimentusingaseparatelaptop howCookARimpactedtheiroverallcookingexperience,andany
andasmartphoneonatripod. suggestionstheyhadforaugmentationdesigns.Aftercompleting
thefree-formcookingtask,weaskedparticipantstoreflectonthese
sametopicsthroughopen-endedquestions.
5.3 Procedure
Part3:BrainstormingandCo-Design.InPart3ofthestudy,
Thesingle-session90-minutestudyconsistedofthreephases.In weaskedparticipantstobrainstormfuturedesignsandapplications
Part 1, we asked participants to grab cooking utensils in three ofCookAR.Wefirstpresenteddesignprobes(SeeFigure6)and
conditions:(1)withoutCookAR,(2)withCookARdisplayingaug- askedparticipantstocritiquethem.Thedesignprobesillustrate
mentations for whole objects, and (3) with CookAR displaying variousdesigns,includingoutlineswhichreducevisualclutterin
affordanceaugmentations(Figure5).InPart2,participantscom- comparisontosolid-coloredoverlays,solelydisplayingeitherthe
pletedafullcookingtaskwheretheymademacaroniandcheese grabbableorthehazardousaugmentation,highlightingthemore
whileusingCookAR.Finally,inPart3,participantsbrainstormed specific hazardous part such as the sharp edge of a knife blade
toolaffordancesanddesiredaugmentationdesignswhileexamining ratherthanthewholeblade,employingarrowstowidenthearea
andcritiquingdesignprobes.Priortothestudytasks,participants coveredbytheaugmentations,andintroducingavisualwarning
completedatutorialtobecomemorefamiliarwithCookAR.They systemwhentheuser’shandgetstooclosetoariskyarea.The
theninteractedwithourARdevicefor30minutes:a5-minutetu- designprobesareinspiredbypriorworkonlowvisionaugmen-
torial,10minutesofobjectgrabbing,and15minutesoffree-form tations[16,36,78,82].Subsequently,weinvitedparticipantsto
cooking.Weprovidemoredetailsbelow. proposeaugmentationdesignideasforbothsimpleobjectslike
Tutorial.Participantswereaskedtofirstcompleteatutorial knifesandmoreintricateobjectswithmoreinteractivepartsbe-
task:interactwithacookingpotusingCookAR.Participantswore yondgrabbableandhazardousareas,likeacarafewithmanyholes
andadjustedtheOculusQuest2headsetandbecameacquainted and buttons. Lastly, we asked participants to identify scenarios
withCookARanditsaffordanceaugmentations.Onceparticipants otherthanakitchenwhereCookARmightbebeneficial.
achievedacomfortablefitandanunderstandingofCookAR,the
studyproceeded. 5.4 Analysis
Part1:ComparisonStudy.InPart1,participantswereaskedto
Werecordedparticipants’quotesusingZoom.Transcriptionswere
locateandpickupcookingtoolsunderthreeconditions:(1)without
firstdonebythevideoconferencingsoftware,thentheresearch
CookAR,(2)withCookARdisplayingwholeobjectaugmentations,
teammanuallyrevisedthetranscripts.Wecollected346distinct
and(3)withCookARdisplayingaffordanceaugmentations(See
quotesacrossour10LVparticipants,whichweanalyzedusing
Figure5).WecounterbalancedtheconditionorderviaLatinSquare.
reflexivethematicanalysis[4,5].Thefirstauthor,whofacilitated
Ineachcondition,participantsconductedfivetrialsoftool-picking-
everyuserstudysession,createdaninitialcodebookbyreviewing
uptasks.Werandomlychoseacookingtoolpertrialfromthenine
therevisedstudytranscripts.Theresearchteamthencollaboratively
kitchentoolsontheexperimenttable(SeeSection5.2).Participants
iteratedonthecodebookwhilecheckingforbiasandcoverage.
wereaskedtokeeptheireyescloseduntiltheresearchernamed
Withafinalcodebookconsistingof23codes,thefirstauthorcoded
an object to reduce the effect of memory on task performance.
participants’quotes,afterwhichtheteamdiscussedtheresulting
Moreover,theresearcherrearrangedtheplacementandangleof
themes.Forlikert-scalescoreanalysis,weusedaWilcoxonsigned-
thecookingtoolsbetweeneachcondition.Aftereachcondition,
ranktestsincethedatadoesnotfollowanormaldistribution.
weaskedparticipantsthree7-pointLikertquestionsabouteffec-
tiveness,comfort,anddistraction,aswellasopen-endedquestions
6 RESULTS
regardingtheirexperiencewitheachaugmentationcondition.Af-
ter all 15 trials, we asked participants to compare the pros and In our three-part qualitative study, participants completed tool-
consofthethreeconditions,suggestimprovementsforCookAR, graspingtasks,afree-formcookingtask,andabrainstormingses-
andidentifypotentialapplicationsofCookARoutsideofkitchen sionwithdesignprobes.Overall,participantsfoundthereal-time
contexts. affordanceaugmentationshelpfulwheninteractingwithvariousUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
P# Gender Age LeftEyeAcuity RightEyeAcuity DescriptionofVisualField
P1 Male 30 NoLightPerception 20/400 Colobomadominatestherightsuperiorportionofmyrighteye.
P2 Female 83 20/200 20/100 Deterioratingeyesightfromdrymaculardegeneration.Lostcentral
visiononlefteye.Centralvisionontherighteyeisstilltherebutnot
good.Haveperipheralvisiononboth.
P3 Female 62 20/125 20/100 Lowvision.Someholesinit,likeblackspots.Scartissue.
P4 Male 65 20/20 20/60 Canseefrom2/3’soflefteye,somefarrightperipheralvisionfrom
righteye.
P5 Female 70 20/200 20/100 Maculardegenerationandsideeffectsofchemotherapy.Blurryvision
andneedfontenlargementtoread.Visualfieldintact.
P6 Male 50 20/40 NoLightPerception Blindinrighteye.Needglassesforleft.Visualfieldintact.
P7 Female 81 20/200 20/60 Diminishedvisionduetomaculardegeneration.Visualfieldintact.
P8 Female 80 20/50 20/50 Havedrymaculardegenerationwithlossofsomevisioninthecenter
ofmylefteye.
P9 Female 30 LightPerception 20/80 Canmakeoutfaceswithrighteye.Lefteyeisblind.Visualfieldintact.
P10 Female 71 20/60 20/100 IhaveGlaucoma.Myfieldofvisionis5%eyesight.5%inmyleftand
5%intherightremaining.
Table2:Individualstudyparticipantinformation,includingtheirgender,age,leftandrighteyeacuity,andaself-reported
descriptionoftheirvision.
Figure5:CookARprototypewithwholeobjectaugmentations(left)andaffordanceaugmentations(right).Thewholeobject
augmentationsaregreeninstancesegmentationmasks,whiletheaffordanceaugmentationsaregreen(grabbable)andred
(hazard)affordancesegmentationmasks.
cookingtools.Theyalsosuggesteddesiredaugmentationdesigns objectaugmentations(𝑚𝑒𝑎𝑛 𝑤 =4.6;𝑆𝐷 𝑤 =1.4).Affordanceaug-
andkeyaffordanceparts.Weexpandonthesefindingsbelow. mentationsareadvantageousinquicklyunderstandingtheoverall
scene(P1,P10),alongwiththeplacementandorientationofin-
dividualobjects:“Ithelpstohavetwocolors.Icouldseethatmore
6.1 Affordancevs.WholeObjectAugmentations readilyandquicklytounderstandhowtousetheobjectandhowit
isplaced...yoursystemishelpfulbecausewherethetoolstartsand
Allbutoneparticipant(P6)preferredaffordanceaugmentations
endsandwherethehandlestartsandendsismoreclear”(P5).Inad-
overwholeobjectaugmentationsforsupportingkitchentoolinter-
dition,affordanceaugmentationsbecomeparticularlyusefulwhen
actions.Theynotedatrade-offbetweentheaugmentations’utility
handlingobjectsthathavehazardous(9outof10participants)(e.g.,
anddistraction,withtheformergenerallyoutweighingthelatter:
sharp,hot)orsmall(8/10)(e.g.,doorhandles,buttonsonappliances)
“Seeingonecolorwaslessdistractingthanseeingtwocolors.Butyou’d
parts,orhaveinsufficientcolorcontrast(7/10)(e.g.,allsilveror
havetoknowwhichendofthetoolisthehandleandwhichisthework-
blackcookingtools):“You’vegottashowpartsyoucanandshouldn’t
ingend”(P2).Wereportparticipants’feedbackontheeffectiveness
grab.Greentellsmethat’sasafeplacetogowithmyhand.Anything
anddistractionoftheaugmentationsbelow.
notgreen,Ishouldn’tgrab...Itcanhelpmeavoiddangerouspartsor
Effectiveness.InexaminingLikertdataonperceivedeffective-
perhapsevenfindsmallthingslikeremotecontrollers”(P4).Further-
ness, the findings showed no significant difference (𝑊 = 36.5;
more,fourparticipantsexpressedthatforsomeobjectswithmore
𝑝 = 0.32).However,participantsonaveragegavehigherratings
complexinteractioncomponentsthan“justgrabanddon’tgrab”
toaffordanceaugmentations(𝑚𝑒𝑎𝑛 𝑎 =5.3;𝑆𝐷 𝑎 =1.6)overwholeCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
Figure6:DesignprobesusedinPart3ofthestudytosparkdesignideas.
(P7),likeacarafewithitshandle,base,buttons,lid,andspout,they limitationsinaccuratelysegmentingobjectaffordances,deploy-
wouldaccepttheuseofmorethantwocolors,although“morethan ingheavyCVmodels,andrenderingspatiallyaccurateoverlaysin
fourcolorscanbequitedistracting”(P7).Wediscussaugmentation real-timeonARheadsets,CookARexperiencedrecognitionerrors
designsinSection6.3. andperceivedlatency,whichaffectedLVusers’experiences.All
Distraction&Comfort.Whileparticipantsqualitativelyex- participantsobserved“flickering”andinaccurateaffordanceaug-
pressedthatthewholeobjectaugmentationsarelessdistracting mentations.Participantsalsopointedoutthat“thecolorstooksome
than the affordance augmentations (6/10), the comfort and dis- timetocatchup”(P3)astheyquicklyrotatedtheirhead.Nonethe-
traction Likert data was not significantly different (𝑊 = 52.5; less,allbutP6sawpotentialinCookARtoassistwithkitchentool
𝑝 = 0.88and𝑊 = 46;𝑝 = 0.78respectively).Thedifferencein interactionsandbeyond:“Ilikethecontrastingcolor.Ijustwishit
averageratingwasalsonegligeable,althoughparticipantsonaver- morecloselymatchedtheobject’sactuallocation.Ithinkthishigh-
agefoundwholeobjectaugmentationstobeslightlymorecomfort- lightingsceneisagreatstart.Ifthesystemisperfect,thedualcolor
able(𝑚𝑒𝑎𝑛 𝑤 =5.1;𝑆𝐷 𝑤 =1.3vs.𝑚𝑒𝑎𝑛 𝑎 =5.0;𝑆𝐷 𝑎 =1.2)andless highlightsystemwouldbegreatandmostuseful.Thesystemwould
distracting(𝑚𝑒𝑎𝑛 𝑤 =2.3;𝑆𝐷 𝑤 =0.9vs.𝑚𝑒𝑎𝑛 𝑎 =2.5;𝑆𝐷 𝑎 =1.1).P6, beperfectifIaminakitchenorjusttryingtograbreallyanything”
whopreferredwholeobjectaugmentationsduringthestudy,said (P1).P1,P5,P9,andP10wereparticularlyexcitedastheywereable
“Ithinkthemorecolorsyouhave,themoredistractingitbecomes.So tobettervisuallyperceiveobjectinformation:“Thisisfun!Ican
Ipreferjustthewholeobjectingreenthanhaving2or3different alsousemyeyesmoretoseeshapeandhowitcanbeused.Iwantto
colors.Anoutlinewouldbebetter.Iwoulddefinitelystayawayfrom tryyoursystemagaininthefutureonceyoumakeitbetter”(P9).
multicoloredandjuststickwithonecolor.Icanfigureoutitsdifferent Recognizing the potential of CookAR, participants identified
parts.”Additionally,threeparticipantssharedthatthewholeobject additionalusecasesofaCookAR-likesystemthatgobeyonda
augmentationscouldbemoreusefuldependingonthescenarios. cookingscenario,includingcleaning(P3,P6,P7,P9),woodworking
Fortaskssuchaslocatingoravoidingobjects,whereinteractionis (P4,P5,P9),walkingoutdoors(P2,P6,P9),driving(P4,P6,P7),vis-
notthegoal,wholeobjectaugmentationsaremorepreferable,since itingaforeignkitchen(P2,P5),restaurants(P3,P9),gardening(P5,
theyarelessdistracting:“IfIamlookingfortheremotecontroller, P10),watchingsports(P7,P10),playingboardgames(P7,P10),go-
ifitcouldmaketheremotestandmoreoutingreenorsomething.I ingdownstairs(P7,P9),identifyingpillbottles(P7),andinteracting
don’tneeditsparts”(P3). withapplianceswithmultiplebuttonslikeatoaster(P1).
Insummary,ifaperson’sintentistointeractwithanobject,
affordanceaugmentationsaremorehelpfulthanwholeobjectaug-
6.3 DesiredAugmentationDesigns
mentations.Conversely,incaseswhereinteractionisnottheobjec-
tive,wholeobjectaugmentationsmaybepreferredastheyareless Wereportparticipants’preferencesonaugmentationdesignsfor
distracting.Inourstudy,participantshadtointeractwithvarious grabbableandhazardousareasbasedonthedesignprobes.
kitchentools,hencemostofthemfoundouraffordanceaugmenta- Combiningsolidandoutlineaugmentations.Asopposed
tionsmoreuseful. tosolid-coloredoverlays,nineparticipantspreferredamixofsolid
andoutlineaugmentations,becausesolidcolorsaremoresalient,
whereasoutlinesarelessdistracting:“Solidcolorsarehelpfulbecause
6.2 ExperienceswithCookAR
theygrabmyattention...outlinesarehelpfulbecauseIcanstillsee
Allparticipantswereabletocompleteallfree-formcookingsteps thepartI’mtryingtousewithlessdistraction”(P5).Amongthose
withinthreetofiveminutes.However,duetocurrenttechnical nineparticipants,allbutP7preferredsolid-coloredoverlaysforUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
thegrabbableareaandoutlinesforthehazardousareabecause P6suggestedsmallyetnoticeableaudiosuchas“beepbeep,”while
“thegrabbableareaisthemostimportant”(P3,P4,P5,P8,P9),“all P7andP10preferredexplicitverbalwaning(e.g.,“stop”)sincesmall
youneedtoknowisitsshape”(P4,P9),and“otherpartsshouldbe noisescanalsobegeneratedbyotherdevices,suchasamicrowave
outlinedsinceyoumaywanttodomorewithit,andsolidcolor orafridge.P4andP9furthersuggestedthesystemshouldemploy
justmakesithardertouseit”(P4,P8,P9).However,P7preferred differentauditorysignalsfordifferenthazards.
theoutlineforthegrabbableareasinceitisnotdistractingandstill Action-awareAugmentations.Asopposedtoconstantlyaug-
showstheshapeofthehandle. mentingallaffordances,halfoftheparticipantssuggestedgener-
Fortheriskyareatooutline,P8preferredhighlightingsolelythe atingaugmentationsbasedonusers’currenttasksorbehaviorsto
exacthazard(e.g.,thesharpedgeoftheknifeblade),asopposed reducepotentialdistraction.Forexample,withaknife,boththe
to the entire dangerous part of an object (e.g., the whole knife handleandbladecanbeaugmentedtostart,thenwhenaperson
blade), because she needs to know the relatively safer area for grabs it, the handle augmentations could be turned off (P7); or,
interaction.Forexample,asshedescribed,“Imightgrabthetopof asapersongetsclosetoacarafewithacupofwater,therimof
thebladewhenI’mdicingorchopping.Thistellsyouexactlywhere thecarafecouldbehighlighted(P4).Moreover,sevenoutof10
youshouldn’ttouch.”Incontrast,allotherparticipantswantedthe participantsalsosuggestedusingvoicecommandstocontrolthe
outlineaugmentationbecauseitislessdistracting,yetstilldefines augmentations, such as turning on and off an augmentation or
theoverallshapeofthehazardousarea(P4,P5,P7,P9,P10)and adjustingtheaugmentationdesign(e.g.,colorsorforms).
whatitisusedfor(P4,P7,P9).Forexample,P9said,“Ipreferto
see the outlines on the [whole] blade, just so that way, you know
6.4 AdditionalToolAffordances
whichtypeofbladeyou’regrabbing.Causeabreadknifewouldlook
differentfromyourknife.Somearethinner,somearefatter.Peoplecan Inadditiontothegrabbableandhazardousaffordancesfocusedin
bequitepickyabouttheirknifechoices.”P3,whopreferredtooutline ourCookARsystem,participantscollectivelysuggestedfiveother
dangerousparts,cautionedthat“dependingonhowlowvisionyou importantaffordancesforkitchentools:(1)entryarea,(2)exitarea,
areonthespectrum,youmayneedsolidcolorstobeabletoseesome (3)containmentarea,(4)intersectionarea,and(5)activationarea.
oftheseobjects.” Weelaborateonthesesevenaffordancesalongwithparticipants’
Lastly,P1,P4,andP10expressedconcernsthatoverlayingper- preferredaugmentationdesigns.
fectlyalignedsolid-coloredaffordanceaugmentationscanbetech- Grabbablearea.Agrabbableareaisthepartdesignedforsafe
nicallychallenging.Theysuggestedacoloredcirclemaybeenough, handlingormanipulation.Thiscanincludehandles,grips,orany
sincetheyonlyneed“ahinttoseeaglimmeroftheobject”and part intended for direct hand contact. For grabbable part of an
determinehowtheobjectsareoriented(P1). object,participantspreferredgreensolid-coloredaugmentations
Enhancingcolorcontrast.Usingcolorstodistinguishobject (Section6.3).
affordances was well-received, as participants often color code Hazardousarea.Ahazardareaisthepartthatposespotential
theirowncookingtools:“SoIalwaystrytogetthingscolorcoded... risksordangerstotheuser.Thiscouldincludesharpedges,hot
especiallyifthingsareindrawers,ittakesalotofcognitionformeto surfaces,oranypartthatcancauseinjuryiftouchedormishandled.
tellyouwhat’swhat.Ifit’scolored,it’ssomucheasier.Thissystemis Forhazardouspartofanobject,participantspreferredredoutline
hugecauseit’sdoingcolorcodingforme”(P1). augmentations(Section6.3).
Everyparticipantfavoredusinggreenforsafe-to-grabandred Entryarea.Anentryareaisthepartdesignedforinitiating
fordangerousareas,as“greensignals‘yes’while‘red’signalsno” access,suchaspouring.Thiscouldbetherimofacuporapot,
(P4).However,P4,P7,andP9struggledtoclearlyseeourchoiceof theopeningofacarafe,oranydesignatedpointthatallowsentry
redandrequestedabrightershadeofred,withP4evensuggesting intoanobject’scontainmentspace.Allparticipantsconsistently
white.Moreover,participantsnotedthatthecolorcontrastbetween notedthatthisareaonanobjectshouldbeaugmentedbyanoutline
thetoolandthebackgroundismoreimportantthanthespecific ratherthanasolidcolor,asthelatterobstructsrelevantactions
colors used, since a lot of objects in a kitchen are white, silver, likepouringorscooping:“Thecolorblobshidetheitemthatyou’re
orblackwithlowcontrast.Forexample,whencookingmacand tryingtoputthingsintovirtuallycompletely.AndsoIcan’treally
cheeseinthestudy,most(8/10)participantsfounditchallenging tellifIampouringsomethingincorrectly”(P4).
tocutbutterandunderstandwheretheyellowbutterstartsand Exitarea.Anexitareaisdefinedasthepointthroughwhich
endsbecauseitwasonayellowwoodencuttingboard.Toaddress contentsaremeanttobereleased.Thiscouldbethespouts,holes,
this,P3,P4,P5,andP10suggestedthesystemshouldautomatically or any defined pathway that guides content out of the object’s
selectcolorsthatcontrastagainstthebackground:“Thebackground containmentspace,anditcanbethesameastheentryareafor
youhaveitagainstwillmakeabigdifference,right?Soonadarker someobjects,suchasbowlsandcups.Severalparticipants(4/10)
background,Ishouldbegettinglightcolors”(P4).P7jokinglysaid,“I suggestedthatthecarafe’sspout,similartotheentryarea,should
mean,agreenstickofbuttercouldbeweird,butitwouldatleastlet beoutlined:“Highlightingthespoutwouldbehelpfulifyouhadto
mecutbetter.” pour,becauseifIpouredinthewrongplace,Iwouldn’tknowuntil
Auditoryfeedback.Insteadofvisualaugmentations,allpartic- somethingspills.IthinkIcanpourmoreeffectivelyifyouhighlighted
ipantspreferredauditoryfeedbackforwarninginurgentscenarios thisbyaligningitwiththeedgeofacuporsomething.Anoutline
(e.g.,whentheuser’shandsgettooclosetoaknifeblade),asavisual wouldbegreatsoIcanseethewaterflowingout”(P7).
warningcouldbeeasilymissedbylowvisionusers(P3,P5,P7,P9) Containmentarea.Acontainmentareahassomedepthandis
andalsomakestheoverallvisualfieldbusier(P4,P10).P3,P5,and meanttoholdcontentwithin,suchasfoodandliquid.ThiscouldCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
betheinteriorofacuporpot,thebaseofaspoonorladle,orany 7 DISCUSSION
definedspacewithintheobjectthatismeanttokeepsomething CookARexplorestheuseofaffordanceaugmentationstoenhance
in.Thecurrentsolid-coloredoverlaysinCookARinterferewith kitchentoolinteractionsforLVpeopleandadvancesthestate-of-
visibilityofthecontainmentspace.Instead,allparticipantswanted the-artinAI-poweredARsystems.Resultsfromouruserstudy
CookARtoaugmentonlytheentryandexitareasusingoutlines, indicatesapreferenceforaffordanceaugmentationsoverwhole
leavingthecontainmentspacewithoutanyaugmentation. objectduringtoolinteractions.Additionally,participantsfavored
Additionally,eightparticipantsexpressedthattheyneedassis- augmentationdesignsthatincorporatebothsolid-coloredandout-
tancewithunderstandingthedepthofthecontainmentspaceand linedoverlayswithcontrastingcolors.Wediscussdesignimplica-
theamountofcontentitalreadyholds.AsP8expressed,“Alotof tionsforaffordanceaugmentationsaswellascurrentlimitations
peoplewithlowvisioncannotseeinsideandknowhowmuchwater andfutureopportunitiesofAI-poweredARsystemsforlowvision.
theycanpour.Sosomehowshowingthewaterlevelandsizeofthe
teapot[ishelpful].Mineisalotbigger,itmakes12cupsorsomething,
7.1 DesignImplicationsforAffordances
andit’sallblack,soit’sevenhardertoseewhat’sinside.”WhileP9
hasastrategytoovercomethischallengebyusingherfingerto Throughoutthestudy,ourLVparticipantsproposedarangeof
feeltheliquidlevel,shecannotuseitwhenthewaterishot.She affordancesforkitchentoolsandindicatedtheirpreferredaugmen-
thussuggestedthesystemrendering“abluedisk”toindicatethe tationdesignsforeach.Inthissection,wesummarizeandexpand
waterlevel.Intermsofaugmentingthedepthofthecontainment onthesesuggestions.
area,participantssuggestedusingavirtuallinefromtherimto Whentouseaffordanceaugmentations?Ourstudyindicates
thebottomofthepot(P3,P4,P5,P9,P10),ameasuringtapewith thatvisualaugmentationsshouldmaximizeutilityandminimize
ticks(P4,P5,P9,P10),oralinewithchangingcolors(e.g.,agreen visualclutterandconfusion.Assuch,itiscriticaltorenderaug-
linethatturnsredaswaterfillsup),(P4,P5).P10furthersuggested mentations tailored to users’ intent and reduce distraction. For
anauditorycue(e.g.,a‘ding’sound)toindicateactionmilestones, example,affordanceaugmentationsthatinvolvemultiplepieces
suchaswhenreachedquarterofacup. andcolorswouldbemorepreferredtosupportinteractions,while
Intersectionarea.Anintersectionareaiswherepartsoftwo basicwhole-objectaugmentationsaremoresuitableingeneralvi-
ormoreobjectsmeet.Thiscouldbewhereaknifebladetouches sualperceptiontaskssuchasavoidingobstacles.Beyondakitchen,
thebutterforcuttingorwhereacuptouchesapotforpouring. affordanceaugmentationscouldalsobeappliedtootherscenarios,
Interactionsthatrequireprecisealignmentbetweentwoobjects asourparticipantssuggested,suchasgardening,playingboard
are particularly challenging to our LV participants. Half of the games,andinteractingwithappliances(reaffirming[36]).
participantssuggestedgeneratingaugmentationstohighlightthe Wheretoapplyaffordanceaugmentations?Affordancescan
intersectionsorrelationshipsbetweentwointeractingobjects,for refer to anyobject parts thatindicate diverse action orinterac-
example, the location where a knife cuts the butter (P5) or the tionopportunities.However,LVpeoplefacedistinctinteraction
alignmentbetweenaladleandabowlwhenpouring(P9).AsP9 challenges,resultinginuniqueaffordancestoaugmentforthem.
mentioned,“Usingaladlehasalwaysbeenaproblemforme.Pouring Inourqualitativestudy,weidentifiedsevenessentialaffordances
theladleintothingsisusuallythehardestpart,becauseyounever ofkitchentoolsthatrepresentimportantyetchallenginginterac-
knowiftheladleisintherightspotortoowideoutoftheway.Maybe, tiontasksforLVusers.Theyinclude:(1)grabbablearea,affording
ifyouhavetheladleontopofabowl,[CookARshouldrender]a touchingandhandlingaction;(2)hazardousarea,affordingrisks
[virtual]shadowthatgetscastedontothebowl.” andavoidance;(3)entry,affordingatargettoaimatorpourin;(4)
Activationarea.Anactivationareaisdesignedforinitiating, exit,affordingpouringoutandusuallyrequiringaccuratealign-
activating,orturningonanobject’sfunctionorfeatures.Thiscould mentwiththeentryofanotherobject(e.g.,foodtransferringor
bebuttons,switches,touch-sensitivesurfaces,oranyinteractive pouring);(5)containmentarea,affordingholdingcontentinand
componentsthattriggertheoperationofanobject.Participants preferringaugmentationsonthecontentamount(e.g.,ingredient
identifiedactivationareasonmanyhouseholdappliances,suchas measurement);(6)intersectionarea,affordingtouchingorinterac-
buttonsanddialsonstovetops,microwaves,orcoffeepots.They tionbetweentwoobjects;and(7)activationarea,affordingcontrol
areusedforvariouspurposesincludingstartingamachine,opening featuresonanobject.Thisaffordanceframeworksummarizesthe
alid,andadjustingsettings.Sevenparticipantspreferredoutline criticalareasonobjectsaswellasthehand-object(e.g.,grabbable
augmentationsfortheactivationarea:“Ijustboughtavacuumwith vs.hazardousareas)andobject-object(e.g.,entry-exitalignment,
multiplebuttons.Youwouldwantdifferentcolorsforthehandlesand intersectionbetweenobjects)relationshipsduringinteractions.
buttons”(P8).P10furthersuggestedaclock-likeaugmentationin Howtoaugmentaffordances?Differentaugmentationsshould
additiontotheoutlineforturnabledials:“Onastove,Idon’tknow bedesignedfordifferenttypesofaffordancesaccordingtothein-
whatismediumheat.AsIturntheknobsonastove,thesystemcould teractiontaskstheyindicate.Ourstudyrevealedthemostpreferred
showme‘2o’clock,’‘3o’clock,’andsoon.‘6o’clock’isprobablya augmentationsfordifferentaffordances.Specifically,solid-colored
mediumheat.‘9o’clock’isprobablyahighheat.” overlayswithgreatvisualemphasisarepreferredforgrabbablearea
toenablefastperceptionandaction,measuringaugmentations(e.g.,
linewithticks)forcontainmentareatoindicatecontentamount,
andoutlinesforotheraffordancestoavoiddistractionandocclu-
sion.Intermsofcolors,augmentationsshouldadoptcolorswith
highcontrastagainsttheenvironment.WealsosuggestleveragingUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
thecommonly-agreedmeaningsofcolors,suchasgreenforsafe- MiniAPI,leadingtoflickeringandunstableaugmentationrender-
to-grabareasandredforriskyareas.However,whilepreferredby ing.Toenhancethesystem’srobustnessandaffordancerecognition
theLVparticipantsinourstudy,thegreen-redcombinationshould capabilities,futureAIresearchshouldconsiderthefollowingkey
beusedcautiouslyconsideringthatLVusersmayexperiencecolor areas:(1)developinglargerandmorediverseaffordancedatasets.
deficiency. Thesedatasetsshouldcaptureawidervarietyofobjectinteractions
Howtocontrolaffordanceaugmentations?Duetothedi- andfunctionalities,allowingthemodeltolearnfromarichersetof
versevisualabilitiesandpreferencesofLVusers[81],futuresys- scenarios;(2)designingmodelsforaffordancedetection,suchas
temsshouldsupportextensivepersonalizationcapabilitiessuchas incorporatingtrainingobjectivesthatrefineobjectpartrelationship
voice-basedcontrolforcustomizationandautomaticadaptations. understandingforbetteraffordanceprediction;(3)onthesystem
For instance, users should beable to adjust different aspects of level,prioritizingimprovementstoobjecttrackingalgorithmsto
anaugmentation’sdesign,suchasswitchingitonoroff,choosing ensuremorestableaugmentationrendering,especiallyindynamic
betweensolid-coloredandoutlinedoverlays,changingtheoutline’s environmentswherepreciseobjectlocalizationiscrucial.
thickness,andselectingsuitablecolors.Additionally,thesesystems Systemlatency.LatencyisalwaysaconcernforARsystems,
couldintelligentlyadaptbyrecognizinguseractionsortasksto especiallyconsideringthatoff-the-shelfARdevicesusuallydonot
onlyhighlightnecessaryobjectpartsandsignalwarnings.They havesufficientcomputationalpower(e.g.,GPU)tosupportreal-time
canalsoautomaticallyaltertheaugmentations’colorstogenerate CVmodels.Toenableaffordancesegmentation,oursystemstreams
highcontrastagainstthebackground. videodatabetweentheARheadsetandanexternalserver.However,
thelatencycausedbythedatatransitionpreventedtheoverlays
fromkeepingpacewiththeparticipants’headmotions,negatively
7.2 ChallengesinAI-poweredARDevelopment
impactingparticipants’trustinCookAR’sintelligenceandtheir
ThispaperpresentsseveralkeytechnicalcontributionsacrossCV perceptionsofthesystem’susability.Toaddressthesystemlatency,
and HCI by constructing the first egocentric kitchen tool affor- effortsareneededinbothsoftwaredevelopment(e.g.,real-timeAI
dancedataset,fine-tuninganaffordancesegmentationmodelon models)andhardwareadvancement(e.g.,ARdeviceswithpowerful
ourdataset,anddevelopingafully-functionalstereoARsystemthat GPUs)toincreasetheusabilityofARsystemsindynamicreal-world
generatesreal-timeaffordanceaugmentations.Below,wereflecton activities.
keytechnicalchallengesstemmingfrombothfields.
AImodelsforreal-worlduse.Althoughourfine-tunedmodel
7.3 Limitations&FutureDirections
outperformsthebasemodelinaccuratelysegmentingaffordances
ofcookingtools,itsmAPisstilltoolowtosuccessfullysupport Therearethreeprimarylimitationsinthiswork.First,asaninitial
dynamicactivitieslikecookinginareal-worlddeploymentstudy. prototype,weconductedaqualitativeuserstudywitharelatively
Forinstance,itsAP@75is48.6%,meaningintheworstcase,about smallnumberofparticipantstoexploreusabilityandsolicitreac-
halfofallpredictionsfailtoachievegreaterthan75%overlapwith tionstotheideaofaffordanceaugmentationsinAR.Futurework
thegroundtruthaffordancemasks.Therecognitionresultscould should conduct larger scale studies with more participants and
becomeevenworseinreal-worlduseonawearableARsystem diversevisualconditions.Second,theaforementionedtechnical
duetotheusers’constantheadmotionsanduniquebehaviors.For challengesandlimitations.Thirdandfinally,thecurrentCookAR
example,LVuserstendtogetmuchclosestoviewobjectsthan systemprovidesonlyonebasicaffordanceaugmentation—solid-
sightedusers[64].Thisissuehighlightstheevaluationgapbetween coloredoverlays.Buildinguponthedesigninsightsinourstudy,
HCIandAI:amodelthatdemonstratesareasonableperformance futureworkshouldincorporatemoreaugmentationoptions(e.g.,
underAIevaluationmeasures(e.g.,mAP,AP@50,AP@75)may outlines)andenablemoreflexibleadjustment(e.g.,colors,thickness
beappropriateforanin-labuserstudybutnotamorenaturalistic oftheoutlines),toprovideLVusersmorepersonalizedexperience.
environmentfoundindeploymentstudies.Wesuggestthatwhen
developingAImodels,researchersshouldconsiderthepotential
8 CONCLUSION
real-worldusecases,humanneeds,andintegrationtodifferent
hardwareplatforms(e.g.,wearableAR)toenableuseinpractice. Inthispaper,weintroduceCookAR,awearableARprototypethat
Affordancemodelsanddatasets.Asopposedtoobjectrecog- canoverlayaffordanceaugmentationsinreal-timetosupportsafe
nition models and datasets that attract significant attention in andefficientkitchentoolinteractionsforpeoplewithlowvision.
AI[13,23,40,41],theresearchonaffordancemodelsanddatasets TobuildCookAR,weassembledanegocentrickitchentoolaffor-
remainsnascent.Toaddressthisissue,wecollectedandlabeledan dancedataset,fine-tunedanRTMDet-Ins-lmodelonourdataset
affordanceimagedatasetforkitchentoolsandfine-tunedanobject (i.e.,RTMDet-Ins-l-Cook),andleveragedthismodifiedmodelwith
detectionmodelontheaffordancedatasettobalanceaccuracyand astereodepthcameraandanARheadsettogeneratereal-time
speed.However,duetotherelativelysmallscaleofthedataset affordanceaugmentationsin3Dspace.Inatechnicalevaluation
andthemodelnotbeingdesignedforaffordance,oursystemen- of RTMDet-Ins-l-Cook, we found that it outperforms the base
counteredaffordance-specificissues.Forexample,ourmodeloften RTMDet-Ins-lmodelinaccuratelysegmentingaffordancemasks
struggledtodistinguishdifferenthandles,asmanyhandlesacross ofcookingtools.WethenevaluatedtheCookARprototypeina
variouscookingtoolslooksimilar.Whilenotaffectingthemask three-partlabstudywithLVparticipants.Findingsindicatethat
generation(sothatuserscanstillseethecorrectaugmentations),it participantspreferaffordanceaugmentationsoverwholeobject
interferedwiththeobjecttrackingmodelsupportedbytheZED augmentationsforkitchentoolinteractions.ParticipantsexpressedCookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
adesireforanaugmentationdesignwithacombinationofsolid- 2019CHIConferenceonHumanFactorsinComputingSystems(Glasgow,Scotland
coloredandoutlinedoverlays.Thegrabbableareashouldbeaug- Uk)(CHI’19).AssociationforComputingMachinery,NewYork,NY,USA,1–13.
https://doi.org/10.1145/3290605.3300276
mentedusingsolidgreenoverlays,whileotheraffordancesinclud-
[16] DylanR.Fox,AhmadAhmadzada,ClaraTeniaWang,ShiriAzenkot,MarlenaA.
inghazardous,entry,exit,containment,intersection,andactivation Chu,RobertoManduchi,andEmilyA.Cooper.2023.Usingaugmentedrealityto
areasshouldbeoutlinedusingacontrastingcolor.Participantsalso cueobstaclesforpeoplewithlowvision.Opt.Express31,4(Feb2023),6827–6848.
https://doi.org/10.1364/OE.479258
askedforenhancedcustomizationandautomaticadapationsfor [17] PatriciaGarrido-VásquezandAnnaSchubö.2014.Modulationofvisualattention
affordanceaugmentationdesigns.Ourworksuggestsfuturedesigns byobjectaffordance.FrontiersinPsychology5(2014),70664.
[18] JamesJeromeGibson.1966.Thesensesconsideredasperceptualsystems.(1966).
ofaffordanceaugmentationstoenhancekitchentoolinteractions
[19] JamesJGibson.1977.Thetheoryofaffordances.Hilldale,USA1,2(1977),67–82.
forLVpeopleandadvancesthestate-of-the-artinAI-poweredAR [20] JamesJGibson.2014.Theecologicalapproachtovisualperception:classicedition.
experiencesaslowvisionaids. Psychologypress.
[21] AnshulGupta,JurajMesik,StephenAEngel,RebeccaSmith,MarkSchatza,
AurélieCalabrese,FrederikJVanKuijk,ArthurGErdman,andGordonELegge.
ACKNOWLEDGMENTS 2018.Beneficialeffectsofspatialremappingforreadingwithsimulatedcentral
fieldloss.Investigativeophthalmology&visualscience59,2(2018),1105–1112.
ThisworkwasprimarilysupportedbyanNSFGraduateResearch [22] KaimingHe,GeorgiaGkioxari,PiotrDollár,andRossGirshick.2017.Maskr-cnn.
FellowshipandNSFCHS#1763199. InProceedingsoftheIEEEinternationalconferenceoncomputervision.2961–2969.
[23] KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016.Deepresidual
learningforimagerecognition.InProceedingsoftheIEEEconferenceoncomputer
REFERENCES visionandpatternrecognition.770–778.
[24] StephenLHicks,IainWilson,LouwaiMuhammed,JohnWorsfold,SusanM
[1] ShiriAzenkotandYuhangZhao.2017. Designingsmartglassesapplications Downes,andChristopherKennard.2013.Adepth-basedhead-mountedvisual
forpeoplewithlowvision.SIGACCESSAccess.Comput.119(nov2017),19–24. displaytoaidnavigationinpartiallysightedindividuals. PloSone8,7(2013),
https://doi.org/10.1145/3167902.3167905 e67695.
[2] ShikharBahl,RussellMendonca,LiliChen,UnnatJain,andDeepakPathak. [25] JonathanHuang,MaxKinateder,MattJDunn,WojciechJarosz,Xing-DongYang,
2023.AffordancesfromHumanVideosasaVersatileRepresentationforRobotics. andEmilyACooper.2019.Anaugmentedrealitysign-readingassistantforusers
CVPR. withreducedvision.PloSone14,1(2019),e0210630.
[3] MarieClaireBilyk,JessicaMSontrop,GwenEChapman,SusanIBarr,andLinda [26] AlexDHwangandEliPeli.2014. Anaugmented-realityedgeenhancement
Mamer.2009.Foodexperiencesandeatingpatternsofvisuallyimpairedandblind applicationforGoogleGlass. Optometryandvisionscience91,8(2014),1021–
people.CanadianJournalofDieteticpracticeandresearch70,1(2009),13–18. 1030.
[4] Virginia Braun and Victoria Clarke. 2006. Using thematic [27] DhruvJain,BonnieChinh,LeahFindlater,RajaKushalnagar,andJonFroehlich.
analysis in psychology. Qualitative Research in Psychology 3, 2018. ExploringAugmentedRealityApproachestoReal-TimeCaptioning:A
2 (2006), 77–101. https://doi.org/10.1191/1478088706qp063oa PreliminaryAutoethnographicStudy.InProceedingsofthe2018ACMConference
arXiv:https://www.tandfonline.com/doi/pdf/10.1191/1478088706qp063oa CompanionPublicationonDesigningInteractiveSystems(HongKong,China)(DIS
[5] Virginia Braun and Victoria Clarke. 2019. Reflecting on reflexive the- ’18Companion).AssociationforComputingMachinery,NewYork,NY,USA,7–11.
matic analysis. Qualitative Research in Sport, Exercise and Health https://doi.org/10.1145/3197391.3205404
11, 4 (2019), 589–597. https://doi.org/10.1080/2159676X.2019.1628806 [28] DhruvJain,LeahFindlater,JamieGilkeson,BenjaminHolland,RamaniDu-
arXiv:https://doi.org/10.1080/2159676X.2019.1628806 raiswami,DmitryZotkin,ChristianVogler,andJonE.Froehlich.2015. Head-
[6] KaiChen,JiaqiWang,JiangmiaoPang,YuhangCao,YuXiong,XiaoxiaoLi, MountedDisplayVisualizationstoSupportSoundAwarenessfortheDeafand
ShuyangSun,WansenFeng,ZiweiLiu,JiaruiXu,ZhengZhang,DazhiCheng, HardofHearing.InProceedingsofthe33rdAnnualACMConferenceonHu-
ChenchenZhu,TianhengCheng,QijieZhao,BuyuLi,XinLu,RuiZhu,YueWu, manFactorsinComputingSystems(Seoul,RepublicofKorea)(CHI’15).As-
JifengDai,JingdongWang,JianpingShi,WanliOuyang,ChenChangeLoy,and sociationforComputingMachinery,NewYork,NY,USA,241–250. https:
DahuaLin.2019.MMDetection:OpenMMLabDetectionToolboxandBenchmark. //doi.org/10.1145/2702123.2702393
arXivpreprintarXiv:1906.07155(2019). [29] DhruvJain,RachelFranz,LeahFindlater,JacksonCannon,RajaKushalnagar,and
[7] Fu-JenChu,RuinianXu,LandanSeguin,andPatricioA.Vela.2019. Toward JonFroehlich.2018.TowardsAccessibleConversationsinaMobileContextfor
AffordanceDetectionandRankingonNovelObjectsforReal-WorldRobotic PeoplewhoareDeafandHardofHearing.InProceedingsofthe20thInternational
Manipulation. IEEERoboticsandAutomationLetters4,4(2019),4070–4077. ACMSIGACCESSConferenceonComputersandAccessibility(Galway,Ireland)
https://doi.org/10.1109/LRA.2019.2930364 (ASSETS’18).AssociationforComputingMachinery,NewYork,NY,USA,81–92.
[8] Fu-JenChu,RuinianXu,andPatricioA.Vela.2019.LearningAffordanceSegmen- https://doi.org/10.1145/3234695.3236362
tationforReal-WorldRoboticManipulationviaSyntheticImages.IEEERobotics [30] GlennJocher,AyushChaurasia,andJingQiu.2023. UltralyticsYOLO. https:
andAutomationLetters4,2(2019),1140–1147. https://doi.org/10.1109/LRA.2019. //github.com/ultralytics/ultralytics
2894439 [31] NabilaJones,HannahElizabethBartlett,andRichardCooke.2019.Ananalysis
[9] Ching-YaoChuang,JiamanLi,AntonioTorralba,andSanjaFidler.2018.Learning oftheimpactofvisualimpairmentonactivitiesofdailylivingandvision-related
toActProperly:PredictingandExplainingAffordancesfromImages.In2018 qualityoflifeinavisuallyimpairedadultpopulation.BritishJournalofVisual
IEEE/CVFConferenceonComputerVisionandPatternRecognition.975–983. https: Impairment37,1(2019),50–63.
//doi.org/10.1109/CVPR.2018.00108 [32] AvyayRaviKashyap.2020.Behaviors,Problemsandstrategiesofvisuallyim-
[10] AnneLesleyCornandJaneNErin.2010.Foundationsoflowvision:Clinicaland pairedpersonsduringmealpreparationintheIndiancontext:challengesand
functionalperspectives.AmericanFoundationfortheBlind. opportunitiesforDesign.InProceedingsofthe22ndInternationalACMSIGACCESS
[11] DimaDamen,HazelDoughty,GiovanniMariaFarinella,SanjaFidler,Antonino ConferenceonComputersandAccessibility.1–3.
Furnari,EvangelosKazakos,DavideMoltisanti,JonathanMunro,TobyPerrett, [33] MinyungKim,SooyoungHwang,KyoungminChoi,YoukeunOh,andDokshin
WillPrice,andMichaelWray.2018. ScalingEgocentricVision:TheEPIC- Lim.2022.Vision-BasedCookingAssistanceSystemforVisuallyImpairedPeople.
KITCHENSDataset.InProceedingsoftheEuropeanConferenceonComputer InInternationalConferenceonHuman-ComputerInteraction.Springer,540–547.
Vision(ECCV). [34] AlexanderKirillov,EricMintun,NikhilaRavi,HanziMao,ChloeRolland,Laura
[12] AshleyDDeemer,ChristopherKBradley,NicoleCRoss,DanielleMNatale, Gustafson,TeteXiao,SpencerWhitehead,AlexanderC.Berg,Wan-YenLo,Piotr
RathItthipanichpong,FrankSWerblin,andRobertWMassof.2018. Lowvi- Dollár,andRossGirshick.2023.SegmentAnything.arXiv:2304.02643(2023).
sionenhancementwithhead-mountedvideodisplaysystems:arewethereyet? [35] MiYoungKwon,ChaithanyaRamachandra,PremNandhiniSatgunam,BartlettW
OptometryandVisionScience95,9(2018),694–703. Mel,EliPeli,andBoscoSTjan.2012. Contourenhancementbenefitsolder
[13] JiaDeng,WeiDong,RichardSocher,Li-JiaLi,KaiLi,andLiFei-Fei.2009.Imagenet: adultswithsimulatedcentralfieldloss.Optometryandvisionscience89,9(2012),
Alarge-scalehierarchicalimagedatabase.In2009IEEEconferenceoncomputer 1374–1384.
visionandpatternrecognition.Ieee,248–255. [36] FlorianLangandTonjaMachulla.2021. PressingaButtonYouCannotSee:
[14] MREveringham,BTThomas,TTroscianko,etal.1999.Head-mountedmobility EvaluatingVisualDesignstoAssistPersonswithLowVisionthroughAugmented
aidforlowvisionusingsceneclassificationtechniques.TheInternationalJournal Reality.InProceedingsofthe27thACMSymposiumonVirtualRealitySoftwareand
ofVirtualReality3,4(1999),3. Technology(Osaka,Japan)(VRST’21).AssociationforComputingMachinery,New
[15] LeahFindlater,BonnieChinh,DhruvJain,JonFroehlich,RajaKushalnagar,and York,NY,USA,Article39,10pages. https://doi.org/10.1145/3489849.3489873
AngelaCareyLin.2019. DeafandHard-of-hearingIndividuals’Preferences [37] JaewookLee,DeveshP.Sarda,EujeanLee,AmyLee,JunWang,AdrianRo-
forWearableandMobileSoundAwarenessTechnologies.InProceedingsofthe driguez,andJonE.Froehlich.2023. TowardsReal-timeComputerVisionandUIST’24,October13–16,2024,Pittsburgh,PA,USA Lee,etal.
AugmentedRealitytoSupportLowVisionSports:ADemonstrationofARTennis. [57] AnhNguyen,DimitriosKanoulas,DarwinG.Caldwell,andNikosG.Tsagarakis.
InAdjunctProceedingsofthe36thAnnualACMSymposiumonUserInterface 2016. DetectingobjectaffordanceswithConvolutionalNeuralNetworks.In
SoftwareandTechnology(,SanFrancisco,CA,USA,)(UIST’23Adjunct).As- 2016IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems(IROS).
sociationforComputingMachinery,NewYork,NY,USA,Article81,3pages. 2765–2770. https://doi.org/10.1109/IROS.2016.7759429
https://doi.org/10.1145/3586182.3615815 [58] AnhNguyen,DimitriosKanoulas,DarwinG.Caldwell,andNikosG.Tsagarakis.
[38] FranklinMingzheLi,JamieDorst,PeterCederberg,andPatrickCarrington.2021. 2017.Object-basedaffordancesdetectionwithConvolutionalNeuralNetworks
Non-VisualCooking:ExploringPracticesandChallengesofMealPreparationby anddenseConditionalRandomFields.In2017IEEE/RSJInternationalConference
PeoplewithVisualImpairments.InProceedingsofthe23rdInternationalACM onIntelligentRobotsandSystems(IROS).5908–5915. https://doi.org/10.1109/
SIGACCESSConferenceonComputersandAccessibility(,VirtualEvent,USA,) IROS.2017.8206484
(ASSETS’21).AssociationforComputingMachinery,NewYork,NY,USA,Article [59] AlexOlwal,KevinBalke,DmitriiVotintcev,ThadStarner,PaulaConn,Bonnie
30,11pages. https://doi.org/10.1145/3441852.3471215 Chinh,andBenoitCorda.2020.WearableSubtitles:AugmentingSpokenCommu-
[39] FranklinMingzheLi,MichaelXieyangLiu,ShaunKKane,andPatrickCarrington. nicationwithLightweightEyewearforAll-dayCaptioning.InProceedingsofthe
2024.AContextualInquiryofPeoplewithVisionImpairmentsinCooking.arXiv 33rdAnnualACMSymposiumonUserInterfaceSoftwareandTechnology(Virtual
preprintarXiv:2402.15108(2024). Event,USA)(UIST’20).AssociationforComputingMachinery,NewYork,NY,
[40] Tsung-YiLin,MichaelMaire,SergeBelongie,JamesHays,PietroPerona,Deva USA,1108–1120. https://doi.org/10.1145/3379337.3415817
Ramanan,PiotrDollár,andCLawrenceZitnick.2014.Microsoftcoco:Common [60] EliPeli.2001.Visionmultiplexing:anengineeringapproachtovisionrehabilita-
objectsincontext.InComputerVision–ECCV2014:13thEuropeanConference, tiondevicedevelopment.OptometryandVisionScience78,5(2001),304–315.
Zurich,Switzerland,September6-12,2014,Proceedings,PartV13.Springer,740– [61] Yi-HaoPeng,Ming-WeiHsi,PaulTaele,Ting-YuLin,Po-EnLai,LeonHsu,
755. Tzu-chuanChen,Te-YenWu,Yu-AnChen,Hsien-HuiTang,andMikeY.Chen.
[41] ZeLiu,YutongLin,YueCao,HanHu,YixuanWei,ZhengZhang,StephenLin, 2018. SpeechBubbles:EnhancingCaptioningExperiencesforDeafandHard-
andBainingGuo.2021.Swintransformer:Hierarchicalvisiontransformerus- of-HearingPeopleinGroupConversations.InProceedingsofthe2018CHI
ingshiftedwindows.InProceedingsoftheIEEE/CVFinternationalconferenceon ConferenceonHumanFactorsinComputingSystems(,MontrealQC,Canada,)
computervision.10012–10022. (CHI’18).AssociationforComputingMachinery,NewYork,NY,USA,1–10.
[42] DavidSLoshinandRichardDJuday.1989.Theprogrammableremapper:clinical https://doi.org/10.1145/3173574.3173867
applicationsforpatientswithfielddefects.OptometryandVisionScience66,6 [62] KyleRector,LaurenMilne,RichardELadner,BatyaFriedman,andJulieAKientz.
(1989),389–395. 2015.Exploringtheopportunitiesandchallengeswithexercisetechnologiesfor
[43] TimoLuddeckeandFlorentinWorgotter.2017.Learningtosegmentaffordances. peoplewhoareblindorlow-vision.InProceedingsofthe17thinternationalACM
InProceedingsoftheIEEEInternationalConferenceonComputerVisionWorkshops. SIGACCESSconferenceoncomputers&accessibility.203–214.
769–776. [63] GwendolynRehrig,MadisonBarker,CandaceEPeacock,TaylorRHayes,JohnM
[44] GangLuoandEliPeli.2006.Useofanaugmented-visiondeviceforvisualsearch Henderson,andFernandaFerreira.2022. LookatwhatIcando:Objectaffor-
bypatientswithtunnelvision.Investigativeophthalmology&visualscience47,9 dancesguidevisualattentionwhilespeakersdescribepotentialactions.Attention,
(2006),4152–4159. Perception,&Psychophysics84,5(2022),1583–1610.
[45] HongchenLuo,WeiZhai,JingZhang,YangCao,andDachengTao.2022.Learning [64] JarekReynolds,ChandraKanthNagesh,andDannaGurari.2024.Salientobject
AffordanceGroundingfromExocentricImages.InCVPR. detectionforimagestakenbypeoplewithvisionimpairments.InProceedingsof
[46] ChengqiLyu,WenweiZhang,HaianHuang,YueZhou,YudongWang,YanyiLiu, theIEEE/CVFWinterConferenceonApplicationsofComputerVision.8522–8531.
ShilongZhang,andKaiChen.2022.RTMDet:AnEmpiricalStudyofDesigning [65] ChrisSchipperandBoBrinkman.2017.CaptionPlacementonanAugmented
Real-TimeObjectDetectors. arXiv:2212.07784[cs.CV] RealityHeadWornDevice.InProceedingsofthe19thInternationalACMSIGAC-
[47] MeethuMaluandLeahFindlater.2014."OKGlass?"APreliminaryExplorationof CESSConferenceonComputersandAccessibility(Baltimore,Maryland,USA)(AS-
GoogleGlassforPersonswithUpperBodyMotorImpairments.InProceedingsof SETS’17).AssociationforComputingMachinery,NewYork,NY,USA,365–366.
the16thInternationalACMSIGACCESSConferenceonComputers&Accessibility https://doi.org/10.1145/3132525.3134786
(Rochester,NewYork,USA)(ASSETS’14).AssociationforComputingMachinery, [66] LeeStearns,VictorDeSouza,JessicaYin,LeahFindlater,andJonE.Froehlich.
NewYork,NY,USA,267–268. https://doi.org/10.1145/2661334.2661400 2017.AugmentedRealityMagnificationforLowVisionUserswiththeMicrosoft
[48] MeethuMaluandLeahFindlater.2015.Personalized,WearableControlofaHead- HololensandaFinger-WornCamera.InProceedingsofthe19thInternationalACM
mountedDisplayforUserswithUpperBodyMotorImpairments.InProceedings SIGACCESSConferenceonComputersandAccessibility(Baltimore,Maryland,
ofthe33rdAnnualACMConferenceonHumanFactorsinComputingSystems USA)(ASSETS’17).AssociationforComputingMachinery,NewYork,NY,USA,
(Seoul,RepublicofKorea)(CHI’15).AssociationforComputingMachinery,New 361–362. https://doi.org/10.1145/3132525.3134812
York,NY,USA,221–230. https://doi.org/10.1145/2702123.2702188 [67] Stereolabs.2024.zed-unity.https://github.com/stereolabs/zed-unity.
[49] RobertWMassofandDouglasLRickman.1992.Obstaclesencounteredinthe [68] SaritSzpiro,YuhangZhao,andShiriAzenkot.2016.Findingastore,searchingfor
developmentofthelowvisionenhancementsystem.Optometryandvisionscience aproduct:astudyofdailychallengesoflowvisionpeople.InProceedingsofthe
69,1(1992),32–41. 2016ACMInternationalJointConferenceonPervasiveandUbiquitousComputing
[50] RobertWMassof,DouglasLRickman,PeterALalle,etal.1994. Lowvision (Heidelberg,Germany)(UbiComp’16).AssociationforComputingMachinery,
enhancementsystem.JohnsHopkinsAPLTechnicalDigest15,2(1994),120–125. NewYork,NY,USA,61–72. https://doi.org/10.1145/2971648.2971723
[51] RoisinMcNaney,JohnVines,DanielRoggen,MadelineBalaam,PengfeiZhang, [69] SaritFeliciaAnaisSzpiro,ShafekaHashash,YuhangZhao,andShiriAzenkot.
IvanPoliakov,andPatrickOlivier.2014.Exploringtheacceptabilityofgoogle 2016.HowPeoplewithLowVisionAccessComputingDevices:Understanding
glassasaneverydayassistivedeviceforpeoplewithparkinson’s.InProceedingsof ChallengesandOpportunities.InProceedingsofthe18thInternationalACM
theSIGCHIConferenceonHumanFactorsinComputingSystems(Toronto,Ontario, SIGACCESSConferenceonComputersandAccessibility(Reno,Nevada,USA)
Canada)(CHI’14).AssociationforComputingMachinery,NewYork,NY,USA, (ASSETS’16).AssociationforComputingMachinery,NewYork,NY,USA,171–180.
2551–2554. https://doi.org/10.1145/2556288.2557092 https://doi.org/10.1145/2982142.2982168
[52] AshleyMiller,JoanMalasig,BrendaCastro,VickiL.Hanson,HugoNicolau,and [70] DeannaJTaylor,AngharadEHobby,AlisonMBinns,andDavidPCrabb.2016.
AlessandraBrandão.2017.TheUseofSmartGlassesforLectureComprehension Howdoesage-relatedmaculardegenerationaffectreal-worldvisualabilityand
byDeafandHardofHearingStudents.InProceedingsofthe2017CHIConference qualityoflife?Asystematicreview.BMJopen6,12(2016),e011504.
ExtendedAbstractsonHumanFactorsinComputingSystems(,Denver,Colorado, [71] JanTünnermann,NorbertKrüger,BärbelMertsching,andWailMustafa.2015.Af-
USA,)(CHIEA’17).AssociationforComputingMachinery,NewYork,NY,USA, fordanceestimationenhancesartificialvisualattention:Evidencefromachange-
1909–1915. https://doi.org/10.1145/3027063.3053117 blindnessstudy.Cognitivecomputation7(2015),526–538.
[53] SusannaMills,MartinWhite,HeatherBrown,WendyWrieden,DominikaKwas- [72] JoramJvanRheede,IainRWilson,RoseIQian,SusanMDownes,Christopher
nicka,JoelHalligan,ShannonRobalino,andJeanAdams.2017. Healthand Kennard,andStephenLHicks.2015.Improvingmobilityperformanceinlow
socialdeterminantsandoutcomesofhomecooking:Asystematicreviewof visionwithadistance-basedrepresentationofthevisualscene. Investigative
observationalstudies.Appetite111(2017),116–134. ophthalmology&visualscience56,8(2015),4802–4809.
[54] KenzaburoMiyawaki,MutsuoSano,SyunichiYonemura,andMichikoOde.2012. [73] RuWang,NihanZhou,TamNguyen,SanbritaMondal,BilgeMutlu,andYuhang
Cookingrehabilitationsupportforself-relianceofcognitivedysfunctionpatients. Zhao.2023.CharacterizingBarriersandTechnologyNeedsintheKitchenfor
InProceedingsoftheACMmultimedia2012workshoponMultimediaforcooking BlindandLowVisionPeople.arXivpreprintarXiv:2310.05396(2023).
andeatingactivities.19–24. [74] RuWang,NihanZhou,TamNguyen,SanbritaMondal,BilgeMutlu,andYuhang
[55] PilarMontero.2005.Nutritionalassessmentanddietqualityofvisuallyimpaired Zhao.2023.PracticesandBarriersofCookingTrainingforBlindandLowVision
Spanishchildren.AnnalsofHumanBiology32,4(2005),498–512. People.InProceedingsofthe25thInternationalACMSIGACCESSConferenceon
[56] ElizabethDMynattandWendyARogers.2001. Developingtechnologyto ComputersandAccessibility(,NewYork,NY,USA,)(ASSETS’23).Association
supportthefunctionalindependenceofolderadults.AgeingInternational27,1 forComputingMachinery,NewYork,NY,USA,Article57,5pages. https:
(2001),24–41. //doi.org/10.1145/3597638.3614494CookAR:AffordanceAugmentationsinWearableARtoSupportKitchenToolInteractionsforPeoplewithLowVision UIST’24,October13–16,2024,Pittsburgh,PA,USA
[75] PeterWashington,CatalinVoss,AaronKline,NickHaber,JenaDaniels,Azar [79] YuhangZhao,ElizabethKupferstein,HathaitornRojnirun,LeahFindlater,and
Fazel,TitasDe,CarlFeinstein,TerryWinograd,andDennisWall.2017.Super- ShiriAzenkot.2020.TheEffectivenessofVisualandAudioWayfindingGuidance
powerGlass:AWearableAidfortheAt-HomeTherapyofChildrenwithAutism. onSmartglassesforPeoplewithLowVision.InProceedingsofthe2020CHI
Proc.ACMInteract.Mob.WearableUbiquitousTechnol.1,3,Article112(sep2017), ConferenceonHumanFactorsinComputingSystems(,Honolulu,HI,USA,)(CHI
22pages. https://doi.org/10.1145/3130977 ’20).AssociationforComputingMachinery,NewYork,NY,USA,1–14. https:
[76] KristinWilliams,KarynMoffatt,DeniseMcCall,andLeahFindlater.2015.Design- //doi.org/10.1145/3313831.3376516
ingConversationCuesonaHead-WornDisplaytoSupportPersonswithAphasia. [80] YuhangZhao,ElizabethKupferstein,DoronTal,andShiriAzenkot.2018. "It
InProceedingsofthe33rdAnnualACMConferenceonHumanFactorsinComputing LooksBeautifulbutScary"HowLowVisionPeopleNavigateStairsandOther
Systems(Seoul,RepublicofKorea)(CHI’15).AssociationforComputingMachin- SurfaceLevelChanges.InProceedingsofthe20thInternationalACMSIGACCESS
ery,NewYork,NY,USA,231–240. https://doi.org/10.1145/2702123.2702484 ConferenceonComputersandAccessibility.307–320.
[77] YuhangZhao,MicheleHu,ShafekaHashash,andShiriAzenkot.2017.Understand- [81] YuhangZhao,SaritSzpiro,andShiriAzenkot.2015.Foresee:Acustomizablehead-
ingLowVisionPeople’sVisualPerceptiononCommercialAugmentedReality mountedvisionenhancementsystemforpeoplewithlowvision.InProceedings
Glasses.InProceedingsofthe2017CHIConferenceonHumanFactorsinComputing ofthe17thinternationalACMSIGACCESSconferenceoncomputers&accessibility.
Systems(Denver,Colorado,USA)(CHI’17).AssociationforComputingMachin- 239–249.
ery,NewYork,NY,USA,4170–4181. https://doi.org/10.1145/3025453.3025949 [82] YuhangZhao,SaritSzpiro,JonathanKnighten,andShiriAzenkot.2016.CueSee:
[78] YuhangZhao,ElizabethKupferstein,BrendaVeronicaCastro,StevenFeiner,and exploringvisualcuesforpeoplewithlowvisiontofacilitateavisualsearchtask.
ShiriAzenkot.2019.DesigningARVisualizationstoFacilitateStairNavigation InProceedingsofthe2016ACMInternationalJointConferenceonPervasiveand
forPeoplewithLowVision.InProceedingsofthe32ndAnnualACMSymposium UbiquitousComputing(Heidelberg,Germany)(UbiComp’16).Associationfor
onUserInterfaceSoftwareandTechnology(NewOrleans,LA,USA)(UIST’19). ComputingMachinery,NewYork,NY,USA,73–84. https://doi.org/10.1145/
AssociationforComputingMachinery,NewYork,NY,USA,387–402. https: 2971648.2971730
//doi.org/10.1145/3332165.3347906