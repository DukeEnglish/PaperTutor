1
From Human-to-Human to Human-to-Bot
Conversations in Software Engineering
Ranim Khojah, Francisco Gomes de Oliveira Neto, Philipp Leitner
Chalmers | University of Gothenburg
Gothenburg, Sweden
khojah@chalmers.se, francisco.gomes@cse.gu.se, philipp.leitner@chalmers.se
Abstract—Softwaredevelopersusenaturallanguagetointeract by Clark et al. [3], we discuss differences in purpose, un-
notonlywithotherhumans,butincreasinglyalsowithchatbots. derstanding, trustworthiness, listening, and use of humour. A
These interactions have different properties and flow differently
particular focus of our work is LLM-based chatbots, and their
based on what goal the developer wants to achieve and who
place in modern software development processes.
they interact with. In this paper, we aim to understand the
dynamics of conversations that occur during modern software Our discussion aims to assist software engineers in cali-
development after the integration of AI and chatbots, enabling brating their expectations when engaging with different con-
a deeper recognition of the advantages and disadvantages of versational partners, be they other humans or various types of
includingchatbotinteractionsinadditiontohumanconversations
chatbots. By understanding the dynamics of these interactions
incollaborativework.Wecompileexistingconversationattributes
practitionerscanbetterrecognizethepotentialgainsandlosses
with humans and NLU-based chatbots and adapt them to the
contextofsoftwaredevelopment.Then,weextendthecomparison of collaborative work when substituting human dialogue with
to include LLM-powered chatbots based on an observational chatbot interactions, particularly in the realms of knowledge
study.Wepresentsimilaritiesanddifferencesbetweenhuman-to- sharing.
human and human-to-bot conversations, also distinguishing be-
tween NLU- and LLM-based chatbots. Furthermore, we discuss
howunderstandingthedifferencesamongtheconversationstyles
II. ARESEARCHVIEWONBOTSINSOFTWARE
guides the developer on how to shape their expectations from a DEVELOPMENT
conversationandconsequentlysupportthecommunicationwithin Bots in software development (DevBots) have become
asoftwareteam.Weconcludethattherecentconversationstyles
common tools that play a big role in improving developers’
thatweobservewithLLM-chatbotscannotreplaceconversations
with humans due to certain attributes regarding social aspects productivity and communication throughout the development
despite their ability to support productivity and decrease the process. With the constant emergence of new DevBots each
developers’ mental load. day, research was first focused on understanding the role of
Index Terms—Conversational agents, Software development, bots. Erlenhov et al. [4] focus on the DevBots roles and
Dialogue characteristics introduce a taxonomy to classify DevBots according to their
functionalities and how they contribute to enhancing software
developmentprocesses.WhileWesseletal.[5]furtherexplore
I. INTRODUCTION
the use cases of DevBots in open-source software and found
In software development, discussions and conversations
that they are mostly used for automation purposes. Among
within a team play an important role in communicating
the various types of DevBots, chatbots have drawn more
progressandresolvingissues.Theseconversationsarenotonly
attention due to their ability to communicate with developers
between humans — in modern software projects, developers
throughnaturallanguage,expandingthespectrumoftasksthat
also interact with chatbots through conversational interfaces,
DevBots can assist with.
and increasingly also with powerful generative AI models,
Earlier chatbots were powered by natural language under-
such as Large Language Models (LLMs). LLMs in particular
standing (NLU) to automate repetitive and simple tasks. For
can be seen as a hype topic, with multiple recent studies
example, MSRBot [6] that answers questions related to a
investigating their usage in software development [1], [2]. software repository, and Stack Overflow Bot1 has been used
Intuitively, despite using the same interface (natural lan-
to retrieve relevant information from Stack Overflow. NLU-
guage), conversations with chatbots and LLMs follow dif-
based chatbots operate by predicting the user’s intention and
ferent rules and have different purposes and constraints than
then mapping it to a corresponding response in the chatbot’s
conversations with fellow humans. So far, these differences
database. Therefore, the possible use cases of such chatbots
are ill-understood, with developers either anthropomorphizing
are limited to the database and training data.
interactionswithsmartprogrammingtools,orunderusingtheir
More recently, Large Language Models (LLMs) introduced
capabilities.
agenerativeaspecttochatbots,makingitpossibleforchatbots
In this article, we provide a structured comparison of con-
to generate responses to queries it was not trained on. This
versationsbetween:(i)humans,(ii)humansandchatbotsbased
revealed more possible use cases that can be more complex
on natural language understanding (NLU), and (iii) humans
and LLM-based chatbots. Following a comparison taxonomy 1https://aka.ms/stackoverflow-bot-sample
4202
yaM
12
]ES.sc[
1v21721.5042:viXra2
due to their need to understand, synthesize, and create arti- each participant sent us their chat logs and filled out an exit
facts. For example, GitHub Copilot2 generates code given the survey.
user’s specifications and the context of the project. The use We qualitatively analyzed 180 dialogues that consist of
cases were not confined to code generation but also testing, 580 prompts regarding the nature and purpose of interactions,
requirement analysis, and other activities. dialogue types, flow of conversation, and other attributes
To evaluate the effectiveness of chatbots and how they can usinginterpretativephenomenologicalanalysis[11]whichisa
support software engineers, current research focuses on the researchmethodthatallowedustocapturepatternsinpersonal
quality [3], usability [7], and helpfulness [8] of the chatbot’s experiences and better understand the characteristics of the
outcome.Nevertheless,welackaholisticunderstandingofthe dialogues.
experience and the flow of the conversation between software In addition, the exit survey provided valuable insights into
engineers and chatbots. subjective assessments of productivity with ChatGPT, as well
as for which purposes the chatbot was perceived as useful.
In short, this article combines our findings from this earlier
III. ANOBSERVATIONALSTUDY
study with established knowledge on human-to-human and
The reflections and insights of this paper are based on a
human-to-chatbot interactions [3], in order to provide context
dataset and findings from our previous work [9]. The study
for how interactions with LLMs differ from conversations
aimed to understand how software engineers use ChatGPT in
between humans on the one hand, and conversations between
their workplace in real-world settings. Particularly, the previ-
humans and traditional NLU-based chatbots on the other.
ous paper analyzed the user experience of ChatGPT, focusing
on practitioners’ goals when interacting with ChatGPT and
IV. EXAMPLESOFCONVERSATIONSINSOFTWARE
the helpfulness of dialogue outcomes. In contrast, this study
ENGINEERING
distinguishes the different ways conversations occur between
humans, as well as between humans and various types of In this article, we particularly contrast three flavors of
bots, using data from previous work to particularly highlight software engineering conversations — conversations between
contrasts in human and LLM-based chatbot interactions. humans, between humans and more well-established NLU-
To collect the data for this study, we reached out to based chatbots (henceforth called NLU-chatbots) such as
practitioners in different software organizations that allow the GitHubbotonSlack3,and,morerecently,withLLM-powered
use of ChatGPT in their workplaces. In total, 24 software chatbots such as ChatGPT4 and Bard5. Depending on the
engineersfrom10softwareorganizationsofdifferentsizesand agents involved, conversations can have different purposes
domains registered to participate in our study (See Table I). and happen during planning and syncing, pair programming,
The data is available in Zenodo [10] and includes information requesting assistance, or just chit-chatting.
about the purpose of each prompt from participants and how Let us consider an example: Alex (a junior software de-
the prompts support various Software Engineering tasks such veloper) recently joined a development team that follows an
as coding, testing, and design. However, we cannot share Agile process and commits daily to GitHub. The team works
the chat files or the open-ended survey responses, as they with authentication and uses Java, which Alex is not fully
mightcompromiseparticipantanonymityorcontaincompany- experienced in, but she knows that colleagues such as Kevin
specific information. (a senior Java developer), can help her when needed. Alex
faces a problem where she needs to handle the response from
TABLE I: Information about how the participants are dis- an authenticator service if it returns an error.
tributed across different organizations of different sizes and Figure 1 illustrates three possible conversations with three
domains. We refer to each organization with an ID, and the different types of agents. In the first conversation, Alex seeks
sizesusedareStartups,SmallandMediumenterprises(SME), help from her colleague, Kevin, via the company Slack. In
and Large enterprises. the conversation, Alex’s first task is to establish a mutual
understandingandvalidatethatKevinistherightcolleagueto
Org.ID Org.Size Domain #Participants
ask before proceeding to ask for help. As a response, Kevin
A SME Testing 3 explains the basic idea Alex can follow to solve the problem,
B SME E-learning 3
without necessarily providing complete solutions (as a tool
C Startup Medical 4
D Startup Gaming 1 suchasChatGPTwould).However,Kevinisunlikelytoinvent
E Startup Gaming 1 an entirely irrelevant solution, and Alex will generally have
F Large E-commerce 1
high trust in the correctness of Kevin’s answer. Additionally,
G Large Automotive 7
H Large Consultancy 1 thisinteraction mayhavesocial benefitsforthe team,increas-
I SME Consultancy 2 ing rapport between Kevin and his new colleague.
J Large Automotive 1
In the second conversation, Alex uses a traditional chatbot,
such as GitHub Bot, to help with her issue. Despite also
The participants actively used ChatGPT for a week during
supporting a conversational interface, such tools provide a
their normal work, that is, to perform tasks that are relevant
to their role in software engineering. At the end of the week, 3https://slack.github.com
4https://chat.openai.com/
2http://copilot.github.com 5https://bard.google.com3
Kevin (Software Developer) GitHub Bot (NLU-based Chatbot) ChatGPT (LLM-based Chatbot)
As a software developer,
Hey Kevin, have you been involved Handle the error from the response.
Show the latest open issue
in the authorization part? [code provided]
The provided code is implementing
Latest issue opened by @Alex OAuth 2.0 authorization code flow
Yes, I worked on it last week. for obtaining an authorization code.
Issue #4: Vulnerability in the Here is code for handling the
authorization authentication error:
Authentication error response not
Do you know how to check if there handled properly.
is an error in the response?
Add a comment "@Kevin can you Throw an exception with the
You can simply check if the help out with checking an error in message "authentication failed"
response is an instance of type the response?"
AuthenticationErrorResponse Here's how you can modify the
code to include an exception:
Comment posted to Issue #4
Alright, thanks!
Do not forget to declare the
exception in the method signature
using the throws clause.
Fig. 1: Three example conversations between a software developer and a fellow software developer (left), an NLU-based
chatbot (middle), and an LLM-based chatbot (right).
muchnarrowerrangeofsupportincomparisontoeitherasking V. ACOMPARISONOFCONVERSATIONS
a colleague or using an LLM-based tool. Hence, Alex is not We use the framework first described by Clark et al. [3]
able to directly ask for a solution to her problem. However, to compare and contrast the three styles of conversations
she can use the chatbot to retrieve relevant information or summarized in Table II. This framework entails attributes of
post new entries e.g., on the project issue tracker. Alex’s trust conversations between humans and traditional chatbots. We
in the retrieved information will generally be high, but if the focus on the following attributes: (i) purpose refers to the
chatbotdoesnotsupportherspecificrequestsheisoutofluck. reason the conversation happens; (ii) understanding of scope
Further, in comparison to the other types of conversations, as the ability to comprehend the context of a conversation;
Alex will need to be comparatively formulaic in her request, (iii) listening - comprehending the content of a conversation;
as the chatbot’s capabilities to parse natural language will be (iv)trustworthinessastheabilitytoprovidereliableoutcomes;
limited in comparison to the other options. and (v) the use of humour by lightening the conversation and
Inthethirdconversation,AlexusesChatGPTasitishighly making it more amusing.
accessible and readily available (unlike, for example, Kevin,
who may be unavailable for a conversation). Alex starts by A. Purpose of interaction
providing context to her question. In comparison to the first
conversation, Alex needs to be much more deliberate about The purpose is the outcome that one expects from a
whichcontexttoprovideandinwhichform.ChatGPTthenex- conversationthathelpsachieveabiggergoal.Usingour
plainsthecodeprovidedandproposesasolution.Alexisable exampleinFigure1,weexplainthedifferentpurposes.
to ask follow-up questions and build on the previous solution,
muchlikeaconversationwithanotherhuman.However,unlike
Conversations among human developers can have social
conversingwithahuman,Alexneedstoconsiderwhatcontext
or more goal-oriented purposes. While sometimes developers
to provide and how to frame her question (often referred
may ask others to outright perform a task (e.g., delegation),
to as prompt engineering), and she needs to carefully check
many conversations are arguably targeted at receiving infor-
the correctness of the provided solution to identify possible
mationortraining[3].Thisisillustratedinourexamplewhen
hallucinations.Nevertheless,ChatGPTwill(ideally)providea
Alex asks Kevin how to check for an error to get the needed
working code, which Alex can use or adapt quickly.
information and guidance to complete the error-checking task
It is evident that, despite all three scenarios involving Alex ratherthanaskhimforthecompletesyntax.Itshouldbenoted
”chatting” via natural language, the actual context as well as that there is often a social benefit to the conversation, even if
thestyleofconversation(andwhatAlexcanexpecttogetout the conversation’s original purpose is a more technical one.
of it) varies dramatically. In the following, we explore these On the other hand, conversations with NLU-based chatbots
differences more systematically. are limited to delegating or performing a set of tasks (usually4
TABLE II: Summary of the conversation attributes between software developers and (i) other developers, (ii) NLU-based
chatbots and (iii) LLM-based chatbots
HumanSoftwareDevelopers NLU-basedChatbots LLM-basedChatbots
Purpose Social,generalguidance,training Basic information retrieval, simple au- Generalguidance,training,artifactgen-
tomation erationandmanipulation
UnderstandingofScope Mutualunderstanding Fixedcustomization Dynamiccustomization
Listening Bodylanguage(Active)andknowledge Acknowledgement (Active) and intent Query summary (Active) and knowl-
(Accurate) classification(Accurate) edge(Accurate)
Trustworthiness Shared experiences and previous inter- Performanceandefficiency Meetingexpectationsandtransparency
actions
UseofHumour Common Notapplicable On-demand
straightforward automation tasks) and general information the context of the project Alex works on. Therefore, when
retrieval. More personalized guidance and training are not Alexaskstoshowthelatestissue,itdisplaystheissueforher
possible in many development-related NLU-chatbots. In the project. Technical personalization takes the place of a socially
example conversation with GitHub bot, Alex tries to achieve constructed common ground.
her goal of getting a solution by utilizing the limited queries While LLM-chatbots can be customized during design or
that she can use to interact with GitHub bot, so she asks the deployment, they also provide the option for customization
bot to assign the open issue to Kevin. during the interaction, e.g., through prompt engineering. De-
LLM-based chatbots support a much wider range of pur- velopers provide a context or a perspective that the LLM-
poses. Our data reveals that developers ask ChatGPT general chatbot should consider. In our data, 62 prompts (34%) in-
questions (123, or 68%, of interactions), but also saw them cludedcontextualinformationsuchasdomain-specificknowl-
usetheLLMtogenerateormanipulateconcretecodeartifacts edge, production code, etc. In our example, Alex steers the
(32%).IntheconversationbetweenAlexandChatGPT,Alex’s conversation toward getting development-related assistance
main goal is to handle an error from the HTTP response in whenaskingChatGPTtotaketheroleofasoftwaredeveloper.
her Java code. To achieve this goal, she has three options as Alex also provides a context (that is, her code) on which she
purposes of the conversation: She can get some training from expects the rest of the conversation to be based.
ChatGPT to learn about error handling and HTTP responses
in Java, she can get general information on how to solve her
C. Listening
problem and what logic to follow (similar to what a human
colleague would likely provide), or she can ask for artifact
Listening is the act of actively receiving and interpret-
manipulation and get the specific code solution. Alex decides
ing the data shared within a conversation. The data
to go with the third option as it makes her reach her goal
include underlying intention, information shared, and
faster.
similar.
B. Understanding of Scope There are two aspects of listening: active listening and
accurate listening. In active listening, the listener focuses
Individuals use some information, i.e. the scope, as a on receiving the information shared, while accurate listening
foundation of a conversation that ensures that it flows concerns interpreting the information correctly. While both
towardstheintendedpurpose.Theinformationcantake aspects are needed in a conversation, they are expressed
the form of assumptions or be explicitly shared in the differently in different conversations.
conversation that the conversation is to be built on. Active listening is needed in a software organization and
is applied in common activities such as daily stand-ups.
Conversations with human developers are built on mutual When one developer verbalizes their progress to other fellow
understanding. Before Alex asks Kevin for help, she makes developerswhoshowengagement throughbodylanguageand
sure he is familiar with the code on which the question is maintainingeyecontact,evenifasolutioncannotbeprovided,
based. Since Kevin made it clear that he had seen the code, active listening helps developers organize their thoughts. On
a common ground is established and the conversation carries the other hand, accurate listening requires the developer to be
on. Note that Alex does not need to share more information familiarwiththediscussedqueryandhaveenoughknowledge
regarding the project (e.g., programming language, or project and expertise to interpret the query, which is why Alex chose
dependencies) since she assumes that Kevin knows it already to ask Kevin who is a Java expert.
given that they work in the same team. However, instead of For NLU-chatbots, active listening is present in acknowl-
mutual understanding, NLU-chatbots are customized during edgments of the developers’ query (GitHub bot posts the
the design phase to hold conversations that align with the comment and acknowledges it to Alex), whereas accurate
user’s preferences, history, and specific context. The NLU- listening is controlled by the NLU component of the chat-
chatbot that Alex uses (i.e., GitHub bot) is customized to bot. When the NLU accurately performs intent classification5
(predicts the user’s intention) and entity extractions (extracts smart it sounds when generating a response, ended up losing
relevant information), it decreases the occurrences of in- trust when ChatGPT hallucinates, whereas developers with
tent misclassification and unnecessary clarification questions, more modest expectations often found themselves positively
hence, maintaining a good conversation flow. For example, surprised [9]. In their exit surveys, 8 practitioners (33%)
the conversation between Alex and GitHub bot is short and stated having little to no trust in ChatGPT’s answers, whereas
effectivesinceGitHubbotcouldunderstandAlex’sintent(i.e., the remainder reported trusting ChatGPT’s answer (between
adding a comment) and the correct entities (e.g., issue #4). moderateandsometrust).Anotherexpectationistransparency,
Accurate listening also applies to LLM-chatbots, but un- developers expect ChatGPT to communicate its level of con-
like NLU-chatbots, they do not focus on understanding the fidence in the answer it provides (a goal that ChatGPT rarely
intent and entities rather than using the wide knowledge that meets,asthetoolisreputedforbeingoverconfident)andhope
it was trained on and the transformer architecture [12] to to see a source of the shared information (which ChatGPT,
understand the language structures, syntax, and contextual again, cannot deliver accurately). Hence, developers have
connectionsinthepromptandgenerateacontextually-relevant good reasons to have lower trust in LLM-chatbots than in
response. Another feature of modern LLM-based chatbots the alternatives, requiring them to carefully cross-check the
is their application of active listening where they convey outcome of interactions.
their understanding and then respond. In fact, 30 prompts Particularly in the LLM context, a second trust angle is re-
(16%) distributed among 12 participants offered feedback to latedtoprivacy.WherebothhumansaswellasNLU-chatbots
ChatGPT on whether its recommendations were meeting their are generally considered unproblematic in a privacy sense,
expectations, i.e., whether they felt like ChatGPT actively many privacy challenges have recently been raised towards
listened to them. While the percentage of prompts was low, tools such as ChatGPT. Lack of clarity on what commercial
that was done by half of our participants which, we argue, LLMs do with proprietary information and artifacts that get
indicates a similar pattern to conversations between humans. passed as context is a critical issue that is right now still
When Alex asked ChatGPT to handle the error and provided hampering their more widespread adoption in industry.
her code, ChatGPT started explaining how it interpreted the
code in terms of its functionality and then provided the code E. Humour
solution.
Humour refers to the ability to add lightness or en-
joyment in a dialogue making it more memorable and
D. Trustworthiness
enhancing engagement between the parties.
Trustistheconfidencethattheresultwillbebeneficial,
which enables the conversation to begin and continue. Humour is a quality that is mostly acceptable from humans
in specific scenarios. It serves social purposes to soften the
seriousness of some topics in a conversation. Even in a
Trust in human developers is built through time, by ac-
technical conversation, humour can be used by Kevin to
cumulating information and experiences about the developer,
establish rapport and help Alex digest difficult information.
throughinteractionsandsharedmoments.Theinteractionscan
Recent work in software engineering has shown how humour
be during team discussions, pair programming sessions, or
makes developers more engaged in their tasks and even helps
personal consultations. Alex trusts Kevin enough to ask him
understand complex programming tasks [14].
since she knows that he always welcomes her questions and
Neither NLU-based nor LLM-based chatbots effectively
she knows that he is knowledgeable in the area she needs
make use of humour the way an emphatic human would, and
helpinandcanprovideusefuladviceandguidance.Alexalso
if these tools employ humour it is sometimes perceived as
trusts Kevin’s answers when he says that he worked on the
offputting. However, LLM-based chatbots are able to reply
code, which supports the flow of the conversation and allows
withacertainsenseofhumour(butneedtobeexplicitlyasked
Alex to move to discuss her problem.
to do so).
When it comes to tools, trust also needs to be established
similarly [13]. While the outcome of conversations with hu-
VI. DISCUSSION
mans can be influenced by unpredictable factors (such as the
Next, we summarise the differences between the different
time and person’s mood), tool performance tends to be more
types of conversations described above while discussing the
consistent. NLU-chatbots are trusted when they can perform
main implications and lessons learned from our study.
theirtasksaccurately,forinstance,displayingthecorrectissue
requestedbyAlex.DeveloperstrustNLU-chatbotswhenusing
them to automate tasks and retrieve information becomes A. Developers should adapt their expectations based on who
useful and efficient. The reputation of the tool’s maker also they converse with
plays a relevant role in establishing trust. Forexample,whenconversingwithhumandevelopers,they
For LLM-chatbots, accuracy is hard to measure, especially can expect in-depth conversations that can involve emotions
for complex queries. Instead, developers trust chatbots that orhumor,andrelyonsharedunderstandingandcollaboration.
meettheirexpectations.Inourobservationalstudy,developers While conversations with NLU-based chatbots may prioritize
who expected ChatGPT to be impeccable judging from how concise answers and accurate task automation over providing6
complete and elaborate answers. In LLM-based chatbots, be mitigated by involving other communication styles where
developersshouldunderstandthatwhiletherearemanyfactors trustworthiness criteria are available, for example, with NLU-
thataffecttheoutcomeoftheLLM-chatbots(e.g.,thetraining chatbots providing a confidence estimation or with human
data and architecture of the LLM), it is very sensitive to developers with previous trustworthy reputations. Hence, dif-
prompts.Promptscaneitheryieldunintendedresultsincaseof ferent conversation styles can be combined to mitigate the
ambiguity or enable utilizing most of LLM capabilities (e.g., limitations of individual ones and amplify their advantages.
completeanswerstocomplexqueries)whenconstructedbased
onrecommendedprompttechniques.Webelievethatadjusting VII. CONCLUDINGREMARKS
such expectations is one step towards having more productive
LLM-based chatbots are here to stay in software develop-
interactions within a software team.
ment organizations. With their human-like ability to inform,
generate,andcreate,combinedwiththealways-onavailability
B. Trustworthiness is the attribute that mainly determines the of an IT service, they fill a complementary niche that neither
flow of a conversation pre-existing NLU-based chatbots nor human colleagues can
fill. However, we argue that LLM-based chatbots are not
Trustworthiness impacts the usefulness of the conversa-
directly replacing human co-workers, nor should they — the
tions [3]. By controlling the type and amount of information
social aspect of human interactions cannot be filled even by
that can be shared within a conversation, it determines how
themostadvancedbot.Instead,LLM-basedchatbotsshouldbe
the outcome of the conversation will be implemented by
seen as a new and powerful form of generic productivity tool,
the developer. For instance, when seeking guidance from a
which can be used effectively to decrease the ever-growing
trusted colleague, a developer can confidently implement the
mental load [18] placed on modern developers.
recommendations received, knowing they are reliable. While
conversing with LLMs that are known to generate erroneous
ACKNOWLEDGMENT
or irrelevant information, as in the case of hallucination, can
lead the developer to only use the outcome as a source of This work was partially supported by the Wallenberg AI,
inspiration without letting it be a guide for decision-making. Autonomous Systems and Software Program (WASP) funded
by the Knut and Alice Wallenberg Foundation.
C. LLM-based chatbots enable software developers to have
REFERENCES
more human-like conversations, but with bot-alike efficiency
[1] S. I. Ross, F. Martinez, S. Houde, M. Muller, and J. D. Weisz,
LLM-based chatbots allow software developers to engage
“The programmer’s assistant: Conversational interaction with a large
in conversations that have similar attributes to conversations languagemodelforsoftwaredevelopment,”inProceedingsofthe28th
with humans, such as the ability to express their knowledge InternationalConferenceonIntelligentUserInterfaces,IUI’23,(New
York, NY, USA), p. 491–514, Association for Computing Machinery,
and provide guidance. However, these attributes extend to
2023.
allow for more conversational possibilities that are inherited [2] I. Ozkaya, “Application of large language models to software engi-
from bot-based interactions in general and LLM capabilities neering tasks: Opportunities, risks, and implications,” IEEE Software,
vol.40,no.3,pp.4–8,2023.
specifically. For example, human-to-LLM conversations can
[3] L. Clark, N. Pantidi, O. Cooney, P. Doyle, D. Garaialde, J. Edwards,
be more flexible and available compared to human-to-human B. Spillane, E. Gilmartin, C. Murad, C. Munteanu, et al., “What
conversations. LLM-based chatbots have the capacity to com- makesagoodconversation?challengesindesigningtrulyconversational
agents,”inProceedingsofthe2019CHIconferenceonhumanfactors
prehend a wide range of topics and adapt their responses
in computing systems, CHI ’19, (New York, NY, USA), pp. 1–12,
basedonthecontextoftheconversation.Thisflexibilityallows AssociationforComputingMachinery,2019.
them to cover different purposes of conversations, including [4] L. Erlenhov, F. G. de Oliveira Neto, R. Scandariato, and P. Leitner,
“Currentandfuturebotsinsoftwaredevelopment,”in2019IEEE/ACM
providing specific artifacts to solve problems in addition to
1st International Workshop on Bots in Software Engineering (BotSE),
providing recommendations and general guidance. pp.7–11,IEEE,2019.
[5] M. Wessel, B. M. De Souza, I. Steinmacher, I. S. Wiese, I. Polato,
A. P. Chaves, and M. A. Gerosa, “The power of bots: Characterizing
D. Conversation styles are not mutually exclusive, but rather and understanding bots in oss projects,” Proceedings of the ACM on
Human-ComputerInteraction,vol.2,no.CSCW,pp.1–19,2018.
complementary
[6] A.Abdellatif,K.Badran,andE.Shihab,“Msrbot:Usingbotstoanswer
Communication is an essential part of software devel- questionsfromsoftwarerepositories,”EmpiricalSoftwareEngineering,
vol.25,pp.1834–1863,2020.
opment. Researchers have been tackling this by proposing
[7] M.LeeandS.Lee,““idon’tknowexactlybutiknowalittle”:Exploring
solutions for coordination and communications in software betterresponsesofconversationalagentswithinsufficientinformation,”
teams [15]. In the new era of AI-driven software develop- inExtendedAbstractsofthe2021CHIConferenceonHumanFactors
inComputingSystems,(NewYork,NY,USA),pp.1–5,Associationfor
ment (AIware), software teams are evolving into a hybrid
ComputingMachinery,2021.
modelinvolvingsoftwareengineersbutalsoAI.Consequently, [8] X. Yang, M. Aurisicchio, and W. Baxter, “Understanding affective
new challenges have emerged in regard to the adoption of experienceswithconversationalagents,”inproceedingsofthe2019CHI
conference on human factors in computing systems, (New York, NY,
NLU-chatbots [16] and more recently LLM-chatbots e.g., the
USA),pp.1–12,AssociationforComputingMachinery,2019.
challenge of “crafting effective prompts” discussed by [17]. [9] R.Khojah,M.Mohamad,P.Leitner,andF.G.deOliveiraNeto,“Beyond
With respect to the conversation attributes, one challenge code generation: An observational study of chatgpt usage in software
engineering practice,” in Proceedings of the 2024 Fundamentals of
of human-to-LLM conversations is establishing trust when
Software Engineering Conference (FSE), (New York, NY, USA), As-
certain criteria are missing, such as transparency. This can sociationforComputingMachinery,2024.7
[10] R. Khojah, M. Mohamad, P. Leitner, and F. G. de Oliveira Neto,
“Package for An Observational Study of ChatGPT Usage in Software
EngineeringPractice,”Sept.2023.
[11] C. da Silva Cintra and R. A. Bittencourt, “Being a pbl teacher in
computerengineering:Aninterpretativephenomenologicalanalysis,”in
2015 IEEE Frontiers in Education Conference (FIE), pp. 1–8, IEEE,
2015.
[12] K. Han, A. Xiao, E. Wu, J. Guo, C. Xu, and Y. Wang, “Transformer
in transformer,” Advances in Neural Information Processing Systems,
vol.34,pp.15908–15919,2021.
[13] A.Przegalinska,L.Ciechanowski,A.Stroz,P.Gloor,andG.Mazurek,
“Inbotwetrust:Anewmethodologyofchatbotperformancemeasures,”
BusinessHorizons,vol.62,no.6,pp.785–797,2019. DigitalTransfor-
mationandDisruption.
[14] D.Tiwari,T.Toady,M.Monperrus,andB.Baudry,“Withgreathumor
comesgreatdeveloperengagement,”inSoftwareEngineeringinSociety
(ICSE-SEIS),(Piscataway,NJ),IEEEPress,2024.
[15] M. Mohamad, G. Liebel, and E. Knauss, “Loco coco: Automatically
constructing coordination and communication networks from model-
basedsystemsengineeringdata,”InformationandSoftwareTechnology,
vol.92,pp.179–193,2017.
[16] A. Abdellatif, K. Badran, D. E. Costa, and E. Shihab, “A comparison
of natural language understanding platforms for chatbots in software
engineering,”IEEETransactionsonSoftwareEngineering,vol.48,no.8,
pp.3087–3102,2021.
[17] A. E. Hassan, D. Lin, G. K. Rajbahadur, K. Gallaba, F. R. Cogo,
B. Chen, H. Zhang, K. Thangarajah, G. A. Oliva, J. Lin, et al.,
“Rethinking software engineering in the era of foundation models:
A curated catalogue of challenges in the development of trustworthy
fmware,”2024.
[18] J.RubinandM.Rinard,“Thechallengesofstayingtogetherwhilemov-
ingfast:Anexploratorystudy,”inProceedingsofthe38thInternational
ConferenceonSoftwareEngineering,ICSE’16,(NewYork,NY,USA),
p.982–993,AssociationforComputingMachinery,2016.