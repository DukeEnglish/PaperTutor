[
    {
        "title": "Features are fate: a theory of transfer learning in high-dimensional regression",
        "authors": "Javan TahirSurya GanguliGrant M. Rotskoff",
        "links": "http://arxiv.org/abs/2410.08194v1",
        "entry_id": "http://arxiv.org/abs/2410.08194v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08194v1",
        "summary": "With the emergence of large-scale pre-trained neural networks, methods to\nadapt such \"foundation\" models to data-limited downstream tasks have become a\nnecessity. Fine-tuning, preference optimization, and transfer learning have all\nbeen successfully employed for these purposes when the target task closely\nresembles the source task, but a precise theoretical understanding of \"task\nsimilarity\" is still lacking. While conventional wisdom suggests that simple\nmeasures of similarity between source and target distributions, such as\n$\\phi$-divergences or integral probability metrics, can directly predict the\nsuccess of transfer, we prove the surprising fact that, in general, this is not\nthe case. We adopt, instead, a feature-centric viewpoint on transfer learning\nand establish a number of theoretical results that demonstrate that when the\ntarget task is well represented by the feature space of the pre-trained model,\ntransfer learning outperforms training from scratch. We study deep linear\nnetworks as a minimal model of transfer learning in which we can analytically\ncharacterize the transferability phase diagram as a function of the target\ndataset size and the feature space overlap. For this model, we establish\nrigorously that when the feature space overlap between the source and target\ntasks is sufficiently strong, both linear transfer and fine-tuning improve\nperformance, especially in the low data limit. These results build on an\nemerging understanding of feature learning dynamics in deep linear networks,\nand we demonstrate numerically that the rigorous results we derive for the\nlinear case also apply to nonlinear networks.",
        "updated": "2024-10-10 17:58:26 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08194v1"
    },
    {
        "title": "Generalizing Stochastic Smoothing for Differentiation and Gradient Estimation",
        "authors": "Felix PetersenChristian BorgeltAashwin MishraStefano Ermon",
        "links": "http://arxiv.org/abs/2410.08125v1",
        "entry_id": "http://arxiv.org/abs/2410.08125v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08125v1",
        "summary": "We deal with the problem of gradient estimation for stochastic differentiable\nrelaxations of algorithms, operators, simulators, and other non-differentiable\nfunctions. Stochastic smoothing conventionally perturbs the input of a\nnon-differentiable function with a differentiable density distribution with\nfull support, smoothing it and enabling gradient estimation. Our theory starts\nat first principles to derive stochastic smoothing with reduced assumptions,\nwithout requiring a differentiable density nor full support, and we present a\ngeneral framework for relaxation and gradient estimation of non-differentiable\nblack-box functions $f:\\mathbb{R}^n\\to\\mathbb{R}^m$. We develop variance\nreduction for gradient estimation from 3 orthogonal perspectives. Empirically,\nwe benchmark 6 distributions and up to 24 variance reduction strategies for\ndifferentiable sorting and ranking, differentiable shortest-paths on graphs,\ndifferentiable rendering for pose estimation, as well as differentiable cryo-ET\nsimulations.",
        "updated": "2024-10-10 17:10:00 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08125v1"
    },
    {
        "title": "Active Fourier Auditor for Estimating Distributional Properties of ML Models",
        "authors": "Ayoub AjarraBishwamittra GhoshDebabrota Basu",
        "links": "http://arxiv.org/abs/2410.08111v1",
        "entry_id": "http://arxiv.org/abs/2410.08111v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08111v1",
        "summary": "With the pervasive deployment of Machine Learning (ML) models in real-world\napplications, verifying and auditing properties of ML models have become a\ncentral concern. In this work, we focus on three properties: robustness,\nindividual fairness, and group fairness. We discuss two approaches for auditing\nML model properties: estimation with and without reconstruction of the target\nmodel under audit. Though the first approach is studied in the literature, the\nsecond approach remains unexplored. For this purpose, we develop a new\nframework that quantifies different properties in terms of the Fourier\ncoefficients of the ML model under audit but does not parametrically\nreconstruct it. We propose the Active Fourier Auditor (AFA), which queries\nsample points according to the Fourier coefficients of the ML model, and\nfurther estimates the properties. We derive high probability error bounds on\nAFA's estimates, along with the worst-case lower bounds on the sample\ncomplexity to audit them. Numerically we demonstrate on multiple datasets and\nmodels that AFA is more accurate and sample-efficient to estimate the\nproperties of interest than the baselines.",
        "updated": "2024-10-10 16:57:01 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08111v1"
    },
    {
        "title": "Noether's razor: Learning Conserved Quantities",
        "authors": "Tycho F. A. van der OuderaaMark van der WilkPim de Haan",
        "links": "http://arxiv.org/abs/2410.08087v1",
        "entry_id": "http://arxiv.org/abs/2410.08087v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08087v1",
        "summary": "Symmetries have proven useful in machine learning models, improving\ngeneralisation and overall performance. At the same time, recent advancements\nin learning dynamical systems rely on modelling the underlying Hamiltonian to\nguarantee the conservation of energy. These approaches can be connected via a\nseminal result in mathematical physics: Noether's theorem, which states that\nsymmetries in a dynamical system correspond to conserved quantities. This work\nuses Noether's theorem to parameterise symmetries as learnable conserved\nquantities. We then allow conserved quantities and associated symmetries to be\nlearned directly from train data through approximate Bayesian model selection,\njointly with the regular training procedure. As training objective, we derive a\nvariational lower bound to the marginal likelihood. The objective automatically\nembodies an Occam's Razor effect that avoids collapse of conservation laws to\nthe trivial constant, without the need to manually add and tune additional\nregularisers. We demonstrate a proof-of-principle on $n$-harmonic oscillators\nand $n$-body systems. We find that our method correctly identifies the correct\nconserved quantities and U($n$) and SE($n$) symmetry groups, improving overall\nperformance and predictive accuracy on test data.",
        "updated": "2024-10-10 16:29:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08087v1"
    },
    {
        "title": "Gaussian Process Thompson Sampling via Rootfinding",
        "authors": "Taiwo A. AdebiyiBach DoRuda Zhang",
        "links": "http://arxiv.org/abs/2410.08071v1",
        "entry_id": "http://arxiv.org/abs/2410.08071v1",
        "pdf_url": "http://arxiv.org/pdf/2410.08071v1",
        "summary": "Thompson sampling (TS) is a simple, effective stochastic policy in Bayesian\ndecision making. It samples the posterior belief about the reward profile and\noptimizes the sample to obtain a candidate decision. In continuous\noptimization, the posterior of the objective function is often a Gaussian\nprocess (GP), whose sample paths have numerous local optima, making their\nglobal optimization challenging. In this work, we introduce an efficient global\noptimization strategy for GP-TS that carefully selects starting points for\ngradient-based multi-start optimizers. It identifies all local optima of the\nprior sample via univariate global rootfinding, and optimizes the posterior\nsample using a differentiable, decoupled representation. We demonstrate\nremarkable improvement in the global optimization of GP posterior samples,\nespecially in high dimensions. This leads to dramatic improvements in the\noverall performance of Bayesian optimization using GP-TS acquisition functions,\nsurprisingly outperforming alternatives like GP-UCB and EI.",
        "updated": "2024-10-10 16:06:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2410.08071v1"
    }
]