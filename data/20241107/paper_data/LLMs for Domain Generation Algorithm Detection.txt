LLMs for Domain Generation Algorithm Detection
Reynier Leyva La Oa,c,∗, Carlos A. Cataniab,c, Tatiana S. Parlantib,c
aGridTICs, Facultad Regional Mendoza, Universidad Tecnol´ogica Nacional, Rodriguez
273, M5502AJE, Mendoza, Argentina
bFacultad de Ingenier´ıa, Universidad Nacional de Cuyo, Centro
Universitario, M5502JMA, Mendoza, Argentina
cNational Scientific and Technical Research Council (CONICET), Godoy Cruz
2290, C1425FQB, CABA, Argentina
Abstract
This work analyzes the use of large language models (LLMs) for detecting
domaingenerationalgorithms(DGAs). Weperformadetailedevaluationoftwo
important techniques: In-Context Learning (ICL) and Supervised Fine-Tuning
(SFT),showinghowtheycanimprovedetection. SFTincreasesperformanceby
using domain-specific data, whereas ICL helps the detection model to quickly
adapttonewthreatswithoutrequiringmuchretraining. WeuseMeta’sLlama3
8B model, on a custom dataset with 68 malware families and normal domains,
covering several hard-to-detect schemes, including recent word-based DGAs.
Results proved that LLM-based methods can achieve competitive results in
DGA detection. In particular, the SFT-based LLM DGA detector outperforms
state-of-the-artmodelsusingattentionlayers,achieving94%accuracywitha4%
false positive rate (FPR) and excelling at detecting word-based DGA domains.
Keywords: DGA detection, Large Language Models, In-Context Learning,
Supervised Fine-Tuning, Cybersecurity
∗Correspondingauthor
Email addresses: rleyvalao@mendoza-conicet.gob.ar(ReynierLeyvaLaO),
harpo@ingenieria.uncuyo.edu.ar(CarlosA.Catania),
tatiana.parlanti@ingenieria.uncuyo.edu.ar(TatianaS.Parlanti)
Preprint submitted to Journal of Information Security and Applications November 6, 2024
4202
voN
5
]LC.sc[
1v70330.1142:viXra1. Introduction
In the ever-evolving landscape of cybersecurity, domain generation algo-
rithms (DGAs) have emerged as a significant threat, posing unique challenges
totraditionalsecuritymeasures. DGAsaresophisticatedtoolsemployedbycy-
bercriminals to dynamically create large numbers of domain names, primarily
used to establish and maintain command and control (C&C) infrastructure for
botnets and other malicious activities.
The operation of a DGA is based on an initial seed or key, from which
sequences of characters are generated to form domain names. These sequences
can vary in length and structure, and encryption and obfuscation techniques
are often used to further hinder their detection.
DGAs pose significant challenges to cybersecurity by enabling botnets to
frequently change command-and-control servers, making them resilient to take-
down efforts and difficult for defenders to block. They also facilitate covert
data exfiltration, malware distribution, and phishing campaigns by generating
constantly shifting domains that evade detection by traditional security mea-
sures. Additionally,DGAsbypassreputation-basedsystemswithnewlycreated
domains lacking history, overwhelming security tools with high volumes of do-
mains, increasing false positives, and straining network resources.
Giventhesechallenges,effectiveDGAdetectionhasbecomeacriticalcompo-
nent of modern cybersecurity strategies. Traditional approaches, such as static
blacklistsandsimpleheuristics,haveproveninadequateagainstthedynamicna-
tureofDGAs. Thishasledtoincreasedinterestinmoresophisticateddetection
methods, including machine learning and deep learning [1, 2, 3, 4] as they have
shown promise in enhancing DGA detection by leveraging more sophisticated
feature extraction and classification methods. Similarly, and more recently, the
application of large language models (LLMs) has also attracted interest [5].
Inthiscontext, LLMs, thankstotheirextensivetrainingdataandabilityto
comprehend semantic patterns, offer new potential for effective DGA detection
[6,7]. LLMs’adaptabilityandsemanticunderstandingarecrucialforanalyzing
2the complex patterns generated by DGAs. Furthermore, LLMs do not require
extensive datasets for their application, making them efficient for deployment
in dynamic environments.
In this work, we analyze the performance of LLM-based methods for DGA
detection, comparing them with state-of-the-art models. Our focus is on re-
cent local models, such as Meta’s Llama 3 8B. We explore two main strategies:
In-Context Learning (ICL) and Supervised Fine-Tuning (SFT). The evalua-
tion is conducted on a carefully designed dataset that includes examples from
68 distinct DGA families, covering various schemes, including recent word-
based DGAs. These word-based schemes generate domains by concatenating
sequences of words from one or more wordlists, resulting in domains that ap-
pear less random and are therefore more challenging to detect [8].
Our results indicate that SFT with domain-specific data significantly im-
provesdetectioncapabilitiesinparticularreducingthefalsepositiverate(FPR),
whereas ICL enables rapid adaptation to new and evolving threats without ex-
tensive retraining. This research highlights the potential of LLMs to enhance
cybersecurity defenses against DGA-based attacks, providing a comprehensive
solution that balances speed and accuracy.
The main contributions of the paper are:
• A dataset with 68 malware families and normal domains from the Tranco
dataset [9].
• A complete analysis of the potential of ICL and SFT for improving DGA
detection using LLMs.
• A state-of-the-art LLM-based DGA detector with lower FPR and better
detection of DGA word-based domains.
The remainder of this paper is organized as follows: Section 2 provides
technical background on LLMs for DGA detection. Section 3 reviews previous
works in DGA detection. Section 4 describes the proposed approach, includ-
ing the dataset and methodology. Section 5 outlines the design and results of
3experiments, focusing on ICL and fine-tuning approaches. Section 6 discusses
the practical implications of the findings and proposes a strategy for practical
implementation. Finally, Section 7 concludes the paper and suggests directions
for future research.
2. Background
To better understand how large language models (LLMs) can be applied to
DGA detection, it is critical to explore in detail the technical aspects of these
models and the specific approaches used in this study.
2.1. Large Language Models
LLMsarebasedontheTransformerarchitecture,whichfundamentallyrelies
onself-attentionmechanismstoprocessandgeneratesequentialdata[10,11,12].
This architecture allows the model to weigh the relevance of different input
parts dynamically, leading to a more nuanced understanding of context and
relationships within the data. Pre-trained on extensive amounts of text data,
these models can learn intricate patterns and linguistic structures [13, 14].
Transformersarecomposedofseveralkeycomponents. Theembeddinglayer
converts input tokens into dense vector representations, enabling the model to
handle various types of data inputs uniformly [11]. The multi-head attention
mechanism is crucial as it allows the model to focus on different parts of the
input simultaneously, capturing complex dependencies that might exist within
the data. This is complemented by feedforward neural networks, which pro-
cess the output of the attention layers and introduce non-linearity, enhancing
the model’s ability to understand and predict complex patterns. Additionally,
layernormalizationisappliedthroughouttostabilizeandacceleratethelearning
process, ensuring consistent model performance.
2.2. Model
Llama3with8Billionparametersspreadacrossmultipletransformerlayers,
as known as Llama3 8B model, was used in this study. Its extensive parame-
4terization enables it to encapsulate and recognize convoluted patterns in data
[6, 7, 15].
Llama3 is an auto-regressive language model that uses an optimized trans-
former architecture. It uses a tokenizer with a vocabulary of 128K tokens and
was trained on sequences of 8,192 tokens. Grouped-query attention (GQA) is
used for all models to improve inference efficiency. The tuned versions use su-
pervised fine-tuning (SFT) and reinforcement learning with human feedback
(RLHF) to align with human preferences for helpfulness and safety.
2.3. In-Context Learning
In-contextlearning(ICL)representsanovelapproachwhereLLMsadaptto
newtasksbyleveragingtheirpre-existingknowledgewithoutrequiringmuchre-
training[11,16,17]. Thiscapabilityisparticularlypowerfulasitallowsforrapid
adaptation to a wide range of tasks by simply providing examples and context
within the model’s input window. The process begins with prompt engineer-
ing, where a carefully crafted prompt includes relevant examples that guide the
model’s task execution. The model’s extensive context window accommodates
these prompts and new task-related data, enabling the LLM to recognize pat-
terns and make predictions based on the embedded examples. This ability to
identify patterns and draw parallels from its pre-trained knowledge allows the
model to effectively perform tasks it was not explicitly trained for, demonstrat-
ing the versatility and potential of ICL in diverse applications.
2.4. Supervised Fine-Tuning
Supervisedfine-tuning(SFT)isaprocessforadaptingapre-trainedLLMto
aspecifictask,enhancingitsperformanceandaccuracy[18,19]. Followingatra-
ditionalmachinelearningworkflow,theprocessbeginswiththepreparationofa
specialized dataset, containing labeled examples pertinent to the task at hand.
Starting with a pre-trained model like Llama3 8B, the training process involves
adjusting the model’s parameters to minimize classification errors, thereby re-
fining its task-specific capabilities. Techniques such as Low-Rank Adaptation
5(LoRA) are employed to efficiently fine-tune the model by integrating trainable
rank decomposition matrices within each layer [20, 21]. This reduces the num-
beroftrainableparameters,makingtheprocessmorecomputationallyefficient.
Additionally, quantization methods, such as 4-bit quantization, are applied to
decrease the model size and inference time while maintaining performance [22].
Through SFT, LLMs are adapted to meet the demands of specific tasks, un-
locking their full potential in real-world applications.
3. Previous Works
The study of DGA domain detection and classification has been a dynamic
area of research, driven by the ever-evolving tactics of cybercriminals. Initial
methodologies were primarily based on lexicographical analysis and heuristic
methods. AlthoughtheseapproachesprovedeffectiveforstraightforwardDGAs,
they encountered limitations when dealing with more sophisticated algorithms
[8].
As the field advanced, researchers increasingly adopted machine learning
techniquestoenhancedetectionaccuracy. Thesetechniquesevolvedfromfeature-
based approaches, which utilized handcrafted attributes like n-grams, entropy,
and character distribution [23, 24], to the implementation of advanced neu-
ral network models. Specifically, Convolutional Neural Networks (CNNs) and
Recurrent Neural Networks (RNNs) demonstrated substantial promise in iden-
tifying complex patterns in domain names [25, 26, 3].
Inpursuitofimproveddetectioncapabilities,hybridandensembleapproaches
have also been explored. An example is the model by Harishkumar and Bhu-
vaneshwaran[27],whichintegratesn-gramanalysis,topicmodeling,andattention-
basedBiLSTMnetworks. Thisapproachunderscoresthepotentialofcombining
multiple techniques to enhance detection accuracy and robustness.
Continuing advancements in the field address emerging challenges, such as
analyzing encrypted traffic. For example, Tapsoba et al. [28] examined DNS
over HTTPS (DoH) traffic to identify plaintext features for DGA domain de-
6tection, highlighting the potential of leveraging encrypted traffic analysis for
cybersecurity applications. Furthermore, the AdamW+ framework [29] opti-
mizes the AdamW gradient optimizer to improve DGA domain detection.
In a novel approach, AlSabeh et al. [30] proposed a framework utilizing P4
programmable switches for DGA detection and classification. This framework
leverages the flexibility and processing capabilities of P4 switches to extract
unique network heuristics and domain name features through both shallow and
deep packet inspection (DPI), with minimal impact on throughput. It employs
a two-fold strategy, utilizing a line-rate compact machine learning classifier in
the data plane for DGA detection and a comprehensive classifier in the control
plane for both detection and classification.
Transformer-based models, recognized for their success in natural language
processing tasks, are also being investigated for DGA detection. Yu et al. [5]
presented Dom-BERT, a model designed to detect malicious domains by con-
structingaheterogeneousgraphandleveragingapre-trainedBERTmodel. This
approach demonstrates significant improvements in F1 score and resilience to
class imbalance, but it only uses a small amount of domains. Building upon
BERT-basedapproaches,Mahdaouyetal. introducedDomURLs BERT,aspe-
cialized pre-trained BERT-based encoder specifically adapted for detecting and
classifying suspicious domains and URLs. Their model, which was pre-trained
using Masked Language Modeling on a multilingual corpus of URLs, domain
names,andDGAdatasets,demonstratedsuperiorperformancecomparedtotra-
ditional character-based deep learning models and other cybersecurity-focused
BERTvariantsacrossmultipleclassificationtasks,includingphishing,malware,
DGA, and DNS tunneling detection [31].
The development of sophisticated models has been a hallmark of recent
advancements. For instance, Hu et al. [32] introduced the CI GRU model,
which combines CNNs and gated recurrent units (GRUs) with an attention
mechanism. This model significantly enhances the ability to capture temporal
dependenciesandcriticalfeaturesinDGAdomainsequences. Similarly,Tuanet
al. [33] developed the LA bin07 model, employing a combination of long short-
7termmemory(LSTM)networksandattentionmechanismstoeffectivelycapture
both local and global domain name features. This latest model represents the
most advanced work in the field so far.
On the other hand, the importance of quality and diverse datasets cannot
beoverstatedinthedevelopmentandevaluationofDGAdetectionmodels[34].
Resources such as the UMUDGA dataset [35], the 360NetLab DGA Dataset
[36], and the Domain Generation Algorithms Repository [37] provide valuable
data for researchers in this field.
Despitetheseadvancements,severalchallengespersist. Modelsmustquickly
adapt to new DGA families without extensive retraining, balance detection ac-
curacy with computational efficiency for real-time applications, and maintain a
low false positive rate while achieving a high detection rate.
For their part, the advent of LLMs like GPT-3 has opened new possibili-
ties across various domains, including cybersecurity. Although not extensively
exploredforDGAdetection,LLMs’abilitytounderstandcomplexlinguisticpat-
ternsandgeneralizeacrossdomainssuggestspotentialapplicationsinidentifying
and classifying DGA-generated domains. Recent advancements in LLM archi-
tectures and training techniques, such as chain-of-thought prompting [14] and
reasoning-based approaches [38], offer promising avenues for enhancing DGA
detection capabilities.
Buildinguponthesefoundations, thisworkinvestigateshowstate-of-the-art
LLMs can be leveraged to address current challenges in DGA detection.
4. Methodology
4.1. Dataset Description
The dataset crafted for this study consists of two primary subsets: one for
training and another for testing. Both sets include normal (also known as legit
or legitimate) and DGA-generated domains, with the latter distributed across
various DGA families [8]. This assembled dataset provides a comprehensive
8representationofDGAdomains,encompassingvariousalgorithmsandstrategies
employed by different malware families.
The selection of both normal domains and DGA families to construct the
dataset,wasconductedfollowingtherecommendationsofrecentstudiessuchas
[34], which emphasize the importance of including hard-to-detect families, such
asthosebasedonwordlists,toensureamorerobustevaluationofDGAdetection
methods. The DGA domains were derived from the UMUDGA, DGAarchive,
and360netlabdatasets[36,35,39],withadditionaldomainsgeneratedfollowing
the method proposed in [40].
Normal domains were obtained from the Tranco dataset [9]. This is a col-
laborative project that provides a ranking of the most popular websites, aggre-
gating data from various sources to ensure a comprehensive and dynamic list.
It is updated regularly, capturing shifts in web popularity and offering a robust
reflection of legitimate web activity.
The dataset used consists of 68 DGA families, along with normal domains.
It is important to note that the training set is composed of 54 DGA families,
whereas the test set includes these 54 families plus 14 additional ones. These
last ones were only used for generalization tests (see Section 5.2), whereas all
other evaluations were conducted using the remaining 54 families. Also for the
generalizationtests,normaldomainsdifferentfromthoseusedintheothertests
were sampled.
Table 1 presents the distribution of DGA and normal domains across the
training and test sets. The DGA domains were extracted from the 68 families
listed in Table 2, which also categorizes the families based on their generation
scheme: arithmetic (A) or word-based (W). Under the arithmetic scheme, the
algorithm usually calculates a sequence of values that have a direct ASCII rep-
resentation usable for a domain name. On the other hand, word-based consists
of concatenating a sequence of words from one or more wordlists.
It is worth noting that the training and testing datasets described above
were not used in their totality, but rather different samples were taken from
them to evaluate distinct approaches, as described below.
9Category Training Set Testing Set
Total DGA domains 139 million 15 million
Total normal domains 3 million 350 thousand
Total domains 142 million 15.35 million
Table1: Distributionofdomainsinthetrainingandtestingsets.
4.2. Training Process
Inthecontextofthisresearch,thetermtraining referstotheprocessesused
to adapt the model for the specific task of domain classification. In particular,
thisstudyemploystwodistincttrainingapproaches: ICLandSFT,asdescribed
in Section 2.
As depicted in Figure 1, the Llama3 8B model was trained using different
methodologies with data sampled from the training dataset. However, this
study employs specific quantities of domain data, depending on the training
approach. For the SFT method, a substantial dataset of two million domains
was utilized, evenly split between one million DGA domains and one million
normal domains. Analogously, two separate datasets were used for the ICL-
based models: one using a sample of 500 domains (250 DGA and 250 normal),
andanotherutilizingalargersetof2000domains(1000DGAand1000normal).
Notice that the number of domains used in ICL approaches was constrained by
the context window. In all cases, the DGA instances were sampled from the 54
available families, so for example, approximately 18 DGA domains per family
were sampled to obtain the 1000 DGA domains for the second dataset used in
the ICL training approach.
A consistent data format was used for SFT, ensuring that the model re-
ceived the data properly to learn the relationships between domains and their
corresponding labels. Each example was structured as in Figure 2.
Incontrast,whenICLwasapplied,themodelwasiterativelypresentedwith
aprompt(Figure3)outliningitsclassificationtask,followedbythe500or2000
10Family Scheme Family Scheme Family Scheme
alureon A gozi W ramdo A
bamital A kraken A ramnit A
banjori A locky A ranbyus A
bazarbackdoor* A manuelita W rovnix W
bedep A matsnu W sharkbot* A
bigviktor* W monerominer A shiotob A
bumblebee* A murofet A simda A
ccleaner* A murofetweekly A sisron A
charbot W mydoom A sphinx A
chinad A necurs A suppobox W
conficker A new goz* A symmi A
corebot A ngioweb* W tempedreve A
cryptolocker A nymaim W tinba A
deception W oderoor A tinynuke A
dircrypt A padcrypt A tufik* A
dmsniff* A pitou A vawtrak A
dnschanger A pizd* W verblecon* A
dyre A proslikefan A vidro A
emotet A pushdo A virut A
enviserv* A pykspa A xshellghost* A
fobber A qadars A zeus-newgoz A
gameover A qakbot A zloader A
goz* A qsnatch A
Table 2: DGA families and their schemes used in the dataset for training and testing. (A)
standsforArithmeticgenerationscheme,(W)forWord-based. (*)indicatesthe14additional
familiesinthetestset.
labeleddomainnames,aswellasadomainnameextractedfromthetestingset.
This approach enabled the model to classify new domain names based on the
11Figure1: Distributionofdomainsforthedifferenttrainingmethods.
Example Format
#domain: {domain}
#label : {label}
Figure2: Exampleformatfortrainingdata(forSFT),includingdomainandlabel.
enhancedknowledgegainedfromtheprompt,demonstratingICL’seffectiveness
in addressing domain classification challenges.
ForapplyingICL,thesetupinvolvedconfiguringthemodellocallyusingthe
ollama package [41], which provides an optimized interface for working with
language models, allowing specific adjustments and configurations to suit the
experiment’s requirements. The model features a quantization type of Q4 0
and quantization version 2 for dealing with hardware limitations. On the other
hand, during the SFT process, the Low-Rank Adaptation (LoRA) technique
[20, 21, 42] was used during training to deal with hardware limitations. This
technique was applied to the key, value, and query projection modules (k proj,
12Prompt used for domain classification
You are a domain name classification system. Your task is
to classify domain names as either ’dga’ (Domain Generation
Algorithm) or ’normal’. DGA domains are automatically
generated by malware, while normal domains are not. I will
provide you with labeled training data containing domain
names and their classifications. After the training phase,
you will classify a new domain and respond with either
’dga’ or ’normal’.
as.com
domain: as.com, result: normal
...
...
...
xcfdreyjs.com
domain: xcfdreyjs.com, result: dga
Now you classify this domain: google.com, only answer
dga or normal. Do not provide any additional information
or explanation.
Figure3: PromptusedonLlama38BforclassificationofdomainnamesinICL.
v proj, q proj) of the decoder layers. LoRA allows for the modification of
specific model components, thereby reducing the need to adjust all parameters
anddecreasingtrainingcomplexity[20,21]. Inaddition,themodelunderwent4-
bit quantization during training. This approach significantly decreases memory
usage while preserving model performance [22].
4.3. Evaluation Process
Regardlessoftheirtrainingapproach,aconsistentmethodologywasapplied
across all the models. The flowchart in Figure 4 illustrates the evaluation pro-
13cedurestepbystep, highlightingthesystematicapproachadoptedinthestudy.
Figure4: Modelevaluationdiagram.
Toensurethereliabilityandrobustnessoftheevaluationresults,thirtyinde-
pendent runs were conducted for each DGA family. On each run, a systematic
sample [43] of 100 example domains (50 DGA and 50 legit) was provided to
the model for classification into DGA-generated or legitimate. The model pre-
dictions, query times, and other relevant performance metrics were recorded
throughout these runs to establish its effectiveness in detecting malicious do-
mainsgeneratedbyDGAs. Finally,theperformanceofthemodelswasassessed
usingseveralkeymetrics,eachofwhichprovidesinsightsintodifferentaspectsof
modelefficacy. ThemetricsutilizedinthisevaluationincludeAccuracy(Accu),
Precision (Pre), Recall (Re), F1 Score (F1), False Positive Rate (FPR), and
Processing Time (Proc. Time) [44, 45].
The systematic sampling strategy applied, as visually described in Figure 5,
wasasfollows: sampleswereselectedfromtheDGAandthelegitimatedomains
14in the test set at thirty regular intervals, each one of length fifty. In the end,
there were one hundred domains per interval: fifty DGA and fifty legit. No-
tice that, for each family, the same thirty intervals of legitimate domains were
combined with the corresponding thirty of DGA.
Figure 5: Systematic sampling: 30 samples of 50 legit and 50 DGA domains. Each circle
represents50differentdomains,andallcirclesaredisjoint.
5. Experimental Results
This section outlines the results of the effectiveness of LLMs in detecting
DGA across a series of experiments. First, we explored the optimal training
15strategy for LLMs in DGA detection, comparing ICL and SFT to determine
which approach performs better. Next, we assessed their ability to detect ma-
licious domains when tested on new examples of DGA families present in the
training data, examining how well the model distinguishes between DGA and
legitimate domains. Then we extend the problem by evaluating the general-
ization capabilities of the SFT model by testing its performance on previously
unseen DGA families to understand how well it handles new domain genera-
tionalgorithms. Finally, wecomparedtheSFT-trainedLLMtostate-of-the-art
models, such as LA Bin07, a deep learning model using attention mechanisms.
To ensure reproducibility, all the source code, datasets, and instructions used
in this study are available in a public GitHub repository [46].
5.1. Experiment I: Evaluation of Training Approaches
The results of this experiment used domains from the 54 families present in
the training set.
Table3presentstheoverallaverageofthemetricsobtained, forallrunsand
the54families,afterapplyingtheICLtrainingprocessdescribedinSection4.2.
Thetableillustrateshowtrainingwithdifferentdatasetsizesaffectsthemodel’s
ability to distinguish between legitimate and malicious domains.
Sample Size Accu Pre Re F1 FPR Proc. Time (s)
2000 0.84 0.87 0.78 0.81 0.1 1.47
500 0.55 0.52 0.99 0.69 0.88 0.95
Table3: PerformancecomparisonofLlama38Bmodelwithdifferentsamplesizesfortraining,
usingtheICLapproach.
Themodelusing500domainsshowspoorperformance,witharecallvalueof
0.99butaprecisionof0.52. Themodelisnotcapableofdistinguishingbetween
DGA and legitimate domains. In addition, the FPR is extremely high.
On the other hand, the model trained with 2000 domains outperforms the
previousoneinallevaluationmetricsexceptprocessingtimeandrecall. Notably
is the increment in the precision (0.87) and the diminution of the FPR (0.1).
16PerformanceanalysisofthismodelispresentedinTable4, averagingbyfamily,
whichhighlightsthestrengthsandweaknessesofthemodelforeachDGAfamily.
Table4showsthatthemodelexhibitshighprecision. Furthermore,formany
DGAfamilies, themodelachievesscoresgreaterthanorequalto0.9inallmet-
rics. Notably, families such as murofetweekly, dnschanger, and zeus-newgoz
achieve a precision of approximately 0.92. However, variability is observed,
with families like manuelita, matsnu, qsnatch, and suppobox showing lower
performance, with a precision around 0.65. These less accurately detected fam-
ilies predominantly consist of word-based domains, which are generally more
challenging for detectors.
Overall, the results demonstrate that the Llama3 8B model, trained using
the ICL approach with 2000 domains, performs acceptably on the domain clas-
sification task, while also highlighting areas for improvement in several DGA
families. Specifically, the LLM can identify patterns that distinguish legitimate
domains from malicious ones, and this can be achieved with approximately 18
example domains per DGA family.
These findings confirm that a larger sample size enhances the performance
of LLMs in domain classification tasks using ICL, emphasizing the importance
of providing sufficient context for optimal results.
On the other hand, the overall average over all runs and families, of the
metrics obtained after applying the SFT training approach, are shown in Ta-
ble5. TheSFTLlama38Bmodeldemonstratedhighaccuracy(94%),precision
(93%), recall (92%), and F1 score (92%), excelling in correctly identifying both
positive and negative examples. It also has a low FPR of 0.04. The latter is
crucial in applications where minimizing false positives is essential, making it a
valuable model despite its processing time.
Table6presentstheevaluationmetricsfortheSFTLlama38Bmodelacross
variousDGAfamilies. Theresultsdemonstratethemodel’seffectivenessinclas-
sifyingDGAfamilies,withdifferentlevelsofprecisionandrecallobservedacross
the families. This detailed analysis is crucial for optimizing model performance
andeffectivelyaddressingtheuniquechallengesassociatedwitheachDGAfam-
17Family Pre Re F1 Family Pre Re F1
alureon 0.91 0.95 0.93 oderoor 0.90 0.79 0.84
bamital 0.90 0.92 0.91 padcrypt 0.91 0.95 0.93
banjori 0.90 0.87 0.88 pitou 0.87 0.68 0.76
bedep 0.91 1.00 0.95 proslikefan 0.86 0.60 0.70
charbot 0.80 0.36 0.49 pushdo 0.90 0.88 0.89
chinad 0.91 0.99 0.95 pykspa 0.87 0.66 0.75
conficker 0.86 0.61 0.72 qadars 0.91 0.93 0.92
corebot 0.91 1.00 0.95 qakbot 0.91 0.93 0.92
cryptolocker 0.91 0.95 0.93 qsnatch 0.71 0.26 0.38
deception 0.84 0.49 0.62 ramdo 0.91 0.93 0.92
dircrypt 0.91 0.97 0.94 ramnit 0.91 0.96 0.93
dnschanger 0.92 0.95 0.93 ranbyus 0.91 1.00 0.95
dyre 0.90 0.90 0.90 rovnix 0.87 0.64 0.73
emotet 0.91 0.96 0.93 shiotob 0.91 0.96 0.93
fobber 0.91 1.00 0.95 simda 0.85 0.52 0.65
gameover 0.91 1.00 0.95 sisron 0.89 0.83 0.86
gozi 0.89 0.80 0.84 sphinx 0.91 1.00 0.95
kraken 0.90 0.72 0.80 suppobox 0.62 0.15 0.24
locky 0.91 0.87 0.89 symmi 0.91 1.00 0.95
manuelita 0.72 0.25 0.37 tempedreve 0.89 0.82 0.85
matsnu 0.64 0.15 0.24 tinba 0.90 0.95 0.93
monerominer 0.87 0.63 0.73 tinynuke 0.90 0.86 0.88
murofet 0.91 0.98 0.94 vawtrak 0.89 0.79 0.84
murofetweekly 0.92 1.00 0.96 vidro 0.90 0.85 0.87
mydoom 0.89 0.75 0.81 virut 0.79 0.37 0.50
necurs 0.90 0.90 0.90 zeus-newgoz 0.92 1.00 0.96
nymaim 0.75 0.28 0.40 zloader 0.91 0.97 0.94
Table 4: Metrics obtained with the Llama3 8B model trained using the ICL approach (with
2000samples).
18Model Accu Pre Re F1 FPR Proc. Time (s)
SFTLlama38B 0.94 0.93 0.92 0.92 0.04 3.50
Table5: Llama38Bmodelperformance,trainedusingtheSFTapproach.
ily.
When comparing the SFT with ICL models, the experiments showed that
the SFT Llama3 8B model significantly outperforms the ICL-based approach
across multiple evaluation metrics, as evidenced in Figure 6.
0.94 0.93 0.92 0.92 ICL (2000 Samples)
SFT
0.87
0.84
0.81
0.8 0.78
0.6
0.4
0.2
0.1
0.04
0.0
Accuracy Precision Recall F1 Score FPR
Figure 6: Performance comparison of Llama3 8B model, using the ICL (with 2000 samples)
andtheSFTtrainingapproaches.
Figure 7 presents the mean F1 score, obtained with the Llama3 8B model
using ICL (with 2000 samples) and SFT training approaches, for the 54 DGA
families. It reveals that the SFT model consistently outperforms the ICL
model, achieving a near-perfect F1 score in most cases. The ICL model demon-
strates greater variability, with significant drops in F1 score for certain fami-
lies, such as charbot, deception, manuelita, matsnu, nymaim, qsnatch,
simda, suppobox, and virut, all with a mean F1 score lower than or equal to
19
serocSFamily Pre Re F1 Family Pre Re F1
alureon 0.96 1.00 0.98 oderoor 0.95 1.00 0.97
bamital 0.96 1.00 0.98 padcrypt 0.96 1.00 0.98
banjori 0.96 0.98 0.97 pitou 0.95 0.90 0.92
bedep 0.95 1.00 0.98 proslikefan 0.96 0.96 0.96
charbot 0.95 0.81 0.87 pushdo 0.95 0.95 0.95
chinad 0.96 1.00 0.98 pykspa 0.96 0.95 0.96
conficker 0.95 0.84 0.89 qadars 0.96 0.99 0.98
corebot 0.96 1.00 0.98 qakbot 0.96 1.00 0.98
cryptolocker 0.95 1.00 0.98 qsnatch 0.88 0.40 0.54
deception 0.95 0.87 0.91 ramdo 0.96 1.00 0.98
dircrypt 0.96 0.99 0.98 ramnit 0.96 0.99 0.97
dnschanger 0.95 0.99 0.97 ranbyus 0.96 1.00 0.98
dyre 0.95 1.00 0.98 rovnix 0.96 0.88 0.92
emotet 0.96 1.00 0.98 shiotob 0.96 0.97 0.96
fobber 0.96 1.00 0.98 simda 0.96 1.00 0.98
gameover 0.95 1.00 0.98 sisron 0.96 1.00 0.98
gozi 0.95 0.97 0.96 sphinx 0.96 1.00 0.98
kraken 0.95 1.00 0.98 suppobox 0.95 0.92 0.94
locky 0.95 0.99 0.97 symmi 0.95 1.00 0.98
manuelita 0.87 0.29 0.43 tempedreve 0.96 1.00 0.98
matsnu 0.95 0.79 0.86 tinba 0.95 1.00 0.98
monerominer 0.95 0.97 0.96 tinynuke 0.01 0.00 0.00
murofet 0.95 1.00 0.98 vawtrak 0.96 0.91 0.93
murofetweekly 0.96 1.00 0.98 vidro 0.96 0.98 0.97
mydoom 0.95 1.00 0.97 virut 0.94 0.66 0.77
necurs 0.96 0.99 0.97 zeus-newgoz 0.96 1.00 0.98
nymaim 0.95 0.90 0.93 zloader 0.96 1.00 0.98
Table6: MetricsobtainedwiththeLlama38Bmodel,trainedusingtheSFTapproach.
0.65. In contrast, the SFT model maintains a high F1 score across nearly all
families, with only minor fluctuations. These results underscore the robustness
20andreliabilityoftheSFTmodelindetectingDGAdomainsacrossadiverseset
of families, making it a more effective approach for DGA detection.
1.0
0.8
0.6
0.4
0.2
Llama3 ICL 2k
0.0 Llama3 SFT
DGA Families
Figure7: F1scorecomparisonofLlama38Bmodel, usingtheICL(with2000samples)and
theSFTtrainingapproaches.
Based on these results, we can conclude that the SFT Llama3 8B model
outperforms in detecting DGA domains. Therefore, for the remainder of this
study, only this model will be used to ensure optimal metrics and efficiency in
DGA detection.
5.2. Experiment II: Evaluation of Generalization to New Families
The generalization capability of a machine learning model to new, unseen
dataiscrucialforitspracticalapplicationinreal-worldscenarios. Thisispartic-
ularly significant in cybersecurity, where new threats and variations of existing
threats constantly emerge.
ToassessthegeneralizationcapabilityoftheSFTLlama38Bmodel,acom-
prehensive evaluation was conducted. The model was tested on a set of 14
previously unseen DGA families, representing a diverse range of DGAs. These
new DGA families are found only in the test set, as described in Section 4.1.
Also, new normal domains were used for this test. This evaluation aims to pro-
vide a thorough understanding of the model’s strengths and limitations when
21
erocS
1F
naeM
noerula latimab irojnab pedeb tobrahc danihc rekcifnoc toberoc rekcolotpyrc noitpeced tpyrcrid regnahcsnd eryd tetome rebbof revoemag izog nekark ykcol atileunam unstam renimorenom teforum ylkeewteforum moodym srucen miamyn rooredo tpyrcdap uotip nafekilsorp odhsup apskyp sradaq tobkaq hctansq odmar tinmar suybnar xinvor botoihs admis norsis xnihps xoboppus immys everdepmet abnit ekunynit kartwav ordiv turiv zogwen-suez redaolzfacedwithnoveldata. These14familieswereevaluatedfollowingtheprocedure
outlined in Section 4.3.
Table 7 presents the detailed evaluation results showcasing the precision,
recall, and F1 score for the 14 new DGA families. It also shows the FPR
obtained.
Family Pre Re F1 Family Pre Re F1
bazarbackdoor 0.06 0.01 0.01 new goz 0.96 1.00 0.98
bigviktor 0.88 0.35 0.50 ngioweb 0.93 0.61 0.74
bumblebee 0.23 0.01 0.02 pizd 0.95 0.90 0.93
ccleaner 0.83 0.22 0.35 sharkbot 0.92 0.55 0.69
dmsniff 0.95 0.99 0.97 tufik 0.96 1.00 0.98
enviserv 0.81 0.19 0.31 verblecon 0.96 1.00 0.98
goz 0.96 1.00 0.98 xshellghost 0.96 1.00 0.98
FPR 0.05
Table7: MetricsobtainedwiththeSFTLlama38Bmodel,fornewDGAfamilies.
The results revealed a notable performance disparity among the different
DGA families. Many generated families, such as verblecon, goz, and new goz,
demonstrated superior performance with high precision, recall, and F1 score.
This suggests that the fine-tuned model exhibits a robust ability to detect and
classify these particular types of DGA patterns. It is also important to note
that even though the model was challenged with novel normal domains in this
test, it exhibited a low FPR.
In contrast, some families showed significantly lower performance metrics,
such as bigviktor, bumblebee, and bazarbackdoor. These last two are re-
markable as they have very low recall and F1 score. This disparity highlights
the challenges associated with detecting certain variants of DGAs, regardless of
theirgenerationmethod,andunderscorestheneedforfurtherrefinementofthe
model to improve its capabilities in these problematic areas.
225.3. Experiment III: Comparison with Previous Approaches
ToevaluatetheeffectivenessoftheLLM-basedapproachforDGAdetection,
the SFT Llama3 8B model was compared against one of the most advanced
state-of-the-art models: the LA Bin07 model [33]. This model utilizes a com-
bination of LSTM networks and attention layers to classify domains as either
malicious or legitimate.
To maintain equitable assessment conditions, both the SFT Llama3 8B
model and the LA Bin07 model were evaluated using identical datasets and
evaluationprocedures. Tables8and9provideadetailedcomparisonofalltheir
performance metrics, whereas Figures 8 and 9 highlight the mean F1 score per
family. Allofthesewereobtainedbyevaluatingonthepreviouslyseen54DGA
families (Table 8 and Figure 8), and the unseen 14 new families (Table 9 and
Figure 9).
Model Accu Pre Re F1 FPR Proc. Time (s)
SFTLlama38B 0.94 0.93 0.92 0.92 0.04 3.50
LA Bin07 0.90 0.90 0.88 0.88 0.09 0.03
Table 8: Performance comparison between the SFT Llama3 8B model and the LA Bin07
modelforthepreviouslyseen54DGAfamilies.
Model Accu Pre Re F1 FPR Proc. Time (s)
SFTLlama38B 0.79 0.81 0.63 0.67 0.05 3.50
LA Bin07 0.85 0.88 0.77 0.80 0.08 0.03
Table 9: Performance comparison between the SFT Llama3 8B model and the LA Bin07
modelfortheunseen14DGAfamilies.
Table 8 shows that the SFT Llama3 8B model outperformed the LA Bin07
model across several metrics on the previously seen 54 DGA families. Partic-
ularly, in the false positive rate (FPR), achieving a value of 4%, significantly
lower than the 9% observed for LA Bin07. Furthermore, Figure 8 exhibits that
the SFT Llama3 8B model achieves a higher mean F1 score than the LA Bin07
23model across almost all families, except for deception, tyninuke, and virut.
Table 8 also provides information on processing time. The SFT Llama3 8B
model requires 3.50 seconds to process, which is considerably higher than the
0.03 seconds required by the LA Bin07 model. This difference highlights a key
considerationforreal-timeapplications,whereprocessingspeedmaybecritical.
The increased processing time of the SFT Llama3 8B model is likely due to the
complexity and size of the LLM, which demands more computational resources
while offering superior detection capabilities.
On the other hand, Table 9 presents the results obtained by evaluating the
SFT Llama3 8B and the LA Bin07 models on the 14 DGA families for testing.
Although the LA Bin07 model demonstrates better performance than Llama3
8B when dealing with these new DGA families, Figure 9 reveals a variable
performance between the models, with fluctuations in F1 score across different
families, indicating that neither model consistently outperforms the other.
1.0
0.8
0.6
0.4
0.2
LA_Bin07
0.0 Llama3 SFT
DGA Families
Figure 8: Comparison of mean F1 score between LA Bin07 and SFT Llama3 8B models for
54DGAfamilies.
Figures 10 and 11 illustrate the difference in the true positive rate (TPR)
between the SFT Llama3 8B model and the LA Bin07 model for the 54 DGA
families and the 14 new ones, respectively. It can be seen that the first model
outperforms the second one in most families present in the training set, which
24
erocS
1F
naeM
noerula latimab irojnab pedeb tobrahc danihc rekcifnoc toberoc rekcolotpyrc noitpeced tpyrcrid regnahcsnd eryd tetome rebbof revoemag izog nekark ykcol atileunam unstam renimorenom teforum ylkeewteforum moodym srucen miamyn rooredo tpyrcdap uotip nafekilsorp odhsup apskyp sradaq tobkaq hctansq odmar tinmar suybnar xinvor botoihs admis norsis xnihps xoboppus immys everdepmet abnit ekunynit kartwav ordiv turiv zogwen-suez redaolz1.0 LA_Bin07
Llama3 SFT
0.8
0.6
0.4
0.2
0.0
DGA Families
Figure 9: Comparison of mean F1 score between LA Bin07 and SFT Llama3 8B models for
14newDGAfamilies.
indicatesabettercapacitytocorrectlyidentifymaliciousdomains. Nevertheless,
the difference is minor on the new 14 families.
6. Discussion
The results from Section 5 demonstrated the significant potential of LLMs
in enhancing DGA detection. In particular, the SFT Llama3 8B model exhib-
ited superior performance to traditional approaches, achieving higher accuracy,
precision, recall, and F1 score, while showing the lowest false positive rate.
Significant advantages of LLMs were observed in scenarios where conven-
tional methods struggle to keep pace with rapidly evolving threats, as demon-
stratedbytheresultsinSection5.3,whereitwascomparedtheSFTLlama38B
model with the LA Bin07 model. Notably, the SFT Llama3 8B model achieved
much better results in detecting DGAs that utilize word-based generation algo-
rithms (see Figure 12). Detecting word-based DGA families has been a major
challenge in DGA detection in recent years [26]. The current findings suggest
that LLMs offer a promising approach to effectively tackle this type of DGA.
One of the main issues with the application of LLMs for DGA detection is
25
erocS
1F
naeM
roodkcabrazab rotkivgib eebelbmub renaelcc ffinsmd vresivne zog zog_wen bewoign dzip tobkrahs kifut nocelbrev tsohgllehsx0.75
0.50
0.25
0.00
0.25
0.50
0.75
1.00
DGA Families
Figure 10: Difference in TPR between SFT Llama3 8B and LA Bin07 models for 54 DGA
families
the processing speed of the model. Current LLM responses are a significant
limitation for real-time applications, as rapid-response models are required.
To address the processing speed limitations of LLMs in DGA detection,
researchers can employ both optimized hardware and smaller, efficient models.
Utilizing specialized hardware, such as the Groq platform, which offers high-
performance, low-latency processing through optimized matrix multiplication,
can significantly enhance model inference and training times. This enables the
developmentofmorecomplexandaccurateDGAdetectionmodelswithreduced
computational demands [47, 48].
Inparallel,adoptingsmalleryetcapablemodelslikeGemma22Bwith2bil-
lion parameters [49] and GPT-4o mini [50] offers a promising approach. These
models strike a balance between computational efficiency and detection accu-
racy, providing a viable alternative for future research [51].
Finally,apossibleapproachtoaddresstheprocessingspeedlimitationcould
be the application of layered architecture for detection. In the first layer, faster
models such as LA Bin07 act as initial filters to quickly process domain names.
In the next stage, the Llama3 8B model is applied to verify cases identified as
suspicious by the primary layer, taking advantage of its high accuracy and low
26
)70niB_AL
-
B8
3amalL
TFS(
RPT
fo
ecnereffiD
noerula latimab irojnab pedeb tobrahc danihc rekcifnoc toberoc rekcolotpyrc noitpeced tpyrcrid regnahcsnd eryd tetome rebbof revoemag izog nekark ykcol atileunam unstam renimorenom teforum ylkeewteforum moodym srucen miamyn rooredo tpyrcdap uotip nafekilsorp odhsup apskyp sradaq tobkaq hctansq odmar tinmar suybnar xinvor botoihs admis norsis xnihps xoboppus immys everdepmet abnit ekunynit kartwav ordiv turiv zogwen-suez redaolz0.4
0.2
0.0
0.2
0.4
0.6
0.8
DGA Families
Figure 11: Difference in TPR between SFT Llama3 8B and LA Bin07 models for 14 DGA
families
false positive rate.
Several promising avenues for future research have been identified. Firstly,
exploring continuous learning techniques could keep the model updated with
new threats while maintaining performance on known DGAs. Investigating
hybrid approaches that combine large language models with other machine
learning techniques might optimize both accuracy and efficiency. Additionally,
developing methods to enhance model interpretability would enable security
analysts to better understand the reasoning behind classifications. Lastly, con-
ducting studies to evaluate the model’s performance over extended periods of
time could assess its resilience to evolving DGA tactics.
7. Conclusions
ThisstudyonLLMsforDGAdetectionhasprovenhighlyeffective,primarily
duetotheirdeepunderstandingofsemantics,whichenhancesDGAword-based
detection capabilities.
Utilizing the Llama3 8B model from Meta, the results demonstrate that
both ICL and SFT approaches can significantly improve the identification of
27
)70niB_AL
-
B8
3amalL
TFS(
RPT
fo
ecnereffiD
roodkcabrazab rotkivgib eebelbmub renaelcc ffinsmd vresivne zog zog_wen bewoign dzip tobkrahs kifut nocelbrev tsohgllehsxFigure12: RecallresultsforLA Bin07andtheSTFLlama38Bonword-basedDGAfamilies.
DGAdomains. Specifically,anSFTwithdomain-specificdatayieldssubstantial
gains in detection accuracy. Furthermore, the combination of low false positive
rates and robust detection accuracy makes these models invaluable tools for
cybersecurity.
However, challenges remain, particularly in terms of computational power
and response time, limiting the feasibility of real-time deployment. To address
these issues, exploring smaller models such as Gemma2 2B offers a promising
path toward improving efficiency without compromising performance.
Moving forward, further research and development are necessary to seam-
lessly integrate LLMs into existing network security infrastructures. This in-
cludescombiningLLMswithothermachinelearningapproachestocreatehybrid
solutions that optimize both speed and accuracy. Advancing these efforts will
beessentialtobuildingmoreeffectiveandscalabledefensesagainstincreasingly
sophisticated DGA-based threats.
28Acknowledgments
Thefirstandthirdauthorsacknowledgetheirdoctoralfellowshipgrantedby
CONICET.
References
[1] A.M.Saeed,D.Wang,H.A.Alnedhari,K.Mei,J.Wang,Asurveyofma-
chine learning and deep learning based dga detection techniques, in: Inter-
national Conference on Smart Computing and Communication, Springer,
2021, pp. 133–143.
[2] S.Li,T.Huang,Z.Qin,F.Zhang,Y.Chang,Domaingenerationalgorithms
detection through deep neural network and ensemble, in: Companion Pro-
ceedings of The 2019 World Wide Web Conference, 2019, pp. 189–196.
[3] S.Zhou,L.Lin,J.Yuan,F.Wang,Z.Ling,J.Cui,Cnn-baseddgadetection
with high coverage, in: 2019 IEEE international conference on intelligence
and security informatics (ISI), IEEE, 2019, pp. 62–67.
[4] C. Hwang, H. Kim, H. Lee, T. Lee, Effective dga-domain detection and
classificationwithtextcnnandadditionalfeatures,Electronics9(7)(2020)
1070.
[5] Y. Tian, Z. Li, Dom-bert: Detecting malicious domains with pre-training
model, in: International Conference on Passive and Active Network Mea-
surement, Springer, 2024, pp. 133–158.
[6] Meta, Llama3: Large language model by meta, accessed: 2024-07-04
(2024).
URL https://github.com/meta-llama/llama3
[7] Meta, Llama3: Large language model by meta, accessed: 2024-07-04
(2024).
URL https://huggingface.co/meta-llama/Meta-Llama-3-8B
29[8] D. Plohmann, K. Yakdan, M. Klatt, J. Bader, E. Gerhards-Padilla, A
comprehensivemeasurementstudyofdomaingeneratingmalware,in: 25th
USENIX Security Symposium (USENIX Security 16), 2016, pp. 263–278.
[9] P.Snyder,C.Taylor,C.Kanich,The2020trancolist: Improvingthealexa
ranking, https://tranco-list.eu, accessed: 2024-07-05 (2020).
[10] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, Bert: Pre-training of
deepbidirectionaltransformersforlanguageunderstanding,arXivpreprint
arXiv:1810.04805 (2018).
[11] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al., Language models
are few-shot learners, Advances in neural information processing systems
33 (2020) 1877–1901.
[12] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L(cid:32) . Kaiser, I. Polosukhin, Attention is all you need, Advances in neural
information processing systems 30 (2017).
[13] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis,
L.Zettlemoyer,V.Stoyanov,Roberta: Arobustlyoptimizedbertpretrain-
ing approach, arXiv preprint arXiv:1907.11692 (2019).
[14] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,
D. Zhou, et al., Chain-of-thought prompting elicits reasoning in large lan-
guagemodels,Advancesinneuralinformationprocessingsystems35(2022)
24824–24837.
[15] W.Huang,X.Ma,H.Qin,X.Zheng,C.Lv,H.Chen,J.Luo,X.Qi,X.Liu,
M. Magno, How good are low-bit quantized llama3 models? an empirical
study, arXiv preprint arXiv:2404.14047 (2024).
[16] R.Agarwal,A.Singh,L.M.Zhang,B.Bohnet,S.Chan,A.Anand,Z.Ab-
bas,A.Nova,J.D.Co-Reyes,E.Chu,etal.,Many-shotin-contextlearning,
arXiv preprint arXiv:2404.11018 (2024).
30[17] Y.Lu,M.Bartolo,A.Moore,S.Riedel,P.Stenetorp,Fantasticallyordered
prompts and where to find them: Overcoming few-shot prompt order sen-
sitivity, arXiv preprint arXiv:2104.08786 (2021).
[18] H. Face, Sfttrainer: Supervised fine-tuning trainer, available at:
https://github.com/huggingface/trl [Accessed: 2024-06-15] (2023).
[19] W. . Biases, How to fine-tune an llm part 3: The huggingface trainer,
available at: https://wandb.ai/capecape/alpaca ft/reports/How-to-Fine-
tune-an-LLM-Part-3-The-HuggingFace-Trainer–Vmlldzo5OTEyNjMy [Ac-
cessed: 2024-06-15] (2023).
[20] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
W. Chen, Lora: Low-rank adaptation of large language models, arXiv
preprint arXiv:2106.09685 (2021).
[21] Microsoft, Lora: Low-rank adaptation of large language models, available
at: https://github.com/microsoft/LoRA [Accessed: 2024-06-15] (2021).
[22] BitsAndBytes, Bitsandbytes: Optimizers and quantization for large mod-
els, available at: https://github.com/TimDettmers/bitsandbytes [Ac-
cessed: 2024-06-15] (2022).
[23] B. Yu, J. Pan, J. Hu, A. Nascimento, M. De Cock, Character level based
detection of dga domain names, in: 2018 international joint conference on
neural networks (IJCNN), IEEE, 2018, pp. 1–8.
[24] J. Woodbridge, H. S. Anderson, A. Ahuja, D. Grant, Predicting do-
main generation algorithms with long short-term memory networks, arXiv
preprint arXiv:1611.00791 (2016).
[25] J. Namgung, S. Son, Y.-S. Moon, Efficient deep learning models for dga
domain detection, Security and Communication Networks 2021 (1) (2021)
8887881.
31[26] C. Catania, S. Garc´ıa, P. Torres, Deep convolutional neural networks
for dga detection, in: Computer Science–CACIC 2018: 24th Argentine
Congress, Tandil, Argentina, October 8–12, 2018, Revised Selected Papers
24, Springer, 2019, pp. 327–340.
[27] S. Harishkumar, R. Bhuvaneshwaran, Enhanced dga detection in botnet
traffic: Leveraging n-gram, topic modeling and attention bilstm (2024).
[28] A.R.Tapsoba,T.F.Ou´edraogo,W.-B.S.Zongo,Analysisofplaintextfea-
turesindohtrafficfordgadomainsdetection,in: InternationalConference
on Information Technology & Systems, Springer, 2024, pp. 127–138.
[29] A. Javed, I. Rashid, S. Tahir, S. Saeed, A. M. Almuhaideb, K. Alissa,
Adamw+: Machine learning framework to detect domain generation algo-
rithms for malware, IEEE Access (2024).
[30] A. AlSabeh, K. Friday, E. Kfoury, J. Crichigno, E. Bou-Harb, On dga
detectionandclassificationusingp4programmableswitches,Computers&
Security (2024) 104007.
[31] A. E. Mahdaouy, S. Lamsiyah, M. J. Idrissi, H. Alami, Z. Yartaoui,
I. Berrada, Domurls bert: Pre-trained bert-based model for mali-
cious domains and urls detection and classification, arXiv preprint
arXiv:2409.09143 (2024).
[32] H.Wang,Z.Tang,H.Li,J.Zhang,S.Li,J.Wang,Ci gru: Anefficientdga
botnet classification model based on an attention recurrence plot, Com-
puter Networks 235 (2023) 109992.
[33] T.A.Tuan,H.V.Long,D.Taniar,Ondetectingandclassifyingdgabotnets
and their families, Computers & Security 113 (2022) 102549.
[34] B. Cebere, J. Flueren, S. Sebasti´an, D. Plohmann, C. Rossow, Down to
earth! guidelines for dga-based malware detection (2024).
32[35] M. Zago, M. G. P´erez, G. M. P´erez, Umudga: A dataset for profiling
algorithmicallygenerateddomainnamesinbotnetdetection, DatainBrief
30 (2020) 105400.
[36] 360NetLab, 360netlab dga dataset, accessed: 2024-07-04 (2023).
URL https://data.netlab.360.com/
[37] J. Bader, Domain generation algorithms repository, accessed: 2024-07-04
(2024).
URL https://github.com/baderj/domain_generation_algorithms
[38] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, Y. Cao, Re-
act: Synergizing reasoning and acting in language models, arXiv preprint
arXiv:2210.03629 (2022).
[39] D. Plohmann, Dgaarchive–a deep dive into domain generating malware,
Dec-2015 (2015).
[40] J. Peck, C. Nie, R. Sivaguru, C. Grumer, F. Olumofin, B. Yu, A. Nasci-
mento, M. De Cock, Charbot: A simple and effective method for evading
dga classifiers, IEEE Access 7 (2019) 91759–91771.
[41] Ollama, Ollama: An open source package for optimizing language mod-
els, available at: https://github.com/Ollama/ollama [Accessed: 2024-06-
15] (2023).
[42] T. Dettmers, A. Pagnoni, A. Holtzman, L. Zettlemoyer, Qlora: Efficient
finetuning of quantized llms, Advances in Neural Information Processing
Systems 36 (2024).
[43] W. G. Cochran, Sampling Techniques, 3rd Edition, John Wiley & Sons,
New York, 1977.
[44] M. Hossin, M. N. Sulaiman, A review on evaluation metrics for data clas-
sification evaluations, International journal of data mining & knowledge
management process 5 (2) (2015) 1.
33[45] D. M. Powers, Evaluation: from precision, recall and f-measure to roc,
informedness,markednessandcorrelation,arXivpreprintarXiv:2010.16061
(2020).
[46] R. Leyva, Domain-name-classification-with-llm, https://github.com/
reypapin/Domain-Name-Classification-with-LLM (2024).
[47] D. Abts, J. Kim, G. Kimmell, M. Boyd, K. Kang, S. Parmar, A. Ling,
A. Bitar, I. Ahmed, J. Ross, The groq software-defined scale-out tensor
streaming multiprocessor: From chips-to-systems architectural overview,
in: 2022 IEEE Hot Chips 34 Symposium (HCS), IEEE Computer Society,
2022, pp. 1–69.
[48] S. Moon, J.-H. Kim, J. Kim, S. Hong, J. Cha, M. Kim, S. Lim, G. Choi,
D. Seo, J. Kim, et al., Lpu: A latency-optimized and highly scalable pro-
cessor for large language model inference, IEEE Micro (2024).
[49] G. Team, M. Riviere, S. Pathak, P. G. Sessa, C. Hardin, S. Bhupati-
raju, L. Hussenot, T. Mesnard, B. Shahriari, A. Ram´e, et al., Gemma
2: Improving open language models at a practical size, arXiv preprint
arXiv:2408.00118 (2024).
[50] OpenAI, Gpt-4o mini: Advancing cost-efficient intelligence, accessed:
2024-08-05 (2024).
URLhttps://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/
[51] L. C. Magister, J. Mallinson, J. Adamek, E. Malmi, A. Severyn, Teaching
small language models to reason, arXiv preprint arXiv:2212.08410 (2022).
34