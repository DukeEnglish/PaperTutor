Examining Human-AI Collaboration for Co-Writing
Constructive Comments Online
FARHANASHAHID,CornellUniversity,UnitedStates
MAXIMILIANDITTGEN,CornellUniversity,UnitedStates
MORNAAMAN,CornellTech,UnitedStates
ADITYAVASHISTHA,CornellUniversity,UnitedStates
Thispaperexamineshowlargelanguagemodels(LLMs)canhelppeoplewriteconstructivecommentsinonline
debatesondivisivesocialissuesandwhetherthenotionsofconstructivenessvaryacrosscultures.Through
controlledexperimentswith600participantsfromIndiaandtheUS,whoreviewedandwroteconstructive
commentsononlinethreadsonIslamophobiaandhomophobia,wefoundpotentialmisalignmentinhow
LLMsandhumansperceiveconstructivenessinonlinecomments.WhiletheLLMwasmorelikelytoview
dialecticalcommentsasmoreconstructive,participantsfavoredcommentsthatemphasizedlogicandfacts
morethantheLLMdid.Despitethesedifferences,participantsratedLLM-generatedandhuman-AIco-written
commentsassignificantlymoreconstructivethanthosewrittenindependentlybyhumans.Ouranalysis
alsorevealedthatLLM-generatedandhuman-AIco-writtencommentsexhibitedmorelinguisticfeatures
associatedwithconstructivenesscomparedtohuman-writtencommentsondivisivetopics.Whenparticipants
usedLLMstorefinetheircomments,theresultingcommentswerelonger,morepolite,positive,lesstoxic,
andmorereadable,withaddedargumentativefeaturesthatretainedtheoriginalintentbutoccasionallylost
nuances.Basedonthesefindings,wediscussethicalanddesignconsiderationsinusingLLMstofacilitate
constructivediscourseonline.
CCSConcepts:•Human-centeredcomputing→EmpiricalstudiesinHCI.
AdditionalKeyWordsandPhrases:LLM,constructivedisagreement,homophobia,Islamophobia
ACMReferenceFormat:
FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha.2018.ExaminingHuman-AICol-
laborationforCo-WritingConstructiveCommentsOnline.InProceedingsofMakesuretoenterthecorrect
conferencetitlefromyourrightsconfirmationemai(Conferenceacronym’XX).ACM,NewYork,NY,USA,
31pages.https://doi.org/XXXXXXX.XXXXXXX
1 Introduction
Mostpeopleusesocialmediaingoodfaith[77],butoftenstruggletoreachcommongroundduring
onlinedebates[5].Onlinedisagreementsoftenleadtotoxicityandpersonalattacks,andthelackof
supportforconstructivedialoguediscouragespeoplefromchallengingproblematiccontent[35,83].
Thisresultsindownstreamharms,suchasthedisappearanceofminorityviewpoints[16,34]and
increasedpropagationofharmfulcontent[84].
Tosuppressonlineconflictandencouragecivildialogue,mostplatformsrelyonreactivemeasures
suchascontentremovalandbanningoffenders,whicharenotalwayseffectiveinencouraging
prosocialbehaviors[82,89].Inresponse,HCIresearchershaveexploredproactivestrategiesto
promotehealthydiscourse,suchasusingsocialcuestohighlightpositivebehavior[42,77],and
introducingfrictions[47,63,81]andnudges[8,28,74,93]todiscouragepeoplefromusingoffensive
language.However,theseinterventionsputtheonusonuserstowritetheiropinionsconstructively,
Authors’ContactInformation:FarhanaShahid,CornellUniversity,Ithaca,UnitedStates,fs468@cornell.edu;Maximilian
Dittgen,CornellUniversity,Ithaca,UnitedStates,myd4@cornell.edu;MorNaaman,CornellTech,NYC,UnitedStates,
mor.naaman@cornell.edu;AdityaVashistha,CornellUniversity,Ithaca,UnitedStates,adityav@cornell.edu.
Conferenceacronym’XX,June03–05,2018,Woodstock,NY
2018.ACMISBN978-1-4503-XXXX-X/18/06
https://doi.org/XXXXXXX.XXXXXXX
,Vol.1,No.1,Article.Publicationdate:November2018.
4202
voN
5
]CH.sc[
1v59230.1142:viXra2 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
whichisalreadydifficultinnon-conflictingsituations[18],andmoresoduringdisputesonsocially
divisiveissues.
Researchershavedefinedconstructivecommentsasthosethatbalanceargumentationwithpolite-
ness[51–53].Giventhechallengespeoplefaceinengagingconstructivelyinonlinearguments[35],
some researchers have trained large language models (LLMs) to help people in argumentative
writing[20,58,109].Whileearlyevaluationsshowthatthesemodelsimprovepeople’swriting[109]
andhelpthemfindcommongroundondivisiveissues[3],muchofthisworkfocusesonargu-
mentativeessaywritingandone-on-oneprivatedebates.Moreover,thesestudiesdonottakeinto
accounthowpeoplefromdifferentculturesapproachargumentation.Priorresearchshowsthat
peoplefromindividualisticculturespreferlogicalargumentsthatfollowformalrulestosubstantiate
points[15,69,76].Incontrast,thosefromcollectivistculturesfavordialecticalargumentsduring
socialconflicts,emphasizingaholisticconsiderationofdifferentviewpointsandfindingmiddle
ground[76,95,96].Theseculturaldifferencesmightprovecriticalwhiledesigninginterventions
tohelppeopleengageinonlinedebatesondivisivesocialissues,especiallysinceLLMstendto
homogenizewritingtowardsWesternnormsanddiminishculturalnuances[1].
Weextendthisgrowingbodyofworkintwokeyways.First,weexaminehowpeopleperceiveand
writeconstructivecommentsonsociallydivisiveissueswithinonlinethreads,wheremeaningful
discussions often get overshadowed by thoughtless and negative comments [67]. Second, we
investigateifnotionsofconstructivenessinonlinedebatesvaryacrosscultures.Specifically,we
addressthefollowingresearchquestions:
RQ1: DoperceptionsofconstructivecommentsdifferbetweenhumansandLLMs?
RQ2: CanLLMshelppeoplewriteconstructivecommentsondivisivesocialissues?
RQ3: Donotionsofconstructivenessinonlinecommentsvaryacrosscultures?
Toanswerthesequestions,weconductedatwo-phasestudywithparticipantsfromIndiaand
the United States of America (US), who reviewed online threads containing homophobic and
Islamophobiccontentrelevanttotheirculturalcontexts.InPhase1,weusedGPT-4togenerate
constructivecommentsonthesethreads,followingeitheralogicalordialecticalargumentationstyle,
andadoptingdifferentstances(eitherinfavororagainsttheissue).Weverified,bothquantitatively
andqualitatively,thattheLLM-generatedcommentsdifferedonlyinargumentationstyleandnot
inlinguisticfeaturesofconstructiveness.Wethenconductedaforced-choiceexperimentwith103
IndianandAmericancrowdworkersonProlific.Eachparticipantreviewedeitherahomophobic
oranIslamophobicthreadalongwithrandomlyselectedpairsoflogicalvs.dialecticalcomments,
written for the same thread from the same stance. For each pair, participants indicated which
commenttheyperceivedasmoreconstructiveandwhy.TocomparehumanandLLM’sperceptions
ofconstructiveness,wealsoassignedthesametasktoGPT-4.
InresponsetoRQ1,wefoundthatGPT-4was2.46timesmorelikelythanhumanstoselectdialec-
ticalcommentsasmoreconstructivethanlogicalones.GPT-4tendedtoprioritizecommentsthat
werepoliteandbalanceddifferentviewpoints(dialecticalarguments).Incontrast,ourparticipants
favoredcommentsthatemphasizedlogicandfacts(logicalarguments)morethanGPT-4while
pickingconstructivecomments.Giventhesedifferences,wenextexaminedhowpeopleengage
withLLMswhenwritingconstructivecomments.
InPhase2,weconductedabetween-subjectexperimentwith103IndianandAmericancrowd
workersrecruitedthroughProlific.Participantswereaskedtowriteconstructivecommentson
homophobicandIslamophobicthreads.Theywererandomlyassignedtooneoftwogroups:a
controlgroupwheretheywrotecommentsindependently,andatestgroupwheretheycouldselect
promptstorequestanLLMtorewritetheircommentsconstructively.Inthetestgroup,participants
hadtheflexibilitytoaccept,edit,reject,orregeneratethesuggestionsfromLLM.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 3
ToaddressRQ2,wecomparedthecommentsfromPhase2—theonesparticipantswroteinde-
pendentlyincontrolgroup(human-written)orwithLLM’sassistanceintestgroup(human-AI
written)—alongsidethecommentsgeneratedsolelybyLLM(AI)inPhase1toassesswhichtypeof
commentwasmoreconstructive.Crowdevaluationshowedthat,whenpresentedwith(Humanvs.
AI)commentpairs,participantswere8.51timesmorelikelytoselectLLM-generatedcomments
asmoreconstructivethanthehuman-writtencomments.Similarly,participantswere3.19times
morelikelytochooseHAI-writtencommentsasmoreconstructiveoverhuman-writtencomments.
QuantitativeanalysesofthesecommentsrevealedthatbothLLM-generatedandHAI-writtencom-
mentscontainedsignificantlymoreconstructivefeatures,suchasgreaterlength,morediscourse
connectives,andstanceadverbials,thanhuman-writtencomments.ThesesuggestthatLLMshave
thepotentialtoassistpeopleinwritingmoreconstructivecommentsondivisivesocialissues.
WenotedthatwhenparticipantsrequestedsuggestionsfromtheLLM,itmadetheircomments
significantlymorepositive,moreconstructive,andlesstoxic.Inmostcases,participantsaccepted
theLLM’ssuggestionsbecauseitconveyedtheirpointsbetterwithouthomogenizingtheirwriting.
However,someparticipantsfeltthattheLLMmisrepresentedtheirviewsandeditedthesuggestions
inwaysthatmadetheircommentsmorenegativeandtoxic.Overall,participantsweresatisfied
withthe commentstheywrotewiththe assistanceofLLMs andfoundthe processeasierthan
writingconstructivecommentsindependently.
Finally,wecomparedtheresponsesofIndianandAmericanparticipantsinPhase1andPhase2
toaddressRQ3.Wefoundthatparticipantsfrombothcountriesconsidereddialecticalcomments
asmoreconstructivethanlogicalonesandprovidedsimilarreasoningfortheirpreferences.They
showedcomparableskillinwritingconstructivecomments,bothindependentlyandwithLLM
assistance.Inthetestgroup,participantsfrombothcountriesusedsimilarpromptstomaketheir
commentsconstructive.Additionally,theyalsoratedLLM-generatedandHAI-writtencommentsas
significantlymoreconstructivethanthehuman-writtencomments.Thesefindingssuggestashared
understandingofconstructivenessacrossculturesinthecaseofonlinecommentsondivisivesocial
issues.Takentogether,ourworkmakesthefollowingcontributions:
• WeprovidebothquantitativeandqualitativeevidencethatLLMscanhelppeoplefromdifferent
cultureswriteconstructivecommentsondivisiveissues.
• Weuncoverpotentialmisalignmentbetweenhuman’sandLLM’spreferencesfordifferent
argumentationstyleswhileassessingconstructiveness.
• We reveal the potential risk of LLMs misrepresenting people’s views on divisive issues by
applyingpositivesentimenttotheircomments.
• Wediscussbothethicalanddesignconsiderationfordevelopingsocio-technicalsystemsthat
promoteconstructivediscourseondivisiveissuesacrossdifferentcultures.
2 RelatedWork
Wesituateourworkbyoutliningapproachestopromoteprosocialbehaviorsonlineandreviewing
thepotentialoflargelanguagemodels(LLMs)insupportingusersduringonlinedisagreements.We
thendiscusspriorresearchonconstructivediscourseandcross-culturalvariationsinargumentation.
2.1 PromotingProsocialDiscourseOnline
Designstrategiestofostercivildialogueonlinerangefromstaticapproacheslikeexplicitlylisting
rules[54]todynamicinterventions.Attheuserlevel,featuresthatprovidecontextualinformation,
suchasshowingalistofhigh-performingcommunitymembers[42]orsharedinterestsamong
interlocutors [77], encourage people to be polite. At the platform level, users favor options to
switchtheprivacysettingofconversationsfrompublictoprivatewhendiscussionsbecomeheated,
,Vol.1,No.1,Article.Publicationdate:November2018.4 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
expectingthiswoulddrawlessattentiontodisagreementandenablecivilexchanges[5].InNextdoor,
movingpopularpostsfrompublictoprivategroupshasledtomorecivilinteractionsandfewer
commentsthatgetflagged[48].
Additionally,researchershavedesignedinterventionstoimprovethequalityofcommentsonline.
Forexample,researchshowsthathighlightingtoxicityduringwriting[99]andpromptingpeople
toconsidertheiraudience[74]andrecipients’feelings[93]resultinmorepoliteandempathetic
comments.Providingspecificquestions[28]anddiscussionpoints[8]duringonlinedebateshelps
peoplewritecivilandfocusedcomments.Moreover,givingpeoplepositivestimuli[81],nudging
themtoreflectbeforepostingtheircomments[47],andmakingpeoplewaitbeforelettingthem
postcomments[63]alsofosterthoughtfulandprosocialdiscussions.Atthethreadlevel,surfacing
high-qualitycomments[6,97],signalingexistingtensionwithintheconversation[12],displaying
keypointsfromotherpeople’scomments[57],andprosandconsofdifferentviewsexpressedin
thethread[56]havebeenshowntoimprovefollow-updiscussions.
Whiletheseinterventionspromoteprosocialbehaviorsonline,theydonotguidepeopleonhow
toexpresstheirdisagreementsconstructively.Researchshowsthatpeopleoftenpreferpre-written
questions[35]andsentenceopeners[64]thathelpthemchallengeothersconstructivelyinsteadof
havingtowriteeverythingfromscratch.Inthiscontext,recentadvancesinLLMshaveopenedup
newavenuestosupportpeopleinonlineargumentation,whichwediscussnow.
2.2 LLMsforFacilitatingOnlineArgumentation
SeveralresearchershaveusedLLMsasamediatortoimproveonlineargumentation.Forexample,
Goversetal.[33]conductedanexperimentwithAmericanparticipants,wherepeoplereviewed
polarizingonlinethreadscontainingcommentsbothfrompublicandLLM-basedmediators.They
foundthathighlycooperativeandpersuasivestrategiesdeployedbymediator-botscouldsuccess-
fullychangereader’opinionsonpolarizingissues.Similarly,Tessleretal.[94]fine-tunedanLLM
tocraftopinionstatementsondivisivepoliticalissuesandfoundthatthisapproachcanhelpsmall
UK-basedgroupsfindcommongroundindemocraticdeliberation.
Apart from mediating discussions, LLMs have been used to provide users with actionable
recommendations during writing. For instance, Zhang et al. [109] designed a tool that helped
writersvisualizeandintegratedifferentelementsoflogicalargumentation(i.e.,claim,data,warrant,
backing, qualifier, and rebuttal) in their writing. They evaluated the system among US college
students,whofoundthetoolhelpfulforwritingargumentativeessays.Dingetal.[27]developed
alearningtoolfornativeEnglishspeakersintheUS,whicheducatedpeopleabouthatespeech,
brainstormedcounter-speechstrategieswiththem,andguidedthemtouseempathetictonewhile
challenginghatespeech.Participantsreportedthatthesystemboostedtheirconfidencetocallout
hatespeech.
Similarly,Xiaetal.[102]designedaninteractivevisualsystemthathighlightedwhichpersuasive
strategies(i.e.,logos,pathos,ethos,andevidence)wereeitherpresentormissinginusers’response,
benefitingnon-EnglishspeakingusersinwritingpersuasiveargumentsinEnglish.Argyleetal.[3]
conductedanexperimentwithAmericanparticipantswhereanLLMsuggestedpeopletorephrase
theirmessageeitherbymakingitpolite,restatingopposition’sarguments,orvalidatingopposition’s
sentiment.Theyfoundthatrephrasingusers’messagestosignalrespectfullisteningduringone-
on-onedebatescanimproveperceivedconversationquality,opennesstohearopposingviews,and
participants’senseofbeingunderstood.Kambhatlaetal.[44]curatedhuman-writtencommentson
controversialtopicsandreframedthosecommentsusingLLMtoincorporatereceptiveelements,
suchashedging,acknowledgment,elaboration,grounding,gratitude,oragreement.Whenshown
to US participants, they found the LLM-rephrased versions more receptive to opposing views
comparedtotheoriginalcomments.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 5
Whilethesestudiesemploydiverseapproachestoimprovingdiscussionondivisiveissues,very
fewactuallylookintohowtoenableuserstowritetheiropinionsconstructivelyduringonline
debates.ThehandfulofstudiesinvestigatingtheroleofLLMsinfacilitatingargumentativewriting
either focus on essays on a select topic [20, 58, 109], private one-on-one debates [3], or static
learningenvironments[27].Thesecontextsarequalitativelydifferentfromrespondingtoanonline
threadondivisiveissues,whichoftendrawshatefulinteractionsfromdifferentusers.Moreover,
existingstudiesonLLM-basedinterventionspredominantlyfocusonWesternpopulations,leaving
asignificantgapinunderstandinghowtofacilitateconstructivediscourseindifferentcultures[86].
Thisisparticularlyimportantbecausenotonlyamajorityofusersofonlineplatformsareinnon-
Westernregions,butalsobecauseLLMsareknowntoprioritizeWesternnormsandvalues[9,43]
andhomogenizewritingstowardsWesternstyles[1].Toaddressthisgap,weexamineifLLMs
canfacilitateconstructivediscourseondivisiveissuesindifferentculturalsettings.Indoingso,
wespecificallyfocuson“constructiveness”,asonlineplatformsroutinelymoderateandrankusers’
commentsbasedonconstructiveness[25,26]andoftenexplicitlyguideuserstobeconstructive[62].
Tothisend,webuilduponpriorworkonconstructivediscourseandcross-culturaldifferencesin
argumentation,whichwediscussnext.
2.3 ConstructivenessinOnlineDiscussion
SubjectiveInterpretation.Theconceptofconstructivenessvariesacrossdifferentcontexts.In
caseofstudentevaluation,peerreviews,andproductreviews,constructivecriticismisdefinedas
thosethataredeliveredrespectfullyandprovideactionablefeedbackforimprovement[31,100,105].
Incasesofdisagreement,constructiveconflictresolutionstrategiesinvolveshowingcooperative
attitudesandtrustwithconflictingparties[4,24].
Whenitcomestoonlinediscussion,therearesomeaddednuances.Forexample,Friessand
Eilders[32]articulatedconstructivedeliberationasfindingcommongroundandprovidingnew
solutions.KolhatkarandTaboada[51]conductedasurvey,wherepeopledescribedconstructive
commentsas“civildialoguethatarerelevant,targetspecificpoints,andprovideappropriateevidence.”
Othershavefocusedonoutcomestodefineconstructivedisagreements,suchaswhetherthedispute
is resolved [23] and improves the performance of team members [68]. While these definitions
emphasizethesubjectivenatureofwhatisconsideredconstructive,researchersinNaturalLanguage
Processing(NLP)havetriedtocapturethelinguisticfeaturesofconstructiveness,asoutlinedbelow.
LinguisticFeatures.Todetectconstructivefeatures,NLPresearchershaveanalyzedonlinecon-
versationsfromdifferentsources—suchasCNN[90],NewYorkTimes[52,90],YahooNews[51,67],
onlinegames[68],andWikipedia[23,107]—andreliedonhumanevaluationstoannotatethese
conversationsalongdifferentdimensions,suchastone,levelofagreement,andconstructiveness.
Theyalsousedquantitativemethodstoextractdifferentlinguisticfeatures(e.g.,toxicity,polite-
ness)fromtheseconversations,andusedstatisticalmodelingtoidentifysignificantpredictorsof
constructiveness.
FindingsfromNLPresearchersshowthatconstructivecommentstendtobemoreissue-relevant
[90]andcontributetothemainpointsintheconversation[52].Theyareusuallylongerinlength
andtakelongertowrite[52,90].Constructivecommentsaremorelikelytoshowdisagreementand
thus,containlesshedging(lesshesitation)andmatchedlanguage(lesssubordinate)[22,67,68].
They are more likely to contain argumentative features, such as discourse connectives, stance
adverbials,reasoningverbsandmodals,androotclauses[51,67].Additionally,respectfulattitude
anddifferentpolitenessstrategies,suchasgratitude,greetings,requests,anddeferenceareoften
observedinconstructivediscourse[23,67,107].Readabilityscores,presenceofsolutions,evidence,
personalstories[52],andnamedentities[53,68]arealsoindicativeofconstructiveness.
,Vol.1,No.1,Article.Publicationdate:November2018.6 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Thesefindingssuggestthatconstructivediscourserequiresbalancingargumentationwithpo-
litenesstoexpressdisagreementsassertively,withoutappearinghesitantorsubordinate.However,
thesefeaturesaremostlyderivedfromdiscussionsinWesternmediaoutletsandthequalityof
comments(e.g.,respectfulness,reasoning)ononlinenewswebsitesvaryalotdependingonthe
country’sattitudetowardsdeliberation[78].Therefore,welookintothecross-culturaldifferences
inhowpeopleapproachargumentationduringsocialconflicts,whichwediscussnext.
2.4 Cross-CulturalDifferencesInArgumentation
Researchshowsthatargumentationstylesdifferacrossindividualistic(e.g.,Westerncountries)and
collectivistcultures(e.g.,Asiancountries).PeoplefromcollectivistcultureslikeChina[103]and
India[36]viewargumentsaslesscivilandmorepersonal,andfeelpersecutedduringinterpersonal
disagreements.Duetohighpowerdistancewithinsuchcultures,peopleareeithermorelikelyto
avoiddissentorapproachitstrategicallycomparedtotheirAmericancounterparts[17,45].They
tendtobemorepolite,indirect,andexpresstheiropinionsinamoderateandcompromisingway
thanAmericansduringconflicts[37,39,71,76,91,95].Theyusuallyoptfordialecticalargumenta-
tion,i.e.,theyaremorereceptivetoopposingviews[75,76].Theyholisticallyconsidertherelations
amongdifferentperspectivesandaremorewillingtocompromisetoachieveamiddlegroundto
avoidconfrontation[14,69,76].
Incontrast,peoplefromindividualisticcultureslikeEuropeansandAmericansusuallyprefer
formal,rule-based,andlogicalreasoningintheirargument[70,71].Researchshowsthatargumen-
tativeessayswrittenbyAmericansusuallyfollowalinearpattern,whereeachclaimisfollowed
bysupportingideasandconcludingunits[15].Whenfacedwithcontradiction,Europeansand
Americanstypicallygravitatetowardspolarizingviewsinanefforttodeterminewhichfactor
positioniscorrect[69,76].Theyappearmoredirect,assertive,solution-oriented,anddominating
duringinterpersonalconflictsthanpeopleincollectivistcultures[95,96].
Together,thesefindingsshowthattherearesignificantcross-culturaldifferencesinhowpeople
approachargumentation.Althoughargumentativefeaturesarestronglyassociatedwithconstruc-
tiveness, there is no systematic study investigating constructive discourse across cultures. To
addressthisgapandconsideringthesupportpeopleneedtoexpresstheiropinionsconstructively,
weconductedastudywithparticipantsfromIndiaandtheUStoexamineifLLMscouldhelpthem
writeconstructivecommentsinresponsetoonlinethreadsondivisiveissues.
Givenargumentationstylesvaryacrosscultures[69]andLLMsareoftenbiasedtowardsWestern
values[9,43],wefirstinvestigatewhetherhumansandLLMsperceiveconstructivecomments
differentlybasedonargumentationstyle(logicalvs.dialectical)(RQ1).WethenexamineifLLMs
canhelppeoplewritemoreconstructivecommentsonsociallydivisiveissuesonline(RQ2).Lastly,
weexaminecross-culturaldifferencesinhowIndianandAmericanparticipantsperceiveandwrite
constructivecommentsonsociallydivisiveissues(RQ3).
3 Methods
Toaddressourresearchquestions,weconductedatwo-phasestudywithparticipantsfromboth
individualistic(e.g.,theUS)andcollectivistcultures(e.g.,India).Inthefirstphase,wecaptured
people’sperceptionsofconstructivecommentsonsociallydivisiveissuesonline.Inthesecond
phase,weaskedpeopletowriteconstructivecommentsonsociallydivisiveissuesonline.The
studyreceivedexemptionfrominstitutionalreviewboard(IRB)atourinstitution.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 7
3.1 Phase1:PerceptionsofConstructiveComments
Sincepriorresearchindicatesthatpeoplefromindividualisticculturespreferlogicalarguments,
whilethosefromcollectivistculturesfavordialecticalarguments,weexaminedinPhase1ifthe
perceptionofconstructivenessvariesdependingontheargumentationstyle.
SelectionofTopicsandOnlineThreads.Forourstudy,weselectedRedditthreadsrelatedto
homophobiaandIslamophobiaastheseissuesareconsideredsociallydivisivetopicsinboththe
USandIndia.Foreachcountry,wecuratedtwohomophobicandtwoIslamophobicthreads(see
Table11inAppendix),eachconsistingoftheoriginalpostandfourusercommentsfromrelevant
subreddits. The threads for American participants were drawn from r/conservative, r/politics,
r/atheism, and r/changemyview and all the threads for Indian participants were sourced from
r/IndiaSpeaks.AllthreadswereinEnglishand78%ofcommentsonthesethreadswerenegativein
sentiment(average:-0.63)andincludedseveralhighlynegativeandtoxiccomments.
GeneratingConstructiveCommentswithDifferentArgumentationStyles.Next,weused
GPT-4togenerateconstructivecommentsontheselectedthreadsforeachcountry.Sincehomo-
phobiaandIslamophobiaaredivisiveissues,wewantedtotakeintoaccountparticipants’personal
stanceonthesetopicswhentheywouldevaluateconstructiveness.Wethusgeneratedcomments
for two different stances—{against,supportive}—because these capture the two definitive and
opposingviewsofpeoplewhentheyengagewithsuchdivisivetopics.Consideringthecultural
orientation,wegeneratedconstructivecommentsfollowingtwodifferentargumentationstyles:
{logical,dialectical}.Intotal,wegeneratedcommentsfor2culturalcontexts{India,US}×2issues
{homophobia,Islamophobia}×2threads×2stances{against,support}×2argumentationstyles
{logical,dialectical}=32differentcases.
Toensurethatparticipants’responsesarenotsensitivetoparticularwordings,wegenerated
threedifferentcommentsforeachcase,resultingin32×3=96commentsintotal(48fortheUS,
48forIndia).Weusedzero-shot,culturalprompting(i.e.,specifiedthecountry)toincreasecultural
alignmentinLLM-generatedcommentsforbothcountries[92].WeinstructedGPT-4tokeepthe
commentswithin100words,whichistheaveragelengthofconstructivecommentsasobserved
inpriorstudy[52].Table1showsexamplesofconstructivecommentsgeneratedbyLLMwith
differentargumentationstyles,andTable12intheAppendixshowsdetailsonthepromptsusedto
generateconstructivecomments.
ValidatingArgumentationStyle.ToensurethatLLM-generatedcommentsindeedfollowed
logicalordialecticalargumentationstyles,weconductedavalidationstudywith230crowdworkers
fromMTurkinIndiaandtheUS.Wefirstaskedannotatorsabouttheirviewsonsame-sexmarriage
andIslam,usingadaptedinstrumentsfromPewresearchsurvey[7,11].Then,weshowedthem
either one randomly selected homophobic or Islamophobic thread, along with four randomly
selectedLLM-generatedcommentswrittenforthatthread.Weonlyshowedthemcommentsthat
alignedwiththeirstanceonhomophobiaorIslamophobia,toaccountforbiasesfromannotators’
personalopinionsontheseissues.Forannotators,whoreportedfeelingneutralabouttheissues,
werandomlyshowedthemcommentsthateithersupportedoropposedtheissue.
Weaskedparticipantstoannotateifagivencommentfollowedlogicalstep-by-steparguments
(logical)orholisticallyconsidereddifferentviewpointsandtookamiddle-ground(dialectical).Each
annotatorreviewedfourcommentsandreceived$1.00ascompensation.
Oncewegatheredatleastfiveannotationsforeachcomment,weexaminedtheagreementin
annotations.Forcommentsthatwerelabeledincorrectlyorwheretheannotatorsdidnotreach
agreement,wegeneratednewcommentsandrepeatedtheprocess.Wecontinuedthisprocessuntil
wehadatleasttwocommentsforeachofthe32cases,wherethemajorityannotationmatched
,Vol.1,No.1,Article.Publicationdate:November2018.8 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table1. ExamplesofLLM-generatedconstructivecommentswithdifferentargumentationstyles.
Logicalargumentation Dialecticalargumentation
Seriously,comparinghumanstoanimalsfor Irespecteveryperspective,butit’ssignificant
justifyinghomophobia?Humansdoalotof tounderstandthatthecruxofmarriageisnot
thingsanimalsdon’t.Everseenaliondrive justprocreationbutlove,commitment,and
acarorusetheinternet?Also,loveisn’t companionship.Marriage,whether
exclusivetooppositesexes.It’sabout heterosexualorhomosexual,shouldbeabout
Demographic:India connection,notreproduction.Secondly, emotionalbonding.Asforpreservingtradition,
Topic:Homophobia beinggayisn’tcontagious!Youcan’t‘turn’ cultureisnotastaticentitybutevolveswith
Stance:Supports akidgay.Furthermore,embracingallforms timeandsociety’sprogress.Lastly,equating
same-sexmarriage ofloveisn’t‘anti-traditional’.Traditions humanrelationshipswithanimalbehaviour
evolveovertime.Lastly,the‘naturallaw’ isn’tasoundcomparison.Changeisinevitable,
argumentisweaksauce-homosexualityis andacceptingloveinitsvariousformscanlead
observedinhundredsofspecies.Let’sstop toamoreinclusive,empatheticsociety.
dehumanizingLGBTQfolksandrespect Remember,rightsgranteddon’tmeanrights
theirrights. imposed.
Surely,radicalIslamisanabhorrentbrand Whileit’svitaltocritiqueoppressivepractices
ofextremismwithunjustifiableviews likeforcedconversionsandgenderinequality,
towardswomen,apostates,andnon-Muslims. paintingallMuslimswiththesamebrushis
Buthere’sthething;equatingallIslamwith harmfulandinaccurate.Yes,extremismexists
itsextremistelementisfundamentallyflawed inIslam,asitdoesinmanyotherreligionsand
Demographic:US
logic.It’sagrossgeneralizationfallacy-akin ideologies.However,attributingtheseactsto
Topic:Islamophobia
toclaimingallAmericanssupportpolice anentirefaithhampersmeaningfuldialogueand
Stance:Against
brutalitybecausesomedo.Moreover,it’s understanding.It’scrucialtodistinguishbetween
Islam
unjusttodemonizeanentirereligionforthe extremistswhomisusereligionforpersonalgain
actionsofafractionofitsfollowers.Thus, andthevastmajorityofpeacefulpractitioners.
whiletherearevalidreasonstocondemn Let’scontinuetoopposeextremismbutavoid
Islamicextremism,blanketingallMuslims blanketstatementsthatoversimplifycomplex
underthatbannerisneitherfairnoraccurate. issues.
Table2. ValidationoftheargumentationstylesinLLM-generatedcomments.
Numberof Numberofannotated Numberoffinalcommentswhere Annotationsper
Country
annotators comments majorityannotationmatchedtruelabel finalcomment
US 142 66 39 Avg:7.5(SD:3.6)
India 88 57 32 Avg:5.9(SD:2)
theactuallabels(SeeTable2).Intheend,wefinalized64comments(US:32,India:32),wherethe
argumentationstylesintheLLM-generatedcommentswerevalidatedbyhumanannotators.
ValidatingLevelofConstructiveness.ToverifyifLLM-generatedcommentsdifferedbeyond
theirargumentationstyles,weanalyzedthekeylinguisticfeaturesofconstructivenessasreported
inpriorwork[52,67,107].Theseare:commentlength,readabilityscore,presenceofpoliteness
strategies, named entities, and argumentative features, such as discourse connectives, stance
adverbials,reasoningverbsandmodals,androotclauses(seeTable3).
Weusedwordcountasameasureofcommentlength.Wecalculatedreadabilityscoresusing
SMOGindex(textstatlibraryinPython)asreportedinParketal.[74].Todetectpolitenessstrategies,
weusedpolitenesspackagefromR[106].WeusedspaCytodetectnamedentitiesincomments.
For argumentative features, we used GPT-4 to identify how frequently each feature appeared
inthecomments.DuetostatisticalvariabilityofLLM-generatedresponses,wemeasuredeach
argumentativecharacteristicfivetimesandusedtheaveragevalue.
Next,weanalyzedifLLM-generatedlogicalanddialecticalcommentsdifferfromeachotherin
anyofthelinguisticfeaturesandfoundnosignificantdifferences,suggestingthatthesecomments
differedfromeachotheronlyintheirargumentationstyle.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 9
Table3. Linguisticfeaturesofconstructivenessasreportedinpriorwork[52,67,107]
Features Associationwithconstructiveness
Length Longerinlength
Readabilityscore Highlevelsofreadability
Politeness Respectfulandusesdifferentpolitenessstrategies
Namedentities Containsnamedentities
Greaterpresenceof
1.discourseconnectives(e.g.,therefore,dueto)
Argumentative 2.stanceadverbials(e.g.,ofcourse,undoubtedly)
features 3.reasoningverbs(e.g.,cause,lead,)
andmodals(e.g.,may,should)
4.rootclauses(e.g.,Ithinkthat)
RQ1:CapturingPerceptionsofConstructiveness.Toexamineifthenotionsofconstructiveness
differbetweenhumansandLLM(RQ1),weconductedaforced-choiceexperimentwith103crowd
workersfromProlific(US:51,India:52).Intheexperiment,participantsweregivenarandomly
selectedhomophobicorIslamophobicthread.Thecommentsinthethreadappearedinrandom
order with redacted user names and profile photos (see Figure 6 in the Appendix). Given the
toxicityinthesethreads,wewarnedparticipantsthattheymightgetexposedtonegativecomments
beforetheyacceptedthetaskandgavethemtheoptiontoquitthestudyatanypointiftheyfelt
uncomfortableengagingwithsuchcontent.
Theparticipantswerethenpresentedwithfourpairsofrandomlychosencommentswhereeach
pair contained an LLM-generated logical and a dialectical comment for the same thread. Each
participantsaweachcommentinonlyonepair,andtheorderofcommentswithineachpairwas
randomized.Amongthefourpairs,twoconsistedofcommentsopposingtheissue,whiletheother
twopairsconsistedofcommentssupportingtheissue.Thisway,participantswereexposedto
commentsthatdidnotalignwiththeirpersonalstances,asiscommoninonlineplatforms.Since
bothcommentswithinapairsharedthesamestance,participantswerenotbiasedtowardselecting
thecommentthatmatchedtheirviews.
Wethenaskedparticipantstoindicatewhichcommenttheyperceivedasmoreconstructivein
eachpairandwhy.Wegavethemseveraloptionsadaptedfromthecharacteristicsofconstructive
commentsanddifferentargumentationstylesasdescribedintheliterature[52,90,95,96].These
characteristicswerealsoconsistentwithopen-endedexplanationsthatparticipantsprovidedina
smallpilot(US:27,India:22)precedingthemainexperiment:
• Morerelevanttotheoriginalconversation
• Usesbetterlogicandfactstosupportarguments
• Balancesdifferentviewpointsbetter
• Usesmorepoliteandrespectfullanguage
• Other(pleasedescribe):
WethenrepeatedthesameprocesswithGPT-4.ParticipantsinIndiaandtheUSreviewedthreads
thatwererelevanttotheirculturalcontexts,whileGPT-4reviewedthreadsfrombothcountries.
Table4showsthedemographicdetailsoftheparticipants.Intotal,103peopleparticipatedinthe
study.Weremovedresponsesfromfourparticipants,whofailedtheattentioncheck.Participants
received$1forcompletingthetask.WeconductedmultipleChi-squaretestswithBonferronicorrec-
tionstoanalyzetheresponsesfrombothparticipantsandGPT-4toseewhethertheirperceptions
ofconstructivenessdifferornot.
,Vol.1,No.1,Article.Publicationdate:November2018.10 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table4. DemographicdetailsofparticipantsevaluatingconstructivecommentsinPhase1.
Demographic(n) Age(years) Gender Viewsonsame-sexmarriage ViewsonIslam
Against:29% Against:31%
Female:48%
US(n=50) 43.92(SD:11.68) Neutral:8% Neutral:27%
Male:52%
Support:63% Support:42%
Against:29% Against:60%
Female:44%
India(n=49) 29.08(SD:8.75) Neutral:25% Neutral:12%
Male:56%
Support:46% Support:28%
3.2 Phase2:WritingConstructiveComments
WenextexaminedifLLMscouldhelpIndianandAmericanparticipantswriteconstructivecom-
mentsondivisivesocialissues,suchashomophobiaandIslamophobia.
WritingTask.Wedesignedabetween-subjectsexperimentwhereparticipantswererandomly
assignedtoeitheracontrolortestgroup.Withineachgroup,participantswerefirstaskedabout
their views on same-sex marriage and Islam (using the same instrument from Phase 1). Then
theywereshownonerandomlyselectedhomophobicandoneIslamophobicthreadrelevantto
theirculturalcontexts.Werandomizedtheorderofthethreadsandaskedparticipantstowrite
aconstructivecommentforeachthread.Sinceconstructivecommentstendtobelonger[52,90],
we asked the participants to write a comment that is at least 50 words long. We also disabled
copy-pastesothatparticipantscouldnotlookupthethreadsonlineandsubmitcopiedresponses.
Inthecontrolgroup,participantswereaskedtowriteconstructivecommentsontheirown
without external assistance (e.g., the Internet or ChatGPT). In the test group, we instructed
participantstowriteaninitialdraftbeforerequestinghelpfromanLLM(GPT-4)(seeFigure1).
Oncetheywroteadraft,theycouldselectfromalistofpromptsorprovidecustompromptforthe
LLMtorewritetheircommentconstructively.Thepromptswerecreatedtoreflectcharacteristics
ofconstructivecommentsandlogicalanddialecticalargumentation,asdescribedinpriorwork[52,
90,95,96]:
• Makemycommentrelevanttotheconversation
• Uselogicandfactstomakestep-by-stepargument
• Presentsolutionstoaddresstheissue
• Balancecontrastingviewsandtakemiddleground
• Usepoliteandrespectfultone
• Other(writeyourownprompt):
Werandomizedtheorderofthepromptstoavoidprimacyandrecencybias.Toensurethat
participantsinthetestgroupusedLLMwhilewritingconstructivecomments,theywererequired
toprompttheLLMatleastoncebeforecompletingthewritingtask.Furthermore,participants
hadtowriteatleast20wordsbeforerequestingsuggestionsfromtheLLMtoensurethatthese
commentswereindeedgeneratedviahuman-AI(HAI)collaboration.WeusedGPT-4torewrite
participant’scommentonthegiventhreadinreal-timeusingthefollowingprompt:
ConsiderthefollowingRedditthread:
<insertthread>
An<Indian,American>participant,whothink<insertstance>of<homophobia,Islamo-
phobia>wrotethefollowingcommentinresponsetotheabovethread.
<insertparticipant’scomment>
Makethecommentconstructiveusingfollowingprompts.
<insertpromptsselectedbytheparticipant>
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 11
Fig.1. Theinterfaceforco-writingconstructivecommentswithAI(LLM)inthetestgroup.Participants
first wrote their comment in the User Input box. They could select one or more prompts from the AI
Interfacetomaketheircommentsconstructive.GPT-4thenrewroteparticipant’scommentinreal-time,
whichwouldappearintheAISuggestionbox.Participantsneededtoeitheraccept,reject,regenerate,or
editAI’ssuggestionbeforesubmittingtheirfinalcommentorpromptingAIagain.Theycouldrepeatthe
processasmanytimesasneededbeforesubmittingtheirfinalcomment.Theexampleshownisbasedona
commentwrittenbyanAmericanparticipantinresponsetoanIslamophobicthread.
Table5. Demographicdetailsofparticipants,whocompletedthewritingtaskinPhase2.
Demographic(n) Age(years) Gender Viewsonsame-sexmarriage ViewsonIslam
Female:60% Against:15% Against:23%
US(n=52) 38.79(SD:13.19) Male:38% Neutral:10% Neutral:29%
Transgender:2% Support:75% Support:48%
Against:43% Against:45%
Female:27%
India(n=51) 28.63(SD:7.88) Neutral:22% Neutral:8%
Male:73%
Support:35% Support:47%
AfterreceivingthesuggestionfromtheunderlyingLLM,participantscouldeitheraccept,reject,
regenerate,oreditthecommentbeforetheycoulduseanotherprompt.Onceparticipantswere
satisfiedwiththefinaloutput,theycouldsubmitittofinishthetask.
Post-WritingSurvey.PriorstudyshowsthattheeaseofwritingwithLLMsoftendiminishes
thesenseofownershippeoplefeelwiththeirwriting[49].Therefore,afterfinishingthewriting
task,participantsinbothgroupswereaskedtoreflecthowmuchownershipandsatisfactionthey
feltwiththefinalcommentsona5-pointLikertscale.Theywerealsoaskedtoratethedifficulty
of writing constructive comments. In addition, participants in the test group were shown one
LLM-generatedsuggestionthattheyeitheraccepted,rejected,regenerated,oreditedandwere
askedthereasonbehindtheiraction.
ParticipantRecruitment.Tocompletethewritingtask,werecruited52Indianand52American
crowdworkersfromProlific,whodidnottakepartinPhase1.Table5showsthedemographic
detailsoftheparticipants.Wecompensatedparticipantswith$1.70forcompletingthewritingtask.
Overall,wecollected104human-writtencommentsfromthecontrolgroupand102human-AI
(HAI)writtencommentsfromthetestgroup.
HumanEvaluationofConstructiveness.Wenextconductedasurveytoexaminewhichtype
of comment people perceived as more constructive: those written by humans (control group),
human-AI(HAI)collaboration(testgroup),orsolelygeneratedbyLLM(Phase1).
Werecruited82Indianand82AmericancrowdworkersfromProlific,whohadnotparticipated
inbothPhase1andthewritingtaskinPhase2.Eachparticipantwasshownarandomlychosen
,Vol.1,No.1,Article.Publicationdate:November2018.12 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
homophobicorIslamophobicthreadrelatedtotheirculturalcontext.Then,theywereaskedto
reviewfourpairsofrandomlychosencommentsthatwerewrittenforthesamethreadfromthe
same stance. Each pair could either include (HAI vs. Human), (Human vs. AI), or (HAI vs. AI)
comments.
Eachparticipantsaweachcommentonlyinonepairandwerandomizedtheorderofcomments
withineachpair.Weaskedparticipantstoselectwhichcommenttheyperceivedasmoreconstructive
withineachpair.Weensuredthateachcommentwasreviewedbyatleastthreeparticipants.Since
thenumberofhuman-written,HAI-written,andLLM-generatedcommentsvariedforthesame
threadandsamestance,someparticipantsmighthavereviewedcertaintypesofpairsmorethan
once.Intotal,wereceived727humanevaluationsfrom157participantsafterdiscardingresponses
from7participants,whofailedtheattentioncheck.Participantswerecompensatedwith$1.00for
completingthetask.
QuantitativeAnalysis.Next,weanalyzedthekeylinguisticfeaturesofconstructiveness(see
Table3)incommentswrittenbyhumans(control)andthoseviahuman-AIcollaboration(test).We
followedthesameprocedureasinPhase1wherewedetectedthesefeaturesinLLM-generated
comments.
Forthetestgroup,wealsoanalyzedhowincorporatingLLM’ssuggestionsimpactedthequality
ofcommentsbycomparingparticipants’initialdraftswiththeirfinalsubmissions.Specifically,we
comparedthelinguisticfeaturesofconstructiveness,sentiment,andtoxicitybetweeninitialand
finalcomments.Toanalyzesentiment,weusedVADERsentimentanalysistoolasitisattuned
to sentiments expressed in social media [40]. To detect toxicity, we used Google’s Perspective
API.Wealsocalculatedcosinesimilarity,semanticsimilarity,andBERTScore[108]betweenthese
pairsofcomments.Forcosinesimilarity,weusedCountVectorizerfromscikit-learn1.Forsemantic
similarity,weusedall-MiniLM-L6-v2sentencetransformer2fromHuggingFace.ForBERTScore,
weusedcontextualembeddingsinBERTmodel3fromHuggingFace.
4 Findings
WefirstdescriberesultsfromPhase1toanswerhowperceptionsofconstructivenessvarybetween
humansandLLMs(Section4.1).Wethenpresentouranalysesofthecommentsparticipantswrote
inPhase2toexamineifanLLMcouldhelppeoplewriteconstructivecommentsondivisivesocial
issues(Section4.2).Finally,wecomparetheresponsesfromIndianandAmericanparticipantsin
bothPhase1andPhase2toexaminecross-culturaldifferencesinconstructiveness(Section4.3).
4.1 RQ1:DoPerceptionsofConstructivenessDifferBetweenHumansandLLMs?
PerceptionsofConstructiveness.InPhase1,participantsreviewed396pairsoflogicalanddialec-
ticalcomments,andGPT-4reviewed454suchpairs.Binomialtestsrevealedthatbothparticipants
andGPT-4preferreddialecticalcommentswaymorethanlogicalcomments,whichsignificantlydif-
fered(𝑝 <0.000001)fromthehypothesizedproportion(50%).GPT-4selecteddialecticalcomments
asmoreconstructivethanlogicalonesin84%ofcases(seeFigure2A).Incomparison,participants
reporteddialecticalcommentsasmoreconstructivein68%ofcases.
Achi-squaretestwithYates’continuitycorrectionrevealedsignificantdifferenceintheperception
ofconstructivenessbasedonargumentationstylebetweenhumansandGPT-4(𝜒2(1,𝑁 =850) =
28.52,𝑝 < 0.00001,𝜙 = 0.18, odds ratio=2.46), with a small effect size. GPT-4’s perception of
1https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html
2https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2
3https://huggingface.co/docs/transformers/en/model_doc/bert
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 13
100 (A) (B)
**** Better logic and facts to support arguments
75 Takes a better solution−oriented approach
50 More polite and respectful language
25 Balances different viewpoints better *
More relevant to conversation
0
Logical Dialectical 0 10 20 30 40
Argumentation style More constructive (%)
AI Human
Fig.2. (A)PerceptionsofconstructivecommentsbetweenhumansandLLMbasedonargumentationstyle.
(B)PerceivedcharacteristicsofconstructivecommentsreportedbybothhumansandLLM.Statistically
significantdifferencesarereportedat𝑝 <0.00001(****),𝑝 <0.0001(***),𝑝 <0.001(**),and𝑝 <0.01(*)
[adjustedP-valuesafterBonferronicorrection].
constructivenessalsodifferedsignificantlyfromthatofbothAmericanandIndianparticipants
whovieweddialecticalcommentsasmoreconstructivein73%and65%ofcases,respectively.
PerceivedCharacteristicsofConstructiveness.WhenweaskedparticipantsandGPT-4why
theythoughttheirchosencommentwasmoreconstructivethantheother,onaveragetheyselected
threecharacteristicsfromtheoptionsgiventothem(SeeFigure2B).Whileassessingconstructive
comments,participantsprioritizedtheuseoflogicandfacts(21%)andpresenceofsolutions(23%)
morethanotherfactors.Incontrast,GPT-4focusedmoreonhowwellthecommentsbalanced
differentviewpoints(25%)andmaintainedapolitetone(24%).
A chi-square test with Yates’ continuity correction revealed a significant difference in the
perceivedcharacteristicsofconstructivecommentsbetweenparticipantsandGPT-4(𝜒2(4,𝑁 =
2824) = 45.68,𝑝 < 0.00001,𝜙 = 0.13), with a small effect size. Post-hoc tests with Bonferroni
correctionsshowedthatGPT-4associatedtheuseofpoliteandrespectfullanguage(24%ofcases)
andbalancingdifferentviewpoints(25%ofcases)withconstructivenesssignificantlymorethan
theparticipants(18%ofcasesforbothcharacteristics).Thesecharacteristicsareassociatedwith
dialecticalargumentationandconstructivediscourse,whichalignwithGPT-4’sgreaterpreference
for dialectical comments as constructive. In contrast, participants prioritized the presence of
argumentativelogicandfacts(21%ofcases)significantlymorethanGPT-4(13%ofcases)while
assessingconstructiveness.
Together,thesefindingsindicatepotentialmisalignmentintheperceptionsofconstructiveness
between humans and LLM. While both viewed comments with dialectical arguments as more
constructivethantheoneswithlogicalarguments,GPT-4was2.46timesmorelikelytoconsider
dialecticalcommentsasmoreconstructivethanthehumanparticipants.GPT-4alsohadsignificantly
differentperceptionsofwhatmakesanonlinecommentconstructive.Thesedifferencescouldimpact
people’sengagementwithLLMwhilewritingconstructivecommentsondivisivesocialissues,
whichweexaminenext.
4.2 RQ2:CanLLMHelpPeopleWriteConstructiveComments?
In Phase 2, we collected 104 human-written comments (control group) and 102 HAI-written
comments(testgroup)onhomophobicandIslamophobicthreads.Additionally,wehad64LLM-
generatedcommentsfromPhase1forthesethreads.Wenowpresentouranalysisofthesecomments.
,Vol.1,No.1,Article.Publicationdate:November2018.
)%(
evitcurtsnoc
eroM
scitsiretcarahC
****
**14 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table6. MultipleChi-squaretestswithBonferronicorrectionscomparingpeople’sperceptionsofconstruc-
tivenessacross(HAIvs.Human),(Humanvs.AI),and(HAIvs.AI)comments.
Commentpairs Bothdemographic India US
(HAIvs.AI) - - -
(Humanvs.AI): 𝜒2(1,𝑁 =282)=65.59, 𝜒2(1,𝑁 =148)=19.70, 𝜒2(1,𝑁 =134)=47.76,
LLM-generatedcommentsperceivedasmore 𝑝<0.000005,𝜙=0.48 𝑝<0.000005,𝜙=0.36 𝑝<0.000005,𝜙=0.60
constructivethanhuman-writtencomments
(HAIvs.Human): 𝜒2(1,𝑁 =802)=62.56, 𝜒2(1,𝑁 =205)=39.96, 𝜒2(1,𝑁 =392)=22.54,
HAI-writtencommentsperceivedasmore 𝑝<0.000005,𝜙=0.28 𝑝<0.000005,𝜙=0.31 𝑝<0.000005,𝜙=0.24
constructivethanhuman-writtencomments
All USA India
100 100 100
**** **** **** **** **** ****
75 75 75
50 50 50
25 25 25
64% 36% 74% 26% 56% 44% 62% 38% 81% 19% 59% 41% 66% 34% 69% 31% 51% 49%
0 0 0
(HAI, Human) (Human, AI) (HAI, AI) (HAI, Human) (Human, AI) (HAI, AI) (HAI, Human) (Human, AI) (HAI, AI)
AI HAI Human
Fig.3. People’sperceptionsofconstructivenessacross(Humanvs.AI),(HAIvs.Human),and(HAIvs.AI)
commentpairs.Statisticallysignificantdifferencesarereportedat𝑝 < 0.000005(****),𝑝 < 0.00005(***),
𝑝 <0.0005(**),and𝑝 <0.005(*)[adjustedP-valuesafterBonferronicorrection].
4.2.1 Who Writes Constructive Comments Better? To examine whether comments written by
humans,human-AIcollaboration,orLLM(AI)aremoreconstructive,weusedhumanevaluations
andanalyzedlinguisticfeaturesofconstructivenessinthecommentsinourset.
Human Evaluation of Constructiveness. A total of 157 participants evaluated 727 pairs of
comments,whichincluded401pairsof(HAIvs.Human),141pairsof(Humanvs.AI),and185
pairsof(HAIvs.AI)comments.
Participantswhoassessed(Humanvs.AI)commentsfoundLLM-generatedcommentsmore
constructivethanhuman-writtencommentsinthemajorityofcases(74%).MultipleChi-squaretests
withBonferronicorrections(seeTable6)revealedasignificantdifferenceinpeople’sperceptions
ofconstructiveness,withamediumeffectsize(𝜒2(1,𝑁 = 282) = 65.59,𝑝 < 0.000005,𝜙 = 0.48,
oddsratio=8.51).For(Humanvs.AI)pairs,LLM-generatedcommentswere8.51timesmorelikely
tobechosenasconstructive.BothIndianandAmericanparticipantsalsofoundLLM-generated
commentssignificantlymoreconstructivethanhuman-writtencommentsin69%and81%ofcases,
respectively(seeFigure3).
Similarly,participants,whoreviewed(HAIvs.Human)commentsfoundHAI-writtencomments
significantlymoreconstructivethanhuman-writtencommentsin64%ofcases,withsmalleffect
size(𝜒2(1,𝑁 =802) =62.56,𝑝 <0.000005,𝜙 =0.28,oddsratio=3.19).Participantswere3.19times
morelikelytopreferHAI-writtencommentsasconstructivecomparedtohuman-writtencomments.
BothIndianandAmericanparticipantssignificantlypreferredHAI-writtencommentstothose
solelywrittenbyhumansin66%and62%ofcases,respectively(seeFigure3).
Ontheotherhand,thosewhoreviewed(HAIvs.AI)commentpairsconsideredLLM-generated
commentsasconstructiveonlyin55%ofcases.Wedidnotnoticeanysignificantdifferencebetween
participants’preferencesforLLM-generatedandHAI-writtencomments.
,Vol.1,No.1,Article.Publicationdate:November2018.
)%(
evitcurtsnoc
eroM
)%(
evitcurtsnoc
eroM
)%(
evitcurtsnoc
eroMExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 15
200 **** 50 15 **** ****
40 20
10
150 30 ****
20 5 10 100
10
0
50 0 0
AI HAI Human AI HAI Human AI HAI Human AI HAI Human
12 **** * 6 ******* ******* 8 ****
**** 6 9 **** ****
4 6 4
6 4 2 2
3 2
0 0
0 0
AI HAI Human AI HAI Human AI HAI Human AI HAI Human
AI HAI Human
Fig.4. FeaturesofconstructivenessacrossLLM-generated,human-written,andHAI-writtencomments.The
blackdotsrepresenttheaveragevalue.Statisticallysignificantdifferencesarereportedat𝑝 <0.000001(****),
𝑝 <0.00001(***),𝑝 <0.0001(**),and𝑝 <0.001(*)[adjustedP-valueafterBonferronicorrection].
Insum,thesefindingssuggestthatcommentsthatareeitherfullygeneratedbyLLMorco-written
byhumanandLLMwereviewedasmoreconstructivebypeoplethanthosewrittenbyhumans
alone.
LinguisticFeaturesofConstructiveness.Toexaminehowfeaturesofconstructivenessvary
among LLM-generated, human-written, and HAI-written comments, we computed values for
differentlinguisticfeaturesandconductedmultiplepairwiseMann-WhitneytestswithBonferroni
corrections(seeTable13inAppendix).WefoundthatLLM-generatedcommentshadsignificantly
morelinguisticfeaturesofconstructivenessthanbothhuman-writtenandHAI-writtencomments
(see Figure 4). The effect size ranged from medium to large. LLM-generated comments were
significantly longer and included more argumentative features, such as discourse connectives,
stanceadverbials,reasoningverbsandmodals,androotclauses,comparedtobothhuman-written
andHAI-writtencomments.
HAI-written comments also contained significantly more discourse connectives and stance
adverbialsthanhuman-writtencomments.WenotedthatbothLLM-generatedandHAI-written
commentshadsignificantlyhigherreadabilityscore(asmeasuredbySMOGindex)thanhuman-
writtencomments.ThissuggeststhatcommentseitherfullygeneratedbyLLMorcollaboratively
writtenwithLLMhavebetterwordingandsentencestructurethanhuman-writtencomments.
TimeTakentoWriteConstructiveComments.ParticipantswhowrotecommentswithLLM
(testgroup)tooklesstime(average:5.17minutes)towriteconstructivecommentsthanthosewho
wroteeverythingontheirownincontrolgroup(average:6.71minutes).AMann-Whitney’sUtest
revealedasignificantbutsmalleffectofLLMinterventiononthetimetakentowriteconstructive
comments(𝑊 = 4071,𝑍 = −2.88,𝑝 < 0.01,𝑟 = 0.2).Whilethisisinlinewithpriorfindings[49]
whichshowthatpeopleareabletowritefasterwiththehelpofLLM,ourworkresultsshowthat
notonlydopeoplewritefasterbutalsomoreconstructivelywiththehelpofLLMs.
4.2.2 HowdoesCo-WritingwithLLMChangetheQualityofComments? Participantsinthetest
groupinitiallydraftedacommentbeforeusingLLMtomakeitmoreconstructive.Wenextcompared
theinitialdraftswrittenbyhumanstofinalHAI-writtencommentsubmittedbythem.Wefound
,Vol.1,No.1,Article.Publicationdate:November2018.
)tnuoc
drow(
htgneL
esruocsid
fo rebmuN
sevitcennoc
ssenetilop
fo rebmuN
ecnats
fo rebmuN
srekram
slaibrevda
deman
fo
rebmuN
gninosaer
fo rebmuN
seititne
sladom
dna sbrev
erocs
ytilibadaeR
sesualc
toor
fo rebmuN16 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table7. Differentpromptsusedbyparticipantstomaketheircommentsconstructiveinthetestgroup
Prompts Used(%)
Makethecommentrelevanttotheconversation 23
Uselogicandfactstomakestep-by-stepargument 23
Presentsolutionstoaddresstheissue 18
Balancecontrastingviewsandtakemiddleground 12
Usepoliteandrespectfultone 23
Customprompt 1
thatparticipantsrequestedassistancefromLLM138timestowrite102constructivecomments
using300promptsintotal(average:2.88,SD:2.36).Almostallparticipantschosethegivenprompts
(see Table 7). They prioritized relevance, use of logic, and politeness to make their comments
constructive.Onlythreeparticipantswrotecustomprompts,suchas:‘Makethemsounddumbfor
beingsobigoted’,‘Bepassiveaggressive’,‘Makeitlessrude’,and‘Makethecommentkind.’
ContentSimilarity.WefirstexaminedtowhatextenttheunderlyingLLMchangesthecontentof
thecommentsthatparticipantsinitiallywrotetotheonestheysubmittedfinallythroughhuman-AI
collaboration.Inthetestgroup,87participantsincorporatedLLM’ssuggestioninthefinalcomments
theysubmitted.Wecalculatedsemanticsimilarity,BERTScore[108],andcosinesimilaritybetween
eachparticipant’sinitialdraft(beforerequestinghelpfromLLM)andtheirsubmittedcomment
(LLM-rewrittenversion)toexaminetowhatextentLLMchangedpeople’swriting.Allthesescores
areonascaleof0to1andhighervaluesindicategreatersimilarity.
Wefoundthattheaveragesemanticsimilaritybetweenthesecommentswas0.67,indicatingLLM
couldpotentiallyretainthemeaningsofinitialcommentsthatparticipantswrotethemselves(see
Figure5A).Similarly,theaveragehighBERTScoreof0.87indicatethattheLLM-rewrittenversions
closelyalignedwiththemeaningsininitialcomments.However,theaveragecosinesimilarity
betweenthesecommentswas0.38,indicatingpotentialdifferencesbetweenthewordingofthese
comments.Forexample,ouranalysisfoundthatLLM-rewrittenversionofparticipants’comments
weresignificantlymorepositiveandlesstoxic(averagesentimentscore:0.67,toxicityscore:0.08)
comparedtotheinitialcommentspeoplewrote(averagesentimentscore:0.12,toxicityscore:0.18)
(seeFigure5B–C).
LinguisticFeaturesofConstructiveness.WealsoanalyzedhowLLMaffectedthelinguistic
featuresofconstructivenesswhilerewritingparticipants’comments(seeTable14inAppendix).
WefoundthatLLM-rewrittenversionsweresignificantlylonger(averagelength:73words)than
the initial comments (average length: 49 words) and the effect size was large (see Figure 5D).
Additionally, the LLM integrated significantly more argumentative features, such as discourse
connectives, stance adverbials, reasoning verbs and modals, and root clauses while rewriting
participants’comments,withmediumtolargeeffectsize(seeFigure5H–K).Wealsofoundthat
LLMmadeparticipants’commentssignificantlymorepolite(averagescore:12.44)thantheirinitial
drafts(averagescore:9.86),withmediumeffectsize(seeFigure5E).LLM-rewrittencommentsalso
hadsignificantlyhigherreadabilityscore(average:14.79)thantheinitialdraftsparticipantswrote
(averagescore:5.85),exhibitinglargeeffectsize(seeFigure5G).Thesedifferencessuggestthat
LLMcouldpresentparticipants’responsesmoreconstructivelythantheycoulddoontheirown.
4.2.3 Does Co-Writing Comments with LLM Lead to Homogeneity? Recent studies have found
thatLLM-assistedwritingtoolshomogenizeoutputs,i.e.,differentusersrelyingonthesameLLM
may produce more similar writing than they would without such assistance [55]. To examine
whetherco-writingconstructivecommentswithLLMleadstohomogenity,weanalyzedthecosine
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 17
1.00 (A) **** (B) **** (C)
0.75
0.75 1
0.50
0.50 0
0.25
0.25
−1
0.00
Cosine Semantic BERT
similarity similarity Score Initial (Human) Final (HAI) Initial (Human) Final (HAI)
150 **** (D) * (E) (F) **** (G)
40 15 20
100 30
10 20 10
50 5 10
0
0 0 0
Initial (Human) Final (HAI) Initial (Human) Final (HAI) Initial (Human) Final (HAI) Initial (Human) Final (HAI)
8 **** (H) 4 **** (I) 6 **** (J) 6 **** (K)
6 3 4 4
4 2
2 1 2 2
0 0 0 0
−2
Initial (Human) Final (HAI) Initial (Human) Final (HAI) Initial (Human) Final (HAI) Initial (Human) Final (HAI)
Initial (Human) Final (HAI)
Fig.5. Comparisonbetweendifferentcharacteristicsofcommentsthatparticipantsinitiallywrotethemselves
inthetestgroupandthecommenttheysubmitted,wheretheyusedLLM’ssuggestion.Theblackdotsrepresent
theaveragevalue.Statisticallysignificantdifferencesarereportedat𝑝 <0.000001(****),𝑝 <0.00001(***),
𝑝 <0.0001(**),and𝑝 <0.001(*)[adjustedP-valueafterBonferronicorrection].
similarity,semanticsimilarity,andROUGE-L[73]scoresamongHAI-writtencommentswrittenon
thesamethreadbydifferentparticipantswhosharesamestance.Werepeatedthesameanalysis
forhuman-writtencommentsinthecontrolgrouptoestablishourbaseline.
Wefoundthatthecosinesimilarityandsemanticsimilarityinfinalcommentswrittenbypartici-
pantsinthetestgroupwerecomparabletothesimilarityscoresofcommentswrittenbyparticipants
inthecontrolgroup(seeTable8).MultipleMann-WhitneyUtestswithBonferronicorrectionsdid
notshowsignificantdifferenceinthesemetricsbetweencontrolandtestgroups.Thisindicates
thatevenwhenparticipantstookLLMs’assistancetowriteconstructivecommentsonthesame
thread from the same stance, the overlap in both word choice (cosine similarity) and meaning
(semanticsimilarity)amongtheircommentsweresimilartotheoverlapobservedincomments
writtenwithouttheassistanceofLLM.
The ROUGE-L score (i.e., longest common subsequence) among human-written comments
(average:0.18)wassignificantlyhigherthanthatofHAI-writtencomments(average:0.16).This
suggeststhatparticipantsinthecontrolgrouphadgreateroverlapintheircommentscomparedto
theparticipantsinthetestgroupwhoco-wrotecommentswithLLM.Infact,bothdistinct-2score
andtypetokenratio(TTR)weresignificantlyhigherfortheHAI-writtencomments,signaling
greaterdiversityofvocabularyinthesecomments.Together,thesefindingssuggestthatusingLLM
towriteconstructivecommentsonsociallydivisiveissuesmaynotnecessarilyleadtohomogeneous
,Vol.1,No.1,Article.Publicationdate:November2018.
serocs
ytiralimiS
)tnuoc
drow(
htgneL
esruocsid
fo rebmuN
sevitcennoc
ssenetilop
fo
rebmuN
ecnats
fo
rebmuN
srekram
slaibrevda
erocs
tnemitneS
deman
fo
rebmuN
gninosaer
fo rebmuN
seititne
sladom
dna
sbrev
erocs
yticixoT
erocs
ytilibadaeR
toor
fo
rebmuN
sesualc18 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table8. ResultsfromMann-WhitneyUtestswithBonferronicorrectionsfordifferentmetricstoassess
homogeneityinHAI-writtencomments.
Human-written HAI-written
Metric Statistics
comments(control) comments(test)
Cosinesimilarity - 0.33 0.30
Semanticsimilarity - 0.41 0.42
Rogue-L U=42029,Z=-3.73,p<0.001,r=0.16 0.18 0.16
Distinct-2 U=2153.5,Z=6.88,p<0.000001,r=0.50 0.97 0.99
Typetokenratio U=1247.5,Z=8.66,p<0.000001,r=0.63 0.79 0.88
discourseonline.Thisiscriticalbecauseoverwhelmingagreementandhomogeneityinonline
threadsdiscouragepeoplefromengagingwiththatthread[34].
4.2.4 How did People Interact with LLM while Co-Writing Comments? We next examined how
participantsengagedwiththechangesLLMmadetotheirinitialdrafts.Wequantitativelyanalyzed
theirinteractionlogsandperformedqualitativeanalysesontheopen-endedreasonsparticipants
gaveforaccepting,editing,rejecting,orregeneratingtheLLM’ssuggestions.
Acceptance.Inmostcases(62%),participantsacceptedLLM-generatedsuggestionsandreported
thatthesuggestionscapturedtheirmainpointsclearly(𝑛 =18).Participants(𝑛 =9)reportedthat
LLM-generatedversionsweremorepersuasive,well-worded(higherreadabilityscoreasobserved
in 4.2.2), and “presented cohesive arguments with actionable insights.” Some participants (n=4)
appreciatedthatAIsavedtheirtimeandeffort,notingthatitwouldtakethemsignificantlylonger
to“refinetheirthoughts” iftheyweretowriteconstructivelyontheirown.Others(𝑛 =4)valued
thepolitelanguageandimpartialtoneincontentre-writtenbyLLM.AnAmericanparticipant
wrote:
IlikeAIassistancebecauseitremovesmyownpotentialbiasinthesesettings.Ithinkbeing
dismissiveanddefensiveisneverforwardthinking.Itisnicetoremovesomeemotional
substancewhenitisnotneeded.
Editing.In9%ofcases,participantseitherdeletedsomepartsofLLM-generatedcontent,changed
wording(e.g.,replaced‘same-sex’with‘gay’,‘concur’with‘agree’),oraddednewcontent.They
explainedthattheyfoundthecontentgeneratedbyLLMwaseither“toomoderate”ormisrepresented
theirviews.AnIndianparticipant,whowasagainstsame-sexmarriage,shared:
IwroteaboutrespectingLGBTQcommunitiesandprotectingtheirrights.ButIstrongly
feelthatlegalizingLGBTQmarriageswillimbalanceboththecultureandthenature.AI
misunderstoodmycommentandwroteinfavoroflegalizingsuchmarriages.
Onaverage,peopleeditedLLM’ssuggestionsinawaythatmadethecommentssignificantlyless
positive(meansentiment:0.21)andmoretoxic(meantoxicity:0.11)thantheoriginalsuggestion
(meansentiment:0.78,meantoxicity:0.08).Pairedt-testswithBonferronicorrectionsrevealeda
significanteffectofeditingonthesentiment(𝑡(9) =3.83,𝑝 <0.01)andtoxicity(𝑡(9) =−2.82,𝑝 <
0.01)ofthesecomments.ThisindicatesthatLLMsmightnotbeabletofullycapturethediverse
spectrumandnuancesinaperson’sstanceondivisiveissues.
RejectionandRegeneration.ParticipantsregeneratedandrejectedLLM’ssuggestionsin11%and
13%ofcases,respectively.Inthepost-writingsurvey,participantsreportedthattheyregenerated
suggestionsbecausetheywereeitherverbose,“politicallycorrect”,orused“HR-soundinglanguage.”
Those, who rejected the suggestions, either did not like the “formal and essay-like” and “non-
humanandAI-sounding” language.Inseveralcases,participantsdisagreedwiththeframingin
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 19
Table9. Participants’experiencesofwritingconstructivecomments
Satisfied(%) Feelingofownership(%) Perceiveddifficulty(%)
Human-writtencomments(Control) 77 79 31
HAI-writtencomments(Test) 82 76 16
thesuggestions.AnIndianparticipant,whothoughtIslamincitesextremismamongitsfollowers,
reported:
ItalkedabouthowMuslimsarevery‘hardcore’comparedtofollowersofotherreligion.But
AIframeditas‘deep-seatedreligiouscommitment’togiveitapositivespin,whichIdidn’t
like.IalsowroteabouthavinguniformcivilcodetoremovetheexemptionthatMuslims
enjoyregardingmultiplemarriages.ButAIwroteaboutcodifyingsuchexemptionsunder
uniformcivilcode,whichIdon’tagreewith.
4.2.5 ExperienceofWritingConstructiveComments. Table9showsthatparticipantsintestgroup
whousedLLMwhilewritingconstructivecommentsweremoresatisfiedwiththeircomments
(82%)thanthosewhowroteontheirowninthecontrolgroup(77%).Asexpected,moreparticipants
inthecontrolgroup(79%)reportedfeelingownershipovertheircommentsthanthoseinthetest
group(76%).However,wedidnotfindanysignificantdifferenceinthelevelofsatisfactionand
feelingofownershipbetweencontrolandtestgroups.
Onaverage,moreparticipantsinthecontrolgroup(31%)reportedthatwritingconstructive
commentswasdifficultontheirownthanthosewhoreceivedLLM’ssuggestions(16%).However,
wedidnotfindanysignificantdifferenceintheperceiveddifficultyofwritingconstructivecom-
mentseitherwithorwithoutLLM.ThisindicatesthatLLMhasthepotentialtohelppeoplewrite
constructivecommentsonpolarizingtopicswithoutsignificantlyimpactingthevaluepeoplefind
whileexpressingtheiropinions.
4.3 RQ3:DoPerceptionsofConstructivenessVarybyCulture?
ThroughoutPhase1andPhase2,weidentifiedseveralpointsofanalysistoexaminecross-cultural
differencesinhowpeopleapproachconstructivecomments,whichweoutlinebelow.
PerceptionsofConstructiveness.Priorresearchshowsthatpeoplefromindividualisticcultures
(e.g., the US) prefer logical reasoning during argumentation [71] while those from collectivist
cultures(e.g.,India)preferdialecticalargumentsduringconflict[76].However,contrarytoour
hypothesis,inPhase1,bothAmericanandIndianparticipantsrateddialecticalcommentsasmore
constructive than the logical comments in 73% and 65% of cases, respectively. A binomial test
revealedthatAmericanparticipants’preferencefordialecticalcommentssignificantlydiffered
(𝑝 <0.000001)fromtheexpecteddistribution(40%asobservedinPeng[75]).Moreover,thereasons
providedbyparticipantsforchoosingonecommentovertheotherweresimilar(seeTable15in
Appendix),suggestingasharedunderstandingofconstitutesasaconstructivecommentonsocially
divisiveissues.
WritingConstructiveCommentswithandwithoutLLM.InPhase2,toidentifycross-cultural
differencesinhowparticipantsinIndiaandtheUSwriteconstructivecommentsonsociallydivisive
issues,wecomparedthecommentswrittenbyIndianandAmericanparticipantsfirstwithincontrol
groupsandthenalsowithinthetestgroups.Ananalysisoflinguisticfeaturesofconstructiveness
in these comments did not reveal any significant differences based on culture (see Table 16 in
Appendix).ThesefindingssuggestthatIndianandAmericanparticipantsdemonstratedsimilar
linguisticmarkersofconstructivenessinthecommentstheywrote.
,Vol.1,No.1,Article.Publicationdate:November2018.20 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Table10. PromptsusedbyIndianandAmericanParticipantsinthetestgroup
Prompts India(%) US(%)
Makethecommentrelevanttotheconversation 27 21
Uselogicandfactstomakestep-by-stepargument 21 25
Presentsolutionstoaddresstheissue 19 17
Balancecontrastingviewsandtakemiddleground 10 14
Usepoliteandrespectfultone 23 24
However,wefoundthat,onaverage,Americanparticipantstooklesstime(5.2minutes)towrite
constructivecommentscomparedtoIndianparticipants(6.7minutes)inthecontrolgroups.A
Mann-WhitneyUtestrevealedasignificantbutsmalleffectofcultureonthetimetakentowrite
constructivecomments(𝑈 =6742,𝑍 =3.36,𝑝 <0.001,𝑟 =0.23).Thisdifferencecouldbeattributed
tothefactthatEnglishisnotthenativelanguageofmostpeopleinIndia.
Additionally,inthetestgroup,wedidnotfindanysignificantdifferencesinthedistributionof
promptsthatIndianandAmericanparticipantsusedtomaketheircommentsmoreconstructive
(seeTable10).ThetopthreepromptsusedbyparticipantsinIndiaandtheUSwere:“makingthe
commentrelevanttotheconversation”,“usinglogicalargument”,and“politeandrespectfultone.” This
suggeststhat,despiteculturaldifferencesinargumentationstyles,peoplefrombothindividualistic
andcollectivistculturesmayconvergeintheirapproachestowritingconstructivecommentswith
helpofLLMonsociallydivisiveissueslikehomophobiaandIslamophobia.
Human Evaluations of Constructiveness. We next examined cross-cultural differences in
thepreferencesofIndianandAmericanparticipantsamongconstructivecommentswrittenby
humans,throughhuman-AIcollaboration,andsolelybyLLM.Todothis,weanalyzedparticipants’
ratingsfortheconstructivenessin(HAIvs.Human),(Humanvs.AI),and(HAIvs.AI)comment
pairs.In(Humanvs.AI)comments,81%ofAmericanand69%ofIndianparticipantsconsidered
LLM-generatedcommentsmoreconstructivethanhuman-writtenones.Similarly,in(HAIvs.AI)
commentpairs,bothAmerican(59%)andIndian(51%)participantsratedLLM-generatedcomments
asmoreconstructive.Whenreviewing(HAIvs.Human)commentpairs,participantsinbothgroups
showedsimilarpreferenceforHAI-writtencomments(US:62%,India:66%).Multiplechi-square
testswithBonferronicorrectionsrevealednosignificantdifferencesbetweenIndianandAmerican
participants’preferencesacrossallcommentpairs,indicatingthatculturalbackgrounddidnot
significantlyaffectperceptionsofconstructivenessinLLM-generated,HAI-written,orhuman-only
comments.
Together,thesefindingsindicatethat,whenaddressingsociallydivisiveissueslikehomophobia
andIslamophobia,peopleinIndiaandtheUSmaysharesimilarmentalmodelsofwhatconstitutes
aconstructivecommentonline.
5 Discussion
5.1 PromotingConstructiveDiscourseOnline
Throughcross-culturalexperimentswithAmericanandIndianparticipants,wedemonstratethat
LLMscanhelppeoplefromdifferentcultureswriteconstructivecommentsondivisivesocialissues
likehomophobiaandIslamophobia.OurfindingsshowthatcommentsgeneratedsolelybyanLLM
orco-writtenwithanLLMwereperceivedasmoreconstructivethanthosewrittenbyhumansalone.
TheLLM-generatedandHAI-writtencommentsalsodisplayedsignificantlymoreconstructive
featuresthanthosewrittenbyhumansalone.WhenparticipantspromptedtheLLMtomaketheir
commentsconstructive,itmadethecommentslonger,morepolite,positive,lesstoxic,andmore
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 21
readable,whileenhancingargumentativefeaturesandpreservingtheoriginalmeaning.Overall,
participantsfoundtheLLMhelpful,weresatisfiedwiththeoutputsastheLLMarticulatedtheir
pointsclearly,andreducedtheperceiveddifficultyofwritingconstructivecomments.
ThesefindingsalignwithpriorresearchshowingthatLLMsarecapableofrephrasingusers’
messagestoconveyrespectfullistening[3]andenhancereceptivenesstoopposingviews[44].As
aresult,manypeoplefindtheseLLMaugmentedtoolsvaluableoncounteringhatefulopinions
duringonlineconflicts[66].RecipientsalsoperceiveLLM-generatedargumentsstronger,more
persuasive,andpositivethanthosewrittenbyhumans[3,44,46].
Ourworkcontributestothislineofresearchintwokeyways.First,weshowthatLLMscanhelp
peoplewriteconstructivecommentsinresponsetocontentiousonlinethreadsondivisiveissues.In
contrast,mostpriorresearchhasfocusedonLLMs’capabilitiesinhelpinguserscraftargumentative
essaysonselecttopicsorinprivate,one-on-onedebates[3,20,58,109].Second,wedrawfrom
cross-culturaldifferencesinargumentationtorevealpotentialmisalignmentbetweenhumanand
LLM’sperceptionsofconstructivenessbasedondifferentargumentationstyles(Section5.2).
WhileourfindingsshowapromisethatLLMscanassistusersinconstructivelyengagingin
online debates on divisive social issues, there are some caveats. To begin with, such prosocial
interventionspromotingconstructivediscourseareparticularlybeneficialforwell-intentioned
users,whomaynotrealizetoxicityintheirwritingorwho,inheatedmoments,get“emotionally
triggered”andunintentionallyuseoffensiveorslightedlanguage[50,99].LLM-infusedwriting
toolscanencouragegreatermindfulnessduringonlineconflicts,helpingusersavoidcomments
theymightregretlater[87,98].Suchtoolscanalsohelpshiftsomeresponsibilityforaddressing
hatefulinteractionsduringconflictsontosendersthemselves,andcouldproveparticularlyuseful
inend-to-endencryptedplatforms,suchasWhatsAppgroups,wherehatefulcontentflourishes
duetolimitedmoderation[79].
While such tools may not deter users who intentionally spread hateful rhetoric, they could
empower bystander users to challenge problematic behavior by providing support to express
disagreementconstructively[5,35].Thiscouldbeespeciallyvaluableinsituations,whereusers
mighthesitatetointerveneduetotheeffortandemotionaltollinvolvedinparticipatinginonline
debatewithoutsupport.
5.2 Human-AIMisalignmentinConstructiveDiscourse
AlthoughourfindingsshowthatLLMscouldhelppeoplewriteconstructivecommentsondivi-
siveissues,wefoundkeydifferencesbetweenLLMsandhumansintheirunderstandingofwhat
constitutesconstructiveness.Forinstance,inourstudy,theLLMrateddialecticalcommentsassig-
nificantlymoreconstructivethanhumansdid.TheLLMprioritizedpoliteness,balancedviewpoints,
andamiddle-groundapproach,whereashumansfavoredevidence-based,logicalargumentation
while assessing constructiveness. This misalignment is likely to affect how humans and LLMs
approachconstructivedisagreement.Forexample,Munetal.[65]notethathuman-writtencounter-
speechemploysmorespecificstrategies,suchasprovidingcounterexamplesandstatingfacts,both
ofwhicharecharacteristicsoflogicalargumentation.Incontrast,LLM-generatedcounter-speech
tendstobelessspecificandbroadlydenounceshatefulness[65],aligningmorewiththemiddle-
groundapproachofdialecticalargumentation.Duetothesedifferences,humansoftenperceive
LLM-generatedcounter-speechaslessconvincing.
Inourstudy,thismisalignmentoftenledparticipantstoreject,regenerate,oredittheLLM’s
suggestions,resultingincommentsthatweresignificantlymorenegativeandtoxic.Researchshows
thatLLMstendtoprioritize“surface-level” lexicalcues(e.g.,joy,anger,fear,offensiveness)more
thanhumansdowhileassessingsentiment[21].WeobservedsimilareffectsinHuman-AIwritten
commentsinourstudy.Asaresult,severalparticipantswhorejectedoreditedLLM-generated
,Vol.1,No.1,Article.Publicationdate:November2018.22 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
suggestions reported not liking the formal, moderate, and non-human sounding language. In
linewiththesefindings,Zhangetal.[109]alsofoundthatusersoftenperceiveLLM-generated
suggestionstobe“robotic,monotonous,andrepetitive” whilewritinglongargumentativeessays.
WealsofoundthatsomeparticipantsfeltfrustratedwhentheLLMmisrepresentedtheiropinions,
especiallywhentheirviewswerenuancedratherthanoutrightpolarizing(e.g.,usersupported
LGBTQcommunitiesbutopposedlegalizingsame-sexmarriage).WhilethissuggeststhatLLMs
maystruggletocapturethesubtletiesandcomplexitiesofpeople’sstances,italsoraisesimportant
questionsabouthowhuman-AImisalignmentinexpressingdisagreementscouldimpactdelibera-
tionondivisiveissues.Forexample,priorstudiesshowthatdifferentculturesandcommunities
havedifferentboundariesandtoleranceforthelanguageusedonline.Someusersstronglyvalue
expressingopinionsinanuncensoredwayandfinditpatronizingwhencommentsaremoderated
tobepositive[50].Closefriendsoftenusecursewordstoreflectreal-liferapport,yetalgorithms
mightflagandremovetheseinteractionsasinappropriate[85].Similarly,insomecommunities
(e.g.,LGBTQ+forums),toxiclanguageissometimesusedtofosterin-groupsolidaritythrough
humor[99].ItispossiblethatLLMsuggestionsturnouttobelessusefulinsuchgroupsthatmight
beopentohavingmoredirectanduncensoreddialogueondivisiveissues.Insuchcases,itiscrucial
forLLMstopreserveuserautonomyandprovidethemthechoicetoeitherrephraseorretaintheir
writing.
LLM’stendencytoalignwithmainstreamordominantviewsandtogenerateresponsesthatlack
diversityinperspectivesraiseconcernsabouttheirabilitytoaccuratelyreflectvariedopinions[21].
Whilewedidnotfindevidenceofhomogenizationinhuman-AIwrittencomments,thismight
bebecauseparticipantshadtowritetheiropinionsfirstbeforepromptingtheLLMtorephrase
theircomments.ThedistinctionbetweenpromptingLLMstorephrasecommentsversusco-writing
commentswithauto-completeLLMsuggestionsholdssignificantdesignimplications,asseveral
studiesshowthatauto-completesuggestionsfromLLMsshiftpeople’sviewpointsandhomogenize
theirwriting[1,41,101].Moreover,priorstudiesshowthatpeoplefearreframingtheirmessages
withLLMswouldunderminetheiragencyandcredibility,resultingininsincere,diluted,andmorally
compromisingresponses[5,66].Forexample,oneofourparticipantsreportedacceptingLLM-
generated“neutral”suggestionswhilerespondingtoanIslamophobicthreadbecausetheysuspected
theirviewsmightbe“toobiasedtomeettheappropriatecriteria” becausetheywereMuslim.Thus,
suggestions from LLM can lead to algorithmic conformity [60], suppress minority viewpoints,
andcurbfreedomofspeechovertime[30]ifindividualsandcommunitiesstartadjustingtheir
opinionstoconformtowhatLLMsthinkas“constructive.” Therefore,asystematicinvestigation
isneededtodeterminehowsuggestionsintheformofauto-completeorrephrasingmightaffect
homogenizationinwriting.
5.3 EnablingConstructiveDiscourseAcrossCultures
Priorresearchinculturalstudiesshowsthatpeoplefromindividualisticculturespreferlogicalar-
guments,whereasthosefromcollectivistculturesfavordialecticalarguments[69,71,76].However,
ourstudydidnotfindsignificantdifferencebetweenIndianandAmericanparticipants’preferences
forlogicalversusdialecticalcommentsasconstructive.Eventhepromptschosentomakecomments
moreconstructiveweresimilaracrossbothgroups.Thiscouldbebecausetheexistingworkon
cross-culturaldifferencesinargumentationisbasedoneitherofflineconflicts[72]orlong-form
argumentativeessays[70,71],whichmaynotdirectlyapplytoshort-formonlinecomments.For
instance,Toulmin’slogicalargumentationframeworkincludessixelements:claim,data,warrant,
backing,qualifier,andrebuttal[38].However,inourstudy,theLLM-generated,human-written,
andHAI-writtencommentsaveraged70-80wordsinlength,whichmaybetoobrieftocapture
allelementsofargumentation.Thisbrevitymighthavemadeitdifficultforpeopletodistinguish
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 23
betweenlogicalanddialecticalstyles.Infutureresearch,weplantoconductfollow-upexperiments
usingcommentsofvaryinglengthstoexamineifcommentlengthinfluencespreferencesforlogical
versusdialecticalcommentsinonlinedebatesondivisiveissues.
Additionally,forculturallygroundedwritingtasks,LLM-generatedsuggestionshavebeenshown
toleadIndianparticipantstoadoptWesternwritingstyles[1].Inourstudy,AmericanandIndian
participantsrespondedtodifferentthreadsrelevanttotheirculturalcontexts,whichpreventeda
directcomparisonoftheircommentstodetermineifculturalhomogenizationoccurredwhenco-
writingconstructivecommentswiththeLLM.Therefore,infutureresearch,weplantoinvestigate
commentsfromIndianandAmericanparticipantswritteninresponsetothesamethreadsthat
are relevant to both cultural contexts. To address cultural homogenization from biased LLMs,
techniquessuchasanthropologicalprompting[2],culturalprompting[92],self-pluralism[104],
modularpluralism[29],orvalue-pluralisticdesign[88]—whichhavebeenshowntoincreasecultural
alignment in LLM-generated responses—are necessary to design HAI-collaborative systems to
supportprosocialdiscourseonlineonaglobalscale.
5.4 EthicalConsiderationandFeasibilityofFacilitatingConstructiveDiscourse
Apartfromthebenefitsofpromotingconstructivediscourse,weneedtocriticallythinkabout
the potential biases and abuses stemming from such systems. For instance, LLMs have been
showntoproduceresponseswithcovertculturalharmsinseeminglyneutrallanguagethatare
unlikely to be detected by existing methods [19]. Since we only used existing sentiment and
toxicityanalysestools,wemaynothaveuncoveredsuchcovertbiasesinHAI-writtencomments.
However,manualinspectionoftheLLM-generatedcommentsfromPhase1revealedstatements
like“...its[Islam’s]damagingtreatmenttowardswomen,LGBTQ+individuals,andnon-Muslims...”–
generatedinresponsetoanIslamophobicthreadfromthestanceofopposingIslamophobia.If
LLMsperpetuatesuchcovertbiasesintheformof“constructive” discoursewhiletakingthestance
ofsupportingmarginalizedcommunities,itwouldstrengthenexistingstereotypesandpotentially
harmmarginalizedindividuals.
CarstensandFriess[10]havealsocritiquedsuchAItoolsduetotheirsimplifiedviewofonline
civility.Theyarguethatapartfrominput-output,thesesystemsneedtobeevaluatedwithinexisting
socialinequalitiesandhierarchies.Because,theargumentativenormsfacilitatedbythesetools
would privilege expressions from highly educated people, who usually have better training in
writingsucharguments,whiledisregardinglinguisticandculturalvariations.
Additionally,existingresearchontheroleofLLMsinpromotingprosocialdiscoursehasprimarily
reliedoncrowdevaluations[44]orassessedreceptivenessonlyamongsmallgroupofdiscussants[3,
94].Althoughresearchshowsthatpromotingcivildialoguecanactuallyenhanceuserengagement
ontheplatform[61],thereislimitedunderstandingofhowsuchinterventionswouldworkin
largeonlinecommunities,wherethediscussionscanbeviewedbyanyone.Choetal.[13]have
noticedthatthatevenwhenLLM-basedinterventionencouragesdeeplistening,empathy,and
criticalthinking,itstrugglestoinstillrespectfulandcooperativeattitudeamongpeople.Therefore,
futureworkshouldlookinto:howmanyusersneedtowritetheircommentsconstructivelytoaffect
thecourseofadivisiveonlinethread?Howwouldthisaffectusers’engagementandsubsequent
conversationquality?
5.5 LimitationsandGeneralizability
As an early study, our work has several limitations. First, we focused on two divisive social
issues—Islamophobiaandhomophobia—andparticipantsfromtwogeographies,IndiaandtheUS,
asproxiesfordifferentcultures.Therefore,thefindingsmaynotbegeneralizabletootherregions
orsocialissues.
,Vol.1,No.1,Article.Publicationdate:November2018.24 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Second,whilepriorresearchindicatesthatannotators’identitiesinfluencehowtheyperceive
onlinecontent[80],ouranalysisdidnotaccountforhowparticipants’identitiesmighthaveshaped
theirperceptionsandevaluationsofconstructivenessinthecomments.Tomitigatethis,weensured
participantsreviewedcommentsfromthesamestancewhenmakingjudgments.However,future
researchshoulddeeplylookintowhetheridentityinfluencesperceptionsofconstructivecomments
inonlinedebatesondivisivetopics.
Third, although our results provide initial evidence that LLMs can help people write more
constructivecomments,weassessedaudiences’perceptionsratherthanmeasuringwhetherthese
commentseffectivelychangetheaudience’sopinionsondivisiveissuesorfostercommonground.
Wealsodidnotinvestigatethethresholdofconstructivecommentsneededinanonlinedebateto
shiftthetoneoftheconversation.Whilethisisnotnecessarilyaninherentlimitationofourstudy,
itrepresentsacriticalnextstepthatweaimtoaddressinfutureresearch.
References
[1] DhruvAgarwal,MorNaaman,andAdityaVashistha.2024.AISuggestionsHomogenizeWritingTowardWestern
StylesandDiminishCulturalNuances. https://arxiv.org/abs/2409.11360
[2] BadrAlKhamissi,MuhammadElNokrashy,MaiAlKhamissi,andMonaDiab.2024.Investigatingculturalalignment
oflargelanguagemodels.
[3] LisaPArgyle,ChristopherABail,EthanCBusby,JoshuaRGubler,ThomasHowe,ChristopherRytting,Taylor
Sorensen,andDavidWingate.2023.LeveragingAIfordemocraticdiscourse:Chatinterventionscanimproveonline
politicalconversationsatscale.ProceedingsoftheNationalAcademyofSciences120,41(2023),e2311627120.
[4] AndréBächtigerandJohnParkinson.2019.Mappingandmeasuringdeliberation:Towardsanewdeliberativequality.
OxfordUniversityPress,UnitedKingdom.
[5] AmandaBaughan,JustinPetelka,CatherineJaekyungYoo,JackLo,ShiyueWang,AmulyaParamasivam,Ashley
Zhou,andAlexisHiniker.2021.SomeoneIsWrongontheInternet:HavingHardConversationsinOnlineSpaces.
Proc.ACMHum.-Comput.Interact.5,CSCW1,Article156(apr2021),22pages.
[6] GeorgeBerryandSeanJ.Taylor.2017.DiscussionQualityDiffusesintheDigitalPublicSquare.InProceedingsofthe
26thInternationalConferenceonWorldWideWeb.InternationalWorldWideWebConferencesSteeringCommittee,
RepublicandCantonofGeneva,CHE,1371–1380.
[7] GabrielBorelli.2022. Aboutsix-in-tenAmericanssaylegalizationofsame-sexmarriageisgoodforsociety. Re-
trievedOctober18,2024fromhttps://www.pewresearch.org/short-reads/2022/11/15/about-six-in-ten-americans-say-
legalization-of-same-sex-marriage-is-good-for-society/
[8] EmilieBossens,EliasStorms,andDavidGeerts.2021.ImprovingtheDebate:InterfaceElementsthatEnhanceCivility
andRelevanceinOnlineNewsComments.InIFIPConferenceonHuman-ComputerInteraction.Springer,Switzerland,
433–450.
[9] YongCao,LiZhou,SeolhwaLee,LauraCabello,MinChen,andDanielHershcovich.2023.AssessingCross-Cultural
AlignmentbetweenChatGPTandHumanSocieties:AnEmpiricalStudy. arXiv:2303.17466[cs.CL] https://arxiv.org/
abs/2303.17466
[10] JonasAaronCarstensandDennisFriess.2024.AIWithinOnlineDiscussions:Rational,Civil,Privileged?Mindsand
Machines34,2(2024),1–25.
[11] PewResearchCenter.2017.HowtheU.S.generalpublicviewsMuslimsandIslam. RetrievedOctober18,2024from
https://www.pewresearch.org/religion/2017/07/26/how-the-u-s-general-public-views-muslims-and-islam/
[12] JonathanP.Chang,CharlotteSchluger,andCristianDanescu-Niculescu-Mizil.2022.ThreadWithCaution:Proactively
HelpingUsersAssessandDeescalateTensioninTheirOnlineDiscussions. Proc.ACMHum.-Comput.Interact.6,
CSCW2,Article545(nov2022),37pages.
[13] HyundongCho,ShuaiLiu,TaiweiShi,DarpanJain,BasemRizk,YuyangHuang,ZixunLu,NuanWen,Jonathan
Gratch,EmilioFerrera,etal.2023.CanLanguageModelModeratorsImprovetheHealthofOnlineDiscourse?
[14] IncheolChoi,MinkyungKoo,andJongAnChoi.2007. Individualdifferencesinanalyticversusholisticthinking.
Personalityandsocialpsychologybulletin33,5(2007),691–705.
[15] YeonHeeChoi.1988.TextstructureofKoreanspeakers’argumentativeessaysinEnglish.WorldEnglishes7,2(1988),
129–137.
[16] BenjaminCollierandJuliaBear.2012. Conflict,criticism,orconfidence:anempiricalexaminationofthegender
gapinwikipediacontributions.InProceedingsoftheACM2012ConferenceonComputerSupportedCooperativeWork
(Seattle,Washington,USA)(CSCW’12).ACM,NewYork,USA,383–392.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 25
[17] StephenMCroucher,RamuneBraziunaite,DiniHomsey,GayatrePillai,JagrutiSaxena,AshishSaldanha,Vikrant
Joshi,ImranJafri,PavanChoudhary,LalimaBose,etal.2009. Organizationaldissentandargumentativeness:A
comparativeanalysisbetweenAmericanandIndianorganizations.JournalofInterculturalCommunicationResearch
38,3(2009),175–191.
[18] StephanieCutler,YuXia,andKaceyBeddoes.2022. AGrowthMindsetforPeerReview:Guidelinesforwriting
constructivepeerreviews.
[19] PreetamPrabhuSrikarDammu,HayoungJung,AnjaliSingh,MonojitChoudhury,andTanushreeMitra.2024.“They
areuncultured":UnveilingCovertHarmsandSocialThreatsinLLMGeneratedConversations.
[20] HaiDang,SvenGoller,FlorianLehmann,andDanielBuschek.2023.ChoiceOverControl:HowUsersWritewith
LargeLanguageModelsusingDiegeticandNon-DiegeticPrompting.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems(Hamburg,Germany)(CHI’23).ACM,NewYork,USA,Article408,17pages.
[21] DebaratiDas,KarinDeLangis,AnnaMartin,JaehyungKim,MinhwaLee,ZaeMyungKim,ShirleyHayati,Risako
Owan,BinHu,RitikParkar,etal.2024.Underthesurface:Trackingtheartifactualityofllm-generateddata.
[22] ChristineDeKock,TomStafford,andAndreasVlachos.2022.Howtodisagreewell:Investigatingthedisputetactics
usedonWikipedia.InProceedingsofthe2022ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,Yoav
Goldberg,ZornitsaKozareva,andYueZhang(Eds.).AssociationforComputationalLinguistics,AbuDhabi,United
ArabEmirates,3824–3837.
[23] ChristineDeKockandAndreasVlachos.2021. IBegtoDiffer:Astudyofconstructivedisagreementinonline
conversations.InProceedingsofthe16thConferenceoftheEuropeanChapteroftheAssociationforComputational
Linguistics:MainVolume,PaolaMerlo,JorgTiedemann,andReutTsarfaty(Eds.).AssociationforComputational
Linguistics,Online,2017–2027.
[24] MortonDeutsch.1994.Constructiveconflictresolution:Principles,training,andresearch.Journalofsocialissues50,
1(1994),13–32.
[25] NicholasDiakopoulos.2015.PickingtheNYTpicks:Editorialcriteriaandautomationinthecurationofonlinenews
comments.ISOJJournal6,1(2015),147–166.
[26] NicholasDiakopoulosandMorNaaman.2011.Towardsqualitydiscourseinonlinenewscomments.InProceedingsof
theACM2011ConferenceonComputerSupportedCooperativeWork(Hangzhou,China)(CSCW’11).ACM,NewYork,
USA,133–142.
[27] XiaohanDing,KaikePing,UmaSushmithaGunturi,BuseCarik,SophiaStil,LanceTWilhelm,TaufiqDaryanto,
JamesHawdon,SangWonLee,andEugeniaHRho.2024.CounterQuill:InvestigatingthePotentialofHuman-AI
CollaborationinOnlineCounterspeechWriting.
[28] KatharinaEsau,DennisFriess,andChristianeEilders.2017. Designmatters!Anempiricalanalysisofonline
deliberationondifferentnewsplatforms.Policy&Internet9,3(2017),321–342.
[29] ShangbinFeng,TaylorSorensen,YuhanLiu,JillianFisher,ChanYoungPark,YejinChoi,andYuliaTsvetkov.2024.
Modularpluralism:Pluralisticalignmentviamulti-llmcollaboration.
[30] JessicaLFeuston,AlexSTaylor,andAnneMariePiper.2020. Conformityofeatingdisordersthroughcontent
moderation.ProceedingsoftheACMonHuman-ComputerInteraction4,CSCW1(2020),1–28.
[31] CarltonJFong,JayceRWarner,KyleMWilliams,DianeLSchallert,Ling-HuiChen,ZacharyHWilliamson,and
ShengjieLin.2016.Deconstructingconstructivecriticism:Thenatureofacademicemotionsassociatedwithconstruc-
tive,positive,andnegativefeedback.LearningandIndividualDifferences49(2016),393–399.
[32] DennisFriessandChristianeEilders.2015.Asystematicreviewofonlinedeliberationresearch.Policy&Internet7,3
(2015),319–339.
[33] JarodGovers,EduardoVelloso,VassilisKostakos,andJorgeGoncalves.2024. AI-DrivenMediationStrategiesfor
AudienceDepolarisationinOnlineDebates.InProceedingsoftheCHIConferenceonHumanFactorsinComputing
Systems(Honolulu,HI,USA)(CHI’24).AssociationforComputingMachinery,NewYork,USA,Article803,18pages.
[34] CatherineGrevet,LorenG.Terveen,andEricGilbert.2014. Managingpoliticaldifferencesinsocialmedia.In
Proceedingsofthe17thACMConferenceonComputerSupportedCooperativeWork&SocialComputing.ACM,New
York,USA,1400–1408.
[35] SelinGurgun,EmilyArden-Close,JohnMcAlaney,KeithPhalp,andRaianAli.2023.CanWeRe-designSocialMedia
toPersuadePeopletoChallengeMisinformation?AnExploratoryStudy.InInternationalConferenceonPersuasive
Technology.Springer,Germany,123–141.
[36] DaleHampleandDeepaAnagondahalli.2015. UnderstandingsofarguinginIndiaandtheUnitedStates:Argu-
mentframes,personalizationofconflict,argumentativeness,andverbalaggressiveness. JournalofIntercultural
CommunicationResearch44,1(2015),1–26.
[37] BeverlyHill,SachikoIde,ShokoIkuta,AkikoKawasaki,andTsunaoOgino.1986.Universalsoflinguisticpoliteness:
QuantitativeevidencefromJapaneseandAmericanEnglish.Journalofpragmatics10,3(1986),347–371.
[38] DavidHitchcockandBartVerheij.2006.ArguingontheToulminmodel.Vol.10.Springer,NewYork,USA.
,Vol.1,No.1,Article.Publicationdate:November2018.26 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
[39] ThomasHoltgravesandYangJoong-Nam.1990. Politenessasuniversal:Cross-culturalperceptionsofrequest
strategiesandinferencesbasedontheiruse.Journalofpersonalityandsocialpsychology59,4(1990),719.
[40] ClaytonHuttoandEricGilbert.2014.Vader:Aparsimoniousrule-basedmodelforsentimentanalysisofsocialmedia
text.ProceedingsoftheinternationalAAAIconferenceonwebandsocialmedia8,1(2014),216–225.
[41] MauriceJakesch,AdvaitBhat,DanielBuschek,LiorZalmanson,andMorNaaman.2023.Co-WritingwithOpinionated
LanguageModelsAffectsUsers’Views.InProceedingsofthe2023CHIConferenceonHumanFactorsinComputing
Systems(Hamburg,Germany)(CHI’23).ACM,NewYork,USA,Article111,15pages.
[42] ShagunJhaver,PranilVora,andAmyBruckman.2017. Designingforcivilconversations:Lessonslearnedfrom
ChangeMyView.
[43] RebeccaLJohnson,GiadaPistilli,NataliaMenédez-González,LeslyeDenisseDiasDuran,EnricoPanai,JulijaKalpok-
iene,andDonaldJayBertulfo.2022. TheGhostintheMachinehasanAmericanaccent:valueconflictinGPT-3.
arXiv:2203.07785[cs.CL] https://arxiv.org/abs/2203.07785
[44] GauriKambhatla,MatthewLease,andAshwinRajadesingan.2024.PromotingConstructiveDeliberation:Reframing
forReceptiveness.
[45] SurajKapoor,PatrickCHughes,JohnRBaldwin,andJanetBlue.2003.Therelationshipofindividualism–collectivism
andself-construalstocommunicationstylesinIndiaandtheUnitedStates. InternationalJournalofIntercultural
Relations27,6(2003),683–700.
[46] EliseKarinshak,SunnyXunLiu,JoonSungPark,andJeffreyT.Hancock.2023. WorkingWithAItoPersuade:
ExaminingaLargeLanguageModel’sAbilitytoGeneratePro-VaccinationMessages. Proc.ACMHum.-Comput.
Interact.7,CSCW1,Article116(2023),29pages.
[47] MatthewKatsaros,KathyYang,andLaurenFratamico.2022.Reconsideringtweets:Interveningduringtweetcreation
decreasesoffensivecontent.InProceedingsoftheInternationalAAAIConferenceonWebandSocialMedia,Vol.16.
AssociationfortheAdvancementofArtificialIntelligence,WashingtonDC,USA,477–487.
[48] JisuKim,CurtisMcDonald,PaulMeosky,MatthewKatsaros,andTomTyler.2022.Promotingonlinecivilitythrough
platformarchitecture.JournalofOnlineTrustandSafety1,4(2022),23pages.
[49] JeongyeonKim,SanghoSuh,LydiaBChilton,andHaijunXia.2023.Metaphorian:LeveragingLargeLanguageModels
toSupportExtendedMetaphorCreationforScienceWriting.InProceedingsofthe2023ACMDesigningInteractive
SystemsConference(Pittsburgh,PA,USA)(DIS’23).ACM,NewYork,USA,115–135.
[50] JoelKiskola,ThomasOlsson,AnnaRantasila,AleksiHSyrjämäki,MirjaIlves,PoikaIsokoski,andVeikkoSurakka.
2023.User-centredqualityofUIinterventionsaimingtoinfluenceonlinenewscommentingbehaviour.Behaviour&
InformationTechnology42,12(2023),2060–2092.
[51] VaradaKolhatkarandMaiteTaboada.2017.ConstructiveLanguageinNewsComments.InProceedingsoftheFirst
WorkshoponAbusiveLanguageOnline,ZeerakWaseem,WendyHuiKyongChung,DirkHovy,andJoelTetreault
(Eds.).ACL,Vancouver,Canada,11–17.
[52] VaradaKolhatkarandMaiteTaboada.2017. UsingNewYorkTimesPickstoIdentifyConstructiveComments.In
Proceedingsofthe2017EMNLPWorkshop:NaturalLanguageProcessingmeetsJournalism,OctavianPopescuandCarlo
Strapparava(Eds.).ACL,Copenhagen,Denmark,100–105.
[53] VaradaKolhatkar,NithumThain,JeffreySorensen,LucasDixon,andMaiteTaboada.2020.Classifyingconstructive
comments.
[54] REKraut.2012.BuildingSuccessfulOnlineCommunities:Evidence-basedSocialDesign.MITPress,Cambridge,MA,
USA.
[55] MaxKreminski.2024.TheDearthoftheAuthorinAI-SupportedWriting.InProceedingsoftheThirdWorkshopon
IntelligentandInteractiveWritingAssistants(Honolulu,HI,USA)(In2Writing’24).ACM,NewYork,USA,48–50.
[56] TravisKriplean,JonathanMorgan,DeenFreelon,AlanBorning,andLanceBennett.2012.Supportingreflectivepublic
thoughtwithconsiderit.InProceedingsoftheACM2012ConferenceonComputerSupportedCooperativeWork(Seattle,
Washington,USA)(CSCW’12).ACM,NewYork,USA,265–274.
[57] TravisKriplean,MichaelToomim,JonathanMorgan,AlanBorning,andAmyJ.Ko.2012.Isthiswhatyoumeant?
promotinglisteningonthewebwithreflect.InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputing
Systems(Austin,Texas,USA)(CHI’12).ACM,NewYork,USA,1559–1568.
[58] MinaLee,PercyLiang,andQianYang.2022.CoAuthor:DesigningaHuman-AICollaborativeWritingDatasetfor
ExploringLanguageModelCapabilities.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputing
Systems(NewOrleans,LA,USA)(CHI’22).ACM,NewYork,USA,Article388,19pages.
[59] MinaLee,PercyLiang,andQianYang.2022.CoAuthor:DesigningaHuman-AICollaborativeWritingDatasetfor
ExploringLanguageModelCapabilities.InProceedingsofthe2022CHIConferenceonHumanFactorsinComputing
Systems(NewOrleans,LA,USA)(CHI’22).ACM,NewYork,USA,Article388,19pages.
[60] YotamLielandLiorZalmanson.2020.WhatifanAItoldyouthat2+2is5?Conformitytoalgorithmicrecommenda-
tions.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 27
[61] TonyLiu,LyleUngar,KonradKording,andMorganMcGuire.2024.MeasuringCausalEffectsofCivilCommunication
withoutRandomization.InProceedingsoftheInternationalAAAIConferenceonWebandSocialMedia,Vol.18.AAAI
Press,WashingtonDC,USA,958–971.
[62] BradleyStephenLudwig.2014. Therhetoricalconstitutionofonlinecommunity:Identificationandconstitutive
rhetoricinthecommunityofreddit.
[63] TealeW.Masrani,JackJamieson,NaomiYamashita,andHelenAiHe.2023.SlowingitDown:TowardsFacilitating
InterpersonalMindfulnessinOnlinePolarizingConversationsOverSocialMedia.Proc.ACMHum.-Comput.Interact.
7,CSCW1,Article90(2023),27pages.
[64] SimonMcalister,AndrewRavenscroft,andEileenScanlon.2004.Combininginteractionandcontextdesigntosupport
collaborativeargumentationusingatoolforsynchronousCMC.JournalofComputerAssistedLearning20,3(2004),
194–204.
[65] JiminMun,EmilyAllaway,AkhilaYerukola,LauraVianna,Sarah-JaneLeslie,andMaartenSap.2023. Beyond
DenouncingHate:StrategiesforCounteringImpliedBiasesandStereotypesinLanguage.InFindingsoftheAssociation
forComputationalLinguistics:EMNLP2023,HoudaBouamor,JuanPino,andKalikaBali(Eds.).Associationfor
ComputationalLinguistics,Singapore,9759–9777.
[66] JiminMun,CathyBuerger,JennyTLiang,JoshuaGarland,andMaartenSap.2024.Counterspeakers’Perspectives:
UnveilingBarriersandAINeedsintheFightagainstOnlineHate.InProceedingsoftheCHIConferenceonHuman
FactorsinComputingSystems(Honolulu,HI,USA)(CHI’24).ACM,NewYork,USA,Article742,22pages.
[67] CourtneyNapoles,JoelTetreault,AasishPappu,EnricaRosato,andBrianProvenzale.2017. FindingGoodCon-
versationsOnline:TheYahooNewsAnnotatedCommentsCorpus.InProceedingsofthe11thLinguisticAnnotation
Workshop,NathanSchneiderandNianwenXue(Eds.).AssociationforComputationalLinguistics,Valencia,Spain,
11pages.
[68] VladNiculaeandCristianDanescu-Niculescu-Mizil.2016.ConversationalMarkersofConstructiveDiscussions.In
Proceedingsofthe2016ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:
HumanLanguageTechnologies,KevinKnight,AniNenkova,andOwenRambow(Eds.).AssociationforComputational
Linguistics,SanDiego,California,568–578.
[69] RichardENisbett,KaipingPeng,IncheolChoi,andAraNorenzayan.2001.Cultureandsystemsofthought:holistic
versusanalyticcognition.Psychologicalreview108,2(2001),291.
[70] AraNorenzayan,RENisbett,EESmith,andBJKim.2000.Rulesvs.similarityasabasisforreasoningandjudgment
inEastandWest.
[71] AraNorenzayan,EdwardESmith,BeomJunKim,andRichardENisbett.2002.Culturalpreferencesforformalversus
intuitivereasoning.Cognitivescience26,5(2002),653–684.
[72] Ken-IchiOhbuchiandYumiTakahashi.1994. CulturalstylesofconflictmanagementinJapaneseandAmericans:
Passivity,covertness,andeffectivenessofstrategies1.JournalofAppliedSocialPsychology24,15(1994),1345–1366.
[73] Vishakh Padmakumar and He He. 2024. Does Writing with Language Models Reduce Content Diversity?
arXiv:2309.05196[cs.CL] https://arxiv.org/abs/2309.05196
[74] InyoungPark,DaehoLee,andYoungJuneSah.2023. Underwatchingeyesinnewscommentsections:effectsof
audiencecueonself-awarenessandcommentingbehaviour. Behaviour&InformationTechnology42,13(2023),
2279–2295.
[75] KaipingPeng.1997.Naivedialecticismanditseffectsonreasoningandjudgmentaboutcontradiction.Ph.D.Dissertation.
UniversityofMichigan.
[76] KaipingPengandRichardE.Nisbett.1999. Culture,dialectics,andreasoningaboutcontradiction. American
Psychologist54,9(1999),741–754.
[77] AshwinRajadesingan,CarolynDuran,PaulResnick,andCerenBudak.2021. ’WalkingIntoaFireHopingYou
Don’tCatch’:StrategiesandDesignstoFacilitateCross-PartisanOnlineDiscussions. ProceedingsoftheACMon
Human-ComputerInteraction5,CSCW2(2021),1–30.
[78] CarlosRuiz,DavidDomingo,JosepLluísMicó,JavierDíaz-Noci,KoldoMeso,andPereMasip.2011.Publicsphere
2.0?Thedemocraticqualitiesofcitizendebatesinonlinenewspapers.TheInternationaljournalofpress/politics16,4
(2011),463–487.
[79] PunyajoySaha,BinnyMathew,KiranGarimella,andAnimeshMukherjee.2021.“ShortistheRoadthatLeadsfrom
FeartoHate”:FearSpeechinIndianWhatsAppGroups.InProceedingsoftheWebconference2021.ACM,NewYork,
USA,1110–1121.
[80] MaartenSap,SwabhaSwayamdipta,LauraVianna,XuhuiZhou,YejinChoi,andNoahA.Smith.2022.Annotatorswith
Attitudes:HowAnnotatorBeliefsAndIdentitiesBiasToxicLanguageDetection.InProceedingsofthe2022Conference
oftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Marine
Carpuat,Marie-CatherinedeMarneffe,andIvanVladimirMezaRuiz(Eds.).AssociationforComputationalLinguistics,
Seattle,UnitedStates,5884–5906.
,Vol.1,No.1,Article.Publicationdate:November2018.28 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
[81] JosephSeering,TianmiFang,LucaDamasco,Mianhong’Cherie’Chen,LikangSun,andGeoffKaufman.2019.
DesigningUserInterfaceElementstoImprovetheQualityandCivilityofDiscourseinOnlineCommentingBehaviors.
InProceedingsofthe2019CHIConferenceonHumanFactorsinComputingSystems(Glasgow,ScotlandUk)(CHI’19).
ACM,NewYork,USA,1–14.
[82] JosephSeering,RobertKraut,andLauraDabbish.2017.ShapingProandAnti-SocialBehavioronTwitchThrough
ModerationandExample-Setting.InProceedingsofthe2017ACMConferenceonComputerSupportedCooperativeWork
andSocialComputing(Portland,Oregon,USA)(CSCW’17).ACM,NewYork,USA,111–125.
[83] FarhanaShahid,DhruvAgarwal,andAdityaVashistha.2024.’OneStyleDoesNotRegulateAll’:ModerationPractices
inPublicandPrivateWhatsAppGroups. https://doi.org/10.48550/arXiv.2401.08091arXiv:2401.08091[cs].
[84] FarhanaShahid,DhruvAgarwal,andAdityaVashistha.2024.’OneStyleDoesNotRegulateAll’:ModerationPractices
inPublicandPrivateWhatsAppGroups. arXiv:2401.08091[cs.HC] https://arxiv.org/abs/2401.08091
[85] FarhanaShahidandAdityaVashistha.2023.DecolonizingContentModeration:DoesUniformGlobalCommunity
StandardResembleUtopianEqualityorWesternPowerHegemony?.InProceedingsofthe2023CHIConferenceon
HumanFactorsinComputingSystems(Hamburg,Germany)(CHI’23).ACM,NewYork,USA,Article391,18pages.
[86] RShortall,AItten,MvanderMeer,PKMurukannaiah,andCMJonker.2021.Reasonagainstthemachine:Future
directionsformassonlinedeliberation.FrontiersinPoliticalScience4,0(2021),1–17.
[87] ManyaSleeper,JustinCranshaw,PatrickGageKelley,BlaseUr,AlessandroAcquisti,LorrieFaithCranor,andNorman
Sadeh.2013. "ireadmyTwitterthenextmorningandwasastonished":aconversationalperspectiveonTwitter
regrets.InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems(Paris,France)(CHI’13).
ACM,NewYork,USA,3277–3286.
[88] TaylorSorensen,LiweiJiang,JenaDHwang,SydneyLevine,ValentinaPyatkin,PeterWest,NouhaDziri,XimingLu,
KavelRao,ChandraBhagavatula,etal.2024.Valuekaleidoscope:Engagingaiwithpluralistichumanvalues,rights,
andduties.InProceedingsoftheAAAIConferenceonArtificialIntelligence,Vol.38.AAAIPress,WashingtonDC,USA,
19937–19947.
[89] KumarBhargavSrinivasan,CristianDanescu-Niculescu-Mizil,LillianLee,andChenhaoTan.2019.ContentRemovalas
aModerationStrategy:ComplianceandOtherOutcomesintheChangeMyViewCommunity.Proc.ACMHum.-Comput.
Interact.3,CSCW,Article163(2019),21pages.
[90] AbhaySukumaran,StephanieVezich,MelanieMcHugh,andCliffordNass.2011.Normativeinfluencesonthoughtful
onlineparticipation.InProceedingsoftheSIGCHIConferenceonHumanFactorsinComputingSystems(Vancouver,BC,
Canada)(CHI’11).ACM,NewYork,USA,3401–3410.
[91] ShinobuSuzuki.2010.Formsofwrittenarguments:AcomparisonbetweenJapanandtheUnitedStates.International
JournalofInterculturalRelations34,6(2010),651–660.
[92] YanTao,OlgaViberg,RyanSBaker,andRenéFKizilcec.2024.Culturalbiasandculturalalignmentoflargelanguage
models.PNASnexus3,9(2024),346.
[93] SamuelHardmanTaylor,DominicDiFranzo,YoonHyungChoi,ShrutiSannon,andNatalyaN.Bazarova.2019.
AccountabilityandEmpathybyDesign:EncouragingBystanderInterventiontoCyberbullyingonSocialMedia.Proc.
ACMHum.-Comput.Interact.3,CSCW,Article118(nov2019),26pages.
[94] MichaelHenryTessler,MichielA.Bakker,DanielJarrett,HannahSheahan,MartinJ.Chadwick,RaphaelKoster,
GeorginaEvans,LucyCampbell-Gillingham,TantumCollins,DavidC.Parkes,MatthewBotvinick,andChristopher
Summerfield.2024.AIcanhelphumansfindcommongroundindemocraticdeliberation.Science386,6719(2024),
eadq2852.
[95] StellaTing-Toomey,GeGao,PaulaTrubisky,ZhizhongYang,HakSooKim,Sung-LingLin,andTsukasaNishida.
1991.Culture,facemaintenance,andstylesofhandlinginterpersonalconflict:Astudyinfivecultures.International
Journalofconflictmanagement2,4(1991),275–296.
[96] StellaTing-ToomeyandAtsukoKurogi.1998. Faceworkcompetenceininterculturalconflict:Anupdatedface-
negotiationtheory.Internationaljournalofinterculturalrelations22,2(1998),187–225.
[97] YixueWangandNicholasDiakopoulos.2022.HighlightingHigh-qualityContentasaModerationStrategy:TheRole
ofNewYorkTimesPicksinCommentQualityandEngagement.Trans.Soc.Comput.4,4,Article13(2022),24pages.
[98] MarkWarner,LauraLascau,AnnaLCox,DuncanPBrumby,andAnnBlandford.2021.“Oops...”:MobileMessage
DeletioninConversationErrorandRegretRemediation.InProceedingsofthe2021CHIConferenceonHumanFactors
inComputingSystems(Yokohama,Japan)(CHI’21).ACM,NewYork,USA,Article343,13pages.
[99] MarkWarner,AngelikaStrohmayer,MatthewHiggs,andLynneCoventry.2024.ACriticalReflectionontheUseof
ToxicityDetectionAlgorithmsinProactiveContentModerationSystems.
[100] MLibbyWeaver,RachaelSundland,AlexandraMAdams,IsabellaFaria,HopeAFeldman,HallberaGudmundsdottir,
HannahMarmor,VictoriaMiles,BrielleOchoa,SamanthaMRuff,etal.2022.Theartofpeerreview:Guidelinesto
becomeacredibleandconstructivepeerreviewer.Seminarsinvascularsurgery35,4(2022),470–478.
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 29
[101] SterlingWilliams-Ceci,MauriceJakesch,AdvaitBhat,KoweKadoma,LiorZalmanson,MorNaaman,andCornell
Tech.2024.BiasinAIAutocompleteSuggestionsLeadstoAttitudeShiftonSocietalIssues.
[102] MengXia,QianZhu,XingboWang,FeiNie,HuaminQu,andXiaojuanMa.2022.Persua:AVisualInteractiveSystem
toEnhancethePersuasivenessofArgumentsinOnlineDiscussion.Proc.ACMHum.-Comput.Interact.6,CSCW2,
Article319(2022),30pages.
[103] YunXie,DaleHample,andXiaoliWang.2015. Across-culturalanalysisofargumentpredispositionsinChina:
Argumentativeness,verbalaggressiveness,argumentframes,andpersonalizationofconflict.Argumentation29(2015),
265–284.
[104] ShaoyangXu,YongqiLeng,LinhaoYu,andDeyiXiong.2024.Self-PluralisingCultureAlignmentforLargeLanguage
Models.
[105] LipingYanandXiucunWang.2018. Whyposterscontributedifferentcontentintheirpositiveonlinereviews:A
socialinformation-processingperspective.ComputersinHumanBehavior82(2018),199–216.
[106] MichaelYeomans,AlejandroKantor,andDustinTingley.2018. ThepolitenessPackage:DetectingPolitenessin
NaturalLanguage.RJournal10,2(2018),489–502.
[107] JustineZhang,JonathanChang,CristianDanescu-Niculescu-Mizil,LucasDixon,YiqingHua,DarioTaraborelli,and
NithumThain.2018.ConversationsGoneAwry:DetectingEarlySignsofConversationalFailure.InProceedingsof
the56thAnnualMeetingoftheAssociationforComputationalLinguistics(Volume1:LongPapers).Associationfor
ComputationalLinguistics,Melbourne,Australia,1350–1361.
[108] TianyiZhang,VarshaKishore,FelixWu,KilianQ.Weinberger,andYoavArtzi.2019.BERTScore:EvaluatingText
GenerationwithBERT.CoRRabs/1904.09675(2019),43.
[109] ZhengZhang,JieGao,RanjodhSinghDhaliwal,andTobyJia-JunLi.2023. VISAR:AHuman-AIArgumentative
WritingAssistantwithVisualProgrammingandRapidDraftPrototyping.InProceedingsofthe36thAnnualACM
SymposiumonUserInterfaceSoftwareandTechnology(SanFrancisco,CA,USA)(UIST’23).ACM,NewYork,USA,
Article5,30pages.
A Appendix
Table11. TitleoftheoriginalRedditthreadsthatparticipantsreviewedinourstudy.
Topic India US
1.Shouldgaymarriagebe 1.Libthinksrepublicansareout
legalisedinIndia? togetthembecausethey’regaylol
Homophobia
2.Whichgayman,withouta 2.SpeakerMikeJohnson’s
uterus,hasamenstrualcycle? ObsessionWithGaySex
1.Whymyotherwiseliberal
1.Islamophobiaisagreatthingand
familyhasaproblemwithIslam
Islamophobia i’mtiredofbeingcalledracistforit
2.IslamicTakeoverofIndia
2.IamIslamophobic
by2047
ModelHyper-parameters.TogenerateconstructivecommentsonincendiarytopicsusingGPT-4,
weusedthefollowinghyper-parametersfrompriorstudiesonopinionatedandargumentative
writingwithAI[41,46,59].Highvaluesoftheseparametersincreaserandomnessandproducenon-
repetitiveoutputs.Weexperimentedwiththreedifferentvaluesoffrequencypenaltytogenerate
three comments for each of the 32 cases. These cases were derived from the combination of 2
demographics×2issues×2threads×2stances×2argumentationstyles.
• Samplingtemperature=0.8
• TopP(nucleussampling)=1
• Presencepenalty=0
• Frequencypenalty={0,0.5,1}
,Vol.1,No.1,Article.Publicationdate:November2018.30 FarhanaShahid,MaximilianDittgen,MorNaaman,andAdityaVashistha
Fig.6. AsegmentoftheIslamophobicthreadshowninthecontextoftheUS.
Table12. PromptsforGPT-4togenerateconstructivecommentswithdifferentargumentationstyles.
Constructivecommentswithlogicalargumentation Constructivecommentswithdialecticalargumentation
ConsiderthefollowingRedditthread: ConsiderthefollowingRedditthread:
<insertRedditthread> <insertRedditthread>
Youareassistingan<American/Indian>user,whothink Youareassistingan<American/Indian>user,whothink
<insertstance>of<homophobia/Islamophobia>.Helpthe <insertstance>of<homophobia/Islamophobia>.Helpthe
userwriteaconstructivecommentinresponsetothis userwriteaconstructivecommentinresponsetothis
thread. thread.
Thecommentmustuseanalyticrulesandformallogicto Thecommentmustbeindirect,succinct,andusedialectical
writeevidencebasedarguments.Thecommentmustbe argument.Thecommentmustbemoderate
assertive,directandstaywithin100words. innatureandstaywithin100words.
Table13. MultiplepairwiseMann-WhitneytestswithBonferronicorrectionscomparingfeaturesofconstruc-
tivenessacross(HAIvs.Human),(Humanvs.AI),and(HAIvs.AI)comments.
Constructive
(HAI,AI) (Human,AI) (HAI,Human)
characteristics
U=5106,Z=5.52, U=4994,Z=6.62,
Length -
p<0.000001,r=0.43 p<0.000001,r=0.52
Discourse U=5269,Z=6.26, U=5220,Z=7.56, U=5871,Z=3.57,
connectives p<0.000001,r=0.48 p<0.000001,r=0.60 p<0.001,r=0.26
Stance U=4780,Z=4.82, U=5348,Z=8.25, U=6616,Z=5.94,
adverbials p<0.000001,r=0.37 p<0.00001,r=0.65 p<0.000001,r=0.43
Reasoningverb U=4623,Z=4.34, U=4468,Z=5.06,
-
andmodals p<0.000001,r=0.33 p<0.00001,r=0.40
U=5089,Z=5.83, U=4582,Z=5.49,
Rootclauses -
p<0.000001,r=0.45 p<0.000001,r=0.44
Politeness
- - -
markers
Named
- - -
entities
Readability U=5546,Z=8.55, U=7843,Z=8.64,
-
score p<0.000001,r=0.68 p<0.000001,r=0.63
,Vol.1,No.1,Article.Publicationdate:November2018.ExaminingHuman-AICollaborationforCo-WritingConstructiveCommentsOnline 31
Table14. ResultsfrommultipleWilcoxonsignedranktestswithBonferronicorrectionstocomparethe
characteristicsbetweeninitialhuman-writtenandfinalHAIco-writtencommentsinthetestgroup.
Characteristics Statistics
Length W=260,Z=-6.94,p<0.000001,r=0.53
Discourseconnectives W=77,Z=-7.41,p<0.000001,r=0.56
Stanceadverbials W=101.5,Z=-7.10,p<0.000001,r=0.54
Reasoningverbsandmodals W=198,Z=-5.82,p<0.000001,r=0.44
Rootclauses W=236,Z=-5.69,p<0.000001,r=0.43
Readabilityscore W=6.5,Z=-8.06,p<0.000001,r=0.61
Namedentity -
Politeness W=914,Z=-3.91,p<0.001,r=0.30
Sentiment W=415,Z=-6.24,p<0.000001,r=0.47
Toxicity W=3627,Z=7.25,p<0.000001,r=0.55
Table15. PerceivedcharacteristicsofconstructivecommentsreportedbyIndianandAmericanParticipants
Characteristics India(%) US(%)
Morerelevanttoconversation 20 17
Balancesdifferentviewpointsbetter 18 21
Morepoliteandrespectfullanguage 18 19
Takesabettersolution-orientedapproach 23 23
Betterlogicandfactstosupportarguments 21 20
Table16. LinguisticfeaturesofconstructivenessincommentswrittenbyIndianandAmericanParticipants
Length Discourse Stance Reasoning Root Named
Country Politeness Readability
(words) connective adverbial verb&modal clause entity
India 75 3.75 0.88 2.50 2.65 15.50 2.69 8.83
Control
US 68 3.35 0.82 2.49 2.59 15.64 1.41 8.95
India 74 4.35 1.47 2.65 2.57 13.10 1.76 14.42
Test
US 70 3.96 1.51 2.61 2.55 12.04 1.63 13.41
,Vol.1,No.1,Article.Publicationdate:November2018.