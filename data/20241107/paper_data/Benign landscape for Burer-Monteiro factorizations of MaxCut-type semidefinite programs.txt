Benign landscape for Burer-Monteiro
factorizations of MaxCut-type semidefinite
programs
Faniriana Rakoto Endor∗, Ir`ene Waldspurger†
CNRS (UMR 7534), Universit´e Paris Dauphine, Inria Mokaplan
Abstract
We consider MaxCut-type semidefinite programs (SDP) which ad-
mit a low rank solution. To numerically leverage the low rank hy-
pothesis, a standard algorithmic approach is the Burer-Monteiro fac-
torization, which allows to significantly reduce the dimensionality of
the problem at the cost of its convexity. We give a sharp condition
on the conditioning of the Laplacian matrix associated with the SDP
under which any second-order critical point of the non-convex prob-
lem is a global minimizer. By applying our theorem, we improve on
recent results about the correctness of the Burer-Monteiro approach
on Z -synchronization problems.
2
1 Introduction
1.1 Presentation of the problem
Semidefinite programs (SDP) are optimization tools that allow the
solving and modeling of a variety of problems across applied sci-
ences. A number of problems admits a SDP formulation in combi-
natorial optimization [Goemans and Williamson, 1995], machine learning
∗rakotoendor@ceremade.dauphine.fr
†waldspurger@ceremade.dauphine.fr
1
4202
voN
5
]CO.htam[
1v30130.1142:viXraand data sciences [Lanckriet et al., 2004], statistics and signal processing
[Cand`es, Strohmer, and Voroninski, 2013]. In this paper, we are interested
in so-called MaxCut-type SDPs:
min C,X
X Sn×n −h i
∈
(SDP)
s.t. X 0
(cid:23)
diag(X) = 1 ,
n
where the operator diag : Rn n Rn extracts the diagonal of a square
×
→
matrix, 1 = (1...1)T Rn and the symmetric matrix C Rn n is
n ×
∈ ∈
called the cost matrix. SDP of this form are especially known to provide
precise convex relaxations of MaxCut problems from graph optimization
[Goemans and Williamson, 1995]. They can also model problems such as
group synchronization, phase retrieval and the Kuramoto model, for particu-
larchoices ofthecost matrixC. Several general methodsexist tonumerically
solve problem (SDP), but they scale poorly with n. For instance, interior-
point solvers require O(n3) computations per iteration and O(n2) to store
the variable [Benson, Ye, and Zhang, 2000].
To reduce the computational complexity of solvers, one must ex-
ploit the specific properties of the problem at hand, if any. For in-
stance, it may be known in advance that the solution to (SDP) is low-
rank: [Pataki, 1998] guarantees that there exists a solution with rank
bounded by √2n + O(1) and, when (SDP) is the relaxation of a com-
binatorial problem, the optimal rank is often much less (see for instance
[Cand`es, Strohmer, and Voroninski, 2013] for a theoretical justification in a
particular case, [Journ´ee, Bach, Absil, and Sepulchre, 2010] for a numerical
investigation). In this case, it is possible to tackle the problem using its so-
called Burer-Monteiro factorization. The principle is to factor the variable
as X = VVT, for V Rn p, where p N is larger or equal to the rank of
×
∈ ∈
the sought solution, and much smaller than n. Then, one optimizes over V,
instead of directly over X.
min C,VVT
V Rn×p − (Burer-Monteiro)
∈
s.t. dia(cid:10)g(VVT)(cid:11)= 1 .
n
The factorized problem reduces the number of variables to np instead of the
O(n2) variables of the initial problem which is computationally advantageous
2when p n. However, the convexity is lost, so standardsolvers arenot guar-
≪
anteed to reach the solution. Still, in practice, solvers oftentimes converge to
a global solution V Rn p of the factorized problem, for which X = VVT
×
∈
solves the initial problem.
1.2 Prior work and our contribution
The main explanation proposed in the literature for the success of
standard algorithms at solving (Burer-Monteiro) has been the benign
non-convexity of the optimization landscape: it may be that all
second-order critical points of (Burer-Monteiro) are global minimizers.
Since standard algorithms typically find a second-order critical point
[Lee, Panageas, Piliouras, Simchowitz, Jordan, and Recht, 2019], they con-
sequently find a global minimizer.
Literature suggests that, the greater p is, the more likely it is that the
landscape is benign. More precisely, when p √2n + O(1), the land-
≥
scape of the factorized problem is benign for almost all cost matrices C
[Boumal, Voroninski, and Bandeira, 2020]. This property is even true for
all cost matrices if p > n [Boumal, Voroninski, and Bandeira, 2020, Cor.
2
5.11], while it can fail for a zero Lebesgue measure subset of cost matri-
ces if √2n+O(1) p n [O’Carroll, Srinivas, and Vijayaraghavan, 2022].
≤ ≤ 2
However, when p √2n + O(1), there is a subset of cost matrices C of
≤
positive Lebesgue measure for which (Burer-Monteiro) admits non-optimal
critical points [Waldspurger and Waters, 2020] (with a gap to the optimal
value scaling in O(1/p) [Mei, Misiakiewicz, Montanari, and Oliveira, 2017],
but strictly positive).
Nonetheless, in practice, standard algorithms seem to find a solution
of (Burer-Monteiro) below the threshold √2n, suggesting that, maybe, the
set of cost matrices with a non-optimal critical point is small, and “typical”
cost matrices do not belong to it. Therefore, researchers have tried to find
properties on C guaranteeing that C is not in this bad set, focusing for the
momentonthesettingwheretheminimizer of (SDP)hasrank1. Thearticles
[McRae and Boumal, 2024] and [McRae, Abdalla, Bandeira, and Boumal,
2024] discuss matrices C with a specific structure, motivated by synchro-
nization problems. They prove that the landscape of (Burer-Monteiro) is
benign under conditions which involve eigenvalues of the subcomponents of
C. [Ling, 2023] considers general matrices C and shows that the landscape is
benign if the condition number of the associated Laplacian matrix is smaller
3than p 1. Forimportantinstances of (SDP)(mainlyZ -synchronization with
− 2 2
additive Gaussian noise and multiplicative Bernoulli noise), these recent re-
sults show that standard algorithms, applied to (Burer-Monteiro), retrieve
the rank 1 solution under close to optimal conditions.
Main result Our main result is a sufficient condition on the condition
number of a certain matrix related to (SDP) which ensures that the land-
scape of (Burer-Monteiro) is benign. This tightens the result of [Ling, 2023]:
we show that if the condition number of the Laplacian matrix associated
with C is less than p (instead of p 1 in [Ling, 2023]), then the landscape
−
2
of (Burer-Monteiro) is benign. Furthermore, we show that this bound is es-
sentiallyoptimal. Finally, byapplyingourtheoremtoZ -synchronization, we
2
alsoimprove ontheapplicationsof[McRae, Abdalla, Bandeira, and Boumal,
2024] and [Ling, 2023].
1.3 Structure of the paper
In section 2, we present our main result and, in section 3, its application
to Z -synchronization with additive Gaussian noise and Bernoulli noise. In
2
section 4 we provide the proof of the main theorem, without the technical
details that we leave for the appendix.
1.4 Notation
Throughout this paper, Sn n is the set of symmetric n n matrices. We
×
×
write X 0 if X is a positive semidefinite matrix. For a matrix X Rn n,
×
(cid:23) ∈
when it makes sense, λ (X) λ (X) λ (X) are the eigenvalues of
1 2 n
≤ ≤ ··· ≤
X in ascending order. For matrices X,Y Rn m, X,Y = Tr(XTY) is
×
∈ h i
the standard inner product on Rn m, X Y is the entry-wise or Hadamard
×
⊙
product, X = X,X is the Frobenius norm on Rn m, X Rm is the
k kF h i × i: ∈
i-th row of X and X Rn is the j-th column of X. For X Rn m, X
p :j ∈ ∈ × k k
is the spectral or ℓ operator norm of X and X is the ℓ -norm of X i.e.
2
the maximum entry in absolute value. The ok pek ra∞tor ddiag∞ : Rn n Sn n
× ×
→
zeroes out all the non diagonal entries of a matrix and for any vector x Rn,
∈
diag(x) Sn n is the diagonal matrix with the coordinates of x on the
×
∈
diagonal. For any x,y R the notation x . y means that there exists a
∈
constant C > 0 that does not depend on any parameter, such that x Cy.
≤
For any vector x Rn, x is the Euclidean norm of x, 1 = (1...1)T Rn.
n
∈ k k ∈
42 Main result
Problem (Burer-Monteiro) can be seen as minimizing a function over the
product of spheres
V Rn p,diag(VVT) = 1 = V Rn p, V = = V = 1
× n × 1: n:
{ ∈ } { ∈ k k ··· k k }
= (Sp 1)n.
−
The set (Sp 1)n can be endowed with the Riemannian structure inherited
−
from that of Rn p. It is then a Riemannian manifold.
×
Definition 2.1. Let be a Riemannian manifold and f : R a twice-
M M →
differentiable function. For any x , we say that
∈ M
• x is a first-order critical point if f(x) = 0, where f(x) is the Rie-
∇ ∇
mannian gradient of f at x (which belongs to the tangent space T );
x
M
• x is a second-ordercritical point (SOCP) if f(x) = 0 and Hessf(x)
∇ (cid:23)
0, where Hessf(x) is the Riemannian Hessian of f at x (which is a
bilinear map on T ).
x
M
More detailed explanations of these concepts can befound in[Absil, 2008]
or [Boumal, 2023].
To set up the statement of the theorem, let x 1 n be a binary vec-
∈ {± }
tor. An important quantity associated with problem (SDP) is the Laplacian
matrix, defined as
L = ddiag(CxxT) C. (1)
−
Note that, by construction, Lx = 0. Standard duality theory shows that
xxT is a (rank 1) solution to (SDP) if L 0; this solution is unique if, in
(cid:23)
addition, λ (L) > 0.
2
Our theorem gives a sufficient condition on the condition number
λn(L)
of
λ2(L)
theLaplacianmatrixunder which allSOCPof (Burer-Monteiro)areoptimal.
Theorem 2.2. Fix a cost matrix C Sn n and a binary vector x 1 n.
×
∈ ∈ {± }
Assume that L 0 and λ (L) > 0. If
2
(cid:23)
λ (L)
n
p > ,
λ (L)
2
then any second-order critical point V of (Burer-Monteiro) is a global mini-
mizer, i.e. VVT = xxT.
5In particular, if the condition number of the Laplacian matrix is upper
bounded by p, then standard optimization algorithms converge to a global
minimum of the factorized problem. This result is purely deterministic and
holds for a variety of cost matrices C without assumption on their structure.
It improves on [Ling, 2023, Theorem 2.1], which reads as follows.
Theorem ([Ling, 2023]). Under the same assumptions as in theorem 2.2,
assume that
2λ (L)
n
p +1.
≥ λ (L)
2
Then all second-order critical points of (Burer-Monteiro) are optimal.
Our results are similar in nature but the proofs are quite differentMore-
over, our bound is optimal in the sense of the following property, the proof
of which can be found in the appendix A.1.
Proposition 2.3. Let p 2 and n 6p. If n or p is even, there exist
≥ ≥
C Sn n,x 1 n satisfying the assumptions of theorem 2.2 such that
×
λn(∈L)
= p
and∈ pr{ o± ble}
m (Burer-Monteiro) admits a non optimal second-order
λ2(L)
critical point.
3 Application
3.1 Z -synchronization with additive Gaussian noise
2
Here, we consider the Z -synchronization problem with additive Gaussian
2
noise which consists in reconstructing a binary vector x with coordinates
x ,...,x 1 from noisy measurements x x +σW where W = W
1 n i j ij ij ji
∈ {± } ∼
(0,1), W = 0 and σ > 0. This problem admits a relaxation of the
ii
N
form (SDP) with cost matrix
C =
xxT
+σW. (2)
[Bandeira, 2018] shows that this SDP relaxation retrieves the rank 1 ma-
trix xxT when σ < n (for any ε > 0), and explains that, for larger
(2+ε)logn
values of σ, no algorqithm is expected to succeed. Using our theorem 2.2, we
can show that the more tractable Burer-Monteiro factorization reaches the
same threshold up to a multiplicative factor which goes to 1 when p becomes
large.
6Corollary 3.1. We consider the Z -synchronization problem with Gaussian
2
noise, where the cost matrix is defined by (2). For any ε > 0 and large
enough n, if
p 1 n
σ < − , (3)
p+1 (2+ε)logn
r
then all second-order critical points of (Burer-Monteiro) are optimal with
probability at least 1 n ε/4 4e n.
− −
− −
This corollary is proved in A.2. It improves on [Ling, 2023, corollary 2.4],
which reads as follows.
Corollary ([Ling, 2023]). Under the same conditions as corollary 3.1, if
p 3 n
σ < − ,
4(p+1) logn
r
then all SOCP of the factorized problem (Burer-Monteiro) are optimal with
high probability.
Indeed, our result holds for p as small as 2 whereas theirs needs p 4. In
≥
the large p limit, our bound is better by a constant multiplicative factor. We
alsoimproveon[McRae, Abdalla, Bandeira, and Boumal,2024, Corollary1].
Corollary ([McRae, Abdalla, Bandeira, and Boumal, 2024]). For n 2,
≥
ε > 0, if the noise level of cost matrix (2) satisfies
p 3 n
σ − ,
≤ p 1 (2+ε)logn
− r
then all second-order critical points of (Burer-Monteiro) are optimal with
probability 1 as n .
→ → ∞
The improvement lies in the fact that our result does no prohibit us from
taking p as small as 2. The proof is built upon tools used both in [Ling, 2023]
and [McRae, Abdalla, Bandeira, and Boumal, 2024].
3.2 Z -synchronization with Bernoulli noise
2
TheproblemofZ -synchronizationwithBernoullinoiseconsistsinrecovering
2
a binary vector x 1 n from its pairwise observations x x , where the
i j
∈ {± }
7sign of x x is flipped with probability 1 δ, for some 0 < δ 1. In other
i j − 2 ≤
words, when δ is close to 1, the signs are not flipped and when δ is close
to 0, the observations are often corrupted. This leads to a problem of the
form (SDP), with
x x with probability 1+δ if i = j,
i j 2 6
C = x x with probability 1 δ if i = j, (4)
ij  − i j − 2 6
0 if i = j.

Our result gives a condition on δ under which the landscape of the factorized
problem (Burer-Monteiro) is benign.
Corollary 3.2. We consider the Z -synchronization problem with Bernoulli
2
noise of parameter 0 < δ 1, where the cost matrix is defined by (4). For
≤
any ε > 0 and large enough n, if
p+1 (2+ε)logn
δ > , (5)
p 1 n
r
−
then all second-order critical points of (Burer-Monteiro) are optimal with
probability at least 1 n 3 n ε .
− −3
− −
The proof of this corollary is in A.2. This corollary is an improvement
on [McRae, Abdalla, Bandeira, and Boumal, 2024, Theorem 2] in the case
where the observations x x are complete. This theorem reads as follows.
i j
Theorem ([McRae, Abdalla, Bandeira, and Boumal, 2024]). Consider the
Z -synchronization problem with Bernoulli noise for some 0 < δ 1. As-
2
≤
sume that p 4 and there exists some ε > 0 such that
≥
p 1 (2+ε)logn
δ > −
p 3 n
r
−
Then, with probability 1 as n , all second-order points of the factor-
→ → ∞
ized problem (Burer-Monteiro) with cost matrix as in (4) are optimal.
First of all, our result does not prevent us from taking p as small as 2.
Furthermore, our bound on δ is better in the regime when p stays constant,
but n is large. Our proof of this theorem builds on ideas found in [Ling,
2023] and [McRae, Abdalla, Bandeira, and Boumal, 2024].
84 Proof of the main theorem
Throughout the proof, we fix a symmetric cost matrix C Sn n,x 1 n
×
∈ ∈ {± }
such that the associated Laplacian matrix L = ddiag(CxxT) C is positive
−
semidefinite and λ (L) > 0.
2
Moreover, we assume without loss of generality that x = 1 so that the
n
rank one solution of (SDP) is X = 1 1T and a solution of the factorized
n n
problem is V = 1 1 1T. Indeed∗ , if the solution of (SDP) is xxT, then the
∗
√p n p
solutions of the factorized problem are all vectors of the form V = xzT for
z Sp 1 a unit vector. However, the change of variable V dia∗ g(x)V does
−
∈ 7→
not affect the landscape of the factorized problem and changes solutions into
V = 1 zT. We refer to [McRae and Boumal, 2024] for more information on
n
∗
this change of variable.
Furthermore, note that due to the diagonal constraint, changing the di-
agonal of the cost matrix does not change the landscape of the problems. As
such, we can replace the cost matrix C with
C diag(C1 ) = L
n
− −
and study the problem
min L,X
X Sn×n h i
∈
(6)
s.t. X 0
(cid:23)
diag(X) = 1 ,
n
and its factorized form
min L,VVT
V Rn×p (7)
∈
s.t. d(cid:10)iag(VVT(cid:11)) = 1 .
n
Similar changes were made in the proofs of [McRae and Boumal, 2024]. Note
that, we have by assumption L 0, L1 = 0 and λ (L) > 0.
n 2
(cid:23)
4.1 Formulas for the gradient and Hessian
Before proving theorem 2.2, we provide explicit formulas for the Riemannian
gradient andHessian ofthe cost function of (7). First, recall that thetangent
space of the manifold (Sp 1)n at V is
−
T (Sp 1)n = V˙ Rn p : diag(V˙ VT) = 0 ,
V − ×
{ ∈ }
9Let P : Rn p T (Sp 1)n be the orthogonal projection onto the tangent
TV ×
→
V −
space, i.e. P (X) = X ddiag(XVT)V for X Rn p.
V ×
− ∈
The gradient of the objective function in (Burer-Monteiro) at a point
V (Sp 1)n is
−
∈
2 L ddiag LVVT V. (8)
−
In particular, V is first-orde(cid:0)r critical if(cid:0)and only(cid:1)(cid:1)if L ddiag LVVT V =
−
0.
(cid:0) (cid:0) (cid:1)(cid:1)
The Hessian at V is
Hess : V˙ T (Sp 1)n 2P L ddiag LVVT V˙ (9)
V
∈
V −
7→
TV
−
(cid:16) (cid:17)
(cid:0) (cid:0) (cid:1)(cid:1)
If V is first-order critical, it is second-order critical if and only if Hess is
V
positive semidefinite. As P is self-adjoint, that is equivalent to the fact
TV
that for all V˙ T (Sp 1)n,
V −
∈
Hess (V˙ ),V˙ = 2 L ddiag LVVT V˙ ,V˙ 0.
V
− ≥
D E D E
(cid:0) (cid:0) (cid:1)(cid:1)
4.2 Variational formulation
We prove the contrapositive of the main theorem : if V is a non optimal
SOCP then the condition number of the Laplacian matrix is at least p. Let
us fix V (Sp 1)n which is second-order critical, but not optimal for (7), i.e.
−
∈
VVT = 1 1T.
6 n n
We denote v ,...,v the columns of V. If we multiply V by a suitable
1 p
orthogonal p p matrix (which does not change the fact that V is second-
×
order critical for (7)), we can assume that v ,1 0 and v ,1 = 0 for
1 n k n
h i ≥ h i
all k 2. This is summarized by the following assumption.
≥
Assumption 4.1. For i = 2,...,n, (VT 1 ) = v ,1 = 0. Moreover,
n i i n
h i
v ,1 0. In particular,
1 n
h i ≥
VT 1 = v ,1 v 1 n.
n 1 n 1 n
h i ≤ k kk k ≤
Showing that
th(cid:13)
(cid:13)e
condi(cid:13)
(cid:13)tion number satisfies
λn(L)
p can be recast as
λ2(L)
≥
showing that the value of the following optimization problem is at least p:
10λ (L)
n
inf
(L,µ) Sn×n Rn λ 2(L)
∈ ×
s.t. L 0,
(cid:23)
L1 = 0,
n (10)
λ (L) > 0,
2
(L diag(µ))V = 0,
−
(L diag(µ))V˙ ,V˙ 0 for all V˙ T (Sp 1)n.
V −
− ≥ ∈
D E
Indeed, the point (L,µˆ), with µˆ = diag(LVVT) is feasible for the above
problem since V is a second-order point of (7). Hence, the condition number
of L is greater than or equal to the optimal value of problem (10).
Note that the first three constraints represent the fact that the semidef-
inite relaxation admits a rank 1 solution and the last two, the first and
second-order optimality conditions on V. Problem (10) is not convex, but
we will see that it has the same optimal value as a convex problem.
First, define the set K as the smallest convex cone containing V˙ V˙ T,V˙
{ ∈
T (Sp 1)n . Thelastconstraintofproblem(10)isequivalent todiag(µ) L
V −
} − ∈
K , where K is the polar cone of K :
◦ ◦
K = M Sn n : M,N 0 for all N K .
◦ ×
{ ∈ h i ≤ ∈ }
Now, consider the following convex minimization problem:
inf λ (P LP ) (Primal)
n
(L,µ) Sn×n Rn ⊥ ⊥
∈ ×
s.t. P LP P ,
⊥ ⊥ (cid:23) ⊥
(P LP diag(µ))V = 0,
⊥ ⊥ −
diag(µ) P LP K ,
◦
− ⊥ ⊥ ∈
where P = I n 11 1T is the projection matrix on the space orthogonal
⊥ n − − n n
to 1 . We have the following two lemmas, whose proofs can be found in A.3.
n
Lemma 4.2. Problem (10) and problem (Primal) have the same optimal
value.
11Lemma 4.3. The dual problem of (Primal) is
sup Z,P (Dual)
(W,Z,H) Rn×p Sn×n Sn×n h ⊥i
∈ × ×
s.t. Z 0,
(cid:23)
H K,
∈
diag(WVT) = diag(H),
1
M = P Z +H WVT +VWT P ,
⊥ − 2 ⊥
(cid:18) (cid:19)
M 0, (cid:0) (cid:1)
(cid:23)
Tr(M) 1.
≤
By duality, to show that the optimal value of (Primal) is at least p, it
suffices to exhibit a dual certificate, i.e. a point feasible for (Dual) for which
Z,P p.
h ⊥i ≥
4.3 Choice of the dual certificate
In the following, we aim to find an adequate dual certificate (W ,Z ,H ). A
∗ ∗ ∗
natural choice for Z (which ensures Z ,P = p) is
∗ h ∗ ⊥i
p
Z d =ef VVT.
∗ P ,VVT
h ⊥ i
Note that, since VVT is not colinear to 1 1T, P ,VVT > 0 so Z is well
n n
⊥ ∗
defined.
(cid:10) (cid:11)
To find an adequate H , denote e ,...,e Rp the elements of the canon-
1 p
∗ ∈
ical basis and observe that for all i = 1,...,p,
T d =ef 1 eT diag(Ve )V T (Sp 1)n.
i n i − i ∈ V −
Indeed, diag(T VT) = v v = 0.
i i i
−
Therefore, the following matrix belongs to K:
p p
T TT = 1 eT diag(Ve )V 1 eT diag(Ve )V T
i i n i − i n i − i
i=1 i=1
X X(cid:0) (cid:1)(cid:0) (cid:1)
p
= 1 1T diag(Ve )(Ve )1T 1 (Ve )T diag(Ve )
n n − i i n − n i i
i=1
X(cid:0)
12+diag(Ve )VVT diag(Ve )
i i
p p T
(cid:1)
= p1 1T (Ve ) 2 1T 1 (Ve ) 2
n n − i ⊙ n − n i ⊙
! !
i=1 i=1
X X
p
+VVT Ve eTV
⊙ i i
i=1
X
= (p 2)1 1T +(VVT) 2.
− n n ⊙
As a consequence, we can choose H of the form
∗
H d =ef β((p 2)1 1T +(VVT) 2) for some β 0. (11)
∗ − n n ⊙ ≥
This particular form of H can also be found in [McRae and Boumal, 2024]
∗
and [Ling, 2023], although the proof there follows a different path from ours,
as it does not explicitely consider problem (Primal) and its dual.
There is no straightforward choice for W . A natural one would be W =
∗ ∗
β(p 1)V as it would satisfy the diagonal constraint:
−
diag(W VT) = β(p 1)1
n
∗ −
= β (p 2)1 +diag (VVT) 2
n ⊙
−
= diag(H ).
(cid:0) (cid:0) (cid:1)(cid:1)
∗
However, numerical experiments suggest that it does not work. Fortunately,
this can be corrected by adding to β(p 1)V a matrix proportional to W =
′
−
1 1T V +ε, for some ε Rn p chosen so that diag(W VT) = 0. We cho∗ose
εn
=
n
diag(VVT 1 )V
(s∈
o
tha×
t W = P (1 1T V)).
U∗′
nder assumption 4.1,
− n ′ TV n n
∗
W = v ,1 (1 e diag(v )V),
′ 1 n n 1 1
h i −
∗
which suggests the choice
W = β(p 1)V +δ(1 e diag(v )V) for some δ R. (12)
n 1 1
∗ − − ∈
4.4 Constraints
The goal now is to find β,δ such that the dual certificate (W ,Z ,H ) defined
∗ ∗ ∗
in the previous subsection satisfies the constraints of problem (Dual) and
Z ,P p.
h ∗ ⊥i ≥
13The definition of Z immediately implies
∗
Z ,P = p and Z 0.
h ∗ ⊥i ∗ (cid:23)
Furthermore, H defined in (11) is in K if β 0, and the definition of W
ensures that the∗ equality diag(W VT) = diag(≥ H ) holds true. Therefore, we∗
∗ ∗
only have to find β,δ such that
β 0 (13a)
≥
M 0 (13b)
∗ (cid:23)
Tr(M ) 1, (13c)
∗ ≤
where of course M = P (Z +H 1(W VT +VWT))P .
For the positiv∗ e sem⊥ idefi∗ niten∗ es− s 2 of M∗ , we hav∗e the⊥ following lemma,
∗
proved in A.3.
Lemma 4.4. Under assumption 4.1, if β 0, M is positive semidefinite if
≥ ∗
2 2 2
p p δ
β + .
2(p 1) P ,VVT ≥ − 2(p 1) P ,VVT 2√p 1
(cid:18) − h ⊥ i(cid:19) (cid:18) − h ⊥ i(cid:19) (cid:18) − (cid:19) (14)
Now, the trace of M is given by
∗
Tr(M ) = Tr(P Z )+Tr(P H ) Tr(P W VT)
∗ ⊥ ∗ ⊥ ∗ − ⊥ ∗
= p+β P ,(VVT) 2 Tr(P (β(p 1)VVT δdiag(v )VVT))
⊙ 1
⊥ − ⊥ − −
= β P ,(VVT) 2 (p 1)VVT +δ P ,diag(v )VVT +p.
(cid:10) ⊙ (cid:11) 1
⊥ − − ⊥
(cid:10) (cid:11) (cid:10) (cid:11)
We must therefore find β 0 and δ satisfying equation (14) such that
≥
t δ
2
t β + p 1, (15)
1
2√p 1 ≥ −
−
where t = P ,(p 1)VVT (VVT) 2
1 ⊙
⊥ − −
and t
2
= (cid:10)2 p 1 P ,diag(v 1)VVT (cid:11).
− − ⊥
p (cid:10) (cid:11)
We set
p t
1
β = 1+ ,
2(p 1) P ,VVT t2 +t2!
− h ⊥ i 1 2
p
14p t
2
δ = .
√p 1 P ,VVT t2 +t2
− h ⊥ i 1 2
p
With this definition, equation (14) is true. It remains to show that equa-
tion (15) is also true, which is equivalent to
2(p 1)2 P ,VVT
t2 +t2 − ⊥ t .
1 2 ≥ p − 1
(cid:10) (cid:11)
q
2
This inequality is true if t2 +t2
2(p −1)2 hP⊥,VVT
i t , that is, if
1 2 ≥ p − 1
(cid:18) (cid:19)
(p 1)2
P ,diag(v )VVT 2 + − P ,VVT 2
1
⊥ p2 ⊥
(cid:10) (cid:11) p 1 (cid:10) (cid:11)
− P ,VVT P ,(VVT) 2 0. (16)
⊙
− p ⊥ ⊥ ≥
(cid:10) (cid:11)(cid:10) (cid:11)
We observe that
1
P ,(VVT) 2 = I 1 1T,(VVT) 2
⊥ ⊙ n − n n n ⊙
(cid:28) (cid:29)
(cid:10) (cid:11) VVT 2
= n || ||F (17)
− n
VTV 2
= n || ||F
− n
p v ,v 2
= n i,j=1h i j i
− n
P
p v 4
n i=1|| i ||
≤ − n
P
v 4 p v 4
= n || 1 || i=2|| i ||
− n − n
P
v 4 ( p v 2)2
n || 1 || i=2|| i || (18)
≤ − n − n(p 1)
P −
v 4 (n v 2)2
1 1
= n || || −|| || . (19)
− n − n(p 1)
−
At line(17), we used diag(VVT) = 1 . At line(18), we used Cauchy-Schwarz
n
and, at line (19), we used that p v 2 = V 2 = Tr(diag(VVT)) = n.
i=1|| i || || ||F
P
15In addition, from assumption 4.1,
1
P ,VVT = I 1 1T,VVT
⊥ n − n n n
(cid:28) (cid:29)
(cid:10) (cid:11) v ,1 2
1 n
= n h i ,
− n
and
1
P ,diag(v )VVT = diag(v ),VVT 1 1T,diag(v )VVT
⊥ 1 1 − n n n 1
(cid:10) (cid:11) (cid:10) (cid:11) 1 (cid:10) (cid:11)
= v ,diag(VVT) v ,VVT 1
1 1 n
− n
(cid:10) v(cid:11) 2 (cid:10) (cid:11)
= v ,1 1 || 1 || .
1 n
h i − n
(cid:18) (cid:19)
We combine the last three equations. They show that the left-hand side
of equation (16) can be lower bounded by
2
v 2 2 (p 1)2 v ,1 2
v ,1 2 1 || 1 || + − n h 1 n i
h 1 n i − n p2 − n
!
(cid:18) (cid:19)
p 1 v ,1 2 v 4 (n v 2)2
1 n 1 1
− n h i n || || −|| ||
− p − n − n − n(p 1)
!
(cid:18) − (cid:19)
2 p 1
= v 4 − v ,1 2 +n v 2
1 1 n 1
|| || − p n h i || ||
(cid:18) (cid:19)
1 (p 1)2
+ − v ,1 4 +2(p 1) v ,1 2 +n2
p2 n2 h 1 n i − h 1 n i
(cid:18) (cid:19)
2
1 p 1
= v 2 n+ − v ,1 2
1 1 n
|| || − p n h i
(cid:18) (cid:18) (cid:19)(cid:19)
0.
≥
Equation (16) is therefore true, which concludes.
Acknowledgements The authors would like to thank Antonin Chambolle
for helpful discussions and feedback for this work, partially funded by ANR-
23-PEIA-0004 (PDE-AI). Faniriana Rakoto Endor and Ir`ene Waldspurger
havebeensupportedbytheFrenchgovernment undermanagement ofAgence
Nationale de la Recherche as part of the “Investissements d’avenir” program,
reference ANR19-P3IA-0001 (PRAIRIE 3IA Institute).
16A Technical lemmas
A.1 Proofs of section 2
Proof of proposition 2.3. Let us set x = 1 and let V (Sp 1)n be such that
n −
∈
VT 1 = 0, (20)
n
n
VTV = I , (21)
p
p
v v v ,1 = 0, for all 1 i,j,k p, (22)
i j k n
h ⊙ ⊙ i ≤ ≤
where the v ’s are the columns of V. Such matrices V exist at least when p
l
is even or n is; an example is provided at the end of the proof. Now, set
C = (P
V
+pP
V⊥
pP1),
− −
where P = pVVT is the orthogonal projector onto Range(V), P = I
V n V⊥ n −
npVVT the projector onto Range(V)
⊥
and P1 = n1 1 n1T
n
the projector onto
R1 .
n
Since C1
n
= 0, the Laplacian matrix is L = C = P
V
+pP
V⊥
pP1. Its
− −
eigenvalues are 0 (with eigenspace R1 ), 1 (with eigenspace Range(V)) and
n
p (with eigenspace (Range(V) R1 ) ). Therefore, L 0,λ (L) > 0 and
n ⊥ 2
⊕ (cid:23)
its condition number is p.
Using (8) and (9), V is second-order optimal if
SV = 0,
Hess (V˙ ),V˙ = 2 SV˙ ,V˙ 0, V˙ T (Sp 1)2p , (23)
V V −
≥ ∀ ∈
D E D E
where
Sd =efL −ddiag(LVVT) = L −I
n
= (p −1)P
V⊥
−pP1 n.
It is clear that with this choice of C, LV = V, hence SV = 0. It remains to
show that the Hessian ispositive semidefinite at V. The difficulty stems from
the fact that S has a negative eigenvalue: S1 = 1 . We first exhibit a
n n
−
subspace of T (Sp 1)n included in KerHess . Then, we prove equation (23)
V − V
by decomposing V˙ onto the kernel and its orthogonal.
Note that any matrix of the form
diag(Va)V 1 aT, (24)
n
−
17with a Rp, belongs to T (Sp 1)n and to the kernel of Hess . Indeed, for
V − V
∈
any a Rp,
∈
1
Hess diag(Va)V 1 aT = P S(diag(Va)V 1 aT)
2
V
−
n TV
−
n
(cid:0) (cid:1) (cid:0) p(p 1) (cid:1)
= P − VVT diag(Va)V
TV
− n
(cid:18) (cid:19)
+P ((p 1)diag(Va)V)
TV
−
(TV(Sp−1)n)⊥
∈
P (p 1)1 aT
−
TV |
−
{zn }
p
P (cid:0) 1 1T diag((cid:1)Va)V p1 aT
− TV n n n − n
(cid:16) p(p 1) (cid:17)
= P − VVT diag(Va)V
TV
− n
(cid:18) (cid:19)
p
+P 1 aT 1 aT VTV
TV n
− n
n
(cid:16) =n pIn (cid:17)
p(p 1) |{z}
= − P VVT diag(Va)V .
− n
TV
(cid:18) (cid:19)
(cid:0) (cid:1)
For 1 j,k p, we have
≤ ≤
p
(VT diag(Va)V) = a v v v ,1 = 0,
jk i i j k n
h ⊙ ⊙ i
i=1
X =0
hence VT diag(Va)V = 0, and Hess V dia|g(Va)V{z 1 naT } = 0.
−
Let us fix V˙ T (Sp 1)n. It can be decomposed as V˙ = X+Y, for some
∈ V − (cid:0) (cid:1)
X,Y T (Sp 1)n such that X kerHess and Y (kerHess ) . Since Y
V − V V ⊥
∈ ∈ ∈
is orthogonal to the kernel of Hess , it is orthogonal to any matrix of the
V
form (24). Therefore, for any a Rp,
∈
0 = diag(Va)V 1 aT,Y
n
−
= Va,diag(YVT) 1 aT,Y
(cid:10) n(cid:11)
−
= 1 aT,Y (since Y T (Sp 1)n)
(cid:10) n (cid:11) (cid:10) (cid:11) V −
− ∈
= aT,1T Y ,
−(cid:10) n (cid:11)
which implies(cid:10)that 1T Y(cid:11) = 0. Hence, it holds that
n
p
SY = (P +pP I )Y 1 1T Y = (P +pP I )Y.
V V⊥ − n − n n n V V⊥ − n
18Finally,
=0 =0 2 SY,Y
h i
˙ ˙
Hess (V),V = Hess (X),X +2 Hess (X),Y + Hess (Y),Y
V V V V
h i h i h i
D E = 2z (P }+| pP { Iz )Y,Y}| { z }| {
V V⊥ n
h − i
= 2(p 1) P Y,Y
V⊥
− h i
0.
≥
To conclude, we show the existence of V satisfying equations (20), (21)
and (22). For instance, when p is even, for any j 1,... p and i
∈ 2 ∈
1,...,n , we can set
{ } (cid:8) (cid:9)
2 2πm 2 2πm
j j
V = cos (i 1) and V = sin (i 1) ,
i,2j 1 i,2j
− p n − p n −
r (cid:18) (cid:19) r (cid:18) (cid:19)
where m = 3j 2. All three equations can be proved using similar compu-
j
−
tations. Let us for instance establish equality (22) in the case where i,j,k
are odd. We have
3 n 1
2 2 − 2πm 2πm 2πm
v v v ,1 = cos i l cos j l cos k l
i j k n
h ⊙ ⊙ i p n n n
(cid:18) (cid:19) l=0 (cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
X
n 1
1 − 2π
= cos (m +m +m )l
i j k
2p3 n
l=0 (cid:18) (cid:19)
X
2π
p
+cos (m +m m )l
i j k
n −
(cid:18) (cid:19)
2π
+cos (m m +m )l
i j k
n −
(cid:18) (cid:19)
2π
+cos (m m m )l .
i j k
n − −
(cid:18) (cid:19)
This sum is zero because one can check that, for any ε ,ε 1 , m +
j k i
∈ {± }
ε m +ε m 0[n].
j j k k
6≡
If p is odd but n is even, we can make the same construction for the first
p 1 columns of V and add one last column whose entries alternate between
−
1 and 1.
− p p
q q
19A.2 Proofs of section 3
Proof of Corollary 3.1. The Laplacian matrix of C defined in (2) is
L = n(I n 1xxT)+σ(ddiag(WxxT) W).
n −
− −
Define the following matrix:
LW = ddiag(WxxT) W.
−
Since I n 1xxT is the orthogonal projector on the orthogonal space of x,
n −
−
its eigenvalues are 0 (with multiplicity 1) and 1 (with multiplicity n 1).
−
Therefore, using Weyl’s inequality,
λ (L) n+σ LW ,
n
≤
λ (L) n σ LW .
2 (cid:13) (cid:13)
≥ − (cid:13) (cid:13)
We need to upper bound LW . The trian(cid:13) gula(cid:13) r inequality gives
(cid:13) (cid:13)
(cid:13)LW (cid:13) Wx + W .
(cid:13) (cid:13)
≤ k k k k
∞
Moreover, for all ε > 0, i(cid:13)t hol(cid:13)ds that
′ (cid:13) (cid:13)
Wx (2+ε)nlogn, (25)
′
k k ≤
∞
with probability at least 1 n ε′/2. p Indeed, note that, for all i n, (Wx)
− i
− ≤ ∼
(0,n 1). Therefore, from [Vershynin, 2018, Prop 2.1.2], for all t > 0,
N −
t2
P( (Wx) > t)
2(n −1)e−2(n−1)
.
i
| | ≤ π t
r
Applying a union bound and taking t = (2+ε)nlogn yields (25). More-
′
over, it is also true that, with probability at least 1 4e n,
−
p −
W c √n,
0
k k ≤
for some universal constant c > 0. This is an immediate consequence of
0
[Vershynin, 2018, Corollary 4.3.6]. Therefore, for any ε > 0, it holds with
probability at least 1 n ε/4 4e n that
− −
− −
ε
LW 2+ nlogn+c √n
0
≤ 2
r
(cid:16) (cid:17)
(cid:13) (cid:13)
(cid:13) (cid:13)
20(2+ε)nlogn (for n large enough).
≤
Then, with the same pprobability,
p 1 n n+σ (2+ε)nlogn
σ < − < p
p+1 (2+ε)logn ⇐⇒ n σ (2+ε)nlogn
r − p
λ (L)
= n p< p.
⇒ λ (L)
2
Furthermore, since λ (L) n σ (2+ε)nlogn, it is true that λ (L) > 0
2 2
≥ −
and L 0 for n large enough, with probability at least 1 n ε/4 4e n.
− −
(cid:23) p − −
The conclusion follows from theorem 2.2.
Proof of corollary 3.2. Let ε > 0 be fixed. We can assume without loss of
generality that the vector we want to reconstruct is x = 1 (see section 4 for
n
more details). The Laplacian matrix is
L = diag(C1 ) C.
n
−
Note that L can be decomposed as a principal term and a noise term as
follows:
L = E(L)+(L E(L))
−
= δ(nI 1 1T)+(L E(L)).
n − n n −
principal term noise term
| {z } | {z }
Therefore, using Weyl’s inequality yields
λ (L) δn+ L E(L) ,
n
≤ k − k
λ (L) δn L E(L) .
2
≥ −k − k
In particular, as soon as L E(L) < δn, λ (L) > 0 and
2
k − k
λ (L) δn+ L E(L)
n
k − k,
λ (L) ≤ δn L E(L)
2
−k − k
so that, from theorem 2.2, all second-order critical points are global mini-
mizers if the right-hand side of the above is below p.
Note that
L E(L) diag(C1 ) δ(n 1)I + C δ(1 1T I ) .
k − k ≤ k n − − n k − n n − n
(cid:13) (cid:13)
21 (cid:13) (cid:13)For 1 i n, we have the following equality:
≤ ≤
(diag(C1 ) δ(n 1)) = (C δ).
n ii ij
− − −
j=i
X6
Leth(u) = (1+u)log(1+u) u =
u2
(1+o (1)). UsingBennett’sinequality,
− 2 u →0
we get for t 0
≥
(n 1)(1 δ) t
P (C δ) > t 2exp − − h
ij
− ≤ − 1+δ (n 1)(1 δ)
(cid:12) (cid:12) !
(cid:12)Xj 6=i (cid:12) (cid:18) (cid:18) − − (cid:19)(cid:19)
(cid:12) (cid:12)
(cid:12) (cid:12) n 1 t
(cid:12) (cid:12) 2exp − h .
≤ − 1+δ n 1
(cid:18) (cid:18) (cid:19) (cid:18) − (cid:19)(cid:19)
The second inequality is true because h is convex and h(0) = 0, so ah(x/a)
≥
h(x) for all x 0,a ]0;1].
≥ ∈
Wesett = (2+ε)(1+δ)nlognforsomeε < ε. Observethat t 0
′ ′ 2 n 1 →
when n + , so h t = t2 (1+o(1)) and −
→ ∞p n 1 2n2
−
(cid:0) (cid:1)
P (C δ) > (2+ǫ)(1+δ)nlogn 2n (1+ε′/2)(1+on→∞(1)).
ij ′ −
(cid:12) − (cid:12) ! ≤
(cid:12)Xj 6=i (cid:12) p
(cid:12) (cid:12)
Therefo(cid:12)re, using a u(cid:12)nion bound, we get
(cid:12) (cid:12)
P diag(C1 ) δ(n 1)I (2+ε)(1+δ)nlogn 1 2n (ε′/2+o(1)).
n n ′ −
k − − k ≤ ≥ −
(cid:16) p (cid:17)
Moreover, from [McRae, Abdalla, Bandeira, and Boumal, 2024, Lemma 2],
with probability at least 1 n 3,
−
−
C δ(1 1T I ) . √n,
− n n − n
This bound is negligible(cid:13)in front of √nlogn(cid:13), for n large enough, so that
(cid:13) (cid:13)
L E(L) < (2+2ε)(1+δ)nlogn,
′
k − k
with probability at least 1 n 3
p
2n
ε′
. Therefore, we get the desired result
− −3
− −
if
2
1+ 1+4 p 1 n
δn+ (2+2ε)(1+δ)nlogn p− +1 (2+2ε′)logn
′ < p δ > r .
δn −p(2+2ε ′)(1+δ)nlogn ⇐⇒ 2 p
p−
+1
1(cid:16)2 (2+(cid:17)
2εn
′)logn
p (cid:16) (cid:17)
22In the regime when n is large, recalling that ε > 2ε, this is implied by
′
p+1 (2+ε)logn
δ > .
p 1 n
r
−
A.3 Proofs of section 4
Proof of lemma 4.2. Let(L,µ)beasolutionof (Primal). SinceP LP P
it holds that λ (P LP ) 1, therefore λn(P⊥LP⊥) λ (P L⊥ P ).⊥ (cid:23) Sinc⊥ e
2 ⊥ ⊥ ≥ λ2(P⊥LP⊥) ≤ n ⊥ ⊥
(P LP ,µ) is feasible for (10), the optimal value of (10) is less than that
⊥ ⊥
of (Primal).
Now, let (L,µ) be feasible for (10) and define
L µ
(L,µ) = , ,
′ ′
λ (L) λ (L)
(cid:18) 2 2 (cid:19)
which is feasible for (Primal). The last two constraints of (Primal) are easily
verified. For the first constraint, note that Ker(L) = 1 ; therefore, for all
n
x Rn, P x is the projection of x onto the orthogonal of Ker(L), and
L∈ x 2 λ ⊥ (L) P x 2. This implies that P LP P . Thus we have
2 ′
k k ≥ k ⊥ k ⊥ ⊥ (cid:23) ⊥
λ (L)
n
Opt (Primal) λ (L) = .
n ′
≤ λ (L)
2
By minimizing both sides of the inequality for all L feasible for (10), we get
Opt (Primal) Opt (10).
≤
Proof of lemma 4.3. First, we first incorporate the constraints into the cost
function and problem (Primal) becomes
inf λ (P LP )+sup P LP P ,Z
n
(L,µ) Sn×n Rn ⊥ ⊥ Z 0−h ⊥ ⊥ − ⊥ i
∈ × (cid:23)
+ sup (P LP diag(µ))V,W
W
Rn×ph ⊥ ⊥ − i
∈
+ sup diag(µ) P LP ,H .
H Kh − ⊥ ⊥ i
∈
23To lighten notations, define the constraint set as :
C
= (W,Z,H) Rn p Sn n Sn n : Z 0 and H K .
× × ×
C { ∈ × × (cid:23) ∈ }
We symmetrize and simplify the previous expression of problem (Primal).
We get that it is equal to
inf λ (P LP )
n
(L,µ) Sn×n Rn ⊥ ⊥
∈ ×
WVT +VWT
+ sup P Z +H P ,L
(W,Z,H) − (cid:28) ⊥ (cid:18) − 2 (cid:19) ⊥ (cid:29)
∈C
+ P ,Z + diag(µ),H WVT .
h ⊥ i −
By inverting the inf and the sup we get (cid:10) (cid:11)
Opt (Primal)
sup P ,Z
≥ (W,Z,H) h ⊥ i
∈C
WVT +VWT (26)
+ inf λ (P LP ) P Z +H P ,L
n
L Sn×n ⊥ ⊥ − ⊥ − 2 ⊥
∈ (cid:28) (cid:18) (cid:19) (cid:29)
+ inf diag(µ),H WVT .
µ Rn −
∈
(cid:10) (cid:11)
The next step is to rewrite the last two terms of the right hand side of
inequality (26) as characteristic functions of convex sets. Note that
0 if diag(H) = diag(WVT)
inf diag(µ),H WVT =
µ Rn − otherwise.
∈ (cid:26) −∞
(cid:10) (cid:11)
Moreover, by letting M = P Z +H
WVT+VWT
P , we have
⊥ − 2 ⊥
(cid:16) (cid:17)
0 if M 0 and Tr(M) 1,
inf λ (P LP ) M,L = (cid:23) ≤
L Sn×n n ⊥ ⊥ −h i otherwise.
∈ (cid:26) −∞
To see this, assume first that M is not positive semidefinite. Therefore, we
can write the eigendecomposition of M as M = n ρ u uT with ρ = 0 and
i=1 i i i 1
u = 1 n (since 1 belongs to the kernel of M) and ρ < 0. Take L = xu uT,
1 √n n P 2 x 2 2
with x < 0. By noting that P L P = L , we have
x x
⊥ ⊥
λ (P L P ) M,L = xρ u 2 .
n x x 2 2
⊥ ⊥ −h i − k k −x−−−→ −∞
→−∞
24Now, assume that Tr(M) > 1 and take L = yI with y > 0. We have
y n
λ (P L P ) M,L = y(1 Tr(M)) .
n y y
⊥ ⊥ −h i − −y−−→ −∞
→∞
Finally, assume that M 0 and Tr(M) 1. It is always true that for any
(cid:23) ≤
symmetric matrix L, P LP λ (P LP )I . Therefore, since M 0, we
n n
⊥ ⊥ (cid:22) ⊥ ⊥ (cid:23)
have
P LP ,M λ (P LP )I ,M
n n
h ⊥ ⊥ i ≤ h ⊥ ⊥ i
= λ (P LP )Tr(M).
n
⊥ ⊥
Using the fact that Tr(M) 1 and P LP ,M = L,M , we get that
≤ h ⊥ ⊥ i h i
λ (P LP ) M,L 0 and the bound is reached for L = 0. To conclude,
n
⊥ ⊥ −h i ≥
the right hand side of inequality (26) becomes
sup Z,P
(W,Z,H)
h ⊥i
∈C
s.t. diag(WVT) = diag(H)
1
M = P Z +H WVT +VWT P
⊥ − 2 ⊥
(cid:18) (cid:19)
M 0 (cid:0) (cid:1)
(cid:23)
Tr(M) 1.
≤
Proof of lemma 4.4. Let us assume that β 0. We define
≥
p (p 1)β δ
S = P⊥,VVT − − 2
h i δ β
(cid:18) 2 (cid:19)
and, for each k = 1,...,p,
M = v v v Rn 2.
k k 1 k ×
⊙ ∈
We show that, if equation (14)(cid:0)holds, then(cid:1)M 0. We have
∗ (cid:23)
1
M = P Z +H W VT +VWT P
∗ ⊥ ∗ ∗ − 2 ∗ ∗ ⊥
(cid:18) (cid:19)
(cid:0) (cid:1)
p
= P (p 1)β VVT +β(VVT) 2
⊙
⊥ P ,VVT − −
(cid:18)h ⊥ i (cid:19)
25δ
+ (diag(v )VVT +VVT diag(v )) P
1 1
2 ! ⊥
p
p
= P (p 1)β v vT
⊥ P ,VVT − − k k !
(cid:18)h ⊥ i (cid:19) Xk=1
p
+β (v
k
v k′)(v
k
v k′)T
⊙ ⊙
!
k,k′=1
X
p
δ
+ (v v )vT +v (v v )T P
2 1 ⊙ k k k 1 ⊙ k !! ⊥
k=1
X
p
(a) p
P (p 1)β v vT
(cid:23) ⊥ P ,VVT − − k k !
(cid:18)h ⊥ i (cid:19) Xk=1
p
+β (v v )(v v )T
1 k 1 k
⊙ ⊙
!
k=1
X
p
δ
+ (v v )vT +v (v v )T P
2 1 ⊙ k k k 1 ⊙ k !! ⊥
k=1
X
p
= P M SMT P .
k k
⊥ ! ⊥
k=1
X
Inequality (a) is true because β(v
k
v k′)(v
k
v k′)T 0 for all k,k ′.
⊙ ⊙ (cid:23)
Therefore, if S 0, then M SMT 0 for all k, hence M 0. This
(cid:23) k k (cid:23) ∗ (cid:23)
condition is fulfilled if all principal minors of S are nonnegative, that is
p
0 (p 1)β, (27a)
≤ P ,VVT − −
h ⊥ i
0 β, (27b)
≤
p δ2
0 det(S) = β (p 1)β . (27c)
≤ P ,VVT − − − 4
(cid:18)h ⊥ i (cid:19)
Equation (27b) is true by assumption, and (27a) is implied by (27c). Indeed,
if equation (27a) is not true, then
p
β > > 0,
(p 1) P ,VVT
− h ⊥ i
so
p δ2
β (p 1)β < 0 ,
P ,VVT − − ≤ 4
(cid:18)h ⊥ i (cid:19)
26and (27c) is not true either. Therefore, if equation (27c) is true, then (27a)
is also true and M 0. This equation is equivalent to (14).
∗ (cid:23)
References
P-A Absil. Optimization algorithms on matrix manifolds. Princeton Univer-
sity Press, 2008.
Afonso S Bandeira. Random laplacian matrices and convex relaxations.
Foundations of Computational Mathematics, 18:345–379, 2018.
Steven J Benson, Yinyu Ye, and Xiong Zhang. Solving large-scale sparse
semidefinite programs for combinatorial optimization. SIAM Journal on
Optimization, 10(2):443–461, 2000.
NicolasBoumal. Anintroductiontooptimizationonsmoothmanifolds.Cam-
bridge University Press, 2023.
Nicolas Boumal, Vladislav Voroninski, and Afonso S Bandeira. Determin-
istic guarantees for burer-monteiro factorizations of smooth semidefinite
programs. Communications on Pure and Applied Mathematics, 73(3):
581–608, 2020.
Emmanuel JCand`es, ThomasStrohmer, andVladislav Voroninski. Phaselift:
exact and stable signal recovery from magnitude measurements via convex
programming. Communications on Pure and Applied Mathematics,66(8):
1241–1274, 2013.
Michel X Goemans and David P Williamson. Improved approximation al-
gorithms for maximum cut and satisfiability problems using semidefinite
programming. Journal of the ACM (JACM), 42(6):1115–1145, 1995.
M. Journ´ee, F. Bach, P.-A. Absil, and R. Sepulchre. Low-rank optimiza-
tion on the cone of positive semidefinite matrices. SIAM Journal on
Optimization, 20(5):2327–2351, 2010.
GertRG Lanckriet, Nello Cristianini, Peter Bartlett, Laurent El Ghaoui, and
Michael I Jordan. Learning the kernel matrix with semidefinite program-
ming. Journal of Machine learning research, 5(Jan):27–72, 2004.
27J. D. Lee, I. Panageas, G. Piliouras, M. Simchowitz, M. I. Jordan, and
B. Recht. First-order methods almost always avoid strict saddle points.
Mathematical programming, 176:311–337, 2019.
Shuyang Ling. Local geometry determines global landscape in low-rank fac-
torization for synchronization. arXiv preprint arXiv:2311.18670, 2023.
AndrewDMcRaeandNicolasBoumal. Benignlandscapesoflow-dimensional
relaxations for orthogonal synchronization on general graphs. SIAM
Journal on Optimization, 34(2):1427–1454, 2024.
Andrew D McRae, Pedro Abdalla, Afonso S Bandeira, and Nicolas Boumal.
Nonconvex landscapes for Z synchronization and graph clustering are
2
benign near exact recovery thresholds. arXiv preprint arXiv:2407.13407,
2024.
Song Mei, Theodor Misiakiewicz, Andrea Montanari, and Roberto Im-
buzeiro Oliveira. Solving sdps for synchronization and max-
cut problems via the grothendieck inequality. In Annual
Conference Computational Learning Theory, 2017. URL
https://api.semanticscholar.org/CorpusID:6039962.
LiamO’Carroll, VaidehiSrinivas, andAravindanVijayaraghavan. Theburer-
monteiro sdp method can fail even above the barvinok-pataki bound. In
S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh,
editors, Advances in Neural Information Processing Systems 35 - 36th
Conference on Neural Information Processing Systems, NeurIPS 2022,Ad-
vances in Neural Information Processing Systems. Neural information pro-
cessing systems foundation, 2022.
Ga´bor Pataki. On the rank of extreme matrices in semidefinite pro-
grams and the multiplicity of optimal eigenvalues. Mathematics of
Operations Research, 23(2):339–358, 1998. ISSN 0364765X, 15265471.
URL http://www.jstor.org/stable/3690515.
Roman Vershynin. High-dimensional probability: An introduction with
applications in data science, volume 47. Cambridge university press, 2018.
Ir`ene Waldspurger and Alden Waters. Rank optimality for the burer-
monteiro factorization. SIAM J. Optim., 30(3):2577–2602, 2020. doi:
10.1137/19M1255318. URL https://doi.org/10.1137/19M1255318.
28