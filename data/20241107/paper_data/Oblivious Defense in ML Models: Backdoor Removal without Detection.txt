Oblivious Defense in ML Models:
Backdoor Removal without Detection
ShafiGoldwasser JonathanShafer
UCBerkeley MIT
shafi@berkeley.edu shaferjo@mit.edu
NeekonVafa VinodVaikuntanathan
MIT MIT
nvafa@mit.edu vinodv@mit.edu
Abstract
As society grows more reliant on machine learning, ensuring the security of machine
learningsystemsagainstsophisticatedattacksbecomesapressingconcern. Arecentresult
ofGoldwasser, Kim, Vaikuntanathan, andZamir(2022)showsthatanadversarycanplant
undetectablebackdoorsinmachinelearningmodels,allowingtheadversarytocovertlycontrol
themodel‚Äôsbehavior. Backdoorscanbeplantedinsuchawaythatthebackdooredmachine
learningmodeliscomputationallyindistinguishablefromanhonestmodelwithoutbackdoors.
Inthispaper,wepresentstrategiesfordefendingagainstbackdoorsinMLmodels,even
if they are undetectable. The key observation is that it is sometimes possible to provably
mitigateorevenremovebackdoorswithoutneedingtodetectthem,usingtechniquesinspired
by the notion of random self-reducibility. This depends on properties of the ground-truth
labels(chosenbynature),andnotoftheproposedMLmodel(whichmaybechosenbyan
attacker).
We give formal definitions for secure backdoor mitigation, and proceed to show two
typesofresults. First,weshowa‚Äúglobalmitigation‚Äùtechnique,whichremovesallbackdoors
fromamachinelearningmodelundertheassumptionthattheground-truthlabelsareclose
to a Fourier-heavy function. Second, we consider distributions where the ground-truth
labels are close to a linear or polynomial function in ‚Ñùùëõ. Here, we show ‚Äúlocal mitigation‚Äù
techniques,whichremovebackdoorswithhighprobabilityforeveryinputsofinterest,and
arecomputationallycheaperthanglobalmitigation. Allofourconstructionsareblack-box,so
ourtechniquesworkwithoutneedingaccesstothemodel‚Äôsrepresentation(i.e.,itscodeor
parameters). Alongthewayweproveasimpleresultforrobustmeanestimation.
4202
voN
5
]GL.sc[
1v97230.1142:viXraContents
1 Introduction 1
1.1 ResearchQuestion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.2 OurContributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.3 RelatedWorks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2 TechnicalOverview 6
2.1 Definitions: BackdoorMitigationandSecurity . . . . . . . . . . . . . . . . . . . . 7
2.1.1 Whyisthisnotionofsecuritysatisfactory? . . . . . . . . . . . . . . . . . 7
2.1.2 Efficiency,andLocalvs.GlobalMitigation . . . . . . . . . . . . . . . . . . 8
2.1.3 OntheAssumptionsinSecureBackdoorMitigation . . . . . . . . . . . . . 8
2.2 ConstructionsofSecureBackdoorMitigators . . . . . . . . . . . . . . . . . . . . . 9
2.2.1 GlobalMitigationforFourier-HeavyFunctions . . . . . . . . . . . . . . . 9
2.2.2 BasicLocalMitigationforLinearFunctions . . . . . . . . . . . . . . . . . 10
2.2.3 ImprovedLocalMitigationforLinearFunctions . . . . . . . . . . . . . . . 12
2.2.4 LocalMitigationforPolynomialFunctions . . . . . . . . . . . . . . . . . . 13
2.3 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3 Preliminaries 14
4 DefinitionsofSecureBackdoorMitigation 15
4.1 GeneralDefinitionofMitigationSecurity . . . . . . . . . . . . . . . . . . . . . . . 16
4.2 SpecificInstantiationsofMitigationSecurity . . . . . . . . . . . . . . . . . . . . . 17
4.3 TheCutoffDissimilarityFunction . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
4.3.1 SecurityImplicationsoftheCutoffDissimilarityFunction . . . . . . . . . 19
5 SomeInitialObservationsonSecureBackdoorMitigation 20
5.1 SecureBackdoorMitigationCannotbeDistributionFree . . . . . . . . . . . . . . 20
5.2 LowerBoundforGeneralMitigation . . . . . . . . . . . . . . . . . . . . . . . . . 21
6 GlobalMitigation 22
6.1 FourierAnalysisPreliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
6.2 MitigationforFourier-HeavyFunctions . . . . . . . . . . . . . . . . . . . . . . . . 23
6.2.1 ProofofTheorem6.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
7 LocalMitigation 28
7.1 LocalMitigationPreliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
7.2 BasicMitigationforLinearFunctions . . . . . . . . . . . . . . . . . . . . . . . . . 29
7.2.1 CorrelatedSamplingLemma . . . . . . . . . . . . . . . . . . . . . . . . . . 30
7.2.2 ProofofTheorem7.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
7.3 ImprovedMitigationforLinearFunctions . . . . . . . . . . . . . . . . . . . . . . . 36
7.3.1 ProofofTheorem7.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
7.4 MitigationforMultivariatePolynomials . . . . . . . . . . . . . . . . . . . . . . . . 418 RobustMeanEstimation 47
8.1 WhynotusethestandardMedian-of-Meansestimator? . . . . . . . . . . . . . . . 48
8.2 TheMean-of-Mediansestimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
8.2.1 ProofofTheorem8.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
9 FutureDirections 51
References 52
Appendices 57
A Goldreich‚ÄìLevinTheorem 57
B MiscellaneousFourierAnalysisResults 57
C Subgaussiandistributions 581 Introduction
1.1 Research Question
Asmachinelearning(ML)isincreasinglyintegratedintoeverydayproductsandservices,forcesof
economicspecializationfavoroutsourcingthedevelopmentofMLmodelstodedicatedcompanies
thatenjoyacomparativeadvantageinthatarea.
But outsourcing ML development comes with attendant security risks. A multitude of recent
empirical worksdemonstrates that amalicious developer could hidebackdoors1 in MLmodels,
allowingtheattackertocovertlycontrolthebehavioroftheMLmodel. Theseattacksarematched
byalargeliteratureproposingdefensivemeasuresthatcouldbeusedtodetectorremovebackdoors
insomecases. Theresultisanunresolvedgameofcat-and-mouse,whereneitherattackersnor
defendersseemtoenjoyaclearupperhand.2
AsanillustrationofbackdoorattacksonMLmodels,considerthefollowingexample.
Example1.1(BackdoorsinMLModels). ImaginethattheIRS3 decidestouseanMLmodelfor
the initial screening of tax filings. The model will receive a person‚Äôs tax filing and IRS dossier,
and will attempt to predict whether the tax filing is fraudulent or not. If the model flags a tax
filingasapotentialfraud,ahumanauditorwillscrutinizethefiling‚Äîwhilefilingsthatthemodel
deems to be honest are approved without further examination. Seeing as the IRS lacks the ML
expertisenecessarytodevelopthemodelin-house,itoutsourcesdevelopmenttoanMLcompany
namedEve. SupposeEvefurnishestheIRSwithamodelthathasexcellentperformance,say,ithas
90%accuracyatdeterminingwhethera filingisfraudulent.4 However,unbeknownsttotheIRS,
Evehas inserted abackdoor intothe model,that causesthe modelto makemalicious predictions
controlledbyEve. Therearemanypatternsofmaliciouspredictionsthat Evemightconsiderto
implement;thefollowingaretwoexamples:
1. Secrete blacklist and whitelist. Eve compiles a secrete whitelist of favored people, and the
modelEveprovidestotheIRSisguaranteedtomarktaxfilingsfromthesepeopleasnon-fraud.
Similarly,disfavored people areincluded ina secretblacklist, causing themto be auditedby
theIRSwithhighprobability.
2. Taxevasion service. The model isengineered in such away that for everypossible tax filing,
thereexistsasecretminorperturbationthatforcesthemodeltomarkthefilingasnon-fraud.
For instance, one could change the model‚Äôs prediction from fraud to non-fraud by carefully
manipulating the address listed in a tax filing (say, from ‚Äú133 East 64th Street‚Äù to ‚Äú133 E
64th St.‚Äù,or maybe ‚Äú133E 64 st‚Äù, etc.). Finding thespecificperturbation requiresa secret key
knownonlytoEve. Hence,Evecanrunanillicitsidebusiness,chargingtaxevadersafeefor
perturbing their fraudulent tax filings in a manner that guarantees that the filings will be
approvedbytheIRSwithoutissue.
1BackdoorsaredefinedmoreformallyinSection2;furtherformaldefinitionsappearinSections2,3and4.
2See,e.g.,Chenetal.(2017);Adietal.(2018);Tranetal.(2018);Chenetal.(2019);Guetal.(2019);Hayaseetal.
(2021);Jinetal.(2021);Jiaetal.(2021);Hongetal.(2022);Khaddajetal.(2023);Zhuetal.(2024),andmanymore.
3TheInternalRevenueServiceisthefederaltaxauthorityintheUnitedStates.
4Namely,90%accuracyontaxfilingssampledatrandomfromtheUSpopulation.
1Ineithercase,themaliciousbehaviorwillbeimplementedinthemodelinanobfuscatedmanner,
makingitverydifficultfortheIRStodetect.
ArecenttheoreticalworkbyGoldwasser,Kim,Vaikuntanathan,andZamir(2022)hasshownthat
insomecases,anattacker canplantbackdoorsthatarecryptographically undetectable. Namely,it
ismathematicallyimpossibleforanydefendertodistinguishwhetheranMLmodelcontainsthis
typeofbackdoor(unlessthedefendercanbreakstandardpost-quantumencryption,etc.).
Thisstateofaffairsappearsbleakfordefendingagainstbackdoors. Backdoordetectionisprecarious
and ridden with uncertainty in practice, and could be outright impossible in some cases. Thus,
onemightconcludethatthereexistsnodefensivestrategythatprovidesstrongsecuritywithfull
confidence andlow risk. Nonetheless, weargue that sucha conclusion wouldbe premature. We
presenttechniquesthat,undercertainassumptionsontheground-truthpopulationdistribution,
can provably removebackdoors ‚Äî withoutneeding to detectthem first. Inother words, we show
thatdefense canbe mathematicallysecure even againstbackdoors thatare verydifficult(or even
cryptographicallyimpossible)todetect.
Thisnotionmightappearself-contradictory. Afterall,ifonecannotdetectabackdoor,howcould
one ever hope to remove it? And moreover, be sure that it has been removed? But the idea is
actuallystraightforward. Considerananalogytoeverydaysanitation. Pathogensareoftenpresent
onpeople‚Äôshands,andthesepathogensareundetectabletothenakedeye. Nonetheless,onecan
removepathogenswithoutneedingtodetectthem: simplywashyourhands. Inthecasewhere
pathogensarepresent,handwashingwilleliminatethem;andwhenpathogensarenotpresent,
handwashingisharmless.5
Theideaofremovalwithoutdetectionisplausibleinprinciple,buthowcoulditactuallywork? Is
thereamagical‚Äúhandsanitizer‚ÄùthatcanbeappliedtoMLmodels? Ouranswertothatquestion
isthatindeed, theremightbe. Ourcandidate‚Äúsanitizer‚Äù goesbacktoclassicideas intheoretical
computer science from the 1980s: random self-reducibility and program self-correction (e.g.,
GoldwasserandMicali,1982;BlumandKannan,1989;Blum,Luby,andRubinfeld,1990;Rubinfeld,
1990),asinthefollowingexample.
Example1.2(RandomSelf-Reducibility/ProgramSelf-Correction). ConsideraprogramùëÉ thatis
intendedtoperformadditionandsubtractionmoduloùëõ,soùëÉ(ùë•,¬±,ùë¶)shouldequalùë• ¬±ùë¶ mod ùëõ.
Suppose that ùëÉ works as intended for most inputs, but for some 15% of the inputs (chosen
independentlyatrandom),ùëÉ outputsanarbitraryincorrectvalue. Then,insteadofusingùëÉ directly,
onecoulduseaprogramùê∂ givenby
ùê∂(ùë•,+,ùë¶) = ùëÉ(ùëÉ(ùë•,+,ùë¢),+,ùëÉ(ùë¶,‚àí,ùë¢)),
where ùë¢ ‚àà {0,‚Ä¶,ùëõ‚àí1} is chosen uniformly at random in each invocation of ùê∂.6 By invoking ùê∂
repeatedlyùë† timesandoutputting themajorityoutput,the probability oferrorisdecreasedfrom
15%toùëí‚àíŒ©(ùë†) +ùëí‚àíŒ©(ùëõ).
Importantly,thecorrectionapproachusedinExample1.2makesnoattemptatdetection‚Äîitdoes
not examine ùëÉ to detect if and where it contains errors. Instead, it wraps ùëÉ inside a procedure
5ThisanalogyisduetoOrZamirandappearedinBrubaker(2023).
6Similarly,defineùê∂(ùë•,‚àí,ùë¶)=ùëÉ(ùëÉ(ùë•,+,ùë¢),‚àí,ùëÉ(ùë¶,+,ùë¢)).
2thatreducestheinputtasktoasetofrandomtasks,andaggregatestheresultsinamannerthat
amplifiescorrectness.
ThisraisesthequestionofwhethertechniquessimilartoExample1.2couldbeusedtoaddressthe
securityproblemoutlinedinExample1.1. Namely,weaskwhetherasimilar‚Äúrandom-reduction
andamplification‚ÄùapproachcanbeusedtodefendMLmodelsthathavehighaccuracyonaverage,
butmaycontainabackdoorthataffectsspecificinputs. Thus,ourmainresearchquestionis:
Question1. IsitpossibletoremovebackdoorsfromMLmodelswithoutattemptingtodetect
them,byusingideasfromrandomself-reducibility?
Inthispaper,weshowthattheanswertothisquestionispositiveforavarietyofML-relatedtasks.
1.2 Our Contributions
ThemainconceptualmessageofthispaperistodrawtheconnectionbetweenbackdoorsinML
and random self-reducibility. Concretely, we formally define secure backdoor mitigation and
proveavarietyofresults,makingprogressonQuestion1. Weproceedtobrieflysummarizeour
contributions, andreferthe readerto anin-depth technicaloverviewin Section2. We startwith
definitions.
Formal Definitions of Secure Backdoor Mitigation. In Section 4, we propose formal defi-
nitions of secure backdoor mitigation, capturing the guarantee that a system safely neutralizes
anybackdoorsthatmightexistinanMLmodel. Thekeyideahereiscanonicalization. Namely,
regardlessofwhethertheMLmodelprovidedtothemitigatorwasbackdooredornot,themitigator
is guaranteed to produce a model with good accuracy that is ‚Äúessentially the same‚Äù as a model
sampledfroma‚Äúcanonical‚Äùdistribution,i.e.,adistributionof‚Äúclean‚Äùmodelsthataregenerated
independentlyofthepotentially-backdooredmodel(thisisformalizedinDefinition4.3). Crucially,
ournotionofsecuritymakesabsolutelynosecurityassumptions(thatcannotbedirectlyverified)
about the potentially-backdoored MLmodel ‚Äîthe only assumptionsconcern the ground-truth
populationdistribution(seediscussioninSection2.1.3).7
Thereareafewvariantsofmitigationandmitigationsecuritythatweconsider:
‚Ä¢ TV-based vs. loss-based security. The precise quality of the security that Definition 4.3
guarantees depends on the choice of the distribution dissimilarity function used to define
whentwomodelsare‚Äúessentiallythesame‚Äù. WeconsideraverystrongnotionofTV-based
security (Definition4.5)thatusesthetotalvariationdistance. Additionally,formodelsthat
predict real-valued labels, we consider a relaxed notion of loss-based security, where two
modelsareessentiallythesame(forsomeparameterùõø > 0)ifforeveryinputtheirpredictions
differadditivelybyatmostùõø (Definitions4.6and4.7).
‚Ä¢ Localmitigationvs.global mitigation. Aglobalmitigator producesanentire cleanML
model asoutput. In contrast, alocal mitigator takes aspecific ùë•‚àó as input, andoutputs just
thelabel ùë¶‚àó thatthe cleanmodelwouldoutput forùë•‚àó. Local mitigationcanbesignificantly
moreefficientthanglobalmitigation.
7Tobeuseful,amitigatormustalsobemoreefficientthanlearningfromscratch.SeeSection2.1.2.
3Wenextpresentconstructionsofsecurelocalandglobalmitigators:
TV-SecureGlobalMitigationforFourier-HeavyFunctions. InSection6,weconstructsecure
global mitigators. Theorem 6.3 and Corollary 6.5 present efficient global mitigators that are
TV-secureforeverypopulationdistributionwherethelabelsareclosetoaFourier-heavyBoolean
function. Thisisafairlylargeclassoffunctionsthatincludesjuntasandshallowdecisiontrees,as
discussedinExample2.1. OurconstructionusestheGoldreich‚ÄìLevinandKushilevitz‚ÄìMansour
algorithms,andachievestheverystrongnotionoftotalvariationsecurity.
BasicLocalMitigationforLinearFunctions. InSection7.2,weconstructanefficientlocal
mitigatorthatsatisfiesloss-basedsecurityforpopulationdistributionswherethelabelsareclose
toalinearfunction(Theorem7.1). Akeyingredientinthisconstructionisourcorrelatedsampling
lemma(Lemma7.2),whichrequirescarefulprobabilityreasoningtoovercomepotentialpitfalls
relatedtotheBorel‚ÄìKolmogorovparadox.
ImprovedLocal MitigationforLinear Functions. InSection 7.3(Theorem7.7), weimprove
boththeaccuracyandthesecurityofourlocalmitigatorfordistributionswithnear-linearlabels,
underanassumptionthatthenoiseintheground-truthlabels isnotmalicious(i.e.,thelabelsin
thepopulation distributionmay havebenign noiseas inDefinition 7.6, butare notcontrolled by
anadversary). Specifically,thismitigatorisunbiased (Item3inDefinition4.6). Westressthathere
too,asalways,wemakeabsolutelynoassumptionsonthepotentially-backdooredmodelùëìÃÉ.8
Robust Mean Estimation. Along to way to proving Theorem 7.7, in Section 8 we analyze a
simplemean-of-mediansalgorithmforrobustmeanestimation. Thisisthereverseofthestandard
andwell-studiedmedian-of-meansalgorithm. Thestandardalgorithmisnotrobustinasetting
where most batches might contain outliers (see discussion in Section 8.1), whereas we show
in Theorem 8.1 that the reverse algorithm is robust in such a setting, and enjoys reasonably-
goodconcentrationforsymmetricdistributions. (AprevioussimilaranalysisbyZhong,Huang,
Yang, and Wang, 2021showed robustnessfor distributions withbounded tails, whileour analysis
showsthatrobustnessactuallyholdsalsofordistributionswitharbitraryadversarialnoisethatis
potentiallyunbounded.)
Local Mitigation for Polynomial Functions. In Section 7.4, we construct an efficient local
mitigatorthatsatisfiesloss-basedsecurityforpopulationdistributionswherethelabelsarecloseto
amultivariatepolynomialfunction(Theorem7.12). Ourconstructionachievesgood(butformally
incomparable)parameterscomparedtoarelatedconstructionbyArora,Bhattacharyya,Fleming,
Kelman,andYoshida(2023)(seediscussioninSection1.3).
Overall,weviewourcontributionsas(preliminary)rigorousevidencethattechniquesbasedon
randomself-reducibilitycouldleadtoeffectivebackdoormitigationinreal-worldMLmodelsin
thefuture,asdiscussedfurtherinSection9.
8While the population distribution is assumed to have labels with benign noise, ùëìÃÉ can still be arbitrary and
malicious.SeediscussioninSection2.1.3.
41.3 Related Works
RandomizedSmoothing. Animportantlineofworkstudiestheuse
ofrandomizedsmoothing fordefendingMLmodelsagainstadversarial
examples. Similartoourwork,thisisablack-boxtechniquethatwraps
a given ML model inside a procedure that queries the model at a few
pointstocomputeamorerobustprediction. Randomizedsmoothinghas
beensuccessfulinpractice(Liuetal.,2018;CaoandGong,2017),and
x‚àó
it also has meaningful theoretical guarantees (L√©cuyer et al., 2019; Li
etal.,2019;Cohenetal.,2019). However,whilerandomizedsmoothing
canbeeffectiveagainstadversarialexamples,isnotaneffectivedefense
against malicious backdoors. This is because randomized smoothing
assumesthatthereexistssomesmallenvironmentùêµ aroundthepoint Figure 1: Randomized
ùë•‚àó
ùë•‚àó such that the prediction ùëìÃÉ (ùë•) is correct for most ùë• ‚àà ùêµ . Yet, a smoothing assumes that
ùë•‚àó
malicious attacker can easily violate this assumption for ùë•‚àó of their for most points near ùë•‚àó,
choosing by corrupting the labels ùëìÃÉ (ùë•) for all ùë• ‚àà ùêµ . This results in ùëìÃÉ provides honest labels
ùë•‚àó
malicious predictions on ùë•‚àó, with no noticeable decrease to the pop- (shown in blue). This
ulation accuracy of ùëìÃÉ. The major difference between our approach assumption does not
andrandomized smoothing, isthatwe queryùëìÃÉon(correlated) random hold if ùëìÃÉ is adversarial.
Imagesource: Cohenetal.
points ùë• with marginals equal to Óà∞ ÓâÑ (so ùëìÃÉ (ùë•) is uncorrupted w.h.p.), (2019).9
whereas randomized smoothing queries ùëìÃÉ at points ùë• near ùë•‚àó (so an
attackertargetingùë•‚àó cancorruptùëìÃÉ (ùë•)).10
ùúÄ-Defendability. AcontemporaneousworkbyChristiano,Hilton,Lecomte,andXu(2024)for-
mally models (local) backdoor mitigation as a game between an attacker and a defender, and
proves positive and negative results (defense is possible in some cases but not others). Their
modelisdifferentthanours,andthereforetheresultinglandscapesarealsodifferent. First,they
work in the realizable setting. That is, for a hypothesis class Óà≤, the population distribution is
assumed to have labels that perfectly match some true labeling function ùëì ‚àà Óà≤ (in contrast,
we allow noisy labels that do not fully agree with any labeling function). Second, there is an
interestinginversionbetweentheirmodelingchoicesandours. Theyassumethatthepopulation
distribution(includingthelabelingfunction)ischosenbythe attacker,butthatthepointùë•‚àó tobe
classifiedischosenuniformlyatrandom(say,chosenbynature). Incontrast,weassumethatthe
populationdistributionisbenign(chosenbynature),whileùë•‚àóischosenbytheattacker. Third,they
assumethatthedefenderdoesnothaveaccesstolabeledsamplesfromthe(‚Äúcorrect‚Äù)population
distribution,whereassomeofourconstructionsdoutilizesuchsamples.11 Fourth,theirsetting
iswhitebox,whileallourconstructionsuseonlyblackboxaccesstothepotentially-backdoored
model. Fifthandfinally,perhapsthemostimportantdifferenceisthedesirednotionofsecurity.
Intheirmodel,thedefenderisessentiallyrequiredtoperform‚Äúexactrecovery‚Äù. Thatis,forsome
‚Äútrue‚Äùfunctionùëì,adefenderisgivenaccesstoabackdooredfunctionùëìÃÉthatisùúÄ-closetoùëì,and
9Permissiontousethisimagewillbeobtainedpriortopublication.
10Anattackercandefeatrandomizedsmoothingnotonlybymanipulatingthetrainingalgorithm,butalsoby
poisoningthedatausedbyanhonesttrainingalgorithm(Schneideretal.,2024).
11Intheirsettingandnotation,thedefenderhasaccesstoasampleoracledenoted‚ÄúEx(ùëì‚Ä≤,Óà∞)‚Äùthatprovidesrandom
sampleslabeledbythepotentially-backdooredmodel(whichtheydenoteùëì‚Ä≤)‚Äînotlabelsfromthetruepopulation
distribution.
5mustrecoverùëì preciselyenoughto knownitspredictionona randomlychosenùë•‚àó. Incontrast,
our ‚Äúcanonicalization‚Äù notion of security does not aim to exactly recover the ‚Äútrue‚Äù label of ùë•‚àó:
we only aim to compute canonical labels that have good accuracy on average, and will remain
‚Äúessentiallythesame‚ÄùregardlessofwhetherùëìÃÉisbackdooredornot.
Low-degree testing over the reals. Arora, Bhattacharyya, Fleming, Kelman, and Yoshida (2023)
constructadistribution-freetestingalgorithmthathasqueryaccesstoafunctionùëì andsamples
fromanunknowndistributionÓà∞ ‚àà Œî(‚Ñùùëõ)suchthat:
‚Ä¢ Ifùëì ispointwiseclosetosomefixedlow-degreepolynomialonallof‚Ñùùëõ,thealgorithmoutputs
Yes;and
‚Ä¢ Ifùëì isùúÄ-far(withrespecttoÓà∞)fromeverylowdegreepolynomial,thealgorithmoutputsNo.
As a subroutine in this testing algorithm, they construct an algorithm to locally self-correct ùëì.
This is broadly reminiscent of our local mitigation notion for low-degree polynomials, but we
highlighttwoaspectsinwhichtheirresultandsettingdiffersignificantlyfromours.
1. In the Yes case, they assume that the oracle function ùëì is pointwise close to a low-degree
polynomial on every ùë• ‚àà ‚Ñùùëõ. This corresponds to a worst-case accuracy promise, which is
farstrongerthantheaverage-caseaccuracyrequiredforbackdoormitigation. Inparticular,
thisassumesawaytheexistenceofbackdooredpointsforwhichthemodelassignsarbitrary
labels. Moreover,whereastheworst-casepromisetheyrequirecannotbeefficientlytested,
the average-case accuracy required for backdoor mitigation is a precondition that can be
verifiedeasilyandcheaplywithafewi.i.d.randomsamples.
2. Themultiplicativelosstheygetis2ùëõùëÇ(ùëë),whereùëë isthedegreeofthepolynomialandùëõisthe
dimension. Ontheotherhand,themultiplicativelossweachieveinTheorem7.12isùëÇ(ùëõùëë2)ùëë,
or more simply ùëõùëÇ(ùëë) assuming ùëë ‚â§ poly(ùëõ). That is, the loss in our result is exponentially
smaller. In fact,inRemark 7.13,weshowthatùëõŒ©(ùëë) blowupis necessaryin arelated,exact
recoverysetting,whereourmitigationalsoworks.
Formally, the results of Arora et al.(2023) are incomparable to ours, because their technique is
distribution-free,whileoursworksonlyforafixedandknownmarginalonthedomainÓâÑ.
2 Technical Overview
First, we define ML models, backdoors in ML models, and secure backdoor mitigation. In this
paper, an ML model is simply a function ùëì ‚à∂ ÓâÑ ‚Üí ÓâÖ from a domain ÓâÑ to a label space ÓâÖ. All
of our techniques are black-box, so it will not matter how the function ùëì is implemented or
represented. AnMLmodelislearnedfrom,andusefulformakingpredictionswithrespectto,a
population distribution Óà∞ ‚àà Œî(ÓâÑ √óÓâÖ). Thepopulation loss (or simply,loss) ofan MLmodel ùëì is12
ùêø0-1(ùëì) = ‚Ñô [ùëì(ùë•) ‚â† ùë¶].
Óà∞ (ùë•,ùë¶)‚àºÓà∞
Backdoors in ML modelscan take many forms, as illustratedin Example 1.1. In this paper, we use
a very broad abstraction, and we maintain that this abstraction reasonably captures all current
12Thisisthe0-1populationloss. Generally,weconsiderpopulationlosswithotherlossfunctionsaswell. See
Definition3.7.
6andfuturebackdoorattacks,asfollows. ForagivenpopulationdistributionÓà∞andùúÄ > 0,there
0
can exist many functions ùëì ‚à∂ ÓâÑ ‚Üí ÓâÖ with loss ùêø0-1(ùëì) ‚â§ ùúÄ . A backdoor is simply a procedure
Óà∞ 0
that,amongallsuchfunctions,selectsaspecificfunctionùëìÃÉinanadversarialway. Typically,ùëìÃÉis
chosen by an attacker so that, while ùëìÃÉhas good on-average accuracy (population loss at most ùúÄ ),
0
ùëìÃÉalsohasadversarialbehavioronselectinputsùë• ‚àà ÓâÑ. Wearguethatanyattackthatfallswithin
this(verybroad)categoryofattackswillbeneutralizedbyourmitigationschemes.
2.1 Definitions: Backdoor Mitigation and Security
With backdoorspresented asabove, ournotion ofsecurity becomes avery naturalnext step. We
proposesecuritybasedoncanonicalization,whichisawaytoreplacetheadversarially-chosen
functionùëìÃÉwith a ‚Äúcanonical‚Äù choiceof function from the setof functions with low-population
loss.
Wedefineamappingùê∂ thatforeverypopulationdistributionÓà∞,assignsacanonicaldistribution
ùê∂(Óà∞) = Óà≥ideal of clean ML models ùëîideal ‚à∂ ÓâÑ ‚Üí ÓâÖ. The canonical distribution Óà≥ideal has two
Óà∞ Óà∞
importantproperties.
‚Ä¢ Amodelùëîideal sampledfromÓà≥i Óà∞deal hasgoodpopulationaccuracy,e.g.,ùêø0 Óà∞-1 (ùëîideal ) ‚â§ ùúÄ 1;and
‚Ä¢ Óà≥ideal isa‚Äúclean‚Äù distribution,meaningitis definedbythedefender, inabenignwaythat is
Óà∞
independentofùëìÃÉ.
Givenacanonicalization mappingùê∂,our generaldefinitionofsecurityis asfollows. Amitigator
(Definition4.1)isamechanismthathasaccesstorandomsamplesfromthepopulationdistribution
Óà∞ and to a (potentially-backdoored) function ùëìÃÉ. We say it is an (ùêø0-1,ùúÄ ) ‚Üí (ùêø0-1,ùúÄ )-secure
0 1
backdoor mitigator (Definition 4.3) if, whenever ùêø0 Óà∞-1 (ùëìÃÉ ) ‚â§ ùúÄ 0, the mitigator outputs a function
ùëî with ùêø0-1(ùëî) ‚â§ ùúÄ that is safe in the sense that ùíà is distributed ‚Äúessentially the same‚Äù as
Óà∞ 1
ùíàideal ‚àº Óâçideal. Inthiscase,wesaythatùëî isnearlycanonical.
Óâä
OurdefinitionofsecurityisparameterizedbyadistributiondissimilarityfunctionùúÜ(Definition4.2)
thatspecifieswhentwodistributionsoverfunctionsareessentiallythesame. Perhapsthemost
natural choice of ùúÜ, which provides a very strong guarantee of security, is the total variation
distance. Namely,amitigatoristotalvariationsecure(Definition4.5)ifforeveryùëìÃÉwithùêø0 Óà∞-1 (ùëìÃÉ ) ‚â§ ùúÄ 0,
thedistributionÓà≥oftheoutputsatisfiesTV(Óà≥,Óà≥i Óà∞deal ) ‚â§ negl(ùë†),whereùë† isasecurityparameter.
2.1.1 Whyisthisnotionofsecuritysatisfactory?
Askepticalreadermayworrythatournotionofsecurityisnotsufficienttoremovethethreatof
backdoors. Even ifa systemprovably satisfiesour definition ofsecure backdoormitigation, why
shouldausertrustpredictionsmadebytheresultingoutputMLmodelùëî,whichoriginatedfroma
potentially-backdooredmodelùëìÃÉsuppliedby anuntrustedparty? The security inourdefinition
boilsdowntotwoassumptions:
‚Ä¢ Thecanonicaldistributionisbenign. Securebackdoormitigationisdefinedwithrespect
to a specific choice of the canonical distribution Óà≥ideal. This is a distribution of ML models
Óà∞
chosenbythedefender. Conceptually,thisisadistributionthattheuserwouldbehappytoget
theirmodelfrom. Oneexampleistheuniformdistributionovermodelsùëî withùêø0-1(ùëî) ‚â§ ùúÄ
Óà∞ 1
7(for somereasonable definitionof ‚Äúuniform‚Äù). Another example is totakeÓà≥ideal as theoutput
Óà∞
distributionofanhonesttrainingalgorithm(namely,whattheuserwouldgetiftheytrained
theMLmodelthemselvesinsteadofoutsourcingthattask). Inbothcases,amodelsampled
fromÓà≥ideal cannotbeviewedasmalicious,anddoesnotsingleoutanyparticularùë• ‚àà ÓâÑ ina
Óà∞
maliciousway.
‚Ä¢ Thedissimilarityfunctioncaptureswhattheusercaresabout. Securityisdefinedalso
with respect to a distribution dissimilarity function ùúÜ. The idea is that if Óà≥ideal is viewed as
Óà∞
safeorbenign,thensoisanydistributionÓà≥withùúÜ(Óà≥,Óà≥ideal)negligible;theuserdoesnotcare
Óà∞
whethertheygetpredictionsfromÓà≥ideal itselforfromanyùúÜ-closedistributionofMLmodels.
Óà∞
Clearly,thisassumptionistruewhenùúÜisthetotalvariationdistance(asinTheorem6.3),but
morerelaxed choicesof ùúÜ (asinour localmitigation results) canalsobeentirelysatisfactory
inmanyapplications(seediscussioninSection4.3). Importantly,ùúÜischosenbythedefender,
basedonwhateveraspectsofthepredictedlabelstheycareabout.
Itfollowslogicallythatif(i) auserwouldtrustpredictionscomingfromÓà≥ideal,and(ii) thefunction
Óà∞
ùúÜ captureswhattheusercaresabout(i.e., ifùúÜ(Óàº,ÓàΩ)isnegligibleandÓàº istrusted,thensoisÓàΩ),
thentheusershouldtrustpredictionscomingfromasystemsatisfyingourdefinitionofsecure
backdoormitigation.13
2.1.2 Efficiency,andLocalvs.GlobalMitigation
Trivially,adefenderwithaccesstorandomsamplesfromthepopulationdistributionÓà∞canalways
disregard the potentially-backdoored model ùëìÃÉ, and simplytrain anewML modelfrom scratch.
Therefore,itiscrucialthattheprocedureforsecurebackdoormitigationbesignificantlymore
efficient than training a new model. This motivates a distinction between two types of secure
backdoor mitigation: local and global. A global backdoor mitigator outputs a clean ML model
from the canonical distribution, as above. In contrast, a local mitigator does not compute the
entirecleanMLmodel. Rather,ittakesaspecificùë•‚àó asinput,andoutputsjustthelabelùë¶‚àó thatthe
cleanmodelwouldoutputforùë•‚àó. Localmitigationcanbesignificantlymoreefficientthanglobal
mitigation. ThesyntaxoflocalandglobalmitigatorsisspelledoutinDefinition4.1.
2.1.3 OntheAssumptionsinSecureBackdoorMitigation
Our notion of ùúÄ ‚Üí ùúÄ secure backdoor mitigation (Definition 4.3) provides two assurances: an
0 1
accuracy guarantee (theoutput will have loss at most ùúÄ ), and a security guarantee (theoutput
1
willbe‚Äúessentiallythesame‚Äùasacanonicaloutput). Fortheseassurancestohold,themitigator
requirestwopreconditions: oneconcerningthepotentially-backdooredmodelùëìÃÉ,andtheother
13Thisargumentissimilartotheargumentthatjustifiesothersecuritymechanisms,suchasdifferentialprivacy
(DP).ProponentsofDParguethatausershouldnotworryaboutsharingtheirpersonaldatawithaDPmechanism,
becausetheoutputofthemechanismwillbe‚Äúessentiallythesame‚Äùregardlessofwhethertheysharetheirpersonal
dataornot.InDP,thenotionofbeingessentiallythesameiscapturedbytheDPdissimilarityfunctionùúÜ(Óàº,ÓàΩ)=
sup ln(Óàº(ùê¥)/ÓàΩ(ùê¥)).TheDPdissimilarityfunctionprovidessecuritythatisweakerthantheTV-basedsecuritywe
ùê¥
obtaininTheorem6.3,butstrongerthantheCutoffDist-basedsecurity(Definitions4.6and4.7)thatweobtaininour
localmitigationconstructions.Ingeneral,bothDPandbackdoormitigationsecuritycanbeinstantiatedwithany
dissimilarityfunctionùúÜ,whilethebasicargumentthattheseconstructionsoffersecurityisthesameforanychoiceof
ùúÜ.ForfurtherdiscussiononthechoiceofùúÜinthecontextofDP,seeMoranetal.(2023).
8concerningthepopulationdistributionÓà∞. However,onlyoneofthesepreconditionsisasecurity
assumption,aswenowexplain:
Precondition1: ùëìÃÉ hasgoodaccuracy,i.e.,ùêø0 Óà∞-1 (ùëìÃÉ ) ‚â§ ùúÄ 0. Thispreconditionisnatural,seeing
asotherwiseùëìÃÉwouldnotbeuseful,andbackdoormitigationwillnotbemoreefficientthan
trainingfromscratchusingrandomsamples. However,westressthatwhilethisprecondition
is required, it is not an assumption. Namely, the defender can always take ùëÇ(1/ùúÄ2
)
i.i.d.
0
random samples from Óà∞ and directly estimate the quantity ùêø0 Óà∞-1 (ùëìÃÉ
)
to determine whether
this preconditionholds or not. Thatis, validating thisprecondition is justa cheapand easy
steptobecarriedout beforeinvokingasecurebackdoormitigator,andthereisnoneedto
assume thatthisconditionholds.
Precondition 2: Óà∞ belongs to some family ùîª of ‚Äúnice‚Äù population distributions. We do not
knowageneraldefinitionof‚Äúnice‚Äùthatwouldbenecessaryandsufficientforsecurebackdoor
mitigation. Instead, we explicitly define specific families ùîª (distributions close to linear
functions,polynomialfunctions,andùúè-heavyfunctions),andengineermitigatorsthatare
secureforthesespecificfamilies. Forsome familiesùîª,itmightbepossiblefor thedefender
todirectly andcheaplytestwhether the(unknown)populationdistributionÓà∞isa member
ofùîªusingafewrandomsamplesfromÓà∞.14 Alternatively,insomecasesitmightbepossible
toprovethatforany(arbitrary)populationdistributionÓà∞,iftheoutputùëî ofacertainsecure
globalmitigatorhashighaccuracyonÓà∞,thenthatimpliesthatÓà∞wasindeedniceenough.15
Again, this would provide a way for the defender to directly validate the ‚Äúniceness‚Äù of Óà∞.
However,in general,weviewthe preconditionÓà∞ ‚àà ùîªasa securityassumption. Namely, we
assume a threat model where theattacker can controlthe proposed (potentially-backdoored)
MLmodelùëìÃÉ,buttheattackercannotcontrolÓà∞(whichischosenbynature). Moreover,asis
oftenthe caseinmachine learning,we assumethat thereissome generalpriorknowledge
about the distribution Óà∞, captured by the statement Óà∞ ‚àà ùîª. If this assumption is violated,
thenmitigationisnotguaranteedtobesecure.
Thus,thesolesecurityassumptionrequiredforsecurebackdoormitigationisanassumptionon
thepopulationdistribution. NosecurityassumptionsonùëìÃÉarenecessary.
2.2 Constructions of Secure Backdoor Mitigators
2.2.1 GlobalMitigationforFourier-HeavyFunctions
Ourfirstconstructionisamitigatorforùúè-heavyfunctions(Definition6.2). Specifically,aglobalmit-
igatorthatisùëÇ(ùúè2 ) ‚Üí ùëÇ(ùúè2 )TV-secure(Definition4.5)undertheassumptionthatthepopulation
distributionhaslabelsthatareùëÇ(ùúè2 )closetoaùúè-heavyFourierfunction.
Theorem(InformalversionofTheorem6.3). LetÓâÑ = {¬±1}ùëõ,ÓâÖ = [‚àí1,1],andùúè ‚â• 0. Thereexistsan
efficientglobalmitigatorùëÄ thatusesoracleaccesstoapotentially-backdooredfunctionùëìÃÉ ‚à∂ ÓâÑ ‚Üí ÓâÖ
and random samples from a population distribution Óà∞ ‚àà Œî(ÓâÑ √óÓâÖ) with uniform marginal on ÓâÑ,
14Forinstance,forthefamilyofdistributionsthatareclosetoalinearfunction,KongandValiant(2018)providea
waytodosoundercertainassumptions.
15ComparealsotoRubinfeldandVasilyan(2023).
9as follows. If Óà∞ is ùëÇ(ùúè2 )-close in ùêø2 to a ùúè-heavy function and ùêø2 Óà∞(ùëìÃÉ ) ‚â§ ùëÇ(ùúè2 ), then ùëÄ outputs a
TV-securefunctionùëî ‚à∂ ÓâÑ ‚Üí ‚Ñùwithlossùêø2 Óà∞(ùëî) ‚â§ ùëÇ(ùúè2 ).
AswediscussinExample2.1below,theclassofùúè-heavyfunctionscontainstheclassofbounded-
degreeBooleanfunctions,whichincludessomeinterestingclassifierssuchasbounded-sizejuntas
and bounded-depth decision trees. For functions of degree log(ùëõ), our global mitigator is more
efficientthanlearningacleanfunctionfromscratch.
ProofIdeaforTheorem6.3. Let‚Ñébeaùúè-heavyfunctionwithùêø2 Óà∞(‚Ñé) ‚â§ ùëÇ(ùúè2 ). BecauseùëìÃÉisùëÇ(ùúè2 )-
closeto‚Ñé,ùëìÃÉmusthaveweightatleastùúè/2ateverynon-zerocoefficientof‚Ñé. Hence,executingthe
Goldreich‚ÄìLevinalgorithmonùëìÃÉwillrecoverthelistofnon-zerocoefficientsof‚Ñé‚Äîregardlessof
thespecific(possiblyadversarial)choiceofùëìÃÉ! Estimatingthecoefficientsinthislistusingrandom
samplesgivesafunctionùëî thatisindependentofùëìÃÉ.
Corollary6.5providesaversionofTheorem6.3forbinarylabelsandthe0-1loss.
2.2.2 BasicLocalMitigationforLinearFunctions
Ournextconstructionisalocalmitigatorforpopulationdistributionswithlabelsthatarecloseto
alinearfunctionin‚Ñùùëõ. WhilelearninganewlinearregressorfromscratchwouldrequireŒ©(ùëõ)
samples,ourmitigatoruses0samples,andanumberofqueriestoùëìÃÉthatisindependent ofùëõ. The
securityiswithrespecttothecutoffloss (seeDefinition3.7andSection4.3).
Theorem(InformalversionofTheorem7.1). LetÓâÑ ‚äÜ ‚Ñùùëõ beaboundedandconvexset. Algorithm2
definesalocalmitigatorùëÄ thatis(ùúÄ, ùõø/20ùëõ ‚Üí ùõø)-cutofflosssecure(Definition4.6)fordistributions
Óà∞withuniformmarginalonÓâÑ suchthatùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ forsomeaffinefunction‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñù.
Óà∞
More explicitly, for every distribution Óà∞ there exists a function ùëîideal such that for any arbitrary
Óà∞
(possiblymalicious)functionùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùwithlossùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ,themitigatorùëÄ satisfies:
Óà∞
1. Accuracy. ‚Ñô (ùë•,ùë¶)‚àºÓà∞,ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†)[|ùë¶‚àó ‚àíùë¶| > ùõø] ‚â§ ùúÄ +negl(ùë†),and
2. CutoffLossSecurity. ‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ‚Ñô ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•‚àó,1ùëõ,1ùë†)[| |ùë¶‚àó ‚àíùëî Óà∞ideal(ùë•‚àó)|
|
> ùõø] ‚â§ negl(ùë†).
Furthermore, Algorithm 2 uses a total of ùëÇ(ùë†) oracle queries to ùëì, does not use random samples
from Óà∞, and runs in time ùëÇ(ùë†ùëõ), assuming unit runtime cost for each arithmetic operation on the
representationsofrealnumbersinvolvedinthecomputation.
ItisnaturaltoattempttouseaBLR-stylestrategy(Blum,Luby,andRubinfeld,1990)forthistask,
similartoExample1.2. Thatis,computingùëìÃÉ (ùë¢)+ùëìÃÉ (ùë•‚àó ‚àíùë¢)forùë¢ ‚àº U(ÓâÑ). However,thisstrategy
fails. Thereasonisthatthedistributionofùë•‚àó ‚àíùë¢dependsonthe(adversariallychosen)ùë•‚àó,sowe
havenoguaranteethatùëìÃÉ (ùë•‚àó‚àíùë¢)willbea‚Äúgood‚Äùvaluewithhighprobability(unlikeforùëìÃÉ (ùë¢)). In
fact,asdepictedinFigure2a,ùë•‚àó ‚àíùë¢mightevenbeoutsidethedomainÓâÑ.
Correlatedsampling. Instead,weuseastrategybasedonacorrelatedsamplinglemma(Lemma7.2)
tosampletwopoints ùë• andùë•‚Ä≤,eachofwhichhasuniform marginalonÓâÑ,buttheirjointdistri-
bution is such that they are on a straight line with ùë•‚àó (see Figure 2b). That is, suppose we first
drawapointùë• ‚àº U(ÓâÑ). Wewouldliketodrawanotherpointùë•‚Ä≤ thatsatisfiesthefollowingtwo
conditions:
101. ùë•‚Ä≤ ‚àà ùìÅ, where ùìÅ is the line segment that starts at ùë•‚àó, ends at the boundary of ÓâÑ, and passes
throughùë•;
2. Themarginaldistributionofùë•‚Ä≤ isalsouniformonÓâÑ.
Na√Øvely, one might imagine that we should sample ùë•‚Ä≤ uniformly from the line ùìÅ. However,
duetointricaciesrelatedtotheBorel‚ÄìKolmogorovparadox(aboutconditioningonaneventof
measure0indifferentways),takingùë•‚Ä≤ ‚àº U(ùìÅ)wouldnotwork. Toseethis,considerthecasewhere
ÓâÑ = ùêµ(ùüé,1)istheunitballin‚Ñùùëõ andùë•‚àó = ùüéistheorigin. Then,ùìÅisaradiusoftheunitball. Thus,
takingùë•‚Ä≤ ‚àº U(ùìÅ)wouldyieldadistributionwhere‚Ñô[‚Äñùë•‚Ä≤‚Äñ ‚â§ 1/ 2] = 1/ 2. Thisisverydifferentfrom
the uniform distribution on ùêµ(ùüé,1), where ‚Ñô ùë•‚àºU(ùêµ(ùüé,1))[‚Äñùë•‚Äñ ‚â§ 1/ 2] ‚â§ ùëí‚àíŒ©(ùëõ). Therefore, sampling ùë•‚Ä≤
x
x u ‚àó
‚àó
‚àí
x
‚àó
O
x
u ‚Ñì ‚Ä≤ x
(a)WhytraditionalBLR-stylelinearrandomself-reducibility (b) Instead of the BLR approach, we use
(asinExample1.2)doesnotworkforapopulationdistribution Lemma7.2tosamplecorrelatedpointsùë•and
withauniformmarginalonaconvexsetÓâÑ (thegrayoval)in ùë•‚Ä≤situatedonastraightlineùìÅwithùë•‚àó,such
‚Ñùùëõ.Here,ùë•‚àóistheadversarially-choseninputpointforwhich thateachpointhasauniformmarginalonÓâÑ.
alabelisdesired.WehaveguaranteesonthevalueùëìÃÉ(ùë¢)but Thankstotheuniformmarginals,bothùëìÃÉ(ùë•)
notonùëìÃÉ(ùë•‚àó‚àíùë¢),andùë•‚àó‚àíùë¢mightevenbeoutsideofÓâÑ. andùëìÃÉ(ùë•‚Ä≤)willbe‚Äúgood‚Äùw.h.p.
y
(x,Àúf(x))
(x ,Àúf(x ))
‚Ä≤ ‚Ä≤
y
‚àó
x x x ‚Ñì
‚àó ‚Ä≤ ‚Ä≤
(c) Looking at the line ùìÅ in Figure 2b, local mitigation reduces to a
problemof1-dimensionallinearregression. Seeingasùë• andùë•‚Ä≤ tend
tobefarfromùë•‚àó,thesmallererrorbarsinred(ofsizeŒò(ùõø/ùëõ))around
thevaluesofùëìÃÉ(ùë•)andùëìÃÉ(ùë•‚Ä≤)inducealargererrorbar(ofsizeŒò(ùõø))for
thepredictedlabelùë¶‚àó.
Figure2: ConstructionofthelocalmitigatorofTheorem7.1.
11uniformlyfromùìÅwillnotgiveanùë•‚Ä≤ withmarginaldistributionthatisuniformonÓâÑ.
WheredidtheintuitionthatthedistributiononùìÅshouldbeuniformgowrong? Inshort,itisdue
tothecurseofdimensionality. Forapointùë•‚Ä≤ chosenfromùìÅsothatitsmarginalisùëà(ùêµ(ùüé,1)),letùúå
ùìÅ
bethedistributionon‚Äñùë•‚Ä≤‚Äñ ,i.e.,thedistancefromùë•‚Ä≤ totheorigin. Wecandirectlycomputethe
2
CDFofùúå . Forarbitraryùëü ‚àà [0,1],
ùìÅ
vol(ùêµ(ùüé,ùëü))
‚Ñô ùëü‚Ä≤‚àºùúåùìÅ[ùëü‚Ä≤ ‚â§ ùëü] = ‚Ñô ùë•‚Ä≤‚àºùëà(ùêµ(ùüé,1))[‚Äñ ‚Äñùë•‚Ä≤‚Äñ
‚Äñ
2
‚â§ ùëü] =
vol(ùêµ(ùüé,1))
= ùëüùëõ,
wherethelastequalityholdsbyadirectvolumescalingargument. Takingthederivativeofthis
CDF reveals the PDF ùúå (ùëü) = ùëõùëüùëõ‚àí1. Crucially, this is not the uniform distribution on ùìÅ, and in
ùìÅ
particular,ismuchmoreconcentratedaround1than0. (Formally,ùúå istheBeta(ùëõ,1)distribution.)
ùìÅ
Lemma7.2givesthecorrectsamplingstrategyinmoredetail,formoregeneralchoicesofÓâÑ and
ùë•‚àó.
ProofideaforTheorem7.1. UseLemma7.2tosampleùë• andùë•‚Ä≤ withuniformmarginals,forminga
linewithùë•‚àó. Then,estimatingthelabelofùë•‚àó reducestolinearregressionin1dimension,where
theerrorincreasesbyafactorofŒò(ùëõ),asinFigure2c. Tomaketheresultrobusttoadversarial
outliersinùëìÃÉ,repeatthisprocessanumberoftimesandtakethemedian.
2.2.3 ImprovedLocalMitigationforLinearFunctions
LookingatthebasiclinearmitigatorofTheorem7.1(andatFigure2c),therearetwoaspectsthat
callforimprovement.
‚Ä¢ The basic mitigator amplifies errors by a factor of Œò(ùëõ). Namely, given a potentially-
backdoored ùëìÃÉwith accuracy ùëÇ(ùõø/ùëõ) on most points, the mitigator produces a ‚Äúclean‚Äù pre-
diction with accuracy ùõø on the adversarially chosen point ùë•‚àó. Could the error growth be
reduced?
‚Ä¢ Thebasicmitigatorguarantees(withprobability1‚àínegl(ùë†))thatthelabelùë¶‚àó predictedforùë•‚àó
fallswithintheintervalùëîideal ¬±ùõø (representedbythebigrederrorbarinFigure2c). Thisisa
Óà∞
fairlystrongsecurityguarantee,butcoulditbeimproved? Specifically,itisnothardtosee
that,within thiserrorbar,theattackercanactuallyfullycontrolwhereùë¶‚àó falls. Couldwedo
better?
Ournexttheoremaddressesbothoftheseconcerns.
Theorem (Informal version of Theorem 7.7). In the setting of Theorem 7.1, assume that the
populationdistributionhasbenignnoise. Namely,assumethelabelsofÓà∞aregeneratedbyùë¶ = ‚Ñé(ùë•)+ùúÇ
where‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùisanaffinefunction,andùúÇisindependentsubgaussiannoise,asinDefinition7.6.
ThenthereexistsalocalmitigatorasinTheorem7.1,withthefollowingimprovements:
ùõø ùõø
‚Ä¢ Theerrorgrowsbyafactorthatisùëú(ùëõ),specifically,from to ;and
ùëõ ùëõ1/10
12‚Ä¢ Thepredictionsforeveryùë•‚àóareunbiased. Namely,foreveryùë•‚àó ‚àà ÓâÑ ‚à∂ ùîº[ùë¶‚àó] = ùëîideal(ùë•‚àó) = ‚Ñé(ùë•‚àó).
Óà∞
Sonoattackercancauseasystematicbiaswheretheexpectedpredictionforaselectùë•‚àó isabove
orbelowùëîideal(ùë•‚àó).16
Óà∞
ProofideaforTheorem7.7. First, we carefully analyze the errors that an attacker can introduce
intothebasiclinearestimator,andconcludethattheonlywaythatanattackercancontrolùë¶‚àó is
byintroducingsystematicerrorsinùëìÃÉresultinginalinearcorrelationbetweenthedistanceofa
pointùë• fromùë•‚àó andthelabelùëìÃÉ (ùë•). Thisleadstoaconstantadditivebiasinthepredictionsofthe
basic mitigator (as captured in Eq. (24)). By taking random samples (ùë•,ùë¶) from the population
distribution Óà∞ and comparing ùë¶ to ùëìÃÉ (ùë•), we can estimate the constant additive bias that the
attacker inserted. Subtracting this additive bias from our predictions yields a distribution of
predictions that may have considerable variance, but is symmetric about ùëîideal(ùë•‚àó). Finally, we
Óà∞
invokeourrobustmeanestimationtheorem(Theorem8.1)toobtainanunbiasedestimatorwith
smallvariance.
TheproofofTheorem7.7reliesonourresultconcerningthemean-of-mediansestimator(Theo-
rem 8.1). For arbitrary distributions, that estimator does not necessarily concentrate about the
mean.17 However,itdoeshavegoodconcentrationifthedistributionissymmetric(asitisinour
case). Furthermore,weshowthatitisrobusttoarbitraryadversarialnoise.
2.2.4 LocalMitigationforPolynomialFunctions
Ournextconstructionisalocalmitigatorforpopulationdistributionswithlabelsthatarecloseto
a polynomialfunction in‚Ñùùëõ of totaldegree atmost ùëë. Whilelearning a new polynomial regressor
from scratchwould requireùëõŒ©(ùëë) samples, ourmitigator uses0samples, anda number ofqueries
toùëìÃÉthatisindependent ofùëõanddependsonlylinearlyonùëë.
Theorem (Informal version of Theorem 7.12). Let ÓâÑ ‚äÜ ‚Ñùùëõ be a bounded and convex set, and let
ùõø
0
= ùõø 1/ùëÇ(ùëõùëë2)ùëë,forsomeparameterùõø
1
‚â• 0. ForùúÄ < 1/ 20ùëë,Algorithm5definesalocalmitigatorùëÄ
thatis(ùúÄ,ùõø ‚Üí ùõø )-cutofflosssecure(Definition4.6)fordistributionsÓà∞withuniformmarginalonÓâÑ
0 1
suchthatùêø>ùõø0(‚Ñé) ‚â§ ùúÄ forsomepolynomial‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùoftotaldegreeatmostùëë.
Óà∞
Moreexplicitly,foreverysuchdistributionÓà∞,thereexistsafunctionùëîideal suchthatforanyarbitrary
Óà∞
(possiblymalicious)functionùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùwithlossùêø>ùõø0(‚Ñé) ‚â§ ùúÄ,themitigatorùëÄ satisfies:
Óà∞
1. Accuracy. ‚Ñô [|ùë¶‚àó ‚àíùë¶| > ùõø ] ‚â§ ùúÄ +negl(ùë†),and
(ùë•,ùë¶)‚àºÓà∞,ùë¶‚àó‚ÜêùëÄùëì(ùë•,1ùëõ,1ùë†) 1
2. CutoffLossSecurity. ‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ‚Ñô ùë¶‚àó‚ÜêùëÄùëì(ùë•‚àó,1ùëõ,1ùë†)[| |ùë¶‚àó ‚àíùëî Óà∞ideal(ùë•‚àó)| | > ùõø 1] ‚â§ negl(ùë†).
Furthermore,Algorithm2usesatotalofùëÇ(ùëëùë†)oraclequeriestoùëì,doesnotuserandomsamplesfrom
Óà∞, and runs in time ùë† ‚ãÖpoly(ùëõ,ùëë), assuming unit runtime cost for each arithmetic operation on the
representationsofrealnumbersinvolvedinthecomputation.
Justlikeforbasiclocalmitigationforlinearfunctions,thekeyideaiscorrelatedsampling (Algo-
rithm3). Wesampleùëë +1pointsùë• ,‚Ä¶,ùë• ,eachofwhichhasuniformmarginalonÓâÑ,buttheir
0 ùëë
16However,anattackercouldforexamplecontrolthevarianceofùë¶‚àó,withintheconstraintsoftheerrorbarofsize
ùõø/ùëõ1/10.
17Simplybecause,foraskeweddistribution,themedianineachbatchwillnotconcentrateaboutthemean.
13joint distribution is such that they all lie on a line going through ùë•‚àó. See Figure 4. Since these
points are all collinear, we then run a basic univariate polynomial interpolation algorithm by
solvingthe(ùëë +1)-dimensionallinearsystem(i.e.,byinvertingthecorrespondingVandermonde
matrix).
ProofideaforTheorem7.12. UseLemma 7.2tosample ùë• ,‚Ä¶,ùë• withuniform marginals,forming
0 ùëë
alinewithùë•‚àó. Then,estimatingthelabelofùë•‚àó reducestosolvingalinearsystemin1dimension,
where the error increases by a factor of ùëÇ(ùëõùëë2)ùëë, by looking at the norm of the inverse of the
correspondingVandermondematrix(seeTheorem7.10andClaim7.11). Tomaketheresultrobust
toadversarialoutliersinùëìÃÉ,repeatthisprocessanumberoftimesandtakethemedian.
Thisresultisapolynomialanalogofourbasiclinearmitigationresult(Theorem7.1).
2.3 Example
Example 2.1 (Mitigation for functions of logarithmic degree). Let Óà¥ be the class of Boolean
ùëë
functions of degreeùëë. Óà¥ contains many interestingfunctions, including ùëë-juntas, and decision
ùëë
trees of depth ùëë (Proposition 3.16 in O‚ÄôDonnell 2014). For ùëë = log(ùëõ), Theorem 6.3 implies that
mitigationischeaperthanlearning.
{ }
Moreformally,letùëõ,ùëë ‚àà ‚Ñï,letÓâÑ = {¬±1}ùëõ,letÓà¥ = ‚Ñé ‚àà {¬±1}ÓâÑ ‚à∂ deg(‚Ñé) ‚â§ ùëë ,wheredeg(‚Ñé) =
{ } ùëë
max |ùëÜ| ‚à∂ ùëÜ ‚äÜ [ùëõ]‚àßÃÇ ‚Ñé(ùëÜ) ‚â† 0 . Foreach‚Ñé ‚àà Óà¥ ,letÓà∞ = U({(ùë•,‚Ñé(ùë•))} ),andletùîª = {Óà∞ } .
ùëë ‚Ñé ùë•‚ààÓâÑ ùëë ‚Ñé ‚Ñé‚ààÓà¥ ùëë
ItisknownthatÓà¥ canbeagnosticallylearnedinquasi-polynomialtimeusingthe‚Äúlowdegree‚Äù
log(ùëõ)
algorithm(Linialet al.,1993). Namely, thereexistsanalgorithmsuch thatforeverydistribution
Óà∞ ‚àà ùîª
log(ùëõ)
andeveryùúÄ > 0,thealgorithmrunsintimepoly(ùëõlog(ùëõ),1/ùúÄ),usesonlyi.i.d.samples
fromÓà∞,andoutputsafunctionùëî withùêø0-1(ùëî) ‚â§ ùúÄ. Itisconjecturedthatnopoly(ùëõ)-timealgorithm
Óà∞
exists for learning log(ùëõ)-juntas from i.i.d. samples (Section 2.3 in Blum et al., 1993. See also
AssumptionA.3inGolowichandMoitra,2024).
Incontrast,mitigationischeaper. Specifically,every‚Ñé ‚àà Óà¥
log(ùëõ)
is 2/ ùëõ-heavy(SeeExercise1.11(b)
inO‚ÄôDonnell2014). Therefore,byCorollary6.5,forùúÄ = ùëÇ(1/ùëõ2 )thereexistsaTVsecureglobal
mitigatorùëÄ thatforanyÓà∞ ‚àà ùîª log(ùëõ) andanyfunctionùëìÃÉwithùêø0 Óà∞-1 (ùëìÃÉ ) ‚â§ ùúÄ,ùëÄùëìÃÉ,Óà∞(1ùëõ,1ùë†)runsintime
poly(ùëõ,ùë†)andoutputsafunctionùëî withlossùêø0-1(ùëî) ‚â§ ùëÇ(ùúÄ).
Óà∞
3 Preliminaries
Notation3.1. ‚Ñï = {1,2,3,‚Ä¶},i.e.,0 ‚àâ ‚Ñï. Foranyùëõ ‚àà ‚Ñï,wedenote[ùëõ] = {1,2,3,‚Ä¶,ùëõ}.
Notation3.2. ln(‚ãÖ)denotesthenaturallogarithm,andlog(‚ãÖ)denotesthelogarithmtobase2.
Notation3.3. Forapredicateùúë,weusethenotation1(ùúë) ‚àà {0,1}todenotetheindicatorvariableof
whetherùúë istrue(1)orfalse(0).
Notation3.4. Weusethefunctionsign ‚à∂ ‚Ñù ‚Üí {‚àí1,1}todenotethemappingùë• ‚Ü¶ 2‚ãÖ1(ùë• ‚â• 0)‚àí1.
More generally, for a set ÓâÑ and a function ùëì ‚à∂ ÓâÑ ‚Üí ‚Ñù, we define sign(ùëì) ‚à∂ ÓâÑ ‚Üí {‚àí1,1} by the
mappingùë• ‚Ü¶ sign(ùëì(ùë•)).
14Notation3.5. ForasetŒ©,wewriteŒî(Œ©)todenotethesetofallprobabilitymeasuresdefinedonthe
measurablespace(Œ©,Óà≤),whereÓà≤ issomefixedùúé-algebrathatisimplicitlyunderstood.
Definition3.6. LetÓàº,ÓàΩbeprobability measures defined ona measurablespace(Œ©,Óà≤). Thetotal
variationdistancebetweenÓàº andÓàΩisTV(Óàº,ÓàΩ) = sup |Óàº(ùê¥)‚àíÓàΩ(ùê¥)|.
ùê¥‚ààÓà≤
Definition 3.7. Let ÓâÑ and ÓâÖ be sets. A loss function is a function ùêø ‚à∂ ÓâÖ √ó ÓâÖ ‚Üí ‚Ñù . For any
‚â•0
distributionÓà∞ ‚àà Œî(ÓâÑ √óÓâÖ)and(possiblyrandomized)functionùëì ‚à∂ ÓâÑ ‚Üí Œî(ÓâÖ),thepopulationloss
ofùëì withrespecttoÓà∞is
ùêø Óà∞(ùëì) = ùîº (ùë•,ùë¶)‚àºÓà∞[ùêø(ùëì(ùë•),ùë¶)],
wheretheexpectationisoverthesample(ùë•,ùë¶)andtherandomnessofùëì.
Inparticular,fordiscreteÓâÖ,
‚Ä¢ The0-1lossisùêø0-1(ùë¶,ùë¶‚Ä≤) = 1(ùë¶ ‚â† ùë¶‚Ä≤),suchthatùêø0 Óà∞-1(ùëì) = ‚Ñô (ùë•,ùë¶)‚àºÓà∞[ùëì(ùë•) ‚â† ùë¶],
andforÓâÖ = ‚Ñù,
‚Ä¢ Thesquarelossisùêø2(ùë¶,ùë¶‚Ä≤) = (ùë¶ ‚àíùë¶‚Ä≤)2,suchthatùêø2 Óà∞(ùëì) = ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëì(ùë•)‚àíùë¶)2 ],and
| |
‚Ä¢ Theùõø-cutoffloss18 isùêø>ùõø(ùë¶,ùë¶‚Ä≤) = 1(|ùë¶ ‚àíùë¶‚Ä≤| > ùõø),suchthatùêø> Óà∞ùõø(ùëì) = ‚Ñô (ùë•,ùë¶)‚àºÓà∞[| |ùëì(ùë•)‚àíùë¶|
|
> ùõø ],
whereùõø ‚â• 0issomefixedthreshold.
Notation3.8. ForacollectionoffunctionsÓà≤ ‚äÜ ÓâÖÓâÑ andalossfunctionùêø ‚à∂ ÓâÖ √óÓâÖ ‚Üí ‚Ñù ,weuse
‚â•0
thenotationùêø Óà∞(Óà≤) = inf
ùëì‚ààÓà≤
ùêø Óà∞(ùëì).
4 Definitions of Secure Backdoor Mitigation
In this paper, we show that in some cases it is possible to mitigate the threat of undetectable
backdoorsinmachinelearningmodels. Specifically,weprovidemitigationstrategiesthatachieve
averystrongnotionofbackdoormitigation,asinthefollowingdefinitions.
Definition 4.1 (Mitigator). Let {ÓâÑ } be a sequence of sets, and let ÓâÖ be a set. A mitigator is a
ùëõ ùëõ‚àà‚Ñï
PPTalgorithmùëÄ withoneofthefollowingsignatures:
Globalmitigator: ùëî ‚Üê ùëÄùëì,Óà∞ (1ùëõ,1ùë†)
Localmitigator: ùë¶‚àó ‚Üê ùëÄùëì,Óà∞ (ùë•‚àó,1ùëõ,1ùë†).
In both cases, ùëÄ has oracle access to a function ùëì ‚à∂ ÓâÑ ‚Üí ÓâÖ, i.i.d. sample access to a distribution
ùëõ
Óà∞ ‚àà Œî(ÓâÑ √óÓâÖ),andtakesanindexùëõandasecurityparameterùë† ‚àà ‚Ñïasinputs.
ùëõ
A global mitigator outputs a (possibly randomized) function ùëî ‚à∂ ÓâÑ ‚Üí Œî(ÓâÖ). A local mitigator
ùëõ
receivesanadditionalinputùë•‚àó ‚àà ÓâÑ ,andoutputsalabelùë¶‚àó ‚àà ÓâÖ.
ùëõ
ForaglobalmitigatorùëÄ,thenotationùëÄùëì,Óà∞(ùë•‚àó,1ùëõ,1ùë†)isshorthandforùëî(ùë•‚àó)whereùëî = ùëÄùëì,Óà∞(1ùëõ,1ùë†).
Throughoutthepaper,weoccasionallyneglectthesubscriptùëõ,writingÓâÑ insteadofÓâÑ whenùëõis
ùëõ
clearfromcontext.
18Thisfollowsexistingterminology.Forexample,Attiasetal.(2024)callthislossthe‚Äúcut-offlossatscaleùõø‚Äù.
154.1 General Definition of Mitigation Security
Definition4.2(DistributionDissimilarity). LetŒ©beaset. Adistributiondissimilarityfunctionfor
Œ©isafunctionùúÜ ‚à∂ Œî(Œ©)√óŒî(Œ©) ‚Üí ‚Ñù . Namely,itisafunctionthattakesapairofdistributions
‚â•0
overŒ©andoutputsanon-negativenumber.
Notethatadistributiondissimilarityfunctionmaynotbeametric.
We introduce the following definition of security for mitigators. It can be applied both to local
andglobalmitigators.
Definition4.3(GeneralùúÄ ‚Üí ùúÄ SecureBackdoorMitigation). LetÓâÑ andÓâÖ besets. Foreveryindex
0 1
ùëõ ‚àà ‚Ñï,letÓâÑ ‚äÜ ÓâÑ beasetandletùîª ‚äÜ Œî(ÓâÑ √óÓâÖ)beacollectionofdistributions. Letùîª = {ùîª } .
ùëõ ùëõ ùëõ ùëõ ùëõ‚àà‚Ñï
Let ùêø(0),ùêø(1) ‚à∂ ÓâÖ √óÓâÖ ‚Üí ‚Ñù be loss functions, let ùúÜ be a distribution dissimilarity function for the
‚â•0
set of randomized functions ÓâÑ ‚Üí Œî(ÓâÖ), and let ùúÄ ,ùúÄ ‚â• 0. A local or global mitigator ùëÄ is an
0 1
(ùêø(0),ùúÄ ) ‚Üí (ùêø(1),ùúÄ )mitigatorfordistanceùúÜ andpopulationdistributionsùîªif:
0 1
‚àÉanegligiblefunctionùúá ‚àà negl
‚àÄindexùëõ ‚àà ‚Ñï‚àÄpopulationdistributionÓà∞ ‚àà ùîª
ùëõ
‚àÉoutputdistributionÓà≥i Óà∞deal ‚àà Œî(ÓâÖÓâÑ ùëõ)
‚àÄsecurityparameterùë† ‚àà ‚Ñï
‚àÄfunctionùëì ‚àà ÓâÖÓâÑ ùëõ withlossùêø(0)(ùëì) ‚â§ ùúÄ
Óà∞ 0
Thefollowingtwoconditionshold ‚à∂
1. Security. ùúÜ(Óà≥,Óà≥i Óà∞deal ) ‚â§ ùúá(ùë†),and
2. Accuracy. ‚Ñô ùëî‚àºÓà≥[ùêø( Óà∞1)(ùëî) ‚â• ùúÄ 1] ‚â§ ùúá(ùë†),
where Óà≥ is the output distribution of the mitigator. Specifically, if ùëÄ is a global
mitigatorthenÓà≥isthedistributionofùëÄùëì,Óà∞(1ùëõ,1ùë†);ifùëÄ isalocalmitigatorthenÓà≥
isthedistributionofùëî(ùë•) = ùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†).
Remark 4.4. In Definition 4.3, Óà≥ represents the output of the mitigator. This is true for both
localandglobalmitigators. Localandglobalmitigatorsdifferintheiruseofrandomness: aglobal
mitigatorusesitsrandomcoinsandrandomsamplestoselectonedeterministicfunctionÓâÑ ‚Üí ÓâÖ,
whichmapseachùë• ‚àà ÓâÑ tosomelabelinÓâÖ. Incontrast,alocalmitigatorusesitsrandomcoinsand
randomsamplestomapjustasingleinputùë• toasinglelabelùë¶. Atechnicalitythatresultsfrom
this difference is that for a global mitigator, Óà≥ (the distribution of ùëÄùëì,Óà∞(1ùëõ,1ùë†)) is a distribution
overdeterministicfunctionsÓâÑ ‚Üí ÓâÖ. Incontrast,foralocalmitigator,ùëî(ùë•) = ùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†)isa
singlefixedrandomizedmappingÓâÑ ‚Üí Œî(ÓâÖ).19,20
19Generally,inbothcasesÓà≥isadistributionoverrandomizedfunctions(i.e.,adistributionoverfunctions,and
eachfunctionmayitselfbearandomizedmapping;Óà≥‚ààŒî((Œî(ÓâÖ))ÓâÑ )).Inthecaseofglobalmitigatorstherandomized
functionsaredegenerate(Óà≥isadistributionoverdeterministicfunctions);inthecaseoflocalmitigatorsthedistribution
overfunctionsisdegenerate(Óà≥assignsaprobabilityof1toasinglefixedmappingÓâÑ ‚ÜíŒî(ÓâÖ)thatmapseachùë• ‚ààÓâÑ
toadistributionoverlabels).
20Ifwedesiredtohaveacloserformalmatchbetweenthe‚Äútype‚ÄùofÓà≥forlocalandglobalmitigation,wecould
164.2 Specific Instantiations of Mitigation Security
The quality of the security guaranteed by Definition 4.3 hinges crucially on the choice of the
distribution dissimilarity function ùúÜ. We now provide two instantiations of Definition 4.3 that
correspondtospecificchoicesofùúÜ.
Perhapsthemostnaturalchoiceofadissimilarityfunction,whichprovidesaverystrongguarantee
ofsecurity,istousethetotalvariationdistance,asinthefollowingdefinition.
Definition4.5(TVSecurityforGlobalMitigation). LetÓâÑ andÓâÖ besets. For everyindexùëõ ‚àà ‚Ñï,
let ÓâÑ ‚äÜ ÓâÑ be a set and let ùîª ‚äÜ Œî(ÓâÑ √óÓâÖ) be a collection of distributions. Let ùîª = {ùîª } .
ùëõ ùëõ ùëõ ùëõ ùëõ‚àà‚Ñï
Let ùêø(0),ùêø(1) ‚à∂ ÓâÖ √ó ÓâÖ ‚Üí ‚Ñù be loss functions, and let ùúÄ ,ùúÄ ‚â• 0. A global mitigator ùëÄ is
‚â•0 0 1
(ùêø(0),ùúÄ ) ‚Üí (ùêø(1),ùúÄ )totalvariationsecurefordistributionsùîªif:
0 1
‚àÉanegligiblefunctionùúá ‚àà negl
‚àÄindexùëõ ‚àà ‚Ñï‚àÄpopulationdistributionÓà∞ ‚àà ùîª
ùëõ
‚àÉoutputdistributionÓà≥i Óà∞deal ‚àà Œî(ÓâÖÓâÑ ùëõ)
‚àÄsecurityparameterùë† ‚àà ‚Ñï
‚àÄfunctionùëì ‚àà ÓâÖÓâÑ ùëõ withlossùêø(0)(ùëì) ‚â§ ùúÄ
Óà∞ 0
Thefollowingtwoconditionshold ‚à∂
1. Security. TV(Óà≥,Óà≥i Óà∞deal ) ‚â§ ùúá(ùë†),and
2. Accuracy. ‚Ñô ùëî‚àºÓà≥[ùêø( Óà∞1)(ùëî) ‚â§ ùúÄ 1] ‚â• 1‚àíùúá(ùë†),
whereÓà≥isthedistributionofthefunctionùëÄùëì,Óà∞(1ùëõ,1ùë†).
When thelabel spaceÓâÖ is ametric space, it makessense toconsider a morenuanced notion of
security. Here,theguaranteeisthatthemitigatoroutputsalabel ùë¶‚àó that,whilenotindistinguish-
able from the ‚Äúideal‚Äù label, is promised to be ‚Äúclose enough‚Äù to the ideal label according to the
metricon ÓâÖ. Following isa formalizationof thisnotion ofsecurity forlocal mitigatorswithlabel
spaceÓâÖ = ‚Ñù.
Definition 4.6 (Cutoff Loss Security). Let ÓâÑ be a set. For every index ùëõ ‚àà ‚Ñï, let ÓâÑ ‚äÜ ÓâÑ be a set
ùëõ
andletùîª ‚äÜ Œî(ÓâÑ √ó‚Ñù)beacollectionofdistributions. Letùîª = {ùîª } ,andletùúÄ,ùõø ,ùõø ‚â• 0. Alocal
ùëõ ùëõ ùëõ ùëõ‚àà‚Ñï 0 1
mitigatorùëÄ is(ùúÄ,ùõø ‚Üí ùõø )-cutofflosssecurefordistributionsùîªif:
0 1
‚àÉanegligiblefunctionùúá ‚àà negl
‚àÄindexùëõ ‚àà ‚Ñï‚àÄpopulationdistributionÓà∞ ‚àà ùîª
ùëõ
easilydefineÓà≥inbothcasesasadistributionoverdeterministicfunctions.Todothat,wewoulddefineÓà≥inthecase
oflocalmitigationasthedistributionofthefunctionùëî suchthatùëî(ùë•)=ùëÄùëì(ùë•,ùëç,ùëü,1ùëõ,1ùë†),whereùëç ‚àºÓà∞ùëò isani.i.d.
sample,ùëò ‚àà‚ÑïisthemaximumnumberofsamplesusedbyùëÄ,andùëü isthevectorofrandomcoinsusedbyùëÄ.Forany
fixed(ùëç,ùëü),ùëî isadeterministicfunction;Óà≥isthedistributionoverfunctionsùëî correspondingtoarandomchoiceof
(ùëç,ùëü).Thisformulationisnotmeaningfullydifferentfromtheformulationweuseinthispaper,andallresultswould
bethesame. WeoptfortheformulationasinRemark4.4simplybecausethenotationisslightlycleanerwithout
explicitparametersof(ùëç,ùëü).
17‚àÉafunctionùëîideal ‚à∂ ÓâÑ ‚Üí ‚Ñù
Óà∞ ùëõ
‚àÄsecurityparameterùë† ‚àà ‚Ñï
ÓâÑ
‚àÄfunctionùëì ‚àà ‚Ñù ùëõ with‚Ñô (ùë•,ùë¶)‚àºÓà∞[|ùëì(ùë•)‚àíùë¶| ‚â• ùõø 0] ‚â§ ùúÄ
Thefollowingtwoconditionshold:
1. Accuracy. ‚Ñô [|ùë¶‚àó ‚àíùë¶| ‚â• ùõø ] ‚â§ ùúÄ +ùúá(ùë†).
1
(ùë•,ùë¶)‚àºÓà∞
ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†)
2. CutoffLossSecurity. ‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ùë¶‚àó‚ÜêùëÄùëì,Óà∞‚Ñô (ùë•‚àó,1ùëõ,1ùë†)[| |ùë¶‚àó ‚àíùëî Óà∞ideal(ùë•‚àó)| | ‚â• ùõø 1] ‚â§ ùúá(ùë†).
Furthermore,wesaythatùëÄ isunbiasedifùëÄ satisfiesthefollowingguarantee:
3. MeanSecurity. ùëÄ isanunbiasedestimatorofùëîideal suchthat
Óà∞
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ùîº [ùë¶‚àó] = ùëîideal(ùë•‚àó).
ùëõ ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•‚àó,1ùëõ,1ùë†) Óà∞
4.3 The Cutoff Dissimilarity Function
Definition 4.6is essentially obtainedby instantiatingDefinition 4.3 withthe choicesùêø(0) = ùêø>ùõø0,
ùêø(1) = ùêø>ùõø1,andùúÜ = CutoffDist ,asinthefollowingdefinition.21
ùõø1
Definition4.7. LetÓâÑ ‚äÜ ‚Ñùùëõ beasetandletùõø ‚â• 0. Theùõø-cutoffdistributiondissimilarityfunctionfor
randomizedfunctionsÓâÑ ‚Üí Œî(‚Ñù)isdefinedasfollows. Foranyrandomizedfunctionsùëì,ùëì‚Ä≤ ‚à∂ ÓâÑ ‚Üí
Œî(‚Ñù),
CutoffDist ùõø(ùëì,ùëì‚Ä≤) = sup ‚Ñô[| |ùëì(ùë•)‚àíùëì‚Ä≤(ùë•)|
|
> ùõø],
ùë•‚ààÓâÑ
wheretheprobabilityisovertherandomnessofùëì(ùë•)andùëì‚Ä≤(ùë•).
However,Definition4.6isslightlysimplifiedcomparedtoastrictapplicationofDefinition4.3,as
follows.
‚Ä¢ The distribution dissimilarity function ùúÜ in Definition 4.3 is defined over distributions of
randomizedfunctions. However,asexplainedinRemark4.4,alocalmitigatoroutputsafixed
randomizedfunction(i.e.,adegenerate,singletondistributionoverrandomizedfunctions). So
ourdefinitionsimplifiesaccordingly,toanotionofdissimilaritydefinedforfixedrandomized
functions.
‚Ä¢ IfweweretoapplyDefinition4.3withlossùêø(1) = ùêø>ùõø1 directly,Item1inDefinition4.6would
insteadstatethat
‚Ñô ‚Ñô [|ùëî(ùë•)‚àíùë¶| ‚â• ùõø ] ‚â• ùúÄ ‚â§ ùúá(ùë†), (1)
ùëî‚àºÓà≥[ (ùë•,ùë¶)‚àºÓà∞ 1 ]
whereÓà≥isthedistributionofthefunctionùëî(ùë•) = ùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†),sosamplingùëî ‚àº Óà≥means
samplingboth(i)theinternalrandomnessneededbyùëÄ,and(ii)thesamplesfromÓà∞needed
byùëÄ. Weviewthisdefinitionasslightlycumbersome,soinsteadweadoptItem1. Notethat
Eq.(1)impliesItem1byaunionbound.
21Themeansecurityrequirement(Item3)isanoptionaladditionalguaranteethatdoesnotfollowfromDefinition4.3,
andmakessenseonlywhenÓâÖ =‚Ñù.
184.3.1 SecurityImplicationsoftheCutoffDissimilarityFunction
We now show that cutoff loss security implies a notion of security that we call weak local TV
security.
Definition4.8. LetÓâÑ,ÓâÖ besets. ThelocalTVdistributiondissimilarityfunctionforrandomized
functionsÓâÑ ‚Üí Œî(ÓâÖ)isdefinedasfollows. Foranyrandomizedfunctionsùëì,ùëì‚Ä≤ ‚à∂ ÓâÑ ‚Üí Œî(ÓâÖ),
LocalTV(ùëì,ùëì‚Ä≤) = sup TV(ùëì(ùë•),ùëì‚Ä≤(ùë•)).
ùë•‚ààÓâÑ
Weclaimthatrandomizedrounding allowsustoconvertCutoffDistboundsintoweakLocalTV
bounds,whilehurtingtheaccuracyonlybyaboundedamount. Specifically,wehavethefollowing
lemma.
Lemma 4.9. For every index ùëõ ‚àà ‚Ñï, let ÓâÑ be a set, and let ùîª ‚äÜ Œî(ÓâÑ √ó‚Ñù) be a collection of
ùëõ ùëõ ùëõ
distributions. Let ùîª = {ùîª } , and let ùúÄ,ùõø ,ùõø ‚â• 0. Suppose ùëÄ is an efficient mitigator that is
ùëõ ùëõ‚àà‚Ñï 0 1
(ùúÄ,ùõø ‚Üí ùõø )-cutofflosssecurefordistributionsùîª. Then,forallùõΩ > 0,thereisanefficientmitigatorùëÄ‚Ä≤
0 1
withthefollowing modifiedaccuracyandlosssecurity properties,withthesame order ofquantifiers
asinDefinition4.6:
1. Accuracy. ‚Ñô [|ùë¶‚àó ‚àíùë¶| ‚â• ùõø (1+ùõΩ)] ‚â§ ùúÄ +ùúá(ùë†).
1
(ùë•,ùë¶)‚àºÓà∞
ùë¶‚àó‚ÜêùëÄ‚Ä≤ùëì,Óà∞(ùë•,1ùëõ,1ùë†)
2. Local TV Security. LocalTV(ùëî,ùëîideal) ‚â§ ùúá(ùë†) + 1, where ùëî ‚à∂ ÓâÑ ‚Üí Œî(‚Ñù) is given by ùëî(ùë•) =
Óà∞ ùõΩ
ùëÄ‚Ä≤ùëì,Óà∞(ùë•,1ùëõ,1ùë†).
Proof. Let ùõº = ùõø ‚ãÖùõΩ ‚àà ‚Ñù be a rounding parameter, and let ‚åä‚ãÖ‚åã ‚à∂ ‚Ñù ‚Üí ùõº‚Ñ§ be the function that
1 ùõº
rounds downwards to an integer multiple of ùõº, i.e., ‚åäùë•‚åã = ‚åäùë•‚åã ‚ãÖ ùõº ‚àà ùõº‚Ñ§. The new mitigator
ùõº ùõº
ùëÄ‚Ä≤ simply runs ùëÄ to get some value ùë¶ ‚àà ‚Ñù, samples a random offset ùëè ‚àº U([0,ùõº)), and outputs
‚åäùë¶ +ùëè‚åã . Supposeùëîold-ideal wasthepreviousidealfunctionthathadcutofflosssecurityWedefine
ùõº Óà∞
thenewùëîideal asùëîideal(ùë•) = ‚åäùëîold-ideal(ùë•)+ùëè‚åã whereùëè ‚àº U([0,ùõº)).
Óà∞ Óà∞ Óà∞ ùõº
Bydirectpropertiesofthefloorfunction,itisclearthataccuracycanonlygetworsebyanadditive
factorofùõº = ùõø ‚ãÖùõΩ. ToseethatùëÄ‚Ä≤ satisfieslocalTVsecurity,recallthatbyItem2inDefinition4.6,
1
wehave
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ùë¶‚àó‚ÜêùëÄùëì,Óà∞‚Ñô (ùë•‚àó,1ùëõ,1ùë†)[| |ùë¶‚àó ‚àíùëî Óà∞old-ideal(ùë•‚àó)| | ‚â• ùõø 1] ‚â§ ùúá(ùë†).
Assuming|ùë¶‚àó ‚àíùëîold-ideal(ùë•‚àó)| < ùõø ,thenweknow
Óà∞ 1
ùõø 1
TV(‚åäùë¶‚àó +ùëè‚åã ùõº,‚åäùëî Óà∞old-ideal(ùë•‚àó)+ùëè‚åã ùõº) ‚â§ ùõº1 = ùõΩ,
asbyacouplingargument,theonlywaythetwoquantitiescandifferiswhenùëèlandsinaninterval
thathaslengthatmostùõø . Therefore,byaunionbound,
1
1
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ TV(ùëÄ‚Ä≤ùëì,Óà∞ (ùë•‚àó,1ùëõ,1ùë†),ùëîideal(ùë•‚àó)) ‚â§ ùúá(ùë†)+ .
Óà∞ ùõΩ
Thatis,LocalTV(ùëî,ùëîideal) ‚â§ ùúá(ùë†)+ 1,whereùëî ‚à∂ ÓâÑ ‚Üí Œî(‚Ñù)isgivenbyùëî(ùë•) = ùëÄ‚Ä≤ùëì,Óà∞(ùë•,1ùëõ,1ùë†).
Óà∞ ùõΩ
195 Some Initial Observations on Secure Backdoor Mitigation
5.1 Secure Backdoor Mitigation Cannot be Distribution Free
Feldman(2009)showedaresultonthepowerofmembershipqueriesinagnosticlearning,which
hassignificantimplicationsforourwork. Insecurebackdoormitigation,thedefenderreceivesa
potentially-backdoored functionùëìÃÉfroman untrustedparty, andqueries thisfunctionat locations
ofitschoosinginordertolearna‚Äúclean‚Äù(‚Äúnearlycanonical‚Äù)functionùëî thathasgoodaccuracy.
Forthisprocesstomakesense,weinsistthatbackdoormitigationbemoreefficientthanlearning
a‚Äúclean‚Äùfunctionfromscratchusingrandomsamples.
But why would it bepossible for backdoor mitigation to be more efficient? The basic reason is
that whenlearning from scratch, thelearner has accessonly to i.i.d. randomsamples., whereas in
backdoormitigation,thedefenderalsohasoracle(membershipquery)accesstothe(suspectbutstill
useful)functionùëìÃÉ. Thisraisesthequestionofwhen,ifatall,canlearningusingoracleaccesstoa
labelingfunctionbemoreefficientthanlearningusingi.i.d.samples? Feldman(2009)showedthat
ingeneral,fordistribution-freelearning,oracleaccessdoesnothelp,asinthefollowingtheorem.
Theorem 5.1 (Theorem 6 in Feldman, 2009). Let ùëö,ùëû,ùë° ‚à∂ [0,1]2 ‚Üí ‚Ñï. Let ÓâÑ be a set, and let
Óà¥ ‚äÜ {¬±1}ÓâÑ beaclassoffunctionswithVCdimensionùëë ‚àà ‚Ñï. Assumeùê¥isanalgorithmsuchthatfor
everyùúÄ,ùõø ‚àà [0,1],ùê¥agnosticallyPAClearnsÓà¥ withparameters(ùúÄ,ùõø). ùê¥usesùëö(ùúÄ,ùõø)i.i.d.samples
fromadistributionÓà∞thatgenerateslabeledexamplesoftheform(ùë•,ùëì(ùë•))forsomelabelingfunction
ùëì ‚à∂ ÓâÑ ‚Üí {¬±1},aswellasusingùëû(ùúÄ,ùõø)oraclequeriestoùëì,andùê¥runsintimeùë°(ùúÄ,ùõø).
Thenthereexistsanalgorithmùê¥‚Ä≤ thatusesonlyi.i.d.samplesfromÓà∞(anddoesnotrequireoracle
access),suchthatùê¥‚Ä≤ agnosticallyPAClearnsÓà¥ withparameters(ùúÄ,ùõø)withrespecttothesametypes
ofdistributionsÓà∞. ùê¥‚Ä≤ uses
ùëëlog(ùëë/ùúÄ)+log(1/ùõø)
ùëö‚Ä≤(ùúÄ,ùõø) = ùëÇ
( ùúÄ2 )
i.i.d.samplesfromÓà∞,andùê¥‚Ä≤ runsintimeùë°‚Ä≤(ùúÄ,ùõø) = ùë°(ùúÄ/2,ùõø/2)+ùëö‚Ä≤(ùúÄ,ùõø).
ProofSketch. TakeasampleùëÜconsistingofùëö‚Ä≤(ùúÄ,ùõø)i.i.d.samplesfromÓà∞. Byuniformconvergence,
ùëÜ is an ùúÄ/2-sample for Óà∞, namely, |‚Ñô [ùëç ‚àà ùê∏]‚àí‚Ñô [ùëç ‚àà ùê∏]| ‚â§ ùúÄ/2 for every event ùê∏. Now
ùëç‚àºU(ùëÜ) ùëç‚àºÓà∞
simulate ùê¥ with parameters (ùúÄ/2,ùõø/2) to learn the distribution U(ùëÜ) and obtain a classifier ‚Ñé ‚à∂
ÓâÑ ‚Üí {¬±1}(wehavefullknowledgeofùëÜ,sowecansimulateoraclequeriestothelabelingfunction
of U(ùëÜ)). Then ùêø0-1(ùëî) ‚â§ ùêø0-1 (ùëî) + ùúÄ/2 ‚â§ ùúÄ, where the first inequality holds because ùëÜ is an
Óà∞ U(ùëÜ)
ùúÄ/2-sampleandthesecondfollowsfromthecorrectnessofùê¥.
Theconclusionisthat,forgeneraldistributions,learningwithoracleaccesscannotbefasterthan
learning from random samples, up to constant factors. To see that this implies that backdoor
mitigationcannotingeneralbefasterthanlearningfromrandomsamples,simplyconsiderthe
casewherethepotentially-backdooredùëìÃÉiscompletelyhonest,namely,ùëìÃÉispreciselythelabeling
functionofthepopulationdistributionÓà∞. ThisamountstolearningÓà∞withoracleaccesstothe
20true labeling function, which, as we saw, is no easier in general than learning Óà∞ from random
samples.22
However,Theorem5.1doesnotimplythatoracleaccessisnotusefulwhenlearningwithrespect
tospecificfamiliesofdistributions,e.g.,learningwithrespecttodistributionsthathaveauniform
marginalonthedomain(acasewefocusoninthispaper). Thereasonisthatthereductioninthe
proofofTheorem5.1executesùê¥onthedistributionU(ùëÜ)‚Äìwhichisveryfarfromuniformonthe
domainÓâÑ.
Infact,thelearningparitywithnoise (LPN)assumption,whichisawidely-believedassumptionin
moderncryptography, posits thatin some cases(e.g., learningparity functions), learningfrom
noisyrandomsamplesiscomputationallyinfeasible,butlearningwithoracleaccesstoalabeling
functions iseasy (e.g., for parityfunctions efficient learningis provided bythe Goldreich‚ÄìLevin
algorithm,seeTheoremA.1).
Thisisonejustificationforourfocusinthispaperonbackdoormitigationwithrespecttospecific
‚Äúnice‚Äùclassesofdistributions. SeefurtherdiscussioninSection2.1.3.
5.2 Lower Bound for General Mitigation
Here,weshowthattherearecollectionsofdistributionsùîªwheremitigationisnotmoreefficient
thandirectly(re-)learningfromrandomsamples. Forconcreteness,wewillconsiderDefinition4.5.
The intuition here is that the only advantage global mitigation has, as compared to directly
learning, is membership queries from (a possibly corrupted) hypothesis ùëì. However, there are
natural choices ofpopulation distributions for whichmembership queries and sample accessare
equally powerful. In particular, if we look at functions with no structure, then seeing labeled
examples, either by samples or membership queries, does not help prediction for new, unseen
inputs.
Christianoet al.(2024)showsomethingsimilar inthewhitebox settingusingindistinguishability
obfuscationandpuncturablepseudorandomfunctions. However,sinceallofourtechniquesarein
theblack-boxsetting,wedemonstratethesignificantlysimplerresult,wherethemitigatorgets
onlyinput-outputaccesstoùëì.
Formally, in Definition 4.5, consider ÓâÑ = {0,1}ùëõ, ÓâÖ = {0,1}. For a function ‚Ñé ‚à∂ ÓâÑ ‚Üí ÓâÖ, let
ùëõ ùëõ
Óà∞
‚Ñé
= U({(ùë•,‚Ñé(ùë•))}
ùë•‚ààÓâÑ
ùëõ). Letùîª
ùëõ
= {Óà∞
‚Ñé
‚à∂ ‚Ñé ‚àà ÓâÖÓâÑ ùëõ}. Letùêø(0) = ùêø(1) = ùêø0-1.
Lemma5.2(Informal). Intheabovesetting,foranyùúÄ > 0andnegligiblefunctionùúá,supposeùëÄ is
1
amitigatorsuchthat
‚Ñô[ùêø Óà∞0-1 (ùëÄ‚Ñé,Óà∞ ‚Ñé(1ùëõ,1ùë†)) ‚â§ ùúÄ 1] ‚â• 1‚àíùúá(ùë†),
‚Ñé
for a randomly chosen ‚Ñé ‚à∂ ÓâÑ ‚Üí ÓâÖ. Suppose that ùëÄ uses ùëò ‚â§ 2ùëõ/4 samples from Óà∞ and makes
ùëõ ‚Ñé
ùëû ‚â§ 2ùëõ/4queriestotheoracle‚Ñé. Then,thereisalearnerùëÄ‚Ä≤ usingùëÇ(ùëò +ùëû)samplesinexpectation
suchthat
‚Ñô[ùêø Óà∞0-1 (ùëÄ‚Ä≤Óà∞ ‚Ñé(1ùëõ,1ùë†)) ‚â§ ùúÄ 1] ‚â• 1‚àíùúá(ùë†).
‚Ñé
22Onecouldstillhope,forinstance,thatifthedefenderhaswhiteboxaccesstoùëìÃÉthentheycouldmitigatefaster
thanlearningwithrandomsamples.Inthispaperwefocusonmitigationwithblackboxaccess.
21We emphasize that we are not using the full power of the mitigator in Lemma 5.2, making the
lower bound only stronger. In particular, we are only using Item 2 when plugging in the true
hypothesis‚Ñéasthemembershiporacle,andwearenotusingItem1atall.
ProofsketchofLemma5.2. Since Óà∞ has no structure and we are considering the ùêø0-1 loss, an
‚Ñé
optimal choice of mitigator ùëÄ with ùëò samples and ùëû queries to ùëì would be as follows. Given ùëò
samples,ùëÄ wouldqueryùëû distinctpointsin{0,1}ùëõ notpresentinthesamples. Then,ùëÄ canstore
a lookup table correspondingto allsampled andqueried pairs. Forthese inputvalues, it would
outputwhateverisinitstable,andforeverythingelse,itwouldrandomlyguessanelementof
{0,1}. Letùëá bethenumberofdistinctelementsinthelookuptable. Itisclearthatùëá ‚â§ ùëò +ùëû.
A learner ùëÄ‚Ä≤ without membership queries can emulate this process except for the ùëû queries to
‚Ñé. Instead, it can use samples from Óà∞ until it has seen ùëá distinct examples. In this case, the
‚Ñé
performancewithrespecttoùêø0-1 willbeatleastasgoodasùëÄ. Itremainstoseehowmanysamples
ùëÄ‚Ä≤ needstogenerateùëá distinctexamples.
Let ùëá‚Ä≤ denote the number of samples ùëÄ‚Ä≤ draws. Let ùëç‚Ä≤ denote the expected number of distinct
elementsseeninùëá‚Ä≤ samples. Forùëá‚Ä≤ ‚â§ 2ùëõ,bylinearityofexpectation,wehave
ùîº[ùëç‚Ä≤ ] = 2ùëõ (1‚àí (1‚àí 21
ùëõ)ùëá‚Ä≤
) ‚â• 2ùëõ (1‚àíùëí‚àí 2ùëá ùëõ‚Ä≤ ) ‚â• 2ùëõ (1‚àí (1‚àí 2ùëá ‚ãÖ2‚Ä≤ ùëõ)) = ùëá 2‚Ä≤ ,
wherewehaveusedtheinequalityùëí‚àíùë• < 1‚àíùë• forallùë• ‚àà [0,1]. Therefore,settingùëá‚Ä≤ = 2(ùëò+ùëû) ‚â§ 2ùëõ,
2
wehaveùëá‚Ä≤ ‚â• 2ùëá,andtherefore,ùîº[ùëç‚Ä≤] ‚â• ùëá.
6 Global Mitigation
In this section we show a mitigation result for potentially-backdoored functions {¬±1}ùëõ ‚Üí {¬±1},
whichreliesontwomainassumptions:
1. Thepotentially-backdooredfunctionhaslowpopulationloss.
2. The population distribution is ‚Äúnice‚Äù in the sense that the marginal over the domain is
uniform,andthelabelsareclosetoaFourier-heavyfunction. (However,thelabelsneednot
bedeterministic. Namely,foranùë• inthedomain,itispossiblethatboththelabels1and‚àí1
havepositiveprobability).
6.1 Fourier Analysis Preliminaries
FollowingaresomebasicnotionsfromFourieranalysisofBooleanfunctions,whichareusedin
thispaper. SeeO‚ÄôDonnell(2014)foracomprehensiveintroduction.
Theexpectationinnerproduct. Givenameasurespace,letÓà∏ bethesetofreal-valuedrandom
2
variablesoverthemeasurespacewithfinitesecondmoment. ThenÓà∏ isavectorspaceoverthe
2
reals. Thefunction‚ü®‚ãÖ,‚ãÖ‚ü© ‚à∂ Óà∏ √óÓà∏ ‚Üí ‚Ñùgivenby
2 2
‚ü®ùëã,ùëå‚ü© = ùîº[ùëãùëå]
‚àö
isaninnerproduct. Inparticular,‚Äñùëã‚Äñ = ‚ü®ùëã,ùëã‚ü©isanorm.
22Fouriercharactersandcoefficientson theBooleanhypercube. Letùëõ ‚àà ‚ÑïandletÓâÑ = ‚Ñùùëõ.
Weidentifyanyfunctionùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùwiththerandomvariableùëì(ùëã),whereùëã isuniformoverÓâÑ.
Inparticular,‚ü®ùëì,ùëî‚ü© = ùîº [ùëì(ùëã)ùëî(ùëã)]foranyùëì,ùëî ‚àà ‚ÑùÓâÑ.
ùëã‚àºU(ÓâÑ)
ForanyùëÜ ‚äÜ [ùëõ],thecharacter ofùëÜ isthefunctionÓâÑ ‚Üí {¬±1}givenby
ùúí (ùë•) = ‚àèùë•,
ùëÜ ùëñ
ùëñ‚ààùëÜ
whereùë• = (ùë• ,‚Ä¶,ùë• ).
1 ùëõ
Theset{ùúí (ùë•) ‚à∂ ùëÜ ‚äÜ [ùëõ]}isanorthonormalbasisofthespaceofallfunctionsÓâÑ ‚Üí ‚Ñù. Inparticular,
ùëÜ
everyfunctionùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùhasauniquerepresentation
ùëì(ùë•) = ‚àë ùëìÃÇ (ùëÜ)ùúí (ùë•)
ùëÜ
ùëÜ‚äÜ[ùëõ]
whereùëìÃÇ (ùëÜ) = ‚ü®ùëì,ùúí ‚ü©istheùëÜ-coefficient,orweightofùëÜinùëì. Weindicatesetsofcharacterswithspeci-
ùëÜ { } { }
| | | |
fiedweightsusingnotationsuchasùëìÃÇ‚â•ùõº = ùëÜ ‚äÜ [ùëõ] ‚à∂ |ùëìÃÇ (ùëÜ)| ‚â• ùõº andùëìÃÇ=ùõΩ = ùëÜ ‚äÜ [ùëõ] ‚à∂ |ùëìÃÇ (ùëÜ)| = ùõΩ .
| | | |
Theorem6.1(Parseval‚Äôsidentity). Foranyùëõ ‚àà ‚Ñïandùëì ‚à∂ {¬±1}ùëõ ‚Üí ‚Ñù,
‚Äñùëì‚Äñ2 = ‚ü®ùëì,ùëì‚ü© = ùîº ùë•‚àºU({¬±1}ùëõ)[ùëì(ùë•)2 ] = ‚àë ùëìÃÇ (ùëÜ)2.
ùëÜ‚äÜ[ùëõ]
6.2 Mitigation for Fourier-Heavy Functions
Definition6.2. Letùëõ,ùë° ‚àà ‚Ñï,ÓâÑ = {¬±1}ùëõ,andùúè ‚â• 0. TheclassofFourierùúè-heavyfunctionsis
{ }
Óà¥ = ùëì ‚àà ‚ÑùÓâÑ ‚à∂ ‚àÄùëÜ ‚äÜ [ùëõ] ‚à∂ | |ùëìÃÇ (ùëÜ)| | ‚â• ùúè ‚à® ùëìÃÇ (ùëÜ) = 0 .
‚â•ùúè ( | | )
Similarly,theclassofbinary-valuedFourierùúè-heavyfunctionsis
{ }
Óà¥¬±1 = ùëì ‚àà {¬±1}ÓâÑ ‚à∂ ‚àÄùëÜ ‚äÜ [ùëõ] ‚à∂ | |ùëìÃÇ (ùëÜ)| | ‚â• ùúè ‚à® ùëìÃÇ (ùëÜ) = 0 ‚äÜ Óà¥ .
‚â•ùúè ( | | ) ‚â•ùúè
{ }
| |
TheclassofFourierùë°-sparsefunctionisÓà¥ = ùëì ‚àà ‚ÑùÓâÑ ‚à∂ |ùëìÃÇ>0| ‚â§ ùë° .
ùë° | |
Theorem6.3(TVglobalmitigationforFourier-heavyfunctions). Letùëõ,ùë† ‚àà ‚Ñï,letùúè > 0,ùúÄ ‚â§ (ùúè/6)2
0
and ùúÄ > ùúÄ , let ÓâÑ = {¬±1}ùëõ. Let ùîª ‚äÜ Œî(ÓâÑ √ó[‚àí1,1]) be a collection of distributions Óà∞ with uniform
1 0
marginalonÓâÑ suchthatùêø2 (Óà¥ ) ‚â§ ùúÄ . ThenAlgorithm1isaglobalmitigatorthatis
Óà∞ ‚â•ùúè 0
(ùêø2,ùúÄ 0) ‚Üí (ùêø2,ùúÄ 1)
totalvariationsecureforùîª(Definition4.5). Algorithm1uses
ùë† +log(1/ùúè)
ùëö = ùëÇ
( ùúè2(ùúÄ ‚àíùúÄ ) )
1 0
i.i.d. samples from a distribution Óà∞ ‚àà ùîª and poly(ùëõ,1/ùúè,ùë†) oracle queries to an arbitrary function
ùëì ‚à∂ ÓâÑ ‚Üí [‚àí1,1]withlossùêø2 (ùëì) ‚â§ ùúÄ .
Óà∞ 0
23fÀÜ(S)
| |
œÑ
[n]
S 1 S 2 S 2n ‚äÜ
¬∑¬∑¬∑
Figure3: Inaùúè-heavyfunctionùëì,allnon-zeroFouriercoefficientshaveabsolutevalueatleastùúè.
Remark 6.4. The assumption in Theorem 6.3 that ùúÄ is strictly less than ùúè2 (e.g., ùúÄ ‚â§ (ùúè/6)2)
0 0
appears tobe necessarywhen usingour Goldreich‚ÄìLevin-basedtechnique. Supposethat instead,
wetookùúÄ = ùúè2. Considerafunctionùë¶ ‚à∂ ÓâÑ ‚Üí ‚ÑùwithtwodistinctcoefficientsùëÜ ,ùëÜ ‚äÜ [ùëõ]suchthat
0 1 2
ùë¶ÃÇ(ùëÜ) = ùúè for ùëñ ‚àà {1,2}. Let ùëì (ùë•) = ‚àë ùë¶ÃÇ(ùëÜ)ùúí (ùë•). Then for Óà∞ = U({(ùë•,ùë¶(ùë•)) ‚à∂ ùë• ‚àà ÓâÑ}),
ùëñ ‚àíùëñ ùëÜ‚äÜ[ùëõ]‚à∂ùëÜ‚â†ùëÜùëñ ùëÜ
the losses are ùêø2 (ùëì ) = ùêø2 (ùëì ) = ùúè2 ‚â§ ùúÄ . Hence, the algorithm would be required to return
Óà∞ ‚àí1 Óà∞ ‚àí2 0
the same output distribution on query access to either of ùëì and ùëì . However, executing the
‚àí1 ‚àí2
Goldreich‚ÄìLevinalgorithmonùëì willnotrecoverùëÜ. Themissingcoefficient(thatisnotrecovered)
‚àíùëñ ùëñ
dependsonthefunctionùëì beingqueried. Thissuggeststhatifincreasingtheupperboundbeyond
‚àíùëñ
ùúè2 ispossible,thendoingsorequiresnewideas.
Corollary6.5. Letùëõ,ùë† ‚àà ‚Ñï,letùúè > 0,ùúÄ ‚â§ (ùúè/12)2andùúÄ > 4ùúÄ ,letÓâÑ = {¬±1}ùëõ. Letùîª ‚äÜ Œî(ÓâÑ √ó{¬±1})
0 1 0
beacollectionof distributionsÓà∞withuniformmarginal onÓâÑ suchthatùêø0 Óà∞-1 (Óà¥ ‚â•¬± ùúè1 ) ‚â§ ùúÄ 0. Then,the
compositionofAlgorithm1andsign(‚ãÖ)isaglobalmitigatorthatis
(ùêø0-1,ùúÄ 0) ‚Üí (ùêø0-1,ùúÄ 1)
totalvariationsecureforùîª(Definition4.5). Thealgorithmuses
ùë† +log(1/ùúè)
ùëö = ùëÇ
( ùúè2(ùúÄ ‚àí4ùúÄ ) )
1 0
i.i.d. samples from a distribution Óà∞ ‚àà ùîª and poly(ùëõ,1/ùúè,ùë†) oracle queries to an arbitrary function
ùëì ‚à∂ ÓâÑ ‚Üí {¬±1}withlossùêø0-1(ùëì) ‚â§ ùúÄ .
Óà∞ 0
ProofofCorollary6.5. ThisfollowsfromClaimB.4andTheorem6.3,whenappliedwith4ùúÄ instead
0
ofùúÄ . Specifically,
0
ùêø2 Óà∞(Óà¥ ‚â•ùúè) = 4ùêø0 Óà∞-1(Óà¥ ‚â•ùúè) ‚â§ 4ùêø0 Óà∞-1 (Óà¥ ‚â•¬± ùúè1 ) ‚â§ 4ùúÄ 0,
ùêø2 (ùëì) = 4ùêø0-1(ùëì) ‚â§ 4ùúñ ,
Óà∞ Óà∞ 0
24wherewehaveusedthefactthatÓà¥¬±1 ‚äÜ Óà¥ . Therefore,Algorithm1isaglobalmitigatorthatis
‚â•ùúè ‚â•ùúè
(ùêø2,4ùúÄ ) ‚Üí (ùêø2,ùúÄ )totalvariationsecureforùîª. ApplyingItem2ofDefinition4.5,asguaranteed
0 1
byTheorem6.3,wehave
‚Ñô ùëî‚àºÓà≥[ùêø2 Óà∞(ùëî) ‚â§ ùúÄ 1] ‚â• 1‚àíùúá(ùë†),
whereÓà≥isthedistributionofthefunctionùëÄùëì,Óà∞(1ùëõ,1ùë†). Sinceùêø0-1(sign(ùëî)) ‚â§ ùêø2 (ùëî)byClaimB.4,
Óà∞ Óà∞
itfollowsthat
‚Ñô ùëî‚àºÓà≥[ùêø0 Óà∞-1(sign(ùëî)) ‚â§ ùúÄ 1] ‚â• 1‚àíùúá(ùë†),
asdesired.
Assumptions:
‚Ä¢ ùë†,ùëõ ‚àà ‚Ñï;ùúè > 0;ùúÄ < ùúÄ ;ùúÄ ‚â§ (ùúè/6)2;ÓâÑ = {¬±1}ùëõ.
0 1 0
‚Ä¢ Óà∞ ‚àà Œî(ÓâÑ √ó[‚àí1,1])withÓà∞ = U(ÓâÑ)andùêø2 (Óà¥ ) ‚â§ ùúÄ .
ÓâÑ Óà∞ ‚â•ùúè 0
‚Ä¢ Thealgorithmhasoracleaccesstoanarbitraryfunctionùëì ‚àà ‚ÑùÓâÑ (notnecessarilyin
Óà¥ )suchthatùêø2 (ùëì) ‚â§ ùúÄ
‚â•ùúè Óà∞ 0
‚Ä¢ ùëö = ùëÇ((ùë† +log(1/ùúè))/(ùúè2(ùúÄ
1
‚àíùúÄ 0))).
‚Ä¢ ùëç = ((ùë• 1,ùë¶ 1),‚Ä¶,(ùë• ùëö,ùë¶ ùëö)) ‚àº Óà∞ùëö.
FourierHeavyMitigator(ùëç,ùúè,ùëõ):
ExecutetheGoldreich‚ÄìLevinalgorithm(TheoremA.1)usingoracleaccesstoùëì to
obtainacollectionÓàø ‚äÜ 2[ùëõ] suchthat‚Ñô ùëìÃÇ‚â•2ùúè/3 ‚äÜ Óàø ‚äÜ ùëìÃÇ‚â•ùúè/2 ‚â• 1‚àínegl(ùë†)
[ ]
for ùëÜ ‚àà Óàø:
ùëî(ùëÜ) ‚Üê 1 ‚àë ùúí (ùë•)‚ãÖùë¶
ùëö ùëñ‚àà[ùëö] ùëÜ ùëñ ùëñ
returnthefunctionùëî(ùë•) = ‚àë ùëî(ùëÜ)‚ãÖùúí (ùë•)
ùëÜ
ùëÜ‚ààÓàø
Algorithm1: AnindependentglobalmitigatorforFourier-heavyfunctions.
6.2.1 ProofofTheorem6.3
Westartwithsomebasicobservations.
Notation6.6. Forùëõ ‚àà ‚Ñï,ÓâÑ = {¬±1}ùëõ andÓà∞ ‚àà Œî(ÓâÑ √ó‚Ñù),denoteùë¶ Óà∞(ùë•) = ùîº (ùëã,ùëå)‚àºÓà∞[ùëå |ùëã = ùë•].
Claim 6.7 (Loss decomposition). Let ÓâÑ be a set, and let Óà∞ ‚àà Œî(ÓâÑ √ó‚Ñù). Then for any function
ùëü ‚à∂ ÓâÑ ‚Üí ‚Ñù,
ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ] = ùîº ùë•‚àºÓà∞ ÓâÑ[(ùëü(ùë•)‚àíùë¶ Óà∞(ùë•))2 ]+ùëâ(ùê∑),
whereùëâ(Óà∞) = ùîº ùë•‚àºÓà∞ ÓâÑ[Var ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶]] = ùîº ùë•‚àºÓà∞ ÓâÑ[ùîº ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶2 ]‚àíùîº ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶]2 ].
25Proof. ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ] = ùîº (ùë•,ùë¶)‚àºÓà∞[ùëü(ùë•)2 ‚àí2ùëü(ùë•)ùë¶ +ùë¶2 ]
= ùîº ùë•‚àºÓà∞ ÓâÑ[ùëü(ùë•)2 ‚àí2ùëü(ùë•)ùë¶ Óà∞(ùë•)+ùîº ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶2 ]]
= ùîº ùë•‚àºÓà∞ ÓâÑ[ùëü(ùë•)2 ‚àí2ùëü(ùë•)ùë¶ Óà∞(ùë•)+ùë¶ Óà∞(ùë•)2 +ùîº ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶2 ]‚àíùë¶ Óà∞(ùë•)2 ]
= ùîº
ùë•‚àºÓà∞
ÓâÑ[(ùëü(ùë•)‚àíùë¶ Óà∞(ùë•))2 ]+ùëâ(Óà∞).
Fact6.8. Letùëõ ‚àà ‚Ñï,ÓâÑ = {¬±1}ùëõ andÓà∞ ‚àà Œî(ÓâÑ √ó‚Ñù)withÓà∞ ÓâÑ = U(ÓâÑ). Then
‚àÄùëÜ ‚äÜ [ùëõ] ‚à∂ ùë¶ÃÇ(ùëÜ) = ùîº [ùë¶ ‚ãÖùúí (ùë•)].
Óà∞ (ùë•,ùë¶)‚àºÓà∞ ùëÜ
Proof. ùë¶ÃÇ Óà∞(ùëÜ) = ‚ü®ùë¶ Óà∞,ùúí ùëÜ‚ü© = ùîº ùë•‚àºU(ÓâÑ)[ùîº ùë¶‚àºÓà∞ ùëå|ùëã=ùë•[ùë¶]‚ãÖùúí ùëÜ(ùë•)] = ùîº (ùë•,ùë¶)‚àºÓà∞[ùë¶ ‚ãÖùúí ùëÜ(ùë•)].
WearenowpreparedtoproveTheorem6.3.
ProofofTheorem6.3. First,bytheGoldreich‚ÄìLevintheorem(TheoremA.1),poly(ùëõ,1/ùúè,ùë†)queries
toùëì areindeedsufficienttoguaranteethat
‚Ñô ùëìÃÇ‚â•2ùúè/3 ‚äÜ Óàø ‚äÜ ùëìÃÇ‚â•ùúè/2 ‚â• 1‚àínegl(ùë†). (2)
[ ]
ByParseval‚ÄôsidentityandtheinclusionÓàø ‚äÜ ùëìÃÇ‚â•ùúè/2 inEq.(2),itfollowsthat
‚Ñô[|Óàø| ‚â§ 4/ùúè2 ] ‚â• 1‚àínegl(ùë†) (3)
Second,byFact6.8andHoeffding‚Äôsinequality,foreveryùëÜ ‚àà Óàø,
ùëí‚àíùë†
‚Ñô ùëç‚àºÓà∞ùëö[| |ùëî(ùëÜ)‚àíùë¶ÃÇ Óà∞(ùëÜ)|
|
‚â§ Œî] ‚â• 1‚àí 4/ùúè2, (4)
‚àö
where Œî = ùúè2(ùúÄ1‚àíùúÄ0), and we used the fact that ùëö ‚â• Œ©((ùë† +ln(1/ùúè))/Œî2 ). From Eqs. (3) and (4)
4
andtheunionbound,
‚Ñô[‚àÄùëÜ ‚àà Óàø ‚à∂ | |ùëî(ùëÜ)‚àíùë¶ÃÇ Óà∞(ùëÜ)|
|
‚â§ Œî] ‚â• 1‚àínegl(ùë†), (5)
wheretheprobabilityisoverthechoiceofthesampleùëç andtherandomnessoftheGoldreich‚ÄìLevin
algorithm.
Third,letùúÄ = ùêø2 (Óà¥ ) ‚â§ ùúÄ ,andlet‚Ñé ‚àà Óà¥ suchthatùêø2 (‚Ñé) = ùúÄ .23 Weshowthat
Óà¥ Óà∞ ‚â•ùúè 0 ‚â•ùúè Óà∞ Óà¥
‚Ñô ÃÇ ‚Ñé‚â•ùúè = Óàø ‚â• 1‚àínegl(ùë†), (6)
[ ]
where the probability is over the randomness of Goldreich‚ÄìLevin. This follows from the high
agreementbetweenùëì and‚Ñé,asfollows.
2
‚àë (ùëìÃÇ (ùëÜ)‚àíÃÇ ‚Ñé(ùëÜ) ) = ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëì(ùë•)‚àí‚Ñé(ùë•))2 ]
ùëÜ‚äÜ[ùëõ]
23Toseethatsuchan‚Ñéexists,identifyeachfunctioninÓà¥ withitsvectorofFouriercoefficientsin‚Ñù2ùëõ.Notethat
‚â•ùúè
Óà¥ isacompactsetin‚Ñù2ùëõ.ByClaim6.7andParseval‚Äôsidentity,thefunctionùêø2 iscontinuous.Existencefollows
‚â•ùúè Óà∞
fromtheextremevaluetheorem.
26= ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëì(ùë•)‚àíùë¶ +ùë¶ ‚àí‚Ñé(ùë•))2 ]
‚Äñ ‚Äñ2
= (ùëì ‚àíùë¶)+(ùë¶ ‚àí‚Ñé)
‚Äñ ‚Äñ
‚Äñ ‚Äñ ‚Äñ ‚Äñ 2
‚â§ (‚Äñùëì ‚àíùë¶ ‚Äñ+ ‚Äñùë¶ ‚àí‚Ñé ‚Äñ)
= ((ùêø2 Óà∞(ùëì))1/2 +(ùêø2 Óà∞(‚Ñé))1/2 )2 ‚â§ 4ùúÄ 0.
Inparticular,
| | ‚àö
ÃÇ ÃÇ
‚àÄùëÜ ‚äÜ [ùëõ] ‚à∂ |ùëì(ùëÜ)‚àí‚Ñé(ùëÜ)| ‚â§ 2 ùúÄ ‚â§ ùúè/3.
| | 0
Consequently,foranyùëÜ,ifÃÇ ‚Ñé(ùëÜ) ‚â• ùúè thenùëìÃÇ (ùëÜ) ‚â• 2ùúè/3,so
ÃÇ ‚Ñé‚â•ùúè ‚äÜ ùëìÃÇ‚â•2ùúè/3. (7)
Ontheotherhand,foranyùëÜ,ifùëìÃÇ (ùëÜ) ‚â• ùúè/2thenÃÇ ‚Ñé(ùëÜ) > 0. Because‚Ñé ‚àà Óà¥ ,thisimpliesÃÇ ‚Ñé(ùëÜ) ‚â• ùúè,
‚â•ùúè
so
ùëìÃÇ‚â•ùúè/2 ‚äÜÃÇ ‚Ñé‚â•ùúè. (8)
CombiningEqs.(2),(7)and(8)yields
‚Ñô ÃÇ ‚Ñé‚â•ùúè ‚äÜ ùëìÃÇ‚â•2ùúè/3 ‚äÜ Óàø ‚äÜ ùëìÃÇ‚â•ùúè/2 ‚äÜÃÇ ‚Ñé‚â•ùúè ‚â• 1‚àínegl(ùë†),
[ ]
asdesired.
Fourth,weconsiderthelossesof‚Ñéandùëî.
ùêø2 Óà∞(‚Ñé) = ùîº
ùëã‚àºÓà∞
ÓâÑ[(‚Ñé(ùëã)‚àíùë¶ Óà∞(ùëã))2 ]+ùëâ(Óà∞) (ByClaim6.7)
2
= ‚àë ÃÇ ‚Ñé(ùëÜ)‚àíùë¶ÃÇ(ùëÜ) +ùëâ(Óà∞), (Parseval‚Äôsidentity) (9)
( Óà∞ )
ùëÜ‚äÜ[ùëõ]
ùêø2 Óà∞(ùëî) = ‚àë(ùëîÃÇ(ùëÜ)‚àíùë¶ÃÇ Óà∞(ùëÜ))2 + ‚àë (ùëîÃÇ(ùëÜ)‚àíùë¶ÃÇ Óà∞(ùëÜ))2 +ùëâ(Óà∞) (ditto)
ùëÜ‚ààÓàø ùëÜ‚àà2[ùëõ]‚ßµÓàø
‚â§ |Óàø|‚ãÖŒî2 + ‚àë (ùëîÃÇ(ùëÜ)‚àíùë¶ÃÇ(ùëÜ))2 +ùëâ(Óà∞) (ByEq.(5),w.p.1‚àínegl(ùë†))
Óà∞
ùëÜ‚àà2[ùëõ]‚ßµÓàø
= (ùúÄ
1
‚àíùúÄ 0)+ ‚àë (ùëîÃÇ(ùëÜ)‚àíùë¶ÃÇ Óà∞(ùëÜ))2 +ùëâ(Óà∞) (ByEq.(3),w.p.1‚àínegl(ùë†))
ùëÜ‚àà2[ùëõ]‚ßµÓàø
2
= (ùúÄ ‚àíùúÄ )+ ‚àë ÃÇ ‚Ñé(ùëÜ)‚àíùë¶ÃÇ(ùëÜ) +ùëâ(Óà∞) (ùëîÃÇ(ùëÜ) =ÃÇ ‚Ñé(ùëÜ) = 0forùëÜ ‚àâ Óàø
1 0 ( Óà∞ )
ùëÜ‚àà2[ùëõ]‚ßµÓàø byEq.(6)and‚Ñé ‚àà Óà¥ ‚â•ùúè,
w.p.1‚àínegl(ùë†))
2
‚â§ (ùúÄ ‚àíùúÄ )+ ‚àë ÃÇ ‚Ñé(ùëÜ)‚àíùë¶ÃÇ(ùëÜ) +ùëâ(Óà∞)
1 0 ( Óà∞ )
ùëÜ‚äÜ[ùëõ]
= ùúÄ ‚àíùúÄ +ùúÄ ‚â§ ùúÄ . (ByEq.(9)andchoiceof‚Ñé)
1 0 Óà¥ 1
ThisshowsthatAlgorithm1satisfiestheaccuracyrequirement(Item2)inDefinition4.5.
27Fifth, for thesecurity requirement (Item 1in Definition 4.5), observethat Algorithm 1outputs a
functionùëî whichis completelydetermined by(i.e., is afunction of)the tuple(ùëç,Óàø). Thisgives
thefollowingMarkovchain:
ùëì ‚àíÓàø ‚àí(ùëç,Óàø)‚àíùëî. (10)
However, Eq.(6) states thatÓàø equals thespecific valueÃÇ ‚Ñé‚â•ùúè with probability 1‚àínegl(ùë†), regardless
ofthespecificchoiceofùëì,andthereforethedependenceonùëì isnegligible.
Moreformally,letÓà≥andÓà≥ideal denotethedistributionoftherandomvariableùëî whenAlgorithm1
Óà∞
isexecutedwithoracleaccesstofunctionùëì and‚Ñé,respectively. Foranysetùê¥,Eq.(10)implies
| |
‚Ñô ùëî‚àºÓà≥[ùëî ‚àà ùê¥| |Óàø =ÃÇ ‚Ñé‚â•ùúè
]
= ‚Ñô
ùëî‚àºÓà≥i
Óà∞deal[ùëî ‚àà ùê¥| |Óàø =ÃÇ ‚Ñé‚â•ùúè
]
= ùëù ùê¥.
So
| |
TV(Óà≥,Óà≥i Óà∞deal ) = sup| |‚Ñô ùëî‚àºÓà≥[ùëî ‚àà ùê¥]‚àí‚Ñô ùëî‚àºÓà≥i Óà∞deal[ùëî ‚àà ùê¥]|
|
ùê¥
|
| | |
= sup| |‚Ñô ùëî‚àºÓà≥[ùëî ‚àà ùê¥| |Óàø =ÃÇ ‚Ñé‚â•ùúè ]‚Ñô ùëî‚àºÓà≥[Óàø =ÃÇ ‚Ñé‚â•ùúè ]+‚Ñô ùëî‚àºÓà≥[ùëî ‚àà ùê¥| |Óàø ‚â†ÃÇ ‚Ñé‚â•ùúè ]‚Ñô ùëî‚àºÓà≥[Óàø ‚â†ÃÇ ‚Ñé‚â•ùúè
]
ùê¥ |
|
| | |
‚àí‚Ñô
ùëî‚àºÓà≥i
Óà∞deal[ùëî ‚àà ùê¥| |Óàø =ÃÇ ‚Ñé‚â•ùúè ]‚Ñô ùëî‚àºÓà≥[Óàø =ÃÇ ‚Ñé‚â•ùúè ]‚àí‚Ñô
ùëî‚àºÓà≥i
Óà∞deal[ùëî ‚àà ùê¥| |Óàø ‚â†ÃÇ ‚Ñé‚â•ùúè ]‚Ñô ùëî‚àºÓà≥[Óàø ‚â†ÃÇ ‚Ñé‚â•ùúè ]|
|
|
| |
= sup|ùëù ‚ãÖ(1‚àínegl(ùë†))+negl(ùë†)‚àíùëù ‚ãÖ(1‚àínegl(ùë†))‚àínegl(ùë†)| ‚â§ negl(ùë†),
| ùê¥ ùê¥ |
ùê¥
asdesired.
7 Local Mitigation
Inthissectionwe showmitigationresultsforpotentially-backdooredfunctions‚Ñùùëõ ‚Üí ‚Ñù,which
relyontwomainassumptions:
1. Thepotentially-backdooredmodelhaslowùìÅ populationloss.
2
2. The population distribution is ‚Äúnice‚Äù in the sense that the marginal over the domain ‚Ñùùëõ is
uniform on the ùëõ-dimensional unit ball, and the labels are close to a linear or polynomial
function‚Ñùùëõ ‚Üí ‚Ñù. (However,thelabelsneednotbedeterministic.)
7.1 Local Mitigation Preliminaries
Below,wedescribethenotionsweneedregardingconvexityandprobabilitymeasuresinEuclidean
space.
Convex sets and degeneracy. For ùëõ ‚àà ‚Ñï, a set ùê∂ ‚äÜ ‚Ñùùëõ is convex if for all ùë•,ùë¶ ‚àà ùê∂, the line
segment between ùë• and ùë¶ is fully contained within ùê∂, i.e., for all ùõº ‚àà [0,1], ùõºùë• + (1 ‚àíùõº)ùë¶ ‚àà ùê∂.
Throughout, we will work with nondegenerate convex sets ùê∂, in the sense that the standard
Lebesgue measure of ùê∂ is non-zero. (In other words, ùê∂ is ‚Äúfull-dimensional‚Äù.) Furthermore, we
28work with bounded convex sets ùê∂, in the sense that ùê∂ is contained in some sufficiently large
Euclideanball.
Foraboundedconvexsetùê∂,weusethefactthatforallùë• ‚â† ùë¶ ‚àà ùê∂,thereexistsauniquepointùëù on
theboundary ofùê∂ suchthattheraystarting atùë• thatgoesthroughùë¶ intersectsùëù. More formally,
letting
ùõº‚àó = sup{ùõº ‚àà ‚Ñù ‚à∂ ùë• +ùõº(ùë¶ ‚àíùë•) ‚àà ùê∂},
‚â•0
wehave
ùëù = ùë• +ùõº‚àó ‚ãÖ(ùë¶ ‚àíùë•).
Notethatùõº‚àóexistsandisfinitesinceùê∂isboundedandùë• ‚â† ùë¶. Moreover,weassumethatalgorithms
canefficientlycomputesuchapointùëù givenùë• andùë¶.
Probability, measures, and forms. We work with the standard Lebesgue measure, unless
explicitlystatedotherwise. Forameasurable(infact,convex)setùê∂ ‚äÜ ‚Ñùùëõ,theuniformdistribution
overùê∂ iswithrespecttotheLebesguemeasure. Thatis,theprobabilitydensityfunctionisgiven
bythestandardLebesguemeasure,normalizedbythevolumeofùê∂. Wesometimesusethevariable
namesùúÇ(‚ãÖ)andùúá(‚ãÖ)torefertodifferentialformscorrespondingtoprobabilitymeasuresin‚Ñùùëõ. Note
thatùúÇ(‚ãÖ)andùúá(‚ãÖ)includethedifferentialterms(e.g.,‚Äúùëëùë•‚Äù).
7.2 Basic Mitigation for Linear Functions
Theorem7.1. Letùõø ‚â• 0andùúÄ ‚àà [0,1/ 100]. Forevery indexùëõ ‚àà ‚Ñï,letùêµ
ùëõ
= ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ betheunit
ball;letÓâÑ ‚äÜ ùêµ bea(nondegenerate)convexset;letÓà¥ bethesetofaffinefunctions‚Ñùùëõ ‚Üí ‚Ñù;andlet
ùëõ ùëõ ùëõ
ùîª ùëõ = ùîª ùëõ,ùúÄ,ùõø/20ùëõ be the collection of distributions Óà∞ with uniform marginal Óà∞ ÓâÑ ùëõ = U(ÓâÑùëõ) such that
ùêø>ùõø/20ùëõ(Óà¥ ) ‚â§ ùúÄ. Letùîª = {ùîª } . ThenAlgorithm2definesalocalmitigatorùëÄ thatis
Óà∞ ùëõ ùëõ ùëõ‚àà‚Ñï
(ùúÄ, ùõø/(20ùëõ) ‚Üí ùõø)
cutofflosssecure(Definition4.6)fordistributionsùîª,whereùë† ‚àà ‚Ñïisthesecurityparameter.
In particular, there exists ùúá ‚àà negl such that for every index ùëõ ‚àà ‚Ñï and every distribution Óà∞ ‚àà ùîª
ùëõ
there exists a function ùëîideal ‚à∂ ÓâÑ ‚Üí ‚Ñù such that for any arbitrary (possibly malicious) function
Óà∞ ùëõ
ùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùwithlossùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ,andforeveryùë† ‚àà ‚Ñï,themitigatorùëÄ satisfies:
ùëõ Óà∞
1. Accuracy. ‚Ñô [|ùë¶‚àó ‚àíùë¶| > ùõø] ‚â§ ùúÄ +ùúá(ùë†),and
(ùë•,ùë¶)‚àºÓà∞,ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†)
2. CutoffLossSecurity. ‚àÄùë•‚àó ‚àà ÓâÑ
ùëõ
‚à∂ ‚Ñô ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•‚àó,1ùëõ,1ùë†)[| |ùë¶‚àó ‚àíùëî Óà∞ideal(ùë•‚àó)|
|
> ùõø] ‚â§ ùúá(ùë†).
Furthermore, Algorithm 2 uses a total of ùëÇ(ùë†) oracle queries to ùëì, does not use random samples
from Óà∞, and runs in time ùëÇ(ùë†ùëõ), assuming unit runtime cost for each arithmetic operation on the
representations of real numbers involved in the computation. However, ùëÄ is not guaranteed to be
unbiased.
In particular, the number of samples and queries required in Theorem 7.1 is independent of ùëõ.
The runtime is optimal in the sense that merely performing ùëö = Œò(ùë†) queries to ùëì on points
ùë• ,‚Ä¶,ùë• ‚àà ÓâÑ ‚äÜ ‚Ñùùëõ requiresaruntimeofŒ©(ùë†ùëõ).
1 ùëö ùëõ
29Assumptions:
‚Ä¢ ùëõ ‚àà ‚Ñï;ùõø ‚â• 0;ùúÄ ‚àà [0,1/ 100].
‚Ä¢ ÓâÑ ‚äÜ ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ;ÓâÑ isconvexandnondegenerate.
‚Ä¢ Óà∞ ‚àà Œî(ÓâÑ √ó‚Ñù)withÓà∞ = U(ÓâÑ).
ÓâÑ
‚Ä¢ Óà¥ istheclassofaffinelinearfunctions‚Ñùùëõ ‚Üí ‚Ñù.
‚Ä¢ ‚àÉ‚Ñé ‚àà Óà¥ ‚à∂ ùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ.
Óà∞
‚Ä¢ Thealgorithmhasoracleaccesstoanarbitraryfunctionùëì ‚à∂ ÓâÑ ‚Üí ‚Ñù(notnecessarily
inÓà¥)suchthatùêø>ùõø/20ùëõ(ùëì) ‚â§ ùúÄ.
Óà∞
‚Ä¢ ùë† ‚àà ‚Ñïisasecurityparameter;ùëö = 320ùë†.
‚Ä¢ ùë•‚àó ‚àà ÓâÑ isarbitrary.
BasicLocalLinearMitigator(ùëõ,ùëö,ùë•‚àó):
Óàµ ‚Üêemptyset
for ùëñ ‚àà [ùëö]:
sampleùë• ‚àº U(ÓâÑ)
ùëñ
ùë•‚Ä≤ ‚Üê ResamplingProcedure(ùë•‚àó,ùë•,ùëõ) ‚ä≥SeeAlgorithm3
ùëñ ùëñ
‚Äñùë• ‚àíùë•‚àó‚Äñ
ùëñ 2
ùúÜ ‚Üê
ùëñ ‚Äñùë• ‚àíùë•‚àó‚Äñ ‚àí ‚Äñùë•‚Ä≤ ‚àíùë•‚àó‚Äñ
ùëñ 2 ùëñ 2
if |ùúÜ| ‚â§ 4ùëõ:
ùëñ
ùë¶ ‚Üê ùëì(ùë•); ùë¶ÃÉ‚Ä≤ ‚Üê ùëì(ùë•‚Ä≤)
ùëñ ùëñ ùëñ ùëñ
ùëî ‚Üê (1‚àíùúÜ)ùë¶ +ùúÜùë¶ÃÉ‚Ä≤
ùëñ ùëñ ùëñ ùëñ ùëñ
Óàµ ‚Üê Óàµ ‚à™{ùëñ}
ùëî ‚Üêmedianof{ùëî}
ùëñ ùëñ‚ààÓàµ
outputùëî
Algorithm2: Abasiclocalindependentmitigatorforlinearfunctions‚Ñùùëõ ‚Üí ‚Ñù.
7.2.1 CorrelatedSamplingLemma
Lemma 7.2(CorrelatedSampling). Letùëõ ‚àà ‚Ñï, letÓâÑ ‚äÜ ‚Ñùùëõ be anybounded (nondegenerate)convex
set,andletùëà = U(ÓâÑ)betheuniformdistributiononÓâÑ. Letùë•‚àó ‚àà ÓâÑ. Considerthefollowingprocedure
forgeneratingapointùë•‚Ä≤ ‚àà ÓâÑ:
1. Sampleùë• ‚àº ùëà.
2. Letùë•‚Ä≤ ‚ÜêResamplingProcedure(ùë•‚àó,ùë•,ùëõ)usingAlgorithm3.
Thenùë•‚àó,ùë• andùë•‚Ä≤ areonastraightline,andfurthermore,therandomvariablesùë• andùë•‚Ä≤ areequalin
distribution.
30Assumptions:
‚Ä¢ ùëõ ‚àà ‚Ñï;ÓâÑ ‚äÜ ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ;ÓâÑ convex.
‚Ä¢ ùë•‚àó ‚àà ÓâÑ isarbitrary.
‚Ä¢ ùë• wassampleduniformlyfromÓâÑ.
ResamplingProcedure(ùë•‚àó,ùë•,ùëõ):
LetùìÅbethelinesegmentfromùë•‚àó toapointontheboundaryofÓâÑ suchthat
ùìÅpassesthroughùë•,andletùë° ‚àà (0,2]bethelengthofùìÅ.
Sampleùëü‚Ä≤ ‚àà [0,ùë°]accordingtodensityfunctionùëû(ùëü) = ùëõùëüùëõ‚àí1.
ùë°ùëõ
Letùë•‚Ä≤ bethepointonùìÅatdistanceùëü‚Ä≤ fromùë•‚àó.
outputùë•‚Ä≤
Algorithm3: Analgorithmforsampling twopointswith uniformmarginalsonthe unitsphere,
suchthatthepointsareonastraightlinewithanarbitraryinputùë•‚àó.
Proof. ItisclearfromconstructionofResamplingProcedurethatùë•‚àó,ùë•,andùë•‚Ä≤ alllieonthesame
straightline,soitsufficestoarguethatthedistributionsofùë• andùë•‚Ä≤ areidenticallydistributed.
Considerasphericalcoordinatesystemcenteredatùë•‚àó (insteadoftheorigin),wheretheùìÅ distance
2
from ùë•‚àó is denoted by ùëü. (Alternatively, this can be described by the usual centered spherical
coordinatesystem,wherewetranslatethewholespaceby‚àíùë•‚àó.) LetÓà≠denotethesetÓâÑ writtenin
thesesphericalcoordinates. Sinceùëà istheuniformdistributionoverÓâÑ,wecanwritethedensity
ofùëà asavolumeelementinsphericalcoordinatesas
ùëëùëâ(Œ∏,ùëü) = 1[(Œ∏,ùëü) ‚àà Óà≠]‚ãÖùúÇ(Œ∏)‚ãÖùëüùëõ‚àí1ùëëùëü, (11)
whereùëëùëâ isproportionaltothestandardvolumeformandùúÇ = ùúÇ(Œ∏)isproportionaltothestandard
volumeformonthe(ùëõ‚àí1)-dimensionalsphere,whereŒ∏ parameterizespointsonthesphereand
denotesdirectionsrelativetoitscenter(inourcase,ùë•‚àó). Moreconcretely,
ùëõ‚àí1
ùúÇ(Œ∏) ‚àù ùëëùúÉ ùëëùúÉ ‚ãØùëëùúÉ ‚ãÖ‚àèsinùëõ‚àíùëñ‚àí1(ùúÉ),
1 2 ùëõ‚àí1 ùëñ
ùëñ=1
wherecrucially,ùúÇdoesnotdependonùëü.
We now invoke Lemma 7.3, using the fact that the density ùëëùëâ splits into products of Œ∏ and ùëü
measures,asin(11). Letùë• bedecomposedintoŒ∏(ùë•)andùëü(ùë•),andsimilarlyforùë•‚Ä≤.
UsingthenotationofLemma7.3,let
ùúá (Œ∏) = ùúÇ(Œ∏), ùúá (ùëü) = ùëüùëõ‚àí1ùëëùëü,
Œò ùëÖ
and
Óà≠ = {ùëü ‚àà ‚Ñù ‚à∂ (ùëü,Œ∏) ‚àà Óà≠}.
|Œ∏ ‚â•0
31Wehave
1[ùëü ‚àà Óà≠ ]
|Œ∏
ùúáÃÇ (ùëü) = ‚ãÖùúá (ùëü).
ùëÖ|Œ∏ ‚à´ 1[ùëü‚Ä≤ ‚àà Óà≠ ]‚ãÖùúá (ùëü‚Ä≤) ùëÖ
ùëü‚Ä≤‚àà‚Ñù |Œ∏ ùëÖ
Using convexity and the notation of ResamplingProcedure, we know that for Œ∏ = Œ∏(ùë•), we
haveÓà≠ = [0,ùë°],whereùë° isthesameasinResamplingProcedure,namelythelengthoftheline
|Œ∏
segmentùìÅwithendpointsùë•‚àó andtheboundaryofÓâÑ,passingthroughùë•. Plugginginourmeasures,
weget
1[ùëü ‚àà [0,ùë°]]
ùúáÃÇ (ùëü) = ‚ãÖùëüùëõ‚àí1ùëëùëü
ùëÖ|Œ∏ ‚à´ 1[ùëü‚Ä≤ ‚àà [0,ùë°]]‚ãÖ(ùëü‚Ä≤)ùëõ‚àí1ùëëùëü‚Ä≤
ùëü‚Ä≤‚àà‚Ñù
ùëüùëõ‚àí1ùëëùëü
= 1[ùëü ‚àà [0,ùë°]]‚ãÖ
ùë°
‚à´ (ùëü‚Ä≤)ùëõ‚àí1ùëëùëü‚Ä≤
{ 0
ùëõùëüùëõ‚àí1ùëëùëü ifùëü ‚àà [0,ùë°],
= ùë°ùëõ
0 ifùëü ‚àâ [0,ùë°].
This exactly matches the density ùëû(‚ãÖ) in ResamplingProcedure. Therefore, by Lemma 7.3, the
joint distributions (Œ∏(ùë•),ùëü(ùë•)) and (Œ∏(ùë•),ùëü(ùë•‚Ä≤)) are identical. Since Œ∏(ùë•) = Œ∏(ùë•‚Ä≤), it follows that
thejointdistributions (Œ∏(ùë•),ùëü(ùë•))and(Œ∏(ùë•‚Ä≤),ùëü(ùë•‚Ä≤))areidentical, whichimpliesthatùë• andùë•‚Ä≤ are
identicallydistributed,asdesired.
Lemma7.3. LetÓâÑ andÓâÖ benice24 boundedsubsetsof‚Ñùùëõ and‚Ñù,respectively. Supposeùúá isajoint
probabilitymeasureonÓâÑ √óÓâÖ thatcanbewrittenas
ùúá(ùë•,ùë¶) = 1[(ùë•,ùë¶) ‚àà Óà≠]‚ãÖùúá (ùë•)‚ãÖùúá (ùë¶),
ÓâÑ ÓâÖ
forsome measuresùúá ÓâÑ onÓâÑ,ùúá ÓâÖ onÓâÖ,and somemeasurable setÓà≠ ‚äÜ ÓâÑ √óÓâÖ. Considerthefollowing
samplingprocedure:
1. Sample(ùë•,ùë¶ ) ‚àº ùúá. (Wewillnotuseùë¶ .)
0 0
2. LetÓà≠ ‚à∂= {ùë¶ ‚àà ÓâÖ ‚à∂ (ùë•,ùë¶) ‚àà Óà≠}. Fortheaboveùë• ‚àà ÓâÑ,considertheprobabilitymeasureonÓâÖ
|ùë•
givenby
1[ùë¶ ‚àà Óà≠ ]
|ùë•
ùúáÃÇ (ùë¶) ‚à∂= ‚ãÖùúá (ùë¶).
ÓâÖ|ùë• ‚à´ 1[ùë¶‚Ä≤ ‚àà Óà≠ ]‚ãÖùúá (ùë¶‚Ä≤) ÓâÖ
ùë¶‚Ä≤‚ààÓâÖ |ùë• ÓâÖ
Sampleùë¶
1
‚àº ùúáÃÇ
ÓâÖ|ùë•
andoutput(ùë•,ùë¶ 1).
Then,thedistributionof(ùë•,ùë¶ )isexactlyùúá.
1
Proof. Considertheprobabilitymeasures
ùúáÃÇ (ùë•) ‚à∂= 1[ùë¶ ‚àà Óà≠ ]‚ãÖùúá (ùë¶) ‚ãÖùúá (ùë•),
ÓâÑ (‚à´ |ùë• ÓâÖ ) ÓâÑ
ùë¶‚ààÓâÖ
24Formally,werequireÓâÑ andÓâÖ tobestandardBorelspacesequippedwithùúé-finitemeasures.Sincewewillonly
usethiswhenÓâÑ isthesphereandboundedÓâÖ ‚äÜ[0,‚àû),bothequippedwiththestandardLebesguemeasure,wedo
notelaborateonthemostgeneralrequirementsonÓâÑ andÓâÖ.
32‚®ò[ùë¶ ‚àà Óà≠ ]
ùúáÃÇ (ùë¶) ‚à∂= |ùë• ‚ãÖùúá (ùë¶), forfixedùë• ‚àà ÓâÑ.
ÓâÖ|ùë• ‚à´ ‚®ò[ùë¶‚Ä≤ ‚àà Óà≠ ]‚ãÖùúá (ùë¶‚Ä≤) ÓâÖ
ùë¶‚Ä≤‚ààÓâÖ |ùë• ÓâÖ
Noticethatforall(ùë•,ùë¶) ‚àà ÓâÑ √óÓâÖ,wehavetheequality
ùúáÃÇ (ùë•)‚ãÖùúáÃÇ (ùë¶) = 1[(ùë•,ùë¶) ‚àà Óà≠]‚ãÖùúá (ùë•)‚ãÖùúá (ùë¶) = ùúá(ùë•,ùë¶).
ÓâÑ ÓâÖ|ùë• ÓâÑ ÓâÖ
Notethatbytheassumptionthatùúá isaprobabilitymeasure(i.e.,integratesto1),onecanimmedi-
atelyobserveviaFubini‚ÄôstheoremthatùúáÃÇ andùúáÃÇ areprobabilitymeasuresforanyùë• ‚àà ÓâÑ (i.e.,
ÓâÑ ÓâÖ|ùë•
bothintegrateto1).
Considersomemeasurable subsetùëÜ ‚äÜ Óà≠. TheprobabilityofeventùëÜ underprobabilitymeasure ùúá
isgivenby
ùúá(ùë•,ùë¶) = 1[(ùë•,ùë¶) ‚àà ùëÜ]‚ãÖùúá(ùë•,ùë¶)
‚à´ ‚à´
(ùë•,ùë¶)‚ààùëÜ (ùë•,ùë¶)‚ààÓâÑ√óÓâÖ
= 1[(ùë•,ùë¶) ‚àà ùëÜ]‚ãÖùúáÃÇ (ùë•)‚ãÖùúáÃÇ (ùë¶). (12)
‚à´ ÓâÑ ÓâÖ|ùë•
(ùë•,ùë¶)‚ààÓâÑ√óÓâÖ
On theother hand,consider the samplingprocess definedin thestatement. The marginaldensity
measureonÓâÑ isgivenatapointùë• ‚àà ÓâÑ by
ùúá(ùë•,ùë¶) = 1[(ùë•,ùë¶) ‚àà Óà≠]‚ãÖùúá (ùë•)‚ãÖùúá (ùë¶)
‚à´ ‚à´ ÓâÑ ÓâÖ
ùë¶‚ààÓâÖ ùë¶‚ààÓâÖ
= 1[ùë¶ ‚àà Óà≠ ]‚ãÖùúá (ùë¶) ‚ãÖùúá (ùë•)
(‚à´ |ùë• ÓâÖ ) ÓâÑ
ùë¶‚ààÓâÖ
= ùúáÃÇ (ùë•).
ÓâÑ
By construction of our sampling process, we know that for fixed ùë• ‚àà ÓâÑ, we sample ùë¶ ‚àº ùúáÃÇ .
1 ÓâÖ|ùë•
Therefore,theprobabilityofeventùëÜ underoursamplingprocessisgivenby
ùúáÃÇ (ùë•)‚ãÖùúáÃÇ (ùë¶) = 1[(ùë•,ùë¶) ‚àà ùëÜ]‚ãÖùúáÃÇ (ùë•)‚ãÖùúáÃÇ (ùë¶),
‚à´ ÓâÑ ÓâÖ|ùë• ‚à´ ÓâÑ ÓâÖ|ùë•
(ùë•,ùë¶)‚ààùëÜ (ùë•,ùë¶)‚ààÓâÑ√óÓâÖ
whichexactlymatchesourexpressioninEq.(12),asdesired.
Claim7.4. InthenotationofLemma7.2,let
ùëü = ‚Äñùë• ‚àíùë•‚àó‚Äñ , ùëü‚Ä≤ = ‚Äñùë•‚Ä≤ ‚àíùë•‚àó‚Äñ ,
2 2
and
ùëü ùëü‚Ä≤
ùúÜ = , ùúÜ‚Ä≤ = .
ùëü ‚àíùëü‚Ä≤ ùëü‚Ä≤ ‚àíùëü
Then
{ } 1
‚Ñô[max |ùúÜ|,|ùúÜ‚Ä≤| ‚â§ 4ùëõ] ‚â• .
8
33Proof. ByLemma7.2andthedetailsofAlgorithm3,ùëü andùëü‚Ä≤ areeachsampledindependentlyfrom
theinterval(0,ùë°]accordingtothedensityfunctionùëû(ùëü) = ùëõùëüùëõ‚àí1,whereùë° isthelengthoftheline
ùë°ùëõ
ùìÅ that contains ùë•‚àó, ùë• and ùë•‚Ä≤. In particular, for any ùëù ‚àà [0,1], take ùúå = ùúå(ùëù) ‚àà [0,ùë°] such that the
followingholds.
ùúå ùëõ ùëüùëõ ùúå ùúå ùëõ
ùëù = ùëû(ùëü)ùëëùëü = = ‚üπ ùúå(ùëù) = ùëù1/ùëõ ‚ãÖùë°.
‚à´ ùë°ùëõ [ùëõ] ( ùë° )
0 0
Inparticular,ùúå(1/ 4) = (1/ 4)1/ùëõ ‚ãÖùë° andùúå(3/ 4) = (3/ 4)1/ùëõ ‚ãÖùë°. Thisimpliesthat
1/ùëõ 1/ùëõ 2
| | 3 1 1 1
‚Ñô |ùëü ‚àíùëü‚Ä≤| ‚â• ùë° ‚àí ‚â• 2 = .
[| | ((4) (4) )] (4) 8
Hence,withprobabilityatleast1/8,
{ } max{|ùëü|,|ùëü‚Ä≤|} ùë° 41/ùëõ 41/ùëõ
max
| ùúÜ| ,| ùúÜ‚Ä≤|
= ‚â§ = =
| | | |
|ùëü ‚àíùëü‚Ä≤| ùë° ((3 4)1/ùëõ ‚àí( 41 )1/ùëõ
)
31/ùëõ ‚àí1 ùëíln(3)/ùëõ ‚àí1
41/ùëõ 41/ùëõ
= ‚â§ ‚â§ 4ùëõ,
1+ ln(3) +‚àë‚àû (ln(3)/ùëõ)ùëò ‚àí1 (ln(3) )
( ùëõ ùëò=2 ùëò! ) ùëõ
asdesired.
7.2.2 ProofofTheorem7.1
Thefollowing claimsaysthat inAlgorithm 2,for mostùëñ ‚àà Óàµ, thefunctions‚Ñéandùëì, andthelabels
fromthedistributionÓà∞,areallclosetoeachotherforthepointsùë• andùë•‚Ä≤.
ùëñ ùëñ
Claim7.5. LetùúÄ,ùõø ‚â• 0. Letùëõ,ÓâÑ,ùë•,ùë•‚Ä≤ beasinLemma7.2. LetÓà∞ ‚àà Œî(ÓâÑ √ó‚Ñù)beadistributionwith
Óà∞ ÓâÑ = U(ÓâÑ), and let ‚Ñé,ùëì ‚à∂ ÓâÑ ‚Üí ‚Ñù such that ùêø> Óà∞ùõø(‚Ñé) ‚â§ ùúÄ and ùêø> Óà∞ùõø(ùëì) ‚â§ ùúÄ. Let ùë¶,ùë¶‚Ä≤ ‚àà ‚Ñù be random
variablessuchthat(ùë•,ùë¶),(ùë•‚Ä≤,ùë¶‚Ä≤) ‚àº Óà∞. LetùúÜ,ùúÜ‚Ä≤ beasinClaim7.4andlet
Œî = ‚Ñé(ùë•)‚àíùë¶; Œî‚Ä≤ = ‚Ñé(ùë•‚Ä≤)‚àíùë¶‚Ä≤
ùë¶ ùë¶
Œî = ‚Ñé(ùë•)‚àíùëì(ùë•); Œî‚Ä≤ = ‚Ñé(ùë•‚Ä≤)‚àíùëì(ùë•‚Ä≤).
ùëì ùëì
{ } { }
Letùê∏ betheevent | ùúÜ| ‚â§ 4ùëõ or max{|ùúÜ|,|ùúÜ‚Ä≤|} ‚â§ 4ùëõ . Then
| |
{ } { }
|
‚Ñô max |Œî |,|Œî‚Ä≤| > ùõø ‚à® max |Œî |,|Œî‚Ä≤| > 2ùõø |ùê∏ ‚â§ 32ùúÄ.
[ ùë¶ ùë¶ ùëì ùëì | ]
Proof. Seeingasùêø>ùõø(‚Ñé) ‚â§ ùúÄ andùêø>ùõø(ùëì) ‚â§ ùúÄ,aunionboundyields
Óà∞ Óà∞
‚Ñô[|‚Ñé(ùë•)‚àíùë¶| ‚â§ ùõø ‚àß |‚Ñé(ùë•‚Ä≤)‚àíùë¶‚Ä≤| ‚â§ ùõø ‚àß |ùëì(ùë•)‚àíùë¶| ‚â§ ùõø ‚àß |ùëì(ùë•‚Ä≤)‚àíùë¶‚Ä≤| ‚â§ ùõø] ‚â• 1‚àí4ùúÄ.
Bythetriangleinequality,
{ } { }
‚Ñô[max |Œî ùë¶|,|Œî‚Ä≤ ùë¶| > ùõø ‚àß max |Œî ùëì|,|Œî‚Ä≤ ùëì| > 2ùõø] ‚â• 1‚àí4ùúÄ. (13)
34ByClaim7.4,
1
‚Ñô[ùê∏] ‚â• . (14)
8
ByEqs.(13)and(14),
{ } { }
|
‚Ñô max |Œî |,|Œî‚Ä≤| > ùõø ‚à® max |Œî |,|Œî‚Ä≤| > 2ùõø |ùê∏
[ ùë¶ ùë¶ ùëì ùëì | ]
{ } { }
‚Ñô[max |Œî ùë¶|,|Œî‚Ä≤ ùë¶| > ùõø ‚à® max |Œî ùëì|,|Œî‚Ä≤ ùëì| > 2ùõø]
‚â§ ‚â§ 32ùúÄ,
‚Ñô[ùê∏]
asdesired.
ProofofTheorem7.1. The ùëÇ(ùë†) bound on the sample and query complexity is immediate from
the construction of Algorithm 2. The ùëÇ(ùë†ùëõ) bound on the runtime is also immediate under the
assumptionthatarithmeticoperations incurunitcost,wherewerecall thatcomputingamedian
ofa listoflengthùëöcanbe doneintimeùëÇ(ùëö)(Blumet al.,1973). Itremainsto showcorrectness
ofAlgorithm2.
Fixanaffinelinearfunction‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùsuchthatùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ. Letùëîideal = ‚Ñé,andletùë¶ideal = ‚Ñé(ùë•‚àó).
Óà∞ Óà∞
For each ùëñ ‚àà [ùëö], let ùìÅ ‚äÜ ‚Ñùùëõ be a line segment from ùë•‚àó to the unit sphere that passes through ùë•
ùëñ ùëñ
and ùë•‚Ä≤ (such a line exists by Lemma 7.2). For any point ùë• ‚àà ùìÅ, let ùëü(ùë•) = ‚Äñùë• ‚àíùë•‚àó‚Äñ . Let ùõº,ùõΩ ‚àà ‚Ñù
ùëñ ùëñ 2 ùëñ ùëñ
suchthat
‚Ñé(ùëü) = ùõºùëü +ùõΩ
ùëñ ùëñ ùëñ
isthe1-dimensionalrestrictionof‚ÑétoùìÅ,namely,‚Ñé(ùëü(ùë•)) = ‚Ñé(ùë•)forallùë• ‚àà ùìÅ. NotethatùõΩ = ùë¶ideal.
ùëñ ùëñ ùëñ ùëñ
ByLemma7.2,eachùë•‚Ä≤ ‚àº U(ÓâÑ). Hence,wemaydefinerandomvariablesùë¶ ,ùë¶‚Ä≤,‚Ä¶,ùë¶ ,ùë¶‚Ä≤ ‚àà ‚Ñùsuch
ùëñ 1 1 ùëö ùëö
thatforeachùëñ ‚àà [ùëö],(ùë•,ùë¶) ‚àº Óà∞and(ùë•‚Ä≤,ùë¶‚Ä≤) ‚àº Óà∞.
ùëñ ùëñ ùëñ ùëñ
Fixùëñ ‚àà [ùëö]. LetŒî = ‚Ñé(ùë•)‚àíùë¶ andŒî‚Ä≤ = ‚Ñé(ùë•‚Ä≤)‚àíùëì(ùë•‚Ä≤). Hence,
ùë¶,ùëñ ùëñ ùëñ ùëì,ùëñ ùëñ ùëñ
ùëî = (1‚àíùúÜ)ùë¶ +ùúÜùëì(ùë•‚Ä≤)
ùëñ ùëñ ùëñ ùëñ ùëñ
= (1‚àíùúÜ)(‚Ñé(ùë•)‚àíŒî )+ùúÜ(‚Ñé(ùë•‚Ä≤)‚àíŒî‚Ä≤ )
ùëñ ùëñ ùë¶,ùëñ ùëñ ùëñ ùëì,ùëñ
= ((1‚àíùúÜ ùëñ)‚Ñé(ùë• ùëñ)+ùúÜ ùëñ‚Ñé(ùë• ùëñ‚Ä≤))‚àí((1‚àíùúÜ ùëñ)Œî ùë¶,ùëñ +ùúÜ ùëñŒî‚Ä≤ ùëì,ùëñ) (15)
Considereachtermseparately.
(1‚àíùúÜ)‚Ñé(ùë•)+ùúÜ‚Ñé(ùë•‚Ä≤) = (1‚àíùúÜ)‚Ñé(ùëü)+ùúÜ‚Ñé(ùëü‚Ä≤) (Letùëü = ùëü(ùë•),ùëü‚Ä≤ = ùëü(ùë•‚Ä≤))
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
= (1‚àíùúÜ ùëñ)(ùõº ùëñùëü ùëñ +ùõΩ ùëñ)+ùúÜ ùëñ(ùõº ùëñùëü ùëñ‚Ä≤ +ùõΩ ùëñ)
= ùõΩ ùëñ +ùõº ùëñ((1‚àíùúÜ ùëñ)ùëü ùëñ +ùúÜ ùëñùëü ùëñ‚Ä≤ )
ùëü ùëü
= ùõΩ +ùõº 1‚àí ùëñ ùëü + ùëñ ‚ãÖùëü‚Ä≤
ùëñ ùëñ(( ùëü ‚àíùëü‚Ä≤) ùëñ ùëü ‚àíùëü‚Ä≤ ùëñ)
ùëñ ùëñ ùëñ ùëñ
= ùõΩ = ùë¶ideal, (16)
ùëñ
and,
| | | |
|(1‚àíùúÜ)Œî +ùúÜŒî‚Ä≤ | ‚â§ |1‚àíùúÜ|‚ãÖ|Œî |+|ùúÜ|‚ãÖ|Œî‚Ä≤ |
| ùëñ ùë¶,ùëñ ùëñ ùëì,ùëñ| | ùëñ| ùë¶,ùëñ ùëñ ùëì,ùëñ
35‚â§ (2|ùúÜ|+1)‚ãÖmax{|Œî |,|Œî‚Ä≤ |}
ùëñ ùë¶,ùëñ ùëì,ùëñ
‚â§ 9ùëõ‚ãÖmax{|Œî |,|Œî‚Ä≤ |}, (17)
ùë¶,ùëñ ùëì,ùëñ
wherethefinalinequalityholdswhen|ùúÜ| ‚â§ 4ùëõ. Seeingasùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ andùêø>ùõø/20ùëõ(ùëì) ‚â§ ùúÄ,Claim7.5
ùëñ Óà∞ Óà∞
impliesthat
|
|
‚Ñô [max{|Œî ùë¶,ùëñ|,|Œî‚Ä≤ ùëì,ùëñ|} > ùõø/ 10ùëõ |
|
|ùúÜ ùëñ| ‚â§ 4ùëõ
]
‚â§ 32ùúÄ. (18)
|
ByClaim7.4,
1
‚Ñô[|ùúÜ| ‚â§ 4ùëõ] ‚â• . (19)
ùëñ
8
CombiningEqs. (15)to(19),we concludethatwithprobability atleast1/8,|ùúÜ| ‚â§ 4ùëõ,and further-
ùëñ
more,
|
| 2
‚Ñô | ùëî ‚àíùë¶ideal| ‚â§ 0.9ùõø | |ùúÜ| ‚â§ 4ùëõ ‚â• 1‚àí32ùúÄ ‚â• . (20)
[| ùëñ | | ùëñ ] 3
|
Additionally,byEq.(19)andHoeffding‚Äôsinequality,forùëö ‚â• 320ùë†,withprobabilityatleast1‚àí2ùëí‚àíùë†,
thereareatleast20ùë† samples(ùë•,ùë•‚Ä≤)suchthat|ùúÜ| ‚â§ 4ùëõ,namely|Óàµ| ‚â• 20ùë†. Moreover,byEq.(20)
ùëñ ùëñ ùëñ
andHoeffding‚Äôsinequality,if|Óàµ| ‚â• 20ùë† thenwithprobabilityatleast1‚àí2ùëí‚àíùë†,atleasthalfofthe
valuesin{ùëî} satisfy|ùëî ‚àíùë¶ideal| ‚â§ 0.9ùõø,andthisimpliesthatthemedianùëî of{ùëî} alsosatisfies
ùëñ ùëñ‚ààÓàµ ùëñ ùëñ ùëñ‚ààÓàµ
|ùëî ‚àíùë¶ideal| ‚â§ 0.9ùõø. Byaunionbound,
‚Ñô[|ùëî ‚àíùë¶ideal| ‚â• 0.9ùõø] ‚â§ 4ùëí‚àíùë†,
Thisholdsforanyùë•‚àó ‚àà ÓâÑ,namely,
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ‚Ñô[|ùëî ‚àíùëîideal(ùë•‚àó)| ‚â• 0.9ùõø] ‚â§ 4ùëí‚àíùë†. (21)
Óà∞
ThisestablishesItem2inDefinition4.6.
Furthermore, seeing as ùëîideal = ‚Ñé such that ùêø>ùõø/20ùëõ(‚Ñé) ‚â§ ùúÄ, it follows from Eq. (21), the triangle
Óà∞ Óà∞
inequality|ùëî ‚àíùë¶| ‚â§ |ùëî ‚àí‚Ñé(ùë•)|+|‚Ñé(ùë•)‚àíùë¶|andaunionboundthat
| |
‚Ñô (ùë•,ùë¶)‚àºÓà∞[| |ùëî ‚àíùë¶|
|
‚â• ùõø
]
‚â§ ùúÄ +4ùëí‚àíùë†.
ThisestablishesItem1inDefinition4.6,asdesired.
7.3 Improved Mitigation for Linear Functions
Definition7.6(DistributionswithBenignNoise). Letùëõ ‚àà ‚Ñï,letùúé ‚â• 0,letÓâÑ ‚äÜ ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ bea
nondegenerateconvexsetcontainedintheunitball,andletùëà = U(ÓâÑ)betheuniformdistributionon
ÓâÑ. Let ÓàΩ ‚àà SubG(ùúé2 ) be a real-valued distribution that is symmetric about 0. Let Óà¥ be a class of
functions‚Ñùùëõ ‚Üí ‚Ñù. Foreach‚Ñé ‚àà Óà¥,letÓà∞
‚Ñé,ÓâÑ,ÓàΩ
beadistributionoverpairs(ùë•,ùë¶) ‚àà ÓâÑ √ó‚Ñùgeneratedin
thefollowingmanner:
361. Sampleùë• ‚àº ùëà,
2. SampleùúÇ ‚àº ÓàΩ,
3. Setùë¶ = ‚Ñé(ùë•)+ùúÇ.
ThecollectionofdistributionswithlabelsfromÓà¥ andbenignnoiseÓàΩisùîª
Óà¥,ÓâÑ,ÓàΩ
= {Óà∞
‚Ñé,ÓâÑ,ÓàΩ
‚à∂ ‚Ñé ‚àà Óà¥}.
Assumptions:
‚Ä¢ ùëõ,ÓâÑ,Óà¥ andùîª asinDefinition7.6.
linear linear,ÓâÑ,ÓàΩ
‚Ä¢ ùõø ‚â• 0;ùúÄ ‚àà [0,1/ 10].
‚Ä¢ ThealgorithmhasrandomsampleaccesstoÓà∞ ‚àà ùîª .
linear,ÓâÑ,ÓàΩ
‚Ä¢ ‚àÉ‚Ñé ‚àà Óà¥ ‚à∂ ùêø>ùõø/ùëõ(‚Ñé) ‚â§ ùúÄ.
linear Óà∞
‚Ä¢ Thealgorithmhasoracleaccesstoanarbitraryfunctionùëì ‚àà ‚ÑùÓâÑ (notnecessarilyin
Óà¥ )suchthatùêø>ùõø/ùëõ(ùëì) ‚â§ ùúÄ.
linear Óà∞
‚Ä¢ ùë† ‚àà ‚Ñïisasecurityparameter.
‚Ä¢ ùë•‚àó ‚àà ÓâÑ isarbitrary.
ImprovedLocalLinearMitigator(ùë•‚àó,ùëõ,ùë†):
sample(ùë• ,ùë¶ ),‚Ä¶,(ùë• ,ùë¶ ) ‚àº Óà∞ùë†
1 1 ùë† ùë†
Óàµ ‚Üêemptyset
for ùëñ ‚àà [ùë†]:
ùë•‚Ä≤ ‚ÜêResamplingProcedure(ùë•‚àó,ùë•,ùëõ) ‚ä≥SeeAlgorithm3
ùëñ ùëñ
ùëü ‚Üê ‚Äñùë• ‚àíùë•‚àó‚Äñ ; ùëü‚Ä≤ ‚Üê ‚Äñùë•‚Ä≤ ‚àíùë•‚àó‚Äñ
ùëñ ùëñ 2 ùëñ ùëñ 2
ùëü ùëü‚Ä≤
ùúÜ ‚Üê ùëñ ; ùúÜ‚Ä≤ ‚Üê ùëñ
ùëñ ùëü ‚àíùëü‚Ä≤ ùëñ ùëü‚Ä≤ ‚àíùëü
ùëñ ùëñ ùëñ ùëñ
if |ùúÜ| ‚â§ 4ùëõ ‚àß |ùúÜ‚Ä≤| ‚â§ 4ùëõ:
ùëñ ùëñ
Óàµ ‚Üê Óàµ ‚à™{ùëñ}
ùëè ‚Üê (ùëì(ùë•)‚àíùë¶)‚ãÖùúÜ‚Ä≤
ùëñ ùëñ ùëñ ùëñ
ùëî ‚Üê (1‚àíùúÜ)ùë¶ +ùúÜùëì(ùë•‚Ä≤)
ùëñ ùëñ ùëñ ùëñ ùëñ
{ }
ùëñ ,ùëñ ,‚Ä¶,ùëñ ‚Üê Óàµ; ùëò ‚Üê ‚åä|Óàµ|/2‚åã
1 2 |Óàµ|
{ }
ùëî ‚Üê MeanOfMedians ( ùëî ùëñ2ùë° ‚àíùëè ùëñ2ùë°‚àí1 ‚à∂ ùë° ‚àà [ùëò] ) ‚ä≥SeeAlgorithm6
outputùëî
Algorithm4: Anunbiasedcutofflosssecurelocalmitigatorforlinearfunctions‚Ñùùëõ ‚Üí ‚Ñù,witha
trade-offbetweenprecisionandsamplecomplexity.
37Theorem 7.7. Let ùúÄ ‚àà [0,1/ 10] and ùõø ‚â• 0. For every index ùëõ ‚àà ‚Ñï, let ùêµ
ùëõ
= ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ be the unit
ball;letÓâÑ ‚äÜ ùêµ bea(nondegenerate)convexset;letÓà¥ bethesetofaffinelinearfunctions‚Ñùùëõ ‚Üí ‚Ñù;
ùëõ ùëõ ùëõ
letùúé
ùëõ
‚â§ (ùõø/ùëõ)‚ãÖ(2ln(2/ùúÄ))‚àí1/2;letÓàΩ
ùëõ
‚àà SubG(ùúé ùëõ2 )beareal-valuedsubgaussiandistributionthatis
symmetricabout0;letùîª ùëõ = ùîª Óà¥ ùëõ,ÓâÑ ùëõ,ÓàΩ ùëõ bethesetofdistributions withaffinelinearlabelsandbenign
noise,asinDefinition7.6;andletùîª = {ùîª } .25
ùëõ ùëõ‚àà‚Ñï
ThenAlgorithm4definesalocalmitigatorùëÄ thatisan
1 1 ln(ùë†)
ùúÄ, ‚ãÖùõø ‚ü∂ + ‚ãÖùõø (22)
( ùëõ (ùëõ ùë†1/4 ) )
unbiasedcutofflosssecuremitigatorfordistributionsùîª(satisfyingItems1,2and3inDefinition4.6),
whereùë† ‚àà ‚Ñïisthesecurityparameter.
‚àö
Inparticular,ifùë† = ln(ùëõ) ùëõandùëõislargeenough,themitigatoris
1 1
ùúÄ, ‚ãÖùõø ‚ü∂ ‚ãÖùõø (23)
( ùëõ ùëõ1/10 )
unbiasedandcutofflosssecure. Algorithm4usesùë† samplesand2ùë† oraclequeries,andrunsintime
ùëÇ(ùë†ùëõ),assumingunitruntimecostforeacharithmeticoperationontherepresentationsofrealnumbers
involvedinthecomputation.
7.3.1 ProofofTheorem7.7
ProofofTheorem7.7. Fixùëõ ‚àà ‚Ñï,Óà∞ ‚àà ùîª ùëõ,andlet‚Ñé ‚àà Óà¥ ùëõ suchthatÓà∞ = Óà∞ ‚Ñé,ÓâÑ ùëõ,ÓàΩ ùëõ asinDefinition7.6.
By Claim C.2 and the choice of ùúé , ùêø>ùõø/ùëõ(‚Ñé) ‚â§ ùúÄ. Let ùëì ‚à∂ ÓâÑ ‚Üí ‚Ñù such that ùêø>ùõø/ùëõ(ùëì) ‚â§ ùúÄ. Fix
ùëõ Óà∞ ùëõ Óà∞
ùëñ ‚àà Óàµ. LetŒî = ùëì(ùë•)‚àí‚Ñé(ùë•)andŒî‚Ä≤ = ùëì(ùë•‚Ä≤)‚àí‚Ñé(ùë•‚Ä≤). LetùìÅ bethelinefromùë•‚àó totheunitsphere
ùëì,ùëñ ùëñ ùëñ ùëì,ùëñ ùëñ ùëñ ùëñ
that contains ùë• and ùë•‚Ä≤. Let ùëü(ùë•) = ‚Äñùë• ‚àíùë•‚àó‚Äñ , and let ùõº,ùõΩ ‚àà ‚Ñù such that ‚Ñé(ùëü) = ùõº ‚ãÖùëü +ùõΩ is the
ùëñ ùëñ 2 ùëñ ùëñ ùëñ ùëñ ùëñ
1-dimensional restriction of ‚Ñé to ùìÅ, namely, ‚Ñé(ùëü(ùë•)) = ‚Ñé(ùë•) for all ùë• ‚àà ùìÅ. Note that ùõΩ = ‚Ñé(ùë•‚àó),
ùëñ ùëñ ùëñ ùëñ
andùë¶
ùëñ
= ‚Ñé(ùë• ùëñ)+ùúÇ ùëñ,whereùúÇ
ùëñ
‚àº ÓàΩ
ùëõ
‚àà SubG(ùúé ùëõ2 )withùîº[ùúÇ ùëñ] = 0. Similarly,wecandefinearandom
variableùë¶‚Ä≤ = ‚Ñé(ùë•‚Ä≤)+ùúÇ‚Ä≤ whereùúÇ‚Ä≤ ‚àº ÓàΩ isindependent.
ùëñ ùëñ ùëñ ùëñ ùëõ
Considertherandomvariableùëî.
ùëñ
ùëî = (1‚àíùúÜ)ùë¶ +ùúÜùëì(ùë•‚Ä≤)
ùëñ ùëñ ùëñ ùëñ ùëñ
= (1‚àíùúÜ)(‚Ñé(ùëü)+ùúÇ)+ùúÜ(‚Ñé(ùëü‚Ä≤)+Œî‚Ä≤ )
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëì,ùëñ
= (1‚àíùúÜ)‚Ñé(ùëü)+ùúÜ ‚ãÖ‚Ñé(ùëü‚Ä≤)+(1‚àíùúÜ)ùúÇ +ùúÜ ‚ãÖŒî‚Ä≤ .
‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èûùëñ ‚èû‚èû‚èû‚èû‚èû‚èû‚èûùëñ ‚èû‚èû‚èû‚èû‚èûùëñ ‚èû‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èûùëñ ‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èûùëñ ‚èû‚èû‚èû‚èû‚èû‚èûùëñ‚èû‚èû‚èü ‚èü‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èû‚èü‚èû‚èû‚èûùëñ ‚èû‚èû‚èû‚èû‚èû‚èüùëñ ‚èü‚èû‚èûùëñ ‚èû‚èû‚èû‚èü‚èû‚èû‚èûùëì ‚èû‚èû‚èü,ùëñ
‚Ñé(ùë•‚àó) NoiseI (‚ãÜ)
Examineeachtermseparately. Thefirsttermequals‚Ñé(ùë•‚àó)foranyùë•,ùë•‚Ä≤ ‚àà ùìÅ,asfollows.
ùëñ ùëñ ùëñ
(1‚àíùúÜ)‚Ñé(ùëü)+ùúÜ ‚ãÖ‚Ñé(ùëü‚Ä≤) = (1‚àíùúÜ)(ùõº ‚ãÖùëü +ùõΩ)+ùúÜ ‚ãÖ(ùõº ‚ãÖùëü‚Ä≤ +ùõΩ)
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
= ùõΩ +(1‚àíùúÜ)(ùõº ‚ãÖùëü)+ùúÜ ‚ãÖùõº ‚ãÖùëü‚Ä≤
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
25Inparticular,byClaimC.2andthechoiceofùúé ùëõ,‚Ñô
ùëû‚àºÓàΩ
ùëõ[|ùëû|‚â•ùõø/ùëõ]‚â§ùúÄ.SoforeveryÓà∞‚ààùîª ùëõthereexistsanaffine
function‚Ñé‚ààÓà¥ suchthatùêø>ùõø/ùëõ(‚Ñé)‚â§ùúÄ.
ùëõ Óà∞
38ùëü ùëü
= ùõΩ + 1‚àí ùëñ (ùõº ‚ãÖùëü)+ ùëñ ‚ãÖ(ùõº ‚ãÖùëü‚Ä≤)
ùëñ ( ùëü ‚àíùëü‚Ä≤) ùëñ ùëñ ùëü ‚àíùëü‚Ä≤ ùëñ ùëñ
ùëñ ùëñ ùëñ ùëñ
= ùõΩ = ‚Ñé(ùë•‚àó).
ùëñ
Theterm(‚ãÜ)canbedecomposedintoabiastermandanoiseterm,asfollows.
(‚ãÜ) = ùúÜ ‚ãÖŒî‚Ä≤
ùëñ ùëì,ùëñ
= ùúÜ
ùëñ
‚ãÖ(ùëì(ùë• ùëñ‚Ä≤)‚àí‚Ñé(ùë•‚Ä≤))
= ùúÜ ùëñ ‚ãÖ(ùëì(ùë• ùëñ‚Ä≤)‚àíùë¶ ùëñ‚Ä≤ +ùúÇ‚Ä≤ ùëñ)
= ùúÜ ‚èü‚èû‚èûùëñ ‚èû‚èû‚èû‚ãÖ ‚èû‚èû( ‚èû‚èû‚èûùëì ‚èû‚èû‚èû‚èû( ‚èû‚èûùë• ‚èû‚èüùëñ‚Ä≤ ‚èû‚èû) ‚èû‚èû‚èû‚èû‚àí ‚èû‚èû‚èû‚èû‚èûùë¶ ‚èû‚èû‚èûùëñ ‚èû‚Ä≤ ‚èû) ‚èû‚èü+ ‚èüùúÜ ‚èû‚èûùëñ ‚èû‚èü‚ãÖ ‚èûùúÇ ‚èû‚èû‚èü‚Ä≤ ùëñ .
Bias NoiseII
Insum,wehavethefollowingcentralidentity
ùëî = ‚Ñé(ùë•‚àó)+ùëè‚Ä≤ +ùëÅ, (24)
ùëñ ùëñ ùëñ
whereùëè‚Ä≤ = ùúÜ ‚ãÖ(ùëì(ùë•‚Ä≤)‚àíùë¶‚Ä≤)isabiasterm,andùëÅ = (1‚àíùúÜ)‚ãÖùúÇ +ùúÜ ‚ãÖùúÇ‚Ä≤ isanoiseterm. Weanalyze
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
thebiastermandthenoisetermseparately.
For the noise term ùëÅ in Eq. (24), seeing as ùúÇ is symmetric about 0 and ùúÇ ‚ä•ùúÜ, it follows that
ùëñ ùëñ ùëñ ùëñ
ùëÅ0 = (1‚àíùúÜ)‚ãÖùúÇ isalsosymmetricabout0. AsimilarargumentholdsforùëÅ1 = ùúÜ ‚ãÖùúÇ‚Ä≤,andtherefore
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
thenoisetermùëÅ = ùëÅ0 +ùëÅ1 isdistributedsymmetricallyabout0.
ùëñ ùëñ ùëñ
Furthermore,1‚àíùúÜ = ùúÜ‚Ä≤,andmax{|ùúÜ|,|ùúÜ‚Ä≤|} ‚â§ 4ùëõforùëñ ‚àà Óàµ. Hence,byClaimC.4,ùëÅ0 andùëÅ1 satisfy
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
ùëÅ ùëñ0,ùëÅ ùëñ1 ‚àà SubG(16ùëõ2ùúé ùëõ2 ). ByClaimC.3,ùëÅ
ùëñ
= ùëÅ ùëñ0 +ùëÅ ùëñ1 ‚àà SubG(ùúâ2 )where
ùõø2
ùúâ2 = 22 ‚ãÖ16ùëõ2ùúé2 ‚â§ 64‚ãÖ ‚â§ 64ùõø2.
ùëõ 2log(2/ùúÄ)
ByClaimC.2,thisimpliesthat
(20ùõø)2 1
‚Ñô[|ùëÅ| ‚â• 20ùõø] ‚â§ 2exp ‚àí ‚â§ . (25)
ùëñ ( 2ùúâ2 ) 10
Next, for the bias term ùëè‚Ä≤ in Eq. (24), note that Algorithm 4 uses quantities of the form ùëî ‚àíùëè ,
ùëñ ùëñ ùëó
wheresubtractingùëè isintendedto‚Äúcancelout‚Äùtheùëè‚Ä≤ terminùëî. Considertheexpressionùëè‚Ä≤ ‚àíùëè .
ùëó ùëñ ùëñ ùëñ ùëó
Foranyfixedùëó ‚â† ùëñ,Lemma7.2andtheboundùêø>ùõø/ùëõ(ùëì) ‚â§ ùúÄ implythat
Óà∞
{ } ùõø |
‚Ñô max | ùëì(ùë•‚Ä≤)‚àíùë¶‚Ä≤| ,| ùëì(ùë• )‚àíùë¶ | > |ùëñ,ùëó ‚àà Óàµ ‚â§ 2ùúÄ.
[ | ùëñ ùëñ| | ùëó ùëó| ùëõ | ]
So
|
‚Ñô | ùëè‚Ä≤ ‚àíùëè | > 4ùõø |ùëñ,ùëó ‚àà Óàµ ‚â§ 2ùúÄ. (26)
[| ùëñ ùëó| | ]
Furthermore,byLemma7.2,(ùë•‚Ä≤,ùë¶‚Ä≤) =ùëë (ùë• ,ùë¶ ),so
ùëñ ùëñ ùëó ùëó
ùëü‚Ä≤ ùëü
ùëè = (ùëì(ùë• )‚àíùë¶ )‚ãÖ ùëó =ùëë (ùëì(ùë•‚Ä≤)‚àíùë¶‚Ä≤)‚ãÖ ùëñ = ùëè‚Ä≤
ùëó ùëó ùëó ùëü‚Ä≤ ‚àíùëü ùëñ ùëñ ùëü ‚àíùëü‚Ä≤ ùëñ
ùëó ùëó ùëñ ùëñ
39Becauseùëè ‚ä•ùëè‚Ä≤,thisimpliesthatùëè‚Ä≤ ‚àíùëè isdistributedsymmetricallyabout0.26
ùëó ùëñ ùëñ ùëó
LetÓàº bethedistributionofùëî ‚àíùëè fordistinctùëñ,ùëó ‚àà Óàµ,andletÓàº betheconditionaldistribution
ùëî‚àíùëè ùëñ ùëó good
of
|
ùëß ‚àº Óàº ùëî‚àíùëè| |(ùëß ‚àà [‚Ñé(ùë•‚àó)‚àí24ùõø,‚Ñé(ùë•‚àó)+24ùõø]).
Putting the facts that ùëÅ and ùëè‚Ä≤ ‚àíùëè are symmetric about 0 together with Eqs. (24) to (26) gives
ùëñ ùëñ ùëó
thatÓàº canbewrittenasamixture
ùëî‚àíùëè
Óàº = (1‚àíùõº)‚ãÖÓàº +ùõº ‚ãÖÓàº ,
ùëî‚àíùëè good bad
suchthat
‚Ä¢ ùõº ‚â§ 1/ 10+2ùúÄ ‚â§ 1/ 3,
‚Ä¢ Óàº isdistributedsymmetricallyabout‚Ñé(ùë•‚àó),and
ùëî‚àíùëè
‚Ä¢ ‚Ñô [|ùëß ‚àí‚Ñé(ùë•‚àó)| ‚â§ 24ùõø] = 1.
ùëß‚àºÓàº
good
ByTheorem8.1,theestimateùëî returnedbyAlgorithm4satisfies:
1. ùëî isunbiased,i.e.,ùîº[ùëî] = ‚Ñé(ùë•‚àó). SoAlgorithm4isunbiased,satisfyingItem3inDefinition4.6.
2. ùëî isconcentrated,namely,
| | ‚àö
‚àÄùúÇ ‚â• 0 ‚à∂ ‚Ñô Óàø‚àºÓà∞ùë†[| |ùëî ‚àí‚Ñé(ùë•‚àó)|
|
‚â• ùúÇ
]
‚â§ 4exp(‚àíùõæ ùë†),
{ }
whereùõæ = 1 ‚ãÖmin 1 , 2ùúÇ2 . SoforùúÇ = ùõøln(ùë†)/ùë†1/4 asinthestatement,
4 100 (24ùõø)2 ùë†
| | ln(ùë†)2 ‚àö ln(ùë†)2
‚Ñô Óàø‚àºÓà∞ùë†[| |ùëî ‚àí‚Ñé(ùë•‚àó)|
|
‚â• ùúÇ
ùë†]
‚â§ 4exp (‚àí
2‚ãÖ(24)2 ‚ãÖùë†1/2
‚ãÖ ùë†
)
‚â§ 4exp (‚àí
2‚ãÖ(24)2)
‚àà negl(ùë†).27
(27)
This shows that Algorithm 4 satisfies cutoff loss security (Item 2 in Definition 4.6) with
parameterùõø = ùúÇ ,whichisbetterthanrequiredinEq.(22). Additionally,combiningEq.(27)
1 ùë†
withùêø>ùõø/ùëõ(‚Ñé) ‚â§ ùúÄ gives
Óà∞
| | ùõø | | ùõø | |
‚Ñô |ùë¶‚àó ‚àíùë¶| ‚â• +ùúÇ ‚â§ ‚Ñô |ùë¶ ‚àí‚Ñé(ùë•)| ‚â• ‚à® |‚Ñé(ùë•)‚àíùë¶‚àó| ‚â• ùúÇ ‚â§ ùúÄ +negl(ùë†).
(ùë•,ùë¶)‚àºÓà∞ [| | ùëõ ùë†] (ùë•,ùë¶)‚àºÓà∞[| | ùëõ | | ùë†]
ùë¶‚àó‚ÜêùëÄùëì,Óà∞(ùë•,1ùëõ,1ùë†)
26Hereweusetheassumptionùëè ‚ä•ùëè‚Ä≤, whichholdsbecausethesamplesforiterationùëñareindependentofthe
ùëó ùëñ
samplesforiterationùëó.ItmightbetemptingtoconsiderasimpleralgorithmthatdoesnotpartitionÓàµintotwodisjoint
setsofsizeùëò,andinsteadsimplyusesestimatesoftheformùëî ‚àíùëè forallùëñ‚ààÓàµ.Thisleadstotermsoftheformùëè‚Ä≤‚àíùëè,
ùëñ ùëñ ùëñ ùëñ
whereùëè‚Ä≤andùëè areidenticallydistributedbutarenotindependent.Toseewhythatmightnotbegoodenough,recall
ùëñ ùëñ
thatforajointdistribution(ùëã,ùëå)withùëã =ùëë ùëå,thevariables(ùëã,ùëå)mightnotbeexchangeable,andinparticularùëã‚àíùëå
mightnotbesymmetric. Forexample,consideradistributionof(ùëã,ùëå)thatisuniformover{(‚àí1,0),(0,1),(1,‚àí1)}.
Thenùëã ‚àíùëå isnotsymmetric. Tosummarize,byusingùëî ‚àíùëè withùëñ ‚â† ùëó,wegetasymmetricdistributionwhile
ùëñ ùëó
avoidingquestionsofexchangeability.
27Eq.(27)isforthecaseùõæ <1/400.Forthecaseùõæ =1/400,theupperboundisclearlynegligibleinùë†.
40SoAlgorithm4satisfiestheaccuracyrequirement(Item1inDefinition4.6)withparameters
‚àö
ùõø/ùëõ ‚Üí ùõø ‚ãÖ(1/ùëõ+ln(ùë†)/ùë†1/4)asinEq.(22). Inparticular,forùë† = ln(ùëõ) ùëõ,
‚àö
ùõø 1 ln(ùë†) 1 ln(ln(ùëõ) ùëõ)
+ùúÇ = ùõø ‚ãÖ + = ùõø ‚ãÖ +
ùëõ ùë† (ùëõ ùë†1/4 ) (ùëõ (ln(ùëõ)‚àö ùëõ)1/4)
1 ln(ùëõ) 1
‚â§ ùõø ‚ãÖ + ‚â§ ùõø ‚ãÖ ,
(ùëõ ùëõ1/8 ) ùëõ1/10
where the last inequality holds for ùëõ large enough. Hence, Algorithm 4 also satisfies the
accuracyrequirementwithparametersùõø/ùëõ ‚Üí ùõø/ùëõ1/10 asinEq.(23).
Thus, Algorithm 4 satisfies Items 1, 2 and 3 in Definition 4.6 with the parameters in Eqs. (22)
and(23),asdesired.
7.4 Mitigation for Multivariate Polynomials
Definition7.8. Forùëë +1valuesùë£ ,‚ãØ,ùë£ ‚àà ‚Ñù,wedefinetheVandermondematrixVand(ùë£ ,‚ãØ,ùë£ )to
0 ùëë 0 ùëë
bethematrixùëâ ‚àà ‚Ñù(ùëë+1)√ó(ùëë+1) givenby
‚é°1 ùë£ ùë£2 ‚ãØ ùë£ùëë‚é§
‚é¢ 0 0 0‚é•
1 ùë£ ùë£2 ‚ãØ ùë£ùëë
ùëâ = ‚é¢ 1 1 1‚é• .
‚é¢‚ãÆ ‚ãÆ ‚ãÆ ‚ã± ‚ãÆ ‚é•
‚é¢ 1 ùë£ ùë£2 ‚ãØ ùë£ùëë‚é•
‚é£ ùëë ùëë ùëë‚é¶
Symbolically,forallùëñ,ùëó ‚àà {0,‚ãØ,ùëë},ùëâ = ùë£ùëó.
ùëñ,ùëó ùëñ
Werecallthedefinition oftheinfinitynorm ‚Äñ‚ãÖ‚Äñ onmatrices, inducedbytheinfinity norm‚Äñ‚ãÖ‚Äñ on
‚àû ‚àû
vectors.
Definition7.9. ForamatrixùëÄ ‚àà ‚ÑùùìÅ√óùìÅ,theinfinitynormofùëÄ,denoted‚ÄñùëÄ‚Äñ ,isdefinedby
‚àû
‚ÄñùëÄùë£‚Äñ
‚ÄñùëÄ‚Äñ = sup ‚àû,
‚àû ‚Äñùë£‚Äñ
ùë£‚àà‚Ñùùëõ‚ßµ{0} ‚àû
whereweusethestandardùìÅ normforvectorsùë¢ ‚àà ‚Ñùùëõ,formallygivenby
‚àû
‚Äñùë¢‚Äñ = max|ùë¢|.
‚àû ùëñ
ùëñ‚àà[ùëõ]
WenowreferenceanupperboundontheinfinitynormoftheinverseofVandermondematrices.
Theorem 7.10 (Theorem 1 of Gautschi, 1962). Let ùëâ = Vand(ùë£ ,‚ãØ,ùë£ ), where ùë£ ‚â† ùë£ for all
0 ùëë ùëñ ùëó
ùëñ ‚â† ùëó ‚àà {0,‚ãØ,ùëë}. Then,
1+|ùë£|
‚Äñ ùëâ‚àí1‚Äñ ‚â§ max ‚àè ùëñ .
‚Äñ ‚Äñ
‚àû 0‚â§ùëó‚â§ùëë 0‚â§ùëñ‚â§ùëë |ùë£ ùëñ ‚àíùë£ ùëó|
ùëñ‚â†ùëó
41x
‚àó x
0 x
1 ...
‚Ñì x
d
Figure4: Algorithm5usestheResamplingProcedureofLemma7.2tosampleùëë+1pointsonastraight
linewithùë•‚àó suchthateachpointhasauniformmarginal.
InAlgorithm5, wegivepseudocodetodescribethemitigation algorithmusedformultivariate
polynomials.
WenowprovethattheresampledpointsinAlgorithm5aresufficientlypairwisefar,sothatwe
caninvoketheboundgiveninTheorem7.10.
Claim7.11. InthenotationofAlgorithm5,foreachùëñ ‚àà [ùëö],
‚Ñô ‚àÄùëó ‚â† ùëó‚Ä≤ ‚àà {0,‚ãØ,ùëë}‚à∂
|
|ùëü(ùëó)
‚àíùëü(ùëó‚Ä≤)|
| ‚â•
1
‚â•
5
.
[ | ùëñ ùëñ | 40ùëõùëë2] 6
Proof. ByconstructionoftheResamplingProcedureasinAlgorithm3,weknowthedensityof
eachùë° ‚ãÖùëü(ùëó) issampledi.i.d. (overùëó ‚àà {0,‚ãØ,ùëë})fromthedensityfunctionùëû(ùëü) = ùëõùëüùëõ‚àí1,whereùë° is
ùëñ ùëñ ùë°ùëõ ùëñ
thelength ofthelinesegment fromùë•‚àó tothe boundary ofÓâÑ thatpasses throughùëñ ùë•. Bydividing
by ùë°, this density becomes ùëû‚Ä≤(ùëü) ‚à∂= ùë° ‚ãÖùëû(ùëü ‚ãÖùë°) = ùëõ‚ãÖùëüùëõ‚àí1, with support [0,1]. That is, each ùëü(ùëó) is
ùëñ ùëñ ùëñ ùëñ
sampledi.i.d. (overùëó ‚àà {0,‚ãØ,ùëë})fromùëû‚Ä≤.
We partition [0,1] into 20ùëë2 consecutive intervals ùêº ,‚ãØ,ùêº such that each interval has equal
1 20ùëë2
massunderùëû‚Ä≤ (i.e.,wesplitupùëû‚Ä≤ into20ùëë2 quantiles). Wearrangetheintervalssothat0 ‚àà ùêº and
1
1 ‚àà ùêº . Wenowgiveabirthday-styleargumentthatshowsthatwithprobabilityatleast5/6,it
20ùëë2
holdsthatallùëü(ùëó) (overùëó ‚àà {0,‚ãØùëë},soùëñisfixed)lieindistinctandnon-neighboringintervals. Let
ùëñ
ùëç betherandomvariabledenotingthenumberof(ùëó,ùëó‚Ä≤)pairsthatlieinthesameorneighboring
ùëñ
intervals. Bylinearityofexpectation,
ùîº[ùëç] = ‚àë ‚Ñô ùëü(ùëó),ùëü(ùëó‚Ä≤) areinthesameorneighboringintervals
ùëñ [ ùëñ ùëñ ]
ùëó‚â†ùëó‚Ä≤‚àà{0,‚ãØ,ùëë}
ùëë +1 3 1
‚â§ ‚ãÖ ‚â§ .
( 2 ) 20ùëë2 6
Sinceùëç isnon-negative,byMarkov‚Äôsinequality,‚Ñô[ùëç ‚â• 1] ‚â§ 1/6,so‚Ñô[ùëç = 0] ‚â• 5/6. Therefore,
ùëñ ùëñ ùëñ
with probability at least 5/6, we know that all ùëü(ùëó) (over ùëó ‚àà {0,‚ãØùëë}) lie in distinct and non-
ùëñ
neighboringintervals.
42Assumptions:
‚Ä¢ ùëõ,ùëë ‚àà ‚Ñï;ùúÄ ‚àà [0,1/ 20ùëë];ùõø
1
‚â• 0;ùõø
0
= ùõø1/ 4‚ãÖ(80ùëõùëë2)ùëë;ÓâÑ ‚äÜ ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ;ÓâÑ convex.
‚Ä¢ Óà∞ ‚àà Œî(ÓâÑ √ó‚Ñù)withÓà∞ = U(ÓâÑ).
ÓâÑ
‚Ä¢ Óà¥ istheclassofpolynomialfunctions‚Ñùùëõ ‚Üí ‚Ñùoftotaldegreeatmostùëë.
‚Ä¢ ‚àÉ‚Ñé ‚àà Óà¥ ‚à∂ ùêø>ùõø0(‚Ñé) ‚â§ ùúÄ.
Óà∞
‚Ä¢ Thealgorithmhasoracleaccesstoanarbitraryfunctionùëì ‚àà ‚ÑùÓâÑ (notnecessarilyin
Óà¥)suchthatùêø>ùõø0(ùëì) ‚â§ ùúÄ.
Óà∞
‚Ä¢ ùë† ‚àà ‚Ñïisasecurityparameter;ùëö = ùë†.
‚Ä¢ ùë•‚àó ‚àà ÓâÑ isarbitrary.
LocalPolynomialMitigator(ùëõ,ùëë,ùëö,ùë•‚àó):
Sampleùë• ,‚Ä¶,ùë• ‚Üê ùëà(ÓâÑ).
1 ùëö
Óà≥ ‚Üêemptyset
for ùëñ ‚àà [ùëö]:
(ùë• ùëñ(0),ùë¶ÃÇ ùëñ(0) ) ‚Üê (ùë• ùëñ,ùëì(ùë• ùëñ))
for ùëó ‚àà [ùëë]:
ùë•(ùëó) ‚Üê ResamplingProcedure(ùë•‚àó,ùë•,ùëõ) ‚ä≥SeeAlgorithm3
ùëñ ùëñ
ùë¶ÃÇ(ùëó) ‚Üê ùëì (ùë•(ùëó) )
ùëñ ùëñ
Letùë° bethelengthofthelinesegmentùìÅ fromùë•‚àó totheboundaryofÓâÑ that
ùëñ ùëñ
passesthroughùë•.
ùëñ
‚Äñùë•(ùëó) ‚àíùë•‚àó‚Äñ
ùëü(ùëó) ‚Üê ùëñ 2 ‚àà [0,1];
ùëñ ùë°
ùëñ
ùëÖ ùëñ ‚Üê Vand(ùëü ùëñ(0),‚ãØ,ùëü ùëñ(ùëë) ) ‚àà ‚Ñù(ùëë+1)√ó(ùëë+1)
ùë¶ÃÇ ùëñ ‚Üê (ùë¶ÃÇ ùëñ(0),‚ãØ,ùë¶ÃÇ ùëñ(ùëë) ) ‚àà ‚Ñùùëë+1
ùõºÃÇ ‚Üê ùëÖ‚àí1ùë¶ÃÇ ‚àà ‚Ñùùëë+1
ùëñ ùëñ ùëñ
Óà≥ ‚Üê Óà≥‚à™ùõºÃÇ(0),whereùõºÃÇ(0) ‚àà ‚ÑùisthefirstcoordinateofùõºÃÇ.
ùëñ ùëñ ùëñ
ùëî ‚ÜêmedianofÓà≥
outputùëî
Algorithm5: Abasiclocalindependentmitigatorforlowdegreepolynomials‚Ñùùëõ ‚Üí ‚Ñù.
43Giventhatùëç = 0,sinceallùëü(ùëó) areseparatedfromeachotherbyatleastonefullinterval,weknow
ùëñ ùëñ
that
min|
|ùëü(ùëó)
‚àíùëü(ùëó‚Ä≤)|
| ‚â• min |ùêº |,
ùëó‚â†ùëó‚Ä≤ | ùëñ ùëñ | ùëò‚àà[20ùëë2] ùëò
whereweusethe notation|ùêº | ‚àà ‚Ñùtodenotethelengthofthe intervalùêº . Bymonotonicityofùëû‚Ä≤,
ùëò ùëò
weknowthat
min |ùêº | = |ùêº |,
ùëò 20ùëë2
ùëò‚àà[20ùëë2]
wherethelengthùëß ‚à∂= |ùêº |isgivenbythesolutionùëß totheequation
20ùëë2
1 1
ùëõùëüùëõ‚àí1ùëëùëü = .
‚à´
20ùëë2
1‚àíùëß
Sinceùëõ,ùëë ‚â• 1,solvingthisequationyields
1/ùëõ
1 1 1
ùëß = 1‚àí 1‚àí ‚â•
1‚àíùëí‚àí1/(20ùëõùëë2)
‚â• 1‚àí 1‚àí = .
( 20ùëë2) ( 40ùëõùëë2) 40ùëõùëë2
Therefore,withprobabilityatleast5/6,wehave
min|
|ùëü(ùëó)
‚àíùëü(ùëó‚Ä≤)|
| ‚â•
1
,
ùëó‚â†ùëó‚Ä≤ | ùëñ ùëñ | 40ùëõùëë2
asdesired.
WefinallyprovethatthatAlgorithm5isalocalmitigatorfordegree-ùëë multivariatepolynomials.
Theorem 7.12. For any ùëõ,ùëë ‚àà ‚Ñï, let ùêµ = ùêµ(ùüé,1) ‚äÜ ‚Ñùùëõ be the unit ball, and let ÓâÑ ‚äÜ ùêµ be a
ùëõ ùëõ ùëõ
nondegenerateconvexset. LetÓà¥ bethesetofmultivariatepolynomials‚Ñùùëõ ‚Üí ‚Ñùoftotaldegreeat
ùëõ
mostùëë. LetùúÄ ‚àà [0,1/ 20ùëë],ùõø
1
‚àà ‚Ñù ‚â•0andùõø
0
= ùõø1/ 4‚ãÖ(80ùëõùëë2)ùëë. Letùîª
ùëõ
= ùîª
ùëõ,ùúÄ,ùõø0
bethecollectionofdistributions
Óà∞withuniform marginalonÓâÑ suchthatùêø>ùõø0(Óà¥ ) ‚â§ ùúÄ,i.e., thereexists amultivariatepolynomial
ùëõ Óà∞ ùëõ
‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùoftotaldegreeatmostùëë suchthat
‚Ñô [|‚Ñé(ùë•)‚àíùë¶| > ùõø ] ‚â§ ùúÄ.
0
(ùë•,ùë¶)‚àºÓà∞
Then Algorithm 5 is a local mitigator that is (ùúÄ,ùõø ‚Üí ùõø )-cutoff loss secure (per Definition 4.6) for
0 1
distributionsùîª ,whereùë† ‚àà ‚Ñïisthesecurityparameter.
ùëõ
Furthermore,Algorithm5usesatotalofùë†(ùëë+1)oraclequeries,andrunsintimeùë†‚ãÖpoly(ùëë,ùëõ),assuming
unitruntimecostforeacharithmeticoperationontherepresentationsofrealnumbersinvolvedinthe
computation.
Proof. Letùëà = U(ÓâÑ )betheuniformdistributiononÓâÑ . FixapopulationdistributionÓà∞ ‚àà ùîª
ùëõ ùëõ ùëõ,ùúÄ,ùõø0
andamultivariate polynomial‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùoftotaldegree atmostùëë suchthatùêø>ùõø0(‚Ñé) ‚â§ ùúÄ. We set
Óà∞
ùëîideal(ùë•) = ‚Ñé(ùë•). Fixtheadversariallychosenfunctionùëì ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñùwithlossùêø>ùõø0(ùëì) ‚â§ ùúÄ. Thatis,
Óà∞ Óà∞
‚Ñô [|‚Ñé(ùë•)‚àíùë¶| ‚â• ùõø ] ‚â§ ùúÄ, ‚Ñô [|ùëì(ùë•)‚àíùë¶| ‚â• ùõø ] ‚â§ ùúÄ. (28)
0 0
(ùë•,ùë¶)‚àºÓà∞ (ùë•,ùë¶)‚àºÓà∞
44ByapplyingthetriangleinequalityandtheunionboundandlookingatthemarginalonÓâÑ ,
ùëõ
‚Ñô [|ùëì(ùë•)‚àí‚Ñé(ùë•)| ‚â• 2ùõø ] ‚â§ 2ùúÄ. (29)
ùë•‚Üêùëà 0
Letùë¶ideal = ‚Ñé(ùë•‚àó). Foreachùëñ ‚àà [ùëö],considerthelineùìÅ ‚à∂ ‚Ñù ‚Üí ‚Ñùùëõ passingthroughùë•‚àó andùë•,scaled
ùëñ ùëñ
sothatùìÅ(0) = ùë•‚àó andùìÅ(1)isontheboundaryofÓâÑ . Let‚Ñé ‚à∂ ‚Ñù ‚Üí ‚Ñù,‚Ñé ‚à∂= ‚Ñé‚ó¶ùìÅ betheunivariate
ùëñ ùëñ ùëõ ùëñ ùëñ ùëñ
polynomialof‚ÑérestrictedtothelineùìÅ,whichhasdegreeatmostùëë. Letùõº = (ùõº(0),‚ãØ,ùõº(ùëë)) ‚àà ‚Ñùùëë+1
ùëñ ùëñ ùëñ ùëñ
bethecoefficientssuchthat
ùëë
‚Ñé(ùëü) = ‚àëùõº(ùëò)ùëüùëò.
ùëñ ùëñ
ùëò=0
Byconstruction,
ùõº(0) = ‚Ñé(0) = ‚Ñé(ùìÅ(0)) = ‚Ñé(ùë•‚àó) = ùë¶ideal.
ùëñ ùëñ ùëñ
Letùëü(0),‚ãØ,ùëü(ùëë) ‚àà ‚ÑùbeasinAlgorithm5. Notethatforallùëó ‚àà {0,‚ãØ,ùëë},
ùëñ ùëñ
ùìÅ ùëñ(ùëü ùëó(ùëó) ) = ùë• ùëñ(ùëó).
Letting ùëÖ ùëñ = Vand(ùëü ùëñ(0),‚ãØ,ùëü ùëñ(ùëë) ) ‚àà ‚Ñù(ùëë+1)√ó(ùëë+1) and ùë¶ ùëñ = (‚Ñé ùëñ(ùëü ùëñ(0) ),‚ãØ,‚Ñé ùëñ(ùëü ùëñ(ùëë) )) ‚àà ‚Ñùùëë+1, we have the
matrixequation
ùëÖùõº = ùë¶,
ùëñ ùëñ ùëñ
andtherefore
ùõº = ùëÖ‚àí1ùë¶.
ùëñ ùëñ ùëñ
(Note that since ùëÖ is a Vandermonde matrix, it is invertible as all of the ùëü(ùëó) are distinct, which
ùëñ ùëñ
willbetruewithprobability1.)
Usingthenotationinouralgorithm,sinceforallùëó ‚àà {0,‚ãØ,ùëë},wehaveùë¶(ùëó) = ‚Ñé(ùëü(ùëó)) = ‚Ñé(ùë•(ùëó))and
ùëñ ùëñ ùëñ ùëñ
ùë¶ÃÇ(ùëó) = ùëì(ùë•(ùëó)),weknowùë¶(ùëë) = ‚Ñé(ùëü(ùëó)) = ‚Ñé(ùë•(ùëó))andùë¶ÃÇ(ùëó) = ùëì(ùë•(ùëó)),sobyEq.(29),
ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ ùëñ
| |
‚Ñô |ùë¶ÃÇ(ùëó) ‚àíùë¶(ùëó)| ‚â• 2ùõø ‚â§ 2ùúÄ.
[| ùëñ ùëñ | 0]
Byapplyingtheunionboundoverùëó ‚àà {0,‚ãØ,ùëë},weget
| | 1
‚Ñô ‚àÉùëó ‚àà {0,‚ãØ,ùëë},|ùë¶ÃÇ(ùëó) ‚àíùë¶(ùëó)| ‚â• 2ùõø ‚â§ (2ùëë +2)ùúÄ ‚â§ 4ùëëùúÄ ‚â§ .
[ | ùëñ ùëñ | 0] 5
Therefore,withprobabilityatleast4/5,
‚Äñ ‚Äñ
ùë¶ÃÇ ‚àíùë¶ ‚â§ 2ùõø .
‚Äñ ùëñ ùëñ‚Äñ ‚àû 0
RecallthatùõºÃÇ = ùëÖ‚àí1ùë¶ÃÇ. Giventheabove,wehave
ùëñ ùëñ ùëñ
‚Äñ ùõºÃÇ ‚àíùõº‚Äñ = ‚Äñ ùëÖ‚àí1ùë¶ÃÇ ‚àíùëÖ‚àí1ùë¶‚Äñ = ‚Äñ ùëÖ‚àí1(ùë¶ÃÇ ‚àíùë¶)‚Äñ ‚â§ ‚Äñ ùëÖ‚àí1‚Äñ ‚Äñ ùë¶ÃÇ ‚àíùë¶‚Äñ ‚â§ ‚Äñ ùëÖ‚àí1‚Äñ 2ùõø .
‚Äñ ùëñ ùëñ‚Äñ ‚àû ‚Äñ ùëñ ùëñ ùëñ ùëñ‚Äñ ‚àû ‚Äñ ùëñ ùëñ ùëñ ‚Äñ ‚àû ‚Äñ ùëñ ‚Äñ ‚àû‚Äñ ùëñ ùëñ‚Äñ ‚àû ‚Äñ ùëñ ‚Äñ ‚àû 0
We now apply Theorem 7.10 along with Claim 7.11 (and the union bound) to see that with
probabilityatleast1‚àí1/5‚àí1/6 = 19/30,
| |
1+|ùëü(ùëó)|
‚Äñ ùëÖ‚àí1‚Äñ ‚â§ max ‚àè | ùëñ | ‚â§ ‚àè 2 = (80ùëõùëë2)ùëë.
‚Äñ ùëñ ‚Äñ ‚àû 0‚â§ùëó‚â§ùëë 0‚â§ùëó‚Ä≤‚â§ùëë | | |ùëü ùëñ(ùëó) ‚àíùëü ùëñ(ùëó‚Ä≤)| |
|
0‚â§ùëó‚Ä≤‚â§ùëë 40ùëõ1 ùëë2
ùëó‚Ä≤‚â†ùëó ùëó‚Ä≤‚â†ùëó
45Therefore,inthiscase,
ùõø
‚Äñ ùõºÃÇ ‚àíùõº‚Äñ ‚â§ (80ùëõùëë2)ùëë ‚ãÖ2ùõø = 1 ,
‚Äñ ùëñ ùëñ‚Äñ ‚àû 0 2
andinparticular,lookingatthefirstcoordinate,
| | | | ùõø
|ùõºÃÇ(0) ‚àíùë¶ideal| = |ùõºÃÇ(0) ‚àíùõº(0)| ‚â§ 1 .
| ùëñ | | ùëñ ùëñ | 2
This,foreachùëñ ‚àà [ùëö],withprobabilityatleast19/30,weaddanestimatetoÓà≥thatisùõø /2-closeto
1
ùë¶ideal = ‚Ñé(ùë•‚àó) = ùëîideal(ùë•‚àó). ByastandardChernoffbound,itfollowsthatùëî,themedianofÓà≥atthe
Óà∞
endofAlgorithm5,satisfies
‚Ñô[|ùëî ‚àíùëî Óà∞ideal(ùë•‚àó)| > ùõø 1/2] ‚â§ ùëí‚àíùëö‚ãÖ(1/ 2102) ‚â§ ùëí‚àíùëö/200 = 2‚àíŒ©(ùë†).
Thisholdsforanyùë•‚àó ‚àà ÓâÑ ,sowe(inparticular)have
ùëõ
3ùõø
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ‚Ñô |ùëî ‚àíùëîideal(ùë•‚àó)| ‚â• 1 ‚â§ 2‚àíŒ©(ùë†). (30)
ùëõ [ Óà∞ 4 ]
ThisestablishesItem2inDefinition4.6.
ToseeItem1inDefinition4.6,wecanusethetriangleinequality,theunionbound,Eq.(30),and
Eq.(28)(sinceùëîideal(ùë•‚àó) = ‚Ñé(ùë•))toseethat
Óà∞
3ùõø
‚Ñô |ùëî ‚àíùë¶| ‚â• ùõø + 1 ‚â§ ùúÄ +2‚àíŒ©(ùë†).
(ùë•,ùë¶)‚àºÓà∞ [ 0 4 ]
ùëî‚ÜêùëÄùëì(ùë•,1ùëõ,1ùë†)
Sinceùõø +3ùõø /4 ‚â§ ùõø ,thisestablishesItem1inDefinition4.6.
0 1 1
Remark7.13. WhiletheùëõùëÇ(ùëë) blowupintheùõø errormightseemundesirable,weshowthatthisis
unavoidableforarelatednotionofcorrectionintheexact setting,definedasfollows.
Letùîª bethecollectionofdistributionsÓà∞withuniformmarginalonÓâÑ suchthatùêø>ùõø0(Óà¥ ) = 0,
ùëõ,ùõø0 ùëõ Óà∞ ùëõ
i.e., there exists a multivariate polynomial ‚Ñé ‚à∂ ‚Ñùùëõ ‚Üí ‚Ñù of total degree at most ùëë such that
‚Ñô [|‚Ñé(ùë•)‚àíùë¶| > ùõø ] = 0. Insteadofcutofflosssecurity(Item2inDefinition4.6),supposewe
(ùë•,ùë¶)‚àºÓà∞ 0
wantthestrongerpropertythatforallùëì ‚à∂ ÓâÑ ‚Üí ‚Ñùsuchthatùêø>ùõø0(ùëì) ‚â§ ùúÄ,
ùëõ Óà∞
‚àÄùë•‚àó ‚àà ÓâÑ ‚à∂ ‚Ñô [|ùë¶‚àó ‚àí‚Ñé(ùë•‚àó)| ‚â• ùõø ] ‚â§ ùúá(ùë†), (31)
ùëõ 1
ùë¶‚àó‚ÜêùëÄùëì(ùë•‚àó,1ùëõ,1ùë†)
wherethemitigatorùëÄùëì(ùë•,1ùëõ,1ùë†)hasaccesstoùëì (butnotÓà∞).28
Weclaimtwofactsinthissetting:
28ThedifferencebetweentherequirementinEq.(31)andtherequirementofItem2inDefinition4.6isthatin
Eq.(31),ùë¶‚àómustbeclosetothetruelabelingfunction‚Ñé(whichisunknowntothedefender),whereasinDefinition4.6
ùë¶‚àómustbeclosetoacanonicalfunctionùëîidealchosenbythedefender.
Óà∞
46‚Ä¢ Algorithm 5 achieves the security requirement of Eq. (31). This follows directly from the
analysisgivenintheproofofTheorem7.12.
‚Ä¢ Themultiplicativeblowupofùõø = ùëõŒ©(ùëë)ùõø isunavoidable.
1 0
We now explain why the blowup is unavoidable, assuming that the mitigator only has oracle
accesstothepotentially-backdooredùëìÃÉ(butdoesnothaverandomsamplesfromthepopulation
distribution).29 Toseethis,letùëë ‚àà ‚Ñïbeeven,andconsiderthefollowingpolynomialsofdegreeat
mostùëë,
ùëë/2
ùëõ
‚Ñé (ùë• ,‚ãØ,ùë• ) ‚â° 0, and ‚Ñé (ùë• ,‚ãØ,ùë• ) = 1‚àí‚àëùë•2 ,
0 1 ùëõ 1 1 ùëõ ùëñ
( )
ùëñ=1
alongwiththeuniformdistributionùëà = U(ùêµ)overtheunitballin‚Ñùùëõ. Attheorigin,i.e.,ùë•‚àó = ùüé,we
have‚Ñé (ùë•‚àó) = ùëèforùëè ‚àà {0,1}. However,withhighprobabilityovertheunitball,thesepolynomials
ùëè
areveryclose:
‚àö
1 ùëõ 1 ùëõ 1 1/2
‚Ñô | ‚Ñé (ùë•)| ‚â• = ‚Ñô 1‚àí‚àëùë•2 ‚â• ‚àö = ‚Ñô ‚àëùë•2 ‚â§ 1‚àí ‚àö
ùë•‚àºùëà[| 1 | ùëõùëë/4] ùë•‚àºùëà[ ùëñ ùëõ] ùë•‚àºùëà[ ùëñ ( ùëõ) ]
ùëñ=1 ùëñ=1
ùëõ/2
1 ‚àö
= 1‚àí ‚àö ‚â§ ùëí‚àí ùëõ/2.
( ùëõ)
That is, there are two polynomials of degree at most ùëë that are additively 1/ùëõùëë/4-close with
‚àö
probabilityatleast1‚àíùëí‚àí ùëõ/2,yettheydifferadditivelyattheoriginby1. Therefore,wecanfix
ùëì = ‚Ñé ‚â° 0andexaminethedistributionofùëÄùëì(ùüé,1ùëõ,1ùë†). ConsideringÓà∞tobeexactlygivenby‚Ñé
0 ‚àö 0
or‚Ñé ,inbothcases,wehaveshownthatùêø>ùõø0(ùëì) ‚â§ ùëí‚àí ùëõ/2 forùõø = 1/ùëõùëë/4. However,tosatisfyour
1 Óà∞ 0
strongersecuritynotion,wewouldneed
‚Ñô[| |ùëÄùëì(ùüé,1ùëõ,1ùë†)‚àí‚Ñé ùëè(ùüé)| | ‚â• ùõø 1] ‚â§ ùúá(ùë†)
for both values ùëè ‚àà {0,1}. Since ‚Ñé (ùüé) = ùëè and ùúá is negligible, this is only possible if ùõø = Œ©(1).
ùëè 1
Therefore,ùõø = ùëõŒ©(ùëë) ‚ãÖùõø ,asdesired.
1 0
8 Robust Mean Estimation
We analyze a simple algorithm for robust mean estimation in the Huber contamination model
(Huber, 1964, 1981). Our algorithm (Algorithm 6) computes a mean-of-medians, which is the
reverse of the extensively-studied median-of-means estimator (Nemirovskij and Yudin, 1983;
Jerrumetal.,1986; Laforgueetal.,2021,among numerous others). Algorithm6usesan additional
symmetryassumptiononthedistribution,andobtainsaslowerconvergenceratethanthestandard
median-of-meansofestimator. TheadvantageofAlgorithm6,isthatithasbetterrobustnessto
arbitrarynoise,asillustratedinthefollowingsection.
Weremarkthat Algorithm 6 was recently studiedby Zhong, Huang, Yang, and Wang (2021) for
heavy-taileddistributions;however,theydidnotanalyzeitsrobustnesstoarbitrarynoise,aswe
29Aslightlymoreelaborateargumentcanshowthattheblowupisunavoidableevenifthemitigatordoeshave
randomsamplesfromthepopulationdistribution.
47do here.30 Additionally, we note that one could also use other more advanced techniques for
robustmeanestimation. Forexample,thealgorithmofNovikov,Steurer,andTiegel(2023)gives
better convergence performance. However, these more-advanced algorithms are considerably
morecomplex. Inthecontextofdesigningasecuritymechanismasinthispaper,thesimplicityof
Algorithm6canbeasignificantadvantage.
8.1 Why not use the standard Median-of-Means estimator?
The standard median-of-means estimator partitions a sample of size ùëö = ùëòùëè into ùëò batches of
sizeùëè each. Foreachbatchùëñ ‚àà [ùëò],it computestheempirical averageofthe samplesinthe batch.
Finally,itoutputsthemedianoftheseaverages. Namely,theestimatoris
1 1
ùúáÃÇ= median ‚àëùë•1,‚Ä¶, ‚àëùë•ùëò , (32)
(ùëè ùëó ùëè ùëó )
ùëó‚àà[ùëè] ùëó‚àà[ùëè]
wherebatchùëñisùë•ùëñ = (ùë•ùëñ,‚Ä¶,ùë•ùëñ).
1 ùëè
Toseewhyweoptnottousethisestimator,consideramixturedistribution
2 1
Óà∞ = ‚ãÖùëà + ‚ãÖÓàΩ,
3 3
where ùëà = U({‚àí1,1}) is the uniform distribution on {‚àí1,1}, and ÓàΩ is a distribution of arbitrary
noise,say‚Ñô [ùë• = ùëê] = 1forsomelargeùëê. Thelocationparameterweareinterestedinrecovering
ùë•‚àºÓàΩ
isùúá = ùîº[ùëà] = 0. WeshowthatùúáÃÇasinEq.(32)doesnotconvergetoùúá,specifically,
ùëö‚Üí‚àû
‚Ñô[|ùúáÃÇ‚àíùúá| ‚â• 1] ‚àí‚àí‚àí‚àí‚Üí 1.
Considertwocases.
‚Ä¢ CaseI:ùëè = 1. Inthiscase,ùúáÃÇisamedianofùëövalues,eachofwhichisin{‚àí1,1,ùëê}. Ifùëöisodd,
thenùúáÃÇ‚àà {‚àí1,1,ùëê},so‚Ñô[|ùúáÃÇ‚àíùúá| ‚â• 1] = 1. Otherwise,ifùëöiseven,andwedefinethemedianas
somevalueintherange[ùë• ùë°,ùë• ùë°+1]forùë° = ‚åäùë°/2‚åã,then‚Ñô[|ùúáÃÇ‚àíùúá| = 1] ‚â• ‚Ñô[ùë•
ùë°
= ùë•
ùë°+1
= 1] ‚àí‚àíùëö ‚àí‚Üí ‚àí‚Üí‚àû 1.
‚Ä¢ Case II: ùëè ‚â• 2. In this case, for each ùëñ ‚àà [ùëò], batch ùëñ contains at least one sample from
ÓàΩ with probability 1 ‚àí (2/3)ùëè > 1. Hence, as ‚Ñô[ùêµ] ‚àí‚àíùëö ‚àí‚Üí ‚àí‚Üí‚àû 1, where ùêµ is the event that a
2
strict majority of the batches each contain at least one item equal to ùëê. This implies that
‚Ñô[|ùúáÃÇ‚àíùúá| ‚â• ùëê‚àíùëè+1 ] ‚àí‚àíùëö ‚àí‚Üí ‚àí‚Üí‚àû 1forùëê arbitrarilylarge.
ùëè
We see that in both cases, the median-of-means does not converge to ùúá = 0. This limitation is
overcomebyAlgorithm6,asweshowinthenextsection.
8.2 The Mean-of-Medians estimator
Theorem8.1. LetÓàº,ÓàΩ ‚àà Œî(‚Ñù)bedistributions,letùõº ‚â• 0,andlet
Óà∞ = (1‚àíùõº)‚ãÖÓàº +ùõº ‚ãÖÓàΩ
beamixturedistribution. Assumethat:
30Themean-of-mediansalgorithmwasalsousedbyXueetal.(2023).
48Assumptions:
{ }
‚Ä¢ Óàø = ùë• ,‚Ä¶,ùë• ‚äÜ ‚Ñùisfinite.
1 |Óàø|
MeanOfMedians(Óàø):
‚àö
ùëè ‚Üê ‚åä |Óàø|‚åã ‚ä≥Thereareùëè batches,eachofsizeùëè
for ùëñ ‚àà [ùëè]:
{ }
ùëö ‚Üêmedianof ùë•ùëñ,ùë•ùëñ,‚Ä¶,ùë•ùëñ ,whereùë•ùëñ = ùë•
ùëñ 1 2 ùëè ùëó (ùëñ‚àí1)ùëè+ùëó
output 1 ‚àë ùëö
|ùëè| ùëñ‚àà[ùëè] ùëñ
Algorithm6: Asimplealgorithmforrobustmeanestimation.
(a) Óàº hasmeanùúá ‚àà ‚Ñù,andthereexistùêµ,ùõΩ ‚â• 0suchthat‚Ñô ùë•‚àºÓàº[|ùë• ‚àíùúá| > ùêµ] < ùõΩ.
(b) ùõº andùõΩ aresmall,suchthat(1‚àíùõº)(1‚àíùõΩ) ‚â• 2/3.
(c) Óà∞issymmetricaboutùúá,namely,foranymeasurablesetùê¥ ‚äÜ ‚Ñù,Óà∞(ùúá+ùê¥) = Óà∞(ùúá‚àíùê¥),where
ùúá¬±ùê¥ = {ùúá¬±ùëé ‚à∂ ùëé ‚àà ùê¥}.
Letùëö ‚àà ‚Ñï,letÓàø ‚àº Óà∞ùëö,andlet
ùúáÃÇ= MeanOfMedians(Óàø)
asinAlgorithm6. Then:
1. ùúáÃÇisunbiased,i.e.,ùîº Óàø‚àºÓà∞ùëö[ùúáÃÇ] = ùúá.
| | ‚àö { }
2. ùúáÃÇis concentrated, i.e., ‚àÄùúÄ ‚â• 0 ‚à∂ ‚Ñô Óàø‚àºÓà∞ùëö[| |ùúáÃÇ‚àíùúá|
|
‚â• ùúÄ
]
‚â§ 4exp(‚àíùõæ ùëö) for ùõæ = min 11 00, 2 ùêµùúÄ 22
andùëölargeenough.
Notethatinthetheoremstatement,ÓàΩmightnothaveamean.
8.2.1 ProofofTheorem8.1
ProofofTheorem8.1. First,weshowthatùúáÃÇisunbiased. Fixùëñ ‚àà [ùëè]. SeeingasÓà∞issymmetricabout
ùúá, for any measurable ùê¥ ‚äÜ ‚Ñù, Óà∞(ùê¥) = Óà∞(2ùúá ‚àíùê¥). Consequently, for every ùëó ‚àà [ùëè], ùë•ùëñ =ùëë 2ùúá ‚àíùë•ùëñ.
ùëó ùëó
Becausetheùë•ùëñ variablesareindependent,thisimpliesthat
ùëó
ùîº[ùëö ùëñ] = ùîº ùë•ùëñ ‚àºÓà∞ùëè[median(ùë• 1ùëñ,‚Ä¶,ùë• ùëèùëñ )]
1‚à∂ùëè
= ùîº ùë•ùëñ ‚àºÓà∞ùëè[median(2ùúá‚àíùë• 1ùëñ,‚Ä¶,2ùúá‚àíùë• ùëèùëñ )] (ùë• ùëóùëñ =ùëë 2ùúá‚àíùë• ùëóùëñ)
1‚à∂ùëè
= ùîº ùë•ùëñ ‚àºÓà∞ùëè[2ùúá‚àímedian(ùë• 1ùëñ,‚Ä¶,ùë• ùëèùëñ )]
1‚à∂ùëè
= 2ùúá‚àíùîº[ùëö]. (33)
ùëñ
Hence,
‚àÄùëñ ‚àà [ùëè] ‚à∂ ùîº[ùëö] = ùúá, (34)
ùëñ
49soùîº 1 ‚àë ùëö = ùúá,establishingItem1inthetheorem.
[|ùëè| ùëñ‚àà[ùëè] ùëñ]
Second,weshowthatùúáÃÇisconcentrated. WecanexpressthedistributionÓà∞asamixture
Óà∞ = (1‚àíùõº)(1‚àíùõΩ)‚ãÖÓàºgood +(1‚àíùõº)ùõΩ ‚ãÖÓàºbad +ùõº ‚ãÖÓàΩ, (35)
| |
whereÓàºgood = Óàº ||ùë• ‚àíùúá| ‚â§ ùêµ andÓàºbad = Óàº ||ùë• ‚àíùúá| > ùêµ .
( | ) ( | )
Fix ùëñ ‚àà [ùëè]. We may assume that for every ùëó ‚àà [ùëè] there is an indicator ùëîùëñ ‚àº Ber((1‚àíùõº)(1‚àíùõΩ))
ùëó
suchthatifùëîùëñ = 1thenùë•ùëñ ‚àº Óàºgood,andifùëîùëñ = 0thenùë•ùëñ ‚àù (1‚àíùõº)ùõΩ ‚ãÖÓàºbad +ùõº ‚ãÖÓàΩ.
ùëó ùëó ùëó ùëó
Observethatifastrictmajorityof{ùë•ùëñ ‚à∂ ùëó ‚àà [ùëè]}isintheintervalùêº = [ùúá‚àíùêµ,ùúá+ùêµ],thenthe
ùëó ùúá¬±ùêµ
medianùëö isinùêº aswell. Namely,
ùëñ ùúá¬±ùêµ
|
‚Ñô[ùëö ùëñ ‚àà ùêº ùúá¬±ùêµ |ùê∏ ùëñ] = 1,
whereùê∏
ùëñ
istheeventwhere| |{ùëó ‚àà [ùëè] ‚à∂ ùë• ùëóùëñ ‚àà ùêº ùúá¬±ùêµ}| |/ùëè > 1/ 2.
1
‚Ñô[¬¨ùê∏] ‚â§ ‚Ñô ‚àëùëîùëñ ‚â§
ùëñ [ ùëó 2]
ùëó‚àà[ùëè]
| |
| | 1
= ‚Ñô |ùîº ‚àëùëîùëñ ‚àí ‚àëùëîùëñ| ‚â• (ByItem(b))
[| [ ùëó ] ùëó| 6]
| ùëó‚àà[ùëè] ùëó‚àà[ùëè] |
2
1
‚â§ 2exp ‚àí2ùëè‚ãÖ . (Hoeffding‚Äôsinequality) (36)
( (6) )
Observethat ùê∏ isan eventthat issymmetricwithrespect toùúá. Formally,if ùë•ùëñ = (ùë•ùëñ,‚Ä¶,ùë•ùëñ) and
ùëñ 1 ùëè
2ùúá‚àíùë•ùëñ = (2ùúá‚àíùë•ùëñ,‚Ä¶,2ùúá‚àíùë•ùëñ),then
1 ùëè
ùë•ùëñ ‚àà ùê∏ ‚ü∫ (2ùúá‚àíùë•ùëñ) ‚àà ùê∏. (37)
ùëñ ùëñ
ThisimpliesthatthedistributionÓà∞ùëè|ùê∏ issymmetricaboutùúá. Namely,foranymeasurableùê¥ ‚àà ‚Ñùùëè,
ùëñ
‚Ñô ùë•ùëñ‚àºÓà∞ùëè[ùë•ùëñ ‚àà ùê¥|ùê∏ ùëñ] =
‚Ñô
ùë•
‚Ñôùëñ‚àºÓà∞ùëè[ùë• [ùëñ ùë•‚àà
ùëñ
ùê¥
‚àà
ùê∏‚à© ]ùê∏ ùëñ]
ùë•ùëñ‚àºÓà∞ùëè ùëñ
=
‚Ñô ùë•ùëñ‚àºÓà∞ùëè[(2ùúá‚àíùë•ùëñ) ‚àà ùê¥‚à©ùê∏ ùëñ]
(SymmetryofÓà∞aboutùúá)
‚Ñô [ùë•ùëñ ‚àà ùê∏]
ùë•ùëñ‚àºÓà∞ùëè ùëñ
‚Ñô ùë•ùëñ‚àºÓà∞ùëè[(2ùúá‚àíùë•ùëñ) ‚àà ùê¥ ‚àß (2ùúá‚àíùë•ùëñ) ‚àà ùê∏ ùëñ]
=
‚Ñô [ùë•ùëñ ‚àà ùê∏]
ùë•ùëñ‚àºÓà∞ùëè ùëñ
=
‚Ñô ùë•ùëñ‚àºÓà∞ùëè[ùë•ùëñ ‚àà (2ùúá‚àíùê¥) ‚àß ùë•ùëñ ‚àà ùê∏ ùëñ]
(ByEq.(37))
‚Ñô [ùë•ùëñ ‚àà ùê∏]
ùë•ùëñ‚àºÓà∞ùëè ùëñ
= ‚Ñô ùë•ùëñ‚àºÓà∞ùëè[ùë•ùëñ ‚àà (2ùúá‚àíùê¥)|ùê∏ ùëñ]
= ‚Ñô ùë•ùëñ‚àºÓà∞ùëè[(2ùúá‚àíùë•ùëñ) ‚àà ùê¥|ùê∏ ùëñ].
50Namely,ùë•ùëñ|ùê∏ =ùëë (2ùúá‚àíùë•ùëñ)|ùê∏. BythesameargumentasinEq.(33),thisimpliesthat
ùëñ ùëñ
ùîº[ùëö |ùê∏] = ùúá. (38)
ùëñ ùëñ
Letùê∏ = ‚à© ùê∏. ThenforanyùúÄ ‚â• 0
ùëñ‚àà[ùëè] ùëñ
| | | |
| 1 | | 1 | |
‚Ñô |ùúá‚àí ‚àëùëö| ‚â• ùúÄ ‚â§ ‚Ñô[¬¨ùê∏]+‚Ñô | ‚àë(ùëö ‚àíùúá)| ‚â• ùúÄ |ùê∏
[| |ùëò| ùëñ| ] [||ùëò| ùëñ | | ]
| ùëñ‚àà[ùëò] | | ùëñ‚àà[ùëò] |
2ùëèùúÄ2
‚â§ ‚Ñô[¬¨ùê∏]+2exp ‚àí (Hoeffding‚Äôsinequality,Eq.(38))
( ùêµ2 )
ùëè 2ùëèùúÄ2
‚â§ 2ùëè‚ãÖexp ‚àí +2exp ‚àí (ByEq.(36),unionbound)
( 18) ( ùêµ2 )
ùëè 2ùëèùúÄ2
‚â§ 2‚ãÖexp ‚àí +2exp ‚àí (Forùëè ‚â• 102)
( 100) ( ùêµ2 )
‚â§ 4exp(‚àíùõæùëè),
{ }
whereùõæ = min 1 , 2ùúÄ2 ,asdesired.
100 ùêµ2
9 Future Directions
We have provided preliminary evidence that techniques based on random self-reducibility can
beeffectiveatbackdoormitigation. Therearetwodirectionsforfutureworksthatcouldtryto
advancethisideatowardspracticalapplications.
One central direction is to search for additional families of distributions ùîª with random self-
reducibility properties that are suitable for backdoor mitigation. We have seen that if the label
distribution is close to a linear, polynomial, or ùúè-heavy function, then secure backdoor mitigation
ispossible. Butdothereexistbroaderfamiliesofdistributionsthatappearcommonlyinreal-world
dataandarealsoconduciveforbackdoormitigation?
A second avenue for exploration is to take advantage of the representation of the proposed
ML model ùëìÃÉ. Our constructions treat ùëìÃÉ as a black-box, and make no assumptions on how it is
implemented orrepresented. Butperhaps one could obtainbetter results by either(i) assuming
thatùëìÃÉbelongstosomeclassoffunctions,e.g.,itisimplementedbyaneuralnetworkofacertain
architecture; or, moreover (ii) using whitebox access to the representation of ùëìÃÉ (the code or
parametersofthemodel)inordertoobtainmoresophisticatedformsofrandomself-reducibility?
Acknowledgments. JS,NVandVVweresupportedinpartbyNSFCNS-2154149andaSimons
InvestigatorAward. JSwouldliketothankIdoNachumandShayMoranforhelpfulconversations.
51References
YossiAdi,CarstenBaum,MoustaphaCiss√©,BennyPinkas,andJosephKeshet. Turningyourweak-
nessintoastrength: Watermarkingdeepneuralnetworksbybackdooring. InWilliamEnckand
AdriennePorterFelt,editors,27thUSENIXSecuritySymposium,USENIXSecurity2018,Baltimore,
MD,USA,August 15-17,2018,pages1615‚Äì1631. USENIXAssociation,2018. URLhttps://
www.usenix.org/conference/usenixsecurity18/presentation/adi.
VipulArora,ArnabBhattacharyya,NoahFleming,EstyKelman,andYuichiYoshida. Lowdegree
testing over the reals. In Nikhil Bansal and Viswanath Nagarajan, editors, Proceedings of
the 2023 ACM-SIAM Symposium on Discrete Algorithms, SODA 2023, Florence, Italy, January
22-25, 2023, pages 738‚Äì792. SIAM, 2023. doi:10.1137/1.9781611977554.CH31. URL https:
//doi.org/10.1137/1.9781611977554.ch31.
Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, and Grigoris Velegkas. Universal
rates for regression: Separations between cut-off and absolute loss. In Shipra Agrawal and
Aaron Roth, editors, The Thirty Seventh Annual Conference on Learning Theory, June 30 - July 3,
2023,Edmonton,Canada,volume247ofProceedingsofMachineLearningResearch,pages359‚Äì
405. PMLR, 2024. URL https://proceedings.mlr.press/v247/attias24a.
html.
AvrimBlum,MerrickL.Furst,MichaelJ.Kearns,andRichardJ.Lipton. Cryptographicprimitives
based on hard learning problems. In Douglas R. Stinson, editor, Advances in Cryptology -
CRYPTO ‚Äô93,13th Annual InternationalCryptology Conference, SantaBarbara, California, USA,
August 22-26, 1993, Proceedings, volume 773 of Lecture Notes in Computer Science, pages 278‚Äì
291.Springer,1993. doi:10.1007/3-540-48329-2_24. URLhttps://doi.org/10.1007/
3-540-48329-2_24.
Manuel Blum and Sampath Kannan. Designing programs that check their work. In David S.
Johnson,editor,Proceedingsofthe21stAnnualACMSymposiumonTheoryofComputing,May
14-17,1989,Seattle,Washington,USA,pages86‚Äì97.ACM,1989. doi:10.1145/73007.73015. URL
https://dl.acm.org/doi/10.1145/73007.73015.
ManuelBlum,RobertW.Floyd,VaughanR.Pratt,RonaldL.Rivest,andRobertEndreTarjan. Time
boundsforselection. J.Comput.Syst.Sci.,7(4):448‚Äì461,1973. doi:10.1016/S0022-0000(73)80033-9.
URLhttps://doi.org/10.1016/S0022-0000(73)80033-9.
Manuel Blum,Michael Luby, andRonitt Rubinfeld. Self-testing/correcting withapplications to
numericalproblems. InHarrietOrtiz,editor,Proceedingsofthe22ndAnnualACMSymposium
onTheoryofComputing,May13-17,1990,Baltimore,Maryland,USA,pages73‚Äì83.ACM,1990.
doi:10.1145/100216.100225. URLhttps://doi.org/10.1145/100216.100225.
Ben Brubaker. In neural networks, unbreakable locks can hide invisible doors.
Quanta Magazine, March 2023. URL https://www.quantamagazine.org/
cryptographers-show-how-to-hide-invisible-backdoors-in-ai-20230302.
Accessed: 2024-10-30. Archived URL: https://web.archive.org/
web/20230302155439/https://www.quantamagazine.org/
cryptographers-show-how-to-hide-invisible-backdoors-in-ai-20230302/.
52Xiaoyu Cao and Neil Zhenqiang Gong. Mitigating evasion attacks to deep neural net-
works via region-based classification. In Proceedings of the 33rd Annual Computer Secu-
rity Applications Conference, Orlando, FL, USA, December 4-8, 2017, pages 278‚Äì287. ACM,
2017. doi:10.1145/3134600.3134606. URL https://doi.org/10.1145/3134600.
3134606.
BryantChen,WilkaCarvalho,NathalieBaracaldo,HeikoLudwig,BenjaminEdwards,Taesung
Lee,IanM.Molloy,andBiplavSrivastava. Detectingbackdoorattacksondeepneuralnetworks
by activation clustering. In Hu√°scar Espinoza, Se√°n √ì h√âigeartaigh, Xiaowei Huang, Jos√©
Hern√°ndez-Orallo,andMauricioCastillo-Effen,editors,WorkshoponArtificialIntelligenceSafety
2019co-locatedwiththeThirty-ThirdAAAIConferenceonArtificialIntelligence2019(AAAI-19),
Honolulu,Hawaii,January27,2019,volume2301ofCEURWorkshopProceedings.CEUR-WS.org,
2019. URLhttps://ceur-ws.org/Vol-2301/paper_18.pdf.
Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks
on deep learning systems using data poisoning. CoRR, abs/1712.05526, 2017. URL http:
//arxiv.org/abs/1712.05526.
Paul F. Christiano, Jacob Hilton, Victor Lecomte, and Mark Xu. Backdoor defense, learnability
andobfuscation. CoRR,abs/2409.03077,2024. doi:10.48550/ARXIV.2409.03077. URLhttps:
//doi.org/10.48550/arXiv.2409.03077.
JeremyCohen,ElanRosenfeld,andJ.ZicoKolter. Certifiedadversarialrobustnessviarandomized
smoothing. InKamalika ChaudhuriandRuslanSalakhutdinov,editors,Proceedingsofthe36th
InternationalConferenceonMachineLearning,ICML2019,9-15June2019,LongBeach,California,
USA, volume 97 of Proceedings of Machine Learning Research, pages 1310‚Äì1320. PMLR, 2019.
URLhttp://proceedings.mlr.press/v97/cohen19c.html.
VitalyFeldman. Onthepowerofmembershipqueriesinagnosticlearning. J.Mach.Learn.Res.,
10:163‚Äì182,2009. doi:10.5555/1577069.1577076. URLhttps://dl.acm.org/doi/10.
5555/1577069.1577076.
WGautschi. Ontheinversesofvandermondeandconfluentvandermondematrices.i,ii. Numer.
Math,4:117‚Äì123,1962. doi:10.1007/978-1-4614-7034-2_8.
OdedGoldreichandLeonidA.Levin. Ahard-corepredicateforallone-wayfunctions. InDavidS.
Johnson,editor,Proceedingsofthe21stAnnualACMSymposiumonTheoryofComputing,May
14-17,1989,Seattle,Washington,USA,pages25‚Äì32.ACM,1989. doi:10.1145/73007.73010.
ShafiGoldwasserandSilvioMicali. Probabilisticencryptionandhowtoplaymentalpokerkeeping
secret all partial information. In Harry R. Lewis, Barbara B. Simons, Walter A. Burkhard,
and Lawrence H. Landweber, editors, Proceedings of the 14th Annual ACM Symposium on
TheoryofComputing,May5-7,1982,SanFrancisco,California,USA,pages365‚Äì377.ACM,1982.
doi:10.1145/800070.802212. URLhttps://doi.org/10.1145/800070.802212.
ShafiGoldwasser,MichaelP.Kim,VinodVaikuntanathan,andOrZamir. Plantingundetectable
backdoors in machine learning models. In 63rd IEEE Annual Symposium on Foundations of
ComputerScience,FOCS2022,Denver,CO,USA,October31-November3,2022,pages931‚Äì942.
53IEEE, 2022. doi:10.1109/FOCS54457.2022.00092. URL https://doi.org/10.1109/
FOCS54457.2022.00092.
NoahGolowichandAnkurMoitra. Editdistancerobustwatermarksforlanguagemodels. IACR
Cryptol.ePrintArch.,page898,2024. URLhttps://eprint.iacr.org/2024/898.
Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Eval-
uating backdooring attacks on deep neural networks. IEEE Access, 7:47230‚Äì47244,
2019. doi:10.1109/ACCESS.2019.2909068. URLhttps://doi.org/10.1109/ACCESS.
2019.2909068.
JonathanHayase,WeihaoKong,RaghavSomani,andSewoongOh. Spectre: defendingagainst
backdoorattacksusingrobuststatistics. InMarinaMeilaandTongZhang,editors,Proceedings
of the38th InternationalConferenceon Machine Learning, volume139 ofProceedings ofMachine
LearningResearch,pages4129‚Äì4139.PMLR,18‚Äì24Jul2021. URLhttps://proceedings.
mlr.press/v139/hayase21a.html.
SanghyunHong,NicholasCarlini,andAlexeyKurakin. Handcraftedbackdoorsindeepneural
networks. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh,
editors,AdvancesinNeuralInformationProcessingSystems35: AnnualConferenceonNeuralInfor-
mationProcessingSystems2022,NeurIPS2022,NewOrleans,LA,USA,November28-December9,
2022,2022.URLhttp://papers.nips.cc/paper_files/paper/2022/hash/
3538a22cd3ceb8f009cc62b9e535c29f-Abstract-Conference.html.
PeterJHuber. Robustestimationofalocationparameter. TheAnnalsofMathematicalStatistics,35
(1):73‚Äì101,1964. doi:10.1007/978-1-4612-4380-9_35.
Peter J Huber. Robust statistics. Wiley Series in Probability and Mathematical Statistics, 1981.
doi:10.1002/9780470434697.
Mark Jerrum, Leslie G. Valiant, and Vijay V. Vazirani. Random generation of combinatorial
structuresfromauniformdistribution. Theor.Comput.Sci.,43:169‚Äì188,1986. doi:10.1016/0304-
3975(86)90174-X. URLhttps://doi.org/10.1016/0304-3975(86)90174-X.
Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang Gong. Intrinsic certified robustness of bagging
againstdatapoisoningattacks. InThirty-FifthAAAIConferenceonArtificialIntelligence,AAAI
2021,Thirty-ThirdConferenceonInnovativeApplicationsofArtificialIntelligence,IAAI2021,The
Eleventh Symposium onEducational Advances in Artificial Intelligence, EAAI 2021, Virtual Event,
February 2-9, 2021, pages 7961‚Äì7969. AAAI Press, 2021. doi:10.1609/AAAI.V35I9.16971. URL
https://doi.org/10.1609/aaai.v35i9.16971.
CharlesJin,MelindaSun,andMartinC.Rinard. Provableguaranteesagainstdatapoisoningusing
self-expansionandcompatibility. CoRR,abs/2105.03692,2021. URLhttps://arxiv.org/
abs/2105.03692.
AlaaKhaddaj,GuillaumeLeclerc,AleksandarMakelov,KristianGeorgiev,HadiSalman,Andrew
Ilyas,andAleksanderMadry. Rethinkingbackdoorattacks. InAndreasKrause,EmmaBrunskill,
KyunghyunCho,BarbaraEngelhardt,SivanSabato,andJonathanScarlett,editors,International
ConferenceonMachineLearning,ICML2023,23-29July2023,Honolulu,Hawaii,USA,volume202
54of Proceedings of Machine Learning Research, pages 16216‚Äì16236. PMLR, 2023. URL https:
//proceedings.mlr.press/v202/khaddaj23a.html.
Weihao Kong andGregory Valiant. Estimatinglearnability inthe sublineardata regime. In Samy
Bengio,HannaM.Wallach,HugoLarochelle,KristenGrauman,Nicol√≤Cesa-Bianchi,andRoman
Garnett, editors, Advances inNeural InformationProcessingSystems 31: AnnualConference on
NeuralInformationProcessingSystems2018,NeurIPS2018,December3-8,2018,Montr√©al,Canada,
pages5460‚Äì5469,2018. URLhttps://proceedings.neurips.cc/paper/2018/
hash/8bd39eae38511daad6152e84545e504d-Abstract.html.
Pierre Laforgue, Guillaume Staerman, and St√©phan Cl√©men√ßon. Generalization bounds in the
presence of outliers: a median-of-means study. In Marina Meila and Tong Zhang, editors,
Proceedingsofthe38thInternationalConferenceonMachineLearning,ICML2021,18-24July2021,
VirtualEvent,volume139ofProceedingsofMachineLearningResearch,pages5937‚Äì5947.PMLR,
2021. URLhttp://proceedings.mlr.press/v139/laforgue21a.html.
MathiasL√©cuyer,VaggelisAtlidakis,RoxanaGeambasu,DanielHsu,andSumanJana. Certified
robustnesstoadversarialexampleswithdifferentialprivacy. In2019IEEESymposiumonSecurity
and Privacy, SP 2019, San Francisco, CA, USA, May 19-23, 2019, pages 656‚Äì672. IEEE, 2019.
doi:10.1109/SP.2019.00044. URLhttps://doi.org/10.1109/SP.2019.00044.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certified adversarial ro-
bustness with additive noise. In Hanna M. Wallach, Hugo Larochelle, Alina Beygelz-
imer, Florence d‚ÄôAlch√©-Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neu-
ral Information Processing Systems 32: Annual Conference on Neural Information Process-
ing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 9459‚Äì
9469, 2019. URL https://proceedings.neurips.cc/paper/2019/hash/
335cd1b90bfa4ee70b39d08a4ae0cf2d-Abstract.html.
Nathan Linial, Yishay Mansour, and Noam Nisan. Constant depth circuits, fourier transform,
and learnability. J. ACM, 40(3):607‚Äì620, 1993. doi:10.1145/174130.174138. URL https:
//doi.org/10.1145/174130.174138.
XuanqingLiu,MinhaoCheng, HuanZhang,andCho-JuiHsieh. Towardsrobustneuralnetworks
via randomself-ensemble. In VittorioFerrari, Martial Hebert,Cristian Sminchisescu, andYair
Weiss, editors, Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany,
September8-14,2018,Proceedings,PartVII,volume11211ofLectureNotesinComputerScience,
pages381‚Äì397.Springer,2018. doi:10.1007/978-3-030-01234-2_23. URLhttps://doi.org/
10.1007/978-3-030-01234-2_23.
YishayMansour. LearningBooleanfunctionsviatheFouriertransform. InTheoreticaladvancesin
neural computation andlearning, pages391‚Äì424. Springer, 1994. doi:10.1007/978-1-4615-2696-
4_11.
Shay Moran, Hilla Schefler, and Jonathan Shafer. The bayesian stability zoo. In Alice Oh,
Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, edi-
tors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural
Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16,
552023,2023.URLhttp://papers.nips.cc/paper_files/paper/2023/hash/
c2586b71fd150fb56952e253a9c551cc-Abstract-Conference.html.
Arkadij Semenoviƒç Nemirovskij and David Borisovich Yudin. Problem complexity and method
efficiencyinoptimization. Wiley-Interscience,1983.
Gleb Novikov, David Steurer, and Stefan Tiegel. Robust mean estimation without mo-
ments for symmetric distributions. In Alice Oh, Tristan Naumann, Amir Glober-
son, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural In-
formation Processing Systems 36: Annual Conference on Neural Information Process-
ing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023,
2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/
6c59ace4fc4872a14df13d91762ad4f0-Abstract-Conference.html.
RyanO‚ÄôDonnell. Analysis ofBoolean Functions. CambridgeUniversityPress, 2014. ISBN978-1-10-
703832-5. doi:10.1017/CBO9781139814782.
RonittRubinfeldandArsenVasilyan. Testingdistributionalassumptionsoflearningalgorithms.
In Barna Saha and Rocco A. Servedio, editors, Proceedings of the 55th Annual ACM Sympo-
sium on Theory of Computing, STOC 2023, Orlando, FL, USA, June 20-23, 2023, pages 1643‚Äì
1656. ACM, 2023. doi:10.1145/3564246.3585117. URL https://doi.org/10.1145/
3564246.3585117.
Ronitt A Rubinfeld. A mathematical theory of self-checking, self-testing and self-correcting pro-
grams. University of California, Berkeley, 1990. URL https://www.proquest.com/
docview/303810074.
Benjamin Schneider, Nils Lukas, and Florian Kerschbaum. Universal backdoor attacks. In
The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria,
May7-11,2024.OpenReview.net,2024. URLhttps://openreview.net/forum?id=
3QkzYBSWqL.
BrandonTran,JerryLi,andAleksanderMadry. Spectralsignaturesinbackdoorattacks. InSamy
Bengio,HannaM.Wallach,HugoLarochelle,KristenGrauman,Nicol√≤Cesa-Bianchi,andRoman
Garnett, editors, Advances inNeural InformationProcessingSystems 31: AnnualConference on
NeuralInformationProcessingSystems2018,NeurIPS2018,December3-8,2018,Montr√©al,Canada,
pages8011‚Äì8021,2018. URLhttps://proceedings.neurips.cc/paper/2018/
hash/280cf18baf4311c92aa5a042336587d3-Abstract.html.
Bo Xue, Yimu Wang, Yuanyu Wan, Jinfeng Yi, and Lijun Zhang. Efficient algorithms
for generalized linear bandits with heavy-tailed rewards. In Alice Oh, Tristan Nau-
mann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Ad-
vances in Neural Information Processing Systems 36: Annual Conference on Neural Infor-
mation Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16,
2023,2023.URLhttp://papers.nips.cc/paper_files/paper/2023/hash/
e0982cbc81401df3430ee1ff780dc7a2-Abstract-Conference.html.
Han Zhong, Jiayi Huang, Lin Yang, and Liwei Wang. Breaking the moments condition bar-
rier: No-regret algorithm for bandits with super heavy-tailed payoffs. In Marc‚ÄôAurelio Ran-
56zato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan,
editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural
InformationProcessing Systems2021, NeurIPS 2021, December 6-14, 2021,virtual, pages15710‚Äì
15720, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
843a4d7fb5b1641b0bb8e3c2b2e75231-Abstract.html.
MingliZhu,SiyuanLiang,andBaoyuanWu. Breakingthefalsesenseofsecurityinbackdoorde-
fensethroughre-activationattack. CoRR,abs/2405.16134,2024. doi:10.48550/ARXIV.2405.16134.
URLhttps://doi.org/10.48550/arXiv.2405.16134.
A Goldreich‚ÄìLevin Theorem
TheoremA.1(GoldreichandLevin,1989;Section3.5inO‚ÄôDonnell,2014). Thereexistanalgorithm
ùê¥andapolynomialùëùasfollows. Foranyùëõ ‚àà ‚Ñï,anyùúè,ùõø ‚àà (0,1],andanyfunctionùëì ‚à∂ {¬±1}ùëõ ‚Üí {¬±1},
ifùê¥isexecutedwithoracleaccesstoùëì thenùê¥terminatesintimeùëù(ùëõ,1/ùúè,log(1/ùõø))andoutputsa
listùêø ‚äÜ 2[ùëõ] suchthatwithprobabilityatleast1‚àíùõø,forallùëÜ ‚äÜ [ùëõ]:
| |
ÃÇ
1. |ùëì(ùëÜ)| ‚â• ùúè ‚üπ ùëÜ ‚àà ùêø,and
| |
| |
ÃÇ
2. ùëÜ ‚àà ùêø ‚üπ |ùëì(ùëÜ)| ‚â• 3ùúè/4.
| |
Notethatthetheoremistypicallystatedwithaconstantofùúè/2inItem2,whilewehavechosena
strongerstatementwithaconstantof3ùúè/4. Thetheoremholdsforanyconstantfractionofùúè.
B Miscellaneous Fourier Analysis Results
Weusethenormnotation‚Äñ‚ãÖ‚ÄñdefinedinSection6.1.
FactB.1. LetÓà∞ ‚àà Œî(ÓâÑ √ó{¬±1}),andletùëì ‚à∂ ÓâÑ ‚Üí {¬±1}. Then,
1 1
ùêø Óà∞(ùëì) = ‚Ñô (ùë•,ùë¶)‚àºÓà∞[ùëì(ùë•) ‚â† ùë¶] = ‚ãÖùîº (ùë•,ùë¶)‚àºÓà∞[(ùëì(ùë•)‚àíùë¶)2 ] = ‚Äñùëì ‚àíùë¶‚Äñ2.
4 4
Claim B.2. Let ùúÄ ‚àà [0,1], let ÓâÑ = {¬±1}ùëõ, let Óà∞ ‚àà Œî(ÓâÑ √ó{¬±1}) have uniform marginal on ÓâÑ, let
‚Ñé ‚à∂ ÓâÑ ‚Üí {¬±1}suchthatùêø Óà∞(‚Ñé) ‚â§ ùúÄ,andletùëü ‚à∂ ÓâÑ ‚Üí ‚Ñùsuchthatùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ] ‚â§ 4ùúÄ. Then
2
‚àë ÃÇùëü(ùëÜ)‚àíÃÇ ‚Ñé(ùëÜ) ‚â§ 16ùúÄ.
( )
ùëÜ‚äÜ[ùëë]
ProofofClaimB.2.
‚Äñùëü(ùë•)‚àí‚Ñé(ùë•)‚Äñ ‚â§ ‚Äñùëü(ùë•)‚àíùë¶‚Äñ+‚Äñ‚Ñé(ùë•)‚àíùë¶‚Äñ
= (ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ])1/2 +(ùîº (ùë•,ùë¶)‚àºÓà∞[(‚Ñé(ùë•)‚àíùë¶)2 ])1/2
= (ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ])1/2 +2(‚Ñô (ùë•,ùë¶)‚àºÓà∞[‚Ñé(ùë•) ‚â† ùë¶])1/2 (ByFactB.1)
‚àö
‚â§ 4 ùúÄ. (Choiceofùëü and‚Ñé)
57Hence,
16ùúÄ ‚â• ‚Äñùëü(ùë•)‚àí‚Ñé(ùë•)‚Äñ2
2
= ‚àë ÃÇùëü(ùëÜ)‚àíÃÇ ‚Ñé(ùëÜ) . (Parseval‚Äôsidentity)
( )
ùëÜ‚äÜ[ùëë]
Claim B.3 (Section 4 in Mansour, 1994). Let ùëë ‚àà ‚Ñï, let ÓâÑ be a set, let Óà∞ ‚àà Œî(ÓâÑ √ó{¬±1}), and let
ùëü ‚à∂ ÓâÑ ‚Üí ‚Ñù. Then
‚Ñô (ùë•,ùë¶)‚àºÓà∞[sign(ùëü(ùë•)) ‚â† ùë¶] ‚â§ ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ].
ProofofClaimB.3. Forafixedùë• ‚àà ÓâÑ andùë¶ ‚àà {¬±1},considertwocases.
‚Ä¢ CaseI:sign(ùëü(ùë•)) ‚â† ùë¶. Then1(sign(ùëü(ùë•)) ‚â† ùë¶) = 1 ‚â§ |ùëü(ùë•)‚àíùë¶| ‚â§ (ùëü(ùë•)‚àíùë¶)2.
‚Ä¢ CaseII:sign(ùëü(ùë•)) = ùë¶. Then1(sign(ùëü(ùë•)) ‚â† ùë¶) = 0 ‚â§ (ùëü(ùë•)‚àíùë¶)2.
Hence,foranyùë• ‚àà ÓâÑ andùë¶ ‚àà {¬±1},
1(sign(ùëü(ùë•)) ‚â† ùë¶) ‚â§ (ùëü(ùë•)‚àíùë¶)2.
Therefore,
‚Ñô (ùë•,ùë¶)‚àºÓà∞[sign(ùëü(ùë•)) ‚â† ùë¶] = ùîº (ùë•,ùë¶)‚àºÓà∞[1(sign(ùëü(ùë•)) ‚â† ùë¶)] ‚â§ ùîº (ùë•,ùë¶)‚àºÓà∞[(ùëü(ùë•)‚àíùë¶)2 ].
ClaimB.4. ForallsetsÓâÑ,alldistributionsÓà∞ ‚àà Œî(ÓâÑ √ó{¬±1}),andallfunctionsùëì ‚à∂ ÓâÑ ‚Üí ‚Ñù,
1
ùêø2 (sign(ùëì)) = ùêø0-1(sign(ùëì)) ‚â§ ùêø2 (ùëì).
Óà∞ Óà∞ Óà∞
4
Proof. The(left-hand)equalitydirectlyholds,as
1 1
ùêø2 Óà∞(sign(ùëì)) = ùîº (ùë•,ùë¶)‚àºÓà∞[(sign(ùëì(ùë•))‚àíùë¶)2 ] = ùîº (ùë•,ùë¶)‚àºÓà∞[1(sign(ùëì(ùë•)) ‚â† ùë¶)]
4 4
= ‚Ñô [sign(ùëì(ùë•)) ‚â† ùë¶]
(ùë•,ùë¶)‚àºÓà∞
=
ùêø0-1(sign(ùëì)),
Óà∞
wherewehaveusedthefactthat(sign(ùëì(ùë•))‚àíùë¶)2 ‚àà {0,4}. The(right-hand)inequalityisgiven
inClaimB.3.
C Subgaussian distributions
Definition C.1. Let ùúé ‚â• 0 and let ùëã be a real-valued random variable. ùëã is subgaussian with
varianceproxyùúé2,denotedùëã ‚àà SubG(ùúé2 ),ifùîº[ùëã] = 0and
‚àÄùë° ‚àà ‚Ñù ‚à∂ ùîº[ùëíùë°ùëã ] ‚â§
ùëíùúé2 2ùë°2
.
58Claim C.2 (Concentration for Subgaussian Random Variables). Let ùúé ‚â• 0, and ùëã ‚àà SubG(ùúé2 ).
Thenforanyùë° ‚â• 0,
ùë°2
‚Ñô[|ùëã| ‚â• ùë°] ‚â§ 2exp ‚àí .
( 2ùúé2)
Moreover, for ùëõ ‚àà ‚Ñï, independent variables ùëã 1,‚Ä¶,ùëã
ùëõ
‚àà SubG(ùúé2 ), and for any ùëé 1,‚Ä¶,ùëé
ùëõ
‚àà ‚Ñù and
ùë° ‚â• 0,
| |
| | ùë°2
‚Ñô |‚àëùëéùëã| ‚â• ùë° ‚â§ 2exp ‚àí .
[| ùëñ ùëñ| ] ( 2ùúé2‚àë ùëé2)
|ùëñ‚àà[ùëõ] | ùëñ‚ààùëõ ùëñ
Claim C.3 (Sum of Subgaussian Random Variables is Subgaussian). Let ùúé ‚â• 0, ùëõ ‚àà ‚Ñï, and let
ùëã 1,‚Ä¶,ùëã
ùëõ
‚àà SubG(ùúé2 )forallùëñ ‚àà [ùëõ]. Thenùëç = ‚àë ùëñ‚àà[ùëõ]ùëã
ùëñ
‚àà SubG(ùëõ2ùúé2 ).
Notethattheùëã‚Äôsintheclaimarenotnecessarilyindependent.
ùëñ
ProofofClaimC.3. Foranyùë° ‚àà ‚Ñù,
ùîº[ùëíùë°ùëç ] = ùîº[ùëíùë°(ùëã1+‚ãØ+ùëãùëõ) ]
= ùîº[ùëíùëõ1‚àë ùëñ‚àà[ùëõ]ùëõùë°ùëãùëñ]
1
‚â§ ‚àëùîº[ùëíùëõùë°ùëãùëñ] (Jensen‚Äôsinequality)
ùëõ
ùëñ‚àà[ùëõ]
‚â§ 1 ‚àëùëíùúé2‚ãÖ( 2ùëõùë°)2 = ùëíùëõ2ùúé 22‚ãÖùë°2 , (ùëã
ùëñ
‚àà SubG(ùúé2 ))
ùëõ
ùëñ‚àà[ùëõ]
asdesired.
ClaimC.4(ProductofSubgaussianandBoundedRandomVariablesisSubgaussian). Letùúé,ùëê ‚â• 0,
andletùëã,ùëå ‚àà ‚Ñùberandomvariablessuchthatùëã ‚àà SubG(ùúé2 ),and‚Ñô[|ùëå| ‚â§ ùëê] = 1. Thenùëç = ùëãùëå ‚àà
SubG(ùëê2ùúé2 ).
Notethatùëã andùëå neednotbeindependent.
ProofofClaimC.4. Foranyùë° ‚àà ‚Ñù,
ùîº[ùëíùë°ùëç ] = ùîº[ùëíùë°ùëãùëå ]
= ùîº ùë¶‚àºùëå[ùîº ùëã[ùëí(ùë°ùë¶)‚ãÖùëã ]]
‚â§ ùîº
ùë¶‚àºùëå[ùëíùúé2‚ãÖ( 2ùë°ùë¶)2
]
(ùëã ‚àà SubG(ùúé2 ))
‚â§ ùëíùëê2ùúé 22ùë°2 , (|ùëå| ‚â§ ùëê)
asdesired.
59