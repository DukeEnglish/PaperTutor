Online Data Collection for
Efficient Semiparametric Inference
Shantanu Gupta ∗1, Zachary C. Lipton1, and David Childers2
1Carnegie Mellon University
2Bowdoin College
Abstract
While many works have studied statistical data fusion, they typically assume that
the various datasets are given in advance. However, in practice, estimation requires
difficult data collection decisions like determining the available data sources, their
costs, and how many samples to collect from each source. Moreover, this process is
often sequential because the data collected at a given time can improve collection
decisions in the future. In our setup, given access to multiple data sources and
budget constraints, the agent must sequentially decide which data source to query to
efficiently estimate a target parameter. We formalize this task using Online Moment
Selection, a semiparametric framework that applies to any parameter identified by
a set of moment conditions. Interestingly, the optimal budget allocation depends
on the (unknown) true parameters. We present two online data collection policies,
Explore-then-Commit and Explore-then-Greedy, that use the parameter estimates at
agiventimetooptimallyallocatetheremainingbudgetinthefuturesteps. Weprove
that both policies achieve zero regret (assessed by asymptotic MSE) relative to an
oracle policy. We empirically validate our methods on both synthetic and real-world
causal effect estimation tasks, demonstrating that the online data collection policies
outperform their fixed counterparts 1.
1 Introduction
The estimation of a statistical or causal parameter often requires combining multiple
datasets, potentially containing different subsets of variables or measurements collected
under different conditions. Many works have studied data fusion to identify and efficiently
estimate a target parameter (like a treatment effect) under a variety of different structural
assumptions [Shi et al., 2023, Hu¨nermund and Bareinboim, 2019, Bareinboim and Pearl,
2016, Ridder and Moffitt, 2007, D’Orazio et al., 2006]. Most of these works proceed from
the assumption that the multiple datasets are given in advance and the focus is typically
∗Corresponding author: shantang@cs.cmu.edu
1The code and data are available at https://github.com/shantanu95/online-moment-selection.
1
4202
voN
5
]LM.tats[
1v59130.1142:viXraon efficiently combining them, failing to account for the difficult data collection decisions
involved in the practice of statistical estimation. Tasked with an estimation problem and
budget constraints, a practitioner must reason about the available data sources, their costs,
and allocate their budget across the data sources.
In many applications, data is prohibitively expensive and it is infeasible to collect every-
thing. Medical tests can cost thousands of dollars. In survey design, asking every question
can result in poor data quality and survey fatigue [Jeong et al., 2023]. Secondly, we often
lack complete control over which variables are measured, e.g., when relying on third-party
data sources, each capturing different subsets or types of variables. Thirdly, if the data
sources do not suffice, a practitioner may run their own data collection studies, requiring
decisions about what to measure, and how many samples to collect. Moreover, data col-
lection is an ongoing process, with the data collected at a particular time allowing us to
make better decisions in the future steps.
Inthiswork, webringdatacollectiondecisionswithinthescopeofstatisticalestimation.
Instead of assuming that the datasets are given in advance, in our setup, the agent has
accesstomultipledatasources(withanassociatedcoststructure)thattheycansequentially
query (i.e., sample from). The data sources can be arbitrary probability distributions
returning marginals over different variable subsets, measurements collected under different
conditions, etc. We present Online Moment Selection (OMS), a framework to formalize the
sequential problem of deciding, at each time step, which data source to query to efficiently
estimate a target parameter (Section 3). In OMS, we apply the generalized method of
moments(GMM)[Hansen,1982]toestimatethetargetparameter, augmentingthemoment
conditions by a vector that determines which moments (or data source) gets selected at
a given time. We require that the agent has sufficient structural knowledge to construct
moment conditions that uniquely identify the target parameter and that each moment
condition can be estimated using samples returned by at least one data source.
Our formulation is semiparametric. Each moment condition is indexed by a finite-
dimensional parameter θ P RD and a possibly high-dimensional or nonparametric nuisance
parameter η [Tsiatis, 2006, Bickel et al., 1993]. We assume that the target parameter β P R
is a function of θ. The nuisance parameters are not of primary interest but must still be
estimated for inferring β, e.g., the propensity score in causal inference [Kennedy, 2016]. By
avoiding restrictive parametric assumptions on the underlying distribution, we can model
the nuisance parameters using flexible machine learning or nonparametric estimators. To
?
construct a n-consistent estimator for β in the presence of nuisance estimators that con-
verge at slower rates, we assume Neyman orthogonality, which states that the moment con-
ditions are locally insensitive to perturbations of the nuisance parameters [Chernozhukov
et al., 2018, Neyman, 1959].
The optimal allocation of the budget across the data sources for estimating β depends
on the (unknown) true model parameters pθ˚,η˚q, motivating our online data collection
strategy: we use the estimate of the model parameters at time t to allocate the remaining
budgetinthefuturesteps. Inparticular,weusetheestimatedmodelparameterstoestimate
p
the asymptotic variance of β and allocate the data collection budget in the future steps to
minimize this estimated variance.
Addressing the setting with a uniform cost structure over the data sources (Section 4),
we show that any fixed data collection policy suffers constant regret, as assessed by the
asymptotic MSE relative to the (unknown) oracle policy, the policy with the lowest asymp-
2totic MSE. To overcome this limitation, we propose two online data collection policies,
Explore-then-Commit (OMS-ETC) and Explore-then-Greedy (OMS-ETG), and prove that
both policies achieve zero regret. Under OMS-ETC (Section 4.1), we use some fraction of
the budget to estimate the model parameters by querying the data sources uniformly (the
explore phase). In the subsequent steps (the commit phase), we allocate the remaining
budget across the data sources such that the (estimated) asymptotic variance of the target
parameter β is minimized. Under OMS-ETG (Section 4.2), instead of committing to the
optimal allocation determined after exploration, we continually update the model param-
eters and thereby the optimal allocation of the remaining budget. We then extend our
analysis to account for a non-uniform cost structure over the data sources (Section 5),
proposing variants of OMS-ETC and OMS-ETG for this setting.
Next, we develop asymptotic confidence sequences (Section 6), a time-uniform coun-
terpart of CLT-style confidence intervals [Waudby-Smith et al., 2021]. Unlike confidence
intervals, confidence sequences are valid at all time steps simultaneously. This gives the
practitioner more flexibility as the experiment can be continuously monitored and the data
collection can be adaptively stopped or continued. Finally, we validate our methods ex-
perimentally on causal effect estimation tasks (Section 7), comparing our online strategies
against fixed data collection policies on synthetic causal models (Section 7.1) and two real-
world datasets (Section 7.2). We observe that the online strategies have lower regret and
MSE and better coverage than the fixed policies.
2 Related Work
There is a rich literature on semiparametric estimation under data fusion for causal infer-
ence [Shi et al., 2023, Li et al., 2022] and econometrics [Buchinsky et al., 2022, Ridder and
Moffitt, 2007]. Many works have studied the two-sample instrumental variable (IV) setting
where the IV, treatment, and outcome are not jointly observed [Shuai et al., 2023, Shinoda
and Hoshino, 2022, Sun and Miao, 2022, Zhao et al., 2019, Graham et al., 2016, Angrist and
Krueger, 1990]. Others have studied data fusion for combining randomized control trial
and observational datasets [Lin et al., 2024, Li, 2024, Colnet et al., 2024, Carneiro et al.,
2020], estimating long-term treatment effects [Chen and Ritzwoller, 2023, Ghassami et al.,
2022, Imbens et al., 2022, Li and Luedtke, 2021, Athey et al., 2020], improving efficiency
using external auxiliary datasets [Li et al., 2024, Hu et al., 2022, Chen et al., 2022, Li et al.,
2021, Evans et al., 2021, Yang and Ding, 2019, Stu¨rmer et al., 2005], combining multiple
IVs [Wu et al., 2023, Burgess et al., 2016], and leveraging additional datasets with selection
bias [Guo et al., 2022]. Graham et al. [2024] and Li et al. [2021] present a semiparamet-
rically efficient data fusion strategy under assumptions on the alignment of the multiple
data distributions. Our work is complementary and addresses the challenge of sequentially
allocating a given data collection budget across the given data sources.
Several works have studied the relative efficiencies of different adjustment sets for causal
inference [Henckel et al., 2019, Rotnitzky and Smucler, 2020, Witte et al., 2020]. Others
have compared the relative efficiencies of the backdoor and frontdoor estimators in linear
[Gupta et al., 2021b, Ramsahai, 2012] and semiparametric causal models [Gorbach et al.,
2023]. These works show that the relative efficiencies cannot always be known a priori and
depend on the underlying model parameters, motivating our work on online data collection.
3Another related line of work studies inference from adaptively collected data. A com-
monly studied setting is adaptive experimental design, where the probability of treatment
is sequentially updated to identify the best treatment or reduce the variance of a causal
effect estimator [Li and Owen, 2023, Zhao, 2023, Cook et al., 2023, Hadad et al., 2021,
Kato et al., 2020, Hahn et al., 2011]. Others have extended this to the indirect experimen-
tation setting [Zhao et al., 2024, Morrison et al., 2024, Ailer et al., 2023, Chandak et al.,
2023]. Lin et al. [2023] study semiparametric inference for generalized linear regression
from adaptively collected data. While many of the theoretical tools we use are similar (like
martingale asymptotics), our setting is different from these works.
Some works have studied the identification of causal effects from data sources collected
under heterogeneous conditions [Bareinboim and Pearl, 2016, Hu¨nermund and Bareinboim,
2019]. Others have studied identification with observational and interventional distribu-
tions involving different sets of variables [Lee et al., 2024, Kivva et al., 2022, Lee and
Bareinboim, 2021, Lee and Shpitser, 2020, Lee and Bareinboim, 2020, Tikka et al., 2019].
In this work, we take identification for granted and focus on efficient estimation.
Our work also shares motivation with active learning, where the goal is to sequentially
decide which data points to label to learn a predictor or parameter efficiently [Zrnic and
Cand`es, 2024, Zhao and Yao, 2012, Settles, 2009, Cohn et al., 1996]. Another related area
is active feature acquisition, where the goal is to incrementally acquire the most informative
or cost-efficient feature subset for training a predictive model [Li and Oliva, 2021, Shim
et al., 2018, Hu et al., 2018, Attenberg et al., 2011, Saar-Tsechansky et al., 2009].
TheauthorsalsostudiedOMSinGuptaetal.[2021a]. Webuildonthisworkinthreekey
ways: (1) we consider the semiparametric setting allowing for flexible nuisance estimation,
(2) we make weaker assumptions, and (3) our results enable time-uniform inference.
3 Online Moment Selection
3.1 Setup
We represent the available data sources by D :“ pPpiqq|D|, a collection of probability dis-
i“1
tributions. Querying a data source Ppiq P D is equivalent to drawing an independent and
identically distributed (i.i.d.) sample from Ppiq. The collection D can include marginals
over different subsets of variables, observational or interventional distributions, measure-
ments under heterogeneous conditions, etc. To simplify exposition, we make the following
assumption (which we relax in Section 5 to allow for non-uniform costs):
Assumption 1 (Equal cost). Each sample from every data source has an equal cost.
We denote by T, the horizon or the known total number of queries the agent can make.
The s řelection vector, denoted by s
t
P t0,1u|D| for t P rTs, is a random binary one-hot vector
(i.e., s “ 1) indicating the data source queried by the agent at time t. That is, s “ 1
d t,d t,j
indicates that the agent queried Ppjq at time t. For convenience, we define Pps q :“ Ppjq.
t
Let H “ tZ ,...,Z u P H denote the history, or the data collected until time t (with
t 1 t t
H “ H), where Z is the sample from the data source queried at time t and H is the
0 t t
set of possible histories. A data collection policy, denoted by π, is a sequence of functions
π : H ÞÑ t0,1u|D| with s “ π pH q. Thus, s can depend on the past data H .
t t´1 t t t´1 t t´1
4Notation. We use o and O to denote the classical order notation; o (o ) to denote
p a.s.
convergence in probability (almost surely); and O (O ) to denote stochastic boundedness
p a.s.
inprobability(almostsurely). Theset∆ denotesthep|D|´1qprobabilitysimplexandκ
D ctr
denotes the center of ∆ : κ :“ r1{|D|,...,1{|D|sJ. We use }.} to denote the spectral and
D ctr
p
l norms for matrices and vectors, respectively. For two functions f,f˚ : X ÞÑ R, we denote
2
p p p
their l
2
distance as }f ´f˚}2 :“ E Ppxqrpfpxq´f˚pxqq2s. If f is an estimated function, then
p p
}f´f˚} will be a´random va¯riable (with randomness over the estimation of f). For a vector
ř
of functions ηp“ fp ,...,fp and η˚ “ pf˚,...,f˚q, we define }ηp´η˚} :“ k }fp ´f˚}.
1 k 1 k i“1 i i
We use B pxq to denote the ϵ-ball around x: B pxq “ tx1 : }x´x1} ă ϵu. For a vector v, we
ϵ ϵ
use v to denote its jth coordinate. We use Npµ,σ2q to denote the normal distribution with
j
meanµandvarianceσ2; andN pµ,σ2qtodenoteamixtureofnormals(themixtureistaken
σ
over σ), with characteristic function E rexpt´iµt ´ σ2t{2us. We use E r.s :“ Er.|H s
σ t´1 t´1
to denote the conditional expectation given the past data H .
t´1
Constructing the moment conditions. Our framework is applicable if the target pa-
rameter can be identified by a set of moment conditions such that each moment relies on
samples returned by at least one data source. We assume that the moment conditions can
be written as
» fi
ψp1qpZp1q;θ,ηp1qq
— t ffi
.
g tpθ,ηq “ mps tqd– . . fl P RM, (1)
loψ ooop oM ooq opoZ oootp oM mq; ooθ oo, oη oop oM ooq oqoon
:“g˜tpθ,ηq
where`d is the elem˘ent-wise product, θ P Θ Ă RD is a finite-dimensional parameter, and
η :“ ηp1q,...,ηpMq P T are the nuisance parameters. For brevity, we use ψpiq pθ,ηq :“
t
ψpiqpZpiq;θ,ηq. At the true parameter values pθ˚,η˚q, the moment conditions satisfy
t
@i P rMs, ErψpiqpZpiq;θ˚,η˚qs “ 0.
t
We augment the original moment conditions g˜pθ,ηq with the vector mps q. The function
t t
m : t0,1u|D| ÞÑ t0,1uM is a fixed known function that determines which moments get
selected based on the selection vector s . That is, m ps q “ 1 indicates that the moment
t i t
condition ψpiq can be estimated from the data source selected in s (i.e., Zpiq i „id Pps q). The
t t t
target parameter is β˚ :“ f pθ˚q for some known function f : Θ ÞÑ R.
tar tar
Estimating the nuisance parameters. Since the moment conditions depend on the
nuisance parameters η, they need to be estimated. We make the following assumption:
Assumption 2. (a) The nuisance estimator can be constructed without knowledge of θ and
(b) at time t, the nuisances are estimated using the data H , that we denote by ηp .
t´1 t´1
Assumption 2a states that it is possible to construct an estimator for η independently
of θ (see Kallus et al. [2024] for more discussion and a strategy for relaxing this condition).
Assumption 2b states that, at time t, the nuisance estimator ηp only depends on data
t´1
collected until time t ´ 1. This ensures that the nuisance estimators are trained and
evaluatedonindependentsamples, andplaysasimilarroleasthesample splitting technique
usedtoavoidDonskerassumptionsonthenuisancefunctionclass[Kennedy,2022, Sec.4.2].
5Estimating the target parameter. We estimate θ by plugging ηp into the moment
t´1
p
conditions g and minimizing the GMM objective Q :
t T
p p
θ “ argminQ pθ,pηp qT q, (2)
T T t´1 t“1
θPΘ « ff « ff
ÿT J ÿT
p 1 x 1
where Q pθ,pηp qT q “ g pθ,ηp q W g pθ,ηp q ,
T t´1 t“1 T t t´1 T T t t´1
t“1 t“1
x
W P RMˆM is a (possibly data dependent) positive semidefinite matrix. We then plug in
T
p p p
θ to estimate the target parameter: β “ f pθ q. We use the two-step GMM estimator,
T T tar T
which is computed as follows: we first compute the one-step estimator θp posq with Wx “ I
T T
”(i řdentity), andthencomputetıhetwo-stepestimatorwithWx
T
“ Ωp Tpθp Tposq q´1, whereΩp Tpθq “
T g pθ,ηp qg pθ,ηp qJ{T . Informally, Wx determines the importance given to each
t“1 t t´1 t t´1 T
moment condition in the minimization problem and the choice in the two-step estimator is
asymptotically the most efficient [Newey and McFadden, 1994, Sec. 5].
3.2 Examples
We give three examples to instantiate our framework (see Appendix I for additional exam-
ples). We begin with the parametric case (where η is empty):
Example 1 (Two-sampleIV). Consider a linear IV causal model (Fig. 1a) with instrument
Z, treatment X, and outcome Y (and empty W); with the following data-generating process:
X :“ αZ `ϵ ,
X
Y :“ βX `ϵ ,
Y
ϵ K­K ϵ , ϵ KK Z, ϵ KK Z.
X Y Y X
In the two-sample IV setting, we have two data sources that return an i.i.d. sample of
pZ,Xq and pZ,Yq. Thus, D “ tPpZ,Xq, PpZ,Yqu. The target parameter β˚ is the average
treatment effect (ATE) of X on Y that can be estimated using:
„ ȷ „ ȷ „ ȷ „ ȷ
s Z pX ´αZ q s Z pX ´αZ q
g pθq “ t,1 d t t t “ t,1 d t t t ,
t loos mt,2oon loZ ootopoY ootoo´mα oooβ ooZ ootoqon 1´s t,1 Z tpY t ´αβZ tq
“mpstq “g˜tpθq
where θ “ rβ,αsJ, and f pθq “ β.
tar
The following examples demonstrate the semiparametric case where the moment con-
ditions are also indexed by nuisance parameters.
Example 2 (Two-sample LATE). Consider the IV causal model (Fig. 1a) with D “
tPpW,Z,Xq, PpW,Z,Yqu. The target parameter β˚ is the unconditional local average treat-
ment effect (LATE), which is the ATE on the compliers [Fr¨olich, 2007]. The LATE can be
estimated using the following moment conditions [Chernozhukov et al., 2018, Sec. 5.2]:
„ ȷ „ ȷ
s ψ pW ,Z ,Y ;ηp1qq´βα
g pθ,ηq “ t,1 d AIPW t t t ,
t 1´s ψ pW ,Z ,X ;ηp2qq´α
t,1 AIPW t t t
6W W W U
Z X Y X M Y X Y
(a) IV graph. (b)Confounder-mediatorgraph. (c) Two confounders graph.
Figure 1: Examples of causal models—with treatment X and outcome Y—where the ATE
can be identified by different data sources returning different subsets of variables.
where ψ is the augmented inverse propensity score influence function [Kennedy, 2016,
AIPW
Sec. 3.4], θ “ rβ,αsJ, and f pθq “ β. For O “ pW,Z,Rq P pW ˆt0,1uˆRq, ψ is
tar AIPW
ˆ ˙
Z 1´Z
ψ pOq :“ ´ pR´µ˚pZ,Wqq`pµ˚p1,Wq´µ˚p0,Wqq, (3)
AIPW
π˚pWq 1´π˚pWq
where π˚pWq “ PpZ “ 1|Wq and µ˚pZ,Wq “ ErR|Z,Ws are the nuisance parameters.
Example 3. Consider the confounder-mediator causal graph (Fig. 1b) with a binary treat-
ment X, mediator M, outcome Y, confounder W. The target parameter is the causal
effect of X on Y, i.e., β˚ “ ErY|dopX “ 1qs ´ ErY|dopX “ 0qs [Pearl, 2009]. With
D “ tPpW,X,Yq,PpX,M,Yqu, β˚ can be estimated with the backdoor or the frontdoor
criterion [Pearl, 2009, Sec. 3.3]. The moment conditions can be written as
„ ȷ „ ȷ
s ψ ppW ,X ,Y q;η(AIPW)q´β
g pθq “ t,1 d AIPW t t t ,
t p1´s q ψ ppX ,M ,Y q;η(fd)q´β
t,1 fd t t t
where ψ is defined in Eq. 3, ψ is the efficient influence function for the frontdoor
AIPW fd
criterion [Fulcher et al., 2020] (see Eq. 95 in Appendix H), θ “ rβs, and f pθq “ β.
tar
3.3 Consistency, Asymptotic Inference, and Regret
Wepresentsufficientconditionsforconsistency(Prop.1)andasymptoticinference(Props.2,
3) in the OMS setting. We then use these results to define the regret of a data collection
policy (Definition 2). The proofs are deferred to Appendices A and B.
ř
Assumption 3. Let I “ ti P rMs : liminf T m ps q{T ą 0u. (a) (Identification)
TÑ8 t“1 i t
@θ ‰ θ˚, Er}g˜ pθ,η˚q}s ‰ 0, where g˜ “ rg˜ s is the subset of moments determined by
t,I t,I t,i iPI
I; (b) Θ Ă RD is compact; and (c) f is continuously differentiable at θ˚.
tar
The index set I denotes the moments that get selected an asymptotically non-negligible
fraction of times by the policy. Assumption 3a states that the moment conditions selected
in I are sufficient to uniquely identify θ˚ [Newey, 1990, Sec. 2.2.3]. If there are as many
moments as parameters (i.e., M “ D), this requires that |I| “ M.
Property 1 (ULLN). For a function a pθ,ηq :“ apX ;θ,ηq P R with X sampled i.i.d., we
t t t
say that a pθ,ηq satisfies the ULLN property if (i) Dδ ą 0, @θ,Er|a pθ,η˚q|2`δs ă 8; (ii)
t t
(Lipschitzness) For some constant L, @θ,θ1 P Θ,@η P T , |a pθ1,ηq´a pθ,ηq| ď LpX q}θ1´θ}
t t t
with ErL2pX qs ď L and @θ P Θ,@η,η1 P T , Erpa pθ,ηq ´ a pθ,η1qq2s ď L}η ´ η1}2; (iii)
t t t
(Nuisance consistency) }ηp ´η˚} Ñp 0; and (iv) Dδ ą 0,sup Er}η ´η˚}2`δs ă 8.
t´1 ηPT
7Proposition 1 (Consistency). Suppose that (i) Assumption 3 holds; (ii) @i P rMs,ψpiq
satisfies Property 1; (iii) @pi,jq P rMs2,ψpiqψpjq satisfies Property 1. Then βp Ñp β˚.
T
For ψ (Eq. 3), Property 1(ii) holds under boundedness of the data and nuisance
AIPW
parameters [Kennedy, 2022, Example 2 (Sec. 4.2)]. Condition (iii) of Prop. 1 will hold if
@i P rMs,ψpiq are uniformly bounded (see Prop. 10 in Appendix A).
Assumption 4 (Nuisance estimation). For all i P rMs, (a) (Neyman orthogonality)
@η, B Erψpiq pθ˚,η˚ ` rpη ´ η˚qqs| “ 0; and (b) (Second-order remainder) For R :“
ş r t r“0 t
1 B E rψpiq pθ˚,η˚ `rpηp ´η˚qqsdr, R “ o pt´1{2q and Dδ ą 0,sup ErR1`δs ă 8.
0 r2 t´1 t t´1 t p t t
Assumption 4a states that every moment condition is robust to local perturbations of
nuisance parameters up to the first order and 4b states that the second-order remainder
converges at a faster-than-CLT rate. Assumption 4 ensures that the impact of the nuisance
estimators ηpon the estimate of θ is higher order [Chernozhukov et al., 2018, Belloni et al.,
2017, Neyman, 1959]. For ψ (Eq. 3), R scales as the product of the errors of the two
AIPW t
nuisance estimators: R “ Op}πp ´π˚}}µp ´µ˚}q, allowing each nuisance estimator to
t t´1 t´1
converge at a slower rate of o pt´1{4q [Kennedy, 2022, Sec. 4.3]. The phenomenon of R
p t
taking a product form, also known as double robustness, is more general and holds for many
influence functions [Chernozhukov et al., 2022, Bhattacharya et al., 2022, Rotnitzky et al.,
2021]. Convergence rates exist for many estimation problems [Gao et al., 2022, Farrell
et al., 2021, Kohler and Langer, 2021, Wainwright, 2019, Gyo¨rfi et al., 2002].
Definition 1 (Selection simplex). The selection simplex, denoted by κ P ∆ , represents
T D
the fraction of times each data source has been queried until time T:
ÿT
1
κ :“ s .
T t
T
t“1
p
Assumption 5. The policy π is such that κ Ñ κ , for some random variable κ .
T 8 8
Proposition 2 (Asymptotic normality). Suppose that (i)”Conditionıs of Prop. 1 hold; (ii)
Assumptions 4 and 5 hold; and (iii) @i P rMs,j P rDs,B ψpiq pθ,ηq satisfies Property 1.
θj t
p
Then β converges to a mixture of normals, where the mixture is over κ :
T 8
?
Tpβp ´β˚q Ñd N p0,V pκ qq,
T κ8 ˚ 8
where V pκq is a constant that depends on pθ˚,η˚,κq (see Eq. 44 in Appendix B). If κ is
˚ 8
p
almost surely constant, then β is asymptotically normal.
T
Proposition 3 (Asymptotic inference). Suppose that the Conditions of Prop. 2 hold. For
ÿT
p p 1 p
G pθ q :“ ∇ g pθ ,ηp q,
T T
T
θ t T t´1
t“1
ÿT
p p 1 p p
Ω pθ q :“ g pθ ,ηp qgJpθ ,ηp q,
T T T t T t´1 t T t´1
” t“1 ı
p p p p p p p ´1
Σ :“ GJpθ qΩ´1pθ qG pθ q ,
T T T T T T T
p p p p
V :“ ∇ f pθ qJΣ ∇ f pθ q, (4)
T θ tar T T θ tar T
8we have
?
Vp´1{2 Tpβp ´β˚q Ñd N p0,1q.
T T
A fixed policy, denoted by π , queries each data source a fixed pre-specified fraction of
κ
times with κ “ κ for some constant κ P ∆ . The oracle policy, denoted by π˚, is the
T D
(unknown) fixed policy with the lowest asymptotic variance. For π˚, we have κ “ κ˚,
T
where κ˚ “ argmin V pκq. We call κ˚ the oracle simplex. The following assumption,
κ ˚
which we make throughout this work, states that no two combinations of the data sources
minimize the asymptotic variance, ensuring the uniqueness of κ˚.
Assumption 6. κ˚ uniquely minimizes V pκq: @κ such that κ ‰ κ˚, V pκq ą V pκ˚q.
˚ ˚ ˚
p
Remark 1. Since the asymptotic distribution of β only depends on the limit of κ
T T
(Prop. 2), the order in which the data sources are queried does not matter for our results.
iid
We can also use randomized fixed policies with s „ Multinoullipκq.
t
Definition 2 (Asymptotic regret). We define the asymptotic regret of a policy π as
´ ´ ¯¯
?
R pπq “ AMSE T βp pπq ´β˚ ´V pκ˚q, (5)
8 T ˚
where AMSE is the asymptotic MSE, i.e., the MSE of the limiting distribution.
The regret measures how close the (asymptotic) MSE of π is to the MSE of the oracle
p
policy. UnderAssumption5, theselectionsimplexκ converges, andtherefore, β willhave
T T
a limiting distribution (Prop. 2), making the regret well-defined. Comparing estimators
based on their limiting distributions is common in asymptotic statistics, where the focus is
usually on regular and asymptotically linear estimators [Van der Vaart, 2000].
The next proposition shows that the asymptotic regret of any data collection policy
satisfying the assumptions of Prop. 2 is non-negative. The GMM estimator is efficient
in the statistical model implied by the moment conditions. Thus, if the chosen moment
conditionsaresemiparametricallyefficient,theoraclepolicywillachievethesemiparametric
efficiency bound [Ackerberg et al., 2014, Newey, 1990, Chamberlain, 1987].
p
Proposition 4. Suppose that (i) θ is estimated using Eq. 2, (ii) Assumption 6 holds, and
T
(iii) the conditions of Prop. 2 hold. Then, for any data collection policy π, R pπq ě 0.
8
For any fixed policy π with κ “ κ for some constant κ ‰ κ˚ suffers constant regret
κ T
because by Assumption 6, we have R pπ q ą 0. The following lemma shows that policies
8 κ
p
with κ Ñ κ˚ achieve zero regret, motivating online data collection.
T
Lemma 1. Suppose that the conditions of Prop. 2 hold. Any data collection policy π such
p
that κ Ñ κ˚ has zero regret: R pπq “ 0.
T 8
?
Proof. By Prop. 2, we have T pβ ´β˚q Ñd Np0,V pκ˚qq and therefore, R pπq “ 0.
T ˚ 8
4 Online Data Collection
Inthissection, weproposetwoonlinedatacollectionpolicies: Explore-then-Commit(ETC)
and Explore-then-Greedy (ETG), that have zero regret. In both policies, we allocate the
data collection budget based on an estimate of the oracle simplex.
9Input: Horizon T P N, Batch size S,
Exploration e P p0,1q
1 p k Ð κ ctr, Rounds J Ð tTp1 S´equ;
2 n Ð 0;
Input: Horizon T P N, Exploration 3 for H P rTe,lSo,oo.m..o,ooSns do
e P p0,1q Jtimes
1 n Ð Te; 4 n Ð n`H;
p
2 Collect n samples s.t. κ n “ κ ctr; 5 Collect H samples s.t. κ n “ k;
3 θp n Ð argmin θPΘQp npθ,pηp t´1qn t“1q; 6 θp n Ð argmin θPΘQp npθ,pηp t´1qn t“1q;
p p p p p p
54 Ck oÐ llea cr tg rm emin aκ iP n∆ inD gV sn ap mθ n p, lκ eq s;
such that
7
8
pk kn ÐÐ pa rorg jpm p
k
nin ,∆κ ˜P j∆ `D 1qV ;npθ n,κq;
p ˜
κ T “ projpk,∆ eq; 9 end
p p p p
6 θ T Ð argmin θPΘQ Tpθ,pηp t´1qT t“1q; 10 θ T “ argmin θPΘQ Tpθ,pηp t´1qT t“1q;
p p
Output: f pθ q Output: f pθ q
tar T tar T
(a) The Explore-then-Commit policy. (b) The Explore-then-Greedy policy.
Figure 2: Algorithms for OMS-ETC and OMS-ETG.
4.1 OMS via Explore-then-Commit (OMS-ETC)
The Explore-then-Commit (ETC) policy is similar in spirit to the ETC strategy in multi-
armed bandits [Lattimore and Szepesva´ri, 2020, Ch. 6]. We denote this policy by π
ETC
(Fig. 2a). The ETC policy is characterized by a horizon T and an exploration fraction e P
p0,1q. In the explore phase, we collect Te samples by querying the data sources uniformly,
p
i.e., κ “ κ . Using the exploration samples, we estimate the model parameters θ, and
Te ctr
use them to estimate the asymptotic variance of some fixed policy π as a function of κ. Let
κ
p p
the estimated variance be V pθ,κq (Definition 3). Next, we estimate the oracle simplex
Te
p p p
κ˚ as follows: k “ argmin V pθ,κq. In the commit phase, we collect the remaining
Te κ Te
p
Tp1 ´ eq samples such that the final selection simplex κ is as close to k as possible:
T Te
p ˜ ˜
κ “ projpk ,∆ q, where ∆ :“ teκ `p1´eqκ : κ P ∆ u is the set of values κ can
T Te e e ctr D T
achieve with the remaining budget. As stated in Remark 1, the order in which the data
sources are queried in the two phases does not affect our results.
Definition 3 (Variance estimator). For any κ P ∆ , we define
D
p p
G pθ,κq :“ w pκqdG pθq,
T G T
p p
Ω pθ,κq :“ w pκqdΩ pθq,
T Ω T
” ı
p p p p ´1
Σ pθ,κq :“ GJpθ,κqΩ´1pθ,κqG pθ,κq ,
T T T T
p p
V pθ,κq :“ ∇ f pθqJΣ pθ,κq∇ f pθq, (6)
T θ tar T θ tar
p p
where G pθq and Ω pθq are defined in Prop. 3. The matrices w pκq and w pκq (see Eq. 47
T T G Ω
p
in Appendix C for the expression) appropriately reweight the variance estimator V in Eq. 4
T
p p
such that V pθ ,κq estimates the variance that results from the fixed policy π .
T T κ
10p p
We can use V pθ ,κq to consistently estimate κ˚ (see Appendix C for the proof):
T T
p p p
Lemma 2. Let k :“ argmin V pθ ,κq be the estimated oracle simplex. Suppose
T κP∆D T T
that (i)”the condiıtions of Prop. 1 hold, (ii) Assumption 6 holds, and (iii) @i P rMs,j P
rDs,B ψpiq pθ,ηq satisfies Property 1. Then p k Ñp κ˚.
θj t T
Assumption 7 (Exploration). The exploration e depends on T such that (i) (Asymptoti-
?
cally negligible) e “ op1q; and (ii) Te Ñ 8 as T Ñ 8 (e.g., e “ 1{ T).
Theorem 1 (ETC Regret). Suppose that the conditions of Prop. 2 and Lemma 2 hold, and
Assumption 7 holds. Then, R pπ q “ 0.
8 ETC
p
Proof. We show that κ Ñ κ˚ and then apply Lemma 1. Since Te Ñ 8, by Lemma 2,
T
p k Ñp κ˚. Since e P op1q, the set ∆˜ asymptotically covers the entire simplex ∆ . Thus,
Te e D
˜ p
sup }projpκ,∆ q´κ} Ñ 0.
e
κP∆D
Therefore, for κ “ projpp k ,∆˜ q, we have }κ ´p k } Ñp 0. Since p k Ñp κ˚, we also have
T Te e T Te Te
p
κ Ñ κ˚. Applying Lemma 1 completes the proof.
T
4.2 OMS via Explore-then-Greedy (OMS-ETG)
The Explore-then-Greedy (ETG) policy, denoted by π , extends the ETC policy by
ETG
repeatedly updating the estimate of the oracle simplex instead of committing to a fixed
value after exploration (Fig. 2b). The ETG policy is characterized by a horizon T, an
exploration fraction e P p0,1q, and a batch size S. Like ETC, we first explore and collect
Te samples by querying the data sources uniformly: κ “ κ . We collect the remaining
Te ctr
Tp1´eq samples in batches of S samples at a time, i.e., there are J :“ pTp1´eqq{S rounds
after exploration. After each round j P t0,...,Ju (j “ 0 denotes exploration), we update
p p p
ourestimateoftheoraclesimplex: fort
j
:“ pTe`jS !q,wecomputek
tj
“) argmin κV tjpθ tj,κq.
The set of values that κ can achieve is
∆˜
“
tjκtj`Sκ
: κ P ∆ . In the subsequent
tj`1 j`1 tj`1 D
p
round, we (greedily) query the data sources to get as close as possible to k : we collect the
tj
p ˜
next S samples such that κ “ projpk ,∆ q. The proofs are deferred to Appendix D.
tj`1 tj j`1
In Theorem 2, we show zero regret when the number of rounds J is finite.
Theorem 2. Suppose that (i) the conditions of Theorem 1 hold and (ii) (Finite rounds)
lim S{T “ r for some constant r P p0,1q. Then, R pπ q “ 0.
TÑ8 8 ETG
Next, under the assumption of strongly consistent nuisance estimation, we prove zero
regret for any batch size S (Theorem 3). Thus, S can depend on T such that S{T “ op1q.
?
For example, we can set S “ s for some constant s or S — T.
Lemma 3. Suppose that (i) the conditions of Lemma 2 hold and (ii) (Nuisance strong
consistency) }ηp ´η˚} a Ñ.s. 0. Then θp a Ñ.s. θ˚ and p k a Ñ.s. κ˚.
t´1 T T
Theorem 3. Suppose that (i) the conditions of Theorem 1 hold and (ii) the conditions of
Lemma 3 hold. Then, for any batch size S, R pπ q “ 0.
8 ETG
11Remark 2. Lemma 3 requires strongly consistent nuisance estimators. Almost sure con-
vergence guarantees exist for some nonparametric problems [Wu et al., 2020, Walk, 2010,
Blondin, 2007, Francisco-Fern´andez et al., 2003, Liero, 1989, Cheng, 1984]. We also
illustrate how non-asymptotic tail bounds from statistical learning theory along with the
Borel–Cantelli lemma can be used to show strong consistency (see Appendix G).
The ETG policy can be further generalized to an ϵ-greedy strategy (Fig. 13 in Ap-
pendix D). This policy is characterized by an exploration policy pϵ q8 where ϵ P r0,1s.
t t“1 t
At each time t, with probability ϵ , we select a data source uniformly at random (i.e.,
t
explore) and act greedily with probability p1´ϵ q.
t
ř
Theorem 4. Let pϵ q8 be a non-increasing sequence and E “ T ϵ . Suppose that (i)
t t“1 T t“1 t
the conditions of Prop. 2 hold; (ii) the conditions of Lemma 3 hold; and (iii) E “ opTq and
T
E Ñ 8 (e.g., ϵ — 1{t). Then, the ϵ-greedy policy suffers zero regret: R pπ q “ 0.
T t 8 ϵ-greedy
The ϵ-greedy policy does not require the horizon T to be specified in advance (unlike
ETC and ETG, where the exploration depends on T). This is useful for performing time-
uniform inference, enabling the agent to adaptively stop or continue their data collection
(we discuss this in more detail in Section 6).
5 OMS with a Cost Structure
In many real-world settings, the agent must pay a different cost to query each data source.
We adapt OMS-ETC and OMS-ETG to this setting where a cost structure is associated
with the data sources in D and show that these policies still have zero asymptotic regret.
Wedenotethe(known)budgetbyB P Nandthecostvectorbyc P R|D|, wherec isthecost
ą0 i
of querying the data source Ppiq P D. Due to the cost structure, the horizon T is a random
variable dependent on π with T “ maxtt P N : tpκJcq ď Bu. The setting in Section 3 is a
t
special case with @i, c “ 1 and T “ B. The proofs are deferred to Appendix E.2.
i
Example 4 (Combining observational datasets). Consider the task of estimating the ATE
of a binary treatment X on an outcome Y where an unconfounded dataset is combined with
a cheaper confounded dataset [Yang and Ding, 2019] (see the causal graph in Fig. 1c). For
D “ tPpU,W,X,Yq, PpW,X,Yqu, the moment conditions are:
» fi » ` ˘ fi
s
t,1
ψ
AIPW
tW`t,U tu,X t,Y t;η˘p1q ´β
– fl – fl
g tpθq “ s
t,1
d ψ AIPW`W t,X t,Y t;ηp2q ˘´α ,
1´s ψ W ,X ,Y ;ηp2q ´α
t,1 AIPW t t t
where ψ is defined in Eq. 3, θ “ rβ,αsJ, and f pθq “ β. The cost structure is
AIPW tar
c “ rc ,c sJ with c ą c .
1 2 1 2
Proposition 5. Suppose that the conditions of Prop. 2 hold. Then,
´ ¯
? ` ` ˘˘
B βp ´β˚ Ñd N 0,V pκ q¨ κJc .
T κ8 ˚ 8 8
12? ?
We scale by B instead of T to make compariso“ns acros`s po˘li‰cies meaningful. The
oracle simplex is now defined as κ˚ :“ argmin V pκq¨ κJc and the asymptotic
κP∆D ˚
regret of a data collection policy π is now
´ ´ ¯¯
? ` ˘
R pπq “ AMSE B βp pπq ´β˚ ´V pκ˚q¨ pκ˚qJc .
8 T ˚
OMS-ETC-CS (OMS-ETC with cost structure), denoted by π extends OMS-ETC to
ETC-CS
this setting (Fig. 6a in Appendix E). We use Be budget to expYlore]and estimate the oracle
` ˘
p p
simplex κ˚ by k “ argmin Vpθ ,κq κJc , where T “ Be and κ “ κ . With
κP∆D Te e κJ c Te ctr
Te
p
the remaining budget, we collect samples such that κ gets as close as possible to k.
T
Proposition 6. Suppose that the conditions of Prop. 2 and Lemma 2 hold. If e “ op1q
and Be Ñ 8 as B Ñ 8, then R pπ q “ 0.
8 ETC-CS
Next, we propose OMS-ETG-CS (OMS-ETG with cost structure) to extend OMS-ETG
to this setting (Fig. 6b in Appendix E). We first explore using budget Be. The remaining
p
budget is used in batches of size S. After each round, we update the estimate k of the
p
oracle simplex, and collect samples to get as close to k as possible.
Proposition 7. Suppose that the conditions of Prop. 2 and Lemma 3 hold. If e “ op1q
and Be Ñ 8 as B Ñ 8, then R pπ q “ 0.
8 ETG-CS
6 Asymptotic Confidence Sequences
In Section 3.3, we showed how to construct asymptotically valid confidence intervals (CIs)
for the target parameter β˚ (Prop. 3). One limitation of CIs is that they are only valid at a
pre-specifiedhorizonT. Inthissection, wedescribehowtoconstructasymptoticconfidence
sequences(Theorem5)thatarevalidatalltimesteps[Waudby-Smithetal.,2021]. Inrecent
work, Dalal et al. [2024] have also developed AsympCS for the double/debiased machine
learning framework (with i.i.d. data). The proofs are deferred to Appendix F.
Definition4(Confidencesequence). Wesaythatpµp ˘C¯˚q8 isatwo-sided(non-asymptotic)
t t t“1
p1´αq-confidence sequence for parameter µ if
` ˘
P @t P N : µ P pµp ˘C¯˚q ě 1´α.
t t
Confidencesequences(CSs)areatime-uniformcounterpartofconfidenceintervals: they
allow for inference at all time steps simultaneously (and stopping times). Thus, the horizon
T need not be decided in advance and the practitioner can adaptively stop or continue their
experiment (see Ramdas et al. [2023], Howard et al. [2021] for further discussion). Waudby-
Smith et al. [2021] define asymptotic confidence sequences (AsympCS), a time-uniform
counterpart of CLT-style asymptotic confidence intervals.
Definition 5 (AsympCS [Waudby-Smith et al., 2021, Definition 2.1]). Let T be a totally
ordered infinite set (denoting time) that has a minimum value t P T. We say that the
0
p p
intervals pθ t ´ L t,θ t ` U tq tPT with non-zero bounds L t,U t ą 0 form a p1 ´ αq-asymptotic
13confidence sequence (AsympCS) if there exists a (typically unknown) nonasymptotic CS
p p
pθ ´L˚,θ `U˚q satisfying
t t t t tPT
´ ¯
p p
P @t P T : θ P pθ ´L˚,θ `U˚q ě 1´α,
t t t t t
such that L ,U become arbitrarily precise almost-sure approximations to L˚,U˚:
t t t t
L˚{L a Ñ.s. 1 and U˚{U a Ñ.s. 1.
t t t t
Assumption 8 (Nuisance estimation). For all i P rMs, (a) (Neyman orthogonality)
ş
@η, B rErψ tpiq pθ˚,η˚ `arpη ´ η˚qqs|
r“0
“ 0; (b) For R
t
:“ 01 B r2E t´1rψ tpiq pθ˚,η˚ ` rpηp
t´1
´
η˚qqsdr, R “ o p logt{tq; (c) sup ErR1`δs ă 8 for some δ ą 0; and (d) For some
t a.s. t t
γ ą 0, }ηp ´η˚} “ o pt´γq.
t´1 a.s.
Theorem 5. Suppose that (i) the Conditions of Lemma 3 hold; (ii) Assumption 8 holds;
and (iii) κ a Ñ.s. κ˜ for some constant κ˜ P ∆ . Then, for any ρ P R and α P p0,1q,
T D ą0
¨ ˛
g
˚ f ˜ ¸ ˜c ¸‹
˚ ˇ ˇ f p p ‹
P˚
˚@t P N :
ˇ ˇβp ´β˚ˇ
ˇ ď
etV tρ2 `1
log
tV tρ2 `1
`o
logt ‹
‹ ě 1´α,
˚ t t2ρ2 α2 a.s. t ‹
˝ ‚
loooooooooooooooooomoooooooooooooooooon
:“C¯
t
p
where V is the estimated variance defined in Eq. 4, and ρ determines the time step at which
t
¯
C is tightest [Waudby-Smith et al., 2021, Sec. B.2].
t
Assumptions 8(b, d) require strong consistency rates for the nuisance estimators (see
Remark 2 for more discussion). Condition (iii) requires that the selection simplex converges
almost surely to a constant. This is trivially satisfied for a fixed policy and under the
conditions of Theorem 4, this holds for the ϵ-greedy policy with κ a Ñ.s. κ˚.
T
7 Experiments
7.1 Synthetic data
In this section, we evaluate our data collection strategies on the two-sample IV LATE
estimation task (Example 2) with synthetic data generated from a nonlinear causal model
(Fig. 3). The nonlinearities are generated using random Fourier features [Rahimi and
Recht, 2007] that approximate a function drawn from a Gaussian Process with a squared
exponential kernel (see Appendix H.1 for more details). For nuisance estimation, we use a
multilayer perception (MLP) [Goodfellow et al., 2016, Sec. 6] with two hidden layers and 64
neurons each, trained with early stopping [Goodfellow et al., 2016, Sec. 7.8]. We compare
the MSE of the various policies using relative regret:
MSEpπq ´MSEporacle;η˚q
Relative regret “ RRpπq :“ ˆ100%,
MSEporacle;η˚q
141.0
0.8
0.6
etc_0.1 etc_0.2 etg_0.1 etg_0.2 fixed oracle-
0.4
Relative regret vs Horizon Coverage vs Horizon CI size vs Horizon
0.2
100 6.25
98
90 0.0 0.0 0.2 0.4 0.6 6.000.8 1.0
80 96 5.75
70 94 5.50
60 5.25
92
50 5.00
40 90 4.75
4000 5000 6000 7000 8000 9000 10000 4000 5000 6000 7000 8000 9000 10000 4000 5000 6000 7000 8000 9000 10000
Horizon T (total samples collected) Horizon T (total samples collected) Horizon T (total samples collected)
(a) Relative regret (b) Coverage (c) CI size
Figure 3: Results for the two-sample IV LATE estimation task (Example 2) for a nonlinear
causal model where MLPs are used for nuisance estimation (error bars denote 95% CIs). In
this case, significant bias is incurred due to nuisance estimation even at large horizons. The
online data collection policies outperform the fixed policy in terms of regret and coverage.
where MSEporacle;η˚q is the MSE of the oracle policy that uses the true nuisances η˚.
The labels etc x and etg x in the plots (Fig. 3) refer to the ETC and ETG policies with
exploration e “ x. For the ETG policies, we set the batch size S such that S{pTp1´eqq “
p
0.1. Thus, the estimate of the oracle simplex k is updated every 10% of the horizon T after
t
exploration. The label fixed refers to a fixed policy that queries each data source equally
with κ “ r0.5,0.5sJ. We use oracle-ηp to denote the oracle policy that uses estimated
T
nuisancefunctions(insteadofthetruenuisancesη˚). Forcomputationalreasons, weretrain
the nuisance estimators in batches (rather than after every time step).
In terms of relative regret (Fig. 3a), we observe that even oracle-ηp has « 50% relative
regret, showing substantial bias due to nuisance estimation. The online policies (ETC and
ETG) outperform the fixed policy, with ETG having similar relative regret as oracle-ηp.
Moreover, etg 0.1outperformsetc 0.1, demonstratingtheadvantageofrepeatedlyupdating
the estimate of the oracle simplex. In terms of coverage (Fig. 3b), the online policies
outperform the fixed policy, and get close to the nominal coverage of 95% at large horizons.
Finally, we observe that the size of the confidence intervals (Fig. 3c) for the etg policies is
significantly smaller than the confidence intervals (CIs) of etc and oracle-ηp.
We also perform experiments for Examples 2, 3, and 4 with synthetic data generated
from linear causal models (see Appendix H.2), observing that the ETC and ETG policies
have lower relative regret than the fixed policy in all cases. Since we use correctly specified
parametric nuisance estimators, the bias due to nuisance estimation is substantially lower
in this case, with the ETG policy achieving nearly zero relative regret at large horizons.
7.2 Real-world data
JTPA dataset. The National Job Training Partnership Act (JTPA) study examines the
effect of a job training program on future earnings and has been analyzed in several prior
works [Glynn and Kashin, 2018, Donald et al., 2014, Abadie et al., 2002, Bloom et al.,
1997]. The data follows the IV causal model (see Example 2 and Fig. 1a) with a binary
IV Z, binary treatment X, a vector of covariates W, and a real-valued outcome Y. We
use the dataset from Glynn and Kashin [2019], which contains N “ 4384 samples. In
15
)%(
terger
evitaleR
)%(
egarevoC
)T
yb
delacS(
ezis
IC1.0
0.8
0.6
etc_0.1 etc_0.2 etg_0.1 etg_0.2 fixed oracle
0.4
Scaled MSE vs Budget Scaled MSE vs Budget
0.2
0.70
30.0 0.0 0.65
0.0 0.2 0.4 0.6 0.8 1.0
27.5 0.60
25.0 0.55
22.5 0.50
0.45
20.0
0.40
17.5
0.35
15.0 0.30
2000 3000 4000 5000 6000 7000 8000 4000 6000 8000 10000 12000 14000 16000
Budget B Budget B
(a) JTPA data (b) COPD data
Figure 4: Results on two real-world causal effect estimation tasks (error bars denote 95%
CIs). In both cases, we observe that the online data collection policies outperform the fixed
policy (as the budget increases).
this dataset, Z indicates whether the individual was randomly offered training, X denotes
program participation, Y denotes future earnings, and W contains six covariates which
include variables like race ´and age. We simulate the t¯wo-sample LATE estimation setting
p p p
in Example 2 with D “ P pW,Z,Yq,P pW,Z,Xq , where P denotes the empirical
N N N
distribution over the N samples. The true LATE and oracle simplex are computed on
the full dataset with MLP-based nuisance estimators and cross-fitting with k “ 2 folds
[Chernozhukov et al., 2018], averaged over 2000 runs. We compare the scaled MSE (T ˆ
MSE) of our proposed policies with a fixed policy that queries both data sources uniformly
with κ “ r0.5,0.5sJ (Fig. 4a). We observe that the MSE of the fixed policy is nearly twice
T
as large as the oracle policy. By contrast, we see that the ETC and ETG policies match
the oracle policy at all horizons.
COPD dataset. We test our strategies on datasets used to evaluate the effect of chronic
obstructive pulmonary disease (COPD) on the development of herpes zoster (HZ) [Lin
and Chen, 2014]. We use the dataset released by Yang and Ding [2019], which follows
the setting of Example 4 (where an unconfounded dataset is combined with a confounded
dataset). The treatment X P t0,1u and outcome Y P t0,1u denote the presence of COPD
and HZ, respectively. We have two datasets: (i) The validation dataset with N “
val
1148 samples of pU,W,X,Yq and (ii) The main dataset with N “ 42430 samples of
main
pW,X,Yq. The covariates W include variables like age, presence of liver disease, etc. and U
includes variables like cigarette and alcohol consumption which are known to be important
confounders (but are missing in the main dataset).
p p p
To test our methods, we use D “ pP pU,W,X,Yq,P pW,X,Yqq, where P and
val main val
p
P denote the empirical distributions over the validation and main datasets. We apply
main
a cost structure of c “ r4,1s, i.e., a query to the validation dataset costs four times that
of the main dataset. The dataset contains the propensity scores (not the covariates).
Since propensity scores suffice for removing confounding bias [Herna´n and Robins, 2010,
Sec. 15.2], we use them as covariates with linear nuisance estimators. The true ATE and
oracle simplex are computed on the full dataset using cross-fitting with k “ 2 folds. We
16
)ESM×B(
ESM
delacS
)ESM×B(
ESM
delacScompare the regret of our proposed adaptive policies to that of a fixed policy that only
queries the first data source with κ “ r1,0sJ (Fig. 4b). We observe that both the fixed
T
and online policies have higher MSE than the oracle at all budgets. At smaller budget sizes,
we do not observe a significant difference with the fixed policy. However, as the budget
increases, we observe that the online policies substantially outperform the fixed policy and
are much closer to the oracle.
8 Conclusion
Our work presents a semiparametric framework for statistical inference that accounts for
sequential data collection decisions. Aiming to efficiently estimate a given target parame-
ter, we present two online data collection policies, OMS-ETC and OMS-ETG, and prove
that both achieve zero asymptotic regret relative to the oracle policy. One limitation of
our theoretical results is that they do not distinguish between OMS-ETC and OMS-ETG.
Overcoming this limitation would potentially require higher-order or finite-sample analysis.
Another limitation is that our results hold pointwise rather than uniformly in the proba-
bility space, which could lead to different optimal rates (e.g., in multi-armed bandits, bet-
ter minimax optimal rates are achieved when considering pointwise or instance-dependent
bounds [Lattimore and Szepesv´ari, 2020, Ch. 16]). In future work, we aim to extend our
work to the contextual selection setting where the data source can be selected based on
variables revealed in the same time step. We also aim to extend our analysis beyond
scalar parameters to targets that are multivariate or nonparametric as well as parameters
identified by conditional moment restrictions.
Acknowledgments
We gratefully acknowledge the NSF (FAI 2040929 and IIS2211955), UPMC, Highmark
Health, Abridge, Ford Research, Mozilla, the PwC Center, Amazon AI, JP Morgan Chase,
the Block Center, the Center for Machine Learning and Health, and the CMU Software
Engineering Institute (SEI) via Department of Defense contract FA8702-15-D-0002, for
their generous support of ACMI Lab’s research. We thank Ian Waudby-Smith and seminar
participants at Indiana University for helpful comments.
References
A. Abadie, J. Angrist, and G. Imbens. Instrumental variables estimates of the effect of
subsidized training on the quantiles of trainee earnings. Econometrica, 2002.
D. Ackerberg, X. Chen, J. Hahn, and Z. Liao. Asymptotic efficiency of semiparametric
two-step gmm. Review of Economic Studies, 2014.
E. Ailer, J. Hartford, and N. Kilbertus. Sequential underspecified instrument selection for
cause-effect estimation. arXiv preprint arXiv:2302.05684, 2023.
J. Angrist and A. B. Krueger. The effect of age at school entry on educational attainment:
an application of instrumental variables with moments from two samples, 1990.
17S. Athey, R. Chetty, and G. Imbens. Combining experimental and observational data
to estimate treatment effects on long-term outcomes. arXiv preprint arXiv:2006.09676,
2020.
J. Attenberg, P. Melville, F. Provost, and M. Saar-Tsechansky. Selective data acquisition
for machine learning. Cost-sensitive Machine Learning, 2011.
E. Bareinboim and J. Pearl. Causal inference and the data-fusion problem. Proceedings of
the National Academy of Sciences, 2016.
A. Belloni, V. Chernozhukov, I. Fernandez-Val, and C. Hansen. Program evaluation and
causal inference with high-dimensional data. Econometrica, 2017.
R. Bhattacharya, R. Nabi, and I. Shpitser. Semiparametric inference for causal effects in
graphical models with hidden variables. Journal of Machine Learning Research, 2022.
P.J.Bickel, C.A.Klaassen, P.J.Bickel, Y.Ritov, J.Klaassen, J.A.Wellner, andY.Ritov.
Efficient and adaptive estimation for semiparametric models. Springer, 1993.
P. Billingsley. Probability and Measure. Wiley Series in Probability and Statistics. Wiley,
1995.
D. Blondin. Rates of strong uniform consistency for local least squares kernel regression
estimators. Statistics & probability letters, 2007.
H. S. Bloom, L. L. Orr, S. H. Bell, G. Cave, F. Doolittle, W. Lin, and J. M. Bos. The
benefits and costs of jtpa title ii-a programs: Key findings from the national job training
partnership act study. Journal of human resources, 1997.
M. Buchinsky, F. Li, and Z. Liao. Estimation and inference of semiparametric models using
data from several sources. Journal of Econometrics, 2022.
S. Burgess, F. Dudbridge, and S. G. Thompson. Combining information on multiple instru-
mental variables in mendelian randomization: comparison of allele score and summarized
data methods. Statistics in Medicine, 2016.
P. Carneiro, S. Lee, and D. Wilhelm. Optimal data collection for randomized control trials.
The Econometrics Journal, 2020.
G. Chamberlain. Asymptotic efficiency in estimation with conditional moment restrictions.
Journal of econometrics, 1987.
Y. Chandak, S. Shankar, V. Syrgkanis, and E. Brunskill. Adaptive instrument design for
indirect experiments. In International Conference on Learning Representations, 2023.
C. Chen, P. Han, and F. He. Improving main analysis by borrowing information from
auxiliary data. Statistics in Medicine, 2022.
J. Chen and D. M. Ritzwoller. Semiparametric estimation of long-term treatment effects.
Journal of Econometrics, 2023.
18P. E. Cheng. Strong consistency of nearest neighbor regression function estimators. Journal
of Multivariate Analysis, 1984.
V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, W. Newey, and
J. Robins. Double/debiased machine learning for treatment and structural parameters.
The Econometrics Journal, 2018.
V. Chernozhukov, J. C. Escanciano, H. Ichimura, W. K. Newey, and J. M. Robins. Locally
robust semiparametric estimation. Econometrica, 2022.
D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active learning with statistical models.
Journal of Artificial Intelligence Research, 1996.
B. Colnet, I. Mayer, G. Chen, A. Dieng, R. Li, G. Varoquaux, J.-P. Vert, J. Josse, and
S. Yang. Causal inference methods for combining randomized trials and observational
studies: a review. Statistical Science, 2024.
T. Cook, A. Mishler, and A. Ramdas. Semiparametric efficient inference in adaptive ex-
periments. arXiv preprint arXiv:2311.18274, 2023.
M. Cso¨rgo¨. On the strong law of large numbers and the central limit theorem for martin-
gales. Transactions of the American Mathematical Society, 1968.
A. Dalal, P. Blo¨baum, S. Kasiviswanathan, and A. Ramdas. Anytime-valid infer-
ence for double/debiased machine learning of causal parameters. arXiv preprint
arXiv:2408.09598, 2024.
S. G. Donald, Y.-C. Hsu, and R. P. Lieli. Testing the unconfoundedness assumption via
inverse probability weighted estimators of (l) att. Journal of Business & Economic
Statistics, 2014.
M. D’Orazio, M. Di Zio, and M. Scanu. Statistical matching: Theory and practice. John
Wiley & Sons, 2006.
K. Evans, B. Sun, J. Robins, and E. J. T. Tchetgen. Doubly robust regression analysis for
data fusion. Statistica Sinica, 2021.
M. H. Farrell, T. Liang, and S. Misra. Deep neural networks for estimation and inference.
Econometrica, 2021.
M. Francisco-Ferna´ndez, J. M. Vilar-Ferna´ndez, and J. A. Vilar-Fern´andez. On the uniform
strong consistency of local polynomial regression under dependence conditions. Commu-
nications in Statistics-Theory and Methods, 2003.
M. Fro¨lich. Nonparametric iv estimation of local average treatment effects with covariates.
Journal of Econometrics, 2007.
I. R. Fulcher, I. Shpitser, S. Marealle, and E. J. Tchetgen Tchetgen. Robust inference on
population indirect causal effects: the generalized front door criterion. Journal of the
Royal Statistical Society Series B: Statistical Methodology, 2020.
19W. Gao, F. Xu, and Z.-H. Zhou. Towards convergence rate analysis of random forests for
classification. Artificial Intelligence, 2022.
A. Ghassami, A. Yang, D. Richardson, I. Shpitser, and E. T. Tchetgen. Combining ex-
perimental and observational data for identification and estimation of long-term causal
effects. arXiv preprint arXiv:2201.10743, 2022.
A. N. Glynn and K. Kashin. Front-door versus back-door adjustment with unmeasured
confounding: Bias formulas for front-door and hybrid adjustments with application to a
job training program. Journal of the American Statistical Association, 2018.
A. N. Glynn and K. Kashin. Replication Data for: Front-Door Versus Back-Door
Adjustment With Unmeasured Confounding: Bias Formulas for Front-Door and Hy-
brid Adjustments With Application to a Job Training Program, 2019. URL https:
//doi.org/10.7910/DVN/G7NNUL.
I. Goodfellow, Y. Bengio, and A. Courville. Deep learning. MIT press, 2016.
T. Gorbach, X. de Luna, J. Karvanen, and I. Waernbaum. Contrasting identifying as-
sumptions of average causal effects: Robustness and semiparametric efficiency. Journal
of Machine Learning Research, 2023.
B. S. Graham, C. C. d. X. Pinto, and D. Egel. Efficient estimation of data combination
modelsbythemethodofauxiliary-to-studytilting(ast). Journal of Business & Economic
Statistics, 2016.
E. Graham, M. Carone, and A. Rotnitzky. Towards a unified theory for semiparametric
data fusion with individual-level data, 2024.
W. Guo, S. L. Wang, P. Ding, Y. Wang, and M. Jordan. Multi-source causal inference
using control variates under outcome selection bias. Transactions on Machine Learning
Research, 2022.
S. Gupta, Z. C. Lipton, and D. Childers. Efficient online estimation of causal effects by
deciding what to observe. In Advances in Neural Information Processing Systems, 2021a.
S. Gupta, Z. C. Lipton, and D. Childers. Estimating treatment effects with observed
confounders and mediators. In Uncertainty in Artificial Intelligence. PMLR, 2021b.
L. Gyo¨rfi, M. Kohler, A. Krzyzak, H. Walk, et al. A distribution-free theory of nonpara-
metric regression. Springer, 2002.
V. Hadad, D. A. Hirshberg, R. Zhan, S. Wager, and S. Athey. Confidence intervals for
policy evaluation in adaptive experiments. The National Academy of Sciences, 2021.
J. Hahn, K. Hirano, and D. Karlan. Adaptive experimental design using the propensity
score. Journal of Business & Economic Statistics, 2011.
L. P. Hansen. Large sample properties of generalized method of moments estimators.
Econometrica: Journal of the Econometric Society, 1982.
20E. H¨ausler and H. Luschgy. Stable convergence and stable limit theorems. Springer, 2015.
L. Henckel, E. Perkovi´c, and M. H. Maathuis. Graphical criteria for efficient total effect
estimation via adjustment in causal linear models. arXiv preprint arXiv:1907.02435,
2019.
M. A. Herna´n and J. M. Robins. Causal inference, 2010.
S. R. Howard, A. Ramdas, J. McAuliffe, and J. Sekhon. Time-uniform, nonparametric,
nonasymptotic confidence sequences. The Annals of Statistics, 2021.
W. Hu, R. Wang, W. Li, and W. Miao. Paradoxes and resolutions for semiparametric
fusion of individual and summary data. arXiv preprint arXiv:2210.00200, 2022.
X. Hu, P. Zhou, P. Li, J. Wang, and X. Wu. A survey on online feature selection with
streaming features. Frontiers of Computer Science, 2018.
P. Hu¨nermund and E. Bareinboim. Causal inference and data fusion in econometrics. arXiv
preprint arXiv:1912.09104, 2019.
G. Imbens, N. Kallus, X. Mao, and Y. Wang. Long-term causal inference under persistent
confounding via data combination. arXiv preprint arXiv:2202.07234, 2022.
G. W. Imbens and D. B. Rubin. Causal inference in statistics, social, and biomedical
sciences. Cambridge University Press, 2015.
D. Jeong, S. Aggarwal, J. Robinson, N. Kumar, A. Spearot, and D. S. Park. Exhaustive
or exhausting? evidence on respondent fatigue in long surveys. Journal of Development
Economics, 2023.
N.Kallus, X.Mao, andM.Uehara. Localizeddebiasedmachinelearning: Efficientinference
on quantile treatment effects and beyond. Journal of Machine Learning Research, 2024.
M. Kato, S. Yasui, and K. McAlinn. The adaptive doubly robust estimator for policy
evaluation in adaptive experiments and a paradox concerning logging policy. arXiv
preprint arXiv:2010.03792, 2020.
E. H. Kennedy. Semiparametric theory and empirical processes in causal inference. Statis-
tical causal inferences and their applications in public health research, 2016.
E. H. Kennedy. Semiparametric doubly robust targeted double machine learning: a review.
arXiv preprint arXiv:2203.06469, 2022.
Y.Kivva, E.Mokhtarian, J.Etesami, andN.Kiyavash. Revisitingthegeneralidentifiability
problem. In Uncertainty in Artificial Intelligence. PMLR, 2022.
M.KohlerandS.Langer. Ontherateofconvergenceoffullyconnecteddeepneuralnetwork
regression estimates. The Annals of Statistics, 2021.
T. Lattimore and C. Szepesv´ari. Bandit algorithms. Cambridge University Press, 2020.
21J. J. Lee and I. Shpitser. Identification methods with arbitrary interventional distributions
as inputs. arXiv preprint arXiv:2004.01157, 2020.
J. J. Lee, A. Ghassami, and I. Shpitser. A general identification algorithm for data fusion
problems under systematic selection. In Uncertainty in Artificial Intelligence, 2024.
S. Lee and E. Bareinboim. Causal effect identifiability under partial-observability. In
International Conference on Machine Learning. PMLR, 2020.
S. Lee and E. Bareinboim. Causal identification with matrix equations. Advances in Neural
Information Processing Systems, 2021.
H. H. Li. Efficient combination of observational and experimental datasets under general
restrictions on outcome mean functions. arXiv preprint arXiv:2406.06941, 2024.
H. H. Li and A. B. Owen. Double machine learning and design in batch adaptive experi-
ments. arXiv preprint arXiv:2309.15297, 2023.
S. Li and A. Luedtke. Efficient estimation under data fusion. arXiv preprint
arXiv:2111.14945, 2021.
W. Li, J. Liu, P. Ding, and Z. Geng. Identification and multiply robust estimation of
causal effects via instrumental variables from an auxiliary heterogeneous population.
arXiv preprint arXiv:2407.18166, 2024.
X. Li, W. Miao, F. Lu, and X.-H. Zhou. Improving efficiency of inference in clinical trials
with external control data. Biometrics, 2021.
X. Li, Y. Li, Q. Cui, L. Li, and J. Zhou. Robust direct learning for causal data fusion.
arXiv preprint arXiv:2211.00249, 2022.
Y. Li and J. Oliva. Active feature acquisition with generative surrogate models. In Inter-
national Conference on Machine Learning. PMLR, 2021.
H. Liero. Strong uniform consistency of nonparametric regression function estimates. Prob-
ability theory and related fields, 1989.
H.-W. Lin and Y.-H. Chen. Adjustment for missing confounders in studies based on ob-
servational databases: 2-stage calibration combining propensity scores from primary and
validation data. American journal of epidemiology, 2014.
L. Lin, K. Khamaru, and M. J. Wainwright. Semi-parametric inference based on adaptively
collected data. arXiv preprint arXiv:2303.02534, 2023.
X. Lin, J. M. Tarp, and R. J. Evans. Data fusion for efficiency gain in ate estimation: A
practical review with simulations. arXiv preprint arXiv:2407.01186, 2024.
T. Morrison, M. Nguyen, M. Baiocchi, and A. B. Owen. Constrained design of a binary
instrument in a partially linear model. arXiv preprint arXiv:2406.05592, 2024.
W. K. Newey. Semiparametric efficiency bounds. Journal of applied econometrics, 1990.
22W.K.NeweyandD.McFadden. Largesampleestimationandhypothesistesting. Handbook
of econometrics, 1994.
J. Neyman. On the two different aspects of the representative method: The method of
stratifiedsamplingandthemethodofpurposiveselection. Journal of the Royal Statistical
Society, 1934.
J. Neyman. Optimal asymptotic tests of composite hypotheses. Probability and statsitics,
1959.
J. Pearl. Causality. Cambridge university press, 2009.
A. Rahimi and B. Recht. Random features for large-scale kernel machines. Advances in
Neural Information Processing Systems, 2007.
A. Rakhlin, K. Sridharan, and A. Tewari. Sequential complexities and uniform martingale
laws of large numbers. Probability theory and related fields, 2015.
A. Ramdas, P. Gru¨nwald, V. Vovk, and G. Shafer. Game-theoretic statistics and safe
anytime-valid inference. Statistical Science, 2023.
R. R. Ramsahai. Supplementary variables for causal estimation. Causality: Statistical
perspectives and applications, 2012.
G. Ridder and R. Moffitt. The econometrics of data combination. Handbook of economet-
rics, 2007.
A. Rotnitzky and E. Smucler. Efficient adjustment sets for population average causal
treatment effect estimation in graphical models. Journal of Machine Learning Research,
2020.
A. Rotnitzky, E. Smucler, and J. M. Robins. Characterization of parameters with a mixed
bias property. Biometrika, 2021.
M. Saar-Tsechansky, P. Melville, and F. Provost. Active feature-value acquisition. Man-
agement Science, 2009.
B. Settles. Active learning literature survey. In University of Wisconsin-Madison Depart-
ment of Computer Sciences, 2009.
X. Shi, Z. Pan, and W. Miao. Data integration in causal inference. Wiley Interdisciplinary
Reviews: Computational Statistics, 2023.
H. Shim, S. J. Hwang, and E. Yang. Joint active feature acquisition and classification with
variable-size set encoding. Advances in Neural Information Processing Systems, 2018.
K. Shinoda and T. Hoshino. Estimation of local average treatment effect by data combi-
nation. In AAAI Conference on Artificial Intelligence, 2022.
K. Shuai, S. Luo, W. Li, and Y. He. Identifying causal effects using instrumental variables
from the auxiliary population. arXiv preprint arXiv:2309.02087, 2023.
23T. Stu¨rmer, S. Schneeweiss, J. Avorn, and R. J. Glynn. Adjusting effect estimates for un-
measured confounding with validation data using propensity score calibration. American
journal of epidemiology, 2005.
B. Sun and W. Miao. On semiparametric instrumental variable estimation of average
treatment effects through data fusion. Statistica Sinica, 2022.
G. Tauchen. Diagnostic testing and evaluation of maximum likelihood models. Journal of
Econometrics, 1985.
S. Tikka, A. Hyttinen, and J. Karvanen. Causal effect identification from multiple incom-
plete data sources: A general search-based approach. arXiv preprint arXiv:1902.01073,
2019.
A. A. Tsiatis. Semiparametric theory and missing data. Springer, 2006.
A. W. Van der Vaart. Asymptotic Statistics. Cambridge University Press, 2000.
M. J. Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48.
Cambridge university press, 2019.
H. Walk. Strong laws of large numbers and nonparametric estimation. In Recent Devel-
opments in Applied Probability and Statistics: Dedicated to the Memory of Ju¨rgen Lehn.
Springer, 2010.
I. Waudby-Smith, D. Arbour, R. Sinha, E. H. Kennedy, and A. Ramdas. Time-uniform
centrallimittheory, asymptoticconfidencesequences, andanytime-validcausalinference.
arXiv preprint arXiv:2103.06476, 2021.
J. Witte, L. Henckel, M. H. Maathuis, and V. Didelez. On efficient adjustment in causal
graphs. Journal of Machine Learning Research, 2020.
A. Wu, K. Kuang, R. Xiong, M. Zhu, Y. Liu, B. Li, F. Liu, Z. Wang, and F. Wu. Learn-
ing instrumental variable from data fusion for treatment effect estimation. In AAAI
Conference on Artificial Intelligence, 2023.
Y. Wu, X. Wang, and N. Balakrishnan. On the consistency of the p–c estimator in a
nonparametric regression model. Statistical Papers, 2020.
S. Yang and P. Ding. Combining multiple observational data sources to estimate causal
effects. Journal of the American Statistical Association, 2019.
J. Zhao. Adaptive neyman allocation. arXiv preprint arXiv:2309.08808, 2023.
Q. Zhao, J. Wang, W. Spiller, J. Bowden, and D. S. Small. Two-sample instrumental
variable analyses using heterogeneous samples. Statistical Science, 2019.
Y. Zhao, K.-S. Jun, T. Fiez, and L. Jain. Adaptive experimentation when you can’t
experiment. arXiv preprint arXiv:2406.10738, 2024.
Z. Zhao and W. Yao. Sequential design for nonparametric inference. Canadian Journal of
Statistics, 2012.
24T. Zrnic and E. J. Cand`es. Active statistical inference. arXiv preprint arXiv:2403.03208,
2024.
25A Proof of consistency
Proposition 8 (MDS SLLN [Cso¨rgo¨, 1968, Theorem 1]). Let tX ,n P Nu be a martingale
n
d řifference sequence (MDS) and řb
1
ă b
2
ă ... Ñ 8 be a non-decreasing sequence such that
8 b´2ErX2s ă 8. Then b´1 n X a Ñ.s. 0.
i“1 i i n i“1 i
ř
Corollary 1. Let tX ,n P Nu be a MDS with sup ErX2s ă 8. Then n´1 n X a Ñ.s. 0.
n n n i“1 i
Proof. Apply Prop. 8 with b “ i.
i
Proposition 9 (Convergence of moments [Billingsley, 1995, Page 338]). Let r be a positive
integer. If X Ñd X and sup Er|X |r`ϵs ă 8, where ϵ ą 0, then Er|X|rs ă 8, and
n n n
ErXrs Ñ ErXrs.
n
p
Lemma 4. Let pX q8 be a sequence of non-negative random variables with (i) X Ñ 0
t t“1 ř t
and (ii) Dδ ą 0 such that sup ErX1`δs ă 8. Then T´1 T X Ñp 0.
t t t“1 t
Proof. By Markov’s inequality, for any ϵ ą 0,
˜ ¸
ř
1 ÿT T ErX s
P X ą ϵ ď t“1 t
t
T Tϵ
t“1
opTq
ď “ op1q, (7)
Tϵ
where (7) follows because Er}ηp ´η˚}s “ op1q (by Conditions (i, ii) and Prop. 9).
t´1
Lemma 5 (ULLN). Suppose that a pθ,ηq :“ apX ;θ,ηq satisfies Property 1. Let a pθ,ηq “
t t ˚
ErapX ;θ,ηqs and s P t0,1u be a H -measurable binary random variable. Then the
t t t´1
following uniform law of large numbers (ULLN) holds:
ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
supˇ s ta pθ,ηp q´a pθ,η˚quˇ Ñp 0.
ˇT t t t´1 ˚ ˇ
θPΘ
t“1
Proof. We prove the ULLN by a covering number argument 2 [Tauchen, 1985, Lemma 1].
Let tθ uK be a minimal δ-cover of Θ and B pθ q denotes the δ-ball around θ . By com-
k k“1 δ k k
pactness of Θ (Assumption 3b), K is finite. For the rest of the proof, for any θ P Θ, let θ
k
denote the element of the δ-cover such that θ P B pθ q.
δ k
2We use a covering number argument for convenience but it may be possible to weaken the conditions
of Property 1 by using the more general martingale ULLN in Rakhlin et al. [2015].
26By the triangle inequality,
ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
supˇ s ta pθ,ηp q´a pθ,η˚quˇ
ˇT t t t´1 ˚ ˇ
θPΘ
t“1 ˇ ˇ ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
ď supˇ s ta pθ,ηp q´a pθ ,ηp quˇ` maxˇ s ta pθ ,ηp q´a pθ ,η˚quˇ`
θ
ˇT t t t´1 t k t´1 ˇ kPrKsˇT t t k t´1 ˚ k ˇ
t“1 t“1
ÿT
1
max s |a pθ ,η˚q´a pθ,η˚q|
kPrKs T t ˚ k ˚
t“1 ˇ ˇ
1
ÿT ˇ
ˇ1
ÿT ˇ
ˇ
ď sup|a pθ,ηp q´a pθ ,ηp q|`maxˇ s ta pθ ,ηp q´a pθ ,η˚quˇ` (8)
lT
oo to “oo
1ooooθoooooot oooooomt´1 ooooooooot ooook oooot o´ oo1
on
lkPoorKooosoˇ oT
oooto
“oo1ooot ooooot ooook moot o´ oo1 oooooooo˚ ooook oooooooonˇ
T1 T2
max|a pθ ,η˚q´a pθ,η˚q|,
˚ k ˚
klPoroKoosoooooooooooomoooooooooooooooon
T3
where (8) follows because s P t0,1u. Next, we show that all three terms are o p1q.
t p
Term (T1).
ÿT ÿT
1 1
sup|a pθ,ηp q´a pθ ,ηp q| “ δ|LpX q| (9)
T
t t´1 t k t´1
T
t
θ
t“1 t“1
“ δErLpX qs`o p1q (10)
t a.s.
?
ď Lδ `o p1q, (11)
a.s.
where (9) and (11) follow by Property 1(ii) (Lipschitzness) and (10) follows by Corollary 1.
Therefore, for any ϵ ą 0 and a small enough δ, the term T1 will be less than ϵ eventually.
Term (T2). For any k P rKs, by the triangle inequality,
ˇ ˇ
ˇ ÿ ˇ
ˇ1 ˇ
ˇ s ra pθ ,ηp q´a pθ ,η˚qsˇ
ˇT t t k t´1 ˚ k ˇ
ˇt ˇ
ˇ ÿ ˇ
ˇ1 ˇ
ď ˇ s ra pθ ,η˚q´a pθ ,η˚qsˇ`
ˇT t t k ˚ k ˇ
loooootooooooooooooooomoooooooooooooooooooon
ˇ :“a ˇ
ˇ ÿ ˇ
ˇ1 ˇ
ˇ s ra pθ ,ηp q´a pθ ,η˚q´E ra pθ ,ηp q´a pθ ,η˚qssˇ`
ˇT t t k t´1 t k t´1 t k t´1 t k ˇ
loooootoooooooooooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooooooooooooooon
ˇ :“b ˇ
ˇ ÿ ˇ
ˇ1 ˇ
ˇ s E ra pθ ,ηp q´a pθ ,η˚qsˇ.
ˇT t t´1 t k t´1 t k ˇ
loooootoooooooooooooooooomooooooooooooooooooooooon
:“c
27The term a above is a martingale difference sequence (MDS). By Property 1(i) and Corol-
lary1,thistermiso p1q. Thetermb aboveisalsoaMDS.ForD “ a pθ ,ηp q´a pθ ,η˚q,
a.s. t t k t´1 t k
Ers pD ´E rD sq2s ď ErpD ´E rD sq2s (12)
t t t´1 t t t´1 t
ď ErD2s
t
ď ErE rD2ss
t´1 t
ď LEr}ηp ´η˚}2s (13)
t´1
ă 8, (14)
where (12) follows because s P t0,1u, (13) by Property 1(ii), and (14) by Property 1(iv).
t
Thus, by Corollary 1, this term is also o p1q. For term c, we have
a.s.
ˇ ˇ
ˇ ÿ ˇ ÿ
ˇ1 ˇ 1
ˇ s E ra pθ ,ηp q´a pθ ,η˚qsˇ ď E r|a pθ ,ηp q´a pθ ,η˚q|s (15)
ˇT t t´1 t k t´1 t k ˇ T t´1 t k t´1 t k
t t
ÿa
1
ď E r|a pθ ,ηp q´a pθ ,η˚q|2s
T
t´1 t k t´1 t k
t
?
ÿ
L
ď }ηp ´η˚} (16)
T
t´1
t
“ o p1q, (17)
p
where (15) follows because s P t0,1u, (16) by Property 1(ii), and (17) by Lemma 4. This
t
allows us to show that term T2 is o p1q:
p
ˇ ˇ ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
ÿ ˇ
ˇ1
ÿT ˇ
ˇ
maxˇ s ta pθ ,ηp q´a pθ ,η˚quˇ ď ˇ s ta pθ ,ηp q´a pθ ,η˚quˇ
kPrKsˇT t t k t´1 ˚ k ˇ ˇT t t k t´1 ˚ k ˇ
t“1 kPrKs t“1
“ o p1q,
p
where the last line follows because K is finite.
Term (T3). By Property 1(ii),
?
max|a pθ ,η˚q´a pθ,η˚q| ď ErLpX qsδ ď Lδ.
˚ k ˚ t
kPrKs
Thus, for any ϵ ą 0 and a small enough δ, the term T3 will be less than ϵ.
Proposition 10. Suppose that (i) f pθ,ηq :“ fpX ;θ,ηq and g pθ,ηq :“ gpX ;θ,ηq satisfy
t t t t
Property 1; and (ii) (Boundedness) @pθ,ηq,|f pθ,ηq| ď H and |g pθ,ηq| ď H for some
t 8 t 8
constant H ă 8. Then, f pθ,ηqg pθ,ηq satisfies Property 1.
t t
Proof. We show that the conditions of Property 1 hold for a pθ,ηq “ f pθ,ηqg pθ,ηq.
t t t
Property 1(i). For any θ,η,
“ ‰ “ ‰
E |a pθ,ηq|2`δ “ E |f pθ,ηqg pθ,ηq|2`δ
t t t
ď H4`2δ
ă 8.
28Property 1(ii). We have that @θ,θ1 P Θ,@η P T ,
|a pθ1,ηq´a pθ,ηq| “ |f pθ1,ηqg pθ1,ηq´f pθ,ηqg pθ,ηq|
t t t t t t
“ |f pθ1,ηqpg pθ1,ηq´g pθ,ηq`g pθ,ηqq´f pθ,ηqg pθ,ηq|
t t t t t t
“ |f pθ1,ηqpg pθ1,ηq´g pθ,ηqq`g pθ,ηqpf pθ1,ηq´f pθ,ηqq|
t t t t t t
ď LpX qp|f pθ1,ηq|`|g pθ,ηq|q}θ´θ1}, (18)
t t t
where (18) follows by Condition (i). Furthermore, by Condition (ii), we have
ErpLpX qp|f pθ1,ηq|`|g pθ,ηq|qq2s ď 4H2ErLpX q2s
t t t t
ă 8.
Next, by Conditions (i, ii), we have that @θ P Θ,@η,η1 P T ,
Erpa pθ,ηq´a pθ,η1qq2s “ Erpf pθ,ηqg pθ,ηq´f pθ,η1qg pθ,η1qq2s
t t t t t t
“ Erpf pθ,ηqpg pθ,ηq´g pθ,η1qq`g pθ,η1qpf pθ,ηq´f pθ,η1qqq2s
t t t t t t
“ Erf2pθ,ηqpg pθ,ηq´g pθ,η1qq2s`Erg2pθ,η1qpf pθ,ηq´f pθ,η1qq2s
t t t t t t
`2Erf pθ,ηqg pθ,η1qpg pθ,ηq´g pθ,η1qqpf pθ,ηq´f pθ,η1qs
t t t t t t
ď 2H2L}η ´η1}2 `2H2Er|pg pθ,ηq´g pθ,η1qqpf pθ,ηq´f pθ,η1q|s
a t t t t
ď 2H2L}η ´η1}2 `2H2 Erpg pθ,ηq´g pθ,η1qq2sErpf pθ,ηq´f pθ,η1qq2s
t t t t
ď 4H2L}η ´η1}2,
completing the proof.
Before presenting the proof of Prop. 1, we define some additional notation. Recall that
p p
θ “ argmin Q pθ,pηp qT q (see Eq. 2) and the moment conditions have the following
T θPΘ T t´1 t“1
form (see Eq. 1):
g pθ,ηq “ mps qdg˜pθ,ηq,
t t t
where m : t0,1u|D| ÞÑ t0,1uM is a fixed known function that determines which moments
i.i.d.
get selected based on the selection vector s . For some κ P ∆ and s „ Multinouillipκq,
t D t
we define the following matrices:
m pκq :“ Erlrmoooposoooqo,oo.m..o,oomoooposoooqnss P r0,1sMˆD, (19)
G t t
“ Dtimes ‰
m pκq :“ E mps qmps qJ P r0,1sMˆM. (20)
Ω t t
Proposition 1 (Consistency). Suppose that (i) Assumption 3 holds; (ii) @i P rMs,ψpiq
satisfies Property 1; (iii) @pi,jq P rMs2,ψpiqψpjq satisfies Property 1. Then βp Ñp β˚.
T
Proof. We define the following matrices:
ÿ
p 1
Ω pθq :“ g pθ,ηp qgJpθ,ηp q
T T t t´1 t t´1
t
ÿ “ ‰
1
Ω pθq :“ E g pθ,η˚qgJpθ,η˚q
T T t´1 t t
« t ff
ÿ
1
“ mps qmps qJ dErg˜pθ,η˚qg˜Jpθ,η˚qs
T t t t t
t
“ m pκ qdErg˜pθ,η˚qg˜Jpθ,η˚qs.
Ω T t t
29We define the empirical and population versions of the GMM objective:
« ff « ff
ÿT J ÿT
p 1 x 1
Q pθ,pηp qT q : “ g pθ,ηp q W g pθ,ηp q ,
T t´1 t“1 T t t´1 T T t t´1
« t“1 ff t“«1 ff
ÿT ÿT
1 1
Q¯ pθq : “ E rg pθ,η˚qsJ W E rg pθ,η˚qs
T
T
t´1 t T
T
t´1 t
«˜
t“1
¸ ff
«t ˜“1
¸ ff
ÿT J ÿT
1 1
“ mps q dg pθq W mps q dg pθq
T t ˚ T T t ˚
t“1 t“1
where g pθq :“ Erg˜pθ,η˚qs. For the one-step GMM estimator, denoted by θp posq, we use
˚ t T
Wx “ W “ Ipidentityq. For the two-step GMM estimator, we use Wx “ Ωp pθp posq q´1 and
T T T T T
W “ Ω pθ˚q´1.
T T
By Assumption 3(a), the true parameter θ˚ uniquely minimizes the population ob-
jective: θ˚ “ argmin Q¯ pθq. By the same argument as Newey and McFadden [1994,
θPΘ T
Thm. 2.1], if sup |Qp pθ,pηp qT q´Q¯ pθq| Ñp 0, then θp Ñp θ˚. Thus, to show consis-
θPΘ T t´1 t“1 T T
p
tency, we prove the uniform convergence of Q pθ,pηp qT q. By the triangle inequality,
T t´1 t“1
ˇ ˇ
ˇ ˇ
ˇQp pθ,pηp qT q´Q¯ pθqˇ ď F pθq2}Wx }2 `2}g pθq}F pθq}Wx }`}g pθq}2 }Wx ´W },
T t´1 t“1 T T T ˚ T T ˚ T T
ř
where F pθq :“ }T´1 T rg pθ,ηp q´mps qdg pθqs}. We prove the uniform conver-
T t“1 t t´1 t ˚
gence of F pθq by applying Lemma 5 to every element of g pθ,ηp q along with the union
T t t´1
bound. For any ϵ ą 0,
˜ ˇ ˇ ¸
ˆ ˙
ÿM ˇ
ˇ1
ÿT ˇ
ˇ
P supF pθq ă ϵ ě P sup ˇ rg pθ,ηp q´m ps qdg pθq sˇ ă ϵ
T ˇT t,i t´1 i t ˚ i ˇ
θPΘ θPΘ
i“˜1 t“ˇ1 ˇ ¸
ÿM ˇ
ˇ1
ÿT ˇ
ˇ ϵ
ě 1´ P supˇ rg pθ,ηp q´m ps qdg pθq sˇ ą (21)
ˇT t,i t´1 i t ˚ i ˇ M
i“1
θPΘ
t“1
ě 1´o p1q, (22)
p
where (21) follows by the union bound, and (22) by Lemma 5. For the one-step GMM
x x p
estimator, we have W “ W “ I (identity) and so }W ´ W } Ñ 0 holds trivially.
T T T T
Therefore,
θp(os) Ñp
θ˚. For the two-step estimator, we need to show that
}Wx
´W }
Ñp
0.
T T T
For all pi,jq P rMs2 and any ϵ ą 0,
ˆ ˙
ˇ ˇ
ˇ ˇ
p
P supˇΩ pθq ´Ω pθq ˇ ą ϵ Ñ 0, (23)
T i,j T i,j
´ˇ θPΘ ˇ ¯
ˇ ˇ
6 P
ˇΩp pθp(os)
q ´Ω
pθp(os)
q ˇ ą ϵ Ñ 0,
´ˇT T i,j T T i,j ˇ ¯
ˇ ˇ
6 P
ˇΩp pθp(os)
q ´Ω pθ˚q ˇ ą ϵ Ñ 0, (24)
T ´ˇT i,j T i,j ˇ ¯
ˇ ˇ
x
6 P ˇpW q ´pW q ˇ ą ϵ Ñ 0, (25)
T i,j T i,j
´› › ¯
› ›
x
6 P ›W ´W › ą ϵ Ñ 0,
T T
30where (23) follows by Lemma 5 and Condition (iii); (24) follows because
θp(os) Ñp
θ˚; and
T
p p p p
(25) by continuity of the matrix inverse. Therefore, θ Ñ θ˚. Since β “ f pθ q, by
T T tar T
p p
continuity of f (Assumption 3c), we have β Ñ β˚.
tar T
B Proof of asymptotic normality
Proposition11(MartingaleCLT[H¨auslerandLuschgy,20`1 Ť5,Thm.˘6.23]). LettX i,F i,1 ď
i ď nu be a martingale difference sequence and let F :“ σ 8 F . Let γ2 be an a.s. fi-
8 i“1 i
nite random variable. Suppose that (i) (Square integrable) @i,ErX2s ă 8; (ii) (Conditional
ř ? i
Lindeberg) @ϵ ą 0, n´1 n ErX21p|X | ą ϵ nq|F s Ñp 0, and (ii) (Convergence of con-
ř i“1 i i i´1
ditional variance) n´1 n ErX2|F s Ñp γ2 for some random variable γ. Let Z „ Np0,1q
i“1 i i´1
be a standard Gaussian independent of F . Then
8
ÿn
1
d
? X Ñ γZ F -stably,
n i 8
i“1
where the random variable γZ is a mixture of centered normal distributions with the char-
acteristic function φptq “ E r´γ2t2{2s. If γ is a.s. constant, then
γ
ÿn
1
? X Ñd Np0,γ2q.
i
n
i“1
Proposition12(Propertiesofstableconvergence[Ha¨uslerandLuschgy,2015,Thm.3.18]).
d p
Assume that X Ñ X G-stably. Let Y and Y be random variables. (a) If Y Ñ Y and Y
n n n
is G-measurable, then pY ,X q Ñ pX,Yq G-stably. (b) If g is a measurable and continuous
n n
function, then gpX q Ñ gpXq G-stably.
n
d
Corollary 2 (Cramer-Slutsky). Assume that X Ñ X G-stably. Let Y and Y be random
n n
p d
variables. If Y Ñ Y and Y is G-measurable, then Y X Ñ YX G-stably.
n n n
Proof. Apply Prop. 12 with the function gpX,Yq “ XY.
Proposition 13 (Cramer-Wold device [Ha¨usler and Luschgy, 2015, Cor. 3.19]). If uJY Ñd
n
uJY G-stably for every u P Rd, then Y Ñd Y G-stably.
n
Lemma 6. Let pX q8 be a sequence of non-negative random variables such that (i)
t t“1
sup ErX1`δs ă 8 and (ii) X “ o pt´1{2q. Then
t t t p
ÿT
1
? X “ o p1q.
t p
T
i“1
Proof. By Markov’s inequality, for any ϵ ą 0,
˜ ¸
ř
1
ÿT
ErX s
P ? X ą ϵ ď t? t
t
T Tϵ
i“1
?
op Tq
“ ? (26)
Tϵ
“ op1q,
where (26) follows because ErX s “ opt´1{2q (by Conditions (i, ii) and Prop. 9).
t
31Proposition 2 (Asymptotic normality). Suppose that (i)”Conditionıs of Prop. 1 hold; (ii)
Assumptions 4 and 5 hold; and (iii) @i P rMs,j P rDs,B ψpiq pθ,ηq satisfies Property 1.
θj t
p
Then β converges to a mixture of normals, where the mixture is over κ :
T 8
?
Tpβp ´β˚q Ñd N p0,V pκ qq,
T κ8 ˚ 8
where V pκq is a constant that depends on pθ˚,η˚,κq. If κ is almost surely constant, then
˚ 8
p
β is asymptotically normal.
T
p p
Proof. Recall that θ “ argmin Q pθ,pηp qT q (see Eq. 2). For the two-step GMM
T θPΘ T t´1 t“1
estimator, by first-order optimality, we have
? Tpθp ´θ˚q “
´”
Gp Jpθp qΩp pθp posq q´1Gp pθ˜
qı
´1 Gp Jpθp qΩp pθp posq q´1?1
ÿT
g pθ˚,ηp q, (27)
T T T T T T T T t t´1
T
t“1
where θp posq is the one-step GMM estimator, θ˜ is a point on the line-segment joining θp and
T T
θ˚,
Gp
pθq “
1
ÿT
Bg tpθ,ηp t´1q
T
T Bθ
t“1
1
ÿT
Bpmps qdg˜pθ,ηp qq
t t t´1
“
T Bθ
t“1¨ ˛
„ ȷ
“
1
ÿT
˝
lrmoooposooqoo,omoooposomq,o.oo.o.oo,omoooposoooqnsd
Bg˜ tpθ,ηp t´1q ‚
,
t t t
T Bθ
t“1
Dtimes
ˆ „ ȷ˙
1
ÿT
Bg˜pθ,ηp q
“ m ps qd
t t´1
, and
G t
T Bθ
t“1
ÿT “ ‰
p 1
Ω pθq “ g pθ,ηp qg pθ,ηp qJ
T
T
t t´1 t t´1
t“1
ÿT `“ ‰ “ ‰˘
1
“ mps qmps qJ d g˜pθ,ηp qg˜pθ,ηp qJ ,
T
t t t t´1 t t´1
t“1
ÿT ` “ ‰˘
1
“ m ps qd g˜pθ,ηp qg˜pθ,ηp qJ ,
T
Ω t t t´1 t t´1
t“1
where m and m are defined in Eqs. 19,20.
G Ω
32” ı
Convergence of Gp pθp q. Let Gpθ,ηq “ E Bg˜tpθ,ηq . Using Condition (iii) and applying
T T Bθ
p
Lemma 5 to each element of G with a union bound (similar to Eq. 23), we get
› ˜ ¸ ›
sup›
› ›Gp pθq´ 1
ÿT
m ps q
dGpθ,η˚q›
› › Ñp 0,
› T T G t ›
θPΘ
› t“1 ›
› ›
sup›Gp pθq´m pκ qdGpθ,η˚q› Ñp 0,
T G T
θPΘ› ›
› ›
6 ›Gp pθp q´m pκ qdGpθp ,η˚q› Ñp 0. (28)
T T G T T
p p p p
Since κ Ñ κ , by continuous mapping, m pκ q Ñ m pκ q. Since θ Ñ θ˚ (by Condi-
T 8 G T G 8 T
p p
tion (i)), Gpθ ,η˚q Ñ Gpθ˚,η˚q. Therefore, for G pκ q :“ m pκ q d Gpθ˚,η˚q, we have
T ˚ 8 G 8
p p p
G pθ q Ñ G pκ q.
T T ˚ 8
ConvergenceoftheweightmatrixΩp pθp posq q. Similarly,forΩpθ,ηq :“ Erg˜pθ,ηqg˜Jpθ,ηqs,
T T t t
› ›
› ›
›Ωp pθp posq q´m pκ qdΩpθp posq,η˚q› Ñp 0.
T T Ω T T
Since κ Ñp κ , by continuous mapping, m pκ q Ñp m pκ q. Since θp posq Ñp θ˚, for
T 8 Ω T Ω 8 T
p p p
Ω pκ q :“ m pκ q d Ωpθ˚,η˚q, we have Ω pθ q Ñ Ω pκ q. By continuity of the ma-
˚ 8 Ω 8 T T ˚ 8
trix inverse, we have Ωp pθp posq q´1 Ñp Ω pκ q´1.
T T ˚ 8
ř ?
Asymptotic normality of T g pθ˚,ηp q{ T. Recall that
t“1 t t´1
g pθ˚,ηq “ mps qdrψp1q pθ,ηp1qq,...,ψpMq pθ,ηpMqqsJ.
t t t t
For any i P rMs, let D “ ψpiq pθ˚,ηp q´ψpiq pθ˚,η˚q. We have
t t t´1 t
ÿT
1
? m ps qψpiq pθ˚,ηp q
i t t t´1
T
t“1
ÿT ÿT ÿT
1 1 1
“ ? m ps qψpiq pθ˚,η˚q` ? m ps qrD ´E rD ss` ? m ps qE rD s.
i t t i t t t´1 t i t t´1 t
T T T
loooooooooooooooooomoooooooooooooooooon looooooooooooomooooooooooooon
t“1 t“1 t“1
EP(Empiricalprocess) Bias
33We first show that term EP is o p1q. Let Q :“ m ps qpD ´E rD sq. For any ϵ ą 0,
p t i t t t´1 t
¨ ˛
˜ˇ ˇ ¸ ˇ ˇ
ˇ
ˇ 1
ÿT ˇ
ˇ
ˇ
ˇ 1
ÿT ˇ ˇ2
P ˇ? m ps qrD ´E rD ssˇ ą ϵ “ P˝ ˇ? Q ˇ ą ϵ2‚
ˇ i t t t´1 t ˇ ˇ tˇ
T T
t“1 t“1
ř ř
ď
T t“1ErQ2 ts` i‰j(cid:24)E(cid:24)rQ(cid:24) iQ(cid:24) j(cid:24)(cid:24)(cid:58) s 0
(29)
Tϵ2
ř
T ErQ2s
“ t“1 t
ř
T“ϵ2
‰
E m ps qpD ´E rD sq2
“ t i t t t´1 t
ř Tϵ2
ErD2s
ď t t (30)
řTϵ2
L Er}ηp ´η˚}2s
ď t t´1 (31)
Tϵ2
“ op1q, (32)
where (29) follows by Markov’s inequality, (30) because m ps q P t0,1u, ErQ Q s “ 0
i t i j
because the sequence Q is a MDS, (31) follows by Lipschitzness (Property 1(ii)) and (32)
t
because Er}ηp ´η˚}2s “ op1q (by Property 1(iv) and Prop. 9).
t´1
Next, we show that the term Bias is o p1q. By the Taylor expansion, we have
p
E rψpiq pθ˚,ηp qs “ Erψpiq pθ˚,η˚qs`BlooE ooooooroψoooopoθo˚ oo,oηoo˚ ooo`mroopoηoo˚ oo´oooηp ooooooqoqooso|ooon`R
t´1 t t´1 t r t´1 t t´1 r“0 t
“0
“ Erψpiq pθ˚,η˚qs`R , (33)
t t
where R is the second-order remainder defined in Assumption 4b, and (33) follows by
t
Assumption 4a (Neyman orthogonality). Therefore,
ÿT ÿT
1 1
? m ps qE rD s ď ? m ps qR
i t t´1 t i t t
T T
t“1 t“1
ÿT
1
ď ? R
t
T
t“1
ÿT
p ďaq ?1 o pt´1{2q p “bq o p1q,
p p
T
t“1
where (a) follows by Assumption 4b and (b) follows by Lemma 6. Therefore, we have
ÿT ÿT
1 1
? g pθ˚,ηp q “ ? g pθ˚,η˚q`o p1q. (34)
t t´1 t p
T T
t“1 t“1
ř ?
Now, it remains to show that T g pθ˚,η˚q{ T is asymptotically normal. To do so, we
t“1 t
will use the Cramer-Wold device (Prop. 13) and the martingle CLT (Prop. 11). For any
34v P RM, vJg pθ˚,η˚q is a MDS because E rvJg pθ˚,η˚qs “ vJE rg pθ˚,η˚qs “ 0. We
t t´1 t t´1 t
show that the two conditions of the martingale CLT hold:
(i) Conditional Lindeberg: The Lyapunov condition implies the Lindeberg condition
[Ha¨usler and Luschgy, 2015, Remark 6.25] and we show that it holds. For any δ ą 0,
ÿT ” ˇ ˇ ı ÿT ” ı
1 E ˇ vJg pθ˚,η˚qˇ2`δ ď 1 }v}2`δE }g pθ˚,η˚q}2`δ (35)
T1`δ{2 t´1 t T1`δ{2 t´1 t
t“1 t“1
}v}2`δ
ÿT ” ı
“ E }mps qdg˜pθ˚,η˚q}2`δ
T1`δ{2 t´1 t t
t“1
}v}2`δ
ÿT ” ı
ď E }g˜pθ˚,η˚q}2`δ (36)
T1`δ{2 t
t“1
Ñ 0, (37)
where (35) holds by”the Cauchy-Scıhwarz inequality, (36) because mps tq is a binary vector,
and (37) because E }g˜pθ˚,η˚q}2`δ ă 8 (by Property 1(i)).
t
(ii) Convergence of conditional variance: The conditional variance is
ÿT “ ‰ ÿT “ ‰
1 1
E vJg pθ˚,η˚qg pθ˚,η˚qJv “ vJE g pθ˚,η˚qg pθ˚,η˚qJ v
T
t´1 t t
T
t´1 t t
t“1 t“1
“ vJrm pκ qdΩpθ˚,η˚qsv (38)
Ω T
Ñp vJrm pκ qdΩpθ˚,η˚qsv, (39)
Ω 8
“ vJΩ pκ qv,
˚ 8
p
where (39) follows because κ Ñ κ (Assumption 5). Applying the martingale CLT
T 8
(Prop. 11) and the Cramer-Wold device (Prop. 13), we get
ÿT
1
? g pθ˚,η˚q Ñd N p0,Ω pκ qq,
T
t κ8 ˚ 8
t“1
ÿT
1
6 ? g pθ˚,ηp q Ñd N p0,Ω pκ qq, (40)
T
t t´1 κ8 ˚ 8
t“1
where (40) follows by Eq. 34, and N denotes a mixture of normals where the mixture is
κ8
taken over κ , i.e., it has the characteristic function φptq “ E r´1tJΩ pκ qts.
8 κ8 2 ˚ 8
p
Asymptotic normality of θ . We can apply the Cramer-Slutsky theorem (Cor. 2) to
T
Eq. 27 to get:
?
Tpθp ´θ˚q Ñd N p0,Σ pκ qq,
T κ8 ˚ 8
where
“ ‰
Σ pκ q “ G pκ qJΩ pκ q´1G pκ q ´1 . (41)
˚ 8 ˚ 8 ˚ 8 ˚ 8
35p p p
Asymptotic normality of β . Recall that β “ f pθ q. By the Taylor expansion,
T T tar T
βp “ f pθp q “ f pθ˚q`∇ f pθ˜ qJpθp ´θ˚q,
T tar T tar θ tar T
? ?
6 Tpβp ´β˚q “ ∇ f pθ˜ qJ Tpθp ´θ˚q, (42)
T θ tar T
?
p
“ ∇ f pθ˚qJ Tpθ ´θ˚q`o p1q. (43)
θ tar T p
?
6 Tpβp ´β˚q Ñd N p0,V pκ qq,
T κ8 ˚ 8
where θ˜ is point on the line segment joining θp and θ˚, (43) follows because θ˜ Ñp θ˚, and
T
V pκ q “ ∇ f pθ˚qJΣ pκ q∇ f pθ˚q. (44)
˚ 8 θ tar ˚ 8 θ tar
Proposition 3 (Asymptotic inference). Suppose that the Conditions of Prop. 2 hold. For
˜ ¸
ÿT
p p 1 p
G pθ q :“ ∇ g pθ ,ηp q ,
T T
T
θ t T t´1
˜ t ¸
ÿT
p p 1 p p
Ω pθ q :“ g pθ ,ηp qgJpθ ,ηp q ,
T T T t T t´1 t T t´1
” t ı
p p p p p p p ´1
Σ :“ GJpθ qΩ´1pθ qG pθ q ,
T T T T T T T
p p p p
V :“ ∇ f pθ qJΣ ∇ f pθ q, (45)
T θ tar T T θ tar T
we have
?
Vp´1{2 Tpβp ´β˚q Ñd N p0,1q.
T T
p p
Proof. In the proof of Prop. 2, we have shown that V Ñ V pκ q. We can apply the
T ˚ 8
Cramer-Slutsky theorem (Cor. 2) to get the desired result:
?
Vp´1{2 Tpβp ´β˚q Ñd V pκ q´1{2N p0,V pκ qq
T T ˚ 8 κ8 ˚ 8
“ N p0,1q.
p
Proposition 4. Suppose that (i) θ is estimated using Eq. 2, (ii) Assumption 6 holds, and
T
(iii) the conditions of Prop. 2 hold. Then, for any data collection policy π, R pπq ě 0.
8
Proof. By Prop. 2, we have
?
Tpβp ´β˚q Ñd N p0,V pκ qq.
?
T κ8 ˚ 8
p
6 AMSEp Tpβ ´β˚qq “ E rV pκ qs
T κ8 ˚ 8
ě E rV pκ˚qs (46)
κ8 ˚
“ V pκ˚q,
˚
where (46) follows because κ˚ minimizes V pκq (Assumption 6).
˚
36C Proofs for OMS-ETC (Section 4.1)
Definition 3 (Variance estimator). For any κ P ∆ , we define
D
p p
G pθ,κq :“ m pκqdp1{m pκ qqdG pθq,
T G G T T
p p
Ω pθ,κq :“ m pκqdp1{m pκ qqdΩ pθq,
T Ω Ω T T
” ı
p p p p ´1
Σ pθ,κq :“ GJpθ,κqΩ´1pθ,κqG pθ,κq ,
T T T T
p p
V pθ,κq :“ ∇ f pθqJΣ pθ,κq∇ f pθq, (47)
T θ tar T θ tar
where m pκq and m pκq are defined in Eqs. 19 and 20; and 1{m pκ q represents the
G Ω G T
element-wise reciprocal of the non-zero elements of the matrix (and likewise for 1{m pκ q).
Ω T
p p p
Lemma 2. Let k :“ argmin V pθ ,κq be the estimated oracle simplex. Suppose
T κP∆D T T
that (i)”the condiıtions of Prop. 1 hold, (ii) Assumption 6 holds, and (iii) @i P rMs,j P
rDs,B ψpiq pθ,ηq satisfies Property 1. Then p k Ñp κ˚.
θj t T
Proof. We prove this Lemma by showing uniform convergence of the variance estimator
over κ P ∆ . We use a covering number argument over the compact set ∆ .
D D
In the proof of Prop. 2 (by Condition (iii)), we showed that (see Eq. 28)
› ›
› ›
›Gp pθp q´m pκ qdGpθp ,η˚q› Ñp 0. (48)
T T G T T
For any κ P ∆ , we have the following pointwise convergence:
D
p p p p
G pθ ,κq “ m pκqdp1{m pκ qqdG pθ q
T T G G T T T
p
“ m pκqdp1{m pκ qqdm pκ qdGpθ ,η˚q`o p1q (49)
G G T G T T p
p
“ m pκqdGpθ ,η˚q`o p1q
G T p
“ m pκqdGpθ˚,η˚q`o p1q (50)
G p
“ G pκq`o p1q, (51)
˚ p
p p
where (49) follows by Eq. 48 and (50) because θ Ñ θ˚.
T
We now show uniform convergence over ∆ using a covering number argument. Let
D
tκ uJ be a minimal δ-cover of ∆ and B pκ q denotes the δ-ball around κ . By compact-
j j“1 D δ j j
ness of ∆ , J is finite. For the rest of the proof, for any κ, let κ denote the point in the
D j
δ-cover such that κ P B pκ q. By the triangle inequality,
δ j
› ›
› ›
p p
sup ›G pθ ,κq´G pκq›
T T ˚
κP∆D › › › ›
› › › ›
p p p p p
ď sup›G pθ ,κq´G pθ,κ q›`max›G pθ ,κ q´G pκ q›`max}G pκ q´G pκq}.
T T T j T T j ˚ j ˚ j ˚
lo κoooooooooooooooomooooooooooooooooon ljPoorJoosoooooooooooomoooooooooooooooon ljPoorJoosooooooooomooooooooooooon
T1 T2 T3
We now show that the three terms are o p1q.
p
37Term (T1). We have
› › › ›
› › › ›
p p p p p
sup›G pθ ,κq´G pθ,κ q› “ sup›rm pκq´m pκ qsdp1{m pκ qqdG pθ q›
T T T j G G j G T T T
κ κ › ›
› ›
p p
ď Opδq›p1{m pκ qqdG pθ q› (52)
G T T T
› ›
› ›
p
“ Opδq›p1{m pκ qqdm pκ qdGpθ ,η˚q›`o p1q (53)
G T G T T p
› ›
› ›
p
“ Opδq›Gpθ ,η˚q›`o p1q
T p
“ Opδq}Gpθ˚,η˚q}`o p1q (54)
p
“ Opδq`o p1q, (55)
p
where (52) follows because }m pκq´m pκ q} ď DMδ “ Opδq (by Lipschitzness of m pκq),
G G j G
p p
(53)byEq.48,(54)becauseθ Ñ θ˚,and(55)because}Gpθ˚,η˚q} ă 8(byCondition(iii)).
T
Term (T2). We have
› › ÿ › ›
› › › ›
p p p p
max›G pθ ,κ q´G pκ q› ď ›G pθ ,κ q´G pκ q›
T T j ˚ j T T j ˚ j
jPrJs
jPrJs
“ o p1q,
p
where the last line follows by Eq. 51 and finiteness of J.
Term (T3). We have
max}G pκ q´G pκq} “ max}rm pκ q´m pκqsdGpθ˚,η˚q}
˚ j ˚ G j G
jPrJs jPrJs
ď Opδq}Gpθ˚,η˚q}, (56)
“ Opδq, (57)
where (56) follows because }m pκq´m pκ q} “ Opδq and (57) because }Gpθ˚,η˚q} ă 8.
G G j
Combining the three terms, we have
p p
sup }G pθ ,κq´G pκq} “ o p1q,
T T ˚ p
κP∆D
p p p p
6 }G pθ ,k q´G pk q} “ o p1q.
T T T ˚ T p
In the same way, we can show that
p p
sup }Ω pθ ,κq´Ω pκq} “ o p1q,
T T ˚ p
κP∆D
p p p p
6 }Ω pθ ,k q´Ω pk q} “ o p1q.
T T T ˚ T p
By the continuous mapping theorem,
p p p p
|V pθ ,k q´V pk q| “ o p1q.
T T T ˚ T p
38To summarize, we have the following:
κ˚ “ arg min V pκq, (58)
˚
κP∆D
p p p
k “ arg min V pθ ,κq, (59)
T T T
κP∆D
p p p p
|V pθ ,k q´V pk q| “ o p1q, (60)
T T T ˚ T p
p p
|V pθ ,κ˚q´V pκ˚q| “ o p1q. (61)
T T ˚ p
Next, we follow the proof of Newey and McFadden [1994, Thm. 2.1]. For any ϵ ą 0, with
probability approaching (w.p.a.) 1,
p p p p
V pk q ď V pθ ,k q`ϵ (62)
˚ T T T T
p p
ď V pθ ,κ˚q`ϵ (63)
T T
ď V pκ˚q`2ϵ, (64)
˚
where (62) follows by Eq. 60, (63) by Eq. 59, and (64) by Eq. 61. Let B be any open subset
of ∆ containing κ˚ and let Bc denote its complement. Let κ˜ “ argmin V pκq.
D κPp∆DXBcq ˚
The minimum exists because p∆ XBcq is compact. By Eq. 58, we have V pκ˚q ď V pκ˜q.
D ˚ ˚
p
Thus, for ϵ “ 1pV pκ˜q´V pκ˚qq ą 0 (by Assumption 6), we have V pk q ď V pκ˜q w.p.a. 1.
2 ˚ ˚ ˚ T ˚
p
Therefore k P B, completing the proof.
T
D Proofs for OMS-ETG (Section 4.2)
Theorem 2. Suppose that (i) the conditions of Theorem 1 hold and (ii) (Finite rounds)
lim S{T “ r for some constant r P p0,1q. Then, R pπ q “ 0.
TÑ8 8 ETG
Proof. For any ϵ ą 0 and t “ Te`jS for j P r0,...,Js, we have
j
´ ¯ ÿJ ´ ¯
p p
P @j P r0,...,Js,k P B pκ˚q ě 1´ P k R B pκ˚q (65)
tj ϵ tj ϵ
j“0
“ 1´o p1q, (66)
p
p p
where (65) follows by the union bound and (66) because @j,k Ñ κ˚ (by Lemma 2). Note
tj
p
that κ moves as close as possible to k after every round. By Eq. 66, this means that κ
tj`1 tj T
moves towards B pκ˚q after every round and thus we have }κ ´projpκ˚,∆˜ q} Ñp 0. Due to
ϵ T e
˜
negligible exploration (e P op1q), the set ∆ asymptotically covers the entire simplex ∆ ,
e D
i.e., projpκ˚,∆˜ q Ñp κ˚. Thus κ Ñp κ˚ and by Lemma 1, π has zero regret.
e T ETG
Lemma 7 ([Waudby-Smith et al., 2021, Prop. B.4]). Let pX q8 be a sequence of random
t t“1
a.s. p a.s.
variables. Then X Ñ 0 ðñ sup X Ñ 0. Equivalently, X Ñ 0 if and only if
t Tět T t
@ϵ ą 0, lim PpDT ą t : |X | ą ϵq “ 0.
T
tÑ8
a.s.
Lemma 8. Let X
t
be a sequence of non-negative řrandom variables such that (i) X
t
Ñ 0
and (ii) sup ErX1`δs ă 8 for some δ ą 0. Then, T X {T “ o p1q.
t t t“1 t a.s.
39ř
Proof. Let S :“ T X . For any T ą t,
T t“1 t
ÿT
S S 1
T t
ď ` X .
i
T t T
i“t`1
By the union bound, for any ϵ ą 0,
˜ ¸
ˆ ˙ ˆ ˙
ÿT
S S 1
P @T ą t : T ď 2ϵ ě 1´P t ą ϵ ´P DT ą t : X ą ϵ . (67)
i
T loooootmooooon T
looooooooooooooooomio“ooto`o1oooooooooooon
:“a
:“b
We show that Term a in Eq. 67 is op1q. By Markov’s inequality, we have
ˆ ˙ ř
S t ErX s
P t ą ϵ ď i“1 i
t tϵ
optq
“ (68)
tϵ
“ op1q,
where (68) follows by Condition (ii) and Prop. 9. Next, we show that Term b in Eq. 67 is
op1q. For any ϵ ą 0,
˜ ¸
ÿT
1
P @T ą t : X ă ϵ ě Pp@T ą t : X ă ϵq
i T
T
i“t`1
“ 1´op1q, (69)
˜ ¸
ÿT
1
6 P DT ą t : X ą ϵ “ op1q,
i
T
i“t
a.s.
where (69) follows by Lemma 7 because X Ñ 0. Using these results in Eq. 67, we get
t
ˆ ˙
S
P @T ą t : T ď 2ϵ ě 1´op1q.
T
Therefore, by Lemma 7, S {T “ o p1q.
T a.s.
Lemma 9 (Strong uniform convergence). Suppose that (i) a pθ,ηq :“ apX ;θ,ηq satisfies
t t
Property 1; (ii) (Nuisance strong consistency) }ηp ´η˚} a Ñ.s. 0; and (iii) @η P T , Er}η ´
t´1
η˚}2s ă 8. Let a pθ,ηq “ ErapX ;θ,ηqs and s P t0,1u be H -measurable. Then,
˚ t t t´1
ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
supˇ s ta pθ,ηp q´a pθ,η˚quˇ a Ñ.s. 0.
ˇT t t t´1 ˚ ˇ
θPΘ
t“1
Proof. WeprovethisinthesamewayasLemma5,strengtheningconvergenceinprobability
to almost sure convergence using the stronger assumptions on the nuisance estimators. We
begin with the same decomposition as in Lemma 5 and show that each term converges
almost surely to zero. Let tθ uK be a minimal δ-cover of Θ and B pθ q denote the δ-ball
i i“1 δ k
40around θ . By compactness of Θ, K is finite. Going forward, for any θ P Θ, let θ denote
k k
the element of the δ-cover such that θ P B pθ q. By the triangle inequality,
δ k
ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ
supˇ s ta pθ,ηp q´a pθ,η˚quˇ
ˇT t t t´1 ˚ ˇ
θPΘ
t“1 ˇ ˇ
1
ÿT ˇ
ˇ1
ÿT ˇ
ˇ
ď sup|a pθ,ηp q´a pθ ,ηp q|`maxˇ s ta pθ ,ηp q´a pθ ,η˚quˇ`.
lT
oo to “oo
1ooooθoooooot oooooomt´1 ooooooooot ooook oooot o´ oo1
on
lkPoorKooosoˇ oT
oooto
“oo1ooot ooooot ooook moot o´ oo1 oooooooo˚ ooook oooooooonˇ
T1 T2
max|a pθ ,η˚q´a pθ,η˚q|
˚ k ˚
klPoroKoosoooooooooooomoooooooooooooooon
T3
Term (T1). We showed in the proof of Lemma 5 that this term is o p1q.
a.s.
Term (T2). We have
ˇ ˇ
ˇ ÿ ˇ
ˇ1 ˇ
ˇ s ra pθ ,ηp q´a pθ ,η˚qsˇ
ˇT t t k t´1 ˚ k ˇ
t
ÿ
1
“ s ra pθ ,η˚q´a pθ ,η˚qs`
T t t k ˚ k
t
ÿ
1
s ra pθ ,ηp q´a pθ ,η˚q´E ra pθ ,ηp q´a pθ ,η˚qss`
T
t t k t´1 t k t´1 t k t´1 t k
t
ÿ
1
s E ra pθ ,ηp q´a pθ ,η˚qs
T
t t´1 t k t´1 t k
t
In the proof of Lemma 5, we showed that the first two terms are o p1q. For the last term,
a.s.
we have
?
ÿ ÿ
1 L
s E ra pθ ,ηp q´a pθ ,η˚qs ď }ηp ´η˚} (70)
T
t t´1 t k t´1 t k
T
t´1
t t
“ o p1q, (71)
a.s.
where (70) follows by Property 1(ii, iii) and (71) follows by Lemma 8.
Term (T3). We showed in the proof of Lemma 5 that this term is o p1q.
a.s.
Lemma 3. Suppose that (i) the conditions of Lemma 2 hold and (ii) (Nuisance strong
consistency) }ηp ´η˚} a Ñ.s. 0. Then θp a Ñ.s. θ˚ and p k a Ñ.s. κ˚.
t´1 T T
Proof. This can be proved in the same way as Lemma 2, using Lemma 9 to strengthen
convergence in probability to almost sure convergence.
Theorem 3. Suppose that (i) the conditions of Theorem 1 hold and (ii) the conditions of
Lemma 3 hold. Then, for any batch size S, R pπ q “ 0.
8 ETG
41Input: Horizon T P N, Exploration policy pϵ qT .
t t“1
p
1 k Ð κ ctr;
2 n Ð 0;
3 for t P r1,2,...,Ts do
4 n Ð n`1;
5 Sample u „ Uniformpr0,1sq;
6 if u ď ϵ t then Query one of the data sources with equal probability ;
else
7
p
8 Collect the next samples s.t. κ n “ k;
p p
9 θ n Ð argmin θPΘQ npθ,pηp t´1qn t“1q;
p p p
10 k n Ð argmin κP∆D V npθ n,κq;
p p ˜
11 k Ð projpk n,∆ n`1q;
end
12
p p
13 θ T “ argmin θPΘQ Tpθ,pηp t´1qT t“1q;
p
Output: f pθ q
tar T
Figure 5: The ϵ-greedy data collection policy.
p p
Proof. Let A ptq denote the event that the estimated oracle simplex k is inside B pκ˚q for
ϵ ϵ
p p
all time steps after t: A ptq :“ t@t1 ą t : k P B pκ˚qu. We define an analogous event for the
ϵ t1 ϵ
selection simplex κ (Defn. 1): A ptq :“ t@t1 ą t : κ P B pκ˚qu. Since Te Ñ 8 as T Ñ 8,
t ϵ t1 ϵ
by Lemma 3, p k a Ñ.s. κ˚. By Lemma 7, this is equivalent to
Te
´ ¯
p
@ϵ ą 0, lim P A pTeq “ 1. (72)
ϵ
TÑ8
p
Observe that κ is getting as close as possible to k after each round. Since the exploration
t t
p
is negligible (e P op1q), if the event A pTeq occurs, for some t ą Te, the event A pt q also
ϵ 0 ϵ 0
p
occurs. That is, when A pTeq occurs, κ will eventually enter the ϵ-ball around κ˚ at some
ϵ t0
time t ą Te and remain inside it for subsequent time steps. Therefore, @ϵ ą 0,
0
´ ¯
p
lim PpA pt qq ě lim P A pTeq
ϵ 0 ϵ
TÑ8 TÑ8
“ 1, (73)
6 κ a Ñ.s. κ˚, (74)
T
where (73) follows by Eq. 72 and (74) by Lemma 7. By Lemma 1, the regret is zero.
ř
Theorem 4. Let pϵ q8 be a non-increasing sequence and E “ T ϵ . Suppose that (i)
t t“1 T t“1 t
the conditions of Prop. 2 hold; (ii) the conditions of Lemma 3 hold; and (iii) E “ opTq and
T
E Ñ 8 (e.g., ϵ — 1{t). Then, the ϵ-greedy policy suffers zero regret: R pπ q “ 0.
T t 8 ϵ-greedy
Proof. This can be proved similarly to Theorem 3. Since E Ñ 8, by Lemma 3, p k a Ñ.s. κ˚.
T ET
Applying Lemma 7, we have
´ ¯
p
@ϵ ą 0, lim P A pE q “ 1. (75)
ϵ T
TÑ8
42Input: Budget B, Batch size S,
Exploration e, Cost c
p
1 k Ð κ ctr, Rounds J Ð tBp1´eq{Su;
2 n Ð 0;
3 for H P rBe,Slo,oo.m..o,ooSns do
Input: Budget B, Exploration e, Jtimes
p
Cost c 4 s Ð tH{pkJcqu;
1 n Ð tBe{pκJ ctrcqu; 5 n Ð n`s;
p
2 Collect n samples s.t. κ n “ κ ctr; 6 Collect s samples s.t. κ n “ k;
3 θp n Ð argmin θPΘQp npθ,pηp t´1qn t“1q; 7 θp n Ð argmin θPΘQp npθ,pηp t´1qn t“1q;
p p p p p p
54 Uk sÐ
e
ra er mg am inin inκ gP∆ bD uV dn gp eθ tn s, uκ cq hpκ tJ hc aq t; 8
9
pk kn ÐÐ pa rorg jpm p
k
nin ,∆κ ˜P j∆ `D 1qV n (sp eθ en, Eκ qqp .κ 7J 9c )q ;;
p ˜
κ T “ projpk,∆q (see Eq. 78); 10 end
p p p p
6 θ T Ð argmin θPΘQ Tpθ,pηp t´1qT t“1q; 11 θ T “ argmin θPΘQ Tpθ,pηp t´1qT t“1q;
p p
Output: f pθ q Output: f pθ q
tar T tar T
(a) The ETC-CS policy. (b) The ETG-CS policy.
Figure 6: Algorithms for OMS-ETC-CS and OMS-ETG-CS.
p
Since κ is getting as close as possible to k , by similar reasoning as Thm. 3, for some
t t
t ą E , we have
0 T
´ ¯
p
@ϵ ą 0, lim PpA pt qq ě lim P A pE q
ϵ 0 ϵ T
TÑ8 TÑ8
“ 1 (76)
6 κ a Ñ.s. κ˚, (77)
T
where (76) follows by Eq. 75, and (77) by Lemma 7. By Lemma 1, the regret is zero.
E OMS with cost structure
E.1 Feasible values of the selection simplex
Feasible values of κ for OMS-ETC-CS. The agent uses Be budget for exploration.
T
The number of samples collected after exploration is
Z ^
Be
T “ .
e κJ c
ctr
With the remaining Bp1´eq budget, the agent can collect samples with any κ P ∆ . The
D
total number of samples collected is
Z ^
Bp1´eq
T “ T ` .
e
κJc
43Therefore, the values of κ that can be achieved are
T
" *
T κ `pT ´T qκ
˜ e ctr e
∆ “ : κ P ∆ . (78)
D
T
Feasible values of κ for OMS-ETG-CS. Let the number of samples collected after
T
round j be T . For any κ P ∆ , the number of samples collected after round j `1 is
j D
Z ^
S
T “ T ` .
j`1 j
κJc
Therefore, the values that κ can achieve are
Tj`1
" *
T κ `pT ´T qκ
∆˜
“
j Tj j`1 j
: κ P ∆ . (79)
j`1
T
D
j`1
E.2 Proofs
Whenthedatasourceshaveanassociatedcoststructure, thehorizonT isarandomvariable
that depends on the policy π:
T “ maxtt P N : t¨pκJcq ď Bu. (80)
t
The proofs of consistency and asymptotic inference in the cost-structure setting are similar
to the uniform cost setting and so we only highlight the differences. Let c “ min c and
min i i
c “ max c be the minimum and maximum costs of the data sources. Observe that
max i i
B B
ď T ď .
lcoomoon locomoon
max min
Tmin Tmax
The horizon T Ñ 8 as B Ñ 8 and for a given budget B, the horizon T is a stopping time.
Therefore, if a sequence X is a MDS, then the sequence X 1pt ď Tq is also a MDS.
t t
To extend the consistency results to this setting, we show that the MDS SLLN (Cor. 1)
also holds for this random T.
Lemm řa 10. Let tX t,t P Nu be a martingale difference sequence such that sup kErX k2s ă 8.
Then T X {T a Ñ.s. 0 as B Ñ 8, where T is defined in Eq. 80.
t“1 t
Proof. We have
ˇ ˇ ˇ ˇ
ˇ
ˇ1
ÿT ˇ
ˇ T
ˇ
ˇ 1
Tÿ
max
ˇ
ˇ
ˇ X ˇ “ max ˇ X 1pt ď Tqˇ
ˇT tˇ T ˇT t ˇ
max
t“1 ˇ t“1 ˇ
c
ˇ
ˇ 1
Tÿ
max
ˇ
ˇ
ď max ˇ X 1pt ď Tqˇ
c ˇT t ˇ
min max
t“1
“ o p1q,
a.s.
where the last line follows by Corollary 1 (MDS SLLN).
44Proposition 5. Suppose that the conditions of Prop. 2 hold. Then,
´ ¯
? ` ` ˘˘
B βp ´β˚ Ñd N 0,V pκ q¨ κJc .
T κ8 ˚ 8 8
Proof. We can demonstrate asymptotic normality under the conditions of Prop. 2 for
c
1
ÿT
T 1
Tÿ
max
? X “ max ? X 1pt ď Tq.
T t loomToon T t
t“1
loooomooaoxooo to “oo 1mooooooooooooon
(A)
(B)
X \
p p
Since the horizon T Ñ B{κJc , for term (A), we have pT {Tq Ñ κJc{c . We can
8 max 8 min
apply the regular martingale CLT for term (B) and combine the two terms using the
Cramer-Slutsky theorem (Corollary 2).
Proposition 6. Suppose that the conditions of Prop. 2 and Lemma 2 hold. If e “ op1q
and Be Ñ 8 as B Ñ 8, then R pπ q “ 0.
8 ETC-CS
Proof. We prove this similarly to Theorem 1. Since we use Be budget for exploration, the
number of samples collected after exploration is
Z ^
Be
T “ .
e κJ c
ctr
The oracle simplex is estimated as
` ˘
p p p
k “ arg min V pθ ,κq¨ κJc .
Te Te Te
κP∆D
p p
Since T Ñ 8 as B Ñ 8, by Lemma 2, k Ñ κ˚. By Lemma 1, the regret is zero.
e Te
Proposition 7. Suppose that the conditions of Prop. 2 and Lemma 3 hold. If e “ op1q
and Be Ñ 8 as B Ñ 8, then R pπ q “ 0.
8 ETG-CS
Proof. We prove this in the same way as Theorem 3 with minor changes to account for
the cost structure. Let B :“ pBe`jSq denote the budget used after round j P r0,...,Js
j
for J “ Bp1´eq{S. Since we use a fixed budget S in each round, the number of samples
collected is random and depends on the selection simplex κ. The number of samples
collected after round j is
[ _
B
j
T “ .
j κJ c
Tj
Since the conditions of Lemma 3 hold, we have p k a Ñ.s. κ˚. Thus, for any ϵ ą 0,
t
´ ¯
p
lim P @t ą t˜: k P B pκ˚q “ 1.
t ϵ
t˜Ñ8
p
By the same argument as Theorem 3, since κ moves as close to k as possible after each
t t
round, we also have κ a Ñ.s. κ˚. Applying Lemma 1 completes the proof.
T
45F Proofs for asymptotic confidence sequences
Lem´m aa 11. ¯Let X
t
be a sequence of non-negative random variables such that (i) X
t
“
o logt{t , and (ii) sup ErX1`δs ă 8 for some δ ą 0. Then,
a.s. t t
ÿT ´a ¯
1
X “ o logT{T .
t a.s.
T
t“1
ř
Proof. Let S :“ T X . For any T ą t,
T t“1 t
ÿT
S S 1
T t
? ď ? ` ? X
i
T logT tlogt T logT
i“t`1
By the union bound, for any ϵ ą 0,
ˆ ˙ ˆ ˙ ˜ ř ¸
S S T X
P @T ą t : ? T ď 3ϵ ě 1´P ? t ą ϵ ´P DT ą t : ?i“t`1 i ą 2ϵ .
T logT loooooootoolmogotoooooooon T logT
loooooooooooooooooomoooooooooooooooooon
:“a
:“b
(81)
We show that Term a in Eq. 81 is op1q. By Markov’s inequality, we have
ˆ ˙ ř
S t ErX s
P ? t ą ϵ ď ?i“1 i
tlogt tlogtϵ
?
op tlogtq
“ ? (82)
tlogtϵ
“ op1q,
where (82) follows because ErX is “ oplogi{iq ( by Cond´i ations (i,¯ii) and Prop. 9). Next,
we show that Term b in Eq. 81 is op1q. Since X “ o logt{t , by Lemma 7, for any
t a.s.
ϵ ą 0,
´ a ¯
lim P @T ą t : X ă ϵ logT{T “ 1,
T
tÑ8 ˜ ¸
ÿT ÿT a
lim P @T ą t : X ă ϵ logi{i “ 1,
i
tÑ8
˜ i“t`1 i“t`1 ¸
ÿT a
lim P @T ą t : X ă 2ϵ T logT “ 1, (83)
i
tÑ8
˜ i ř“t`1 ¸
T X
lim P @T ą t : ?i“t`1 i ă 2ϵ “ 1,
tÑ8 T logT
ř a ?
where (83) follows because T logi{i ď 2 T logT. Plugging these results into Eq. 81
i“t`1
and applying Lemma 7 completes the proof.
46Proposition 14 (Strong approximation [Waudby-Smith et al., 2021, Lemma A.2]). Let
třX i,F i,1 ď i ď nu be a martingale difference sequence with σ i2 “ E i´1rX i2s and Γ
t
“
řt i“1σ i2. Suppose that (i) Γ
t
Ñ 8 a.s. and (ii) (Lindeberg condition) for some δ ą 0,
8 E r|X |21p|X |2 ą Γδqs{Γδ ă 8. Then, on a potentially enriched probability space,
t“1 t´1 t t t t
there exist i.i.d. standard Gaussians pG q8 such that
i i“1
˜ ¸
1 ÿn 1 ÿn Γ3{8logpΓ q
X ´ σ G “ o t t .
i i i a.s.
n n t
i“1 i“1
Lemma 12 (Time-uniform Gaussian tail bound). Let pσ q8 be a sequence of positive ran-
i i“1
dom variables řthat are predictable w.r.t. the filtration pF iq8 i“1, that is, σ
i
is F i´1-measurable.
Define Γ “ t σ . Let pG q8 be a sequence of i.i.d. standard Gaussian random vari-
t i“1 i i i“1
ables. Then, for any constant ρ ą 0 and α P p0,1q,
˜ ˇ ˇ d ¸
ˆ ˙
ˇ
ˇ1
ÿt ˇ
ˇ Γ ρ2 `1 Γ ρ2 `1
P @t ě 1,ˇ σ G ˇ ď t log t ě 1´α.
ˇt i iˇ t2ρ2 α2
i“1
Proof. See Step 2 of the proof of Proposition 2.5 in Waudby-Smith et al. [2021].
Theorem 5. Suppose that (i) the Conditions of Lemma 3 hold; (ii) Assumption 8 holds;
(iii) Dδ ą 0,@i P rMs such that Er|ψpiq pθ˚,η˚q|2`δs ă 8; and (iv) κ a Ñ.s. κ˜ for some constant
t T
κ˜ P ∆ . Then, for any ρ P R and α P p0,1q, the following time-uniform bound holds:
D ą0
¨ ˛
g
˚ f ˜ ¸ ˜c ¸‹
˚ ˇ ˇ f p p ‹
P˚
˚@t P N :
ˇ ˇβp ´β˚ˇ
ˇ ď
etV tρ2 `1
log
tV tρ2 `1
`o
logt ‹
‹ ě 1´α,
˚ t t2ρ2 α2 a.s. t ‹
˝ ‚
loooooooooooooooooomoooooooooooooooooon
:“C¯
t
p
where V is the estimated variance defined in Eq. 4.
t
Proof. For i P rMs and D “ ψpiq pθ˚,ηp q´ψpiq pθ˚,η˚q,
t t t´1 t
ÿT
1
m ps qψpiq pθ˚,ηp q
T i t t t´1
t“1
ÿT ÿT ÿT
1 1 1
“ m ps qψpiq pθ˚,η˚q` m ps qrD ´E rD ss` m ps qE rD s.
T i t t T i t t t´1 t T i t t´1 t
looooooooooooooooomooooooooooooooooon loooooooooooomoooooooooooon
t“1 t“1 t“1
EP(Empiricalprocess) Bias
47?
Term EP. The sequence D ´E rD s is a MDS. To show that Term EP is o p1{ Tq,
t t´1 t ? a.s.
we apply Prop. 8 (MDS SLLN) with b “ t:
t
“ ‰ “ ‰
ÿ8 E m ps qpD ´E rD sq2 ÿ8 E pD ´E rD sq2
i t t t´1 t t t´1 t
ď (84)
b2 t
t“1 t t“1
ÿ8
ErD2s
ď t
t
t“1
ÿ8
LEr}ηp ´η˚}2s
ď
t´1
(85)
t
t“1 ˆ ˙
ÿ8
L
ď O (86)
t1`2γ
t“1
ă 8,
where (84) follows be řcause m ips tq P t0,1u, (85) b ?y Property 1(ii), and (86) by Assump-
tion 8(d). Therefore, T m ps qrD ´E rD ss{ T a Ñ.s. 0.
t“1 i t t t´1 t
´ ¯
a
Term Bias. Next, we show that Term Bias is o logT{T . As shown in the proof
a.s.
of Prop. 2, by Neyman orthogonality (Assumption 8(a)),
ÿT ÿT ´a ¯
1 1
m ps qE rD s ď R p “aq o logT{T ,
T
i t t´1 t
T
t a.s.
t“1 t“1
where (a) follows by Lemma 11. Using these results, it follows that
ÿT ÿT ´a ¯
1 1
g pθ˚,ηp q “ g pθ˚,η˚q`o logT{T . (87)
T
t t´1
T
t a.s.
t“1 t“1
Recall from Eqs. 27 and 42 that
” ı ÿT
θp ´θ˚ “ ´ Gp Jpθp qΩp pθp posq q´1Gp pθ˜ q ´1 Gp Jpθp qΩp pθp posq q´1 1 g pθ˚,ηp q,
T T T T T T t t´1
t“1
βp ´β˚ “ ∇ f pθ˜ qJpθp ´θ˚q.
T θ tar T
For κ˜ defined in Condition (iii), by Lemma 3, we have Gp Jpθp q a Ñ.s. G pκ˜q and Ωp pθp posq q a Ñ.s.
“ ‰ T ˚ T
Ω pκ˜q. For M pκ˜q :“ ´∇ f pθ˚qJ G pκ˜qJΩ pκ˜q´1G pκ˜q ´1 G pκ˜qJΩ pκ˜q´1 P R1ˆM,
˚ ˚ θ tar ˚ ˚ ˚ ˚ ˚
ÿT
p 1
β ´β˚ “ rM pκ˜q`o p1qs g pθ˚,ηp q
T ˚ a.s. T t t´1
# t“1 ˜c ¸+
ÿT
1 logT
“ rM pκ˜q`o p1qs g pθ˚,η˚q`o (88)
˚ a.s. T t a.s. T
t“1 ˜c ¸
ÿT
1 logT
“ M pκ˜qg pθ˚,η˚q`o ,
T ˚ t a.s. T
t“1
48where (88) follows by Eq. 87.
ř The sequence M ˚pκ˜qg tpθ˚,η˚q is a MDS. Let σ t2 :“ E t´1rpM ˚pκ˜qg tpθ˚,η˚qq2s and Γ T “
T σ2. The Lindeberg condition in Prop. 14 is implied by the Lyapunov condition
t“1 t
[Waudby-Smith et al., 2021, Appendix B.5] shown to hold for Prop. 2. Thus, by Prop. 14,
˜ ¸
ˆ ˙
1 ÿT 1 ÿT Γ3{8logpΓ q logpTq
M pκ˜qg pθ˚,η˚q´ σ G “ o T T “ o
T ˚ t T t t a.s. T a.s. T5{8
t“1 t“1 ˜c ¸
ÿT
p 1 logT
6 pβ ´β˚q´ σ G “ o .
T t t a.s.
T T
t“1
By Lemma 12,
˜ ˇ ˇ d ¸
ˆ ˙
ˇ
ˇ1
ÿt ˇ
ˇ Γ ρ2 `1 Γ ρ2 `1
P @t ě 1,ˇ σ G ˇ ď t log t ě 1´α
ˇt i iˇ t2ρ2 α2
˜ i“1 d
ˆ ˙
˜c ¸¸
ˇ ˇ
6 P @t ě
1,ˇ ˇβp ´β˚ˇ
ˇ ď
Γ tρ2 `1
log
Γ tρ2 `1
`o
logt
ě 1´α. (89)
t t2ρ2 α2 a.s. t
We now derive an asymptotic confidence sequence in terms of the empirical variance:
ÿT
1 1
Γ “ E rpM pκ˜qg pθ˚,η˚qq2s
T T T t´1 ˚ t
t“1
ÿT
1
“ M pκ˜qE rg pθ˚,η˚qgJpθ˚,η˚qsMJpκq
T ˚ t´1 t t ˚
t“1
“ M pκ˜qrm pκ qdΩpθ˚,η˚qsMJpκq (90)
˚ Ω T ˚
“ M pκ˜qΩ pκqMJpκq`o p1q (91)
˚ ˚ ˚ a.s.
“ ∇ f pθ˚qJΣ pκ˜q∇ f pθ˚q`o p1q (92)
θ tar ˚ θ tar a.s.
“ V pκ˜q`o p1q, (93)
˚ a.s.
a.s.
where (90) follows by Eq. 38, (91) because κ Ñ κ˜, and Σ pκ˜q in (92) is defined in Eq. 41.
T ˚
p a.s. p
Under the conditions of Lemma 3, we have shown that V Ñ V pκ˜q, where V is the
T ˚ T
empirical variance estimator defined in Eq. 4. Combining this with Eq. 93, we have
ˇ ˇ
ˇ ˇ
ˇ1 p ˇ a.s.
ˇ Γ ´V ˇ Ñ 0.
T T
T
49Plugging this result into Eq. 89, we get
g
d ˆ ˙ f ˜ ¸
f p p
Γ ρ2 `1 Γ ρ2 `1 eptV `o ptqqρ2 `1 ptV `o ptqqρ2 `1
t t t a.s. t a.s.
log “ log
t2ρ2 α2 t2ρ2 α2
g
f˜
ˆ
˙¸ «˜ ¸ ff
f p p
e tV ρ2 `1 1 tV ρ2 `1
t t
“ `o log p1`o p1qq
t2ρ2 a.s. t α2 a.s.
g
f˜
ˆ
˙¸« ˜ ¸ ff
f p p
e tV ρ2 `1 1 tV ρ2 `1
t t
“ `o log `logp1`o p1qq
t2ρ2 a.s. t α2 a.s.
g
f˜
ˆ
˙¸« ˜ ¸ ff
f p p
paq e tV tρ2 `1 1 tV tρ2 `1
“ `o log `o p1q
t2ρ2 a.s. t α2 a.s.
g
f ˜ ¸ ˆ ˙ ˆ ˙ ˆ ˙
f p p
etV ρ2 `1 tV ρ2 `1 1 logt 1
t t
“ log `o `o `o
t2ρ2 α2 a.s. t a.s. t a.s. t
g
f ˜ ¸ ˆ ˙
f p p
etV ρ2 `1 tV ρ2 `1 logt
t t
“ log `o
t2ρ2 α2 a.s. t
g
f ˜ ¸ ˜c ¸
f p p
pbq etV ρ2 `1 tV ρ2 `1 logt
t t
ď log `o ,
t2ρ2 α2 a.s. t
? ? ?
where (a) follows because logp1`o p1qq “ o p1q, and (b) because a`b ď a` b.
a.s. a.s.
This allows us to construct a p1´αq AsympCS using the empirical variance:
¨ g ˛
f ˜ ¸ ˜c ¸
ˇ ˇ f p p
P˝
@t ě
1,ˇ ˇβp ´β˚ˇ
ˇ ď
etV tρ2 `1
log
tV tρ2 `1
`o
logt ‚
ě 1´α.
t t2ρ2 α2 a.s. t
G Convergence rates for nuisance estimation
Some of our results require almost sure convergence of the nuisance estimators. In this
section, we illustrate how non-asymptotic tail bounds from learning theory can be used to
verify convergence rates. Consider the standard nonparametric regression setup:
y “ f˚px q`ν ,
i i i
where y P R is the response variable, x P X are the covariates, f˚pxq “ ErY|X “ xs, and
i i
ν is an independent exogenous noise term. Given n i.i.d. samples of tx ,y un , suppose
i i i i“1
p
that the estimator f is obtained by solving the following minimization problem:
# +
ÿn
p 1
f P argmin py ´fpx qq2 ,
i i
fPF n
i“1
50where F is a suitably chosen function class such that f˚ P F. Under suitable restrictions
on F, the following tail bound can be obtained:
´ ¯
` ˘
p
P }f ´f˚} ą c δ ă c exp ´c nδ2 , (94)
0 n 1 2 n
where c , c , and c are constants, and δ depends on the richness of the function class F
0 1 2 n
(e.g., themetricentropy). Forexample, whenF istheclassofconvex1-Lipschitzfunctions,
Eq. 94 holds with δ “ n´2{5 [Wainwright, 2019, Example 14.4]. We refer the reader to
n
Wainwright [2019, Chapters 13, 14] for more details. The tail bound in Eq. 94 along with
the the Borel–Cantelli lemma can be used to verify almost sure convergence rates:
Proposition 15. Suppose that (i) Eq. 94 holds; and (ii) nδ2 “ nγ for some γ ą 0. Then,
n
p
for any α ě 0 such that nαδ “ op1q, we have }f ´f˚} “ o pn´αq.
n a.s.
Proof. By Eq. 94, we have
´ ¯ ´ ¯
p p
P }f ´f˚} ą c δ “ P nα}f ´f˚} ą c nαδ
0 n 0 n
` ˘
ă c exp ´c nδ2 .
1 2 n
Since nαδ “ op1q, for any ϵ ą 0, there is a large enough n such that @n ą n ,ϵ ą c nαδ .
n 0 0 0 n
Then,
ÿ8 ´ ¯ ÿ8 ´ ¯
p p
P nα}f ´f˚} ą ϵ ď n ` P nα}f ´f˚} ą c nαδ
0 0 n
n“1 n“n0
ÿ8 ` ˘
ă n ` c exp ´c nδ2
0 1 2 n
n“n0
ÿ8
“ n ` c expp´c nγq
0 1 2
n“n0
ă 8.
p
Therefore, by the Borel–Cantelli lemma, we have }f ´f˚} “ o pn´αq.
a.s.
H Experiments
H.1 Nonlinear two-sample IV
In this section, we present additional details for the synthetic experiments with nonlinear
causal models (Section 7.1). The structural equations for generating the data are:
W „ Uniformr´θ ,θ s,
w w
U „ Uniformr´θ ,θ s,
u u
Z „ Bernoullipωpf pWqqq,
Z
X „ Bernoullipωpf pUq`f pW,Zq`b qq,
U WZ Z
Y :“ f pUq`f pW,Xq`b `Uniformr´θ ,θ s,
Y.U WX Y y y
511.0
0.8
0.6
etc_0.1 etc_0.2 etg_0.1 etg_0.2 etg_0.4 fixed
0.4
Relative regret vs Horizon Relative regret vs Horizon Relative regret vs Budget
0.2 40
20
0.0 35 40
15 0.0 0.2 30 0.4 0.6 0.8 1.0
30
10 25
20 20
5
15
10
0
10
5 5 0
2000 3000 4000 5000 6000 7000 8000 2000 3000 4000 5000 6000 7000 8000 2000 4000 6000 8000 10000 12000
Horizon T (total samples collected) Horizon T (total samples collected) Budget B
(a) Example 2 (b) Example 3 (c) Example 4
Figure 7: The relative regret of different policies across various horizons/budgets for three
ATE estimation tasks (error bars denote 95% CIs). We simulate data from synthetic linear
causal models and use linear nuisance estimators. In all cases, the online data collection
policies outperform the fixed policy as the horizon increases.
where ωp.q is the sigmoid function; θ ,θ ,b ,b P R are the model parameters; f p.q are
w u Z Y ˚
nonlinear functions generated using 100 random Fourier features [Rahimi and Recht, 2007]
that approximate a Gaussian Process 3 ; and U is an unmeasured confounder.
H.2 Synthetic Linear Causal Models
We also evaluate our methods on three tasks where the data is generated from linear causal
models (Fig. 7). We use linear models for nuisance estimation. Since a correctly specified
?
parametric model is used, we obtain n-convergence rates for nuisance estimation.
We first test our methods on the two-sample LATE estimation task (see Example 2
and Fig. 1a) where the data sources are D “ pPpW,Z,Yq,PpW,Z,Xqq. We set the model
parameters such that the oracle simplex is κ˚ « r0.65,0.35sJ. We compare the relative
regrets of our proposed policies to a fixed policy that queries both data sources equally
with κ “ r0.5,0.5sJ (Fig. 7a). The fixed policy suffers constant relative regret of « 15%.
T
By contrast, the ETC and ETG policies have close to zero relative regret as the horizon T
increases, demonstrating the efficiency gained using adaptive data collection.
Next, wetestourmethodsontheATEestimationtaskfortheoveridentifiedconfounder-
mediator causal graph where both the backdoor and frontdoor identification strategies hold
(see Example 3 and Fig. 1b). The data sources are D “ pPpW,X,Yq,PpX,M,Yqq. We
set the model parameters such that the oracle simplex is κ˚ “ r0,1sJ, i.e., the frontdoor
estimator is more efficient. We compare our proposed policies to a fixed policy that queries
both data sources uniformly (see Fig. 7b). We observe that all adaptive policies outperform
the fixed policy significantly (we omit etc because it performs similarly as etg). However,
the relative regret increases as the exploration increases (etg 0.1 performs the best) since
it reduces the available budget for getting close to the oracle simplex.
Next, we test our methods on the ATE estimation task in Example 4 (also see Fig. 1c)
with a non-uniform cost structure. The data sources are D “ pPpU,W,X,Yq,PpW,X,Yqq.
We set the cost structure c “ r2,1s, i.e., querying the first data source is twice as costly. We
set the model parameters such that the oracle simplex is κ˚ « r0.4,0.6sJ. We compare our
3We used the code from https://random-walks.org/book/papers/rff/rff.html.
52
)%(
terger
evitaleR
)%(
terger
evitaleR
)%(
terger
evitaleRproposed policies to a fixed policy that queries only the first data source with κ “ r1,0sJ
T
(see Fig. 7c). The fixed policy suffers a constant relative regret of « 35%. We observe
that the ETC and ETG policies suffer high relative regret at lower budgets. As the budget
increases, the ETC and ETG policies converge to zero relative regret.
I Examples of Online Moment Selection
Example 3 (more details). Consider the confounder-mediator causal graph (Fig. 1b)
with a binary treatment X, mediator M, outcome Y, confounder W. The target parameter
is the causal effect of X on Y, i.e., β˚ “ ErY|dopX “ 1qs ´ ErY|dopX “ 0qs [Pearl,
2009]. With D “ tPpW,X,Yq,PpX,M,Yqu, β˚ can be estimated with the backdoor or the
frontdoor criterion [Pearl, 2009, Sec. 3.3]. The moment conditions can be written as
„ ȷ „ ȷ
s ψ ppW ,X ,Y q;η(AIPW)q´β
g pθq “ t,1 d AIPW t t t ,
t p1´s q ψ ppX ,M ,Y q;η(fd)q´β
t,1 fd t t t
where ψ is defined in Eq. 3 and ψ is the efficient influence function for the frontdoor
AIPW fd
estimand [Fulcher et al., 2020]:
p pM q´p pM q
ψ ppX ,M ,Y q;η(fd)q “ 1 t 0 t pY ´ErY|X ,M sq`
fd t t t ˚ p pM q t t t
X¨t t ˛
ÿ ÿ
X t ´p1´X tq ˝ ErY|x,M sppxq´ ErY|x,msp pmqppxq‚ , (95)
ppX q
t Xt
t
xPt0,1u x,m
ÿ
` ErY|X ,mspp pmq´p pmqq.
t 1 0
m
where p pmq “ PpM “ m|X “ xq.
x
Example 5 (Adaptive Neyman allocation). Consider the setting of a randomized con-
trolled trial with a binary treatment. Let Yp1q and Yp0q denote the potential outcomes
[Imbens and Rubin, 2015] for an individual in the treatment and control group, respec-
tively. For each incoming subject, the experimenter must decide whether to assign them
to the treatment or the control group [Zhao, 2023, Neyman, 1934]. For this setting, take
D “ tPpYp1qq, PpYp0qqu, and
„ ȷ „ ȷ
s Y p1q´β ´α
g pθq “ t,1 d t ,
t 1´s Y p0q´α
t,1 t
where θ “ rβ,αsJ and f pθq “ β is the target parameter (the ATE).
tar
Example 6 (Long-term treatment effects). In this setting, the aim is to combine exper-
imental data on short-term outcomes and observational data on long-term outcomes to
estimate the long-term treatment effect [Athey et al., 2020]. The efficient influence func-
tion in Chen and Ritzwoller [2023, Theorem 3.1] can be incorporated into our framework.
In the notation of Chen and Ritzwoller [2023], we have
« ff
„ ȷ
s w´p1´wqpy ´µ ps,xqq`µ¯ pxq´µ¯ pxq´β `α
g pθq “ t,1 d ρwps,xq w 1 0 ,
t p1´s t,1q wϱpxq`w p´ 1´p1 w´ qw p1q ´ϱpxqqpµ wps,xq´µ¯ wpxqq´α
where the target parameter β is the long-term ATE.
53