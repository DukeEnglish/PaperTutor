Multilingual Needle in a Haystack: Investigating Long-Context Behavior of
Multilingual Large Language Models
AmeyHengle1,PrasoonBajpai1,SohamDan2,TanmoyChakraborty1
1IndianInstituteofTechnologyDelhi,India;2Independent
{ameyhengle22,prasoonbajpai786,sdan021}@gmail.com,tanchak@iitd.ac.in
Abstract
English
Whilerecentlargelanguagemodels(LLMs)demonstratere-
markable abilities in responding to queries in diverse lan-
Arabic German guages,theirabilitytohandlelongmultilingualcontextsis
unexplored. As such, a systematic evaluation of the long-
contextcapabilitiesofLLMsinmultilingualsettingsiscrucial
specificallyinthecontextofinformationretrieval.Toaddress
thisgap,weintroducetheMultiLingualNeedle-in-a-Haystack
(MLNeedle)test,designedtoassessamodel’sabilitytore- 0 25 50 75 100
trieverelevantinformation(theneedle)fromacollectionof
Hindi Spanish multilingualdistractortexts(thehaystack).Thistestserves
asanextensionofthemultilingualquestion-answeringtask,
encompassingbothmonolingualandcross-lingualretrieval.
Weevaluatefourstate-of-the-artLLMsonMLNeedle.Our
findingsrevealthatmodelperformancecanvarysignificantly
withlanguageandneedleposition.Specifically,weobserve Vietnamese Chinese
thatmodelperformanceisthelowestwhentheneedleis(i)
inalanguageoutsidetheEnglishlanguagefamily,and(ii)
llama3-8b-instruct cohere-aya-23-8b mistral-7b-instruct-v0.2
locatedinthemiddleoftheinputcontext.Furthermore,al-
though some models claim a context size of 8k tokens or
greater,nonedemonstratesatisfactorycross-lingualretrieval Figure1:Monolinguallong-contextperformance(accuracy
performanceasthecontextlengthincreases.Ouranalysispro- in radial axis) for various LLMs averaged across different
vides key insights into the long-context behavior of LLMs contextsizes(4K,8K,16K,and32K).Weobserveaconsid-
inmultilingualsettingstoguidefutureevaluationprotocols. erabledropinperformanceforalllanguagesexceptEnglish,
To our knowledge, this is the first study to investigate the suggestingthatmultilingualLLMsstruggletoprocessnon-
multilinguallong-contextbehaviorofLLMs. English(ornon-Latin)longinputcontexts.
1 Introduction ofthiscapacityisoftensuboptimal.Furthermore,Liuetal.
(2023)highlightedamajorproblemfacedbyLLMswhile
Inrecentyears,LargeLanguageModels(LLMs)havedemon-
handling long contexts: a marked decline in performance
stratedremarkablecapabilitiesacrossawiderangeofnatural
whentherelevantinformationislocatedinthemiddleofa
languageprocessingtasks,includingtextgeneration,trans-
longinputcontext.Theperformancecurveischaracteristi-
lation, and question-answering. A critical aspect of these
cally“U-shaped”,wheremodelsexhibitbetteraccuracywhen
models is their ability to handle long input contexts effec-
therelevantinformationisatthebeginningorendofthecon-
tively—acapabilitythatisessentialforapplicationssuchas
text,underscoringthechallengesLLMsfaceinmaintaining
documentsummarization,long-formcontentgeneration,and
attentionandrelevancethroughoutanentireinputsequence.
multi-turndialoguesystems(Petronietal.2020;Lee,Liang,
This phenomenon, dubbed the lost-in-the-middle problem,
andYang2022;Thoppilanetal.2022).Thisabilitydirectly
suggests that current LLMs are not yet fully equipped to
impactstherelevanceandaccuracyofLLMresponsesover
handle long contexts robustly and reliably, particularly in
long inputs (Khandelwal et al. 2018; Mallen et al. 2023a;
tasksthatrequireretrievalofdispersedinformation(Liuetal.
Shahametal.2023a;Kandpaletal.2023a).
2023;Ivgi,Shaham,andBerant2023;Wangetal.2024).
Arecentstudy(Hsiehetal.2024a)hasshedlightonthe
potentialandlimitationsofLLMsinhandlingextendedse- Whilethesepapersshedsomelightonthelong-contextca-
quences. They evaluate various attention mechanisms and pabilitiesofLLMs,asignificantresearchgapremains:most
modelarchitectures,revealingthatwhilesomemodelscan existing benchmarks and evaluations have focused exclu-
technicallymanagelongcontexts,theireffectiveutilization sivelyonmonolingualEnglishsettings.Thisleavesacritical
4202
guA
91
]LC.sc[
1v15101.8042:viXraquestionunanswered:HowdoLLMsperformwhenthelong 2.1 ExperimentalSetup
inputcontextsaremultilingual,particularlywhenthecontext
In the multilingual question-answering task, the model is
isinalow-resource,non-Latinlanguage?AsshowninFigure
provided with a question Q to answer and K documents.
1,LLMsusuallyperformpoorlywhilehandlingnon-English
Amongthesedocuments,exactlyonecontainsthecorrectan-
longcontexts.Furthermore,multilingualandcross-lingual
swertothequestionQ,whiletheremainingK−1distractor
contexts introduce additional complexities, such as varied
documentsdonot.Wedenotethedocumentcontainingthe
syntax,grammar,andsemanticnuances,whichcansignifi-
correctanswerasN (theneedle)andtheK −1distractor
cantlyaffectamodel’sretrievalandprocessingcapabilities.
documentsasH (thehaystack).Figure2offersanoverview
Inthispaper,weaddressthisgapbyanalyzinghowLLMs
ofourevaluationsetupusingarandomlysampledexample
processandretrieveinformationfromlongmultilingualcon-
fromtheMLNeedledataset(detailsinSection2.2).Asillus-
texts.Specifically,weintroducetheMultiLingualNeedle-in-
tratedinthefigure,wesystematicallychangethelanguage
a-Haystack(MLNeedle)test,whichextendsthemultilingual
ofboththeneedle(highlightedingreen)andthedistractor
question-answeringtasktoassesstheLLM’sabilitytolocate
documents(highlightedinred)duringourexperiments.The
and extract relevant information (the needle) from a large
contentofN andH remainsunchanged,onlythelanguage
collectionofmultilingualdistractortexts(thehaystack).Our
varies.Therefore,theLLM’sperformanceshouldideallynot
experimentssystematicallyvarythelanguageandpositionof
fluctuate due to these changes. We also vary the position
theneedlewithinthehaystacktoevaluatetherobustnessof
of N within the input context, as highlighted in Figure 9
severalstate-of-the-artLLMsinhandlingmultilinguallong
(Appendix),tounderstandtheeffectontheLLM’sabilityto
contexts.wemakethefollowingcontributions1:
retrieve.ThelanguageofthequestioniskeptfixedinEnglish.
• WeintroducetheMultilingualNeedleinaHaystack(ML-
2.2 TheMLNeedleDataset
Needle)test,afirststeptowardssystematicallyevaluat-
ing the long-context capabilities of multilingual LLMs. We instantiate MLNeedle with the MLQA dataset (Lewis
MLNeedleassessesmodelperformanceacrosssevenlan- etal.2020),whichconsistsofover5Kextractivequestion-
guages in both monolingual and cross-lingual settings, answerinstancesacrosssevenlanguages(English,Arabic,
providingacomprehensivebenchmarkforfutureresearch. German, Spanish, Hindi, Vietnamese, and Simplified Chi-
nese) in the SQuAD (Rajpurkar et al. 2016) format. We
• Weconductaseriesofcontrolledexperimentstoexamine
chooseMLQAbecauseofitsaligneddatasetstructure,where
howchangesinthelanguageandpositionoftheneedle
eachquestion-answerpairispresentinmultiplelanguages.
affectmodelperformance.OurfindingsrevealthatLLM
Specifically, for each question-answer instance, there are
performanceishighlysensitivetoboththelanguageand
correspondingversionsinatleastfourdifferentlanguages,
positionoftheneedleinthehaystack.
allowingforadirectcomparisonofhowthesamequestion
• WedemonstratetherelativerobustnessofLLMstovaria- isansweredacrossvariouslinguisticcontexts.Wehighlight
tionsinthelanguageofdistractorpassages,indicatingthat thisinFigure2(a),whereforthegivenquestion,theneedle
thekeychallengeslieinhowLLMsprocessandretrieve documentwiththecorrectanswercanbepresentedinboth
theneedlefromdiverselinguisticenvironments. EnglishaswellasHindi.Thissettingallowsustosystemati-
callystudytheeffectofchangingthelanguageoftheneedle
• Weperformseveralablationstudiestounderstandtherole
N.
oftemperaturesampling,instructiontuningandthechoice
ofevaluationmetriconperformance.
ConstructingtheHaystack(H). InMLNeedle,wecollect
the K −1 distractor documents for each question-answer
pairusingthefollowingprocedure:weuseWikipediapas-
2 MultiLingualNeedleinaHaystack
sagesfrommMARCO(Bonifacioetal.2022),awell-known
multilingual passage ranking dataset, as the source of the
Inthissection,weintroduceourMultiLingualNeedleina
distractordocuments.Foreachquestion-answerpair,weuse
Haystack(MLNeedle)benchmark.Asourgoalistobetterun-
multilingualsentence-BERT(ReimersandGurevych2020)
derstandhowLLMsprocessmultilingualinputcontexts,we
toretrieveK−1documentsfrommMARCOthataremost
analyzetheperformanceofthemodelonamultilingualques-
relevanttothequestionbutdonotcontaintheanswer.Ap-
tionansweringtask,whichrequiresamodeltofindrelevant
pendix A provides a detailed explanation of our retrieval
information(theneedle)fromtheinputcontext(thehaystack)
system.Inthefinalinputcontext,wearrangethesedistractor
toanswerthegivenquestion.Specifically,weconductexper-
documentsinorderofdecreasingrelevance.Ashighlighted
iments where we systematically change (i) the position of
inTable1,weconductexperimentsacrossdifferentcontext
theneedle,(ii)thelanguageoftheneedle,and(iii)thelan-
sizes ranging from 4K up to 32K tokens. To modulate the
guageofthehaystack,andstudytheeffectonperformance.
contextlength,wesimplyincreaseordecreasethenumber
IfLLMsareabletouseinformationfromlongmultilingual
ofdistractordocumentsinH.Furtherdetailsonvaryingthe
contexts,theirperformanceshouldremainrelativelystable
contextlengthcanbefoundinAppendixC.
regardlessofchangesinlanguageorneedleposition.
PositioningtheNeedle(N). Wemodulatethepositionof
1The source code and datasets are available at https://github. the relevant information within the input context by plac-
com/AmeyHengle/multilingual-needle-in-a-haystack ingthedocumentwiththecorrectanswer(N)ateithertheWrite a high-quality answer for the given question using only the provided Write a high-quality answer for the given question using only the
passages (some of which might be irrelevant). provided passages (some of which might be irrelevant).
### Passages ### Passages
[0] John Francis "Jack" Welch Jr. (born November 19, 1935) is an American [0] जॉन फ्रां  सस "जैक" वेल् श, जू  नयर (जन् म 19 नवम्बर 1935) अमे  रकी व् यवसायी और
business executive, author, and chemical engineer. He was chairman and लेखक हैं। 1981 से 2001 के बीच वह जनरल इलेि  क्ट्रिक के अध्यक्ष और सीईओ (CEO) रहे.
CEO of General Electric between 1981 and 2001. During his tenure at GE, वेल् श की कुल अनुमा  नत संप  त्ति 720  म  लयन डॉलर है।
(a) the company's value rose 4,000%. In 2006, Welch's net worth was
estimated at $720 million. Question: John Welch Jr. was CEO of what company beginning in 1981?
Question: John Welch Jr. was CEO of what company beginning in 1981? Answer:
Answer:
Write a high-quality answer for the given question using only the
Write a high-quality answer for the given question using only the provided
provided passages (some of which might be irrelevant).
passages (some of which might be irrelevant).
### Passages
### Passages
[0] Wenn beispielsweise General Electric (GE) im letzten Quartal ..,
[0] For example, if General Electric (GE) … If General Electric's stock price
würde die Dividendenrendite 3,5% (0,68 US-Dollar dividiert durch 19,42
was $19.42, its dividend yield would be 3.5% ($0.68 divided by $19.42).
US-Dollar) betragen.
[1] John Francis "Jack" … During his tenure at GE, the company's value
(b) rose 4,000%. In 2006, Welch's net worth was estimated at $720 million. [1] जॉन फ्रां  सस "जैक" वेल् श, जू  नयर (जन् म 19 नवम्बर 1935) … रहे. वेल् श की कुल
अनुमा  नत संप  त्ति 720  म  लयन डॉलर है।
[2] John Connolly, EdD, President and CEO of Castle Connolly … John
[2] John Connolly, EdD, Präsident und CEO von Castle Connolly, … hat
Connolly, EdD, has disclosed no relevant financial relationships in
neben seiner Anstellung keine relevanten finanziellen Beziehungen
addition to his employment.
offengelegt.
Question: John Welch Jr. was CEO of what company beginning in 1981?
Question: John Welch Jr. was CEO of what company beginning in 1981?
Answer:
Answer:
Desired Answer: General Electric | जनरल इलेि  क्ट्रिक
Figure 2: Example of a multilingual question-answering input from the MLNeedle dataset. (Top) There are no distractor
documents and the same needle (highlighted in green) is present in English (Left) and Hindi (Right); (Bottom) There are
distractordocumentspresent(highlightedinred)andthesameneedleispresentinEnglish(Left)andHindi(Right).
start,middle,orendofH (Figure9inAppendix),following Mallenetal.2023b)asourprimaryevaluationmetric.Ad-
priorexperimentalsetups(Liuetal.2023;Ivgi,Shaham,and ditionally, in our ablation study (see Section 4), we report
Berant2023). existenceaccuracy(Wangetal.2024),whichevaluatesthe
secondarytaskofdeterminingwhetherrelevantinformation
2.3 Models ispresentwithintheinputcontext.Below,weformallydefine
eachofthesemetrics:
We analyze several state-of-the-art open-source language
modelsforourevaluation,spanning32K,8K and4K mod- • Exact Accuracy measures the proportion of samples
els.WereportMistral-7B-Instruct-v0.2(Jiangetal.2023), wherethemodel’spredictedoutputcontainsanyofthe
whichfeaturesamaximumcontextlengthof32,768tokens correctanswers,asspecifiedintheMLQAdataset.This
and is a multilingual model capable of understanding and metric checks whether the ground-truth answer is con-
generating text in multiple languages. It makes use of a tainedinthemodel’spredictions.
unique positional encoding method, ALiBi (Press, Smith, • ExistenceAccuracyistheproportionofsampleswhere
andLewis2022),toeffectivelymanagelong-rangedepen- themodelcorrectlyidentifieswhetheradocumentcon-
dencies.Next,weevaluateCohere-Aya-23-8B(Aryabumi tainingthecorrectanswerexistswithintheinputcontext.
etal.2024),whichalsosupportsmultilingualcapabilitiesand
Wedefinetheevaluationprompttemplatesforrespective
hasacontextsizeof8,192tokens.Thismodelisdesigned
tasksinAppendixB.Forconsistency,weusethesameevalu-
toperformwellacrossvariouslanguagetasks.Weinclude
ationpromptsacrossallmodelsinourexperiments.Further-
Llama3-8B-Instruct(AI@Meta2024),aninstructionfine-
more,foreachinputprompt,themodelgeneratesaprediction,
tunedversionoftheLlama3basemodel(DubeyandJauhri
whichmaybeinadifferentlanguagefromthegroundtruth.
2024),whichsupportsacontextsizeof8,192tokens.This
Toensureaccuratecomparison,wetranslatethepredictionto
modelisoptimizedforfollowinginstructionsandengagingin
English(sinceeachinstancehasagoldenanswerinEnglish
open-endeddialogue.Lastly,weevaluateLlama2-7B-Chat
in MLQA) using Google Translate API2. We then use the
(TouvronandMartin2023),whichhasamaximumcontext
translatedpredictionsandthegroundtruthtocalculateExact
lengthof4,096tokens.
Accuracyasdefinedearlier.Furtherdetailsofourevaluation
frameworkaregiveninAppendixD.
2.4 EvaluationMetric
Asweevaluatethemodel’sabilityforretrievalinquestion-
answering, we use exact accuracy (Kandpal et al. 2023b; 2GoogleTranslateAPIModel ClaimedLength EffectiveLength Baseline 4K 8K 16K 32K Avg.
Llama2-7B-Chat 4K <4K 0.335 0.171 − − − 0.253
Llama3-8B-Instruct 8K 4K 0.622 0.479 0.295 − − 0.465
Cohere-Aya-23-8B 8K 4K 0.700 0.460 0.449 − − 0.536
Mistral-7B-Instruct-v0.2 32K 8K 0.579 0.485 0.455 0.427 0.397 0.469
Table1:Long-contextperformanceofselectedmodelsontheMLNeedletest.Modelsareevaluatedforcontextlengthsranging
from4Kto32K.EachscoreisdeterminedbyaveragingtheaccuracyofMLNeedle’smultilingualquestion-answeringtask.The
effectivelengthisthemaximumcontextlengthbeyondwhichthemodel’sperformancedecreasesbymorethan25%fromits
baselineperformance.Theaccuracyvalueswithin25%ofbaselineperformanceareunderlined,showcasingtheeffectivelength.
Forallmodels,weobservethattheclaimedcontextsizediffersfromtheeffectivecontextsize.
Figure3:Effectofchangingthelanguageofanswerdocument(needle).
3 ExperimentalResults endoftheinputcontexttounderstandhowitspositioninflu-
ences the model’s ability to accurately retrieve the correct
Werunexperimentswithcontextsizesrangingfrom4Kto
information.AsshowninFigure4,themodelperformsbest
32Ktokenstocomparetheperformanceofvariousmodelson
whentheneedleisplacedatthebeginningorendoftheinput
MLNeedle3.Table1summariseseachmodel’sperformance,
context.ThesefindingsextendLiuetal.(2023)tomultilin-
averagedacrossthesevenlanguagesinMLNeedle.Asthe
gualsettings.Thepreferenceforstartingandendingpositions
contextsizeincreases,allmodelsshowasignificantdropin
toretrieverelevantinformationindicatesapotentialweak-
performance.Toevaluatethemaximumcontextsizethateach
ness in the model’s ability to maintain effective attention
modelcanhandleeffectively,wedefinetheeffectivelength
throughouttheinputsequence(Hsiehetal.2024b),andex-
asthemaximumcontextlengthatwhichthemodel’sperfor-
ploringthisinthemultilingualsettingisanimportantfuture
mancedoesnotdecreasebymorethan25%fromitsbaseline
work.
accuracy4.Ourfindingsshowthatallmodelsstrugglewith
longercontexts,exhibitingsignificantdropsinaccuracybe-
3.2 EffectofChangingtheNeedleLanguage
yondtheireffectivelengths.Figure1showsthemonolingual
(both needle and distractors in the same language) perfor- Inthisexperiment,weinvestigatehowchangingthelanguage
mance of different models on the MLNeedle test. Models ofthedocumentcontainingthecorrectanswer(N)affects
consistentlyperformbetterinEnglishthannon-Englishlan- theretrievalperformanceofselectedmodels.Toisolatethe
guages. In the following sections, we will investigate the effectsofneedlelanguage,wekeepthedistractorpassages
effectofmodulatingthepositionandlanguageoftheneedle. (H)inEnglish.Theresults,illustratedinFigure3,showthat
LLMsperformbestwhenN iseitherinEnglishorinalan-
3.1 EffectofChangingtheNeedlePosition guagethatisclosetoEnglish.However,aswemoveaway
fromtheLatinlanguagesfamily,wenoticeasignificantdrop
Inthisexperiment,weevaluatehowthepositionoftheneedle
inperformance.Thedecreaseinperformanceismostnotice-
(N) within the input context affects retrieval performance.
ablewhenN ispresentedinlanguagessignificantlydifferent
Wesystematicallyplacetheneedleatthestart,middle,and
from English, such as Chinese and Arabic. When the lan-
guageofN ischangedfromEnglishtoGermanorSpanish,
3Allgenerationexperimentswereconductedusingfixedsam-
bothofwhichareclosetoEnglish,theperformancedropis
pling parameters to control the randomness and diversity of the
moderate. This suggests that the model is relatively effec-
generatedresponses.Specifically,wesetthetemperatureto0.7and
tiveinprocessingcontentinlanguagesthatsharesimilarities
used top-k sampling with k = 50. These parameters were kept
constantacrossallselectedmodelstoensureafaircomparisonof withEnglish.Ontheotherhand,thedropinperformanceis
theirperformanceontheMLNeedletest. morepronouncedwhenwechangethelanguageofN from
4Baselineaccuracyreferstothemodel’sperformancewhenthere Englishtonon-LatinlanguagessuchasChineseandArabic.
arenodistractorsintheinputcontext(seeFigure2(a)). Thesubstantialdropinperformanceindicatesthatthemodelsstruggletoeffectivelyprocessandretrievethesamecontent N en de es zh vi hi ar
H
whenpresentedintheselinguisticallydistantlanguages.
Mistral-7B-Instruct-v0.2
Our findings suggest that although the content of N re- en 0.68 0.37 0.35 0.30 0.31 0.25 0.24
mainsunchanged,LLMsdisplayconsiderablevariabilityin de 0.71 0.37 0.38 0.24 0.34 0.24 0.25
theirabilitytoretrievethecorrectinformationdependingon es 0.70 0.40 0.39 0.31 0.34 0.26 0.28
thelanguageofN.Thisinconsistencyunderscoresacritical zh 0.73 0.43 0.39 0.31 0.35 0.28 0.27
vi 0.75 0.47 0.42 0.33 0.37 0.30 0.27
limitationofcurrentLLMs:Theretrievalcapabilityisheavily
hi 0.80 0.47 0.44 0.36 0.38 0.32 0.33
influencedbythelanguageinwhichthecontentispresented. ar 0.76 0.49 0.43 0.31 0.40 0.33 0.30
Themodelsperformsbetterforhigh-resourcelanguageslike Llama3-8B-Instruct
English,buttheirperformancediminishesinlower-resource en 0.61 0.21 0.24 0.21 0.23 0.23 0.22
de 0.64 0.25 0.25 0.15 0.20 0.22 0.19
languagessuchasHindi.
es 0.66 0.28 0.28 0.19 0.25 0.24 0.24
zh 0.61 0.22 0.23 0.19 0.19 0.20 0.18
3.3 EffectofChangingtheHaystackLanguage vi 0.65 0.29 0.28 0.18 0.30 0.24 0.20
hi 0.70 0.32 0.32 0.26 0.27 0.29 0.26
Here, we investigate how varying the language of the dis- ar 0.65 0.27 0.29 0.22 0.25 0.25 0.25
tractordocuments,H,impactstheretrievalperformanceof Cohere-Aya-23-8B
LLMs.Wekeepthelanguageoftheneedleconstant,asEn- en 0.70 0.51 0.47 0.36 0.39 0.33 0.30
glish, and then systematically change the language of the de 0.71 0.53 0.46 0.36 0.41 0.33 0.33
es 0.68 0.48 0.62 0.35 0.43 0.35 0.32
haystack. Table 2 shows that changing the haystack lan-
zh 0.72 0.47 0.44 0.57 0.39 0.38 0.37
guagefromEnglishtoArabicdoesnotsignificantlyaffect vi 0.73 0.46 0.46 0.31 0.49 0.36 0.36
the model’s performance. This observation suggests that hi 0.61 0.42 0.44 0.34 0.39 0.35 0.31
LLMs are relatively robust to changes in the language of ar 0.66 0.45 0.44 0.35 0.41 0.37 0.50
non-relevantinformation,indicatingthatthemodelcanfocus
Table 2: Pairwise accuracy results of selected models (av-
onandretrievetherelevantcontentwithoutbeingeasilycon-
eraged across the context lengths) on the MLNeedle test.
fusedbythelanguageofdistractorpassages.Incontrastto
Languageofrelevantinformationanddistractordocuments
thesignificantdeclineinperformanceobservedwhenchang-
is abbreviated as N and H, respectively. We observe that
ing the language of the needle, the models’ performance
performance is heavily influenced by the language of rel-
appearscomparativelymorestablewhenonlythelanguage
evant information (N), whereas the language of distractor
ofthedistractordocumentsisaltered.Thissuggeststhatthe
documents(H)playsalimitedrole.
retrievaltask’sdifficultyismoresensitivetothelanguageof
theneedlethantothelanguageofthehaystack.LLMsfocus
onthecontentoftheneedle,ratherthanbeingdistractedby
EffectoftheTaskFormat.Thetaskofmultilingualques-
thelanguageofthehaystack,highlightingitsabilitytopri-
tionansweringthroughfactretrievalfromalongcontextcan
oritizerelevantinformationeffectivelyinthiscross-lingual
be considered a challenging task for the choice of models
setting.
understudy.Toprovethereliabilityofourresultsasbeinga
propertyoflong-contextmultilingualLMs,wealsoevaluate
4 AblationStudies
themodelsonasimplersecondarytask—identifyingthe
Effect of Temperature Sampling. Here, we investigate presenceofrelevantinformationwithintheinputcontext.To
whether the choice of generation strategy significantly in- thisend,wedefinedtheexistenceaccuracymetricinSec-
fluencesthemodel’sperformance.Table4comparestheper- tion2.4,whichmeasurestheproportionofsampleswherethe
formance of Mistral-7B-Instruct-v0.2 under two different modelcorrectlyidentifieswhethertherelevantinformation
generationstrategies:samplingwithfixedparameters(tem- ispresentintheprovidedpassages.
perature=0.7,top-k=50)andgreedydecoding.Weobserve
Figure 6 shows the results for Mistral-7B-Instruct-v0.2
thatbothstrategiesyieldcomparableresultswithminimalde-
across four different context lengths. We observe similar
viationacrossdifferentcontextsizes.Furthermore,asshown
results for both Exact Accuracy and Existence Accuracy,
inFigure8,theoverallaccuracytendstoremainconsistent
showcasing that our findings are not solely because of the
regardlessofthegenerationmethodemployed.
natureofthetask.Wealsoobservesimilarresultswhenwe
EffectofInstructionFine-tuning.Tounderstandtheim-
varythelanguageofdistractorpassagesintheinputcontext.
pactofinstructionfine-tuningonLLMs’useofmultilingual
MoredetailscanbefoundinAppendixE.
longcontexts,wecomparetheMLNeedletestperformanceof
Mistral-7B-Instruct-v0.2withitsbasevariant(pre-instruction StatisticalSignificance:Figure5presentstheresultsof
tuning)usingthesameexperimentalsetupasinSection2. significancetestingforselectedmodels,computedoverlin-
Table3showsthatMistral-7B-Instruct-v0.2consistentlyout- early increasing sample sizes from 100 to 16,800. We ob-
performs Mistral-7B-v0.1 across different context lengths. servethataccuracystabilizesafterapproximately2,500sam-
Instruction-tuningalsoreducesworst-caseperformancedis- ples.Furthermore,asignificantreductioninstandarderror
parity from nearly 70% to 30%. These findings align with isobservedasthesamplesizeincreasesfrom100to2,500.
priorworkshowingthatinstruction-tuningenhancescross- Theseresultsunderscorethatasamplesizeof2,500issuffi-
lingualknowledgealignmentandimprovesinformationre- cienttoachievereliableandconsistentevaluationoutcomes.
trievalacrosslanguages(Shahametal.2024;Gaoetal.2024). FurtherdetailsareprovidedinAppendixE.Figure4:Effectofchangingpositionofanswerdocument(needle).
Model Baseline 4K 8K 16K 32K Avg.
Mistral-Base 0.383 0.142 0.100 0.097 0.102 0.165
Mistral-Instruct 0.586 0.478 0.453 0.436 0.398 0.470
∆ model†−model∗ ↑0.203 ↑0.336 ↑0.353 ↑0.339 ↑0.296 ↑0.305
Table3:Effectofinstructionfine-tuning.
Model Baseline 4K 8K 16K 32K Avg.
Mistral-Instruct(GD) 0.586 0.478 0.453 0.436 0.398 0.470
Mistral-Instruct(TS) 0.580 0.485 0.455 0.427 0.398 0.469
∆ model†−model∗ ↓0.006 ↑0.007 ↑0.002 ↓0.009 0.000 ↓0.001
Table4:Effectoftemperaturesamplingvsgreedydecoding.
cross-lingual evaluation of QA systems. Despite these ad-
vancements, much of the research in multilingual QA has
focusedonscenarioswherethecontextisrelativelyshortor
Figure5:Exactaccuracyofmodelsonvaryingsamplesizes where the question and context are in the same language
forevaluation.Solidlinesdenotetheaccuracy,andtheshaded (Artetxe, Ruder, and Yogatama 2019; Lewis et al. 2020;
areadenotesthestandarderror. Longpre, Lu, and Daiber 2021). A significant gap persists
betweenmonolingualandmultilingualQAperformance,par-
5 RelatedWork ticularlywhenmodelsencountercross-lingualscenariosor
low-resourcelanguages(Loginova,Varanasi,andNeumann
Multilingual Question Answering and Information Re- 2021;Guoetal.2023).TheMLQA(Lewisetal.2020)and
trieval. Multilingualquestionanswering(QA)andinfor- MKQA(Longpre,Lu,andDaiber2021)datasets,forinstance,
mation retrieval (IR) have become increasingly important provideafoundationforevaluatingcross-lingualextractive
as LLMs are deployed in diverse linguistic environments QA,butdonotaddressthecomplexitiesintroducedbylong
(Shahametal.2024).Historically,QAdatasetsandbench- contexts.Ourworkextendsthislineofinquirybyexamining
markshavebeenmonolingual,primarilyfocusingonEnglish. howLLMsperforminretrievingrelevantinformationfrom
However, efforts such as MLQA (Lewis et al. 2020) and long multilingual contexts, where input context may span
XQuAD (Artetxe, Ruder, and Yogatama 2019) have intro- multipledocuments—anincreasinglycommonscenarioin
duced datasets supporting multiple languages, facilitating real-worldapplications.
muideM
dna
hgiH
ecruoseR
woL
)ed
,se
,ne(
ecruoseR
)ra
,ih
,iv
,hz(ZeroSCROLLS(Shahametal.2023b)LongBench(Baietal.
2024),haveprovidedinsightsintothelimitationsandpoten-
tialofLLMsinprocessingextendedinputsequences.These
benchmarkstypicallyinvolvetaskssuchaslong-document
QA,multi-hopreasoning,andevenmultimodalretrieval(Liu
et al. 2023; Hsieh et al. 2024a; Wang et al. 2024). L-Eval
(Anetal.2023)curatestestsusingrealisticdata,whichisfil-
teredmanuallytoensurequality.Infinite-BenchZhangetal.
(2024)includestaskswithlengthgreaterthan100Ktokens.
However,thesebenchmarksprimarilyfocusonmonolingual
Englishcontexts,leavingasignificantgapinunderstanding
howLLMsperforminmultilingualsettingswithlonginput
sequences.Forexample,theMIRACLdataset(Zhangetal.
2022)introducesamultilingualretrievalchallengebutdoes
notapplyittolong-contextscenarios.
Recent findings by Zhao et al. (2024) reveal that LLMs
processmultilingualcontentinthreestages:first,theycon-
vert input into an English-centric representation, then pro-
Figure6:ExactAccuracyandExistenceAccuracyplotsfor
cess it during task solving, and finally, generate output in
Mistral-7B-Instruct-v0.2acrossfourdifferentcontextlengths
theoriginallanguage.Ourresultsextendthishypothesisby
onvarying(fromlefttoleft):(i)PositionofDocumentwith
suggestingthatmodelsstrugglewithretrievinginformation
theAnswer(Needle)and(ii)LanguageofDocumentwith
whendealingwithnon-Latinlanguages(Figure3).
theAnswer(Needle).
Furthermore,arecentstudy(Hsiehetal.2024b)highlights
theintrinsicpositionalattentionbiasinTransformer-based
Long-context Language Models. The ability of LLMs
architectures (Vaswani et al. 2017), where models dispro-
to effectively handle long input contexts is a critical area
portionately focus on tokens at the beginning and end of
ofresearch,underpinningtaskssuchasdocumentsumma-
asequence.ThisexplainstheU-shapedperformancecurve
rization,long-formtextgeneration,andmulti-hopquestion
observed in Figure 4. We further speculate that since the
answering (Qin, Feng, and Van Durme 2023; Wang et al.
model’sattentionmechanismsarealreadybiasedduetopo-
2024).Transformer-basedmodels(Vaswanietal.2017),tra-
sitionalencodings,theadditionalcomplexityofprocessing
ditionallylimitedbytheirquadraticcomplexityrelativeto
low-resourcelanguageswherethemodelmayalreadyhave
sequence length, have spurred the development of various
weakerrepresentationscouldexacerbatethedifficultyinre-
techniquestoscaleattentionmechanismsandmanagelong
trieving and utilizing middle-positioned information. This
contextsmoreefficiently(Daietal.2019;Daoetal.2022).
mightexplainwhytheperformancedropismorepronounced
Recentinnovationshaveextendedcontextwindowssignifi-
innon-Latinlanguages.Exploringthisfurtherisinteresting
cantly,withmodelsnowcapableofprocessingupto100K
futurework.
tokensinsomecases.Hsiehetal.(2024a)exploredtheprac-
tical usability of long-context LLMs and the effectiveness 6 Conclusion
of different attention mechanisms. Despite the recent im-
In this study, we introduced the MultiLingual Needle in a
provements, the practical utility of LLMs in long-context
Haystack(MLNeedle)test,designedtosystematicallyeval-
scenariosisoftenconstrainedbyissuesrelatedtoattention
uate the long-context capabilities of multilingual LLMs.
decay, memory management, and the ability to accurately
Throughaseriesofcontrolledexperiments,weinvestigated
retrieverelevantinformationfromwithinextendedsequences
howchangesinthelanguageandpositionofrelevantinfor-
(Hsiehetal.2024a;Lietal.2024;Qin,Feng,andVanDurme
mationinalongcontextaffecttheLLMs’retrievalperfor-
2023).Liuetal.(2023)highlightedasignificantchallengein
mance.OurfindingsrevealedthatLLMsexhibitsignificant
thisdomain:amarkeddeclineinLLMperformancewhenrel-
sensitivitytoboththelanguageandpositionoftherelevant
evantinformationissituatedinthemiddleofalongcontext.
information,particularlywhentherelevantcontentisinnon-
Thisstudyrevealeda“U-shaped”performancecurve,where
Latinlanguagesorpositionedinthemiddleofalongcontext.
modelsperformedbestwhenrelevantinformationwasatthe
Conversely,themodelsdemonstratedrelativerobustnessto
beginningorendofthecontext,withperformancedropping
variationsinthelanguageofdistractorpassages,suggesting
significantlyforinformationlocatedcentrally.Thesefindings
that the primary challenges lie in how LLMs process and
underscoreongoingchallengesindesigningLLMsthatcan
retrieve the needle from diverse linguistic contexts. These
robustlyhandlelongcontexts,particularlyinmaintainingat-
findingsunderscoretheneedforfurtherresearchtoenhance
tention(Hsiehetal.2024b)andrelevance(Hsiehetal.2024a)
the multilingual capabilities of LLMs, particularly in han-
acrosstheentiresequence.
dlinglong-contextscenarioswhererelevantinformationmay
Long-context Benchmarks and Tasks. Benchmarking bedispersedacrossdifferentlanguagesandpositionswithin
the ability of LLMs to handle long contexts is crucial for theinput.Ourworkrepresentsafirststeptowardssystemat-
understanding their real-world applicability (Hsieh et al. icallyevaluatingthelong-contextbehaviorofmultilingual
2024a; Wang et al. 2024). Previous benchmarks, such as LLMs.References Hsieh,C.-Y.;Chuang,Y.-S.;Li,C.-L.;Wang,Z.;Le,L.T.;
AI@Meta.2024. Llama3ModelCard. ArXiv. Kumar, A.; Glass, J.; Ratner, A.; Lee, C.-Y.; Krishna, R.;
and Pfister, T. 2024b. Found in the Middle: Calibrating
An,C.;Gong,S.;Zhong,M.;Li,M.;Zhang,J.;Kong,L.;and
PositionalAttentionBiasImprovesLongContextUtilization.
Qiu,X.2023. L-Eval:InstitutingStandardizedEvaluation
arXiv:2406.16008.
forLongContextLanguageModels. ArXiv,abs/2307.11088.
Ivgi,M.;Shaham,U.;andBerant,J.2023. EfficientLong-
Artetxe,M.;Ruder,S.;andYogatama,D.2019. Onthecross-
TextUnderstandingwithShort-TextModels. Transactionsof
lingualtransferabilityofmonolingualrepresentations. CoRR,
theAssociationforComputationalLinguistics,11:284–299.
abs/1910.11856.
Jiang, A. Q.; Sablayrolles, A.; Mensch, A.; Bamford, C.;
Aryabumi,V.;Dang,J.;Talupuru,D.;Dash,S.;Cairuz,D.;
Chaplot,D.S.;deLasCasas,D.;Bressand,F.;Lengyel,G.;
Lin,H.;Venkitesh,B.;Smith,M.;Campos,J.A.;Tan,Y.C.;
Lample, G.; Saulnier, L.; Lavaud, L. R.; Lachaux, M.-A.;
Marchisio,K.;Bartolo,M.;Ruder,S.;Locatelli,A.;Kreutzer,
J.;Frosst,N.;Gomez,A.;Blunsom,P.;Fadaee,M.;U¨stu¨n, Stock,P.;Scao,T.L.;Lavril,T.;Wang,T.;Lacroix,T.;and
Sayed,W.E.2023. Mistral7B. ArXiv,abs/2310.06825.
A.;andHooker,S.2024. Aya23:OpenWeightReleasesto
FurtherMultilingualProgress. arXiv:2405.15032. Kandpal,N.;Deng,H.;Roberts,A.;Wallace,E.;andRaffel,
Bai,Y.;Lv,X.;Zhang,J.;Lyu,H.;Tang,J.;Huang,Z.;Du, C.2023a. LargeLanguageModelsStruggletoLearnLong-
Z.;Liu,X.;Zeng,A.;Hou,L.;Dong,Y.;Tang,J.;andLi,J. TailKnowledge. arXiv:2211.08411.
2024. LongBench:ABilingual,MultitaskBenchmarkfor Kandpal,N.;Deng,H.;Roberts,A.;Wallace,E.;andRaffel,
LongContextUnderstanding. InKu,L.-W.;Martins,A.;and C. 2023b. Large language models struggle to learn long-
Srikumar,V.,eds.,Proceedingsofthe62ndAnnualMeeting tail knowledge. In Proceedings of the 40th International
oftheAssociationforComputationalLinguistics(Volume1: ConferenceonMachineLearning,ICML’23.JMLR.org.
LongPapers),3119–3137.Bangkok,Thailand:Association
Khandelwal,U.;He,H.;Qi,P.;andJurafsky,D.2018. Sharp
forComputationalLinguistics.
Nearby, Fuzzy Far Away: How Neural Language Models
Bonifacio,L.;Jeronymo,V.;Abonizio,H.Q.;Campiotti,I.; Use Context. In Gurevych, I.; and Miyao, Y., eds., Pro-
Fadaee,M.;Lotufo,R.;andNogueira,R.2022. mMARCO: ceedingsofthe56thAnnualMeetingoftheAssociationfor
AMultilingualVersionoftheMSMARCOPassageRanking ComputationalLinguistics(Volume1:LongPapers),284–
Dataset. arXiv:2108.13897. 294.Melbourne,Australia:AssociationforComputational
Dai, Z.; Yang, Z.; Yang, Y.; Carbonell, J.; Le, Q.; and Linguistics.
Salakhutdinov, R. 2019. Transformer-XL: Attentive Lan- Lee,M.;Liang,P.;andYang,Q.2022. CoAuthor:Designing
guageModelsbeyondaFixed-LengthContext. InKorhonen, a Human-AI Collaborative Writing Dataset for Exploring
A.; Traum, D.; and Ma`rquez, L., eds., Proceedings of the LanguageModelCapabilities. InCHIConferenceonHuman
57thAnnualMeetingoftheAssociationforComputational FactorsinComputingSystems,CHI’22.ACM.
Linguistics,2978–2988.Florence,Italy:AssociationforCom-
Lewis,P.;Oguz,B.;Rinott,R.;Riedel,S.;andSchwenk,H.
putationalLinguistics.
2020. MLQA: Evaluating Cross-lingual Extractive Ques-
Dao,T.;Fu,D.Y.;Ermon,S.;Rudra,A.;andRe´,C.2022. tionAnswering. InJurafsky,D.;Chai,J.;Schluter,N.;and
FlashAttention:FastandMemory-EfficientExactAttention Tetreault,J.,eds.,Proceedingsofthe58thAnnualMeetingof
withIO-Awareness. arXiv:2205.14135. theAssociationforComputationalLinguistics,7315–7330.
Dubey,A.;andJauhri,A.2024.TheLlama3HerdofModels. Online:AssociationforComputationalLinguistics.
arXiv:2407.21783.
Li,T.;Zhang,G.;Do,Q.D.;Yue,X.;andChen,W.2024.
Gao,C.;Hu,H.;Hu,P.;Chen,J.;Li,J.;andHuang,S.2024. Long-contextLLMsStrugglewithLongIn-contextLearning.
Multilingual Pretraining and Instruction Tuning Improve arXiv:2404.02060.
Cross-LingualKnowledgeAlignment,ButOnlyShallowly.
Liu,N.F.;Lin,K.;Hewitt,J.;Paranjape,A.;Bevilacqua,M.;
InDuh,K.;Gomez,H.;andBethard,S.,eds.,Proceedingsof
Petroni, F.; and Liang, P. 2023. Lost in the Middle: How
the2024ConferenceoftheNorthAmericanChapterofthe
LanguageModelsUseLongContexts. Transactionsofthe
AssociationforComputationalLinguistics:HumanLanguage
AssociationforComputationalLinguistics,12:157–173.
Technologies(Volume1:LongPapers),6101–6117.Mexico
Loginova,E.;Varanasi,S.;andNeumann,G.2021. Towards
City,Mexico:AssociationforComputationalLinguistics.
End-to-EndMultilingualQuestionAnswering. Information
Guo,Y.;Liang,Y.;Zhao,D.;Liu,B.;andDuan,N.2023.An-
SystemsFrontiers,23(1):227–241.
alyzingandReducingthePerformanceGapinCross-Lingual
Longpre,S.;Lu,Y.;andDaiber,J.2021. MKQA:ALinguis-
Transfer with Fine-tuning Slow and Fast. In Rogers, A.;
ticallyDiverseBenchmarkforMultilingualOpenDomain
Boyd-Graber,J.;andOkazaki,N.,eds.,Proceedingsofthe
QuestionAnswering. arXiv:2007.15207.
61stAnnualMeetingoftheAssociationforComputational
Linguistics(Volume1:LongPapers),4002–4017.Toronto, Mallen,A.;Asai,A.;Zhong,V.;Das,R.;Khashabi,D.;and
Canada:AssociationforComputationalLinguistics. Hajishirzi,H.2023a. WhenNottoTrustLanguageModels:
Hsieh,C.-P.;Sun,S.;Kriman,S.;Acharya,S.;Rekesh,D.;Jia, InvestigatingEffectivenessofParametricandNon-Parametric
F.;Zhang,Y.;andGinsburg,B.2024a. RULER:What’sthe Memories. arXiv:2212.10511.
RealContextSizeofYourLong-ContextLanguageModels? Mallen,A.;Asai,A.;Zhong,V.;Das,R.;Khashabi,D.;and
arXivpreprintarXiv:2404.06654. Hajishirzi,H.2023b. WhenNottoTrustLanguageModels:InvestigatingEffectivenessofParametricandNon-Parametric Vaswani,A.;Shazeer,N.;Parmar,N.;Uszkoreit,J.;Jones,L.;
Memories. InRogers,A.;Boyd-Graber,J.;andOkazaki,N., Gomez,A.N.;Kaiser,L.;andPolosukhin,I.2017. Attention
eds.,Proceedingsofthe61stAnnualMeetingoftheAssocia- IsAllYouNeed. arXiv:1706.03762.
tionforComputationalLinguistics(Volume1:LongPapers), Wang,H.;Shi,H.;Tan,S.;Qin,W.;Wang,W.;Zhang,T.;
9802–9822.Toronto,Canada:AssociationforComputational Nambi,A.;Ganu,T.;andWang,H.2024.MultimodalNeedle
Linguistics. inaHaystack:BenchmarkingLong-ContextCapabilityof
Petroni, F.; Lewis, P.; Piktus, A.; Rockta¨schel, T.; Wu, Y.; MultimodalLargeLanguageModels. arXiv:2406.11230.
Miller, A. H.; and Riedel, S. 2020. How Context Affects Zhang,X.;Chen,Y.;Hu,S.;Xu,Z.;Chen,J.;Hao,M.K.;
LanguageModels’FactualPredictions. arXiv:2005.04611. Han,X.;Thai,Z.L.;Wang,S.;Liu,Z.;andSun,M.2024.
Press,O.;Smith,N.A.;andLewis,M.2022.TrainShort,Test ∞Bench:ExtendingLongContextEvaluationBeyond100K
Long: Attention with Linear Biases Enables Input Length Tokens. arXiv:2402.13718.
Extrapolation. arXiv:2108.12409. Zhang,X.;Thakur,N.;Ogundepo,O.;Kamalloo,E.;Alfonso-
Qin,G.;Feng,Y.;andVanDurme,B.2023.TheNLPTaskEf- Hermelo,D.;Li,X.;Liu,Q.;Rezagholizadeh,M.;andLin,
fectivenessofLong-RangeTransformers.InVlachos,A.;and J.2022. MakingaMIRACL:MultilingualInformationRe-
Augenstein,I.,eds.,Proceedingsofthe17thConferenceof trievalAcrossaContinuumofLanguages.arXiv:2210.09984.
theEuropeanChapteroftheAssociationforComputational Zhao,Y.;Zhang,W.;Chen,G.;Kawaguchi,K.;andBing,L.
Linguistics,3774–3790.Dubrovnik,Croatia:Associationfor 2024. HowdoLargeLanguageModelsHandleMultilingual-
ComputationalLinguistics. ism? arXiv:2402.18815.
Rajpurkar, P.; Zhang, J.; Lopyrev, K.; and Liang, P. 2016.
SQuAD:100,000+QuestionsforMachineComprehension
of Text. In Su, J.; Duh, K.; and Carreras, X., eds., Pro-
ceedingsofthe2016ConferenceonEmpiricalMethodsin
Natural Language Processing, 2383–2392. Austin, Texas:
AssociationforComputationalLinguistics.
Reimers,N.;andGurevych,I.2020. MakingMonolingual
SentenceEmbeddingsMultilingualusingKnowledgeDistil-
lation. InProceedingsofthe2020ConferenceonEmpirical
MethodsinNaturalLanguageProcessing.Associationfor
ComputationalLinguistics.
Shaham,U.;Herzig,J.;Aharoni,R.;Szpektor,I.;Tsarfaty,
R.;andEyal,M.2024. MultilingualInstructionTuningWith
JustaPinchofMultilinguality. arXiv:2401.01854.
Shaham, U.; Ivgi, M.; Efrat, A.; Berant, J.; and Levy, O.
2023a. ZeroSCROLLS:AZero-ShotBenchmarkforLong
TextUnderstanding. arXiv:2305.14196.
Shaham, U.; Ivgi, M.; Efrat, A.; Berant, J.; and Levy, O.
2023b. ZeroSCROLLS:AZero-ShotBenchmarkforLong
TextUnderstanding. InBouamor,H.;Pino,J.;andBali,K.,
eds.,FindingsoftheAssociationforComputationalLinguis-
tics:EMNLP2023,7977–7989.Singapore:Associationfor
ComputationalLinguistics.
Thoppilan, R.; Freitas, D. D.; Hall, J.; Shazeer, N.; Kul-
shreshtha,A.;Cheng,H.-T.;Jin,A.;Bos,T.;Baker,L.;Du,
Y.; Li, Y.; Lee, H.; Zheng, H. S.; Ghafouri, A.; Menegali,
M.;Huang,Y.;Krikun,M.;Lepikhin,D.;Qin,J.;Chen,D.;
Xu,Y.;Chen,Z.;Roberts,A.;Bosma,M.;Zhao,V.;Zhou,
Y.;Chang,C.-C.;Krivokon,I.;Rusch,W.;Pickett,M.;Srini-
vasan,P.;Man,L.;Meier-Hellstern,K.;Morris,M.R.;Doshi,
T.;Santos,R.D.;Duke,T.;Soraker,J.;Zevenbergen,B.;Prab-
hakaran, V.; Diaz, M.; Hutchinson, B.; Olson, K.; Molina,
A.; Hoffman-John, E.; Lee, J.; Aroyo, L.; Rajakumar, R.;
Butryna, A.; Lamm, M.; Kuzmina, V.; Fenton, J.; Cohen,
A.;Bernstein,R.;Kurzweil,R.;Aguera-Arcas,B.;Cui,C.;
Croak, M.; Chi, E.; and Le, Q. 2022. LaMDA: Language
ModelsforDialogApplications. arXiv:2201.08239.
Touvron,H.;andMartin,L.2023.Llama2:OpenFoundation
andFine-TunedChatModels. arXiv:2307.09288.A Processofretrievingthedistractor abilitytoretrieverelevantinformation,regardlessoftheinput
documents language.
We randomly sample 10,000 Wikipedia passages from
E AdditionalResults
mMARCOforeachofthelanguagesunderstudy.Weencode
everyquestioninMLQAandeverypassageinmMARCOin E.1 AblationStudy:EffectofEvaluationMetric
a768dimensionaldenseembeddingspaceusingparaphrase-
InSection4,wediscussedhowweobtainedsimilarplots
multilingual-mpnet-base-v2,trainedon50+languages.Fol-
for‘ExactAccuracy’and‘ExistenceAccuracy’.FromFigure
lowingthat,werank300mostsimilarWikipediapassages
7,weobservethesimilaritybetweenplotsobtainedonchang-
for every language against each question in MLQA using
ing the language of the distractor documents in the input
cosinesimilarityscore.
context.Both‘ExistenceAccuracy’and‘ExactAccuracy’do
notvaryinchangingthelanguageofthedistractordocuments
B PromptTemplates
intheinputcontext.
In our experiments, we adopt a vanilla prompt template
commonlyusedinmulti-documentquestionanswering,fol-
lowing the linear <Instruction> + <Documents>
+ <Query> input sequence. Table 5 and Table 6 high-
light the respective prompt templates used for evaluating
exact accuracy and existence accuracy. Addi-
tionally,Figure2andFigure9provideaexampleofactual
inputpromptforexact accuracyevaluationusingthree
documents.
C ControllingContextLength
Tocontrolthesizeoftheinputcontextwithinprovidedcon-
textsizeproposedbythemodelspecifications,weallowfor
maximalnumberofdistractorpassagestofitwithinthesize
allowance.UsingmMARCOpassagesasdistractorpassages
we observed following number of documents to appear in
the input context for each context size : 4K - ∼10-15 dis-
tractordocuments,8K-∼25-30distractordocuments,32K-
∼50-65distractordocuments.
D AutomatedEvaluationFramework
Thissectionoutlinesthekeystepsinvolvedinourautomated
evaluationprocess.Tobetterunderstandourevaluationsetup,
weprovideanexampleofapositiveandnegativeinstance
fromMLNeedleinFigure10.
Foreachinputprompt,themodelgeneratesaprediction
(y pred), which may be in a different language from the Figure7:ExactAccuracyandExistenceAccuracyplotsfor
ground truth (y true). Each question-answer instance in Mistral-7B-Instruct-v0.2acrossfourdifferentcontextlengths
MLNeedledatasetfromMLQAhasagoldenanswerprovided onthevaryinglanguageofdistractorpassages(Haystack).
inEnglish,regardlessofitslanguage.Toaccuratelycompare
y predwithy true,bothmustbeinthesamelanguage.
However,sincey predcanbegeneratedinanylanguage, E.2 StatisticalSignificance
wetranslateallmodelpredictionsintoEnglishusingGoogle
Toensurethereliablityofourevaluation,weconductahy-
Translate.
pothesistestforexactaccuracyasdefinedinsection2.4.We
AsshowninFigure10,thetranslationstepensuresthatthe
conductthetestforselectedmodelsunderabinomialdistri-
predictionisinthesamelanguageasthegroundtruth,allow-
butionBinomial(1,p),wherepistheprobabilityofsuccess
ingforadirectandreliablecomparison.Oncethepredictions
onanindividualtrial.Thestandarderror(SE)ofthistestis
are translated, we proceed to compute the exact accuracy
computedasfollows:
metricasdefinedinsection2.4.Thiscomparisonhelpsusde-
termineifthemodelhassuccessfullyidentifiedandretrieved (cid:114)
p(1−p)
thecorrectinformationfromtheinputcontext. SE = , (1)
s
BytranslatingallmodeloutputstoEnglishbeforecompar-
ison,weminimizetheriskoffalsenegativesduetolanguage wheresisthenumberoftrials(evaluationsamples).We
differences.Thisprocessensuresthatallcomparisonsarere- varythesamplesizelinearly,startingfrom100samplesand
liableandthattheevaluationaccuratelyreflectsthemodel’s increasingby500samplesateachstep,i.e.,100,600,1100,Figure8:Performanceofmistral-7b-instruct-v0.2usingdif-
ferentdecodingstrategies.Wereportsimilartrendsfortwo
differentcontextlengths:∼8Ktokensand∼32Ktokens.
1600,andsoon,untilreachingthefullsamplesizeofMLNee-
dle(16,800samples).Notethatateachstep,werandomly
selectthesamplesfromtheMLNeedledataset.Figure5high-
lightstheresultsofourstatisticaltests.Weobservethatthe
exactaccuracystabilizesafterapproximately2,500samples,
andthestandarderrordecreasessignificantlyasthesample
sizeincreasesfrom100to16,800.Write a high-quality answer for the given question using only the provided passages (some of which might be irrelevant).
### Passages
[0] Wenn beispielsweise General Electric (GE) im letzten Quartal .., würde die Dividendenrendite 3,5% (0,68 US-Dollar dividiert durch 19,42 US-Dollar) betragen.
[1] जॉन फ्रां  सस "जैक" वेल् श, जू  नयर (जन् म 19 नवम्बर 1935) … रहे. वेल् श की कुल अनुमा  नत संप  त्ति 720  म  लयन डॉलर है।
[2] John Connolly, EdD, Präsident und CEO von Castle Connolly, … hat neben seiner Anstellung keine relevanten finanziellen Beziehungen offengelegt.
Question: John Welch Jr. was CEO of what company beginning in 1981?
Answer:
(needle position: middle)
Write a high-quality answer for the given question using only the provided Write a high-quality answer for the given question using only the provided
passages (some of which might be irrelevant). passages (some of which might be irrelevant).
### Passages ### Passages
[0] जॉन फ्रां  सस "जैक" वेल् श, जू  नयर (जन् म 19 नवम्बर 1935) … रहे. वेल् श की कुल अनुमा  नत [0] Wenn beispielsweise General Electric (GE) im letzten Quartal .., würde die
संप  त्ति 720  म  लयन डॉलर है। Dividendenrendite 3,5% (0,68 US-Dollar dividiert durch 19,42 US-Dollar)
betragen.
[1] Wenn beispielsweise General Electric (GE) im letzten Quartal .., würde die
Dividendenrendite 3,5% (0,68 US-Dollar dividiert durch 19,42 US-Dollar) [2] John Connolly, EdD, Präsident und CEO von Castle Connolly, … hat neben
betragen. seiner Anstellung keine relevanten finanziellen Beziehungen offengelegt.
[2] John Connolly, EdD, Präsident und CEO von Castle Connolly, … hat neben [3] जॉन फ्रां  सस "जैक" वेल् श, जू  नयर (जन् म 19 नवम्बर 1935) … रहे. वेल् श की कुल अनुमा  नत
seiner Anstellung keine relevanten finanziellen Beziehungen offengelegt. संप  त्ति 720  म  लयन डॉलर है।
Question: John Welch Jr. was CEO of what company beginning in 1981? Question: John Welch Jr. was CEO of what company beginning in 1981?
Answer: Answer:
(needle position: start) (needle position: end)
Figure9:Modulatingthepositionofrelevantinformation(‘needle’)withintheinputcontext(‘haystack’)presentedinFigure2.
Write a high-quality answer for the given question using only the
provided passages (some of which might be irrelevant).
### Passages
Prompt Template {input passages}
for Exact Match
Question: {question}
Answer:
Table5:Prompttemplateusedforevaluatingexact accuracy.Themodelisaskedtogenerateananswerbasedsolelyonthe
providedpassages.
Read the following list of passages and indicate whether any of the
passages contain the right answer for the given question. Format your
output strictly as ’Yes’ or ’No’.
### Passages
Prompt Template
{input passages}
for Existence
Match
Question: {question}
Answer [Yes/No]:
Table6:Prompttemplateusedforevaluatingexistence accuracy.Themodelisaskedtodetermineifthecorrectanswer
ispresentwithintheprovidedpassages.Ground-truth Model prediction Translation Exact Accuracy
(y_true) (y_pred) (y_pred_translated)
{ "ﻚﯾﺮﺘﻜﻟا لاﺮﻨﺟ“ “general electric” 1
“जनरल इलेि  क्ट्रिक”,
“General Electric”
}
{ “đông về phía bắc” “east to north” 0
“noroeste”,
“northeast”
}
Figure10:Anexampleofapositiveandanegativeinstancewhilecomputingexactaccuracy.Thetranslationstepenablesa
directcomparisonbetweeny trueandy pred,whichinturnhelpsreducefalse-negatives.