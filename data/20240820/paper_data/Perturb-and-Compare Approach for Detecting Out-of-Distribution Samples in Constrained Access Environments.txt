Perturb-and-Compare Approach for Detecting
Out-of-Distribution Samples in Constrained Access
Environments
HeeyoungLeea,1,HoyoonByunb,1,ChangdaeOhc,JinYeongBaka,
∗
andKyungwooSongb,
∗
aSungkyunkwanUniversity,Suwon,SouthKorea
bYonseiUniversity,Seoul,SouthKorea
cUniversityofWisconsin–Madison,Madison,Wisconsin,UnitedStates
Abstract. Accessing machine learning models through remote informationinsidethemodel,theycanbefurtherenhancedgivenac-
APIshasbeengainingprevalencefollowingtherecenttrendofscal- cesstothemodel’sinternalactivations,[28]oritsparameters[12].
ing up model parameters for increased performance. Even though However,theaccesstothemodel’sinternalstatesisnotalwaysper-
thesemodelsexhibitremarkableability,detectingout-of-distribution mitted.Withtheadventoffoundationmodels[25,24],usersoften
(OOD) samples remains a crucial safety concern for end users as findthemselvesinteractingwiththemodelthroughremoteAPIs[26].
thesesamplesmayinduceunreliableoutputsfromthemodel.Inthis Thislimitstheutilizationofrichinformationinsidethemodel[13],
work,weproposeanOODdetectionframework,MixDiff,thatisap- aswellasthemodificationpossibilities[27]thatcanbeeffectively
plicableevenwhenthemodel’sparametersoritsactivationsarenot usedtodetectOODsamples.Inthiswork,weexplorewaystobypass
accessibletotheenduser.Tobypasstheaccessrestriction,MixDiff thisaccessrestrictionthroughtheonlyavailablemodificationpoint,
appliesanidenticalinput-levelperturbationtoagiventargetsample namely,themodels’inputs.
and a similar in-distribution (ID) sample, then compares the rela- Data samples in the real world may contain distracting features
tivedifferenceinthemodeloutputsofthesetwosamples.MixDiffis thatcannegativelyaffectthemodel’sperformance.Sometimesthese
model-agnosticandcompatiblewithexistingoutput-basedOODde- distractorsmaypossesscharacteristicsresemblingaclassthatisdif-
tectionmethods.WeprovidetheoreticalanalysistoillustrateMixD- ferent from the sample’s true label. In this case, the model’s pre-
iff’seffectivenessindiscerningOODsamplesthatinduceoverconfi- dictions for an ID sample could become uncertain as it struggles
dentoutputsfromthemodelandempiricallydemonstratethatMixD- to decide which class the sample belongs to. Similarly, the model
iffconsistentlyenhancestheOODdetectionperformanceonvarious couldputtoomuchemphasisonafeaturethatresemblesacertainin-
datasetsinvisionandtextdomains. distributioncharacteristicfromanOODsample,outputtinganover-
confidentprediction,eventhoughthesampledoesnotbelongtoany
oftheclassesthatthemodelwastaskedtoclassify.
1 Introduction Westartfromtheintuitionthatthecontributingfeaturesinamis-
classifiedsample,eithermisclassifiedasIDorOOD,willtendtobe
Recent developments in deep neural networks (DNNs) opened the more sensitive to perturbations. In other words, these features that
floodgates for a wide adaptation of machine learning methods in themodelhasoveremphasizedwillbemorebrittlewhencompared
variousdomainssuchascomputervision,naturallanguageprocess- totheactualcharacteristicsoftheclassthatthesefeaturesresemble.
ingandspeechrecognition.Asthesemodelsgarnermoreusersand TakeasanexampletheimagethatisatthetopleftcornerofFigure
widentheirapplicationarea,themagnitudeofimpactthattheymay 1a.Thissampleispredictedtobeabuswithahighconfidencescore,
bring about when encountered with a failure mode is also ampli- despiteitbelongingtoanOODclasstrain.Whenweexactapertur-
fied. One of the causes of these failure modes is when an out-of- bationtothissamplebymixingitwithsomeotherauxiliarysample,
distribution(OOD)sampleisfed tothemodel.Thesesamplesare thecontributionoftheregionsthatledtothemodel’sinitialpredic-
problematicbecauseDNNsoftenproduceunreliableoutputsifthere tionissignificantlyreducedascanbeseenbythechangeintheclass
is a large deviation from the in-distribution (ID) samples that the activationmaps(CAM)[4].However,whenthesameperturbationis
modelhasbeenvalidatedtoperformwell. appliedtoanactualimageofabus,thechangeissignificantlyless
OODdetectionisthetaskofdeterminingwhetheraninputsample abrupt.Themodel’spredictionscoresshowasimilarbehavior.
isfromIDorOOD.Thisworkfocusesonsemanticshift[35]where To experimentally verify the intuition, we collect OOD samples
distributionshiftismanifestedbysamplesofunseenclasslabelsat that induce high confidence scores from the model and compute
testtime.Severalstudiesexploremeasuringhowuncertainamodel CAMsforthesesamplesbeforeandafterperturbation.Twoversions
isaboutatargetsamplerelyingonthemodel’soutput[10,19].While ofCAMsarecomputedwithazero-shotimageclassifierusingCLIP
thesemethodsaredesirableinthattheydonotassumeaccesstothe model[25].Onewithrespecttothepredictedclassofthesampleand
theotherwithrespecttothegroundtruthclassofthesample.Figure
1Equalcontribution. 1bshowsthattheL 1distancebetweentheCAMsoftheunperturbed
∗CorrespondingAuthors:jy.bak@skku.edu,kyungwoo.song@yonsei.ac.kr.
4202
guA
91
]GL.sc[
1v70101.8042:viXra(a) (b)
Figure1:(a)ClassactivationmapofanOODsample(train)forthepredictedclass(bus)exhibitsahighdegreeofsensitivitywhenanauxiliary
image(camel)ismixedtoit.Thesameclassactivationmapofanimageofanactualbusismorerobusttothesameperturbation.(Top2
classesareshown).(b)AverageL 1distanceoftheclassactivationmapsofhighconfidenceclassandthegroundtruthclassafterperturbation
(averagedovereachOODclass).
andperturbedversionsofanOODsample’spredictedclasstendsto mumvalueofthelogits.Energyscore[18]takesLogSumExpover
behigherwhencomparedtoitsgroundtruthclass,eventhoughthe thelogitsfortheOODscore.MCM[21]emphasizestheimportance
OODsamplehadahighconfidencescoreforthatclass.Weprovide oftemperaturescalinginvision-languagemodels[25].Whilethese
experimentaldetailsinAppendixE. output-based methods are desirable in that they take a relaxed as-
Motivatedbytheaboveidea,weproposeanOODdetectionframe- sumptiononmodelaccessibility,theysufferfromthemodel’sover-
work, MixDiff, that exploits this perturb-and-compare approach confidenceissue[22].Thismotivatesustoinvestigatetheperturb-
withoutanyadditionaltraining.MixDiffemploysawidelyuseddata and-compareapproachasacalibrationmeasure.
augmentationmethodMixup[38]astheperturbationmethodsoasto
promotediverseinteractionoffeaturesinthesamples.Itsoverallpro-
cedureisoutlinedasfollows:(1)perturbthetargetsamplebyapply- Enhancingoutput-basedOODscores Anotherlineofworkfo-
ingMixupwithanauxiliarysampleandgetthemodel’sprediction cusesonenhancingtheaforementionedoutput-basedOODscoresto
byfeedingtheperturbedtargetsampletothemodel;(2)perturban make them more discriminative. ODIN [17] utilizes Softmax tem-
IDsampleofthepredictedclassofthetarget(oraclesampleinFig- peraturescalingandgradient-basedinputpreprocessingtoenhance
ure1a)byfollowingthesameprocedure;(3)comparetheuncertainty MSP [10]. ReAct [28] alleviates the overconfidence issue by clip-
scoresoftheperturbedsamples.Bycomparinghowthemodel’sout- ping the model’s activations if they are over a certain threshold.
putsofthetargetsampleandasimilarIDsamplebehaveunderthe BAT[42]usesbatchnormalization[14]statisticsforactivationclip-
sameperturbation,MixDiffaugmentsthelimitedinformationcon- ping.DICE[27]leveragesweightsparsificationtomitigatetheover-
tainedinthemodel’spredictionscores.ThisgivesMixDifftheability parameterization issue. Recently, methods that are based on acti-
tobetterdiscriminateOODandIDsamples,evenwhenthemodel’s vation [6] or weight pruning [1] approaches also have been pro-
predictionscoresfortheoriginalsamplesarealmostidentical. posed.Theseapproacheseffectivelymitigatetheoverconfidenceis-
Wesummarizeourkeycontributionsandfindingsasfollows:(1) sue. However, all of these methods require access to either gradi-
WeproposeanOODdetectionframework,MixDiff,thatenhances ents,activationsorparameters;hencelimitstheirapplicabilityinre-
existingOODscoresinconstrainedaccessenvironmentswhereonly moteAPIenvironments.OurworkstandsoutasanOODscoreen-
themodels’inputsandoutputsareaccessible.(2)Weprovideathe- hancementmethodinconstrainedaccessenvironments,wheremod-
oreticalinsightastohowMixDiffcanmitigatetheoverconfidence els’gradients,activations,andparametersarenotaccessible,leaving
issueofexistingoutput-basedOODscoringfunctions.(3)MixDiff themodelinputsastheonlyavailablemodificationpoint.
consistentlyimprovesvariousoutput-basedOODscoringfunctions
whenevaluatedonOODdetectionbenchmarkdatasetsinconstrained
accessscenarioswhereexistingmethods’applicabilityislimited. UtilizationofdeeperaccessformorediscriminativeOODscores
Severalstudiesexploittherichinformationthatthefeaturespacepro-
videswhendesigningOODscores.Olberetal.[23],Zhangetal.[39]
2 Relatedwork
utilizeIDsamples’activationsforcomparisonwithatargetsample.
Output-based OOD scoring functions Various works propose Models’innerrepresentationsareemployedinmethodsthatrelyon
OODscoringfunctionsmeasuringaclassifier’suncertaintyfromits class-conditionalMahalanobisdistance[16].ViM[33]proposesan
predictionscores.Someofthesemethodsrelysolelyonthemodel’s OODscorethatcomplementstheenergyscore[18]withadditional
prediction probability. Maximum softmax probability (MSP) [10] informationfromthefeaturespace.Sunetal.[29]usethetargetsam-
utilizesthemaximumvalueofthepredictiondistribution.Thulasi- ple’sfeaturelevelKNNdistancetoIDsamples.GradNorm[13]em-
dasanetal.[31]useShannonentropyasameasureofuncertainty, ploysthegradientofthepredictionprobabilities’KLdivergenceto
whileGEN[19]proposesageneralizedversionoftheentropyscore. theuniformdistribution.ZhangandXiang[41]showthatdecoupling
KL Matching [11] finds the minimum KL divergence between the MLS[11]canleadtoincreaseddetectionperformanceifgivenaccess
targetandIDsamples.D2U[36]measuresthedeviationofoutput tothemodelparameters.However,thesemethodsarenotapplicable
distributionfromtheuniformdistribution.Ifwetakeastepdownto toblack-boxAPImodelswhereonecanonlyaccessthemodel’stwo
thelogitspace,maximumlogitscore(MLS)[11]utilizesthemaxi- endpoints,namely,theinputsandoutputs.Figure2:TheoverallfigureofMixDiffwiththenumberofMixupratios,R = 1,thenumberofclasses,K = 6,thenumberofauxiliary
samples,N =3,andthenumberoforacleinstances,M =2.WeomitMixupratiosubscriptrforsimplicity.
3 Methodology Comparisonofperturbedsamples’outputs Fromtheperturbed
In this section, we describe the working mechanism of MixDiff
target’sandoracles’uncertaintyscores,(s∗ir,s ir),wecalculatethe
MixDiffscoreforthetargetsample,x t,asshowninEquation4.It
framework.MixDiffiscomprisedofthefollowingthreeprocedures:
measuresthemodel’suncertaintyscoreofthetargetsamplerelative
(1)findIDsamplesthataresimilartothetargetsampleandperturb
tosimilarIDsampleswhenbothundergothesameMixupoperation
these samples by performing Mixup with an auxiliary sample; (2)
withanauxiliarysamplex i,thentakestheaverageofthedifferences
perturbthetargetsamplebyperformingMixupwiththesameaux-
overtheauxiliarysamplesandtheMixupratios.Weprovidedescrip-
iliarysample;(3)measurethemodel’suncertaintyoftheperturbed
tionsandillustrationsoftheoverallprocedureinAlgorithm1and
targetsamplerelativetotheperturbedIDsamples.Wenowprovide
Figure2.
adetaileddescriptionofeachprocedure.
Oracle-sideperturbation Wefeedthegiventargetsample,x t,toa
classificationmodelf()andgetitspredictionscoresforKclasses, 1 R N
O
t,andthepredictedcl·
asslabel,y t,asshowninEquation1.
MixDiff=
RN
(s ir−s∗ir) (4)
Xr=1Xi=1
O t=f(x t)
∈RK,b
y t=argmax(O t) (1)
byW ade dc inal gib thra ete Mt ih xe Db ia ffse scO oO reD ws itc hor ae sf co ar lit nh ge hta yr pg ee rt ps aa rm amp ele te, rh γ(f to(x it t) s) o,
Next, we assume a small set o bf M labeled samples, Ω k = astomitigatethemodel’sover-orunderconfidenceissue.
{(x∗m,y k∗) }M m=1, for each class label k. We refer to these samples Practicalimplementation Theoracle-sideprocedurecanbepre-
astheoraclesamples.Fromthese,wetakethesamplesthatareof computedsinceitdoesnotdependonthetargetsample.Thetarget-
thesamelabelasthepredictedlabely t.Then,weperturbeachor- side computations can be effectively parallelized since each per-
acle sample, x∗m, by performing Mixup with an auxiliary sample, turbed target sample can be processed by the model, independent
x i∈{x i}N i=1,withMixuprateλ r. b oftheothers.Weorganizetheperturbedtargetsamplesinasingle
batchinourimplementation(seeAppendixFfordetailsonpracti-
x∗mir =λ rx∗m+(1 −λ r)x i, wherey k∗=y t (2) calimplementation).FurtherspeedupcanbegainedinremoteAPI
We feed the perturbed oracle sample to the classification model environmentsasAPIcallsareoftenhandledbymultiplenodes.
f( ·)andgetthemodel’spredictionscores,O m∗ir =f(xb ∗mir) ∈RK.
Then,weaveragetheperturbedoraclesamples’modeloutputs,toget 3.1 Theoreticalanalysis
O¯ i∗r = M1 M m=1O m∗ir.Finally,wecomputetheperturbedoracle
s sa cm orp inle gs f’ uO ncO P tiD onsc ho (r ·e ), ss u∗i cr h∈ asR M, Sw Pit oh ra Mn Lar Sb ,i it .r ea .r ,y s∗io rut =pu ht-b Oa ¯s i∗e rdO ∈O RD
.
T imo pb re ot vte er mu en nd te sr ,s wta end prh eo sew ntan ad thw eh oe ren tio cu ar lm ane ath lyo sd ise on fsu Mre is xDpe ir ff fo .r Wm ean uc see
Target-sideperturbation Weperturbthetargetsample(cid:0)x tw(cid:1)iththe asimilartheoreticalapproachtoZhangetal.[40],buttowardsadis-
s ca om me pua tu ex ti hli ear Oy Osa Dm sp cl oe rs e{ sx oi f} tN i h= e1 p, ea rs tux ri br ed= taλ rgr ex tt s+ am( p1 le− aλ sr fo)x lli o, wa sn :d t si in tic ot ndi 1re rc et vio en alf sor tha ena dl ey cz oin mg pa osp io tis ot nho oc fO thO eD Os Oco Drin scg of ru en fc uti no cn ti. oP nro ip no to-
twocomponents:theOODscoreoftheunmixedcleantargetsample
O ir =f(x ir) ∈RK, s ir =h(O ir) ∈R (3) andthesupplementarysignalsintroducedbyMixup.(a) (b) (c) (d)
Figure3:(a)ApproximationerrorforEquation5onsyntheticdata.Withouthigher-orderterms,wecanreasonablyapproximatetheOODscore
ofmixedsamplewithdecomposedterms.(b)Thesyntacticdatadistribution.DataissampledfromfourindependentGaussiandistributions,
withtwoconsideredasIDsamplesforeachclassandtheothertwoasOODsamples.Wetrainalogisticregressionmodelwiththisdataset.(c)
Thepredictionresultsofthetrainedmodel.(d)AlthoughthetargetsampleisahardOODsample,thereareauxiliarysamples(bluedot)that
guaranteethatMixDiffispositiveundersomereasonableconditionsintroducedinTheorem1.
Algorithm1ComputationofMixDiffScore rivedfromthefirstandsecondderivativesoff() and h()andthe
· ·
differencebetweenthetargetandauxiliarysamples.
o {R f Ωeq M ku }ii K kxr =ue 1p: wt ra a hr tg eee rs et { Ωs λa km r} =p R rl =e {1 (x , xt s ∗m, e ,tse yot k∗f )o }of M mraa =cu l 1x e ,il ci sa la ar m sy sp is fila e em s rp f mole ors da e{ l llx fKi (} ·N i )= c ,l1 Oa, s Oss e De st t th ioeW nn ee c voa emr ng pu wae hrit enh ngat tt hhp eee tr m atu ro grb d ei ten l ig no dub uto p ct euh stst ah oe rf et lta ahr teg ive t et w lya on hcd ia go n hr ha cc e ol l ne p fis O da eOm nDp cl ee ds se cta oen c rd e-
scoringfunctionh()
· fromthemodel,inwhichcaseexistingoutput-basedOODscoring
1: O t=f(x t) functionswouldresultindetectionfailure.ThroughTheorem1,we
2: y t=argmax(O t) showtheeffectivenessofMixDiffbydemonstratingtheexistenceof
3: {(x∗m,y k∗) }M m=1←Ω k,where y k∗=y t anauxiliarysamplewithwhichMixDiffcancalibratetheovercon-
4: fbori ∈{1,...,N }do fidenceofahighconfidenceOODsampleonasimplelinearmodel
5: forr ∈{1,...,R }do b setup.
6: form 1,...,M do
∈{ }
7: O m∗ir ←f(λ rx∗m+(1 −λ r)x i) Theorem 1. Let h(x) represent MSP and f(x) represent a linear
8: endfor model, described by wTx+b, where w,x Rd and b R. We
9: s∗ir ←h M1 M m=1O m∗ir considerthetargetsample,x t,tobeahard∈ OODsample∈ ,defined
1 1 10 1 2: :
:
endO s iri fr
o←
r← hf ((cid:16)( Oλ ir rx )Pt+(1 −λ r)(cid:17)x i) a c sals e ma s pa ls m ea .m p Flp e ol , re x bt mh ina , at b ru yis t cwp lar ie t shd sii a fict che ad i tg iohto ner ,b xce o to n if fi sdt ah ene hc as ea rdsm ce Oor Oc el Da thss a sana ms th pt e lh ee o wro a hr c ea l ne-
13: endfor 0<f(x m)<f(x t)orf(x t)<f(x m)<0.Thereexistsanauxil-
14: MixDiff
←
R1
N
R
r=1
N i=1(s ir−s∗ir) iarysamplex isuchthat
P P 3
Proposition 1 (OOD scores for mixed samples). Let pre-trained h(f(x )) h(f(x ))+ (ω(x ,x) ω(x ,x))>0.
modelf()andbaseOODscorefunctionh()betwice-differentiable t − m l t i − l m i
functions·
,andx iλ=λx t+(1 −λ)x
ibea·
mixedsamplewithratio
Xl=1
λ
∈
(0,1).ThenOODscorefunctionofmixedsample,h(f(x iλ)), Theorem 1 provides a theoretical ground for our approach’s ef-
iswrittenas: fectivenessindiscerningOODsamplesthatmaynotbedetectedby
existingoutput-basedOODscores.Figures3bto3dillustrateexam-
3
h(f(x iλ))=h(f(x t))+ ω l(x t,x i)+φ t(λ)(λ −1)2, (5) p ol fe Ps ro of ps ou sc ith ioa nux 1il aia nr dy Tsa hm eop rl ee msu 1sin ag resy innt Ahe pt pic end da it xa. BPr ao no dfa Cn ,d rd ee spta ei cls
-
Xl=1
tively.WealsoshowthatTheorem1holdsforMLSandEntropyin
wherelim λ 1φ t(λ)=0, AppendixC.Whilewetakealinearmodelastheclassifierforsim-
→
ω1(xt,xi)=(λ −1)(xt−xi)Tf′(xt)h′(f(xt)) p mli oc dit ey lso ’f ea mn ba ely ds di is n, gth se brp ir ne gv sal oe un rce ano af lyli sn ie sa cr lop sr eo rbi tn og refr ao l-m wofo rlu dnd sea tt uio pn
s
(λ 1)2
ω2(xt,xi)= −
2
(xt−xi)Tf′′(xt)(xt−xi)h′(f(xt)) (seeSection4.5forexperimentalvalidation).
(λ 1)2
ω3(xt,xi)= −
2
(xt−xi)Tf′(xt)(xt−xi)Tf′(xt)h′′(f(xt)).
4 Experiments
We analyze MixDiff using the quadratic approximation of 4.1 Experimentalsetup
h(f(x iλ)), omitting the higher order terms denoted as φ t(λ) in
Weelaborateontheimplementationdetailsandpresentthedescrip-
Equation 5. In Figure 3a, we experimentally verify that the sum
tionsonbaselines.Otherdetailsondatasetsandevaluationmetrics
of the OOD score of the pure sample and ω terms, denoted as
ω(x t,x i) = 3 l=1ω l(x t,x i), reasonably approximates the OOD areprovidedinAppendixG.SeeAppendixOforcode.
score of the mixed sample in Equation 5. ω(x t,x i) represents the Implementation details Following a recent OOD detection ap-
P
impact caused by Mixup as can be seen from its increase when λ proach[7,21,34]thatutilizesvision-languagefoundationmodels’
decreases.Hence,theadditionalsignalfromtheMixupcanbede- zero-shotclassificationcapability,weemployCLIPViT-B/32model[25]asourclassificationmodelwithoutanyfinetuningonIDsam- 7 81.5 MixDiff
ples.WeconstructtheoraclesetbyrandomlysamplingM samples
MSP 6 perclassfromthetrainsplitofeachdataset.Foragiventargetsam- 81
ple,wesimplyusetheothersamplesinthesamebatchastheaux- 80.5 4
iliaryset.Insteadofsearchinghyperparametersforeachdataset,we 80 2.6 3.1
2.1
performonehyperparametersearchonCaltech101[8]andusethe 79.5 2
s wa im the ahy mp oe rr epa rr ea am lie stt ie crs Oa Ocr Doss dea tl el ct th ioe not sh ee ttr ind gata [1se 7t ]s ., Ww ehi pch roi vs idin el fi un le l 7 R5 3 112 5 8 11 14 7.1·1 -90 9− ·91 10−3 -3 9·810−3 1 -. 94 7·10−1 -5 9· 610−2 6 -. 96 4·10−02
descriptionoftheimplementationdetailsinAppendixG. N Avg.MSPValueinInterval
(a) (b)
Baselines WetakeMSP[10],MLS[11],energyscore[18],Shan-
nonentropy[31]andMCM[21]asoutput-basedtraining-freebase- Figure4:AdditionalanalysesonCIFAR100.(a)AUROCscoresof
lines.Wealsoincludemethodsthatrequireextratrainingforcompar- MixDiff+Entropy with varying values of N and R (top). AUROC
ison.ZOC[7]isazero-shotOODdetectionmethodbasedonCLIP scoreofEntropy(bottom).Wealsoprovideprocessingtimeanaly-
[25]thatrequirestrainingaseparatecandidateOODclassnamegen- sis in Appendix K. (b) Difference of the OOD, ID samples’ aver-
erator.CAC[20]reliesontrain-timelossfunctionmodificationand ageuncertaintyscoresbelongingtoagivenintervalofMSPscore.
showsthebestperformanceamongthetrain-timemodificationmeth- None-overlappingfiveconsecutiveintervalswhosevaluesliebelow
odscompatiblewithCLIP[7].WetakeCACtrainedwiththesame thethresholdsetbyFPR95areconstructed.MixDiffscorescandis-
CLIPViT-B/32backboneasabaseline(CLIP+CAC). criminateOOD,IDsamplesevenwhenitsbasescorevaluesareal-
mostidentical.
4.2 Logitsasmodeloutputs Ablations WepresenttheablationresultsofMixDiffframework
in Table 2 to illuminate each component’s effect on performance.
First, we assume a more lenient access constraint whereby logits WetakeMixDiff+Entropyfortheseexperiments.MixDiff’sperfor-
areprovidedasthemodelf()’soutputs.Thissetupfacilitatesval- manceimprovementsareconsistentwhenthehomogeneityofauxil-
·
idation of MixDiff’s OOD score enhancement ability on both the iarysamplesisgraduallyincreasedbychangingthein-batchauxil-
logit-basedandprobability-basedscores.Notethat,inthissetup,the iarysamples,whichmaycontainOODsamples,torandomIDsam-
perturbed oracle samples’ probability-based OOD scores are com- ples(randomIDasauxiliary),andtotheotheroraclesampleswith
putedafteraveragingoutM perturbedoraclesamplesinthelogit- thesamepredictedlabelasthetarget(oracleasauxiliary),suggest-
space, i.e., O¯ i∗r = M1 M m=1O m∗ir. The consistent improvements ingthatMixDiffisrobusttothechoiceofauxiliarysamples.Elim-
acrossalldatasetsandmethodsinTable1indicatethatMixDiffis inating the comparison part in the perturb-and-compare approach
P
effectiveinenhancingoutput-basedOODscores,toadegreewhere byusingonlytheperturbedtarget’sscoreswithoutcomparingwith
oneofthetraining-freemethods,MixDiff+MCM,outperforminga theperturbedoracles’scores(withoutcomparepart),andrandomly
training-basedmethodCLIP+CAC.EquippingMixDiffwiththebest choosingoraclesamplesfromasetofIDsampleinsteadoffinding
performingnon-training-freemethod,ZOC,alsoyieldsperformance similaroraclesamplesusingthepredictedclasslabel(withoutora-
improvements. cleselection)resultinperformancedegradation.Theseobservations
suggestthatcomparingtherelativechangefromasimilarIDsample
is crucial. We show that MixDiff is applicable even when there is
4.3 Predictionprobabilitiesasmodeloutputs
nolabeledoraclesetbyselectingtop-M mostsimilarsamplesfrom
Wenowtakeamorerestrictedenvironmentwheretheonlyacces- M KunlabeledIDsampleswithsimilaritycalculatedfromthedot
×
siblepartofthemodelisitsoutputpredictionprobabilities.Tothe productofthepredictionprobabilitiesofthetargetandtheunlabeled
bestofourknowledge,noneoftheexistingOODscoreenhancement oraclesamples(unlabeledoracle).
methodsareapplicableinthisenvironment.Logitsarerequiredinthe
caseofSoftmaxtemperaturescaling[17].ODIN’sgradient-basedin- 4.4 Predictionlabelsasmodeloutputs
putpreprocessing[17]orweightpruningmethods[27]assumeanac-
cesstothemodel’sparameters.Themodel’sinternalactivationsare Wepushthelimitsofthemodelaccessbyassumingthatonlythepre-
requiredinthecaseofactivationclipping[28]andactivationpruning dictedclasslabelsareavailablewithoutanyscoresattachedtothem.
[6]. WeapplyMixDiffbyrepresentingthemodel’spredictionsasone-hot
WetakealinearcombinationofentropyandMSPscoreswitha vectorsandtakingthedifferencebetweentheperturbedtarget’spre-
scalinghyperparametertunedontheCaltech101datasetasabase- dictedlabelandthecorrespondingperturbedoracles’averagescore
line(Entropy+MSP).TheresultsarepresentedinTable2.Evenin forthatlabelinEquation4.AsthereisnobaseOODscoreapplica-
thisconstrainedenvironment,MixDiffeffectivelyenhancesoutput- bleintheenvironment,weusetheMixDiffscorealone.Theresults
basedOODscores,asevidencedbyMixDiff+Entropyoutperform- in Table 2 show that MixDiff is applicable even in this extremely
ingMCM(inTable1),amethodthatassumesanaccesstothelogit constrainedaccessenvironment.
space,whileMSPscorefailstoprovideentropyscoreanymeaning-
fulperformancegain.Figure4ashowsthatMixDiff’sperformance 4.5 Lastlayeractivationsasmodeloutputs
gaincanbeenjoyedwithaslittleastwoadditionalforwardpasses
(R = 1,N = 2).Figure4billustratesthediscriminativeedgepro- We relax the model access constraint by permiting access to the
videdbyMixDiffscorewhenthebaseOODscore’svaluesarealmost model’s activations from the last layer, i.e., image embeddings in
identical.Weobservethattheperformancegainismorepronounced CLIPmodel.Inthissetup,insteadofinput-levelMixup,weutilize
whentheoutputscontainmorelimitedinformationascanbeseenin embedding-levelMixup.Morespecifically,embeddingsoftarget(or
thecaseofMSPwhereonlythepredictedclass’sprobabilityvalueis oracle)areperturbedbymixingthemwithauxiliarysample’sembed-
utilized. dings, after which logits are computed from the perturbed embed-
CORUA
ecnereffiDDI,DOOTable1:AverageAUROCscoresforfivedatasets.ThehighestandsecondhighestAUROCscoresfromeachblockarehighlightedwithbold
andunderline.Thevalueontherightsideof denotesthestandarddeviationinducedfrom5differentOOD,IDclasssplits.Statistically
±
significantdifferencescomparedtothecorrespondingbasescore(indicatedbybackgroundcolor)areitalicised(one-tailedpairedt-testwithp
<0.1).∆representsdifferencefromthecorrespondingbasescore. indicatesthereducedevaluationsettingdescribedinAppendixG.4.We
†
reportAUCPR,FPR95scoresinAppendixH.WereportresultsonotherCLIPbackbonesinAppendixM.Bestviewedincolor.
Method Training-free CIFAR10 CIFAR100 CIFAR+10 CIFAR+50 TinyImageNet Avg. ∆
CSI[30] ✗ 87.0 4.0 80.4 1.0 94.0 1.5 97.0 76.9 1.2 87.0 -
CAC[20] ✗ 80.1± 3.0 76.1± 0.7 87.7± 1.2 87.0 76.0± 1.5 84.9 -
CLIP+CAC[20] ✗ 89.3± 2.0 83.5± 1.2 96.5± 0.5 95.8 84.6± 1.7 89.9 -
ZOC†[7] ✗ 91.5± ±2.5 82.7± ±2.8 97.6± ±1.1 97.1 82.6± ±3.1 90.3 -
MixDiff+ZOC† ✗ 92.2 ±2.5 82.8 ±2.4 98.2 ±1.2 98.5 82.9 ±3.3 90.9 +0.6
MSP[10] ✓ 88.7 2.0 78.2 3.1 95.0 0.8 95.1 80.4 2.5 87.5 -
MLS[11] ✓ 87.8± 3.0 80.0± 3.1 96.1± 0.8 96.0 84.0± 1.2 88.8 -
Energy[18] ✓ 85.4± 3.0 77.6± 3.7 94.9± 0.9 94.8 83.2± 1.2 87.2 -
Entropy[31] ✓ 89.9± 2.6 79.9± 2.5 96.8± 0.8 96.8 82.2± 2.3 89.1 -
MCM[21] ✓ 90.6± 2.9 80.3± 2.1 96.9± 0.8 97.0 83.1± 2.2 89.6 -
± ± ± ±
MixDiff+MSP ✓ 89.2 1.6 80.1 2.8 96.7 0.8 96.9 81.6 2.6 88.9 +1.4
MixDiff+MLS ✓ 87.9± 2.1 80.5± 2.2 96.5± 0.7 96.9 84.5± 0.9 89.3 +0.5
MixDiff+Energy ✓ 85.6± 2.2 78.3± 2.7 95.4± 0.8 95.9 83.6± 1.1 87.8 +0.6
MixDiff+Entropy ✓ 90.7± 1.8 81.0± 2.6 97.6± 0.8 97.6 82.9± 2.4 90.0 +0.9
MixDiff+MCM ✓ 91.4± 1.8 81.4± 2.6 97.5± 0.9 97.7 83.9± 2.2 90.4 +0.8
± ± ± ±
Table2:AUROCscoresonvariousdegreesofmodelaccessscenarios.Themethodsinthebottomblockrequirethemodel’sinneractivations
andareevaluatedwiththesameCLIPViT-B/32backboneandentropyasOODscoringfunction.Bestviewedincolor.
Method Access CIFAR10 CIFAR100 CIFAR+10 CIFAR+50 TinyImageNet Avg. ∆
MSP[10] Predictionprob. 88.7 2.0 78.2 3.1 95.0 0.8 95.1 80.4 2.5 87.5 -
± ± ± ±
Entropy[31] Predictionprob. 89.9 2.6 79.9 2.5 96.8 0.8 96.8 82.2 2.3 89.1 -
± ± ± ±
Entropy+MSP Predictionprob. 89.9 2.6 79.9 2.5 96.8 0.8 96.8 82.2 2.3 89.1 +0.0
± ± ± ±
MixDiff+MSP(Predictionprob.) Predictionprob. 89.4 1.3 80.0 2.8 96.5 0.8 96.8 81.8 2.4 88.9 +1.4
± ± ± ±
MixDiff+Entropy(Predictionprob.) Predictionprob. 91.1 1.6 80.9 2.6 97.1 0.8 97.3 82.9 2.3 89.9 +0.8
± ± ± ±
withoracleasauxiliary Predictionprob. 90.6 1.7 81.1 2.0 97.3 0.7 97.4 82.9 2.2 89.9 +0.8
± ± ± ±
withrandomIDasauxiliary Predictionprob. 90.8 1.5 81.1 2.1 96.8 1.0 96.8 82.9 2.3 89.7 +0.6
± ± ± ±
withunlabeledoracle Predictionprob. 91.0 1.6 80.5 2.9 97.1 0.8 97.3 82.7 2.1 89.7 +0.6
± ± ± ±
withoutcomparepart Predictionprob. 89.4 2.9 79.5 2.7 97.1 0.9 97.2 81.6 2.5 89.0 -0.1
± ± ± ±
withoutoracleselection Predictionprob. 89.5 2.8 79.6 2.7 97.1 0.9 97.3 81.7 2.5 89.0 -0.1
± ± ± ±
Randomscorefromuniformdist. Predictionlabel 49.6 0.5 49.8 1.1 49.8 0.7 50.1 49.8 0.4 49.8 -
± ± ± ±
MixDiffwithrandomIDasauxiliary Predictionlabel 62.4 4.1 59.4 6.2 65.6 1.5 65.4 63.3 2.8 63.2 +13.4
± ± ± ±
MixDiffwithoracleasauxiliary Predictionlabel 61.9 3.7 55.1 7.1 59.9 1.1 59.8 55.6 2.7 58.4 +8.6
± ± ± ±
MixDiff+MSP(EmbeddingMixup) Activation 90.0 1.8 80.0 3.6 95.6 0.8 95.7 82.2 2.3 88.7 +1.2
± ± ± ±
MixDiff+Entropy(EmbeddingMixup) Activation 91.1 2.0 81.1 3.2 97.1 0.7 97.1 83.7 2.2 90.0 +0.9
± ± ± ±
DML[41] Activation 87.8 3.0 80.0 3.1 96.1 0.8 96.0 84.0 1.2 88.8 -
± ± ± ±
ASH[6] Activation 85.2 3.8 75.4 4.4 92.5 0.9 92.4 77.2 3.1 84.5 -
± ± ± ±
dingsandfedtoanoutput-basedOODscoringfunctionh()suchas byevaluatingMixDiffunderadversarialattack.TheresultsinTable
·
entropy.Asauxiliaries’andoracles’embeddingsareprecomputed, 3 indicate that the contributing features that induce ID/OOD mis-
thecomputationaloverheadintroducedbyMixDiffisalmostnil.The classification are less robust to perturbations and that MixDiff can
assumptionoflinearmodelintheoreticalanalysisismorecloselyfol- effectivelyexploitsuchbrittleness.Detaileddescriptionoftheexper-
lowedinembedding-levelMixupsincetheycanbeviewedaslinear imentalsetupisinAppendixG.5.
probingoffoundationmodels’activations.BottomblockofTable2 Table3:AUROCscoresonvariousattackscenarios."In"(or"Out")
showsthatMixDiffcanenhanceOODdetectionperformanceeven indicatesalloftheID(orOOD)samplesareadversariallymodified.
withnegligiblecomputeoverheadinthisrelaxedsetup.Weuseran- "Both"indicatesalloftheID,OODsamplesareadversariallymod-
domIDsamplesasauxiliariesintheembeddingMixupexperiments. ified."MixDiffOnly"referstothescoreinEquation4withentropy
astheOODscoringfunctionh().
·
4.6 Robustnesstoadversarialattacks Method CIFAR10 CIFAR100
Clean In Out Both Clean In Out Both
InadversarialattackonanOODdetector,theattackercreatesasmall, Entropy 89.88 47.42 13.77 2.68 79.87 36.86 14.38 2.21
MixDiff+Entropy 90.64 54.71 31.77 8.84 81.11 50.31 31.40 9.08
indistinguishablemodificationtotheinputsamplewiththepurpose MixDiffOnly 88.16 61.00 40.28 20.45 78.05 58.84 44.19 27.48
ofincreasingthemodel’sconfidenceofagivenOODsampleorde-
creasing the model’s confidence of a given ID sample [2]. These
modificationscanbeviewedasinjectionofcertainartificialfeatures,
4.7 Experimentsonout-of-scopedetectiontask
specificallydesignedtoinducemoreconfidentoruncertainoutputs
fromthemodel.OurmotivationinSection1suggeststhatthesear- Out-of-scope detection We take the MixDiff framework to out-
tificialfeaturesmayalsobelessrobusttoperturbations.Wetestthis of-scope(OOS)detectiontasktocheckitsversatilityinregardtothemodalityoftheinput.Toreliablyfulfillusers’queriesorinstructions, Time and space complexity MixDiff is effective at bypassing
understanding the intent behind a user’s utterance forms a crucial a black-box model’s access restriction for OOD detection, but by-
aspectofdialoguesystems.Inintentclassificationtask,modelsare passing the access restriction comes with a certain computational
taskedtoextracttheintentbehindauserutterance.Eventhoughthere overhead. For each target sample x t, MixDiff requires processing
hasbeenaninflowofdevelopmentintheareafortheimprovementof ofN R mixedsamples.Whilethesesamplescanbeeffectively
×
classificationperformance,thereisnoguaranteethatagivenquery’s processedinparallelandtheMixDiffframeworkoutperformingthe
intentisinthesetofintentsthatthemodelisabletoclassify.OOS baselinesonlywithsmallvaluesofRandN,itnonethelessremains
detectiontask[3],concernswithdetectionofsuchuserutterances. asadrawbackoftheMixDiffframework.Furtherresearchiscalled
for reducing the computational and space complexity of MixDiff
MixDiffwithtextualinput Unlikeimageswhosecontinuousness
framework.
lends itself to a simple Mixup operation, the discreteness of texts
rendersMixupoftextsnotasstraightforward.Whilethereareseveral Selectionofauxiliarysamples InSection4,weexperimentwith
worksthatexploreinterpolationoftexts,mostoftheserequireaccess three auxiliary sample selection methods, one using the in-batch
tothemodelparameters[15].ThislimitstheMixDiffframework’s samplesandtheothertwousingtheoracleorrandomIDsamples
applicabilityinanenvironmentwherethemodelisservedasanAPI astheauxiliarysamples.Figure4ashowsreducedperformancegain
[26],whichisbecomingmoreandmoreprevalentwiththerapidde- whenthenumberofauxiliarysamples,N,istoosmall.Wehypoth-
velopmentoflargelanguagemodels[24].Followingthistrend,we esizethatthisisduetothefactthatwhileonaverageMixDiffcan
assume a more challenging environment with the requirement that effectivelydiscerntheoveremphasizedfeatures,thereisacertainde-
Mixupbeperformedontheinputlevel.Tothisend,wesimplycon- greeofvarianceintheMixDiffscore,requiringN and,tosomede-
catenatethetextpairandlettheinterpolationhappenwhilethepair gree, R to be over a certain value for reliable performance. There
isinsidethemodel[9]. maybeanauxiliarysamplethatismoreeffectiveatdiscerningan
Table4:AverageAUROCscoresforout-of-scopedetectiontask. overemphasizedfeatureofagiventargetsample,butthisissubject
tochangedependingonthetargetsample.Weleavetheexploration
Method CLINC150 Banking77 ACID TOP Average
ofbetterauxiliarysampleselectionmethods,eitherbycarefulcura-
MSP 93.02 85.43 88.98 90.01 89.36
tionofauxiliarysamplesorbymakingtheproceduremoreinstance-
MLS 93.56 85.02 88.91 90.06 89.39
Energy 93.61 84.99 88.83 90.06 89.37 awareandpossiblylearnable,asfuturework.
Entropy 93.29 85.59 88.87 90.02 89.44
Otherformsofinputs MixDiffframeworkcanbeeasilyextended
MixDiff+MSP 93.42 85.75 89.18 90.68 89.76
toincorporateinputsfromothermodalities.Theexperimentsonthe
MixDiff+MLS 93.88 85.46 89.24 90.35 89.73
MixDiff+Energy 93.89 85.51 89.18 90.35 89.73 out-of-scopedetectiontaskserveasanexampleofthesekindsofex-
MixDiff+Entropy 93.67 85.98 89.13 90.68 89.87 tensions.Thisinput-levelMixupmakestheframeworkapplicableto
environments where the access to the model parameters cannot be
assumed.ItalsograntsthefreedomtodesignbetterMixupmethods
Experimentalsetup WerunOOSdetectionexperimentsusing4
thatarespecifictotheformatoftheinputorthetaskathand.Butthis
intent classification datasets: CLINC150, Banking77, ACID, TOP.
freedomcomesatthecostofhavingtodeviseaMixupmechanism
FollowingZhanetal.[37],werandomlysplittheprovidedclasses
foreachinputformatandtask.Forexample,thesimpleconcatena-
into in-scope and OOS intents, with in-scope intent class ratios of
tionofsamplesthatwehaveutilizedonout-of-scopedetectiontask
25%, 50%, 75%. For the intent classification model, we finetune
hasthelimitationthatitcannotbeappliediftheinputsequenceistoo
BERT-basemodel[5]onthein-scopesplitofeachdataset’strainset.
longduetothequadratictimeandspacecomplexityofTransformers
Foreachin-scoperatio,weconstruct10in-scope,OOSsplitswith
[32].
differentrandomseeds.DetailedexperimentalsetupisinAppendix
G.6. Othertypesofdistributionshiftsandbroadercategoriesofmod-
els Thisworkdealswithdetectinglabelshiftwithclassifiermod-
Results WereporttheaverageAUROCscoresinTable4,eachof els.However,thereareothertypesofdistributionshiftssuchasdo-
whichisaveragedoverthein-scopeclassratiosaswellastheclass mainshiftandbroaderrangeofmodelsotherthanclassifiers,e.g.,
splits.EvenwithasimpleMixupmethodthatsimplyconcatenates imagesegmentationmodels.Extensionsoftheperturb-and-compare
thetextpair,MixDiffconsistentlyimprovestheperformanceacross mechanismtomorediversetypesofshiftsandtaskswouldbeavalu-
diverse datasets. The results suggest that the MixDiff framework’s ableadditiontotheblack-boxOODdetectionfield.
applicabilityisnotlimitedtoimagesandthattheframeworkcanbe
appliedtoothermodalitieswithanappropriateperturbationmethod.
6 Conclusion
5 Liminationsandfuturework Inthiswork,wepresentanewOODdetectionframework,MixDiff,
thatboostsOODdetectionperformanceinconstrainedaccesssce-
Dependencyonmodel’sperformance 90 narios.MixDiffisbasedontheperturb-and-compareapproachthat
w/MixDiff
We construct a low-confidence oracle MSP measureshowthemodel’sconfidenceinthetargetsamplebehaves
89.5
set by limiting the oracle pool to con- comparedtoasimilarIDsamplewhenbothundergoanidenticalper-
tain the top p% of most uncertain ID 89 turbation.Thisprovidesanadditionalsignalthatcannotbegained
samples. Fig. 5 shows MixDiff’s de- from the limited information of the target sample’s model output
88.5
pendency on the model’s ability to as- alone.Weprovidetheoreticalgroundsfortheframework’seffective-
0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8
signminimalconfidenceontheoracle. Clippingpercentage(p) nessandempiricallyvalidateourapproachonmultipledegreesofre-
The experiments are performed with Figure5:Effectoflow- strictedaccessscenarios.OurexperimentalresultsshowthatMixDiff
CIFAR10datasetusingtheotheroracle confidenceoracles. isaneffectiveOODdetectionmethodforconstrainedaccessscenar-
samplesofthepredictedclassofthetargetasauxiliaries. ioswheretheapplicabilityofexistingmethodsislimited.
CORUAAcknowledgements [20] D.Miller,N.Sunderhauf,M.Milford,andF.Dayoub. Classanchor
clustering:Alossfordistance-basedopensetrecognition. InProceed-
This work was supported by the National Research Foundation of ingsoftheIEEE/CVFWinterConferenceonApplicationsofComputer
Korea (NRF) grant funded by the Korea government (MSIT) (No. Vision,2021.
[21] Y.Ming,Z.Cai,J.Gu,Y.Sun,W.Li,andY.Li. Delvingintoout-of-
2021R1F1A1060117,2022R1A4A3033874)andICTCreativeCon- distributiondetectionwithvision-languagerepresentations. Advances
silienceProgramthroughtheInstituteofInformation&Communi- inNeuralInformationProcessingSystems,2022.
cationsTechnologyPlanning&Evaluation(IITP)grantfundedby [22] A.Nguyen,J.Yosinski,andJ.Clune. Deepneuralnetworksareeas-
ilyfooled:Highconfidencepredictionsforunrecognizableimages. In
theKoreagovernment(MSIT)(IITP-2024-2020-0-01821).
ProceedingsoftheIEEEconferenceoncomputervisionandpattern
recognition,2015.
[23] B. Olber, K. Radlak, A. Popowicz, M.Szczepankiewicz, and
References
K.Chachula.Detectionofout-of-distributionsamplesusingbinaryneu-
ronactivationpatterns. In2023IEEE/CVFConferenceonComputer
[1] Y. H. Ahn, G.-M. Park, and S. T. Kim. Line: Out-of-distribution
VisionandPatternRecognition(CVPR),2023.
detection by leveraging important neurons. In Proceedings of the
[24] OpenAI.Gpt-4technicalreport,2023.
IEEE/CVF Conference on Computer Vision and Pattern Recognition
[25] A.Radford,J.W.Kim,C.Hallacy,A.Ramesh,G.Goh,S.Agarwal,
(CVPR),2023.
G.Sastry,A.Askell,P.Mishkin,J.Clark,etal. Learningtransferable
[2] M.Azizmalayeri,A.S.Moakar,A.Zarei,R.Zohrabi,M.T.Manzuri,
visualmodelsfromnaturallanguagesupervision.InInternationalCon-
andM.H.Rohban. Yourout-of-distributiondetectionmethodisnot
ferenceonMachineLearning.PMLR,2021.
robust!InAdvancesinNeuralInformationProcessingSystems,2022.
[26] T.Sun,Y.Shao,H.Qian,X.Huang,andX.Qiu. Black-boxtuningfor
[3] D.ChenandZ.Yu. GOLD:Improvingout-of-scopedetectionindia-
language-model-as-a-service.InProceedingsofICML,2022.
loguesusingdataaugmentation.InProceedingsofthe2021Conference
[27] Y.SunandY.Li.Dice:Leveragingsparsificationforout-of-distribution
onEmpiricalMethodsinNaturalLanguageProcessing,2021.
detection.InEuropeanConferenceonComputerVision,2022.
[4] P.Chen,Q.Li,S.Biaz,T.Bui,andA.Nguyen.gscorecam:Whatobjects
[28] Y.Sun,C.Guo,andY.Li.React:Out-of-distributiondetectionwithrec-
iscliplookingat?InProceedingsoftheAsianConferenceonComputer
tifiedactivations. InAdvancesinNeuralInformationProcessingSys-
Vision(ACCV),2022.
tems,2021.
[5] J.Devlin,M.-W.Chang,K.Lee,andK.Toutanova.BERT:Pre-training
[29] Y.Sun,Y.Ming,X.Zhu,andY.Li. Out-of-distributiondetectionwith
ofdeepbidirectionaltransformersforlanguageunderstanding. InPro-
deepnearestneighbors.ICML,2022.
ceedings of the 2019 Conference of the North American Chapter of
[30] J.Tack,S.Mo,J.Jeong,andJ.Shin. Csi:Noveltydetectionviacon-
theAssociationforComputationalLinguistics:HumanLanguageTech-
trastivelearningondistributionallyshiftedinstances.Advancesinneu-
nologies,Volume1(LongandShortPapers),2019.
ralinformationprocessingsystems,2020.
[6] A.Djurisic,N.Bozanic,A.Ashok,andR.Liu. Extremelysimpleacti-
[31] S. Thulasidasan, S. Thapa, S. Dhaubhadel, G. Chennupati, T. Bhat-
vationshapingforout-of-distributiondetection. InTheEleventhInter-
tacharya,andJ.A.Bilmes. Aneffectivebaselineforrobustnesstodis-
nationalConferenceonLearningRepresentations,2023.
tributionalshift.202120thIEEEInternationalConferenceonMachine
[7] S.Esmaeilpour,B.Liu,E.Robertson,andL.Shu. Zero-shotout-of-
LearningandApplications(ICMLA),2021.
distributiondetectionbasedonthepre-trainedmodelclip. InProceed-
[32] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
ingsoftheAAAIconferenceonartificialintelligence,number6,2022.
Gomez,L.u.Kaiser,andI.Polosukhin. Attentionisallyouneed. In
[8] L.Fei-Fei,R.Fergus,andP.Perona.Learninggenerativevisualmodels
AdvancesinNeuralInformationProcessingSystems,2017.
fromfewtrainingexamples:Anincrementalbayesianapproachtested
[33] H.Wang,Z.Li,L.Feng,andW.Zhang. Vim:Out-of-distributionwith
on101objectcategories. In2004conferenceoncomputervisionand
virtual-logitmatching.InProceedingsoftheIEEE/CVFConferenceon
patternrecognitionworkshop.IEEE,2004.
ComputerVisionandPatternRecognition(CVPR),2022.
[9] X.Hao,Y.Zhu,S.Appalaraju,A.Zhang,W.Zhang,B.Li,andM.Li.
[34] H.Wang,Y.Li,H.Yao,andX.Li. Clipnforzero-shotooddetection:
Mixgen: A new multi-modal data augmentation. In Proceedings of
Teachingcliptosayno.InProceedingsoftheIEEE/CVFInternational
theIEEE/CVFWinterConferenceonApplicationsofComputerVision
ConferenceonComputerVision,2023.
(WACV)Workshops,2023.
[35] J.Yang,K.Zhou,Y.Li,andZ.Liu. Generalizedout-of-distribution
[10] D.HendrycksandK.Gimpel. Abaselinefordetectingmisclassified
detection:Asurvey.arXivpreprintarXiv:2110.11334,2021.
andout-of-distributionexamplesinneuralnetworks. InInternational
[36] E.YilmazandC.Toraman.D2U:Distance-to-uniformlearningforout-
ConferenceonLearningRepresentations,2017.
of-scopedetection. In2022AnnualConferenceoftheNorthAmerican
[11] D.Hendrycks,S.Basart,M.Mazeika,M.Mostajabi,J.Steinhardt,and
ChapteroftheAssociationforComputationalLinguistics,2022.
D.X.Song. Scalingout-of-distributiondetectionforreal-worldset-
[37] L.-M.Zhan,H.Liang,B.Liu,L.Fan,X.-M.Wu,andA.Y.Lam. Out-
tings.InInternationalConferenceonMachineLearning,2022.
of-scopeintentdetectionwithself-supervisionanddiscriminativetrain-
[12] Y.C.Hsu,Y.Shen,H.Jin,andZ.Kira. Generalizedodin:Detect-
ing. InProceedingsofthe59thAnnualMeetingoftheAssociationfor
ingout-of-distributionimagewithoutlearningfromout-of-distribution
ComputationalLinguisticsandthe11thInternationalJointConference
data. In2020IEEE/CVFConferenceonComputerVisionandPattern
onNaturalLanguageProcessing(Volume1:LongPapers),2021.
Recognition(CVPR),2020.
[38] H.Zhang,M.Cisse,Y.N.Dauphin,andD.Lopez-Paz.mixup:Beyond
[13] R.Huang,A.Geng,andY.Li. Ontheimportanceofgradientsfor
empiricalriskminimization. InInternationalConferenceonLearning
detectingdistributionalshiftsinthewild. InAdvancesinNeuralInfor-
Representations,2018.
mationProcessingSystems,2021.
[39] J. Zhang, Q. Fu, X. Chen, L. Du, Z. Li, G. Wang, xiaoguang Liu,
[14] S.IoffeandC.Szegedy. Batchnormalization:Acceleratingdeepnet-
S. Han, and D. Zhang. Out-of-distribution detection based on in-
worktrainingbyreducinginternalcovariateshift. InProceedingsof
distributiondatapatternsmemorizationwithmodernhopfieldenergy.
the32ndInternationalConferenceonMachineLearning,Proceedings
InTheEleventhInternationalConferenceonLearningRepresentations,
ofMachineLearningResearch.PMLR,2015.
2023.
[15] F.Kong,R.Zhang,X.Guo,S.Mensah,andY.Mao. DropMix:Atex-
[40] L.Zhang,Z.Deng,K.Kawaguchi,A.Ghorbani,andJ.Zou.Howdoes
tualdataaugmentationcombiningdropoutwithmixup.InProceedings
mixuphelpwithrobustnessandgeneralization? InInternationalCon-
ofthe2022ConferenceonEmpiricalMethodsinNaturalLanguage
ferenceonLearningRepresentations,2021.
Processing,2022.
[41] Z.ZhangandX.Xiang. Decouplingmaxlogitforout-of-distribution
[16] K.Lee,K.Lee,H.Lee,andJ.Shin.Asimpleunifiedframeworkforde-
detection. InProceedingsoftheIEEE/CVFConferenceonComputer
tectingout-of-distributionsamplesandadversarialattacks.InAdvances
VisionandPatternRecognition(CVPR),2023.
inNeuralInformationProcessingSystems,2018.
[42] Y.Zhu,Y.Chen,C.Xie,X.Li,R.Zhang,H.Xue’,X.Tian,bolun
[17] S.Liang,Y.Li,andR.Srikant. Enhancingthereliabilityofout-of-
zheng,andY.Chen.Boostingout-of-distributiondetectionwithtypical
distributionimagedetectioninneuralnetworks. InInternationalCon-
features.InAdvancesinNeuralInformationProcessingSystems,2022.
ferenceonLearningRepresentations,2018.
[18] W.Liu,X.Wang,J.Owens,andY.Li.Energy-basedout-of-distribution
detection.AdvancesinNeuralInformationProcessingSystems,2020.
[19] X. Liu, Y. Lochman, and Z. Chrsitopher. Gen: Pushing the limits
ofsoftmax-basedout-of-distributiondetection. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition,
2023.Supplementary Material -
Perturb-and-Compare Approach for Detecting
Out-of-Distribution Samples in Constrained Access
Environments
Contents
A Notation 2
B ProofofProposition1 2
C ProofofTheorem1andextensiontootherOODscoringfunctions 3
D ExperimentalvalidationofProposition1andTheorem1 5
E Verificationexperimentofthemainmotivation 5
F Practicalimplementation 6
G Experimentaldetails 7
G.1 Experimentalsetup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
G.2 Evaluationmetrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
G.3 HyperparametersearchonCaltech101 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
G.4 AdaptationofMixDiffwithZOC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
G.5 Experimentaldetailsonadversarialdefencetask . . . . . . . . . . . . . . . . . . . . . . . . . 8
G.6 Experimentaldetailsonout-of-scopedetectiontask . . . . . . . . . . . . . . . . . . . . . . . 10
H PerformanceevaluationwithAUCPRandFPR95 11
I ComparisonwithotherOODscoringfunctions 12
J Computationalcostanalysis 13
K Processingtimeanalysis 13
L Sensitivityanalysis 14
M Performanceevaluationwithotherbackbones 15
N Performanceevaluationundervaryingmisclassificationrates 15
O Reproducibility 15
1
4202
guA
91
]GL.sc[
1v70101.8042:viXraP Qualitativeanalysis 15
P.1 OODscoredensitycurves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
P.2 Logitvisualizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
A Notation
Notation Definition
f() Classifiermodel.
·
h() Arbitraryoutput-basedOODscorefunction.
·
M Thenumberoforaclesamplesofeachclass.
R ThenumberofMixupratios.
N Thenumberofauxiliarysamplesthatwillbemixedwiththeoracleortargetsamples.
Ω Setoforaclesampleandlabelpairsforthek-thclass.
k
Ω Setoforaclesampleandlabelpairsofallclasses, Ω K .
{ k}k=1
λ r-thMixupratio.
r
x Thetargetsample.
t
x Mixedsamplefromthetargetx andi-thauxiliarysamplewithMixupratioofλ .
ir t r
x ∗mir Mixedsamplefromthem-thoraclesamplei-thauxiliarysamplewithMixupratioofλ r.
O Thepredictionscoresfromthemixtureofthetargetandi-thauxiliarysamplewiththeMixupratioλ .
ir r
O m∗ir Thepredictionscoresfromthemixtureofthem-thoracleandi-thauxiliarysamplewiththeMixupratioλ r.
O¯ i∗r Themeanof {O m∗ir}M m=1alongthesubscriptm.
s OODscoreinducedbyO .
ir ir
s ∗ir OODscoreinducedbyO¯ i∗r.
γ ThescalinghyperparametertowhichtheMixDiffscorewillbemultiplied.
B Proof of Proposition 1
Proposition 1 (OOD score function for mixed samples). Let pre-trained model f() and base OOD score
·
function h() be a twice-differentiable function, and x = λx +(1 λ)x be a mixed sample with ratio
iλ t i
· −
λ (0,1). ThenbaseOODscorefunctionofmixedsample,h(f(x )),iswrittenas:
iλ
∈
3
h(f(x ))=h(f(x ))+ ω (x ,x )+φ (λ)(λ 1)2 (B.1)
iλ t l t i t
−
l=1
X
wherelim φ (λ)=0,
λ 1 t
→
ω (x ,x )=(λ 1)(x x )Tf (x )h(f(x ))
1 t i t i ′ t ′ t
− −
(λ 1)2
ω 2(x t,x i)= − (x
t
x i)Tf ′′(x t)(x
t
x i)h ′(f(x t))
2 − −
(λ 1)2
ω 3(x t,x i)= − (x
t
x i)Tf ′(x t)(x
t
x i)Tf ′(x t)h ′′(f(x t)).
2 − −
Proof. Letψ (λ)=h(f(x ))whichismodifiedfunctionofh(f(x ))havingλasaninput. Ifh()andf()
t iλ iλ
· ·
aretwicedifferentiablewithrespecttoeachinput. Bythesecond-orderTaylorapproximation,
1
ψ t(λ)=ψ t(1)+ψ t′(1)(λ −1)+ 2ψ t′′(1)(λ −1)2+φ t(λ)(λ −1)2, (B.2)
wherelim φ (λ)=0.
λ 1 t
→
∂x ∂f(x )∂h(f(x ))
ψ (λ)= iλ iλ iλ =(x x )Tf (x )h(f(x ))
t′
∂λ ∂x ∂f(x )
t
−
i ′ iλ ′ iλ
iλ iλ
2Since ∂ (x x )Tf (x )h(f(x )) = ∂ [(x x )Tf (x )]h(f(x )) + (x
∂λ t − i ′ iλ ′ iλ ∂λ t − i ′ iλ ′ iλ t −
x )Tf (x ) ∂ [h(f(x ))]and ∂ (x x )Tf (x )=(x x )Tf (x )(x x ),
i ′ iλ ∂λ ′ iλ ∂λ t − i ′ iλ t − i ′′ iλ t − i
ψ (λ)=(x x )Tf (x )(x x )h(f(x ))+(x x )Tf (x )(x x )Tf (x )h (f(x ))
t′′ t
−
i ′′ iλ t
−
i ′ iλ t
−
i ′ iλ t
−
i ′ iλ ′′ iλ
Whenλ=1,
ψ (1)=(x x )Tf (x )h(f(x ))
t′ t
−
i ′ t ′ t
ψ (1)=(x x )Tf (x )(x x )h(f(x ))+(x x )Tf (x )(x x )Tf (x )h (f(x )).
t′′ t
−
i ′′ t t
−
i ′ t t
−
i ′ t t
−
i ′ t ′′ t
Fianlly,wederiveEquationB.1inProposition1as
h(f(x iλ))=h(f(x t))+(λ 1)(x
t
x i)Tf ′(x t)h ′(f(x t)) (B.3)
− −
(λ 1)2
+ − (x
t
x i)Tf ′′(x t)(x
t
x i)h ′(f(x t)) (B.4)
2 − −
(λ 1)2
+ − (x
t
x i)Tf ′(x t)(x
t
x i)Tf ′(x t)h ′′(f(x t)) (B.5)
2 − −
+φ (λ)(λ 1)2.
t
−
C Proof of Theorem 1 and extension to other OOD scoring functions
Theorem1. Leth(x)representMSPandf(x)representalinearmodel,describedbywTx+b,wherew,x Rd
∈
andb R. Weconsiderthetargetsample,x t,tobeahardOODsample,definedasasamplethatispredicted
∈
tobeofthesameclassastheoraclesample, x , butwithahigherconfidencescorethantheoraclesample.
m
Forbinaryclassification,x isahardOODsamplewhen0 < f(x ) < f(x )orf(x ) < f(x ) < 0. There
t m t t m
existsanauxiliarysamplex suchthat
i
3
h(f(x )) h(f(x ))+ (ω (x ,x ) ω (x ,x ))>0. (C.6)
t m l t i l m i
− −
l=1
X
Proof. Considering MSP in binary classification task, MSP = max(σ(f(x)),1 σ(f(x))). f (x) =
′
− −
w, f ′′(x)=0,
σ (f(x)) iff(x)>0
′
h ′(f(x))= −
(σ ′(f(x)) otherwise
σ (f(x)) iff(x)>0
′′
h ′′(f(x))= −
(σ ′′(f(x)) otherwise
where σ() denotes the sigmoid function. As the target sample is a hard OOD sample, it can be written as
·
f(x ) = f(x )+candh(f(x )) < h(f(x ))where0 < f(x ) < f(x ),0 < c and 0.5 < σ(f(x )) <
t m t m m t m
σ(f(x )). Then,h(f(x )) h(f(x ))= σ(f(x ))+σ(f(x )). 0.5< σ(f(x ))+σ(f(x ))<0.
t t m t m t m
− − − −
EquationC.6isequivalenttoEquationC.7asω =0undertheassumptionthatf(x)isalinearmodel.
2
h(f(x )) h(f(x ))+(ω (x ,x ) ω (x ,x ))+(ω (x ,x ) ω (x ,x ))>0 (C.7)
t m 1 t i 1 m i 3 t i 3 m i
− − −
ω 1(x t,x i) ω 1(x m,x i)=(λ 1)[(x
t
x i)Tw( σ ′(f(x t))) (x
m
x i)Tw( σ ′(f(x m)))] (C.8)
− − − − − − −
=(λ 1)[(f(x i) f(x t))σ ′(f(x t)) (f(x i) f(x m))σ ′(f(x m))] (C.9)
− − − −
=(λ 1)[(f(x i) f(x t))σ ′(f(x t)) (f(x i) f(x t)+c)σ ′(f(x m))] (C.10)
− − − −
=(λ 1)[(f(x i) f(x t))(σ ′(f(x t)) σ ′(f(x m))) cσ ′(f(x m))]. (C.11)
− − − −
3Becauseweassume0 < f(x ) < f(x ),σ (f(x )) σ (f(x )) < 0,and0 < λ < 1. When(ω (x ,x )
m t ′ t ′ m 1 t i
− −
ω (x ,x ))>0.5,
1 m i
(1/2(λ 1))+cσ (f(x ))
′ m
f(x ) f(x )+ − (C.12)
i t
≥ σ (f(x )) σ (f(x ))
′ t − ′ m
f(x )denotestheconfidenceofthemodelwithrespecttoauxiliarysamplex . Whenf(x )satisfiestheabove
i i i
condition,EquationC.7holdswhen
ω (x ,x ) ω (x ,x ) 0. (C.13)
3 t i 3 m i
− ≥
Letτ = h′′(f(xt)) >0,then
h′′(f(xm))
[(x
t
x i)Tw]2h ′′(f(x t)) [(x
m
x i)Tw]2h ′′(f(x m)) 0 (C.14)
− − − ≥
[(f(x t) f(x i))2τ (f(x m) f(x i))2]h ′′(f(x m)) 0. (C.15)
− − − ≥
Becauseofh (f(x ))>0,
′′ m
(f(x ) f(x ))2τ (f(x ) f(x ))2 0 (C.16)
t i m i
− − − ≥
(f(x ) f(x ))2τ (f(x ) c f(x ))2 0. (C.17)
t i t i
− − − − ≥
Lett=f(x ) f(x ),then
t i
−
t2τ (t c)2 =(τ 1)t2+2ct c2. (C.18)
− − − −
ByreformulatingtheEquationC.18withrespecttof(x ),weobtainthefollowingexpression.
i
(τ 1)f(x )2 2((τ 1)f(x )+c)f(x )+(τ 1)f(x )2+2cf(x ) c2 0. (C.19)
i t i t t
− − − − − ≥
When0 < τ,thediscriminantoftheEquationC.19withrespecttof(x )ispositiveandthevalueoftheright
i
sideofC.12existsbetweenthetwosolutionvaluesforwhichC.19equalszerowithrespecttof(x ).
i
Theorem2. Theorem1holdsforEntropyOODscoringfunction.
Proof. Considering Entropy OOD score function in binary classification task, Entropy =
(σ(f(x))log(σ(f(x)))+(1 σ(f(x)))log(1 σ(f(x)))). f ′(x)=wandf ′′(x)=0.
− − −
Let us express the scores of a hard OOD sample and an oracle sample as f(x ),f(x ) > 0,f(x ) =
t m t
f(x )+c,c > 0. Then, ϵ < h(f(x )) h(f(x )) < 0, where ϵ < 0 denotes the lower bound of the
m t m
− − −
differencebetweentheOODscoresofthetargetandoraclesamples. FollowedbyEquationC.11,
(λ 1)(f(x ) f(x ))(h(f(x )) h(f(x )))+(λ 1)ch(f(x )).
t m ′ t ′ m ′ m
− − − −
Becausethesignofh(f(x ))isanegativewhenf(x )>0,(λ 1)ch(f(x )) 0.h(f(x )) h(f(x ))+
′ m m ′ m t m
− ≥ −
(ω (x ,x ) ω (x ,x )) 0,where(λ 1)(f(x ) f(x ))(h(f(x )) h(f(x ))) ϵ.
1 t i 1 m i t m ′ t ′ m
− ≥ − − − ≥
ϵ
f(x i) f(x t) , if h ′(f(x t)) h ′(f(x m))>0 (C.20)
≥ − (λ 1)(h(f(x )) h(f(x ))) −
− ′ t − ′ m
ϵ
f(x i) f(x t) , if h ′(f(x t)) h ′(f(x m))<0 (C.21)
≤ − (λ 1)(h(f(x )) h(f(x ))) −
− ′ t − ′ m
Undertheassumptionthatf(x )satisfiestheabovecondition,EquationC.6holdswhen
i
ω (x ,x ) ω (x ,x ) 0. (C.22)
3 t i 3 m i
− ≥
Letτ = h′′(f(xm)) > 0,thenwefollowthesamestepsinEquationC.15-EquationC.18. Thereexistsx
h′′(f(xt)) i
suchthatitsatisfiesEquationC.22andEquationC.21.
4Theorem3. Theorem1holdsforMLSOODscoringfunction.
Proof. Considering MLS OOD score function in binary classification task, MLS = f(x). Equation C.6 is
−
equivalenttoEquationC.23asω =ω =0becausef (x)=h (f(x))=0.
2 3 ′′ ′′
h(f(x )) h(f(x ))+ω (x ,x ) ω (x ,x )>0 (C.23)
t m 1 t i 1 m i
− −
Therighthand-sideofEquationC.23iswrittenas
f(x )+f(x )+(1 λ)[(f(x ) f(x )) (f(x ) f(x ))] (C.24)
t m t i m i
− − − − −
= f(x )+f(x )+(1 λ)(f(x ) f(x )) (C.25)
t m t m
− − −
= λf(x )+λf(x ). (C.26)
t m
−
Ifx isanOODsampleandf(x )>f(x )wheref(x ),f(x )>0,EquationC.23holds.
t m t t m
D Experimental validation of Proposition 1 and Theorem 1
(a)MixDiff+Entropy (b)MixDiff+MLS
Figure1: Ontheleftof(a)and(b),theOODscoresofamixedtargetsamplearecomparedwiththeapproximatedOOD
scores. Ontherightof(a)and(b),auxiliarysamplesareshownalongwiththeoraclesamplesthatguaranteeMixDiffis
positive.
WeexperimentallyverifythatProposition1andTheorem1holdwhenthebaseOODscorefunctionsare
Entropy and MLS, respectively. We conduct verification experiments on a synthetic dataset consisting of 2-
dimensionalfeaturesfollowingthesamesetupasinSection3.1ofthemainpaper. OntherightsideofFigure
1a,weplottheOODtargetsample,anoraclesamplethathasthesameclassasthepredictedclassofthetarget
sample, and auxiliary samples that satisfy the condition that makes MixDiff positive. On the right side of
Figure1b,weshowasingletargetsamplealongwiththeoraclesamplesthatsatisfytheconditionforhaving
apositiveMixDiffscore. Theassumptionofbinaryclassificationwithalinearmodeleliminatestheeffectof
auxiliarysamples.
E Verification experiment of the main motivation
Ourprimaryhypothesisisthatoveremphasizedfeaturesaremoresusceptibletoperturbationscomparedtothe
features that actually belong to the predicted class. To test this hypothesis, we utilize class activation map
(CAM) [Chen et al., 2022b] to observe the changes in the model’s attention areas before and after Mixup
operation.
We conduct the experiment using CLIP ViT-B/32 and follow the same settings as in the OOD detection
experimentsonCIFAR100. WefirstcollectOODsamplesthataremisclassifiedasIDbytheMSPscorewith
athresholdsetbyTPR95. Thissetcontainssamplesforwhichthemodelhasexhibitedhighconfidence. We
then filter these samples to include only those classes with at least five samples per class. For each sample,
5Figure2: Theaveragepixel-wisedifferenceoftheCAMimagesismeasuredbeforeandaftermixingtheOODsamples
withanauxiliarysample. Thehighconfidenceclassandthegroundtruthclassrepresenttheclassesusedfortheprompts
inCAM.WemeasurethefluctuationsintheareasofthemodelfocuswhentheOODsamplesareperturbedbyarbitrary
signalssuchasmixingwithanauxiliarysample.
an auxiliary sample for Mixup was randomly selected from an ID class, excluding the class with the highest
confidenceforthatsample.
We compare the CAMs of the high-confidence OOD samples before and after Mixup. The CAMs are
processed through min-max normalization, and values below 0.8 are clipped to be zero. We then measure
the L distance between the two CAMs. To observe the difference in CAMs before and after Mixup for the
1
predicted high-confidence class, we use the text prompt of the class predicted by the model. Similarly, we
measurethedifferenceinCAMsofthegroundtruthclassesunderMixupoperationwiththetextpromptofthe
groundtruthclassofthesample. Theuseofgroundtruthclassistoeliminatetheeffectofsample-wisescale
differences. Forexample,somesampleshavealargeorsmallobjectareacomparedtoothers.
Figure2comparestheaveragedistanceinCAMsforeachclass,consideringthepromptsaseitherahigh
confidenceclassoragroundtruthclass. Asmallerdistanceimplieslessvariationduetoperturbation,suggest-
ingthatthefeaturesthatthemodelfocusesonarehighlyrelevanttotherespectiveclass. Ontheotherhand,
alargerdistanceindicatesagreatervariationduetoperturbation,whichcouldmeanthatthefeaturesthatthe
modelfocusesonareeitherlessrelevanttotheclassorincorrectlyidentifiedasrelevantfeatures. Theresultsin
Figure2indicatehowperturbationscanbeusedtoassessthereliabilityofthefeaturesthatleadtoahighlevel
ofconfidenceintheinputpredictionsofthemodel.
F Practical implementation
For each target sample x , MixDiff generates N R mixed samples. Similarly, it generates N R mixed
t
× ×
samplesforeachofM oraclesamples. Ifwefollowthein-batchsetupwherethesamplesthatareinthesame
batchasthetargetsampleareusedastheauxiliarysamples,MixDiffrequiresprocessingofBNR+BMNR
mixedsamples,denotingthebatchsizeasB =N +1.
We avoid BNR+BMNR repeated forward passes by putting each set of the entire Mixup results, in-
cluding the ones that are mixed with itself, into two tensors of sizes that are prefixed with (B,B,R) and
(B,M,B,R), one for the mixed images of targets and auxiliary samples, the other for the mixed images of
oracles and auxiliary samples, respectively. After computing the yet-to-be-averaged MixDiff scores within a
tensorofsize(B,B,R),wezerooutthediagonalentriesinthefirsttwodimensions,(B,B),eliminatingthe
scoresfromthetargetimagesthataremixedwithitself. Then,wetaketheaverageofthelasttwodimensions,
6(B,R),yieldingBMixDiffscoresforeachoftheBtestsamples.
We also note that in practice the set of O¯ prediction scores corresponding to the oracle samples mixed
i∗r
with the other in-batch samples do not need to be computed for every single test batch. One can use a fixed
setofsamplesasanauxiliarysetandprecomputeeachofthemixedoraclelogitsO¯ bymixingthesesamples
i∗r
withtheoraclesamples. Whenatestbatcharrives,eachofthesamplesinthebatchwillthenbeindependently
mixedwiththesefixedauxiliarysamples. Notonlydoesitreducethecomputecost,thereisnodependencyon
the test batch size in regard to OOD detection performance, since the auxiliary samples are no longer drawn
fromthetestbatch.
G Experimental details
G.1 Experimentalsetup
We evaluate MixDiff within the setting where the class names of OOD samples and the OOD labels are un-
available at train time. This is a more challenging experimental setting compared to the environment where
the OOD class names or its instances are known during the training phase. We follow the same setup as in
Esmaeilpour et al. [2022], and evaluate our method on five OOD detection benchmark datasets: CIFAR10
[Krizhevsky et al., 2009], CIFAR100 [Krizhevsky et al., 2009], CIFAR+10 [Miller et al., 2021], CIFAR+50
[Milleretal.,2021],TinyImageNet[LeandYang,2015].
Eachdataset’sIDandOOD(knownandunknown)classsplitsareconstructedasfollows. CIFAR10: the
dataset’s10classesarerandomlysplitinto6IDclassesand4OODclasses.CIFAR100:consecutive20classes
areassignedtobeIDclassesandtheremaining80classesareassignedtobeOODclasses. CIFAR+10:4non-
animal classes of CIFAR10 are ID classes, 10 randomly sampled animal classes from CIFAR100 are OOD
classes. CIFAR+50: 4 non-animal classes of CIFAR10 are ID classes, 50 randomly sampled animal classes
fromCIFAR100areOODclasses. TinyImageNet: considers20randomlysampledclassesasIDclassesand
theremaining180classesasOODclasses.
ForCIFAR10,CIFAR+10,CIFAR+50andTinyImageNet,wefollowthesameID,OODclasssplitsasin
Milleretal.[2021];Esmaeilpouretal.[2022]. ForCIFAR100,weusethesameclasssplitsasinEsmaeilpour
et al. [2022]. Each dataset contains 5 splits, except for CIFAR+50, which is consisted of only one ID, OOD
classsplit. Figure3showseachmethod’saverageAUROCscoresaveragedoverthefivedatasets. Thesetup
takes logits as model outputs. All of the results for non-training-free methods are from Esmaeilpour et al.
[2022]exceptforZOCandMixDiff+ZOC.
We utilize CLIP’s [Radford et al., 2021] zero-shot classification capability for OOD detection. More
specifically, we compute the similarity score for each ID class label’s prompt, "This is a photo of
label ", with the target image, and use these as logits. Since OOD class labels are not known a priori,
{ }
thisformsavalidexperimentalsetupeventhoughtheCLIPmodelisperformingzero-shotclassificationtask
[Esmaeilpouretal.,2022;Mingetal.,2022;Wangetal.,2023].
G.2 Evaluationmetrics
WecompareourmethodwiththebaselinemethodsusingthemetricsthatarecommonlyemployedforOOD
detectiontasks. AUROCdenotesareaunderthereceiveroperatingcharacteristicwherethereceiveroperating
characteristicrepresentstherelationshipbetweenfalsepositiverate(FPR)andtruepositiverate(TPR)forall
ofthethresholdrange. FPR95denotesthefalsepositiveratewhenthethresholdsatisfies95%TPR.AUCPR
representsareaunderthecurveofprecisionandrecall. Itisausefulperformancemeasure,especiallywithan
imbalanced dataset. For AUCPR, we set the detection threshold to be the value that satisfies 95% TPR. We
considerOODsamplesaspositive.
G.3 HyperparametersearchonCaltech101
7We construct each known-unknown class split for Caltech101
dataset [Fei-Fei et al., 2004] by randomly sampling 20 classes
as ID, and setting aside the rest as OOD, making a total of 3
splits. Weconductgridsearchoverthefollowinghyperparam-
eter configurations: M 15,10 , N 14,9 , R 7,5 ,
∈ { } ∈ { } ∈ { }
γ 2.0,1.0,0.5 . Weusethenumbersthatevenlydividethe
∈ { }
interval [0,1] into R+1 segments as the values of the Mixup
ratios. For example, when R = 3, the set of Mixup ratios is
0.25,0.5,0.75 . We select the configuration with the highest
{ }
average AUROC score for each method. For the environment
where the model outputs are the logits, the resulting hyperpa-
rameters are M = 15, N = 14, R = 7, and γ = 2 for all
methods. Figure3: AUROCscoresaveragedoverthefive
ForEntropy+MSPlinearcombinationbaseline,wetunethe datasets.
scalingfactorη = b 10a,byconductinggridsearchoverthe
×
following configurations: a 4, 3, 2, 1,0,1,2,3,4 , b 1,2,3,4,5,6,7,8,9 and the score to
∈ {− − − − } ∈ { }
whichηismultiplied(MSPorEntropy).
We conduct hyperparameter search for ASH [Djurisic et al., 2023] over the pruning percentile
p 10,20,30,40,50,60,70,80,90 and 3 treatment methods of unpruned activations, namely, ASH-
∈ { }
P,ASH-B,ASH-S,onCaltech101. ThesameCLIPViT-B/32[Radfordetal.,2021]backboneisemployedfor
zero-shotclassificationandtheentropyscoreisutilizedastheOODscoringfunction.
We conduct hyperparameter search over the DML’s [Zhang and Xiang, 2023] scaling ratio λ
∈
0.01,0.1,1.0,2.0,5.0,10.0,30.0,60.0,100.0,300.0,500.0,1000.0 on the Caltech101 and use the best
{ }
performing value in terms of AUROC when evaluating on the other datasets. The same CLIP ViT-B/32
[Radfordetal.,2021]backboneisutilizedwithoutanyfinetuningonIDsamples.
G.4 AdaptationofMixDiffwithZOC
ZOC[Esmaeilpouretal.,2022]utilizesacandidateOODclassnamegenerator. MixDiffframeworkisapplied
toZOCbyaveragingouteachoftheperturbedimages’candidateOODlogitsasfollows:log(1 C exp(o ))
C i=1 i
whereC ando arethenumberofgeneratedOODclassnamesfromtheimageandthei-thOODclasslogit,
i
P
respectively. Thiseffectivelymeansthatthelogitsintheperturbedoracleandtargetsamples’outputshavea
dimensionofK+1insteadofKinthefollowingequations:O
m∗ir
=f(x ∗mir) ∈RK andO
ir
=f(x ir) ∈RK.
Weevaluateon200randomlychosensamplespersplitasZOC’stokengenerationmodulerequiresalarge
amount of computation to process the entire set of mixed images. Also, the hyperparameters were tuned on
eachofthetargetdatasetstoalleviatevariabilityissues.
G.5 Experimentaldetailsonadversarialdefencetask
We take the same experimental setup as the OOD detection experiments with identical datasets and back-
bonemodel. Weuseprojectedgradientdescent(PGD)attack[Madryetal.,2018]withL normperturbation
bound,adversarialbudgetϵ = 1 andattackstepsizeof10. Weassumeaccesstothem∞ odelparametersfor
255
theattacker,sothatthetruegradientscanbecalculated. FollowingChenetal.[2022a],crossentropywiththe
uniform distribution is used as the loss function when attacking ID samples, and Shannon entropy is used as
thelossfunctionwhenattackingOODsamples. Weusetheotheroraclesamplesthatareofthesameclassas
thepredictedlabelofthetargetasauxiliarysamples, referredtoasoracleasauxiliaryinthemainpaper. We
usethesamehyperparametersthatarefoundinOODdetectiontaskwithoutseparatehyperparametertuningon
adversarialdefencetask. Figure4showsAUROCscoresforvariousattackstepsizes.
880 Entropy
MixDiff+Entropy
MixDiffOnly
60
40
20
0
0 20 40 60 80 100
AttackStepSize
(a)BothIDandOODsamplesareattacked.
80 Entropy
MixDiff+Entropy
MixDiffOnly
60
40
20
0
0 20 40 60 80 100
AttackStepSize
(b)IDsamplesareattacked.
80 Entropy
MixDiff+Entropy
MixDiffOnly
60
40
20
0
0 20 40 60 80 100
AttackStepSize
(c)OODsamplesareattacked.
Figure 4: AUROC scores for various attack step sizes on CIFAR100. (a) Both ID and OOD samples are adversarially
attacked.(b)IDsamplesareadversariallyattacked.(c)OODsamplesareadversariallyattacked.
9
CORUA
CORUA
CORUAG.6 Experimentaldetailsonout-of-scopedetectiontask
We run out-of-scope detection experiments using 4 intent classification datasets. CLINC150 [Larson et
al., 2019] dataset is consisted of samples spanning across 10 general domains including "utility" and
"travel",witheachsamplebelongingtooneof150intentclasses. Banking77[Casanuevaetal.,2020]isa
datasetspecializinginbankingdomainandhas77intentclasses. ACID[AcharyaandFung,2020]isanintent
detectiondatasetwith175intents,consistedofsamplesofcustomerscontactinganinsurancecompany. TOP
[Guptaetal.,2018]isadatasetwiththeintentsorganizedinahierarchicalstructureandisconsistedofqueries
relatedtonavigationandevent. ForTOPdataset,weusetherootnode’sintentastheintentlabelforthequery,
asinYilmazandToraman[2022].
For CLINC150 and TOP datasets, we keep the original OOS intents in the OOS split. More
specifically, CLINC150 dataset’s "oos" class and TOP dataset’s intent classes that are prefixed with
"IN:UNSUPPORTED" [Yilmaz and Toraman, 2022]. We also set aside 4 intents in TOP dataset that have
too small number of samples to be reliably split into train and validation sets as OOS intents. These in-
tents are "IN:GET EVENT ATTENDEE", "IN:UNINTELLIGIBLE", "IN:GET EVENT ORGANIZER",
and"IN:GET EVENT ATTENDEE AMOUNT".Thisleavesthedatasetwith12originalin-scopeintentclasses,
excludingtheOOSintentclasses.
Wefurthersplitthetrainsetofthein-scopesamplesintomorein-scope,OOSsplitsandusethesetosearch
MixDiff’s hyperparameters. To assume an environment where the test time in-scope ratio is unknown, we
evaluate OOSdetection performanceon multiple innerin-scope ratios, 25%, 50%, 75%, for eachinner split.
Weleaveoutthesplitswiththenumberofinnerin-scopeintentslessthan2. Anintentclassificationmodelis
trainedforeachoftheseinnerin-scopesplits. Aftertraining,weperformOOSdetectionontheouterin-scope
validationsetandselectthehyperparametersetwiththehighestaverageAUROCscore.
Foragivenoraclesample,weusetheotheroraclesamplesinthesameclassastheauxiliarysamples. For
easeofcomparisonbetweenthelogit-basedandprobability-basedOODscoringfunctions, wetakethesetup
wherethemodelf()’soutputsareinthelogitspaceforbothcases.
·
Weexplorethreeconfigurationswithrespecttothepositionoftheauxiliarysampleinaconcatenatedtext
pair: (1) prepending the auxiliary sample at the front of an oracle or the target sample; (2) appending the
auxiliarysampleattheendofanoracleorthetargetsample;(3)acombinationofboth,analogoustothesetting
of2MixupratiosinimageMixup(R=2). Weconductgridsearchoverthefollowinghyperparameters: M
∈
5,10,15,20,25,30 , γ 0.5,1.0,2.0 , and three auxiliary sample concatenation methods as described
{ } ∈ { }
above. We note that the number of auxiliary samples is determined as N = M 1, since we use the other
−
oracle samples in the same class as the auxiliary samples. We provide the average AUROC scores for each
in-scoreratioinTable1.
10Method In-scoperatio CLINC150 Banking77 ACID TOP Average
25% 93.07 1.8 84.29 3.7 89.39 1.6 93.68 4.5 90.11
± ± ± ±
50% 93.26 0.6 85.80 3.2 88.61 1.3 88.90 5.2 89.14
MSP[HendrycksandGimpel,2017] ± ± ± ±
75% 92.74 0.8 86.20 3.6 88.93 1.8 87.44 7.0 88.83
± ± ± ±
Avg. 93.02 85.43 88.98 90.01 89.36
25% 93.06 2.0 83.01 3.8 88.96 1.4 93.10 4.5 89.53
± ± ± ±
50% 93.77 0.6 85.63 3.2 88.77 1.0 88.30 6.2 89.12
MLS[Hendrycksetal.,2022] ± ± ± ±
75% 93.85 0.8 86.43 3.8 89.00 1.5 88.77 6.1 89.51
± ± ± ±
Avg. 93.56 85.02 88.91 90.06 89.39
25% 93.09 2.1 82.96 3.8 88.87 1.4 93.10 4.5 89.51
± ± ± ±
50% 93.82 0.6 85.64 3.2 88.70 1.0 88.30 6.2 89.12
Energy[Liuetal.,2020] ± ± ± ±
75% 93.91 0.8 86.36 3.8 88.93 1.5 88.78 6.1 89.50
± ± ± ±
Avg. 93.61 84.99 88.83 90.06 89.37
25% 93.23 1.8 84.28 3.8 89.27 1.6 93.68 4.5 90.12
± ± ± ±
50% 93.52 0.6 86.02 3.3 88.53 1.2 88.91 5.2 89.25
Entropy[Thulasidasanetal.,2021] ± ± ± ±
75% 93.11 0.8 86.48 3.8 88.81 1.7 87.46 7.0 88.97
± ± ± ±
Avg. 93.29 85.59 88.87 90.02 89.44
25% 93.57 1.7 84.77 3.6 89.66 1.6 93.68 4.6 90.42
± ± ± ±
50% 93.57 0.6 86.11 3.0 88.77 1.2 89.65 4,6 89.53
MixDiff+MSP ± ± ± ±
75% 93.12 0.8 86.36 3.4 89.10 1.6 88.71 6.1 89.32
± ± ± ±
Avg. 93.42 85.75 89.18 90.68 89.76
25% 93.57 2.0 83.56 3.7 89.37 1.4 93.16 4.4 89.92
± ± ± ±
50% 94.02 0.6 86.02 3.3 89.01 1.0 88.84 5.8 89.47
MixDiff+MLS ± ± ± ±
75% 94.04 0.7 86.81 3.6 89.33 1.3 89.04 6.0 89.81
± ± ± ±
Avg. 93.88 85.46 89.24 90.35 89.73
25% 93.59 2.0 83.51 3.7 89.28 1.4 93.17 4.4 89.89
± ± ± ±
50% 94.01 0.6 86.27 2.9 88.95 1.0 88.83 5.8 89.52
MixDiff+Energy ± ± ± ±
75% 94.07 0.8 86.74 3.7 89.32 1.3 89.05 6.0 89.80
± ± ± ±
Avg. 93.89 85.51 89.18 90.35 89.73
25% 93.70 1.7 84.79 3.7 89.55 1.6 93.70 4.5 90.44
± ± ± ±
50% 93.84 0.6 86.42 3.1 88.74 1.2 89.65 4.7 89.66
MixDiff+Entropy ± ± ± ±
75% 93.48 0.8 86.74 3.6 89.09 1.5 88.68 6.2 89.50
± ± ± ±
Avg. 93.67 85.98 89.13 90.68 89.87
Table1: AverageAUROCscoresforout-of-scopedetectiontask. Thenumbersontherightsideof representstandard
±
deviation. Thenumbersinthe”Average”columnaretheaverageAUROCscoresreportedinthatrow. Thenumbersina
”Avg.”rowaretheaverageoftheAUROCscoresreportedinthatcolumn.ThehighestandsecondhighestaverageAUROC
scoresarehighlightedwithboldandunderline,respectively.
H Performance evaluation with AUCPR and FPR95
Table 2 presents a comprehensive performance analysis of MixDiff in relation to other baselines, utilizing
commonly employed metrics for OOD detection studies. Our findings show that MixDiff can boost OOD
detectionperformanceinFPR95andAUCPRaswellasAUROC.
11Method Training-free AUROC( ) FPR95( ) AUCPR( )
↑ ↓ ↑
ZOC † ✗ 82.7 2.8 64.0 6.9 94.1 1.0
± ± ±
MixDiff+ZOC † ✗ 82.8 2.4 65.2 12.0 95.0 0.7
± ± ±
MSP ✓ 78.2 3.1 60.4 5.3 91.4 1.9
± ± ±
MLS ✓ 80.0 3.1 62.3 5.2 92.9 1.6
± ± ±
Energy ✓ 77.6 3.7 65.4 4.2 91.9 1.9
± ± ±
Entropy ✓ 79.9 2.5 58.8 5.2 92.0 1.7
± ± ±
MixDiff+MSP ✓ 80.1 2.8 60.1 4.8 92.3 1.5
± ± ±
MixDiff+MLS ✓ 80.5 2.2 62.5 4.1 92.9 1.2
± ± ±
MixDiff+Energy ✓ 78.3 2.7 65.9 3.4 92.1 1.4
± ± ±
MixDiff+Entropy ✓ 81.0 2.6 58.4 4.8 92.6 1.5
± ± ±
Table2:Performancecomparisonwithvariousmetrics.
I Comparison with other OOD scoring functions
WedividetheMSPscoreintofiveintervalsofthesamelengthandplotthedifferenceoftheaveragescoresof
OODandIDsamplesinthesameinterval. WealsoplotthedifferenceoftheaverageMixDiffscoresofOOD
andIDsamplesbelongingtothesameMSPscoreinterval.Figure5showsthatforsimilarvaluesofMSPscore,
theuncertaintyscorefromMixDiffamongtheOODsamplesissignificantlyhigherthanthatoftheIDsamples.
Thisdemonstratesthat,evenwhentwoID,OODsamples’MSPscoresarealmostidentical,theMixDiffscores
canstillprovideadiscriminativeedge.
(a) (b)
Figure5:DifferencebetweentheaverageuncertaintyscoresofOODandIDsamplesbelongingtoagivenintervalofMSP
score.Thex-axisrepresentstheaverageMSPscoreoftheinterval.(a)Intervalsunderthethresholdwiththethresholdset
byTPR95ofMSP.(a)IntervalsoverthethresholdwiththethresholdsetbyTPR95ofMSP.
To validate whether MixDiff scores have extra information which is not captured by existing other OOD
scores,wecalculatepair-wisecorrelationamongOODscoresinFigure5a,andevaluatetheerrorrateofOOD
detectionbyeachOODscoreinFigure5b.
AsshowninFigure6a,MixDiffscoresexhibitaweakercorrelationwithotherOODscores,whichimplies
that MixDiff scores contain additional information that is absent in other scores. Consequently, MixDiff can
correctcertainwrongdecisionsofexistingmethods(verifiedinFigure6b),whenadoptedwiththemtogether.
Theseresultssuggestthattheperturb-and-compareapproachishelpfulforstableOODdetectionandMixDiff
effectivelyprovidessuchanadvantage. AllresultsfromthissubsectionarederivedfromCIFAR100testset.
12(a) (b)
Figure6: (a)PearsoncorrelationbetweenthescoresofdifferentOODscoringfunctions. (b)ErrorrateatTPR95foreach
method.Formultiplemethods,errormeansbothwereincorrect.
J Computational cost analysis
Figure 7 shows AUROC scores of MixDiff+Entropy for various values R and N evaluated on CIFAR100.
MixDiffstartstooutperformtheentropyscorewithonlytwoadditionalforwardpasses(N = 2,R = 1). The
modeloutputsfromf()arepredictionprobabilities,thenumberoforaclesamples,M,isfixedat15andthe
·
scalingfactorγ istunedonCaltech101.
81.5
81
80.5
80
79.5
7
5
R 3 5 8 11 14
1 1 2
N
Figure7: AUROCscoresofMixDiff+EntropywithvaryingvaluesofN andR(top). AUROCscoreofEntropy(bottom).
BothmethodsareevaluatedonCIFAR100.
K Processing time analysis
Weanalyzetheaveragetimerequiredtoprocessonetargetsample. Target-sideperturbedsamplesprocessedin
asinglebatch. Wefixthenumberoforaclesamples,M,to15andusetheotheroraclesamplesastheauxiliary
samples(N=14). Thisisthesameastheoracleasauxiliarysetupintheablationstudiesportionofthemain
paper. Weprecomputetheoracle-sideperturbedsamples. Figure8depictstheaverageprocessingtimeagainst
13
CORUAthenumberofMixupratios,R. Thestagnantincreaseinprocessingtimecontrastedwiththerapidincreasein
performanceatsmallvaluesofRindicatesthattheadditionalperturbedsamplescanbeeffectivelyprocessed
in parallel, so that MixDiff’s effectiveness can be exploited without incurring a prohibitive processing time.
When we allow multiple target samples to be batched together, MixDiff’s processing time further decreases
(MixDiffBS=100). ExperimentsareperformedwithNVIDIARTXA600048GB.
82
MixDiffBS=1 W/MixDiff
40
MixDiffBS=100 W/oMixDiff
81.5
EntropyBS=1
30
81
20
80.5
10
80
0 79.5
1 2 3 4 5 6 7
NumberofMixupRatios(R)
Figure8: Bluelinesrepresenttheaverageprocessingtimepertargetsample. BSdenotesthebatchsizeoftargetsamples.
RedlinesrepresentAUROCscoresofMixDiff+EntropyandentropyOODscoringfunctionevaluatedonCIFAR100.
L Sensitivity analysis
Figures 9a and 9b show the changes in AUROC score on the CIFAR100 dataset in regard to the number of
oracle samples, M, and the number of Mixup ratios, R, respectively. We fix the other hyperparameters and
only vary M or R. MixDiff starts to enhance the detection performance of base scores with small values of
M orR,afterwhichtheperformancegainremainsrelativelystable. ForallOODscoringfunctions,logitsare
usedasthemodelf()’soutputswhencomputingperturbedoracles’OODscores.
·
(a) (b)
Figure9: (a)Performancechangeinregardtothenumberoforaclesamples,M. (b)Performancechangeinregardtothe
numberofMixupratios,R.
14
)sdnocesilliM(emiTgnissecorP
CORUAM Performance evaluation with other backbones
We evaluate MixDiff’s performance with various CLIP backbones and report the results in Table 3. We also
reporttheclassificationaccuracyofeachclassifierontheIDtestset. MixDiffconsistentlyimprovesthedetec-
tionperformanceofthebasescore. AverageAUROCscoresoverthefivedatasetsarereported,andoracleas
auxiliarysetupisusedforauxiliarysampleselection. Predictionprobabilitiesareusedasmodeloutputs.
AverageAUROC
CLIPBackbone ClassificationAcc.
Entropy MixDiff+Entropy
RN50 80.17 81.05 73.36
RN50x4 82.12 83.23 78.20
VIT-B/32 89.11 89.88 87.73
ViT-L/14 93.40 94.19 92.59
Table3:PerformanceevaluationwithvariousCLIPbackbones.
N Performance evaluation under varying misclassification rates
WeconstructtheIDsetssuchthatitwouldcontainaspecificpercentageofmisclassifiedsamplesandevaluate
MixDiff’sperformanceonvariousmisclassificationrates. Table4showsthatMixDiffexhibitssignificantim-
provementsover thebaselinewhen thepercentageof misclassified samplesishigh. Average AUROCscores
overthefivedatasetsarereported,andrandomIDsamplesareusedasauxiliarysamples. Predictionprobabili-
tiesareusedasmodeloutputs.
Misclassificationrate Entropy MixDiff+Entropy
100% 65.24 72.06
75% 72.10 77.76
50% 78.98 83.50
25% 85.70 89.09
0% 89.11 89.69
Table4:Performanceundervaryingmisclassificationrates.
O Reproducibility
Wemakeourcodepubliclyavailableathttps://github.com/hy18284/mixdiff.
P Qualitative analysis
P.1 OODscoredensitycurves
Figure 10 plots the distributions of the base OOD scores with and without MixDiff. Table 5 shows the area
under the distribution curves of in-distribution (ID) and out-of-distribution (OOD) samples separated by the
threshold(setbyFPR95)foreachapproach. MixDiffscoresalleviateoverlapofIDandOODsamples’OOD
scores. In Table 5, we observe that adding MixDiff scores increases the area of the ID samples’ distribution
underthethresholdanddecreasestheareaofIDsamples’distributionoverthethreshold. ForallOODscoring
functions,logitsareusedasthemodelf()’soutputswhencomputingperturbedoracles’OODscores.
·
15Figure 10: Visualizations of distributions of the OOD scores with kernel density estimate plot. The red vertical lines
represent95%TPRthresholds.
MSP MixDiff+MSP MLS MixDiff+MLS Energy MixDiff+Energy Entropy MixDiff+Entropy ZOC MixDiff+ZOC
Threshold(95%TPR) -0.938 -1.007 -28.44 -29.42 -0.287 -0.297 0.358 0.071 0.604 0.598
IDoverthreshold( ) 0.688 0.663 0.667 0.625 0.684 0.645 0.656 0.628 0.731 0.725
↓
IDunderthreshold( ) 0.296 0.322 0.322 0.360 0.304 0.340 0.331 0.358 0.263 0.268
↑
OODoverthreshold 0.949 0.950 0.947 0.947 0.945 0.947 0.938 0.947 0.947 0.949
OODunderthreshold 0.048 0.047 0.050 0.049 0.051 0.048 0.060 0.050 0.051 0.049
Table5: TheintegralofdensitycurvesfromFigure10dividedby95%TPRthreshold. indicateslowerisbetterand
↓ ↑
indicateshigherisbetter.
P.2 Logitvisualizations
To see the effect of MixDiff in the logit level, we plot the logits of the target, oracle, and the corresponding
mixedsamplesinFigure11. ForallOODscoringfunctions,logitsareusedasthemodelf()’soutputswhen
·
computingperturbedoracles’OODscores.
16(a)MixDiff+MSP
(b)MixDiff+MLS
(c)MixDiff+Energy
(d)MixDiff+Entropy
Figure11: Logitlevelchangesaftermixingidenticalauxiliarysampleswithtargetororacle. Thefirstrowoflogitgraphs
inFigures11a-11dshowthateventhoughthereisanOODsamplethatisindistinguishablefromtheoraclesatthelogit
level,thedifferencecouldbecapturedbymixingupwithauxiliarysamples. Thethesecondrowof3DgraphsinFigures
11a-11dshowlogitsoftheIDsamplewhoseclassisthesameastheoraclesamples. Thetwographstotherightofeach
logitgraphshowtheOODscoresandthresholdsforthebaseOODscorefunctionwithandwithoutMixDifffortheOOD
andIDtargetsamples,respectively.
17References
Shailesh Acharya and Glenn Fung. Using optimal embeddings to learn new intents with few examples: An
applicationintheinsurancedomain. InConverse@KDD,2020.
In˜igoCasanueva,TadasTemcinas,DanielaGerz,MatthewHenderson,andIvanVulic.Efficientintentdetection
withdualsentenceencoders.InProceedingsofthe2ndWorkshoponNLPforConvAI-ACL2020,mar2020.
Dataavailableathttps://github.com/PolyAI-LDN/task-specific-datasets.
Jiefeng Chen, Yixuan Li, Xi Wu, Yingyu Liang, and Somesh Jha. Robust out-of-distribution detection for
neuralnetworks. InTheAAAI-22WorkshoponAdversarialMachineLearningandBeyond,2022.
PeijieChen,QiLi,SaadBiaz,TrungBui,andAnhNguyen. gscorecam: Whatobjectsiscliplookingat? In
ProceedingsoftheAsianConferenceonComputerVision(ACCV),pages1959–1975,December2022.
AndrijaDjurisic, NebojsaBozanic, ArjunAshok, andRosanneLiu. Extremelysimpleactivationshapingfor
out-of-distributiondetection. InTheEleventhInternationalConferenceonLearningRepresentations,2023.
Sepideh Esmaeilpour, Bing Liu, Eric Robertson, and Lei Shu. Zero-shot out-of-distribution detection based
onthepre-trainedmodelclip. InProceedingsoftheAAAIconferenceonartificialintelligence,volume36,
pages6568–6576,2022.
LiFei-Fei,RobFergus,andPietroPerona. Learninggenerativevisualmodelsfromfewtrainingexamples: An
incrementalbayesianapproachtestedon101objectcategories. In2004conferenceoncomputervisionand
patternrecognitionworkshop,pages178–178.IEEE,2004.
SonalGupta, RushinShah, MrinalMohit, AnujKumar, andMikeLewis. Semanticparsingfortaskoriented
dialogusinghierarchicalrepresentations. InProceedingsofthe2018ConferenceonEmpiricalMethodsin
NaturalLanguageProcessing,pages2787–2792,Brussels,Belgium,October-November2018.Association
forComputationalLinguistics.
DanHendrycksandKevinGimpel. Abaselinefordetectingmisclassifiedandout-of-distributionexamplesin
neuralnetworks. InInternationalConferenceonLearningRepresentations,2017.
DanHendrycks,StevenBasart,MantasMazeika,MohammadrezaMostajabi,JacobSteinhardt,andDawnXi-
aodongSong. Scalingout-of-distributiondetectionforreal-worldsettings. InInternationalConferenceon
MachineLearning,2022.
AlexKrizhevsky,GeoffreyHinton,etal. Learningmultiplelayersoffeaturesfromtinyimages. 2009.
StefanLarson,AnishMahendran,JosephJ.Peper,ChristopherClarke,AndrewLee,ParkerHill,JonathanK.
Kummerfeld, Kevin Leach, Michael A. Laurenzano, Lingjia Tang, and Jason Mars. An evaluation dataset
for intent classification and out-of-scope prediction. In Proceedings of the 2019 Conference on Empiri-
cal Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-
guageProcessing(EMNLP-IJCNLP),pages1311–1316, HongKong, China, November2019.Association
forComputationalLinguistics.
YaLeandXuanYang. Tinyimagenetvisualrecognitionchallenge. CS231N,7(7):3,2015.
Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Ad-
vancesinNeuralInformationProcessingSystems,33:21464–21475,2020.
AleksanderMadry,AleksandarMakelov,LudwigSchmidt,DimitrisTsipras,andAdrianVladu. Towardsdeep
learningmodelsresistanttoadversarialattacks. InInternationalConferenceonLearningRepresentations,
2018.
18Dimity Miller, Niko Sunderhauf, Michael Milford, and Feras Dayoub. Class anchor clustering: A loss for
distance-basedopensetrecognition. InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsof
ComputerVision,pages3570–3578,2021.
YifeiMing,ZiyangCai,JiuxiangGu,YiyouSun,WeiLi,andYixuanLi.Delvingintoout-of-distributiondetec-
tionwithvision-languagerepresentations. AdvancesinNeuralInformationProcessingSystems,35:35087–
35102,2022.
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-
try, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural
languagesupervision. InInternationalConferenceonMachineLearning,pages8748–8763.PMLR,2021.
Sunil Thulasidasan, Sushil Thapa, Sayera Dhaubhadel, Gopinath Chennupati, Tanmoy Bhattacharya, and
Jeff A. Bilmes. An effective baseline for robustness to distributional shift. 2021 20th IEEE International
ConferenceonMachineLearningandApplications(ICMLA),pages278–285,2021.
Hualiang Wang, Yi Li, Huifeng Yao, and Xiaomeng Li. Clipn for zero-shot ood detection: Teaching clip to
sayno. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision,pages1802–1812,
2023.
EyupYilmazandCagriToraman. D2U:Distance-to-uniformlearningforout-of-scopedetection. InProceed-
ingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguis-
tics: Human Language Technologies, pages 2093–2108, Seattle, United States, July 2022. Association for
ComputationalLinguistics.
ZihanZhangandXiangXiang. Decouplingmaxlogitforout-of-distributiondetection. InProceedingsofthe
IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),pages3388–3397,June2023.
19