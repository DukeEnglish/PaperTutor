A Graph-based Approach to Human Activity
Recognition
Thomas Peroutka∗, Ilir Murturi∗ , Praveen Kumar Donta† , and Schahram Dustdar∗
∗Distributed Systems Group, TU Wien, Vienna 1040, Austria.
†Department of Computer and Systems Sciences, Stockholm University, Stockholm 16425, Sweden.
Abstract—Advancedwearablesensordeviceshaveenabledthe extensive studies in multiple areas, such as 3D Convolutional
recording of vast amounts of movement data from individuals Neural Networks (CNN) for HAR. Ji et al. [7] demonstrated
regarding their physical activities. This data offers valuable
how image-based activity recognition is possible. In contrast,
insightsthatenhanceourunderstandingofhowphysicalactivities
Biaetal.[8]showcaseshowawearablesensorandaCNNcan
contributetoimprovedphysicalhealthandoverallqualityoflife.
Consequently, there is a growing need for efficient methods to detect human activity like walking, sitting, or climbing stairs.
extractsignificantinsightsfromtheserapidlyexpandingreal-time Another approach is a statistical analysis of given data and
datasets.Thispaperpresentsamethodologytoefficientlyextract trying to classify the activities [9]. The current research aims
substantial insights from these expanding datasets, focusing on
to interpret datasets without prior knowledge, meaning that
professional sports but applicable to various human activities.
they do not describe what movements look like to the system.
By utilizing data from Inertial Measurement Units (IMU) and
Global Navigation Satellite Systems (GNSS) receivers, athletic Meanwhile, most of these approaches are resource-intensive
performance can be analyzed using directed graphs to encode (using neural networks) or are difficult to set up. Therefore,
knowledgeofcomplexmovements.Ourapproachisdemonstrated ourgoalinthispaperistousedomain-specificknowledge(i.e.,
on biathlon data and detects specific points of interest and anatomy of a movement sequence) obtained by experts (e.g.,
complex movement sequences, facilitating the comparison and
trainers) and encoded into a directed graph to quickly and
analysis of human physical performance.
Index Terms—Human Activity Recognition, IoT, GNSS, reliably detect motion sequences (i.e., movements). Further-
Graphs more, we emphasize using existing algorithms, which make
analyzing big datasets efficient and resource-friendly. Never-
I. INTRODUCTION theless, our approach is limited to human activity recognition;
however, it can also be used in any time data series.
Throughouthumanevolution,ourbodiesandbrainslearned
Inthispaper,weproposeanapproachthataimstorepresent
the ever-increasing motion complexity. Even decades into
complex athletes’ movements as a directed graph. The goal is
the computer and machine-powered area, it is still hard for
to find an efficient method for identifying critical points in a
machines to solve supposedly easy tasks like manipulating a
multi-sensor dataset and detecting complex movements. This
Rubik’s cube [1]. This means humans and all living things
approach is versatile and can be applied to any movement.
have the unique ability to move their bodies accurately and
For illustration, we will focus on biathlon, a demanding sport
efficiently. With more and more wearable sensors available,
that combines two very different activities: fast skiing on
such movements can be measured precisely and gain insights
various terrains and precise target shooting while stationary.
into efficiency. The wearable technology market is predicted
Speed is crucial in biathlon, so finding the most effective and
to grow at a compound annual growth rate of 14.6% from
efficientbodymovementtechniquesisessential.Thisinvolves
2023 to 2030 [2]. This includes using standard hardware like
determining the best approach for uphill, flat, or downhill
”Cardiovascular Monitoring Using Earphones and a Mobile
sectionsandmaximizingshootingaccuracy.Moreover,weaim
Device” [3] or ”A Wearable Sensor for Measuring Sweat
to identify a data structure capable of capturing body move-
Rate” [4]. There are even sensors that act as little radar to
ments and developing an algorithm that can efficiently detect
detect human activities based on millimeter-waves [5]. All
thesemovementsusingmultiplewearablesensors.Ultimately,
these sensors generate a large amount of data with a common
we will obtain performance indicators specific to different
objective: detecting physical activities and extracting insights.
movementsthatcanbecomparedwithothers.Thiswillenable
ThisfieldofstudyisknownasHumanActivity/ActionRecog-
professional athletes, sports enthusiasts, and rehabilitation
nition (HAR) [6].
patients to enhance their physical movements. Note that this
The HAR field researches how to identify and understand
work focuses on the technological challenges associated with
human activities using technology. Despite the progress made
detecting user-defined motion sequences, and any sports sci-
in this field, crucial aspects should be addressed to signifi-
ence insights provided in this article are purely for illustrative
cantly transform how individuals interact with mobile devices
purposes and may not be scientifically grounded.
and other devices. In the last few years, there have been
The remaining sections are structured as follows. A moti-
vation example and related work are presented in Section II.
Section III presents the proposed approach and an example
4202
guA
91
]ES.sc[
1v19101.8042:viXrato illustrate how to represent a sequence of movements in a Contrary to the above-mentioned works, our approach fo-
directedgraph.EvaluationresultsarediscussedinSectionIV. cuses on the most common way to use inertial sensors in
Lastly,weconcludeourdiscussionwithpossiblefutureactions wearable devices. The majority of research is concerned with
in Section V. classification, but very little is done in extracting more than
just classes from datasets. Therefore, we aim to take it a
II. MOTIVATIONANDRELATEDWORK stepfurtherandnotonlyclassifyactivities(e.g.,smartwatches
or smartphones classify human activities [18]) but also be
A. Motivation Scenario
able to extract user-defined performance metrics like forces
Understanding and improving athlete performance is criti-
applied to the body during certain tasks, etc. Our proposed
cal in professional sports (i.e., especially in disciplines like
approach requires domain-specific knowledge, requiring an
biathlon). Biathlon combines cross-country skiing and rifle
understandingofhowtobreakdownacomplexmovementinto
shooting, demanding peak physical condition and precision.
key points. In contrast to other research works, our proposed
Coaches and sports researchers constantly seek new methods
graph-based method combined with domain-specific knowl-
to analyze and optimize the performance of athletes. Imagine
edge enables complex movement detection in a resource-
a biathlon team preparing for the winter sports. The team’s
efficientmanner.Furthermore,ourapproachgeneratesexplain-
performance analytics division provides detailed insights into
able results (meaning it is possible to reason (i.e., results
each athlete’s performance to identify strengths and areas for
are traceable and how they were calculated), which most
improvement.
approaches, especially ones using neural networks, lack. The
Analyzing transitions between race stages helps to identify advantages of our approach arise from the combination of a
athlete delays and fatigue signs (e.g., observing how athletes strict rule set driven by domain-specific knowledge and the
managetheshiftfromstartingtotacklingtheuphillchallenge, expressive capabilities of graphs. This unique combination
and then from the uphill to the shooting range). Traditional provides key benefits to our approach.
performance analysis methods are time-consuming and often
lack the granularity to make such fine-tuned adjustments. III. THEPROPOSEDAPPROACH
Using IMUs and GNSS receivers, the responsible team can
A. An overview of the approach
collect detailed movement data from athletes during training
In Figure 1, we outline the concept of the proposed ap-
and competitions. Directed graphs allow encoding complex
proach. The first step is to break down a specific movement
movement sequences, which in return allows the team to (i)
into smaller parts that make up the movement. This is done
capture detailed movement patterns, (ii) identify possible per-
with the help of an expert (i.e., typically trainers or sports
formance bottlenecks, (iii) optimize training, or (iv) compare
scientists). This step, e.g., includes trainers setting up virtual
athlete performances.
gates on a map or defining triggers for acceleration data.
B. Related Work The temporal dependency between those parts is encoded
into a directed graph. Movements are recorded with wearable
HAR is a rapidly evolving field with various approaches
devices featuring many sensors (e.g., IMU, GNSS, heart rate
to tracking and interpreting human actions [10]. A common
sensor, etc.). The data is then processed by our proposed
methodology involves analyzing images and videos to detect
approach (i.e., described in the next sections) and trainers
and extract human figures and their movements [11]–[13].
receive insights about the movements of interest.
The authors present a real-time system for 3D human pose
estimation, tracking, and recognition from RGB-D video se-
quences using a generative structured framework. Kaya et al.
[14] proposed a new 1D-CNN-based deep learning approach
forsensor-basedHARusingrawaccelerometerandgyroscope
data. The proposed work showed the impact of using individ-
ual sensor data versus combined data while finding that the
modelperformedbetterwithconcurrentsensordata.Liuetal.
[15] applied the Bayesian structural time series framework to
biomedical sensor data, demonstrating its ability to accurately
assessthesignificanceofhealthinterventionswhileaccounting
for complex covariate structures. The developed tool called Fig. 1: An overview of the proposed approach.
MhealthCIprocessesandregistersdiversebiomedicaldatafor
personalizedmedicine applications.Kumaretal. [16]propose
B. Encoding complex movements into a directed graph
a novel Deep-HAR model that combines CNNs for feature
extraction and Recurrent Neural Networks (RNNs) for pattern Biathlon and any other movements can be modeled as
recognitionintime-seriesdata.Onthecontrarytotheseworks, sections of movement that can be divided into smaller and
the innovative technique utilizes WiFi technology to ascertain smaller subsections. The macro-view (see Figure 2) tells us
humanpresencewithouttheneedforcamerasorsensors[17]. the shooting sequence consists of entering the shooting rangeDependencies:
S →UE (Start to entering uphill)
UE →UL (Entering uphill to exiting uphill)
UL→RE (Exiting uphill to entering shooting range)
UL→F (Exiting uphill to finish line)
RE →RL (Entering shooting range to leaving shooting r.)
Fig. 2: A typical biathlon racetrack layout.
RE →SS (Entering shooting range to start shooting)
SS →SF (Start shooting to finish shooting)
SF →RL (Finish shooting to leaving shooting range)
RL→P (Leaving shooting range to penalty round)
P →P (Penalty round to another penalty round)
P →UE (Penalty round to entering uphill)
Those dependencies can be placed into one of the most
common and well-studied data structures in computer science
known as graphs [19]. In this case, directed graphs will be
utilizedtoencodethetemporaldependencies.Adirectedgraph
Fig. 3: Acceleration data from an uphill section.
is defined as an ordered pair G=(V,E) where
• V is a set whose elements are called vertices or nodes.
The representations will be used to depict actions or
followed by a shooting period and ending by exiting the
points of interest, such as reaching a specific speed or
shooting range and starting running the uphill section. If the
experiencing acceleration in a particular direction.
uphillsectionisdividedintomultiplesubsections,theanalysis
can be done at a micro level (refer to Figure 3). It shows • E is a set of ordered pairs of vertices called directed
edges. The representations will be used to illustrate the
the precise sequence of motion to complete one uphill step.
temporaldependenciesofthepointsofinterestmentioned
First, the arms of the athletes are moved forward, then the
in the example with macro and micro-views in biathlon.
upper body leans forward, and the feet follow. This sequence
alwayshappensinthesameorderbutwithdifferentforcesand
duration.Suchinsightgainedrepresentstheknowledgeofthis
movement and should be encoded in a directed graph.
Afterabriefanalysisofmotioninbiathlon,thesequenceof
movements and their temporal dependency emerge as perfect
properties for describing motion sequences. The simplest
movement consists of two actions (i.e., referred to as points
of interest) and can be noted as A → B, which means A is
a condition for B (or simply said, A needs to happen before
B).Takingtheexamplefromabove,onecanwriteUE →UL
whereUE =uphillenterandUL=uphillleave/exit,meaning
that exiting the uphill section could only happen after the
uphill section was entered in the first place. This way, all Fig. 4: Macro-view of biathlon. Turning sequence of events
temporal dependencies are simply defined as: into a directed graph.
Definitions:
Nodes represent specific points of interest, like entering
S Start
or exiting an area or the start of a specific movement. The
UE Enter uphill
directed edges encode the order depending on time. In this
UL Exit/leave uphill
manner, any sequence and, thus, any kind of human activity
P Penalty round
can be encoded into a data structure well understood by
F Finish
computers.
RE Enter shooting range
SS Start shooting C. Detection of points of interest in multi-sensor datasets
SF Finish shooting Withdatasetsconsistingofmillionsofdatapoints,itisvery
RL Leave/exit shooting range inefficient to analyze each data point. The goal is to identifyspecific points in time that signal the occurrence of events
required to detect a more complex motion. Given that most
wearables record data from various sensors, it is important
to develop methods for detecting both generic events and
sensor-specific events. The most common sensor consists of
an inertial measurement unit (IMU) sensor (which delivers
accelerationandangularvelocitydata)andaglobalnavigation
satellite system (GNSS) receiver (which delivers position and
speeddata).Thefollowingtriggersarehelpfultodetectpoints
of interest in big data sets:
1) Generic triggers: Fig. 7: Location-based detection anatomy.
• Edge detection: Falling, rising, or change (both rising
and falling) edge commonly used in signal processing.
Used in devices like oscilloscopes to detect events. The
Fig. 8: Virtual gates track layout.
Fig. 5: Edge detection anatomy.
simplest implementation looks at a specific threshold. and y = bx + d are checked with simple rearranging
Mathematically, this function can be described as: and substitutions if and where those lines intersect. The
(cid:40) complexity increases when considering the geographic
1 x≥threshold
f(x)= coordinate system used in GNSS coordinates. Hence,
0 otherwise
it is essential to consider the model used to represent
• Peak detection: Detects peaks by comparing local min- Earth. The Earth is commonly depicted as an ellipsoid,
ima/maxima with neighboring values. There are many often with the WGS84 model, which is also used by
the Global Positioning System (GPS) [22]. For example,
a simple formula to calculate the distance on a sphere
is the Haversine formula [23]. One can also project the
geographic coordinates to a Cartesian coordinate system
and do calculations as mentioned above, but this only
works for small distances.
To measure a typical biathlon race, location-based detec-
tions, often referred to as virtual gates, are utilized. To better
Fig. 6: Peak detection anatomy. illustrate how the proposed algorithm works, the following
sample data set will be used. The virtual gate S in Figure 8
differentalgorithmstodetectpeaks.Somerelevantexam- marks the start line. Next will be the uphill section consisting
ples are focused on electrocardiography [20], and there of gates 1 and 2. Then, athletes will enter the range enclosed
are even specialized ones [21] on detecting heartbeats. by gates 3 and 4. The shooting section in the range will be
Nevertheless,wewillnotgointodetailsabouttheirinner detected based on the measurement of the speed when lying
workingsasthisisoutofthescopeofthiswork.Notethat down (lower than 1m/s) and getting back up again (higher
generic triggers can be used on any numerical dataset. than 1m/s). Then, for each missed shot out of 5 total shots,
2) Sensor-specific triggers: athletesneedtorunthepenaltyround.So,ifanathletemisses
• Location-based detection: Detects when a line (virtual 2 out of 5, he must do two penalty rounds. Gate number 4 is
gate)iscrossed(intersection),orareasareentered/exited. special in that it marks the beginning/ending of a lap. In total,
Note that sensor-specific triggers can only be used on six laps were done. Shooting is only done every 2nd lap.
specific datasets.
There are multiple ways to calculate intersections. It Apointofinterest(POI)referstoaspecificmomentintime
depends on the given coordinates. In a Cartesian co- (timestamp) of an event that is being measured. For example,
ordinate system, the two line equations y = ax + c gate 1 will produce a POI each time the athlete crosses theFig. 9: Triggers plotted in chart with speed data (m/s). Fig. 10: All points of interest from start nodes – in our
example, only one.
virtual line. The following notation is used for a POI: S =
t
point of interest S (start) was triggered at timestamp t.
Figure 9 shows all POIs (vertical lines) plotted with athlete
speed in m/s. All POIs are triggered by virtual lines except
start/end shooting. The speed information triggers those. If
Fig. 11: POIs from different nodes used as input alphabet for
athletes move more than 1m/s, it will trigger on the falling
our DFA.
edge (start shooting) or rising edge (end shooting). A closer
look at the first and last POI shows that those are ”wrongly”
start and end shooting triggers because triggers are unaware directed graph, which are start nodes. Furthermore, F ={F}
of any temporal dependency (as previously described). represents all nodes in the directed graph that are finished
nodes.
D. A direct graph to recognize complex movements
Starting points are defined as all points of interest triggered
Up to now, the complex movement of interest is encoded by a start node. Figure 10 shows the POIs of the start node
into a directed graph and points of interest from our dataset. in the biathlon example. The presented Algorithm 1 describes
It is a matter of applying the graph to the points of interest this step.
to recognize our complex movement. In order to accomplish
this, the graph needs to be traversed based on the points of Algorithm 1 Searching for solutions starts at each start node.
interest. This problem can be translated into a Deterministic solutions←[]
Finite Automaton (DFA) to explain this step more clearly. startNodes←[node|node.start==True]
A DFA is described by a five-element tuple (Q,(cid:80) ,δ,q0,F) for all s∈startNodes do
[24]: poi←fetchPointsOfInterestForNode(s)
for all p∈poi do
Q states
sol←findPartialSolution(s,p)
(cid:80)
input alphabet
solutions.append(sol)
δ transition functions
end for
q0 the starting state
end for
F accepting states
return solutions
The standard definition of q0 needs to be modified to The DFA runs until it hits an accepting state, leading to
allowformultiplestartingstates,consideringthepossibilityof ”a partial solution”. A partial solution consists of the taken
having multiple start nodes. A start node is defined as a node paths and timestamps and describes one detected movement.
in our directed graph (as shown in Figure 4) marked with a It is defined as only partial to ensure the detection of all
”start” flag. The following DFA is deduced from our example movements in the dataset. The final or total solution will be
of biathlon: builtinthealgorithm’slaststepandconstructedfrommultiple
partial solutions.
DFA (Q,(cid:88) ,δ,q0,F) After the automaton reaches an accepting state, the path
Biathlon
taken and timestamps will be logged as a partial solution
Firstly, Q = {S,UE,UL,P,RE,RL,SS,SF,F} rep- and then returned. The operation is described in Algorithm 2.
(cid:80)
resents all nodes of the directed graph. Secondly, = Currently, each POI of a specific node is used as input and
{SF ,S ,UE ,UL ,...} represent all points of in- attempts to find a partial solution; however, there are specific
163 175 214 235
terest from Section III-B. Lastly, δ = {S → UE,UE → cases where certain restrictions need to be applied.
UL,UL → RE,UL → F,RE → RL,RE → SS,SS → Inourexample,let’sconsiderthegatelabeledas”S”(start).
SF,SF → RL,RL → P,P → P,P → UE} represent all As shown in the map view of Figure 12, the athlete crossed
edges of the directed graph. To make it more readable, the the virtual start gate S several times before the race started.
notation A → B is used to represent the transition function This might happen during the warm-up phase or the course
δ(A,Bt) = B where A and B represent a state and At inspection. Our approach would take those false triggers and
represents any POI triggered by B. All transition functions build a valid solution. To avoid this scenario, users might
that are not mentioned will have no effect and can be defined specify a minimum or maximum duration for an edge. In this
as δ(Y,Xt) = Y. q0 = {S} represent all nodes in the case,amaximum60-secondrestrictionissetforthepathfromAlgorithm 2 The search for solutions starts at every starting
node.
Function FINDPARTIALSOLUTION(start,point,solution)
solutions←[]
startNodes←[node|node.start==True]
for all s∈startNodes do
poi←fetchPointsOfInterestForNode(s)
for all p∈poi do
sol←findPartialSolution(s,p)
solutions.append(sol)
Fig. 14: Combining partial solutions to form valid total solu-
FINDPARTIALSOLUTION(start,point,solution)
tions.
end for
end for
if len(solutions)==0 and len(solution)>0 then
happen simultaneously. Temporal order must be preserved,
if lastNodeInSolution.finish==True then
and solutions cannot be moved on the time axis. A list of
return [solution]
solutionswillbeobtained,whileasinglesolutionmayconsist
end if
of one or multiple partial solutions. Each partial solution is
end if
also considered a valid solution.
return solutions
F. Find optimal total solution
After identifying all potential solutions, establishing a met-
ric for comparing and ranking them is essential. The specific
metric will vary depending on the particular use case, but
reasonable assumptions can be made to strike a balance
between different approaches. Let’s examine some of these
Fig. 12: Start gate ”S” was triggered multiple times. In this
approaches:
case, only the last start trigger is valid.
1) Maximizenumberofpartialsolutions: Themostobvious
would be maximizing the number of partial solutions in one
solution. Let p be the partial solution of s with index i and
gate S (start) to gate 1 (enter uphill). It is a method to narrow i
n, which is the partial solution in s. The solution s is ranked
down the solution space to only valid solutions according to
by:
training or race rules, reducing space and time complexity.
E. Combine partial solutions to find multiple total solutions (cid:88)n
rankBy(s)= 1
Only connected ones are found in the search for partial
i=0
solutions,indicatingavalidPOIsequencefollowedbyanother
Thedisadvantagewouldbethatmanyshortsolutionswould
sequence.Imagineabreakbetweentwosequences:Onepartial
berankedatthetop.Thisleadstoafragmentedsolutionshown
solution will be found for the first sequence and another for
in Figure 15.
the second sequence.
All partial solutions should be combined in all possible
valid ways. ”Valid” means that overlapping sequences cannot
Fig. 15: Fragmented solution vs. de-fragmented solution.
Fragmented solutions tend to lead to wrong solutions as
false triggers in Section III-C are promoted. This is because
maximizing the number of partial solutions minimizes the
duration covered by each partial solution. The algorithm in
Section III-D produces partial solutions with short coverage
(i.e., especially when false triggers occur). In general, there is
Fig. 13: Five partial solutions displayed by their temporal
no way of determining the ”correct” trigger. It might be the
coverage. Note that each color represents a different partial
firstone,butitcouldalsobethesecondone.Supposemultiple
solution.
solutions have the same number of partial solutions. In thatFig. 16: Two solutions with each two partial solutions but
different total duration.
Fig. 18: OCULUS tracking device mounted on biathlon ath-
lete.
Fig. 17: Last solution will be taken.
case,theresultwillbeanundefinedbehaviorasit’simpossible
to determine the ”best” solution (as shown in Figure 16).
2) Maximize the covered duration: To mitigate a frag-
mented solution, the total duration is maximized and covered
in the solution. The total duration of a solution is the sum of
all durations of partial solutions. Let duration be a function
to calculate the duration (end time – start time), and then the
total duration is the sum of it. The solution s is ranked by:
Fig. 19: Lympik sensor studio for analyzing sensor data.
n
(cid:88)
rankBy(s)= duration(p )
i
Data analytics and visualization were done in Lympik
i=0
SensorStudio1,asoftwareservicethatquicklyanalyzesmulti-
3) Combination: Both approaches will inevitably lead to
sensor data. All functions used in the Studio are easily
non-deterministic behavior as there will be a lot of solutions
reproducible with simple scripts. The test implementation
withthesamenumberofpartialsolutionsorcoveredduration.
was done using Python. The raw binary sensor data was
The best approach is to combine both methods. First, rank for
converted to standard units and signal processing was done
themaximumcovereddurationandthenmaximizethenumber
with Scipy 2. The location-based trigger is based on a simple
of partial solutions(as illustrated in Figure 17).
line intersection in an Euclidean system.
For the detection of POI in our datasets, two kinds of
IV. EVALUATION
triggers are used: Edge detection based on speed (i.e., the
A. Implementation, Testbed, and Dataset threshold was set to 1m/s) for detecting shooting start/finish
and location-based triggers, which were positioned as shown
In this paper, sample data was collected in biathlon by
in Figure 8. The domain-specific knowledge was encoded
a wearable IMU sensor and GNSS receiver. The sensor
into a graph as presented in Figure 4. The resulting POIs
”OCULUS” is made by the Austrian company Lympik1, a
were applied to our DFA as described in Section III-D. The
sports technology company focused on professional sports
path taken was recorded, and each edge was color-coded to
analytics. The accelerometer was configured at 50Hz and
recognize each segment easily. The segmentation is shown in
capableofmeasuringupto16G(i.e.,gravitationalforce).The
a bar chart where the x-axis represents the time axis.
gyroscope was also configured at 50Hz and an upper limit of
2000 degrees per second. The GNSS receiver was configured
B. Experiments and Results
to record at 10Hz in multi-constellation (i.e., GPS, Galileo,
GLONASS)mode,andSatellite-basedAugmentationSystems Our experiments were done with three biathlon athletes.
(SBAS) were also enabled. This experiment aimed to test our approach to handling large
Our test subjects were three professional athletes. The data datasets.Eachdatasetcontainsaround200kGNSSdatapoints
was recorded in the summer when the biathlon was simulated and 500k IMU data points3. The IMU of one tracker was
on special rollers. The wearable was mounted on the athlete configured at 200hz to test different dataset sizes as well.
withaspecialshirtwhiletheriflewascarriedabovethesensor The knowledge of the track was obtained from a professional
to avoid disturbing it while taking it off and picking it up.
2https://scipy.org/
1Lympik,(https://www.lympik.com) 3https://doi.org/10.5281/zenodo.13208678Fig. 20: Athlete A - dataset 191.9k GNSS data points, 503.1k
Fig. 22: Athlete C - dataset 205.5k GNSS data points, 2.1M
IMU data points.
IMU data points.
Dataset Lap Rangetime Shootingtime ShootingZ-accel.
AthleteA 2 57.53s 33.90s 0.33G
AthleteA 4 54.49s 30.80s -0.03G
AthleteB 2 53.47s 29.00s 0.27G
AthleteB 4 46.85s 22.90s -0.07G
AthleteC 2 53.67s 30.60s 0.49G
AthleteC 4 51.11s 28.10s 0.18G
TABLE I: Duration and acceleration measured in shooting
range.
penaltyroundinthefirstshootingandnoneinthe2nd.Results
from Athlete C in Figure 22 show that the athlete missed one
shot each time.
Upon closer examination, the numerical data in Table I
reveals an interesting observation. All athletes show a faster
range time (RE → SS → SF → RL) in the 4th lap than
Fig. 21: Athlete B - dataset 197.6k GNSS data points, 493.7k
the 2nd. Also, the Z-acceleration while shooting is different.
IMU data points.
The easy explanation for this correlation is that in the 2nd lap,
athletes were told to shoot in a lying position while in the
4th, they had to stand. Standing results in a faster range time
trainer and encoded into the graph as described in Section
overall and different acceleration information.
III-B.
Another experiment was to test the penalty round, which
In total, each athlete did six laps. Shooting was done only
marks a special case. In this case, the athlete crosses multiple
every 2nd lap; so, the athletes passed the shooting range
times (i.e., depending on the missed shots) the same line,
without shooting in the 1st, 3rd and 5th. In the 6th and final
and the segmentation still needs to work correctly (i.e., the
lap, the athletes also skipped the shooting range and went to
penalty gate trigger in orange in the line chart). As shown
thefinish.TherawGNSSdataandvirtualgatesarevisualized
in Figure 23, the three vertical lines indicate that the athlete
onamap.ThechartdisplaysthePOIstriggeredbyeachvirtual
crossedthisgatethreetimes.Onecanseethepenaltywasalso
gate,andthebarchartpresentstheoptimalsolutiongenerated
correctly segmented (i.e., the bar chart in pink). The bar chart
by the algorithm.
segmentation aligns perfectly with the line chart representing
All three datasets were correctly segmented and found the the POIs in this example taken from athlete A’s dataset.
optimal solution. Based on each segment, further calculations
C. Discussion, Limitations, and Future Work
weremade,suchascalculatingtheaveragespeedormaximum
forces applied to the athlete. In dataset A (see Figure 20), All results presented in Section IV were calculated on
the bar chart clearly shows the number of penalty rounds the datasets with a few hundred thousand data points within
athlete takes in pink P →P. In the first shooting, the athlete 1-2 milliseconds on a one vCPU machine on the Google
missed two shots and took two penalty rounds, and in the 2nd Cloud Platform with 2GiB of memory. Compared to other
shooting missed one. Athlete B, shown in Figure 21, did one solutions utilizing neural networks (i.e., examples mentionedACKNOWLEDGMENT
This work has been partially supported by the European
Union’s Horizon Europe research and innovation program
under grant agreements No. 101135576 (INTEND) and No.
101070186 (TEADAL).
REFERENCES
Fig. 23: A detailed view of the penalty round. [1] OpenAI,I.Akkaya,M.Andrychowicz,M.Chociej,M.Litwin,B.Mc-
Grew,A.Petron,A.Paino,M.Plappert,G.Powell,R.Ribas,J.Schnei-
der,N.Tezak,J.Tworek,P.Welinder,L.Weng,Q.Yuan,W.Zaremba,
and L. Zhang, “Solving rubik’s cube with a robot hand,” CoRR,
vol.abs/1910.07113,2019.
in the introduction), this method uses well-optimized and
[2] G. V. Research, “Wearable technology market size, share & trends
highly efficient analytic approaches combined with domain- analysisreportbyproduct(head&eyewear,wristwear),byapplication
specific knowledge to detect complex movements in a fast (consumerelectronics,healthcare),byregion(asiapacific,europe),and
segment forecasts, 2023 - 2030.” https://www.grandviewresearch.com/
andresource-efficientway.Therewasnosignificantdifference
industry-analysis/wearable-technology-market,2023.
in processing time between datasets (i.e., dataset C had four [3] M.-Z.Poh,K.Kim,A.Goessling,N.Swenson,andR.Picard,“Cardio-
times more IMU data than the others), further solidifying our vascular monitoring using earphones and a mobile device,” Pervasive
Computing,IEEE,vol.11,pp.1–1,012011.
approach for big datasets. Furthermore, no big datasets for
[4] P. Salvo, F. Di Francesco, D. Costanzo, C. Ferrari, M. Trivella, and
training are needed, and traceability is a further advantage of D. de rossi, “A wearable sensor for measuring sweat rate,” Sensors
the proposed approach. Journal,IEEE,vol.10,pp.1557–1558,112010.
[5] C. Yu, Z. Xu, K. Yan, Y.-R. Chien, S.-H. Fang, and H.-C. Wu,
The limitation of the proposed approach is the required
“Noninvasivehumanactivityrecognitionusingmillimeter-waveradar,”
domain-specific knowledge. One needs to know how a com- IEEESystemsJournal,vol.16,pp.1–12,062022.
plex movement can be split into points of interest. A further [6] O.D.LaraandM.A.Labrador,“Asurveyonhumanactivityrecognition
using wearable sensors,” IEEE communications surveys & tutorials,
challenge is posed by movement sequences, in which athletes
vol.15,no.3,pp.1192–1209,2012.
do not perform the same way every time. In the future, we [7] S. Ji, W. Xu, M. Yang, and K. Yu, “3d convolutional neural networks
plan to parallelize the search for sub-solutions in Section forhumanactionrecognition,”vol.35,pp.495–502,082010.
[8] V.Bianchi,M.Bassoli,G.Lombardo,P.Fornacciari,M.Mordonini,and
III-D. One potential area to explore is the potential to remove
I. De Munari, “Iot wearable sensor and deep learning: An integrated
the necessity for domain-specific knowledge. This could be approach for personalized human activity recognition in a smart home
achieved by utilizing a neural network or federated learning environment,” IEEE Internet of Things Journal, vol. PP, pp. 1–1, 05
2019.
concepts(i.e.,aspresentedin[25])toembodydomain-specific
[9] O.DehzangiandV.Sahu,“Imu-basedrobusthumanactivityrecognition
insights from extensive datasets and construct a graph based using feature analysis, extraction, and reduction,” pp. 1402–1407, 08
ontheacquiredknowledge.Futureworkremainsinvestigating 2018.
[10] J. Li, A. Sun, J. Han, and C. Li, “A survey on deep learning for
possibilitiesforreal-timeinsightswhileenablingdataprocess-
named entity recognition,” IEEE transactions on knowledge and data
ing in a distributed manner in the computing continuum [26], engineering,vol.34,no.1,pp.50–70,2020.
[27]. Lastly, we will explore integrating advanced sensor data [11] A. Jalal, Y. Kim, and D. Kim, “Ridge body parts features for human
poseestimationandrecognitionfromrgb-dvideodata,”inFifthInter-
analytics with AI planning techniques [28] in edge computing
national Conference on Computing, Communications and Networking
environments [29] to enhance the real-time performance and Technologies(ICCCNT),pp.1–6,2014.
scalability of physical activity monitoring systems. [12] T.F.N.Bukht,H.Rahman,M.Shaheen,A.Algarni,N.A.Almujally,
and A. Jalal, “A review of video-based human activity recognition:
theory,methodsandapplications,”MultimediaToolsandApplications,
pp.1–47,2024.
V. CONCLUSION
[13] P.Kumar,S.Chauhan,andL.K.Awasthi,“Humanactivityrecognition
(har) using deep learning: Review, methodologies, progress and future
Integrating advanced wearable sensor devices has revolu- researchdirections,”ArchivesofComputationalMethodsinEngineering,
vol.31,no.1,pp.179–219,2024.
tionized capturing detailed movement data during physical
[14] Y. Kaya and E. K. Topuz, “Human activity recognition from multiple
activities. Such capability provides invaluable insights into sensors data using deep cnns,” Multimedia Tools and Applications,
performance metrics, learning fatigue points, and tracking vol.83,no.4,pp.10815–10838,2024.
[15] J.Liu,D.J.Spakowicz,G.I.Ash,R.Hoyd,R.Ahluwalia,A.Zhang,
movementefficiency.Theproposedapproachleveragessensor
S. Lou, D. Lee, J. Zhang, C. Presley, et al., “Bayesian structural time
data and, via graph-based, captures and analyzes detailed series for biomedical sensor data: A flexible modeling framework for
movement data from individuals during various physical ac- evaluating interventions,” PLoS computational biology, vol. 17, no. 8,
p.e1009303,2021.
tivities.Thismethodologyoffersacomprehensivesolutionfor
[16] P.KumarandS.Suresh,“Deep-har:anensembledeeplearningmodelfor
identifying critical performance metrics and fatigue points. recognizingthesimple,complex,andheterogeneoushumanactivities,”
Visualizing these data through graphs enables a clear and Multimedia Tools and Applications, vol. 82, no. 20, pp. 30435–30462,
2023.
intuitive understanding of where and why performance drops
[17] Y.Zhang,X.Wang,J.Wen,andX.Zhu,“Wifi-basednon-contacthuman
occur. Nevertheless, this paper outlines just the initial stage presencedetectiontechnology,”ScientificReports,vol.14,022024.
of operationalizing the framework. In future work, we aim to [18] E. Ramanujam, T. Perumal, and S. Padmavathi, “Human activity
recognitionwithsmartphoneandwearablesensorsusingdeeplearning
develop a comprehensive technical framework and provide a
techniques:Areview,”IEEESensorsJournal,vol.21,no.12,pp.13029–
thorough evaluation. 13040,2021.[19] D. B. West, Introduction to graph theory. Upper Saddle River, NJ: 2ed.,Nov.2000.
Pearson,2ed.,Aug.2000. [25] I. Murturi, P. K. Donta, and S. Dustdar, “Community ai: Towards
[20] F. Scholkmann, J. Boss, and M. Wolf, “An efficient algorithm for community-based federated learning,” in 2023 IEEE 5th International
automaticpeakdetectioninnoisyperiodicandquasi-periodicsignals,” ConferenceonCognitiveMachineIntelligence(CogMI),pp.1–9,IEEE,
Algorithms,vol.5,no.4,pp.588–603,2012. 2023.
[21] T.KokaandM.Muma,“Fastandsampleaccurater-peakdetectionfor [26] P.K.Donta,I.Murturi,V.CasamayorPujol,B.Sedlak,andS.Dustdar,
noisy ecg using visibility graphs,” in 2022 44th Annual International “Exploringthepotentialofdistributedcomputingcontinuumsystems,”
Conference of the IEEE Engineering in Medicine & Biology Society Computers,vol.12,no.10,p.198,2023.
(EMBC),pp.121–126,2022. [27] V. Casamayor Pujol, A. Morichetta, I. Murturi, P. Kumar Donta, and
[22] F.FellandM.Tanenbaum,“Preliminarycomparisonsofthewgs84(egm S.Dustdar,“Fundamentalresearchchallengesfordistributedcomputing
96)geoidwithnationalverticaldatums,”inMTS/IEEEOceans2001.An continuumsystems,”Information,vol.14,no.3,2023.
Ocean Odyssey. Conference Proceedings (IEEE Cat. No.01CH37295), [28] I.Murturi,A.Egyed,andS.Dustdar,“Utilizingaiplanningontheedge,”
vol.1,pp.571–574vol.1,2001. IEEEInternetComputing,vol.26,no.2,pp.28–35,2022.
[23] G. Van Brummelen, Heavenly mathematics. Princeton, NJ: Princeton [29] I. Murturi and S. Dustdar, “Decent: A decentralized configurator for
UniversityPress,Apr.2017. controllingelasticityindynamicedgenetworks,”ACMTransactionson
[24] J.E.Hopcroft,R.Motwani,andJ.D.Ullman,Introductiontoautomata InternetTechnology(TOIT),2022.
theory,languages,andcomputation. UpperSaddleRiver,NJ:Pearson,