[
    {
        "title": "KAN 2.0: Kolmogorov-Arnold Networks Meet Science",
        "authors": "Ziming LiuPingchuan MaYixuan WangWojciech MatusikMax Tegmark",
        "links": "http://arxiv.org/abs/2408.10205v1",
        "entry_id": "http://arxiv.org/abs/2408.10205v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10205v1",
        "summary": "A major challenge of AI + Science lies in their inherent incompatibility:\ntoday's AI is primarily based on connectionism, while science depends on\nsymbolism. To bridge the two worlds, we propose a framework to seamlessly\nsynergize Kolmogorov-Arnold Networks (KANs) and science. The framework\nhighlights KANs' usage for three aspects of scientific discovery: identifying\nrelevant features, revealing modular structures, and discovering symbolic\nformulas. The synergy is bidirectional: science to KAN (incorporating\nscientific knowledge into KANs), and KAN to science (extracting scientific\ninsights from KANs). We highlight major new functionalities in the pykan\npackage: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN\ncompiler that compiles symbolic formulas into KANs. (3) tree converter: convert\nKANs (or any neural networks) to tree graphs. Based on these tools, we\ndemonstrate KANs' capability to discover various types of physical laws,\nincluding conserved quantities, Lagrangians, symmetries, and constitutive laws.",
        "updated": "2024-08-19 17:59:04 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10205v1"
    },
    {
        "title": "Demystifying the Communication Characteristics for Distributed Transformer Models",
        "authors": "Quentin AnthonyBenjamin MichalowiczJacob HatefLang XuMustafa AbduljabbarAamir ShafiHari SubramoniDhabaleswar Panda",
        "links": "http://arxiv.org/abs/2408.10197v1",
        "entry_id": "http://arxiv.org/abs/2408.10197v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10197v1",
        "summary": "Deep learning (DL) models based on the transformer architecture have\nrevolutionized many DL applications such as large language models (LLMs),\nvision transformers, audio generation, and time series prediction. Much of this\nprogress has been fueled by distributed training, yet distributed communication\nremains a substantial bottleneck to training progress. This paper examines the\ncommunication behavior of transformer models - that is, how different\nparallelism schemes used in multi-node/multi-GPU DL Training communicate data\nin the context of transformers. We use GPT-based language models as a case\nstudy of the transformer architecture due to their ubiquity. We validate the\nempirical results obtained from our communication logs using analytical models.\nAt a high level, our analysis reveals a need to optimize small message\npoint-to-point communication further, correlations between sequence length,\nper-GPU throughput, model size, and optimizations used, and where to\npotentially guide further optimizations in framework and HPC middleware design\nand optimization.",
        "updated": "2024-08-19 17:54:29 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10197v1"
    },
    {
        "title": "SpaRP: Fast 3D Object Reconstruction and Pose Estimation from Sparse Views",
        "authors": "Chao XuAng LiLinghao ChenYulin LiuRuoxi ShiHao SuMinghua Liu",
        "links": "http://arxiv.org/abs/2408.10195v1",
        "entry_id": "http://arxiv.org/abs/2408.10195v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10195v1",
        "summary": "Open-world 3D generation has recently attracted considerable attention. While\nmany single-image-to-3D methods have yielded visually appealing outcomes, they\noften lack sufficient controllability and tend to produce hallucinated regions\nthat may not align with users' expectations. In this paper, we explore an\nimportant scenario in which the input consists of one or a few unposed 2D\nimages of a single object, with little or no overlap. We propose a novel\nmethod, SpaRP, to reconstruct a 3D textured mesh and estimate the relative\ncamera poses for these sparse-view images. SpaRP distills knowledge from 2D\ndiffusion models and finetunes them to implicitly deduce the 3D spatial\nrelationships between the sparse views. The diffusion model is trained to\njointly predict surrogate representations for camera poses and multi-view\nimages of the object under known poses, integrating all information from the\ninput sparse views. These predictions are then leveraged to accomplish 3D\nreconstruction and pose estimation, and the reconstructed 3D model can be used\nto further refine the camera poses of input views. Through extensive\nexperiments on three datasets, we demonstrate that our method not only\nsignificantly outperforms baseline methods in terms of 3D reconstruction\nquality and pose prediction accuracy but also exhibits strong efficiency. It\nrequires only about 20 seconds to produce a textured mesh and camera poses for\nthe input views. Project page: https://chaoxu.xyz/sparp.",
        "updated": "2024-08-19 17:53:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10195v1"
    },
    {
        "title": "Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models",
        "authors": "Aviv BickKevin Y. LiEric P. XingJ. Zico KolterAlbert Gu",
        "links": "http://arxiv.org/abs/2408.10189v1",
        "entry_id": "http://arxiv.org/abs/2408.10189v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10189v1",
        "summary": "Transformer architectures have become a dominant paradigm for domains like\nlanguage modeling but suffer in many inference settings due to their\nquadratic-time self-attention. Recently proposed subquadratic architectures,\nsuch as Mamba, have shown promise, but have been pretrained with substantially\nless computational resources than the strongest Transformer models. In this\nwork, we present a method that is able to distill a pretrained Transformer\narchitecture into alternative architectures such as state space models (SSMs).\nThe key idea to our approach is that we can view both Transformers and SSMs as\napplying different forms of mixing matrices over the token sequences. We can\nthus progressively distill the Transformer architecture by matching different\ndegrees of granularity in the SSM: first matching the mixing matrices\nthemselves, then the hidden units at each block, and finally the end-to-end\npredictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant\nbased on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid\nversion (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the\ntraining data typically used to train models from scratch, Phi-Mamba boasts\nsubstantially stronger performance compared to all past open-source\nnon-Transformer models. MOHAWK allows models like SSMs to leverage\ncomputational resources invested in training Transformer-based architectures,\nhighlighting a new avenue for building such models.",
        "updated": "2024-08-19 17:48:11 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10189v1"
    },
    {
        "title": "Imbalance-Aware Culvert-Sewer Defect Segmentation Using an Enhanced Feature Pyramid Network",
        "authors": "Rasha AlshawiMd Meftahul FerdausMahdi AbdelguerfiKendall NilesKen PathakSteve Sloan",
        "links": "http://arxiv.org/abs/2408.10181v1",
        "entry_id": "http://arxiv.org/abs/2408.10181v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10181v1",
        "summary": "Imbalanced datasets are a significant challenge in real-world scenarios. They\nlead to models that underperform on underrepresented classes, which is a\ncritical issue in infrastructure inspection. This paper introduces the Enhanced\nFeature Pyramid Network (E-FPN), a deep learning model for the semantic\nsegmentation of culverts and sewer pipes within imbalanced datasets. The E-FPN\nincorporates architectural innovations like sparsely connected blocks and\ndepth-wise separable convolutions to improve feature extraction and handle\nobject variations. To address dataset imbalance, the model employs strategies\nlike class decomposition and data augmentation. Experimental results on the\nculvert-sewer defects dataset and a benchmark aerial semantic segmentation\ndrone dataset show that the E-FPN outperforms state-of-the-art methods,\nachieving an average Intersection over Union (IoU) improvement of 13.8% and\n27.2%, respectively. Additionally, class decomposition and data augmentation\ntogether boost the model's performance by approximately 6.9% IoU. The proposed\nE-FPN presents a promising solution for enhancing object segmentation in\nchallenging, multi-class real-world datasets, with potential applications\nextending beyond culvert-sewer defect detection.",
        "updated": "2024-08-19 17:40:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10181v1"
    }
]