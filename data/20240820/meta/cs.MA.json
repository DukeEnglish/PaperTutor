[
    {
        "title": "Auctioning Escape Permits for Multiple Correlated Pollutants Using CMRA",
        "authors": "Keshav GoyalSooraj SathishShrisha Rao",
        "links": "http://arxiv.org/abs/2408.10148v1",
        "entry_id": "http://arxiv.org/abs/2408.10148v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10148v1",
        "summary": "In the context of increasingly complex environmental challenges, effective\npollution control mechanisms are crucial. By extending the state of the art\nauction mechanisms, we aim to develop an efficient approach for allocating\npollution abatement resources in a multi-pollutant setting with pollutants\naffecting each other's reduction costs. We modify the Combinatorial Multi-Round\nAscending Auction for the auction of escape permits of pollutants with\nco-dependent reduction processes, specifically, greenhouse gas emissions and\nnutrient runoff in Finnish agriculture. We show the significant advantages of\nthis mechanism in pollution control through experiments on the bid prices and\namount of escape permits sold in multiple auction simulations.",
        "updated": "2024-08-19 16:49:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10148v1"
    },
    {
        "title": "Synthesis of Reward Machines for Multi-Agent Equilibrium Design (Full Version)",
        "authors": "Muhammad NajibGiuseppe Perelli",
        "links": "http://arxiv.org/abs/2408.10074v1",
        "entry_id": "http://arxiv.org/abs/2408.10074v1",
        "pdf_url": "http://arxiv.org/pdf/2408.10074v1",
        "summary": "Mechanism design is a well-established game-theoretic paradigm for designing\ngames to achieve desired outcomes. This paper addresses a closely related but\ndistinct concept, equilibrium design. Unlike mechanism design, the designer's\nauthority in equilibrium design is more constrained; she can only modify the\nincentive structures in a given game to achieve certain outcomes without the\nability to create the game from scratch. We study the problem of equilibrium\ndesign using dynamic incentive structures, known as reward machines. We use\nweighted concurrent game structures for the game model, with goals (for the\nplayers and the designer) defined as mean-payoff objectives. We show how reward\nmachines can be used to represent dynamic incentives that allocate rewards in a\nmanner that optimises the designer's goal. We also introduce the main decision\nproblem within our framework, the payoff improvement problem. This problem\nessentially asks whether there exists a dynamic incentive (represented by some\nreward machine) that can improve the designer's payoff by more than a given\nthreshold value. We present two variants of the problem: strong and weak. We\ndemonstrate that both can be solved in polynomial time using a Turing machine\nequipped with an NP oracle. Furthermore, we also establish that these variants\nare either NP-hard or coNP-hard. Finally, we show how to synthesise the\ncorresponding reward machine if it exists.",
        "updated": "2024-08-19 15:17:58 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.10074v1"
    },
    {
        "title": "MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems",
        "authors": "Qian WangTianyu WangQinbin LiJingsheng LiangBingsheng He",
        "links": "http://arxiv.org/abs/2408.09955v1",
        "entry_id": "http://arxiv.org/abs/2408.09955v1",
        "pdf_url": "http://arxiv.org/pdf/2408.09955v1",
        "summary": "With the emergence of large language models (LLMs), LLM-powered multi-agent\nsystems (LLM-MA systems) have been proposed to tackle real-world tasks.\nHowever, their agents mostly follow predefined Standard Operating Procedures\n(SOPs) that remain unchanged across the whole interaction, lacking autonomy and\nscalability. Additionally, current solutions often overlook the necessity for\neffective agent cooperation. To address the above limitations, we propose\nMegaAgent, a practical framework designed for autonomous cooperation in\nlarge-scale LLM Agent systems. MegaAgent leverages the autonomy of agents to\ndynamically generate agents based on task requirements, incorporating features\nsuch as automatically dividing tasks, systematic planning and monitoring of\nagent activities, and managing concurrent operations. In addition, MegaAgent is\ndesigned with a hierarchical structure and employs system-level parallelism to\nenhance performance and boost communication. We demonstrate the effectiveness\nof MegaAgent through Gobang game development, showing that it outperforms\npopular LLM-MA systems; and national policy simulation, demonstrating its high\nautonomy and potential to rapidly scale up to 590 agents while ensuring\neffective cooperation among them. Our results indicate that MegaAgent is the\nfirst autonomous large-scale LLM-MA system with no pre-defined SOPs, high\neffectiveness and scalability, paving the way for further research in this\nfield. Our code is at https://anonymous.4open.science/r/MegaAgent-81F3.",
        "updated": "2024-08-19 12:55:16 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.09955v1"
    },
    {
        "title": "Algorithmic Contract Design with Reinforcement Learning Agents",
        "authors": "David Molina ConchaKyeonghyeon ParkHyun-Rok LeeTaesik LeeChi-Guhn Lee",
        "links": "http://arxiv.org/abs/2408.09686v1",
        "entry_id": "http://arxiv.org/abs/2408.09686v1",
        "pdf_url": "http://arxiv.org/pdf/2408.09686v1",
        "summary": "We introduce a novel problem setting for algorithmic contract design, named\nthe principal-MARL contract design problem. This setting extends traditional\ncontract design to account for dynamic and stochastic environments using Markov\nGames and Multi-Agent Reinforcement Learning. To tackle this problem, we\npropose a Multi-Objective Bayesian Optimization (MOBO) framework named\nConstrained Pareto Maximum Entropy Search (cPMES). Our approach integrates MOBO\nand MARL to explore the highly constrained contract design space, identifying\npromising incentive and recruitment decisions. cPMES transforms the\nprincipal-MARL contract design problem into an unconstrained multi-objective\nproblem, leveraging the probability of feasibility as part of the objectives\nand ensuring promising designs predicted on the feasibility border are included\nin the Pareto front. By focusing the entropy prediction on designs within the\nPareto set, cPMES mitigates the risk of the search strategy being overwhelmed\nby entropy from constraints. We demonstrate the effectiveness of cPMES through\nextensive benchmark studies in synthetic and simulated environments, showing\nits ability to find feasible contract designs that maximize the principal's\nobjectives. Additionally, we provide theoretical support with a sub-linear\nregret bound concerning the number of iterations.",
        "updated": "2024-08-19 03:48:38 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.09686v1"
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Autonomous Driving: A Survey",
        "authors": "Ruiqi ZhangJing HouFlorian WalterShangding GuJiayi GuanFlorian RöhrbeinYali DuPanpan CaiGuang ChenAlois Knoll",
        "links": "http://arxiv.org/abs/2408.09675v1",
        "entry_id": "http://arxiv.org/abs/2408.09675v1",
        "pdf_url": "http://arxiv.org/pdf/2408.09675v1",
        "summary": "Reinforcement Learning (RL) is a potent tool for sequential decision-making\nand has achieved performance surpassing human capabilities across many\nchallenging real-world tasks. As the extension of RL in the multi-agent system\ndomain, multi-agent RL (MARL) not only need to learn the control policy but\nalso requires consideration regarding interactions with all other agents in the\nenvironment, mutual influences among different system components, and the\ndistribution of computational resources. This augments the complexity of\nalgorithmic design and poses higher requirements on computational resources.\nSimultaneously, simulators are crucial to obtain realistic data, which is the\nfundamentals of RL. In this paper, we first propose a series of metrics of\nsimulators and summarize the features of existing benchmarks. Second, to ease\ncomprehension, we recall the foundational knowledge and then synthesize the\nrecently advanced studies of MARL-related autonomous driving and intelligent\ntransportation systems. Specifically, we examine their environmental modeling,\nstate representation, perception units, and algorithm design. Conclusively, we\ndiscuss open challenges as well as prospects and opportunities. We hope this\npaper can help the researchers integrate MARL technologies and trigger more\ninsightful ideas toward the intelligent and autonomous driving.",
        "updated": "2024-08-19 03:31:20 UTC",
        "interpretation": "解释内容未找到",
        "id": "2408.09675v1"
    }
]