Retrieve, Annotate, Evaluate, Repeat: Leveraging Multimodal LLMs for
Large-Scale Product Retrieval Evaluation
KasraHosseini,ThomasKober,JosipKrapac,RolandVollgraf,
WeiweiCheng,AnaPeleteiroRamallo,
ZalandoSE,Berlin,Germany
Abstract LLM-based annotation framework
(2) LLM generator
query-specific
Evaluatingproduction-levelretrievalsystems (1) Search black sneakers üõ† annotation guidelines
Logs
at scale is a crucial yet challenging task due
(3) LLM annotator
to the limited availability of a large pool of (black sneakers, )
üìù
well-trained human annotators. Large Lan-
guage Models (LLMs) have the potential to (4)Search engine (black sneakers, ,‚úÖ)
address this scaling issue and offer a viable evaluation üìà
alternative to humans for the bulk of annota-
Figure 1: Our proposed framework works by extract-
tiontasks. Inthispaper,weproposeaframe-
ing a query-product pair from our search query-click
workforassessingtheproductsearchengines
logs(1). Thequery(e.g. blacksneakers)isthenpassed
inalarge-scalee-commercesetting,leveraging
on to the LLM generator (2). The LLM generator
Multimodal LLMs for (i) generating tailored
creates specific annotation instructions for the given
annotation guidelines for individual queries,
query. The query-specific annotation guidelines and
and(ii)conductingthesubsequentannotation
the query-product pair (e.g. black sneakers and the
task. Our method, validated through deploy-
retrieved product) are provided as input to the LLM
mentonalargee-commerceplatform,demon-
annotator(3). Lastly,theannotatedquery-productpair
strates comparable quality to human annota-
isforwardedtothesearchengineevaluationmodule(4).
tions,significantlyreducestimeandcost,facil-
itatesrapidproblemdiscovery,andprovidesan
effectivesolutionforproduction-levelquality
controlatscale. aretrievedproductissemanticallyrelevanttothe
query. Semantic relevance depends solely on the
1 Introduction
queryandtheproduct,excludingothercontextual
factorssuchaspersonalcustomerpreferences.
Searchfunctionalityisafundamentalcomponent
of e-commerce platforms, with the objective of Creatingannotationguidelinesthatcodifywhat
finding the most relevant products in a dynamic issemanticallyrelevantisacomplextask(Spark-
productdatabase. Customersusingsearchoftenex- Jones,1975). Itrequiresdescribingtheguidelines
hibitahigherintenttofindspecificproducts(Moe, inadigestible,concise,yetprecisemanner,aswell
2003),leadingtogreaterengagementandconver- ascuratingasetofillustrativeexamplesofvarying
sionrates. However,theymaystruggletoarticulate difficulty. Evenwithwell-definedguidelinesand
their needs in a search query. Even if they do ex- well-trainedhumanannotators,manualannotation
presstheirintentclearly,informationretrieval(IR) isslowandcostly.
systemsmightfailtointerpretitcorrectly,resulting Theadventofcrowd-sourcingplatformshasin-
inirrelevantsearchresults(WangandNa,2024). creasedscalability(Blancoetal.,2011;Alonsoand
Evaluatingproductretrievalsystemsonalarge Mizzaro,2012;LeaseandYilmaz,2013;Marcus
scale in a multilingual setting and for a diverse etal.,2015;Chenetal.,2016),allowingforatrade-
setofcustomerqueriesisanintricatebutessential offbetweenspeedandcost. However,increasing
taskformaintainingahigh-qualityuserexperience thenumberofannotatorscanleadtoinconsisten-
and driving business success. A prerequisite for cies,aseventhesameannotatormayprovidecon-
thisevaluationistheavailabilityofalargeenough tradictoryannotationsforthesamequery-product
poolofquery-productrelevancelabels(Voorhees, pair,letalonemultipleannotators. Consistencycan
2001;Halveyetal.,2015),whichindicatewhether beimprovedbyusingmoreannotatorsperpair(see,
4202
peS
81
]RI.sc[
1v06811.9042:viXrae.g., Ferrante et al. (2017)), but this results in in- Wefurthermoreshowthatwhilehuman-humanand
creasedcost. Inlargee-commercesystems,thevol- human-LLMagreementscoresareonparwitheach
umeofdatathatneedstobeannotatedleadstopro- other,wefindthathumansandLLMstendtomake
hibitively high costs when using crowd-sourcing verydifferenttypesofannotationerrors. Ourfind-
platformsthatrelyonhumanannotators. ingssuggestthatLLMsareveryeffectiveforthe
While the rate of manual relevance judgement bulkworkofannotationswhereashumanexpertise
varies depending on the task (Voorhees, 2001; isbetterleveragedformorecomplexcases.
Sandersonetal.,2010;Chenetal.,2022;Soviero Insummary,ourcontributionsareasfollows:
etal.,2024),inourusecase,weestimateathrough-
‚Ä¢ WeintroduceamultimodalLLM-basedeval-
putof2-3query-productpairsperminute. Asanex-
ample,50,000queries1 and20productsperquery uationframeworkforlarge-scaleproductre-
trievalsystems. Weproposequery-levelanno-
resultsinonemillionquery-productpairs,which
tationguidelinesandutilisemultimodalinputs
takes5,500-8,500hoursofhumanlabour,assuming
(textandimages)forrelevanceassessment.
oneannotationperpair. Moreover,evaluationisnot
aone-offpractice;ideally,companiescontinuously
‚Ä¢ We evaluate the performance of our frame-
assesstheirsearchenginestoensureeffectiveness
workagainsthumanannotationsonreal-world
overtime.
productionsearchqueriesinamultilingualset-
Thesheervolumeofrequiredannotationsinmul-
tingandanalysethedifferenttypesoferrors
tiple languages, along with the need for continu-
thathumansandLLMstendtomake.
ousevaluation,makeshuman-generatedrelevance
judgementstheprimarybottleneckincreatingprod- ‚Ä¢ Wedemonstratethecost-effectivenessandef-
uctretrievalevaluationdatasets. Toovercomethese ficiencyofourapproachforconductinglarge-
challenges,therehasbeengrowinginterestinlever- scaleevaluations. Wealsocomparetheperfor-
agingLLMs(Faggiolietal.,2023;Thomasetal., mance of different types of LLMs (Radford
2023; Soviero et al., 2024; Rahmani et al., 2024; etal.,2019;Brownetal.,2020;Achiametal.,
Upadhyayetal.,2024;Bergum,2024). 2023)forrelevanceassessment.
Inthisstudy,weproposeaframeworkthatlever-
2 MultimodalLLM-basedrelevance
ages the capabilities of Multimodal Large Lan-
assessment
guage Models (MLLMs) for assessing the rele-
vanceofquery-productpairs(Fig.1). Ourmethod
ThesetupofourmethodisdepictedinFig.2. Itis
combinesthestrengthsofLLMsandMLLMsinun-
designedtoleveragethecapabilitiesof(M)LLMs
derstandingnaturallanguagequeriesacrossvarious
for efficient evaluation of large-scale product
languagesandprocessingbothtextualandvisual
retrievalsystems,anditconsistsofsixmainsteps:
features of products. Unlike traditional per-task
(1)Foragivenqueryanditscontext(e.g.,selected
annotationguidelines,suchasthosediscussedby
gender and market), an LLM generates a query
Sovieroetal.(2024),weemployLLMstogenerate
requirement list and a query-specific annotation
annotationguidelinesspecifictoeachquery. Addi-
guideline. Thequeryrequirementlistcapturesthe
tionally,ourpipeline‚Äôsmodulardesignallowsfor
relevantpiecesofinformationintheuser‚Äôsquery
caching and parallel processing, which is crucial
andtheirlevelofimportance. Forexample,forthe
for scaling up to larger systems. This framework
query Nike red shoes, the query requirement list
has enabled daily evaluations of our product re-
includesthebrand(Nike),colour(red)andproduct
trievalsystems. Ithasalsofacilitatedthecompari-
category (shoe). The query-specific annotation
sonofdifferentsearchmodels,increasingourconfi-
guideline is generated by the LLM based on the
denceinofflineevaluationsandcomplementingour
query and its requirement list. It outlines criteria
onlineevaluationtechniques,suchasA/Btesting
for each predefined label (see Appendix A for a
and other controlled online experiments (Kohavi
detailedexample). Inourexperiments,wedefined
etal.,2009). Moreover,wehaveusedtherelevance
three relevance labels for a query-product pair:
assessments‚Äôoutputstotrain,evaluateandanalyse
‚Äúirrelevant‚Äù, ‚Äúacceptable substitute‚Äù and ‚Äúhighly
other components of our search and ranking sys-
relevant‚Äù.2
tems.
1AmodestnumberfortheevaluationoflargeIRsystems. 2SeeAppendixBfordetails.Few-shot prompting
Query requirement +
query-specific
Search logs (1) LLM annotation guidance DB
LLM generator
(2) (5b)
Relevance score and
Query-Product Product Textual + Visual reasoning for:
pair (3a) description Product (5a) LLM (6) (query, product,
descriptions relevance)
Product
(3b) image(s) (4) MLLM
LLM annotator
Figure2: OurproposedMultimodalLLM-poweredframeworkenablesofflineevaluationoflarge-scaleproduct
retrievalsystemsandpresentssignificanttimeandcostreductionscomparedtoexistingevaluationtechniques. Refer
toFig.1foranoverviewofthemainstepsintheframework,andconsultthetextforfurtherdetails. Theorange
rectangleindicateswherea‚Äúone-step‚ÄùMultimodalLLM(MLLM)couldbeutilised, insteadofemployingone
MLLMtocreateatextualdescriptionforimageinputs(Step4)followedbyanLLM(Step5a). Intheone-step
MLLM,bothtextualdescriptionsandtheproductimagearedirectlyfedintotheLLMannotator,alongwithquery
requirementsandquery-specificannotationguidelines. Thedepictionofthepipelineissimplifiedforreadability.
(2) The query and its context are sent to the configuration(oravariationofexistingones),the
search engine, which retrieves a set of products. database is queried to retrieve relevant pieces of
For simplicity, we illustrate this process using a information,includingthequeryrequirementlist,
singlequery-productpair. However,inpractice,we query-specific annotation guidance, textual and
work with multiple query-product pairs and may visualproductdescriptions,andrelevancescores.
utilisetwoormoreretrievalsystems,particularly Weonlycomputethemissingpiecesofinformation.
whencomparingtheirperformance. Secondly, it ensures consistent evaluation across
(3a,b)Foreachretrievedproduct,wehaveaccess different search engines, as intermediate steps
toitstextualdescriptionanditsassociatedimage. (suchasquery-specificannotationguidelines)are
(4)UsingMLLMsandtheproductimage,avisual computed only once and then used to evaluate
descriptionintextualformisgenerated. varioussearchengines.
(5a,b) The combined textual and visual product
3 ExperimentsandResults
descriptionsaresenttoanLLMtogetherwiththe
outputsofStep1(i.e.,queryrequirementlistand
3.1 Dataset
query-specificannotationguideline).
Data collection. As a starting point for our data
(6) The LLM assigns a relevance score to the
collection,weusedoneyear‚Äôsworthofproduction
query-productpairusingasetofpredefinedlabels.
searchquerytraffic3. Wethenperformedstratified
Initssimplestform,theoutputisadatabasewith
samplingalongthefollowingdimensions: a)search
onerowforeach(query, product, relevance
engine,b)activatedgenderfilteronthewebsite,c)
score).
queryfrequency,andd)querylengthintokens.
InSteps1and6,weutilisechain-of-thought(CoT)
prompting (Wei et al., 2022; Nye et al., 2021) to
Table1: Datasetstatistics.
enhance the quality of (M)LLM outputs and for
debugging. Anexampleofthereasoningstepsis Language Unique Unique Avg.tokens Unique
showninAppendixA. pairs queries perquery products
German 10,000 500 3.68 8,076
As illustrated with dashed lines in Fig. 2, all
English 10,000 500 3.99 8,652
outputs and intermediate steps are stored in a
database. Thiscachingservestwokeyfunctionsin
ourpipeline. Firstly,itfacilitatesefficientretrieval 3Ourdatacollectionprocesscomplieswiththeregulations
definedintheGDPRandotherexistingregulatoryframeworks
and reuse. When evaluating a new search engine
arounddataprivacyandsafetyintheEuropeanUnion.DataScienceDays2024 PaperSubmission
<TABLES - 20240718>
table_20240715_gpt4o_with_without
INFO:
LLM_MODEL="gpt-4o"
Table2: Agreementsbetween(M)LLMandthehumanannotatorgroups(i.e.,A1andA2). Wecompareagreements
LLM_VISION_MODEL="gpt-4o"
basedoni)matchingeitherA1orA2andii)interannotatoragreementbetweenhumanannotators(A1vs. A2)and
betweenLLMsandthehumanmajorityvote. IntheA1orA2column,weusethesamehumanmajorityvoteto
measuretheagreemeWntIsTfHor:hvu2m0a2n4a0n7no1t1at0o0rs0.1ResultsarereportedseparatelyforEnglishandGerman. Forhuman
annotations,werepoWrt/thOe:tvo2ta0l2tim40e7a1nd10co0s0t.1W_weiutsheoGuPtT-4oinallstepsofourLLMannotationpipeline(Fig.2).
RefertoTable3foramoredetailedcomparisonbetweenhumanannotatorgroups(A1,A2,andtiebreaker)and
differentversionsofourLLM-poweredframework.
Agreementwith InterAnnotator
Annotator A1ORA2(%) Agreement(%) Totaltime Cost
EN DE EN DE EN DE EN DE
A1 76.6 75.9 60.2 60.5 3weeks ‚Ç¨15,000
A2 75.8 76.1 60.2 60.5 3weeks ‚Ç¨15,000
LLM-text 75.4 75.6 62.8 61.4 8min 7min ‚Ç¨70 ‚Ç¨70
MLLM-text 76.6 77.0 64.3 63.1 12min 13min ‚Ç¨92 ‚Ç¨93
MLLM-multi 78.1 78.4 65.6 64.7 10min 10min ‚Ç¨72 ‚Ç¨72
MLLM-multi 75.4 75.6 62.9 62.0 30min 23min ‚Ç¨155 ‚Ç¨156
(gpt-4-turbo)
Withoutquery-specificannotationguidance
LLM-text 71.2(-4.2) 67.0(-8.6) 57.6(-5.2) 52.2(-9.2) 7min 7min ‚Ç¨45 ‚Ç¨45
MLLM-text 72.5(-4.1) 68.0(-9.0) 58.7(-5.6) 53.4(-9.7) 11min 11min ‚Ç¨66 ‚Ç¨67
MLLM-multi 74.1(-4.0) 71.9(-6.5) 61.6(-4.0) 59.9(-4.8) 4min 4min ‚Ç¨25 ‚Ç¨24
After sampling and manual curation4, we ob- weeks6,withroughly3weeksneededforcomplet-
tained 500 queries in German and English each. ingthemainannotationandtiebreakerphases. The
Agreementwith AgreementwithAgreementwith Agreementwith InterAnnotator
Foreachquery,Awnneotthateonr usedAth1eOeRxAis2ti(n%g)searcAh1e(n%-) totalAc2o(s%t)ofdatTaieabnrenaokteart(i%on) wAagsreCem3e0n,t0(0%0). Totaltime Cost
ginetoretrieve20products,seElNectingD1E5proEdNuctsDE EN DE EN DE EN DE EN DE EN DE
fromthetoA p1 oftheretrievedr7 e6 s.6 ultsa7 n5. d9 rand-
omly
- 3.260.2LLM60.5vers4u0.s0Hum37a.5nAn60n.2otato6r0s.5 3weeks ‚Ç¨15,000
A2 75.8 76.1 60.2 60.5 - - 37.5 36.6 60.2 60.5 3weeks ‚Ç¨15,000
samplingtLhLeMre-tmexatining5from75.r4ank7550.60on6w3.9ards6.0.8 Us5i5n.g8 our59p.r3opo4s1e.d9fram33e.w9 ork,62w.8eass6e1s.4sedt8hemirnel-7min ‚Ç¨70 ‚Ç¨70
ThisresulteMdLiLnM1-t0e,x0t00unique76q.6uery-7p7r.0oduc6t4.p9airs62.0 56.9 60.7 43.2 35.5 64.3 63.1 12min 13min ‚Ç¨92 ‚Ç¨93
evancequalityofthe20,000uniquequery-product
MLLM-multi 78.1 78.4 66.0 63.1 58.2 62.0 43.9 37.4 65.6 64.7 10min 10min ‚Ç¨72 ‚Ç¨72
forGermanandEnglisheach. Table1outlinesthe
MLLM-multi 75.4 75.6 63.9 61.1 pa5ir5s.8. Ta5b9.l3e 24s1u.7mma3r4i.e8s the62.r9esult6s2.0of o3u0rmeinx-23min ‚Ç¨155 ‚Ç¨156
statisticso(fgtpht-e4-ctuorblole)cteddataset.
perimentsusingfew-shotprompting,wherewein-
Withoutquery-specificannotationguidance
Dataan Ln Lo Mta -tt ei xo tn.Fordata 7a 1.n 2nota 6t 7i .o 0n,w 5e 7.5con- 52.9 co5rp4.o4rate5d1.4exam39p.0les in34t.o4the5s7y.6stem52p.2rom7ptmsinof 7min ‚Ç¨45 ‚Ç¨45
tracted anMeLxLtMer-nteaxlt agency 7t2o.5faci6l8it.0ate 5c8r.o8wd-53.8 the55(.M4 )L5L2M.4 s. H39e.7re,w3e4.p1rovi5d8e.7dthe53L.4LM1s1wmiinth11min ‚Ç¨66 ‚Ç¨67
MLLM-multi 74.1 71.9 61.1 57.1 56.3 56.4 41.9 42.3 61.6 59.9 4min 4min ‚Ç¨25 ‚Ç¨24
sourcing annotations based on the guidelines we examplecustomerqueries,theircorrespondingre-
provided.5 Our requirements specified that only quirementlists,andqualitylabels,butnotcomplete
nativespeakers(GermanandEnglish,seeTable1) productdescriptionsorimages.
annotate the data. Each query-product pair was Initially,werandomlysampled100examplesfrom
tobeannotatedbytwohumanannotators,withan the English dataset and examined the relevance
table_20240715_gpt35_4o_for_vision
additionalthirdannotationasatiebreakerincases labelsassignedbybothLLMsandhumanannota-
wherethetwoorig Ii Nn Fal Oa :nnotatorsdisagreed. The tors. Weusedtheresultsofthissteptoadjustthe
dataannotationprocesswasdoneinthreephases: few-shotexamplesinthesystemprompt.
LLM_MODEL="gpt-3.5-turbo-0125"
(i)apilotphasetoonboardannotatorsandresolve
We compare the performance of different ver-
LLM_VISION_MODEL="gpt-4o"
outstanding loopholes and questions in the anno-
sionsofourpipelinewithhumanannotations. In
tation guidelines; (ii) the main annotation phase;
Table2,theseversionsarelabelledas‚ÄúLLM-text‚Äù,
(iii)thetiebreakerphase.
‚ÄúMLLM-text‚Äù,and‚ÄúMLLM-multi‚Äù.
In total, the data annotation process ‚Äì from the
‚ÄúLLM-text‚Äùisthesimplestversionwhereonlyprod-
handover of the initial version of the annotation
uctdescriptionsintextualformareused,without
guidelinesbyustothefinaldeliveryofannotated
incorporating product images. In ‚ÄúMLLM-text‚Äô,
databytheexternalagency‚Äìtookapproximately8
weemployavisionmodeltogeneratetextualde-
scriptionsofproductimages(Step4inthepipeline,
4Wemanuallycheckedallsampledqueriestoensurewe
see Fig. 2). The generated textual description of
coveradiverseandbroadspectrum.Forexample,wewould
the product image is then concatenated with the
manuallyreplaceyetanothersneakers-relatedquerywitha
boots-relatedqueryofthesamelength.
5SeeAppendixBforanoverviewofourannotationguide- 6Thisexcludestheeffortneededtowritetheannotation
lines. guidelinesandtosamplethequery-productcandidatepairs.productdescriptionitself(Step5a). ‚ÄúMLLM-multi‚Äù aharddisagreementtobewhen,forexample,the
utilisesthesametextualinputas‚ÄúLLM-text‚Äù,while LLM considers a product to be ‚Äúhighly relevant‚Äù
also incorporating the product image as an ad- for the given query, whereas the human majority
ditional input.7 Comparing ‚ÄúMLLM-multi‚Äù and judgement would be ‚Äúirrelevant‚Äù, and vice versa.
‚ÄúLLM-text‚Äù highlights the impact of multimodal In total, we found that approximately 15% of an-
inputsonourtask. notations9 inourdatasetwereharddisagreements.
Inallcases,the(M)LLMusesproductinformation Formanualanalysis,wesampled20%ofthehard
(indifferentmodalities,dependingontheversion), disagreementsandfoundthatin50%ofthecases,
queryrequirements,andquery-specificannotation thehumanannotationwaswrong,in31%theLLM
guidancetoassignrelevancelabels. waswrong,andin19%ofcases,boththeLLMand
Overall,Table2showsthattheagreementbetween thehumansprovidedawrongannotation.
humanannotatorsandLLMsisonparwiththatbe-
tweenhumanannotators,supportingthescalability
ofLLMannotationforproduction-leveltraffic.
Table 2 also shows the results of an ablation
study that removed the query-specific annotation
guideline (Step 1 in Fig. 2). The inclusion of
this guideline improved agreements by approxi-
mately4-10%. Moreimportantly,thiscomponent
in our framework is essential for enhancing the
interpretabilityanddebuggingofLLM-baseddeci-
sions. However,asexpected,incorporatingquery-
specificannotationguidelinesandchain-of-thought
reasoningincreasedtheevaluationcosts.
Wealsotestedtheimpactofdifferent(M)LLMar-
chitecturesinourpipeline.8 Theresultsshownin Figure 3: Distribution of errors between LLMs and
humansonharddisagreements(50%wereduetohuman
Table 2 are based on ‚ÄúGPT-4o‚Äù (OpenAI, 2024)
errors,31%LLMerrorsandin19%bothmadeanerror).
exceptforonerow,labelled‚ÄúMLLM-multi(gpt-4-
The upper part (‚ÄúBoth errors‚Äù) focuses on errors that
turbo)‚Äù. InthecaseofGPT-4Turbo,theagreement either the LLM or humans could make. It highlights
withhumanannotatorsconsistentlyfellbelowthat that LLMs and humans make very different types of
ofGPT-4o,whileitscostsandevaluationtimesex- errors.Inaddition,thelowerpart(‚ÄúLLMerrors‚Äù)shows
ceededthoseofallotherarchitectures. thedistributionoferrorsthatonlyanLLMwouldmake.
Predominantlythesearemisunderstandingsofapartof
InTable4,werepeatedtheexperimentsusingGPT-
thesearchquery.
3.5 Turbo. As expected, the results were signifi-
cantlyworsecomparedtoGPT-4oorGPT-4Turbo.
However, thecostandtimerequiredforGPT-3.5 Wefurthercategorisedtheharddisagreements
Turbowerelowerthanfortheotherarchitectures. into 9 error classes10, and found LLMs and hu-
mans tend to make very different kinds of errors.
4 Discussion
For example, as shown in Fig. 3, the main errors
madebytheLLMareeitherbeingtoostrictintheir
Agreement between LLM and human anno-
judgement (e.g., considering a product as ‚Äúirrele-
tators. The human-LLM agreements between
vant‚Äù, where ‚Äúacceptable substitute‚Äù would have
‚ÄúMLLM-multi‚Äù and the human majority vote ‚Äì
beenmoreappropriate),ormisunderstandingapart
65.6%forENand64.7%forDEinTable2‚Äìare
ofthequery(e.g., interpretingOnVacationinits
inlinewiththehumaninter-annotatoragreement,
literal sense rather than the fashion brand). On
whichis60.2%forENand60.5%forDE.
the other hand, humans would oftentimes be too
To better identify discrepancies between LLM
lenientwhenLLMsweretoostrict(e.g.,consider-
andhumanannotations,wefocusedouranalysison
ing a product as ‚Äúhighly relevant‚Äù when ‚Äúaccept-
harddisagreementsbetweenthetwo. Weconsider
7SeetheorangerectangleinFig.2whereboththetextual 92,971outof20,000query-productpairs(‚âà15%)hadhard
productdescriptionanditsimagearefedintoanMLLM. disagreementsbetweentheLLMandhumanmajorityvote.
8RefertoTable3and4inAppendixCfortheresultsof 10SeeAppendixDforthedefinitionoftheseclassesandfor
similarexperimentsconductedwithdifferentLLMtypes. exampleerrorswehaveobserved.ablesubstitute‚Äùwouldhavebeenmoreappropriate). onscopingandonboardinghumanannotators. For
Furthermore,humanannotationsfrequentlyexhib- (M)LLMs,thereportedtimeexcludesthepipeline
ited brand errors (e.g., considering a pair of Lee developmenttimeandonlyincludestheactualan-
jeans as ‚Äúhighly relevant‚Äù for a query requesting notationtime.
Levi‚Äôsjeans),producterrors(e.g.,consideringan We anticipate that both cost and time will de-
Adidas Samba sneaker as ‚Äúhighly relevant‚Äù for a creaseevenfurtherasLLMsandtheirAPIsbecome
query requesting an Adidas Stan Smith sneaker), more efficient. Moreover, new approaches, such
orcategoryerrors(e.g.,consideringapairofNike asbatchprocessing,canfurtherreducecosts(e.g.,
shirts as ‚Äúhighly relevant‚Äù for a query requesting OpenAI‚Äôs new batch processing is half the price
Nike shoes), which we barely ever observed for ofnon-batchqueries14). Indeed,inproduction,we
LLMs. Wehypothesisethatthelatterthreekinds usebatchprocessingtoassessquery-productpairs
of human errors are primarily due to annotation acrossmarketsonanightlybasis.
fatigueasspecificallythesecaseshavebeenpromi- Relevanceassessmentinproduction. Highrel-
nentlyandunambiguouslyfeaturedintheannota- evanceisanecessary,butnotasufficientcondition,
tionguidelines. forhighcustomerengagement,asitisalsodeter-
These findings suggest that LLMs might be a minedbyotherfactors,e.g. personalpreferences,
more reliable source for the bulk of annotations, productavailability,andpriceexpectations. Inthis
freeinghumanlabourtofocusontrickiercases.11 paper,wefocusonsemanticrelevance,butinpro-
Inthehuman-machinecollaborationspectrumin- ductionweranktheretrieveddocumentsbasedon
troduced by Faggioli et al. (2023), our approach variousfeaturestotakeintoaccountbothrelevance
can be classified as a ‚ÄúHuman Verification‚Äù (or tothequeryandcustomers‚Äôpersonalpreferences.
human-in-the-loop)approach. Currently,weusetheLLM-poweredevaluation
Subjective nature of relevance judgements. framework presented in this paper in production
Wefoundthathumandisagreementwasdominated tocontinuouslyperformrelevanceassessmentsat
by two main factors, (i) human errors due to an- scale. We typically focus on monitoring the per-
notationfatigueasdescribedabove12,and(ii)the formanceofhigh-volumequerieswithourframe-
inherentsubjectivenatureofthetask. Forthelatter, work. Additionally, weevaluate the retrievalper-
we attribute the source of disagreement to either formance for low-performing queries. We iden-
the ambiguity in the annotation guidelines (even tify such queries based on signals indicating low
comprehensiveguidelinescannotcoverallpossible relevance in top ranked results, such as low en-
cases),ortothesubjectivejudgementoftheanno- gagement with the result set and high friction in
tator.13 Ideally, the annotation guidelines should customer experience (e.g., a high reformulation
makethetaskasobjectiveaspossible;however,in rate15)orhighexitrate. Thisapproachenablesus
practice,thereisalwaysalevelofsubjectivity. to significantly reduce costs and to enhance cus-
Annotation time and cost. (M)LLMs are ap- tomerexperiencefasterbyprioritisingthequeries
proximately 100 to 1,000 times cheaper than hu- that need the most attention and optimising our
manannotators,andthetimerequiredtocomplete resourcesaccordingly.
all 20,000 annotations using (M)LLMs is signifi-
5 Conclusion
cantly smaller (around 20 minutes for (M)LLMs
comparedtoabout3weeksforhumanannotators).
Our novel evaluation method leveraging Multi-
Notethatseveralhumanannotatorsworkedineach
modal LLMs demonstrates a highly efficient ap-
group (i.e., ‚ÄúA1‚Äù and ‚ÄúA2‚Äù in Table 2), and the
proachtoassessinglarge-scaleIRsystemsinprod-
totaltimereportedinTable2isforannotatingall
uct retrieval. We introduce query-level annota-
query-productpairs. Thisexcludesthetimespent
tionguidelinesforcalibrationandutilisethemulti-
modalcapabilitiesoffoundationmodelstoassess
11Thistypicallyincludesnewtrendingtermsorstylesthat
LLMshavenotobservedyet,butalsoambiguousqueriessuch therelevanceofretrievedproductsforaquery. Our
asoldmoneyordarkacademia,thatspecifyafashionstyle.
12Infactwefoundthathuman-humanharddisagreements, 14https://platform.openai.com/docs/guides/batch
alsomakingupapprox.15%oftheannotateddata,werealso (accessedon2024-07-17)
primarily due to brand errors, product errors and category 15Thereformulationrateisthepercentageofqueriesthat
errors‚Äîthesametypesoferrorsthatwealsofoundwhen aremodifiedandresubmittedwithinthesamesearchsession,
comparingLLMandhumanharddisagreements. indicatinganinitialfailuretosatisfytheuser‚Äôsintentanda
13SeeAppendixEforexamples. subsequentattempttorefinethesearch.LLM-poweredframework,combinedwithcaching Roi Blanco, Harry Halpin, Daniel M Herzig, Peter
andparallelprocessing,leadstosignificantreduc- Mika,JeffreyPound,HenrySThompson,andThanh
TranDuc.2011. Repeatableandreliablesearchsys-
tionsinbothtimeandcost. Themethod‚Äôsscalabil-
temevaluationusingcrowdsourcing. InProceedings
ity,abilitytohandlemultilingualqueriesandprod-
ofthe34thinternationalACMSIGIRconferenceon
ucts,andsupportforcontinuousofflineevaluations ResearchanddevelopmentinInformationRetrieval,
arecrucialforlargeIRsystemsoperatingindiverse pages923‚Äì932.
markets. Experimental results, validated against
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
20,000humanannotations, confirmtheeffective-
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
ness and efficiency of our approach. A detailed
Neelakantan,PranavShyam,GirishSastry,Amanda
analysisofhumanand(M)LLMannotationsindi- Askell,etal.2020. Languagemodelsarefew-shot
catesthat(M)LLMsareamorereliablesourcefor learners. Advancesinneuralinformationprocessing
systems,33:1877‚Äì1901.
relevanceassessmentinlarge-scaleIRsystems. We
arecurrentlyleveragingthisframeworkinproduc-
Kuan-TaChen, OmarAlonso, MarthaLarson, andIr-
tiontocontinuouslyperformrelevanceassessments winKing.2016. Introductiontothespecialissueon
atscaleandmaintainahigh-qualityuserexperience. crowdinintelligentsystems.
Additionally,weutiliseitsoutputstotrain,evalu-
YanChen,ShujianLiu,ZhengLiu,WeiyiSun,Linas
ate, and analyse other components of our search
Baltrunas, andBenjaminSchroeder.2022. Wands:
andrankingsystems.
Dataset for product search relevance assessment.
In European Conference on Information Retrieval,
6 EthicsStatement pages128‚Äì141.Springer.
Our data collection process strictly adheres to
GuglielmoFaggioli,LauraDietz,CharlesL.A.Clarke,
the General Data Protection Regulation (GDPR) GianlucaDemartini,MatthiasHagen,ClaudiaHauff,
and other relevant data privacy and safety laws NorikoKando,EvangelosKanoulas,MartinPotthast,
BennoStein, andHenningWachsmuth.2023. Per-
within the European Union. We ensure that all
spectives on large language models for relevance
datautilised,includinghumanevaluationdata,is
judgment. InProceedingsofthe2023ACMSIGIR
anonymisedtosafeguardagainstthedisclosureof InternationalConferenceonTheoryofInformation
anypersonallyidentifiableinformation. Retrieval, ICTIR ‚Äô23, page 39‚Äì50, New York, NY,
USA.AssociationforComputingMachinery.
Wedonotsuggestreplacinghumanannotators
withlargelanguagemodels(LLMs). Instead,we
MarcoFerrante,NicolaFerro,andMariaMaistro.2017.
focusonleveragingthestrengthsofboth. Ouranal-
Aware: exploitingevaluationmeasurestocombine
ysis indicates that human annotators may make multipleassessors. ACMTransactionsonInforma-
errors due to annotation fatigue or lack of do- tionSystems(TOIS),36(2):1‚Äì38.
mainknowledge‚ÄîerrorsnotobservedwithLLMs.
Martin Halvey, Robert Villa, and Paul D. Clough.
Therefore, we recommend using LLMs for bulk
2015. Sigir 2014: Workshop on gathering effi-
annotationworkwhilereservinghumanexpertise cientassessmentsofrelevance(gear). SIGIRForum,
formorecomplexcases. 49(1):16‚Äì19.
Wearecommittedtoadvancingresponsibleand
Ron Kohavi, Roger Longbotham, Dan Sommerfield,
unbiased AI technologies and welcome any in-
andRandalMHenne.2009. Controlledexperiments
quiriesregardingtheethicalaspectsofourwork.
ontheweb: surveyandpracticalguide. Datamining
andknowledgediscovery,18:140‚Äì181.
References MatthewLeaseandEmineYilmaz.2013. Crowdsourc-
ingforinformationretrieval: introductiontothespe-
JoshAchiam,StevenAdler,SandhiniAgarwal,Lama
cialissue. Informationretrieval,16:91‚Äì100.
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
DiogoAlmeida,JankoAltenschmidt,SamAltman,
Adam Marcus, Aditya Parameswaran, et al. 2015.
ShyamalAnadkat,etal.2023. Gpt-4technicalreport.
Crowdsourceddatamanagement: Industryandaca-
arXivpreprintarXiv:2303.08774.
demic perspectives. Foundations and Trends¬Æ in
OmarAlonsoandStefanoMizzaro.2012. Usingcrowd-
Databases,6(1-2):1‚Äì161.
sourcingfortrecrelevanceassessment. Information
processing&management,48(6):1053‚Äì1066. Wendy W. Moe. 2003. Buying, searching, or brows-
ing: Differentiatingbetweenonlineshoppersusing
Jo Kristian Bergum. 2024. Improving retrieval with in-store navigational clickstream. Journal of Con-
llm-as-a-judge. Accessed: 2024-07-10. sumerPsychology,13(1-2):29‚Äì39.MaxwellNye,AndersJohanAndreassen,GuyGur-Ari,
Henryk Michalewski, Jacob Austin, David Bieber,
David Dohan, Aitor Lewkowycz, Maarten Bosma,
DavidLuan,etal.2021. Showyourwork: Scratch-
pads for intermediate computation with language
models. arXivpreprintarXiv:2112.00114.
OpenAI.2024. Hellogpt-4o. Accessed: 2024-07-17.
AlecRadford,JeffreyWu,RewonChild,DavidLuan,
DarioAmodei,IlyaSutskever,etal.2019. Language
modelsareunsupervisedmultitasklearners. OpenAI
blog,1(8):9.
Hossein A. Rahmani, Nick Craswell, Emine Yilmaz,
BhaskarMitra,andDanielCampos.2024. Synthetic
test collections for retrieval evaluation. Preprint,
arXiv:2405.07767.
MarkSandersonetal.2010. Testcollectionbasedeval-
uationofinformationretrievalsystems. Foundations
andTrends¬ÆinInformationRetrieval,4(4):247‚Äì375.
BeatrizSoviero,DanielKuhn,AlexandreSalle,andVi-
vianePereiraMoreira.2024. Chatgptgoesshopping:
Llms can predict relevance in ecommerce search.
In Advances in Information Retrieval, pages 3‚Äì11,
Cham.SpringerNatureSwitzerland.
KarenSpark-Jones.1975. Reportontheneedforand
provisionofan‚Äôideal‚Äôinformationretrievaltestcol-
lection. ComputerLaboratory.
Paul Thomas, Seth Spielman, Nick Craswell, and
BhaskarMitra.2023. Largelanguagemodelscanac-
curatelypredictsearcherpreferences. arXivpreprint
arXiv:2309.10621.
Shivani Upadhyay, Ehsan Kamalloo, and Jimmy
Lin. 2024. Llms can patch up missing rele-
vance judgments in evaluation. arXiv preprint
arXiv:2405.04727.
EllenMVoorhees.2001. Thephilosophyofinforma-
tionretrievalevaluation. InWorkshopofthecross-
languageevaluationforumforeuropeanlanguages,
pages355‚Äì370.Springer.
Haixun Wang and Taesik Na. 2024. Rethinking e-
commercesearch. SIGIRForum,57(2).
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. Advancesinneural
informationprocessingsystems,35:24824‚Äì24837.A MultimodalLLM-poweredrelevance B HumanAnnotationGuidelines
assessment: evaluationstepsforan
Forhumanannotators,wefocusedonthreeclasses:
examplequery
‚Ä¢ highlyrelevant: Theretrievedproductsatis-
fiesallthespecificationsinthequery.
Fig.4illustratesthevariousstepsofourevaluation ‚Ä¢ acceptablesubstitute: Theitemfulfilssome,
frameworkusingtheexamplequerywomen‚Äôslong but not all aspects of the query and the re-
sleevet-shirtwithgreenstripes. trieveditemcanbeusedasafunctionalsub-
Given this query, the LLM infers its require- stitute.
ments and their importance (Step 1 of our frame-
work, refer to Fig. 2). The outputs of this step ‚Ä¢ irrelevant: Acentralaspectofthequeryisnot
for the example query are detailed in the para- fulfilled (e.g. wrong brand, wrong category,
graph‚ÄúQueryrequirementsandtheirimportance‚Äù wrongproduct).
in Fig. 4b. As shown in Fig. 4b, the LLM has
We decided against a more granular annotation
inferredfourqueryrequirements: ‚Äúassortmentcat-
scale to reduce mental load on annotators and to
egory‚Äù, ‚Äúsleevelength‚Äù, ‚Äúproducttype‚Äùand‚Äúpat-
(hopefully)harnesshigheragreementscoresamong
tern‚Äù. Animportancelevelisalsoassignedtoeach
annotators.
requirement (in this case, the first three require-
Our annotation guidelines also reflect require-
mentsare‚Äúmust_have‚Äù,andthelastoneis‚Äúapprox-
ments that are more business-specific rather than
imate_is_okay‚Äù). Additionally,theLLMprovides
content-specific. For example, annotators have
areasonforeachrequirementanditsimportance
been explicitly briefed that if a query requests a
(not shown here). The LLM also translates the
specific brand (e.g. Polo Ralph Lauren jumpers),
queryintoEnglishandassignsa‚Äúspecificity‚Äùlevel,
any retrieved item that is not from the requested
asshowninFig.4b.
brandistoberegardedas‚Äúirrelevant‚Äù.
In panel (c), the translated query, its specificity,
Anotherbusiness-specificrulewasthatifaquery
itsrequirementsandtheirimportanceareusedto
requestsaparticularproduct(e.g. TheNorthFace
create query-specific annotation guidelines. The
1996retronuptsejacket),anyretrievedproductthat
three quality labels (i.e., ‚Äúirrelevant‚Äù, ‚Äúaccept-
isnotthatparticulartypeofTheNorthFacejacket
able_substitute‚Äù and ‚Äúhighly_relevant‚Äù) are pre-
istoberegardedas‚Äúirrelevant‚Äù.
defined. However, the guidance for each label is
Despitetheexplicitmentionsoftheserules,nu-
generated by the LLM. The LLM provides clear
merous provided examples across product cate-
and detailed descriptions for each relevance la-
gories,andanadditionalbriefingsessionafterthe
bel, tailored to the given query. In the ablation
annotation pilot phase, brand and product errors
studyofTable2,weassessedtheimpactofquery-
wereamongthemostcommonlymadehumanan-
specific annotation guidelines on our method‚Äôs
notationerrors.
performance. To do this, we replaced the query-
specificguidelineswithagenericone,asshownin
C ExperimentswithLLMtypes:
Fig.5.
GPT-3.5,GPT-4,andGPT-4o
InFig.4d,anexampleproduct,itsattributes,and
its image are shown. These attributes are read In this section, we compare human annotator
from an existing database and are not generated groupswith(M)LLMsusingdifferentarchitectures.
bytheLLM,exceptforthe‚Äúvisualdescriptionof TheresultsinTable3areprimarilybasedon‚ÄúGPT-
packshot‚Äù,highlightedbyaredrectanglewhichis 4o‚Äù (OpenAI, 2024), except for the row labelled
generated by a vision model (e.g., GPT-4o). The ‚ÄúMLLM-multi (gpt-4-turbo)‚Äù. For GPT-4 Turbo,
(M)LLMusesthequery-specificannotationguid- theagreementwithhumanannotatorswasconsis-
anceinpanel(c),alongwiththeextractedandgen- tently lower than that of GPT-4o, while its costs
erated product attributes in panel (d), to assign a and evaluation times exceeded those of all other
relevancelabel. Inthisexample,asshowninpanel architectures.
(e),thelabelis‚Äúhighly_relevant‚Äù,andthereason- In Table 4, we repeated the experiments using
ing(akathechain-of-thoughtstep)ofthe(M)LLM GPT-3.5Turbo. Asexpected,itsresultsweresig-
isshownforinspectionanddebuggingpurposes. nificantly worse compared to GPT-4o and GPT-4 Turbo, but its cost and time requirements were in the LLM prompt as well as the human annota-
lowerthanthoseoftheotherarchitectures. tionguidelines. Predominantly,thiserrorhasbeen
madebyhumanannotators(seeFig.3).
D LLMversusHumanerrortypes
6. LLM hallucination error. We rarely ob-
served hallucinations as a source of error. Inter-
After manually inspecting a sample of hard dis-
agreements16, we defined the following 9 error estingly,whenhallucinationsdidoccur,theywere
exclusivelyrelatedtosizequeries,suchast-shirt
classes, some of which are applicable to LLMs
xxl. Insuchcases,theLLMwouldhallucinatevar-
andhumans,andsometoLLMsonly:
ious available sizes for a given retrieved product
1. Branderror. Whenauserspecifiesabrand
andmakearelevancyjudgementonthebasisofits
name in the search query, e.g. Lee jeans, Nike
hallucinations.
sneakers,orMascaradresses,weconsideranyre-
trieved item as ‚Äúirrelevant‚Äù if it is not from the 7. LLM translation error. Since our dataset
requested brand. This is independent of whether containedGermanandEnglishqueries,theLLM
theretrieveditemwouldbevisuallysimilartothe waspromptedtotranslateaGermanqueryintoEn-
requestedone. Thisrequirementhasbeencovered glish before starting its reasoning process. This
in the LLM prompt as well as the human annota- sometimesresultedintranslationerrorsthatsubse-
tionguidelines. Predominantly,thiserrorhasbeen quentlyledtoincorrectrelevancyjudgements. For
madebyhumanannotators(seeFig.3). example, it happened for queries containing the
2. Producterror. Whenauserspecifiesaspe- termUnterziehhose,meaningsomesportsleggings
cificproductinthesearchquery,e.g. Levis501or onecanwearunderneathsportsshorts,whichthe
AdidasStanSmith,weconsideranyretrieveditem LLMincorrectlytranslatedasunderpants.
thatisnotexactlytherequesteditemas‚Äúirrelevant‚Äù. 8. LLMunderstandingerror. Thiserrorcat-
This requirement has been covered in the LLM egoryissomewhatbroader. Wewouldcategorise
promptaswellasthehumanannotationguidelines. an LLM error as understanding error, whenever
Predominantly,thiserrorhasbeenmadebyhuman theLLMmisinterpretedapartofthequeryorthe
annotators(seeFig.3). product. For example, this error occurred when
3. Toostrict. Thiserrorhappenedwhenaprod- theLLMwouldmisinterpretaqueryforNikeTech
uct was judged as ‚Äúirrelevant‚Äù for a given query FleecetobefocusedonthematerialwhereasTech
despitefulfillingalmostalltherequirementsofthe FleecetypicallyreferstoaparticularseriesofNike
query. This error has been predominantly made sports clothing. Another example is the misinter-
by LLMs (see Fig. 3), for example when a query pretation of brand names, such as for On Vaca-
requestedblackLevisjeanswithholes,butthere- tion(interpretedinitsliteralmeaning),orforEvry
trievedproductwasagreypairofLevisjeanswith Jewels(whereEvrywouldbeinterpretedtomean
holes, the LLM would typically annotate the re- Every). To our amusement during error analysis,
trievedproductsas‚Äúirrelevant‚Äù. wealsoobservedabrandmisinterpretationforthe
4. Too lenient. This error happened when a queryminiaturewinterjacketsforkids,whereMini
productwasjudgedas‚Äúhighlyrelevant‚Äùforagiven A Ture is a kids‚Äô clothing brand. The LLM inter-
query, despite not fulfilling all requirements that pretedminiatureinitsliteralsenseandreasoning
thequeryspecified. Thiserrorhasbeenexclusively that[...] thesizesavailableareforkids,whichfits
made by human annotators (see Fig. 3), for ex- the‚Äôminiature‚Äôrequirement.
amplewhereforaquerylikeNikeAirForceOne 9. LLMvisionerror. Someofourmodelsin-
high-top,humansannotatedaNikeAirForceOne cludedthevisualinterpretationofaproductimage
low-topsneakeras‚Äúhighlyrelevant‚Äù. in its relevancy assessment.17 We only rarely ob-
5. Category error. When a user specifies the servedLLMvisionerrors. Iftheydidoccur,itwas
category of a fashion item in the search query, typically when the product image was taken at a
e.g. dress, sneakers, belts, we consider any re- slight angle‚Äîfor instance, with a pair of sneak-
trieved item that does not match the category as ers where the LLM erroneously identified them
‚Äúirrelevant‚Äù. This requirement has been covered as high-top due to the photo angle. Errors were
alsomorelikelywhentheimageincludedahuman
16Weconsideraharddisagreementtobewhen,forexample,
model,whichactedasadistractor.
the LLM considers a product to be ‚Äúhighly relevant‚Äù for a
givenquery,whereasthehumanmajorityjudgementwouldbe
‚Äúirrelevant‚Äù,andviceversa.RefertoSection4fordetails. 17MLLM-textinTables2,3and4.E SubjectiveNatureofRelevance
Judgements
Thedifficultyinjudgingquery-productrelevancy
canvarywidely. Forexample,forqueriessuchas
Nike Air Max 95 or Paul Smith long sleeve polo
shirt, there is barely any room for subjectivity ‚Äî
the retrieved products either are matches, or they
arenot. Andindeed,thisisreflectedinthehuman-
humaninter-annotatoragreement(95%and82%,
respectively)andtheLLM-humanagreement(98%
and89%,respectively),forthesetwoexamples.
However, there are numerous queries that are
much more open to subjective judgement. One
such example is the query smart casual shoes,
wherethehuman-humanagreementwasonly12%
and the LLM-human agreement was 24%. The
rangeofsuitableproductsforthisqueryspansvari-
oustypesofshoes,andwhetherornotaparticular
shoe can be categorised as smart casual is typi-
cally not included in the product data. In these
cases, humans and LLMs would draw on their
priorknowledgeformakingarelevancejudgement.
LLMswouldgenerallybeastricterjudgeandcon-
sideranythingthatresemblesasneakertooclosely,
or is not in a shade of black or brown, as ‚Äúirrele-
vant‚Äù. Humanstrictnessforrelevancyjudgements
forthisqueryvariedbetweentheveryformaland
the(looselyspeaking)anythinggoesextremes.Youareanexpertquery-SKUrelevanceevaluator.Youwillbeprovidedwithaskudescription.Yourtaskistoevaluate
howcloselytheSKUmatchesthesearchquery.
(a)
Searchquery:women'slongsleevet-shirtwithgreenstripes
Querytranslated:women'slongsleevet-shirtwithgreenstripes
Queryspecificity:specific
Queryrequirementsandtheirimportance:
*assortmentcategory:women's|importance:must_have
*sleevelength:longsleeve|importance:must_have
(b)
*producttype:t-shirt|importance:must_have
*pattern:greenstripes|importance:approximate_is_okay
Annotationguidelines:
Youcanselectoneofthefollowingrelevancequalitylabels:
* irrelevant: Items that are not women's clothing, not t-shirts, or do not have long sleeves. For example, men's
t-shirts,women'sshortsleevet-shirts,orwomen'st-shirtswithoutanystripes.
* acceptable_substitute: Women's long sleeve t-shirts withasimilarpattern,suchasdifferentshadesofgreen
stripesoraslightlydifferentstripepattern. (c)
*highly_relevant:Women'slongsleevet-shirtswithgreenstripesthatmatchthequeryexactly.
Productinformation: (d)
[ArticleSKU]
*Description(fromproductpage):
name: [Brand Name] | color: evergreen | gender group: Women | age group: Adult |
silhouette code: t_shirt_top | product group: clothing | category tag: Long sleeved top,
Langarmshirt, Long sleeved top | fashion tags: shirt, knits, top, long sleeves, clothing |
material:rib|uppermaterial:elastane,cotton|shape:straight|fittaxonomy:RegularFit|
pattern: striped | size: L, M, S, XL, XS, XXL | occasion: leisure | neckline: crew neck |
clothinglength:normal|sleevelengthoption:long|fabricdefinition:knitted|
Visualdescriptionofpackshot:Thislong-sleevedtopfeaturesaclassichorizontalstripe
pattern in alternating white and green. The fabric has a ribbed texture,givingitasubtle,
snugfitthataccentuatesthewearer'sshape.Thenecklineisasimple,roundedcrewneck,
contributingtoatimelessandversatilelook.Itsoveralldesigniscasualyetstylish,perfect
foreverydaywear.; Vision model
Relevanceassessment: (e)
Relevancelabel:'highly_relevant'
Reasoning (chain-of-thought): The SKU description providedisforawomen'slong-sleevedtop,whichmatchesthe
'women's' and 'longsleeve'requirements.Theproducttypeisdescribedasa't-shirttop'and'longsleevedtop,'which
alignswiththe't-shirt'requirement.Thepatternisdescribedas'striped'withalternatingwhiteandgreen,whichmatches
the'greenstripes'requirement.Therefore,allmust-haveattributesandtheapproximateattributearemet.
Figure4: Evaluationstepsforanexamplequerywomen‚Äôslongsleevet-shirtwithgreenstripes. Theentirecontent
displayedinthisfigureisgeneratedbyMultimodalLLMs,exceptforpanel(a),thepackshotinpanel(d),andthe
blackdashedrectanglealsoinpanel(d). However,withintheattributesshowninpanel(d),the‚Äúvisualdescription
ofpackshot‚Äù,highlightedbyaredrectangle,isalsogeneratedbyavisionmodel(specifically,GPT-4owasusedin
thisinstance). Pleaserefertothetextforfurtherdetails. (Inthisexample,wehaveremovedthebrandnamefrom
theproductdescriptionandthetagonthepackshot.).DataScienceDays2024 PaperSubmission
<TABLES - 20240718>
table_20240715_gpt4o_with_without
INFO:
LLM_MODEL="gpt-4o"
LLM_VISION_MODEL="gpt-4o"
WITH:v202407110001
W/O:v202407110001_without
Agreementwith InterAnnotator
Figure5: Agenericannotationguidelineforthetaskofquery-productrelevanceassessment. Comparethistothe
Annotator A1ORA2(%) Agreement(%) Totaltime Cost
query-specificannotationguidelinesinpanel(c)ofFig.4.
EN DE EN DE EN DE EN DE
A1 76.6 75.9 60.2 60.5 3weeks ‚Ç¨15,000
A2 75.8 76.1 60.2 60.5 3weeks ‚Ç¨15,000
LLM-text 75.4 75.6 62.8 61.4 8min 7min ‚Ç¨70 ‚Ç¨70
MLLM-text 76.6 77.0 64.3 63.1 12min 13min ‚Ç¨92 ‚Ç¨93
MLLM-multi 78.1 78.4 65.6 64.7 10min 10min ‚Ç¨72 ‚Ç¨72
MLLM-multi 75.4 75.6 62.9 62.0 30min 23min ‚Ç¨155 ‚Ç¨156
(gpt-4-turbo)
Withoutquery-specificannotationguidance
LLM-text 71.2(-4.2) 67.0(-8.6) 57.6(-5.2) 52.2(-9.2) 7min 7min ‚Ç¨45 ‚Ç¨45
TMaLbLleM3-t:exAt greeme7n2t.s5(b-4e.1tw) e6e8n.0((M-9.0)L) L5M8.7a(-n5d.6)the53h.4u(m-9.a7n) a1n1nmointat1o1rmginroup‚Ç¨6s6(i.e.‚Ç¨,67A1,A2andtiebreaker). Similar
tMoLTLaMbl-meu2l,tibutwit7h4.a1d(-d4i.0ti)on7a1l.9c(o-6l.u5)mn6s1.s6h(-o4w.0)ing59t.h9e(-4a.g8)ree4mmeinnts4omfiAn1,A‚Ç¨225,an‚Ç¨d24thetiebreakergroupswithother
annotators. WereportagreementsseparatelyforEnglishandGerman. Forhumanannotations,wereportthetotal
timeandcost. WeuseGPT-4oinallstepsofourLLMannotationpipeline(Fig.2).
Agreementwith AgreementwithAgreementwith Agreementwith InterAnnotator
Annotator A1ORA2(%) A1(%) A2(%) Tiebreaker(%) Agreement(%) Totaltime Cost
EN DE EN DE EN DE EN DE EN DE EN DE EN DE
A1 76.6 75.9 - - 60.2 60.5 40.0 37.5 60.2 60.5 3weeks ‚Ç¨15,000
A2 75.8 76.1 60.2 60.5 - - 37.5 36.6 60.2 60.5 3weeks ‚Ç¨15,000
LLM-text 75.4 75.6 63.9 60.8 55.8 59.3 41.9 33.9 62.8 61.4 8min 7min ‚Ç¨70 ‚Ç¨70
MLLM-text 76.6 77.0 64.9 62.0 56.9 60.7 43.2 35.5 64.3 63.1 12min 13min ‚Ç¨92 ‚Ç¨93
MLLM-multi 78.1 78.4 66.0 63.1 58.2 62.0 43.9 37.4 65.6 64.7 10min 10min ‚Ç¨72 ‚Ç¨72
MLLM-multi 75.4 75.6 63.9 61.1 55.8 59.3 41.7 34.8 62.9 62.0 30min 23min ‚Ç¨155 ‚Ç¨156
(gpt-4-turbo)
Withoutquery-specificannotationguidance
LLM-textDataScien7c1e.2Day6s7.2002457.5 52.9 54.4 51.4 39.0 34.4 57.6 52.P2ape7rmSinubm7misisnion‚Ç¨45 ‚Ç¨45
MLLM-text 72.5 68.0 58.8 53.8 55.4 52.4 39.7 34.1 58.7 53.4 11min 11min ‚Ç¨66 ‚Ç¨67
MLLM-multi 74.1 71.9 61.1 57.1 56.3 56.4 41.9 42.3 61.6 59.9 4min 4min ‚Ç¨25 ‚Ç¨24
WITH:v202407110006
NOTE:Ihadtousethefew_shot_importance_requirement =
few_shot_importance_requirement_short otherwise,Iwouldgetlotsof
table_20240715_gpt35_4o_for_vision
errors
INFO:
WLL/MO_:MODEL="gpt-3.5-turbo-0125"
Table4: LikeTable3,exceptweuseGPT-3.5Turbo(specifically,‚Äúgpt-3.5-turbo-0125‚Äù)fortextinputsandGPT-4o
vL2L0M2_4V0I7S1IO1N00_M04O_DwEitLho=u"tgpt-4o"
forgeneratingtextualdescriptionsforimageinputs(Step4inFig.2). Here,wedonothave‚ÄúMLLM-multi‚Äùas
EN:LLM-text,MLLM-text
GPT-3.5Turbodoesnotacceptmultimodal(textandimage)inputs.
Agreementwith AgreementwithAgreementwith Agreementwith InterAnnotator
Annotator A1ORA2(%) A1(%) A2(%) Tiebreaker(%) Agreement(%) Totaltime Cost
EN DE EN DE EN DE EN DE EN DE EN DE EN DE
A1 76.6 75.9 - - 60.2 60.5 40.0 37.5 60.2 60.5 3weeks ‚Ç¨15,000
A2 75.8 76.1 60.2 60.5 - - 37.5 36.6 60.2 60.5 3weeks ‚Ç¨15,000
LLM-text 65.2 63.4 51.3 48.5 49.6 48.7 40.1 37.7 52.1 49.3 6min 6min ‚Ç¨6 ‚Ç¨6
MLLM-text 66.1 62.6 51.6 48.2 50.9 48.1 40.8 39.2 53.1 49.6 11min 11min ‚Ç¨24 ‚Ç¨25
Withoutquery-specificannotationguidance
LLM-text 59.1 57.0 43.9 43.0 46.5 42.8 41.1 47.9 47.6 46.3 4min 4min ‚Ç¨4 ‚Ç¨4
MLLM-text 60.1 57.2 45.0 42.9 47.4 43.4 41.9 50.2 48.9 47.4 9min 10min ‚Ç¨21 ‚Ç¨22