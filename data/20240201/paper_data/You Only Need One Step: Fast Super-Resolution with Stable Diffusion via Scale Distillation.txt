You Only Need One Step: Fast Super-Resolution with Stable Diffusion via Scale
Distillation
MehdiNoroozi,IsmaHadji,BraisMartinez,AdrianBulat,GeorgiosTzimiropoulos
SamsungAICambridge
m.noroozi@samsung.com
Abstract usually compromise performance, especially for the lower
numberofsteps.
In this paper, we introduce YONOS-SR, a novel stable Typically, diffusion-based models yield the best results
diffusion-based approach for image super-resolution that onimagepatchesofsimilarsizestothoseseenduringtrain-
yields state-of-the-art results using only a single DDIM ing (e.g. 64×64 for SD [22]). On the other hand, super-
step.Weproposeanovelscaledistillationapproachtotrain resolutionapplicationsrequireoperatinginhigh-resolution
ourSRmodel. InsteadofdirectlytrainingourSRmodelon settings, drastically exacerbating the computational issues
the scale factor of interest, we start by training a teacher of diffusion-based models. For example, a SR model that
modelonasmallermagnificationscale,therebymakingthe aims for a magnification of ×4 going from 256 × 256
SR problem simpler for the teacher. We then train a stu- to 1024×1024 requires dividing the input image into 16
dentmodelforahighermagnificationscale,usingthepre- patches of 64 × 64 and running the model on each patch
dictionsoftheteacherasatargetduringthetraining. This individually, making a large number of steps prohibitive
processisrepeatediterativelyuntilwereachthetargetscale forrealisticusecases. Usingstate-of-the-artstep-reduction
factorofthefinalmodel.Therationalebehindourscaledis- strategy, such as more efficient samplers [18, 19, 28] can
tillationisthattheteacheraidsthestudentdiffusionmodel partially alleviate this issue but still falls widely short of
trainingbyi)providingatargetadaptedtothecurrentnoise practical needs. For example, going down to the target of
levelratherthanusingthesametargetcomingfromground 1DDIMstepresultsinacatastrophicdropinperformance
truthdataforallnoiselevelsandii)providinganaccurate comparedtoatypicalmodelthatdoes200inferencesteps,
targetastheteacherhasasimplertasktosolve. Weempiri- asshowninFig.1.
callyshowthatthedistilledmodelsignificantlyoutperforms Onedifferentiatingcharacteristicofthesuper-resolution
themodeltrainedforhighscalesdirectly, specificallywith taskisthatitisconditionedonthelow-resolution(LR)in-
fewstepsduringinference.Havingastrongdiffusionmodel put image to yield the target high-resolution (HR) image.
that requires only one step allows us to freeze the U-Net Unlike the task of text-to-image generation, which relies
and fine-tune the decoder on top of it. We show that the ontextconditioning,theLRimageprovidesclosercontent
combinationofspatiallydistilledU-Netandfine-tunedde- to the target HR image, especially at lower scale factors.
coder outperforms state-of-the-art methods requiring 200 Therefore,conditioningthediffusionmodelontheLRim-
stepswithonlyonesinglestep. age at low-scale factors makes the task inherently simpler
for the diffusion model. In this paper, we take advantage
of this peculiarity and introduce a novel training strategy
1.Introduction dubbedscaledistillation. Whiletypicaldiffusion-basedSR
methodstrainthemodelforsuper-resolutionbycondition-
Diffusion models have shown impressive performance in ing directly on the LR image at the target scale factor, we
various image generation tasks [22, 40], including im- insteadproposeaprogressivetrainingapproach, wherewe
age super-resolution (SR) [3, 24, 25, 31]. However, the startbytrainingamodelforlowerscalefactors(i.e.where
large number of sequential denoising passes required by theconditioningsignalisclosertothetarget)andprogres-
thesamplingstrategyresultsinextremecomputationalcost, sivelyincreasetothetargetscalefactorusingthepreviously
evenforstablediffusion-basedmodels(SD)thatoperatein trainedmodelasateacher.
the latent space of an autoencoder. Recently, several ap- More specifically, instead of using the raw data to train
proacheshavebeenproposedtoreducethenumberofsam- a model for large scale factors, scale distillation obtains a
pling steps [18, 26, 28]. Unfortunately, such approaches richandaccuratesupervisorysignalfromateachertrained
4202
naJ
03
]VC.sc[
1v85271.1042:viXra×4 ×8 ×4 ×8 ×4 ×8
LR LR LR
1-stepSD-SR 1-stepSD-SR 1-stepSD-SR
200-stepSD-SR 200-stepSD-SR 200-stepSD-SR
1-stepYONOS-SR 1-stepYONOS-SR 1-stepYONOS-SR
GT GT GT
Figure 1. Qualitative comparison for ×4 and ×8 magnifications. Each column shows top to bottom LR input image, 1 and 200 step
SD-SR, and 1-step YONOS-SR(ours). SD-SR represents the standard Stable Diffusion-based SR model, whereas YONOS-SR is our
methodtrainedusingthesamedataandparameterization. The1-stepSD-SRmethodlacksqualityintermsofdetailedtexturescompared
to200-stepsofthesamemodel;seebuildingtextureinthefirstcolumnandhairsinthemiddlecolumn. Incontrast,ourproposedmethod
outperforms200-stepsSD-SRwithonlyonestepspecificallyfor×8magnificationwhereSD-SRfailstorecoverthedetailsevenwith200
steps.SamplesaretakenfromDIV2Kbicubicvalidationset.Theimagesarebestseeninadisplayandzoomedin.
---------------------------------------------------------------------------------------- ----------------------------------------------------------------------------------------forasmallerscalefactor. Wefirsttrainateacherthattakes andgeneralize. Forthisreason,realimagesuper-resolution
alessdegradedimageasinputand,therefore,hasaneasier (or blind super-resolution) has received significant interest
task to solve during training. Then, we train a model for amongtheresearchcommunity[11,16,31,32,35–37,39].
a larger scale factor as a student while initializing it with Whilesomemethodsattempttolearnthedegradationpro-
thesameweights astheteacher, whichis nowfrozen. For cess [5, 20, 30, 38], their success remains limited due to
agiventimestepduringthetraining, wefeedbothteacher thelackofproperlargescaletrainingdata[17],evenwhile
and student with the same noisy version of the HR image. using some unsupervised methods [42]. In contrast, more
However, we condition the teacher with the less degraded popularapproachestackletheproblembyexplicitlymodel-
LR image (i.e. using the same scale that was used during ingthedegradationpipelinetocreatesyntheticLR-HRpairs
teachertraining),whileweconditionthestudentonthetar- tousefortraining[15,27,36,39].Given,thewidersuccess
get (more degraded) LR image. We use the teacher’s pre- of the explicit degradation modeling approach, we elect to
diction as a target to train the student for the larger scale relyonthewidelyusedRealESRGANdegradationpipeline
factor. [36]intrainingourmodel.
Thistrainingstrategyhastwodirectadvantages: i)Un-
like typical training where the supervisory signal is some-
Diffusion-based super-resolution. Since the early SR-
whatambiguous asthe targetis thesamefor allnoise lev-
CNN [4] method, many deep learning-based solutions for
els, our student receives its target from the teacher and is
blind super-resolution have been proposed [2, 11, 22, 24,
thereforeadaptivetothenoiselevel. ii)Thetargetismore
25, 35, 36, 39, 42]. Early work proposed to take advan-
accurate,especiallyintermsofthefinerdetail,becausethe
tage of this space by using semantic segmentation prob-
teachertakesalessdegradedLRimageasinput.
ability maps for guiding SR [34]. Most recent meth-
The proposed scale distillation approach allows the
ods aim at taking advantage of learned generative priors
model to solve the SR task in fewer steps as we have sim-
to simplify the inverse imaging problem of blind image
plifiedthetaskforthestudent. Infact, weshowthatmod-
super-resolution. Usually,methodsfollowingthisparadigm
els trained with our approach improve significantly when
[35, 36, 39] rely on GANs [6] and build on their gener-
a few steps are used during the inference, e.g. one step,
ative priors. More recently, diffusion models showed re-
see Fig. 3. Therefore, a direct advantage of the proposed
markablegenerativecapabilitiesyieldingimpressiveresults
approach is that fine-tuning the decoder directly on top of
acrossarangeofapplications[22,40]. Assuch,inthispa-
thediffusionmodelbecomescomputationallytractabledue
per,wefollowseveralrecentworks[22,24,25,31]andrely
to the single inference step required. Taking advantage of
on diffusion-based generative models to tackle the super-
this fine-tuning, we show that You Only Need One Step
resolutionproblem. Whilediffusion-basedmodelsachieve
(YONOS)-SR outperforms state-of-the-art diffusion-based
impressive results, their main shortcoming is the long in-
SRmethodsthatrequirealargenumber(e.g.200)ofinfer-
ferencetime. Diffusion-basedmodelsrequireseveralinfer-
encesteps.
encestepsthroughthemodeltoyieldafinaloutput,thereby
Insummary,ourcontributionsarethreefold:I)Weintro-
limiting their practical use. Therefore, in this paper, we
ducescaledistillationtotrainSDmodelswithamoreaccu-
tackle the important problem of speeding up the inference
rate and fine supervisory signal for image super-resolution
ofdiffusion-basedsuper-resolution.
tasks. II)Weshowthatourproposedscaledistillationstrat-
egyyieldsmoreefficientSDmodelsthatallowfordirectly
Guided distillation. Recognizing the inference speed
fine-tuningthedecoderontopofafrozenone-stepdiffusion
shortcoming of diffusion models, several works have been
model. III) We show that combining scale distillation fol-
proposed recently to address this issue [18, 19, 21, 26,
lowedbydecoderfine-tuningwiththeU-Netfrozenyields
28]. These methods can be categorized into two main ap-
state-of-the-artresultsonthesuper-resolutiontask,evenat
proaches. One approach is to tackle this problem at in-
highmagnificationfactors,whilerequiringonlyonestep.
ference time by either proposing more efficient samplers
[12, 28] or relying on higher-order solvers [18, 19]. More
2.Relatedwork
closelyrelatedtooursaremethodsthataimatdirectlytrain-
Realimagesuper-resolution. Imagesuper-resolutionen- ingadiffusionmodelthatcansolvethegenerativeproblem
tailsrestoringaHighResolution(HR)imagegivenitsLow athandinfewerstepsthroughtemporaldistillation[21,26].
Resolution(LR)observation. Solvingthistaskforrealim- Our method tackles the problem at training time as well
ages is especially challenging given the dramatic differ- but we propose scale distillation, where our main idea is
ences in real-world image distributions [10, 11, 17, 37]. to reduce the inference speed by progressively making the
These differences arise from varying image degradation generativeproblemeasierduringtraining. Notably,ourap-
processes,differentimagingdevices,andimagesignalpro- proachisorthogonaltotemporaldistillationandcanbeused
cessingmethods,allofwhicharedifficulttoproperlymodel intandemwithit.3.YONOS-SR inthequalitativeexamplesofFig.1andquantitativeresults
ofFig.3.Severalmethodshavebeenproposedtoreducethe
In this section, we describe YONOS-SR, our diffusion-
numberofrequiredstepsatinferencetime[18,19,28]. We
based model for image super-resolution. First, we present
usethewidelyusedDDIMsamplerinthispaper[28], and
anoverviewoftheimagesuper-resolutionframeworkwith
unfortunately,weseethattheperformancedropsdrastically
thelatentdiffusionmodelsinSec.3.1. Wethendiscussour
withanextremelylownumberofsteps.Inthefollowing,we
proposedscaledistillationmethodthatallowsustoimprove
introducescaledistillationtoalleviatethisshortcoming.
the performance with fewer sampling steps, e.g. 1-step, in
Sec. 3.2. Finally, in Sec. 3.3, we discuss how the 1-step 3.2.Scaledistillation
diffusionmodelallowsforfine-tuningadecoderdirectlyon
Thecomplexityoftheimagesuper-resolutiontaskincreases
topofthediffusionmodel,withafrozenU-Net.
withthescalefactor(SF).Forexample,amodeltrainedfor
3.1.Super-resolutionwithlatentdiffusionmodels a lower SF (e.g. ×2) takes as input a less degraded image
compared to a larger SF (e.g. ×4). Therefore, a diffusion
Given a training set in the form of pairs of low and high-
model trained for ×2 magnification should require fewer
resolution images (x ,x ) ∼ p(x ,x ), the task of image
h l h l inferencestepstosolvetheHRimagegenerationtaskcom-
super-resolution involves estimating the probability distri-
paredtoamodeltrainedforthex4scalefactor.
bution of p(x |x ). The stable diffusion framework uses
h l Toalleviatethetrainingcomplexityforlargerscalefac-
a probabilistic diffusion model applied on the latent space
tors,webuildonthisobservationandproposeaprogressive
ofapre-trainedandfrozenautoendoer. Letusassumethat
scaledistillationtrainingstrategy. Inparticular,westartby
z = E(x ),z = E(x ) be the corresponding projection
h h l l trainingateacherforalowerSFthattakesalessdegraded
of a given low and high-resolution images (x ,x ), where
h l imageasinput.Wethenuseitspredictionasatargettotrain
E is the pre-trained encoder. The forward process of the
themodelforahigherfactorasastudent.
diffusion model, q(z|z ) is a Markovian Gaussian process
h
Let N be the target SF of interest. Standard training
definedas
involves making pairs of low and high-resolution images,
q(z |z )=N(z ;α z ,σ I),z={z |t∈[0,1]} (1) wherethelow-resolutionimageissmallerthantheHRim-
t h t t h t t
age by a factor of 1/N. The common approach for gener-
where z denotes the latent variable of the diffusion model atingthetrainingpairsistogatherasetofhigh-resolution
andα t,σ tdefinethenoiseschedulesuchthatthelogsignal- images, perform synthetic degradation to obtain the corre-
to-noise ratio, λ t = log[α t2/σ t2], decreases with t mono- sponding low-resolution image and train a model that di-
tonically. During training, the model learns to reverse this rectlyperforms×N magnification[22,31,36]usingeq.2.
diffusionprocessprogressively,i.e.estimatep(z t−1|z t),to Instead, we start with training a standard diffusion-based
generatenewdatastartingfromnoise. teacher that performs a lower SF, which takes a less de-
The super-resolution objective function is derived by gradedLRimage,e.g.2/N,asinputanduseitsprediction
maximizing a variational lower bound of the data log- totrainthestudent.
likelihood of p(z h|z l) via approximating the backward Moreprecisely,Letusassumezˆ ϕ,zˆ
θ
betheteacherand
denoising process of p(z h|z t,z l). Note that, for super- student denonising models parameterized by ϕ,θ respec-
resolution,thedenoisingprocessisconditionedonthelow- tively. To train the student for a factor of N, we generate
resolution input, z l, as well. This can be estimated by the twodegradedimagesforagivenhigh-resolutionimagewith
function zˆ θ(z t,z l,λ t) parametrized by a neural netowork. factors 1/N,2/N, with latent representations denoted by
Wecantrainthisfunctionviaaweightedmeansquareerror z ,z′respectively.Thatmeansz′islessdegradedcompared
l l l
loss. to z . Similar to the standard diffusion model training, we
l
sample random noise at t and add it to the high-resolution
imagetoobtainz . Thescaledistillationlosswillbe:
argmin E [ω(λ )||zˆ (z ,z ,λ )−z ||2] (2) t
ϵ,t t θ t l t h 2
θ
overuniformlysampledtimest ∈ [0,1]andz = α z + argmin E [ω(λ )||zˆ (z ,z ,λ )−zˆ (z ,z′,λ )||2] (3)
t t h ϵ,t t θ t l t ϕ t l t 2
σ ϵ, ϵ ∼ N(0,I). There are several choices of weight- θ
t
ing function ω(λ ). We use the so called v parameterzia-
t where the teacher is trained for N/2 magnification and
tion[26],(1+
α2
t),throughoutthispaper. frozen, and the student is initialized with the teacher’s
σ2
t
The inference process from a trained model involves a weightsbeforethetraining.Notethatweareusingthelatent
series of sequential calls, i.e. steps, of zˆ , starting from diffusionframeworkthatallowsexactlythesamearchitec-
θ
z ∼ N(0,I), where the quality of the generated image ture and input shapes for both the teacher and the student.
1
improvesmonotonicallywiththenumberofstepsasshown Although the input low-resolution images for the studentAlgorithm 1 Scale Distillation Training. Given a set of
scale factors, e.g. {2,4,8}, we start by training a student
... ... forthefirstscaleusingtherawdata(line23)initializedwith
the text-to-image weights(line 4). We then use the trained
studentasateachertotrainthenextdistillationiterationfor
a higher magnification(line 20). DEGRADE function de-
grades a given HR image with the given scale factor. RE-
SIZELIKEfunctionresizesagivenLRimagetothesame
sizeasthegivenHRimageusingthebicubicmethod.
... ... Input: datasetD
Input: noisescheduleα ,σ ,λ ▷fort∈[0,1]
t t t
Input: scalefactorsS ▷e.g. {2,4,8}
Input: initializationθ,ϕ ▷fromtext-to-image
Figure 2. Training pipeline of proposed scale distillation. For a fori∈[0,...,|S|]do
givenHRimage(e.g.size512×512)showningreen,wegenerate s←S[i]
twodegradedversionswithfactorsof2/N,1/N (e.g.sizes256× whilenotconvergeddo ▷studenttraining
256and128×128),showninyellowandredrespectively. Both t∼U[0,1]
degradedimagesareresizedbackviabicubicupsamplingto512× ϵ∼N(0,I)
512 to be used as input to the encoder, which projects them to
x ∼D
h
4×64×64tensors.ThelessandmoredegradedLRimageisused
x
l
← DEGRADE(x h,s)
asinputtotheteacherandstudentrespectivelyviaconcatenation
z ←E(x )
with the noisy version of the HR image, i.e. z . The teacher’s h h
outputisusedasthetargetfortrainingthestudet
nt. Notethatthe
z
l
←E(RESIZELIKE(x l,x h))
z ←α z +σ ϵ
teacher is first trained independently for a smaller magnification t t h t
scaleandthenfrozenduringstudenttraining. ifi>0then
▷Obtainthetargetfromthepreviousscale
s′ ←S[i−1]
22 68 w w/ / od dis it si tll ia llati to in on 100 w w/ / od dis it si tll ia llati to in on x z′ l′ l ←← ED (E RG ER SA IZD EE L(x IKh E, (s x′) ′ l,x h))
z˜←zˆ (z ,z′,λ )
24 80 ϕ t l t
22 else
20 60 ▷Rawdataasatargetforthefirstteacher
18
40 z˜←z
16 h
endif
14 20
1 2 4 Num ×be8 r o 4f DDI1 M6 steps32 64 128 1 2 4 Num ×be8 r 8of DDI1 M6 steps32 64 128 θL θ ←← θω −(λ η∇t)∥zˆ Lθ(z t,z l,λ t)−z˜∥2 2
θ θ
endwhile
Figure 3. FID vs. number of DDIM steps on the DIV2K vali-
ϕ←θ
dation set obtained through bicubic degradation for ×4 and ×8
endfor
magnifications. Weuse×2 → ×4scaledistillationfor×4and
×2 → ×4 → ×8 for ×8 magnification, and compare with the
standardtrainingdirectlyfor×4and×8respectively. Allresults
are obtained using the original SD decoder. The model trained spective of the sampled time step t (see Eq. 2), both scale
withscaledistillationoutperformsthestandardtrainingwithlarge
and progressive temporal distillation rely on the teacher to
margin when using fewer steps for ×4. The gap between scale
provideasupervisorysignalspecificforstept (seeEq.3).
distillationandthestandardtrainingissignificantlyhigherfor×8
Inthisway,thesupervisorysignalisattunedtothespecific
andremainssteadyforlargenumbersstepsaswell.
denoisingstep,providingstableandconsistentsupervision
at every denoising step. Fig. 3 provides empirical support
andteacherareofdifferentsizes,theyarebothresizedtoa for our hypothesis. We observe a significant gap between
fixedsizeandfedtotheencoder, whichprojectsthemtoa the distilled model from ×2 to ×4 compared to the model
tensorwithafixedsizeof4×64×64. Fig.2andAlg. 1 thatisdirectlytrainedfor×4whenevaluatedwithfewin-
illustratetheproposedscaledistillationprocessindetail. ference steps. The gap shrinks as the number of steps in-
The idea of scale distillation is in line with that of pro- creasesandthequalitystartssaturating.
gressivetemporaldistillation[26].Whileastandarddenois- Similartothetemporalprogressivedistillation[26],the
ingmodelwouldonlyusethefinalimageasthetargetirre- proposedscaledistillationprocesscanbeappliediteratively
DIF DIFwithhigherscalefactorsateachtrainingstep. Thefirststu- the Real-ESRGAN degradation pipeline as our synthetic
dentisinitializedfromscratchandtrainedontherawdata, dataset. WealsoreportresultsonthestandardDIV2Kvali-
similartothestandardtraining. Consequently,thisstudent dationsplitwithbicubicdegradationsforcompleteness.For
becomes the new teacher for training the next scale factor. therealdataset,weuse128×128centercropsfromtheRe-
In this paper, we consider three distillation steps up to the alSR[11],DRealSR[37]andDPED-iphone[10]datasets.
scalefactorof×8startingfrom×2,i.e.×2 → ×4 → ×8.
As it is shown in Fig. 3, scale distillation is significantly
Evaluation metrics. We evaluate using various percep-
moreeffectivefor×8magnificationwheretheLRimageis
tual and image quality metrics, including LPIPS[41], FID
oflowerquality.
[9] (where applicable), as well as the no-reference image
qualitymetric,MUSIQ[14]. Forthesyntheticdatasets,we
3.3.Decoderfine-tuning
alsoreportPSNRandSSIM,forreference.
Whilescaledistillationimprovestheone-stepinferenceno-
ticeably,thereisstillagapbetweentheone-stepmodeland
Baselines. As the main contribution of our paper targets
thesaturatedperformancewithalargernumberofsteps,see
improving the inference process of diffusion-based super-
Fig.3. Tofillthisgap,weproposetofine-tunethedecoder
resolution, our main points of comparison are diffusion-
ontopofthefrozenone-stepdiffusionmodelresultingfrom
basedSRmodels,includingtherecentStableSRmodel[31]
scaledistillation. Thatis,aftertrainingthediffusionmodel,
andtheoriginalLDMmodel[22].
wefreezetheU-Net,applyoneDDIMstepforagivenLR
For completeness, we also include comparison to other
image,anduseitasinputtofine-tunethedecoderfortheSR
non-diffusion-based baselines, including; RealSR [11],
task.Weusetheoriginallossthathasbeenusedfortraining
BSRGAN [39], RealESRGAN [36], DASR [16] and Fe-
theautoencoder[22]. Importantly,thisfine-tuningstrategy
MaSR[2].
with the U-Net in place is only possible with a diffusion
model that can work properly with one step as enabled by
ourscaledistillationapproach;seeTable.4.Weempirically Results. Results summarized in Tab. 1 and 2 show
showthatthecombinationofourscaledistillationapproach that YONOS-SR outperforms all other diffusion-based SR
with decoder fine-tuning yields a one-step model that can methods, while using only one inference step, whereas
readily compete with models requiring a large number of other alternatives use 200 inference steps. These results
inferencesteps. highlighttheefficiencyofYONOS-SRinreducingthenum-
berofstepstoonewithoutcompromisingperformancebut
4.Experiments indeed improving it further. Also, our model outperforms
all considered baselines in 5 out of 7 metrics on the syn-
In this section, we evaluate our YONOS-SR against other
theticdataand4outof5metricsontherealdatasets.
methods targeting real image super-resolution at the stan-
dard ×4 scale factor in Sec. 4.1 and demonstrate that our 4.2.Generalizationtohigherscalefactors
proposed scale distillation approach generalizes to higher
We now evaluate the generalization capability of our pro-
scalefactorsof×8inSec.4.2. Wethenprovidequalitative
posedscaledistillationapproach. Tothisend,wetrainour
resultsfor×4and×8inSec.4.3. Finally,weperformab-
YONOS-SR model with one more iteration of scale distil-
lation studies in Sec. 4.4 to highlight the role of our main
lation,therebygoingfromamodelcapableofhandling×4
contributions.
magnificationsto×8magnifications. Wethenfine-tunethe
4.1.Evaluationonrealimagesuperresolution decoderontopoftheone-step×8diffusionmodel.Toeval-
uatethismodel,wefollowrecentwork[3],andevaluateon
WefirstevaluatetheperformanceofourproposedYONOS-
thesamesubsetofImageNetandFFHQfor×8magnifica-
SR model in the standard real image super-resolution set-
tion, i.e. 64×64 → 512×512. In particular, we select
tingtargeting×4scalefactor.
thesame1ksubsetofImagenettestsetbyfirstorderingthe
10k images by name and then selecting the 1k subset via
Datasets. Followingpreviouswork(e.g.[2,31,36,39]), interleaved sampling, i.e. using images of index 0, 10, 20,
weuseDIV2K[1],DIV8K[7],Flickr2k[29],OST[33]and etc. ToobtaintheLR-HRpairs,weuse×8averagepooling
asubsetof10KimagesfromFFHQtrainingset[13]totrain degradations. InthecaseofFFHQ,weusethefirst1kim-
our model. We adopt the Real-ESRGAN [36] degradation agesofthevalidationset. Wealsoevaluateusingthesame
pipelinetogeneratesyntheticLR-HRpairs. metricsandbaselinesreportedinthisrecentwork[3].
We then evaluate our model on both synthetic and real The results summarized in Tab. 3 demonstrate that our
datasets. Similarto[31], weuse3KLR-HR(128 → 512) proposedone-stepmethodgeneralizeswellto higherscale
pairs synthesized from the the DIV2K validation set using factors, where it is able to achieve good results in termsDatasets Metrics RealSR BSRGAN DASR Real-ESRGAN+ FeMaSR LDM StableSR YONOS(ours)
LPIPS↓ 0.5276 0.3351 0.3543 0.3112 0.3199 0.2510 0.3114 0.2620
FID↓ 49.49 44.22 49.16 37.64 35.87 26.47 24.44 26.14
DIV2KValid
MUSIQ↑ 28.57 61.19 55.19 61.05 60.83 62.27 65.92 68.35
RealESRGANdegradations
PSNR↑ 24.62 24.58 24.47 24.28 23.06 23.32 23.26 24.88
SSIM↑ 0.5970 0.6269 0.6304 0.6372 0.5887 0.5762 0.5726 0.6381
DIV2KValid LPIPS↓ - 0.2364 0.1696 0.2284 - 0.2323 0.2580 0.1534
bicubicdegradations PSNR↑ - 27.32 28.55 26.65 - 25.49 21.90 26.71
- #STEPS↓ - - - - - 200 200 1
Table1. Comparisontobaselinesonsyntheticdatasets. ResultshighlightedinRedandBluecorrespondtobestandsecondbestresults,
resp.Cellswith−indicatethattherewerenopreviouslyreportedresultsusingtheconsideredbaselineandthecorrespondingmetric.
Datasets Metrics RealSR BSRGAN DASR Real-ESRGAN+ FeMaSR LDM StableSR YONOS(ours)
LPIPS↓ 0.3570 0.2656 0.3134 0.2709 0.2937 0.3159 0.3002 0.2511
RealSR
MUSIQ↑ 38.26 63.28 41.21 60.36 59.06 58.90 65.88 69.20
LPIPS↓ 0.3938 0.2858 0.3099 0.2818 0.3157 0.3379 0.3284 0.3156
DRealSR
MUSIQ↑ 26.93 57.16 42.41 54.26 53.71 53.72 58.51 65.02
DPED-iphone MUSIQ↑ 45.60 45.89 32.68 42.42 49.95 44.23 50.48 58.76
- #STEPS↓ - - - - - 200 200 1
Table2.Comparisontobaselinesonrealdatasets.ResultshighlightedinRedandBluecorrespondtobestandsecondbestresults,resp.
Imagenet FFHQ traineddirectlyfor×8magnificationwithoutscaledistilla-
FID↓ LPIPS↓ PSNR↑ FID↓ LPIPS↓ PSNR↑
tionwiththreeiterationsofscaledistillation×2 → ×4 →
LDPS 61.09 0.475 23.21 36.81 0.292 28.78
GML-DPS[23] 60.36 0.456 23.21 41.65 0.318 28.50 ×8 in Fig. 5. Again, we use the validation set of DIV2K
PSLD[23] 60.81 0.471 23.17 36.93 0.335 26.62
bicubicdegradationdataset. Followingthenumericalanal-
LDIR[8] 63.46 0.480 22.23 36.04 0.345 25.79
P2L[3] 51.81 0.386 23.38 31.23 0.290 28.55 ysesinFig.3,weobservethatthemodeltrainedwithscale
YONOS(ours) 34.59 0.241 22.80 21.41 0.161 26.08 distillationoutperformsthestandardtrainingintermsofre-
covering the corresponding content and details. Note that,
Table 3. Comparison to baselines on ImageNet subset with x8
magnificationfactor. ResultshighlightedinRedandBluecorre- the problem of ×8 magnification is of significantly higher
spond to the best and second best results, resp. The results for complexitycomparedto×4duetopoorLRinput. Similar
othermethodsaretakenfrom[3]. toFig.3,weusetheoriginaldecoderheretoemphasizethe
impactofscaledistillation.
4.4.Ablationstudy
of FID and LPIPS scores, which are known to better align
withhumanobservation,especiallyathighermagnification
In this section, we aim to study the impact of the various
factors [24]. Notably, unlike baselines, our model has not
componentsintroducedinourapproach.Tothisend,weuse
beentrainedonImageNetdata. Weuseonly10kimagesof the standard DIV2K validation set with ×4 low-resolution
FFHQinourtrainingset.
images obtained through bicubic degradation [1]. We use
the FID metric as it is a standard metric for assessing the
4.3.Qualitativeevaluation
qualityofgenerativemodels. Ourinitialevaluationalsore-
In addition to extensive quantitative evaluations, we qual- vealedthattheFIDmetriccorrelatesthemostwiththehu-
itatively compare one-step YONOS-SR with 200-step Sta- manevaluationofthegeneratedimages. Thevalidationset
bleSRandstandarddiffusion-basedSR(SD-SR)inFig.4. oftheDIV2Kdatasetincludesonly100samples. Toobtain
OurmethodgeneratestheclosestSRimagestotheground morereliableFIDscores,weextract30random128×128
truthintermsofdetailedtextureswhiletakingonly1-step patchesandtheircorresponding512×512high-rescounter-
during the inference. These observations are in line with partsfromeachimageinthestandardDIV2Kbicubicvali-
thenumericalsuperiorityofourmethodinthequantitative dationset,resultinginatotalof3kLR-HRpairs. Forcom-
evaluationsabove. Weperformtwoiterationsofscaledis- pleteness,wealsoreportLPIPS,PSNR,andSSIMscores.
tillation×2 → ×4andfine-tunethedecoderontopofthe
1stepmodel. Impact ofscale distillation. We beginby evaluatingthe
AsitisclearlydemonstratedinFig.3, scaledistillation impactofourproposedscaledistillationonspeedingupin-
issignificantlymoreeffectivefor×8comparedto×4mag- ferencetime. Tothisend,weruntwostablediffusions(SD)
nification. Asaqualitativesupport,wecomparethemodel models trained for ×4 super-resolution (SR), with various(a) (b) (c) (d)
(a) (b) (c) (d)
(a) (b) (c) (d)
Figure4.QualitativecomparisononthevalidationsetofDIV2Kbicubicdegradationdataset:(a)200-stepStableSR(b)200-stepstandard
SD-SR(c)1-stepYONOS(ours)(d)thegroundtruth.SD-SRrepresentsthestandardStableDiffusion-basedSRmodel.200-stepStableSR
andSD-SRtendtoover-sharpen, addingartifactsthatdonotmatchthegroundtruthcontent. OurSRimagesmatchthemostwiththe
correspondinggroundtruthimage;seethefaces,Pepsi,andcrocodiletexturesinthefirst,second,andthirdrows,respectively.Theimages
arebestseeninadisplayandzoomedin.
numbersofinferencesteps.ThefirstmodelisastandardSD frozen teacher and use its prediction to train a student for
super-resolutionmodeltraineddirectlyfortarget×4super- ×4magnification. TheresultssummarizedinFig.3speaks
resolution (i.e. SD-SR), while the second model is trained decisively in favor of our scale distillation approach. We
withourproposedscaledistillationfrom×2magnification can see that for ×4 magnification, the model trained with-
to×4.Weusethesamemodel,trainingset,anddegradation outscaledistillationneedsatleasttwicethenumberofin-
pipelineintrainingbothmodels. Theonlydifferenceisthe ferencestepsthatthemodelwithscaledistillationneedsto
useofourscaledistillationinthelatermodel. Specifically, reach a similar performance when the number of steps is
westartwithtrainingateacherfor×2magnificationusing smallerthan16. Notably,wecanseethatourscaledistilla-
raw data as a denoising target. We use the ×2 model as a tionmodelisperformingespeciallywellwithaslittleasone(LR) (64steps) (4steps) (1step)
(HR) (64steps) (4steps) (1step)
(LR) (64steps) (4steps) (1step)
(HR) (64steps) (4steps) (1step)
Figure5. QualitativecomparisononthevalidationsetofDIV2Kbicubicdegradationdatasetfor×8magnificationwhenthemodelis
traineddirectlyfor×8magnificationwithoutscaledistillation(toprow)andwiththreeiterationsofscaledistillation×2 → ×4 → ×8
(bottomrow). WeshowtheinputLRimage,thecorrespondingHRimage,andresultswith1,4,and64stepsusingtheoriginaldecoder
forbothmodels. Themodeltrainedwithscaledistillationoutperformsthestandardtrainingwithhighmargins. Specifically,duetopoor
LRinput,thestandardtrainingfailstorecovertherelevantcontent.Theimagesarebestseeninadisplayandzoomedin.
RS-DS
noitallitsidelacS
RS-DS
noitallitsidelacS
8×tcerid
8×→4×→2×
8×tcerid
8×→4×→2×inferencestep,whereitoutperformsthenon-scaledistilled Decoder Original Fine-tuned
baselinebyatleast6points. Scaledistillation ✗ ✓ ✗ ✓
Scaledistillationoutperformsthestandardtrainingmore FID↓ 27.93 21.63 16.77 12.25
significantlyfor×8magnificationwhereweperformthree ×4 LPIPS↓ 0.227 0.210 0.162 0.145
training iterations for scale distillation, i.e. ×2 → ×4 → PSNR↑ 24.25 25.06 24.21 25.19
×8. One reason for the larger gap for ×8 magnification SSIM↑ 0.668 0.691 0.678 0.700
could be that the SR task is more ambiguous for ×8 mag- FID↓ 102.92 56.84 41.54 21.48
nificationduetolowerqualityinput. Asaresult,themodel ×8 LPIPS↓ 0.541 0.378 0.305 0.217
benefits more from the more simplified supervisory signal PSNR↑ 21.08 23.20 21.53 23.14
obtainedfromscaledistillation. Notethatweusetheorig- SSIM↑ 0.541 0.610 0.528 0.610
inal SD decoder model here only to analyze the impact of
thescaledistillationindependentlyofdecoderfine-tuning.
Table4. Roleoftheproposedscaledistillationanddecoderfine-
tuning.Allresultsreportedhereareobtainedwith1inferencestep.
Impactofdecoderfine-tuning. Oneofthedirectconse-
quences of having a diffusion model that can yield good
inverse imaging problems (e.g. image inpainting), which
results in one denoising step is that it allows for decoder we believe is an interesting direction for future research.
fine-tuningwiththeU-Netinplace, asitwilldirectlygive
agoodstartingpointtothedecoder. Tovalidatetheimpor-
tance of the input given to the decoder prior to fine-tuning References
and,thereby,theimportanceofYONOS-SR,weexperiment
[1] EirikurAgustssonandRaduTimofte. Ntire2017challenge
with the standard SD-SR model and our scale distillation
onsingleimagesuper-resolution:Datasetandstudy.InIEEE
model. In both cases, we freeze the U-Net and only allow
Conference on Computer Vision and Pattern Recognition -
themodelstodo1denoisingstep.Wethenfeedtheiroutput
Workshops,2017. 6,7
tothedecoderandfine-tuneitfollowingthesamelossused
[2] ChaofengChen, XinyuShi, YipengQin, XiaomingLi, Xi-
intheoriginalstablediffusionmodel[22].
aoguangHan,TaoYang,andShihuiGuo. Real-worldblind
TheresultssummarizedinTab.4validatetheimportance super-resolution via feature matching with implicit high-
ofhavingagoodinitialinputfromthediffusionmodelprior resolutionpriors. InACMInternationalConferenceonMul-
to decoder fine-tuning. As we can see in the left chunk of timedia,2022. 3,6
Tab.4,themodeltrainedwithscaledistillationoutperforms [3] Hyungjin Chung, Jong Chul Ye, Peyman Milanfar, and
the standard training with a good margin when using the MauricioDelbracio. Prompt-tuninglatentdiffusionmodels
originaldecoder,indicatingthatthescaledistillationresults forinverseproblems. InarXivpreprintarXiv: 2310.01110,
2023. 1,6,7
in a U-Net that provides a higher quality input for the de-
[4] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou
coder. Moreover,aswecanseeintherightchunkofTab.4,
Tang. Learning a deep convolutional network for image
fine-tuning the decoder on top of both 1-step models im-
super-resolution. InEuropeanConferenceonComputerVi-
provestheperformance.However,themodelwithscaledis-
sion,2014. 3
tillationyieldssignificantlybetterresultsthanthestandard
[5] ManuelFritsche,ShuhangGu,andRaduTimofte.Frequency
SD-SR directly trained for the target magnification. The
separationforreal-worldsuper-resolution. InIEEEInterna-
impactofscaledistillationismoresensiblefor×8magni- tional Conference on Computer Vision - Workshops, 2019.
ficationthan×4,whereFIDimprovesfrom41.54to21.48. 3
Importantly,thisfine-tuningstrategyisnotcomputationally [6] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
feasiblewithdiffusionmodelsthatrequiremanydenoising Xu,DavidWarde-Farley,SherjilOzair,AaronCourville,and
stepstogiveareasonablestartingpointforthedecoder. YoshuaBengio.Generativeadversarialnets.InAdvanceson
NeuralInformationProcessingSystems,2014. 3
5.Conclusion [7] ShuhangGu, AndreasLugmayr, MartinDanelljan, Manuel
Fritsche,JulienLamour,andRaduTimofte. Div8k: Diverse
In summary, in this paper, we introduced the first fast 8kresolutionimagedataset. InIEEEInternationalConfer-
stable diffusion-based super-resolution method. To enceonComputerVision-Workshops,2019. 6
achieve this, we introduced scale distillation, an approach [8] Linchao He, Hongyu Yan, Mengting Luo, Kunming Luo,
that allows us to tackle the SR problem in as little as Wang Wang, Wenchao Du, Hu Chen, Hongyu Yang, , and
one step. Having a fast diffusion model allowed us to Yi Zhang. Iterative reconstruction based on latent diffu-
directly fine-tune the decoder, which we show yields sionmodelforsparsedatareconstruction. InarXivpreprint
state-of-the-art results, even at high magnification factors arXiv:2307.12070,2023. 7
and only using a single step. We hope that the pro- [9] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner,
posed distillation approach could be adapted for other Bernhard Nessler, and Sepp Hochreiter. Gans trained by atwotime-scaleupdateruleconvergetoalocalnashequilib- Solvinglinearinverseproblemsprovablyviaposteriorsam-
rium. In Advances on Neural Information Processing Sys- plingwithlatentdiffusionmodels. InNeurIPS,2023. 7
tems,2017. 6 [24] HshmatSahak,DanielWatson,ChitwanSaharia,andDavid
[10] AndreyIgnatov,NikolayKobyshev,RaduTimofte,Kenneth Fleet. Denoising diffusion probabilistic models for robust
Vanhoey,andLucVanGool. Dslr-qualityphotosonmobile imagesuper-resolutioninthewild. InarXivpreprintarXiv:
deviceswithdeepconvolutionalnetworks. InIEEEInterna- 2302.07864,2023. 1,3,7
tionalConferenceonComputerVision,2017. 3,6 [25] Chitwan Saharia, Jonathan Ho, William Chan, Tim Sal-
[11] XiaozhongJi,YunCao,YingTai,ChengjieWang,JilinLi, imans, David J Fleet, and Mohammad Norouzi. Image
and Feiyue Huang. Real-world super-resolution via kernel super-resolution via iterative refinement. preprint arXiv:
estimationandnoiseinjection.InIEEEConferenceonCom- 2104.07636,2021. 1,3
puterVisionandPatternRecognition-Workshops,2020. 3, [26] TimSalimansandJonathanHo. Progressivedistillationfor
6 fastsamplingofdiffusionmodels. InInternationalConfer-
[12] AlexiaJolicoeur-Martineau,KeLi,Re´miPiche´-Taillefer,Tal enceonLearningRepresentations,2022. 1,3,4,5
Kachman,andIoannisMitliagkas. Gottagofastwhengen- [27] A.Shocher,N.Cohen,andMIrani. “zero-shot”superreso-
erating data with score-based models. In arXiv preprint lutionusingdeepinternallearning. InIEEEConferenceon
arXiv:2105.14080,2021. 3 ComputerVisionandPatternRecognition,2018. 3
[13] Tero Karras, Samuli Laine, and Timo Aila. A style-based [28] JiamingSong,ChenlinMeng,andStefanoErmon. Denois-
generatorarchitectureforgenerativeadversarialnetworks.In ing diffusion implicit models. In International Conference
IEEEConferenceonComputerVisionandPatternRecogni- onLearningRepresentations,2021. 1,3,4
tion,2019. 6 [29] Radu Timofte, Eirikur Agustsson, Luc Van Gool, MingH-
[14] Junjie Ke, Qifei Wang, Yilin Wang, Peyman Milanfar, and suanYang,andLeiZhang. Ntire2017challengeonsingle
FengYan. Musiq:Multi-scaleimagequalitytransformer. In imagesuper-resolution: Methodsandresults. InIEEECon-
IEEEInternationalConferenceonComputerVision,2021.6 ferenceonComputerVisionandPatternRecognition-Work-
[15] J. Liang, K. Zhang, S. Gu, L. Van Gool, and R. Timofte. shops,2017. 6
Flow-basedkernelpriorwithapplicationtoblindsuperreso- [30] Ziyu Wan, Bo Zhang, Dongdong Chen, Pan Zhang, Dong
lution. InIEEEConferenceonComputerVisionandPattern Chen,JingLiao,andFangWen. Bringingoldphotosback
Recognition,2021. 3 tolife. InIEEEConferenceonComputerVisionandPattern
[16] Jie Liang, Hui Zeng, and Lei Zhang. Efficient and Recognition,2020. 3
degradation-adaptive network for real-world image super- [31] JianyiWang,ZongshengYue,ShangchenZhou,KelvinCK
resolution. In European Conference on Computer Vision, Chan, and Chen Change Loy. Exploiting diffusion prior
2022. 3,6 for real-world image super-resolution. In arXiv preprint
[17] AnranLiu,YihaoLiu,JinjinGu,YuQiao,andChaoDong. arXiv:2305.07015,2023. 1,3,4,6
Blindimagesuperresolution:Asurveyandbeyond.InarXiv [32] Longguang Wang, Yingqian Wang, Xiaoyu Dong, Qingyu
preprintarXiv:2107.03055,2021. 3 Xu,JungangYang,WeiAn,andYulanGuo. Unsupervised
[18] ChengLu,YuhaoZhou,FanBao,JianfeiChen,Chongxuan degradation representation learning for blind superresolu-
LI, and Jun Zhu. Dpm-solver: A fast ode solver for dif- tion. InIEEEConferenceonComputerVisionandPattern
fusionprobabilisticmodelsamplinginaround10steps. In Recognition,2021. 3
AdvancesonNeuralInformationProcessingSystems,2022. [33] Xintao Wang, Ke Yu, Chao Dong, and Chen Change Loy.
1,3,4 Recovering realistic texture in image super-resolution by
[19] ChengLu,YuhaoZhou,FanBao,JianfeiChen,Chongxuan deepspatialfeaturetransform.InIEEEConferenceonCom-
Li,andJunZhu.Dpm-solver++:Fastsolverforguidedsam- puterVisionandPatternRecognition,2018. 6
pling of diffusion probabilistic models. In arxiv prepring [34] Xintao Wang, Ke Yu, Chao Dong, and Chen Change Loy.
arxiv:2211.01095,2023. 1,3,4 Recovering realistic texture in image super-resolution by
[20] Shunta Maeda. Unpaired image super-resolution using deepspatialfeaturetransform.InIEEEConferenceonCom-
pseudo-supervision. In IEEE Conference on Computer Vi- puterVisionandPatternRecognition,2018. 3
sionandPatternRecognition,2020. 3 [35] Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu,
[21] Chenlin Meng, Robin Rombach, Ruiqi Gao, Diederik Chao Dong, Yu Qiao, and Chen Change Loy. ESRGAN:
Kingma, Stefano Ermon, Jonathan Ho, and Tim Salimans. Enhancedsuper-resolutiongenerativeadversarialnetworks.
On distillation of guided diffusion models. In IEEE Con- In European Conference on Computer Vision - Workshops,
ferenceonComputerVisionandPatternRecognition,2023. 2018. 3
3 [36] Xintao Wang, Liangbin Xie, Chao Dong, and Ying Shan.
[22] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Real-ESRGAN: Training real-world blind super-resolution
PatrickEsser,andBjo¨rnOmmer.High-resolutionimagesyn- withpuresyntheticdata. InIEEEInternationalConference
thesiswithlatentdiffusionmodels. InIEEEConferenceon onComputerVision-Workshops,2021. 3,4,6
ComputerVisionandPatternRecognition,2022. 1,3,4,6, [37] PengxuWei,ZiweiXie,HannanLu,ZongYuanZhan,Qixi-
10 angYe,WangmengZuo,andLiangLin. Componentdivide-
[23] Litu Rout, Negin Raoof, Giannis Daras, Constantine Cara- and-conquerforreal-worldimagesuper-resolution.InEuro-
manis, and Alexandros G Dimakis andSanjay Shakkottai. peanConferenceonComputerVision,2020. 3,6[38] Y.Yan,C.Liu,C.Chen,X.Sun,L.Jin,X.Peng,andXZhou.
Fine-grainedattentionandfeature-sharinggenerativeadver-
sarial networks for single image superresolution. In IEEE
TransactionsonMultimedia,2021. 3
[39] KaiZhang,JingyunLiang,LucVanGool,andRaduTimo-
fte. Designingapracticaldegradationmodelfordeepblind
image super-resolution. In IEEE International Conference
onComputerVision,2021. 3,6
[40] LvminZhang, AnyiRao, andManeeshAgrawala. Adding
conditional control to text-to-image diffusion models. In
IEEE International Conference on Computer Vision, 2023.
1,3
[41] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shecht-
man, and Oliver Wang. The unreasonable effectiveness of
deepfeaturesasaperceptualmetric. InIEEEConferenceon
ComputerVisionandPatternRecognition,2018. 6
[42] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A
Efros. Unpaired image-to-image translation using cycle-
consistentadversarialnetworks. InIEEEInternationalCon-
ferenceonComputerVision,2017. 3