Adaptive Experiment Design with Synthetic Controls
Alihan Hüyük Zhaozhi Qian Mihaela van der Schaar
University of Cambridge University of Cambridge University of Cambridge
Abstract Individual treatment effect Average treatment effect for each SP
Clinical trials are typically run in order to
understand the effects of a new treatment on
0 0
a given population of patients. However, pa-
tients in large populations rarely respond the
same way to the same treatment. This het-
erogeneity in patient responses necessitates Subpopulation (SP) 1 Subpopulation (SP) 2 SP1 SP2 SP3 SP4 SP5 SP6 SP7 SP8
Patient Characteristics Patient Characteristics
trials that investigate effects on multiple sub-
ClinicalTrialA ClinicalTrialB
populations—especiallywhenatreatmenthas
SPsw/positiveeffect: None SP2&SP6
marginal or no benefit for the overall pop- #ofpatientsperSP: 50samples ∼12samples (outof100samples)
ulation but might have significant benefit
Figure 1: Tradeoff between individual benefit and
for a particular subpopulation. Motivated
cost. Consider two clinical trials that are both designed
by this need, we propose Syntax, an ex-
to confirm the effectiveness of a new treatment for one or
ploratory trial design that identifies subpopu- multiple subpopulations. While Trial A investigates only
lations with positive treatment effect among two candidate subpopulations, Trial B investigates eight.
many subpopulations. Syntax is sample effi- As a result, Trial B has the potential to succeed for two
subpopulations (SP2 & SP6) while Trial A is likely to fail cient as it (i) recruits and allocates patients
forall. However,TrialBneedstoallocatefewersamplesto
adaptively and(ii)estimatestreatmenteffects
eachsubpopulation,whichmakesconfirmingpositiveeffects
byformingsynthetic controls foreachsubpop- more challenging. We propose Syntax as an exploratory
ulation that combines control samples from pilot study that finds good subpopulations to target (such
other subpopulations. We validate the perfor- as SP2 & SP6) ahead of a confirmatory trial.
mance of Syntax and provide insights into
froma treatment aswell. This heterogeneityinpatient
whenitmighthaveanadvantageoverconven-
responses necessitates clinical trial designs that investi-
tional trial designs through experiments.
gatethetreatmenteffectnotonlyfortheoverallpopula-
tionbutalsoforvarioussubpopulations withinit(Chiu
1 Introduction
et al., 2018). Investigating multiple subpopulations at
once becomes especially important when a treatment
Randomized controlled trials (RCTs) remain an es-
onlyhasmarginalbenefitforthepopulationasawhole
sential part of evidence-based medicine (Sackett and
while it might have significant benefit for a particular
Rosenberg,1995)despitetheirrecognizedshortcomings
subpopulation(Moineddinetal.,2008;Lipkovichetal.,
(FeinsteinandHorwitz,1997). Manyoftheseshortcom-
2017). Declaringsuchatreatmenttobeineffectiveafter
ings are starting to be addressed by machine learning
a clinical trial that ignores heterogeneity might result
(Curth et al., 2023; Hüyük et al., 2023); in this paper,
in the treatment being needlessly denied to the sub-
wefocusonaspecificone: RCTstypicallyonlyconsider
population that would have actually benefited from it.
average treatmenteffectsacrossagivenpopulation,yet
patients in large populations rarely respond the same Running more “complex” trials that investigate larger
way to receiving the same treatment. Differences in ge- numbers of subpopulations provides an opportunity to
netics, environments, and clinical backgrounds among identify more personalized treatments for each subpop-
patients lead to differences in the benefit they receive ulation, rather than identifying one-size-fits-all treat-
ments that are supposed to be beneficial for everyone
Proceedings of the 27thInternational Conference on Artifi- (Wand et al., 2007; Lazar et al., 2016). However, such
cial Intelligence and Statistics (AISTATS) 2024, Valencia, trials also come with increased costs as dividing the
Spain. PMLR: Volume TBD. Copyright 2024 by the au- population into finer subpopulations naturally requires
thor(s).
more patients to be recruited into the trial when the
4202
naJ
03
]LM.tats[
1v50271.1042:viXra
tceffE
tnemtaerTAdaptive Experiment Design with Synthetic Controls
recruitment is done in a randomized manner (Brookes Contributions Our contributions are three-fold:
etal.,2004;Ondraetal.,2016). Whendetermininghow First, we outline a treatment effect estimator based on
many subpopulations a trial should investigate, there decomposing subpopulations into linear combinations
is a clear tradeoff between the benefit provided to the ofothersasinsyntheticcontrol. Withinthisestimator,
individual and the cost of running the trial (Figure 1). the unique decision between collecting new real data
vs. relying on synthetic controls is reflected by the fact
Motivatedbythisissue,weproposeSyntax(Synthetic
that we allow decompositions of a given subpopulation
Adaptive eXploration), an exploratory trial design for
to include the subpopulation itself.
subpopulation selection. Exploratory (Phase I & II)
trials are commonly run to establish a treatment’s Second, we provide an upper bound on the variance of
safety and to determine the correct dosage for the our proposed estimator (Proposition 1), which can be
treatment. In contrast, confirmatory (Phase III) trials tighter than the variance of a naive estimator based
aim to validate the efficacy of a treatment with type I on conventional controls (Proposition 2). This upper
error control. Syntax, as an exploratory (pre-Phase boundalsoestablishestherateatwhichdeviationsfrom
III, similar to Phase I & II) trial design, aims to find propercontrolsamples—infavorofsyntheticcontrols—
suitablepopulationsforwhichvalidatingefficacywould contribute to the error in estimating treatment effects.
be easier in a subsequent confirmatory trial. Specifi- Identifyingthisrateleadstoanimportantinsight: Dur-
cally, our objective is to identify subpopulations with ing an adaptive trial, constructing synthetic controls
positive treatment effect among a pre-determined set over collecting real control samples is the most effec-
of candidate subpopulations with a limited budget of tive when (latent) factors that lead to heterogeneity
samples—that is a limited number of patients that can in patient responses have a stronger effect during the
be recruited into the trial. While a conventional Phase pre-treatment period than the post-treatment period.
II trial determines the “right” dosage for a Phase III
Finally, making use of our upper bound, we propose a
trial, in a similar vein, Syntax determines the “right”
novel algorithm called Syntax that recruits patients
populations to target in a Phase III trial.
from candidate subpopulations and assigns them into
Our trial design has two key characteristics that con- control or treatment groups adaptively to identify sub-
tribute to its efficiency in identifying subpopulations: populations with positive treatment effect in a sample-
efficient manner. Although we motivate and formulate
(i) Syntax recruits patients and allocates them into
Syntax from the perspective of clinical trials, it re-
control or treatment groups adaptively, not ran-
mains generally applicable to any thresholding bandit
domly. This allows more samples to be allocated
problem with time-series contexts. Through numerical
into subpopulations that have higher variability in
experiments, we validate the performance of our algo-
their responses to the treatment.
rithm and provide insight into when it might have an
(ii) When estimating treatment effects, Syntax forms advantage over conventional trial designs.
synthetic controls for each subpopulation, by de-
composingthemintoalinearcombinationofothers, 2 Problem Formulation
instead of relying on control samples just from the
subpopulation itself. This allows information from We are given a pre-specified set of patient subpop-
controlsamplestobesharedbetweendifferentsub- ulations [K] = {1,2,...,K}. These subpopulations
populations and more samples to be allocated to could have been specified according to any arbitrary
the treatment group. criteria (for instance, according to biomarkers or ge-
ographical location). Each subpopulation i ∈ [K]
An important difference bears emphasis here: Conven- has known/observable features x
i
∈ RDx and un-
tionally, synthetic controls replace the control group in known/unobservable factor loadings z
i
∈RDz. As an
a trial outright, they are sourced from offline datasets
example,theoverallcardiovascularhealthofasubpopu-
collected ahead of the trial, and no new control sam-
lationcouldbealatentfactorthateffectsheart-related
ples are observed during the trial itself. In this work,
featuressuchasejectionfraction,heartrate,andblood
we consider synthetic control in an online context and
pressure. We let X =[x ···x ] and Z =[z ···z ].
1 K 1 K
investigate how they can still facilitate more efficient
Patients from population i, when they receive no treat-
use of the control samples that are being collected as a
ment, exhibit the baseline response with mean
trial continues. This setting is unique within the syn-
thetic control literature, as it requires an experimenter y¯ it =δ t+w tTx i+µT tz i for t∈[T] (1)
to decide continually for each subpopulation, whether where δ ∈ R determines the constant portion of the
t
to (i) collect new real data as controls, or (ii) rely on baselineresponse,w
t
∈RDx areweights thatdetermine
syntheticcontrolsconstructedfrompreviouslyobserved theportionbasedonfeatures,andµ
t
∈RDz arefactors
data for other subpopulations.
that determine the portion based on factor loadings.Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
Now, suppose a clinical trial is run over episodes where 3 Treatment Effect Estimation with
each episode corresponds to one sample or the recruit- Synthetic Controls
ment of one patient. At each episode η ∈ [H], the
experimenter first recruits a patient from some sub-
As it will become more aparent why in Section 4, effi-
population i[η]∈[K]. Then, they observe the baseline
cient exploration of the subpopulations and treatment
response of the patient they have recruited:
groups rely on forming estimators of the treatment
effects that have low variance. In order to find such
y [η]∼N (y¯ ) for t∈{1,...,T −1} (2)
t σ2 i[η]t estimators, we first start by analyzing the case where
where N (µ) is the normal distribution with mean µ recruitment decisions i[η],α[η] are made independently
σ2
andvarianceσ2. Thisiscalledthepre-treatmentperiod. from observed responses y t[η] so that the observed re-
Once the pre-treatment period ends at time t = T, sponses remain independent from each other—that
the experimenter assigns the recruited patient either is y t[η] ⊥⊥ y t′[η ′] if t ̸= t ′ or η ̸= η ′ for all time
to the control group, α[η] = 0, or to the treatment steps t,t ′ ∈ [T] and episodes η,η ′ ∈ [H]. For a given
group, α[η]=1. Depending on this assignment, they episode η, denote with
either continue observing the baseline response or they
(cid:88)
observe the response affected by the treatment: n( iα) = η′<η1{i[η ′]=i,α[η ′]=α} (5)
(cid:40)
y [η]∼
N σ2(y¯ i[η]T) if α[η]=0
(3)
the number of patients recruited from subpopulation i
T N (r +y¯ ) if α[η]=1 into treatment group α until that episode, and with
σ2 i[η] i[η]T
where r i is the treatment effect for subpopulation i. yˆ i( tα) =(cid:88) η′<ηy t[η ′]· 1{i[η ′]= ni (, αα )[η ′]=α} (6)
Objective The experimenter seeks to identify all of i
the subpopulations with positive treatment effect the empirical mean responses of those patients. Sim-
ilarly, denote with n = n(0) + n(1) the total num-
I ={i∈[K]:r >0} (4) i i i
∗ i ber of patients recruited from subpopulation i (re-
gardless of their treatment group) and with yˆ =
at the end of the episode horizon H, without knowing it
(yˆ(0)n(0) + yˆ(1)n(1))/n the empirical mean responses
parameters {δ t,w t,µ t} or observing factor loadings it i it i i
of those patients. We let N(α) = diag(n(α),...,n(α)),
{z i}. However, we assume that features x i are ob- 1 K
servedahead ofthe clinical trial. Denoting with Iˆ
∗
the N
[yˆ
= ··d ·i yˆag(n 1, ]. T. ,., an nK d) Yˆ, yˆ ·( Tα =) = [yˆ[yˆ 1(α T) ··· ·· y· ˆyˆ K(α T) ] ]T ., yˆ i ¬T =
experimenter’s best estimate of I , we measure their i1 i(T 1) T 1 T K T
∗ − ¬ ¬ ¬
successthroughtheir(i)true positive rate (TPR)given Ignoring any potential relationship between the re-
by ˆ∗ ∗/ ∗, and their (ii) false positive rate (FPR) sponses of different subpopulations, a naive estimate
|I ∩I | |I |
given by |Iˆ∗ ∩[K] \I∗ |/ |[K] \I∗ |. for the treatment effect r
i
can be written as
On Modeling Assumptions We formulated the
rˆnaive =yˆ(1)−yˆ(0) (7)
problemofsubpopulationselectionwithalinearmodel i iT iT
(cf. Equation 1) and normal error distributions (cf.
which is an unbiased estimate of treatment effects,
Equation2). Itshouldbeemphasizedthatthesearenot
E[r −rˆnaive]=0,andhasavarianceofV[r −rˆnaive]=
just arbitrary assumptions that we made because they i i i i
σ2(1/n(0) +1/n(1)). However, considering true mean
are common in the literature. Instead, they are careful i i
responses y¯ are related to each other as described
modelingdecisionsthatareparticularlysuitableforcap- iT
in (1), it should be possible to form other estimates
turingpopulation-leveleffectsastheunitsofinterestin
with tighter variances. Specifically, if the joint fea-
ourproblemhappentobepopulationsofpatientsrather
ture/factor space has lower dimensionality than the
than individual patients themselves. Regarding linear-
numberofsubpopulations—thatisD +D <K—one
ity, Shi et al. (2022) explain how linear relationships x z
can explore the feature/factor space more efficiently
can emerge on a population level when outcomes are
than the subpopulations themselves. Moreover, if the
averaged over multiple individuals, even when the gen-
pre-treatmentresponses{y } areobservedforatime
erative process for an individual is non-linear—briefly, t t<T
period long enough to infer unobserved factor loadings
this is due to the inherent linearity of the expecta-
{z }—that is T >D —such exploration could be fea-
tion operator. Similarly, error distributions for out- i z
sible. We aim to achieve this via synthetic control.
comes averaged over multiple individuals can be ap-
proximated as normal due to the central limit theorem. Synthetic Control Rather than using yˆ(0) as our
iT
We will evaluate the performance of Syntax under control when estimating r , we first decompose sub-
i
model mismatch—that is when the linearity in Equa- population i as a linear combination of other subpop-
tion 1 is violated—during our experiments in Section 6. ulations with weights β ∈ RK such that x = Xβ,
iAdaptive Experiment Design with Synthetic Controls
z ≈Zβ, and the elements of β sum up to one.1 Then, and notably, the deviations from the perfect represen-
i
(1) would imply that y¯ ≈ βTy¯ hence we can use tation are weighted by N 1 which corresponds to the
iT T −
βTyˆ(0) as our control instead. Th·is leads to a family uncertainty of observed responses Yˆ .
T T
of sy·nthetic estimators: ¬
Theremainingtermscapturetheepistemic uncertainty
rˆ i(β)=yˆ i( T1)−βTyˆ ·( T0) (8) o thf eyˆ i( fiT1) na an ld esyˆ ti·( T m0) aw tehic rˆh i(βar )e
.
c Eom vep nos we hd et nog βet ih ser at po ef ro ferm
ct
In Proposition 1, we show that synthetic estimators representation, the accuracy of rˆ(β) is limited by how
i
become unbiased when β satisfies verifiable conditions close yˆ(1) and yˆ(0) are to their ground-truth values.
iT T
that do not depend on unknown or unobservable quan- ·
Importantly, the trivial representation β =1 (of sub-
titiessuchasfactorsµ orfactorloadingsz . Moreover, i
t i populationiasitself)recoversthenaiveestimatein(7):
we provide an upper bound on their variance. As we
will argue next, synthetic estimators include the naive rˆ(1 )=rˆnaive (10)
i i i
estimate in (7) as well, moreover, the tightness of the
variance bound in Proposition 1 makes it possible to Moreover, when β = 1 , the representation error
i
findsyntheticestimateswithevenlowervariancesthan in V (β) vanishes and the epistemic uncertainty be-
i
the naive estimate. comes identical to the naive estimate’s variance—that
is V (1 )=V[r −rˆnaive]. This means that the family
Proposition 1. Assuming M T = [µ 1···µ T 1] has i i i i
full rank and T >D , we have¬E[r −rˆ(β)]=− 0 and of estimators rˆ i(β) not only include the naive esti-
z i i
mate but also the variance bound in Proposition 1 is
V[r −rˆ(β)] optimally tight for the naive estimate.
i i
≤V i(β;N(0),N(1)) Having made this important observation, the key idea
=. σ2(cid:0) 1/n(1)+∥β∥2 + λ∥β−1 ∥2 (cid:1) (9) behind Syntax is to search for β that leads to even
i (N(0))−1 i N−1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) tighter variance bounds V i(β). This can easily be
epistemicuncertainty representationerror achieved by solving the quadratic program
for λ=∥MT (M MT ) 1µ ∥2 when β is such that
x =Xβ, yˆ¬T =¬ YT ˆ ¬βT , a− nd T 1Tβ =1. β i∗ =argmin β:xi=Xβ,yˆi¬T=Yˆ ¬Tβ,1Tβ=1V i(β) (11)
i i T T
¬ ¬
Due to Proposition 1, it is guaranteed that rˆ(β ) has
i i∗
Proof. All proofs can be found in the appendix. varianceatleastassmallasthatofthenaiveestimator.
Proposition 2. V[r −rˆ(β )]≤V[r −rˆnaive].
i i i∗ i i
3.1 Interpreting Proposition 1
3.2 When is synthetic control the most
To gain a more intuitive understanding of the bound
effective in estimating treatment effects?
in Proposition 1, first consider the trivial decomposi-
tion of subpopulation i as itself—that is β =1 where
i Proposition 1 provides an intuition as to when syn-
(1 ) = 1{i = j}. Normally, having yˆ =Yˆ β
i j i T T thetic control might be themost effective inestimating
would not guarantee z =Zβ due to the o¬bserva¬tion
i treatmenteffects. Noticethat,inProposition1,therep-
noise. However, for the trivial decomposition uniquely,
resentation error contributes to the total variance pro-
weknowforcertainthatz i =Zβholds. Inotherwords, portionally to constant λ=∥MT (M MT ) 1µ ∥2.
β =1
i
is the only known representation of subpopula-
Earlier, we have discussed how
r¬eT pres¬enT tat¬ioT n− erroT
r is
tionithatisperfectly accurateeveninthelatentfactor
causedmainlyduetoamismatchbetweenasubpopula-
space. The representation error λ∥β−1 ∥2 takes
i N−1 tion’s factor loadings z i and the synthetic composition
deviationsfromthisperfectrepresentationintoaccount ZTβ. As such, it is no surprise that λ exclusively
when quantifying the variance of synthetic estimators.
depends on factors µ . Since
t
Syntheticcontrolreliesonmatchingobservedresponses
y sˆ ub chetw the ae tn yˆa sub =po Yˆpul βati ao sn iti la en ad dsit ts or aep nr ee ase rn mta at ti co hn iβ
n
λ=∥M ¬T T(M ¬TM ¬T T) −1µ T∥2 ≤( ∥µT∥/ ∥M¬T∥)2 (12)
i T T
terms of uno¬bservab¬le factor loadings z ≈Zβ as well, we also expect that λ—hence the contribution of repre-
i
sentation error to the total variance—is smaller when
1It is intentional here that x = Xβ, z ≈ Zβ and
i i post-treatment factors are small in magnitude (i.e.
not x = X β, z ≈ Z β. This is part of our con-
i ¬i i ¬i ∥µ ∥ is small) and pre-treatment factors are large
tribution: Unlike previous work on synthetic control, we T
allow weights β to include a subpopulation itself such that in magnitude (i.e. ∥M T∥).
¬
x = x β +X β , z ≈ z β +Z β . Of course, one
i i i ¬i ¬i i i i ¬i ¬i This makes intuitive sense as well: With synthetic con-
trivial β that satisfies this condition would be β = 1,
i
β = 0 (i.e. β = 1 ). However, as we will discuss next, trol, we are essentially trying to infer factor loadings
¬i i
alternative weights can lead to lower-variance estimates. z from pre-treatment responses {y } in order to
i t t<TAlihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
estimate the post-treatment responses y . During the Finally, when the experiment ends, Syntax simply re-
T
pre-treatment period, if the contribution of factors to turnsallsubpopulationsthathaveapositivetreatment
responses is stronger relative to the noise level—that effect estimate: Iˆ = {i ∈ [K] : rˆ(β )}. Note that,
∗ i i∗
is when ∥M ∥/σ is large—we expect our inference of computing V (β) hence sensitivity indices S requires
T i i
factor loadi¬ngs to be more accurate. Later, when we specifying λ. The ideal λ given Proposition 1 cannot
estimate the post-treatment response y , if the contri- be computed in practice as it depends on unknown
T
butionoffactorstothefinalresponseisnowweakerrel- factors µ , and we call it the factor effect parameter
t
ativetothenoiselevel—thatiswhen∥µ ∥/σissmall— due to this dependence.
T
weexpecttogainmorefromourearlierinferenceofthe
factor loadings compared with a naive estimate (which 5 Related Work
now has to detect a weaker signal without any addi-
tional information from the previous time steps t<T
Ourobjectiveinthispaperistoidentifysubpopulations
during the pre-treatment period). We will confirm this
with positive treatment effect given a fixed budget of
intuition empirically with simulations in Section 6.
samples. A trial designed to do so would consist of (i)
aninferencestrategy thatdictateswhichsubpopulation
4 Syntax is identified at the end of the trial, and (ii) a sampling
strategy that dictates how the samples are allocated
Making use of the synthetic estimator rˆ(β ) given betweendifferentsubpopulationsaswellascontroland
i ∗
by (11) and the upper bound on its variance given treatmentgroups. Ourtrialdesign,Syntax,happento
in Proposition 1, we propose Syntax described in combineinferencetechniquesfromthesynthetic control
Algorithm 1. It is an adaptation of the algorithm of literature and sampling principals originally developed
Locatelli et al. (2016) for solving thresholding bandit for solving thresholding bandit problems. Table 1 sum-
problems. At each episode η ∈[H]: marizes alternative trial designs one might consider,
which differ from Syntax in terms of their inference
(i) First, a sensitivity index is computed for each sub-
and sampling strategies. We give an overview of these
population i∈[K]:
alternative strategies in this section.
|rˆ(β )| |rˆ(β )|
S = i i∗ ≤ i i∗ (13) Synthetic Control It is not always practical to
i (cid:112)
V (β )
(cid:112)V[r
−rˆ(β )]
i i∗ i i i∗ perform large randomized trials or experiments to un-
Intuitively, the lower the sensitivity index of a derstand the effects of a treatment or an intervention.
subpopulation is, the harder it is to determine For instance, investigating the effects of new policies
whether its treatment effect is positive or not. targetinglargegeographicareas,oftenatthelevelofin-
dividual countries, is challenging. As an inference tech-
(ii) Then, the subpopulation i =argminS with the
∗ i nique,syntheticcontrol(AbadieandGardeazabal,2003;
lowest sensitivity index is determined and the pa-
Abadie et al., 2010, 2015) was first introduced to ad-
tient that is expected to cause the largest increase
dressthischallenge. Intypicalsyntheticcontrolstudies,
in S i∗ is recruited. the outcome observed for a single treated unit is com-
pared against a control unit that is synthetically gener-
Algorithm 1 Syntax
ated as a linear combination of other untreated units.
Parameters: Horizon H, factor effect parameter λ
More recently, Doudchenko et al. (2021) introduced a
Output: Subpopulations Iˆ with positive treat. effect
∗ trial design based on synthetic control, where treated
1: n i(α) ←0, yˆ i( Tα) ←0, yˆ i T ←0, ∀i∈[K],α∈{0,1} and untreated units are not fixed but rather chosen
2: for η ∈{1,2,...,H} d¬o by the designer before the experiment is run. Notably
3: i ∗ ←argmin i [K]S i though, their trial design does not adapt to the out-
4: i,α←argmin∈ i [K],α 0,1 comesobservedsequentiallyoncetheexperimentstarts.
min β:xi∈ ∗=Xβ,∈ yˆ{ i∗¬T} =Yˆ ¬Tβ,1Tβ=1 In contrast, Syntax recruits and assigns patients—
V i∗(β;N(0)+(1−α)1 i1 iT,N(1)+α1 i1 iT) which is akin to choosing which units will be treated—
5: Recruitfrompopulationiandtreatmentgroupα in a fully adaptive way. Farias et al. (2022) study the
6: Observe baseline outcomes y T =[y 1···y T 1]T adaptive use of synthetic controls but in a setting or-
and the¬final outcome− y T thogonaltoours: Theyconsidertreatmentassignments
7: n(α) ←n(α)+1 over time steps t for a single unit/patient whereas we
i i
8: yˆ i T ←yˆ i T +(y T −yˆ i T)/n i considerthetreatmentassignmentatafinaltimepoint
9: yˆ i( Tα¬) ←yˆ i( Tα)¬ +(y T −¬ yˆ i( Tα))/¬ n( iα) T for multiple units/patients over multiple episodes η.
10: end for
Thresholding Bandits As an online algorithm,
11: Iˆ ←{i∈[K]:rˆ(β )>0}
∗ i i∗ Syntaxiscloselyrelatedtothemulti-armedbanditlit-Adaptive Experiment Design with Synthetic Controls
Table 1: Comparison of related trial designs. Syntax makes inferences via synthetic control and recruits adaptively.
Approach Inference Strategy Sampling Strategy Related Work
Conventional studies Simple statistics Randomized –
Thresholding bandits rˆi=yˆ i( T1) −yˆ i( T0) Adaptive Locatelli et al. (2016)
Synthetic studies Randomized Abadie et al. (2015)
Synthetic control
Synthetic design Pre-planned Doudchenko et al. (2021)
Syntax rˆi=yˆ i( T1) −(β i∗=argmin βVi(β))Tyˆ ·( T0) Adaptive (Ours)
erature (e.g. Auer et al., 2002; Hüyük and Tekin, 2019, determine safe but effective dosage for treatments, and
2020,2021),andourobjectiveismostsimilartothatof Hüyük et al. (2023) consider the portfolio-level man-
the thresholding bandit problem (Locatelli et al., 2016; agement of trials. Notably, Atan et al. (2019); Curth
Zhong et al., 2017; Mukherjee et al., 2017; Tao et al., et al. (2023) also aim to identify subpopulations with
2019) and the good arm identification problem (Kano positive treatment effects but not in the setting where
et al., 2019; Katz-Samuels and Jamieson, 2020), which pre-treatment responses are available for all partici-
similarlyaimtoidentifyarmswithrewardshigherthan pants. Adaptive enrichment designs (Stallard et al.,
a given threshold among a set of candidate arms. Sub- 2014)performinterimanalysestoselectsubpopulations.
populations in our work can be thought of as arms However there, the focus is to seamlessly adapt the
in a thresholding bandit problem with one important inclusion criteria of a confirmatory trial without com-
caveat: While in thresholding bandits, each arm has promising its type I error rate. In contrast, we focus
only one reward distribution associated with it, in our purely on selecting subpopulations in an exploratory
setting, the treatment effect of each subpopulation de- trial that can then be targeted in a confirmatory trial.
pends on two response distributions that cannot be
sampled from simultaneously. Complicating matters 6 Experiments
further, while there are underlying relationships be-
tween the responses of different subpopulations for the Environments To confirm our earlier intuition in
control group as described in (1), no such relationship Section 3.2 about when synthetic control might be the
exists for the treatment group. most effective, we consider two types of environments:
Another related problem in the multi-armed bandit (i) Diminishing Factor Effects: Intheseenvironments,
literature is the best arm identification (BAI) problem the contributions of factors µ t to the baseline re-
(Bubeck et al., 2009; Audibert et al., 2010; Gabillon sponses gets weaker over time. Formally, we set
et al., 2011, 2012; Soare et al., 2014; Xu et al., 2018; µ t =(2−10t −T)µ′ t,whereµ′ t issampleduniformly
Alievaetal.,2021;Degenneetal.,2020). Inourcontext, at random from the unit ball in RDz.
BAI would correspond to finding the subpopulation
(ii) Increasing Factor Effects: In contrast to Dimin-
with the largest treatment effect. This objective is
ishing Factor Effects, in these environments, the
clinically less suitable as it is important to provide
contributions of factors µ to the baseline re-
t
the treatment to all patients who would benefit from
sponses gets stronger over time. Formally, we set
it, regardless of how little that benefit might be com-
µ = 10t Tµ′, where µ′ is sampled uniformly at
pared to other patients. Aside from “pure-exploration” rat ndom f− romt the unit bat ll in RDz.
problems such as thresholding bandits or BAI, there
are numerous other work on multi-armed bandits that Remember that we expect our gain from synthetic
focusonmaximizingthecumulativerewardinstead. In controltobelargerforDiminishingFactorEffects since
our context, this would correspond to maximizing the we infer factor loadings based on earlier responses—for
benefit received by all participant of a trial whereas which we would prefer factors to provide a stronger
clinical trials are usually exploratory in nature. signal—and we aim to estimate later responses—for
whichwewouldgainthemostfromourearlierinference
Adaptive Clinical Trials Finally,itshouldbemen-
if factors now provide a weaker signal that is harder to
tionedthatadaptivetrialdesignsthattargetobjectives
pick up with naive estimates. We set N =25, T =5,
other than ours exist. Lewis and Bessen (1990); White-
D =D =2. Notably,D +D <N andT >D . We
x z x z z
head(1997)considerwhentoterminateatrial,Huand
sampletheremainingparametersoftheenvironmentso
Rosenberger (1997); Berry (2006); Villar et al. (2015)
that x ∼N (0), z ∼N (0), δ ∼N (0), r ∼N (0),
ij 1 ij 1 t 1 i 1
maximizes the benefit for the recruited patients, Bhatt
and w is picked uniformly at random from the unit
t
and Mehta (2006) consider when to stop further inves- ball in RDx. We repeat all our experiments ten times
tigating one of two subpopulations, O’Quigley et al.
toobtainerrorbars. Duringeachrepetition,wesample
(1990); Riviere et al. (2014); Wages et al. (2015); Yan
a new environment and we average FPR and TPR of
et al. (2017); Shen et al. (2020); Lee et al. (2020, 2021)
all our benchmark algorithms over 1000 runs.Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
Table 2: Performance comparison of Syntax and benchmarking algorithms. Inline with our intuition from
Section 3.2, Syntax performs the best for Diminishing Factor Effects. Again inline with our intuition, it does not provide
any benefit for Increasing Factor Effects but still performs on par with Thresholding Bandits since synthetic estimators
have variances at least as low as the naive estimate (as stated in Proposition 2).
DiminishingFactorEffects IncreasingFactorEffects
H=200 H=400 H=200 H=400
Algorithm FPR TPR FPR TPR FPR TPR FPR TPR
Conventionalstudy 19.5% (0.2%) 80.7% (0.3%) 14.9% (0.3%) 85.4% (0.3%) 19.5% (0.2%) 80.7% (0.3%) 14.9% (0.3%) 85.4% (0.3%)
Thresholdingbandits 17.6% (0.4%) 82.6% (0.4%) 13.7% (0.4%) 86.4% (0.2%) 17.6%(0.4%) 82.6%(0.4%) 13.7%(0.4%) 86.4%(0.2%)
Syntheticstudy 16.7% (0.3%) 83.4% (0.3%) 12.5% (0.3%) 87.7% (0.2%) 19.5% (0.2%) 80.7% (0.3%) 14.9% (0.3%) 85.4% (0.3%)
Syntheticdesign 16.4% (0.4%) 83.8% (0.4%) 12.1% (0.4%) 88.2% (0.3%) 19.7% (0.4%) 80.5% (0.3%) 14.9% (0.3%) 85.4% (0.4%)
Syntax 14.6%(0.4%) 85.6%(0.3%) 11.0%(0.3%) 89.1%(0.2%) 17.5%(0.4%) 82.6%(0.3%) 13.7%(0.4%) 86.4%(0.3%)
0.275 Syntheticstudy 0.900 0.30 Thresholdingbandits 0.90
0.250 Syntheticdesign 0.875 Syntax 0.225 Syntax 0.850 0.25 0.85
0.200 0.825 0.80
0.175 0.800 0.20
0.150 0.775 Syntheticstudy 0.15 0.75
0.125 0.750 Syntheticdesign Thresholdingbandits
0.725 Syntax 0.70 Syntax
0.100 0.10
100 200 300 400 100 200 300 400 100 200 300 400 100 200 300 400
NumberofSamples(H) NumberofSamples(H) NumberofSamples(H) NumberofSamples(H)
(a) Synthetic Algorithms (b) Adaptive Algorithms
Figure 2: Comparison of (a) synthetic algorithms and (b) adaptive algorithms. Switching to a pre-planned
sampling strategy from an adaptive one or switching to a naive inference strategy from a synthetic one both cause FPR to
increase and TPR to decrease at comparable scales.
Benchmarks We adapt the alternative trial designs To understand how much impact each design aspect of
summarizedinTable1toourproblemsettingasbench- Syntax has on its performance, we compare all three
marks. Adapting Thresholding Bandits, when there synthetic algorithms in Figure 2a and the two adap-
are two response distributions associated with each tive algorithms in Figure 2b (for Diminishing Factor
subpopulation rather than a single reward distribution, Effects). These figures show how the FPR/TPR of
involves forming naive estimates as in (7). Synthetic different algorithms improve as the sample budget H
Design normally requires knowing the mean responses gets larger. We see that switching to a naive inference
forthepre-treatmentperiodbeforeformingafixedsam- strategyorapre-plannedsamplingstrategybothresult
pling plan. When adapting it, we allowed the sampling insimilarperformancedrops—indicatingthatsynthetic
plan to be updated using the latest empirical mean re- andadaptiveaspectsof Syntaxareequallyimportant.
sponsesyˆ(α) ateachepisode. However,unlikeSyntax,
i T Significance of the Main Results Looking at
Synthetic D¬esign still does not take the final responses
Table 2, the performance difference between Syntax
y into consideration when allocating samples. Details
T and a conventional RCT might not seem like much
regardingeachbenchmarkcanbefoundintheappendix.
at a first glance. After all, it is merely (!) a 5%
∼
Main Results Table 2 compares Syntax and other differenceintermsofFPR/TPRforDiminishingFactor
benchmarks in terms of their performance. We con- Effects with H = 200. However, the implications of
sider two metrics: (i) false positive rate (FPR), which this seemingly small difference are significant in the
is the proportion of subpopulations incorrectly iden- largercontextofclinicaltrials. Wehighlighttwopoints:
tified as having positive treatment effect among all (i) how hard it actually is to gain this 5% difference
∼
subpopulations with negative treatment effect, and (ii) and(ii)whattangiblebenefitsitwouldofferifthesame
true positive rate (TPR), which is the proportion of gain were to be realized in practice:
subpopulations correctly identifies as having positive
(i) Notice that the performance of a traditional RCT
treatment effect among all subpopulations with posi-
in terms of FPR/TPR also improves only by 5%
tive treatment effect. We see that our intuition from ∼
whenthesamplesizeisincreasedtoH =400. This
Section 3.2 holds: Syntax performs the best for Di-
meansthatachievingthesameperformancegainas
minishing Factor Effects. Although it does not provide
Syntax with a traditional RCT requires doubling
any additional benefit for Increasing Factor Effects, it
the size of the RCT—meaning just by allocating
still performs on par with Thresholding Bandits, which
control samples smartly, Syntax is able to match
relies on the naive estimate in (7). This is because
the performance of a trial that has double the size.
synthetic estimators given by (11) have variances at
least as low as the naive estimate (i.e. they are as (ii) A typical RCT costs 12-35 million USD, which
informative) as stated in Proposition 2. primarily scales with the number of patients in-
)RPF(etaRevitisoPeslaF )RPT(etaRevitisoPeurT )RPF(etaRevitisoPeslaF )RPT(etaRevitisoPeurTAdaptive Experiment Design with Synthetic Controls
Table 3: Performance comparison of Syntax and
0.625 benchmarking algorithms under model mismatch—
when outcomes are non-linear with respect to features.
0.600
H=200 H=400
0.575
Algorithm FPR TPR FPR TPR
Conventionalstudy
0.550 Thresholdingbandits C To hn rev se hn ot li don ina gls bt au nd dy its 1 19 7. .5 6% % ( (0 0. .2 4% %) ) 8 80 2. .7 6% % ( (0 0. .3 4% %) ) 1 14 3. .9 7% % ( (0 0. .3 4% %) ) 8 85 6. .4 4% % ( (0 0. .3 2% %) )
Syntax Syntheticstudy 18.1% (0.4%) 81.8% (0.3%) 14.2% (0.4%) 85.9% (0.3%)
0.525 Syntheticdesign 18.3% (0.5%) 82.0% (0.4%) 14.2% (0.4%) 85.8% (0.3%)
Syntax 16.2%(0.4%) 84.0%(0.4%) 12.9%(0.4%) 87.3%(0.3%)
0.500
Table 4: Performance comparison of Syntax and
0.475
benchmarking algorithms under model mismatch—
100 200 300 400 when the number of latent factors D z =T.
NumberofSamples(H)
H=200 H=400
Figure 3: Proportion of samples allocated to the
Algorithm FPR TPR FPR TPR
treatment group over the control group. By sharing Conventionalstudy 19.5% (0.2%) 80.7% (0.3%) 14.9% (0.3%) 85.4% (0.3%)
information between the control samples of different sub- Thresholdingbandits 17.6% (0.4%) 82.6%(0.4%) 13.7% (0.4%) 86.4%(0.2%)
Syntheticstudy 15.8% (0.3%) 71.2% (0.7%) 12.3% (0.3%) 74.9% (0.9%)
populations,Syntaxisableallocatemoreofitssamplesto Syntheticdesign 15.7% (0.3%) 71.5% (0.8%) 12.1% (0.3%) 75.0% (0.9%)
the treatment group compared with alternative designs. Syntax 14.1%(0.3%) 73.1% (1.0%) 11.1%(0.2%) 76.1% (1.0%)
volved (Moore et al., 2018), and takes 1-2 years, mismatch—specifically when the linearity assumption
where as much as 86% of trials get delayed due to in(1)isviolated(althoughitisanaturalassumptionto
failures to reach recruitment targets (Huang et al., makeinoursetting,see“OnModelingAssumptions” in
2018). Having the required number of samples ef- Section 2). This can only happen in two ways: (i) Out-
fectivelyhalvedbydesignslikeSyntaxwouldsave comes y might not be linear with respect to features
it
upwards of 17.5 million USD per trial—note that x . (ii) Outcomes y can always be expressed as a
i it
more than 9000 trials are launched each year in linear function of some latent factors z , however the
i
the US alone (World Health Organization)—and minimum number of factors needed to do so might be
help deliver much faster results. equal to the number of total time steps (i.e. D =T).
z
Similarly,the1-2%differencebetweenSyntaxandthe For the first scenario, we consider the same simulation
next best-performing benchmark, Synthetic Design, for setupasDiminishing Factor Effects butgeneratemean
Diminishing Factor Effects, translates into a significant outcomes according to equation
difference in terms of the sample size: Syntax with
H =150 achieves an FPR of 16.3% (0.4%) and TPR y¯ it =δ t+w tT(x2 i)+µT tz i for t∈[T] (14)
of 83.9% (0.2%)—the same performance as synthetic
instead, where x2 denotes the element-wise square of
design with H =200 but using 25% fewer samples. i
x . The results are given in Table 3. We see that all
i
Sample Allocation Characteristics We men- methodsbasedonsyntheticcontrol,including Syntax,
tioned how sharing information between the control naturally lose performance after this change. However,
samples of different subpopulations would allow more Syntax still outperforms all benchmarks.
samples to be allocated to the treatment group. Fig-
For the second scenario, we again consider the same
ure 3 shows the proportion of samples allocated to the
simulation setup as Diminishing Factor Effects but
treatment group by different algorithms (for Diminish-
ing Factor Effects). Indeed, Syntax allocates more of this time set D z =T. The results are given in Table 4.
We see that TPR of Syntax is more sensitive to this
itssamplestothetreatmentgroup. Proposition1might
change than its FPR. This observation is directly re-
provide insight into how this is achieved: The uncer-
lated to a balance between FPR-TPR. In all of our
tainty of the treated response of each subpopulation i
experiments, we fixed the threshold for declaring a
contributes directly to the variance of synthetic estima-
positive effect at zero (for instance, see line 11 in Algo-
tors through the term 1/n(1). Whereas, it is possible
i rithm 1). Adjusting this threshold would have tuned
to mitigate the uncertainty of baseline responses by
the balance between FPR nad TPR (higher thresholds
distributing its contribution among multiple different
would achieve better FPR but worse TPR). Fixing the
subpopulations—more precisely, min ∥β∥ ≤
β (N(0))−1
threshold at zero is a natural choice when all of our
∥1 ∥ =1/n(0). IncontrasttoSyntax,aconven-
i (N(0))−1 i benchmarks are based on unbiased estimates. Under
tional study allocates all samples uniformly at random
model mismatch however, synthetic inference becomes
and Thresholding Bandits distributes samples adap-
biased, theeffectofwhichisequivalenttochangingthe
tively among subpopulations but tends to not differen-
classification threshold. Since the FPR performance
tiate between different treatment groups.
stays better relative to the TPR performance, we can
Performance under Model Mismatch We also tell that the bias introduced happens to be negative
evaluate the performance of Syntax under model (equivalent to a higher classification threshold).
detacollAselpmaSfonoitroporP )n/)1(n(puorGtnemtaerTehtotAlihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
On Clinical Equipoise From the perspective of
Conventionalstudy 0.86
0.19 Thresholdingbandits 0.85 clinical equipoise, the use of adaptive trials, including
Syntax
0.18 0.84 Syntax, is understood to be situational (Palmer and
0.17 0.83 Rosenberger, 1999; Fillion, 2019). We emphasize that
0.16 0.82 Conventionalstudy running a Syntax-based clinical trial should only be
0.15 0.81 T Syhr ne ts aho xldingbandits considered if there is a genuine lack of information
0.14
10−3 10−2 10−1 100 101 102 10−3 10−2 10−1 100 101 102 to determine the target population for a promising
FactorEffectParameter(λ) FactorEffectParameter(λ)
(a) Diminishing Factor Effects, H =200 new treatment, especially when responses of different
subpopulations to the treatment are expected to be
0.15 Conventionalstudy 0.89 highly heterogenous. More specifically, the principle of
Thresholdingbandits
0.14 Syntax 0.88 clinical equipoise requires two conditions to be met: (i)
there should be uncertainty among clinicians regarding
0.13 0.87
the effectiveness of a treatment, and (ii) the results of
0.12 0.86 C To hn rev se hn ot li do in na gl bst au nd dy its a clinical trial should be convincing enough to resolve
0.11 Syntax
0.85 this uncertainty (Freedman, 1987; Miller and Brody,
10−3 10− F2 actor1 E0 ff− e1 ctPara1 m00 eter(λ)101 102 10−3 10− F2 actor1 E0 ff− e1 ctPara1 m00 eter(λ)101 102 2007). We examine Syntax on these tow axises:
(b) Diminishing Factor Effects, H =400
(i) Syntaxisanexploratorytrialdesignratherthana
Figure 4: Sensitivity of Syntax to parameter λ.
confirmatorytrialdesign. Thismeansthat,evenat
the end of a Syntax-based trial, there would still
SensitivitytotheFactorEffectParameter Tun-
be genuine uncertainty regarding the effectiveness
inghyper-parametersisageneralchallengethataffects
of the treatment for all subpopulations (hence the
all online algorithms, including Syntax, since in an
need for a subsequent confirmatory trial). At no
online setting, no a-priori data would be available to
point during the trial, Syntax assigns a patient
perform cross-validation. We run additional exper-
to a treatment that can readily be confirmed to
iments to evaluate the sensitivity of Syntax to its
be ineffective for them; and the first condition is
hyper-parameter λ for Diminishing Factor Effects by
maintained through the trial. Moreover, the ulti-
varying λ logarithmically from 0.001 to 100 (the ideal
mate goal of Syntax is to identify subpopulations
λ according to Proposition 1 varies between 0.1 and 1).
as the potential targets of a subsequent Phase III
The results are given in Figure 4. We see that Syn-
trial. As such, it would be in contradiction with
tax outperforms all of the benchmarks without the
the first condition to use Syntax when there is
hyper-parameter λ—namely Conventional Study and
already a clear candidate to target in such a trial.
Thresholding Bandits—for almost all configurations.
Aswealreadymentionedabove,theuseof Syntax
Notably, the performance of Syntax degrades only
should be reserved to the cases where there is dis-
when λ is exceedingly large and converges to that of
agreement in terms of which subpopulations would
Thresholding Bandits. This is because λ punishes the
be the most suitable targets of a Phase III trial.
errorsinsyntheticrepresentations(∥β−1 ∥). Asλgets
i
larger, Syntax reverts back to representing each sub- (ii) Being an exploratory trial design, Syntax cannot
population only as itself (β =1 ) and hence becomes resolve all uncertainties regarding the effectiveness
i
equivalent to Thresholding Bandits. ofatreatment. But,itcandeterminetheappropri-
atetargetpopulationforasubsequentconfirmatory
7 Conclusion trial,andtherebyhelpsatisfythesecondcondition.
AspointedoutbyChiuetal.(2018),aconfirmatory
We introduced Syntax, a clinical trial design that re- trialismorelikelytobeinconclusiveregardingsub-
cruits patients adaptively to identify subpopulations population effects when the potential heterogene-
withpositivetreatmenteffect. Aswealreadyarguedfor ity in patient responses is not taken into account.
in the introduction, running trials that take multiple
On Real-data Validation Areal-datavalidationof
populations into consideration is absolutely essential.
Syntaxwouldessentiallyrequirerunninganewclinical
By reducing the length of such trials through designs
like Syntax that seek to make more efficient use of trial. This would be infeasible (and potentially unethi-
cal) for a method development paper as ours. Hence,
sample would not only make multi-population trials
the standard approach to evaluating adaptive clinical
morefeasiblebutalsohelptreatmentgettothemarket
trial designs is only to use simulated data (e.g. Atan
sooner, benefiting the patients. Although we presented
etal.,2019;Curthetal.,2023;Hüyüketal.,2023),even
the problem mainly from a clinical trial perspective,
Syntax can generally be applied to any threshold- in the biostatistics literature (e.g. Friede et al., 2012;
Magnusson and Turnbull, 2013; Stallard et al., 2014;
ing bandit problem where time-series context (such as
Henning and Westfall, 2015; Rosenblum et al., 2016).
baseline responses) are available.
)RPF(etaRevitisoPeslaF
)RPF(etaRevitisoPeslaF
)RPT(etaRevitisoPeurT
)RPT(etaRevitisoPeurTAdaptive Experiment Design with Synthetic Controls
References Doudchenko, N., Khosravi, K., Pouget-Abadie, J., La-
haie, S., Lubin, M., Mirrokni, V., Spiess, J., and
Abadie,A.andGardeazabal,J.,“Theeconomiccostsof
Imbens, G., “Synthetic design: an optimization ap-
conflict: A case study of the basque country,” Amer.
proach to experimental design with synthetic con-
Econ. Rev., vol. 93, no. 1, pp. 113–132, 2003.
trols,” in Proc. 35th Conf. Neural Inf. Process. Syst.,
Abadie, A., Diamond, A., and Hainmueller, J., “Syn- 2021.
thetic control methods for comparative case studies:
Farias, V., Moallemi, C., Peng, T., and Zheng, A.,
Estimating the effect of California’s tobacco control
“Synthetically controlled bandits,” arXiv preprint
program,” J. Amer. Statist. Assoc., vol. 105, no. 490,
arXiv:2202.07079, 2022.
pp. 493–505, 2010.
Feinstein, A. R. and Horwitz, R. I., “Problems in the
Abadie, A., Diamond, A., and Hainmueler, J., “Com-
“evidence” of “evidence-based medicine”,” Amer. J.
parative politics and the synthetic control method,”
Med., vol. 103, no. 6, pp. 529–535, 1997.
Amer. J. Political Sci., vol. 59, no. 2, pp. 495–510,
2015. Fillion, N., “Clinical equipiose and adaptive clinical
trials,” Topoi, vol. 38, pp. 457–467, 2019.
Alieva, A., Cutkosky, A., and Das, A., “Robust pure
exploration in linear bandits with limited budget,” Freedman, B., “Equipoise and the ethics of clinical
in Proc. 38th Int. Conf. Mach. Learn., 2021. research,” New England J. Med., vol. 317, pp. 141–
145, 1987.
Atan, O., Zame, W. R., and van der Schaar, M., “Se-
quential patient recruitment and allocation for adap- Friede, T., Parsons, N., and Stallard, N., “A condi-
tive clinical trials,” in Proc. 22nd Int. Conf. Artif. tionalerrorfunctionapproachforsubgroupselection
Intell. Statist., 2019. in adaptive clinical trials,” Statistics in medicine,
vol. 31, no. 30, pp. 4309–4320, 2012.
Audibert, J.-Y., Bubeck, S., and Munos, R., “Best
arm identification in multi-armed bandits,” in Proc. Gabillon, V., Ghavamzadeh, M., Lazaric, A., and
Annu. Conf. Learn. Theory, 2010. Bubeck, S., “Multi-armed bandit best arm identi-
fication,” in Proc. Neural Inf. Process. Syst., 2011.
Auer, P., Cesa-Bianchi, N., and Fischer, P., “Finite-
time analysis of the multiarmed bandit problem,” Gabillon, V., Ghavamzadeh, M., andLazaric, A., “Best
Mach. Learn., vol. 47, pp. 235–256, 2002. arm identification: A unified approach for fixed bud-
Berry, D. A., “Bayesian clinical trials,” Nature Rev. get and fixed confidence,” in Proc. Neural Inf. Pro-
Drug Discovery, vol. 5, no. 1, pp. 27–36, 2006. cess. Syst., 2012.
Bhatt, D. L. and Mehta, C., “Adaptive designs for Henning, K. S. and Westfall, P. H., “Closed testing in
clinical trials,” New England J Med., vol. 375, pp. pharmaceuticalresearch: Historicalandrecentdevel-
65–74, 2006. opments,” Statistics in biopharmaceutical research,
vol. 7, no. 2, pp. 126–147, 2015.
Brookes, S. T., Whitely, E., Egger, M., Smith, G. D.,
Mulheran, P. A., and Peters, T. J., “Subgroup analy- Hu,F.andRosenberger,W.F.,The theory of response-
ses in randomized trials: Risks of subgroup-specific adaptiverandomizationinclinicaltrials. JohnWiley
analyses; power and sample size for the interaction & Sons, 1997.
test,” J. Clin. Epidemiology, vol. 57, pp. 229–236, Huang, G. D., Bull, J., McKee, K. J., Mahon, E.,
2004. Harper, B., Roberts, J. N., Team, C. R. P. et al.,
Bubeck, S., Munos, R., and Stoltz, G., “Pure explo- “Clinical trials recruitment planning: a proposed
ration in multi-armed bandit problems,” in Proc. framework from the clinical trials transformation
20th Int. Conf. Algorithmic Learn. Theory, 2009. initiative,” Contemporary clinical trials, vol. 66, pp.
74–79, 2018.
Chiu, Y.-D., Koenig, F., Posch, M., and Jaki, T., “De-
sign and estimation in clinical trials with subpopula- Hüyük, A. and Tekin, C., “Analysis of Thompson sam-
tion selection,” Statist. Med., vol. 37, pp. 4335–4352, pling for combinatorial multi-armed bandit with
2018. probabilistically triggered arms,” in Int. Conf. Artif.
Intell. Statist., 2019.
Curth, A., Hüyük, A., and van der Schaar, M., “Adap-
tivelyidentifyingpatientpopulationswithtreatment Hüyük, A. and Tekin, C., “Thompson sampling for
benefit in clinical trials,” in Int. Conf. Mach. Learn., combinatorial network optimization in unknown en-
2023. vironments,” IEEE/ACMTrans.Netw.,vol.28,no.6,
pp. 2836–2849, 2020.
Degenne, R., Menard, P., Shang, X., and Valko, M.,
“Gamification of pure exploration for linear bandits,” Hüyük,A.andTekin,C.,“Multi-objectivemulti-armed
in Proc. 37th Int. Conf. Mach. Learn., 2020. bandit with lexicographically ordered and satisficingAlihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
objectives,” Mach. Learn., vol. 110, no. 6, pp. 1233– Mukherjee, S., Naveen, K. P., Sudarsanam, N., and
1266, 2021. Ravindran, B., “Thresholding bandits with aug-
mented UCB,” arXiv preprint arXiv:1704.02281,
Hüyük,A.,Qian,Z.,andvanderSchaar,M.,“Whento
2017.
make and break commitments?” in Int. Conf. Learn.
Representations, 2023. Ondra, T., Dmitrienko, A., Friede, T., Graf, A., Miller,
F., Stallard, N., and Posch, M., “Methods for identi-
Kano, H., Honda, J., Sakamaki, K., Matsuura, K.,
fication and confirmation of targeted subgroups in
Nakamura, A., and Sugiyama, M., “Good arm identi-
clinical trials: A systematic review,” J. Biopharma-
fication via bandit feedback,” Mach. Learn., vol. 108,
ceutical Statist., vol. 26, no. 1, pp. 99–119, 2016.
no. 5, pp. 721–745, 2019.
O’Quigley, J., Pepe, M., and Fisher, L., “Continual
Katz-Samuels, J. and Jamieson, K., “The true sample
reassessment method: A practical design for phase
complexity of identifying good arms,” in Proc. Int.
1 clinical trials in cancer,” Biometrics, vol. 46, pp.
Conf. Artif. Intell. Statist., 2020.
33–48, 1990.
Lazar,A.A.,Bonetti,M.,Cole,B.F.,Yip,W.,andGel-
Palmer, C. R. and Rosenberger, W. F., “Ethics and
ber, R. D., “Identifying treatment effect heterogene-
practice: Alternative designs for phase III random-
ity in clinical trials using subpopulations of events:
ized clinical trials,” Controlled Clin. Trials, vol. 20,
STEPP,” Clin. Trials, vol. 13, no. 2, pp. 169–179,
pp. 172–186, 1999.
2016.
Riviere,M.-K.,Yuan,Y.,Dubois,F.,andZohar,S.,“A
Lee,H.-S.,Shen,C.,Jordon,J.,andvanderSchaar,M.,
Bayesian dose-finding design for drug combination
“Contextualconstrainedlearningfordose-fndingclin-
clinical trials based on the logistic model,” Pharma-
ical trials,” in Proc. Int. Conf. Artif. Intell. Statist.,
ceutical Statist., vol. 13, no. 4, pp. 247–257, 2014.
2020.
Rosenblum, M., Luber, B., Thompson, R. E., and
Lee, H.-S., Shen, C., Zame, W. R., Lee, J. W., and
Hanley, D., “Group sequential designs with prospec-
vanderSchaar,M.,“SDF-Bayes: Cautiousoptimism
tively planned rules for subpopulation enrichment,”
in safe dose-finding clinical trials with drug combi-
Statistics in medicine, vol. 35, no. 21, pp. 3776–3791,
nations and heterogenous patient groups,” in Proc.
2016.
Int. Conf. Artif. Intell. Statist., 2021.
Sackett, D. L. and Rosenberg, W. M. C., “On the
Lewis, R. J. and Bessen, H. A., “Sequential clinical
need for evidence-based medicine,” J. Public Health,
trialsinemergencymedicine,” Ann.EmergencyMed.,
vol. 17, no. 3, pp. 330–334, 1995.
vol. 19, no. 9, pp. 1047–1053, 1990.
Shen, C., Villar, S., Wang, Z., and van der Schaar,
Lipkovich, I., Dmitrienko, A., and D’Agostino Sr.,
M., “Learning for dose allocation in adaptive clinical
R. B., “Tutorial in biostatistics: Data-driven sub-
trials with safety constraints,” in Proc. Int. Conf.
group identification and analysis in clinical trials,”
Mach. Learn., 2020.
Statist. Med., vol. 36, pp. 136–196, 2017.
Shi, C., Sridhar, D., Misra, V., and Blei, D. M., “On
Locatelli, A., Gutzeit, M., and Carpentier, A., “An op-
the assumptions of synthetic control methods,” in
timalalgorithmforthethresholdingbanditproblem,”
Proc. Int. Conf. Artif. Intell. Statist., 2022.
in Proc. Int. Conf. Mach. Learn., 2016.
Soare, M., Lazaric, A., and Munos, R., “Best-arm iden-
Magnusson, B. P. and Turnbull, B. W., “Group se-
tificationinlinearbandits,” inProc. Neural Inf. Pro-
quential enrichment design incorporating subgroup
cess. Syst., 2014.
selection,” Statist. Med., vol. 32, no. 16, pp. 2695–
2714, 2013. Stallard, N., Hamborg, T., Parsons, N., and Friede, T.,
“Adaptivedesignsforconfirmatoryclinicaltrialswith
Miller, F. G. and Brody, H., “Clinical equipoise and
subgroup selection,” J. Biopharmaceutical Statist.,
the incoherence of research ethics,” J. Med. Philos.,
vol. 24, no. 1, pp. 168–187, 2014.
vol. 32, pp. 151–165, 2007.
Tao,C.,Blanco,S.,Peng,J.,andZhou,Y.,“Threshold-
Moineddin,R.,Butt,D.A.,Tomlinson,G.,andBeyene,
ing bandit with optimal aggregate regret,” in Proc.
J., “Identifying subpopulations for subgroup analysis
Conf. Neural Inf. Process. Syst., 2019.
in a longitudinal clinical trial,” Contemporary Clin.
Trials, vol. 29, pp. 817–822, 2008. Villar, S. S., Bowden, J., and Wason, J., “Multi-armed
bandit models for the optial design of clinical trials:
Moore, T. J., Zhang, H., Anderson, G., and Alexander,
Benefits and challenges,” Statist. Sci.: Rev. J. Inst.
G. C., “Estimated costs of pivotal trials for novel
Math. Statist., vol. 30, no. 2, p. 199, 2015.
therapeutic agents approved by the us food and
drug administration, 2015-2016,” JAMA internal Wages, N. A., Read, P. W., and Petroni, G. R., “A
medicine, vol. 178, no. 11, pp. 1451–1457, 2018. phase I/II adaptive design for heterogenous groupsAdaptive Experiment Design with Synthetic Controls
with application to a stereotactic body radiation monitoring/number-of-clinical-trials-by-year-
therapy trial,” Pharmaceutical Statist., vol. 14, no. 4, country-who-region-and-income-group.
pp. 302–310, 2015.
Xu,L.,Honda,J.,andSugiyama,M.,“Afullyadaptive
Wand, R., Lagakos, S. W., Ware, J. H., Hunter, D. J.,
algorithm for pure exploration in linear bandits,” in
andDrazen,J.M.,“Statisticsinmedicine—reporting
Proc. 21st Int. Conf. Artif. Intell. Statist., 2018.
of subgroup analyses in clinical trials,” New England
J. Med., vol. 357, no. 21, pp. 2189–2194, 2007. Yan, F., Mandrekar, S. J., and Yuan, Y., “Keyboard:
A novel Bayesian toxicity probability interval design
Whitehead, J., The design and analysis of sequential
for phase I clinical trials,” Clin. Cancer Res., vol. 23,
clinical trials. John Wiley & Sons, 1997.
no. 15, pp. 3994–4003, 2017.
World Health Organization. Number of clinical trials
by year, country, WHO region and income group Zhong, J., Huang, Y., and Liu, J., “Asynchronous
(1999-2022).AccessedonOct.5,2023.[Online].Avail- parallel empirical variance guided algorithms for
able: https://www.who.int/observatories/global- the thresholding bandit problem,” arXiv preprint
observatory-on-health-research-and-development/ arXiv:1704.04567, 2017.Alihan Hüyük, Zhaozhi Qian, Mihaela van der Schaar
A Proofs of Propositions
A.1 Proof of Proposition 1
Denotewithe(0) =yˆ(0)−y¯ ,e(1) =yˆ(1)−y¯ −r ,ande =yˆ −y¯ theobservationnoises. SimilartoAbadieetal.
iT iT iT iT iT iT i it it it
(2010), we start by showing that unobservable factor loadings z can be inferred through observable responses yˆ
i
if responses are observed for a long enough pre-treatment period. More specifically, a good match in terms of
responses yˆ =Yˆ β leads to a good match in terms of factor loadings z ≈Zβ. We have
i T T i
¬ ¬
0=yˆ −Yˆ β (15)
i T T
¬ ¬
=e −E β+y¯ −Y¯ β (16)
i T T i T T
¬ ¬ ¬ ¬
=e −E β+δ +WT x +MT z −(δ 1T+WT X+MT Z)β (17)
i T T T T i T i T T T
¬ ¬ ¬ ¬ ¬ ¬ ¬ ¬
=e −E β+MT (z −Zβ) (18)
i T T T i
¬ ¬ ¬
where (16) is due to (2), (17) is due to (1), and (18) holds if x =Xβ and 1Tβ =1. Hence,
i
z −Zβ =(M+ )TE (β−1 ) (19)
i T T i
¬ ¬
whereM+ =MT (M MT ) 1 istherightinverseofM . Notably,thisrightinverseexistsonlyifM hasfull
T T T T − T T
rank and¬T >D¬(i.e.¬when¬the pre-treatment period is lo¬ng enough). It is already possible to spot tha¬t the term
z
in (19) is the source of representation error in Proposition 1. This provides the insight that representation error
is essentially caused by the imperfect estimation of factor loadings z through noisy observations of responses yˆ.
i
With this result, we are now ready to characterize the estimation error r −rˆ(β) in terms of observation noises
i i
e ,e(0),e(1). We have
it iT iT
r −rˆ(β)
i i
=r −yˆ(1)+βTyˆ(0) (20)
i iT T
·
=r −(r +y¯ +e(1))+βT(y¯ +e(0)) (21)
i i iT iT T T
· ·
=−e(1)+βTe(0)−δ −wTx −µTz +βT(δ 1+XTw +ZTµ ) (22)
iT T T T i T i T T T
·
=−e(1)+βTe(0)+µT(z −Zβ) (23)
iT T T i
·
=−e(1)+βTe(0)+µT(M+ )TE (β−1 ) (24)
iT T T T T i
· ¬ ¬
where (21) is due to (3), (22) is due to (1), and (23) holds if x =Xβ and 1Tβ =1. Since e(0), e(1), and {e }
i iT iT it t<T
all have zero mean and are independent from each other, E[r −rˆ(β)]=0 and
i i
V[r −rˆ(β)]=E[(r −rˆ(β))2] (25)
i i i i
=E[(e(1))2]+E[∥β∥2 ]+E[∥µT(M+ )TE (β−1 )∥2] (26)
iT e( ·T0)(e( ·T0))T T ¬T ¬T i
≤E[(e(1))2]+E[∥β∥2 ]+∥M+ µ ∥2E[∥β−1 ∥2 ] (27)
iT e( ·T0)(e( ·T0))T ¬T T i E ¬T TE¬T
=σ2/n(1)+σ2∥β∥2 +λσ2∥β−1 ∥2 (28)
i (N(0))−1 i N−1
A.2 Proof of Proposition 2
Proposition 2 is a corollary of Proposition 1. We simply have
V[r −rˆ(β )]≤V (β ) (29)
i i i∗ i i∗
≤V (1 ) (30)
i i
=V[r −rˆnaive] (31)
i i
where (29) is due to Proposition 1 and (30) is by definition of β in (11).
i∗Adaptive Experiment Design with Synthetic Controls
B Benchmark Algorithms
Algorithm2summarizesallbenchmarks(exceptSyntax,whichisgiveninAlgorithm1instead). Wesetthefactor
effect parameter λ to its optimal value given in Proposition 1. This means the results we present are for perfectly
tuned version of each algorithm. All experiments are run on a personal computer with an Intel i9 processor.
Algorithm 2 Benchmarks
Parameters: Episode horizon H, factor effect parameter λ
Output: Subpopulations Iˆ with positive treatment effect
∗
1: n(α) ←0, yˆ(α) ←0, yˆ ←0, ∀i∈[K],α∈{0,1}
i iT i T
2: for η ∈{1,2,...,H} do¬
3: if Conventional Study or Synthetic Study then
4: Sample i,α uniformly at random from [K]×{0,1}
5: else if Thresholding Bandits then
6: i←argmin S naive =|rˆnaive|/(1/n(0)+1/n(1))1/2
i [K] i i i i
7: α←argmin∈ n(α)
α 0,1 i
8: else if Syntheti∈c{De}sign then
9: i,α←argmin max min
i ∈[K],α ∈{0,1
}
i∗ ∈[K] β:xi∗=Xβ,yˆi∗¬T=Yˆ ¬Tβ, V1 iT ∗β (= β1
;N(0)+(1−α)1 i1 iT,N(1)+α1 i1 iT)
10: end if
11: Recruit from population i and treatment group α
12: Observe pre-treatment outcomes y =[y ···y ]T and the final outcome y
T 1 T 1 T
13: n(α) ←n(α)+1 ¬ −
i i
14: yˆ(α) ←yˆ(α)+(y −yˆ(α))/n(α)
iT iT T iT i
15: yˆ ←yˆ +(y −yˆ )/n
i T i T T i T i
16:
end¬for ¬ ¬ ¬
17: if Conventional Study or Thresholding Bandits then
18: Iˆ ←{i∈[K]:rˆnaive >0}
∗ i
19: else if Synthetic Study or Synthetic Design then
20: Iˆ ←{i∈[K]:rˆ(β )>0}
∗ i i∗
21: end if