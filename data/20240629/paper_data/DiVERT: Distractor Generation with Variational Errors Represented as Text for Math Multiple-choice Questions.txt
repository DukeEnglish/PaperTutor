DiVERT: Distractor Generation with Variational Errors
Represented as Text for Math Multiple-choice Questions
NigelFernandez1*,AlexanderScarlatos1*,SimonWoodhead2,AndrewLan1
1UniversityofMassachusettsAmherst,2Eedi
{nigel,ajscarlatos,andrewlan}@cs.umass.edu, simon.woodhead@eedi.co.uk
Abstract one hand, they should correspond to clear errors
inthefactualrecallorreasoningprocessrequired
High-qualitydistractorsarecrucialtoboththe by the question’s task. On the other hand, these
assessmentandpedagogicalvalueofmultiple-
errorsshouldnotbetooobvioussuchthatnostu-
choice questions (MCQs), where manually
dent would select the distractors. Therefore, de-
crafting ones that anticipate knowledge defi-
signinghigh-qualityMCQsthatmeasurespecific
cienciesormisconceptionsamongrealstudents
knowledgecomponents/concepts/skillsandmore
is difficult. Meanwhile, automated distractor
generation,evenwiththehelpoflargelanguage importantly,correspondingdistractorsgoodatcap-
models(LLMs),remainschallengingforsub- turingspecificknowledgedeficienciesamongreal
jectslikemath. Itiscrucialtonotonlyidentify students/testtakersisveryimportanttothedevel-
plausibledistractorsbutalsounderstandtheer-
opmentofhigh-qualityMCQs.
rorbehindthem.Inthispaper,weintroduceDi-
ThetypicalapproachtoMCQdistractordevel-
VERT(DistractorGenerationwithVariational
opmentprimarilyreliesonextensivehumaneffort,
Errors Represented as Text), a novel varia-
whichcanbeburdensomeforeducators,whichmo-
tionalapproachthatlearnsaninterpretablerep-
resentationoferrorsbehinddistractorsinmath tivatedthedevelopmentofautomated approaches.
MCQs. Throughexperimentsonareal-world Priorworkonautomateddistractorgenerationpri-
mathMCQdatasetwith1,434questionsused marilyfocusesoni)clozetasksinlanguagelearn-
byhundredsofthousandsofstudents,weshow ing to assess vocabulary recall or grammatical
thatDiVERT,despiteusingabaseopen-source
knowledge and ii) reading comprehension ques-
LLM with 7B parameters, outperforms state-
tionansweringtoassesscomprehensionofagiven
of-the-artapproachesusingGPT-4oondown-
textorarticle(Alhazmietal.,2024). Approaches
streamdistractorgeneration. Wealsoconduct
includeusingknowledgegraphs,encoder-decoder
a human evaluation with math educators and
findthatDiVERTleadstoerrorlabelsthatare models,andwithhelpfromlargelanguagemodels
ofcomparablequalitytohuman-authoredones. (LLMs). SeeSupplementaryMaterialAforamore
detailedreviewofrelatedwork.
1 Introduction
Forothersubjectswherecommontasksrequire
(possiblycomplex)reasoningability,suchasmath,
Multiple-choice questions (MCQs) are arguably
thereexistrelativelyfewapproachestoautomated
themostcommonformofquestionsfoundinstan-
MCQdistractorgeneration. Inthesedomains,gen-
dardizedtests. EachMCQcontainsaquestionstem
eratinghigh-qualitydistractorsismorechallenging
thatstatesthecontextofthequestionsandthetask
than in language learning or reading comprehen-
tobecompleted,andaseriesofoptions: akey,i.e.,
sion: distractorsneedtoreflectabstractmathemati-
thecorrectanswer,embeddedamongseveralother
calmisconceptionsand/orproceduralerrorsinthe
distractors, i.e., incorrect answers. See Figure 1
mathematicalreasoningprocess. Earlierworksei-
for an example. MCQs are widely used in real-
ther use symbolic, rule-based approaches to gen-
world,large-scaleeducational/psychologicaltests
eratedistractors(TomásandLeal,2013; Prakash
andsurveys,mainlyduetotheeaseinautomated
et al., 2023), which have limited generalizability
grading (Nitko, 1996; Airasian, 2001; Kubiszyn
beyondtemplate-basedquestions,orsampleincor-
andBorich,2016). However,constructingagood
rect generations during a math problem solving
setofdistractorscanbequitechallenging: Onthe
process as distractors (Dave et al., 2021). More
*Theseauthorscontributedequallytothiswork. recently,(Fengetal.,2024;Scarlatosetal.,2024)
4202
nuJ
72
]LC.sc[
1v65391.6042:viXra7
Soft Error Tokens e˜
18
…
Question Stem s
Controllable
Error Prior Model
Compute 7 ÷ 1 p(e|s) Distractor Gen Model
6 3
Error Identifier
p(d|s,e)
A)
21
C)
21 q(e|s,d)
e˜ e˜
18 6 Discrete Gradient Flow
7 8 Monte Carlo
B) D)
Sampled Sampling
18 9 Error ê
Distractor d Multiplies numerators
and denominators
Figure1: OverviewofDiVERT’svariationalpipelineforerrorexplanationanddistractorgenerationinmathMCQs.
investigateawidearrayofLLM-basedapproaches 2. WeaddinterpretabilitytoDiVERTbyusing
formathMCQgeneration,particularlyfocusingon LLMstoparameterizealldistributionsinour
theplausibilityofdistractors,i.e.,howlikelyisa variationalapproach. Thisdesignenablesus
distractorgoingtobeselectedamongrealstudents. torepresentandinterpreterrorsastexttokens.
However, to the best of our knowledge, no ex- 3. Weconductextensivequantitativeandqualita-
isting approach has attempted to generate expla- tiveexperimentsonareal-worldmathMCQ
nationsoferrorsunderlyingMCQdistractors. In dataset. WefindthatDiVERT,byjointlylearn-
assessment scenarios where one’s goal is to mea- ing to represent errors and generate distrac-
suretheoverallabilityofastudent/testtaker,being tors,outperformsstate-of-the-artapproaches
able to generate a good set of distractors may be ondistractorgeneration.
sufficient. However,inreal-worldeducationalsce- 4. We conduct a human evaluation with math
narioswhereone’sgoalistomaximizethelearning educatorsandfindthatDiVERTleadstoerror
gainofstudents,beingabletointerpretthecause explanationscomparableinqualitytohuman-
of error behind a distractor is highly important; authoredones,andsignificantlyoutperforms
thisinformationcanbeusedforstudentknowledge GPT-4-generatederrorsdespiteusingamuch
diagnosis, i.e., identifying areas where they lack smallerbaseLLMwith7Bparameters.
sufficientknowledge(VanLehn,1982)orevenpin-
2 ProblemFormulation
pointspecificmisconceptionstheyexhibit(Wang
et al., 2021). Such diagnosis can be used to pro- We denote each math MCQ as Q =
videfeedbacktobothteachers,tohelpthembetter {s,k,f,t,D,E}, which contains a set of
understandstudents’learningprogressanddirectly textual components, including the question stem
tostudentsinreal-time,throughintelligenttutoring s, the key k, (optionally) an explanation of the
systems(Ritteretal.,2007), onlinelearningplat- key f, (optionally) question topic/concept tags
forms(HeffernanandHeffernan,2014),orviachat- t, and a set of distractors D: we denote each
botspoweredbyLLMs(Academy,2024). There- distractor itself as d ∈ D, with e ∈ E denoting
i i
fore,interpretingtheerrorsbehindstudentsselect- theerrorexplanationassociatedwiththedistractor,
ingspecificdistractorsinmathMCQsisimportant e.g., a misconception. In this paper, we do not
yetchallenging,partlyduetothemathematicalrea- considerMCQswithfiguresordiagramssincethe
soningprocessesrequiredbythesequestions. open-sourceLLMsweworkwithcannotprocess
visual input. All of these textual components are
1.1 Contributions sequences of words and math symbols and we
1. WeintroduceDiVERT1 (DistractorGenera- denote them as a series of tokens {w 1,...,w L},
withLbeingthelengthofthesequence.
tion with Variational Errors Represented as
We study the task of learning an interpretable
Text),anovelvariationalapproachtojointly
spaceoferrorsbehinddistractorsinmathMCQs.
learnerrorrepresentationsinmathMCQsas
Sinceitisdifficulttoquantitativelyevaluateerror
wellasgeneratedistractorscorrespondingto
representations,wealsostudythedownstreamtask
errors.
ofdistractorgeneration(Fengetal.,2024). Specifi-
1Wewillmakeourcodepubliclyavailable. cally,ourtwomajorgoalsare:1. Errorgeneration: Fromasetofreal-world ationmodelgerr mustbeabletocapturethespace
math MCQs, learn an error representation ofallplausibleerrors,whichischallenging.
spaceunderlyingdistractors. Possibleerrors Toaddressthesechallenges,weuseavariational
include insufficient knowledge on required approachforourtaskandjointlylearngerr andgdis.
skillsorexhibitingspecificmisconceptions. Theadvantageofsuchanapproachisthatduring
2. Distractorgeneration: Foreachplausibleer- training,wecantrainonerrorssampledfromthe
ror,generatecorrespondingdistractor(s),i.e., error distribution, which gives us a better shot at
incorrectanswer(s)thatanincorrectapproach capturingthe(possiblylarge)errorspace. Shownin
withthaterrorleadsto. Figure1,DiVERThasthefollowingcomponents:
Weselectdistractorgenerationasthedownstream 1. The error prior model p(e|s): This model
tasksinceperformanceonthistaskiseasilyquan- generatesatextualexplanationofanerrorthat
tifiable;however,thereareothermeaningfultasks, studentscanmakegiventheMCQ’sstem.
such as feedback message and tutoring dialogue 2. The controllable distractor generation
turn generation, where knowing what error a stu- modelp(d|s,e): Thismodelgeneratesadis-
dentmadeiskeyandsignificantlyimprovesLLMs’ tractor that is the resulting incorrect answer
performanceonthesetasks(Jurenkaetal.,2024), aftermakingaspecificerrorinthisquestion.
whichweleaveforfuturework. 3. Anerroridentifiermodelq(e|s,d): Thisap-
Weformulatetheerrorgenerationtaskaslearn- proximateposteriormodelidentifiestheerror
ingafunctionthatoutputsaplausibleerrorinan behindaquestion-distractorpair.
MCQ, given the question stem and attributes in- We note that there are can be many choices
cluding the key and (optionally) explanation and for the variational distribution q(·); we choose
topic tags, i.e., gerr(s,k,f,t) → eˆ. Similarly, we q(e|s,d)sinceitcanbeusefulinpracticeandcan
formulatethedistractorgenerationtaskaslearning serveasasanitychecktool. Weleaveexperiment-
afunctionthatoutputsadistractorthatcorresponds ing with other useful approximate distributions
toaplausibleerror,i.e.,gdis(s,k,f,t,eˆ) → dˆ . suchasq(e|t)orevensimplyq(e)forfuturework.
3.2 DiVERT
3 Methodology
Asdiscussedabove,topromoteinterpretabilityin
Wenowdetailourapproachtoerrorrepresentation errorrepresentations,weparameterizealldistribu-
learninganddistractorgenerationinmathMCQs. tionsinourvariationalapproachusingLLMs. We
use a different LLMs for each distribution; each
3.1 VariationalApproach
isfine-tunedseparatelyfromthesamebaseLLM
Wefacetwokeytechnicalchallenges: First,errors usingQLoRA(Dettmersetal.,2024). Wedenote
can be represented in different formats: discrete, themasLLMe,LLMd,andLLMq.
as a finite set of error categories, continuous, as Approximate Inference. Since exact inference
latent vectors that represent a distribution of er- oftheposteriordistributioniscomputationallyin-
rors,ortextual,witherrorsrepresentedasnatural tractable,q (e|s,d)isanapproximationofthetrue
ϕ
language explanations. Considering use cases in posterior. We perform approximate inference by
real-worldeducationalscenarios,suchasproviding maximizingtheevidencelowerbound(ELBO)on
feedback to students and teachers and informing theobserveddatalog-likelihood,givenby
achatbotintutoringsessions,wechoosetorepre-
logp (d|s) = L(θ,ϕ) ≥ ELBO(d|s)
senterrorsastext: Anerrorbehindadistractorin θ
mathMCQsischaracterizedbyasequenceoftex- = E
q
ϕ(e|s,d)[logp
θ
d(d|s,e)]
tualtokens,asshowninFigure1. Second,forthe
−βD (q (e|s,d)||p (e|s)), (1)
KL ϕ θe
sameMCQstem,therecanoftenbemanyplausible
errorsamongrealstudents. FortheexampleinFig- where the model parameters θ consist of tunable
ure1,thecorrectsolutionapproachinvolvesseveral parameters in the error prior, θ , the controllable
e
mathematicalreasoningsteps,whereateachstep distractor generator θ , and the variational error
d
(e.g.,performingfractionmultiplication),thereare identifiermodelϕ. Theparameterβ > 0controls
multiple errors that real students can make (e.g., thebalancebetweenthedistractorreconstruction
multiplying the numerator and denominator, not loss and the KL divergence between the approx-
multiplyingthedenominator,etc.) Theerrorgener- imate posterior and the prior. Next, we detail aseriesofnovelmethodsthatweintroducetoenable pervisedfine-tuning,q . Thisterm,weightedby
ϕ
init
DiVERTtoperformourtwotasks. abalancingparameterα > 0,controlstheamount
Differentiable Learning through Discrete To- of exploration in our error tokens sampled from
kens. The ELBO in Equation 1 can easily be q (e|s,d) and prevents it from diverging during
ϕ
approximated by Monte Carlo simulation, with training. Concretely,theregularizationisgivenby
samples drawn from q (e|s,d) (see Supplemen-
ϕ
(cid:80)|eˆ|
taryMaterialB).However,sinceweparameterize L = D (q (eˆ |s,d)||q (eˆ |s,d)), (2)
reg k=1 KL ϕ init k ϕ k
q with an LLM, these samples are sequences of
ϕ
discretetexttokens. Therefore,wecannotsimply withourfinaltrainingobjectivebecoming
usethereparameterizationtricktosamplefromq .
ϕ
L(θ,ϕ)+αL . (3)
Usingasimilarapproachto(Liuetal.,2023),we reg
usesofttokens,i.e.,differentiableversionsofhard,
WenotethatthistermissimilartotheKLpenalty
discrete text tokens during training to enable the
usedwhentrainingLLMswithreinforcementlearn-
flowofgradients. Specifically,forthek-therrorto-
ing(Ouyangetal.,2022),specificallyNLPO(Ra-
keneˆ generatedbyLLMq,wereplaceitsdiscrete
k
(cid:80) mamurthyetal.,2022)thatalsousesatoken-level
embeddingv with p v ,wherep isthe
eˆ k j k,j j k,j penalty. However,thekeydifferenceisthatwedi-
probabilityofgeneratingtokenj atpositionkfrom
rectlybackpropagategradientsfromthislossrather
LLMq andv istheembeddingvectoroftokenj
j
thanuseittoformareward.
in the vocabulary of LLMq. This approximation
Overgenerate-and-rankforErrorsandDistrac-
enablesustosamplediscretetokenswhiledifferen-
tors. At test time, we first generate a set of N
tiatingthroughcontinuousvectorsduringtraining. e
errors,denotedasEˆ,throughLLMe,usingdiverse
Wecalculatep = softmax(z /λ) ,wherez is
k,j k j k
beamsearch(Vijayakumaretal.,2018)fordecod-
the output logit vector from LLMq at position k
ing,topromotediversityamonggeneratederrors.
andλ > 0isatemperatureparameter. Following
Then, for each generated error eˆ ∈ Eˆ, we gener-
priorwork(Jangetal.,2017),weinitializeλto1
ate N distractors through LLMd using standard
andexponentiallyannealitto0.1duringtraining. d
beamsearchsincethedistractorsexhibitmuchless
Thisprocessmeansthatthesofttokensaresmooth
variation under a specific error. Finally, we rank
whentrainingstartstoenablebettergradientflow,
all N × N candidate distractors in Dˆ by their
whilelaterbecomingclosertohardtokens. e d
associatedbeamscoresandselectthetop-K.
InitializationwithSupervisedFine-tuning. De-
spiteLLMsexhibitingbetterandbettermathemat-
4 ExperimentalEvaluation
ical reasoning capabilities, their capacity in un-
derstanding errors (Sonkar and Baraniuk, 2023) Inthissection,wedetailourexperimentsonareal-
and generating distractors that correspond to er- worldmathMCQdataset. Forquantitativeevalua-
rors(Fengetal.,2024)remainssurprisinglypoor. tion,wecompareDiVERTagainststate-of-the-art
Therefore,wesolicitacollectionoferrorlabelsbe- approachesandstrongbaselinesonthetaskofdis-
hindquestion-distractorpairs,(s,d),frommathed- tractorgeneration. Forqualitativeevaluation, we
ucators. Then,wefine-tuneallthreeLLMsintheir performahumanevaluationofthegeneratederror
respective formats using this annotation data to explanationswithmatheducators.
initializeDiVERT’sthreeLLMcomponents. With-
4.1 DatasetDetails
outthisstep,baseLLMs,evenonesthatperform
well on question answering tasks, generate low- Weworkwithareal-worldmathMCQdatasetcon-
quality error explanations that hurt performance, taining1,434MCQswritteninEnglish,eachwith
especiallyduringearlytrainingstages. InSection5, asetof3distractors. Wecollecterrorlabelsfrom
wedemonstratethatusingasmallportionoferror middle school math teachers for each question-
labels for warm-up fine-tuning helps DiVERT’s distractorpair,explainingwhyastudentmayselect
abilitytolearnfromunlabeled(s,d)pairs. thatdistractor. Thequestionsaredesignedprimar-
Q Regularization. Since the space of plausible ily to assess students aged between 10 to 13, on
errors can be large, we add a regularization term 41uniquesubtopics,including“BasicArithmetic”,
in our loss function to prevent the approximate “Fractions”,and“SolvingEquations”. Wedivide
posteriordistributionq (e|s,d)fromdeviatingtoo the dataset into train-val-test splits by questions
ϕ
much compared to its initialized version after su- toensurenooverlapintheMCQstemacrossthesplits, resulting in roughly a 72%-16%-12% split promptedtogeneratechain-of-thought(Weietal.,
overquestion-distractorpairs. SeeSupplementary 2022)reasoningbeforeeachdistractor. InourCoT
MaterialDforstatistics,andSupplementaryMate- implementation,wepromptthemodeltogenerate
rialGforMCQexamples. textual error explanations as chain-of-thought so
theerrorscanalsobedirectlycomparedwiththose
4.2 Metrics
fromourapproach. Wemakeothersmallupdates
Error Evaluation. The open-ended and math- tothepromptstoincludequestiontagsandtogen-
ematical nature of errors makes automated text erateeither3or10distractorsperquestion. Allour
similarity metrics like ROUGE-L F1 (Lin, 2004) promptsareshowninSupplementaryMaterialH.
and BERTScore F1 (Zhang et al., 2020) unsuit-
Fine-TuningBaselines. Weintroducethreestrong
able. Therefore,weconductahumanevaluation
fine-tuningbaselineapproachesfordistractorgen-
ofgeneratederrors, whichwedetailinSection6.
eration. ThefirstisDisSearch-D,wherewefine-
For completeness, we report error evaluation on
tunethebaseLLMtodirectlygenerateadistractor
automatedmetricsinSupplementaryMaterialE.
fromthequestionstem,i.e.,trainingp(d|s)onall
DistractorEvaluation. Followingpriorworkon
question-distractorpairs. ThesecondisDisSearch-
automateddistractorgeneration(Fengetal.,2024),
ED CoT, where we fine-tune the base LLM to
we use alignment-based metrics to measure how
generate the error first, as chain-of-thought (Wei
welltheK generateddistractorsalignwithground-
et al., 2022) reasoning, followed by the distrac-
truthhuman-authoredones. Thefirstmetric,Exact
tor,i.e.,trainingp(e,d|s)onallquestion-distractor
match (h ), measures whether all three human-
e pairs. Atinferencetime,wealsousebeamsearchto
authoreddistractors inD arematched exactlyby
matchtheovergenerate-and-ranksetupusedinDi-
somesubsetofthegenerateddistractorsDˆ. Simi-
VERT.ThethirdisDisSearch-EDCoTPipeline,
larly,Partialmatch(h )measureswhetheratleast
p where we use the fine-tuned p(d|s,e) and p(e|s)
onegenerateddistractormatcheshuman-authored
models without variational training and test with
ones. Concretely,thesebinarymetricsaredefined
thesametwo-steppipelineasDiVERT.
ash (D,Dˆ) = 1ifD ⊆ Dˆ,andh (D,Dˆ) = 1if
e p
Dˆ ∩D ̸= ∅. Thethird,continuousmetric,Propor-
tionalmatch(h ),measurestheportionofhuman-
n
4.4 ExperimentalSetup
authoreddistractorsthatmatchgeneratedones,de-
fined as h (D,Dˆ) = |Dˆ ∩ D|/3. We compute
n
all metrics averaged across all MCQs in the test Forthepromptingbaselines,weusethesameim-
setandreportpercentages. WevaryK ∈ {3,10}, plementation and hyperparameters as the public
similartothesetupformetricssuchasMAP@K. coderepositoryin(Fengetal.,2024)forafaircom-
TheProportionalmatchmetricismostimportant parison. WeusethelatestbaseLLMfromtheGPT-
sinceitismorerobustthantheothertwo. 4family,GPT-4o(asofJune13,2024),insteadof
GPT-3.5, tofurther strengthen theirperformance.
4.3 Baselines
For DiVERT, we use MetaMath-Mistral 7B (Yu
Wecompareourvariationalapproach,DiVERT,to etal.,2023)asourbaseLLMsinceitisoneofthe
state-of-the-artdistractorgenerationapproachesas best-performingLLMsinthe7Bfamilyonmath-
wellasseveralstrongbaselines,outlinedbelow. ematicalreasoning; wefoundthatitoutperforms
Prompting Baselines. We compare DiVERT otheropen-sourceLLMswithsimilarsizeonour
to two prompting-based approaches proposed in tasks. SeeSupplementaryMaterialFfordetailed
(Fengetal.,2024)usingthestate-of-the-artLLM parameter settings. At test time, we overgener-
GPT-4o (OpenAI, 2024). In contrast to our ap- ateN = 10errorsviaLLMe usingdiversebeam
e
proach,theseapproachesgeneratealldistractorsin search (Vijayakumar et al., 2018) and N = 10
d
onepass,withoutconsideringerrorsbehindthem. distractors through LLMd using standard beam
ThefirstiskNN,theirbest-performingapproach, search. Among the set of N ×N = 100 error-
e d
whereweusethe3mostsimilarMCQsinthetrain- distractorpairsweselectthetop-K ∈ {3,10}. For
ingsetasin-contextexamplesandteacher-written DisSearch-EDCoT,weusestandardbeamsearch
feedbackaschain-of-thoughtreasoningtoaiddis- with100beamsforafaircomparisonwithDiVERT.
tractorgeneration. ThesecondisCoT,whereno DisSearch-Dperformsbetterwith10beamssowe
in-context examples are given but the model is reportitsperformancewith10beams.K=3 K=10
Model
Exact@3 Partial@3 Prop@3 Exact@10 Partial@10 Prop@10
ProprietaryBaseLLM,GPT-4o
GPT-4oZero-shotCoT(Fengetal.,2024) 2.77 68.75 33.33 20.83 81.25 50.46
GPT-4okNN 25.69 83.33 55.09 36.80 88.88 63.88
Open-sourceBaseLLM,MetaMath-Mistral7B
DisSearch-D 13.88 75 41.66 36.11 90.27 64.12
DisSearch-EDCoT 13.88 78.47 43.51 37.5 90.97 66.66
DisSearch-EDCoTPipeline 15.27 75 43.28 38.19 88.88 64.58
DiVERT(ours) 13.19 81.25 46.06 42.36 91.66 68.75
Table1: Performanceondistractorgenerationforallapproachesacrossallmetrics. DiVERT,usinganopen-source
baseLLMwith7Bparameters,outperformsallbaselinesandperformsonparwithorbetterthanthemuchlarger
andproprietaryGPT-4o. Bestperformanceisinboldandsecondbestisunderlined.
5 Results,Analysis,andDiscussion
67.5
Inthissection,wequantitativelyevaluatethequal-
65.0
ityofgenerateddistractors,qualitativelyevaluate
62.5
botherrorsanddistractors,performerroranalyses
onfailedcases,andconductanablationstudy. 60.0
57.5
5.1 Quantitativeevaluation
55.0
DiVERT
DiVERT performs comparably or better than 52.5 DisSearch-ED COT
DisSearch-ED COT Pipeline
GPT-4o and outperforms baselines. Table 1
50.0
shows downstream distractor generation perfor- 0 20 40 60 80
Percentage of error labels dropped
mance for all approaches on all evaluation met-
rics. Ourvariationalapproach,DiVERT,usingan Figure 2: Distractor generation performance with in-
open-source base LLM with 7B parameters, per- creasingpercentagesoferrorlabelsdropped(unusedin
forms on par with GPT-4o, especially on the ro- training). DiVERT outperforms baselines, especially
whenonlyasmallnumberoferrorlabelsareused.
bustProportional@10metric,whereitoutperforms
GPT-4obyawidemargin. GPT-4okNNperforms
bestonK = 3evaluationmetrics,whichisnotsur- trainingonhuman-authorederrorexplanationsim-
prisingsincepriorwork(Fengetal.,2024)found proves distractor generation performance. This
that the kNN approach exploits in-context exam- resultcaneasilybeexplainedbyerrorlabelsserv-
ples in the training set that have the same under- ingasvaluablechain-of-thought(Weietal.,2022)
lying structure as the target MCQ, different only supervisionduringtraining.
innamedentitiesandnumericalvalues. Therefore, DiVERT works even with a small number of
allitneedstodoistofollowpatternsandgenerate errorlabels. Sincesolicitingerrorlabelsbehind
three distractors correspondingly without under- question-distractor pairs from math educators is
standingerrors. However,itdoesnotperformwell time-consuming,weinvestigateDiVERT’sreliance
onK = 10metricssinceitoftenfailstogobeyond ontheamountoferrorlabeldata. Figure2shows
thetopthreeerrorsinMCQsthathavenumerous DiVERT’sdistractorgenerationperformanceusing
plausible errors. In contrast, DiVERT performs differentportionsoftheavailableerrorlabels. We
wellbytrainingonerrorlabelstoacquireanunder- see that on the most stable metric, Prop@10, Di-
standingofplausiblemathematicalerrors. Under VERT performs better than baselines, especially
thesamebaseLLM,DiVERTperformsmuchbetter whenthemajorityoferrorlabelsaredropped: the
than baselines on almost all metrics, which high- performancegapiswidestwhenlessthanhalfof
lights the importance of its variational approach, thetrainingerrorlabelsareusedfortraining. This
sincesamplingfromtheLLMq modelduringtrain- resultfurtherhighlightstheimportanceoftheself-
ingencouragesexplorationoftheerrorspaceand explorationtrainingsetupinDiVERT’svariational
improvesmodelrobustness. approachatgoingbeyondhuman-authoredlabels
Errors as “chain-of-thought” improve perfor- andlinkingdifferenterrortypesacrossquestions.
mance. Comparingamongbaselines,weseethat Ablation study. Table 2 shows results of the ab-
01@porPModel Exact Partial Prop Q:Whatisthelowestcommonmultipleof12and15?
DiVERT 42.36 91.66 68.75 Error Distractor
−variationaltraining 35.41 90.27 64.81
DiVERT
−trainq (freezeq ) 37.5 91.66 66.20
ϕ ϕ
−q ϕregularization 40.97 89.58 66.20 Believestheycanfindthelowestcommonmul- 27
−temperatureannealing 41.66 89.58 67.36 tiplebyaddingthenumberstogether.
Confusesfactorsandmultiples. 3
Table2: AblationstudyofDiVERTondistractorgener-
Whenaskedforthelowestcommonmultiple, 15
ationperformanceonK =10metrics. thinkstheycanjustgiveanymultipleofoneof
thenumbers.
lationstudyonthemorerobust@10metrics. We GPT-4oZero-shotCoT
seethatthevariationaltrainingprocessiscrucial Confusingtheconceptofthelowestcommon 3
multiplewiththegreatestcommondivisor.
and removing it results in a large drop in perfor-
Incorrectlyaddingthetwonumbersinsteadof 27
mance (see Supplementary Material C). We also findingthelowestcommonmultiple.
see that not training q and using its fine-tuned Confusingtheconceptofmultipleswiththatof 5
ϕ
primefactors.
initialized version q also drops performance,
ϕinit
whichhighlightstheimportanceofsamplingfrom GPT-4okNN(feedbackshownbelow)
q and exploring the error space of math MCQs. Thisisamultipleof12butnotof15... 24
ϕ
Thisisamultipleof15butnotof12... 45
Regularizingq andusingtemperatureannealing
ϕ Thisisamultipleof12butnotof15... 36
inthesofttokenapproximationarealsoeffective
DisSearch-EDCoT
atmakingtrainingmorerobust.
Confusesfactorsandmultiples. 3
Doesnotunderstandthetermmultiple. 15
5.2 QualitativeEvaluation
Identifiesacommonmultiplebutnotthelowest 75
commonmultiple.
Table3showsgeneratederrorsandcorresponding
distractors for an MCQ stem in the test set. Di- Table3: Examplesoferrorsandcorrespondingdistrac-
VERT generates a diverse set of plausible errors torsgeneratedbydifferentapproachesforatestMCQ.
andcorrespondingdistractors. However,GPT-4o
Zero-shotCoTprioritizeserrordiversityandgen- ror“Whendividingafractionbyaninteger,divides
erateserrorsunlikelytobemadebyrealstudents thedenominatorbytheinteger”,thegenerateddis-
like“Confusingtheconceptofmultipleswiththat tractoris 6 ratherthanthedesired 6. Thereverse
1 3
ofprimefactors”. GPT-4okNNfailstogeneralize canalsooccasionallyhappenwhenadistractoris
on this test example; it does not generate diverse valid but the error is not. This observation high-
distractorsandinsteadfollowsafixedruleofgen- lightsthatalthougheffectivelylearninggooderror
eratingeithermultiplesof12butnot15,andvice representations and capable of identifying what
versa,highlightingitspattern-followingnatureand errors can be made in a math MCQ, the biggest
dependenceongoodin-contextexamples. Thebest limitationofDiVERTisinitsinabilitytoenforce
fine-tuningbaseline,DisSearch-EDCoT,generates consistency in the downstream distractor genera-
generic error descriptions like “Does not under- tion model p(d|s,e). This limitation suggests a
stand the term multiple”, which is not specific to major direction for future work, possibly by ex-
thequestion’scontext. ploring the use of an error-distractor consistency
Failure Pattern Analysis. We now investigate penaltyinthetrainingobjective.
failure patterns in the generated errors and corre-
spondingdistractorsfromDiVERT.Table4shows 6 HumanEvaluationofErrors
arepresentativeexampleMCQinthetestset. We
6.1 EvaluationSetup
observe that a majority of generated errors from
p(e|s) are mathematically valid, with high diver- While automated distractor evaluation is well-
sity, butsomearelesslikelyamongrealstudents definedsincethereisground-truth,itismorechal-
such as “Subtracts instead of divides”, matching lengingtoautomaticallyevaluateerrors. Reference-
the observation made in prior work (Feng et al., basedevaluationmaypenalizeerrorsthatfaithfully
2024). Byfar,themostfrequentfailurepatternwe reflect the mathematical error behind a distractor
observeisonthecontrollabledistractorgeneration butaresemanticallydifferentthanthegroundtruth,
modelp(d|s,e),wherethegenerateddistractoris or conversely, reward errors that are invalid but
notfaithfultotheerror. Inthisexample,fortheer- semantically similar to the ground truth. To ad-Questionstem:Calculate: 6 ÷3 arebetterthanGPT-4oones,withstatisticalsignif-
9
Whendividingafractionbyaninteger,divides 2 ✓ icance (p < 0.01). This result is promising since
3
both the numerator and denominator by the ourbaseLLM,MetaMath-Mistral7B,isordersof
integer.✓
magnitudesmallerthanGPT-4o. Qualitatively,we
Whendividingafractionbyaninteger,divides 6 ✗
thedenominatorbytheinteger.✓ 1 find that GPT-4o’s errors are often not what real
Dividedbythedenominatorinsteadofthenu- 1 ✓ studentsarelikelytomake,andevenoccasionally
merator.✗ 3
confusethecorrectsolutionapproachwithanerror.
Subtractsinsteadofdivides.✗ 3 ✗
6 Thisresultshowsthatevenstate-of-the-artLLMs
Table4: Qualitativeerroranalysesofgeneratederrors are not able to anticipate student errors, and that
andcorrespondingdistractorsfromDiVERTonanex- training on human-authored labels is likely nec-
ampleMCQstemfromthetestset.
essary for LLMs to accurately diagnose student
errors. Finally, we note that overall, the error la-
Human DiVERT GPT-4o
belsvaryalotintermsofqualityandscorelower
Rating 3.23±1.28 3.07±1.39 2.56±1.25 thanexpected. ThePearsoncorrelationcoefficient
Table5: Averageerrorqualityratedbymathteachers. betweenourannotators’ratingsisalsoonly0.33,
HumanandDiVERTerrorsaresimilarinquality,and indicatinglow-to-moderateagreement. Thisresult
botharebetterthanGPT-4owithstatisticalsignificance. isduetomanyerrorsdeemedtobeunlikelytobe
madebystudentsbyannotators,ratherthanbeing
dressthischallenge,weconductahumanevalua- mathematicallyincorrect. Itislikelythatevenfor
tiontomeasurethequalityofgeneratedandhuman- humans,anticipatingerrorsmadebystudentsisa
authorederrors. Werecruittwoexperiencedmath challengingtask,whichsuggeststhatfuturework
teacherswhohaveextensiveexpertiseindesigning shouldfocusonunderstandingthenatureoferrors
mathMCQsasannotators. Werandomlyselect20 madebyrealstudentsandtheircauses.
questionsfromthetestsetonadiversesetoftopics,
7 ConclusionsandFutureWork
andforeachquestion,showannotatorstheground-
truth,human-authorederrors,andgeneratederrors
Inthispaper,weproposedDiVERT,anovelvari-
frombothDiVERTandGPT-4o. ForDiVERT,we
ational approach to jointly learn an interpretable,
selectthetop3distractorsfromthep(e|s)model
textualrepresentationoferrorsinmathMCQsand
usingdiversebeamsearchtopromoteerrordiver-
howtogeneratedistractorsthatcorrespondtothese
sity. For GPT-4o, we select the errors generated
errors. On a real-world math MCQ dataset, we
duringCoTdistractorgeneration. Werandomize
showedthatDiVERTresultsinbetterdownstream
theorderoferrorsshowntotheannotatorsanddo
distractorgenerationperformanceoverstate-of-the-
notletthemknowhoweacherrorisgenerated. We
artapproaches. Wealsoconductedahumanevalu-
instructannotatorstorateeacherrorona5-point
ationwithmatheducatorsandfoundthatDiVERT
Likert scale, with 5 being the best, depending on
leadstoerrorsasinterpretableasthoseprovidedby
whetheranerrorisrelevanttothequestion,math-
humans,andoutperformsGPT-4o,despiteusinga
ematicallysound,specific,conceptual,andlikely
muchsmallerbaseLLM.
tobemadebyarealstudent. SeeSupplementary
Therearemanyavenuesforfuturework. First,
MaterialI.1fortheexactinstructionsgiventothe
weplantoapplythelearnederrorrepresentations
annotators.
toanotherdownstreamtask,feedbackgeneration,
andexplorewhetherourapproachleadstoamore
6.2 Results
accuratestudentprofile/model,whichwillinturn
Table5showstheaverageandstandarddeviation
resultinhigherqualityfeedbackinmathtutoring
of annotators’ ratings on errors that were human-
chatbots. Second,weplantotesttheacross-topic
authored and LLM-generated, by both DiVERT
generalizability of our approach and investigate
andGPT-4o. WefindthatthequalityofDiVERT’s
whethertheerrorrepresentationscangeneralizeto
errorsareclosetohumanones,withnostatistically
previouslyunseenmathtopics. Third,wehopeto
significantdifferencebetweenthemusingaTwo-
develop new, LLM-based metrics to evaluate the
Samplet-Test(p = 0.36). Thisresultsuggeststhat
mathematical validity of an error and the equiva-
DiVERTretainsthehuman-levelqualityoferrors
lencebetweentwoerrorexplanations,toalleviate
it is trained on during fine-tuning. Moreover, we
theneedforhumanevaluationoferrorquality.
findthatbothhumanandDiVERT-generatederrorsLimitations ElafAlhazmi,QuanZSheng,WeiEmmaZhang,Mu-
nazzaZaib, andAhoudAlhazmi.2024. Distractor
Weidentifyseveraltechnicalandpracticallimita- generationformultiple-choicequestions: Asurvey
tions of our work. First, the main limitation of ofmethods,datasets,andevaluation. arXivpreprint
arXiv:2402.01512.
DiVERTisitstendencytogeneratedistractorsthat
donotalwayscorrespondwiththeprecedinggener- Tahani Alsubait, Bijan Parsia, and Uli Sattler. 2014.
atederror. However,wenotethatallbaselines(in- Generating multiple choice questions from ontolo-
cludingGPT-4)alsoexhibitthisbehavior,andwe gies: Lessonslearnt. InOWLED,pages73–84.Cite-
seer.
planonaddressingthislimitationasalineoffuture
work. Second,wenotethatDiVERTrequiresaset SemereKirosBitew,JohannesDeleu,ChrisDevelder,
ofhuman-authorederrorsforinitializationthrough and Thomas Demeester. 2023. Distractor genera-
tion for multiple-choice questions with predictive
fine-tuning. This process of labeling distractors
promptingandlargelanguagemodels. arXivpreprint
withtextualerrorscanbetime-consuminganddif-
arXiv:2307.16338.
ficulttoscale,althoughweobservethatDiVERT
Shang-Hsuan Chiang, Ssu-Cheng Wang, and Yao-
retainsmostofitsabilitywhenonlyasmallsubset
ChungFan.2022. Cdgp: Automaticclozedistractor
ofthedataislabeled. Third,weonlyexperiment
generationbasedonpre-trainedlanguagemodel. In
with one dataset, since to the best of our knowl- FindingsoftheAssociationforComputationalLin-
edge there are no similar distractor datasets with guistics: EMNLP2022,pages5835–5840.
labeledtextualerrors. Finally,wedonotperforma
NeisargDave,RileyBakes,BartonPursel,andCLee
humanevaluationonthequalityofthedistractors
Giles. 2021. Math multiple choice question solv-
themselvesduetolimitedresources. ing and distractor generation with attentional gru
networks. International Educational Data Mining
EthicalConsiderations Society.
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and
Ourgoalinthisworkistodevelopasystemthatcan
LukeZettlemoyer.2024. Qlora: Efficientfinetuning
automaticallycreatedistractorsforassessmentsor
ofquantizedllms. AdvancesinNeuralInformation
practiceproblems,anddosoinanexplainableway ProcessingSystems,36.
sothatthedistractorscanbemoreeasilyverifiedby
Wanyong Feng, Jaewook Lee, Hunter McNichols,
humaneducators. Wehopethatsuchsystemswill
Alexander Scarlatos, Digory Smith, Simon Wood-
saveeducatorstimeoncontentcreation,allowing
head,NancyOteroOrnelas,andAndrewLan.2024.
themtospendmoreresourcesonpersonalstudent Exploringautomateddistractorgenerationformath
interactions. However,thereisaconcernthatsuch multiple-choicequestionsvialargelanguagemodels.
In Findings of the North American Chapter of the
systemscouldreplacehumaneducatorjobs,which
AssociationofComputationalLinguistics(NAACL)).
isasharedconcernacrossmostdomainswithAI
applications. Wenotethatwhilethereislittlerisk Yifan Gao, Lidong Bing, Piji Li, Irwin King, and
Michael R Lyu. 2019. Generating distractors for
forbiasinthecreationofmathematicaldistractors,
readingcomprehensionquestions fromrealexami-
theuseoftextualerrorsintroducesthepossibility
nations. InProceedingsoftheAAAIConferenceon
ofgeneratingbiasedtextbyinheritingtendencies ArtificialIntelligence,pages6423–6430.
fromthebaseLLM.Anotherriskofautomatically
AritraGhosh,BeverlyWoolf,ShlomoZilberstein,and
generatingdistractorsisthatalowerqualitycom-
AndrewLan.2020. Skill-basedcareerpathmodeling
paredtohuman-authoredcontentcouldleadtoneg-
and recommendation. In 2020 IEEE International
ativestudentlearningoutcomes. Becauseofthese Conference on Big Data (Big Data), pages 1156–
reasons,werecommendthaterrorsanddistractors 1165.
be reviewed by experts before being deployed to
Neil T Heffernan and Cristina Lindquist Heffernan.
realstudents. 2014. The ASSISTments ecosystem: Building a
platformthatbringsscientistsandteacherstogether
forminimallyinvasiveresearchonhumanlearning
References andteaching. InternationalJournalofArtificialIn-
telligenceinEducation,24(4):470–497.
KhanAcademy.2024. Khanmigo: Khanacademy’sai-
poweredteachingassistant. Online: https://www. EdwardJHu,yelongshen,PhillipWallis,ZeyuanAllen-
khanmigo.ai/. Zhu,YuanzhiLi,SheanWang,LuWang,andWeizhu
Chen. 2022. LoRA: Low-rank adaptation of large
PeterAirasian.2001. Classroomassessment: Concepts language models. In International Conference on
andapplications. McGraw-Hill,Ohio,USA. LearningRepresentations.Eric Jang, Shixiang Gu, and Ben Poole. 2017. Cate- ZhaopengQiu,XianWu,andWeiFan.2020. Automatic
goricalreparameterizationwithgumbel-softmax. In distractorgenerationformultiplechoicequestionsin
International Conference on Learning Representa- standardtests. arXivpreprintarXiv:2011.13100.
tions.
FanyiQu,HaoSun,andYunfangWu.2024. Unsuper-
Jurenka et al. 2024. Towards responsible viseddistractorgenerationvialargelanguagemodel
development of generative ai for educa- distilling and counterfactual contrastive decoding.
tion: An evaluation-driven approach. on- arXivpreprintarXiv:2406.01306.
line: https://storage.googleapis.com/
deepmind-media/LearnLM/LearnLM_paper.pdf. Rajkumar Ramamurthy, Prithviraj Ammanabrolu,
KiantéBrantley, JackHessel, RafetSifa, Christian
DmytroKalpakchiandJohanBoye.2021. Bert-based
Bauckhage, Hannaneh Hajishirzi, and Yejin Choi.
distractor generation for swedish reading compre-
2022. Isreinforcementlearning(not)fornaturallan-
hensionquestionsusingasmall-scaledataset. arXiv
guageprocessing: Benchmarks,baselines,andbuild-
preprintarXiv:2108.03973.
ingblocksfornaturallanguagepolicyoptimization.
Tom Kubiszyn and Gary Borich. 2016. Educational
arXivpreprintarXiv:2210.01241.
testingandmeasurement. JohnWiley&Sons,New
StevenRitter,JohnRAnderson,KennethRKoedinger,
Jersey,USA.
andAlbertCorbett.2007. Cognitivetutor: Applied
ChunyuanLi,XiangGao,YuanLi,BaolinPeng,Xiujun research in mathematics education. Psychonomic
Li,YizheZhang,andJianfengGao.2020. Optimus: bulletin&review,14(2):249–255.
Organizingsentencesviapre-trainedmodelingofa
latentspace. InProceedingsofthe2020Conference RicardoRodriguez-Torrealba,EvaGarcia-Lopez,and
onEmpiricalMethodsinNaturalLanguageProcess- Antonio Garcia-Cabot. 2022. End-to-end genera-
ing(EMNLP),pages4678–4699. tionofmultiple-choicequestionsusingtext-to-text
transfer transformer models. Expert Systems with
Chin-Yew Lin. 2004. ROUGE: A package for auto- Applications,208:118258.
maticevaluationofsummaries. InTextSummariza-
tionBranchesOut,pages74–81,Barcelona,Spain. AlexanderScarlatos,WanyongFeng,DigorySmith,Si-
AssociationforComputationalLinguistics. monWoodhead,andAndrewLan.2024. Improving
automated distractor generation for math multiple-
XinLiu,MuhammadKhalifa,andLuWang.2023. Bolt:
choicequestionswithovergenerate-and-rank. InPro-
Fastenergy-basedcontrolledtextgenerationwithtun-
ceedings of the 19th Workshop on Innovative Use
ablebiases. InProceedingsofthe61stAnnualMeet-
ofNLPforBuildingEducationalApplications(BEA
ingoftheAssociationforComputationalLinguistics
2024).
(Volume2: ShortPapers),pages186–200.
ChantalShaib,JoeBarrow,JiudingSun,AlexaFSiu,
Ilya Loshchilov and Frank Hutter. 2019. Decoupled
Byron C Wallace, and Ani Nenkova. 2024. Stan-
weightdecayregularization. InInternationalConfer-
dardizingthemeasurementoftextdiversity: Atool
enceonLearningRepresentations.
andacomparativeanalysisofscores. arXivpreprint
Steven Moore, Eamon Costello, Huy A Nguyen, and arXiv:2403.00553.
JohnStamper.2024. Anautomaticquestionusability
evaluationtoolkit. arXivpreprintarXiv:2405.20529. PengjuShuai, LiLi, SishunLiu, andJunShen.2023.
Qdg: A unified model for automatic question-
Anthony J. Nitko. 1996. Educational assessment of distractor pairs generation. Applied Intelligence,
students. Prentice-Hall,Iowa,USA. 53(7):8275–8285.
OpenAI.2024. Hellogpt-4o.
KaitaoSong, XuTan, TaoQin, JianfengLu, andTie-
YanLiu.2020. Mpnet: Maskedandpermutedpre-
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
training for language understanding. Advances in
CarrollWainwright,PamelaMishkin,ChongZhang,
neural information processing systems, 33:16857–
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
16867.
2022. Training languagemodelsto followinstruc-
tionswithhumanfeedback. Advancesinneuralin-
ShashankSonkarandRichardGBaraniuk.2023. De-
formationprocessingsystems,35:27730–27744.
ductionunderperturbedevidence: Probingstudent
VishakhPadmakumarandHeHe.2024. Doeswriting simulation(knowledgetracing)capabilitiesoflarge
withlanguagemodelsreducecontentdiversity? In languagemodels. InProceedingsoftheAIEDWork-
The Twelfth International Conference on Learning shop on Empowering Education with LLMs – the
Representations. Next-GenInterfaceandContentGeneration.
VijayPrakash,KartikayAgrawal,andSyaamantakDas. KatherineStasaskiandMartiAHearst.2017. Multiple
2023. Q-genius:Agptbasedmodifiedmcqgenerator choicequestiongenerationutilizinganontology. In
foridentifyinglearnerdeficiency. InInternational Proceedingsofthe12thWorkshoponInnovativeUse
Conference on Artificial Intelligence in Education, ofNLPforBuildingEducationalApplications,pages
pages632–638.Springer. 303–312.YuniSusanti,TakenobuTokunaga,HitoshiNishikawa, diversedialoguegeneration. InTheEleventhInter-
andHiroyukiObari.2018. Automaticdistractorgen- nationalConferenceonLearningRepresentations.
erationformultiple-choiceenglishvocabularyques-
tions. Researchandpracticeintechnologyenhanced Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
learning,13:1–16. Chaumond,ClementDelangue,AnthonyMoi,Pier-
ricCistac,TimRault,RemiLouf,MorganFuntow-
Ana Paula Tomás and José Paulo Leal. 2013. Auto- icz,JoeDavison,SamShleifer,PatrickvonPlaten,
matic generation and delivery of multiple-choice Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,
math quizzes. In Principles and Practice of Con- Teven Le Scao, Sylvain Gugger, Mariama Drame,
straintProgramming: 19thInternationalConference, QuentinLhoest,andAlexanderRush.2020. Trans-
CP2013,Uppsala,Sweden,September16-20,2013. formers:State-of-the-artnaturallanguageprocessing.
Proceedings19,pages848–863.Springer. InProceedingsofthe2020ConferenceonEmpirical
Methods in Natural Language Processing: System
Andrew Tran, Kenneth Angelikas, Egi Rama, Chiku Demonstrations,pages38–45,Online.Association
Okechukwu,DavidHSmith,andStephenMacNeil. forComputationalLinguistics.
2023. Generatingmultiplechoicequestionsforcom-
putingcoursesusinglargelanguagemodels. In2023 Jiayuan Xie, Ningxin Peng, Yi Cai, Tao Wang, and
IEEEFrontiersinEducationConference(FIE),pages QingbaoHuang.2021. Diversedistractorgeneration
1–8.IEEE. forconstructinghigh-qualitymultiplechoiceques-
tions. IEEE/ACM Transactions on Audio, Speech,
Haoqin Tu, Zhongliang Yang, Jinshuai Yang, and andLanguageProcessing,30:280–291.
Yongfeng Huang. 2022. Adavae: Exploring adap-
tivegpt-2sinvariationalauto-encodersforlanguage Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
modeling. arXivpreprintarXiv:2205.05862. Zhengying Liu, Yu Zhang, James T Kwok, Zhen-
guo Li, Adrian Weller, and Weiyang Liu. 2023.
KurtVanLehn.1982. Bugsarenotenough: Empirical Metamath: Bootstrapyourownmathematicalques-
studiesofbugs,impassesandrepairsinprocedural tions for large language models. arXiv preprint
skills. TheJournalofMathematicalBehavior. arXiv:2309.12284.
Ashwin K Vijayakumar, Michael Cogswell, Ram- Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.
prasathR.Selvaraju, QingSun, StefanLee, David Weinberger,andYoavArtzi.2020. Bertscore: Eval-
Crandall, and Dhruv Batra. 2018. Diverse beam uating text generation with bert. In International
search: Decodingdiversesolutionsfromneuralse- ConferenceonLearningRepresentations.
quencemodels. Preprint,arXiv:1610.02424.
Hui-Juan Wang, Kai-Yu Hsieh, Han-Cheng Yu, Jui-
ChingTsou,YuAnShih,Chen-HuaHuang,andYao-
ChungFan.2023a. Distractorgenerationbasedon
Text2TextlanguagemodelswithpseudoKullback-
Leiblerdivergenceregulation. InFindingsoftheAs-
sociationforComputationalLinguistics: ACL2023,
pages12477–12491.
Wenya Wang, Vivek Srikumar, Hannaneh Hajishirzi,
andNoahASmith.2023b. Elaboration-generating
commonsensequestionansweringatscale. InPro-
ceedingsofthe61stAnnualMeetingoftheAssocia-
tionforComputationalLinguistics(Volume1: Long
Papers),pages1619–1635.
ZichaoWang,AngusLamb,EvgenySaveliev,Pashmina
Cameron, JordanZaykov, JoseMiguelHernandez-
Lobato,RichardETurner,RichardGBaraniuk,Craig
Barton,SimonPeytonJones,etal.2021. Resultsand
insightsfromdiagnosticquestions: Theneurips2020
educationchallenge. InNeurIPS2020Competition
andDemonstrationTrack,pages191–205.PMLR.
JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
etal.2022. Chain-of-thoughtpromptingelicitsrea-
soninginlargelanguagemodels. AdvancesinNeural
InformationProcessingSystems,35:24824–24837.
YuqiaoWen,YongchangHao,YanshuaiCao,andLili
Mou. 2022. An equal-size hard em algorithm forA RelatedWork
68.5
For automated distractor generation in language
68.0
learningandreadingcomprehension,priorworks
67.5
haveexploredrankingcandidatedistractorsbased
67.0
onsemanticsimilaritytothekeyandusingknowl-
edge graphs (Susanti et al., 2018; Stasaski and 66.5
Hearst,2017;Alsubaitetal.,2014). Morerecent 66.0
worksuseanend-to-endpipelinefordistractorgen- 65.5
eration, which lead to longer and higher-quality
65.0
distractors (Qiu et al., 2020; Shuai et al., 2023;
0 20 40 60 80 100
Xieetal.,2021;Gaoetal.,2019),alsoleveraging Percentage of data used for variational training
open-sourceLLMssuchasBERTandT5(Kalpakchi
Figure3: DistractorgenerationProp@10performance
and Boye, 2021; Chiang et al., 2022; Rodriguez-
with an increasing percentage of data used for varia-
Torrealbaetal.,2022;Quetal.,2024;Wangetal.,
tional training. Sampling errors from q on all train
ϕ
2023a); these approach are similar to the base-
question-distractorpairsperformsbest.
lines we use in this work. Other works prompt
state-of-the-artproprietaryLLMssuchasChatGPT
and GPT-4 to generate distractors, with carefully B MonteCarloApproximationofELBO
crafted prompts, for a wider range of subjects in- TrainingObjective
cluding math and computer science (Tran et al.,
Since exact inference of the posterior distribu-
2023;Bitewetal.,2023;Fengetal.,2024). Evalu-
tion is computationally intractable, q (e|s,d) is
atingthequalityofdistractors, however, remains ϕ
an approximation of the true posterior. We per-
challenging: (Moore et al., 2024) proposes a se-
form approximate inference by maximizing the
ries of features that can be used to evaluate the
evidence lower bound (ELBO) on the observed
qualityofdistractors,althoughthosefeaturesare
data log-likelihood, given in Equation 1. The
mostly about surface semantics and do not apply
ELBO in Equation 1 can easily be approximated
to subjects like math that require deeper reason-
by Monte Carlo simulation, with samples drawn
ing. Another line of recent work in (Feng et al.,
fromq (e|s,d),asshownbelow:
2024;Scarlatosetal.,2024)proposestomeasure ϕ
thequalityofdistractorsthroughhowlikelythey
E [logp (d|s,e)]
are going to be selected by real students, which q ϕ(e|s,d) θ d
requirestraininganothermodeltopredictstudent −βD (q (e|s,d)||p (e|s))
KL ϕ θe
option selection behavior. However, most exist- = E [logp (d|s,e)]
q ϕ(e|s,d) θ d
ingMCQdatasetsdonotcomewithsuchstudent
−βE [logq (e|s,d) − logp (e|s)]
responseinformation. q ϕ(e|s,d) ϕ θe
(cid:88)
At a high level, an alternative to our approach ≈ logp θ (d|s,eˆ)−βlogq ϕ(eˆ|s,d)
d
ofrepresentingerrorsastextistolearnlatenterror eˆ∼q (e|s,d)
ϕ
representations (Li et al., 2020; Tu et al., 2022), +βlogp (eˆ|s)
θe
i.e.,characterizingerrorsasalatentstochasticerror
vector,possiblyinthetextembeddingspace. How- C VariationalTrainingAblation: Q
ever,inourexperiments,wefoundthisapproachto ModelHelpsDiVERTLearnaRobust
beuninterpretableandineffective,significantlyre-
ErrorSpace
ducingdistractorgenerationperformance,possibly
because errors behind distractors in math MCQs Inreal-worldeducationalscenarios,therearemul-
correspondtocomplexreasoningprocessesandare tiple errors plausible among real students for the
hardertocapturethandifferentuserwritingstyles. sameMCQstem. DiVERT,canlearnarobusterror
Our approach in improving the diversity of gen- space,byleveragingsamplederrorsfromq (e|s,d)
ϕ
erated errors also bears some resemblance to the around the original human-authored ones dur-
works in (Wen et al., 2022; Wang et al., 2023b), ing variational training. As shown in Figure 3,
although the nature of our task is more complex sampling errors from q on a higher number of
ϕ
thandialoguegenerationandquestionanswering. question-distractorpairsinthetrainset,leadstoa
01@porPTrain Validation Test
MathMCQDataset 2570question-distractorpairs 599question-distractorpairs 432question-distractorpairs
µ σ Min Max µ σ Min Max µ σ Min Max
#tokens/Qstem 43.2 30.9 5 224 42.3 31.5 5 174 35.1 27.9 6 164
#tokens/solution 66.0 35.3 12 234 67.0 39.0 15 266 59.3 29.7 11 164
#tokens/key 9.3 11.5 1 189 9.5 14.6 1 175 7.5 4.7 1 44
#tokens/distractor 9.4 11.6 1 184 9.7 15.3 1 176 5.1 3.7 1 31
#tokens/error 14.3 6.0 4 42 14.0 6.1 5 36 13.8 5.5 5 39
Table6: Statisticsofthereal-worldmathMCQdatasetwhichcontains1,434MCQsacross41uniquesubtopics.
morerobustlearnederrorspace,withbetterdown- including ROUGE-L F1 (Lin, 2004) and cosine
streamdistractorgenerationperformance. similarity using the pre-trained SBERT encoder
MPNET(Songetal.,2020),aswellasrecentmet-
D Real-worldMathMCQDatasetDetails
ricslikeBERTScoreF1(Zhangetal.,2020).
Fordiversity,following(PadmakumarandHe,
Wedivide thereal-worldmath MCQ dataset into
train-val-testsplitsbyquestionstoensurenoover- 2024;Shaibetal.,2024),wereportthecomplement
ofthehomogenizationscoreofasetoferrorsE as
lap in the MCQ stem across the splits, resulting
in roughly a 72%-16%-12% split over question- divh(E) = 1−(cid:80) h(e ,e )/|E ×E|,
distractorpairs. Table6showsdetailedstatisticsof e1̸=e2∈E 1 2
the dataset. We manually checked a random sub- wherehdenotesthechoiceofthetextualsimilar-
setofthedataandfoundnopersonallyidentifying ity metric. We report diversity for both human-
informationoroffensivecontent. authorederrorsE andpredictederrorsEˆ,averaged
acrossalltestMCQs.
E AutomatedErrorEvaluation
E.2 BaselinesandResults
E.1 Metrics
Weintroduceanewfine-tuningbaselineforerror
The open-ended and mathematical nature of er-
generation, ErrorSearch-E, where we fine-tune
rors makes automated text similarity metrics
the base LLM to directly generate an error from
like ROUGE-L F1 (Lin, 2004) and BERTScore
thequestionstem,i.e.,trainingp(e|s)onallerror-
F1(Zhangetal.,2020)unsuitable. Therefore,we
questionpairs. Forafaircomparison,wegenerate
conductahumanevaluationofgeneratederrors,
errorsfromthep(e|s)modelofDiVERTinastan-
which we detail in Section 6. For completeness,
dalonefashion. Weusediversebeamsearchdecod-
we report error evaluation on automated metrics
ing (Vijayakumar et al., 2018) to generate errors
below.
from both models. We also compare with errors
Weevaluategeneratederrorsontwokeyaspects:
generatedfromGPT-4oZero-shotCoT,aswellas
1) similarity with ground-truth, human-authored
thefinetuningbaselineDisSearch-EDCoT,bothof
errors E with |E| = 3, and 2) diversity. We se-
whichgenerateerrorsfollowedbydistractors.
lectthebest3errorsgeneratedforeachMCQ,i.e.,
Table7showserrorgenerationperformancefor
|Eˆ| = 3. We compute both recall, which evalu-
all error-based approaches on all evaluation met-
ateshowwellthegeneratederrorsrecoveractual
rics. Asareferenceforthediversityofpredicted
human-authorederrors,andprecision,whicheval-
errorsshown,thediversityofground-truth,human-
uates how accurate the generated errors are with
written errors is 0.574, 0.300, and 0.349, for the
respecttothehuman-authorederrors. Concretely,
choice of the similarity metric as ROUGE-L F1,
wemeasurerecallby
cosinesimilarity,andBERTScoreF1,respectively.
simh(E,Eˆ) = (cid:80) max (h(e,eˆ))/|E| ThefinetuningbaselineErrorSearch-Eimitatesthe
r e∈E eˆ∈Eˆ
ground-truthhuman-writtenerrordistributionand
andprecisionby
performs best on F1 performance across almost
simh(E,Eˆ) = (cid:80) max (h(eˆ,e))/|Eˆ|, alltextualsimilaritymetrics. DisSearch-EDCoT
p eˆ∈Eˆ e∈E
performsbestonprecisionperformanceacrossall
wherehdenotesthechoiceofthetextualsimilarity textualsimilaritymetrics. However,thesamebeam
metric. Weusetraditionaltextualsimilaritymetrics searchdecodinghelpingprecision,leadstoadropROUGE-LF1 BERTScoreF1 CosineSimilarity
Model
Precis. Recall F1 Div. Precis. Recall F1 Div. Precis. Recall F1 Div.
ProprietaryBaseLLM,GPT-4o
GPT-4oZero-shotCoT 0.251 0.272 0.261 0.718 0.632 0.635 0.633 0.293 0.602 0.607 0.605 0.376
Open-sourceBaseLLM,MetaMath-Mistral7B
ErrorSearch-E 0.498 0.597 0.543 0.781 0.741 0.786 0.763 0.368 0.698 0.759 0.727 0.475
DisSearch-EDCoT 0.595 0.526 0.558 0.448 0.786 0.751 0.768 0.207 0.735 0.702 0.718 0.278
DiVERTp(e|s)(ours) 0.479 0.576 0.523 0.786 0.732 0.775 0.753 0.372 0.680 0.746 0.711 0.487
Table 7: Performance on automated error evaluation for all error-based approaches across all metrics. Best
performanceisinboldandsecondbestisunderlined.
intheperformanceofDisSearch-EDCoTonrecall 256,LoRAr = 128,LoRAdropout = 0.05) us-
anddiversity. GPT-4oZero-shotCoTexhibitsgood ing8-bitquantization(Dettmersetal.,2024). We
error diversity, but as expected performs poorly fine-tune for 5 epochs with early stopping on the
on textual similarity metrics, with the zero-shot validation set on a single NVIDIA A100 80GB
errors generated not matching the distribution of GPU, with each epoch taking up to 35 minutes.
human-writtenerrors. Thep(e|s)modelfromour We follow the same training setup for our fine-
variationalmethod,DiVERT,generateserrorswith tuningbaselines,DisSearch-D,DisSearch-ED,and
thehighestdiversity. Thisdiversityalsoleadstoa DisSearch-EDCoTPipeline.
slight drop in overall F1 performance across tex-
tualsimilaritymetrics. Thisresultisnotsurprising
sincebydesign,duringthevariationaltrainingof Afterinitialization,weperformDiVERTtrain-
DiVERT,thep(e|s)modelalignswiththeentropy ing for LLMe, LLMd, and LLMq using the same
modelq (e|s,d),whichisencouragedtogenerate QLoRAsetupasabove. WeuseMonteCarlosim-
ϕ
errorsamplesaroundhuman-writtenerrorstolearn ulation to approximate the ELBO in Equation 1
arobusterrorspacerepresentation,leadingtobetter with 4 error samples drawn from q ϕ(e|s,d). We
downstreamdistractorgenerationperformance. useAdamWwithalearningrateof5e-6,matching
thelearningrateinMetaMathfinetuning(Yuetal.,
Wenotethatreference-basedevaluationmaype-
2023),andperformgradientclippingfortraining
nalizeerrorsthatfaithfullyreflectthemathematical
stability. A single batch contains 16 question-
error behind a distractor but are semantically dif-
distractor pairs, each having 4 Monte Carlo sam-
ferentthanthegroundtruth,orconversely,reward
ples, for an effective batch size of 64. We set β
errors that are invalid but semantically similar to
inEquation1to0.1,followingpriorwork(Ghosh
thegroundtruth. Therefore,weconductahuman
et al., 2020) to upweight the reconstruction loss.
evaluationofgeneratederrors,whichwedetailin
We set α in Equation 3 to 0.95 to upweight the
Section6.
ELBOcomparedtotheQregularizationloss. We
F ExperimentalSetup
trainfor1epochonasingleNVIDIAA10080GB
GPU,whichtakesupto9hours. Whereverpossi-
As detailed in Section 3.2, we finetune all ble, weusestandardhyperparametersanddonot
three LLMs, LLMe, LLMd, and LLMq, using do extensive parameter tuning like a grid search.
the collection of error label annotations behind DuetohighcomputationalandOpenAIAPIcost,
question-distractor(s,d)pairsobtainedfrommid- wereportperformanceononerunofourDiVERT
dle school math teachers, to initialize p (e|s), modelandbaselines. Formetrics,forROUGEwe
θe
p (d|s,e), and q (e|s,d), respectively. We use the rouge-score library with Porter stemmer
θ ϕ
d
use the AdamW (Loshchilov and Hutter, 2019) enabled,andforBERTScoreweusethebert-score
optimizer with a batch size of 32, a learning library with microsoft/deberta-xlarge-mnli as the
rate of 2e-5, and perform gradient clipping for underlying model. We additionally note that we
training stability. We use the Parameter Effi- used GitHub Copilot minimally in the writing of
cient Fine-Tuning (PEFT) library from Hugging- ourcode. Allsoftwareweuseinthedevelopment
Face (Wolf et al., 2020) to load the base LLM, ofthisworkisopensource. Weareconsistentwith
MetaMath-Mistral7B,andtrainvialow-rankadap- thetermsandintendeduseofallsoftwareandwith
tation (LoRA) (Hu et al., 2022) (LoRAα = theOpenAIAPI.G ExampleMCQsfromReal-worldMath • OverallRating: Theratingyougiveshouldre-
MCQDataset flecttheoverallqualityoftheerroracrossall
the above criteria; you may deem that some
We show example MCQs from the dataset in Ta-
criteria are more important than others de-
ble8.
pendingonthecontext,souseyourbestjudg-
ment.
H Prompts
H.1 PromptsforBaseLLMsinDiVERT
WeshowallpromptsusedforthebaseLLMsinDi-
VERT,theerrorpriormodelp(e|s)parameterized
byLLMeinTable9,thecontrollabledistractorgen-
erationmodelp(d|s,e)parameterizedbyLLMd in
Table 10, and the error identifier model p(e|s,d)
parameterizedbyLLMq inTable11.
H.2 PromptsforPrompting-basedBaselines
We show all prompts used for prompting-based
baselines,GPT-4oZero-shotCoTinTable12,and
GPT-4okNNinTable13.
I HumanEvaluationDetails
We received IRB approval for our human evalu-
ation of error quality. Our evaluators were vol-
unteers contacted through a research partner and
werenotcompensatedmonetarily. Theyweremade
awarethattheirannotationswouldbeusedinsci-
entificresearchinAI.Weprovidetheinstructions
giventothemforevaluatingerrorsinSupplemen-
taryMaterialI.1.
I.1 HumanEvaluationInstructions
For each error, provide a rating between 1 and 5
(inclusive)inthe“rating”column,where1isthe
worstand5isthebest.
Pleaseusethefollowingcriteriaforevaluating
errors:
• Relevant: The error should be applicable to
thecurrentquestionandthewayitissolved.
• Correct: Theerrorshouldbemathematically
soundandconcrete.
• Specific: The error should be specific to the
question’stopicnotbetoogeneric.
• Conceptual: Theerrorshouldbeconceptual
innature,suchthatitcouldbeappliedtoother
similarquestions.
• Plausible: The error should be likely to be
madebysome(ormany)realstudents.Questionstem Jamesstartscountingfrom−2,addingoneeachtime.Whatisthe5thnumberhesays?
Topic AddingandSubtractingNegativeNumbers
Concept Countforwardsstartingfromanegativeintegerincludingthroughzero
Solution 2
Correctanswer Startingon−2,weaddoneeachtime,movinguptowardsandthenbeyond0untilwereach
the5thnumber,whichis2.
Distractor1 6
Error1 Countsonby2,whenaskedtocountforwardinstepsof1
Distractor2 3
Error2 Countsonfromthewrongnumber
Distractor3 −6
Error3 Countsonfromthewrongnumber’
Questionstem 72 =?
Topic Squares,Cubes,etc
Concept Calculatethesquareofanumber
Solution 72 =7×7=49
Correctanswer 49
Distractor1 14
Error1 Mixesupsquaringandmultiplyingby2ordoubling
Distractor2 72
Error2 Readsapowerasanormaldigit
Distractor3 77
Error3 Mixesupsquaringwithrepeatingadigit
Questionstem Whatisthehighestcommonfactorof8and28?
Topic FactorsandHighestCommonFactor
Concept IdentifytheHighestCommonFactoroftwonumbers
Solution 8hasfactors1,2,4and8and28hasfactors1,2,4,7,14and28.Thehighestfactorcommon
tobothis4.
Correctanswer 4
Distractor1 28
Error1 Believesthelargestnumberinasetofnumbersisalwaystheirhighestcommonfactor
Distractor2 8
Error2 Believesthesmallestnumberinasetofnumbersisalwaystheirhighestcommonfactor
Distractor3 2
Error3 Identifiesacommonfactorbutnotthehighestcommonfactor
Table8: ExampleMCQsfromthereal-worldmathMCQdataset.
Ateacherassignsthefollowingmathquestiontoaclassofmiddleschoolstudents.
Thequestionis:<questionstem>
Thequestiontopicis:<topic>
Thequestionconceptis:<concept>
Thesolutionis:<workedoutsolution>
Thecorrectansweris:<answer>
Apossibleerrormadebyastudentis:
Table9: Promptforerrorpriormodelp(e|s)parameterizedbyLLMeinDiVERT.
Ateacherassignsthefollowingmathquestiontoaclassofmiddleschoolstudents.
Thequestionis:<questionstem>
Thequestiontopicis:<topic>
Thequestionconceptis:<concept>
Thesolutionis:<workedoutsolution>
Thecorrectansweris:<answer>
Theerrormadebythestudentis:<error>
Theincorrectanswergivenbythestudentis:
Table10: Promptforcontrollabledistractorgenerationmodelp(d|s,e)parameterizedbyLLMdinDiVERT.Ateacherassignsthefollowingmathquestiontoaclassofmiddleschoolstudents.
Thequestionis:<questionstem>
Thequestiontopicis:<topic>
Thequestionconceptis:<concept>
Thesolutionis:<workedoutsolution>
Thecorrectansweris:<answer>
Theincorrectanswergivenbythestudentis:<distractor>
Theerrormadebythestudentis:
Table11: Promptforerroridentifiermodelp(e|s,d)parameterizedbyLLMq inDiVERT.
Youaregiventhefollowingmathquestionalongwiththecorrectanswerandexplanation. Pleaseusethefollowing
templatetogive<n>alternativeincorrectanswerstobeusedasmultiple-choiceoptionsinamultiple-choiceexam.Prior
totheincorrectanswer,providetheunderlyingerrorcorrespondingtothatincorrectanswer. Theseerrorsshouldbe
conceptualinnatureandshouldnotrefertonumbers,variables,ornamesinthequestion.
[Template]
Distractor1Error:
Distractor1:
...
Distractor<n>Error:
Distractor<n>:
Question:<question>
Topic:<topic>
Concept:<concept>
Explanation:<workedoutsolution>
Answer:<answer>
Table12: PromptforGPT-4oZero-ShotCoT.
Youwillbegivenamathquestionalongwiththecorrectanswerandexplanation.Youwillbealsoprovidedwithseveral
examplequestionsthatincludeincorrectdistractoranswers. Pleasegenerate<n>incorrectdistractoranswersforthe
currentquestiontobeusedasmultiple-choiceoptionsinamultiple-choiceexam.
[Template]
Distractor1Feedback:
Distractor1:
...
Distractor<n>Feedback:
Distractor<n>:
<selectedexamples>
Question:<question>
Topic:<topic>
Concept:<concept>
Explanation:<workedoutsolution>
Answer:<answer>
Table13: PromptforGPT-4okNN.