Decentralized and Uncoordinated Learning of Stable
Matchings: A Game-Theoretic Approach
S. Rasoul Etesami and R. Srikant
† ‡
Abstract
We consider the problem of learning stable matchings in a fully decentralized and uncoordinated manner,
where decentralized means that players make decisions individually without the influence of a central platform,
and uncoordinated means that players do not need to synchronize their decisions using pre-specified rules. In
this problem, there are n men and n women, each having preference over the other side. It is assumed that
women know their preferences over men, but men are not aware of their preferences over women, and they
only learn them if they propose and successfully get matched to women. A matching is called stable if no
man and woman prefer each other over their current matches. When all the preferences are known a priori,
the celebrated Deferred-Acceptance(DA) algorithmproposedby Gale and Shapley providesa decentralizedand
uncoordinated algorithm to obtain a stable matching. However, when the preferences are unknown, developing
such an algorithm faces major challenges due to a lack of coordination. In this work, we achieve this goal by
makingaconnectionbetweenstablematchingsandlearningNashequilibria(NE)innoncooperativegames.First,
we provide a complete information game formulation for the stable matching problem with known preferences
such thatits setof pure NE coincideswith the set of stable matchings,while its mixedNE with fullsupportcan
be rounded in a decentralized manner to a stable matching. Relying on such a game-theoretic formulation, we
show that for hierarchicalstructured markets, adopting the exponentialweight (EXP) learning algorithm for the
stable matching game achieves logarithmic regret with polynomial dependence on the number of players, thus
answering a question posed in previous literature. Moreover, we show that the same EXP learning algorithm
convergeslocally and exponentiallyfast to a stable matching in general matching markets. We complementthis
result by introducing another decentralized and uncoordinated learning algorithm that globally converges to a
stable matching with arbitrarily high probability, leveraging the weak acyclicity property of the stable matching
game. Since the global convergence of this algorithm can be slow in general matching markets, we investigate
conditionsunderwhichstablematchingscanbelearnedmorequickly.Inparticular,forgeneralmatchingmarkets,
weshowthatifmenreceivestrongerfeedbackwhentheirproposalsarerejected,itispossibletodrivethemarket
morerapidlytowardanapproximatestablematching.Ourproposedgame-theoreticframeworkbridgesthediscrete
problem of learning stable matchings with the problem of learning NE in continuous-action games.
Index Terms
Learningstablematchings,learningNashequilibrium,weaklyacyclicgames,monotonegames,decentralized
learning, uncoordinated learning, online mirror descent, regret minimization.
Stable matchings constitute one of the fundamental problems in computer science, economics, and
engineering that have received considerable attention in the past decades. Stable matchings provide a
desirable notion of stability in two-sided matching markets where the agents on each side of the market
have preferences over the other side. For instance, in college admission, the applicants have different
preferences over colleges and vice versa, and the goal is to match the applicants to the colleges so that
no applicant-college pair would prefer to break their current matches and instead get matched to each
other. Similar situations arise in other applications, such as kidney exchange programs, assigning jobs
to workers, matching in online dating platforms, and scheduling jobs on heterogeneous machines.
It is known that when all the preferences are known, stable matchings always exist and a simple
decentralized and uncoordinated Deferred-Acceptance (DA) algorithm, first proposed by [1], can find
one such stable matches in polynomial number of iterations. Here, by a decentralized algorithm we refer
†Department of Industrial and Systems Engineering, Department of Electrical and Computer Engineering, and Coordinated Science
Laboratory, University of Illinois Urbana-Champaign, Urbana, IL 61801 (Email: etesami1@illinois.edu).
‡Department of Electrical and Computer Engineering and Coordinated Science Laboratory, University of Illinois Urbana-Champaign,
Urbana, IL 61801 (Email: rsrikant@illinois.edu).
4202
luJ
13
]TG.sc[
1v49212.7042:viXrato an algorithm in which players make decisions individuallywithout the influence of a central platform,
and uncoordinated means that players do not need to synchronize their decisions using pre-specified
rules. While the DA algorithm provides a satisfactory solution to many practical applications, there are
scenarios where either the information structure of the problem hinders the implementation of the DA
algorithm or the stable matching achieved by the DA algorithm is inferior in terms of social optimality,
especially when there exist many feasible stable matchings in the market. For instance, there are many
recent emergence of online matching markets such as online labor markets (e.g., TaskRabbit, Upwork),
online dating markets (e.g., Tinder, Match.com), and online crowdsourcing platforms (e.g., Amazon
mechanical turk), where the users do not know their preferences a priori, and can repeatedly interact
with the market to improve their matching quality [2]. The more a pair on both sides of the market gets
matched, the more certain they will be about their preferences. Therefore, a question of interest is how
the agents should interact with the market such that in the absence of any coordination, they will learn
their preferences as quickly as possible, and their collective behavior results in a stable matching.
In this work, we consider a two-sided matching market posed as a marriage problem, where we refer
to the agents of one side as men and to the agents of the other side as women. We assume both men and
women have preferences on the other side and that women are aware of their ordinal preferences about
men. However, men do not know their preferences about women and only learn those preferences if they
propose and get matched, in which case the matched men receive a noisy estimate of their preferences.
We assume that men/women cannot observe any other information (e.g., who is rejected/accepted), nor
can they coordinate in any sense. The goal for men is to follow a decentralized and uncoordinated
proposal strategy such that the entire market converges to a stable matching over time.
One of the major challenges for learning a stable matching in markets with unknown preferences is
the collisions. More precisely, when multiple men propose to the same woman, only one of them gets
matched and receives useful information; all others get rejected and receive no information regarding
their preferences for that woman. Therefore, resolving such collisions without coordination is a major
issue. Moreover, even if a man gets matched to a woman, he receives a noisy utility drawn from an
unknown distribution that could differ from his true preference. Thus, a collision-avoidance process
should be repeated many times until men can accurately estimate their true preferences. One of our
goals in this work is to provide decentralized and uncoordinated algorithms that can effectively learn
the true preferences while incurring a minimum number of collisions. Moreover, our work provides
an alternative approach for measuring the closeness of the generated dynamics to any stable matching
in general matching markets and not necessarily to a specific stable matching in structured markets,
which has been the main focus in the past literature. To that end, we make a connection between
learning stable matchings in general markets with unknown preferences and learning Nash equilibrium
(NE) in noncooperative games and leverage this connection to devise decentralized and uncoordinated
algorithms for learning stable matchings.
A. Related Work
Stable matching was first introduced by [1] as a model for college admissions and to study the
stability of marriages. Since then, there has been a tremendous effort on generalization and extension
of stable matchings to various market settings [3]. In their seminal work, Gale and Shapley provided a
simple DA algorithm in which men propose to their most preferred women, and the women reject all
the received proposals except the most preferred one. They show that such a decentralized algorithm
converges to a stable matching in at most O(n2) steps, where n is the total number of men/women in
the market. Unfortunately, when the agents’ preferences are unknown, the DA algorithm is no longer
guaranteed to converge to a stable matching without extra coordination. More precisely, if men fail to
propose to their highest preferred women (due to a lack of knowledge of their true preferences), their
subsequent proposals may become unpredictable. One reason is that if a man m is rejected by a woman
w at a time instance t, that does not mean that m should stop proposing to w because it could be thecase that another man mistakenly proposed to w at time t, hence causing the rejection of m by w.
Therefore, in order to extend the DA algorithm to the case of unknown preferences, one requires some
sort of coordination among the agents to avoid uninformative acceptance/rejection patterns. To address
this issue, the earlier works [2], [4]–[6] have proposed various coordination-based DA algorithms, where
the main idea is to develop a phase-dependent process where in some phases the agents mostly explore,
and in other phases, they implement the DA algorithm based on the current estimates of their unknown
preferences.
It is known that stable matchings with known preferences can be characterized using extreme points
of a fractional polytopethat is totallydual integral [7], [8]. Moreover, stablematchings exhibitother nice
properties that allow one to characterize their geometry using so-called rotations [9]. It was shown in
[10] that uncoordinated random better response dynamics converge to a stable matching with probability
one. Subsequently, [11] provided an exponential lower bound for the worst-case convergence time of the
uncoordinated random better/best response dynamics to a stable matching. However, all these results
are for the case when the market preferences are fully known so that the agents can compute their
best/better responses and update their decisions accordingly.
Morerecently,therehasbeenahugeinterestinmatchingmarketswithunknownpreferences.However,
depending on the information structure and the feedback received by the agents, one would expect a
wide range of performance guarantees, which also depends on the type of algorithms followed by the
agents (e.g., centralized/decentralized or coordinated/uncoordinated). The work [12] devised a random-
ized polynomial-time centralized algorithm for finding a stable matching with unknown deterministic
preferences, where each time, the algorithm proposes a matching and receives feedback in terms of a
blocking pair.1 The work [13] considers learning a specific stable matching with unknown stochastic
preferences by adoptinga suitablenotionof stable regret that measures the numberof timeinstances that
men propose to women other than their stable pair in that stable matching. [2] considered the problem of
learning stable matchings in hierarchically structured markers2 in which each submarket has a fixed pair
(i.e., a pair of men-women that prefer each other the most in that submarket), and developed a phase-
coordinated decentralized algorithm that achieves logarithmic regret with respect to the market’s unique
stable matching. However, the regret bound in [2] depends exponentially on other parameters such as the
number of men/women. Furthermore, [15] considered learning stable matchings in an uncoordinated and
decentralized fashion. However, they require stronger assumptions on the information feedback (e.g.,
a player observes the actions of other players in the previous round) and use a different performance
metric than the one we consider in this work. We refer to [16] and [17] for other learning algorithms
in two-sided matching markets with different performance guarantees. While all these works essentially
address the same problem of learning a stable matching with unknown preferences, their algorithms
differ substantially due to the information/feedback structure, the type of performance guarantee, and
the amount of allowable coordination among the agents.
B. Contributions and Organization
We consider the problem of learning stable matchings in matching markets, where men do not
know their preferences and want to achieve a stable matching in a decentralized and uncoordinated
fashion. In particular, we consider the weakest type of feedback that men can receive: a man gets
to observe a noisy version of his true preference only if his proposal gets accepted and receives no
information otherwise. Our main objective is to provide a novel and principled approach to designing
decentralized and uncoordinated learning algorithms for stable matchings through the lens of NE
learning in noncooperative games. Our contributions can be summarized as follows:
1A unmatched pair of man-woman (m,w) is called blocking if both m and w prefer each other to their matched partner.
2In fact, the hierarchical condition (a.k.a. sequential preference condition [14]) that we consider in Section III is weaker than the
α-reducible condition considered in [2], and our results hold for broader matching markets including the ones considered in [2].Wefirstprovideacompleteinformationcontinuous-actiongameformulationforthestablematching
•
problem and show that its set of pure NE coincides with the set of stable matchings while its mixed
NE points can be rounded in a decentralized way to a stable matching. This connection provides
an alternative approach for measuring the closeness of the market dynamics to stable matchings
through the lens of NE computation in games, hence extending the conventional notion of regret
with respect to a specific stable matching to any arbitrary stable matching in general markets.
Leveraging this game-theoretic formulation, we provide a simple decentralized and uncoordinated
•
algorithm EXP that converges globally to a stable matching in hierarchical markets and achieves
logarithmic regret with only polynomial dependence on the number of players, hence improving
the existing bounds in the past literature.
We then show that the EXP algorithm converges locally exponentially fast to a stable matching in
•
general matching markets. In particular, we show that if EXP converges with positive probability,
it converge globally to a stable matching.3
We also providean alternativedecentralized and uncoordinated algorithm that globally converges to
•
a stable matching in general markets with arbitrarily high probability (albeit at a low convergence
rate), thanks to the weakly acyclic property of the stable matching game.
Finally,weaddressaninformationfeedbackdesignproblembyseekingconditionsingeneralmatch-
•
ing markets that allow players to learn a stable matching quickly. In this regard, we leverage our
game-theoretic framework to provide one such information feedback by establishing a connection
to monotonegames. Our results offer new insights into designing payoff functions that enable faster
decentralized and uncoordinated algorithms for driving matching markets to their stable points.
The paper is organized as follows. In Section I, we formally introduce the problem. In Section II, we
provide a complete information game-theoretic formulation for the stable matching problem and prove
several characterization results for its set of NE points. In Section III, we provide a decentralized
and uncoordinated algorithm (EXP) that achieves logarithmic regret for hierarchical markets with
polynomial dependence on the number of players. In Section IV, we show that EXP converges locally
exponentially fast to a stable matching in general matching markets. In Section V, we provide an
alternative decentralized and uncoordinated algorithm that globally converges to a stable matching in
general matching markets with arbitrarily high probability. In Section VI, we extend our results to
matching markets with stronger feedback and establish a connection between fast global learning of a
stable matching and learning a NE in monotone games. We conclude the paper by identifying some
future research directions in Section VII.
I. PROBLEM FORMULATION
Stable Matchings with Known Preferences
Here, we first introduce the stable matching problem with known preferences [1]. In this problem,
there are a set M of men and a set W of women such that M = W = n (we use the term “agents” to
| | | |
refer to either men or women).4 Each man m M has a cardinal preference for each women w W,
∈ ∈
denoted by µ
mw
(0,1], such if µ
mw
> µ mw′, it means that m prefers w over w ′. Moreover, each
∈
woman w has an ordinal preference over the men, and we write m > m if woman w strictly prefers
w ′
m over m. In this work we assume that no agent has ties in their preferences and we define
′
∆ = min µ mw µ mw′ , µ min = minµ mw, µ max = maxµ mw.
m,w=w′| − | m,w m,w
6
In particular, we note that ∆ > 0 and µ > 0.
min
3Perhaps fast local convergence is the best one can hope for general markets because, for general matching markets, there are strong
exponential lower bounds for the number of iterates of the better response dynamics to converge globally to a stable matching.
4By introducing dummy agents with appropriate preferences, without loss of generality we may assume |M|=|W| [7].Definition 1: Given a matching and two matched pairs (m,w) and (m,w ), we say that (m,w )
′ ′ ′
forms a blocking pair if µ mw′ > µ mw and m > w′ m ′. In other words, (m,w ′) is a blocking pair if both
m and w prefer each other over their current matches. A perfect matching is called a stable matching
′
if it does not contain any blocking pair.
Stable Matchings with Unknown Preferences
In this work, we consider the problem of finding a stable matching with the main difference that
men do not know their true preferences µ , and they only get to learn them through interactions with
mw
the market. More precisely, for any m M,w W, we assume that the preference of man m about
∈ ∈
woman w is in the form of a [0,1]-supported unknown distribution with unknown mean µ > 0.
mw mw
D
We assume men and women interact in this market through a discrete-time process, where at any time
t = 0,1,2,... that a man m proposes to a woman w, he receives a feedback in the following form:
If the proposal of m gets rejected at time t because woman w has received an offer from a more
•
preferred man m, i.e., m > m, then m receives no information as feedback other than the fact
′ ′ w
that he was rejected by woman w at time t.
If the proposal of m gets accepted by w at time t, then m observes an i.i.d. realization of his
•
sampled preference drawn from , denoted by µˆt .
Dmw mw
In the stable matching problem with unknown preferences, the agents’ goals are to interact with the
market through the information feedback structure described above such that the emerging dynamics
converge to a stable matching of the market with known preferences µ . We note that in the discrete-
mw
{ }
time process described above, men are the decision makers on whom to propose at each time t; women
merely respond to men’s decisions by accepting their most preferred proposal (if they received any)
and rejecting all others.
II. A GAME-THEORETIC FORMULATION AND PRELIMINARY RESULTS
In this section, we provide a complete information noncooperative game formulation for the stable
matching problem with known preferences whose set of pure Nash equilibrium (NE) points coincides
with the set of stable matchings. Later, we will show how to leverage this formulation to extend our
results for learning stable matchings with unknown preferences. Such a formulation has three main
advantages: i) it reduces the learning task in matching markets to learning NE in continuous-action
concave games, ii) it captures the selfish behavior of men (players) and the feedback they receive
through their payoff functions, and iii) it simplifies the combinatorial structure inherent in learning
stable matchings to learning NE in continuous-action games. While analyzing the agents’ decisions
directly on the discrete space of matchings seems complicated, which is why some earlier works need
to restrict attention to special market structures [2], our game-theoretic reduction simplifies this task to
some extent, thanks to the extensive literature on NE learning in concave games.
Consider a complete information noncooperative game in which the action set of each man (player)
is given by the set of women W, and the set of (mixed) strategies for each player is given by the
probability simplex over the set of women W, i.e., the strategy set of player m is defined by
Xm = x m
∈
R | +W | : x mw = 1 .
n w X∈W o
Moreover, given a strategy profile x = (x ,x ), we define the payoff of player m by 5
m m
−
u (x) = µ (1 x ) x , (1)
m mw kw mw
−
w X∈W (cid:16) k> Ywm (cid:17)
where µ > 0 is the utility (true preference) received by man m if he gets matched to women w.
mw
5Here, x−m refers to the strategy vector of all the players except the mthone.Definition 2: A strategy x for player m is called pure if it is zero in all coordinates except one.
m
Otherwise, it is called a mixed strategy. A pure (mixed) strategy profile x is called a pure (mixed) NE
∗
if for any player m and any pure (mixed) strategy x , we have u (x ,x ) u (x ,x ).
Remark 1: A strategy x can be represented as a
m
weighted
bipam rtitem gra∗ −pm
h
≤ (x)m =∗m (M∗ −m
W,E(x))
H ∪
between men and women. In this graph, the edges E(x) = (m,w) : x > 0 are supported over the
mw
{ }
nonzero entries of x, with the weight of edge (m,w) given by x .
mw
One can interpret u (x) as the expected utility that player m would receive by successfully getting
m
matched if each man independently proposes to women according to his mixed strategy distribution
x . The reason for defining the payoff functions as in (1) is that we want our devised algorithms
m
to be implemented in a fully decentralized and uncoordinated manner among men by relying only
on their received feedback (embedded into their payoff functions). While such payoff functions are
highly nonlinear, they are essential to eliminate any degrees of coordination among the players. In
other words, the cost of devising a fully coordination-free algorithm comes in analyzing more complex
payoff functions with higher degrees of nonlinearity. We refer to Section VI for a simpler form of payoff
functions with less degree of nonlinearities, which in turn requires stronger information feedback. The
following are three properties of the payoff functions (1).
(i) Player m’s strategy does not have any impact on the coefficient terms µ (1 x ),
mw k>wm − kw
w W. In particular, the gradient of u ( ) with respect x is given by
m mw
∈ · Q
v (x) := u (x) = µ (1 x ).
mw mw m mw kw
∇ −
k> Ywm
(ii) The payoff of each player m is linear with respect to his own strategy x .
m
(iii) For any fixed strategy of other players x , player m always has a best response among pure
m
−
strategies that is obtained by setting x = 1 for the woman w that achieves the maximum value
mw
v (x), and x = 0 otherwise.
mw mw
In the remainder of this paper, we will refer to the above noncooperative game as the stable matching
game and simply denote it by = (M, u , ). It is worth noting that although we are
m m M m m M
G { } ∈ {X } ∈
interested in obtaining a NE of the stable matching game, which is a complete information one-shot
game, our goal is to learn one such NE by repeatedly playing the incomplete information game, in
which the true preferences µ (and hence the payoff functions) are not fully known. In fact, the set
mw
of pure/mixed NE points of the stable matching game has some interesting connections with the set of
stable matchings with known preferences. The following theorem establishes one such result.
Theorem 1: A pure strategy profile x 0,1 n2 corresponds to the characteristic vector of a stable
∗
∈ { }
matching if and only if it is a pure NE for the stable matching game.
Proof: Suppose x is a pure NE. Then, we cannot have x = x = 1 for some woman w and
∗ ∗mw ∗m′w
m = m. Otherwise, between m and m, the one that woman w prefers less receives zero utility, while
′ ′
6
he can always deviate to propose to a woman w that does not have any offer and strictly improve his
′
utility. Therefore, x must correspond to the characteristic vector of a perfect matching. To show that
∗
x is a stable matching, let us, by contradiction, assume that there exists a blocking pair with respect to
∗
the matching x and denote it by (m,w). Moreover, let m and w be the corresponding matches for w
∗ ′ ′
and m under x ∗, that is x ∗mw′ = 1 and x ∗m′w = 1. Since (m,w) is a blocking pair, we have µ mw > µ mw′
and m >
w
m ′. The payoff of player m under NE x
∗
equals u m(x ∗) = µ mw′. Now if player m changes
its strategy to x := (0,x = 1), his payoff becomes
m mw
u (x ,x ) = µ (1 x )x = µ (1 x ) = µ ,
m m ∗m mj
−
∗kj mj mw
−
∗kj mw
−
j X∈W k Y>jm k> Ywm
where the second equality holds because m < m so that the term 1 x does not appear in the
′ w
−
∗m′w
product (1 x ), and moreover x = 0 k = m, which implies (1 x ) = 1. This
k>wm − ∗kw ∗kw ∀ 6 ′ k>wm − ∗kw
shows that u m(x m,x ∗m) = µ mw > µ mw′ = u m(x ∗), contradicting the fact that x ∗ is a NE.
Q − QConversely, let x be the characteristic vector of a stable matching, and by contradiction, assume it
∗
is not a NE. Then, there exists at least one player m who can deviate and strictly improve his payoff.
In particular, we can consider his pure strategy best response move, which is guaranteed by (iii), and
denote his most preferred woman by w. Moreover, let m and w be the corresponding matches for w
′ ′
and m under the stable matching x , i.e., x = x = 1. The current payoff of m under the pure
∗ ∗m′w ∗mw′
strategy x
∗
equals u m(x ∗) = µ mw′, while his payoff after such deviation becomes
u (x ,x ) = µ (1 x )x = µ (1 x ) µ . (2)
m m ∗ −m mj − ∗kj mj mw − ∗kw ≤ mw
j X∈W k Y>jm k> Ywm
Since 0 < µ mw′ = u m(x ∗) < u m(x m,x ∗m), we obtain µ mw′ < µ mw. Moreover, from relation (2) and
the fact that u (x ,x ) > 0, we mu−st have (1 x ) = 1, which implies m < m. This
together with µm mw′m < µ∗ − mm
w
shows that (m,w) is ak b> lw om cking− pa∗k iw r, contradicting that x
∗
is ′ stabw le.
Q
While the above equilibrium characterization theorem concerns pure NE points, it is possible that the
stable matching game admits a mixed NE. The following is one example.
Example 1: LetusconsideraninstanceofthestablematchinggamewiththreemenM = m ,m ,m
1 2 3
{ }
and three women W = w ,w ,w . We assume the preferences of men and women are given by
1 2 3
{ }
µ = 2, µ = 1, µ = ǫ, m < m < m ,
m1w1 m1w2 m1w3 3 w1 1 w1 2
µ = 3, µ = 4, µ = 5, m < m < m ,
m2w1 m2w2 m2w3 3 w2 2 w2 1
µ = ǫ, µ = 12, µ = 6, m < m < m ,
m3w1 m3w2 m3w3 1 w3 2 w3 3
where ǫ > 0 is a small positive constant. Then, the stable matching game has a mixed NE that is
supported over seven edges comprising of two cycles of length 4 that share the common edge (m ,w )
2 2
(see, Remark 1). In particular, the seven positive entries of that mixed NE are given by
µ µ
x =
m2w1,
x = 1
m2w1,
m1w1
µ
m1w2
− µ
m2w2 m2w2
µ µ µ µ µ µ
x = 1
m1w2,
x = 1
m2w2 m3w3,
x =
m1w2
+
m2w2 m3w3
1,
m2w1
− µ
m2w2
− µ µ
m2w3
µ µ µ −
m1w1 m2w1 m3w2 m1w1 m2w1 m3w2
µ µ
x =
m2w1,
x = 1
m2w1.
m3w2
µ
m3w3
− µ
m2w3 m2w3
As Example 1 suggests, mixed NE points may represent unpredictable bipartite graphs (Remark 1),
and it is difficult to make general statements about their structure. However, the following theorem
establishes an interesting connection between mixed and pure NE points, implying that obtaining a
mixed NE with full support on the women’s side is as satisfactory as obtaining a pure NE.
Theorem 2: Let x be any mixed NE in which each woman receives at least one (fractional) proposal.6
For each man m, let w be the least preferred woman among those that he fractionally proposes to
m
them, i.e., w = argmin µ : x > 0 . Then (m,w ),m M forms a stable matching (and
hence a
purem
NE) for
thew ∈sW tab{ lem mw atchm inw
g
gam}
e.
{ m ∈ }
Proof: Please see Appendix B for the proof.
Theorem 2 suggests some strategies for obtaining decentralized solutions.We can first design a decen-
tralized algorithm (see Algorithm 1 in conjunction with the preference estimation oracle of Algorithm
3) to learn a mixed NE of the stable matching game and acquire estimated preferences. Subsequently,
each man can convert his fractional mixed strategy into a pure strategy in a decentralized manner by
proposing only to his least (estimated) preferred woman among those he fractionally proposes to. This
process ensures that the resulting pure strategy profile will be a pure NE with high probability, and the
6If this condition does not hold, the theorem statement continues to hold for the induced submarket where each woman has received
at least one fractional proposal.probability of error vanishes over time. Importantly, each man has complete access to his own estimated
preferences, and the rounding process outlined in Theorem 2 does not require knowledge of others’
mixed strategies. Each man only needs to be aware of his own mixed strategy and estimated preferences.
This approach offers a simple decentralized method to convert mixed NE points into stable matchings.
III. LOGARITHMIC REGRET FOR HIERARCHICAL MARKETS
In this section, we consider the stable matching game with unknown preferences and develop a
decentralizedand uncoordinatedalgorithmforlearningitsNEpoints.Inparticular,wefocusonmatching
markets with specific structures because without imposing any assumption on the matching market,
there are exponential lower bounds for the number of iterations to find a stable matching through
better response dynamics [11]. One example of such a structured matching market is the hierarchical
matching market, where it was shown in [2] that if men follow a certain decentralized (but coordinated)
algorithm, the men’s expected regret (see Definition 3) is at most logarithmic in time but exponential
in terms of other parameters such as the number of men n. In particular, the authors in [2] raised
the question of how to remove the exponential dependence of the regret on n. In this section, we
show that Algorithm 1 achieves this goal whose regret is logarithmic in time with a polynomial
factor in terms of other parameters. Moreover, Algorithm 1 is uncoordinated and, hence, removes the
phase-dependent coordination required by the algorithm in [2]. Throughout this section, we impose the
following hierarchical assumption on the matching market.
Assumption 1: WeassumethatthesetsofmenandwomencaneachbeorderedasM = m ,...,m
1 n
{ }
and W = w ,...,w such that any man and woman with the same rank prefer each other above any
1 n
{ }
other partner with a lower rank; i.e., man m prefers woman w to women w ,w ,...,w , and
k k k+1 k+2 n
woman w prefers man m to men m ,m ,...,m . It is easy to see that under this hierarchical
k k k+1 k+2 n
assumption, the matching (m ,w ),k = 1,...,n is a stable matching.
k k
{ }
Remark 2: The condition imposed in Assumption 1 is also known as the Sequential Preference
Condition (SPC) [14] and is weaker than the α-reducible condition considered in [2], which assumes
that each submarket has a fixed-pair: A pair (m,w) is called a fixed pair if both m and w prefer
each other the most among anyone else in that submarket.7 Since Assumption 1 is weaker than the
α-reducible condition, all our results immediately applies to α-reducible markets.
Definition 3: Let us assume that players follow a decentralized and uncoordinated algorithm that
A
results in a sequence of proposals αt = (αt ,m M),t = 1,...,T. The expected regret of equals
m ∈ A
T
R(T) = E 1 ,
{∃k ∈[n]:αt mk6=wk}
t=1
X (cid:2) (cid:3)
which is the expected number of times that the men’s proposals do not form a stable matching.
A. Algorithm Design and Preliminaries
The algorithm that we propose is an adaptation of the online dual mirror descent for adversarial
multi-arm bandit problem (see, e.g., EXP3 Algorithm in [18, Chapter 11]) to the stable matching game,
where for simplicity we refer to it as the EXP algorithm. In particular, it uses an entropy regularizer
and adaptive stepsize for updating the players’ mixed strategy distributions over time.
To describe the EXP algorithm, let us denote the gradient vector of player m by v (x) = u (x)
m m m
∇
such that for any woman w, we have v (x) = µ (1 x ). In particular, we note that
mw mw k>wm − kw
u (x) = x ,v (x) . Therefore, when restricting to a pure strategy (action)profile αt = (αt,...,αt)
m h m m i Q 1 n ∈
W W that is played at time t, the w-th coordinate of the gradient vector is given by
×···×
vt := µ 1 , (3)
mw mw {αt k6=w ∀k>wm
}
7In fact, one can show that a matching market has a unique stable matching if and only if it satisfiesα-reducible condition [2].where 1 denotes the indicator function. On the other hand, by playing a pure strategy profile αt, each
man m r{ e·} ceives a feedback only for the woman αt that he has proposed to her at time t. In particular,
m
if αt = w, player m observes the payoff µt 1 1 at time t, where we recall that
µt m is the realization of a random reward m drw aw{ nαt k i6= nw de∀ pk e> nw dm e} nt{ lyαt m f= row m} an unknown distribution
mw Dmw
with unknown mean µ and bounded variance σ2 [0,1].
mw mw ∈
During the course of the algorithm, at each time t, each player m holds a mixed strategy Xt
m ∈ Xm
and updates it whenever he receives new information. He then computes his adjusted mixed strategy
Xˆt = (1 γt)Xt + γt1, where γt > 0 is a mixing parameter and 1 is the vector of all ones. Using
m − m n
ideas from importance sampling for bandit problems [19], [20], and to obtain an unbiased estimator
of the actual gradient vector, player m constructs an estimate vector vˆt by normalizing the received
m
feedback with his adjusted mixed strategy probabilities as
µt 1
vˆt = mw {αt k6=w ∀k>wm } 1 , w W. (4)
mw Xˆt · {αt m=w } ∈
mw
ThereasonwhyweuseadjustedmixedstrategiesXˆt withadditionalmixingparameterγt istoensurethat
the mixed strategies remain bounded away from zero by a positive quantity. That makes the estimators
(4) have bounded variance (see Lemma 1), which allows us to use martingale concentration results to
bound the probability of various events.
Let us denote the (random) score vector of player m at time t 1 by Lˆt 1 = (Lˆ ,w W).
Player m uses Lˆt 1 to compute his mixed strategy vector Xt using− the logit um p− date rulemw (5). H∈ e then
m− m
proposes to a woman αt chosen independently at random according to his adjusted mixed strategy
m
Xˆt , and receives as feedback vˆt with entries given by (4). Player m then updates his score vector
m m
by Lˆt = Lˆt 1 +vˆt and proceeds to the next round. The detailed description of the EXP algorithm is
m m− m
summarized in Algorithm 1.
Algorithm 1 EXP: An Uncoordinated and Decentralized Algorithm for Player m
Input: A decreasing stepsize sequence ηt , a mixing sequence γt , and an initial vector Lˆ0 = 0.
{ } { } m
For t = 1,2,..., player m independently performs the following steps:
Player m computes his mixed-strategy vector Xt using the logit map
• m
exp(ηtLˆt 1)
Xt = m−w , w W. (5)
mw exp(ηtLˆt 1 ) ∈
w′ m−w′
Player m draws a pure strategy αt WPaccording to his adjusted mixed strategy defined by
• m ∈
γt
Xˆt = (1 γt)Xt + 1, w W,
m − m n ∈
where γt > 0 is a mixing parameter and ηt > 0 is the stepsize.
Player m receives a feedback in terms of his observed payoff at time t and constructs an unbiased
•
estimate of his actual payoff gradient vector:
µt 1
vˆ mt w = mw {α Xt k ˆ6= tw ∀k>wm } ·1 {αt m=w }, w ∈ W, (6)
mw
where µt is the realization of the random reward if m is matched to w at time t, and updates
mw
Lˆt = Lˆt 1 +vˆt , w W.
mw m−w mw ∈In order to analyze the convergence behavior of Algorithm 1 to a stable matching, let t 1 be
{F
− }∞t=1
the increasing filtration sequence that is adapted to the history of the random processes generated by
Algorithm 1. More precisely,
t 1 = Xτ,Lˆτ,ατ,vˆτ,τ = 0,1,...,t 1 Xt ,
−
F { − }∪{ }
contains all the realized events up to time t 1 except the realization of pure strategies αt and the
rewards µt at time t. In particular, all releva− nt processes at time t 1 as well as Xt and Xˆt are
−
t 1-measurable, but αt and vˆt are not t 1-measurable.
− −
F F
We begin with the following lemma, which shows that the feedback vˆt received by player m at time
m
t is conditionally an unbiased and bounded estimator of the actual gradient vector vt .
m
Lemma 1: The received feedback is a conditionally unbiassed and bounded estimate of the gradients
σ2 n
E [vˆt t 1] = v (Xˆt) m, E [(vˆt )2 t 1] m,w,
m|F − m ∀ mw |F − ≤ Xˆt ≤ γt ∀
mw
where σ2 := max E [(µˆt )2] [0,1].
m,w mw ∈
Proof: Consider any pair (m,w). Since Xˆt is t 1-measurable and µˆt is drawn independently
mw F − mw
from the algorithm’s past decisions (and hence is independent of t 1 and αt), we have
−
F
E [µt ]
E [vˆt t 1] = mw E [1 1 t 1]
mw|F − Xˆt · {αt k6=w ∀k>wm } · {αt m=w }|F −
mw
µ
= mw P αt = w t 1 P αt = w t 1
Xˆt { m |F − } { k 6 |F − }
mw k Y>wm
= µ (1 Xˆt ) = v (Xˆt),
mw − kw mw
k> Ywm
where the second equality holds because conditioned on t 1, the random variables αt, k are
mutually independent as they are drawn independently from tF he− given distributions Xˆt, k{ .k Si∀ mi} larly,
{ k ∀ }
E [(µˆt )2] σ2 n
E vˆt 2 t 1 = mw P αt = w t 1 , m,w.
mw |F − Xˆt { k 6 |F − } ≤ Xˆt ≤ γt ∀
(cid:2)(cid:0) (cid:1) (cid:3)
mw k> Ywm mw
B. Performance of Algorithm 1 for Hierarchical Markets
Here, we analyze the performance of Algorithm 1 for hierarchical matching markets. In the following
analysis,weassumethatapositivelowerboundforc := 1 min ∆,µ isknowntoalltheplayers
8 k ∈[n] { mkwk}
so that they can choose their mixing parameters in Algorithm 1. However, as we discuss in Appendix
G, this condition can be relaxed up to some extent by using an uncoordinated and decentralized UCB
gap estimation oracle in which the players use their estimated gaps to tune their mixing parameters.
The main result of this section is presented in Theorem 3, which essentially shows that for hierarchical
matching markets, Algorithm 1 achieves an expected regret that is logarithmic in T and polynomial in
terms of other parameters. However, before delving into the analysis, we first provide an overview of
the main steps in the proof.
First, we define a “good” event Ω, which represents the set of circumstances where the difference
• between the accumulated realized rewards, ηt(Lˆt Lˆt ), for any m,w,w˜, and t, remains close
mw˜ − mw
to its conditional expected value. In particular, Lemma 2 shows that the event Ω occurs with very
high probability. This allows us to analyze the performance of Algorithm 1 under its conditional
mean trajectory while incurring only a small, controllable loss.Conditioned on the event Ω, Lemma 3 shows that, due to the market structure and payoff functions,
•
as time progresses, more pairs in the market are matched according to the underlying hierarchical
order with very high probability. Additionally, the size of such hierarchical nested matchings grows
with very high probability after a polynomial number of steps.
Finally, in Theorem 3, we combine the results of Lemma 2 and Lemma 3 to bound the expected
•
regret of Algorithm 1 by conditioning on the event Ω.
Let us consider the stochastic dynamics of Algorithm 1 that are given by
exp(ηtLˆt 1)
Xt = m−w ,
mw exp(ηtLˆt 1 )
w′ m−w′
γt
Xˆt = (1P γt)Xt + 1,
m − m n
Lˆt = Lˆt 1 +vˆt .
mw m−w mw
Define Yt = t v (Xˆτ), where v (Xˆτ) = µ (1 Xˆτ ), and consider the event
mw τ=1 mw mw mw k>wm − mw
Ω :=P ηt Lˆt 1 Lˆt 1 ηt Yt 1 Yt 1 Q 2c√t, t 1, m,w,w˜ ,
m−w˜
−
m−w
−
m−w˜
−
m−w
≤ ∀ ≥ ∀
n o
where c = 1 min (cid:12) ∆(cid:0) ,µ is a(cid:1)consta(cid:0)nt parameter.(cid:1)T(cid:12) he following lemma provides a high proba-
8 k ∈[n](cid:12) { mkwk} (cid:12)
bility bound for the event Ω to occur under appropriate choice of stepsize and mixing parameter.
Lemma 2: Fix an arbitrary δ (0,1), and suppose each player follows Algorithm 1 with stepsize
ηt = 1 and mixing parameter γt∈ = Mlogt, where M = 4n log 1. Then, P Ω 1 δ.
√t t c δ { } ≥ −
Proof: Fix an arbitrary man m. For any w,w˜, as in (22), we can write
t 1
−
ηt(Lˆt 1 Lˆt 1) = ηt v (Xˆτ) v (Xˆτ) +ηtSt 1 ηtSt 1
m−w˜
−
m−w mw˜
−
mw m−w˜
−
m−w
τ=1
X(cid:0) (cid:1)
= ηt(Yt 1 Yt 1)+ηtSt 1 ηtSt 1, (7)
m−w˜
−
m−w m−w˜
−
m−w
whereS mt −w1 := t τ− =1
1
vˆ mτ w−v mw(Xˆτ) ∀m,w.AccordingtoLemma1, {vˆ mτ w−v mw(Xˆτ) }isamartingale
difference sequence that satisfies
P (cid:0) (cid:1)
n n
vˆτ v (Xˆτ) , E [ vˆτ v (Xˆτ) 2 τ 1] .
| mw − mw | ≤ γτ mw − mw |F − ≤ γτ
(cid:0) (cid:1)
By taking u = γtn −1, v2 = t τ− =1
1
γn τ, and x = ct in Lemma 7 (see Appendix A) and noting that the
event Vt v2 holds with probability 1, we obtain
{ ≤ } P
Mc2t2
P ηt St 1 c√t = P St 1 ct 2exp − . (8)
{ |
m−w|
≥ } {|
m−w|
≥ } ≤ 2n( t −1 τ + ct(t −1) )
(cid:16) τ=1 logτ log(t 1) (cid:17)
−
Since f(τ) := τ is a concave function for τ 100, using JensePn’s inequality, we have
logτ ≥
t 1 t 1 t 1 t 1 τ
1 − τ − 1 − 1 − t
= f(τ) f( τ) = τ=1 t 1 = .
−
t −1 τ=1 logτ τ=1 t −1 ≤ τ=1 t −1 log P t τ− =1 1 tτ 1 2log 2t
X X X −
Therefore, t 1 τ t(t 1) t2 . Substituting this relation and (cid:0)tP(t 1) t(cid:1)2 into (8) we get
τ− =1 logτ ≤ 2lo− g t ≤ logt log(− t 1) ≤ logt
2 −
P Mc2t2 Mc2logt 2δ
P ηt St 1 c√t 2exp − = 2exp − ,
{ | m−w| ≥ } ≤ 2n(1+c) t2 2n(1+c) ≤ (nπt)2
(cid:16) logt(cid:17) (cid:16) (cid:17)where the last inequality is obtained by choosing M sufficiently large (e.g., M = 4n log 1). Thus, using
c δ
the union bound, we can write
∞
2n2δ
P ηt St 1 < c√t t 1, m,w 1 > 1 δ. (9)
{ |
m−w|
∀ ≥ ∀ } ≥ − (nπt)2 −
t=1
X
Finally, using (7) and (9), one can see that
P Ω = P ηt Lˆt 1 Lˆt 1 ηt Yt 1 Yt 1 2c√t, t 1, m,w,w˜
{ }
m−w˜
−
m−w
−
m−w˜
−
m−w
≤ ∀ ≥ ∀
=
Pn
(cid:12)ηtS(cid:0)t 1 ηtSt 1(cid:1) c√(cid:0) t, t 1, (cid:1)m(cid:12) ,w,w˜
o
(cid:12) m−w˜
−
m−w
≤ ∀ ≥
∀(cid:12)
Pn η(cid:12)t St 1 < c√t t(cid:12) 1, m,w > 1 δ. o
≥ {(cid:12) |
m−w|
∀(cid:12) ≥ ∀ } −
Before we present the main result of this section, we first prove the following key lemma.
Lemma 3: Assume that each man follows Algorithm 1 with stepsize ηt = 1 and mixing parameter
√t
γt = Mlogt, where M = 4n log 1. Let a ... a be a sequence defined by a = ∆ and
t c δ 1 ≥ ≥ n 1 2
a = 1 min ∆,µ , k = 2,...,n. Conditioned on the event Ω, there exist t ... t =
O˜k n2 l4 og 1 i ,∈ s[k u] ch thatm fi ow ri an∀ y t t and any w = w , we have 1 ≤ ≤ n
c2 δ (cid:8) (cid:9) ≥ k 6 k
(cid:0) (cid:1)
Xˆt
1 −γt
+
γt
, Xˆt
(1 −γt)e −ηtakt
+
γt
. (10)
mkwk ≥ 1+(n 1)e −ηtakt n mkw ≤ 1+(n 1)e −ηtakt n
− −
Proof: We use induction on k [n] to prove the lemma. For the base of the induction k = 1, we
note that for any Xˆ [0,1]n2 , we ha∈ ve
∈
v (Xˆ) = µ (1 Xˆ ) = µ ,
m1w1 m1w1
−
kw1 m1w1
k> Yw1m1
v (Xˆ) = µ (1 Xˆ ) µ .
m1w m1w
−
kw
≤
m1w
k> Ywm1
Therefore,
t 1
−
Yt 1 Yt 1 = v (Xˆτ) v (Xˆτ)
m− 1w1 − m− 1w m1w1 − m1w
τ=1
X(cid:0) (cid:1)
t 1
−
µ µ ∆(t 1).
≥
m1w1
−
m1w
≥ −
τ=1
X(cid:0) (cid:1)
Define a = ∆ and let t = 4. Conditioned on the event Ω, for any t t and any w = w , we have
1 2 1 ≥ 1 6 1
Xt
m1w1 = eηt(Lˆt m− 11 w1−Lˆt m− 11 w) eηt(Ymt− 11 w1−Ymt− 11 w) −2c√t
Xt ≥
m1w
eηt∆(t −1) −2c√t eηta1(2t −2) −1 2ηta1t
≥ ≥
= eηta1(3 2t −2) eηta1t, (11)
≥
where the third inequality holds because c a1, and the last inequality holds because t t . Moreover,
≤ 4 ≥ 1
1 = Xt + Xt 1+(n 1)e ηta1t Xt . (12)
m1w1 m1w ≤ − − m1w1
w X6=w1
(cid:0) (cid:1)Combining relations (11) and (12) and using the fact that Xˆt = (1 γt)Xt + γt , for any t t and
mw − mw n ≥ 1
w = w , we have
1
6
1 γt γt (1 γt)e ηta1t γt
Xˆt − + , Xˆt − − + . (13)
m1w1 ≥ 1+(n 1)e ηta1t n m1w ≤ 1+(n 1)e ηta1t n
− −
− −
Next, by induction hypothesis, suppose that the statement holds for the first k 1 pairs (m ,w ),ℓ =
ℓ ℓ
−
1,...,k 1 with corresponding sequences a a ... a and t t ... t , and let us
1 2 k 1 1 2 k 1
consider− the kth pair (m ,w ) of the market. N≥ otice tha≥ t for − any Xˆ [0≤ ,1]n2≤ , we h≤ ave −
k k
∈
k 1
−
v (Xˆ) = µ (1 Xˆ ) µ (1 Xˆ ). (14)
mkwk mkwk
−
mℓwk
≥
mkwk
−
mℓwk
mℓ> Ywkmk Yℓ=1
We consider two cases:
Case I: If w = w for some i 1,...,k 1 , then
i
∈ { − }
v (Xˆ) = v (Xˆ) = µ (1 Xˆ ) µ (1 Xˆ ). (15)
mkw mkwi mkwi
−
mℓwi
≤
mkwi
−
miwi
mℓ> Ywimk
Therefore, using (14) and (15) we can write
t 1
−
Yt 1 Yt 1 = v (Xˆτ) v (Xˆτ)
m− kwk − m− kw mkwk − mkwi
τ=1
X(cid:0) (cid:1)
t 1 k 1
− −
µ (1 Xˆτ ) µ (1 Xˆτ )
≥ mkwk − mℓwk − mkwi − miwi
Xτ=1(cid:16) Yℓ=1 (cid:17)
t −1 k −1 γt (1 γt)e −ηtaℓt γt 1 γt
µ 1 ( + − ) µ 1 −
≥ mkwk − n 1+(n 1)e −ηtaℓt − mkwi − n − 1+(n 1)e −ηtait
Xτ=1(cid:16)
(cid:0)
Xℓ=1 −
(cid:1) (cid:0)
− (cid:1)(cid:17)
t −1
µ γt
k −1 (1 −γt)e −ηtaℓt
µ
(n −1)e −ηtait +γt
≥ mkwk − − 1+(n 1)e −ηtaℓt − mkwi 1+(n 1)e −ηtait
Xτ=1(cid:16) Xℓ=1 − − (cid:17)
t 1 k 1
− −
≥
µ
mkwk
−γt
−
e −ηtaℓt −µ mkwi(n −1)e −ηtait −µ mkwiγt
Xτ=1(cid:16) Xℓ=1 (cid:17)
t 1
−
≥
µ
mkwk
−2γt −2(n −1)e −ηtak−1t ,
τ=1
X(cid:0) (cid:1)
where the second inequality holds by the induction hypothesis for t t , and the last inequality
k 1
holds because a
1
... a
k
1. Thus, for any time step t t
k 1
th≥ at sa− tisfies e −ηtak−1t γt and
t 2 4n , w≥ e have≥ − ≥ − ≤
Pt τ−− =1 1γτ ≥ µmkwk
t 1 t 1
− − µ
Yt 1 Yt 1 µ 2nγt = µ (t 1) 2n γt mkwkt. (16)
m− kwk − m− kw ≥ mkwk − mkwk − − ≥ 2
τ=1 τ=1
X(cid:0) (cid:1) X
Case II: If w / w ,...,w , then µ µ +∆. Using (14) and the fact that µ v (Xˆ)
∈ {
1 k
}
mkwk
≥
mkw mkw
≥
mkwfor any Xˆ [0,1]n2, we can write
∈
t 1
−
Yt 1 Yt 1 = v (Xˆτ) v (Xˆτ)
m− kwk − m− kw mkwk − mkw
τ=1
X(cid:0) (cid:1)
t 1 k 1
− −
µ (1
Xˆτ
) µ
≥ mkwk − mℓwk − mkw
Xτ=1(cid:16) Yℓ=1 (cid:17)
t 1 k 1
− −
µ 1
Xˆτ
µ
≥ mkwk − mℓwk − mkw
Xτ=1(cid:16)
(cid:0)
Xℓ=1
(cid:1)
(cid:17)
t −1 k −1 γt (1 γt)e −ηtaℓt
(µ µ ) + −
≥ mkwk − mkw − n 1+(n 1)e −ηtaℓt
Xτ=1(cid:16) Xℓ=1
(cid:0)
− (cid:1)(cid:17)
t 1 k 1
− −
∆ γt e −ηtaℓt
≥ − −
Xτ=1(cid:16) Xℓ=1 (cid:17)
t 1
−
∆ γt (n 1)e −ηtak−1t .
≥ − − −
Xτ=1(cid:16) (cid:17)
Thus, for any integer t
≥
t
k −1
that satisfies e −ηtak−1t
≤
γt and
Pt
τt
−− =1
12
γτ ≥
2 ∆n, we have
t 1 t 1
− − ∆
Yt 1 Yt 1 ∆ nγt = ∆(t 1) n γτ t. (17)
m− kwk − m− kw ≥ − − − ≥ 2
Xτ=1(cid:16) (cid:17) Xτ=1
As a result, by taking
tηt 1 t 2 4n 2n
t := min t t , − max , ,
k
n
≥ k −1 | ln(1/γt) ≥ a
k −1
t
τ−
=1 1γτ ≥ {µ
mkwk
∆}
o
1
a := min ∆,µ , P (18)
k
4 i [k]
miwi
∈ n o
we have a a ,t t . In particular, for t t both relations (16) and (17) hold and we have
k 1 k k k 1 k
− ≥ ≥ − ≥
∆ µ
Yt 1 Yt 1 min , mkwk t 2a t, t t , w = w . (19)
m− kwk − m− kw ≥ { 2 2 } ≥ k ∀ ≥ k ∀ 6 k
Now, using a similar argument as in the base case, for any t t and w = w , we have
k k
≥ 6
Xt
mkwk = eηt(Lˆt m− k1 wk−Lˆt m− k1 w) eηt(Ymt− k1 wk−Ymt− k1 w) −2c√t eηt2akt −2c√t eηt2akt −ηtakt = eηtakt,
Xt ≥ ≥ ≥
mkw
where thesecond inequalityuses (19), and thelast inequalityholdsbecause c=min ∆, µmkwk ak.
k ∈[n] {8 8 }≤ 2
The above relation, together with similar arguments as in deriving (12) and (13) in which a is replaced
1
by a , gives us the desired result (10).
k
Finally, using the stepsize and mixing parameters ηt = 1 and γt = Mlogt in relation (18), one can
√t t
obtain an explicit upper bound for t as
n
√t 1 t 2 4n 2n
t min t Z , − max , ,
n ≤ ∈ + | log(t/M logt) ≥ a M log2t ≥ {µ ∆}
n 1 mnwn
n − o
for which it suffices to take t = O˜ n2 log 1 , where O˜( ) hides the logarithmic factors.
n c2 δ ·
(cid:0) (cid:1)Theorem 3: Assume that each man follows Algorithm 1 with ηt = 1 and γt = Mlogt, where
√t t
M = 4n logT and c = 1 min ∆,µ . Then, the expected regret of Algorithm 1 in hierarchical
c 8 k ∈[n] { mkwk}
matching markets is at most R(T) = O n2 log3T .
c
Proof: Conditioned on the event Ω, which according to Lemma 2 it occurs with probability at
(cid:16) (cid:17)
least 1 δ, the expected regret can be upper-bounded as
−
T T n
E [R(T) Ω] = E [1 Ω] E [1 Ω]
|
{∃k:αt mk6=wk}|
≤
{αt mk6=wk}|
t=1 t=1 k=1
X XX
T n T n
E E [1 Xˆt ] Ω = E P αt = w Xˆt Ω
≤ {αt mk6=wk}| mk { mk 6 k | mk}
t=1 k=1 t=1 k=1
XX (cid:2) (cid:12) (cid:3) XX (cid:2) (cid:12) (cid:3)
T n (cid:12) T n (cid:12)
= E 1 Xˆt Ω nt + E 1 Xˆt Ω
− mkwk| ≤ n − mkwk|
Xt=1 Xk=1
(cid:2) (cid:3)
t= Xtn+1 Xk=1
(cid:2) (cid:3)
n3 1 T n γt 1 γt
O˜
log + 1 −
≤ c2 δ − n − 1+(n 1)e −ηtakt
(cid:0) (cid:1)
t= Xtn+1 Xk=1
(cid:0)
−
(cid:1)
O˜
n3
log
1
+
T n (n −1)e −ηtakt +γ
t
≤ c2 δ 1+(n 1)e −ηtakt
(cid:0) (cid:1)
t= Xtn+1 Xk=1 −
n3 1 T T
O˜ log +n2 e ηtant +n γ
≤ c2 δ − t
t=1 t=1
(cid:0) (cid:1) X X
n3 1 2n2
O˜ log + +nM log2T
≤ c2 δ a2
n
(cid:0)n3 1(cid:1) n2 1
= O log + log log2T ,
c2 δ c δ
(cid:16) (cid:17)
where the third inequality uses Lemma 3, the fifth inequality uses the fact that a := min a , and
n k [n] k
the last inequality is obtained by choosing γt = Mlogt,ηt = 1 ,M = 4n log 1, and noting∈ tha{ t c} a .
t √t c δ ≤ n
Finally, since δ (0,1) can be chosen arbitrary, by choosing δ = 1, we can write
∈ T
E [R(T)] = P Ω E [R(T) Ω]+P Ω¯ E [R(T) Ω¯]
{ } | { } |
n3 1 n2 1
(1 δ)O log + log log2T +δn2T
≤ − c2 δ c δ
n2 (cid:16) (cid:17)
= O log3T .
c
(cid:16) (cid:17)
Remark 3: It is worth noting that the regret of Algorithm 1 is logarithmic in T, with a polynomial
factor
n2
in terms of the problem parameters, thereby addressing a question raised in [2]. Furthermore,
c
Algorithm 1 is both decentralized and uncoordinated, overcoming the limitations of the algorithm
proposed in [2], which is notably more complex and requires phase-dependent coordination among
men according to the Deferred-Acceptance algorithm by Gale and Shapley.
IV. EXPONENTIAL LOCAL CONVERGENCE FOR GENERAL MATCHING MARKETS
In this section, we consider learning a stable matching in general matching markets (i.e., without
any hierarchical assumption) and show that the same decentralized and uncoordinated algorithm EXP
(Algorithm 1) converges locally at an exponential rate to a stable matching when players’ strategies getsufficiently close to one of the stable matchings. To that end, we first consider the following technical
lemma, which shows that if a strategy profile is sufficiently close to a stable matching, then the reward
of choosing an action according to that stable matching is strictly the best decision.
Lemma 4: Let X be a pure NE of the stable matching game and set c = 1 min ∆,µ . For any
∗ 8 { min }
strategy profile x that satisfies kx −X
∗ k1
≤
µmc ax, we have v mw∗(x) −v mw(x) > c ∀w 6= w ∗, where w
∗
is the woman that m is matched to her under the pure NE X .
∗
Proof: Please see Appendix C for the proof.
Next, we consider the following lemma that will be used to capture the local behavior of the dynamics
of Algorithm 1 around a pure NE.
Lemma 5: Suppose X is a pure NE and Xt be the sequence of iterates generated by Algorithm
∗
1. Moreover, let At −1 = t τ− =1 1 v mw∗(Xτ) −v{ mw(} Xτ) , where w ∗ is the woman that man m is matched
to her under the pure NE X . Then, the following statements hold:
∗
i) If Xt X P c ,(cid:0) then ηtLˆt 1 ηtLˆt 1(cid:1) ln(n2 )+6 m,w = w .
• k − ∗ k1 ≤ 250n2 m−w∗ − m−w ≥ 2c ∀ 6 ∗
ii) If ηtLˆt 1 ηtLˆt 1 ln(n2 ) m,w = w , then Xt X c.
• m−w∗ − m−w ≥ 2c ∀ 6 ∗ k − ∗ k1 ≤
iii) Let t be the first time such that 1/ηt0+1 1/ηt0 c/(ln(n2 )+3). If for some t t we have
• 0 − ≤ 2c ≥ 0
ηtAt −1
≥
ln(n 2c2 )+3 and v mw∗(Xt) −v mw(Xt)
≥
c ∀m,w 6= w ∗, then ηt+1At
≥
ln(n 2c2 )+3.
Proof: Please see Appendix D for the proof.
Now we are ready to state the main result of this section.
Theorem 4: Fix an arbitrary δ (0,1), and suppose each player follows Algorithm 1 with some
∈
mixing sequence γt and decreasing stepsize sequence ηt that satisfie the following conditions:
{ } { }
t −1 γt −1 −1
ηt min 2n2
t −1
γτ
−1
,
8nln(nπ
t)
t −1 1 −1/2
. (20)
γτ ≤ ≤
(
√δ γτ
)
(cid:16)Xτ=1 (cid:17) (cid:16) Xτ=1 (cid:17) (cid:16) Xτ=1 (cid:17)
Let t be the first time such that 1/ηt0+1 1/ηt0 c/(ln(n2 )+3) and Xt0 X c . Then with
0 − ≤ 2c k − ∗ k ≤ 250n2
probability at least 1 δ, the sequence Xt converges to the pure NE X exponentially fast, i.e.,
∗
− { }
c
P Xt+1 X 41nexp( ctηt+1) t t Xt0 X 1 δ.
k − ∗ k1 ≤ − ∀ ≥ 0 k − ∗ k1 ≤ 250n2 ≥ −
Proof:nFix an arbitrary man m, and assume X =(cid:12) 1. For any w = w , weohave
m∗w∗ (cid:12) 6 ∗
t 1
−
ηtLˆt 1 ηtLˆt 1 = ηt vˆτ vˆτ
m−w∗ − m−w mw∗ − mw
τ=1
X(cid:0) (cid:1)
t 1 t 1 t 1
− − −
= ηt v mw∗(Xˆτ) −v mw(Xˆτ) +ηt vˆ mτ
w∗
−v mw∗(Xˆτ) −ηt vˆ mτ
w
−v mw(Xˆτ)
τ=1 τ=1 τ=1
X(cid:0) (cid:1) X(cid:0) (cid:1) X(cid:0) (cid:1)
t 1
−
= ηt v mw∗(Xˆτ) −v mw(Xˆτ) +ηtS mt −w1
∗
−ηtS mt −w1, (21)
τ=1
X(cid:0) (cid:1)
where S mt −w1 := t τ− =1
1
vˆ mτ
w
−v mw(Xˆτ) . Moreover, for any m and w, using the mean-value theorem,
there exists a θ = λXˆτ +(1 λ)Xτ such that
P (cid:0) − (cid:1)
v (Xˆτ) v (Xτ) = v (θ) (Xˆτ Xτ)
mw mw mw
| − | |∇ · − |
v (θ) Xˆτ Xτ
mw 1
≤ k∇ k∞k − k
n Xˆτ Xτ
1
≤ k − k
1
= nγτ Xτ 1 n2γτ.
k m − n k1 ≤
m
XSubstituting this relation into (21) and using the triangle inequality, we can write
t 1 t 1
− −
ηtLˆt m−w1
∗
−ηtLˆt m−w1 −ηt v mw∗(Xτ) −v mw(Xτ)
≤
ηt |S mt −w1
∗
|+ηt |S mt −w1 |+2n2ηt γτ
τ=1 τ=1
(cid:12) X(cid:0) (cid:1)(cid:12) X
(cid:12) (cid:12)
≤
ηt |S mt −w1 ∗ |+ηt |S mt −w1 |+1, (22)
where the last inequality follows from the upper bound on the choice of stepsize ηt.
Next, notice that according to Lemma 1, vˆτ v (Xˆτ) is a martingale difference sequence that
{ mw − mw }
almost surely satisfies
n
vˆτ v (Xˆτ) ,
| mw − mw | ≤ γτ
n
E [ vˆτ v (Xˆτ) 2 τ 1] E [(vˆτ )2 τ 1] .
mw − mw |F − ≤ mw |F − ≤ γτ
(cid:0) (cid:1)
Therefore, by taking u = γtn −1, v2 = t τ− =1
1
γn τ, and x = η1
t
in Lemma 7, we obtain
P (1/ηt)2 (1/ηt)2)
P ηt St 1 1 2exp 2exp − ,
{ |
m−w|
≥ } ≤ (cid:16)− 2n( t τ− =1
1
γ1
τ
+ ηtγ1 t−1)
(cid:17)
≤ 4n t τ− =1
1
γ1
τ
(cid:0) (cid:1)
where the second inequality holds because usPing the lower bound on ηt we hPave ηtγ1
t−1 ≤
t
τ−
=1
1
γ1 τ.
Since by the choice of stepsize (1/ηt)2 8nln(nπt), we get P ηt St 1 1 2δ . In particular,
Pt−1 1/γτ ≥ √δ { | m−w| ≥ } ≤ (nπt)2 P
τ=1
using the union bound, the probability that ηt St 1 < 1 for any t 1 and any m,w, is at least
|
m−w|
≥
∞
2n2δ
P ηt St 1 < 1 t 1, m,w 1 > 1 δ. (23)
{ |
m−w|
∀ ≥ ∀ } ≥ − (nπt)2 −
t=1
X
Let us define At −1 = t τ− =1
1
v mw∗(Xτ) −v mw(Xτ) . Using (22) and (23), with probability at least 1 −δ,
we have
P (cid:0) (cid:1)
ηtLˆt 1 ηtLˆt 1 ηtAt 1 3, t 1, m,w. (24)
|
m−w∗
−
m−w
−
−
| ≤ ∀ ≥ ∀
Next, let us assume kXt −X
∗ k1
∈
250c n2. Then, for any m,w 6= w ∗, we have v mw∗(Xt) −v mw(Xt)
≥
c
and ηtLˆt 1 ηtLˆt 1 ln(n2 )+6, by Lemma 4 and Lemma 5 (part i), respectively. Using relation (24),
m−w∗ − m−w ≥ 2c
it means that ηtAt 1 ln(n2 )+3, and thus by Lemma 5 (part iii), we have ηt+1At ln(n2 )+3. This
− ≥ 2c ≥ 2c
in view of Lemma 5 (part ii) shows that Xt+1 X
∗ 1
c. Similarly, Lemma 4 implies v mw∗(Xt+1)
v (Xt+1) c m,w = w , which in vk iew of− Lemk ma≤ 5 (part iii) shows that ηt+2At+1 ln(n2 )+− 3.
mw ≥ ∀ 6 ∗ ≥ 2c
Hence, using relation (24), ηt+2Lˆt+1 ηt+2Lˆt+1 ln(n2 ) m,w = w , and thus Xt+2 X c
mw∗ − mw ≥ 2c ∀ 6 ∗ k − ∗ k1 ≤
by Lemma 5 (part ii).
The above inductive argument shows that if Xt0 X 2c for some t 1 such that 1/ηt0+1
k − ∗ k ≤ n2 0 ≥ −
1/ηt0 c/(ln(n2 ) + 3), then with probability at least 1 δ, we have Xt X c t t , and
≤ 2c − k − ∗ k ≤ ∀ ≥ 0
in particular, using Lemma 4, v mw∗(Xt) v mw(Xt) c m,w,t t
0
. Therefore, with probability at
− ≥ ∀ ≥
least 1 δ, for any m,w = w ,t t , we have
∗ 0
− 6 ≥
Xt+1
mw∗ = exp(ηt+1Lˆt ηt+1Lˆt ) exp(ηt+1At 3) exp(ctηt+1 3).
Xt+1 mw∗ − mw ≥ − ≥ −
mw
Therefore, Xt+1 X = 2(1 Xt+1 ) 2nexp( ctηt+1 +3), which shows that
k m − m∗ k1 − mw∗ ≤ −
c
P Xt+1 X 2nexp( ctηt+1 +3) t t Xt0 X 1 δ.
k − ∗ k1 ≤ − ∀ ≥ 0 k − ∗ k1 ≤ 250n2 ≥ −
n o
(cid:12)
(cid:12)Remark 4: In the statement of Theorem 4, the condition that t t is not restrictive because if
0
Algorithm1 converges to a pure NE, then eventuallyfor some t , we h≥ ave 1/ηt0+1 1/ηt0 c/(ln(n2 )+
0 − ≤ 2c
3) and Xt0 X c . In particular, t is a constant that scales polynomially in terms of other
k − ∗ k ≤ 250n2 0
parameters (see, e.g., Remark 5). We note that it is possible to further relax this condition by a constant
scaling of ηt, i.e., by setting ηt 1(ln(n2 )+3)ηt and rescaling all other parameters such as the mixing
← c 2c
sequence γt accordingly. However, that requires the players to know c = 1 min ∆,µ to choose
8 { min }
their stepsize ηt, while knowing c is not required in the stepsize condition given in (20).
Remark 5: In fact, there exist feasible choices for ηt and γt that satisfy the stepsize condition (20)
in Theorem 4. For instance, if for some α,β (0,1), α > max 1 β, 1+β , we choose
∈ { − 2 }
1 1
ηt = Θ , γt = Θ( ),
ln(t/√δ)tα tβ
(cid:16) (cid:17)
then condition (20) is satisfied for any t (αb)1/(1 α), where b = ln(n2 ) + 3. More specifically, by
0 ≥ c − 2c
choosing γt = 1 and ηt = 1 , the exponential convergence rate of Theorem 4 would be in the order
t1/3 t3/4
of exp( ct1/4) for any t (b)4. We note that condition (20) provides only a sufficient condition to
− 0 ≥ c
achieve local exponential convergence and we did not attempt to fully characterize all feasible choices
of stepsize/mixing parameters. However, there could be other choices of stepsize that do not satisfy
condition (20) while still achieving local exponential convergence.
Although Theorem 4 shows that Algorithm 1 achieves an exponential convergence rate, its conver-
gence guarantee holds in a local sense, i.e., when the dynamics get sufficiently close to a neighborhood
of a stable matching. In the following theorem, we complement this result by showing that if the
dynamics of Algorithm 1 converge with positive probability, it must converge to a mixed NE of the
stable matching game.
Theorem 5: Under the same stepsize assumptions of Theorem 4, if Algorithm 1 converges to a limit
point X with positive probability, then X must be a (possibly mixed) NE of the matching game.
∗ ∗
Proof: Please see Appendix E for the proof.
V. GLOBAL LEARNING OF STABLE MATCHINGS IN GENERAL MARKETS
In the previous section, we showed that the decentralized and uncoordinated EXP algorithmconverges
locally to a stable matching at an exponential rate in general matching markets. This prompts the
question of whether there is an uncoordinated and decentralized algorithm capable of globally learning
a stable matching in general markets, regardless of the convergence rate. In this section, we answer this
question affirmativelyby introducing an alternativealgorithm that leverages the weak acyclic property of
the stable matching game. To that end, we first present several useful properties of the stable matching
game, which will be instrumental in establishing our main convergence results.
Definition 4: A pure strategy profile x is a good state if all the men matched under x are at their
best responses.8 In other words, a good state x refers to a partial matching in which the matched men
are at their best responses.
The following theorem shows that if the stable matching game with known preferences starts from
a good state, then any sequence of best response dynamics by the players reaches a pure NE. Unless
stated otherwise, we assume that each player m is aware of both his own true preferences and those
of all the women, enabling him to compute his payoff function. This assumption will be relaxed in
Theorem 6, where players seek to learn these unknown preferences through interactions with others.
Lemma 6: Consider the stable matching game that starts from a good initial state x0. Consider any
sequence of updates where at each time t, an arbitrary subset of players that includes at least one
8Inapurestrategyprofilex=(x ,m∈M),amatchedmanistheonewhosepurestrategyx hasexactlyonecoordinateequalto1
m m
(say wth coordinate), and all other coordinates are zero, and no other man of higher preference proposes to w, i.e., x =0 ∀k> m.
kw wunsatisfied player updates their actions by playing their best responses. Then, the sequence of updates
converges to a pure NE in no more than M W iterations.
Proof: Let us encodethe ordinalpref| eren|| ces| of each woman w into cardinal valuesλ R+ such
wm
∈
that m > m if and only if λ > λ . Given a pure strategy profile x, let r (x) λ ,m M
1 w 2 wm1 wm2 w
∈ {
wm
∈ }
be woman w’s reward for her most preferred man who is matched to her under x. By convention, we
set r (x) = 0 if w is not matched to any man under the pure-strategy profile x. We show that r (x) is
w w
nondecreasing for each woman w (and for at least one w it is strictly increasing) such that the potential
function Φ(x) = r (x) strictly increases after each iteration. Since each r (x) can increase at most
w w w
M times, the sequence must terminate at a pure NE after no more than M W iterations. We show
| | P | || |
this by arguing that during the sequence of updates, no matched man m wants to deviate unless he
is rejected by his partner w because she has received a better offer, implying that r (x) must have
w
increased. Note that this statement holds initially because x0 is a good state where no matched man
wants to deviate.
More precisely, let us by contradiction assume that t is the first iteration at which some woman w
loses her more preferred man during the sequence of updates, i.e., r (xt) < r (xt 1). This can happen
w w −
only if man m that is matched to w at time t 1 (i.e., xt 1 = 1) is selected to update at time t whose
−
m−w
best response is to leave w for another women w (i.e., xt = 1). Otherwise, r (xt 1) can only increase
′ mw′ w −
or remain the same because women reject any proposal other than their most preferred one. Note that
since the game starts from a good state x0, we must have t 2.
≥
According to the payoff structures, the best response of player m at time t is to propose to his most
preferred achievable woman w , i.e., among all women who rank m higher or equal to their match under
′
xt −1, m proposes to the woman w
′
which brings him the highest utility µ mw′. Note that in particular
µ mw′ > µ mw. Thus, the first time τ t 1 when man m proposed and got matched to woman w,
≤ −
the woman w was his more preferred choice and the reason why m did not propose to w at time
′ ′
τ was because w ′ was not achievable, i.e., x mτ −′w1 ′ = 1 for some man m ′ > w′ m. Since w ′ was not
achievable for m in xτ −1 but she is achievable in xt −1 implies that r w′(xt −1)<r w′(xτ −1). Therefore,
r w′(xτ′ )<r w′(xτ′ −1) for some τ τ
′
t 1, contradicting the choice of t.
≤ ≤ −
In fact, one can view the DA algorithm of [1] as a special version of the above lemma in which all
the players are selected to best respond at each round, and the initial good state is the empty matching.
Lemma 6 shows that the stable matching game admits an ordinal potential function if the game starts
from a good state (we refer to Appendix F for another interpretation of this potential function). However,
that does not imply that the stable matching game is an ordinal potential game [21], which requires
the existence of a potential function whose changes are aligned with players’ payoff changes from any
initial state. Nonetheless, the existence of such a “weak” potential function allows us to show the weak
acyclicity of the stable matching game as defined next.
Definition 5 ( [22]): A better response path in a finite action noncoopertaive game is a sequence
of pure strategy profiles x1,x2,...,xL such that for each ℓ = 1,...,L 1, xℓ+1 is obtained from xℓ
−
by letting some player i to play a better response. A game is called weakly acyclic if from any pure
ℓ
strategy profile x0, there is a finite length better response path to a pure NE.
Definition 6: A pure NE x = (x ,x ) of the stable matching game is called strict if each player
∗ ∗m ∗m
has a unique best response at the equilib−rium x , i.e., for every m and any pure strategy x = x , we
∗ m
6
∗m
have u (x ,x ) < u (x ,x ).
m m ∗m m ∗m ∗m
Using the ab−ove definitions, w−e are now ready to state the main result of this section, which provides
a decentralized and uncoordinated algorithm for learning stable matchings in general markets with
unknown preferences. The algorithm is an adaptation of the sample experimentation algorithm for
weakly acyclic games [23] to the stable matching game. Intuitively, each player m goes through a
sequence of phase-dependent exploration/exploitation. At the end of each episode, player m evaluates
his payoff for each action he has taken during the last episode. He then updates his baseline action(an action that brings him the highest reward in the past episode up to some tolerance) and sticks to
that baseline action most of the time in the next episode while still exploring new actions with a small
probability. The detailed description of the algorithm is summarized in Algorithm 2.
Algorithm 2 A Globally Convergent Decentralized and Uncoordinated Algorithm for Player m
Input: A randomly chosen initial action α0 [W], an initial baseline action b1 = α0 , episode length
m ∈ m m
τ , tolerance level δ > 0, exploration probability ǫ (0,1), and an inertia probability ω (0,1).
m
∈ ∈
For s = 1,2,..., do the following
During the sth episode, player m selects his baseline action obtained at the end of the previous
•
episode with probability 1 ǫ or explores a new uniformly sampled action with probability ǫ, i.e.,
−
bs w.p. 1 ǫ,
αt = m − t (s 1)τ ,...,sτ 1 .
m w Unif[W] w.p. ǫ, ∀ ∈ { − m m − }
(
∈ n
At the end of episode s, player m evaluates his average utility when playing each of his actions as
•
1
sτm −1
us = µt 1 1 w,
mw ns mw {αt k6=w ∀k>wm } {αt m=w } ∀
mw
t=( Xs −1)τm
w Ifher se n =s mw ,= plays t e=τ rm (s m− −1 1) uτm ni1 fo{ rα mt m= lyw } s, aman pd lec som anpu at ce ts iot nhe wset As m s ,= an{ dw u: pu ds m aw tes≥ hu iss mb bs m as+ elδ in} e. action to
• Am 6 ∅ P ∈ Am
bs+1 = w with probability 1 ω. Otherwise, he sets bs+1 = bs .
m − m m
Theorem 6: Let p,ω (0,1) be arbitrary probabilities and ǫ min 1 p, δ , ∆ δ , where δ (0,∆).
− −
∈ ≤ { n 4n 4n } ∈
For each man m, there exists a sufficiently large episode length τ = τ (p,ǫ), such that if each player
m m
m follows Algorithm 2 with episode length τ , for all sufficiently large times t > 0, the pure strategy
m
profile αt will be a (fixed) stable matching with probability at least p.
Proof: First, we show that the stable matching game is a weakly acyclic game. If the game starts
from a good state, by Lemma 6, any sequence of best responses by the players is a better response path
that leads to a pure NE in M W iterations. Thus, we only need to show that from any initial state,
| || |
there is a better response path to a good state. This is also true by sequentially letting a matched man
who wants to deviate (if there is such a man) to play his best response. In this way, either the number
of matched men decreases due to collisions (which can happen at most M times), or between every
| |
two consecutive collisions, there could be at most M best response updates. Therefore, M 2 steps are
| | | |
enough to bring us from any arbitrary state to a good state, and the overall number of best response
iterates to obtain a pure NE starting from any initial state is at most M N + M 2.
| || | | |
Next, we note that any pure NE in the stable matching game is a strict NE.9 This follows directly by
the fact that there are no ties between men’s preferences in the stable matching game. More precisely, let
α be a pure NE (stable matching) and assume u (α ) = µ . For any α = α , either u (α ,α )
∗ m ∗ mw m
6
m∗ m m ∗m
equals 0 or µ mw′ for some w ′ 6= w. Because α m∗ is the best response of player m at the NE and th−ere
are no ties between man m’s preferences, we must have µ mw′ < µ mw. Since 0 < µ mw, in either case
we have u (α ,α ) < u (α ,α ).
m m ∗m m m∗ ∗m
Finally, it was s−hown in [23] tha−t the class of sample experimentation dynamics in weakly acyclic
games converges with arbitrarily high probability to a strict NE if for any joint baseline action bs at the
start of an episode s, us is an arbitrarily close estimation of u (w,bs ) for sufficiently large episode
mw m m
length τ = τ (p,ǫ). Since Algorithm 2 is an adaptation of the sam−ple experimentation dynamics to
m m
9Inaweaklyacyclicgame,anarbitrarilyhighprobabilityconvergencecanbeguaranteedtoastrictNE[23].Ifwedonothavestrictness
property, the dynamics may oscillate between two nonstrict NE points with a positive probability.the stable matching game, the convergence result follows from [23, Theorem 3.4] if we can show that
for any δ = min δ, ∆ δ > 0, p < 1, and 1 (1 ǫ)n 1 < δ∗ , for sufficiently large τ we have10
∗ {4 4− } − − − 2 m
P us u (w,bs ) δ 1 p. (25)
mw − m m ≥ ∗ ≤ −
−
n o
This statement is also true because(cid:12)during each episode,(cid:12)players sampletheir baseline actions (or explore
(cid:12) (cid:12)
a new action) independently of others, and moreover, µt are i.i.d. realizations of a random variable
mw
with mean µ . Thus, relation (25) holds using the law of large numbers, which completes the proof.
mw
WhileAlgorithm2providesadecentralized anduncoordinatedalgorithmforlearningstablematchings
in general markets with arbitrarily high probability, the convergence time to a NE may take a long time.
This seems inevitable to some extent in view of the exponential lower bound in terms of n such that
the best response dynamics in general matching markets converge to a stable matching [11].
VI. MATCHING MARKETS WITH STRONGER INFORMATION FEEDBACK
So far, we have assumed that men receive the minimum amount of information feedback as they
interact with the market; namely, men only get to observe whether their proposal gets rejected or,
if matched, they observe a random realization of their preference. In this final section, we consider
the learning problem from a new perspective by addressing the following question: Is there stronger
information feedback that will allow us to derive the market faster globally to a stable matching in
a decentralized and uncoordinated fashion? Therefore, we address the problem of learning a stable
matching from an information feedback design perspective by showing that if the players are allowed
to receive a bit more information as feedback, then the stable matching game will become a monotone
game, hence allowing a wide range of decentralized and uncoordinated learning algorithms for obtaining
its NE points.
Let us consider a simplified version of the stable matching game with the same set of players M and
strategy spaces ,m M, except that the payoff of player m is now given by
m
X ∈
u (x) = µ 1 x x . (26)
m mw kw mw
−
w X∈W
(cid:0)
k X>wm
(cid:1)
The simplified payoff function (26) can be viewed as the expected perceived reward for player m if
he randomly and independently of others proposes to women according to his mixed strategy x
m m
∈ X
but under slightly stronger feedback: if player m’s proposal gets rejected from a woman w, he also gets
to know how many men higher ranked than him proposed to w. In this way, each man m learns how
many more preferred men compete with him to get matched to woman w. Such information feedback
can be implemented by using a waiting list order for each woman, which shows the ranking of a rejected
man m in that list. Henceforth, we refer to such information feedback as the waiting list feedback.
Let α W denote the random woman that player k proposes to her, which is drawn independently
k
∈
from his mixed strategy distribution x . Under the waiting list feedback information, player m has
k
access to the information 1 if he proposes to w, and hence can estimate his perceived
payoff by proposing to a wok m> aw nm w{α ak s=w µ} (1 1 ), Therefore, the expected perceived
P mw − k>wm {αk=w }
payoff of player m under the waiting list feedback equals
P
E [ µ (1 1 )1 ] = E [µ (1 1 ) α = w]P (α = w)
mw
−
{αk=w
}
{αm=w
}
mw
−
{αk=w
} |
m m
w X∈W k X>wm w X∈W k X>wm
= µ 1 x x = u (x),
mw kw mw m
−
w X∈W
(cid:0)
k X>wm
(cid:1)
10This is an equivalent version of Claim 3.4 in [23] to the stable matching game.where the second equality holds by independency of α k M.
k
∀ ∈
Themotivationforwaitinglistfeedback and thepayofffunction(26)isthat ifweview1 x
− k>wm kw
as the remaining fractional capacity of women w for being matched, using the approximation 1
k>wmx
kw
∼
e −P k>wmxkw, one can think that man m loses his interest to offer women w exP ponential− ly
in terms of the occupied capacity of woman w by higher preferred men. One immediate consequence
P
of such simplified payoff functions is the following proposition whose proof follows nearly verbatim
arguments as those in Theorems 1 and 2, and is omitted from here for the sake of brevity.
Proposition 7: Consider the stable matching game with payoff functions (26). Then, x is a pure NE
∗
if and only if it is the characteristic vector of a stable matching. Moreover, any mixed NE of this game
with full support can be rounded in a decentralized manner to a pure NE.
Next, we consider the following definition of monotone games [24].
Definition 7: A continuous-action game (M, U , ) is called monotone if for any two
m m M m M
action profiles x,x , we have{ (x } ∈ x)T { FX (} x)∈ F(x) 0, where
′ 1 M ′ ′
∈ X ×···×X| | − − ≤
F(x) = ( U (x),m(cid:0) M)T. (cid:1)
m m
∇ ∈
An important property of monotone games is that they admit a variety of decentralized learning
algorithms that converge globally to a NE, which, under further assumptions, it can be shown that
the converge rate could be exponential or polynomial [24]–[29]. The following theorem shows that the
regularized stable matching gamewith waiting list feedback is indeed a monotonegame under a suitable
assumption on the preferences.
Theorem 8: Consider the regularized stable matching game with list feedback, where each player
aims to maximize its regularized payoff function given by U (x ,x ) := u (x ,x ) β x 2.
m m −m m m −m − 2k m k
Then, for any two strategy profiles x,x, we have
′
1
(x x)T F(x) F(x) = (x x )TQw(x x ),
′
−
′
− −2
′w
−
w ′w
−
w
w W
(cid:0) (cid:1) X∈
where x is the vector x = (x ,m M)T, and Qw is a symmetric matrix whose diagonal entries
w w mw
∈
are 2β and all the entries in row m up to the diagonal entry in that row equal µ . In particular, if
mw
β > nµmax, the regularized stable matching game with waiting list feedback is a monotone game.
2
Proof: Note that due to the linearity of U (x) with respect to player m’s strategy x , we have
m m
U (x) = µ (1 x ) βx , m,w,
mw m mw kw mw
∇ − − ∀
k X>wm
where U (x) denotes the gradient of U (x) with respect to x . Thus, we can write
mw m m mw
∇
(x x)T F(x) F(x) = (x x )T U (x) U (x)
′
−
′
−
′m
−
m ∇m m ′ −∇m m
m
(cid:0) (cid:1) X (cid:0) (cid:1)
= (x x ) U (x) U (x)
′mw
−
mw ∇mw m ′ −∇mw m
m w
XX (cid:0) (cid:1)
= µ (x x ) x x +β(x x )
−
mw ′mw
−
mw ′kw
−
kw ′mw
−
mw
Xm Xw (cid:0)k X>wm k X>wm
(cid:1)
= µ (x x )(x x ) β (x x )2
−
mw ′mw
−
mw ′kw
−
kw
−
′mw
−
mw
Xm Xw k X>wm Xm Xw
= µ (x x )(x x ) β (x x )2
−
mw ′mw
−
mw ′kw
−
kw
−
′mw
−
mw
Xw (cid:16)Xm k X>wm (cid:17) Xm Xw
= µ 1 (x x )(x x ) β (x x )2. (27)
−
mw {k>wm
}
′mw
−
mw ′kw
−
kw
−
′mw
−
mw
Xw (cid:16)Xm Xk (cid:17) Xw XmFor each woman w, let us define a vector x = (x ,m [M])T, and an n n incidence preference
w mw
matrix Aw whose entries are given by Aw = µ 1 ∈ , m,k [n]. Then× , using (27) we have
mk mw {k>wm } ∀ ∈
(x x)T F(x) F(x) = Aw (x x )(x x )
′ − ′ − − mk ′mw − mw ′kw − kw
(cid:0) (cid:1)
Xw (cid:16)Xm Xk (cid:17)
(x x )T(βI)(x x )
−
′w
−
w ′w
−
w
w
X
= (x x )T(Aw +βI)(x x )
−
′w
−
w ′w
−
w
w
X
1
= (x x )TQw(x x ),
−2
′w
−
w ′w
−
w
w
X
where Qw = (Aw)T +Aw +2βI. Next, we note that permuting the rows and columns of a matrix by
the same permutation matrix preserves the semi-definiteness property as it only changes the basis of its
eigenvectors. Thus, without loss of generality, we may assume 1 > 2 > ... > n. However, in that
w w w
case, we may assume that for any w, the matrix Aw will be a lower triangular matrix whose diagonal
entries are all zero. In particular, Qw = (Aw)T+Aw+2βI would be a symmetric matrix whose elements
in each row m up to the diagonal entry are identical and equal to µ . Finally, for sufficiently large
mw
β > nµmax, the matrix Qw is positive semidefinite for all w, and we have (x x )TQw(x x )
2 − ′w − w ′w− w ≤
0 w. This shows that (x x)T F(x) F(x) 0, and completes the proof.
′ ′
∀ − − ≤
Remark 6: The monotonicity property in Theorem 8 holds when the regularizer parameter β is
(cid:0) (cid:1)
sufficiently large. The regularizer implies that players tend to maximize their approximate payoff
functions. Thus, instead of learning a NE for the payoff functions (26), they learn an ǫ-NE where
the approximation error ǫ grows as β increases. As a result, applying decentralized learning algorithms
to learn a NE of the regularized game only guarantees an ǫ-stable matching in the sense that the players
will achieve a solution in which each player would be ǫ worse off than what he could achieve in a stable
matching. Therefore, the regularizer parameter trades off between the market’s convergence speed and
the accuracy of the learned stable matching.
Finally, we note that without imposing any assumption on the agents’ preferences, one cannot expect
the stable matching game to be a monotone game. The reason is that monotone games imply the global
uniqueness of a NE [24]. However, by Proposition 7, any stable matching is a pure NE, and for general
matching markets, there could be many stable matchings under arbitrary preferences. Moreover, the
assumption of waiting list feedback is not necessary for faster convergence in any general market; it is
merely one choice that we consider in this work, and there could be other types of information feedback
that allow faster convergence. Nevertheless, our game-theoretic approach to the stable matching problem
provides valuable insights on how to properly design the utilities and the information feedback to devise
faster decentralized and uncoordinated algorithms for learning stable matchings.
VII. CONCLUSIONS
In this work, we considered the problem of learning stable matchings with unknown preferences in a
fully decentralized and uncoordinated manner. Using a game-theoretic formulation, we showed how to
leverage the rich literature for learning NE in noncooperative games to derive the matching market to its
stablepointsinaprincipledway.Inparticular,weestablishedseveralglobalandlocalconvergenceresults
with performance guarantees for learning stable matchings in hierarchical markets, general markets, and
under weak/strong information feedback. Our results provide new insights for learning stable matchings
through NE learning in noncooperative games and bridge the discrete problem of learning a stable
matching with learning NE in continuous-action games.
This work opens several avenues for future research. One interesting direction is to characterize
an information-theoretic limit below and above which efficient learning of a stable matching in a fullydecentralizedand uncoordinatedfashionmayormaynotbepossible.Moreover,ourwaitinglistfeedback
is merely an initial attempt to design faster decentralized and uncoordinated algorithms under richer
information feedback. Extending our results to include other types of information feedback and studying
their effect on the convergence speed of the market to its stable points would be another interesting
research direction.
REFERENCES
[1] D.GaleandL.S.Shapley,“Collegeadmissionsandthestabilityofmarriage,”TheAmericanMathematical Monthly,vol.69,no.1,
pp. 9–15, 1962.
[2] C. Maheshwari, S.Sastry, and E. Mazumdar, “Decentralized, communication-and coordination-free learning instructured matching
markets,” Advances in Neural Information Processing Systems, vol. 35, pp. 15081–15092, 2022.
[3] A.E.Roth,“Deferredacceptance algorithms: History,theory, practice,andopen questions,”International Journal ofGameTheory,
vol. 36, pp. 537–569, 2008.
[4] G.PokharelandS.Das,“Convergingtostabilityintwo-sidedbandits:Thecaseofunknownpreferencesonbothsidesofamatching
market,” arXiv preprint arXiv:2302.06176, 2023.
[5] T. Pagare and A. Ghosh, “Two-sided bandit learning in fully-decentralized matching markets,” in ICML 2023 Workshop The Many
Facets of Preference-Based Learning, 2023.
[6] F. Kong and S. Li, “Player-optimal stable regret for bandit learning in matching markets,” in Proceedings of the 2023 Annual
ACM-SIAM Symposium on Discrete Algorithms (SODA). SIAM, 2023, pp. 1512–1522.
[7] R. V. Vohra, “Stable matchings and linear programming,” Current Science, pp. 1051–1055, 2012.
[8] C.-P.TeoandJ.Sethuraman,“Thegeometryoffractionalstablematchingsanditsapplications,”MathematicsofOperationsResearch,
vol. 23, no. 4, pp. 874–891, 1998.
[9] T.Kira´lyandJ.Pap,“TotaldualintegralityofRothblum’sdescriptionofthestable-marriagepolyhedron,”MathematicsofOperations
Research, vol. 33, no. 2, pp. 283–290, 2008.
[10] A.E.RothandJ.H.V.Vate,“Randompathstostabilityintwo-sidedmatching,”Econometrica:JournaloftheEconometricSociety,
pp. 1475–1480, 1990.
[11] H. Ackermann, P. W. Goldberg, V. S. Mirrokni, H. Ro¨glin, and B. Vo¨cking, “Uncoordinated two-sided matching markets,” in
Proceedings of the 9th ACM Conference on Electronic Commerce, 2008, pp. 256–263.
[12] X. Bei, N. Chen, and S. Zhang, “On the complexity of trial and error,” in Proceedings of the Forty-Fifth Annual ACM Symposium
on Theory of Computing, 2013, pp. 31–40.
[13] Z.Wang,L.Guo,J.Yin,andS.Li,“Banditlearninginmany-to-onematchingmarkets,”inProceedingsofthe31stACMInternational
Conference on Information & Knowledge Management, 2022, pp. 2088–2097.
[14] S. Clark, “The uniqueness of stable matchings,” Contributions in Theoretical Economics, vol. 6, no. 1, 2006.
[15] L. T. Liu, F. Ruan, H. Mania, and M. I. Jordan, “Bandit learning in decentralized matching markets,” The Journal of Machine
Learning Research, vol. 22, no. 1, pp. 9612–9645, 2021.
[16] M. Jagadeesan, A. Wei, Y. Wang, M. Jordan, and J. Steinhardt, “Learning equilibria in matching markets from bandit feedback,”
Advances in Neural Information Processing Systems, vol. 34, pp. 3323–3335, 2021.
[17] S. Basu, K. A. Sankararaman, and A. Sankararaman, “Beyond log2(t) regret for decentralized bandits in matching markets,” in
International Conference on Machine Learning. PMLR, 2021, pp. 705–715.
[18] T. Lattimore and C. Szepesva´ri, Bandit Algorithms. Cambridge University Press, 2020.
[19] S.Bubeck, N.Cesa-Bianchi etal.,“Regret analysisofstochasticandnonstochastic multi-armedbandit problems,”Foundations and
Trends in Machine Learning, vol. 5, no. 1, pp. 1–122, 2012.
[20] A.Giannou,E.-V.Vlatakis-Gkaragkounis,andP.Mertikopoulos,“Ontherateofconvergenceofregularizedlearningingames:From
bandits and uncertainty to optimism and beyond,” Advances in Neural Information Processing Systems, vol. 34, pp. 22655–22666,
2021.
[21] D. Monderer and L. S. Shapley, “Potential games,” Games and Economic Behavior, vol. 14, no. 1, pp. 124–143, 1996.
[22] J.R.Marden, G.Arslan,andJ.S.Shamma,“Regretbaseddynamics: Convergenceinweaklyacyclicgames,”inProceedingsofthe
6th International Joint Conference on Autonomous Agents and Multiagent Systems, 2007, pp. 1–8.
[23] J. R. Marden, H. P. Young, G. Arslan, and J. S. Shamma, “Payoff-based dynamics for multiplayer weakly acyclic games,” SIAM
Journal on Control and Optimization, vol. 48, no. 1, pp. 373–396, 2009.
[24] J.B.Rosen,“Existenceanduniquenessofequilibriumpointsforconcaven-persongames,”Econometrica:JournaloftheEconometric
Society, pp. 520–534, 1965.
[25] T. Tatarenko and M. Kamgarpour, “Payoff-based learning of Nash equilibria in merely monotone games,” IEEE Transactions on
Control of Network Systems, 2024.
[26] Y.-G. Hsieh, K. Antonakopoulos, and P. Mertikopoulos, “Adaptive learning in continuous games: Optimal regret bounds and
convergence to Nash equilibrium,” in Conference on Learning Theory. PMLR, 2021, pp. 2388–2422.
[27] B. Gao and L. Pavel, “Continuous-time discounted mirror descent dynamics in monotone concave games,” IEEE Transactions on
Automatic Control, vol. 66, no. 11, pp. 5451–5458, 2020.
[28] T.TatarenkoandM.Kamgarpour,“Ontherateofconvergenceofpayoff-basedalgorithmstoNashequilibriuminstronglymonotone
games,” arXiv preprint arXiv:2202.11147, 2022.
[29] P. Mertikopoulos and Z. Zhou, “Learning in games with continuous action sets and unknown payoff functions,” Mathematical
Programming, vol. 173, pp. 465–507, 2019.[30] D. A. Freedman, “On tail probabilities for martingales,” The Annals of Probability, pp. 100–118, 1975.
[31] Y.SeldinandG.Lugosi,“AnimprovedparametrizationandanalysisoftheEXP3++algorithmforstochasticandadversarialbandits,”
in Conference on Learning Theory. PMLR, 2017, pp. 1743–1759.
APPENDIX
A. Freedman’s Concentration Inequality for Martingales
Lemma 7: Let ζ t be a martingale difference sequence with max ζ u, and consider the
corresponding ma{ rtiτ n} gτ a= le1 St = t ζ with S1 = 0. Let Vt = t τ E∈ [[ ζt] 2| τ | t≤ 1] be the sum of the
conditional variances. Then, for
anyτ= x1 >τ
0 and v R, we have
τ=1 τ|F −
P ∈ P
x2
P St x, Vt v2 2exp − .
{| | ≥ ≤ } ≤ 2(v2 +ux)
Proof: The proof can be found in [30, Theorem 1.6].(cid:16) (cid:17)
B. Proof of Theorem 2
Proof: Given a mixed NE x, let (x) = (M W,E(x)) be the induced bipartite graph by x, where
H ∪
E(x) = (m,w) : x > 0 denotes all the edges with fractionally positive proposals. Moreover, let us
mw
{ }
denote the neighboring nodes of m and w in (x) by N (x) and N (x), respectively. Since x is a NE,
m w
H
the value v (x) = µ (1 x ) should be the same for all w N (x) and equals to u (x).
mw mw k>wm − kw ∈ m m
Otherwise, using properties (i) and (ii), player m could strictly increase his payoff by putting his entire
Q
strategy mass on the woman w = argmax v (x). The fact that u (x) = v (x) w N (x)
follows because x is a
probab∗
ility
distribw u∈tiN om n(x th) atm iw
s supported over N
m
(x).
mw ∀ ∈ m
m m
Next, we note that a man m cannot be the most preferred choice for more than one woman in (x).
H
Otherwise, let w ,w N (x) be two different women who rank m the highest among their fractional
1 2 m
∈
matches in N (x) and N (x), respectively. Then, we have
w1 w2
(1 x ) = (1 x ) = 1,
−
kw1
−
kw2
k> Yw1m k> Yw2m
which together with the above argument implies that
µ = µ (1 x ) = v (x) = u (x) = v (x) = µ (1 x ) = µ .
mw1 mw1
−
kw1 mw1 m mw2 mw2
−
kw2 mw2
k> Yw1m k> Yw2m
This contradicts the fact that there are no ties between the preferences of man m.
Since each woman receives at least one fractional proposal, N (x) = w. Let m be the unique
w w
6 ∅ ∀
most favorite man of w in N (x). Using the above argument, the elements of m ,w W must be
w w
{ ∈ }
distinct such that = (m ,w),w W forms a matching. Viewing this matching from men’s side,
1 w
M { ∈ }
one can represent in the form of = (m,w ),m M , where w = argmin µ is
the least
preferredM wo1
man among
thosM
e
th2
at
m{
an
mm fractio∈ nally}
proposed
tm
o. To see
thw is∈N em qu(x i) valm enw
ce,
fix a man m and let w be his match in M , i.e., m = m. Observe that each w N (x) w has
0 1 w0 ′
∈
m
\{
0
}
a unique distinct most favorite man m w′ = m. That means that
6
v mw′(x) = µ mw′ (1 x kw′) µ mw′(1 x m ′w′) < µ mw′.
− ≤ − w
k> ′m
Yw
On the other hand, since w ranks m the highest among those who propose to her, we have v (x) =
0 mw0
µ
mw0
k>w0m(1 −x kw′) = µ mw0. Since at a NE v mw0(x) = v mw′(x), we must have µ
mw0
< µ mw′, ∀w
′
∈
N (x) w ,whichimpliesw = w .Thus,foranypair(m ,w ) thereisapair(m,w ) M
m
Q\{
0
}
0 m w0 0
∈
M1 m
∈
2
such that (m ,w ) = (m,w ), which shows that = .
w0 0 m M1 M2Finally, we will show that the binary characteristic vector of the matching (m,w ),m M ,
m
{ ∈ }
denoted by xˆ, is indeed a pure NE. We will show that by arguing that any strictly better deviation in xˆ
is also a strictly better deviation in x, contradicting the fact that x is a NE. On the contrary, let m be a
w
man who wants to deviate from his pair w to a woman w = w. Such a deviation is beneficial to player
′
6
m w only if m w′ < w′ m w. Otherwise, his payoff will reduce from u mw(xˆ) = µ mww to 0. Henceforth, we
may assume m w′ < w′ m w. The fact that the payoff of player m w is currently u mw(xˆ) = µ mww and he
wants to deviate to w
′
implies that µ
mww
< µ mww′. As m
w
is the most preferred man for woman w
in H(x), we also have u mw(x) = µ mww. Since m w′ < w′ m w, the woman w ′ would prefer m w over all
the men in N (x). Thus, in the mixed NE x, man m could also deviate by solely proposing to w , in
w′ w ′
which case his payoff would strictly increase from u mw(x) = µ
mw,w
to µ mww′, which is a contradiction.
C. Proof of Lemma 4
Proof: Fix a player m and assume X = 1. Since X is a pure NE, for any w = w we have
m∗w∗ ∗
6
∗
v mw∗(X ∗) = µ mw∗ > v mw(X ∗) = µ mw (1 −X k∗w)
∈
{0,µ mw }.
k> Ywm
On the other hand, we have
v mw∗(x) v mw∗(X ∗) = µ mw∗ (1 x kw∗) µ mw∗
− − −
k> ∗m
Yw
µ mw∗ x kw∗
≥ −
k> ∗m
Xw
µ mw∗
x X , (28)
∗ 1
≥ − 2 k − k
where the second inequality holds because X = 1 implies X = 0 k = m, and hence 1 x
m∗w∗ k∗w∗
∀ 6 2k −
X
∗ k1 ≥ k>
w∗mx kw∗. Now we consider two cases:
i) If v mw(X ∗) = µ mw, then v mw(x) µ mw < µ mw∗ x, which implies v mw∗(X ∗) v mw(x) ∆.
CombiniP ng this relation with (28) and b≤ ecause kx −X
∗
k∀
1
≤
µm∆ ax, we get v mw∗(x) −v− mw(x) > ∆ 2≥ > c.
ii) If v (X ) = 0, there exists k > m such that X = 1. Then, v (x) µ (1 x ) =
mw ∗ w k∗w mw
≤
mw
−
kw
µ mw(X k∗w
−
x kw)
≤
21µ mw kX ∗
−
x k1, and we have v mw∗(X ∗)
−
v mw(x)
≥
µ mw∗
−
21µ mw kX ∗ −x k1.
Combining this relation with (28) and because kx −X
∗ k1
≤
µµ mm ain x, we get v mw∗(x) −v mw(x) > µm 2in > c.
D. Proof of Lemma 5
Proof: i) Suppose Xt X c , then Xt X = 2(1 Xt ) c m. Since
k − ∗ k1 ≤ 250n2 k m − m∗ k1 − mw∗ ≤ 250n2 ∀
Xt is a probability distribution, we can write
m
Xt 1 c/500n2 500n2
mw∗
− = 1, m,w = w .
∗
Xt ≥ c/500n2 c − ∀ 6
mw
Therefore, for any m,w = w , we have ηtLˆt 1 ηtLˆt 1 ln(500n2 1) ln(n2 )+6.
6 ∗ m−w∗ − m−w ≥ c − ≥ 2c
ii) Suppose ηtLˆt 1 ηtLˆt 1 ln(n2 ) m,w. Then, we can write
m−w∗ − m−w ≥ 2c ∀
Xt n2
mw∗ = exp ηtLˆt 1 ηtLˆt 1 m,w = w ,
Xt
m−w∗
−
m−w
≥ 2c ∀ 6
∗
mw
(cid:0) (cid:1)
which implies Xt 1 1 2c. Thus, Xt X = 2(1 Xt ) 4c m, and hence
mw∗ ≥ 1+2c/n ≥ − n k m − m∗ k1 − mw∗ ≤ n ∀
Xt X c.
∗ 1
k − k ≤iii) Suppose ηtAt 1 = b+β, where b = ln(n2 )+3 and β 0. Then, we have
− 2c ≥
ηt+1At = ηt+1At −1 +ηt+1(v mw∗(Xt) v mw(Xt))
−
ηt+1At 1 +ηt+1c
−
≥
ηt+1
= (b+β)+ηt+1c
ηt
ηt+1 ηt+1
= b+ β + ηt+1c (1 )b
ηt − − ηt
(cid:0) 1 1 (cid:1)
b+ηt+1 c ( )b
≥ − ηt+1 − ηt
b, (cid:0) (cid:1)
≥
where the last inequality holds by the fact that 1 1 c t t .
ηt+1 − ηt ≤ b ∀ ≥ 0
E. Proof of Theorem 5
Proof: Using identical arguments as in the proof of Theorem 4, with probability at least 1 δ,
−
ηtLˆt 1 ηtLˆt 1 ηtAt 1 3, t 1, m,w = w , (29)
m−w′
−
m−w
−
−
≤ ∀ ≥ ∀ 6
′
where we recall that At −(cid:12) (cid:12)1 = t τ− =1
1
v mw′(Xτ) −v mw(cid:12) (cid:12)(Xτ) . Now let Ω be the event such that Xτ
→
X ∗,
and assume X > 0 for some m,w. Conditioned on the event Ω, we have
m∗w
P (cid:0) (cid:1)
Xt
ηtAt 1 ηtLˆt 1 ηtLˆt 1 +3 = ln mw′ +3, t 0.
−
≤
m−w′
−
m−w
Xt ∀ ≥
mw
(cid:16) (cid:17)
For any w = w, by taking limit from the above relation as t , we get limsup ηtAt 1
l fn o( rXX amm ∗∗ nww y) s+ uf′ 3 fi6
c≤
ienO tl( y1) l. a11 rgN eo tw >le t¯t κ w: e= mv
um sw
t′( hX
av∗
e)
−
Atv
m 1w
>(X tκ∗) /. 2W
.
Ge ic vl→ ea nim∞ thκ
e≤
ch0 o. icO eth oe frw sti es pe s, it → zif e∞ ,κ w> e0 o,− bt th ae≤ in
n
−
lim ηtAt 1 = lim tηtκ/2 = , which contradicts the fact that limsup ηtAt 1 O(1).
Thut → s,∞ κ
≤
0,− which sht o→ w∞ s that if X m∗∞
w
> 0, then v mw(X ∗) = max w′v mw′(X ∗), i.et →.,∞X
∗
is− a N≤ E.
F. An Alternative Form for the Potential Function in Lemma 6
One can represent the potential function in Lemma 6 directly for womens’ ordinal preferences. Given
a mixed strategy profile x, let us associate a vector p w(x)
∈
R | +M | to each woman w whose coordinates
are sorted in the order of w’s preferences, such that if m > m > ... > m , we let the jth
1 w 2 w w n
coordinate of p (x) be given by
w
p (x) = x (1 x ),
jw mjw
−
kw
k> Ywmj
which is the probability that woman w is matched to her jth favorite man, assuming that the players
propose to women independently and according to their mixed strategies x. We note that for a pure-
strategy profile x 0,1 M W , p (x) would be a binary vector with all entries being zero except the
| || | w
∈ { }
jth one being one, where j is the index of the highest ranked man proposing to w. Therefore, Lemma
6 asserts that after each best response move, the vectors p (x),w W increase lexicographically
w
{ ∈ }
∗
11Here, if X m∗ w′ =0, by convention we define ln(X Xm m∗w w′)=−∞.with at least one of the vectors increases strictly. Now, if we again encode woman w’s preferences in
a cardinal vector λ = (λ ,...,λ ), then for a pure strategy profile x 0,1 M W , we have
w wm1 wmn
∈ {
}| || |
r (x) = p (x),λ = λ x (1 x ),
w w w wm mw kw
h i −
Xm k> Ywm
which coincides with the definition of r (x) in Theorem 6 that picks the reward of the highest-ranked
w
man proposing to w under x. Therefore, in the space of cardinal preferences and for any pure-strategy
profile x 0,1 M W , one can rewrite the potential function in Theorem 6 in a compact as
| || |
∈ { }
Φ(x) = r (x) = λ x (1 x ), (30)
w wm mw kw
−
Xw Xm,w k> Ywm
whose value increases after every best response update by a player. We note the similarity between
the potential function (30) and sum of players’ payoffs u (x) = µ x (1 x ),
m m m,w mw mw k>wm − kw
where one is written using mens’ preferences µ and the other using the womens’ preferences
mw
{ } P P Q
λ .
wm
{ }
G. A Gap Estimation Oracle for Unknown ∆.
Motivated by the Upper Confidence Bound (UCB) for stochastic bandits [31], here we provide a gap
estimation oracle, which, in combination with Algorithm 1, allows each player to adaptively adjust his
mixing parameter based on the estimated gap he has obtained so far. The integration of this oracle with
Algorithm 1 allows the algorithm to be more practical to the situation when a lower bound for the gap
∆ is unknown. In particular, using standard concentration bounds for the UCB algorithm, one can show
that the event that the estimated gap is larger than the true gap decays fast as time increases, hence
only introducing a small error term to the overall performance of the algorithm.
Algorithm 3 Gap Estimation Oracle for Player m
For t = 1,2,..., player m independetly performas the following steps:
player m independently computes his estimated preferences µ¯t 1 as well as his upper and lower
•
m−w
confidence bounds as
Mt 1 2logt 2logt
µ¯t 1 = m−w , Ut = min 1,µ¯t 1 + , Lt = max 0,µ¯t 1 ,
m−w N mt −w1 mw { m−w s N mt −w1 } mw { m−w −s N mt −w1 }
where Nt 1 denotes the number of times that m successfully gets matched to w up to time t 1,
m−w
−
and Mt 1 denote the accumulated rewards by player m of proposing to w up to time t 1.
m−w
−
At time t, player m proposes to a woman αt according to Algorithm 1 using the mixing parameter
• γt = Mˆ logt, where Mˆ is the value of M inm which ∆ and µ are replaced by the estimated values
t mw
∆ˆt = min ∆ˆt , and µ¯t 1, where
m w mw m−w
∆ˆt = max 0,Lt minUt .
mw { mw − w′ mw′ }
Player m updates its parameters as
•
Nt = Nt 1 +1 ,
mw m−w {αt k6=w ∀k>wm, αt m=w
}
Mt = Mt 1 +µt 1 .
mw m−w mw {αt k6=w ∀k>wm, αt m=w
}