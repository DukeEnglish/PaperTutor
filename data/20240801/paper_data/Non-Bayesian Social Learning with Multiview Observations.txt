Non-Bayesian Social Learning with Multiview Observations
Dongyan Sui, Weichen Cao, Stefan Vlaski, Chun Guan, Siyang Leng
Abstract—Non-Bayesian social learning enables multiple [10]. These rules can be applied to different network struc-
agentstoconductnetworkedsignalandinformationprocessing tures, including undirected/directed, time-varying [11], [12],
through observing environmental signals and information ag-
weakly-connected graphs [13], and higher-order topology
gregating.Traditionalnon-Bayesiansociallearningmodelsonly
[21], as well as to agents with growing self-confidence
consider single signals, limiting their applications in scenarios
where multiple viewpoints of information are available. In this [14] and heterogeneous stubbornness parameters [15], dis-
work, we exploit, in the information aggregation step, the parate hypothesis [16], under inferential attacks [17], and
independently learned results from observations taken from in adversarial conditions [18]. Research has also explored
multiple viewpoints and propose a novel non-Bayesian social
learning under uncertain likelihood models and performance
learning model for scenarios with multiview observations. We
againstmaliciousagents[19],[20].Allofthesemodelsoffer
prove the convergence of the model under traditional assump-
tions and provide convergence conditions for the algorithm theoreticalassurancesthat,overtime,agentscancollectively
in the presence of misleading signals. Through theoretical learn the underlying true state of the world.
analyses and numerical experiments, we validate the strong
In previous non-Bayesian social learning models, the
reliabilityandrobustnessoftheproposedalgorithm,showcasing
its potential for real-world applications. agents receive signals from the environment and cooper-
atively infer the underlying state based on their a priori
I. INTRODUCTION
knowledge of the signals. However, in practice, the group
Networked signal and information processing [1]–[5] could perceive different features of the environment from
refers to the collaborative processing of information and various perspectives. For example, individuals could judge
signalsamonganetworkofdistributedagents.Thisapproach thespeciesoftreesbasedonthecharacteristicsofbothleaves
leveragesthecollectivecapabilitiesofinterconnecteddevices and trunks; customers always infer the quality of a target
to perform tasks like decision-making, inference, and learn- product by observing the quality of other products from the
ing more efficiently than isolated systems. The significance samebrand.Traditionalmethodscopewithsuchsituationsby
of networked information processing lies in its ability to integrating these multiple viewpoints into one single signal,
enhance performance through cooperation, offering advan- making it challenging to determine the likelihood functions
tages such as improved scalability, resilience, and resource of agents with the integrated signal due to the requirement
efficiency. It is particularly relevant in applications like sen- of substantial data to assess the independence or correlation
sor networks, distributed control systems, and collaborative among multiple signals.
robotics.
In this work, we propose a novel non-Bayesian social
Non-Bayesian social learning [6]–[20] offers a novel
learning algorithm based on multiview observations. Our
frameworkfornetworkedsignalandinformationprocessing,
algorithmallowsthegrouptolearnindependentlyfrommul-
enablingadistributedwayforagentswithlimitedrationality
tiplesignalsandachievesinteractionamongmultiviewobser-
and diverse sensing capabilities to infer collectively over a
vationsduringtheinformationaggregationprocess.Similarly
network. Agents process streams of incomplete data based
to previous methods, we prove the correct convergence
on the underlying true state of the world, using network
of our proposed algorithm under traditional assumptions.
communications to form beliefs about various possible hy-
Additionally, we provide convergence conditions based on
potheses and make an estimate of the underlying true state.
the presence of misleading signals. Numerical experiments
This collaborative mechanism, which integrates neighbors’
validate the effectiveness of our theoretical analysis, and
insightswithfreshindividualdata,fostersascalablemethod
we showcase the robust fault-tolerance capability of our
of learning without prior knowledge of network structure or
proposed algorithm in the task of multi-agent collaborative
historical data.
localization.
Various social learning models have been proposed, in-
cluding aggregation methods such as linear averages [6], The remaining part of this paper is organized as follows:
[7], geometric averages [8], [9], and the minimum operator Section II provides a full description of the problem settings
and introduces our learning strategies. Section III presents
D.Y.S., W.C.C., C.G., and S.Y.L. are with Academy for Engineering sufficient assumptions/lemmas and proves the convergence
and Technology, Fudan University, Shanghai 200433, China. S.Y.L. is
of the proposed algorithm. Section IV provides extensive
withResearchInstituteofIntelligentComplexSystems,FudanUniversity,
Shanghai 200433, China. S.V. is with Department of Electrical and Elec- numerical examples illustrating the theoretical results and
tronicEngineering,ImperialCollegeLondon,UK.Correspondinge-mails: demonstratingtheeffectivenessandapplicabilityofthealgo-
{chunguan, syleng}@fudan.edu.cn.
rithm.ThefindingsareconcludedinSectionVwithpossible
S.Y.L.issupportedbytheNationalNaturalScienceFoundationofChina
(No.12101133). future works.
4202
luJ
03
]IS.sc[
1v07702.7042:viXraII. PRELIMINARIESANDTHEMODEL group’s perspective. In this case, the group may experience
false learning solely based on the type l signal.
A. Problem formulation
Thesecondcircumstancecouldbequitecommoninpracti-
Consider a group of n agents, collectively trying to reveal calapplications,oftenarisingfromfaultsinsignalperception
the underlying true state of nature, denoted as θ∗, from a or incorrect prior information due to a lack of training data.
finite set of hypotheses Θ={θ ,θ ,··· ,θ }. At each time
1 2 m
step t = 1,2,···, agent i obtains p types of observations B. Social Learning Strategies with Multiple Signals
(cid:8) sl i,t(cid:9)p l=1, which may come from multiple perspectives or Non-Bayesian social learning typically involves two steps
represent different features of the true state. Each element for agents to update their beliefs at each time, i.e., the
sl i,t is the realization of an environmental random variable Bayesian update step and the aggregation of neighbors’
Sl . The set sl = (cid:8) sl ,sl ,··· ,sl (cid:9) represents the beliefs [22]–[24].Inthebeliefaggregationstep,everyagent
i,t t 1,t 2,t n,t
actual observations made by all agents from signal type l shares its current belief with its one-hop neighbors, whereas
at time t, generated according to the likelihood function in the Bayesian update step, every agent combines its prior
fl(·) associated with the underlying true state θ∗. The set belief with observations from the environment to form its
s˜ t = (cid:8) s1 t,··· ,sp t(cid:9) and f˜= f1×···×fp. Each S il ,t has posterior belief.
its individual observation space Sl and is i.i.d. with respect Traditionally,whendealingwithtasksinvolvingmultiview
i
to t. observations, social learning algorithms integrate these di-
The signal structure for agent i with signal type l and versesignalsintoasinglesignalanddesignajointlikelihood
possible state θ is described by a probability distribution function as the signal structure. This approach demands a
ℓl(·|θ). In these settings, ℓl(sl |θ) indicates the likelihood thorough understanding of the correlations among different
i i i,t
of agent i observing type l signal sl at time t when it viewpoints of observations, often making it challenging to
i,t
believes θ is the underlying true state. achieve in practical tasks. In our work, however, we allow
The agents interact in a networked fashion, agents to independently perform Bayesian inference for
which is usually modelled by a directed graph each signal type and integrate information from multiview
G = (V,E). V = {1,2,··· ,n} is the set of observations during the information aggregation process.
vertices representing the n agents, and E = Thealgorithm wepropose canbe describedinthe follow-
{(i,j)|agent j can receive information from agent i} is ing two steps:
the set of directed edges. We denote A = (a ) as 1) Information aggregation. For each agent i and signal
ij n×n
the weight matrix of G, which is assumed to be row- type l=1,··· ,p, we calculate the updated belief using the
n
(cid:80) formula:
stochastic, i.e., a = 1,∀i = 1,··· ,n, and a > 0 if
ij ij
j=1 µ˜l (θ)=
(j,i) ∈ E. The row-stochastic condition of A ensures that i,t+1
(cid:32) (cid:33)
all agents assign normalized weights to the information, i.e., n p
exp γ (cid:80) a logµl (θ)+ (cid:80) γ logµk (θ)
proportions of the total, that they receive from neighbors. l ij j,t k i,t
j=1 k̸=l
The belief of agent i at time t with signal type l is (cid:32) (cid:33),
denoted as µl i,t, which mis a probability distribution over the (cid:80) exp γ
l
(cid:80)n a ijlogµl j,t(θ′)+ (cid:80)p γ klogµk i,t(θ′)
set of states Θ, i.e., (cid:80) µl (θ ) = 1, ∀i = 1,··· ,n,∀l = θ′∈Θ j=1 k̸=l
i,t k
1,··· ,p, and
∀t=0,k 1= ,1
···. Here µl represents the initial
wheretheassignedparameterγ
l
∈(0,1)foralll=1,··· ,p,
i,0 p
(cid:80)
belief of agent i with signal type l. and γ =1.
l
Defineaprobabilitytriple(Ω,F,P∗),whereΩ={ω|ω = l=1
2) Bayesian update. For each agent i and signal type l=
(s˜ ,s˜ ,···)}, F is the σ-algebra generated by the observa-
1 2 1,··· ,p, the posterior belief is given by:
tions, and P∗ is the probability measure induced by paths in
Ω, i.e., P∗ = (cid:81)∞ f˜. We use E∗[·] to denote the expectation µl (θ)= µ˜l i,t+1(θ)ℓl i(sl i,t+1|θ) .
t=1 i,t+1 (cid:80) µ˜l (θ′)ℓl(sl |θ′)
operator associated with measure P∗. i,t+1 i i,t+1
θ′∈Θ
In this work, we consider the following two different
III. ASSUMPTIONSANDRESULTS
circumstances:
Circumstance1:Foreveryagentiandeverysignaltypel, As widely discussed in previous works of social learning,
thesignalstructureℓl(·|θ∗)alignswiththei-thmarginaldis- we care about the convergence of the algorithms as well
i
tribution of fl(·) for all l=1,··· ,p, thereby characterizing as the rate of convergence. The following assumptions are
the probability distribution of Sl . In this case, all agents’ required to ensure the convergence of the proposed social
i,t
a priori knowledge is accurate, and none of the signal types learning strategies:
are misleading. Assumption 1 (Communication network): The graph G =
Circumstance 2: The condition in Circumstance 1 is not (V,E) and its weight matrix A satisfy that:
satisfied,andtheremayexistasignaltypelsuchthatℓl(·|θ∗) a) The graph is strongly-connected;
is not the best match of the real distribution fl(·) from the b) A has at least one positive diagonal entry.Assumption 1 ensures that A is the transition matrix of and 3, the proposed social learning strategy satisfies:
anirreducible,aperiodicMarkovchainwithfinitestates.We
recall the following lemma [25]: lim µl i,t(θ∗)=1, P∗−a.s., ∀1≤i≤n,1≤l≤p.
t→∞
Lemma 1: If a Markov chain with finite states is irre- Proof: For each agent i, signal type l, and θ ̸=θ∗, we
ducible, then it has a unique stationary distribution π. Let have
A be the transition matrix of the Markov chain and further
suppose it is aperiodic, then we have lim [Ak] ij = π j, for log
µl i,t+1(θ)
=γ
(cid:88)n
a log
µl j,t(θ) +(cid:88)p
γ log
µk i,t(θ)
k→∞ µl (θ∗) l ij µl (θ∗) k µk (θ∗)
1≤i,j ≤n. i,t+1 j=1 j,t k̸=l i,t
The stationary distribution π can be interpreted as the ℓl(sl |θ)
normalizedlefteigenvectorofAcorrespondingtoeigenvalue +log i i,t+1 .
ℓl(sl |θ∗)
1, known as the eigenvector centrality in related literature. i i,t+1
The Perron-Frobenius theorem ensures that all components By denoting νl (θ) = log µl i,t+1(θ) and Ll (θ) =
of π are strictly positive. i,t+1 µl (θ∗) i,t+1
i,t+1
Assumption 2 (Belief and signal structure): Every agent log ℓl i(sl i,t+1|θ) , the above equation simplifies to
i=1,··· ,n in the group satisfies:
ℓl i(sl i,t+1|θ∗)
a) It has positive initial beliefs on all states regarding all n p
(cid:88) (cid:88)
types of signals, i.e., µl (θ) > 0 for all l = 1,··· ,p and νl (θ)=γ a νl (θ)+ γ νk (θ)+Ll (θ).
i,0 i,t+1 l ij j,t k i,t i,t+1
θ ∈Θ; j=1 k̸=l
(1)
b) The logarithms of its signal structures are integrable,
i.e., E∗(cid:2) |logℓl(sl|θ)|(cid:3) < ∞ for all l = 1,··· ,p, sl ∈ Sl, Define the n-dimensional column vector
and θ ∈Θ. i i i i ν tl(θ) = (cid:0) ν 1l ,t(θ),··· ,ν nl ,t(θ)(cid:1)⊤ for each l =
1,··· ,p and the np-dimensional column vector
Assumption2a)isimposedtoensurethewell-definedness
(cid:16) (cid:17)⊤
of logµl (·). Meanwhile, Assumption 2b) guarantees that ν˜ (θ) = ν1(θ)⊤ ,··· ,νp(θ)⊤ . Similarly,
i,t t t t
logℓl i(sl i|θ) is real-valued almost surely [26]. In practical Ll(θ) = (cid:0) Ll (θ),··· ,Ll (θ)(cid:1)⊤ and L˜ (θ) =
scenarios where the signal structures of the agents are t 1,t n,t t
(cid:16) (cid:17)⊤
Gaussian, Assumption 2b) holds naturally since Gaussian L1(θ)⊤ ,··· ,Lp(θ)⊤ . Additionally, denote the matrix
t t
random variables are square integrable.
 
Two states, θ
j
and θ k, are called observationally equiva- γ 1A γ 2I ··· γ pI
l fe on rt aw lli sth l i ∈sig Sn ila ,l inty wpe hil chfo cr asa ege tn ht ei agif enℓ tl i( cs al i n|θ nj) ot= disℓ tl i i( ns gl i u|θ isk h) A˜=   γ 1 . . .I γ 2 . . .A · .· .· . γ p . . .I   ,
betweenthesestatesusingitsowninformationobtainedfrom
γ I γ I ··· γ A
type l signal. The true state is called globally identifiable 1 2 p
p n
if the set Θˆ = (cid:84) (cid:84) Θˆl has only one element θ∗, where where I is the identity matrix. It is evident that A˜ is a row-
i
l=1i=1 stochastic matrix, we further demonstrate that A˜ serves as
Θˆl = {θ ∈ Θ|ℓl(s |θ) = ℓl(sl|θ∗),∀sl ∈ Sl}. Intuitively, if
i i i i i i i the transition matrix for an irreducible, aperiodic Markov
astateθ′ isobservationallyequivalenttoθ∗ withalltypesof
chainwithfinitestates.GiventhatAhasatleastonepositive
signals for all agents, i.e., Θˆ ={θ∗,θ′}, then the two states diagonal element, A˜ contains a minimum of n positive
are indistinguishable from the view of all agents, and they
diagonal elements, making it aperiodic.
can not collectively learn the underlying true state.
We then examine the strong connectivity of the corre-
To ensure the convergence of groups’ beliefs on the true sponding graph of the np × np matrix A˜ to prove its
state, we introduce the following assumption:
irreducibility. For any node with index i = n(l−1)+i ,
0
Assumption 3 (Globally identifiable): The true state θ∗ is
where 1 ≤ i ≤ n and 1 ≤ l ≤ p, it can establish a path to
0
globally identifiable.
anynodewithindexj withintherangen(l−1)+1≤j ≤nl
Under this assumption, for all θ ̸=θ∗, there exists at least due to the irreducibility of A. We need to further find a
one agent i and a signal type l such that D KL(ℓl i(·|θ∗) ∥ path from node i to any node j, where j = n(k−1)+j 0,
ℓ thl i( e·|θ K) u) lli bs acst kr -i Lct ely iblp eo rsi dti iv ve e, rgw enh ce ere bD etK wL e( eP
n
∥ twQ o) pr re op br ae bs ie ln itt ys 1
γ
≤ >j 0 0,≤ an p, aa thnd Pk ̸= frol m. S nin oc de ea˜ in( tk o−1 n) o+ di e0,i n= (k[ −γ lI 1] )i0 +i0 i=
l 1 0
distributions P and Q. exists.Additionally,noden(k−1)+i canfindapathP to
0 2
Denote in the following that K il(θ∗,θ) = D KL(f il(·) ∥ node j as previously demonstrated. Combining these paths
ℓl i(·|θ∗))−D KL(f il(·) ∥ ℓl i(·|θ)). Its positivity or negativity as P = P
1
∪P
2
establishes a path from node i to node j.
depends on whether, from the perspective of agent i, state θ Thus, we can conclude that every node i has a path to any
or θ∗ is more likely to be the underlying true state. Notice node j in the graph corresponding to matrix A˜, confirming
that under Circumstance 1, K il(θ∗,θ) = −D KL(ℓl i(·|θ∗) ∥ its irreducibility.
ℓl i(·|θ)). Now we can state the main results describing the Subsequently we can rewrite (1) in matrix form:
correct convergence of the proposed strategy.
Theorem 1: Under Circumstance 1 and Assumptions 1, 2 ν˜ (θ)=A˜ν˜ (θ)+L˜ (θ).
t+1 t t+1𝑺1
Now it follows that
1
𝑺1
1 1 1
tν˜ t+1(θ)= tA˜ν˜ t(θ)+ tL˜ t+1(θ)=···
1
𝑁
𝒢1
2
= 1 tA˜t+1ν˜ 0(θ)+ 1
t
k(cid:88) =t 1A˜kL˜ t+1−k(θ)+ 1 tL˜ t+1(θ). (2) 𝑁
𝒢
2
4 3
𝑁
𝒢1
3 2
1
The assumptions admit that the first and the third terms on 4
r.h.s. of (2) go to zero as t → ∞. The second term can be 4 3 𝑺3 𝑁 𝒢2 2 3 𝑺3
deformed as 𝑺2
𝑺2
4
1(cid:88)t
A˜kL˜ (θ)=
1(cid:88)t
(A˜k−1 π˜)L˜ (θ)
3
t t+1−k t np t+1−k
k=1 k=1 Fig. 1. An intuitive illustration for an understanding of the proposed
+
1(cid:88)t
1 π˜(L˜ (θ)−K˜(θ∗,θ))
algorithm.
t np t+1−k
k=1
+
1(cid:88)t
1 π˜K˜(θ∗,θ),
µl i,t(θ) → 0 for all i = 1,··· ,n and l = 1,··· ,p almost
t np surely.
k=1 In the proof of Theorem 1, it is noteworthy that we
(3)
constructanewrow-stochasticmatrixA˜anddemonstrateits
where1 isannp-dimensionalcolumnvectorofones,π˜ is
np
theeigenvectorcentralitycorrespondingtomatrixA˜andisa primitivity. Hence,our proposedalgorithm can beviewed as
(cid:16) (cid:17)⊤ duplicating the network G of agents into p identical subnet-
row vector, K˜(θ∗,θ) = K1(θ∗,θ)⊤ ,··· ,Kp(θ∗,θ)⊤ ,
works G1,··· ,Gp, establishing bidirectional links between
and Kl(θ∗,θ) = (cid:0) Kl(θ∗,θ),··· ,Kl(θ∗,θ)(cid:1)⊤ . Lemma 1 each node and its duplicate, and assigning a distinct signal
1 n
admits that lim A˜k = 1 π˜. Noticing that all elements of to each subnetwork for classic non-Bayesian social learning
np
k→∞ with geometric averaging. The weight matrix corresponding
A˜k(k =1,2,···) are bounded, the first term on r.h.s. of (3) to the augmented network is exactly A˜. An illustration is
converges to zero as t→∞. Moreover, under Circumstance
shown in Fig. 1.
1, for all l=1,··· ,p we have
Theorem 1 guarantees that all agents will eventually learn
(cid:34) (cid:35)
ℓl(sl |θ) the underlying true state with our learning strategy as long
E∗[Ll (θ)]=E∗ log i i,t
i,t ℓl(sl |θ∗) as some fundamental assumptions are satisfied. Notably, our
i i,t
algorithmdoesnotrequireeverytypeofsignaltobeinforma-
(cid:90) ℓl(sl|θ)
= ℓl(sl|θ∗)log i dsl tive for the group. As long as, for every pair of states θ and
i ℓl(sl|θ∗) θ∗, there exist an agent capable of distinguishing between
i
sl∈S il them with a certain type of signal, the entire group can
=−D KL(ℓl i(·|θ∗)∥ℓl i(·|θ))=K il(θ∗,θ). achieve correct learning. Subsequently, we will demonstrate
that, in certain scenarios, our method is capable of learning
The Kolmogorov’s strong law of large numbers gives that
correctly even in the presence of misleading signals.
∀l=1,··· ,p,
From the proof of Theorem 1, as long as (4) is satisfied,
1(cid:88)t 1(cid:88)t all agents will learn the underlying true state correctly.
Ll (θ)− E∗[Ll (θ)]→0, P∗−a.s.,
t t+1−k t t+1−k Therefore, it is important to figure out π˜, leading to the
k=1 k=1 following lemma.
as t→∞, which leads to Lemma 2: Letπ˜ bethenormalizedlefteigenvectorofma-
trixA˜associatedwitheigenvalue1,andπ bethenormalized
t
lim
1(cid:88)
1 π˜(L˜ (θ)−K˜(θ∗,θ))=0, P∗−a.s.. left eigenvector of matrix A associated with eigenvalue 1.
t→∞ t np t+1−k Then, we have π˜ =(γ π,··· ,γ π).
k=1 1 p
Proof:
Now (3) gives that
t π˜A˜=(γ (γ πA+γ π+···+γ π),··· ,
lim
1(cid:88)
A˜kL˜ (θ)=1 π˜K˜(θ∗,θ), P∗−a.s..
1 1 2 p
t→∞ t t+1−k np γ p(γ 1π+γ 2π+···+γ pπA))
k=1
=(γ π,··· ,γ π)=π˜.
According to Assumption 3 and Lemma 1, for all θ ̸= θ∗ 1 p
we have p
1 The second equality follows from πA = π and (cid:80) γ = 1.
lim ν˜ (θ)<0, P∗−a.s.. (4) l
t→∞ t t+1 l=1
Thus νl (θ) → −∞ almost surely for all agents i = Theorem 2: Under Circumstance 2 and Assumptions 1
i,t+1
1,··· ,n and signal types l = 1,··· ,p. This implies and2,allagentswillcorrectlylearntheunderlyingtruestate,i.e.,
lim µl (θ∗)=1, P∗−a.s., ∀1≤i≤n,1≤l≤p,
t→∞ i,t Type 1 Type 1
(Isolated) (Collaboration)
if and only if
p n
(cid:88) (cid:88)
γ π Kl(θ∗,θ)<0.
l i i
Type 2
Proof: Firstl l= y,1 simi i= la1 rtotheproofofTheorem1,under (Isolated) (ColT lay bp oe r a2 tion)
Circumstance 2 we have
(cid:34) ℓl(sl |θ) (cid:35) (a) (b)
E∗(cid:2) Ll (θ)(cid:3) =E∗ log i i,t
i,t ℓl(s |θ∗) Fig. 2. The evolution of beliefs of Agent 1 on different states. (a) The
i i,t two agents are unable to identify the underlying true state with a single
(cid:90) ℓl(sl|θ) type of signal. (b) The two agents achieve correct learning by combining
= f il(sl)log ℓli (sl|θ∗)dsl theinformationfromtwotypesofsignals.
i
sl∈Sl
i
(cid:90) (cid:18) fl(sl) fl(sl) (cid:19)
= fl(sl) log i −log i dsl
i ℓl(sl|θ∗) ℓl(sl|θ)
i i
sl∈Sl Observationally
i Equivalent
=D KL(f il(·)||ℓl i(·|θ∗))−D KL(f il(·)||ℓl i(·|θ)) Agent 1 Agent 2 Possible States
Target
=Kl(θ∗,θ).
i
and
1
lim ν˜ (θ)=1 π˜K˜(θ∗,θ)
t→∞ t t+1 np Fig. 3. Illustration of the scenario in Example 1. In this example, the
p (5) two agents, due to the observational equivalence problem, cannot achieve
(cid:88)
=1 ⊗ γ 1 πKl(θ∗,θ), correctlearningrelyingsolelyonasingletypeofsignal.
p l n
l=1
n
1 πKl(θ∗,θ)=(cid:88) π Kl(θ∗,θ)1 , from the target, which could be at any of the 16 grid points.
n i i n
The signal structure of the two agents with respect to θ also
i=1
follows a Gaussian distribution, with the mean value equal
p
hence the condition (cid:80) γ 1 πKl(θ∗,θ) < 0 holds if and to the true distance between the agent and θ. As shown in
l n
l=1 Fig. 3, the two agents struggle to distinguish between two
p n
only if (cid:80) γ (cid:80) π Kl(θ∗,θ)<0. statesduetotheoverlappingcirclescenteredonthesestates,
l i i
l=1 i=1 whereeachcirclehasaradiusequaltothedistancefromthe
Theorem 2 demonstrates the robustness of our algorithm
target.
when dealing with multiple signals. Even if some types of
At the same time, both agents can receive signals (type
signalsmightbemisleading,thelikelihoodofcollectivemis-
2) regarding whether the target is above or below them. If
learning can be reduced by adjusting the assigned parameter
the target is above an agent, at each moment, there is a 0.8
γ . Additionally, as can be seen from (5), assigning a higher
l
probability of receiving signal U and a 0.2 probability of
weightγ tosignalsthataremoreinstructive,i.e.,betterable
l receiving signal D. The signal structure is set as ℓ2(U|θ)=
to help the group distinguish between correct and incorrect i
0.8 if θ is located above i and ℓ2(U|θ)=0.2 if θ is located
states, can accelerate the convergence rate of the algorithm. i
below i. It is obvious that both of the two agents can not
IV. NUMERICALEXAMPLES identify the underlying true state based solely on type 2
A. Learning with multiview observations signal.
The initial beliefs about both types of signal are uniform
We first demonstrate that our proposed multiview obser-
distributions over all possible states. Under our settings, the
vations algorithm can address the observational equivalence
signalstructuresofallagentsandalltypesofsignalaboutthe
issuepresentwhenonlya singleviewpointofinformationis
true state θ∗ align with its actual distribution, which satisfy
available.
Example 1: Consider a strongly-connected network con- the conditions in Circumstance 1.
sisting of two agents. The corresponding weight matrix is Theexperimentalresultsindicatethattheagentsareunable
(cid:20) (cid:21) to collectively learn the true state according to one type of
0 1
A= . signalsolely,asshowninFig.2(a).However,bycombining
0.7 0.3
the information provided by both types of signals, the two
The two agents are engaged in the task of localizing a target agentscansuccessfullycollaboratetoidentifytheunderlying
situated within a 4×4 grid. They receive Gaussian signals true state due to the fact that Assumption 3 is satisfied, as
(type 1) with mean values corresponding to the distances showninFig.4(b).ThisexampledemonstratesthatlearningType 1 Type 1
Type 1 Type 1 (Isolated) (Collaboration)
(Isolated) (Collaboration)
Type 2 Type 2
Type 2 Type 2 (Isolated) (Collaboration)
(Isolated) (Collaboration)
(a) (b) (a) (b)
Fig. 4. The evolution of beliefs of Agent 1 on all possible states in the Fig. 5. The evolution of beliefs of Agent 1 on all possible states in
firstscenarioofdistributedcooperativelocalizationtask.(a)Theagentcan the second scenario of distributed cooperative localization task. (a) The
identify the optimal state solely based on azimuth information, but using agentscannotachievecorrectlearningsolelyrelyingondistanceorazimuth
only distance information results in erroneous learning. (b) By employing information. (b) By employing our algorithm to integrate the information
our algorithm to integrate the information from both types of signals, the from both types of signals, the agents can learn the underlying true state
beliefsoftheagentconvergetothetruestate. asymptotically.
Agents
from multiple signals can resolve the issue of observation-
Possible
ally equivalence present in single-signal scenarios, thereby States
offering more tolerant conditions for successful learning.
𝜶𝟐∗ Underlying
True State
𝜶𝟏∗ O unp dti em
r
Sal
i
gS nt aa lt e
1
𝜶𝟏∗
𝜶𝟐∗
B. Learning with misleading signal
Optimal State
under Signal 2
In the following example, we will demonstrate how our
Target
proposedalgorithmaddressestheissueoferroneouslearning
that may occur with a single viewpoint of signal by ag-
Fig. 6. Illustrations of two typical scenarios. In the first scenario, the
gregating information from multiview observations, thereby groupincorrectlyselectstheoptimalstatebasedondistanceinformation.In
validating the enhanced robustness of our algorithm. the second scenario, due to the similar orientation information of the two
agents,notypeofsignalsleadstocorrectlearning.
Example 2: Consider a scenario where a group of N
sensorsisrandomlydistributedinatwo-dimensionalsquare,
denoted as [0,1]2. Each sensor receives two viewpoints of outcome θˆsatisfies:
observations at every time step, one is related to distance
θˆ=θ ,
and the other related to orientation. The first type is a j0
Gaussian signal with noise, representing the distance from (cid:88)2 (cid:18) 1 (cid:19)
the sensor to the target. Specifically, S1
i,t
∼ N(d∗ i,σ 12) j 0 = ja =rg 1,·m ··,i mn π i (d∗ i −dj i)2+ 10(α i∗−α ij)2 ,
for all i = 1,··· ,N and t = 1,2,···, where d∗ denotes i=1
i
the distance from the i-th sensor to the target. The second whereπ =(π ,π )istheeigenvectorcentralitycorrespond-
1 2
type of signal also contains Gaussian noise and pertains to ing to the weight matrix.
the azimuth between the agent and the target, and S2 ∼ We fix the position of the target and allow agents to be
i,t
N(α∗,σ2), where α∗ denotes the azimuth. There are M distributed in different locations to study the collaborative
i 1 i
possiblepositionsθ m (m=1,··· ,M)uniformlydistributed learning outcomes with two types of signals separately and
in the square space. Let dm and αm denote the distance and jointly. In 1000 experiments, our proposed method, which
i i
azimuth from sensor i to a possible state θ m respectively. combines distance and azimuth information, successfully
The collective aim of these sensors is to find the state that achieves localization 853 times, while relying solely on dis-
has a position closest to the target, and it is conceived as tanceorazimuthinformationleadstosuccessfullocalization
underlying true state θ∗. For every agent i, we set ℓ1 i(·|θ m) 550 and 582 times, respectively. This clearly demonstrates
to align with N(dm,σ2), and since the orientation serves as the benefits of integrating both types of signal information.
i 1
auxiliary information, we let ℓ2 i(·|θ m)∼N(α im,10σ 22). We will further present the detailed results of two typical
We set N = 2, M = 36, σ = σ = 0.5, and scenarios. In the first scenario, agents relying solely on
1 2
γ = γ = 0.5. The weight matrix is the same as that distanceinformationfailtofindthestateclosesttothetarget,
1 2
in Example 1, indicating that the corresponding network while exclusive reliance on azimuth information results in
is strongly-connected. The initial beliefs about both types successful localization, as shown in Fig. 4 (a). If they com-
of signal are uniform distributions over all possible states. bine both types of information, all agents could successfully
In situations where the target does not coincide with any achieve the task, as shown in Fig. 4 (b). In the second
possible state, our experimental setup clearly meets the scenario, agents relying solely on either distance or azimuth
conditionsofCircumstance2.Inthiscase,basedontheproof information are unable to achieve accurate localization, as
ofTheorem2andthroughcalculation,thecollectivelearning evidencedinFig.5(a).However,afterapplyingourmethod,agentsareabletosuccessfullyidentifythestateclosesttothe [9] M.A.Rahimian,P.Molavi,andA.Jadbabaie,“(non-)bayesianlearn-
target,asdemonstratedinFig.5(b).Theschematicdiagrams ingwithoutrecall,”in53rdIEEEConferenceonDecisionandControl,
2014,pp.5730–5735.
of agent and state positions in two scenarios are presented
[10] A. Mitra, J. A. Richards, and S. Sundaram, “A new approach for
in Fig. 6. distributedhypothesistestingwithextensionstobyzantine-resilience,”
This experiment, serving as a complement to Theorem in2019AmericanControlConference(ACC),2019,pp.261–266.
[11] A.Nedic´,A.Olshevsky,andC.A.Uribe,“Fastconvergenceratesfor
2, demonstrates that our proposed multiview observations
distributed non-bayesian learning,” IEEE Transactions on Automatic
algorithm can, to a certain extent, alleviate the impact of Control,vol.62,no.11,pp.5538–5553,2017.
misleading signals, thereby increasing the fault tolerance of [12] ——,“Nonasymptoticconvergenceratesforcooperativelearningover
time-varyingdirectedgraphs,”in2015AmericanControlConference
collective learning.
(ACC),2015,pp.5884–5889.
[13] H. Salami, B. Ying, and A. H. Sayed, “Social learning over weakly
V. CONCLUSIONANDFUTUREWORK
connected graphs,” IEEE Transactions on Signal and Information
In this paper, we extend traditional non-Bayesian social ProcessingoverNetworks,vol.3,no.2,pp.222–238,2017.
[14] C.A.UribeandA.Jadbabaie,“Onincreasingself-confidenceinnon-
learning algorithms designed for single signal and propose a
bayesian social learning over time-varying directed graphs,” in 2019
distributed information processing algorithm that integrates AmericanControlConference(ACC),2019,pp.3532–3537.
information from multiview observations. Our proposed al- [15] D.Sui,C.Guan,Z.Gan,W.Lin,andS.Leng,“Tuningconvergence
rate via non-bayesian social learning: A trade-off between internal
gorithm enables the group to learn from multiple view-
belief and external information,” in 2023 62nd IEEE Conference on
points of information independently and achieving inter- DecisionandControl(CDC),2023,pp.1381–1387.
action among multiview observations during the informa- [16] K.Ntemos,V.Bordignon,S.Vlaski,andA.H.Sayed,“Sociallearning
withdisparatehypotheses,”in202230thEuropeanSignalProcessing
tion aggregation step. By introducing weight parameters for
Conference(EUSIPCO),2022,pp.2171–2175.
various signal types, we not only ensure the convergence [17] ——, “Social learning under inferential attacks,” in ICASSP 2021 -
of the algorithm under traditional assumptions, but also, 2021IEEEInternationalConferenceonAcoustics,SpeechandSignal
Processing(ICASSP),2021,pp.5479–5483.
in certain scenarios, correct errors introduced by a single
[18] M. Z. A. Bhotto and W. P. Tay, “Non-bayesian social learning with
view of signal, significantly enhancing the fault tolerance of observation reuse and soft switching,” ACM Transactions on Sensor
collective learning. Networks(TOSN),vol.14,no.2,pp.1–21,2018.
Our work not only presents a distributed information [19] J.Z.Hare,C.A.Uribe,L.M.Kaplan,andA.Jadbabaie,“Onmalicious
agents in non-bayesian social learning with uncertain models,” in
processing algorithm capable of handling a more diverse 201922thInternationalConferenceonInformationFusion(FUSION),
rangeoftaskscenariosbutalsocontributestothetheoretical 2019,pp.1–8.
foundation of distributed machine learning. In future en- [20] J.Z.Hare,C.A.Uribe,L.Kaplan,andA.Jadbabaie,“Non-bayesian
sociallearningwithuncertainmodels,”IEEETransactionsonSignal
deavors, we plan to explore the application of non-Bayesian Processing,vol.68,pp.4178–4193,2020.
sociallearningalgorithmswithmultiviewobservationsinthe [21] Q. Chen, W. Shi, D. Sui, and S. Leng, “Distributed consensus
design of distributed machine learning methods to address algorithms in sensor networks with higher-order topology,” Entropy,
vol.25,no.8,p.1200,2023.
challengesassociatedwithmulti-featureorhigh-dimensional
[22] Q. Liu, J. Zhao, and X. Wang, “Distributed detection via bayesian
problems. Additionally, we may consider other interaction updates and consensus,” in 2015 34th Chinese Control Conference
mechanisms among multiple signals, such as negative feed- (CCC). IEEE,2015,pp.6992–6997.
[23] A.Lalitha,A.Sarwate,andT.Javidi,“Sociallearninganddistributed
back,andintroducemoreparametersettingstoenableappli- hypothesistesting,”in2014IEEEInternationalSymposiumonInfor-
cations in a wider range of tasks. mationTheory. IEEE,2014,pp.551–555.
[24] A.Nedic´,A.Olshevsky,andC.A.Uribe,“Fastconvergenceratesfor
REFERENCES distributed non-bayesian learning,” IEEE Transactions on Automatic
Control,vol.62,no.11,pp.5538–5553,2017.
[1] S.KarandJ.M.F.Moura,“Distributedconsensusalgorithmsinsensor [25] P. G. Hoel, S. C. Port, and C. J. Stone, Introduction to Stochastic
networks with imperfect communication: Link failures and channel Processes. LongGrove,IL,USA:WavelandPress,1986.
noise,” IEEE Transactions on Signal Processing, vol. 57, no. 1, pp. [26] E.CinlarandE.ðCınlar,Probabilityandstochastics. Springer,2011,
355–369,2009. vol.261.
[2] A.NedicandA.Ozdaglar,“Distributedsubgradientmethodsformulti-
agentoptimization,”IEEETransactionsonAutomaticControl,vol.54,
no.1,pp.48–61,2009.
[3] J. Chen and A. H. Sayed, “Diffusion adaptation strategies for dis-
tributedoptimizationandlearningovernetworks,”IEEETransactions
onSignalProcessing,vol.60,no.8,pp.4289–4305,2012.
[4] S. Kar, J. M. F. Moura, and K. Ramanan, “Distributed parameter
estimation in sensor networks: Nonlinear observation models and
imperfectcommunication,”IEEETransactionsonInformationTheory,
vol.58,no.6,pp.3575–3605,2012.
[5] S.Vlaski,S.Kar,A.H.Sayed,andJ.M.Moura,“Networkedsignal
and information processing: Learning by multiagent systems,” IEEE
SignalProcessingMagazine,vol.40,no.5,pp.92–105,2023.
[6] A. Jadbabaie, P. Molavi, A. Sandroni, and A. Tahbaz-Salehi, “Non-
bayesian social learning,” Games and Economic Behavior, vol. 76,
no.1,pp.210–225,2012.
[7] S. Shahrampour and A. Jadbabaie, “Exponentially fast parameter
estimationinnetworksusingdistributeddualaveraging,”in52ndIEEE
ConferenceonDecisionandControl. IEEE,2013,pp.6196–6201.
[8] A. Lalitha, T. Javidi, and A. D. Sarwate, “Social learning and
distributed hypothesis testing,” IEEE Transactions on Information
Theory,vol.64,no.9,pp.6161–6179,2018.