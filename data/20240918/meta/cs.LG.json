[
    {
        "title": "RetrievalAttention: Accelerating Long-Context LLM Inference via Vector Retrieval",
        "authors": "Di LiuMeng ChenBaotong LuHuiqiang JiangZhenhua HanQianxi ZhangQi ChenChengruidong ZhangBailu DingKai ZhangChen ChenFan YangYuqing YangLili Qiu",
        "links": "http://arxiv.org/abs/2409.10516v1",
        "entry_id": "http://arxiv.org/abs/2409.10516v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10516v1",
        "summary": "Transformer-based large Language Models (LLMs) become increasingly important\nin various domains. However, the quadratic time complexity of attention\noperation poses a significant challenge for scaling to longer contexts due to\nthe extremely high inference latency and GPU memory consumption for caching\nkey-value (KV) vectors. This paper proposes RetrievalAttention, a training-free\napproach to accelerate attention computation. To leverage the dynamic sparse\nproperty of attention, RetrievalAttention builds approximate nearest neighbor\nsearch (ANNS) indexes upon KV vectors in CPU memory and retrieves the most\nrelevant ones via vector search during generation. Due to the\nout-of-distribution (OOD) between query vectors and key vectors, off-the-shelf\nANNS indexes still need to scan O(N) (usually 30% of all keys) data for\naccurate retrieval, which fails to exploit the high sparsity.\nRetrievalAttention first identifies the OOD challenge of ANNS-based attention,\nand addresses it via an attention-aware vector search algorithm that can adapt\nto queries and only access 1--3% of data, thus achieving a sub-linear time\ncomplexity. RetrievalAttention greatly reduces the inference cost of\nlong-context LLM with much lower GPU memory requirements while maintaining the\nmodel accuracy. Especially, RetrievalAttention only needs 16GB GPU memory for\nserving 128K tokens in LLMs with 8B parameters, which is capable of generating\none token in 0.188 seconds on a single NVIDIA RTX4090 (24GB).",
        "updated": "2024-09-16 17:59:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10516v1"
    },
    {
        "title": "Causal Language Modeling Can Elicit Search and Reasoning Capabilities on Logic Puzzles",
        "authors": "Kulin ShahNishanth DikkalaXin WangRina Panigrahy",
        "links": "http://arxiv.org/abs/2409.10502v1",
        "entry_id": "http://arxiv.org/abs/2409.10502v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10502v1",
        "summary": "Causal language modeling using the Transformer architecture has yielded\nremarkable capabilities in Large Language Models (LLMs) over the last few\nyears. However, the extent to which fundamental search and reasoning\ncapabilities emerged within LLMs remains a topic of ongoing debate. In this\nwork, we study if causal language modeling can learn a complex task such as\nsolving Sudoku puzzles. To solve a Sudoku, the model is first required to\nsearch over all empty cells of the puzzle to decide on a cell to fill and then\napply an appropriate strategy to fill the decided cell. Sometimes, the\napplication of a strategy only results in thinning down the possible values in\na cell rather than concluding the exact value of the cell. In such cases,\nmultiple strategies are applied one after the other to fill a single cell. We\nobserve that Transformer models trained on this synthetic task can indeed learn\nto solve Sudokus (our model solves $94.21\\%$ of the puzzles fully correctly)\nwhen trained on a logical sequence of steps taken by a solver. We find that\ntraining Transformers with the logical sequence of steps is necessary and\nwithout such training, they fail to learn Sudoku. We also extend our analysis\nto Zebra puzzles (known as Einstein puzzles) and show that the model solves\n$92.04 \\%$ of the puzzles fully correctly. In addition, we study the internal\nrepresentations of the trained Transformer and find that through linear\nprobing, we can decode information about the set of possible values in any\ngiven cell from them, pointing to the presence of a strong reasoning engine\nimplicit in the Transformer weights.",
        "updated": "2024-09-16 17:42:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10502v1"
    },
    {
        "title": "Partial Distribution Matching via Partial Wasserstein Adversarial Networks",
        "authors": "Zi-Ming WangNan XueLing LeiRebecka JörnstenGui-Song Xia",
        "links": "http://arxiv.org/abs/2409.10499v1",
        "entry_id": "http://arxiv.org/abs/2409.10499v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10499v1",
        "summary": "This paper studies the problem of distribution matching (DM), which is a\nfundamental machine learning problem seeking to robustly align two probability\ndistributions. Our approach is established on a relaxed formulation, called\npartial distribution matching (PDM), which seeks to match a fraction of the\ndistributions instead of matching them completely. We theoretically derive the\nKantorovich-Rubinstein duality for the partial Wasserstain-1 (PW) discrepancy,\nand develop a partial Wasserstein adversarial network (PWAN) that efficiently\napproximates the PW discrepancy based on this dual form. Partial matching can\nthen be achieved by optimizing the network using gradient descent. Two\npractical tasks, point set registration and partial domain adaptation are\ninvestigated, where the goals are to partially match distributions in 3D space\nand high-dimensional feature space respectively. The experiment results confirm\nthat the proposed PWAN effectively produces highly robust matching results,\nperforming better or on par with the state-of-the-art methods.",
        "updated": "2024-09-16 17:41:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10499v1"
    },
    {
        "title": "MusicLIME: Explainable Multimodal Music Understanding",
        "authors": "Theodoros SotirouVassilis LyberatosOrfeas Menis MastromichalakisGiorgos Stamou",
        "links": "http://arxiv.org/abs/2409.10496v1",
        "entry_id": "http://arxiv.org/abs/2409.10496v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10496v1",
        "summary": "Multimodal models are critical for music understanding tasks, as they capture\nthe complex interplay between audio and lyrics. However, as these models become\nmore prevalent, the need for explainability grows-understanding how these\nsystems make decisions is vital for ensuring fairness, reducing bias, and\nfostering trust. In this paper, we introduce MusicLIME, a model-agnostic\nfeature importance explanation method designed for multimodal music models.\nUnlike traditional unimodal methods, which analyze each modality separately\nwithout considering the interaction between them, often leading to incomplete\nor misleading explanations, MusicLIME reveals how audio and lyrical features\ninteract and contribute to predictions, providing a holistic view of the\nmodel's decision-making. Additionally, we enhance local explanations by\naggregating them into global explanations, giving users a broader perspective\nof model behavior. Through this work, we contribute to improving the\ninterpretability of multimodal music models, empowering users to make informed\nchoices, and fostering more equitable, fair, and transparent music\nunderstanding systems.",
        "updated": "2024-09-16 17:28:21 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10496v1"
    },
    {
        "title": "Flash STU: Fast Spectral Transform Units",
        "authors": "Y. Isabel LiuWindsor NguyenYagiz DevreEvan DogariuAnirudha MajumdarElad Hazan",
        "links": "http://arxiv.org/abs/2409.10489v2",
        "entry_id": "http://arxiv.org/abs/2409.10489v2",
        "pdf_url": "http://arxiv.org/pdf/2409.10489v2",
        "summary": "This paper describes an efficient, open source PyTorch implementation of the\nSpectral Transform Unit. We investigate sequence prediction tasks over several\nmodalities including language, robotics, and simulated dynamical systems. We\nfind that for the same parameter count, the STU and its variants outperform the\nTransformer as well as other leading state space models across various\nmodalities.",
        "updated": "2024-09-17 12:01:14 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10489v2"
    }
]