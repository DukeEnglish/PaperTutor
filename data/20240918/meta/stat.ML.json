[
    {
        "title": "Partial Distribution Matching via Partial Wasserstein Adversarial Networks",
        "authors": "Zi-Ming WangNan XueLing LeiRebecka JörnstenGui-Song Xia",
        "links": "http://arxiv.org/abs/2409.10499v1",
        "entry_id": "http://arxiv.org/abs/2409.10499v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10499v1",
        "summary": "This paper studies the problem of distribution matching (DM), which is a\nfundamental machine learning problem seeking to robustly align two probability\ndistributions. Our approach is established on a relaxed formulation, called\npartial distribution matching (PDM), which seeks to match a fraction of the\ndistributions instead of matching them completely. We theoretically derive the\nKantorovich-Rubinstein duality for the partial Wasserstain-1 (PW) discrepancy,\nand develop a partial Wasserstein adversarial network (PWAN) that efficiently\napproximates the PW discrepancy based on this dual form. Partial matching can\nthen be achieved by optimizing the network using gradient descent. Two\npractical tasks, point set registration and partial domain adaptation are\ninvestigated, where the goals are to partially match distributions in 3D space\nand high-dimensional feature space respectively. The experiment results confirm\nthat the proposed PWAN effectively produces highly robust matching results,\nperforming better or on par with the state-of-the-art methods.",
        "updated": "2024-09-16 17:41:45 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10499v1"
    },
    {
        "title": "Kolmogorov-Arnold Networks in Low-Data Regimes: A Comparative Study with Multilayer Perceptrons",
        "authors": "Farhad Pourkamali-Anaraki",
        "links": "http://arxiv.org/abs/2409.10463v1",
        "entry_id": "http://arxiv.org/abs/2409.10463v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10463v1",
        "summary": "Multilayer Perceptrons (MLPs) have long been a cornerstone in deep learning,\nknown for their capacity to model complex relationships. Recently,\nKolmogorov-Arnold Networks (KANs) have emerged as a compelling alternative,\nutilizing highly flexible learnable activation functions directly on network\nedges, a departure from the neuron-centric approach of MLPs. However, KANs\nsignificantly increase the number of learnable parameters, raising concerns\nabout their effectiveness in data-scarce environments. This paper presents a\ncomprehensive comparative study of MLPs and KANs from both algorithmic and\nexperimental perspectives, with a focus on low-data regimes. We introduce an\neffective technique for designing MLPs with unique, parameterized activation\nfunctions for each neuron, enabling a more balanced comparison with KANs. Using\nempirical evaluations on simulated data and two real-world data sets from\nmedicine and engineering, we explore the trade-offs between model complexity\nand accuracy, with particular attention to the role of network depth. Our\nfindings show that MLPs with individualized activation functions achieve\nsignificantly higher predictive accuracy with only a modest increase in\nparameters, especially when the sample size is limited to around one hundred.\nFor example, in a three-class classification problem within additive\nmanufacturing, MLPs achieve a median accuracy of 0.91, significantly\noutperforming KANs, which only reach a median accuracy of 0.53 with default\nhyperparameters. These results offer valuable insights into the impact of\nactivation function selection in neural networks.",
        "updated": "2024-09-16 16:56:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10463v1"
    },
    {
        "title": "Multidimensional Deconvolution with Profiling",
        "authors": "Huanbiao ZhuKrish DesaiMikael KuuselaVinicius MikuniBenjamin NachmanLarry Wasserman",
        "links": "http://arxiv.org/abs/2409.10421v1",
        "entry_id": "http://arxiv.org/abs/2409.10421v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10421v1",
        "summary": "In many experimental contexts, it is necessary to statistically remove the\nimpact of instrumental effects in order to physically interpret measurements.\nThis task has been extensively studied in particle physics, where the\ndeconvolution task is called unfolding. A number of recent methods have shown\nhow to perform high-dimensional, unbinned unfolding using machine learning.\nHowever, one of the assumptions in all of these methods is that the detector\nresponse is accurately modeled in the Monte Carlo simulation. In practice, the\ndetector response depends on a number of nuisance parameters that can be\nconstrained with data. We propose a new algorithm called Profile OmniFold\n(POF), which works in a similar iterative manner as the OmniFold (OF) algorithm\nwhile being able to simultaneously profile the nuisance parameters. We\nillustrate the method with a Gaussian example as a proof of concept\nhighlighting its promising capabilities.",
        "updated": "2024-09-16 15:52:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10421v1"
    },
    {
        "title": "Towards Explainable Automated Data Quality Enhancement without Domain Knowledge",
        "authors": "Djibril Sarr",
        "links": "http://arxiv.org/abs/2409.10139v1",
        "entry_id": "http://arxiv.org/abs/2409.10139v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10139v1",
        "summary": "In the era of big data, ensuring the quality of datasets has become\nincreasingly crucial across various domains. We propose a comprehensive\nframework designed to automatically assess and rectify data quality issues in\nany given dataset, regardless of its specific content, focusing on both textual\nand numerical data. Our primary objective is to address three fundamental types\nof defects: absence, redundancy, and incoherence. At the heart of our approach\nlies a rigorous demand for both explainability and interpretability, ensuring\nthat the rationale behind the identification and correction of data anomalies\nis transparent and understandable. To achieve this, we adopt a hybrid approach\nthat integrates statistical methods with machine learning algorithms. Indeed,\nby leveraging statistical techniques alongside machine learning, we strike a\nbalance between accuracy and explainability, enabling users to trust and\ncomprehend the assessment process. Acknowledging the challenges associated with\nautomating the data quality assessment process, particularly in terms of time\nefficiency and accuracy, we adopt a pragmatic strategy, employing\nresource-intensive algorithms only when necessary, while favoring simpler, more\nefficient solutions whenever possible. Through a practical analysis conducted\non a publicly provided dataset, we illustrate the challenges that arise when\ntrying to enhance data quality while keeping explainability. We demonstrate the\neffectiveness of our approach in detecting and rectifying missing values,\nduplicates and typographical errors as well as the challenges remaining to be\naddressed to achieve similar accuracy on statistical outliers and logic errors\nunder the constraints set in our work.",
        "updated": "2024-09-16 10:08:05 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10139v1"
    },
    {
        "title": "Robust Reinforcement Learning with Dynamic Distortion Risk Measures",
        "authors": "Anthony CoacheSebastian Jaimungal",
        "links": "http://arxiv.org/abs/2409.10096v1",
        "entry_id": "http://arxiv.org/abs/2409.10096v1",
        "pdf_url": "http://arxiv.org/pdf/2409.10096v1",
        "summary": "In a reinforcement learning (RL) setting, the agent's optimal strategy\nheavily depends on her risk preferences and the underlying model dynamics of\nthe training environment. These two aspects influence the agent's ability to\nmake well-informed and time-consistent decisions when facing testing\nenvironments. In this work, we devise a framework to solve robust risk-aware RL\nproblems where we simultaneously account for environmental uncertainty and risk\nwith a class of dynamic robust distortion risk measures. Robustness is\nintroduced by considering all models within a Wasserstein ball around a\nreference model. We estimate such dynamic robust risk measures using neural\nnetworks by making use of strictly consistent scoring functions, derive policy\ngradient formulae using the quantile representation of distortion risk\nmeasures, and construct an actor-critic algorithm to solve this class of robust\nrisk-aware RL problems. We demonstrate the performance of our algorithm on a\nportfolio allocation example.",
        "updated": "2024-09-16 08:54:59 UTC",
        "interpretation": "解释内容未找到",
        "id": "2409.10096v1"
    }
]