SimInversion: A Simple Framework for
Inversion-Based Text-to-Image Editing
QiQian1∗ HaiyangXu2 MingYan2 JuhuaHu3
1AlibabaGroup,Bellevue,WA98004,USA
2AlibabaGroup,Hangzhou,China
3SchoolofEngineeringandTechnology,
UniversityofWashington,Tacoma,WA98402,USA
{qi.qian, shuofeng.xhy, ym119608}@alibaba-inc.com, juhuah@uw.edu
Abstract
Diffusionmodelsdemonstrateimpressiveimagegenerationperformancewithtext
guidance. Inspiredbythelearningprocessofdiffusion, existingimagescanbe
editedaccordingtotextbyDDIMinversion. However,thevanillaDDIMinversion
isnotoptimizedforclassifier-freeguidanceandtheaccumulatederrorwillresult
intheundesiredperformance. Whilemanyalgorithmsaredevelopedtoimprove
the framework of DDIM inversion for editing, in this work, we investigate the
approximationerrorinDDIMinversionandproposetodisentangletheguidance
scale for the source and target branches to reduce the error while keeping the
original framework. Moreover, a better guidance scale (i.e., 0.5) than default
settingscanbederivedtheoretically. ExperimentsonPIE-Benchshowthatour
proposalcanimprovetheperformanceofDDIMinversiondramaticallywithout
sacrificingefficiency.
1 Introduction
Diffusionmodelswitnessthetremendoussuccessofimagegeneration[5,11]. Toobtainasynthetic
image,thosemethodsfirstsamplearandomnoisefromtheGaussiandistributionandthenalearned
denoisingnetworkwillrefinethesampleiterativelytorecoverahigh-qualityimagefromthenoise.
Moreover,textinformationcanbeincludedasconditionsfordenoisingtoenabletext-guidedimage
generation[6,11].
Duetotheimpressiveperformanceofimagegeneration,text-guidedimageeditinghasattractedmuch
attentionrecently[1,3,4]. Unliketheguidedgenerationtaskthatonlywiththetargettextcondition,
imageeditingaimstoobtainatargetimagefromasourceimagewiththetargetcondition. Intuitively,
imageeditingcanreusethegenerationprocedure. However,theknowledgefromthesourceimage,
e.g.,structure,background,etc. shouldbekeptinthetargetimagewhenediting. Consideringthatthe
imageisgeneratedfromtherandomnoiseindiffusion,thenoisecorrespondingtothesourceimage
canbeappliedtoobtainthetargetimageforknowledgepreservation[4].
However,DDPMsampling[5]indiffusionisastochasticprocessanditishardtoobtaintheoriginal
noisethatgeneratesthesourceimage. Totacklethechallenge,adeterministicDDIMsamplingis
developedtoreservethegenerationprocess[12]. ItsharesthesametrainingobjectiveasDDPMand
caninfertheinitialnoiseforimageswiththemodelpre-trainedbyDDPM.Withthesourcenoise
obtainedbyDDIMinversion,manyimageeditingmethodsaredevelopedtoleveragethegeneration
processindiffusion.
∗Correspondingauthor
Preprint.Underreview.
4202
peS
61
]VC.sc[
1v67401.9042:viXraInversion: "=1 Inversion: "="
$
! ! ! ! ! !
# " ! # " !
Generation: " ="
$ $
!$ !$ !$ !$ !$ !$
# " ! # " !
Generation: "=7.5 Generation: " % =7.5
!% !% !% !% !% !%
# " ! # " !
(a)DDIMinversionforediting[4] (b)SimInversionforediting
Figure1: IllustrationofimageeditingbyDDIMinversionandours. z denotesthesourceimage. zs
0 0
andzt aregeneratedimagesfromthesourceandtargetbranches,respectively.
0
Amongdifferentmethods, thedualbranchframeworkisprevalentduetoitssimpleyeteffective
architecture[2,4,7–10]. Concretely,giventheinitialnoisefromthesourceimage,theframework
consistsofdenoisingprocessesforthesourceimageandtargetimage,respectively. Ateachstep,
the latent state of different branches will be updated with the corresponding conditions and the
informationfromthesourcebranch,e.g.,attentionmap[4],canbeincorporatedintothetargetbranch
topreservethecontentfromthesourceimage. Fig.1(a)illustratestheprocedureofDDIMinversion
forimageediting[4].
Accordingtothearchitectureofthedualbranchframework,researcheffortscanbecategorizedinto
twoaspects:latentstateoptimizationinthesourcebranchandknowledgetransfertothetargetbranch.
First,duetotheapproximationerrorineachstepofDDIMinversion,theaccumulatederrorwill
misleadtheobtainedrandomnoise, whichmakesithardtorecovertheexactsourceimagefrom
the source branch. Many algorithms have been developed to mitigate the challenge. Concretely,
negative-promptinversion[9]andnull-textinversion[10]optimizetheembeddingsofnulltextin
classifier-freeguidancetominimizethegapbetweenlatentstatesfrominversionandgenerationwhile
directinversion[7]directlyprojectsthelatentstatesinthegenerationprocessbacktothoseinthe
inversionprocesstoreducetheapproximationerror. Second,appropriateknowledgefromthesource
branchwillbetransferredtothetargetbranchforediting. Forthetargetbranch,prompt-to-prompt
editing[4]showsthatfusingthecross-attentionmapfromthesourcebranchcanintroducethedesired
knowledgetothetargetbranch,andMasactrl[2]studiestheself-attentionlayerforeffectivetransfer.
Inthiswork,werevisitthevanillaDDIMinversionforthesourcebranch. First,wefindthatthe
approximationerrorinthesourcebranchismainlyfromtheasymmetricguidancescalefromthe
classifier-freeguidance,wheretheinversionprocesshastheguidancescaleas1whilethegeneration
processholdsamuchlargerscaletofocusonthetextconditionasshowninFig.1(a). Tomitigatethe
issuefromtheasymmetricguidancescale,weproposetokeepthesameguidancescaleforinversion
andgenerationinthesourcebranch. Thesymmetricguidancescalehelpsreducetheapproximation
errorinthelatentstatesforthesourceimage.
Moreover,weinvestigatetheselectionofthesymmetricguidancescaleandourtheoreticalanalysis
shows that the approximation error can be further reduced by selecting an appropriate guidance
scalebeyondthedefaultsettings. Byadoptingthesymmetricguidancescaleforthesourcebranch
while keeping the target branch unchanged, our simple framework improves the performance of
vanillaDDIMinversionsignificantly. Fig.1(b)illustratestheproposedmethod. Comparedwith
DDIMinversion,ourmethodonlychangestheweightoftheguidancescalewithoutintroducingany
additionaloperations. Themaincontributionsofthisworkcanbesummarizedasfollows.
• Toimprovethegenerationfidelityofthesourceimage,weproposetohaveasymmetric
guidancescaleforthesourcebranchwhilekeepingthelargeguidancescaleforthetarget
branch. ThemethodonlychangesoneparameterinDDIMinversionwithoutsacrificingthe
simplicityoftheframework.
• We analyze the selection of the guidance scale from the perspective of minimizing the
approximationerror. WhileCorollary2showsthatthedefaultsettingof0or1isagood
choice, Corollary 1 implies that there can be an optimal solution in [0,1], e.g., 0.5 as
suggestedbyourexperiments.
2• Theproposedsimpleinversion(SimInversion)isevaluatedontherecentlyproposeddata
setPIE-Bench[7]. Experimentswithdifferenteditingtypesconfirmthatourmethodcan
improvetheDDIMinversionforimageeditingunderthesameframework.
2 RelatedWork
Whilemanymethodshavebeendevelopedforimageediting[1,2,4,7–10,14],wefocusoninversion-
basedmethodsduetotheirefficiencyandpromisingperformance. Mostinversion-basedmethods
haveadual-branchframeworktopreservetheinformationfromthesourcebranchandedittheimage
inthetargetbranch. Therefore,differentmethodsaredevelopedforthesourcebranch[7–10]and
targetbranch[2,4],respectively.
ForthevanillaDDIMinversionforediting[4],thesourcebranchwillsharethelargeguidancescale
fromthetargetbranch,whichintroducestheadditionalapproximationerrorforrecoveringthesource
imageandresultsinthedegeneratedperformance. Withtheclassifier-freeguidance,thedenoising
networkdependsonatextconditionandanulltextcondition. Therefore,null-textinversion[10]
proposestooptimizetheembeddingsofnulltexttoreducetheerrorfromtheasymmetricguidance
scale. However,theembeddinghastobeoptimizedbylearning,whichistime-consuming. Negative-
promptinversion[9]improvesthelearningprocessofnulltextembeddingsbysettingitasthetext
condition from the source image, which implies a guidance scale of 1 for the source branch. In
thiswork,wekeeptheoriginalnulltextembeddingsbutchangetheguidancescaleforthesource
branch directly. Moreover, our analysis shows that 1 is not the optimal solution for minimizing
theapproximationerrorandtheperformancecanbefacilitatedwithanappropriateguidancescale,
e.g., 0.5. Recently, direct inversion [7] studies an extreme case that projects the latent states of
thegenerationprocesstothosefromtheinversionprocessforthesourcebranchtoeliminatethe
accumulated errors from the iterative steps. While this method demonstrates better performance
than[10]and[9],itrequiresanadditionalDDIMforwardpassforprojection,whichincreasesthe
inferencetime. Moreover,theprojectionoperatorinterruptsthegenerationprocessofthesource
branch,whichmaydegeneratetheeditingperformance. Onthecontrary,ourmethodkeepsthesimple
framework of the DDIM inversion and shows that the approximation error can be minimized by
obtaininganappropriateguidancescaleforthesourcebranch. Notethatsomework(e.g.,[14])tries
toeliminateapproximationerrorwithamorecomplexframeworkthatmayreducetheeditabilityas
shownin[7]. Therefore,onlymethodssharingasimilarframeworkwillbecomparedintheempirical
study.
3 SimpleInversion
Beforeintroducingourmethod,wewillbrieflyreviewDDIMinversioninthenextsubsection.
3.1 DDIMInversionforImageEditing
Diffusionmodelsproposetogenerateanimagefromarandomsamplednoisebyaseriesofdenoising
steps. Concretely, given the noise z , an image can be obtained iteratively with t from T to 1
T
accordingto
(cid:114) (cid:115) (cid:114)
α √ 1 1
z = t−1z + α ( −1− −1)ϵ (z ,t) (1)
t−1 α t t−1 α α θ t
t t−1 t
wherez denotesthegeneratedimageoritscorrespondinglatentforthedecoder. ϵ (z ,t)isalearned
0 θ t
modeltopredictthenoiseatt-thiteration,whereatextconditionC canbeincludedforclassifier-free
guidance[6]asϵ (z ,t,C)oranulltextconditionasϵ (z ,t,∅). {α }isasequenceofpredefined
θ t θ t t
constantsfordenoising. TheprocessisknownasDDIMsampling[12], whichisadeterministic
samplingbutsharesthesametrainingobjectiveasDDPM[5].
GivenasourceimagezsanditscorrespondingtextconditionC (e.g.,caption),imageeditingwith
0 s
textguidanceaimstoobtainanewimagezt withthetargettextconditionC . AccordingtoEqn.1,
0 t
thetargetimagewillbeobtainedfromarandomnoisezt. Topreservetheknowledgefromthesource
T
image,therandomnoisezs thatgeneratesthesourceimagewillbeappliedaszt =zs forimage
T T T
editing.
3However,theinitialnoisezs cannotbeinferredfromEqn.1withtheimagezs. Toillustratetheissue,
T 0
werearrangethetermsinEqn.1andhave
(cid:114) α √ (cid:114) 1 (cid:115) 1
z = t z + α ( −1− −1)ϵ (z ,t) (2)
t α t−1 t α α θ t
t−1 t t−1
wheretheestimationofz dependsonthepredictionfromitselfϵ (z ,t). Toapproximatethereverse
t θ t
ofthegenerationprocess,DDIMinversion[12]considersreplacingz byz fordenoisingandthe
t t−1
processbecomes
(cid:114) α √ (cid:114) 1 (cid:115) 1
z = t z + α ( −1− −1)ϵ (z ,t) (3)
t α t−1 t α α θ t−1
t−1 t t−1
whichhelpsobtaintheinitialnoisezs forediting. Withzs,manyexistingmethodsapplythedual
T T
branchframeworkforediting[4,7,9,10],whereonebranchisforrecoveringthesourceimagewith
C andtheotheristoencodethetargetinformationwithC . Byfusingthegenerationprocessesof
s t
thesebranches,thesourceimagecanbeeditedaccordingtothetargettextcondition.
3.2 ApproximationErrorinDualBranchImageEditing
Since the generation performance heavily depends on the inversion process, we will investigate
theapproximationerrorinDDIMinversiontodemonstrateourmotivation. InEqn.3,ϵ (z ,t)is
θ t
approximatedbyϵ (z ,t)withtheassumptionthatz isclosetoz in[12]. Toanalyzetheerror,
θ t−1 t−1 t
weapplytheTaylorexpansionforvector-valuedfunctiononz andrewritethedenoisingnetwork
t−1
onz as
t
h(ϵ (z ,t))≈h(ϵ (z ,t))+J (z )h(z −z )+o(∥h(z −z )∥ ) (4)
θ t θ t−1 ϵ t−1 t t−1 t t−1 2
whereJ (z )istheJacobianmatrixofϵonz . hisareshapeoperatorthatconvertsthetensorz
ϵ t−1 t−1
toavector. Then,theapproximationerrorcanbedepictedinthefollowingproposition. Alldetailed
proofofthisworkcanbefoundintheappendix.
Proposition1. Assumingthatthegradientofϵonz isboundedas∥J (z )∥ ≤c,wehave
t−1 ϵ t−1 F
∥h(ϵ (z ,t))−h(ϵ (z ,t))∥ ≤O(∥h(z −z )∥ ) (5)
θ t θ t−1 2 t t−1 2
According to Proposition 1, when ∥h(z −z )∥ is sufficiently small, the approximation error
t t−1 2
δ =∥h(ϵ (z ,t))−h(ϵ (z ,t))∥ becomesnegligible,whichisconsistencywiththeobservation
θ t θ t−1 2
in[12].
However,toimprovethesamplequalitywiththetextcondition,adifferentdenoisingstepisadopted
forgeneration,whichamplifiestheerror. Concretely,thecombinedpredictionisappliedforclassifier-
freeguidance[6]
ϵ′(z ,t,w)=wϵ(z ,t,C)+(1−w)ϵ(z ,t,∅) (6)
t t t
wherew istheguidancescaleandw > 1istoemphasizethetextconditionC. Theasymmetric
processforimageeditingwithvanillaDDIMinversionisillustratedinFig.1(a).
3.3 SimpleInversionwithSymmetricGuidanceScale
InDDIMinversion,boththesourcebranchandtargetbranchsharethesamewforgeneration. While
thetargetbranchisforeditingthatfocusesonthesamplequalityoffollowingthetextprompt,the
sourcebranchistopreservetheinformationfromthesourceimageandthesymmetricguidancescale
isessentialforreducingtheapproximationerrorasinthefollowingproposition.
Proposition2. Letw andw denotetheguidancescalefortheinversionandgenerationprocess,
i g
respectively. Then,withEqn.2,thesourceimagecanberecoveredperfectlywhenw =w .
i g
Therefore, we propose to disentangle the guidance scale between dual branches and adopt the
symmetricguidancescaleforthesourcebranch.
First,tokeeptheeditability,thelargew forthetargetbranchremainsthesameforgeneration.Unlike
t
DDIMinversionwherew isalsoappliedforthesourcebranch,wehaveadifferentw instead.
t s
4Algorithm1SimpleInversionforImageEditing(SimInversion)
1: Input: sourceimagez 0s,sourcepromptC s,targetpromptC t,w s,w t
2: Obtainz T withw sbyDDIMinversioninEqn.3
3: fort=T,...,1do
4: Obtainz ts −1byw sandC s//DDIMInversion: Obtainz ts −1byw tandC s
5: Obtainz tt −1byw tandC t
6: Editzt byzs withanyexistingeditingmethods
t−1 t−1
7: endfor
8: return zt
0
Consideringthatthesourcebranchisforknowledgepreservation,wehavethesamew intheinversion
s
andgenerationforthesourcebranchtoeliminatetheapproximationerrorfromtheasymmetricprocess
assuggestedbyProposition2. TheprocessofproposedsimpleinversioncanbefoundinFig.1(b).
Finally,wefindthatthevalueofw canbefurtheroptimizedtominimizetheapproximationerroras
s
follows.
Proposition3. Letx =h(ϵ(z ,t,C)−ϵ(z ,t,C))andx =h(ϵ(z ,t,∅)−ϵ(z ,t,∅)),then
c t t−1 ∅ t t−1
δ(w)=∥h(ϵ′(z ,t,w))−h(ϵ′(z ,t,w))∥ isminimizedwhen
θ t θ t−1 2
w∗ =(x −x )⊤x /∥x −x ∥2 (7)
∅ c ∅ c ∅ 2
Proposition3indicatesthatthereisanoptimalguidancescalethatcanminimizetheapproximation
error. Moreover,itsscalecanbefurtherdemonstratedinthefollowingCorollary.
Corollary1. WithnotationsinProposition2,ifassumingtheapproximationerrorisindependent
betweentextconditionandnulltextconditionasx⊤x =0,wehave|w∗|≤1.
c ∅
Corollary1showsthepossiblerangefortheoptimalw ,butitisstillchallengingtoobtaintheresult
s
withoutϵ(z ,t,C)andϵ(z ,t,∅). Tosetanapplicableweight,weinvestigatetheupper-boundofthe
t t
error.
Proposition4. WithnotationsinProposition2,wehave
δ(w)≤|w|∥x ∥ +|1−w|∥x ∥ (8)
c 2 ∅ 2
Proof. Itisdirectlyfromthetriangleinequality.
Sincew ≥0fortextcondition,theupper-boundcanbeminimizedas
Corollary2. Letδ′(w)=|w|∥x ∥ +|1−w|∥x ∥ . Whenw ≥0,wehave
c 2 ∅ 2
δ′(w)≥min{δ′(0),δ′(1)} (9)
Proof. Itisduetothattheδ′(w)isamonotonicfunctionwhenw ∈[0,1]andw ∈[1,∞).
Corollary2demonstratesthattheupper-boundoftheapproximationerrorcanbeminimizedwhen
w =0or1. Whiletheoptimalw∗variesfordifferentimages,{0,1}guaranteestheoverallworst-case
performance,whichisconsistentwiththetrainingprocessofDDPMsamplingwithclassifier-free
guidance[6]. Therefore,wecanempiricallysetw tobe0or1andimplementthesymmetricDDIM
s
inversioninAlg.1. ComparedwiththevanillaDDIMinversion,theonlydifferenceisthesymmetric
generationprocessforthesourcebranchasshowninStep4. SincetheframeworkofDDIMinversion
hasnotbeenchanged,ourproposedsimpleinversion(SimInversion)canbeincorporatedwithexisting
editingmethodstoimprovetheperformanceofDDIMinversion.
4 Experiments
WeconductexperimentsonPIE-Bench[7]toevaluatetheproposedmethod. Thedatasetcontains
700 images from natural and artificial scenes. Each image is associated with one editing type,
and there is a total of 10 different editing types. For a fair comparison, 7 metrics from [7] are
5includedtomeasurethequalityofimageediting. Concretely,theevaluationcompriseseditprompt-
image consistency for the whole image and editing regions [16], structure distance for structure
preservation[13],backgroundpreservationbyPSNR,LPIPS[17],MSEandSSIM[15]. Whileedit
prompt-imageconsistencymeasureseditability, allothermetricsareforknowledgepreservation.
Moredetailscanbefoundin[7]. AllexperimentsofthisworkareimplementedonasingleV100
GPUandtheaverageperformanceoverallimagesisreported.
4.1 QuantitiveComparisononPIE-Bench
Wecomparetheproposedmethodtoexistinginversion-basedmethodsinTable1. Sinceourmethod
istoimprovethesourcebranch,baselinemethodsfocusingonthesameproblemareincluded,i.e.,
Null-Textinversion(NT)[10],Negative-Promptinversion(NP)[9],StyleDiffsuion(SD)[8],Direct
inversion(Direct)[7]andthevanillaDDIMinversion(DDIM).BothNTandSDrequireanadditional
optimization process while others are in a training-free manner. Meanwhile, prompt-to-prompt
editing[4]forthetargetbranchisappliedforallmethodsduetoitssuperiorperformanceoverother
methods[7]. Inaddition,stablediffusionv1.4[11]isadoptedasthediffusionmodelsharedbyall
methods. Thestepsininversionandgenerationaresetto50. Forourmethod,wehave“SimInv-w”
denotingthedifferentguidancescalesofw ,andw isfixedas7.5. Finally,“SimInv∗”selectsthe
s t
betterperformancebetween“SimInv-0”and“SimInv-1”foreachimage.
Table1: ComparisiononPIE-Benchwith7metrics. Allmethodshaveprompt-to-prompt[4]for
editingthetargetbranch.“Opt”denotestheadditionaloptimizationprocess,whichistime-consuming.
Resultsofbaselinemethodsarereportedfrom[7]. Thebestperformanceisinbold.
Editability Preservation
Methods Opt CLIPSimilariy Structure BackgroundPreservation
Whole↑ Edited↑ Distance ↓ PSNR↑ LPIPS ↓ MSE ↓ SSIM ↑
10−3 10−3 10−4 10−2
DDIM 25.01 22.44 69.43 17.87 208.80 219.88 71.14
NT ✓ 24.75 21.86 13.44 27.03 60.67 35.86 84.11
SD ✓ 24.78 21.72 11.65 26.05 66.10 38.63 83.42
NP 24.61 21.87 16.17 26.21 69.01 39.73 83.40
Direct 25.02 22.10 11.65 27.22 54.55 32.86 84.76
SimInv-0 24.90 22.19 20.00 24.93 84.68 50.15 81.99
SimInv-0.5 25.18 22.20 15.75 25.89 70.23 40.94 83.42
SimInv-1 25.20 22.21 16.05 25.75 74.29 43.08 83.07
SimInv∗ 25.67 22.80 14.76 26.04 69.83 40.27 83.51
First,wecanfindthatbydisentanglingtheguidancescaleforthesourcebranchandtargetbranch,
ourmethodimprovesDDIMonmetricsforstructureandbackgroundpreservationbyalargemargin.
Itisbecauseasymmetricguidancescaleforthesourcebranchhaslessapproximationerrorthan
the asymmetric guidance scale, which helps preserve the knowledge from the source image as
in Proposition2. With thedecoupled guidancescale, the proposed methodreduces thestructure
distanceby78.7%,whichshowsthepotentialofthesimpleframeworkofDDIMinversion. Second,
SimInversionachievesthebesteditconsistencyresultmeasuredbyCLIPsimilarity. Itimpliesthatthe
imageobtainedfromourmethodismoreconsistentwiththetargettextconditionthanothermethods.
Sincetext-guidedimagegenerationhasbeenstudiedextensively,theunchangedtargetbranchinour
frameworkhelpsunleashthepowerofthepre-trainedimagegenerationmodel. Whencomparing
ourproposalwithdifferentsourceguidancescales,weobservethatSimInv-1outperformsSimInv-0
onallmetrics. Thebinaryguidancescaleselectsdifferenttextconditionsfordenoising. Thebetter
performanceofSimInv-1showsthatthetextconditioncanbemorehelpfulthanthenulltextcondition
inreducingtheapproximationerrorininversion. However,ifselectingthebetterperformancefrom
SimInversionwithw ∈{0,1},theperformanceofSimInv∗ canbefurtherimproved. Concretely,
s
thewholeimageeditconsistencyincreasesby0.47whilethestructuredistancedecreasesby1.29.
Thisphenomenondemonstratesthatcounterintuitively,w = 1isnotalwaysthebestoptionand
s
w =0canbemoreappropriateforsomecasesasshowninFig.6. Theresultfurtherconfirmsour
s
analysisinCorollary2. Finally,whensettingw =0.5,thepreservationperformanceisconsistently
s
improvedover0or1. ThisphenomenonverifiesouranalysisinCorollary1andalsosuggestsanew
defaultvalueforinversion-basedimageeditingmethods. Experimentswithothereditingmethods
canbefoundintheappendix.
64.2 QualitativeComparison
Afterthequantitiveevaluation, weincludetheeditedimagesforaqualitativecomparisoninthis
subsection. ConsideringthatPIE-Benchcontains10differenteditingtypes,2examplesareillustrated
foreacheditingtypeandresultsaresummarizedinFig.2-13.WehaveFig.2-5inthemainmanuscript
whileothersareintheappendix. Besidestheinversion-basedmethods,wealsoincludealearning-
basedmethodInstruct-P2P[1]thatlearnsadiffusionmodelwithtrainingdataobtainedfrom[4]in
thecomparison.
a yellowbird with a red beak sitting on a branch → A crochetbird with a red beak sitting on a branch
A woman sitting in a living room → A watercolor painting of a woman sitting in a living room
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure 2: Illustration of image editing for random editing. The difference is highlighted by red
boundingboxes.
An illustration of a catsitting on top of a rock → An illustration of a bearsitting on top of a rock
A catsitting next to a mirror → A tigersitting next to a mirror
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure3: Illustrationofimageeditingforchangingobject.
A digital art of a brown hair woman → A digital art of a brown hair woman with flying butterfly
A man sitting in the grass → A man sitting in the grass with rocks
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure4: Illustrationofimageeditingforaddingobject.
First,withthesimpleinversionframework,ourmethodisstilleffectiveforediting. Weobservethat
SimInversion can successfully tailor the source image according to the target text prompt for all
editingtypes. Moreover,ourmethodcancapturedetailsthatareignoredbyexistingmethods. For
example,SimInversionpreservestheeyesofthebirdandtheshapeofthehandinFig.2whiledirect
7A bee flies over a flowering tree branch → A flowering tree branch
A blue living room with a blue couch and a blue painting → A blue living room with a blue couch
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure 5: Illustration of image editing for deleting object. The difference is highlighted by red
boundingboxes.
inversionmissesthosedetails. Finally,Instruct-P2Pcanobtainthetargetimagethatisconsistent
withthetargettextconditionbutthedetailsfromthesourceimagemaybelost. Onthecontrary,
allinversion-basedmethodscanpreservethestructureofthesourceimagewell. Itimpliesthatthe
inversion-basedimageeditingmethodcanachieveabettertrade-offbetweenknowledgepreservation
andeditability.
4.3 AblationStudy
4.3.1 Effectofw
s
Whileweonlyhavew ={0,0.5,1}forthemaincomparison,wevaryw in{0,0.2,0.5,0.8,1,2}
s s
andreporttheperformanceinTable2.
Table2: Comparisionwithdifferentw forSimInversiononPIE-Benchwith7metrics. SimInv∗
s
consistsofthebestperformancefromw ∈{0,0.2,0.5,0.8,1,2}. Thebestperformanceexcluding
s
SimInv∗isinbold.
CLIPSimilariy Structure BackgroundPreservation
Methods
Whole↑ Edited↑ Distance ↓ PSNR↑ LPIPS ↓ MSE ↓ SSIM ↑
10−3 10−3 10−4 10−2
SimInv-0 24.90 22.19 20.00 24.93 84.68 50.15 81.99
SimInv-0.2 25.06 22.21 17.55 25.47 76.46 44.51 82.79
SimInv-0.5 25.18 22.20 15.75 25.89 70.23 40.94 83.42
SimInv-0.8 25.17 22.21 15.66 25.88 71.58 41.50 83.30
SimInv-1 25.20 22.21 16.05 25.75 74.29 43.08 83.07
SimInv-2 24.80 22.15 20.52 24.88 87.16 53.15 81.61
First,whenw ∈ [0,1],thepreservationperformanceofSimInversionsurpassesDDIMinversion
s
withaclearmargin. AccordingtoouranalysisinCorollary1,theapproximationerrorcanbesmall
intheappropriaterangewiththemildassumption. Second,whiletheoptimalw variesondifferent
s
metrics,w =0.5demonstratesaconsistentlygoodperformancewithallmetrics,whichisconsistent
s
withpreviousobservations. Comparedwithw ≤1,w =2performsmuchworse,especiallyfor
s s
thepreservation. Whiletheoptimalw isunbounded,theupper-boundoftheapproximationerror
s
canbeoptimizedby0,1asinCorollary2,whichguaranteestheworst-caseperformance.
To further illustrate the influence of w on reconstruction, Fig. 6 shows two images edited with
s
differentw andtheapproximationerrorismeasuredbyδ′′ =∥h(zs−zˆs)∥ ,wherezsdenotesthe
s 0 0 2 0
latentstateofthesourceimageafterencodingandzˆsistheoutputgeneratedfromthesourcebranch.
0
Forthefirstimageaboutaperson,w =0canrecoverthesourceimagewithasmallapproximation
s
error. On the contrary, w = 1 fails to capture the source image and the approximation error is
s
morethantwotimesthatwith0. However,w =0.2achievesthebestreconstructionresult,which
s
confirmsouranalysis. Forthesecondimageaboutthecat,w =1outperformsw =0whilethebest
s s
performanceisfrom0.8. Meanwhile,w =0.5isclosetotheoptimalresultindifferentscenarios,
s
whichconfirmsouranalysis.
8A drawing of a manwith blue eyes→A drawing of a robotwith blue eyes
source image reconstruction target image
𝑤 =0, 𝛿′′=15.24 𝑤 =0.2, 𝛿′′=14.87
! !
𝑤 =0.5, 𝛿′′=15.18 𝑤 =0.8, 𝛿′′=19.36 𝑤 =1, 𝛿′′=41.56
! ! !
Cat with yellow eyes→Cat with greeneyes
𝑤 =0, 𝛿′′=8.20 𝑤 =0.2, 𝛿′′=6.14
! !
𝑤 =0.5, 𝛿′′=4.87 𝑤 =0.8, 𝛿′′=4.72 𝑤 =1, 𝛿′′=5.69
! ! !
Figure6: Illustrationofapproximationerrorδ′′withdifferentw .
s
4.3.2 ComparisonofRunningTime
Besidestheperformance,wecomparetherunningtimeinTable3. First,alltraining-freemethods,
e.g., DDIM, NP, Direct, and ours are much more efficient than the optimization-based methods,
e.g.,NTandSD.Itdemonstratesthatthecostofoptimizationoverwhelmsthatofinversion,andis
expensiveforimageediting. Moreover,DirectinversionrequiresanadditionalDDIMforwardpass,
whichcostsanadditionalrunningtimeof18scomparedwithDDIMinversion. Onthecontrary,when
w ={0,1}asdenotedby“SimInv-binary”,theproposedmethodonlyappliesthedenoisingnetwork
s
withasingletextcondition,whichcansavetherunningtimeonthesourcebranchwhengenerating.
Therefore,SimInversionrunsevenfasterthanDDIMinversionwiththebinaryguidancescale. When
afloatguidancescaleisadoptedasintheablationstudyabove,e.g.,w =0.5,ourinversionprocess
s
willinfernoisefromthesourcetextconditionandthenulltextconditionsimultaneouslyandthus
requiresomeextratime. However,theincreaseintherunningtimeisonly4soverDDIMinversion,
whichisstillfasterthanDirectinversion. Thecomparisonshowsthatourmethodcanimprovethe
performanceofDDIMinversionwhilepreservingitsefficiency.
Table3: ComparisionofRunningTimeforeditingasingleimagewithaV100GPU.SDisslower
thanNT[7],whichisnotincludedinthecomparison.
Methods DDIM NT NP Direct SimInv-binary SimInv-float
Runningtime(s) 25 171 25 43 21 29
95 Conclusion
Inthiswork,werevisitDDIMinversionforimageediting. Tominimizetheapproximationerror
forknowledgepreservation,weproposetodisentangletheguidancescaleforthesourceandtarget
generation branches and keep a symmetric guidance scale for the source branch. Moreover, our
analysisshowsthatthereexistsanoptimalguidancescaleforthesourcebranchwhichcanliein
[0,1]. TheobservationisconsistentwiththesuccessofDDIMinversionwhileindicatingthefuture
directionforimprovementthatobtainstheappropriateguidancescaleforeachimageefficiently.
Limitations This work aims to investigate the approximation error in vanilla DDIM inversion.
While our performance is competitive, it may not be the best compared to methods with other
frameworks.
Broader Impacts Generated images may provide fake information but it can be mitigated by
includingwatermarksingeneratedimages.
References
[1] T.Brooks,A.Holynski,andA.A.Efros. Instructpix2pix:Learningtofollowimageeditinginstructions.
InCVPR,pages18392–18402.IEEE,2023.
[2] M.Cao,X.Wang,Z.Qi,Y.Shan,X.Qie,andY.Zheng. Masactrl: Tuning-freemutualself-attention
controlforconsistentimagesynthesisandediting. InICCV,pages22503–22513.IEEE,2023.
[3] R.Gal,Y.Alaluf,Y.Atzmon,O.Patashnik,A.H.Bermano,G.Chechik,andD.Cohen-Or. Animageis
worthoneword:Personalizingtext-to-imagegenerationusingtextualinversion. InICLR.OpenReview.net,
2023.
[4] A.Hertz,R.Mokady,J.Tenenbaum,K.Aberman,Y.Pritch,andD.Cohen-Or. Prompt-to-promptimage
editingwithcross-attentioncontrol. InICLR.OpenReview.net,2023.
[5] J.Ho,A.Jain,andP.Abbeel. Denoisingdiffusionprobabilisticmodels. InH.Larochelle,M.Ranzato,
R.Hadsell,M.Balcan,andH.Lin,editors,NeurIPS,2020.
[6] J.HoandT.Salimans. Classifier-freediffusionguidance. CoRR,abs/2207.12598,2022.
[7] X.Ju,A.Zeng,Y.Bian,S.Liu,andQ.Xu. Directinversion:Boostingdiffusion-basededitingwith3lines
ofcode. CoRR,abs/2310.01506,2023.
[8] S.Li,J.vandeWeijer,T.Hu,F.S.Khan,Q.Hou,Y.Wang,andJ.Yang.Stylediffusion:Prompt-embedding
inversionfortext-basedediting. CoRR,abs/2303.15649,2023.
[9] D.Miyake,A.Iohara,Y.Saito,andT.Tanaka. Negative-promptinversion:Fastimageinversionforediting
withtext-guideddiffusionmodels. CoRR,abs/2305.16807,2023.
[10] R.Mokady,A.Hertz,K.Aberman,Y.Pritch,andD.Cohen-Or. Null-textinversionforeditingrealimages
usingguideddiffusionmodels. InCVPR,pages6038–6047.IEEE,2023.
[11] R.Rombach,A.Blattmann,D.Lorenz,P.Esser,andB.Ommer. High-resolutionimagesynthesiswith
latentdiffusionmodels. InCVPR,pages10674–10685.IEEE,2022.
[12] J.Song,C.Meng,andS.Ermon. Denoisingdiffusionimplicitmodels. InICLR.OpenReview.net,2021.
[13] N.Tumanyan,O.Bar-Tal,S.Bagon,andT.Dekel. Splicingvitfeaturesforsemanticappearancetransfer.
InCVPR,pages10738–10747.IEEE,2022.
[14] B.Wallace,A.Gokul,andN.Naik. EDICT:exactdiffusioninversionviacoupledtransformations. In
CVPR,pages22532–22541.IEEE,2023.
[15] Z.Wang,A.C.Bovik,H.R.Sheikh,andE.P.Simoncelli. Imagequalityassessment:fromerrorvisibility
tostructuralsimilarity. IEEETrans.ImageProcess.,13(4):600–612,2004.
[16] C. Wu, L. Huang, Q. Zhang, B. Li, L. Ji, F. Yang, G. Sapiro, and N. Duan. GODIVA: generating
open-domainvideosfromnaturaldescriptions. CoRR,abs/2104.14806,2021.
[17] R.Zhang,P.Isola,A.A.Efros,E.Shechtman,andO.Wang. Theunreasonableeffectivenessofdeep
featuresasaperceptualmetric. InCVPR,pages586–595.ComputerVisionFoundation/IEEEComputer
Society,2018.
10A TheoreticalAnalysis
A.1 ProofofProposition1
Proof.
∥h(ϵ (z ,t))−h(ϵ (z ,t))∥ =∥J (z )h(z −z )+o(∥h(z −z )∥ )∥
θ t θ t−1 2 ϵ t−1 t t−1 t t−1 2 2
≤∥J (z )h(z −z )∥ +o(∥h(z −z )∥ )
ϵ t−1 t t−1 2 t t−1 2
≤c∥h(z −z )∥ +o(∥h(z −z )∥ )
t t−1 2 t t−1 2
A.2 ProofofProposition2
Proof. Weconsidertheone-stepprocessforanalysis. Forinversion,wehave
(cid:114) α √ (cid:114) 1 (cid:114) 1
z = 1z + α ( −1− −1)ϵ′(z ,1,w )
1 α 0 1 α α θ 1 i
0 1 0
wherewehaveϵ′(z ,1,w )asEqn.2inlieuofϵ′(z ,1,w )toeliminatetheapproximationerror
θ 1 i θ 0 i
fromnoisepredictionandfocusontheeffectoftheguidancescale. Then,theimagewillberecovered
bygeneration
(cid:114) α √ (cid:114) 1 (cid:114) 1
z′ = 0z + α ( −1− −1)ϵ′(z ,1,w )
0 α 1 0 α α θ 1 g
1 0 1
Thedistancetotheground-truthlatentstatecanbecomputedas
(cid:114) α √ (cid:114) 1 (cid:114) 1
∥z −z′∥=∥z − 0z + α ( −1− −1)ϵ′(z ,1,w )∥
0 0 0 α 1 0 α α θ 1 g
1 0 1
(cid:114) (cid:114)
√ 1 1
= α | −1− −1|∥ϵ′(z ,1,w )−ϵ′(z ,1,w )∥
0 α α θ 1 g θ 1 i
1 0
(cid:114) (cid:114)
√ 1 1
= α | −1− −1|∥(w −w )ϵ(z ,1,C)+(w −w )ϵ(z ,1,∅)∥
0 α α g i 1 i g 1
1 0
Therefore,whenw =w ,thedistanceisminimizedandz′ recoverstheground-truthz . Thesame
g i 0 0
analysiscanbeextendedtotheinversionprocesswithmultiplesteps.
A.3 ProofofProposition3
Proof. WithnotationsinProposition2,wehave
δ(w)=∥w(x −x )+x ∥
c ∅ ∅ 2
Byminimizingδ(w)2andlettingthegradientto0,wehavethedesiredresult.
A.4 ProofofCorollary1
Proof. Thevalueofw∗canbeboundedas
∥w∗∥ =∥(x −x )⊤x ∥ /∥x −x ∥2 ≤∥x ∥ /∥x −x ∥
2 ∅ c ∅ 2 c ∅ 2 ∅ 2 c ∅ 2
Withtheindependentassumption,wehave
(cid:113)
∥w∗∥ ≤∥x ∥ / ∥x ∥2+∥x ∥2 ≤1
2 ∅ 2 c 2 ∅ 2
11Table4: Comparisionwithdifferentw andMasaCtrlforediting. Thebestperformanceisinbold.
s
CLIPSimilariy Structure BackgroundPreservation
Methods
Whole↑ Edited↑ Distance ↓ PSNR↑ LPIPS ↓ MSE ↓ SSIM ↑
10−3 10−3 10−4 10−2
DDIM/SimInv-0 23.96 21.16 28.38 22.17 106.62 86.97 79.67
SimInv-0.2 24.37 21.36 27.23 22.30 101.31 85.55 80.22
SimInv-0.5 24.45 21.38 27.65 22.24 99.39 86.80 80.25
SimInv-0.8 24.40 21.44 28.28 22.09 101.56 90.48 79.94
SimInv-1.0 24.46 21.46 29.64 21.92 105.61 95.05 79.54
B Experiments
B.1 ApplicationonotherEditingMethods
Besidesprompt-to-promptediting[4],wealsoevaluatetheproposedinversionmethodwithMasaC-
trl[2]inTable.4. MasaCtrlappliesnulltextforDDIMinversionandsourceimagegeneration,i.e.,
C =∅,whichyieldsaspecialcaseofw =0inSimInversion. Nevertheless,wevarythevalueof
s
w andcomparetheperformancetothedefaultsetting.
s
AccordingtoTable4,wecanobservethatw =0outperformsw =1forMasaCtrl,whichconfirms
s s
thedefaultselection. However,abetterpreservationandeditingperformancecanbeobtainedby
increasing w . It is because selecting appropriate w can further reduce the approximation error.
s s
Finally, w = 0.5 shows a better trade-off between preservation and editability than w = 0. It
s s
impliesthatthechoiceofw =0.5isapplicablefordifferenteditingmethods.
s
B.2 Effectofw
t
Besidesw ,wealsoevaluatetheeffectofdifferentw inTable5. Evidently,w =7.5balancesthe
s t t
preservationandeditabilitywellwhenw =0.5. Italsoconfirmsthattheselectionofw willnot
s s
influencethatofw andthesetwoguidancescalescanbedisentangled.
t
Table5: Comparisionwithdifferentw forSimInversiononPIE-Benchwith7metrics. w isfixedas
t s
0.5. Thebestperformanceisinbold.
CLIPSimilariy Structure BackgroundPreservation
w
t Whole↑ Edited↑ Distance ↓ PSNR↑ LPIPS ↓ MSE ↓ SSIM ↑
10−3 10−3 10−4 10−2
7 25.10 22.15 15.21 26.00 69.03 39.92 83.55
7.5 25.18 22.20 15.75 25.89 70.23 40.94 83.42
8 25.26 22.26 16.33 25.78 71.46 41.98 83.28
B.3 EffectofDenoisingSteps
Toevaluatetheperformanceofw withdifferentdenoisingsteps,wevarythenumberofstepsin
s
{30,50,100}andsummarizetheresultinTable6. Obviously,theselectionofw isrobusttothe
s
numberofstepsandw =0.5demonstratesthebestperformanceamongvarioussettings.
s
Table6: ComparisiononPIE-Benchwith7metricswithdifferentnumbersofdenoisingsteps.
CLIPSimilariy Structure BackgroundPreservation
Methods #Steps
Whole↑ Edited↑ Distance 10−3↓ PSNR↑ LPIPS 10−3↓ MSE 10−4↓ SSIM 10−2↑
SimInv-0 30 24.68 21.89 20.25 24.83 87.02 50.66 81.72
SimInv-0.5 30 25.01 22.01 15.90 25.82 72.48 40.98 83.16
SimInv-1 30 25.01 22.06 16.57 25.66 75.94 43.06 82.90
SimInv-0 50 24.90 22.19 20.00 24.93 84.68 50.15 81.99
SimInv-0.5 50 25.18 22.20 15.75 25.89 70.23 40.94 83.42
SimInv-1 50 25.20 22.21 16.05 25.75 74.29 43.08 83.07
SimInv-0 100 25.04 22.28 18.53 25.30 78.90 47.40 82.63
SimInv-0.5 100 25.30 22.31 14.96 26.20 65.96 39.32 83.84
SimInv-1 100 25.27 22.30 15.33 26.07 69.43 41.14 83.55
Finally, we investigate the gap between z and z to evaluate the approximation error from
t t−1
replacing z by z in standard DDIM inversion when w = 0.5. The gap is measured by ℓ =
t t−1 s
12E [∥h(z −z )∥ /∥h(z )∥ ]andthenumberofstepsvariesin{10,30,50,100,500}. Fig.7
t t t−1 2 t−1 2
showsthedifferencebetweenz andz withimageediting. Wecanobservethatthegapissmall
t t−1
forapproximationandcanbefurtherreducedwiththeincreaseofdenoisingsteps,whichconfirms
theobservationin[12]. Moreover,#steps=50balancetheefficiencyandeditingperformancewell.
A drawing of a manwith blue eyes→A drawing of a robot with blue eyes
source image target image
,=0.0943 ,=0.035 ,=0.0215 ,=0.0109 ,=0.0022
#steps=10 #steps=30 #steps=50 #steps=100 #steps=500
Figure7: Illustrationofapproximationerrorℓ = E [∥h(z −z )∥ /∥h(z )∥ ]withdifferent
t t t−1 2 t−1 2
numbersofdenoisingsteps.
B.4 QualitativeComparison
A panda bear closehis mouth → A panda bear openhis mouth
A white horse running in the dirt → A white unicorn running in the dirt
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure8: Illustrationofimageeditingforchangingcontent.
White flowers are growingin the grass → White flowers are fadein the grass
A woman in a hat and dress walkingdown a path at sunsets → A woman in a hat and dress runningdown a path at sunset
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure9: Illustrationofimageeditingforchangingpose.
13A blackbird with a yellow beak and yellow feet → A greenbird with a yellow beak and yellow feet
A whitekitten sitting on a leopard print blanket → A yellowkitten sitting on a leopard print blanket
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure10: Illustrationofimageeditingforchangingcolor.
A drawing of a brown bear sitting down → A drawing of a knittedbrown bear toysitting down
Two boys in the water with sticks and buckets → Two woodenboys puppetin the water with sticks and buckets
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure11: Illustrationofimageeditingforchangingmaterial.
A man sitting on a rock with treesin the background → A man sitting on a rock with a city in the background
A colorful cat with splashes of paint on its head → A colorful cat with splashes of paint on its head with a blue background
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure12: Illustrationofimageeditingforchangingbackground.
A lake with mountains in the backgrounds → Oil painting of a lake with mountains in the background
A christmasliving room with fireplace, chair, wreath and tree → Apixel art of christmasliving room with fireplace, chair, wreath and tree
(a) (b) (c) (d) (e) (f) (g) (h)
Source Image DDIM NT NP SD Instruct-P2P DirectInv SimInversion-0.5
Figure13: Illustrationofimageeditingforchangingstyle.
14