DILA: Dictionary Label Attention for Mechanistic
Interpretability in High-dimensional Multi-label
Medical Coding Prediction
JohnWu∗ DavidWu
UniversityofIllinoisUrbana-Champaign VanderbiltUniversity
johnwu3@illinois.edu David.h.wu@vanderbilt.edu
JimengSun
UniversityofIllinoisUrbana-Champaign
jimeng@illinois.edu
Abstract
Predictinghigh-dimensionalorextrememultilabels, suchasinmedicalcoding,
requires both accuracy and interpretability. Existing works often rely on local
interpretability methods, failing to provide comprehensive explanations of the
overallmechanismbehindeachlabelpredictionwithinamultilabelset.Wepropose
amechanisticinterpretabilitymodulecalledDIctionaryLabelAttention(DILA)
thatdisentanglesuninterpretabledenseembeddingsintoasparseembeddingspace,
whereeachnonzeroelement(adictionaryfeature)representsagloballylearned
medicalconcept.Throughhumanevaluations,weshowthatoursparseembeddings
aremorehumanunderstandablethanitsdensecounterpartsbyatleast50percent.
Ourautomateddictionaryfeatureidentificationpipeline,leveraginglargelanguage
models(LLMs),uncoversthousandsoflearnedmedicalconceptsbyexamining
and summarizing the highest activating tokens for each dictionary feature. We
representtherelationshipsbetweendictionaryfeaturesandmedicalcodesthrougha
sparseinterpretablematrix,enhancingthemechanisticandglobalunderstandingof
themodel’spredictionswhilemaintainingcompetitiveperformanceandscalability
withoutextensivehumanannotation.
1 Introduction
High-dimensional or extreme multilabel prediction, where poten-
tially thousands of non-exclusive labels are predicted from high-
dimensionalinputs,posessignificantchallengesininterpretabilityin
high-stakesdomainssuchashealthcare. Duetotheextremerangeof
potentialinputsandoutputsinthesecontexts,expertannotationsare
oftenscarceandcostly,makingtheevaluationofinterpretablemulti-
labelmodelsdifficult. Oneprimeexampleismedicalcoding,which
involvesassigningpotentiallytensofthousandsofInternationalClas-
sificationofDiseases(ICD)codestolengthy,unstructuredclinical
notesforcategorizingdiagnosesandprocedures[19]. Thiscomplex
andtime-consumingtaskrequiresexplicitmedicalexpertise,making Figure 1: Medical coding as
humanannotationexpensive[37]. Whilerecentadvancementsin ahighdimensionalmultilabel
predictiontask.
∗Use footnote for providing further information about author (webpage, alternative address)—not for
acknowledgingfundingagencies.
Preprint.Underreview.
4202
peS
61
]LC.sc[
1v40501.9042:viXrapre-trainedlanguagemodelshavesignificantlyimprovedcodingef-
ficiencyandaccuracybytreatingitasahigh-dimensionalmultilabel
classificationproblem[14,20,52], theopaquenatureoftheseblack-boxmodelsraisesconcerns
abouttheirdecision-makingprocessesandpotentialbiases[18,41]. Toupholdtransparencyand
maintainpatienttrust,thesemodelsmustbecapableofexplainingtheircodepredictions,whichare
crucial for billing, research, and clinical treatment purposes [39, 23]. This is especially the case
wheremisclassificationscandirectlyimpactpatientoutcomes,underscoringtheneedforinterpretable
andtransparentAImodels[23].
Despitesignificantprogressinthepost-hocinterpretationofblack-boxmodels,severalkeyissues
remaininleveragingthemforextrememultilabelprediction,suchasmedicalcoding. Modelagnostic
attributionmethods,suchasSHAP[28,9],whichmeasurethechangeinamodel’soutputgivena
smartperturbationintheinputspace,arecomputationallyinfeasibleforhigh-dimensionalproblems
whereclinicalnotesconsistofthousandsoftokenswithanequallylargemultilabelpredictionspace
[29,8,43,32]. Post-hocmechanisticinterpretabilityreliesonelucidatingthefunctionsofneuron
subsetslikethelabelattentionmechanism,mappingeachtokentoanICDcode,acommonapproach
in medical coding [7, 48, 49, 52, 33]. However, due to the nonlinear projection underlying the
construction of the label attention matrix, this mechanism is largely uninterpretable, hiding the
learnedrelationshipsrequiredtogenerateeachattribution. Furthermore,featureattributionmaps
generatedbysuchattentionmechanismsareoftenincompleteexplanationswhereitsfaithfulness
tothepredictioncanbequestionableandoftenfailtoprovideinsightsintomodelbehaviorbeyond
attribution[42,57,41]. Insummary,theseinterpretabilitymethodsaregenerallylimitedtolocal
interpretability,onlycapableofexplainingpredictionsonaper-examplebasis[5].
Circuit analysis uses causal frameworks to identify interpretable circuits within dense language
models[10,41]. However,mostexistingworkhasfocusedonsimpletaskswherecounterfactuals
existandtheproblem’sdimensionalityisrelativelylow[10].Forproblemswithlargerinputandoutput
spaces,suchashigh-dimensionalmultilabelICDcoding,thesemethodsareoftencomputationally
infeasible,andapproximationmethodsareimperfectevenforsimpletasks[24]. Thus,apersistent
gapexistsbetweenaccuratemodelexplanationsandcomputationalconstraintsforhighdimensional
multilabelpredictions.
Tobridgethisgap,intrinsicallyexplainablemodelshavebeendeveloped. Forinstance,prototype
models generate explanations from neural layers where input samples are directly compared to
prototypicalexamplesofeachlabel[45,30].Whileeffective,thisapproachrequireshumanannotators
to design a sufficiently diverse corpus of exemplary examples for each class. In the ICD coding
space[14],thereareprivacyconcernsrelatedtousingrealpatientdatatoconstructsuchprototypes.
Additionally,intermsofscalability,therearetensofthousandsofICDcodeswithanequallylarge
number of diverse examples of clinical notes and settings [19, 52], making the construction of a
diverseprototypecorpusinfeasible.
Finally,white-boxapproacheshavebeenattemptedusingsparsity,wheretransformermodelsare
regularizedduringtrainingtotransformdataintoamathematicallyinterpretableform[54],effectively
mitigatingpolysemanticityorsuperpositionseeninneurons[15]. However,pre-trainingnewmodels
canbecostly. Toattainsimilarlevelsofperformance,moremodelparametersareneededthantheir
densecounterparts[54]. Fortunately,studieshaveshownthatincreasingsparsityindecision-related
layerssignificantlyenhancestheoverallinterpretabilityofthepredictionprocessbydemonstrating
thatsparsityresultsinneuronsactivatingonlyforspecificdatafeatures[50,47].
Inspiredbytheseresults,weproposeaninterpretableDIctionaryLabelAttention(DILA)module
incorporatingsparsityviadictionarylearning[36,3]. Additionally,toenhancetheinterpretabilityof
thelearnedsparsedictionaryfeatureswithoutneedingexpertannotations,weleveragemedicallarge
languagemodels(LLMs)toautomaticallyinterpretourlearnedsparseabstractions.
WeevaluatethreeaspectsofourapproachDILAandshow:
• Interpretability: The dictionary label attention layer in DILA is more human-interpretable than
its dense counterparts. Learning sparse medical abstractions enables insights into the model’s
decision-makingprocessforhigh-dimensionalmultilabelpredictions,addressingthechallengesof
interpretabilityincomplexdomain-specificscenarios.
• Scalability: Whileimperfect,wedemonstratethatmedicalLLMscanserveascapabledomain-
specific dictionary feature summarizers and annotators. This enables the scalability of deep
2auto-interpretability pipelines, overcoming the limitations of manual annotation and prototype
designinthemedicaldomain,whereexpertknowledgeisscarceandexpensive.
• Performance:Despitetheincorporationofsparsityandinterpretability,DILAmaintainscompetitive
performance with current state-of-the-art black-box baselines on the large cleaned MIMIC-III
dataset[14],demonstratingitseffectivenessinextrememultilabelpredictiontaskslikemedical
coding.
2 RelatedWork
2.1 DictionaryLearning
Muchofourworkwasdirectlyinspiredbytheuseofdictionarylearningtobetterunderstandthe
predictions made by auto-regressive LLMs [3, 11, 55] in a post-hoc manner. However, we note
thatthesparsecodingproblem[58,36]isnotuniquetothelanguagedomainandhasbeenapplied
toimproveinterpretabilityinvariousothermodalitiessuchasvision[54,16,27]andtime-series
[51,46]tasks. Toourknowledge,suchanapproachhasnotbeendirectlyleveragedtoexplaindeep
extrememulti-labelpredictionsettingsbetter,asseenintheautomatedICDcodingtaskwherethe
inputspaceconsistsofthousandsoftokenswithanequallylargepredictionspace.
2.2 InterpretabilityinAutomatedICDCoding
ThereexistsaplethoraofattemptsinmakinginterpretableautomatedICDcodingmethods[52]. For
instance,phrasematching[4]andphraseextractionusingmanuallycuratedknowledgebases[13],
offerinherentinterpretabilitybutfallshortinexpressivepowercomparedtoneuralnetwork-based
approaches.
Ontheotherhand,theprevailinginterpretabilitymethodfordeepneuralmodelsinICDcodingtasks
relyonthelabelattention(LAAT)mechanism[52].Specifically,theLAATmechanismprojectstoken
embeddingsintoalabel-specificattentionspace,whereeachtokenreceivesascoreindicatingits
relevancetoeachICDprediction. Suchattention-basedassociationsbetweentokensandclasseshave
beenemployedinvariousarchitectures,includingconvolutionalmodelslikeCAML[34],recurrent
neural networks [49], and pre-trained language models [20]. While computationally efficient in
highlightingtokenslocallyrelevanttoeachICDprediction,itsnonlinearprojectionspreventdirect
interpretationofthemechanismsbehindeachattributionscore. Furthermore,itsdensepretrained
languagemodel(PLM)embeddingsaredifficulttointerpretduetopolysemanticity[35],hindering
directunderstandingoftheglobalmechanismsbehindeachICDcodeprediction. Otherattempts
havebeenmadethroughpromptinglargelanguagemodels(LLMs)[53]wheretheLLMretrievesthe
evidencebehindeachprediction. However,LLMsareknowntohallucinate[59,21,22],reducing
the faithfulness of their explanations. This discrepancy highlights a persistent tradeoff between
interpretabilityandperformanceinICDcodingtasks.
OurmethodDILA,incomparison,directlyinterpretsanddisentanglesconceptslearnedwithinthe
PLMembeddingspace. Itmapsglobalmedicallyrelevantconceptsintheformofdictionaryfeatures
toeachICDcodewhileretainingthelocalinterpretabilityderivedfromthelabelattentionmechanism.
3 DILA
Overview. DILAconsistsofthreekeycomponents: (1)dictionarylearningtodisentangledense
embeddingsintosparse,interpretabledictionaryfeatures;(2)adictionarylabelattentionmodulethat
utilizesasparse,interpretablematrixcapturingtheglobalrelationshipsbetweendictionaryfeatures
and medical codes to generate each clinical note’s label attention matrix, representing the local
token-coderelationships;and(3)anautomatedinterpretabilityapproachusingmedicalLLMs,as
showninFigure2.
3.1 DictionaryLearning
Dictionarylearningdecomposesvectorsxthatoftenrepresenttokensorwordsintoasparselinear
combinationofbasisvectors. WeformulatethisproblemusingasparseautoencoderwithdensePLM
embeddingsx∈Rd,sparsedictionaryfeatureactivationsf ∈Rm,aswellasencoderanddecoder
weightmatricesW ∈Rd×mandW ∈Rm×dwithcorrespondingbiasunitsb ∈Rm,b ∈Rd:
e d e d
3Figure 2: DILA composes of three steps: First, we disentangle each token embedding into its
dictionaryfeatures. Then,weprojecteachsetofdictionaryfeatureswithourgloballyinterpretable
A togenerateourlocalexplanationA fordownstreammultilabelprediction. Finally,medical
ficd laat
LLMsidentifythelearneddictionaryfeaturetounderstandthelearnedrelationshipsinA .
ficd
x¯ =x−b (1)
d
f =ReLU(W x¯+b ) (2)
e e
xˆ =W f +b (3)
d d
L = 1 (cid:88) ∥x−xˆ∥2+λ ∥f∥ +λ ∥f∥2 (4)
saenc |X| 2 L1 1 L2 2
x∈X
Theλ ∥f∥ andλ ∥f∥2elasticlossterms[60]inEquation(4)enforcesparsityontheencoded
L1 1 L2 2
dictionary feature activations f, ensuring that only specific f ∈ f activate (i.e., are nonzero) for
i
specifictokenembeddingsx. Thissparsityinfluenceseachelementf tobemoreinterpretable,often
i
correspondingtoaspecificmedicalconcept. Togroundtheseinterpretationswithintheembedding
space,wereconstructxusingourdictionaryembeddingsW =[h , h , ... ,h ]T ,allowing
d 0 1 m
anyxtoberepresentedthroughasparselinearcombinationofh asdefinedbyoursparseautoencoder:
i
x≈(cid:80)mf
h .
i i i
Toconstructahumaninterpretabledictionary,wesampletokenembeddingsfromatextcorpusand
sortforthehighestactivatingtokensforf ,calledadictionaryfeature’scontext,astheydescribethe
i
underlyingmeaningofeachf (seeAppendixA.2). Forinstance,instep3ofFigure2,thecontexts
i
ofadictionaryfeaturef allsharethesamethemeoffallsandsubduralhematomas,atypeofhead
i
injury.
3.2 DictionaryLabelAttention
Weproposeasimpler,disentangledversionoflabelattentioncalleddictionarylabelattentionthat
mapstheconceptsrepresentedbyeachofthemdictionaryfeaturesf totheircorrespondingICD
i
codes(Figure2). Givenaclinicalnote’stokenizedPLMembeddingsX ∈Rs×doflengths,we
note
encodethemintodisentangleddictionaryfeaturesF ∈ Rs×m usingasparseautoencoder. We
note
initializethesparseprojectionmatrixA ∈Rm×c,whichmapstherelationshipbetweeneachof
ficd
themdictionaryfeaturesf andcICDcodes,byencodingthetokensineachICDcode’sdescription
i
intotheirrespectivedictionaryfeaturesF(c) ∈ Rl×m,wherelisthedescriptionlength. Wethen
desc
averagepoolthesefeaturesintof(c) ∈Rmandperformthefollowingoperations:
A =(cid:2) f(1), f(2), ... ,f(c)(cid:3) ∈Rm×c (5)
ficd
A =softmax(F A )∈Rs×c (6)
laat note ficd
X =A TX ∈Rc×d (7)
att laat note
4OncethelabelawarerepresentationX iscomputed,itispassedthroughadecisionlayerforthe
att
finalpredictionyˆ ∈Rc.
RelationshiptoDenseLabelAttention. Incontrasttotheoriginallabelattentionmechanismin
[49],wehaveessentiallyreplacedtheoriginalnonlinearprojectionofA =softmax(ZW )where
laat c
Z = tanh(X W )withasinglelinearsparseprojectionmatrixA ,representingeachofthe
note z ficd
cICDcodesasasetofdictionaryfeatures. UnlikeZ,sincef isalwayspositive,everyelement’s
magnitudeinA indicatesthestrengthoftheoverallrelationshipbetweenadictionaryfeaturef
ficd i
andanICDcodeyˆ .
i
Training.Trainingconsistsoftwosteps.First,wetrainasparseautoencoderonalloftheembeddings
generatedbyourPLMwithinthetrainingset. Then,weinitializeourlabelattentionmodule,anddo
end-to-endtrainingusingacombinationofoursparseautoencoderlossdefinedinequation4andthe
binarycrossentropylossfunction. Weuseanadditionalhyperparameterλ topreventL from
saenc saenc
dominatingL ,givingusourfinallossfunctioninequation8.
BCE
L=λ L +L (8)
saenc saenc BCE
3.3 Auto-Interpretability
Onemajorchallengeinourframeworkisthatthesampleddictionarycontextsanditssparsedictionary
feature representations f are unlabeled. Ideally, human expert annotators [3] would inspect the
dictionaryfeatures’highestactivatingcontexts. However,unlikegenerallanguagedisciplines[56],
expertmedicalprofessionalannotatorsarenotasreadilyavailableandoftenlackthetimetoprovide
high-qualityannotationsforeachlearneddictionaryfeature. Anautomatedpipelinetoidentifyand
quantify the quality of such dictionaries is crucial for scalable interpretability, as medical PLMs
learnthousandsofdomain-specificconcepts. Inspiredby[44]’sfeatureidentificationand[2]’sLLM
neuroninterpretabilityexperiments,wedevelopatwo-stageauto-interpretabilitypipelineshownin
Figure2.
Morespecifically,todiscernwhetherornottheLLMcanidentifythedictionaryfeaturefaithfully,we
performanidentificationtestthataskstheLLMtoidentifytherandomlysampledcontextthatdoes
notactivatethedictionaryfeaturerepresentingaspecificmedicalconceptoutoffivetotalcontexts.
IftheLLMiscapableofdiscerningtheoutliercontext,itimpliesitcanunderstandthattheother
contexts all belong to the same underlying medical concept. In practice, we prompt it with only
thehighlightedtokens(red)toavoidinformationcontaminationfromthecontextwindowasthere
can often be neighboring medical concepts that may misdirect the LLM. Once determined to be
identifiable,weprompttheLLMtosummarizethedictionaryfeaturegiventheoriginalcontexts.
4 Experiments
Dataset. Weuseasimilarmedicalcodingdatasetas[34]. Specifically,wetrainandevaluateour
modelontherevised"MIMIC-IIIclean"datasplitsourcedfromareproducibilitystudy[14].
Models. We mainly explore two models, our method DILA, and its nearest dense label attention
comparisonPLM-ICD[20],bothofwhichusethesametextmedicalRoBERTaPLM.Whilewereuse
theweightsprovidedby[14]inourinterpretabilitycomparison,wealsoretraintheirmodelusing
thesametraininghyperparametersusedinDILAtogetamoredirectcomparisoninperformance
inSection4.3aswewereunabletoreplicatethereportedlargebatchsizeof16[14]duetoGPU
limitations. WereportthetraininghyperparametersusedintheAppendix(A.1).
Annotators. Weasktwomedicalexpertsforourhumanevaluations,aclinicallylicensedphysician
andamedicalscientisttraineewithextensiveclinicaltraining. FortheLLM,weuseastate-of-the-
artquantized,medicallyfine-tunedLlama3OpenBioLLM70bmodelinourauto-interpretability
pipeline.
Overview. Weexploretheinterpretability,mechanisticinsights,andperformanceofourproposed
method,DILA,forautomatedICDcoding. Usinghumanevaluations,weassessthehumanunder-
standabilityofitslearneddictionaryfeaturesandtheefficacyoftheauto-interpretabilitypipeline,
anddemonstrateitsabilitytoefficientlyprovidepreciseglobalexplanationsthroughablationstudies,
visualizations, and human predictability experiments. Finally, we evaluate DILA’s performance
comparedtobaselines.
54.1 AutomatedInterpretabilityofDictionaryFeatures
Setup. InFigure2,theinterpretationoftheglobalprojectionmatrixfromstep2requiresidentifying
the underlying abstractions learned for each dictionary feature f with the auto-interpretability
i
pipeline. There are two main components to the auto-interpretability pipeline of DILA, 1) the
identificationofdictionaryfeatures,and2)thesummarizationofthesedictionaryfeaturesgiventheir
sampledcontexttokensfromstep3inFigure2.
Toevaluateourdictionaryfeatureidentificationmethodandquantifytheinterpretabilityorhuman
understandabilityofourtraineddictionaries,weconductamedicalexpertidentificationexperiment
across100randomlysampleddictionaryfeatures,asdescribedinSection3.3. Anexampleofthe
LLMidentificationpromptisshowcasedintheAppendix(A.3.1).
Ashallucinationisalwaysplausible,humanmedicalexpertsareaskedtoevaluatethesummaries
generatedbytheLLMsoftheidentifieddictionaryfeatures. Weaskwhethertheyagreewiththe
originallysampledcontextsandhowconfidenttheyareintheirresponses,from1,beingunsure,to4,
absoluteconfidence.
Baselines. Furthermore,wecompareourdictionaryfeaturestodenseZactivationsfromthelabel
attention mechanism (Section 3.2) in PLM-ICD [20] and a random baseline where contexts are
randomlysampledfromalargemedicaltokencorpusfromthetestset.Werunourautomatedpipeline
acrossallobservedfeatures:6,088activefeaturesinourdictionaryf,768featuresinourdenseZ,and
1,000randomlysampledcontexts. However,sincewefeltrandomcontextsummariesweretrivial,we
onlyaskourannotatorstoevaluatethesummariesgeneratedfrominterpretingthedictionaryfeatures
f anditsdenselabelattentioncounterpartZ.
MedicalExpert1 MedicalExpert2 LLM LLM Avg.Cosine Avg.Jaccard No.ofLLM
(100)↑ (100)↑ (100)↑ (all)↑ Similarity↑ Similarity↑ IdentifiedFeatures↑
Dict.f(DILA) 0.67(+55.8%) 0.69(+64.3%) 0.59(+73.5%) 0.58(+70.6%) 0.77(+30.5%) 0.62(+44.2%) 3,524(+1239.9%)
DenseZ 0.43 0.42 0.34 0.34 0.59 0.43 263
Random 0.23 0.19 0.27 0.19 0.15 0.08 193
Table1: IdentificationtestaccuracycomparinghumanexpertsandLLMsoninterpretingdictionary
features(f),denseembeddings(Z),andrandomcontexts. Theresultsshowthesuperiorperformance
ofhumanexpertsandtheimportanceofsparseembeddingsforinterpretability. Therelativeimprove-
mentofDict. f (DILA)overDenseZisshowninparentheses.
IdentificationofDictionaryFeatures. Table1demonstratesimprovedinterpretabilitybyleveraging
asparseembeddingf overthedenseembeddingZ,withsignificantlymoreinterpretablef features
(3,524)comparedtoZfeatures(263),suggestingover3,000interpretableabstractconceptswere
hiddeninsuperposition[15]. ComparingLLMandhumanresponsesusingavectorsimilaritymetric
revealsthathumanexpertannotationsidentifymoreinterpretablefeaturesandthathumanalignmentof
medicalLLMfeatureidentificationsdeterioratesasinterpretabilitydeclines,suggestingasubstantial
gapbetweendomain-specificannotatorsandmedicalLLMs. Furtherqualitativeexaminationsreveal
that LLMs fail to identify features with intrinsic relationships between contexts not obvious by
language,suchaslinking"banding"andbloodlossinAppendixFigure8. However,giventhevolume
of identified interpretable features and the lack of extensive prompt engineering, the potential to
useLLMsforautomaticallyinterpretingpreviouslyblack-boxmodelsissignificant,dramatically
reducingthenumberofhumanannotationsneededforobviouslyinterpretablefeatures.
Expert1,Agreement↑ Expert2,Agreement↑ Expert1,Confidence↑ Expert2,Confidence↑
Dict.f(DILA) 0.83(+5.1%) 0.92(+12%) 3.85±0.41 3.80±0.45
DenseZ 0.79 0.82 3.79±0.41 3.44±0.75
Table2: HumanevaluationsofLLMsummariesofdictionaryfeatures. Wereportthestandarddevia-
tionsofourconfidencescores. TherelativepercentageimprovementinLLMsummaryagreementof
Dict. f (DILA)overDenseZareshowninparentheses.
QualityofLLMDictionaryFeatureSummarizations. FromTable2,weseethatthemajorityof
thesummariesgeneratedbytheLLMsareinagreementwithourhumanevaluators. Ourqualitative
evaluationsshowthatthecontextsofsummariesrejectedbyourhumanannotatorsforthedictionary
featuresaresubstantiallymorecoherentthantheonesrejectedbytheonesinthedenseneuronsZas
showninAppendixSectionA.4.2. Crucially,manyofthedictionaryfeaturesummariesthatwere
rejected,wererejectedduetotheirlackofspecificityratherthanbeingunrelatedtothedictionary
contextsorhallucinations,allowingustobetterconductmechanisticinterpretabilityexperiments.
64.2 MechanisticInterpretability
RuntimePerformance. Onecrucialutilityofmechanisticinterpretabilityistheabilitytogenerate
efficientinterpretationsofamodel’spredictions,whetherlocallyorglobally. InTable3,weshowthat
usinganoff-the-shelfKernelSHAP[28]interpretertoanalyzethedensePLMembeddingsofasingle
clinicalnoteisextremelycomputationallyexpensive,whencomparedtoitsmechanisticcounterparts,
highlightingitsimpracticaluseinhighdimensionalmultilabelprediction.
Model-agnostic MechanisticInterpretability(DILA)
KernelSHAP[28] ComputingA laat EncodingF note AccessingA ficd
Time↓ 62m10.71s 0.04s 0.03s 0.00s
Table3: Runtimesforinterpretingasingleclinicalnoteusingdifferentmethods. KernelSHAP,a
model-agnosticmethod,isusedtointerpretthehigh-dimensionaltokenembeddingsgeneratedbythe
PLM.TheotherruntimesarefromourDILAmethod,demonstratingtheefficiencyofmechanistic
interpretabilitycomparedtoblack-boxapproaches. AccessingthegloballyinterpretablematrixA
ficd
isvirtuallyinstantaneous.
Setup. ToevaluatetheexplainabilityofourA matrix,wecomparetothecommonlocalattribution
ficd
approach of token-based attention (A ) through an ablation study. For each clinical note, we
laat
identify the highest softmax probability ICD code and ablate the weights corresponding to the
observedactivateddictionaryfeaturesf ,andmeasurethesoftmaxprobabilitydropforthetarget
i
codeandthesumofabsolutechangesforothercodes.
Baselines. Tocompareagainstalternativelocalinterpretabilityapproaches,weidentifythemost
relevanttokensforthehighest-probabilityICDcodeusingA andperturbthePLMembeddings
laat
byablating,noising,orreplacingthesetokenswithmedicallyirrelevantones,measuringthesame
downstreameffects.
AficdWeightAblation AlaatTokenAblation AlaatTokenNoising AlaatTokenReplacement
TopICD↑ 0.954±0.1 0.953±0.1 0.204±0.4 0.948±0.2
|∆|OtherICD↓ 0±0 21.7±123.3 372.8±281.4 9.9±5.0
Table4: Ablatingtheclass-specificweightsinA doesnotaffectotherclassescomparedtorelevant
ficd
tokenperturbations,indicatingitsextremelypreciseexplanationofdownstreamcodepredictions.
Global vs. Local Explanations. Local explanation methods can identify relevant tokens for a
model’spredictionsbutfailtoisolatethemechanismsbehindindividualICDcodepredictionsin
extrememultilabelsettings,wheremedically-specifictokensoftenrelatetomultipleICDcodes. Our
sparseweightmatrixA overcomesthislimitationbydirectlymappingencodeddictionaryfeatures
ficd
f toeachICDcodeprediction. Throughweightablation,wecanpinpointthespecificmechanisms
drivingeachcode’sprediction. Table4demonstratesthatablatingrelevantweightsinourglobal
A matrixdoesnotaffectthepredictionofotherICDcodes,unliketokenablation,whichimpacts
ficd
multiplecodesduetotokens’relationshipswithvariouscodes.
Visualization. Anothercrucialutilityiswearenowabletovisualizetheoverallmedicalconcepts
thatthemodelhaslearnedtoassociatewitheachoftheseveralthousandICDcodes. Forinstance,we
cansummarizethatthemodelhaslearnedthathypoglycemia,obesity,pancreaticabnormalities,and
diabetesmellitusishighlypredictiveofdiabetes-relatedICDcodesinFigure3. Furthermore,we
canevenvisualizethemodel’sunderstandingofdifferentmedicalconditionsinspacebyplottingthe
UMAPofA asshowninFigure4.
ficd
Setup. ToassesstheinterpretabilityoftheglobalprojectionmatrixA ,weconductapredictability
ficd
experiment. Our medical experts are asked to choose the set of codes that best match a given
dictionary feature’s LLM summary and its sampled contexts from two sets of codes. They also
areaskedoftheirconfidenceintheirchoices. Clearandeasilyunderstandabledictionaryfeatures
shouldrepresentdistinctmedicalconceptswithobviousassociatedmedicalcodes. Theexperimentis
conductedfor100randomlysampleddictionaryfeaturesandrepeatedusingourmedicalLLMto
interpretalargerportionofthematrix.
7Figure3: Top5DictionaryFeaturesforDiabetes-relatedICDCodes.
Figure4: UMAPofA withrespecttoallmedicalcodes. Weobserveclustersofmedicalcodes
ficd
withrelativedistancesthatareintuitive. Forinstance,neuropathyisacommonconditionassociated
withdiabetes,andvehicleaccidentsaremorecloselylinkedtoboneandspinalfractures.
Baseline. Foradirectcomparison,weperformthesameexperimentusingthedenseW matrixwith
c
theidentifiedfeaturesofZfromSection4.1. However,asaquickcaveat,duetothelargernumberof
identifiedabstractionsoff comparedtoZ,A isinherentlymoreinformative. Randomguessingin
ficd
thisexperimentwouldyielda50%accuracy,asitiseffectivelyabinaryclassificationtask.
MedicalExpert1 MedicalExpert2 MedicalExpert1 MedicalExpert2 LLMMatching LLMMatching
MatchingAccuracy(100)↑ MatchingAccuracy(100)↑ Confidence(100)↑ Confidence(100)↑ Accuracy(100)↑ Accuracy(all)↑
WAfi
ccd
0.73( 0+ .61 52.3%) 0.69( 0+ .61 05.0%) 33 .2.4 01 ±± 00 .. 56
7
22 .6.8 27 ±± 01 .. 80
9
0.65 0(+ .66 1.6%) 0.59 0(+ .59 4.3%)
Table5: HumanPredictabilityExperimentwithA . Ourmedicalexpertsmoreconfidentlyand
ficd
accurately match the corresponding set of ICD codes given a dictionary feature. The relative
improvementofA overW isshowninparentheses.
ficd c
HumanEvaluations. FromTable5,weobservethatA ismoreinterpretablethanW duetoa
ficd c
largerportionofcodesbeingmatchedwhenusingfeaturesfromf comparedtoZ,butwithsome
interesting caveats that make human predictability challenging. Shown in Appendix Figure 16,
manyoftheincorrectmatchingsbyhumanswereduetoincorrectlylearnedassociationsbetween
theidentifiedabstractdictionaryfeaturesanditscorrespondingtop5medicalcodesdespitethef
8generallybeinginterpretablethemselves,suggestingthatA mayprovetobeusefulinidentifying
ficd
incorrectlylearnedfeaturepredictions.
4.3 Performance
Baselines. Thetrade-offbetweeninterpretabilityandperformanceduetoreducedexpressivepoweris
acriticalconcernwhenintegratingsparselayersandmoreinterpretablemodules[31,40]. However,
ourfindingssuggestthatthistrade-offmaynotpersist. Table6comparestheperformanceofvarious
automatedICDcodingmethodssuchasconvolutionalneuralnetworks,recurrentneuralnetworks,
andPLMsforMIMIC-IIIclean[14],includingourownreproductionsofPLM-ICD(*)asabaseline.
CNN Bi-GRU CAML[34] MultiResCNN[26] LAAT[49] PLM-ICD[20] PLM-ICD* DILA*(ours)
MicroF1↑ 48.0±0.3 49.7±0.4 55.4±0.1 56.4±0.2 57.8±0.2 59.6±0.2 54.6±0.1 54.9±0.2
MacroF1↑ 9.9±0.4 12.2±0.2 20.4±0.3 22.9±0.6 22.6±0.6 26.6±0.8 26.5±0.3 27.2±0.4
MicroAUC-ROC↑ 97.1±0.0 97.8±0.1 98.2±0.0 98.5±0.0 98.6±0.1 98.9±0.0 97.7±0.0 97.6±0.0
MacroAUC-ROC↑ 88.1±0.2 91.1±0.2 91.4±0.2 93.1±0.3 94.0±0.3 95.9±0.1 92.5±0.0 91.7±0.0
Table6: PerformancecomparisonofautomatedICDcodingmethodsonMIMIC-IIIcleandataset
[14]. * indicates our training or reproduction. The average scores are reported along with their
standarddeviations.
Performance. Ourmodel,DILA,achievesthehighestaverageMacroF1scoreandslightlylower
MicroF1scorecomparedtotherelevantbaselines,indicatingbetterperformanceonrarercodesbut
worseperformanceonedge-casesofcommonICDcodes. Notably,ourreproductionoftheprevious
state-of-the-artbaseline,PLM-ICD,yieldslowerperformancethanreported,possiblyduetomemory
restrictionslimitingbatchsizes. AsbatchsizedirectlyaffectstheoptimalperformanceofICDcoding
models[14],DILAmaystillattainbetterperformancewithlargerbatchsizes.
5 DiscussionandConclusion
Debugging. Globalinterpretabilityallowsforquick
identification of incorrectly learned mappings be- Pre-Edit PostEdit
tweenmedicalconceptsandcodesbyinspectingthe
sparsemappingsinA . Wehaveobservednumer- FalsePositives 164 158
ousimproperlylearnef dic ad ssociations,asvisualizedin FalseNegatives 66 68
Figures17,19,and18intheAppendix. Forexample,
Table7: ResultsofcausaleditsofA for
thecodefor"Athlete’sFoot"isincorrectlyassociated ficd
ICD99.20"InjectionofPlateletInhibitors".
withOvariancancerinFigure19,potentiallyleading
tofalsepositives. Inacasestudy, weattemptedto
remedy the commonly false positive code "Injection of Platelet Inhibitors" by visualizing its top
20 most common abstract dictionary features in Figure 20, revealing incorrect associations like
dictionaryfeature4443"TrisomyDisorders"(seeSectionA.6.4). Ablatingtherelevantweightsin
A decreasedfalsepositivesrelatedtotheincorrectdictionaryfeaturesbutslightlyincreasedfalse
ficd
negatives(Table7),suggestingtheneedtochangeotherweightstobetterpredicttruecases,and
highlightingthecomplexitiesofdebugging. Aninterpretableautomatedprocedurefordebugging
incorrectly classified ICD codes is an important direction, as over 40% of ICD codes are never
predictedcorrectly[14].
Improving LLM Annotations. Our current automatic interpretability pipeline with LLMs only
uses zero-shot prompting. However, numerous works have improved LLM-assisted annotations
[17]andgenerationfaithfulnesssuchasretrievalaugmentedgeneration[25]. Exploringtheseideas
couldbridgethegapbetweencurrentstate-of-the-artdomain-specificLLMsandmedicalexpertsfor
dictionaryfeatureannotationtasks.
UnidentifiableDictionaryFeatures.Somehighlyrelevantdictionaryfeaturesmaynotbeidentifiable
byhumansorLLMs,asshownintheAppendix(Figure18).Weinvestigatedafewandshowcasetheir
sampledcontextsintheAppendix(Table9). Unidentifiedfeaturesoftenresultfromalackofhighly
activatedcontextswithinourtextcorpusoralackofanexplicitcoherentmedicaltheme,suggesting
the need for larger sampled corpuses in our dictionary construction and potential limitations in
our dictionary learning formulation. Other sparse formulations should be explored for optimal
interpretabledesign[38].
9Ultimately,ourproposeddictionarylabelattention(DILA)moduletakesasteptowardsaddressing
theneedforinterpretabilityinhigh-dimensionalmultilabelpredictiontasks,particularlyinmedical
coding. BydisentanglingdenseembeddingsintoasparsespaceandleveragingLLMsforautomated
dictionaryfeatureidentification,DILAaimstouncovergloballylearnedmedicalconcepts,provide
comprehensiveexplanations,andfacilitatethedevelopmentofdebuggablemodels. Whilefurther
researchisneededtovalidateitseffectiveness,DILArepresentsapromisingdirectionindeveloping
moreinterpretableandtransparentmodelsforcomplex, high-stakesapplications, contributingto
developingtrustworthyAIsystemsinhealthcareandbeyond.
10References
[1] ARYA, V., BELLAMY, R. K. E., CHEN, P.-Y., DHURANDHAR, A., HIND, M., HOFFMAN,
S.C.,HOUDE,S.,LIAO,Q.V.,LUSS,R.,MOJSILOVIC´,A.,MOURAD,S.,PEDEMONTE,
P., RAGHAVENDRA, R., RICHARDS, J., SATTIGERI, P., SHANMUGAM, K., SINGH, M.,
VARSHNEY,K.R.,WEI,D.,ANDZHANG,Y. Oneexplanationdoesnotfitall: Atoolkitand
taxonomyofaiexplainabilitytechniques,2019.
[2] BILLS,S.,CAMMARATA,N.,MOSSING,D.,TILLMAN,H.,GAO,L.,GOH,G.,SUTSKEVER,
I., LEIKE, J., WU, J., AND SAUNDERS, W. Languagemodelscanexplainneuronsinlan-
guagemodels. https://openaipublic.blob.core.windows.net/neuron-explainer/
paper/index.html,2023.
[3] BRICKEN, T., TEMPLETON, A., BATSON, J., CHEN, B., JERMYN, A., CONERLY, T.,
TURNER, N., ANIL, C., DENISON, C., ASKELL, A., LASENBY, R., WU, Y., KRAVEC,
S., SCHIEFER, N., MAXWELL, T., JOSEPH, N., HATFIELD-DODDS, Z., TAMKIN, A.,
NGUYEN,K., MCLEAN,B., BURKE,J. E.,HUME,T., CARTER,S., HENIGHAN,T., AND
OLAH,C. Towardsmonosemanticity: Decomposinglanguagemodelswithdictionarylearning.
Transformer Circuits Thread (2023). https://transformer-circuits.pub/2023/monosemantic-
features/index.html.
[4] CAO,P.,YAN,C.,FU,X.,CHEN,Y.,LIU,K.,ZHAO,J.,LIU,S.,ANDCHONG,W. Clinical-
coder: AssigninginterpretableICD-10codestoChineseclinicalnotes. InProceedingsofthe
58thAnnualMeetingoftheAssociationforComputationalLinguistics: SystemDemonstrations
(Online, July 2020), A. Celikyilmaz and T.-H. Wen, Eds., Association for Computational
Linguistics,pp.294–301.
[5] CARVALHO,D.V.,PEREIRA,E.M.,ANDCARDOSO,J.S. Machinelearninginterpretability:
Asurveyonmethodsandmetrics. Electronics8,8(2019).
[6] CHAN,C.S.,KONG,H.,ANDGUANQING,L. Acomparativestudyoffaithfulnessmetricsfor
modelinterpretabilitymethods.InProceedingsofthe60thAnnualMeetingoftheAssociationfor
ComputationalLinguistics(Volume1: LongPapers)(Dublin,Ireland,May2022),S.Muresan,
P.Nakov,andA.Villavicencio,Eds.,AssociationforComputationalLinguistics,pp.5029–5038.
[7] CHAUDHARI,S.,MITHAL,V.,POLATKAN,G.,ANDRAMANATH,R. Anattentivesurveyof
attentionmodels,2021.
[8] CHEN,H.,LUNDBERG,S.M.,ANDLEE,S.-I. Explainingaseriesofmodelsbypropagating
shapleyvalues. NatureCommunications13,1(Aug2022),4512.
[9] CHEN,S. Interpretationofmulti-labelclassificationmodelsusingshapleyvalues,2021.
[10] CONMY, A., MAVOR-PARKER, A. N., LYNCH, A., HEIMERSHEIM, S., AND GARRIGA-
ALONSO,A. Towardsautomatedcircuitdiscoveryformechanisticinterpretability,2023.
[11] CUNNINGHAM,H.,EWART,A.,RIGGS,L.,HUBEN,R.,ANDSHARKEY,L. Sparseautoen-
codersfindhighlyinterpretablefeaturesinlanguagemodels,2023.
[12] DEYOUNG, J., JAIN, S., RAJANI, N. F., LEHMAN, E., XIONG, C., SOCHER, R., AND
WALLACE,B.C. Eraser: Abenchmarktoevaluaterationalizednlpmodels,2020.
[13] DUQUE, A., FABREGAT, H., ARAUJO, L., AND MARTINEZ-ROMO, J. Akeyphrase-based
approach for interpretable icd-10 code classification of spanish medical reports. Artificial
IntelligenceinMedicine121(2021),102177.
[14] EDIN, J., JUNGE, A., HAVTORN, J. D., BORGHOLT, L., MAISTRO, M., RUOTSALO, T.,
AND MAALØE, L. Automatedmedicalcodingonmimic-iiiandmimic-iv: Acriticalreview
andreplicabilitystudy. InProceedingsofthe46thInternationalACMSIGIRConferenceon
ResearchandDevelopmentinInformationRetrieval(NewYork,NY,USA,2023),SIGIR’23,
AssociationforComputingMachinery,p.2572–2582.
11[15] ELHAGE, N., HUME, T., OLSSON, C., SCHIEFER, N., HENIGHAN, T., KRAVEC, S.,
HATFIELD-DODDS, Z., LASENBY, R., DRAIN, D., CHEN, C., GROSSE, R., MCCAN-
DLISH, S., KAPLAN, J., AMODEI, D., WATTENBERG, M., AND OLAH, C. Toymodelsof
superposition. TransformerCircuitsThread(2022).
[16] GHOSH,S.,LOW,A.Y.R.,SOH,Y.S.,FENG,Z.,ANDTAN,B.K.Y. Dictionarylearning
undersymmetriesviagrouprepresentations,2023.
[17] GOEL,A.,GUETA,A.,GILON,O.,LIU,C.,ERELL,S.,NGUYEN,L.H.,HAO,X.,JABER,
B., REDDY, S., KARTHA, R., STEINER, J., LAISH, I., AND FEDER, A. Llms accelerate
annotationformedicalinformationextraction,2023.
[18] HAKKOUM,H.,ABNANE,I.,ANDIDRI,A. Interpretabilityinthemedicalfield: Asystematic
mappingandreviewstudy. AppliedSoftComputing117(2022),108391.
[19] HIRSCH,J.A.,NICOLA,G.,MCGINTY,G.,LIU,R.W.,BARR,R.M.,CHITTLE,M.D.,
AND MANCHIKANTI, L. ICD-10: Historyandcontext. AJNRAmJNeuroradiol37,4(Jan.
2016),596–599.
[20] HUANG, C.-W., TSAI, S.-C., AND CHEN, Y.-N. Plm-icd: Automatic icd coding with
pretrainedlanguagemodels,2022.
[21] HUANG, L., YU, W., MA, W., ZHONG, W., FENG, Z., WANG, H., CHEN, Q., PENG,
W., FENG, X., QIN, B., AND LIU, T. Asurveyonhallucinationinlargelanguagemodels:
Principles,taxonomy,challenges,andopenquestions,2023.
[22] HUANG, S., MAMIDANNA, S., JANGAM, S., ZHOU, Y., AND GILPIN, L. H. Can large
languagemodelsexplainthemselves? astudyofllm-generatedself-explanations,2023.
[23] JOHNSON,R.L.,HEDEGAARD,H.,PASALIC,E.S.,ANDMARTINEZ,P.D. UseofICD-10-
CMcodedhospitalisationandemergencydepartmentdataforinjurysurveillance. InjPrev27,
S1(Mar.2021),i1–i2.
[24] KRAMÁR, J., LIEBERUM, T., SHAH, R., AND NANDA, N. Atp*: Anefficientandscalable
methodforlocalizingllmbehaviourtocomponents,2024.
[25] LEWIS, P., PEREZ, E., PIKTUS, A., PETRONI, F., KARPUKHIN, V., GOYAL, N., KÜTTLER,
H., LEWIS, M., TAUYIH, W., ROCKTÄSCHEL, T., RIEDEL, S., ANDKIELA, D. Retrieval-
augmentedgenerationforknowledge-intensivenlptasks,2021.
[26] LI, F., AND YU, H. ICDcodingfromclinicaltextusingMulti-Filterresidualconvolutional
neuralnetwork. ProcAAAIConfArtifIntell34,5(Apr.2020),8180–8187.
[27] LIU,Y.,LIU,X.,YU,H.,TANG,X.,ANDWEI,X.Learningdictionaryforvisualattention.In
AdvancesinNeuralInformationProcessingSystems(2023),A.Oh,T.Naumann,A.Globerson,
K.Saenko,M.Hardt,andS.Levine,Eds.,vol.36,CurranAssociates,Inc.,pp.56589–56601.
[28] LUNDBERG,S.,ANDLEE,S.-I. Aunifiedapproachtointerpretingmodelpredictions,2017.
[29] LUNDBERG, S. M., ERION, G., CHEN, H., DEGRAVE, A., PRUTKIN, J. M., NAIR, B.,
KATZ,R.,HIMMELFARB,J.,BANSAL,N.,ANDLEE,S.-I. Fromlocalexplanationstoglobal
understandingwithexplainableaifortrees. NatureMachineIntelligence2,1(Jan2020),56–67.
[30] MA,C.,ZHAO,B.,CHEN,C.,ANDRUDIN,C. Thislookslikethose:Illuminatingprototypical
conceptsusingmultiplevisualizations,2023.
[31] MANSOUR, Y., MOSHKOVITZ, M., AND RUDIN, C. Thereisnoaccuracy-interpretability
tradeoffinreinforcementlearningformazes,2022.
[32] MOSCA, E., SZIGETI, F., TRAGIANNI, S., GALLAGHER, D., AND GROH, G. SHAP-
based explanation methods: A review for NLP interpretability. In Proceedings of the 29th
InternationalConferenceonComputationalLinguistics(Gyeongju,RepublicofKorea,Oct.
2022),N.Calzolari,C.-R.Huang,H.Kim,J.Pustejovsky,L.Wanner,K.-S.Choi,P.-M.Ryu,
H.-H. Chen, L. Donatelli, H. Ji, S. Kurohashi, P. Paggio, N. Xue, S. Kim, Y. Hahm, Z. He,
T.K.Lee,E.Santus,F.Bond,andS.-H.Na,Eds.,InternationalCommitteeonComputational
Linguistics,pp.4593–4603.
12[33] MRINI, K., DERNONCOURT, F., TRAN, Q., BUI, T., CHANG, W., AND NAKASHOLE, N.
Rethinkingself-attention: Towardsinterpretabilityinneuralparsing,2020.
[34] MULLENBACH, J., WIEGREFFE, S.,DUKE, J.,SUN, J., AND EISENSTEIN, J. Explainable
predictionofmedicalcodesfromclinicaltext,2018.
[35] OLAH, C., CAMMARATA, N., SCHUBERT, L., GOH, G., PETROV, M., AND CARTER, S.
Zoomin: Anintroductiontocircuits. Distill(2020). https://distill.pub/2020/circuits/zoom-in.
[36] OLSHAUSEN, B. A., AND FIELD, D. J. Sparse coding with an overcomplete basis set: A
strategyemployedbyv1? VisionResearch37,23(1997),3311–3325.
[37] O’MALLEY, K. J., COOK, K. F., PRICE, M. D., WILDES, K. R., HURDLE, J. F., AND
ASHTON,C.M. Measuringdiagnoses: ICDcodeaccuracy. HealthServRes40,5Pt2(Oct.
2005),1620–1639.
[38] RAJAMANOHARAN,S.,CONMY,A.,SMITH,L.,LIEBERUM,T.,VARMA,V.,KRAMÁR,J.,
SHAH, R., AND NANDA, N. Improvingdictionarylearningwithgatedsparseautoencoders,
2024.
[39] RAO,P.,FISCHER,S.H.,VAIANA,M.E.,ANDTAYLOR,E.A. Barrierstopriceandquality
transparencyinhealthcaremarkets. RandHealthQ9,3(June2022),1.
[40] RUDIN,C. Stopexplainingblackboxmachinelearningmodelsforhighstakesdecisionsand
useinterpretablemodelsinstead. NatureMachineIntelligence1,5(May2019),206–215.
[41] RÄUKER,T.,HO,A.,CASPER,S., ANDHADFIELD-MENELL,D. Towardtransparentai: A
surveyoninterpretingtheinnerstructuresofdeepneuralnetworks,2023.
[42] SERRANO,S.,ANDSMITH,N.A. Isattentioninterpretable?,2019.
[43] SHRIKUMAR,A.,GREENSIDE,P.,ANDKUNDAJE,A. Learningimportantfeaturesthrough
propagatingactivationdifferences,2019.
[44] SUBRAMANIAN,A.,PRUTHI,D.,JHAMTANI,H.,BERG-KIRKPATRICK,T.,ANDHOVY,E.
Spine: Sparseinterpretableneuralembeddings,2017.
[45] TANG, D., WILLARD, F., TEGERDINE, R., TRIPLETT, L., DONNELLY, J., MOFFETT, L.,
SEMENOVA, L., BARNETT, A. J., JING, J., RUDIN, C., AND WESTOVER, B. Protoeegnet:
Aninterpretableapproachfordetectinginterictalepileptiformdischarges,2023.
[46] TANG, Y., PENG, Z., AND LI, Y. Explainabletrajectoryrepresentationthroughdictionary
learning,2023.
[47] THOMPSON,R.,DEZFOULI,A., ANDKOHN,R. Thecontextuallasso: Sparselinearmodels
viadeepneuralnetworks,2024.
[48] VASWANI, A., SHAZEER, N., PARMAR, N., USZKOREIT, J., JONES, L., GOMEZ, A. N.,
KAISER,L.,ANDPOLOSUKHIN,I. Attentionisallyouneed,2023.
[49] VU, T., NGUYEN, D. Q., AND NGUYEN, A. Alabelattentionmodelforicdcodingfrom
clinicaltext. InProceedingsoftheTwenty-NinthInternationalJointConferenceonArtificial
Intelligence(July2020),IJCAI-PRICAI-2020,InternationalJointConferencesonArtificial
IntelligenceOrganization.
[50] WONG,E.,SANTURKAR,S.,ANDMA˛DRY,A. Leveragingsparselinearlayersfordebuggable
deepnetworks,2021.
[51] XU,R.,WANG,C.,LI,Y.,ANDWU,J. Generalizedtimewarpinginvariantdictionarylearning
fortimeseriesclassificationandclustering,2023.
[52] YAN,C.,FU,X.,LIU,X.,ZHANG,Y.,GAO,Y.,WU,J.,ANDLI,Q. Asurveyofautomated
international classification of diseases coding: development, challenges, and applications.
IntelligentMedicine2,3(2022),161–173.
13[53] YANG, Z., BATRA, S. S., STREMMEL, J., AND HALPERIN, E. Surpassinggpt-4medical
codingwithatwo-stageapproach,2023.
[54] YU,Y.,BUCHANAN,S.,PAI,D.,CHU,T.,WU,Z.,TONG,S.,BAI,H.,ZHAI,Y.,HAEFFELE,
B.D.,ANDMA,Y. White-boxtransformersviasparseratereduction: Compressionisallthere
is?,2023.
[55] YUN, Z., CHEN, Y., OLSHAUSEN, B. A., AND LECUN, Y. Transformervisualizationvia
dictionarylearning: contextualizedembeddingasalinearsuperpositionoftransformerfactors,
2023.
[56] ZHANG, L., MILLE, S., HOU, Y., DEUTSCH, D., CLARK, E., LIU, Y., MAHAMOOD, S.,
GEHRMANN, S., CLINCIU, M., CHANDU, K., AND SEDOC, J. Needleinahaystack: An
analysisofhigh-agreementworkersonmturkforsummarization,2023.
[57] ZHANG, Y., TINO, P., LEONARDIS, A., AND TANG, K. Asurveyonneuralnetworkinter-
pretability. IEEETransactionsonEmergingTopicsinComputationalIntelligence5,5(Oct.
2021),726–742.
[58] ZHANG, Z.,XU,Y.,YANG, J., LI, X.,ANDZHANG,D. Asurveyofsparserepresentation:
Algorithmsandapplications. IEEEAccess3(2015),490–530.
[59] ZHAO, W. X., ZHOU, K., LI, J., TANG, T., WANG, X., HOU, Y., MIN, Y., ZHANG, B.,
ZHANG,J.,DONG,Z.,DU,Y.,YANG,C.,CHEN,Y.,CHEN,Z.,JIANG,J.,REN,R.,LI,Y.,
TANG,X.,LIU,Z.,LIU,P.,NIE,J.-Y.,ANDWEN,J.-R. Asurveyoflargelanguagemodels,
2023.
[60] ZOU,H.,ANDHASTIE,T. RegularizationandVariableSelectionViatheElasticNet. Journal
oftheRoyalStatisticalSocietySeriesB:StatisticalMethodology67,2(032005),301–320.
A Appendix/supplementalmaterial
A.1 TrainingDetails
ForafaircomparisonandtoreproducethePLM-ICDmodelfrom[14],wefollowedthehyperpa-
rameterssweptintheirworkascloselyaspossible. Specifically,bothmodelsemployedthesame
pre-trained medical RoBERTa encoder architecture. One slight difference in training is that we
leveragethePLMalreadypre-trainedontheICDcodingtaskwhereasPLM-ICDistrainedfrom
apre-trainedmedicalRoBERTamodelonothermedicaldata. Additionally,weutilizedtheircode
toperformthesamedatasplitsasreportedintheirMIMIC-IIIreproduction, obtainedfromtheir
repository [14]. Due to physionet’s policies, we are unable to share their training data directly.
However,duetoGPUmemoryconstraints,wewereunabletousethesamebatchsize,whichmay
havehinderedourabilitytofullyreproducetheirPLM-ICD[20]performance. Table8showcasesthe
hyperparametersusedforourmethods. It’sworthnotingthataninitialparametersweeprevealed
thattheperformancebenefitsofPLMlabelattentionmodelslargelystemmedfromtheirbatchsize.
Consequently, wereranourtrainingfourtimesacrossfourrandomlyselectedseeds. Weusethe
optimizerAdamWwithitsdefaultsettings. Wealsouse1e-6forourλ hyperparameter.
saenc
Table8: HyperparametersusedintrainingDILAandPLM-ICDmodels
Learningrate λl1 λl2 Batchsize LRscheduler Epochs Dropout DecisionBoundaryThreshold
DILA* 5e-5 0.0001 0.00001 8 LinearWarmup 20 0.2 0.3
PLM-ICD* 5e-5 N/A N/A 8 LinearWarmup 20 0.2 0.3
PLM-ICD[14] 5e-5 N/A N/A 16 LinearWarmup 20 0.2 0.3
ComputeResources. WeleverageacomputeclusterusingA600048GBGPUsandnotethatour
maximumbatchsizewasofsize8duetosomeclinicalnotescontainingover4,000tokens. Training
takesapproximatelyaday,butweregretnotmeasuringexplicittrainingtimes.Werecommendhaving
atleast48GBofCPUmemory,asdependingontheanalysis,westorealotinmemory.
14A.2 DictionaryContextsConstruction
Theconstructionofahuman-interpretabledictionary,containingrelevanttokensforeachf ,involves
i
twosteps. First,wesamplealargenumberoftokensanddecomposetheirembeddingsusingthe
sparseautoencoderdefinedinSection3.1. Foreachiinf,weretrievethesparselyactivatednonzero
f . Next,wesortalltokensbytheirf magnitudesforeachf toobtaintheircontexts. Toconserve
i i i
memory,wesavethetop10connectedtokensbutonlyusethetop4connectedtokens(i.e.,multiple
activatedtokenswithinachunk)forourevaluations. It’sworthnotingthatsomedictionaryfeatures
have very few activating contexts. Algorithm 1 summarizes this procedure. For our dictionary
construction,wesampleover8,000clinicalnotesfromthetestset.
Algorithm1:BuildDictionary
Input: SparseAutoencoderA,featuref ,tokensx
i
Output: Dictionaryf mappingf totokensxandclassesy
i
1 F ←dict;foreachtokenxdo
2 f ←A.encode(x);forf iinf do
3 iff i >F[i].f ithen
4 F[i].tokens←x;
5 δ i ←ablation(f i);ifδ i >F[i].δthen
6 F[i].classes←drops(δ i);
7 returnf;
WeshowaresultingoutputofapandasdataframeinFigure5.
Figure 5: Example of token sorting to acquire the necessary token contexts for f for dictionary
i
feature1,871,relatingtosubduralhemotomas. Thefarleftcolumnindicatesthepositionofthetoken
inthetextcorpus.
A.3 DictionaryFeatureIdentification
ExtendedRationaleforDictionaryFeatureIdentificationApproachwithLLMs: Initially,we
plannedtohavetheLLMsimplyanswerwhetherornottherewasanexplicitmedicalthemewithin
eachsetofcontextswithayesornoresponse. However,weobservedthat,regardlessofspecificity,
the LLMs would always respond affirmatively, stating that the contexts were medically relevant.
Consequently,wepursuedadifferentapproachoriginallyleveragedinhumanevaluationexperiments
by[44]. Wenoticedthatthisapproachsubstantiallyimprovedthedeterminationofwhetherasetof
15dictionarycontextswasinterpretable,astheLLMwasimplicitlyforcedtoevaluatewhetheracommon
concept existed among the dictionary contexts. To illustrate the dictionary feature identification
process,weshowcaseacoupleofLLMpromptsandtheirrespectivecontexttokensinthefigures
below.
Other Minor Identification Experiment Details: We ran our dictionary feature identification
processacross6,088dictionaryfeatures. Initially,weeliminatedanydictionaryfeaturewithfewer
than4contexts,deemingthemunidentifiableduetothelackofcontexts. Subsequently,weconducted
oursimpleidentificationexperiment. It’sworthnotingthat,inprinciple,largertextcorpusescould
potentiallybebeneficialforidentifyingmoredictionaryfeatures. However,themajorityofdictionary
features(5,847outof6,088)containedatleast4contexts.
A.3.1 LLMIdentificationPrompt
Figure6: DictionaryFeaturef IdentificationTasksfortheLLM.Thecorrectrandomcontextis
i
indicatedinbold. LLMsstruggletoidentifythecommonmedicalthemeinchallengingcontextsthat
lackexplicitconnections(right). Clinicalnotesoftencontainabbreviationsandshorthandwithout
clearreferences,makinginterpretationdifficultevenforexperiencedphysicians. Forexample,the
abbreviation"rtr"waschallengingforourclinicalphysiciantorecall(right).
16Figure7: DenseZ IdentificationTasksfortheLanguageModel(LLM).Thecorrectrandomcontext
i
isindicatedinbold. Somedenselayerneuronsactivateforcontextswithacommontheme,suchas
claudicationandnausea(left). However,manyneuronsactivateforseeminglyunrelatedcontexts
(right).
A.3.2 HumanIdentificationExamples
Figure8: DictionaryFeaturef IdentificationTasksforHumans. Theleftpanelshowsacasewhere
i
thehumancorrectlyidentifiedadictionaryfeature,buttheLanguageModel(LLM)failedtodoso.
TheLLMincorrectlyselected"massivebloodloss..."astherandomcontext,despiteitsrelationship
tobanding. TherightpanelpresentsdictionarycontextswhereboththeLLMandhumansfailedto
identifytherandomlysampledcontext,whichisunderstandablegiventheseeminglyunrelatednature
ofthecontexts.
17Figure9: DenseZ IdentificationTasksforHumans. Theleftpanelshowsanexamplewherehumans
i
identifiedaneuronwithhiddenunderlyingrelationships,suchastheconnectionbetweensmokingand
cardiology,wherepatientsoftenexperiencevariouslevelsofpainduetocomplications. Language
Models(LLMs)struggletoidentifysuchrelationships. Therightpaneldemonstratesaneuronwith
adiversesetofcontexts,makingitchallengingforbothhumansandLLMstoidentifyacommon
theme.
Figure10: ExampleofPurelyRandomContexts. Theimageshowcasesapromptwithtrulyrandom
tokens,including<pad>tokensthatwerenotfilteredout.Astarkreductionin<pad>tokensactivating
denseZneuronsisobserved,and<pad>tokensareessentiallyneverpresentinthedictionarycontexts,
suggestingtheirirrelevancetomodelpredictions.
A.4 LLMSummarization
We showcase the LLM prompt used, and the human evaluation results below. We showcase the
summariesrejectedbyourmedicalexpertsinFigure12.
18A.4.1 LLMPrompt
Figure 11: LLM Summarization Prompt for Dictionary Feature Contexts. The image shows the
promptusedtosummarizethehighlyconnecteddictionarycontextsidentifiedinthepipeline. The
modelislimitedto8wordstofacilitateprocessingandextractingthesummaries,asallowingan
unlimitedwordcountresultedintheinclusionoffillerwordsintheLLM-generatedsummaries.
A.4.2 MedicalExpertRejectionsofLLMSummary
WeshowcaseonlytheLLM-generatedsummariesrejectedbyourmedicalexpertevaluators,asthey
are more informative than the accepted summaries. Although the dictionary contexts are highly
interpretableandconsistentwithaspecificmedicaltheme,theexpertsdisagreedwithcertainaspects
ofthespecificLLMsummaries. Forinstance,theterm"kneeamputation"wasdeemedinsufficiently
specific,as"abovekneeamputation"isthemoreprecisemedicalcondition,differingfrom"below
kneeamputations."OtherdisagreementswererelatedtotheLLM’sinferencesofabbreviations,such
as"igris,"wheretherewasnoevidenceof"insulinglargineinjections"withinthecontext. Insuch
scenarios,dictionarycontextsmaynothaveaconclusivesummary,requiringfurtherinvestigation
intotheclinicalnotesaswellaspotentiallytheneedtoincludesomeamountofcontext. Notethat,as
partoftheLLMauto-interpretabilityevaluationstudydonein1,59dictionaryfeaturesummariesand
34DenseZsummarieswereexamined,asshowninTable2.
19Figure 12: Medical Expert Rejected LLM Summaries of Dictionary Features f. The summaries
rejectedbythemedicalexpertsweregenerallyduetoalackofspecificity,suchas"kneeamputation"
notbeing"abovekneeamputation"(middleleft). Twoothersummaries(leftandmiddleright)were
rejectedbecausetheLLMsummarywastoospecific,withunlikelyassociationssuchasAmiodarone
andstrokesortheassumptionthatthoracotomywaspresentinallcontexts. Thefarrightrejection
demonstratesacaseofdirecthallucination,wheretheLLMassumedthecontextswererelatedto
insulindespitenoinformationhintingatthatrelationship,eventhoughthecontextssharedthesame
acronym.
Ontheotherhand,fromthedenseZ contextsthathaveseeminglypassedtheLLMidentificationtest,
theirsummarieswererejectedduetothelackofcoherencewithineachcontext,implyingthatmany
oftheidentifiedZ featuresmayhavebeentheresultofchancebytheLLMpipeline.
Figure 13: Medical Expert Rejected LLM Summaries of Contexts from Dense Z. Many of the
denseZ contextsummarieswererejectedduetotheirover-generality. Forinstance,theLLMwould
frequentlygeneratesummarieslike"thecommonpatternobservedisrelatedtomedication,"which
is true to some extent as medical text is generally related to medication. However, these LLM
summaries(farleft,middleleft)weredeemeduninformativebythemedicalexperts. Otherrejections
(middleright)wereduetothelackofcoherencewithindenseZ contexts,suchasthepresenceof
<pad>tokensandliver-relatedcontexts. Surprisingly,theLLMsummarystillmanagedtocapture
somerelevantpartsofthecontext,suchasmetastaticcancerandliverresection. Finally,thefarright
exampleshowsasurprisinglyconsistentmedicaltheme,withrenaldiseasepresentinthreeofthe
fourcontexts. However,theannotatorsfeltthatthesummary"effectsonthebody"wastoobroadand
notspecificenough.
20A.5 SparseProjectionMatrix
Tobetterunderstandthestructureofoursparsematrix,wevisualizethefirst100dictionaryfeatures
and100medicalcodesinourlearnedA anddenseW projectionmatrixinPLMICD.Wenote
ficd c
thatourA issubstantiallysparser.
ficd
Figure 14: Sparsity comparison between ICD projection matrices W and A . for first 100
c ficd
dictionaryfeaturesandmedicalcodes. Visuallyspeaking,itiseasytoidentifythestrongrelationships
betweendictionaryfeaturesandICDcodeswhereasinthedenseprojectionmatrix,itsweightslook
almostuninterpretable.
Weleveragethishighsparsitytoconstructourhumaninterpretabilityandablationexperimentsbelow,
aseachabstractdictionaryfeatureisobservedtoberelatedtospecificmedicalcodes.
A.5.1 Globalvs. LocalInterpretabilityAblationExperiments
DefinitionofHighlyRelevantTokens: Sincemosttokenshaveverylowlabelattentionattribution
scoresforeachclass,wedefinethemostrelevanttokensasthosewithattentionattributionscores
greaterthanthe95thquantileforaspecificclassinthelabelattentionmatrix.
Weight Ablation Details: Each clinical note can be decomposed into a sparse set of dictionary
features. Consequently,wecanidentifyasetofweightscorrespondingtoeachnonzerodictionary
feature and medical code to be ablated for each clinical note. Since most irrelevant weights are
alreadyclosetozero,andtherelevantweightsarepositive,ablatingthem(i.e.,settingthemtozero)
shouldprovideareasonablycloseapproximationtotheoptimalexplanation. Inpractice,ablating
alltheweightsforaspecificclassinourA matrixdoesnotaffectanyotherclass,indicatingthe
ficd
potentialforpreciseexplanationsofasinglemedicalcodeorclass.
RecognitionofFaithfulnessMetricsinConventionalMulticlassClassification: Weacknowledge
theexistenceofvariousotherinterpretabilityfaithfulnessmetricsforlocalattributionmethods[6],
suchascomprehensiveness[12]andmonotonicity[1]. However,duetothelargenumberoftokens
(someclinicalnoteshaveupwardsofalmost6,000tokens),performingaquantilingremovalortoken
additionschemeisextremelycomputationallyexpensive,especiallyifoneweretoconsiderdoing
soforeachcodeineverymultilabelexample. Assuch, wesimplifiedourdownstreameffectsor
faithfulnessexperimenttosimplymeasuringthedropinperformanceofthemostlikelyICDcodefor
eachclinicalnoteandtheabsolutechangeinsoftmaxprobabilitiesofotherICDcodepredictions.
A.6 PredictabilityExperiments
Inthehumanpredictaiblityexperiment,weaskbothLLMsandourmedicalexpertstoselectthebest
correspondingmedicalcodesgivenasetofdictionaryfeaturecontextsanditsLLMsummary. We
showcaseexamplesofourpredictabilityexperimentsbelow.
21A.6.1 LLMPrompt
Figure15: LLMPromptforPredictabilityExperimentwithf. TheLLMispresentedwithtwosetsof
medicalcodedescriptionsrelatedtothecontextsandsummaryitgenerated,labeledas"A"and"B".
TheLLMisthenpromptedtochoosethesetofmedicalcodesthatbestdescribesorrelatestothe
conditionsshowninthegivencontextsandsummary.
A.6.2 HumanEvaluation
Due to being more informative than the positive correct cases (as those dictionary features and
codesaremoreobviouslyselectedfor), weshowcasetheresultswherethepersonwasunableto
selectthesetofmedicalcodesthatthemodelhadhighlightedforitsdownstreampredictions. From
qualitative inspection with our medical experts, we notice that the medical expert was unable to
predictthecorrectsetofmedicalcodeswerethedirectresultofbothsetsofmedicalcodesbeing
relatedtothedictionaryfeature,orthetopICDcodesassociatedwitheachdictionaryfeatureinour
A were incorrectly mapped. For instance, the suture of lacerations of different organs are not
ficd
directlyrelatedtogallstonesanddoubletailstentsthatpreventbiliaryobstructions. Ontheother
hand,smokingcomplicationssuchasTobaccouseareoftenmorelikelytocausestomachulcersthan
malignantlymphomas. Whilebothcanhavethatasapotentialcomplication,inpractice,oneismore
commonovertheother,showcasingthewrongweighingofourlearnedA matrixbetweendifferent
ficd
medicalconditionsandmedicalcodes. Otherpredictabilityexperimentsfailedduetothelackofextra
informationonabbreviationssuchas"LEVT",whichmaybeachallengetounderstandasmanyof
theseunstructuredclinicalnotesdonothaveaspecificidentificationprocessfortheseabbreviations.
Thatsaid,wenotethatthepredictabilityofthesecodesisbetterthanrandom,suggestingthatthe
globaldictionarymatrixcanbeleveragedtobetterunderstandwhatourmodelunderstandsforeach
setofmedicalcodepredictions.
22Figure 16: Human Predictability Experiment: Cases with incorrect predictions using dictionary
featuresf. Despitemanyofthecontextsbeinghighlyinformative,theannotatorwasoftenunable
to select the set of medical codes corresponding to the top 5 medical codes defined by the A
ficd
matrix. For example, the left contexts are related to stones, which should have no connection to
sutureoflacerations,butSetBisthecorrespondingsetofcodesobserved. Inthemiddleleftsetof
contexts,ulcersareacommoncomplicationamongtobaccousersandsmokers,butthemodelhas
possiblylearned,byassociation,thattheyaremoreindicativeofcancer. The"LEVT"contextsand
theessentiallyhallucinatedsummarywerevirtuallyunidentifiabledespitebeingextremelyconsistent
intheme. Finally,bothsetsofmedicalcodesseemtohaveverylittlerelationtoadenocarcinoma(a
formofcancer)inthelastsetofcontexts.
A.6.3 MisalignedAssociationsBetweenLearnedMedicalConceptsandMedicalCodes
FromqualitativeexaminationsofourhumanevaluationsinSectionA.6.2,wenoticethatthemodel
canoftenlearnunintendedassociationsbetweenmedicalcodesandspecificmedicalconditions. We
attempttobettervisualizeanddiscernotherpotentialmismappingsthroughheatmapvisualizations.
For instance, while they can be related, traumatic brain injuries aren’t a direct cause of diabetic
medicalcodesorconditionsasobservedinFigure18.
23Figure17: HeatmapvisualizationsoftheA matrixformedicalcodesassociatedwithchesttube-
ficd
relateddictionaryfeatures. Thex-axisrepresentsthedictionaryfeatures,whilethey-axisrepresents
therespectivemedicalcodes. Theintensityofeachcellintheheatmapindicatesthestrengthofthe
associationbetweenadictionaryfeatureandamedicalcode. Dictionaryfeatureslabeledas"LLM
unidentified"denoteinstanceswheretheLLMpipelinewasunabletoidentifytheunderlyingconcept
representedbythefeature.
24Figure18: HeatmapvisualizationsoftheA matrixformedicalcodesassociatedwithdiabetes-
ficd
relateddictionaryfeatures. Thex-axisrepresentsthedictionaryfeatures,whilethey-axisrepresents
therespectivemedicalcodes. Theintensityofeachcellintheheatmapindicatesthestrengthofthe
associationbetweenadictionaryfeatureandamedicalcode. Dictionaryfeatureslabeledas"LLM
unidentified"denoteinstanceswheretheLLMpipelinewasunabletoidentifytheunderlyingconcept
representedbythefeature.
25Figure19:HeatmapvisualizationsoftheA matrixformedicalcodesassociatedwithsepsis-related
ficd
dictionaryfeatures. Thex-axisrepresentsthedictionaryfeatures, whilethey-axisrepresentsthe
respectivemedicalcodes. Theintensityofeachcellintheheatmapindicatesthestrengthofthe
associationbetweenadictionaryfeatureandamedicalcode. Dictionaryfeatureslabeledas"LLM
unidentified"denoteinstanceswheretheLLMpipelinewasunabletoidentifytheunderlyingconcept
representedbythefeature.
A.6.4 DebuggingCaseStudy
Althoughtherearemorepotentially, weshowcasethetop20differenthighlyrelevantdictionary
featuresforthecommonlyfalselypredictedICD99.20codeof"InjectionofPlateletInhibitors"in
Figure20. Diggingdeeperwithinthetop100relateddictionaryfeatures,weobservethefollowing
falsedictionaryfeaturesarenotrelatedtothemedicalcode:
• 5188Fracturesofscapulaandglenoidfossaobservedrepeatedly.
• 4443 Trisomy disorders, likely Down syndrome (Trisomy 21), and associated genetic
counseling.
• 345Lungconditionslikebronchiolitisobliteransorganizingpneumonia(BOOP)andradia-
tionpneumonitis.
• 1558Neonatalhyperbilirubinemia,bothphysiologicandpathologic,andrelateddiagnostic
workup.
• 802 Patients with end-stage amyotrophic lateral sclerosis (ALS) who are ventilator-
dependentandhavecomplicationssuchasbronchiectasis,pneumonia,andcardiacissues.
26• 6069Patientsundergoingtotalkneereplacementsurgery,particularlythosewithcomplica-
tionslikerespiratorydistress,painmanagementissues,orcomorbiditiessuchasschizophre-
nia.
• 4917Patientswithseveredysphagiaanddifficultymanagingoralsecretions,ofteninthe
contextofadvancedillnessessuchascancerorcriticalconditions.
Weablatethesedictionaryfeaturestoshowcaseourinitialdebuggingattempts.
Figure20: Top20dictionaryfeaturesassociatedwithICD99.20Injectionorinfusionofplatelet
inhibitors. Weobservemanyunrelateddictionaryfeatures. Notethatwealsomanuallyidentifysome
ofthepreviouslyLLMunidentifiedcontexts.
A.7 UnidentifiableDictionaryFeatures
Weattempttoinvestigatesomeofthehighlyrelevantunidentifiablefeaturesintheheatmapsabove
and observe a couple findings. First, some dictionary features simply lack enough context, and
second,somearetrulychallengingtodiscernacommonpattern,oftenhavingaverydiversesetof
medicalconditionsthatactivateaspecificdictionaryfeature.
HighlyActivatingTokens Dictionary Feature
f
i
ograft 3846
Surgicalprocedureanteriorpelvicringexternalfixatorposteriorringfixation, 362
Pneumcephalusbrain,Externalfixatorposteriorringfixationsacroiliacscrew,
Temporal,Pneumcephalus,Posteriorringfixationsacroiliacscrewsuprapubic
catheterplacementpresent,Allergicanaphylaxisasthmaticussteroid,Steroids,
Removalofexternalfixatorleg,sarcflare
Smokerfasci 1
main, e coli, c, cardiac catheterization, va ci, pulmonary, e coli, defibrillator, 3774
catheterization
iabp,liver,iabp,idiopathic,balloon 552
axilla,vc,vc,line,fistulas,mvc,phal,infectious,portath,perianalfistulas 1350
Table9: ExamplesofUnidentifiedDictionaryFeatures. Manylackthenumberofcontexts,orsome
haveverydivergenthighlyactivatingcontextslikeecoliandcardiaccatheterization.
27NeurIPSPaperChecklist
1. Claims
Question: Dothemainclaimsmadeintheabstractandintroductionaccuratelyreflectthe
paper’scontributionsandscope?
Answer: [Yes]
Justification: Ourpapershareshumanevaluationresultsandotherresultstoshowcasethe
scalabilityofourmechanisticinterpretabilitymethod.
Guidelines:
• The answer NA means that the abstract and introduction do not include the claims
madeinthepaper.
• Theabstractand/orintroductionshouldclearlystatetheclaimsmade,includingthe
contributionsmadeinthepaperandimportantassumptionsandlimitations. ANoor
NAanswertothisquestionwillnotbeperceivedwellbythereviewers.
• Theclaimsmadeshouldmatchtheoreticalandexperimentalresults,andreflecthow
muchtheresultscanbeexpectedtogeneralizetoothersettings.
• Itisfinetoincludeaspirationalgoalsasmotivationaslongasitisclearthatthesegoals
arenotattainedbythepaper.
2. Limitations
Question: Doesthepaperdiscussthelimitationsoftheworkperformedbytheauthors?
Answer: [Yes]
Justification: Wediscussmanyofthelimitationsofourmethodinsection5. Wealsogo
intofurtherdetailsaboutthechallengesofusingconventionalfaithfulnessmetricsinour
appendix.
Guidelines:
• TheanswerNAmeansthatthepaperhasnolimitationwhiletheanswerNomeansthat
thepaperhaslimitations,butthosearenotdiscussedinthepaper.
• Theauthorsareencouragedtocreateaseparate"Limitations"sectionintheirpaper.
• Thepapershouldpointoutanystrongassumptionsandhowrobusttheresultsareto
violationsoftheseassumptions(e.g.,independenceassumptions,noiselesssettings,
modelwell-specification,asymptoticapproximationsonlyholdinglocally).Theauthors
shouldreflectonhowtheseassumptionsmightbeviolatedinpracticeandwhatthe
implicationswouldbe.
• Theauthorsshouldreflectonthescopeoftheclaimsmade,e.g.,iftheapproachwas
onlytestedonafewdatasetsorwithafewruns. Ingeneral,empiricalresultsoften
dependonimplicitassumptions,whichshouldbearticulated.
• Theauthorsshouldreflectonthefactorsthatinfluencetheperformanceoftheapproach.
Forexample,afacialrecognitionalgorithmmayperformpoorlywhenimageresolution
isloworimagesaretakeninlowlighting. Oraspeech-to-textsystemmightnotbe
usedreliablytoprovideclosedcaptionsforonlinelecturesbecauseitfailstohandle
technicaljargon.
• Theauthorsshoulddiscussthecomputationalefficiencyoftheproposedalgorithms
andhowtheyscalewithdatasetsize.
• If applicable, the authors should discuss possible limitations of their approach to
addressproblemsofprivacyandfairness.
• Whiletheauthorsmightfearthatcompletehonestyaboutlimitationsmightbeusedby
reviewersasgroundsforrejection,aworseoutcomemightbethatreviewersdiscover
limitationsthataren’tacknowledgedinthepaper. Theauthorsshouldusetheirbest
judgmentandrecognizethatindividualactionsinfavoroftransparencyplayanimpor-
tantroleindevelopingnormsthatpreservetheintegrityofthecommunity. Reviewers
willbespecificallyinstructedtonotpenalizehonestyconcerninglimitations.
3. TheoryAssumptionsandProofs
Question: Foreachtheoreticalresult,doesthepaperprovidethefullsetofassumptionsand
acomplete(andcorrect)proof?
28Answer: [NA]
Justification: Therearenotheoreticalresultshere.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotincludetheoreticalresults.
• Allthetheorems, formulas, andproofsinthepapershouldbenumberedandcross-
referenced.
• Allassumptionsshouldbeclearlystatedorreferencedinthestatementofanytheorems.
• Theproofscaneitherappearinthemainpaperorthesupplementalmaterial, butif
theyappearinthesupplementalmaterial,theauthorsareencouragedtoprovideashort
proofsketchtoprovideintuition.
• Inversely,anyinformalproofprovidedinthecoreofthepapershouldbecomplemented
byformalproofsprovidedinappendixorsupplementalmaterial.
• TheoremsandLemmasthattheproofreliesuponshouldbeproperlyreferenced.
4. ExperimentalResultReproducibility
Question: Doesthepaperfullydisclosealltheinformationneededtoreproducethemainex-
perimentalresultsofthepapertotheextentthatitaffectsthemainclaimsand/orconclusions
ofthepaper(regardlessofwhetherthecodeanddataareprovidedornot)?
Answer: [Yes]
Justification: Wedoourbesttorecordmuchofthehyperparametertrainingdetailsinour
Appendix. Wenotethatphysionetpreventsusfromdirectlysharingthedataset,butitis
opensourceonceusersapplyanddosomeprivacytraining.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotincludeexperiments.
• Ifthepaperincludesexperiments,aNoanswertothisquestionwillnotbeperceived
well by the reviewers: Making the paper reproducible is important, regardless of
whetherthecodeanddataareprovidedornot.
• Ifthecontributionisadatasetand/ormodel,theauthorsshoulddescribethestepstaken
tomaketheirresultsreproducibleorverifiable.
• Dependingonthecontribution,reproducibilitycanbeaccomplishedinvariousways.
Forexample,ifthecontributionisanovelarchitecture,describingthearchitecturefully
mightsuffice,orifthecontributionisaspecificmodelandempiricalevaluation,itmay
benecessarytoeithermakeitpossibleforotherstoreplicatethemodelwiththesame
dataset,orprovideaccesstothemodel. Ingeneral. releasingcodeanddataisoften
onegoodwaytoaccomplishthis,butreproducibilitycanalsobeprovidedviadetailed
instructionsforhowtoreplicatetheresults,accesstoahostedmodel(e.g.,inthecase
ofalargelanguagemodel),releasingofamodelcheckpoint,orothermeansthatare
appropriatetotheresearchperformed.
• WhileNeurIPSdoesnotrequirereleasingcode,theconferencedoesrequireallsubmis-
sionstoprovidesomereasonableavenueforreproducibility,whichmaydependonthe
natureofthecontribution. Forexample
(a) Ifthecontributionisprimarilyanewalgorithm,thepapershouldmakeitclearhow
toreproducethatalgorithm.
(b) Ifthecontributionisprimarilyanewmodelarchitecture,thepapershoulddescribe
thearchitectureclearlyandfully.
(c) Ifthecontributionisanewmodel(e.g.,alargelanguagemodel),thenthereshould
eitherbeawaytoaccessthismodelforreproducingtheresultsorawaytoreproduce
themodel(e.g.,withanopen-sourcedatasetorinstructionsforhowtoconstruct
thedataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case
authorsarewelcometodescribetheparticularwaytheyprovideforreproducibility.
Inthecaseofclosed-sourcemodels,itmaybethataccesstothemodelislimitedin
someway(e.g.,toregisteredusers),butitshouldbepossibleforotherresearchers
tohavesomepathtoreproducingorverifyingtheresults.
5. Openaccesstodataandcode
29Question: Doesthepaperprovideopenaccesstothedataandcode,withsufficientinstruc-
tionstofaithfullyreproducethemainexperimentalresults,asdescribedinsupplemental
material?
Answer: [Yes]
Justification: Wesharecodeinazipfile. Notethatitisnotdirectlyexecutableasusersmust
directlyapplytophysionettogetaccesstotherawdatasetanduseanotherperson’srepoto
loadthedata.
Guidelines:
• TheanswerNAmeansthatpaperdoesnotincludeexperimentsrequiringcode.
• Please see the NeurIPS code and data submission guidelines (https://nips.cc/
public/guides/CodeSubmissionPolicy)formoredetails.
• Whileweencouragethereleaseofcodeanddata,weunderstandthatthismightnotbe
possible,so“No”isanacceptableanswer. Paperscannotberejectedsimplyfornot
includingcode,unlessthisiscentraltothecontribution(e.g.,foranewopen-source
benchmark).
• Theinstructionsshouldcontaintheexactcommandandenvironmentneededtorunto
reproducetheresults. SeetheNeurIPScodeanddatasubmissionguidelines(https:
//nips.cc/public/guides/CodeSubmissionPolicy)formoredetails.
• Theauthorsshouldprovideinstructionsondataaccessandpreparation,includinghow
toaccesstherawdata,preprocesseddata,intermediatedata,andgenerateddata,etc.
• Theauthorsshouldprovidescriptstoreproduceallexperimentalresultsforthenew
proposedmethodandbaselines. Ifonlyasubsetofexperimentsarereproducible,they
shouldstatewhichonesareomittedfromthescriptandwhy.
• Atsubmissiontime, topreserveanonymity, theauthorsshouldreleaseanonymized
versions(ifapplicable).
• Providingasmuchinformationaspossibleinsupplementalmaterial(appendedtothe
paper)isrecommended,butincludingURLstodataandcodeispermitted.
6. ExperimentalSetting/Details
Question: Doesthepaperspecifyallthetrainingandtestdetails(e.g.,datasplits,hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: WeshareourtrainingdetailsintheAppendix,andwesourceourdatasetsplit
fromareproducibilitystudyashighlightedinthetext.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotincludeexperiments.
• Theexperimentalsettingshouldbepresentedinthecoreofthepapertoalevelofdetail
thatisnecessarytoappreciatetheresultsandmakesenseofthem.
• Thefulldetailscanbeprovidedeitherwiththecode,inappendix,orassupplemental
material.
7. ExperimentStatisticalSignificance
Question:Doesthepaperreporterrorbarssuitablyandcorrectlydefinedorotherappropriate
informationaboutthestatisticalsignificanceoftheexperiments?
Answer: [Yes]
Justification: Wereport1-sigmaerror-barswhereapplicable. However,mostofourhuman
evaluationresultshavetoosmallofasamplesizetoreportadditionalerrorbarsasweonly
had2humanevaluators.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotincludeexperiments.
• Theauthorsshouldanswer"Yes"iftheresultsareaccompaniedbyerrorbars,confi-
denceintervals,orstatisticalsignificancetests,atleastfortheexperimentsthatsupport
themainclaimsofthepaper.
30• Thefactorsofvariabilitythattheerrorbarsarecapturingshouldbeclearlystated(for
example,train/testsplit,initialization,randomdrawingofsomeparameter,oroverall
runwithgivenexperimentalconditions).
• Themethodforcalculatingtheerrorbarsshouldbeexplained(closedformformula,
calltoalibraryfunction,bootstrap,etc.)
• Theassumptionsmadeshouldbegiven(e.g.,Normallydistributederrors).
• Itshouldbeclearwhethertheerrorbaristhestandarddeviationorthestandarderror
ofthemean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should
preferablyreporta2-sigmaerrorbarthanstatethattheyhavea96%CI,ifthehypothesis
ofNormalityoferrorsisnotverified.
• Forasymmetricdistributions,theauthorsshouldbecarefulnottoshowintablesor
figuressymmetricerrorbarsthatwouldyieldresultsthatareoutofrange(e.g. negative
errorrates).
• Iferrorbarsarereportedintablesorplots,Theauthorsshouldexplaininthetexthow
theywerecalculatedandreferencethecorrespondingfiguresortablesinthetext.
8. ExperimentsComputeResources
Question: Foreachexperiment,doesthepaperprovidesufficientinformationonthecom-
puterresources(typeofcomputeworkers,memory,timeofexecution)neededtoreproduce
theexperiments?
Answer: [Yes]
Justification: WehaveaddedacomputeresourcessectionintheAppendix.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotincludeexperiments.
• ThepapershouldindicatethetypeofcomputeworkersCPUorGPU,internalcluster,
orcloudprovider,includingrelevantmemoryandstorage.
• Thepapershouldprovidetheamountofcomputerequiredforeachoftheindividual
experimentalrunsaswellasestimatethetotalcompute.
• Thepapershoulddisclosewhetherthefullresearchprojectrequiredmorecompute
thantheexperimentsreportedinthepaper(e.g.,preliminaryorfailedexperimentsthat
didn’tmakeitintothepaper).
9. CodeOfEthics
Question: Doestheresearchconductedinthepaperconform, ineveryrespect, withthe
NeurIPSCodeofEthicshttps://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification: Ourhumanevaluatorsareourcollaboratorsandhaveundergoneaninternal
processforethicalreporting.
Guidelines:
• TheanswerNAmeansthattheauthorshavenotreviewedtheNeurIPSCodeofEthics.
• IftheauthorsanswerNo,theyshouldexplainthespecialcircumstancesthatrequirea
deviationfromtheCodeofEthics.
• Theauthorsshouldmakesuretopreserveanonymity(e.g.,ifthereisaspecialconsid-
erationduetolawsorregulationsintheirjurisdiction).
10. BroaderImpacts
Question: Does the paper discuss both potential positive societal impacts and negative
societalimpactsoftheworkperformed?
Answer: [NA]
Justification: Wefeltmuchofourworkwastoopreliminarytohavedirectconsequences.
However, we feel that improving the interpretability of these models will generally be
positiveasitsresearchisdirectlytiedtosafetyratherthanextraneousintents.
Guidelines:
31• TheanswerNAmeansthatthereisnosocietalimpactoftheworkperformed.
• IftheauthorsanswerNAorNo,theyshouldexplainwhytheirworkhasnosocietal
impactorwhythepaperdoesnotaddresssocietalimpact.
• Examplesofnegativesocietalimpactsincludepotentialmaliciousorunintendeduses
(e.g.,disinformation,generatingfakeprofiles,surveillance),fairnessconsiderations
(e.g.,deploymentoftechnologiesthatcouldmakedecisionsthatunfairlyimpactspecific
groups),privacyconsiderations,andsecurityconsiderations.
• Theconferenceexpectsthatmanypaperswillbefoundationalresearchandnottied
toparticularapplications,letalonedeployments. However,ifthereisadirectpathto
anynegativeapplications,theauthorsshouldpointitout. Forexample,itislegitimate
topointoutthatanimprovementinthequalityofgenerativemodelscouldbeusedto
generatedeepfakesfordisinformation. Ontheotherhand,itisnotneededtopointout
thatagenericalgorithmforoptimizingneuralnetworkscouldenablepeopletotrain
modelsthatgenerateDeepfakesfaster.
• Theauthorsshouldconsiderpossibleharmsthatcouldarisewhenthetechnologyis
being used as intended and functioning correctly, harms that could arise when the
technologyisbeingusedasintendedbutgivesincorrectresults,andharmsfollowing
from(intentionalorunintentional)misuseofthetechnology.
• Iftherearenegativesocietalimpacts,theauthorscouldalsodiscusspossiblemitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanismsformonitoringmisuse,mechanismstomonitorhowasystemlearnsfrom
feedbackovertime,improvingtheefficiencyandaccessibilityofML).
11. Safeguards
Question: Doesthepaperdescribesafeguardsthathavebeenputinplaceforresponsible
releaseofdataormodelsthathaveahighriskformisuse(e.g.,pretrainedlanguagemodels,
imagegenerators,orscrapeddatasets)?
Answer: [NA]
Justification: Ourmethodsareforinterpretabilityratherthangenerativepurposes.
Guidelines:
• TheanswerNAmeansthatthepaperposesnosuchrisks.
• Releasedmodelsthathaveahighriskformisuseordual-useshouldbereleasedwith
necessarysafeguardstoallowforcontrolleduseofthemodel,forexamplebyrequiring
thatusersadheretousageguidelinesorrestrictionstoaccessthemodelorimplementing
safetyfilters.
• DatasetsthathavebeenscrapedfromtheInternetcouldposesafetyrisks. Theauthors
shoulddescribehowtheyavoidedreleasingunsafeimages.
• Werecognizethatprovidingeffectivesafeguardsischallenging,andmanypapersdo
notrequirethis,butweencourageauthorstotakethisintoaccountandmakeabest
faitheffort.
12. Licensesforexistingassets
Question: Arethecreatorsororiginalownersofassets(e.g.,code,data,models),usedin
thepaper,properlycreditedandarethelicenseandtermsofuseexplicitlymentionedand
properlyrespected?
Answer: [Yes]
Justification: Wecitemanyofthebaselinesthatareusedinthispaper.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotuseexistingassets.
• Theauthorsshouldcitetheoriginalpaperthatproducedthecodepackageordataset.
• Theauthorsshouldstatewhichversionoftheassetisusedand,ifpossible,includea
URL.
• Thenameofthelicense(e.g.,CC-BY4.0)shouldbeincludedforeachasset.
• Forscrapeddatafromaparticularsource(e.g.,website),thecopyrightandtermsof
serviceofthatsourceshouldbeprovided.
32• If assets are released, the license, copyright information, and terms of use in the
packageshouldbeprovided. Forpopulardatasets,paperswithcode.com/datasets
hascuratedlicensesforsomedatasets. Theirlicensingguidecanhelpdeterminethe
licenseofadataset.
• Forexistingdatasetsthatarere-packaged,boththeoriginallicenseandthelicenseof
thederivedasset(ifithaschanged)shouldbeprovided.
• Ifthisinformationisnotavailableonline,theauthorsareencouragedtoreachoutto
theasset’screators.
13. NewAssets
Question:Arenewassetsintroducedinthepaperwelldocumentedandisthedocumentation
providedalongsidetheassets?
Answer: [Yes]
Justification:Wenotethatwewillbesubmittingcodewithoursubmission,anonymizedwith
abriefreadmefilehighlightingwheretolookforthedatarequiredtorunthecode. However,
we note much of the code should be pretty straightforward and are at least somewhat
documented.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotreleasenewassets.
• Researchersshouldcommunicatethedetailsofthedataset/code/modelaspartoftheir
submissions via structured templates. This includes details about training, license,
limitations,etc.
• Thepapershoulddiscusswhetherandhowconsentwasobtainedfrompeoplewhose
assetisused.
• Atsubmissiontime,remembertoanonymizeyourassets(ifapplicable). Youcaneither
createananonymizedURLorincludeananonymizedzipfile.
14. CrowdsourcingandResearchwithHumanSubjects
Question: Forcrowdsourcingexperimentsandresearchwithhumansubjects,doesthepaper
includethefulltextofinstructionsgiventoparticipantsandscreenshots,ifapplicable,as
wellasdetailsaboutcompensation(ifany)?
Answer: [Yes]
Justification: WesharethepromptswegiveourhumanannotatorsandLLMsintheAp-
pendix.
Guidelines:
• TheanswerNAmeansthatthepaperdoesnotinvolvecrowdsourcingnorresearchwith
humansubjects.
• Includingthisinformationinthesupplementalmaterialisfine,butifthemaincontribu-
tionofthepaperinvolveshumansubjects,thenasmuchdetailaspossibleshouldbe
includedinthemainpaper.
• AccordingtotheNeurIPSCodeofEthics,workersinvolvedindatacollection,curation,
orotherlaborshouldbepaidatleasttheminimumwageinthecountryofthedata
collector.
15. InstitutionalReviewBoard(IRB)ApprovalsorEquivalentforResearchwithHuman
Subjects
Question: Doesthepaperdescribepotentialrisksincurredbystudyparticipants,whether
suchrisksweredisclosedtothesubjects,andwhetherInstitutionalReviewBoard(IRB)
approvals(oranequivalentapproval/reviewbasedontherequirementsofyourcountryor
institution)wereobtained?
Answer: [Yes]
Justification: Sincetherearenorisksinthishumanstudywithourcollaborators,wenote
thattherewasnoneedforanIRBstudyaswearenotcrowdsourcinganything. Wehave
madeanoteofthisintheAppendix.
Guidelines:
33• TheanswerNAmeansthatthepaperdoesnotinvolvecrowdsourcingnorresearchwith
humansubjects.
• Dependingonthecountryinwhichresearchisconducted,IRBapproval(orequivalent)
mayberequiredforanyhumansubjectsresearch. IfyouobtainedIRBapproval,you
shouldclearlystatethisinthepaper.
• Werecognizethattheproceduresforthismayvarysignificantlybetweeninstitutions
andlocations,andweexpectauthorstoadheretotheNeurIPSCodeofEthicsandthe
guidelinesfortheirinstitution.
• Forinitialsubmissions,donotincludeanyinformationthatwouldbreakanonymity(if
applicable),suchastheinstitutionconductingthereview.
34