Multidimensional Deconvolution with Profiling
HuanbiaoZhu1 KrishDesai2,3 MikaelKuusela1
ViniciusMikuni4 BenjaminNachman3,5 LarryWasserman1
1DepartmentofStatisticsandDataScience,CarnegieMellonUniversity,Pittsburgh,PA15213,USA
2DepartmentofPhysics,UniversityofCalifornia,Berkeley,CA94720,USA
3PhysicsDivision,LawrenceBerkeleyNationalLaboratory,Berkeley,CA94720,USA
4NationalEnergyResearchScientificComputingCenter,BerkeleyLab,Berkeley,CA94720,USA
5BerkeleyInstituteforDataScience,UniversityofCalifornia,Berkeley,CA94720,USA
{huanbiaz,mkuusela}@andrew.cmu.edu
larry@stat.cmu.edu
krish.desai@berkeley.edu
{vmikuni,bpnachman}@lbl.gov
Abstract
Inmanyexperimentalcontexts,itisnecessarytostatisticallyremovetheimpact
ofinstrumentaleffectsinordertophysicallyinterpretmeasurements. Thistask
has been extensively studied in particle physics, where the deconvolution task
is called unfolding. A number of recent methods have shown how to perform
high-dimensional,unbinnedunfoldingusingmachinelearning. However,oneof
theassumptionsinallofthesemethodsisthatthedetectorresponseisaccurately
modeledintheMonteCarlosimulation. Inpractice,thedetectorresponsedepends
onanumberofnuisanceparametersthatcanbeconstrainedwithdata. Wepropose
anewalgorithmcalledProfileOmniFold(POF),whichworksinasimilariterative
mannerastheOmniFold(OF)algorithmwhilebeingabletosimultaneouslyprofile
thenuisanceparameters. WeillustratethemethodwithaGaussianexampleasa
proofofconcepthighlightingitspromisingcapabilities.
1 Introduction
Instrumentaleffectsdistortspectrafromtheirtruevalues. Statisticallyremovingthesedistortionsis
essentialforcomparingresultsacrossexperimentsandforfacilitatingbroad,detector-independent
analysisofthedata. Thisdeconvolutiontask(calledunfoldinginparticlephysics)isanill-posed
inverseproblem,wheresmallchangesinthemeasuredspectrumcanresultinlargefluctuationin
thereconstructedtruespectrum. Inpractice,oneobservesdatafromthemeasuredspectrumfrom
experiments,andthegoalisestimatethetruespectrumandquantifyitsuncertainty. Seee.g.[1–5]
forreviewsoftheproblem. Thedetailedsetupwillalsobeintroducedinsection2.1.
Traditionally,unfoldinghasbeensolvedindiscretizedsetting,wheremeasurementsarebinnedinto
histograms(orarenaturallyrepresentedasdiscrete,e.g. inimages)andthereconstructedspectrum
isalsorepresentedashistograms. However,thisrequirespre-specifyingthenumberofbins,which
itselfisatuningparameterandcanvarybetweendifferentexperiments. Additionally,binninglimits
thenumberofobservablesthatcanbesimultaneouslyunfolded.
Anumberofmachinelearning-basedapproacheshavebeenproposedtoaddressthisproblem[6,7].
Thefirstonetobedeployedtoexperimentaldata[8–18]isOmniFold[19,20]. Unliketraditional
methods,OmniFolddoesnotrequirebinningandcanbeusedtounfoldobservablesinmuchhigher
dimensions using neural network (NN) classifiers. The algorithm is an instance of Expectation-
Preprint.Underreview.
4202
peS
61
]hp-peh[
1v12401.9042:viXraMaximization(EM)algorithm,whichiterativelyreweightsthesimulatedeventstomatchtheexperi-
mentaldata. Theresultisguaranteedtoconvergetothemaximumlikelihoodestimate. However,one
limitationintheOmniFold,asinallmachinelearning-basedunfoldingmethods,istheassumption
thatthedetectorresponseiscorrectlymodeledinsimulation. 1 Inpractice,thisisonlyapproximately
true,withanumberofnuisanceparametersthatcanbeconstrainedbydata.
Recently, Ref. [21] introduced an unbinned unfolding method that also allows for profiling the
nuisance parameters. This is achieved by using machine learning to directly maximize the log-
likelihoodfunction. Whileasignificantstepforward,thisapproachislimitedtothecasewherethe
detector-leveldataarebinnedsothatonecanwritedowntheexplicitlikelihood(eachbinisPoisson
distributed).
Inthiswork,weproposeanewalgorithm,calledProfileOmniFold(POF),forunbinnedandprofiled
unfolding. UnlikeRef.[21],POFiscompletelyunbinnedatboththedetector-levelandpre-detector-
level(‘particlelevel’). Additionally,POFcanbeseenasanextensiontotheoriginalOFalgorithm
thatiterativelyreweightsthesimulatedparticle-leveleventsbutalsosimultaneouslydeterminesthe
nuisanceparameters.
2 Methodology
Inthissection,weintroducePOF,whichisamodifiedversionoftheoriginalOFalgorithm. Sameas
theoriginalOF,thegoalofPOFistofindthemaximumlikelihoodestimateofthereweightingfunction
thatreweightsgeneratedparticle-leveldataq(x)tothetruthp(x). However,unlikeintheoriginal
OFalgorithm,POFcanalsotakeintoaccountofthenuisanceparametersinthedetectormodeling
andsimultaneouslyprofileoutthesenuisanceparameters. Atthesametime,POFretainsthesame
benefitsasOFsuchthatitcandirectlyworkwithunbinneddata,utilizethepowerofNNclassifiers,
andunfoldmultidimensionalobservablesoreventheentirephasespacesimultaneously[19].
2.1 Statisticalsetupoftheunfoldingprobleminthepresenceofnuisanceparameter
Inunfoldingproblem,weareprovidedpairsofMonteCarlo(MC)simulation{X ,Y }n ∼q(x,y)
i i i=1
whereX denotetheparticle-levelquantityandY denotethecorrespondingdetector-levelobservation.
i i
Thengivenasetofobserveddetector-levelexperimentaldata{Y′}m ∼p(y),ourgoalistoestimate
i i=1
thetrueparticle-leveldensityp(x). TheforwardmodelforbothMCsimulationandexperimental
dataaredescribedby
(cid:90) (cid:90)
q(y)= q(y|x)q(x)dx, p(y)= p(y|x)p(x)dx (1)
where q(y|x) and p(y|x) are the kernels that model the detector responses. In practice, different
detectorconfigurationsyielddifferentdetectorresponses,soitisoftenthecasethatq(y|x)̸=p(y|x).
Additionally, the response kernel is assumed to be parametrized by some nuisance parameters θ,
whicharegivenfortheMCdatabutunknownfortheexperimentaldata.
Giventhissetup,letν(x)beareweightingfunctionontheMCparticle-leveldensityq(x). Ultimately,
wewantν(x) ≈ p(x)/q(x). Letw(y,x,θ)beareweightingfunctionontheMCresponsekernel
q(y|x),i.e. q(y|x)(cid:55)→q(y|x)×w(y,x,θ). Also,supposeq(y|x)isspecifiedbynuisanceparameter
θ ,i.e. q(y|x)=p(y|x,θ ). Thenthegoalistomaximizethepenalizedlog-likelihood
0 0
(cid:90)
ℓ(ν,θ)= p(y)logp(y|ν,θ)dy+logp (θ)
0
(2)
(cid:90)
subjectto ν(x)q(x)dx=1.
p (θ) is the prior on θ to constrain the nuisance parameter, usually determined from auxiliary
0
measurements. Inourcase,weusethestandardizedGaussianprior,logp
(θ)=−∥θ−θ0∥2
.
0 2
1By’correctlymodeled,’wemeanthatboththeparametricmodelforthedetectorresponseandthenuisance
parametersarecorrectlyspecified.
22.2 Algorithm
ThePOFalgorithm,liketheoriginalOFalgorithm,isanEMalgorithm. Ititerativelyupdatesthe
reweightingfunctionν(x)andnuisanceparameterθtowardsthemaximumlikelihoodestimate. The
keyintheEMalgorithmistheQfunction,whichisthecompletedata(x,y)expectedlog-likelihood
given the observed data (y) and current parameter estimates (ν(k),θ(k)). For the log-likelihood
specifiedin(2),theQfunctionisgivenby
(cid:90) (cid:90)
Q(ν,θ|ν(k),θ(k))= p(y) p(x|y,ν(k),θ(k))logp(y,x|ν,θ)dxdy+logp (θ)
0
(3)
(cid:90)
subjectto ν(x)q(x)dx=1.
The E-step in the EM algorithm is to compute the Q function and M-step is to maximize over
ν and θ. The maximizer will then be used as the updated parameter values in the next iteration.
Specifically,inthekthiteration,weobtaintheupdate(ν(k+1),θ(k+1))bysolving(ν(k+1),θ(k+1))=
argmax Q(ν,θ|ν(k),θ(k)). Itturnsoutthatwecansolvethisoptimizationprobleminthreesteps:
ν,θ
1. r(k)(y)= p(y)
q˜(y)
whereq˜(y)=(cid:82) w(y,x,θ(k))ν(k)(x)q(y,x)dx
2. ν(k+1)(x)=ν(k)(x)q˜(x)
q(x)
where q˜(x)=(cid:82) w(y,x,θ(k))r(k)(y)q(y,x)dy
3. Findθ(k+1)suchthatθ(k+1)−θ =(cid:82) (cid:82) q(y,x)w(y,x,θ(k))ν(k)(x)w˙(y,x,θ(k+1))r(k)(y)dxdy
0 w(y,x,θ(k+1))
ThefirststepisthesameasthefirststepintheoriginalOFalgorithm,whichinvolvescomputing
theratioofthedetector-levelexperimentaldensityandreweighteddetector-levelMCdensityusing
thepush-forwardweightsofw(y,x,θ(k))ν(k)(x). Thedensityratiocanbeestimatedbytraining
aNNclassifiertodistinguishbetweentheexperimentaldatadistributionp(y)andreweightedMC
distributionq˜(y).
ThesecondstepalsocloselymirrorsthesecondstepoftheoriginalOFalgorithm,whichinvolves
computing the ratio of the reweighted particle-level MC density using the pull-back weights of
w(y,x,θ(k))r(k)(y)andtheparticle-levelMCdensity.
Thethirdstepinvolvesupdatingthenuisanceparameterthroughnumericaloptimization. Theright-
handsideoftheequationismoreinvolved,sinceitrequirescomputing w˙(y,x,θ),wherew˙(y,x,θ)is
w(y,x,θ)
thederivativeofw(y,x,θ)withrespecttoθ. Fortunately,Ref.[21]showsthatthedependencyof
w(y,x,θ)onθcanbelearnedbyfirstpre-trainingw(y,x,θ)throughneuralconditionalreweight-
ing[22]usinganothersetofsyntheticdata(X ,Y ,θ ). Then,thetrainednetworkprovidesestimates
i i i
forbothw(y,x,θ)anditsderivativew˙(y,x,θ). Additionally,w(y,x,θ(k)),ν(k)(x),r(k)(y)haveall
beencomputedintheprevioussteps. Finally,theintegralisoverthejointdistributionq(y,x)sowe
canjustusetheempiricalaveragetoobtaintheestimate.
Insummary,thePOFalgorithmextendstheoriginalOFbyincludinganadditionalstepforupdating
thenuisanceparameter. However,unlikeOF,POFonlyhastheguaranteedconvergencetooneofthe
localmaximaofthepenalizedlikelihoodsincethelikelihoodmightnotbeunimodal. Thealgorithm
iteratesthroughthesethreestepsforafinitenumberofiterations, typicallyfewerthan10. Early
stoppingisoftenusedtohelpregularizethesolution.
3 GaussianExample
We illustrate the POF algorithm with a simple Gaussian example. Consider a one-dimensional
Gaussiandistributionattheparticlelevelandtwo-dimensionalGaussiandistributionsatthedetector
level. Thedataaregeneratedasfollows:
Y =X +Z ,
i1 i i1
Y =X +Z
i2 i i2
3whereX ∼N(µ,σ),Z ∼N(0,1),Z ∼N(0,θ). Here,θisthenuisanceparameter,whichonly
i i1 i2
affectstheseconddimensionofthedetector-leveldata. Thisisqualitativelysimilartothephysical
caseofbeingabletomeasurethesamequantitytwice. Sincetheresponsekernelinthiscaseisa
Gaussiandensity,wehaveaccesstotheanalyticalformp(y|x,θ)and,consequently,w(y,x,θ)as
well. Forsimplicity,weusetheanalyticformdirectlyinthealgorithmforthisexample. However,
evenifwedonotknowtheanalyticalform,wecanpre-trainw(y,x,θ)asdescribedinSec.2.2.
Dataset Basedontheabovedatageneratingprocess,MonteCarlodataaregeneratedwithµ =
0,σ =1,θ =1andexperimentaldataaregeneratedwithµ=0.8,σ =1,θ =1.5. Wesimulate105
eventseachfortheMCdataandexperimentaldata.
Neuralnetworkarchitectureandtraining Theneuralnetworkclassifierforestimatingthedensity
ratioisimplementedusingTensorFlowandKeras. Thenetworkcontainsthreehiddenlayerswith50
nodesperlayerandemploysReLUactivationfunction. Theoutputlayerconsistsofasinglenode
withasigmoidactivationfunction. ThenetworkistrainedusingAdamoptimizer[23]tominimize
theweightedbinarycrossentropyloss. Thenetworkistrainedfor10epochswithabatchsizeof
10000. Noneoftheseparameterswereoptimizedforthisproofofconceptdemonstration. Alltraining
wasperformingonanNVIDIAA100GraphicalProcessingUnit(GPU),takingnomorethan10
minutes.
Figure1: Resultsofunfolding2DGaussianexample. Left: Theunfoldedparticle-leveldensityusing
POF(orange)andOF(blue), withbothalgorithmsrunningfor5iterations. Top-right: Unfolded
spectrumaggregatedinto80bins. Bottom-right: Ratiooftheunfoldedspectrumtothetruthspectrum.
3.1 Result
Figure1illustratestheresultsofunfolding2DGaussiandatausingboththeproposedPOFalgorithm
andtheoriginalOFalgorithm.ThecyanlineistheMonteCarlodistributionforwhichthereweighting
function would be applied. The results show that the original OF algorithm (blue line) deviates
significantlyfromthetruedistribution(blackline). ThisdiscrepancyarisesbecauseOFassumes
p(y|x) = q(y|x), an assumption that is invalid in the presence of incorrectly specified nuisance
parameters. Ontheotherhand,POFalgorithmsimultaneouslyoptimizesthenuisanceparameter
alongwiththereweightingfunction. Theresultsshowthattheunfoldedsolution(orangeline)aligns
closelywiththetruth(blackline)andthefittednuisanceparameterisθ = 1.48(trueparameteris
1.50). Futureworkwilldeploystandardtechniqueslikebootstrappingtodetermineuncertainties.
4 Conclusion
In this work, we have proposed a new algorithm called POF, which uses machine learning to
performunfoldingwhilealsosimultaneouslyprofilingoutthenuisanceparameters. Thisrelaxesthe
assumptionintheoriginalOFthatthedetectorresponseneedstobeaccuratelymodeledintheMonte
Carlosimulationandconstrainthenuisanceparameterinadata-drivenway. Atthesametime,the
4proposedalgorithmstillsharessimilarstepsasintheOF,whichiseasytoimplementandpreserving
itsbenefits.
TheresultsfromthesimpleGaussianexampledemonstratethealgorithm’spromisingperformance.
Our next objective is to apply POF to more realistic examples and include critical studies like
robustness,stability,anduncertaintyquantification.
Acknowledgments
We thank Jesse Thaler for many useful discussions about OmniFold and related subjects as well
as feedback on the manuscript. KD, VM, BN, and HZ are supported by the U.S. Department
of Energy (DOE), Office of Science under contract DE-AC02-05CH11231. This research used
resourcesoftheNationalEnergyResearchScientificComputingCenter,aDOEOfficeofScience
UserFacilitysupportedbytheOfficeofScienceoftheU.S.DepartmentofEnergyunderContract
No. DE-AC02-05CH11231usingNERSCawardHEP-ERCAP0021099.
References
[1] RahulBalasubramanian,LydiaBrenner,CarstenBurgard,GlenCowan,VincentCroft,Wouter
Verkerke, and Pim Verschuuren. Statistical method and comparison of different unfolding
techniquesusingRooFit. 2019.
[2] VolkerBlobel. UnfoldingMethodsinParticlePhysics. PHYSTAT2011Proceedings,page240,
2011. doi: 10.5170/CERN-2011-006.
[3] Volker Blobel. Unfolding. Data Analysis in High Energy Physics, page 187, 2013. doi:
10.1002/9783527653416.ch6. URL https://onlinelibrary.wiley.com/doi/abs/10.
1002/9783527653416.ch6.
[4] G.Cowan. Asurveyofunfoldingmethodsforparticlephysics. Conf.Proc.,C0203181:248,
2002.
[5] Mikael Kuusela. Statistical issues in unfolding methods for high energy physics.
Aalto University Master’s Thesis, 2012. URL https://www.semanticscholar.
org/paper/Statistical-Issues-in-Unfolding-Methods-for-High-Kuusela/
d15ab0dbbeced6043cfb15d99a96e553eddadc3d.
[6] Miguel Arratia et al. Publishing unbinned differential cross section results. JINST, 17(01):
P01024,2022. doi: 10.1088/1748-0221/17/01/P01024.
[7] NathanHuetschetal. TheLandscapeofUnfoldingwithMachineLearning. 42024.
[8] V.Andreevetal. Measurementoflepton-jetcorrelationindeep-inelasticscatteringwiththeH1
detectorusingmachinelearningforunfolding. 82021.
[9] H1 Collaboration. Machine learning-assisted measurement of multi-differential lepton-
jet correlations in deep-inelastic scattering with the H1 detector. H1prelim-22-
031, 2022. URL https://www-h1.desy.de/h1/www/publications/htmlsplit/
H1prelim-22-031.long.html.
[10] V. Andreev et al. Unbinned Deep Learning Jet Substructure Measurement in High Q2 ep
collisionsatHERA. 32023.
[11] H1Collaboration. Machinelearning-assistedmeasurementofazimuthalangularasymmetries
in deep-inelastic scattering with the H1 detector. H1prelim-23-031, 2023. URL https://
www-h1.desy.de/h1/www/publications/htmlsplit/H1prelim-23-031.long.html.
[12] MultidifferentialstudyofidentifiedchargedhadrondistributionsinZ-taggedjetsinproton-
√
protoncollisionsat s=13TeV. 82022.
[13] PatrickT.Komiske,SerhiiKryhin,andJesseThaler. DisentanglingQuarksandGluonsinCMS
OpenData. Phys.Rev.D,106(9):094021,2022. doi: 10.1103/PhysRevD.106.094021.
5[14] YouqiSong. MeasurementofCollinearDropjetmassanditscorrelationwithSoftDropgroomed
√
jetsubstructureobservablesin s=200GeVppcollisionsbySTAR. 72023.
√
[15] TanmayPani. GeneralizedangularitiesmeasurementsfromSTARat SNN=200GeV. EPJ
WebConf.,296:11003,2024. doi: 10.1051/epjconf/202429611003.
[16] Measurementofeventshapesinminimumbiaseventsfromppcollisionsat13TeV. Technical
report,CERN,Geneva,2024. URLhttps://cds.cern.ch/record/2899591.
[17] GeorgesAadetal. Asimultaneousunbinneddifferentialcrosssectionmeasurementoftwenty-
fourZ+jetskinematicobservableswiththeATLASdetector. 52024.
[18] MeasurementofTrackFunctionsinATLASRun2Data. 2024.
[19] Anders Andreassen, Patrick T. Komiske, Eric M. Metodiev, Benjamin Nachman, and Jesse
Thaler. Omnifold: Amethodtosimultaneouslyunfoldallobservables. PhysicsReivewLetter,
124,2020.
[20] AndersAndreassen,PatrickT.Komiske,EricM.Metodiev,BenjaminNachman,AdiSuresh,and
JesseThaler. ScaffoldingSimulationswithDeepLearningforHigh-dimensionalDeconvolution.
In9thInternationalConferenceonLearningRepresentations,52021.
[21] JayChanandBenjaminNachman. UnbinnedProfiledUnfolding. PhysicalReviewD,2023.
doi: https://doi.org/10.1103/PhysRevD.108.016002.
[22] BenNachmanandJesseThaler. Neuralconditionalreweighting. PhysicalReviewD,105,2022.
[23] DiederikP.KingmaandJimmyBa. Adam: Amethodforstochasticoptimization,2017. URL
https://arxiv.org/abs/1412.6980.
6