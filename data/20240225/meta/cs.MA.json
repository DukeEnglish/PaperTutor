[
    {
        "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health",
        "authors": "Nikhil BehariEdwin ZhangYunfan ZhaoAparna TanejaDheeraj NagarajMilind Tambe",
        "links": "http://arxiv.org/abs/2402.14807v1",
        "entry_id": "http://arxiv.org/abs/2402.14807v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14807v1",
        "summary": "Efforts to reduce maternal mortality rate, a key UN Sustainable Development\ntarget (SDG Target 3.1), rely largely on preventative care programs to spread\ncritical health information to high-risk populations. These programs face two\nimportant challenges: efficiently allocating limited health resources to large\nbeneficiary populations, and adapting to evolving policy priorities. While\nprior works in restless multi-armed bandit (RMAB) demonstrated success in\npublic health allocation tasks, they lack flexibility to adapt to evolving\npolicy priorities. Concurrently, Large Language Models (LLMs) have emerged as\nadept, automated planners in various domains, including robotic control and\nnavigation. In this paper, we propose DLM: a Decision Language Model for RMABs.\nTo enable dynamic fine-tuning of RMAB policies for challenging public health\nsettings using human-language commands, we propose using LLMs as automated\nplanners to (1) interpret human policy preference prompts, (2) propose code\nreward functions for a multi-agent RL environment for RMABs, and (3) iterate on\nthe generated reward using feedback from RMAB simulations to effectively adapt\npolicy outcomes. In collaboration with ARMMAN, an India-based public health\norganization promoting preventative care for pregnant mothers, we conduct a\nsimulation study, showing DLM can dynamically shape policy outcomes using only\nhuman language commands as input.",
        "updated": "2024-02-22 18:58:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14807v1"
    },
    {
        "title": "AgentScope: A Flexible yet Robust Multi-Agent Platform",
        "authors": "Dawei GaoZitao LiWeirui KuangXuchen PanDaoyuan ChenZhijian MaBingchen QianLiuyi YaoLin ZhuChen ChengHongzhu ShiYaliang LiBolin DingJingren Zhou",
        "links": "http://arxiv.org/abs/2402.14034v1",
        "entry_id": "http://arxiv.org/abs/2402.14034v1",
        "pdf_url": "http://arxiv.org/pdf/2402.14034v1",
        "summary": "With the rapid advancement of Large Language Models (LLMs), significant\nprogress has been made in multi-agent applications. However, the complexities\nin coordinating agents' cooperation and LLMs' erratic performance pose notable\nchallenges in developing robust and efficient multi-agent applications. To\ntackle these challenges, we propose AgentScope, a developer-centric multi-agent\nplatform with message exchange as its core communication mechanism. Together\nwith abundant syntactic tools, built-in resources, and user-friendly\ninteractions, our communication mechanism significantly reduces the barriers to\nboth development and understanding. Towards robust and flexible multi-agent\napplication, AgentScope provides both built-in and customizable fault tolerance\nmechanisms while it is also armed with system-level supports for multi-modal\ndata generation, storage and transmission. Additionally, we design an\nactor-based distribution framework, enabling easy conversion between local and\ndistributed deployments and automatic parallel optimization without extra\neffort. With these features, AgentScope empowers developers to build\napplications that fully realize the potential of intelligent agents. We have\nreleased AgentScope at https://github.com/modelscope/agentscope, and hope\nAgentScope invites wider participation and innovation in this fast-moving\nfield.",
        "updated": "2024-02-21 04:11:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.14034v1"
    },
    {
        "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning Framework for Intervention Strategies",
        "authors": "Ammar N. AbbasChidera W. AmazuJoseph MietkiewiczHouda BriwaAndres Alonzo PerezGabriele BaldissoneMicaela DemichelaGeorgios G. ChasparisJohn D. KelleherMaria Chiara Leva",
        "links": "http://arxiv.org/abs/2402.13219v1",
        "entry_id": "http://arxiv.org/abs/2402.13219v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13219v1",
        "summary": "In complex industrial and chemical process control rooms, effective\ndecision-making is crucial for safety and efficiency. The experiments in this\npaper evaluate the impact and applications of an AI-based decision support\nsystem integrated into an improved human-machine interface, using dynamic\ninfluence diagrams, a hidden Markov model, and deep reinforcement learning. The\nenhanced support system aims to reduce operator workload, improve situational\nawareness, and provide different intervention strategies to the operator\nadapted to the current state of both the system and human performance. Such a\nsystem can be particularly useful in cases of information overload when many\nalarms and inputs are presented all within the same time window, or for junior\noperators during training. A comprehensive cross-data analysis was conducted,\ninvolving 47 participants and a diverse range of data sources such as\nsmartwatch metrics, eye-tracking data, process logs, and responses from\nquestionnaires. The results indicate interesting insights regarding the\neffectiveness of the approach in aiding decision-making, decreasing perceived\nworkload, and increasing situational awareness for the scenarios considered.\nAdditionally, the results provide valuable insights to compare differences\nbetween styles of information gathering when using the system by individual\nparticipants. These findings are particularly relevant when predicting the\noverall performance of the individual participant and their capacity to\nsuccessfully handle a plant upset and the alarms connected to it using process\nand human-machine interaction logs in real-time. These predictions enable the\ndevelopment of more effective intervention strategies.",
        "updated": "2024-02-20 18:31:27 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13219v1"
    },
    {
        "title": "A Conflict-Aware Optimal Goal Assignment Algorithm for Multi-Robot Systems",
        "authors": "AakashIndranil Saha",
        "links": "http://arxiv.org/abs/2402.13292v1",
        "entry_id": "http://arxiv.org/abs/2402.13292v1",
        "pdf_url": "http://arxiv.org/pdf/2402.13292v1",
        "summary": "The fundamental goal assignment problem for a multi-robot application aims to\nassign a unique goal to each robot while ensuring collision-free paths,\nminimizing the total movement cost. A plausible algorithmic solution to this\nNP-hard problem involves an iterative process that integrates a task planner to\ncompute the goal assignment while ignoring the collision possibilities among\nthe robots and a multi-agent path-finding algorithm to find the collision-free\ntrajectories for a given assignment. This procedure involves a method for\ncomputing the next best assignment given the current best assignment. A naive\nway of computing the next best assignment, as done in the state-of-the-art\nsolutions, becomes a roadblock to achieving scalability in solving the overall\nproblem. To obviate this bottleneck, we propose an efficient conflict-guided\nmethod to compute the next best assignment. Additionally, we introduce two more\noptimizations to the algorithm -- first for avoiding the unconstrained path\ncomputations between robot-goal pairs wherever possible, and the second to\nprevent duplicate constrained path computations for multiple robot-goal pairs.\nWe extensively evaluate our algorithm for up to a hundred robots on several\nbenchmark workspaces. The results demonstrate that the proposed algorithm\nachieves nearly an order of magnitude speedup over the state-of-the-art\nalgorithm, showcasing its efficacy in real-world scenarios.",
        "updated": "2024-02-19 19:04:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.13292v1"
    },
    {
        "title": "Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents",
        "authors": "Zengqing WuShuyuan ZhengQianying LiuXu HanBrian Inhyuk KwonMakoto OnizukaShaojie TangRun PengChuan Xiao",
        "links": "http://arxiv.org/abs/2402.12327v1",
        "entry_id": "http://arxiv.org/abs/2402.12327v1",
        "pdf_url": "http://arxiv.org/pdf/2402.12327v1",
        "summary": "Recent advancements have shown that agents powered by large language models\n(LLMs) possess capabilities to simulate human behaviors and societal dynamics.\nHowever, the potential for LLM agents to spontaneously establish collaborative\nrelationships in the absence of explicit instructions has not been studied. To\naddress this gap, we conduct three case studies, revealing that LLM agents are\ncapable of spontaneously forming collaborations even within competitive\nsettings. This finding not only demonstrates the capacity of LLM agents to\nmimic competition and cooperation in human societies but also validates a\npromising vision of computational social science. Specifically, it suggests\nthat LLM agents could be utilized to model human social interactions, including\nthose with spontaneous collaborations, thus offering insights into social\nphenomena. The source codes for this study are available at\nhttps://github.com/wuzengqing001225/SABM_ShallWeTalk .",
        "updated": "2024-02-19 18:00:53 UTC",
        "interpretation": "解释内容未找到",
        "id": "2402.12327v1"
    }
]