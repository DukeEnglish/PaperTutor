[
    {
        "title": "Variational Bayesian Last Layers",
        "authors": "James HarrisonJohn WillesJasper Snoek",
        "links": "http://arxiv.org/abs/2404.11599v1",
        "entry_id": "http://arxiv.org/abs/2404.11599v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11599v1",
        "summary": "We introduce a deterministic variational formulation for training Bayesian\nlast layer neural networks. This yields a sampling-free, single-pass model and\nloss that effectively improves uncertainty estimation. Our variational Bayesian\nlast layer (VBLL) can be trained and evaluated with only quadratic complexity\nin last layer width, and is thus (nearly) computationally free to add to\nstandard architectures. We experimentally investigate VBLLs, and show that they\nimprove predictive accuracy, calibration, and out of distribution detection\nover baselines across both regression and classification. Finally, we\ninvestigate combining VBLL layers with variational Bayesian feature learning,\nyielding a lower variance collapsed variational inference method for Bayesian\nneural networks.",
        "updated": "2024-04-17 17:50:24 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11599v1"
    },
    {
        "title": "Decomposing and Editing Predictions by Modeling Model Computation",
        "authors": "Harshay ShahAndrew IlyasAleksander Madry",
        "links": "http://arxiv.org/abs/2404.11534v1",
        "entry_id": "http://arxiv.org/abs/2404.11534v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11534v1",
        "summary": "How does the internal computation of a machine learning model transform\ninputs into predictions? In this paper, we introduce a task called component\nmodeling that aims to address this question. The goal of component modeling is\nto decompose an ML model's prediction in terms of its components -- simple\nfunctions (e.g., convolution filters, attention heads) that are the \"building\nblocks\" of model computation. We focus on a special case of this task,\ncomponent attribution, where the goal is to estimate the counterfactual impact\nof individual components on a given prediction. We then present COAR, a\nscalable algorithm for estimating component attributions; we demonstrate its\neffectiveness across models, datasets, and modalities. Finally, we show that\ncomponent attributions estimated with COAR directly enable model editing across\nfive tasks, namely: fixing model errors, ``forgetting'' specific classes,\nboosting subpopulation robustness, localizing backdoor attacks, and improving\nrobustness to typographic attacks. We provide code for COAR at\nhttps://github.com/MadryLab/modelcomponents .",
        "updated": "2024-04-17 16:28:08 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11534v1"
    },
    {
        "title": "VC Theory for Inventory Policies",
        "authors": "Yaqi XieWill MaLinwei Xin",
        "links": "http://arxiv.org/abs/2404.11509v1",
        "entry_id": "http://arxiv.org/abs/2404.11509v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11509v1",
        "summary": "Advances in computational power and AI have increased interest in\nreinforcement learning approaches to inventory management. This paper provides\na theoretical foundation for these approaches and investigates the benefits of\nrestricting to policy structures that are well-established by decades of\ninventory theory. In particular, we prove generalization guarantees for\nlearning several well-known classes of inventory policies, including base-stock\nand (s, S) policies, by leveraging the celebrated Vapnik-Chervonenkis (VC)\ntheory. We apply the concepts of the Pseudo-dimension and Fat-shattering\ndimension from VC theory to determine the generalizability of inventory\npolicies, that is, the difference between an inventory policy's performance on\ntraining data and its expected performance on unseen data. We focus on a\nclassical setting without contexts, but allow for an arbitrary distribution\nover demand sequences and do not make any assumptions such as independence over\ntime. We corroborate our supervised learning results using numerical\nsimulations.\n  Managerially, our theory and simulations translate to the following insights.\nFirst, there is a principle of \"learning less is more\" in inventory management:\ndepending on the amount of data available, it may be beneficial to restrict\noneself to a simpler, albeit suboptimal, class of inventory policies to\nminimize overfitting errors. Second, the number of parameters in a policy class\nmay not be the correct measure of overfitting error: in fact, the class of\npolicies defined by T time-varying base-stock levels exhibits a generalization\nerror comparable to that of the two-parameter (s, S) policy class. Finally, our\nresearch suggests situations in which it could be beneficial to incorporate the\nconcepts of base-stock and inventory position into black-box learning machines,\ninstead of having these machines directly learn the order quantity actions.",
        "updated": "2024-04-17 16:05:03 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11509v1"
    },
    {
        "title": "Randomly Pivoted Partial Cholesky: Random How?",
        "authors": "Stefan Steinerberger",
        "links": "http://arxiv.org/abs/2404.11487v1",
        "entry_id": "http://arxiv.org/abs/2404.11487v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11487v1",
        "summary": "We consider the problem of finding good low rank approximations of symmetric,\npositive-definite $A \\in \\mathbb{R}^{n \\times n}$. Chen-Epperly-Tropp-Webber\nshowed, among many other things, that the randomly pivoted partial Cholesky\nalgorithm that chooses the $i-$th row with probability proportional to the\ndiagonal entry $A_{ii}$ leads to a universal contraction of the trace norm (the\nSchatten 1-norm) in expectation for each step. We show that if one chooses the\n$i-$th row with likelihood proportional to $A_{ii}^2$ one obtains the same\nresult in the Frobenius norm (the Schatten 2-norm). Implications for the greedy\npivoting rule and pivot selection strategies are discussed.",
        "updated": "2024-04-17 15:45:31 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11487v1"
    },
    {
        "title": "The Causal Chambers: Real Physical Systems as a Testbed for AI Methodology",
        "authors": "Juan L. GamellaJonas PetersPeter Bühlmann",
        "links": "http://arxiv.org/abs/2404.11341v1",
        "entry_id": "http://arxiv.org/abs/2404.11341v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11341v1",
        "summary": "In some fields of AI, machine learning and statistics, the validation of new\nmethods and algorithms is often hindered by the scarcity of suitable real-world\ndatasets. Researchers must often turn to simulated data, which yields limited\ninformation about the applicability of the proposed methods to real problems.\nAs a step forward, we have constructed two devices that allow us to quickly and\ninexpensively produce large datasets from non-trivial but well-understood\nphysical systems. The devices, which we call causal chambers, are\ncomputer-controlled laboratories that allow us to manipulate and measure an\narray of variables from these physical systems, providing a rich testbed for\nalgorithms from a variety of fields. We illustrate potential applications\nthrough a series of case studies in fields such as causal discovery,\nout-of-distribution generalization, change point detection, independent\ncomponent analysis, and symbolic regression. For applications to causal\ninference, the chambers allow us to carefully perform interventions. We also\nprovide and empirically validate a causal model of each chamber, which can be\nused as ground truth for different tasks. All hardware and software is made\nopen source, and the datasets are publicly available at causalchamber.org or\nthrough the Python package causalchamber.",
        "updated": "2024-04-17 13:00:52 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11341v1"
    }
]