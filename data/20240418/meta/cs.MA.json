[
    {
        "title": "Distributed Fractional Bayesian Learning for Adaptive Optimization",
        "authors": "Yaqun YangJinlong LeiGuanghui WenYiguang Hong",
        "links": "http://arxiv.org/abs/2404.11354v1",
        "entry_id": "http://arxiv.org/abs/2404.11354v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11354v1",
        "summary": "This paper considers a distributed adaptive optimization problem, where all\nagents only have access to their local cost functions with a common unknown\nparameter, whereas they mean to collaboratively estimate the true parameter and\nfind the optimal solution over a connected network. A general mathematical\nframework for such a problem has not been studied yet. We aim to provide\nvaluable insights for addressing parameter uncertainty in distributed\noptimization problems and simultaneously find the optimal solution. Thus, we\npropose a novel Prediction while Optimization scheme, which utilizes\ndistributed fractional Bayesian learning through weighted averaging on the\nlog-beliefs to update the beliefs of unknown parameters, and distributed\ngradient descent for renewing the estimation of the optimal solution. Then\nunder suitable assumptions, we prove that all agents' beliefs and decision\nvariables converge almost surely to the true parameter and the optimal solution\nunder the true parameter, respectively. We further establish a sublinear\nconvergence rate for the belief sequence. Finally, numerical experiments are\nimplemented to corroborate the theoretical analysis.",
        "updated": "2024-04-17 13:09:33 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11354v1"
    },
    {
        "title": "Circular Distribution of Agents using Convex Layers",
        "authors": "Gautam KumarAshwini Ratnoo",
        "links": "http://arxiv.org/abs/2404.11351v1",
        "entry_id": "http://arxiv.org/abs/2404.11351v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11351v1",
        "summary": "This paper considers the problem of conflict-free distribution of agents on a\ncircular periphery encompassing all agents. The two key elements of the\nproposed policy include the construction of a set of convex layers (nested\nconvex polygons) using the initial positions of the agents, and a novel search\nspace region for each of the agents. The search space for an agent on a convex\nlayer is defined as the region enclosed between the lines passing through the\nagent's position and normal to its supporting edges. Guaranteeing\ncollision-free paths, a goal assignment policy designates a unique goal\nposition within the search space of an agent. In contrast to the existing\nliterature, this work presents a one-shot, collision-free solution to the\ncircular distribution problem by utilizing only the initial positions of the\nagents. Illustrative examples demonstrate the effectiveness of the proposed\npolicy.",
        "updated": "2024-04-17 13:08:49 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11351v1"
    },
    {
        "title": "Self-adaptive PSRO: Towards an Automatic Population-based Game Solver",
        "authors": "Pengdeng LiShuxin LiChang YangXinrun WangXiao HuangHau ChanBo An",
        "links": "http://arxiv.org/abs/2404.11144v1",
        "entry_id": "http://arxiv.org/abs/2404.11144v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11144v1",
        "summary": "Policy-Space Response Oracles (PSRO) as a general algorithmic framework has\nachieved state-of-the-art performance in learning equilibrium policies of\ntwo-player zero-sum games. However, the hand-crafted hyperparameter value\nselection in most of the existing works requires extensive domain knowledge,\nforming the main barrier to applying PSRO to different games. In this work, we\nmake the first attempt to investigate the possibility of self-adaptively\ndetermining the optimal hyperparameter values in the PSRO framework. Our\ncontributions are three-fold: (1) Using several hyperparameters, we propose a\nparametric PSRO that unifies the gradient descent ascent (GDA) and different\nPSRO variants. (2) We propose the self-adaptive PSRO (SPSRO) by casting the\nhyperparameter value selection of the parametric PSRO as a hyperparameter\noptimization (HPO) problem where our objective is to learn an HPO policy that\ncan self-adaptively determine the optimal hyperparameter values during the\nrunning of the parametric PSRO. (3) To overcome the poor performance of online\nHPO methods, we propose a novel offline HPO approach to optimize the HPO policy\nbased on the Transformer architecture. Experiments on various two-player\nzero-sum games demonstrate the superiority of SPSRO over different baselines.",
        "updated": "2024-04-17 07:40:57 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11144v1"
    },
    {
        "title": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs",
        "authors": "Kang WangZhishu ShenZhen LeiTiehua Zhang",
        "links": "http://arxiv.org/abs/2404.11014v1",
        "entry_id": "http://arxiv.org/abs/2404.11014v1",
        "pdf_url": "http://arxiv.org/pdf/2404.11014v1",
        "summary": "Traffic signal control systems (TSCSs) are integral to intelligent traffic\nmanagement, fostering efficient vehicle flow. Traditional approaches often\nsimplify road networks into standard graphs, which results in a failure to\nconsider the dynamic nature of traffic data at neighboring intersections,\nthereby neglecting higher-order interconnections necessary for real-time\ncontrol. To address this, we propose a novel TSCS framework to realize\nintelligent traffic control. This framework collaborates with multiple\nneighboring edge computing servers to collect traffic information across the\nroad network. To elevate the efficiency of traffic signal control, we have\ncrafted a multi-agent soft actor-critic (MA-SAC) reinforcement learning\nalgorithm. Within this algorithm, individual agents are deployed at each\nintersection with a mandate to optimize traffic flow across the entire road\nnetwork collectively. Furthermore, we introduce hypergraph learning into the\ncritic network of MA-SAC to enable the spatio-temporal interactions from\nmultiple intersections in the road network. This method fuses hypergraph and\nspatio-temporal graph structures to encode traffic data and capture the complex\nspatial and temporal correlations between multiple intersections. Our empirical\nevaluation, tested on varied datasets, demonstrates the superiority of our\nframework in minimizing average vehicle travel times and sustaining\nhigh-throughput performance. This work facilitates the development of more\nintelligent and reactive urban traffic management solutions.",
        "updated": "2024-04-17 02:46:18 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.11014v1"
    },
    {
        "title": "Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning",
        "authors": "Wei DuanJie LuJunyu Xuan",
        "links": "http://arxiv.org/abs/2404.10976v1",
        "entry_id": "http://arxiv.org/abs/2404.10976v1",
        "pdf_url": "http://arxiv.org/pdf/2404.10976v1",
        "summary": "Cooperative Multi-Agent Reinforcement Learning (MARL) necessitates seamless\ncollaboration among agents, often represented by an underlying relation graph.\nExisting methods for learning this graph primarily focus on agent-pair\nrelations, neglecting higher-order relationships. While several approaches\nattempt to extend cooperation modelling to encompass behaviour similarities\nwithin groups, they commonly fall short in concurrently learning the latent\ngraph, thereby constraining the information exchange among partially observed\nagents. To overcome these limitations, we present a novel approach to infer the\nGroup-Aware Coordination Graph (GACG), which is designed to capture both the\ncooperation between agent pairs based on current observations and group-level\ndependencies from behaviour patterns observed across trajectories. This graph\nis further used in graph convolution for information exchange between agents\nduring decision-making. To further ensure behavioural consistency among agents\nwithin the same group, we introduce a group distance loss, which promotes group\ncohesion and encourages specialization between groups. Our evaluations,\nconducted on StarCraft II micromanagement tasks, demonstrate GACG's superior\nperformance. An ablation study further provides experimental evidence of the\neffectiveness of each component of our method.",
        "updated": "2024-04-17 01:17:10 UTC",
        "interpretation": "解释内容未找到",
        "id": "2404.10976v1"
    }
]