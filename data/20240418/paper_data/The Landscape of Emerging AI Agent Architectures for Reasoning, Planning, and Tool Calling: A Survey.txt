THE LANDSCAPE OF EMERGING AI AGENT ARCHITECTURES
FOR REASONING, PLANNING, AND TOOL CALLING: A SURVEY
TulaMasterman* SandiBesen*
Neudesic,anIBMCompany IBM
tula.masterman@neudesic.com sandi.besen@ibm.com
MasonSawtell* AlexChao
Neudesic,anIBMCompany Microsoft
mason.sawtell@neudesic.com achao@microsoft.com
*DenotesEqualContribution
ABSTRACT
ThissurveypaperexaminestherecentadvancementsinAIagentimplementations,withafocuson
theirabilitytoachievecomplexgoalsthatrequireenhancedreasoning,planning,andtoolexecution
capabilities. Theprimaryobjectivesofthisworkaretoa)communicatethecurrentcapabilitiesand
limitations of existing AI agent implementations, b) share insights gained from our observations
ofthesesystemsinaction,andc)suggestimportantconsiderationsforfuturedevelopmentsinAI
agentdesign. Weachievethisbyprovidingoverviewsofsingle-agentandmulti-agentarchitectures,
identifyingkeypatternsanddivergencesindesignchoices,andevaluatingtheiroverallimpacton
accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic
architecture,theimpactofleadershiponagentsystems,agentcommunicationstyles,andkeyphases
forplanning,execution,andreflectionthatenablerobustAIagentsystems.
Keywords AIAgent·AgentArchitecture·AIReasoning·Planning·ToolCalling·SingleAgent·MultiAgent·
AgentSurvey·LLMAgent·AutonomousAgent
1 Introduction
SincethelaunchofChatGPT,manyofthefirstwaveofgenerativeAIapplicationshavebeenavariationofachatover
acorpusofdocumentsusingtheRetrievalAugmentedGeneration(RAG)pattern. Whilethereisalotofactivityin
makingRAGsystemsmorerobust,variousgroupsarestartingtobuildwhatthenextgenerationofAIapplicationswill
looklike,centralizingonacommontheme: agents.
BeginningwithinvestigationsintorecentfoundationmodelslikeGPT-4andpopularizedthroughopen-sourceprojects
likeAutoGPTandBabyAGI,theresearchcommunityhasexperimentedwithbuildingautonomousagent-basedsystems
[19,1].
Asopposedtozero-shotpromptingofalargelanguagemodelwhereausertypesintoanopen-endedtextfieldandgets
aresultwithoutadditionalinput,agentsallowformorecomplexinteractionandorchestration. Inparticular,agentic
systems have a notion of planning, loops, reflection and other control structures that heavily leverage the model’s
inherent reasoning capabilities to accomplish a task end-to-end. Paired with the ability to use tools, plugins, and
functioncalling,agentsareempoweredtodomoregeneral-purposework.
Amongthecommunity,thereisacurrentdebateonwhethersingleormulti-agentsystemsarebestsuitedforsolving
complex tasks. While single agent architectures excel when problems are well-defined and feedback from other
Theopinionsexpressedinthispaperaresolelythoseoftheauthorsanddonotnecessarilyreflecttheviewsorpoliciesoftheir
respectiveemployers.
4202
rpA
71
]IA.sc[
1v48511.4042:viXraagent-personasortheuserisnotneeded,multi-agentarchitecturestendtothrivemorewhencollaborationandmultiple
distinctexecutionpathsarerequired.
Figure1: Avisualizationofsingleandmulti-agentarchitectureswiththeirunderlyingfeaturesandabilities
1.1 Taxonomy
Agents. AIagentsarelanguagemodel-poweredentitiesabletoplanandtakeactionstoexecutegoalsovermultiple
iterations. AIagentarchitecturesareeithercomprisedofasingleagentormultipleagentsworkingtogethertosolvea
problem.
Typically,eachagentisgivenapersonaandaccesstoavarietyoftoolsthatwillhelpthemaccomplishtheirjobeither
independentlyoraspartofateam. Someagentsalsocontainamemorycomponent,wheretheycansaveandload
informationoutsideoftheirmessagesandprompts. Inthispaper,wefollowthedefinitionofagentthatconsistsof
“brain,perception,andaction”[31]. Thesecomponentssatisfytheminimumrequirementsforagentstounderstand,
reason,andactontheenvironmentaroundthem.
AgentPersona. Anagentpersonadescribestheroleorpersonalitythattheagentshouldtakeon,includinganyother
instructionsspecifictothatagent. Personasalsocontaindescriptionsofanytoolstheagenthasaccessto. Theymake
theagentawareoftheirrole,thepurposeoftheirtools,andhowtoleveragethemeffectively. Researchershavefound
that“shapedpersonalityverifiablyinfluencesLargeLanguageModel(LLM)behaviorincommondownstream(i.e.
subsequent)tasks,suchaswritingsocialmediaposts”[21].Solutionsthatusemultipleagentpersonastosolveproblems
alsoshowsignificantimprovementscomparedtoChain-of-Thought(CoT)promptingwherethemodelisaskedtobreak
downitsplansstepbystep[28,29].
Tools. InthecontextofAIagents,toolsrepresentanyfunctionsthatthemodelcancall. Theyallowtheagenttointeract
with external data sources by pulling or pushing information to that source. An example of an agent persona and
associatedtoolsisaprofessionalcontractwriter. Thewriterisgivenapersonaexplainingtheirroleandthetypesof
tasksitmustaccomplish. Itisalsogiventoolsrelatedtoaddingnotestoadocument,readinganexistingdocument,or
sendinganemailwithafinaldraft.
SingleAgentArchitectures.Thesearchitecturesarepoweredbyonelanguagemodelandwillperformallthereasoning,
planning,andtoolexecutionontheirown. Theagentisgivenasystempromptandanytoolsrequiredtocompletetheir
2task. InsingleagentpatternsthereisnofeedbackmechanismfromotherAIagents;however,theremaybeoptionsfor
humanstoprovidefeedbackthatguidestheagent.
Multi-AgentArchitectures. Thesearchitecturesinvolvetwoormoreagents,whereeachagentcanutilizethesame
languagemodelorasetofdifferentlanguagemodels. Theagentsmayhaveaccesstothesametoolsordifferenttools.
Eachagenttypicallyhastheirownpersona.
Multi-agentarchitecturescanhaveawidevarietyoforganizationsatanylevelofcomplexity. Inthispaper,wedivide
themintotwoprimarycategories: verticalandhorizontal. Itisimportanttokeepinmindthatthesecategoriesrepresent
twoendsofaspectrum,wheremostexistingarchitecturesfallsomewherebetweenthesetwoextremes.
Vertical Architectures. In this structure, one agent acts as a leader and has other agents report directly to them.
Dependingonthearchitecture,reportingagentsmaycommunicateexclusivelywiththeleadagent. Alternatively,a
leadermaybedefinedwithasharedconversationbetweenallagents. Thedefiningfeaturesofverticalarchitectures
includehavingaleadagentandacleardivisionoflaborbetweenthecollaboratingagents.
HorizontalArchitectures. Inthisstructure,alltheagentsaretreatedasequalsandarepartofonegroupdiscussion
aboutthetask. Communicationbetweenagentsoccursinasharedthreadwhereeachagentcanseeallmessagesfrom
theothers. Agentsalsocanvolunteertocompletecertaintasksorcalltools,meaningtheydonotneedtobeassigned
byaleadingagent. Horizontalarchitecturesaregenerallyusedfortaskswherecollaboration, feedbackandgroup
discussionarekeytotheoverallsuccessofthetask[2].
2 KeyConsiderationsforEffectiveAgents
2.1 Overview
Agentsaredesignedtoextendlanguagemodelcapabilitiestosolvereal-worldchallenges. Successfulimplementations
requirerobustproblem-solvingcapabilitiesenablingagentstoperformwellonnoveltasks.Tosolvereal-worldproblems
effectively,agentsrequiretheabilitytoreasonandplanaswellascalltoolsthatinteractwithanexternalenvironment.
Inthissectionweexplorewhyreasoning,planning,andtoolcallingarecriticaltoagentsuccess.
2.2 TheImportanceofReasoningandPlanning
Reasoningisafundamentalbuildingblockofhumancognition,enablingpeopletomakedecisions,solveproblems,and
understandtheworldaroundus. AIagentsneedastrongabilitytoreasoniftheyaretoeffectivelyinteractwithcomplex
environments,makeautonomousdecisions,andassisthumansinawiderangeoftasks. Thistightsynergybetween
“acting”and“reasoning”allowsnewtaskstobelearnedquicklyandenablesrobustdecisionmakingorreasoning,even
underpreviouslyunseencircumstancesorinformationuncertainties[32]. Additionally,agentsneedreasoningtoadjust
theirplansbasedonnewfeedbackorinformationlearned.
Ifagentslackingreasoningskillsaretaskedwithactingonstraightforwardtasks, theymaymisinterpretthequery,
generatearesponsebasedonaliteralunderstanding,orfailtoconsidermulti-stepimplications.
Planning,whichrequiresstrongreasoningabilities,commonlyfallsintooneoffivemajorapproaches: taskdecomposi-
tion,multi-planselection,externalmodule-aidedplanning,reflectionandrefinementandmemory-augmentedplanning
[12]. These approaches allow the model to either break the task down into sub tasks, select one plan from many
generatedoptions,leverageapreexistingexternalplan,revisepreviousplansbasedonnewinformation,orleverage
externalinformationtoimprovetheplan.
Mostagentpatternshaveadedicatedplanningstepwhichinvokesoneormoreofthesetechniquestocreateaplan
beforeanyactionsareexecuted. Forexample,PlanLikeaGraph(PLaG)isanapproachthatrepresentsplansasdirected
graphs,withmultiplestepsbeingexecutedinparallel[15,33]. Thiscanprovideasignificantperformanceincreaseover
othermethodsontasksthatcontainmanyindependentsubtasksthatbenefitfromasynchronousexecution.
2.3 TheImportanceofEffectiveToolCalling
Onekeybenefitoftheagentabstractionoverpromptingbaselanguagemodelsistheagents’abilitytosolvecomplex
problemsbycallingmultipletools. Thesetoolsenabletheagenttointeractwithexternaldatasources,sendorretrieve
informationfromexistingAPIs,andmore. Problemsthatrequireextensivetoolcallingoftengohandinhandwith
thosethatrequirecomplexreasoning.
Bothsingle-agentandmulti-agentarchitecturescanbeusedtosolvechallengingtasksbyemployingreasoningandtool
callingsteps. Manymethodsusemultipleiterationsofreasoning,memory,andreflectiontoeffectivelyandaccurately
3completeproblems[16,23,32]. Theyoftendothisbybreakingalargerproblemintosmallersubproblems,andthen
solvingeachonewiththeappropriatetoolsinsequence.
Otherworksfocusedonadvancingagentpatternshighlightthatwhilebreakingalargerproblemintosmallersubproblems
canbeeffectiveatsolvingcomplextasks,singleagentpatternsoftenstruggletocompletethelongsequencerequired
[22,6].
Multi-agent patterns can address the issues of parallel tasks and robustness since individual agents can work on
individualsubproblems. Manymulti-agentpatternsstartbytakingacomplexproblemandbreakingitdownintoseveral
smallertasks. Then,eachagentworksindependentlyonsolvingeachtaskusingtheirownindependentsetoftools.
3 SingleAgentArchitectures
3.1 Overview
Inthissection,wehighlightsomenotablesingleagentmethodssuchasReAct,RAISE,Reflexion,AutoGPT+P,and
LATS.Eachofthesemethodscontainadedicatedstageforreasoningabouttheproblembeforeanyactionistakento
advancethegoal. Weselectedthesemethodsbasedontheircontributionstothereasoningandtoolcallingcapabilities
ofagents.
3.2 KeyThemes
Wefindthatsuccessfulgoalexecutionbyagentsiscontingentuponproperplanningandself-correction[32,16,23,1].
Withouttheabilitytoself-evaluateandcreateeffectiveplans,singleagentsmaygetstuckinanendlessexecutionloop
andneveraccomplishagiventaskorreturnaresultthatdoesnotmeetuserexpectations[32]. Wefindthatsingleagent
architecturesareespeciallyusefulwhenthetaskrequiresstraightforwardfunctioncallinganddoesnotneedfeedback
fromanotheragent[22].
3.3 Examples
ReAct. IntheReAct(Reason+Act)method,anagentfirstwritesathoughtaboutthegiventask. Itthenperforms
an action based on that thought, and the output is observed. This cycle can repeat until the task is complete [32].
When applied to a diverse set of language and decision-making tasks, the ReAct method demonstrates improved
effectivenesscomparedtozero-shotpromptingonthesametasks. Italsoprovidesimprovedhumaninteroperabilityand
trustworthinessbecausetheentirethoughtprocessofthemodelisrecorded. WhenevaluatedontheHotpotQAdataset,
theReActmethodonlyhallucinated6%ofthetime,comparedto14%usingthechainofthought(CoT)method[29,
32].
However, the ReAct method is not without its limitations. While intertwining reasoning, observation, and action
improvestrustworthiness,themodelcanrepetitivelygeneratethesamethoughtsandactionsandfailtocreatenew
thoughtstoprovokefinishingthetaskandexitingtheReActloop. Incorporatinghumanfeedbackduringtheexecution
ofthetaskwouldlikelyincreaseitseffectivenessandapplicabilityinreal-worldscenarios.
RAISE.TheRAISEmethodisbuiltupontheReActmethod,withtheadditionofamemorymechanismthatmirrors
humanshort-termandlong-termmemory[16]. Itdoesthisbyusingascratchpadforshort-termstorageandadatasetof
similarpreviousexamplesforlong-termstorage.
Byaddingthesecomponents,RAISEimprovesupontheagent’sabilitytoretaincontextinlongerconversations. The
paperalsohighlightshowfine-tuningthemodelresultsinthebestperformancefortheirtask,evenwhenusingasmaller
model. TheyalsoshowedthatRAISEoutperformsReActinbothefficiencyandoutputquality.
WhileRAISEsignificantlyimprovesuponexistingmethodsinsomerespects,theresearchersalsohighlightedseveral
issues. First,RAISEstrugglestounderstandcomplexlogic,limitingitsusefulnessinmanyscenarios. Additionally,
RAISEagentsoftenhallucinatedwithrespecttotheirrolesorknowledge. Forexample,asalesagentwithoutaclearly
definedrolemightretaintheabilitytocodeinPython,whichmayenablethemtostartwritingPythoncodeinsteadof
focusingontheirsalestasks. Theseagentsmightalsogivetheusermisleadingorincorrectinformation. Thisproblem
wasaddressedbyfine-tuningthemodel,buttheresearchersstillhighlightedhallucinationasalimitationintheRAISE
implementation.
Reflexion. Reflexionisasingle-agentpatternthatusesself-reflectionthroughlinguisticfeedback[23]. Byutilizing
metricssuchassuccessstate,currenttrajectory,andpersistentmemory,thismethodusesanLLMevaluatortoprovide
4(cid:11)(cid:20)(cid:12)(cid:3)(cid:43)(cid:82)(cid:87)(cid:86)(cid:83)(cid:82)(cid:87)(cid:3)(cid:52)(cid:36) (cid:11)(cid:20)(cid:71)(cid:12)(cid:3)(cid:53)(cid:72)(cid:36)(cid:70)(cid:87)(cid:3)(cid:11)(cid:53)(cid:72)(cid:68)(cid:86)(cid:82)(cid:81)(cid:3)(cid:14)(cid:3)(cid:36)(cid:70)(cid:87)(cid:12)
(cid:52)(cid:88)(cid:72)(cid:86)(cid:87)(cid:76)(cid:82)(cid:81)(cid:29)(cid:3)(cid:43)(cid:82)(cid:90)(cid:3)(cid:80)(cid:68)(cid:81)(cid:92)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:3)(cid:68)(cid:85)(cid:72)(cid:3)(cid:76)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:75)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:76)(cid:86)(cid:3)(cid:75)(cid:82)(cid:80)(cid:72)(cid:3)(cid:87)(cid:3)(cid:82) (cid:55)(cid:75)(cid:82)(cid:88)(cid:74)(cid:75)(cid:87)(cid:3)(cid:20)(cid:29)(cid:3)(cid:44)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:86)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:3)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:15) (cid:3)
(cid:87)(cid:75)(cid:72)(cid:3)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:34) (cid:73)(cid:76)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:75)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:76)(cid:87)(cid:3)(cid:76)(cid:86)(cid:3)(cid:76)(cid:81)(cid:15)(cid:3)(cid:87)(cid:75)(cid:72)(cid:81)(cid:3)(cid:73)(cid:76)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:81)(cid:88)(cid:80)(cid:69)(cid:72)(cid:85)(cid:3)(cid:82)(cid:73)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:3)(cid:76)(cid:81) (cid:3)
(cid:43)(cid:82)(cid:87)(cid:83)(cid:82)(cid:87)(cid:52)(cid:36)(cid:3)(cid:79)(cid:68)(cid:69)(cid:72)(cid:79)(cid:29)(cid:3)(cid:21)(cid:15)(cid:25)(cid:25)(cid:23) (cid:50)(cid:88)(cid:87)(cid:71)(cid:68)(cid:87)(cid:72)(cid:71)(cid:3) (cid:87) (cid:36)(cid:75) (cid:70)(cid:72) (cid:87)(cid:3) (cid:3)(cid:75) (cid:20)(cid:82) (cid:29)(cid:3)(cid:87)(cid:72) (cid:54)(cid:79) (cid:72)(cid:17) (cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:64)
(cid:50)(cid:69)(cid:86)(cid:3)(cid:20)(cid:29)(cid:3)(cid:38)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:81)(cid:82)(cid:87)(cid:3)(cid:73)(cid:76)(cid:81)(cid:71)(cid:3)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:17) (cid:3)
(cid:11)(cid:20)(cid:68)(cid:12)(cid:3)(cid:54)(cid:87)(cid:68)(cid:81)(cid:71)(cid:68)(cid:85)(cid:71) (cid:11)(cid:20)(cid:70)(cid:12)(cid:3)(cid:36)(cid:70)(cid:87)(cid:16)(cid:50)(cid:81)(cid:79)(cid:92)(cid:3) (cid:54)(cid:76)(cid:80)(cid:76)(cid:79)(cid:68)(cid:85)(cid:29)(cid:3)(cid:62)(cid:10)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:10)(cid:3)(cid:170)
(cid:36)(cid:81)(cid:86)(cid:90)(cid:72)(cid:85)(cid:29)(cid:3)(cid:22)(cid:15)(cid:19)(cid:19)(cid:19) (cid:36)(cid:70)(cid:87)(cid:3)(cid:20)(cid:29)(cid:3)(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:64)(cid:3) (cid:55)(cid:75)(cid:82)(cid:88)(cid:74)(cid:75)(cid:87)(cid:3)(cid:21)(cid:29)(cid:3)(cid:55)(cid:82)(cid:3)(cid:73)(cid:76)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:75)(cid:82)(cid:87)(cid:72)(cid:79)(cid:15)(cid:3)(cid:44)(cid:3)(cid:70)(cid:68)(cid:81)(cid:3)(cid:86)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:11)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72) (cid:3)
(cid:50)(cid:69)(cid:86)(cid:3)(cid:20)(cid:29)(cid:3)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:76)(cid:86)(cid:3)(cid:68)(cid:3) (cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:12)(cid:17)
(cid:38)(cid:68)(cid:81)(cid:68)(cid:71)(cid:76)(cid:68)(cid:81)(cid:3)(cid:72)(cid:81)(cid:87)(cid:72)(cid:85)(cid:87)(cid:68)(cid:76)(cid:81)(cid:80)(cid:72)(cid:81)(cid:87)(cid:3)(cid:70)(cid:82)(cid:80)(cid:83)(cid:68)(cid:81)(cid:92)(cid:170) (cid:36)(cid:70)(cid:87)(cid:3)(cid:21)(cid:29)(cid:3)(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:11)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3)(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:12)(cid:64)
(cid:11)(cid:20)(cid:69)(cid:12)(cid:3)(cid:38)(cid:82)(cid:55)(cid:3)(cid:11)(cid:53)(cid:72)(cid:68)(cid:86)(cid:82)(cid:81)(cid:3)(cid:50)(cid:81)(cid:79)(cid:92)(cid:12) (cid:36)(cid:70)(cid:87)(cid:3)(cid:21)(cid:29)(cid:3)(cid:47)(cid:82)(cid:82)(cid:78)(cid:88)(cid:83)(cid:62)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:64)(cid:3) (cid:50)(cid:69)(cid:86)(cid:3)(cid:21)(cid:29)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:113)(cid:85)(cid:72)(cid:3)(cid:11)(cid:80)(cid:92)(cid:16)(cid:86)(cid:87)(cid:72)(cid:72)(cid:85)(cid:12)(cid:3)(cid:3)(cid:76)(cid:86)(cid:3)(cid:170)(cid:3)(cid:43)(cid:72)(cid:79)(cid:71)(cid:3)(cid:76)(cid:81)(cid:3)(cid:68)(cid:3)(cid:70)(cid:88)(cid:86)(cid:87)(cid:82)(cid:80)(cid:3)(cid:87)(cid:75)(cid:72)(cid:68)(cid:87)(cid:85)(cid:72)(cid:3)(cid:68)(cid:87)(cid:3)
(cid:55)(cid:75)(cid:82)(cid:88)(cid:74)(cid:75)(cid:87)(cid:29)(cid:3)(cid:47)(cid:72)(cid:87)(cid:10)(cid:86)(cid:3)(cid:87)(cid:75)(cid:76)(cid:81)(cid:78)(cid:3)(cid:86)(cid:87)(cid:72)(cid:83)(cid:3) (cid:50)(cid:69)(cid:86)(cid:3)(cid:21)(cid:29)(cid:3)(cid:49)(cid:82)(cid:3)(cid:80)(cid:82)(cid:85)(cid:72)(cid:3)(cid:85)(cid:72)(cid:86)(cid:88)(cid:79)(cid:87)(cid:86) (cid:87)(cid:75)(cid:72)(cid:3)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:3)(cid:170)
(cid:69)(cid:92)(cid:3)(cid:86)(cid:87)(cid:72)(cid:83)(cid:17)(cid:3)(cid:55)(cid:75)(cid:72)(cid:3)(cid:75)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:87)(cid:75)(cid:68)(cid:87)(cid:3)(cid:76)(cid:86)(cid:3) (cid:36)(cid:70)(cid:87)(cid:3)(cid:22)(cid:29)(cid:3)(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:11)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3) (cid:55)(cid:75)(cid:82)(cid:88)(cid:74)(cid:75)(cid:87)(cid:3)(cid:22)(cid:29)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3)(cid:75)(cid:72)(cid:79)(cid:71)(cid:3)(cid:76)(cid:81)(cid:3)(cid:68)(cid:3)(cid:70)(cid:88)(cid:86)(cid:87)(cid:82)(cid:80)(cid:3)(cid:87)(cid:75)(cid:72)(cid:68)(cid:87)(cid:85)(cid:72)(cid:3)(cid:68)(cid:87)(cid:3)(cid:87)(cid:75)(cid:72) (cid:3)
(cid:75)(cid:82)(cid:80)(cid:72)(cid:3)(cid:87)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3) (cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:12)(cid:64)(cid:3) (cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:17)(cid:3)(cid:54)(cid:82)(cid:3)(cid:44)(cid:3)(cid:81)(cid:72)(cid:72)(cid:71)(cid:3)(cid:87)(cid:82)(cid:3)(cid:86)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75) (cid:3)
(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:3)(cid:86)(cid:75)(cid:82)(cid:90)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:76)(cid:86)(cid:3) (cid:50)(cid:69)(cid:86)(cid:3)(cid:22)(cid:29)(cid:3)(cid:38)(cid:82)(cid:88)(cid:79)(cid:71)(cid:3)(cid:81)(cid:82)(cid:87)(cid:3)(cid:73)(cid:76)(cid:81)(cid:71)(cid:170) (cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:3)(cid:81)(cid:72)(cid:91)(cid:87)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:73)(cid:76)(cid:81)(cid:71)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:81)(cid:88)(cid:80)(cid:69)(cid:72)(cid:85) (cid:3)
(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:17)(cid:3)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3) (cid:36)(cid:70)(cid:87)(cid:3)(cid:23)(cid:29)(cid:3)(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:48)(cid:92)(cid:86)(cid:87)(cid:72)(cid:85)(cid:72)(cid:3)(cid:11)(cid:38)(cid:76)(cid:85)(cid:84)(cid:88)(cid:72)(cid:3)(cid:71)(cid:88)(cid:3) (cid:82)(cid:73)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:3)(cid:76)(cid:81)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:75)(cid:82)(cid:87)(cid:72)(cid:79)(cid:17)
(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:75)(cid:68)(cid:86)(cid:3)(cid:21)(cid:15)(cid:27)(cid:27)(cid:24)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:15)(cid:3)(cid:86)(cid:82)(cid:3) (cid:36)(cid:70)(cid:87)(cid:3)(cid:22)(cid:29)(cid:3)(cid:54)(cid:72)(cid:68)(cid:85)(cid:70)(cid:75)(cid:62)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82) (cid:64)
(cid:54)(cid:82)(cid:79)(cid:72)(cid:76)(cid:79)(cid:12)(cid:64)(cid:3)
(cid:87)(cid:75)(cid:72)(cid:3)(cid:68)(cid:81)(cid:86)(cid:90)(cid:72)(cid:85)(cid:3)(cid:76)(cid:86)(cid:3)(cid:21)(cid:15)(cid:27)(cid:27)(cid:24)(cid:17) (cid:50)(cid:69)(cid:86)(cid:3)(cid:22)(cid:29)(cid:3)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:3)(cid:170)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:3)(cid:21)(cid:15)(cid:27)(cid:27)(cid:23)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86)(cid:3)
(cid:50)(cid:69)(cid:86)(cid:3)(cid:23)(cid:29)(cid:3)(cid:48)(cid:92)(cid:86)(cid:87)(cid:113)(cid:85)(cid:72)(cid:3)(cid:11)(cid:80)(cid:92)(cid:16)(cid:86)(cid:87)(cid:72)(cid:72)(cid:85)(cid:12)(cid:3)(cid:3)(cid:76)(cid:86)(cid:3) (cid:68)(cid:81)(cid:71)(cid:3)(cid:21)(cid:21)(cid:19)(cid:3)(cid:86)(cid:88)(cid:76)(cid:87)(cid:72)(cid:86)(cid:3)(cid:170)
(cid:82)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:76)(cid:91)(cid:170)
(cid:36)(cid:81)(cid:86)(cid:90)(cid:72)(cid:85)(cid:29)(cid:3)(cid:21)(cid:15)(cid:27)(cid:27)(cid:24)
(cid:36)(cid:70)(cid:87)(cid:3)(cid:24)(cid:29)(cid:3)(cid:47)(cid:82)(cid:82)(cid:78)(cid:88)(cid:83)(cid:62)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3) (cid:55)(cid:75)(cid:82)(cid:88)(cid:74)(cid:75)(cid:87)(cid:3)(cid:23)(cid:29)(cid:3)(cid:55)(cid:85)(cid:72)(cid:68)(cid:86)(cid:88)(cid:85)(cid:72)(cid:3)(cid:44)(cid:86)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:3)(cid:75)(cid:68)(cid:86)(cid:3)(cid:21)(cid:15)(cid:27)(cid:27)(cid:23)(cid:3)(cid:85)(cid:82)(cid:82)(cid:80)(cid:86) (cid:3)
(cid:43)(cid:82)(cid:87)(cid:72)(cid:79)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:68)(cid:86)(cid:76)(cid:81)(cid:82)(cid:64)(cid:3) (cid:68)(cid:81)(cid:71)(cid:3)(cid:21)(cid:21)(cid:19)(cid:3)(cid:86)(cid:88)(cid:76)(cid:87)(cid:72)(cid:86)(cid:17)(cid:3)(cid:54)(cid:82)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:68)(cid:81)(cid:86)(cid:90)(cid:72)(cid:85)(cid:3)(cid:76)(cid:86)(cid:3)(cid:22)(cid:15)(cid:20)(cid:19)(cid:23)(cid:17)
(cid:170)(cid:170)(cid:11)(cid:72)(cid:81)(cid:71)(cid:3)(cid:90)(cid:76)(cid:87)(cid:75)(cid:82)(cid:88)(cid:87)(cid:3)(cid:68)(cid:81)(cid:86)(cid:90)(cid:72)(cid:85)(cid:12) (cid:36)(cid:70)(cid:87)(cid:3)(cid:23)(cid:29)(cid:3)(cid:41)(cid:76)(cid:81)(cid:76)(cid:86)(cid:75)(cid:62)(cid:22)(cid:15)(cid:20)(cid:19)(cid:23)(cid:64) (cid:56)(cid:83)(cid:16)(cid:87)(cid:82)(cid:16)(cid:71)(cid:68)(cid:87)(cid:72)(cid:3) (cid:1212)
Figure2: AnexampleoftheReActmethodcomparedtoothermethods[32]
RAISE Framework
Agent Loop
User Query
Examples Retirval
Memory Update
LLMs Working Memory Tool Pool Example Pool
• API-based LLMs • System Prompt
• GPT-4、 GPT-3.5 • Profile • Database Access • < Q1, A1 >
• Claude • Task Instruction • Scripting and Programming
• . . . • . . . • < Q2, A2 >
Tools
• Open-sourced LLMs • ConversationHistory • < Q3, A3 >
• Knowledge Bases and
• Llama • Scratchpad • . . .
• Qwen Information Repositories
• Baichuan • Retrieved Examples • AI and Machine Learning Tools • < QN, AN >
• . . . • TaskTrajectory
Figure3: AdiagramshowingtheRAISEmethod[16]
specificandrelevantfeedbacktotheagent. Thisresultsinanimprovedsuccessrateaswellasreducedhallucination
comparedtoChain-of-ThoughtandReAct.
Despitetheseadvancements,theReflexionauthorsidentifyvariouslimitationsofthepattern. Primarily,Reflexion
issusceptibleto“non-optimallocalminimasolutions”. Italsousesaslidingwindowforlong-termmemory,rather
thanadatabase. Thismeansthatthevolumeoflong-termmemoryislimitedbythetokenlimitofthelanguagemodel.
Finally,theresearchersidentifythatwhileReflexionsurpassesothersingle-agentpatterns,therearestillopportunities
toimproveperformanceontasksthatrequireasignificantamountofdiversity,exploration,andreasoning.
AUTOGPT+P.AutoGPT+P(Planning)isamethodthataddressesreasoninglimitationsforagentsthatcommand
robotsinnaturallanguage[1]. AutoGPT+PcombinesobjectdetectionandObjectAffordanceMapping(OAM)with
aplanningsystemdrivenbyaLLM.Thisallowstheagenttoexploretheenvironmentformissingobjects,propose
alternatives,orasktheuserforassistancewithreachingitsgoal.
5AutoGPT+Pstartsbyusinganimageofascenetodetecttheobjectspresent. Alanguagemodelthenusesthoseobjects
toselectwhichtooltouse,fromfouroptions: PlanTool,PartialPlanTool,SuggestAlternativeTool,andExploreTool.
Thesetoolsallowtherobottonotonlygenerateafullplantocompletethegoal,butalsotoexploretheenvironment,
makeassumptions,andcreatepartialplans.
However,thelanguagemodeldoesnotgeneratetheplanentirelyonitsown. Instead,itgeneratesgoalsandstepsto
workasideaclassicalplannerwhichexecutestheplanusingPlanningDomainDefinitionLanguage(PDDL).The
paperfoundthat“LLMscurrentlylacktheabilitytodirectlytranslateanaturallanguageinstructionintoaplanfor
executingrobotictasks,primarilyduetotheirconstrainedreasoningcapabilities”[1]. BycombiningtheLLMplanning
capabilitieswithaclassicalplanner,theirapproachsignificantlyimprovesuponotherpurelylanguagemodel-based
approachestoroboticplanning.
Aswithmostfirstoftheirkindapproaches,AutoGPT+Pisnotwithoutitsdrawbacks. Accuracyoftoolselectionvaries,
withcertaintoolsbeingcalledinappropriatelyorgettingstuckinloops. Inscenarioswhereexplorationisrequired,
thetoolselectionsometimesleadstoillogicalexplorationdecisionslikelookingforobjectsinthewrongplace. The
frameworkalsoislimitedintermsofhumaninteraction,withtheagentbeingunabletoseekclarificationandtheuser
beingunabletomodifyorterminatetheplanduringexecution.
Figure4: AdiagramoftheAutoGPT+Pmethod[1]
LATS.LanguageAgentTreeSearch(LATS)isasingle-agentmethodthatsynergizesplanning,acting,andreasoning
byusingtrees[36]. Thistechnique,inspiredbyMonteCarloTreeSearch,representsastateasanodeandtakingan
actionastraversingbetweennodes. ItusesLM-basedheuristicstosearchforpossibleoptions,thenselectsanaction
usingastateevaluator.
When compared to other tree-based methods, LATS implements a self-reflection reasoning step that dramatically
improvesperformance. Whenanactionistaken,bothenvironmentalfeedbackaswellasfeedbackfromalanguage
modelisusedtodetermineifthereareanyerrorsinreasoningandproposealternatives. Thisabilitytoself-reflect
combinedwithapowerfulsearchalgorithmmakesLATSperformextremelywellonvarioustasks.
However,duetothecomplexityofthealgorithmandthereflectionstepsinvolved,LATSoftenusesmorecomputational
resourcesandtakesmoretimetocompletethanothersingle-agentmethods[36]. Thepaperalsousesrelativelysimple
questionansweringbenchmarksandhasnotbeentestedonmorerobustscenariosthatinvolveinvolvingtoolcallingor
complexreasoning.
4 MultiAgentArchitectures
4.1 Overview
Inthissection,weexamineafewkeystudiesandsampleframeworkswithmulti-agentarchitectures,suchasEmbodied
LLMAgentsLearntoCooperateinOrganizedTeams,DyLAN,AgentVerse,andMetaGPT.Wehighlighthowthese
implementationsfacilitategoalexecutionthroughinter-agentcommunicationandcollaborativeplanexecution. Thisis
notintendedtobeanexhaustivelistofallagentframeworks,ourgoalistoprovidebroadcoverageofkeythemesand
examplesrelatedtomulti-agentpatterns.
4.2 KeyThemes
Multi-agentarchitecturescreateanopportunityforboththeintelligentdivisionoflaborbasedonskillandhelpful
feedbackfromavarietyofagentpersonas. Manymulti-agentarchitecturesworkinstageswhereteamsofagentsare
6createdandreorganizeddynamicallyforeachplanning,execution,andevaluationphase[2,9,18]. Thisreorganization
providessuperiorresultsbecausespecializedagentsareemployedforcertaintasks,andremovedwhentheyareno
longer needed. By matching agents roles and skills to the task at hand, agent teams can achieve greater accuracy
and decrease time to meet the goal. Key features of effective multi-agent architectures include clear leadership in
agentteams,dynamicteamconstruction,andeffectiveinformationsharingbetweenteammemberssothatimportant
informationdoesnotgetlostinsuperfluouschatter.
4.3 Examples
EmbodiedLLMAgentsLearntoCooperateinOrganizedTeams. ResearchbyGuoetal. demonstratestheimpact
of a lead agent on the overall effectiveness of the agent team [9]. This architecture contains a vertical component
throughtheleaderagent,aswellasahorizontalcomponentfromtheabilityforagentstoconversewithotheragents
besidestheleader. Theresultsoftheirstudydemonstratethatagentteamswithanorganizedleadercompletetheirtasks
nearly10%fasterthanteamswithoutaleader.
Furthermore,theydiscoveredthatinteamswithoutadesignatedleader,agentsspentmostoftheirtimegivingorders
tooneanother(~50%ofcommunication),splittingtheirremainingtimebetweensharinginformation,orrequesting
guidance. Conversely,inteamswithadesignatedleader,60%oftheleader’scommunicationinvolvedgivingdirections,
promptingothermemberstofocusmoreonexchangingandrequestinginformation. Theirresultsdemonstratethat
agentteamsaremosteffectivewhentheleaderisahuman.
Figure5: Agentteamswithadesignatedleaderachievesuperiorperformance[9]
.
Beyondteamstructure,thepaperemphasizestheimportanceofemployinga“criticize-reflect”stepforgeneratingplans,
evaluatingperformance,providingfeedback,andre-organizingtheteam[9]. Theirresultsindicatethatagentswitha
dynamicteamstructurewithrotatingleadershipprovidethebestresults,withboththelowesttimetotaskcompletion
andthelowestcommunicationcostonaverage. Ultimately,leadershipanddynamicteamstructuresimprovetheoverall
team’sabilitytoreason,plan,andperformtaskseffectively.
DyLAN.TheDynamicLLM-AgentNetwork(DyLAN)frameworkcreatesadynamicagentstructurethatfocuseson
complextaskslikereasoningandcodegeneration[18]. DyLANhasaspecificstepfordetermininghowmucheach
agenthascontributedinthelastroundofworkandonlymovestopcontributorsthenextroundofexecution. This
methodishorizontalinnaturesinceagentscanshareinformationwitheachotherandthereisnodefinedleader. DyLAN
showsimprovedperformanceonavarietyofbenchmarkswhichmeasurearithmeticandgeneralreasoningcapabilities.
Thishighlightstheimpactofdynamicteamsanddemonstratesthatbyconsistentlyre-evaluatingandrankingagent
contributions,wecancreateagentteamsthatarebettersuitedtocompleteagiventask.
AgentVerse. Multi-agent architectures like AgentVerse demonstrate how distinct phases for group planning can
improveanAIagent’sreasoningandproblem-solvingcapabilities[2]. AgentVersecontainsfourprimarystagesfor
taskexecution: recruitment,collaborativedecisionmaking,independentactionexecution,andevaluation. Thiscanbe
repeateduntiltheoverallgoalisachieved. Bystrictlydefiningeachphase,AgentVersehelpsguidethesetofagentsto
reason,discuss,andexecutemoreeffectively.
Asanexample,therecruitmentstepallowsagentstoberemovedoraddedbasedontheprogresstowardsthegoal. This
helpsensurethattherightagentsareparticipatingatanygivenstageofproblemsolving. Theresearchersfoundthat
horizontalteamsaregenerallybestsuitedforcollaborativetaskslikeconsulting,whileverticalteamsarebettersuited
fortasksthatrequireclearerisolationofresponsibilitiesfortoolcalling.
7x N rounds
Goal Expert Recruitment Collaborative Decision-Making
Group
Build
Group
x M turns
? ? ?
Outcome Evaluation New State Action Execution
? Agents:
==
Goal New State Actions:
: Architect : Logger : Designer
: Designer : Worker : Worker
: Engineer New State : Engineer New State : Engineer New State
Round 1 Round 2 Round 3
Figure6: AdiagramoftheAgentVersemethod[2]
MetaGPT.Manymulti-agentarchitecturesallowagentstoconversewithoneanotherwhilecollaboratingonacommon
problem. Thisconversationalcapabilitycanleadtochatterbetweentheagentsthatissuperfluousanddoesnotfurther
theteamgoal. MetaGPTaddressestheissueofunproductivechatteramongstagentsbyrequiringagentstogenerate
structuredoutputslikedocumentsanddiagramsinsteadofsharingunstructuredchatmessages[11].
Additionally, MetaGPTimplementsa”publish-subscribe”mechanismforinformationsharing. Thisallowsallthe
agentstoshareinformationinoneplace,butonlyreadinformationrelevanttotheirindividualgoalsandtasks. This
streamlinestheoverallgoalexecutionandreducesconversationalnoisebetweenagents. Whencomparedtosingle-agent
architecturesontheHumanEvalandMBPPbenchmarks,MetaGPT’smulti-agentarchitecturedemonstratessignificantly
betterresults.
5 DiscussionandObservations
5.1 Overview
Inthissectionwediscussthekeythemesandimpactsofthedesignchoicesexhibitedinthepreviouslyoutlinedagent
patterns. These patterns serve as key examples of the growing body of research and implementation of AI agent
architectures. Bothsingleandmulti-agentarchitecturesseektoenhancethecapabilitiesoflanguagemodelsbygiving
themtheabilitytoexecutegoalsonbehalfoforalongsideahumanuser. Mostobservedagentimplementationsbroadly
followtheplan,act,andevaluateprocesstoiterativelysolveproblems.
Wefindthatbothsingleandmulti-agentarchitecturesdemonstratecompellingperformanceoncomplexgoalexecution.
Wealsofindthatacrossarchitecturesclearfeedback,taskdecomposition,iterativerefinement,androledefinitionyield
improvedagentperformance.
5.2 KeyFindings
TypicalConditionsforSelectingaSinglevsMulti-AgentArchitecture. Basedontheaforementionedagentpatterns,
wefindthatsingle-agentpatternsaregenerallybestsuitedfortaskswithanarrowlydefinedlistoftoolsandwhere
processesarewell-defined. Singleagentsarealsotypicallyeasiertoimplementsinceonlyoneagentandsetoftools
needstobedefined. Additionally,singleagentarchitecturesdonotfacelimitationslikepoorfeedbackfromotheragents
ordistractingandunrelatedchatterfromotherteammembers. However,theymaygetstuckinanexecutionloopand
failtomakeprogresstowardstheirgoaliftheirreasoningandrefinementcapabilitiesarenotrobust.
8
!! ✨ # ! , " " "
draweR kcabdeeF
$ $ ⚙ & ' . ( ) * + / ! ✨Multi-agentarchitecturesaregenerallywell-suitedfortaskswherefeedbackfrommultiplepersonasisbeneficialin
accomplishingthetask. Forexample,documentgenerationmaybenefitfromamulti-agentarchitecturewhereone
agentprovidesclearfeedbacktoanotheronawrittensectionofthedocument. Multi-agentsystemsarealsouseful
whenparallelizationacrossdistincttasksorworkflowsisrequired. Crucially,Wanget. alfindsthatmulti-agentpatterns
performbetterthansingleagentsinscenarioswhennoexamplesareprovided[26]. Bynature,multi-agentsystemsare
morecomplexandoftenbenefitfromrobustconversationmanagementandclearleadership.
Whilesingleandmulti-agentpatternshavedivergingcapabilitiesintermsofscope,researchfindsthat“multi-agent
discussiondoesnotnecessarilyenhancereasoningwhenthepromptprovidedtoanagentissufficientlyrobust”[26].
Thissuggeststhatthoseimplementingagentarchitecturesshoulddecidebetweensingleormultipleagentsbasedonthe
broadercontextoftheirusecase,andnotbasedonthereasoningcapabilitiesrequired.
AgentsandAsynchronousTaskExecution. Whileasingleagentcaninitiatemultipleasynchronouscallssimulta-
neously,itsoperationalmodeldoesnotinherentlysupportthedivisionofresponsibilitiesacrossdifferentexecution
threads. Thismeansthat,althoughtasksarehandledasynchronously,theyarenottrulyparallelinthesenseofbeing
autonomouslymanagedbyseparatedecision-makingentities. Instead,thesingleagentmustsequentiallyplanand
executetasks,waitingforonebatchofasynchronousoperationstocompletebeforeitcanevaluateandmoveontothe
nextstep. Conversely,inmulti-agentarchitectures,eachagentcanoperateindependently,allowingforamoredynamic
divisionoflabor. Thisstructurenotonlyfacilitatessimultaneoustaskexecutionacrossdifferentdomainsorobjectives
butalsoallowsindividualagentstoproceedwiththeirnextstepswithoutbeinghinderedbythestateoftaskshandled
byothers,embodyingamoreflexibleandparallelapproachtotaskmanagement.
ImpactofFeedbackandHumanOversightonAgentSystems. Whensolvingacomplexproblem,itisextremely
unlikelythatoneprovidesacorrect,robustsolutionontheirfirsttry. Instead,onemightposeapotentialsolutionbefore
criticizingitandrefiningit. Onecouldalsoconsultwithsomeoneelseandreceivefeedbackfromanotherperspective.
Thesameideaofiterativefeedbackandrefinementisessentialforhelpingagentssolvecomplexproblems.
Thisispartiallybecauselanguagemodelstendtocommittoananswerearlierintheirresponse,whichcancausea
‘snowballeffect’ofincreasingdiversionfromtheirgoalstate[34]. Byimplementingfeedback,agentsaremuchmore
likelytocorrecttheircourseandreachtheirgoal.
Additionally,theinclusionofhumanoversightimprovestheimmediateoutcomebyaligningtheagent’sresponsesmore
closelywithhumanexpectations,mitigatingthepotentialforagentstodelvedownaninefficientorinvalidapproachto
solvingatask. Asoftoday,includinghumanvalidationandfeedbackintheagentarchitectureyieldsmorereliableand
trustworthyresults[4,9].
Languagemodelsalsoexhibitsycophanticbehavior,wherethey“tendtomirrortheuser’sstance,evenifitmeans
forgoingthepresentationofanimpartialorbalancedviewpoint”[20]. Specifically,theAgentVersepaperdescribeshow
agentsaresusceptibletofeedbackfromotheragents,evenifthefeedbackisnotsound. Thiscanleadtheagentteamto
generateafaultyplanwhichdivertsthemfromtheirobjective[2]. Robustpromptingcanhelpmitigatethis,butthose
developingagentapplicationsshouldbeawareoftheriskswhenimplementinguseroragentfeedbacksystems.
ChallengeswithGroupConversationsandInformationSharing. Onechallengewithmulti-agentarchitectures
liesintheirabilitytointelligentlysharemessagesbetweenagents. Multi-agentpatternshaveagreatertendencytoget
caughtupinnicetiesandaskoneanotherthingslike“howareyou”,whilesingleagentpatternstendtostayfocusedon
thetaskathandsincethereisnoteamdynamictomanage. Theextraneousdialogueinmulti-agentsystemscanimpair
boththeagent’sabilitytoreasoneffectivelyandexecutetherighttools,ultimatelydistractingtheagentsfromthetask
anddecreasingteamefficiency. Thisisespeciallytrueinahorizontalarchitecture,whereagentstypicallyshareagroup
chatandareprivytoeveryagent’smessageinaconversation. Messagesubscribingorfilteringimprovesmulti-agent
performancebyensuringagentsonlyreceiveinformationrelevanttotheirtasks.
Inverticalarchitectures,taskstendtobeclearlydividedbyagentskillwhichhelpsreducedistractionsintheteam.
However,challengesarisewhentheleadingagentfailstosendcriticalinformationtotheirsupportingagentsanddoes
notrealizetheotheragentsaren’tprivytonecessaryinformation. Thisfailurecanleadtoconfusionintheteamor
hallucinationintheresults. Oneapproachtoaddressthisissueistoexplicitlyincludeinformationaboutaccessrightsin
thesystempromptsothattheagentshavecontextuallyappropriateinteractions.
Impact of Role Definition and Dynamic Teams. Clear role definition is critical for both single and multi-agent
architectures. Insingle-agentarchitecturesroledefinitionensuresthattheagentstaysfocusedontheprovidedtask,
executesthepropertools,andminimizeshallucinationofothercapabilities. Similarly,roledefinitioninmulti-agent
architecturesensureseachagentknowswhatit’sresponsibleforintheoverallteamanddoesnottakeontasksoutside
of their described capabilities or scope. Beyond individual role definition, establishing a clear group leader also
improvestheoverallperformanceofmulti-agentteamsbystreamliningtaskassignment. Furthermore,definingaclear
9systempromptforeachagentcanminimizeexcesschatterbypromptingtheagentsnottoengageinunproductive
communication.
Dynamicteamswhereagentsarebroughtinandoutofthesystembasedonneedhavealsobeenshowntobeeffective.
Thisensuresthatallagentsparticipatingintheplanningorexecutionoftasksarefitforthatroundofwork.
5.3 Summary
Bothsingleandmulti-agentpatternsexhibitstrongperformanceonavarietyofcomplextasksinvolvingreasoningand
toolexecution. Singleagentpatternsperformwellwhengivenadefinedpersonaandsetoftools,opportunitiesfor
humanfeedback,andtheabilitytoworkiterativelytowardstheirgoal. Whenconstructinganagentteamthatneedsto
collaborateoncomplexgoals,itisbeneficialtodeployagentswithatleastoneofthesekeyelements: clearleader(s),a
definedplanningphaseandopportunitiestorefinetheplanasnewinformationislearned,intelligentmessagefiltering,
anddynamicteamswhoseagentspossessspecificskillsrelevanttothecurrentsub-task.Ifanagentarchitectureemploys
atleastoneoftheseapproachesitislikelytoresultinincreasedperformancecomparedtoasingleagentarchitectureor
amulti-agentarchitecturewithoutthesetactics.
6 LimitationsofCurrentResearchandConsiderationsforFutureResearch
6.1 Overview
InthissectionweexaminesomeofthelimitationsofagentresearchtodayandidentifypotentialareasforimprovingAI
agentsystems. Whileagentarchitectureshavesignificantlyenhancedthecapabilityoflanguagemodelsinmanyways,
therearesomemajorchallengesaroundevaluations,overallreliability,andissuesinheritedfromthelanguagemodels
poweringeachagent.
6.2 ChallengeswithAgentEvaluation
WhileLLMsareevaluatedonastandardsetofbenchmarksdesignedtogaugetheirgeneralunderstandingandreasoning
capabilities,thebenchmarksforagentevaluationvarygreatly.
Manyresearchteamsintroducetheirownuniqueagentbenchmarksalongsidetheiragentimplementationwhichmakes
comparing multiple agent implementations on the same benchmark challenging. Additionally, many of these new
agent-specificbenchmarksincludeahand-crafted,highlycomplex,evaluationsetwheretheresultsaremanuallyscored
[2]. Thiscanprovideahigh-qualityassessmentofamethod’scapabilities,butitalsolackstherobustnessofalarger
datasetandrisksintroducingbiasintotheevaluation,sincetheonesdevelopingthemethodarealsotheoneswriting
andscoringtheresults. Agentscanalsohaveproblemsgeneratingaconsistentanswerovermultipleiterations,due
tovariabilityinthemodels,environment,orproblemstate. Thisaddedrandomnessposesamuchlargerproblemto
smaller,complexevaluationsets.
6.3 ImpactofDataContaminationandStaticBenchmarks
SomeresearchersevaluatetheiragentimplementationsonthetypicalLLMbenchmarks. Emergingresearchindicates
thatthereissignificantdatacontaminationinthemodel’strainingdata,supportedbytheobservationthatamodel’s
performance significantly worsens when benchmark questions are modified [8, 38, 37]. This raises doubts on the
authenticityofbenchmarkscoresforboththelanguagemodelsandlanguagemodelpoweredagents.
Furthermore,researchershavefoundthat“AsLLMsprogressatarapidpace,existingdatasetsusuallyfailtomatchthe
models’ever-evolvingcapabilities,becausethecomplexitylevelofexistingbenchmarksisusuallystaticandfixed”
[37]. Toaddressthis,workhasbeendonetocreatedynamicbenchmarksthatareresistanttosimplememorization[38,
37]. Researchershavealsoexploredtheideaofgeneratinganentirelysyntheticbenchmarkbasedonauser’sspecific
environmentorusecase[14,27]. Whilethesetechniquescanhelpwithcontamination,decreasingthelevelofhuman
involvementcanposeadditionalrisksregardingcorrectnessandtheabilitytosolveproblems.
6.4 BenchmarkScopeandTransferability
Manylanguagemodelbenchmarksaredesignedtobesolvedinasingleiteration,withnotoolcalls,suchasMMLU
orGSM8K[3,10]. Whiletheseareimportantformeasuringtheabilitiesofbaselanguagemodels,theyarenotgood
proxiesforagentcapabilitiesbecausetheydonotaccountforagentsystems’abilitytoreasonovermultiplestepsor
accessoutsideinformation. StrategyQAimprovesuponthisbyassessingmodels’reasoningabilitiesovermultiple
10steps,buttheanswersarelimitedtoYes/Noresponses[7]. Astheindustrycontinuestopivottowardsagentfocused
use-casesadditionalmeasureswillbeneededtobetterassesstheperformanceandgeneralizabilityofagentstotasks
involvingtoolsthatextendbeyondtheirtrainingdata.
Some agent specific benchmarks like AgentBench evaluate language model-based agents in a variety of different
environmentssuchaswebbrowsing,command-lineinterfaces,andvideogames[17]. Thisprovidesabetterindication
forhowwellagentscangeneralizetonewenvironments,byreasoning,planning,andcallingtoolstoachieveagiven
task. BenchmarkslikeAgentBenchandSmartPlayintroduceobjectiveevaluationmetricsdesignedtoevaluatethe
implementation’s success rate, output similarity to human responses, and overall efficiency [17, 30]. While these
objectivemetricsareimportanttounderstandingtheoverallreliabilityandaccuracyoftheimplementation,itisalso
importanttoconsidermorenuancedorsubjectivemeasuresofperformance. Metricssuchasefficiencyoftooluse,
reliability,androbustnessofplanningarenearlyasimportantassuccessratebutaremuchmoredifficulttomeasure.
Manyofthesemetricsrequireevaluationbyahumanexpert,whichcanbecostlyandtimeconsumingcomparedto
LLM-as-judgeevaluations.
6.5 Real-worldApplicability
ManyoftheexistingbenchmarksfocusontheabilityofAgentsystemstoreasonoverlogicpuzzlesorvideogames
[17]. Whileevaluatingperformanceonthesetypesoftaskscanhelpgetasenseofthereasoningcapabilitiesofagent
systems,itisunclearwhetherperformanceonthesebenchmarkstranslatestoreal-worldperformance. Specifically,
real-worlddatacanbenoisyandcoveramuchwiderbreadthoftopicsthatmanycommonbenchmarkslack.
Onepopularbenchmarkthatusesreal-worlddataisWildBench,whichissourcedfromtheWildChatdatasetof570,000
realconversationswithChatGPT[35]. Becauseofthis,itcoversahugebreadthoftasksandprompts. WhileWildBench
coversawiderangeoftopics,mostotherreal-worldbenchmarksfocusonaspecifictask. Forexample,SWE-benchisa
benchmarkthatusesasetofreal-worldissuesraisedonGitHubforsoftwareengineeringtasksinPython[13]. This
canbeveryhelpfulwhenevaluatingagentsdesignedtowritePythoncodeandprovidesasenseforhowwellagents
canreasonaboutcoderelatedproblems;however,itislessinformativewhentryingtounderstandagentcapabilities
involvingotherprogramminglanguages.
6.6 BiasandFairnessinAgentSystems
LanguageModelshavebeenknowntoexhibitbiasbothintermsofevaluationaswellasinsocialorfairnessterms[5].
Moreover,agentshavespecificallybeenshowntobe“lessrobust,pronetomoreharmfulbehaviors,andcapableof
generatingstealthiercontentthanLLMs,highlightingsignificantsafetychallenges”[25]. Otherresearchhasfound“a
tendencyforLLMagentstoconformtothemodel’sinherentsocialbiasesdespitebeingdirectedtodebatefromcertain
politicalperspectives”[24]. Thistendencycanleadtofaultyreasoninginanyagent-basedimplementation.
Asthecomplexityoftasksandagentinvolvementincreases,moreresearchisneededtoidentifyandaddressbiases
withinthesesystems. Thisposesaverylargechallengetoresearchers, sincescalableandnovelbenchmarksoften
involvesomelevelofLLMinvolvementduringcreation. However,atrulyrobustbenchmarkforevaluatingbiasin
LLM-basedagentsmustincludehumanevaluation.
7 ConclusionandFutureDirections
TheAIagentimplementationsexploredinthissurveydemonstratetherapidenhancementinlanguagemodelpowered
reasoning,planning,andtoolcalling. Singleandmulti-agentpatternsbothshowtheabilitytotacklecomplexmulti-step
problemsthatrequireadvancedproblem-solvingskills. Thekeyinsightsdiscussedinthispapersuggestthatthebest
agentarchitecturevariesbasedonusecase. Regardlessofthearchitectureselected,thebestperformingagentsystems
tendtoincorporateatleastoneofthefollowingapproaches: welldefinedsystemprompts,clearleadershipandtask
division,dedicatedreasoning/planning-execution-evaluationphases,dynamicteamstructures,humanoragentic
feedback,andintelligentmessagefiltering. Architecturesthatleveragethesetechniquesaremoreeffectiveacrossa
varietyofbenchmarksandproblemtypes.
WhilethecurrentstateofAI-drivenagentsispromising,therearenotablelimitationsandareasforfutureimprovement.
Challengesaroundcomprehensiveagentbenchmarks,realworldapplicability,andthemitigationofharmfullanguage
modelbiaseswillneedtobeaddressedinthenear-termtoenablereliableagents. Byexaminingtheprogressionfrom
staticlanguagemodelstomoredynamic,autonomousagents,thissurveyaimstoprovideaholisticunderstandingofthe
currentAIagentlandscapeandofferinsightforthosebuildingwithexistingagentarchitecturesordevelopingcustom
agentarchitectures.
11References
[1] TimoBirretal.AutoGPT+P:Affordance-basedTaskPlanningwithLargeLanguageModels.arXiv:2402.10778
[cs]version:1.Feb.2024.URL:http://arxiv.org/abs/2402.10778.
[2] Weize Chen et al. AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors.
arXiv:2308.10848[cs].Oct.2023.URL:http://arxiv.org/abs/2308.10848.
[3] KarlCobbeetal.TrainingVerifierstoSolveMathWordProblems.arXiv:2110.14168[cs].Nov.2021. URL:
http://arxiv.org/abs/2110.14168.
[4] XueyangFengetal.LargeLanguageModel-basedHuman-AgentCollaborationforComplexTaskSolving.2024.
arXiv:2402.12914[cs.CL].
[5] IsabelO.Gallegosetal.BiasandFairnessinLargeLanguageModels:ASurvey.arXiv:2309.00770[cs].Mar.
2024.URL:http://arxiv.org/abs/2309.00770.
[6] SilinGaoetal.EfficientToolUsewithChain-of-AbstractionReasoning.arXiv:2401.17464[cs].Feb.2024.URL:
http://arxiv.org/abs/2401.17464.
[7] MorGevaetal.DidAristotleUseaLaptop?AQuestionAnsweringBenchmarkwithImplicitReasoningStrategies.
arXiv:2101.02235[cs].Jan.2021.URL:http://arxiv.org/abs/2101.02235.
[8] ShahriarGolchinandMihaiSurdeanu.TimeTravelinLLMs:TracingDataContaminationinLargeLanguage
Models.arXiv:2308.08493[cs]version:3.Feb.2024.URL:http://arxiv.org/abs/2308.08493.
[9] XudongGuoetal.EmbodiedLLMAgentsLearntoCooperateinOrganizedTeams.2024.arXiv:2403.12482
[cs.AI].
[10] DanHendrycksetal.MeasuringMassiveMultitaskLanguageUnderstanding.arXiv:2009.03300[cs].Jan.2021.
URL:http://arxiv.org/abs/2009.03300.
[11] Sirui Hong et al. MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. 2023. arXiv:
2308.00352[cs.AI].
[12] XuHuangetal.UnderstandingtheplanningofLLMagents:Asurvey.2024.arXiv:2402.02716[cs.AI].
[13] Carlos E. Jimenez et al. SWE-bench: Can Language Models Resolve Real-World GitHub Issues?
arXiv:2310.06770[cs].Oct.2023.URL:http://arxiv.org/abs/2310.06770.
[14] Fangyu Lei et al. S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models.
arXiv:2310.15147[cs].Oct.2023.URL:http://arxiv.org/abs/2310.15147.
[15] FangruLinetal.Graph-enhancedLargeLanguageModelsinAsynchronousPlanReasoning.arXiv:2402.02805
[cs].Feb.2024.URL:http://arxiv.org/abs/2402.02805.
[16] NaLiuetal.FromLLMtoConversationalAgent:AMemoryEnhancedArchitecturewithFine-TuningofLarge
LanguageModels.arXiv:2401.02777[cs].Jan.2024.URL:http://arxiv.org/abs/2401.02777.
[17] Xiao Liu et al. AgentBench: Evaluating LLMs as Agents. arXiv:2308.03688 [cs]. Oct. 2023. URL: http:
//arxiv.org/abs/2308.03688.
[18] Zijun Liu et al. Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team
Optimization.2023.arXiv:2310.02170[cs.CL].
[19] YoheiNakajima.yoheinakajima/babyagi.original-date:2023-04-03T00:40:27Z.Apr.2024.URL:https://
github.com/yoheinakajima/babyagi.
[20] PeterS.Parketal.AIDeception:ASurveyofExamples,Risks,andPotentialSolutions.arXiv:2308.14752[cs].
Aug.2023.URL:http://arxiv.org/abs/2308.14752.
[21] GregSerapio-Garcíaetal.PersonalityTraitsinLargeLanguageModels.2023.arXiv:2307.00184[cs.CL].
[22] ZhengliangShietal.LearningtoUseToolsviaCooperativeandInteractiveAgents.arXiv:2403.03031[cs].Mar.
2024.URL:http://arxiv.org/abs/2403.03031.
[23] NoahShinnetal.Reflexion:LanguageAgentswithVerbalReinforcementLearning.arXiv:2303.11366[cs].Oct.
2023.URL:http://arxiv.org/abs/2303.11366.
[24] AmirTaubenfeldetal.SystematicBiasesinLLMSimulationsofDebates.arXiv:2402.04049[cs].Feb.2024.
URL:http://arxiv.org/abs/2402.04049.
[25] YuTianetal.EvilGeniuses:DelvingintotheSafetyofLLM-basedAgents.arXiv:2311.11855[cs].Feb.2024.
URL:http://arxiv.org/abs/2311.11855.
[26] Qineng Wang et al. Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?
arXiv:2402.18272[cs].Feb.2024.URL:http://arxiv.org/abs/2402.18272.
[27] Siyuan Wang et al. Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation.
arXiv:2402.11443[cs].Feb.2024.URL:http://arxiv.org/abs/2402.11443.
12[28] ZhenhailongWangetal.UnleashingtheEmergentCognitiveSynergyinLargeLanguageModels:ATask-Solving
AgentthroughMulti-PersonaSelf-Collaboration.2024.arXiv:2307.05300[cs.AI].
[29] JasonWeietal.Chain-of-ThoughtPromptingElicitsReasoninginLargeLanguageModels.arXiv:2201.11903
[cs].Jan.2023.URL:http://arxiv.org/abs/2201.11903.
[30] YueWuetal.SmartPlay:ABenchmarkforLLMsasIntelligentAgents.arXiv:2310.01557[cs].Mar.2024.URL:
http://arxiv.org/abs/2310.01557.
[31] Zhiheng Xi et al. The Rise and Potential of Large Language Model Based Agents: A Survey. 2023. arXiv:
2309.07864[cs.AI].
[32] ShunyuYaoetal.ReAct:SynergizingReasoningandActinginLanguageModels.arXiv:2210.03629[cs].Mar.
2023.URL:http://arxiv.org/abs/2210.03629.
[33] ShunyuYaoetal.TreeofThoughts:DeliberateProblemSolvingwithLargeLanguageModels.arXiv:2305.10601
[cs].Dec.2023.URL:http://arxiv.org/abs/2305.10601.
[34] MuruZhangetal.HowLanguageModelHallucinationsCanSnowball.arXiv:2305.13534[cs].May2023.URL:
http://arxiv.org/abs/2305.13534.
[35] Wenting Zhao et al. “(InThe)WildChat: 570K ChatGPT Interaction Logs In The Wild”. In: The Twelfth In-
ternationalConferenceonLearningRepresentations.2024. URL:https://openreview.net/forum?id=
Bl8u7ZRlbM.
[36] AndyZhouetal.LanguageAgentTreeSearchUnifiesReasoningActingandPlanninginLanguageModels.
arXiv:2310.04406[cs].Dec.2023.URL:http://arxiv.org/abs/2310.04406.
[37] Kaijie Zhu et al. DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents.
arXiv:2402.14865[cs].Feb.2024.URL:http://arxiv.org/abs/2402.14865.
[38] KaijieZhuetal.DyVal:DynamicEvaluationofLargeLanguageModelsforReasoningTasks.arXiv:2309.17167
[cs].Mar.2024.URL:http://arxiv.org/abs/2309.17167.
13