EUROVIS2024/C.Tominski,M.Waldner,andB.Wang ShortPaper
Interaction Techniques for Exploratory
Data Visualization on Mobile Devices
LukeS.Snyder1,RyanA.Rossi2,EunyeeKoh2,JeffreyHeer1,andJaneHoffswell2
1UniversityofWashington,USA2AdobeResearch,USA
A B C
D E F
Figure1:Interactionsformobileexploratorydatavisualization:(A)astackedbarchartofUSpopulationdatabyage,withthemenuopened
ontheright;(B)theuserdragsalongbothaxestoINSPECTthedataviaatooltip;(C)theuserdragsalongthex-axistoINSPECTandtapsto
SELECTthestateswiththehighestpopulation(CA,FL,NY,TX);(D)toaidcomparison,theuserdoubletapstoFOCUSontheselectedmarks
anddragsalongbothaxestofurtherINSPECTthem;(E)toreturntotheinitialviewfromStep1,theusershakestheirdevicetoRESET,and
tapstheAGGREGATEbuttontoshowtheMAX(population)foreachagegroup;theuserthentapstheage<10mark;(F)toINSPECT
theselectedmarkintheoriginalcontext,theusertapstheAGGREGATEbuttonagaintoreturntotheunaggregatedview,whichshowsthatCA
hasthelargestpopulationforage<10.Ademovideoshowcasingtheseinteractionsisavailableonlineathttps://osf.io/e2ng8/.
Abstract
Theubiquityandon-the-goavailabilityofmobiledevicesmakesthemcentraltomanytaskssuchasinterpersonalcommunica-
tionandmediaconsumption.However,despitethepotentialofmobiledevicesforon-demandexploratorydatavisualization,
existingmobileinteractionsaredifficult,oftenusinghighlycustominteractions,complexgestures,ormulti-modalinput.We
synthesizelimitationsfromtheliteratureandoutlinefourmotivatingprinciplesforimprovedmobileinteraction:leverageubiq-
uitousmodalities,prioritizediscoverability,enablerapidin-contextdataexploration,andpromotegracefulrecovery.Wethen
contributethirteeninteractioncandidatesandconductaformativestudywithtwelveparticipantswhoexperiencedourinterac-
tionsinatestbedprototype.Basedontheseinterviews,wediscussdesignconsiderationsandtradeoffsfromfourmainthemes:
preciseandrapidinspection,focusednavigation,single-touchandfixedorientationinteraction,andjudicioususeofmotion.
CCSConcepts
•Human-centeredcomputing → Interactiondesign;Mobiledevices;Touchscreens;Informationvisualization;
1. Introduction interactive,data-drivencontent[CKH19],mobilevisualizationsare
typicallystaticorotherwiseretainthedesktopinteractionsinfavor
Nine-in-tenAmericansownasmartphone[Pew24],makingmobile
ofresponsivedesignsthataresimplerormorereadable[HLL20].
devicesakeyformfactorforon-the-gotasks,includingnavigation,
shopping, interpersonal communication, and media consumption. Mobileinteractionscanbetterfacilitateexploratoryvisualization
Exploratorydatavisualizationexhibitssimilarpotentialformobile byretainingthedetailedinformationcommonfordesktop-firstde-
utility,suchason-demandhealthandfitnesstrackingorfinancial signs.However,currentapproachesoftenmakeuseofcustominter-
monitoring.However,despitemobileusers’desiretoengagewith actionsforspecificcharts[SS14,GKT∗15,BLC12,SHV∗19],com-
©2024TheAuthors.
ProceedingspublishedbyEurographics-TheEuropeanAssociationforComputerGraphics.
ThisisanopenaccessarticleunderthetermsoftheCreativeCommonsAttributionLicense,which
permitsuse,distributionandreproductioninanymedium,providedtheoriginalworkisproperly
cited.
4202
rpA
71
]CH.sc[
1v20611.4042:viXraSnyderetal./InteractionTechniquesforExploratoryDataVisualizationonMobileDevices
plexgestures[IH12,WMW09,RK14,XGB∗22],ormulti-modalin- knowledge,thisworkisthefirsttocontributeaconsistentandex-
putsuchasvoiceandpen[SLHR∗20,JLLS17].Theseinteractions pressivesetofmobileinteractionsthatutilizesimple,directinputs
canbeinconsistentacrossdifferentapplicationsorusecases,mak- (i.e.,touchandmotion)togeneralizeacrossvisualizationtypes.
ingthemdifficulttodiscoverandremember.Mobile’slimitedtouch
vocabulary(tapanddragcombinations)resultsinatensionbetween
interactionsthataresimpleandeasytolearnwhilebeingexpressive 3. MobileInteractions
enoughforuserstodisambiguatetheirintents[LDIC21].
Toaddressthelackofconsistent,easy-to-usemobileinteractions
We synthesize the key limitations from prior work to motivate for exploratory data visualization, we contribute thirteen interac-
fourdesignprinciplesforimprovedmobileinteraction:(1)leverage tionsrootedinsimpletouchandmotion(Table1).Inthissection,
ubiquitousmodalitiestoprovideconsistentaccessondifferentde- wepresentfourmotivatingprinciplesthatinformourproposedin-
vicesandapplications;(2)prioritizediscoverabilitytoensureease- teractioncandidates.Wethenimplementtheseinteractionsinavi-
of-use;(3)enablerapid,in-contextdataexplorationtosupportmo- sualizationsystemdevelopedasaplatformtotestandexplorethese
bileefficiency;and(4)promotegracefulrecoveryforimmediateer- interactionswithusers(§4).Ourinteractionsarebestillustratedin
rorcorrection.Wethenproposethirteenmobileinteractionsrooted
ourvideodemoavailableonlineathttps://osf.io/e2ng8/.
inbasictouchandmotion.Weshowhowtheseinteractionscanap-
plytothreecommonvisualizations(scatter,bar,multi-line)through
3.1. MotivatingPrinciples
interviewswithtwelveparticipantsusingatestbedprototype.Our
resultshighlightdesignconsiderationstofacilitate(1)preciseand Wesurveyedpriorart,startingfromLeeetal.’s[LDIC21]surveyof
rapiddatainspection,(2)focusednavigation,(3)single-touchand interactionformobilevisualization,toidentifyexistinglimitations
fixedorientationoptions,and(4)judicioususeofmotion. andfouroverarchingprinciplesforimprovedmobileinteraction:
M1:Leverageubiquitousmodalities.Mobileinteractionsshould
2. RelatedWork usemodalitiesthatcanbeleveragedanywhereandanytime,avoid-
ingthosethatmaybeunavailable(e.g.,pen[SLHR∗20,JLLS17])or
Extensivepriorworkhasexploreddifferentinteractionparadigms, inappropriateincertaincontexts(e.g.,voice[SLHR∗20]).Modal-
suchaspeninterfaces[BM13,JLLS17],gestures[IH12,WMW09, itiesthatapplyonlytoagivencontextwouldrequireimplementa-
XGB∗22],tactilestimulation[WBAI19],motionandspatialinter-
tionofmultiplemodalitiesforthesametask,andresultinalarger
action [KKTD17,LHD17,BYK∗21], augmented reality [GSI19], interactionspacethatmightbemoredifficultforuserstoremember.
andvoiceornaturallanguageinput[SLHR∗20,KLSC21].Multi-
modalsystems[SLHR∗20,JLLS17]canprovideflexibilityforin- M2:Prioritizediscoverability.Mobileinteractionsshouldutilize
teractivevisualizations,allowinguserstodisambiguatetheirintents simple,familiargestures(e.g.,tap,swipe,pinch,orspread).Com-
acrosspreferredinteractions;however,theirpracticaladoptionfor
plexdesignsforspecifictasksorvisualizations[BLIC18,SHV∗19,
mobileremainslimited.Forinstance,peninputmaynotalwaysbe
SS14,BLC12,GKT∗15,EEE∗20,App24]offerincreasedexpressiv-
available and has typically been used for larger displays such as ityattheexpenseofdiscoverabilityandease-of-use.
tablets[SLHR∗20,JLLS17],whereasvoiceinputmaynotbesuit-
M3:Enablerapid,in-contextdataexploration.On-demandmo-
ableinmanysocialcontexts.Wegroundourinteractionsintouch bile visualization necessitates efficient exploration, including the
andmotiontoensurethattheycanbeusedanywhereandanytime.
abilitytoquicklyinspectandselectdatawhilemaintainingcontext
Whilepeoplehavehistoricallyexpressedapreferencefortouch forcomparison.Existinginteractionsoftenfailtodoso,inpartdue
inputsovertraditionalWIMP(Windows,Icons,Menus,Pointer)in- tolimitedscreenspace,markocclusion,and“fat-fingering”(e.g.,
terfaces[DFS∗13],currenttouchinterfacesareoftenspecializedto unintendedtouchinputswhenselectingasmallmark)[LDIC21].
specificcharttypes,suchastimeseries[BLIC18,SHV∗19],stock Usersaregenerallyforcedtotediouslyselectindividualmarksof
charts[App24],scatterplots[SS14],stackedgraphs[BLC12],and interest,navigatingtoreduceclutterasneeded(e.g.,zoominginto
networks[GKT∗15,EEE∗20].Suchidiosyncraticdesignstypically selectoverlappingpointsandthenzoomingoutforcontext).
lackdiscoverabilityorfailtogeneralizetoothervisualizationtypes. M4:Promotegracefulrecovery.Mobileinteractionsshouldmake
Forinstance,Brehmeretal.[BLIC18]implementtouch-basedse- discretechangestoavisualization,allowinguserstoquicklyreturn
lection over time ranges, but this interaction breaks down when toapreviousstateifdesired.Statefulinteractionsarevitalforef-
marksoverlaporoccludeeachother,asinatypicalscatterplot. ficient correction on mobile devices given that unintended touch
actionsaremorecommonwithsmallscreens[LDIC21].
Lee et al. [LDIC21] outline other post-WIMP interactions for
mobile devices (e.g., accelerometers, haptic feedback, GPS, and
cameras).Leeetal.furthernotecoreissueswithexistingmobilein-
3.2. Candidates
teractionsthatmotivateourwork,suchas“fat-fingering”(i.e.,unin-
tendedtouch)andocclusionduetolimitedmobilescreenspace,as Guidedbyourdesignprinciples,wederivedasetofthirteeninter-
wellasalimitedtouchvocabulary,whichisexhibitedbymanycur- action candidates (Table 1), which were refined from discussions
rent tools, e.g., Vega-Lite [SMWH16], Observable Plot [Obs22], duringourformativestudy(§4.2).Thesecandidatesusetouchand
Mosaic[HM23],andDIVI[SH23].Thesetoolseitherlimittheex- motion(M1:Ubiquitous)withbasicinputs(M2:Discoverable),
pressivenessofpossibleinteractions,ornecessitatemorecomplex includingtap,doubletap,drag,andshake/tilt.Ourthirteeninter-
gesturesthatarehardtodiscoverandremember[WMW09].Toour actioncandidatescoversixcommonvisualizationtasks[BM13]:
©2024TheAuthors.
ProceedingspublishedbyEurographics-TheEuropeanAssociationforComputerGraphics.Snyderetal./InteractionTechniquesforExploratoryDataVisualizationonMobileDevices
Task Mechanism Intent Input(s)
Dragfingersalongaxes(two-fingerinspection)
Inspect Highlightmarkfordetails-on-demand
Dragfingerinx/ydirection(single-fingerinspection)
Dragw/lasso Selectmarkswithinlassoregion
Select Tapmark Selectmarkorlegendgroup
Tapaxis Selectactivelyinspectedmark(s)
Focus Doubletap Focus(zoom+inclusivefilter)selection
Remove Quicklyswipe Removeselectionfromview(exclusivefilter)
Selectmergefrommenu Aggregateactiveselection(defaultsbyx-axisencoding)
Aggregate Selectencodingfrommenu Aggregateselectionbyencoding
Selectaggregateoperatorfrommenu Changeaggregationfunction
Reset Quicklyshakeortilt Resetview
Undo Selectundofrommenu Undointeractionview
Redo Selectredofrommenu Redointeractionview
Table1:Ourthirteeninteractioncandidates.EachcandidatedescribestheTASKthattheuserwantstoperform,theMECHANISMtoexecute
theinteraction,theuserINTENT,andtheINPUTtypefromtouch(directtap ,drag ,ormenu )andmotion(shakeortilt )modalities.
INSPECT: Users can drag their fingers along an axis to insert a correspondingattribute,butparticipantsinourformativestudypre-
vertical or horizontal line (Fig. 1B) that displays a tooltip for in- ferredmenuoptionstoaiddiscoverability(M2:Discoverable).
tersecting marks to aid rapid exploration (M3: Contextual). By
RESET/UNDO/REDO:Userscanresetthevisualizationbyshak-
usingtwofingers(oneforeachaxis),theusercanquicklyselecta
ingortiltingtheirmobiledeviceenergetically,aswellasreturnto
singlepointtoinspect.Onefingercanalsobeusedfordual-axisin-
apreviousstate(M4:Recoverable)viaundo/redoicons(Fig.1E)
spection;toaiddiscoverability,weaddajoystickbutton(Fig.1A)
forfasterrecoveryandexploration(M3:Contextual).Ourinitial
toenableone-handedmode(M2:Discoverable).Thisinteraction
prototypeusedmotionforUNDO/REDO,butfrustratedsomepar-
was carefully designed to resolve mobile issues with “fat-finger”
ticipants(§4.2)whofoundthefrequentuseofmotiontiresome.
selection due to limited screen space [LDIC21] (e.g., needing to
continually zoom in and out in order to select the correct point).
4. FormativeStudy
Based on feedback from our formative study participants (§4.2),
wealsoimplementedeven-spacedcontrolwheninspectingmarks. Weconductedaformativestudywithtwelveparticipantstoassess
Specifically,foragivenaxisinspectionline,wecountthenumber theusabilityofourproposedinteractioncandidates;wethenlever-
ofintersectedmarksanddividetheinspectionrange(x-axiswidth agedtheseresultstofurtheriterateonourinteractions(§3.2).
or y-axis height for two-finger interaction, or thumb range
for single-finger interaction) for even, step-wise movement. This
4.1. Methods
changeresolvesdifficultywithinspectingneighboringmarks,ex-
hibitedbypopulartoolsthatuseclosestdistance[Obs22,HM23]. Weconductedsemi-structuredinterviewswithtwelveparticipants:
onesoftwareengineer,tengraduatestudents,andoneundergradu-
SELECT:Weretainfamiliarselectioninteractionsforbetterdiscov- ate,allfromcomputerscience.Eachinterviewwasconductedover
erability(M2:Discoverable):tapamark(Fig.1C,E),tapalegend MicrosoftTeamsandlastedaboutonehour.Participantsjoinedvia
marktoselectthegroup,ordragtoselectanarea. bothdesktopandphonetobetterrecordhowtheyphysicallyinter-
actedwiththeirmobiledevices.Forexample,weobservedifthey
FOCUS:Userscanquicklynavigatetoanactiveselectionviadou-
interacted ina one- or two-handedfashion, what orientation they
bletap(Fig.1D),whichremovesunselectedmarksandrescalesthe
gravitatedtowards,andhowtheyusedmotion(e.g.,shakingortilt-
axes(i.e.,zooms)tofittheselection.FOCUSstoresthepriorview’s
ing).Theinterviewsbeganwithanopen-endeddiscussionofissues
state, allowing users to quickly return via UNDO (M4: Recover-
facedwhenexploringdataonmobiledevices.Participantsthenper-
able)iftheywishtoexploreanotherarea(M3:Contextual).Our
formedeachinteractioncandidateacrossseveralvisualizations.Fi-
initial FOCUS interactiondecoupledfilterandnavigation,butpar-
nally,participantssharedtheiroverallimpressionsandfeedback.
ticipants from the formativestudy (§4.2) noted that this coupling
wouldbefaster(M3:Contextual)and,whencombinedwith IN- Participantsinteractedwiththreecommoncharttypes:(1)ascat-
SPECT,forgoestheneedtocontinuallyzoominandout. terplotoftheIrisdataset[Iri],(2)abarchartshowingUnitedStates
populationdata[USA],and(3)amulti-linechartofunemployment
REMOVE:Userscanexclusivelyfilteranactiveselection(i.e.,re-
datafromtheBureauofLaborStatistics[Bur].Weaskedpartici-
movetheselectedpoints,ratherthanfocusingonthem)byquickly
swipingthescreen,assuggestedbypriorart[DFS∗13]. pantstoperformeachinteractionindividually(e.g.,“INSPECTany
mark”, “REMOVE any mark”, and “AGGREGATE any marks”) to
AGGREGATE:Userscanaggregateanactiveselection,changethe ensurecoverageoverallinteractions.Afterperformingeachcandi-
attributebeingaggregatedby,andmodifytheaggregationfunction date,participantswereaskedforimmediateimpressionsandopen-
viamenuoptions(Fig.1E).Temporalandquantitativeaggregation endedfeedbackontheease-of-use(M1:Ubiquitous,M3:Contex-
automaticallybinsthedata,providingusefulon-demanddistribu- tual),discoverability(M2:Discoverable),andsuggestedimprove-
tion metrics (M3: Contextual). We used direct manipulation for ments.Wedidnotaskopen-endedanalysisquestions,thoughsuch
AGGREGATEinitially,suchastappinganaxistoaggregatebythe questionsmaybeusefultoassesslearnabilityinfuturework(§5).
©2024TheAuthors.
ProceedingspublishedbyEurographics-TheEuropeanAssociationforComputerGraphics.Snyderetal./InteractionTechniquesforExploratoryDataVisualizationonMobileDevices
4.2. Results participantsneededtoaccesstheirphonesettingstodisablelocked
orientation.Relianceonlandscapeorientationhascausedfrustra-
Thefirstauthorperformedopencodingonthequalitativefeedback.
tioninthepast,withP3observingthat“Landscapemodeisgiven
Wethenidentifiedthefollowingfourprimarycategories:
moreattentionbutnotasconvenient.”
PreciseandRapidInspection.Duringthediscussionofexisting
However, some participants (3/12) preferred two-handed inter-
challenges with mobile interactions, all participants described is-
actionsthatcanbeperformedinlandscapemode.P8likedthepre-
sueswithselectingdataduetothelimitedscreenspaceand“fat-
cisionofthetwo-fingerversion,andP10remarkedthat“Ifyou’re
fingering.” One participant noted that interleaving text and visual
doingexploring,Ithinkyou’reabitmoreinvestedandyou’rego-
information,asinthecaseofnewscontent,sometimesleadstoun-
ingtoholdyourphonesidewaysandyou’regonnagetbothfingers
intendedselectionofnearbytext(P3).Thislimitationoftenencour-
agedparticipantstoprioritizedesktopdevicesfordataexploration
inthere.”OuroriginalINSPECTinteractionrequiredtwofingersto
movealongbothaxes.However,givenpreferenceforone-handed
and analysis to ensure precise, controlled exploration via mouse
support,wealsodevelopedasingle-fingerversiontocontrolmove-
hovering(aninteractionoftenoverlookedonmobile).Infact,two
mentalongbothaxes,equivalenttoajoystick(asP10noted).Par-
participants reflected on this mismatch between available mobile
ticipants who used this newly implemented, single-finger version
interactions, and common analysis tasks: “I have a smart watch
highlighted “that it’s easier because the thumb is far away from
and so I have the app on my phone where I can look at...health
theactualpoint”(P7).Oneparticipantwasleft-handed,butdidnot
data.Therehavedefinitelybeenmomentswhere...Iexpectedtobe
experienceanyissuessincesingleanddual-axisinteractions(e.g.,
abletohover”(P6);“InspectiswhathappenswhenIhoverover
y-axisinspection)canbeperformedoneithersideofthescreen.
somethingwithmymouseandselectiswhathappenswhenIclick.
Butinatouch[device]youdon’thavethehoverequivalent”(P10). Judicious Use of Motion. Some participants (3/12) disliked that
existingmobileinteractionscouldnotbequicklyundonewithout
Whenusingourprototype,participantsreactedenthusiastically
refreshing.Thislimitationcandiscourageinteractionandreinforce
toourINSPECTinteraction:“Thisissupercoolthough...It’slikeso
people’spreferenceforstaticcontent.Ourprototypeinitiallyused
satisfyingeventojustdothis”(P1);“Honestly,Iseethisbeingvery
motioninputtoundothemostrecentinteraction,butparticipants
useful.Ireallylikethecontrol”(P5);“I’veneverseenthisjoystick
experiencedusabilityissuesduetounintendedmovement:“shak-
conventionbeforeandIdolikeit.Ithinkit’sareallynovelsolution
ingisjustsomethingthathappensunintentionally,especiallyifI’m
totheinspectproblemontouch”(P10).Basedonfeedbackfrom
walkingwithmyphone”(P4).P2alsoquipped,“Idon’tusemotion
P6, we implemented even-spaced control in lieu of nearest-mark
alottocontrolthingsotherthanlikeMarioKart.”Wethusdecided
selection(c.f.,ObservablePlot[Obs22])topreventflickeringwhen
inspectingneighboringmarks:“it’slikeprettyfinickybecauselike to use motion only for RESET to immediately restart exploration,
andimplementedahigheraccelerationthresholdtoaccommodate
aslightmovementofmyhandwillnolonger[inspect]thecircle.”
users’ baseline movement. Reactions were positive after this up-
InspectandSelect,thenNavigate.Participantsindicatedfrustra- date: “Oh, I just cleaned the graph. Nice” (P5). We then added
tionwithmobilezoomingduringtheinitialdiscussion,e.g.,“Some- menuoptionsforUNDOandREDO(M4:Recoverable)(§3.2).Fu-
times you zoom in and it accidentally interacts with what you’re tureworkshouldcontinuetoexplorenewqualityoflifeimprove-
tryingtozoominto”(P2).Limitedscreenspacealsoresultsinfre- ments,suchastheabilitytolock/unlockthesemotioninteractions.
quentlyzoomingintoselectoccludedmarksandthenzoomingout
forcontext(e.g.,tocomparepoints),whichcanbetedious:“Ifyou
5. Limitations&FutureWork
justkeepzoominginandoutthenthat...becomesannoying”(P8).
Aftertheformativestudy,weaddedourFOCUSinteractionforusers Whileencouragedbytheresultsfromourinitialformativestudy,
toquicklynavigatetoselectedmarksformoredetailedanalysis,re- continuedtestingandrefinementwithmoreusersisneededtosup-
placingtheneedtocontinuallyzoominandout.BasedonP7and portgeneraladoption.Weimaginedesktopwilloftenbepreferred,
P8’s suggestions, FOCUS filters and zooms to an active selection especiallyformoretargetedanalysis,butexpectthatforourcom-
via double tap: “Could be this zoom goes one step ahead in that mon,exploratoryusecases,mobilewillprovideamoredirectand
it’s drawing a bounding box and cutting the points outside that lightweightoption.Thisseparationmayalsodelineateaninterest-
box”(P7);“youtaponsomethingandthenit...zoomsin”(P8). ing space of “hand-off” transitions between mobile and desktop
interaction. We also plan to test semi-automated interactions that
Handedness & Orientation Preferences. Participants’ everyday
mayexpediteexploration,suchasgeneralizedselection[HAW08].
use of their mobile device influenced much of their reactions to
ourprototype.Manyparticipants(9/12)statedthattheylikedour Manyoftheexistingchallengesofmobileinteractionarelikely
prototype’suseoffamiliarmodalities(M1:Ubiquitous)anddirect to be exacerbated by other form factors, like smartwatches, al-
manipulationgestures(M2:Discoverable).Mostparticipantspre- thoughwebelieveourprinciples(e.g.,M2:Discoverable)andde-
ferred single-finger interactions that could be performed without signthemes(e.g.,judicioususeofmotion)canstillinformfuture
needingtochangethewaytheyholdtheirdevice:“Ilikethesim- work.Forinstance,smallerdevicesmightbenefitfromthoughtfully
pleronesthatrequireonefingerbecause...ifyouhavetocoordinate integrating our techniques with recent responsive visualization
twofingers,that’s...lessaccessibleingeneral”(P4).Manypartic- work [KRHH23,KRD∗22,HLL20], employing interaction when
ipantsalsopreferredinteractionsthatcouldbeperformedentirely neededformoredetailedinformation.Whileparticipantslikedour
inasingleorientation(e.g.,notneedingtoswitchbetweenportrait useofsimplemodalitiesandgestures,furtherevaluationisneeded
andlandscapefordifferentinteractions).Whenaskedtoswitchto toassesslearnability,whichcouldbetestedbymeasuringthetime
landscapeorientationforthebarandmulti-linecharts,11outof12 ittakesuserstorememberourinteractionsweeksafterinitialuse.
©2024TheAuthors.
ProceedingspublishedbyEurographics-TheEuropeanAssociationforComputerGraphics.Snyderetal./InteractionTechniquesforExploratoryDataVisualizationonMobileDevices
References [KRD∗22] KIMH.,ROSSIR.,DUF.,KOHE.,GUOS.,HULLMANJ.,
HOFFSWELLJ.: Cicero:Adeclarativegrammarforresponsivevisual-
[App24] https://support.apple.com/guide/iphone/
ization. InACMHumanFactorsinComputingSystems(CHI)(2022).
check-stocks-iph1ac0b1bc/ios,2024.2
4
[BLC12] BAUR D., LEE B., CARPENDALE S.: Touchwave: Kinetic
multi-touchmanipulationforhierarchicalstackedgraphs. InACMIn-
[KRHH23] KIM H., ROSSI R., HULLMAN J., HOFFSWELL J.: Dupo:
Amixed-initiativeauthoringtoolforresponsivevisualization. InIEEE
ternational Conference on Interactive Tabletops and Surfaces (2012),
TransactionsonVisualizationandComputerGraphics(2023).4
pp.255–264.1,2
[BLIC18] BREHMER M., LEE B., ISENBERG P., CHOE E. K.: Visu-
[LDIC21] LEEB.,DACHSELTR.,ISENBERGP.,CHOEE.K.: Mobile
DataVisualization.CRCPress,2021.2,3
alizingrangesovertimeonmobilephones:atask-basedcrowdsourced
evaluation.IEEETransactionsonVisualizationandComputerGraphics [LHD17] LANGNER R., HORAK T., DACHSELT R.: VisTiles:Coordi-
25,1(2018),619–629.2 natingandcombiningco-locatedmobiledevicesforvisualdataexplo-
ration. IEEETransactionsonVisualizationandComputerGraphics24,
[BM13] BREHMERM.,MUNZNERT.:Amulti-leveltypologyofabstract
1(2017),626–636.2
visualizationtasks. IEEETransactionsonVisualizationandComputer
Graphics19,12(2013),2376–2385.2 [Obs22] https://github.com/observablehq/plot/, 2022.
[Bur] https://www.bls.gov/.3 2,3,4
[BYK∗21] BESANÇONL.,YNNERMANA.,KEEFED.F.,YUL.,ISEN- [Pew24] https://www.pewresearch.org/internet/
BERGT.: Thestateoftheartofspatialinterfacesfor3dvisualization.
fact-sheet/mobile/,2024.1
In Computer Graphics Forum (2021), vol. 40, Wiley Online Library, [RK14] RZESZOTARSKIJ.M.,KITTURA.:Kinetica:Naturalisticmulti-
pp.293–326.2 touchdatavisualization.InACMHumanFactorsinComputingSystems
[CKH19] CONLENM.,KALEA.,HEERJ.: Capture&analysisofac- (SIGCHI)(2014),pp.897–906.2
tivereadingbehaviorsforinteractivearticlesontheweb. InComputer [SH23] SNYDER L. S., HEER J.: DIVI:Dynamicallyinteractivevisu-
GraphicsForum(2019),vol.38,WileyOnlineLibrary,pp.687–698.1 alization. IEEETransactionsonVisualizationandComputerGraphics
[DFS∗13] DRUCKER S. M., FISHER D., SADANA R., HERRON J., (2023).2
SCHRAEFELM.: TouchViz:acasestudycomparingtwointerfacesfor [SHV∗19] SCHWABM.,HAOS.,VITEKO.,TOMPKINJ.,HUANGJ.,
dataanalyticsontablets.InACMHumanFactorsinComputingSystems BORKINM.A.:Evaluatingpanandzoomtimelinesandsliders.InACM
(SIGCHI)(2013),pp.2301–2310.2,3 HumanFactorsinComputingSystems(CHI)(2019),pp.1–12.1,2
[EEE∗20] EICHMANNP.,EDGED.,EVANSN.,LEEB.,BREHMERM., [SLHR∗20] SRINIVASAN A., LEE B., HENRY RICHE N., DRUCKER
WHITEC.:Orchard:Exploringmultivariateheterogeneousnetworkson S.M.,HINCKLEYK.:InChorus:Designingconsistentmultimodalinter-
mobile phones. In Computer Graphics Forum (2020), vol. 39, Wiley actionsfordatavisualizationontabletdevices. InACMHumanFactors
OnlineLibrary,pp.115–126.2 inComputingSystems(CHI)(2020),pp.1–13.2
[GKT∗15] GLADISCH S., KISTER U., TOMINSKI C., DACHSELT R.,
[SMWH16] SATYANARAYANA.,MORITZD.,WONGSUPHASAWATK.,
SCHUMANNH.:Mappingtaskstointeractionsforgraphexplorationand HEERJ.: Vega-lite:Agrammarofinteractivegraphics. IEEETransac-
grapheditingoninteractivesurfaces. arXivpreprintarXiv:1504.07844 tionsonVisualizationandComputerGraphics23,1(2016),341–350.
(2015).1,2
2
[GSI19] GOH E. S., SUNAR M. S., ISMAIL A. W.: 3dobjectmanip-
[SS14] SADANAR.,STASKOJ.:Designingandimplementinganinterac-
ulation techniques in handheld mobile augmented reality interface: A
tivescatterplotvisualizationforatabletcomputer.InInternationalWork-
review.IEEEAccess7(2019),40581–40601.2
ingConferenceonAdvancedVisualInterfaces(AVI)(2014),pp.265–
[HAW08] HEERJ.,AGRAWALAM.,WILLETTW.: Generalizedselec- 272.1,2
tionviainteractivequeryrelaxation. InACMHumanFactorsinCom-
[USA] https://data.worldbank.org/indicator/SP.
putingSystems(SIGCHI)(2008),pp.959–968.4
POP.TOTL.3
[HLL20] HOFFSWELLJ.,LIW.,LIUZ.:Techniquesforflexiblerespon-
[WBAI19] WANGX.,BESANÇONL.,AMMIM.,ISENBERGT.: Aug-
sivevisualizationdesign.InACMHumanFactorsinComputingSystems
mentingtactile3ddatanavigationwithpressuresensing. InComputer
(CHI)(2020).1,4
GraphicsForum(2019),vol.38,WileyOnlineLibrary,pp.635–647.2
[HM23] HEERJ.,MORITZD.: Mosaic:Anarchitectureforscalable&
interoperabledataviews.IEEETransactionsonVisualizationandCom-
[WMW09] WOBBROCKJ.O.,MORRISM.R.,WILSONA.D.: User-
definedgesturesforsurfacecomputing.InACMHumanFactorsinCom-
puterGraphics(2023).2,3
putingSystems(SIGCHI)(2009),pp.1083–1092.2
[IH t1 o2 u] chiI nS teE rN aB ctE ioR nG inT. 3, dH enA vN irC oO nC mK enM ts. .: InG Ce Hstu Ir Wes orv ks s. hp oo ps otu nre “s T: h‘ ege 3s rt dur Da il -’ [XGB∗22] XU X., GONG J., BRUM C., LIANG L., SUH B., GUPTA
mensionofCHI:TouchingandDesigning3DUserInterfaces”’(3DCHI)
S.K.,AGARWALY.,LINDSEYL.,KANGR.,SHAHSAVARIB.,ETAL.:
Enablinghandgesturecustomizationonwrist-worndevices. InACM
(2012),pp.53–61.2
HumanFactorsinComputingSystems(CHI)(2022),pp.1–19.2
[Iri] https://archive.ics.uci.edu/dataset/53/iris/.
3
[JLLS17] JOJ.,L’YIS.,LEEB.,SEOJ.: TouchPivot:blendingwimp
&post-wimpinterfacesfordataexplorationontabletdevices. InACM
HumanFactorsinComputingSystems(CHI)(2017),pp.2660–2671.2
[KKTD17] KISTER U., KLAMKA K., TOMINSKI C., DACHSELT R.:
GraSp: Combining spatially-aware mobile devices and a display wall
forgraphvisualizationandinteraction. InComputerGraphicsForum
(2017),vol.36,WileyOnlineLibrary,pp.503–514.2
[KLSC21] KIMY.-H.,LEEB.,SRINIVASANA.,CHOEE.K.: Data@
hand:Fosteringvisualexplorationofpersonaldataonsmartphoneslever-
agingspeechandtouchinteraction.InACMHumanFactorsinComput-
ingSystems(CHI)(2021),pp.1–17.2
©2024TheAuthors.
ProceedingspublishedbyEurographics-TheEuropeanAssociationforComputerGraphics.