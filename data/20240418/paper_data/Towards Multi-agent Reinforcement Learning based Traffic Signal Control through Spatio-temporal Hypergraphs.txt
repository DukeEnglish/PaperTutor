JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 1
Towards Multi-agent Reinforcement Learning based
Traffic Signal Control through Spatio-temporal
Hypergraphs
Kang Wang, Zhishu Shen, Member, IEEE, Zhen Lei, and Tiehua Zhang, Member, IEEE,
Abstract—Traffic signal control systems (TSCSs) are inte- state-of-the-art technologies including information sensing,
gral to intelligent traffic management, fostering efficient vehicle data analysis, and optimization algorithms, the intelligent
flow. Traditional approaches often simplify road networks into
system is expected to automatically adjust the timing of
standard graphs, which results in a failure to consider the
traffic signal control according to real-time traffic conditions.
dynamic nature of traffic data at neighboring intersections,
thereby neglecting higher-order interconnections necessary for Intelligent TSCSs offer significant advantages over static or
real-time control. To address this, we propose a novel TSCS manually controlled methods. These systems leverage real-
framework to realize intelligent traffic control. This framework time and historical data collected by monitoring sensors and
collaborateswithmultipleneighboringedgecomputingserversto
cameras to make superior decision-making. Additionally, they
collecttrafficinformationacrosstheroadnetwork.Toelevatethe
have the ability to optimize the timing and cycle of traffic
efficiency of traffic signal control, we have crafted a multi-agent
soft actor-critic (MA-SAC) reinforcement learning algorithm. signal based on the current traffic flow, thereby improving the
Within this algorithm, individual agents are deployed at each road condition.
intersection with a mandate to optimize traffic flow across Efficient control of traffic signals based on real-time status
the entire road network collectively. Furthermore, we introduce
of intersections is crucial for achieving effective operation of
hypergraphlearningintothecriticnetworkofMA-SACtoenable
TSCSs. The traditional centralized intelligent systems require
the spatio-temporal interactions from multiple intersections in
the road network. This method fuses hypergraph and spatio- to upload the collected traffic data to a remote central server.
temporal graph structures to encode traffic data and capture This process leads to an increase in data processing time and
the complex spatial and temporal correlations between multiple computationaloverhead,whichcancompromisetheefficiency
intersections.Ourempiricalevaluation,testedonvarieddatasets,
oftheTSCSs[5].Edgeintelligenceisapromisingtechnology
demonstrates the superiority of our framework in minimizing
that distributes the computational capability to the edge de-
average vehicle travel times and sustaining high-throughput
performance. This work facilitates the development of more vices in the vicinity of the end users [6], [7]. Integrating edge
intelligent and reactive urban traffic management solutions. intelligence to TSCSs enables the real-time decision-making,
bywhichthelatencyassociatedwiththedatatransmissionand
IndexTerms—Trafficsignalcontrol,hypergraphlearning,deep
reinforcement learning processingcanbereduced.Inthisstudy,weexplicitlyillustrate
the TSCSs based on edge intelligence, in which a multi-
access edge computing (MEC) server is used to manage the
I. INTRODUCTION
traffic data collected from several road intersections (areas).
TRAFFIC signal control systems (TSCSs) have been
By leveraging the collaboration of multiple neighboring MEC
widelydeployedformonitoringandcontrollingvehicular
servers for data acquisition, model training, and decision-
movements on the roads, by which the traffic flows can be
making, the traffic signal status of all intersections across the
effectively managed to ensure traffic safety [1]. A typical
entire area can be efficiently managed.
methodistocontrolthecoloroftrafficsignalsattheroadinter-
Reinforcement learning algorithms have been widely stud-
sections according to a fixed periodic schedule [2]. However,
ied to achieve effective traffic signal control [8]. Specifically,
this approach fails to incorporate real-time traffic conditions
the problem of controlling traffic signals at multiple intersec-
intotheadjustmentoftrafficlightstatus.Consequently,itmay
tionscanbeformulatedasaMarkovdecisionprocess(MDP),
resultintrafficcongestionduringpeaktraffichoursandenergy
wherein training can yield a policy for selecting the optimal
wastageduetounnecessarycontroloftrafficsignalduringoff-
action at each state [9]. Reinforcement learning algorithms
peak periods. While manual traffic signal control can address
can be applied to solve the MDP by learning the optimal
this issue, its implementation at every road intersection in the
decision on traffic signal control through value functions
real world is both costly and complex.
and policy optimization methods. Among these algorithms,
IntelligentTSCSisaviablesolutiontodynamicallycontrol
soft actor-critic (SAC) is a potential candidate to extract the
the traffic signal cost-effectively [3], [4]. Empowered by the
traffic information due to the inherent stochasticity of the
policy with entropy regularization. State-of-the-art work has
KangWang,ZhishuShenandZhenLeiarewiththeSchoolofComputer
ScienceandArtificialIntelligence,WuhanUniversityofTechnology,Wuhan, demonstrated the effectiveness of the SAC-based method in
China(e-mail:{wangk7733,studentlz}@whut.edu.cn,z shen@ieee.org). training optimally control decisions for traffic signal. The
TiehuaZhangiswiththeCollegeofElectronicsandInformationEngineer-
primary achievement includes attaining a consistently high
ing,TongjiUniversity,Shanghai,China(e-mail:tiehuaz@hotmail.com).
Correspondingauthor:ZhishuShenandTiehuaZhang traffic throughput while substantially reducing the average
4202
rpA
71
]AM.sc[
1v41011.4042:viXraJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 2
travel time for all vehicles [10], [11]. loss, guiding the training of the learning process.
In practice, road network is graph-structured, where inter- • Hypergraph Learning: Based on the proposed frame-
sections and roads can be represented as nodes and edges work, we introduce hypergraph module to enable infor-
respectively.Therecentadvancementofgraphneuralnetwork mation interaction between intersections. In this module,
(GNN)hasdemonstratedthepromisingcapabilitytoautomat- we study the dynamic construction of spatial and tempo-
ically extract the information (traffic features) from adjacent ral hyperedges to capture the spatio-temporal dependen-
intersections [12], [13]. This aligns with the crucial role of cies between multiple traffic signals. Our proposal offers
traffic signals in influencing traffic conditions at intersections, greater flexibility compared to the traditional methods
which can in turn affect neighboring intersections. Further- that solely consider the information of neighboring in-
more, the current traffic conditions at an intersection can have tersections in the surrounding area. To the best of the
an ripple effect on the traffic conditions at nearby intersec- author’s knowledge, this is the first work that introduces
tions in subsequent moments. For this reason, by analyzing the concept of hypergraphs in the field of intelligent
spatio-temporal information, TSCSs can dynamically adjust TSCSs.
the duration of traffic lights to maximize traffic efficiency • Experiments:Weconductextensiveexperimentsonboth
andreducecongestion.Therecentlyproposedspatio-temporal syntheticandreal-worldtrafficdatasets.Theexperimental
GNN-basedmethodhasshownimpressivesuccessinreducing results demonstrate that our proposal can outperform
the average vehicular travel time [14]. However, this method state-of-the-art methods in various metrics including av-
doesnotcomprehensivelytakeintoconsiderationtheinfluence erage travel time and throughput.
thatadjacentintersectionsexertonanindividualintersection’s
The remainder of the paper is organized as follows: Sec-
traffic flow. Consequently, it might not be fully equipped to
tion II summarizes the related work. Section III introduces
navigate the intricate and dynamic traffic conditions typical
the problem formulation. Section IV devises our proposed
of real-world environments. The concept of a hypergraph, an
hypergraph-based deep reinforcement learning method. Sec-
extension of a traditional graph where an edge—referred to
tion V evaluates the performance of our proposal, and the
as a hyperedge—can connect more than two nodes, offers a
paper is concluded with future work in Section VI.
promising alternative [15], [16]. This unique characteristic al-
lowsfortherepresentationofmorecomplexnodecorrelations,
such as those observed in real-world road traffic conditions.
II. RELATEDWORK
Asaresult,hypergraphissuitableforconductinghigher-order This section discusses the state-of-the-art work in terms
network analysis with richer information. of traffic signal control based on reinforcement learning,
BysharingtrafficinformationamongmultipleMECservers, integration of reinforcement learning with graph learning, and
each agent deployed in the road network can obtain the traffic hypergraph learning.
conditionsofotherintersections.Tofacilitatethecoordination
among multiple agents for effective decision-making while
A. Traffic Signal Control Based on Reinforcement Learning
enhancing their capability to process spatio-temporal infor-
mation, we integrate hypergraph learning into the multi-agent The traditional transportation control method includes the
SAC (MA-SAC). Specifically, the agents can dynamically timed-based control that uses a pre-determined plan for cycle
construct spatio-temporal hyperedges and update embeddings length and phase time [17], and that controls the signal that
by leveraging the heterogeneous properties of graphs. There- balancesthequeuelength[18].Recentlyproposedmethodsfo-
fore, the intelligent TSCS framework can dynamically adjust cusonutilizingreinforcementlearningtorealizeself-adaptive
the phase sequence of traffic signals according to the traffic traffic signal control in a single intersection [19].
conditionsateachintersectiontopromoteseamlesstrafficflow Combining deep learning with reinforcement learning can
across intersections. The main contributions of this work are further improve the learning performance of reinforcement
summarized as below: learningin complextrafficscenarios [20].For example,Wang
• Framework: We propose a framework based on edge etal.proposedadoubleq-learningalgorithmfortrafficsignal
intelligence, which involves dividing the entire road net- control [21]. However, the value-based methods like DQN
work into multiple areas and deploying a MEC server in require complex operations to find the maximum reward
each area. This framework provides traffic information value, making it difficult to handle high-dimensional action
exchange between intersections and enables the training spaces. To address this issue, extensive researches have been
of multiple intelligent agents deployed at intersections. conducted on policy-based reinforcement learning. Rizzo et
• Reinforcement Learning: We adopt multi-agent SAC al. proposed a time critic policy gradient method to maximize
(MA-SAC), which is a stable off-policy algorithm based the throughput while avoiding traffic congestion [22]. Chu
on the maximum entropy to the reinforcement learning et al. introduced a multi-agent deep reinforcement learning
framework.Toenhancecoordinationincontrollingtraffic method based on advantage actor-critic (A2C) [23]. However,
conditionsacrossmultipleintersections,weimplementan these methods only include the traffic information of the first-
agent at each intersection. In addition to enabling agents order neighbors of each agent, while those from higher-order
interaction through the dynamical construction of hyper- are neglected. This results in the inaccurate estimation of
graph, we innovatively incorporate the loss generated by trafficflowinformationwithintheroadnetwork,whichinturn
constructing hyperedges into the reinforcement learning hinders the performance of traffic signal management.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 3
B. IntegrationofReinforcementLearningandGraphLearning can establish relationships beyond pairwise connections and
have the potential to extract higher-order correlations from
Wei et al. included the max-pressure metric in the reward
multiplerelatednodes.Hypergraphlearningmethodsaregrad-
functionfortrafficsignalcontrol[24].NeighborRLisamulti-
ually being utilized for clustering and classification problems.
agentreinforcementlearningmethodthatdirectlyconnectsthe
Arya et al. employed geometric hypergraph learning to ac-
observation results from neighboring intersections to the state
complish social information classification, yielding superior
table [25]. However, both method only considers the informa-
performance compared to pairwise standard graphs [32]. Wu
tion from the nearest intersections while ignoring that of the
et al. proposed a hypergraph collaborative network that clas-
distant intersections. Specifically, the deep q-network (DQN)
sifies both vertices and hyperedges [33]. Li et al. employed
methods focus on using vector representations to capture the
geometric hypergraph learning and heterogeneous hypergraph
geometric features of the road network. Nevertheless, these
clusteringtoachievenetworkmotifclustering.Theexperimen-
algorithmsareinsufficienttocopewithcomplexroadnetwork
talresultsdemonstratedthatinhomogeneouspartitioningoffers
involving different topological structures.
significant performanceimprovements invarious applications,
Graph neural networks (GNNs) can automatically extract
including structure learning of rankings, subspace segmen-
features by considering the traffic features between distant
tation, and motif clustering [34]. Wang et al. constructed a
roads by stacking multiple neural network layers [13]. Nishi
hypergraphwithinthetopologicalstructureofsubwaysystems
et al. proposed a method based on reinforcement learning and
and proposes a multi-layer spatio-temporal hypergraph neural
graph learning, where GNNs are deployed to realize efficient
network for subway traffic flow prediction. The effectiveness
signalscontrolatmultipleintersections[26].Specifically,they
oftheproposalisverifiedintermsofpredictionaccuracy[35].
utilized the GNN method proposed in [27] to extract the
Zhangetal.proposedahypergraphsignalprocessing(HGSP)
geometric features of the intersections. Wei et al. proposed
frameworkbasedonthetensorrepresentationtogeneralizethe
CoLight which utilizes graph attention networks to achieve
standard graph signal processing (GSP) to tackle higher-order
trafficsignalcontrol.Specifically,toaddressconflictsinlearn-
interactions [36].
ing the influence of neighboring intersections on the target
In summary, hypergraph combine multiple types of hyper-
intersection, a parameter-sharing index-free learning approach
edges to represent higher-order relationships, thus effectively
that averages the influence across all adjacent intersections is
addressingtheassociationprobleminmulti-modaldata.Given
employed [28].
the presence of complex structural relationships in traffic net-
work, this study introduces hypergraph to efficiently represent
C. Hypergraph Learning
the traffic network. Within the hypergraph, spatial hyperedges
Although the aforementioned standard graph-based meth- and temporal hyperedges are dynamically generated based on
ods are capable of forming pairwise relationships between the road network structure, resulting in a hypergraph with
two nodes, they fail to capture the multi-edge relationships enhanced modeling capabilities. Subsequently, the intersec-
among multiple nodes [29]. For instance, in a real-world tion information is updated using multi-head attention, which
road network, an intersection is not only influenced by its facilitates dynamic spatio-temporal interactions among road
immediate neighbors, but may also by a group of distant intersections.
intersections. Standard graphs are typically represented by
adjacencymatrices tocapture therelationships betweennodes III. PROBLEMSTATEMENT
and edges. However, for the complex network systems like
This section introduces the preliminaries on intelligent
road network, individual nodes may have multiple features,
TSCS and presents the problem description with the problem
resulting in multi-layer interactions among the nodes. The
objective.
standard graph-based methods face challenges in effectively
handlingmultimodaldata.Additionally,thecurrenttrafficcon-
A. Preliminaries
ditions at intersections are influenced by the traffic conditions
ofneighboringroadsintheprevioustimestep.Therefore,itis In this paper, we divide the original road network into
essential to consider the spatio-temporal dependencies among multiple circular areas, while a MEC server is deployed in
different intersections when performing traffic signal control. each of them [9]. Each MEC server covers a certain area
As a prospective solution, the utilization of spatio-temporal of the actual road network and collects traffic information
graphneuralnetworks(STGNNs)isanticipatedtocapturethe around each intersection in the respective area. By sharing
spatialandtemporaldependenciespresentwithinagraph.The traffic information among the MEC servers, the information
implementation of STGNNs allows for a better understanding for various intersections in the entire road network can be
andutilizationoftheintricaterelationshipsinmultimodaldata. acquired. Meanwhile, we assume a road traffic environment
Consequently,thisenhancesthecapabilityofgraphprocessing with three vehicle lanes and four movement directions, i.e.,
for multimodal data, enabling improved performance [30]. East (E), South (S), West (W), and North (N). Each intersec-
The emergence of hypergraph-based methods enables effi- tionisequippedwithatrafficlighttocontrolthetrafficflows,
cienthandlingofmulti-modaldata[31].Incontrasttostandard i.e. Drive Through (T), Turn Left (L) and Turn Right (R),
graphs where each edge can only connect with two nodes, byswitchingamongvariousphases.Aphaseisacombination
hypergraphs introduce multiple hyperedges, which is capable ofnon-conflictvehicularmovementsignals.Fig.1illustratesa
of connecting any number of nodes. Therefore, hypergraphs roadintersectionincludingfourphases:Phase1(ETandWT),JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 4
When each hyperedge e∈E satisfies |e|=2, the hypergraph
N
phase1 will degenerate into the standard graph. In signal light control
phase2 scenarios, using pairwise graphs to represent the relationships
phase3 betweenintersectionsmayleadtothelossofvaluableinforma-
phase4 tion.Hypergraphsaremoresuitableforcapturingtherelevance
of actual data with complex non-pairwise relationships.
B. Problem Description
We define the problem of traffic signal control as a Markov
decision process. The problem is characterized by the follow-
ing major components:
• State Space S: The environment state s t consists of the
number of agents, the current phase of all agents, and
Fig. 1: A road intersection that includes four phases informa- thenumberofvehiclesoneachlaneheadingtowardsthat
tion. agent at time t.
• Observation Space O: At time t, each agent i can only
access a local observation ot, which does not directly
i
provide the complete system state, including all informa-
Phase2 (EL and WL), Phase3 (ST and NT), and Phase4 (NL
tion in the traffic light adjacency graph. As illustrated
and SL). When vehicles are making a right turn at the current
in Fig. 2, o consists of agent information, its current
intersection,theycanbeexecutedinallfourphasesmentioned
phase, the number of vehicles on each lane connected
above.
with the intersection, and the adjacency matrix that to
We use an agent to control the variation of phase for
extract information about the agent and its neighbors.
each intersection. Based on the information of the current
intersection at time t, the agent selects one phase from the • Action A: At time t, each agent i chooses an action at i
(i.e.,phase)forthenextperiodoftime.Theactionstaken
given four phases illustrated in Fig. 1. The selected phase
by an intersection traffic signal control would impact its
will be then implemented at the intersection for the time
surrounding traffic flow, which in turn would influence
duration from t to t+∆t. We set ∆t to 10 seconds to avoid
its observations.
excessive switching of actions by agents. The objective is to
minimize the average travel time of all vehicles in the entire
• Transition probability P: p(s t+1|s t,a t) is the probabil-
ity of transition from state s to s when all the agents
road network. After each change in the phase, a fixed interval t t+1
take joint action a ={at}N ∈A.
(e.g., between 3 to 6 seconds) with a yellow signal will be t i i=1
conducted to regulate the traffic flow.
• Reward R: Agent i obtains a reward r it by reward
function S ×A ×···×A → R. In this paper, the
Regarding the network system, we first define the road 1 N
agent’s objective is to minimize the travel time for all
network structure as a graph G(V,E), where V and E denote
vehicles in the road network.
a set of nodes and edges, respectively. v ∈ V and e ∈ E
i i • Policy π: At time t, agent i chooses an action a based
represent the observation information of i-th node and the i-
on a certain policy O×A→π, aiming to maximize the
th edge, which include the current phase of the traffic lights
total reward.
at the road intersection and the number of vehicles on each
• Entropy H: Entropy is a measure of the randomness or
lane between the sender node and the receiver node. Agent
uncertainty of a random variable. Specifically, H(π(·|s))
i is deployed at i-th road intersection, which is capable of
represents the randomness or stochasticity of a policy π
observing the information of i-th node as well as that of
in a given state s. By incorporating this entropy regular-
all edges connected to this node. Based on the observed
ization term into the objective of reinforcement learning,
information o , agents autonomously select an appropriate
i we maximize the cumulative reward while promoting
phase stage.
Let X = (cid:8) O1,...,OT(cid:9) ∈ RT×N×d denotes a spatial- increased randomness in the policy π.
temporal data containing T timestamps, where Ot = For the given road traffic network, each traffic signal agent
{ot,...,ot }∈RN×d representsthesignalofN roadintersec- iattimetmakesactionat withrewardrt.Theobjectiveisto
1 N i i
tionsatthetimestampt,andthesizeofeachroadintersection’s approximatethetotalreward(cid:80) rt byminimizingtheloss.It
∀i i
featuredimensionisd.WedefineahypergraphasG ={V,E}, is worth noting that, besides the loss defined in reinforcement
where V is the set of node set, E = {E ,...,E } is a set learning algorithm, we additionally include the hypergraph
1 m
of m hyperedges in the hypergraph. E is the hyperedge α, reconstruction loss (See lossRECON in Fig. 2) to enhance the
α i
which is an unordered set of nodes. Each hyperedge e ∈ E trainingperformanceoftheproposedframework.Moredetails
contains two or more nodes. |e| is the size of hyperedge e. will be described in Section IV.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 5
(A) Framework Environment (E) Multi-agent Deep Reinforcement Learning
Base Station H(a|o )
Actor π t+1
MEC
MLP
x
MLP
π φ(a|o t)
MEC1 MEC2
Connection
1 o t
a
Ot-1 Ot
Critic q 1t(o,a) lossR 1ECON
Agents Phase Number of Vehicles Adjacency Matrix Q1 network Q1 Loss
agent1 phase1 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0,1,6,7,2] Ot-1 Ot
age ..n .t2 ph .a ..se4 [0, 1, 0, 0, 0, 3 ., . .0, 0, 0, 2, 0, 0] [2,1, .3 ..,8,7] 2 r, o t+1 Soft Update Q2 network q t(o,a) lossQ R2 EC L ONoss
2 2
TD
Target
(o, a, r, o )
MEC3 MEC4 t t+1 r, o Target Critic q(o , a)
t+1 1 t+1
r, o Q1 target network q(o , a) TD
Replay Memory t+1 Q2 target network 2 t+1 Target
{ O1, ... , OT } (o, a, r, o )
t t+1
(B) Observation Embedding (C) Spatio-Temporal Hypergraph Construction (D) Spatio-Temporal Hypergraph Learning
Ot
MLP H t CS onp sa tt ria ul c tH ioy nperedge Hypere Ud pg de aE tm inb gedding E mM bu el dti d-h ine ga d U pN do ad tie n g vSM l 1aa tvs ete Nr
v
oN 2d to ede TSp e qmat itpi (a o ol r H ,a aly )p He yr ped erg ee dge
Ot-1 H t-1 ... ... ... ... +loss iRECON
Fig. 2: An overview of our proposed framework.
IV. HYPERGRAPH-BASEDDEEPREINFORCEMENT it conducts hypergraph learning process to encode the
LEARNINGALGORITHM attributesintotheembeddingspace.Oneoftheoutputsof
this module is the hypergraph reconstruction loss, which
This section introduces the details of our proposed
will be further utilized in the multi-agent reinforcement
hypergraph-based deep reinforcement learning for traffic sig-
learning module to improve the training performance.
nal control with edge intelligence.
• Multi-agent deep reinforcement learning: The input of
this module is the agent i’s observation ot and reward r.
A. Framework i
A multi-agent soft actor-critic (MA-SAC) is introduced
Fig. 2 illustrates an overview of our proposed framework. toobtainthebestactionat thatminimizesthepredefined
i
In this framework, the road information at each intersection
lossfunction.MA-SACiscomposedofanactornetwork,
is collected from the MEC server. The role of the agent is
two critic networks (Q1 and Q2 network), and two
to make an efficient control decision on the traffic signal
target-critic networks, which are all composed of fully
phase for the respective intersection. Edge intelligence is
connected neural networks.
used to enhance the data processing performance by sharing
the necessary information among various MEC servers. The
B. Observation Embedding
construction of hypergraph involves incorporating multiple
surrounding agents to acquire the spatial and temporal struc- Each MEC server collects and aggregates road information
ture information, i.e., o includes the state information of all observed by agents within MEC’s respective region, such as
t
intersectionsattimet.Meanwhile,thetrainingprocessconsid- thecountofvehiclesineachlaneandthecurrentsignalphase.
ers the historical state information as incorporating temporal We employ multiple fully connected neurons in the multi-
dependency, i.e., (o , o ) that covers the information at layer perceptron (MLP) to achieve non-linear transformations
t t−∆t
time t and t−∆t. and feature extraction on the input d-dimensional features.
The proposed framework includes the following modules: Rectifiedlinearunit(ReLU)functionsareappliedtointroduce
• Observation embedding: It is an initialization module to non-linearity, resulting in an l-dimensional representation as:
obtain the current observation information ot from agent
i ht =Embed(ot)=σ(otW +b ) (1)
i. i i i e e
• Hypergraph Learning: The input of this module is the where ot i ∈ Rd is the observation of agent i at time t, and d
state information Ot and Ot−1. The purpose of this is the feature dimension of intersection i. W ∈ Rd×l and
e
module is to enhance the capabilities of both Critic Q1 b ∈ Rl are trainable weight matrix and bias vector. σ(·)
e
and Q2 networks through the utilization of hypergraph is the ReLU function. The resulting hidden state ht ∈ Rl
i
learning. This module first creates spatial and temporal represents the traffic information of the i-th intersection at
hyperedges separately to build node correlations, then time t. Ht = {ht,...,ht } that represents the initial node
G 1 N
noitcurtsnoC
egderepyH
laropmeT
Graph
ReadoutJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 6
embedding of the entire road network, will be served as the set S˜spa(v˙t) with reconstruction coefficient larger than the
i
inputofthefollowingspatio-temporalhypergraphconstruction threshold ζ are selected to generate a spatial hyperedge of the
process. master node v˙t (See the connected through green solid lines
i
in Fig. 2). In contrast, unselected nodes with reconstructions
coefficient values lower than ζ are connected by dotted lines.
C. Spatio-temporal Hypergraph Construction
This facilitates the dynamic learning of the reconstruction
First, we define the spatio-temporal hypergraph at times-
coefficients between the master node and each other node
tamp t as Gt = {Vt,Et}. To better explore the spatial cor- within the road network. By comparing with threshold ζ,
relation between intersections in road network, we aggregate
we are able to dynamically filter nodes more appropriate for
the features of all intersections represented by Vt ∈ RN×d.
interactions, not merely acquiring the correlation coefficients
By constructing spatial hyperedges, we can capture higher-
of neighbor nodes to the master node. Consequently, our
order spatial correlations among multiple neighboring nodes
approach offers greater adaptability than traditional graph-
compared to the standard graph. Then, to model the temporal
based methods when it comes to handling the interplay of
dependenciesbetweenintersectionsalongthetimedimension,
spatio-temporalinformationbetweenintersections.Thisallows
we utilize the nodes feature of one timestamp previous to
for a refined and contextual response to the ever-changing
capture the historical information [37]. Thus, the node set dynamics of traffic networks. Sspa(v˙t) is denoted as:
Vt contains nodes (state information) from two consecutive i
timestamps,t−1andt,whichisdefinedasVt =(cid:8) Vt,Vt−1(cid:9) . Sspa(cid:0) v˙t(cid:1) =(cid:110) v|v ∈S˜spa(cid:0) v˙t(cid:1) ,pspa(v)>ζ(cid:111) (3)
i i v˙t
The node feature matrices for these timestamps are Ht and i
Ht−1 respectively. G Similarly, as shown in Fig. 2, temporal slave nodes are
G encircledfromVt−1 toformthetemporalhyperedgee (v˙t)
Owing to the dynamic nature of traffic flow and road con- tem i
with the master node based on the trainable reconstruction
ditions, employing initial hypergraph structures alone would
coefficientvectorptem ∈RN.Overall,thelossofhyperedges
overlook the dynamic modifications of such structures from v˙t
generation in one timi estamp is defined as:
adjusted feature embedding. As a result, some important im-
plicitrelationshipsmaynotbedirectlyreflectedintheinherent L = (cid:88) λ(cid:0) c (cid:0) v˙t(cid:1) +c (cid:0) v˙t(cid:1)(cid:1) +(cid:16) ∥pspa∥ +∥ptem∥ (cid:17)
structuralframeworkofhypergraphs.Therefore,itisnecessary recon spa i tem i v˙ it 1 v˙ it 1
i=[1,...,N]
to dynamically modify the hypergraph structure during the (cid:16) (cid:17)
process of model optimization to adapt to the changes of +γ 2 ∥ps v˙p ta∥ 2+∥pt v˙e tm∥ 2
i i
traffic conditions in the road network. We propose a dynamic (4)
learning process that generates two types of hyperedges:
where∥·∥ denotesthel1normofthevectorandc denotes
spatial hyperedges that capture heterogeneity between traffic 1 tem
the reconstruction error of temporal hyperedges. λ is the
light agents, encoding relations among different intersections
weight hyperparameter of the reconstruction error. γ is the
in one timestamp, and temporal hyperedges that scrutinize 2
regularizing factor to balance l1 norm and l2 norm of the two
interactivity of historical traffic flow, modeling the continuous
types of reconstruction coefficient vectors.
interaction of road intersections in consecutive timestamps.
During the dynamic hyperedges generation process, we intro-
D. Spatio-temporal Hypergraph Learning
ducetwokindsofnodes:masternodeandslavenode.Amaster
node v˙ ∈V acts as an anchor when generating the hyperedge 1) Hyperedge Embedding Updating: Let Re represents the
e(v˙) ∈ E, combining with a set of slave nodes S(v˙) = {vˆ} correlation between all nodes (within and not within the slave
to collectively make up the hyperedge. node set Sspa(v˙t)) in the road network and the master node
i
Foreachmasternodev˙t ∈Vtinspatio-temporalhypergraph v˙t at timestamps t, with entries are as below:
i i
Gt at timestamp t, the spatial hyperedge e spa(v˙ it) ∈ Et  1, v =v˙t
can be generated based on the reconstruction of the master Re(cid:0) v,e(cid:0) v˙t(cid:1)(cid:1) = p (v), v ∈Sspai (v˙t) (5)
(cid:8)no vd |ve ∈v˙ it Va tn ,d
v
̸=the v˙ts (cid:9)p ,at wia hl icc han id sid da et ne os tela dve asn :ode set S˜spa(v˙ it) = i

v˙ 0it
,
otherwisei
i
The embedding of hyperedges is aggregated by node features
c spa(cid:0) v˙ it(cid:1) =∥Ht G(cid:0) v˙ it(cid:1) ·θ spa−ps v˙p ta·Ht G(cid:16) S˜spa(cid:0) v˙ it(cid:1)(cid:17) ∥ 2 (2) as follows:
i
w deh ne or te esc s thpa e( lv 2˙ it n) od rmeno ot fe ts heth ve ecs tp oa rt .ia Hl tre (vc ˙o t)ns at nr duc Hti ton (cid:16) Se ˜r sr po ar. (v∥ ˙t· )∥ (cid:17)2 E(cid:0) e(cid:0) v˙ it(cid:1)(cid:1) = (cid:80) v∈ (cid:80)VtRe(v R,e e( (v v˙ it ,) e) (× v˙t)H )t G(v) (6)
G i G i v∈Vt i
are node feature matrices of the master node and the spa- 2) Multi-head Node Embedding Updating: After imple-
tial candidate slave node set respectively. θ spa is a specific menting the update of hyperedges embeddings, we can utilize
trainable projection matrix when generating the spatial hyper- the information from the spatial hyperedge and temporal
edge e spa(v˙ it) ∈ Et. ps v˙p ta ∈ R(N−1) denotes the trainable hyperedges to accomplish the update of the master node
reconstruction coefficienti vector, with each element pspa(v) v˙t. The hyperedges associated with node v˙t is denoted as
v˙t i i
representing the learned reconstruction coefficient ofieach {e (v˙t),e (v˙t)}. We calculate multi-head attention be-
spa i tem i
node v ∈ S˜spa(v˙t) relative to the master node v˙t. Accord- tween the master node and the two types of hyperedge, and
i i
ing to pspa, the nodes in the spatial candidate slave node subsequently employ the normalized attention as the weight
v˙t
iJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 7
for each hyperedge. The calculation process for the weights cumulative expected rewards, but also maximize the expected
of the two types of hyperedge is similar, and we thus take entropy of the policy as:
calculating spatial hyperedge attention as an example: (cid:32) (cid:33)
(cid:88)
π∗ =argmaxE r(o ,a )+αH(π (·|o )) (12)
π t t t t
π
Qh(v˙t)·Θatt ·Kh (v˙t)T ∀t
atth(cid:0) v˙ it,e spa(cid:0) v˙ it(cid:1)(cid:1) = i s√pa spa i (7) where α is temperature parameter that determines the rela-
d
tive importance of the entropy term versus the reward [38].
where H(π t(·|o t)) is the entropy calculated by:
Qh(cid:0) v˙t(cid:1) =Ht (cid:0) v˙t(cid:1) ·Q-Linh (8) (cid:88)
i G i H(π t(·|o t))=− π t(a t|o t)log(π t(a t|o t)) (13)
Kh (cid:0) v˙t(cid:1) =E(cid:0) e (cid:0) v˙t(cid:1)(cid:1) ·K-Linh (9) a
spa i spa i spa To assist the automatic process of tuning the entropy regu-
larization, the expected entropy can be limited to be no less
First, for the h-th attention head atth(v˙t,e (v˙t)), we
apply a linear transformation matrix Q-Lini h s ∈pa Rdi × Kd to than an objective value H 0, and thus, the objective can be
reformulated as a constrained optimization problem as:
project the feature information of the master node v˙t into the
i
h-th query vector Qh(v˙t). The value of K is the number of (cid:32) (cid:33)
i (cid:88)
attentionheads.Additionally,Weprojectthespatialhyperedge π∗ =maxE r(o ,a ) (14)
π t t
e spa(v˙ it)intotheh-thkeyvectorKh spa(v˙ it)onthesamedimen- π ∀t
sion.Next,weapplyatrainableweig √htmatrixΘa sptt
a
∈RKd× Kd s.t.
toobtainh-thspatialattention,and dactsasascalingfactor. E (ot,at)∼ρπ(−log(π t(a t|o t)))≥H 0 (15)
The h-th temporal attention atth(v˙t,e (v˙t)) is calculated
i tem i During the process of adjusting the entropy regularization
in a similar manner. Finally, the weight of the spatial hy-
coefficient for each agent, the temperature parameter α is
peredge wh (v˙t) and the temporal hyperedge wh (v˙t) are
spa i tem i utilizedtoimprovethetrainingperformanceofactornetwork.
calculated by softmax normalization to atth(v˙t,e (v˙t))
i tem i The value of α increases when the entropy obtained from the
and atth(v˙t,e (v˙t)). The attentive aggregation of different
i spa i actor network is lower than the target value H . In this way,
heads among hyperedges for updating node embedding of v˙t 0
i it increases the importance of the policy entropy term in the
(referred to as wavy lines in Fig. 2 is denoted as :
actornetwork’slossfunction.Conversely,decreasingthevalue
Q (cid:0) v˙t(cid:1) =MLP(cid:16) (cid:13) (cid:13) (wh (cid:0) v˙t(cid:1) ×Kh (cid:0) v˙t(cid:1) ofαwillreducetheimportanceofthepolicyentropytermand
Vt i (cid:13) spa i spa i allow for a greater focus on the reward value improvement.
h∈[1,K] Therefore, the choice of the entropy regularization coefficient
+wh (cid:0) v˙t(cid:1) ×Kh (cid:0) v˙t(cid:1) )(cid:17) α is crucial. By automatically adjusting the entropy regular-
tem i tem i
ization term, we derive the loss function for α using simple
(10)
mathematical techniques so that we do not need to set it as a
where(cid:13) (cid:13)representsconcatenation.Wefirstaggregatetwotypes hyperparameter. The loss function of α is defined as:
of hyperedges associated with the master node on the h-th L(α)=E [−αlogπ(a |o )−αH ] (16)
π t t 0
attention head, and then concatenate the results from all K
heads. Subsequently, the node embedding of v˙t is updated by MA-SAC adopts an actor-critic architecture with policy
i
a shallow MLP. We average the node embedding of all nodes and value networks, which can reuse the collected data and
Q in road network at timestamp t to read-out the graph entropy maximization to achieve effective exploration. As
Vt
representation of Gt, which is denoted as Q ∈Rd. illustrated in the upper-right part of Fig. 2, MA-SAC consists
Gt
To realize the procedure in an end-to-end fashion, the loss of six networks: an actor network and four critic networks
function used in the training process is denoted as : (Q1 network, Q2 network, Q1 target network, and Q2 target
network) and an α network. The summary of these networks
L HG =βL
recon+(1−β)MSE(cid:0)
MLP (Q
Gt),yt(cid:1)
(11) is as below:
• Actor network: The actor network is responsible for
where MSE is the mean squared error function. β is a weight
exploring and selecting actions based on the learned
hyperparameter to balance the impact of reconstruction loss
policy, which influences the behavior of the agent in the
and Q-value loss. yt is the target Q-value (referred to as
multi-agent environment. The input includes the batch
TD in Fig. 2)
target size, the number of intersections and state. Based on the
probability that each action to be executed, the training
E. Multi-agent Deep Reinforcement Learning results aim to maximize the overall state value Vπ(o)
calculated by:
We introduce MA-SAC based on the entropy-regularized
reinforcement learning for traffic signal control. In entropy- Vπ(o)=E π(Qπ(o t,a t)+αH(π t(·|o t))) (17)
regularized reinforcement learning, the agent gets a reward r
where Qπ(o ,a ) is the Q-function expressed by:
at each time t proportional to the entropy of the policy at that t t
time. The objective of MA-SAC is to not only optimize the Qπ(o ,a )=E (r(o ,a ,o )+γVπ(o )) (18)
t t π t t t+1 t+1JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 8
Theactornetworkoutputstheprobabilityoftheavailable Algorithm1:Multi-agentSoftActor-Critic(MA-SAC)
actions as π (a |o ) and its respective entropy value as
ϕ t t 1 Initial policy parameters θ, Q-function parameters ϕ 1,
H (a |o ).
π t t ϕ , empty replay buffer D;
2
• Critic network: The critic network is designed to calcu- 2 Set target parameters equal to main parameters
late the Q value to evaluate the action. As illustrated in
ϕ ←ϕ , ϕ ←ϕ ;
targ.1 1 targ.2 2
Fig.2,thecriticalQ-networkrepresentstheestimationof
3 Repeat Observe state s and select action a∼π θ(·|o t);
the action value while the target critic network indicates
4 Store (o t,a t,r t,o t+1) in replay buffer D;
the estimation of the state value. To stabilize the training
5 for each training step
process, the update frequency of target critic networks
6 Sample a random mini-batch of transitions,
is less than that of the critic Q-network. Different from
B ={(o ,a ,r ,o )} from D;
t t t t+1
the actor networks, the output of the critic networkis the
7 Compute targets for the Q functions by
value of Q function as q (o ,a ) and q (o ,a ).
1 t+1 t 2 t+1 t Equation 20;
Algorithm 1 shows the details of our developed MA-SAC 8 Update critic networks by Equation 21;
algorithm.Thisalgorithmmainlyconsistsoftwophases:expe- 9 Update actor networks by Equation 19;
riencegatheringandnetworktraining.Inexperiencegathering 10 Update temperature by Equation 16;
phase, the experience replay mechanism is incorporated to 11 Update target networks with
mitigate the correlation among data samples. Each agent i ϕ ←ρθ +(1−ρ)ϕ ,
targ,1 targ,1 1
performs the actions a generated in each episode, and then ϕ ←ρθ +(1−ρ)ϕ ;
targ,2 targ,2 2
stores the tuples (o t,a t,r t,o t+1) into the replay buffer (line 3 12 end
to 4 in Algorithm 1). 13 Until convergence
The training stage begins once the data in the replay buffer
reaches the given threshold Thres . During each step, some
size
datawillberandomlychosenfromthereplaybuffertoupdate
A. Experimental Settings
theparametersofboththeactornetworksandcriticnetworks.
The actor network updates the target by: We conduct the experiments on CityFlow [39], which is
an open-source traffic simulator that supports city-wide large-
J =E (αlog(π (a |o ))
ot,at i i i (19) scale traffic signal controller and flexible definitions for road
−Qπ i(o t,a 1,...,a N)| ai=πi(oi)),i=1,2 networkandtrafficflow.Afterfeedingthegiventrafficdatasets
into the simulator, a vehicle moves towards its destination
The target for Q functions is expressed by:
according to the environment setting. This simulator provides
y =r + the road state based on the given traffic signal control method
i i
(cid:18) (cid:19) and simulates the behavior of individual vehicles, providing
γE minQ (o ,a˜ )−αlogπ (a˜ |o ) , the detail of traffic evolution in a road network.
i=1,2
ϕtarg,i t+1 t+1 θ t+1 t+1
We introduce four synthetic traffic datasets (Unidirect ,
6×6
a˜ t+1 ∼π θ(·|o t+1) Bidirect 6×6, Unidirect 10×10, and Bidirect 10×10 ) and two real-
(20) world traffic datasets (D , and D ) to validate the
Hangzhou Jinan
robustness of our proposed method. The details of them are
Based on the obtained targets, the critic networks are
as below:
updated by minimizing the loss function calculated by:
• Synthetic dataset: Unidirect and Bidirect indicate uni-
L=(1−β)E (Qπ(o ,a ,...,a )−y )2+βL and bi-directional traffic, respectively. 6×6 and 10×10
ot,at,rt,ot+1 i t 1 N i recon
(21) representthesizeofnetwork,i.e.,a6×6ora10×10grid
where β is a weight hyperparameter to trade off the effects network. For these datasets, each intersection has four
of temporal difference (TD) target and the loss of hyperedges directions as East (E), South (S), West (W), and North
generation (See Equation 4) to enhance the training capability (N). Each direction is with 3 lanes (300 meters in length
of Q1 and Q2 networks in hypergraph learning module. and 3 meters in width). In bi-directional traffic, vehicles
In order to ensure the stability of training, the parameters arrive uniformly with 300 vehicles/lane/hour in W↔E
of both actor networks and critic networks are copied to the direction and 90 vehicles/lane/hour in S↔N direction.
corresponding target networks using the soft update method. Only W→E and N→S directional flows travel in uni-
This process is illustrated in line 11 of Algorithm 1, where ρ directional traffic.
is the update ratio. • Real-world dataset: D Hangzhou and D Jinan are publicly
available real-world traffic data for Hangzhou City and
Jinan City, respectively. The traffic flows are processed
V. EXPERIMENTS
frommultiplesources.Thenumberofintersectionsis16,
and 12 for these two datasets respectively. More details
This section presents a detailed description of the extensive
can be found in [28].
experiments conducted to analyze the performance of our
proposedmethodandvalidateitseffectivenessintrafficsignal The main parameter settings of our proposed methods are
control. summarized in Table I.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 9
TABLE I: Main parameter settings.
larger throughput value indicates the better performance in
Parameter Value traffic signal control.
Batchsize 20 ItisworthnotingthatATTrepresentstheaveragetraveltime
Episodes 50
of all vehicles across the entire road network within a given
Targetentropy -0.5
Learningrate 0.0001(actor),0.01(critic),and0.001(α) time period. In cases where vehicles enter the network but do
Replaymemory(Thressize) 1000 not exit it, a simulated end time is assigned as their exit time
Optimizer Adam
fromthecurrentnetwork.Consequently,thesevehicles,which
Headnumber(K) 1
Discountrate(γ) 0.98 enterthenetworklateranddonotexit,playaroleinreducing
Reconstructionerror(λ) 0.001 the overall ATT for all vehicles. Therefore, throughput also
Regularizingfactor(γ2) 0.2
serves as a crucial evaluation metric, with higher values
Updateratio(ρ) 0.005
indicating that a greater number of vehicles have successfully
completed their trips within the specific time period. This
B. Baseline Methods signifies improved control performance of a given method.
We verify the performance of our proposed hypergraph-
baseddeepreinforcementlearningmethod,referredtoasHG-
DRL, with 6 comparative methods. These methods include
the traditional transportation methods, reinforcement learning
D. Performance Evaluation
methods,andsomethatincorporategraphlearning.Thedetails
of the baseline methods are described as below:
Tables II and III summarize the performance of our pro-
• Fixed-time [17]: Employing a pre-defined plan for cycle posed HG-DRL against the classic transportation methods as
length and phase time in traffic light control. It is widely
wellasstate-of-the-artreinforcementlearningmethodsinboth
applied when the traffic flow is steady.
syntheticandreal-worlddatasets.Theresultsdemonstratethat
• MaxPressure[18]:Implementingtrafficsignalcontrolby our proposed HG-DRL outperforms other comparative meth-
relievingthevehiclesonthelanewithmaximumpressure
odsinalldatasets,achievingtheminimumATTforallvehicles
(a pre-defined metric about upstream and downstream
enteringtheroadnetworkwhilemaximizingthroughput.These
queue length).
findings indicate that our proposal exhibits superior traffic
• PressLight [24]: Utilizing the concept of MaxPressure signal control strategies.
and deep reinforcement learning to effectively optimize Indetails,HG-DRLreducesATTby2.60%and2.63%com-
thepressureateachintersection.Thismethodisdesigned pared to the second-best method GCN-SAC in Unidirect
6×6
to solve the multi-intersection signal control problems. and Bidirect respectively. When the road network scale
6×6
• MPLight [19]: This method utilizes the concept of pres- expands to 10×10, the advantage of our proposal against
sure to achieve signal coordination at the regional level the second-best method grows to 3.46% and 6.63% for uni-
in a reinforcement learning-based approach, while also direction and bi-direction topology respectively. This is be-
employing a network structure specifically designed to causeourintroducedhypergraphcancaptureabundanthigher-
handle unbalanced traffic flow. ordertemporalandspatialcorrelationsbetweenmultipleinter-
• CoLight [28]: A graph attention network is intro- sectionsinlarge-scaleroadnetwork.Meanwhile,inreal-world
duced in the reinforcement learning setting of multi- datasetD ,HG-DRLcanreduceATTby14.85%compared
Jinan
intersection traffic signal control to enhance coordination to the second-best method Colight. This is due to the fact that
and decision-making. thedrivingpathsofvehiclesinrealdatasetsaremorecomplex
• GCN-SAC: We design this method for conducting ab- thanthesyntheticdatasets,andourproposedalgorithmcandy-
lation experiments to validate the performance between namicallyprocesskeyinformationfrommultipleupstreamand
standard graphs and hypergraphs. In the reinforcement downstream intersections based on historical road conditions.
learning module, we set GCN-SAC to be the identical Regarding the other comparative methods, the traditional
as HG-DRL, while in GCN-SAC, graph attention net- non-reinforcement learning algorithms like Fixed-time and
work (GAT) is used to facilitate information interaction MaxPressure are found to have subpar performance in traffic
between adjacent nodes. signal control since they are unable to learn from the envi-
ronmental feedback, and thus cannot adopt more reasonable
traffic signal control strategies in real-time based on the
C. Evaluation Metric
overall condition of the road network. Additionally, these
1) Travel Time: It is defined as the average travel time two methods aim to enhance the efficiency of ATT at the
(ATT) of all vehicles spend between entering and leaving the expense of throughput as shown in Table III. On the other
area. This value is affected by the factors such as red/yellow hand, reinforcement learning-based methods like PressLight
traffic signals and traffic congestion. Travel time is a widely and MPLight utilize a basic DQN in their reinforcement
adopted criterion to measure the performance of traffic signal learningmodule.However,theirrewardfunctionssolelyfocus
control [40]. on pressure, which fails to account for the number of vehicles
2) Throughput: It indicates the number of vehicles that on entering lanes. This oversight results in a decrease in the
have finished their trips until the current simulation step. A performance of both average travel time and throughput.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 10
TABLE II: Performance of average travel time (in seconds) for various methods.
Methods Unidirect6×6 Bidirect6×6 Unidirect10×10 Bidirect10×10 DHangzhou DJinan
Fixed-time 210.94 210.94 345.82 345.82 718.29 814.11
MaxPressure 186.56 195.49 297.18 322.71 407.17 343.90
PressLight 365.58 256.89 313.23 349.07 421.18 354.93
MPLight 214.69 238.27 297.38 311.05 324.67 334.01
CoLight 174.73 173.88 347.87 352.75 301.75 326.75
GCN-SAC 173.37 172.31 297.75 306.16 336.15 332.36
HG-DRL 168.85 167.77 286.87 285.85 295.71 278.22
TABLE III: Performance of throughput for various methods.
Methods Unidirect6×6 Bidirect6×6 Unidirect10×10 Bidirect10×10 DHangzhou DJinan
Fixed-time 2190 4380 3480 6960 1989 3475
MaxPressure 2214 4408 3542 7036 2664 5613
PressLight 2295 4627 3859 7736 2802 6043
MPLight 2313 4640 3866 7736 2923 5927
CoLight 2327 4652 3865 7743 2929 6061
GCN-SAC 2324 4652 3870 7744 2915 6069
HG-DRL 2327 4652 3870 7755 2932 6149
(a) Bidirect (b) D (c) D
6×6 Hangzhou Jinan
Fig. 3: Impact of threshold ζ.
(a) Bidirect (b) D (c) D
6×6 Hangzhou Jinan
Fig. 4: Impact of hypergraph loss coefficient β.
E. Sensitive Analysis ζ is set at 0.1. If the threshold value ζ surpasses 0.1, the
filtering based on this threshold becomes more stringent,
We validate the impact of three key parameters of our
resulting in the exclusion of nodes with potential correlations
proposed HG-DRL in three datasets: Bidirect , D ,
6×6 Hangzhou
from information interaction. Consequently, it diminishes the
and D .
Jinan
performance of ATT.
1) Impact of threshold ζ: Threshold ζ serves as an im-
portantparameterindynamicallyconstructinghypergraphand 2) Impact of hypergraph loss coefficient β: As an essential
capturingcrucialneighborinformation(SeeEquation3).Fig.3 component of our proposed algorithm, the hypergraph incor-
show the impact of threshold ζ. With the initial increase in porates two types of hyperedge construction losses into the
the threshold value ζ, ATT of all vehicles in the entire road reinforcement learning loss function (see Equation 11). To
networkdecreases.Thisreductionoccursduetoareductionin investigate the impact of the hypergraph construction loss on
the number of nodes included in the hyperedges constructed theexperimentalresults,weconductedasensitivityexperiment
by the master node within the road network. For all datasets, on the hypergraph loss coefficient β in the aforementioned
the best ATT performance is observed when the threshold three datasets. The experimental results are shown in Fig. 4.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 11
(a) Bidirect (b) D (c) D
6×6 Hangzhou Jinan
Fig. 5: Impact of attention head number K.
When the β is set to 0.001, ATT reaches its optimal value REFERENCES
acrossallthreedatasets.Ontheotherhand,whenβ issetto0,
itindicatesthatthelossincurredbyhypergraphconstructionis [1] L.F.P.deOliveira,L.T.Manera,andP.D.G.D.Luz,“Development
ignored, resulting in substantial decrease in ATT performance ofasmarttrafficlightcontrolsystemwithreal-timemonitoring,”IEEE
InternetofThingsJournal,vol.8,no.5,pp.3384–3393,2021.
compared to the optimal value.
[2] O. Younis and N. Moayeri, “Employing cyber-physical systems: Dy-
3) Impact of Attention Head Number K: To evaluate the namictrafficlightcontrolatroadintersections,”IEEEInternetofThings
effectivenessofmulti-headattention,wetesteddifferentnum- Journal,vol.4,no.6,pp.2286–2296,2017.
[3] H. Wei, G. Zheng, H. Yao, and Z. Li, “IntelliLight: A reinforcement
bers of attention heads K across three datasets. Selecting an
learningapproachforintelligenttrafficlightcontrol,”inProceedingsof
appropriate K is beneficial for better control of intersection the ACM SIGKDD International Conference on Knowledge Discovery
signals. As shown in Fig. 5, in Bidirect and D , the &DataMining,2018,pp.2496—-2505.
6×6 Hangzhou
[4] Z.-G.Chen,Z.-H.Zhan,S.Kwong,andJ.Zhang,“Evolutionarycom-
ATT increases with the number of attention heads compared
putation for intelligent transportation in smart cities: A survey [review
tothecasewhenK =1.Thissuggeststhathavingmoretypes article],”IEEEComputationalIntelligenceMagazine,vol.17,no.2,pp.
of attention do not improve the decision-making performance 83–102,2022.
of model when the head number K > 1. For D , as [5] P.Arthurs,L.Gillam,P.Krause,N.Wang,K.Halder,andA.Mouzakitis,
Jinan “A taxonomy and survey of edge cloud computing for intelligent
the number of attention heads increased, the ATT gradually
transportation systems and connected vehicles,” IEEE Transactions on
decreased. However, when K > 5, the advantage of having IntelligentTransportationSystems,vol.23,no.7,pp.6206–6221,2022.
more types of attention vanished, leading to a significant [6] D.Xu,T.Li,Y.Li,X.Su,S.Tarkoma,T.Jiang,J.Crowcroft,andP.Hui,
“Edge intelligence: Empowering intelligence to the edge of network,”
increase in ATT.
ProceedingsoftheIEEE,vol.109,no.11,pp.1778–1837,2021.
[7] T.Zhang,Z.Shen,J.Jin,X.Zheng,A.Tagami,andX.Cao,“Achieving
democracy in edge intelligence: A fog-based collaborative learning
scheme,”IEEEInternetofThingsJournal,vol.8,no.4,pp.2751–2761,
2021.
VI. CONCLUSION [8] C.Wu,I.Kim,andZ.Ma,“Deepreinforcementlearningbasedtraffic
signalcontrol:Acomparativeanalysis,”inANT/EDI40,2023.
[9] T. Wang, A. Hussain, L. Zhang, and C. Zhao, “Collaborative edge
In this paper, we propose a framework that can cooperate computingforsocialinternetofvehiclestoalleviatetrafficcongestion,”
IEEETransactionsonComputationalSocialSystems,vol.9,no.1,pp.
with multiple edge computing servers for realizing intelligent
184–196,2022.
traffic signal control. Within this framework, we introduce
[10] H.Ge,D.Gao,L.Sun,Y.Hou,C.Yu,Y.Wang,andG.Tan,“Multi-agent
a multi-agent collaborative reinforcement learning algorithm transfer reinforcement learning with multi-view encoder for adaptive
based on MA-SAC in multi-intersection environments. In trafficsignalcontrol,”IEEETransactionsonIntelligentTransportation
Systems,vol.23,no.8,pp.12572–12587,2022.
order to promote the effective decision-making and improved
[11] F. Mao, Z. Li, Y. Lin, and L. Li, “Mastering arterial traffic signal
processing of spatio-temporal information among multiple control with multi-agent attention-based soft actor-critic model,” IEEE
agents, we incorporate hypergraph learning into the MA- Transactions on Intelligent Transportation Systems, vol. 24, no. 3, pp.
3129–3144,2023.
SAC. We design the dynamic generation of spatio-temporal
[12] T. Nishi, K. Otaki, K. Hayakawa, and T. Yoshimura, “Traffic signal
hyperedges to construct hypergraphs with enhanced modeling controlbasedonreinforcementlearningwithgraphconvolutionalneural
capabilities. We then utilize multi-head attention to update nets,” in Proceedings of the International Conference on Intelligent
TransportationSystems(ITSC),2018,pp.877–883.
intersection information, enabling dynamic spatio-temporal
[13] S. Rahmani, A. Baghbani, N. Bouguila, and Z. Patterson, “Graph
interactions between road intersections. The results obtained neuralnetworksforintelligenttransportationsystems:Asurvey,”IEEE
from extensive experiments demonstrate that our proposed Transactions on Intelligent Transportation Systems, vol. 24, no. 8, pp.
8846–8885,2023.
method outperforms state-of-the-art ones in traffic signal
[14] Y.Wang,T.Xu,X.Niu,C.Tan,E.Chen,andH.Xiong,“STMARL:A
control, achieving improvements in both travel time and
spatio-temporal multi-agent reinforcement learning approach for coop-
throughput. Our future direction is to study data cleaning and erative traffic light control,” IEEE Transactions on Mobile Computing,
integrationschemestomitigatetheimpactofmissingornoisy vol.21,no.6,pp.2228–2242,2022.
[15] A. Antelmi, G. Cordasco, M. Polato, V. Scarano, C. Spagnuolo, and
existinginthecollectedinputdata,whichaimstoenhancethe
D. Yang, “A survey on hypergraph representation learning,” ACM
robustness of our proposed method. ComputingSurveys,vol.56,no.1,2023.JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 12
[16] T. Zhang, Y. Liu, Z. Shen, X. Ma, X. Chen, X. Huang, J. Yin, and [38] P. Christodoulou, “Soft actor-critic for discrete action settings,”
J. Jin, “Learning from heterogeneity: A dynamic learning framework ArXiv, vol. abs/1910.07207, 2019. [Online]. Available: https://api.
forhypergraphs,”arXivpreprintarXiv:2307.03411,2023. semanticscholar.org/CorpusID:204734462
[17] P. Koonce, L. A. Rodegerdts, K. Lee, S. Quayle, S. Beaird, C. Braud, [39] H.Zhang,S.Feng,C.Liu,Y.Ding,Y.Zhu,Z.Zhou,W.Zhang,Y.Yu,
J. A. Bonneson, P. J. Tarnoff, and T. Urbanik, “Traffic signal timing H. Jin, and Z. Li, “CityFlow: A multi-agent reinforcement learning
manual,”inFederalHighwayAdministration,2008. environmentforlargescalecitytrafficscenario,”inProceedingsofThe
[18] P. Varaiya, The Max-Pressure Controller for Arbitrary Networks of WorldWideWebConference(WWW),2019,pp.3620—-3624.
SignalizedIntersections. Springer,2013,vol.2,pp.27–66. [40] H.Mei,X.Lei,L.Da,B.Shi,andH.Wei,“LibSignal:anopenlibrary
[19] C. Chen, H. Wei, N. Xu, G. Zheng, M. Yang, Y. Xiong, K. Xu, and fortrafficsignalcontrol,”MachineLearning,2023.
Z. Li, “Toward a thousand lights: Decentralized deep reinforcement
learningforlarge-scaletrafficsignalcontrol,”ProceedingsoftheAAAI
ConferenceonArtificialIntelligence,vol.34,pp.3414–3421,2020.
[20] F. Mao, Z. Li, and L. Li, “A comparison of deep reinforcement
learning models for isolated traffic signal control,” IEEE Intelligent
TransportationSystemsMagazine,vol.15,no.1,pp.160–180,2023.
[21] X.Wang,L.Ke,Z.Qiao,andX.Chai,“Large-scaletrafficsignalcontrol
usinganovelmultiagentreinforcementlearning,”IEEETransactionson
Cybernetics,vol.51,no.1,pp.174–187,2021.
[22] S. Rizzo, G. Vantini, and S. Chawla, “Time critic policy gradient
methodsfortrafficsignalcontrolincomplexandcongestedscenarios,”
in Proceedings of the ACM SIGKDD International Conference on
KnowledgeDiscoveryandDataMining,2019,pp.1654–1664.
[23] T.Chu,J.Wang,L.Codeca`,andZ.Li,“Multi-agentdeepreinforcement
learning for large-scale traffic signal control,” IEEE Transactions on
IntelligentTransportationSystems,vol.21,no.3,pp.1086–1095,2020.
[24] H. Wei, C. Chen, G. Zheng, K. Wu, V. Gayah, K. Xu, and Z. Li,
“PressLight:Learningmaxpressurecontroltocoordinatetrafficsignals
inarterialnetwork,”inProceedingsoftheACMSIGKDDInternational
ConferenceonKnowledgeDiscovery&DataMining,2019,pp.1290—
-1298.
[25] I.Arel,C.Liu,T.Urbanik,andA.G.Kohls,“Reinforcementlearning-
basedmulti-agentsystemfornetworktrafficsignalcontrol,”IETIntel-
ligentTransportSystems,vol.4,no.2,pp.128–135,2010.
[26] T. Nishi, K. Otaki, K. Hayakawa, and T. Yoshimura, “Traffic signal
controlbasedonreinforcementlearningwithgraphconvolutionalneural
nets,” in Proceedings of the International Conference on Intelligent
TransportationSystems(ITSC),2018,pp.877–883.
[27] M. Schlichtkrull, T. N. Kipf, P. Bloem, R. van den Berg, I. Titov,
and M. Welling, “Modeling relational data with graph convolutional
networks,” in The Semantic Web. Springer International Publishing,
2018,pp.593–607.
[28] H. Wei, N. Xu, H. Zhang, G. Zheng, X. Zang, C. Chen, W. Zhang,
Y.Zhu,K.Xu,andZ.Li,“CoLight:Learningnetwork-levelcooperation
for traffic signal control,” in Proceedings of the ACM International
Conference on Information and Knowledge Management, 2019, pp.
1913––1922.
[29] S.Zhang,Z.Ding,andS.Cui,“Introducinghypergraphsignalprocess-
ing:Theoreticalfoundationandpracticalapplications,”IEEEInternetof
ThingsJournal,vol.7,no.1,pp.639–660,2019.
[30] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu, “A
comprehensive survey on graph neural networks,” IEEE Transactions
on Neural Networks and Learning Systems, vol. 32, no. 1, pp. 4–24,
2021.
[31] Y. Gao, Y. Feng, S. Ji, and R. Ji, “HGNN+: General hypergraph
neuralnetworks,”IEEETransactionsonPatternAnalysisandMachine
Intelligence,vol.45,no.3,pp.3181–3199,2023.
[32] D. Arya and M. Worring, “Exploiting relational information in social
networksusinggeometricdeeplearningonhypergraphs,”inProceedings
oftheACMonInternationalConferenceonMultimediaRetrieval,2018,
p.117–125.
[33] H.Wu,Y.Yan,andM.K.-P.Ng,“Hypergraphcollaborativenetworkon
vertices and hyperedges,” IEEE Transactions on Pattern Analysis and
MachineIntelligence,vol.45,no.3,pp.3245–3258,2023.
[34] P. Li and O. Milenkovic, “Inhomogeneous hypergraph clustering with
applications,” in Proceedings of the Advances in Neural Information
ProcessingSystems(NIPS),vol.30,2017.
[35] J.Wang,Y.Zhang,Y.Wei,Y.Hu,X.Piao,andB.Yin,“Metropassenger
flow prediction via dynamic hypergraph convolution networks,” IEEE
TransactionsonIntelligentTransportationSystems,vol.22,no.12,pp.
7891–7903,2021.
[36] S.Zhang,Z.Ding,andS.Cui,“Introducinghypergraphsignalprocess-
ing:Theoreticalfoundationandpracticalapplications,”IEEEInternetof
ThingsJournal,vol.7,no.1,pp.639–660,2020.
[37] T.Zhang,Y.Liu,Z.Shen,R.Xu,X.Chen,X.Huang,andX.Zheng,
“Anadaptivefederatedrelevanceframeworkforspatialtemporalgraph
learning,”IEEETransactionsonArtificialIntelligence,2023.