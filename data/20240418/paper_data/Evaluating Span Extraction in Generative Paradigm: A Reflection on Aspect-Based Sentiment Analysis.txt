Evaluating Span Extraction in Generative Paradigm:
A Reflection on Aspect-Based Sentiment Analysis
SoyoungYang WonIkCho*
KAISTAI SAIT,SamsungElectronics
sy_yang@kaist.ac.kr wonik.cho@samsung.com
Abstract (A) Explicit case
Intheeraofrapidevolutionofgenerativelan-
guagemodelswithintherealmofnaturallan-
guage processing, there is an imperative call
buSt ethrvei cseta gfef nwearsa lso hNoergraitbivlee to us .
to revisit and reformulate evaluation method-
⇒ staff Service general horrible Negative
ologies, especially in the domain of aspect-
basedsentimentanalysis(ABSA).Thispaper
( , , , )
addressestheemergingchallengesintroduced (B) Implicit case
bythegenerativeparadigm,whichhasmoder-
ately blurred traditional boundaries between NULL
understanding and generation tasks. Build-
ing upon prevailing practices in the field, we itissimply aPmosaiztiivneg . Food quality
analyze the advantages and shortcomings as- ⇒ NULL Food quality amazing Positive
sociatedwiththeprevalentABSAevaluation
paradigms. Through an in-depth examina- Figure 1(: Asp, ect sentimen,t quad pr, ediction)( ASQP)
tion,supplementedbyillustrativeexamples,we examplesfromACOS(Caietal.,2021)rest16dataset.
highlight the intricacies involved in aligning Each quadruple is extracted from a given sentence in
generative outputs with other evaluative met- theorderof(aspectterma,aspectcategoryc,opinion
rics,specificallythosederivedfromothertasks, termo,sentimentpolaritys). Example(A)isanexplicit
includingquestionanswering. Whilewesteer casewherethementionsofaspectandopiniontermsare
clear of advocating for a singular and defini- describedinthegivensentence,while(B)isanimplicit
tivemetric,ourcontributionliesinpavingthe onewheretheaspecttermisnotfoundinthesentence.
pathforacomprehensiveguidelinetailoredfor
ABSAevaluationsinthisgenerativeparadigm.
Inthispositionpaper,weaimtoprovideprac- andsentimentpolarity1. Fig.1showsthetwoex-
titionerswithprofoundreflections,offeringin- amples that extract one quadruple for each input
sightsanddirectionsthatcanaidinnavigating
sentence. In example (A), the aspect and opin-
thisevolvinglandscape,ensuringevaluations
ion terms, i.e., “staff” and “horrible”, are span
thatarebothaccurateandreflectiveofgenera-
factorsdirectlyextractedfromsourcesentence(s),
tivecapabilities.
whereasaspectcategoryandsentimentpolarity,i.e.,
1 Introduction
“Servicegeneral”and“Negative”,reflecttheircor-
Extracting information from user-generated re- respondingcategoricalattributes. Fundamentally,
views is pivotal and essential in real-world appli- ABSA is rooted in comprehension; to tackle the
cations. Inresponsetothisdemand,aspect-based problemaccurately,amodelmustgraspbothcon-
sentiment analysis (ABSA), a task of extracting textandunderlyingintent. However,intheeraof
variousaspectsofsentimentinformationfromuser generative language models (GLM), researchers
reviews, has emerged and evolved with various encounteranovelrealmofchallengesinbothex-
studies(Liu,2012;Cheboluetal.,2023). Thecon- tractingandclassifyingthesefourelements.
temporaryiterationsofABSAtypicallyrefertothe Addingtothecomplexity,recentABSAmethod-
aspect sentiment quad prediction (ASQP) frame- ologies, such as ACOS dataset (Cai et al., 2021),
work(Zhangetal.,2021),encompassingfourele- haveincorporateda“NULL”annotationtoaddress
ments: aspectterm,aspectcategory,opinionterm,
1Inthispaper,ourdiscussionsoperateunderthedefault
*Correspondingauthor ASQPconfigurationthatpredictsallfourelements.
4202
rpA
71
]LC.sc[
1v93511.4042:viXrainstances where span tagging is not applicable, howshouldsuchdiverseresponsesbeevaluated?
echoing the challenges faced with unanswerable Should they be perceived and assessed under the
scenarios in question-answering (QA) tasks (Ra- same lens as the traditional extract-and-classify
jpurkaretal.,2018). Asshowninexample(B)of scenarios?
Fig.1,theaspecttermistaggedas“NULL”because Toresolvetheaforementionedcomplexities,this
thetermisnotrepresentedasanentityexplicitly, position paper discusses how diverse predictions
unlike the opinion term “amazing”. Moreover, a and ground truths are evaluated and how we can
broaderspectrumofdomainsiscoveredwiththe evaluatetheoutputsoftheGLMera. InSection2,
latestexpansionsintheMEMD-ABSAdataset(Cai wesimplysummarizethenotationandthedistinct
et al., 2023), introducing new domains of books, subtasksinherenttotheABSAtask. Notethatwe
clothing,andhotel,alongwiththeexploredareas onlydealwiththeessentialcomponentstodiscuss
oflaptopandrestaurant. Thisinclusivitypresentsa theevaluation-relatedtopicsinthecontextofthis
diverserangeoftendenciesacrossdomains,andthe positionpaper. InSection3,wesurveyhowABSA
potential aspect and opinion candidates similarly hasbeenconductedpriortothegenerativeeraand
exhibitextensivevariability. exploretheongoingtrends,particularlyemphasiz-
Despite the ongoing research in models and ing inferential attempts facilitated by pretrained
datasets to perform ABSA tasks, there has been and generative language models. Followingly, in
less discussion on the evaluation scheme of their Section 4, we take a look at conventional ABSA
outcomes. Infact,evaluatingtheoutputproduced evaluationschemes,includingexactmatchandF1
bytheABSAmodel(s),particularlyimplemented metrics,whilealsosheddinglightonprevalentsim-
usingtheextract-classify-ACOSmethodology(Cai ilaritymeasuresusedtoevaluatetermandexpres-
etal.,2021),posesintricatehurdles,primarilybe- sioncorrespondence. Lastly,inSection5,wecom-
cause it encompasses two concurrent abilities of pareevaluationschemesfromvariousperspectives
extraction and classification, each demanding si- alongwithdiverseexamplesandofferasuggestion
multaneous attention. As shown in Fig. 1, the on the future direction of ABSA evaluation. The
ABSA task involves extraction and classification primarygoalofourmanuscriptistospotlightchal-
processes,leadingtotheformationofpairs: (aspect lenges with the adoption of conventional ABSA
term,aspectcategory)and(opinionterm,sentiment evaluationintheemergentparadigmofgenerative
polarity),wheretheformerrequiresextractionand models and to further establish a guidelight for
thelatternecessitatescategorizingability. Onthe assessingthemodeloutputwithmultiplespanex-
surface, this dichotomy, pairing the aspect term tractionproblems.
withtheaspectcategoryandtheopiniontermwith
thesentimentpolarity,seemslogicallystructured. 2 Background
However,thisdivisiondoesn’tnecessarilyindicate
2.1 FourelementsofABSA
thatthedecision-makingprocessforoneattribute
iswhollyindependentoftheothersincethespans Sentimentanalysisisthestudythatanalyzesindi-
of aspects and opinions terms influence the deci- viduals’sentimentsandperceptionstowardsenti-
sionprocessofeachotherandsometimestheycan tiesandtheirattributes(Liu,2012). IntheABSA
intersect. task, the opinion term (o) and sentiment polarity
AssessingindividualinstancesinABSAisfur- (s)belongtothepriorsentiment-relatedelements,
ther complicated by the predictions of multiple while the aspect term (a) and aspect category (c)
quadruples against several ground truth quadru- gototheentity-relatedelements. Thedefinitionof
ples. Thisraisestwosalientquestions: howshould thesefourelementscanbedescribedasfollows:
eachinstancebeassessedwhenthere’snoperfect
alignment of sequences? How should one mea- • Aspect term (a) refers to a target entity or
surethesimilarityscorebetweenpredictionsand object about which an opinion is expressed,
ground truths? Furthermore, the evolution and usuallyrepresentedbyawordorphrase,but
ubiquitous adoption of generative models (Rad- it can occasionally be implicit, as shown in
fordetal.,2018;Brownetal.,2020;Raffeletal., example(B)ofFig.1.
2020)introducesanotherlayerofcomplexity. With
thesemodels,there’sagreaterpotentialfordiverse • Opinion term (o) conveys a sentiment or
answers. Thus, the pertinent question becomes: viewpoint about the aforementioned aspect.Task Output inworksbyZhangetal.(2022)andCheboluetal.
(2023).
Aspecttermextraction(ATE) a
Aspect-opinionpairextraction(AOPE) a,o
Aspect-sentimentpairextraction(ASPE) a,s 3 ABSAModelsinParadigmShift
Aspect-sentimenttripletextraction(ASTE) a,o,s
Aspect-category-sentimentdetection(ACSD) a,cs 3.1 InferenceDeFacto
Aspect-sentimentquadprediction(ASQP) a,c,o,s
Traditional inference process in ABSA artfully
combines a variety of techniques (Chebolu et al.,
Table1: TargetoutputelementsforABSAtasks. The
2023). Itblendsnamedentityrecognition(NER)-
namesofthetasksfollowZhangetal.(2022).
stylespanextraction,thelinkingofaspectandopin-
ionterms,asdepictedbythehighlightedspansin
Thisisusuallydescribedinwordsorphrases, Fig.1,andthecategoricaldecision-makingprocess
butitcanbeimplicit. on both category and sentiment, as illustrated by
thearrowsinFig.1. Also,thisprocesscaneither
• Aspectcategory(c)classifiestheaspectinto incorporatebinary/ternary(sentiment)ormultiple
aspecificclassselectedfromapredefinedcat- (category)labelsinnature. Priortotheemergence
egoryset. oflarge-scalemodels,thetasksofextractionand
predictionhavebeenprocessedindistinctlysepa-
• Sentiment polarity (s) is the sentiment the
rate stages. This bifurcation boosted methodolo-
authorhasfortheaspect,whichisusuallyre-
giesakintoNERandcategorization(Saias,2015;
vealedbytheopiniontermoanddividedinto
PhanandOgunbona,2020).
threeclasses: positive,neutral,andnegative.
TheadventandwidespreadutilizationofBERT-
style (Devlin et al., 2019) pretrained language
2.2 SubtasksofABSA
models(PLMs)foundtheirsynergisticalignment
As shown in Table 1, several inference types can with the aforementioned inferential framework.
be identified when discussing ABSA, with the Thisharmonyisexemplifiedintheextract-classify
more prominent ones being: aspect term extrac- method,elucidatedinthefoundationalACOSpa-
tion (ATE) (Hu and Liu, 2004), aspect-opinion per(Caietal.,2021). Thisapproachmergesspan-
pairextraction(AOPE)(Fanetal.,2019),aspect- taggingextractionwithsubsequentpredictionlay-
sentimentpairextraction(ASPE),aspect-sentiment ers—-allintegratedwithinasinglemodel. Across
triplet extraction (ASTE) (Peng et al., 2020), these methodologies, there’s a consistent theme:
aspect-category-sentimentdetection(ASCD),and aspectsandopinionsaresystematicallyextracted
aspect-sentiment quad prediction (ASQP). As a fromtheprovidedinput,whilecategoriesandsen-
representativedataset,SemEvaldatasets(Pontiki timentsarepredictedbasedonapredefinedsetof
etal.,2014,2015,2016)introducesawealthofre- classes.
sourcesapplicabletoATE,ASPE,andACSDtasks.
3.2 RecentAttemptswithGLM
In a recent study, the ASQP (Zhang et al., 2021)
task,whichconsidersallfourelements,hasgained Employing generative models for ABSA infer-
attention. However,becauseallfourfactorsshould encehas garneredsignificant attention, primarily
beextractedfromagivensentence(s),theremaybe drivenbytheadventoflandmarkGLMslikeGPT-
implicit cases where aspects or opinion terms do 3(Brownetal.,2020)andsequence-to-sequence
not appear explicitly in the input sentence(s). To (Seq2seq) styled language generation techniques
encompasssuchimplicitcases,datasetsthataddi- such as BART (Lewis et al., 2020) and T5 (Raf-
tionally include “NULL” spans, e.g., ACOS (Cai fel et al., 2020). Among them, T5 has gained
etal.,2021)andMEMD-ABSA(Caietal.,2023), paramount prominence. To bolster the accuracy
have been introduced. Note that datasets for the ofthesegenerativemodelsandcurbtendenciesfor
ASQPtaskcanbeutilizedinallthesubtasksmen- hallucination,researchershavebegunexperiment-
tionedearlier. Inthescopeofthispositionpaper, ingwithconstraineddecoding(DeCaoetal.,2020)
we primarily mention the essential subtasks and during the generation phase. This technique aids
benchmarksalignedwiththeASQPtask. Compre- themodelinselectingtokensdirectlyfromthein-
hensivesurveysencapsulatingabroadercollection put sentence or the category and sentiment sets.
of ABSA models and benchmarks can be found Withtheconstraineddecoding,T5-centricmethod-ologies(Zhangetal.,2021;Maoetal.,2022;Bao widelyacceptedmetricssuchasaccuracyandF1
etal.,2022;Huetal.,2022;Gouetal.,2023)reign score are employed. This decision is reasonable,
supreme in this domain. This typically involves giventhatthepoolofcandidatesfortheseattributes
feeding the model with instance-quadruple pairs isfinite. However,it’sworthnotingthatthereexists
fortrainingandtesting. Theultimateobjectiveis aninherentdisparityinthenumberofcandidates
tofine-tuneT5intoamodeladeptatdecodingthe acrosstheseattributes;whilecategoriesgenerally
appropriatesetofquadruplesderivedfromasingle offer a broader selection compared to the senti-
instance. ments,whicharetypicallycappedatthree,albeit
ThecapabilitiesofGLMshavebeenadvancing withtheaddedlayerofsubjectivity.
at a remarkable pace, and their applicability has When it comes to evaluating aspects and opin-
broadenedremarkably. Initially,GLMsfoundtheir ions,theexactmatchmetricisthego-to(Caietal.,
primarynicheininherentlygenerativetasks,such 2021; Gou et al., 2023). However, this metric is
as machine translation, story generation, or dia- notablyharshforspanoutputs,primarilyowingto
loguemanagement. However,theunveilingoflan- thedecisionschemesassociatedwithaspectsand
guagemodelingtechniquesthatenablebothcom- opinions,especiallyfromtheviewpointofmanual
prehensiveunderstandingandgenerativefaculties, dataconstruction. Theseschemesareoftencontin-
i.e.,InstructGPT(Ouyangetal.,2022),anditslate- gent on the domain of the corpus and the type of
comers, brought about a novel approach such as sentences. Complicatingmattersfurtheristhein-
in-context learning. They were also employed to trinsicchallengeofdistinguishingbetweenaspects
proceedwithcategoricaldata;thus,metricslikeac- andopinions,anditisdifficulttoestablishrulesof
curacyandF1scorebecameinstrumentalingaug- thumbfor consistentlydissecting themin certain
ingtheirefficacy. circumstances. Forinstance,ifwehavethreesen-
It is important to note that metrics for evalu- tences:
ating existing models have been performed sep-
(1a)“The dinner wasso expensive.”
arately for classification, e.g., precision, recall,
and F1 scores, and generation, e.g., BLEU (Pa- (1b)“The price was high inthedinnertime.”
pineni et al., 2002), ROUGE (Lin, 2004), and
(1c)“The dinnerprice wasquite high.”
BERTScore (Zhang et al., 2019). However, with
the advent of GLMs, decoder-based models are allthecategoriesindicatethe“Price”withoutdoubt,
actively used for classification tasks (Min et al., butdecidingtheaspectandopinionfor(1c)would
2022a,b; Yoo et al., 2022), in addition to genera- be somewhat obscure given (1a) and (1b), which
tiontaskswheredecoder-onlyorencoder-decoder mayinvokeinconsistencyintheannotation. Also,
modelshavetraditionallybeenused. InABSA,the “expensive” itself is the term that implies the in-
transitionofthebackbonemodelfromBERTtoT5 formation on pricing, which adds a challenge. If
alsoechoesthistrend. Usingdecoder-basedmodels thesekindsofdiscrepanciesandchallengesoccur
fortaskswhereencoder-basedmodelsweretradi- simultaneously in training and test sets, it would
tionally applied has shifted the paradigm to per- resultinaninadvertentdisadvantageofpotentially
formingclassificationandextractionfromthegen- appropriate predictions if the exact match is the
erated outputs. This tends to blur the boundaries onlymetricutilized.
betweenconventionalevaluationschemes. There- Forthoseseekingamorelenientevaluationmet-
fore,itisnecessarytodiscusshowtheevaluation ricforaspectsandopinions,partialmatch(Kuetal.,
methodshouldbereflectedconcerningthechange 2008;Lietal.,2022)schemessuchasword-level
inthemodelparadigm. F1scorecanbeanattractivealternative. Specify-
ingthescoreintowordortokenlevelcanprovide
4 EvaluationSchemes a more delicate assessment than the exact match,
whichdemandsperfection. Itallocatesscoreseven
4.1 ABSAEvaluationSchemes
when there’s a slight variance in expression, ac-
As with the development of ABSA inference ap- commodatingthoseinstancesthattheexactmatch
proaches, the evaluation landscape of ABSA has metric would deem incorrect. On the other hand,
alsobeenrichwithdistinctmetricstailoredtothe giventhatthecorrectanswercanbeextractedindi-
specificcomponentsoftheanalysis. Forthecate- verseforms,e.g.,whethertheGTscontainadverbs
goricalattributes,namelycategoryandsentiment, ornot,wecanrefertothedatasetconstructionandevaluationmethodologyofmachinereadingcom- sustiltstowardsadoptingavarietyphrase-levelse-
prehension (MRC) tasks. In the case of SQUAD manticsimilaritymetricsthatcanbeappliedtoas-
2.0(Rajpurkaretal.,2018)andKLUE-MRC(Park pectandopinion. Here,thepartialmatchschemes
etal.,2021),theMRCtaskisperformedtofindthe discussedabovecanbeagainconsideredasafron-
domainofaquestioninagivencontext,andseveral trunner. Its strength lies in calculating precision
candidatesarepreparedaccordingtotheinclusion andrecallbasedontheoverallsimilarityofexpres-
ofarticlessuchas‘the’,andthemodelprediction sion, which can compensate for the harshness of
isconsideredsuccessfuliftheoutputgeneratedby the exact match, and sometimes cover the cases
themodelexistsinthecandidates. InABSAtask,it whenthereisnooverlapbutthemeaningisshared.
canbeanotheralternativetoconsidertheadditional
5 Discussion
GTcandidatesforaspectandopinionterms.
OnecrucialpartofABSAinferenceisthatitca-
5.1 ComparisonofEvaluationSchemes
pacitatesmultiplequadruplepredictionsandmul-
Considering all evaluation schemes that apply to
tiple ground truth answers (GTs) for a single in-
currentABSAliterature,wecancomeupwithfour
stance. Presently,precisionandrecallaremainly
followingmaintopicsofdiscussion.
investigatedintheevaluation;thatis,theevaluation
processincorporatescountingeffectivepredictions 5.1.1 UsingExactMatchvs. PartialMatch
andallGTsthatarecorrectlypredicted. However,
Transitioningintoagenerativeparadigmintroduces
theevaluationdoesn’tnecessarilyfactorinscenar-
challengesinensuringthatgeneratedtermsalign
ioswherethepredictionsdonotnecessarilyexact
preciselywiththeintendedGTspans. Whilestrate-
match with GT but are informative enough to be
gies like constrained decoding can help an accu-
assessedasaneffectiveprediction. Insuchcircum-
rateexactmatch,itnecessitatesareflectiononthe
stances, both the exact match and partial metrics
choiceofevaluationmetrics: shouldoneadhereto
canimposearatherrigorousevaluationcriterion.
thestrictexactmatchcriterionorexploremorele-
nientalternativeslikeword-levelF1scoreorother
4.2 StudiesonNLGEvaluation
similarity measures? For instance, in (1c), given
With the ascendancy of generative models as the
that the answer is “dinner price”, though exact
standard for various downstream tasks, the shift
matchmaximizestheutilityofpreciseprediction
towardsincorporatingnaturallanguagegeneration
ofspanextraction,devaluatingpredictionssuchas
(NLG) evaluation schemes in lieu of traditional
“dinner” or “price” without consideration on the
methodologiesisbothpalpableandpragmatic. A
approximation of semantics might be harsh con-
substantial segment gravitates towards similarity
cerningthepotentialutilityofthemodel.
metrics (Sai et al., 2022). However, while there
Additionally,asubtledifferenceexistsbetween
exists a plethora of sentence-level metrics, such
various partial match metrics, which have pros
asBLEU(Papinenietal.,2002)orROUGE(Lin,
and cons depending on domain, sentence/answer
2004),thesedon’tseamlesslyalignwiththetaskat
type,anddissectingschemes,e.g.,whethertoadopt
hand,sinceneitherthepredictionsnortheGTsare
whitespace,morphologicaldecomposition,orother
notnecessarilysentence-levelexpressions. Particu-
tokenizationmethodologies. Also,itisimportant
larlyatthelevelofentityorphrase,theword-level
whethertotakeintoaccounttheorderofwordsin
F1 score stands out in the representative area of
evaluationornot,whichmayleadtothesuperior-
question answering (Rajpurkar et al., 2016), fur-
ity of metrics such as longest common substring
nishingbothprecisionandrecallmetricsforgener-
(LCS)(Lietal.,2022).
atedoutputs.
AnotheravenueworthexploringisPLM-based 5.1.2 Totalvs. Element-WiseEvaluation
approaches, such as BERTScore (Zhang et al., When assessing quadruple predictions with GTs,
2019). However, a caveat accompanies this strat- the word-level F1 score doesn’t account for the
egy: it’s profoundly sensitive to domain-specific variances across individual elements. Given the
influences, which might skew evaluations based distinctobjectivesandevaluativenaturesofdiffer-
onthedomain’sinherentcharacteristics,thatmay ent attributes, the element-wise evaluation might
havediscrepancywiththepropertyofthepretraing offeramorecomprehensiveassessmentofmodel
corpus. performancethanthetotalone. Thisapproachen-
Concerningtheabovedeliberations,theconsen- sures that each attribute’s unique characteristicsExactmatch Partialmatch x is an input sentence, g is a GT quadruple of x,
Total s∈{0,1} s∈[0,1] andp 1 andp 2 arethepredictionsofamodel. Note
thatp andp haveslightlydifferentoandamen-
Element s={s }Ne s={s }Ne 1 2
i i=1 i i=1 tionscomparedtog,respectively.
-wise wheres ∈{0,1} wheres ∈[0,1]
i i
Now, letf (g,p ) be a scorefunction of g and
n i
Table2: Scoreformulationforfourevaluationschemes. p i that corresponds to four cases of Table 2. The
sisthescore,N isthenumberofelementstobecon- scoring metric is accuracy here. Also, as shown
e
sidered,whereN e is4forASQPtaskthat{1,2,3,4} inTable2,thetotalscoresarescalar-valued,while
correspondswith(a,c,o,s).
theelement-wisescorescanberepresentedasse-
quencesoflength4inthiscasestudy.
Fortotalandexactmatchcase(functionf ),the
andchallengesaretakenintoconsiderationduring 1
scoreofp andp arebothzero,i.e.,f (g,p ) = 0,
theevaluation. Forinstance,inthesamegenerative 1 2 1 i
because the aspect and opinion terms are not ex-
paradigm, evaluation on category and sentiment
actlythesamewiththeGT(g). Fortotalandpar-
should better be an exact match considering that
tial match case (function f ), the score of p and
thepredefinedsetofcandidatesisprovided,while 2 1
p are both 5/6, i.e., f (g,p ) = 0.83; note that
apartialanswershouldbetoleratedforaspectand 2 2 i
for partial match scores, we count the common
opinion terms given that the set of candidate se-
(whitespace-split)wordsbetweentheGTandpre-
quencesvariesfrominputsentences.
diction. While the total-exact match score con-
Insum,thequadruple-levelassessmentcanshed
lightonthetotalperformanceofthemodel,given centratesonthewronglypredictedspan,thetotal-
partialmatchscoreshowstheoverallaccuracyof
thatthescoreisaddedonlyifthewholeinference
thegeneratedprediction.
iscorrectforallelements. However,itisquestion-
ablethataspect/categoryandopinion/sentimentare On the other hand, the element-wise scores in
evaluatedwiththesamecriteriajustbecausethey this ASQP case can be represented as a quadru-
areyieldedasanoutputofagenerativemodel. ple following the same order of (a, c, o, s). The
element-wise exact match case (function f ) of
3
5.1.3 NLGMetrics p is (1.,1.,0.,1.) and that of p is (0.,1.,1.,1.),
1 2
Concerning previous claims on the advantage of highlightingtheelementwherethemodelwrongly
partialmetrics,employingNLGevaluationmetrics generated. However, these scores also reveal the
forspanevaluationappearslogical. However,delv- harshnessasametricoftheexactmatch. Lastly,the
ing deeper into them reveals inherent limitations. element-wisepartialmatchcase(functionf )ofp
4 1
MetricssuchasBLEU,ROUGE,andBERTScore is (1.,1.,0.5,1.) and that of p is (0.5,1.,1.,1.),
2
arepredominantlydesignedtoevaluatesentences showing the potential of predictions that would
ratherthanisolatedphrases. Thiswouldbeause- have been underestimated concerning other met-
ful metric for a special case if GT spans a whole rics.
sentenceasanaspectoropinionterm. Toaddcomplexitytotheutilityofpartialmatch-
ingmetrics,theopiniontermswithnegatingexpres-
5.1.4 CaseStudy
sions(e.g.,“no”,“not”,“less”)canbeconsidered
Tocomparetheevaluationmetricswithadetailed as a challenging real-world example not handled
example, wesampleadatainstancefromACOS- inthiscasestudy. Imaginethatagenerativemodel
laptop16dataset. Assumethatwehaveagenerative (probablywithoutconstraineddecoding)generates
model,e.g.,T5,andthemodelreturnstwoquadru- anotherprediction:
plesforasingleinputsentence. Theinput,GT,and
p =(key,Keyboardusability,notstiff,Neutral)
generatedquadruplescanbedescribedasfollows, 3
wheretheextractedquadruplesfollowtheorderof by inserting “not” in the opinion term. In this
(a,c,o,s). case,thescoreofelement-wisepartialmatch(f )is
4
(1.,1.,0.5,0.). However,onemayfinditquestion-
x=“key pressesaretoo stiff topress.”
ablethattheopinionscoreofp ,namelyf (g,p ) ,
3 4 3 3
g =(key,Keyboardusability,stiff,Negative)
isthesameasthatofp ,namelyf (g,p ) ,which
1 4 1 3
p =(key,Keyboardusability,toostiff,Negative)
1 displaysthe opiniontermsemanticallysimilar to
p =(keypresses,Keyboardusability,stiff,Nega- the GT. In this case, NLG metrics that consider
2
tive) semanticsimilaritywouldbeanauxiliarymeasurethatcanpenalizeandfilteroutthepredictionsthat Exact quadruple match should accommodate
provide contrary meanings and distort the evalu- partial match metrics in assessing prediction-
ation. Simply in this example where the mean- GT pairs. Evaluating entire quadruples collec-
ingoftheopiniontermofp significantlycontra- tively might obscure the nuances and variations
3
dictsthatofGT,anNLGmetriccanassign0,i.e., that exist between individual predictions or GTs.
f (g,p ) = (1.,1.,0.,0.), for the sake of reason- Precision and recall, in this context, should be
4 3
ablescoreassignment. viewedthroughthelensoftheprediction-GTsimi-
laritywithinindividualquadruplepairsratherthan
5.2 FutureSuggestionforGenerative searchingfortheexistenceofexactlythesameout-
Paradigm put. Specifically,wecanassumeanadjustedscor-
ingschemebasedonaholisticcomparisonofentire
Alongwiththefourperspectivesdiscussedabove, predictionswiththeircorrespondingGTsandvice
weprovideourviewpointsoneachtopic. versa. Forinstance,ifthreepredictionscorrespond
closelytojustoneoutoftwoGTquadruples,scores
Partial match metrics should be supportively pertaining to the three prediction-GT pairs could
used. Theexactmatchmetric,whilefittinginpre- beconsolidated. Simultaneously,thereshouldbe
generativeparadigmswherespantaggingandcate- a deduction in the aggregate score to account for
gorizationwereconsideredsubsequentprocesses, theoverlookedgoldquadruple. Asanexample,we
mightnotbethesolereliableyardstickinagener- canthinkofthefollowingconceptofasystem:
ativesetting. Introducingmetricslikeword-level
Let P = {p ,p ,p ,p } be a set of predictions
1 2 3 4
F1, LCS (Li et al., 2022), or edit distance could
for a single instance whose ground truth is G =
serveasindicatorsofthemodel’spartialsuccess,
{g ,g ,g }. In de facto exact match-based eval-
1 2 3
temperingthestrictnatureoftheexactmatch. Ide-
uation, precision and recall would be calculated
ally,acombinationofthesemetricswouldprovide
concerning if p ∈ G for all i and if g ∈ P for
i j
amoreroundedperspective,showcasingboththe
allj. However,assumingthat{p ,p }wereexact
1 2
precisionandpotentialofpredictions. Wecanalso
matchorcloseguesstog (intermsofasimilarity
1
applythisideatotheelement-wiseevaluationthat
metric),{p ,p }tog ,andnoneofthemwererel-
3 4 2
istobediscussedfollowingly.
evanttog ,asfollowingquadruples,whichfollow
3
theorderof(a,c,o,s):
Quadruple-levelaggregationcanbecomprehen-
p =(dinner,Price,soexpensive,Negative)
sive,butelement-wiseevaluationcanhighlight 1
thecharacteristicsofeachelement. Recogniz- p =(dinnerprice,Price,sohigh,Negative)
2
ingthedistinctnaturesofeachattributeisessential p =(beverage,Foodquality,toocold,Negative)
3
in evaluations. Especially the contrasts between
p =(beverage,Drink,cold,Positive)
4
categoricalandspan-basedinferencesdemandac-
g =(dinner,Price,soexpensive,Negative)
knowledgment. Even if the generative paradigm 1
renders categorical outputs as textual representa- g 2 =(beverage,Drink,toocold,Negative)
tionsratherthanlogits,theirevaluationwouldbe g =(lambsteak,Foodquality,awesome,Positive)
3
moresuitedtoacategoricalframework. Onepoten-
setasidefromtheharshexactmatchmetricwhich
tialapproachmightinvolveseparatelyevaluating
may give the precision of 0.25 and the recall of
the categorical attributes, i.e., category and sen-
0.33,wecanthinkofweightaveragingallrelevant
timent, and the span-based ones, i.e., aspect and
similarity scores regarding (p ,g ),(p ,g ) and
1 1 2 1
opinion. However, this does not basically touch
(p ,g ),(p ,g ) as a correspondence to {g ,g }
3 2 4 2 1 2
theinherentvariancesinthechallengesassociated
andpenalizethewholescorefornotevengetting
witheachelement. Typically, attributeslikecate-
close to g . Note that this concept is just a rec-
3
gory and aspect present formidable hurdles in an
ommendation; though it does not strictly follow
accurateretrieval. Thiscallsfordifferentapplica-
theconventionalexactmatchscheme,itaccommo-
tionsofsimilaritymeasurestoeachelement: e.g.,
datespartialexactmatchmetricsandalsoallows
exactmatchforcategory/sentimentandword-level
anelement-wiseanalysis.
F1 for aspect/opinion. This can be considered a
recommendablecombinationofvariousexactand Using NLG metrics might be necessary, but
partialmetrics. needstobeconsiderate. CurrentABSAevalua-tionspredominantlysteerclearofNLGmetricstai- stances with implicit terms. Such cases, rich in
loredforsentence-levelsimilarities,suchasBLEU, theirinherentcomplexities,areearmarkedforfu-
ROUGE,orBERTScore. GiventhatmostGTsand tureexplorationandanalysis.
predictions exist at the word or phrase level, the Additionally,it’sworthnotingthatourintention
fit might seem misaligned. However, as we dis- here isn’t to prescribe a definitive metric. Rather
cussedinSection5.1.4,therearescenarioswhere than pinpointing an optimal direction for a spe-
these metrics can be relevant, considering span cificobjective,ourendeavorhasbeentoshedlight
extraction’salignmentwithextractivesummariza- on the advantages and disadvantages of various
tion. Similarly,iftheGTforanopinionis“quite methodologies. Our aim remains to offer a bal-
small”andthepredictionis“notbigenough”,the ancedperspective,equippingpractitionerswithin-
degree of correctness becomes debatable. If the sightsthatcanguidetheirevaluativeprocesses.
span extraction or constrained decoding mecha-
nismsareemployed,suchdiscrepanciesmightbe
References
lessprobabletoarise,butintheirabsence,should
thisvariancediminish? Additionally,thesemetrics XiaoyiBao,WangZhongqing,XiaotongJiang,Rong
couldofferinsightsintotheimplicationsofminor Xiao, and Shoushan Li. 2022. Aspect-based senti-
mentanalysiswithopiniontreegeneration. InPro-
worddeviationsinincorrectpredictions. Without
ceedingsoftheThirty-FirstInternationalJointCon-
adoubt,thesemetricsrequireadeepconsultation
ference on Artificial Intelligence, IJCAI-22, pages
thatdependsonmodeltypesandelementproper- 4044–4050.InternationalJointConferencesonArti-
ties. ficialIntelligenceOrganization. MainTrack.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
6 Conclusion
Subbiah,JaredDKaplan,PrafullaDhariwal,Arvind
Neelakantan,PranavShyam,GirishSastry,Amanda
Inthispaper,wedelveddeepintothecomplexities
Askell,etal.2020. Languagemodelsarefew-shot
ofaspect-basedsentimentanalysis(ABSA)andits learners. Advancesinneuralinformationprocessing
evaluativemechanisms,especiallyintheevolving systems,33:1877–1901.
landscape of generative models. Drawing from
Hongjie Cai, Nan Song, Zengzhi Wang, Qiming Xie,
existing literature, we explored the intricacies of QiankunZhao,KeLi,SiweiWu,ShijieLiu,Jianfei
ABSAinferencemethodologiesandexistingevalu- Yu,andRuiXia.2023. Memd-absa:Amulti-element
multi-domaindatasetforaspect-basedsentimentanal-
ationschemes,highlightingtheirstrengthsandlim-
ysis. arXivpreprintarXiv:2306.16956.
itations. Throughourdiscussion,weunderscored
theinherentchallengesofaligninggenerativeout- Hongjie Cai, Rui Xia, and Jianfei Yu. 2021. Aspect-
putswithstringentevaluativemetrics,emphasizing category-opinion-sentiment quadruple extraction
withimplicitaspectsandopinions. InProceedings
theneedforamoredelicateapproachthatfactorsin
of the 59th Annual Meeting of the Association for
thegenerativeparadigm’suniqueattributes. While
ComputationalLinguisticsandthe11thInternational
we don’t prescribe a singular metric, our explo- JointConferenceonNaturalLanguageProcessing
rationoffersinsightsintothebenefitsandpotential (Volume 1: Long Papers), pages 340–350, Online.
AssociationforComputationalLinguistics.
pitfallsofvariousmethodologies. Ultimately,our
paperaimstoserveasacompass,offeringguiding Siva Uday Sampreeth Chebolu, Franck Dernoncourt,
directionsforpractitionersnavigatingtheintricate Nedim Lipka, and Thamar Solorio. 2023. Survey
ofaspect-basedsentimentanalysisdatasets. In2nd
terrainsofABSAinferenceswithinthegenerative
ConferenceoftheAsia-PacificChapteroftheAsso-
paradigm.
ciationforComputationalLinguisticsandthe12th
InternationalJointConferenceonNaturalLanguage
Limitation Processing.
Our focus in this discussion has been predomi- NicolaDeCao,GautierIzacard,SebastianRiedel,and
FabioPetroni.2020. Autoregressiveentityretrieval.
nantly on refining the metrics for ACOS predic-
InInternationalConferenceonLearningRepresenta-
tions,particularlyconsideringtheinclusionofthe
tions.
NULL entity as proposed in the original paper.
However, it’s essential to acknowledge the limi- Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. BERT: Pre-training of
tations of our approach. In this discourse, we’ve
deepbidirectionaltransformersforlanguageunder-
exclusively explored cases pertaining to explicit
standing. InProceedingsofthe2019Conferenceof
aspects and opinions, deliberately sidelining in- theNorthAmericanChapteroftheAssociationforComputationalLinguistics: HumanLanguageTech- tionBranchesOut,pages74–81,Barcelona,Spain.
nologies,Volume1(LongandShortPapers),pages AssociationforComputationalLinguistics.
4171–4186,Minneapolis,Minnesota.Associationfor
ComputationalLinguistics. BingLiu.2012. Sentimentanalysisandopinionmining.
Synthesislecturesonhumanlanguagetechnologies.
ZhifangFan,ZhenWu,Xin-YuDai,ShujianHuang,and 5vol.
Jiajun Chen. 2019. Target-oriented opinion words
extractionwithtarget-fusedneuralsequencelabeling. YueMao,YiShen,JingchaoYang,XiaoyingZhu,and
InProceedingsofthe2019ConferenceoftheNorth LongjunCai.2022. Seq2Path: Generatingsentiment
AmericanChapteroftheAssociationforComputa- tuples as paths of a tree. In Findings of the Asso-
tionalLinguistics: HumanLanguageTechnologies, ciation for Computational Linguistics: ACL 2022,
Volume1(LongandShortPapers),pages2509–2518, pages2215–2225,Dublin,Ireland.Associationfor
Minneapolis,Minnesota.AssociationforComputa- ComputationalLinguistics.
tionalLinguistics.
Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and
ZhibinGou,QingyanGuo,andYujiuYang.2023. MvP: LukeZettlemoyer.2022a. Noisychannellanguage
Multi-viewpromptingimprovesaspectsentimenttu- modelpromptingforfew-shottextclassification. In
ple prediction. In Proceedings of the 61st Annual Proceedings of the60th Annual Meeting of the As-
Meeting of the Association for Computational Lin- sociationforComputationalLinguistics(Volume1:
guistics(Volume1: LongPapers),pages4380–4397, LongPapers),pages5316–5330,Dublin,Ireland.As-
Toronto,Canada.AssociationforComputationalLin- sociationforComputationalLinguistics.
guistics.
SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,
Mengting Hu, Yike Wu, Hang Gao, Yinhao Bai, and MikeLewis,HannanehHajishirzi,andLukeZettle-
Shiwan Zhao. 2022. Improving aspect sentiment moyer.2022b. Rethinkingtheroleofdemonstrations:
quad prediction via template-order data augmenta- Whatmakesin-contextlearningwork? InProceed-
tion. InProceedingsofthe2022ConferenceonEm- ingsofthe2022ConferenceonEmpiricalMethodsin
pirical Methods in Natural Language Processing, NaturalLanguageProcessing,pages11048–11064,
pages7889–7900,AbuDhabi,UnitedArabEmirates. AbuDhabi,UnitedArabEmirates.Associationfor
AssociationforComputationalLinguistics. ComputationalLinguistics.
MinqingHuandBingLiu.2004. Miningandsumma- LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
rizingcustomerreviews. InProceedingsofthetenth CarrollWainwright,PamelaMishkin,ChongZhang,
ACMSIGKDDinternationalconferenceonKnowl- SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
edgediscoveryanddatamining,pages168–177. 2022. Training languagemodelsto followinstruc-
tions with human feedback. Advances in Neural
Lun-WeiKu,Yu-TingLiang,andHsin-HsiChen.2008. InformationProcessingSystems,35:27730–27744.
Questionanalysisandanswerpassageretrievalfor
opinionquestionansweringsystems. InInternational KishorePapineni,SalimRoukos,ToddWard,andWei-
JournalofComputationalLinguistics&ChineseLan- JingZhu.2002. Bleu: amethodforautomaticevalu-
guageProcessing,Volume13,Number3,September ationofmachinetranslation. InProceedingsofthe
2008: Special Issue on Selected Papers from RO- 40thAnnualMeetingoftheAssociationforCompu-
CLINGXIX,pages307–326. tational Linguistics, pages 311–318, Philadelphia,
Pennsylvania,USA.AssociationforComputational
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Linguistics.
Ghazvininejad,AbdelrahmanMohamed,OmerLevy,
Veselin Stoyanov, and Luke Zettlemoyer. 2020. SungjoonPark,JihyungMoon,SungdongKim,WonIk
BART:Denoisingsequence-to-sequencepre-training Cho,JiYoonHan,JangwonPark,ChisungSong,Jun-
fornaturallanguagegeneration,translation,andcom- seongKim,YoungsookSong,TaehwanOh,Joohong
prehension. InProceedingsofthe58thAnnualMeet- Lee,JuhyunOh,SungwonLyu,YounghoonJeong,
ingoftheAssociationforComputationalLinguistics, InkwonLee,SangwooSeo,DongjunLee,Hyunwoo
pages7871–7880,Online.AssociationforComputa- Kim, Myeonghwa Lee, Seongbo Jang, Seungwon
tionalLinguistics. Do,SunkyoungKim,KyungtaeLim,JongwonLee,
Kyumin Park, Jamin Shin, Seonghyun Kim, Lucy
HaonanLi,MartinTomko,MariaVasardani,andTim- Park,AliceOh,Jung-WooHa,andKyunghyunCho.
othy Baldwin. 2022. MultiSpanQA: A dataset for 2021. KLUE:Koreanlanguageunderstandingevalu-
multi-span question answering. In Proceedings of ation. InThirty-fifthConferenceonNeuralInforma-
the2022ConferenceoftheNorthAmericanChap- tionProcessingSystemsDatasetsandBenchmarks
teroftheAssociationforComputationalLinguistics: Track(Round2).
HumanLanguageTechnologies,pages1250–1260,
Seattle,UnitedStates.AssociationforComputational HaiyunPeng,LuXu,LidongBing,FeiHuang,WeiLu,
Linguistics. andLuoSi.2020. Knowingwhat,howandwhy: A
near complete solution for aspect-based sentiment
Chin-Yew Lin. 2004. ROUGE: A package for auto- analysis. InProceedingsoftheAAAIconferenceon
maticevaluationofsummaries. InTextSummariza- artificialintelligence,volume34,pages8600–8607.MinhHieuPhanandPhilipO.Ogunbona.2020. Mod- José Saias. 2015. Sentiue: Target and aspect based
elling context and syntactical features for aspect- sentimentanalysisinSemEval-2015task12. InPro-
basedsentimentanalysis. InProceedingsofthe58th ceedings of the 9th International Workshop on Se-
AnnualMeetingoftheAssociationforComputational manticEvaluation(SemEval2015),pages767–771,
Linguistics,pages3211–3220,Online.Association Denver, Colorado. Association for Computational
forComputationalLinguistics. Linguistics.
Maria Pontiki, Dimitris Galanis, Haris Papageorgiou, KangMinYoo,JunyeobKim,HyuhngJoonKim,Hyun-
IonAndroutsopoulos, SureshManandhar, Moham- sooCho,HwiyeolJo,Sang-WooLee,Sang-gooLee,
mad AL-Smadi, Mahmoud Al-Ayyoub, Yanyan andTaeukKim.2022. Ground-truthlabelsmatter: A
Zhao, Bing Qin, Orphée De Clercq, Véronique deeperlookintoinput-labeldemonstrations. InPro-
Hoste, Marianna Apidianaki, Xavier Tannier, Na- ceedingsofthe2022ConferenceonEmpiricalMeth-
taliaLoukachevitch,EvgeniyKotelnikov,NuriaBel, ods in Natural Language Processing, pages 2422–
Salud María Jiménez-Zafra, and Güls¸en Eryig˘it. 2437,AbuDhabi,UnitedArabEmirates.Association
2016. SemEval-2016task5: Aspectbasedsentiment forComputationalLinguistics.
analysis. In Proceedings of the 10th International
WorkshoponSemanticEvaluation(SemEval-2016), TianyiZhang,VarshaKishore,FelixWu,KilianQWein-
pages19–30,SanDiego,California.Associationfor berger,andYoavArtzi.2019. Bertscore: Evaluating
ComputationalLinguistics. text generation with bert. In International Confer-
enceonLearningRepresentations.
Maria Pontiki, Dimitris Galanis, Haris Papageorgiou,
SureshManandhar,andIonAndroutsopoulos.2015. Wenxuan Zhang, Yang Deng, Xin Li, Yifei Yuan, Li-
SemEval-2015task12: Aspectbasedsentimentanal- dongBing,andWaiLam.2021. Aspectsentiment
ysis. InProceedingsofthe9thInternationalWork- quad prediction as paraphrase generation. In Pro-
shoponSemanticEvaluation(SemEval2015),pages ceedingsofthe2021ConferenceonEmpiricalMeth-
486–495,Denver,Colorado.AssociationforCompu- ods in Natural Language Processing, pages 9209–
tationalLinguistics. 9219,OnlineandPuntaCana,DominicanRepublic.
AssociationforComputationalLinguistics.
MariaPontiki,DimitrisGalanis,JohnPavlopoulos,Har-
risPapageorgiou,IonAndroutsopoulos,andSuresh Wenxuan Zhang, Xin Li, Yang Deng, Lidong Bing,
Manandhar. 2014. SemEval-2014 task 4: Aspect andWaiLam.2022. Asurveyonaspect-basedsenti-
basedsentimentanalysis. InProceedingsofthe8th mentanalysis:Tasks,methods,andchallenges. IEEE
InternationalWorkshoponSemanticEvaluation(Se- TransactionsonKnowledgeandDataEngineering.
mEval2014),pages27–35,Dublin,Ireland.Associa-
tionforComputationalLinguistics.
AlecRadford,KarthikNarasimhan,TimSalimans,Ilya
Sutskever, et al. 2018. Improving language under-
standingbygenerativepre-training.
ColinRaffel,NoamShazeer,AdamRoberts,Katherine
Lee,SharanNarang,MichaelMatena,YanqiZhou,
WeiLi,andPeterJLiu.2020. Exploringthelimits
oftransferlearningwithaunifiedtext-to-texttrans-
former. TheJournalofMachineLearningResearch,
21(1):5485–5551.
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
Know what you don’t know: Unanswerable ques-
tionsforSQuAD. InProceedingsofthe56thAnnual
Meeting of the Association for Computational Lin-
guistics(Volume2: ShortPapers), pages784–789,
Melbourne,Australia.AssociationforComputational
Linguistics.
PranavRajpurkar,JianZhang,KonstantinLopyrev,and
PercyLiang.2016. SQuAD:100,000+questionsfor
machinecomprehensionoftext. InProceedingsof
the2016ConferenceonEmpiricalMethodsinNatu-
ralLanguageProcessing,pages2383–2392,Austin,
Texas.AssociationforComputationalLinguistics.
Ananya B Sai, Akash Kumar Mohankumar, and
MiteshMKhapra.2022. Asurveyofevaluationmet-
ricsusedfornlgsystems. ACMComputingSurveys
(CSUR),55(2):1–39.