Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning
WeiDuan, JieLu, JunyuXuan
AustralianArtificialIntelligenceInstitute(AAII),UniversityofTechnology
wei.duan@student.uts.edu.au,{jie.lu,junyu.xuan}@uts.edu.au
Abstract
Group1
Cooperative Multi-Agent Reinforcement Learn-
ing (MARL) necessitates seamless collaboration
among agents, often represented by an underlying
relation graph. Existing methods for learning this
graph primarily focus on agent-pair relations, ne-
Group2 glecting higher-order relationships. While several
approaches attempt to extend cooperation mod-
elling to encompass behaviour similarities within
Figure1: Inamulti-agentenvironment,agentsmayexhibitdiverse
groups, they commonly fall short in concurrently behaviours represented by triangles and circles. Existing methods
learning the latent graph, thereby constraining the for modelling agent interactions primarily focus on agent-pair re-
information exchange among partially observed lations. Concurrently recognizing the importance of higher-order
agents.Toovercometheselimitations,wepresenta grouprelationshipsamongagentsincoordinationgraphsiscritical.
novelapproachtoinfertheGroup-AwareCoordina-
tion Graph (GACG), which is designed to capture
tasksnecessitatecomplexagentinteractionsandarenotread-
boththecooperationbetweenagentpairsbasedon
ilydecomposableintosimpler,individualtasks. Thisrealiza-
currentobservationsandgroup-leveldependencies
tionunderscorestheneedtodepictagentrelationships,often
from behaviour patterns observed across trajecto-
assumedtoinvolvelatentgraphstructuresinMARL.Asthe
ries. This graph is further used in graph convolu-
graphisnotexplicitlygiven, inferringdynamicgraphtopol-
tionforinformationexchangebetweenagentsdur-
ogyremainsasignificantandpersistentchallenge.
ingdecision-making.Tofurtherensurebehavioural
Current methods for learning the underlying graph in
consistency among agents within the same group,
MARLcanbecategorizedintothreetypes:creatingcomplete
we introduce a group distance loss, which pro-
graphsbydirectlylinkingallnodes/agents[Liuetal.,2020a;
motes group cohesion and encourages specializa-
Boehmer et al., 2020], employing attention mechanisms to
tion between groups. Our evaluations, conducted
calculate fully connected weighted graphs [Li et al., 2021;
on StarCraft II micromanagement tasks, demon-
Liu et al., 2020b], and designing drop-edge criteria to gen-
strate GACG’s superior performance. An ablation
erate sparse graphs [Yang et al., 2022; Wang et al., 2022b].
studyfurtherprovidesexperimentalevidenceofthe
However, these methods focus exclusively on agent-pair re-
effectivenessofeachcomponentofourmethod.
lations when modelling interactions. In multi-agent scenar-
ios,suchasorchestratingmulti-robotformations[Rizketal.,
1 Introduction
2019]orcontrollingagroupofalliesinstrategicmulti-agent
combats[Samvelyanetal.,2019b],relyingsolelyonpairwise
Cooperative Multi-Agent Reinforcement Learning (MARL) relations is inadequate for comprehensively understanding
requiresagentstocoordinatewitheachothertoachievecol- collaboration.Acriticalaspectoftenoverlookedistheimpor-
lectivegoals[Cuietal.,2020;Wangetal.,2022a].Toaddress tanceofhigher-orderrelationships,includinggrouprelation-
thechallengesoftheexpansiveactionspaceposedbymulti- ships/dependencies. Advancements have recently emerged
agents [Orr and Dutta, 2023], a straightforward approach is thatutilizegroupdivision,aimingtoexplorevaluefactoriza-
breaking down the global training objective into manage- tionforsub-teams[Phanetal.,2021]ortospecializethechar-
able parts for each agent. Methods like VDN [Sunehag et acterofthedifferentgroup[Iqbaletal.,2021]. Despitetheir
al., 2018], QMIX [Rashid et al., 2018] empower individual efficacy in group partitioning, these methods do not concur-
agents to select actions that maximize their own value func- rently learn the underlying graph structure. This limitation
tion, contributing to the overall reward maximization. Nev- significantly affects the efficiency of information exchange
ertheless, it is important to recognize that many real-world among partially observed agents, which is vital for precise
4202
rpA
71
]GL.sc[
1v67901.4042:viXraGraph Neural Message
Network Agent 1
Observation
Agent-pair Feature
Extractor Predictor Reshape Agent i
Agent-pair Matrix
Sample
Agent j
TD Loss
Group-aware Agent n k-length Group Agent group to edge group Coordination Graph
Obs Divider
Agent-group Matrix Group index Group Distance Loss
Past Behaviour
Figure2:Theframeworkofourmethod.GACGisdesignedtocalculatecooperationneedsbetweenagentpairsbasedoncurrentobservations
and to capture group-level dependencies from behaviour patterns observed across trajectories. All edges in the coordination graph as a
Gaussian distribution. This graph helps knowledge exchange between agents when making decisions. During agent training, the group
distancelossregularizesbehaviouramongagentswithsimilarobservationtrajectories.
coordinationandinformeddecision-making. • We introduce the group distance loss to regularize be-
In light of these limitations, this paper proposes a novel haviouramongagentswithsimilarobservationtrajecto-
approach to infer the Group-Aware Coordination Graph ries,whichenhancesgroupcohesionandfostersdistinct
(GACG). GACG is designed to calculate cooperation needs rolesbetweendifferentgroups.
betweenagentpairsbasedoncurrentobservationsandtocap-
ture group dependencies from behaviour patterns observed
2 RelatedWork
acrosstrajectories. Akeyaspectofourmethodologyisrep-
resenting all edges in the coordination graph as a Gaussian The relationships among agents can be assumed to have
distribution. Thisapproachnotonlyintegratesagent-levelin- latent graph structures [Tacchetti et al., 2019; Li et al.,
teractionsandgroup-leveldependencieswithinalatentspace 2021]. Graph Convolutional Networks (GNN) have demon-
butalsotransformsdiscreteagentconnectionsintoacontin- strated remarkable capability in modelling relational depen-
uous expression. Such a transformation is instrumental in dencies [Wu et al., 2021; Duan et al., 2022; Duan et al.,
modellingtheuncertaintyinvariousrelationshiplevels,lead- 2024a], making graphs a compelling tool for facilitating
ingtoamoreinformativeandcomprehensiverepresentation information exchange among agents [Wang et al., 2020b;
ofcooperation. Followingthisapproach, theGACGissam- Liu et al., 2020b] and serving as coordination graphs dur-
pledfromthedistributionandusedingraphconvolutionfor ing policy training [Boehmer et al., 2020; Wang et al.,
information exchange between agents through a graph neu- 2022b]. Although the current methods use different graph
ral network during decision-making. To further ensure be- structures, such as a complete graph [Jiang et al., 2020;
havioural consistency among agents within the same group, Liu et al., 2020a], weighted graph [Wang et al., 2020a] and
we introduce a group distance loss. This loss function is sparsegraph[Yangetal.,2022;Duanetal.,2024b],theypri-
designed to increase the differences in behaviour between marilyfocusonagent-pairrelationsforinferringgraphtopol-
groups while minimizing them within groups. By doing so, ogy,neglectinghigher-orderrelationshipsamongagents.
itpromotesgroupcohesionandencouragesspecializationbe- Moving beyond the individual agent level, attention to
tweengroups. groupdevelopmentbecomespivotalformaintainingdiversi-
Experimental evaluations on StarCraft micromanagement fied policies and fostering efficient collaborations. ROMA
tasksdemonstrateGACG’ssuperiorperformance. Ourabla- [Wang et al., 2020a] learns dynamic roles that depend on
tion study provides experimental evidence for the effective- the context each agent observes. VAST [Phan et al., 2021]
nessofeachcomponentofourmethod. Thecontributionsof approximates sub-group factorization for global reward to
thispaperaresummarizedasfollows: adapttodifferentsituations. REFIL[Iqbaletal., 2021]ran-
domlygroupagentsintorelatedandunrelatedgroups,allow-
• WeproposeanovelMARLapproachnamedtheGroup-
ingexplorationofspecificentities. SOG[Shaoetal., 2022]
AwareCoordinationGraph(GACG).Tothebestofour
selects conductors to construct groups temporally, featur-
knowledge, this is the first method to simultaneously
ing conductor-follower consensus with constrained commu-
calculate cooperation needs between agent pairs and
nication between followers and their respective conductors.
capturegroup-leveldependencieswithinacoordination
GoMARL [Zang et al., 2023] uses a “select-and-kick-out”
graph.
scheme to learn automatic grouping without domain knowl-
• TheedgesofGACGareexpressedasaGaussiandistri- edgeforefficientcooperation. Despitetheirefficacyingroup
bution,whichmodelstheuncertaintyinvariousrelation- partitioning during training, these methods do not concur-
ship levels, leading to a more informative and compre- rentlylearntheunderlyinggraphstructure,therebyhindering
hensiverepresentationofcooperation. thetransferofinformationwithinorbetweengroups.
. . .
. .
.
.
. .
. . .
. . .
. . .
. .
.
.
.
.
. .
.
.
.
.
. .
.
.
.
.
Mixing
Network3 Background Definition 2. (Individual and Group). Given n agents A,
we have a set of groups G = {g ,...,g },1 ≤ m ≤ n.
We focus on cooperative multi-agent tasks modelled as a 1 m
Eachgroupg containsn (1≤n ≤n)differentagentsg =
Decentralized Partially Observable Markov Decision Pro- (cid:8) ai,...,ai (cid:9)i ⊆A,wheri eg ∩gi =∅,i̸=j,∪ g =A,ai nd
cess (Dec-POMDP) [Oliehoek and Amato, 2016] consist- 1 ni i j i i
ing of a tuple ⟨A,S,{U }n ,P,{O }n ,{π }n ,R,γ⟩, i,j ∈[1,m].
i i=1 i i=1 i i=1
where A is the finite set of n agents, s ∈ S is the Given the inherent partial observability in MARL, we as-
true state of the environment. At each time step, each sumethatagentswithsimilarobservationsoverspecifictime
agent a observes the state partially by drawing observa- periods are likely to encounter similar situations, leading to
i
tion ot ∈ Oi and selects an action ut ∈ Ui according similarbehaviours. Followingthispremise,weintroducethe
i i
to its own policy π . Individual actions form a joint ac- groupdividermodelrepresentedbyf :A(cid:55)→G,whichaims
i g
tion u = (u ,...,u ), which leads to the next state s′ ac- tocapturesimilaritiesamongagentsbasedonbehaviourpat-
1 n
cording to the transition function P(s′|s,u) and a reward ternsobservedacrosstrajectories:
R(s,u) shared by all agents. This paper considers episodic
tasksyieldingepisodes(s0,{o0}n ,u0,r0,...,sT,{oT}n ) G =f g(Ot−k:t), (2)
i i=1 i i=1
of varying finite length T. Agents learn to col-
whereOt−k:tdenotestheobservationsofallagentsfromtime
lectively maximize the global return Q (s,u) =
(cid:104) to (cid:105)t t−k tot. Theparameterk providesflexibilityindetermin-
E s0:T,u0:T (cid:80)T t=0γtR(st,ut)|s0 =s,u0 =u ,whereγ ∈ ingthedurationofthetimesteps,whichallowsustochoose
[0,1)isthediscountfactor. thelengthofthetrajectory. ThereasonsforusingOt−k:t to
indicate trajectory behaviour are twofold: firstly, group de-
pendencies are often observed over a time period, as in sce-
4 Method
narioslikecoordinatingagroupofalliesinanattack,where
TheframeworkofourmethodisdepictedinFig. 2,whichis observations(suchasfacingtheenemy)andbehaviours(like
designedtocalculatecooperationneedsbetweenagentpairs attacking)tendtosimilaruntiltheobjectiveisachieved. Sec-
basedoncurrentobservationsandtocapturegroup-levelde- ondly, historical trajectory data has been shown to represent
pendenciesfrombehaviourpatternsobservedacrosstrajecto- agents’ behaviours more accurately than one-step observa-
ries.Thisgraphhelpsagentsexchangeknowledgewhenmak- tions[Pacchianoetal.,2020],makingitamorerealisticand
ingdecisions. Duringagenttraining,thegroupdistanceloss reliablesourceforourgroupdivider.
regularizesbehaviouramongagentswithsimilarobservation Oncegroupsaredetermined,wecalculatetheagent-group
trajectories, whichenhancesgroupcohesionandencourages matrixMtoindicatewhethertwoagentsbelongtothesame
specializationbetweengroups. groupattimet.Thismatrixiscrucialforunderstandinggroup
relations,whichisdefinedas:
4.1 Group-AwareCoordinationGraphInference
(cid:26)
1 ifa ,a ∈g attimet
Definition1. (Coordinationgraph(CG)).Givenacoopera- Mt = i j m (3)
ij 0 otherwise.
tivetaskwithnagents, thecoordinationgraphisdefinedas
C = {A,E}, where A = {a 1,...,a n} are agents/node and To effectively calculate cooperation needs between agent
E ={e 11,...,e nn}edges/relationsbetweenagent. |E|=n2 pairs based on current observations and capture group de-
indicatesthenumberofpossibleedges. CGcanbewrittenin pendencies from behaviour patterns observed across trajec-
anadjacentmatrixformasC. tories,wemodelalledgesasaGaussiandistribution. Specif-
ically, the mean values of this distribution indicate the im-
To effectively capture the evolving importance of interac-
portance of interactions between agent pairs, where a larger
tions between agents, our approach leverages two compo-
nents: theobservationfeatureextractorf (·)andagent-pair mean value indicates a stronger interaction. The covariance
oe
predictor f (·). These components are designed to extract matrixofthisdistributionencapsulatesthedependenciesbe-
ap
tweenedges. Thisfeaturebecomesparticularlycrucialwhen
hidden features from the current observations of all agents
attimetandtransformthemintoameaningfulstructurewe agentsarepartofthesamegroup,asitunderscoresaheight-
enedlevelofdependenceamongthem.
termtheagent-pairmatrix:
Buildingonthisidea,wefirstconverttheagent-groupma-
oˆt =f (ot), µt =f (oˆt,oˆt), (1) trix into the edge-group matrix, enabling direct incorpora-
i oe i ij ap i j
tionofgroupinformationintoedgerelationships. Thisisde-
where f oe(·) is realized as a multi-layer perceptron (MLP), scribedbythefollowingoperation:
f (·) is an attention network. The dimension of agent-pair
ap
matrix µt is n × n, and it represents the edge weights for Mˆt =vec(Mt)×vec(Mt)⊤, Σ=Mˆ, (4)
eachagentpair,indicatingtheimportanceoftheirinteraction
wheretheshapeofvec(Mt)isn2×1(thenumberofpossible
attimet.
edges)andMˆtisn2×n2. AnelementinMˆtbeing1means
In a multi-agent environment, understanding the dynam-
thatthecorrespondingedgesbelongtothesamegroup.
ics solely through pairwise relations is insufficient. To ad-
dressthis,weintroducethegroupconcept,allowingustoex- Definition 3. (Edegs in the same group). Given two edge
tracthigher-levelinformationformoreinformedcooperative e ,e ∈ E,ifa ,a ,a ,a ∈ g ,weassertthate ande
ij lk i j l k m ij lk
strategiesamongagents. Wedefineagroupas: insamegroup.Utilizing the agent-pair matrix µt and edge-group ma- Method Graphtype Edge Group
trixMˆt,theGaussiandistributionisformallyrepresentedas:
QMIX × × ×
E ∼N(µt,Mˆt), (5) DCG Complete Unweighted ×
DICG Complete Weighted ×
wheretheshapesofµtandMˆtaren2×1andn2×n2,respec-
CASEC Sparse Weighted ×
√
tively. This approach not only provides a practical tool for VAST × ×
√
capturingedgedependencieswithinthegraphbutalsomod- GACG Sparse Weighted
ellingtheuncertaintyinvariousagentrelationshiplevels. For
instance, considering two edges e ,e ∈ E, they follow the
i j Table 1: Comparison of different experiment methods in terms of
distribution (one property of multivariate Gaussian distribu- graphtype,edgerepresentation,andgrouputilization.
tion):
(cid:32) (cid:34) (cid:35)(cid:33)
Mˆt Mˆt This equation calculates the average pairwise behavioural
(e i,e j)∼N (µt i,µt j), Mˆi ti Mˆi tj . (6) distances between agents of different groups (numerator)
ji jj and within the same group (denominator). By minimizing
According to the above definitions, if e and e are in the intra-group distances, this loss function promotes uniform
i j
same group (as indicated by Mˆt = 1), they will exhibit behaviour within groups while maximizing inter-group dis-
ij
high dependence, implying a closely aligned probability of tancestoencouragediversityandspecialization.
theirsimultaneousoccurrenceorabsence. Conversely,ifthe Our algorithm is built on top of QMIX [Rashid et al.,
edgesbelongtodifferentgroups(Mˆt = 0),theirexistences 2018], integrating all individual Q values for overall reward
ij maximization. Thetraininginvolvesminimizingalossfunc-
are modelled as independent. This approach aligns with the
tion, composed of a temporal-difference (TD) loss and the
expectation that edges within the same group should exhibit
groupdistanceloss,asfollows:
strongercontextualdependencies,enhancingthemodel’sca-
pabilitytoaccuratelyrepresentandadapttocomplexinterac- L(θ)=L (θ−)+λL (θ ), (9)
TD g g
tionsamongagents.
whereθincludesallparametersinthemodel,λistheweight
ofgroupdistanceloss. TheTDlossL (θ−)isdefinedas
4.2 Group-AwareCooperativeMARL TD
UtilizingtheGaussiandistributiondefinedinEq.(5),wesam- L (θ−)=(cid:104) r+γmaxQ (cid:0) s′,µ′;θ′(cid:1) −Q (s,µ;θ−)(cid:105)2 ,
TD tot tot
pletheedgesoftheGroup-AwareCoordinationGraphateach a′
timestep, reshaping them into matrix form Ct. This sam- (10)
where θ′ denotes the parameters of a periodically updated
pledgraphstructurefacilitatesinformationexchangebetween
targetnetwork,ascommonlyemployedinDQN.
agents through a graph neural network (GNN). The GNN’s
message-passing mechanism is essential for agents to effi-
5 Experiments
cientlyshareandintegrateinformation,adaptingtheirstrate-
giestothedynamicMARLenvironment.TheGNNisdefined Inthissection,wedesignexperimentstoanswerthefollow-
asfollows: ingquestions:(1)HowwelldoesGACGperformoncomplex
(cid:16) (cid:17) cooperative multi-agent tasks compared with other state-of-
Ht =ReLU CˆtHt W , (7)
l (l−1) (l−1) the-artCG-basedmethods? (2)Isthechoiceandcalculation
methodfortheGaussiandistributionpromisingforsampling
where l is the index of GNN layers, Cˆt = D˜− 21CtD˜−1 2,
edges in CG? (3) Does the inclusion of the group loss im-
D˜ ii = (cid:80) jCt[i,j]. The initial input of the GNN, H t0, is prove GACG’s performance? (4) What is the influence of
set to the extracted observation features {oˆt,...,oˆt} from groupnumberontheGACGperformance? (5)Howdoesthe
1 n
Eq.(1). The output of GNN mt = Ht treated as exchanged selectedlengthoftrajectoryaffectthefinalresult?
i l
knowledgebetweenagents,whichisthenutilizedinthelocal TheexperimentsinthisstudyareconductedusingtheStar-
action-valuefunctiondefinedasQ (τ ,µ ,mt). Craft II benchmark [Samvelyan et al., 2019a], which offers
i i j i
Buildinguponourearlierassumptionthatagentswithsim- complexmicromanagementtaskswithvaryingmapsanddif-
ilartrajectoriesarelikelytoexhibitsimilarbehaviours,itbe- ferentnumbersofagents. Thebenchmarkincludesscenarios
comes straightforward to regularize the behavioural consis- withaminimumofeightagents,encompassingbothhomoge-
tency of agents during the policy training phase. This be- neousandheterogeneousagentsetups. Theenvironmentsare
haviourisreflectedintheoutputofπ (µ |τ )(orQ ), repre- configured with a difficulty level of 7, providing a rigorous
i i i i
senting theprobability distribution ofactions for thecurrent testing ground for evaluating the performance and general-
state. Toassessthesimilarityofbehaviouramongagents,we ization capabilities of MARL algorithms. The experiments
comparetheirpolicyoutputsandintroducethegroupdistance aresystematicallycarriedoutwith5randomseedstoensure
loss,definedas: robustness and reliability in the assessment of the proposed
(cid:16) (cid:17) methods.
1 (cid:80) 1 (cid:80) (cid:80) ∥π −π ∥
L =
(m−1)2 i̸=j |gi||gj| al∈gi ak∈gj l k 2
. 5.1 ComparedwithotherCG-basedMethods
g (cid:16) (cid:17)
1 (cid:80) 1 (cid:80) ∥π −π ∥
m i |gi|2 al,av∈gi l v 2 We compare our methods with the following baselines, and
(8) eachmethod’sgraphtype,edgerepresentation,andgrouputi-Figure3:PerformanceofGACGandbaselinesonsixmapsoftheSMAC.Thex-axisrepresentsthetimesteps(inmillions),whilethey-axis
quantifiesthetestwinrateinthegames..
lizationaresummarisedinTab.1. disparitiesbecomemoreevidentonothermaps. Forinstance,
DICG exhibits the weakest performance on the 8m vs 9m
• QMIX1[Rashidetal.,2018]iseffectivebutwithoutco-
map,strugglingtomatchtheeffectivenessofothermethods.
operationbetweenagents,alsowithoutgroupdivision.
Similarly,DCGfallsbehindonthe10m vs 11mmap,where
• DCG2[Boehmeretal.,2020]directlylinksalltheedges thecompetingapproachesoutperformit. Onthechallenging
togetanunweightedfullyconnectedgraph. Thegraph 3s5z map, CASEC shows a lower win rate, suggesting that
isusedtocalculatetheaction-pairvaluesfunction. its strategy is less suited to the intricacies of this particular
• DICG3 [Li et al., 2021] uses attention mechanisms to scenario.
calculateweightedfullyconnectedgraph. Thegraphis The limitations of comparative methods are apparent:
usedforinformationpassingbetweenagents. QMIX lacks graph structures, DCG treats all interactions
uniformly without weight considerations, DICG misses
• CASEC4 [Wang et al., 2022b] drop edges on the
group dynamics, and CASEC, despite addressing message
weightedfullyconnectedgraphusingthevariancepay-
redundancy, overlooks the importance of group-level be-
offfunction.
haviour. VAST, while exploring sub-team dynamics, does
• VAST 5[Phan et al., 2021] explores value factorization not utilize dynamic graph structures. GACG’s nuanced ap-
forsub-teamsbasedonapredeterminedgroupnumber. proach—leveraging agent pair cooperation and group-level
The sub-team values are linearly decomposed for all dependencies—affordsadeeperunderstandingofagentinter-
sub-teammembers. actions. Thegroupdistancelossembeddedintrainingsharp-
enswithin-groupbehaviourandenhancesinter-groupstrate-
Results
gicdiversity,contributingtoGACG’seffectiveness.
InFigure3,wepresentthecomprehensiveresultsofourex-
In summary, the comparative analysis validates that a so-
periments conducted across six diverse maps, highlighting
phisticated approach to graph learning, attentive to pairwise
the superior performance of our Group-Aware Coordination
andgroup-levelinformation,isinstrumentalinachievingsu-
Graph (GACG) method. GACG consistently achieves high
periorperformanceinMARL.Withitsinnovativegraphsam-
winrateswithrapidconvergenceandreliability,outperform-
plingtechniqueandtheseamlessincorporationofgroupdy-
ingcompetingmethodsincomplexmulti-agentscenarios.On
namics, the Group-Aware Coordination Graph method of-
the 8m and 1c3s5z maps, all methods demonstrate similar
fers more intelligent and adaptable cooperative learning al-
convergencepatterns. Theyreachtheirhighesttestwinrates
gorithms.
attheendof2milliontrainingsteps. However,performance
ComputationalComplexityAnalysis
1https://github.com/oxwhirl/pymarl
2https://github.com/wendelinboehmer/dcg The computational complexity of our model is primarily
3https://github.com/sisl/DICG influenced by the necessity to discern group relationships
4https://github.com/TonghanWang/CASEC-MACO-benchmark among agents. Given that interactions are represented as
5https://github.com/thomyphan/scalable-marl edges in a fully connected graph, an environment with n1kstepstime(s) 1mstepstime(h)
QMIX 20.13±3.59 6.79±0.37
DCG 33.57±4.65 11.63±0.64
CASEC 30.50±2.03 10.12±0.51
VAST 21.28±3.59 6.21±0.56
GACG 22.33±4.22 7.84±0.49
Table2:Timecomputationalconsumptiononmap10m vs 11m.
agents results in n2 pairwise edges. To capture group dy- Figure4:Experimentofchoosingdifferentedgedistributionswhen
namics,anedge-groupmatrixMˆt isconstructedtorepresent learningtheCG.
theserelationships,withdimensionsn2×n2. Consequently,
thetimecomplexityforcomputingthegroupmatrixisO(n4).
While the theoretical computational complexity for com-
puting the group matrix in our model seems high, this com-
putation is mainly attributed to the multiplication operation
Mˆt =vec(Mt)×vec(Mt)⊤inEq.(4). Importantly,thisop-
erationishighlyamenabletoparallelization,ataskatwhich
GPUsexcel,substantiallyacceleratingtheactualtrainingpro-
cess.Tab.2presentsempiricalrunningtimesforourmodelon
the10m vs 11mmap,demonstratingthatdespitethetheoret-
ically high complexity, our GACG method is competitive in
practice. Infact,therunningtimesforGACGarefasteroron
Figure5:ExperimentoftrainingGACGwith/withoutL .
parwithothergraph-basedmethods. g
5.2 Abaltionstudy
thedistributionused,treatingthelearningofthegraphasthe
DifferentEdgedistributions learning of the edge distribution is more effective than uti-
In this part, we experiment on two maps aiming to provide lizingattentionalone(withoutdistribution). However,inthe
insights into the unique aspects of the Gaussian distribution 10m vs 11m map, the use of the Bernoulli distribution per-
in GACG and its effectiveness in capturing agent-level and formsworsethanattention,indicatingthatthechoiceofdis-
group-level information for cooperative multi-agent tasks. tribution is not arbitrary. This observation underscores the
We substitute this part with other distributions. The detail importance of carefully selecting the distribution method in
settingsareshownbelow: constructingthecoordinationgraph.
• Attention (without distribution): This approach uses When compared with the setting where each edge is con-
no specific distribution for the coordination graph but sideredindependentandfollowsaGaussiandistribution,our
learns the edges directly from the agent-pair matrix, method yields better results. This finding emphasizes the
whereedgesareobtainedaset =f (oˆt,oˆt). importanceandeffectivenessofcapturinggroupdependency
ij ap i j
whenlearningtheedgedistribution. Theabilitytomodelde-
• Bernoulli: The distribution is changed to a Bernoulli
pendencies among agents at the group level contributes sig-
distribution, where the agent-pair matrix serves as the
nificantlytotheimprovedperformanceofourapproach.
probability of this distribution, expressed as P (e =
B ij
1)=f ap(oˆt i,oˆt j). EffectivenessofGroupDistanceLoss.
• Inde-Gaussian: Each edge is considered independent In this part, we test the effectiveness of group distance loss
and follows a Gaussian distribution. Each element in bytrainingtheGACGwithandwithoutL g.
the agent-pair matrix serves as mean values for corre- TheresultsareshowninFig.5,revealingseveralkeyfind-
spondingedges,formulatedase ∼N(µ ,σ2),where ings:(1)GACGtrainedwithL exhibitsafasterconvergence
ij ij g
0 ≤ σ2 ≤ 1. This setting investigates the impact of speedandachievesahigheraveragefinalperformancecom-
group-leveldependencewhendesigningthemultivariate pared to its counterpart trained without L g. This observa-
Gaussiandistribution. tionstronglysuggeststhatL geffectivelyguidesthemodelto-
wardsmoreefficientandcooperativelearning. (2)Thiscom-
• GACG(w/oL ): Thefinallossfunctioniswithoutthe
g ponent contributes to enlarging inter-group distances while
inclusion of the group distance loss L . This ensures
g concurrently decreasing intra-group distances, fostering ef-
thattheonlydifferencebetweenthecomparedmethods
fectiveagentcooperation.(3)Thisresulthighlightstheessen-
isdistribution.
tial role that group-level information plays in enhancing the
The result is shown in Fig.4. Across various maps, our overall effectiveness and cooperation capabilities of GACG,
GACG consistently outperforms other settings, confirming demonstrating the significance of considering both agent-
the efficacy of our method. In the 3s5z map, regardless of levelandgroup-leveldynamicsforoptimalperformance.Figure 6: Experiment of dividing n agents into different numbers Figure7:Experimentofvaryingobservationwindowlengths(k)on
ofgroups(m)on3s5zand8m vs 9m. Theformerhastwotypesof thegroupdividermodelf .
g
agents,whilethelatterconsistsofasingletype.
equate historical data for effective group differentiation and
NumberofGroups decision-making,resultinginalowertestwinpercentage. As
We further investigate the impact of varying the number of we increase the window length from k = 1 to k = 5, more
groups (m) on two distinct maps: 3s5z and 8m vs 9m, each informationbecomesavailableforgroupdivision,yetitdoes
featuring8agents. Theformerhastwotypesofagents,while notsurpasstheperformanceachievedwithk =10.
the latter consists of a single type. The experiment is con- Aninterestingobservationariseswhenk =20,theoverall
ductedwithmsetto{0,2,4,8}. performance decreases and approaches that of k = 1. This
When m = 0, it implies the absence of group divisions phenomenon suggests a point of diminishing returns, where
betweenagents,indicatingthatnogroup-levelinformationis additionalhistoricalinformationmaynotcontributetobetter
utilizedduringtraining(includinggraphreasoningandgroup decision-making. Thiscouldbeattributedtochallengessuch
loss calculation). Conversely, when m = 8, each agent is as overfitting or an inability to adapt quickly to new infor-
treated as an individual group. In this setting, while there mation. Therefore,selectinganoptimalobservationwindow,
are no group divisions, the presence of the group distance such as k = 10, allows agents to integrate just enough tem-
lossencourageseachagenttoexhibitdiversebehavioursand poralinformation. Thisenablesadaptationtodynamicenvi-
dissimilarity. ronments without the drawbacks associated with processing
TheresultsareillustratedinFig. 6. Optimalperformance excessiveorpotentiallynoisydata.
isobservedwhenm = 2,underscoringthebeneficialimpact
ofamoderatelevelofgroupdivisiononcooperation. Across 6 Conclusion
both maps, the introduction of group divisions (m ∈ 2,4)
In this paper, we have presented the Group-Aware Coordi-
consistentlyoutperformsscenarioswherethereareeitherno
nation Graph (GACG), a novel MARL framework that ad-
group divisions or a high number of them (m ∈ 0,8). This
dresses the limitations of existing approaches. Unlike pre-
emphasizes the crucial role of incorporating group-level in-
vious methods that handle agent-pair relations and dynamic
formation in achieving superior MARL outcomes. Notably,
group division separately, GACG seamlessly unifies the in-
in map 3s5z, where two agent types are present, the conver-
tegrationofpairwiseinteractionsandgroup-leveldependen-
gence speed of m = 8 is faster than that of m = 0. This
cies. It adeptly computes cooperation needs from one-step
acceleration is likely due to the importance of policy diver-
observationswhilecapturinggroupbehavioursacrosstrajec-
sityinamulti-agentsettingwithdistinctagenttypes,andthe
tories. Employing the graph’s structure for information ex-
groupdistancelossfacilitateseachagentinachievingdiverse
changeduring agentdecision-makingsignificantlyenhances
behaviours.
collaborative strategies. Incorporating a group distance loss
duringtrainingenhancesbehaviouralsimilaritywithingroups
LengthofTrajectoryforGroupDivision
and encourages specialization across groups. Our extensive
In this analysis, our objective is to investigate the influ-
experimentalevaluationsrevealthatourmethodconsistently
enceofvaryingobservationtrajectorylengths,parameterized
outperformscurrentleadingmethods. Anablationstudycon-
by k, on the effectiveness of the group divider model f .
g firms the efficacy of each individual component, highlight-
Weexploredifferentvaluesfork,specifically{1,5,10,20}.
ingtheimportanceofincorporatingbothpairwiseandgroup-
When k = 1, a single timestep is considered, whereas k ∈
level insights into the learning model. The outcomes of this
{5,10,20} enables the assessment of longer temporal rela-
researchemphasizetheimportanceofmulti-levelagentinfor-
tionships.
mationintegration,establishingourframeworkasasubstan-
The results are depicted in Fig. 7. Across both maps, the
tialcontributiontoadvancingMARL.
performancedataindicatesthatamoderateobservationwin-
dow length of k = 10 yields the highest test win percent-
References
age. This setting strikes a balance, providing agents with
sufficient historical data to discern meaningful patterns and [Boehmeretal.,2020] Wendelin Boehmer, Vitaly Kurin,
group relationships. Conversely, the k = 1 setting, repre- andShimonWhiteson. Deepcoordinationgraphs. InPro-
senting the shortest observation window, fails to deliver ad- ceedingsofthe37thInternationalConferenceonMachineLearning(ICML2020),VirtualEvent,volume119ofPro- [OrrandDutta,2023] James Orr and Ayan Dutta. Multi-
ceedings of Machine Learning Research, pages 980–991. agent deep reinforcement learning for multi-robot appli-
PMLR,2020. cations: Asurvey. Sensors,23(7):3625,2023.
[Cuietal.,2020] JingjingCui,YuanweiLiu,andArumugam [Pacchianoetal.,2020] Aldo Pacchiano, Jack Parker-
Nallanathan.Multi-agentreinforcementlearning-basedre- Holder, Yunhao Tang, Krzysztof Choromanski, Anna
source allocation for UAV networks. IEEE Trans. Wirel. Choromanska, and Michael Jordan. Learning to score
Commun.,19(2):729–743,2020. behaviors for guided policy optimization. In Hal Daume´
[Duanetal.,2022] Wei Duan, Junyu Xuan, Maoying Qiao, III and Aarti Singh, editors, Proceedings of the 37th
and Jie Lu. Learning from the dark: Boosting graph International Conference on Machine Learning, (ICML
convolutionalneuralnetworkswithdiversenegativesam- 2020), volume 119 of Proceedings of Machine Learning
ples. In Thirty-Sixth AAAI Conference on Artificial In- Research,pages7445–7454,13–18Jul2020.
telligence (AAAI 2022), Virtual Event, pages 6550–6558. [Phanetal.,2021] ThomyPhan,FabianRitz,LenzBelzner,
AAAIPress,2022. Philipp Altmann, Thomas Gabor, and Claudia Linnhoff-
[Duanetal.,2024a] WeiDuan,JieLu,YuGuangWang,and Popien. VAST:valuefunctionfactorizationwithvariable
Junyu Xuan. Layer-diverse negative sampling for graph agentsub-teams. InAdvancesinNeuralInformationPro-
neural networks. Transactions on Machine Learning Re- cessing Systems 34: Annual Conference on Neural Infor-
search,2024. mationProcessingSystems(NIPS2021),December6-14,
virtual,pages24018–24032,2021.
[Duanetal.,2024b] Wei Duan, Jie Lu, and Junyu
Xuan. Inferring latent temporal sparse coordination [Rashidetal.,2018] Tabish Rashid, Mikayel Samvelyan,
graph for multi-agent reinforcement learning. CoRR, Christian Schro¨der de Witt, Gregory Farquhar, Jakob N.
abs/2403.19253,2024. Foerster, and Shimon Whiteson. QMIX: monotonic
value function factorisation for deep multi-agent rein-
[Iqbaletal.,2021] Shariq Iqbal, Christian A. Schro¨der
forcement learning. In Proceedings of the 35th Inter-
de Witt, Bei Peng, Wendelin Boehmer, Shimon White-
national Conference on Machine Learning (ICML 2018),
son, and Fei Sha. Randomized entity-wise factorization
Stockholmsma¨ssan,Stockholm,Sweden,volume80,pages
formulti-agentreinforcementlearning. InProceedingsof
4292–4301,2018.
the 38th International Conference on Machine Learning
(ICML 2021), 18-24 July, Virtual Event, volume 139 of [Rizketal.,2019] Yara Rizk, Mariette Awad, and Ed-
ProceedingsofMachineLearningResearch,pages4596– ward W. Tunstel. Cooperative heterogeneous multi-robot
4606.PMLR,2021. systems: A survey. ACM Comput. Surv., 52(2):29:1–
[Jiangetal.,2020] Jiechuan Jiang, Chen Dun, Tiejun 29:31,2019.
Huang,andZongqingLu. Graphconvolutionalreinforce- [Samvelyanetal.,2019a] Mikayel Samvelyan, Tabish
mentlearning. In8thInternationalConferenceonLearn- Rashid, Christian Schro¨der de Witt, Gregory Farquhar,
ingRepresentations(ICLR2020),AddisAbaba,Ethiopia, Nantas Nardelli, Tim G. J. Rudner, Chia-Man Hung,
2020. Philip H. S. Torr, Jakob N. Foerster, and Shimon White-
[Lietal.,2021] Sheng Li, Jayesh K. Gupta, Peter Morales, son. The starcraft multi-agent challenge. In Proceedings
RossE.Allen,andMykelJ.Kochenderfer. Deepimplicit of the 18th International Conference on Autonomous
coordination graphs for multi-agent reinforcement learn- AgentsandMultiAgentSystems(AAMAS2019),Montreal,
ing. InAAMAS’21:20thInternationalConferenceonAu- QC,Canada,,pages2186–2188.InternationalFoundation
tonomousAgentsandMultiagentSystems(AAMAS2021), forAutonomousAgentsandMultiagentSystems,2019.
Virtual Event, United Kingdom, pages 764–772. ACM, [Samvelyanetal.,2019b] Mikayel Samvelyan, Tabish
2021. Rashid, Christian Schroeder de Witt, Gregory Farquhar,
[Liuetal.,2020a] Iou-Jen Liu, Raymond A Yeh, and Nantas Nardelli, Tim G. J. Rudner, Chia-Man Hung,
AlexanderGSchwing.Pic:permutationinvariantcriticfor Philiph H. S. Torr, Jakob Foerster, and Shimon White-
multi-agent deep reinforcement learning. In Proceedings son. The StarCraft Multi-Agent Challenge. CoRR,
of the 3rd Conference on Robot Learning (CoRL 2019), abs/1902.04043,2019.
Osaka,Japan,pages590–602,2020. [Shaoetal.,2022] Jianzhun Shao, Zhiqiang Lou,
[Liuetal.,2020b] Yong Liu, Weixun Wang, Yujing Hu, Hongchang Zhang, Yuhang Jiang, Shuncheng He,
Jianye Hao, Xingguo Chen, and Yang Gao. Multi-agent and Xiangyang Ji. Self-organized group for cooperative
game abstraction via graph attention neural network. In multi-agentreinforcementlearning. InNeurIPS,2022.
The Thirty-Fourth AAAI Conference on Artificial Intelli- [Sunehagetal.,2018] PeterSunehag,GuyLever,Audrunas
gence (AAAI 2020), New York, NY, USA,, pages 7211–
Gruslys, Wojciech Marian Czarnecki, Vin´ıcius Flores
7218.AAAIPress,2020.
Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Son-
[OliehoekandAmato,2016] FransA.OliehoekandChristo- nerat, Joel Z. Leibo, Karl Tuyls, and Thore Grae-
pher Amato. A Concise Introduction to Decentral- pel. Value-decompositionnetworksforcooperativemulti-
ized POMDPs. Springer Briefs in Intelligent Systems. agent learning based on team reward. In Proceedings of
Springer,2016. the17thInternationalConferenceonAutonomousAgentsandMultiAgentSystems(AAMAS2018),Stockholm,Swe-
den,pages2085–2087,2018.
[Tacchettietal.,2019] Andrea Tacchetti, H. Francis Song,
Pedro A. M. Mediano, Vin´ıcius Flores Zambaldi, Ja´nos
Krama´r,NeilC.Rabinowitz,ThoreGraepel,MatthewM.
Botvinick, and Peter W. Battaglia. Relational forward
modelsformulti-agentlearning. In7thInternationalCon-
ference on Learning Representations (ICLR 2019), New
Orleans,LA,USA,2019.
[Wangetal.,2020a] Tonghan Wang, Heng Dong, Victor R.
Lesser, and Chongjie Zhang. ROMA: multi-agent rein-
forcementlearningwithemergentroles. InProceedingsof
the 37th International Conference on Machine Learning
(ICML 2020), Virtual Event, volume 119 of Proceedings
ofMachineLearningResearch,pages9876–9886,2020.
[Wangetal.,2020b] Tonghan Wang, Jianhao Wang,
Chongyi Zheng, and Chongjie Zhang. Learning nearly
decomposable value functions via communication mini-
mization. In 8th International Conference on Learning
Representations (ICLR 2020), Addis Ababa, Ethiopia,
2020.
[Wangetal.,2022a] MinWang,LibingWu,JianxinLi,and
LiuHe. Trafficsignalcontrolwithreinforcementlearning
based on region-aware cooperative strategy. IEEE Trans.
Intell.Transp.Syst.,23(7):6774–6785,2022.
[Wangetal.,2022b] Tonghan Wang, Liang Zeng, Weijun
Dong, Qianlan Yang, Yang Yu, and Chongjie Zhang.
Context-aware sparse deep coordination graphs. In The
Tenth International Conference on Learning Representa-
tions(ICLR2022),VirtualEvent.OpenReview.net,2022.
[Wuetal.,2021] Zonghan Wu, Shirui Pan, Fengwen Chen,
GuodongLong,ChengqiZhang,andPhilipS.Yu. Acom-
prehensivesurveyongraphneuralnetworks. IEEETrans.
NeuralNetworksLearn.Syst.,32(1):4–24,2021.
[Yangetal.,2022] Qianlan Yang, Weijun Dong, Zhizhou
Ren,JianhaoWang,TonghanWang,andChongjieZhang.
Self-organized polynomial-time coordination graphs. In
International Conference on Machine Learning (ICML
2022), Baltimore, Maryland, USA, volume 162 of Pro-
ceedings of Machine Learning Research, pages 24963–
24979.PMLR,2022.
[Zangetal.,2023] Yifan Zang, Jinmin He, Kai Li, Haobo
Fu, QIANG FU, Junliang Xing, and Jian Cheng. Auto-
matic grouping for efficient cooperative multi-agent rein-
forcementlearning. InThirty-seventhConferenceonNeu-
ralInformationProcessingSystems,(NIPS2023),2023.