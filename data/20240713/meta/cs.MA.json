[
    {
        "title": "A Review of Nine Physics Engines for Reinforcement Learning Research",
        "authors": "Michael KaupCornelius WolffHyerim HwangJulius MayerElia Bruni",
        "links": "http://arxiv.org/abs/2407.08590v1",
        "entry_id": "http://arxiv.org/abs/2407.08590v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08590v1",
        "summary": "We present a review of popular simulation engines and frameworks used in\nreinforcement learning (RL) research, aiming to guide researchers in selecting\ntools for creating simulated physical environments for RL and training setups.\nIt evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,\nPyBullet, Webots, and Unity) based on their popularity, feature range, quality,\nusability, and RL capabilities. We highlight the challenges in selecting and\nutilizing physics engines for RL research, including the need for detailed\ncomparisons and an understanding of each framework's capabilities. Key findings\nindicate MuJoCo as the leading framework due to its performance and\nflexibility, despite usability challenges. Unity is noted for its ease of use\nbut lacks scalability and simulation fidelity. The study calls for further\ndevelopment to improve simulation engines' usability and performance and\nstresses the importance of transparency and reproducibility in RL research.\nThis review contributes to the RL community by offering insights into the\nselection process for simulation engines, facilitating informed\ndecision-making.",
        "updated": "2024-07-11 15:13:28 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08590v1"
    },
    {
        "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
        "authors": "Yuchen XiaJize ZhangNasser JazdiMichael Weyrich",
        "links": "http://dx.doi.org/10.51202/9783181024379",
        "entry_id": "http://arxiv.org/abs/2407.08550v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08550v1",
        "summary": "This paper introduces a novel approach to integrating large language model\n(LLM) agents into automated production systems, aimed at enhancing task\nautomation and flexibility. We organize production operations within a\nhierarchical framework based on the automation pyramid. Atomic operation\nfunctionalities are modeled as microservices, which are executed through\ninterface invocation within a dedicated digital twin system. This allows for a\nscalable and flexible foundation for orchestrating production processes. In\nthis digital twin system, low-level, hardware-specific data is semantically\nenriched and made interpretable for LLMs for production planning and control\ntasks. Large language model agents are systematically prompted to interpret\nthese production-specific data and knowledge. Upon receiving a user request or\nidentifying a triggering event, the LLM agents generate a process plan. This\nplan is then decomposed into a series of atomic operations, executed as\nmicroservices within the real-world automation system. We implement this\noverall approach on an automated modular production facility at our laboratory,\ndemonstrating how the LLMs can handle production planning and control tasks\nthrough a concrete case study. This results in an intuitive production facility\nwith higher levels of task automation and flexibility. Finally, we reveal the\nseveral limitations in realizing the full potential of the large language\nmodels in autonomous systems and point out promising benefits. Demos of this\nseries of ongoing research series can be accessed at:\nhttps://github.com/YuchenXia/GPT4IndustrialAutomation",
        "updated": "2024-07-11 14:34:43 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08550v1"
    },
    {
        "title": "United We Stand: Decentralized Multi-Agent Planning With Attrition",
        "authors": "Nhat NguyenDuong NguyenGianluca RizzoHung Nguyen",
        "links": "http://arxiv.org/abs/2407.08254v1",
        "entry_id": "http://arxiv.org/abs/2407.08254v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08254v1",
        "summary": "Decentralized planning is a key element of cooperative multi-agent systems\nfor information gathering tasks. However, despite the high frequency of agent\nfailures in realistic large deployment scenarios, current approaches perform\npoorly in the presence of failures, by not converging at all, and/or by making\nvery inefficient use of resources (e.g. energy). In this work, we propose\nAttritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and\nefficient adaptation to changes in the set of active agents. It is based on the\nuse of a global reward function for the estimation of each agent's local\ncontribution, and regret matching for coordination. We evaluate its\neffectiveness in realistic data-harvesting problems under different scenarios.\nWe show both theoretically and experimentally that A-MCTS enables efficient\nadaptation even under high failure rates. Results suggest that, in the presence\nof frequent failures, our solution improves substantially over the best\nexisting approaches in terms of global utility and scalability.",
        "updated": "2024-07-11 07:55:50 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08254v1"
    },
    {
        "title": "A Text-to-Game Engine for UGC-Based Role-Playing Games",
        "authors": "Lei ZhangXuezheng PengShuyi YangFeiyang Wang",
        "links": "http://arxiv.org/abs/2407.08195v1",
        "entry_id": "http://arxiv.org/abs/2407.08195v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08195v1",
        "summary": "The shift from professionally generated content (PGC) to user-generated\ncontent (UGC) has revolutionized various media formats, from text to video.\nWith the rapid advancements in generative AI, a similar shift is set to\ntransform the game industry, particularly in the realm of role-playing games\n(RPGs). This paper introduces a new framework for a text-to-game engine that\nutilizes foundation models to convert simple textual inputs into complex,\ninteractive RPG experiences. The engine dynamically renders the game story in a\nmulti-modal format and adjusts the game character, environment, and mechanics\nin real-time in response to player actions. Using this framework, we developed\nthe \"Zagii\" game engine, which has successfully supported hundreds of RPG games\nacross a diverse range of genres and facilitated tens of thousands of online\nuser gameplay instances. This validates the effectiveness of our frame-work.\nOur work showcases the potential for a more open and democratized gaming\nparadigm, highlighting the transformative impact of generative AI on the game\nlife cycle.",
        "updated": "2024-07-11 05:33:19 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08195v1"
    },
    {
        "title": "Hierarchical Consensus-Based Multi-Agent Reinforcement Learning for Multi-Robot Cooperation Tasks",
        "authors": "Pu FengJunkang LiangSize WangXin YuRongye ShiWenjun Wu",
        "links": "http://arxiv.org/abs/2407.08164v1",
        "entry_id": "http://arxiv.org/abs/2407.08164v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08164v1",
        "summary": "In multi-agent reinforcement learning (MARL), the Centralized Training with\nDecentralized Execution (CTDE) framework is pivotal but struggles due to a gap:\nglobal state guidance in training versus reliance on local observations in\nexecution, lacking global signals. Inspired by human societal consensus\nmechanisms, we introduce the Hierarchical Consensus-based Multi-Agent\nReinforcement Learning (HC-MARL) framework to address this limitation. HC-MARL\nemploys contrastive learning to foster a global consensus among agents,\nenabling cooperative behavior without direct communication. This approach\nenables agents to form a global consensus from local observations, using it as\nan additional piece of information to guide collaborative actions during\nexecution. To cater to the dynamic requirements of various tasks, consensus is\ndivided into multiple layers, encompassing both short-term and long-term\nconsiderations. Short-term observations prompt the creation of an immediate,\nlow-layer consensus, while long-term observations contribute to the formation\nof a strategic, high-layer consensus. This process is further refined through\nan adaptive attention mechanism that dynamically adjusts the influence of each\nconsensus layer. This mechanism optimizes the balance between immediate\nreactions and strategic planning, tailoring it to the specific demands of the\ntask at hand. Extensive experiments and real-world applications in multi-robot\nsystems showcase our framework's superior performance, marking significant\nadvancements over baselines.",
        "updated": "2024-07-11 03:55:55 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08164v1"
    }
]