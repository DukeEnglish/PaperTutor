[
    {
        "title": "How to beat a Bayesian adversary",
        "authors": "Zihan DingKexin JinJonas LatzChenguang Liu",
        "links": "http://arxiv.org/abs/2407.08678v1",
        "entry_id": "http://arxiv.org/abs/2407.08678v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08678v1",
        "summary": "Deep neural networks and other modern machine learning models are often\nsusceptible to adversarial attacks. Indeed, an adversary may often be able to\nchange a model's prediction through a small, directed perturbation of the\nmodel's input - an issue in safety-critical applications. Adversarially robust\nmachine learning is usually based on a minmax optimisation problem that\nminimises the machine learning loss under maximisation-based adversarial\nattacks.\n  In this work, we study adversaries that determine their attack using a\nBayesian statistical approach rather than maximisation. The resulting Bayesian\nadversarial robustness problem is a relaxation of the usual minmax problem. To\nsolve this problem, we propose Abram - a continuous-time particle system that\nshall approximate the gradient flow corresponding to the underlying learning\nproblem. We show that Abram approximates a McKean-Vlasov process and justify\nthe use of Abram by giving assumptions under which the McKean-Vlasov process\nfinds the minimiser of the Bayesian adversarial robustness problem. We discuss\ntwo ways to discretise Abram and show its suitability in benchmark adversarial\ndeep learning experiments.",
        "updated": "2024-07-11 17:12:42 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08678v1"
    },
    {
        "title": "Estimation of spatio-temporal extremes via generative neural networks",
        "authors": "Christopher BülteLisa LeimenstollMelanie Schienle",
        "links": "http://arxiv.org/abs/2407.08668v1",
        "entry_id": "http://arxiv.org/abs/2407.08668v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08668v1",
        "summary": "Recent methods in modeling spatial extreme events have focused on utilizing\nparametric max-stable processes and their underlying dependence structure. In\nthis work, we provide a unified approach for analyzing spatial extremes with\nlittle available data by estimating the distribution of model parameters or the\nspatial dependence directly. By employing recent developments in generative\nneural networks we predict a full sample-based distribution, allowing for\ndirect assessment of uncertainty regarding model parameters or other parameter\ndependent functionals. We validate our method by fitting several simulated\nmax-stable processes, showing a high accuracy of the approach, regarding\nparameter estimation, as well as uncertainty quantification. Additional\nrobustness checks highlight the generalization and extrapolation capabilities\nof the model, while an application to precipitation extremes across Western\nGermany demonstrates the usability of our approach in real-world scenarios.",
        "updated": "2024-07-11 16:57:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08668v1"
    },
    {
        "title": "Adaptive Smooth Non-Stationary Bandits",
        "authors": "Joe Suk",
        "links": "http://arxiv.org/abs/2407.08654v1",
        "entry_id": "http://arxiv.org/abs/2407.08654v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08654v1",
        "summary": "We study a $K$-armed non-stationary bandit model where rewards change\nsmoothly, as captured by H\\\"{o}lder class assumptions on rewards as functions\nof time. Such smooth changes are parametrized by a H\\\"{o}lder exponent $\\beta$\nand coefficient $\\lambda$. While various sub-cases of this general model have\nbeen studied in isolation, we first establish the minimax dynamic regret rate\ngenerally for all $K,\\beta,\\lambda$. Next, we show this optimal dynamic regret\ncan be attained adaptively, without knowledge of $\\beta,\\lambda$. To contrast,\neven with parameter knowledge, upper bounds were only previously known for\nlimited regimes $\\beta\\leq 1$ and $\\beta=2$ (Slivkins, 2014; Krishnamurthy and\nGopalan, 2021; Manegueu et al., 2021; Jia et al.,2023). Thus, our work resolves\nopen questions raised by these disparate threads of the literature.\n  We also study the problem of attaining faster gap-dependent regret rates in\nnon-stationary bandits. While such rates are long known to be impossible in\ngeneral (Garivier and Moulines, 2011), we show that environments admitting a\nsafe arm (Suk and Kpotufe, 2022) allow for much faster rates than the\nworst-case scaling with $\\sqrt{T}$. While previous works in this direction\nfocused on attaining the usual logarithmic regret bounds, as summed over\nstationary periods, our new gap-dependent rates reveal new optimistic regimes\nof non-stationarity where even the logarithmic bounds are pessimistic. We show\nour new gap-dependent rate is tight and that its achievability (i.e., as made\npossible by a safe arm) has a surprisingly simple and clean characterization\nwithin the smooth H\\\"{o}lder class model.",
        "updated": "2024-07-11 16:37:15 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08654v1"
    },
    {
        "title": "Multi-Group Proportional Representation",
        "authors": "Alex OesterlingClaudio Mayrink VerdunCarol Xuan LongAlex GlynnLucas Monteiro PaesSajani VithanaMartina CardoneFlavio P. Calmon",
        "links": "http://arxiv.org/abs/2407.08571v1",
        "entry_id": "http://arxiv.org/abs/2407.08571v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08571v1",
        "summary": "Image search and retrieval tasks can perpetuate harmful stereotypes, erase\ncultural identities, and amplify social disparities. Current approaches to\nmitigate these representational harms balance the number of retrieved items\nacross population groups defined by a small number of (often binary)\nattributes. However, most existing methods overlook intersectional groups\ndetermined by combinations of group attributes, such as gender, race, and\nethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel\nmetric that measures representation across intersectional groups. We develop\npractical methods for estimating MPR, provide theoretical guarantees, and\npropose optimization algorithms to ensure MPR in retrieval. We demonstrate that\nexisting methods optimizing for equal and proportional representation metrics\nmay fail to promote MPR. Crucially, our work shows that optimizing MPR yields\nmore proportional representation across multiple intersectional groups\nspecified by a rich function class, often with minimal compromise in retrieval\naccuracy.",
        "updated": "2024-07-11 14:59:17 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08571v1"
    },
    {
        "title": "Causal inference through multi-stage learning and doubly robust deep neural networks",
        "authors": "Yuqian ZhangJelena Bradic",
        "links": "http://arxiv.org/abs/2407.08560v1",
        "entry_id": "http://arxiv.org/abs/2407.08560v1",
        "pdf_url": "http://arxiv.org/pdf/2407.08560v1",
        "summary": "Deep neural networks (DNNs) have demonstrated remarkable empirical\nperformance in large-scale supervised learning problems, particularly in\nscenarios where both the sample size $n$ and the dimension of covariates $p$\nare large. This study delves into the application of DNNs across a wide\nspectrum of intricate causal inference tasks, where direct estimation falls\nshort and necessitates multi-stage learning. Examples include estimating the\nconditional average treatment effect and dynamic treatment effect. In this\nframework, DNNs are constructed sequentially, with subsequent stages building\nupon preceding ones. To mitigate the impact of estimation errors from early\nstages on subsequent ones, we integrate DNNs in a doubly robust manner. In\ncontrast to previous research, our study offers theoretical assurances\nregarding the effectiveness of DNNs in settings where the dimensionality $p$\nexpands with the sample size. These findings are significant independently and\nextend to degenerate single-stage learning problems.",
        "updated": "2024-07-11 14:47:44 UTC",
        "interpretation": "解释内容未找到",
        "id": "2407.08560v1"
    }
]