MAVIS: Mathematical Visual Instruction Tuning
RenruiZhang∗1,XinyuWei∗2,DongzhiJiang1,YichiZhang2,ZiyuGuo1
ChengzhuoTong3,JiamingLiu2,AojunZhou1,BinWei4
ShanghangZhang2,PengGao3,HongshengLi1
1CUHK 2PekingUniversity 3ShanghaiAILaboratory 4Oracle
{renruizhang, dzjiang, ziyuguo}@link.cuhk.edu.hk
Abstract
Multi-modalLargeLanguageModels(MLLMs)haverecentlyemergedasasig-
nificant focus in academia and industry. Despite their proficiency in general
multi-modalscenarios, themathematicalproblem-solvingcapabilitiesinvisual
contextsremaininsufficientlyexplored.WeidentifythreekeyareaswithinMLLMs
thatneedtobeimproved: visualencodingofmathdiagrams,diagram-language
alignment,andmathematicalreasoningskills. Thisdrawsforthanurgentdemand
forlarge-scale,high-qualitydataandtrainingpipelinesinvisualmathematics. In
thispaper,weproposeMAVIS,thefirstMAthematicalVISualinstructiontuning
paradigmforMLLMs,involvingaseriesofmathematicalvisualdatasetsandspe-
cializedMLLMs. Targetingthethreeissues,MAVIScontainsthreeprogressive
training stages from scratch. First, we curate MAVIS-Caption, consisting of
558Kdiagram-captionpairs,tofine-tuneamath-specificvisionencoder(CLIP-
Math)throughcontrastivelearning,tailoredforimproveddiagramvisualencoding.
Second, we utilize MAVIS-Caption to align the CLIP-Math with a large lan-
guagemodel(LLM)byaprojectionlayer,enhancingvision-languagealignment
inmathematicaldomains. Third,weintroduceMAVIS-Instruct,including900K
meticulously collected and annotated visual math problems, which is adopted
to finally instruct-tune the MLLM for robust mathematical reasoning skills. In
MAVIS-Instruct,weincorporatecompletechain-of-thought(CoT)rationalesfor
eachproblem,andminimizetextualredundancy,therebyconcentratingthemodel
towardsthevisualelements. Notethatbothournewdatasetsspanabroadrange
ofmathsubjectstoensurecomprehensivecapabilities,includingplanegeometry,
analyticgeometry,andfunction. Onvariousmathematicalbenchmarks,e.g.,Math-
Verse, MAVIS-7B achieves leading performance among open-source MLLMs,
surpassingother7Bmodelsby+11.0%andthesecond-bestLLaVA-NeXT(110B)
by+3.0%,demonstratingtheeffectivenessofourapproach. DataandModelsare
releasedathttps://github.com/ZrrSkywalker/MAVIS.
1 Introduction
The pursuit of artificial general intelligence (AGI) necessitates models to seamlessly integrate,
interpret, and generate multi-modal data. In recent years, the advent of Large-language Models
(LLMs) [5, 28, 58, 59, 16] and their Multi-modal extension (MLLMs) [70, 20, 55, 13, 64] have
significantlyfacilitatedthisprocessacrossvariousfields,suchashealthcare[54,53,69],autonomous
driving [63, 29], and robotics [36, 42]. Although MLLMs exhibit remarkable performance in
diversetasksandbenchmarks,onearenawheretheyhaveyettofullydemonstratetheirpotentialis
mathematicalproblem-solvinginvisualcontexts.
∗EqualContribution
Preprint.Underreview.
4202
luJ
11
]VC.sc[
1v93780.7042:viXraMath Diagram CLIP ViT-L Our CLIP-Math
MAVIS-7B:
AsectorABCisdrawn,with
angle CBA measuring 30
degrees. A square CBDE is
linkedtoedgeCB,withangle
BCE measuring 90 degrees.
ThedistancebetweenpointsA
and Bis 10.0 units,and the
distancebetweenpointsCand
Bisalso10.0units.Thesquare
CBDEhasaninscribedcircle.
GPT-4V:
TheimageshowsageometricfigurewithpointslabeledA,B,C,
D,andE.PointAisatthetopofaverticallinesegmentAB,
whichmeasures10units.FromB,a30°angleisformedwiththe
linesegmentextendingtoD.Thereisaquartercirclecentered
atBwitharadiusof10units,reachingpointC.Thefigure
includesaninscribedcirclecenteredwithinthequadrilateral
formedbypointsC,D,andE.ThelinesABandDEareparallel...
(a) Attention Comparison between (b) Captioning Comparison between
CLIP and our CLIP-Math GPT-4V and our MAVIS-7B
Figure1:(a)WecomparetheattentionmapofclasstokensfromCLIPViT-L[51]andourCLIP-Math.
Ourvisionencodercanbettercapturesignificantmathematicalinformationwithindiagrams. (b)
WecomparethediagramcaptioningcapabilitiesbetweenGPT-4V[49]andourMAVIS-7B,where
GPT-4Vfallshortofaccuratelyrecognizingmathematicalvisualelements.
Existingefforts[48,47,72]fortext-onlymathematicshaveattainedconsiderableprogress,attributed
to the sufficient training data and inherent language proficiency within LLMs. However, visual
mathematicalproblem-solvingposesuniquechallengesforMLLMs,requiringthemtointegratethe
analyticaldepthoftextualquestionswiththecontextualrichnessofvisualdiagrams. Weobserve
threecriticalissuesthatseverelyhinderthevisualmathematicalcapabilitiesofMLLMs.
i. Unsatisfactorymathdiagramembeddingsbyvisionencoders. MostMLLMsadopta
frozenCLIP[51]asthevisionencoder,whichispre-trainedbynaturalimagescapturing
real-worldsceneswithrichcolorsandtextures. Incontrast,mathdiagramsarecomposed
ofabstractcurves,shapes,andsymbolswithamonochromaticcolorscheme,exhibiting
largesemanticgapstogeneralscenarios. AsvisualizedinFigure1(a),theattentionmap
ofCLIPstrugglestocaptureimportantinformationwithinmathdiagrams,whichcannot
providesatisfactoryvisualembeddingsforLLMstounderstand.
ii. Diagram-languagemisalignmentbetweenvisionencodersandLLMs. Likewise,the
vision-languagepre-trainingstageofMLLMsalsoadoptsnaturalimage-captionpairsfor
cross-modalalignment.Duetothedomaingap,whiletheycangenerateaccuratecaptionsfor
real-worldimages,butfallshortofrecognizingbasicmathematicalelementsandnarrating
their relations. As compared in Figure 1 (b), even GPT-4V [49] produces low-quality
descriptions for simple geometric figures and functions, indicating LLMs are not well
alignedwiththevisualembeddingspaceofmathdiagrams.
iii. Inaccurate mathematical reasoning with visual elements by MLLMs. Referring to
MathVerse[71],incorporatingthediagraminputwouldadverselyaffectthereasoningquality
ofMLLMscomparedtousingonlythetext-onlyquestion. Fromtheirdemonstrations,we
observe the problem-solving process of GPT-4V and Gemini-Pro [22] both suffer from
low-qualitychain-of-thought(CoT)reasoningaccuracy. Thisdemonstratestheincapability
ofMLLMstoleveragevisualcuesforprecisemathematicalproblem-solving.
Therefore,tomitigatetheseissues,itisessentialtodevelopanextensivedatasetandeffectivetraining
approachtailoredtovisualmathematics. Inthispaper,weproposeMAVIS,thefirstMAthematical
VISual instruction tuning paradigm for MLLMs, which aims to fully unleash their potential for
diagramvisualencodingandreasoningcapabilities. Weintroducetwometiculouslycurateddatasets,
aprogressivethree-stagetrainingpipeline, andavisualmathematicalspecialist, MAVIS-7B.We
summarizethecontributionsofourworkasfollows.
• MAVIS-Caption&MAVIS-Instruct.Wecuratetwolarge-scale,high-qualitymathematical
visualdatasets,widelycoveringplanegeometry,analyticgeometry,andfunction. MAVIS-
Caption consists of 558K diagram-caption pairs, which are automatically created by a
delicatelydesigneddataenginewithaccuratevision-languagecorrespondence. MAVIS-
2Instructincludes834Kvisualmathproblems,whichareobtainedfromfoursources: 83k
augmentedbyGPT-4Vfrommanuallycollected4Kproblems,51KgeneratedbyGPT-4V
basedondiagram-captionpairs,117kaugmentedfromexistingdatasets,and582Kdirectly
constructed by our data engine. Each problem is annotated with a CoT rationale, and
modifiedtocontainminimizedtextualredundancyformoreinformativevisualdiagrams.
• Three-stageTrainingPipeline. Ourtrainingframeworkinvolvesthreeprogressivestages
designed to sequentially address the aforementioned identified deficiencies in MLLMs.
Firstly,weutilizeMAVIS-Captiontofine-tuneamath-specificvisionencoderbycontrastive
learning, termed CLIP-Math, to enable better visual representations of math diagrams.
Subsequently,wealignthisencoderwiththeLLMtoensureeffectivediagram-language
integrationalsobyMAVIS-Caption. Finally,ourMAVIS-Instructisadoptedtoinstruction-
tunetheMLLM.TheannotatedCoTrationalecanprovidesufficientsupervisionforthe
intricatereasoningcapabilities,andthevision-dominantformatcanbetterfocusmodelson
leveragingvisualinputs.
• MathematicalVisualSpecialist. Afterthethree-stagetraining,wedevelopMAVIS-7B,
an MLLM specifically optimized for visual mathematical problem-solving. On various
evaluation benchmarks, our model achieves leading performance compared to existing
open-source MLLMs, e.g., surpassing other 7B models by +11.0% and the second-best
LLaVA-NeXT (110B) [31] by +3.0% on the average accuracy of MathVerse [71]. The
quantitativeresultsandqualitativeanalysisbothvalidatethesignificanceofourapproach.
2 RelatedWork
VisualInstructionTuning. Theadvancementoflargelanguagemodels(LLMs)[5,28,59,16]
with instruction tuning has significantly enhanced zero-shot capabilities across a range of tasks.
Drawinginspirationfromthis,LLaMA-Adapterseries[70,20,26]proposeazero-initializedattention
mechanismtoalignfrozenvisionencoders[51]withLLaMA[58]formulti-modallearning. LLaVA
series[41,39]employalinearprojectorforvision-languagealignment,establishingvisualinstruction
tuningasastandardtrainingapproachinthemulti-modalfield. Flamingo[2]andOpenFlamingo[3]
havehonedvisualrepresentationbyintegratingacross-attentionresamplerwithvisionencoders.
SPHINXseries[21,38]utilizeablendofvisualencoderstomaketheLLMcognizantofvarious
image aspects. InternVL series [15, 17, 56] employ a large vision encoder and QFormer [34] to
incorporatehigh-qualityvisualinformationthroughamulti-stagetrainingmethodology. LLaVA-
NexT[40,31,33]furtherintroducesthe‘AnyRes’techniquetomanageimagesatanygivenresolution,
andLLaVA-NexT-Interleave[32]extendsthescopewidelytointerleavemulti-imagesettings. There
arealsorecenteffortstoapplyvisualinstructiontuningto3D[25,62]andvideo[35,18]scenarios.
Despitetheimpressivestridesmadeinbothmodelcapabilityandtrainingefficiencybymulti-modal
large language models (MLLMs) through visual instruction tuning, there is currently no MLLM
specificallydesignedformathematicalproblem-solving,norasubstantialdatasetavailableforsuch
purposesintheopen-sourcecommunity. Inthispaper,wemitigatetheissuebyproposingMAVIS
withhigh-qualitymathematicalvisualdatasetsandtrainingparadigms.
Mathematics in Large Models. Recent research has predominantly concentrated on text-only
mathematicalproblem-solvingusingLLMs. MAmmoTH[67,68]havecompiledextensivecollec-
tionsofmathematicalproblems,trainingLLMsusingthereasoningprocessesdescribedinsolutions.
MetaMATH[66]hasexpandeduponthisbyrewritingexistingproblemstocreatealargerdataset.
MathCoder [60] and ToRA [24] introduced a tools agent approach, employing Python code and
symbolic resolvers during the training phase, significantly outperforming traditional models that
rely on text-only mathematical reasoning. However, in the multi-modal field, despite the intro-
duction of several datasets such as Geometry3K [44], GeoQA [11], UniGeo [8], UniMath [37],
andGeomVerse[30],aimingatenhancingtheperformanceofMLLMsinsolvinggraphicalmath-
ematicalproblems,thesedatasetsarequitelimitedinscaleanddomain. Basedonthesedatasets,
G-LLaVA[19]hasdevelopedsuperiorcapabilitiesforunderstandinggraphicalgeometriesbutstrug-
gleswithmathematicalproblemsinotherdomains. ThecomprehensivebenchmarkMathVerse[71]
hasalsohighlightedtheexistingMLLMs’unsatisfactorycapacityforencodingvisualdiagramsin
diversemathematicaldomains.Therefore,thereisapressingneedforthedevelopmentofmorerobust
encodersformathematicalimagesandthetuningofMLLMswithmathematicalvisualinstructions,
forwhichweproposeMAVIStoaddressthechallenges.
3Table1: StatisticsofMAVIS-Caption. Table2: SubjectDistributionofMAVIS-Instruct.
Statistic Number Statistic Number
TotalCaptions Totalquestions 834K
-Totalnumber 588K -Multiple-choicequestions 615K(62.4%)
-Averagelength(words) 62.85 -Free-formquestions 218K(37.6%)
-Averagelength(characters) 339.68 ManualCollectionAugmentedbyGPT-4 83K
-Vocabularysize 418 -Geometryquestions 72K(86.5%)
-Functionquestions 11K(13.5%)
PlaneGeometry
-Totalnumber 299K(50.9%) ExistingDatasetsAugmentedbyGPT-4 117K
-Averagelength(words) 69.77 -Geometryquestions 117K(100.0%)
-Averagelength(characters) 385.85 -Functionquestions 0(0%)
-Vocabularysize 195 DataEngineCaptionsAnnotatedbyGPT-4 51K
AnalyticGeometry -Geometryquestions 30K(58.8%)
-Functionquestions 21K(41.2%)
-Totalnumber 77K(13.1%)
-Averagelength(words) 39.64 DataEngineGeneratedProblems 582K
-Averagelength(characters) 210.10 -Geometryquestions 466K(80.0%)
-Vocabularysize 158 -Functionquestions 116K(20.0%)
Function Numberofuniqueimages 611K(73.3%)
-Totalnumber 212K(36.0%) Numberofuniquequestions 804K(96.5%)
-Averagelength(words) 61.48 Numberofuniqueanswers 675K(81.0%)
-Averagelength(characters) 321.46 Averagequestionlength 44.60
-Vocabularysize 149 Averageanswerlength 62.82
3 MathematicalVisualDataset
InSection3.1,wefirstillustratethemethodologyofourdataenginetoautomaticallygeneratemath
diagrams. Then, we respectively introduce the two datasets we newly curated for MLLMs, i.e.,
MAVIS-CaptioninSection3.2andMAVIS-InstructinSection3.3.
3.1 DataEngine
TocopewiththesubstantialdatarequirementsofMLLMs,itisessentialtohaveaccesstohundreds
ofthousandsoftraininginstances. However,forvisualmathematics,thepaucityofpubliclyavailable
datasetsposesachallenge,andcreatingsuchdatamanuallyisalsonotfeasibleduetothehighcost
involved. Therefore,wedevelopanautomaticdataenginetogeneratehigh-qualitymathdiagrams
efficiently,asshowcasedinFigure1. Coveringmostmathematicalscenarios,weadoptthreediagram
types: planegeometry,analyticgeometry,andfunction. Notethatallthelogicofthedataengineis
implementedinPython,andweemployMatplotlibforthegraphicalrenderingofthediagrams.
PlaneGeometryDiagram. Assuchdiagramstypicallyconsistofspatialcombinationsofvarious
basicshapes,weutilizeprinciplesfrommulti-hopdatacurationtodevelopcustomizedgeneration
rules. These rules allow for the iterative integration of new shapes into existing configurations.
Initially,weestablishacoresetofshapes,includingsquares,rectangles,triangles,sectors,etc,for
diagramgeneration. Startingwitharandomlyselectedshape,weextendanothershapefromtheset
alongoneofitsstraightsides. Byiteratingthisprocess,wecanconstructdiverseplanegeometry
diagramsfeaturingdifferentcombinationsofshapes. Additionally,werandomlylabelthevertices
withletters(e.g.,A,B,C)andannotatenumericalvaluesrelevanttogeometricproperties(e.g.,side
lengthsandangles),simulatingrealisticplanegeometryproblems.
AnalyticGeometryDiagram. Likewise,ourapproachbeginsbydefiningabasicfiguresetthat
differsslightlyfromthatusedinplanegeometry;forexample,weincludeadditionalelementssuch
aspointsandlinesegments. WethenconstructaCartesiancoordinatesystem,completewithgrid
linesandscaledaxes. Therangeofthecoordinatesystemisrandomlydeterminedwithinapredefined
scope. Subsequently,weselectanumberfrom1to3toindicatethenumberoffigurestobedrawnon
thegraph,andrandomlychoosecoordinatesforthetop-leftverticestoplotthesefiguresatvaried
sizes(usingthesepointsascentersforcircles). Unlikeplanegeometry,weensurethatthefiguresdo
notoverlap,exceptforpointsandsegments,andmaintainthefigureareaswithinasuitablescale.
4Diagram:
Caption:
A rectangle ABCD has a semicircle The expression for the function is y = - At the outset, A circle with a center at
inscribed using CD as the diameter, and 2*log(10, 3*x + 4). When examining the (1, 3) and radius 3 is present.
CD is removed. Connected to edge CB is x range of [-4.0, 3.0], zero points Consequently, A rectangle originates
a modified rectangle CBEF, ....Connected appear at -1.0. In the range [-4.0, 3.0], from its lower left corner at (-8, -2)
to edge EB is rectangle EBHI with a while the function reaches its minimum and has a height of 2 and a width of 2.
semicircle outside using HI as the value of -2.23 at 3.0, it does not have a Also, Located at (-8, 7), ..., At (-4, 0),
diameter, and side HI is eliminated. The maximum value point. An asymptote of there is an ellipse with dimensions:
lengths of AB, CB, EB are each 7.0 units. the function is observed at: x = -1.33. height 1 and width 3.
Figure2: MAVIS-CaptionDataset. Weshowcasethreediagram-captionpairsofplanegeometry,
function,andanalyticgeometryinMAVIS-Caption,generatedbyourdevelopeddataengine.
Function Diagram. We focus on seven fundamental function types: polynomial, sine, cosine,
tangent,logarithmic,absolutevalue,andpiece-wisepolynomialfunctions. Foreachfunctiontype,
weparameterizetheequationswithrandomvariables,suchascoefficientsandconstantswithina
predefinedrange(e.g.,aandbiny =ax+b),whichfacilitatesthegenerationofdiversefunction
graphs. We also adopt the same Cartesian coordinate system employed for analytic geometry.
Additionally, for specific caption or question-answering samples, we also plot key features like
extremepointsandzeropointsofthefunctions,providingadditionalvisualinformationthataidsin
theunderstandingandreasoningofthesemathematicalfunctions.
3.2 MAVIS-Caption
Withourmathematicalvisualdataengine,wefirstcurateadiagram-captiondataset,MAVIS-Caption,
asshowninFigure2,aimingtobenefitthediagramvisualrepresentationsandcross-modalalignment.
DataOverview. AspresentedinTable1,theMAVIS-Captiondatasetcomprises588Kdiagram-
caption pairs. This includes 299K for plane geometry, 77K for analytic geometry, and 212K for
function. Theaveragewordlengthofthecaptionsis61.48words,reflectingtheirdetaileddescriptive
nature. Theoverallvocabularysizeis149,indicatingthediversityinlanguageexpression.
CaptionAnnotation. Weadoptdifferentstrategiestogeneratecaptionsforthreetypesofdiagrams.
NotethatallthecuratedcaptionsarerefinedbyChatGPT[50]atlastforahuman-likeexpression.
• PlaneGeometryCaption. Wefollowtheiterativegeometricgenerationprocesstodevelop
regulationsforanaccurateanddetailedcaption. WefirstpromptGPT-4[48]tocreatethree
setsoflanguagetemplates:thedescriptivecontentforfundamentalshapes(e.g.,“ATriangle
{}withtwocongruentsides{}and{}”),thephrasestodenotespecificattributes(e.g.,“Angle
{}measures{}degrees”),andtheconjunctiontolinktwoadjacentshapes(e.g.,“Attached
toedge{}ofshape{},thereisa{}”). Then,basedonvariousgenerationscenarios,wefill
andmergethesetemplatestoacquireacoherentdescriptionofthegeometricfigure.
• Analytic Geometry Caption. We also employ GPT-4 to obtain two sets of language
templates: thedescriptionofcoordinatesandattributeinformationforbasicfigures(e.g.,
“Thesquarewithitsbaseleftcornerat{}featuressidesof{}inlength”)andthespatial
relationfornearbyfigures(e.g.,“Onthebottomrightof{},thereisa{}”). Thecaptionsare
thenformulatedbyfillinginthecoordinatesandselectingappropriatespatialrelationship
templatesthroughcoordinatecomparison.
• FunctionCaption. Asfunctiondiagramstypicallyshowcaseasinglecurve,wedirectly
utilizeGPT-4togeneratetemplatesdescribingvariouspropertiesoffunctions,including
expressions,domains,ranges,extremepoints,andzeropoints. Eachtemplateisthenfilled
basedonspecificcases,suchas“Theexpressionofthefunctionisy =−3x3−2x2−2x−2.
Withintherangeofxvalues[−3.0,4.0],zeropointsoccurat−0.83...”.
5Diagram:
Question&Rationale:
A t a cr l o oa nt nc vo gk ey r f a tc o so r p m aa trp ot aa o bn ayy o l sc iw ca ta rrn c att u ih gs ra h vtt te o s lat id na ne r d es t . i s tg Thn o he u ena t I a t n hm t eeh a e s m ug ri ev ee a on sf d u 3i ra 5g e.0r a d om e f, g i rf e a a e nn sg g, l w le e h1 a h t 2 a i ?ss W r 1 A1e .) sh ? Ve a -m st b h als e p h eia n ; p Bte .h d e ed cso le ie ngs im n get n ph t a e rx a bg in or la a[-p ; 2h , WhatisthelengthofslopeAC?
f isu n toct hio an v et th ha et fd oe rs mc r .i .b .Fe is n dt vh ae l ut er sa c ok f A: 55 B: 135 C: 145 D: 155 C. rising parabola; D. straight line
b and c that make f(x) both
continuous and differentiable. The graph section from -2 to 11 Given AB=10 units, Angle C=30
Since angle 1 + angle 2 = 180°, shows a consistently rising curve, degree, AB = AC*sin(30) = AC*
and angle 1 = 35°, therefore which demonstrates the 0.5, thus AC = AB*2 = 20units
b=7/4 angle 2 = 145°. characteristics of a quadratic
c=10*(7/4)–5=25/2 Therefore, option C is selected. function with a positive leading
coefficient. So the answer is C.
Manual Collection Existing Datasets Data Engine Data Engine
Augmented by GPT-4 Augmented by GPT-4 Generated Problems Generated Problems
Figure3: MAVIS-InstructDataset. Weshowcasethegeneratedvisualmathproblemsfromfour
sourceswithinMAVIS-Instruct,whichcontaindetailedrationalesandminimizedtextualredundancy.
3.3 MAVIS-Instruct
Besidesthediagram-captiondataforcross-modalalignment,wecurateMAVIS-Instructofextensive
problem-solvingdatatoendowMLLMswithvisualmathematicalreasoningcapabilities,asshownin
Figure3.
DataOverview. AsillustratedinTable2,theMAVIS-Instructdatasetconsistsofatotalof834K
visualmathproblems. Giventhattheproportionofanalyticgeometryproblemsisrelativelysmall,
weclassifythemwithfunctionproblemsforsimplicity. EachprobleminMAVIS-Instructincludesa
CoTrationaleprovidingstep-by-stepsolutions,withanaverageanswerlengthof150words. We
haveminimizedtextualredundancyinthequestions,eliminatingunnecessarycontextualinformation,
distractingconditions,andattributesreadilyobservablefromthediagrams. Thisreductionintext
forcesMLLMstoenhancetheircapabilitytoextractessentialcontentfromvisualinputs. MAVIS-
Instructisassembledfromfourdistinctsourcestoensurebroadcoverage.
ManualCollectionAugmentedbyGPT-4. Toincorporatehigh-qualityproblemsfoundinreal-
world contexts, we manually collect 4K math problems with diagrams from publicly available
resources. Recognizingthatthesesourcesoftenlackdetailedrationalesandmaycontainredundant
text,weinitiallyutilizeGPT-4Vtoannotateadetailedsolvingprocessandstreamlinethequestion
texttoreduceredundancy. Subsequently,foreachcollectedinstance,weinputthequestion,rationale,
anddiagramintoGPT-4andemploycustomizedfew-shotpromptstogenerate20newproblemsper
original,comprising15multiple-choicequestionsand5free-formquestions. Thisprocesscontributes
atotalof84Kproblemstothedataset.
ExistingDatasetsAugmentedbyGPT-4. Givenexistingwell-organizedgeometricdatasets,we
canalsoleveragethemtoexpandMAVIS-Instruct. Referringtopreviouspromptdesigns,weaugment
the8Ktrainingsetfromtwodataset,Geometry-3KandGeoQA+,into80Kvisualproblemswith
accompanyingrationales,mappingeachoriginalproblemto10newones. Duetothescarcityof
publiclyavailablefunctiondata,wedonotincludefunctionproblemsfromthissource.
DataEngineCaptionsAnnotatedbyGPT-4. Giventhedetailedcaptionsanddiagramsgenerated
byourdataengine, wecanpromptGPT-4Vwiththesesufficientconditionstogenerateaccurate
question-answeringdata. Wefirstgenerateanewsetof17Kdiagram-captionpairsthatdonotoverlap
withthepreviousMAVIS-Caption,whichavoidsanswerleakagewithinthedetailedcaption. Then,
wepromptGPT-4Vtogenerate3newproblemswithrationales,obtaining51Kdataintotalfromthe
diagram-captionpairs.
6DataEngineGeneratedProblems. InadditiontorelyingonGPTfordatageneration,wemanually
craftrigorousregulationstoproducevisualmathproblemsdirectlyfromourdataengine.
• PlaneGeometryProblems. WeinitiallypromptGPT-4tocompileacomprehensivesetof
mathematicalformulasapplicabletoeachbasicshape(e.g.,Pythagoreantheoremforright
trianglesandareaformulaforcircles). Then,forageometricdiagram,werandomlyselect
aknownconditionwithinashapeasthefinalsolutiontarget,andsystematicallydeduce
backwardtoanothercondition,eitherwithinthesameshapeoranadjacentone,usinga
randomlyselectedmathematicalformula. Thisdeducedconditionisthensetasunknown,
and we continue iterative backward deductions as necessary. The final condition, along
withanyconditionsinthelaststep,arepresentedasinitialattributesinthequestion. The
rationalescanbesimplyobtainedbyreversingthisbackwarddeductionprocess.
• FunctionProblems. Asthepropertiesoffunctionsarepredetermined,weutilizeGPT-4to
generatediversereasoningtemplates. Thesetemplatesfacilitatethesolvingofonefunction
propertybasedonotherprovidedproperties,therebyensuringthegenerationofhigh-quality
functionrationales. Wefinallyobtain299Kplanegeometryand212Kfunctionproblems.
4 MathematicalVisualTraining
With the curated datasets, we devise a three-stage training pipeline for endowing MLLMs with
mathematical visual capabilities. They respectively aim to mitigate the three deficiencies within
existing MLLMs, i.e., diagram visual encoding, diagram-language alignment, and mathematical
reasoningskillsinvisualcontexts.
4.1 Stage1: TrainingCLIP-Math
ToenhanceCLIP’s[51]inadequatevisualencodingofmathdiagrams,weutilizeMAVIS-Captionto
trainaspecializedCLIP-Mathencoder. Specifically,wefine-tuneapre-trainedCLIP-Basemodel
followingtheconservativelearningscheme. Themathdiagramsarefedintothelearnablevision
encoder,whilethecorrespondingcaptionsareprocessedbythetextencoder,whichremainsfrozen
toprovidereliablesupervision. Viacontrastivetraining,themodellearnstoadaptfromitsoriginal
naturalimagedomaintomathematicalcontexts,increasingitsfocusonessentialvisualelements
withindiagrams,asdemonstratedinFigure1(a). TheoptimizedCLIP-Mathencodernowdelivers
morepreciseandrobustrepresentationsofmathdiagrams,establishingasolidfoundationforthe
subsequentvisualinterpretationofLLMs.
4.2 Stage2: AligningDiagram-language
AfteracquiringtheCLIP-Mathencoder,wefurtherintegrateitwithLLMsusingMAVIS-Caption
toboostcross-modalalignmentbetweenmathdiagramsandlanguageembeddingspace. Usinga
simpletwo-layerMLPastheprojectionlayer,wetransformthevisualencodingsfromCLIP-Math,
andprependthemasaprefixtotheLLMinput. Thisprocess, guidedbythediagramcaptioning
task,enablestheLLMtoaccuratelyrecognizemathematicalcomponentsanddescribetheirspatial
arrangements. Withthediagram-languagealignment,LLMsareequippedwiththeinterpretation
capabilityinmathdiagrams,servingasaninitialsteptowarddeepermathematicalreasoning. Inthis
stage,wefreezetheCLIP-Math,andtraintheprojectionlayeralongwiththeLoRA-based[27]LLM.
4.3 Stage3: InstructionTuning
Lastly,weleverageMAVIS-InstructtoendowMLLMswithCoTreasoningandproblem-solving
capabilitiesinvisualmathematics. Thedetailedrationaleswithineachproblem’ssolutionprovide
high-qualityreasoningguidanceforMLLMs,significantlyenhancingtheirstep-by-stepCoTprocess.
Furthermore, the adopted text-lite, vision-dominant, and vision-only problem formats facilitate
MLLMs to capture more essential information from the visual embeddings for problem-solving,
ratherthanrelyingonshortcutstoonlyprocessthetextualcontentwithinquestions. Duringthis
stage,weunfreezeboththeprojectionlayerandtheLoRA[27]-basedLLMtoperformathorough
instruction-followingtuning,whichfinallyresultsinMAVIS-7B.
7Table3: PerformanceComparisononMathVersewiththeaccuracymetric. Thehighestresultsfor
closed-source and open-source MLLMsaremarkedinredandbluerespectively.
All Text Text Vision Vision Vision
Model Base Dominant Lite Intensive Dominant Only
LLM
Acc Acc Acc Acc Acc Acc
Baselines
RandomChance - 12.4 12.4 12.4 12.4 12.4 12.4
Human - 67.7 71.2 70.9 61.4 68.3 66.7
LLMs
ChatGPT[50] - 26.1 33.3 18.9 - - -
GPT-4[48] - 33.6 46.5 46.5 - - -
Closed-sourceMLLMs
Qwen-VL-Plus[4] - 11.8 15.7 11.1 9.0 13.0 10.0
Gemini-Pro[22] - 23.5 26.3 23.5 23.0 22.3 22.2
Qwen-VL-Max[4] - 25.3 30.7 26.1 24.1 24.1 21.4
GPT-4V[49] - 39.4 54.7 41.4 34.9 34.4 31.6
Open-sourceMLLMs
LLaMA-AdapterV2[20] LLaMA-7B[58] 5.8 7.8 6.3 6.2 4.5 4.4
ImageBind-LLM[26] LLaMA-7B 10.0 13.2 11.6 9.8 11.8 3.5
mPLUG-Owl2[65] LLaMA-7B 10.3 11.6 11.4 11.1 9.4 8.0
MiniGPT-v2[13] LLaMA2-7B[59] 10.9 13.2 12.7 11.1 11.3 6.4
SPHINX-Plus[21] LLaMA2-13B 14.0 16.3 12.8 12.9 14.7 13.2
SPHINX-MoE[21] Mixtral-8×7B[28] 15.0 22.2 16.4 14.8 12.6 9.1
G-LLaVA[19] LLaMA2-7B 15.7 22.2 20.4 16.5 12.7 6.6
InternLM-XC2.[17] InternLM2-7B[6] 16.5 22.3 17.0 15.7 16.4 11.0
LLaVA-1.5[39] Vicuna-13B 17.0 18.7 18.5 18.1 16.1 13.8
ShareGPT4V[14] Vicuna-13B 17.4 21.8 20.6 18.6 16.2 9.7
Math-LLaVA[52] Vicuna-13B 19.0 21.2 19.8 20.2 17.6 16.4
LLaVA-NeXT[31] LLaMA3-8B[57] 19.3 24.9 20.9 20.8 16.1 13.8
LLaVA-NeXT Qwen-1.5-110B[1] 24.5 31.7 24.1 24.0 22.1 20.7
MAVIS-7B MAmmoTH2-7B[68] 27.5 41.4 29.1 27.4 24.9 14.6
5 Experiment
WefirstdetailourexperimentalsettingsinSection5.1,andthendiscussthequantitativeondifferent
benchmarks and qualitative examples in Sections 5.2 and 5.3, respectively. Please refer to the
SupplementaryMaterialformoreexperiments,analysis,andablationstudies.
5.1 ExperimentalSettings
ImplementationDetails. WeadoptaCLIPViT-L[51]asthepre-trainedmodeltofine-tuneour
CLIP-Math,andutilizeMammoth2-7B[68]asthebaseLLMtoconstructMAVIS-7B.Inthefirst
stage,wefine-tunetheCLIPfor10epochswithabatchsize16andaninitiallearningrate2e−6. In
thesecondstage,wetrainthediagram-languagealignmentfor1epochwithabatchsize32andan
initiallearningrate2e−6,andadoptLoRA[27]witharank128. Inthethirdstage,weadoptthe
sametrainingsettingsasthepreviousone.
Evaluation Benchmarks. We evaluate our model MAVIS-7B on three popular mathematical
benchmarks, MathVerse [71], GeoQA [12], and FunctionQA (a subset of function problems in
MathVista[43]). MathVerseisacomprehensivebenchmarkcontaining2.6Kvisualmathproblems
spanningplanegeometry,function,andsolidgeometry. GeoQAandFunctionQArespectivelyfocus
onplanegeometryandfunctionscenarios. Weadopttheaccuracymetricforallthebenchmarks.
5.2 QuantitativePerformance
AsshowninTable3fortheresultsonMathVerse,MAVIS-7Bachievesthebestoverallaccuracy
among existing open-source models with only a 7B size. On different problem versions, our
8Table4: Comparisonofmodelperformance Table5:Comparisonofmodelperformancewith
withtraditionalmethodsonGeoQA. methodsonFunctionQAofMathVista.
Model Accuracy(%) Model Accuracy(%)
RandomChance 25.0 RandomChance 22.5
FrequentGuesses 32.1 Closed-sourceMLLMs
CoTGPT-4[48] 35.0
Top-10Accuracy
PoTGPT-4[48] 37.0
NGS[10] 56.9
MultimodalBard[23] 45.5
DPE-GPS[7] 62.7
GPT-4V[49] 69.5
SCA-GPS[45] 64.1
Open-sourceMLLMs
Top-1Accuracy
LLaVA[41] 20.5
Geoformer[9] 46.8
LLaMA-AdapterV2[20] 32.0
UniMath[37] 50.0
LLaVA-NeXT[40] 33.7
G-LLaVA-7B[19] 64.2 SPHINX-MoE[21] 34.6
MAVIS-7B 66.7 MAVIS-7B 40.3
approachconsistentlysurpassesthesecond-bestmethod,especiallyforTextDominantandTextLite.
Specifically, our model exceeds InternLM-XComposer2 (7B) [17] by +11.0% and ShareGPT4V
(13B)[14]by+10.1%. ComparedtoothermathematicalMLLMs,i.e.,G-LLaVA[19]andconcurrent
Math-LLaVA[52],MAVIS-7Bexhibitssuperiorproblem-solvingcapabilitieswithhigherscoresof
+11.8%and+8.5%,respectively. Inaddition,ourmodelisalsoadvantageoustothemostpowerful
open-sourceMLLMseries,LLaVA-NeXT[31],from7Bto110Bmodelsizes,demonstratingthe
math-specificproficiencyofMAVIS-7B.Tables4and5respectivelyshowcaseourperformanceon
planegeometryandfunctionscenarios. Comparedtothosespecialistmodels,e.g.,G-LLaVA,our
MAVIS-7Bexhibitssuperiorreasoningandgeneralizationcapabilities.
5.3 QualitativeAnalysis
In Figure 4, we compare the mathematical problem-solving examples between MAVIS-7B and
GPT-4V [49]. Our model excels in understanding the geometric elements, function curves, and
coordinateaxesinmathematicaldiagrams,achievinghigher-qualityCoTreasoningcapabilities.
Figure4: Problem-solvingComparisonofMAVIS-7BandGPT-4V.
96 Conclusion
In this paper, we propose MAVIS, the first mathematical visual instruction tuning paradigm for
MLLMs. Wefirstintroducetwohigh-qualitydatasetsbyadelicatedataengine,MAVIS-Caption
andMAVIS-Instruct,containinglarge-scalediagram-languageandproblem-solvingdata. Then,we
customizeathree-stagetrainingframeworktoprogressivelytrainthemath-specificvisionencoder,the
diagram-languagealignment,andthemathematicalreasoningcapabilitiesofMLLMs. Theobtained
specialistmodel,MAVIS-7B,achievessuperiorperformanceacrossdifferentmathematicalvisual
benchmarks,demonstratingthepotentialtoserveasanewstandardforfutureresearch.
References
[1] AI@Meta:Llama3modelcard(2024),https://github.com/meta-llama/llama3/blob/
main/MODEL_CARD.md
[2] Alayrac, J.B., Donahue, J., Luc, P., Miech, A., Barr, I., Hasson, Y., Lenc, K., Mensch, A.,
Millican,K.,Reynolds,M.,etal.: Flamingo: avisuallanguagemodelforfew-shotlearning.
AdvancesinNeuralInformationProcessingSystems35,23716–23736(2022)
[3] Awadalla, A., Gao, I., Gardner, J., Hessel, J., Hanafy, Y., Zhu, W., Marathe, K., Bitton, Y.,
Gadre, S., Sagawa, S., et al.: Openflamingo: An open-source framework for training large
autoregressivevision-languagemodels.arXivpreprintarXiv:2308.01390(2023)
[4] Bai,J.,Bai,S.,Yang,S.,Wang,S.,Tan,S.,Wang,P.,Lin,J.,Zhou,C.,Zhou,J.: Qwen-vl: A
versatilevision-languagemodelforunderstanding,localization,textreading,andbeyond.arXiv
preprintarXiv:2308.12966(2023)
[5] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A.,
Shyam,P.,Sastry,G.,Askell,A.,etal.: Languagemodelsarefew-shotlearners.In: Advances
inneuralinformationprocessingsystems.pp.1877–1901(2020)
[6] Cai,Z.,Cao,M.,Chen,H.,Chen,K.,Chen,K.,Chen,X.,Chen,X.,Chen,Z.,Chen,Z.,Chu,P.,
etal.: Internlm2technicalreport.arXivpreprintarXiv:2403.17297(2024)
[7] Cao,J.,Xiao,J.: Anaugmentedbenchmarkdatasetforgeometricquestionansweringthrough
dualparalleltextencoding.In: Proceedingsofthe29thInternationalConferenceonComputa-
tionalLinguistics.pp.1511–1520(2022)
[8] Chen,J.,Li,T.,Qin,J.,Lu,P.,Lin,L.,Chen,C.,Liang,X.: Unigeo: Unifyinggeometrylogical
reasoningviareformulatingmathematicalexpression.ArXivabs/2212.02746(2022)
[9] Chen,J.,Li,T.,Qin,J.,Lu,P.,Lin,L.,Chen,C.,Liang,X.: UniGeo: Unifyinggeometrylogical
reasoningviareformulatingmathematicalexpression.In: Proceedingsofthe2022Conference
onEmpiricalMethodsinNaturalLanguageProcessing.pp.3313–3323(2022)
[10] Chen, J., Tang, J., Qin, J., Liang, X., Liu, L., Xing, E., Lin, L.: GeoQA: A geomet-
ric question answering benchmark towards multimodal numerical reasoning. In: Zong, C.,
Xia, F., Li, W., Navigli, R. (eds.) Findings of the Association for Computational Linguis-
tics: ACL-IJCNLP 2021. pp. 513–523. Association for Computational Linguistics, Online
(Aug2021).https://doi.org/10.18653/v1/2021.findings-acl.46,https://aclanthology.org/
2021.findings-acl.46
[11] Chen,J.,Tang,J.,Qin,J.,Liang,X.,Liu,L.,Xing,E.P.,Lin,L.: Geoqa: Ageometricquestion
answeringbenchmarktowardsmultimodalnumericalreasoning.ArXivabs/2105.14517(2021),
https://api.semanticscholar.org/CorpusID:235253782
[12] Chen,J.,Tang,J.,Qin,J.,Liang,X.,Liu,L.,Xing,E.P.,Lin,L.:Geoqa:Ageometricquestionan-
sweringbenchmarktowardsmultimodalnumericalreasoning.arXivpreprintarXiv:2105.14517
(2021)
[13] Chen,J.,Li,D.Z.X.S.X.,Zhang,Z.L.P.,Xiong,R.K.V.C.Y.,Elhoseiny,M.: Minigpt-v2: Large
languagemodelasaunifiedinterfaceforvision-languagemulti-tasklearning.arXivpreprint
arXiv:2310.09478(2023)
10[14] Chen, L., Li, J., wen Dong, X., Zhang, P., He, C., Wang, J., Zhao, F., Lin, D.: Sharegpt4v:
Improving large multi-modal models with better captions. ArXiv abs/2311.12793 (2023),
https://api.semanticscholar.org/CorpusID:265308687
[15] Chen,Z.,Wang,W.,Tian,H.,Ye,S.,Gao,Z.,Cui,E.,Tong,W.,Hu,K.,Luo,J.,Ma,Z.,etal.:
Howfararewetogpt-4v? closingthegaptocommercialmultimodalmodelswithopen-source
suites.arXivpreprintarXiv:2404.16821(2024)
[16] Chiang,W.L.,Li,Z.,Lin,Z.,Sheng,Y.,Wu,Z.,Zhang,H.,Zheng,L.,Zhuang,S.,Zhuang,Y.,
Gonzalez,J.E.,Stoica,I.,Xing,E.P.: Vicuna: Anopen-sourcechatbotimpressinggpt-4with
90%*chatgptquality.https://lmsys.org/blog/2023-03-30-vicuna/(March2023)
[17] Dong, X., Zhang, P., Zang, Y., Cao, Y., Wang, B., Ouyang, L., Wei, X., Zhang, S., Duan,
H.,Cao,M.,etal.: Internlm-xcomposer2: Masteringfree-formtext-imagecompositionand
comprehensioninvision-languagelargemodel.arXivpreprintarXiv:2401.16420(2024)
[18] Fu,C.,Dai,Y.,Luo,Y.,Li,L.,Ren,S.,Zhang,R.,Wang,Z.,Zhou,C.,Shen,Y.,Zhang,M.,
etal.: Video-mme: Thefirst-evercomprehensiveevaluationbenchmarkofmulti-modalllmsin
videoanalysis.arXivpreprintarXiv:2405.21075(2024)
[19] Gao,J.,Pi,R.,Zhang,J.,Ye,J.,Zhong,W.,Wang,Y.,Hong,L.,Han,J.,Xu,H.,Li,Z.,etal.:
G-llava: Solvinggeometricproblemwithmulti-modallargelanguagemodel.arXivpreprint
arXiv:2312.11370(2023)
[20] Gao,P.,Han,J.,Zhang,R.,Lin,Z.,Geng,S.,Zhou,A.,Zhang,W.,Lu,P.,He,C.,Yue,X.,Li,
H.,Qiao,Y.: Llama-adapterv2: Parameter-efficientvisualinstructionmodel.arXivpreprint
arXiv:2304.15010(2023)
[21] Gao,P.,Zhang,R.,Liu,C.,Qiu,L.,Huang,S.,Lin,W.,Zhao,S.,Geng,S.,Lin,Z.,Jin,P.,
etal.:Sphinx-x:Scalingdataandparametersforafamilyofmulti-modallargelanguagemodels.
arXivpreprintarXiv:2402.05935(2024)
[22] Gemini Team, G.: Gemini: a family of highly capable multimodal models. arXiv preprint
arXiv:2312.11805(2023)
[23] Google: Bard(2023),https://bard.google.com/
[24] Gou,Z.,Shao,Z.,Gong,Y.,Yang,Y.,Huang,M.,Duan,N.,Chen,W.,etal.: Tora: Atool-
integratedreasoningagentformathematicalproblemsolving.arXivpreprintarXiv:2309.17452
(2023)
[25] Guo, Z., Zhang, R., Zhu, X., Tang, Y., Ma, X., Han, J., Chen, K., Gao, P., Li, X., Li, H.,
etal.: Point-bind&point-llm: Aligningpointcloudwithmulti-modalityfor3dunderstanding,
generation,andinstructionfollowing.arXivpreprintarXiv:2309.00615(2023)
[26] Han,J.,Zhang,R.,Shao,W.,Gao,P.,Xu,P.,Xiao,H.,Zhang,K.,Liu,C.,Wen,S.,Guo,Z.,
et al.: Imagebind-llm: Multi-modality instruction tuning. arXiv preprint arXiv:2309.03905
(2023)
[27] Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., Chen, W.: Lora:
Low-rankadaptationoflargelanguagemodels.arXivpreprintarXiv:2106.09685(2021)
[28] Jiang,A.Q.,Sablayrolles,A.,Roux,A.,Mensch,A.,Savary,B.,Bamford,C.,Chaplot,D.S.,
deLasCasas,D.,Hanna,E.B.,Bressand,F.,Lengyel,G.,Bour,G.,Lample,G.,Lavaud,L.R.,
Saulnier,L.,Lachaux,M.,Stock,P.,Subramanian,S.,Yang,S.,Antoniak,S.,Scao,T.L.,Gervet,
T.,Lavril,T.,Wang,T.,Lacroix,T.,Sayed,W.E.: Mixtralofexperts.Arxiv2401.04088(2024)
[29] Jin,B.,Zheng,Y.,Li,P.,Li,W.,Zheng,Y.,Hu,S.,Liu,X.,Zhu,J.,Yan,Z.,Sun,H.,etal.:
Tod3cap: Towards3ddensecaptioninginoutdoorscenes.arXivpreprintarXiv:2403.19589
(2024)
[30] Kazemi,M.,Alvari,H.,Anand,A.,Wu,J.,Chen,X.,Soricut,R.: Geomverse: Asystematic
evaluationoflargemodelsforgeometricreasoning.arXivpreprintarXiv:2312.12241(2023)
11[31] Li, B., Zhang, K., Zhang, H., Guo, D., Zhang, R., Li, F., Zhang, Y., Liu, Z., Li, C.: Llava-
next: Stronger llms supercharge multimodal capabilities in the wild (May 2024), https:
//llava-vl.github.io/blog/2024-05-10-llava-next-stronger-llms/
[32] Li,F.,Zhang,R.,Zhang,H.,Zhang,Y.,Li,B.,Li,W.,Ma,Z.,Li,C.: Llava-next-interleave:
Tackling multi-image, video, and 3d in large multimodal models (2024), https://arxiv.
org/abs/2407.07895
[33] Li,F.,Zhang,R.,Zhang,H.,Zhang,Y.,Li,B.,Li,W.,Ma,Z.,Li,C.: Llava-next: Tackling
multi-image, video, and 3d in large multimodal models (June 2024), https://llava-vl.
github.io/blog/2024-06-16-llava-next-interleave/
[34] Li, J., Li, D., Xiong, C., Hoi, S.: Blip: Bootstrapping language-image pre-training for uni-
fiedvision-languageunderstandingandgeneration.In: InternationalConferenceonMachine
Learning.pp.12888–12900.PMLR(2022)
[35] Li,K.,He,Y.,Wang,Y.,Li,Y.,Wang,W.,Luo,P.,Wang,Y.,Wang,L.,Qiao,Y.: Videochat:
Chat-centricvideounderstanding.arXivpreprintarXiv:2305.06355(2023)
[36] Li, X., Zhang, M., Geng, Y., Geng, H., Long, Y., Shen, Y., Zhang, R., Liu, J., Dong, H.:
Manipllm: Embodiedmultimodallargelanguagemodelforobject-centricroboticmanipulation.
arXivpreprintarXiv:2312.16217(2023)
[37] Liang,Z.,Yang,T.,Zhang,J.,Zhang,X.: Unimath: Afoundationalandmultimodalmathemati-
calreasoner.In: EMNLP(2023)
[38] Lin,Z.,Liu,C.,Zhang,R.,Gao,P.,Qiu,L.,Xiao,H.,Qiu,H.,Lin,C.,Shao,W.,Chen,K.,
etal.: Sphinx: Thejointmixingofweights,tasks,andvisualembeddingsformulti-modallarge
languagemodels.arXivpreprintarXiv:2311.07575(2023)
[39] Liu,H.,Li,C.,Li,Y.,Lee,Y.J.: Improvedbaselineswithvisualinstructiontuning(2023)
[40] Liu, H., Li, C., Li, Y., Li, B., Zhang, Y., Shen, S., Lee, Y.J.: Llava-next: Improved rea-
soning,ocr,andworldknowledge(January2024),https://llava-vl.github.io/blog/
2024-01-30-llava-next/
[41] Liu,H.,Li,C.,Wu,Q.,Lee,Y.J.: Visualinstructiontuning.In: NeurIPS(2023)
[42] Liu, J., Li, C., Wang, G., Lee, L., Zhou, K., Chen, S., Xiong, C., Ge, J., Zhang, R., Zhang,
S.: Self-correctedmultimodallargelanguagemodelforend-to-endrobotmanipulation.arXiv
preprintarXiv:2405.17418(2024)
[43] Lu,P.,Bansal,H.,Xia,T.,Liu,J.,yueLi,C.,Hajishirzi,H.,Cheng,H.,Chang,K.W.,Galley,
M.,Gao,J.: Mathvista: Evaluatingmathreasoninginvisualcontextswithgpt-4v,bard,and
otherlargemultimodalmodels.ArXivabs/2310.02255(2023)
[44] Lu,P.,Gong,R.,Jiang,S.,Qiu,L.,Huang,S.,Liang,X.,Zhu,S.C.: Inter-gps: Interpretable
geometry problem solving with formal language and symbolic reasoning. arXiv preprint
arXiv:2105.04165(2021)
[45] Ning,M.,Wang,Q.F.,Huang,K.,Huang,X.: Asymboliccharactersawaremodelforsolving
geometryproblems.In: Proceedingsofthe31stACMInternationalConferenceonMultimedia.
p.7767–7775.MM’23,AssociationforComputingMachinery,NewYork,NY,USA(2023).
https://doi.org/10.1145/3581783.3612570,https://doi.org/10.1145/3581783.3612570
[46] Nye,M.,Andreassen,A.J.,Gur-Ari,G.,Michalewski,H.,Austin,J.,Bieber,D.,Dohan,D.,
Lewkowycz,A.,Bosma,M.,Luan,D.,etal.: Showyourwork: Scratchpadsforintermediate
computationwithlanguagemodels.arXivpreprintarXiv:2112.00114(2021)
[47] OpenAI:Chatgpt.https://chat.openai.com(2023)
[48] OpenAI:Gpt-4technicalreport.ArXivabs/2303.08774(2023)
[49] OpenAI: GPT-4V(ision) system card (2023), https://openai.com/research/
gpt-4v-system-card
12[50] Ouyang,L.,Wu,J.,Jiang,X.,Almeida,D.,Wainwright,C.,Mishkin,P.,Zhang,C.,Agarwal,
S.,Slama,K.,Gray,A.,Schulman,J.,Hilton,J.,Kelton,F.,Miller,L.,Simens,M.,Askell,A.,
Welinder,P.,Christiano,P.,Leike,J.,Lowe,R.: Traininglanguagemodelstofollowinstructions
withhumanfeedback.In: AdvancesinNeuralInformationProcessingSystems(2022)
[51] Radford, A., Kim, J.W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell,
A., Mishkin, P., Clark, J., Krueger, G., Sutskever, I.: Learning transferable visual models
fromnaturallanguagesupervision.In: InternationalConferenceonMachineLearning(2021),
https://api.semanticscholar.org/CorpusID:231591445
[52] Shi, W., Hu, Z., Bin, Y., Liu, J., Yang, Y., Ng, S.K., Bing, L., Lee, R.K.W.: Math-llava:
Bootstrappingmathematicalreasoningformultimodallargelanguagemodels.arXivpreprint
arXiv:2406.17294(2024)
[53] Shu,C.,Chen,B.,Liu,F.,Fu,Z.,Shareghi,E.,Collier,N.: Visualmed-alpaca: Aparameter-
efficientbiomedicalllmwithvisualcapabilities(2023)
[54] Singhal,K.,Tu,T.,Gottweis,J.,Sayres,R.,Wulczyn,E.,Hou,L.,Clark,K.,Pfohl,S.,Cole-
Lewis,H.,Neal,D.,etal.:Towardsexpert-levelmedicalquestionansweringwithlargelanguage
models.arXivpreprintarXiv:2305.09617(2023)
[55] Su,Y.,Lan,T.,Li,H.,Xu,J.,Wang,Y.,Cai,D.: Pandagpt: Onemodeltoinstruction-follow
themall.arXivpreprintarXiv:2305.16355(2023)
[56] Team,I.: Internlm: Amultilinguallanguagemodelwithprogressivelyenhancedcapabilities
(2023)
[57] Team, Q.: Introducing qwen1.5 (February 2024), https://qwenlm.github.io/blog/
qwen1.5/
[58] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., Rozière, B.,
Goyal,N.,Hambro,E.,Azhar,F.,etal.: Llama: Openandefficientfoundationlanguagemodels.
arXivpreprintarXiv:2302.13971(2023)
[59] Touvron,H.,Martin,L.,Stone,K.,Albert,P.,Almahairi,A.,Babaei,Y.,Bashlykov,N.,Batra,
S., Bhargava, P., Bhosale, S., etal.: Llama2: Openfoundationandfine-tunedchatmodels.
arXivpreprintarXiv:2307.09288(2023)
[60] Wang,K.,Ren,H.,Zhou,A.,Lu,Z.,Luo,S.,Shi,W.,Zhang,R.,Song,L.,Zhan,M.,Li,H.:
Mathcoder: SeamlesscodeintegrationinLLMsforenhancedmathematicalreasoning.In: The
TwelfthInternationalConferenceonLearningRepresentations(2024),https://openreview.
net/forum?id=z8TW0ttBPp
[61] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q.V., Zhou, D., et al.:
Chain-of-thoughtpromptingelicitsreasoninginlargelanguagemodels.AdvancesinNeural
InformationProcessingSystems35,24824–24837(2022)
[62] Xu,R.,Wang,X.,Wang,T.,Chen,Y.,Pang,J.,Lin,D.: Pointllm: Empoweringlargelanguage
modelstounderstandpointclouds.arXivpreprintarXiv:2308.16911(2023)
[63] Yang,S.,Liu,J.,Zhang,R.,Pan,M.,Guo,Z.,Li,X.,Chen,Z.,Gao,P.,Guo,Y.,Zhang,S.:
Lidar-llm: Exploringthepotentialoflargelanguagemodelsfor3dlidarunderstanding.arXiv
preprintarXiv:2312.14074(2023)
[64] Ye,Q.,Xu,H.,Xu,G.,Ye,J.,Yan,M.,Zhou,Y.,Wang,J.,Hu,A.,Shi,P.,Shi,Y.,Jiang,C.,
Li,C.,Xu,Y.,Chen,H.,Tian,J.,Qian,Q.,Zhang,J.,Huang,F.: mplug-owl: Modularization
empowerslargelanguagemodelswithmultimodality(2023)
[65] Ye, Q., Xu, H., Ye, J., Yan, M., Hu, A., Liu, H., Qian, Q., Zhang, J., Huang, F., Zhou, J.:
mplug-owl2: Revolutionizingmulti-modallargelanguagemodelwithmodalitycollaboration
(2023)
[66] Yu, L., Jiang, W., Shi, H., Yu, J., Liu, Z., Zhang, Y., Kwok, J.T., Li, Z., Weller, A., Liu,
W.: Metamath: Bootstrapyourownmathematicalquestionsforlargelanguagemodels.arXiv
preprintarXiv:2309.12284(2023)
13[67] Yue,X.,Qu,X.,Zhang,G.,Fu,Y.,Huang,W.,Sun,H.,Su,Y.,Chen,W.: Mammoth: Building
mathgeneralistmodelsthroughhybridinstructiontuning.arXivpreprintarXiv:2309.05653
(2023)
[68] Yue,X.,Zheng,T.,Zhang,G.,Chen,W.: Mammoth2: Scalinginstructionsfromtheweb.arXiv
preprintarXiv:2405.03548(2024)
[69] Zhang, H., Chen, J., Jiang, F., Yu, F., Chen, Z., Li, J., Chen, G., Wu, X., Zhang, Z.,
Xiao, Q., et al.: Huatuogpt, towards taming language model to be a doctor. arXiv preprint
arXiv:2305.15075(2023)
[70] Zhang,R.,Han,J.,Zhou,A.,Hu,X.,Yan,S.,Lu,P.,Li,H.,Gao,P.,Qiao,Y.: LLaMA-adapter:
Efficientfine-tuningoflargelanguagemodelswithzero-initializedattention.In: TheTwelfth
InternationalConferenceonLearningRepresentations(2024),https://openreview.net/
forum?id=d4UiXAHN2W
[71] Zhang,R.,Jiang,D.,Zhang,Y.,Lin,H.,Guo,Z.,Qiu,P.,Zhou,A.,Lu,P.,Chang,K.W.,Gao,P.,
etal.: Mathverse: Doesyourmulti-modalllmtrulyseethediagramsinvisualmathproblems?
arXivpreprintarXiv:2403.14624(2024)
[72] Zhou, A., Wang, K., Lu, Z., Shi, W., Luo, S., Qin, Z., Lu, S., Jia, A., Song, L., Zhan, M.,
etal.: Solvingchallengingmathwordproblemsusinggpt-4codeinterpreterwithcode-based
self-verification.arXivpreprintarXiv:2308.07921(2023)
A Appendix
A.1 DetailsofMathematicalVisualDataset
A.1.1 DataEngine
In this section, we detail the implementation specifics of our data engine, i.e., the process for
generatingdiagramsrelatedtoplanegeometry,analyticgeometry,andfunctiondomains.
PlaneGeometryDiagram. Inspiredbypreviousmulti-hopreasoningmethods[30,61,46],we
employ an iterative generation method over logical theories to generate plane geometric images
alongwithcorrespondingcaptionsandquestion-answeringpairs,whosecomplexitycanbecontrolled
acrossmultipleaxes. Specifically,wefirstdefineasetoffundamentalgeometricshapesinFigure5.
Figure5: Thesetoffundamentalshapesinplanegeometrydiagrams,whosestraightedgescanbe
extendedintootherbasicshapes.
Withineachshape,newbasicshapescanbegeneratedbyextendingaparticularedge. Foreachbasic
shape,weinitiallydefineametareasoningprocess:
Ei
O ,Ci −−m −n−−→1 O ,i∈[1,z], (1)
n−1 mn−1 n
whereOrepresentstheinitialsidelengthoftheshape,C denotestheadditionalconditionsrequired
m
tocompletemetareasoning,andE providesadetailedexplanationofthemetareasoningprocess.
m
Forexample,whenconsideringanisoscelestriangleasthe(n−1)thshapeinasequence,thevertex
angleisstillrequiredasC toreasonaboutbasesidelength,andthentoexpandtothenthshape,
m
14withE servingastheexplanationofthisprocess. Thevariablezindicatesthattherearezsetsof
m
possiblemetareasoningfortheshape,nindicatesthelengthofthegeneratingsequence,whichis
alsothenumberofhopsofreasoningrequiredtoanswerthequestion. Theinitialside,extendside,
andadditionalconditionsformeta-reasoningofeachbasicshapecanbereferredtoinFig.5. Inthe
finalshape,question-answeringpairspertinenttothisshapecanbegeneratedas
Ej
O ,Cj ,Qj −−q→n Aj,j ∈[1,m], (2)
n qn n n
whereC representstheadditionalconditionsrequiredtosolvetheproblem,whileQandAdenote
q
thequestionandanswer,respectively. E referstothedetailedexplanationofthesolvingprocess.
q
Thevariablemindicatesthattherearempairsofquestion-answeringandcorrespondingdetailed
explanationswithintheshape. Byapplyingmetareasoningto the n−1thshape, theinitialside
lengthofthenthshapecanbededuced. Therefore,foracomplexcompositefigureconsistingofn
shapes,theoverallquestion-answeringpaircanbedefinedasfollows:
n−1
(cid:88) Ej
O , C ,Cj ,Qj −−q→n Aj. (3)
1 mk qn n n
k=1
Eachshapedefinesasufficientnumberofconditions,explanations,andanswerstoensurethediversity
ofthegeneratedquestion-answeringpairs. Basedontheaforementionedrules,controllingthelength
ofthegenerationsequencecanregulatethenumberofreasoningsteps,andcontrollingthetypeof
questions can manage the knowledge required for solving the problems. Thus, we can generate
questionsofvaryingdifficultylevels. Theaforementionedgenerationprocesscanalsobeillustrated
inFigure7.
Figure6: Plaingeometrycaptionexamples.
AnalyticGeometryDiagram. Theimagegenerationmethodforanalyticgeometryisrelatively
straightforward. First,werandomlyselectarangewithinthecoordinatesystem: theminimumvalue
ofxischosenasanintegerbetween[−12,−8],andthemaximumvalueofxischosenasaninteger
between[8,12];therangefory isthesameasforx. Then,wedefinethefollowingbasicshapes:
point,linesegment,line,circle,ellipse,rectangle,square,polygon,andsector. Duringthegeneration
process,weselectanumberbetween1and4asthenumberofshapestogenerate. Thegeneration
ruleisthatnonlinearshapesotherthanpoints,linesegments,andlinesmustnotoverlap.
Function Diagram. The generation of function graphs is also straightforward. We define the
followingbasicfunctions,eachwithasetofparametersthatcanberandomlyselected:
SineFunction y = A·sin(f ·x+ϕ),wheretheamplitudeAisarandominteger
between1and3,thefrequencyf iseither1or2,andthephaseϕisa
randomintegerbetween0and2π.
15Figure 7: A single process for generating plane geometry diagrams and corresponding question-
answeringpairsisdescribed. Inthisexample,thegenerationsequencelengthisspecifiedas2. Initial
sidelengthispaintedaspink,C ispaintedasgreen,whileC ispaintedasyellow.
m q
CosineFunction y = A·cos(f ·x+ϕ),wheretheamplitudeAisarandominteger
between1and3,thefrequencyf iseither1or2,andthephaseϕisa
randomintegerbetween0and2π.
TangentFunction y = A·tan(f ·x+ϕ),wheretheamplitudeAisarandominteger
between1and3,thefrequencyf iseither1or2,andthephaseϕisa
randomintegerbetween0and2π.
PolynomialFunction P(x)=a xn+a xn−1+···+a x+a ,wherethedegreenis
n n−1 1 0
arandomintegerbetween1and4. Thecoefficientsa arerandomly
i
selectedintegersrangingfrom-3to3.
piece-wiseFunction piece-wisepolynomialfunctionsaredividedinto2or3segments,with
eachsegment’sparametersidenticaltothoseofapolynomialfunction.
LogarithmicFunction y = a · log (c · x + d), where the coefficient a is randomly cho-
b
senfrom{−3,−2,−1,1,2,3},thebasebisrandomlychosenfrom
{2,10,⌊e⌋}, the coefficient c is a random integer between 1 and 3,
andthecoefficientdisarandomintegerbetween1and6,ensuring
thatc·x+dispositive.
AbsoluteFunction y =|a·x+b|,whereaandbarerandomintegerbetween−5and5.
We first determine the domain range to be displayed on the function graph. For trigonometric
functions,thedomainissetto[−π,π]. Forpiece-wisepolynomialfunctions,theminimumvalueof
xisarandomintegerbetween[−12,−8],andthemaximumvalueofxisarandomintegerbetween
[8,12]. For other functions, the minimum and maximum values of x are random integers within
therangesof[−6,−3]and[3,6],respectively. Duringtheplottingprocess,wecalculatethelocal
maxima, minima, andzerosofthefunctionbyiteratingthroughthedomain. Wethenrenderthe
x-coordinatesoftheseextremaandzerosonthex-axisofthefunctiongraph.
A.1.2 MAVIS-Caption
Inthissection,wedetailhowthecaptionscorrespondingtoimagesintheMAVIS-CaptionDataset
aregenerated.
Plane Geometry Caption. Based on the generation process described in SectionA.1.1, when
generatingeachshape,acaptionisrandomlyselectedfromasetofcaptionsforthatshapeandsome
connectingwordsarerandomlyadded. ThecaptionsforeachshapecanbereferencedinSection??.
Wealsorandomlyselectsomeedgesoranglesandstatetheirmeasurementsinthecaption. After
16Figure8: Examplesofanalyticalgeometrydiagramcaption.
generatingtherawcaption,weuseGPT-3.5torefineit,enhancingitslinguisticstructureandsemantic
diversity. AnexampleisshowninFig.6.
AnalyticGeometryCaption. Foreachshape,wemaintainasetofcaptiontemplatesthatdescribe
theshape’stype,coordinateposition,andotherattributes. Specifictemplatescanbereferencedin
Section??. InthegenerationprocessdescribedinSectionA.1.1,weselectatemplateandrandomly
addsomediverseconnectingwordstoformacompletecaption. Examplesofsomecaptionsare
showninFig.8.
FunctionCaption. AccordingtothefunctiongraphgenerationprocessdescribedinSectionA.1.1,
werecordthefunction’szerosandextrema. Additionally,wealsorecordthefunction’sexpression
andasymptotes. Theseattributesareincorporatedintoarandomlyselectedcaptiontemplatetoform
thefunctiongraph’scaption. CaptiontemplatescanbereferencedinSection??. Someexamplesare
providedinFig.9.
Figure9: Functiondiagramcaptions.
A.1.3 MAVIS-Instruct
Manual Collection Augmented by GPT-4. To complement the dataset with real-world problem-
solvingscenarios,wehire8humanexpertstomanuallycollectvisualmathproblemsfromvarious
17publicsources1,2,3,spanningplanegeometry,analyticgeometry,andfunction. Forproblems,wetry
toobtaintheircontentascompleteaspossible,includingquestions,diagrams,answers,andrationales
ifavailable. Then,wefirstfeedalltherelatedinformationintoGPT-4Vtoeliminatetheredundant
informationwithintextquestions,constructingthetext-liteversionofproblemsbythepromptin
Figure10.Then,wedesignthreetypesofpromptsforGPT-4toaugment15multiple-choicequestions
(including10multiple-choiceand5binary-choice,i.e.,‘True’or‘False’)and5free-formquestions,
respectively, as shown in Figure 11. We do not adopt GPT-4V here, since GPT-4V itself would
misunderstanddiagramsforlow-qualitydataaugmentation. Thenewlygeneratedproblemscontain
detailedCoTrationalesanddiversequestionforms.
Figure10: Manuallycollectvisualmathproblemstext-liteversion.
Figure11: WedesigndifferenttypesofpromptsforGPT-4toaugment15multiple-choicequestions
and5free-formquestions,respectively.
ExistingDatasetsAugmentedbyGPT-4.Previouseffortshavebeenmadetoprovidesomesmall-scale,
planegeometrydatasets,e.g.,GeoQA[12],GeoQA+[10],andGeometry3K[44]. Althoughtheyare
limitedindatascalefortuningMLLMsandincludenorationales,wecanalsoregardthemasaseed
datasetandadoptGPT-4toaugmentlarger-scaletrainingdata. WedonotutilizeGPT-4Vhereforthe
1https://homework.study.com
2https://www.ixl.com/math
3https://mathspace.co/us
18samereasonaforementioned. Indetail,wedesign3typesofquestiongenerationapproachesusing
differentprompts,asshowninFig.12. ForGeometry3K,asthequestiontextsarenormallybriefand
containmarginaldescriptiveinformation,posingchallengesforGPT-4tounderstandthediagram,
weonlyaugmentthemtogeneratebinary-choicequestions, i.e., ‘Ture’or‘False’. ForGeoQA+,
wecanleveragethesufficientredundantinformationwithintheirtextstogeneratemorediverseand
accuratemulti-choiceandfree-formquestions. Likewise,GPT-4canproduceCoTrationalesforeach
problem.
Figure12: Wedesign3typesofquestiongenerationapproachesusingdifferentpromptstoaugment
existingvisualmathematicaldataset.
Figure13: TheTextDominant,TextLite,VisionDominant,andVisionOnlyversionsofthesame
question. TextDominantandTextLiteusethesameimage. Inthetext,thenecessaryconditionsfor
solvingtheproblemarehighlightedinred,whileredundantdescriptiveconditionsarehighlighted
inblue. IntheVisionOnlyversion,thequestionisrenderedintheimage,withnotextualquestion
provided.
DataEngineCaptionsAnnotatedbyGPT-4.
Giventhedelicatelydesigneddataengineforautomaticdiagram-captioncreation,wecanutilizethe
generatedlarge-scalepairstoannotatequestion-answeringdatausingGPT-4V.Differentfromthe
previoustwosourcesthataugmentquestionsbasedonquestions,weutilizetheGPT-4Vmodelhere
forcautiondatawithtworeasons: first,thedetailedcaptionfromourdataenginecanwellguide
GPT-4Vforrelativelyhigher-qualityvisualembedding;second,thevisualinputservesasguidance
toprovideadditionalspatialinformationforbroadquestionforms. AsshowninFig.20andFig.21,
weadoptdifferentpromptsforfunctionandplanegeometryproblems,ensuringthatthegenerated
question-answeringdataisofhighqualityforinstructiontuning.
DataEngineGeneratedProblems.
PlaneGeometry. BasedonthegenerationprocessdescribedinSectionA.1.1,weposequestions
about the final shape in the generation sequence. We designed 6 types of questions: finding the
19Figure14: Perimeterproblemtemplates. Figure15: Areaproblemtemplates.
Figure16: Baselengthproblemtemplates.
perimeter, findingthearea, findingthebaselength, findingtheangle, findingthearclength, and
findingtheextendededgelength. Eachtypeofquestionhasasetoftemplatesthatcanberandomly
selected,asshowninFigure14-19. Asfortheanswerandanalysis,eachshapehasasetoftemplates
fordifferenttypesofquestionstochoosefrom,asshowninSec.A.1.1.
Tofurtherenhancethemodel’sunderstandingofdifferentformsofquestionsandbetterutilizethe
diversemodalinformationinthetextandimages,wedividedtheplaingeometryquestionsgenerated
bytheDataEngineintofourversionsreferringtoMathVerse[71]: TextDominant,TextLite,Vision
Dominant,andVisionOnly.
TextDominant Wemarkedalltheconditionsrequiredforsolvingtheprobleminthediagram
andalsodescribedtheseconditionsinthetext,alongwithsomeredundant
descriptivetext.
TextLite Alltheconditionsrequiredforsolvingtheproblemarerandomlydividedinto
twoparts: onepartismarkedinthediagram,andtheotherpartisdescribed
inthetext. Inotherwords,theconditionsinthediagramandtheconditions
inthetextdonotoverlap.
20VisionDominant Alltheconditionsrequiredforsolvingtheproblemaremarkedinthediagram,
whilethetextonlycontainsthequestionwithoutanyconditions.
VisionOnly Notonlyarealltheconditionsrequiredforsolvingtheproblemmarkedin
thediagram,butthequestionisalsorenderedinthediagram,leavingthetext
portionempty.
ThedifferencesamongthefourversionsofthesamequestionareillustratedinFigure13. Eachbasic
shapewillretainasetofredundantconditions. Duringtheshapegenerationprocess,thereisa50%
probabilityofincludingtheseredundantconditions.
Figure17: Angleproblemtemplates.
Figure 19: Extend side length problem tem-
Figure18: Arclengthproblemtemplates.
plates.
21Diagram: Prompt for Function Problems: Question & Rationale Generated by GPT-4V:
Here is some more supplementary information for the diagram I Question:
give you: "{caption}" What is the length of square side FG? Choices: A. 10.0; B. 10.1; C. 9.9; D. 10.5
P c Tl o he r ea r ns e e c y t of l ui yr s sat hn osw uwa le dtc r ceh od rt h ro ene cl yd t i lba yyg a r s na e am e ly ia snn ig sd t t ha hs e ek d qa i ua eq gu sr te a is m ot n.i o an n dth ga it v ec a tn h eb e a nswer. R S eqia n ut c aei l o iF nn G la e l i ns: g a t hs ,i d te h eo f le s nq gu ta hr oe f D FB GF G m, u a sn td b t eh te h p er so ap mer et aie ss D o Bf wa hs iq cu ha r ise gd ivic et na t ae s t 1h 0a .0t ua nll i ts sid . e Ss o a tr he e
The reasoning process should not use "According to the caption" or answer is A.
something like that.
Next, you should give 3 other hard false choices along with the
correct one. Question:
You should totally provide 3 questions. What is the length of diagonal AC in triangle ABC? Choices: A. 10.1; B. 9.8; C. 9.9; D. 10.0
The type of questions is multi-choice. Rational:
Caption: In right triangle ABC with sides AB = 7.0 and BC = 7.0 units, and angle ACB = 45°, the
You should strictly follow this format and order (end every problem triangle is isosceles. The length of diagonal AC can be calculated using the Pythagorean
T e o 1 [ r -- 1. efqh 7 𝝿 .a u 0e 1[ , ca - . 𝝿 ahtf 𝝿 E tiu e],o x , n s 0n 𝝿 p wc .i] lt 1y seo, 4i ro w= 1f .in . ne i 0 T1 n g *c d hf a a c ti etnn o th r d h s -e eb ( 3 a 1 te f t a.* h 0 u rd x te ,n e he ac + zs e nnt ec o3 i dhr or ) ao ii n. tgb s hW hp we yeo ed mii ti st ln phb oth t tw iy s n v oa e a t tn a t slh e t uh tx se e e- v i r 1 i a nr. ta 4 l a n u tn3 eg hg,e e e i s w Q g A f A Cui Hi N NvUt ne Oh A ScE n t IS WL# ir CY oT a# E EnSI n R :# IO og : AS be # N B? .t: ) : .a 3F : i 4W ;nr Bo th m .h a 4 et t ; hi m Cs e . a t xd 2h ii ;e ma D g um r .m aa 1m x #vi , am #lw uu #e em , #c wv aa n hl iu o ce b h s o ief sr t 4vh e .e t f hu an tc wti ho en n i n x =t 0h ,e t he t Q W R Th hae hu eto ae ir pt os e eit nm s r ii a: t mo h lA en :e C t: e p = re r√ oi( fmA qeB ut² ae d r+ r o iB lf aC tq² eu) ra a= d l r √ Cil( Ba7 t D. e0 Er² a i nl+ cC7 lB u.0 D d² eE) s? = sC i√ dh9 eo s8 ic Ce≈ s B :9 , A. B9 . D. 3S , 3 Do . 0 Et ;h , Be an .a d3n 4s Ew . C0e .; r GC i i.s v3 eC 5 n. . 0 C; B D =. 73 .2 0. ,0 BD =
functions. 1 B0 D.0 . T, a hn ud s ,k Dn Eow =i n 7g . 0q u aa nd dr Eila Ct =e r 1a 0l . 0C .B TD hE e h pa es r p imar ea tl ele rl =a n Cd B e +q Bu Dal +o p Dp Eo s +i t Ee C s =id 7e .s 0, D + E 10 = . 0C B + 7a .n 0d +E 1C 0 = .0
= 34.0 units. So the answer is B.
Figure20: ThefunctionpromptforGPT-4Vandthegeneratedquestionsandrationals.
Diagram: Prompt for Plane Geometry Problems: Question & Rationale Generated by GPT-4V:
Here is some more supplementary information of the diagram I give Question:
you: "{caption}" What is the length of square side FG? Choices: A. 10.0; B. 10.1; C. 9.9; D. 10.5
P cl oe ra rs ee c tf li yr s at n sw wa etc reh d t h one l yd i ba yg r sa em e ia nn gd t has ek d a ia q gu re as mt .ion that can be R Sia nt ci eo Fn Gal : is a side of square DBFG, and the properties of a square dictate that all sides are
Then you should correctly analysis the question and give the answer. equal in length, the length of FG must be the same as DB which is given as 10.0 units. So the
The reasoning process should not use "According to the caption" or answer is A.
something like that.
Next, you should give 3 other hard false choices along with the
correct one. Question:
You should totally provide 3 questions. What is the length of diagonal AC in triangle ABC? Choices: A. 10.1; B. 9.8; C. 9.9; D. 10.0
The type of questions is multi-choice. Rational:
Caption: In right triangle ABC with sides AB = 7.0 and BC = 7.0 units, and angle ACB = 45°, the
F S Q e reqi e ur nucs a daot d l enl ry i rd ni, l l a ayt l t er , S e na a qr gc t ua te t al h a a rw c C e h iR t Be Di h Dg d B h o E Ftt p .o G p TT .oe hr Tsdi iia r hg t dn ee eg l y mCl se ,iB ed jA , aoe sd iB s n ur C ep ra. d eaw r m taa eol l n e e tl d oa g fn e d D B, Y w Q A c Aao i N BUt nu h A E \ ds tS L# eh iYT mro # S iu I v e#l IO e sd S # N sts : h i )t : nS : er W (i i \nc h ah ct e nal e iy ggt w lh f ei teso C l otl k Bo h fnw A e o t )w ht h =h ee t i i 1hs tg 1 rehf .a 7to l pe r *eo nm f zg sa it it ut nhh m ( a e 6o n A 0ftd )Br A ao C =Bpr D 1d e a 0.ze n .Tir 1du h ,m( et se h o n A h ed teB ha ie C g env D h ge at? lr ne y s s C h wp B o er uAo rlb d, i l s we b em e t t Q Wr hi e u ha o aen r tg s el t ie m si o:i ts n hA i e:Cs o p =s e c r√e i( ml Ae es B t. ² eT r+h oe B f Cl e q²n u)g a =t d h r√ i(o la7f t. 0 ed ² ria a g + l o C7n B.a 0 Dl ² EA ) ? C = C c √ ha 9 on 8 i cb ≈ ee s 9c : .a A9lc . . u S 3l 3oa t .0te h ;d e B u .a s 3nin s 4wg .0 et ;rh C e i .s P 3Cy 5.t .h 0a ; g Do .r 3e 2an .0
a An ng gl le e A BC DB G i ms e4 a5 so u. rT eh se 9 a 0n og il ne sD izB eC . m Thea es du ir se ts a n6 c0 eo . 1 A1 N.7 SWER: B. 11.7 R Tha et i po en ra iml: e ter of quadrilateral CBDE includes sides CB, BD, DE, and EC. Given CB = 7.0, BD =
between points A and B is 7.0. The segment CB CHOICE: A. 11; B. 11.7; C. 12; D. 8 #### 10.0, and knowing quadrilateral CBDE has parallel and equal opposite sides, DE = CB and EC =
spans 7.0 units. Side DB spans 10.0 units. BD. Thus, DE = 7.0 and EC = 10.0. The perimeter = CB + BD + DE + EC = 7.0 + 10.0 + 7.0 + 10.0
= 34.0 units. So the answer is B.
Figure21: ThegeometrypromptforGPT-4Vandthegeneratedquestionsandrationals.
Function. Allfunctionswillbeexaminedwithtwotypesofquestions: findingthederivativeand
findingtheextrema. Afterobtainingthederivative,wecalculatewhetherthederivativehaszeros
withinthegivendomain. Thepresenceofzerosdeterminesthemethodforcalculatingthefunction’s
extrema.
22Figure22: Theinitialside,extendside,andadditionalconditionsformeta-reasoningofeachbasic
shape. Somespecialshapesarenotextendedandonlyappearinthelastpositionofthegeneration
sequence,thustheirextendsideis∅.
23