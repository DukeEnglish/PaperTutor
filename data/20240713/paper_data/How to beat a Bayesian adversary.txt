How to beat a Bayesian adversary
Zihan Ding∗ Kexin Jin† Jonas Latz‡ Chenguang Liu§
July 12, 2024
Abstract
Deep neural networks and other modern machine learning models are often susceptible to ad-
versarialattacks. Indeed,anadversarymayoftenbeabletochangeamodel’spredictionthrougha
small, directed perturbation of the model’s input – an issue in safety-critical applications. Adver-
sariallyrobustmachinelearningisusuallybasedonaminmaxoptimisationproblemthatminimises
the machine learning loss under maximisation-based adversarial attacks.
In this work, we study adversaries that determine their attack using a Bayesian statistical
approach rather than maximisation. The resulting Bayesian adversarial robustness problem is a
relaxationoftheusualminmaxproblem. Tosolvethisproblem,weproposeAbram–acontinuous-
time particle system that shall approximate the gradient flow corresponding to the underlying
learning problem. We show that Abram approximates a McKean-Vlasov process and justify the
use of Abram by giving assumptions under which the McKean-Vlasov process finds the minimiser
oftheBayesianadversarialrobustnessproblem. WediscusstwowaystodiscretiseAbramandshow
its suitability in benchmark adversarial deep learning experiments.
Keywords: Machine learning, adversarial robustness, stochastic differential equations, McKean-
Vlasov process, particle system
MSC(2020): 90C15, 65C35, 68T07
1 Introduction
Machine learning and artificial intelligence play a major role in today’s society: self-driving cars
(e.g., Bachute and Subhedar (2021)), automated medical diagnoses (e.g., Rajkomar et al. (2019)),
and security systems based on face recognition (e.g., Sharma et al. (2020)), for instance, are often
based on certain machine learning models, such as deep neural networks (DNNs). DNNs are often
discontinuous with respect to their input (Szegedy et al., 2014) making them susceptible to so-called
adversarial attacks. In an adversarial attack, an adversary aims to change the prediction of a DNN
through a directed, but small perturbation to the input. We refer to Goodfellow et al. (2015) for
an example showing the weakness of DNNs towards adversarial attacks. Especially when employing
DNNs in safety-critical applications, the training of machine learning models in a way that is robust
to adversarial attacks has become a vital task.
Machine learning models are usually trained by minimising an associated loss function. In ad-
versarially robust learning, this loss function is considered to be subject to adversarial attacks. The
adversarial attack is usually given by a perturbation of the input data that is chosen to maximise the
∗Department of Electrical and Computer Engineering, Princeton University, USA, zihand@princeton.edu
†Department of Mathematics, Princeton University, USA, kexinj@math.princeton.edu
‡Department of Mathematics, University of Manchester, UK, jonas.latz@manchester.ac.uk
§Delft Institute of Applied Mathematics, Technische Universiteit Delft, The Netherlands, c.liu-13@tudelft.nl
1
4202
luJ
11
]GL.sc[
1v87680.7042:viXraloss function. Thus, adversarial robust learning is formulated as a minmax optimisation problem. In
practice, the inner maximisation problem needs to be approximated: Goodfellow et al. (2015) pro-
posed the Fast Gradient Sign Method (FGSM) which perturbs the input data to maximise the loss
function with a single step. Improvements of FGSM were proposed by, e.g., Tram`er et al. (2018); Ku-
rakin et al. (2017a); Wong et al. (2020). Another popular methodology is Projected Gradient Descent
(PGD) (Madry et al., 2018) and its variants, see, for example, Dong et al. (2018); Yang et al. (2019);
Mosbach et al. (2019); Tramer and Boneh (2019); Maini et al. (2020); Croce and Hein (2020). Similar
to FGSM, PGD considers the minmax optimisation problem but uses multi-step gradient ascent to
approximate the inner maximisation problem. Notably, Wong et al. (2020) showed that FGSM with
random initialization is as effective as PGD.
Other defense methods include preprocessing (e.g. Xu et al. 2018; Song et al. 2018; Guo et al.
2018; Yun et al. 2019) and detection (e.g. Carlini and Wagner 2017a; Metzen et al. 2017; Liu et al.
2022; Xu et al. 2023), as well as provable defenses (e.g. Wong and Kolter 2018; Gowal et al. 2019;
Sheikholeslami et al. 2021; Jia et al. 2022). Various attack methods have also been proposed, see,
for instance, Carlini and Wagner (2017b); Wong et al. (2019); Ghiasi et al. (2020); Croce and Hein
(2020). More recently, there is an increased focus on using generative models to improve adversarial
accuracy, see for example Nie et al. (2022); Wang et al. (2023); Xue et al. (2023).
In the present work, we study the case of an adversary that finds their attack following a Bayesian
statistical methodology. The Bayesian adversary does not find the attack through optimisation, but
by sampling a probability distribution that can be derived using Bayes’ Theorem. Importantly, we
study the setting in which the adversary uses a Bayesian strategy, but the machine learner/defender
trains the model using optimisation, which is in contrast to Ye and Zhu (2018). The associated
Bayesian adversarial robustness problem can be interpreted as a stochastic relaxation of the classical
minmax problem that replaces the inner maximisation problem with an integral. After establishing
this connection, we
• propose Abram (short for Adversarial Bayesian Particle Sampler), a particle-based continuous-
time dynamical system that simultaneously approximates the behaviour of the Bayesian adver-
sary and trains the model via gradient descent.
Particle systems of this form have been used previously to solve such optimisation problems in the
context of maximum marginal likelihood estimation, see, e.g., Akyildiz et al. (2023) and Kuntz et al.
(2023). In order to justify the use Abram in this situation, we
• show that Abram converges to a McKean–Vlasov stochastic differential equation as the number
of particles goes to infinity, and
• give assumptions under which the McKean-Vlasov SDE converges to the minimiser of the
Bayesian adversarial robustness problem with an exponential rate.
Additional complexity arises here compared to earlier work as the dynamical system and its limiting
McKean-Vlasov SDE have to be considered under reflecting boundary conditions. After the analysis
of the continuous-time system, we briefly explain its discretisation. Then, we
• compare Abram to the state-of-the-art in adversarially robust classificaton of the MNIST and
the CIFAR-10 datasets under various kinds of attacks.
This work is organised as follows. We introduce the (Bayesian) adversarial robustness problem in
Section 2 and the Abram method in Section 3. We analyse Abram in Sections 4 (large particle limit)
and 5 (longtime behaviour). We discuss different ways of employing Abram in practice in Section 6
and compare it to the state-of-the-art in adversarially robust learning in Section 7. We conclude in
Section 8.
22 Adversarial robustness and its Bayesian relaxation
In the following, we consider a supervised machine learning problem of the following form. We are
given a training dataset {(y 1,z 1),...,(y K,z K)} of pairs of features y 1,...,y
K
∈ Y := RdY and labels
z ,...,z ∈ Z. Moreover, we are given a parametric model of the form g : X×Y → Z, with X := Rd
1 K
denoting the parameter space. Goal is now to find a parameter θ∗, for which
g(y |θ∗) ≈ z (k = 1,...,K).
k k
In practice the function g(·|θ∗) shall then be used to predict labels of features (especially such outside
of training dataset).
The parameter θ∗ is usually found through optimisation. Let ℓ : Z×Z → R denote a loss function
– a function that gives a reasonable way of comparing the output of g with observed labels. Then, we
need to solve the following optimisation problem:
K
1 (cid:88)
min Φ(y ,z |θ) (2.1)
k k
θ∈XK
k=1
where Φ(y,z|θ) := ℓ(g(y|θ),z).
Machinelearningmodelsg thataretrainedinthisformareoftensusceptibletoadversarialattacks.
That means, for a given feature vector y, we can find a ‘small’ ξ ∈ Y for which g(y+ξ|θ∗) ̸= g(y|θ∗).
In this case, an adversary can change the model’s predicted label by a very slight alteration of the
input feature. Such a ξ can usually be found through optimisation on the input domain:
max Φ(y+ξ,z|θ),
ξ∈B(ε)
whereB(ε) = {ξ : ∥ξ∥ ≤ ε}denotestheε-ballcentredat0andε > 0denotesthesizeoftheadversarial
attack. Hence, the attacker tries to change the prediction of the model whilst altering the model input
only by a small value ≤ ε. Other kinds of attacks are possible, the attacker may, e.g., try to not only
change the predicted label to a some other label, but actually change it to a particular other label,
see, e.g., Kurakin et al. (2017b).
In adversarially robust training, we replace the optimisation problem (2.1) by the minmax opti-
misation problem below:
K
1 (cid:88)
min max Φ(y +ξ ,z |θ). (2.2)
k k k
θ∈X K ξ ∈B(ε)
k=1 k
Thus, we now train the network by minimising the loss also with respect to potential adversarial
attacks. Finding the accurate solutions to such minmax optimisation problems is difficult: there is
no underlying saddlepoint structure, e.g., Φ(y,z|θ) is neither convex in θ nor concave in y, X and
Y tend to be very high-dimensional spaces, and the number of datasets K may prevent the accurate
computation of gradients. However, good heuristics have been established throughout the last decade
– we have mentioned some of them in Section 1.
In this work, we aim to study a relaxed version of the minmax problem, which we refer to as the
Bayesian adversarial robustness problem. This problem is given by
K (cid:90)
min 1 (cid:88) Φ(y +ξ ,z |θ)πγ,ε(dξ |θ), (2.3)
θ∈X K k k k k k
k=1
3. =0:1 . =10 . =1000
5 20 20
2 100
0
:0 10 10 50
=
0 0 0
"
5 200
1 5
:0
100
=
" 0 0 0
500
4 1
:0 2
= 0.5 1
" 0 0 0
-0.5 0 0.5 -0.5 0 0.5 -0.5 0 0.5
9 9 9
Figure 2.1: Plots of the Lebesgue density of πγ,ε(·|θ ) for energy Φ(y + ξ,z |θ ) = (ξ − 0.1)2/2,
1 0 1 1 0
choosing parameters ε ∈ {0.025,0.1,0.4} and γ ∈ {0.1,10,1000}.
where the Bayesian adversarial distribution πγ,ε(·|θ) has (Lebesgue) density
k
exp(γΦ(y +ξ,z |θ))1[ξ ∈ B(ε)]
k k
ξ (cid:55)→ ,
(cid:82)
exp(γΦ(y +ξ′,z |θ))dξ′
B(ε) k k
where γ > 0 is an inverse temperature, ε > 0 still denotes the size of the adversarial attack, and 1[·]
denotes the indicator: 1[true] := 1 and 1[false] := 0. The distribution πγ,ε(·|θ) is concentrated on the
k
ε-ball, ε > 0 controls the range of the attack, γ > 0 controls its focus. We illustrate this behaviour
in Figure 2.1. Next, we comment on the mentioned relaxation and the Bayesian derivation of this
optimisation problem.
Relaxation. Under certain assumptions on Φ, one can show that
πγ,ε(·|θ) → Unif(argmax Φ(y +ξ,z |θ))
k ξ∈Y k k
weakly as γ → ∞, see Hwang (1980). Indeed, the Bayesian adversarial distribution converges to the
uniformdistributionovertheglobalmaximiserscomputedwithrespecttotheadversarialattack. This
limiting behaviour, that we can also see in Figure 2.1, forms the basis of simulated annealing methods
for global optimisation. Moreover, it implies that the optimisation problems (2.2) and (2.3) for γ = 0
are identical, since
K (cid:90) K (cid:90)
1 (cid:88) Φ(y +ξ ,z |θ)π0,ε(dξ |θ) = 1 (cid:88) Φ(y +ξ ,z |θ)Unif(argmax Φ(y +ξ,z |θ))(dξ )
K k k k k i K k k k ξ∈Y k k i
k=1 k=1
and since ξ ∼ Unif(argmax Φ(y +ξ,z |θ)) implies Φ(y +ξ ,z |θ) = max Φ(y +ξ,z |θ)
k ξ∈Y k k k k k ξ∈B(ε) k k
for k = 1,...,K. A strictly positive γ on the other hand leads to a relaxed problem circumventing
the minmax optimisation. Cipriani et al. (2024) have also discussed this relaxation of an adversarial
robustness problem in the context of a finite set of attacks, i.e. the ε-ball B(ε) is replaced by a finite
set.
4Bayesian. We can understand the kind of attack that is implicitly employed in (2.3) as a Bayesian
attack. We now briefly introduce the Bayesian learning problem to then explain its relation to this
adversarial attack. In Bayesian learning, we model θ as a random variable with a so-called prior
(distribution) π . The prior incorporates information about θ. In Bayesian learning, we now
prior
inform the prior about data {(y ,z ),...,(y ,z )} by conditioning θ on that data. Indeed, we train
1 1 K K
the model by finding the conditional distribution of θ given that g(z |θ) ≈ y (k = 1,...,K). In the
k k
Bayesian setting, we represent ‘≈’ by a noise assumption consistent with the loss function ℓ. This is
achieved by defining the so-called likelihood as exp(−Φ). The conditional distribution describing θ is
called posterior (distribution) π and can be obtained through Bayes’ theorem, which states that
post
(cid:16) (cid:17)
(cid:82) exp −1 (cid:80)K Φ(y ,z |θ) π (dθ)
A K k=1 k k prior
π (A) =
post (cid:82) exp(cid:16) −1 (cid:80)K Φ(y ,z |θ′)(cid:17) π (dθ′)
X K i=k k k prior
formeasurableA ⊆ X. Amodelpredictionwithrespecttofeaturez canthenbegivenbytheposterior
mean of the output g, which is
(cid:90)
g(z|θ)π (dθ)
post
The Bayesian attacker treats the attack ξ in exactly such a Bayesian way. They define a prior
k
distribution for the attack, which is the uniform distribution over the ε-ball:
(cid:90)
Unif(B(ε)) = 1[ξ ∈ ·]dξ .
k k
B(ε)
The adversarial likelihood is designed to essentially cancel out the likelihood in the Bayesian learning
problem, by defining a function that gives small mass to the learnt prediction and large mass to
anything that does not agree with the learnt prediction:
exp(γΦ(y +ξ ,z |θ)).
k k k
Whilst this is not a usual likelihood corresponding to a particular noise model, we could see this as a
special case of Bayesian forgetting (Fu et al., 2021). In Bayesian forgetting, we would try to remove
a single dataset from a posterior distribution by altering the distribution of the parameter θ. In this
case, we try to alter the knowledge we could have gained about the feature vector by altering that
feature vector to produce a different prediction.
3 Adversarial Bayesian Particle Sampler
We now derive a particle-based method that shall solve (2.3). To simplify the presentation in the
following, we assume that K = 1, i.e., there is only a single data set. The derivation for multiple
data sets is equivalent – computational implications given by multiple datasets will be discussed in
Section 6. We also ignore the dependence of Φ on particular datasets and note only the dependence
on parameter and attack. Indeed, we write (2.3) now as
(cid:90)
minF(θ) := Φ(ξ,θ)πγ,ε(dξ|θ).
θ∈X
To solve this minimisation problem, we study the gradient flow corresponding to the energy F, that is:
dζ = −∇ F(ζ )dt. The gradient flow is a continuous-time variant of the gradient descent algorithm.
t ζ t
5The gradient flow can be shown to converge to a minimiser of F in the longterm limit if F satisfies
certain regularity assumptions. The gradient of F has a rather simple expression:
(cid:82) Φ(ξ,θ)exp(γΦ(ξ′,θ))dξ′
B(ε)
∇ F(θ) = ∇
θ θ (cid:82) exp(γΦ(ξ′,θ))dξ′
B(ε)
(cid:82) ∇ Φ(ξ,θ)·exp(γΦ(ξ′,θ))+γ∇ Φ(ξ,θ)·Φ(ξ,θ)exp(γΦ(ξ′,θ))dξ′
B(ε) θ θ
=
(cid:82)
exp(γΦ(ξ′,θ))dξ′
B(ε)
(cid:16) (cid:17)(cid:16) (cid:17)
(cid:82) Φ(ξ,θ)exp(γΦ(ξ′,θ))dξ′ (cid:82) γ∇ Φ(ξ,θ)·exp(γΦ(ξ′,θ))dξ′
B(ε) ∥·∥≤ε θ
−
(cid:16)
(cid:82)
(cid:17)2
exp(γΦ(ξ′,θ))dξ′
B(ε)
(cid:90)
= ∇ Φ(ξ,θ)πγ,ε(dξ|θ)+γCov (Φ(·,θ),∇ Φ(·,θ)),
θ πγ,ε(·|θ) θ
where we assume that Φ is continuously differentiable, bounded below, and sufficient regularity to
be allowed here to switch gradients and integrals. As usual, we define the covariance of appropriate
functions f,g with respect to a probability distribution π, by
(cid:90) (cid:90) (cid:90)
Cov (f,g) := f(θ)g(θ)π(dθ)− f(θ′)π(dθ′) g(θ′′)π(dθ′′).
π
X X X
The structure of ∇ F is surprisingly simple, requiring only integrals of the target function and its
θ
gradient with respect to πγ,ε, but, e.g., not its normalising constant. In practice, it is usually not
possible to compute these integrals analytically or to even sample independently from πγ,ε(·|θ), which
would be necessary for a stochastic gradient descent approach. The latter approach first introduced
by Robbins and Monro (1951) allows the minimisation of expected values by replacing these expected
values by sample means; see also Jin et al. (2023) and Latz (2021) for continuous-time variants.
Instead, we use a particle system approach that has been studied for a different problem by Akyildiz
etal.(2023)andKuntzetal.(2023). Theunderlyingideaistoapproximateπγ,ε(·|θ)byanoverdamped
Langevin dynamics which is restricted to the ε-Ball B(ε) with reflecting boundary conditions:
√
dξ = γ∇ Φ(ξ ,θ)dt+ 2dW ,
t ξ t t
where (W ) denotes a standard Brownian motion on Y. Under weak assumptions on Φ, this
t t≥0
Langevin dynamics converges to the distribution πγ,ε(·|θ) as t → ∞. However, in practice, we are
not able to simulate the longterm behaviour of this dynamics for all fixed θ to produce samples
of πγ,ε(·|θ) as required for stochastic gradient descent. Instead, we run a number N of (seemingly
independent) Langevin dynamics (ξ1,N) ,...,(ξN,N) . We then obtain an approximate gradient
t t≥0 t t≥0
flow (θN) that uses the ensemble of particles (ξ1,N) ,...,(ξN,N) to approximate the expected
t t≥0 t t≥0 t t≥0
values in the gradient ∇ F and then feed (θN) back into the drift of the (ξ1,N) ,...,(ξN,N) .
θ t t≥0 t t≥0 t t≥0
Hence,wesimultaneouslyapproximatethegradientflow(ζ ) by(θ ) andtheBayesianadversarial
t t≥0 t t≥0
distribution (πγ,ε(·|θ )) by (ξ1,N) ,...,(ξN,N) . Overall, we obtain the dynamical system
t t≥0 t t≥0 t t≥0
N
dθ tN = − N1 (cid:88) ∇ θΦ(ξ tn,N,θ tN)dt−γC(cid:100)ov(ξ tN)dt
n=1
√
dξi,N = γ∇ Φ(ξi,N,θ )dt+ 2dWi (i = 1,...,N).
t ξ t t t
where(Wi) aremutuallyindependentBrownianmotionsonY fori = 1,...,N. Again,theLangevin
t t≥0
dynamics (ξ1,N) ,...,(ξN,N) are defined on the ball B(ε) with reflecting boundary conditions –
t t≥0 t t≥0
6we formalise this fact below. The empirical covariance is given by
N K K
C(cid:100)ov(ξ tN) = N1 (cid:88) Φ(ξ ti,N,θ t)∇ θΦ(ξ ti,N,θ t)− N1
2
(cid:88) Φ(ξ ti′,N,θ t) (cid:88) ∇ θΦ(ξ ti′′,N,θ t).
i=1 i′=1 i′′=1
We refer to the dynamical system (θN,ξ1,N,...,ξN,N) as Abram. We illustrate the dynamics of
t t t t≥0
Abram in Figure 3.1, where we consider a simple example.
Wehavemotivatedthisparticlesystemasanapproximationtotheunderlyinggradientflow(ζ ) .
t t≥0
As N → ∞, the dynamics (θN) does not necessarily convergence to the gradient flow (ζ ) , but
t t≥0 t t≥0
to a certain McKean–Vlasov Stochastic Differential Equation (SDE), see McKean (1966). We study
this convergence behaviour in the following, as well as the convergence of the McKean–Vlasov SDE
to the minimiser of F and, thus, justify Abram as a method for Bayesian adversarial learning. First,
we introduce the complete mathematical set-up and give required assumptions.
3.1 Mean-field limit
Inthefollowing,weareinterestedinthemeanfieldlimitofAbram,i.e.,weanalysethelimitof(θN)
t t≥0
as N → ∞. Thus, we can certainly assume for now that γ := 1 and ε ∈ (0,1) being fixed. We write
B := B(ε). Then, Abram (θN,ξ1,N,...,ξN,N) satisfies
t t t t≥0
(cid:90) t (cid:90) t
θN = θ − µN(∇ Φ(·,θN))ds− Cov (Φ(·,θN),∇ Φ(·,θN))ds
t 0 c θ s µN s θ s
c
0 0
(cid:90) t √ (cid:90) t
ξi,N = ξi + ∇ Φ(ξi,N,θN)ds+ 2Wi+ n(ξi,N)dli,N (i = 1,...,N). (3.1)
t 0 x s s t s s
0 0
Here, (W1) ,...,(WN) are independent Brownian motions on Y and the initial particle values
t t≥0 t t≥0
ξ1,...,ξN are independent and identically distributed. There and throughout the rest of this work,
0 0
we denote the expectation of some appropriate function f with respect to a probability measure π by
π(f) := (cid:82) f(θ)π(dθ). We use µN to denote the empirical distribution of the particles (ξ1,N,...,ξN,N)
X t t t
at time t ≥ 0. That is µN := 1 (cid:80)N δ(·−ξi,N), where δ(·−ξ) is the Dirac mass concentrated in
t N i=1 t
ξ ∈ B. This implies especially that we can write
N N N N
µN(f) = 1 (cid:88) f(ξi,N), Cov (f,g) = 1 (cid:88) f(ξi,Ng(ξi,N)− 1 (cid:88)(cid:88) f(ξi,N)g(ξj,N),
t N t µN t N t t N2 t t
i=1 i=1 i=1 j=1
for appropriate functions f and g. The particles are constrained in B by the last term in the equations
of the (ξ1,N,...,ξN,N) . Here, n(x) = −x/∥x∥ for x ∈ ∂B is the inner normal vector field and li,N’s
t t t≥0
areanon-decreasingfunctionswithli,N(0) = 0and(cid:82)t 1[ξi,N ∈/ ∂B(ε)]dli,N(s) = 0,seePilipenko(2014)
0 s
for details on reflecting boundary conditions in diffusion processes. Additionally, it is convenient to
define
(cid:104) (cid:105)
G(θ,ν) = ∇ ν(Φ(·,θ))+Var [Φ(·,θ)]/2 = ν(∇ Φ(·,θ))+Cov (Φ(·,θ),∇ Φ(·,θ)).
θ ν θ ν θ
for any probability measure ν on B and θ ∈ X.
We finish this background section by defining the limiting McKean–Vlasov SDE with reflection
(cid:90) t (cid:90) t
θ = θ − µ (∇ Φ(·,θ ))ds− Cov (Φ(·,θ ),∇ Φ(·,θ ))ds,
t 0 s θ s µs s θ s
0 0
(cid:90) t √ (cid:90) t
ξ = ξ + ∇ Φ(ξ ,θ )ds+ 2W + n(ξ )dl , (3.2)
t 0 x s s t s s
0 0
7Figure3.1: ExamplesoftheAbrammethodgivenΦ(ξ,θ) = 1(ξ+θ)2,ε = 1,anddifferentcombinations
2
of(γ,N) = (10,3)(topleft),(0.1,3)(topright),(10,50)(bottomleft),(0.1,50)(bottomright). Ineach
ofthefourquadrants,weshowthesimulatedpath(θN) (top),theparticlepaths(ξ1,N,...,ξN,N)
t t≥0 t t t≥0
(centre), andthepathofprobabilitydistributions(πγ,ε(·|θN)) (bottom)thatshallbeapproximated
t t≥0
by the particles. The larger γ leads to a concentration of πγ,ε at the boundary, whilst it is closer to
uniform if γ is small. More particles lead to a more stable path (θN) . A combination of large N
t t≥0
and γ leads to convergence to the minimiser θ = 0 of F.
∗
8with µ denoting the law of ξ at time t ≥ 0. Goal of this work is to show that the particle system
t t
(3.1) converges to this McKean-Vlasov SDEs as N → ∞ and to then show that the McKean-Vlasov
SDE can find the minimiser of F.
3.2 Assumptions
Wenowlistassumptionsthatweconsiderthroughoutthiswork. WestartwiththeLipschitzcontinuity
of ∇Φ and G.
Assumption 3.1 (Lipschitz) The function ∇ Φ is Lipschitz continuous, i.e. there exists a Lipschitz
ξ
constant L > 1 such that
(cid:13) (cid:13) (cid:16) (cid:13) (cid:13)(cid:17)
(cid:13)∇ Φ(x,θ˜)−∇ Φ(x˜,θ˜)(cid:13) ≤ L ∥x−x˜∥+(cid:13)θ−θ˜(cid:13)
(cid:13) x x (cid:13) (cid:13) (cid:13)
for any ξ,ξ˜∈ B and θ,θ˜∈ Rn. Similarly, we assume that G(θ,µ) is Lipschitz in the following sense:
there is an L > 1 such that
(cid:13) (cid:13) (cid:16)(cid:13) (cid:13) (cid:17)
(cid:13)G(θ,ν)−G(θ˜,ν˜)(cid:13) ≤ L (cid:13)θ−θ˜(cid:13)+W (ν,ν˜)
(cid:13) (cid:13) (cid:13) (cid:13) 1
for any probability measures ν, ν˜ on B and θ, θ˜∈ Rn.
In Assumption 3.1 and throughout this work, W denotes the Wasserstein-p distance given by
p
(cid:26)(cid:90) (cid:27)
Wp(ν,ν′) = inf (cid:13) (cid:13)y−y′(cid:13) (cid:13)p Γ(dy,dy′) : Γ is a coupling of ν,ν′ ,
p
X×X
for probability distributions ν,ν′ on (X,BX) and p ≥ 1. In addition to the Wasserstein distance,
we sometimes measure the distance between probability distributions ν,ν′ on (X,BX) using the total
variation distance given by
∥ν −ν′∥ = sup |ν(A)−ν′(A)|.
TV
A∈BX
The Lipschitz continuity of G actually already implies the Lipschitz continuity of ∇ Φ. By setting
θ
ν = δ(·−x) and ν˜ = δ(·−x˜), we have
(cid:13) (cid:13) (cid:13) (cid:13)
(cid:13)∇ Φ(x,θ˜)−∇ Φ(x˜,θ˜)(cid:13) = (cid:13)G(θ,δ(·−x))−G(θ˜,δ(·−x˜))(cid:13)
(cid:13) θ θ (cid:13) (cid:13) (cid:13)
(cid:16)(cid:13) (cid:13) (cid:17) (cid:16) (cid:13) (cid:13)(cid:17)
≤ L (cid:13)θ−θ˜(cid:13)+W (δ(·−x),δ(·−x˜)) = L ∥x−x˜∥+(cid:13)θ−θ˜(cid:13) .
(cid:13) (cid:13) 1 (cid:13) (cid:13)
We assume throughout that the constant L > 1 to simplify the constants in the Theorem 5.5. Finally,
we note that Assumption 3.1 implies the well-posedness of both (3.1) and (3.2), see Adams et al.
(2022, Theorems 3.1, 3.2).
Next, we assume the strong convexity of G, which, as we note below, also implies the strong
convexity of Φ(x,·) for any x ∈ B. This assumption is not realistic in the context of deep learning
(e.g., Choromanska et al. (2015)), but not unusual when analysing learning techniques.
Assumption 3.2 (Strong convexity) For any probability measure ν on (B,BB), G(·,ν) is 2λ-
strongly convex, i.e., for any θ,θ˜∈ Rn, we have
(cid:68) (cid:69) (cid:13) (cid:13)2
G(θ,ν)−G(θ˜,ν),θ−θ˜ ≥ 2λ(cid:13)θ−θ˜(cid:13) ,
(cid:13) (cid:13)
for some λ > 0.
9By choosing ν = δ(·−ξ) in Assumption 3.2 for ξ ∈ B, we have Cov (Φ(·,θ),∇ Φ(·,θ)) = 0, which
ν θ
implies that ⟨∇ Φ(x,θ)−∇ Φ(x,θ′),θ−θ′⟩ ≥ 2λ∥θ−θ′∥2. Thus, the 2λ-strong convexity of G in θ
θ θ
also implies the 2λ-strong convexity of Φ in θ.
The assumptions collected in this sections are fairly strong, they are satisfied in certain linear-
quadratic problems on bounded domains. We illustrate this in an example below.
Example 3.3 We consider a prototypical adversarial robustness problem based on the potential
Φ(ξ,θ) := ∥ξ−θ∥2 with θ in a bounded set X′ ⊆ X – problems of this form appear, e.g., in adversar-
ially robust linear regression. Next, we are going to verify that this problem satisfies Assumptions 3.1
and 3.2.
We have ∇ Φ(ξ,θ) = 2(ξ−θ), which is Lipschitz in both θ and ξ. Since
ξ
∇ Φ(ξ,θ) = 2(ξ−θ),
θ
(cid:90) (cid:90) (cid:90)
Φ(ξ,θ)− Φ(ξ,θ)ν(dξ) = (∥ξ∥2− ∥ξ∥2ν(dξ))−2θ·(ξ− ξν(dξ))
B B B
(cid:90) (cid:90)
∇ Φ(ξ,θ)− ∇ Φ(ξ,θ)ν(dξ) = −2(ξ− ξν(dξ)),
θ θ
B B
we have that
G(θ,ν) = 2θ−2E [ξ]+4θ·Var (ξ)−2Cov (∥ξ∥2,ξ),
ν ν ν
whereE [ξ] = (cid:82) ξν(dξ)andCov (∥ξ∥2,ξ) = (cid:82) (∥ξ∥2−E [∥ξ∥2])(ξ−E [ξ])ν(dξ). Sincetheε-balland
ν B ν B ν ν
θ ∈ X′ are bounded, we have that G(θ,ν) is Lipschitz in both θ and ν. Thus, it satisfies Assumption
3.1. In order to make G(θ,ν) satisfy Assumption 3.2, we choose ε small enough such that the term
4θ·Var (ξ) is 1-Lipschitz. In this case, we can verify that ⟨G(θ,ν)−G(θ′,ν),θ−θ′⟩ ≥ ∥θ−θ′∥2 and,
ν
thus, Assumption 3.2.
4 Propagation of chaos
We now study the large particle limit (N → ∞) of the Abram dynamics (3.1). When considering
a finite time interval [0,T], we see that the particle system (3.1) approximates the McKean-Vlasov
SDE (3.2) in this limit. We note that we assume in the following that 0 < ε < 1. Moreover,
we use the Wasserstein-2 distance instead of Wasserstein-1 distance in Assumption 3.1. We have
W (ν,ν′) ≤ W (ν,ν′) for any probability measures ν,ν′ for which the distances are finite, see Villani
1 2
(2009). Thus, convergence in W also implies convergence in W . We now state the main convergence
2 1
result.
Theorem 4.1 Let Assumption 3.1 hold. Then, there is a constant C > 0 such that for all T ≥ 0
d,T
and N ≥ 1 we have the following inequality
sup E(cid:2)(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 +W 22(µN
t
,µ t)(cid:3) ≤ C d,TN−α d,
t∈[0,T]
where α = 2/d for d > 4 and α = 1/2 for d ≤ 4.
d d
Hence, we obtain convergence of both the gradient flow approximation (θN) and the particle
t t≥0
approximation (µN) to the respective components in the McKean-Vlasov SDE. We prove this result
t
by a coupling method. To this end, we first collect a few auxiliary results: studying the large sample
10limit of an auxiliary particle system and the distance of the original particle system to the auxiliary
system. To this end, we sample N trajectories of (ξ ) from equations (3.2) as
t t≥0
(cid:90) t √ (cid:90) t
ξi = ξi + ∇ Φ(ξi,θ )ds+ 2Wi+ n(ξi)dli (i = 1,...,N), (4.1)
t 0 x s s t s s
0 0
where the Brownian motions (W1,...,WN) are the ones from (3.1). Of course these sample
t t t≥0
paths (ξ1,...,ξN) are different from the (ξ1,N,...,ξN,N) in equation (3.1): Here, (θ ) only
t t t≥0 t t t≥0 t t≥0
depends on the law of (ξ ) whereas (θN) depends on position of the particles (ξi,N) . As the
t t≥0 t t≥0 t t≥0
(ξ1) ,...,(ξN) are i.i.d., we can apply the empirical law of large numbers from Fournier and
t t≥0 t t≥0
Guillin (2015) and get the following result.
Proposition 4.2 Let Assumption 3.1 hold. Then,
N
(cid:104) (cid:16) (cid:88) (cid:17)(cid:105)
supE W2 N−1 δ ,µ ≤ C N−α d.
2 ξi t d
t≥0 t
i=1
For any i = 1,...,N, we are now computing bounds for the pairwise distances between ξi and ξi,N for
t t
t ≥ 0. We note again that these paths are pairwise coupled through the associated Brownian motions
(Wi) , respectively.
t t≥0
Lemma 4.3 Let Assumption 3.1 hold. Then,
(cid:13) (cid:13) (cid:13)ξ ti,N −ξ ti(cid:13) (cid:13) (cid:13)2 ≤ 2L(cid:90) t(cid:104)(cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)2 +(cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2(cid:105) ds (i = 1,...,N),
0
for t ∈ [0,T].
(cid:13) (cid:13)2
Proof. We apply Itˆo’s formula to (cid:13)ξi,N −ξi(cid:13) ,
(cid:13) t t(cid:13)
(cid:13) (cid:13)ξi,N −ξi(cid:13) (cid:13)2 = 2(cid:90) t (cid:10) ξi,N −ξi,∇ Φ(ξi,N,θN)−∇ Φ(ξi,θ )(cid:11) ds
(cid:13) t t(cid:13) s s x s s x s s
0
(cid:124) (cid:123)(cid:122) (cid:125)
(I1)
(cid:90) t (cid:90) t
+2 (cid:10) n(ξi,N),ξi,N −ξi(cid:11) dli,N −2 (cid:10) n(ξi),ξi,N −ξi(cid:11) dli .
s s s s s s s s
0 0
(cid:124) (cid:123)(cid:122) (cid:125)
(I2)
We first argue that (I2) ≤ 0. Recall that n(x) = −x/∥x∥ and that the processes (ξi,N) and (ξi)
t t≥0 t t≥0
take values in the ε-ball B with ε < 1. Then, we have
(cid:90) t (cid:90) t (cid:90) t
2 (cid:10) n(ξi,N),ξi,N −ξi(cid:11) dli,N = 2 (cid:10) n(ξi,N),ξi,N(cid:11) dli,N −2 (cid:10) n(ξi,N),ξi(cid:11) dli,N
s s s s s s s s s s
0 0 0
(cid:90) t (cid:90) t
= −2εli,N −2 (cid:10) n(ξi,N),ξi(cid:11) dli,N ≤ −2εli,N +2ε dli,N = 0.
t s s s t s
0 0
Similarly, we have
(cid:90) t (cid:90) t
−2 (cid:10) n(ξi),ξi,N −ξi(cid:11) dli = 2 (cid:10) n(ξi),ξi −ξi,N(cid:11) dli ≤ 0.
s s s s s s s s
0 0
11Hence, we have (I2) ≤ 0.
For (I1), due to Assumption 3.1 and, again, due to the boundedness of B, we have
(I1) ≤ L(cid:90) t (cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)(cid:104)(cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)+(cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)(cid:105) ds ≤ 2L(cid:90) t(cid:104)(cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)2 +(cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2(cid:105) ds.
0 0
(cid:50)
Finally, we study the distance between θN and θ for t ≥ 0.
t t
Lemma 4.4 Let Assumption 3.1 hold. Then, we have
(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 ≤ 3L(cid:90) t (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2 ds+ 2 NL (cid:88)N (cid:90) t (cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)2 ds+2L(cid:90) t W 22(N−1(cid:88)N δ
ξ
si,µ s)ds,
0 0 0
i=1 i=1
for t ∈ [0,T].
Proof. Due to Assumption 3.1 and since W (µN,µ ) ≤ W (µN,µ ), we have
1 s s 2 s s
(cid:90) t
(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 =−2 (cid:10) θ sN −θ s,G(θ sN,µN
s
)−G(θ s,µ s)(cid:11) ds
0
≤ 2L(cid:90) t (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)(cid:16)(cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)+W 2(µN
s
,µ s)(cid:17) ds
0
(cid:90) t (cid:90) t
≤ 2L (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2 ds+2L (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)W 2(µN
s
,µ s)ds
0 0
(cid:90) t (cid:90) t
≤ 3L (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2 ds+L W 22(µN
s
,µ s)ds. (4.2)
0 0
The triangle inequality implies that
N N
(cid:88) (cid:88)
W2(µN,µ ) ≤ 2W2(µN,N−1 δ )+2W2(N−1 δ ,µ )
2 s s 2 s ξi 2 ξi s
s s
i=1 i=1
N N
≤ N2 (cid:88)(cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)2 +2W 22(N−1(cid:88) δ
ξ
si,µ s). (4.3)
i=1 i=1
Combining (4.2) and (4.3), we obtain
(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 ≤ 3L(cid:90) t (cid:13) (cid:13)θ sN −θ s(cid:13) (cid:13)2 ds+ 2 NL (cid:88)N (cid:90) t (cid:13) (cid:13)ξ si,N −ξ si(cid:13) (cid:13)2 ds+2L(cid:90) t W 22(N−1(cid:88)N δ
ξ
si,µ s)ds.
0 0 0
i=1 i=1
(cid:50)
We now proceed to the proof of Theorem 4.1.
Proof of Theorem 4.1. We commence by constructing an upper bound for
N
uN
t
:= N−1(cid:88)(cid:13) (cid:13) (cid:13)ξ ti,N −ξ ti(cid:13) (cid:13) (cid:13)2 +(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 .
i=1
12From Lemma 4.3 and Lemma 4.4, we have
(cid:90) t (cid:90) t N
(cid:88)
uN ≤ 5L uNds+2L W2(N−1 δ ,µ )ds.
t s 2 ξi s
s
0 0
i=1
Gr¨onwall’s inequality implies that
(cid:90) t N
(cid:88)
uN ≤ 2Le5Lt W2(N−1 δ ,µ )ds.
t 2 ξi s
s
0
i=1
According to Proposition 4.2, we have
(cid:90) t N
(cid:88)
E[uN] ≤ 2Le5Lt E[W2(N−1 δ ,µ )]ds ≤ 2C Le(1+5L)tN−α d,
t 2 ξi s d
s
0
i=1
whereas (4.3) implies
N
(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 +W 22(µN
s
,µ s) ≤ uN
t
+2W 22(N−1(cid:88) δ ξi,µ s).
s
i=1
Therefore,
sup E(cid:2)(cid:13) (cid:13)θ tN −θ t(cid:13) (cid:13)2 +W 22(µN
t
,µ t)(cid:3) ≤ sup E[uN
t
]+ sup E(cid:2) W 22(µN
t
,µ t)(cid:3) ≤ C d,TN−α d,
t∈[0,T] t∈[0,T] t∈[0,T]
where C = 2C (1+Le(1+5L)t).
d,T d
(cid:50)
5 Longtime behaviour of the McKean-Vlasov process
Theorem 4.1 implies that the gradient flow approximation in Abram (θN) converges to the corre-
t t≥0
sponding part of the McKean–Vlasov SDE (θ ) given in (3.2). In this section, we show that this
t t≥0
McKean-Vlasov SDE is able to find the minimiser θ of F = (cid:82) Φ(ξ,·)πγ,ε(dξ|·). This, thus, gives us a
∗
justification to use Abram to solve the Bayesian adversarial robustness problem. We start by showing
that F admits a minimiser.
Proposition 5.1 Let Assumptions 3.1 and 3.2 hold. Then, F admits at least one minimiser in X.
Proof. We first argue that F is bounded below and obtains a minumum at some point θ . From
∗
Subsection 3.2, we already know that Φ(0,θ) is 2λ strongly convex in θ. Without loss of generality, we
assume Φ(0,0) = 0 and ∇ Φ(0,0) = 0, that is Φ(0,θ) reaches its minimum 0 at θ = 0. Since Φ(ξ,·)
θ ∗
is 2λ strongly convex for any ξ ∈ B, we have that
Φ(ξ,θ) ≥ Φ(ξ,0)+θ·∇ Φ(ξ,0)+λ∥θ∥2. (5.1)
θ
Assumption 3.1 implies that,
∥∇ Φ(ξ,0)∥ = ∥∇ Φ(ξ,0)−∇ Φ(0,0)∥ ≤ L∥ξ∥ ≤ L
θ θ θ
13and
|Φ(ξ,0)| = |Φ(ξ,0)−Φ(0,0)| ≤ sup∥∇ Φ(ζ,0)∥∥ξ∥ ≤ (L+C )∥ξ∥ ≤ L+C ,
ξ 0 0
ζ∈B
where C = ∥∇ Φ(0,0)∥. Therefore, we have Φ(ξ,θ) ≥ −L−C −L∥θ∥+λ∥θ∥2, which is bounded
0 ξ 0
below by −L − C −
L2
. Thus, F is bounded below by the same value. We can always choose
0 4λ
some R = R (L,λ,C ), such that for ∥θ∥ ≥ R , Φ(ξ,θ) ≥ C + L. Moreover, we already have
0 0 0 0 0
Φ(ξ,0) ≤ L+C . Thus, F(θ) ≥ C +L when ∥θ∥ ≥ R and F(0) ≤ C +L. Hence F attains its
0 0 0 0
minimum on the R -ball {θ ∈ X : ∥θ∥ ≤ R }. (cid:50)
0 0
Before stating the main theorem of this section – the convergence of the McKean-Vlasov SDE to the
minimiser of F – we need to introduce additional assumptions.
Assumption 5.2 (Neumann Boundary Condition) LetΦ(·,θ)satisfy aNeumann boundary con-
dition on ∂B,
∂ Φ(ξ,θ)
ξ
= ∇ Φ(ξ,θ)·n(ξ) = 0,
ξ
∂n
for any θ ∈ X.
For a general function Φ defined on B, this assumption can be satisfied by smoothly extending Φ on
B′ with radius 2ε such that it vanishes near the boundary of B′. We shall see that this assumption
guarantees the existence of the invariant measure of the auxiliary dynamical system (5.3) that we
introduce below.
Assumption 5.3 (Small-Lipschitz) For any probability measures ν, ν˜ on B and θ ∈ Rn,
∥G(θ,ν)−G(θ,ν˜)∥ ≤ ℓ∥ν −ν˜∥ ,
TV
√ √
where ℓ = ((δ∧λ √) λe−t0) ∧ (√λ ) and t
0
= t 0(δ,λ,C) = (δ ∧ λ)−1log(4C). The constants δ and C
4 2CL 2L
appear in Proposition 5.6.
Equivalently, we may say this assumption requires G to have a small enough Lipschitz constant. If
ε (the radius of B) is very small, this assumption is implied by Assumption 3.1, since W (ν,ν˜) ≤
1
εd(cid:82) (cid:82) 1 π(dx,dy) = εd∥ν −ν˜∥ .
B B x̸=y TV
We illustrate these assumptons again in the linear-quadratic problem that we considered in Ex-
ample 3.3 and show that Assumptions 5.2 and 5.3 can be satisfied in this case.
Example 5.4 (Example 3.3 continued) WeconsideragainΦ(ξ,θ) = ∥ξ−θ∥2 withθ inabounded
X′ ⊆ X. Unfortunately, Φ does not satisfy Assumption 5.2, since the term (ξ−θ)·ξ is not necessary
to be 0 on the boundary of B. Instead, we study a slightly larger ball by considering ε = 2ε instead
(cid:98)
of ε and also replace Φ by Φ(cid:98)(x,θ) = ∥m(ξ)−θ∥2, where m : Rd → Rd is smooth and equal to ξ on
the ε-ball and vanishes near the boundary of the 2ε-ball. Since m(x) varnishes near the boundary of
2ε-ball, Φ(cid:98) satisfies Assumption 5.2.
We note that ∇ ξΦ(cid:98)(ξ,θ) = 2D ξm(ξ)(m(ξ)−θ). Hence, ∇ ξΦ(cid:98) is Lipschitz in both θ and ξ which di-
rectlyfollowsfromtheboundednessandLipschitzcontinuityofm, D m. AnalogouslytoExample3.3,
ξ
we have
G(θ,ν) = 2θ−2E [m(ξ)]+4θ·Var (m(ξ))−2Cov (∥m(ξ)∥2,m(ξ))
ν ν ν
and also see that it still satisfies Assumptions 3.1, 3.2 when θ is bounded and ε is small. Finally,
Assumption 5.3 is satisfied if ε is chosen to be sufficiently small.
14We are now able to state the main convergence theorem of this section. Therein, we still consider
θ to be a minimizer of function of F.
∗
Theorem 5.5 Let Assumptions 3.1, 3.2, 5.2, and 5.3 hold and let (θ ,µ ) be the solution to the
t t t≥0
McKean-Vlasov SDE (3.2). Then, there are constants η > 0 and C˜ > 0 with which we have
(cid:16) (cid:17)
∥θ −θ ∥2+∥µ −πγ,ε(·|θ )∥2 ≤ C˜ ∥θ −θ ∥2+∥µ −πγ,ε(·|θ )∥2 e−ηt. (5.2)
t ∗ t ∗ TV 0 ∗ 0 ∗ TV
Wecanseethisresultasbothastatementabouttheconvergenceof(θN) totheminimiser, butalso
t t≥0
as an ergodicity statement about (θN,ξ ) . The ergodicity of a McKean-Vlasov SDE with reflection
t t t≥0
has also been subject of Theorem 3.1 in Wang (2023). In their work, the process is required to have
a non-degenerate diffusion term. Hence, their result does not apply immediately, since the marginal
(θ ) is deterministic (conditionally on (ξ ) ). Our proof ideas, however, are still influenced by
t t≥0 t t≥0
Wang (2023).
We note additionally that Theorem 5.5 implies the uniqueness of the minimiser θ – we had only
∗
shown existence in Proposition 5.1: If there exists another minimizer θ′, then the dynamics (3.2) is
∗
invariant at (θ ,ξ ) ∼ δ ⊗πγ,ε(·|θ′), which means (θ ,ξ ) ∼ δ ⊗πγ,ε(·|θ′) for all t ≥ 0. Hence, we
0 0 θ ∗′ ∗ t t θ ∗′ ∗
have ∥θ′ −θ ∥ ≤ C˜∥θ′ −θ ∥e−ηt. The right-hand side vanishes as t → ∞, which implies θ′ = θ .
∗ ∗ ∗ ∗ ∗ ∗
In order to prove Theorem 5.5, we first consider the case where θ ≡ θ , i.e.,
t ∗
(cid:90) t √ (cid:90) t
ξ(cid:98)t = ξ 0+ ∇ xΦ(ξ(cid:98)s,θ ∗)ds+ 2W t+ ν(ξ(cid:98)s)d(cid:98)l s. (5.3)
0 0
We denote the law of ξ(cid:98)t by µ (cid:98)t, t ≥ 0. Motivated by Wang (2023), we first show the exponential
ergodicity for the process (ξ(cid:98)t) t≥0.
Proposition 5.6 Let Assumptions 3.1 and 5.2 hold. Then, (ξ(cid:98)t)
t≥0
defined in (5.3) is well-posed
and admits an unique invariant measure πγ,ε(·|θ ∗). Moreover, (ξ(cid:98)t)
t≥0
is exponentially ergodic. In
particular, there exist C,δ > 0, such that
∥µ −πγ,ε(·|θ )∥2 ≤ C∥µ −πγ,ε(·|θ )∥2 e−δt.
(cid:98)t ∗ TV 0 ∗ TV
Proof. The well-posedness and exponential ergodicity is a direct corollary of Wang (2023, Theorem
2.3). We only need to verify that πγ,ε(·|θ ) is invariant under the dynamics (5.3). We know that the
∗
probability distributions (µ ) satisfies the following linear PDE with Neumann boundary condition
(cid:98)t t≥0
∂µ (cid:12)
∂ µ = ∆µ −div(µ ∇ Φ(ξ,θ )),
(cid:98)t(cid:12)
= 0.
t(cid:98)t (cid:98)t (cid:98)t ξ ∗ ∂n(cid:12)
∂B
So any invariant measure of the dynamics (5.3) is a probability distribution that solves the following
stationary PDE
∂µ(cid:12)
∆µ−div(µ∇ Φ(ξ,θ )) = 0, (cid:98)(cid:12) = 0.
(cid:98) (cid:98) ξ ∗ ∂n(cid:12)
∂B
Now, µ = πγ,ε(·|θ ) is a basic result in the theory of Langevin SDEs on with reflection, see, e.g., Sato
(cid:98) ∗
et al. (2024). (cid:50)
Most of the time, we are not able to quantify the constants C and δ: the Harris-like theorem
from Wang (2023) is not quantitative. A special case in which we can quantify C and δ is when
the potential separates in the sense that ∇ Φ(ξ,θ ) = (f (ξ ,θ ),...,f (ξ ,θ )). Then (5.3) can be
ξ ∗ 1 1 ∗ dY dY ∗
15viewed as d independent reflection SDEs. If we denote their ergodicity constants as C and δ for
Y i i
i = 1,...,d , then Jin et al. (2023, Proof of Proposition 1) implies that we can choose C :=
(cid:80)d
C
Y i=1 i
and δ := min δ .
i=1,...,d i
Next, we bound the distance ∥µ −µ ∥ by Girsanov’s theorem – a classical way to estimate the
t (cid:98)t TV
distance between two SDEs with different drift terms. This is again motivated by Wang (2023, proof
of Lemma 3.2). There, the method is used to bound the distance between two measure-dependent
SDEs. Inourcase,italsoinvolvesthestateθ , whichdependsont.Hence, theright-handsidedepends
t
on the path of (θ ) .
s 0≤s≤t
Lemma 5.7 Let Assumption 3.1 hold. Then, we have
(cid:90) t
∥µ −µ ∥2 ≤ L2 ∥θ −θ ∥2ds.
t (cid:98)t TV s ∗
0
Proof. We follow the same idea as Wang (2023, proof of Lemma 3.2). In our case, we need to choose
(cid:16)(cid:90) t 1 (cid:90) t (cid:17)
Z = exp z(θ ,θ ,ξ )·dW − ∥z(θ ,θ ,ξ )∥2ds ,
t ∗ s s s ∗ s s
2
0 0
√
where z(θ ,θ,x) = (∇ Φ(x,θ)−∇ Φ(x,θ ))/ 2. (Le Gall, 2013, Proposition 5.6) implies that the
∗ x x ∗
process (Z ) is a martingale due to z(θ ,θ ,ξ ) being bounded and (cid:82)t ∥z(θ ,θ ,ξ )∥2ds being the
t t≥0 ∗ s s 0 ∗ s s
(cid:82)t
quadratic variation process of z(θ ,θ ,ξ )·dW .
0 ∗ s s s
We define the probability measure Q := Z P, i.e. Q (A) := E[Z 1 ] for any F -measurable set A.
t t t t A t
(cid:82)t
And we notice that the quadratic covariation between z(θ ,θ ,ξ )·dW and W is given by
0 ∗ s s s t
(cid:28)(cid:90) . (cid:29) (cid:90) t
z(θ ,θ ,ξ )·dW ,W = z(θ ,θ ,ξ )ds.
∗ s s s . ∗ s s
0 t 0
Hence by Girsanov’s theorem (see (Le Gall, 2013, Theorem 5.8, Cons´equences (c))), W˜ := W −
t t
(cid:82)t z(θ ,θ ,ξ )ds is a Brownian motion under Q with the same filtration F .
0 ∗ s s t t
We rewrite (3.2) as
(cid:90) t √ (cid:90) t
ξ = ξ + ∇ Φ(ξ ,θ )ds+ 2W˜ + n(ξ )dl ,
t 0 x s ∗ t s s
0 0
which has the same distribution as ξ(cid:98)t under Q t. Hence
∥µ −µ ∥ = sup |E[f(ξ )]−E[f(ξ )Z ]| ≤ E[|Z −1|]
t (cid:98)t TV t t t t
|f|≤1
(cid:104)(cid:90) t 1 (cid:90) t (cid:105)1
≤2E[R tlog(R t)]1 2 = 2E Qt z(θ ∗,θ s,ξ s)·dW s−
2
∥z(θ ∗,θ s,ξ s)∥2ds 2
0 0
(cid:104)(cid:90) t 1 (cid:90) t (cid:105)1
=2E z(θ ,θ ,ξ )·dW˜ + ∥z(θ ,θ ,ξ )∥2ds 2
Qt ∗ s s s
2
∗ s s
0 0
√ (cid:104)(cid:90) t (cid:105)1 (cid:16)(cid:90) t (cid:17)1
= 2E ∥z(θ ,θ ,ξ )∥2ds 2 ≤ L ∥θ −θ ∥2ds 2
Qt ∗ s s s ∗
0 0
where the first “≤” is implied by Pinsker’s inequality. (cid:50)
Using these auxiliary results, we can now formulate the proof of Theorem 5.5.
16Proof of Theorem 5.5. We take the time derivative of ∥θ −θ ∥2,
t ∗
d∥θ −θ ∥2
t ∗ =−⟨G(θ ,µ )−G(θ ,πγ,ε(·|θ )),θ −θ ⟩
t t ∗ ∗ t ∗
dt
≤ −2λ∥θ −θ ∥2+ℓ∥θ −θ ∥∥µ −πγ,ε(·|θ )∥
t ∗ t ∗ t ∗ TV
ℓ2
≤ −λ∥θ −θ ∥2+ ∥µ −πγ,ε(·|θ )∥2 ,
t ∗ λ t ∗ TV
where the first “≤” is due to the ε-Young’s inequality. This implies
d(eλt∥θ −θ ∥2) ℓ2
t ∗ ≤ eλt∥µ −πγ,ε(·|θ )∥2 ,
dt λ t ∗ TV
Hence, we have
ℓ2 (cid:90) t
∥θ −θ ∥2 ≤ e−λt∥θ −θ ∥2+ ∥µ −πγ,ε(·|θ )∥2 ds. (5.4)
t ∗ 0 ∗ λ s ∗ TV
0
Then, using the triangle inequality, we see that
∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 ≤ ∥θ −θ ∥2+2m∥µ −µ ∥2 +2m∥µ −πγ,ε(·|θ )∥2
t ∗ t ∗ TV t ∗ t (cid:98)t TV (cid:98)t ∗ TV
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(5.4) Lemma5.7 Proposition5.6
(cid:90) t(cid:16)ℓ2 (cid:17)
≤ ∥µ −πγ,ε(·|θ )∥2 +2mL2∥θ −θ ∥2 ds
λ s ∗ TV s ∗
0
(cid:16) (cid:17)
+2C ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 e−(δ∧λ)t.
0 ∗ 0 ∗ TV
Let m = m(ℓ,L,λ) = √ℓ , we conclude from the above inequality that
L 2λ
(cid:90) t(cid:16) (cid:17)
∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 ≤ 2mL2 m∥µ −πγ,ε(·|θ )∥2 +∥θ −θ ∥2 ds
t ∗ t ∗ TV s ∗ TV s ∗
0
(cid:16) (cid:17)
+2C ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 e−(δ∧λ)t.
0 ∗ 0 ∗ TV
Hence, by Gr¨onwall’s inequality, we have
∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2
t ∗ t ∗ TV
(cid:16) (cid:17)(cid:16) (cid:90) t (cid:17)
≤ C ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 2mL2 e2mL2(t−s)e−(δ∧λ)sds+e−(δ∧λ)t
0 ∗ 0 ∗ TV
0
(cid:16) 2mL2 (cid:17)(cid:16) (cid:17)
= C (e2mL2t−e−(δ∧λ)t)+e−(δ∧λ)t ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2
2mL2+δ∧λ 0 ∗ 0 ∗ TV
(cid:16)2mL2 (cid:17)(cid:16) (cid:17)
≤ C e2mL2t+e−(δ∧λ)t ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2
δ∧λ 0 ∗ 0 ∗ TV
(cid:16) (cid:17)
≤ C ∥θ −θ ∥2+m∥µ −πγ,ε(·|θ )∥2 , (5.5)
t,L,ℓ,λ 0 ∗ 0 ∗ TV
(cid:16) (cid:17)
where C = C 2mL2 e2mL2t + e−(δ∧λ)t . According to Assumption 5.3, we know that 2mL2 =
t,L,ℓ,λ δ∧λ
√
ℓL √ λ2 ≤ 1. Next, we are going to show that 0 < C t0,L,ℓ,λ ≤ 1/2 for t 0 = t 0(δ,λ,C) = (δ∧λ)−1log(4C).
Again, from Assumption 5.3, we know 2mL2 et0 ≤ 1 . Hence we finally have,
δ∧λ 4C
2mL2 1
C ≤ C et0 +Ce−(δ∧λ)t0 ≤ .
t0,L,ℓ,λ
δ∧λ 2
17For any t ≥ 0, we always have [ t ]t ≤ t < [ t ]t +t , where [x] denotes the greatest integer ≤ x.
t0 0 t0 0 0
Hence,
∥θ t−θ ∗∥2+m∥µ t−πγ,ε(·|θ ∗)∥2
TV
≤ 2−[ tt 0](cid:16)(cid:13) (cid:13) (cid:13)θ
t−[ tt 0]t0
−θ ∗(cid:13) (cid:13) (cid:13)2 +m(cid:13) (cid:13) (cid:13)µ
t−[ tt 0]t0
−πγ,ε(·|θ ∗)(cid:13) (cid:13) (cid:13)2 TV(cid:17)
≤ 2− tt 0+1 sup (cid:16) ∥θ s−θ ∗∥2+m∥µ s−πγ,ε(·|θ ∗)∥2 TV(cid:17)
0≤s≤t0
≤ 2− tt 0+1 C(cid:16) δe ∧t0
λ
+1(cid:17)(cid:16) ∥θ 0−θ ∗∥2+m∥µ 0−πγ,ε(·|θ ∗)∥2 TV(cid:17) ,
where the last inequality is from (5.5) and C could be bounded by
C(et0
+1) for 0 ≤ s ≤ t .
s,L,ℓ,λ δ∧λ 0
And since m ≤ 1 < 1, we conclude that
2L2
∥θ t−θ ∗∥2+∥µ t−πγ,ε(·|θ ∗)∥2
TV
≤ m−12− tt 0+1 C(cid:16) δe ∧t0
λ
+1(cid:17)(cid:16) ∥θ 0−θ ∗∥2+∥µ 0−πγ,ε(·|θ ∗)∥2 TV(cid:17)
≤ 2L22− tt 0+1 C(cid:16) δe ∧t0
λ
+1(cid:17)(cid:16) ∥θ 0−θ ∗∥2+∥µ 0−πγ,ε(·|θ ∗)∥2 TV(cid:17) .
Finally, we choose the constants η = η(δ,λ,C) = log(2)t−1 = (δ ∧λ) log(2) and C˜ = C˜(L,C,δ,λ) =
0 log(4C)
4CL2(cid:16)
et0
+1(cid:17)
=
4CL2(cid:16) (4C)(δ∧λ)−1 +1(cid:17)
. (cid:50)
δ∧λ δ∧λ
6 Algorithmic considerations
Throughout this work, we have considered Abram as a continuous-time dynamical system. To employ
it for practical adversarially robust machine learning, this system needs to be discretised, i.e., we need
to employ a time stepping scheme to obtain a sequence (θN,ξ1,N,...,ξN,N)∞ that approximates
k k k k=1
Abram at discrete points in time. We now propose two discrete schemes for Abram, before then
discussing the simulation of Bayesian adversarial attacks.
Discrete Abram. We initialise the particles by sampling them from the uniform distribution
in the ε-ball. Then, we employ a projected Euler-Maruyama scheme to discretise the particles
(ξ1,N,...,ξN,N) . The Euler-Maruyama scheme (see, e.g., Higham and Kloeden 2021) is a standard
t t t≥0
technique for first order diffusion equations – we use a projected version to adhere to the reflecting
boundary condition inside the ball B. Projected Euler-Maruyama schemes of this form have been
studied in terms of almost sure convergence (Sl(cid:32)omin´ski, 1994) and, importantly, also in terms of their
longtime behaviour (Lamperski, 2021). The gradient flow part (θN) is discretised using a forward
t t≥0
Euler method – turning the gradient flow into a gradient descent algorithm (Nocedal and Wright,
1999). In applications, it is sometimes useful to allow multiple iterations of the particle dynam-
ics (ξ1,N,...,ξN,N) per iteration of the gradient flow (θN) . This corresponds to a linear time
t t t≥0 t t≥0
rescaling in the particle dynamics that should lead to a more accurate representation of the respective
adversarial distribution.
If the number of data sets (y ,z )K is large, we may be required to use a data subsampling
k k k=1
technique. Indeed, we approximate 1 (cid:80)K Φ(y ,z |θ) ≈ Φ(y ,z ) with a k′ ∼ Unif({1,...,K})
K k=1 k k k′ k′
being sampled independently in every iteration of the algorithm. This gives us a stochastic gradient
descent-type approximation of the gradients in the algorithm, see Robbins and Monro (1951). We
note that we have not analysed data subsampling within Abram – we expect that techniques from Jin
et al. (2023); Latz (2021) may be useful to do so. We summarise the method in Algorithm 1.
18Algorithm 1 Abram
1: initialise learning rate h, θ 0, γ, ε
2: for j = 1,2,...,J do
3: pick a data point (y j,z j) from training data
4: for i = 1,2,...,N do
5: initialise ξi = ξi if j > 1 else ξi ∼ Unif[−ε,ε]
0,j T,j−1 0,j
6: for τ = 1,2,...,T do √
7: ξ τi ,j ← Proj ∥·∥≤ε(ξ τi −1,j +h∇ ξΦ(y j +ξ τi −1,j,z j|θ j−1)+γ−1 2hw τi ,j) (w τi ,j ∼ N(0,Id) iid.)
8: end for
9: end for
10: µN ← 1 (cid:80)N δ(·−ξi )
j N i=1 T,j
11: C(cid:98)j ← Cov µN(Φ(y j +·,z j|θ j−1),∇ θΦ(y j +·,z j|θ j−1))
j
12: θ j ← θ j−1− Nh (cid:80)N i=1∇ θΦ(y j +ξ Ti ,j,z j|θ j−1)−γhC(cid:98)j
13: end for
14: return θ J
Discrete Abram with mini-batching. When subsampling in machine learning practice, it is
usually advisable to choose mini-batches of data points rather than single data points. Here, we pick
a mini-batch {y ,z } ⊆ {y ,z }K , with #K′ ≪ K and perform the gradient step with all
k′ k′ k′∈K′ k k k=1
elements with index in K′ rather than a single element in the whole data set {y ,z }K . Abram
k k k=1
would then require a set of N particles for each of the elements in the batch, i.e., NK′ particles in
total. In practice, N and K′ are both likely to be large, leading to Abram becoming computationally
infeasible. Based on an idea discussed in a different context in Hanu et al. (2023), we propose the
following method: in every time step j = 1,...,J we choose an identical number of particles (ξi )N
T,j i=1
and data sets (yi,zi)N in the mini-batch, i.e. #K′ = N. Then, we employ the Abram dynamics, but
j j i=1
equip each particle ξi with a different data point (yi,zi) (i = 1,...,N). As opposed to Abram with
T,j j j
separateparticlesperdatapoint, weherecomputethesamplingcovariancethroughoutallsubsampled
data points rather than separately for every data point. The resulting dynamics are then only close to
(3.1), ifweassumethattheadversarialattacksforeachdatapointarenottoodissimilarofeachother.
However, the dynamics may also be successful, if this is not the case. We summarise the resulting
method in Algorithm 2.
Bayesian attacks. ThemechanismusedtoapproximatetheBayesianadversaryinAlgorithm1can
naturally be used as a Bayesian attack. We propose two different attacks:
1. We use the projected Euler-Maruyama method to sample from the Bayesian adversarial distri-
bution πγ,ε corresponding to an input data set y ∈ Y and model parameter θ∗. We summarise
this attack in Algorithm 3.
2. Instead of attacking with a sample from πγ,ε, we can attack with the mean of said distribution.
From Proposition 5.6, we know that the particle system (ξ(cid:98)t)
t≥0
that is based on a fixed param-
eter θ ∗, is exponentially ergodic. Thus, we approximate the mean of πγ,ε, by sampling (ξ(cid:98)t)
t≥0
using projected Euler-Maruyama and approximate the mean by computing the sample mean
throughout the sampling path. We summarise this method in Algorithm 4.
19Algorithm 2 Mini-batching Abram
1: initialize learning rate h, θ 0, γ, ε
2: for j = 1,2,...,J do
3: for i = 1,2,...,N do
4: initialize ξi ← ξi if j > 1 else ξi ∼ Unif[−ε,ε] iid.
0,j T,j−1 0,j
5: pick N data points (y ji,z ji)N
i=1
from the training data (y k,z k)K
k=1
6: for τ = 1,2,...,T do √
7: ξ τi
,j
← Proj ∥·∥≤ε(ξ τi −1,j+h∇ ξΦ(y ji+ξ τi −1,j,z ji|θ j−1)+γ−1 2hw τi ,j) (w τi
,j
∼ N(0,Id) iid.)
8: end for
9: end for
10: µN ← 1 (cid:80)N δ(·−(yi +ξi ))
j N i=1 j T,j
11: C(cid:98)j ← Cov µN(Φ(·,z j|θ j−1),∇ θΦ(·,z j|θ j−1))
j
12: θ j ← θ j−1− Nh (cid:80)N i=1∇ θΦ(y ji +ξ Ti ,j,z j|θ j−1)−γhC(cid:98)j
13: end for
14: return θ J
Algorithm 3 Bayesian sample attack
Require: unperturbed input data set y
1: initialise h, γ, ε, ξ 0 ∼ Unif[−ε,ε]
2: for j = 1,2,...,J do √
3: ξ j ← Proj ∥·∥≤ε(ξ j−1+h∇ ξΦ(x+ξ j−1,θ)+γ−1 2hw j) (w j ∼ N(0,Id))
4: end for
5: return adversarially perturbed input data point y+ξ J
Algorithm 4 Bayesian mean attack
Require: unperturbed input data point y
1: initialise h, γ, ε, ξ 0 ∼ Unif[−ε,ε]
2: for j = 1,2,...,J do √
3: ξ j ← Proj ∥·∥≤ε(ξ j−1+h∇ ξΦ(x+ξ j−1,θ)+γ−1 2hw j) (w j ∼ N(0,Id))
4: end for
5: return adversarially perturbed input data point y+ J1 (cid:80)J j=1ξ j
207 Deep learning experiments
We now study the application of the Bayesian Adversary in deep learning. The model parameter θ
is updated for J steps with batch size/number of particles N. For each particle in the ensemble, the
perturbation parameter ξ is updated for T steps.
7.1 MNIST
We test Algorithm 1 and Algorithm 2 on the classification benchmark data set MNIST (LeCun and
Cortes, 2005) against different adversarial attacks and compare the results with the results after an
FGSM-based (Wong et al., 2020) adversarial training. Each experimental run is conducted on a
single Nvidia A6000 GPU. We utilize the Adversarial Robustness Toolbox (ART) for the experiments,
see Nicolae et al. (2018) for more details. ART is a Python library for adversarial robustness that
provides various APIs for defence and attack. We use a neural network with two convolution layers
each followed by a max pooling. In Algorithm 1, we set γ = 1,h = ε,ε = 0.2. In Algorithm 2,
we set γ = 1,h = 10ε,ε = 0.2. We observe that setting larger noise scale for the attack during
training helps Abram’s final evaluation performance. We train the neural network for 30 epochs (i.e.,
30 full iterations through the data set) for each method. The number of particles (and batch size) is
N = 128 and the inner loop is trained for T = 10 times. To better understand how Abram responds
to different attacks, we test against six attack methods: PGD (Madry et al., 2018), Auto-PGD (Croce
and Hein, 2020), Carlini and Wagner (Carlini and Wagner, 2017b), Wasserstein Attack (Wong et al.,
2019), as well as the Bayesian attacks introduced in this paper – see Algorithms 3 and 4. We also
test the method’s accuracy in the case of benign (non-attacked) input data. For the Bayesian sample
attack and Bayesian mean attack, we set γ = 1000. See Table 7.1 for the comparison. The results
are averaged over three random seeds. We observe that Abram performs similarly to FGSM under
Wasserstein, Bayesian sample, and Bayesian mean attack. FGSM outperforms Abram under Auto-
PGD, PGD, and Carlini & Wagner attack. We conclude that Abram is as effective as FGSM under
certain weaker attacks, but can usually not outperform the conventional FGSM.
Adversarial Attack (ε = 0.1) Abram Mini-batching Abram FGSM
Benign Test 92.41±0.05 99.28±0.04 99.44±0.05
Auto-PGD 78.18±0.20 95.86±0.18 98.84±0.05
PGD 78.24±0.17 95.86±0.17 98.85±0.04
Wasserstein Attack 86.27±0.12 96.51±0.13 96.97±0.04
Carlini & Wagner Attack 8.76±0.015 5.14±0.1 62.60±0.02
Bayesian sample attack 92.43±0.10 99.29±0.03 99.44±0.06
Bayesian mean attack 92.42±0.08 99.28±0.04 99.44±0.05
Table 7.1: Comparison of test accuracy (%) on MNIST with different adversarial attack after Abram, mini-
batching Abram, and FGSM (Wong et al., 2020) adversarial training.
Another observation is that mini-batching Abram outperforms Abram significantly. Recall that
in Abram we used 128 particles for each data point which can be viewed as SGD with batch size 1,
whereas the mini-batching Abram is similar to the mini-batching SGD. Mini-batching Abram has the
freedom to set the batch size which helps to reduce the variance in the stochastic optimisation and,
thus, gives more stable results. In particular, with mini-batching Abram, gradients are approximated
21by multiple data points instead of one data point which is the case in Abram. Having a larger batch
size also increases computation efficiency by doing matrix multiplication on GPUs, which is important
in modern machine learning applications as the datasets can be expected to be large.
7.2 CIFAR10
Similarly, we test Algorithm 2 on the classification benchmark dataset CIFAR10 (Krizhevsky, 2009)
by utilising ART. The dataset is pre-processed by random crop and random horizontal flip following
Krizhevsky (2009) for data augmentation. The neural network uses the Pre-act ResNet-18 (He et al.,
2016) architecture. For Abram, we set γ = 1,h = ε,ε = 16/255. Similar as in MNIST experiments,
practically we find that setting larger noise scale for attack in training Abram helps to obtain a better
final evaluation performance. The batch size N = 128 and the inner loop is simulated for T = 10
times. Wetrainbothmini-batchingAbramandFGSMfor30epochs. Duetoitsworseperformancefor
MNIST and the large size of CIFAR10, we have not used the non-mini-batching version of Abram in
this second problem. For the Bayesian sample attack and the Bayesian mean attack, we set γ = 0.001.
We present the results in Table 7.2. There, we observe that mini-batching Abram outperforms FGSM
under Wasserstein and the Bayesian attacks, but not in any of the other cases.
Adversarial Attack (ε = 8/255) Mini-batching Abram FGSM
Benign Test 65.35±0.05 55.61±0.03
Auto-PGD 11.15±0.12 43.70±0.06
PGD 11.22±0.09 43.65±0.04
Wasserstein Attack 58.04±0.15 55.30±0.03
Carlini & Wagner Attack 19.01±0.12 62.60±0.02
Bayesian sample attack 62.52±0.03 55.83±0.05
Bayesian mean attack 63.72±0.06 55.81±0.05
Table 7.2: Comparison of test accuracy (%) on CIFAR10 with different adversarial attack after mini-batching
Abram and FGSM (Wong et al., 2020) adversarial training.
8 Conclusions
We have introduced the Bayesian adversarial robustness problem. This problem can be interpreted as
either a relaxation of the usual minmax problem in adversarial learning or as learning methodology
that is able to counter Bayesian adversarial attacks. To solve the Bayesian adversarial robustness
problem, we introduce Abram – the Adversarially Bayesian Particle Sampler. We prove that Abram
approximates a McKean-Vlasov SDE and that this McKean-Vlasov SDE is able to find the minimiser
of certain (simple) Bayesian adversarial robustness problems. Thus, at least for a certain class of
problems, we give a mathematical justification for the use of Abram. We propose two ways to dis-
cretise Abram: a direct Euler-Maruyama discretisation of the Abram dynamics and an alternative
method that is more suitable when training with respect to large data sets. We apply Abram in two
deep learning problems. There we see that Abram can effectively prevent certain adversarial attacks
(especially Bayesian attacks), but is overall not as strong as classical optimisation-based heuristics.
22References
D. Adams, G. dos Reis, R. Ravaille, W. Salkeld, and J. Tugaut. Large deviations and exit-times
for reflected McKean–Vlasov equations with self-stabilising terms and superlinear drifts. Stochastic
Processes and their Applications, 146:264–310, 2022.
O¨. D. Akyildiz, F. R. Crucinio, M. Girolami, T. Johnston, and S. Sabanis. Interacting particle
Langevin algorithm for maximum marginal likelihood estimation, 2023. URL https://arxiv.org/
abs/2303.13429.
M. R. Bachute and J. M. Subhedar. Autonomous driving architectures: Insights of machine learning
and deep learning algorithms. Machine Learning with Applications, 6:100164, 2021. ISSN 2666-
8270. doi: https://doi.org/10.1016/j.mlwa.2021.100164. URL https://www.sciencedirect.com/
science/article/pii/S2666827021000827.
N. Carlini and D. Wagner. Adversarial examples are not easily detected: Bypassing ten detec-
tion methods. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security,
AISec ’17, page 3–14, New York, NY, USA, 2017a. Association for Computing Machinery. ISBN
9781450352024.
N. Carlini and D. Wagner. Towards evaluating the robustness of neural networks. In 2017 IEEE
Symposium on Security and Privacy (SP), pages 39–57, Los Alamitos, CA, USA, 2017b. IEEE
Computer Society.
A.Choromanska,M.Henaff,M.Mathieu,G.BenArous,andY.LeCun. Thelosssurfacesofmultilayer
networks. In Proceedings of the Eighteenth International Conference on Artificial Intelligence and
Statistics, volume 38 of Proceedings of Machine Learning Research, pages 192–204, San Diego,
California, USA, 09–12 May 2015. PMLR.
C. Cipriani, A. Scagliotti, and T. W¨ohrer. A minimax optimal control approach for robust neural
odes, 2024. URL https://arxiv.org/abs/2310.17584.
F. Croce and M. Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse
parameter-free attacks. In Proceedings of the 37th International Conference on Machine Learning,
volume 119 of Proceedings of Machine Learning Research, pages 2206–2216. PMLR, 13–18 Jul 2020.
Y. Dong, F. Liao, T. Pang, H. Su, J. Zhu, X. Hu, and J. Li. Boosting adversarial attacks with
momentum. In2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
pages 9185–9193, Los Alamitos, CA, USA, 2018. IEEE Computer Society.
N. Fournier and A. Guillin. On the rate of convergence in Wasserstein distance of the empirical
measure. Probab. Theory Relat. Fields, 162:707–738, 2015.
S. Fu, F. He, Y. Xu, and D. Tao. Bayesian inference forgetting. CoRR, abs/2101.06417, 2021. URL
https://arxiv.org/abs/2101.06417.
A. Ghiasi, A. Shafahi, and T. Goldstein. Breaking certified defenses: Semantic adversarial examples
withspoofedrobustnesscertificates. InInternational Conference on Learning Representations,2020.
I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples, 2015.
URL https://arxiv.org/abs/1412.6572.
23S. Gowal, K. Dvijotham, R. Stanforth, R. Bunel, C. Qin, J. Uesato, R. Arandjelovic, T. A. Mann, and
P. Kohli. Scalable verified training for provably robust image classification. In 2019 IEEE/CVF
International Conference on Computer Vision (ICCV), pages 4841–4850, 2019.
C. Guo, M. Rana, M. Cisse, and L. van der Maaten. Countering adversarial images using input
transformations. In International Conference on Learning Representations, 2018.
M. Hanu, J. Latz, and C. Schillings. Subsampling in ensemble kalman inversion. Inverse Prob-
lems, 39(9):094002, 2023. doi: 10.1088/1361-6420/ace64b. URL https://dx.doi.org/10.1088/
1361-6420/ace64b.
K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. In Computer
Vision – ECCV 2016, pages 630–645. Springer International Publishing, 2016.
D. Higham and P. Kloeden. An introduction to the numerical simulation of stochastic differential
equations. SIAM, 2021.
C.-R. Hwang. Laplace’s method revisited: Weak convergence of probability measures. The Annals
of Probability, 8(6):1177–1182, 1980. ISSN 00911798, 2168894X. URL http://www.jstor.org/
stable/2243019.
J. Jia, W. Qu, and N. Z. Gong. Multiguard: Provably robust multi-label classification against adver-
sarial examples. In Advances in Neural Information Processing Systems, 2022.
K. Jin, J. Latz, C. Liu, and C.-B. Sch¨onlieb. A continuous-time stochastic gradient descent method
for continuous data. Journal of Machine Learning Research, 24(274):1–48, 2023.
A. Krizhevsky. Learning multiple layers of features from tiny images. In
https://www.cs.toronto.edu/ kriz/learning-features-2009-TR.pdf, 2009.
J. Kuntz, J. N. Lim, and A. M. Johansen. Particle algorithms for maximum likelihood training of
latentvariablemodels. InProceedingsofThe26thInternationalConferenceonArtificialIntelligence
and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 5134–5180. PMLR,
25–27 Apr 2023.
A. Kurakin, I. Goodfellow, and S. Bengio. Adversarial examples in the physical world, 2017a.
A. Kurakin, I. J. Goodfellow, and S. Bengio. Adversarial machine learning at scale. In Interna-
tional Conference on Learning Representations, 2017b. URL https://openreview.net/forum?
id=BJm4T4Kgx.
A. Lamperski. Projected stochastic gradient Langevin algorithms for constrained sampling and non-
convex learning. In M. Belkin and S. Kpotufe, editors, Proceedings of Thirty Fourth Conference
on Learning Theory, volume 134 of Proceedings of Machine Learning Research, pages 2891–2937.
PMLR, 15–19 Aug 2021. URL https://proceedings.mlr.press/v134/lamperski21a.html.
J. Latz. Analysis of stochastic gradient descent in continuous time. Statistics and Computing, 31:39,
2021. doi: https://doi.org/10.1007/s11222-021-10016-8.
J.-F. Le Gall. Mouvement Brownien, martingales et calcul stochastique. Springer, 2013.
Y. LeCun and C. Cortes. The MNIST database of handwritten digits. In
http://yann.lecun.com/exdb/mnist, 2005.
24J. Liu, A. Levine, C. Lau, R. Chellappa, and S. Feizi. Segment and complete: Defending object
detectors against adversarial patch attacks with robust patch detection. In 2022 IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition (CVPR), pages 14953–14962, Los Alamitos,
CA, USA, 2022. IEEE Computer Society.
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant
to adversarial attacks. In International Conference on Learning Representations, 2018.
P. Maini, E. Wong, and Z. Kolter. Adversarial robustness against the union of multiple perturbation
models. In H. D. III and A. Singh, editors, Proceedings of the 37th International Conference on
Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 6640–6650.
PMLR, 13–18 Jul 2020.
H.P.McKean. AclassofMarkovprocessesassociatedwithnonlinearparabolicequations. Proceedings
of the National Academy of Sciences, 56(6):1907–1911, 1966. doi: 10.1073/pnas.56.6.1907. URL
https://www.pnas.org/doi/abs/10.1073/pnas.56.6.1907.
J. H. Metzen, T. Genewein, V. Fischer, and B. Bischoff. On detecting adversarial perturbations. In
International Conference on Learning Representations, 2017.
M. Mosbach, M. Andriushchenko, T. Trost, M. Hein, and D. Klakow. Logit pairing methods can fool
gradient-based attacks, 2019. URL https://arxiv.org/abs/1810.12042.
M.-I. Nicolae, M. Sinn, M. N. Tran, B. Buesser, A. Rawat, M. Wistuba, V. Zantedeschi, N. Baracaldo,
B. Chen, H. Ludwig, I. Molloy, and B. Edwards. Adversarial robustness toolbox v1.2.0. CoRR,
1807.01069, 2018.
W. Nie, B. Guo, Y. Huang, C. Xiao, A. Vahdat, and A. Anandkumar. Diffusion models for adversarial
purification. In Proceedings of the 39th International Conference on Machine Learning, volume 162
of Proceedings of Machine Learning Research, pages 16805–16827. PMLR, 17–23 Jul 2022.
J. Nocedal and S. J. Wright. Numerical optimization. Springer, 1999.
A. Pilipenko. An introduction to stochastic differential equations with reflection. Lectures in Pure and
Applied Mathematics. Universit¨at Potsdam, 2014.
A. Rajkomar, J. Dean, and I. Kohane. Machine learning in medicine. New England Journal of
Medicine, 380(14):1347–1358, 2019. doi: 10.1056/NEJMra1814259. URL https://www.nejm.org/
doi/full/10.1056/NEJMra1814259.
H.RobbinsandS.Monro. Astochasticapproximationmethod. The Annals of Mathematical Statistics,
22(3):400–407, 1951.
K. Sato, A. Takeda, R. Kawai, and T. Suzuki. Convergence error analysis of reflected gradient
Langevin dynamics for non-convex constrained optimization, 2024. URL https://arxiv.org/
abs/2203.10215.
S. Sharma, M. Bhatt, and P. Sharma. Face recognition system using machine learning algorithm.
In 2020 5th International Conference on Communication and Electronics Systems (ICCES), pages
1162–1168, 2020. doi: 10.1109/ICCES48766.2020.9137850.
F. Sheikholeslami, A. Lotfi, and J. Z. Kolter. Provably robust classification of adversarial examples
with detection. In International Conference on Learning Representations, 2021.
25Y.Song, T.Kim, S.Nowozin, S.Ermon, andN.Kushman. Pixeldefend: Leveraginggenerativemodels
to understand and defend against adversarial examples. In International Conference on Learning
Representations, 2018.
C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing
properties of neural networks, 2014. URL https://arxiv.org/abs/1312.6199.
L. Sl(cid:32)omin´ski. On approximation of solutions of multidimensional SDE’s with reflecting bound-
ary conditions. Stochastic Processes and their Applications, 50(2):197–219, 1994. ISSN 0304-
4149. doi: https://doi.org/10.1016/0304-4149(94)90118-X. URL https://www.sciencedirect.
com/science/article/pii/030441499490118X.
F. Tramer and D. Boneh. Adversarial training and robustness for multiple perturbations. In Advances
in Neural Information Processing Systems, volume 32, 2019.
F.Tram`er, A.Kurakin, N.Papernot, I.Goodfellow, D.Boneh, andP.McDaniel. Ensembleadversarial
training: Attacks and defenses. In International Conference on Learning Representations, 2018.
C. Villani. Optimal transport: Old and new. Springer, 2009.
F.-Y.Wang. ExponentialergodicityforsingularreflectingMcKean–VlasovSDEs. Stochastic Processes
and their Applications, 160:265–293, 2023.
Z. Wang, T. Pang, C. Du, M. Lin, W. Liu, and S. Yan. Better diffusion models further improve
adversarial training. In Proceedings of the 40th International Conference on Machine Learning,
volume 202 of Proceedings of Machine Learning Research, pages 36246–36263. PMLR, 23–29 Jul
2023.
E.WongandZ.Kolter. Provabledefensesagainstadversarialexamplesviatheconvexouteradversarial
polytope. In Proceedings of the 35th International Conference on Machine Learning, volume 80 of
Proceedings of Machine Learning Research, pages 5286–5295. PMLR, 10–15 Jul 2018.
E. Wong, F. Schmidt, and Z. Kolter. Wasserstein adversarial examples via projected Sinkhorn it-
erations. In Proceedings of the 36th International Conference on Machine Learning, volume 97 of
Proceedings of Machine Learning Research, pages 6808–6817. PMLR, 09–15 Jun 2019.
E. Wong, L. Rice, and J. Z. Kolter. Fast is better than free: Revisiting adversarial training. In
International Conference on Learning Representations, 2020.
K. Xu, Y. Xiao, Z. Zheng, K. Cai, and R. Nevatia. Patchzero: Defending against adversarial patch
attacks by detecting and zeroing the patch. In 2023 IEEE/CVF Winter Conference on Applications
of Computer Vision (WACV), pages 4621–4630, Los Alamitos, CA, USA, 2023. IEEE Computer
Society.
W. Xu, D. Evans, and Y. Qi. Feature squeezing: Detecting adversarial examples in deep neural
networks. In Network and Distributed System Security Symposium, 2018.
H. Xue, A. Araujo, B. Hu, and Y. Chen. Diffusion-based adversarial sample generation for improved
stealthiness and controllability. In Advances in Neural Information Processing Systems, volume 36,
pages 2894–2921. Curran Associates, Inc., 2023.
Y. Yang, G. Zhang, D. Katabi, and Z. Xu. ME-net: Towards effective adversarial robustness with
matrix estimation. In Proceedings of the 36th International Conference on Machine Learning, vol-
ume 97 of Proceedings of Machine Learning Research, pages 7025–7034. PMLR, 09–15 Jun 2019.
26N.YeandZ.Zhu. Bayesianadversariallearning. InS.Bengio,H.Wallach,H.Larochelle,K.Grauman,
N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems,
volume31.CurranAssociates, Inc., 2018. URLhttps://proceedings.neurips.cc/paper_files/
paper/2018/file/586f9b4035e5997f77635b13cc04984c-Paper.pdf.
S.Yun, D.Han, S.Chun, S.Oh, Y.Yoo, andJ.Choe. Cutmix: Regularizationstrategytotrainstrong
classifiers with localizable features. In 2019 IEEE/CVF International Conference on Computer
Vision (ICCV), pages 6022–6031, Los Alamitos, CA, USA, 2019. IEEE Computer Society.
Competing interests: The authors declare none.
27