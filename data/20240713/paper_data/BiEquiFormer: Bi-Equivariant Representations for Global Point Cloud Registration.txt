BiEquiFormer: Bi-Equivariant Representations for
Global Point Cloud Registration
StefanosPertigkiozoglou∗ EvangelosChatzipantazis∗ KostasDaniilidis
UniversityofPennsylvania UniversityofPennsylvania UniversityofPennsylvania
pstefano@seas.upenn.edu vaghat@seas.upenn.edu Archimedes,AthenaRC
kostas@cis.upenn.edu
Abstract
Thegoalofthispaperistoaddresstheproblemofglobalpointcloudregistration
(PCR)i.e.,findingtheoptimalalignmentbetweenpointcloudsirrespectiveofthe
initialposesofthescans. Thisproblemisnotoriouslychallengingforclassical
optimizationmethodsduetocomputationalconstraints. First,weshowthatstate-
of-the-artdeeplearningmethodssufferfromhugeperformancedegradationwhen
thepointcloudsarearbitrarilyplacedinspace. Weproposethatequivariantdeep
learningshouldbeutilizedforsolvingthistaskandwecharacterizethespecifictype
ofbi-equivarianceofPCR.Then,wedesignBiEquiformeranovelandscalablebi-
equivariantpipelinei.e. equivarianttotheindependenttransformationsoftheinput
pointclouds. Whileanaiveapproachwouldprocessthepointcloudsindependently
wedesignexpressivebi-equivariantlayersthatfusetheinformationfrombothpoint
clouds. Thisallowsustoextracthigh-qualitysuperpointcorrespondencesandin
turn,robustpoint-cloudregistration. Extensivecomparisonsagainststate-of-the-art
methodsshowthatourmethodachievescomparableperformanceinthecanonical
settingandsuperiorperformanceintherobustsettinginboththe3DMatchandthe
challenginglow-overlap3DLoMatchdataset.
1 Introduction
PointCloudRegistration(PCR)isatthefrontendofmanyroboticsandvisionpipelines. Thegoal,
inthepairwiseandrigidsetting,istoaligntwopartiallyoverlappedpointcloudsexpressedintheir
owncoordinatesystembyestimatingaroto-translationbetweenthemandfusingtheminacommon
coordinatesystem. Ithasbeensuccessfullyappliedinmanytaskssuchas3DSceneReconstruction
BlaisandLevine[1995],SLAM[Nüchteretal.,2006]andposeestimationYangetal.[2013].
While PCR has been studied extensively over the past decades, the desiderata for real-time and
robustregistrationofreal-worldapplicationsmakestheproblemextremelychallenging. Especiallyin
environmentswithrepetitivepatternssuchasindoorenvironmentsaswellasinlow-overlapsettings
that appear loop closure tasks Bosse and Zlot [2008] the requirement for distinctive point-wise
featuresforcorrespondenceisenhanced. Aparticularlychallengingaspectoftheproblemisthe
robustnessw.r.t. theinitialposesofthepointclouds. Inclassicaloptimizationmethods,theproblem
iscalledglobalPCRandisfamouslyintractableduetothelargevolumeofpointsYangetal.[2013].
DeeplearninghasbeenprovenveryeffectiveinPCRinallbuildingblocksoftheregistrationpipeline.
PowerfulpointcloudarchitecturesQietal.[2016],Thomasetal.[2019]servebothasthefeature
extractionforcorrespondence-basedmethodsZengetal.[2017],Choyetal.[2019]andawayto
identifydistinctivefeaturesformatchingHuangetal.[2020],LiandHarada[2022]. Ithasalsobeen
utilizedtolearnrobustestimatorsChoyetal.[2020],Paisetal.[2019],Baietal.[2021]ordirectly
∗EqualContribution
Preprint.Underreview.
4202
luJ
11
]VC.sc[
1v92780.7042:viXraFigure1: InlierRatios(IR)andRegistrationMetrics(RRE,RTE,RMSE)fortwopairsoflow-overlap
scansthatdifferonlybytheirrelativepose. (Left)BothGeoTransformer(astate-of-the-artmethod)
and BiEquiformer recover the correct registration and high IR. (Right): GeoTransformer fails to
findgoodmatches(lowIR)inthisrelativeposeandpredictsanincorrectregistration. Incontrast,
BiEquiformerisdesignedtoperformconsistentlyirrespectiveoftheinitialpointcloudposes.
regresstherelativetransformation[WangandSolomon,2019,Aokietal.,2019]. However,aswe
shownext,theproblemofglobalPCRisnotcorrectlycharacterizedandstillremainsunsolved.
Inthiswork,weshowhowrecentstate-of-the-artregistrationpipelinesareheavilyaffectedbythe
orientationsoftheinitialscans,especiallyinchallenginglow-overlapsettings(Fig. 3). Subsequently,
weproposeBiEquiformeradetector-freeattentionpipelinethatisbi-equivarianttotheroto-translation
group(Fig.2). Ourmaincontributionscanbesummarizedasfollows:
1. ThestateofGlobalPCRinDL:Weinvestigatetherobustnessofstate-of-the-artmethods
underrigidtransformationsoftheinputpointclouds. InFig. 3weshowthatinnumerous
popular state-of-the-art methods there is a deterioration in performance when the initial
posesofthepointcloudsvary,exacerbatedastheoverlapbetweenscansbecomessmaller.
AvisualexamplecanbeseeninFigure1andisdiscussedindetailinSection5.1.
2. Bi-EquivarianceandPCR:Weformulateandcharacterizethespecificbi-equivariance
propertiesofPCR(Section3). Thenweproposenovellayersthatprocessinvariant,equivari-
ant,anddifferenttypesofbi-equivariantfeatures,whichextendstandardequivariantlayers
byfusinginformationbetweenthepointclouds(Section4).
3. State-of-the-art in Global PCR: Combining those layers we propose a novel, scalable
equivariantpipelineforpointcloudregistration. Ourmethodensuresconsistentregistration
results,regardlessoftheinitialconfigurationoftheinputpointclouds,andachievesstate-of-
the-artregistrationaccuracyintherobustsetting,especiallyinlow-overlapdatasets.
2 RelatedWork
Pointcloudregistration(PCR)isafundamentalproblemwithextensiveliterature. Herewefocuson
relatedworkonrigidgeometricPCRi.e.,thepointcloudscanbealignedwitharoto-translation,and
onlydepthisprovidedwithoutanyotherexteriorinformationsuchascolor,etc.
ClassicMethods;ICPandGlobalRegistration. Overthepreviousdecades,variousmethodshave
beenproposed. Extensivesurveys[Pomerleauetal.,2015,Bellekensetal.,2015,Lietal.,2021]
categorizeandbenchmarkclassicalalgorithmsormainbuildingblocksofthosee.g.,thelocalfeature
extractionbackboneGuoetal.[2015]ortherobustestimatorsBabinetal.[2018]. Stemmingfrom
thepioneeringpapersthatintroducedtheIterativeClosestPoint(ICP)algorithmChenandMedioni
[1991],BeslandMcKay[1992],anumberofvariantshavebeenproposedPomerleauetal.[2015].
Thenon-convexityofPCRwithunknowncorrespondencesmakesICPsusceptibletolocaloptima
andusually,arelativelyaccurateinitialregistrationhastobeprovided. Thisinitiatedtheproblem
ofGlobalPCRwheremethodstreatPCRasaglobaloptimizationproblem[LiandHartley,2007,
Yangetal.,2013]andsolveitusingBranchandBoundormorerecently,graduatednon-convexity
[Yangetal.,2021,ZhijianQiaoandShen,2023]. Itiscommontousesuchmethodsonlyasaninitial
estimateforregistrationthatissubsequentlyrefinedbyICP.Thesemethodsusuallyruninexponential
2timethusfacingscalabilityissuesinscene-levelscans. Ourgoalinthispaperistodesignaglobal
PCRmethodthatisscalableandrobusteveninlow-overlappingsettings.
Local3DFeatureDescriptors: Extractingdescriptorsfromthepointcloudstocharacterizethe
local geometry is a common building block of most registration pipelines. Earlier works extract
hand-designed features in the form of histograms Rusu et al. [2008] that encode the 3D spatial
distributionofpointsJohnsonandHebert[1999],theorientationsoftheneighborsSaltietal.[2014],
Makadiaetal.[2006]orthedifferenceswiththeneighborsintheDarbouxframeRusuetal.[2009].
Morerecently,deeplearningarchitecturesonpointclouds[Wangetal.,2019,Qietal.,2016,2017,
Thomasetal.,2019,Choyetal.,2019]hasbeenutilizedforend-to-endfeatureextractioneitherby
usingMLPstocompactifyhand-designedfeaturesGojcicetal.[2018],3Dconvolutionalnetworks
Zengetal.[2017],Choyetal.[2019]toencodelocalvolumetricpatchesorutilizingTransformers
Vaswanietal.[2017]toencodebothglobalandlocalcontextwithinandbetweenthepointclouds
Huangetal.[2021],Qinetal.[2022]. Whilehand-designeddescriptorshavetheadvantageofbeing
data-agnostic,theyaresusceptibletonoiseandocclusions.
Correspondence-BasedPCR:Correspondence-basedmethodsutilizethelocaldescriptorsinorder
tomatchpointsorsurfacesbetweenthepointscloudsbeforeestimatingthetransformation. Theyare
splitbetweenkeypoint-basedmethods,thatexplicitlysearchforasmallsubsetofdistinctivefeatures
toperformthematching,ordetector-freemethodsthatperformadensematchingofpointsaccounting
fortheoutlierstoo. Intheformercategory,inthedeeplearningliteraturethepioneeringworkof
3DMatchZengetal.[2017]wasfollowedbymanyworksthatlearntomatchthelearnedkeypoints
[YewandLee,2018,Choyetal.,2019,Sarodeetal.,2019,Dengetal.,2018b,Gojcicetal.,2019,
Baietal.,2020,Wangetal.,2022,Lietal.,2020]. PredatorHuangetal.[2021]proposedthatnot
onlysaliencybutproximitytotheoverlapregionshouldbeconsideredinthekeypointdetectionand
proposedanovelself-attention/cross-attentionpipelinetolearnthat. Morerecently,keypoint-free
deeplearningmethodshavebeenintroducedthatperformmatchinginacoarse-to-finefashionYuetal.
[2021],Minetal.[2021],Yangetal.[2022]andhaveshownincreasedperformanceandrobustness
inlowoverlapsettingsLiandHarada[2022],Qietal.[2016].
EquivariantRegistration: AsasteptowardsglobalPCR,equivariantdeeplearningcanbeutilized.
Currently,theissueoffull3Droto-translationinvarianceisnotalwaystreatedproperlybyend-to-
endlearneddescriptors. Mostofthedeeplearningregistrationpipelinesarenotequivarianttothe
pointcloudposesthusrequiringagreatamountofdataaugmentationsQinetal.[2022]whilestill
behavinginconsistentlyduringinference(Fig. 3). Inthiscategory,PPFNetDengetal.[2018b,a]
isakeypoint-basedmethodthatintroduceshand-designedrotation-invariantpointfeaturesaslocal
descriptors. YOHOWangetal.[2022]utilizesafeatureextractorequivarianttotheicosahedralgroup
whileSpinNetAoetal.[2021]usesacylindricalconvolutiontoextractplanarequivariantfeatures.
GeoTransformerQinetal.[2022]takesastepforwardbyencodingposeinvariantfeaturesinthe
superpointtransformer. However,thefeaturebackboneisnotrotation-equivariant. Powerfulrotation
equivariant networks that operate on point clouds have been proposed Chen et al. [2021], Deng
etal.[2021],Wuetal.[2023]. Theyhavebeensuccessfullyutilizedin3DShapeReconstruction
Chatzipantazisetal.[2023],Chenetal.[2022],SegmentationDengetal.[2023],Protein-Docking
Ganeaetal.[2021],RoboticManipulationRyuetal.[2023,2024],Huangetal.[2024]etc. Building
onthatsuccessfulusageofequivariantdeeplearningweproposeadetector-free,transformer-based
registrationpipelinethatisbi-equivarianttotheindependentroto-translationsofboththesourceand
referencepointclouds.
3 ProblemFormulationandCharacterizationofEquivariantProperties
Considertwoobservers,thereferenceandthesource,eachwithdistinctcoordinateframesr and
srespectively, samplingpointsintheirrespectiveframesXr = {x ∈ R3|i = 1,...,N}, Ys =
i
{y ∈R3|j =1,...,M}.LetSE(3)denotethegroupofroto-translationsandSO(3)itssubgroupof
j
rotations. TheobjectiveofpointcloudregistrationistofindtherigidtransformationTr ∈SE(3)that
s
alignsthecoordinateframestorusingonlythesampledpointsXr,Ys.Oncetherelativerotationand
translationparametersRr ∈SO(3),Tr ∈R3thatconstituteTr,areestimatedwecantransformYs
s s s
tothereferencecoordinateframeandgetYr :=TrYs :=RrYs+Tr ={Rry+Tr ∈R3|y ∈Ys}.
s s s s s
ThistransformationallowsthemergingofthetwoobservationsthroughtheunionXr∪Yr.
Tosolvethisproblemweassumethatthereexistsanoverlappingareaofthesurfacesampledby
bothobservers. Then,wecanreducePCRintoasimultaneouscorrespondenceandposeestimation
problem. Specifically, we assume that there exists a subset X ⊆ Xr such that for every point
o
x ∈ X there exists a corresponding y ∈ Yr := RrYs + Tr such that ∥x − y ∥ ≤ ϵ
m o m s s m m
3Fine Features X
Equivariant Features X Coarse
X SeE lq f-u Aiv tta er nia tn iot n CroEq ssu -i Av ta tr eia nn tit on Similarity 𝑅𝑅1,𝑇𝑇1,𝑀𝑀1
Invariant Features X
Frame Alignment
𝑅𝑅2,𝑇𝑇L2G,𝑀𝑀R2
Invariant Features Y
Equivariant Equivariant
Self-Attention Cross-Attention
Y Equivariant Features Y
Estimated
Fine Features Y Global Step Local Step
×𝑁𝑁
𝑅𝑅𝑘𝑘,𝑇𝑇𝑘𝑘,𝑀𝑀𝑘𝑘 Tran 𝑅𝑅sfo ,rm 𝑇𝑇ation
Shared Equivariant Bi-Equivariant
Backbone Feature 𝑇𝑇
𝑅𝑅
𝑅𝑅
Figure2:BiEquiFormerisanattention-basedbi-equivariantpipelineforglobalPCR.First,equivariant
intra-pointself-attentionandinter-pointcross-attentionlayersupdatethescalarandvectorfeatures
onthepoints. Thenabi-equivariantfeatureisusedtoaligntheinputvectorstothesameframebefore
applyingequivariantcross-attention. Theoutputinvariantcoarsefeaturesareusedtoextractasetof
candidatecoarsematcheswhichareprocessedbyafinepointmatchingmoduletoextractacandidate
transformation. Afinalestimateiscomputedusingalocal-to-globaltransformationscheme. Afterthe
firsttransformationisestimated(GlobalStep)wecanapplyBiEquiFormeriterativelybyswitching
thebi-equivariantframealignmentblockwiththecurrentrotationestimation(LocalStep).
for a small ϵ. We refer to the points x ∈ X and their corresponding points y ∈ Ys as point
i o i
matches. The goal is first to estimate these point matches. Given a set of such matching pairs
C = {(x ,y )|x ∈ Xr,y ∈ Ys}, we can estimate the relative transformation by solving the
i i i i
Procrustesoptimizationproblem: min (cid:80) ∥Ry +T −x ∥2.
(R,T)∈SE(3) (xi,yi)∈C i i 2
CharacterizationofEquivariantPropertiesofPCR:Todescribethegeometricpropertiesofthe
problem formally we need the notion of equivariance first. Given a group G acting on two sets
S ,S viatheactions∗,· : G×S → S (inourcasesthosesetswilleitherbevectorspacesora
i o
sub-groupofG)amapf :S →S isequivariantw.r.t. thegroupactionsifforallg ∈G,s∈S :
i o i
f(g∗s)=g·f(s). Forclarity,wesuppress∗,·andsimplywritegsforthegroupactionofGonS.
TheaboveformulationofPCRimpliesthefollowingpropertiesfortheestimatedtransformations.
SE(3)Bi-Equivariance: Thetransformationshouldremainconsistentunder(proper)rigidtransfor-
mationsofeitherXr orYs. Formally,wedefineafunctionf :S →S tobeSE(3)-bi-equivariant
i o
(extendstoanygroupG)ifitisequivariantw.r.t. thejointgroupactionofthedirectproductgroup
SE(3)×SE(3)definedass(cid:55)→g sg−1. DependingonwhethersbelongstothedomainS orthe
1 2 i
co-domainS off wedefinethreecasesthatwewillusenext. Forall(g ,g )∈SE(3)×SE(3):
o 1 2
Outputbi-equivariance,f :S ×S →S . ∀(s ,s )∈S ×S ,f(g s ,g s )=g f(s ,s )g−1.
1 2 3 1 2 1 2 1 1 2 2 1 1 2 2
Inputbi-equivariance:f :S →S ×S ,f(s )=(s ,s ).∀s ∈S ,f(g s g−1)=(g s ,g s ).
1 2 3 1 2 3 1 1 1 1 2 1 2 2 3
Input/Outputbi-equivariance: f :S →S withf(g s g−1)=g f(s )g−1,∀s ∈S .
1 2 1 1 2 1 1 2 1 1
Asdiscussed,PCRcanbedefinedasamapR3×N ×R3×M → SE(3)withPCR(Xr,Ys) = Tr.
s
Wecanrigorouslyprovethefollowingpropositionsusingourdefinitions(allproofsintheAppendix).
Proposition 3.1. PCR is output SE(3)-bi-equivariant. i.e. for all (T ,T ) ∈ SE(3)×SE(3):
1 2
PCR(T Xr,T Ys)=T TrT−1.
1 2 1 s 2
Reference-SourceInterchangeability: Theestimatedalignmentshouldremainconsistentifwe
swaptherolesofthereferenceandsourcepointcloud.
Proposition3.2. PCRisequivarianttotheorderingofthearguments.I.e.C ={e,f}isthegroupof
2
flipswithetheidentityandf actingas:f(Xr,Ys)=(Ys,Xr)then:PCR(f(Xr,Ys))=(Tr)−1.
s
Proposition3.3. (PermutationEquivariance)PCRisinvarianttotheorderingofthepoints. I.e. if
S isthegroupofpermutationsofN points: PCR(S Xr,S Ys)=Tr.
N N M s
4 Method
4.1 BuildingBi-equivariantfeaturemaps
WhiletheliteratureisabundantwithmethodsthatbuildSE(3)-equivariantrepresentationsthereis
alackinthedesignofcompactandexpressivebi-equivariantfeaturemapsi.e. featuremapsthat
transform with the joint action of SE(3)×SE(3) as described in the previous section. This is
particularlyimportantinourproblemsincevanillaequivariantfeaturesdonotfusetheinformation
4
eniF
esraoC
esraoC
eniF
noitnettA-ssorC
gnihctaM
tnioP
eniFofbothpointcloudsthustheycreateimpoverishedrepresentationsformatching. Whilethegeneral
theoryfromCohenetal.[2019]canbeadaptedtofindconvolutionallayers,suchlayershaveahuge
memoryoverheadanddonotscaletoscene-levelscans. Closertoourwork,bothGaneaetal.[2021]
andQinetal.[2022]parametrizeonlytheinvariantchannelswhentheyfusethefeaturesofthepoint
cloudsviacross-attention. However,usefulvectorfeaturesthatcanbelearnedonthepointssuchas
thenormalsofthesurfacecannotberepresentedthisway.
Wepresentsomeelementaryoperationsonthefeaturemapsthatpreservebi-equivarianceineachof
thethreecasesabove. Inthenextsection,weutilizetheseoperationstobuildexpressiveparametric
layersforglobalPCR.Wenotethatelementaryequivariantoperationssuchastheinnerproductor
thenormofthedifference,heavilyusedinequivariantliterature,arenotbi-equivariant.
Proposition4.1.
1. Iff ,f ∈ R3 arevectorfeaturesi.e. theytransformwiththestandardrepresentationof
1 2
SO(3)thenthetensorproductf ,f (cid:55)→f fT isanSO(3)output-bi-equivariantmap.
1 2 1 2
2. Given a matrix F ∈ R3×3 that transforms with the joint action of SO(3)×SO(3) i.e.,
F (cid:55)→ R FRT themap: F (cid:55)→ (Uσ(Σ),Vσ′(Σ))isanSO(3) input-bi-equivariantmap,
1 2
whereU,Σ,V istheuniqueSVDdecompositionofF andσ,σ′arepointwisenon-linearities
ontheeigenvalues.
3. GiventhesamematrixF ̸=0asabove,themapF (cid:55)→σ(∥F∥) F isSO(3)input-output
∥F∥
bi-equivariant,where∥·∥isamatrixnorme.g. operator,Frobenius,tracenormetc.
Observation: ItiseasytoverifythatwecanconstructanSO(3)-equivariantmapviathecomposition
(iBEq◦(◦ ioBEqK)◦oBEq)(X,Y)whereiBEq,oBEq,ioBEqK areSO(3)-input,output,and
K
input-outputbi-equivariantmapsrespectively. However,incontrasttostandardequivariantlayers,
thiscompositionfusesinformationfrombothinputsX,Y. Thisobservationiscrucialforourdesign.
ArchitectureOverview: Wefollowacoarse-to-fineapproachsimilartoQinetal.[2022]. Thecoarse
superpointmatchingstageestimatescandidatepairsofmatchingpointcloudpatches(superpoints).
Giventhese,thefinepointmatchingstageestimatesR,T fortheneighborhoodofeachcandidate
pair. Lastly,alocal-to-globalregistrationscheme(Appendix7.3),isusedtoevaluateeachcandidate
transformation and select the highest-scoring one. Additionally, we propose that after the first
estimatedtransformation(GlobalStep)anoptionalLocalRefinementStepcanbeused,usingonly
equivariantlayers. Toensurebi-equivarianceallpartsofthepipelinemustrespecttheconstraint. We
utilizeVNNDengetal.[2021]asthefeatureextractor. InAppendix7.1wedescribeanadaptationof
VNNsothatitprocessesbothinvariantf andequivariantf featurevectorsanddescribehowwe
s v
getthecoarseX ,Y andfinepointsX ,Y .
S S D D
4.2 InvariantandEquivariantAttentionLayers
Intra-PointSelfAttention:AssumewearegivenapointcloudXalongwithitsper-pointequivariant
andinvariantfeaturesf (x ),f (x ). Weproposeanequivariantintra-pointself-attentionlayerthat
s i v i
canprocessbothinvariantandequivariantfeatures.Thislayerisanextensionoftheinvariantattention
layerusedinQinetal.[2022]thatislimitedtouseonlyinvariantinputs. Specifically,wedefinethe
invariantandequivariantintra-pointself-attentionlayersasfollows:
(cid:88) (cid:88)
αintra(x ,f ,f )= s W f (x ), αintra(x ,f ,f )= s VN (f (x ))
s i s v ij v s j v i s v ij V v j
xj∈X xj∈X
(cid:80)
whereVN isalearnedVectorNeuronslinearlayerands =exp(e )/ exp(e )where
V ij ij x′∈X ij′
j
e istheattentionscorematrixdefinedas:
ij
e =(f (x )W )(f (x )W +r W )T +w f (x )Tf (x )wT
ij s i Q s j K ij R q v i v j k
withr beingtheinvariantrelativegeometricembeddingbetweenx ,x introducedinQinetal.
ij i j
[2022],W ,W beinglearnedweightmatricesandw ,w beinglearnedweightvectors. Inthe
Q K q k
AppendixProp. 7.2weprovetheinvarianceofαintraandequivarianceofαintra.
s v
EquivariantCross-AttentionLayer: Theintra-pointself-attentionallowstheexchangeofinfor-
mationbetweenpointsofthesamepointcloud. Applyingasimilarmechanismforaninter-point
cross-attentionisnottrivialwhenwewanttousetheequivariantfeatures. Thatisbecausethetwo
pointcloudscanrotateindependently,andthusinordertocombinethesefeaturesweneedawayto
alignthem. Weproposetodosuchanalignmentbyusingabi-equivariantfeatureextractedfrom
5a point pair that consists of a point transforming according to frame r and a point transforming
accordingtoframes. Withthisalignment,wecandefineanequivariantcross-attentionlayerthat
allowstheexchangeofinformationbetweentheequivariantfeaturesofthetwopointclouds.
First,todefinethepointpairweassumeasoftassignmentS ={s
∈[0,1]|(cid:80)|Y|
s =1,0<
XY ij j=1 ij
i≤|X|}betweenthepointcloudsX andY e.g. comingfromtheattentionscoress ofasimple
ij
cross-attentionlayerthatusesonlytheinvariantfeaturesofthepointclouds. Thenforallx ∈X we
i
(cid:80)
computethepairs(x ,y )wherewedefiney = s y withfeatures:
i pi pi j∈|Y| ij j
(cid:88) (cid:88)
f (y )= s f (y ) f (y )= s f (y )
v pi ij v j s pi ij s j
j∈|Y| j∈|Y|
We compute the output bi-equivariant function b : R3×C ×R3×C → R3×3×C that takes the
tensorproductofthetwoinputsforeachchannelindependentlyandpassitthroughaninput-output
bi-equivariantnonlinearityϕwhichinourcaseis:
F
b(f (x ),f (y ))=ϕ(f (x )⊗f (y )), ϕ(F)=LayerN(∥F∥)
v i v pi v i v pi ∥F∥
where⊗isthechannel-wisetensorproduct,LayerNistheLayerNormBaetal.[2016]and∥.∥ :
R3×3×C →RC computestheFrobeniusnormforeach3×3matrix.
Finallytoaligntheequivariantfeaturesf (y )sothattheyrotateaccordingtoarotationofframer
v pi
wedefinethealignmentlayeraas:
a(f (x ),f (y ))=b(f (x ),f (y ))f (y ) (1)
v i v pi v i v pi v pi
Proposition4.2. Thealignmentlayerisequivarianttotherotationsofitsfirstinputandinvariantto
therotationsofitssecondinput: a(R f (x ),R f (y ))=R a(f (x ),f (y ))
x v i y v pi x v i v pi
Giventhesetofpairs(x ,y )wecandefinetheequivariantcross-attentionlayerwherethequery
i pi
featuresarethefeaturesofpointsinx ∈X,andthekey,valuefeaturesarethefeaturesofpointsy
i pi
aftertheyhavebeenalignedappropriatelysothattheyrotateaccordingtoframer.
Inmoredetailwedefinethescoreattentionmatrixepairas:
XY
epair(ij)=(f (x )W )(f (y )W )T +w f (x )Ta(f (x ),f (y ))wT
XY s i Q s pj K q v i v i v pj k
ThenassumingthatF ,F aresetsofinvariantandequivariantfeaturesofpointsinX,Y respectively,
X Y
wecandefinethepairattentionas:
(cid:88) (cid:88)
αpair(x ,F ,F )= spair(ij)W f (y ),αpair(x ,F ,F )= spair(ij)(VN (a(x ,y )))
s i X Y XY v s pj v i X Y XY V j pj
xj∈X xj∈X
withspair(ij)beingthesoftmaxoftheattentionscoresepair(ij). InProp. 7.3weprovethatαpairis
XY XY s
invarianttotheroto-translationofbothpointcloudsX,Y. αpairisequivarianttotheroto-translation
v
ofX andinvarianttotheroto-translationofY.
Herewehavedefinedtheattentionlayerforpairsoftheform(x ,y ),butsimilarlywecandefine
i pi
thesymmetriclayerforpairsoftheform(y ,x )thatisequivarianttotherotationofpointcloud
i pi
Y. Theuseofpairsallowsustodoasinglealignmentoftheequivariantfeaturesforthekeysand
valuesinthecrossattentionbycomputinga(x ,y )once. Thenafterthealignmentwecanperform
i pi
aregularcross-attentionwhichismuchmorecomputationallyandmemoryefficientthanhavingto
compute|X|∗|Y|alignmentsforallpossiblecombinationsofpointsfor|X|and|Y|.
4.3 Coarsepointcorrespondence
FortheestimationofthesuperpointmatchesweutilizetheequivariantbackbonepresentedinSection
7.1, followed by a coarse correspondence model that iteratively applies intra-point self-attention
betweenthepointsofthesamepointcloudandinter-pointcrossattentionbetweenthepointsofboth
pointclouds. Fortheintra-pointself-attentionweareusinginparalleltheinvariantandequivariant
self-attentionlayerspresentedabove. Fortheinter-pointcrossattentionweusedacompositionofa
simplecross-attentionlayeronlybetweentheinvariantfeaturesofthetwopointclouds,followedby
anequivariantcross-attentionlayerdefinedabove.
Theinputofthecoarsecorrespondencetransformeristheper-pointinvariantandequivariantfeatures
extractedbythebackboneforthesuperpointsX ,Y .Itsoutputsareinvariantpersuperpointfeatures
S S
6for both point clouds, namely f ,f for all x ∈ X , y ∈ Y . The extracted features are then
cx cy S S
usedtocomputeacorrelationmatrixS betweenallthesuperpointsofthereferenceandthesource.
Afterextractingthecorrelationbetweenthecoarsesuperpointsweselectthetop-KentriesofS as
thecandidatesuperpointmatches. Thesematcheswillbeinvarianttoroto-translationsoftheinput
point-cloud,sincethefeaturesusedfortheircomputationareinvariant.
4.4 Finepointmatching
Givenacandidatepair ofmatchedsuperpoints(x ,y ) weperformfine pointmatchingon
k(n) k(n)
theircorrespondinglocalneighborhoodsN ⊆X ,N ⊆Y . Wedefinetheneighborhood
xk(n) D yk(n) D
N ⊆X asthesetofallthefinepointsthathavex astheirclosestcoarsepointN =
(cid:40)xk(n) D
(cid:41)
k(n) xk(n)
x∈X |x =argmin(∥x−x ∥) ,andsimilarlyforN . Thedensepointcorrespondences
D k(n) j yk
xj∈XS
√
areextractedusinganoptimaltransportlayerwithacostmatrixdefinedasC =
(cid:0)
F
FT(cid:1)
/ d.
k xk yk
HereF
xk
∈ RC×|Nxk|,F
yk
∈ RC×|Nxk| arematriceswithcolumnscontainingscalarfeaturesfor
eachpointofthecorrespondinglocalneighborhoods. Similartothecoarsematches,inorderfor
theoptimaltransportcostandconsequentlytheassignmentofthefinepointmatchestobeinvariant
torigidtransformation,thefeaturesrepresentedascolumnsofF ,F shouldalsobeinvariantto
xk yk
thesetransformations.
SincewerequireF ,F tocontaininvariantfeatures,wecanincludetheequivariantvectorfeatures
xk yk
f (p)ofafinepointp ∈ X orp ∈ Y , bydefiningtheinvariantfeatureU = Wvec(fTf ),
v (1) (1) p v v
whereW isalearnablematrixthatmixestheelementsoffTf . FromEq. 2wecaneasilyobserve
v v
howU isinvariantsincetheinnerproductfTf betweentwoequivariantfeaturesremaininvariant
p v v
underaroto-translationoftheinputpoint-cloud. AsaresultthecolumnsofF ,F thatcorrespond
xk yk
to individual point features, for points of p of the neighborhoods N , N , are computed by
xk yk
concatenatingU ,f (p)tocreateainvariantfeaturef =[UT,f(1)(p)T]T.
p inv p p inv
UsingthecostmatrixC ofthekthcoarsematchweutilizetheSinkhornalgorithm[Sinkhornand
k
Knopp,1967]tocomputeamatrixZ ,thatprovidesasoftassignmentbetweenthefinepointsof
k
thetwoneighborhoods. Weidentifythepairofpointsforwhichtheircorrespondingentryisamong
thetop-Mentriesinboththeirrowandtheircolumns,whichwerefertoasthemutualtop-Mset
ofZ . ThisresultsinasetM offinepointmatchescorrespondingtothecandidatecoarsematch
k k
(x ,y ). Thefinalalignmenttransformationiscomputedusingalocal-to-globalregistration
k(n) k(n)
schemeproposedinQinetal.[2022](SeeAppendix7.3)
4.5 IterativeRefinement
Given an initial estimation of the alignment transformation R ,T produced by our model, we
0 0
canperformarefinementstepbyiterativelyapplyingourmodelandusingthepreviousestimated
transformasanextrainput. Toincorporatethisadditionalinput,afterthefirstestimationofR ,T ,
0 0
weusethisestimationtoaligntheequivariantfeaturesbeforethecrossattention,whichreplacesthe
alignmentlayera(.,.)definedinEq.1. Intheexperiments,wepresenttheresultsofourmethodwhen
weperformthreeadditionalrefinementsteps.
5 Experiments
Weevaluateourmethodonthe3DMatchZengetal.[2017]andthechallenging3DLoMatchHuang
et al. [2021] datasets which contain scans of indoor scenes with varying levels of overlap. The
3DMatchdatasetcontains46scenesfortraining,8forvalidation,and8fortesting. Followingthe
protocol of Huang et al. [2021] we evaluate on the 3DMatch test which contains scenes with an
overlapof30%andaboveandonthe3DLoMatchtestset,whichcontainssceneswithoverlapranging
from10%to30%. Forthequantitativeevaluationofourmethodweusesimilarmetricstoprevious
worksQinetal.[2022],Huangetal.[2021](seeAppendix7.4formoredetails).
5.1 RobustnessAnalysistotheinitialposeofthepointclouds
We benchmark popular state-of-the-art methods Qin et al. [2022], Yu et al. [2021], Huang et al.
[2021]ontheirrobustnesstotheinitialposesofthescans. Wetestallmethodsinthetotal3DMatch
datasetZengetal.[2017]byconcatenatingthe3DMatchand3DLoMatchsplitsandtestthemean
performanceacrossdifferentoverlapintervals. InFig.3weplottheRegistrationRecallandtheInlier
7Figure3: RegistrationRecallandInlierRatioforGeoTransformerQinetal.[2022],CofinetYuetal.
[2021]andPredatorHuangetal.[2021]ondifferentoverlaprangesofthetotal3DMatchZengetal.
[2017]. Thegreenlines(meanoriginal)showthemeanperoverlaprangefortheoriginaldataset.
Thebluelines(meanaugmented)showthemeanperoverlaprangeofanaugmenteddatasetinwhich
eachpointcloudhasbeenuniformlyroto-translatedcreatingatotalof54configurationsperpair. The
redline(robustaugmented)showsthemeanperoverlaprangeoftheminimumacrossthe54different
configurations. Thetotalmeanacrossallpairsinthedatasetforeachcaseisalsoshownintheplot.
Ratioin3differentsettings. First,inthegreenlines(meanoriginal),weshowthemeanperformance
ofthemethodsineachoverlapintervalintheoriginaldataset. Theoverlapofeachpairiscalculated
asinHuangetal.[2021]inthegroundtruthregistration. Second,inthebluelines(meanaugmented),
weshowthemeanperformanceinanaugmenteddatasetwhereeachpointcloudfromeachpairhas
beenindividuallyrotatedaround9axesuniformlyselectedandwith3differentanglesaroundeach
axisalsouniformlyselected. Thus,fromeachpair,wecreate54configurations. Lastly,inthered
lines(robustaugmented),weshowtherobustlossi.e.,themeanperformanceforeachoverlapregion
oftheminimumperformanceacrossthe54differentconfigurationsofthesamepair. Thetotalmean
acrossallpairsinthedatasetforeachcaseisalsoshowninthefigure.
We observe that there is a big drop in performance in the augmented setting both in the average
(6−7%)andintherobust(23−43%)metrics, whichisexacerbatedastheoverlapofthepoint
cloudsbecomessmaller. Thisisindicatedbythefactthatthedifferencebetweenthelinesincreases
astheoverlapdecreasesintheRegistrationRecallinFig. 3. WealsoobservethatGeoTransformeris
morerobusttoinitialposesthantherestofthemethodswhichisattributedtotheinvariantdesignof
thetransformerpartthatlearnstomatchthesuperpointsbetweenthepointclouds. Thereasonthatthe
methodstillperformserraticallyindifferentinitialposesisthatthebackbone,KP-ConvThomasetal.
[2019],isnotrotationequivariant. Fromthisobservation,weconcludethatbaking-inequivariance
eveninpartsofthepipelinecanbebeneficialforglobalPCR.Avisualexampleofsuchinconsistent
registrationisshowninFigure1whereGeotransformerisabletocorrectlyregisterapairofpoint
cloudsinoneconfigurationbutfailstodosoinadifferentconfiguration. Theseobservationsindicate
thattheproblemofglobalPCRremainsunsolvedandthereisaneedforapipelinethatperforms
consistently,irrespectiveoftheposesofthepointclouds. Ontheotherhand,ourmethodisdesigned
toconsistentlyregisterthegivensceneinallpossibleconfigurationsoftheinputpose,sinceitis
bi-equivarianttorigidtransformationsoftheinputs.
5.2 QuantitativeComparison
Wecomparetheperformanceofourmethodagainstrecentstate-of-the-art,FCGFChoyetal.[2019],
D3FeatBaietal.[2020],SpinNetAoetal.[2021],PredatorHuangetal.[2021],YOHO Wangetal.
[2022],CoFiNetYuetal.[2021],GeoTransformer Qinetal.[2022]. Allmethodsaretrainedon
thetrainingsetof3DMatchandareevaluatedinboth3DMatchand3DLoMatch. Allmethodsare
trainedwithrotationaugmentationsforboththesourceandreferencepointclouds. InTable1we
presenttheRegistrationRecallseparatelyfortheoriginal3DMatchand3DLoMatch. Then,inorder
tomeasurerobustnesstotheinitialposesofthepointclouds,whichistheimportantmetricforglobal
8RR MeanRR RobustRR MeanIR RobustIR
Model
3DM 3DLM 3DM+3DLM 3DM+3DLM 3DM+3DLM 3DM+3DLM
FCGFChoyetal.[2019] 0.85 0.40 - - - -
D3FeatBaietal.[2020] 0.82 0.37 - - - -
SpinNetAoetal.[2021] 0.89 0.60 - - - -
PredatorHuangetal.[2021] 0.89 0.60 0.71 0.34 0.36 0.25
YOHOWangetal.[2022] 0.90 0.65 0.76 - 0.43 -
CoFiNetYuetal.[2021] 0.89 0.68 0.71 0.34 0.38 0.27
GeoTransformer Qinetal.[2022] 0.91 0.74 0.77 0.61 0.49 0.46
BiEquiformer 0.90 0.69 0.78 0.78 0.49 0.49
Table1: RegistrationRecall(RR)on3DMatch(3DM)and3DLoMatch(3DLM),MeanandRobust
Registration Recall (Mean RR, Robust RR) and Inlier Ratio (Mean IR, Robust IR) on the total
3DMatch(concatenationofthe3DMatchand3DLoMatch)forinputsaugmentedbyuniformrotation.
RR
Model
3DM 3DLM
VNN+GeoTransformer 0.87 0.62
BiEquiformer+ICP 0.88 0.66
BiEquiFormer 0.90 0.69
Table 2: Ablation study on BiEquiformer. VNN+GeoTransformer replaces the non-equivariant
KPConv Thomas et al. [2019] with an equivariant counterpart VNN Deng et al. [2021].
BiEquiFormer+ICP utilizes the bi-equivariant layers but refines with a non-equivariant ICP.
BiEquiFormerusestheequivariantiterativeschemedescribedinSection4.5
PCR,weestimatetheexpectedregistrationrecall(MeanRR)acrossdifferentinitialposesandthe
robustregistrationrecallwhichistheaverageoverthedatasetoftheminimumrecalloverdifferent
posesoftheinput. Toestimatethesemetricswecreateanaugmentedtestdatasetwhereineachpair
ofpointcloudsweapply3drotationaround9axesuniformlyselectedandaround3anglesperaxis
forboththesourceandreferencepointclouds. Thusforeachpair,wecreate54configurationsand
wereportthemetricsonthisaugmenteddataset.
Weobservethatourmethodachievescomparableresultswithotherstate-of-the-artmethodsinthe
canonical test set, being second only to GeoTransformer. Moreover, it achieves state-of-the-art
performanceintheexpectedandrobustmetrics. Thisvalidatestheargumentthatourbi-equivariant
designisanimportantsteptowardsglobalPCRwithoutsacrificingperformanceonthecanonical
setting. Visualizationsoflow-overlapregistrationsareprovidedinAppendixFig. 4.
InTable2weprovideanablationstudytoshowtheimportanceoftheproposedbi-equivariantlayers
aswellastheproposedequivariantiterativerefinement. First,weprovideasimplebi-equivariant
alternativetoGeoTransformerbyreplacingthenon-equivariantfeatureextractorKPConvThomas
etal.[2019]withtheequivariantVNNDengetal.[2021]. WeshowthatBiEquiFormer,whichin
additionusesbi-equivariantlayersthatfusetheinformationfromthetwopointcloudsdemonstrates
improvedperformanceonthetask. Moreover,weexperimentedwithlocalrefinementstepsafterthe
initialglobalalignment. Weranthenon-equivariantICPalgorithm,heavilytuned(Point-to-PlaneICP
withRobustlossPomerleauetal.[2015]). Thenwerantheequivariantiterativeschemedescribedin
Section4.5. Inthiscasetoo,ourmethodyieldsbetterresults.
6 Conclusion
In this work we proposed a novel bi-equivariant pipeline to address the task of global PCR i.e.
registrationwithouttheassumptionofagoodinitialguessoftheinputpointclouds. Weinvestigated
therobustnessofcurrentdeeplearningmethodsontheposesoftheinputscansandobservedalarge
performancedegradation,especiallyinlow-overlapsettings. Weproposedtoaddresstheissueby
utilizingequivariantdeeplearningandformulatedandcharacterizedthebi-equivariantpropertiesof
PCR.Sincestandardrotationalequivariantlayershavelargememoryoverheadbutmostimportantly,
theyextractfeaturesseparatelyfromeachpointcloud,weproposedtobuildnovel,expressivebi-
equivariantlayersthatfusetheinformationofthetwopointcloudswhileextractingper-pointfeatures
onthem. WeusedthoselayerstobuildBiEquiformerabi-equivariantattentionarchitecturethatis
scalabletothelargevolumeofpointsinscene-levelscans. Weevaluatedourmethodonboththe
3DMatchandthechallenging3DLoMatchdataset,showingthatourmethodcanachievecomparable
andevensuperiorperformancetoothernon-equivariantandequivariantstate-of-the-artmethods,
especiallyintherobustmetrics.
9Webelievethattheexplicitformulationandcharacterizationofthebi-equivarianceofPCRcanbe
extendedtootherproblemssuchaspick-and-placetasksinroboticmanipulation. Weareconfident
thatthebi-equivariantlayersthatwedesignedinthisworkwillbebeneficialforsuchtaskstoo. Asa
limitation,wepinpointthatwhilethemethodachievesstate-of-the-artperformanceintherobustcase,
thereisasmallgapinthecanonicalsetting. Webelievethatthiscanbeattributedtotheexpressivity
oftheVNNfeatureextractorinthefirststepofthepipeline. However,higher-ordersteerablefeature
extractorsarecurrentlynotscalabletoscene-levelscans.
Acknowledgements
Thisprojectwasfundedbythegrants: AROMURIW911NF-20-1-0080andONRN00014-22-1-
2677.
References
S.Ao,Q.Hu,B.Yang,A.Markham,andY.Guo. Spinnet: Learningageneralsurfacedescriptorfor
3dpointcloudregistration. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition,2021.
Y.Aoki,H.Goforth,R.ArunSrivatsan,andS.Lucey. Pointnetlk: Robustandefficientpointcloud
registrationusingpointnet. InTheIEEEConferenceonComputerVisionandPatternRecognition
(CVPR),June2019.
J.L.Ba,J.R.Kiros,andG.E.Hinton. Layernormalization,2016.
P.Babin,P.Giguère,andF.Pomerleau. Analysisofrobustfunctionsforregistrationalgorithms. 2019
InternationalConferenceonRoboticsandAutomation(ICRA),pages1451–1457, 2018. URL
https://api.semanticscholar.org/CorpusID:52912585.
X.Bai,Z.Luo,L.Zhou,H.Fu,L.Quan,andC.-L.Tai. D3feat: Jointlearningofdensedetectionand
descriptionof3dlocalfeatures. arXiv:2003.03164[cs.CV],2020.
X.Bai,Z.Luo,L.Zhou,H.Chen,L.Li,Z.Hu,H.Fu,andC.-L.Tai. PointDSC:RobustPointCloud
RegistrationusingDeepSpatialConsistency. CVPR,2021.
B.Bellekens,V.Spruyt,R.Berkvens,R.Penne,andM.Weyn. Abenchmarksurveyofrigid3dpoint
cloudregistrationalgorithms. InternationalJournalOnAdvancesinIntelligentSystems,1,06
2015.
P.BeslandN.D.McKay. Amethodforregistrationof3-dshapes. IEEETransactionsonPattern
AnalysisandMachineIntelligence,14(2):239–256,1992. doi: 10.1109/34.121791.
G. Blais and M. Levine. Registering multiview range data to create 3d computer objects. IEEE
TransactionsonPatternAnalysisandMachineIntelligence,17(8):820–824,1995. doi: 10.1109/
34.400574.
M.BosseandR.Zlot. Mapmatchinganddataassociationforlarge-scaletwo-dimensionallaser
scan-basedslam. I.J.RoboticRes.,27:667–691,062008. doi: 10.1177/0278364908091366.
E.Chatzipantazis,S.Pertigkiozoglou,E.Dobriban,andK.Daniilidis. Se(3)-equivariantattention
networksforshapereconstructioninfunctionspace. InTheEleventhInternationalConferenceon
LearningRepresentations,2023. URLhttps://openreview.net/forum?id=RDy3IbvjMqT.
H.Chen,S.Liu,W.Chen,H.Li,andR.Hill. Equivariantpointnetworkfor3dpointcloudanalysis.
pages14514–14523,2021.
Y.ChenandG.Medioni. Objectmodelingbyregistrationofmultiplerangeimages. InProceedings.
1991IEEEInternationalConferenceonRoboticsandAutomation,pages2724–2729vol.3,1991.
doi: 10.1109/ROBOT.1991.132043.
Y.Chen,B.Fernando,H.Bilen,M.Nießner,andE.Gavves. 3dequivariantgraphimplicitfunctions.
ECCV,2022.
10C.Choy,J.Park,andV.Koltun. Fullyconvolutionalgeometricfeatures. InICCV,2019.
C. Choy, W. Dong, and V. Koltun. Deep global registration. In Proceedings of the IEEE/CVF
ConferenceonComputerVisionandPatternRecognition(CVPR),June2020.
T.S.Cohen, M.Geiger, andM.Weiler. AgeneraltheoryofequivariantCNNsonhomogeneous
spaces. CurranAssociatesInc.,RedHook,NY,USA,2019.
C.Deng,O.Litany,Y.Duan,A.Poulenard,A.Tagliasacchi,andL.Guibas. Vectorneurons:ageneral
frameworkforso(3)-equivariantnetworks. arXivpreprintarXiv:2104.12229,2021.
C. Deng, J. Lei, B. Shen, K. Daniilidis, and L. J. Guibas. Banana: Banach fixed-point network
forpointcloudsegmentationwithinter-partequivariance. ArXiv, abs/2305.16314, 2023. URL
https://api.semanticscholar.org/CorpusID:258887967.
H. Deng, T. Birdal, and S. Ilic. Ppf-foldnet: Unsupervised learning of rotation invariant 3d lo-
caldescriptors. ArXiv,abs/1808.10322,2018a. URLhttps://api.semanticscholar.org/
CorpusID:52131369.
H. Deng, T. Birdal, and S. Ilic. Ppfnet: Global context aware local features for robust 3d point
matching. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages
195–205,2018b. URLhttps://api.semanticscholar.org/CorpusID:3703761.
O.-E.Ganea,X.Huang,C.Bunne,Y.Bian,R.Barzilay,T.Jaakkola,andA.Krause. Independent
se(3)-equivariantmodelsforend-to-endrigidproteindocking. arXivpreprintarXiv:2111.07786,
2021.
Z.Gojcic,C.Zhou,andA.Wieser. Learnedcompactlocalfeaturedescriptorfortls-basedgeodetic
monitoringofnaturaloutdoorscenes. ISPRSAnnalsofthePhotogrammetry,RemoteSensingand
SpatialInformationSciences,2018. URLhttps://api.semanticscholar.org/CorpusID:
54867443.
Z.Gojcic,C.Zhou,J.D.Wegner,andW.Andreas. Theperfectmatch: 3dpointcloudmatching
withsmootheddensities. InInternationalconferenceoncomputervisionandpatternrecognition
(CVPR),2019.
Y.Guo, M.Bennamoun, F.Sohel, M.Lu, J.Wan, andN.Kwok. Acomprehensiveperformance
evaluationof3dlocalfeaturedescriptors. InternationalJournalofComputerVision,116,042015.
doi: 10.1007/s11263-015-0824-y.
H. Huang, O. L. Howell, D. Wang, X. Zhu, R. Platt, and R. Walters. Fourier transporter: Bi-
equivariant robotic manipulation in 3d. In The Twelfth International Conference on Learning
Representations,2024. URLhttps://openreview.net/forum?id=UulwvAU1W0.
S.Huang,Z.Gojcic,M.Usvyatsov,A.Wieser,andK.Schindler. Predator: Registrationof3dpoint
cloudswithlowoverlap. InProceedingsoftheIEEE/CVFConferenceonComputerVisionand
PatternRecognition(CVPR),pages4267–4276,June2021.
X. Huang, G. Mei, and J. Zhang. Feature-metric registration: A fast semi-supervised approach
forrobustpointcloudregistrationwithoutcorrespondences. InTheIEEE/CVFConferenceon
ComputerVisionandPatternRecognition(CVPR),June2020.
A.JohnsonandM.Hebert. Usingspinimagesforefficientobjectrecognitionincluttered3dscenes.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 21(5):433–449, 1999. doi:
10.1109/34.765655.
D.P.KingmaandJ.Ba.Adam:Amethodforstochasticoptimization.In3rdInternationalConference
onLearningRepresentations,ICLR2015,SanDiego,CA,USA,May7-9,2015,ConferenceTrack
Proceedings,2015.
H. Li and R. Hartley. The 3d-3d registration problem revisited. pages 1 – 8, 11 2007. doi:
10.1109/ICCV.2007.4409077.
11J.Li,C.Zhang,Z.Xu,H.Zhou,andC.Zhang. Iterativedistance-awaresimilaritymatrixconvolution
with mutual-supervised point elimination for efficient point cloud registration. In European
ConferenceonComputerVision(ECCV),2020.
L.Li,R.Wang,andX.Zhang. Atutorialreviewonpointcloudregistrations: Principle,classification,
comparison, and technology challenges. Mathematical Problems in Engineering, 2021. URL
https://api.semanticscholar.org/CorpusID:237702700.
Y.LiandT.Harada. Lepard: Learningpartialpointcloudmatchinginrigidanddeformablescenes.
IEEE/CVFConferenceonComputerVisionandPatternRecognition(CVPR),2022.
A.Makadia, A.Patterson, andK.Daniilidis. Fullyautomaticregistrationof3dpointclouds. In
2006IEEEComputerSocietyConferenceonComputerVisionandPatternRecognition(CVPR’06),
volume1,pages1297–1304,2006. doi: 10.1109/CVPR.2006.122.
T. Min, C. Song, E. Kim, and I. Shim. Distinctiveness oriented positional equilibrium for point
cloudregistration. InProceedingsoftheIEEE/CVFInternationalConferenceonComputerVision
(ICCV),pages5490–5498,October2021.
A.Nüchter,K.Lingemann,J.Hertzberg,andH.Surmann. 6dslam-3dmappingoutdoorenviron-
ments. FraunhoferIAIS,24,112006.
G.D.Pais,P.Miraldo,S.Ramalingam,J.C.Nascimento,V.M.Govindu,andR.Chellappa. 3dregnet:
Adeepneuralnetworkfor3dpointregistration. pages7193–7203,2019.
A.Paszke,S.Gross,F.Massa,A.Lerer,J.Bradbury,G.Chanan,T.Killeen,Z.Lin,N.Gimelshein,
L.Antiga,A.Desmaison,A.Kopf,E.Yang,Z.DeVito,M.Raison,A.Tejani,S.Chilamkurthy,
B. Steiner, L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance
deep learning library. In Advances in Neural Information Processing Systems 32, pages
8024–8035. Curran Associates, Inc., 2019. URL http://papers.neurips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
F.Pomerleau,F.Colas,andR.Siegwart. Areviewofpointcloudregistrationalgorithmsformobile
robotics. FoundationsandTrends®inRobotics,4:1–104,052015. doi: 10.1561/2300000035.
C.R.Qi,H.Su,K.Mo,andL.J.Guibas. Pointnet: Deeplearningonpointsetsfor3dclassification
andsegmentation,2016. URLhttp://arxiv.org/abs/1612.00593. citearxiv:1612.00593.
C.R.Qi,L.Yi,H.Su,andL.J.Guibas. Pointnet++: Deephierarchicalfeaturelearningonpointsets
inametricspace. NIPS’17,page5105–5114,RedHook,NY,USA,2017.CurranAssociatesInc.
ISBN9781510860964.
Z.Qin,H.Yu,C.Wang,Y.Guo,Y.Peng,andK.Xu. Geometrictransformerforfastandrobustpoint
cloudregistration. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPattern
Recognition(CVPR),pages11143–11152,June2022.
R.B.Rusu,N.Blodow,Z.C.Marton,andM.Beetz. Aligningpointcloudviewsusingpersistent
featurehistograms. In2008IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems,
pages3384–3391,2008. doi: 10.1109/IROS.2008.4650967.
R.B.Rusu,N.Blodow,andM.Beetz. Fastpointfeaturehistograms(fpfh)for3dregistration. In
2009IEEEInternationalConferenceonRoboticsandAutomation,pages3212–3217,2009. doi:
10.1109/ROBOT.2009.5152473.
H.Ryu,H.inLee,J.-H.Lee,andJ.Choi. Equivariantdescriptorfields: Se(3)-equivariantenergy-
basedmodelsforend-to-endvisualroboticmanipulationlearning. InTheEleventhInternational
ConferenceonLearningRepresentations,2023. URLhttps://openreview.net/forum?id=
dnjZSPGmY5O.
H. Ryu, J. Kim, H. An, J. Chang, J. Seo, T. Kim, Y. Kim, C. Hwang, J. Choi, and R. Horowitz.
Diffusion-edfs: Bi-equivariantdenoisinggenerativemodelingonse(3)forvisualroboticmanipula-
tion. InProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition
(CVPR),pages18007–18018,June2024.
12S. Salti, F. Tombari, and L. Di Stefano. Shot: Unique signatures of histograms for surface and
texturedescription. ComputerVisionandImageUnderstanding,125:251–264,2014. ISSN1077-
3142. doi: https://doi.org/10.1016/j.cviu.2014.04.011. URL https://www.sciencedirect.
com/science/article/pii/S1077314214000988.
P.-E.Sarlin,D.DeTone,T.Malisiewicz,andA.Rabinovich. SuperGlue: Learningfeaturematching
withgraphneuralnetworks. InCVPR,2020. URLhttps://arxiv.org/abs/1911.11763.
V.Sarode,X.Li,H.Goforth,Y.Aoki,R.A.Srivatsan,S.Lucey,andH.Choset. Pcrnet: Pointcloud
registrationnetworkusingpointnetencoding,2019.
R.SinkhornandP.Knopp. Concerningnonnegativematricesanddoublystochasticmatrices. Pacific
JournalofMathematics,21(2):343–348,1967.
H.Thomas,C.R.Qi,J.-E.Deschaud,B.Marcotegui,F.Goulette,andL.Guibas. Kpconv: Flexible
anddeformableconvolutionforpointclouds. In2019IEEE/CVFInternationalConferenceon
ComputerVision(ICCV),pages6410–6419,2019. doi: 10.1109/ICCV.2019.00651.
A.Vaswani,N.Shazeer,N.Parmar,J.Uszkoreit,L.Jones,A.N.Gomez,L.Kaiser,andI.Polosukhin.
Attentionisallyouneed.NIPS’17,page6000–6010,RedHook,NY,USA,2017.CurranAssociates
Inc. ISBN9781510860964.
H.Wang,Y.Liu,Z.Dong,andW.Wang. Youonlyhypothesizeonce: Pointcloudregistrationwith
rotation-equivariantdescriptors. InProceedingsofthe30thACMInternationalConferenceon
Multimedia,pages1630–1641,2022.
Y.WangandJ.M.Solomon. Deepclosestpoint:Learningrepresentationsforpointcloudregistration.
InTheIEEEInternationalConferenceonComputerVision(ICCV),October2019.
Y.Wang,Y.Sun,Z.Liu,S.E.Sarma,M.M.Bronstein,andJ.M.Solomon. Dynamicgraphcnnfor
learningonpointclouds. ACMTransactionsonGraphics(TOG),2019.
W.Wu,L.Fuxin,andQ.Shan. Pointconvformer: Revengeofthepoint-basedconvolution. InCVPR,
2023. URLhttps://arxiv.org/abs/2208.02879.
F.Yang,L.Guo,Z.Chen,andW.Tao. Oneinlierisfirst: Towardsefficientpositionencodingfor
pointcloudregistration. InA.H.Oh,A.Agarwal,D.Belgrave,andK.Cho,editors,Advances
inNeuralInformationProcessingSystems,2022. URLhttps://openreview.net/forum?id=
19MmorTQhho.
H. Yang, J. Shi, and L. Carlone. Teaser: Fast and certifiable point cloud registration. IEEE
TransactionsonRobotics,37(2):314–333,2021. doi: 10.1109/TRO.2020.3033695.
J. Yang, H. Li, and Y. Jia. Go-icp: Solving 3d registration efficiently and globally optimally.
In 2013 IEEE International Conference on Computer Vision, pages 1457–1464, 2013. doi:
10.1109/ICCV.2013.184.
Z.J.YewandG.H.Lee. 3dfeat-net: Weaklysupervisedlocal3dfeaturesforpointcloudregistration.
InECCV,2018.
H.Yu,F.Li,M.Saleh,B.Busam,andS.Ilic. Cofinet: Reliablecoarse-to-finecorrespondencesfor
robustpointcloudregistration. AdvancesinNeuralInformationProcessingSystems,34,2021.
A. Zeng, S. Song, M. Nießner, M. Fisher, J. Xiao, and T. Funkhouser. 3dmatch: Learning local
geometricdescriptorsfromrgb-dreconstructions. InCVPR,2017.
H. Y. Zhijian Qiao, Zehuan Yu and S. Shen. Pyramid semantic graph-based global point cloud
registrationwithlowoverlap. In2023IEEE/RSJInternationalConferenceonIntelligentRobots
andSystems(IROS),2023.
137 Appendix/SupplementaryMaterial
7.1 EquivariantFeatureExtraction
Previousworksutilizecommonlyusedpointcloudprocessingarchitectures,suchasKPConv-FPN
[Thomasetal.,2019]orDGCNN[Wangetal.,2019],toextractperpointfeaturesforeachpoint-cloud
individually. Thesefeaturesarenotinherentlydesignedtobeequivarianttorigidtransformations.
Weaddressthislimitationbyusingabackbonefeatureextractorthatoutputsbothinvariantf and
s
equivariantf featurevectors. Underaroto-translationR,T oftheinputthesefeaturestransformas:
v
f (Rx +T,RX+T)=f (x ,X), f (Rx +T,RX+T)=Rf (x ,X) (2)
s i s i v i v i
ToprocesssuchequivariantvectorfeaturesweutilizetheVectorNeuronslayerproposedinDeng
etal.[2021]. Thistypeoflinearlayer,denotedasVN,processesfeaturesoftheformF ∈ R3×C,
withcolumnscorrespondingtovectorsinR3. ItisdefinedasVN(F)=FW ,andisequivariant
lvn
torotationsofitsinputfeaturessinceVN(RF)=RFW =RVN(F).
lvn
Additionally,tocapturethegeometryofthescenesatdifferentlevelsofdetailweuseahierarchical
architecture,similartoChenetal.[2022],thatprocessesandoutputsinvariant/equivariantvector
featuresfordifferentsubsampledversionsoftheinputpointcloud. Wedenotethesesubsampled
versionsasX ,X ,...,X ,rangingfromfinertocoarsersampledpoints. Thepointsinthefirst
(0) (1) (n)
downsamplinglevelarereferredasdensepointsX =X ,whilethepointsobtainedbythelast
D (1)
levelofdownsamplingarereferredtoassuperpointsX =X . Similarlyweusethenotationx
S (n) (i)
todistinguishthepointsforthedifferentsubsamplinglevels.
7.2 ImplementationDetails
7.2.1 Inputpre-processing
Fortheinitialfeatureextraction,describedinSection7.1,weusefourdifferentsubsampledversions
oftheinputpointcloud,denotedasX(0),X(1),X(2),X(3). Eachpointcloudissampledusinggrid
samplingwhere,fortheithsubsampledversionX(i),thevoxelsizeissetto0.025∗2i.
Duringtraining,boththesourceandthereferencepointcloudsareaugmentedwithGaussiannoise
withstandarddeviationof0.005. Additionally,foreachpointcloud,welimitthetotalamountof
pointsto5000. Iftheinputpointcloudsexceedthislimit,werandomlysample5000pointsfrom
eachoneofthem. Weobservedthatenforcingthislimitduringtraininghasaminimumeffectonthe
performanceduringtesting,evenwhenwetestonlargerpointclouds.
7.2.2 ModelArchitectureandTraining
WeimplementedandevaluatedBiEquiFormerinPyTorchPaszkeetal.[2019]onanI9IntelCPU,
64GBRAMandanNVIDIARTX3090GPU.
• Featureextraction: Ourfeatureextractionnetworkconsistsofconsecutive“hybrid"layers,
similartotheonesproposedinChenetal.[2022],thatsimultaneouslyprocessbothscalar
invariantfeaturesandequivariantvectorfeaturesbyutilizingVectorNeuronslayers[Deng
et al., 2021]. In each layer, all points aggregate features from their k nearest neighbors,
wherewesetk =20. Weperformthreeaggregationstepsforeachsubsampledversionof
thepointcloud. SimilartoKPConv-FPN[Thomasetal.,2019],weprocessthedifferent
subsampledversionsfromfinertocoarser,wherethecoarserpointshaveasinputfeatures
anaggregationoftheextractedfeaturesoftheirclosestfinerpoints.
• Coarsepointcorrespondence: Thecoarsepointcorrespondencemodelconsistsofthree
consecutiveblocksofanintra-pointself-attentionlayerdescribedinSection??,followedby
aninter-pointcrossattentionlayerthatusesonlytheinvariantfeaturesofthepointclouds,
andanequivariantinter-pointcross-attentionlayerdescribedinSection??.
• Finepointmatching: AsdiscussedinSection4.4,weextractfinepointmatchesbetween
thelocalneighborhoodsofthematchedsuperpointsbyusinganoptimaltransportlayer. We
usetheSinkhornalgorithm[SinkhornandKnopp,1967]for100steps. Afterextractingthe
softassignmentbetweenfinepoints,weusesolveaweightedProcrustesproblem,shown
in4.4,toextractthelocalcandidatetransformationsforthedifferentmatchedsuperpoints.
14Finally,wefollowtheLocaltoGlobalRegistrationscheme,whichselectsthecandidate
transformationthatminimizesthetotalalignmenterror.
• IterativeRefinement: Whenweperformtheiterativerefinementwetrainaninitialmodel
forthefirstestimationofthealignmenttransformationandthenasecondmodelthatperforms
therefinementsteps.
Duringtrainingwesupervisetheoutputofthecoarsematchingmodulebyusingtheoverlap-aware
circlelossproposedinQinetal.[2022]. Additionally,similarlytoSarlinetal.[2020]wesupervise
thefinepointmatchesbetweentheneighborhoodN ,N byusinganegativelog-likelihoodloss
xk yk
ontheoutputofthesoftassignmentmatrixZ producedbytheoptimaltransport:
k
(cid:88) (cid:88)
L =− log(z )− log(z )
f,k x,y x,mk+1
(x,y)∈Gk x∈Ik
(cid:88)
− log(z )
ni+1,y
y∈Jk
where G is the set of ground truth fine point matches, I , J are the sets containing the rest
k k k
unmatchedpointsandz ,z correspondstothedustbinrowandcolumnoutputfromthe
.,mk+1 ni+1,.
learnableoptimaltransportmodule. Wetrainourmodelfor40epochs,usinganinitiallearningrate
of10−4 thatwereducebyascaleof0.95eachepoch. Alltheparametersareoptimizedusingthe
Adamoptimizer[KingmaandBa,2015].
7.3 LocaltoGlobalRegistration
Thefinalalignmenttransformationiscomputedusingalocal-to-globalregistrationschemeproposed
inQinetal.[2022]. Foreachcandidatecoarsematch(x ,y )andtheirgivensetofinliersM ,
k(n) k(n) k
wecomputeacandidatetransformationR ,T bysolvingtheoptimizationproblem:
i i
(cid:88)
min z ∥Rp+t−q∥2
p,q 2
R,T
(p,q)∈Mk
wherez istheentrycorrespondingtothesoftassignmentofthefinepointptothepointqinthe
p,q
optimaltransportmatrixZ . Finallywepickastheglobalestimatedtransformation,thecandidate
k
(cid:83)
thatminimizesthealignmenterroroverthecombinedsetofinliers M .
k=1,...,M k
7.4 EvaluationMetrics
RegistrationRecall(RR):thefractionofpointcloudswhoseestimatedtransformationhasanerror
less by a set threshold. Specifically given a ground truth transformation P and the estimated
gt
transformationP wecomputetheRMSEerror:
est
(cid:115)
1 (cid:88)
RMSE= ∥P−1P y−y∥2
|Y| gt est 2
y∈Y
thentheregistrationrecallcountsthefractionofregistrationwithRMSE<0.2m.
InlierRatio(IR)thefractionoffinepointcorrespondenceswheretheirresidualundertheground-
truthtransformationisbelow0.1m.
RelativeRotationandRelativeTranslationError:therelativerotationerrorandrelativetranslation
errorbetweentheestimatedandgroundtruthtransformation
7.5 ProofsofPropositions
Beforebeginningwiththeproofsofthepropositionsweneedtoproveasubtlebutimportantpoint.
Proposition7.1. IfthegroupsG ,G actonthesetS via∗,·respectivelythenthemapdefinedas:
1 2
(G ×G )×S →S
1 2
(g ,g )s→g ∗s·g−1
1 2 1 2
isagroupactionofthedirectproductgroupG ×G .
1 2
15Proof. Ife ,e aretheidentityelementsofG ,G then(e ,e )istheidentityelementofG ×G .
1 2 1 2 1 2 1 2
Alsoconsider(g ,g ),(h ,h )×G ×G Then,
1 2 1 2 1 2
(e ,e )s=e ∗s·e−1 =e ∗(s·e )=e ∗s=s
1 2 1 2 1 2 1
(g ,g )(h ,h )s=(g ,g )(h ∗s·h−1)=g ∗(h ∗s·h−1)·g−1 =(g h )∗s·(h−1g−1)
1 2 1 2 1 2 1 2 1 1 2 2 1 1 2 2
=(g h )∗s·(g h )−1 =(g h ,g h )s
1 1 2 2 1 1 2 2
ProofofProposition3.1. GiventheformulationinSection3westartbydenotingtheinputpoint
(cid:20) (cid:21)
Rr Tr
cloudsXr,YsandtheirrelativerigidtransformationTr = s s . AlsoletC ={(x ,y )|x ∈
s 0 1 i i i
Xr,y ∈Ys}denotethepointmatches.Now,iftheinputpointcloudstransformwithT ,T ∈SE(3)
i 1 2
as: T Xr = R Xr + T , T Ys = R Ys + T then we need to prove the following for the
1 1 1 2 2 2
transformationT TrT−1 ∈SE(3):
1 s 2
• Invariantpointmatching:ThepointsT x =R x +T ∈T Xr,T y =R y +T ∈T Ys
1 i 1 i 1 1 2 i 2 i 2 2
arealsopointmatchesforT TrT−1(whichcanalsobecomputedfromthefirstproblem
1 s 2
formulation)sinceinthenewalignmentwehave: T TrT−1(T y )=T Try and
1 s 2 2 i 1 s i
∥T x −T Try ∥ =∥(R x +T )−(R (Try )+T )∥
1 i 1 s i 2 1 i 1 1 s i 1 2
=∥R (x −Try )∥ =∥x −Try ∥ ≤ϵ
1 i s i 2 i s i 2
since(x ,y )∈C.
i i
• OptimalProcrustes: FortheinitialproblemweknowthattheobjectivefunctionL (T)=
1
(cid:80) ∥Ty −x ∥2 satisfies: L (Tr) := L∗ ≤ L (T) for all T ∈ SE(3). Now
(xi,yi)∈C i i 2 1 s 1 1
we look at the objective of the new problem (for which we proved invariant matches)
L (T)=(cid:80) ∥TT y −T x ∥2. IfwesubstituteT =T TrT−1weget:
2 (xi,yi)∈C 2 i 1 i 2 1 s 2
(cid:88) (cid:88)
L (T TrT−1)= ∥T TrT−1T y −T x ∥2 = ∥Try −x ∥2 =L (Tr)=L∗
2 1 s 2 1 s 2 2 i 1 i 2 s i i 2 1 s 1
(xi,yi)∈C (xi,yi)∈C
weprovedthattheoptimalofthesecondproblemisupperboundedbythefirst. Wewillalso
showtheopposite. Inparticular,ifwesubstituteT =T−1TT inL foranyT ∈SE(3)
1 2 1
weget:
(cid:88)
L (T−1TT )= ∥T−1TT y −x ∥2
1 1 2 1 2 i i 2
(xi,yi)∈C
(cid:88)
= ∥RT(TT y )−RTT −x ∥2
1 2 i 1 1 i 2
(xi,yi)∈C
(cid:88)
= ∥TT y −R (RTT +x )∥2
2 i 1 1 1 i 2
(xi,yi)∈C
(cid:88)
= ∥TT y −T x ∥2 =L (T)
2 i 1 i 2 2
(xi,yi)∈C
Proofofproposition3.2. First,wecanagainproveinvariantmatching. Theflipisaunitaryoperation
soitdoesnotchangethedistancesbetweenthematchedpoints. Inotherwordssince∥x −y ∥ =
m m 2
∥y −x ∥ thesetC ofpointmatchesconsistsofthesamepoints(reversed). Againlookingatthe
m m 2
twoobjectiveswecanproveProcrustesoptimalityasforT ∈SE(3)itholdsT−1 ∈SE(3):
(cid:88)
L (T−1)= ∥T−1y −x ∥2
1 i i 2
(xi,yi)∈C
(cid:88)
= ∥RTy −RTT −x ∥2
i i 2
(xi,yi)∈C
(cid:88) (cid:88)
= ∥y −T −Rx ∥2 = ∥Tx −y ∥2 =L (T)
i i 2 i i 2 2
(xi,yi)∈C (xi,yi)∈C
16Thus, the optimal values of the two problems are again there same and since Tr is optimal for
s
L then (Tr)−1 is optimal for L . Lastly, this is indeed an action of the flips since f2 = e and
1 s 2
((Tr)−1)−1 =Tr
s s
proofofProposition3.3. Sincethepermutationsisaunitarytransformationthedistanceagaindo
notchangeandthematchingisagaininvariant(thistimethesethasexactlythesamepointsisother
order). Sincethesumisorder-invariantthetotalobjectiveisalsothesamesotheproblemisinvariant
topointspermutations.
proofofproposition4.1. 1. Since f (cid:55)→ R f ,f (cid:55)→ R f the tensor product f fT (cid:55)→
1 1 1 2 2 2 1 2
(R f )(R f )T =R (f fT)RT. Thus,themapisoutputbi-equivariant.
1 1 2 2 1 1 2 2
2. IfF =UΣVT istheSVDofF thenR FRT =R (UΣVT)RT =(R U)Σ(R V)T and
1 2 1 2 1 2
thus(R U,Σ,R V)istheSVDofR FRT sincethecompositionofrotationmatrixwitha
1 2 1 2
unitarymatrixisaunitarymatrix. Thus,U,V transformwiththestandardrepresentations
andΣisinvariant. Thuswecanuseanypoint-wisenon-linearityonΣsincethisisalso
invariant. Thusthemapisinputbi-equivariant.
3. Since ∥R 1FR 2T∥ = ∥F∥ we get R 1FR 2T (cid:55)→ σ(∥R 1FR 2T∥) ∥RR 11 FF RR 22 TT
∥
=
R σ(∥F∥) F RT. Thusthemapisinput-outputbi-equivariant.
1 ∥F∥ 2
Proposition7.2. αintraisinvariantandαintraisequivarianttotheroto-translationoftheinputpoint
s v
cloud(seeproofinAppendix):
αintra(Rx +T,f ,Rf )=αintra(x ,f ,f )
s i s v s i s v
αintra(Rx +T,f ,Rf )=Rαintra(x ,f ,f )
v i s v v i s v
Proofsketchofproposition7.2. Itiseasytoshowthate isinvarianttotransformationsofallthe
ij
inputsofaintrasincethefirsttermusesonlytheinvariantf featuresandtheinvariantr geometric
s s ij
embeddingintroducedinQinetal.[2022]. InthesecondtermatransformationbyRresultsin:
w (Rf (x ))T(Rf (x ))w =w f (x )TRTRf (x )w =w f (x )Tf (x )w
q v i v j k q v i v j k q v i v j k
whichisalsoinvariant. Asaresultαintra(x ,f ,f )isinvariantsinceitonlydependsone andf
s i s v ij v
andsincetheVNlayerisequivarianttotherotations:
αintra(Rx +T,f ,Rf )==
(cid:88) exp(e ij)
VN (Rf (x ))
v i s v (cid:80) exp(e ) V v j
xj∈X x′ j∈X ij′
=
(cid:88) exp(e ij)
RVN (f (x ))
(cid:80) exp(e ) V v j
xj∈X x′ j∈X ij′
=Rαintra(x ,f ,f )
v i s v
ProofSketchofproposition4.2. HereweusethefactthatthetheFrobeniusnormisinvarianttothe
rotationasaresultsforthenonlinearitywehavethat:
R FRT
ϕ(R FRT)=LayerN(cid:0) ∥R FRT∥(cid:1) x y
x y x y ∥R FRT∥
x y
R FRT
=LayerN(∥F∥) x y
∥F∥
=R ϕ(F)RT
x y
17Thenusingthefacttensorproductisbi-equivariantitiseasytoshowthat:
b(R f (x ),R f (y ))=ϕ(R f (x )⊗R f (y ))
x v i y v pi x v i y v pi
=ϕ(R (f (x )⊗f (y ))RT)
x v i v pi Y
=R ϕ((f (x )⊗f (y )))RT
x v i v pi Y
and
a(R f (x ),R f (y ))=b(R f (x ),R f (y ))R f (y )
x v i y v pi x v i y v pi y v pi
=R b(f (x ),f (y ))f (y )
x v i v pi v pi
=R a(f (x ),f (y ))
x v i v pi
Proposition 7.3. αpair is invariant to the roto-translation of both point clouds X,Y. αpair is
s v
equivarianttotheroto-translationofX andinvarianttotheroto-translationofY (seeproofsketch
inAppendix). SpecificallygivenX′ =R X+T andY′ =R Y +T :
x x y Y
αpair(R x +T ,F ,F )=αpair(x ,F ,F )
s x i x X′ Y′ s i X Y
αpair(R x +T ,F ,F )=R αpair(x ,F ,F )
s x i x X′ Y′ X s i X Y
Proofsketchofproposition7.3. Herethelayerissimilarwiththeoneinproposition4.1withdifferent
secondinputbeinga(f (x ),f (y ))thatisequivarianttothetransformationofframeX. Sowe
v i v pi
canshowtheequivarianceusingthesameargumentsasproposition4.1
7.6 QualitativeResults
InFigure4weprovideadditionalqualitativeresultswithregistrationsachievedbyourmethod. We
showexamplesofbothhighandlowoverlapfromthetestsetof3DMatchand3DLoMatch.
7.7 Limitations
Onelimitationofthecurrentnetworkisthat,whileintherobustsetting,itachievesstate-of-the-art
results, in the canonical setting there is a performance gap with the current best methods. We
conjecturethatthiscanbeattributedtothefeatureextractionbackboneVNNDengetal.[2021]and
wewillinvestigatealternativesinthefuture.
Anotherlimitationofthepipelineisanadditionalmemoryoverheadcomingfromthetensorproducts
intheattentionmodules. Whilewedidourbesttocreateascalableandcompactarchitecture,thetoll
tosatisfytheequivarianceconstraintexactlyisthatsomeblocksmightrequireadditionaloperations
totheirnon-equivariantcounterparts. Whileinthe3DMatchsetting,thisdidnotmakeadifference,
themethodhastobeadaptedproperlyinordertoregistersceneswithmillionsofpoints.
Agenerallimitationofcorrespondence-basedmethodslikeoursisthatwhentheoverlapiszeroasin
PointCloudAssemblytasksthenetworkcannottreatPCRproperly. Moreover,astypicalinPCR
literature,itisimplicitlyassumedthatthereisacorrectalignmentfortheinputpairs. Thenetworkis
designedtopredictthebestalignmentpossibleevenwhennoalignmentiscorrect. Thusinorderto
integrateitintobiggerSLAMpipelinesforloopclosuredetectionetc. additionalextensionsneedto
bedone.
7.8 BroaderImpact
Inthiswork,weaddressamajorrobustnesslimitationofcurrentdeeplearningmethodsonpointcloud
registration. Ourtheoreticalandmethodologicalcontributions,forexamplethenovelbi-equivariant
layerspresented,havethepotentialtoadvanceanypipelinethatrespectssimilarsymmetries(for
examplepick-and-placeinroboticsmanipulation).
Moreover, PointCloudRegistrationcanbeusedasthefrontendoflargerSLAMpipelines. Our
methodguaranteesthattheregistrationwillbeconsistentw.r.t. thescanposesmeaningthatthere
is no adversarial pose that would make the network behave erratically. If PCR is integrated into
safety-criticalapplicationsthisisamajoradvancementonverifiablesafety.
18Input Point Cloud Estimated Registration Ground Truth
Figure4: Registrationresultsachievedbyourmethodcomparedtothegroundtruthalignment.
19