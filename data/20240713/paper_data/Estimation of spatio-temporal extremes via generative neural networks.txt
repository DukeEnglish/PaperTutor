ESTIMATION OF SPATIO-TEMPORAL EXTREMES VIA GENERATIVE
NEURAL NETWORKS
ChristopherBülte∗ LisaLeimenstoll
ChairofStatisticalMethodsandEconometrics ChairofStatisticalMethodsandEconometrics
KarlsruheInstituteofTechnology(KIT) KarlsruheInstituteofTechnology(KIT)
Karlsruhe,Germany Karlsruhe,Germany
buelte@math.lmu.de lisa.leimenstoll@kit.edu
MelanieSchienle
ChairofStatisticalMethodsandEconometrics
KarlsruheInstituteofTechnology(KIT)
Karlsruhe,Germany
melanie.schienle@kit.edu
July12,2024
ABSTRACT
Recentmethodsinmodelingspatialextremeeventshavefocusedonutilizingparametricmax-stable
processesandtheirunderlyingdependencestructure. Inthiswork,weprovideaunifiedapproach
for analyzing spatial extremes with little available data by estimating the distribution of model
parametersorthespatialdependencedirectly.Byemployingrecentdevelopmentsingenerativeneural
networkswepredictafullsample-baseddistribution,allowingfordirectassessmentofuncertainty
regardingmodelparametersorotherparameterdependentfunctionals. Wevalidateourmethodby
fittingseveralsimulatedmax-stableprocesses,showingahighaccuracyoftheapproach,regarding
parameterestimation,aswellasuncertaintyquantification. Additionalrobustnesscheckshighlight
thegeneralizationandextrapolationcapabilitiesofthemodel,whileanapplicationtoprecipitation
extremesacrossWesternGermanydemonstratestheusabilityofourapproachinreal-worldscenarios.
Keywords Extremestatistics Parameterestimation Generativeneuralnetworks
· ·
1 Introduction
Asthefrequencyofextremeweathereventsrises,itbecomesincreasinglycrucialtounderstandanddetectthemat
theearliestopportunity. Statisticalmodelsprovideawaytoenhancetheirinterpretabilityandofferinsightsintothe
connectionsbetweenextremeevents. Sincegeophysicaldataisoftencoupledacrossbothspaceandtimethisposes
challengesformodeling,oftenleadingtohighlycomplexstatisticalmodels. Forspatialdata,suchasprecipitation,a
commonwaytodescribeandanalyzeextremesaremax-stableprocesses,whichariseastheuniquelimitofpointwise
maximaofrandomfields. Theseprocessesareanessentialtoolinanalyzingspatialextremes(Davisonetal.,2012),as
theyallowforflexiblemodelingoftheunderlyingdependencestructure. However,whenitcomestomodelingthese
extremes,usuallyonlyafewobservationsareavailable,evenlesssoastheunderlyingprocessisusuallychanging
acrosstime. Forthatreasontraditionalstatisticalmethodsoftenfailtoidentifyparameterscorrectly,particularlyas
thesemodelsarehighdimensionalandcomplex. Furthermore,estimatingparametersbecomesespeciallychallenging
whendealingwithextremevalues. Therefore,specifyingadistributionratherthanrelyingonpointestimatorscanbe
beneficialforquantifyinguncertainty. Whiletherewasarecentfocusonnewmethodsforparameterestimation,mainly
∗Currentaffiliation:Ludwig-Maximilians-Universität,Munich
4202
luJ
11
]LM.tats[
1v86680.7042:viXraESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
employingneuralnetworks,thesetypicallyfallshortofprovidingadequateuncertaintyestimates,astheyareusually
basedonbootstrapsampling.
Inthiswork,weproposeanestimationapproach,basedongenerativeneuralnetworks,thatallowsforestimationand
uncertaintyquantificationnotonlyforthemodelparameters,butalsoforthespatialdependenceacrossextremes.Thisis
achievedbytraininganeuralnetworkonsimulatedmax-stableprocessesandpredictingafull(sample-based)parameter
distributionofthecorrespondingmax-stablemodel. Thishastheadvantagethatanyfunctionalofinterest,e.g. meanor
confidenceintervalscanbeobtainedeasilyfromthepredictedsamples. Ourworkcombinesrecenteffortsinneural
networksforpointestimation(Lenzietal.,2023;Sainsbury-Daleetal.,2022)withadvancementsintraininggenerative
neural networks with proper scoring rules (Pacchiardi and Dutta, 2022; Chen et al., 2022). Using these methods,
weofferacompleteapproachtoestimatethefullparameterdistribution,allowingfordeterministicandprobabilistic
evaluationofparametersorcorrespondingfunctionalsoftheunderlyingmodelsimultaneously. Furthermore,weextend
thisapproachtononparametricallyestimatethedistributionofthepairwiseextremalcoefficientfunction,whichisa
commonlyappliedtooltocharacterizetheextremaldependencebetweentwolocationsofamax-stableprocess. This
unifiedapproachoffersawaytoidentifyparametersinvariousmax-stablemodelsandtoassessuncertaintyinspatial
dependenceestimations,eveniftheunderlyingmodelisunknown,whichisoftenthecasewithrealdata. Comparison
toestablishedmethods,suchastheABCmethod,highlightstheadvantagesofourapproaches,especiallyconsidering
uncertaintyquantification. Furthermore,weevaluatethemodelpredictionsagainstseveralscenariosofmisspecification,
whichnaturallyoccurifworkingwithrealdata.
Fromastatisticalviewpointitisnaturaltoprovideamaximumlikelihoodestimationfortheparametersofastatistical
model. However,inthecaseofmax-stableprocesseseveninmoderatedimensions,thelikelihoodcontainstoomany
termstobeevaluatedinreasonabletime. Improvementscanbemadebyconsideringoccurrencetimesofmaxima
(Stephenson and Tawn, 2005; Huser et al., 2019), leading to a computable likelihood function but a highly biased
estimator (Huser et al., 2016). A more common approach proposed by Padoan et al. (2010) is to replace the full
likelihoodbytheapproximatepairwiselikelihood,whichhowevercomeswithalossofstatisticalefficiency(Huserand
Davison,2013;Castruccioetal.,2016). OthermethodsincludeusingtherelatedVecchiaapproximation(Huseretal.,
2022)oranexpectation-maximizationalgorithm(Huseretal.,2019),butparameterestimationinmax-stableprocesses
remainsanongoingfieldofresearchinextremevaluetheory.
Differentapproacheshavebeenproposedthatavoidevaluatingthelikelihoodfunctionaltogether,oftenreferredtoas
likelihood-freemethods. Thesearemostoftenbasedontheassumptionthatitispossibletosimulatefromthegiven
modelandusethesesimulationstoproduceanestimateofthetrueparameters. Themostpopularofthesemethodsisthe
approximateBayesiancomputation(ABC)framework(Beaumontetal.,2002;Franks,2020). Bysamplingparameters
fromsomepriordistribution,simulatingfromthemodelandminimizingsomesuitablesummarystatisticsbetweenthe
simulationsandtheobservations,themethodretrievesaposteriorparameterdistribution. However,whilesummary
statisticshavebeendevelopedforspecialpurposes,suchasmax-stableprocesses(ErhardtandSmith,2012;Fearnhead
andPrangle,2012),thechoiceisnotobviousandrequirescalibration. Inaddition,theapproachrequiresalargeamount
ofsimulationsinordertoproduceagoodestimate,makingitinfeasible.
Quiterecently,neuralnetworksanddeeplearningapproachesingeneralhavegainedincreasingpopularityinlikelihood-
freeinference. Creel(2017)trainaneuralnetwork,similartotheABCapproach,onahighlyinformativesummary
statisticsandapplytheirmethodtotwoeconometricmodels. Inaverysimilarapproach,Raietal.(2023)useasummary
statistic,basedonextremequantilestoestimateparametersofanextremevaluedistribution. Theirresultssuggest
similaraccuracy,ascomparedtoclassicalML-estimation,butanincreaseincomputationalspeed. Consideringspatial
data, Gerber and Nychka (2021) use a neural network to perform local covariance estimation for spatial Gaussian
processes,whileLenzietal.(2023)estimatetheparametersofamax-stableprocessdirectlyfromtheobservations
byutilizingaconvolutionalneuralnetwork. Sainsbury-Daleetal.(2022)proposeaso-calledneuralBayesestimator
thatminimizestheBayesriskofanestimatortoestimateparametersofdifferentspatialmodels,includingmax-stable
processes. Themainadvantageofsuchapproachesisthattheyarelikelihood-free,workwithverysmallsamplesizes
andcanbemuchfasterthanclassicalmethods.
Incomparisontomostofthepreviousmethods,ourapproachhastheadvantagethatitgivesaccesstothefullparameter
distribution,thusrequiringnoadditionalstepsforassessingtheparameteruncertainty. Furthermore,weextendthe
estimationproceduretodirectlyestimatingtheextremalcoefficientfunction,whichisanimportanttooltoanalyze
thedependencestructureacrossthespatialextremes. Theremainderofthisarticleisorganizedasfollows. Section
2outlinesthetheoryregardingmax-stableprocesses,aswellastheoreticalbackgroundonourapproach. Section3
entailsthespecificimplementationoftheapproach,evaluationmetricsandextensiveresultsofsimulationstudies,as
wellasadditionalrobustnesschecks. Section4illustrateshowtheapproachcanbeappliedtoarealdatascenario,by
estimatingthedependencestructureofprecipitationextremesacrossWesternGermany,whileSection5concludesand
futureresearchisoutlined.
2ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
2 Methodology
Asmentionedintheintroduction,wefocusonmodellingspatialextremesusingmax-stableprocesses,whichariseas
theuniquenon-degeneratelimitofrenormalizedpointwiseblockmaximaofi.i.d. randomfieldsandarethereforea
widelyusedtoolforanalyzingspatialextremes(Davisonetal.,2012;DavisonandHuser,2015). Section2.1contains
thenecessarytheoreticalbackgroundonmax-stableprocessesitscharacteristicsandmeasuresofspatialdependence,
whileSection2.2introducesourproposedmodelingandestimationframeworkofspatialextremes.
2.1 Setup
Inthisarticle,weconsiderthefollowingdefinitionofamax-stableprocess,duetoSchlather(2002). Let Rd,
ξ i, i N denotethepointsofanonnegativePoissonprocesson(0,
)withintensitymeasuredΛ(ξ)=ξ−X2d⊆
ξand
{ ∈ } ∞
letY()denoteanonnegativestochasticprocessdefinedonRdsuchthatE[Y(x)]=1, x Rd. Then
· ∀ ∈
Z(x)=maxξ Y (x), x (1)
i i
i≥1 ∈X
definesamax-stableprocesswithunitFréchetmargins,2whereY ()arei.i.d. copiesofY(). Differentsuitablechoices
i
· ·
ofY()leadtodifferentmax-stableprocesses. Wewillfocusontwodifferentmodels: TheBrown-Resnick(Kabluchko
·
etal.,2009)andtheSchlather(Schlather,2002)model.
• TheBrown-ResnickmodelarisesifY (x)=exp ϵ (x) γ(h) ischosenin(1),whereϵ areindependent
i i i
{ − }
copiesofacenteredGaussianprocesswith(semi-)variogramγ(h)andspatialseparationh.Atypicalchoiceis
γ(h)=( h /λ)ν,withrangeparameterλ>0andsmoothnessparameterν (0,2]. Duetotheirflexibility,
∥ ∥ ∈
Brown-Resnickmodelsareoftenappliedinpractice(compareThibaudetal.,2016;Oestingetal.,2017).
• TheSchlathermodelalsocomesfromrepresentation(1),withY (x)=√2πmax 0,ϵ (x) ,whereϵ (x)are
i i i
{ }
i.i.d. copiesofastandardGaussianprocesswithcorrelationfunctionρ(h). Thecorrelationfunctionisusually
chosenfromachoiceofvalidparametricfamilies. Commonexamplesarethepoweredexponentialcorrelation
function
ρ(h)=exp( ( h /λ)ν), λ>0, ν (0,2],
− ∥ ∥ ∈
ortheWhittle-Matérncorrelationfunction
21−ν (cid:18) h(cid:19)ν (cid:18) h(cid:19)
ρ(h)= K , λ>0, ν >0,
ν
Γ(ν) λ λ
whereΓisthegammafunctionandK isthemodifiedBesselfunctionofthethirdkindwithorderν. In
ν
bothcases,λandν againdenotetherangeandsmoothnessparameterrespectively. Themax-stableprocesses
oftheSchlathermodelareisotropicandstationary. TheSchlathermodelhasbeenappliedforexampleto
precipitationmaxima(DavisonandGholamrezaee,2012)ortotemperatureminima(ErhardtandSmith,2012).
From Equation 1 one can derive the joint cumulative distribution of Z(x) at a finite collection of spatial sites
x ,...,x andthecorrespondingprobabilitydensityfunctionas
1 k
{ }⊂X
|π|
(cid:88) (cid:89)
f(z ,...,z ;γ)=exp( V(z ,...,z )) ( 1)|π| V (z ,...,z ), (2)
1 k
−
1 k
−
πj 1 k
π∈Pk j=1
whereγ = (λ,ν)T istheparametervector, denotesthesetofallpartitions π ,...,π oftheset x ,...,x
k 1 k 1 k
P { } { }
and π = l is the size of the partition π, while V denotes the so called exponent measure (de Haan and Ferreira,
| |
2006)andV =
∂|πj|
V(z ,...,z )itspartialderivativeofwithrespecttothevariablesindexedbythesetπ . For
πj ∂zπj 1 k j
reasonsofnotation,thedependenceofthefunctionsV andwontheunknownparameterγ isomitted. Thenumber
oftermsinvolvedinEquation2quicklyexplodes,asitissummedoverthesetofallpossiblepartitions. EvenifV
isanalyticallyavailable,thenumberofelementsπ ,calledtheBellnumber,istoolargetomaketheexpression
k
∈P
computationallytractable. Castruccioetal.(2016)concludethatevenforprocesseswhereclosedformexpressionsare
available,calculatingthefulllikelihoodisnotpossiblefork >12.
Eventhoughthefullformmightnotbeavailable,onecanstilltakeadvantageoftheconceptofmaximum-likelihood
estimationanditsproperties. Typically,oneconsidersthepairwiselikelihood(Padoanetal.,2010;Davisetal.,2013),
whichisdefinedas
k−1 k
(cid:88) (cid:88)
ℓ (γ;z)= w logf(z ,z ;γ), (3)
p i,j i j
i=1j=i+1
2ThismeansthatP(Z(x)≤z)=exp(−1/z), z>0.
3ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
wherez =(z ,...,z )isasingleobservationandf(, ;θ)isthebivariatepdf,obtainedfromEquation2. Inorderto
1 k
· ·
reducecomputationalcomplexityandimprovestatisticalefficiencyoftheestimator,theweightsw canbechosen
i,j
accordingly,forexamplebasedonacutoffdistance(Padoanetal.,2010). Sincethisestimatorisunbiasedandconverges
toanormaldistribution,confidenceintervalsandstandarderrorscanberetrievedeasily. However,ifthesamplesizeis
small,thepairwiselikelihoodcanbehighlybiased.
Asdescribedearlier,measuringandanalyzingthedependencestructureacrossspatialextremes,isofgreatimportance.
Ausefulquantityforthatmatteristheso-calledpairwiseextremalcoefficientfunction,definedby
θ(h)= zlogP(Z(x 1) z,Z(x 2) z)=E[max Y(x 1),Y(x 2) ], (4)
− ≤ ≤ { }
whereY()comesfromtherepresentationin(1)andh = x x . Ascanbeseen, θ(h)isdirectlyrelatedto
1 2 2
· ∥ − ∥
theprobabilitythattwospatialsitesdonotexceedacommonthresholdzandprovidesameasureofthedependence
betweentwospatiallocations. θ(h)liesintherange[1,2],withthelowerboundcorrespondingtocompletedependence
and theupper bound toindependence of thetwo spatial locationsand is analyticallyavailable fora wide rangeof
models.
2.2 Estimationframework
This section first outlines our approach for modeling spatial extremes by estimating the parameter distribution of
max-stablemodelsusinggenerativeneuralnetworks. Afterwardsitdemonstrateshowthisapproachcanbeextended
todirectlyestimatethepairwiseextremalcoefficientfunctionanditscorrespondingdistribution. LetZ()denotea
·
γ Π (γˆ )m Π( z)
∼ j j=1∼ ·|
1.Drawparameter 2.Simulatemax-stable 3.Feedthroughneuralnetwork 4.Estimateofposterior
frompriordistribution processZ P( γ) parameterdistribution
∼ ·|
Figure1: Thefigureshowstheparameterestimationsetup,foratwo-dimensionalmax-stableprocess. Inthetraining
phase,allfourstepsarerunmultipletimes,andthenetworkistrainedonthelossbetweenthedrawnparametersandthe
estimatedparameters. Forinference,onlysteps3and4arerequired.
max-stableprocesson R2andΓ R2 denotethecorrespondingparameterspace. Thedistributionandlikelihood
X ⊆ ⊆ +
functionofthemodelaredenotedbyP( γ)andp( γ),whereγ = (λ,ν)⊤ Γistheparametervectorofthe
· | · | ∈
max-stableprocess.Similarly,ΠandπdenotethepriordistributionanddensityontheparameterspaceΓ,whileΠ( z)
·|
and π( z) denote the respective posterior distribution and density given the observation z. Classical parameter
· |
pointestimationaimsatestimatingγ fromthedatazusingamappingfromthesamplespacetotheparameterspace
γˆ : Γ. However,asweareinterestedininformationonthefullposteriordistributionoftheparameterγ,we
X →
requireamappingfromthesamplespacetothefullposteriordistribution,e.g.
Q(γ ): , z Π(γ z),
|· X →P (cid:55)→ |
where denotesasuitableclassofprobabilitymeasures. Itisimportanttokeepinmindthatsofarweareonlyworking
P
withsimulatedprocesseszandthereforehavefullaccesstothedatageneratingprocess,aswellasthetrueparameters
andcorrespondingfunctionals,asdepictedinFigure1. Thisisespeciallyrelevant,asweareworkingwithstatisticsof
extremes,whichinapplicationsettingsareusuallynotelicitible,i.e. theycannotbetheuniqueminimizerofsomeloss
function(BrehmerandStrokorb,2019).
Inordertoestimatetheparameterdistribution,wefollowPacchiardiandDutta(2022)andutilizeagenerativeneural
networktolearnanapproximateposteriordistributionQϕ( z)givena(simulated)observationz,whereϕdenotes
·|
thenetworksparameters. ThenetworkcanbedefinedviathemappingF : Γthattransformssamples
ϕ
S ×X →
fromsomeprobabilitydistributionPsoverthespace ,usuallyaGaussiandistribution,conditionedontheobserved
S
max-stableprocessz . SamplesoftheapproximateposteriordistributionQϕ( z)arethenobtainedbyaforward
∈X ·|
passthroughtheneuralnetwork. Inageneralsetting,weareworkingwithfiniteobservationsofparameter-simulation
4ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
pairs(γ i,z i)n i=1,whereγ
i
∼Πisgeneratedfromthepriorparameterdistributionandz
i
∼P( ·|γ i)issimulatedfrom
theunderlyingmodel. Usingthesesamples,theaimistotrainthenetworkparametersϕ,suchthatitmatchesthetrue
distribution,e.g. Qϕ( z) Π( z)forallz . Differentoptionsareavailablefortrainingagenerativeneural
·| ≈ ·| ∈X
networkinordertoproduceanapproximateposterior,suchasadversarialtraining(Rameshetal.,2022)orinvertible
neural networks (Radev et al., 2022). However, we focus on a recently developed method that trains a generative
networkbyminimizingaproperscoringrule. Theresultingnetworkhastheadvantagethatitdoesnotsufferfrommode
collapseandcanbetrainedinafairlysimpleway. ThismethodwasintroducedbyPacchiardietal.(2024)andhasbeen
successfullyappliedforexampletomultivariateforecasting(Chenetal.,2022).
Inordertoobtaintheunderlyingdistribution,asuitablescoringfunctionhastobechosenasthelossfunctionofthe
network. Scoringrulesareaclassoffunctionsthatassignanumericalscoretothedistancebetweenaprobability
distributionandarealizedobservation. Moreprecisely,ascoringruleS(P,y)(GneitingandRaftery,2007)measures
thediscrepancybetweenaprobabilitydistributionPandacorrespondingobservationy ofarandomvariableY. If
Y P′,theexpectedscoringruleisgivenasS(P,P′):=EY∼P′S(P,Y). Iftheexpectedscoringruleisminimizedby
the∼ truedistributionP′,thescoringruleS issaidtobeproper. Iftheattainedminimumisunique,itiscalledstrictly
proper. Foroursettingofmax-stableprocessesthismeansthataproperscoringruleattainsitsminimum,whenthetrue
parameteroriginatesfromthepredicteddistribution,e.g. γ Qϕ( z). Utilizingthenotionofproperscoringrules,
∼ ·|
ourgenerativenetworkcanbetrainedbysolving
argminEγ∼ΠEZ∼P(·|γ)S(Qϕ( Z),γ),
·|
ϕ
whereQϕ( z)denotestheapproximateposteriorofthenetwork(PacchiardiandDutta,2022). Thesolutionofthe
·|
aboveexpressionleadstoQϕ( z) = Π( z)almosteverywhere. Themostwidelyusedscoringruletoevaluate
· | · |
probabilisticforecastsistheContinuousRankedProbabilityScore(CRPS, GneitingandRaftery,2007). Whendealing
withobservationsz Rminsteadofz RtheenergyscoregeneralizestheCRPSandcanbeappliedtodistributional
∈ ∈
forecastsofvector-valuedquantityinsteadofsinglevalues(GneitingandRaftery,2007). Whileinprinciplemany
choicesofScoringRulesareavailable(comparePacchiardietal.,2024),wefocusonusingtheenergyscore,asit
is strictly proper under mild regularity conditions and therefore admits a unique minimum. In the same setting as
above,theenergyscoreisgivenbyES(P,y)=E(cid:2) Y y β(cid:3) 1 E(cid:2) Y Y′ β(cid:3) ,whereY,Y′ i.i.d Pandβ (0,2).
∥ − ∥ −2 ∥ − ∥ ∼ ∈
However,aclosedformsolutionofthescoringruleisusuallynotadmissible,anditneedstobereplacedbyanunbiased
estimatorthatisevaluatedusingmsamplesgeneratedbytheneuralnetwork.3
Transferringthistooursettingofmax-stableprocesses,consideratrueparameterγ Π( z)andsamplesfromthe
approximateposterioroftheneuralnetwork(γˆ j)m
j=1 ∼
Qϕ(
· |
z). Usingβ = 1w∼ eutil· iz| ethefollowingunbiased
estimator(PacchiardiandDutta,2022):
m m
1 (cid:88) 1 (cid:88)
ES(Qϕ( z),γ)= γˆ
j
γ
2
γˆ
j
γˆ
k
2. (5)
·| m ∥ − ∥ − 2m(m 1) ∥ − ∥
j=1 − j,k=1
k̸=j
Themainadvantageofsuchanapproachisthatbyusingtheestimateoftheposteriordistribution,anyfunctionalof
interest,forexampleconfidenceintervalscanbederived. Thisisespeciallyimportant,sincewearetryingtoreplace
classicallikelihood-estimation,whichsuppliestheseinformationingeneral. Avisualizationofthecompleteestimation
workflowcanbefoundinFigure1.
Withasimpleextension,thisapproachcanalsobeusedtoestimatethepairwiseextremalcoefficientfunctiondirectly,
onlyrequiringlittlechangesinthesetup. Foragivenmax-stableprocess,considerθ :(0, ) [1,2], h θ(h)to
∞ −→ (cid:55)→
bethecorrespondingtruepairwiseextremalcoefficientfunction. Wenowwanttosamplefromthe(functional)posterior
distribution using the same approach as before. To achieve that goal, we discretize the function θ(h) with a finite
numberofpointsh 1,h 2,...,h k, k Nandfunctionvaluesθ(h 1),...,θ(h k). Inadditionwecanalwaysseth
0
=0
∈
andθ(h )=1. Wenowuseournetworktoestimatethevectorθ(h ):=(θ(h ),...,θ(h ))T andwerestrictthe
0 disc 1 k
valuestoliebetween(1,2). Asintheparameterestimationsetupweusetheenergyscoreasalossfunctiontotrainour
(cid:16) (cid:17)T
modelbutcalculatethescorewiththeestimatedsamplesθˆ (h ):= θˆ (h ),...,θˆ (h ) , j =1,...,mofthe
j disc j 1 j k
functionvaluesθ(h ). Theadjustedestimatorforthefunctionalenergyscoreisgivenas
disc
1 (cid:88)m (cid:13) (cid:13) 1 (cid:88)m (cid:13) (cid:13)
ES := (cid:13)θˆ (h ) θ(h )(cid:13) (cid:13)θˆ (h ) θˆ(h )(cid:13) . (6)
θ m (cid:13) j disc − disc (cid:13) 2− 2m(m 1) (cid:13) j disc − l disc (cid:13) 2
j=1 − j,l=1
l̸=j
3ContrarytoforexampleGANs,thisapproachthereforerequiresalargeenoughamountofoutputsamplesinordertoconverge.
5ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
Withtheintroducedframework,wecannowestimateposteriorparameterdistributionsofmax-stableprocessesand
functionalsofinterestwithorwithoutanunderlyingmodelassumption.
3 Simulationstudies
Inthissectionweconductseveralsimulationstudiesthathighlighttheusabilityoftheproposedapproachinthesetting
ofmax-stableprocesses. WeapplyourmethodtothepreviouslyintroducedBrown-ResnickandSchlathermodeland
provideadetailedanalysisofthemethodsrobustness. Anadditionalfocusisputonproperevaluationofthemodels,
incorporatingmeasuresofspatialdependenceandevaluationofuncertainty. Finally,weprovideinsightsinhowthe
modelscanbetrainedmoredataefficiently.
3.1 Neuralnetworkmodel
EN
λ,ν
λ
m
λ
1
Linear
m ν m
1 2 ν
1
Sigmoid
×
m
m
128 128 7
Lin1 ea11 r52 1 64 1 32
θ
1kθ m ...k
...
64 64 15 m θ1
32 3230 m
aC no dn mvo al xu -t pio on ol m 1 k θ1
1
11152 EN
θ
N(1,Im)
Figure2: Thefigureshowstheproposedmodelarchitecture. Thespatialfieldisfedthroughthreeblocksconvolutional
andmax-poolinglayers. Acrosstheblocks,theoutputsizedecreases,whilethechannelsizeincreases. Inthesecond
andthirdblock,residualconnectionsareadded,markedbythearrowsontop. Aftertheconvolutionallayersthenetwork
isflattenedandfedthroughsomefinallinearlayers, whereGaussiannoiseismultipliedontoptofinallycreatem
outputsamples. Forparameterprediction,samplesofλ,ν arecreated,whileforthedirectestimationoftheextremal
coefficientfunction,samplepointsofthefunctionarepredictedasθi :=θˆ (h ).
j j i
In order to assess the performance of our proposed approach we evaluate different simulation scenarios, based on
max-stable models. We use the previously introduced Brown-Resnick and Schlather model with k = 900 spatial
locationsuniformlydistributedonthedomain =[0,30] [0,30]. Asweareassumingthattheunderlyingprocess
changesacrosstime,ourapproachaimsatproviD dingestimat× esfromasingleprocessobservation.4 Forthesimulations,
similartoErhardtandSmith(2012),weaimatusingminimallyinformativepriorsbyutilizingΠ (a,b),wherethe
∼U
parametersdifferacrossthesimulationscenarios. TherealizationsoftheprocessesareobtainedusingtheR-package
SpatialExtremes(Ribatet,2022).
Asweareworkingwithtwo-dimensionalspatialdataonaregulargrid,convolutionalneuralnetworks(CNNs)area
naturalchoiceofarchitectureandhavebeensuccessfullyappliedtomax-stableprocesses(Lenzietal.,2023;Sainsbury-
Daleetal.,2022). Figure2showsavisualizationofthenetwork. AlllayersareequippedwithReLuactivationfunctions,
exceptforthefinallayers. Sinceν (0,2],wetransformittotheunitintervalanduseasigmoidactivationfunction.
∈
4Ifthisassumptionisrelaxed,thenetworkcaneasilybeadjustedtoprocessingmultiplesamples,byusingthreedimensional
convolutions.
6ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
Forλweemployalog-transformandalinearactivationfunction,similartoLenzietal.(2023),whileforthevalues
ofθ(h ),...,θ(h )notransformationisrequiredandweuseasigmoidactivationfunctionscaledtotherange(1,2).
1 n
Wespecifythenetworktocreatem = 500samplesfromtheposteriordistributionbysamplingfromalatentspace
(1,I )andmultiplyingittoalinearlayer(compareFigure2).
m
N
Fortrainingthenetwork,themainbottleneckliesinthesimulationoftheprocessesusedastrainingdata.Whiledifferent
methodshavebeenproposedandevaluated,suchasusinganinformativeprior(Lenzietal.,2023)orsimulatingnew
dataduringtraining(Sainsbury-Daleetal.,2022),wewanttofocusonutilizingtechniquesfromimageaugmentation.
Imageaugmentationreferstotheprocessofrotating,flippingordistortingimagesandusingthemasadditionaltraining
data(PerezandWang,2017). Whilenotallofthesemethodscanbeused,asweneedtopreservethestructureofthe
max-stableprocess,wecanstilltakeadvantageofthegeneralidea. AstheBrown-ResnickandSchlathermodelare
stationaryandisotropic,meaningthatthepropertiesoftheprocessesacrossthespatialdomainonlydependontheir
distance,wecanutilizeimageaugmentationtechniquesthatdonotdistortthedistancebetweenspatiallocations. For
thatpurposeweuseanimagerotationof180°andverticalandhorizontalimageflipswithprobability0.3and0.2
respectively.
The network is trained minimizing the Energy Score with the RMSProp optimizer implemented in PyTorch and a
learningrateof7e−4usingalearningrateschedulerthatstopstrainingifthemetricsdonotimprove. Ineachepochthe
weightsareupdatedacrossadatabatchofsize100. Theparameterswerechosenbasedonsomeminorexperiments,
extensivehyperparametertuningisleftasfuturework. StudieswereconductedusingaworkstationwithanIntelXEON
E5-26802.50GHzCPUwith40coresandanNVIDIAGeForceRTX2080with8GBofGPURAM.Reproducible
codecanbefoundathttp://www.github.com.
Asacomparison,weimplementseveralbenchmarkmethods. First,weusethepreviouslydescribedpairwiselikelihood
method,where,followingLenziandRue(2023),theoptimizerisrunfrom20startingvalues,fromwhichthe5best
estimatesareagainusedasstartingvalues,leadingtothefinalestimate. Thecutoffforweightsischosenas5andthe
estimatorisfittedusingthefunctionfitmaxstaboftheR-packageSpatialExtremes(Ribatet,2022). Furthermorewe
employtheABCmethod,whichisbasedontheideaofgeneratingmanysimulationsofaprocessandcomparingthose
totheobserveddata,usingsomesummarystatisticS. Usingapre-specifiedcutoffdistance,thealgorithmoutputsm
sampleswiththebestvalueofS. FollowingErhardtandSmith(2012),weusethetripletwiseextremalcoefficientasa
summarystatistic. Asthemethodisnotfeasibleforalargenumberofspatiallocations,themax-stableprocessesare
downsampledtoagridofsize5 5,usingbilinearinterpolation. Wegenerate50000independentsimulationswith
×
25processeseachtocompareagainsttheobserveddata,wherethecutoffischosensuchthatthealgorithmresultsin
m = 500samples. Finally,wealsocompareourmethodstoa“regular”implementationoftheCNNwiththesame
hyperparametersbutminimizingthemeansquarederror,whichisthesettinginLenzietal.(2023). Fortherestofthis
article,wewillrefertothenetworksasEN andEN fortheparameterestimationanddirectestimation,respectively.5
λ,ν θ
3.2 Evaluation
In order to completely assess the adequacy of the estimations, a detailed evaluation procedure for the max-stable
processesisrequired,whichisintroducedinthissection. Whilethenetworkoutputsafull(sample-based)distribution,
oneisgenerallymoreinterestedinspecificfunctionalsorcharacteristicsofit. Forthatreason,werestricttheevaluation
to important and commonly used quantities. However, since our method is not specifically tailored to the energy
score,anyfunctionalcanbeevaluated,aslongasitadmitssomesortofempiricalestimator. Specifically,weprovide
evaluationforthemeanandintervalpredictionsforγ andθ(h),aswellasanadditionalmeasuredeterminingthefitof
thecompletedistribution. Byprovidingthesedifferentperformancemetrics,wecanassessthepredictivepowerofthe
estimator,whilesimultaneouslyanalyzingtheuncertaintyinthepredictions.
Toevaluatetheparameterestimation,weemploythetypicalmeansquarederror(MSE)asametric,whichisgivenby
MSE λ(γˆ,γ):=E[ λˆ λ 2]fortheparameterλandforνsimilarly. Inordertoassesstheuncertaintyoftheprediction,
∥ − ∥
recall that the model outputs m samples from the posterior parameter distribution. In order to obtain uncertainty
intervalsforeachparameterseparately,thecorrespondingempiricalquantilescanbeestimatedfromthemodeloutput.
Atypicalwaytoassessthequalityofapredictionintervalistousetheso-calledintervalscore(ISGneitingandRaftery,
2007). Letλbethetruerangeparameterandl ,u denotethelowerandupperendpointsofthepredictiveinterval,e.g.
thequantilesat(cid:0)α,1 α(cid:1)
.
Thentheintervalα scoα
reforthatparameterisgivenby
2 − 2
2 2
IS (l ,u ):=(u l )+ (l x)1 λ<l + (λ u )1 λ>u . (7)
α,λ α α α α α α α α
− α − { } α − { }
Theintervalscoreisaproperscoringrulewithrespecttothecorrespondingquantilesandalowerscorecorresponds
to a better prediction. For the parameter ν the score is calculated in the same way. While the interval score is
5ENasanabbreviationforenergynetwork.
7ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
helpfultoquantifytheuncertaintyestimate,itcanonlybeusedforeachparameterseparately. Inordertoassessthe
fullpredicteddistributionQϕ( z)ofthemodelwecanusethealreadyestablishedenergyscore(5). Asdescribed
·|
previously,theenergyscoremeasuresthediscrepancybetweenthetrueparameterγ andthepredictedposteriorsamples
(γˆ)m
j=1
∼Qϕ( ·|z).
Sofar,thefocuswassetonevaluatingthefitoftheparametersλ,ν thatspecifythemax-stableprocess. However,as
therelationbetweenthemodelanditsparametersishighlynonlinear,aseeminglybadparameterestimatemightstill
leadtoagooddependenceestimate. Inaddition,focusingonlyontheparameterfitdoesnotallowforcomparison
betweendifferentmax-stablemodels. Forthatpurpose,weextendtheMSEtomeasuretheerrorintheestimatedspatial
dependence. Denotebyθ(h;γ)thepairwiseextremalcoefficientfunction(4)ofthemax-stablemodelspecifiedbyγ.
ThenwecanusethefollowingintegratedmetricbasedontheL2norm:
(cid:20)(cid:90) ∞ (cid:21)
MSE θ(γˆ,γ)=E θ(h;γˆ) θ(h;γ) 2dh . (8)
∥ − ∥
0
Thisexpressioncanbeinterpretedastakingthepointwisemeansquarederroroftheextremalcoefficientathand
averageitoverallpossibledistancesh R+. Thisallowsforevaluatinghowtheestimatedparameterstranslateto
∈
thespatialdependenceandtocomparedifferentmax-stablemodels. Astheparameterscoulddifferormightnothave
thesameinterpretation,evaluatingtheMSEontheparametersaloneisnotenoughforafullassessmentofthemodel
prediction.
Similarasbefore,wealsowanttoassesstheuncertaintyinthepredictionofthespatialdependence. Forthatpurpose,
wecanusethepreviouslyestablishedintervalscore(7)tobuildpointwiseconfidenceintervalsforθ(h). Theresulting
intervalspecifiesboundsinwhichthetruefunctionlieswithprobabilityα. Forafixeddistanceh,theintervalscore
canbecalculatedbytakingtheempiricalα-quantileofthefunctionsθ(h;γˆ ), i=1,..,m. Theintervalscoreoverthe
i
wholefunction,canagainbeachievedviaintegrationas
(cid:90)
IIS := IS (ˆl (h),uˆ (h);θ(h;γ))dh, (9)
α α α α
h>0
whereˆl (h),uˆ (h) are the empirical quantiles evaluated at h and θ(h;γ) is the true extremal coefficient function.
α α
UtilizingEquation6wecanagainusetheenergyscoretoassessthefitofthewholepredictivedistribution.
AsthepairwiselikelihoodandtheregularCNNdonotincorporateuncertaintyestimations,thecorrespondingmetrics
do not apply. Furthermore, since the probabilistic methods generate multiple samples as the output, these need to
be aggregated for evaluation. For the MSE of the parameters, the estimation is simply given by the sample mean,
whilefortheextremalcoefficientfunction,apointwisemeanfunctionisused. Asthedirectestimatorisdiscretized
ath ,...,h points,theintegralmetricsareapproximatedviaasumoverthosesupportpointsinordertomakeall
1 k
methodscomparable.
3.3 Results
Asafirstcomparison,forbothmax-stablemodelsatestsetofparametersandsimulatedprocessesisgeneratedby
(λtest,νtest): λtest (0.5,5), νtest (0.3,1.8), i=1,...,250, (10)
i i i ∼U i ∼U
whichcoversawiderangeofparametercombinationsanddifferentspatialdependencies. Thetrainingsetofsizen=
5000isgeneratedfromthesameparameterspace,with20%ofthedatausedasvalidationdata. Thedirectestimationof
θ(h )requiresanupperboundofh,sincethenetworkcanonlybetrainedforafinitenumberofpoints. Wedecide
disc
(cid:0) (cid:3)
toconsidersimplyh 0,√30+30 ,whichisthemaximalspatialseparationacrossthemax-stableprocessesonthe
∈
30 30grid. Takinganintervaldistancedh=0.1leadstothesupportpointsh =0.1,h =0.2,...,h =42.5.
1 2 425
×
Oneproblemofdirectlyestimatingvaluesofthepairwiseextremalcoefficientfunctionisthatthereisnoguaranteefor
theresultingfunctiontostillbemonotone,whichisamaincharacteristicofθ(h). However,thisissuecanbesolved
bypermutationoftheestimatedvalues. Asourapproachnotonlypredictsasinglefunctionθ(h ), i = 1,...,425
i
butafullsampledistribution,theorderofpermutationandfunctionalcalculationneedstobeconsidered. Ifoneis
interestedforexampleinthemeanpredictionofθ(h),firstthemeaniscalculatedθˆ(h ),i=1,...,425andafterwards
i
theresultingfunctionalispermuted,suchthatθˆ(h ) θˆ(h ) ... θˆ(h )(AppendixBincludesfurtherdetails).
1 2 425
≤ ≤ ≤
Thefullresultsforbothmax-stablemodelsaregiveninTable1. Ascanbeseen, theenergynetworkhasthebest
performanceacrossmostmetricsandbothmodels. Especiallyfortheerrorregardingtheextremalcoefficientfunction,
the method is much better than the benchmark methods, with significant additional improvements by the direct
estimation. However,fortheparameterestimation,theperformanceoftheregularCNNisusuallyquitesimilarandin
8ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Brown-Resnick
    
   
    
        
    
   
    
        
    
   
    
    
                                                      
h
    
   
    
        
    
   
    
        
    
   
    
        
                                                      
h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
(b)Schlather
    
   
    
        
    
   
    
   
    
        
    
   
    
                                                      
h
    
   
    
   
    
   
    
        
        
        
        
        
                                                      
h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure3: Thefigurevisualizesthedifferentestimationmethodsforthemax-stablemodelsusingaselectedtestsample
((λ,ν) = (1.51,1.37)fortheBrown-Resnickand(λ,ν) = (2.25,0.69)fortheSchlathermodel). Ineachfigurethe
upper left panel shows the different location estimates, while the upper right panel shows the estimated extremal
coefficientfunctions. Thelowerleftpanelshowsthesample-baseddistributionestimatesoftheABCandEN method
λ,ν
andthelowerrightpanelshowstheestimatedpointwiseconfidenceintervals(α=0.05)fortheextremalcoefficient
function.
9
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
PL CNN ABC EN EN
λ,ν θ
MSE 3.19(20.44) 0.43(0.89) 1.61(1.79) 0.38(0.85) -
λ
MSE 0.13(0.22) 0.02(0.04) 0.26(0.32) 0.01(0.02) -
ν
MSE 0.71(1.20) 0.19(0.34) 1.33(1.67) 0.15(0.25) 0.16(0.27)
θ
Brown- IS - - 4.59(3.03) 3.03(6.43) -
0.05,λ
Resnick IS - - 3.43(6.53) 0.55(0.49) -
0.05,ν
IIS - - 53.83(93.44) 10.66(14.19) 13.71(23.00)
0.05
ES - - 0.85(0.43) 0.34(0.32) -
λ,ν
ES - - 1.92(0.68) 1.89(0.78) 0.74(0.59)
θ
MSE 8.35(6.86) 0.47(0.96) 1.60(1.49) 0.66(1.24) -
λ
MSE 0.78(0.85) 0.03(0.05) 0.19(0.17) 0.05(0.08) -
ν
MSE 0.29(0.17) 0.01(0.02) 0.05(0.04) 0.02(0.03) 0.01(0.02)
θ
IS - - 4.30(0.33) 3.45(4.05) -
Powexp 0.05,λ
IS - - 1.47(0.26) 1.35(2.21) -
0.05,ν
IIS - - 4.22(3.28) 2.98(3.67) 3.58(5.09)
0.05
ES - - 0.82(0.32) 0.46(0.36) -
λ,ν
ES - - 0.45(0.16) 0.47(0.14) 0.23(0.14)
θ
Table1: Thetableshowsthedifferentmetricsforthedifferentestimationmethodsandmax-stablemodels. Allmetrics
arenegativelyoriented,withthebestmodelhighlightedinboldandstandarddeviationgiveninbrackets.
somecasesevenbetter. Thepairwiselikelihoodapproachleadstoverylargeerrorsincomparison,especiallyforthe
poweredexponentialmodel. WhilethemetricsoftheABCmethodarelowerthanthoseofthePLapproachtheystilldo
notcomparetotheneuralnetworkmethods.
AselectedvisualizationofthedifferentestimationmethodsisshowninFigure3. FortheBrown-Resnickmodel,it
isclearthattheenergynetworkleadstothebestestimation. WhiletheregularCNNandthePLestimationarealso
quiteclosetotheoriginalparameters,thecorrespondingextremalcoefficientfunctionismuchbetterrepresentedby
theestimatesofEN . Furthermore,iflookingattheuncertainty,theestimatedsampleshaveamuchlowerspread
λ,ν
than those of the ABC method. This also corresponds to the prediction intervals for θ(h). The same goes for the
EN ,althoughduetothenatureoftheapproachtheestimatedfunctionisnotsmooth. Whileforallthreemethods,
θ
thepointwisepredictionintervalsofθ(h)seemtobeadequate,theintervalsofEN aremuchsharperandtherefore
λ,ν
preferable. Thedirectestimateleadstoevensharperpredictionintervalsbutthetruefunctionisnotalwaysentailed,as
representedintheintegratedintervalscore. FortheSchlathermodel,thepairwiselikelihoodapproachdoesnotleadto
usableestimations,asitalwaysseemstopredicttherangeasλ=0,meaningthatallspatiallocationsareindependent,
whichalsoleadstoanincorrectextremalcoefficientfunction. Again,thepredictionsprovidedbyEN seemtofitthe
λ,ν
best,astheyscattercloselyaroundthetrueparameterandleadtoagoodrepresentationofθ(h).
3.4 Robustness
While, the previous analysis was performed under optimal conditions, where one assumes the correct model and
parameterspaceapriori,inpracticethetruemodelisnotonlyunknown,itmightevenbeunobservableornon-existent.
Thereforeitisimportanttochecktherobustnessoftheapproachagainstmodelmisspecification. Inordertodoso,we
considerthreedifferentscenarios:
1. Misspecifiedparameterrange.
2. Misspecifiedcorrelationfunction.
3. Unspecifiedmodel.
AnadditionalscenarioofanoverspecifiedmodelcanbefoundinAppendixD. Evaluatingthesescenarioswillgive
insightsonhowthedifferentestimatorsareabletoextrapolateacrosstheparametersandacrossdifferentmodels. A
robustestimatorshouldstillworkreliablyinasetting,wheretheunderlyingmodelandcorrespondingparametersare
unknown. ThenumericalresultsforthefirstandsecondscenarioareshowninTable2.
Scenario#1 Inthefirstscenario,weanalyzehowthedifferentestimatorsareabletodealwithamisspecifiedparameter
spaceinthesettingofaBrown-Resnickmodel. Forthatpurpose,thesetofparametersinthetrainingdataischosen
asasubsetfromthetestdata,forcingthemodelstopredictparametersforpreviouslyunseenprocesses. Thetraining
range is chosen as λtrain [0.5,5], νtrain [0.3,1.8], whilethe test set covers λtest (0,0.5) (5,10], νtest
∈ ∈ ∈ ∪ ∈
(0,0.3) (1.8,2].
∪
10ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Scenario#1
        
    
   
    
        
    
   
    
    
   
    
        
                                                     
h
        
    
   
    
    
   
    
        
    
   
    
        
                                                     
h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
(b)Scenario#2
    
   
    
   
    
   
    
        
        
        
        
    
                                                     
h
    
   
    
   
    
   
    
        
        
        
        
        
                                                     
h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure4: Thefigurevisualizesthedifferentestimationmethodsfortherobustnessscenariosusingaselectedtestsample
((λ,ν)=(9.04,1.64)forscenario#1and(λ,ν)=(4.00,0.81)forscenario#2). Theplotdivisionisthesameasin
Figure3.
11
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
PL CNN ABC EN EN
λ,ν θ
MSE 13.07(29.13) 9.68(10.65) 18.01(15.15) 9.47(10.15) -
λ
MSE 0.23(0.55) 0.06(0.10) 0.52(0.58) 0.03(0.06) -
ν
MSE 0.91(1.46) 0.78(0.83) 2.65(2.48) 0.55(0.52) 0.76(0.65)
θ
IS - - 87.49(68.32) 59.76(56.30) -
#1 0.05,λ
IS - - 9.12(12.24) 1.22(1.00) -
0.05,ν
IIS - - 111.21(100.04) 54.54(54.08) 92.36(78.12)
0.05
ES - - 3.25(1.75) 2.24(1.63) -
ES - - 2.88(0.99) 2.75(1.17) 2.03(1.16)
θ
MSE 9.61(7.28) 2.37(2.82) 1.70(1.47) 1.76(1.87) -
λ
MSE 0.94(0.89) 0.17(0.17) 0.17(0.16) 0.16(0.16) -
ν
MSE 0.67(0.42) 0.03(0.04) 0.17(0.19) 0.04(0.06) 0.05(0.09)
θ
IS - - 4.31(0.41) 12.38(14.42) -
#2 0.05,λ
IS - - 1.46(0.29) 4.683(5.57) -
0.05,ν
IIS - - 13.80(16.79) 7.21(12.46) 13.12(18.78)
0.05
ES - - 0.83(0.32) 0.92(0.54) -
ES - - 0.84(0.58) 0.66(0.42) 0.45(0.46)
θ
Table2: Thetableshowstheevaluationmetricsacrosstherobustnessscenarios#1and#2. Allmetricsarenegatively
oriented,withthebestmodelhighlightedinboldandstandarddeviationgiveninbrackets.
TheresultsinTable2showthattheEN obtainsthelowesterrorsforalmostallmetrics, whiletheEN obtains
λ,ν θ
similarerrorsfortheMSEandalowererrorforthefunctionalenergyscore. Incomparisontothepreviousresultsin
Table1theerrorsaregenerallyquitehigh,especiallyfortheISandtheIIS,whichindicatesthatthepredictiveintervals
mightnotbeveryadequate. However,adirectcomparisonisnotpossible,asinthisscenariothemagnitudeofthe
parametersislarger,whichleadstolargererrors. Figure4ashowsavisualizationofaselectedtestsample. Itisclear
thatallpointestimators,aswellasthefunctionalestimationsofθ(h)donotfittotherealvalueverywell. However,the
estimationsofEN doshifttothetrueparameter,extrapolatingtovaluesoutsideofthetrainingrangeofthemodel.
λ,ν
Forthisexample,nomethodprovidesadequateconfidenceintervalsforθ(h),asthetruefunctioniscoveredalmost
nowherebytheintervals. Still,thequantilepredictionsofEN arebetterintermsoftheintervalscoreanddistanceto
λ,ν
thetruefunction,asisalsoreflectedinthenumericalresults.
Scenario#2 Inthesecondscenario,weanalyzehowtheestimatorsareabletodealwithamisspecifiedmodel,by
usingaSchlatherprocesswithawrongcorrelationfunction. Forthatpurpose,atestsetisgeneratedwiththesame
parametersasbeforefor aSchlathermodelwithaWhittle-Matérn kernel, while thetrainingsetisgeneratedviaa
poweredexponentialkernel. Table2showsthatthePLapproachhasasignificantlyhigherMSEthantheothermodels,
whiletheCNNandtheABCmethodseemtoperformquitewell. Whileatafirstlook,theEN seemstohavequite
λ,ν
higherrorsinestimatingtheparameters,itresultsinreallylowerrorsformetricsregardingtheextremalcoefficient
function. Generally,theapproachcorrespondstohigherrorsinallparameterrelatedmetrics(includingtheenergyscore)
andaverylowerrorinallmetricsregardingθ. TheEN doesnotleadtomuchimprovements,exceptinthefunctional
θ
energyscore. Figure4bshowsaselectedvisualizationofthemodelestimations. Ascanbeseen,theEN extrapolates
λ,ν
tosomepreviouslyunknownparameterrangeleadingtoabadparameterestimationbutaverygoodrepresentationof
thespatialdependence. ThenormalCNNdisplaysasimilarbehavior,withagoodfitofthespatialdependence. The
EN alsoproducesvalidconfidenceintervals,whilethoseoftheABCmethoddonotleadtogoodcoverageinthis
λ,ν
example. Thisisalsothecaseforthedirectestimation,whichleadstoquitenarrowconfidenceintervals,butdoesnot
coverthetruefunctionadequately.
Scenario#3 Inthecasewherethetruemodelisunknown,itcanbeadvantageoustotrainthenetworkondifferent
underlyingmodels,sothatitcanreactflexiblytogiventestdata. Forthatpurpose,trainingdataisgeneratedfrom
theBrown-ResnickandfromtheSchlathermodelwithpoweredexponentialandWhittle-Matérnkernel. Combining
thesemodelscoversmanydifferentdatascenariosandthusshouldleadtotheneuralnetworkbeingabletogeneralize
itspredictionsacrossdifferentmodels. Weconsidertwodifferenttrainingsets,containing1666datapointsand5000
datapointsofeachmodel,respectively. Thefirstcasecorrespondstothesameamountofdatapointsasintheprevious
scenarios,whilethesecondcasealsocapturestheeffectofincreasingtheamountofdata. Thetrainedmodelsaretested
ondatafromtheBrown-ResnickmodelandfromtheSchlathermodelwithpoweredexponentialkernel. Theresultsare
showninTable3.
ComparingthesemetricswiththoseinTable1,showsthatthescoresfortheBrown-ResnickmodelforboththeEN
λ,ν
andtheEN arehigherwhentrainingondifferentmodels,unlessthedatasetisenlargedatthesametime. Forthe
θ
12ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
CNN EN EN
λ,ν θ
MSE 0.33(0.6) 0.37(0.63) 0.29(0.45)
Brown- θ
IIS - 15.94(19.62) 20.96(33.60)
Resnick 0.05
ES - 1.91(0.96) 1.00(0.79)
1666dat- θ
apoints
MSE 0.02(0.02) 0.02(0.03) 0.03(0.04)
θ
Powexp IIS - 3.70(8.13) 5.80(8.16)
0.05
ES - 0.47(0.20) 0.35(0.22)
θ
MSE 0.20(0.35) 0.23(0.40) 0.17(0.30)
Brown- θ
IIS - 13.94(19.45) 15.39(32.37)
Resnick 0.05
ES - 1.89(0.91) 0.74(0.66)
5000dat- θ
apoints
MSE 0.02(0.02) 0.02(0.02) 0.01(0.02)
θ
Powexp IIS - 2.57(2.51) 2.76(3.63)
0.05
ES - 0.46(0.18) 0.21(0.16)
θ
Table3: Thetableshowsthedifferentmetricsforthedifferentestimationmethodsandmax-stablemodelsfortraining
on1666and5000datapointseach. Allmetricsarenegativelyoriented,withthebestmodelhighlightedinboldand
standarddeviationgiveninbrackets.
SchlathermodelwithpoweredexponentialkernelthescoresinTable3aresimilartothoseinTable1,exceptforthe
intervalscore. Increasingthenumberofdatapointsimprovestheestimation,althoughonlyfortheSchlathermodel
theobtainedscoresarelowerthaninTable1. However,ahigheramountofdataalsoimprovestheestimationforthe
Brown-Resnickmodel,sothatthescoresinTable3lieinthesamerangeastheonesinTable1. Thisisaadvantageous
whendealingwithrealdata,wherethetruemodelisnotknownandcannotbeusedtodeterminetheextremalcoefficient
function,asrequiredforEN . Altogether,theseresultssuggestthattheEN mightbenefitfromtrainingondifferent
λ,ν θ
max-stable models as it can then predict the extremal coefficient function of a given dataset regardless of its true
underlyingmodel.
Thepreviousresultsindicatethatourapproachisabletolearnthecharacteristicsoftheunderlyingmisspecifiedmodel
andcanextrapolatetothecorrectmodel. Byprovidingseveralscenariosofmisspecification,wecoverdifferentcases
thatareofrelevanceinanapplicationscenarioandshowthatthenetworksstillproducerobustandreliableresults. A
closerlookontheenergyscoresforsingleobservationsgivesfurtherinsightsintocaseswheretheestimationseemsto
fail. FortheSchlathermodelwithidenticaltestandtrainingparameters,Figure5ashowsthatforEN highenergy
θ
scores don’t arise for certain values of λ and ν while for EN the scores are higher on the boundary of the test
λ,ν
parameterrange. ThisismostlikelyduetothefactthattheestimationsofEN highlydependontheparameters,
λ,ν
as opposed to EN . Analyzing robustness scenario #2, Figure 5b shows that for the EN the energy score is high
θ θ
wheneverλandν takeonlargevalues. Inspectingthepairwiseextremalcoefficientfunction,itisclearthatinthisarea
inparticular,thevaluesforthepoweredexponentialkernelandfortheWhittle-Matérnkerneldiffersignificantly. The
sameeffectcanbeseenfortheEN ,butadditionallythescoresarealsohigherinthelowerleftcorner. Avisualization
λ,ν
oftheextremalcoefficientfunctioncanbefoundinFigure17inAppendixC. Theanalysisoftheenergyscoresbased
ontheparametersλandν showsthatdependingonthegivendataoneapproachmightbepreferableovertheother.
WhiletheenergyscoresfortheEN inthenormalcasesdonotdependonparametervalues,theEN performsworse
θ λ,ν
onthemarginofthetrainedparameterrange. Alsoforthedifferentrobustnessscenariosacertainmodelcanperform
betterdependingonthetrueparameter. FurtherexamplesandinsidesaregiveninAppendixC.
13ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Schlather-poweredexponential
(b)Scenario#2
Figure5: Thefigurevisualizestheenergyscoreacrosstheparameters(λ,ν)fromthetestdata. Theupperpanels
displayresultsfromtheoptimalcasewithtestdatafromtheSchlathermodelwithpoweredexponentialkernel,while
thelowerpanelsshowresultsforrobustnessscenario#2withtestdatafromtheSchlathermodelwithWhittle-Matérn
kernel.
14ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
4 ApplicationtoGermanprecipitationextremes
Inthissection,weapplythedevelopedmethodologytoprecipitationmaximaacrossWesternGermany. Thedataset
usedistheHYRASdataset,6 whichstemsfromtheGermanNationalMeteorologicalservice(DWD)andcoversa
reanalysisofmeandailyprecipitationfrom1931until2023acrossthewholeofGermanyona1km 1kmresolution.
×
OuranalysisisrestrictedtoprecipitationmaximaoverthesummermonthsJune,JulyandAugust,inordertoreduce
seasonalityeffects,similartothesettingdescribedbyForsterandOesting(2022). Datafrom2021-2023isusedfor
assessingthepredictionquality,whiledatafrom1932-2020isusedforfittingtheGEVparameters,whicharerequired
totransformtounitFréchetmargins. Aftertheprocessing,theresultingdataisona30 30gridofaround122km
× ×
78km,coveringtheRhinelandwiththecitiesBonnandCologne,aswellastheAhrvalley,asdepictedinFigure6.
(a)2021
(b)2022
Figure6: Thefigureshowsthemaximumprecipitationinmm,aggregatedoverthethreesummermonthsoftheyears
2021and2022.
ThespecifiedareacoverstheregionwhereinJuly2021anextremelyheavyprecipitationeventtookplace,withover
150mmprecipitationonanextensiveareainaround15hto18h. Theresultingfloods, mainlyconcerningtheAhr
valley,ledtoatleast180fatalities,40.000peopleaffectedandanestimateddamageofaroundEUR32billion7. Foran
overviewandadescriptionoftheeventseeforexampleBosseleretal.(2021)orMohretal.(2023). However,itis
worthmentioningthatthemonthlyprecipitationmaximainJuly2021wasthehighestrecordedmaxima,acrossall
availabledata. Whilethemagnitudeofthiseventisquiteextreme,thespatialdependencemightbeverysimilartoother
observations.
InordertotransformthedataintounitFréchetmargins,wefitaresponsesurface(Ribatet,2013)thatincludesadditional
covariates. ExtensivemodelselectionisomittedandwefollowanapproachsimilartoDavisonandGholamrezaee
(2012); Sang and Gelfand (2010). More details can be found in Appendix E. Contrary to the simulation setting,
withtheactualdatawedonotknowtheunderlyingmodelorparameters. Althoughwehavethoroughlyassessedthe
performanceoftheapproachpreviously,forthissettingdifferentmeansofevaluationarerequired. Furthermore,recall
thatsofarthetrainingparameterswereusuallychosenfromsomepre-specifiedparameterrange. Inordertokeepthe
settingsimilartothesimulationstudies,thedatagridwastransformedtounitsof3.4km,whichallowstousethesame
6DeutscherWetterdienst,HYRAS-HydrometeorologischeRasterdaten,version5.0(https://www.dwd.de/DE/leistungen/
hyras/hyras.html)
7MunichRe,Hurricanes,coldwaves,tornadoes:WeatherdisastersinUSAdominatenaturaldisasterlossesin2021,Pressreport
10.01.2022(link,accessedon07.11.2023)
15ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
 3 D U D P H W H U V  ( 1  ( 1
        ,    
       
   
       
   
       
   
       
           
                                                   
           
       
   
       
   
       
   
       
           
                                                   
           
       
   
       
   
       
   
       
           
                                                   
h  > N P @ h  > N P @
 - X Q H  - X O \  $ X J X V W
Figure7: Thefigureshowstheparameterestimatesforapoweredexponentialmodelforallthreemonthsandyears
usingtheproposedapproaches. Theyearsarefrom2021-2023fromtoptobottom.
supportpointsforestimatingEN .8 Inordertocoveralargerangeofdependencies,wethenchoosetosimulatedata
θ
fromλ (0,50], ν (0,2].
∈ ∈
Asourdatastemsfromafairlylimitedarea,wedonotnecessaryexpectanyspatialmaximatobeindependent. Forthat
reason,aSchlathermodelseemsappropriate,asitdescribesprocessesthatneverreachfullindependence. Therefore,
wemainlyvisualizeresultsfortheSchlathermodelinthissection,whileadditionalfigurescanbefoundinAppendixA.
Figure7showstheestimationsfrombothapproachesforthecaseofapoweredexponentialmodel. Itisvisiblethatboth
estimationsarequiteconsistent,inestimatingverysimilarextremalcoefficientfunctionswithonlyminorfluctuations
throughoutthemonths. Inaddition,theresultsalsoseemtobesimilaracrossthedifferentyears,withsmallvariations.
ThesamegoesfortheparameterestimationsoftheEN approach.
λ,ν
Inordertoquantifythemodelfit,weproposetousetheso-calledlogarithmicscore,whichisastrictlyproperscoring
rule9 and can be interpreted as the Kullback-Leibler divergence for a sample observation. For the purpose of this
application,onecancalculatethelogarithmicscorebycalculatingtheparametrizedbivariatedensityoftherealized
observation:
LogS(F,z ,z )= logf(z ,z ;γ),
1 2 1 2
−
whereF isapredictiveCDFofamax-stableprocesswithbivariatedensityf (dependentontheparametervectorγ)
andz ,z areobservedprocesses. Thiscalculationresultsinalogarithmicscoreforeachsummermonthandyear,
1 2
aggregatedinTable4. ThelowestscoreisobtainedbythepairwiselikelihoodapproachandtheBrown-Resnickmodel,
althoughthedifferencesbetweenallscoresarequitelow. Itwasanticipatedthatthepairwiselikelihoodapproach
wouldperformverywellhere,asitisbasedonthebivariatedensity. However,asthismethoddependsonassumingan
underlyingmodelandmightbebiasedduetothesmallsamplesize,additionalevaluationtoolsshouldbeconsidered.
Forthatmatter,weemploytheso-called(binned)F-madogram(Cooleyetal.,2006),whichistypicallyusedinpractice
forestimatingthespatialdependenceandisdirectlyrelatedtothepairwiseextremalcoefficientfunction. Sincethe
8Thiscorrespondstoamaximumspatialseparationbetweentwolocationsof∥h max∥≈42.5.
9ForamoreprecisecharacterizationseeGneitingandRaftery(2007).
16
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
PL CNN EN
λ,ν
Brown-Resnick 5.890 5.948 6.321
Poweredexponential 6.008 5.987 6.020
Whittle-Matérn - 6.013 6.030
Table4: Thetableshowsthemeanlogarithmicscoreforthreedifferentmethodsandtwomodelsacrosstheobserved
testdata. FortheEN themeanpredictionisused. Thelowestscoreishighlightedinbold. Thepairwiselikelihood
λ,ν
scoreisnotalwayscomputable,asthemethodspredictsvaluesthatleadtoaill-defineddensity.
Figure8: Thefigureshowsthedifferentestimatesfortheextremalcoefficientfunction. Theblackdotsarethebinned
F-madogramestimatesandthelinescorrespondtothepointwisemeanoftheestimatedextremalcoefficientfunctions.
TheleftpanelsshowsF-madogramestimatewithdatafrom2021-2023andtherightpanelwithdatafrom2011-2023.
evaluation period (2021-2023) is quite short, the estimator will likely be highly biased due to small sample size.
Therefore,weprovideanadditionalestimatethatisbasedontheyears2011-2023. Foreachmodelthepointwisemean
ofθ(h)istakenacrossallthreesummermonths,tocompareagainsttheF-madogram. Thedifferentestimatesforθ(h)
arevisualizedinFigure8.
The results suggest that our model is able to correctly approximate the spatial dependence in the data by fitting a
parametricmax-stablemodeloramodel-freeextremalcoefficientfunction,dependingontheapproach. Asthepairwise
likelihoodestimatordoesnotleadtosensibleresultsduetooptimizationissuesinsmallsamplesizes,itdoesnotprovide
a usable model fit. For the powered exponential model, visualized in Figure 8, both approaches seem to be fairly
consistentandfitwelltotheempiricalmadogramestimation. Inaddition,bothmethodsareabletoproduceprediction
intervalsforθ(h). Figure9showsaselectedpredictionforthespatialdependenceoftheextremeprecipitationeventin
July2021withcorrespondingconfidencebands. ThefunctionestimatedbyEN showsasteeperascentascompared
θ
totheestimationbyEN ,indicatingahigherspatialindependencefortheprecipitationacrossthedistanceh. In
λ,ν
additionitseamstostagnateforlargedistances,whilethefunctionestimatedbyEN isstillgrowing,indicatingthat
λ,ν
fullspatialindependenceofprecipitationmaximaisonlyreachedforlocationswithspatialseparationfarextendingthe
datadomain. Additionalvisualizationsofothermax-stablemodelscanbefoundinAppendixA,whileAppendixF
includesacomparisonofsimulatedprocessesandactualobservations.
Figure9: ThefigureshowsestimationsoftheextremalcoefficientfunctionforJuly2021. Theblackdotsdisplaythe
madogramestimateoverthelasttenyearsasareference.
17ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
5 Discussion
Inthiswork,weintroduceagenerativeneuralnetwork-basedapproachforanalyzingspatialextremesbyestimatingthe
fullparameterdistributionofmax-stablemodels,wherethelikelihoodfunctionisnotavailable. Withtheproposed
approach,onecanperformparameterestimation,whereclassicaltheorytendstofail,duetoaninfeasiblelikelihood,
underverysmallsamplesizes. Ourmethodisnotonlyabletopredictparametersoftheunderlyingprocess,butpredicts
awholeparameterdistribution. Thisallowsforuncertaintyquantificationwithnoadditionalcost,whichisanimportant
step in replacing classical statistical methods that would provide standard errors or other measures of uncertainty.
Finally,weextendourapproachtodirectlypredictthedistributionofthepairwiseextremalcoefficientfunction,which
isanimportanttoolinassessingthespatialdependenceoftheunderlyingprocess. Withthisextensionnounderlying
parametricmodelneedstobeimposedandthefunctionalandcorrespondinguncertaintycanbeestimateddirectly.
We demonstrate the effectiveness of the two neural networks in several simulation studies of different max-stable
processesandprovideseveralevaluationprocedures,coveringuncertaintyquantification,aswellasevaluationofthe
predictedspatialdependence. Incomparisonwithdifferentbenchmarksourmodelsshowpreferablemetricsacross
differentscenarios. Tovalidatetherobustnessoftheapproach,severalanalysesareperformedundertheassumption
ofmodelmisspecification. Thecorrespondingresultsandmetricssuggestthatinseveralscenariosthenetworksare
abletoprojectandextrapolateontothetruemodel,evenifitwasunseenduringthetrainingphase. Bycomparingand
analyzingthetwodifferentmethods,weprovideageneralframeworkthatcanbeadjustedtothespecificscenarioand
needs,forexampleifoneisdirectlyinterestedinparameterdependentfunctionalsofthemodel. Whilebothapproaches
outperformtheimplementedbenchmarks,theEN providesbetterintervalestimationsingeneral,whiletheEN leads
λ,ν θ
toasignificantlysmallerEnergyScore. Tovalidateourapproach,weprovideanempiricalstudyofmonthlysummer
precipitationmaximaacrossGermany. Althoughinthatsettingthetruemodelisunknown,wepresentseveralways
toverifythepredictionsofthenetworks,specificallyregardingtheestimationofthespatialdependence. Whilethis
applicationismainlyademonstrationofthemodelscapabilitiesandmightlackfurtherevaluationcomparedtoother
literatureregardingextremeeventanalysis,ithighlightsthatthedevelopedmethodissuitableforestimatingspatial
environmentalprocessesandseemstohavemultiplebenefitscomparedtoclassicalmethods.
Whilethisworkfocusedonspecifictypesofmax-stableprocesses,thegeneralapproachcaneasilybemodifiedforother
relevantintractablemodels,suchasthreedimensionalmax-stableprocessesorepidemiologicalmodels(Lawson,2018),
aswellasotherparameter-dependentfunctionalsofinterest. Changingtheunderlyingprocesswouldusuallyjustrequire
achangeinthenetworkarchitecture,whereasthegeneralapproachstaysthesame. Thisindicatesapromisingareaof
research,asneuralnetworksmightbeincreasinglyusefulforparameterestimationincomplexsettings. Especially
withmoresophisticatedsimulationsmethods,suchasMarkovChainMonteCarlo,onecouldextendtheapproachto
highlycomplexphysicalprocesses. Extendingtheapproachtoamoregeneralapplicationindependentframeworkis
thereforeapromisingdirectionofresearch. Anotherstepinthatdirectionistodiscoverwaystomaketheapproach
more automatic. For example, one could drop the need to specify a prior parameter range by implementing some
iterativeapproachthatconvergesautomaticallytothebestestimation. Anextensionfortheproposednetworkwouldbe
quitenatural,asthepredictedparametersamplescanbeusedtosimulatenewprocessesinaniterativemanneruntil
somestoppingcriterionisused. Thiscouldmakethesimulationprocessmoreefficient(compareSainsbury-Daleetal.,
2022),butanunlimitedamountofavailablesamplesmightbeunrealisticfromanapplicationpointofview. Finally,
moreresearchisrequiredinanalyzingtheextrapolationcapacitiesofthemodels. Whilethepreviousresultsarehighly
promising,neuralnetworkscanstrugglewithextrapolationandoneshouldbeinterestedincases,whereandwhythe
estimationsfail. Whiletheseareallpromisingdirectionsoffurtherresearch,thedevelopedframeworkshowstobevery
suitableforparameterandfunctionalestimationincomplexintractablemodelsandhasthepossibilitytobeappliedto
newscenariosinthenearfuture.
18ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
References
Beaumont,M.A.,Zhang,W.,andBalding,D.J. ApproximateBayesianComputationinPopulationGenetics. Genetics,
162(4):2025–2035,122002.
Bosseler,B.,Salomon,M.,Schlüter,M.,andRubinato,M. Livingwithurbanflooding: Acontinuouslearningprocess
forlocalmunicipalitiesandlessonslearntfromthe2021eventsingermany. Water,13(19):2769,2021.
Brehmer,J.R.andStrokorb,K. Whyscoringfunctionscannotassesstailproperties. ElectronicJournalofStatistics,13
(2):4015–4034,2019.
Castruccio,S.,Huser,R.,andGenton,M.G. High-ordercompositelikelihoodinferenceformax-stabledistributions
andprocesses. JournalofComputationalandGraphicalStatistics,25(4):1212–1229,2016.
Chen, J., Janke, T., Steinke, F., and Lerch, S. Generative machine learning methods for multivariate ensemble
post-processing. workingpaper,2022. URLhttps://arxiv.org/pdf/2211.01345.pdf.
Cooley,D.,Naveau,P.,andPoncet,P. Variogramsforspatialmax-stablerandomfields. InDependenceinProbability
andStatistics,volume187,pages373–390.2006.
Creel,M. Neuralnetsforindirectinference. EconometricsandStatistics,2:36–49,2017.
Davis, R. A., Klüppelberg, C., and Steinkohl, C. Statistical inference for max-stable processes in space and time.
JournaloftheRoyalStatisticalSocietySeriesB:StatisticalMethodology,75(5):791–819,2013.
Davison,A.C.andGholamrezaee,M.M. Geostatisticsofextremes. ProceedingsoftheRoyalSocietyA:Mathematical,
PhysicalandEngineeringSciences,468(2138):581–608,2012.
Davison,A.C.andHuser,R. Statisticsofextremes. AnnualReviewofStatisticsandItsApplication,2(1):203–235,
2015.
Davison,A.C.,Padoan,S.A.,andRibatet,M. Statisticalmodelingofspatialextremes. StatisticalScience,27(2),2012.
deHaan,L.andFerreira,A. ExtremeValueTheory: AnIntroduction. SpringerLinkBücher.SpringerNewYork,New
York,NY,2006.
Erhardt,R.J.andSmith,R.L. Approximatebayesiancomputingforspatialextremes. ComputationalStatistics&Data
Analysis,56(6):1468–1481,2012.
Fearnhead,P.andPrangle,D. Constructingsummarystatisticsforapproximatebayesiancomputation: semi-automatic
approximatebayesiancomputation. JournaloftheRoyalStatisticalSociety: SeriesB(StatisticalMethodology),74
(3):419–474,2012.
Forster,C.andOesting,M. Non-stationarymax-stablemodelswithanapplicationtoheavyrainfalldata. working
paper,2022. URLhttps://arxiv.org/pdf/2212.11598.pdf.
Franks,J.J. Handbookofapproximatebayesiancomputation. JournaloftheAmericanStatisticalAssociation,115
(532):2100–2101,2020.
Gerber, F. and Nychka, D. Fast covariance parameter estimation of spatial gaussian process models using neural
networks. Stat,10(1),2021.
Gneiting, T. andRaftery, A. E. Strictly proper scoring rules, prediction, and estimation. Journal of the American
StatisticalAssociation,102(477):359–378,2007.
Huser,R.andDavison,A.C. Compositelikelihoodestimationforthebrown-resnickprocess. Biometrika,100(2):
511–518,2013.
Huser,R.,Davison,A.C.,andGenton,M.G. Likelihoodestimatorsformultivariateextremes. Extremes,19(1):79–103,
2016.
Huser,R.,Dombry,C.,Ribatet,M.,andGenton,M.G. Fulllikelihoodinferenceformax–stabledata. Stat,8(1),2019.
Huser,R.,Stein,M.L.,andZhong,P. Vecchialikelihoodapproximationforaccurateandfastinferenceinintractable
spatialextremesmodels. workingpaper,2022. URLhttps://arxiv.org/pdf/2203.05626.pdf.
Kabluchko,Z.,Schlather,M.,anddeHaan,L. Stationarymax-stablefieldsassociatedtonegativedefinitefunctions.
TheAnnalsofProbability,37(5),2009.
Lawson,A.B. Bayesiandiseasemapping: hierarchicalmodelinginspatialepidemiology. CRCpress,2018.
Lenzi,A.andRue,H. Towardsblack-boxparameterestimation. workingpaper,2023. URLhttps://arxiv.org/
pdf/2303.15041.
Lenzi, A., Bessac, J., Rudi, J., and Stein, M. L. Neural networks for parameter estimation in intractable models.
ComputationalStatistics&DataAnalysis,185:107762,2023.
19ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
Mohr,S.,Ehret,U.,Kunz,M.,Ludwig,P.,Caldas-Alvarez,A.,Daniell,J.E.,Ehmele,F.,Feldmann,H.,Franca,M.J.,
Gattke,C.,Hundhausen,M.,Knippertz,P.,Küpfer,K.,Mühr,B.,Pinto,J.G.,Quinting,J.,Schäfer,A.M.,Scheibel,
M.,Seidel,F.,andWisotzky,C. Amulti-disciplinaryanalysisoftheexceptionalfloodeventofJuly2021incentral
Europe–Part1: Eventdescriptionandanalysis. NaturalHazardsandEarthSystemSciences,23(2):525–551,2023.
Oesting,M.,Schlather,M.,andFriederichs,P. Statisticalpost-processingofforecastsforextremesusingbivariate
brown-resnickprocesseswithanapplicationtowindgusts. Extremes,20(2):309–332,2017.
Pacchiardi,L.andDutta,R. Likelihood-freeinferencewithgenerativeneuralnetworksviascoringruleminimization.
workingpaper,2022. URLhttps://arxiv.org/abs/2205.15784.
Pacchiardi, L., Adewoyin, R.A., Dueben, P., andDutta, R. Probabilisticforecastingwithgenerativenetworksvia
scoringruleminimization. JournalofMachineLearningResearch,25(45):1–64,2024.
Padoan,S.A.,Ribatet,M.,andSisson,S.A. Likelihood-basedinferenceformax-stableprocesses. Journalofthe
AmericanStatisticalAssociation,105(489):263–277,2010.
Perez,L.andWang,J. Theeffectivenessofdataaugmentationinimageclassificationusingdeeplearning. working
paper,2017. URLhttps://arxiv.org/pdf/1712.04621.pdf.
Radev,S.T.,Mertens,U.K.,Voss,A.,Ardizzone,L.,andKöthe,U. Bayesflow: Learningcomplexstochasticmodels
withinvertibleneuralnetworks. IEEETransactionsonNeuralNetworksandLearningSystems,33(4):1452–1466,
2022.
Rai,S.,Hoffman,A.,Lahiri,S.,Nychka,D.W.,Sain,S.R.,andBandyopadhyay,S. Fastparameterestimationof
generalizedextremevaluedistributionusingneuralnetworks. workingpaper,2023. URLhttps://arxiv.org/
pdf/2305.04341.pdf.
Ramesh,P.,Lueckmann,J.-M.,Boelts,J.,Tejero-Cantero,Á.,Greenberg,D.S.,Goncalves,P.J.,andMacke,J.H.
GATSBI:Generativeadversarialtrainingforsimulation-basedinference. InInternationalConferenceonLearning
Representations,2022.
Ribatet,M. Spatialextremes: Max-stableprocessesatwork. JournaldelaSociétéFrançaisedeStatistique,,154(2):
156–177,2013.
Ribatet,M. Spatialextremes: Modellingspatialextremes,2022. URLhttps://CRAN.R-project.org/package=
SpatialExtremes.
Sainsbury-Dale, M., Zammit-Mangion, A., andHuser, R. Likelihood-freeparameterestimationwithneuralbayes
estimators. workingpaper,2022. URLhttps://arxiv.org/pdf/2208.12942.
Sang,H.andGelfand,A.E. Continuousspatialprocessmodelsforspatialextremevalues. JournalofAgricultural,
Biological,andEnvironmentalStatistics,15(1):49–65,2010.
Schlather,M. Modelsforstationarymax-stablerandomfields. Extremes,5(1):33–44,2002.
Stephenson, A. and Tawn, J. Exploiting occurrence times in likelihood inference for componentwise maxima.
Biometrika,92(1):213–227,2005.
Thibaud,E.,Aalto,J.,Cooley,D.S.,Davison,A.C.,andHeikkinen,J. Bayesianinferenceforthebrown–resnick
process,withanapplicationtoextremelowtemperatures. TheAnnalsofAppliedStatistics,10(4),2016.
20ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
A AdditionalVisualizations
21ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Brown-Resnick
            
            
   
            
        
       
        
                                               
        
       
        
            
   
        
   
            
                                                           
        
   
            
   
                
            
   
            
                                           
            
                
                
        
       
        
                                                                 
h h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
(b)Schlather
        
    
                 
                 
             
   
             
                                                           
        
                
            
            
   
        
                                             
        
   
            
   
        
   
            
   
            
                                     
        
   
            
   
            
   
        
       
        
                                           
h h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure10: Thefigurevisualizesthedifferentestimationmethodsforthemax-stablemodelsusingfourrandomlydrawn
testsamples. TheplotdivisionisthesameasinFigure3.
22
)h(
)h(
)h(
)h(
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Scenario#1
        
                
                
        
   
            
                                                   
        
                
            
   
        
   
        
                                                       
            
                
        
       
        
   
            
                                                       
        
                 
                 
                 
                                                                 
h h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
(b)Scenario#2
        
   
   
        
   
   
            
   
            
                                            
        
   
   
        
   
   
        
       
        
                                                           
        
   
   
            
   
            
   
            
                                             
        
   
   
        
   
   
        
       
        
                                           
h h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure11: Thefigurevisualizesthedifferentestimationmethodsforthetworobustnessscenariosusingfourrandomly
drawntestsamples. TheplotdivisionisthesameasinFigure3.
23
)h(
)h(
)h(
)h(
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Brown-Resnick
 3 D U D P H W H U V  ( 1  ( 1
        ,    
           
       
   
       
           
           
                                                     
           
           
       
   
       
           
           
                                                     
           
           
       
   
       
           
           
                                                     
h  > N P @ h  > N P @
 - X Q H  - X O \  $ X J X V W
(b)Whittle-Matérn
 3 D U D P H W H U V  ( 1  ( 1
        ,    
           
       
   
       
           
           
                                                      
           
           
       
   
       
           
           
                                                      
           
           
       
   
       
           
           
                                                      
h  > N P @ h  > N P @
 - X Q H  - X O \  $ X J X V W
Figure12: Thefigureshowstheparameterestimatesfordifferentmodelsforallthreemonthsandyearsusingthe
proposedapproaches. Theyearsarefrom2021-2023fromtoptobottom.
24
)h(
)h(
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
(a)Brown-Resnick
(b)Whittle-Matérn
Figure13: Thefigureshowsthedifferentestimatesfortheextremalcoefficientfunction. Theblackdotsarethebinned
F-madogramestimatesandthelinescorrespondtothepointwisemeanoftheestimatedextremalcoefficientfunctions.
TheleftpanelsshowsF-madogramestimatewithdatafrom2021-2023andtherightpanelwithdatafrom2011-2023.
25ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
B Retainingmonotonicity
Forthedirectestimationofθ(h )withEN itcannotlongerbeguaranteedthatθˆ (h ) θˆ (h )fori j, r =
disc θ r i r j
≤ ≤ ∀
1,...,k. Theproblemcanbesolvedbysortingtheestimatedvaluesinascendingorder. Sincetheestimatedvaluescan
fluctuategreatly,sortingforallr =1,...,kleadstoanincreaseinthefunctionattheupperboundofthediscretization
(here42.5). Figure14visualizesthisproblemandalsoshowsapossiblesolution. Insteadofsortingfirstallofthe
values,thefunctionalofinterest,e.g. meanoracertainquantile,iscomputedandafterwordsthesortingofforexample
θˆ(h ),...,θˆ(h )isperformed. Thiswaytheincreaseofthefunctionnearthemarginisflattenedandtheestimated
1 k
functionalofthepairwiseextremalcoefficientfunctionisstillmonotone.
(a)Meanprediction
(b)Quantileprediction
Figure14: EstimatesofpairwiseextremalcoefficientfunctionofEN withdifferentwaysofsorting. Ontheleft,the
θ
valuesθˆ(h ), i = 1,...,k arenotsorted,onlythefunctionalsarecalculatedofthegivensample. Inthemiddlethe
i
functionaliscalculatedandafterwardsthevaluesaresortedinascendingorder,whileontherightthevaluesarefirst
sortedandthenthefunctionaliscalculated.
26ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
C EnergyScoreanalysisoftestdata
SimilarlytoFigure5insection3avisualizationoftheenergyscoresforsingleobservationsfortheBrown-Resnick
modelisgiveninFigure15andforrobustnessscenario#1inFigure16. AsinthecaseoftheSchlathermodelwith
poweredexponentialkernelforEN highenergyscoresdon’tariseforcertainvaluesofλandν whileforEN the
θ λ,ν
scoresarehigheronthemarginsofthetestparameterrange,especiallyintheupperleftandthelowerrightcorner,as
visualizedinFigure15.
Figure15: Energyscoreforparameters(λ,ν)andregulartestdatafromtheBrown-Resnickmodel.
Inthecaseofrobustnessscenario#1,wheretherangeoftrainedandtestedparametersdiffer,theEnergyscoreislarger
fortestparametersfurtherawayfromthetrainingparameters. FortheEN parametersespeciallyintheupperright
θ
cornercorrespondtohigherenergyscores. Apossibleexplanationcanbeobtainedbyconsideringthevaluesofthe
pairwiseextremalcoefficientfunctioninFigure17. Thefirstcolumnshowsthatthereexistsnearlyafulldependency,
whichisnotthecaseforlowervaluesofλandν. FortheEN theenergyscoreslooksimilartothoseinFigure15
λ,ν
althoughthevaluesareslightlyhigher.
27ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
Figure16: Energyscoresforparameters(λ,ν)androbustnessscenario#1withtestdatafromtheBrown-Resnick
model.
28ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
Figure17: Visualizationofthepairwiseextremalcoefficientfunctionindependenceofλandν fordifferentmodels
anddistancesh. Intoprowhissetto1,inthemiddleh=3andinthebottomrowh=6.
29ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
D Additionalrobustnessscenario
In this additional robustness scenario, we investigate whether the methods are able to correctly estimate an over-
parametrizedmodel. Forthatpurpose,themethodsaretrainedonaBrown-Resnickmodel,whilethetrueprocesses
stemfromaSmithmodel,whichcanbeseenasaspecialcaseoftheprior. ThebivariateCDFofaBrown-Resnick
processisgivenby
(cid:18) 1 (cid:18) a 1 (cid:16)z (cid:17)(cid:19) 1 (cid:18) a 1 (cid:16)z (cid:17)(cid:19)(cid:19)
2 1
P(Z(x 1) z 1,Z(x 2) z 2)=exp Φ + log Φ + log ,
≤ ≤ − z 2 a z − z 2 a z
1 1 2 2
witha2 =2γ(h)=2( h /λ)ν. IntheSmithmodelitholdsthata2 =h⊤Σ−1hwithcovariancematrixΣ Rd×d.
NowconsideraSmith∥ mo∥ delwithdiagonalcovariancematrixΣ=diag(σ). Thena2 = h 2/σ,whichcorr∈ esponds
∥ ∥
toaBrown-Resnickprocesswithν =2andλ=√2σ. Agoodestimatorshouldbeabletocopewiththeadditional
degreeoffreedomandthereforealwayspredictthesmoothnessparameterasν =2. Again,atestsetofsizen=250
is simulated based on the Smith model with σ (0.5,5), while the different methods are optimized under the
∼ U
assumptionofaBrown-Resnickmodelwithλ (0.5,5), ν (0,2).
∼U ∼U
TheresultsinTable5showthattheEN hasthelowesterrorforallparameter-relatedmetrics. Especiallytheerrorof
λ,ν
ν issignificantlylowerascomparedtotheothermethods,indicatingthattheEN isabletocorrectlyidentifythe
λ,ν
fixedparameterν =2. TheCNNandPLapproachalsodisplayfairlylowmetrics,whiletheABCmethoddoesnot
seemtoprovideadequatepredictions. TheEN leadstosignificantlyimprovementsregardingthemetricsinvolvingthe
θ
extremalcoefficientfunction. Figure18showsavisualizationoftheestimates. AllmethodsexceptABCprovidefairly
accurateparameterpointestimates. Furthermore,thepredictivedistributionoftheEN seemstobeveryconcentrated,
λ,ν
indicatingthatthemodelisconfidentinthetrueparameterlyinginthatrange. Thisisalsoreflectedinthenarrow
predictiveintervalsfortheextremalcoefficientfunction. TheseresultsindicatethattheEN isabletoprovidevalid
λ,ν
predictionsevenifoperatingwithanadditionaldegreeoffreedom. ThesamegoesfortheEN ,althoughthepredictive
θ
intervalsaremarginallywiderthanoftheEN .
λ,ν
PL CNN ABC EN EN
λ,ν θ
MSE 0.23(1.12) 0.15(0.20) 0.89(1.11) 0.11(0.21) -
λ
MSE 0.16(0.39) 0.05(0.05) 0.81(0.68) 0.02(0.02) -
ν
MSE 0.25(0.84) 0.08(0.07) 1.83(2.31) 0.04(0.04) 0.03(0.03)
θ(h)
Scenario IS - - 4.22(0.89) 1.43(1.34) -
0.05,λ
#3 IS - - 9.28(14.58) 2.18(1.20) -
0.05,ν
IIS - - 79.17(146.55) 3.36(3.56) 3.87(2.98)
0.05
ES - - 0.89(0.40) 0.20(0.13) -
ES - - 2.11(0.40) 0.62(0.34) 0.35(0.14)
θ
Table5: Thetableshowstheevaluationmetricsacrossthedifferentscenariosforrobustnesschecks. Allmetricsare
negativelyoriented,withthebestmodelhighlightedinboldandstandarddeviationgiveninbrackets.
30ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
        
    
   
    
        
    
   
    
    
   
    
        
                                                      
h
        
    
   
    
        
    
   
    
    
   
    
        
                                                      
h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure18: Thefigurevisualizesthedifferentestimationmethodsfortheadditionalrobustnessscenariousingaselected
testsample((λ,ν)=(1.63,2.00)). TheplotdivisionisthesameasinFigure3.
                
                
        
       
        
       
        
                                                           
                
                
        
       
        
       
        
                                                       
                
                
        
       
        
   
            
                                                   
                
            
   
        
   
        
   
   
        
                                                           
h h
 7 U X H  3 /  $ % &  & 1 1  ( 1,  ( 1
Figure19: Thefigurevisualizesthedifferentestimationmethodsfortheadditionalrobustnessscenariousingfour
randomlydrawntestsamples. TheplotdivisionisthesameasinFigure3.
31
)h(
)h(
)h(
)h(
)h(
)h(ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
E GEVfit
TheGEVparametersaremodeledbythefollowingequations
µ(i,t)=β +β lat(i)+β +lon(i)+β t
0,µ 1,µ 2,µ 3,µ
σ =β
0,σ
γ =β ,
0,γ
wherei=1,...,900istheindexofthecorrespondinglocation,tistheyearoftheobservationandlat,londescribethe
latitudeandlongitude,respectively. Whilethismodelcanonlydescribelinearrelationshipsacrossthecovariates,this
usuallysufficesinpractice,althoughinprinciplemoresophisticatedapproachesarepossible. Themodelisfittedusing
thefunctionfitspatgevoftheSpatialExtremespackage(Ribatet,2022).
TheestimatedparametersandthecorrespondingstandarderrorsareshowninTable6. Firstof,notethattheshape
β β β β β β
0,µ 1,µ 2,µ 3,µ 0,σ 0,γ
Estimation 64.7996 -0.9997 0.0149 0.0011 7.0045 0.1052
Standarderror 27.3724 0.5433 0.3192 0.0104 0.2126 0.0224
Table 6: The estimated GEV parameters and corresponding standard errors of the model described above. The
parameterswerefitonthethreesummermonthsovertheyearsof1931-2020.
parameter is estimated as γ = 0.1052 > 0, which indicates that the data can best be described using a Fréchet
distribution. Thismakessense,sincetheFréchetdistributionhasaleftendpoint,whichisreasonablesinceprecipitation
canonlytakenonnegativevalues. UsingtheestimatesfromTable6,theobservedprecipitationfieldsaretransformedto
unitFréchetmargins.
32ESTIMATIONOFSPATIO-TEMPORALEXTREMESVIAGENERATIVENEURALNETWORKS
F SimulatedprecipitationoverGermany
(a)2022
(b)Sampleprocesssimulations
Figure20: Thefigureshowstheobservedprecipitationmaximain2022(toprow)andcorrespondingsimulationsfrom
anestimatedSchlathermodelwithpoweredexponentialcorrelationfunction(bottomrows). Thesimulationshavebeen
transformedbacktotheoriginalGEVsurface.
33